<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]
- [cs.SE](#cs.SE) [Total: 2]
- [cs.LO](#cs.LO) [Total: 4]
- [cs.CL](#cs.CL) [Total: 2]
- [cs.DM](#cs.DM) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Decompiling Rust: An Empirical Study of Compiler Optimizations and Reverse Engineering Challenges](https://arxiv.org/abs/2507.18792)
*Zixu Zhou*

Main category: cs.PL

TL;DR: 本文系统性评估了 Rust 反编译难点，指出泛型、trait 和错误处理机制极大影响反编译质量，并呼吁开发专门应对 Rust 的反编译工具。


<details>
  <summary>Details</summary>
Motivation: Rust 由于其复杂的类型系统、编译优化和高级抽象的广泛使用，使得反编译极具挑战性。但目前缺乏对不同 Rust 语言特性、编译模式下反编译质量的系统评估。本文旨在填补这一研究空白。

Method: 本文采用基准测试驱动的方法，设计自动化评分框架，定量评估 Rust 不同核心特性和编译模式下的反编译质量。同时通过典型案例研究，分析语言特性如何影响控制流、变量命名与类型信息恢复。

Result: 实验证明，泛型类型、trait 方法和错误处理结构会显著降低反编译质量，且 release 模式影响更大。具体分析揭示了 Rust 语言结构对反编译难度的具体影响。

Conclusion: 本文为工具开发者提供了可操作性建议，强调了急需开发具备 Rust 感知能力的反编译策略。

Abstract: Decompiling Rust binaries is challenging due to the language's rich type
system, aggressive compiler optimizations, and widespread use of high-level
abstractions. In this work, we conduct a benchmark-driven evaluation of
decompilation quality across core Rust features and compiler build modes. Our
automated scoring framework shows that generic types, trait methods, and error
handling constructs significantly reduce decompilation quality, especially in
release builds. Through representative case studies, we analyze how specific
language constructs affect control flow, variable naming, and type information
recovery. Our findings provide actionable insights for tool developers and
highlight the need for Rust-aware decompilation strategies.

</details>


### [2] [IsaMini: Redesigned Isabelle Proof Lanugage for Machine Learning](https://arxiv.org/abs/2507.18885)
*Qiyuan Xu,Renxi Wang,Haonan Li,David Sanan,Conrad Watt*

Main category: cs.PL

TL;DR: 本文提出的新型证明语言MiniLang，通过优化表示方式，显著提升了基于LLM的自动化定理证明成功率，为形式化验证领域带来新的突破。


<details>
  <summary>Details</summary>
Motivation: 现有的形式化证明自动化依赖于大型语言模型（LLMs），但模型对表示方式高度敏感，证明语言的设计对自动证明成功率有直接影响。本文旨在通过重新设计证明语言，提升神经定理证明（NTP）系统的性能，以降低证明工程的人力和计算成本。

Method: 作者提出了一种新的证明语言MiniLang，并将其集成到Isabelle/HOL中，同时改进了Sledgehammer工具。对两种微调后的LLM进行了实验，采用PISA基准测试评估生成MiniLang与传统Isar证明脚本的表现；通过pass@1和pass@8等指标对比自动证明的成功率。

Result: 使用MiniLang后，微调LLM在PISA基准上的证明成功率提升显著。pass@1成功率达到69.1%，超过了以往Baldur模型pass@64的65.7%；pass@8达到79.2%，优于目前同类最佳方法Magnushammer在PISA基准上的71.0%。

Conclusion: 重新设计的MiniLang证明语言能够充分发挥LLMs的能力，在自动化形式化证明中显著提升了成功率，显示出改进表示方式对神经定理证明系统的巨大潜力。

Abstract: Neural Theorem Proving (NTP) employs deep learning methods, particularly
Large Language Models (LLMs), to automate formal proofs in proof assistants.
This approach holds promise for reducing the dramatic labor costs or
computation costs required in proof engineering, which is fundamental to formal
verification and other software engineering methods. The paper explores the
potential of improving NTP by redesigning the proof language, given that LLMs'
capabilities depend highly on representations. We introduce \emph{MiniLang}, a
redesigned proof language for Isabelle/HOL incorporating an improved version of
Sledgehammer. Experiments show MiniLang benefits two fine-tuned LLMs by
improving the success rate on the PISA benchmark by up to 29\% in comparison to
generation of Isar proof script. The success rate under one attempt (so-called
\emph{pass@1}) reaches 69.1\%, exceeding the previous Baldur's pass@64
(65.7\%); The pass@8 reaches 79.2\%, exceeding the state-of-the-art on PISA
(71.0\%) achieved by Magnushammer.

</details>


### [3] [An Enumerative Embedding of the Python Type System in ACL2s](https://arxiv.org/abs/2507.19015)
*Samuel Xifaras,Panagiotis Manolios,Andrew T. Walter,William Robertson*

Main category: cs.PL

TL;DR: 本论文将Python类型的一部分嵌入到ACL2s系统中，通过形式化定义和自动枚举生成fuzz输入，提升了Python程序的覆盖率和bug检测能力，并在实际项目中得到了验证。


<details>
  <summary>Details</summary>
Motivation: 目前Python类型检查器难以发现所有类型相关的bug，缺乏理论自动化手段提升测试输入多样性。本研究旨在探索形式化方法支持下自动生成高质量测试输入以提升代码覆盖率和bug发现效率。

Method: 将Python常用类型及自定义类型嵌入到ACL2s，并为其定义defdata枚举器，用以自动生成满足类型约束的测试输入，通过这些输入进行黑盒fuzz测试，并统计代码覆盖率和寻找未被覆盖的代码模式。

Result: 在测试的4个开源库中，使用本方法生成的输入能够实现68%-80%以上的代码覆盖率，并发现受复杂分支表达式及文件系统依赖影响的覆盖短板，验证了方法的有效性。

Conclusion: 通过将Python部分类型系统嵌入ACL2s，可以自动生成用于fuzz测试的输入，发现现有类型检查器难以检测的bug，并提出了改进测试覆盖率的方法及未来研究建议。

Abstract: Python is a high-level interpreted language that has become an industry
standard in a wide variety of applications. In this paper, we take a first step
towards using ACL2s to reason about Python code by developing an embedding of a
subset of the Python type system in ACL2s. The subset of Python types we
support includes many of the most commonly used type annotations as well as
user-defined types comprised of supported types. We provide ACL2s definitions
of these types, as well as defdata enumerators that are customized to provide
code coverage and identify errors in Python programs. Using the ACL2s
embedding, we can generate instances of types that can then be used as inputs
to fuzz Python programs, which allows us to identify bugs in Python code that
are not detected by state-of-the-art Python type checkers. We evaluate our work
against four open-source repositories, extracting their type information and
generating inputs for fuzzing functions with type signatures that are in the
supported subset of Python types. Note that we only use the type signatures of
functions to generate inputs and treat the bodies of functions as black boxes.
We measure code coverage, which ranges from about 68% to more than 80%, and
identify code patterns that hinder coverage such as complex branch conditions
and external file system dependencies. We conclude with a discussion of the
results and recommendations for future work.

</details>


### [4] [A Programming Language for Feasible Solutions](https://arxiv.org/abs/2507.19176)
*Weijun Chen,Yuxi Fu,Huan Long*

Main category: cs.PL

TL;DR: 该论文提出一种新命令式语言，通过类型系统本质性保证了程序能在多项式时间内终止运行，并具备强大表达能力，验证和实现均已完成，有助于高效程序验证。


<details>
  <summary>Details</summary>
Motivation: 在程序验证领域，运行时效率和终止性是关键问题，现有方案通常是临时解决。作者希望设计一种体系，能在设计之初就保证这些性质。

Method: 作者提出了一种新的命令式编程语言，这种语言建立在静态类型系统之上，其核心设计是所有定义的程序都保证在多项式时间内运行，且所有可在多项式时间内解决的问题都能被该语言描述。通过理论证明该等价性质，并实现了解释器。

Result: 1. 理论上，证明了该语言与多项式时间可解问题的等价性；2. 实现了该语言的解释器，展示了其实用性和可行性。

Conclusion: 该论文提出一种新型命令式语言，通过类型系统保证程序运行效率和终止性，理论和实践上都展示了其有效性，对可行计算的程序分析与验证带来了便利。

Abstract: Runtime efficiency and termination are crucial properties in the studies of
program verification. Instead of dealing with these issues in an ad hoc manner,
it would be useful to develop a robust framework in which such properties are
guaranteed by design. This paper introduces a new imperative programming
language whose design is grounded in a static type system that ensures the
following equivalence property: All definable programs are guaranteed to run in
polynomial time; Conversely, all problems solvable in polynomial time can be
solved by some programs of the language. The contribution of this work is
twofold. On the theoretical side, the foundational equivalence property is
established, and the proof of the equivalence theorem is non-trivial. On the
practical side, a programming approach is proposed that can streamline program
analysis and verification for feasible computations. An interpreter for the
language has been implemented, demonstrating the feasibility of the approach in
practice.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [5] [Exploring the Landscape of Fairness Interventions in Software Engineering](https://arxiv.org/abs/2507.18726)
*Sadia Afrin Mim*

Main category: cs.SE

TL;DR: 本文综述了AI在实际应用中面临的公平性挑战及相关应对方法，对现有研究进行了归纳总结。


<details>
  <summary>Details</summary>
Motivation: AI在医疗、金融等重要领域广泛应用于减少人工和成本，但在实际应用过程中，由于数据存在偏见等风险因素，AI系统面临诸多风险和不利影响。

Method: 本论文采用综述（survey）方法，汇总和总结了已有文献中面向公平性问题所开发的各种研究和技术手段。

Result: 本文对现有为应对AI公平性问题而提出的多种方法和干预措施进行了系统梳理和归纳，总结了各类研究的成果与局限。

Conclusion: 针对AI系统在现实应用中可能因数据偏见等问题而引发的公平性挑战，学界已提出并实践了多种干预与解决途径，未来相关研究仍需持续推进。

Abstract: Current developments in AI made it broadly significant for reducing human
labor and expenses across several essential domains, including healthcare and
finance. However, the application of AI in the actual world poses multiple
risks and disadvantages due to potential risk factors in data (e.g., biased
dataset). Practitioners developed a number of fairness interventions for
addressing these kinds of problems. The paper acts as a survey, summarizing the
various studies and approaches that have been developed to address fairness
issues

</details>


### [6] [Agentic Program Repair from Test Failures at Scale: A Neuro-symbolic approach with static analysis and test execution feedback](https://arxiv.org/abs/2507.18755)
*Chandra Maddila,Adam Tait,Claire Chang,Daniel Cheng,Nauman Ahmad,Vijayaraghavan Murali,Marshall Roch,Arnaud Avondet,Aaron Meltzer,Victor Montalvao,Michael Hopko,Chris Waterson,Parth Thakkar,Renuka Fernandez,Kristian Kristensen,Sivan Barzily,Sherry Chen,Rui Abreu,Nachiappan Nagappan,Payam Shodjai,Killian Murphy,James Everingham,Aparna Ramani,Peter C. Rigby*

Main category: cs.SE

TL;DR: 本文介绍了基于Llama与ReAct框架的智能工程代理系统，能大规模自动修复代码。修复有效率较高，部分自动修复直接落地，获得工程师普遍认可。


<details>
  <summary>Details</summary>
Motivation: 随着大模型（LLMs）的出现，在大型组织与大规模代码库中，实现复杂的自动化程序修复变得可行。本文旨在开发一种工程代理，可以自动修复因测试失败而出现的源代码错误，提高代码维护效率。

Method: 以Llama为基础，采用ReAct框架开发智能工程代理。流程从规则驱动的测试失败机器人分类后的测试失败开始。为代理设置了15种动作（如读取文件、生成补丁等），通过静态分析和测试反馈不断迭代修复方案。采用LLM-as-a-Judge确保补丁达到标准，最终由人类审核并提交修复。

Result: 离线评测显示，基于70B参数的定制模型在效果上与更大参数量的Llama-405B不相上下，且ReAct框架结合符号信息可提升效果。基准任务修复成功率为42.3%，平均需11.8次反馈。实际应用三个月内，80%的自动修复经人工审核，31.5%实际应用到代码库。

Conclusion: 工程代理利用大模型和自动反馈机制，能有效地处理大规模代码修复任务，提升效率并减轻人工负担。人类审核后，部分自动修复可直接落地，部分方案作为工程师修改的良好起点。技术与人工协作结合，实际效果得到工程师总体认可。

Abstract: Aim: With the advent of LLMs, sophisticated agentic program repair has become
viable at large organizations with large codebases. In this work, we develop an
Engineering Agent that fixes the source code based on test failures at scale
across diverse software offerings internally.
  Method: Using Llama as the base, we employ the ReAct harness to develop an
agent. We start with a test failure that was triaged by a rule-based test
failure bot. We then set up an agentic harness and allow the agent to reason
and run a set of 15 actions from reading a file to generating a patch. We
provide feedback to the agent through static analysis and test failures so it
can refine its solution. We leverage an LLM-as-a-Judge to ensure that the patch
conforms to the standards followed by a human review to land fixes.
  Benchmark Findings: We curated offline benchmarks for our patch generator,
the Engineering Agent loop, and the LLM-as-a-Judge. In offline evaluations we
found that a specialized 70B model is highly competitive with the much larger
but vanilla Llama-405B. In an ablation study, we found that the ReAct harness
(neural model) benefited from the symbolic information from static analysis
tools and test execution traces. A model that strikes a balance between the
solve rate and error rate vs the cost and latency has a benchmark solve rate of
42.3% using an average 11.8 feedback iterations.
  Production Findings: In a three month period, 80% of the generated fixes were
reviewed, of which 31.5% were landed (25.5% of the total number of generated
fixes).
  Feedback from Engineers: We used open coding to extract qualitative themes
from engineers' feedback. We saw positive feedback in the form of quick
approvals, gratitude, and surprise. We also found mixed feedback when the
Engineering Agent's solution was partially correct and it served as a good
starting point.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [7] [Who Wins the Multi-Structural Game?](https://arxiv.org/abs/2507.18718)
*Ronald Fagin,Neil Immerman,Phokion Kolaitis,Jonathan Lenchner,Rik Sengupta*

Main category: cs.LO

TL;DR: 本研究分析了多结构组合游戏的复杂度，发现其相关决策问题为PSPACE-hard且在NEXPTIME内，并解决了此前关于EF游戏复杂度与元组元数关系的开放问题。


<details>
  <summary>Details</summary>
Motivation: 用组合游戏（如Ehrenfeucht-Fraïssé游戏）刻画形式逻辑语言的句法性质已由来已久，但对于新近关注的多结构（MS）游戏，其对应决策问题的复杂度未被完全解决，尤其是其与经典EF游戏复杂度的比较以及对游戏对象结构的影响。因此，本文旨在弥补这一知识空白，并解决Pezzoli提出的一个相关开放问题。

Method: 采用了Pezzoli的复杂度构造方法，结合优化问题不可近似性理论中的见解，以及近期提出的多结构游戏的并行玩技术，对MS游戏的决策问题展开复杂度分析。

Result: 证明了MS游戏的‘Spoiler是否获胜’决策问题是PSPACE-hard的，但上界被限制在NEXPTIME内。同时，解决了EF游戏复杂度对模式元组元数（arity）依赖性的开放问题。

Conclusion: MS游戏的决策问题比EF游戏更难（PSPACE-hard，但不超过NEXPTIME），并首次明确了EF游戏复杂度与模式元组元数的关系；方法上的创新是将多领域理论方法与并行玩技术相结合。

Abstract: Combinatorial games played between two players, called Spoiler and
Duplicator, have often been used to capture syntactic properties of formal
logical languages. For instance, the widely used Ehrenfeucht-Fra\"iss\'e (EF)
game captures the syntactic measure of quantifier rank of first-order formulas.
For every such game, there is an associated natural decision problem: "given an
instance of the game, does Spoiler win the game on that instance?" For EF
games, this problem was shown to be PSPACE-complete by Pezzoli in 1998. In this
present paper, we show that the same problem for the *multi-structural* (MS)
games of recent interest is PSPACE-hard, but contained in NEXPTIME. In the
process, we also resolve an open problem posed by Pezzoli about the dependence
of the hardness results for EF games on the arity of the schema under
consideration. Our techniques combine adaptations of Pezzoli's constructions
together with insights from the theory of inapproximability of optimization
problems, as well as the recently developed technique of parallel play for MS
games.

</details>


### [8] [Higher-order Kripke models for intuitionistic and non-classical modal logics](https://arxiv.org/abs/2507.18798)
*Victor Barroso-Nascimento*

Main category: cs.LO

TL;DR: 本文提出高阶Kripke模型，显著拓展了传统Kripke模型用于非经典逻辑的语义表达力，并通过具体分析直觉主义模态逻辑，赋予模型新的直观诠释并推广至广泛的非经典逻辑。


<details>
  <summary>Details</summary>
Motivation: 标准的Kripke模型在处理非经典逻辑特别是直觉主义模态逻辑时存在一些限制，难以用于解释具有更复杂语义层次结构的系统。作者试图通过对Kripke模型进行高阶推广来突破现有方法的不足。

Method: 作者推广了Kripke模型，将其扩展为高阶Kripke模型，允许可能世界自身是更低阶的Kripke模型，从而引入多层次的模型结构，并重新定义了模态语义的可达性关系。首先详细分析了直觉主义模态逻辑的情形，随后定义了更高阶模型的结构和变体，并提出相关猜想。

Result: 通过推广Kripke模型为高阶形式，作者构建了可处理多层语义框架的模型。结果表明，针对允许的0阶模型选择，可以得到等价于IK双关系模型或新引入的MK逻辑的1阶模型。这些1阶模型赋予直觉主义模型“替代理线”含义，且相应的模态语义条款具有模块化特征，适用于其他非经典逻辑。还给出了一般高阶模型结构及其推测性质。

Conclusion: 高阶Kripke模型为非经典逻辑（如直觉主义模态逻辑）的语义提供了更一般化、更富表现力的分析工具，能够处理更复杂的“可能世界”层次，并为非经典模态逻辑提供了新的直观解释和更广泛的适用性。

Abstract: This paper introduces higher-order Kripke models, a generalization of
standard Kripke models that is remarkably close to Kripke's original idea -
both mathematically and conceptually. Standard Kripke models are now considered
$0$-ary models, whereas an $n$-ary model for $n > 0$ is a model whose set of
objects (''possible worlds'') contains only $(n-1)$-ary Kripke models. Models
with infinitely many layers are also considered. This framework is obtained by
promoting a radical change of perspective in how modal semantics for
non-classical logics are defined: just like classical modalities are obtained
through use of an accessibility relation between classical propositional
models, non-classical modalities are now obtained through use of an
accessibility relation between non-classical propositional models (even when
they are Kripke models already). The paper introduces the new models after
dealing specifically with the case of intuitionistic modal logic. It is shown
that, depending on which intuitionistic $0$-ary propositional models are
allowed, we may obtain $1$-ary models equivalent to either birelational models
for $IK$ or for a new logic called $MK$. Those $1$-ary models have an intuitive
reading that adds to the interpretation of intuitionistic models in terms of
''timelines'' the concept of ''alternative timelines''. More generally, the
$1$-ary models can be read as defining a concept of ''alternative'' for any
substantive interpretation of the $0$-ary models. The semantic clauses for
necessity and possibility of $MK$ are also modular and can be used to obtain
similar modal semantics for every non-classical logic, each of which can be
provided with a similar intuitive reading. After intuitionistic modal logic is
dealt with, the general structure of High-order Kripke Models and some of its
variants are defined, and a series of conjectures about their properties are
stated.

</details>


### [9] [A Proof of the Schröder-Bernstein Theorem in ACL2](https://arxiv.org/abs/2507.19008)
*Grant Jurgensen*

Main category: cs.LO

TL;DR: 本文在ACL2定理证明器中形式化并验证了Schröder-Bernstein定理，引入链理论来构造关键证明对象，推动了集合论定理的机械化证明。


<details>
  <summary>Details</summary>
Motivation: Schröder-Bernstein定理是集合论中的基础定理，传统上该定理的证明与无穷集合和基数的等价性密切相关。本文关注将这一经典定理在ACL2定理证明器中形式化，满足自动化验证需求。

Method: 作者采用ACL2定理证明器，实现并验证了Schröder-Bernstein定理。他们遵循了一种著名的证明思路，引入了链理论（theory of chains）来构造非可计算的见证。

Result: 实现了Schröder-Bernstein定理在ACL2中的形式化证明，并用链理论定义了关键的非可计算映射。验证了该定理在ACL2下的有效性。

Conclusion: 该工作为Schröder-Bernstein定理在机械化证明环境中的验证建立了方法论基础。提出的链理论思路为类似集合论定理的自动化证明提供了参考。

Abstract: The Schr\"oder-Bernstein theorem states that, for any two sets P and Q, if
there exists an injection from P to Q and an injection from Q to P, then there
must exist a bijection between the two sets. Classically, it follows that the
ordering of the cardinal numbers is antisymmetric. We describe a formulation
and verification of the Schr\"oder-Bernstein theorem in ACL2 following a
well-known proof, introducing a theory of chains to define a non-computable
witness.

</details>


### [10] [A Formalization of the Yul Language and Some Verified Yul Code Transformations](https://arxiv.org/abs/2507.19012)
*Alessandro Coglio,Eric McCarthy*

Main category: cs.LO

TL;DR: 本文利用ACL2定理证明器，对以太坊智能合约编译中用到的Yul中间语言进行了语法和语义的形式化及转换正确性的证明，有助于提升智能合约编译安全性。


<details>
  <summary>Details</summary>
Motivation: 为了确保以太坊智能合约Solidity语言编译过程中对Yul中间语言进行转换的正确性，作者希望实现Yul语法和语义的形式化以及相关转换的验证。

Method: 作者采用了ACL2定理证明器，对Yul语言的语法和语义进行了形式化，证明了静态语义与动态语义之间的关系，并对部分Yul代码转换进行了形式化及其正确性证明。

Result: 得到了Yul的正式语法和语义描述，以及部分Yul转换操作的形式化和正确性证明。

Conclusion: 通过使用ACL2形成了Yul语言及其转换的形式化模型，实现了Yul代码转换正确性的保障，为智能合约的安全性和可靠性提供了理论支持。

Abstract: Yul is an intermediate language used in the compilation of the Solidity
programming language for Ethereum smart contracts. The compiler applies
customizable sequences of transformations to Yul code. To help ensure the
correctness of these transformations and their sequencing, we used the ACL2
theorem prover to develop a formalization of the syntax and semantics of Yul,
proofs relating static and dynamic semantics, a formalization of some Yul code
transformations, and correctness proofs for these transformations.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [11] [Specification Self-Correction: Mitigating In-Context Reward Hacking Through Test-Time Refinement](https://arxiv.org/abs/2507.18742)
*Víctor Gallego*

Main category: cs.CL

TL;DR: 提出SSC方法，使大语言模型能在推理阶段主动检测并修正参考规范中的漏洞，大幅减少‘钻漏洞’行为，无需微调权重，实践中对齐效果显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LM）容易受到上下文中存在缺陷或有误的标准（如评分标准、规范）影响，从而‘钻漏洞’获得高分，但未真正完成用户意图。这种现象称为‘in-context reward hacking’，是影响模型实际应用可靠性的难题。

Method: 提出了一种新的推理时框架Specification Self-Correction（SSC），该方法允许语言模型自行识别和修正其参考规范中的缺陷。SSC具体采用多步推理流程：模型首先依照可能有缺陷的规范生成初步回答，然后对该回答进行批判，接着修正原规范以删除可被利用的漏洞，最后基于修正后的规范生成更健全的回答。整个过程无需修改模型权重，在推理阶段动态完成。

Result: 在涵盖创意写作和代码任务的多个实验中，多个语言模型在初始条件下‘钻漏洞’的比例为50-70%，但经过SSC流程处理后，该脆弱性降低了90%以上，显著提升了模型生成结果对真实意图的对齐及健壮性。

Conclusion: SSC方法为解决大语言模型在推理时规范缺陷带来的行为偏差提供了有效手段，可以动态修复规范、提升模型对用户意图的忠实度；技术简单、无需重训练，有良好的应用潜力。

Abstract: Language models (LMs) are susceptible to in-context reward hacking, where
they exploit flaws in tainted or faulty written specifications or rubrics to
achieve high scores without fulfilling the user's true intent. We introduce
Specification Self-Correction (SSC), a novel, test-time framework that enables
an LM to identify and correct flaws within its own guiding specification. SSC
employs a multi-step inference process where the model first generates a
response based on a potentially tainted specification, critiques its output,
and then revises the specification itself to remove the exploitable loophole. A
final, more robust response is then generated using this self-corrected
specification. Across experiments spanning creative writing and agentic coding
tasks with several LMs, we demonstrate that while models initially game tainted
specifications in 50-70\% of cases, the SSC process reduces this vulnerability
by over 90\%. This dynamic repair occurs at inference time, requires no weight
modification, and leads to more robustly aligned model behavior. Code at
https://github.com/vicgalle/specification-self-correction .

</details>


### [12] [The Role of Orthographic Consistency in Multilingual Embedding Models for Text Classification in Arabic-Script Languages](https://arxiv.org/abs/2507.18762)
*Abdulhady Abas Abdullah,Amir H. Gandomi,Tarik A Rashid,Seyedali Mirjalili,Laith Abualigah,Milena Živković,Hadi Veisi*

Main category: cs.CL

TL;DR: 为库尔德索拉尼、阿拉伯、波斯和乌尔都等阿拉伯文书写的语言分别训练RoBERTa模型，专注于文字系统差异，优于通用多语种模型2-5%；文字系统知识预训练对提升表现至关重要。


<details>
  <summary>Details</summary>
Motivation: 多语种模型如mBERT和XLM-RoBERTa虽然覆盖面广，但对于使用相同文字系统（如阿拉伯字母），但在正字法和文化背景上有差异的语言（如库尔德语索拉尼、阿拉伯语、波斯语和乌尔都语）表现有限。这个问题尤其突出。

Method: 提出阿拉伯字母RoBERTa（AS-RoBERTa）家族，为每种目标语言（库尔德索拉尼语、阿拉伯语、波斯语、乌尔都语）各训练一个以RoBERTa为基础、专门针对其大规模语料预训练的模型。预训练时注重语言特定的文字系统特征和统计信息。

Result: 在分类任务微调后，AS-RoBERTa模型比mBERT和XLM-RoBERTa高出2~5个百分点。消融实验显示，文字系统聚焦的预训练方式是性能提升的关键。混淆矩阵分析展示了文字共性和领域内容差异对模型性能的影响。

Conclusion: 针对使用阿拉伯文字系统的多种语言，专注于文字系统特性的预训练模型取得了优于通用多语种模型的表现，验证了“文字系统感知”专门化策略的有效性，值得在相关语种和预训练策略上进一步研究。

Abstract: In natural language processing, multilingual models like mBERT and
XLM-RoBERTa promise broad coverage but often struggle with languages that share
a script yet differ in orthographic norms and cultural context. This issue is
especially notable in Arabic-script languages such as Kurdish Sorani, Arabic,
Persian, and Urdu. We introduce the Arabic Script RoBERTa (AS-RoBERTa) family:
four RoBERTa-based models, each pre-trained on a large corpus tailored to its
specific language. By focusing pre-training on language-specific script
features and statistics, our models capture patterns overlooked by
general-purpose models. When fine-tuned on classification tasks, AS-RoBERTa
variants outperform mBERT and XLM-RoBERTa by 2 to 5 percentage points. An
ablation study confirms that script-focused pre-training is central to these
gains. Error analysis using confusion matrices shows how shared script traits
and domain-specific content affect performance. Our results highlight the value
of script-aware specialization for languages using the Arabic script and
support further work on pre-training strategies rooted in script and language
specificity.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [13] [A Formalization of Elementary Linear Algebra: Part I](https://arxiv.org/abs/2507.19006)
*David Russinoff*

Main category: cs.DM

TL;DR: 本文在ACL2上形式化了交换环上矩阵的线性代数，重点实现并证明了行列式的性质。


<details>
  <summary>Details</summary>
Motivation: 本论文旨在为未来处理含有多项式环元素矩阵的特征多项式作铺垫，系统地形式化线性代数基础，特别是适用于带幺元的任意交换环上的矩阵理论。

Method: 利用ACL2定理证明辅助系统，构建与严格验证相关线性代数概念，重点形式化行列式及其相关性质。

Result: 提出了行列式的完备形式理论，包括行列式作为行的唯一交错n线性函数的刻画、乘法性、以及按代数余子式展开的正确性证明。

Conclusion: 论文首次系统性地在ACL2系统中形式化了行列式理论，并为后续对含多项式环元素矩阵理论的研究奠定基础。

Abstract: This is the first installment of an exposition of an ACL2 formalization of
elementary linear algebra, focusing on aspects of the subject that apply to
matrices over an arbitrary commutative ring with identity, in anticipation of a
future treatment of the characteristic polynomial of a matrix, which has
entries in a polyniomial ring. The main contribution of this paper is a formal
theory of the determinant, including its characterization as the unique
alternating n-linear function of the rows of an non matrix, multiplicativity of
the determinant, and the correctness of cofactor expansion.

</details>


### [14] [A Formalization of Elementary Linear Algebra: Part II](https://arxiv.org/abs/2507.19007)
*David Russinoff*

Main category: cs.DM

TL;DR: 该论文通过ACL2形式化手段，深入探讨了域上的矩阵相关线性代数理论，包括初等行变换、矩阵逆及线性方程组求解，提升了这些理论和算法的可验证性和严谨性。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在继续对线性代数基础内容的ACL2形式化展开，具体关注于仅适用于域上的矩阵的相关理论。

Method: 以ACL2形式化方法，对矩阵的初等行变换、矩阵求逆及线性方程组求解等过程进行形式化描述与证明。

Result: 扩展了前作中关于交换环上矩阵代数的结果，形式化实现并验证了在域上矩阵上的初等行变换、矩阵求逆和线性方程组求解等内容。

Conclusion: 通过ACL2系统，系统性地形式化并验证了域上矩阵的线性代数理论，提高了相关算法和理论的可靠性。

Abstract: This is the second installment of an exposition of an ACL2 formalization of
elementary linear algebra. It extends the results of Part I, which covers the
algebra of matrices over a commutative ring, but focuses on aspects of the
theory that apply only to matrices over a field: elementary row reduction and
its application to the computation of matrix inverses and the solution of
simultaneous systems of linear equations.

</details>
