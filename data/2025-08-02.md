<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 12]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.CL](#cs.CL) [Total: 67]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Abstractions of Sequences, Functions and Operators](https://arxiv.org/abs/2507.23151)
*Louis Rustenholz,Pedro Lopez-Garcia,Manuel V. Hermenegildo*

Main category: cs.PL

TL;DR: 本文提出了一种用于递归函数闭合边界推理的高阶抽象解释新方法——B-bound抽象域，既能刻画复杂数值关系，又方便自动化设计传递函数，并支持符号到数值映射及降维，服务于程序分析等多个场景。


<details>
  <summary>Details</summary>
Motivation: 对递归定义函数（如程序中的递推、微分方程解等）寻找闭合形式上下界具有广泛应用，例如程序复杂度分析、循环加速、声明式语言分析和混合系统分析。传统数值抽象域难以表达复杂非线性不变式，因此需要更强的函数抽象方法。

Method: 1. 提出并构建了B-bound抽象域，用边界函数的集合来刻画目标函数的约束；2. 在约束空间中发现并利用了凸性性质以简化（甚至自动化）传递函数的设计；3. 引入域抽象（domain abstraction）函子，将任意值空间的映射提升为函数空间的Galois连接，实现从符号到数值函数（如尺寸抽象）和方程降维；4. 基于简单操作符语言递推定义转移函数，支持多元、分段、非离散等一般函数。

Result: 1. B-bound域能自动综合高度非线性的数值不变式，提高了自动化推理能力；2. 通过发现约束空间的凸性简化传递函数的构造，并在部分场景下实现自动化；3. 域抽象方法支持方程降维和表达从符号到数值的普适抽象。

Conclusion: 本文提出了一种适用于抽象数值函数的新型约束型抽象域B-bound域，并通过Galois连接和域抽象等技术，实现了高度复杂函数关系的自动化推理和维度简化，扩展了高阶抽象解释在程序分析等领域的能力。

Abstract: We present theoretical and practical results on the order theory of lattices
of functions, focusing on Galois connections that abstract (sets of) functions
- a topic known as higher-order abstract interpretation.
  We are motivated by the challenge of inferring closed-form bounds on
functions which are defined recursively, i.e. as the fixed point of an operator
or, equivalently, as the solution to a functional equation. This has multiple
applications in program analysis (e.g. cost analysis, loop acceleration,
declarative language analysis) and in hybrid systems governed by differential
equations.
  Our main contribution is a new family of constraint-based abstract domains
for abstracting numerical functions, B-bound domains, which abstract a function
f by a conjunction of bounds from a preselected set of boundary functions. They
allow inferring highly non-linear numerical invariants, which classical
numerical abstract domains struggle with. We uncover a convexity property in
the constraint space that simplifies, and, in some cases, fully automates,
transfer function design.
  We also introduce domain abstraction, a functor that lifts arbitrary mappings
in value space to Galois connections in function space. This supports
abstraction from symbolic to numerical functions (i.e. size abstraction), and
enables dimensionality reduction of equations.
  We base our constructions of transfer functions on a simple operator
language, starting with sequences, and extending to more general functions,
including multivariate, piecewise, and non-discrete domains.

</details>


### [2] [Kernel-FFI: Transparent Foreign Function Interfaces for Interactive Notebooks](https://arxiv.org/abs/2507.23205)
*Hebi Li,Forrest Sheng Bao,Qi Xiao,Jin Tian*

Main category: cs.PL

TL;DR: 本文提出了Kernel-FFI，一个用于notebook环境的透明跨语言函数和对象交互框架，通过代码转换和创新的通信机制简化了配置和开发，并将被开源。


<details>
  <summary>Details</summary>
Motivation: 目前的外部函数接口（FFI）方案难以支持Jupyter等现代交互式notebook环境，因为它们配置繁琐、样板代码多且对递归调用和面向对象编程支持不佳，不利于多语言协作开发。

Method: 提出了Kernel-FFI，这是一个透明且语言无关的框架，通过源代码级转换自动改写跨语言调用，无需手动绑定或写样板代码。同时支持跨语言对象引用和自动资源管理，并引入了新颖的边信道通信机制以支持递归和异步外部调用。

Result: Kernel-FFI实现了在notebook环境下无缝进行跨语言函数调用和对象操作，提升了多语言开发效率和交互体验。工具将开源发布。

Conclusion: Kernel-FFI有效解决了现有FFI方案在交互式notebook中的局限，实现在这些环境下的高效、面向对象的跨语言互操作。

Abstract: Foreign Function Interfaces (FFIs) are essential for enabling
interoperability between programming languages, yet existing FFI solutions are
ill-suited for the dynamic, interactive workflows prevalent in modern notebook
environments such as Jupyter. Current approaches require extensive manual
configuration, introduce significant boilerplate, and often lack support for
recursive calls and object-oriented programming (OOP) constructs-features
critical for productive, multi-language development.
  We present Kernel-FFI, a transparent, language-agnostic framework that
enables seamless cross-language function calls and object manipulation within
interactive notebooks. Kernel-FFI employs source-level transformation to
automatically rewrite cross-language invocations, eliminating the need for
manual bindings or boilerplate. Kernel-FFI provides robust support for OOP by
enabling foreign object referencing and automatic resource management across
language boundaries. Furthermore, to address the blocking nature of Jupyter
kernels and support recursive and asynchronous foreign calls, we introduce a
novel side-channel communication mechanism. Our tool will be open-sourced and
available at https://codepod.io/docs/kernel-ffi

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [On LLM-Assisted Generation of Smart Contracts from Business Processes](https://arxiv.org/abs/2507.23087)
*Fabian Stiehle,Hans Weytjens,Ingo Weber*

Main category: cs.SE

TL;DR: 本文开发了自动化评估系统，系统性测试了多种LLM从业务流程自动生成智能合约的能力，发现其性能尚未满足高可靠性需求。建议未来在现有工具中审慎集成LLM，并利用本文提供的评测框架提升输出质量。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）正广泛应用于代码生成领域，尤其是从业务流程描述自动生成智能合约代码。传统基于规则的方法存在局限性，如何提升生成质量成为亟需解决的问题。

Method: 提出一种自动化评估框架，针对不同类型和规模的LLM，测试其在智能合约代码生成中对关键执行属性（如流程控制、资源分配和数据条件）的实现能力，并使用大规模数据集进行实证研究。

Result: LLM在智能合约开发中，生成的代码可靠性尚未达到理想要求，存在不足。本文数据和基准框架可为未来LLM与现有代码生成工具的集成研究提供参考。

Conclusion: 当前LLM生成智能合约代码的表现距离生产级需求仍有差距。未来需在工具整合、可靠性提升方面加强研究，本文提供的框架为后续工作奠定了基础。

Abstract: Large language models (LLMs) have changed the reality of how software is
produced. Within the wider software engineering community, among many other
purposes, they are explored for code generation use cases from different types
of input. In this work, we present an exploratory study to investigate the use
of LLMs for generating smart contract code from business process descriptions,
an idea that has emerged in recent literature to overcome the limitations of
traditional rule-based code generation approaches. However, current LLM-based
work evaluates generated code on small samples, relying on manual inspection,
or testing whether code compiles but ignoring correct execution. With this
work, we introduce an automated evaluation framework and provide empirical data
from larger data sets of process models. We test LLMs of different types and
sizes in their capabilities of achieving important properties of process
execution, including enforcing process flow, resource allocation, and
data-based conditions. Our results show that LLM performance falls short of the
perfect reliability required for smart contract development. We suggest future
work to explore responsible LLM integrations in existing tools for code
generation to ensure more reliable output. Our benchmarking framework can serve
as a foundation for developing and evaluating such integrations.

</details>


### [4] [FlowETL: An Autonomous Example-Driven Pipeline for Data Engineering](https://arxiv.org/abs/2507.23118)
*Mattia Di Profio,Mingjun Zhong,Yaji Sripada,Marcel Jaspars*

Main category: cs.SE

TL;DR: 本文提出了一种面向示例、自动规划和执行ETL任务的新体系结构FlowETL，能够自动完成数据标准化和准备工作，在多领域数据集上展示了良好的泛化和效果，有效减少人工参与。


<details>
  <summary>Details</summary>
Motivation: 现有ETL（提取、转换、加载）流程严重依赖人工设计和实现个性化转化，对自动化程度要求亟需提升，当前自动化ETL方案无法充分自动设计和执行转换流程。

Method: 本文提出FlowETL体系结构，通过实例指导的方式（example-based），用户只需给出目标数据集的示例，系统自动规划和应用数据标准化与转换流程。其架构包括规划引擎、ETL执行单元、监控和日志，组件间协同实现自动化ETL。

Result: FlowETL对14个来自不同领域、文件结构和大小的数据集进行了测试，表现出良好的泛化和自动化能力。

Conclusion: FlowETL有效减少了人工参与，实现了自动化、可泛化的数据预处理和标准化，提升了ETL流程效率。

Abstract: The Extract, Transform, Load (ETL) workflow is fundamental for populating and
maintaining data warehouses and other data stores accessed by analysts for
downstream tasks. A major shortcoming of modern ETL solutions is the extensive
need for a human-in-the-loop, required to design and implement
context-specific, and often non-generalisable transformations. While related
work in the field of ETL automation shows promising progress, there is a lack
of solutions capable of automatically designing and applying these
transformations. We present FlowETL, a novel example-based autonomous ETL
pipeline architecture designed to automatically standardise and prepare input
datasets according to a concise, user-defined target dataset. FlowETL is an
ecosystem of components which interact together to achieve the desired outcome.
A Planning Engine uses a paired input-output datasets sample to construct a
transformation plan, which is then applied by an ETL worker to the source
dataset. Monitoring and logging provide observability throughout the entire
pipeline. The results show promising generalisation capabilities across 14
datasets of various domains, file structures, and file sizes.

</details>


### [5] [Vibe Modeling: Challenges and Opportunities](https://arxiv.org/abs/2507.23120)
*Jordi Cabot*

Main category: cs.SE

TL;DR: 本文指出传统MDE与新兴基于LLM的自动编码方法各有优势和不足，提出vibe modeling方法融合两者优点，推动可靠复杂系统开发，并展望了其机遇与挑战。


<details>
  <summary>Details</summary>
Motivation: 当前软件系统需求增长和复杂性提升，对开发方法和工具提出了更高要求。新型用户界面、智能组件和可持续性问题带来了新的挑战。模型驱动工程（MDE）虽提高了软件开发质量和生产力，但模型自身日益复杂。同时，基于大语言模型（LLMs）的vibe coding方法流行，但也带来安全性、可扩展性和可维护性问题。

Method: 提出了一种新的vibe modeling方法，将AI与MDE优势整合，推动可靠复杂系统开发。文中介绍了vibe modeling的关键概念，并探讨这一新方法的机遇与挑战。

Result: 提出了vibe modeling概念，描述了其基本思想和潜在影响，展示了该方法在未来建模领域中的广阔前景和需解决的问题。

Conclusion: vibe modeling作为融合AI和MDE的新方法，有望同时提升开发效率和系统可靠性，但也带来了新的挑战，需要进一步研究和实践验证。

Abstract: There is a pressing need for better development methods and tools to keep up
with the growing demand and increasing complexity of new software systems. New
types of user interfaces, the need for intelligent components, sustainability
concerns, ... bring new challenges that we need to handle. In the last years,
model-driven engineering (MDE) has been key to improving the quality and
productivity of software development, but models themselves are becoming
increasingly complex to specify and manage. At the same time, we are witnessing
the growing popularity of vibe coding approaches that rely on Large Language
Models (LLMs) to transform natural language descriptions into running code at
the expenses of code vulnerabilities, scalability issues and maintainability
concerns. In this paper, we introduce the concept of \textit{vibe modeling} as
a novel approach to integrate the best of both worlds (AI and MDE) to speed up
the development of reliable complex systems. We outline the key concepts of
vibe modeling and highlight the opportunities and open challenges it presents
for the future of modeling.

</details>


### [6] [Extension Decisions in Open Source Software Ecosystem](https://arxiv.org/abs/2507.23168)
*Elmira Onagh,Maleknaz Nayebi*

Main category: cs.SE

TL;DR: GitHub Marketplace中近三分之二的新CI工具是在短期内复刻已有功能，创新聚焦于少数抢先亮相的工具。该研究为开发者和维护者制定创新战略、优化产品决策提供了数据支持，并公开了完整数据集供进一步研究。


<details>
  <summary>Details</summary>
Motivation: GitHub Marketplace年增长迅速，但许多新工具重复了已有功能，特别是在其最大的领域——持续集成（CI）。作者旨在研究功能重复现象，揭示创新和竞争模式，帮助开发者和维护者优化产品选择和创新时机。

Method: 作者将6983个CI Actions与3869个供应商关联，挖掘它们的版本历史。通过图模型标记每项功能首次出现的时间、跟踪其被采用的过程，并对冗余工具进行聚类分析。

Result: 约65%的新CI Actions在六个月内复刻了现有功能，少数“第一行动者”涵盖了随后大部分的分支和扩展。

Conclusion: 该研究揭示了GitHub Marketplace中工具功能大规模重复的现象，为开发者和行业从业者提供了利用数据驱动选择创新时机、识别功能空缺和消除冗余工具的道路图。作者还公开了完整的数据和图模型以促进更多创新和竞争相关研究。

Abstract: GitHub Marketplace is expanding by approximately 41% annually, with new
tools; however, many additions replicate existing functionality. We study this
phenomenon in the platform's largest segment, Continuous Integration (CI), by
linking 6,983 CI Actions to 3,869 providers and mining their version histories.
Our graph model timestamps every functionality's debut, tracks its adoption,
and clusters redundant tools. We find that approximately 65% of new CI Actions
replicate existing capabilities, typically within six months, and that a small
set of first-mover Actions accounts for most subsequent forks and extensions.
These insights enable developers to choose the optimal moment to launch, target
unmet functionality, and help maintainers eliminate redundant tools. We publish
the complete graph and dataset to encourage longitudinal research on innovation
and competition in software ecosystems, and to provide practitioners with a
data-driven roadmap for identifying emerging trends and guiding product
strategy.

</details>


### [7] [AutoBridge: Automating Smart Device Integration with Centralized Platform](https://arxiv.org/abs/2507.23178)
*Siyuan Liu,Zhice Yang,Huangxun Chen*

Main category: cs.SE

TL;DR: AutoBridge可以自动生成IoT设备集成代码，大幅减少人工工作量和技术难度，其准确率高于人类专家，可显著提升IoT平台兼容性和扩展能力。


<details>
  <summary>Details</summary>
Motivation: 多模态IoT系统需要集成不同设备，以提供以人为中心的服务，但集成新设备需要大量人工编写复杂的对接代码，难度大、成本高，因此急需自动化IoT设备集成方案。

Method: 提出AutoBridge系统，通过分而治之方法，分两步实现代码生成：第一步，通过逐步检索设备专有知识，生成设备控制逻辑；第二步，结合平台专有知识，合成符合平台要求的对接代码。为保证代码正确性，设计了多阶段调试流程，包括自动化虚拟设备调试器和只需‘是/否’反馈的交互式实物调试。

Result: AutoBridge在两大开源IoT平台的34款设备基准测试中，实现了平均93.87%的成功率和94.87%的功能覆盖率，无需人工干预。在获得用户简单二元反馈后，功能覆盖率可达100%。用户实验表明，AutoBridge的代码准确率高出专家程序员50%-80%，即便后者可使用商业代码大模型。

Conclusion: AutoBridge无需人工作业即可极大提升IoT设备集成效率与准确率，极大降低了技术门槛，有望推动IoT系统更快速扩展和部署。

Abstract: Multimodal IoT systems coordinate diverse IoT devices to deliver
human-centered services. The ability to incorporate new IoT devices under the
management of a centralized platform is an essential requirement. However, it
requires significant human expertise and effort to program the complex IoT
integration code that enables the platform to understand and control the device
functions. Therefore, we propose AutoBridge to automate IoT integration code
generation. Specifically, AutoBridge adopts a divide-and-conquer strategy: it
first generates device control logic by progressively retrieving
device-specific knowledge, then synthesizes platformcompliant integration code
using platform-specific knowledge. To ensure correctness, AutoBridge features a
multi-stage debugging pipeline, including an automated debugger for virtual IoT
device testing and an interactive hardware-in-the-loop debugger that requires
only binary user feedback (yes and no) for real-device verification. We
evaluate AutoBridge on a benchmark of 34 IoT devices across two open-source IoT
platforms. The results demonstrate that AutoBridge can achieves an average
success rate of 93.87% and an average function coverage of 94.87%, without any
human involvement. With minimal binary yes and no feedback from users, the code
is then revised to reach 100% function coverage. A user study with 15
participants further shows that AutoBridge outperforms expert programmers by
50% to 80% in code accuracy, even when the programmers are allowed to use
commercial code LLMs.

</details>


### [8] [XABPs: Towards eXplainable Autonomous Business Processes](https://arxiv.org/abs/2507.23269)
*Peter Fettke,Fabiana Fournier,Lior Limonad,Andreas Metzger,Stefanie Rinderle-Ma,Barbara Weber*

Main category: cs.SE

TL;DR: ABP能带来效率提升，但引发信任和合规问题。为促进可解释性，提出XABP体系结构，并详述挑战。


<details>
  <summary>Details</summary>
Motivation: 虽然ABP能带来效率、成本和响应速度等多方面好处，但自动化和AI的引入导致了信任、可调试性、责任、偏见和合规性的担忧。

Method: 系统性地梳理了可解释ABP的形式、结构，并总结了实现XABP的研究挑战。

Result: 提出了可解释ABP（XABP）的框架，为其可解释性形式与结构提供了系统化方案，并厘清了研究难题。

Conclusion: 提出应通过可解释性来解决自主业务流程（ABPs）带来的信任、责任、合规等问题。

Abstract: Autonomous business processes (ABPs), i.e., self-executing workflows
leveraging AI/ML, have the potential to improve operational efficiency, reduce
errors, lower costs, improve response times, and free human workers for more
strategic and creative work. However, ABPs may raise specific concerns
including decreased stakeholder trust, difficulties in debugging, hindered
accountability, risk of bias, and issues with regulatory compliance. We argue
for eXplainable ABPs (XABPs) to address these concerns by enabling systems to
articulate their rationale. The paper outlines a systematic approach to XABPs,
characterizing their forms, structuring explainability, and identifying key BPM
research challenges towards XABPs.

</details>


### [9] [SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution](https://arxiv.org/abs/2507.23348)
*Han Li,Yuling Shi,Shaoxin Lin,Xiaodong Gu,Heng Lian,Xin Wang,Yantao Jia,Tao Huang,Qianxiang Wang*

Main category: cs.SE

TL;DR: 创新提出多智能体辩论的代码修复方案，显著优于原有方法，提升了复杂软件工程问题的自动定位与修复能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于智能体的代码问题修复方法，通常依赖于智能体的独立探索，这容易导致只解决局部问题，难以识别跨代码库多处的复杂错误模式。

Method: 提出SWE-Debate：一种多智能体竞争性辩论框架。具体方法包括：1）通过遍历代码依赖图生成多个故障传播路径作为定位建议；2）组织三轮辩论，每个专用智能体代表不同的推理视角；3）通过结构化竞争，智能体协作收敛到更全面的修复方案；4）将修复方案集成到基于蒙特卡洛树搜索（MCTS）的代码修改智能体中生成补丁。

Result: 在SWE-bench基准测试上，SWE-Debate在开源智能体框架中取得了新的最先进成果，显著优于现有基线方法。

Conclusion: SWE-Debate通过竞争性多智能体辩论，有效提升了问题定位和修复的综合能力，推动了自动化软件工程问题解决技术的进步。

Abstract: Issue resolution has made remarkable progress thanks to the advanced
reasoning capabilities of large language models (LLMs). Recently, agent-based
frameworks such as SWE-agent have further advanced this progress by enabling
autonomous, tool-using agents to tackle complex software engineering tasks.
While existing agent-based issue resolution approaches are primarily based on
agents' independent explorations, they often get stuck in local solutions and
fail to identify issue patterns that span across different parts of the
codebase. To address this limitation, we propose SWE-Debate, a competitive
multi-agent debate framework that encourages diverse reasoning paths and
achieves more consolidated issue localization. SWE-Debate first creates
multiple fault propagation traces as localization proposals by traversing a
code dependency graph. Then, it organizes a three-round debate among
specialized agents, each embodying distinct reasoning perspectives along the
fault propagation trace. This structured competition enables agents to
collaboratively converge on a consolidated fix plan. Finally, this consolidated
fix plan is integrated into an MCTS-based code modification agent for patch
generation. Experiments on the SWE-bench benchmark show that SWE-Debate
achieves new state-of-the-art results in open-source agent frameworks and
outperforms baselines by a large margin.

</details>


### [10] [Quality Evaluation of COBOL to Java Code Transformation](https://arxiv.org/abs/2507.23356)
*Shmulik Froimovich,Raviv Gal,Wesam Ibraheem,Avi Ziv*

Main category: cs.SE

TL;DR: 本文提出一种融合LLM和分析工具的自动化评估系统，用于高效、可扩展地评估COBOL转Java代码翻译质量，促进代码现代化。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型（LLM）的代码翻译工具存在评估困难，如模型不透明和翻译质量评判复杂，亟需自动化、可扩展的评估方案。

Method: 将分析检查工具与LLM作为评判者（LaaJ）的方法结合，构建支持持续集成和大规模基准测试的自动化评估系统，并集成多维度的评估与报告机制。

Result: 该系统能够自动化多方面地评估代码翻译质量，显著降低人工审查依赖，并生成对开发流程有指导意义的分析报告。

Conclusion: 本文提出的自动化评估系统能够有效提升COBOL到Java代码翻译评估的效率和质量，为开发者和项目经理提供有用反馈，促进代码现代化。

Abstract: We present an automated evaluation system for assessing COBOL-to-Java code
translation within IBM's watsonx Code Assistant for Z (WCA4Z). The system
addresses key challenges in evaluating LLM-based translators, including model
opacity and the complexity of translation quality assessment. Our approach
combines analytic checkers with LLM-as-a-judge (LaaJ) techniques to deliver
scalable, multi-faceted evaluations. The system supports continuous integration
workflows, enables large-scale benchmarking, and reduces reliance on manual
review. We describe the system architecture, evaluation strategies, and
reporting mechanisms that provide actionable insights for developers and
project managers, facilitating the evolution of high-quality, modernized
codebases.

</details>


### [11] [SWE-Exp: Experience-Driven Software Issue Resolution](https://arxiv.org/abs/2507.23361)
*Silin Chen,Shaoxin Lin,Xiaodong Gu,Yuling Shi,Heng Lian,Longfei Yun,Dong Chen,Weiguo Sun,Lin Cao,Qianxiang Wang*

Main category: cs.SE

TL;DR: 本文提出SWE-Exp方法，创新性建立经验库，系统收集与复用修复经验，极大提升了软件自动修复能力，在权威基准上取得最佳表现，引领代理由盲目探索向智能经验驱动转变。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLM）在软件问题自动修复表现出色，但这些模型通常对每个问题独立处理，无法从历史修复经验中学习，导致重复探索失败路径及无法复用已有有效方法。

Method: 提出了SWE-Exp方法，通过建立多层次的经验库，从过往代理执行轨迹中提炼可操作的经验，包括成功和失败的修复尝试，提取从高层理解到具体代码修改的可复用知识，实现跨问题的持续学习。

Result: 在SWE-bench-Verified数据集上，SWE-Exp实现了41.6%的Pass@1最先进问题解决率，优于其他开源代理框架方法。

Conclusion: SWE-Exp树立了一种新范式，使自动化软件工程代理能够系统化累积与利用修复经验，从仅凭尝试—错误转向基于经验的策略化问题解决，显著提升了效率与效果。

Abstract: Recent advances in large language model (LLM) agents have shown remarkable
progress in software issue resolution, leveraging advanced techniques such as
multi-agent collaboration and Monte Carlo Tree Search (MCTS). However, current
agents act as memoryless explorers - treating each problem separately without
retaining or reusing knowledge from previous repair experiences. This leads to
redundant exploration of failed trajectories and missed chances to adapt
successful issue resolution methods to similar problems. To address this
problem, we introduce SWE-Exp, an experience - enhanced approach that distills
concise and actionable experience from prior agent trajectories, enabling
continuous learning across issues. Our method introduces a multi-faceted
experience bank that captures both successful and failed repair attempts.
Specifically, it extracts reusable issue resolution knowledge at different
levels - from high-level problem comprehension to specific code changes.
Experiments show that SWE-Exp achieves state-of-the-art resolution rate (41.6%
Pass@1) on SWE-bench-Verified under open-source agent frameworks. Our approach
establishes a new paradigm in which automated software engineering agents
systematically accumulate and leverage repair expertise, fundamentally shifting
from trial-and-error exploration to strategic, experience-driven issue
resolution.

</details>


### [12] [Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling](https://arxiv.org/abs/2507.23370)
*Trae Research Team,Pengfei Gao,Zhao Tian,Xiangxin Meng,Xinchen Wang,Ruida Hu,Yuanan Xiao,Yizhou Liu,Zhao Zhang,Junjie Chen,Cuiyun Gao,Yun Lin,Yingfei Xiong,Chao Peng,Xia Liu*

Main category: cs.SE

TL;DR: 本文提出Trae Agent，通过智能体方式提升大语言模型在软件库级问题解决中的推理和集成能力，在权威基准实验中超越现有方法，并已开源。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型用于软件问题解决时，依赖提示的集成方法存在难以有效探索大规模集成空间、缺乏库级理解的问题，影响了解题性能。

Method: 提出了一种基于智能体（agent-based）的集成推理方法，通过生成、剪枝和选择三个模块化智能体高效探索方案空间，实现库级别的问题理解和解决。

Result: Trae Agent在SWE-bench基准获得了Pass@1分数75.20%，在所有对比方法中表现最好，并提升了平均10.22%的性能。

Conclusion: Trae Agent在SWE-bench基准测试中表现优异，相较于现有最先进方法平均提升10.22%，成功登顶该榜单，并已开源。

Abstract: Software issue resolution is a critical challenge in software engineering and
has garnered increasing attention in recent years. With the rapid advancement
of large language models (LLMs), substantial progress has been made in
addressing real-world software engineering tasks. Recent studies have
introduced ensemble reasoning techniques to enhance the performance of
LLM-based issue resolution. However, existing prompting-based methods still
face limitations in effectively exploring large ensemble spaces and lack the
capacity for repository-level understanding, both of which constrain their
overall effectiveness. In this paper, we propose Trae Agent, the first
agent-based ensemble reasoning approach for repository-level issue resolution.
Trae Agent formulates our goal as an optimal solution search problem and
addresses two key challenges, i.e., large ensemble spaces and repository-level
understanding, through modular agents for generation, pruning, and selection.
We conduct extensive experiments using three leading LLMs on the widely-adopted
SWE-bench benchmark, comparing Trae Agent against four state-of-the-art
ensemble reasoning techniques. Experimental results demonstrate that Trae Agent
consistently achieves superior performance, with an average improvement of
10.22% over all baselines in terms of Pass@1. Trae Agent has achieved first
place on the SWE-bench Verified leaderboard, with a notable Pass@1 score of
75.20%. We are pleased to release Trae Agent as an open-source project to
support the research community, with all resources available at
https://github.com/bytedance/trae-agent.

</details>


### [13] [Dynamic and Static Analysis of Python Software with Kieker Including Reconstructed Architectures](https://arxiv.org/abs/2507.23425)
*Daphné Larrivain,Shinhyung Yang,Wilhelm Hasselbring*

Main category: cs.SE

TL;DR: Kieker observability框架现在也支持Python，通过静态加动态分析流水线提升了Python系统的结构化洞察能力。


<details>
  <summary>Details</summary>
Motivation: Kieker框架原本是为Java设计的，随着Python近年来的流行，支持Python变得非常有价值，尤其是对Python应用的结构性洞察需求增加。

Method: 提出并实现了一个针对Python的分析流水线，结合了静态分析和动态分析方法，以便全面理解一个给定系统。

Result: 成功将Kieker框架扩展支持Python应用，并通过结合静态与动态分析获得了系统的完整结构信息。

Conclusion: 通过扩展Kieker至Python并设计联合分析流水线，增强了对Python应用结构洞察和可观测性的能力。

Abstract: The Kieker observability framework is a tool that provides users with the
means to design a custom observability pipeline for their application.
Originally tailored for Java, supporting Python with Kieker is worthwhile.
Python's popularity has exploded over the years, thus making structural
insights of Python applications highly valuable. Our Python analysis pipeline
combines static and dynamic analysis in order to build a complete picture of a
given system.

</details>


### [14] [An Empirical Study on the Amount of Changes Required for Merge Request Acceptance](https://arxiv.org/abs/2507.23640)
*Samah Kansab,Mohammed Sayagh,Francis Bordeleau,Ali Tizghadam*

Main category: cs.SE

TL;DR: 本研究基于GitLab大规模MR数据，量化了代码评审中的实际工作量，并通过解释型机器学习模型识别了关键影响因子，为提前评估和优化代码集成工作提供了参考。


<details>
  <summary>Details</summary>
Motivation: 代码评审（Code Review，CR）在软件开发中至关重要，但其过程通常需要大量的工作，包括代码调整、与评审者的互动以及持续实现。过去的研究多关注CR过程中的延迟和迭代次数，较少从代码变动量的角度研究评审工作量，特别是在GitLab Merge Requests（MRs）环境下的相关探索很少。

Method: 作者以MR提交后修改的代码量作为代码评审工作量的衡量指标，利用四个GitLab项目、共23,600多个MR的数据分析了MR中实际发生的代码调整。进一步，作者针对CR工作量搭建了可解释的机器学习模型，输入特征涵盖文本、代码复杂度、开发者经验、历史审查情况和分支信息等多维度指标，用以理解和预测代码评审的工作量。

Result: 71%的MR提交后需要调整，其中28%修改内容超过200行。CR涉及的实际工作量与评审时间、参与人数无明显相关性。机器学习模型表现良好（AUC 0.84-0.88），关键预测因子为代码复杂度、开发者经验与文本特征，项目历史特性同样显著影响当前评审工作量。

Conclusion: 提升代码评审阶段的工作量识别与预判能力具有可行性，机器学习方法能够有效解释并预测GitLab代码评审中的实际工作量，为代码集成过程提供决策依据。

Abstract: Code review (CR) is essential to software development, helping ensure that
new code is properly integrated. However, the CR process often involves
significant effort, including code adjustments, responses to reviewers, and
continued implementation. While past studies have examined CR delays and
iteration counts, few have investigated the effort based on the volume of code
changes required, especially in the context of GitLab Merge Requests (MRs),
which remains underexplored. In this paper, we define and measure CR effort as
the amount of code modified after submission, using a dataset of over 23,600
MRs from four GitLab projects. We find that up to 71% of MRs require
adjustments after submission, and 28% of these involve changes to more than 200
lines of code. Surprisingly, this effort is not correlated with review time or
the number of participants. To better understand and predict CR effort, we
train an interpretable machine learning model using metrics across multiple
dimensions: text features, code complexity, developer experience, review
history, and branching. Our model achieves strong performance (AUC 0.84-0.88)
and reveals that complexity, experience, and text features are key predictors.
Historical project characteristics also influence current review effort. Our
findings highlight the feasibility of using machine learning to explain and
anticipate the effort needed to integrate code changes during review.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [15] [Explanations for Unrealizability of Infinite-State Safety Shields](https://arxiv.org/abs/2507.23603)
*Andoni Rodriguez,Irfansha Shaik,Davide Corsi,Roy Fox,Cesar Sanchez*

Main category: cs.LO

TL;DR: 本文针对安全强化学习中shield合成因规范矛盾等问题导致不可实现的情况，提出了基于时间公式展开的解释方法，能够自动发现并揭示规范的矛盾，辅助开发者修正问题，提升实际shield设计的安全性和可用性。


<details>
  <summary>Details</summary>
Motivation: 安全强化学习领域需要在保证系统安全的前提下开发最优策略，目前主流做法是通过从逻辑规范中综合构建可正确保障安全的组件（shielding）。但在面对无限状态空间（如连续环境）时，保护机制可能因规范自相矛盾而无法实现，亟需找到未能实现的根本原因。

Method: 提出了一种通过时间公式展开（temporal formula unrolling）的技术，能够为不可实现的shield合成结果提供简单的无条件和有条件解释。文中展示了该技术的不同变体及其实用性。

Result: 该方法能够有效为不可实现的规范生成解释，直观揭示规范矛盾或不一致性。在多个实例中，展示了该方法在实际安全强化学习问题中的适用性。

Conclusion: 提出的方法为安全强化学习中shield不可实现问题提供了有效的解释工具，有助于开发者更好地理解和修正规范问题，提高shield设计的实际应用价值。

Abstract: Safe Reinforcement Learning focuses on developing optimal policies while
ensuring safety. A popular method to address such task is shielding, in which a
correct-by-construction safety component is synthesized from logical
specifications. Recently, shield synthesis has been extended to infinite-state
domains, such as continuous environments. This makes shielding more applicable
to realistic scenarios. However, often shields might be unrealizable because
the specification is inconsistent (e.g., contradictory). In order to address
this gap, we present a method to obtain simple unconditional and conditional
explanations that witness unrealizability, which goes by temporal formula
unrolling. In this paper, we show different variants of the technique and its
applicability.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [16] [Large Language Models in the Travel Domain: An Industrial Experience](https://arxiv.org/abs/2507.22910)
*Sergio Di Meglio,Aniello Somma,Luigi Libero Lucio Starace,Fabio Scippacercola,Giancarlo Sperlì,Sergio Di Martino*

Main category: cs.CL

TL;DR: 本文探讨了两种主流LLM在住宿预订平台中的应用效果：Mixtral 8x7B针对内容质量表现显著优于Mistral 7B，但需显著更高的资源成本。研究为生产环境中LLM的选择与部署提供了实用参考。


<details>
  <summary>Details</summary>
Motivation: 在线物业预订平台依赖于一致、实时的住宿设施信息，但第三方数据源常常存在信息不全或不一致的问题，从而影响用户体验并导致市场损失。

Method: 本文以FERVENTO开发的CALEIDOHOTELS平台为例，研究了将大型语言模型（LLM）集成到物业预订平台中的方法。具体比较了Mistral 7B（通过QLoRA微调）和Mixtral 8x7B（优化系统提示词），在生成一致、同质化描述并降低幻觉方面的表现。

Result: Mixtral 8x7B在内容完整度（99.6% vs. 93%）、准确性（98.8% vs. 96%）及幻觉率（1.2% vs. 4%）上均优于Mistral 7B，并能生成更简洁的文本（平均249词 vs. 277词），但计算资源和成本显著更高（50GB VRAM与$1.61/小时 vs. 5GB与$0.16/小时）。

Conclusion: LLM可以显著提升住宿信息的一致性与可靠性，但在模型质量和资源效率之间需要权衡。Mixtral 8x7B在表现上虽然更好，但代价较高，为模型部署决策和生产环境应用提供了实践指导。

Abstract: Online property booking platforms are widely used and rely heavily on
consistent, up-to-date information about accommodation facilities, often
sourced from third-party providers. However, these external data sources are
frequently affected by incomplete or inconsistent details, which can frustrate
users and result in a loss of market. In response to these challenges, we
present an industrial case study involving the integration of Large Language
Models (LLMs) into CALEIDOHOTELS, a property reservation platform developed by
FERVENTO. We evaluate two well-known LLMs in this context: Mistral 7B,
fine-tuned with QLoRA, and Mixtral 8x7B, utilized with a refined system prompt.
Both models were assessed based on their ability to generate consistent and
homogeneous descriptions while minimizing hallucinations. Mixtral 8x7B
outperformed Mistral 7B in terms of completeness (99.6% vs. 93%), precision
(98.8% vs. 96%), and hallucination rate (1.2% vs. 4%), producing shorter yet
more concise content (249 vs. 277 words on average). However, this came at a
significantly higher computational cost: 50GB VRAM and $1.61/hour versus 5GB
and $0.16/hour for Mistral 7B. Our findings provide practical insights into the
trade-offs between model quality and resource efficiency, offering guidance for
deploying LLMs in production environments and demonstrating their effectiveness
in enhancing the consistency and reliability of accommodation data.

</details>


### [17] [ElectriQ: A Benchmark for Assessing the Response Capability of Large Language Models in Power Marketing](https://arxiv.org/abs/2507.22911)
*Jinzhi Wang,Qingke Peng,Haozhou Li,Zeyuan Zeng,Qinfeng Song,Kaixuan Yang,Jiangbo Zhang,Yaoying Wang,Ruimeng Li,Biyi Zhou*

Main category: cs.CL

TL;DR: 本文提出了电力营销领域大模型评测与增强基准ElectriQ，证明领域知识库与微调可使小模型在部分指标上超过GPT-4o，为专用电力服务大模型开发提供可行路径。


<details>
  <summary>Details</summary>
Motivation: 电力营销客户服务在处理咨询、投诉和服务请求中至关重要，但目前系统（如中国的95598热线）存在响应缓慢、流程死板、任务准确率有限等问题。主流大模型虽然能力强，但缺乏电力领域知识和服务共情。

Method: 作者提出ElectriQ，这是首个针对电力营销场景的大模型基准，包含六大服务类别对话数据，设定了专业性、通俗性、可读性和用户友好度四个评价维度。引入电力知识库，并提出知识增强方法提升模型表现。通过在13个大模型上进行实验和微调，评估其在电力服务场景中的实际适用性。

Result: 经过知识增强和微调后，部分小型模型（如LLama3-8B）在专业性和用户友好度方面超过了GPT-4o。

Conclusion: ElectriQ为电力营销服务领域开发专用大模型奠定了全面基础，并证明通过知识增强和领域微调，小模型亦能优于通用型大模型。

Abstract: Electric power marketing customer service plays a critical role in addressing
inquiries, complaints, and service requests. However, current systems, such as
China's 95598 hotline, often struggle with slow response times, inflexible
procedures, and limited accuracy in domain-specific tasks. While large language
models (LLMs) like GPT-4o and Claude 3 demonstrate strong general capabilities,
they lack the domain expertise and empathy required in this field. To bridge
this gap, we introduce ElectriQ, the first benchmark designed to evaluate and
enhance LLMs in electric power marketing scenarios. ElectriQ consists of a
dialogue dataset covering six key service categories and introduces four
evaluation metrics: professionalism, popularity, readability, and
user-friendliness. We further incorporate a domain-specific knowledge base and
propose a knowledge augmentation method to boost model performance. Experiments
on 13 LLMs reveal that smaller models such as LLama3-8B, when fine-tuned and
augmented, can surpass GPT-4o in terms of professionalism and
user-friendliness. ElectriQ establishes a comprehensive foundation for
developing LLMs tailored to the needs of power marketing services.

</details>


### [18] [A Language Model-Driven Semi-Supervised Ensemble Framework for Illicit Market Detection Across Deep/Dark Web and Social Platforms](https://arxiv.org/abs/2507.22912)
*Navid Yazdanjue,Morteza Rakhshaninejad,Hossein Yazdanjouei,Mohammad Sadegh Khorshidi,Mikko S. Niemela,Fang Chen,Amir H. Gandomi*

Main category: cs.CL

TL;DR: 本文提出结合特定领域预训练Transformer和半监督集成学习的方法，显著提升对多平台非法市场内容的检测和分类性能。


<details>
  <summary>Details</summary>
Motivation: 非法市场活动日益隐蔽，犯罪分子转向深网、暗网等平台从事交易，但因数据标注稀缺、语言不断变化及数据来源多样性，相关内容的检测和分类极具挑战性。

Method: 提出了层级分类框架，结合了特定领域微调的长文本Transformer模型（ModernBERT）和半监督集成学习策略。首先提取句子语义和手工设计特征（如结构、嵌入模式及元数据），使用XGBoost、随机森林、SVM组成的半监督集成模型进行两阶段分类：第一步判定是否为交易文档，第二步细分为毒品、武器或凭证销售。

Result: 在三个公开及自建数据集（多源语料库、DUTA、CoDA）上验证，准确率达0.96489，F1分数为0.93467，TMCC为0.95388，显著优于主流基线（如BERT、ALBERT等）。

Conclusion: 本方法能在有限监督下实现高度泛化与鲁棒，具有良好的实际非正规市场内容检测性能。

Abstract: Illegal marketplaces have increasingly shifted to concealed parts of the
internet, including the deep and dark web, as well as platforms such as
Telegram, Reddit, and Pastebin. These channels enable the anonymous trade of
illicit goods including drugs, weapons, and stolen credentials. Detecting and
categorizing such content remains challenging due to limited labeled data, the
evolving nature of illicit language, and the structural heterogeneity of online
sources. This paper presents a hierarchical classification framework that
combines fine-tuned language models with a semi-supervised ensemble learning
strategy to detect and classify illicit marketplace content across diverse
platforms. We extract semantic representations using ModernBERT, a transformer
model for long documents, finetuned on domain-specific data from deep and dark
web pages, Telegram channels, Subreddits, and Pastebin pastes to capture
specialized jargon and ambiguous linguistic patterns. In addition, we
incorporate manually engineered features such as document structure, embedded
patterns including Bitcoin addresses, emails, and IPs, and metadata, which
complement language model embeddings. The classification pipeline operates in
two stages. The first stage uses a semi-supervised ensemble of XGBoost, Random
Forest, and SVM with entropy-based weighted voting to detect sales-related
documents. The second stage further classifies these into drug, weapon, or
credential sales. Experiments on three datasets, including our multi-source
corpus, DUTA, and CoDA, show that our model outperforms several baselines,
including BERT, ModernBERT, DarkBERT, ALBERT, Longformer, and BigBird. The
model achieves an accuracy of 0.96489, an F1-score of 0.93467, and a TMCC of
0.95388, demonstrating strong generalization, robustness under limited
supervision, and effectiveness in real-world illicit content detection.

</details>


### [19] [A Hybrid Framework for Subject Analysis: Integrating Embedding-Based Regression Models with Large Language Models](https://arxiv.org/abs/2507.22913)
*Jinyu Liu,Xiaoying Song,Diana Zhang,Jason Thomale,Daqing He,Lingzi Hong*

Main category: cs.CL

TL;DR: 本研究提出用ML+LLM混合方法提升图书馆主题词预测的准确性与规范性，防止LLM胡编现象，实验效果优于单独用LLM。


<details>
  <summary>Details</summary>
Motivation: 图书馆资源的主题分析对于管理系统至关重要。传统机器学习模型在多标签分类任务上表现有限，尤其面对未见案例时效果不佳。大语言模型（LLMs）尽管理论上适用于该场景，但存在过度生成和幻觉问题。为了解决这些问题，作者提出整合两者优点的混合方法。

Method: 作者构建了一个混合框架，将基于嵌入的ML模型与LLM结合。（1）ML模型先预测最优的主题标签数量，为LLM生成提供指导；（2）利用实际LCSH术语对LLM预测结果进行后编辑修正，减少幻觉。

Result: 通过对图书馆主题词（LCSH）的预测实验，混合框架在控制输出和对齐词汇标准方面优于单独使用LLM，表现出更好的可控性和准确性。

Conclusion: 混合方法能更有效地引导和修正LLM的主题分析，减少幻觉并与专业词表保持一致。该方法有助于提升图书馆主题分析系统的性能。

Abstract: Providing subject access to information resources is an essential function of
any library management system. Large language models (LLMs) have been widely
used in classification and summarization tasks, but their capability to perform
subject analysis is underexplored. Multi-label classification with traditional
machine learning (ML) models has been used for subject analysis but struggles
with unseen cases. LLMs offer an alternative but often over-generate and
hallucinate. Therefore, we propose a hybrid framework that integrates
embedding-based ML models with LLMs. This approach uses ML models to (1)
predict the optimal number of LCSH labels to guide LLM predictions and (2)
post-edit the predicted terms with actual LCSH terms to mitigate
hallucinations. We experimented with LLMs and the hybrid framework to predict
the subject terms of books using the Library of Congress Subject Headings
(LCSH). Experiment results show that providing initial predictions to guide LLM
generations and imposing post-edits result in more controlled and
vocabulary-aligned outputs.

</details>


### [20] [Full Triple Matcher: Integrating all triple elements between heterogeneous Knowledge Graphs](https://arxiv.org/abs/2507.22914)
*Victor Eiti Yamamoto,Hideaki Takeda*

Main category: cs.CL

TL;DR: 提出了一种结合标签和三元组匹配的知识图谱整合方法，显著提升了多源异构背景下的匹配效果，并在国际竞赛和多项数据集上取得了高准确率，实现了对上下文匹配问题的突破。


<details>
  <summary>Details</summary>
Motivation: 知识图谱在表示和推理结构化信息方面非常有用，但当前实体匹配方法主要关注于模式和身份匹配，对于上下文的匹配研究较少。而现实中的知识图谱往往来源多样、规模和信息密度各异，这使得现有方法在复杂、多样的上下文整合场景下效果有限。本文旨在解决复杂上下文下知识图谱整合的难题。

Method: 提出了一种新的知识图谱整合方法，包括标签匹配和三元组匹配两大步骤。首先利用字符串操作、模糊匹配和向量相似度等技术对实体和谓词标签进行对齐。然后，通过识别在信息表达上相似的三元组来完善匹配，进而提升实体匹配的准确性。

Result: 该方法在知名的OAEI竞赛和与有监督方法的比较中表现出色，能够在多样化测试案例中达到高准确率。同时，还构建了一个新的基准数据集，用于三元组匹配步骤的更全面评估。

Conclusion: 本文方法有效提升了复杂背景下知识图谱整合的准确率，并展示了较强的通用性和竞争力，在无监督条件下也能实现优秀表现。文章还为三元组匹配提出新的评测基准，为后续相关研究提供支持。

Abstract: Knowledge graphs (KGs) are powerful tools for representing and reasoning over
structured information. Their main components include schema, identity, and
context. While schema and identity matching are well-established in ontology
and entity matching research, context matching remains largely unexplored. This
is particularly important because real-world KGs often vary significantly in
source, size, and information density - factors not typically represented in
the datasets on which current entity matching methods are evaluated. As a
result, existing approaches may fall short in scenarios where diverse and
complex contexts need to be integrated.
  To address this gap, we propose a novel KG integration method consisting of
label matching and triple matching. We use string manipulation, fuzzy matching,
and vector similarity techniques to align entity and predicate labels. Next, we
identify mappings between triples that convey comparable information, using
these mappings to improve entity-matching accuracy. Our approach demonstrates
competitive performance compared to leading systems in the OAEI competition and
against supervised methods, achieving high accuracy across diverse test cases.
Additionally, we introduce a new dataset derived from the benchmark dataset to
evaluate the triple-matching step more comprehensively.

</details>


### [21] [Theoretical Foundations and Mitigation of Hallucination in Large Language Models](https://arxiv.org/abs/2507.22915)
*Esmail Gumaan*

Main category: cs.CL

TL;DR: 本论文形式化分析了大语言模型幻觉问题，理论推导风险边界，系统梳理检测与缓解方法并提供评测建议，是理解和解决幻觉的理论与实践参考。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型广泛应用，模型生成与实际不符的幻觉内容成为关键挑战，急需理论基础和系统解决方案指导识别和减轻幻觉。

Method: 采用了理论分析（包括PAC-Bayes和Rademacher复杂度），系统性综述和流程化工作的梳理，覆盖检测及缓解幻觉的多种策略。

Result: 区分并定义了内在与外在幻觉，给出幻觉风险的理论界，梳理和提出一体化的检测、缓解方法，并推荐评测协议、数据集和指标，对行业实践有重要指导意义。

Conclusion: 本论文为大语言模型（LLMs）幻觉问题提供了理论基础和实际应对指南。通过形式化定义、理论分析及实际措施，帮助业界更系统地理解与减少幻觉现象。

Abstract: Hallucination in Large Language Models (LLMs) refers to the generation of
content that is not faithful to the input or the real-world facts. This paper
provides a rigorous treatment of hallucination in LLMs, including formal
definitions and theoretical analyses. We distinguish between intrinsic and
extrinsic hallucinations, and define a \textit{hallucination risk} for models.
We derive bounds on this risk using learning-theoretic frameworks (PAC-Bayes
and Rademacher complexity). We then survey detection strategies for
hallucinations, such as token-level uncertainty estimation, confidence
calibration, and attention alignment checks. On the mitigation side, we discuss
approaches including retrieval-augmented generation, hallucination-aware
fine-tuning, logit calibration, and the incorporation of fact-verification
modules. We propose a unified detection and mitigation workflow, illustrated
with a diagram, to integrate these strategies. Finally, we outline evaluation
protocols for hallucination, recommending datasets, metrics, and experimental
setups to quantify and reduce hallucinations. Our work lays a theoretical
foundation and practical guidelines for addressing the crucial challenge of
hallucination in LLMs.

</details>


### [22] [Reading Between the Timelines: RAG for Answering Diachronic Questions](https://arxiv.org/abs/2507.22917)
*Kwun Hang Lau,Ruiyuan Zhang,Weijie Shi,Xiaofang Zhou,Xiaojun Cheng*

Main category: cs.CL

TL;DR: 论文提出了一种新型方法，为RAG系统引入时序逻辑，使其能处理跨时段检索与生成任务，并在自建金融新闻数据集上实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统的RAG（Retrieval-Augmented Generation）在处理需要跟踪实体与现象随时间变化的“纵向”查询时存在明显短板，主要因为现有的检索方法只依赖语义相关性，无法确保取证内容在时序上的连贯性。该论文的研究动机在于解决这一检索和生成系统的时序盲点。

Method: 作者提出重新设计RAG流程，引入时序逻辑。具体方法包括：首先将用户查询拆解为核心主题和特定时间窗口，然后采用特殊检索器，对语义匹配与时序相关性进行联合校准，确保获得横跨整个查询周期的连贯证据集合。最后，作者还提出了用于此类任务评估的Analytical Diachronic Question Answering Benchmark（ADQAB）数据集。

Result: 实验结果显示，针对ADQAB基准的实证测试中，作者方法在答案准确率上比标准RAG系统提升13%-27%。

Conclusion: 该方法有效提升了RAG在处理需要时序演化分析的复杂真实世界问题的能力，为类似系统的精细化时序推理提供了一条可行、经过验证的路径。论文相应的数据集和代码也已开放。

Abstract: While Retrieval-Augmented Generation (RAG) excels at injecting static,
factual knowledge into Large Language Models (LLMs), it exhibits a critical
deficit in handling longitudinal queries that require tracking entities and
phenomena across time. This blind spot arises because conventional,
semantically-driven retrieval methods are not equipped to gather evidence that
is both topically relevant and temporally coherent for a specified duration. We
address this challenge by proposing a new framework that fundamentally
redesigns the RAG pipeline to infuse temporal logic. Our methodology begins by
disentangling a user's query into its core subject and its temporal window. It
then employs a specialized retriever that calibrates semantic matching against
temporal relevance, ensuring the collection of a contiguous evidence set that
spans the entire queried period. To enable rigorous evaluation of this
capability, we also introduce the Analytical Diachronic Question Answering
Benchmark (ADQAB), a challenging evaluation suite grounded in a hybrid corpus
of real and synthetic financial news. Empirical results on ADQAB show that our
approach yields substantial gains in answer accuracy, surpassing standard RAG
implementations by 13% to 27%. This work provides a validated pathway toward
RAG systems capable of performing the nuanced, evolutionary analysis required
for complex, real-world questions. The dataset and code for this study are
publicly available at https://github.com/kwunhang/TA-RAG.

</details>


### [23] [Semantic Convergence: Investigating Shared Representations Across Scaled LLMs](https://arxiv.org/abs/2507.22918)
*Daniel Son,Sanjana Rathore,Andrew Rufail,Adrian Simon,Daniel Zhang,Soham Dave,Cole Blondin,Kevin Zhu,Sean O'Brien*

Main category: cs.CL

TL;DR: 本文比较了不同规模的Gemma-2语言模型，在中间层具有高度通用的语义特征，证明了参数扩大的模型仍然会学到相似、可解释的内部表征，为模型可解释性研究提供了理论支撑。


<details>
  <summary>Details</summary>
Motivation: 研究不同规模（2B和9B参数）的Gemma-2语言模型在内部表征（特征）上的通用性和收敛情况，即模型规模扩大后其学习到的内部表示是否一致。

Method: 使用Sparse Autoencoder (SAE)字典学习技术，对每个模型的残差流激活进行特征提取，并通过激活相关性对齐特征。利用SVCCA和RSA等方法比较匹配后的特征空间重叠度。同时进行多token子空间的初步扩展实验。

Result: 中间层的特征重叠度最高，表明最大共性；而早期和末尾层的相似性较低。多token子空间分析显示语义相似的子空间与模型的交互方式近似。

Conclusion: 大语言模型在参数规模存在较大差异时，依然会收敛成相似且可解释的内部特征。这种特征通用性对跨模型可解释性研究具有重要基础意义。

Abstract: We investigate feature universality in Gemma-2 language models (Gemma-2-2B
and Gemma-2-9B), asking whether models with a four-fold difference in scale
still converge on comparable internal concepts. Using the Sparse Autoencoder
(SAE) dictionary-learning pipeline, we utilize SAEs on each model's
residual-stream activations, align the resulting monosemantic features via
activation correlation, and compare the matched feature spaces with SVCCA and
RSA. Middle layers yield the strongest overlap, while early and late layers
show far less similarity. Preliminary experiments extend the analysis from
single tokens to multi-token subspaces, showing that semantically similar
subspaces interact similarly with language models. These results strengthen the
case that large language models carve the world into broadly similar,
interpretable features despite size differences, reinforcing universality as a
foundation for cross-model interpretability.

</details>


### [24] [A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations](https://arxiv.org/abs/2507.22919)
*Qixuan Hu,Xumou Zhang,Jinman Kim,Florence Bourgeois,Adam G. Dunn*

Main category: cs.CL

TL;DR: 本文利用ClinicalTrials.gov数据，结合预训练语言模型和滑动窗口技术，实现了较高准确度的临床试验SAE结果预测，有助于提升临床研究的安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 临床试验在设计阶段若能准确预测安全性事件，将有助于避免试验中断并减少受试者暴露于不必要风险中。目前依赖注册信息预测严重不良事件（SAE）结果的方法有限。

Method: 分析了ClinicalTrials.gov上22,107个两组平行对照干预性临床试验的结构化摘要结果。分别建立了两个预测模型：1）分类模型预测实验组SAE发生率是否高于对照组（以AUC衡量）；2）回归模型预测对照组SAE发生比例（以RMSE衡量）。采用了预训练语言模型（如ClinicalT5、BioBERT）为特征提取基础，并结合下游模型进行预测。同时，为应对超长文本输入问题，开发滑动窗口方法用于文本嵌入提取。

Result: 最佳模型（ClinicalT5+Transformer+MLP）在预测试验组与对照组中哪一组SAE比例较高时，AUC达到77.6%；在预测对照组参与者经历SAE的比例时，RMSE为18.6%。滑动窗口方法在各类模型中表现均优于未采用该方法时，分类器平均AUC提升2.00%，回归器平均RMSE下降1.58%。

Conclusion: 基于注册信息，利用先进的语言模型和滑动窗口策略，可以显著提升临床试验SAE结果的预测准确性，这对于优化临床试验设计和识别安全性预期与结果之间的差异具有重要意义。

Abstract: Objectives: With accurate estimates of expected safety results, clinical
trials could be designed to avoid terminations and limit exposing participants
to unnecessary risks. We evaluated methods for predicting serious adverse event
(SAE) results in clinical trials using information only from their
registrations prior to the trial. Material and Methods: We analysed 22,107
two-arm parallel interventional clinical trials from ClinicalTrials.gov with
structured summary results. Two prediction models were developed: a classifier
predicting will experimental arm have higher SAE rates (area under the receiver
operating characteristic curve; AUC) than control arm, and a regression model
to predict the proportion of SAEs in control arms (root mean squared error;
RMSE). A transfer learning approach using pretrained language models (e.g.,
ClinicalT5, BioBERT) was used for feature extraction, combined with downstream
model for prediction. To maintain semantic representation in long trial texts
exceeding localised language model input limits, a sliding window method was
developed for embedding extraction. Results: The best model
(ClinicalT5+Transformer+MLP) had 77.6% AUC predicting which trial arm has a
higher proportion of patients with SAEs. When predicting proportion of
participants experiencing SAE in the control arm, the same model achieved RMSE
of 18.6%. The sliding window approach consistently outperformed methods without
it. Across 12 classifiers, the average absolute AUC increase was 2.00%; across
12 regressors, the average absolute RMSE reduction was 1.58%. Discussion:
Summary results data available at ClinicalTrials.gov remains underutilised. The
potential to estimate results of trials before they start is an opportunity to
improve trial design and flag discrepancies between expected and reported
safety results.

</details>


### [25] [Discrete Tokenization for Multimodal LLMs: A Comprehensive Survey](https://arxiv.org/abs/2507.22920)
*Jindong Li,Yali Fu,Jiahong Liu,Linxiao Cao,Wei Ji,Menglin Yang,Irwin King,Ming-Hsuan Yang*

Main category: cs.CL

TL;DR: 本综述系统梳理了LLM中的离散分词与矢量量化方法，总结8种主流VQ变体与现实挑战，并探讨未来发展方向，对推动高效通用多模态系统有重要参考价值。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的快速发展，将连续的多模态数据有效转化为可离散化、适用于语言处理的数据表示需求日益迫切。尽管矢量量化（VQ）等离散分词方法越来越重要，但缺乏系统性的综述分析VQ在LLM体系中的应用与挑战。

Method: 本文对现有的离散分词和VQ技术进行了系统梳理，搭建了首个 LLM 离散分词方法结构化分类体系。文中共归纳分析了8种代表性VQ变体，覆盖了经典和现代范式，并从算法原理、训练动态及与 LLM 结合时的挑战等多个角度进行分析。还比较了VQ在传统（无LLM）、LLM单模态和多模态系统中的应用与影响。

Result: 本文系统总结了VQ的研究进展，归纳了当前面临的主要挑战，如码本坍塌、梯度估计不稳定及模态专属编码限制等，并提出了未来研究方向，比如动态/任务自适应量化、统一分词框架以及生物启发式码本学习。作者还提供了不断更新的资源以供后续参考。

Conclusion: 本文是首个围绕LLM体系下离散分词与矢量量化方法的系统综述，分析其技术分类、关键难点与未来趋势，为后续高效通用多模态系统的构建提供了理论基础与参考资源。

Abstract: The rapid advancement of large language models (LLMs) has intensified the
need for effective mechanisms to transform continuous multimodal data into
discrete representations suitable for language-based processing. Discrete
tokenization, with vector quantization (VQ) as a central approach, offers both
computational efficiency and compatibility with LLM architectures. Despite its
growing importance, there is a lack of a comprehensive survey that
systematically examines VQ techniques in the context of LLM-based systems. This
work fills this gap by presenting the first structured taxonomy and analysis of
discrete tokenization methods designed for LLMs. We categorize 8 representative
VQ variants that span classical and modern paradigms and analyze their
algorithmic principles, training dynamics, and integration challenges with LLM
pipelines. Beyond algorithm-level investigation, we discuss existing research
in terms of classical applications without LLMs, LLM-based single-modality
systems, and LLM-based multimodal systems, highlighting how quantization
strategies influence alignment, reasoning, and generation performance. In
addition, we identify key challenges including codebook collapse, unstable
gradient estimation, and modality-specific encoding constraints. Finally, we
discuss emerging research directions such as dynamic and task-adaptive
quantization, unified tokenization frameworks, and biologically inspired
codebook learning. This survey bridges the gap between traditional vector
quantization and modern LLM applications, serving as a foundational reference
for the development of efficient and generalizable multimodal systems. A
continuously updated version is available at:
https://github.com/jindongli-Ai/LLM-Discrete-Tokenization-Survey.

</details>


### [26] [Fast and Accurate Contextual Knowledge Extraction Using Cascading Language Model Chains and Candidate Answers](https://arxiv.org/abs/2507.22921)
*Lee Harris*

Main category: cs.CL

TL;DR: 本文提出的语言模型链（LMC）算法将多种语言模型按需串联，大幅提升了从医疗文档中提取信息的准确性与速度，并有效降低了模型幻觉，为知识抽取任务带来新突破。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型虽然能够捕捉文本中的复杂关系，但其计算成本高，并且容易产生虚假信息（幻觉）。在实际应用场景中，错误信息不仅无用，还会浪费计算资源。作者旨在解决语言模型幻觉和资源浪费的问题。

Method: 本文提出了语言模型链（Language Model Chain, LMC）算法：首先利用模型从给定文本给出多个候选答案，若答案在候选集中则被认为是正确的，否则将错误的文本输入到更强但更慢的语言模型重复判断。这个过程可串联多个模型，直到所有预测都正确为止。

Result: 在医学文档中提取患者出生日期的实验表明，LMC算法比单一的语言模型在速度和准确率上均有明显提升，同时大幅降低了幻觉（虚假信息）的发生频率。

Conclusion: LMC算法通过模型级联的方式，有效提升文本知识抽取的准确率和执行效率，显著减少虚假信息的输出，对知识抽取领域有重要贡献，未来值得进一步研究和应用。

Abstract: Language models can capture complex relationships in given text, but these
are notorious for being costly and for producing information that does not
exist (i.e., hallucinations). Furthermore, the resources invested into
producing this information would be wasted if it were incorrect. We address
these issues by proposing, implementing, and applying the Language Model Chain
(LMC) algorithm. In this, a language model's response to a given prompt about
given text is only correct if it exists in the collection of possible (i.e.,
candidate) answers, and text corresponding to incorrect responses is fed into a
more predictive (but slower) language model. This process is repeated for a
collection of language models, or until all predictions about the text are
correct. We used the LMC algorithm to extract patient dates of birth from
medical documents, and combining a collection of language models in a
multi-stage cascade significantly increased prediction speed and accuracy over
individual language models, while greatly reducing the number of corresponding
hallucinations. We believe that the novel LMC algorithm significantly
contributes to the knowledge extraction field, and that this should be explored
much further in the future.

</details>


### [27] [Predicting stock prices with ChatGPT-annotated Reddit sentiment](https://arxiv.org/abs/2507.22922)
*Mateusz Kmak,Kamil Chmurzyński,Kamil Matejuk,Paweł Kotzbach,Jan Kocoń*

Main category: cs.CL

TL;DR: 文中结合Reddit讨论与网络热度数据，发现社交媒体情绪文本对股价预测作用有限，简单的评论量和搜索热度指标反而效果更好，指出传统方法难以揭示复杂的散户行为机制。


<details>
  <summary>Details</summary>
Motivation: 随着2021年GameStop轧空事件的爆发，散户在社交媒体上的活跃引发了线上情绪是否能影响股价的讨论。作者试图研究社交媒体情绪对股市的实际预测力。

Method: 文章以Reddit的r/wallstreetbets版块为例，选取GameStop（GME）和AMC Entertainment（AMC）为研究对象，应用了两种已有文本情感分析方法，并引入一种基于ChatGPT标注并微调RoBERTa的新模型，专门适应非正式语言和表情符号。作者还借助相关性与因果关系度量来评估这些模型的预测能力。

Result: 结果显示，社交媒体情绪与股价之间只有较弱的相关性，而评论量和谷歌搜索趋势等更简单的指标反而有更强的预测信号。

Conclusion: 传统情感分析方法难以捕捉复杂的散户投资行为，社交媒体情绪的实际预测价值有限。市场推动因素中存在更多未被传统方法覆盖的复杂性。

Abstract: The surge of retail investor activity on social media, exemplified by the
2021 GameStop short squeeze, raised questions about the influence of online
sentiment on stock prices. This paper explores whether sentiment derived from
social media discussions can meaningfully predict stock market movements. We
focus on Reddit's r/wallstreetbets and analyze sentiment related to two
companies: GameStop (GME) and AMC Entertainment (AMC). To assess sentiment's
role, we employ two existing text-based sentiment analysis methods and
introduce a third, a ChatGPT-annotated and fine-tuned RoBERTa-based model
designed to better interpret the informal language and emojis prevalent in
social media discussions. We use correlation and causality metrics to determine
these models' predictive power. Surprisingly, our findings suggest that social
media sentiment has only a weak correlation with stock prices. At the same
time, simpler metrics, such as the volume of comments and Google search trends,
exhibit stronger predictive signals. These results highlight the complexity of
retail investor behavior and suggest that traditional sentiment analysis may
not fully capture the nuances of market-moving online discussions.

</details>


### [28] [How and Where to Translate? The Impact of Translation Strategies in Cross-lingual LLM Prompting](https://arxiv.org/abs/2507.22923)
*Aman Gupta,Yingying Zhuang,Zhou Yu,Ziji Zhang,Anurag Beniwal*

Main category: cs.CL

TL;DR: 本文系统评估了多语言RAG系统中不同提示词翻译策略在分类任务中的影响，发现优化的策略可显著提升非英语、尤其是低资源语言的分类表现，建议推广多语言资源共享和跨语言提示优化。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽具备多语言能力，但在不同语言及任务上的表现差距较大。RAG系统常用英文知识库在多语言场景下会导致检索信息与上下文语言不一致，目前常见预翻译与跨语言提示的效果尚不明确，需要系统评估。

Method: 系统性地评估了不同提示词翻译策略在RAG增强大语言模型进行多语言分类任务中的效果。通过实验分析了预翻译和跨语言提示两种常见做法的影响。

Result: 实验表明，合理优化的提示策略不仅能提升多语言系统的知识共享，也能显著提升下游分类任务的准确性与效果，尤其对低资源语言提升明显。

Conclusion: 针对多语言RAG系统中的分类任务，优化的提示词翻译策略能够显著提升跨语言的知识共享和下游任务表现，尤其对低资源语言系统有益。

Abstract: Despite advances in the multilingual capabilities of Large Language Models
(LLMs), their performance varies substantially across different languages and
tasks. In multilingual retrieval-augmented generation (RAG)-based systems,
knowledge bases (KB) are often shared from high-resource languages (such as
English) to low-resource ones, resulting in retrieved information from the KB
being in a different language than the rest of the context. In such scenarios,
two common practices are pre-translation to create a mono-lingual prompt and
cross-lingual prompting for direct inference. However, the impact of these
choices remains unclear. In this paper, we systematically evaluate the impact
of different prompt translation strategies for classification tasks with
RAG-enhanced LLMs in multilingual systems. Experimental results show that an
optimized prompting strategy can significantly improve knowledge sharing across
languages, therefore improve the performance on the downstream classification
task. The findings advocate for a broader utilization of multilingual resource
sharing and cross-lingual prompt optimization for non-English languages,
especially the low-resource ones.

</details>


### [29] [Using Sentiment Analysis to Investigate Peer Feedback by Native and Non-Native English Speakers](https://arxiv.org/abs/2507.22924)
*Brittney Exline,Melanie Duffin,Brittany Harbison,Chrissa da Gomez,David Joyner*

Main category: cs.CL

TL;DR: 本研究发现，在美国在线CS课程中，非英语母语学生写的反馈更积极，但他们收到的反馈情感较低，母语学生则对反馈评价更苛刻。语言背景对同伴反馈体验影响复杂，应针对性优化教学互动。


<details>
  <summary>Details</summary>
Motivation: 在美国CS研究生项目中，国际学生比例持续上升，许多学生通过英文在线课程学习，并参与同伴互评，但多数为非母语环境。因此，了解母语与非母语学生在同伴反馈中的体验差异，对改进在线教育质量尤为重要。

Method: 采用Twitter-roBERTa模型，对500名学生的同伴评价文本进行情感分析，并将其结果与学生的语言背景（英语母语与非母语）进行关联分析，同时结合评分、性别及年龄等因素进一步探讨。

Result: 研究发现，英语母语学生对收到的反馈评价较低；非母语学生提供的反馈情感更积极，但他们收到的反馈情感却更少积极。在控制性别和年龄后，发现语言背景对同伴反馈体验有一定但较为复杂的影响。

Conclusion: 学生语言背景在在线CS课程同伴反馈中具有一定影响，非母语学生写作较积极，但收获的反馈较不积极。不同学生群体之间的反馈机制应进一步优化，以促进有效沟通与学习体验。

Abstract: Graduate-level CS programs in the U.S. increasingly enroll international
students, with 60.2 percent of master's degrees in 2023 awarded to non-U.S.
students. Many of these students take online courses, where peer feedback is
used to engage students and improve pedagogy in a scalable manner. Since these
courses are conducted in English, many students study in a language other than
their first. This paper examines how native versus non-native English speaker
status affects three metrics of peer feedback experience in online U.S.-based
computing courses. Using the Twitter-roBERTa-based model, we analyze the
sentiment of peer reviews written by and to a random sample of 500 students. We
then relate sentiment scores and peer feedback ratings to students' language
background. Results show that native English speakers rate feedback less
favorably, while non-native speakers write more positively but receive less
positive sentiment in return. When controlling for sex and age, significant
interactions emerge, suggesting that language background plays a modest but
complex role in shaping peer feedback experiences.

</details>


### [30] [Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents](https://arxiv.org/abs/2507.22925)
*Haoran Sun,Shaoning Zeng*

Main category: cs.CL

TL;DR: 本文提出H-MEM层次化记忆架构，有效提升了LLM代理长期记忆的结构化管理与检索效率，在多个任务中表现优于主流方法。


<details>
  <summary>Details</summary>
Motivation: 长时记忆是影响大语言模型代理（LLM Agents）推理能力的关键因素。现有的内存机制在存储和高效检索方面存在结构化不足与效率低下的问题。

Method: 提出了一种层次化记忆（H-MEM）架构，将记忆按语义抽象程度多层次组织，并通过位置索引编码将每个记忆向量与其下层相关子记忆连接。在推理阶段，采用基于索引的路由机制，逐层高效检索记忆，无需高耗时的相似度搜索。

Result: 在LoCoMo数据集的五个任务设置下，H-MEM方法在长期对话场景中整体上优于五种主流基线方法，验证了该架构的有效性。

Conclusion: H-MEM为LLM代理带来了结构化、层次化的记忆管理与高效检索机制，在实际推理与对话任务中提升了表现，解决了现有方法的主要短板。

Abstract: Long-term memory is one of the key factors influencing the reasoning
capabilities of Large Language Model Agents (LLM Agents). Incorporating a
memory mechanism that effectively integrates past interactions can
significantly enhance decision-making and contextual coherence of LLM Agents.
While recent works have made progress in memory storage and retrieval, such as
encoding memory into dense vectors for similarity-based search or organizing
knowledge in the form of graph, these approaches often fall short in structured
memory organization and efficient retrieval. To address these limitations, we
propose a Hierarchical Memory (H-MEM) architecture for LLM Agents that
organizes and updates memory in a multi-level fashion based on the degree of
semantic abstraction. Each memory vector is embedded with a positional index
encoding pointing to its semantically related sub-memories in the next layer.
During the reasoning phase, an index-based routing mechanism enables efficient,
layer-by-layer retrieval without performing exhaustive similarity computations.
We evaluate our method on five task settings from the LoCoMo dataset.
Experimental results show that our approach consistently outperforms five
baseline methods, demonstrating its effectiveness in long-term dialogue
scenarios.

</details>


### [31] [Multi-Relation Extraction in Entity Pairs using Global Context](https://arxiv.org/abs/2507.22926)
*Nilesh,Atul Gupta,Avinash C Panday*

Main category: cs.CL

TL;DR: 提出以实体为中心的全局嵌入方法，有效提升文档级关系抽取性能，实现了更准确和全面的实体关系检测。


<details>
  <summary>Details</summary>
Motivation: 现有文档级关系抽取方法仅关注于实体出现的句子，无法捕获文档全局上下文，导致关系判断不准确。实体在文档中可能多次出现，并且不同语境下关系可能不同，因此需要捕获跨越所有相关句子的全局上下文。

Method: 提出了一种新颖的输入嵌入方法，通过表示实体在文档中的全局位置，将实体作为独立片段进行建模，而不是仅关注实体出现的局部区间。这种编码方法促进了文档全局关系的建模和多句推理能力。

Result: 在DocRED、Re-DocRED和REBEL三个基准关系抽取数据集上进行了测试，实验结果表明该方法能在文档级别准确预测实体关系。

Conclusion: 本研究提出的全局实体输入嵌入方法提升了文档级关系抽取任务中的全局上下文建模和多句推理能力，在理论与实践层面均具有重要意义，提高了关系检测的准确性、覆盖性和可解释性。

Abstract: In document-level relation extraction, entities may appear multiple times in
a document, and their relationships can shift from one context to another.
Accurate prediction of the relationship between two entities across an entire
document requires building a global context spanning all relevant sentences.
Previous approaches have focused only on the sentences where entities are
mentioned, which fails to capture the complete document context necessary for
accurate relation extraction. Therefore, this paper introduces a novel input
embedding approach to capture the positions of mentioned entities throughout
the document rather than focusing solely on the span where they appear. The
proposed input encoding approach leverages global relationships and
multi-sentence reasoning by representing entities as standalone segments,
independent of their positions within the document. The performance of the
proposed method has been tested on three benchmark relation extraction
datasets, namely DocRED, Re-DocRED, and REBEL. The experimental results
demonstrated that the proposed method accurately predicts relationships between
entities in a document-level setting. The proposed research also has
theoretical and practical implications. Theoretically, it advances global
context modeling and multi-sentence reasoning in document-level relation
extraction. Practically, it enhances relationship detection, enabling improved
performance in real-world NLP applications requiring comprehensive entity-level
insights and interpretability.

</details>


### [32] [PRGB Benchmark: A Robust Placeholder-Assisted Algorithm for Benchmarking Retrieval-Augmented Generation](https://arxiv.org/abs/2507.22927)
*Zhehao Tan,Yihan Jiao,Dan Yang,Lei Liu,Jie Feng,Duolin Sun,Yue Shen,Jian Wang,Peng Wei,Jinjie Gu*

Main category: cs.CL

TL;DR: 本文提出了细粒度的RAG能力评测基准，可以更好地揭示大模型在知识检索增强生成任务下的优缺点，对提升系统可靠性和效果有实用价值。


<details>
  <summary>Details</summary>
Motivation: 虽然RAG技术使大模型可以结合外部知识生成更优答案，但现有评测主要关注整体性能，缺乏对大模型在文档利用上能力的细致评估。因此，作者希望建立一个更细粒度的基准，用以分析大模型在RAG系统中的具体表现和局限。

Method: 提出了Placeholder-RAG-Benchmark，一种多层次、细粒度的评估基准。该基准专注于过滤能力、组合能力和推理能力三个维度，通过创新的方法将大模型本体知识与外部知识的贡献解耦，方便更精准地评估大模型在RAG中的作用。

Result: 实验证明，代表性大模型在RAG任务的生成能力上仍存在较大局限，特别是在抗干扰性和上下文忠实性方面。该基准为研发更可靠、更高效的RAG系统提供了可复现的评测框架。

Conclusion: 提出的Placeholder-RAG-Benchmark有效填补了现有RAG评估的空白，有助于发现并解决大模型在RAG场景下的实际问题，为后续相关系统的研发提供了科学依据。

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by
integrating external knowledge, where the LLM's ability to generate responses
based on the combination of a given query and retrieved documents is crucial.
However, most benchmarks focus on overall RAG system performance, rarely
assessing LLM-specific capabilities. Current benchmarks emphasize broad aspects
such as noise robustness, but lack a systematic and granular evaluation
framework on document utilization. To this end, we introduce
\textit{Placeholder-RAG-Benchmark}, a multi-level fine-grained benchmark,
emphasizing the following progressive dimensions: (1) multi-level filtering
abilities, (2) combination abilities, and (3) reference reasoning. To provide a
more nuanced understanding of LLMs' roles in RAG systems, we formulate an
innovative placeholder-based approach to decouple the contributions of the
LLM's parametric knowledge and the external knowledge. Experiments demonstrate
the limitations of representative LLMs in the RAG system's generation
capabilities, particularly in error resilience and context faithfulness. Our
benchmark provides a reproducible framework for developing more reliable and
efficient RAG systems. Our code is available in
https://github.com/Alipay-Med/PRGB.

</details>


### [33] [How does Chain of Thought Think? Mechanistic Interpretability of Chain-of-Thought Reasoning with Sparse Autoencoding](https://arxiv.org/abs/2507.22928)
*Xi Chen,Aske Plaat,Niki van Stein*

Main category: cs.CL

TL;DR: 本文首次在特征层面研究了CoT提示与模型内部推理的因果关系。方法结合稀疏自动编码器和激活修补，发现仅大模型（2.8B）存在通过CoT特征提升推理表现的效应、小模型（70M）无此现象。CoT让大模型内部推理更清晰、可解释，进一步支持其作为结构化提示机制的理论基础。


<details>
  <summary>Details</summary>
Motivation: 当前链式思维(Chain-of-Thought, CoT)提示方法能提升大语言模型对多步任务的准确率，但尚不清楚这种“思维”是否真正反映了模型的内部推理过程。

Method: 结合稀疏自动编码器和激活修补技术，提取在GSM8K数学问题下，Pythia-70M与Pythia-2.8B模型在CoT与无CoT提示下的单语义特征。对比分析用CoT推理特征替换至无CoT运行中的效果，并引入patch-curves与随机特征修补基线。

Result: 在Pythia-2.8B模型中，将少量CoT推理特征注入无CoT运行能显著提升答案对数概率，而在70M模型中无此效应，呈现清晰的规模门槛。此外，大模型在CoT下表现出更高的激活稀疏性和特征可解释性，内部推理更模块化（模型生成正确答案的置信度从1.2提升到4.3）。有用信息不仅存在于前K个patch，而是广泛分布。

Conclusion: 链式思维（CoT）提示能够在高容量的LLM中诱发更具可解释性的内部结构，证明其作为结构化提示方法的有效性和信号作用。

Abstract: Chain-of-thought (CoT) prompting boosts Large Language Models accuracy on
multi-step tasks, yet whether the generated "thoughts" reflect the true
internal reasoning process is unresolved. We present the first feature-level
causal study of CoT faithfulness. Combining sparse autoencoders with activation
patching, we extract monosemantic features from Pythia-70M and Pythia-2.8B
while they tackle GSM8K math problems under CoT and plain (noCoT) prompting.
Swapping a small set of CoT-reasoning features into a noCoT run raises answer
log-probabilities significantly in the 2.8B model, but has no reliable effect
in 70M, revealing a clear scale threshold. CoT also leads to significantly
higher activation sparsity and feature interpretability scores in the larger
model, signalling more modular internal computation. For example, the model's
confidence in generating correct answers improves from 1.2 to 4.3. We introduce
patch-curves and random-feature patching baselines, showing that useful CoT
information is not only present in the top-K patches but widely distributed.
Overall, our results indicate that CoT can induce more interpretable internal
structures in high-capacity LLMs, validating its role as a structured prompting
method.

</details>


### [34] [EH-Benchmark Ophthalmic Hallucination Benchmark and Agent-Driven Top-Down Traceable Reasoning Workflow](https://arxiv.org/abs/2507.22929)
*Xiaoyu Pan,Yang Bai,Ke Zou,Yang Zhou,Jun Zhou,Huazhu Fu,Yih-Chung Tham,Yong Liu*

Main category: cs.CL

TL;DR: 本文提出用于评测和缓解医学大模型在眼科领域幻觉现象的新基准及三阶段优化框架，实验显示有效提升了模型的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有医疗大模型在眼科诊断中表现受到幻觉现象影响，而当前基准无法有效评测和缓解这些问题。因此，亟需更精细的评测体系和有效的优化方法。

Method: 设计了EH-Benchmark，细致划分幻觉类型，并基于代理的三阶段流程（知识检索、病例推理、结果验证）对医学大模型进行评测和优化。

Result: 通过EH-Benchmark和多代理机制，实验表明幻觉现象显著得到缓解，模型的各项性能均有提升。

Conclusion: 提出的多代理三阶段框架显著减少了医学大模型在眼科领域中的幻觉现象，提高了诊断的准确性、可解释性和可靠性。

Abstract: Medical Large Language Models (MLLMs) play a crucial role in ophthalmic
diagnosis, holding significant potential to address vision-threatening
diseases. However, their accuracy is constrained by hallucinations stemming
from limited ophthalmic knowledge, insufficient visual localization and
reasoning capabilities, and a scarcity of multimodal ophthalmic data, which
collectively impede precise lesion detection and disease diagnosis.
Furthermore, existing medical benchmarks fail to effectively evaluate various
types of hallucinations or provide actionable solutions to mitigate them. To
address the above challenges, we introduce EH-Benchmark, a novel ophthalmology
benchmark designed to evaluate hallucinations in MLLMs. We categorize MLLMs'
hallucinations based on specific tasks and error types into two primary
classes: Visual Understanding and Logical Composition, each comprising multiple
subclasses. Given that MLLMs predominantly rely on language-based reasoning
rather than visual processing, we propose an agent-centric, three-phase
framework, including the Knowledge-Level Retrieval stage, the Task-Level Case
Studies stage, and the Result-Level Validation stage. Experimental results show
that our multi-agent framework significantly mitigates both types of
hallucinations, enhancing accuracy, interpretability, and reliability. Our
project is available at https://github.com/ppxy1/EH-Benchmark.

</details>


### [35] [Protecting Vulnerable Voices: Synthetic Dataset Generation for Self-Disclosure Detection](https://arxiv.org/abs/2507.22930)
*Shalini Jangra,Suparna De,Nishanth Sastry,Saeed Fadaei*

Main category: cs.CL

TL;DR: 本文提出利用大语言模型生成与真实Reddit帖子风格相似的合成PII数据集，构建了19类PII分类体系，并从可复现性、去关联性和可分辨性三个角度验证合成数据集的实用性与安全性，公开数据和代码以促进在线社交媒体PII隐私风险的研究。


<details>
  <summary>Details</summary>
Motivation: 社交平台上的用户常自曝个人敏感信息（PII），带来隐私风险，但揭示PII相关的开源标注数据集缺乏，阻碍了研究的开展。

Method: 提出并实践了一种新颖方法，利用三种大语言模型（Llama2-7B、Llama3-8B、zephyr-7b-beta）生成与真实Reddit帖子风格相似的合成PII标注数据集。同时建立了19类针对弱势群体的PII披露类别分类法。

Result: 生成并公开了带有多文本片段PII标签的合成数据集，并通过三项指标评估：模型在合成和真实数据上的训练结果可比性、合成数据无法通过通用工具如Google搜索与原始用户关联，以及合成人工难以区分。

Conclusion: 该方法实现了可以安全共享的PII合成数据集的构建，并验证其实用性和隐私保护效果，为相关领域的可复现研究提供了数据支持与工具。

Abstract: Social platforms such as Reddit have a network of communities of shared
interests, with a prevalence of posts and comments from which one can infer
users' Personal Information Identifiers (PIIs). While such self-disclosures can
lead to rewarding social interactions, they pose privacy risks and the threat
of online harms. Research into the identification and retrieval of such risky
self-disclosures of PIIs is hampered by the lack of open-source labeled
datasets. To foster reproducible research into PII-revealing text detection, we
develop a novel methodology to create synthetic equivalents of PII-revealing
data that can be safely shared. Our contributions include creating a taxonomy
of 19 PII-revealing categories for vulnerable populations and the creation and
release of a synthetic PII-labeled multi-text span dataset generated from 3
text generation Large Language Models (LLMs), Llama2-7B, Llama3-8B, and
zephyr-7b-beta, with sequential instruction prompting to resemble the original
Reddit posts. The utility of our methodology to generate this synthetic dataset
is evaluated with three metrics: First, we require reproducibility equivalence,
i.e., results from training a model on the synthetic data should be comparable
to those obtained by training the same models on the original posts. Second, we
require that the synthetic data be unlinkable to the original users, through
common mechanisms such as Google Search. Third, we wish to ensure that the
synthetic data be indistinguishable from the original, i.e., trained humans
should not be able to tell them apart. We release our dataset and code at
https://netsys.surrey.ac.uk/datasets/synthetic-self-disclosure/ to foster
reproducible research into PII privacy risks in online social media.

</details>


### [36] [Enhancing RAG Efficiency with Adaptive Context Compression](https://arxiv.org/abs/2507.22931)
*Shuyu Guo,Zhaochun Ren*

Main category: cs.CL

TL;DR: 本文提出了ACC-RAG，一种能根据问题复杂度自适应调整上下文压缩率的新架构，可在不降低准确率的基础上，大幅提升RAG推理速度。


<details>
  <summary>Details</summary>
Motivation: 传统的RAG方法虽然能增强LLMs的外部知识获取能力，但由于检索到的内容较长，导致推理成本显著增加。为了解决这个问题，通常会用上下文压缩技术，但现有方法普遍采用固定压缩率，简单问题容易被过度压缩，复杂问题又压缩不够。因此，提出了更有效的自适应压缩方法的需求。

Method: 提出了一种名为ACC-RAG（Adaptive Context Compression for RAG）的新型框架，能够根据输入复杂度动态调整压缩率。ACC-RAG结合了多粒度嵌入的分层压缩器和上下文选择器，确保保留最少且足够的信息，借鉴了人类略读和筛选信息的方式。

Result: ACC-RAG在Wikipedia和五个问答数据集上进行了评测。相比固定压缩率的方法，ACC-RAG推理速度提升了4倍以上，并且准确率保持或有提升，在效率和效果之间取得了更好的平衡。

Conclusion: ACC-RAG作为RAG的新型自适应压缩方案，能够动态平衡信息保留与推理效率，有效提升大模型推理能力。该方法未来可在需要知识增强但对推理效率敏感的应用场景中广泛应用。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs)
with external knowledge but incurs significant inference costs due to lengthy
retrieved contexts. While context compression mitigates this issue, existing
methods apply fixed compression rates, over-compressing simple queries or
under-compressing complex ones. We propose Adaptive Context Compression for RAG
(ACC-RAG), a framework that dynamically adjusts compression rates based on
input complexity, optimizing inference efficiency without sacrificing accuracy.
ACC-RAG combines a hierarchical compressor (for multi-granular embeddings) with
a context selector to retain minimal sufficient information, akin to human
skimming. Evaluated on Wikipedia and five QA datasets, ACC-RAG outperforms
fixed-rate methods and matches/unlocks over 4 times faster inference versus
standard RAG while maintaining or improving accuracy.

</details>


### [37] [FinMarBa: A Market-Informed Dataset for Financial Sentiment Classification](https://arxiv.org/abs/2507.22932)
*Baptiste Lefort,Eric Benhamou,Beatrice Guez,Jean-Jacques Ohana,Ethan Setrouk,Alban Etienne*

Main category: cs.CL

TL;DR: 作者提出一种结合情绪和市场数据的分层强化学习投资组合优化系统，不仅提升了回报率和风险指标，还具备良好扩展性和开源复现性，在2018-2024年间显著优于主流基准。


<details>
  <summary>Details</summary>
Motivation: 在金融投资组合优化中，传统方法通常仅依赖市场指标，忽略了金融新闻中的情绪信息，导致预测和决策的效果有限。作者希望能有效结合情绪信号与市场数据以提升投资组合表现。

Method: 提出一种三层级的新型层次化框架，将轻量级大语言模型（LLMs）产生的新闻情绪信号与传统市场指标结合，引入深度强化学习（DRL）进行端到端优化。具体分为基层RL代理处理混合数据，元代理聚合决策，顶层超级代理综合市场与情绪做最终决策。

Result: 在2018-2024年真实市场数据上评估，训练期为2000-2017年，该框架年化收益率达26%，Sharpe比率1.2，明显优于等权重策略和S&P 500指数。

Conclusion: 该框架实现了可扩展的跨模态信息融合，并显著提升了投资组合的稳定性和收益，框架可复现且已开源，有望为智能投资决策提供有效工具。

Abstract: This paper presents a novel hierarchical framework for portfolio
optimization, integrating lightweight Large Language Models (LLMs) with Deep
Reinforcement Learning (DRL) to combine sentiment signals from financial news
with traditional market indicators. Our three-tier architecture employs base RL
agents to process hybrid data, meta-agents to aggregate their decisions, and a
super-agent to merge decisions based on market data and sentiment analysis.
Evaluated on data from 2018 to 2024, after training on 2000-2017, the framework
achieves a 26% annualized return and a Sharpe ratio of 1.2, outperforming
equal-weighted and S&P 500 benchmarks. Key contributions include scalable
cross-modal integration, a hierarchical RL structure for enhanced stability,
and open-source reproducibility.

</details>


### [38] [Augmented Vision-Language Models: A Systematic Review](https://arxiv.org/abs/2507.22933)
*Anthony C Davis,Burhan Sadiq,Tianmin Shu,Chien-Ming Huang*

Main category: cs.CL

TL;DR: 本文综述了结合视觉-语言模型和符号信息系统的神经-符号方法及改进，提升了推理、可解释性和知识集成效率。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言模型虽然能力强大，但解释性差、难以整合新知识、计算资源消耗大、逻辑推理有限。为克服这些问题，需要新的解决方案。

Method: 通过系统性文献综述，归纳和分类现有利用外挂符号信息系统提升视觉-语言理解的方法和技术。

Result: 神经-符号系统为视觉-语言模型带来了更好的可解释性、推理能力以及更便捷的知识更新方法，无需大量重新训练。该综述归类了相关技术路线。

Conclusion: 将预训练视觉-语言模型与外部符号信息系统结合，可提升模型推理能力、记忆力及解释性，并能更高效地整合新知识。

Abstract: Recent advances in visual-language machine learning models have demonstrated
exceptional ability to use natural language and understand visual scenes by
training on large, unstructured datasets. However, this training paradigm
cannot produce interpretable explanations for its outputs, requires retraining
to integrate new information, is highly resource-intensive, and struggles with
certain forms of logical reasoning. One promising solution involves integrating
neural networks with external symbolic information systems, forming neural
symbolic systems that can enhance reasoning and memory abilities. These neural
symbolic systems provide more interpretable explanations to their outputs and
the capacity to assimilate new information without extensive retraining.
Utilizing powerful pre-trained Vision-Language Models (VLMs) as the core neural
component, augmented by external systems, offers a pragmatic approach to
realizing the benefits of neural-symbolic integration. This systematic
literature review aims to categorize techniques through which visual-language
understanding can be improved by interacting with external symbolic information
systems.

</details>


### [39] [Deep Learning Approaches for Multimodal Intent Recognition: A Survey](https://arxiv.org/abs/2507.22934)
*Jingwei Zhao,Yuhua Wen,Qifei Li,Minchi Hu,Yingying Zhou,Jingyao Xue,Junyang Wu,Yingming Gao,Zhengqi Wen,Jianhua Tao,Ya Li*

Main category: cs.CL

TL;DR: 本文综述了意图识别领域从单模态到多模态、从传统到基于 Transformer 深度学习方法的演进，归纳了数据集、应用、挑战与未来方向，对该领域发展有重要参考价值。


<details>
  <summary>Details</summary>
Motivation: 意图识别在自然语言处理中主要针对文本，但为了满足更加自然的人机交互需求，领域逐渐引入了多模态（如音频、视觉、生理信号等）和深度学习方法。随着对自然交互需求的提升，亟需系统性梳理和总结最新技术进展。

Method: 本文通过综述的方式，系统梳理了意图识别领域从单一模态到多模态的技术演进，重点介绍了基于 Transformer 的方法，并分析了相关数据集、方法、应用场景与所面临的挑战。

Result: 对意图识别相关的深度学习与多模态方法、数据集与实际应用进行了全面归纳，总结了当前成果与不足，并指出了未来研究的可能方向。

Conclusion: 多模态深度学习方法推动了意图识别的发展，当前面临的数据、融合与泛化等挑战需要进一步研究。本文为研究人员提供了全面的技术综述与未来研究建议。

Abstract: Intent recognition aims to identify users' underlying intentions,
traditionally focusing on text in natural language processing. With growing
demands for natural human-computer interaction, the field has evolved through
deep learning and multimodal approaches, incorporating data from audio, vision,
and physiological signals. Recently, the introduction of Transformer-based
models has led to notable breakthroughs in this domain. This article surveys
deep learning methods for intent recognition, covering the shift from unimodal
to multimodal techniques, relevant datasets, methodologies, applications, and
current challenges. It provides researchers with insights into the latest
developments in multimodal intent recognition (MIR) and directions for future
research.

</details>


### [40] [Trusted Knowledge Extraction for Operations and Maintenance Intelligence](https://arxiv.org/abs/2507.22935)
*Kathleen Mealey,Jonathan A. Karr Jr.,Priscila Saboia Moreira,Paul R. Brenner,Charles F. Vardeman II*

Main category: cs.CL

TL;DR: 本文评估了16种NLP工具与LLM在航空运维知识提取方面的表现，发现当前本地化工具在关键领域仍有较大局限，并开源了相关数据集及改进建议。


<details>
  <summary>Details</summary>
Motivation: 出于数据保密要求和数据整合目标及NLP针对运维等专业领域知识结构的局限性，现有方法难以有效从组织数据仓库中提取运维智能。

Method: 本文将知识图谱的构建细分为命名实体识别、共指消解、实体链接和关系抽取各个组件，对16种NLP工具与大型语言模型（LLMs）的零样本表现进行了评估，并使用美国联邦航空管理局的设备故障或维护需求数据集作为基线数据。强调所有工具均可在本地、机密环境下独立运行。

Result: 发现NLP和LLM工具在本地、受控环境下用于航空等关键行业存在显著性能不足，难以满足任务需求。此外，文章还开源了整理好的数据集，以支持后续的基线测试和评估。

Conclusion: 本文认为当前在受控、机密环境下运行的NLP和LLM工具在航空等关键行业中仍存在显著性能局限性，难以完全满足知识提取和运维智能的实际需求，并提出了相关改进建议。

Abstract: Deriving operational intelligence from organizational data repositories is a
key challenge due to the dichotomy of data confidentiality vs data integration
objectives, as well as the limitations of Natural Language Processing (NLP)
tools relative to the specific knowledge structure of domains such as
operations and maintenance. In this work, we discuss Knowledge Graph
construction and break down the Knowledge Extraction process into its Named
Entity Recognition, Coreference Resolution, Named Entity Linking, and Relation
Extraction functional components. We then evaluate sixteen NLP tools in concert
with or in comparison to the rapidly advancing capabilities of Large Language
Models (LLMs). We focus on the operational and maintenance intelligence use
case for trusted applications in the aircraft industry. A baseline dataset is
derived from a rich public domain US Federal Aviation Administration dataset
focused on equipment failures or maintenance requirements. We assess the
zero-shot performance of NLP and LLM tools that can be operated within a
controlled, confidential environment (no data is sent to third parties). Based
on our observation of significant performance limitations, we discuss the
challenges related to trusted NLP and LLM tools as well as their Technical
Readiness Level for wider use in mission-critical industries such as aviation.
We conclude with recommendations to enhance trust and provide our open-source
curated dataset to support further baseline testing and evaluation.

</details>


### [41] [Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis](https://arxiv.org/abs/2507.22936)
*Md Talha Mohsin*

Main category: cs.CL

TL;DR: 本研究系统比较了五大主流LLM在金融年报文本处理中的表现，发现GPT最优，其它模型稳定性与一致性略逊。此外，所有模型对提示写法及源材料均较为敏感。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在金融自然语言处理（FinNLP）领域表现突出，但不同主流LLMs之间的系统性比较仍然较少。考虑到LLMs对金融分析的日益重要影响，本研究意在填补此领域的研究空白。

Method: 选取GPT、Claude、Perplexity、Gemini和DeepSeek五种主流LLM，对'Magnificent Seven'科技公司年报（10-K filings）上的应用进行对比。构建金融领域专属提示语，采用三种评估方法：1）人工标注；2）自动词汇-语义指标（ROUGE、余弦相似度、Jaccard）；3）模型行为诊断（提示级方差、跨模型相似度）。

Result: GPT在连贯性、语义一致性及语境相关性方面表现最佳；Claude和Perplexity次之。Gemini和DeepSeek则表现出较大输出变异性和较少的一致性。此外，不同公司及不同时期的输出稳定性和相似性存在明显差异，说明模型对提示内容与源材料极为敏感。

Conclusion: 现有主流LLMs在金融文本处理表现不一：GPT综合表现最好，但所有模型对提示语与源材料变化较为敏感。因此，模型的选择和提示设计在金融应用中尤为重要。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
a wide variety of Financial Natural Language Processing (FinNLP) tasks.
However, systematic comparisons among widely used LLMs remain underexplored.
Given the rapid advancement and growing influence of LLMs in financial
analysis, this study conducts a thorough comparative evaluation of five leading
LLMs, GPT, Claude, Perplexity, Gemini and DeepSeek, using 10-K filings from the
'Magnificent Seven' technology companies. We create a set of domain-specific
prompts and then use three methodologies to evaluate model performance: human
annotation, automated lexical-semantic metrics (ROUGE, Cosine Similarity,
Jaccard), and model behavior diagnostics (prompt-level variance and
across-model similarity). The results show that GPT gives the most coherent,
semantically aligned, and contextually relevant answers; followed by Claude and
Perplexity. Gemini and DeepSeek, on the other hand, have more variability and
less agreement. Also, the similarity and stability of outputs change from
company to company and over time, showing that they are sensitive to how
prompts are written and what source material is used.

</details>


### [42] [CoE-Ops: Collaboration of LLM-based Experts for AIOps Question-Answering](https://arxiv.org/abs/2507.22937)
*Jinkun Zhao,Yuanshuai Wang,Xingjian Zhang,Ruibo Chen,Xingchuang Liao,Junle Wang,Lei Huang,Kui Zhang,Wenjun Wu*

Main category: cs.CL

TL;DR: 该论文提出了一种结合多专家协作与大型语言模型的AIOps框架，有效提升了任务路由与问题解决准确率，在多个任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在AIOps领域，现有模型受到领域知识限制，单一模型只能解决特定任务，而多模型组合可以带来更高效的结果。受集成学习和大模型训练领域成果启发，作者提出改进AIOps系统应采用多专家协作机制。

Method: 提出了CoE-Ops（collaboration-of-expert）多专家协作框架，整合通用大型语言模型作为任务分类器，并引入基于检索增强生成的机制，以提升高层次和低层次AIOps任务的处理能力。

Result: 实验在DevOps-EVAL数据集上展开，CoE-Ops在高层AIOps任务的分流准确率提升了72%，在DevOps问题解决任务准确率相较单一模型提升了多达8%，比大规模MoE模型在准确率上高出14%。

Conclusion: CoE-Ops框架通过多专家协作和检索增强大型语言模型，显著提升了AIOps在不同任务上的表现，证明了其在DevOps自动化问题中的优势。

Abstract: With the rapid evolution of artificial intelligence, AIOps has emerged as a
prominent paradigm in DevOps. Lots of work has been proposed to improve the
performance of different AIOps phases. However, constrained by domain-specific
knowledge, a single model can only handle the operation requirement of a
specific task,such as log parser,root cause analysis. Meanwhile, combining
multiple models can achieve more efficient results, which have been proved in
both previous ensemble learning and the recent LLM training domain. Inspired by
these works,to address the similar challenges in AIOPS, this paper first
proposes a collaboration-of-expert framework(CoE-Ops) incorporating a
general-purpose large language model task classifier. A retrieval-augmented
generation mechanism is introduced to improve the framework's capability in
handling both Question-Answering tasks with high-level(Code,build,Test,etc.)
and low-level(fault analysis,anomaly detection,etc.). Finally, the proposed
method is implemented in the AIOps domain, and extensive experiments are
conducted on the DevOps-EVAL dataset. Experimental results demonstrate that
CoE-Ops achieves a 72% improvement in routing accuracy for high-level AIOps
tasks compared to existing CoE methods, delivers up to 8% accuracy enhancement
over single AIOps models in DevOps problem resolution, and outperforms
larger-scale Mixture-of-Experts (MoE) models by up to 14% in accuracy.

</details>


### [43] [A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents](https://arxiv.org/abs/2507.22938)
*Sumit Soman,H. G. Ranjani,Sujoy Roychowdhury,Venkata Dharma Surya Narayana Sastry,Akshat Jain,Pranav Gangrade,Ayaaz Khan*

Main category: cs.CL

TL;DR: 通过VLM提取流程图的图结构表示，与文本RAG系统结合，显著提升了电信领域技术文档问答的性能，并减少了推理成本。


<details>
  <summary>Details</summary>
Motivation: 技术文档问答任务中，常有问题依赖于图像（如流程图）中的答案，而单纯的文本检索增强生成系统（RAG）难以处理这类情况。

Method: 利用视觉大型语言模型（VLM）从流程图中提取图结构表示，并将其融入文本RAG系统，实现图文联合检索。具体流程包括技术文档处理、图像类型分类、生成图结构表示，并与文本嵌入管道结合以提升检索效率。还构建了专有电信产品信息的QA数据集进行实验。

Result: 实验结果表明，基于经过微调的VLM模型获得的图结构表示与真实标注的编辑距离更低，显示了其鲁棒性。利用这些图结构进行QA时，文档检索性能良好，且在使用行业适配的文本嵌入模型时依然有效。此外，推理过程中不再需要VLM，减少了系统部署成本。

Conclusion: 该方法有效增强了技术文档中的问答系统，能够处理流程图等图像类型的问题，提升了检索性能并降低了实际部署成本。

Abstract: Question-Answering (QA) from technical documents often involves questions
whose answers are present in figures, such as flowcharts or flow diagrams.
Text-based Retrieval Augmented Generation (RAG) systems may fail to answer such
questions. We leverage graph representations of flowcharts obtained from Visual
large Language Models (VLMs) and incorporate them in a text-based RAG system to
show that this approach can enable image retrieval for QA in the telecom
domain. We present the end-to-end approach from processing technical documents,
classifying image types, building graph representations, and incorporating them
with the text embedding pipeline for efficient retrieval. We benchmark the same
on a QA dataset created based on proprietary telecom product information
documents. Results show that the graph representations obtained using a
fine-tuned VLM model have lower edit distance with respect to the ground truth,
which illustrate the robustness of these representations for flowchart images.
Further, the approach for QA using these representations gives good retrieval
performance using text-based embedding models, including a telecom-domain
adapted one. Our approach also alleviates the need for a VLM in inference,
which is an important cost benefit for deployed QA systems.

</details>


### [44] [PARROT: An Open Multilingual Radiology Reports Dataset](https://arxiv.org/abs/2507.22939)
*Bastien Le Guellec,Kokou Adambounou,Lisa C Adams,Thibault Agripnidis,Sung Soo Ahn,Radhia Ait Chalal,Tugba Akinci D Antonoli,Philippe Amouyel,Henrik Andersson,Raphael Bentegeac,Claudio Benzoni,Antonino Andrea Blandino,Felix Busch,Elif Can,Riccardo Cau,Armando Ugo Cavallo,Christelle Chavihot,Erwin Chiquete,Renato Cuocolo,Eugen Divjak,Gordana Ivanac,Barbara Dziadkowiec Macek,Armel Elogne,Salvatore Claudio Fanni,Carlos Ferrarotti,Claudia Fossataro,Federica Fossataro,Katarzyna Fulek,Michal Fulek,Pawel Gac,Martyna Gachowska,Ignacio Garcia Juarez,Marco Gatti,Natalia Gorelik,Alexia Maria Goulianou,Aghiles Hamroun,Nicolas Herinirina,Krzysztof Kraik,Dominik Krupka,Quentin Holay,Felipe Kitamura,Michail E Klontzas,Anna Kompanowska,Rafal Kompanowski,Alexandre Lefevre,Tristan Lemke,Maximilian Lindholz,Lukas Muller,Piotr Macek,Marcus Makowski,Luigi Mannacio,Aymen Meddeb,Antonio Natale,Beatrice Nguema Edzang,Adriana Ojeda,Yae Won Park,Federica Piccione,Andrea Ponsiglione,Malgorzata Poreba,Rafal Poreba,Philipp Prucker,Jean Pierre Pruvo,Rosa Alba Pugliesi,Feno Hasina Rabemanorintsoa,Vasileios Rafailidis,Katarzyna Resler,Jan Rotkegel,Luca Saba,Ezann Siebert,Arnaldo Stanzione,Ali Fuat Tekin,Liz Toapanta Yanchapaxi,Matthaios Triantafyllou,Ekaterini Tsaoulia,Evangelia Vassalou,Federica Vernuccio,Johan Wasselius,Weilang Wang,Szymon Urban,Adrian Wlodarczak,Szymon Wlodarczak,Andrzej Wysocki,Lina Xu,Tomasz Zatonski,Shuhang Zhang,Sebastian Ziegelmayer,Gregory Kuchcinski,Keno K Bressem*

Main category: cs.CL

TL;DR: 本研究构建并公开了全球最大、涵盖多语种和多模态成像的放射学报告数据集PARROT，为放射学NLP模型的开发和测试提供了重要资源，人类难以轻易区分AI生成的报告。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏大规模、多语言并且开放获取的放射学报告数据集，限制了NLP技术在放射学领域的测试与应用，尤其是在保障隐私的前提下。

Method: 邀请全球放射科医师按照其日常规范撰写虚构放射学报告，收集相关元数据（解剖部位、成像方式、临床情境、ICD-10编码、英文翻译），并开展人类与AI报告分辨试验。

Result: 最终收集了来自21个国家、13种语言、76位作者的2658份放射学报告，涵盖多种成像方式及解剖部位。在分辨试验中，参与者区分人类与AI报告的准确率为53.9%，其中放射科医师略优于其他参与者。

Conclusion: PARROT数据集是目前最大的开放式多语言放射学报告数据集，可用于开发和验证超越语种、地理和临床范围的自然语言处理（NLP）应用，并且无需担忧隐私限制。

Abstract: Rationale and Objectives: To develop and validate PARROT (Polyglottal
Annotated Radiology Reports for Open Testing), a large, multicentric,
open-access dataset of fictional radiology reports spanning multiple languages
for testing natural language processing applications in radiology. Materials
and Methods: From May to September 2024, radiologists were invited to
contribute fictional radiology reports following their standard reporting
practices. Contributors provided at least 20 reports with associated metadata
including anatomical region, imaging modality, clinical context, and for
non-English reports, English translations. All reports were assigned ICD-10
codes. A human vs. AI report differentiation study was conducted with 154
participants (radiologists, healthcare professionals, and non-healthcare
professionals) assessing whether reports were human-authored or AI-generated.
Results: The dataset comprises 2,658 radiology reports from 76 authors across
21 countries and 13 languages. Reports cover multiple imaging modalities (CT:
36.1%, MRI: 22.8%, radiography: 19.0%, ultrasound: 16.8%) and anatomical
regions, with chest (19.9%), abdomen (18.6%), head (17.3%), and pelvis (14.1%)
being most prevalent. In the differentiation study, participants achieved 53.9%
accuracy (95% CI: 50.7%-57.1%) in distinguishing between human and AI-generated
reports, with radiologists performing significantly better (56.9%, 95% CI:
53.3%-60.6%, p<0.05) than other groups. Conclusion: PARROT represents the
largest open multilingual radiology report dataset, enabling development and
validation of natural language processing applications across linguistic,
geographic, and clinical boundaries without privacy constraints.

</details>


### [45] [Trustworthy Reasoning: Evaluating and Enhancing Factual Accuracy in LLM Intermediate Thought Processes](https://arxiv.org/abs/2507.22940)
*Rui Jiao,Yue Zhang,Jinku Li*

Main category: cs.CL

TL;DR: RELIANCE框架通过事实核查、强化学习和平行可解释性显著提升了大模型推理环节的事实准确性，尤其适用于高风险领域，实验表明其可将事实稳健性最高提升近50%。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLM）在推理过程中，即使最终答案正确，其中间推理步骤仍可能包含事实错误。这一现象在医疗、法律和科研等高风险领域带来严重隐患，因为错误但自信的推理可能导致用户做出危险决策。

Method: 提出了RELIANCE框架，包括三大组件：（1）基于反事实增强数据训练的专用事实核查分类器，检测推理链条中的细微事实不一致；（2）利用分组相对策略优化（GRPO）的强化学习方法，通过多维奖励在事实性、连贯性和结构正确性之间平衡；（3）机制可解释性模块，分析事实性改进如何在推理过程中体现在模型激活中。

Result: 在十个主流模型上进行广泛评测发现，领先的模型（如Claude-3.7和GPT-o1）推理事实准确率只有约82%。RELIANCE框架能显著提升事实稳健性，提升最高可达49.90%，且在Math-500、AIME-2024、GPQA等高难基准上表现优异。同时，激活层级分析为事实性优化提供了可行的解释机制。

Conclusion: RELIANCE不仅有效提高推理事实准确率，而且为通过激活引导优化提升语言模型事实稳健性奠定了基础，有望推动未来更有效的训练方法。

Abstract: We present RELIANCE (Reasoning Evaluation with Logical Integrity and Accuracy
for Confidence Enhancement), a novel framework addressing a critical
vulnerability in Large Language Models (LLMs): the prevalence of factual
inaccuracies within intermediate reasoning steps despite correct final answers.
This phenomenon poses substantial risks in high-stakes domains including
healthcare, legal analysis, and scientific research, where erroneous yet
confidently presented reasoning can mislead users into dangerous decisions. Our
framework integrates three core components: (1) a specialized fact-checking
classifier trained on counterfactually augmented data to detect subtle factual
inconsistencies within reasoning chains; (2) a Group Relative Policy
Optimization (GRPO) reinforcement learning approach that balances factuality,
coherence, and structural correctness through multi-dimensional rewards; and
(3) a mechanistic interpretability module examining how factuality improvements
manifest in model activations during reasoning processes. Extensive evaluation
across ten state-of-the-art models reveals concerning patterns: even leading
models like Claude-3.7 and GPT-o1 demonstrate reasoning factual accuracy of
only 81.93% and 82.57% respectively. RELIANCE significantly enhances factual
robustness (up to 49.90% improvement) while maintaining or improving
performance on challenging benchmarks including Math-500, AIME-2024, and GPQA.
Furthermore, our activation-level analysis provides actionable insights into
how factual enhancements reshape reasoning trajectories within model
architectures, establishing foundations for future training methodologies that
explicitly target factual robustness through activation-guided optimization.

</details>


### [46] [SigBERT: Combining Narrative Medical Reports and Rough Path Signature Theory for Survival Risk Estimation in Oncology](https://arxiv.org/abs/2507.22941)
*Paul Minchella,Loïc Verlingue,Stéphane Chrétien,Rémi Vaucher,Guillaume Metzler*

Main category: cs.CL

TL;DR: 提出了专门处理时序电子病历文本的SigBERT框架，有效捕捉文本的时间动态信息，提升了肿瘤患者生存分析的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有生存分析方法难以有效处理复杂且具时间顺序的医学文本数据，因此需要创新方法提升基于文本的生存分析准确性。

Method: SigBERT框架首先将带有时间戳的医学报告文本转化为句子嵌入，然后使用粗路径理论中的signature特征提取时间序列动态信息，最后将这些特征输入LASSO惩罚的Cox模型进行生存分析。

Result: 在现实肿瘤学数据集（Léon Bérard Center corpus）上，SigBERT模型在独立测试集上取得了C-index 0.75（标准差0.014）的表现。

Conclusion: SigBERT能够有效处理顺序型文本电子病历中的时间动态信息，从而提升了对患者风险的估计能力。

Abstract: Electronic medical reports (EHR) contain a vast amount of information that
can be leveraged for machine learning applications in healthcare. However,
existing survival analysis methods often struggle to effectively handle the
complexity of textual data, particularly in its sequential form. Here, we
propose SigBERT, an innovative temporal survival analysis framework designed to
efficiently process a large number of clinical reports per patient. SigBERT
processes timestamped medical reports by extracting and averaging word
embeddings into sentence embeddings. To capture temporal dynamics from the time
series of sentence embedding coordinates, we apply signature extraction from
rough path theory to derive geometric features for each patient, which
significantly enhance survival model performance by capturing complex temporal
dynamics. These features are then integrated into a LASSO-penalized Cox model
to estimate patient-specific risk scores. The model was trained and evaluated
on a real-world oncology dataset from the L\'eon B\'erard Center corpus, with a
C-index score of 0.75 (sd 0.014) on the independent test cohort. SigBERT
integrates sequential medical data to enhance risk estimation, advancing
narrative-based survival analysis.

</details>


### [47] [A chart review process aided by natural language processing and multi-wave adaptive sampling to expedite validation of code-based algorithms for large database studies](https://arxiv.org/abs/2507.22943)
*Shirley V Wang,Georg Hahn,Sushama Kattinakere Sreedhara,Mufaddal Mahesri,Haritha S. Pillai,Rajendra Aldis,Joyce Lii,Sarah K. Dutcher,Rhoda Eniafe,Jamal T. Jones,Keewan Kim,Jiwei He,Hana Lee,Sengwee Toh,Rishi J Desai,Jie Yang*

Main category: cs.CL

TL;DR: 本研究提出结合NLP和自适应抽样的新流程，显著提高了健康结局算法验证的效率和精度，有望促进代码算法在数据库研究中的广泛可靠应用。


<details>
  <summary>Details</summary>
Motivation: 在利用大型索赔数据库进行分析时，基于代码的算法用于识别健康结局等关键参数，但此类算法的测量特性（如准确度）需通过人工回顾电子健康记录的手工审核建立参考标准标签，耗时且资源消耗大。因此，作者希望开发更高效的验证流程以便更广泛、灵活地进行算法特征验证。

Method: 提出了一种高效的验证流程，结合了自然语言处理（NLP）辅助人工标注以节省回顾时间，并采用多轮自适应抽样及预设准则决定何时终止调查，当性能参数达到足够精度时即可停止，避免无谓资源浪费。以肥胖症患者自伤事件的结局算法为案例开展实证验证。

Result: NLP辅助的标注流程将每个病历的回顾时间缩短了40%；多轮抽样且应用预设终止规则后，仅需回顾23%的病例，便能获得类似精度的测量特征。大大节省了人力与资源。

Conclusion: 该方法有助于更常规地对基于代码的算法进行验证，提升数据库研究发现的可靠性。

Abstract: Background: One of the ways to enhance analyses conducted with large claims
databases is by validating the measurement characteristics of code-based
algorithms used to identify health outcomes or other key study parameters of
interest. These metrics can be used in quantitative bias analyses to assess the
robustness of results for an inferential study given potential bias from
outcome misclassification. However, extensive time and resource allocation are
typically re-quired to create reference-standard labels through manual chart
review of free-text notes from linked electronic health records. Methods: We
describe an expedited process that introduces efficiency in a validation study
us-ing two distinct mechanisms: 1) use of natural language processing (NLP) to
reduce time spent by human reviewers to review each chart, and 2) a multi-wave
adaptive sampling approach with pre-defined criteria to stop the validation
study once performance characteristics are identified with sufficient
precision. We illustrate this process in a case study that validates the
performance of a claims-based outcome algorithm for intentional self-harm in
patients with obesity. Results: We empirically demonstrate that the
NLP-assisted annotation process reduced the time spent on review per chart by
40% and use of the pre-defined stopping rule with multi-wave samples would have
prevented review of 77% of patient charts with limited compromise to precision
in derived measurement characteristics. Conclusion: This approach could
facilitate more routine validation of code-based algorithms used to define key
study parameters, ultimately enhancing understanding of the reliability of
find-ings derived from database studies.

</details>


### [48] [Opacity as Authority: Arbitrariness and the Preclusion of Contestation](https://arxiv.org/abs/2507.22944)
*Naomi Omeonga wa Kayembe*

Main category: cs.CL

TL;DR: 本文将任意性由负面规范缺陷转变为结构性机制，提出可跨领域解释的理论框架，并形式化其功能，拓展至社会、法律及AI系统的分析。


<details>
  <summary>Details</summary>
Motivation: 传统上，不确定性（arbitrariness）常被视为规范缺陷或权力支配的表现，本文质疑并重新界定这一观念，试图揭示其在人类系统和互动中的基础功能结构作用。

Method: 借用索绪尔（Saussure）符号任意性理论，将“任意性”从语言领域推广至法律和社会领域。提出“动机—可确证性—可争议性”链条，剖析其中任意性如何通过“去动机化”等机制加强权威不可问责性，并结合香农（Shannon）熵理论对任意性进行形式化。

Result: 任意性被形式化为条件熵A=H(L|M)，不仅仅是社会控制的工具，也是关怀关系中的中性调节者。该理论为人类社会系统及先进人工智能系统的可解释性分析提供了新路径。

Conclusion: 任意性并非单纯的规范缺陷，而是跨越语言、法律与社会互动的功能性结构机制，对理解权力、系统运作及AI可解释性具有启发意义。

Abstract: This article redefines arbitrariness not as a normative flaw or a symptom of
domination, but as a foundational functional mechanism structuring human
systems and interactions. Diverging from critical traditions that conflate
arbitrariness with injustice, it posits arbitrariness as a semiotic trait: a
property enabling systems - linguistic, legal, or social - to operate
effectively while withholding their internal rationale. Building on Ferdinand
de Saussure's concept of l'arbitraire du signe, the analysis extends this
principle beyond language to demonstrate its cross-domain applicability,
particularly in law and social dynamics. The paper introduces the "Motivation
-> Constatability -> Contestability" chain, arguing that motivation functions
as a crucial interface rendering an act's logic vulnerable to intersubjective
contestation. When this chain is broken through mechanisms like
"immotivization" or "Conflict Lateralization" (exemplified by "the blur of the
wolf drowned in the fish"), acts produce binding effects without exposing their
rationale, thus precluding justiciability. This structural opacity, while
appearing illogical, is a deliberate design protecting authority from
accountability. Drawing on Shannon's entropy model, the paper formalizes
arbitrariness as A = H(L|M) (conditional entropy). It thereby proposes a modern
theory of arbitrariness as a neutral operator central to control as well as
care, an overlooked dimension of interpersonal relations. While primarily
developed through human social systems, this framework also illuminates a new
pathway for analyzing explainability in advanced artificial intelligence
systems.

</details>


### [49] [C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations](https://arxiv.org/abs/2507.22968)
*Chengqian Ma,Wei Tao,Yiwen Guo*

Main category: cs.CL

TL;DR: 本文提出了涵盖中英文的口语对话基准数据集和基于大模型的自动评测方法，系统考察了SDM在真实复杂语境下的表现，为该领域的发展与评估方法完善提供了数据支撑和评估工具。


<details>
  <summary>Details</summary>
Motivation: 尽管口语对话模型（SDM）能够直接对用户的语音查询生成回应，并受到广泛关注，但对其在理解和模拟人类会话实际效果的全面研究还很有限，尤其与已经有大量基准测试的文本类大语言模型（LLM）相比。鉴于语音交流具有语音歧义、上下文依赖等独特复杂特征，因此有必要专门评估SDM在真实语音对话环境下的表现。

Method: 作者提出了一个包含1079例（英文和中文）的基准数据集，并设计了基于LLM的方法对SDM进行评测，该方法能够较好地反映人工评判结果，从而系统性地探究SDM面对实际语音对话挑战时的表现。

Result: 研究中建立的数据集和评测方法能够有效支持对SDM在多种现实语言挑战（如语义和语音歧义、上下文依赖等）下的性能评估。实验显示，该评测框架能帮助科学理解SDM在面对复杂语音对话问题时的优劣。

Conclusion: 通过构建跨中英双语的基准数据集，并结合贴近人工标准的评测体系，本文为SDM的性能评估提供了有力工具，促进了相关模型理解和研发进步。

Abstract: Spoken Dialogue Models (SDMs) have recently attracted significant attention
for their ability to generate voice responses directly to users' spoken
queries. Despite their increasing popularity, there exists a gap in research
focused on comprehensively understanding their practical effectiveness in
comprehending and emulating human conversations. This is especially true
compared to text-based Large Language Models (LLMs), which benefit from
extensive benchmarking. Human voice interactions are inherently more complex
than text due to characteristics unique to spoken dialogue. Ambiguity poses one
challenge, stemming from semantic factors like polysemy, as well as
phonological aspects such as heterograph, heteronyms, and stress patterns.
Additionally, context-dependency, like omission, coreference, and multi-turn
interaction, adds further complexity to human conversational dynamics. To
illuminate the current state of SDM development and to address these
challenges, we present a benchmark dataset in this paper, which comprises 1,079
instances in English and Chinese. Accompanied by an LLM-based evaluation method
that closely aligns with human judgment, this dataset facilitates a
comprehensive exploration of the performance of SDMs in tackling these
practical challenges.

</details>


### [50] [Math Natural Language Inference: this should be easy!](https://arxiv.org/abs/2507.23063)
*Valeria de Paiva,Qiyue Gao,Hai Hu,Pavel Kovalev,Yikang Liu,Lawrence S. Moss,Zhiheng Qian*

Main category: cs.CL

TL;DR: 本文针对LLM在数学文本NLI任务上的能力进行了系统评估，发现其部分表现已接近人类水平，但整体对数学语言理解仍有限，并公开了相关数据集以促进后续研究。


<details>
  <summary>Details</summary>
Motivation: 探讨当前大型语言模型（LLM）是否能够在数学文本上执行自然语言推断（NLI）任务，即Math NLI问题。

Method: 构建了一个由真实数学文本组成的Math NLI数据集，其中假设和标签由具备高级数学和NLI领域经验的人类标注，并对比了LLM自动生成的假设数据集。同时，分析了多种LLM的表现和互相一致性。

Result: 在某些场景下，LLM的多数投票结果与人工标注数据表现相当。但LLM在理解和处理数学文本方面依然存在困难，并在一些基本推理任务上出现失败。最新的LLM模型已不易陷入仅基于假设进行推断的误区。

Conclusion: 尽管LLM在一些数学NLI场景下与人工标注接近，但总体上在理解复杂数学语言和推理方面仍有不足。本文数据集也为后续Math NLI研究提供了资源。

Abstract: We ask whether contemporary LLMs are able to perform natural language
inference (NLI) tasks on mathematical texts. We call this the Math NLI problem.
We construct a corpus of Math NLI pairs whose premises are from extant
mathematical text and whose hypotheses and gold labels were provided by people
with experience in both research-level mathematics and also in the NLI field.
We also investigate the quality of corpora using the same premises but whose
hypotheses are provided by LLMs themselves. We not only investigate the
performance but also the inter-group consistency of the diverse group of LLMs.
We have both positive and negative findings. Among our positive findings: in
some settings, using a majority vote of LLMs is approximately equivalent to
using human-labeled data in the Math NLI area. On the negative side: LLMs still
struggle with mathematical language. They occasionally fail at even basic
inferences. Current models are not as prone to hypothesis-only "inference" in
our data the way the previous generation had been. In addition to our findings,
we also provide our corpora as data to support future work on Math NLI.

</details>


### [51] [Exploring In-Context Learning for Frame-Semantic Parsing](https://arxiv.org/abs/2507.23082)
*Diego Garat,Guillermo Moncecchi,Dina Wonsever*

Main category: cs.CL

TL;DR: 作者利用自动生成的任务提示，结合FrameNet知识库，通过六种大型语言模型在无需微调的情况下完成了高质量的框架语义分析任务，取得了接近主流微调方法的效果。


<details>
  <summary>Details</summary>
Motivation: 句法语义分析（Frame Semantic Parsing, FSP）通常需要对模型进行专门的微调，而这成本较高并且不易扩展。作者希望探索大型语言模型（LLMs）能否仅通过上下文学习（ICL）和任务特定提示来完成FSP，从而跳过微调步骤。

Method: 作者提出了一种新方法，自动基于FrameNet数据库为句法识别（FI）和语义角色标注（FSRL）两个子任务生成任务专用的提示。这些提示结合了框架定义和标注示例，随后被用于引导六种不同的大型语言模型（LLMs）进行任务推理。

Result: 在与暴力事件相关的框架上进行实验，FI子任务取得了94.3%的F1分数，FSRL达到了77.4%的F1分数。模型表现具有竞争力。

Conclusion: 基于ICL和任务自适应提示的大型语言模型在无需微调的情况下即可实现高质量的框架语义分析，为领域特定的FSP提供了一种实用且有效的新方案。

Abstract: Frame Semantic Parsing (FSP) entails identifying predicates and labeling
their arguments according to Frame Semantics. This paper investigates the use
of In-Context Learning (ICL) with Large Language Models (LLMs) to perform FSP
without model fine-tuning. We propose a method that automatically generates
task-specific prompts for the Frame Identification (FI) and Frame Semantic Role
Labeling (FSRL) subtasks, relying solely on the FrameNet database. These
prompts, constructed from frame definitions and annotated examples, are used to
guide six different LLMs. Experiments are conducted on a subset of frames
related to violent events. The method achieves competitive results, with F1
scores of 94.3% for FI and 77.4% for FSRL. The findings suggest that ICL offers
a practical and effective alternative to traditional fine-tuning for
domain-specific FSP tasks.

</details>


### [52] [Context-aware Rotary Position Embedding](https://arxiv.org/abs/2507.23083)
*Ali Veisi,Delaram Fartoot,Hamidreza Amirzadeh*

Main category: cs.CL

TL;DR: 该论文提出一种上下文感知的新型位置编码CARoPE，能基于输入动态调节频率模式，有效提升Transformer模型的表达能力、泛化能力及训练速度，同时保持高效、简洁的结构，实验显示其优于主流位置编码方法，尤其在长上下文和大规模数据集上效果突出。


<details>
  <summary>Details</summary>
Motivation: Transformer结构中位置编码能够帮助模型理解序列顺序，而当前广泛使用的RoPE（旋转位置编码）虽然高效，但因所有频率模式都是固定且与输入无关，导致其在建模上下文敏感关系上受限。

Method: 提出了一种新的位置编码方法CARoPE（上下文感知旋转位置编码），该方法能够基于token嵌入动态生成针对各attention head的特定频率模式。通过对token embeddings做有限范围（bounded）的转换获得输入相关的相位偏移，将其整合进旋转机制，并保持RoPE的高效性和结构简洁性。

Result: 在FineWeb-Edu-10B数据集、基于GPT-2变体的下一个token预测任务上进行实验，CARoPE在所有情境下均优于RoPE和其他常用位置编码基线方法，取得更低的perplexity，尤其在较长上下文长度下依旧表现更好。同时，CARoPE在不降低模型稳定性的前提下，还能提升训练吞吐量。

Conclusion: CARoPE能以更高的表现力和高效性提升现有Transformer模型的位置编码策略，具有良好的可扩展性、表达能力和效率优势。

Abstract: Positional encoding is a vital component of Transformer architectures,
enabling models to incorporate sequence order into self-attention mechanisms.
Rotary Positional Embeddings (RoPE) have become a widely adopted solution due
to their compatibility with relative position encoding and computational
efficiency. However, RoPE relies on static, input-independent sinusoidal
frequency patterns, limiting its ability to model context-sensitive
relationships. In this work, we propose CARoPE (Context-Aware Rotary Positional
Embedding), a novel generalization of RoPE that dynamically generates
head-specific frequency patterns conditioned on token embeddings. This design
introduces token- and context-sensitive positional representations while
preserving RoPE efficiency and architectural simplicity. CARoPE computes
input-dependent phase shifts using a bounded transformation of token embeddings
and integrates them into the rotary mechanism across attention heads. We
evaluate CARoPE on the FineWeb-Edu-10B dataset using GPT-2 variants trained on
next-token prediction tasks. Experimental results show that CARoPE consistently
outperforms RoPE and other common positional encoding baselines, achieving
significantly lower perplexity, even at longer context lengths. Additionally,
CARoPE enables faster training throughput without sacrificing model stability.
These findings demonstrate that CARoPE offers a scalable, expressive, and
efficient upgrade to existing positional encoding strategies in Transformer
models.

</details>


### [53] [SMART-Editor: A Multi-Agent Framework for Human-Like Design Editing with Structural Integrity](https://arxiv.org/abs/2507.23095)
*Ishani Mondal,Meera Bharadwaj,Ayush Roy,Aparna Garimella,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: SMART-Editor是一套能跨结构化和非结构化领域进行整体内容编辑的新框架，通过奖励机制在推理和训练阶段不断优化，显著优于现有方法，在自动和人工评测中均表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的内容编辑模型大多只能进行局部编辑，缺乏对整体一致性的把控，且在结构化和非结构化领域表现有限。因此，作者提出了一种旨在提升全局连贯性的编辑框架。

Method: 提出SMART-Editor框架，覆盖结构化（如海报、网站）和非结构化（自然图像）内容编辑。框架包括两个关键策略：Reward-Refine（推理阶段基于奖励的精炼方法）和RewardDPO（训练阶段基于奖励对齐的偏好优化）。并引入了多领域、多级编辑的基准测试集SMARTEdit-Bench进行评价。

Result: SMART-Editor在结构化内容和自然图像编辑中相较于InstructPix2Pix和HIVE等强基线取得了更优表现。在结构化场景下，RewardDPO带来高达15%的提升，Reward-Refine在自然图像编辑上表现突出。自动评估和人工评测均证实了奖励引导规划对提升编辑一致性和视觉对齐的重要价值。

Conclusion: SMART-Editor通过奖励引导的推理与训练策略，在多领域内容编辑任务中显著提升了全局一致性和视觉效果，超越了现有方法，展示了奖励机制在通用编辑框架中的有效性。

Abstract: We present SMART-Editor, a framework for compositional layout and content
editing across structured (posters, websites) and unstructured (natural images)
domains. Unlike prior models that perform local edits, SMART-Editor preserves
global coherence through two strategies: Reward-Refine, an inference-time
rewardguided refinement method, and RewardDPO, a training-time preference
optimization approach using reward-aligned layout pairs. To evaluate model
performance, we introduce SMARTEdit-Bench, a benchmark covering multi-domain,
cascading edit scenarios. SMART-Editor outperforms strong baselines like
InstructPix2Pix and HIVE, with RewardDPO achieving up to 15% gains in
structured settings and Reward-Refine showing advantages on natural images.
Automatic and human evaluations confirm the value of reward-guided planning in
producing semantically consistent and visually aligned edits.

</details>


### [54] [RASL: Retrieval Augmented Schema Linking for Massive Database Text-to-SQL](https://arxiv.org/abs/2507.23104)
*Jeffrey Eben,Aitzaz Ahmad,Stephen Lau*

Main category: cs.CL

TL;DR: 本文提出一种新的基于组件的数据库检索架构，显著提升了大型企业数据库中文本到SQL系统的可扩展性与准确性，无需领域特定微调即可部署。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大型语言模型（LLM）的数据库自然语言接口，在扩展到企业级数据目录时面临挑战。之前的工作依赖领域特定微调，部署复杂，并且没有充分利用数据库元数据中的语义上下文。

Method: 提出了一种基于组件的检索架构，将数据库模式和元数据分解为离散的语义单元，并分别建立索引以实现有针对性的检索。该方法重视表的有效识别，并利用列级信息，确保检索到的表的数量控制在合理的上下文范围内。

Result: 实验表明，该方法能够在不同结构和元数据条件下的大型数据库中保持高召回率和高准确率，且性能优于基线方法。

Conclusion: 该方案无需专门微调，能在多样化企业环境中实现可部署的文本到SQL系统，填补了自然语言数据库接口在可扩展性方面的关键空白。

Abstract: Despite advances in large language model (LLM)-based natural language
interfaces for databases, scaling to enterprise-level data catalogs remains an
under-explored challenge. Prior works addressing this challenge rely on
domain-specific fine-tuning - complicating deployment - and fail to leverage
important semantic context contained within database metadata. To address these
limitations, we introduce a component-based retrieval architecture that
decomposes database schemas and metadata into discrete semantic units, each
separately indexed for targeted retrieval. Our approach prioritizes effective
table identification while leveraging column-level information, ensuring the
total number of retrieved tables remains within a manageable context budget.
Experiments demonstrate that our method maintains high recall and accuracy,
with our system outperforming baselines over massive databases with varying
structure and available metadata. Our solution enables practical text-to-SQL
systems deployable across diverse enterprise settings without specialized
fine-tuning, addressing a critical scalability gap in natural language database
interfaces.

</details>


### [55] [Uncovering the Fragility of Trustworthy LLMs through Chinese Textual Ambiguity](https://arxiv.org/abs/2507.23121)
*Xinwei Wu,Haojie Li,Hongyu Liu,Xinyu Ji,Ruohan Li,Yule Chen,Yigeng Zhang*

Main category: cs.CL

TL;DR: 本文系统研究了大语言模型对中文歧义文本的处理能力及其局限性，发现当前模型在识别、解释歧义上存在显著不足，提醒未来需持续增强模型对语言不确定性的理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLM）在处理歧义文本时的可信度存在隐忧，尤其是在实际应用中，语言歧义非常普遍，而相关研究不足。本论文旨在系统性分析LLM对中文歧义文本的理解能力及其行为表现。

Method: 作者构建了一个基准数据集，收集和生成了包含上下文的歧义句及其消歧对，覆盖多种可能的解释。所有数据被系统性划分为3个主类别和9个子类别，并通过实验分析了LLM面对歧义时的处理表现。

Result: 实验发现，LLM在识别和理解歧义文本方面表现出明显的脆弱性，如难以区分歧义与非歧义内容，对歧义文本过度自信地单一解释，或在尝试理解多种意思时出现“过度思考”。这些表现与人类理解方式存在本质差异。

Conclusion: 当前LLM在歧义处理上存在根本性局限，这对其在实际应用中的可信可靠性造成了严峻挑战。作者建议进一步改进模型以更好地处理语言理解中的不确定性。

Abstract: In this work, we study a critical research problem regarding the
trustworthiness of large language models (LLMs): how LLMs behave when
encountering ambiguous narrative text, with a particular focus on Chinese
textual ambiguity. We created a benchmark dataset by collecting and generating
ambiguous sentences with context and their corresponding disambiguated pairs,
representing multiple possible interpretations. These annotated examples are
systematically categorized into 3 main categories and 9 subcategories. Through
experiments, we discovered significant fragility in LLMs when handling
ambiguity, revealing behavior that differs substantially from humans.
Specifically, LLMs cannot reliably distinguish ambiguous text from unambiguous
text, show overconfidence in interpreting ambiguous text as having a single
meaning rather than multiple meanings, and exhibit overthinking when attempting
to understand the various possible meanings. Our findings highlight a
fundamental limitation in current LLMs that has significant implications for
their deployment in real-world applications where linguistic ambiguity is
common, calling for improved approaches to handle uncertainty in language
understanding. The dataset and code are publicly available at this GitHub
repository: https://github.com/ictup/LLM-Chinese-Textual-Disambiguation.

</details>


### [56] [ISO-Bench: Benchmarking Multimodal Causal Reasoning in Visual-Language Models through Procedural Plans](https://arxiv.org/abs/2507.23135)
*Ananya Sadana,Yash Kumar Lal,Jiawei Zhou*

Main category: cs.CL

TL;DR: 本文提出ISO-Bench基准以系统评测多模态模型的视觉-文本因果推理能力，发现当前模型表现远低于人类，为未来模型改进指明路径。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型在实际环境中理解和推理不同模态之间因果关系存在较大挑战。作者希望通过新的基准检测并推动相关能力提升。

Method: 作者提出了ISO-Bench基准，设计任务要求模型判断图片中的任务步骤在文本描述步骤之前还是之后，以测试模型跨视觉和文本模态的因果推理能力。采用了领先的十种视觉-语言模型进行评估，并尝试了链式推理等策略提升表现。

Result: 现有多模态模型在该基准上的表现不佳。最佳零样本F1值仅为0.57，即使结合链式推理也只能提升到0.62，远低于人类水平（0.98）。

Conclusion: 多模态模型在因果推理能力上存在明显短板，还需进一步改进。分析为提升因果理解能力提供了具体方向。

Abstract: Understanding causal relationships across modalities is a core challenge for
multimodal models operating in real-world environments. We introduce ISO-Bench,
a benchmark for evaluating whether models can infer causal dependencies between
visual observations and procedural text. Each example presents an image of a
task step and a text snippet from a plan, with the goal of deciding whether the
visual step occurs before or after the referenced text step. Evaluation results
on ten frontier vision-language models show underwhelming performance: the best
zero-shot F1 is only 0.57, and chain-of-thought reasoning yields only modest
gains (up to 0.62 F1), largely behind humans (0.98 F1). Our analysis further
highlights concrete directions for improving causal understanding in multimodal
models.

</details>


### [57] [User Feedback in Human-LLM Dialogues: A Lens to Understand Users But Noisy as a Learning Signal](https://arxiv.org/abs/2507.23158)
*Yuhan Liu,Michael J. Q. Zhang,Eunsol Choi*

Main category: cs.CL

TL;DR: 本研究系统分析了从用户-语言模型交互日志中挖掘隐性用户反馈的过程及效果。发现提取反馈的具体内容而非仅情绪倾向有助提升短小任务表现，但对复杂任务提升有限，反馈效力高度依赖用户初始提示质量。该方法有潜力也有明显边界。


<details>
  <summary>Details</summary>
Motivation: 语言模型部署后会长期与用户交互，理想情况下能根据用户反馈不断进化。直接索取用户反馈可能会打扰用户，因此该研究关注如何从用户与模型的交互日志中收集隐性反馈。

Method: 在两个用户-大语言模型交互数据集（WildChat和LMSYS）中分析隐性用户反馈。首先分析对话过程中的用户反馈现象，探究其发生的时机和原因；其次研究如何从这些隐性反馈中提取有用的学习信号以提升模型性能。

Result: 用户反馈的具体内容（如用户想要澄清某问题）比单纯的情感倾向（如不满）在提升模型回答短小、人为设计问题（MTBench）时更有效，但对复杂长问题（WildBench）作用不大。此外，用户反馈的有效性与用户最初输入提示的质量高度相关。

Conclusion: 隐性用户反馈在提升模型表现上具有一定潜力，但也存在诸多局限，尤其是在复杂任务中。此外，如何引导用户给出优质提示也是关键。

Abstract: Once language models (LMs) are deployed, they can interact with users
long-term, ideally evolving continuously based on their feedback. Asking for
direct user feedback can be disruptive; thus, we study harvesting user feedback
from user-LM interaction logs. We study implicit user feedback in two user-LM
interaction datasets (WildChat and LMSYS). First, we analyze user feedback in
the user-LLM conversation trajectory, providing insights into when and why such
feedback occurs. Second, we study harvesting learning signals from such
implicit user feedback. We find that the contents of user feedback (e.g., user
wanted clarification), not just the polarity (e.g., users were unhappy with the
previous model response), can improve model performance in short human-designed
questions (MTBench) but not on longer and more complex questions (WildBench).
We also find that the usefulness of user feedback is largely tied to the
quality of the user's initial prompt. Together, we provide an in-depth study of
implicit user feedback, showing its potential and limitations.

</details>


### [58] [LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer Integration](https://arxiv.org/abs/2507.23167)
*Jizhou Guo*

Main category: cs.CL

TL;DR: LENS是一种基于分析LLM内部状态信息的置信度学习方法，在多个任务上显著超过传统集成技巧，且无需更改模型参数。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型（LLM）在各种任务中表现出色，但不同模型在特定领域和能力上各有优势。现有的模型集成方法过于简单，往往忽略了模型在不同上下文中的信心和可靠性差异，因此，如何更有效地结合多个LLM变得十分关键。

Method: 提出了一种新方法LENS（Learning ENsemble confidence from Neural States），通过分析LLM的内部表示来学习模型置信度。为每个LLM训练一个轻量级线性置信度预测器，输入包括不同层的隐藏状态和归一化概率，无需修改LLM参数，计算开销极小。

Result: 在多项选择题与布尔问答任务上，LENS的表现大幅优于传统集成方式。实验证明，LLM的内部表示能够为置信度估计提供有效信息，从而提升集成效果。

Conclusion: LENS通过利用神经网络内部表示信息，有效提升了集成模型的置信度估计及性能。内部表示能为集成学习带来价值，适用于增强系统鲁棒性和决策效果。

Abstract: Large Language Models (LLMs) have demonstrated impressive performance across
various tasks, with different models excelling in distinct domains and specific
abilities. Effectively combining the predictions of multiple LLMs is crucial
for enhancing system robustness and performance. However, existing ensemble
methods often rely on simple techniques like voting or logits ensembling, which
overlook the varying confidence and reliability of models in different
contexts. In this work, we propose LENS (Learning ENsemble confidence from
Neural States), a novel approach that learns to estimate model confidence by
analyzing internal representations. For each LLM, we train a lightweight linear
confidence predictor that leverages layer-wise hidden states and normalized
probabilities as inputs. This allows for more nuanced weighting of model
predictions based on their context-dependent reliability. Our method does not
require modifying the model parameters and requires negligible additional
computation. Experimental results on multiple-choice and boolean
question-answering tasks demonstrate that LENS outperforms traditional ensemble
methods by a substantial margin. Our findings suggest that internal
representations provide valuable signals for determining model confidence and
can be effectively leveraged for ensemble learning.

</details>


### [59] [Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks](https://arxiv.org/abs/2507.23194)
*Jianghui Wang,Vinay Joshi,Saptarshi Majumder,Xu Chao,Bin Ding,Ziqiong Liu,Pratik Prabhanjan Brahma,Dong Li,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: 本文提出了利用大模型和反馈循环机制自动生成AMD GPU优化Triton内核的GEAK框架，正确率和速度均大幅优于现有基线，推动了GPU内核开发的自动化与高性能化。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习工作负载复杂度和多样性的增加，业界和学术界急需可扩展、硬件优化的AI自动生成GPU内核，以满足高性能和高生产力的需求。手动优化困难且耗时，推动了AI驱动的GPU代码生成成为研究和应用的热点。

Method: 提出GEAK框架，结合前沿大模型和Reflexion式推理反馈机制，在推理时动态扩展计算资源，专门生成适配AMD GPU（包括MI300X和MI250）的Triton代码。同时建立Triton GPU内核评测套件，系统性评估GEAK输出的效果。

Result: GEAK在两个基准测试中，生成GPU内核的正确率高达63%，在执行速度上相较直接LLM提示和Reflexion生成流程有最高2.59倍的提速。

Conclusion: GEAK框架通过结合大模型与推理型反馈迭代机制，实现了高效能、自动化的Triton GPU内核生成，显著优于现有生成方法，有望推动多样化硬件平台的普及并降低高效GPU编程门槛。

Abstract: The demand for AI-generated GPU kernels is rapidly growing, influenced by the
need for scalable, hardware-optimized solutions in both industry and academia.
As deep learning workloads grow in complexity and diversity, it is imperative
to automate low-level kernel development to meet performance and productivity
demands. Major cloud providers, semiconductor companies, and research
institutions are now investing heavily in AI-driven code generation for GPUs,
aiming to reduce manual optimization efforts while achieving near-expert
performance on hardware like AMD MI300X. The Triton language, a Python-based
DSL for GPU programming, has emerged as a popular target for such AI-generated
kernels due to its balance of performance and ease-of-coding. In this work, we
present an evaluation suite for Triton-based GPU kernels and GEAK (Generating
Efficient AI-centric GPU Kernels)-a framework that leverages cutting-edge LLMs
to generate performant Triton code specifically for AMD GPUs, including the AMD
MI300X and MI250. GEAK leverages inference-time compute scaling to produce
Triton-based GPU kernels using a reasoning loop adapted from Reflexion-style
feedback mechanisms. On two evaluation benchmarks, GEAK significantly
outperformed the baselines of directly prompting frontier LLMs as well as
Reflexion-based generation pipelines by achieving correctness up to $63$% and
execution speed up of up to $2.59$X. These results highlight the promise of
GEAK-like agentic code generation for accelerating the adoption of diverse
hardware platforms and democratizing access to expert-level kernel performance.

</details>


### [60] [Failures Are the Stepping Stones to Success: Enhancing Few-Shot In-Context Learning by Leveraging Negative Samples](https://arxiv.org/abs/2507.23211)
*Yunhao Liang,Ruixuan Ying,Takuya Taniguchi,Zhe Cui*

Main category: cs.CL

TL;DR: 文章提出一种利用负样本辅助正样本选择的新方法，显著提升了few-shot ICL性能，实验结果验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 以往ICL示例选择侧重于使用正样本，忽略了负样本的信息，导致系统性能受限。作者希望借助负样本的信息改进正样本的选择，提升ICL性能。

Method: 首先根据Zero-Shot-CoT构建正、负样本库；推理时基于语义相似度从正负样本库各自选择与查询最相似的样例。之后再以负样本为参照，从正样本库中进一步检索与这些负样本相似的正样本，将这些与初步选取的正样本拼接后，作为ICL示范输入给大语言模型。

Result: 实验证明，该方法优于只依赖相似正样本的方法，说明负样本中的附加信息有助于通过改进正样本选取提升ICL性能。

Conclusion: 在ICL示例选择中加入负样本信息，有助于更优地选取正样本示范，从而提升大语言模型的few-shot ICL能力。

Abstract: Large Language Models exhibit powerful few-shot in-context learning (ICL)
capabilities, but the performance is highly sensitive to provided examples.
  Recent research has focused on retrieving corresponding examples for each
input query, not only enhancing the efficiency and scalability of the learning
process but also mitigating inherent biases in manual example selection.
  However, these studies have primarily emphasized leveraging Positive samples
while overlooking the additional information within Negative samples for
contextual learning.
  We propose a novel method that utilizes Negative samples to better select
Positive sample examples, thereby enhancing the performance of few-shot ICL.
Initially, we construct Positive and Negative sample corpora based on
Zero-Shot-Cot. Then, during inference, we employ a semantic similarity-based
approach to select the most similar examples from both the Positive and
Negative corpora for a given query. Subsequently, we further retrieve Positive
examples from the Positive sample corpus based on semantic similarity to the
Negative examples, then concatenating them with the previously selected
Positive examples to serve as ICL demonstrations. Experimental results
demonstrate that our approach surpasses methods solely relying on the most
similar positive examples for context, validating that the additional
information in negative samples aids in enhancing ICL performance through
improved Positive sample selection.

</details>


### [61] [Model Directions, Not Words: Mechanistic Topic Models Using Sparse Autoencoders](https://arxiv.org/abs/2507.23220)
*Carolina Zheng,Nicolas Beltran-Velez,Sweta Karlekar,Claudia Shi,Achille Nazaret,Asif Mallik,Amir Feder,David M. Blei*

Main category: cs.CL

TL;DR: MTMs 利用稀疏自编码器学习的特征定义话题，相比以往模型能更好捕捉复杂主题，表现优异，还支持基于话题的文本生成调控。


<details>
  <summary>Details</summary>
Motivation: 传统的话题模型虽然能揭示文本集合中的潜在主题，但由于只依赖词袋模型，难以捕捉语义抽象特征。目前的一些神经网络变体虽有更丰富表示，但话题表达仍局限于单纯的词汇列表，难以表述复杂主题。

Method: 提出了机械化话题模型（MTMs），利用稀疏自编码器（SAE）学习出的可解释特征来定义话题，从而在更富语义的空间中表述主题。同时，MTMs 首次支持基于话题的向量调控文本生成。为了公平评估 MTM 与传统词列表方式的差异，提出了一种基于大型语言模型（LLM）的配对比较评价框架“topic judge”。

Result: 在五个数据集上，MTMs 在一致性指标上可与传统方法匹敌或超越，被“topic judge”优选，并支持对 LLM 输出的有效话题调控。

Conclusion: MTMs 能在更高语义层次上揭示文本主题，具备可控文本生成能力，并在主观和客观评价中都表现出色。

Abstract: Traditional topic models are effective at uncovering latent themes in large
text collections. However, due to their reliance on bag-of-words
representations, they struggle to capture semantically abstract features. While
some neural variants use richer representations, they are similarly constrained
by expressing topics as word lists, which limits their ability to articulate
complex topics. We introduce Mechanistic Topic Models (MTMs), a class of topic
models that operate on interpretable features learned by sparse autoencoders
(SAEs). By defining topics over this semantically rich space, MTMs can reveal
deeper conceptual themes with expressive feature descriptions. Moreover,
uniquely among topic models, MTMs enable controllable text generation using
topic-based steering vectors. To properly evaluate MTM topics against
word-list-based approaches, we propose \textit{topic judge}, an LLM-based
pairwise comparison evaluation framework. Across five datasets, MTMs match or
exceed traditional and neural baselines on coherence metrics, are consistently
preferred by topic judge, and enable effective steering of LLM outputs.

</details>


### [62] [Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs](https://arxiv.org/abs/2507.23227)
*Sophie Kearney,Shu Yang,Zixuan Wen,Bojian Hou,Duy Duong-Tran,Tianlong Chen,Jason Moore,Marylyn Ritchie,Li Shen*

Main category: cs.CL

TL;DR: TAP-GPT首次将多模态表格专用LLM应用于阿尔茨海默病诊断，利用少量样本和结构化生物标志物数据，通过表格提示与高效微调，优于现有LLM和表格模型，推进了生物医学信息学领域的智能诊断模式。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）是一种复杂的神经退行性疾病，早期且准确的诊断需要分析多种异质生物标志物（如神经影像、遗传风险因子、认知测试和脑脊液蛋白），这些数据通常以表格形式存在。然而，如何高效利用有限样本的表格生物医学数据进行准确预测仍是挑战。

Method: 本文提出了TAP-GPT（Tabular Alzheimer's Prediction GPT）框架，将面向商业智能的多模态表格专用大模型TableGPT2，适配到AD的临床二分类（AD或认知正常）任务。方法包括使用结构化生物医学数据构造few-shot表格提示，结合qLoRA参数高效微调技术，针对小样本及结构化生物标记物数据进行有监督训练。

Result: TAP-GPT充分发挥了TableGPT2对表格的理解能力与大模型先验知识，实验结果表明其诊断性能优于其他通用型LLM以及面向表格预测任务的Tabular Foundation Model（TFM）。

Conclusion: 本文首次将大语言模型应用于表格生物标记物数据的AD预测任务，效果显著，展示了LLM在生物医学信息学领域的广阔应用前景。

Abstract: Early and accurate diagnosis of Alzheimer's disease (AD), a complex
neurodegenerative disorder, requires analysis of heterogeneous biomarkers
(e.g., neuroimaging, genetic risk factors, cognitive tests, and cerebrospinal
fluid proteins) typically represented in a tabular format. With flexible
few-shot reasoning, multimodal integration, and natural-language-based
interpretability, large language models (LLMs) offer unprecedented
opportunities for prediction with structured biomedical data. We propose a
novel framework called TAP-GPT, Tabular Alzheimer's Prediction GPT, that adapts
TableGPT2, a multimodal tabular-specialized LLM originally developed for
business intelligence tasks, for AD diagnosis using structured biomarker data
with small sample sizes. Our approach constructs few-shot tabular prompts using
in-context learning examples from structured biomedical data and finetunes
TableGPT2 using the parameter-efficient qLoRA adaption for a clinical binary
classification task of AD or cognitively normal (CN). The TAP-GPT framework
harnesses the powerful tabular understanding ability of TableGPT2 and the
encoded prior knowledge of LLMs to outperform more advanced general-purpose
LLMs and a tabular foundation model (TFM) developed for prediction tasks. To
our knowledge, this is the first application of LLMs to the prediction task
using tabular biomarker data, paving the way for future LLM-driven multi-agent
frameworks in biomedical informatics.

</details>


### [63] [P-ReMIS: Pragmatic Reasoning in Mental Health and a Social Implication](https://arxiv.org/abs/2507.23247)
*Sneha Oram,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 本文提出了P-ReMe数据集，并针对心理健康领域中的含义推理和前提假设任务，系统评估了多种主流LLMs，发现Mistral与Qwen推理能力较强，Claude-3.5-haiku在应对心理健康污名化方面最为负责。


<details>
  <summary>Details</summary>
Motivation: 虽然心理健康领域的个性化聊天机器人和可解释性研究迅速发展，但对推理层面的解释性和对话话语结构的研究不足，尤其是在隐含意义和假定前提方面。为此，作者希望探究大语言模型在这些语用现象上的推理能力，并提升相关聊天机器人的解释与交互质量。

Method: 提出了P-ReMe数据集，重新定义了心理健康领域的含义推理和预设现象，并针对这两类现象设计了任务，衡量多种大语言模型（如Llama3.1、Mistral、MentaLLaMa、Qwen）的表现；同时引入StiPRompts，评估现有主流LLMs对心理健康污名化问题的处理能力。

Result: Mistral与Qwen对心理健康领域的含义和预设推理能力表现优异；在对心理健康污名化的应对上，Claude-3.5-haiku优于GPT-4o mini和Deepseek-chat等其他模型。

Conclusion: Mistral和Qwen在心理健康领域展现了相当好的推理能力，而Claude-3.5-haiku在应对心理健康污名化方面表现得最为负责任。

Abstract: There has been an increase in recent advancements in the explainability and
development of personalized chatbots for mental health. However, the reasoning
aspects for explainability and dialogue discourse have not been explored
previously for mental health. Hence, we are investigating the pragmatic
reasoning capability of large language models (LLMs) in this domain. We
introduce P-ReMe dataset, and propose a modified definition for the pragmatic
phenomena of implicature (implied meaning) and presupposition (implicit
assumption) in mental health. Following the definition, we formulate two tasks
in implicature and one task in presupposition. To benchmark the dataset and the
presented tasks, we consider four models - Llama3.1, Mistral, MentaLLaMa, and
Qwen. The results of the experiments suggest that Mistral and Qwen show
substantial reasoning capabilities in the domain. In addition, we also propose
StiPRompts to study the stigma around mental health with the state-of-the-art
LLMs, GPT-4o mini, Deepseek-chat, and Claude-3.5-haiku. Our evaluated findings
show that Claude-3.5-haiku deals with the stigma more responsibly compared to
the other two LLMs.

</details>


### [64] [Evaluating LLMs' Multilingual Capabilities for Bengali: Benchmark Creation and Performance Analysis](https://arxiv.org/abs/2507.23248)
*Shimanto Bhowmik,Tawsif Tashwar Dipto,Md Sazzad Islam,Sheryl Hsu,Tahsin Reasat*

Main category: cs.CL

TL;DR: 该论文分析了孟加拉语NLP遇到的难题，比较了不同大语言模型表现，指出分词效率和模型准确率的关系，并强调标准评估体系及高质量数据集对多语种NLP进步的重要性。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语在自然语言处理（NLP）领域被严重低估，因其独特的语言结构以及缺乏标准化评估基准，孟加拉语NLP 容易受挑战。本研究旨在系统调查阻碍孟加拉语 NLP 表现的主要挑战。

Method: 评估了10个最新开源大语言模型（LLMs）在8个翻译数据集上的表现，并进行综合性错误分析以识别主要失效模式。特别关注不同模型架构以及分词效率影响。

Result: 发现孟加拉语相较于英语始终存在性能差距，尤其是规模较小或特定模型（如Mistral）。部分架构（如DeepSeek）在多语种条件下表现更稳健。分词效率与LLM准确率呈负相关，过度分词会导致模型表现下降。

Conclusion: 目前大模型在处理孟加拉语时存在明显短板，需要提升数据集质量与多语种适配的评估方法。这些发现促进了对被低估语言NLP研究的进一步加强，有助于推动全球范围内高级语言技术的普及。

Abstract: Bengali is an underrepresented language in NLP research. However, it remains
a challenge due to its unique linguistic structure and computational
constraints. In this work, we systematically investigate the challenges that
hinder Bengali NLP performance by focusing on the absence of standardized
evaluation benchmarks. We then evaluated 10 recent open source Large Language
Models (LLMs) in 8 of the translated datasets and performed a comprehensive
error analysis to pinpoint their primary failure modes. Our findings reveal
consistent performance gaps for Bengali compared to English, particularly for
smaller models and specific model families like Mistral. We also identified
promising robustness in certain architectures, such as DeepSeek, that maintain
more stable performance across languages. Our analysis reveals an inverse
relationship between tokenization efficiency and LLM accuracy where models tend
to perform worse when inputs are excessively tokenized, whereas more efficient
\& concise tokenization results in improved performance. These findings
highlight critical areas where current models fall short and underscore the
need for improved dataset quality and evaluation methodologies tailored to
multilingual contexts. This work will catalyze further research on NLP for
underrepresented languages, helping to democratize access to advanced language
technologies worldwide. The code and dataset used in this research is publicly
available at https://github.com/BengaliAI/bn-llm-benchmark.

</details>


### [65] [Unveiling Super Experts in Mixture-of-Experts Large Language Models](https://arxiv.org/abs/2507.23279)
*Zunhai Su,Qingyuan Li,Hao Zhang,YuLei Qian,Yuchen Xie,Kehong Yuan*

Main category: cs.CL

TL;DR: 提出并深入分析了Super Experts（SEs）这一对MoE大模型表现至关重要的专家；SEs虽稀少但决定推理和注意力机制如剪枝则模型不可用，需对其特殊性给予关注。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE大模型经常仅凭经验标准来筛选重要专家，缺乏对专家异质性重要性的深入研究。作者期望理解和发现模型中对推理机制至关重要的一类专家——超级专家（SEs），探索它们在MoE LLMs中的作用及特性。

Method: 本文首次从模型正向推理机制入手，利用专家级别的激活分布分析和剪枝实验，系统性梳理和揭示Super Experts（超级专家，SEs）的存在及其关键作用。通过对多个开源MoE LLMs的专家结果进行分布分析，对专家进行逐步剪枝，评估其对多任务表现（尤其是数学推理）的影响，再结合解码层hidden states的活动模式分析SEs机制。

Result: 研究发现SEs在模型中数量稀少，但作用极为重要。SEs输出存在罕见的极端激活异常，这导致解码层hidden states异常强烈激活。即使剪去少数SEs也会令模型性能（如Qwen3-30B-A3B）严重下降，出现输出重复且无信息的问题。SEs在各类任务上都大幅影响模型表现，尤其是数学推理。而剪除SEs还会显著破坏MoE LLM中的attention sink结构，影响注意力分布。SE分布具有模型特异性，不受训练后处理影响。

Conclusion: MoE LLMs中存在着极少数但至关重要的超级专家（SEs），它们决定了模型推理与注意力机制的有效性。以往以压缩为目的的专家剪枝若未识别保护SEs，将带来灾难性损失。未来MoE高效部署必须重视SEs特征与分布，对专家重要性设计有针对性的评估与压缩方案。

Abstract: Sparsely activated Mixture-of-Experts (MoE) models have shown promise in
enhancing the learning capacity of large language models (LLMs). Leveraging the
intrinsic importance differences among experts, recent research has explored
expert-level compression techniques to improve the efficiency of MoE LLMs.
However, existing approaches often rely on empirical criteria to identify
critical experts, lacking a deeper exploration and understanding of the
heterogeneous importance of experts. In this study, we present the first
discovery and investigation of a distinct subset of experts that play a crucial
role in the underlying mechanisms during the model's forward inference. These
experts are prevalent in open-source MoE LLMs, and despite their limited
number, pruning them leads to a significant decline in model performance (e.g.,
pruning three causes Qwen3-30B-A3B to produce repetitive and uninformative
outputs). We refer to these experts as Super Experts (SEs). Our comprehensive
analysis provides progressively deeper insights into SEs. (i) SEs are
characterized by rare but extreme activation outliers in the output of the
down_proj, which give rise to massive activations in the hidden states between
decoder layers. Moreover, the distribution of SEs remains model-specific and is
unaffected by post-training processes. (ii) By pruning SEs, we assess their
significance across a variety of tasks, revealing their considerable impact on
the model's overall performance, particularly in mathematical reasoning. (iii)
We further enhance our understanding of the influence of SEs compression. Our
findings confirm that MoE LLMs rely on SEs to induce attention sinks, which are
crucial for the distribution of attention scores but are significantly
disrupted by SE pruning. The code is available at
https://github.com/ZunhaiSu/Super-Experts-Profilling.

</details>


### [66] [What's Taboo for You? - An Empirical Evaluation of LLMs Behavior Toward Sensitive Content](https://arxiv.org/abs/2507.23319)
*Alfio Ferrara,Sergio Picascia,Laura Pinnavaia,Vojimir Ranitovic,Elisabetta Rocchetti,Alice Tuveri*

Main category: cs.CL

TL;DR: 该论文发现LLM（如GPT-4o-mini）即使未被显式指示，也会在处理敏感内容时自动净化语言并有效降低敏感度，在敏感性分类任务上表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 先前的研究主要关注通过显式训练使大模型进行内容过滤，但很少探讨大模型在没有指令下是否会自动调整敏感内容。

Method: 实证分析GPT-4o-mini在复述敏感内容时的隐式内容调节行为，并评估敏感性转变程度。同时，评估大模型在零样本条件下对敏感句子的分类能力，并与传统方法进行对比。

Result: 实验结果表明，GPT-4o-mini在处理敏感内容时会系统性地进行隐式调节，显著减少贬低性和禁忌性用语。同时，在句子敏感性分类任务中，其零样本能力优于传统方法。

Conclusion: LLM（如GPT-4o-mini）即使无明确指令，也具备隐式净化和适度内容审核能力，并能较好区分敏感内容级别。

Abstract: Proprietary Large Language Models (LLMs) have shown tendencies toward
politeness, formality, and implicit content moderation. While previous research
has primarily focused on explicitly training models to moderate and detoxify
sensitive content, there has been limited exploration of whether LLMs
implicitly sanitize language without explicit instructions. This study
empirically analyzes the implicit moderation behavior of GPT-4o-mini when
paraphrasing sensitive content and evaluates the extent of sensitivity shifts.
Our experiments indicate that GPT-4o-mini systematically moderates content
toward less sensitive classes, with substantial reductions in derogatory and
taboo language. Also, we evaluate the zero-shot capabilities of LLMs in
classifying sentence sensitivity, comparing their performances against
traditional methods.

</details>


### [67] [MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation](https://arxiv.org/abs/2507.23334)
*Daeyong Kwon,SeungHeon Doh,Juhan Nam*

Main category: cs.CL

TL;DR: 本文提出MusT-RAG框架，通过结合专用的音乐向量数据库MusWikiDB和RAG技术，极大提升了大语言模型在音乐领域问答任务上的适应性和表现，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLM）在不同领域表现出色，但在音乐相关任务上的效果有限，主要由于其训练数据中与音乐相关的知识较少。

Method: 提出了MusT-RAG框架，即基于检索增强生成（RAG）的方法，将外部音乐领域相关知识引入LLM，并包括自建的音乐专属向量数据库MusWikiDB，同时在推理和微调时利用上下文信息以实现音乐任务适配。

Result: MusT-RAG在音乐领域适应性显著优于传统微调方法，在同域和跨域的音乐问答基准测试上都有持续提升。同时，自建MusWikiDB数据库相比通用维基百科语料表现更好，并且效率更高。

Conclusion: MusT-RAG框架能显著提升LLM在音乐领域问答任务的能力，且配合MusWikiDB数据库具有更强的效果和效率，是音乐领域LLM应用的有效方案。

Abstract: Recent advancements in Large language models (LLMs) have demonstrated
remarkable capabilities across diverse domains. While they exhibit strong
zero-shot performance on various tasks, LLMs' effectiveness in music-related
applications remains limited due to the relatively small proportion of
music-specific knowledge in their training data. To address this limitation, we
propose MusT-RAG, a comprehensive framework based on Retrieval Augmented
Generation (RAG) to adapt general-purpose LLMs for text-only music question
answering (MQA) tasks. RAG is a technique that provides external knowledge to
LLMs by retrieving relevant context information when generating answers to
questions. To optimize RAG for the music domain, we (1) propose MusWikiDB, a
music-specialized vector database for the retrieval stage, and (2) utilizes
context information during both inference and fine-tuning processes to
effectively transform general-purpose LLMs into music-specific models. Our
experiment demonstrates that MusT-RAG significantly outperforms traditional
fine-tuning approaches in enhancing LLMs' music domain adaptation capabilities,
showing consistent improvements across both in-domain and out-of-domain MQA
benchmarks. Additionally, our MusWikiDB proves substantially more effective
than general Wikipedia corpora, delivering superior performance and
computational efficiency.

</details>


### [68] [Text-to-SQL Task-oriented Dialogue Ontology Construction](https://arxiv.org/abs/2507.23358)
*Renato Vukovic,Carel van Niekerk,Michael Heck,Benjamin Ruppik,Hsien-Chin Lin,Shutong Feng,Nurul Lubis,Milica Gasic*

Main category: cs.CL

TL;DR: 提出TeQoDO方法，实现LLM无监督自动构建对话本体，兼具可扩展性和竞争力，显著提升了LLM的可解释性和实际应用前景。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）作为通用知识源使用广泛，但依赖参数化知识，导致可解释性和可信度有限。在面向任务的对话系统（TOD）中，通常通过外部、基于本体的数据库实现可解释性和可控性，但本体构建又需要人工标注或有监督训练。

Method: 提出了一种名为TeQoDO的新方法，让LLM结合提示中的对话理论和自身SQL编程能力，无监督地从零自动构建TOD本体，无需人工标签。

Result: TeQoDO在构建本体的效果上优于迁移学习方法，生成的本体在下游对话状态跟踪任务中有竞争力。消融实验也验证了对话理论的关键作用。此外，该方法可扩展到更大规模的本体构建（如Wikipedia和ArXiv数据集）。

Conclusion: TeQoDO方法展示了LLM可自发、无监督地构建可扩展的对话本体，有助于提高LLM的可解释性，推动本体方法在更广泛领域的应用。

Abstract: Large language models (LLMs) are widely used as general-purpose knowledge
sources, but they rely on parametric knowledge, limiting explainability and
trustworthiness. In task-oriented dialogue (TOD) systems, this separation is
explicit, using an external database structured by an explicit ontology to
ensure explainability and controllability. However, building such ontologies
requires manual labels or supervised training. We introduce TeQoDO: a
Text-to-SQL task-oriented Dialogue Ontology construction method. Here, an LLM
autonomously builds a TOD ontology from scratch without supervision using its
inherent SQL programming capabilities combined with dialogue theory provided in
the prompt. We show that TeQoDO outperforms transfer learning approaches, and
its constructed ontology is competitive on a downstream dialogue state tracking
task. Ablation studies demonstrate the key role of dialogue theory. TeQoDO also
scales to allow construction of much larger ontologies, which we investigate on
a Wikipedia and ArXiv dataset. We view this as a step towards broader
application of ontologies to increase LLM explainability.

</details>


### [69] [MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models](https://arxiv.org/abs/2507.23382)
*Yiyan Ji,Haoran Chen,Qiguang Chen,Chengyue Wu,Libo Qin,Wanxiang Che*

Main category: cs.CL

TL;DR: 作者提出了MPCC基准系统，用于评估多模态大模型在复杂真实约束下的规划能力。实验表明，不论开源还是闭源模型，在面对多种约束（预算、时间、空间等）时表现都很差，传统多模态提示也无法应对多限制条件。该工作为今后多模态受限推理研究提供了方向和标准。


<details>
  <summary>Details</summary>
Motivation: 当前多模态规划能力的评估存在两个主要挑战：一是无法直接评价真实世界中的多模态规划能力；二是现有基准缺乏针对多模态之间限制条件的设计。

Method: 提出了一个新的评测基准——MPCC（Multimodal Planning with Complex Constraints），系统性地评估多模态大模型（MLLMs）在规划中处理多模态复杂限制条件的能力，涵盖航班、日历和会议规划等三类真实世界任务，并引入预算、时间和空间等多种复杂约束，分级难度。

Result: 实验覆盖了13个先进的MLLM，结果显示：闭源模型的可行性规划仅达21.3%，开源模型更低，平均不超过11%。模型对约束复杂度极为敏感，传统的多模态提示策略在多限制场景下失效。

Conclusion: MPCC正式定义了多模态规划中的约束条件，提出了严谨的评测体系，并指出当前多模态大模型在受限推理方面存在显著不足，需要进一步研究。

Abstract: Multimodal planning capabilities refer to the ability to predict, reason, and
design steps for task execution with multimodal context, which is essential for
complex reasoning and decision-making across multiple steps. However, current
benchmarks face two key challenges: (1) they cannot directly assess multimodal
real-world planning capabilities, and (2) they lack constraints or implicit
constraints across modalities. To address these issues, we introduce Multimodal
Planning with Complex Constraints (MPCC), the first benchmark to systematically
evaluate MLLMs' ability to handle multimodal constraints in planning. To
address the first challenge, MPCC focuses on three real-world tasks: Flight
Planning, Calendar Planning, and Meeting Planning. To solve the second
challenge, we introduce complex constraints (e.g. budget, temporal, and
spatial) in these tasks, with graded difficulty levels (EASY, MEDIUM, HARD) to
separate constraint complexity from search space expansion. Experiments on 13
advanced MLLMs reveal significant challenges: closed-source models achieve only
21.3% feasible plans, while open-source models average below 11%. Additionally,
we observe that MLLMs are highly sensitive to constraint complexity and that
traditional multimodal prompting strategies fail in multi-constraint scenarios.
Our work formalizes multimodal constraints in planning, provides a rigorous
evaluation framework, and highlights the need for advancements in
constraint-aware reasoning for real-world MLLM applications.

</details>


### [70] [Causal2Vec: Improving Decoder-only LLMs as Versatile Embedding Models](https://arxiv.org/abs/2507.23386)
*Ailiang Lin,Zhuoyun Li,Kotaro Funakoshi*

Main category: cs.CL

TL;DR: Causal2Vec方法通过在LLM输入前加Contextual token，结合最终状态池化，不改变解码器-only架构或增加计算量的前提下，大幅提升嵌入效果和推理效率，在公开数据集（MTEB）中表现领先。


<details>
  <summary>Details</summary>
Motivation: 目前解码器-only的大型语言模型（LLM）在文本嵌入任务中表现出色，但主流方式要么去除因果注意力掩码（降低模型预训练时获取的语义信息利用），要么引入额外的输入文本（增加计算开销）。需要一种能够提升嵌入性能、又不显著增加计算量或改变原有架构的方法。

Method: 提出Causal2Vec方法：采用轻量BERT风格模型先将输入文编码为单个Contextual token，并将其添加到LLM输入序列前，使每个token能在不看未来token的情况下获得上下文信息；最终采用Contextual和EOS token的隐藏状态串联作为文本嵌入结果。

Result: Causal2Vec在MTEB文本嵌入基准中取得了业界领先的性能（在仅用公开检索数据集训练的模型中），同时与最佳方法相比，序列长度减少最高达85%，推理时间减少最高达82%。

Conclusion: Causal2Vec无需更改原架构或显著增加计算开销，就显著提升了解码器-only LLM的文本嵌入能力，是一种高效、通用的嵌入模型方案。

Abstract: Decoder-only large language models (LLMs) are increasingly used to build
embedding models that effectively encode the semantic information of natural
language texts into dense vector representations for various embedding tasks.
However, many existing methods primarily focus on removing the causal attention
mask in LLMs to enable bidirectional attention, potentially undermining the
model's ability to extract semantic information acquired during pretraining.
Additionally, leading unidirectional approaches often rely on extra input text
to overcome the inherent limitations of causal attention, inevitably increasing
computational costs. In this work, we propose Causal2Vec, a general-purpose
embedding model tailored to enhance the performance of decoder-only LLMs
without altering their original architectures or introducing significant
computational overhead. Specifically, we first employ a lightweight BERT-style
model to pre-encode the input text into a single Contextual token, which is
then prepended to the LLM's input sequence, allowing each token to capture
contextualized information even without attending to future tokens.
Furthermore, to mitigate the recency bias introduced by last-token pooling and
help LLMs better leverage the semantic information encoded in the Contextual
token, we concatenate the last hidden states of Contextual and EOS tokens as
the final text embedding. In practice, Causal2Vec achieves state-of-the-art
performance on the Massive Text Embeddings Benchmark (MTEB) among models
trained solely on publicly available retrieval datasets, while reducing the
required sequence length by up to 85% and inference time by up to 82% compared
to best-performing methods.

</details>


### [71] [Beyond the Cloud: Assessing the Benefits and Drawbacks of Local LLM Deployment for Translators](https://arxiv.org/abs/2507.23399)
*Peter Sandrini*

Main category: cs.CL

TL;DR: 本研究评估了三款开源大语言模型在本地CPU上的应用表现，结果显示其不仅具有实际使用价值，还在隐私和自主性方面优于云端商业AI，对推动AI技术普及有积极意义。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）迅猛发展，为翻译领域带来了机遇和挑战。由于云端商业AI聊天机器人存在数据隐私、安全和公平访问等问题，迫切需要探索其他本地化部署模型的可行性。

Method: 通过在CPU平台上本地部署三种开源语言模型，并与线上商业聊天机器人进行对比，侧重评估这些模型的功能性表现，不涉及人机翻译质量的直接比较。

Result: 本地部署开源语言模型虽有一定挑战，但提升了数据控制、隐私保护，并减少了对云服务的依赖，带来一系列显著优势。

Conclusion: 本研究证明本地可部署、免费的开源大语言模型在功能表现和实际应用层面具有可行性，能够为推动AI技术民主化及满足个人译者和小型企业用户需求提供有力支持。

Abstract: The rapid proliferation of Large Language Models presents both opportunities
and challenges for the translation field. While commercial, cloud-based AI
chatbots have garnered significant attention in translation studies, concerns
regarding data privacy, security, and equitable access necessitate exploration
of alternative deployment models. This paper investigates the feasibility and
performance of locally deployable, free language models as a viable alternative
to proprietary, cloud-based AI solutions. This study evaluates three
open-source models installed on CPU-based platforms and compared against
commercially available online chat-bots. The evaluation focuses on functional
performance rather than a comparative analysis of human-machine translation
quality, an area already subject to extensive research. The platforms assessed
were chosen for their accessibility and ease of use across various operating
systems. While local deployment introduces its own challenges, the benefits of
enhanced data control, improved privacy, and reduced dependency on cloud
services are compelling. The findings of this study contribute to a growing
body of knowledge concerning the democratization of AI technology and inform
future research and development efforts aimed at making LLMs more accessible
and practical for a wider range of users, specifically focusing on the needs of
individual translators and small businesses.

</details>


### [72] [MRGSEM-Sum: An Unsupervised Multi-document Summarization Framework based on Multi-Relational Graphs and Structural Entropy Minimization](https://arxiv.org/abs/2507.23400)
*Yongbing Zhang,Fang Nan,Shengxiang Gao,Yuxin Huang,Kaiwen Tan,Zhengtao Yu*

Main category: cs.CL

TL;DR: 提出了基于多关系图与结构熵最小化的新型无监督多文档摘要方法MRGSEM-Sum，显著提升了语句关系建模与冗余压缩能力，在多个数据集评测中逼近甚至超越监督模型表现。


<details>
  <summary>Details</summary>
Motivation: 多文档摘要面临的核心问题在于文档间关系复杂和信息冗余问题。现有方法主要基于单一关系图且需预设聚类数，难以充分表示丰富的句间关系并自适应减少冗余。

Method: 提出无监督多文档摘要框架MRGSEM-Sum。首先构建整合语义与篇章关系的多关系图，建模跨文档复杂句间联系。接着，通过二维结构熵最小化自动聚类句子并优化聚类数，最后引入位置感知压缩机制从每个聚类中生成简明摘要。

Result: 在Multi-News、DUC-2004、PubMed和WikiSum四大基准数据集上，MRGSEM-Sum在无监督方法中表现突出，多项指标接近或超过部分有监督模型和大语言模型。人工评估表明，系统生成的摘要在一致性与涵盖性上已接近人工水准。

Conclusion: 多关系结构熵最小化与自适应聚类机制能更好地解决多文档摘要中的关系建模与冗余问题。MRGSEM-Sum无监督方法在多个数据集上取得优异表现，显示出其泛化性与实际应用潜力。

Abstract: The core challenge faced by multi-document summarization is the complexity of
relationships among documents and the presence of information redundancy. Graph
clustering is an effective paradigm for addressing this issue, as it models the
complex relationships among documents using graph structures and reduces
information redundancy through clustering, achieving significant research
progress. However, existing methods often only consider single-relational
graphs and require a predefined number of clusters, which hinders their ability
to fully represent rich relational information and adaptively partition
sentence groups to reduce redundancy. To overcome these limitations, we propose
MRGSEM-Sum, an unsupervised multi-document summarization framework based on
multi-relational graphs and structural entropy minimization. Specifically, we
construct a multi-relational graph that integrates semantic and discourse
relations between sentences, comprehensively modeling the intricate and dynamic
connections among sentences across documents. We then apply a two-dimensional
structural entropy minimization algorithm for clustering, automatically
determining the optimal number of clusters and effectively organizing sentences
into coherent groups. Finally, we introduce a position-aware compression
mechanism to distill each cluster, generating concise and informative
summaries. Extensive experiments on four benchmark datasets (Multi-News,
DUC-2004, PubMed, and WikiSum) demonstrate that our approach consistently
outperforms previous unsupervised methods and, in several cases, achieves
performance comparable to supervised models and large language models. Human
evaluation demonstrates that the summaries generated by MRGSEM-Sum exhibit high
consistency and coverage, approaching human-level quality.

</details>


### [73] [Enhanced Arabic Text Retrieval with Attentive Relevance Scoring](https://arxiv.org/abs/2507.23404)
*Salah Eddine Bekhouche,Azeddine Benlamoudi,Yazid Bounab,Fadi Dornaika,Abdenour Hadid*

Main category: cs.CL

TL;DR: 本文提出了一种专为阿拉伯语设计的增强型Dense Passage Retrieval（DPR）检索框架，利用创新的关注相关性评分方法（ARS），有效提升了问题与段落之间的语义相关性建模能力，显著改善了阿拉伯语检索与问答的性能。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语由于形态复杂、可选的音标及标准语与方言共存等因素，给自然语言处理和信息检索带来极大挑战。与此同时，阿拉伯语在NLP领域的研究和资源仍很匮乏，亟需提升。

Method: 核心方法是用一种新的关注相关性评分（ARS）替代传统的交互机制，通过自适应评分函数，更有效地建模问题与段落之间的语义相关性。同时，结合预训练阿拉伯语语言模型与架构改进，以提升检索性能。

Result: 提出的改进型DPR框架通过ARS机制与阿拉伯语语言模型的结合，在阿拉伯语问答检索任务上取得了显著提升，排名准确率明显提高，表现优于传统方法。同时，相关代码开源，促进领域发展。

Conclusion: 实验结果表明，该方法能显著提高阿拉伯语问题检索和排名准确性，验证了所提出方法的有效性。

Abstract: Arabic poses a particular challenge for natural language processing (NLP) and
information retrieval (IR) due to its complex morphology, optional diacritics
and the coexistence of Modern Standard Arabic (MSA) and various dialects.
Despite the growing global significance of Arabic, it is still underrepresented
in NLP research and benchmark resources. In this paper, we present an enhanced
Dense Passage Retrieval (DPR) framework developed specifically for Arabic. At
the core of our approach is a novel Attentive Relevance Scoring (ARS) that
replaces standard interaction mechanisms with an adaptive scoring function that
more effectively models the semantic relevance between questions and passages.
Our method integrates pre-trained Arabic language models and architectural
refinements to improve retrieval performance and significantly increase ranking
accuracy when answering Arabic questions. The code is made publicly available
at \href{https://github.com/Bekhouche/APR}{GitHub}.

</details>


### [74] [Beyond Passive Critical Thinking: Fostering Proactive Questioning to Enhance Human-AI Collaboration](https://arxiv.org/abs/2507.23407)
*Ante Wang,Yujie Lin,Jingyao Liu,Suhang Wu,Hao Liu,Xinyan Xiao,Jinsong Su*

Main category: cs.CL

TL;DR: 文章提出主动批判性思维新范式，并设计GSM-MC与GSM-MCE两个评测集，发现当前大模型在该能力上普遍较弱。通过强化学习训练，模型的主动批判性思维能力大幅提升。


<details>
  <summary>Details</summary>
Motivation: 现有研究多专注于被动批判性思维（如直接拒答），缺少对模型主动与用户互动、完善信息以更好达成推理的能力的考查与提升，针对该空白设计新范式和评测方法。

Method: 提出了主动批判性思维范式，设计了GSM-MC和GSM-MCE两个新型数学推理评测基准，考查在缺失或干扰信息情况下模型能否主动提问获取必要信息，并用Qwen3与Llama系列模型进行实验，对比普通推理能力和主动批判性思维能力，进一步用提升的RL算法优化模型表现。

Result: Qwen3和Llama系列基础（尤其是小参数）模型在主动批判性思维上的表现极差，但通过融入增强型RL算法，Qwen3-1.7B在GSM-MC任务准确率从原来仅0.15%大幅提升至73.98%。

Conclusion: 现有大模型普遍缺乏主动批判性思维能力，即在面对不完整或误导信息时，难以主动与用户互动、获取缺失内容，而通过强化学习（RL）训练，可以显著提升模型的主动批判性思维表现。

Abstract: Critical thinking is essential for building robust AI systems, preventing
them from blindly accepting flawed data or biased reasoning. However, prior
work has primarily focused on passive critical thinking, where models simply
reject problematic queries without taking constructive steps to address user
requests. In this work, we introduce proactive critical thinking, a paradigm
where models actively seek missing or clarifying information from users to
resolve their queries better. To evaluate this capability, we present GSM-MC
and GSM-MCE, two novel benchmarks based on GSM8K for assessing mathematical
reasoning under incomplete or misleading conditions. GSM-MC contains 1,368 math
problems with a key variable deliberately removed, requiring models to identify
and request the missing information. GSM-MCE further increases the difficulty
by introducing irrelevant details to test robustness against distractions.
Experiments on Qwen3 and Llama series models show that, while these models
excel in traditional reasoning tasks due to extensive post-training and
inference-time scaling, they struggle with proactive critical thinking,
especially smaller ones. However, we demonstrate that reinforcement learning
(RL) can significantly improve this ability. Using our enhanced RL algorithm,
we achieve substantial gains, boosting the Qwen3-1.7B's accuracy from 0.15% to
73.98% on GSM-MC. We hope this work advances models that collaborate more
effectively with users in problem-solving through proactive critical thinking.

</details>


### [75] [Role-Aware Language Models for Secure and Contextualized Access Control in Organizations](https://arxiv.org/abs/2507.23465)
*Saeed Almheiri,Yerulan Kongrat,Adrian Santosh,Ruslan Tasmukhanov,Josemaria Vera,Muhammad Dehan Al Kautsar,Fajri Koto*

Main category: cs.CL

TL;DR: 本文提出并比较了三种LLM在企业场景下基于用户角色进行访问控制的方法，并通过两个数据集全面评估其有效性和安全性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在企业中的广泛应用，如何根据用户身份进行模型行为控制成为关键需求。然而，现有安全方法一般只关注防止有害或攻击性输出，忽略了针对不同用户角色的访问权限问题。

Method: 本文考察了三种方法：基于BERT的分类器、基于LLM的分类器、以及基于角色条件生成模型。为评估这些方法，作者构建了两类数据集：一类是改编自现有指令微调数据，通过聚类和角色标记得到，另一类为合成数据，设计为贴近真实的、具有角色敏感度的企业场景。

Result: 这些方法在不同的组织结构下进行了性能评估，同时分析了模型对提示注入、角色不匹配和越狱攻击等安全威胁的鲁棒性。

Conclusion: LLMs可通过微调有效实现基于角色的访问控制，不同方法在安全威胁防御和适应复杂企业场景方面各有优势。

Abstract: As large language models (LLMs) are increasingly deployed in enterprise
settings, controlling model behavior based on user roles becomes an essential
requirement. Existing safety methods typically assume uniform access and focus
on preventing harmful or toxic outputs, without addressing role-specific access
constraints. In this work, we investigate whether LLMs can be fine-tuned to
generate responses that reflect the access privileges associated with different
organizational roles. We explore three modeling strategies: a BERT-based
classifier, an LLM-based classifier, and role-conditioned generation. To
evaluate these approaches, we construct two complementary datasets. The first
is adapted from existing instruction-tuning corpora through clustering and role
labeling, while the second is synthetically generated to reflect realistic,
role-sensitive enterprise scenarios. We assess model performance across varying
organizational structures and analyze robustness to prompt injection, role
mismatch, and jailbreak attempts.

</details>


### [76] [A Novel Evaluation Benchmark for Medical LLMs: Illuminating Safety and Effectiveness in Clinical Domains](https://arxiv.org/abs/2507.23486)
*Shirui Wang,Zhihui Tang,Huaxia Yang,Qiuhong Gong,Tiantian Gu,Hongyang Ma,Yongxin Wang,Wubin Sun,Zeliang Lian,Kehang Mao,Yinan Jiang,Zhicheng Huang,Lingyun Ma,Wenjie Shen,Yajie Ji,Yunhui Tan,Chunbo Wang,Yunlu Gao,Qianling Ye,Rui Lin,Mingyu Chen,Lijuan Niu,Zhihao Wang,Peng Yu,Mengran Lang,Yue Liu,Huimin Zhang,Haitao Shen,Long Chen,Qiguang Zhao,Si-Xuan Liu,Lina Zhou,Hua Gao,Dongqiang Ye,Lingmin Meng,Youtao Yu,Naixin Liang,Jianxiong Wu*

Main category: cs.CL

TL;DR: 论文开发了临床大语言模型安全与有效性双轨基准（CSEDB），通过专家共识和大规模开放问答评测六款主流模型。结果显示，现有LLM在临床场景表现一般，高风险场景下掉分明显，医疗域专用模型表现优于通用。提出的CSEDB为行业提供标准化评估工具，有助于推动LLM在医疗安全应用。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）在临床决策支持方面展现出巨大潜力，当前其在安全性评估和有效性验证上面临重大挑战。迫切需要标准化的评测体系以促进LLMs在医疗领域的可持续、可信赖应用。

Method: 研究团队基于临床专家共识，建立了一个多维度的评测框架CSEDB（Clinical Safety-Effectiveness Dual-Track Benchmark），涵盖30项临床安全和有效性相关标准，并由32名专科医生制定和审核了2069个开放式问答题，覆盖26个临床科室，用于模拟真实临床场景，对6种主流大语言模型进行基准测试。

Result: 六种LLM的整体得分中等（平均总分57.2%，安全性54.7%，有效性62.3%），在高风险场景下表现显著下降13.3%；医疗专用模型在安全性（最高0.912）与有效性（最高0.861）得分方面均优于通用模型。

Conclusion: 本工作提出了临床大语言模型标准化评测体系，不仅有助于量化和比较不同LLM在医疗领域的安全性与有效性，还能识别高风险暴露场景并指引后续改进方向，促进LLM在医疗环境中更安全、有效的部署。

Abstract: Large language models (LLMs) hold promise in clinical decision support but
face major challenges in safety evaluation and effectiveness validation. We
developed the Clinical Safety-Effectiveness Dual-Track Benchmark (CSEDB), a
multidimensional framework built on clinical expert consensus, encompassing 30
criteria covering critical areas like critical illness recognition, guideline
adherence, and medication safety, with weighted consequence measures.
Thirty-two specialist physicians developed and reviewed 2,069 open-ended Q&A
items aligned with these criteria, spanning 26 clinical departments to simulate
real-world scenarios. Benchmark testing of six LLMs revealed moderate overall
performance (average total score 57.2%, safety 54.7%, effectiveness 62.3%),
with a significant 13.3% performance drop in high-risk scenarios (p < 0.0001).
Domain-specific medical LLMs showed consistent performance advantages over
general-purpose models, with relatively higher top scores in safety (0.912) and
effectiveness (0.861). The findings of this study not only provide a
standardized metric for evaluating the clinical application of medical LLMs,
facilitating comparative analyses, risk exposure identification, and
improvement directions across different scenarios, but also hold the potential
to promote safer and more effective deployment of large language models in
healthcare environments.

</details>


### [77] [Med-R$^3$: Enhancing Medical Retrieval-Augmented Reasoning of LLMs via Progressive Reinforcement Learning](https://arxiv.org/abs/2507.23541)
*Keer Lu,Zheng Liang,Youquan Li,Jiejun Tan,Da Pan,Shusen Zhang,Guosheng Dong,Huang Leng*

Main category: cs.CL

TL;DR: Med-R$^3$是一种创新的医学检索增强推理框架，采用递进式强化学习联合优化检索与推理能力，在多个模型上获得了显著性能提升，超越甚至比肩同规模闭源模型。


<details>
  <summary>Details</summary>
Motivation: 现有医学场景下对知识检索和逻辑推理能力的研究往往单独优化二者，缺乏协同，且过分依赖有监督微调，导致泛化性差。此外，通用领域中的检索增强推理方法未能针对医学领域设计有效奖励函数。

Method: 提出了Med-R$^3$（医学检索增强推理框架），采用递进式强化学习。先培养模型的医学逻辑推理能力，再自适应优化知识检索，最后联合优化检索与推理协调性。

Result: 通过实验，Med-R$^3$在多个模型上取得了最新最优成绩：LLaMA3.1-8B-Instruct + Med-R$^3$超越同级别的GPT-4o-mini 3.93%，Qwen2.5-14B + Med-R$^3$提升13.53%。

Conclusion: Med-R$^3$通过递进式强化学习联合优化医学知识检索与逻辑推理，显著提升了大模型在医学推理任务上的性能和泛化能力。

Abstract: In medical scenarios, effectively retrieving external knowledge and
leveraging it for rigorous logical reasoning is of significant importance.
Despite their potential, existing work has predominantly focused on enhancing
either retrieval or reasoning capabilities of the models in isolation, with
little attention given to their joint optimization, which leads to limited
coordination between the two processes. Additionally, current methods rely
heavily on supervised fine-tuning (SFT), which can cause models to memorize
existing problem-solving pathways, thereby restricting their generalization
ability when confronted with novel problem contexts. Furthermore, while some
studies have explored to improve retrieval-augmented reasoning in general
domains via reinforcement learning, their reward function designs do not
adequately capture the specific demands of the medical domain. To address these
challenges, we introduce **Med-R$^3$**, a **Med**ical **R**etrieval-augmented
**R**easoning framework driven by progressive **R**einforcement learning. In
this framework, we first develop the model's ability to perform logical
reasoning over medical problems. Subsequently, on the basis of this foundation,
we adaptively optimize the retrieval capability to better align with the
characteristics of knowledge corpus and external information utilization
throughout the reasoning process. Finally, we conduct joint optimization of the
model's retrieval and reasoning coordination. Extensive experiments indicate
that **Med-R$^3$** could achieve state-of-the-art performances, with
LLaMA3.1-8B-Instruct + Med-R$^3$ surpassing closed-sourced GPT-4o-mini by
3.93\% at a comparable parameter scale, while Qwen2.5-14B augmented with
Med-R$^3$ shows a more substantial gain of 13.53\%.

</details>


### [78] [T-Detect: Tail-Aware Statistical Normalization for Robust Detection of Adversarial Machine-Generated Text](https://arxiv.org/abs/2507.23577)
*Alva West,Luodan Zhang,Liuliu Zhang,Minjun Zhu,Yixuan Weng,Yue Zhang*

Main category: cs.CL

TL;DR: T-Detect是一种基于学生t分布的重尾统计新方法，显著提升了自动文本检测在对抗性和非标准文本下的鲁棒性，现有检测方法难以应对的场景中表现突出。


<details>
  <summary>Details</summary>
Motivation: 当前文本生成模型极为复杂，能生成高度仿真的文本，并且有些内容故意规避检测，现有检测器在识别被对抗扰动后的文本时效果受限。主要问题在于，许多检测器假设文本的统计分布为高斯分布，但对抗文本和非母语英文文本却呈现重尾分布，这破坏了传统假设。

Method: 提出T-Detect方法，革新曲率检测器的统计核心。主要创新是用源自学生t分布（Student's t-distribution）的重尾离差分数代替传统高斯归一化。该方法通过对文本log-likelihood进行t分布归一化处理，提高了对统计异常值的鲁棒性。

Result: 在主流对抗文本基准（RAID）和综合数据集（HART）上进行实证，T-Detect在多个任务上的AUROC比强基线方法提升最多3.9%。在联合检测框架（CT）下，在RAID的Books领域实现了0.926的AUROC，达到当前最佳性能。

Conclusion: T-Detect为文本检测构建了新的理论统计基础，并通过消融实验验证了其强鲁棒性。在对抗环境下表现优越，为应对未来更复杂的机器生成文本提供了新思路。

Abstract: The proliferation of sophisticated text generation models necessitates the
development of robust detection methods capable of identifying
machine-generated content, particularly text designed to evade detection
through adversarial perturbations. Existing zero-shot detectors often rely on
statistical measures that implicitly assume Gaussian distributions, a premise
that falters when confronted with the heavy-tailed statistical artifacts
characteristic of adversarial or non-native English texts. This paper
introduces T-Detect, a novel detection method that fundamentally redesigns the
statistical core of curvature-based detectors. Our primary innovation is the
replacement of standard Gaussian normalization with a heavy-tailed discrepancy
score derived from the Student's t-distribution. This approach is theoretically
grounded in the empirical observation that adversarial texts exhibit
significant leptokurtosis, rendering traditional statistical assumptions
inadequate. T-Detect computes a detection score by normalizing the
log-likelihood of a passage against the expected moments of a t-distribution,
providing superior resilience to statistical outliers. We validate our approach
on the challenging RAID benchmark for adversarial text and the comprehensive
HART dataset. Experiments show that T-Detect provides a consistent performance
uplift over strong baselines, improving AUROC by up to 3.9\% in targeted
domains. When integrated into a two-dimensional detection framework (CT), our
method achieves state-of-the-art performance, with an AUROC of 0.926 on the
Books domain of RAID. Our contributions are a new, theoretically-justified
statistical foundation for text detection, an ablation-validated method that
demonstrates superior robustness, and a comprehensive analysis of its
performance under adversarial conditions. Ours code are released at
https://github.com/ResearAI/t-detect.

</details>


### [79] [DiffLoRA: Differential Low-Rank Adapters for Large Language Models](https://arxiv.org/abs/2507.23588)
*Alexandre Misrahi,Nadezhda Chirkova,Maxime Louis,Vassilina Nikoulina*

Main category: cs.CL

TL;DR: DiffLoRA结合了LoRA和差分注意力机制，尽管整体效果一般，但在特定任务上展现出显著提升，适合需要参数高效与特定性能优化的场景。


<details>
  <summary>Details</summary>
Motivation: 提高Transformer模型的性能，解决噪声干扰问题，同时追求参数高效的适应方法。

Method: 提出DiffLoRA方法，在正负注意力项上都添加低秩适配器，与LoRA结合，应用于差分注意力机制。

Result: DiffLoRA在多数NLP任务中表现不及其他高效微调方法，但在人类评测的HumanEval任务上比LoRA提高了11分。在模型微调后，分析了注意力模式来解释这一现象。

Conclusion: DiffLoRA在部分领域展现出优势，特别是在HumanEval测试中有较大提升，通过对注意力机制的分析发现其特殊表现，证明在某些特定任务下有应用潜力。

Abstract: Differential Transformer has recently been proposed to improve performance in
Transformer models by canceling out noise through a denoiser attention
mechanism. In this work, we introduce DiffLoRA, a parameter-efficient
adaptation of the differential attention mechanism, with low-rank adapters on
both positive and negative attention terms. This approach retains the
efficiency of LoRA while aiming to benefit from the performance gains of
differential attention. We evaluate DiffLoRA across a broad range of NLP tasks,
including general benchmarks, many-shot in-context learning, RAG, and
long-context tests. We observe that, although DiffLoRA falls short of other
parameter-efficient fine-tuning methods in most evaluation tasks, it shows
interesting results in certain domains (+11 pts on LoRA for HumanEval). We
analyze the attention patterns post-finetuning to identify the reasons for this
behavior.

</details>


### [80] [Arabic Hate Speech Identification and Masking in Social Media using Deep Learning Models and Pre-trained Models Fine-tuning](https://arxiv.org/abs/2507.23661)
*Salam Thabet Doghmash,Motaz Saad*

Main category: cs.CL

TL;DR: 该研究针对阿拉伯语社交媒体文本，利用深度学习与transformer进行仇恨言论识别和自动清理，取得了优异的检测准确率和良好的词汇屏蔽效果。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中的仇恨言论识别日益重要，特别是阿拉伯语环境下的相关研究较少，因此需要针对阿拉伯语文本进行仇恨言论检测和清理。

Method: 本研究使用深度学习和transformer模型，对阿拉伯语文本进行仇恨言论检测。对于文本清理问题，将其视为机器翻译任务，通过模型将含有仇恨言论的词语用星号替换。

Result: 在仇恨言论检测任务中，最佳模型的Macro F1分数达到92%，准确率达到95%。在文本清理任务中，仇恨言论屏蔽模型的1-gram BLEU分数达到0.3，优于现有主流机器翻译系统。

Conclusion: 深度学习和transformer模型能够有效检测阿拉伯语文本中的仇恨言论，同时可以较好地自动化清理和屏蔽攻击性词汇。两项任务的实验结果均优于现有技术水平。

Abstract: Hate speech identification in social media has become an increasingly
important issue in recent years. In this research, we address two problems: 1)
to detect hate speech in Arabic text, 2) to clean a given text from hate
speech. The meaning of cleaning here is replacing each bad word with stars
based on the number of letters for each word. Regarding the first problem, we
conduct several experiments using deep learning models and transformers to
determine the best model in terms of the F1 score. Regarding second problem, we
consider it as a machine translation task, where the input is a sentence
containing dirty text and the output is the same sentence with masking the
dirty text. The presented methods achieve the best model in hate speech
detection with a 92\% Macro F1 score and 95\% accuracy. Regarding the text
cleaning experiment, the best result in the hate speech masking model reached
0.3 in BLEU score with 1-gram, which is a good result compared with the state
of the art machine translation systems.

</details>


### [81] [Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs](https://arxiv.org/abs/2507.23740)
*Nasim Shirvani-Mahdavi,Devin Wingfield,Amin Ghasemi,Chengkai Li*

Main category: cs.CL

TL;DR: 本文利用大语言模型生成知识图谱逻辑规则的自然语言解释，实验显示解释较为准确明晰，但仍存在改进空间。


<details>
  <summary>Details</summary>
Motivation: 知识图谱中存在丰富信息，可以推理新事实。明确逻辑规则有助于提升知识图谱的完整性、查错、揭示数据模式和增强推理能力。但逻辑规则通常复杂且受限于知识图谱特定的标签方式，难以被人理解。为提升逻辑规则的可解释性，需要将其转化为自然语言。

Method: 从公开数据集（如FB15k-237、FB-CVT-REV和FB+CVT-REV）利用AMIE 3.5.1算法挖掘逻辑规则，并借助大语言模型，采用包括zero-shot、few-shot、实体类型提示和链式思考等多种提示策略，将逻辑规则转写为自然语言。随后，用人工评价和自动评价相结合的方法，从正确性、清晰度以及幻觉发生方面评估解释效果。

Result: 大语言模型生成的解释具有较高的正确性和清晰度，但也存在某些挑战和局限，仍需进一步研究。

Conclusion: 大语言模型能够有效生成逻辑规则的自然语言解释，推动知识图谱的可解释化。尽管现有方法表现良好，但在实用性和鲁棒性方面还有改进空间。相关代码和数据已公开。

Abstract: Knowledge graphs (KGs) often contain sufficient information to support the
inference of new facts. Identifying logical rules not only improves the
completeness of a knowledge graph but also enables the detection of potential
errors, reveals subtle data patterns, and enhances the overall capacity for
reasoning and interpretation. However, the complexity of such rules, combined
with the unique labeling conventions of each KG, can make them difficult for
humans to understand. In this paper, we explore the potential of large language
models to generate natural language explanations for logical rules.
Specifically, we extract logical rules using the AMIE 3.5.1 rule discovery
algorithm from the benchmark dataset FB15k-237 and two large-scale datasets,
FB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including
zero- and few-shot prompting, including variable entity types, and
chain-of-thought reasoning. We conduct a comprehensive human evaluation of the
generated explanations based on correctness, clarity, and hallucination, and
also assess the use of large language models as automatic judges. Our results
demonstrate promising performance in terms of explanation correctness and
clarity, although several challenges remain for future research. All scripts
and data used in this study are publicly available at
https://github.com/idirlab/KGRule2NL}{https://github.com/idirlab/KGRule2NL.

</details>


### [82] [Cascaded Information Disclosure for Generalized Evaluation of Problem Solving Capabilities](https://arxiv.org/abs/2507.23776)
*Yunxiang Yan,Tomohiro Sawada,Kartik Goyal*

Main category: cs.CL

TL;DR: 本文提出了级联问题披露框架用于更准确、自动化地评估大模型问题解决能力，实验证明比传统QA评测更科学，能更好对比不同大模型，减少评测中高估模型间差异的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于QA基准的评估方法虽然自动且可扩展，但仅间接反映大模型的问题解决能力，容易低估模型的真实推理水平和夸大模型间表现差距。提出更综合、通用的框架是为了解决这一评估不足。

Method: 设计并采用一种级联问题披露（cascaded question disclosure）框架，分阶段逐步向模型披露部分问题信息，然后收集模型响应，并在多个LLM、不同QA数据集和任务下进行了实证比较和消融实验。

Result: 该框架带来了更好的模型对比结果和更有价值的推理过程记录，且能缩小不同语言模型在传统评测方法下的性能差距。通过实验证明其有效性，并通过消融实验进行了进一步验证。

Conclusion: 提出的级联问题披露方法能更准确地评估LLMs的问题解决能力，且可以缩小不同模型之间在传统QA任务中表现出的性能差距。现有的QA评估方法可能高估了模型间的差异。

Abstract: While question-answering~(QA) benchmark performance is an automatic and
scalable method to compare LLMs, it is an indirect method of evaluating their
underlying problem-solving capabilities. Therefore, we propose a holistic and
generalizable framework based on \emph{cascaded question disclosure} that
provides a more accurate estimate of the models' problem-solving capabilities
while maintaining the scalability and automation. This approach collects model
responses in a stagewise manner with each stage revealing partial information
about the question designed to elicit generalized reasoning in LLMs. We find
that our approach not only provides a better comparison between LLMs, but also
induces better intermediate traces in models compared to the standard QA
paradigm. We empirically verify this behavior on diverse reasoning and
knowledge-heavy QA datasets by comparing LLMs of varying sizes and families.
Our approach narrows the performance gap observed in the standard QA evaluation
settings, indicating that the prevalent indirect QA paradigm of evaluation
overestimates the differences in performance between models. We further
validate our findings by extensive ablation studies.

</details>
