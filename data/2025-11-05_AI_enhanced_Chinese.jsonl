{"id": "2511.02164", "categories": ["cs.LO", "cs.AI", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.02164", "abs": "https://arxiv.org/abs/2511.02164", "authors": ["Eric Vin", "Kyle A. Miller", "Inigo Incer", "Sanjit A. Seshia", "Daniel J. Fremont"], "title": "ScenicProver: A Framework for Compositional Probabilistic Verification of Learning-Enabled Systems", "comment": "26 pages, 4 figures. Full version (including appendices) of a paper\n  submitted to TACAS 2026", "summary": "Full verification of learning-enabled cyber-physical systems (CPS) has long\nbeen intractable due to challenges including black-box components and complex\nreal-world environments. Existing tools either provide formal guarantees for\nlimited types of systems or test the system as a monolith, but no general\nframework exists for compositional analysis of learning-enabled CPS using\nvaried verification techniques over complex real-world environments. This paper\nintroduces ScenicProver, a verification framework that aims to fill this gap.\nBuilt upon the Scenic probabilistic programming language, the framework\nsupports: (1) compositional system description with clear component interfaces,\nranging from interpretable code to black boxes; (2) assume-guarantee contracts\nover those components using an extension of Linear Temporal Logic containing\narbitrary Scenic expressions; (3) evidence generation through testing, formal\nproofs via Lean 4 integration, and importing external assumptions; (4)\nsystematic combination of generated evidence using contract operators; and (5)\nautomatic generation of assurance cases tracking the provenance of system-level\nguarantees. We demonstrate the framework's effectiveness through a case study\non an autonomous vehicle's automatic emergency braking system with sensor\nfusion. By leveraging manufacturer guarantees for radar and laser sensors and\nfocusing testing efforts on uncertain conditions, our approach enables stronger\nprobabilistic guarantees than monolithic testing with the same computational\nbudget.", "AI": {"tldr": "ScenicProver\u662f\u4e00\u79cd\u65b0\u578b\u5b66\u4e60\u578bCPS\u9a8c\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u7ec4\u5408\u5206\u6790\u3001\u5951\u7ea6\u8bc1\u660e\u548c\u8bc1\u636e\u8ffd\u8e2a\uff0c\u80fd\u5728\u73b0\u5b9e\u590d\u6742\u73af\u5883\u4e0b\u5b9e\u73b0\u6bd4\u4f20\u7edf\u5355\u4e00\u6d4b\u8bd5\u66f4\u5f3a\u7684\u4fdd\u969c\u6548\u679c\u3002", "motivation": "\u7531\u4e8e\u5b58\u5728\u9ed1\u76d2\u7ec4\u4ef6\u548c\u590d\u6742\u7684\u771f\u5b9e\u73af\u5883\uff0c\u652f\u6301\u5b66\u4e60\u7684\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\uff08CPS\uff09\u5168\u9762\u9a8c\u8bc1\u4e00\u76f4\u975e\u5e38\u56f0\u96be\u3002\u73b0\u6709\u5de5\u5177\u53ea\u80fd\u9488\u5bf9\u6709\u9650\u7c7b\u578b\u7684\u7cfb\u7edf\u63d0\u4f9b\u5f62\u5f0f\u5316\u4fdd\u8bc1\uff0c\u6216\u5c06\u6574\u4e2a\u7cfb\u7edf\u4f5c\u4e3a\u6574\u4f53\u6d4b\u8bd5\uff0c\u7f3a\u4e4f\u53ef\u7528\u4e8e\u590d\u6742\u771f\u5b9e\u73af\u5883\u3001\u80fd\u591f\u91c7\u7528\u591a\u6837\u5316\u9a8c\u8bc1\u65b9\u6cd5\u7684\u901a\u7528\u7ec4\u5408\u5206\u6790\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86ScenicProver\u6846\u67b6\u3002\u8be5\u6846\u67b6\u57fa\u4e8eScenic\u6982\u7387\u7f16\u7a0b\u8bed\u8a00\uff0c\u652f\u6301\u53ef\u7ec4\u5408\u7684\u7cfb\u7edf\u63cf\u8ff0\uff0c\u63a5\u53e3\u6e05\u6670\uff0c\u9002\u7528\u8303\u56f4\u4ece\u53ef\u89e3\u91ca\u4ee3\u7801\u5230\u9ed1\u76d2\u7ec4\u4ef6\uff1b\u6269\u5c55\u4e86\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\uff0c\u5b9e\u73b0\u4e86\u5305\u542b\u4efb\u610fScenic\u8868\u8fbe\u5f0f\u7684\u5047\u8bbe-\u4fdd\u8bc1\u5951\u7ea6\uff1b\u53ef\u901a\u8fc7\u6d4b\u8bd5\u3001Lean 4\u5f62\u5f0f\u5316\u8bc1\u660e\u4ee5\u53ca\u5916\u90e8\u5047\u8bbe\u5bfc\u5165\u751f\u6210\u8bc1\u636e\uff0c\u5e76\u53ef\u7cfb\u7edf\u6027\u5730\u7ec4\u5408\u8fd9\u4e9b\u8bc1\u636e\uff0c\u901a\u8fc7\u5951\u7ea6\u7b97\u5b50\u5408\u6210\u4fdd\u969c\uff0c\u5e76\u81ea\u52a8\u751f\u6210\u57fa\u4e8e\u6765\u6e90\u8ddf\u8e2a\u7684\u7cfb\u7edf\u7ea7\u4fdd\u969c\u8bba\u8bc1\u3002", "result": "\u5728\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u7684\u81ea\u52a8\u7d27\u6025\u5236\u52a8\u7cfb\u7edf\uff08\u5305\u542b\u4f20\u611f\u5668\u878d\u5408\uff09\u6848\u4f8b\u4e2d\uff0c\u5c55\u793a\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002\u7ed3\u5408\u96f7\u8fbe\u548c\u6fc0\u5149\u4f20\u611f\u5668\u7684\u5382\u5bb6\u62c5\u4fdd\uff0c\u5e76\u5bf9\u4e0d\u786e\u5b9a\u6761\u4ef6\u8fdb\u884c\u91cd\u70b9\u6d4b\u8bd5\uff0c\u4f7f\u5f97\u5728\u76f8\u540c\u8ba1\u7b97\u8d44\u6e90\u4e0b\uff0c\u7cfb\u7edf\u83b7\u5f97\u6bd4\u6574\u4f53\u6d4b\u8bd5\u66f4\u5f3a\u7684\u6982\u7387\u6027\u4fdd\u969c\u3002", "conclusion": "ScenicProver\u6846\u67b6\u5b9e\u73b0\u4e86\u5b66\u4e60\u578bCPS\u7684\u53ef\u7ec4\u5408\u5206\u6790\uff0c\u80fd\u591f\u5728\u590d\u6742\u5b9e\u9645\u73af\u5883\u4e0b\uff0c\u5c06\u591a\u79cd\u9a8c\u8bc1\u6280\u672f\u7ed3\u5408\uff0c\u751f\u6210\u66f4\u5f3a\u7684\u7cfb\u7edf\u6027\u4fdd\u8bc1\u3002"}}
{"id": "2511.02348", "categories": ["cs.LO", "cs.CC", "cs.FL", "math.LO"], "pdf": "https://arxiv.org/pdf/2511.02348", "abs": "https://arxiv.org/abs/2511.02348", "authors": ["Yusaku Nishimiya", "Masaya Taniguchi"], "title": "Non-commutative linear logic fragments with sub-context-free complexity", "comment": "Presented at TbiLLC 2025: Fifteenth International Tbilisi Symposium\n  on Logic, Language and Computation", "summary": "We present new descriptive complexity characterisations of classes REG\n(regular languages), LCFL (linear context-free languages) and CFL (context-free\nlanguages) as restrictions on inference rules, size of formulae and permitted\nconnectives in the Lambek calculus; fragments of the intuitionistic\nnon-commutative linear logic with direction-sensitive implication connectives.\nOur identification of the Lambek calculus fragments with proof complexity REG\nand LCFL is the first result of its kind. We further show the CFL complexity of\none of the strictly `weakest' possible variants of the logic, admitting only a\nsingle inference rule. The proof thereof, moreover, is based on a direct\ntranslation between type-logical and formal grammar and structural induction on\nprovable sequents; a simpler and more intuitive method than those employed in\nprior works. We thereby establish a clear conceptual utility of the\nCut-elimination theorem for comparing formal grammar and sequent calculus, and\nidentify the exact analogue of the Greibach Normal Form in Lambek grammar. We\nbelieve the result presented herein constitutes a first step toward a more\nextensive and richer characterisation of the interaction between computation\nand logic, as well as a finer-grained complexity separation of various sequent\ncalculi.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8eLambek\u6f14\u7b97\u7247\u6bb5\u9996\u6b21\u660e\u786e\u523b\u753b\u4e86\u4e09\u7c7b\u5f62\u5f0f\u8bed\u8a00\uff08REG\u3001LCFL\u3001CFL\uff09\u4e0e\u903b\u8f91\u590d\u6742\u6027\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u63d0\u51fa\u66f4\u7b80\u6d01\u7684\u8bc1\u660e\u5de5\u5177\uff0c\u4e30\u5bcc\u4e86\u8ba1\u7b97\u4e0e\u903b\u8f91\u5173\u7cfb\u7684\u7406\u8bba\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u540e\u7eed\u7ec6\u81f4\u590d\u6742\u5ea6\u5206\u79bb\u7814\u7a76\u3002", "motivation": "\u4ee5\u5f80\u590d\u6742\u5ea6\u523b\u753b\u65b9\u6cd5\u590d\u6742\uff0c\u4e14\u5bf9\u8ba1\u7b97\u4e0e\u903b\u8f91\u4e4b\u95f4\u7ec6\u7c92\u5ea6\u5173\u7cfb\u7684\u7406\u89e3\u4e0d\u8db3\u3002\u6587\u7ae0\u8bd5\u56fe\u4e3a\u4e0d\u540c\u5e8f\u5217\u6f14\u7b97\u63d0\u4f9b\u66f4\u7ec6\u81f4\u7684\u590d\u6742\u5ea6\u5206\u5c42\uff0c\u5e76\u63ed\u793a\u8ba1\u7b97\u4e0e\u903b\u8f91\u4ea4\u4e92\u7684\u57fa\u7840\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u9650\u5236Lambek\u6f14\u7b97\u4e2d\u7684\u63a8\u7406\u89c4\u5219\u3001\u516c\u5f0f\u5927\u5c0f\u548c\u53ef\u7528\u8fde\u7ed3\u8bcd\u6765\u63cf\u8ff0\u4e0d\u540c\u590d\u6742\u5ea6\u7c7b\u3002\u901a\u8fc7\u7c7b\u578b\u903b\u8f91\u4e0e\u5f62\u5f0f\u6587\u6cd5\u4e4b\u95f4\u7684\u76f4\u63a5\u8f6c\u6362\u4ee5\u53ca\u5bf9\u53ef\u8bc1\u5e8f\u5217\u7684\u7ed3\u6784\u5f52\u7eb3\uff0c\u7b80\u5316\u4e86\u8bc1\u660e\u8fc7\u7a0b\uff0c\u5e76\u9996\u6b21\u4ee5\u7b80\u5355\u76f4\u89c2\u65b9\u5f0f\u5b9e\u73b0\u4e86\u76f8\u5173\u590d\u6742\u5ea6\u7684\u523b\u753b\u3002", "result": "\uff081\uff09\u9996\u6b21\u5c06Lambek\u6f14\u7b97\u7684\u7279\u5b9a\u90e8\u5206\u4e0eREG\u548cLCFL\u8bc1\u660e\u590d\u6742\u6027\u4e00\u4e00\u5bf9\u5e94\uff1b\uff082\uff09\u8bc1\u660e\u4e86\u67d0\u79cd\u6700\u5f31\u903b\u8f91\u53d8\u4f53\u5177\u6709CFL\u590d\u6742\u6027\uff1b\uff083\uff09\u65b9\u6cd5\u57fa\u4e8e\u66f4\u52a0\u76f4\u63a5\u548c\u76f4\u89c2\u7684\u5de5\u5177\uff0c\u5e76\u660e\u786e\u4e86Lambek\u8bed\u6cd5\u4e2d\u7684Greibach\u8303\u5f0f\u3002", "conclusion": "\u6587\u7ae0\u9996\u6b21\u5c06Lambek\u6f14\u7b97\u7684\u82e5\u5e72\u7247\u6bb5\u4e0e\u6b63\u89c4\u8bed\u8a00\uff08REG\uff09\u3001\u7ebf\u6027\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\uff08LCFL\uff09\u548c\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\uff08CFL\uff09\u7684\u8bc1\u660e\u590d\u6742\u6027\u8fdb\u884c\u4e86\u660e\u786e\u5bf9\u5e94\uff0c\u63d0\u51fa\u8fd9\u7c7b\u903b\u8f91\u7247\u6bb5\u4e0e\u76f8\u5173\u590d\u6742\u5ea6\u7c7b\u7684\u5177\u4f53\u5173\u7cfb\uff0c\u5e76\u5229\u7528Cut-elimination\u5b9a\u7406\u5efa\u7acb\u4e86\u5206\u6790\u5de5\u5177\uff0c\u5bf9\u5f62\u5f0f\u8bed\u6cd5\u548c\u5e8f\u5217\u6f14\u7b97\u8fdb\u884c\u6bd4\u8f83\u3002"}}
{"id": "2511.02521", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2511.02521", "abs": "https://arxiv.org/abs/2511.02521", "authors": ["Romy Peled", "Daniel Kroening", "Michael Tautschnig", "Yakir Vizel"], "title": "Large Lemma Miners: Can LLMs do Induction Proofs for Hardware?", "comment": null, "summary": "Large Language Models (LLMs) have shown potential for solving mathematical\ntasks. We show that LLMs can be utilized to generate proofs by induction for\nhardware verification and thereby replace some of the manual work done by\nFormal Verification engineers and deliver industrial value. We present a\nneurosymbolic approach that includes two prompting frameworks to generate\ncandidate invariants, which are checked using a formal, symbolic tool. Our\nresults indicate that with sufficient reprompting, LLMs are able to generate\ninductive arguments for mid-size open-source RTL designs. For $87\\%$ of our\nproblem set, at least one of the prompt setups succeeded in producing a\nprovably correct inductive argument.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528LLMs\u7ed3\u5408\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u81ea\u52a8\u5316\u751f\u6210\u786c\u4ef6\u5f52\u7eb3\u8bc1\u660e\uff0c\u51cf\u5c11\u4eba\u5de5\u9a8c\u8bc1\u5de5\u4f5c\u3002\u572887%\u6d4b\u8bd5\u95ee\u9898\u4e2d\uff0c\u81ea\u52a8\u65b9\u6cd5\u6210\u529f\u751f\u6210\u53ef\u8bc1\u660e\u7684\u8bba\u8bc1\uff0c\u5c55\u73b0\u4e86\u5b9e\u9645\u5de5\u4e1a\u4ef7\u503c\u3002", "motivation": "\u624b\u52a8\u7684\u786c\u4ef6\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5de5\u4f5c\u91cf\u5927\uff0c\u6548\u7387\u4f4e\uff0c\u5bfb\u6c42\u7528LLMs\u81ea\u52a8\u5316\u751f\u6210\u5f52\u7eb3\u8bc1\u660e\u4ee5\u63d0\u9ad8\u6548\u7387\u548c\u8d4b\u80fd\u5de5\u4e1a\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u4e24\u4e2a\u63d0\u793a\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u5019\u9009\u4e0d\u53d8\u91cf\uff0c\u5e76\u7528\u5f62\u5f0f\u5316\u7b26\u53f7\u5de5\u5177\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5728\u5f00\u653e\u6e90\u4ee3\u7801\u7684\u4e2d\u7b49\u89c4\u6a21RTL\u8bbe\u8ba1\u4e2d\uff0c\u7ecf\u8fc7\u5145\u5206\u91cd\u63d0\u793a\uff0cLLMs\u80fd\u591f\u6210\u529f\u751f\u6210\u5f52\u7eb3\u8bba\u8bc1\u3002\u572887%\u7684\u95ee\u9898\u4e2d\uff0c\u81f3\u5c11\u6709\u4e00\u79cd\u63d0\u793a\u65b9\u6cd5\u6210\u529f\u751f\u6210\u4e86\u53ef\u88ab\u8bc1\u660e\u6b63\u786e\u7684\u5f52\u7eb3\u8bba\u8bc1\u3002", "conclusion": "LLMs\u80fd\u591f\u751f\u6210\u7528\u4e8e\u786c\u4ef6\u9a8c\u8bc1\u7684\u5f52\u7eb3\u8bc1\u660e\uff0c\u5e76\u4e14\u5728\u5927\u90e8\u5206\u6d4b\u8bd5\u95ee\u9898\u4e0a\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u5de5\u5de5\u4f5c\u5e76\u5177\u5907\u5de5\u4e1a\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.02594", "categories": ["cs.LO", "F.4.1"], "pdf": "https://arxiv.org/pdf/2511.02594", "abs": "https://arxiv.org/abs/2511.02594", "authors": ["Bahareh Afshari", "Giacomo Barlucchi", "Graham E. Leigh"], "title": "The Limit of Recursion in State-based Systems", "comment": "In Proceedings FICS 2024, arXiv:2511.00626", "summary": "We prove that omega^2 strictly bounds the iterations required for modal\ndefinable functions to reach a fixed point across all countable structures. The\nresult corrects and extends the previously claimed result by the first and\nthird authors on closure ordinals of the alternation-free mu-calculus in [3].\nThe new approach sees a reincarnation of Kozen's well-annotations, devised for\nshowing the finite model property for the modal mu-calculus. We develop a\ntheory of 'conservative' well-annotations where minimality of annotations is\nguaranteed, and isolate parts of the structure that locally determine the\nclosure ordinal of relevant formulas. This adoption of well-annotations enables\na direct and clear pumping process that rules out closure ordinals between\nomega^2 and the limit of countability.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4fdd\u5b88\u578bwell-\u6ce8\u91ca\u7406\u8bba\uff0c\u8bc1\u660e\u4e86\u5728\u6240\u6709\u53ef\u6570\u7ed3\u6784\u4e0b\uff0c\u6a21\u6001\u53ef\u5b9a\u4e49\u51fd\u6570\u8fbe\u5230\u56fa\u5b9a\u70b9\u65f6\u6240\u9700\u7684\u8fed\u4ee3\u6b21\u6570\u4e25\u683c\u5c0f\u4e8eomega^2\uff0c\u4fee\u6b63\u5e76\u6269\u5c55\u4e86\u6b64\u524d\u7684\u76f8\u5173\u7ed3\u8bba\u3002", "motivation": "\u6b64\u524d\u5173\u4e8emu\u6f14\u7b97\u95ed\u5305\u5e8f\u6570\u7684\u8fb9\u754c\u5b58\u5728\u4e0d\u8db3\u6216\u9519\u8bef\uff0c\u9700\u5efa\u7acb\u66f4\u7cbe\u786e\u7684\u7406\u8bba\uff0c\u6f84\u6e05\u6a21\u6001\u53ef\u5b9a\u4e49\u51fd\u6570\u56fa\u5b9a\u70b9\u8fed\u4ee3\u7684\u590d\u6742\u6027\u4e0a\u9650\u3002\u5e76\u5e0c\u671b\u5229\u7528Kozen\u7684well-\u6ce8\u91ca\u65b9\u6cd5\u627e\u5230\u65b0\u7684\u5206\u6790\u8def\u5f84\u3002", "method": "\u5f15\u5165\u4fdd\u5b88\u578bwell-\u6ce8\u91ca\u7406\u8bba\uff0c\u5206\u6790\u6ce8\u91ca\u6700\u5c0f\u6027\u548c\u7ed3\u6784\u7684\u5c40\u90e8\u51b3\u5b9a\u6027\uff0c\u91c7\u7528well-\u6ce8\u91ca\u8fdb\u884c\u76f4\u63a5\u7684\u201cpumping\u201d\u8fc7\u7a0b\uff0c\u4ee5\u8bc1\u660e\u8fed\u4ee3\u6b21\u6570\u7684\u4e25\u683c\u4e0a\u754c\u3002", "result": "\u83b7\u5f97\u4e86omega^2\u7684\u4e25\u683c\u754c\u9650\uff0c\u6392\u9664\u4e86\u95f4\u65ad\u533a\u95f4\u7684\u53ef\u80fd\u6027\uff0c\u5b8c\u5584\u4e86\u5173\u4e8emu\u6f14\u7b97\u548c\u6a21\u6001\u903b\u8f91\u4e2d\u56fa\u5b9a\u70b9\u8fed\u4ee3\u7684\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "omega^2 \u662f\u53ef\u6570\u7ed3\u6784\u4e2d\u6a21\u6001\u53ef\u5b9a\u4e49\u51fd\u6570\u8fbe\u5230\u4e0d\u52a8\u70b9\u6240\u9700\u8fed\u4ee3\u6b21\u6570\u7684\u4e25\u683c\u4e0a\u754c\uff0c\u4fee\u6b63\u5e76\u6269\u5c55\u4e86\u4e4b\u524d\u5173\u4e8e\u4ea4\u66ff\u81ea\u7531mu\u6f14\u7b97\u95ed\u5305\u5e8f\u6570\u7684\u7ed3\u679c\u3002\u901a\u8fc7\u5f15\u5165\u4fdd\u5b88\u578bwell-\u6ce8\u91ca\u7406\u8bba\uff0c\u4fdd\u8bc1\u6ce8\u91ca\u7684\u6700\u5c0f\u6027\uff0c\u5b9a\u4f4d\u4e86\u7ed3\u6784\u4e2d\u5f71\u54cd\u516c\u5f0f\u95ed\u5305\u5e8f\u6570\u7684\u5c40\u90e8\u90e8\u5206\uff0c\u5e76\u901a\u8fc7well-\u6ce8\u91ca\u5b9e\u73b0\u4e86\u76f4\u63a5\u6e05\u6670\u7684\u6392\u9664\u65b9\u6cd5\uff0c\u6392\u9664\u4e86omega^2\u4e0e\u53ef\u6570\u6781\u9650\u4e4b\u95f4\u7684\u95ed\u5305\u5e8f\u6570\u3002"}}
{"id": "2511.01891", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01891", "abs": "https://arxiv.org/abs/2511.01891", "authors": ["Rongxin Chen", "Yunfan Li", "Yige Yuan", "Bingbing Xu", "Huawei Shen"], "title": "Multi-Personality Generation of LLMs at Decoding-time", "comment": "WSDM2026", "summary": "Multi-personality generation for LLMs, enabling simultaneous embodiment of\nmultiple personalization attributes, is a fundamental challenge. Existing\nretraining-based approaches are costly and poorly scalable, while decoding-time\nmethods often rely on external models or heuristics, limiting flexibility and\nrobustness. In this paper, we propose a novel Multi-Personality Generation\n(MPG) framework under the decoding-time combination paradigm. It flexibly\ncontrols multi-personality without relying on scarce multi-dimensional models\nor extra training, leveraging implicit density ratios in single-dimensional\nmodels as a \"free lunch\" to reformulate the task as sampling from a target\nstrategy aggregating these ratios. To implement MPG efficiently, we design\nSpeculative Chunk-level based Rejection sampling (SCR), which generates\nresponses in chunks and parallelly validates them via estimated thresholds\nwithin a sliding window. This significantly reduces computational overhead\nwhile maintaining high-quality generation. Experiments on MBTI personality and\nRole-Playing demonstrate the effectiveness of MPG, showing improvements up to\n16%-18%. Code and data are available at https://github.com/Libra117/MPG .", "AI": {"tldr": "MPG\u6846\u67b6\u4f7f\u5927\u6a21\u578b\u80fd\u7075\u6d3b\u9ad8\u6548\u5730\u878d\u5408\u591a\u4e2a\u4eba\u683c\u7279\u5f81\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u914d\u5408SCR\u91c7\u6837\u663e\u8457\u63d0\u9ad8\u591a\u4eba\u683c\u751f\u6210\u8d28\u91cf\u548c\u6548\u7387\u3002", "motivation": "\u5b9e\u73b0LLM\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u6216\u4f9d\u8d56\u5916\u90e8\u6a21\u578b\u7684\u524d\u63d0\u4e0b\uff0c\u540c\u65f6\u5c55\u73b0\u591a\u79cd\u4e2a\u6027\u5c5e\u6027\uff0c\u89e3\u51b3\u591a\u4e2a\u4e2a\u6027\u5408\u6210\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\u95ee\u9898\u3002", "method": "\u63d0\u51faMPG\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u7801\u65f6\u7684\u9690\u5f0f\u5bc6\u5ea6\u6bd4\u7ec4\u5408\u5355\u7ef4\u6a21\u578b\uff0c\u5229\u7528\u201c\u514d\u8d39\u5348\u9910\u201d\u65b9\u6cd5\u5b9e\u73b0\u4e2a\u6027\u805a\u5408\u91c7\u6837\uff0c\u5e76\u8bbe\u8ba1\u4e86SCR\u91c7\u6837\u65b9\u6cd5\uff0c\u4ee5chunk\u4e3a\u5355\u4f4d\u751f\u6210\u548c\u9a8c\u8bc1\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "result": "\u5728MBTI\u4eba\u683c\u548c\u89d2\u8272\u626e\u6f14\u4efb\u52a1\u4e0a\uff0cMPG\u6846\u67b6\u5e26\u676516%-18%\u7684\u751f\u6210\u63d0\u5347\uff0c\u4e14\u7ef4\u6301\u9ad8\u8d28\u91cf\u3002", "conclusion": "MPG\u6846\u67b6\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u5927\u578b\u591a\u7ef4\u6a21\u578b\uff0c\u80fd\u591f\u9ad8\u6548\u4e14\u7075\u6d3b\u5730\u5b9e\u73b0\u591a\u4e2a\u6027\u751f\u6210\uff0c\u63d0\u5347\u4e86\u53ef\u6269\u5c55\u6027\u548c\u751f\u6210\u6548\u679c\u3002"}}
{"id": "2511.02081", "categories": ["cs.DM"], "pdf": "https://arxiv.org/pdf/2511.02081", "abs": "https://arxiv.org/abs/2511.02081", "authors": ["Krist\u00f3f B\u00e9rczi", "Florian H\u00f6rsch", "Andr\u00e1s Imolay", "Tam\u00e1s Schwarcz"], "title": "Fixed-parameter tractability and hardness for Steiner rooted and locally connected orientations", "comment": null, "summary": "Finding a Steiner strongly $k$-arc-connected orientation is particularly\nrelevant in network design and reliability, as it guarantees robust\ncommunication between a designated set of critical nodes. Kir\\'aly and Lau\n(FOCS 2006) introduced a rooted variant, called the Steiner Rooted Orientation\nproblem, where one is given an undirected graph on $n$ vertices, a root vertex,\nand a set of $t$ terminals. The goal is to find an orientation of the graph\nsuch that the resulting directed graph is Steiner rooted $k$-arc-connected.\nThis problem generalizes several classical connectivity results in graph\ntheory, such as those on edge-disjoint paths and spanning-tree packings. While\nthe maximum $k$ for which a Steiner strongly $k$-arc-connected orientation\nexists can be determined in polynomial time via Nash-Williams' orientation\ntheorem, its rooted counterpart is significantly harder: the problem is NP-hard\nwhen both $k$ and $t$ are part of the input. In this work, we provide a\ncomplete understanding of the problem with respect to these two parameters. In\nparticular, we give an algorithm that solves the problem in time $f(k,t)\\cdot\nn^{O(1)}$, establishing fixed-parameter tractability with respect to the number\nof terminals $t$ and the target connectivity $k$. We further show that the\nproblem remains NP-hard if either $k$ or $t$ is treated as part of the input,\nmeaning that our algorithm is essentially optimal from a parameterized\nperspective. Importantly, our results extend far beyond the Steiner setting:\nthe same framework applies to the more general orientation problem with local\nconnectivity requirements, establishing fixed-parameter tractability when\nparameterized by the total demand and thereby covering a wide range of\narc-connectivity orientation problems.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5b9a\u6839Steiner k-\u5f27\u8fde\u901a\u6709\u5411\u5316\u95ee\u9898\u7684\u53c2\u6570\u5316\u590d\u6742\u6027\uff0c\u63d0\u51fa\u4e86\u4ee5\u7ec8\u7aef\u6570t\u548c\u8fde\u901a\u5ea6k\u4e3a\u53c2\u6570\u7684\u56fa\u5b9a\u53c2\u6570\u53ef\u89e3\uff08FPT\uff09\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u5728k\u6216t\u4e3a\u8f93\u5165\u65f6\u95ee\u9898\u4ecd\u4e3aNP\u96be\uff0c\u83b7\u5f97\u4e86\u53c2\u6570\u5316\u610f\u4e49\u4e0b\u7684\u6700\u4f18\u7ed3\u679c\u3002\u65b9\u6cd5\u6846\u67b6\u53ef\u63a8\u5e7f\u5230\u66f4\u5e7f\u6cdb\u7684\u6709\u5411\u5316\u8fde\u901a\u5ea6\u95ee\u9898\uff0c\u6210\u679c\u5bf9\u7f51\u7edc\u8bbe\u8ba1\u548c\u53ef\u9760\u6027\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u8be5\u95ee\u9898\u5728\u7f51\u7edc\u8bbe\u8ba1\u548c\u53ef\u9760\u6027\u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4fdd\u8bc1\u6307\u5b9a\u5173\u952e\u8282\u70b9\u95f4\u7684\u5f3a\u9c81\u68d2\u901a\u4fe1\u3002\u7ecf\u5178\u7b97\u6cd5\u53ef\u9ad8\u6548\u89e3\u51b3\u975e\u5b9a\u6839\u60c5\u5f62\uff0c\u4f46\u5b9a\u6839Steiner\u8fde\u901a\u95ee\u9898\u590d\u6742\u6027\u66f4\u9ad8\uff0c\u90e8\u5206\u60c5\u51b5\u4e0b\u4e3aNP\u96be\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u5206\u6790\u8be5\u95ee\u9898\u4e24\u53c2\u6570k\u548ct\u4e0a\u7684\u590d\u6742\u6027\uff0c\u5e76\u63a2\u8ba8\u5176\u4e00\u822c\u6027\u63a8\u5e7f\u3002", "method": "\u901a\u8fc7\u53c2\u6570\u5316\u7b97\u6cd5\u8bbe\u8ba1\uff0c\u7ed9\u51fa\u5173\u4e8e\u5173\u952e\u8282\u70b9\u6570\u91cft\u548c\u8fde\u901a\u5ea6k\u7684\u5b9a\u6839Steiner\u6709\u5411\u5316\u95ee\u9898\u7684\u5b8c\u6574\u7b97\u6cd5\u590d\u6742\u6027\u5206\u6790\u3002\u63d0\u51fa\u4e00\u4e2a\u56fa\u5b9a\u53c2\u6570\u53ef\u89e3\u7b97\u6cd5\uff0c\u5176\u65f6\u95f4\u590d\u6742\u5ea6\u4e3af(k,t)\u00b7n^{O(1)}\u3002\u540c\u65f6\u7406\u8bba\u6027\u8bc1\u660e\uff1a\u5f53k\u6216t\u4e3a\u8f93\u5165\u65f6\u95ee\u9898\u4f9d\u7136NP\u96be\uff0c\u8868\u660e\u7ed9\u51fa\u7b97\u6cd5\u5728\u53c2\u6570\u5316\u89c6\u89d2\u4e0b\u5df2\u8fd1\u4e4e\u6700\u4f18\u3002\u65b9\u6cd5\u6846\u67b6\u8fd8\u63a8\u5e7f\u5230\u5c40\u90e8\u8fde\u901a\u5ea6\u9700\u6c42\u7684\u66f4\u4e00\u822c\u6709\u5411\u5316\u95ee\u9898\u3002", "result": "\u8be5\u95ee\u9898\u5bf9\u53c2\u6570t\u548ck\u4e3a\u56fa\u5b9a\u53c2\u6570\u53ef\u89e3\uff08FPT\uff09\uff0c\u5373\u6709\u7b97\u6cd5\u5728f(k,t)\u00b7n^{O(1)}\u65f6\u95f4\u5185\u6c42\u89e3\u3002\u8fdb\u4e00\u6b65\u8bc1\u660e\uff0c\u53ea\u8981k\u6216t\u4e3a\u8f93\u5165\uff0c\u5219\u95ee\u9898\u4ecdNP\u96be\uff0c\u8bf4\u660e\u83b7\u5f97\u7684FPT\u7ed3\u679c\u5df2\u6700\u4f18\u3002\u6846\u67b6\u53ef\u6269\u5c55\u5230\u4e00\u7c7b\u66f4\u4e00\u822c\u7684\u6709\u5411\u5316\u4e0e\u8fde\u901a\u5ea6\u95ee\u9898\uff0c\u5728\u53c2\u6570\u201c\u603b\u9700\u6c42\u201d\u4e0b\u540c\u6837FPT\u3002", "conclusion": "\u672c\u6587\u7cfb\u7edf\u523b\u753b\u4e86\u5b9a\u6839Steiner k-\u5f27\u8fde\u901a\u6709\u5411\u5316\u95ee\u9898\u7684\u53c2\u6570\u5316\u590d\u6742\u6027\uff0c\u63d0\u51fa\u4e86\u6700\u4f18\uff08\u53c2\u6570\u5316\u610f\u4e49\u4e0b\uff09\u6c42\u89e3\u65b9\u6cd5\uff0c\u4e14\u65b9\u6cd5\u5e7f\u6cdb\u9002\u7528\u4e8e\u66f4\u4e00\u822c\u7684\u5c40\u90e8\u8fde\u901a\u5ea6\u6709\u5411\u5316\u95ee\u9898\u3002\u7814\u7a76\u4e3a\u7f51\u7edc\u53ef\u9760\u6027\u76f8\u5173\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u4e0e\u9ad8\u6548\u5de5\u5177\u3002"}}
{"id": "2511.02491", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.02491", "abs": "https://arxiv.org/abs/2511.02491", "authors": ["Roland Meyer", "Jakob Tepe"], "title": "Oriented Metrics for Bottom-Up Enumerative Synthesis", "comment": "37 pages, 16 figures", "summary": "In syntax-guided synthesis, one of the challenges is to reduce the enormous\nsize of the search space. We observe that most search spaces are not just flat\nsets of programs, but can be endowed with a structure that we call an oriented\nmetric. Oriented metrics measure the distance between programs, like ordinary\nmetrics do, but are designed for settings in which operations have an\norientation. Our focus is on the string and the bitvector domains, where\noperations like concatenation and bitwise conjunction transform an input into\nan output in a way that is not symmetric. We develop several new oriented\nmetrics for these domains. Oriented metrics are designed for search space\nreduction, and we present four techniques: (i) pruning the search space to a\nball around the ground truth, (ii) factorizing the search space by an\nequivalence that is induced by the oriented metric, (iii) abstracting the\noriented metric (and hence the equivalence) and refining it, and (iv) improving\nthe enumeration order by learning from abstract information. We acknowledge\nthat these techniques are inspired by developments in the literature. By\nunderstanding their roots in oriented metrics, we can substantially increase\ntheir applicability and efficiency. We have integrated these techniques into a\nnew synthesis algorithm and implemented the algorithm in a new solver. Notably,\nour solver is generic in the oriented metric over which it computes. We\nconducted experiments in the string and the bitvector domains, and consistently\nimprove the performance over the state-of-the-art by more than an order of\nmagnitude.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u6709\u5411\u5ea6\u91cf\u7528\u4e8e\u7ea6\u675f\u8bed\u6cd5\u5f15\u5bfc\u5408\u6210\u4e2d\u7684\u641c\u7d22\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7\u591a\u6280\u672f\u96c6\u6210\u663e\u8457\u63d0\u5347\u641c\u7d22\u6548\u7387\uff0c\u5b9e\u9a8c\u8bc1\u660e\u65b0\u7b97\u6cd5\u8868\u73b0\u8fdc\u8d85\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u8bed\u6cd5\u5f15\u5bfc\u5408\u6210\u9762\u4e34\u641c\u7d22\u7a7a\u95f4\u5de8\u5927\u5bfc\u81f4\u7684\u6548\u7387\u74f6\u9888\uff0c\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u7a0b\u5e8f\u4e4b\u95f4\u7684\u7ed3\u6784\u6027\u8ddd\u79bb\uff0c\u5c24\u5176\u5728\u5b57\u7b26\u4e32\u548c\u4f4d\u5411\u91cf\u9886\u57df\u4e2d\u64cd\u4f5c\u5177\u6709\u65b9\u5411\u6027\u800c\u975e\u5bf9\u79f0\u6027\uff0c\u56e0\u6b64\u4e9f\u9700\u65b0\u65b9\u6cd5\u6765\u6709\u6548\u7ec4\u7ec7\u548c\u7ea6\u675f\u641c\u7d22\u7a7a\u95f4\u3002", "method": "\u5f00\u53d1\u4e86\u591a\u79cd\u9488\u5bf9\u5b57\u7b26\u4e32\u548c\u4f4d\u5411\u91cf\u9886\u57df\u7684\u65b0\u578b\u6709\u5411\u5ea6\u91cf\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u6709\u5411\u5ea6\u91cf\u7684\u56db\u79cd\u51cf\u5c11\u641c\u7d22\u7a7a\u95f4\u7684\u6280\u672f\uff1a\u641c\u7d22\u7a7a\u95f4\u526a\u679d\u3001\u7b49\u4ef7\u7c7b\u5206\u89e3\u3001\u5ea6\u91cf\u62bd\u8c61\u4e0e\u7ec6\u5316\u3001\u4ee5\u53ca\u57fa\u4e8e\u62bd\u8c61\u4fe1\u606f\u7684\u679a\u4e3e\u987a\u5e8f\u4f18\u5316\u3002\u5c06\u8fd9\u4e9b\u6280\u672f\u96c6\u6210\u5230\u65b0\u7684\u5408\u6210\u7b97\u6cd5\u53ca\u6c42\u89e3\u5668\u4e2d\uff0c\u8be5\u6c42\u89e3\u5668\u4ee5\u6709\u5411\u5ea6\u91cf\u4e3a\u901a\u7528\u6846\u67b6\u3002", "result": "\u5728\u5b57\u7b26\u4e32\u548c\u4f4d\u5411\u91cf\u9886\u57df\u8fdb\u884c\u5b9e\u9a8c\uff0c\u96c6\u6210\u4e86\u6709\u5411\u5ea6\u91cf\u7684\u7b97\u6cd5\u4e0e\u6c42\u89e3\u5668\u5728\u6027\u80fd\u4e0a\u7a33\u5b9a\u8d85\u8d8a\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u63d0\u5347\u5e45\u5ea6\u8d85\u8fc7\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u548c\u5229\u7528\u201c\u6709\u5411\u5ea6\u91cf\u201d\u7ed3\u6784\uff0c\u8fd9\u9879\u5de5\u4f5c\u5927\u5e45\u63d0\u9ad8\u4e86\u8bed\u6cd5\u5f15\u5bfc\u5408\u6210\u4e2d\u7684\u641c\u7d22\u6548\u7387\uff0c\u5b9e\u73b0\u4e86\u8d85\u8fc7\u73b0\u6709\u65b9\u6cd5\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2511.02595", "categories": ["cs.LO", "cs.PL", "F.3.3; F.4.1; D.3.3"], "pdf": "https://arxiv.org/pdf/2511.02595", "abs": "https://arxiv.org/abs/2511.02595", "authors": ["R\u00e9my Cerda"], "title": "Nominal Algebraic-Coalgebraic Data Types, with Applications to Infinitary Lambda-Calculi", "comment": "In Proceedings FICS 2024, arXiv:2511.00626", "summary": "Ten years ago, it was shown that nominal techniques can be used to design\ncoalgebraic data types with variable binding, so that alpha-equivalence classes\nof infinitary terms are directly endowed with a corecursion principle. We\nintroduce \"mixed\" binding signatures, as well as the corresponding type of\nmixed inductive-coinductive terms. We extend the aforementioned work to this\nsetting. In particular, this allows for a nominal description of the sets\nLambda_abc of abc-infinitary lambda-terms (for a, b, c in {0,1}) and of\ncapture-avoiding substitution on alpha-equivalence classes of such terms.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u540d\u4e49\u6570\u636e\u7c7b\u578b\u7406\u8bba\uff0c\u5f15\u5165\u6df7\u5408\u7ed1\u5b9a\u7b7e\u540d\u53ca\u6df7\u5408\u5f52\u7eb3-\u4f59\u5f52\u7eb3\u9879\u7c7b\u578b\uff0c\u4ece\u800c\u652f\u6301\u66f4\u590d\u6742\u7684\u65e0\u9650\u03bb\u9879\u53ca\u5176\u66ff\u6362\u64cd\u4f5c\u7684\u540d\u4e49\u63cf\u8ff0\u548c\u7ba1\u7406\u3002", "motivation": "\u6b64\u524d\u7684\u7814\u7a76\u8868\u660e\uff0c\u5229\u7528\u540d\u4e49\u6280\u5de7\u53ef\u4ee5\u8bbe\u8ba1\u5e26\u6709\u53d8\u91cf\u7ed1\u5b9a\u7684\u4f59\u4ee3\u6570\u6570\u636e\u7c7b\u578b\uff0c\u80fd\u591f\u5728\u65e0\u9650\u9879\u7684\u03b1-\u7b49\u4ef7\u7c7b\u4e0a\u76f4\u63a5\u5b9a\u4e49\u6838\u5fc3\u9012\u5f52\u539f\u5219\u3002\u4f46\u539f\u6709\u65b9\u6cd5\u9650\u4e8e\u5355\u4e00\u7ed1\u5b9a\u89c4\u5219\uff0c\u65e0\u6cd5\u5e94\u5bf9\u66f4\u590d\u6742\u7684\u7ed1\u5b9a\u573a\u666f\u3002\u672c\u6587\u52a8\u673a\u5728\u4e8e\u6269\u5c55\u540d\u4e49\u6280\u5de7\u7684\u5e94\u7528\uff0c\u8ba9\u5176\u652f\u6301\u6df7\u5408\u7ed1\u5b9a\u7b7e\u540d\uff0c\u4ee5\u9002\u5e94\u5982abc-\u65e0\u9650\u03bb\u9879\u7b49\u66f4\u590d\u6742\u7684\u7c7b\u578b\u548c\u64cd\u4f5c\u573a\u666f\u3002", "method": "\u5f15\u5165\u201c\u6df7\u5408\u7ed1\u5b9a\u7b7e\u540d\u201d\u548c\u5bf9\u5e94\u7684\u6df7\u5408\u5f52\u7eb3-\u4f59\u5f52\u7eb3\u9879\u7c7b\u578b\uff0c\u5728\u6b64\u6846\u67b6\u4e0b\u5c06\u4ee5\u5f80\u7684\u540d\u4e49\u6570\u636e\u7c7b\u578b\u7406\u8bba\u6269\u5c55\u5230\u80fd\u591f\u5904\u7406\u66f4\u590d\u6742\u7ed1\u5b9a\u7ed3\u6784\u7684\u573a\u666f\u3002", "result": "\u8be5\u65b9\u6cd5\u5141\u8bb8\u5bf9\u96c6\u5408Lambda_abc\uff08abc-\u65e0\u9650\u03bb\u9879\uff09\u7684\u540d\u4e49\u63cf\u8ff0\uff0c\u5e76\u80fd\u5728\u8fd9\u4e9b\u9879\u7684\u03b1-\u7b49\u4ef7\u7c7b\u4e0a\u5b9a\u4e49\u907f\u514d\u6355\u83b7\u7684\u66ff\u6362\u64cd\u4f5c\u3002\u8fd9\u6837\u5b9e\u73b0\u4e86\u5bf9\u590d\u6742\u65e0\u9650\u7ed3\u6784\u7684\u4e25\u683c\u548c\u6709\u6548\u8d4b\u503c\u5904\u7406\u3002", "conclusion": "\u901a\u8fc7\u6269\u5c55\u540d\u4e49\u6570\u636e\u7c7b\u578b\u7406\u8bba\u5230\u6df7\u5408\u7ed1\u5b9a\u548c\u6df7\u5408\u5f52\u7eb3-\u4f59\u5f52\u7eb3\u9879\uff0c\u672c\u6587\u5b9e\u73b0\u4e86\u5bf9\u590d\u6742\u65e0\u9650\u03bb\u9879\u7684\u03b1-\u7b49\u4ef7\u7c7b\u53ca\u5176\u6355\u83b7\u907f\u514d\u66ff\u6362\u64cd\u4f5c\u7684\u76f4\u63a5\u652f\u6301\uff0c\u63a8\u52a8\u4e86\u76f8\u5173\u9886\u57df\u6570\u636e\u7ed3\u6784\u7406\u8bba\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.02135", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.02135", "abs": "https://arxiv.org/abs/2511.02135", "authors": ["Joseph Suh", "Suhong Moon", "Serina Chang"], "title": "Rethinking LLM Human Simulation: When a Graph is What You Need", "comment": "Code: https://github.com/schang-lab/gems", "summary": "Large language models (LLMs) are increasingly used to simulate humans, with\napplications ranging from survey prediction to decision-making. However, are\nLLMs strictly necessary, or can smaller, domain-grounded models suffice? We\nidentify a large class of simulation problems in which individuals make choices\namong discrete options, where a graph neural network (GNN) can match or surpass\nstrong LLM baselines despite being three orders of magnitude smaller. We\nintroduce Graph-basEd Models for human Simulation (GEMS), which casts discrete\nchoice simulation tasks as a link prediction problem on graphs, leveraging\nrelational knowledge while incorporating language representations only when\nneeded. Evaluations across three key settings on three simulation datasets show\nthat GEMS achieves comparable or better accuracy than LLMs, with far greater\nefficiency, interpretability, and transparency, highlighting the promise of\ngraph-based modeling as a lightweight alternative to LLMs for human simulation.\nOur code is available at https://github.com/schang-lab/gems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGEMS\u6a21\u578b\uff0c\u901a\u8fc7\u56fe\u795e\u7ecf\u7f51\u7edc\u5b8c\u6210\u79bb\u6563\u9009\u62e9\u7c7b\u4eba\u7c7b\u884c\u4e3a\u6a21\u62df\u4efb\u52a1\uff0c\u6548\u679c\u4f18\u4e8e\u6216\u4e0d\u900a\u4e8eLLM\uff0c\u4e14\u6548\u7387\u66f4\u9ad8\uff0c\u662f\u4eba\u7c7b\u6a21\u62df\u9886\u57df\u7684\u6709\u524d\u666f\u7684\u8f7b\u91cf\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u88ab\u5e7f\u6cdb\u7528\u4e8e\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\uff0c\u4f46\u5176\u89c4\u6a21\u5e9e\u5927\uff0c\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u9ad8\u3002\u4f5c\u8005\u63d0\u51fa\u7591\u95ee\uff1a\u662f\u5426\u4e00\u5b9a\u9700\u8981LLM\uff0c\u6216\u8005\u66f4\u5c0f\u7684\u3001\u9886\u57df\u76f8\u5173\u6a21\u578b\u4e5f\u80fd\u5b8c\u6210\u7c7b\u4f3c\u4efb\u52a1\uff1f", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u7684\u6a21\u578bGEMS\uff0c\u5c06\u79bb\u6563\u9009\u62e9\u7684\u6a21\u62df\u4efb\u52a1\u8f6c\u5316\u4e3a\u56fe\u4e0a\u7684\u94fe\u8def\u9884\u6d4b\u95ee\u9898\uff0c\u5e76\u5728\u9700\u8981\u65f6\u7ed3\u5408\u8bed\u8a00\u8868\u5f81\u3002\u4e0eLLM\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u5728\u4e09\u79cd\u573a\u666f\u3001\u4e09\u4e2a\u6a21\u62df\u6570\u636e\u96c6\u4e0a\uff0cGEMS\u5728\u51c6\u786e\u7387\u4e0a\u53ef\u4e0eLLM\u5ab2\u7f8e\u751a\u81f3\u8d85\u8d8a\uff0c\u5e76\u4e14\u6548\u7387\u3001\u53ef\u89e3\u91ca\u6027\u548c\u900f\u660e\u6027\u66f4\u9ad8\u3002", "conclusion": "\u56fe\u795e\u7ecf\u7f51\u7edc\u4e3a\u4eba\u7c7b\u884c\u4e3a\u6a21\u62df\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u3001\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u65e0\u9700\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5373\u53ef\u83b7\u5f97\u9ad8\u8d28\u91cf\u6a21\u62df\u6548\u679c\u3002"}}
{"id": "2511.02596", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2511.02596", "abs": "https://arxiv.org/abs/2511.02596", "authors": ["Florian Bruse", "David Kronenberger", "Martin Lange"], "title": "Characterizing the Exponential-Space Hierarchy Via Partial Fixpoints", "comment": "In Proceedings FICS 2024, arXiv:2511.00626", "summary": "The characterization of PSPACE-queries over ordered structures as exactly\nthose expressible in first-order logic with partial fixpoints (Vardi'82) is one\nof the classical results in the field of descriptive complexity. In this paper,\nwe extend this result to characterizations of k-EXPSPACE-queries for arbitrary\nk, characterizing them as exactly those expressible in order-k+1-higher-order\nlogic with partial fixpoints. For k>1, the restriction to ordered structures is\nno longer necessary due to the high expressive power of higher-order logic.", "AI": {"tldr": "\u672c\u6587\u62d3\u5c55\u4e86PSPACE\u4e0e\u4e00\u9636\u90e8\u5206\u4e0d\u52a8\u70b9\u903b\u8f91\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u63d0\u51fa\u4efb\u610fk\u7684EXPSPACE\u67e5\u8be2\u53ef\u7528(k+1)-\u9636\u9ad8\u9636\u90e8\u5206\u4e0d\u52a8\u70b9\u903b\u8f91\u8868\u8fbe\uff0c\u5bf9\u9ad8\u9636\u60c5\u51b5\u65e0\u9700\u6709\u5e8f\u7ed3\u6784\u7ea6\u675f\uff0c\u6df1\u5316\u4e86\u590d\u6742\u6027\u4e0e\u903b\u8f91\u523b\u753b\u7406\u8bba\u3002", "motivation": "Vardi(1982)\u63d0\u51fa\u4e86PSPACE\u67e5\u8be2\u5728\u6709\u5e8f\u7ed3\u6784\u4e0a\u4e0e\u5177\u6709\u90e8\u5206\u4e0d\u52a8\u70b9\u7684\u4e00\u9636\u903b\u8f91\u4e4b\u95f4\u7684\u523b\u753b\u3002\u8fd9\u4e00\u7ed3\u679c\u5728\u63cf\u8ff0\u6027\u590d\u6742\u6027\u7406\u8bba\u9886\u57df\u5177\u6709\u5960\u57fa\u610f\u4e49\u3002\u672c\u6587\u65e8\u5728\u62d3\u5c55\u8fd9\u4e00\u7ecf\u5178\u7ed3\u679c\uff0c\u4e3a\u66f4\u9ad8\u590d\u6742\u5ea6\u7684k-EXPSPACE\u67e5\u8be2\u5bfb\u627e\u5bf9\u5e94\u7684\u903b\u8f91\u523b\u753b\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5316\u7684\u65b9\u6cd5\uff0c\u5c06\u66f4\u9ad8\u9636\u7684k-EXPSPACE\u67e5\u8be2\u4e0e\u5e26\u6709\u90e8\u5206\u4e0d\u52a8\u70b9\u7684(k+1)-\u9636\u9ad8\u9636\u903b\u8f91\u8fdb\u884c\u7b49\u4ef7\u523b\u753b\u3002\u7279\u522b\u5206\u6790\u4e86\u5f53k>1\u65f6\uff0c\u9ad8\u9636\u903b\u8f91\u7684\u8868\u8fbe\u80fd\u529b\u662f\u5426\u8fd8\u9700\u8981\u5bf9\u7ed3\u6784\u6709\u5e8f\u6027\u52a0\u4ee5\u9650\u5236\u3002", "result": "\u8bc1\u660e\u4e86\u4efb\u610fk\u7684k-EXPSPACE\u67e5\u8be2\u53ef\u4ee5\u6070\u597d\u901a\u8fc7\u5e26\u6709\u90e8\u5206\u4e0d\u52a8\u70b9\u7684(k+1)-\u9636\u9ad8\u9636\u903b\u8f91\u6765\u8868\u8fbe\u3002\u5f53k>1\u65f6\uff0c\u5f97\u76ca\u4e8e\u9ad8\u9636\u903b\u8f91\u5f3a\u5927\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u5bf9\u7ed3\u6784\u7684\u6709\u5e8f\u6027\u9650\u5236\u4e0d\u518d\u662f\u5fc5\u987b\u6761\u4ef6\u3002", "conclusion": "\u5c06\u63cf\u8ff0\u6027\u590d\u6742\u6027\u4e2d\u7684\u7ecf\u5178PSPACE\u523b\u753b\u6269\u5c55\u5230\u4efb\u610fk\u7684EXPSPACE\uff0c\u5efa\u7acb\u4e86\u4e0e\u9ad8\u9636\u903b\u8f91\u548c\u90e8\u5206\u4e0d\u52a8\u70b9\u7684\u65b0\u5bf9\u5e94\u5173\u7cfb\uff0c\u5e76\u6d88\u9664\u4e86\u5bf9\u7ed3\u6784\u6709\u5e8f\u6027\u7684\u90e8\u5206\u9650\u5236\uff0c\u4e30\u5bcc\u4e86\u590d\u6742\u6027\u4e0e\u903b\u8f91\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\u3002"}}
{"id": "2511.02213", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.02213", "abs": "https://arxiv.org/abs/2511.02213", "authors": ["Kangyu Qiao", "Shaolei Zhang", "Yang Feng"], "title": "IG-Pruning: Input-Guided Block Pruning for Large Language Models", "comment": "Accepted to EMNLP 2025. Code is available at\n  https://github.com/ictnlp/IG-Pruning", "summary": "With the growing computational demands of large language models (LLMs),\nefficient inference has become increasingly critical for practical deployment.\nDepth pruning has emerged as a promising approach for reducing the\ncomputational costs of large language models by removing transformer layers.\nHowever, existing methods typically rely on fixed block masks, which can lead\nto suboptimal performance across different tasks and inputs. In this paper, we\npropose IG-Pruning, a novel input-aware block-wise pruning method that\ndynamically selects layer masks at inference time. Our approach consists of two\nstages: (1) Discovering diverse mask candidates through semantic clustering and\nL0 optimization, and (2) Implementing efficient dynamic pruning without the\nneed for extensive training. Experimental results demonstrate that our method\nconsistently outperforms state-of-the-art static depth pruning methods, making\nit particularly suitable for resource-constrained deployment scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u5927\u91cf\u8bad\u7ec3\u5373\u53ef\u52a8\u6001\u526a\u679dTransformer\u5c42\u7684\u65b0\u65b9\u6cd5IG-Pruning\uff0c\u5728\u4fdd\u8bc1\u6548\u679c\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u5927\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\uff0c\u5bf9\u5b9e\u9645\u90e8\u7f72\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8ba1\u7b97\u9700\u6c42\u7684\u589e\u957f\uff0c\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u73b0\u6709\u7684\u6df1\u5ea6\u526a\u679d\u65b9\u6cd5\u591a\u91c7\u7528\u56fa\u5b9a\u7684\u5c42\uff08block\uff09\u63a9\u7801\uff0c\u96be\u4ee5\u9002\u5e94\u4e0d\u540c\u4efb\u52a1\u548c\u8f93\u5165\uff0c\u53ef\u80fd\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u65b0\u7684\u57fa\u4e8e\u8f93\u5165\u611f\u77e5\u7684\u5757\u7ea7\u526a\u679d\u65b9\u6cd5\uff08IG-Pruning\uff09\uff0c\u80fd\u5728\u63a8\u7406\u65f6\u52a8\u6001\u9009\u62e9\u5c42\u63a9\u7801\u3002\u65b9\u6cd5\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a\u901a\u8fc7\u8bed\u4e49\u805a\u7c7b\u548cL0\u4f18\u5316\u53d1\u73b0\u591a\u6837\u5316\u7684\u63a9\u7801\u5019\u9009\uff0c\u7136\u540e\u65e0\u9700\u5927\u91cf\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u52a8\u6001\u526a\u679d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u60c5\u51b5\u4e0b\u90fd\u4f18\u4e8e\u5f53\u524d\u4e3b\u6d41\u7684\u9759\u6001\u6df1\u5ea6\u526a\u679d\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "IG-Pruning\u5c55\u793a\u4e86\u52a8\u6001\u3001\u8f93\u5165\u611f\u77e5\u526a\u679d\u5728\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u6548\u7387\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u573a\u666f\u3002"}}
{"id": "2511.01941", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.01941", "abs": "https://arxiv.org/abs/2511.01941", "authors": ["Sogol Masoumzadeh"], "title": "Detecting Vulnerabilities from Issue Reports for Internet-of-Things", "comment": "ACCEPTED/To Appear in the Proceedings of the 40th IEEE/ACM\n  International Conference on Automated Software Engineering (ASE) 2025.\n  https://conf.researchr.org/details/ase-2025/ase-2025-student-research-competition/5/Detecting-Vulnerabilities-from-Issue-Reports-for-Internet-of-Things", "summary": "Timely identification of issue reports reflecting software vulnerabilities is\ncrucial, particularly for Internet-of-Things (IoT) where analysis is slower\nthan non-IoT systems. While Machine Learning (ML) and Large Language Models\n(LLMs) detect vulnerability-indicating issues in non-IoT systems, their IoT use\nremains unexplored. We are the first to tackle this problem by proposing two\napproaches: (1) combining ML and LLMs with Natural Language Processing (NLP)\ntechniques to detect vulnerability-indicating issues of 21 Eclipse IoT projects\nand (2) fine-tuning a pre-trained BERT Masked Language Model (MLM) on 11,000\nGitHub issues for classifying \\vul. Our best performance belongs to a Support\nVector Machine (SVM) trained on BERT NLP features, achieving an Area Under the\nreceiver operator characteristic Curve (AUC) of 0.65. The fine-tuned BERT\nachieves 0.26 accuracy, emphasizing the importance of exposing all data during\ntraining. Our contributions set the stage for accurately detecting IoT\nvulnerabilities from issue reports, similar to non-IoT systems.", "AI": {"tldr": "\u672c\u8bba\u6587\u9996\u6b21\u5c06\u673a\u5668\u5b66\u4e60\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8eIoT\u9879\u76ee\u6f0f\u6d1e\u95ee\u9898\u62a5\u544a\u68c0\u6d4b\uff0c\u63d0\u51fa\u4e86\u591a\u79cd\u6a21\u578b\u5e76\u9a8c\u8bc1\u5176\u6027\u80fd\uff0c\u4e3a\u672a\u6765IoT\u7cfb\u7edf\u5b89\u5168\u81ea\u52a8\u5316\u68c0\u6d4b\u94fa\u8def\u3002", "motivation": "\u5c3d\u65e9\u8bc6\u522b\u53cd\u6620\u8f6f\u4ef6\u6f0f\u6d1e\u7684\u95ee\u9898\u62a5\u544a\u5bf9\u4e8e\u7269\u8054\u7f51\uff08IoT\uff09\u7cfb\u7edf\u5c24\u5176\u91cd\u8981\uff0c\u56e0\u4e3a\u5bf9\u8fd9\u4e9b\u7cfb\u7edf\u7684\u5206\u6790\u5f80\u5f80\u6162\u4e8e\u975eIoT\u7cfb\u7edf\u3002\u867d\u7136\u673a\u5668\u5b66\u4e60\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5df2\u88ab\u7528\u4e8e\u975eIoT\u7cfb\u7edf\u6f0f\u6d1e\u68c0\u6d4b\uff0c\u4f46\u5728IoT\u9886\u57df\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u65b9\u6cd5\uff1a1\uff09\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u3001LLM\u4e0eNLP\u6280\u672f\uff0c\u68c0\u6d4b21\u4e2aEclipse IoT\u9879\u76ee\u7684\u95ee\u9898\u62a5\u544a\u4e2d\u7684\u6f0f\u6d1e\u6307\u793a\u4fe1\u606f\uff1b2\uff09\u572811,000\u6761GitHub\u95ee\u9898\u4e0a\u5fae\u8c03\u9884\u8bad\u7ec3\u7684BERT\u63a9\u7801\u8bed\u8a00\u6a21\u578b\uff08MLM\uff09\uff0c\u7528\u4e8e\u6f0f\u6d1e\u5206\u7c7b\u3002", "result": "\u57fa\u4e8eBERT NLP\u7279\u5f81\u7684\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u53d6\u5f97\u6700\u4f73\u6027\u80fd\uff0cAUC\u8fbe\u52300.65\u3002\u5fae\u8c03\u540e\u7684BERT\u6a21\u578b\u51c6\u786e\u7387\u4e3a0.26\uff0c\u5f3a\u8c03\u4e86\u8bad\u7ec3\u65f6\u5e94\u66b4\u9732\u5168\u90e8\u6570\u636e\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u63a2\u7d22\u7528ML\u4e0eLLM\u68c0\u6d4bIoT\u7cfb\u7edf\u6f0f\u6d1e\u76f8\u5173\u95ee\u9898\u62a5\u544a\uff0c\u4e3aIoT\u9886\u57df\u7684\u51c6\u786e\u6f0f\u6d1e\u68c0\u6d4b\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.02597", "categories": ["cs.LO", "F.4.1"], "pdf": "https://arxiv.org/pdf/2511.02597", "abs": "https://arxiv.org/abs/2511.02597", "authors": ["Leonardo Pacheco"], "title": "The mu-calculus' Alternation Hierarchy is Strict over Non-Trivial Fusion Logics", "comment": "In Proceedings FICS 2024, arXiv:2511.00626", "summary": "The modal mu-calculus is obtained by adding least and greatest fixed-point\noperators to modal logic. Its alternation hierarchy classifies the mu-formulas\nby their alternation depth: a measure of the codependence of their least and\ngreatest fixed-point operators. The mu-calculus' alternation hierarchy is\nstrict over the class of all Kripke frames: for all n, there is a mu-formula\nwith alternation depth n+1 which is not equivalent to any formula with\nalternation depth n. This does not always happen if we restrict the semantics.\nFor example, every mu-formula is equivalent to a formula without fixed-point\noperators over S5 frames. We show that the multimodal mu-calculus' alternation\nhierarchy is strict over non-trivial fusions of modal logics. We also comment\non two examples of multimodal logics where the mu-calculus collapses to modal\nlogic.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u591a\u6a21\u6001\u03bc-\u6f14\u7b97\u7684\u4ea4\u66ff\u5c42\u7ea7\u5728\u5927\u591a\u6570\u6a21\u6001\u903b\u8f91\u878d\u5408\u4e2d\u662f\u4e25\u683c\u7684\uff0c\u4f46\u5728\u5982S5\u7b49\u7279\u5b9a\u60c5\u51b5\u4f1a\u574d\u7f29\u4e3a\u666e\u901a\u6a21\u6001\u903b\u8f91\u3002", "motivation": "\u6a21\u6001\u03bc-\u6f14\u7b97\u662f\u4e00\u79cd\u901a\u8fc7\u5f15\u5165\u6700\u5c0f\u548c\u6700\u5927\u4e0d\u52a8\u70b9\u7b97\u5b50\u6269\u5c55\u6a21\u6001\u903b\u8f91\u7684\u5f62\u5f0f\u7cfb\u7edf\uff0c\u5176\u4ea4\u66ff\u5c42\u7ea7\u80fd\u53cd\u6620\u03bc-\u516c\u5f0f\u4e2d\u4e0d\u52a8\u70b9\u7b97\u5b50\u7684\u76f8\u4e92\u4f9d\u8d56\u7a0b\u5ea6\u3002\u7406\u89e3\u8fd9\u79cd\u5c42\u7ea7\u7684\u4e25\u683c\u6027\u5bf9\u4e8e\u523b\u753b\u4e0d\u540c\u903b\u8f91\u7cfb\u7edf\u7684\u8868\u8fbe\u80fd\u529b\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u4f5c\u8005\u5206\u6790\u4e86\u03bc-\u6f14\u7b97\u5728\u591a\u6a21\u6001\u60c5\u51b5\u4e0b\u7684\u4ea4\u66ff\u5c42\u7ea7\uff0c\u91cd\u70b9\u8ba8\u8bba\u4e86\u8be5\u5c42\u7ea7\u5728\u4e0d\u540c\u6a21\u6001\u903b\u8f91\u878d\u5408\u80cc\u666f\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u6bd4\u8f83\u4e86\u51e0\u79cd\u7279\u6b8a\u60c5\u5f62\uff08\u5982S5\u6846\u67b6\uff09\u4e0b\u03bc-\u6f14\u7b97\u5c42\u7ea7\u7684\u574d\u7f29\u73b0\u8c61\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u591a\u6a21\u6001\u03bc-\u6f14\u7b97\u7684\u4ea4\u66ff\u5c42\u7ea7\u5728\u975e\u5e73\u51e1\u7684\u6a21\u6001\u903b\u8f91\u878d\u5408\u4e0a\u662f\u4e25\u683c\u7684\u2014\u2014\u5373\u5bf9\u4e8e\u4efb\u610f\u5c42\u7ea7n\uff0c\u90fd\u5b58\u5728\u67d0\u4e00\u66f4\u9ad8\u5c42\u7ea7\u7684\u516c\u5f0f\u4e0d\u80fd\u7528\u8f83\u4f4e\u5c42\u7ea7\u516c\u5f0f\u8868\u8fbe\u3002\u540c\u65f6\u6307\u51fa\uff0c\u5728\u7279\u5b9a\u591a\u6a21\u6001\u903b\u8f91\uff08\u5982S5\uff09\u4e0b\uff0c\u03bc-\u6f14\u7b97\u53ef\u4ee5\u5b8c\u5168\u7b49\u4ef7\u4e8e\u65e0\u4e0d\u52a8\u70b9\u7b97\u5b50\u7684\u6a21\u6001\u903b\u8f91\u3002", "conclusion": "\u8be5\u7814\u7a76\u6269\u5c55\u4e86\u03bc-\u6f14\u7b97\u4ea4\u66ff\u5c42\u7ea7\u7684\u7406\u8bba\uff0c\u8bc1\u660e\u4e86\u5728\u66f4\u5e7f\u6cdb\u7684\u6a21\u6001\u903b\u8f91\u7ed3\u6784\u4e0b\u8be5\u5c42\u7ea7\u7684\u4e25\u683c\u6027\u3002\u8fd8\u5173\u6ce8\u4e86\u03bc-\u6f14\u7b97\u5728\u67d0\u4e9b\u7279\u6b8a\u7cfb\u7edf\u4e2d\u9000\u5316\u4e3a\u4f20\u7edf\u6a21\u6001\u903b\u8f91\u7684\u60c5\u5f62\u3002"}}
{"id": "2511.02246", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02246", "abs": "https://arxiv.org/abs/2511.02246", "authors": ["Jonathan Liu", "Haoling Qiu", "Jonathan Lasko", "Damianos Karakos", "Mahsa Yarmohammadi", "Mark Dredze"], "title": "Demo: Statistically Significant Results On Biases and Errors of LLMs Do Not Guarantee Generalizable Results", "comment": null, "summary": "Recent research has shown that hallucinations, omissions, and biases are\nprevalent in everyday use-cases of LLMs. However, chatbots used in medical\ncontexts must provide consistent advice in situations where non-medical factors\nare involved, such as when demographic information is present. In order to\nunderstand the conditions under which medical chatbots fail to perform as\nexpected, we develop an infrastructure that 1) automatically generates queries\nto probe LLMs and 2) evaluates answers to these queries using multiple\nLLM-as-a-judge setups and prompts. For 1), our prompt creation pipeline samples\nthe space of patient demographics, histories, disorders, and writing styles to\ncreate realistic questions that we subsequently use to prompt LLMs. In 2), our\nevaluation pipeline provides hallucination and omission detection using\nLLM-as-a-judge as well as agentic workflows, in addition to LLM-as-a-judge\ntreatment category detectors. As a baseline study, we perform two case studies\non inter-LLM agreement and the impact of varying the answering and evaluation\nLLMs. We find that LLM annotators exhibit low agreement scores (average Cohen's\nKappa $\\kappa=0.118$), and only specific (answering, evaluation) LLM pairs\nyield statistically significant differences across writing styles, genders, and\nraces. We recommend that studies using LLM evaluation use multiple LLMs as\nevaluators in order to avoid arriving at statistically significant but\nnon-generalizable results, particularly in the absence of ground-truth data. We\nalso suggest publishing inter-LLM agreement metrics for transparency. Our code\nand dataset are available here:\nhttps://github.com/BBN-E/medic-neurips-2025-demo.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u81ea\u52a8\u5316\u7cfb\u7edf\u63a2\u6d4b\u533b\u7597\u573a\u666f\u4e0bLLM\u5e7b\u89c9\u548c\u504f\u89c1\uff0c\u53d1\u73b0\u4e0d\u540cLLM\u8bc4\u5ba1\u4e0d\u4e00\u81f4\uff0c\u5efa\u8bae\u591a\u6a21\u578b\u8054\u5408\u8bc4\u4f30\u4e0e\u516c\u5f00\u4e00\u81f4\u6027\u6570\u636e\u3002\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u5f00\u6e90\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u65e5\u5e38\u5e94\u7528\u4e2d\u5e38\u89c1\u5e7b\u89c9\u3001\u758f\u6f0f\u4ee5\u53ca\u504f\u89c1\uff0c\u4f46\u5728\u533b\u7597\u573a\u666f\u4e0b\uff0c\u5c24\u5176\u6d89\u53ca\u60a3\u8005\u4eba\u53e3\u7edf\u8ba1\u7b49\u975e\u533b\u7597\u56e0\u7d20\u65f6\uff0c\u5fc5\u987b\u4fdd\u8bc1\u5efa\u8bae\u7684\u4e00\u81f4\u6027\u548c\u516c\u6b63\u6027\u3002\u4e3a\u63a2\u67e5LLM\u5728\u533b\u7597\u573a\u666f\u4e0b\u5931\u6548\u7684\u5177\u4f53\u6761\u4ef6\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u65b0\u7684\u63a2\u7d22\u65b9\u6cd5\u3002", "method": "\u8be5\u8bba\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u7840\u8bbe\u65bd\uff1a1\uff09\u81ea\u52a8\u751f\u6210\u7528\u4e8e\u63a2\u67e5LLM\u53cd\u5e94\u7684\u67e5\u8be2\u95ee\u9898\uff0c2\uff09\u901a\u8fc7\u591a\u79cdLLM\u62c5\u4efb\u8bc4\u5ba1\u548c\u4e0d\u540c\u63d0\u793a\u8bcd\uff0c\u8bc4\u4f30\u8fd9\u4e9b\u7b54\u6848\u3002\u751f\u6210\u95ee\u9898\u65f6\uff0c\u7cfb\u7edf\u4f1a\u7efc\u5408\u62bd\u6837\u60a3\u8005\u7684\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u3001\u75c5\u53f2\u3001\u75be\u75c5\u53ca\u5199\u4f5c\u98ce\u683c\u4ee5\u6784\u5efa\u771f\u5b9e\u95ee\u9898\u3002\u8bc4\u4f30\u6d41\u7a0b\u63d0\u4f9b\u57fa\u4e8eLLM\u62c5\u4efb\u88c1\u5224\u7684\u5e7b\u89c9\u4e0e\u758f\u6f0f\u68c0\u6d4b\u3001\u4ee3\u7406\u5f0f\u5de5\u4f5c\u6d41\uff0c\u4ee5\u53caLLM\u62c5\u4efb\u7684\u6cbb\u7597\u7c7b\u522b\u68c0\u6d4b\u5668\u3002", "result": "\u5b9e\u8bc1\u5206\u6790\u663e\u793a\uff0c\u4e0d\u540c\u7684LLM\u8bc4\u5ba1\u8005\u4e4b\u95f4\u4e00\u81f4\u6027\u5f88\u4f4e\uff08Cohen's Kappa\u5e73\u5747\u4ec5\u4e3a0.118\uff09\uff0c\u4e14\u53ea\u6709\u7279\u6b8a\u7684\u201c\u95ee\u7b54-\u8bc4\u4f30\u201dLLM\u7ec4\u5408\u5728\u5199\u4f5c\u98ce\u683c\u3001\u6027\u522b\u3001\u79cd\u65cf\u7b49\u5206\u7ec4\u4e0b\u663e\u793a\u51fa\u7edf\u8ba1\u663e\u8457\u5dee\u5f02\u3002\u7ed3\u8bba\u5efa\u8bae\u8bc4\u4f30\u7814\u7a76\u5e94\u540c\u65f6\u91c7\u7528\u591a\u4e2aLLM\u4f5c\u4e3a\u8bc4\u5ba1\u8005\uff0c\u5e76\u53d1\u5e03LLM\u95f4\u4e00\u81f4\u6027\u6307\u6807\uff0c\u4ee5\u63d0\u5347\u900f\u660e\u5ea6\u5e76\u907f\u514d\u56e0\u7f3a\u5931\u771f\u5b9e\u6807\u7b7e\u5bfc\u81f4\u7684\u4e0d\u5177\u6cdb\u5316\u6027\u7684\u663e\u8457\u7ed3\u8bba\u3002", "conclusion": "LLM\u4f5c\u4e3a\u533b\u7597\u95ee\u7b54\u8bc4\u5224\u8005\u5728\u5e7b\u89c9\u548c\u758f\u6f0f\u68c0\u6d4b\u4e0a\u7684\u4e00\u81f4\u6027\u8f83\u5dee\uff0c\u7814\u7a76\u5e94\u7efc\u5408\u591a\u79cdLLM\u8bc4\u5ba1\uff0c\u516c\u5f00\u8bc4\u5ba1\u4e00\u81f4\u6027\u7ed3\u679c\uff0c\u4ee5\u907f\u514d\u5f97\u51fa\u8bef\u5bfc\u6027\u7ed3\u8bba\u3002"}}
{"id": "2511.02108", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02108", "abs": "https://arxiv.org/abs/2511.02108", "authors": ["Steven Cho", "Stefano Ruberto", "Valerio Terragni"], "title": "Metamorphic Testing of Large Language Models for Natural Language Processing", "comment": null, "summary": "Using large language models (LLMs) to perform natural language processing\n(NLP) tasks has become increasingly pervasive in recent times. The versatile\nnature of LLMs makes them applicable to a wide range of such tasks. While the\nperformance of recent LLMs is generally outstanding, several studies have shown\nthat they can often produce incorrect results. Automatically identifying these\nfaulty behaviors is extremely useful for improving the effectiveness of LLMs.\nOne obstacle to this is the limited availability of labeled datasets, which\nnecessitates an oracle to determine the correctness of LLM behaviors.\nMetamorphic testing (MT) is a popular testing approach that alleviates this\noracle problem. At the core of MT are metamorphic relations (MRs), which define\nrelationships between the outputs of related inputs. MT can expose faulty\nbehaviors without the need for explicit oracles (e.g., labeled datasets). This\npaper presents the most comprehensive study of MT for LLMs to date. We\nconducted a literature review and collected 191 MRs for NLP tasks. We\nimplemented a representative subset (36 MRs) to conduct a series of experiments\nwith three popular LLMs, running approximately 560,000 metamorphic tests. The\nresults shed light on the capabilities and opportunities of MT for LLMs, as\nwell as its limitations.", "AI": {"tldr": "\u672c\u8bba\u6587\u7cfb\u7edf\u6027\u5730\u8bba\u8bc1\u4e86\u53d8\u5f62\u6d4b\u8bd5\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u884c\u4e3a\u8bc6\u522b\u4e2d\u7684\u5e94\u7528\u4ef7\u503c\uff0c\u901a\u8fc7\u5e7f\u6cdb\u6587\u732e\u7efc\u8ff0\u548c\u5927\u89c4\u6a21\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u53ca\u4e0d\u8db3\u4e4b\u5904\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u79c0\uff0c\u4f46\u5e38\u5e38\u51fa\u73b0\u9519\u8bef\u7ed3\u679c\u3002\u81ea\u52a8\u8bc6\u522b\u8fd9\u4e9b\u9519\u8bef\u884c\u4e3a\u5bf9\u4e8e\u63d0\u5347LLMs\u7684\u6709\u6548\u6027\u975e\u5e38\u91cd\u8981\u3002\u7136\u800c\uff0c\u53d7\u9650\u4e8e\u6807\u6ce8\u6570\u636e\u96c6\u7684\u7a00\u7f3a\uff0c\u5224\u65adLLMs\u7ed3\u679c\u6b63\u786e\u4e0e\u5426\u53d8\u5f97\u56f0\u96be\uff0c\u9700\u8981\u65b0\u7684\u6d4b\u8bd5\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "\u91c7\u7528\u53d8\u5f62\u6d4b\u8bd5\uff08Metamorphic Testing, MT\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u51fa\u548c\u5206\u6790\u53d8\u5f62\u5173\u7cfb\uff08MRs\uff09\u5728\u6ca1\u6709\u660e\u786e\u6807\u7b7e\u6570\u636e\u96c6\u7684\u60c5\u51b5\u4e0b\u81ea\u52a8\u8bc4\u4f30LLMs\u884c\u4e3a\u3002\u8bba\u6587\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\uff0c\u6536\u96c6\u4e86191\u79cd\u7528\u4e8eNLP\u4efb\u52a1\u7684MR\uff0c\u5e76\u9009\u53d636\u79cd\u4ee3\u8868\u6027MR\u5728\u4e09\u4e2a\u4e3b\u6d41LLM\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6d4b\u8bd5\u7ea656\u4e07\u6b21\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e86\u53d8\u5f62\u6d4b\u8bd5\u65b9\u6cd5\u5728LLMs\u5e94\u7528\u4e2d\u7684\u80fd\u529b\u548c\u673a\u4f1a\uff0c\u540c\u65f6\u4e5f\u6307\u51fa\u4e86\u5176\u5c40\u9650\u6027\u3002", "conclusion": "\u8bba\u6587\u8868\u660e\uff0c\u53d8\u5f62\u6d4b\u8bd5\u662f\u4e00\u79cd\u975e\u5e38\u6709\u4ef7\u503c\u7684\u3001\u53ef\u5e94\u7528\u4e8e\u65e0\u6807\u7b7e\u6570\u636e\u96c6\u73af\u5883\u4e0b\u8bc4\u4f30LLMs\u8868\u73b0\u7684\u65b9\u6cd5\uff0c\u4f46\u4e5f\u9700\u8981\u5173\u6ce8\u5176\u5c40\u9650\u6027\u3002"}}
{"id": "2511.02347", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.02347", "abs": "https://arxiv.org/abs/2511.02347", "authors": ["Liuhao Lin", "Ke Li", "Zihan Xu", "Yuchen Shi", "Yulei Qin", "Yan Zhang", "Xing Sun", "Rongrong Ji"], "title": "LTD-Bench: Evaluating Large Language Models by Letting Them Draw", "comment": "Accepted by NeurIPS 2025", "summary": "Current evaluation paradigms for large language models (LLMs) represent a\ncritical blind spot in AI research--relying on opaque numerical metrics that\nconceal fundamental limitations in spatial reasoning while providing no\nintuitive understanding of model capabilities. This deficiency creates a\ndangerous disconnect between reported performance and practical abilities,\nparticularly for applications requiring physical world understanding. We\nintroduce LTD-Bench, a breakthrough benchmark that transforms LLM evaluation\nfrom abstract scores to directly observable visual outputs by requiring models\nto generate drawings through dot matrices or executable code. This approach\nmakes spatial reasoning limitations immediately apparent even to non-experts,\nbridging the fundamental gap between statistical performance and intuitive\nassessment. LTD-Bench implements a comprehensive methodology with complementary\ngeneration tasks (testing spatial imagination) and recognition tasks (assessing\nspatial perception) across three progressively challenging difficulty levels,\nmethodically evaluating both directions of the critical language-spatial\nmapping. Our extensive experiments with state-of-the-art models expose an\nalarming capability gap: even LLMs achieving impressive results on traditional\nbenchmarks demonstrate profound deficiencies in establishing bidirectional\nmappings between language and spatial concept--a fundamental limitation that\nundermines their potential as genuine world models. Furthermore, LTD-Bench's\nvisual outputs enable powerful diagnostic analysis, offering a potential\napproach to investigate model similarity.", "AI": {"tldr": "\u63d0\u51faLTD-Bench\uff0c\u5c06\u5927\u6a21\u578b\u8bc4\u4f30\u7531\u62bd\u8c61\u5206\u6570\u8f6c\u4e3a\u53ef\u89c6\u5316\u8f93\u51fa\uff0c\u663e\u8457\u63ed\u793a\u5176\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8AI\u6a21\u578b\u8bc4\u4f30\u65b9\u5f0f\u9769\u65b0\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u65b9\u5f0f\u4f9d\u8d56\u4e8e\u4e0d\u900f\u660e\u7684\u6570\u503c\u6307\u6807\uff0c\u8fd9\u63a9\u76d6\u4e86\u6a21\u578b\u5728\u7a7a\u95f4\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e14\u65e0\u6cd5\u76f4\u89c2\u7406\u89e3\u6a21\u578b\u80fd\u529b\u3002\u8fd9\u6837\u7684\u7f3a\u9677\u5bfc\u81f4\u6a21\u578b\u5b9e\u9645\u80fd\u529b\u4e0e\u62a5\u544a\u7ed3\u679c\u5b58\u5728\u91cd\u5927\u8131\u8282\uff0c\u5c24\u5176\u5728\u9700\u8981\u7269\u7406\u4e16\u754c\u7406\u89e3\u7684\u5e94\u7528\u573a\u666f\u4e0b\u53ef\u80fd\u5e26\u6765\u4e25\u91cd\u540e\u679c\u3002", "method": "\u63d0\u51faLTD-Bench\u57fa\u51c6\uff0c\u901a\u8fc7\u8ba9\u6a21\u578b\u751f\u6210\u70b9\u9635\u7ed8\u56fe\u6216\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u5c06\u8bc4\u4f30\u4ece\u62bd\u8c61\u5206\u6570\u8f6c\u5411\u53ef\u89c6\u5316\u8f93\u51fa\u3002\u57fa\u51c6\u5305\u542b\u751f\u6210\u4efb\u52a1\uff08\u6d4b\u8bd5\u7a7a\u95f4\u60f3\u8c61\u529b\uff09\u548c\u8bc6\u522b\u4efb\u52a1\uff08\u8bc4\u4f30\u7a7a\u95f4\u611f\u77e5\uff09\uff0c\u6db5\u76d6\u4e09\u79cd\u6e10\u8fdb\u96be\u5ea6\uff0c\u5168\u9762\u8003\u5bdf\u8bed\u8a00-\u7a7a\u95f4\u53cc\u5411\u6620\u5c04\u80fd\u529b\u3002", "result": "\u7528LTD-Bench\u5bf9\u4e3b\u6d41\u6a21\u578b\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u53d1\u73b0\u5b83\u4eec\u867d\u7136\u5728\u4f20\u7edf\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u8bed\u8a00\u4e0e\u7a7a\u95f4\u6982\u5ff5\u7684\u53cc\u5411\u6620\u5c04\u4e0a\u4ecd\u5b58\u5728\u660e\u663e\u80fd\u529b\u7f3a\u53e3\uff0c\u8fd9\u4e25\u91cd\u5f71\u54cd\u4e86\u5b83\u4eec\u4f5c\u4e3a\u771f\u5b9e\u4e16\u754c\u6a21\u578b\u7684\u6f5c\u529b\u3002", "conclusion": "LTD-Bench\u80fd\u76f4\u89c2\u66b4\u9732\u5927\u6a21\u578b\u5728\u7a7a\u95f4\u63a8\u7406\u4e0a\u7684\u6839\u672c\u4e0d\u8db3\uff0c\u4e3a\u6a21\u578b\u80fd\u529b\u7684\u611f\u6027\u8bc4\u4f30\u63d0\u4f9b\u5de5\u5177\uff0c\u5e76\u6709\u52a9\u4e8e\u6df1\u5165\u8bca\u65ad\u548c\u5206\u6790\u6a21\u578b\u7684\u5f02\u540c\uff0c\u63a8\u52a8\u66f4\u6709\u6548\u7684AI\u8bc4\u4f30\u53d1\u5c55\u3002"}}
{"id": "2511.02197", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02197", "abs": "https://arxiv.org/abs/2511.02197", "authors": ["Shufan Wang", "Xing Hu", "Junkai Chen", "Zhiyuan Pan", "Xin Xia"], "title": "Open the Oyster: Empirical Evaluation and Improvement of Code Reasoning Confidence in LLMs", "comment": "13 pages, 4 figures", "summary": "With the widespread application of large language models (LLMs) in the field\nof code intelligence, increasing attention has been paid to the reliability and\ncontrollability of their outputs in code reasoning tasks. Confidence estimation\nserves as an effective and convenient approach for evaluating these aspects.\nThis paper proposes a confidence analysis and enhancement framework for LLMs\ntailored to code reasoning tasks. We conduct a comprehensive empirical study on\nthe confidence reliability of mainstream LLMs across different tasks, and\nfurther evaluate the effectiveness of techniques such as prompt strategy\noptimisation and mathematical calibration (e.g., Platt Scaling) in improving\nconfidence reliability. Our results show that DeepSeek-Reasoner achieves the\nbest performance across various tasks, outperforming other models by up to\n$0.680$, $0.636$, and $13.652$ in terms of ECE, Brier Score, and Performance\nScore, respectively. The hybrid strategy combining the reassess prompt strategy\nand Platt Scaling achieves improvements of up to $0.541$, $0.628$, and $15.084$\nover the original performance in the aforementioned three metrics. These\nresults indicate that models with reasoning capabilities demonstrate superior\nconfidence reliability, and that the hybrid strategy is the most effective in\nenhancing the confidence reliability of various models. Meanwhile, we elucidate\nthe impact of different task complexities, model scales, and strategies on\nconfidence performance, and highlight that the confidence of current LLMs in\ncomplex reasoning tasks still has considerable room for improvement. This study\nnot only provides a research foundation and technical reference for the\napplication of confidence in LLM-assisted software engineering, but also points\nthe way for future optimisation and engineering deployment of confidence\nmechanisms.", "AI": {"tldr": "\u672c\u8bba\u6587\u9488\u5bf9\u4ee3\u7801\u63a8\u7406\u4efb\u52a1\uff0c\u63d0\u51fa\u4e86\u4e00\u5957\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7f6e\u4fe1\u5ea6\u5206\u6790\u4e0e\u589e\u5f3a\u6846\u67b6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4e3b\u6d41\u6a21\u578b\u7684\u7f6e\u4fe1\u5ea6\u53ef\u9760\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e86\u7b56\u7565\u4f18\u5316\u4e0e\u6570\u5b66\u6821\u51c6\u7684\u6709\u6548\u6027\u3002\u5b9e\u9a8c\u8bc1\u660eDeepSeek-Reasoner\u53ca\u590d\u5408\u589e\u5f3a\u7b56\u7565\u8868\u73b0\u7a81\u51fa\uff0c\u5e76\u63ed\u793a\u7f6e\u4fe1\u5ea6\u63d0\u5347\u7684\u5de5\u7a0b\u4e0e\u7814\u7a76\u4ef7\u503c\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u667a\u80fd\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u5728\u4ee3\u7801\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8f93\u51fa\u53ef\u9760\u6027\u548c\u53ef\u63a7\u6027\u8d8a\u6765\u8d8a\u53d7\u5230\u5173\u6ce8\u3002\u4fe1\u5fc3\u4f30\u8ba1\u88ab\u8ba4\u4e3a\u662f\u8bc4\u4f30\u8fd9\u4e9b\u6027\u80fd\u7684\u6709\u6548\u9014\u5f84\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u4e13\u4e3a\u4ee3\u7801\u63a8\u7406\u4efb\u52a1\u8bbe\u8ba1\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4fe1\u5fc3\u5206\u6790\u4e0e\u589e\u5f3a\u6846\u67b6\uff1b\u5bf9\u4e3b\u6d41\u6a21\u578b\u5728\u4e0d\u540c\u4efb\u52a1\u4e0b\u7684\u7f6e\u4fe1\u5ea6\u53ef\u9760\u6027\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u5e76\u8bc4\u4f30\u63d0\u793a\u7b56\u7565\u4f18\u5316\u548c\u6570\u5b66\u6821\u51c6\uff08\u5982Platt Scaling\uff09\u7b49\u6280\u672f\u63d0\u5347\u7f6e\u4fe1\u5ea6\u53ef\u9760\u6027\u7684\u6548\u679c\u3002", "result": "DeepSeek-Reasoner\u5728\u5404\u9879\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u76f8\u6bd4\u5176\u4ed6\u6a21\u578b\u5728ECE\u3001Brier\u5206\u6570\u548c\u6027\u80fd\u5206\u6570\u65b9\u9762\u5206\u522b\u63d0\u5347\u4e860.680\u30010.636\u548c13.652\u3002\u7ed3\u5408\u518d\u8bc4\u4f30\u63d0\u793a\u7b56\u7565\u4e0ePlatt Scaling\u7684\u6df7\u5408\u7b56\u7565\u5728\u4e0a\u8ff0\u4e09\u9879\u6307\u6807\u4e0a\u5bf9\u539f\u59cb\u6027\u80fd\u5206\u522b\u63d0\u5347\u4e860.541\u30010.628\u548c15.084\u3002\u63a8\u7406\u80fd\u529b\u5f3a\u7684\u6a21\u578b\u5177\u6709\u66f4\u597d\u7684\u7f6e\u4fe1\u5ea6\u53ef\u9760\u6027\uff0c\u6df7\u5408\u7b56\u7565\u5728\u589e\u5f3a\u7f6e\u4fe1\u5ea6\u53ef\u9760\u6027\u4e0a\u6700\u4e3a\u6709\u6548\u3002", "conclusion": "\u4e0d\u540c\u4efb\u52a1\u590d\u6742\u5ea6\u3001\u6a21\u578b\u89c4\u6a21\u53ca\u7b56\u7565\u660e\u663e\u5f71\u54cd\u6a21\u578b\u7f6e\u4fe1\u5ea6\u8868\u73b0\uff0c\u76ee\u524d\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u7f6e\u4fe1\u5ea6\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\u3002\u672c\u7814\u7a76\u4e3aLLM\u8f85\u52a9\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u7f6e\u4fe1\u5ea6\u673a\u5236\u5e94\u7528\u63d0\u4f9b\u4e86\u6280\u672f\u53c2\u8003\uff0c\u4e5f\u4e3a\u672a\u6765\u4f18\u5316\u548c\u5de5\u7a0b\u90e8\u7f72\u63d0\u51fa\u4e86\u65b9\u5411\u3002"}}
{"id": "2511.02358", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.02358", "abs": "https://arxiv.org/abs/2511.02358", "authors": ["Wongyu Kim", "Hochang Lee", "Sanghak Lee", "Yoonsung Kim", "Jaehyun Park"], "title": "Let Multimodal Embedders Learn When to Augment Query via Adaptive Query Augmentation", "comment": "Accepted to MMGenSR Workshop (CIKM 2025)", "summary": "Query augmentation makes queries more meaningful by appending further\ninformation to the queries to find relevant documents. Current studies have\nproposed Large Language Model (LLM)-based embedders, which learn representation\nfor embedding and generation for query augmentation in a multi-task manner by\nleveraging the generative capabilities of LLM. During inference, these jointly\ntrained embedders have conducted query augmentation followed by embedding,\nshowing effective results. However, augmenting every query leads to substantial\nembedding latency and query augmentation can be detrimental to performance for\nsome queries. Also, previous methods have not been explored in multimodal\nenvironments. To tackle these problems, we propose M-Solomon, a universal\nmultimodal embedder that can adaptively determine when to augment queries. Our\napproach first divides the queries of the training datasets into two groups at\nthe dataset level. One includes queries that require augmentation and the other\nincludes queries that do not. Then, we introduces a synthesis process that\ngenerates appropriate augmentations for queries that require them by leveraging\na powerful Multimodal LLM (MLLM). Next, we present adaptive query augmentation.\nThrough this step, M-Solomon can conduct query augmentation only when necessary\nby learning to generate synthetic augmentations with the prefix /augment for\nqueries that demand them and to generate the simple string /embed for others.\nExperimental results showed that M-Solomon not only surpassed the baseline\nwithout augmentation by a large margin but also outperformed the baseline that\nalways used augmentation, providing much faster embedding latency.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u67e5\u8be2\u6269\u5c55\u5e26\u6765\u7684\u5ef6\u8fdf\u548c\u6027\u80fd\u8d1f\u9762\u5f71\u54cd\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u53ef\u81ea\u9002\u5e94\u5224\u65ad\u662f\u5426\u9700\u8981\u6269\u5c55\u7684\u591a\u6a21\u6001\u5d4c\u5165\u6a21\u578bM-Solomon\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u68c0\u7d22\u6027\u80fd\u548c\u66f4\u4f4e\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u6709\u7684\u67e5\u8be2\u6269\u5c55\u65b9\u6cd5\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u591a\u4efb\u52a1\u8bad\u7ec3\uff0c\u540c\u65f6\u8fdb\u884c\u5d4c\u5165\u548c\u751f\u6210\uff0c\u53ef\u4ee5\u63d0\u5347\u67e5\u8be2\u8d28\u91cf\u3002\u4f46\u6240\u6709\u67e5\u8be2\u90fd\u8fdb\u884c\u6269\u5c55\u4f1a\u663e\u8457\u589e\u52a0\u5ef6\u8fdf\uff0c\u5e76\u4e14\u5bf9\u4e8e\u90e8\u5206\u67e5\u8be2\u53cd\u800c\u964d\u4f4e\u6027\u80fd\u3002\u6b64\u5916\uff0c\u4e4b\u524d\u7684\u65b9\u6cd5\u5728\u591a\u6a21\u6001\u573a\u666f\u4e0b\u7814\u7a76\u8f83\u5c11\u3002", "method": "\u63d0\u51fa\u4e86M-Solomon\uff0c\u4e00\u79cd\u901a\u7528\u7684\u591a\u6a21\u6001\u5d4c\u5165\u6a21\u578b\uff0c\u53ef\u4ee5\u81ea\u9002\u5e94\u5730\u5224\u65ad\u4f55\u65f6\u5bf9\u67e5\u8be2\u8fdb\u884c\u6269\u5c55\u3002\u8bad\u7ec3\u9636\u6bb5\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u67e5\u8be2\u5206\u4e3a\u9700\u8981\u6269\u5c55\u548c\u4e0d\u9700\u8981\u6269\u5c55\u4e24\u7ec4\uff0c\u5bf9\u9700\u6269\u5c55\u7684\u67e5\u8be2\u901a\u8fc7\u5f3a\u5927\u7684\u591a\u6a21\u6001LLM\u5408\u6210\u9002\u5f53\u7684\u6269\u5c55\u5185\u5bb9\u3002\u63a8\u7406\u9636\u6bb5\uff0c\u6a21\u578b\u901a\u8fc7\u751f\u6210/augment\u6216/embed\u524d\u7f00\uff0c\u51b3\u5b9a\u662f\u5426\u8fdb\u884c\u6269\u5c55\uff0c\u4ece\u800c\u5b9e\u73b0\u9002\u5e94\u6027\u67e5\u8be2\u6269\u5c55\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cM-Solomon\u4e0d\u4ec5\u5927\u5e45\u8d85\u8d8a\u4e86\u65e0\u6269\u5c55\u7684\u57fa\u7ebf\uff0c\u8fd8\u4f18\u4e8e\u59cb\u7ec8\u6269\u5c55\u7684\u57fa\u7ebf\uff0c\u540c\u65f6\u5927\u5e45\u63d0\u5347\u4e86\u5d4c\u5165\u5ef6\u8fdf\u3002", "conclusion": "M-Solomon\u6709\u6548\u5b9e\u73b0\u4e86\u81ea\u9002\u5e94\u3001\u5feb\u901f\u7684\u591a\u6a21\u6001\u67e5\u8be2\u6269\u5c55\u548c\u5d4c\u5165\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2511.02203", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.02203", "abs": "https://arxiv.org/abs/2511.02203", "authors": ["Gerhard Yu", "Mithila Sivakumar", "Alvine B. Belle", "Soude Ghari", "Song Wang", "Timothy C. Lethbridge"], "title": "LLMs as Judges: Toward The Automatic Review of GSN-compliant Assurance Cases", "comment": null, "summary": "Assurance cases allow verifying the correct implementation of certain\nnon-functional requirements of mission-critical systems, including their\nsafety, security, and reliability. They can be used in the specification of\nautonomous driving, avionics, air traffic control, and similar systems. They\naim to reduce risks of harm of all kinds including human mortality,\nenvironmental damage, and financial loss. However, assurance cases often tend\nto be organized as extensive documents spanning hundreds of pages, making their\ncreation, review, and maintenance error-prone, time-consuming, and tedious.\nTherefore, there is a growing need to leverage (semi-)automated techniques,\nsuch as those powered by generative AI and large language models (LLMs), to\nenhance efficiency, consistency, and accuracy across the entire assurance-case\nlifecycle. In this paper, we focus on assurance case review, a critical task\nthat ensures the quality of assurance cases and therefore fosters their\nacceptance by regulatory authorities. We propose a novel approach that\nleverages the \\textit{LLM-as-a-judge} paradigm to automate the review process.\nSpecifically, we propose new predicate-based rules that formalize\nwell-established assurance case review criteria, allowing us to craft LLM\nprompts tailored to the review task. Our experiments on several\nstate-of-the-art LLMs (GPT-4o, GPT-4.1, DeepSeek-R1, and Gemini 2.0 Flash) show\nthat, while most LLMs yield relatively good review capabilities, DeepSeek-R1\nand GPT-4.1 demonstrate superior performance, with DeepSeek-R1 ultimately\noutperforming GPT-4.1. However, our experimental results also suggest that\nhuman reviewers are still needed to refine the reviews LLMs yield.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5ba1\u67e5\u5173\u952e\u7cfb\u7edf\u4fdd\u969c\u6848\u4f8b\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u4ee5DeepSeek-R1\u7b49\u6a21\u578b\u5b9e\u6d4b\uff0c\u53d1\u73b0AI\u53ef\u663e\u8457\u63d0\u5347\u5ba1\u67e5\u6548\u7387\uff0c\u4f46\u76ee\u524d\u4ecd\u9700\u4eba\u5de5\u4fee\u6b63\uff0c\u4e0d\u80fd\u5b8c\u5168\u66ff\u4ee3\u4eba\u7c7b\u5ba1\u67e5\u3002", "motivation": "\u9ad8\u98ce\u9669\u7cfb\u7edf\uff08\u5982\u81ea\u52a8\u9a7e\u9a76\u3001\u822a\u7a7a\u7535\u5b50\u3001\u7a7a\u4e2d\u4ea4\u901a\u63a7\u5236\u7b49\uff09\u7684\u5b89\u5168\u6027\u3001\u53ef\u9760\u6027\u5ba1\u6838\u9700\u8981\u8017\u8d39\u5927\u91cf\u4eba\u529b\u3001\u65f6\u95f4\u3002\u4f20\u7edf\u4fdd\u969c\u6848\u4f8b\u6587\u6863\u5197\u957f\uff0c\u4eba\u5de5\u5ba1\u67e5\u6613\u51fa\u9519\u3001\u6548\u7387\u4f4e\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u5ba1\u67e5\u65b9\u6cd5\u63d0\u5347\u4fdd\u969c\u8d28\u91cf\u548c\u6548\u7387\u3002", "method": "\u63d0\u51faLLM-as-a-judge\u8303\u5f0f\uff0c\u57fa\u4e8e\u751f\u6210\u5f0fAI\u548c\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5316\u5ba1\u67e5\u4fdd\u969c\u6848\u4f8b\u3002\u8bbe\u8ba1\u8c13\u8bcd\u89c4\u5219\u5f62\u5f0f\u5316\u4f20\u7edf\u5ba1\u67e5\u6807\u51c6\uff0c\u5e76\u751f\u6210\u9002\u7528LLM\u7684\u5b9a\u5236\u5316\u5ba1\u67e5\u63d0\u793a\u3002\u5728\u4e3b\u6d41LLM\u4e0a\uff08GPT-4o\uff0cGPT-4.1\uff0cDeepSeek-R1\uff0cGemini 2.0 Flash\uff09\u8fdb\u884c\u5b9e\u9a8c\u5bf9\u6bd4\u6a21\u578b\u8868\u73b0\u3002", "result": "\u7edd\u5927\u591a\u6570LLM\u6a21\u578b\u5177\u5907\u8f83\u597d\u7684\u5ba1\u67e5\u80fd\u529b\uff0c\u5176\u4e2dDeepSeek-R1\u548cGPT-4.1\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\uff0cDeepSeek-R1\u6700\u7ec8\u6548\u679c\u6700\u4f73\u3002\u4f46\u5b9e\u9a8c\u8868\u660eLLM\u5ba1\u67e5\u7ed3\u679c\u4ecd\u9700\u4eba\u5de5\u8fdb\u4e00\u6b65\u4fee\u8ba2\u5b8c\u5584\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5316\u4fdd\u969c\u6848\u4f8b\u5ba1\u67e5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u548c\u4e00\u81f4\u6027\uff0cDeepSeek-R1\u5728\u6b64\u4efb\u52a1\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u4f46LLM\u5c1a\u4e0d\u80fd\u5b8c\u5168\u66ff\u4ee3\u4eba\u5de5\u5ba1\u67e5\uff0c\u4eba\u5de5\u628a\u5173\u4f9d\u7136\u5fc5\u8981\u3002"}}
{"id": "2511.02366", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.02366", "abs": "https://arxiv.org/abs/2511.02366", "authors": ["Yudong Li", "Zhongliang Yang", "Kejiang Chen", "Wenxuan Wang", "Tianxin Zhang", "Sifang Wan", "Kecheng Wang", "Haitian Li", "Xu Wang", "Lefan Cheng", "Youdan Yang", "Baocheng Chen", "Ziyu Liu", "Yufei Sun", "Liyan Wu", "Wenya Wen", "Xingchi Gu", "Peiru Yang"], "title": "LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context", "comment": null, "summary": "In this work, we propose LiveSecBench, a dynamic and continuously updated\nsafety benchmark specifically for Chinese-language LLM application scenarios.\nLiveSecBench evaluates models across six critical dimensions (Legality, Ethics,\nFactuality, Privacy, Adversarial Robustness, and Reasoning Safety) rooted in\nthe Chinese legal and social frameworks. This benchmark maintains relevance\nthrough a dynamic update schedule that incorporates new threat vectors, such as\nthe planned inclusion of Text-to-Image Generation Safety and Agentic Safety in\nthe next update. For now, LiveSecBench (v251030) has evaluated 18 LLMs,\nproviding a landscape of AI safety in the context of Chinese language. The\nleaderboard is publicly accessible at https://livesecbench.intokentech.cn/.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u9762\u5411\u4e2d\u6587\u5e94\u7528\u573a\u666f\u4e14\u6301\u7eed\u52a8\u6001\u66f4\u65b0\u7684LLM\u5b89\u5168\u8bc4\u6d4b\u57fa\u51c6LiveSecBench\uff0c\u6db5\u76d6\u516d\u4e2a\u5173\u952e\u5b89\u5168\u7ef4\u5ea6\uff0c\u5df2\u8bc4\u6d4b18\u6b3e\u6a21\u578b\u5e76\u516c\u5f00\u6392\u884c\u699c\uff0c\u4e3a\u4e2d\u6587AI\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5b89\u5168\u8bc4\u6d4b\u591a\u96c6\u4e2d\u4e8e\u82f1\u6587\u573a\u666f\uff0c\u7f3a\u4e4f\u9488\u5bf9\u4e2d\u6587\u5b9e\u9645\u5e94\u7528\u9700\u6c42\u7684\u5b89\u5168\u57fa\u51c6\u3002\u4f5c\u8005\u5e0c\u671b\u6784\u5efa\u4e00\u4e2a\u9488\u5bf9\u4e2d\u6587\u8bed\u5883\uff0c\u4e0e\u4e2d\u56fd\u6cd5\u5f8b\u548c\u793e\u4f1a\u6846\u67b6\u76f8\u5173\u8054\u7684\u5b89\u5168\u57fa\u51c6\uff0c\u4ee5\u52a8\u6001\u5e94\u5bf9\u4e0d\u65ad\u53d8\u5316\u7684\u65b0\u5b89\u5168\u5a01\u80c1\u3002", "method": "\u63d0\u51fa\u4e86LiveSecBench\uff0c\u4e00\u4e2a\u52a8\u6001\u66f4\u65b0\u7684\u4e2d\u6587LLM\u5b89\u5168\u8bc4\u6d4b\u57fa\u51c6\uff0c\u4ece\u5408\u6cd5\u6027\u3001\u4f26\u7406\u6027\u3001\u4e8b\u5b9e\u6027\u3001\u9690\u79c1\u4fdd\u62a4\u3001\u5bf9\u6297\u9c81\u68d2\u6027\u3001\u63a8\u7406\u5b89\u5168\u516d\u4e2a\u7ef4\u5ea6\u51fa\u53d1\u8fdb\u884c\u8bc4\u6d4b\u3002\u7cfb\u7edf\u4f1a\u5b9a\u671f\u5f15\u5165\u65b0\u7684\u5b89\u5168\u8bc4\u6d4b\u7ef4\u5ea6\uff08\u5982\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u5b89\u5168\u3001Agentic\u5b89\u5168\uff09\uff0c\u5e76\u6839\u636e\u6700\u65b0\u5a01\u80c1\u53ca\u65f6\u6269\u5c55\u6d4b\u8bd5\u5185\u5bb9\u3002", "result": "\u5f53\u524d\u7248\u672cLiveSecBench (v251030)\u5df2\u5bf918\u4e2a\u4e3b\u6d41\u4e2d\u6587LLM\u8fdb\u884c\u4e86\u5b89\u5168\u8bc4\u4f30\uff0c\u5f62\u6210\u4e86\u516c\u5f00\u7684\u5b89\u5168\u6392\u884c\u699c\u3002", "conclusion": "LiveSecBench\u4e3a\u4e2d\u6587\u573a\u666f\u4e0b\u7684LLM\u5b89\u5168\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6743\u5a01\u3001\u5b9e\u65f6\u3001\u900f\u660e\u7684\u5de5\u5177\uff0c\u5e76\u968f\u7740\u65b0\u5a01\u80c1\u4e0d\u65ad\u52a8\u6001\u62d3\u5c55\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u4e2d\u6587LLM\u5b89\u5168\u6807\u51c6\u53d1\u5c55\u3002"}}
{"id": "2511.02352", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.02352", "abs": "https://arxiv.org/abs/2511.02352", "authors": ["Sanket Mhatre", "Yasharth Bajpai", "Sumit Gulwani", "Emerson Murphy-Hill", "Gustavo Soares"], "title": "SWE-Sharp-Bench: A Reproducible Benchmark for C# Software Engineering Tasks", "comment": null, "summary": "AI coding agents have shown great progress on Python software engineering\nbenchmarks like SWE-Bench, and for other languages like Java and C in\nbenchmarks like Multi-SWE-Bench. However, C# -- a prominent enterprise language\nranking #5 in the TIOBE index -- remains absent from such benchmarks. We\nintroduce SWE-Sharp-Bench, a reproducible software engineering benchmark for\nC\\# featuring 150 instances from 17 repositories. Evaluating identical\nmodel-agent configurations across languages reveals a significant performance\ngap: while 70% of Python tasks in SWE-Bench Verified are solved, $only 40% of\nour C\\# tasks are resolved. We open-source SWE-Sharp-Bench and our entire\ncuration pipeline.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u516c\u5f00\u4e86\u9762\u5411C#\u7684\u81ea\u52a8\u5316\u8f6f\u4ef6\u5de5\u7a0b\u57fa\u51c6SWE-Sharp-Bench\uff0c\u53d1\u73b0AI\u4ee3\u7801\u4ee3\u7406\u5728C#\u4e0a\u7684\u8868\u73b0\u8fdc\u4f4e\u4e8ePython\uff0c\u63ed\u793a\u4e86\u8de8\u8bed\u8a00AI\u4ee3\u7801\u5de5\u5177\u6027\u80fd\u7684\u663e\u8457\u5dee\u5f02\uff0c\u5e76\u4e3aC#\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u6807\u51c6\u548c\u8d44\u6e90\u3002", "motivation": "\u5728\u73b0\u6709\u7684AI\u4ee3\u7801\u4ee3\u7406\u548c\u8f6f\u4ef6\u5de5\u7a0b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8bf8\u5982Python\u3001Java\u548cC\u7b49\u8bed\u8a00\u90fd\u6709\u76f8\u5e94\u7684\u6d4b\u8bd5\u96c6\uff0c\u4f46\u4e3b\u6d41\u4f01\u4e1a\u7ea7\u8bed\u8a00C#\u5374\u7f3a\u4e4f\u76f8\u5173\u57fa\u51c6\uff0c\u963b\u788d\u4e86AI\u4ee3\u7801\u5de5\u5177\u5728C#\u9886\u57df\u7684\u53d1\u5c55\u548c\u8bc4\u4f30\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86SWE-Sharp-Bench\uff0c\u8fd9\u662f\u9488\u5bf9C#\u5f00\u53d1\u7684\u8f6f\u4ef6\u5de5\u7a0b\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b150\u4e2a\u5b9e\u4f8b\uff0c\u6765\u81ea17\u4e2a\u4e0d\u540c\u7684\u4ee3\u7801\u5e93\uff0c\u5e76\u4e14\u590d\u73b0\u4e86\u8de8\u8bed\u8a00\u7edf\u4e00\u7684\u8bc4\u6d4b\u914d\u7f6e\uff0c\u786e\u4fdd\u8bc4\u4ef7\u7684\u516c\u5e73\u548c\u53ef\u5bf9\u6bd4\u6027\uff0c\u540c\u65f6\u5f00\u653e\u4e86\u6570\u636e\u96c6\u548c\u6574\u4e2a\u6570\u636e\u6574\u7406\u7531\u5de5\u5177\u94fe\u3002", "result": "\u5728\u76f8\u540c\u7684\u6a21\u578b\u914d\u7f6e\u4e0b\uff0cC#\u4efb\u52a1\u7684\u89e3\u51b3\u7387\u4ec5\u4e3a40%\uff0c\u800cPython\u4efb\u52a1\u53ef\u8fbe70%\uff0c\u5c55\u73b0\u4e86AI\u4ee3\u7801\u4ee3\u7406\u5728C#\u8bed\u8a00\u4e0a\u7684\u663e\u8457\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "\u672c\u7814\u7a76\u586b\u8865\u4e86C#\u8bed\u8a00\u5728AI\u8f6f\u4ef6\u5de5\u7a0b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u6807\u51c6\u5e76\u8bc1\u5b9e\u4e86\u5f53\u524d\u6a21\u578b\u5728C#\u9886\u57df\u7684\u5c40\u9650\uff0c\u4e3a\u540e\u7eedC#\u76f8\u5173\u81ea\u52a8\u5316\u5de5\u5177\u53d1\u5c55\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u3002"}}
{"id": "2511.02374", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02374", "abs": "https://arxiv.org/abs/2511.02374", "authors": ["Mohd Nauman", "Sravan Gvm", "Vijay Devane", "Shyam Pawar", "Viraj Thakur", "Kundeshwar Pundalik", "Piyush Sawarkar", "Rohit Saluja", "Maunendra Desarkar", "Ganesh Ramakrishnan"], "title": "AyurParam: A State-of-the-Art Bilingual Language Model for Ayurveda", "comment": null, "summary": "Current large language models excel at broad, general-purpose tasks, but\nconsistently underperform when exposed to highly specialized domains that\nrequire deep cultural, linguistic, and subject-matter expertise. In particular,\ntraditional medical systems such as Ayurveda embody centuries of nuanced\ntextual and clinical knowledge that mainstream LLMs fail to accurately\ninterpret or apply. We introduce AyurParam-2.9B, a domain-specialized,\nbilingual language model fine-tuned from Param-1-2.9B using an extensive,\nexpertly curated Ayurveda dataset spanning classical texts and clinical\nguidance. AyurParam's dataset incorporates context-aware, reasoning, and\nobjective-style Q&A in both English and Hindi, with rigorous annotation\nprotocols for factual precision and instructional clarity. Benchmarked on\nBhashaBench-Ayur, AyurParam not only surpasses all open-source\ninstruction-tuned models in its size class (1.5--3B parameters), but also\ndemonstrates competitive or superior performance compared to much larger\nmodels. The results from AyurParam highlight the necessity for authentic domain\nadaptation and high-quality supervision in delivering reliable, culturally\ncongruent AI for specialized medical knowledge.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e13\u95e8\u9488\u5bf9\u963f\u80b2\u5420\u9640\u533b\u5b66\u7684\u53cc\u8bed\u5fae\u8c03\u5927\u6a21\u578bAyurParam-2.9B\uff0c\u5176\u5728\u6743\u5a01\u57fa\u51c6\u4e0a\u8d85\u8d8a\u4e86\u540c\u7ea7\u522b\u751a\u81f3\u66f4\u5927\u6a21\u578b\uff0c\u8bc1\u660e\u901a\u8fc7\u9ad8\u8d28\u91cf\u6570\u636e\u548c\u9886\u57df\u9002\u914d\u53ef\u4ee5\u5927\u5e45\u63d0\u5347\u533b\u7597\u9886\u57dfAI\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u867d\u7136\u5728\u901a\u7528\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u9700\u8981\u6df1\u539a\u6587\u5316\u3001\u8bed\u8a00\u548c\u4e13\u4e1a\u77e5\u8bc6\u7684\u9ad8\u5ea6\u4e13\u4e1a\u5316\u9886\u57df\uff08\u5982\u4f20\u7edf\u533b\u5b66\u7cfb\u7edf\u2014\u2014\u963f\u80b2\u5420\u9640\uff09\u8868\u73b0\u4e0d\u4f73\u3002\u4e3b\u6d41LLM\u96be\u4ee5\u51c6\u786e\u89e3\u91ca\u548c\u5e94\u7528\u8fd9\u4e9b\u590d\u6742\u7684\u533b\u5b66\u77e5\u8bc6\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e13\u7528\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u5e76\u8bad\u7ec3\u4e86AyurParam-2.9B\uff0c\u8fd9\u662f\u5728Param-1-2.9B\u57fa\u7840\u4e0a\u5fae\u8c03\u800c\u6765\u7684\u3001\u4e13\u95e8\u7528\u4e8e\u963f\u80b2\u5420\u9640\u533b\u5b66\u7684\u53cc\u8bed\uff08\u82f1\u8bed\u548c\u5370\u5730\u8bed\uff09\u6a21\u578b\u3002\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u4e3a\u5927\u91cf\u7ecf\u8fc7\u4e13\u5bb6\u7cbe\u5fc3\u6574\u7406\u7684\u7ecf\u5178\u6587\u732e\u53ca\u4e34\u5e8a\u6307\u5bfc\u5185\u5bb9\uff0c\u5305\u542b\u60c5\u5883\u7406\u89e3\u3001\u63a8\u7406\u3001\u5ba2\u89c2\u95ee\u7b54Q&A\uff0c\u4e25\u683c\u4fdd\u8bc1\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u6307\u5bfc\u6027\u3002", "result": "\u5728BhashaBench-Ayur\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cAyurParam-2.9B\u8868\u73b0\u4f18\u4e8e\u540c\u53c2\u6570\u91cf\uff081.5-3B\u53c2\u6570\uff09\u7684\u5f00\u6e90\u6307\u4ee4\u5fae\u8c03\u6a21\u578b\uff0c\u5bf9\u6bd4\u66f4\u5927\u89c4\u6a21\u7684\u6a21\u578b\u4e5f\u6709\u7ade\u4e89\u529b\uff0c\u751a\u81f3\u6709\u4e9b\u6027\u80fd\u66f4\u4f73\u3002", "conclusion": "AyurParam-2.9B\u7684\u5b9e\u9a8c\u7ed3\u679c\u51f8\u663e\u4e86\u771f\u5b9e\u9886\u57df\u9002\u914d\u548c\u9ad8\u8d28\u91cf\u76d1\u7763\u5bf9\u4e8e\u9ad8\u53ef\u9760\u6027\u3001\u66f4\u8d34\u5408\u6587\u5316\u80cc\u666f\u7684\u4e13\u4e1a\u533b\u7597AI\u7684\u91cd\u8981\u6027\u3002\u5f00\u53d1\u9886\u57df\u4e13\u7528LLM\u80fd\u591f\u5f25\u8865\u4e3b\u6d41LLM\u5728\u4e13\u4e1a\u77e5\u8bc6\u9886\u57df\u7684\u4e0d\u8db3\u3002"}}
{"id": "2511.02399", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02399", "abs": "https://arxiv.org/abs/2511.02399", "authors": ["Junwei Liu", "Chen Xu", "Chong Wang", "Tong Bai", "Weitong Chen", "Kaseng Wong", "Yiling Lou", "Xin Peng"], "title": "EvoDev: An Iterative Feature-Driven Framework for End-to-End Software Development with LLM-based Agents", "comment": "14 pages, 6 figures", "summary": "Recent advances in large language model agents offer the promise of\nautomating end-to-end software development from natural language requirements.\nHowever, existing approaches largely adopt linear, waterfall-style pipelines,\nwhich oversimplify the iterative nature of real-world development and struggle\nwith complex, large-scale projects. To address these limitations, we propose\nEvoDev, an iterative software development framework inspired by feature-driven\ndevelopment. EvoDev decomposes user requirements into a set of user-valued\nfeatures and constructs a Feature Map, a directed acyclic graph that explicitly\nmodels dependencies between features. Each node in the feature map maintains\nmulti-level information, including business logic, design, and code, which is\npropagated along dependencies to provide context for subsequent development\niterations. We evaluate EvoDev on challenging Android development tasks and\nshow that it outperforms the best-performing baseline, Claude Code, by a\nsubstantial margin of 56.8%, while improving single-agent performance by\n16.0%-76.6% across different base LLMs, highlighting the importance of\ndependency modeling, context propagation, and workflow-aware agent design for\ncomplex software projects. Our work summarizes practical insights for designing\niterative, LLM-driven development frameworks and informs future training of\nbase LLMs to better support iterative software development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEvoDev\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u7279\u6027\u4f9d\u8d56\u56fe\u548c\u4e0a\u4e0b\u6587\u4f20\u9012\u673a\u5236\uff0c\u5b9e\u73b0LLM\u9a71\u52a8\u7684\u8f6f\u4ef6\u5f00\u53d1\u8fed\u4ee3\u4f18\u5316\uff0c\u5e76\u5728\u590d\u6742\u9879\u76ee\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u4e3b\u6d41\u65b9\u6cd5\u591a\u91c7\u7528\u7ebf\u6027\u3001\u7011\u5e03\u5f0f\u6d41\u7a0b\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u73b0\u5b9e\u4e2d\u8fed\u4ee3\u6027\u5f3a\u3001\u9700\u6c42\u590d\u6742\u7684\u5927\u578b\u9879\u76ee\u3002\u4f5c\u8005\u5e0c\u671b\u5f25\u8865\u8fd9\u4e00\u4e0d\u8db3\u3002", "method": "\u63d0\u51faEvoDev\u6846\u67b6\uff0c\u501f\u9274\u7279\u6027\u9a71\u52a8\u5f00\u53d1\u7406\u5ff5\uff0c\u5c06\u7528\u6237\u9700\u6c42\u5206\u89e3\u4e3a\u7279\u6027\u96c6\u5408\uff0c\u901a\u8fc7\u6709\u5411\u65e0\u73af\u56fe\uff08Feature Map\uff09\u5efa\u6a21\u7279\u6027\u95f4\u4f9d\u8d56\u3002\u6bcf\u4e2a\u8282\u70b9\u5305\u542b\u4e1a\u52a1\u903b\u8f91\u3001\u8bbe\u8ba1\u4e0e\u4ee3\u7801\u7b49\u591a\u5c42\u4fe1\u606f\uff0c\u4f9d\u8d56\u4f20\u64ad\u4e3a\u540e\u7eed\u5f00\u53d1\u63d0\u4f9b\u4e0a\u4e0b\u6587\u3002", "result": "\u5728\u590d\u6742\u7684Android\u5f00\u53d1\u4efb\u52a1\u4e2d\uff0cEvoDev\u76f8\u8f83\u6700\u4f18\u57fa\u7ebf\u65b9\u6cd5\uff08Claude Code\uff09\u63d0\u5347\u4e8656.8%\uff0c\u5728\u4e0d\u540c\u57fa\u7840LLM\u4e0b\u7684\u5355\u4f53\u6027\u80fd\u63d0\u534716.0%-76.6%\u3002", "conclusion": "EvoDev\u5c55\u793a\u4e86\u4f9d\u8d56\u5efa\u6a21\u3001\u4e0a\u4e0b\u6587\u4f20\u9012\u548c\u9762\u5411\u6d41\u7a0b\u7684\u667a\u80fd\u4f53\u8bbe\u8ba1\u5bf9\u4e8e\u590d\u6742\u9879\u76ee\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4e3a\u672a\u6765LLM\u9a71\u52a8\u7684\u8fed\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u6846\u67b6\u548cLLM\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u76ca\u7ecf\u9a8c\u3002"}}
{"id": "2511.02376", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02376", "abs": "https://arxiv.org/abs/2511.02376", "authors": ["Aashray Reddy", "Andrew Zagula", "Nicholas Saban"], "title": "AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) remain vulnerable to jailbreaking attacks where\nadversarial prompts elicit harmful outputs, yet most evaluations focus on\nsingle-turn interactions while real-world attacks unfold through adaptive\nmulti-turn conversations. We present AutoAdv, a training-free framework for\nautomated multi-turn jailbreaking that achieves up to 95% attack success rate\non Llama-3.1-8B within six turns a 24 percent improvement over single turn\nbaselines. AutoAdv uniquely combines three adaptive mechanisms: a pattern\nmanager that learns from successful attacks to enhance future prompts, a\ntemperature manager that dynamically adjusts sampling parameters based on\nfailure modes, and a two-phase rewriting strategy that disguises harmful\nrequests then iteratively refines them. Extensive evaluation across commercial\nand open-source models (GPT-4o-mini, Qwen3-235B, Mistral-7B) reveals persistent\nvulnerabilities in current safety mechanisms, with multi-turn attacks\nconsistently outperforming single-turn approaches. These findings demonstrate\nthat alignment strategies optimized for single-turn interactions fail to\nmaintain robustness across extended conversations, highlighting an urgent need\nfor multi-turn-aware defenses.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u65e0\u9700\u8bad\u7ec3\u7684\u81ea\u52a8\u591a\u8f6e\u653b\u51fb\u6846\u67b6AutoAdv\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5728\u4e0d\u540c\u5927\u6a21\u578b\u4e0a\u7684jailbreaking\u653b\u51fb\u6210\u529f\u7387\uff0c\u63ed\u793a\u73b0\u6709\u6a21\u578b\u5355\u8f6e\u4f18\u5316\u7684\u5b89\u5168\u7b56\u7565\u5728\u591a\u8f6e\u4ea4\u4e92\u4e0b\u5931\u6548\uff0c\u5f3a\u8c03\u591a\u8f6e\u9632\u5fa1\u673a\u5236\u7684\u7d27\u8feb\u9700\u6c42\u3002", "motivation": "\u76ee\u524d\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9762\u5bf9jailbreaking\u653b\u51fb\uff0c\u5373\u901a\u8fc7\u5bf9\u6297\u6027\u63d0\u793a\u8bcd\u8bf1\u5bfc\u6a21\u578b\u8f93\u51fa\u6709\u5bb3\u5185\u5bb9\u65f6\u4ecd\u7136\u8106\u5f31\u3002\u73b0\u6709\u8bc4\u4f30\u5927\u591a\u53ea\u5173\u6ce8\u5355\u8f6e\u4ea4\u4e92\uff0c\u4f46\u771f\u5b9e\u4e16\u754c\u4e2d\u653b\u51fb\u901a\u5e38\u662f\u591a\u8f6e\u3001\u9002\u5e94\u6027\u5f3a\u7684\u5bf9\u8bdd\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u591a\u8f6ejailbreaking\u653b\u51fb\u81ea\u52a8\u5316\u8bc4\u6d4b\u7684\u65b9\u6cd5\u7a7a\u767d\u3002", "method": "\u63d0\u51faAutoAdv\u6846\u67b6\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u8fdb\u884c\u81ea\u52a8\u5316\u591a\u8f6ejailbreaking\u653b\u51fb\u3002AutoAdv\u878d\u5408\u4e09\u79cd\u9002\u5e94\u6027\u673a\u5236\uff1a1\uff09\u6a21\u5f0f\u7ba1\u7406\u5668\u5b66\u4e60\u6210\u529f\u653b\u51fb\u63d0\u5347\u672a\u6765\u63d0\u793a\u8bcd\uff1b2\uff09\u6e29\u5ea6\u7ba1\u7406\u5668\u6839\u636e\u5931\u8d25\u60c5\u51b5\u52a8\u6001\u8c03\u6574\u91c7\u6837\u53c2\u6570\uff1b3\uff09\u4e24\u9636\u6bb5\u91cd\u5199\u7b56\u7565\uff0c\u5148\u4f2a\u88c5\u6709\u5bb3\u8bf7\u6c42\u518d\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5728Llama-3.1-8B\u4e0a\uff0cAutoAdv\u516d\u8f6e\u5185\u53ef\u8fbe95%\u653b\u51fb\u6210\u529f\u7387\uff0c\u6bd4\u5355\u8f6e\u63d0\u534724%\u3002\u5728GPT-4o-mini\u3001Qwen3-235B\u3001Mistral-7B\u7b49\u591a\u4e2a\u6a21\u578b\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u591a\u8f6e\u653b\u51fb\u59cb\u7ec8\u4f18\u4e8e\u5355\u8f6e\u3002\u5f53\u524d\u5b89\u5168\u673a\u5236\u5728\u591a\u8f6e\u573a\u666f\u4e0b\u5747\u5b58\u5728\u6301\u7eed\u6027\u6f0f\u6d1e\u3002", "conclusion": "\u4f18\u5316\u4e3a\u5355\u8f6e\u4ea4\u4e92\u7684\u6a21\u578b\u5b89\u5168\u65b9\u6848\u65e0\u6cd5\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u4e9f\u9700\u9488\u5bf9\u591a\u8f6e\u4ea4\u4e92\u8bbe\u8ba1\u9632\u5fa1\u673a\u5236\u4ee5\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6027\u3002"}}
{"id": "2511.02434", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.02434", "abs": "https://arxiv.org/abs/2511.02434", "authors": ["Dominik Fuch\u00df", "Haoyu Liu", "Sophie Corallo", "Tobias Hey", "Jan Keim", "Johannes von Geisau", "Anne Koziolek"], "title": "Who's Who? LLM-assisted Software Traceability with Architecture Entity Recognition", "comment": null, "summary": "Identifying architecturally relevant entities in textual artifacts is crucial\nfor Traceability Link Recovery (TLR) between Software Architecture\nDocumentation (SAD) and source code. While Software Architecture Models (SAMs)\ncan bridge the semantic gap between these artifacts, their manual creation is\ntime-consuming. Large Language Models (LLMs) offer new capabilities for\nextracting architectural entities from SAD and source code to construct SAMs\nautomatically or establish direct trace links. This paper presents two\nLLM-based approaches: ExArch extracts component names as simple SAMs from SAD\nand source code to eliminate the need for manual SAM creation, while ArTEMiS\nidentifies architectural entities in documentation and matches them with\n(manually or automatically generated) SAM entities. Our evaluation compares\nagainst state-of-the-art approaches SWATTR, TransArC and ArDoCode. TransArC\nachieves strong performance (F1: 0.87) but requires manually created SAMs;\nExArch achieves comparable results (F1: 0.86) using only SAD and code. ArTEMiS\nis on par with the traditional heuristic-based SWATTR (F1: 0.81) and can\nsuccessfully replace it when integrated with TransArC. The combination of\nArTEMiS and ExArch outperforms ArDoCode, the best baseline without manual SAMs.\nOur results demonstrate that LLMs can effectively identify architectural\nentities in textual artifacts, enabling automated SAM generation and TLR,\nmaking architecture-code traceability more practical and accessible.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u67b6\u6784\u5b9e\u4f53\u8bc6\u522b\u65b9\u6cd5ExArch\u548cArTEMiS\uff0c\u5e76\u548c\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u3002\u7ed3\u679c\u663e\u793a\uff0cLLM\u65b9\u6cd5\u65e0\u9700\u624b\u5de5\u5efa\u6a21\u5373\u53ef\u63a5\u8fd1\u751a\u81f3\u4f18\u4e8e\u4eba\u5de5\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u67b6\u6784\u4e0e\u4ee3\u7801\u8ffd\u6eaf\u7684\u81ea\u52a8\u5316\u548c\u5b9e\u7528\u6027\u53d1\u5c55\u3002", "motivation": "\u5728\u8f6f\u4ef6\u67b6\u6784\u6587\u4ef6\u4e0e\u6e90\u4ee3\u7801\u4e4b\u95f4\u5efa\u7acb\u53ef\u8ffd\u8e2a\u6027\u8fde\u63a5\uff08TLR\uff09\u5bf9\u8f6f\u4ef6\u67b6\u6784\u5206\u6790\u548c\u7ef4\u62a4\u81f3\u5173\u91cd\u8981\u3002\u4f46\u67b6\u6784\u6a21\u578b\uff08SAM\uff09\u7684\u4eba\u5de5\u521b\u5efa\u8fc7\u7a0b\u8017\u65f6\u4e14\u6613\u51fa\u9519\uff0c\u56e0\u6b64\u7814\u7a76\u5982\u4f55\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u8bc6\u522b\u67b6\u6784\u5b9e\u4f53\u3001\u751f\u6210SAM\uff0c\u63d0\u5347\u6548\u7387\u548c\u81ea\u52a8\u5316\u6c34\u5e73\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\uff1aExArch\u4ece\u8f6f\u4ef6\u67b6\u6784\u6587\u6863\u548c\u6e90\u4ee3\u7801\u4e2d\u81ea\u52a8\u63d0\u53d6\u7ec4\u4ef6\u540d\u79f0\uff0c\u5b9e\u73b0SAM\u81ea\u52a8\u751f\u6210\uff1bArTEMiS\u5219\u8bc6\u522b\u6587\u6863\u4e2d\u7684\u67b6\u6784\u5b9e\u4f53\uff0c\u5e76\u4e0eSAM\u5b9e\u4f53\u8fdb\u884c\u5339\u914d\u3002\u901a\u8fc7\u5bf9\u6bd4\u5f53\u524d\u4e3b\u6d41\u65b9\u6cd5SWATTR\u3001TransArC\u548cArDoCode\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "ExArch\u80fd\u591f\u4ec5\u4f9d\u8d56\u67b6\u6784\u6587\u6863\u548c\u6e90\u7801\u8fbe\u5230\u4e0e\u9700\u8981\u624b\u5de5SAM\u7684TransArC\u76f8\u5f53\u7684\u6548\u679c\uff08F1:0.86 vs 0.87\uff09\uff1bArTEMiS\u4e0e\u4f20\u7edf\u542f\u53d1\u5f0f\u7684SWATTR\u8868\u73b0\u4e00\u81f4\uff08F1:0.81\uff09\uff0c\u4e14\u53ef\u4e0eTransArC\u96c6\u6210\u66ff\u6362SWATTR\uff1bExArch\u548cArTEMiS\u7ec4\u5408\u4f18\u4e8e\u65e0\u9700\u624b\u5de5SAM\u7684\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5ArDoCode\u3002", "conclusion": "LLM\u80fd\u591f\u6709\u6548\u8bc6\u522b\u8f6f\u4ef6\u67b6\u6784\u76f8\u5173\u7684\u6587\u672c\u5b9e\u4f53\uff0c\u5b9e\u73b0SAM\u7684\u81ea\u52a8\u751f\u6210\u548c\u53ef\u8ffd\u8e2a\u6027\u94fe\u63a5\u6062\u590d\uff0c\u6781\u5927\u7b80\u5316\u67b6\u6784\u4e0e\u4ee3\u7801\u7684\u8ffd\u8e2a\uff0c\u63d0\u5347\u5b9e\u9645\u5e94\u7528\u7684\u53ef\u884c\u6027\u548c\u4fbf\u5229\u6027\u3002"}}
{"id": "2511.02451", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.02451", "abs": "https://arxiv.org/abs/2511.02451", "authors": ["Kentaro Ueda", "Fran\u00e7ois Portet", "Hirohiko Suwa", "Keiichi Yasumoto"], "title": "Merging Continual Pretraining Models for Domain-Specialized LLMs: A Case Study in Finance", "comment": null, "summary": "While LLMs excel at general tasks, they struggle in specialized domains like\nfinance, requiring diverse skills in domain knowledge, mathematical reasoning,\nand multilingual processing. Merging domain-specific Continual Pre-training\n(CPT) \"experts\" offers a practical alternative to costly and unstable\nmulti-skill training. However, unlike established Supervised Fine-Tuning (SFT)\nmodel-based merging, CPT model merging remains largely unexplored. We address\nthis gap by creating financial LLMs from experts in finance, math, and\nJapanese. We propose a three-stage evaluation focusing on knowledge recovery,\ncomplementarity, and emergence, and assess three merging methods (Task\nArithmetic, TIES, and DARE-TIES) on a comprehensive financial benchmark curated\nfrom 18 tasks across 8 established datasets. Results show that merging an\nexpert with its base model recovers general knowledge lost during CPT, while\nmerging experts improves performance and can yield emergent cross-domain\nskills. Among the methods, Task Arithmetic performs strongly but is\nhyperparameter-sensitive, whereas TIES is more robust. Our findings also\nsuggest that while model similarity correlates with merging success, emergent\nskills depend on more complex factors. This work presents the first\nfoundational analysis of CPT model merging, establishing a principled framework\nand providing clear guidance for building multi-skill LLMs from existing\nassets.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u4e0d\u540c\u9886\u57dfCPT\u4e13\u5bb6\u6a21\u578b\u7684\u878d\u5408\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u878d\u5408\u7b56\u7565\u5bf9\u4e8e\u63d0\u5347\u91d1\u878d\u7b49\u4e13\u9886\u57dfLLM\u80fd\u529b\u7684\u6709\u6548\u6027\uff0c\u5e76\u7ed9\u51fa\u4e86\u6784\u5efa\u591a\u6280\u80fd\u6a21\u578b\u7684\u7ecf\u9a8c\u4e0e\u5efa\u8bae\u3002", "motivation": "LLMs\u867d\u7136\u5728\u901a\u7528\u4efb\u52a1\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u91d1\u878d\u7b49\u4e13\u4e1a\u9886\u57df\u5b58\u5728\u663e\u8457\u6311\u6218\u3002\u8fd9\u4e9b\u9886\u57df\u9700\u8981\u591a\u6837\u5316\u7684\u77e5\u8bc6\u3001\u6570\u5b66\u63a8\u7406\u548c\u591a\u8bed\u79cd\u5904\u7406\u80fd\u529b\u3002\u591a\u6280\u80fd\u8bad\u7ec3\u6210\u672c\u9ad8\u4e14\u4e0d\u7a33\u5b9a\uff0c\u56e0\u6b64\u4f5c\u8005\u63d0\u51fa\u878d\u5408\u9886\u57df\u4e13\u7528CPT\u4e13\u5bb6\u6a21\u578b\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\u3002\u6b64\u524d\uff0c\u9488\u5bf9\u76d1\u7763\u5fae\u8c03\u6a21\u578b\u878d\u5408\u5df2\u6709\u7814\u7a76\uff0c\u4f46CPT\u6a21\u578b\u878d\u5408\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f5c\u8005\u521b\u5efa\u4e86\u6765\u81ea\u91d1\u878d\u3001\u6570\u5b66\u548c\u65e5\u8bed\u9886\u57df\u7684\u4e13\u5bb6\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e09\u9636\u6bb5\u8bc4\u4f30\u6846\u67b6\uff1a\u77e5\u8bc6\u6062\u590d\u3001\u4e92\u8865\u6027\u548c\u6d8c\u73b0\u6027\u3002\u91c7\u7528\u4e09\u79cd\u6a21\u578b\u878d\u5408\u65b9\u6cd5\uff08Task Arithmetic\u3001TIES\u548cDARE-TIES\uff09\uff0c\u5728\u75318\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u6db5\u76d618\u9879\u4efb\u52a1\u7684\u91d1\u878d\u57fa\u51c6\u4e0a\u8fdb\u884c\u8bc4\u6d4b\u3002\u5206\u6790\u4e86\u6a21\u578b\u878d\u5408\u540e\u7684\u8868\u73b0\u548c\u4ea7\u751f\u8de8\u9886\u57df\u6280\u80fd\u7684\u80fd\u529b\u3002", "result": "\u5c06\u4e13\u5bb6\u4e0e\u57fa\u7840\u6a21\u578b\u878d\u5408\u53ef\u6062\u590dCPT\u8fc7\u7a0b\u4e2d\u4e22\u5931\u7684\u901a\u7528\u77e5\u8bc6\uff1b\u591a\u4e13\u5bb6\u878d\u5408\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u6709\u53ef\u80fd\u6d8c\u73b0\u51fa\u65b0\u7684\u8de8\u9886\u57df\u80fd\u529b\u3002Task Arithmetic\u6027\u80fd\u5f3a\u4f46\u5bf9\u8d85\u53c2\u6570\u654f\u611f\uff0cTIES\u65b9\u6cd5\u66f4\u4e3a\u7a33\u5065\u3002\u6a21\u578b\u76f8\u4f3c\u6027\u4e0e\u878d\u5408\u6210\u529f\u5ea6\u76f8\u5173\uff0c\u4f46\u6d8c\u73b0\u6280\u80fd\u53d7\u66f4\u590d\u6742\u56e0\u7d20\u5f71\u54cd\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u6027\u5206\u6790\u4e86\u9886\u57df\u4e13\u5c5eCPT\u6a21\u578b\u878d\u5408\uff0c\u63d0\u51fa\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u4e3a\u6784\u5efa\u591a\u6280\u80fdLLM\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u6027\u6307\u5357\u3002"}}
{"id": "2511.02445", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.02445", "abs": "https://arxiv.org/abs/2511.02445", "authors": ["Eriks Klotins", "Magnus Ahlgren", "Nicolas Martin Vivaldi", "Even-Andre Karlsson"], "title": "When Continuous Delivery Is Not an Option: Practical Paths to Continuous Engineering in Complex Organizations", "comment": null, "summary": "Purpose: Continuous Software Engineering (CSE) promises improved efficiency,\nquality, and responsiveness in software-intensive organizations. However, fully\nadopting CSE is often constrained by complex products, legacy systems,\norganizational inertia, and regulatory requirements. In this paper, we examine\nfour industrial cases from the automation, automotive, retail, and chemical\nsectors to explore how such constraints shape CSE adoption in practice.\nMethods: We apply and extend a previously proposed CSE Industry Readiness Model\nto assess the current and potential levels of adoption in each case. Through\nexpert interviews and narrative synthesis, we identify common driving forces\nand adoption barriers, including organizational preparedness,\ncross-organizational dependencies, and limited customer demand for continuous\ndelivery. Results: Based on our findings, we propose an updated readiness model\nthat introduces additional levels of internal and external feedback,\ndistinguishes market- and organization-facing constraints, and better guides\npractitioners in setting realistic CSE adoption goals. Conclusions: Our results\nhighlight that while full end-to-end CSE adoption may not always be feasible,\nmeaningful internal improvements are still possible and beneficial. This study\nprovides empirically grounded guidance for organizations navigating partial or\nconstrained CSE transformations.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u4e86\u4e0d\u540c\u884c\u4e1aCSE\u91c7\u7eb3\u7684\u969c\u788d\u4e0e\u52a8\u529b\uff0c\u63d0\u51fa\u6539\u8fdb\u7684\u6a21\u578b\u548c\u5b9e\u7528\u5efa\u8bae\uff0c\u5f3a\u8c03\u5373\u4f7f\u91c7\u7eb3\u53d7\u9650\uff0c\u5185\u90e8\u6301\u7eed\u6539\u8fdb\u4f9d\u7136\u80fd\u5e26\u6765\u660e\u663e\u76ca\u5904\u3002", "motivation": "\u8fde\u7eed\u8f6f\u4ef6\u5de5\u7a0b\uff08CSE\uff09\u867d\u6709\u63d0\u5347\u6548\u7387\u548c\u54cd\u5e94\u6027\u7684\u6f5c\u529b\uff0c\u4f46\u5b9e\u9645\u5168\u9762\u5e94\u7528\u5728\u53d7\u9650\u4e8e\u590d\u6742\u4ea7\u54c1\u3001\u9057\u7559\u7cfb\u7edf\u3001\u7ec4\u7ec7\u60ef\u6027\u548c\u6cd5\u89c4\u8981\u6c42\u3002\u8be5\u6587\u65e8\u5728\u63a2\u7d22\u884c\u4e1a\u5b9e\u9645\u91c7\u7528CSE\u65f6\u8fd9\u4e9b\u7ea6\u675f\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u6269\u5c55CSE\u5de5\u4e1a\u51c6\u5907\u5ea6\u6a21\u578b\uff0c\u5bf9\u81ea\u52a8\u5316\u3001\u6c7d\u8f66\u3001\u96f6\u552e\u548c\u5316\u5de5\u7b49\u56db\u4e2a\u884c\u4e1a\u6848\u4f8b\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u7ed3\u5408\u4e13\u5bb6\u8bbf\u8c08\u4e0e\u53d9\u8ff0\u7efc\u5408\uff0c\u8bc6\u522b\u63a8\u52a8\u529b\u548c\u969c\u788d\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u66f4\u65b0\u7684\u51c6\u5907\u5ea6\u6a21\u578b\uff0c\u589e\u52a0\u4e86\u5185\u90e8\u4e0e\u5916\u90e8\u53cd\u9988\u5c42\u6b21\uff0c\u533a\u5206\u4e86\u5e02\u573a\u4e0e\u7ec4\u7ec7\u5c42\u9762\u7684\u7ea6\u675f\uff0c\u66f4\u597d\u5730\u6307\u5bfc\u4e1a\u754c\u5236\u5b9a\u73b0\u5b9e\u7684CSE\u91c7\u7eb3\u76ee\u6807\u3002\u53d1\u73b0\u5b8c\u5168\u7aef\u5230\u7aef\u7684CSE\u5e94\u7528\u901a\u5e38\u4e0d\u53ef\u884c\uff0c\u4f46\u5185\u90e8\u6539\u8fdb\u4f9d\u7136\u53ef\u884c\u4e14\u6709\u76ca\u3002", "conclusion": "\u4e3a\u7ec4\u7ec7\u5728\u90e8\u5206\u6216\u53d7\u9650\u7684CSE\u8f6c\u578b\u4e2d\u63d0\u4f9b\u4e86\u57fa\u4e8e\u5b9e\u8bc1\u7684\u6307\u5bfc\uff0c\u5f3a\u8c03\u5373\u4f7f\u65e0\u6cd5\u5b9e\u73b0\u5b8c\u6574\u91c7\u7eb3\uff0c\u79ef\u6781\u7684\u5185\u90e8\u53d8\u9769\u540c\u6837\u91cd\u8981\u3002"}}
{"id": "2511.02458", "categories": ["cs.CL", "cs.CE", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2511.02458", "abs": "https://arxiv.org/abs/2511.02458", "authors": ["Giulia Iadisernia", "Carolina Camassa"], "title": "Prompting for Policy: Forecasting Macroeconomic Scenarios with Synthetic LLM Personas", "comment": "9 pages, 8-pages appendix, accepted at ICAIF 25", "summary": "We evaluate whether persona-based prompting improves Large Language Model\n(LLM) performance on macroeconomic forecasting tasks. Using 2,368\neconomics-related personas from the PersonaHub corpus, we prompt GPT-4o to\nreplicate the ECB Survey of Professional Forecasters across 50 quarterly rounds\n(2013-2025). We compare the persona-prompted forecasts against the human\nexperts panel, across four target variables (HICP, core HICP, GDP growth,\nunemployment) and four forecast horizons. We also compare the results against\n100 baseline forecasts without persona descriptions to isolate its effect. We\nreport two main findings. Firstly, GPT-4o and human forecasters achieve\nremarkably similar accuracy levels, with differences that are statistically\nsignificant yet practically modest. Our out-of-sample evaluation on 2024-2025\ndata demonstrates that GPT-4o can maintain competitive forecasting performance\non unseen events, though with notable differences compared to the in-sample\nperiod. Secondly, our ablation experiment reveals no measurable forecasting\nadvantage from persona descriptions, suggesting these prompt components can be\nomitted to reduce computational costs without sacrificing accuracy. Our results\nprovide evidence that GPT-4o can achieve competitive forecasting accuracy even\non out-of-sample macroeconomic events, if provided with relevant context data,\nwhile revealing that diverse prompts produce remarkably homogeneous forecasts\ncompared to human panels.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\uff0cGPT-4o\u5728\u5b8f\u89c2\u7ecf\u6d4e\u9884\u6d4b\u4e0a\u80fd\u5339\u654c\u4eba\u7c7b\u4e13\u5bb6\uff0c\u52a0\u4eba\u4eba\u8bbe\u63d0\u793a\u4e0d\u63d0\u5347\u9884\u6d4b\u6c34\u5e73\uff0c\u53ef\u5ffd\u7565\u8be5\u8fc7\u7a0b\u4ee5\u8282\u7701\u8d44\u6e90\u3002\u63d0\u793a\u8bcd\u591a\u6837\u5316\u5e76\u672a\u660e\u663e\u6539\u5584\u6a21\u578b\u8868\u73b0\uff0c\u6a21\u578b\u8f93\u51fa\u8fdc\u6bd4\u4eba\u7c7b\u4e13\u5bb6\u5171\u8bc6\u66f4\u8d8b\u540c\u8d28\u5316\u3002", "motivation": "\u63a2\u8ba8\u5728\u5b8f\u89c2\u7ecf\u6d4e\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0c\u57fa\u4e8e\u4eba\u683c\u5316\u63d0\u793a\uff08persona-based prompting\uff09\u662f\u5426\u80fd\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002\u9274\u4e8eLLM\u5728\u4e13\u4e1a\u9886\u57df\u5e94\u7528\u4e2d\u7684\u8fc5\u901f\u53d1\u5c55\uff0c\u4f5c\u8005\u5e0c\u671b\u4e86\u89e3\u4eba\u683c\u5316\u63cf\u8ff0\u80fd\u5426\u6210\u4e3a\u63d0\u5347\u6a21\u578b\u6027\u80fd\u7684\u6709\u6548\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528PersonaHub\u8bed\u6599\u5e93\u4e2d\u76842,368\u4e2a\u7ecf\u6d4e\u76f8\u5173\u89d2\u8272\uff0c\u901a\u8fc7\u4eba\u683c\u5316\u63d0\u793a\u5728GPT-4o\u4e2d\u6a21\u62df\u6b27\u6d32\u592e\u884c\u4e13\u4e1a\u9884\u6d4b\u8005\u8c03\u67e5\u768450\u4e2a\u5b63\u5ea6\uff082013-2025\uff09\u3002\u5206\u522b\u5bf9\u56db\u4e2a\u76ee\u6807\u53d8\u91cf\uff08HICP\u3001\u6838\u5fc3HICP\u3001GDP\u589e\u957f\u3001\u5931\u4e1a\u7387\uff09\u548c\u56db\u4e2a\u9884\u6d4b\u65f6\u95f4\u8de8\u5ea6\u8fdb\u884c\u6bd4\u8f83\uff0c\u540c\u65f6\u4e0e\u65e0\u89d2\u8272\u63cf\u8ff0\u7684100\u4e2a\u57fa\u7ebf\u9884\u6d4b\u7ed3\u679c\u8fdb\u884c\u5bf9\u6bd4\uff0c\u4ee5\u5265\u79bb\u4eba\u683c\u5316\u63d0\u793a\u7684\u5b9e\u9645\u6548\u5e94\u3002", "result": "GPT-4o\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5728\u9884\u6d4b\u51c6\u786e\u6027\u4e0a\u975e\u5e38\u63a5\u8fd1\uff0c\u5c3d\u7ba1\u5dee\u5f02\u5728\u7edf\u8ba1\u5c42\u9762\u663e\u8457\uff0c\u4f46\u5b9e\u9645\u5f71\u54cd\u8f83\u5c0f\u3002GPT-4o\u57282024-2025\u5e74\u672a\u89c1\u6837\u672c\u6570\u636e\u4e0a\u7684\u51c6\u786e\u6027\u4f9d\u7136\u5177\u6709\u7ade\u4e89\u529b\u3002\u6b64\u5916\uff0c\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\uff0c\u52a0\u5165\u4eba\u683c\u5316\u63cf\u8ff0\u5e76\u672a\u7ed9\u9884\u6d4b\u5e26\u6765\u5b9e\u8d28\u6027\u4f18\u52bf\uff0c\u8868\u660e\u53ef\u7701\u7565\u8be5\u6b65\u9aa4\u4ee5\u8282\u7701\u7b97\u529b\u6210\u672c\u4e14\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\u3002\u4e0d\u540c\u63d0\u793a\u8bcd\u4e0b\u7684\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u5f02\u8d28\u6027\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\u4e13\u5bb6\u5c0f\u7ec4\u3002", "conclusion": "GPT-4o\u5728\u5b8f\u89c2\u7ecf\u6d4e\u9884\u6d4b\u4e2d\u80fd\u5728\u6709\u76f8\u5173\u80cc\u666f\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u8fd1\u7684\u51c6\u786e\u6027\uff0c\u4e14\u65e0\u9700\u590d\u6742\u7684\u4eba\u8bbe\u63d0\u793a\uff0c\u63d0\u793a\u591a\u6837\u5316\u5e76\u672a\u6539\u8fdb\u9884\u6d4b\u6548\u679c\uff0c\u53cd\u800c\u6a21\u578b\u8f93\u51fa\u9ad8\u5ea6\u540c\u8d28\u5316\u3002\u5bf9\u4e8e\u5b9e\u9645\u5e94\u7528\uff0c\u53ef\u4ee5\u7701\u7565\u4eba\u8bbe\u63d0\u793a\u4ee5\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2511.02475", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.02475", "abs": "https://arxiv.org/abs/2511.02475", "authors": ["J\u00fcrgen Cito", "Dominik Bork"], "title": "Lost in Code Generation: Reimagining the Role of Software Models in AI-driven Software Engineering", "comment": null, "summary": "Generative AI enables rapid ``vibe coding,\" where natural language prompts\nyield working software systems. While this lowers barriers to software\ncreation, it also collapses the boundary between prototypes and engineered\nsoftware, leading to fragile systems that lack robustness, security, and\nmaintainability. We argue that this shift motivates a reimagining of software\nmodels. Rather than serving only as upfront blueprints, models can be recovered\npost-hoc from AI-generated code to restore comprehension, expose risks, and\nguide refinement. In this role, models serve as mediators between human intent,\nAI generation, and long-term system evolution, providing a path toward\nsustainable AI-driven software engineering.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u7b80\u5316\u4e86\u8f6f\u4ef6\u5f00\u53d1\u4f46\u5e26\u6765\u7cfb\u7edf\u8106\u5f31\u7b49\u95ee\u9898\u3002\u4f5c\u8005\u5efa\u8bae\u901a\u8fc7\u4eceAI\u751f\u6210\u4ee3\u7801\u4e2d\u9006\u5411\u6062\u590d\u8f6f\u4ef6\u6a21\u578b\uff0c\u63d0\u5347\u53ef\u7406\u89e3\u6027\u3001\u98ce\u9669\u7ba1\u63a7\u548c\u7cfb\u7edf\u53ef\u6301\u7eed\u53d1\u5c55\u3002", "motivation": "\u751f\u6210\u5f0fAI\u8fc5\u901f\u63a8\u52a8\u4e86\u81ea\u7136\u8bed\u8a00\u751f\u6210\u8f6f\u4ef6\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u4f46\u5bfc\u81f4\u539f\u578b\u4e0e\u5de5\u7a0b\u5316\u8f6f\u4ef6\u754c\u9650\u6a21\u7cca\uff0c\u7cfb\u7edf\u6613\u8106\u5f31\uff0c\u96be\u4ee5\u7ef4\u62a4\uff0c\u7f3a\u4e4f\u5b89\u5168\u6027\u4e0e\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u6a21\u578b\u5728AI\u751f\u6210\u4ee3\u7801\u540e\u7528\u4e8e\u8865\u5145\u8bbe\u8ba1\u4e0e\u589e\u8fdb\u7406\u89e3\u7684\u65b0\u65b9\u6cd5\u3002", "result": "\u91cd\u5851\u6a21\u578b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u89d2\u8272\uff0c\u8ba9\u5176\u4f5c\u4e3a\u7406\u89e3\u3001\u98ce\u9669\u5206\u6790\u548c\u7cfb\u7edf\u6539\u8fdb\u7684\u4e2d\u4ecb\uff0c\u6709\u52a9\u4e8e\u63a8\u8fdbAI\u751f\u6210\u8f6f\u4ef6\u5411\u66f4\u53ef\u9760\u3001\u66f4\u53ef\u7ef4\u62a4\u7684\u65b9\u5411\u53d1\u5c55\u3002", "conclusion": "\u6a21\u578b\u53ef\u4ee5\u5728AI\u751f\u6210\u4ee3\u7801\u540e\u7528\u4e8e\u6062\u590d\u7406\u89e3\u3001\u66b4\u9732\u98ce\u9669\uff0c\u5e76\u6307\u5bfc\u540e\u7eed\u6539\u8fdb\uff0c\u662f\u5b9e\u73b0\u53ef\u6301\u7eedAI\u9a71\u52a8\u7684\u8f6f\u4ef6\u5de5\u7a0b\u7684\u5173\u952e\u4e2d\u4ecb\u3002"}}
{"id": "2511.02537", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.02537", "abs": "https://arxiv.org/abs/2511.02537", "authors": ["Kenza Khelkhal", "Dihia Lanasri"], "title": "Smart-Hiring: An Explainable end-to-end Pipeline for CV Information Extraction and Job Matching", "comment": null, "summary": "Hiring processes often involve the manual screening of hundreds of resumes\nfor each job, a task that is time and effort consuming, error-prone, and\nsubject to human bias. This paper presents Smart-Hiring, an end-to-end Natural\nLanguage Processing (NLP) pipeline de- signed to automatically extract\nstructured information from unstructured resumes and to semantically match\ncandidates with job descriptions. The proposed system combines document\nparsing, named-entity recognition, and contextual text embedding techniques to\ncapture skills, experience, and qualifications. Using advanced NLP technics,\nSmart-Hiring encodes both resumes and job descriptions in a shared vector space\nto compute similarity scores between candidates and job postings. The pipeline\nis modular and explainable, allowing users to inspect extracted entities and\nmatching rationales. Experiments were conducted on a real-world dataset of\nresumes and job descriptions spanning multiple professional domains,\ndemonstrating the robustness and feasibility of the proposed approach. The\nsystem achieves competitive matching accuracy while preserving a high degree of\ninterpretability and transparency in its decision process. This work introduces\na scalable and practical NLP frame- work for recruitment analytics and outlines\npromising directions for bias mitigation, fairness-aware modeling, and\nlarge-scale deployment of data-driven hiring solutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u81ea\u52a8\u5206\u6790\u7b80\u5386\u4e0e\u804c\u4f4d\u63cf\u8ff0\u3001\u51cf\u5c11\u4eba\u5de5\u504f\u89c1\u4e0e\u5de5\u4f5c\u91cf\u7684NLP\u7cfb\u7edf\uff0c\u5728\u5b9e\u9645\u6570\u636e\u4e0a\u5c55\u73b0\u51fa\u9ad8\u51c6\u786e\u7387\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u667a\u80fd\u62db\u8058\u8fc8\u51fa\u91cd\u8981\u4e00\u6b65\u3002", "motivation": "\u4f20\u7edf\u7684\u62db\u8058\u8fc7\u7a0b\u5f80\u5f80\u9700\u8981\u4eba\u5de5\u7b5b\u9009\u5927\u91cf\u7b80\u5386\uff0c\u8017\u65f6\u8017\u529b\uff0c\u5bb9\u6613\u51fa\u9519\u4e14\u5b58\u5728\u4eba\u4e3a\u504f\u89c1\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u79cd\u81ea\u52a8\u5316\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6cd5\u4ee5\u63d0\u5347\u62db\u8058\u8d28\u91cf\u548c\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u540d\u4e3aSmart-Hiring\u7684\u7aef\u5230\u7aefNLP\u6d41\u7a0b\uff0c\u5305\u62ec\u6587\u6863\u89e3\u6790\u3001\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u4e0a\u4e0b\u6587\u6587\u672c\u5d4c\u5165\u6280\u672f\u3002\u8be5\u7cfb\u7edf\u5c06\u7b80\u5386\u548c\u804c\u4f4d\u63cf\u8ff0\u7f16\u7801\u5230\u540c\u4e00\u5411\u91cf\u7a7a\u95f4\uff0c\u901a\u8fc7\u8ba1\u7b97\u76f8\u4f3c\u5ea6\u5b9e\u73b0\u5019\u9009\u4eba\u4e0e\u804c\u4f4d\u7684\u8bed\u4e49\u5339\u914d\uff0c\u5177\u5907\u6a21\u5757\u5316\u548c\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5728\u8986\u76d6\u591a\u4e2a\u804c\u4e1a\u9886\u57df\u7684\u771f\u5b9e\u7b80\u5386\u548c\u804c\u4f4d\u63cf\u8ff0\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u7cfb\u7edf\u5c55\u793a\u51fa\u8f83\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u53ef\u884c\u6027\uff0c\u5339\u914d\u51c6\u786e\u7387\u5177\u6709\u7ade\u4e89\u529b\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86\u51b3\u7b56\u8fc7\u7a0b\u7684\u9ad8\u5ea6\u53ef\u89e3\u91ca\u6027\u548c\u900f\u660e\u5ea6\u3002", "conclusion": "Smart-Hiring\u4e3a\u62db\u8058\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u5b9e\u7528\u7684NLP\u6846\u67b6\uff0c\u5c55\u73b0\u4e86\u6d88\u9664\u504f\u89c1\u3001\u516c\u5e73\u5efa\u6a21\u548c\u5927\u89c4\u6a21\u81ea\u52a8\u5316\u62db\u8058\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.02713", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.02713", "abs": "https://arxiv.org/abs/2511.02713", "authors": ["Qianru Meng", "Zhaochun Ren", "Joost Visser"], "title": "ReleaseEval: A Benchmark for Evaluating Language Models in Automated Release Note Generation", "comment": null, "summary": "Automated release note generation addresses the challenge of documenting\nfrequent software updates, where manual efforts are time-consuming and prone to\nhuman error. Although recent advances in language models further enhance this\nprocess, progress remains hindered by dataset limitations, including the lack\nof explicit licensing and limited reproducibility, and incomplete task design\nthat relies mainly on commit messages for summarization while overlooking\nfine-grained contexts such as commit hierarchies and code changes. To fill this\ngap, we introduce ReleaseEval, a reproducible and openly licensed benchmark\ndesigned to systematically evaluate language models for automated release note\ngeneration. ReleaseEval comprises 94,987 release notes from 3,369 repositories\nacross 6 programming languages, and supports three task settings with three\nlevels of input granularity: (1) commit2sum, which generates release notes from\ncommit messages; (2) tree2sum, which incorporates commit tree structures; and\n(3) diff2sum, which leverages fine-grained code diffs. Both automated and human\nevaluations show that large language models consistently outperform traditional\nbaselines across all tasks, achieving substantial gains on tree2sum, while\nstill struggling on diff2sum. These findings highlight LLMs' proficiency in\nleveraging structured information while revealing challenges in abstracting\nfrom long code diffs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u516c\u5f00\u53ef\u590d\u73b0\u7684ReleaseEval\u57fa\u51c6\uff0c\u7cfb\u7edf\u8bc4\u6d4b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u751f\u6210\u53d1\u5e03\u8bf4\u660e\u4e0a\u7684\u80fd\u529b\uff0c\u53d1\u73b0LLMs\u80fd\u6709\u6548\u5229\u7528\u7ed3\u6784\u5316\u4fe1\u606f\u4f46\u5904\u7406\u7ec6\u7c92\u5ea6\u4ee3\u7801\u5dee\u5f02\u4ecd\u9700\u63d0\u5347\u3002", "motivation": "\u4eba\u5de5\u64b0\u5199\u53d1\u5e03\u8bf4\u660e\u8017\u65f6\u4e14\u6613\u51fa\u9519\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u53d7\u6570\u636e\u96c6\u8bb8\u53ef\u3001\u590d\u73b0\u80fd\u529b\u3001\u4efb\u52a1\u8bbe\u8ba1\u5355\u4e00\u7b49\u9650\u5236\uff0c\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u4fe1\u606f\u5229\u7528\uff0c\u4e9f\u9700\u66f4\u79d1\u5b66\u7cfb\u7edf\u7684\u8bc4\u6d4b\u57fa\u51c6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aReleaseEval\u7684\u65b0\u57fa\u51c6\uff0c\u5305\u62ec\u4e09\u4e2a\u4efb\u52a1\uff08commit2sum, tree2sum, diff2sum\uff09\uff0c\u6570\u636e\u96c6\u6db5\u76d6\u591a\u4e2a\u7f16\u7a0b\u8bed\u8a00\u548c\u4e30\u5bcc\u6570\u636e\u5c42\u6b21\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u548c\u4eba\u5de5\u8bc4\u4f30\u5bf9\u6bd4\u4e0d\u540c\u65b9\u6cd5\u8868\u73b0\u3002", "result": "LLMs\u5728\u6240\u6709\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u5229\u7528\u7ed3\u6784\u5316\u4fe1\u606f\uff08\u5982commit\u6811\u7ed3\u6784\uff09\u65b9\u9762\u8868\u73b0\u7a81\u51fa\uff0c\u5bf9\u957f\u4ee3\u7801\u5dee\u5f02\uff08diff2sum\uff09\u62bd\u8c61\u63d0\u70bc\u4ecd\u8f83\u56f0\u96be\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u53d1\u5e03\u8bf4\u660e\u751f\u6210\u4efb\u52a1\u4e0a\u6574\u4f53\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u5728\u5904\u7406\u7ec6\u7c92\u5ea6\u4ee3\u7801\u53d8\u66f4\uff08diff2sum\uff09\u4efb\u52a1\u65f6\u4ecd\u6709\u660e\u663e\u6311\u6218\u3002"}}
{"id": "2511.02587", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.02587", "abs": "https://arxiv.org/abs/2511.02587", "authors": ["Angela Stamatie"], "title": "The Analysis of Lexical Errors in Machine Translation from English into Romanian", "comment": "Doctoral thesis", "summary": "The research explores error analysis in the performance of translating by\nMachine Translation from English into Romanian, and it focuses on lexical\nerrors found in texts which include official information, provided by the World\nHealth Organization (WHO), the Gavi Organization, by the patient information\nleaflet (the information about the active ingredients of the vaccines or the\nmedication, the indications, the dosage instructions, the storage instructions,\nthe side effects and warning, etc.). All of these texts are related to Covid-19\nand have been translated by Google Translate, a multilingual Machine\nTranslation that was created by Google. In the last decades, Google has\nactively worked to develop a more accurate and fluent automatic translation\nsystem. This research, specifically focused on improving Google Translate, aims\nto enhance the overall quality of Machine Translation by achieving better\nlexical selection and by reducing errors. The investigation involves a\ncomprehensive analysis of 230 texts that have been translated from English into\nRomanian.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u4e86230\u7bc7\u5b98\u65b9\u53ca\u533b\u5b66\u7c7b\u65b0\u51a0\u76f8\u5173\u6587\u672c\u5728\u8c37\u6b4c\u7ffb\u8bd1\u82f1\u8bd1\u7f57\u65f6\u7684\u8bcd\u6c47\u9519\u8bef\uff0c\u6307\u51fa\u5176\u8bcd\u6c47\u9009\u62e9\u95ee\u9898\uff0c\u5e76\u4e3a\u673a\u5668\u7ffb\u8bd1\u8d28\u91cf\u63d0\u5347\u5efa\u8bae\u6539\u8fdb\u65b9\u6848\u3002", "motivation": "\u9274\u4e8e\u6d89\u75ab\u5b98\u65b9\u548c\u533b\u5b66\u4fe1\u606f\u51c6\u786e\u6027\u7684\u9ad8\u5ea6\u8981\u6c42\uff0c\u4ee5\u53ca\u673a\u5668\u7ffb\u8bd1\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4e0d\u8db3\uff0c\u4e9f\u9700\u5206\u6790\u5e76\u63d0\u5347\u5176\u8bcd\u6c47\u9009\u62e9\u548c\u51cf\u5c11\u7ffb\u8bd1\u9519\u8bef\u3002", "method": "\u901a\u8fc7\u6536\u96c6230\u7bc7\u4e0e\u65b0\u51a0\u76f8\u5173\u3001\u5b98\u65b9\u53ca\u533b\u5b66\u6027\u4fe1\u606f\u6587\u672c\uff0c\u5206\u6790\u8c37\u6b4c\u7ffb\u8bd1\u82f1\u8bd1\u7f57\u7684\u8bcd\u6c47\u9519\u8bef\u7c7b\u578b\u4e0e\u5206\u5e03\u3002", "result": "\u63ed\u793a\u4e86\u8c37\u6b4c\u7ffb\u8bd1\u5728\u533b\u5b66\u548c\u5b98\u65b9\u4fe1\u606f\u7ffb\u8bd1\u4e2d\u5b58\u5728\u660e\u663e\u7684\u8bcd\u6c47\u9519\u8bef\uff0c\u901a\u8fc7\u5206\u6790\u8fd9\u4e9b\u9519\u8bef\u4e3a\u6539\u8fdb\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u8df5\u4f9d\u636e\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u8c37\u6b4c\u7ffb\u8bd1\u5728\u82f1\u8bed\u5230\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u533b\u5b66\u4e0e\u5b98\u65b9\u4fe1\u606f\u7ffb\u8bd1\u4e0a\u7684\u8bcd\u6c47\u9519\u8bef\uff0c\u8868\u660e\u8bcd\u6c47\u9009\u62e9\u6539\u8fdb\u5bf9\u63d0\u5347\u673a\u5668\u7ffb\u8bd1\u8d28\u91cf\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.02736", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.02736", "abs": "https://arxiv.org/abs/2511.02736", "authors": ["Madalena Sasportes", "Grischa Liebel", "Miguel Goul\u00e3o"], "title": "Investigating the Experience of Autistic Individuals in Software Engineering", "comment": null, "summary": "Context: Autism spectrum disorder (ASD) leads to various issues in the\neveryday life of autistic individuals, often resulting in unemployment and\nmental health problems. To improve the inclusion of autistic adults, existing\nstudies have highlighted the strengths these individuals possess in comparison\nto non-autistic individuals, e.g., high attention to detail or excellent\nlogical reasoning skills. If fostered, these strengths could be valuable in\nsoftware engineering activities, such for identifying specific kinds of bugs in\ncode. However, existing work in SE has primarily studied the challenges of\nautistic individuals and possible accommodations, with little attention their\nstrengths. Objective: Our goal is to analyse the experiences of autistic\nindividuals in software engineering activities, such as code reviews, with a\nparticular emphasis on strengths. Methods: This study combines Social-Technical\nGrounded Theory through semi-structured interviews with 16 autistic software\nengineers and a survey with 49 respondents, including 5 autistic participants.\nWe compare the emerging themes with the theory by Gama et al. on the Effect of\nNeurodivergent Cognitive Dysfunctions in Software Engineering Performance.\nResults: Our results suggest that autistic software engineers are often skilled\nin logical thinking, attention to detail, and hyperfocus in programming; and\nthey enjoy learning new programming languages and programming-related\ntechnologies. Confirming previous work, they tend to prefer written\ncommunication and remote work. Finally, we report a high comfort level in\ninteracting with AI-based systems. Conclusions: Our findings extend existing\nwork by providing further evidence on the strengths of autistic software\nengineers.", "AI": {"tldr": "\u81ea\u95ed\u75c7\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u8868\u73b0\u51fa\u663e\u8457\u7684\u903b\u8f91\u601d\u7ef4\u3001\u7ec6\u8282\u5173\u6ce8\u548c\u4e13\u6ce8\u529b\uff0c\u504f\u597d\u4e66\u9762\u6c9f\u901a\u53ca\u8fdc\u7a0b\u5de5\u4f5c\uff0c\u4e0eAI\u7cfb\u7edf\u4e92\u52a8\u65f6\u66f4\u8212\u9002\u3002\u7814\u7a76\u8bc1\u5b9e\u5e76\u8865\u5145\u4e86\u4ed6\u4eec\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u72ec\u7279\u4f18\u52bf\uff0c\u5efa\u8bae\u884c\u4e1a\u66f4\u597d\u5730\u53d1\u6398\u548c\u5229\u7528\u8fd9\u4e9b\u80fd\u529b\uff0c\u4ee5\u63d0\u5347\u5305\u5bb9\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u81ea\u95ed\u75c7\u4e2a\u4f53\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u6311\u6218\u4e0e\u9002\u5e94\uff0c\u800c\u5ffd\u89c6\u4e86\u4ed6\u4eec\u7684\u4f18\u52bf\uff0c\u5982\u9ad8\u5ea6\u7684\u7ec6\u8282\u5173\u6ce8\u548c\u903b\u8f91\u63a8\u7406\u80fd\u529b\u3002\u672c\u6587\u65e8\u5728\u5206\u6790\u81ea\u95ed\u75c7\u4eba\u58eb\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u4e2d\u7684\u4f18\u52bf\uff0c\u4fc3\u8fdb\u4ed6\u4eec\u66f4\u597d\u5730\u53c2\u4e0e\u548c\u5305\u5bb9\u3002", "method": "\u91c7\u7528\u793e\u4f1a\u2014\u6280\u672f\u624e\u6839\u7406\u8bba\uff0c\u901a\u8fc7\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0816\u540d\u81ea\u95ed\u75c7\u8f6f\u4ef6\u5de5\u7a0b\u5e08\uff09\u53ca\u95ee\u5377\u8c03\u67e5\uff0849\u540d\u53c2\u4e0e\u8005\uff0c\u5305\u62ec5\u540d\u81ea\u95ed\u75c7\u4eba\u58eb\uff09\uff0c\u5e76\u5c06\u7814\u7a76\u4e3b\u9898\u4e0eGama\u7b49\u4eba\u5173\u4e8e\u795e\u7ecf\u591a\u6837\u6027\u8ba4\u77e5\u969c\u788d\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u7ee9\u6548\u5f71\u54cd\u7684\u7406\u8bba\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u53d1\u73b0\u81ea\u95ed\u75c7\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u5728\u903b\u8f91\u601d\u7ef4\u3001\u7ec6\u8282\u5173\u6ce8\u548c\u7f16\u7a0b\u65f6\u7684\u9ad8\u5ea6\u4e13\u6ce8\u65b9\u9762\u8868\u73b0\u7a81\u51fa\uff0c\u559c\u6b22\u5b66\u4e60\u65b0\u7f16\u7a0b\u8bed\u8a00\u548c\u76f8\u5173\u6280\u672f\uff0c\u503e\u5411\u4e8e\u4e66\u9762\u6c9f\u901a\u53ca\u8fdc\u7a0b\u5de5\u4f5c\uff0c\u5e76\u4e14\u4e0e\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e92\u52a8\u65f6\u611f\u5230\u8212\u9002\u3002\u7ed3\u679c\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86\u4ed6\u4eec\u7684\u6c9f\u901a\u548c\u5de5\u4f5c\u504f\u597d\u3002", "conclusion": "\u672c\u7814\u7a76\u6269\u5c55\u4e86\u524d\u4eba\u7684\u53d1\u73b0\uff0c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u5e76\u5f3a\u8c03\u4e86\u81ea\u95ed\u75c7\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u5728\u903b\u8f91\u3001\u4e13\u6ce8\u3001\u5b66\u4e60\u548c\u6280\u672f\u9002\u5e94\u6027\u7b49\u65b9\u9762\u7684\u7a81\u51fa\u4f18\u52bf\uff0c\u4e3a\u63d0\u5347\u5176\u884c\u4e1a\u53c2\u4e0e\u548c\u5305\u5bb9\u6027\u63d0\u4f9b\u4e86\u4f9d\u636e\u3002"}}
{"id": "2511.02599", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02599", "abs": "https://arxiv.org/abs/2511.02599", "authors": ["Max Norris", "Kobi Gal", "Sahan Bulathwela"], "title": "Next Token Knowledge Tracing: Exploiting Pretrained LLM Representations to Decode Student Behaviour", "comment": null, "summary": "Modelling student knowledge is a key challenge when leveraging AI in\neducation, with major implications for personalised learning. The Knowledge\nTracing (KT) task aims to predict how students will respond to educational\nquestions in learning environments, based on their prior interactions. Existing\nKT models typically use response correctness along with metadata like skill\ntags and timestamps, often overlooking the question text, which is an important\nsource of pedagogical insight. This omission poses a lost opportunity while\nlimiting predictive performance. We propose Next Token Knowledge Tracing\n(NTKT), a novel approach that reframes KT as a next-token prediction task using\npretrained Large Language Models (LLMs). NTKT represents both student histories\nand question content as sequences of text, allowing LLMs to learn patterns in\nboth behaviour and language. Our series of experiments significantly improves\nperformance over state-of-the-art neural KT models and generalises much better\nto cold-start questions and users. These findings highlight the importance of\nquestion content in KT and demonstrate the benefits of leveraging pretrained\nrepresentations of LLMs to model student learning more effectively.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u878d\u5408\u5927\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u8ffd\u8e2a\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6587\u672c\u5e8f\u5217\u5316\u5b66\u751f\u5386\u53f2\u548c\u95ee\u9898\u5185\u5bb9\uff0c\u663e\u8457\u63d0\u5347KT\u9884\u6d4b\u6548\u679c\uff0c\u5e76\u5728\u65b0\u95ee\u9898\u548c\u65b0\u7528\u6237\u573a\u666f\u4e0b\u5177\u5907\u66f4\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5b66\u751f\u77e5\u8bc6\u8ffd\u8e2a\uff08KT\uff09\u6a21\u578b\u901a\u5e38\u5ffd\u7565\u4e86\u95ee\u9898\u6587\u672c\u8fd9\u4e00\u91cd\u8981\u6559\u5b66\u4e60\u5f97\u4fe1\u606f\u6e90\uff0c\u9650\u5236\u4e86\u4e2a\u6027\u5316\u9884\u6d4b\u7684\u80fd\u529b\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u63a2\u7d22\u5c06\u95ee\u9898\u6587\u672c\u7eb3\u5165KT\u4ee5\u63d0\u5347\u6a21\u578b\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684KT\u65b9\u6cd5\u2014\u2014Next Token Knowledge Tracing\uff08NTKT\uff09\uff0c\u5c06KT\u4efb\u52a1\u8f6c\u5316\u4e3a\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0a\u7684\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\uff0c\u540c\u65f6\u628a\u5b66\u751f\u5386\u53f2\u548c\u95ee\u9898\u5185\u5bb9\u90fd\u8868\u793a\u4e3a\u6587\u672c\u5e8f\u5217\uff0c\u8ba9LLM\u80fd\u591f\u540c\u65f6\u5b66\u4e60\u884c\u4e3a\u548c\u8bed\u8a00\u6a21\u5f0f\u3002", "result": "NTKT\u5728\u591a\u7ec4\u5b9e\u9a8c\u4e2d\u76f8\u6bd4\u73b0\u6709\u6700\u4f18\u795e\u7ecfKT\u6a21\u578b\u8868\u73b0\u51fa\u663e\u8457\u63d0\u5347\uff0c\u5c24\u5176\u5728\u51b7\u542f\u52a8\u95ee\u9898\u548c\u65b0\u7528\u6237\u4e0a\u7684\u6cdb\u5316\u6027\u80fd\u66f4\u4f18\u3002", "conclusion": "\u95ee\u9898\u5185\u5bb9\u5bf9\u4e8e\u77e5\u8bc6\u8ffd\u8e2a\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0c\u5229\u7528\u9884\u8bad\u7ec3LLM\u8868\u8fbe\u80fd\u591f\u66f4\u6709\u6548\u5730\u5b66\u4e60\u5b66\u751f\u77e5\u8bc6\uff0c\u5b9e\u73b0\u66f4\u4f18\u7684\u4e2a\u6027\u5316\u5b66\u4e60\u9884\u6d4b\u3002"}}
{"id": "2511.02810", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.02810", "abs": "https://arxiv.org/abs/2511.02810", "authors": ["Suddhasvatta Das", "Kevin Gary"], "title": "Formalizing Regression Testing for Agile and Continuous Integration Environments", "comment": "This is the first attempt to formalize regression testing in agile\n  context as a continuous/near-continuos activity. This formalization will help\n  practitioners and researchers to answer 'when', 'what' and 'how much'\n  question of regression testing in real world time constrained agile projects.\n  This work is currently under review with Software Quality Journal", "summary": "Software developed using modern agile practices delivers a stream of software\nversions that require continuous regression testing rather than testing once\nclose to the delivery or maintenance phase, as assumed by classical\nregression-testing theory. In this work, we formalize the phenomenon of\ncontinuous or near-continuous regression testing using successive builds as a\ntime-ordered chain, where each build contains the program, requirements, and\nthe accompanying tests. We also formalize the regression test window between\nany two builds, which captures the limited time budget available for regression\ntesting. As the time limit is set to infinity and the chain is closed to two\nbuilds, the model degenerates to retest-all, thereby preserving semantics for\nthe classical two-version case. The formalization is validated by directly\nrepresenting two state-of-the-art agile regression testing algorithms in terms\nof build-tuple operations without requiring auxiliary assumptions, followed by\nproof of the soundness and completeness of our formalization.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u4e86\u9002\u7528\u4e8e\u654f\u6377\u5f00\u53d1\u73af\u5883\u4e0b\u7684\u8fde\u7eed\u56de\u5f52\u6d4b\u8bd5\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u6709\u6548\u7edf\u4e00\u4e86\u65b0\u65e7\u56de\u5f52\u6d4b\u8bd5\u7406\u8bba\uff0c\u5e76\u8bc1\u660e\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u4ee3\u654f\u6377\u5f00\u53d1\u4e0b\uff0c\u8f6f\u4ef6\u7248\u672c\u6301\u7eed\u8fed\u4ee3\uff0c\u56de\u5f52\u6d4b\u8bd5\u9700\u8981\u8d2f\u7a7f\u5f00\u53d1\u5468\u671f\uff0c\u4f20\u7edf\u56de\u5f52\u6d4b\u8bd5\u7406\u8bba\u65e0\u6cd5\u5f88\u597d\u5730\u9002\u5e94\u8fd9\u4e00\u4e0d\u65ad\u4ea4\u4ed8\u7684\u80cc\u666f\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u5f62\u5f0f\u5316\u6a21\u578b\u3002", "method": "\u5c06\u8fde\u7eed\u6216\u8fd1\u8fde\u7eed\u7684\u56de\u5f52\u6d4b\u8bd5\u5f62\u5f0f\u5316\u4e3a\u6309\u65f6\u95f4\u6392\u5e8f\u7684\u6784\u5efa\u94fe\uff0c\u5bf9\u6bcf\u4e00\u6784\u5efa\u5305\u542b\u7a0b\u5e8f\u3001\u9700\u6c42\u548c\u6d4b\u8bd5\uff0c\u5e76\u5b9a\u4e49\u4e86\u6784\u5efa\u4e4b\u95f4\u7684\u56de\u5f52\u6d4b\u8bd5\u7a97\u53e3\u3002\u5229\u7528\u6784\u5efa\u5143\u7ec4\u64cd\u4f5c\uff0c\u65e0\u9700\u989d\u5916\u5047\u8bbe\uff0c\u5373\u53ef\u8868\u8fbe\u4e3b\u6d41\u654f\u6377\u56de\u5f52\u6d4b\u8bd5\u7b97\u6cd5\uff0c\u5e76\u8fdb\u884c\u4e86\u5176\u5b8c\u5907\u6027\u548c\u6b63\u786e\u6027\u7684\u8bc1\u660e\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u53ef\u5b8c\u5168\u8868\u793a\u4e3b\u6d41\u654f\u6377\u56de\u5f52\u6d4b\u8bd5\u7b97\u6cd5\uff0c\u4e14\u6a21\u578b\u7684\u6b63\u786e\u6027\u548c\u5b8c\u5907\u6027\u5f97\u5230\u8bc1\u660e\uff0c\u540c\u65f6\u53ef\u4ee5\u517c\u5bb9\u4e8e\u4f20\u7edf\u56de\u5f52\u6d4b\u8bd5\u7279\u4f8b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u8fde\u7eed\u56de\u5f52\u6d4b\u8bd5\u5f62\u5f0f\u5316\u6a21\u578b\u6709\u6548\u5730\u6982\u62ec\u4e86\u8f6f\u4ef6\u7248\u672c\u8fed\u4ee3\u4e2d\u56de\u5f52\u6d4b\u8bd5\u7684\u5b9e\u9645\u9700\u6c42\uff0c\u5e76\u80fd\u6db5\u76d6\u7ecf\u5178\u4e24\u7248\u672c\u56de\u5f52\u6d4b\u8bd5\u7684\u8bed\u4e49\u3002"}}
{"id": "2511.02603", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.02603", "abs": "https://arxiv.org/abs/2511.02603", "authors": ["Ehsan Aghazadeh", "Ahmad Ghasemi", "Hedyeh Beyhaghi", "Hossein Pishro-Nik"], "title": "CGES: Confidence-Guided Early Stopping for Efficient and Accurate Self-Consistency", "comment": "Efficient Reasoning @ NeurIPS2025", "summary": "Large language models (LLMs) are often queried multiple times at test time,\nwith predictions aggregated by majority vote. While effective, this\nself-consistency strategy (arXiv:2203.11171) requires a fixed number of calls\nand can fail when the correct answer is rare. We introduce Confidence-Guided\nEarly Stopping (CGES), a Bayesian framework that forms posteriors over\ncandidate answers using scalar confidence signals derived from token\nprobabilities or reward models. CGES adaptively halts sampling once the\nposterior mass of a candidate exceeds a threshold. We provide theoretical\nguarantees for both perfectly calibrated confidences and realistic noisy\nconfidence signals. Across five reasoning benchmarks, CGES reduces the average\nnumber of model calls by about 69 percent (for example, from 16.0 to 4.9) while\nmatching the accuracy of self-consistency within 0.06 percentage points.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u4e86\u5229\u7528\u7f6e\u4fe1\u4fe1\u53f7\u5f15\u5bfc\u81ea\u9002\u5e94\u91c7\u6837\u505c\u6b62\u7684\u65b0\u65b9\u6cd5CGES\uff0c\u53ef\u5728\u4fdd\u8bc1\u6a21\u578b\u9884\u6d4b\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u51cf\u5c11\u6a21\u578b\u8c03\u7528\u6b21\u6570\uff0c\u5177\u6709\u7406\u8bba\u4e0e\u5b9e\u9a8c\u4f18\u52bf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6d4b\u8bd5\u9636\u6bb5\u5e38\u5e38\u8fdb\u884c\u591a\u6b21\u67e5\u8be2\uff0c\u5e76\u901a\u8fc7\u591a\u6570\u6295\u7968\u7684\u65b9\u5f0f\u6c47\u603b\u9884\u6d4b\u7ed3\u679c\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u81ea\u6d3d\u7b56\u7565\u9700\u8981\u56fa\u5b9a\u6b21\u6570\u7684\u6a21\u578b\u8c03\u7528\uff0c\u5e76\u4e14\u5728\u6b63\u786e\u7b54\u6848\u7f55\u89c1\u65f6\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86Confidence-Guided Early Stopping\uff08CGES\uff09\u65b9\u6cd5\u3002\u8fd9\u662f\u4e00\u79cd\u8d1d\u53f6\u65af\u6846\u67b6\uff0c\u57fa\u4e8etoken\u6982\u7387\u6216\u5956\u52b1\u6a21\u578b\u63a8\u65ad\u51fa\u7684\u7f6e\u4fe1\u4fe1\u53f7\uff0c\u5bf9\u5019\u9009\u7b54\u6848\u5f62\u6210\u540e\u9a8c\u5206\u5e03\uff0c\u5e76\u5728\u67d0\u4e2a\u5019\u9009\u7684\u540e\u9a8c\u8d28\u91cf\u8d85\u8fc7\u9608\u503c\u65f6\u81ea\u9002\u5e94\u5730\u505c\u6b62\u91c7\u6837\u3002\u8be5\u65b9\u6cd5\u517c\u5bb9\u7406\u60f3\u6821\u51c6\u7f6e\u4fe1\u5ea6\u548c\u73b0\u5b9e\u4e2d\u7684\u566a\u58f0\u7f6e\u4fe1\u4fe1\u53f7\uff0c\u5e76\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u3002", "result": "\u5728\u4e94\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCGES\u5c06\u5e73\u5747\u6a21\u578b\u8c03\u7528\u6b21\u6570\u51cf\u5c11\u7ea669%\uff08\u4f8b\u5982\u4ece16.0\u6b21\u51cf\u5c11\u52304.9\u6b21\uff09\uff0c\u4e14\u51c6\u786e\u7387\u4e0e\u81ea\u6d3d\u7b56\u7565\u76f8\u5dee\u4e0d\u52300.06\u767e\u5206\u70b9\u3002", "conclusion": "CGES\u65b9\u6cd5\u80fd\u591f\u5927\u5e45\u964d\u4f4e\u67e5\u8be2\u6b21\u6570\uff0c\u540c\u65f6\u51e0\u4e4e\u4e0d\u635f\u5931\u51c6\u786e\u7387\uff0c\u662f\u591a\u6570\u6295\u7968\u81ea\u6d3d\u7b56\u7565\u7684\u6709\u6548\u66ff\u4ee3\u3002"}}
{"id": "2511.02827", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.02827", "abs": "https://arxiv.org/abs/2511.02827", "authors": ["Mohamed Almukhtar", "Anwar Ghammam", "Marouane Kessentini", "Hua Ming"], "title": "From Code Changes to Quality Gains: An Empirical Study in Python ML Systems with PyQu", "comment": "Accepted for publication in the proceedings of IEEE/ACM 48th\n  International Conference on Software Engineering", "summary": "In an era shaped by Generative Artificial Intelligence for code generation\nand the rising adoption of Python-based Machine Learning systems (MLS),\nsoftware quality has emerged as a major concern. As these systems grow in\ncomplexity and importance, a key obstacle lies in understanding exactly how\nspecific code changes affect overall quality-a shortfall aggravated by the lack\nof quality assessment tools and a clear mapping between ML systems code changes\nand their quality effects. Although prior work has explored code changes in\nMLS, it mostly stops at what the changes are, leaving a gap in our knowledge of\nthe relationship between code changes and the MLS quality. To address this gap,\nwe conducted a large-scale empirical study of 3,340 open-source Python ML\nprojects, encompassing more than 3.7 million commits and 2.7 trillion lines of\ncode. We introduce PyQu, a novel tool that leverages low level software metrics\nto identify quality-enhancing commits with an average accuracy, precision, and\nrecall of 0.84 and 0.85 of average F1 score. Using PyQu and a thematic\nanalysis, we identified 61 code changes, each demonstrating a direct impact on\nenhancing software quality, and we classified them into 13 categories based on\ncontextual characteristics. 41% of the changes are newly discovered by our\nstudy and have not been identified by state-of-the-art Python changes detection\ntools. Our work offers a vital foundation for researchers, practitioners,\neducators, and tool developers, advancing the quest for automated quality\nassessment and best practices in Python-based ML software.", "AI": {"tldr": "\u63d0\u51faPyQu\u5de5\u5177\uff0c\u6df1\u5165\u5206\u67903340\u4e2aPython\u673a\u5668\u5b66\u4e60\u5f00\u6e90\u9879\u76ee\uff0c\u53d1\u73b0\u548c\u5f52\u7eb3\u51fa13\u7c7b\u3001\u517161\u79cd\u76f4\u63a5\u63d0\u5347\u8d28\u91cf\u7684\u4ee3\u7801\u53d8\u66f4\uff0c\u5176\u4e2d41%\u4e3a\u9996\u6b21\u53d1\u73b0\uff0c\u4e3a\u4eca\u540e\u81ea\u52a8\u5316\u8d28\u91cf\u8bc4\u4f30\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u548c\u57fa\u4e8ePython\u7684\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5e7f\u6cdb\u5e94\u7528\uff0c\u4ee3\u7801\u8d28\u91cf\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u6709\u6548\u7684\u5de5\u5177\u548c\u65b9\u6cd5\u5c06\u4ee3\u7801\u53d8\u66f4\u4e0e\u8f6f\u4ef6\u8d28\u91cf\u5f71\u54cd\u76f4\u63a5\u5173\u8054\u3002\u5148\u524d\u5de5\u4f5c\u5927\u591a\u4ec5\u505c\u7559\u5728\u63cf\u8ff0\u53d8\u66f4\u5185\u5bb9\uff0c\u672a\u660e\u786e\u9610\u8ff0\u5176\u5bf9\u8d28\u91cf\u7684\u5177\u4f53\u5f71\u54cd\u3002", "method": "\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u4e863340\u4e2a\u5f00\u6e90Python\u673a\u5668\u5b66\u4e60\u9879\u76ee\uff0c\u6d89\u53ca370\u591a\u4e07\u6b21\u63d0\u4ea4\u548c2.7\u4e07\u4ebf\u884c\u4ee3\u7801\u3002\u63d0\u51fa\u4e86\u65b0\u5de5\u5177PyQu\uff0c\u57fa\u4e8e\u5e95\u5c42\u8f6f\u4ef6\u5ea6\u91cf\u8bc6\u522b\u63d0\u5347\u8d28\u91cf\u7684\u4ee3\u7801\u63d0\u4ea4\uff0c\u5e76\u7ed3\u5408\u4e3b\u9898\u5206\u6790\u6cd5\u5bf9\u5f71\u54cd\u8d28\u91cf\u7684\u4ee3\u7801\u53d8\u66f4\u8fdb\u884c\u5206\u7c7b\u3002", "result": "PyQu\u5de5\u5177\u80fd\u591f\u4ee50.84\u7684\u5e73\u5747\u51c6\u786e\u7387\u3001\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u4ee5\u53ca0.85\u7684F1\u5206\u6570\u8bc6\u522b\u63d0\u5347\u8d28\u91cf\u7684\u4ee3\u7801\u63d0\u4ea4\u3002\u5171\u5f52\u7eb3\u51fa61\u79cd\u76f4\u63a5\u63d0\u5347\u8d28\u91cf\u7684\u4ee3\u7801\u53d8\u66f4\uff0c\u5206\u4e3a13\u7c7b\uff0c\u5176\u4e2d41%\u4e3a\u9996\u6b21\u53d1\u73b0\uff0c\u672a\u88ab\u73b0\u6709\u68c0\u6d4b\u5de5\u5177\u8986\u76d6\u3002", "conclusion": "\u672c\u6587\u6784\u5efa\u4e86\u4ee3\u7801\u53d8\u66f4\u4e0ePython\u673a\u5668\u5b66\u4e60\u8f6f\u4ef6\u8d28\u91cf\u5f71\u54cd\u4e4b\u95f4\u7684\u6865\u6881\uff0c\u63d0\u51fa\u4e86\u65b0\u5de5\u5177\u548c\u53d8\u66f4\u5206\u7c7b\uff0c\u4e3a\u81ea\u52a8\u5316\u8d28\u91cf\u8bc4\u4f30\u548c\u6700\u4f73\u5b9e\u8df5\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0e\u5de5\u5177\u57fa\u7840\u3002"}}
{"id": "2511.02623", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.02623", "abs": "https://arxiv.org/abs/2511.02623", "authors": ["Aakash Sen Sharma", "Debdeep Sanyal", "Vivek Srivastava", "Shirish Karande", "Murari Mandal"], "title": "The Realignment Problem: When Right becomes Wrong in LLMs", "comment": "23 Pages", "summary": "The alignment of Large Language Models (LLMs) with human values is central to\ntheir safe deployment, yet current practice produces static, brittle, and\ncostly-to-maintain models that fail to keep pace with evolving norms and\npolicies. This misalignment, which we term the Alignment-Reality Gap, poses a\ngrowing challenge for reliable long-term use. Existing remedies are inadequate:\nlarge-scale re-annotation is economically prohibitive, and standard unlearning\nmethods act as blunt instruments that erode utility rather than enable precise\npolicy updates. We introduce TRACE (Triage and Re-align by Alignment Conflict\nEvaluation), a framework for principled unlearning that reconceives\nre-alignment as a programmatic policy application problem. TRACE\nprogrammatically triages existing preference data against a new policy,\nidentifies high-impact conflicts via a alignment impact score, and applies a\nhybrid optimization that cleanly inverts, discards, or preserves preferences\nwhile safeguarding model performance. Empirical results show that TRACE\nachieves robust re-alignment across diverse model families (Qwen2.5-7B,\nGemma-2-9B, Llama-3.1-8B). On both synthetic benchmarks and the PKU-SafeRLHF\ndataset under complex policy shift, TRACE enforces new principles without\ndegrading general capabilities. Our work establishes a scalable, dynamic, and\ncost-effective paradigm for maintaining LLM alignment, providing a foundation\nfor sustainable and responsible AI deployment.", "AI": {"tldr": "\u8bba\u6587\u9488\u5bf9LLMs\u56e0\u793e\u4f1a\u89c4\u8303\u53d8\u5316\u9891\u7e41\u5e26\u6765\u7684\u201c\u5bf9\u9f50-\u73b0\u5b9e\u5dee\u8ddd\u201d\u95ee\u9898\uff0c\u63d0\u51faTRACE\u6846\u67b6\uff0c\u4ee5\u7a0b\u5e8f\u5316\u3001\u7cbe\u51c6\u7684\u65b9\u5f0f\u8c03\u6574\u6a21\u578b\u504f\u597d\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u52a8\u6001\u7684\u6a21\u578b\u91cd\u65b0\u5bf9\u9f50\uff0c\u5e76\u5728\u591a\u4e2a\u6a21\u578b\u548c\u5b9e\u9645\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u4e86\u6548\u679c\uff0c\u63a8\u52a8\u4e86LLM\u5b89\u5168\u548c\u6301\u7eed\u90e8\u7f72\u7684\u8fdb\u7a0b\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u4eba\u7c7b\u4ef7\u503c\u5bf9\u9f50\uff0c\u5b58\u5728\u6a21\u578b\u9759\u6001\u3001\u6613\u7834\u88c2\u4e14\u7ef4\u62a4\u6210\u672c\u9ad8\u7b49\u95ee\u9898\uff0c\u96be\u4ee5\u9002\u5e94\u4e0d\u65ad\u53d8\u5316\u7684\u793e\u4f1a\u89c4\u8303\u548c\u653f\u7b56\uff0c\u9020\u6210\u201c\u5bf9\u9f50-\u73b0\u5b9e\u5dee\u8ddd\u201d\uff08Alignment-Reality Gap\uff09\u3002", "method": "\u63d0\u51fa\u4e86TRACE\u6846\u67b6\uff0c\u5c06\u91cd\u65b0\u5bf9\u9f50\u89c6\u4e3a\u7a0b\u5e8f\u5316\u7684\u653f\u7b56\u5e94\u7528\u95ee\u9898\u3002TRACE\u80fd\u591f\u7b5b\u9009\u4e0e\u6700\u65b0\u653f\u7b56\u51b2\u7a81\u7684\u504f\u597d\u6570\u636e\uff0c\u901a\u8fc7\u5bf9\u9f50\u5f71\u54cd\u5206\u6570\u7cbe\u786e\u5b9a\u4f4d\u9ad8\u51b2\u7a81\u70b9\uff0c\u5e76\u4ee5\u6df7\u5408\u4f18\u5316\u65b9\u5f0f\u53cd\u8f6c\u3001\u4e22\u5f03\u6216\u4fdd\u7559\u504f\u597d\uff0c\u786e\u4fdd\u6a21\u578b\u6027\u80fd\uff0c\u907f\u514d\u5927\u89c4\u6a21\u6ce8\u91ca\u6216\u66b4\u529b\u5f0f\u5378\u8f7d\u7684\u5f0a\u7aef\u3002", "result": "TRACE\u5728\u591a\u79cd\u4e3b\u6d41\u6a21\u578b\uff08\u5982Qwen2.5-7B\u3001Gemma-2-9B\u3001Llama-3.1-8B\uff09\u548c\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u53caPKU-SafeRLHF\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u653f\u7b56\u53d8\u5316\u4e0b\u5b9e\u8bc1\u8bc4\u4f30\u3002\u7ed3\u679c\u8868\u660e\uff0c\u4e0d\u635f\u5931\u901a\u7528\u80fd\u529b\u7684\u524d\u63d0\u4e0b\uff0cTRACE\u80fd\u6709\u6548\u65bd\u52a0\u65b0\u539f\u5219\uff0c\u5b9e\u73b0\u7a33\u5065\u7684\u6a21\u578b\u91cd\u65b0\u5bf9\u9f50\u3002", "conclusion": "TRACE\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u52a8\u6001\u4e14\u7ecf\u6d4e\u9ad8\u6548\u7684LLM\u6301\u7eed\u5bf9\u9f50\u65b0\u8303\u5f0f\uff0c\u4e3a\u8d1f\u8d23\u4efb\u548c\u53ef\u6301\u7eed\u7684AI\u90e8\u7f72\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.02626", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.02626", "abs": "https://arxiv.org/abs/2511.02626", "authors": ["Renfei Dang", "Peng Hu", "Changjiang Gao", "Shujian Huang"], "title": "Understanding New-Knowledge-Induced Factual Hallucinations in LLMs: Analysis, Solution, and Interpretation", "comment": null, "summary": "Previous studies show that introducing new knowledge during large language\nmodels (LLMs) fine-tuning can lead to the generation of erroneous output when\ntested on known information, thereby triggering factual hallucinations.\nHowever, existing studies have not deeply investigated the specific\nmanifestations and underlying mechanisms of these hallucinations. Our work\naddresses this gap by designing a controlled dataset Biography-Reasoning, and\nconducting a fine-grained analysis across multiple knowledge types and two task\ntypes, including knowledge question answering (QA) and knowledge reasoning\ntasks. We find that when fine-tuned on a dataset in which a specific knowledge\ntype consists entirely of new knowledge, LLMs exhibit significantly increased\nhallucination tendencies. This suggests that the high unfamiliarity of a\nparticular knowledge type, rather than the overall proportion of new knowledge,\nis a stronger driver of hallucinations, and these tendencies can even affect\nother knowledge types in QA tasks. To mitigate such factual hallucinations, we\npropose KnownPatch, which patches a small number of known knowledge samples in\nthe later stages of training, effectively alleviating new-knowledge-induced\nhallucinations. Through attention analysis, we find that learning new knowledge\nreduces the model's attention to key entities in the question, thus causing\nexcessive focus on the surrounding context, which may increase the risk of\nhallucination. Moreover, the attention pattern can propagate to similar\ncontexts, facilitating the spread of hallucinations to textually similar\nquestions. Our method effectively mitigates the disruption of new knowledge\nlearning to the model's attention on key entities, accompanied by improved\nperformance.", "AI": {"tldr": "\u5f15\u5165\u65b0\u77e5\u8bc6\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u4f1a\u663e\u8457\u589e\u52a0\u4e8b\u5b9e\u5e7b\u89c9\uff0c\u7279\u522b\u662f\u9488\u5bf9\u67d0\u7c7b\u77e5\u8bc6\u7684\u9ad8\u5ea6\u964c\u751f\u6027\u3002\u672c\u7814\u7a76\u63ed\u793a\u4e86\u5e7b\u89c9\u53d1\u751f\u673a\u5236\uff0c\u5e76\u63d0\u51faKnownPatch\u65b9\u6cd5\u901a\u8fc7\u8865\u5145\u5c11\u91cf\u5df2\u77e5\u77e5\u8bc6\u6709\u6548\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u5347\u6a21\u578b\u6ce8\u610f\u529b\u5206\u5e03\u548c\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5c1a\u672a\u6df1\u5165\u63a2\u8ba8\u5927\u6a21\u578b\u5f15\u5165\u65b0\u77e5\u8bc6\u540e\u4ea7\u751f\u60c5\u62a5\u5e7b\u89c9\u7684\u5177\u4f53\u8868\u73b0\u4e0e\u673a\u5236\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5206\u6790\u5176\u6210\u56e0\u5e76\u5bfb\u6c42\u7f13\u89e3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u4e86\u53d7\u63a7\u6570\u636e\u96c6Biography-Reasoning\uff0c\u5728\u591a\u4e2a\u77e5\u8bc6\u7c7b\u578b\u548c\u4e24\u7c7b\u4efb\u52a1\uff08\u95ee\u7b54\u4e0e\u77e5\u8bc6\u63a8\u7406\uff09\u4e0b\u7ec6\u7c92\u5ea6\u5206\u6790\u5e7b\u89c9\u73b0\u8c61\u53ca\u5176\u673a\u5236\uff0c\u5e76\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u5206\u6790\u9a8c\u8bc1\u5176\u5f71\u54cd\u3002\u63d0\u51fa\u4e86KnownPatch\u65b9\u6cd5\uff0c\u5728\u8bad\u7ec3\u540e\u671f\u5f15\u5165\u5c11\u91cf\u5df2\u77e5\u77e5\u8bc6\u4ee5\u51cf\u5c11\u65b0\u77e5\u8bc6\u5e26\u6765\u7684\u8d1f\u9762\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u5bf9\u67d0\u4e00\u77e5\u8bc6\u7c7b\u578b\u7684\u65b0\u77e5\u8bc6\u964c\u751f\u6027\u6bd4\u603b\u4f53\u65b0\u77e5\u8bc6\u6bd4\u4f8b\u66f4\u80fd\u5bfc\u81f4\u6a21\u578b\u5e7b\u89c9\uff1b\u5e7b\u89c9\u503e\u5411\u53ef\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u6269\u6563\u81f3\u5176\u4ed6\u77e5\u8bc6\u7c7b\u578b\u3002KnownPatch\u65b9\u6cd5\u6709\u6548\u6539\u5584\u4e86\u6a21\u578b\u6ce8\u610f\u529b\u5206\u914d\uff0c\u51cf\u5c11\u5e7b\u89c9\u5e76\u63d0\u5347\u95ee\u7b54\u8868\u73b0\u3002", "conclusion": "\u901a\u8fc7\u5728\u8bad\u7ec3\u540e\u9636\u6bb5\u52a0\u5165\u5c11\u91cf\u5df2\u77e5\u77e5\u8bc6\u6837\u672c\u7684\u65b9\u6cd5KnownPatch\uff0c\u80fd\u6709\u6548\u7f13\u89e3\u56e0\u5f15\u5165\u65b0\u77e5\u8bc6\u800c\u5bfc\u81f4\u7684\u5927\u6a21\u578b\u865a\u5047\u4fe1\u606f\uff08factual hallucinations\uff09\u95ee\u9898\uff0c\u5e76\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2511.02681", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02681", "abs": "https://arxiv.org/abs/2511.02681", "authors": ["Mohammadsajad Alipour", "Mohammad Mohammadi Amiri"], "title": "Optimal Singular Damage: Efficient LLM Inference in Low Storage Regimes", "comment": null, "summary": "Large language models (LLMs) are increasingly prevalent across diverse\napplications. However, their enormous size limits storage and processing\ncapabilities to a few well-resourced stakeholders. As a result, most\napplications rely on pre-trained LLMs, fine-tuned for specific tasks. However,\neven storing the fine-tuned versions of these models remains a significant\nchallenge due to the wide range of tasks they address. Recently, studies show\nthat fine-tuning these models primarily affects a small fraction of parameters,\nhighlighting the need for more efficient storage of fine-tuned models. This\npaper focuses on efficient storage of parameter updates in pre-trained models\nafter fine-tuning. To address this challenge, we leverage the observation that\nfine-tuning updates are both low-rank and sparse, which can be utilized for\nstorage efficiency. However, using only low-rank approximation or\nsparsification may discard critical singular components that enhance model\nexpressivity. We first observe that given the same memory budget, sparsified\nlow-rank approximations with larger ranks outperform standard low-rank\napproximations with smaller ranks. Building on this, we propose our method,\noptimal singular damage, that selectively sparsifies low-rank approximated\nupdates by leveraging the interleaved importance of singular vectors, ensuring\nthat the most impactful components are retained. We demonstrate through\nextensive experiments that our proposed methods lead to significant storage\nefficiency and superior accuracy within the same memory budget compared to\nemploying the low-rank approximation or sparsification individually.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4f4e\u79e9\u8fd1\u4f3c\u548c\u9009\u62e9\u6027\u7a00\u758f\u5316\u7684\u65b0\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5fae\u8c03\u53c2\u6570\u5b58\u50a8\u6548\u7387\uff0c\u540c\u65f6\u5728\u540c\u6837\u5b58\u50a8\u6761\u4ef6\u4e0b\u7cbe\u5ea6\u4f18\u4e8e\u4f20\u7edf\u65b9\u6848\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8d8a\u6765\u8d8a\u5e7f\u6cdb\u5730\u5e94\u7528\u4e8e\u5404\u7c7b\u573a\u666f\uff0c\u4f46\u7531\u4e8e\u5176\u89c4\u6a21\u5de8\u5927\uff0c\u5b58\u50a8\u548c\u5904\u7406\u80fd\u529b\u4ec5\u9650\u4e8e\u5c11\u6570\u8d44\u6e90\u5145\u8db3\u7684\u7ec4\u7ec7\u3002\u5373\u4f7f\u662f\u9488\u5bf9\u5177\u4f53\u4efb\u52a1\u5fae\u8c03\u540e\u7684\u6a21\u578b\uff0c\u4e5f\u9762\u4e34\u7740\u5b58\u50a8\u96be\u9898\uff0c\u56e0\u6b64\u6025\u9700\u63d0\u9ad8\u5fae\u8c03\u6a21\u578b\u53c2\u6570\u5b58\u50a8\u7684\u6548\u7387\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5206\u6790\u5fae\u8c03\u540e\u7684\u53c2\u6570\u66f4\u65b0\uff0c\u53d1\u73b0\u8fd9\u4e9b\u66f4\u65b0\u5177\u6709\u4f4e\u79e9\u548c\u7a00\u758f\u6027\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u2014\u2014optimal singular damage\uff0c\u901a\u8fc7\u5bf9\u4f4e\u79e9\u8fd1\u4f3c\u53c2\u6570\u8fdb\u884c\u9009\u62e9\u6027\u7a00\u758f\u5316\uff0c\u5229\u7528\u5947\u5f02\u5411\u91cf\u7684\u91cd\u8981\u6027\u6392\u5e8f\uff0c\u4fdd\u7559\u5bf9\u6a21\u578b\u6548\u679c\u5f71\u54cd\u6700\u5927\u7684\u7ec4\u5206\uff0c\u63d0\u5347\u5b58\u50a8\u6548\u7387\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u91c7\u7528\u8be5\u65b9\u6cd5\u540e\uff0c\u5728\u76f8\u540c\u7684\u5b58\u50a8\u9884\u7b97\u4e0b\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u5b58\u50a8\u6548\u7387\uff0c\u5e76\u4e14\u6a21\u578b\u7cbe\u5ea6\u9ad8\u4e8e\u4ec5\u4f7f\u7528\u4f4e\u79e9\u8fd1\u4f3c\u6216\u7a00\u758f\u5316\u7684\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u5728\u4e0d\u635f\u5931\u6a21\u578b\u8868\u73b0\u7684\u524d\u63d0\u4e0b\uff0c\u5927\u5e45\u63d0\u5347\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u53c2\u6570\u7684\u5b58\u50a8\u6548\u7387\uff0c\u4e3a\u6a21\u578b\u90e8\u7f72\u548c\u5e94\u7528\u5e26\u6765\u7684\u5b58\u50a8\u538b\u529b\u63d0\u4f9b\u89e3\u51b3\u601d\u8def\u3002"}}
{"id": "2511.02721", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.02721", "abs": "https://arxiv.org/abs/2511.02721", "authors": ["Doreen Osmelak", "Koel Dutta Chowdhury", "Uliana Sentsova", "Cristina Espa\u00f1a-Bonet", "Josef van Genabith"], "title": "PragExTra: A Multilingual Corpus of Pragmatic Explicitation in Translation", "comment": null, "summary": "Translators often enrich texts with background details that make implicit\ncultural meanings explicit for new audiences. This phenomenon, known as\npragmatic explicitation, has been widely discussed in translation theory but\nrarely modeled computationally. We introduce PragExTra, the first multilingual\ncorpus and detection framework for pragmatic explicitation. The corpus covers\neight language pairs from TED-Multi and Europarl and includes additions such as\nentity descriptions, measurement conversions, and translator remarks. We\nidentify candidate explicitation cases through null alignments and refined\nusing active learning with human annotation. Our results show that entity and\nsystem-level explicitations are most frequent, and that active learning\nimproves classifier accuracy by 7-8 percentage points, achieving up to 0.88\naccuracy and 0.82 F1 across languages. PragExTra establishes pragmatic\nexplicitation as a measurable, cross-linguistic phenomenon and takes a step\ntowards building culturally aware machine translation. Keywords: translation,\nmultilingualism, explicitation", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u6784\u5efa\u4e86\u9996\u4e2a\u591a\u8bed\u79cd\u7ffb\u8bd1\u663e\u5316\u8bed\u6599\u5e93PragExTra\uff0c\u4ee5\u53ca\u81ea\u52a8\u68c0\u6d4b\u6846\u67b6\uff0c\u5bf98\u79cd\u8bed\u8a00\u5bf9\u8fdb\u884c\u4e86\u7cfb\u7edf\u7814\u7a76\u3002\u7ed3\u679c\u663e\u793a\u4e3b\u52a8\u5b66\u4e60\u80fd\u663e\u8457\u63d0\u5347\u663e\u5316\u68c0\u6d4b\u6548\u679c\uff0c\u5e76\u4e3a\u5efa\u8bbe\u66f4\u5177\u6587\u5316\u610f\u8bc6\u7684\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5de5\u5177\u548c\u6570\u636e\u57fa\u7840\u3002", "motivation": "\u7ffb\u8bd1\u8fc7\u7a0b\u4e2d\uff0c\u8bd1\u8005\u5e38\u5e38\u9700\u8981\u4e3a\u4e0d\u540c\u6587\u5316\u80cc\u666f\u7684\u8bfb\u8005\u8865\u5145\u9690\u542b\u4fe1\u606f\uff0c\u8fd9\u4e00\u73b0\u8c61\u88ab\u79f0\u4e3a\u201c\u8bed\u7528\u663e\u5316\u201d\u3002\u867d\u7136\u7ffb\u8bd1\u7406\u8bba\u5bf9\u5176\u6709\u8f83\u591a\u8ba8\u8bba\uff0c\u4f46\u5728\u8ba1\u7b97\u5efa\u6a21\u65b9\u9762\u5374\u7814\u7a76\u751a\u5c11\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86PragExTra\uff0c\u8fd9\u662f\u9996\u4e2a\u9488\u5bf9\u8bed\u7528\u663e\u5316\u7684\u591a\u8bed\u8a00\u8bed\u6599\u5e93\u53ca\u68c0\u6d4b\u6846\u67b6\uff0c\u6db5\u76d68\u79cd\u8bed\u8a00\u5bf9\uff0c\u5e76\u5229\u7528TED-Multi\u548cEuroparl\u6570\u636e\uff0c\u7ed3\u5408\u4e3b\u52a8\u5b66\u4e60\u548c\u4eba\u5de5\u6807\u6ce8\u6765\u7b5b\u9009\u548c\u7cbe\u70bc\u663e\u5316\u5b9e\u4f8b\u3002", "result": "\u901a\u8fc7\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\uff0c\u5c06\u5206\u7c7b\u5668\u51c6\u786e\u7387\u63d0\u5347\u4e867-8\u4e2a\u767e\u5206\u70b9\uff0c\u6700\u9ad8\u8fbe\u52300.88\u7684\u51c6\u786e\u7387\u548c0.82\u7684F1\u503c\u3002\u5b9e\u4f53\u548c\u7cfb\u7edf\u7ea7\u522b\u7684\u663e\u5316\u6700\u4e3a\u5e38\u89c1\u3002", "conclusion": "PragExTra\u8bed\u6599\u5e93\u548c\u6846\u67b6\u8bc1\u660e\u4e86\u8bed\u7528\u663e\u5316\u662f\u4e00\u79cd\u53ef\u5ea6\u91cf\u3001\u53ef\u8de8\u8bed\u8a00\u7814\u7a76\u7684\u73b0\u8c61\uff0c\u5e76\u4e3a\u672a\u6765\u6587\u5316\u654f\u611f\u7684\u673a\u5668\u7ffb\u8bd1\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.02752", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.02752", "abs": "https://arxiv.org/abs/2511.02752", "authors": ["Amit Misra", "Syed Waqas Zamir", "Wassim Hamidouche", "Inbal Becker-Reshef", "Juan Lavista Ferres"], "title": "AI Diffusion in Low Resource Language Countries", "comment": "9 pages, 4 tables. Also available at\n  https://aka.ms/AI_Diffusion_Low_Resource_Language_Countries", "summary": "Artificial intelligence (AI) is diffusing globally at unprecedented speed,\nbut adoption remains uneven. Frontier Large Language Models (LLMs) are known to\nperform poorly on low-resource languages due to data scarcity. We hypothesize\nthat this performance deficit reduces the utility of AI, thereby slowing\nadoption in Low-Resource Language Countries (LRLCs). To test this, we use a\nweighted regression model to isolate the language effect from socioeconomic and\ndemographic factors, finding that LRLCs have a share of AI users that is\napproximately 20% lower relative to their baseline. These results indicate that\nlinguistic accessibility is a significant, independent barrier to equitable AI\ndiffusion.", "AI": {"tldr": "\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u56fd\u5bb6\u8868\u73b0\u4e0d\u4f73\uff0c\u5bfc\u81f4\u8fd9\u4e9b\u56fd\u5bb6AI\u7528\u6237\u6bd4\u4f8b\u4f4e20%\uff0c\u8bed\u8a00\u969c\u788d\u662fAI\u666e\u53ca\u7684\u91cd\u8981\u963b\u788d\u56e0\u7d20\u3002", "motivation": "\u5c3d\u7ba1\u5168\u7403\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u6269\u6563\u901f\u5ea6\u6781\u5feb\uff0c\u4f46\u5728\u4e0d\u540c\u5730\u533a\u7684\u91c7\u7528\u60c5\u51b5\u5b58\u5728\u4e0d\u5747\u8861\uff0c\u5c24\u5176\u662f\u4f4e\u8d44\u6e90\u8bed\u8a00\u56fd\u5bb6\uff08LRLCs\uff09\u91c7\u7528\u8f83\u5c11\u3002\u73b0\u6709\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u7684\u8868\u73b0\u8f83\u5dee\uff0c\u4f5c\u8005\u6000\u7591\u8fd9\u5f71\u54cd\u4e86AI\u5728\u8fd9\u4e9b\u56fd\u5bb6\u7684\u5b9e\u7528\u6027\u548c\u666e\u53ca\u901f\u5ea6\u3002", "method": "\u4f5c\u8005\u91c7\u7528\u52a0\u6743\u56de\u5f52\u6a21\u578b\uff0c\u5265\u79bb\u8bed\u8a00\u6548\u5e94\u4e0e\u793e\u4f1a\u7ecf\u6d4e\u53ca\u4eba\u53e3\u56e0\u7d20\u7684\u5f71\u54cd\uff0c\u5206\u6790\u4f4e\u8d44\u6e90\u8bed\u8a00\u56fd\u5bb6\u7684AI\u7528\u6237\u6bd4\u4f8b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4f4e\u8d44\u6e90\u8bed\u8a00\u56fd\u5bb6\u7684AI\u7528\u6237\u6bd4\u4f8b\u5927\u7ea6\u6bd4\u5176\u57fa\u7ebf\u4f4e20%\u3002", "conclusion": "\u8bed\u8a00\u53ef\u53ca\u6027\u662fAI\u516c\u5e73\u6269\u6563\u7684\u663e\u8457\u4e14\u72ec\u7acb\u7684\u969c\u788d\u3002"}}
{"id": "2511.02755", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.02755", "abs": "https://arxiv.org/abs/2511.02755", "authors": ["Bowen Jin", "TJ Collins", "Donghan Yu", "Mert Cemri", "Shenao Zhang", "Mengyu Li", "Jay Tang", "Tian Qin", "Zhiyang Xu", "Jiarui Lu", "Guoli Yin", "Jiawei Han", "Zirui Wang"], "title": "Controlling Performance and Budget of a Centralized Multi-agent LLM System with Reinforcement Learning", "comment": "14 pages", "summary": "Large language models (LLMs) exhibit complementary strengths across domains\nand come with varying inference costs, motivating the design of multi-agent LLM\nsystems where specialized models collaborate efficiently. Existing approaches\npredominantly rely on decentralized frameworks, which invoke multiple LLMs for\nevery input and thus lead to substantial and uncontrolled inference costs. In\nthis work, we introduce a centralized multi-LLM framework, where a controller\nLLM selectively coordinates a pool of expert models in a cost-efficient and\ncost-controllable manner. We formulate this coordination problem as\nreinforcement learning with dual objectives: maximizing task performance while\nminimizing the overall inference cost. In addition, we expect the multi-agent\nsystem to have adapted behavior with different budget conditions during\ninference. To this end, we propose CoRL, a reinforcement learning framework\nthat optimizes the performance cost trade-off in a controllable multi-budget\nsetting. Experiments on four diverse benchmarks demonstrate that CoRL enables a\nsingle system to surpass the best expert LLM under high-budget settings, while\nmaintaining strong performance in more economical low-budget modes,\nhighlighting the effectiveness of centralized coordination for scalable and\ncost-efficient multi-agent LLM systems.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u96c6\u4e2d\u5f0f\u591aLLM\u534f\u4f5c\u65b9\u6cd5CoRL\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u4e13\u5bb6\u6a21\u578b\u9009\u62e9\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u53ef\u63a7\u7684\u63a8\u7406\u6210\u672c\uff0c\u540c\u65f6\u5728\u591a\u4e2a\u4efb\u52a1\u548c\u9884\u7b97\u8bbe\u5b9a\u4e0b\u6027\u80fd\u4f18\u5f02\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e0d\u540c\u9886\u57df\u5404\u6709\u4f18\u52bf\uff0c\u4f46\u63a8\u7406\u6210\u672c\u4e0d\u4e00\u3002\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u8bbe\u8ba1\u591a\u6a21\u578b\u534f\u4f5c\u7cfb\u7edf\uff0c\u4ee5\u671f\u9ad8\u6548\u534f\u4f5c\u3001\u5e73\u8861\u6027\u80fd\u4e0e\u6210\u672c\u3002\u73b0\u6709\u65b9\u6848\u591a\u4e3a\u53bb\u4e2d\u5fc3\u5316\u6846\u67b6\uff0c\u63a8\u7406\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u63a7\u5236\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u96c6\u4e2d\u5f0f\u591aLLM\u6846\u67b6\uff0c\u7531\u4e00\u4e2a\u63a7\u5236\u5668LLM\u6839\u636e\u4efb\u52a1\u548c\u9884\u7b97\u5728\u4e13\u5bb6\u6a21\u578b\u6c60\u4e2d\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u8fdb\u884c\u534f\u4f5c\u3002\u8be5\u534f\u8c03\u95ee\u9898\u88ab\u5efa\u6a21\u4e3a\u5e26\u6709\u53cc\u91cd\u76ee\u6807\uff08\u6700\u5927\u5316\u6027\u80fd\u3001\u6700\u5c0f\u5316\u6210\u672c\uff09\u7684\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u3002\u63d0\u51fa\u4e86CoRL\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u591a\u9884\u7b97\u73af\u5883\u4e0b\u4f18\u5316\u6027\u80fd\u4e0e\u6210\u672c\u7684\u6743\u8861\u3002", "result": "\u5728\u56db\u4e2a\u4e0d\u540c\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cCoRL\u6846\u67b6\u5728\u9ad8\u9884\u7b97\u4e0b\u8d85\u8d8a\u4e86\u6700\u4f18\u5355\u4e00\u4e13\u5bb6LLM\uff0c\u5728\u4f4e\u9884\u7b97\u6a21\u5f0f\u4e0b\u4e5f\u80fd\u4fdd\u6301\u8f83\u5f3a\u6027\u80fd\uff0c\u663e\u793a\u4e86\u96c6\u4e2d\u5f0f\u534f\u8c03\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u4e0e\u6210\u672c\u6548\u76ca\u4e0a\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u96c6\u4e2d\u5f0f\u591aLLM\u534f\u4f5c\u7cfb\u7edf\uff08\u5982CoRL\uff09\u80fd\u6709\u6548\u6743\u8861\u63a8\u7406\u6027\u80fd\u4e0e\u6210\u672c\uff0c\u5b9e\u73b0\u591a\u9884\u7b97\u4e0b\u7684\u9ad8\u6548\u534f\u4f5c\uff0c\u662f\u6784\u5efa\u53ef\u63a7\u6210\u672c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6709\u6548\u65b0\u8303\u5f0f\u3002"}}
{"id": "2511.02770", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.02770", "abs": "https://arxiv.org/abs/2511.02770", "authors": ["Hung-Ting Chen", "Xiang Liu", "Shauli Ravfogel", "Eunsol Choi"], "title": "Beyond Single Embeddings: Capturing Diverse Targets with Multi-Query Retrieval", "comment": null, "summary": "Most text retrievers generate \\emph{one} query vector to retrieve relevant\ndocuments. Yet, the conditional distribution of relevant documents for the\nquery may be multimodal, e.g., representing different interpretations of the\nquery. We first quantify the limitations of existing retrievers. All retrievers\nwe evaluate struggle more as the distance between target document embeddings\ngrows. To address this limitation, we develop a new retriever architecture,\n\\emph{A}utoregressive \\emph{M}ulti-\\emph{E}mbedding \\emph{R}etriever (AMER).\nOur model autoregressively generates multiple query vectors, and all the\npredicted query vectors are used to retrieve documents from the corpus. We show\nthat on the synthetic vectorized data, the proposed method could capture\nmultiple target distributions perfectly, showing 4x better performance than\nsingle embedding model. We also fine-tune our model on real-world multi-answer\nretrieval datasets and evaluate in-domain. AMER presents 4 and 21\\% relative\ngains over single-embedding baselines on two datasets we evaluate on.\nFurthermore, we consistently observe larger gains on the subset of dataset\nwhere the embeddings of the target documents are less similar to each other. We\ndemonstrate the potential of using a multi-query vector retriever and open up a\nnew direction for future work.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u81ea\u56de\u5f52\u591a\u5d4c\u5165\u68c0\u7d22\u5668AMER\uff0c\u80fd\u751f\u6210\u591a\u4e2a\u67e5\u8be2\u5411\u91cf\u663e\u8457\u63d0\u5347\u591a\u6a21\u6001\u68c0\u7d22\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4f18\u4e8e\u4f20\u7edf\u5355\u5411\u91cf\u6a21\u578b\u7684\u7ed3\u679c\u3002", "motivation": "\u4f20\u7edf\u6587\u672c\u68c0\u7d22\u5668\u901a\u5e38\u53ea\u751f\u6210\u4e00\u4e2a\u67e5\u8be2\u5411\u91cf\u6765\u68c0\u7d22\u76f8\u5173\u6587\u6863\uff0c\u4f46\u5b9e\u9645\u60c5\u51b5\u4e0b\uff0c\u4e00\u4e2a\u67e5\u8be2\u7684\u76f8\u5173\u6587\u6863\u5206\u5e03\u53ef\u80fd\u662f\u591a\u6a21\u6001\u7684\uff0c\u5373\u8868\u793a\u67e5\u8be2\u7684\u591a\u79cd\u89e3\u91ca\u3002\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u5355\u4e00\u67e5\u8be2\u5411\u91cf\u96be\u4ee5\u8986\u76d6\u6240\u6709\u76f8\u5173\u6587\u6863\u3002", "method": "\u63d0\u51fa\u4e86\u81ea\u56de\u5f52\u591a\u5d4c\u5165\u68c0\u7d22\u5668\uff08AMER\uff09\u67b6\u6784\uff0c\u8be5\u6a21\u578b\u4ee5\u81ea\u56de\u5f52\u65b9\u5f0f\u751f\u6210\u591a\u4e2a\u67e5\u8be2\u5411\u91cf\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u67e5\u8be2\u5411\u91cf\u540c\u65f6\u5728\u8bed\u6599\u5e93\u4e2d\u68c0\u7d22\u6587\u6863\u3002", "result": "\u5728\u5408\u6210\u5411\u91cf\u6570\u636e\u4e0a\uff0cAMER\u80fd\u5b8c\u7f8e\u6355\u6349\u591a\u76ee\u6807\u5206\u5e03\uff0c\u6027\u80fd\u6bd4\u5355\u5d4c\u5165\u6a21\u578b\u63d0\u5347\u4e864\u500d\u3002\u5728\u771f\u5b9e\u591a\u7b54\u6848\u68c0\u7d22\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u5e76\u8bc4\u4f30\uff0cAMER\u5728\u4e24\u7ec4\u6570\u636e\u96c6\u4e0a\u76f8\u8f83\u5355\u4e00\u5d4c\u5165\u57fa\u7ebf\u5206\u522b\u5e26\u6765\u4e864%\u548c21%\u7684\u76f8\u5bf9\u63d0\u5347\uff1b\u5bf9\u76ee\u6807\u6587\u6863\u5206\u5e03\u4e0d\u76f8\u4f3c\u7684\u5b50\u6570\u636e\u96c6\uff0c\u6027\u80fd\u63d0\u5347\u66f4\u4e3a\u663e\u8457\u3002", "conclusion": "\u591a\u67e5\u8be2\u5411\u91cf\u68c0\u7d22\u5668\uff08AMER\uff09\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u591a\u6a21\u5f0f\u5206\u5e03\u7684\u68c0\u7d22\u4efb\u52a1\uff0c\u5c24\u5176\u5728\u76ee\u6807\u6587\u6863\u5206\u5e03\u5dee\u5f02\u8f83\u5927\u65f6\u6548\u679c\u7a81\u51fa\uff0c\u5c55\u793a\u4e86\u4eca\u540e\u591a\u5411\u91cf\u68c0\u7d22\u65b9\u5411\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.02805", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02805", "abs": "https://arxiv.org/abs/2511.02805", "authors": ["Qianhao Yuan", "Jie Lou", "Zichao Li", "Jiawei Chen", "Yaojie Lu", "Hongyu Lin", "Le Sun", "Debing Zhang", "Xianpei Han"], "title": "MemSearcher: Training LLMs to Reason, Search and Manage Memory via End-to-End Reinforcement Learning", "comment": "Project page: https://github.com/icip-cas/MemSearcher", "summary": "Typical search agents concatenate the entire interaction history into the LLM\ncontext, preserving information integrity but producing long, noisy contexts,\nresulting in high computation and memory costs. In contrast, using only the\ncurrent turn avoids this overhead but discards essential information. This\ntrade-off limits the scalability of search agents. To address this challenge,\nwe propose MemSearcher, an agent workflow that iteratively maintains a compact\nmemory and combines the current turn with it. At each turn, MemSearcher fuses\nthe user's question with the memory to generate reasoning traces, perform\nsearch actions, and update memory to retain only information essential for\nsolving the task. This design stabilizes context length across multi-turn\ninteractions, improving efficiency without sacrificing accuracy. To optimize\nthis workflow, we introduce multi-context GRPO, an end-to-end RL framework that\njointly optimize reasoning, search strategies, and memory management of\nMemSearcher Agents. Specifically, multi-context GRPO samples groups of\ntrajectories under different contexts and propagates trajectory-level\nadvantages across all conversations within them. Trained on the same dataset as\nSearch-R1, MemSearcher achieves significant improvements over strong baselines\non seven public benchmarks: +11% on Qwen2.5-3B-Instruct and +12% on\nQwen2.5-7B-Instruct relative average gains. Notably, the 3B-based MemSearcher\neven outperforms 7B-based baselines, demonstrating that striking a balance\nbetween information integrity and efficiency yields both higher accuracy and\nlower computational overhead. The code and models will be publicly available at\nhttps://github.com/icip-cas/MemSearcher", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u7d27\u51d1\u8bb0\u5fc6\u7ba1\u7406\u7684\u68c0\u7d22\u667a\u80fd\u4f53MemSearcher\uff0c\u7ed3\u5408\u591a\u4e0a\u4e0b\u6587\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u7387\u548c\u6548\u7387\uff0c3B\u53c2\u6570\u7248\u672c\u751a\u81f3\u8d85\u8d8a7B\u57fa\u7ebf\uff0c\u4e3a\u667a\u80fd\u4f53\u5728\u591a\u8f6e\u68c0\u7d22\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41\u7684\u68c0\u7d22\u667a\u80fd\u4f53\u5728\u4e0e\u5927\u6a21\u578b\uff08LLM\uff09\u4ea4\u4e92\u65f6\uff0c\u5c06\u6574\u4e2a\u5bf9\u8bdd\u5386\u53f2\u62fc\u63a5\u8fdb\u4e0a\u4e0b\u6587\uff0c\u867d\u7136\u5b8c\u6574\u4fdd\u7559\u4e86\u4fe1\u606f\uff0c\u4f46\u4f1a\u5bfc\u81f4\u4e0a\u4e0b\u6587\u8fc7\u957f\u3001\u566a\u58f0\u5927\uff0c\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u5927\u3002\u800c\u53ea\u4f7f\u7528\u5f53\u524d\u8f6e\u5bf9\u8bdd\u5219\u867d\u8282\u7ea6\u8d44\u6e90\uff0c\u4f46\u4f1a\u4e22\u5931\u5173\u952e\u4fe1\u606f\u3002\u8fd9\u79cd\u6743\u8861\u9650\u5236\u4e86\u68c0\u7d22\u667a\u80fd\u4f53\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMemSearcher\u7684\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u8fed\u4ee3\u5730\u7ef4\u62a4\u4e00\u4efd\u7cbe\u7b80\u7684\u8bb0\u5fc6\uff0c\u5c06\u5f53\u524d\u8f6e\u4fe1\u606f\u4e0e\u8bb0\u5fc6\u878d\u5408\u4f7f\u7528\u3002\u6bcf\u8f6e\u4e2d\uff0cMemSearcher\u5c06\u7528\u6237\u95ee\u9898\u4e0e\u8bb0\u5fc6\u7ed3\u5408\u751f\u6210\u63a8\u7406\u8f68\u8ff9\uff0c\u6267\u884c\u68c0\u7d22\u5e76\u66f4\u65b0\u8bb0\u5fc6\uff0c\u4fdd\u8bc1\u4ec5\u4fdd\u7559\u4efb\u52a1\u5fc5\u9700\u7684\u4fe1\u606f\uff0c\u4ece\u800c\u4fdd\u6301\u7a33\u5b9a\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u63d0\u9ad8\u6548\u7387\u540c\u65f6\u4e0d\u635f\u5931\u51c6\u786e\u6027\u3002\u4e3a\u8fdb\u4e00\u6b65\u4f18\u5316\u6d41\u7a0b\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u591a\u4e0a\u4e0b\u6587GRPO\uff08multi-context GRPO\uff09\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u8054\u5408\u4f18\u5316\u63a8\u7406\u3001\u68c0\u7d22\u7b56\u7565\u4e0e\u8bb0\u5fc6\u7ba1\u7406\u3002\u5176\u901a\u8fc7\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u4e0b\u91c7\u6837\u4e00\u7ec4\u8f68\u8ff9\uff0c\u5c06\u8f68\u8ff9\u7ea7\u4f18\u52bf\u4f20\u64ad\u5230\u6240\u6709\u5bf9\u8bdd\u4e2d\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u4f18\u5316\u3002", "result": "\u5728\u76f8\u540c\u6570\u636e\u96c6\u4e0a\uff0cMemSearcher\u5728\u4e03\u4e2a\u516c\u5f00\u57fa\u51c6\u4e0a\u76f8\u5bf9\u4e3b\u6d41\u65b9\u6cd5\u663e\u8457\u63d0\u5347\uff1aQwen2.5-3B-Instruct\u63d0\u534711%\uff0cQwen2.5-7B-Instruct\u63d0\u534712%\u3002\u5c24\u5176\u662f3B\u7248\u672c\u7684MemSearcher\u8d85\u8d8a\u4e867B\u57fa\u7ebf\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u5728\u4fe1\u606f\u5b8c\u6574\u6027\u4e0e\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u53ef\u5b9e\u73b0\u66f4\u9ad8\u51c6\u786e\u7387\u548c\u66f4\u4f4e\u7b97\u529b\u6d88\u8017\u3002", "conclusion": "MemSearcher\u901a\u8fc7\u7d27\u51d1\u8bb0\u5fc6\u7ba1\u7406\u548c\u5f3a\u5316\u5b66\u4e60\u8054\u5408\u4f18\u5316\u65b9\u6848\uff0c\u5728\u4fdd\u8bc1\u4fe1\u606f\u5145\u5206\u7684\u57fa\u7840\u4e0a\u5927\u5e45\u63d0\u9ad8\u68c0\u7d22\u6548\u7387\u548c\u6027\u80fd\uff0c\u4e14\u4f4e\u53c2\u6570\u6a21\u578b\u53ef\u8d85\u8d8a\u9ad8\u53c2\u6570\u57fa\u7ebf\uff0c\u5bf9\u4e8e\u63d0\u5347\u68c0\u7d22\u667a\u80fd\u4f53\u7684\u6269\u5c55\u6027\u548c\u5b9e\u7528\u6027\u5177\u6709\u91cd\u5927\u610f\u4e49\u3002"}}
{"id": "2511.02817", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02817", "abs": "https://arxiv.org/abs/2511.02817", "authors": ["Amanda Bertsch", "Adithya Pratapa", "Teruko Mitamura", "Graham Neubig", "Matthew R. Gormley"], "title": "Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities", "comment": "Preprint", "summary": "As model context lengths continue to grow, concerns about whether models\neffectively use the full context length have persisted. While several carefully\ndesigned long-context evaluations have recently been released, these\nevaluations tend to rely on retrieval from one or more sections of the context,\nwhich allows nearly all of the context tokens to be disregarded as noise. This\nrepresents only one type of task that might be performed with long context. We\nintroduce Oolong, a benchmark of long-context reasoning tasks that require\nanalyzing individual chunks of text on an atomic level, and then aggregating\nthese analyses to answer distributional questions. Oolong is separated into two\ntask sets: Oolong-synth, a set of naturalistic synthetic tasks, where we can\neasily ablate components of the reasoning problem; and Oolong-real, a\ndownstream setting which requires reasoning over real-world conversational\ndata. Oolong requires models to reason over large quantities of examples, to\nperform both classification and counting in-context, and to reason over\ntemporal and user relations. Even frontier models struggle on Oolong, with\nGPT-5, Claude-Sonnet-4, and Gemini-2.5-Pro all achieving less than 50% accuracy\non both splits at 128K. We release the data and evaluation harness for Oolong\nto enable further development of models that can reason over large quantities\nof text.", "AI": {"tldr": "\u63d0\u51faOolong\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u57fa\u51c6\uff0c\u5305\u542b\u6311\u6218\u6027\u7684\u5206\u6790\u548c\u805a\u5408\u4efb\u52a1\u3002\u4e3b\u6d41\u5927\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0c\u51c6\u786e\u7387\u5747\u4f4e\u4e8e50%\u3002\u516c\u5f00\u6570\u636e\u96c6\u548c\u8bc4\u6d4b\u5de5\u5177\uff0c\u63a8\u52a8\u6a21\u578b\u5bf9\u957f\u6587\u672c\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u8bc4\u6d4b\u957f\u4e0a\u4e0b\u6587\u80fd\u529b\u7684\u65b9\u6cd5\u591a\u4ee5\u68c0\u7d22\u4efb\u52a1\u4e3a\u4e3b\uff0c\u5ffd\u7565\u4e86\u8981\u6c42\u6a21\u578b\u5168\u5c40\u7406\u89e3\u548c\u63a8\u7406\u7684\u4efb\u52a1\u7c7b\u578b\u3002\u4f5c\u8005\u5e0c\u671b\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63a2\u7d22\u6a21\u578b\u5728\u590d\u6742\u957f\u6587\u672c\u63a8\u7406\u4e0a\u7684\u771f\u5b9e\u80fd\u529b\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Oolong\u57fa\u51c6\uff0c\u5305\u62ecOolong-synth\uff08\u53ef\u63a7\u7684\u81ea\u7136\u5316\u5408\u6210\u4efb\u52a1\uff09\u548cOolong-real\uff08\u771f\u5b9e\u4e16\u754c\u5bf9\u8bdd\u6570\u636e\uff09\uff0c\u8981\u6c42\u6a21\u578b\u5bf9\u5927\u91cf\u6587\u672c\u7247\u6bb5\u8fdb\u884c\u539f\u5b50\u7ea7\u5206\u6790\uff0c\u5e76\u805a\u5408\u5206\u6790\u7ed3\u679c\u6765\u56de\u7b54\u5206\u5e03\u6027\u95ee\u9898\u3002\u901a\u8fc7\u5206\u7c7b\u3001\u8ba1\u6570\u53ca\u65f6\u5e8f\u548c\u7528\u6237\u5173\u7cfb\u63a8\u7406\uff0c\u5bf9\u5f53\u524d\u5927\u6a21\u578b\u8fdb\u884c\u8bc4\u6d4b\u3002", "result": "\u5305\u62ecGPT-5\u3001Claude-Sonnet-4\u3001Gemini-2.5-Pro\u5728128K\u6587\u672c\u957f\u5ea6\u4e0b\u51c6\u786e\u7387\u4f4e\u4e8e50%\uff0c\u8bf4\u660e\u8fd9\u4e9b\u6a21\u578b\u96be\u4ee5\u6709\u6548\u5904\u7406Oolong\u57fa\u51c6\u7684\u6311\u6218\u6027\u4efb\u52a1\u3002\u8bba\u6587\u540c\u65f6\u516c\u5f00\u4e86\u6570\u636e\u96c6\u548c\u8bc4\u6d4b\u6846\u67b6\u3002", "conclusion": "\u5373\u4f7f\u662f\u6700\u524d\u6cbf\u7684\u5927\u6a21\u578b\uff0c\u5728Oolong\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\u4e5f\u4e0d\u7406\u60f3\uff0c\u5728128K\u957f\u5ea6\u4e0b\u4e24\u79cd\u4efb\u52a1\u7684\u51c6\u786e\u7387\u90fd\u4f4e\u4e8e50%\u3002\u8fd9\u8868\u660e\u73b0\u6709\u6a21\u578b\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4efb\u52a1\u4e0a\u4ecd\u6709\u8f83\u5927\u63d0\u5347\u7a7a\u95f4\u3002"}}
