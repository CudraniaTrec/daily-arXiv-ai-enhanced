{"id": "2511.14953", "categories": ["cs.PL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14953", "abs": "https://arxiv.org/abs/2511.14953", "authors": ["Joey Velez-Ginorio", "Nada Amin", "Konrad Kording", "Steve Zdancewic"], "title": "Compiling to recurrent neurons", "comment": null, "summary": "Discrete structures are currently second-class in differentiable programming. Since functions over discrete structures lack overt derivatives, differentiable programs do not differentiate through them and limit where they can be used. For example, when programming a neural network, conditionals and iteration cannot be used everywhere; they can break the derivatives necessary for gradient-based learning to work. This limits the class of differentiable algorithms we can directly express, imposing restraints on how we build neural networks and differentiable programs more generally. However, these restraints are not fundamental. Recent work shows conditionals can be first-class, by compiling them into differentiable form as linear neurons. Similarly, this work shows iteration can be first-class -- by compiling to linear recurrent neurons. We present a minimal typed, higher-order and linear programming language with iteration called $\\textsf{Cajal}\\scriptstyle(\\mathbb{\\multimap}, \\mathbb{2}, \\mathbb{N})$. We prove its programs compile correctly to recurrent neurons, allowing discrete algorithms to be expressed in a differentiable form compatible with gradient-based learning. With our implementation, we conduct two experiments where we link these recurrent neurons against a neural network solving an iterative image transformation task. This determines part of its function prior to learning. As a result, the network learns faster and with greater data-efficiency relative to a neural network programmed without first-class iteration. A key lesson is that recurrent neurons enable a rich interplay between learning and the discrete structures of ordinary programming.", "AI": {"tldr": "\u63d0\u51faCajal\u8bed\u8a00\u4ee5\u652f\u6301\u53ef\u5fae\u5206\u7f16\u7a0b\u4e2d\u7684\u79bb\u6563\u7ed3\u6784\uff08\u8fed\u4ee3\uff09\uff0c\u5c06\u8fed\u4ee3\u7f16\u8bd1\u4e3a\u5faa\u73af\u795e\u7ecf\u5143\uff0c\u5b9e\u73b0\u76f8\u5173\u7f51\u7edc\u5728\u5b66\u4e60\u901f\u5ea6\u4e0e\u6570\u636e\u5229\u7528\u4e0a\u7684\u63d0\u5347\uff0c\u62d3\u5bbd\u4e86\u795e\u7ecf\u7f51\u7edc\u4e0e\u7a0b\u5e8f\u7ed3\u6784\u7684\u7ed3\u5408\u3002", "motivation": "\u5728\u53ef\u5fae\u5206\u7f16\u7a0b\u4e2d\uff0c\u79bb\u6563\u7ed3\u6784\u56e0\u7f3a\u4e4f\u663e\u5f0f\u7684\u5bfc\u6570\u652f\u6301\u800c\u96be\u4ee5\u76f4\u63a5\u53c2\u4e0e\u68af\u5ea6\u5b66\u4e60\uff0c\u8fd9\u9650\u5236\u4e86\u6211\u4eec\u80fd\u591f\u8868\u8fbe\u7684\u53ef\u5fae\u5206\u7b97\u6cd5\u7c7b\u578b\uff0c\u5e76\u4e14\u9650\u5236\u4e86\u795e\u7ecf\u7f51\u7edc\u7684\u6784\u5efa\u65b9\u5f0f\u3002\u4f5c\u8005\u5e0c\u671b\u89e3\u51b3\u8fd9\u4e00\u5c40\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5e26\u6709\u8fed\u4ee3\u3001\u6781\u7b80\u3001\u5f3a\u7c7b\u578b\u3001\u9ad8\u9636\u548c\u7ebf\u6027\u7f16\u7a0b\u8bed\u8a00Cajal($\\mathbb{\\multimap}, \\mathbb{2}, \\mathbb{N}$)\uff0c\u5e76\u8bc1\u660e\u8be5\u8bed\u8a00\u7684\u7a0b\u5e8f\u53ef\u6b63\u786e\u7f16\u8bd1\u4e3a\u5faa\u73af\u795e\u7ecf\u5143\uff0c\u4f7f\u5f97\u79bb\u6563\u7b97\u6cd5\u53ef\u8f6c\u5316\u4e3a\u517c\u5bb9\u68af\u5ea6\u5b66\u4e60\u7684\u53ef\u5fae\u5206\u5f62\u5f0f\u3002", "result": "\u901a\u8fc7\u5b9e\u73b0\u5e76\u8fdb\u884c\u4e24\u7ec4\u5b9e\u9a8c\uff0c\u5c06\u7f16\u8bd1\u540e\u7684\u5faa\u73af\u795e\u7ecf\u5143\u4e0e\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\uff0c\u7528\u4e8e\u89e3\u51b3\u8fed\u4ee3\u56fe\u50cf\u53d8\u6362\u4efb\u52a1\u3002\u7ed3\u679c\u8868\u660e\u76f8\u6bd4\u4e0d\u5177\u5907\u4e00\u7b49\u8fed\u4ee3\u529f\u80fd\u7684\u7f51\u7edc\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u52a0\u5feb\u5b66\u4e60\u901f\u5ea6\uff0c\u63d0\u9ad8\u6570\u636e\u6548\u7387\u3002", "conclusion": "\u672c\u5de5\u4f5c\u8bc1\u660e\u4e86\u79bb\u6563\u7ed3\u6784\uff08\u5982\u8fed\u4ee3\uff09\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u7b49\u516c\u6c11\u53c2\u4e0e\u53ef\u5fae\u5206\u7f16\u7a0b\uff0c\u901a\u8fc7\u5c06\u5176\u7f16\u8bd1\u4e3a\u53ef\u5fae\u5206\u5f62\u5f0f\uff08\u5faa\u73af\u795e\u7ecf\u5143\uff09\uff0c\u4e0d\u4ec5\u4e30\u5bcc\u4e86\u795e\u7ecf\u7f51\u7edc\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u8fd8\u63d0\u5347\u4e86\u795e\u7ecf\u7f51\u7edc\u7684\u5b66\u4e60\u6548\u679c\u4e0e\u6548\u7387\uff0c\u6253\u7834\u4e86\u6b64\u524d\u79bb\u6563\u7ed3\u6784\u9650\u5236\u53ef\u5fae\u5206\u7a0b\u5e8f\u8868\u8fbe\u7684\u58c1\u5792\u3002"}}
{"id": "2511.15000", "categories": ["cs.PL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.15000", "abs": "https://arxiv.org/abs/2511.15000", "authors": ["Alexander J Root", "Christophe Gyurgyik", "Purvi Goel", "Kayvon Fatahalian", "Jonathan Ragan-Kelley", "Andrew Adams", "Fredrik Kjolstad"], "title": "Compiling Set Queries into Work-Efficient Tree Traversals", "comment": null, "summary": "Trees can accelerate queries that search or aggregate values over large collections. They achieve this by storing metadata that enables quick pruning (or inclusion) of subtrees when predicates on that metadata can prove that none (or all) of the data in a subtree affect the query result. Existing systems implement this pruning logic manually for each query predicate and data structure. We generalize and mechanize this class of optimization. Our method derives conditions for when subtrees can be pruned (or included wholesale), expressed in terms of the metadata available at each node. We efficiently generate these conditions using symbolic interval analysis, extended with new rules to handle geometric predicates (e.g., intersection, containment). Additionally, our compiler fuses compound queries (e.g., reductions on filters) into a single tree traversal. These techniques enable the automatic derivation of generalized single-index and dual-index tree joins that support a wide class of join predicates beyond standard equality and range predicates. The generated traversals match the behavior of expert-written code that implements query-specific traversals, and can asymptotically outperform the linear scans and nested-loop joins that existing systems fall back to when hand-written cases do not apply.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u7b26\u53f7\u533a\u95f4\u5206\u6790\u81ea\u52a8\u63a8\u5bfc\u6811\u7ed3\u6784\u67e5\u8be2\u4e2d\u526a\u679d\u548c\u5305\u542b\u6761\u4ef6\uff0c\u5b9e\u73b0\u590d\u5408\u67e5\u8be2\u878d\u5408\uff0c\u5e76\u81ea\u52a8\u751f\u6210\u9ad8\u6548\u7684\u6811\u904d\u5386\u548c\u8fde\u63a5\u64cd\u4f5c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u67e5\u8be2\u4f18\u5316\u7684\u81ea\u52a8\u5316\u548c\u6027\u80fd\u3002", "motivation": "\u6811\u7ed3\u6784\u901a\u5e38\u901a\u8fc7\u5b58\u50a8\u5143\u6570\u636e\u6765\u52a0\u901f\u5927\u89c4\u6a21\u6570\u636e\u96c6\u5408\u4e0a\u7684\u67e5\u8be2\uff0c\u5b9e\u73b0\u5b50\u6811\u7684\u5feb\u901f\u526a\u679d\u6216\u5305\u542b\u3002\u4f46\u73b0\u6709\u7cfb\u7edf\u9700\u8981\u9488\u5bf9\u6bcf\u79cd\u67e5\u8be2\u8c13\u8bcd\u548c\u6570\u636e\u7ed3\u6784\u624b\u52a8\u5b9e\u73b0\u526a\u679d\u903b\u8f91\uff0c\u5f00\u53d1\u6548\u7387\u4f4e\u4e14\u7f3a\u4e4f\u901a\u7528\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u901a\u7528\u4e14\u81ea\u52a8\u5316\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b26\u53f7\u533a\u95f4\u5206\u6790\u4ee5\u53ca\u6269\u5c55\u7684\u51e0\u4f55\u8c13\u8bcd\u5904\u7406\u89c4\u5219\uff0c\u4ece\u8282\u70b9\u5143\u6570\u636e\u81ea\u52a8\u63a8\u5bfc\u53ef\u526a\u679d\uff08\u6216\u6574\u4f53\u5305\u542b\uff09\u5b50\u6811\u7684\u6761\u4ef6\u3002\u7f16\u8bd1\u5668\u8fd8\u5c06\u590d\u5408\u67e5\u8be2\u81ea\u52a8\u878d\u5408\u4e3a\u5355\u6b21\u6811\u904d\u5386\uff0c\u5e76\u652f\u6301\u81ea\u52a8\u63a8\u5bfc\u5355\u7d22\u5f15\u548c\u53cc\u7d22\u5f15\u7684\u6811\u8fde\u63a5\uff0c\u6db5\u76d6\u591a\u7c7b\u8fde\u63a5\u8c13\u8bcd\u3002", "result": "\u81ea\u52a8\u751f\u6210\u7684\u6811\u904d\u5386\u64cd\u4f5c\u4e0d\u4ec5\u4e0e\u4e13\u5bb6\u624b\u5199\u4ee3\u7801\u7684\u884c\u4e3a\u4e00\u81f4\uff0c\u8fd8\u80fd\u5728\u5927\u591a\u6570\u67e5\u8be2\u573a\u666f\u4e0b\u4f18\u4e8e\u987a\u5e8f\u626b\u63cf\u548c\u5d4c\u5957\u5faa\u73af\u8fde\u63a5\uff0c\u5c24\u5176\u5728\u672a\u6709\u9488\u5bf9\u6027\u7684\u624b\u5199\u4f18\u5316\u65f6\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6811\u7ed3\u6784\u67e5\u8be2\u4f18\u5316\u7684\u81ea\u52a8\u5316\u548c\u6cdb\u5316\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u548c\u5f00\u53d1\u6548\u7387\uff0c\u4e3a\u652f\u6301\u591a\u6837\u5316\u67e5\u8be2\u8c13\u8bcd\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6280\u672f\u65b9\u6848\u3002"}}
{"id": "2511.15028", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.15028", "abs": "https://arxiv.org/abs/2511.15028", "authors": ["Christophe Gyurgyik", "Alexander J Root", "Fredrik Kjolstad"], "title": "Data Layout Polymorphism for Bounding Volume Hierarchies", "comment": null, "summary": "Bounding volume hierarchies are ubiquitous acceleration structures in graphics, scientific computing, and data analytics. Their performance depends critically on data layout choices that affect cache utilization, memory bandwidth, and vectorization -- increasingly dominant factors in modern computing. Yet, in most programming systems, these layout choices are hopelessly entangled with the traversal logic. This entanglement prevents developers from independently optimizing data layouts and algorithms across different contexts, perpetuating a false dichotomy between performance and portability. We introduce Scion, a domain-specific language and compiler for specifying the data layouts of bounding volume hierarchies independent of tree traversal algorithms. We show that Scion can express a broad spectrum of layout optimizations used in high performance computing while remaining architecture-agnostic. We demonstrate empirically that Pareto-optimal layouts (along performance and memory footprint axes) vary across algorithms, architectures, and workload characteristics. Through systematic design exploration, we also identify a novel ray tracing layout that combines optimization techniques from prior work, achieving Pareto-optimality across diverse architectures and scenes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Scion\uff0c\u4e00\u79cd\u7528\u4e8e\u63cf\u8ff0BVH\u6570\u636e\u5e03\u5c40\u7684\u4e13\u7528\u8bed\u8a00\uff0c\u901a\u8fc7\u5c06\u5e03\u5c40\u4e0e\u7b97\u6cd5\u904d\u5386\u5206\u79bb\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u548c\u53ef\u79fb\u690d\u6027\u7684\u53cc\u91cd\u4f18\u5316\uff0c\u53d1\u73b0\u5e76\u9a8c\u8bc1\u4e86\u591a\u573a\u666f\u4e0b\u7684\u6700\u4f18\u5e03\u5c40\u7b56\u7565\u3002", "motivation": "\u76ee\u524dBVH\u7b49\u52a0\u901f\u7ed3\u6784\u5728\u6027\u80fd\u4f18\u5316\u65f6\uff0c\u6570\u636e\u5e03\u5c40\u4e0e\u7b97\u6cd5\u904d\u5386\u903b\u8f91\u7d27\u5bc6\u4ea4\u7ec7\uff0c\u9650\u5236\u4e86\u6027\u80fd\u3001\u53ef\u79fb\u690d\u6027\u53ca\u72ec\u7acb\u4f18\u5316\u7684\u7a7a\u95f4\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5206\u79bb\u5e03\u5c40\u548c\u904d\u5386\u7b97\u6cd5\u7684\u65b9\u6cd5\u6765\u7a81\u7834\u4e0a\u8ff0\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00Scion\uff0c\u7528\u4e8e\u5c06BVH\u7684\u6570\u636e\u5e03\u5c40\u4e0e\u904d\u5386\u903b\u8f91\u89e3\u8026\uff0c\u5e76\u901a\u8fc7\u7f16\u8bd1\u4f18\u5316\u5b9e\u73b0\u5e03\u5c40\u7684\u7075\u6d3b\u8868\u8fbe\u548c\u7cfb\u7edf\u5316\u63a2\u7d22\u3002", "result": "Scion\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\uff0c\u4e0d\u4ec5\u80fd\u8868\u8fbe\u4e30\u5bcc\u7684\u5e03\u5c40\u4f18\u5316\uff0c\u8fd8\u80fd\u5b9e\u73b0\u5bf9\u4e0d\u540c\u7b97\u6cd5\u3001\u4f53\u7cfb\u7ed3\u6784\u53ca\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u7684Pareto\u6700\u4f18\u5e03\u5c40\uff0c\u5e76\u53d1\u73b0\u4e86\u4e00\u79cd\u65b0\u7684\u9002\u7528\u4e8e\u5149\u7ebf\u8ffd\u8e2a\u7684\u9ad8\u6548\u5e03\u5c40\u3002", "conclusion": "Scion\u80fd\u591f\u4ece\u6570\u636e\u5e03\u5c40\u7684\u89d2\u5ea6\u63d0\u5347\u6811\u7ed3\u6784\u7684\u6027\u80fd\uff0c\u5e76\u5b9e\u73b0\u6027\u80fd\u4e0e\u53ef\u79fb\u690d\u6027\u7684\u4f18\u5316\u5e73\u8861\uff0c\u4e14\u80fd\u53d1\u73b0\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u7684Pareto\u6700\u4f18\u5e03\u5c40\u3002"}}
{"id": "2511.14772", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14772", "abs": "https://arxiv.org/abs/2511.14772", "authors": ["Zhuoyi Yang", "Xu Guo", "Tong Zhang", "Huijuan Xu", "Boyang Li"], "title": "Test-time Scaling of LLMs: A Survey from A Subproblem Structure Perspective", "comment": null, "summary": "With this paper, we survey techniques for improving the predictive accuracy of pretrained large language models by allocating additional compute at inference time. In categorizing test-time scaling methods, we place special emphasis on how a problem is decomposed into subproblems and on the topological organization of these subproblems whether sequential, parallel, or tree-structured. This perspective allows us to unify diverse approaches such as Chain-of-Thought, Branch-Solve-Merge, and Tree-of-Thought under a common lens. We further synthesize existing analyses of these techniques, highlighting their respective strengths and weaknesses, and conclude by outlining promising directions for future research", "AI": {"tldr": "\u8bba\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u63a8\u7406\u9636\u6bb5\u901a\u8fc7\u63d0\u5347\u8ba1\u7b97\u8d44\u6e90\u6765\u589e\u5f3a\u5927\u6a21\u578b\u8868\u73b0\u7684\u65b9\u6cd5\uff0c\u5e76\u7edf\u4e00\u5206\u6790\u8fd9\u4e9b\u65b9\u6cd5\u7684\u7ec4\u7ec7\u7ed3\u6784\uff0c\u4e3a\u672a\u6765\u76f8\u5173\u6280\u672f\u53d1\u5c55\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "motivation": "\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u9636\u6bb5\u8868\u73b0\u63d0\u5347\u7684\u9700\u6c42\uff0c\u8c03\u7814\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5206\u914d\u66f4\u591a\u8ba1\u7b97\u8d44\u6e90\u4ee5\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u7684\u6280\u672f\u3002", "method": "\u901a\u8fc7\u5bf9\u73b0\u6709\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\u6280\u672f\u8fdb\u884c\u5206\u7c7b\uff0c\u91cd\u70b9\u8ba8\u8bba\u95ee\u9898\u5206\u89e3\u65b9\u5f0f\u4ee5\u53ca\u5b50\u95ee\u9898\u7684\u62d3\u6251\u7ed3\u6784\u7ec4\u7ec7\uff08\u987a\u5e8f\u3001\u5e76\u884c\u6216\u6811\u72b6\u7b49\uff09\uff0c\u5e76\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e86\u4e0d\u540c\u65b9\u6cd5\u7684\u4f18\u52a3\u3002", "result": "\u5c06 Chain-of-Thought\u3001Branch-Solve-Merge \u4ee5\u53ca Tree-of-Thought \u7b49\u591a\u79cd\u65b9\u6cd5\u7edf\u4e00\u5230\u5171\u540c\u5206\u6790\u6846\u67b6\u4e0b\uff0c\u5bf9\u5b83\u4eec\u7684\u4f18\u52bf\u4e0e\u4e0d\u8db3\u505a\u4e86\u7efc\u5408\u8bc4\u8ff0\u3002", "conclusion": "\u8be5\u8bba\u6587\u603b\u7ed3\u4e86\u5f53\u524d\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u51c6\u786e\u6027\u7684\u5404\u7c7b\u65b9\u6cd5\uff0c\u5e76\u7edf\u4e00\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u7684\u5206\u6790\u89c6\u89d2\uff0c\u6307\u51fa\u672a\u6765\u503c\u5f97\u5173\u6ce8\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.15073", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.15073", "abs": "https://arxiv.org/abs/2511.15073", "authors": ["Youwei Xiao", "Zizhang Luo", "Weijie Peng", "Yuyang Zou", "Yun Liang"], "title": "Cement2: Temporal Hardware Transactions for High-Level and Efficient FPGA Programming", "comment": null, "summary": "Hardware design faces a fundamental challenge: raising abstraction to improve productivity while maintaining control over low-level details like cycle accuracy. Traditional RTL design in languages like SystemVerilog composes modules through wiring-style connections that provide weak guarantees for behavioral correctness. While high-level synthesis (HLS) and emerging abstractions attempt to address this, they either introduce unpredictable overhead or restrict design generality. Although transactional HDLs provide a promising foundation by lifting design abstraction to atomic and composable rules, they solely model intra-cycle behavior and do not reflect the native temporal design characteristics, hindering applicability and productivity for FPGA programming scenarios.\n  We propose temporal hardware transactions, a new abstraction that brings cycle-level timing awareness to designers at the transactional language level. Our approach models temporal relationships between rules and supports the description of rules whose actions span multiple clock cycles, providing intuitive abstraction to describe multi-cycle architectural behavior. We implement this in Cement2, a transactional HDL embedded in Rust, enabling programming hardware constructors to build both intra-cycle and temporal transactions. Cement2's synthesis framework lowers description abstraction through multiple analysis and optimization phases, generating efficient hardware. With Cement2's abstraction, we program a RISC-V soft-core processor, custom CPU instructions, linear algebra kernels, and systolic array accelerators, leveraging the high-level abstraction for boosted productivity. Evaluation shows that Cement2 does not sacrifice performance and resources compared to hand-coded RTL designs, demonstrating the high applicability for general FPGA design tasks.", "AI": {"tldr": "\u5f15\u5165\u65f6\u5e8f\u786c\u4ef6\u4e8b\u52a1\u65b0\u62bd\u8c61\uff0c\u5c55\u5f00\u4e3aRust\u5d4c\u5165\u5f0fCement2\u8bed\u8a00\uff0c\u517c\u5177\u9ad8\u62bd\u8c61\u548c\u65f6\u5e8f\u63a7\u5236\uff0c\u4e14\u5728\u4e3b\u6d41FPGA\u5e94\u7528\u4e2d\u6027\u80fd\u4e0e\u8d44\u6e90\u5229\u7528\u7387\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709RTL\u548c\u9ad8\u5c42\u5408\u6210\u8bbe\u8ba1\u65b9\u6cd5\u5728\u62bd\u8c61\u4e0e\u4f4e\u5c42\u7ec6\u8282\u63a7\u5236\u95f4\u96be\u4ee5\u5e73\u8861\uff0c\u5f71\u54cd\u751f\u4ea7\u529b\u548c\u884c\u4e3a\u6b63\u786e\u6027\uff0c\u7279\u522b\u662f\u5728FPGA\u7f16\u7a0b\u4e2d\u7f3a\u4e4f\u5bf9\u591a\u5468\u671f\u65f6\u5e8f\u884c\u4e3a\u7684\u76f4\u89c2\u548c\u9ad8\u5c42\u63cf\u8ff0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65f6\u5e8f\u786c\u4ef6\u4e8b\u52a1\u62bd\u8c61\uff0c\u5e76\u5728Rust\u8bed\u8a00\u4e2d\u5b9e\u73b0\u4e86\u5d4c\u5165\u5f0f\u4e8b\u52a1HDL Cement2\uff0c\u652f\u6301\u591a\u65f6\u949f\u5468\u671f\u89c4\u5219\u540c\u65f6\u4f18\u5316\u786c\u4ef6\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u4f7f\u7528Cement2\u5b9e\u73b0\u4e86RISC-V\u8f6f\u6838\u5904\u7406\u5668\u3001\u5b9a\u5236CPU\u6307\u4ee4\u3001\u7ebf\u6027\u4ee3\u6570\u6838\u548c\u9635\u5217\u52a0\u901f\u5668\uff0c\u83b7\u5f97\u4e86\u4e0e\u624b\u5de5RTL\u76f8\u8fd1\u751a\u81f3\u66f4\u4f18\u7684\u6027\u80fd\u548c\u8d44\u6e90\u5360\u7528\u3002", "conclusion": "Cement2\u7ed3\u5408\u4e86\u9ad8\u5c42\u62bd\u8c61\u4e0e\u65f6\u5e8f\u63a7\u5236\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7387\u4e14\u8d44\u6e90\u5229\u7528\u7387\u4e0d\u4f4e\u4e8e\u624b\u5199RTL\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdbFPGA\u4efb\u52a1\u3002"}}
{"id": "2511.14773", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.14773", "abs": "https://arxiv.org/abs/2511.14773", "authors": ["Joey David"], "title": "Temporal Predictors of Outcome in Reasoning Language Models", "comment": "4 pages, 4 figures", "summary": "The chain-of-thought (CoT) paradigm uses the elicitation of step-by-step rationales as a proxy for reasoning, gradually refining the model's latent representation of a solution. However, it remains unclear just how early a Large Language Model (LLM) internally commits to an eventual outcome. We probe this by training linear classifiers on hidden states after the first t reasoning tokens, showing that eventual correctness is highly predictable after only a few tokens, even when longer outputs are needed to reach a definite answer. We show that, for harder questions, a drop in predictive accuracy highlights a selection artifact: hard items are disproportionately represented in long CoTs. Overall, our results imply that for reasoning models, internal self-assessment of success tends to emerge after only a few tokens, with implications for interpretability and for inference-time control.", "AI": {"tldr": "\u4f5c\u8005\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u94fe\u5f0f\u63a8\u7406\u8fc7\u7a0b\u4e2d\uff0c\u63a8\u7406\u7ed3\u679c\u7684\u6b63\u786e\u6027\u5728\u65e9\u671f\u5c31\u53ef\u4ee5\u5185\u90e8\u9884\u6d4b\uff0c\u8fd9\u6709\u52a9\u4e8e\u6a21\u578b\u89e3\u91ca\u6027\u548c\u63a8\u7406\u8fc7\u7a0b\u4f18\u5316\u3002", "motivation": "\u867d\u7136\u94fe\u5f0f\u601d\u7ef4(CoT)\u65b9\u6cd5\u88ab\u5e7f\u6cdb\u7528\u4e8e\u63d0\u5347\u6a21\u578b\u63a8\u7406\u6027\u80fd\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u65e9\u7684\u9636\u6bb5\u5c31\u5df2\u7ecf\u786e\u5b9a\u6700\u7ec8\u8f93\u51fa\u7684\u8d70\u5411\u3002", "method": "\u901a\u8fc7\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\uff0c\u4e0d\u540csteps\u7684\u9690\u85cf\u72b6\u6001\u8bad\u7ec3\u7ebf\u6027\u5206\u7c7b\u5668\uff0c\u8bc4\u4f30\u80fd\u5426\u9884\u6d4b\u6700\u7ec8\u63a8\u7406\u7684\u6b63\u786e\u6027\u3002", "result": "\u4ec5\u4f7f\u7528\u524d\u51e0\u4e2a\u63a8\u7406token\u7684\u9690\u85cf\u72b6\u6001\uff0c\u5c31\u53ef\u4ee5\u9ad8\u5ea6\u51c6\u786e\u5730\u9884\u6d4b\u6700\u7ec8\u63a8\u7406\u7684\u6b63\u786e\u4e0e\u5426\uff1b\u96be\u9898\u5f80\u5f80\u9700\u8981\u66f4\u957f\u94fe\u5f0f\u601d\u7ef4\u6b65\u9aa4\uff0c\u9884\u6d4b\u80fd\u529b\u5728\u8fd9\u4e9b\u60c5\u51b5\u4e0b\u6709\u6240\u4e0b\u964d\uff0c\u53cd\u6620\u4e86\u6837\u672c\u9009\u62e9\u504f\u5dee\u3002", "conclusion": "\u5bf9\u4e8e\u63a8\u7406\u6a21\u578b\u6765\u8bf4\uff0c\u5176\u5185\u90e8\u5bf9\u63a8\u7406\u7ed3\u679c\u6210\u529f\u4e0e\u5426\u7684\u81ea\u6211\u8bc4\u4f30\u5f80\u5f80\u5728\u4ec5\u4ec5\u51e0\u4e2a\u63a8\u7406token\u4e4b\u540e\u5c31\u5df2\u5177\u5907\u80fd\u529b\u3002"}}
{"id": "2511.14786", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.14786", "abs": "https://arxiv.org/abs/2511.14786", "authors": ["Sidney Shapiro"], "title": "Hybrid Quantum-Classical Machine Learning with PennyLane: A Comprehensive Guide for Computational Research", "comment": "35 pages", "summary": "Hybrid quantum-classical machine learning represents a frontier in computational research, combining the potential advantages of quantum computing with established classical optimization techniques. PennyLane provides a Python framework that seamlessly bridges quantum circuits and classical machine learning, enabling researchers to build, optimize, and deploy variational quantum algorithms. This paper introduces PennyLane as a versatile tool for quantum machine learning, optimization, and quantum chemistry applications. We demonstrate use cases including quantum kernel methods, variational quantum eigensolvers, portfolio optimization, and integration with classical ML frameworks such as PyTorch, TensorFlow, and JAX. Through concrete Python examples with widely used libraries such as scikit-learn, pandas, and matplotlib, we show how PennyLane facilitates efficient quantum circuit construction, automatic differentiation, and hybrid optimization workflows. By situating PennyLane within the broader context of quantum computing and machine learning, we highlight its role as a methodological building block for quantum-enhanced data science. Our goal is to provide researchers and practitioners with a concise reference that bridges foundational quantum computing concepts and applied machine learning practice, making PennyLane a default citation for hybrid quantum-classical workflows in Python-based research.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdPennyLane\u6846\u67b6\uff0c\u9610\u91ca\u5176\u5728\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5e76\u901a\u8fc7\u591a\u79cd\u5e94\u7528\u573a\u666f\u5c55\u793a\u5176\u5de5\u5177\u4ef7\u503c\uff0c\u4e3a\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u53c2\u8003\u6307\u5357\u3002", "motivation": "\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u80fd\u7ed3\u5408\u91cf\u5b50\u8ba1\u7b97\u7684\u6f5c\u529b\u4e0e\u7ecf\u5178\u4f18\u5316\u6280\u672f\u3002\u4f46\u7f3a\u4e4f\u6613\u4e8e\u4f7f\u7528\u7684\u5e73\u53f0\uff0c\u5c06\u91cf\u5b50\u8ba1\u7b97\u878d\u5165\u4e3b\u6d41\u673a\u5668\u5b66\u4e60\u5e76\u5f62\u6210\u9ad8\u6548\u4f18\u5316\u6d41\u7a0b\u3002", "method": "\u4ecb\u7ecdPennyLane Python\u6846\u67b6\uff0c\u901a\u8fc7\u5177\u4f53\u793a\u4f8b\u5c55\u793a\u5176\u5728\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u3001\u91cf\u5b50\u5316\u5b66\u3001\u4f18\u5316\u7b49\u9886\u57df\u7684\u5e94\u7528\uff0c\u5f3a\u8c03\u4e0e\u4e3b\u6d41ML\u5de5\u5177\uff08\u5982PyTorch\u3001TensorFlow\u3001JAX\uff09\u7684\u96c6\u6210\u80fd\u529b\u3002", "result": "PennyLane\u53ef\u9ad8\u6548\u8fde\u63a5\u91cf\u5b50\u7ebf\u8def\u4e0e\u7ecf\u5178ML\u6846\u67b6\uff0c\u652f\u6301\u81ea\u52a8\u5fae\u5206\u548c\u6df7\u5408\u4f18\u5316\u6d41\u7a0b\uff0c\u4fbf\u4e8e\u591a\u79cd\u5e94\u7528\u573a\u666f\u4e0b\u7684\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u7814\u7a76\uff0c\u5e76\u4f5c\u4e3aPython\u7814\u7a76\u4e2d\u7684\u6807\u51c6\u5de5\u5177\u3002", "conclusion": "PennyLane\u662f\u9762\u5411\u91cf\u5b50-\u7ecf\u5178\u6df7\u5408\u5de5\u4f5c\u6d41\u7684\u6709\u529b\u5de5\u5177\uff0c\u80fd\u5728\u91cf\u5b50\u8ba1\u7b97\u4e0e\u673a\u5668\u5b66\u4e60\u95f4\u642d\u5efa\u6865\u6881\uff0c\u4e3a\u91cf\u5b50\u589e\u5f3a\u6570\u636e\u79d1\u5b66\u63d0\u4f9b\u575a\u5b9e\u7684\u65b9\u6cd5\u652f\u6301\u3002"}}
{"id": "2511.15323", "categories": ["cs.PL", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15323", "abs": "https://arxiv.org/abs/2511.15323", "authors": ["Youwei Xiao", "Yuyang Zou", "Yun Liang"], "title": "SkyEgg: Joint Implementation Selection and Scheduling for Hardware Synthesis using E-graphs", "comment": null, "summary": "Hardware synthesis from high-level descriptions remains fundamentally limited by the sequential optimization of interdependent design decisions. Current methodologies, including state-of-the-art high-level synthesis (HLS) tools, artificially separate implementation selection from scheduling, leading to suboptimal designs that cannot fully exploit modern FPGA heterogeneous architectures. Implementation selection is typically performed by ad-hoc pattern matching on operations, a process that does not consider the impact on scheduling. Subsequently, scheduling algorithms operate on fixed selection solutions with inaccurate delay estimates, which misses critical optimization opportunities from appropriately configured FPGA blocks like DSP slices.\n  We present SkyEgg, a novel hardware synthesis framework that jointly optimizes implementation selection and scheduling using the e-graph data structure. Our key insight is that both algebraic transformations and hardware implementation choices can be uniformly represented as rewrite rules within an e-graph, modeling the complete design space of implementation candidates to be selected and scheduled together. First, SkyEgg constructs an e-graph from the input program. It then applies both algebraic and implementation rewrites through equality saturation. Finally, it formulates the joint optimization as a mixed-integer linear programming (MILP) problem on the saturated e-graph. We provide both exact MILP solving and an efficient ASAP heuristic for scalable synthesis. Our evaluation on benchmarks from diverse applications targeting Xilinx Kintex UltraScale+ FPGAs demonstrates that SkyEgg achieves an average speedup of 3.01x over Vitis HLS, with improvements up to 5.22x for complex expressions.", "AI": {"tldr": "SkyEgg\u6846\u67b6\u901a\u8fc7e-graph\u8054\u5408\u4f18\u5316\u5b9e\u73b0\u9009\u62e9\u4e0e\u8c03\u5ea6\uff0c\u91c7\u7528MILP\u6a21\u578b\u548c\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u76f8\u8f83\u4e8e\u4e3b\u6d41\u5de5\u5177\u5728FPGA\u4e0a\u5b9e\u73b0\u4e86\u5927\u5e45\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u76ee\u524d\u7684\u786c\u4ef6\u9ad8\u5c42\u63cf\u8ff0\u7efc\u5408\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff0c\u7279\u522b\u662f\u5728\u8bbe\u8ba1\u51b3\u7b56\uff08\u5982\u5b9e\u73b0\u9009\u62e9\u548c\u8c03\u5ea6\uff09\u4e0a\u662f\u987a\u5e8f\u3001\u5272\u88c2\u5730\u8fdb\u884c\uff0c\u5bfc\u81f4\u96be\u4ee5\u5145\u5206\u5229\u7528\u73b0\u4ee3FPGA\u7684\u5f02\u6784\u67b6\u6784\u3002\u73b0\u6709\u65b9\u6cd5\u5206\u522b\u5904\u7406\u5b9e\u73b0\u9009\u62e9\u548c\u8c03\u5ea6\uff0c\u5ffd\u7565\u4e86\u4e92\u76f8\u7684\u5f71\u54cd\uff0c\u9020\u6210\u6027\u80fd\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86SkyEgg\u6846\u67b6\uff0c\u5229\u7528e-graph\u6570\u636e\u7ed3\u6784\uff0c\u5c06\u4ee3\u6570\u53d8\u6362\u4e0e\u786c\u4ef6\u5b9e\u73b0\u9009\u62e9\u7edf\u4e00\u4e3a\u91cd\u5199\u89c4\u5219\uff0c\u901a\u8fc7equality saturation\u5bf9\u8f93\u5165\u7a0b\u5e8f\u751f\u6210\u9971\u548ce-graph\uff0c\u6700\u540e\u5c06\u8054\u5408\u4f18\u5316\u95ee\u9898\u5efa\u6a21\u4e3a\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08MILP\uff09\uff0c\u5e76\u63d0\u4f9b\u7cbe\u786e\u6c42\u89e3\u548c\u9ad8\u6548ASAP\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "result": "\u5728\u9488\u5bf9Xilinx Kintex UltraScale+ FPGA\u7684\u591a\u79cd\u5e94\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSkyEgg\u5e73\u5747\u6027\u80fd\u63d0\u53473.01\u500d\uff0c\u590d\u6742\u8868\u8fbe\u5f0f\u573a\u666f\u4e0b\u6700\u9ad8\u63d0\u53475.22\u500d\uff0c\u76f8\u8f83\u4e8e\u4e3b\u6d41Vitis HLS\u5de5\u5177\u3002", "conclusion": "\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5b9e\u73b0\u9009\u62e9\u4e0e\u8c03\u5ea6\uff0cSkyEgg\u80fd\u591f\u663e\u8457\u63d0\u5347\u786c\u4ef6\u7efc\u5408\u6027\u80fd\uff0c\u5145\u5206\u5229\u7528FPGA\u5f02\u6784\u67b6\u6784\uff0c\u5728\u591a\u4e2a\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e0b\u6548\u679c\u4f18\u8d8a\u3002"}}
{"id": "2511.14774", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14774", "abs": "https://arxiv.org/abs/2511.14774", "authors": ["Pei-Fu Guo", "Yun-Da Tsai", "Chun-Chia Hsu", "Kai-Xin Chen", "Ya-An Tsai", "Kai-Wei Chang", "Nanyun Peng", "Mi-Yen Yeh", "Shou-De Lin"], "title": "LiveCLKTBench: Towards Reliable Evaluation of Cross-Lingual Knowledge Transfer in Multilingual LLMs", "comment": null, "summary": "Evaluating cross-lingual knowledge transfer in large language models is challenging, as correct answers in a target language may arise either from genuine transfer or from prior exposure during pre-training. We present LiveCLKTBench, an automated generation pipeline specifically designed to isolate and measure cross-lingual knowledge transfer. Our pipeline identifies self-contained, time-sensitive knowledge entities from real-world domains, filters them based on temporal occurrence, and verifies them against the model's knowledge. The documents of these valid entities are then used to generate factual questions, which are translated into multiple languages to evaluate transferability across linguistic boundaries. Using LiveCLKTBench, we evaluate several LLMs across five languages and observe that cross-lingual transfer is strongly influenced by linguistic distance and often asymmetric across language directions. While larger models improve transfer, the gains diminish with scale and vary across domains. These findings provide new insights into multilingual transfer and demonstrate the value of LiveCLKTBench as a reliable benchmark for future research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLiveCLKTBench\u81ea\u52a8\u8bc4\u6d4b\u5de5\u5177\uff0c\u6709\u6548\u8bc4\u4f30LLM\u8de8\u8bed\u8a00\u77e5\u8bc6\u8fc1\u79fb\u80fd\u529b\u5e76\u63ed\u793a\u5176\u673a\u5236\u53ca\u9650\u5236\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8de8\u8bed\u8a00\u77e5\u8bc6\u8fc1\u79fb\u7684\u8868\u73b0\u5f88\u6709\u6311\u6218\u6027\uff0c\u4e3b\u8981\u56e0\u4e3a\u6b63\u786e\u7b54\u6848\u53ef\u80fd\u6765\u81ea\u6a21\u578b\u9884\u8bad\u7ec3\u4e2d\u7684\u5148\u9a8c\u66b4\u9732\uff0c\u4e5f\u53ef\u80fd\u6e90\u81ea\u771f\u5b9e\u8fc1\u79fb\u3002\u56e0\u6b64\u9700\u8981\u8bbe\u8ba1\u4e00\u4e2a\u80fd\u591f\u6392\u9664\u5148\u9a8c\u5f71\u54cd\u3001\u7eaf\u7cb9\u8bc4\u4f30\u77e5\u8bc6\u8fc1\u79fb\u7684\u8bc4\u6d4b\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u4e86LiveCLKTBench\uff0c\u4e00\u4e2a\u81ea\u52a8\u5316\u751f\u6210\u6d41\u7a0b\u3002\u8be5\u6d41\u7a0b\u4ece\u771f\u5b9e\u4e16\u754c\u4e2d\u62bd\u53d6\u72ec\u7acb\u4e14\u65f6\u6548\u6027\u5f88\u5f3a\u7684\u77e5\u8bc6\u5b9e\u4f53\uff0c\u5bf9\u5176\u53d1\u751f\u65f6\u95f4\u8fc7\u6ee4\u3001\u4e0e\u6a21\u578b\u5df2\u77e5\u77e5\u8bc6\u6838\u67e5\uff0c\u7136\u540e\u4ee5\u8fd9\u4e9b\u5b9e\u4f53\u4e3a\u57fa\u7840\u751f\u6210\u4e8b\u5b9e\u6027\u95ee\u9898\uff0c\u5e76\u7ffb\u8bd1\u6210\u591a\u79cd\u8bed\u8a00\uff0c\u4ee5\u8de8\u8bed\u79cd\u8bc4\u4f30\u8fc1\u79fb\u80fd\u529b\u3002", "result": "\u5229\u7528LiveCLKTBench\u5bf9\u591a\u79cdLLM\u5728\u4e94\u79cd\u8bed\u8a00\u4e0a\u8fdb\u884c\u8bc4\u6d4b\uff0c\u7ed3\u679c\u53d1\u73b0\u8de8\u8bed\u8a00\u8fc1\u79fb\u53d7\u8bed\u8a00\u8ddd\u79bb\u663e\u8457\u5f71\u54cd\uff0c\u4e14\u4e0d\u540c\u8bed\u8a00\u65b9\u5411\u4e4b\u95f4\u5177\u6709\u4e0d\u5bf9\u79f0\u6027\u3002\u6a21\u578b\u89c4\u6a21\u8d8a\u5927\u8fc1\u79fb\u8868\u73b0\u8d8a\u597d\uff0c\u4f46\u63d0\u5347\u5b58\u5728\u8fb9\u9645\u9012\u51cf\u4e14\u5728\u4e0d\u540c\u9886\u57df\u8868\u73b0\u4e0d\u4e00\u3002", "conclusion": "LiveCLKTBench\u6709\u6548\u9694\u79bb\u4e86\u77e5\u8bc6\u8fc1\u79fb\u4e0e\u5148\u9a8c\uff0c\u63ed\u793a\u4e86\u8de8\u8bed\u8a00\u77e5\u8bc6\u8fc1\u79fb\u4e2d\u7684\u8bed\u8a00\u8ddd\u79bb\u3001\u65b9\u5411\u4e0d\u5bf9\u79f0\u4e0e\u89c4\u6a21\u5f71\u54cd\uff0c\u6210\u4e3a\u672a\u6765\u7814\u7a76\u53ef\u9760\u7684\u57fa\u51c6\u5de5\u5177\u3002"}}
{"id": "2511.14791", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14791", "abs": "https://arxiv.org/abs/2511.14791", "authors": ["Cyriana M. A. Roelofs", "Edison Guevara Bastidas", "Thomas Hugo", "Stefan Faulstich", "Anna Cadenbach"], "title": "Enabling Predictive Maintenance in District Heating Substations: A Labelled Dataset and Fault Detection Evaluation Framework based on Service Data", "comment": "30 pages, 6 figures", "summary": "Early detection of faults in district heating substations is imperative to reduce return temperatures and enhance efficiency. However, progress in this domain has been hindered by the limited availability of public, labelled datasets. We present an open source framework combining a service report validated public dataset, an evaluation method based on Accuracy, Reliability, and Earliness, and baseline results implemented with EnergyFaultDetector, an open source Python framework.\n  The dataset contains time series of operational data from 93 substations across two manufacturers, annotated with a list of disturbances due to faults and maintenance actions, a set of normal-event examples and detailed fault metadata. We evaluate the EnergyFaultDetector using three metrics: Accuracy for recognising normal behaviour, an eventwise F Score for reliable fault detection with few false alarms, and Earliness for early detection. The framework also supports root cause analysis using ARCANA. We demonstrate three use cases to assist operators in interpreting anomalies and identifying underlying faults. The models achieve high normal-behaviour accuracy (0.98) and eventwise F-score (beta=0.5) of 0.83, detecting 60% of the faults in the dataset before the customer reports a problem, with an average lead time of 3.9 days.\n  Integrating an open dataset, metrics, open source code, and baselines establishes a reproducible, fault centric benchmark with operationally meaningful evaluation, enabling consistent comparison and development of early fault detection and diagnosis methods for district heating substations.", "AI": {"tldr": "\u6587\u4e2d\u63d0\u51fa\u4e86\u9488\u5bf9\u533a\u57df\u4f9b\u70ed\u6362\u70ed\u7ad9\u6545\u969c\u65e9\u671f\u68c0\u6d4b\u7684\u5f00\u6e90\u5de5\u5177\u4e0e\u6570\u636e\u96c6\uff0c\u6a21\u578b\u5728\u90e8\u5206\u6545\u969c\u53ef\u63d0\u524d\u7ea64\u5929\u68c0\u6d4b\u5230\uff0c\u51c6\u786e\u7387\u548cF\u5206\u6570\u8868\u73b0\u4f18\u5f02\uff0c\u7814\u7a76\u4e3a\u8be5\u9886\u57df\u5efa\u7acb\u4e86\u53ef\u590d\u73b0\u3001\u516c\u5f00\u3001\u5b9e\u9645\u8bc4\u4f30\u57fa\u51c6\u3002", "motivation": "\u533a\u57df\u4f9b\u70ed\u6362\u70ed\u7ad9\u65e9\u671f\u6545\u969c\u68c0\u6d4b\u5bf9\u4e8e\u964d\u4f4e\u56de\u6c34\u6e29\u5ea6\u548c\u63d0\u5347\u6548\u7387\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8be5\u9886\u57df\u7684\u53d1\u5c55\u53d7\u9650\u4e8e\u516c\u5f00\u6807\u6ce8\u6570\u636e\u96c6\u7684\u532e\u4e4f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f00\u6e90\u6846\u67b6\uff0c\u5305\u62ec\u7ecf\u670d\u52a1\u62a5\u544a\u9a8c\u8bc1\u7684\u516c\u5f00\u6570\u636e\u96c6\u3001\u57fa\u4e8e\u51c6\u786e\u7387\u3001\u53ef\u9760\u6027\u548c\u63d0\u524d\u6027\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4ee5\u53ca\u7528EnergyFaultDetector\u5b9e\u73b0\u7684\u57fa\u7ebf\u7ed3\u679c\u3002\u6570\u636e\u96c6\u5305\u542b\u6765\u81ea93\u4e2a\u6362\u70ed\u7ad9\u7684\u65f6\u5e8f\u8fd0\u884c\u6570\u636e\uff0c\u5e76\u6709\u6545\u969c\u3001\u7ef4\u4fee\u3001\u6b63\u5e38\u4e8b\u4ef6\u53ca\u8be6\u7ec6\u7684\u6545\u969c\u5143\u6570\u636e\u6807\u6ce8\u3002\u91c7\u7528\u4e09\u79cd\u6307\u6807\u8fdb\u884c\u6a21\u578b\u8bc4\u4f30\uff1a\u8bc6\u522b\u6b63\u5e38\u884c\u4e3a\u7684\u51c6\u786e\u7387\u3001\u4e8b\u4ef6\u7ea7F\u5206\u6570\uff08\u7528\u4e8e\u53ef\u9760\u6545\u969c\u68c0\u6d4b\u548c\u51cf\u5c11\u8bef\u62a5\uff09\u548c\u63d0\u524d\u6027\uff08\u7528\u4e8e\u65e9\u671f\u68c0\u6d4b\uff09\u3002\u6846\u67b6\u8fd8\u652f\u6301\u901a\u8fc7ARCANA\u8fdb\u884c\u6545\u969c\u6839\u56e0\u5206\u6790\uff0c\u5e76\u5c55\u793a\u4e86\u4e09\u79cd\u8f85\u52a9\u64cd\u4f5c\u4eba\u5458\u89e3\u91ca\u5f02\u5e38\u548c\u53d1\u73b0\u6839\u672c\u6545\u969c\u7684\u5e94\u7528\u573a\u666f\u3002", "result": "\u6a21\u578b\u5728\u8bc6\u522b\u6b63\u5e38\u884c\u4e3a\u4e0a\u7684\u51c6\u786e\u7387\u8fbe\u52300.98\uff0c\u4e8b\u4ef6\u7ea7F\u5206\u6570\uff08\u03b2=0.5\uff09\u4e3a0.83\uff0c\u80fd\u5728\u5ba2\u6237\u62a5\u544a\u95ee\u9898\u524d\u68c0\u6d4b\u523060%\u7684\u6545\u969c\uff0c\u5e73\u5747\u63d0\u524d3.9\u5929\u3002", "conclusion": "\u5c06\u5f00\u653e\u6570\u636e\u96c6\u3001\u6307\u6807\u3001\u5f00\u6e90\u4ee3\u7801\u53ca\u57fa\u7ebf\u65b9\u6cd5\u76f8\u7ed3\u5408\uff0c\u5efa\u7acb\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u3001\u4ee5\u6545\u969c\u4e3a\u4e2d\u5fc3\u4e14\u5177\u5907\u5b9e\u9645\u64cd\u4f5c\u610f\u4e49\u7684\u57fa\u51c6\uff0c\u6709\u52a9\u4e8e\u533a\u57df\u4f9b\u70ed\u6362\u70ed\u7ad9\u6545\u969c\u65e9\u671f\u68c0\u6d4b\u53ca\u8bca\u65ad\u65b9\u6cd5\u7684\u6301\u7eed\u6bd4\u8f83\u548c\u53d1\u5c55\u3002"}}
{"id": "2511.15581", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.15581", "abs": "https://arxiv.org/abs/2511.15581", "authors": ["Kayo Tei", "Haruto Mishina", "Naoki Yamamoto", "Kazunori Ueda"], "title": "Graph Rewriting Language as a Platform for Quantum Diagrammatic Calculi", "comment": "27 pages, 27 figures. Extended version (with Appendices) of the paper to be presented at the 28th International Symposium on Practical Aspects of Declarative Languages (PADL 2026), January 2026", "summary": "Systematic discovery of optimization paths in quantum circuit simplification remains a challenge. Today, ZX-calculus, a computing model for quantum circuit transformation, is attracting attention for its highly abstract graph-based approach. Whereas existing tools such as PyZX and Quantomatic offer domain-specific support for quantum circuit optimization, visualization and theorem-proving, we present a complementary approach using LMNtal, a general-purpose hierarchical graph rewriting language, to establish a diagrammatic transformation and verification platform with model checking. Our methodology shows three advantages: (1) manipulation of ZX-diagrams through native graph transformation rules, enabling direct implementation of basic rules; (2) quantified pattern matching via QLMNtal extensions, greatly simplifying rule specification; and (3) interactive visualization and validation of optimization paths through state space exploration. Through case studies, we demonstrate how our framework helps understand optimization paths and design new algorithms and strategies. This suggests that the declarative language LMNtal and its toolchain could serve as a new platform to investigate quantum circuit transformation from a different perspective.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8e\u901a\u7528\u56fe\u91cd\u5199\u8bed\u8a00LMNtal\u7684\u65b0\u5e73\u53f0\uff0c\u6709\u6548\u652f\u6301\u91cf\u5b50\u7535\u8def\u7684ZX\u6f14\u7b97\u4f18\u5316\u3001\u53ef\u89c6\u5316\u548c\u9a8c\u8bc1\uff0c\u5c55\u73b0\u4e86\u5728\u7406\u89e3\u548c\u8bbe\u8ba1\u4f18\u5316\u8def\u5f84\u4e0a\u7684\u72ec\u7279\u4f18\u52bf\u3002", "motivation": "\u91cf\u5b50\u7535\u8def\u4f18\u5316\u8def\u5f84\u7684\u7cfb\u7edf\u53d1\u73b0\u4ecd\u5177\u6709\u6311\u6218\u6027\uff0c\u76ee\u524d\u4e3b\u8981\u65b9\u6cd5\u5982ZX\u6f14\u7b97\u6a21\u578b\u4e0e\u76f8\u5173\u5de5\u5177\uff0c\u867d\u6709\u7279\u5b9a\u9886\u57df\u652f\u6301\uff0c\u4f46\u4ecd\u5b58\u5728\u5c40\u9650\u3002", "method": "\u91c7\u7528\u901a\u7528\u7684\u5206\u5c42\u56fe\u91cd\u5199\u8bed\u8a00LMNtal\uff0c\u5e76\u7ed3\u5408QLMNtal\u6269\u5c55\uff0c\u5b9e\u73b0\u5bf9ZX\u56fe\u7684\u672c\u5730\u8f6c\u6362\u3001\u6a21\u5f0f\u5339\u914d\u4e0e\u72b6\u6001\u7a7a\u95f4\u63a2\u7d22\uff0c\u6784\u5efa\u91cf\u5b50\u7535\u8def\u56fe\u5f62\u5316\u8f6c\u6362\u548c\u9a8c\u8bc1\u5e73\u53f0\u3002", "result": "\u8be5\u65b9\u6cd5\u5177\u6709\u4e09\u5927\u4f18\u52bf\uff1a\u539f\u751f\u56fe\u8f6c\u6362\u89c4\u5219\u53ef\u76f4\u63a5\u6267\u884cZX\u53d8\u6362\u3001\u91cf\u5316\u6a21\u5f0f\u5339\u914d\u7b80\u5316\u89c4\u5219\u4e66\u5199\u3001\u53ef\u4ea4\u4e92\u5730\u63a2\u7d22\u548c\u9a8c\u8bc1\u4f18\u5316\u8def\u3002\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u7406\u89e3\u4f18\u5316\u8def\u5f84\uff0c\u5e76\u53ef\u8bbe\u8ba1\u65b0\u7b97\u6cd5\u4e0e\u7b56\u7565\u3002", "conclusion": "LMNtal\u53ca\u5176\u5de5\u5177\u94fe\u4e3a\u91cf\u5b50\u7535\u8def\u8f6c\u6362\u63d0\u4f9b\u4e86\u65b0\u7684\u5e73\u53f0\u4e0e\u89c6\u89d2\uff0c\u663e\u793a\u51fa\u5176\u5728\u91cf\u5b50\u7535\u8def\u4f18\u5316\u9886\u57df\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.14776", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.14776", "abs": "https://arxiv.org/abs/2511.14776", "authors": ["Snigdha Pandya", "Rohan Nagale", "Kenji Sahay", "Anna Lin", "Shikhar Shiromani", "Kevin Zhu", "Dev Sunishchal"], "title": "COMPASS: Context-Modulated PID Attention Steering System for Hallucination Mitigation", "comment": "9 pages, 6 figures including algorithmns, 2 tables", "summary": "Large language models (LLMs) often generate fluent but factually incorrect statements despite having access to relevant evidence, a failure mode rooted in how they allocate attention between contextual and parametric knowledge. Understanding and steering this internal behavior is key both for trustworthy deployment and for scientific interpretability of model mechanisms. We introduce COMPASS (Context-Modulated PID Attention Steering System), a lightweight, interpretable control framework that embeds a model-based feedback loop directly within decoding. COMPASS quantifies context reliance via a transparent metric, the Context Reliance Score (CRS), which serves as an online probe of how attention heads ground generation in evidence. Using this interpretable signal, a PID controller dynamically modulates attention heads to maintain factual consistency without retraining or multi-pass decoding. Across benchmarks (HotpotQA, XSum, HaluEval, RAGTruth), COMPASS consistently reduces contextual hallucination rates (2.8 to 5.8 percent absolute) while revealing how distinct attention heads contribute to evidence alignment. These results highlight feedback-driven interpretability as a pathway toward scientific understanding of LLM behavior.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCOMPASS\u6846\u67b6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u4f9d\u8d56\u6027\u8bc4\u5206\u548cPID\u63a7\u5236\u52a8\u6001\u8c03\u6574\u6ce8\u610f\u529b\u5934\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u4e8b\u5b9e\u4e00\u81f4\u6027\uff0c\u540c\u65f6\u589e\u5f3a\u6a21\u578b\u53ef\u89e3\u91ca\u6027\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5e38\u5e38\u867d\u6709\u76f8\u5173\u8bc1\u636e\u5374\u751f\u6210\u5185\u5bb9\u6d41\u7545\u4f46\u4e8b\u5b9e\u9519\u8bef\u7684\u9648\u8ff0\u3002\u8fd9\u79cd\u73b0\u8c61\u6e90\u4e8e\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u77e5\u8bc6\u548c\u53c2\u6570\u5316\u77e5\u8bc6\u4e4b\u95f4\u5206\u914d\u6ce8\u610f\u529b\u7684\u65b9\u5f0f\u3002\u7406\u89e3\u53ca\u5f15\u5bfc\u8fd9\u79cd\u5185\u90e8\u884c\u4e3a\u5bf9\u6a21\u578b\u53ef\u9760\u90e8\u7f72\u548c\u79d1\u5b66\u673a\u5236\u89e3\u91ca\u975e\u5e38\u5173\u952e\u3002", "method": "\u63d0\u51fa\u4e86COMPASS\uff08Context-Modulated PID Attention Steering System\uff09\uff0c\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u63a7\u5236\u6846\u67b6\uff0c\u5728\u89e3\u7801\u8fc7\u7a0b\u4e2d\u5d4c\u5165\u57fa\u4e8e\u6a21\u578b\u7684\u53cd\u9988\u56de\u8def\u3002COMPASS\u901a\u8fc7Context Reliance Score\uff08CRS\uff09\u91cf\u5316\u6a21\u578b\u5bf9\u4e0a\u4e0b\u6587\u7684\u4f9d\u8d56\uff0c\u5e76\u5229\u7528\u8be5\u4fe1\u53f7\uff0c\u901a\u8fc7PID\u63a7\u5236\u5668\u52a8\u6001\u8c03\u6574\u6ce8\u610f\u529b\u5934\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u591a\u6b21\u89e3\u7801\uff0c\u5373\u80fd\u7ef4\u6301\u4e8b\u5b9e\u4e00\u81f4\u6027\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff08HotpotQA, XSum, HaluEval, RAGTruth\uff09\u4e0a\uff0cCOMPASS\u663e\u8457\u964d\u4f4e\u4e86\u6a21\u578b\u60c5\u5883\u5e7b\u89c9\u7387\uff08\u7edd\u5bf9\u4e0b\u964d2.8%-5.8%\uff09\uff0c\u5e76\u63ed\u793a\u4e86\u4e0d\u540c\u6ce8\u610f\u529b\u5934\u5bf9\u8bc1\u636e\u5bf9\u9f50\u7684\u8d21\u732e\u3002", "conclusion": "\u57fa\u4e8e\u53cd\u9988\u7684\u53ef\u89e3\u91ca\u6027\u8def\u5f84\u4e3a\u79d1\u5b66\u7406\u89e3LLM\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0cCOMPASS\u6846\u67b6\u5728\u63d0\u5347\u6a21\u578b\u4e8b\u5b9e\u4e00\u81f4\u6027\u548c\u89e3\u91ca\u80fd\u529b\u65b9\u9762\u6548\u679c\u663e\u8457\u3002"}}
{"id": "2511.14794", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14794", "abs": "https://arxiv.org/abs/2511.14794", "authors": ["Camilo Chac\u00f3n Sartori", "Christian Blum"], "title": "irace-evo: Automatic Algorithm Configuration Extended With LLM-Based Code Evolution", "comment": null, "summary": "Automatic algorithm configuration tools such as irace efficiently tune parameter values but leave algorithmic code unchanged. This paper introduces a first version of irace-evo, an extension of irace that integrates code evolution through large language models (LLMs) to jointly explore parameter and code spaces. The proposed framework enables multi-language support (e.g., C++, Python), reduces token consumption via progressive context management, and employs the Always-From-Original principle to ensure robust and controlled code evolution. We evaluate irace-evo on the Construct, Merge, Solve & Adapt (CMSA) metaheuristic for the Variable-Sized Bin Packing Problem (VSBPP). Experimental results show that irace-evo can discover new algorithm variants that outperform the state-of-the-art CMSA implementation while maintaining low computational and monetary costs. Notably, irace-evo generates competitive algorithmic improvements using lightweight models (e.g., Claude Haiku 3.5) with a total usage cost under 2 euros. These results demonstrate that coupling automatic configuration with LLM-driven code evolution provides a powerful, cost-efficient avenue for advancing heuristic design and metaheuristic optimization.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fairace-evo\uff0c\u7ed3\u5408\u81ea\u52a8\u53c2\u6570\u8c03\u4f18\u4e0e\u5927\u6a21\u578b\u4ee3\u7801\u8fdb\u5316\uff0c\u5728\u591a\u8bed\u8a00\u548c\u6210\u672c\u63a7\u5236\u4e0b\u4f18\u5316\u7b97\u6cd5\u3002\u5b9e\u9a8c\u5728\u53d8\u5c3a\u5bf8\u7bb1\u5305\u88c5\u95ee\u9898\u4e0a\u8868\u660e\u5176\u80fd\u4f4e\u6210\u672c\u53d1\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u65b0\u7b97\u6cd5\u65b9\u6848\u3002", "motivation": "\u81ea\u52a8\u7b97\u6cd5\u914d\u7f6e\u5de5\u5177\uff08\u5982irace\uff09\u80fd\u6709\u6548\u8c03\u6574\u53c2\u6570\uff0c\u4f46\u65e0\u6cd5\u66f4\u6539\u7b97\u6cd5\u4ee3\u7801\uff0c\u672c\u8bba\u6587\u65e8\u5728\u7a81\u7834\u53c2\u6570\u7a7a\u95f4\u9650\u5236\uff0c\u5c06\u4ee3\u7801\u8fdb\u5316\u4e0e\u81ea\u52a8\u914d\u7f6e\u7ed3\u5408\uff0c\u63d0\u5347\u7b97\u6cd5\u8bbe\u8ba1\u521b\u65b0\u6027\u3002", "method": "\u63d0\u51fairace-evo\uff0c\u7ed3\u5408irace\u81ea\u52a8\u53c2\u6570\u8c03\u6574\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7801\u8fdb\u5316\uff0c\u5b9e\u73b0\u591a\u8bed\u8a00\u652f\u6301\u3001\u6e10\u8fdb\u5f0f\u4e0a\u4e0b\u6587\u7ba1\u7406\u4e0eAlways-From-Original\u539f\u7406\u63a7\u5236\u4ee3\u7801\u53d8\u66f4\uff0c\u7528\u4ee5\u8bc4\u4f30CMSA\u5143\u542f\u53d1\u5f0f\u5728\u53d8\u5c3a\u5bf8\u7bb1\u5305\u88c5\u95ee\u9898\u4e0a\u7684\u4f18\u5316\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cirace-evo\u80fd\u5728\u4f4e\u7b97\u529b\u4e0e\u4f4e\u6210\u672c\u6761\u4ef6\u4e0b\u53d1\u73b0\u4f18\u4e8e\u73b0\u6709CMSA\u5b9e\u73b0\u7684\u65b0\u7b97\u6cd5\u53d8\u4f53\uff0c\u5176\u4e2d\u8f7b\u91cf\u7ea7\u6a21\u578b\uff08\u5982Claude Haiku 3.5\uff09\u603b\u6210\u672c\u4f4e\u4e8e2\u6b27\u5143\uff0c\u751f\u6210\u7684\u7b97\u6cd5\u6539\u8fdb\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u5c06\u53c2\u6570\u81ea\u52a8\u914d\u7f6e\u4e0eLLM\u9a71\u52a8\u7684\u4ee3\u7801\u8fdb\u5316\u7ed3\u5408\u53ef\u5927\u5e45\u63d0\u5347\u542f\u53d1\u5f0f\u4e0e\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u4f18\u5316\uff0c\u63d0\u4f9b\u5f3a\u529b\u4e14\u6027\u4ef7\u6bd4\u9ad8\u7684\u7b97\u6cd5\u8bbe\u8ba1\u8def\u5f84\u3002"}}
{"id": "2511.15403", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.15403", "abs": "https://arxiv.org/abs/2511.15403", "authors": ["Isabel Amaral", "Alexandra Mendes", "Jos\u00e9 Campos"], "title": "MutDafny: A Mutation-Based Approach to Assess Dafny Specifications", "comment": null, "summary": "This paper explores the use of mutation testing to reveal weaknesses in formal specifications written in Dafny. In verification-aware programming languages, such as Dafny, despite their critical role, specifications are as prone to errors as implementations. Flaws in specs can result in formally verified programs that deviate from the intended behavior.\n  We present MutDafny, a tool that increases the reliability of Dafny specifications by automatically signaling potential weaknesses. Using a mutation testing approach, we introduce faults (mutations) into the code and rely on formal specifications for detecting them. If a program with a mutant verifies, this may indicate a weakness in the specification. We extensively analyze mutation operators from popular tools, identifying the ones applicable to Dafny. In addition, we synthesize new operators tailored for Dafny from bugfix commits in publicly available Dafny projects on GitHub. Drawing from both, we equipped our tool with a total of 32 mutation operators. We evaluate MutDafny's effectiveness and efficiency in a dataset of 794 real-world Dafny programs and we manually analyze a subset of the resulting undetected mutants, identifying five weak real-world specifications (on average, one at every 241 lines of code) that would benefit from strengthening.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u5229\u7528\u53d8\u5f02\u6d4b\u8bd5\u63ed\u793aDafny\u89c4\u683c\u8584\u5f31\u70b9\u7684\u65b0\u5de5\u5177MutDafny\uff0c\u901a\u8fc7\u5b9e\u6d4b\u8868\u660e\u80fd\u6709\u6548\u627e\u51fa\u771f\u5b9e\u9879\u76ee\u4e2d\u9700\u52a0\u5f3a\u7684\u6b63\u5f0f\u89c4\u683c\uff0c\u4ece\u800c\u63d0\u5347\u7a0b\u5e8f\u53ef\u9760\u6027\u3002", "motivation": "\u6b63\u5f0f\u89c4\u683c\u5728\u7a0b\u5e8f\u9a8c\u8bc1\u4e2d\u8d77\u7740\u5173\u952e\u4f5c\u7528\uff0c\u4f46\u540c\u6837\u5bb9\u6613\u51fa\u9519\uff1b\u4e00\u65e6\u89c4\u683c\u5b58\u5728\u7f3a\u9677\uff0c\u5c06\u5bfc\u81f4\u5df2\u88ab\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u7a0b\u5e8f\u884c\u4e3a\u504f\u79bb\u9884\u671f\u3002\u56e0\u6b64\uff0c\u63d0\u5347\u6b63\u5f0f\u89c4\u683c\u7684\u53ef\u9760\u6027\u662f\u5fc5\u9700\u7684\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86Mutation Testing\u65b9\u6cd5\uff0c\u5e76\u5b9e\u73b0\u4e86MutDafny\u5de5\u5177\u3002\u8be5\u5de5\u5177\u901a\u8fc7\u81ea\u52a8\u5f15\u5165\u53d8\u5f02\uff08faults\uff09\u5e76\u68c0\u67e5\u8fd9\u4e9b\u53d8\u5f02\u662f\u5426\u88ab\u89c4\u683c\u68c0\u6d4b\u5230\uff0c\u4ece\u800c\u53d1\u73b0\u89c4\u683c\u7684\u6f5c\u5728\u5f31\u70b9\u3002\u4f5c\u8005\u8fd8\u7cfb\u7edf\u5206\u6790\u4e86\u73b0\u6709\u53d8\u5f02\u7b97\u5b50\uff0c\u5e76\u7ed3\u5408GitHub\u4e0a\u7684bug\u4fee\u590d\u8bb0\u5f55\uff0c\u4e3aDafny\u91cf\u8eab\u5b9a\u5236\u4e86\u4e00\u6279\u65b0\u7684\u53d8\u5f02\u7b97\u5b50\uff0c\u6700\u7ec8\u6574\u5408\u4e3a32\u79cd\u3002", "result": "MutDafny\u5de5\u5177\u5728794\u4e2a\u771f\u5b9eDafny\u7a0b\u5e8f\u4e0a\u8fdb\u884c\u4e86\u8bc4\u6d4b\uff0c\u8bc1\u660e\u5176\u6709\u6548\u6027\u4e0e\u6548\u7387\u3002\u901a\u8fc7\u5bf9\u68c0\u6d4b\u672a\u5230\u7684\u53d8\u5f02\u4f53\u624b\u52a8\u5206\u6790\uff0c\u8bc6\u522b\u51fa\u4e865\u4e2a\u771f\u5b9e\u7684\u8584\u5f31\u89c4\u683c\uff0c\u5e73\u5747\u6bcf241\u884c\u4ee3\u7801\u5c31\u53d1\u73b0\u4e00\u4e2a\u9700\u52a0\u5f3a\u7684\u89c4\u683c\u3002", "conclusion": "Mutation Testing\u65b9\u6cd5\u80fd\u6709\u6548\u63ed\u793aDafny\u6b63\u5f0f\u89c4\u683c\u4e2d\u7684\u8584\u5f31\u73af\u8282\uff0cMutDafny\u5de5\u5177\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u89c4\u683c\u7684\u53ef\u9760\u6027\uff0c\u5728\u5b9e\u8bc1\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u826f\u3002\u8be5\u5de5\u5177\u548c\u65b9\u6cd5\u5bf9\u5176\u5b83\u4f9d\u8d56\u5f62\u5f0f\u5316\u89c4\u683c\u7684\u7cfb\u7edf\u5177\u6709\u63a8\u5e7f\u4ef7\u503c\u3002"}}
{"id": "2511.14779", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.14779", "abs": "https://arxiv.org/abs/2511.14779", "authors": ["Julio Cesar Galdino", "Sidney Evaldo Leal", "Leticia Gabriella De Souza", "Rodrigo de Freitas Lima", "Antonio Nelson Fornari Mendes Moreira", "Arnaldo Candido Junior", "Miguel Oliveira", "Edresson Casanova", "Sandra M. Alu\u00edsio"], "title": "The Impact of Prosodic Segmentation on Speech Synthesis of Spontaneous Speech", "comment": null, "summary": "Spontaneous speech presents several challenges for speech synthesis, particularly in capturing the natural flow of conversation, including turn-taking, pauses, and disfluencies. Although speech synthesis systems have made significant progress in generating natural and intelligible speech, primarily through architectures that implicitly model prosodic features such as pitch, intensity, and duration, the construction of datasets with explicit prosodic segmentation and their impact on spontaneous speech synthesis remains largely unexplored. This paper evaluates the effects of manual and automatic prosodic segmentation annotations in Brazilian Portuguese on the quality of speech synthesized by a non-autoregressive model, FastSpeech 2. Experimental results show that training with prosodic segmentation produced slightly more intelligible and acoustically natural speech. While automatic segmentation tends to create more regular segments, manual prosodic segmentation introduces greater variability, which contributes to more natural prosody. Analysis of neutral declarative utterances showed that both training approaches reproduced the expected nuclear accent pattern, but the prosodic model aligned more closely with natural pre-nuclear contours. To support reproducibility and future research, all datasets, source codes, and trained models are publicly available under the CC BY-NC-ND 4.0 license.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5df4\u897f\u8461\u8404\u7259\u8bed\u8bed\u97f3\u5408\u6210\u4e2d\u624b\u52a8\u4e0e\u81ea\u52a8\u97f5\u5f8b\u5206\u6bb5\u7684\u6548\u679c\uff0c\u53d1\u73b0\u5f15\u5165\u97f5\u5f8b\u5206\u6bb5\u80fd\u63d0\u5347\u8bed\u97f3\u7684\u53ef\u61c2\u6027\u4e0e\u81ea\u7136\u5ea6\uff1b\u624b\u52a8\u5206\u6bb5\u8868\u73b0\u66f4\u81ea\u7136\u3002\u7814\u7a76\u6210\u679c\u548c\u8d44\u6e90\u5df2\u5168\u9762\u516c\u5f00\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u81ea\u53d1\u6027\u8bed\u97f3\u5408\u6210\u53d1\u5c55\u3002", "motivation": "\u81ea\u53d1\u6027\u8bed\u97f3\uff08spontaneous speech\uff09\u5408\u6210\u9762\u4e34\u81ea\u7136\u5bf9\u8bdd\u6d41\u7545\u6027\uff08\u5982\u8f6e\u66ff\u3001\u505c\u987f\u548c\u8bed\u97f3\u4e0d\u6d41\u7545\u7b49\uff09\u5b9e\u73b0\u4e0a\u7684\u6311\u6218\u3002\u867d\u7136\u5f53\u524d\u8bed\u97f3\u5408\u6210\u7cfb\u7edf\u5728\u751f\u6210\u81ea\u7136\u4e14\u53ef\u61c2\u8bed\u97f3\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u4e3b\u8981\u662f\u57fa\u4e8e\u9690\u5f0f\u97f5\u5f8b\u7279\u5f81\u7684\u67b6\u6784\uff0c\u4f46\u5bf9\u660e\u786e\u97f5\u5f8b\u5206\u6bb5\u6570\u636e\u96c6\u7684\u6784\u5efa\u53ca\u5176\u5bf9\u81ea\u53d1\u6027\u8bed\u97f3\u5408\u6210\u8d28\u91cf\u7684\u5f71\u54cd\u5c1a\u5c11\u6709\u6df1\u5165\u7814\u7a76\u3002", "method": "\u672c\u6587\u5bf9\u5df4\u897f\u8461\u8404\u7259\u8bed\u4e2d\u624b\u52a8\u4e0e\u81ea\u52a8\u97f5\u5f8b\u5206\u6bb5\u6ce8\u91ca\u5728\u57fa\u4e8eFastSpeech 2\u975e\u81ea\u56de\u5f52\u6a21\u578b\u5408\u6210\u8bed\u97f3\u8d28\u91cf\u4e0a\u7684\u4f5c\u7528\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u5b9e\u9a8c\u4ee5\u4e24\u79cd\u97f5\u5f8b\u5206\u6bb5\u65b9\u5f0f\u5206\u522b\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u5bf9\u751f\u6210\u8bed\u97f3\u7684\u53ef\u61c2\u6027\u4e0e\u81ea\u7136\u5ea6\u8fdb\u884c\u4e3b\u5ba2\u89c2\u5206\u6790\u3002\u540c\u65f6\uff0c\u5206\u6790\u4e86\u4e24\u79cd\u65b9\u5f0f\u5bf9\u58f0\u660e\u53e5\u6838\u91cd\u97f3\u548c\u524d\u6838\u97f5\u5f8b\u8f6e\u5ed3\u7684\u590d\u73b0\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u91c7\u7528\u97f5\u5f8b\u5206\u6bb5\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u53ef\u61c2\u6027\u548c\u58f0\u5b66\u81ea\u7136\u5ea6\u4e0a\u7565\u6709\u63d0\u5347\u3002\u81ea\u52a8\u5206\u6bb5\u4ea7\u751f\u66f4\u89c4\u5219\u7684\u7247\u6bb5\uff0c\u624b\u52a8\u5206\u6bb5\u5219\u5e26\u6765\u66f4\u4e30\u5bcc\u7684\u53d8\u5316\uff0c\u4f7f\u97f5\u5f8b\u66f4\u81ea\u7136\u3002\u5728\u4e2d\u6027\u58f0\u660e\u53e5\u5b9e\u9a8c\u4e2d\uff0c\u4e24\u79cd\u6a21\u578b\u5747\u80fd\u590d\u73b0\u9884\u671f\u6838\u91cd\u97f3\uff0c\u5e76\u4e14\u97f5\u5f8b\u6a21\u578b\uff08\u91c7\u7528\u97f5\u5f8b\u5206\u6bb5\uff09\u5728\u524d\u6838\u8f6e\u5ed3\u4e0a\u66f4\u8d34\u5408\u81ea\u7136\u8bed\u97f3\u3002\u6240\u6709\u6570\u636e\u96c6\u3001\u4ee3\u7801\u548c\u6a21\u578b\u5747\u5df2\u5f00\u653e\u83b7\u53d6\u3002", "conclusion": "\u660e\u786e\u97f5\u5f8b\u5206\u6bb5\u6570\u636e\u6709\u52a9\u4e8e\u63d0\u9ad8\u81ea\u53d1\u6027\u8bed\u97f3\u5408\u6210\u4e2d\u8bed\u97f3\u7684\u53ef\u61c2\u5ea6\u4e0e\u81ea\u7136\u5ea6\uff0c\u5c24\u5176\u662f\u624b\u52a8\u5206\u6bb5\u80fd\u8d4b\u4e88\u97f5\u5f8b\u53d8\u5316\u66f4\u591a\u81ea\u7136\u6027\u3002\u76f8\u5173\u6570\u636e\u96c6\u53ca\u5de5\u5177\u7684\u516c\u5f00\u5c06\u4fc3\u8fdb\u9886\u57df\u5185\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2511.14798", "categories": ["cs.SE", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.14798", "abs": "https://arxiv.org/abs/2511.14798", "authors": ["Ahmad Memon", "Abdallah Mohamed"], "title": "Evaluating Generative AI for CS1 Code Grading: Direct vs Reverse Methods", "comment": "10 pages, 5 figures. This version corresponds to the paper accepted for presentation at CASCON 2025", "summary": "Manual grading of programming assignments in introductory computer science courses can be time-consuming and prone to inconsistencies. While unit testing is commonly used for automatic evaluation, it typically follows a binary pass/fail model and does not give partial marks. Recent advances in large language models (LLMs) offer the potential for automated, scalable, and more objective grading.\n  This paper compares two AI-based grading techniques: \\textit{Direct}, where the AI model applies a rubric directly to student code, and \\textit{Reverse} (a newly proposed approach), where the AI first fixes errors, then deduces a grade based on the nature and number of fixes. Each method was evaluated on both the instructor's original grading scale and a tenfold expanded scale to assess the impact of range on AI grading accuracy. To assess their effectiveness, AI-assigned scores were evaluated against human tutor evaluations on a range of coding problems and error types.\n  Initial findings suggest that while the Direct approach is faster and straightforward, the Reverse technique often provides a more fine-grained assessment by focusing on correction effort. Both methods require careful prompt engineering, particularly for allocating partial credit and handling logic errors. To further test consistency, we also used synthetic student code generated using Gemini Flash 2.0, which allowed us to evaluate AI graders on a wider range of controlled error types and difficulty levels. We discuss the strengths and limitations of each approach, practical considerations for prompt design, and future directions for hybrid human-AI grading systems that aim to improve consistency, efficiency, and fairness in CS courses.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6bd4\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u4e24\u79cd\u81ea\u52a8\u8bc4\u6d4b\u7f16\u7a0b\u4f5c\u4e1a\u7684\u65b9\u6cd5\uff1a\u76f4\u63a5\u8bc4\u5206\u548c\u57fa\u4e8e\u9519\u8bef\u4fee\u6b63\u7684\u53cd\u5411\u63a8\u65ad\u8bc4\u5206\u3002\u7ed3\u679c\u663e\u793a\uff0c\u53cd\u5411\u63a8\u65ad\u6cd5\u7ed9\u5206\u66f4\u7ec6\u81f4\uff0c\u4f46\u4e24\u8005\u5747\u4f9d\u8d56\u7cbe\u7ec6\u7684\u63d0\u793a\u8bbe\u8ba1\u3002\u672a\u6765\u63a8\u8350\u91c7\u7528\u4eba\u673a\u6df7\u5408\u7684\u81ea\u52a8\u5316\u6279\u6539\u7cfb\u7edf\u4ee5\u63d0\u5347\u4e00\u81f4\u6027\u4e0e\u516c\u5e73\u6027\u3002", "motivation": "\u7f16\u7a0b\u4f5c\u4e1a\u7684\u4eba\u5de5\u4f5c\u4e1a\u6279\u6539\u6548\u7387\u4f4e\u4e14\u5bb9\u6613\u51fa\u73b0\u4e0d\u4e00\u81f4\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u624b\u6bb5\uff08\u5982\u5355\u5143\u6d4b\u8bd5\uff09\u4ec5\u652f\u6301\u4e8c\u5143\u5224\u5b9a\uff0c\u96be\u4ee5\u652f\u6301\u90e8\u5206\u5206\u7ed9\u5206\u3002\u8fd1\u5e74\u6765\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u4e3a\u81ea\u52a8\u5316\u3001\u516c\u6b63\u3001\u53ef\u6269\u5c55\u7684\u7f16\u7a0b\u4f5c\u4e1a\u81ea\u52a8\u6279\u6539\u5e26\u6765\u4e86\u65b0\u673a\u9047\u3002", "method": "\u672c\u6587\u63d0\u51fa\u5e76\u6bd4\u8f83\u4e86\u4e24\u79cdAI\u8f85\u52a9\u7f16\u7a0b\u4f5c\u4e1a\u6279\u6539\u7684\u6280\u672f\uff1aDirect\u65b9\u6cd5\u8ba9AI\u76f4\u63a5\u5e94\u7528\u8bc4\u5206\u6807\u51c6\u8bc4\u5224\u5b66\u751f\u4ee3\u7801\uff1bReverse\u65b9\u6cd5\u5219\u521b\u65b0\u6027\u5730\u5148\u7531AI\u4fee\u590d\u5b66\u751f\u4ee3\u7801\u4e2d\u7684\u9519\u8bef\uff0c\u518d\u57fa\u4e8e\u4fee\u590d\u7684\u9519\u8bef\u79cd\u7c7b\u548c\u6570\u91cf\u6765\u63a8\u65ad\u7ed9\u5206\u3002\u4e24\u79cd\u65b9\u6cd5\u5747\u5728\u539f\u59cb\u548c\u6269\u5c55\u5341\u500d\u7684\u8bc4\u5206\u533a\u95f4\u4e0b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u4e0e\u4eba\u5de5\u6279\u6539\u7ed3\u679c\u5bf9\u6bd4\u8bc4\u4f30\uff0c\u8fd8\u4f7f\u7528Gemini Flash 2.0\u5408\u6210\u5b66\u751f\u4ee3\u7801\u4ee5\u6269\u5c55\u6d4b\u8bd5\u8986\u76d6\u9762\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cDirect\u6cd5\u5feb\u901f\u3001\u7b80\u5355\uff0cReverse\u6cd5\u80fd\u6839\u636e\u4fee\u6b63\u96be\u5ea6\u7ed9\u51fa\u66f4\u7ec6\u81f4\u7684\u5206\u6570\u3002\u4e24\u79cd\u65b9\u6cd5\u5728\u5206\u914d\u90e8\u5206\u5206\u548c\u5904\u7406\u903b\u8f91\u9519\u8bef\u65f6\u90fd\u4f9d\u8d56\u826f\u597d\u7684\u63d0\u793a\u5de5\u7a0b\u3002\u6b64\u5916\uff0c\u5408\u6210\u4ee3\u7801\u7684\u8bc4\u6d4b\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86AI\u6279\u6539\u7cfb\u7edf\u5728\u5404\u79cd\u9519\u8bef\u7c7b\u578b\u548c\u96be\u5ea6\u4e0b\u7684\u4e00\u81f4\u6027\u8868\u73b0\u3002", "conclusion": "\u4e24\u79cdAI\u8bc4\u5206\u65b9\u6cd5\u5404\u6709\u4f18\u7f3a\u70b9\u3002Direct\u6cd5\u5728\u6548\u7387\u4e0a\u4f18\u4e8eReverse\u6cd5\uff0c\u4f46\u7ec6\u81f4\u6027\u7565\u900a\u3002Reverse\u6cd5\u5173\u6ce8\u4fee\u6b63\u624b\u6bb5\uff0c\u5728\u5206\u6570\u7ec6\u5ea6\u4e0a\u66f4\u6709\u4f18\u52bf\u3002\u4e24\u8005\u90fd\u5bf9\u63d0\u793a\u8bbe\u8ba1\u6709\u8f83\u9ad8\u4f9d\u8d56\u3002\u672a\u6765\u53ef\u8003\u8651\u4eba\u673a\u6df7\u5408\u6a21\u5f0f\uff0c\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u6279\u6539\u7684\u516c\u5e73\u6027\u3001\u4e00\u81f4\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2511.14783", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.14783", "abs": "https://arxiv.org/abs/2511.14783", "authors": ["Bingquan Zhang", "Xiaoxiao Liu", "Yuchi Wang", "Lei Zhou", "Qianqian Xie", "Benyou Wang"], "title": "Human or LLM as Standardized Patients? A Comparative Study for Medical Education", "comment": "10 pages, 9 figures, 8 table", "summary": "Standardized Patients (SP) are indispensable for clinical skills training but remain expensive, inflexible, and difficult to scale. Existing large-language-model (LLM)-based SP simulators promise lower cost yet show inconsistent behavior and lack rigorous comparison with human SP. We present EasyMED, a multi-agent framework combining a Patient Agent for realistic dialogue, an Auxiliary Agent for factual consistency, and an Evaluation Agent that delivers actionable feedback. To support systematic assessment, we introduce SPBench, a benchmark of real SP-doctor interactions spanning 14 specialties and eight expert-defined evaluation criteria. Experiments demonstrate that EasyMED matches human SP learning outcomes while producing greater skill gains for lower-baseline students and offering improved flexibility, psychological safety, and cost efficiency.", "AI": {"tldr": "EasyMED\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e0e\u7cfb\u7edf\u6027\u8bc4\u4f30\u57fa\u51c6\uff0c\u5b9e\u73b0\u4e0e\u771f\u4eba\u6807\u51c6\u5316\u75c5\u4eba\u76f8\u5f53\u7684\u4e34\u5e8a\u8bad\u7ec3\u6548\u679c\uff0c\u5e76\u5728\u7075\u6d3b\u6027\u548c\u6210\u672c\u7b49\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5c24\u5176\u9002\u5408\u63d0\u5347\u57fa\u7840\u8f83\u5f31\u5b66\u751f\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u6807\u51c6\u5316\u75c5\u4eba\uff08SP\uff09\u5728\u4e34\u5e8a\u6280\u80fd\u8bad\u7ec3\u4e2d\u5fc5\u4e0d\u53ef\u5c11\uff0c\u4f46\u6210\u672c\u9ad8\u3001\u7075\u6d3b\u6027\u5dee\u3001\u96be\u4ee5\u5927\u89c4\u6a21\u5e94\u7528\u3002\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684SP\u6a21\u62df\u5668\u867d\u7136\u6210\u672c\u8f83\u4f4e\uff0c\u4f46\u8868\u73b0\u4e0d\u4e00\u81f4\u4e14\u7f3a\u4e4f\u4e0e\u771f\u4ebaSP\u7684\u7cfb\u7edf\u5bf9\u6bd4\u3002", "method": "\u63d0\u51faEasyMED\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u62ec\u60a3\u8005\u4ee3\u7406\u5b9e\u73b0\u771f\u5b9e\u5bf9\u8bdd\u3001\u8f85\u52a9\u4ee3\u7406\u4fdd\u969c\u4e8b\u5b9e\u4e00\u81f4\u6027\u3001\u8bc4\u4f30\u4ee3\u7406\u63d0\u4f9b\u53cd\u9988\uff1b\u540c\u65f6\u6784\u5efaSPBench\u57fa\u51c6\uff0c\u5305\u62ec14\u4e2a\u4e13\u4e1a\u9886\u57df\u548c8\u9879\u4e13\u5bb6\u5b9a\u4e49\u8bc4\u4f30\u6807\u51c6\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cEasyMED\u5728\u5b66\u4e60\u6210\u6548\u4e0a\u4e0e\u771f\u4ebaSP\u76f8\u5f53\uff0c\u4e14\u5bf9\u57fa\u7840\u8f83\u5f31\u5b66\u751f\u63d0\u5347\u66f4\u5927\uff0c\u5e76\u63d0\u9ad8\u4e86\u7075\u6d3b\u6027\u3001\u5fc3\u7406\u5b89\u5168\u6027\u548c\u6210\u672c\u6548\u7387\u3002", "conclusion": "EasyMED\u5177\u6709\u53ef\u66ff\u4ee3\u4f20\u7edfSP\u7684\u6f5c\u529b\uff0c\u65e2\u80fd\u8fbe\u5230\u540c\u7b49\u6559\u5b66\u6548\u679c\uff0c\u53c8\u517c\u5177\u6210\u672c\u548c\u89c4\u6a21\u4f18\u52bf\u3002"}}
{"id": "2511.14803", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14803", "abs": "https://arxiv.org/abs/2511.14803", "authors": ["Pranjal Gupta", "Karan Bhukar", "Harshit Kumar", "Seema Nagar", "Prateeti Mohapatra", "Debanjana Kar"], "title": "Scalable and Efficient Large-Scale Log Analysis with LLMs: An IT Software Support Case Study", "comment": null, "summary": "IT environments typically have logging mechanisms to monitor system health and detect issues. However, the huge volume of generated logs makes manual inspection impractical, highlighting the importance of automated log analysis in IT Software Support. In this paper, we propose a log analytics tool that leverages Large Language Models (LLMs) for log data processing and issue diagnosis, enabling the generation of automated insights and summaries. We further present a novel approach for efficiently running LLMs on CPUs to process massive log volumes in minimal time without compromising output quality. We share the insights and lessons learned from deployment of the tool - in production since March 2024 - scaled across 70 software products, processing over 2000 tickets for issue diagnosis, achieving a time savings of 300+ man hours and an estimated $15,444 per month in manpower costs compared to the traditional log analysis practices.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5e76\u5b9e\u9645\u90e8\u7f72\u4e86\u4e00\u79cd\u57fa\u4e8eLLMs\u7684\u65e5\u5fd7\u81ea\u52a8\u5206\u6790\u5de5\u5177\uff0c\u4e0d\u4ec5\u80fd\u9ad8\u6548\u5904\u7406\u6d77\u91cf\u65e5\u5fd7\u5e76\u51c6\u786e\u8bca\u65ad\u95ee\u9898\uff0c\u8fd8\u5728\u5927\u89c4\u6a21\u5b9e\u9645\u5e94\u7528\u4e2d\u663e\u8457\u8282\u7701\u4eba\u529b\u4e0e\u6210\u672c\uff0c\u5c55\u793a\u4e86LLMs\u5728IT\u8fd0\u7ef4\u81ea\u52a8\u5316\u4e2d\u7684\u5de8\u5927\u6f5c\u529b\u3002", "motivation": "\u4f20\u7edf\u65e5\u5fd7\u5206\u6790\u4f9d\u8d56\u4eba\u5de5\u68c0\u67e5\uff0c\u9762\u5bf9\u5de8\u91cf\u65e5\u5fd7\u6570\u636e\u65f6\u6548\u7387\u4f4e\u4e0b\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u3001\u667a\u80fd\u5316\u89e3\u51b3\u65b9\u6848\u4ee5\u63d0\u5347IT\u652f\u6301\u670d\u52a1\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u81ea\u52a8\u5904\u7406\u548c\u8bca\u65ad\u65e5\u5fd7\u6570\u636e\u7684\u65b0\u5de5\u5177\uff0c\u5e76\u521b\u65b0\u6027\u5730\u4f18\u5316LLMs\u5728CPU\u4e0a\u7684\u8fd0\u884c\uff0c\u5b9e\u73b0\u9ad8\u6548\u5927\u89c4\u6a21\u65e5\u5fd7\u5904\u7406\u3002", "result": "\u81ea2024\u5e743\u6708\u6295\u4ea7\u4ee5\u6765\uff0c\u5de5\u5177\u5df2\u572870\u6b3e\u8f6f\u4ef6\u4ea7\u54c1\u4e2d\u90e8\u7f72\uff0c\u5904\u74062000+\u6545\u969c\u5355\uff0c\u8282\u7701300+\u5de5\u65f6/\u6708\uff0c\u9884\u8ba1\u6bcf\u6708\u53ef\u8282\u7ea6\u4eba\u529b\u6210\u672c$15,444\u3002", "conclusion": "\u672c\u6587\u8bc1\u660e\u4e86\u901a\u8fc7\u5728CPU\u4e0a\u9ad8\u6548\u8fd0\u884cLLMs\u7684\u65e5\u5fd7\u5206\u6790\u5de5\u5177\uff0c\u5728\u5b9e\u9645IT\u8fd0\u7ef4\u4e2d\u80fd\u5927\u5e45\u63d0\u9ad8\u6548\u7387\u548c\u8282\u7701\u6210\u672c\u3002"}}
{"id": "2511.14796", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14796", "abs": "https://arxiv.org/abs/2511.14796", "authors": ["Adel Hidri", "Suleiman Ali Alsaif", "Muteeb Alahmari", "Eman AlShehri", "Minyar Sassi Hidri"], "title": "Opinion Mining and Analysis Using Hybrid Deep Neural Networks", "comment": "22 pages, 4 figures, 11 tables", "summary": "Understanding customer attitudes has become a critical component of decision-making due to the growing influence of social media and e-commerce. Text-based opinions are the most structured, hence playing an important role in sentiment analysis. Most of the existing methods, which include lexicon-based approaches and traditional machine learning techniques, are insufficient for handling contextual nuances and scalability. While the latter has limitations in model performance and generalization, deep learning (DL) has achieved improvement, especially on semantic relationship capturing with recurrent neural networks (RNNs) and convolutional neural networks (CNNs). The aim of the study is to enhance opinion mining by introducing a hybrid deep neural network model that combines a bidirectional gated recurrent unit (BGRU) and long short-term memory (LSTM) layers to improve sentiment analysis, particularly addressing challenges such as contextual nuance, scalability, and class imbalance. To substantiate the efficacy of the proposed model, we conducted comprehensive experiments utilizing benchmark datasets, encompassing IMDB movie critiques and Amazon product evaluations. The introduced hybrid BGRULSTM (HBGRU-LSTM) architecture attained a testing accuracy of 95%, exceeding the performance of traditional DL frameworks such as LSTM (93.06%), CNN+LSTM (93.31%), and GRU+LSTM (92.20%). Moreover, our model exhibited a noteworthy enhancement in recall for negative sentiments, escalating from 86% (unbalanced dataset) to 96% (balanced dataset), thereby ensuring a more equitable and just sentiment classification. Furthermore, the model diminished misclassification loss from 20.24% for unbalanced to 13.3% for balanced dataset, signifying enhanced generalization and resilience.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u60c5\u611f\u5206\u6790\u96be\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u7ed3\u5408BGRU\u548cLSTM\u7684\u6df7\u5408\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u7387\u8fbe95%\uff0c\u660e\u663e\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86\u8d1f\u9762\u60c5\u611f\u7684\u53ec\u56de\u7387\u548c\u6a21\u578b\u9c81\u68d2\u6027\u3002", "motivation": "\u7531\u4e8e\u793e\u4ea4\u5a92\u4f53\u548c\u7535\u5b50\u5546\u52a1\u7684\u5f71\u54cd\u65e5\u76ca\u589e\u5f3a\uff0c\u4e86\u89e3\u5ba2\u6237\u6001\u5ea6\u5df2\u6210\u4e3a\u51b3\u7b56\u7684\u91cd\u8981\u73af\u8282\u3002\u73b0\u6709\u7684\u60c5\u611f\u5206\u6790\u65b9\u6cd5\uff08\u5305\u62ec\u8bcd\u5178\u6cd5\u548c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6280\u672f\uff09\u96be\u4ee5\u5904\u7406\u6587\u672c\u7684\u4e0a\u4e0b\u6587\u7ec6\u5fae\u5dee\u5f02\u53ca\u5927\u89c4\u6a21\u6570\u636e\uff0c\u6df1\u5ea6\u5b66\u4e60\u80fd\u591f\u66f4\u597d\u6355\u6349\u8bed\u4e49\u5173\u7cfb\uff0c\u4f46\u4ecd\u9762\u4e34\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6df7\u5408\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u5c06\u53cc\u5411\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08BGRU\uff09\u548c\u957f\u77ed\u65f6\u8bb0\u5fc6\u7f51\u7edc\uff08LSTM\uff09\u7ed3\u5408\uff0c\u7528\u4e8e\u63d0\u5347\u60c5\u611f\u5206\u6790\u7684\u6548\u679c\uff0c\u5c24\u5176\u5728\u4e0a\u4e0b\u6587\u7ec6\u8282\u3001\u6570\u636e\u89c4\u6a21\u6269\u5c55\u548c\u7c7b\u522b\u4e0d\u5747\u8861\u65b9\u9762\u8fdb\u884c\u6539\u8fdb\u3002\u5e76\u5728IMDB\u7535\u5f71\u8bc4\u8bba\u548c\u4e9a\u9a6c\u900a\u4ea7\u54c1\u8bc4\u4ef7\u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u8be5\u6df7\u5408\u6a21\u578bHBGRU-LSTM\u5728\u6d4b\u8bd5\u96c6\u4e0a\u83b7\u5f9795%\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u5982LSTM 93.06%\u3001CNN+LSTM 93.31%\u3001GRU+LSTM 92.20%\uff09\u3002\u5bf9\u4e8e\u8d1f\u9762\u60c5\u611f\u8bc6\u522b\uff0c\u53ec\u56de\u7387\u4ece\u4e0d\u5e73\u8861\u6570\u636e\u768486%\u63d0\u5347\u81f3\u5e73\u8861\u6570\u636e\u768496%\uff0c\u663e\u8457\u6539\u5584\u4e86\u5206\u7c7b\u516c\u5e73\u6027\u3002\u6a21\u578b\u8bef\u5206\u7c7b\u635f\u5931\u4ece20.24%\uff08\u4e0d\u5e73\u8861\uff09\u964d\u81f313.3%\uff08\u5e73\u8861\uff09\uff0c\u63d0\u5347\u4e86\u6cdb\u5316\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684HBGRU-LSTM\u6df7\u5408\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u5728\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u7279\u522b\u662f\u5728\u4e0a\u4e0b\u6587\u7406\u89e3\u3001\u7c7b\u522b\u5747\u8861\u4e0e\u6a21\u578b\u6cdb\u5316\u65b9\u9762\u5177\u5907\u663e\u8457\u4f18\u52bf\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2511.14805", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14805", "abs": "https://arxiv.org/abs/2511.14805", "authors": ["Dhaminda B. Abeywickrama", "Michael Fisher", "Frederic Wheeler", "Louise Dennis"], "title": "Towards Continuous Assurance with Formal Verification and Assurance Cases", "comment": "15 pages, 7 figures", "summary": "Autonomous systems must sustain justified confidence in their correctness and safety across their operational lifecycle-from design and deployment through post-deployment evolution. Traditional assurance methods often separate development-time assurance from runtime assurance, yielding fragmented arguments that cannot adapt to runtime changes or system updates - a significant challenge for assured autonomy. Towards addressing this, we propose a unified Continuous Assurance Framework that integrates design-time, runtime, and evolution-time assurance within a traceable, model-driven workflow as a step towards assured autonomy. In this paper, we specifically instantiate the design-time phase of the framework using two formal verification methods: RoboChart for functional correctness and PRISM for probabilistic risk analysis. We also propose a model-driven transformation pipeline, implemented as an Eclipse plugin, that automatically regenerates structured assurance arguments whenever formal specifications or their verification results change, thereby ensuring traceability. We demonstrate our approach on a nuclear inspection robot scenario, and discuss its alignment with the Trilateral AI Principles, reflecting regulator-endorsed best practices.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6301\u7eed\u4fdd\u969c\u6846\u67b6\uff0c\u5c06\u5f62\u5f0f\u5316\u9a8c\u8bc1\u4e0e\u98ce\u9669\u5206\u6790\u65b9\u6cd5\u6574\u5408\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u5de5\u5177\u5b9e\u73b0\u8bba\u8bc1\u7684\u8ffd\u6eaf\u4e0e\u6301\u7eed\u66f4\u65b0\uff0c\u5e76\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027\uff0c\u4e3a\u63d0\u5347\u81ea\u4e3b\u7cfb\u7edf\u5b89\u5168\u6027\u548c\u5408\u89c4\u6027\u63d0\u4f9b\u65b0\u601d\u8def\u3002", "motivation": "\u5f53\u524d\u81ea\u4e3b\u7cfb\u7edf\u5728\u6574\u4e2a\u751f\u547d\u5468\u671f\u5185\u4fdd\u6301\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\u65f6\uff0c\u4f20\u7edf\u4fdd\u969c\u65b9\u6cd5\u5b58\u5728\u5206\u5272\u5f00\u53d1\u4e0e\u8fd0\u884c\u65f6\u4fdd\u969c\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u4fdd\u8bc1\u8bba\u8bc1\u4e0d\u6613\u9002\u5e94\u7cfb\u7edf\u8fd0\u884c\u65f6\u53d8\u5316\u6216\u66f4\u65b0\uff0c\u5f71\u54cd\u81ea\u4e3b\u7cfb\u7edf\u7684\u53ef\u4fe1\u6027\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6301\u7eed\u4fdd\u969c\u6846\u67b6\uff0c\u5c06\u8bbe\u8ba1\u65f6\u3001\u8fd0\u884c\u65f6\u548c\u6f14\u5316\u65f6\u7684\u4fdd\u969c\u7ed3\u5408\u5728\u53ef\u8ffd\u6eaf\u3001\u6a21\u578b\u9a71\u52a8\u7684\u6d41\u7a0b\u5185\u3002\u8bbe\u8ba1\u65f6\u90e8\u5206\u7ed3\u5408\u4e86RoboChart\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff08\u529f\u80fd\u6b63\u786e\u6027\uff09\u4e0ePRISM\u6982\u7387\u98ce\u9669\u5206\u6790\u65b9\u6cd5\uff0c\u540c\u65f6\u7814\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eEclipse\u63d2\u4ef6\u7684\u6a21\u578b\u9a71\u52a8\u8f6c\u6362\u7ba1\u9053\uff0c\u53ef\u968f\u65f6\u81ea\u52a8\u751f\u6210\u7ed3\u6784\u5316\u7684\u4fdd\u969c\u8bba\u8bc1\uff0c\u5b9e\u73b0\u6301\u7eed\u8ffd\u8e2a\u3002", "result": "\u5728\u6838\u67e5\u673a\u5668\u4eba\u573a\u666f\u4e0b\u5e94\u7528\u8be5\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u80fd\u591f\u81ea\u52a8\u8ffd\u8e2a\u548c\u66f4\u65b0\u4fdd\u969c\u8bba\u8bc1\uff0c\u5e76\u4e0eTrilateral AI Principles\u7b49\u76d1\u7ba1\u6700\u4f73\u5b9e\u8df5\u76f8\u5951\u5408\u3002", "conclusion": "\u6301\u7eed\u4fdd\u969c\u6846\u67b6\u80fd\u591f\u5728\u8bbe\u8ba1\u3001\u8fd0\u884c\u548c\u6f14\u5316\u5404\u9636\u6bb5\u5b9e\u73b0\u53ef\u4fe1\u3001\u53ef\u8ffd\u6eaf\u3001\u81ea\u52a8\u5316\u7684\u4fdd\u969c\u8bba\u8bc1\uff0c\u63d0\u5347\u81ea\u4e3b\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u4e0e\u53ef\u4fe1\u5ea6\uff0c\u5177\u5907\u826f\u597d\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.14868", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14868", "abs": "https://arxiv.org/abs/2511.14868", "authors": ["Xueying Ding", "Xingyue Huang", "Mingxuan Ju", "Liam Collins", "Yozen Liu", "Leman Akoglu", "Neil Shah", "Tong Zhao"], "title": "Hierarchical Token Prepending: Enhancing Information Flow in Decoder-based LLM Embeddings", "comment": null, "summary": "Large language models produce powerful text embeddings, but their causal attention mechanism restricts the flow of information from later to earlier tokens, degrading representation quality. While recent methods attempt to solve this by prepending a single summary token, they over-compress information, hence harming performance on long documents. We propose Hierarchical Token Prepending (HTP), a method that resolves two critical bottlenecks. To mitigate attention-level compression, HTP partitions the input into blocks and prepends block-level summary tokens to subsequent blocks, creating multiple pathways for backward information flow. To address readout-level over-squashing, we replace last-token pooling with mean-pooling, a choice supported by theoretical analysis. HTP achieves consistent performance gains across 11 retrieval datasets and 30 general embedding benchmarks, especially in long-context settings. As a simple, architecture-agnostic method, HTP enhances both zero-shot and finetuned models, offering a scalable route to superior long-document embeddings.", "AI": {"tldr": "HTP\u901a\u8fc7\u5206\u5757\u6dfb\u52a0summary token\u548c\u5747\u503c\u6c60\u5316\uff0c\u89e3\u51b3\u4e86\u957f\u6587\u6863\u5d4c\u5165\u4e2d\u7684\u4fe1\u606f\u6d41\u53d7\u9650\u548c\u538b\u7f29\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u53d6\u5f97\u8868\u73b0\u63d0\u5347\uff0c\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5404\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u5d4c\u5165\u65b9\u9762\u8868\u73b0\u5f3a\u5927\uff0c\u4f46\u57fa\u4e8e\u56e0\u679c\u6ce8\u610f\u529b\u673a\u5236\u5bfc\u81f4\u4fe1\u606f\u65e0\u6cd5\u4ece\u540e\u5411\u524d\u4f20\u64ad\uff0c\u964d\u4f4e\u4e86\u957f\u6587\u672c\u7684\u8868\u793a\u8d28\u91cf\u3002\u73b0\u6709\u65b9\u6cd5\u5982\u6dfb\u52a0\u5355\u4e2a\u603b\u7ed3token\u4f1a\u8fc7\u5ea6\u538b\u7f29\u4fe1\u606f\uff0c\u5bfc\u81f4\u957f\u6587\u6863\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u5206\u5c42token\u524d\u7f6e\u6cd5\uff08Hierarchical Token Prepending, HTP\uff09\uff0c\u5c06\u8f93\u5165\u5212\u5206\u4e3a\u591a\u4e2a\u5206\u5757\uff0c\u5e76\u5728\u6bcf\u4e2a\u5206\u5757\u524d\u52a0\u4e0a\u5757\u7ea7summary token\uff0c\u5efa\u7acb\u591a\u6761\u4fe1\u606f\u53cd\u5411\u6d41\u901a\u8def\u5f84\u3002\u540c\u65f6\u7528\u5747\u503c\u6c60\u5316(mean-pooling)\u66ff\u6362\u6700\u540e\u4e00token\u6c60\u5316\uff0c\u907f\u514d\u4fe1\u606f\u8fc7\u5ea6\u6324\u538b\uff0c\u5e76\u7ecf\u8fc7\u7406\u8bba\u5206\u6790\u652f\u6301\u3002", "result": "\u572811\u4e2a\u68c0\u7d22\u6570\u636e\u96c6\u548c30\u4e2a\u901a\u7528\u5d4c\u5165\u57fa\u51c6\u4e0a\uff0cHTP\u5747\u5e26\u6765\u4e00\u81f4\u6027\u80fd\u63d0\u5347\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u8868\u73b0\u663e\u8457\u3002\u5bf9\u96f6\u6837\u672c\u548c\u5fae\u8c03\u6a21\u578b\u90fd\u6709\u6548\uff0c\u5e76\u4e14\u65e0\u9700\u66f4\u6539\u539f\u6709\u67b6\u6784\uff0c\u65b9\u6cd5\u7b80\u5355\u53ef\u6269\u5c55\u3002", "conclusion": "HTP\u65b9\u6cd5\u6709\u6548\u7f13\u89e3\u4e86\u957f\u6587\u6863\u8868\u793a\u4e2d\u7684\u4fe1\u606f\u4f20\u64ad\u548c\u538b\u7f29\u74f6\u9888\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u6587\u672c\u5d4c\u5165\u8868\u73b0\uff0c\u4e3a\u957f\u6587\u6863\u4efb\u52a1\u5e26\u6765\u5207\u5b9e\u63d0\u5347\u3002"}}
{"id": "2511.14825", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.14825", "abs": "https://arxiv.org/abs/2511.14825", "authors": ["Alexandre-Xavier Labont\u00e9-Lamoureux", "Simon Boyer"], "title": "Automatic Pipeline Provisioning", "comment": null, "summary": "The goal of this paper is to explore the benefits of automatic pipeline provisioning and identify how it can be applied. Automatic pipeline provisioning can be defined as a process of quickly deploying a pipeline for a software engineering project. This research will focus on CI pipelines, although the outcomes of this approach on CD pipelines will likely be similar.", "AI": {"tldr": "\u672c\u8bba\u6587\u5206\u6790\u4e86\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\u914d\u7f6e\u7684\u4f18\u52bf\uff0c\u91cd\u70b9\u5173\u6ce8CI\u6d41\u7a0b\uff0c\u5bf9CD\u6d41\u7a0b\u4e5f\u6709\u4e00\u5b9a\u53c2\u8003\u4ef7\u503c\u3002\u81ea\u52a8\u90e8\u7f72\u6709\u52a9\u4e8e\u63d0\u5347\u8f6f\u4ef6\u5f00\u53d1\u6548\u7387\u3002", "motivation": "\u672c\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\u914d\u7f6e\u7684\u4f18\u52bf\uff0c\u4ee5\u53ca\u5176\u5e94\u7528\u573a\u666f\uff0c\u4ee5\u63d0\u5347\u8f6f\u4ef6\u5de5\u7a0b\u9879\u76ee\u4e2d\u7684\u5f00\u53d1\u6548\u7387\u3002", "method": "\u805a\u7126\u4e8eCI\uff08\u6301\u7eed\u96c6\u6210\uff09\u6d41\u6c34\u7ebf\uff0c\u5e76\u901a\u8fc7\u5206\u6790\u81ea\u52a8\u5316\u90e8\u7f72\u6d41\u7a0b\uff0c\u8bc4\u4f30\u81ea\u52a8\u5316\u914d\u7f6e\u7684\u6548\u679c\u3002", "result": "\u7814\u7a76\u4e3b\u8981\u9488\u5bf9CI\u6d41\u6c34\u7ebf\uff0c\u4f46\u7ed3\u679c\u53ef\u80fd\u540c\u6837\u9002\u7528\u4e8eCD\uff08\u6301\u7eed\u4ea4\u4ed8\uff09\u6d41\u6c34\u7ebf\u3002\u5f3a\u8c03\u81ea\u52a8\u5316\u5feb\u901f\u90e8\u7f72\u5bf9\u5f00\u53d1\u6d41\u7a0b\u7684\u79ef\u6781\u5f71\u54cd\u3002", "conclusion": "\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\u914d\u7f6e\u80fd\u591f\u6709\u6548\u63d0\u5347\u8f6f\u4ef6\u9879\u76ee\u7684\u5f00\u53d1\u6548\u7387\uff0c\u76f8\u5173\u6210\u679c\u53ef\u63a8\u5e7f\u81f3\u6301\u7eed\u4ea4\u4ed8\u573a\u666f\u3002"}}
{"id": "2511.15005", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15005", "abs": "https://arxiv.org/abs/2511.15005", "authors": ["Moses Kiprono"], "title": "Mathematical Analysis of Hallucination Dynamics in Large Language Models: Uncertainty Quantification, Advanced Decoding, and Principled Mitigation", "comment": "10 pages, theoretical/mathematical LLM research, no figures, intended for peer-reviewed journal", "summary": "Large Language Models (LLMs) are powerful linguistic engines but remain susceptible to hallucinations: plausible-sounding outputs that are factually incorrect or unsupported. In this work, we present a mathematically grounded framework to understand, measure, and mitigate these hallucinations. Drawing on probabilistic modeling, information theory, trigonometric signal analysis, and Bayesian uncertainty estimation, we analyze how errors compound autoregressively, propose refined uncertainty metrics, including semantic and phase-aware variants, and develop principled mitigation strategies such as contrastive decoding, retrieval-augmented grounding, factual alignment, and abstention. This unified lens connects recent advances in calibration, retrieval, and alignment to support safer and more reliable LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u6570\u5b66\u7406\u8bba\u7684LLMs\u5e7b\u89c9\u7406\u89e3\u4e0e\u7f13\u89e3\u7edf\u4e00\u6846\u67b6\uff0c\u5c06\u591a\u9879\u6700\u65b0\u624b\u6bb5\u8fde\u63a5\u8d77\u6765\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u7684\u5b89\u5168\u53ef\u9760\u6027\u3002", "motivation": "\u5c3d\u7ba1LLMs\u8868\u73b0\u5f3a\u5927\uff0c\u4f46\u5e7b\u89c9\uff08\u865a\u5047\u6216\u65e0\u6839\u636e\u7684\u8f93\u51fa\uff09\u4f9d\u7136\u7a81\u51fa\uff0c\u4e9f\u9700\u7406\u8bba\u652f\u6491\u548c\u6709\u6548\u89e3\u51b3\u65b9\u5f0f\u3002", "method": "\u91c7\u7528\u6982\u7387\u5efa\u6a21\u3001\u4fe1\u606f\u8bba\u3001\u4e09\u89d2\u4fe1\u53f7\u5206\u6790\u548c\u8d1d\u53f6\u65af\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u5206\u6790\u6a21\u578b\u9519\u8bef\u5982\u4f55\u81ea\u56de\u5f52\u7d2f\u79ef\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u7684\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\uff0c\u5305\u62ec\u8bed\u4e49\u548c\u76f8\u4f4d\u611f\u77e5\u7b49\u65b0\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u89e3\u51b3\u5e7b\u89c9\u7684\u7b56\u7565\uff0c\u5982\u5bf9\u6bd4\u89e3\u7801\u3001\u68c0\u7d22\u589e\u5f3a\u3001\u4e8b\u5b9e\u5bf9\u9f50\u548c\u62d2\u7b54\u673a\u5236\u3002", "result": "\u901a\u8fc7\u8be5\u6846\u67b6\uff0c\u5206\u6790\u4e86\u5e7b\u89c9\u4ea7\u751f\u673a\u5236\uff0c\u63d0\u51fa\u4e86\u65b0\u578b\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u548c\u4e00\u7cfb\u5217\u6709\u6548\u7684\u7f13\u89e3\u624b\u6bb5\uff0c\u5c06\u6821\u51c6\u3001\u68c0\u7d22\u548c\u5bf9\u9f50\u76f8\u5173\u8fdb\u5c55\u8fdb\u884c\u7edf\u4e00\uff0c\u5b9e\u8bc1\u4e0a\u63d0\u5347\u4e86LLMs\u7684\u5b89\u5168\u6027\u4e0e\u53ef\u9760\u6027\u3002", "conclusion": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u6570\u5b66\u5316\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u548c\u7f13\u89e3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5e7b\u89c9\u95ee\u9898\uff0c\u652f\u6301\u66f4\u5b89\u5168\u3001\u66f4\u53ef\u9760\u7684LLMs\u3002"}}
{"id": "2511.14967", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14967", "abs": "https://arxiv.org/abs/2511.14967", "authors": ["Basel Shbita", "Farhan Ahmed", "Chad DeLuca"], "title": "MermaidSeqBench: An Evaluation Benchmark for LLM-to-Mermaid Sequence Diagram Generation", "comment": null, "summary": "Large language models (LLMs) have demonstrated excellent capabilities in generating structured diagrams from natural language descriptions. In particular, they have shown great promise in generating sequence diagrams for software engineering, typically represented in a text-based syntax such as Mermaid. However, systematic evaluations in this space remain underdeveloped as there is a lack of existing benchmarks to assess the LLM's correctness in this task. To address this shortcoming, we introduce MermaidSeqBench, a human-verified and LLM-synthetically-extended benchmark for assessing an LLM's capabilities in generating Mermaid sequence diagrams from textual prompts. The benchmark consists of a core set of 132 samples, starting from a small set of manually crafted and verified flows. These were expanded via a hybrid methodology combining human annotation, in-context LLM prompting, and rule-based variation generation. Our benchmark uses an LLM-as-a-judge model to assess Mermaid sequence diagram generation across fine-grained metrics, including syntax correctness, activation handling, error handling, and practical usability. We perform initial evaluations on numerous state-of-the-art LLMs and utilize multiple LLM judge models to demonstrate the effectiveness and flexibility of our benchmark. Our results reveal significant capability gaps across models and evaluation modes. Our proposed benchmark provides a foundation for advancing research in structured diagram generation and for developing more rigorous, fine-grained evaluation methodologies.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5e8f\u5217\u56fe\u751f\u6210\u8bc4\u6d4b\u57fa\u51c6\uff0c\u5e76\u5b9e\u6d4b\u591a\u6b3e\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u63ed\u793a\u5f53\u524d\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e0a\u7684\u4e0d\u8db3\uff0c\u4e3a\u540e\u7eed\u76f8\u5173\u7814\u7a76\u548c\u8bc4\u6d4b\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5e8f\u5217\u56fe\u51c6\u786e\u6027\u7684\u57fa\u51c6\uff0c\u56e0\u6b64\u9700\u8981\u6784\u5efa\u65b0\u7684\u8bc4\u6d4b\u4f53\u7cfb\u3002", "method": "\u63d0\u51fa\u4e86MermaidSeqBench\uff0c\u4e00\u4e2a\u901a\u8fc7\u4eba\u5de5\u6821\u9a8c\u4e0eLLM\u6269\u5c55\u751f\u6210\u7684\u8bc4\u6d4b\u96c6\uff0c\u7ed3\u5408\u4eba\u7c7b\u6ce8\u91ca\u3001\u4e0a\u4e0b\u6587LLM\u63d0\u793a\u548c\u89c4\u5219\u53d8\u5316\u751f\u6210\u6d41\u7a0b\uff0c\u91c7\u7528LLM Judge\u6a21\u578b\u8bc4\u4f30\u751f\u6210\u7684Mermaid\u5e8f\u5217\u56fe\u5728\u591a\u7ef4\u7ec6\u7c92\u5ea6\u6307\u6807\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u5bf9\u591a\u79cd\u4e3b\u6d41LLM\u8fdb\u884c\u8bc4\u4f30\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u751f\u6210\u7ed3\u6784\u5316\u56fe\u8868\u4efb\u52a1\u4e0a\u5b58\u5728\u663e\u8457\u80fd\u529b\u5dee\u8ddd\uff0c\u8bc1\u660e\u4e86\u6240\u5efa\u57fa\u51c6\u7684\u6709\u6548\u6027\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "\u8be5\u57fa\u51c6\u4e3a\u63a8\u52a8\u7ed3\u6784\u5316\u56fe\u8868\u751f\u6210\u9886\u57df\u7684\u7814\u7a76\u53ca\u66f4\u7ec6\u81f4\u4e25\u8c28\u7684\u8bc4\u6d4b\u65b9\u6cd5\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.15163", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.15163", "abs": "https://arxiv.org/abs/2511.15163", "authors": ["Yang Wu", "Rujing Yao", "Tong Zhang", "Yufei Shi", "Zhuoren Jiang", "Zhushan Li", "Xiaozhong Liu"], "title": "Teaching According to Students' Aptitude: Personalized Mathematics Tutoring via Persona-, Memory-, and Forgetting-Aware LLMs", "comment": "AAAI 2026 Workshop", "summary": "Large Language Models (LLMs) are increasingly integrated into intelligent tutoring systems to provide human-like and adaptive instruction. However, most existing approaches fail to capture how students' knowledge evolves dynamically across their proficiencies, conceptual gaps, and forgetting patterns. This challenge is particularly acute in mathematics tutoring, where effective instruction requires fine-grained scaffolding precisely calibrated to each student's mastery level and cognitive retention. To address this issue, we propose TASA (Teaching According to Students' Aptitude), a student-aware tutoring framework that integrates persona, memory, and forgetting dynamics for personalized mathematics learning. Specifically, TASA maintains a structured student persona capturing proficiency profiles and an event memory recording prior learning interactions. By incorporating a continuous forgetting curve with knowledge tracing, TASA dynamically updates each student's mastery state and generates contextually appropriate, difficulty-calibrated questions and explanations. Empirical results demonstrate that TASA achieves superior learning outcomes and more adaptive tutoring behavior compared to representative baselines, underscoring the importance of modeling temporal forgetting and learner profiles in LLM-based tutoring systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u7ed3\u5408\u5b66\u751f\u753b\u50cf\u3001\u8bb0\u5fc6\u53ca\u9057\u5fd8\u52a8\u6001\u7684\u4e2a\u6027\u5316\u6570\u5b66\u8f85\u5bfc\u6846\u67b6TASA\uff0c\u5728\u751f\u6210\u9002\u5e94\u6027\u5f3a\u7684\u6559\u5b66\u5185\u5bb9\u548c\u5b66\u4e60\u6548\u679c\u4e0a\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u51f8\u663e\u4e86\u7efc\u5408\u5b66\u751f\u7279\u5f81\u548c\u65f6\u95f4\u9057\u5fd8\u5efa\u6a21\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73b0\u6709LLM\u9a71\u52a8\u7684\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u96be\u4ee5\u7cbe\u51c6\u6355\u6349\u5b66\u751f\u77e5\u8bc6\u7684\u52a8\u6001\u53d8\u5316\uff0c\u5c24\u5176\u5728\u6570\u5b66\u6559\u5b66\u4e2d\uff0c\u5bf9\u6bcf\u4e2a\u5b66\u751f\u7684\u638c\u63e1\u6c34\u5e73\u53ca\u9057\u5fd8\u6a21\u5f0f\u8fdb\u884c\u7ec6\u81f4\u628a\u63a7\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86TASA\u6846\u67b6\uff0c\u6574\u5408\u5b66\u751f\u753b\u50cf\u3001\u5b66\u4e60\u8bb0\u5fc6\u548c\u9057\u5fd8\u52a8\u6001\uff0c\u901a\u8fc7\u6301\u7eed\u66f4\u65b0\u5b66\u751f\u638c\u63e1\u72b6\u6001\uff0c\u7ed3\u5408\u77e5\u8bc6\u8ffd\u8e2a\u673a\u5236\uff0c\u751f\u6210\u4e2a\u6027\u5316\u4e14\u96be\u5ea6\u9002\u914d\u7684\u95ee\u9898\u4e0e\u89e3\u91ca\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cTASA\u5728\u5b66\u4e60\u6548\u679c\u548c\u81ea\u9002\u5e94\u8f85\u5bfc\u884c\u4e3a\u4e0a\u4f18\u4e8e\u4e3b\u6d41\u65b9\u6cd5\u3002", "conclusion": "\u5728LLM\u8f85\u5bfc\u7cfb\u7edf\u4e2d\uff0c\u7ed3\u5408\u9057\u5fd8\u65f6\u95f4\u52a8\u6001\u548c\u5b66\u751f\u753b\u50cf\uff0c\u5bf9\u4e8e\u63d0\u5347\u6559\u5b66\u4e2a\u6027\u5316\u548c\u6709\u6548\u6027\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.15007", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15007", "abs": "https://arxiv.org/abs/2511.15007", "authors": ["Shehan I Pranto", "Brett Fassler", "Md Rafi Islam", "Ashley Schenkel", "Larry W Hawk", "Edward Sazonov"], "title": "FRIENDS GUI: A graphical user interface for data collection and visualization of vaping behavior from a passive vaping monitor", "comment": null, "summary": "Understanding puffing topography (PT), which includes puff duration, intra puff interval, and puff count per session, is critical for evaluating Electronic Nicotine Delivery Systems (ENDS) use, toxicant exposure, and informing regulatory decisions. We developed FRIENDS (Flexible Robust Instrumentation of ENDS), an open-source device that records puffing and touch events of ENDS by attaching to it. This paper introduces the FRIENDS GUI that improves accessibility and interpretability of data collected by FRIENDS. The GUI is a Python-based open-source tool that extracts, decodes, and visualizes 24-hour puffing data from the FRIENDS device. Validation using 24-hour experimental data confirmed accurate timestamp conversion, reliable event decoding, and effective behavioral visualization. The software is freely available on GitHub for public use.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u5e76\u9a8c\u8bc1\u4e86\u4e00\u4e2a\u5f00\u6e90Python\u5de5\u5177\uff08FRIENDS GUI\uff09\uff0c\u53ef\u7cbe\u51c6\u63d0\u53d6\u3001\u89e3\u7801\u5e76\u53ef\u89c6\u5316\u7535\u5b50\u70df\u7528\u6237\u768424\u5c0f\u65f6\u5438\u70df\u4e60\u60ef\u6570\u636e\uff0c\u63d0\u5347\u4e86\u6570\u636e\u89e3\u8bfb\u7684\u4fbf\u6377\u6027\u548c\u79d1\u5b66\u6027\uff0c\u5df2\u514d\u8d39\u5f00\u653e\u4e0b\u8f7d\u3002", "motivation": "\u4e86\u89e3\u5438\u7535\u5b50\u70df\u7684\u4e60\u60ef\uff08\u5982\u6bcf\u6b21\u5438\u70df\u65f6\u957f\u3001\u95f4\u9694\u548c\u6b21\u6570\uff09\u5bf9\u4e8e\u8bc4\u4f30\u4f7f\u7528\u60c5\u51b5\u3001\u6bd2\u7269\u66b4\u9732\u53ca\u76d1\u7ba1\u51b3\u7b56\u975e\u5e38\u91cd\u8981\u3002\u73b0\u6709\u7684\u6570\u636e\u8bb0\u5f55\u5de5\u5177\u5728\u6570\u636e\u5904\u7406\u4e0e\u89e3\u91ca\u4e0a\u5b58\u5728\u96be\u9898\uff0c\u4e9f\u9700\u66f4\u65b9\u4fbf\u6613\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86FRIENDS\uff08Flexible Robust Instrumentation of ENDS\uff09\u8fd9\u4e00\u5f00\u6e90\u88c5\u7f6e\uff0c\u53ef\u8bb0\u5f55\u7535\u5b50\u70df\u7684\u5438\u70df\u53ca\u89e6\u78b0\u4e8b\u4ef6\u3002\u672c\u6587\u8fdb\u4e00\u6b65\u4ecb\u7ecd\u4e86FRIENDS\u7684\u56fe\u5f62\u7528\u6237\u754c\u9762\uff08GUI\uff09\uff0c\u8be5\u754c\u9762\u57fa\u4e8ePython\u5f00\u53d1\uff0c\u80fd\u591f\u63d0\u53d6\u3001\u89e3\u7801\u5e76\u53ef\u89c6\u531624\u5c0f\u65f6\u7684\u5438\u70df\u6570\u636e\uff0c\u5e76\u5bf9\u5176\u5b9e\u9a8c\u6709\u6548\u6027\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "result": "\u901a\u8fc724\u5c0f\u65f6\u5b9e\u9a8c\u6570\u636e\u9a8c\u8bc1\uff0c\u8be5GUI\u5de5\u5177\u5b9e\u73b0\u4e86\u51c6\u786e\u7684\u65f6\u95f4\u6233\u8f6c\u6362\u3001\u53ef\u9760\u7684\u4e8b\u4ef6\u89e3\u7801\uff0c\u4ee5\u53ca\u6709\u6548\u7684\u884c\u4e3a\u53ef\u89c6\u5316\u3002\u8be5\u8f6f\u4ef6\u5df2\u5728GitHub\u4e0a\u5f00\u6e90\uff0c\u4f9b\u516c\u4f17\u514d\u8d39\u4f7f\u7528\u3002", "conclusion": "FRIENDS GUI\u6781\u5927\u63d0\u5347\u4e86\u7535\u5b50\u70df\u5438\u70df\u6570\u636e\u7684\u53ef\u83b7\u53d6\u6027\u4e0e\u89e3\u91ca\u6027\uff0c\u4e3a\u6bd2\u7269\u66b4\u9732\u8bc4\u4f30\u548c\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2511.15183", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.15183", "abs": "https://arxiv.org/abs/2511.15183", "authors": ["Rishikant Chigrupaatii", "Ponnada Sai Tulasi Kanishka", "Lalit Chandra Routhu", "Martin Patel Sama Supratheek Reddy", "Divyam Gupta", "Dasari Srikar", "Krishna Teja Kuchimanchi", "Rajiv Misra", "Rohun Tripathi"], "title": "HinTel-AlignBench: A Framework and Benchmark for Hindi-Telugu with English-Aligned Samples", "comment": null, "summary": "With nearly 1.5 billion people and more than 120 major languages, India represents one of the most diverse regions in the world. As multilingual Vision-Language Models (VLMs) gain prominence, robust evaluation methodologies are essential to drive progress toward equitable AI for low-resource languages. Current multilingual VLM evaluations suffer from four major limitations: reliance on unverified auto-translations, narrow task/domain coverage, limited sample sizes, and lack of cultural and natively sourced Question-Answering (QA). To address these gaps, we present a scalable framework to evaluate VLMs in Indian languages and compare it with performance in English. Using the framework, we generate HinTel-AlignBench, a benchmark that draws from diverse sources in Hindi and Telugu with English-aligned samples. Our contributions are threefold: (1) a semi-automated dataset creation framework combining back-translation, filtering, and human verification; (2) the most comprehensive vision-language benchmark for Hindi and and Telugu, including adapted English datasets (VQAv2, RealWorldQA, CLEVR-Math) and native novel Indic datasets (JEE for STEM, VAANI for cultural grounding) with approximately 4,000 QA pairs per language; and (3) a detailed performance analysis of various State-of-the-Art (SOTA) open-weight and closed-source VLMs. We find a regression in performance for tasks in English versus in Indian languages for 4 out of 5 tasks across all the models, with an average regression of 8.3 points in Hindi and 5.5 points for Telugu. We categorize common failure modes to highlight concrete areas of improvement in multilingual multimodal understanding.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9762\u5411\u5370\u5ea6\u4e3b\u8981\u4f4e\u8d44\u6e90\u8bed\u8a00VLM\u8bc4\u6d4b\u7684\u7cfb\u7edf\u6846\u67b6\u4e0e\u6570\u636e\u96c6\uff0c\u63ed\u793a\u4e86\u591a\u8bed\u79cd\u4efb\u52a1\u660e\u663e\u5f31\u4e8e\u82f1\u6587\u7684\u73b0\u72b6\uff0c\u5e76\u4e3a\u6a21\u578b\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u591a\u8bed\u79cd\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u7684\u5174\u8d77\uff0c\u5b9e\u73b0\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5982\u5370\u5ea6\u5404\u8bed\u79cd\uff09\u516c\u5e73AI\u7684\u53d1\u5c55\uff0c\u9700\u8981\u6709\u66f4\u5065\u5168\u7684\u8bc4\u4ef7\u65b9\u6cd5\u3002\u5f53\u524d\u591a\u8bed\u79cdVLM\u8bc4\u4f30\u5b58\u5728\u81ea\u52a8\u7ffb\u8bd1\u672a\u7ecf\u9a8c\u8bc1\u3001\u4efb\u52a1\u8986\u76d6\u72ed\u7a84\u3001\u6837\u672c\u91cf\u6709\u9650\u3001\u7f3a\u4e4f\u672c\u571f\u6587\u5316\u4e0e\u539f\u751fQA\u7b49\u5c40\u9650\u3002\u4e3a\u6b64\uff0c\u9700\u7814\u53d1\u7cfb\u7edf\u5316\u7684\u8bc4\u6d4b\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u5957\u53ef\u6269\u5c55\u7684\u6846\u67b6\u6765\u8bc4\u4ef7\u5370\u5ea6\u8bed\u8a00\u4e2d\u7684VLMs\u6027\u80fd\uff0c\u5e76\u4e0e\u82f1\u8bed\u505a\u5bf9\u6bd4\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u56de\u8bd1\u3001\u7b5b\u9009\u53ca\u4eba\u5de5\u6821\u9a8c\u7b49\u534a\u81ea\u52a8\u5316\u6d41\u7a0b\u521b\u5efa\u591a\u8bed\u79cd\u6570\u636e\u96c6\uff0c\u5e76\u6574\u5408VQAv2\u3001RealWorldQA\u3001CLEVR-Math\u7b49\u82f1\u6587\u6570\u636e\u96c6\u7684\u9002\u914d\u7248\u672c\uff0c\u4ee5\u53caJEE\uff08STEM\uff09\u548cVAANI\uff08\u6587\u5316\u7406\u89e3\uff09\u7b49\u539f\u751f\u5370\u5730\u8bed\u548c\u6cf0\u5362\u56fa\u8bed\u6570\u636e\u96c6\uff0c\u6784\u5efa\u4e86HinTel-AlignBench\u57fa\u51c6\uff0c\u6bcf\u79cd\u8bed\u8a00\u5305\u542b\u7ea64,000\u5bf9QA\u6837\u672c\u3002\u8fd8\u5bf9\u5f53\u524d\u4e3b\u6d41VLMs\uff08\u5f00\u6e90\u4e0e\u5c01\u95ed\u6e90\uff09\u8fdb\u884c\u4e86\u8be6\u7ec6\u6027\u80fd\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u5728\u51e0\u4e4e\u6240\u6709\u6a21\u578b\u4e0a\uff0c\u5370\u5730\u8bed\u548c\u6cf0\u5362\u56fa\u8bed\u4efb\u52a1\u7684\u8868\u73b0\u76f8\u8f83\u4e8e\u82f1\u6587\u4efb\u52a1\u5b58\u5728\u660e\u663e\u56de\u9000\uff08\u5206\u522b\u5e73\u5747\u56de\u90008.3\u5206\u548c5.5\u5206\uff09\uff0c4/5\u4efb\u52a1\u5747\u8868\u73b0\u4e0d\u4f73\u3002\u5206\u6790\u4e86\u5e38\u89c1\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u4e3a\u591a\u8bed\u79cd\u591a\u6a21\u6001\u7406\u89e3\u63d0\u51fa\u4e86\u6709\u5f85\u6539\u8fdb\u7684\u65b9\u5411\u3002", "conclusion": "\u65b0\u63d0\u51fa\u7684\u6570\u636e\u96c6\u548c\u8bc4\u4ef7\u4f53\u7cfb\u63ed\u793a\u4e86\u4e3b\u6d41VLM\u5728\u5370\u5ea6\u4e3b\u8981\u4f4e\u8d44\u6e90\u8bed\u8a00\u4efb\u52a1\u4e2d\u7684\u663e\u8457\u6027\u80fd\u7f3a\u53e3\u3002\u8be5\u5de5\u4f5c\u4e3a\u76f8\u5173\u6a21\u578b\u516c\u5e73\u6027\u548c\u591a\u8bed\u79cd\u80fd\u529b\u7684\u6539\u8fdb\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\u548c\u6307\u5bfc\u3002"}}
{"id": "2511.15107", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15107", "abs": "https://arxiv.org/abs/2511.15107", "authors": ["Yuan Jiang", "Zehao Li", "Shan Huang", "Christoph Treude", "Xiaohong Su", "Tiantian Wang"], "title": "Effective Code Membership Inference for Code Completion Models via Adversarial Prompts", "comment": null, "summary": "Membership inference attacks (MIAs) on code completion models offer an effective way to assess privacy risks by inferring whether a given code snippet was part of the training data. Existing black- and gray-box MIAs rely on expensive surrogate models or manually crafted heuristic rules, which limit their ability to capture the nuanced memorization patterns exhibited by over-parameterized code language models. To address these challenges, we propose AdvPrompt-MIA, a method specifically designed for code completion models, combining code-specific adversarial perturbations with deep learning. The core novelty of our method lies in designing a series of adversarial prompts that induce variations in the victim code model's output. By comparing these outputs with the ground-truth completion, we construct feature vectors to train a classifier that automatically distinguishes member from non-member samples. This design allows our method to capture richer memorization patterns and accurately infer training set membership. We conduct comprehensive evaluations on widely adopted models, such as Code Llama 7B, over the APPS and HumanEval benchmarks. The results show that our approach consistently outperforms state-of-the-art baselines, with AUC gains of up to 102%. In addition, our method exhibits strong transferability across different models and datasets, underscoring its practical utility and generalizability.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u5229\u7528\u5bf9\u6297\u6027\u63d0\u793a\u8bcd\u53ca\u6df1\u5ea6\u5b66\u4e60\u589e\u5f3a\u68c0\u6d4b\u4ee3\u7801\u8865\u5168\u6a21\u578b\u8bad\u7ec3\u96c6\u6210\u5458\u8eab\u4efd\u7684\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u4e3b\u6d41\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u6548\u679c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5b9e\u73b0\u66f4\u9ad8\u51c6\u786e\u7387\u4e0e\u66f4\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4ee3\u7801\u8865\u5168\u6a21\u578b\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u73b0\u6709\u7684\u6210\u5458\u63a8\u65ad\u653b\u51fb\uff08MIA\uff09\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u6cdb\u5316\u6027\u5dee\uff0c\u96be\u4ee5\u63ed\u793a\u6a21\u578b\u7684\u590d\u6742\u8bb0\u5fc6\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86\u9488\u5bf9\u4ee3\u7801\u8865\u5168\u6a21\u578b\u7684AdvPrompt-MIA\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bbe\u8ba1\u4ee3\u7801\u7279\u5b9a\u7684\u5bf9\u6297\u6027\u63d0\u793a\u8bcd\uff08adversarial prompts\uff09\u6765\u8bf1\u5bfc\u6a21\u578b\u751f\u6210\u5dee\u5f02\u5316\u8f93\u51fa\uff0c\u5e76\u4e0e\u771f\u5b9e\u8865\u5168\u8fdb\u884c\u5bf9\u6bd4\uff0c\u6784\u5efa\u7279\u5f81\u5411\u91cf\u8bad\u7ec3\u5206\u7c7b\u5668\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u533a\u5206\u6210\u5458\u4e0e\u975e\u6210\u5458\u6837\u672c\u3002", "result": "\u5728\u4e3b\u6d41\u6a21\u578b\uff08\u5982Code Llama 7B\uff09\u548c\u516c\u5f00\u57fa\u51c6\u96c6\uff08APPS\u3001HumanEval\uff09\u4e0a\u8fdb\u884c\u8be6\u7ec6\u8bc4\u6d4b\uff0c\u7ed3\u679c\u663e\u793a\u672c\u65b9\u6cd5AUC\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe102%\uff0c\u4e14\u5177\u5907\u826f\u597d\u7684\u6a21\u578b\u548c\u6570\u636e\u96c6\u8fc1\u79fb\u80fd\u529b\u3002", "conclusion": "AdvPrompt-MIA\u6709\u6548\u63d0\u9ad8\u4e86\u4ee3\u7801\u8865\u5168\u6a21\u578b\u6210\u5458\u63a8\u65ad\u653b\u51fb\u7684\u51c6\u786e\u6027\u4e0e\u6cdb\u5316\u6027\uff0c\u6709\u52a9\u4e8e\u8bc4\u4f30\u548c\u7f13\u89e3\u6a21\u578b\u9690\u79c1\u98ce\u9669\u3002"}}
{"id": "2511.15210", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.15210", "abs": "https://arxiv.org/abs/2511.15210", "authors": ["Vladislav Pedashenko", "Laida Kushnareva", "Yana Khassan Nibal", "Eduard Tulchinskii", "Kristian Kuznetsov", "Vladislav Zharchinskii", "Yury Maximov", "Irina Piontkovskaya"], "title": "Unveiling Intrinsic Dimension of Texts: from Academic Abstract to Creative Story", "comment": null, "summary": "Intrinsic dimension (ID) is an important tool in modern LLM analysis, informing studies of training dynamics, scaling behavior, and dataset structure, yet its textual determinants remain underexplored. We provide the first comprehensive study grounding ID in interpretable text properties through cross-encoder analysis, linguistic features, and sparse autoencoders (SAEs). In this work, we establish three key findings. First, ID is complementary to entropy-based metrics: after controlling for length, the two are uncorrelated, with ID capturing geometric complexity orthogonal to prediction quality. Second, ID exhibits robust genre stratification: scientific prose shows low ID (~8), encyclopedic content medium ID (~9), and creative/opinion writing high ID (~10.5) across all models tested. This reveals that contemporary LLMs find scientific text \"representationally simple\" while fiction requires additional degrees of freedom. Third, using SAEs, we identify causal features: scientific signals (formal tone, report templates, statistics) reduce ID; humanized signals (personalization, emotion, narrative) increase it. Steering experiments confirm these effects are causal. Thus, for contemporary models, scientific writing appears comparatively \"easy\", whereas fiction, opinion, and affect add representational degrees of freedom. Our multi-faceted analysis provides practical guidance for the proper use of ID and the sound interpretation of ID-based results.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u63ed\u793a\u4e86\u6587\u672c\u5c5e\u6027\u5982\u4f55\u51b3\u5b9aLLM\u4e2d\u7684\u672c\u5f81\u7ef4\u5ea6\uff08ID\uff09\uff1a\u79d1\u5b66\u5199\u4f5cID\u4f4e\u3001\u53d9\u4e8b\u6027\u548c\u60c5\u611f\u6027\u5199\u4f5cID\u9ad8\u3002ID\u4e0e\u71b5\u578b\u6307\u6807\u4e92\u8865\uff0c\u5bf9\u4e0d\u540c\u6587\u672c\u5e94\u533a\u522b\u89e3\u8bfb\u3002", "motivation": "\u5c3d\u7ba1\u672c\u5f81\u7ef4\u5ea6\uff08ID\uff09\u5728\u8bad\u7ec3\u52a8\u6001\u3001\u6a21\u578b\u6269\u5c55\u548c\u6570\u636e\u7ed3\u6784\u5206\u6790\u4e2d\u5f97\u5230\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46ID\u80cc\u540e\u7684\u6587\u672c\u51b3\u5b9a\u56e0\u7d20\u4ecd\u7136\u7f3a\u4e4f\u7cfb\u7edf\u6027\u63a2\u7d22\u3002\u8bba\u6587\u65e8\u5728\u63ed\u793aID\u6307\u6807\u4e0e\u6587\u672c\u5c5e\u6027\u7684\u5177\u4f53\u5173\u8054\uff0c\u5e2e\u52a9\u7406\u89e3\u548c\u66f4\u597d\u5730\u5229\u7528ID\u3002", "method": "\u91c7\u7528\u4ea4\u53c9\u7f16\u7801\u5668\u5206\u6790\u3001\u8bed\u8a00\u5b66\u7279\u5f81\u5206\u6790\u3001\u548c\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAEs\uff09\u65b9\u6cd5\uff0c\u7cfb\u7edf\u6027\u5730\u7814\u7a76\u4e86\u6587\u672c\u53ef\u89e3\u91ca\u5c5e\u6027\u4e0eID\u7684\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u63a7\u5236\u53d8\u91cf\u548c\u5e72\u9884\u5b9e\u9a8c\u9a8c\u8bc1\u56e0\u679c\u6027\u3002", "result": "1\uff09ID\u4e0e\u71b5\u7c7b\u6307\u6807\u4e92\u8865\uff0c\u4e14\u63a7\u5236\u6587\u672c\u957f\u5ea6\u540e\u65e0\u76f8\u5173\u6027\uff0c\u53cd\u6620\u4e86\u6b63\u4ea4\u7684\u51e0\u4f55\u590d\u6742\u5ea6\u30022\uff09ID\u80fd\u533a\u5206\u6587\u672c\u4f53\u88c1\uff1a\u79d1\u5b66\u6587\u4f53ID\u4f4e\uff0c\u767e\u79d1\u4e2d\u7b49\uff0c\u521b\u610f/\u8bc4\u8bba\u9ad8\u30023\uff09\u901a\u8fc7SAEs\u53d1\u73b0\uff0c\u6b63\u5f0f\u3001\u6a21\u677f\u5316\u3001\u5e26\u7edf\u8ba1\u7c7b\u4fe1\u53f7\u53ef\u964d\u4f4eID\uff0c\u800c\u4e2a\u6027\u5316\u3001\u60c5\u611f\u548c\u53d9\u4e8b\u6027\u5219\u63d0\u9ad8ID\uff0c\u4e14\u5177\u56e0\u679c\u5173\u7cfb\u3002", "conclusion": "\u79d1\u5b66\u6587\u672c\u5728\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u8868\u73b0\u4e3a\u201c\u8868\u5f81\u4e0a\u7b80\u5355\u201d\uff0c\u800c\u5c0f\u8bf4\u3001\u89c2\u70b9\u548c\u60c5\u611f\u6027\u5199\u4f5c\u5219\u589e\u52a0\u4e86\u8868\u5f81\u81ea\u7531\u5ea6\u3002\u9002\u7528\u4e0d\u540c\u7c7b\u578b\u6587\u672c\u65f6\uff0cID\u6307\u6807\u9700\u8981\u8c28\u614e\u89e3\u91ca\u548c\u4f7f\u7528\u3002"}}
{"id": "2511.15168", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15168", "abs": "https://arxiv.org/abs/2511.15168", "authors": ["Nguyen-Khang Le", "Nguyen Hiep", "Minh Nguyen", "Son Luu", "Trung Vo", "Quan Bui", "Nomura Shoshin", "Le-Minh Nguyen"], "title": "Finetuning LLMs for Automatic Form Interaction on Web-Browser in Selenium Testing Framework", "comment": "Published in the Proceedings of KSE 2025", "summary": "Automated web application testing is a critical component of modern software development, with frameworks like Selenium widely adopted for validating functionality through browser automation. Among the essential aspects of such testing is the ability to interact with and validate web forms, a task that requires syntactically correct, executable scripts with high coverage of input fields. Despite its importance, this task remains underexplored in the context of large language models (LLMs), and no public benchmark or dataset exists to evaluate LLMs on form interaction generation systematically. This paper introduces a novel method for training LLMs to generate high-quality test cases in Selenium, specifically targeting form interaction testing. We curate both synthetic and human-annotated datasets for training and evaluation, covering diverse real-world forms and testing scenarios. We define clear metrics for syntax correctness, script executability, and input field coverage. Our empirical study demonstrates that our approach significantly outperforms strong baselines, including GPT-4o and other popular LLMs, across all evaluation metrics. Our work lays the groundwork for future research on LLM-based web testing and provides resources to support ongoing progress in this area.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u5927\u6a21\u578b\u81ea\u52a8\u751f\u6210Selenium\u8868\u5355\u6d4b\u8bd5\u811a\u672c\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u6784\u5efa\u4e86\u516c\u5f00\u6570\u636e\u96c6\u548c\u8bc4\u6d4b\u6807\u51c6\uff0c\u5728\u591a\u9879\u6307\u6807\u4e0a\u663e\u8457\u8d85\u8d8aGPT-4o\u7b49\u57fa\u7ebf\uff0c\u4e3a\u5927\u6a21\u578b\u81ea\u52a8\u5316\u7f51\u9875\u6d4b\u8bd5\u7814\u53d1\u63d0\u4f9b\u4e86\u57fa\u7840\u548c\u8d44\u6e90\u3002", "motivation": "\u5728\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u4e2d\uff0c\u81ea\u52a8\u5316\u7f51\u9875\u5e94\u7528\u6d4b\u8bd5\u81f3\u5173\u91cd\u8981\uff0c\u5176\u4e2d\u8868\u5355\u4ea4\u4e92\u9a8c\u8bc1\u662f\u6838\u5fc3\u4f46\u5c1a\u672a\u88ab\u5927\u6a21\u578b\u7cfb\u7edf\u6027\u7814\u7a76\u3002\u5f53\u524d\u7f3a\u4e4f\u516c\u6709\u57fa\u51c6\u548c\u6570\u636e\u96c6\u6765\u8bc4\u4f30\u5927\u6a21\u578b\u5728\u81ea\u52a8\u751f\u6210\u7f51\u9875\u8868\u5355\u4ea4\u4e92\u6d4b\u8bd5\u811a\u672c\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u7684Selenium\u6d4b\u8bd5\u7528\u4f8b\uff0c\u4e13\u6ce8\u4e8e\u7f51\u9875\u8868\u5355\u4ea4\u4e92\u6d4b\u8bd5\u3002\u7814\u7a76\u56e2\u961f\u6784\u5efa\u4e86\u6db5\u76d6\u591a\u6837\u5316\u771f\u5b9e\u573a\u666f\u7684\u5408\u6210\u4e0e\u4eba\u5de5\u6ce8\u91ca\u6570\u636e\u96c6\uff0c\u5e76\u8bbe\u5b9a\u4e86\u5305\u62ec\u8bed\u6cd5\u6b63\u786e\u6027\u3001\u811a\u672c\u53ef\u6267\u884c\u6027\u548c\u8f93\u5165\u5b57\u6bb5\u8986\u76d6\u7387\u7684\u8bc4\u6d4b\u6807\u51c6\u3002", "result": "\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6240\u6709\u8bc4\u4f30\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5f3a\u57fa\u7ebf\uff0c\u5305\u62ecGPT-4o\u7b49\u6d41\u884c\u5927\u6a21\u578b\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u57fa\u4e8e\u5927\u6a21\u578b\u7684\u7f51\u9875\u81ea\u52a8\u5316\u6d4b\u8bd5\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e76\u63d0\u4f9b\u4e86\u652f\u6301\u540e\u7eed\u7814\u7a76\u7684\u6570\u636e\u8d44\u6e90\u548c\u8bc4\u6d4b\u6807\u51c6\u3002"}}
{"id": "2511.15211", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15211", "abs": "https://arxiv.org/abs/2511.15211", "authors": ["Xinli Tao", "Xin Dong", "Xuezhong Zhou"], "title": "OEMA: Ontology-Enhanced Multi-Agent Collaboration Framework for Zero-Shot Clinical Named Entity Recognition", "comment": "12 pages, 4 figures, 4 tables", "summary": "Clinical named entity recognition (NER) is crucial for extracting information from electronic health records (EHRs), but supervised models like CRF and BioClinicalBERT require costly annotated data. While zero-shot NER with large language models (LLMs) reduces this dependency, it struggles with example selection granularity and integrating prompts with self-improvement. To address this, we propose OEMA, a zero-shot clinical NER framework using multi-agent collaboration. OEMA's three components are: a self-annotator generating examples, a discriminator filtering them via SNOMED CT, and a predictor using entity descriptions for accurate inference. On MTSamples and VAERS datasets, OEMA achieves state-of-the-art exact-match performance. Under related-match, it matches supervised BioClinicalBERT and surpasses CRF. OEMA addresses key zero-shot NER challenges through ontology-guided reasoning and multi-agent collaboration, achieving near-supervised performance and showing promise for clinical NLP applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86OEMA\uff0c\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u96f6\u6837\u672c\u4e34\u5e8aNER\u65b9\u6cd5\uff0c\u7ed3\u5408\u81ea\u52a8\u793a\u4f8b\u751f\u6210\u3001\u672c\u4f53\u8fc7\u6ee4\u548c\u63cf\u8ff0\u63a8\u65ad\uff0c\u5728\u591a\u4e2a\u516c\u5f00\u4e34\u5e8a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u4f18\u5f02\u751a\u81f3\u63a5\u8fd1\u76d1\u7763\u6a21\u578b\u7684\u8bc6\u522b\u6548\u679c\uff0c\u5bf9\u4e34\u5e8aNLP\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u4e34\u5e8a\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08NER\uff09\u5bf9\u4e8e\u4ece\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHRs\uff09\u4e2d\u63d0\u53d6\u5173\u952e\u4fe1\u606f\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7684\u76d1\u7763\u6a21\u578b\u5982CRF\u548cBioClinicalBERT\u4f9d\u8d56\u5927\u91cf\u6602\u8d35\u7684\u6807\u6ce8\u6570\u636e\u3002\u540c\u65f6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u96f6\u6837\u672cNER\u867d\u7136\u53ef\u4ee5\u964d\u4f4e\u6570\u636e\u4f9d\u8d56\uff0c\u4f46\u5728\u793a\u4f8b\u9009\u62e9\u548c\u81ea\u6211\u63d0\u5347\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86OEMA\uff0c\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u96f6\u6837\u672c\u4e34\u5e8aNER\u6846\u67b6\u3002OEMA\u5305\u62ec\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u81ea\u6211\u6807\u6ce8\u5668\uff08\u81ea\u52a8\u751f\u6210\u793a\u4f8b\uff09\u3001\u5224\u522b\u5668\uff08\u901a\u8fc7SNOMED CT\u6807\u51c6\u8fc7\u6ee4\u793a\u4f8b\uff09\u3001\u9884\u6d4b\u5668\uff08\u5229\u7528\u5b9e\u4f53\u63cf\u8ff0\u8fdb\u884c\u63a8\u65ad\uff09\u3002", "result": "\u5728MTSamples\u548cVAERS\u6570\u636e\u96c6\u4e0a\uff0cOEMA\u53d6\u5f97\u4e86\u76ee\u524d\u6700\u4f18\u7684\u7cbe\u786e\u5339\u914d\u6027\u80fd\u3002\u5728\u76f8\u5173\u5339\u914d\u4efb\u52a1\u4e0b\uff0cOEMA\u4e0eBioClinicalBERT\u7684\u76d1\u7763\u6548\u679c\u76f8\u5f53\uff0c\u5e76\u4f18\u4e8eCRF\u6a21\u578b\u3002", "conclusion": "OEMA\u901a\u8fc7\u6574\u5408\u672c\u4f53\u6307\u5bfc\u63a8\u7406\u548c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u96f6\u6837\u672cNER\u7684\u5173\u952e\u96be\u9898\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u76d1\u7763\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4e3a\u4e34\u5e8aNLP\u5e94\u7528\u5e26\u6765\u4e86\u5e0c\u671b\u3002"}}
{"id": "2511.15229", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15229", "abs": "https://arxiv.org/abs/2511.15229", "authors": ["Bashar Abdallah", "Martyna E. Wojciechowska", "Gustavo Santos", "Edmand Yu", "Maxime Lamothe", "Alain Abran", "Mohammad Hamdaqa"], "title": "From Code Smells to Best Practices: Tackling Resource Leaks in PyTorch, TensorFlow, and Keras", "comment": null, "summary": "Much of the existing ML research focuses on model performance metrics, leaving limited attention to the long-term sustainability and resource efficiency of ML applications. While high performance is essential, ensuring efficient resource management is equally critical for robust deployment. This study addresses this gap by systematically identifying code smells that lead to resource leaks in ML applications. We conducted an empirical investigation of developer discussions and real-world code snippets from PyTorch, TensorFlow, and Keras. The analysis identified 30 PyTorch-related smells and 16 TensorFlow/Keras smells linked to resource leaks. These smells were categorized in two ways: (1) based on their root causes, and (2) as general ML smells with framework-specific characteristics. For each smell, we derived at least one best practice, resulting in 50 recommended coding patterns aimed at reducing resource leakage and improving efficiency. To ensure the validity of our findings, we employed a three-phase validation process involving independent analysis by three authors followed by consensus discussions. This is the first comprehensive study to examine resource-leak-inducing code smells across major ML frameworks and to present actionable best practices for mitigating them. The contributions support developers in building more efficient and sustainable ML applications and offer a structured view of the underlying causes of resource leaks.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5206\u6790ML\u5f00\u53d1\u4e2d\u7684\u4ee3\u7801\u5f02\u5473\uff0c\u7cfb\u7edf\u8bc6\u522b\u5e76\u5206\u7c7b\u4e86PyTorch\u53caTensorFlow/Keras\u4e2d\u4e0e\u8d44\u6e90\u6cc4\u6f0f\u76f8\u5173\u7684\u5f02\u5473\uff0c\u603b\u7ed3\u51fa50\u6761\u4f18\u5316\u5efa\u8bae\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u51cf\u5c11\u8d44\u6e90\u6cc4\u6f0f\u3001\u63d0\u5347ML\u7cfb\u7edf\u7684\u6548\u7387\u548c\u53ef\u6301\u7eed\u6027\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6a21\u578b\u6027\u80fd\u6307\u6807\uff0c\u5bf9ML\u5e94\u7528\u7684\u957f\u671f\u53ef\u6301\u7eed\u6027\u548c\u8d44\u6e90\u6548\u7387\u5173\u6ce8\u6709\u9650\u3002\u5b9e\u9645\u4e0a\uff0c\u9664\u4e86\u9ad8\u6027\u80fd\u5916\uff0c\u8d44\u6e90\u7ba1\u7406\u6548\u7387\u5bf9\u4e8e\u7a33\u5065\u90e8\u7f72\u540c\u6837\u91cd\u8981\uff0c\u56e0\u6b64\u672c\u7814\u7a76\u8bd5\u56fe\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5168\u9762\u8bc6\u522b\u5bfc\u81f4\u8d44\u6e90\u6cc4\u6f0f\u7684\u4ee3\u7801\u5f02\u5473\uff0c\u91c7\u7528\u5b9e\u8bc1\u8c03\u67e5\u65b9\u6cd5\u5206\u6790\u4e86\u5f00\u53d1\u8005\u8ba8\u8bba\u53caPyTorch\u3001TensorFlow\u548cKeras\u7684\u771f\u5b9e\u4ee3\u7801\u7247\u6bb5\u3002\u5bf9\u5f02\u5473\u8fdb\u884c\u4e86\u5f52\u7c7b\u5e76\u901a\u8fc7\u4e09\u9636\u6bb5\u9a8c\u8bc1\u8fc7\u7a0b\u4fdd\u8bc1\u4e86\u53d1\u73b0\u7684\u6709\u6548\u6027\u3002", "result": "\u8bc6\u522b\u51fa30\u9879PyTorch\u76f8\u5173\u5f02\u5473\u548c16\u9879TensorFlow/Keras\u76f8\u5173\u5f02\u5473\uff0c\u8fd9\u4e9b\u5f02\u5473\u90fd\u4e0e\u8d44\u6e90\u6cc4\u6f0f\u76f8\u5173\u3002\u9488\u5bf9\u6bcf\u79cd\u5f02\u5473\uff0c\u63d0\u51fa\u4e86\u81f3\u5c11\u4e00\u4e2a\u6700\u4f73\u5b9e\u8df5\uff0c\u5171\u5f62\u6210\u4e8650\u6761\u63a8\u8350\u7f16\u7801\u6a21\u5f0f\uff0c\u4ee5\u51cf\u5c11\u8d44\u6e90\u6cc4\u6f0f\u3001\u63d0\u5347\u6548\u7387\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u6027\u5206\u6790\u4e86\u4e3b\u6d41ML\u6846\u67b6\u4e2d\u5f15\u53d1\u8d44\u6e90\u6cc4\u6f0f\u7684\u4ee3\u7801\u5f02\u5473\uff0c\u5e76\u7ed9\u51fa\u53ef\u64cd\u4f5c\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u4e3a\u5f00\u53d1\u8005\u6784\u5efa\u66f4\u9ad8\u6548\u3001\u53ef\u6301\u7eed\u7684ML\u5e94\u7528\u63d0\u4f9b\u4e86\u652f\u6301\uff0c\u540c\u65f6\u4e5f\u68b3\u7406\u4e86\u8d44\u6e90\u6cc4\u6f0f\u7684\u6839\u672c\u539f\u56e0\u3002"}}
{"id": "2511.15244", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.15244", "abs": "https://arxiv.org/abs/2511.15244", "authors": ["Fanfan Liu", "Haibo Qiu"], "title": "Context Cascade Compression: Exploring the Upper Limits of Text Compression", "comment": null, "summary": "Million-level token inputs in long-context tasks pose significant computational and memory challenges for Large Language Models (LLMs). Recently, DeepSeek-OCR conducted research into the feasibility of Contexts Optical Compression and achieved preliminary results. Inspired by this, we introduce Context Cascade Compression C3 to explore the upper limits of text compression. Our method cascades two LLMs of different sizes to handle the compression and decoding tasks. Specifically, a small LLM, acting as the first stage, performs text compression by condensing a long context into a set of latent tokens (e.g., 32 or 64 in length), achieving a high ratio of text tokens to latent tokens. A large LLM, as the second stage, then executes the decoding task on this compressed context. Experiments show that at a 20x compression ratio (where the number of text tokens is 20 times the number of latent tokens), our model achieves 98% decoding accuracy, compared to approximately 60% for DeepSeek-OCR. When we further increase the compression ratio to 40x, the accuracy is maintained at around 93%. This indicates that in the domain of context compression, C3 Compression demonstrates superior performance and feasibility over optical character compression. C3 uses a simpler, pure-text pipeline that ignores factors like layout, color, and information loss from a visual encoder. This also suggests a potential upper bound for compression ratios in future work on optical character compression, OCR, and related fields. Codes and model weights are publicly accessible at https://github.com/liufanfanlff/C3-Context-Cascade-Compression", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faC3\u7ea7\u8054\u538b\u7f29\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u5c0fLLM\u534f\u540c\u5b9e\u73b0\u8d85\u957f\u6587\u672c\u9ad8\u538b\u7f29\u6bd4\u4e0e\u9ad8\u89e3\u7801\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5149\u5b66\u538b\u7f29\u65b9\u6848\uff0c\u5bf9\u672a\u6765\u6587\u672c\u538b\u7f29\u4e0eOCR\u9886\u57df\u5177\u6709\u91cd\u8981\u53c2\u8003\u4ef7\u503c\u3002", "motivation": "\u968f\u7740\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u8f93\u5165token\u89c4\u6a21\u8fbe\u5230\u767e\u4e07\u7ea7\uff0c\u5df2\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u5e26\u6765\u5de8\u5927\u6311\u6218\u3002\u73b0\u6709\u7684DeepSeek-OCR\u5c1d\u8bd5\u4e86\u4e0a\u4e0b\u6587\u5149\u5b66\u538b\u7f29\u6280\u672f\uff0c\u4f46\u538b\u7f29\u6548\u7387\u6709\u9650\u3002\u56e0\u6b64\uff0c\u672c\u6587\u8bd5\u56fe\u63a2\u7d22\u7eaf\u6587\u672c\u9886\u57df\u4e0a\u4e0b\u6587\u538b\u7f29\u7684\u6781\u9650\uff0c\u4ee5\u63d0\u5347\u5927\u6a21\u578b\u5728\u8d85\u957f\u6587\u672c\u5904\u7406\u4e0a\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86Context Cascade Compression\uff08C3\uff09\u65b9\u6cd5\uff0c\u5c06\u4e24\u79cd\u4e0d\u540c\u89c4\u6a21LLM\u7ea7\u8054\u4f7f\u7528\uff1a\u7b2c\u4e00\u9636\u6bb5\u7531\u5c0f\u578bLLM\u5bf9\u957f\u6587\u672c\u8fdb\u884c\u6781\u81f4\u538b\u7f29\uff0c\u63d0\u53d6\u5c11\u91cf\u6f5c\u5728token\uff1b\u7b2c\u4e8c\u9636\u6bb5\u7531\u5927\u578bLLM\u8d1f\u8d23\u89e3\u7801\uff0c\u5c06\u8fd9\u4e9b\u6f5c\u5728token\u8fd8\u539f\u56de\u539f\u59cb\u6587\u672c\u5185\u5bb9\u3002\u6574\u4e2a\u8fc7\u7a0b\u5b9e\u73b0\u7eaf\u6587\u672c\u8de8\u6a21\u578b\u7ea7\u8054\u538b\u7f29\u4e0e\u89e3\u7801\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cC3\u65b9\u6cd5\u5728\u538b\u7f29\u6bd420\u500d\uff08\u5373\u6587\u672ctoken\u6570\u91cf\u662f\u6f5c\u5728token\u768420\u500d\u65f6\uff09\u53ef\u83b7\u5f9798%\u7684\u89e3\u7801\u51c6\u786e\u7387\uff0c\u8fdc\u9ad8\u4e8eDeepSeek-OCR\u768460%\u3002\u5373\u4f7f\u538b\u7f29\u6bd4\u5347\u81f340\u500d\uff0c\u51c6\u786e\u7387\u4ecd\u670993%\u5de6\u53f3\u3002C3\u5c55\u73b0\u4e86\u5728\u4e0a\u4e0b\u6587\u538b\u7f29\u9886\u57df\u7684\u5353\u8d8a\u6027\u80fd\u548c\u53ef\u884c\u6027\u3002", "conclusion": "C3\u65b9\u6cd5\u5728\u4e0d\u501f\u52a9\u89c6\u89c9\u7f16\u7801\u5668\uff08\u5ffd\u7565\u5e03\u5c40\u3001\u989c\u8272\u7b49\u4fe1\u606f\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u4ee5\u7eaf\u6587\u672c\u7ba1\u7ebf\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u4e0a\u4e0b\u6587\u6781\u81f4\u538b\u7f29\u548c\u9ad8\u7cbe\u5ea6\u89e3\u7801\uff0c\u4f18\u4e8e\u5149\u5b66\u5b57\u7b26\u538b\u7f29\u3002\u4e3a\u672a\u6765OCR\u3001\u5b57\u7b26\u538b\u7f29\u7b49\u76f8\u5173\u5de5\u4f5c\u6307\u51fa\u4e86\u6f5c\u5728\u7684\u538b\u7f29\u6bd4\u4e0a\u9650\u3002\u6a21\u578b\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2511.15257", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15257", "abs": "https://arxiv.org/abs/2511.15257", "authors": ["Hiep Hong Trinh", "Federico Ciccozzi", "Abu Naser Masud", "Marjan Sirjani", "Mikael Sj\u00f6din"], "title": "M, Toolchain and Language for Reusable Model Compilation", "comment": null, "summary": "Complex software-driven systems often interleave distributed, concurrent computation processes with physical interactions with the environment. Developing these systems more efficiently and safely can be achieved by employing actionable, software-based models. From a high-level system model, engineers often need to derive multiple specialized models for different purposes, including simulation, deployment, and formal verification. Each of these target models usually rely on its own formalism, specification language, and execution platform. Traditionally, a compiler analyzes a program written in a programming language and generates executable code. In contrast, a model compiler processes a source model written in a modeling language and should ideally support the generation of multiple heterogeneous targets. However, most existing modeling languages are designed with a narrow focus, typically targeting only simulation or implementation. Multi-target compilation, when not considered during the language's early design, becomes significantly harder to achieve. In this paper, we introduce our initiative: a toolchain and modeling language called M, designed to support system modeling and multi-target compilation for model-driven engineering of complex, concurrent, and time-aware systems. M is a textual, grammar-driven language based on the actor model and extended with discrete-event scheduling semantics. It provides constructs for modeling system entities, message-based interactions, and time- or state-triggered reactions. From such models, M enables the systematic generation of diverse target artifacts while preserving semantic conformance to the original model. Moreover, M can serve as a middle language to which other modeling languages may anchor, thereby allowing them to benefit from its compilation framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86M\u8bed\u8a00\u53ca\u76f8\u5173\u5de5\u5177\u94fe\uff0c\u80fd\u591f\u5bf9\u590d\u6742\u7cfb\u7edf\u8fdb\u884c\u9ad8\u5c42\u5efa\u6a21\uff0c\u5e76\u5b9e\u73b0\u4e00\u5957\u6a21\u578b\u591a\u76ee\u6807\u81ea\u52a8\u7f16\u8bd1\u751f\u6210\u4eff\u771f\u3001\u90e8\u7f72\u3001\u9a8c\u8bc1\u7b49\u591a\u79cd\u5e73\u53f0 artefact\uff0c\u662f\u89e3\u51b3\u591a\u76ee\u6807\u6a21\u578b\u751f\u6210\u96be\u9898\u7684\u65b0\u65b9\u6848\u3002", "motivation": "\u5f53\u4eca\u590d\u6742\u7684\u8f6f\u786c\u4ef6\u7cfb\u7edf\u9700\u8981\u540c\u65f6\u652f\u6301\u5e76\u53d1\u3001\u5206\u5e03\u5f0f\u8ba1\u7b97\u548c\u4e0e\u7269\u7406\u73af\u5883\u7684\u4ea4\u4e92\u3002\u7531\u4e8e\u5de5\u7a0b\u5e08\u5e38\u5e38\u9700\u8981\u4ece\u9ad8\u5c42\u7cfb\u7edf\u6a21\u578b\u5bfc\u51fa\u591a\u4e2a\u7528\u4e8e\u4e0d\u540c\u76ee\u7684\uff08\u5982\u4eff\u771f\u3001\u90e8\u7f72\u3001\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff09\u7684\u4e13\u7528\u6a21\u578b\uff0c\u800c\u4e14\u8fd9\u4e9b\u6a21\u578b\u4f9d\u8d56\u4e0d\u540c\u7684\u5f62\u5f0f\u5316\u7406\u8bba\u3001\u8bed\u8a00\u548c\u5e73\u53f0\uff0c\u56e0\u6b64\u5982\u4f55\u9ad8\u6548\u6784\u5efa\u540c\u65f6\u9002\u914d\u591a\u76ee\u6807\u9700\u6c42\u7684\u5efa\u6a21\u5de5\u5177\u5c24\u4e3a\u91cd\u8981\u3002\u73b0\u6709\u7684\u5efa\u6a21\u8bed\u8a00\u5927\u591a\u53ea\u652f\u6301\u5355\u4e00\u76ee\u6807\uff0c\u7f3a\u5c11\u591a\u76ee\u6807\u7f16\u8bd1\u80fd\u529b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5de5\u5177\u94fe\u548c\u5efa\u6a21\u8bed\u8a00M\u3002M\u4e3a\u6587\u672c\u5316\u4e14\u57fa\u4e8e\u8bed\u6cd5\u9a71\u52a8\uff0c\u91c7\u7528actor\u6a21\u578b\u5e76\u6269\u5c55\u4e86\u79bb\u6563\u4e8b\u4ef6\u8c03\u5ea6\u8bed\u4e49\uff0c\u80fd\u8868\u8fbe\u7cfb\u7edf\u5b9e\u4f53\u3001\u57fa\u4e8e\u6d88\u606f\u7684\u4ea4\u4e92\u4ee5\u53ca\u5b9a\u65f6/\u72b6\u6001\u89e6\u53d1\u7684\u884c\u4e3a\u53cd\u5e94\uff0c\u5e76\u4e14\u652f\u6301\u4ece\u539f\u6a21\u578b\u7cfb\u7edf\u5730\u751f\u6210\u591a\u79cd\u7b26\u5408\u8bed\u4e49\u4e00\u81f4\u6027\u7684\u76ee\u6807\u5de5\u4ef6\uff0c\u53ef\u4f5c\u4e3a\u591a\u79cd\u5efa\u6a21\u8bed\u8a00\u7684\u4e2d\u95f4\u951a\u5b9a\u5c42\u3002", "result": "M\u8bed\u8a00\u548c\u5de5\u5177\u94fe\u652f\u6301\u7cfb\u7edf\u5efa\u6a21\u4e0e\u591a\u76ee\u6807\u7f16\u8bd1\uff0c\u80fd\u591f\u81ea\u52a8\u5316\u751f\u6210\u591a\u79cd\u5e94\u7528\u4e8e\u4eff\u771f\u3001\u90e8\u7f72\u3001\u9a8c\u8bc1\u7b49\u76ee\u6807\u5e73\u53f0\u7684\u4ea7\u7269\uff0c\u5e76\u5b9e\u73b0\u6a21\u578b\u8bed\u4e49\u4e00\u81f4\uff1b\u6b64\u5916\uff0cM\u8fd8\u80fd\u4f5c\u4e3a\u5176\u4ed6\u6a21\u578b\u8bed\u8a00\u7684\u4e2d\u95f4\u5c42\uff0c\u63a8\u5e7f\u591a\u76ee\u6807\u7f16\u8bd1\u80fd\u529b\u3002", "conclusion": "M\u8bed\u8a00\u548c\u5de5\u5177\u94fe\u4e3a\u5e76\u53d1\u3001\u65f6\u5e8f\u654f\u611f\u7cfb\u7edf\u7684\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\u63d0\u4f9b\u4e86\u7edf\u4e00\u3001\u53ef\u6269\u5c55\u7684\u591a\u76ee\u6807\u7f16\u8bd1\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u5efa\u6a21\u548c\u76ee\u6807\u5bfc\u51fa\u6548\u7387\uff0c\u6709\u671b\u6210\u4e3a\u89e3\u51b3\u590d\u6742\u7cfb\u7edf\u591a\u76ee\u6807\u7f16\u8bd1\u96be\u9898\u7684\u91cd\u8981\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2511.15260", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15260", "abs": "https://arxiv.org/abs/2511.15260", "authors": ["Sowmya Vajjala"], "title": "IndicGEC: Powerful Models, or a Measurement Mirage?", "comment": "Technical report", "summary": "In this paper, we report the results of the TeamNRC's participation in the BHASHA-Task 1 Grammatical Error Correction shared task https://github.com/BHASHA-Workshop/IndicGEC2025/ for 5 Indian languages. Our approach, focusing on zero/few-shot prompting of language models of varying sizes (4B to large proprietary models) achieved a Rank 4 in Telugu and Rank 2 in Hindi with GLEU scores of 83.78 and 84.31 respectively. In this paper, we extend the experiments to the other three languages of the shared task - Tamil, Malayalam and Bangla, and take a closer look at the data quality and evaluation metric used. Our results primarily highlight the potential of small language models, and summarize the concerns related to creating good quality datasets and appropriate metrics for this task that are suitable for Indian language scripts.", "AI": {"tldr": "\u4f5c\u8005\u9488\u5bf9\u5370\u5ea6\u4e94\u79cd\u8bed\u8a00\u7684\u8bed\u6cd5\u7ea0\u9519\u4efb\u52a1\uff0c\u901a\u8fc7\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u96f6/\u5c11\u6837\u672c\u63d0\u793a\u65b9\u6cd5\u83b7\u5f97\u4e86\u826f\u597d\u6210\u7ee9\uff0c\u5c24\u5176\u5728\u6cf0\u5362\u56fa\u8bed\u548c\u5370\u5730\u8bed\u3002\u5b9e\u9a8c\u4e5f\u63ed\u793a\u4e86\u6570\u636e\u8d28\u91cf\u53ca\u8bc4\u4f30\u65b9\u6cd5\u5bf9\u4efb\u52a1\u6210\u679c\u7684\u91cd\u8981\u5f71\u54cd\u3002", "motivation": "\u53c2\u4e0eBHASHA-Task 1\u8bed\u6cd5\u7ea0\u9519\u5171\u4eab\u4efb\u52a1\uff0c\u63a2\u7d22\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0b\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\uff0c\u5e76\u5173\u6ce8\u5370\u5ea6\u8bed\u8a00\u7279\u6709\u7684\u6570\u636e\u548c\u8bc4\u4f30\u6311\u6218\u3002", "method": "\u91c7\u7528\u96f6\u6837\u672c/\u5c11\u6837\u672c\u63d0\u793a\uff0c\u5229\u7528\u4e0d\u540c\u89c4\u6a21\uff084B\u81f3\u5927\u578b\u4e13\u6709\uff09\u7684\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bed\u6cd5\u7ea0\u9519\u5b9e\u9a8c\uff0c\u5e76\u5728\u4e94\u79cd\u5370\u5ea6\u8bed\u8a00\u4e0a\u6d4b\u8bd5\u3002", "result": "\u5728\u6cf0\u5362\u56fa\u8bed\u548c\u5370\u5730\u8bed\u4e0a\u7684GLEU\u5f97\u5206\u5206\u522b\u4e3a83.78\u548c84.31\uff0c\u5206\u522b\u83b7\u5f97\u7b2c4\u548c\u7b2c2\u540d\u3002\u6269\u5c55\u5b9e\u9a8c\u5230\u6cf0\u7c73\u5c14\u8bed\u3001\u9a6c\u62c9\u96c5\u62c9\u59c6\u8bed\u548c\u5b5f\u52a0\u62c9\u8bed\uff0c\u53d1\u73b0\u5c0f\u578b\u6a21\u578b\u6709\u6548\uff0c\u4f46\u6570\u636e\u548c\u8bc4\u4f30\u9700\u6539\u8fdb\u3002", "conclusion": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5370\u5ea6\u8bed\u8a00\u8bed\u6cd5\u7ea0\u9519\u4efb\u52a1\u4e2d\u5177\u5907\u6f5c\u529b\uff0c\u4f46\u6570\u636e\u96c6\u8d28\u91cf\u548c\u8bc4\u4f30\u6307\u6807\u9700\u8981\u6539\u8fdb\u4ee5\u66f4\u9002\u5e94\u5370\u5ea6\u8bed\u8a00\u3002"}}
{"id": "2511.15293", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15293", "abs": "https://arxiv.org/abs/2511.15293", "authors": ["Jia Li", "Zhi Jin", "Kechi Zhang", "Huangzhao Zhang", "Jiaru Qian", "Tiankuo Zhao"], "title": "A Viable Paradigm of Software Automation: Iterative End-to-End Automated Software Development", "comment": null, "summary": "Software development automation is a long-term goal in software engineering. With the development of artificial intelligence (AI), more and more researchers are exploring approaches to software automation. They view AI systems as tools or assistants in software development, still requiring significant human involvement. Another initiative is ``vibe coding'', where AI systems write and repeatedly revise most (or even all) of the code. We foresee these two development paths will converge towards the same destination: AI systems participate in throughout the software development lifecycle, expanding boundaries of full-stack software development. In this paper, we present a vision of an iterative end-to-end automated software development paradigm AutoSW. It operates in an analyze-plan-implement-deliver loop, where AI systems as human partners become first-class actors, translating human intentions expressed in natural language into executable software. We explore a lightweight prototype across the paradigm and initially execute various representative cases. The results indicate that AutoSW can successfully deliver executable software, providing a feasible direction for truly end-to-end automated software development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7aef\u5230\u7aef\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\u65b0\u8303\u5f0fAutoSW\uff0cAI\u8d2f\u7a7f\u5206\u6790\u5230\u4ea4\u4ed8\u5168\u8fc7\u7a0b\uff0c\u8f7b\u91cf\u7ea7\u539f\u578b\u9a8c\u8bc1\u5176\u53ef\u884c\u6027\uff0c\u8868\u660eAI\u4e3b\u5bfc\u7684\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\u5177\u6709\u53ef\u884c\u6027\u4e0e\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u968f\u7740AI\u7684\u53d1\u5c55\uff0c\u63a8\u52a8\u8f6f\u4ef6\u5f00\u53d1\u81ea\u52a8\u5316\u6210\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u70ed\u95e8\u8bfe\u9898\uff0c\u5f53\u524dAI\u591a\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\uff0c\u4f46\u5b8c\u5168\u81ea\u52a8\u5316\u5f00\u53d1\u4ecd\u9700\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e86AutoSW\u81ea\u52a8\u5316\u5f00\u53d1\u8303\u5f0f\uff0c\u91c7\u7528\u5206\u6790-\u89c4\u5212-\u5b9e\u73b0-\u4ea4\u4ed8\u7684\u5faa\u73af\uff0cAI\u4f5c\u4e3a\u4e0e\u4eba\u534f\u4f5c\u7684\u4e3b\u89d2\uff0c\u4ece\u81ea\u7136\u8bed\u8a00\u610f\u56fe\u5230\u53ef\u6267\u884c\u8f6f\u4ef6\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u81ea\u52a8\u5316\u3002\u5f00\u53d1\u4e86\u8f7b\u91cf\u7ea7\u539f\u578b\u5e76\u8fdb\u884c\u4ee3\u8868\u6027\u6848\u4f8b\u9a8c\u8bc1\u3002", "result": "AutoSW\u539f\u578b\u5728\u591a\u79cd\u4ee3\u8868\u6027\u573a\u666f\u4e0b\u80fd\u591f\u6210\u529f\u4ea7\u51fa\u53ef\u6267\u884c\u8f6f\u4ef6\uff0c\u9a8c\u8bc1\u4e86\u5176\u521d\u6b65\u53ef\u884c\u6027\u3002", "conclusion": "AutoSW\u4e3a\u5168\u6d41\u7a0b\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0cAI\u6709\u671b\u6210\u4e3a\u8d2f\u7a7f\u5f00\u53d1\u751f\u547d\u5468\u671f\u7684\u4e3b\u5bfc\u89d2\u8272\u3002"}}
{"id": "2511.15291", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15291", "abs": "https://arxiv.org/abs/2511.15291", "authors": ["Randa Zarnoufi"], "title": "MAPROC at AHaSIS Shared Task: Few-Shot and Sentence Transformer for Sentiment Analysis of Arabic Hotel Reviews", "comment": null, "summary": "Sentiment analysis of Arabic dialects presents significant challenges due to linguistic diversity and the scarcity of annotated data. This paper describes our approach to the AHaSIS shared task, which focuses on sentiment analysis on Arabic dialects in the hospitality domain. The dataset comprises hotel reviews written in Moroccan and Saudi dialects, and the objective is to classify the reviewers sentiment as positive, negative, or neutral. We employed the SetFit (Sentence Transformer Fine-tuning) framework, a data-efficient few-shot learning technique. On the official evaluation set, our system achieved an F1 of 73%, ranking 12th among 26 participants. This work highlights the potential of few-shot learning to address data scarcity in processing nuanced dialectal Arabic text within specialized domains like hotel reviews.", "AI": {"tldr": "\u4f5c\u8005\u57fa\u4e8eSetFit\u6846\u67b6\u5bf9\u6469\u6d1b\u54e5\u548c\u6c99\u7279\u65b9\u8a00\u9152\u5e97\u8bc4\u8bba\u8fdb\u884c\u60c5\u611f\u5206\u7c7b\uff0c\u5728\u5c11\u6837\u672c\u7684\u60c5\u51b5\u4e0b\u53d6\u5f97\u4e86\u8f83\u597d\u6548\u679c\uff08F1=73%\uff0c\u6392\u540d\u7b2c12\uff09\uff0c\u9a8c\u8bc1\u5c11\u6837\u672c\u5b66\u4e60\u5728\u4e13\u95e8\u9886\u57df\u5185\u963f\u62c9\u4f2f\u65b9\u8a00\u5904\u7406\u7684\u4ef7\u503c\u3002", "motivation": "\u963f\u62c9\u4f2f\u65b9\u8a00\u56e0\u8bed\u8a00\u591a\u6837\u6027\u548c\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\uff0c\u60c5\u611f\u5206\u6790\u4efb\u52a1\u5341\u5206\u56f0\u96be\u3002\u4f5c\u8005\u65e8\u5728\u63a8\u52a8\u9152\u5e97\u9886\u57df\u963f\u62c9\u4f2f\u65b9\u8a00\u60c5\u611f\u5206\u6790\u7684\u53d1\u5c55\u3002", "method": "\u91c7\u7528SetFit\uff08\u53e5\u5b50\u53d8\u6362\u5668\u5fae\u8c03\uff09\u6846\u67b6\uff0c\u4e00\u79cd\u9ad8\u6548\u7684\u6570\u636e\u5c11\u6837\u672c\u5b66\u4e60\u6280\u672f\uff0c\u7528\u4e8e\u60c5\u611f\u5206\u7c7b\u4efb\u52a1\u3002", "result": "\u5728\u5b98\u65b9\u8bc4\u6d4b\u96c6\u4e0a\uff0c\u7cfb\u7edfF1\u5206\u6570\u8fbe73%\uff0c\u572826\u4e2a\u53c2\u8d5b\u961f\u4f0d\u4e2d\u6392\u540d\u7b2c12\u3002", "conclusion": "\u5c11\u6837\u672c\u5b66\u4e60\u6280\u672f\u5728\u5904\u7406\u9152\u5e97\u9886\u57df\u7684\u963f\u62c9\u4f2f\u65b9\u8a00\u60c5\u611f\u5206\u6790\u65b9\u9762\u5c55\u73b0\u4e86\u6f5c\u529b\uff0c\u53ef\u6709\u6548\u7f13\u89e3\u6570\u636e\u532e\u4e4f\u7684\u95ee\u9898\u3002"}}
{"id": "2511.15340", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15340", "abs": "https://arxiv.org/abs/2511.15340", "authors": ["Yi Peng", "Hans-Martin Heyn", "Jennifer Horkoff"], "title": "From Machine Learning Documentation to Requirements: Bridging Processes with Requirements Languages", "comment": "To be published in proceedings of the 26th International Conference on Product-Focused Software Process Improvement (PROFES 2025). All raw and processed data are available in online repository, see https://doi.org/10.6084/m9.figshare.28564058.v1", "summary": "In software engineering processes for machine learning (ML)-enabled systems, integrating and verifying ML components is a major challenge. A prerequisite is the specification of ML component requirements, including models and data, an area where traditional requirements engineering (RE) processes face new obstacles. An underexplored source of RE-relevant information in this context is ML documentation such as ModelCards and DataSheets. However, it is uncertain to what extent RE-relevant information can be extracted from these documents. This study first investigates the amount and nature of RE-relevant information in 20 publicly available ModelCards and DataSheets. We show that these documents contain a significant amount of potentially RE-relevant information. Next, we evaluate how effectively three established RE representations (EARS, Rupp's template, and Volere) can structure this knowledge into requirements. Our results demonstrate that there is a pathway to transform ML-specific knowledge into structured requirements, incorporating ML documentation in software engineering processes for ML systems.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e8620\u4efdML\u6587\u6863\uff0c\u8bc1\u5b9e\u5176\u5bf9\u9700\u6c42\u5de5\u7a0b\u6781\u5177\u4ef7\u503c\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u501f\u52a9EARS\u7b49\u6a21\u677f\u5c06\u5176\u5185\u5bb9\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u9700\u6c42\uff0c\u4ece\u800c\u63a8\u52a8ML\u7cfb\u7edf\u7684\u8f6f\u4ef6\u5de5\u7a0b\u53d1\u5c55\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u8f6f\u4ef6\u5de5\u7a0b\u8fc7\u7a0b\u4e2d\uff0cML\u7ec4\u4ef6\u7684\u96c6\u6210\u4e0e\u9a8c\u8bc1\u56f0\u96be\uff0c\u5c24\u4ee5\u9700\u6c42\u89c4\u8303\u65b9\u9762\u4e3a\u663e\u8457\u6311\u6218\u3002\u4f20\u7edf\u9700\u6c42\u5de5\u7a0b\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u6a21\u578b\u548c\u6570\u636e\u5c42\u9762\u7684\u65b0\u95ee\u9898\u3002ML\u6587\u6863\uff08\u5982ModelCards\u548cDataSheets\uff09\u53ef\u80fd\u5305\u542b\u6709\u4ef7\u503c\u7684\u9700\u6c42\u4fe1\u606f\uff0c\u4f46\u5176\u5b9e\u9645\u4ef7\u503c\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u5bf920\u4efd\u516c\u5f00\u53ef\u83b7\u5f97\u7684ModelCards\u548cDataSheets\u8fdb\u884c\u5185\u5bb9\u5206\u6790\uff0c\u8bc4\u4f30\u5176\u4e2d\u8574\u542b\u7684\u9700\u6c42\u5de5\u7a0b\u76f8\u5173\u4fe1\u606f\uff1b\u968f\u540e\u5c1d\u8bd5\u901a\u8fc7\u4e09\u79cd\u4e3b\u6d41\u9700\u6c42\u8868\u8fbe\u65b9\u5f0f\uff08EARS\u3001Rupp\u6a21\u677f\u548cVolere\uff09\u5c06\u8fd9\u4e9b\u4fe1\u606f\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u9700\u6c42\u3002", "result": "\u53d1\u73b0ML\u6587\u6863\u4e2d\u786e\u5b9e\u5305\u542b\u5927\u91cf\u6f5c\u5728\u7684\u9700\u6c42\u76f8\u5173\u4fe1\u606f\uff0c\u4e14\u901a\u8fc7\u73b0\u6709\u9700\u6c42\u8868\u8fbe\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u5730\u5bf9\u8fd9\u4e9b\u4fe1\u606f\u8fdb\u884c\u7ed3\u6784\u5316\u548c\u8f6c\u5316\u3002", "conclusion": "ML\u6587\u6863\u4e3aML\u7cfb\u7edf\u7684\u9700\u6c42\u5de5\u7a0b\u63d0\u4f9b\u4e86\u5b9d\u8d35\u4fe1\u606f\u6765\u6e90\uff0c\u73b0\u6709\u9700\u6c42\u5de5\u7a0b\u6a21\u5f0f\u53ef\u4ee5\u5e2e\u52a9\u5c06\u8fd9\u4e9b\u4fe1\u606f\u8f6c\u5316\u4e3a\u6b63\u5f0f\u9700\u6c42\uff0c\u6709\u52a9\u4e8e\u63d0\u5347ML\u7cfb\u7edf\u8f6f\u4ef6\u8fc7\u7a0b\u7684\u8d28\u91cf\u3002"}}
{"id": "2511.15304", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15304", "abs": "https://arxiv.org/abs/2511.15304", "authors": ["Piercosma Bisconti", "Matteo Prandi", "Federico Pierucci", "Francesco Giarrusso", "Marcantonio Bracale", "Marcello Galisai", "Vincenzo Suriani", "Olga Sorokoletova", "Federico Sartore", "Daniele Nardi"], "title": "Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models", "comment": null, "summary": "We present evidence that adversarial poetry functions as a universal single-turn jailbreak technique for large language models (LLMs). Across 25 frontier proprietary and open-weight models, curated poetic prompts yielded high attack-success rates (ASR), with some providers exceeding 90%. Mapping prompts to MLCommons and EU CoP risk taxonomies shows that poetic attacks transfer across CBRN, manipulation, cyber-offence, and loss-of-control domains. Converting 1,200 MLCommons harmful prompts into verse via a standardized meta-prompt produced ASRs up to 18 times higher than their prose baselines. Outputs are evaluated using an ensemble of open-weight judge models and a human-validated stratified subset (with double-annotations to measure agreement). Disagreements were manually resolved. Poetic framing achieved an average jailbreak success rate of 62% for hand-crafted poems and approximately 43% for meta-prompt conversions (compared to non-poetic baselines), substantially outperforming non-poetic baselines and revealing a systematic vulnerability across model families and safety training approaches. These findings demonstrate that stylistic variation alone can circumvent contemporary safety mechanisms, suggesting fundamental limitations in current alignment methods and evaluation protocols.", "AI": {"tldr": "\u5c06\u6709\u5bb3\u5185\u5bb9\u5305\u88c5\u4e3a\u8bd7\u6b4c\u5f62\u5f0f\uff0c\u53ef\u5927\u5e45\u63d0\u5347\u5bf9LLM\u5b89\u5168\u673a\u5236\u7684\u7ed5\u8fc7\u7387\u3002\u65e0\u8bba\u5546\u7528\u6216\u5f00\u6e90\u6a21\u578b\uff0c\u5bf9\u8bd7\u6b4c\u653b\u51fb\u5747\u9ad8\u5ea6\u654f\u611f\uff0c\u663e\u793a\u51fa\u5b89\u5168\u8bad\u7ec3\u5728\u5e94\u5bf9\u98ce\u683c\u5316\u5185\u5bb9\u65b9\u9762\u5b58\u5728\u7cfb\u7edf\u6027\u4e0d\u8db3\uff0c\u8fd9\u5bf9LLM\u7684\u5b89\u5168\u8bc4\u4f30\u548c\u98ce\u9669\u63a7\u5236\u63d0\u51fa\u4e86\u65b0\u7684\u6311\u6218\u3002", "motivation": "\u7814\u7a76\u4eba\u5458\u5e0c\u671b\u63a2\u7a76\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5b89\u5168\u673a\u5236\u662f\u5426\u5bb9\u6613\u88ab\u7a81\u7834\uff0c\u5e76\u5bfb\u627e\u4e00\u79cd\u53ef\u80fd\u666e\u9002\u7684\u653b\u7834\u65b9\u6cd5\u3002\u9274\u4e8e\u5bf9\u6297\u6027\u653b\u51fb\u5df2\u77e5\u80fd\u589e\u52a0\u6a21\u578b\u7684\u8f93\u51fa\u98ce\u9669\uff0c\u672c\u7814\u7a76\u805a\u7126\u4e8e\u8bd7\u6b4c\u5f62\u5f0f\u662f\u5426\u80fd\u4f5c\u4e3a\u901a\u7528\u578b\u201c\u8d8a\u72f1\u201d\u653b\u51fb\u5de5\u5177\u3002", "method": "\u7814\u7a76\u4eba\u5458\u9488\u5bf925\u4e2a\u4e3b\u6d41\u524d\u6cbfLLM\uff08\u6db5\u76d6\u5546\u4e1a\u53ca\u5f00\u6e90\u6a21\u578b\uff09\uff0c\u5c061,200\u6761\u6709\u5bb3\u7684MLCommons\u57fa\u7ebf\u63d0\u793a\u8f6c\u6362\u4e3a\u8bd7\u6b4c\uff0c\u901a\u8fc7\u6807\u51c6\u5316\u7684meta-prompt\u751f\u6210\u3002\u540c\u65f6\uff0c\u56e2\u961f\u7f16\u5199\u4e86\u624b\u5de5\u8bd7\u6b4c\u653b\u51fb\uff0c\u5e76\u5c06\u8bd7\u6b4c\u653b\u51fb\u4e0e\u539f\u59cb\u6563\u6587\u653b\u51fb\u6548\u679c\u8fdb\u884c\u5bf9\u6bd4\u3002\u653b\u51fb\u7ed3\u679c\u7528\u591a\u4e2a\u5f00\u6e90\u88c1\u5224\u6a21\u578b\u548c\u4eba\u5de5\uff08\u53cc\u6ce8\u91ca\u4e14\u4e00\u81f4\u6027\u5904\u7406\uff09\u65b9\u6cd5\u8bc4\u4f30\uff0c\u5e76\u636eMLCommons\u53ca\u6b27\u76df\u98ce\u9669\u5206\u7c7b\u4f53\u7cfb\u6620\u5c04\u4e86\u653b\u51fb\u7c7b\u578b\u53ca\u9886\u57df\u3002", "result": "\u8bd7\u6b4c\u63d0\u793a\u5728\u5927\u90e8\u5206\u6a21\u578b\u4e0a\u663e\u8457\u63d0\u5347\u653b\u51fb\u6210\u529f\u7387\uff0c\u90e8\u5206\u6a21\u578b\u7a81\u7834\u7387\u5927\u4e8e90%\u3002\u8bd7\u6b4c\u8f6c\u5316\u76841,200\u6761\u63d0\u793a\u6210\u529f\u7387\u6700\u9ad8\u53ef\u8fbe\u539f\u59cb\u6563\u6587\u768418\u500d\u3002\u624b\u5de5\u8bd7\u6b4c\u5e73\u5747\u8d8a\u72f1\u6210\u529f\u7387\u4e3a62%\uff0cmeta-prompt\u751f\u6210\u7ea643%\uff0c\u5747\u8fdc\u9ad8\u4e8e\u975e\u8bd7\u6b4c\u5f62\u5f0f\u3002\u8bd7\u6b4c\u5f62\u5f0f\u80fd\u666e\u904d\u7a81\u7834\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u53ca\u5b89\u5168\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4e14\u4e0e\u6563\u6587\u57fa\u7ebf\u5dee\u8ddd\u660e\u663e\u3002", "conclusion": "\u8bd7\u6b4c\uff08\u98ce\u683c\u5316\u53d8\u4f53\uff09\u53ef\u4f5c\u4e3a\u5355\u8f6e\u8d8a\u72f1LLM\u7684\u901a\u7528\u6280\u672f\uff0c\u5f53\u524d\u5b89\u5168\u673a\u5236\u5bf9\u98ce\u683c\u53d8\u5316\uff08\u5982\u8bd7\u6b4c\u4f53\uff09\u7f3a\u4e4f\u9632\u5fa1\u529b\uff0c\u63ed\u793a\u51fa\u73b0\u6709\u6a21\u578b\u5bf9\u653b\u51fb\u5b58\u5728\u7cfb\u7edf\u6027\u5f31\u70b9\u548c\u5bf9\u9f50\u65b9\u6cd5\u7684\u6839\u672c\u5c40\u9650\u3002\u8bc4\u4f30\u534f\u8bae\u540c\u6837\u672a\u80fd\u6355\u6349\u6b64\u7c7b\u7ec6\u5fae\u6f0f\u6d1e\u3002"}}
{"id": "2511.15355", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15355", "abs": "https://arxiv.org/abs/2511.15355", "authors": ["Alexis Correa-Guill\u00e9n", "Carlos G\u00f3mez-Rodr\u00edguez", "David Vilares"], "title": "HEAD-QA v2: Expanding a Healthcare Benchmark for Reasoning", "comment": "Preprint. 12 pages", "summary": "We introduce HEAD-QA v2, an expanded and updated version of a Spanish/English healthcare multiple-choice reasoning dataset originally released by Vilares and G\u00f3mez-Rodr\u00edguez (2019). The update responds to the growing need for high-quality datasets that capture the linguistic and conceptual complexity of healthcare reasoning. We extend the dataset to over 12,000 questions from ten years of Spanish professional exams, benchmark several open-source LLMs using prompting, RAG, and probability-based answer selection, and provide additional multilingual versions to support future work. Results indicate that performance is mainly driven by model scale and intrinsic reasoning ability, with complex inference strategies obtaining limited gains. Together, these results establish HEAD-QA v2 as a reliable resource for advancing research on biomedical reasoning and model improvement.", "AI": {"tldr": "\u672c\u6587\u63a8\u51fa\u4e86HEAD-QA v2\uff0c\u4e00\u4e2a\u6269\u5c55\u4e14\u66f4\u65b0\u7684\u897f\u73ed\u7259\u8bed/\u82f1\u8bed\u533b\u7597\u591a\u9879\u9009\u62e9\u63a8\u7406\u6570\u636e\u96c6\u3002\u901a\u8fc7\u52a0\u5165\u66f4\u591a\u9898\u76ee\u548c\u591a\u8bed\u8a00\u7248\u672c\uff0c\u5e76\u7cfb\u7edf\u8bc4\u6d4b\u5f00\u6e90\u5927\u6a21\u578b\uff0c\u53d1\u73b0\u6a21\u578b\u80fd\u529b\u4e3b\u8981\u7531\u89c4\u6a21\u4e0e\u63a8\u7406\u6df1\u5ea6\u51b3\u5b9a\u3002\u8be5\u6570\u636e\u96c6\u4e3a\u533b\u7597\u63a8\u7406\u9886\u57df\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6301\u3002", "motivation": "\u73b0\u6709\u533b\u7597\u63a8\u7406\u6570\u636e\u96c6\u65e0\u6cd5\u5145\u5206\u4f53\u73b0\u8bed\u8a00\u548c\u6982\u5ff5\u7684\u590d\u6742\u6027\uff0c\u800c\u9ad8\u8d28\u91cf\u3001\u591a\u8bed\u8a00\u7684\u6570\u636e\u8d44\u6e90\u5bf9\u4e8e\u63a8\u52a8\u76f8\u5173\u9886\u57df\u7814\u7a76\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6269\u5c55\u539f\u6709HEAD-QA\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u8d85\u8fc7\u4e00\u4e07\u4e24\u5343\u9053\u897f\u73ed\u7259\u8bed\u4e13\u4e1a\u8003\u8bd5\u9898\u76ee\uff0c\u5e76\u5f15\u5165\u591a\u8bed\u8a00\u7248\u672c\u3002\u91c7\u7528\u591a\u79cd\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5229\u7528prompt\u3001RAG\u548c\u6982\u7387\u9009\u62e9\u7b49\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u6a21\u578b\u7684\u8868\u73b0\u4e3b\u8981\u53d7\u89c4\u6a21\u548c\u5185\u5728\u63a8\u7406\u80fd\u529b\u5f71\u54cd\uff0c\u590d\u6742\u63a8\u7406\u7b56\u7565\u5e26\u6765\u7684\u63d0\u5347\u6709\u9650\u3002", "conclusion": "HEAD-QA v2\u4e3a\u751f\u7269\u533b\u5b66\u63a8\u7406\u548c\u6a21\u578b\u6539\u8fdb\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u9760\u8d44\u6e90\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u8be5\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2511.15589", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15589", "abs": "https://arxiv.org/abs/2511.15589", "authors": ["Qian Zhu", "Yuxuan Liu", "Ziyuan Zhu", "Shangqing Liu", "Lei Bu"], "title": "EPSO: A Caching-Based Efficient Superoptimizer for BPF Bytecode", "comment": null, "summary": "Extended Berkeley Packet Filter (eBPF) allows developers to extend Linux kernel functionality without modifying its source code. To ensure system safety, an in-kernel safety checker, the verifier, enforces strict safety constraints (for example, a limited program size) on eBPF programs loaded into the kernel. These constraints, combined with eBPF's performance-critical use cases, make effective optimization essential. However, existing compilers (such as Clang) offer limited optimization support, and many semantics-preserving transformations are rejected by the verifier, which makes handcrafted optimization rule design both challenging and limited in effectiveness. Superoptimization overcomes the limitations of rule-based methods by automatically discovering optimal transformations, but its high computational cost limits scalability. To address this, we propose EPSO, a caching-based superoptimizer that discovers rewrite rules via offline superoptimization and reuses them to achieve high-quality optimizations with minimal runtime overhead. We evaluate EPSO on benchmarks from the Linux kernel and several eBPF-based projects, including Cilium, Katran, hXDP, Sysdig, Tetragon, and Tracee. EPSO discovers 795 rewrite rules and achieves up to 68.87 percent (average 24.37 percent) reduction in program size compared to Clang's output, outperforming the state-of-the-art BPF optimizer K2 on all benchmarks and Merlin on 92.68 percent of them. Additionally, EPSO reduces program runtime by an average of 6.60 percent, improving throughput and lowering latency in network applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86EPSO\u7f13\u5b58\u5f0f\u8d85\u7ea7\u4f18\u5316\u5668\uff0c\u65e0\u7f1d\u63d0\u5347eBPF\u4f18\u5316\u6548\u7387\u548c\u6548\u679c\uff0c\u5927\u5e45\u51cf\u5c11\u7a0b\u5e8f\u5c3a\u5bf8\u548c\u8fd0\u884c\u65f6\uff0c\u5728\u591a\u9879\u57fa\u51c6\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6848\u3002", "motivation": "eBPF\u9700\u8981\u9ad8\u6548\u4f18\u5316\uff0c\u4f46\u73b0\u6709\u7f16\u8bd1\u5668\u5982Clang\u548c\u624b\u5de5\u4f18\u5316\u89c4\u5219\u6548\u679c\u6709\u9650\uff0c\u5f88\u591a\u4f18\u5316\u4f1a\u56e0\u5185\u6838\u6821\u9a8c\u5668\u53d7\u9650\u800c\u65e0\u6cd5\u751f\u6548\u3002\u73b0\u6709\u8d85\u7ea7\u4f18\u5316\u5668\u867d\u80fd\u81ea\u52a8\u53d1\u73b0\u4f18\u5316\uff0c\u4f46\u8ba1\u7b97\u5f00\u9500\u592a\u5927\uff0c\u96be\u4ee5\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7f13\u5b58\u5f0f\u8d85\u7ea7\u4f18\u5316\u5668EPSO\uff0c\u901a\u8fc7\u79bb\u7ebf\u53d1\u73b0\u53d8\u6362\u89c4\u5219\uff0c\u5728\u7ebf\u91cd\u7528\u8fd9\u4e9b\u89c4\u5219\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u4f4e\u5f00\u9500\u7684eBPF\u7a0b\u5e8f\u4f18\u5316\u3002EPSO\u5148\u81ea\u52a8\u751f\u6210\u4f18\u5316\u89c4\u5219\uff0c\u518d\u5e94\u7528\u4e8e\u5b9e\u9645\u7f16\u8bd1\u6d41\u7a0b\u3002", "result": "EPSO\u53d1\u73b0\u4e86795\u6761\u4f18\u5316\u89c4\u5219\uff0c\u5e73\u5747\u51cf\u5c1124.37%\u7684\u7a0b\u5e8f\u4f53\u79ef\uff08\u6700\u9ad8\u8fbe68.87%\uff09\uff0c\u5728\u6240\u6709\u57fa\u51c6\u4e0a\u8d85\u8d8a\u4e86\u6700\u65b0BPF\u4f18\u5316\u5668K2\uff0c\u5e76\u572892.68%\u7684\u57fa\u51c6\u4e0a\u8d85\u8fc7Merlin\u3002\u540c\u65f6\uff0c\u5e73\u5747\u964d\u4f4e6.6%\u7684\u8fd0\u884c\u65f6\uff0c\u63d0\u9ad8\u4e86\u7f51\u7edc\u5e94\u7528\u541e\u5410\u4e0e\u964d\u4f4e\u4e86\u5ef6\u8fdf\u3002", "conclusion": "EPSO\u6709\u6548\u5730\u5e73\u8861\u4e86\u81ea\u52a8\u4f18\u5316\u7684\u9ad8\u8d28\u91cf\u4e0e\u5b9e\u9645\u53ef\u7528\u6027\uff0c\u663e\u8457\u63d0\u5347eBPF\u7a0b\u5e8f\u7684\u4f53\u79ef\u4e0e\u8fd0\u884c\u6548\u7387\uff0c\u4f18\u4e8e\u76ee\u524d\u4e3b\u6d41\u7684\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2511.15370", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15370", "abs": "https://arxiv.org/abs/2511.15370", "authors": ["Guoqiang Liang", "Jingqian Gong", "Mengxuan Li", "Gege Lin", "Shuo Zhang"], "title": "The Empowerment of Science of Science by Large Language Models: New Tools and Methods", "comment": "The manuscript is currently ongoing the underreview process of the journal of information science", "summary": "Large language models (LLMs) have exhibited exceptional capabilities in natural language understanding and generation, image recognition, and multimodal tasks, charting a course towards AGI and emerging as a central issue in the global technological race. This manuscript conducts a comprehensive review of the core technologies that support LLMs from a user standpoint, including prompt engineering, knowledge-enhanced retrieval augmented generation, fine tuning, pretraining, and tool learning. Additionally, it traces the historical development of Science of Science (SciSci) and presents a forward looking perspective on the potential applications of LLMs within the scientometric domain. Furthermore, it discusses the prospect of an AI agent based model for scientific evaluation, and presents new research fronts detection and knowledge graph building methods with LLMs.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u7efc\u8ff0\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5173\u952e\u6280\u672f\u53ca\u5176\u5728\u79d1\u5b66\u8ba1\u91cf\u5b66\u9886\u57df\u7684\u5e94\u7528\u524d\u666f\uff0c\u6db5\u76d6\u63d0\u793a\u5de5\u7a0b\u3001\u77e5\u8bc6\u589e\u5f3a\u751f\u6210\u3001\u5fae\u8c03\u7b49\uff0c\u5e76\u63d0\u51fa\u5229\u7528LLMs\u63a8\u52a8\u79d1\u5b66\u8bc4\u4ef7\u4e0e\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u7b49\u521b\u65b0\u65b9\u5411\u3002", "motivation": "\u968f\u7740LLMs\u5728\u591a\u4e2a\u9886\u57df\u8868\u73b0\u7a81\u51fa\uff0c\u63a2\u8ba8\u5176\u5e95\u5c42\u6838\u5fc3\u6280\u672f\u53ca\u672a\u6765\u5728\u79d1\u5b66\u8ba1\u91cf\u5b66\u9886\u57df\u7684\u5e94\u7528\u53d8\u5f97\u975e\u5e38\u91cd\u8981\uff0c\u4ee5\u63a8\u52a8AI\u6280\u672f\u5728\u79d1\u5b66\u8bc4\u4ef7\u4e0e\u524d\u6cbf\u7814\u7a76\u68c0\u6d4b\u7b49\u65b9\u9762\u7684\u521b\u65b0\u3002", "method": "\u4f5c\u8005\u91c7\u7528\u7efc\u5408\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u4ece\u7528\u6237\u89c6\u89d2\u7cfb\u7edf\u68b3\u7406\u4e86\u652f\u6491LLMs\u7684\u6838\u5fc3\u6280\u672f\uff0c\u5305\u62ec\u63d0\u793a\u5de5\u7a0b\u3001\u77e5\u8bc6\u589e\u5f3a\u53ca\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3001\u5fae\u8c03\u3001\u9884\u8bad\u7ec3\u548c\u5de5\u5177\u5b66\u4e60\uff0c\u540c\u65f6\u56de\u987e\u4e86\u79d1\u5b66\u8ba1\u91cf\u5b66\u7684\u53d1\u5c55\u5386\u7a0b\u3002", "result": "\u6587\u7ae0\u4e0d\u4ec5\u7efc\u8ff0\u4e86LLMs\u7684\u6838\u5fc3\u6280\u672f\uff0c\u8fd8\u5c55\u671b\u4e86\u5176\u5728\u79d1\u5b66\u8ba1\u91cf\u5b66\u9886\u57df\u7684\u5e94\u7528\uff0c\u5305\u62ecAI\u4ee3\u7406\u79d1\u5b66\u8bc4\u4ef7\u6a21\u578b\u3001\u65b0\u7814\u7a76\u524d\u6cbf\u68c0\u6d4b\u53ca\u5229\u7528LLMs\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u7684\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u8ba4\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4e0e\u751f\u6210\u3001\u56fe\u50cf\u8bc6\u522b\u548c\u591a\u6a21\u6001\u4efb\u52a1\u7b49\u65b9\u9762\u5c55\u73b0\u51fa\u5353\u8d8a\u80fd\u529b\uff0c\u6b63\u5f15\u9886\u901a\u7528\u4eba\u5de5\u667a\u80fd\uff08AGI\uff09\u7684\u53d1\u5c55\uff0c\u4e14\u5728\u5168\u7403\u79d1\u6280\u7ade\u8d5b\u4e2d\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.15665", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15665", "abs": "https://arxiv.org/abs/2511.15665", "authors": ["Huixiang Zhang", "Mahzabeen Emu"], "title": "Quantum-Guided Test Case Minimization for LLM-Based Code Generation", "comment": "This is a preprint version, full paper has been accepted in IEEE CASCON 2025 and will appear on lEEE Xplore", "summary": "Precisely controlling Large Language Models (LLMs) to generate efficient and concise code is a central challenge in software engineering. We introduce a framework based on Test-Driven Development (TDD) that transforms code specification into a combinatorial optimization task. The framework first prompts an LLM to generate a test suite, then formulates the Test Case Minimization (TCM) problem as a Quadratic Unconstrained Binary Optimization (QUBO) model. This QUBO paradigm is compatible with both classical solvers and emerging hardware such as quantum annealers. Experimentally, quantum annealing solves the core TCM task 16 times faster than simulated annealing. This performance underpins our end-to-end framework, which reduces total token consumption by 36.5\\% and significantly improves code quality. This work demonstrates a powerful synergy between generative AI and combinatorial optimization in software engineering, highlighting the critical importance of precise model formulation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u878d\u5408TDD\u548c\u7ec4\u5408\u4f18\u5316\uff08QUBO\u3001\u91cf\u5b50\u9000\u706b\uff09\u7684\u65b0\u6846\u67b6\uff0c\u5927\u5e45\u51cf\u5c11token\u6d88\u8017\u548c\u63d0\u9ad8\u4ee3\u7801\u8d28\u91cf\uff0c\u9a8c\u8bc1\u4e86\u751f\u6210\u5f0fAI\u4e0e\u91cf\u5b50\u8ba1\u7b97\u6280\u672f\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u4f18\u52bf\u548c\u524d\u666f\u3002", "motivation": "\u76ee\u524d\uff0c\u5982\u4f55\u7cbe\u786e\u63a7\u5236\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u9ad8\u6548\u7b80\u6d01\u7684\u4ee3\u7801\uff0c\u662f\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u6838\u5fc3\u96be\u9898\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u65b0\u7684\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4ee3\u7801\u8d28\u91cf\u5e76\u964d\u4f4e\u751f\u6210\u6210\u672c\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6d4b\u8bd5\u9a71\u52a8\u5f00\u53d1\uff08TDD\uff09\u7684\u6846\u67b6\uff0c\u9996\u5148\u63d0\u793aLLM\u751f\u6210\u6d4b\u8bd5\u5957\u4ef6\uff0c\u7136\u540e\u5c06\u6d4b\u8bd5\u7528\u4f8b\u6700\u5c0f\u5316\uff08TCM\uff09\u95ee\u9898\u5efa\u6a21\u4e3aQUBO\uff08\u4e8c\u6b21\u65e0\u7ea6\u675f\u4e8c\u8fdb\u5236\u4f18\u5316\uff09\u95ee\u9898\uff0c\u517c\u5bb9\u7ecf\u5178\u4e0e\u91cf\u5b50\u9000\u706b\u6c42\u89e3\u5668\u3002", "result": "\u91cf\u5b50\u9000\u706b\u5728TCM\u6838\u5fc3\u4efb\u52a1\u4e0a\u6bd4\u6a21\u62df\u9000\u706b\u5feb16\u500d\u3002\u6574\u4f53\u6846\u67b6\u80fd\u51cf\u5c1136.5%\u7684token\u6d88\u8017\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\u3002", "conclusion": "\u672c\u5de5\u4f5c\u5c55\u73b0\u4e86\u751f\u6210\u5f0fAI\u4e0e\u7ec4\u5408\u4f18\u5316\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5f3a\u5927\u534f\u540c\u6548\u5e94\uff0c\u5f3a\u8c03\u4e86\u7cbe\u786e\u6a21\u578b\u6784\u5efa\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.15383", "categories": ["cs.CL", "cs.AI", "cs.ET", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.15383", "abs": "https://arxiv.org/abs/2511.15383", "authors": ["Byungho Jo"], "title": "A Compliance-Preserving Retrieval System for Aircraft MRO Task Search", "comment": null, "summary": "Aircraft Maintenance Technicians (AMTs) spend up to 30% of work time searching manuals, a documented efficiency bottleneck in MRO operations where every procedure must be traceable to certified sources. We present a compliance-preserving retrieval system that adapts LLM reranking and semantic search to aviation MRO environments by operating alongside, rather than replacing, certified legacy viewers. The system constructs revision-robust embeddings from ATA chapter hierarchies and uses vision-language parsing to structure certified content, allowing technicians to preview ranked tasks and access verified procedures in existing viewers. Evaluation on 49k synthetic queries achieves >90% retrieval accuracy, while bilingual controlled studies with 10 licensed AMTs demonstrate 90.9% top-10 success rate and 95% reduction in lookup time, from 6-15 minutes to 18 seconds per task. These gains provide concrete evidence that semantic retrieval can operate within strict regulatory constraints and meaningfully reduce operational workload in real-world multilingual MRO workflows.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u98de\u673a\u7ef4\u4fee\u6280\u672f\u5458\u67e5\u627e\u624b\u518c\u4f4e\u6548\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u7ed3\u5408LLM\u91cd\u6392\u4e0e\u8bed\u4e49\u68c0\u7d22\u7684\u65b0\u7cfb\u7edf\uff0c\u80fd\u591f\u5728\u4e0d\u66ff\u6362\u539f\u6709\u8ba4\u8bc1\u5e73\u53f0\u7684\u524d\u63d0\u4e0b\uff0c\u5927\u5e45\u63d0\u5347\u67e5\u627e\u51c6\u786e\u7387\u548c\u6548\u7387\uff0c\u5e76\u7b26\u5408\u884c\u4e1a\u5408\u89c4\u8981\u6c42\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u7cfb\u7edf\u80fd\u5c06\u6d41\u7a0b\u67e5\u627e\u65f6\u95f4\u5927\u5e45\u7f29\u77ed\u81f3\u79d2\u7ea7\uff0c\u6709\u6548\u8f85\u4f50AMT\u63d0\u5347\u5de5\u4f5c\u6548\u7387\u3002", "motivation": "\u98de\u673a\u7ef4\u4fee\u6280\u672f\u5458\uff08AMT\uff09\u82b1\u8d39\u9ad8\u8fbe30%\u7684\u5de5\u4f5c\u65f6\u95f4\u5728\u67e5\u627e\u624b\u518c\u4e0a\uff0c\u8fd9\u4e25\u91cd\u5f71\u54cd\u4e86\u7ef4\u62a4\u3001\u4fee\u7406\u548c\u5927\u4fee\uff08MRO\uff09\u64cd\u4f5c\u7684\u6548\u7387\uff0c\u800c\u6240\u6709\u7a0b\u5e8f\u90fd\u5fc5\u987b\u8ffd\u6eaf\u5230\u8ba4\u8bc1\u6765\u6e90\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5408\u89c4\u6027\u4fdd\u5b58\u7684\u68c0\u7d22\u7cfb\u7edf\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u91cd\u6392\u548c\u8bed\u4e49\u641c\u7d22\u65b9\u6cd5\u9002\u5e94\u4e8e\u822a\u7a7aMRO\u73af\u5883\u3002\u8be5\u7cfb\u7edf\u5e76\u4e0d\u66ff\u6362\u5df2\u6709\u7684\u8ba4\u8bc1\u67e5\u770b\u5668\uff0c\u800c\u662f\u4e0e\u5176\u534f\u540c\u5de5\u4f5c\uff0c\u901a\u8fc7ATA\u7ae0\u8282\u7ed3\u6784\u521b\u5efa\u5177\u5907\u4fee\u8ba2\u9c81\u68d2\u6027\u7684\u5d4c\u5165\uff0c\u540c\u65f6\u5229\u7528\u89c6\u89c9-\u8bed\u8a00\u89e3\u6790\u65b9\u6cd5\u7ed3\u6784\u5316\u8ba4\u8bc1\u5185\u5bb9\uff0c\u8ba9\u6280\u672f\u5458\u9884\u89c8\u6392\u5e8f\u4efb\u52a1\uff0c\u5e76\u53ef\u5728\u539f\u8ba4\u8bc1\u67e5\u770b\u5668\u4e2d\u8bbf\u95ee\u5df2\u9a8c\u8bc1\u7684\u6d41\u7a0b\u3002", "result": "\u572849,000\u4e2a\u5408\u6210\u67e5\u8be2\u4e0a\u7684\u8bc4\u4f30\u83b7\u5f97\u4e86\u8d85\u8fc790%\u7684\u68c0\u7d22\u51c6\u786e\u7387\u3002\u4e0e10\u540d\u6301\u8bc1AMT\u8fdb\u884c\u7684\u53cc\u8bed\u5bf9\u7167\u5b9e\u9a8c\uff0c\u524d\u5341\u6761\u68c0\u7d22\u547d\u4e2d\u7387\u8fbe\u523090.9%\uff0c\u67e5\u627e\u65f6\u95f4\u4ece\u539f\u6765\u76846-15\u5206\u949f\u51cf\u5c11\u81f3\u6bcf\u9879\u4efb\u52a1\u4ec5\u970018\u79d2\uff0c\u6548\u7387\u63d0\u5347\u8fbe95%\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0c\u8bed\u4e49\u68c0\u7d22\u7cfb\u7edf\u53ef\u5728\u4e25\u683c\u76d1\u7ba1\u8981\u6c42\u4e0b\u5b9e\u9645\u8fd0\u884c\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u591a\u8bed\u79cdMRO\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u64cd\u4f5c\u8d1f\u62c5\u3002"}}
{"id": "2511.15392", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15392", "abs": "https://arxiv.org/abs/2511.15392", "authors": ["Sirui Chen", "Mengshi Zhao", "Lei Xu", "Yuying Zhao", "Beier Zhu", "Hanwang Zhang", "Shengjie Zhao", "Chaochao Lu"], "title": "DEPO: Dual-Efficiency Preference Optimization for LLM Agents", "comment": "Accepted to AAAI 2026", "summary": "Recent advances in large language models (LLMs) have greatly improved their reasoning and decision-making abilities when deployed as agents. Richer reasoning, however, often comes at the cost of longer chain of thought (CoT), hampering interaction efficiency in real-world scenarios. Nevertheless, there still lacks systematic definition of LLM agent efficiency, hindering targeted improvements. To this end, we introduce dual-efficiency, comprising (i) step-level efficiency, which minimizes tokens per step, and (ii) trajectory-level efficiency, which minimizes the number of steps to complete a task. Building on this definition, we propose DEPO, a dual-efficiency preference optimization method that jointly rewards succinct responses and fewer action steps. Experiments on WebShop and BabyAI show that DEPO cuts token usage by up to 60.9% and steps by up to 26.9%, while achieving up to a 29.3% improvement in performance. DEPO also generalizes to three out-of-domain math benchmarks and retains its efficiency gains when trained on only 25% of the data. Our project page is at https://opencausalab.github.io/DEPO.", "AI": {"tldr": "\u8bba\u6587\u9996\u6b21\u660e\u786e\u63d0\u51faLLM\u667a\u80fd\u4f53\u6548\u7387\u7684\u53cc\u91cd\u5b9a\u4e49\uff0c\u5e76\u636e\u6b64\u63d0\u51faDEPO\u4f18\u5316\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u660e\u663e\u51cf\u5c11\u4ee4\u724c\u548c\u6b65\u9aa4\u6d88\u8017\uff0c\u540c\u65f6\u63d0\u5347\u6574\u4f53\u6027\u80fd\u4e0e\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f5c\u4e3a\u667a\u80fd\u4f53\u5728\u63a8\u7406\u548c\u51b3\u7b56\u65b9\u9762\u53d6\u5f97\u4e86\u91cd\u5927\u8fdb\u5c55\uff0c\u4f46\u66f4\u4e30\u5bcc\u7684\u63a8\u7406\u8fc7\u7a0b\u5f80\u5f80\u5bfc\u81f4\u63a8\u7406\u94fe\u6761\u53d8\u957f\uff0c\u964d\u4f4e\u4e86\u5b9e\u9645\u4ea4\u4e92\u6548\u7387\u3002\u540c\u65f6\uff0c\u76ee\u524d\u8fd8\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684LLM\u667a\u80fd\u4f53\u6548\u7387\u5b9a\u4e49\uff0c\u9650\u5236\u4e86\u6709\u9488\u5bf9\u6027\u7684\u4f18\u5316\u65b9\u6cd5\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u4e86\u201c\u53cc\u91cd\u6548\u7387\u201d\uff08dual-efficiency\uff09\u6982\u5ff5\uff0c\u5305\u62ec\u6b65\u9aa4\u7ea7\u6548\u7387\uff08\u51cf\u5c11\u6bcf\u6b65\u4ee4\u724c\u6570\u91cf\uff09\u4e0e\u8f68\u8ff9\u7ea7\u6548\u7387\uff08\u51cf\u5c11\u5b8c\u6210\u4efb\u52a1\u7684\u6b65\u9aa4\u6570\uff09\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u4e86DEPO\u7b97\u6cd5\uff1a\u4e00\u79cd\u7efc\u5408\u9f13\u52b1\u56de\u590d\u7b80\u7ec3\u4e0e\u6b65\u9aa4\u66f4\u5c11\u7684\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u3002", "result": "\u5728WebShop\u548cBabyAI\u5b9e\u9a8c\u4e2d\uff0cDEPO\u80fd\u5c06\u4ee4\u724c\u4f7f\u7528\u51cf\u5c11\u6700\u591a60.9%\uff0c\u6b65\u9aa4\u6570\u51cf\u5c11\u6700\u591a26.9%\uff0c\u5e76\u4f7f\u6027\u80fd\u6700\u9ad8\u63d0\u534729.3%\u3002\u6b64\u5916\uff0cDEPO\u5728\u4e09\u4e2a\u6570\u5b66\u9886\u57df\u5916\u6570\u636e\u96c6\u4e0a\u4e5f\u8868\u73b0\u51fa\u826f\u597d\u6cdb\u5316\uff0c\u5728\u4ec5\u4f7f\u752825%\u8bad\u7ec3\u6570\u636e\u65f6\u4ecd\u4fdd\u6301\u6548\u7387\u4f18\u52bf\u3002", "conclusion": "\u7cfb\u7edf\u6027\u63d0\u51fa\u5e76\u5b9a\u4e49\u4e86LLM\u667a\u80fd\u4f53\u6548\u7387\u7684\u4e24\u5c42\u7ef4\u5ea6\uff0c\u5e76\u4ee5\u6b64\u4e3a\u57fa\u7840\u8bbe\u8ba1\u51faDEPO\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u63a8\u7406\u6548\u7387\u548c\u4efb\u52a1\u5b8c\u6210\u8868\u73b0\uff0c\u5e76\u5177\u5907\u8f83\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2511.15408", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.MA", "cs.NE"], "pdf": "https://arxiv.org/pdf/2511.15408", "abs": "https://arxiv.org/abs/2511.15408", "authors": ["Shanlin Zhou", "Xinpeng Wang", "Jianxun Lian", "Zhenghao Liu", "Laks V. S. Lakshmanan", "Xiaoyuan Yi", "Yongtao Hao"], "title": "NAMeGEn: Creative Name Generation via A Novel Agent-based Multiple Personalized Goal Enhancement Framework", "comment": "13 pages,9 figures. This work has been submitted to the IEEE for possible publication", "summary": "Trained on diverse human-authored texts, Large Language Models (LLMs) unlocked the potential for Creative Natural Language Generation (CNLG), benefiting various applications like advertising and storytelling. Nevertheless, CNLG still remains difficult due to two main challenges. (1) Multi-objective flexibility: user requirements are often personalized, fine-grained, and pluralistic, which LLMs struggle to satisfy simultaneously; (2) Interpretive complexity: beyond generation, creativity also involves understanding and interpreting implicit meaning to enhance users' perception. These challenges significantly limit current methods, especially in short-form text generation, in generating creative and insightful content. To address this, we focus on Chinese baby naming, a representative short-form CNLG task requiring adherence to explicit user constraints (e.g., length, semantics, anthroponymy) while offering meaningful aesthetic explanations. We propose NAMeGEn, a novel multi-agent optimization framework that iteratively alternates between objective extraction, name generation, and evaluation to meet diverse requirements and generate accurate explanations. To support this task, we further construct a classical Chinese poetry corpus with 17k+ poems to enhance aesthetics, and introduce CBNames, a new benchmark with tailored metrics. Extensive experiments demonstrate that NAMeGEn effectively generates creative names that meet diverse, personalized requirements while providing meaningful explanations, outperforming six baseline methods spanning various LLM backbones without any training.", "AI": {"tldr": "\u8bba\u6587\u9488\u5bf9\u77ed\u6587\u672c\u521b\u610f\u751f\u6210\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u591a\u667a\u80fd\u4f53\u4f18\u5316\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u65b0\u6570\u636e\u96c6\u548c\u6307\u6807\u9a8c\u8bc1\uff0c\u5728\u4e2d\u6587\u8d77\u540d\u4efb\u52a1\u4e0a\u53d6\u5f97\u4f18\u5f02\u7ed3\u679c\u3002", "motivation": "\u76ee\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5df2\u89e3\u9501\u81ea\u7136\u8bed\u8a00\u521b\u610f\u751f\u6210\uff08CNLG\uff09\u7684\u6f5c\u529b\uff0c\u4f46\u77ed\u6587\u672c\u7684\u521b\u610f\u751f\u6210\u4ecd\u9762\u4e34\u591a\u76ee\u6807\u7075\u6d3b\u6027\u4e0e\u89e3\u91ca\u590d\u6742\u6027\u4e24\u5927\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86NAMeGEn\u591a\u667a\u80fd\u4f53\u4f18\u5316\u6846\u67b6\uff0c\u4ea4\u66ff\u8fdb\u884c\u76ee\u6807\u63d0\u53d6\u3001\u59d3\u540d\u751f\u6210\u548c\u8bc4\u4f30\uff1b\u6784\u5efa\u4e86\u4e2d\u56fd\u53e4\u8bd7\u8bcd\u5e93\uff0817k+\u9996\u8bd7\uff09\u63d0\u5347\u5ba1\u7f8e\uff0c\u5e76\u63a8\u51faCBNames\u8bc4\u6d4b\u57fa\u51c6\u4e0e\u5b9a\u5236\u6307\u6807\u3002", "result": "NAMeGEn\u80fd\u6709\u6548\u6ee1\u8db3\u591a\u6837\u5316\u4e2a\u6027\u5316\u9700\u6c42\uff0c\u751f\u6210\u5bcc\u6709\u521b\u610f\u4e14\u6709\u89e3\u91ca\u7684\u59d3\u540d\uff0c\u5728\u516d\u79cd\u4e3b\u6d41\u65e0\u8bad\u7ec3\u57fa\u7ebf\u65b9\u6cd5\u4e2d\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e86\u77ed\u6587\u672c\u521b\u610f\u751f\u6210\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u4e2a\u6027\u5316\u3001\u6709\u89e3\u91ca\u7684\u4e2d\u6587\u8d77\u540d\u4efb\u52a1\u5e26\u6765\u4e86\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2511.15418", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15418", "abs": "https://arxiv.org/abs/2511.15418", "authors": ["Arjun Gangwar", "Kaousheik Jayakumar", "S. Umesh"], "title": "Building Robust and Scalable Multilingual ASR for Indian Languages", "comment": null, "summary": "This paper describes the systems developed by SPRING Lab, Indian Institute of Technology Madras, for the ASRU MADASR 2.0 challenge. The systems developed focuses on adapting ASR systems to improve in predicting the language and dialect of the utterance among 8 languages across 33 dialects. We participated in Track 1 and Track 2, which restricts the use of additional data and develop from-the-scratch multilingual systems. We presented a novel training approach using Multi-Decoder architecture with phonemic Common Label Set (CLS) as intermediate representation. It improved the performance over the baseline (in the CLS space). We also discuss various methods used to retain the gain obtained in the phonemic space while converting them back to the corresponding grapheme representations. Our systems beat the baseline in 3 languages (Track 2) in terms of WER/CER and achieved the highest language ID and dialect ID accuracy among all participating teams (Track 2).", "AI": {"tldr": "\u63d0\u51fa\u591a\u89e3\u7801\u5668\u67b6\u6784\u548c\u97f3\u7d20\u5171\u540c\u6807\u7b7e\u4e2d\u95f4\u8868\u793a\uff0c\u63d0\u5347\u4e86\u591a\u8bed\u8a00\u591a\u65b9\u8a00ASR\u7cfb\u7edf\u5728\u53d7\u9650\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\uff0c\u8bed\u8a00\u548c\u65b9\u8a00\u8bc6\u522b\u51c6\u786e\u7387\u6700\u9ad8\uff0c\u90e8\u5206\u8bed\u8a00WER/CER\u8d85\u8d8a\u57fa\u7ebf\u3002", "motivation": "\u591a\u8bed\u79cd\u591a\u65b9\u8a00\u573a\u666f\u4e0b\uff0cASR\u7cfb\u7edf\u96be\u4ee5\u51c6\u786e\u533a\u5206\u548c\u8f6c\u6362\u8bed\u8a00\u4e0e\u65b9\u8a00\uff1b\u800c\u6570\u636e\u53d7\u9650\u548c\u7cfb\u7edf\u9700\u4ece\u96f6\u5f00\u53d1\uff0c\u63a8\u52a8\u65b0\u65b9\u6cd5\u6765\u63d0\u9ad8\u8bc6\u522b\u548c\u8f6c\u6362\u51c6\u786e\u7387\u3002", "method": "\u91c7\u7528\u591a\u89e3\u7801\u5668\uff08Multi-Decoder\uff09\u67b6\u6784\uff0c\u5229\u7528\u97f3\u7d20\u5171\u540c\u6807\u7b7e\u96c6\uff08CLS\uff09\u4f5c\u4e3a\u4e2d\u95f4\u5c42\u6765\u8bad\u7ec3ASR\u7cfb\u7edf\uff0c\u5728CLS\u7a7a\u95f4\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u63a2\u7d22\u6807\u7b7e\u4ece\u97f3\u7d20\u56de\u5230\u5b57\u7d20\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "result": "SPRING Lab\u63d0\u51fa\u4e86\u4e00\u5957\u7528\u4e8eASRU MADASR 2.0\u6311\u6218\u7684\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u7cfb\u7edf\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u4e13\u6ce8\u4e8e\u63d0\u5347\u8de88\u79cd\u8bed\u8a0033\u4e2a\u65b9\u8a00\u7684\u8bed\u8a00\u548c\u65b9\u8a00\u8bc6\u522b\u80fd\u529b\u3002\u5728\u53d7\u9650\u6761\u4ef6\uff08\u4e0d\u80fd\u4f7f\u7528\u989d\u5916\u6570\u636e\uff09\u7684Track 1\u548cTrack 2\u4e2d\uff0c\u56e2\u961f\u5f00\u53d1\u4e86\u591a\u8bed\u8a00ASR\u7cfb\u7edf\u3002\u6838\u5fc3\u521b\u65b0\u662f\u63d0\u51fa\u4e86\u591a\u89e3\u7801\u5668\uff08Multi-Decoder\uff09\u67b6\u6784\uff0c\u5e76\u91c7\u7528\u97f3\u7d20\u5171\u540c\u6807\u7b7e\u96c6\uff08CLS\uff09\u4f5c\u4e3a\u4e2d\u95f4\u8868\u793a\uff0c\u4ece\u800c\u63d0\u5347\u4e86\u7cfb\u7edf\u5728CLS\u7a7a\u95f4\u4e2d\u7684\u8868\u73b0\u3002\u8bba\u6587\u8fd8\u8ba8\u8bba\u4e86\u5982\u4f55\u5728\u5c06CLS\u8868\u793a\u8f6c\u56de\u5b57\u7d20\u65f6\u4fdd\u7559\u6027\u80fd\u63d0\u5347\u3002\u6700\u7ec8\uff0c\u7cfb\u7edf\u57283\u79cd\u8bed\u8a00\uff08Track 2\uff09\u4e0a\u8d85\u8d8a\u4e86\u57fa\u7ebf\u7cfb\u7edf\uff0c\u5e76\u5728\u8bed\u8a00\u8bc6\u522b\u548c\u65b9\u8a00\u8bc6\u522b\u4e0a\u53d6\u5f97\u4e86\u6700\u9ad8\u51c6\u786e\u7387\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4fdd\u6301\u6027\u80fd\u63d0\u5347\u7684\u540c\u65f6\uff0c\u80fd\u6709\u6548\u63d0\u5347\u591a\u8bed\u8a00ASR\u7cfb\u7edf\u7684\u8bed\u8a00\u548c\u65b9\u8a00\u533a\u5206\u80fd\u529b\uff0c\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u7cfb\u7edf\uff0c\u5e76\u5728\u6311\u6218\u4e2d\u53d6\u5f97\u6700\u4f73\u8bc6\u522b\u51c6\u786e\u7387\u3002"}}
{"id": "2511.15424", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15424", "abs": "https://arxiv.org/abs/2511.15424", "authors": ["Yuanjie Zhu", "Liangwei Yang", "Ke Xu", "Weizhi Zhang", "Zihe Song", "Jindong Wang", "Philip S. Yu"], "title": "LLM-MemCluster: Empowering Large Language Models with Dynamic Memory for Text Clustering", "comment": null, "summary": "Large Language Models (LLMs) are reshaping unsupervised learning by offering an unprecedented ability to perform text clustering based on their deep semantic understanding. However, their direct application is fundamentally limited by a lack of stateful memory for iterative refinement and the difficulty of managing cluster granularity. As a result, existing methods often rely on complex pipelines with external modules, sacrificing a truly end-to-end approach. We introduce LLM-MemCluster, a novel framework that reconceptualizes clustering as a fully LLM-native task. It leverages a Dynamic Memory to instill state awareness and a Dual-Prompt Strategy to enable the model to reason about and determine the number of clusters. Evaluated on several benchmark datasets, our tuning-free framework significantly and consistently outperforms strong baselines. LLM-MemCluster presents an effective, interpretable, and truly end-to-end paradigm for LLM-based text clustering.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLLM-MemCluster\u6846\u67b6\uff0c\u89e3\u51b3\u4e86LLM\u505a\u6587\u672c\u805a\u7c7b\u65f6\u7f3a\u5c11\u8bb0\u5fc6\u548c\u96be\u4ee5\u786e\u5b9a\u805a\u7c7b\u6570\u91cf\u7684\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u5916\u90e8\u6a21\u5757\u5373\u53ef\u5b9e\u73b0\u7aef\u5230\u7aef\u805a\u7c7b\uff0c\u5e76\u5728\u591a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6587\u672c\u805a\u7c7b\u53d7\u5230\u6a21\u578b\u7f3a\u4e4f\u72b6\u6001\u8bb0\u5fc6\u4e0e\u805a\u7c7b\u7c92\u5ea6\u96be\u4ee5\u7ba1\u63a7\u7684\u9650\u5236\uff0c\u5bfc\u81f4\u73b0\u6709\u65b9\u6848\u4f9d\u8d56\u590d\u6742\u7ec4\u4ef6\uff0c\u65e0\u6cd5\u7aef\u5230\u7aef\uff0c\u9700\u89e3\u51b3\u8fd9\u4e00\u75db\u70b9\u3002", "method": "\u63d0\u51faLLM-MemCluster\u6846\u67b6\uff0c\u5229\u7528\u52a8\u6001\u8bb0\u5fc6\u673a\u5236\u8d4b\u4e88\u6a21\u578b\u72b6\u6001\u611f\u77e5\u80fd\u529b\uff0c\u7528\u53cc\u63d0\u793a\u7b56\u7565\u8ba9\u6a21\u578b\u81ea\u4e3b\u63a8\u7406\u548c\u51b3\u5b9a\u805a\u7c7b\u6570\u91cf\uff0c\u6574\u4e2a\u65b9\u6cd5\u65e0\u987b\u8c03\u53c2\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cLLM-MemCluster\u65e0\u987b\u8c03\u53c2\u4e14\u5728\u5404\u9879\u6307\u6807\u4e0a\u660e\u663e\u4f18\u4e8e\u4f20\u7edf\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "LLM-MemCluster\u6846\u67b6\u5728\u6587\u672c\u805a\u7c7b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u771f\u6b63\u7aef\u5230\u7aef\u5e76\u4e14\u53ef\u89e3\u91ca\u7684\u805a\u7c7b\u65b9\u5f0f\uff0c\u4e14\u6027\u80fd\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2511.15512", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15512", "abs": "https://arxiv.org/abs/2511.15512", "authors": ["Yves Pauli", "Jan-Bernard Marsman", "Finn Rabe", "Victoria Edkins", "Roya H\u00fcppi", "Silvia Ciampelli", "Akhil Ratan Misra", "Nils Lang", "Wolfram Hinzen", "Iris Sommer", "Philipp Homan"], "title": "Standardising the NLP Workflow: A Framework for Reproducible Linguistic Analysis", "comment": "26 pages, 3 figures", "summary": "The introduction of large language models and other influential developments in AI-based language processing have led to an evolution in the methods available to quantitatively analyse language data. With the resultant growth of attention on language processing, significant challenges have emerged, including the lack of standardisation in organising and sharing linguistic data and the absence of standardised and reproducible processing methodologies. Striving for future standardisation, we first propose the Language Processing Data Structure (LPDS), a data structure inspired by the Brain Imaging Data Structure (BIDS), a widely adopted standard for handling neuroscience data. It provides a folder structure and file naming conventions for linguistic research. Second, we introduce pelican nlp, a modular and extensible Python package designed to enable streamlined language processing, from initial data cleaning and task-specific preprocessing to the extraction of sophisticated linguistic and acoustic features, such as semantic embeddings and prosodic metrics. The entire processing workflow can be specified within a single, shareable configuration file, which pelican nlp then executes on LPDS-formatted data. Depending on the specifications, the reproducible output can consist of preprocessed language data or standardised extraction of both linguistic and acoustic features and corresponding result aggregations. LPDS and pelican nlp collectively offer an end-to-end processing pipeline for linguistic data, designed to ensure methodological transparency and enhance reproducibility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u8bed\u8a00\u5b66\u6570\u636e\u6807\u51c6\u5316\u7ed3\u6784\uff08LPDS\uff09\u53ca\u914d\u5957Python\u5305\uff08pelican nlp\uff09\uff0c\u89e3\u51b3\u4e86\u8bed\u8a00\u6570\u636e\u7ba1\u7406\u548c\u5904\u7406\u65e0\u6807\u51c6\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6d41\u7a0b\u900f\u660e\u548c\u7ed3\u679c\u53ef\u590d\u73b0\uff0c\u5bf9\u8bed\u8a00\u5904\u7406\u7814\u7a76\u5177\u6709\u91cd\u8981\u63a8\u52a8\u4f5c\u7528\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u548c\u4eba\u5de5\u667a\u80fd\u5728\u8bed\u8a00\u5904\u7406\u9886\u57df\u7684\u8fdb\u6b65\uff0c\u4f7f\u5f97\u91cf\u5316\u5206\u6790\u8bed\u8a00\u6570\u636e\u7684\u65b9\u6cd5\u4e0d\u65ad\u6f14\u5316\uff0c\u7136\u800c\u968f\u4e4b\u800c\u6765\u7684\u6311\u6218\u5305\u62ec\u8bed\u8a00\u6570\u636e\u7684\u7ec4\u7ec7\u3001\u5206\u4eab\u7f3a\u4e4f\u6807\u51c6\u5316\uff0c\u4ee5\u53ca\u5904\u7406\u65b9\u6cd5\u96be\u4ee5\u6807\u51c6\u5316\u548c\u590d\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u53d7\u8111\u6210\u50cf\u6570\u636e\u7ed3\u6784\uff08BIDS\uff09\u542f\u53d1\u7684\u8bed\u8a00\u5904\u7406\u6570\u636e\u7ed3\u6784\uff08LPDS\uff09\uff0c\u7528\u4e8e\u89c4\u8303\u8bed\u8a00\u5b66\u7814\u7a76\u4e2d\u7684\u6587\u4ef6\u5939\u7ed3\u6784\u548c\u6587\u4ef6\u547d\u540d\u3002\u540c\u65f6\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u7684Python\u5305pelican nlp\uff0c\u5b9e\u73b0\u4ece\u6570\u636e\u6e05\u6d17\u3001\u9884\u5904\u7406\u5230\u63d0\u53d6\u590d\u6742\u7684\u8bed\u8a00\u548c\u58f0\u5b66\u7279\u5f81\u7684\u5168\u6d41\u7a0b\u7ba1\u7406\u3002\u6574\u4e2a\u6d41\u7a0b\u53ef\u901a\u8fc7\u5355\u4e00\u4e14\u53ef\u5206\u4eab\u7684\u914d\u7f6e\u6587\u4ef6\u89c4\u5b9a\uff0c\u5e76\u81ea\u52a8\u6267\u884c\u4e8eLPDS\u683c\u5f0f\u7684\u6570\u636e\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u9884\u5904\u7406\u8bed\u8a00\u6570\u636e\uff0c\u6216\u63d0\u53d6\u6807\u51c6\u5316\u7684\u8bed\u8a00\u53ca\u58f0\u5b66\u7279\u5f81\uff0c\u5e76\u8fdb\u884c\u7ed3\u679c\u6574\u7406\u6c47\u603b\u3002LPDS\u4e0epelican nlp\u7ed3\u5408\uff0c\u5f62\u6210\u4e86\u7aef\u5230\u7aef\u7684\u8bed\u8a00\u5b66\u6570\u636e\u5904\u7406\u7ba1\u7ebf\uff0c\u63d0\u5347\u4e86\u65b9\u6cd5\u7684\u900f\u660e\u6027\u548c\u7ed3\u679c\u7684\u53ef\u590d\u73b0\u6027\u3002", "conclusion": "LPDS\u548cpelican nlp\u5171\u540c\u4e3a\u8bed\u8a00\u5b66\u6570\u636e\u7684\u7ec4\u7ec7\u3001\u5904\u7406\u548c\u7279\u5f81\u63d0\u53d6\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u3001\u900f\u660e\u548c\u53ef\u590d\u73b0\u7684\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u8bed\u8a00\u5b66\u7814\u7a76\u7684\u6570\u636e\u6807\u51c6\u5316\u548c\u65b9\u6cd5\u53ef\u590d\u73b0\u5316\u3002"}}
{"id": "2511.15552", "categories": ["cs.CL", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.15552", "abs": "https://arxiv.org/abs/2511.15552", "authors": ["Artem Chervyakov", "Ulyana Isaeva", "Anton Emelyanov", "Artem Safin", "Maria Tikhonova", "Alexander Kharitonov", "Yulia Lyakh", "Petr Surovtsev", "Denis Shevelev Vildan Saburov", "Vasily Konovalov", "Elisei Rykov", "Ivan Sviridov", "Amina Miftakhova", "Ilseyar Alimova", "Alexander Panchenko", "Alexander Kapitanov", "Alena Fenogenova"], "title": "Multimodal Evaluation of Russian-language Architectures", "comment": null, "summary": "Multimodal large language models (MLLMs) are currently at the center of research attention, showing rapid progress in scale and capabilities, yet their intelligence, limitations, and risks remain insufficiently understood. To address these issues, particularly in the context of the Russian language, where no multimodal benchmarks currently exist, we introduce Mera Multi, an open multimodal evaluation framework for Russian-spoken architectures. The benchmark is instruction-based and encompasses default text, image, audio, and video modalities, comprising 18 newly constructed evaluation tasks for both general-purpose models and modality-specific architectures (image-to-text, video-to-text, and audio-to-text). Our contributions include: (i) a universal taxonomy of multimodal abilities; (ii) 18 datasets created entirely from scratch with attention to Russian cultural and linguistic specificity, unified prompts, and metrics; (iii) baseline results for both closed-source and open-source models; (iv) a methodology for preventing benchmark leakage, including watermarking and licenses for private sets. While our current focus is on Russian, the proposed benchmark provides a replicable methodology for constructing multimodal benchmarks in typologically diverse languages, particularly within the Slavic language family.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u4fc4\u8bed\u9886\u57df\u7f3a\u4e4f\u591a\u6a21\u6001\u5927\u6a21\u578b\u8bc4\u6d4b\u57fa\u51c6\u95ee\u9898\uff0c\u63d0\u51faMera Multi\u6846\u67b6\uff0c\u8986\u76d6\u6587\u672c\u3001\u56fe\u50cf\u3001\u97f3\u9891\u548c\u89c6\u9891\uff0c\u63d0\u4f9b\u7edf\u4e00\u4efb\u52a1\u4e0e\u8bc4\u6d4b\u65b9\u6cd5\uff0c\u4e3a\u4fc4\u8bed\u53ca\u5176\u4ed6\u7c7b\u578b\u8bed\u8a00\u7684\u591a\u6a21\u6001\u7814\u7a76\u5960\u5b9a\u57fa\u51c6\u548c\u65b9\u6cd5\u57fa\u7840\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u5176\u667a\u80fd\u3001\u5c40\u9650\u53ca\u98ce\u9669\u4ecd\u7f3a\u4e4f\u6df1\u5165\u7406\u89e3\uff0c\u5c24\u5176\u662f\u4fc4\u8bed\u9886\u57df\u7f3a\u4e4f\u76f8\u5173\u8bc4\u6d4b\u57fa\u51c6\u3002", "method": "\u63d0\u51fa\u4e86Mera Multi\uff0c\u4e00\u4e2a\u9762\u5411\u4fc4\u8bed\u7684\u5f00\u653e\u591a\u6a21\u6001\u8bc4\u6d4b\u6846\u67b6\u3002\u8be5\u57fa\u51c6\u57fa\u4e8e\u6307\u4ee4\uff0c\u8986\u76d6\u6587\u672c\u3001\u56fe\u7247\u3001\u97f3\u9891\u4e0e\u89c6\u9891\u7b49\u6a21\u6001\uff0c\u5305\u542b18\u4e2a\u65b0\u6784\u5efa\u7684\u8bc4\u6d4b\u4efb\u52a1\uff0c\u9002\u7528\u4e8e\u901a\u7528\u53ca\u6a21\u6001\u7279\u5b9a\u6a21\u578b\u3002\u5e76\u63d0\u51fa\u4e86\u9632\u6b62\u6570\u636e\u6cc4\u6f0f\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u6c34\u5370\u53ca\u6388\u6743\u673a\u5236\u3002", "result": "\u8d21\u732e\u5305\u62ec\uff1a\uff081\uff09\u591a\u6a21\u6001\u80fd\u529b\u901a\u7528\u5206\u7c7b\u4f53\u7cfb\uff1b\uff082\uff09\u5b8c\u5168\u81ea\u4e3b\u521b\u5efa\u768418\u4e2a\u4fc4\u8bed\u6587\u5316\u4e0e\u8bed\u8a00\u7279\u8272\u7684\u6570\u636e\u96c6\uff0c\u7edf\u4e00\u7684\u8bc4\u6d4b\u65b9\u6cd5\u4e0e\u6307\u6807\uff1b\uff083\uff09\u95ed\u6e90\u4e0e\u5f00\u6e90\u6a21\u578b\u7684\u57fa\u7ebf\u7ed3\u679c\uff1b\uff084\uff09\u9632benchmark\u6cc4\u9732\u7684\u65b9\u6cd5\u3002", "conclusion": "\u867d\u5f53\u524d\u805a\u7126\u4fc4\u8bed\uff0c\u6240\u63d0\u65b9\u6cd5\u53ef\u590d\u5236\u4e8e\u591a\u6837\u8bed\u8a00\uff0c\u5c24\u5176\u662f\u65af\u62c9\u592b\u8bed\u65cf\uff0c\u4e3a\u5168\u7403\u591a\u6a21\u6001\u8bc4\u6d4b\u57fa\u51c6\u5efa\u8bbe\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2511.15574", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15574", "abs": "https://arxiv.org/abs/2511.15574", "authors": ["Qihao Yang", "Xuelin Wang", "Jiale Chen", "Xuelian Dong", "Yuxin Hao", "Tianyong Hao"], "title": "HSKBenchmark: Modeling and Benchmarking Chinese Second Language Acquisition in Large Language Models through Curriculum Tuning", "comment": "Accepted by AAAI-2026", "summary": "Language acquisition is vital to revealing the nature of human language intelligence and has recently emerged as a promising perspective for improving the interpretability of large language models (LLMs). However, it is ethically and practically infeasible to conduct experiments that require controlling human learners' language inputs. This poses challenges for the verifiability and scalability of language acquisition modeling, particularly in Chinese second language acquisition (SLA). While LLMs provide a controllable and reproducible alternative, a systematic benchmark to support phase-wise modeling and assessment is still lacking. In this paper, we present HSKBenchmark, the first benchmark for staged modeling and writing assessment of LLMs in Chinese SLA. It covers HSK levels 3 to 6 and includes authentic textbooks with 6.76 million tokens, 16K synthetic instruction samples, 30 test topics, and a linguistically grounded evaluation system. To simulate human learning trajectories, we introduce a curriculum-tuning framework that trains models from beginner to advanced levels. An evaluation system is created to examine level-based grammar coverage, writing errors, lexical and syntactic complexity, and holistic scoring. We also build HSKAgent, fine-tuned on 10K learner compositions. Extensive experimental results demonstrate that HSKBenchmark not only models Chinese SLA effectively, but also serves as a reliable benchmark for dynamic writing assessment in LLMs. Our fine-tuned LLMs have writing performance on par with advanced human learners and exhibit human-like acquisition characteristics. The HSKBenchmark, HSKAgent, and checkpoints serve as foundational tools and resources, with the potential to pave the way for future research on language acquisition modeling and LLMs interpretability. Code and data are publicly available at: https://github.com/CharlesYang030/HSKB.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faHKSBenchmark\uff0c\u7cfb\u7edf\u5316\u652f\u6301\u4e2d\u6587\u4e8c\u8bed\u5b66\u4e60\u5206\u9636\u6bb5\u5efa\u6a21\u4e0e\u8bc4\u6d4b\uff0c\u5e76\u8bc1\u5b9e\u73b0\u6709\u5927\u6a21\u578b\u7ecf\u5408\u7406\u8bad\u7ec3\u540e\u53ef\u8fbe\u5230\u9ad8\u7ea7\u5b66\u4e60\u8005\u6c34\u5e73\uff0c\u4e3a\u8bed\u8a00\u4e60\u5f97\u7814\u7a76\u548c\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u6807\u51c6\u5e73\u53f0\u4e0e\u5de5\u5177\u3002", "motivation": "\u8bed\u8a00\u4e60\u5f97\u7814\u7a76\u5bf9\u4e8e\u63ed\u793a\u4eba\u7c7b\u8bed\u8a00\u667a\u80fd\u672c\u8d28\u81f3\u5173\u91cd\u8981\uff0c\u5374\u56e0\u96be\u4ee5\u5b9e\u9645\u548c\u4f26\u7406\u4e0a\u63a7\u5236\u4eba\u7c7b\u5b66\u4e60\u8f93\u5165\u800c\u96be\u4ee5\u8fdb\u884c\u53ef\u9a8c\u8bc1\u3001\u53ef\u6269\u5c55\u5efa\u6a21\uff0c\u5c24\u5176\u662f\u4e2d\u6587\u4e8c\u8bed\u9886\u57df\u3002\u5927\u6a21\u578b\u5177\u5907\u53ef\u63a7\u6027\u4e0e\u53ef\u91cd\u590d\u6027\uff0c\u4f46\u7f3a\u5c11\u9636\u6bb5\u6027\u5efa\u6a21\u548c\u8bc4\u4f30\u7684\u7cfb\u7edf\u57fa\u51c6\u3002\u8be5\u7814\u7a76\u62df\u5f25\u8865\u6b64\u7a7a\u767d\u3002", "method": "1. \u6784\u5efa\u8986\u76d6HSK3-6\u7ea7\u522b\u3001\u5305\u542b\u771f\u5b9e\u6559\u6750\u548c16K\u5408\u6210\u6307\u4ee4\u6837\u672c\u7684\u8bed\u6599\uff1b2. \u63d0\u51fa\u5206\u9636\u6bb5\uff08\u7531\u521d\u7ea7\u5230\u9ad8\u7ea7\uff09\u7684\u8bfe\u7a0b\u5fae\u8c03\uff08curriculum-tuning\uff09\u6846\u67b6\u4ee5\u6a21\u62df\u8bed\u8a00\u5b66\u4e60\u8fc7\u7a0b\uff1b3. \u5efa\u7acb\u6db5\u76d6\u8bed\u6cd5\u3001\u5199\u4f5c\u9519\u8bef\u3001\u8bcd\u6c47\u53ca\u53e5\u6cd5\u590d\u6742\u5ea6\u548c\u6574\u4f53\u5f97\u5206\u7684\u591a\u7ef4\u8bc4\u6d4b\u7cfb\u7edf\uff1b4. \u6784\u5efa\u5e76\u5fae\u8c03HSKAgent\u6a21\u578b\uff0c\u5e76\u7528\u771f\u5b9e\u5b66\u4e60\u8005\u4f5c\u6587\u8fdb\u884c\u8bad\u7ec3\uff1b5. \u5bf9LLM\u6a21\u578b\u8fdb\u884c\u5168\u9762\u5b9e\u9a8c\u8bc1\u660e\u6709\u6548\u6027\u3002", "result": "HSKBenchmark \u5b9e\u73b0\u4e86\u5bf9\u4e2d\u6587\u4e8c\u8bed\u9636\u6bb5\u6027\u5efa\u6a21\u4e0e\u52a8\u6001\u5199\u4f5c\u6d4b\u8bc4\uff0c\u5b9e\u9a8c\u4e2d\u5fae\u8c03\u540e\u7684LLM\u5199\u4f5c\u80fd\u529b\u53ef\u5339\u654c\u9ad8\u7ea7\u5b66\u4e60\u8005\uff0c\u5e76\u5c55\u73b0\u51fa\u4e0e\u4eba\u7c7b\u76f8\u4f3c\u7684\u8bed\u8a00\u4e60\u5f97\u8f68\u8ff9\u3002", "conclusion": "HSKBenchmark \u662f\u9996\u4e2a\u9488\u5bf9\u4e2d\u6587\u4e8c\u8bed\uff08SLA\uff09\u9636\u6bb5\u6027\u8bed\u8a00\u5efa\u6a21\u4e0e\u5199\u4f5c\u8bc4\u4f30\u7684\u57fa\u51c6\uff0c\u5b9e\u9a8c\u8868\u660e\u57fa\u4e8e\u5176\u5fae\u8c03\u7684LLM\u5199\u4f5c\u80fd\u529b\u53ef\u5ab2\u7f8e\u9ad8\u7ea7\u4eba\u7c7b\u5b66\u4e60\u8005\uff0c\u5e76\u5177\u6709\u4eba\u7c7b\u5f0f\u7684\u4e60\u5f97\u7279\u5f81\u3002\u6240\u63d0\u51fa\u7684\u5de5\u5177\u548c\u8d44\u6e90\u4e3a\u540e\u7eed\u8bed\u8a00\u4e60\u5f97\u5efa\u6a21\u53ca\u5927\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.15709", "categories": ["cs.CL", "cs.DS", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.15709", "abs": "https://arxiv.org/abs/2511.15709", "authors": ["Violeta Kastreva", "Philip Whittington", "Dennis Komm", "Tiago Pimentel"], "title": "Tokenisation over Bounded Alphabets is Hard", "comment": null, "summary": "Recent works have shown that tokenisation is NP-complete. However, these works assume tokenisation is applied to inputs with unboundedly large alphabets -- an unrealistic assumption, given that in practice tokenisers operate over fixed-size alphabets, such as bytes or Unicode characters. We close this gap by analysing tokenisation over bounded $n$-ary alphabets, considering two natural variants: bottom-up tokenisation and direct tokenisation, where we must, respectively, select a sequence of merge operations or a vocabulary whose application optimally compresses a dataset. First, we note that proving hardness results for an $n$-ary alphabet proves the same results for alphabets of any larger size. We then prove that even with binary alphabets, both variants are not only NP-complete, but admit no polynomial-time approximation scheme (unless P=NP). We further show that direct tokenisation remains NP-complete even when applied to unary alphabets. While unary alphabets may not be practically useful, this result establishes that the computational intractability of tokenisation is not an artifact of large alphabets or complex constructions, but a fundamental barrier. Overall, our results explain why practical algorithms such as BPE and UnigramLM are heuristic, and points toward approximation algorithms being an important path going forward for tokenisation research.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u5373\u4f7f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u6709\u9650\u5b57\u6bcd\u8868\uff08\u5982\u4e8c\u5143/\u5355\u5143\uff09\uff0ctokenisation\u4f9d\u7136\u662fNP-\u5b8c\u5168\u4e14\u4e0d\u53ef\u8fd1\u4f3c\uff0c\u4ece\u7406\u8bba\u5c42\u9762\u652f\u6301\u4e86\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6848\u7684\u5408\u7406\u6027\uff0c\u5e76\u5efa\u8bae\u672a\u6765\u5e94\u5173\u6ce8\u8fd1\u4f3c\u7b97\u6cd5\u7684\u7814\u7a76\u3002", "motivation": "\u4ee5\u5f80\u5173\u4e8eTokenisation\uff08\u5206\u8bcd\uff09NP-\u5b8c\u5168\u6027\u7684\u5de5\u4f5c\uff0c\u5047\u5b9a\u8f93\u5165\u5b57\u6bcd\u8868\u5927\u5c0f\u65e0\u9650\u5927\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2dTokeniser\u662f\u5728\u6709\u9650\u5b57\u6bcd\u8868\uff08\u5982\u5b57\u8282\u3001Unicode\u5b57\u7b26\uff09\u4e0a\u5de5\u4f5c\u7684\u3002\u8be5\u6587\u65e8\u5728\u5f25\u8865\u6b64\u7406\u8bba\u4e0e\u73b0\u5b9e\u7684\u5dee\u8ddd\u3002", "method": "\u5f62\u5f0f\u5316\u5730\u5206\u6790\u4e86\u6709\u9650\u5927\u5c0f\uff08\u5982\u4e8c\u5143\u3001\u5355\u5143\uff09\u5b57\u6bcd\u8868\u4e0a\u7684tokenisation\u95ee\u9898\uff0c\u5206\u522b\u7814\u7a76\u4e86\u4e24\u79cd\u81ea\u7136\u53d8\u4f53\uff1a\u81ea\u5e95\u5411\u4e0a\u7684\u5408\u5e76\u64cd\u4f5c\u5e8f\u5217\u9009\u62e9\uff08bottom-up\uff09\u548c\u76f4\u63a5\u9009\u62e9\u8bcd\u8868\u7684\u4f18\u5316\u538b\u7f29\uff08direct\uff09\uff0c\u5e76\u8fdb\u884c\u4e86\u590d\u6742\u5ea6\u8bc1\u660e\u3002", "result": "1. \u8bc1\u660e\u4e86\u5bf9\u4efb\u610f\u56fa\u5b9a\u5927\u5c0f\u7684\u5b57\u6bcd\u8868\uff08\u5373\u4f7f\u662f\u4e8c\u5143\u6216\u5355\u5143\uff09\uff0ctokenisation\u7684\u4e24\u4e2a\u53d8\u4f53\u5747\u662fNP-\u5b8c\u5168\u7684\uff0c\u4e14\u4e0d\u5b58\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u65b9\u6848\uff0c\u9664\u975eP=NP\u30022. \u76f4\u63a5tokenisation\u5728\u53ea\u7528\u5355\u4e00\u5b57\u6bcd\u7684\u60c5\u51b5\u4e0b\u4f9d\u7136\u662fNP-\u5b8c\u5168\uff0c\u8bf4\u660e\u8ba1\u7b97\u96be\u5ea6\u4e0d\u662f\u7531\u4e8e\u5b57\u6bcd\u8868\u8fc7\u5927\u6216\u7279\u6b8a\u6784\u9020\u9020\u6210\u7684\uff0c\u800c\u662f\u672c\u8d28\u7684\u3002", "conclusion": "\u5bf9tokenisation\u7684\u8ba1\u7b97\u96be\u5ea6\u8fdb\u884c\u4e86\u4e25\u683c\u754c\u5b9a\uff0c\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48BPE\u3001UnigramLM\u7b49\u5b9e\u9645tokeniser\u53ea\u80fd\u91c7\u7528\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u53ef\u884c\u7684\u7814\u7a76\u8def\u5f84\u662f\u5bfb\u627e\u9ad8\u6548\u7684\u8fd1\u4f3c\u7b97\u6cd5\u3002"}}
