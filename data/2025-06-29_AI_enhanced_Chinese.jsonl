{"id": "2506.20754", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.20754", "abs": "https://arxiv.org/abs/2506.20754", "authors": ["Marina Ara\u00fajo", "J\u00falia Ara\u00fajo", "Romeu Oliveira", "Lucas Romao", "Marcos Kalinowski"], "title": "Domain Knowledge in Requirements Engineering: A Systematic Mapping Study", "comment": "Accepted for publication at the 51st Euromicro Conference Series on\n  Software Engineering and Advanced Applications (SEAA) 2025", "summary": "[Context] Domain knowledge is recognized as a key component for the success\nof Requirements Engineering (RE), as it provides the conceptual support needed\nto understand the system context, ensure alignment with stakeholder needs, and\nreduce ambiguity in requirements specification. Despite its relevance, the\nscientific literature still lacks a systematic consolidation of how domain\nknowledge can be effectively used and operationalized in RE. [Goal] This paper\naddresses this gap by offering a comprehensive overview of existing\ncontributions, including methods, techniques, and tools to incorporate domain\nknowledge into RE practices. [Method] We conducted a systematic mapping study\nusing a hybrid search strategy that combines database searches with iterative\nbackward and forward snowballing. [Results] In total, we found 75 papers that\nmet our inclusion criteria. The analysis highlights the main types of\nrequirements addressed, the most frequently considered quality attributes, and\nrecurring challenges in the formalization, acquisition, and long-term\nmaintenance of domain knowledge. The results provide support for researchers\nand practitioners in identifying established approaches and unresolved issues.\nThe study also outlines promising directions for future research, emphasizing\nthe development of scalable, automated, and sustainable solutions to integrate\ndomain knowledge into RE processes. [Conclusion] The study contributes by\nproviding a comprehensive overview that helps to build a conceptual and\nmethodological foundation for knowledge-driven requirements engineering.", "AI": {"tldr": "\u672c\u8bba\u6587\u7cfb\u7edf\u68b3\u7406\u4e86\u9886\u57df\u77e5\u8bc6\u5728\u9700\u6c42\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\uff0c\u603b\u7ed3\u73b0\u72b6\u3001\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\uff0c\u4e3a\u77e5\u8bc6\u9a71\u52a8\u7684\u9700\u6c42\u5de5\u7a0b\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u53c2\u8003\u3002", "motivation": "\u9886\u57df\u77e5\u8bc6\u5728\u9700\u6c42\u5de5\u7a0b\uff08RE\uff09\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u79d1\u5b66\u6587\u732e\u4ecd\u7f3a\u4e4f\u5173\u4e8e\u5982\u4f55\u6709\u6548\u5229\u7528\u548c\u64cd\u4f5c\u9886\u57df\u77e5\u8bc6\u7684\u7cfb\u7edf\u603b\u7ed3\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\uff0c\u7ed3\u5408\u6570\u636e\u5e93\u68c0\u7d22\u548c\u9012\u5f52\u7684\u524d\u5411\u4e0e\u540e\u5411\u6eaf\u6e90\u6cd5\u8fdb\u884c\u6587\u732e\u7b5b\u67e5\u548c\u5206\u6790\u3002", "result": "\u5171\u7b5b\u9009\u51fa75\u7bc7\u76f8\u5173\u6587\u732e\uff0c\u5206\u6790\u4e86\u9700\u6c42\u7c7b\u578b\u3001\u5e38\u89c1\u8d28\u91cf\u5c5e\u6027\uff0c\u4ee5\u53ca\u9886\u57df\u77e5\u8bc6\u7684\u5f62\u5f0f\u5316\u3001\u83b7\u53d6\u548c\u957f\u671f\u7ef4\u62a4\u4e2d\u9047\u5230\u7684\u6311\u6218\uff0c\u603b\u7ed3\u4e86\u5df2\u5efa\u7acb\u7684\u65b9\u6cd5\u548c\u672a\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u5e94\u6ce8\u91cd\u53ef\u6269\u5c55\u3001\u81ea\u52a8\u5316\u548c\u53ef\u6301\u7eed\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u5168\u9762\u7efc\u8ff0\u73b0\u6709\u6587\u732e\uff0c\u4e3a\u77e5\u8bc6\u9a71\u52a8\u7684\u9700\u6c42\u5de5\u7a0b\u63d0\u4f9b\u4e86\u6982\u5ff5\u548c\u65b9\u6cd5\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u540e\u7eed\u7814\u7a76\u4e0e\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2506.20759", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20759", "abs": "https://arxiv.org/abs/2506.20759", "authors": ["Lucas Romao", "Hugo Villamizar", "Romeu Oliveira", "Silvio Alonso", "Marcos Kalinowski"], "title": "Agile Management for Machine Learning: A Systematic Mapping Study", "comment": "Accepted for publication at the 51st Euromicro Conference Series on\n  Software Engineering and Advanced Applications (SEAA) 2025", "summary": "[Context] Machine learning (ML)-enabled systems are present in our society,\ndriving significant digital transformations. The dynamic nature of ML\ndevelopment, characterized by experimental cycles and rapid changes in data,\nposes challenges to traditional project management. Agile methods, with their\nflexibility and incremental delivery, seem well-suited to address this\ndynamism. However, it is unclear how to effectively apply these methods in the\ncontext of ML-enabled systems, where challenges require tailored approaches.\n[Goal] Our goal is to outline the state of the art in agile management for\nML-enabled systems. [Method] We conducted a systematic mapping study using a\nhybrid search strategy that combines database searches with backward and\nforward snowballing iterations. [Results] Our study identified 27 papers\npublished between 2008 and 2024. From these, we identified eight frameworks and\ncategorized recommendations and practices into eight key themes, such as\nIteration Flexibility, Innovative ML-specific Artifacts, and the Minimal Viable\nModel. The main challenge identified across studies was accurate effort\nestimation for ML-related tasks. [Conclusion] This study contributes by mapping\nthe state of the art and identifying open gaps in the field. While relevant\nwork exists, more robust empirical evaluation is still needed to validate these\ncontributions.", "AI": {"tldr": "\u6587\u732e\u56de\u987e\u4e86ML\u7cfb\u7edf\u654f\u6377\u7ba1\u7406\u7684\u73b0\u72b6\uff0c\u6574\u7406\u51fa8\u5927\u4e3b\u9898\u4e0e\u76f8\u5e94\u6846\u67b6\uff0c\u8ba4\u5b9a\u5de5\u4f5c\u91cf\u4f30\u7b97\u56f0\u96be\u4e3a\u6838\u5fc3\u6311\u6218\uff0c\u5e76\u547c\u5401\u540e\u7eed\u52a0\u5f3a\u5b9e\u8bc1\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u4f20\u7edf\u9879\u76ee\u7ba1\u7406\u65b9\u5f0f\u96be\u4ee5\u6ee1\u8db3\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u7cfb\u7edf\u5feb\u901f\u53d8\u5316\u4e0e\u5b9e\u9a8c\u9a71\u52a8\u7684\u5f00\u53d1\u7279\u6027\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u9002\u5408ML\u7cfb\u7edf\u7684\u654f\u6377\u7ba1\u7406\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\uff0c\u901a\u8fc7\u6570\u636e\u5e93\u68c0\u7d22\u7ed3\u5408\u6b63\u53cd\u5411\u6eda\u96ea\u7403\u6cd5\uff0c\u5bf9\u73b0\u6709\u6587\u732e\u8fdb\u884c\u7efc\u8ff0\u4e0e\u6574\u7406\u3002", "result": "\u5171\u8bc6\u522b\u51fa27\u7bc7\uff082008-2024\uff09\uff0c\u63d0\u53d6\u4e868\u4e2a\u7ba1\u7406\u6846\u67b6\u5e76\u5c06\u76f8\u5173\u5efa\u8bae\u5f52\u7eb3\u4e3a8\u5927\u4e3b\u9898\uff08\u5982\u8fed\u4ee3\u7075\u6d3b\u6027\u3001\u521b\u65b0\u6027ML\u5de5\u4ef6\u3001\u6700\u5c0f\u53ef\u884c\u6a21\u578b\u7b49\uff09\uff0c\u53d1\u73b0\u6700\u5927\u96be\u70b9\u4e3aML\u4efb\u52a1\u7684\u5de5\u4f5c\u91cf\u4f30\u7b97\u3002", "conclusion": "\u672c\u7814\u7a76\u7cfb\u7edf\u68b3\u7406\u4e86\u5f53\u524dML\u7cfb\u7edf\u654f\u6377\u7ba1\u7406\u65b9\u6cd5\u7684\u53d1\u5c55\u73b0\u72b6\u4e0e\u5b58\u5728\u95ee\u9898\uff0c\u6307\u51fa\u9700\u8981\u66f4\u591a\u5b9e\u8bc1\u8bc4\u4f30\u6765\u652f\u6491\u8fd9\u4e9b\u5b9e\u8df5\u4e0e\u6846\u67b6\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.20851", "categories": ["cs.SE", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2506.20851", "abs": "https://arxiv.org/abs/2506.20851", "authors": ["Srikar Reddy Gadusu", "Larry Callahan", "Samir Lababidi", "Arunasri Nishtala", "Sophia Healey", "Hande McGinty"], "title": "Generating Reliable Adverse event Profiles for Health through Automated Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach", "comment": null, "summary": "As data and knowledge expand rapidly, adopting systematic methodologies for\nontology generation has become crucial. With the daily increases in data\nvolumes and frequent content changes, the demand for databases to store and\nretrieve information for the creation of knowledge graphs has become\nincreasingly urgent. The previously established Knowledge Acquisition and\nRepresentation Methodology (KNARM) outlines a systematic approach to address\nthese challenges and create knowledge graphs. However, following this\nmethodology highlights the existing challenge of seamlessly integrating Neo4j\ndatabases with the Web Ontology Language (OWL). Previous attempts to integrate\ndata from Neo4j into an ontology have been discussed, but these approaches\noften require an understanding of description logics (DL) syntax, which may not\nbe familiar to many users. Thus, a more accessible method is necessary to\nbridge this gap. This paper presents a user-friendly approach that utilizes\nPython and its rdflib library to support ontology development. We showcase our\nnovel approach through a Neo4j database we created by integrating data from the\nFood and Drug Administration (FDA) Adverse Event Reporting System (FAERS)\ndatabase. Using this dataset, we developed a Python script that automatically\ngenerates the required classes and their axioms, facilitating a smoother\nintegration process. This approach offers a practical solution to the\nchallenges of ontology generation in the context of rapidly growing adverse\ndrug event datasets, supporting improved drug safety monitoring and public\nhealth decision-making.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8ePython rdflib\u5e93\uff0c\u81ea\u52a8\u5316\u96c6\u6210Neo4j\u6570\u636e\u5e93\u4e0eOWL\u672c\u4f53\u7684\u65b0\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u64cd\u4f5c\u7b80\u4fbf\u3001\u65e0\u9700\u6df1\u539a\u672c\u4f53\u5b66\u77e5\u8bc6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u4e2d\u7684\u96c6\u6210\u96be\u9898\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5728\u836f\u54c1\u5b89\u5168\u6570\u636e\u573a\u666f\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u6570\u636e\u548c\u77e5\u8bc6\u7684\u5feb\u901f\u6269\u5c55\u5bfc\u81f4\u672c\u4f53\uff08ontology\uff09\u751f\u6210\u65b9\u6cd5\u8bba\u7684\u91cd\u8981\u6027\u63d0\u5347\uff0c\u5c24\u5176\u662f\u5728\u9762\u5bf9\u6570\u636e\u4f53\u91cf\u5feb\u901f\u589e\u957f\u4e0e\u5185\u5bb9\u53d8\u5316\u9891\u7e41\u7684\u80cc\u666f\u4e0b\uff0c\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u548c\u6570\u636e\u96c6\u6210\u9762\u4e34\u6280\u672f\u6311\u6218\u3002\u4ee5\u5f80\u5c06Neo4j\u6570\u636e\u5e93\u4e0eOWL\u672c\u4f53\u8bed\u8a00\u96c6\u6210\u65f6\uff0c\u4e0d\u4ec5\u8981\u6c42\u5bf9DL\u8bed\u6cd5\u6709\u8f83\u6df1\u4e86\u89e3\uff0c\u4e5f\u5b58\u5728\u4e00\u5b9a\u4f7f\u7528\u95e8\u69db\uff0c\u9650\u5236\u4e86\u66f4\u5e7f\u6cdb\u7528\u6237\u7684\u4f7f\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u66f4\u6613\u7528\u7684\u65b9\u6cd5\uff0c\u5229\u7528Python\u53ca\u5176rdflib\u5e93\u6765\u652f\u6301\u672c\u4f53\u5f00\u53d1\u3002\u5177\u4f53\u91c7\u7528Python\u811a\u672c\uff0c\u4eceNeo4j\u6570\u636e\u5e93\u4e2d\u81ea\u52a8\u751f\u6210OWL\u672c\u4f53\u6240\u9700\u7684\u7c7b\u53ca\u5176\u516c\u7406\uff0c\u5b9e\u73b0\u4e86\u8fc7\u7a0b\u81ea\u52a8\u5316\u3002\u5728\u5b9e\u9a8c\u4e2d\uff0c\u4f5c\u8005\u5c06FDA\u4e0d\u826f\u53cd\u5e94\u62a5\u544a\u7cfb\u7edf\uff08FAERS\uff09\u6570\u636e\u96c6\u5bfc\u5165Neo4j\uff0c\u8fdb\u800c\u901a\u8fc7\u811a\u672c\u5b9e\u73b0\u6570\u636e\u4e0e\u672c\u4f53\u7684\u9ad8\u6548\u8854\u63a5\u3002", "result": "\u8be5\u65b9\u6cd5\u65e0\u9700\u6df1\u5165\u638c\u63e1\u63cf\u8ff0\u903b\u8f91\uff08DL\uff09\u8bed\u6cd5\uff0c\u6781\u5927\u964d\u4f4e\u4e86\u64cd\u4f5c\u95e8\u69db\uff0c\u5b9e\u73b0\u4e86\u6570\u636e\u4eceNeo4j\u6570\u636e\u5e93\u5230OWL\u672c\u4f53\u7684\u81ea\u52a8\u5316\u3001\u9ad8\u6548\u96c6\u6210\u3002\u901a\u8fc7FDA FAERS\u6570\u636e\u5e93\u7684\u5b9e\u9645\u5e94\u7528\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u4f5c\u8005\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u4e0d\u826f\u836f\u7269\u4e8b\u4ef6\u6570\u636e\u96c6\u5feb\u901f\u589e\u957f\u7684\u80cc\u666f\u4e0b\uff0c\u4e3a\u672c\u4f53\u751f\u6210\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6027\u7684\u3001\u7528\u6237\u53cb\u597d\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u836f\u54c1\u5b89\u5168\u76d1\u6d4b\u548c\u516c\u5171\u5065\u5eb7\u51b3\u7b56\u3002"}}
{"id": "2506.20869", "categories": ["cs.SE", "cs.AI", "cs.IR", "D.2.11; I.2.6; H.3.3"], "pdf": "https://arxiv.org/pdf/2506.20869", "abs": "https://arxiv.org/abs/2506.20869", "authors": ["Md Toufique Hasan", "Muhammad Waseem", "Kai-Kristian Kemell", "Ayman Asad Khan", "Mika Saari", "Pekka Abrahamsson"], "title": "Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation", "comment": "Accepted as a full paper to the 51st Euromicro Conference on Software\n  Engineering and Advanced Applications (SEAA 2025). 9 pages, 4 figures. This\n  is the preprint version and not the final camera ready version", "summary": "Retrieval-Augmented Generation (RAG) systems are emerging as a key approach\nfor grounding Large Language Models (LLMs) in external knowledge, addressing\nlimitations in factual accuracy and contextual relevance. However, there is a\nlack of empirical studies that report on the development of RAG-based\nimplementations grounded in real-world use cases, evaluated through general\nuser involvement, and accompanied by systematic documentation of lessons\nlearned. This paper presents five domain-specific RAG applications developed\nfor real-world scenarios across governance, cybersecurity, agriculture,\nindustrial research, and medical diagnostics. Each system incorporates\nmultilingual OCR, semantic retrieval via vector embeddings, and domain-adapted\nLLMs, deployed through local servers or cloud APIs to meet distinct user needs.\nA web-based evaluation involving a total of 100 participants assessed the\nsystems across six dimensions: (i) Ease of Use, (ii) Relevance, (iii)\nTransparency, (iv) Responsiveness, (v) Accuracy, and (vi) Likelihood of\nRecommendation. Based on user feedback and our development experience, we\ndocumented twelve key lessons learned, highlighting technical, operational, and\nethical challenges affecting the reliability and usability of RAG systems in\npractice.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u5e76\u8bc4\u6d4b\u4e86\u4e94\u4e2a\u9762\u5411\u5b9e\u9645\u9886\u57df\u7684RAG\u7cfb\u7edf\uff0c\u901a\u8fc7100\u4eba\u53c2\u4e0e\u591a\u7ef4\u5ea6\u7528\u6237\u8c03\u67e5\uff0c\u603b\u7ed3\u4e8612\u6761\u7ecf\u9a8c\uff0c\u63ed\u793a\u4e86RAG\u7cfb\u7edf\u5b9e\u8df5\u4e2d\u7684\u5173\u952e\u6311\u6218\u53ca\u6539\u8fdb\u7a7a\u95f4\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u5728\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7cfb\u7edf\u6210\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u7684\u91cd\u8981\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u73b0\u6709\u5f88\u5c11\u6709\u5173\u4e8eRAG\u5728\u771f\u5b9e\u573a\u666f\u4e0b\u5f00\u53d1\u548c\u7528\u6237\u8bc4\u4ef7\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u540c\u65f6\u4e5f\u7f3a\u4e4f\u7cfb\u7edf\u7684\u7ecf\u9a8c\u603b\u7ed3\u3002", "method": "\u5f00\u53d1\u4e86\u4e94\u4e2a\u9762\u5411\u6cbb\u7406\u3001\u7f51\u7edc\u5b89\u5168\u3001\u519c\u4e1a\u3001\u5de5\u4e1a\u7814\u7a76\u548c\u533b\u7597\u8bca\u65ad\u7b49\u9886\u57df\u7684RAG\u7cfb\u7edf\uff0c\u6bcf\u4e2a\u7cfb\u7edf\u90fd\u96c6\u6210\u4e86\u591a\u8bed\u79cdOCR\u3001\u57fa\u4e8e\u5411\u91cf\u5d4c\u5165\u7684\u8bed\u4e49\u68c0\u7d22\u548c\u9886\u57df\u9002\u5e94\u7684LLMs\uff0c\u5e76\u901a\u8fc7\u672c\u5730\u670d\u52a1\u5668\u6216\u4e91API\u90e8\u7f72\u3002\u968f\u540e\uff0c\u901a\u8fc7\u5305\u542b100\u540d\u53c2\u4e0e\u8005\u7684\u57fa\u4e8e\u7f51\u9875\u7684\u8bc4\u4ef7\u6d41\u7a0b\uff0c\u4ece\u6613\u7528\u6027\u3001\u76f8\u5173\u6027\u3001\u900f\u660e\u5ea6\u3001\u54cd\u5e94\u6027\u3001\u51c6\u786e\u6027\u548c\u63a8\u8350\u610f\u613f\u516d\u4e2a\u7ef4\u5ea6\u5bf9\u7cfb\u7edf\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7100\u4eba\u7528\u6237\u8bc4\u4ef7\uff0c\u7cfb\u7edf\u5728\u516d\u4e2a\u7ef4\u5ea6\u4e0a\u5f97\u5230\u53cd\u9988\uff0c\u603b\u7ed3\u51fa\u6280\u672f\u3001\u8fd0\u7ef4\u548c\u4f26\u7406\u7b49\u65b9\u9762\u517112\u6761\u5b9e\u9645\u7ecf\u9a8c\uff0c\u8fd9\u4e9b\u7ecf\u9a8c\u5bf9RAG\u7cfb\u7edf\u5728\u771f\u5b9e\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u548c\u53ef\u7528\u6027\u6709\u6df1\u523b\u5f71\u54cd\u3002", "conclusion": "RAG\u7cfb\u7edf\u5728\u591a\u4e2a\u5b9e\u9645\u9886\u57df\u5177\u6709\u826f\u597d\u7684\u5b9e\u7528\u6027\u3002\u7528\u6237\u591a\u7ef4\u5ea6\u8bc4\u4ef7\u63d0\u4f9b\u4e86\u5b9d\u8d35\u53cd\u9988\uff0c\u540c\u65f6\u7814\u7a76\u7cfb\u7edf\u6027\u5730\u603b\u7ed3\u4e86\u5f00\u53d1\u548c\u90e8\u7f72\u4e2d\u7684\u5173\u952e\u6280\u672f\u4e0e\u4f26\u7406\u6311\u6218\uff0c\u4e3a\u4eca\u540eRAG\u7cfb\u7edf\u7684\u5b9e\u8df5\u548c\u6539\u8fdb\u63d0\u4f9b\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2506.21254", "categories": ["cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2506.21254", "abs": "https://arxiv.org/abs/2506.21254", "authors": ["Julien Bensmail", "Romain Bourneuf", "Paul Colinot", "Samuel Humeau", "Timoth\u00e9e Martinod"], "title": "Making Graphs Irregular through Irregularising Walks", "comment": null, "summary": "The 1-2-3 Conjecture, introduced by Karo\\'nski, {\\L}uczak, and Thomason in\n2004, was recently solved by Keusch. This implies that, for any connected graph\n$G$ different from $K_2$, we can turn $G$ into a locally irregular multigraph\n$M(G)$, i.e., in which no two adjacent vertices have the same degree, by\nreplacing some of its edges with at most three parallel edges. In this work, we\nintroduce and study a restriction of this problem under the additional\nconstraint that edges added to $G$ to reach $M(G)$ must form a walk (i.e., a\npath with possibly repeated edges and vertices) of $G$. We investigate the\ngeneral consequences of having this additional constraint, and provide several\nresults of different natures (structural, combinatorial, algorithmic) on the\nlength of the shortest irregularising walks, for general graphs and more\nrestricted classes.", "AI": {"tldr": "\u57281-2-3\u731c\u60f3\u5df2\u88ab\u8bc1\u660e\u7684\u57fa\u7840\u4e0a\uff0c\u672c\u6587\u8fdb\u4e00\u6b65\u63a2\u8ba8\u5e76\u884c\u8fb9\u9700\u6784\u6210\u539f\u56fewalk\u7684\u60c5\u5f62\u4e0b\uff0c\u5c06\u4e00\u822c\u6216\u7279\u5b9a\u7c7b\u578b\u7684\u56fe\u53d8\u4e3a\u5c40\u90e8\u4e0d\u89c4\u5219\u56fe\u65f6\u6240\u9700walk\u7684\u6027\u8d28\u53ca\u957f\u5ea6\u754c\uff0c\u5e76\u7ed9\u51fa\u4e86\u5177\u4f53\u7684\u7ed3\u6784\u548c\u7b97\u6cd5\u7ed3\u679c\u3002", "motivation": "1-2-3\u731c\u60f3\u5df2\u88ab\u8bc1\u660e\u540e\uff0c\u4f5c\u8005\u5173\u6ce8\u5176\u5728\u66f4\u4e25\u683c\u9650\u5236\u6761\u4ef6\u4e0b\u7684\u63a8\u5e7f\uff0c\u5c24\u5176\u662f\u52a0\u5165\u201c\u6dfb\u52a0\u7684\u8fb9\u5fc5\u987b\u6784\u6210\u539f\u56fewalk\u201d\u8fd9\u4e00\u65b0\u9650\u5236\uff0c\u4ee5\u63a2\u7a76\u66f4\u81ea\u7136\u6216\u5b9e\u9645\u573a\u666f\u4e0b\u7684\u95ee\u9898\u590d\u6742\u6027\u3002", "method": "\u5728\u5f15\u5165walk\u7ea6\u675f\u4e0b\uff0c\u5206\u6790\u6700\u77edirregularising walk\u7684\u7ed3\u6784\u7279\u5f81\uff0c\u9488\u5bf9\u4e00\u822c\u56fe\u4e0e\u7279\u6b8a\u7c7b\u522b\uff0c\u5229\u7528\u7ed3\u6784\u3001\u7ec4\u5408\u548c\u7b97\u6cd5\u65b9\u6cd5\uff0c\u5f97\u5230\u4e0d\u540c\u60c5\u51b5\u4e0bwalk\u957f\u5ea6\u7684\u4e0a\u754c\u3001\u4e0b\u754c\u53ca\u76f8\u5173\u6027\u8d28\u3002", "result": "\u63d0\u51fa\u4e86\u82e5\u5e72\u5173\u4e8e\u5728walk\u7ea6\u675f\u4e0b\u7684\u7ed3\u6784\u3001\u7ec4\u5408\u548c\u7b97\u6cd5\u6027\u8d28\uff1b\u5bf9\u4e00\u822c\u56fe\u548c\u7279\u6b8a\u7c7b\u578b\u56fe\uff0c\u7ed9\u51fa\u4e86\u6700\u77edirregularising walk\u957f\u5ea6\u7684\u4e0a\u3001\u4e0b\u754c\u4ee5\u53ca\u4f18\u5316\u7b97\u6cd5\u3002", "conclusion": "\u8bba\u6587\u57281-2-3\u731c\u60f3\u7684\u57fa\u7840\u4e0a\uff0c\u7814\u7a76\u4e86\u5728\u989d\u5916\u201c\u5e76\u884c\u8fb9\u9700\u5f62\u6210\u4e00\u6761\u539f\u56fe\u7684walk\u201d\u7ea6\u675f\u4e0b\uff0c\u4e0d\u540c\u56fe\u53ca\u7279\u6b8a\u56fe\u7c7b\u4e2d\u4f7f\u56fe\u5c40\u90e8\u4e0d\u89c4\u5219\u6240\u9700walk\u7684\u957f\u5ea6\u3001\u7ed3\u6784\u3001\u7ec4\u5408\u4e0e\u7b97\u6cd5\u6027\u8d28\u3002"}}
{"id": "2506.21149", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2506.21149", "abs": "https://arxiv.org/abs/2506.21149", "authors": ["Lisa-Marie Jaser", "Jacobo Toran"], "title": "Pebble Games and Algebraic Proof Systems", "comment": null, "summary": "Analyzing refutations of the well known 0pebbling formulas Peb$(G)$ we prove\nsome new strong connections between pebble games and algebraic proof system,\nshowing that there is a parallelism between the reversible, black and\nblack-white pebbling games on one side, and the three algebraic proof systems\nNullstellensatz, Monomial Calculus and Polynomial Calculus on the other side.\nIn particular we prove that for any DAG $G$ with a single sink, if there is a\nMonomial Calculus refutation for Peb$(G)$ having simultaneously degree $s$ and\nsize $t$ then there is a black pebbling strategy on $G$ with space $s$ and time\n$t+s$. Also if there is a black pebbling strategy for $G$ with space $s$ and\ntime $t$ it is possible to extract from it a MC refutation for Peb$(G)$ having\nsimultaneously degree $s$ and size $ts$. These results are analogous to those\nproven in {deRezende et al.21} for the case of reversible pebbling and\nNullstellensatz. Using them we prove degree separations between NS, MC and PC,\nas well as strong degree-size tradeoffs for MC.\n  We also notice that for any directed acyclic graph $G$ the space needed in a\npebbling strategy on $G$, for the three versions of the game, reversible, black\nand black-white, exactly matches the variable space complexity of a refutation\nof the corresponding pebbling formula Peb$(G)$ in each of the algebraic proof\nsystems NS, MC and PC. Using known pebbling bounds on graphs, this connection\nimplies separations between the corresponding variable space measures.", "AI": {"tldr": "\u672c\u8bba\u6587\u9996\u6b21\u7cfb\u7edf\u5efa\u7acb\u4e86Pebbling\u535a\u5f08\u4e0e\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edfNS\u3001MC\u3001PC\u7684\u590d\u6742\u5ea6\u7cbe\u786e\u8054\u7cfb\uff0c\u5c55\u793a\u4e86\u5bf9\u5e94\u7b56\u7565/\u53d8\u91cf\u7a7a\u95f4\u590d\u6742\u5ea6\u7684\u7b49\u4ef7\uff0c\u4ee5\u53ca\u7cfb\u7edf\u95f4\u7684\u590d\u6742\u5ea6\u5206\u79bb\u4e0e\u4e0b\u754c\u7ed3\u679c\u3002", "motivation": "\u63a2\u7d22\u8ba1\u7b97\u590d\u6742\u6027\u7406\u8bba\u4e2dPebbling\u65b9\u6cd5\u4e0e\u4e3b\u6d41\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edf\u4e4b\u95f4\u7684\u8054\u7cfb\u53ca\u5176\u5f7c\u6b64\u4e4b\u95f4\u7684\u590d\u6742\u5ea6\u5206\u79bb\u95ee\u9898\uff0c\u4ece\u800c\u52a0\u6df1\u5bf9\u63a8\u7406\u548c\u8bc1\u660e\u7cfb\u7edf\u6548\u7387\u7684\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u5206\u67900\u538b\u77f3\u516c\u5f0fPeb(G)\u7684\u53cd\u8bc1\u6cd5\uff0c\u8003\u5bdf\u5355\u4e00\u6c47\u70b9DAG\uff08\u6709\u5411\u65e0\u73af\u56fe\uff09\u5728Monomial Calculus\u4e2d\u7684\u53cd\u8bc1\u590d\u6742\u5ea6\uff0c\u5e76\u5c06\u8fd9\u4e9b\u590d\u6742\u5ea6\u7279\u5f81\u4e0ePebbling\u535a\u5f08\u7684\u7a7a\u95f4\u3001\u65f6\u95f4\u53c2\u6570\u8fdb\u884c\u4e25\u683c\u6bd4\u8f83\u3002\u540c\u65f6\u4f7f\u7528\u5df2\u77e5\u7684\u56fePebbling\u754c\u9650\u63a8\u5bfc\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edf\u4e2d\u7684\u7a7a\u95f4\u6d4b\u5ea6\u5206\u79bb\u3002", "result": "\u8bc1\u660e\u4e86\u82e5Peb(G)\u5728Monomial Calculus\u4e2d\u7684\u53cd\u8bc1\u5177\u6709\u4e00\u5b9a\u6b21\u6570\u548c\u89c4\u6a21\uff0c\u5219\u5728\u5bf9\u5e94\u7684DAG\u4e0a\u6709\u4e0e\u4e4b\u7a7a\u95f4\u548c\u65f6\u95f4\u5339\u914d\u7684black-pebbling\u7b56\u7565\uff0c\u53cd\u4e4b\u4ea6\u7136\uff0c\u5e76\u62d3\u5c55\u4e86\u6b64\u524d\u4ec5\u9650\u4e8ereversible-pebbling\u4e0eNullstellensatz\u7684\u7ed3\u679c\u3002\u6b64\u5916\uff0c\u83b7\u5f97\u4e86\u4e09\u79cd\u7cfb\u7edf\u4e4b\u95f4\u7684\u6b21\u6570\u5206\u79bb\u7ed3\u679c\u4ee5\u53caMC\u7cfb\u7edf\u7684\u6b21\u6570-\u89c4\u6a21\u6743\u8861\u4e0b\u754c\u3002", "conclusion": "\u8bba\u6587\u5efa\u7acb\u4e86Pebbling\u6e38\u620f\u4e0e\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edf\u4e4b\u95f4\u7684\u5f3a\u5173\u8054\uff0c\u8be6\u7ec6\u63ed\u793a\u4e86\u5728\u4e0d\u540c\u7c7b\u578b\u7684Pebbling\u6e38\u620f\u4e0e\u4e0d\u540c\u7c7b\u522b\u7684\u4ee3\u6570\u8bc1\u660e\u7cfb\u7edf\uff08NS, MC, PC\uff09\u4e4b\u95f4\u53d8\u91cf\u7a7a\u95f4\u590d\u6742\u5ea6\u548c\u7b56\u7565\u7684\u7cbe\u786e\u5bf9\u5e94\u5173\u7cfb\u3002"}}
{"id": "2506.20747", "categories": ["cs.CL", "68T50, 68T37", "I.2.7"], "pdf": "https://arxiv.org/pdf/2506.20747", "abs": "https://arxiv.org/abs/2506.20747", "authors": ["Chen Shen", "Sajjadur Rahman", "Estevam Hruschka"], "title": "Towards Probabilistic Question Answering Over Tabular Data", "comment": null, "summary": "Current approaches for question answering (QA) over tabular data, such as\nNL2SQL systems, perform well for factual questions where answers are directly\nretrieved from tables. However, they fall short on probabilistic questions\nrequiring reasoning under uncertainty. In this paper, we introduce a new\nbenchmark LUCARIO and a framework for probabilistic QA over large tabular data.\nOur method induces Bayesian Networks from tables, translates natural language\nqueries into probabilistic queries, and uses large language models (LLMs) to\ngenerate final answers. Empirical results demonstrate significant improvements\nover baselines, highlighting the benefits of hybrid symbolic-neural reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLUCARIO\u57fa\u51c6\u548c\u4e00\u79cd\u7ed3\u5408\u8d1d\u53f6\u65af\u7f51\u7edc\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6982\u7387\u95ee\u7b54\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5728\u5927\u8868\u683c\u6570\u636e\u4e0a\u6982\u7387\u95ee\u9898\u7684\u9ad8\u6548\u56de\u7b54\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u7684\u8868\u683c\u95ee\u7b54\u65b9\u6cd5\uff08\u5982NL2SQL\uff09\u80fd\u8f83\u597d\u5904\u7406\u76f4\u63a5\u4ece\u8868\u4e2d\u68c0\u7d22\u7b54\u6848\u7684\u4e8b\u5b9e\u6027\u95ee\u9898\uff0c\u4f46\u5728\u9762\u5bf9\u9700\u8981\u4e0d\u786e\u5b9a\u6027\u63a8\u7406\u7684\u6982\u7387\u6027\u95ee\u9898\u65f6\u8868\u73b0\u4e0d\u4f73\u3002\u4e3a\u6b64\uff0c\u4f5c\u8005\u8bd5\u56fe\u63d0\u5347\u8868\u683c\u95ee\u7b54\u5728\u6982\u7387\u6027\u95ee\u9898\u4e0a\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86LUCARIO\u57fa\u51c6\uff0c\u4ee5\u53ca\u4e00\u4e2a\u9488\u5bf9\u5927\u89c4\u6a21\u8868\u683c\u6570\u636e\u7684\u6982\u7387\u95ee\u7b54\u6846\u67b6\u3002\u65b9\u6cd5\u5305\u62ec\uff1a\u4ece\u8868\u683c\u4e2d\u5f52\u7eb3\u51fa\u8d1d\u53f6\u65af\u7f51\u7edc\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8f6c\u5316\u4e3a\u6982\u7387\u67e5\u8be2\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u6700\u7ec8\u7b54\u6848\u3002\u91c7\u7528\u7b26\u53f7\u63a8\u7406\u548c\u795e\u7ecf\u63a8\u7406\u6df7\u5408\u7684\u65b9\u6cd5\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u6982\u7387\u95ee\u7b54\u4efb\u52a1\u4e0a\u76f8\u6bd4\u57fa\u7ebf\u6709\u663e\u8457\u63d0\u5347\uff0c\u4f53\u73b0\u4e86\u6df7\u5408\u7b26\u53f7-\u795e\u7ecf\u63a8\u7406\u65b9\u6cd5\u7684\u4f18\u52bf\u3002", "conclusion": "\u6df7\u5408\u8d1d\u53f6\u65af\u7f51\u7edc\u5f52\u7eb3\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u8868\u683c\u6570\u636e\u4e2d\u7684\u6982\u7387\u6027\u95ee\u7b54\u80fd\u529b\u3002\u65b0\u63d0\u51fa\u7684LUCARIO\u57fa\u51c6\u6709\u52a9\u4e8e\u63a8\u8fdb\u8be5\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2506.20883", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20883", "abs": "https://arxiv.org/abs/2506.20883", "authors": ["Kyanna Dagenais", "Istvan David"], "title": "Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance", "comment": "Accepted for ACM/IEEE MODELS'25", "summary": "Model-driven engineering problems often require complex model transformations\n(MTs), i.e., MTs that are chained in extensive sequences. Pertinent examples of\nsuch problems include model synchronization, automated model repair, and design\nspace exploration. Manually developing complex MTs is an error-prone and often\ninfeasible process. Reinforcement learning (RL) is an apt way to alleviate\nthese issues. In RL, an autonomous agent explores the state space through trial\nand error to identify beneficial sequences of actions, such as MTs. However, RL\nmethods exhibit performance issues in complex problems. In these situations,\nhuman guidance can be of high utility. In this paper, we present an approach\nand technical framework for developing complex MT sequences through RL, guided\nby potentially uncertain human advice. Our framework allows user-defined MTs to\nbe mapped onto RL primitives, and executes them as RL programs to find optimal\nMT sequences. Our evaluation shows that human guidance, even if uncertain,\nsubstantially improves RL performance, and results in more efficient\ndevelopment of complex MTs. Through a trade-off between the certainty and\ntimeliness of human advice, our method takes a step towards RL-driven\nhuman-in-the-loop engineering methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u4eba\u7c7b\u5efa\u8bae\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u5f00\u53d1\u590d\u6742\u7684\u6a21\u578b\u8f6c\u6362\u94fe\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5373\u4f7f\u5efa\u8bae\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\uff0c\u4e5f\u80fd\u63d0\u5347RL\u6027\u80fd\u548c\u5f00\u53d1\u6548\u7387\uff0c\u4e3a\u6a21\u578b\u5de5\u7a0b\u9886\u57df\u7684\u4eba\u673a\u534f\u4f5c\u63d0\u4f9b\u65b0\u601d\u8def\u3002", "motivation": "\u5728\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\u4e2d\uff0c\u590d\u6742\u7684\u6a21\u578b\u8f6c\u6362\uff08MT\uff09\u5f80\u5f80\u9700\u8981\u591a\u4e2a\u6b65\u9aa4\u4e32\u8054\uff0c\u4eba\u5de5\u5f00\u53d1\u8fd9\u4e9b\u590d\u6742\u8f6c\u6362\u5bb9\u6613\u51fa\u9519\u4e14\u6548\u7387\u4f4e\u4e0b\u3002\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u65b9\u6cd5\u867d\u80fd\u81ea\u4e3b\u63a2\u7d22\u6700\u4f73\u8f6c\u6362\u5e8f\u5217\uff0c\u4f46\u5728\u590d\u6742\u95ee\u9898\u4e0a\u6027\u80fd\u6709\u9650\uff0c\u56e0\u6b64\u8feb\u5207\u9700\u8981\u63d0\u5347\u5176\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u5e76\u7ed3\u5408\u53ef\u80fd\u4e0d\u786e\u5b9a\u7684\u4eba\u7c7b\u5efa\u8bae\u5f15\u5bfc\u7684\u65b9\u6cd5\u548c\u6280\u672f\u6846\u67b6\u3002\u8be5\u6846\u67b6\u53ef\u4ee5\u5c06\u7528\u6237\u5b9a\u4e49\u7684\u6a21\u578b\u8f6c\u6362\u6620\u5c04\u5230RL\u7684\u57fa\u672c\u64cd\u4f5c\u4e2d\uff0c\u5e76\u4ee5RL\u7a0b\u5e8f\u7684\u65b9\u5f0f\u6267\u884c\uff0c\u5bfb\u627e\u6700\u4f18\u8f6c\u6362\u5e8f\u5217\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u662f\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\u7684\u4eba\u7c7b\u5efa\u8bae\uff0c\u4e5f\u80fd\u663e\u8457\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u5728\u590d\u6742\u6a21\u578b\u8f6c\u6362\u5f00\u53d1\u4e2d\u7684\u8868\u73b0\uff0c\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u5728\u5f3a\u5316\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u5f15\u5165\u4eba\u7c7b\u5efa\u8bae\uff0c\u5b9e\u73b0\u4e86\u4eba\u673a\u534f\u540c\u7684\u590d\u6742\u6a21\u578b\u8f6c\u6362\u5f00\u53d1\uff0c\u6709\u6548\u63d0\u5347\u4e86RL\u7684\u6027\u80fd\u5e76\u63a8\u52a8\u4e86\u5de5\u7a0b\u65b9\u6cd5\u7684\u81ea\u52a8\u5316\u548c\u667a\u80fd\u5316\u3002"}}
{"id": "2506.21281", "categories": ["cs.DM"], "pdf": "https://arxiv.org/pdf/2506.21281", "abs": "https://arxiv.org/abs/2506.21281", "authors": ["Denise Graafsma", "Bodo Manthey", "Alexander Skopalik"], "title": "Playing Snake on a Graph", "comment": null, "summary": "Snake is a classic computer game, which has been around for decades. Based on\nthis game, we study the game of Snake on arbitrary undirected graphs. A snake\nforms a simple path that has to move to an apple while avoiding colliding with\nitself. When the snake reaches the apple, it grows longer, and a new apple\nappears. A graph on which the snake has a strategy to keep eating apples until\nit covers all the vertices of the graph is called snake-winnable. We prove that\ndetermining whether a graph is snake-winnable is NP-hard, even when restricted\nto grid graphs. We fully characterize snake-winnable graphs for odd-sized\nbipartite graphs and graphs with vertex-connectivity 1. While Hamiltonian\ngraphs are always snake-winnable, we show that non-Hamiltonian snake-winnable\ngraphs have a girth of at most 6 and that this bound is tight.", "AI": {"tldr": "\u57fa\u4e8e\u86c7\u6e38\u620f\uff0c\u4f5c\u8005\u7814\u7a76\u4e86\u65e0\u5411\u56fe\u4e0asnake-winnable\u95ee\u9898\uff0c\u5176\u5224\u5b9a\u4e3aNP-hard\uff0c\u5e76\u5bf9\u7279\u5b9a\u7c7b\u578b\u7684\u56fe\u7ed9\u51fa\u4e86\u5b8c\u5168\u523b\u753b\u3002", "motivation": "\u63a2\u7d22\u86c7\u6e38\u620f\u5728\u4efb\u610f\u65e0\u5411\u56fe\u4e0a\u7684\u73a9\u6cd5\u53ca\u6027\u8d28\uff0c\u4e30\u5bcc\u7ecf\u5178\u6e38\u620f\u4e0e\u56fe\u8bba\u7684\u4ea4\u53c9\u7814\u7a76\u3002", "method": "\u5b9a\u4e49\u4e86\u201csnake-winnable\u201d\u56fe\uff0c\u5f15\u5165\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u8ba8\u8bba\u5728\u4e0d\u540c\u7c7b\u578b\u56fe\uff08\u5982\u7f51\u683c\u56fe\u3001\u4e8c\u5206\u56fe\u3001\u8fde\u901a\u5ea6\u4e3a1\u7684\u56fe\uff09\u4e0b\u86c7\u80fd\u5426\u8986\u76d6\u6240\u6709\u9876\u70b9\uff0c\u5e76\u5206\u6790\u5bf9\u5e94\u7684\u8ba1\u7b97\u590d\u6742\u6027\u3002", "result": "\u8bc1\u660e\u5224\u65ad\u4e00\u4e2a\u56fe\u662f\u5426\u4e3asnake-winnable\u662fNP-hard\u95ee\u9898\uff08\u5373\u4f7f\u5728\u7f51\u683c\u56fe\u4e0b\u4ecd\u7136\u56f0\u96be\uff09\uff1b\u5b8c\u6574\u523b\u753b\u4e86\u5947\u6570\u9636\u4e8c\u5206\u56fe\u548c\u8fde\u901a\u5ea6\u4e3a1\u7684\u56fe\u4f55\u65f6snake-winnable\uff1b\u6307\u51fa\u6240\u6709\u54c8\u5bc6\u987f\u56fe\u90fdsnake-winnable\uff0c\u4e14\u975e\u54c8\u5bc6\u987fsnake-winnable\u56fe\u7684\u5708\u957f\u6700\u5927\u4e3a6\uff0c\u4e14\u6b64\u4e0a\u754c\u662f\u4e25\u683c\u7684\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660esnake-winnable\u95ee\u9898\u666e\u904d\u5177\u6709\u9ad8\u5ea6\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u540c\u65f6\u5bf9\u7279\u5b9a\u56fe\u7c7b\u8fdb\u884c\u4e86\u5177\u4f53\u523b\u753b\uff0c\u4e30\u5bcc\u4e86\u56fe\u8bba\u4e0e\u6e38\u620f\u7b97\u6cd5\u7684\u4ea4\u53c9\u9886\u57df\u3002"}}
{"id": "2506.21481", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2506.21481", "abs": "https://arxiv.org/abs/2506.21481", "authors": ["Eike Neumann"], "title": "Deciding Robust Instances of an Escape Problem for Dynamical Systems in Euclidean Space", "comment": null, "summary": "We study the problem of deciding whether a point escapes a closed subset of\n$\\mathbb{R}^d$ under the iteration of a continuous map $f \\colon \\mathbb{R}^d\n\\to \\mathbb{R}^d$ in the bit-model of real computation. We give a sound partial\ndecision method for this problem which is complete in the sense that its\nhalting set contains the halting set of all sound partial decision methods for\nthe problem. Equivalently, our decision method terminates on all problem\ninstances whose answer is robust under all sufficiently small perturbations of\nthe function. We further show that the halting set of our algorithm is dense in\nthe set of all problem instances. While our algorithm applies to general\ncontinuous functions, we demonstrate that it also yields complete decision\nmethods for much more rigid function families: affine linear systems and\nquadratic complex polynomials. In the latter case, completeness is subject to\nthe density of hyperbolicity conjecture in complex dynamics. This in particular\nyields an alternative proof of Hertling's (2004) conditional answer to a\nquestion raised by Penrose (1989) regarding the computability of the Mandelbrot\nset.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5b9e\u6570\u4f4d\u6a21\u578b\u4e0b\uff0c\u5bf9\u70b9\u5728\u8fde\u7eed\u6620\u5c04\u4e0b\u9003\u79bb\u95ed\u96c6\u95ee\u9898\u7684\u6700\u4f18\u90e8\u5206\u51b3\u7b56\u7b97\u6cd5\uff0c\u8986\u76d6\u4e86\u4e00\u822c\u51fd\u6570\u4e0e\u7279\u6b8a\u51fd\u6570\u65cf\uff0c\u5e76\u7ed9\u51fa\u6761\u4ef6\u4e0bMandelbrot\u96c6\u53ef\u8ba1\u7b97\u6027\u7684\u65b0\u8bc1\u636e\u3002", "motivation": "\u672c\u6587\u5173\u6ce8\u5728\u8fde\u7eed\u6620\u5c04\u4e0b\uff0c\u5224\u65ad\u4e00\u4e2a\u70b9\u662f\u5426\u4f1a\u9003\u79bb\u95ed\u5b50\u96c6\u7684\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5b9e\u6570\u4f4d\u6a21\u578b\u4e0b\u8f83\u96be\u83b7\u5f97\u5b8c\u6574\u51b3\u7b56\u8fc7\u7a0b\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5b9e\u6570\u4f4d\u6a21\u578b\u4e0b\u7528\u4e8e\u8be5\u95ee\u9898\u7684\u53ef\u9760\u90e8\u5206\u51b3\u7b56\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u5728\u6240\u6709\u53ef\u9760\u90e8\u5206\u51b3\u7b56\u65b9\u6cd5\u7684\u505c\u673a\u96c6\u5408\u4e2d\u4e3a\u6700\u5927\uff0c\u5373\u5bf9\u6240\u6709\u5728\u5fae\u5c0f\u6270\u52a8\u4e0b\u7b54\u6848\u7a33\u5b9a\u7684\u95ee\u9898\u5b9e\u4f8b\u90fd\u80fd\u7ed9\u51fa\u7ed3\u8bba\u3002\u5e76\u5c06\u65b9\u6cd5\u5e94\u7528\u4e8e\u4e00\u822c\u8fde\u7eed\u51fd\u6570\u3001\u4eff\u5c04\u7ebf\u6027\u7cfb\u7edf\u53ca\u4e8c\u6b21\u590d\u591a\u9879\u5f0f\u3002", "result": "\u7b97\u6cd5\u5bf9\u4e8e\u89e3\u7b54\u5728\u5c0f\u6270\u52a8\u4e0b\u9c81\u68d2\u7684\u95ee\u9898\u5b9e\u4f8b\u603b\u80fd\u505c\u673a\uff0c\u5e76\u4e14\u5176\u505c\u673a\u96c6\u5728\u6240\u6709\u95ee\u9898\u5b9e\u4f8b\u4e2d\u662f\u7a20\u5bc6\u7684\u3002\u5bf9\u7279\u6b8a\u51fd\u6570\u65cf\uff08\u5982\u4eff\u5c04\u7ebf\u6027\u7cfb\u7edf\u3001\u4e8c\u6b21\u590d\u591a\u9879\u5f0f\uff09\u4e5f\u80fd\u7ed9\u51fa\u5b8c\u6574\u7ed3\u679c\uff0c\u5728\u540e\u8005\u7684\u60c5\u5f62\u4e0b\u5b8c\u6574\u6027\u4f9d\u8d56\u4e8e\u590d\u52a8\u529b\u5b66\u4e2d\u7684\u8d85\u8d8a\u6027\u7a20\u5bc6\u6027\u5047\u8bbe\u3002\u6b64\u5916\u5f97\u5230Mandelbrot\u96c6\u53ef\u8ba1\u7b97\u6027\u7684\u53e6\u4e00\u79cd\u8bc1\u660e\uff0c\u56de\u5e94\u4e86Penrose\u63d0\u51fa\u7684\u95ee\u9898\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5224\u65ad\u70b9\u662f\u5426\u80fd\u5728\u8fde\u7eed\u6620\u5c04\u4e0b\u9003\u79bb\u95ed\u96c6\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0a\u6700\u5b8c\u5907\u7684\u90e8\u5206\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5e76\u62d3\u5c55/\u5b8c\u5584\u4e86\u76f8\u5173\u51fd\u6570\u65cf\u7684\u53ef\u8ba1\u7b97\u6027\u7406\u89e3\uff0c\u5c24\u5176\u5728\u590d\u6742\u52a8\u529b\u7cfb\u7edf\u9886\u57df\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2506.20793", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.20793", "abs": "https://arxiv.org/abs/2506.20793", "authors": ["Victor Ojewale", "Inioluwa Deborah Raji", "Suresh Venkatasubramanian"], "title": "Multi-lingual Functional Evaluation for Large Language Models", "comment": null, "summary": "Multi-lingual competence in large language models is often evaluated via\nstatic data benchmarks such as Belebele, M-MMLU and M-GSM. However, these\nevaluations often fail to provide an adequate understanding of the practical\nperformance and robustness of models across multi-lingual settings. In\nresponse, we create multi-lingual functional benchmarks -- Cross-Lingual Grade\nSchool Math Symbolic (CL-GSM Symbolic) and Cross-Lingual Instruction-Following\nEval (CL-IFEval)-- by translating existing functional benchmark templates from\nEnglish to five additional languages that span the range of resources available\nfor NLP: French, Spanish, Hindi, Arabic and Yoruba. Our results reveal that\nsome static multi-lingual benchmarks capture functional performance much more\nclosely than others (i.e. across models, there is a 24%, 17% and 18% decrease\nin performance between M-GSM and CL-GSM Symbolic in English, French and Spanish\nrespectively; similarly there's a 15 - 24% performance drop across languages\nbetween Belebele and CL-IFEval, and only a 0.5% to 3% performance drop between\nM-MMLU and CL-IFEval). Similarly, we find that model robustness across\nlanguages varies significantly, with certain languages (eg. Arabic, English)\nbeing the most consistently well performing across evaluation iterations.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6784\u5efa\u8de8\u8bed\u8a00\u529f\u80fd\u578b\u57fa\u51c6\uff0c\u53d1\u73b0\u5f53\u524d\u591a\u8bed\u8a00\u5927\u6a21\u578b\u5728\u5b9e\u9645\u591a\u8bed\u8a00\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u4e0e\u9759\u6001\u8bc4\u6d4b\u7ed3\u679c\u5b58\u5728\u660e\u663e\u5dee\u8ddd\uff0c\u4e14\u5728\u4e0d\u540c\u8bed\u8a00\u95f4\u7684\u9c81\u68d2\u6027\u8868\u73b0\u4e0d\u5747\u3002\u65b0\u57fa\u51c6\u4e3a\u591a\u8bed\u8a00\u80fd\u529b\u7684\u771f\u5b9e\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u5de5\u5177\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u8bed\u8a00\u80fd\u529b\u4e3b\u8981\u901a\u8fc7\u9759\u6001\u6570\u636e\u57fa\u51c6\u8fdb\u884c\u8bc4\u4f30\uff0c\u5982Belebele\u3001M-MMLU\u548cM-GSM\uff0c\u4f46\u8fd9\u4e9b\u8bc4\u4f30\u672a\u80fd\u5145\u5206\u53cd\u6620\u6a21\u578b\u5728\u5b9e\u9645\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u7684\u8868\u73b0\u548c\u7a33\u5065\u6027\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u5177\u5b9e\u7528\u6027\u7684\u591a\u8bed\u8a00\u529f\u80fd\u578b\u57fa\u51c6\u3002", "method": "\u7814\u7a76\u521b\u5efa\u4e86\u4e24\u7c7b\u591a\u8bed\u8a00\u529f\u80fd\u578b\u57fa\u51c6\uff1a\u8de8\u8bed\u8a00\u7684Grade School Math Symbolic\uff08CL-GSM Symbolic\uff09\u548c\u8de8\u8bed\u8a00\u6307\u4ee4\u8ddf\u968f\u8bc4\u6d4b\uff08CL-IFEval\uff09\uff0c\u5373\u5c06\u73b0\u6709\u7684\u529f\u80fd\u578b\u57fa\u51c6\u6a21\u677f\u4ece\u82f1\u8bed\u7ffb\u8bd1\u81f3\u6cd5\u8bed\u3001\u897f\u73ed\u7259\u8bed\u3001\u5370\u5730\u8bed\u3001\u963f\u62c9\u4f2f\u8bed\u548c\u7ea6\u9c81\u5df4\u8bed\u4e94\u79cd\u4e0d\u540c\u8d44\u6e90\u6c34\u5e73\u7684\u8bed\u8a00\u3002\u968f\u540e\u5728\u8fd9\u4e9b\u65b0\u57fa\u51c6\u4e0a\u5bf9\u5927\u6a21\u578b\u8fdb\u884c\u8bc4\u6d4b\u3002", "result": "\u53d1\u73b0\u4e0d\u540c\u9759\u6001\u591a\u8bed\u8a00\u57fa\u51c6\u6355\u6349\u529f\u80fd\u578b\u6027\u80fd\u7684\u51c6\u786e\u6027\u5dee\u5f02\u8f83\u5927\u3002\u4f8b\u5982\uff0c\u5728\u6a21\u578b\u95f4\uff0cM-GSM\u5230CL-GSM Symbolic\u4e4b\u95f4\u5728\u82f1\u8bed\u3001\u6cd5\u8bed\u548c\u897f\u73ed\u7259\u8bed\u4e0a\u7684\u6027\u80fd\u5206\u522b\u4e0b\u964d24%\u300117%\u548c18%\uff1bBelebele\u5230CL-IFEval\uff0c\u5404\u8bed\u8a00\u6027\u80fd\u4e0b\u964d15-24%\uff1b\u800cM-MMLU\u5230CL-IFEval\u4ec5\u4e0b\u964d0.5%-3%\u3002\u540c\u65f6\uff0c\u6a21\u578b\u5728\u4e0d\u540c\u8bed\u8a00\u4e0b\u7684\u7a33\u5065\u6027\u663e\u8457\u4e0d\u540c\uff0c\u90e8\u5206\u8bed\u8a00\uff08\u5982\u963f\u62c9\u4f2f\u8bed\u548c\u82f1\u8bed\uff09\u5728\u591a\u6b21\u8bc4\u6d4b\u4e2d\u8868\u73b0\u6700\u4e3a\u7a33\u5b9a\u3002", "conclusion": "\u4f20\u7edf\u9759\u6001\u591a\u8bed\u8a00\u57fa\u51c6\u672a\u80fd\u5168\u9762\u53cd\u6620\u5927\u6a21\u578b\u7684\u5b9e\u9645\u591a\u8bed\u8a00\u80fd\u529b\u3002\u65b0\u6784\u5efa\u7684\u529f\u80fd\u578b\u591a\u8bed\u8a00\u57fa\u51c6\u66f4\u597d\u68c0\u6d4b\u4e86\u6a21\u578b\u7684\u6cdb\u7528\u548c\u7a33\u5065\u6027\u80fd\uff0c\u5e76\u63ed\u793a\u4e86\u4e0d\u540c\u8bed\u8a00\u95f4\u6a21\u578b\u80fd\u529b\u7684\u4e0d\u5747\u8861\u3002\u5efa\u8bae\u540e\u7eed\u8bc4\u4f30\u591a\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u91c7\u7528\u66f4\u8d34\u8fd1\u5b9e\u9645\u4efb\u52a1\u7684\u591a\u8bed\u8a00\u529f\u80fd\u578b\u6d4b\u8bd5\u65b9\u6cd5\u3002"}}
{"id": "2506.21014", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.21014", "abs": "https://arxiv.org/abs/2506.21014", "authors": ["Shaojian Qiu", "Mengyang Huang", "Jiahao Cheng"], "title": "Boosting Vulnerability Detection with Inter-function Multilateral Association Insights", "comment": null, "summary": "Vulnerability detection is a crucial yet challenging technique for ensuring\nthe security of software systems. Currently, most deep learning-based\nvulnerability detection methods focus on stand-alone functions, neglecting the\ncomplex inter-function interrelations, particularly the multilateral\nassociations. This oversight can fail to detect vulnerabilities in these\ninterrelations. To address this gap, we present an Inter-Function Multilateral\nAssociation analysis framework for Vulnerability Detection (IFMA-VD). The\ncornerstone of the IFMA-VD lies in constructing a code behavior hypergraph and\nutilizing hyperedge convolution to extract multilateral association features.\nSpecifically, we first parse functions into a code property graph to generate\nintra-function features. Following this, we construct a code behavior\nhypergraph by segmenting the program dependency graph to isolate and encode\nbehavioral features into hyperedges. Finally, we utilize a hypergraph network\nto capture the multilateral association knowledge for augmenting vulnerability\ndetection. We evaluate IFMA-VD on three widely used vulnerability datasets and\ndemonstrate improvements in F-measure and Recall compared to baseline methods.\nAdditionally, we illustrate that multilateral association features can boost\ncode feature representation and validate the effectiveness of IFMA-VD on\nreal-world datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86IFMA-VD\u6846\u67b6\uff0c\u901a\u8fc7\u8d85\u56fe\u7f51\u7edc\u5efa\u6a21\u8de8\u51fd\u6570\u591a\u8fb9\u5173\u8054\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6f0f\u6d1e\u68c0\u6d4b\u7684\u6548\u679c\uff0c\u5e76\u5728\u516c\u5f00\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u90fd\u83b7\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5927\u591a\u6570\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4e8e\u5355\u72ec\u51fd\u6570\uff0c\u5ffd\u7565\u4e86\u51fd\u6570\u95f4\u7684\u590d\u6742\u591a\u8fb9\u5173\u8054\uff0c\u4ece\u800c\u53ef\u80fd\u9057\u6f0f\u8fd9\u4e9b\u5173\u8054\u4e2d\u7684\u6f0f\u6d1e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9762\u5411\u6f0f\u6d1e\u68c0\u6d4b\u7684\u8de8\u51fd\u6570\u591a\u8fb9\u5173\u8054\u5206\u6790\u6846\u67b6\uff08IFMA-VD\uff09\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u6784\u5efa\u4ee3\u7801\u884c\u4e3a\u8d85\u56fe\uff0c\u5e76\u5229\u7528\u8d85\u8fb9\u5377\u79ef\u63d0\u53d6\u591a\u8fb9\u5173\u8054\u7279\u5f81\uff0c\u5177\u4f53\u5305\u62ec\uff1a\u5c06\u51fd\u6570\u89e3\u6790\u4e3a\u4ee3\u7801\u5c5e\u6027\u56fe\u751f\u6210\u51fd\u6570\u5185\u7279\u5f81\uff0c\u5206\u5272\u7a0b\u5e8f\u4f9d\u8d56\u56fe\u6784\u5efa\u884c\u4e3a\u7279\u5f81\u8d85\u8fb9\uff0c\u6700\u540e\u901a\u8fc7\u8d85\u56fe\u7f51\u7edc\u6355\u83b7\u591a\u8fb9\u5173\u8054\u77e5\u8bc6\u4ee5\u589e\u5f3a\u6f0f\u6d1e\u68c0\u6d4b\u3002", "result": "\u5728\u4e09\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u6f0f\u6d1e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cIFMA-VD\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5728F-measure\u548cRecall\u4e0a\u5747\u6709\u63d0\u5347\u3002\u6b64\u5916\uff0c\u591a\u8fb9\u5173\u8054\u7279\u5f81\u53ef\u4ee5\u63d0\u5347\u4ee3\u7801\u7279\u5f81\u8868\u8fbe\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u4e5f\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8003\u8651\u51fd\u6570\u4e4b\u95f4\u591a\u8fb9\u5173\u8054\u80fd\u591f\u663e\u8457\u63d0\u5347\u6f0f\u6d1e\u68c0\u6d4b\u6027\u80fd\uff0cIFMA-VD\u6846\u67b6\u5728\u591a\u9879\u6307\u6807\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u5b9e\u9645\u573a\u666f\u4e0b\u9a8c\u8bc1\u6709\u6548\u3002"}}
{"id": "2506.20803", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20803", "abs": "https://arxiv.org/abs/2506.20803", "authors": ["Chenglei Si", "Tatsunori Hashimoto", "Diyi Yang"], "title": "The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas", "comment": "main paper is 14 pages", "summary": "Large Language Models (LLMs) have shown promise in accelerating the\nscientific research pipeline. A key capability for this process is the ability\nto generate novel research ideas, and prior studies have found settings in\nwhich LLM-generated research ideas were judged as more novel than human-expert\nideas. However, a good idea should not simply appear to be novel, it should\nalso result in better research after being executed. To test whether\nAI-generated ideas lead to better research outcomes, we conduct an execution\nstudy by recruiting 43 expert researchers to execute randomly-assigned ideas,\neither written by experts or generated by an LLM. Each expert spent over 100\nhours implementing the idea and wrote a 4-page short paper to document the\nexperiments. All the executed projects are then reviewed blindly by expert NLP\nresearchers. Comparing the review scores of the same ideas before and after\nexecution, the scores of the LLM-generated ideas decrease significantly more\nthan expert-written ideas on all evaluation metrics (novelty, excitement,\neffectiveness, and overall; p < 0.05), closing the gap between LLM and human\nideas observed at the ideation stage. When comparing the aggregated review\nscores from the execution study, we even observe that for many metrics there is\na flip in rankings where human ideas score higher than LLM ideas. This\nideation-execution gap highlights the limitations of current LLMs in generating\ntruly effective research ideas and the challenge of evaluating research ideas\nin the absence of execution outcomes.", "AI": {"tldr": "LLM\u867d\u7136\u80fd\u4ea7\u751f\u770b\u8d77\u6765\u65b0\u9896\u7684\u7814\u7a76\u60f3\u6cd5\uff0c\u4f46\u7ecf\u8fc7\u4e13\u5bb6\u5b9e\u9645\u6267\u884c\u540e\uff0c\u7814\u7a76\u6548\u679c\u8fdc\u4e0d\u5982\u4eba\u7c7b\u4e13\u5bb6\u7684\u60f3\u6cd5\uff0c\u63ed\u793a\u51fa\u5927\u6a21\u578b\u5728\u79d1\u7814\u521b\u610f\u751f\u6210\u4e0a\u4ecd\u6709\u660e\u663e\u77ed\u677f\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660eLLM\u80fd\u5728\u521b\u610f\u9636\u6bb5\u4ea7\u751f\u65b0\u9896\u60f3\u6cd5\uff0c\u4f46\u7814\u7a76\u521b\u610f\u7684\u597d\u574f\u4e0d\u4ec5\u5728\u4e8e\u65b0\u9896\uff0c\u66f4\u5728\u4e8e\u4ed8\u8bf8\u5b9e\u8df5\u540e\u7684\u7814\u7a76\u6210\u679c\u4f18\u52a3\u3002\u672c\u7814\u7a76\u8bd5\u56fe\u5b9e\u8bc1\u9a8c\u8bc1\uff1aLLM\u4ea7\u51fa\u7684\u60f3\u6cd5\u662f\u5426\u5728\u5b9e\u9645\u6267\u884c\u540e\u80fd\u8f6c\u5316\u4e3a\u4f18\u8d28\u7684\u7814\u7a76\u7ed3\u679c\u3002", "method": "\u4f5c\u8005\u7ec4\u7ec743\u540dNLP\u9886\u57df\u4e13\u5bb6\uff0c\u5728\u4e0d\u77e5\u60c5\u7684\u60c5\u51b5\u4e0b\uff0c\u5206\u522b\u6267\u884c\u7531\u4e13\u5bb6\u548cLLM\u4ea7\u51fa\u7684\u7814\u7a76\u60f3\u6cd5\u3002\u6bcf\u4f4d\u4e13\u5bb6\u6295\u5165100\u5c0f\u65f6\u4ee5\u4e0a\uff0c\u5c06\u60f3\u6cd5\u843d\u5b9e\u4e3a\u5b9e\u9a8c\u5e76\u5199\u6210\u77ed\u8bba\u6587\uff0c\u7136\u540e\u7531\u72ec\u7acb\u4e13\u5bb6\u533f\u540d\u8bc4\u5ba1\u5e76\u6bd4\u8f83\u5404\u4e2a\u9636\u6bb5\uff08\u521b\u610f\u3001\u6267\u884c\u540e\uff09\u8bc4\u5206\u3002", "result": "LLM\u4ea7\u51fa\u7684\u60f3\u6cd5\u5728\u5b9e\u8df5\u6267\u884c\u540e\uff0c\u5404\u9879\u8bc4\u5ba1\u6307\u6807\uff08\u65b0\u9896\u6027\u3001\u6fc0\u52a8\u4eba\u5fc3\u3001\u6709\u6548\u6027\u548c\u6574\u4f53\u8bc4\u5206\uff09\u5747\u663e\u8457\u4e0b\u8dcc\uff0c\u751a\u81f3\u5728\u90e8\u5206\u6307\u6807\u4e0a\u88ab\u4e13\u5bb6\u521b\u610f\u53cd\u8d85\uff0c\u4f53\u73b0LLM\u5728\u9ad8\u6548\u79d1\u7814\u60f3\u6cd5\u751f\u6210\u4e0a\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u5f53\u524d\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u751f\u6210\u79d1\u5b66\u7814\u7a76\u521b\u610f\u65f6\uff0c\u867d\u7136\u8868\u9762\u4e0a\u663e\u793a\u51fa\u65b0\u9896\u6027\uff0c\u4f46\u5176\u521b\u610f\u7ecf\u8fc7\u5b9e\u9645\u6267\u884c\u540e\uff0c\u6548\u679c\u663e\u8457\u900a\u4e8e\u4eba\u7c7b\u4e13\u5bb6\u63d0\u51fa\u7684\u60f3\u6cd5\uff0c\u8bf4\u660eLLM\u5c1a\u4e0d\u80fd\u66ff\u4ee3\u4eba\u7c7b\u4e13\u5bb6\u5728\u5f62\u6210\u9ad8\u8d28\u91cf\u7814\u7a76\u8bae\u9898\u65b9\u9762\u7684\u4f5c\u7528\u3002"}}
{"id": "2506.21138", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21138", "abs": "https://arxiv.org/abs/2506.21138", "authors": ["Abdelkarim El-Hajjami", "Camille Salinesi"], "title": "How Good Are Synthetic Requirements ? Evaluating LLM-Generated Datasets for AI4RE", "comment": null, "summary": "The shortage of publicly available, labeled requirements datasets remains a\nmajor barrier to advancing Artificial Intelligence for Requirements Engineering\n(AI4RE). While Large Language Models offer promising capabilities for synthetic\ndata generation, systematic approaches to control and optimize the quality of\ngenerated requirements remain underexplored. This paper presents Synthline v1,\nan enhanced Product Line approach for generating synthetic requirements data\nthat extends our earlier v0 version with advanced generation strategies and\ncuration techniques. We investigate four research questions assessing how\nprompting strategies, automated prompt optimization, and post-generation\ncuration affect data quality across four classification tasks: defect\ndetection, functional vs. non-functional, quality vs. non-quality, and security\nvs. non-security. Our evaluation shows that multi-sample prompting\nsignificantly boosts both utility and diversity over single-sample generation,\nwith F1-score gains from 6 to 44 points. The use of PACE (Prompt Actor-Critic\nEditing) for automated prompt optimization yields task-dependent results,\ngreatly improving functional classification (+32.5 points) but reducing\nperformance on others. Interestingly, similarity-based curation improves\ndiversity but often harms classification performance, indicating that some\nredundancy may help ML models. Most importantly, our results show that\nsynthetic requirements can match or outperform human-authored ones for specific\ntasks, with synthetic data surpassing human data for security (+7.8 points) and\ndefect classification (+15.4 points). These findings offer practical insights\nfor AI4RE and chart a viable path to mitigating dataset scarcity through\nsystematic synthetic generation.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u7684\u9700\u6c42\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\uff0c\u5728\u7279\u5b9a\u4efb\u52a1\u4e2d\u5408\u6210\u6570\u636e\u7684\u6027\u80fd\u53ef\u8d85\u8fc7\u4eba\u5de5\u6570\u636e\uff0c\u4e3aAI4RE\u9886\u57df\u89e3\u51b3\u6570\u636e\u96c6\u7a00\u7f3a\u6307\u660e\u4e86\u65b9\u5411\u3002", "motivation": "AI\u5728\u9700\u6c42\u5de5\u7a0b\u9886\u57df\u7684\u5e94\u7528\u53d7\u9650\u4e8e\u7f3a\u4e4f\u516c\u5f00\u53ef\u7528\u4e14\u6709\u6807\u6ce8\u7684\u9700\u6c42\u6570\u636e\u96c6\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5408\u6210\u6570\u636e\uff0c\u4f46\u5982\u4f55\u7cfb\u7edf\u63d0\u5347\u751f\u6210\u9700\u6c42\u6570\u636e\u7684\u8d28\u91cf\u5c1a\u672a\u88ab\u6df1\u5165\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e86Synthline v1\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u4ea7\u54c1\u7ebf\u7684\u589e\u5f3a\u5408\u6210\u9700\u6c42\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u6539\u8fdb\u751f\u6210\u7b56\u7565\u548c\u540e\u5904\u7406\u6280\u672f\uff0c\u63a2\u8ba8\u4e86\u63d0\u793a\u7b56\u7565\u3001\u591a\u6837\u672c\u751f\u6210\u3001\u81ea\u52a8\u5316\u4f18\u5316\uff08\u5982PACE\uff09\u53ca\u540e\u671f\u7b5b\u9009\u7b49\u65b9\u5f0f\u5bf9\u6570\u636e\u96c6\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u5e76\u5728\u56db\u9879\u5206\u7c7b\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u591a\u6837\u672c\u751f\u6210\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u7684\u5b9e\u7528\u6027\u548c\u591a\u6837\u6027\uff0cF1\u5206\u6570\u63d0\u53476~44\u70b9\uff1bPACE\u4f18\u5316\u5bf9\u67d0\u4e9b\u4efb\u52a1\uff08\u5982\u529f\u80fd\u5206\u7c7b\uff09\u6548\u679c\u660e\u663e\uff08+32.5\u70b9\uff09\uff0c\u4f46\u4f1a\u524a\u5f31\u5176\u4ed6\u4efb\u52a1\u8868\u73b0\uff1b\u57fa\u4e8e\u76f8\u4f3c\u5ea6\u7684\u540e\u5904\u7406\u63d0\u5347\u591a\u6837\u6027\u5374\u5e38\u524a\u5f31\u5206\u7c7b\u6027\u80fd\u3002\u90e8\u5206\u4efb\u52a1\u4e0a\uff0c\u751f\u6210\u6570\u636e\u8868\u73b0\u8d85\u8d8a\u771f\u4eba\u6570\u636e\uff08\u5b89\u5168\u4efb\u52a1\u63d0\u5347+7.8\u70b9\uff0c\u7f3a\u9677\u4efb\u52a1+15.4\u70b9\uff09\u3002", "conclusion": "\u7cfb\u7edf\u6027\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u53ef\u4ee5\u6709\u6548\u7f13\u89e3\u9700\u6c42\u5de5\u7a0b\u9886\u57df\u6570\u636e\u96c6\u532e\u4e4f\u95ee\u9898\uff0c\u5e76\u5728\u7279\u5b9a\u4efb\u52a1\u4e2d\u8fbe\u5230\u751a\u81f3\u8d85\u8fc7\u4eba\u5de5\u6570\u636e\u7684\u6548\u679c\u3002"}}
{"id": "2506.20821", "categories": ["cs.CL", "cs.AI", "cs.CE", "68T50, 68T07 (Primary) 68P20, 91G15, 91G70, 68U10 (Secondary)", "I.2.7; I.2.10; H.3.3; H.2.8; I.5.4; J.1"], "pdf": "https://arxiv.org/pdf/2506.20821", "abs": "https://arxiv.org/abs/2506.20821", "authors": ["Chinmay Gondhalekar", "Urjitkumar Patel", "Fang-Chun Yeh"], "title": "MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering", "comment": "Preprint Copy", "summary": "Financial documents--such as 10-Ks, 10-Qs, and investor presentations--span\nhundreds of pages and combine diverse modalities, including dense narrative\ntext, structured tables, and complex figures. Answering questions over such\ncontent often requires joint reasoning across modalities, which strains\ntraditional large language models (LLMs) and retrieval-augmented generation\n(RAG) pipelines due to token limitations, layout loss, and fragmented\ncross-modal context. We introduce MultiFinRAG, a retrieval-augmented generation\nframework purpose-built for financial QA. MultiFinRAG first performs multimodal\nextraction by grouping table and figure images into batches and sending them to\na lightweight, quantized open-source multimodal LLM, which produces both\nstructured JSON outputs and concise textual summaries. These outputs, along\nwith narrative text, are embedded and indexed with modality-aware similarity\nthresholds for precise retrieval. A tiered fallback strategy then dynamically\nescalates from text-only to text+table+image contexts when necessary, enabling\ncross-modal reasoning while reducing irrelevant context. Despite running on\ncommodity hardware, MultiFinRAG achieves 19 percentage points higher accuracy\nthan ChatGPT-4o (free-tier) on complex financial QA tasks involving text,\ntables, images, and combined multimodal reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86MultiFinRAG\uff0c\u4e00\u5957\u9488\u5bf9\u91d1\u878d\u591a\u6a21\u6001\u6587\u6863\u95ee\u7b54\u7684\u9ad8\u6548RAG\u65b9\u6848\uff0c\u5728\u590d\u6742\u573a\u666f\u4e0b\u51c6\u786e\u7387\u663e\u8457\u4f18\u4e8eChatGPT-4o\u3002", "motivation": "\u4f20\u7edf\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u5728\u5904\u7406\u91d1\u878d\u6587\u6863\u65f6\u5b58\u5728\u8bf8\u591a\u6311\u6218\uff0c\u5982Token\u9650\u5236\u3001\u5e03\u5c40\u4e22\u5931\u548c\u8de8\u6a21\u6001\u4e0a\u4e0b\u6587\u788e\u7247\u5316\uff0c\u96be\u4ee5\u5e94\u5bf9\u590d\u6742\u7684\u8de8\u6587\u672c\u3001\u8868\u683c\u548c\u56fe\u50cf\u7684\u63a8\u7406\u4efb\u52a1\u3002", "method": "\u63d0\u51faMultiFinRAG\u6846\u67b6\uff0c\u5229\u7528\u8f7b\u91cf\u5316\u7684\u5f00\u6e90\u591a\u6a21\u6001LLM\u5bf9\u8868\u683c\u548c\u56fe\u7247\u8fdb\u884c\u6279\u91cf\u62bd\u53d6\uff0c\u4e3a\u5176\u751f\u6210\u7ed3\u6784\u5316JSON\u548c\u7b80\u660e\u6458\u8981\uff0c\u5e76\u4e0e\u53d9\u8ff0\u6587\u672c\u5171\u540c\u91c7\u7528\u6a21\u6001\u611f\u77e5\u7684\u76f8\u4f3c\u5ea6\u5d4c\u5165\u548c\u68c0\u7d22\u3002\u6846\u67b6\u5f15\u5165\u5206\u5c42\u56de\u9000\u7b56\u7565\uff0c\u6839\u636e\u9700\u8981\u52a8\u6001\u4ece\u6587\u672c\u63a8\u7406\u5347\u7ea7\u5230\u6587\u672c+\u8868\u683c+\u56fe\u7247\u8054\u5408\u63a8\u7406\u3002", "result": "\u5728\u666e\u901a\u786c\u4ef6\u4e0a\uff0cMultiFinRAG\u5728\u590d\u6742\u91d1\u878d\u95ee\u7b54\u4efb\u52a1\u4e2d\uff0c\u51c6\u786e\u7387\u6bd4ChatGPT-4o\uff08\u514d\u8d39\u7248\uff09\u9ad8\u51fa19\u4e2a\u767e\u5206\u70b9\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u6587\u672c\u3001\u8868\u683c\u3001\u56fe\u7247\u548c\u591a\u6a21\u6001\u8054\u5408\u63a8\u7406\u573a\u666f\u4e0b\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "MultiFinRAG\u662f\u4e00\u79cd\u4e13\u4e3a\u91d1\u878d\u9886\u57df\u591a\u6a21\u6001\u95ee\u7b54\u8bbe\u8ba1\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u9ad8\u6548\u62bd\u53d6\u4e0e\u5206\u5c42\u68c0\u7d22\u663e\u8457\u63d0\u5347\u590d\u6742\u91d1\u878d\u6587\u6863\u7684\u95ee\u7b54\u80fd\u529b\uff0c\u8d85\u8d8a\u73b0\u6709\u4e3b\u6d41LLM\u8868\u73b0\u3002"}}
{"id": "2506.21211", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21211", "abs": "https://arxiv.org/abs/2506.21211", "authors": ["Quanming Liu", "Xupeng Bu", "Zhichao Yan", "Ru Li"], "title": "$T^3$: Multi-level Tree-based Automatic Program Repair with Large Language Models", "comment": null, "summary": "Automatic Program Repair (APR) is a core technology in software development\nand maintenance, with aims to enable automated defect repair with minimal human\nintervention. In recent years, the substantial advancements in Large Language\nModels (LLMs) and the Chain-of-Thought (CoT) techniques have significantly\nenhanced the reasoning capabilities of these models. However, due to the\ncomplex logic and multi-step reasoning ability needed, the application of CoT\ntechniques in the APR domain remains insufficient. This study systematically\nevaluates the performance of several common CoT techniques in APR tasks and\nproposes an innovative framework $T^3$, which integrates the powerful reasoning\ncapabilities of LLMs with tree search, effectively improving the precision of\ngenerating candidate repair solutions. Furthermore, $T^3$ provides valuable\nguidance for optimizing sample selection and repair strategies in APR tasks,\nestablishing a robust framework for achieving efficient automated debugging.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0APR\u6846\u67b6$T^3$\uff0c\u7ed3\u5408\u4e86LLM\u63a8\u7406\u548c\u6811\u641c\u7d22\uff0c\u5728\u81ea\u52a8\u4fee\u590d\u7a0b\u5e8f\u7f3a\u9677\u548c\u63d0\u5347\u4fee\u590d\u65b9\u6848\u7cbe\u5ea6\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u968f\u7740LLMs\u548cCoT\u6280\u672f\u7684\u53d1\u5c55\uff0c\u63a8\u7406\u80fd\u529b\u5f97\u5230\u589e\u5f3a\uff0c\u4f46\u73b0\u6709CoT\u5728APR\u9886\u57df\u5e94\u7528\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u590d\u6742\u903b\u8f91\u4e0e\u591a\u6b65\u63a8\u7406\u7684\u573a\u666f\u3002\u4f5c\u8005\u5e0c\u671b\u63d0\u5347APR\u4efb\u52a1\u4e2d\u7684\u81ea\u52a8\u5316\u4e0e\u7cbe\u5ea6\u3002", "method": "\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e86\u591a\u79cd\u4e3b\u6d41CoT\u6280\u5de7\u5728APR\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u521b\u65b0\u6027\u5730\u63d0\u51fa\u4e86 $T^3$ \u6846\u67b6\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u63a8\u7406\u80fd\u529b\u4e0e\u6811\u641c\u7d22\u7b97\u6cd5\u7ed3\u5408\u3002", "result": "$T^3$ \u6846\u67b6\u63d0\u5347\u4e86APR\u4efb\u52a1\u7684\u5019\u9009\u4fee\u590d\u751f\u6210\u7cbe\u5ea6\uff0c\u5e76\u4e3a\u81ea\u52a8\u8c03\u8bd5\u63d0\u4f9b\u4e86\u66f4\u52a0\u9ad8\u6548\u3001\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u7684 $T^3$ \u6846\u67b6\u5c06LLMs\u7684\u63a8\u7406\u80fd\u529b\u4e0e\u6811\u641c\u7d22\u7ed3\u5408\uff0c\u63d0\u5347\u4e86\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u7684\u5019\u9009\u4fee\u590d\u65b9\u6848\u7684\u7cbe\u5ea6\uff0c\u5e76\u4e3a\u6837\u672c\u9009\u62e9\u548c\u4fee\u590d\u7b56\u7565\u4f18\u5316\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2506.20822", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20822", "abs": "https://arxiv.org/abs/2506.20822", "authors": ["Quintin Myers", "Yanjun Gao"], "title": "Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral Vignettes", "comment": "Under review", "summary": "Large language models (LLMs) are increasingly proposed for detecting and\nresponding to violent content online, yet their ability to reason about morally\nambiguous, real-world scenarios remains underexamined. We present the first\nstudy to evaluate LLMs using a validated social science instrument designed to\nmeasure human response to everyday conflict, namely the Violent Behavior\nVignette Questionnaire (VBVQ). To assess potential bias, we introduce\npersona-based prompting that varies race, age, and geographic identity within\nthe United States. Six LLMs developed across different geopolitical and\norganizational contexts are evaluated under a unified zero-shot setting. Our\nstudy reveals two key findings: (1) LLMs surface-level text generation often\ndiverges from their internal preference for violent responses; (2) their\nviolent tendencies vary across demographics, frequently contradicting\nestablished findings in criminology, social science, and psychology.", "AI": {"tldr": "\u672c\u7814\u7a76\u521b\u65b0\u6027\u5730\u7528\u66b4\u529b\u884c\u4e3a\u60c5\u666f\u95ee\u5377\u7cfb\u7edf\u8bc4\u4f30\u4e3b\u6d41LLM\u5728\u771f\u5b9e\u9053\u5fb7\u56f0\u5883\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u5185\u5728\u503e\u5411\u4e0e\u751f\u6210\u6587\u672c\u5e38\u6709\u4e0d\u7b26\uff0c\u4e14\u5728\u591a\u7ef4\u4eba\u8bbe\u4e0b\u8868\u73b0\u51fa\u4e0e\u4e3b\u6d41\u793e\u4f1a\u79d1\u5b66\u8ba4\u77e5\u76f8\u6096\u7684\u504f\u5dee\uff0c\u8868\u660eLLM\u5728\u5904\u7406\u73b0\u5b9e\u51b2\u7a81\u65f6\u5b58\u5728\u663e\u8457\u98ce\u9669\u3002", "motivation": "\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u88ab\u5e7f\u6cdb\u7528\u4e8e\u7f51\u7edc\u66b4\u529b\u5185\u5bb9\u8bc6\u522b\u4e0e\u54cd\u5e94\uff0c\u4f46\u5176\u5904\u7406\u9053\u5fb7\u6a21\u7cca\u7684\u3001\u73b0\u5b9e\u60c5\u5883\u7684\u80fd\u529b\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u9996\u6b21\u4f7f\u7528\u793e\u4f1a\u79d1\u5b66\u9886\u57df\u9a8c\u8bc1\u8fc7\u7684\u201c\u66b4\u529b\u884c\u4e3a\u60c5\u666f\u95ee\u5377\u201d(VBVQ)\u8bc4\u4f30LLM\u5728\u4eba\u7c7b\u65e5\u5e38\u51b2\u7a81\u4e0b\u7684\u53cd\u5e94\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u89d2\u8272\u7684\u4eba\u8bbe\u63d0\u793a\uff08\u5305\u542b\u79cd\u65cf\u3001\u5e74\u9f84\u3001\u5730\u7406\u8eab\u4efd\u53d8\u6362\uff09\u8003\u5bdf\u53ef\u80fd\u7684\u504f\u89c1\u3002\u5728\u7edf\u4e00\u7684zero-shot\u8bbe\u5b9a\u4e0b\uff0c\u8bc4\u4f306\u4e2a\u8de8\u4e0d\u540c\u5730\u7f18\u53ca\u7ec4\u7ec7\u5f00\u53d1\u7684LLM\u3002", "result": "\uff081\uff09LLM\u5728\u6587\u672c\u751f\u6210\u7684\u8868\u9762\u7ed3\u679c\u4e0e\u5176\u5185\u90e8\u5bf9\u4e8e\u66b4\u529b\u54cd\u5e94\u7684\u504f\u597d\u5b58\u5728\u5dee\u5f02\uff1b\uff082\uff09\u5176\u66b4\u529b\u503e\u5411\u5728\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u7279\u5f81\u95f4\u6709\u6240\u4e0d\u540c\uff0c\u4e14\u7ecf\u5e38\u4e0e\u72af\u7f6a\u5b66\u3001\u793e\u4f1a\u79d1\u5b66\u4ee5\u53ca\u5fc3\u7406\u5b66\u7684\u4e3b\u6d41\u7ed3\u8bba\u76f8\u8fdd\u80cc\u3002", "conclusion": "LLM\u4e0d\u4ec5\u5728\u8868\u8ff0\u4e0a\u4e0e\u5b9e\u9645\u201c\u6001\u5ea6\u201d\u6709\u51fa\u5165\uff0c\u4e14\u5728\u4eba\u53e3\u7edf\u8ba1\u5b66\u7ef4\u5ea6\u8fd8\u5b58\u5728\u4e0d\u4e00\u81f4\u4e43\u81f3\u504f\u89c1\uff0c\u63ed\u793a\u51fa\u5176\u5728\u5b9e\u9645\u4f26\u7406\u51b2\u7a81\u573a\u666f\u5904\u7406\u4e0a\u7684\u5c40\u9650\u6027\u4e0e\u98ce\u9669\u3002"}}
{"id": "2506.21266", "categories": ["cs.SE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.21266", "abs": "https://arxiv.org/abs/2506.21266", "authors": ["Daniil Karol", "Elizaveta Artser", "Ilya Vlasov", "Yaroslav Golubev", "Hieke Keuning", "Anastasiia Birillo"], "title": "KOALA: a Configurable Tool for Collecting IDE Data When Solving Programming Tasks", "comment": "Accepted to CompEd'25, 7 pages, 4 figures", "summary": "Collecting data of students solving programming tasks is incredibly valuable\nfor researchers and educators. It allows verifying that the students correctly\napply the features and concepts they are taught, or finding students'\nmisconceptions. However, existing data collection tools have limitations, e.g.,\nno control over the granularity of the collected code, not collecting the\nspecific events of the programming environment used, and overall being hard to\nconfigure.\n  To overcome these limitations, we propose KOALA, a convenient and highly\nconfigurable tool for collecting code snapshots and feature usage from students\nsolving programming tasks in JetBrains IDEs. The plugin can be installed in\nIDEs and configured to provide the students with the necessary tasks, enable or\ndisable certain IDE features like code completion, and run surveys. During\nproblem solving, the plugin collects code snapshots at the configured\ngranularity, all IDE actions like running and debugging, as well as some data\nnot collected in prior works, like employed hotkeys and switching focus between\nfiles. The collected data is sent to the server that comes with the tool, where\nit is stored and can be converted to the standardized ProgSnap2 format. To\nshowcase the tool, we collected data from 28 students solving tasks in two\ncourses within the IDE, highlighting some insights from this data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u6b3e\u540d\u4e3aKOALA\u7684JetBrains IDE\u63d2\u4ef6\uff0c\u80fd\u591f\u7075\u6d3b\u3001\u8be6\u7ec6\u5730\u6536\u96c6\u5b66\u751f\u5728\u7f16\u7a0b\u4efb\u52a1\u4e2d\u7684\u884c\u4e3a\u548c\u7f16\u7801\u5feb\u7167\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u5de5\u5177\u7684\u4e0d\u8db3\uff0c\u5e76\u7528\u5b9e\u9645\u6570\u636e\u5c55\u793a\u4e86\u5176\u5e94\u7528\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u6570\u636e\u6536\u96c6\u5de5\u5177\u5728\u7f16\u7a0b\u6559\u80b2\u573a\u666f\u4e0b\u5bf9\u5b66\u751f\u7f16\u7a0b\u4efb\u52a1\u7684\u6536\u96c6\u5b58\u5728\u8bf8\u5982\u6536\u96c6\u7c92\u5ea6\u4e0d\u53ef\u63a7\u3001\u65e0\u6cd5\u6536\u96c6\u5177\u4f53\u7f16\u7a0b\u73af\u5883\u4e8b\u4ef6\u3001\u914d\u7f6e\u590d\u6742\u7b49\u5c40\u9650\u6027\u3002\u7814\u7a76\u8005\u548c\u6559\u80b2\u8005\u8feb\u5207\u9700\u8981\u66f4\u7075\u6d3b\u3001\u6613\u914d\u7f6e\u4e14\u529f\u80fd\u5168\u9762\u7684\u6570\u636e\u6536\u96c6\u5de5\u5177\u4ee5\u6539\u8fdb\u6559\u5b66\u548c\u7814\u7a76\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u6b3e\u540d\u4e3aKOALA\u7684\u63d2\u4ef6\uff0c\u8be5\u63d2\u4ef6\u53ef\u4ee5\u96c6\u6210\u5728JetBrains IDE\u4e2d\u3002KOALA\u5141\u8bb8\u6839\u636e\u9700\u6c42\u914d\u7f6e\u6536\u96c6\u4ee3\u7801\u5feb\u7167\u548cIDE\u529f\u80fd\u4f7f\u7528\u7684\u7c92\u5ea6\uff0c\u8fd8\u53ef\u4ee5\u5206\u53d1\u7f16\u7a0b\u4efb\u52a1\u3001\u63a7\u5236IDE\u7279\u6027\uff08\u5982\u542f\u7528/\u7981\u7528\u4ee3\u7801\u8865\u5168\uff09\u3001\u4ee5\u53ca\u8fd0\u884c\u95ee\u5377\u8c03\u67e5\u3002\u63d2\u4ef6\u4f1a\u5728\u5b66\u751f\u7f16\u7a0b\u65f6\u6536\u96c6\u4ee3\u7801\u5feb\u7167\u3001IDE\u884c\u4e3a\uff08\u8fd0\u884c\u3001\u8c03\u8bd5\uff09\u3001\u4f7f\u7528\u70ed\u952e\u53ca\u6587\u4ef6\u5207\u6362\u7b49\u8be6\u7ec6\u6570\u636e\uff0c\u5e76\u5c06\u6570\u636e\u53d1\u9001\u81f3\u914d\u5957\u670d\u52a1\u5668\uff0c\u8fd8\u652f\u6301\u8f6c\u6362\u4e3a\u6807\u51c6ProgSnap2\u6570\u636e\u683c\u5f0f\u3002", "result": "\u4f5c\u8005\u4f7f\u7528KOALA\u63d2\u4ef6\uff0c\u5728\u4e24\u4e2a\u8bfe\u7a0b\u517128\u540d\u5b66\u751f\u5b8c\u6210\u7f16\u7a0b\u4efb\u52a1\u65f6\u6536\u96c6\u4e86\u76f8\u5173\u6570\u636e\uff0c\u5e76\u7528\u8fd9\u4e9b\u6570\u636e\u5c55\u793a\u4e86\u4e00\u4e9b\u521d\u6b65\u5206\u6790\u548c\u6d1e\u5bdf\uff0c\u8bc1\u5b9e\u4e86KOALA\u5de5\u5177\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "KOALA\u662f\u4e00\u6b3e\u9ad8\u5ea6\u53ef\u914d\u7f6e\u3001\u4fbf\u4e8e\u90e8\u7f72\u4e14\u80fd\u7ec6\u81f4\u91c7\u96c6\u6570\u636e\u7684JetBrains IDE\u63d2\u4ef6\uff0c\u80fd\u591f\u5f25\u8865\u73b0\u6709\u5de5\u5177\u7684\u4e0d\u8db3\uff0c\u4e3a\u7f16\u7a0b\u6559\u80b2\u7814\u7a76\u4e0e\u6559\u5b66\u6539\u8fdb\u63d0\u4f9b\u6709\u529b\u7684\u6570\u636e\u652f\u6301\u3002"}}
{"id": "2506.20876", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.20876", "abs": "https://arxiv.org/abs/2506.20876", "authors": ["Sebastian Joseph", "Lily Chen", "Barry Wei", "Michael Mackert", "Iain J. Marshall", "Paul Pu Liang", "Ramez Kouzy", "Byron C. Wallace", "Junyi Jessy Li"], "title": "Decide less, communicate more: On the construct validity of end-to-end fact-checking in medicine", "comment": null, "summary": "Technological progress has led to concrete advancements in tasks that were\nregarded as challenging, such as automatic fact-checking. Interest in adopting\nthese systems for public health and medicine has grown due to the high-stakes\nnature of medical decisions and challenges in critically appraising a vast and\ndiverse medical literature. Evidence-based medicine connects to every\nindividual, and yet the nature of it is highly technical, rendering the medical\nliteracy of majority users inadequate to sufficiently navigate the domain. Such\nproblems with medical communication ripens the ground for end-to-end\nfact-checking agents: check a claim against current medical literature and\nreturn with an evidence-backed verdict. And yet, such systems remain largely\nunused. To understand this, we present the first study examining how clinical\nexperts verify real claims from social media by synthesizing medical evidence.\nIn searching for this upper-bound, we reveal fundamental challenges in\nend-to-end fact-checking when applied to medicine: Difficulties connecting\nclaims in the wild to scientific evidence in the form of clinical trials;\nambiguities in underspecified claims mixed with mismatched intentions; and\ninherently subjective veracity labels. We argue that fact-checking should be\napproached and evaluated as an interactive communication problem, rather than\nan end-to-end process.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u533b\u5b66\u9886\u57df\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u5e94\u7528\u53d7\u9650\u7684\u539f\u56e0\uff0c\u53d1\u73b0\u4e3b\u8981\u6311\u6218\u5305\u62ec\u58f0\u660e\u4e0e\u8bc1\u636e\u7684\u96be\u4ee5\u5bf9\u5e94\u3001\u58f0\u660e\u542b\u7cca\u548c\u8bc4\u4ef7\u4e3b\u89c2\u6027\u7b49\u3002\u4f5c\u8005\u5efa\u8bae\u5c06\u533b\u5b66\u4e8b\u5b9e\u6838\u67e5\u5f53\u4f5c\u4e00\u4e2a\u57fa\u4e8e\u4e92\u52a8\u7684\u4f20\u64ad\u95ee\u9898\u6765\u89e3\u51b3\uff0c\u800c\u975e\u5355\u7eaf\u7684\u7aef\u5230\u7aef\u81ea\u52a8\u4efb\u52a1\u3002", "motivation": "\u533b\u5b66\u51b3\u7b56\u5173\u7cfb\u5e7f\u5927\u6c11\u4f17\uff0c\u4f46\u5927\u90e8\u5206\u4eba\u7f3a\u4e4f\u533b\u5b66\u7d20\u517b\uff0c\u96be\u4ee5\u7406\u89e3\u548c\u5224\u65ad\u533b\u5b66\u6587\u732e\u7684\u4fe1\u606f\u3002\u540c\u65f6\uff0c\u793e\u4ea4\u5a92\u4f53\u4e0a\u533b\u5b66\u76f8\u5173\u4fe1\u606f\u771f\u5047\u96be\u8fa8\uff0c\u56e0\u6b64\u9700\u8981\u81ea\u52a8\u5316\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u6765\u5e2e\u52a9\u5224\u65ad\u533b\u5b66\u58f0\u660e\u7684\u771f\u4f2a\u3002\u5c3d\u7ba1\u8fd9\u4e00\u9700\u6c42\u5f3a\u70c8\uff0c\u5b9e\u9645\u4f7f\u7528\u7684\u81ea\u52a8\u5316\u533b\u5b66\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u4ecd\u975e\u5e38\u6709\u9650\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u89c2\u5bdf\u548c\u5206\u6790\u4e34\u5e8a\u4e13\u5bb6\u5728\u5b9e\u9645\u793e\u4ea4\u5a92\u4f53\u533b\u5b66\u58f0\u660e\u7684\u6838\u67e5\u8fc7\u7a0b\uff0c\u8003\u5bdf\u4ed6\u4eec\u5982\u4f55\u68c0\u7d22\u3001\u6574\u5408\u548c\u5229\u7528\u533b\u5b66\u8bc1\u636e\uff0c\u5e76\u63d0\u51fa\u5c06\u4e8b\u5b9e\u6838\u67e5\u4efb\u52a1\u89c6\u4e3a\u4e00\u4e2a\u4e92\u52a8\u5f0f\u4f20\u64ad\u95ee\u9898\u6765\u7814\u7a76\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u81ea\u52a8\u5316\u7aef\u5230\u7aef\u533b\u5b66\u4e8b\u5b9e\u6838\u67e5\u9762\u4e34\u7684\u5173\u952e\u96be\u9898\uff1a\u96be\u4ee5\u5c06\u771f\u5b9e\u4e16\u754c\u7684\u58f0\u660e\u4e0e\u5177\u4f53\u7684\u4e34\u5e8a\u8bd5\u9a8c\u8bc1\u636e\u5bf9\u5e94\uff1b\u58f0\u660e\u8868\u8ff0\u542b\u7cca\u4e14\u610f\u56fe\u5404\u5f02\uff0c\u5bfc\u81f4\u7406\u89e3\u6b67\u4e49\uff1b\u58f0\u660e\u771f\u4f2a\u7684\u5224\u65ad\u5e26\u6709\u56fa\u6709\u7684\u4e3b\u89c2\u6027\u3002", "conclusion": "\u533b\u5b66\u4e8b\u5b9e\u6838\u67e5\u4e0d\u5e94\u88ab\u7b80\u5316\u4e3a\u4e00\u4e2a\u7aef\u5230\u7aef\u8fc7\u7a0b\uff0c\u800c\u5e94\u5f53\u88ab\u89c6\u4f5c\u4e00\u4e2a\u9700\u8981\u4e92\u52a8\u548c\u6c9f\u901a\u7684\u8fc7\u7a0b\u6765\u8bbe\u8ba1\u548c\u8bc4\u4f30\u3002"}}
{"id": "2506.21297", "categories": ["cs.SE", "cs.DC", "D.2.11; D.2.13; D.2.7"], "pdf": "https://arxiv.org/pdf/2506.21297", "abs": "https://arxiv.org/abs/2506.21297", "authors": ["Ricardo Hideki Hangai Kojo", "Luiz Fernando Corte Real", "Renato Cordeiro Ferreira", "Thatiane de Oliveira Rosa", "Alfredo Goldman"], "title": "Exploring Micro Frontends: A Case Study Application in E-Commerce", "comment": "11 pages, 2 figures (2 diagrams), submitted to the workshop AMP 2025", "summary": "In the micro frontends architectural style, the frontend is divided into\nsmaller components, which can range from a simple button to an entire page. The\ngoal is to improve scalability, resilience, and team independence, albeit at\nthe cost of increased complexity and infrastructure demands. This paper seeks\nto understand when it is worth adopting micro frontends, particularly in the\ncontext of industry. To achieve this, we conducted an investigation into the\nstate of the art of micro frontends, based on both academic and gray\nliterature. We then implemented this architectural style in a marketplace for\nhandcrafted products, which already used microservices. Finally, we evaluated\nthe implementation through a semi-open questionnaire with the developers. At\nthe studied marketplace company, the need for architectural change arose due to\nthe tight coupling between their main system (a Java monolith) and a dedicated\nfrontend system. Additionally, there were deprecated technologies and poor\ndeveloper experience. To address these issues, the micro frontends architecture\nwas adopted, along with the API Gateway and Backend for Frontend patterns, and\ntechnologies such as Svelte and Fastify. Although the adoption of Micro\nFrontends was successful, it was not strictly necessary to meet the company's\nneeds. According to the analysis of the mixed questionnaire responses, other\nalternatives, such as a monolithic frontend, could have achieved comparable\nresults. What made adopting micro frontends the most convenient choice in the\ncompany's context was the monolith strangulation and microservices adoption,\nwhich facilitated implementation through infrastructure reuse and knowledge\nsharing between teams.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u5fae\u524d\u7aef\u67b6\u6784\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u7684\u9002\u7528\u6027\uff0c\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u53d1\u73b0\u867d\u7136\u5176\u5b9e\u65bd\u53ef\u89e3\u51b3\u7cfb\u7edf\u8026\u5408\u548c\u4f53\u9a8c\u95ee\u9898\uff0c\u4f46\u5176\u5fc5\u8981\u6027\u9700\u5177\u4f53\u6743\u8861\uff0c\u5fae\u524d\u7aef\u6700\u9002\u7528\u4e8e\u5df2\u6709\u5fae\u670d\u52a1\u548c\u9700\u62c6\u5206\u5355\u4f53\u7cfb\u7edf\u7684\u573a\u666f\u3002", "motivation": "\u52a8\u673a\u662f\u4e3a\u4e86\u7406\u89e3\u5728\u4f55\u79cd\u60c5\u51b5\u4e0b\u503c\u5f97\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u91c7\u7528\u5fae\u524d\u7aef\u67b6\u6784\uff0c\u5c24\u5176\u662f\u5728\u9762\u5bf9\u4e3b\u7cfb\u7edf\u4e0e\u524d\u7aef\u9ad8\u5ea6\u8026\u5408\u3001\u6280\u672f\u9648\u65e7\u3001\u5f00\u53d1\u4f53\u9a8c\u5dee\u7b49\u95ee\u9898\u65f6\u3002", "method": "\u8be5\u8bba\u6587\u9996\u5148\u57fa\u4e8e\u5b66\u672f\u548c\u7070\u8272\u6587\u732e\u8c03\u67e5\u5f53\u524d\u5fae\u524d\u7aef\u7684\u73b0\u72b6\uff0c\u968f\u540e\u5728\u4e00\u4e2a\u5df2\u4f7f\u7528\u5fae\u670d\u52a1\u7684\u624b\u5de5\u827a\u54c1\u5e02\u573a\u5e73\u53f0\u5b9e\u65bd\u5fae\u524d\u7aef\u67b6\u6784\uff0c\u5e76\u901a\u8fc7\u9762\u5411\u5f00\u53d1\u8005\u7684\u534a\u5f00\u653e\u5f0f\u95ee\u5377\u5bf9\u5b9e\u65bd\u6548\u679c\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5fae\u524d\u7aef\u7684\u5b9e\u65bd\u6210\u529f\u6539\u5584\u4e86\u539f\u6709\u95ee\u9898\uff0c\u4f46\u901a\u8fc7\u95ee\u5377\u5206\u6790\u7ed3\u679c\u663e\u793a\uff1a\u5b9e\u73b0\u516c\u53f8\u9700\u6c42\u5e76\u975e\u5fc5\u987b\u4f9d\u9760\u5fae\u524d\u7aef\uff0c\u5355\u4f53\u524d\u7aef\u7b49\u66ff\u4ee3\u65b9\u6848\u4e5f\u53ef\u8fbe\u5230\u7c7b\u4f3c\u6548\u679c\u3002\u6700\u7ec8\u9009\u62e9\u5fae\u524d\u7aef\uff0c\u4e3b\u8981\u56e0\u516c\u53f8\u5df2\u6709\u5fae\u670d\u52a1\u67b6\u6784\uff0c\u6709\u5229\u4e8e\u57fa\u7840\u8bbe\u65bd\u590d\u7528\u548c\u56e2\u961f\u77e5\u8bc6\u5171\u4eab\u3002", "conclusion": "\u5fae\u524d\u7aef\u67b6\u6784\u5728\u67d0\u4e9b\u516c\u53f8\u80cc\u666f\u4e0b\u66f4\u65b9\u4fbf\uff0c\u4f46\u5e76\u4e0d\u662f\u89e3\u51b3\u8026\u5408\u548c\u63d0\u5347\u5f00\u53d1\u4f53\u9a8c\u7684\u552f\u4e00\u9009\u62e9\u3002\u5176\u91c7\u7528\u7684\u5fc5\u8981\u6027\u9700\u7ed3\u5408\u5177\u4f53\u573a\u666f\u8bc4\u4f30\u3002"}}
{"id": "2506.20917", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.20917", "abs": "https://arxiv.org/abs/2506.20917", "authors": ["Zhengyan Shi"], "title": "Optimising Language Models for Downstream Tasks: A Post-Training Perspective", "comment": "PhD Thesis", "summary": "Language models (LMs) have demonstrated remarkable capabilities in NLP, yet\nadapting them efficiently and robustly to specific tasks remains challenging.\nAs their scale and complexity grow, fine-tuning LMs on labelled data often\nunderutilizes available unlabelled data, leads to overfitting on small\ntask-specific sets, and imposes significant computational costs. These\nlimitations hamper their application to the open-ended landscape of real-world\nlanguage tasks.\n  This thesis proposes a series of methods to better adapt LMs to downstream\napplications. First, we explore strategies for extracting task-relevant\nknowledge from unlabelled data, introducing a novel continued pre-training\ntechnique that outperforms state-of-the-art semi-supervised approaches. Next,\nwe present a parameter-efficient fine-tuning method that substantially reduces\nmemory and compute costs while maintaining competitive performance. We also\nintroduce improved supervised fine-tuning methods that enable LMs to better\nfollow instructions, especially when labelled data is scarce, enhancing their\nperformance across a range of NLP tasks, including open-ended generation.\nFinally, we develop new evaluation methods and benchmarks, such as multi-hop\nspatial reasoning tasks, to assess LM capabilities and adaptation more\ncomprehensively.\n  Through extensive empirical studies across diverse NLP tasks, our results\ndemonstrate that these approaches substantially improve LM robustness,\nefficiency, and generalization, making them more adaptable to a broad range of\napplications. These advances mark a significant step towards more robust and\nefficient LMs, bringing us closer to the goal of artificial general\nintelligence.", "AI": {"tldr": "\u9488\u5bf9\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u4efb\u52a1\u9002\u5e94\u65b9\u9762\u9762\u4e34\u7684\u6548\u7387\u3001\u7a33\u5065\u6027\u3001\u8d44\u6e90\u6d88\u8017\u7b49\u95ee\u9898\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u65b0\u578b\u7684\u9884\u8bad\u7ec3\u3001\u5fae\u8c03\u548c\u8bc4\u6d4b\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6027\u80fd\u548c\u9002\u7528\u8303\u56f4\uff0c\u63a8\u52a8\u4e86\u4eba\u5de5\u667a\u80fd\u7684\u901a\u7528\u5316\u8fdb\u7a0b\u3002", "motivation": "\u968f\u7740\u8bed\u8a00\u6a21\u578b\uff08LMs\uff09\u89c4\u6a21\u548c\u590d\u6742\u5ea6\u7684\u589e\u52a0\uff0c\u5176\u9ad8\u6548\u4e14\u7a33\u5065\u5730\u9002\u5e94\u7279\u5b9a\u4efb\u52a1\u4ecd\u9762\u4e34\u6311\u6218\u3002\u5f53\u524d\u7684\u5fae\u8c03\u65b9\u6cd5\u5b58\u5728\u672a\u5145\u5206\u5229\u7528\u65e0\u6807\u7b7e\u6570\u636e\u3001\u5728\u5c0f\u6837\u672c\u96c6\u4e0a\u8fc7\u62df\u5408\u3001\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u5927\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u5f00\u653e\u6027\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "method": "1. \u63d0\u51fa\u4e86\u57fa\u4e8e\u65e0\u6807\u7b7e\u6570\u636e\u63d0\u53d6\u4efb\u52a1\u76f8\u5173\u77e5\u8bc6\u7684\u65b0\u578b\u7ee7\u7eed\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4f18\u4e8e\u73b0\u6709\u534a\u76d1\u7763\u65b9\u6cd5\u30022. \u5f00\u53d1\u4e86\u9ad8\u6548\u7684\u53c2\u6570\u5fae\u8c03\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u964d\u4f4e\u4e86\u5185\u5b58\u4e0e\u8ba1\u7b97\u9700\u6c42\u30023. \u4f18\u5316\u4e86\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\uff0c\u4f7f\u8bed\u8a00\u6a21\u578b\u5728\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u65f6\u66f4\u597d\u5730\u9075\u5faa\u6307\u4ee4\uff0c\u63d0\u5347\u5f00\u653e\u6027\u751f\u6210\u7b49\u591a\u7c7bNLP\u4efb\u52a1\u8868\u73b0\u30024. \u6784\u5efa\u4e86\u65b0\u7684\u8bc4\u6d4b\u65b9\u5f0f\u548c\u57fa\u51c6\uff08\u5982\u591a\u8df3\u7a7a\u95f4\u63a8\u7406\u4efb\u52a1\uff09\uff0c\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u4e0e\u9002\u5e94\u6027\u3002", "result": "\u5728\u591a\u4e2a\u4e0d\u540c\u7684NLP\u4efb\u52a1\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u53ef\u663e\u8457\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u7a33\u5065\u6027\u3001\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u66f4\u597d\u5730\u9002\u5e94\u591a\u6837\u5316\u5e94\u7528\u573a\u666f\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52a1\u9002\u5e94\u6027\uff0c\u5728\u63d0\u5347\u7a33\u5065\u6027\u4e0e\u6548\u7387\u65b9\u9762\u8d77\u5230\u5173\u952e\u4f5c\u7528\uff0c\u662f\u671d\u5411\u66f4\u901a\u7528\u4eba\u5de5\u667a\u80fd\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2506.21300", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.21300", "abs": "https://arxiv.org/abs/2506.21300", "authors": ["Yannis Bertrand", "Christian Imenkamp", "Lukas Malburg", "Matthias Ehrendorfer", "Marco Franceschetti", "Joscha Gr\u00fcger", "Francesco Leotta", "J\u00fcrgen Mangler", "Ronny Seiger", "Agnes Koschmider", "Stefanie Rinderle-Ma", "Barbara Weber", "Estefania Serral"], "title": "An object-centric core metamodel for IoT-enhanced event logs", "comment": null, "summary": "Advances in Internet-of-Things (IoT) technologies have prompted the\nintegration of IoT devices with business processes (BPs) in many organizations\nacross various sectors, such as manufacturing, healthcare and smart spaces. The\nproliferation of IoT devices leads to the generation of large amounts of IoT\ndata providing a window on the physical context of BPs, which facilitates the\ndiscovery of new insights about BPs using process mining (PM) techniques.\nHowever, to achieve these benefits, IoT data need to be combined with\ntraditional process (event) data, which is challenging due to the very\ndifferent characteristics of IoT and process data, for instance in terms of\ngranularity levels. Recently, several data models were proposed to integrate\nIoT data with process data, each focusing on different aspects of data\nintegration based on different assumptions and requirements. This fragmentation\nhampers data exchange and collaboration in the field of PM, e.g., making it\ntedious for researchers to share data. In this paper, we present a core model\nsynthesizing the most important features of existing data models. As the core\nmodel is based on common requirements, it greatly facilitates data sharing and\ncollaboration in the field. A prototypical Python implementation is used to\nevaluate the model against various use cases and demonstrate that it satisfies\nthese common requirements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u6574\u5408\u7269\u8054\u7f51\u4e0e\u4e1a\u52a1\u6d41\u7a0b\u6570\u636e\u7684\u6838\u5fc3\u6570\u636e\u6a21\u578b\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u6a21\u578b\u788e\u7247\u5316\u548c\u534f\u4f5c\u96be\u9898\u3002\u901a\u8fc7\u539f\u578b\u5b9e\u73b0\u9a8c\u8bc1\uff0c\u8868\u73b0\u51fa\u8f83\u5f3a\u7684\u6570\u636e\u5171\u4eab\u548c\u9002\u914d\u80fd\u529b\uff0c\u5bf9\u6d41\u7a0b\u6316\u6398\u9886\u57df\u7684\u6570\u636e\u96c6\u6210\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u968f\u7740\u7269\u8054\u7f51\uff08IoT\uff09\u6280\u672f\u7684\u53d1\u5c55\uff0cIoT\u8bbe\u5907\u8d8a\u6765\u8d8a\u591a\u5730\u878d\u5165\u5230\u4f01\u4e1a\u6d41\u7a0b\uff08BP\uff09\u4e2d\u3002\u7136\u800c\uff0cIoT\u6570\u636e\u4e0e\u4f20\u7edf\u6d41\u7a0b\u6570\u636e\u5728\u7c92\u5ea6\u548c\u7279\u6027\u4e0a\u6709\u5f88\u5927\u4e0d\u540c\uff0c\u5982\u4f55\u6709\u6548\u6574\u5408\u5b83\u4eec\u6210\u4e3a\u6d41\u7a0b\u6316\u6398\u4e2d\u7684\u6311\u6218\u3002\u73b0\u6709\u6570\u636e\u6a21\u578b\u5404\u81ea\u5173\u6ce8\u4e0d\u540c\u65b9\u9762\uff0c\u5bfc\u81f4\u6570\u636e\u788e\u7247\u5316\uff0c\u59a8\u788d\u4e86PM\u9886\u57df\u7684\u6570\u636e\u5171\u4eab\u4e0e\u534f\u4f5c\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u7efc\u5408\u73b0\u6709\u4e0d\u540c\u6570\u636e\u6a21\u578b\u5173\u952e\u7279\u5f81\u7684\u6838\u5fc3\u6a21\u578b\uff0c\u65e8\u5728\u8986\u76d6\u4e3b\u6d41\u7684\u6570\u636e\u6574\u5408\u9700\u6c42\uff0c\u5e76\u901a\u8fc7\u539f\u578b\u5316\u7684Python\u5b9e\u73b0\u8fdb\u884c\u7528\u4f8b\u9a8c\u8bc1\u3002", "result": "\u63d0\u51fa\u7684\u6838\u5fc3\u6a21\u578b\u80fd\u591f\u5f88\u597d\u5730\u6ee1\u8db3\u4e3b\u6d41\u6570\u636e\u6574\u5408\u9700\u6c42\uff0c\u5927\u5927\u4fc3\u8fdb\u4e86\u6d41\u7a0b\u6316\u6398\u9886\u57df\u7684\u6570\u636e\u5171\u4eab\u4e0e\u534f\u4f5c\u3002\u901a\u8fc7Python\u539f\u578b\u5b9e\u73b0\u5bf9\u5404\u79cd\u7528\u4f8b\u8fdb\u884c\u4e86\u6709\u6548\u9a8c\u8bc1\u3002", "conclusion": "\u8bbe\u8ba1\u7684\u6838\u5fc3\u6a21\u578b\u878d\u5408\u4e86\u73b0\u6709IoT\u4e0e\u6d41\u7a0b\u6570\u636e\u6574\u5408\u6a21\u578b\u7684\u4f18\u70b9\uff0c\u63d0\u5347\u4e86\u6570\u636e\u5171\u4eab\u6027\u548c\u534f\u4f5c\u6027\uff0c\u4e3a\u6d41\u7a0b\u6316\u6398\u9886\u57df\u63d0\u4f9b\u4e86\u7edf\u4e00\u9ad8\u6548\u7684\u6570\u636e\u6574\u5408\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.20920", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.20920", "abs": "https://arxiv.org/abs/2506.20920", "authors": ["Guilherme Penedo", "Hynek Kydl\u00ed\u010dek", "Vinko Sabol\u010dec", "Bettina Messmer", "Negar Foroutan", "Amir Hossein Kargaran", "Colin Raffel", "Martin Jaggi", "Leandro Von Werra", "Thomas Wolf"], "title": "FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data Processing to Every Language", "comment": null, "summary": "Pre-training state-of-the-art large language models (LLMs) requires vast\namounts of clean and diverse text data. While the open development of large\nhigh-quality English pre-training datasets has seen substantial recent\nprogress, training performant multilingual LLMs remains a challenge, in large\npart due to the inherent difficulty of tailoring filtering and deduplication\npipelines to a large number of languages. In this work, we introduce a new\npre-training dataset curation pipeline based on FineWeb that can be\nautomatically adapted to support any language. We extensively ablate our\npipeline design choices on a set of nine diverse languages, guided by a set of\nmeaningful and informative evaluation tasks that were chosen through a novel\nselection process based on measurable criteria. Ultimately, we show that our\npipeline can be used to create non-English corpora that produce more performant\nmodels than prior datasets. We additionally introduce a straightforward and\nprincipled approach to rebalance datasets that takes into consideration both\nduplication count and quality, providing an additional performance uplift.\nFinally, we scale our pipeline to over 1000 languages using almost 100 Common\nCrawl snapshots to produce FineWeb2, a new 20 terabyte (5 billion document)\nmultilingual dataset which we release along with our pipeline, training, and\nevaluation codebases.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u591a\u8bed\u8a00\u6570\u636e\u96c6\u6784\u5efa\u6d41\u7a0b\uff0c\u5927\u89c4\u6a21\u6536\u96c6\u5904\u74061000+\u79cd\u8bed\u8a00\u517120TB\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u975e\u82f1\u8bed\u5927\u6a21\u578b\u8bad\u7ec3\u6548\u679c\uff0c\u5f00\u6e90\u4e86\u6570\u636e\u4e0e\u76f8\u5173\u4ee3\u7801\u3002", "motivation": "\u5f53\u524d\u9ad8\u6027\u80fd\u591a\u8bed\u8a00\u5927\u6a21\u578b\u8bad\u7ec3\u9762\u4e34\u6570\u636e\u96c6\u96be\u4ee5\u6e05\u6d17\u3001\u53bb\u91cd\u7b49\u6311\u6218\uff0c\u5c24\u5176\u662f\u652f\u6301\u591a\u8bed\u79cd\u7684\u8fc7\u6ee4\u548c\u53bb\u91cd\u6d41\u7a0b\u96be\u4ee5\u9ad8\u6548\u6269\u5c55\u3002\u5df2\u6709\u7684\u9ad8\u8d28\u91cf\u82f1\u6587\u6570\u636e\u96c6\u8fdb\u5c55\u8f83\u5feb\uff0c\u4f46\u591a\u8bed\u8a00\u9886\u57df\u6ede\u540e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eFineWeb\u7684\u6570\u636e\u9884\u5904\u7406\u7ba1\u9053\uff0c\u53ef\u81ea\u52a8\u9002\u914d\u4efb\u610f\u8bed\u8a00\uff0c\u5e76\u5728\u4e5d\u79cd\u8bed\u8a00\u4e0a\u6d88\u878d\u5b9e\u9a8c\u4ee5\u4f18\u5316\u5404\u9879\u8bbe\u8ba1\uff1b\u901a\u8fc7\u521b\u65b0\u7684\u4efb\u52a1\u9009\u62e9\u6d41\u7a0b\u6307\u5bfc\u8bc4\u4f30\uff0c\u540c\u65f6\u63d0\u51fa\u6839\u636e\u53bb\u91cd\u6570\u4e0e\u6570\u636e\u8d28\u91cf\u91cd\u65b0\u5e73\u8861\u6570\u636e\u96c6\u7684\u7b80\u6d01\u539f\u5219\u5316\u65b9\u6cd5\u3002\u6700\u7ec8\uff0c\u5229\u7528\u5927\u89c4\u6a21\u7f51\u7edc\u6293\u53d6\u6570\u636e\uff08Common Crawl\uff09\u6269\u5c55\u81f31000+\u79cd\u8bed\u8a00\u751f\u6210FineWeb2\u591a\u8bed\u8a00\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7ba1\u9053\u751f\u6210\u7684\u975e\u82f1\u8bed\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u5927\u6a21\u578b\u5728\u6027\u80fd\u4e0a\u8d85\u8fc7\u73b0\u6709\u6570\u636e\u96c6\u65b9\u6cd5\u3002\u91cd\u65b0\u5e73\u8861\u65b9\u6cd5\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002FineWeb2\u6570\u636e\u96c6\u89c4\u6a21\u8fbe20TB\uff0850\u4ebf\u6587\u6863\uff09\uff0c\u516c\u5f00\u4e86\u6570\u636e\u96c6\u3001\u7ba1\u9053\u548c\u8bad\u7ec3\u3001\u8bc4\u6d4b\u4ee3\u7801\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u591a\u8bed\u8a00\u6570\u636e\u96c6\u6784\u5efa\u65b9\u6848\uff0c\u4f7f\u5404\u8bed\u79cd\u6a21\u578b\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u540c\u65f6\u63a8\u52a8\u591a\u8bed\u8a00\u9884\u8bad\u7ec3\u57fa\u7840\u8bbe\u65bd\u7684\u5f00\u6e90\u53d1\u5c55\u3002"}}
{"id": "2506.21182", "categories": ["cs.CL", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.21182", "abs": "https://arxiv.org/abs/2506.21182", "authors": ["Isaac Chung", "Imene Kerboua", "Marton Kardos", "Roman Solomatin", "Kenneth Enevoldsen"], "title": "Maintaining MTEB: Towards Long Term Usability and Reproducibility of Embedding Benchmarks", "comment": null, "summary": "The Massive Text Embedding Benchmark (MTEB) has become a standard evaluation\nplatform for text embedding models. While previous work has established the\ncore benchmark methodology, this paper focuses on the engineering aspects that\nensure MTEB's continued reproducibility and extensibility. We present our\napproach to maintaining robust continuous integration pipelines that validate\ndataset integrity, automate test execution, and assess benchmark results'\ngeneralizability. We detail the design choices that collectively enhance\nreproducibility and usability. Furthermore, we discuss our strategies for\nhandling community contributions and extending the benchmark with new tasks and\ndatasets. These engineering practices have been instrumental in scaling MTEB to\nbecome more comprehensive while maintaining quality and, ultimately, relevance\nto the field. Our experiences offer valuable insights for benchmark maintainers\nfacing similar challenges in ensuring reproducibility and usability in machine\nlearning evaluation frameworks. The MTEB repository is available at:\nhttps://github.com/embeddings-benchmark/mteb", "AI": {"tldr": "\u672c\u6587\u5173\u6ce8\u4e8eMTEB\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\u7684\u5de5\u7a0b\u5b9e\u73b0\uff0c\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u786e\u4fdd\u5e73\u53f0\u53ef\u590d\u73b0\u6027\u4e0e\u53ef\u6269\u5c55\u6027\u7684\u5de5\u7a0b\u63aa\u65bd\u4e0e\u6d41\u7a0b\u7ba1\u7406\uff0c\u63d0\u5347\u4e86\u5e73\u53f0\u8d28\u91cf\uff0c\u4e3a\u7c7b\u4f3c\u9886\u57df\u7684\u57fa\u51c6\u5e73\u53f0\u7ef4\u62a4\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7ecf\u9a8c\u3002", "motivation": "MTEB\u5df2\u7ecf\u6210\u4e3a\u6587\u672c\u5d4c\u5165\u6a21\u578b\u7684\u6807\u51c6\u8bc4\u6d4b\u5e73\u53f0\uff0c\u4f46\u968f\u7740\u89c4\u6a21\u6269\u5927\uff0c\u5982\u4f55\u4fdd\u969c\u8bc4\u6d4b\u7ed3\u679c\u7684\u53ef\u590d\u73b0\u6027\u548c\u62d3\u5c55\u6027\u6210\u4e3a\u4e3b\u8981\u6311\u6218\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\u5728\u5de5\u7a0b\u7ba1\u7406\u65b9\u9762\u7684\u96be\u9898\u3002", "method": "\u4f5c\u8005\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u5982\u4f55\u7ef4\u62a4\u6301\u7eed\u96c6\u6210\u6d41\u6c34\u7ebf\uff0c\u9a8c\u8bc1\u6570\u636e\u96c6\u7684\u5b8c\u6574\u6027\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u6d4b\u8bd5\uff0c\u5e76\u8bc4\u4f30\u57fa\u51c6\u7ed3\u679c\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6b64\u5916\uff0c\u8fd8\u63cf\u8ff0\u4e86\u5e94\u5bf9\u793e\u533a\u8d21\u732e\u53ca\u6dfb\u52a0\u65b0\u4efb\u52a1\u548c\u6570\u636e\u96c6\u7684\u5de5\u7a0b\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u4e0a\u8ff0\u5de5\u7a0b\u5b9e\u8df5\uff0cMTEB\u57fa\u51c6\u4e0d\u4ec5\u53d8\u5f97\u66f4\u52a0\u5168\u9762\uff0c\u800c\u4e14\u5728\u8d28\u91cf\u548c\u53ef\u7528\u6027\u65b9\u9762\u4e5f\u5f97\u5230\u4e86\u7ef4\u6301\u548c\u63d0\u5347\uff0c\u5bf9\u6574\u4e2a\u9886\u57df\u4ecd\u5177\u9ad8\u5ea6\u76f8\u5173\u6027\u3002", "conclusion": "\u8bba\u6587\u603b\u7ed3\u4e86\u63d0\u5347\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\u53ef\u590d\u73b0\u6027\u4e0e\u53ef\u7528\u6027\u7684\u5de5\u7a0b\u65b9\u6cd5\u548c\u7ecf\u9a8c\uff0c\u4e3a\u5176\u4ed6\u673a\u5668\u5b66\u4e60\u8bc4\u6d4b\u5e73\u53f0\u7684\u7ef4\u62a4\u8005\u63d0\u4f9b\u4e86\u6709\u76ca\u53c2\u8003\u3002"}}
{"id": "2506.20923", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.20923", "abs": "https://arxiv.org/abs/2506.20923", "authors": ["Xinping Zhao", "Xinshuo Hu", "Zifei Shan", "Shouzheng Huang", "Yao Zhou", "Zetian Sun", "Zhenyu Liu", "Dongfang Li", "Xinyuan Wei", "Qian Chen", "Youcheng Pan", "Yang Xiang", "Meishan Zhang", "Haofen Wang", "Jun Yu", "Baotian Hu", "Min Zhang"], "title": "KaLM-Embedding-V2: Superior Training Techniques and Data Inspire A Versatile Embedding Model", "comment": "Technical Report; 26 pages 12 tables 1 figure. arXiv admin note:\n  substantial text overlap with arXiv:2501.01028", "summary": "In this paper, we propose KaLM-Embedding-V2, a versatile and compact\nembedding model, which achieves impressive performance in general-purpose text\nembedding tasks by leveraging superior training techniques and data. Our key\ninnovations include: (1) To better align the architecture with representation\nlearning, we remove the causal attention mask and adopt a fully bidirectional\ntransformer with simple yet effective mean-pooling to produce fixed-length\nembeddings; (2) We employ a multi-stage training pipeline: (i) pre-training on\nlarge-scale weakly supervised open-source corpora; (ii) fine-tuning on\nhigh-quality retrieval and non-retrieval datasets; and (iii) model-soup\nparameter averaging for robust generalization. Besides, we introduce a\nfocal-style reweighting mechanism that concentrates learning on difficult\nsamples and an online hard-negative mixing strategy to continuously enrich hard\nnegatives without expensive offline mining; (3) We collect over 20 categories\nof data for pre-training and 100 categories of data for fine-tuning, to boost\nboth the performance and generalization of the embedding model. Extensive\nevaluations on the Massive Text Embedding Benchmark (MTEB) Chinese and English\nshow that our model significantly outperforms others of comparable size, and\ncompetes with 3x, 14x, 18x, and 26x larger embedding models, setting a new\nstandard for a versatile and compact embedding model with less than 1B\nparameters.", "AI": {"tldr": "KaLM-Embedding-V2\u662f\u4e00\u79cd\u7d27\u51d1\u9ad8\u6548\u7684\u6587\u672c\u5d4c\u5165\u6a21\u578b\uff0c\u7ed3\u6784\u548c\u8bad\u7ec3\u65b9\u6cd5\u5747\u6709\u521b\u65b0\uff0c\u6027\u80fd\u663e\u8457\u8d85\u8d8a\u540c\u89c4\u6a21\u6a21\u578b\uff0c\u5e76\u80fd\u5ab2\u7f8e\u6570\u91cf\u7ea7\u5927\u5f97\u591a\u7684\u6a21\u578b\uff0c\u9002\u5408\u591a\u573a\u666f\u5e94\u7528\u3002", "motivation": "\u5f53\u524d\u5927\u89c4\u6a21\u6587\u672c\u5d4c\u5165\u6a21\u578b\u867d\u7136\u6027\u80fd\u4f18\u8d8a\uff0c\u4f46\u53c2\u6570\u89c4\u6a21\u5e9e\u5927\uff0c\u8d44\u6e90\u6d88\u8017\u8f83\u9ad8\uff0c\u9650\u5236\u4e86\u5176\u901a\u7528\u6027\u4e0e\u90e8\u7f72\u3002\u4e3a\u6b64\uff0c\u6709\u5fc5\u8981\u8bbe\u8ba1\u4f53\u79ef\u5c0f\u5de7\u4e14\u6027\u80fd\u5f3a\u52b2\u7684\u901a\u7528\u6587\u672c\u5d4c\u5165\u6a21\u578b\uff0c\u4ee5\u517c\u987e\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6548\u7387\u4e0e\u6548\u679c\u3002", "method": "\u63d0\u51faKaLM-Embedding-V2\u6a21\u578b\uff0c\u521b\u65b0\u70b9\u5305\u62ec\uff1a\uff081\uff09\u79fb\u9664\u56e0\u679c\u6ce8\u610f\u529b\u63a9\u7801\uff0c\u91c7\u7528\u5168\u53cc\u5411Transformer\u7ed3\u6784\u548c\u5747\u503c\u6c60\u5316\u751f\u6210\u5b9a\u957f\u5d4c\u5165\uff1b\uff082\uff09\u91c7\u7528\u591a\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff1a\u5927\u89c4\u6a21\u5f31\u76d1\u7763\u8bed\u6599\u9884\u8bad\u7ec3\u3001\u9ad8\u8d28\u91cf\u68c0\u7d22\u4e0e\u975e\u68c0\u7d22\u6570\u636e\u5fae\u8c03\uff0c\u4ee5\u53ca\u6a21\u578b\u53c2\u6570\u5e73\u5747\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\uff1b\uff083\uff09\u5f15\u5165focal-style\u6837\u672c\u52a0\u6743\u548c\u5728\u7ebfhard-negative\u6df7\u5408\u673a\u5236\u3002\u540c\u65f6\uff0c\u5e7f\u6cdb\u6536\u96c6\u591a\u7c7b\u522b\u8bad\u7ec3\u6570\u636e\u4ee5\u63d0\u5347\u6548\u679c\u548c\u6cdb\u5316\u80fd\u529b\u3002", "result": "KaLM-Embedding-V2\u5728MTEB\u4e2d\u82f1\u6587\u5927\u89c4\u6a21\u6587\u672c\u5d4c\u5165\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5927\u5e45\u4f18\u4e8e\u540c\u7b49\u89c4\u6a21\u6a21\u578b\uff0c\u5e76\u53ef\u5ab2\u7f8e\u8fdc\u8d85\u81ea\u8eab\u4f53\u91cf\uff083\u500d\u300114\u500d\u300118\u500d\u300126\u500d\u5927\uff09\u7684\u5927\u578b\u6a21\u578b\uff0c\u6210\u4e3a\u5c0f\u578b\u901a\u7528\u5d4c\u5165\u6a21\u578b\u65b0\u6807\u6746\u3002", "conclusion": "KaLM-Embedding-V2\u51ed\u501f\u521b\u65b0\u7ed3\u6784\u548c\u9ad8\u6548\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u4f4e\u4e8e1B\u53c2\u6570\u7684\u5c0f\u4f53\u91cf\u4e0b\u4f18\u5f02\u7684\u4e2d\u82f1\u6587\u901a\u7528\u6587\u672c\u5d4c\u5165\u6027\u80fd\uff0c\u63a8\u52a8\u4e86\u8f7b\u91cf\u7ea7\u3001\u9ad8\u6548\u6587\u672c\u5d4c\u5165\u6a21\u578b\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.20989", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.20989", "abs": "https://arxiv.org/abs/2506.20989", "authors": ["Eric Zhang", "Leshem Choshen", "Jacob Andreas"], "title": "Can Gradient Descent Simulate Prompting?", "comment": "14 pages, 2 figures", "summary": "There are two primary ways of incorporating new information into a language\nmodel (LM): changing its prompt or changing its parameters, e.g. via\nfine-tuning. Parameter updates incur no long-term storage cost for model\nchanges. However, for many model updates, prompting is significantly more\neffective: prompted models can generalize robustly from single examples and\ndraw logical inferences that do not occur under standard fine-tuning. Can\nmodels be modified so that fine-tuning does emulate prompting? This paper\ndescribes a method for meta-training LMs such that gradient updates emulate the\neffects of conditioning on new information. Our approach uses tools from\ngradient-based meta-learning but uses an LM's own prompted predictions as\ntargets, eliminating the need for ground-truth labels. Subsequent gradient\ndescent training recovers some (and occasionally all) of prompted model\nperformance -- showing improvement on the ``reversal curse'' tasks, and\nanswering questions about text passages after a single gradient update. These\nresults suggest that, with appropriate initialization, gradient descent can be\nsurprisingly expressive. Our results suggest new avenues for long-context\nmodeling and offer insight into the generalization capabilities of\ngradient-based learning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u5143\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u4f7f\u5fae\u8c03\u8fc7\u7a0b\u80fd\u591f\u6a21\u62df\u63d0\u793a\u65b9\u5f0f\u5e26\u6765\u7684\u9ad8\u6548\u6cdb\u5316\u80fd\u529b\uff0c\u4ec5\u7528\u6a21\u578b\u81ea\u8eab\u8f93\u51fa\u8fdb\u884c\u8bad\u7ec3\uff0c\u65e0\u9700\u6807\u7b7e\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u4e0e\u63d0\u793a\u7c7b\u4f3c\u751a\u81f3\u66f4\u597d\u7684\u6548\u679c\u3002", "motivation": "\u5728\u5c06\u65b0\u4fe1\u606f\u878d\u5165\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5305\u62ec\u66f4\u6539\u63d0\u793a\u548c\u53c2\u6570\u5fae\u8c03\uff0c\u4f46\u4e24\u8005\u5404\u6709\u4f18\u7f3a\u70b9\u3002\u8be5\u8bba\u6587\u5173\u6ce8\u4e8e\u5fae\u8c03\u5982\u4f55\u6a21\u62df\u63d0\u793a\u7684\u6548\u679c\uff0c\u4ece\u800c\u7ed3\u5408\u4e24\u79cd\u65b9\u6cd5\u7684\u4f18\u52bf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5143\u8bad\u7ec3\uff08meta-training\uff09\u65b9\u6cd5\uff0c\u4f7f\u5f97\u901a\u8fc7\u68af\u5ea6\u66f4\u65b0\uff0c\u5fae\u8c03\u80fd\u591f\u6a21\u62df\u6761\u4ef6\u5316\uff08prompting\uff09\u7684\u6548\u679c\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u8bed\u8a00\u6a21\u578b\u81ea\u8eab\u7684\u63d0\u793a\u9884\u6d4b\u4f5c\u4e3a\u8bad\u7ec3\u76ee\u6807\uff0c\u65e0\u9700\u5916\u90e8\u771f\u5b9e\u6807\u7b7e\uff0c\u7ed3\u5408\u68af\u5ea6\u578b\u5143\u5b66\u4e60\u6280\u5de7\u5b9e\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u901a\u8fc7\u8fd9\u79cd\u5143\u8bad\u7ec3\u521d\u59cb\u5316\u540e\uff0c\u5fae\u8c03\u80fd\u591f\u6062\u590d\u751a\u81f3\u8fbe\u5230\u63d0\u793a\u6a21\u578b\u7684\u8868\u73b0\uff0c\u5c24\u5176\u5728\u201c\u9006\u8f6c\u8bc5\u5492\u201d\u4efb\u52a1\u548c\u6587\u672c\u5feb\u901f\u95ee\u7b54\u7b49\u4efb\u52a1\u4e0a\u53d6\u5f97\u660e\u663e\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8868\u660e\uff0c\u901a\u8fc7\u9002\u5f53\u7684\u521d\u59cb\u5316\uff0c\u57fa\u4e8e\u68af\u5ea6\u7684\u5fae\u8c03\u53ef\u9ad8\u5ea6\u8868\u8fbe\u5e76\u63a5\u8fd1\u63d0\u793a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u548c\u68af\u5ea6\u5b66\u4e60\u7684\u6cdb\u5316\u80fd\u529b\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.20993", "categories": ["cs.CL", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.20993", "abs": "https://arxiv.org/abs/2506.20993", "authors": ["Adithya Chittem", "Aishna Shrivastava", "Sai Tarun Pendela", "Jagat Sesh Challa", "Dhruv Kumar"], "title": "SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control", "comment": "Under review", "summary": "Large language models (LLMs) have gained significant traction across a wide\nrange of fields in recent years. There is also a growing expectation for them\nto display human-like personalities during interactions. To meet this\nexpectation, numerous studies have proposed methods for modelling LLM\npersonalities through psychometric evaluations. However, most existing models\nface two major limitations: they rely on the Big Five (OCEAN) framework, which\nonly provides coarse personality dimensions, and they lack mechanisms for\ncontrolling trait intensity. In this paper, we address this gap by extending\nthe Machine Personality Inventory (MPI), which originally used the Big Five\nmodel, to incorporate the 16 Personality Factor (16PF) model, allowing\nexpressive control over sixteen distinct traits. We also developed a structured\nframework known as Specific Attribute Control (SAC) for evaluating and\ndynamically inducing trait intensity in LLMs. Our method introduces\nadjective-based semantic anchoring to guide trait intensity expression and\nleverages behavioural questions across five intensity factors:\n\\textit{Frequency}, \\textit{Depth}, \\textit{Threshold}, \\textit{Effort}, and\n\\textit{Willingness}. Through experimentation, we find that modelling intensity\nas a continuous spectrum yields substantially more consistent and controllable\npersonality expression compared to binary trait toggling. Moreover, we observe\nthat changes in target trait intensity systematically influence closely related\ntraits in psychologically coherent directions, suggesting that LLMs internalize\nmulti-dimensional personality structures rather than treating traits in\nisolation. Our work opens new pathways for controlled and nuanced human-machine\ninteractions in domains such as healthcare, education, and interviewing\nprocesses, bringing us one step closer to truly human-like social machines.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u57fa\u4e8e16PF\u4eba\u683c\u6a21\u578b\u548c\u65b0\u63a7\u5236\u6846\u67b6\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u66f4\u7ec6\u81f4\u3001\u8fde\u7eed\u548c\u771f\u5b9e\u5730\u8868\u8fbe\u591a\u7ef4\u5ea6\u4e2a\u6027\u7279\u5f81\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5176\u7c7b\u4eba\u683c\u7684\u8868\u73b0\u548c\u8c03\u63a7\u80fd\u529b\uff0c\u62d3\u5c55\u4e86\u5176\u5728\u73b0\u5b9e\u5e94\u7528\u573a\u666f\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4eba\u673a\u4ea4\u4e92\u4e2d\u8d8a\u6765\u8d8a\u88ab\u671f\u5f85\u5177\u5907\u201c\u7c7b\u4eba\u201d\u4e2a\u6027\u3002\u7136\u800c\uff0c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u57fa\u4e8eBig Five\uff08OCEAN\uff09\u4eba\u683c\u7ed3\u6784\uff0c\u7ef4\u5ea6\u8f83\u7c97\u7cd9\u4e14\u7f3a\u4e4f\u5bf9\u4eba\u683c\u7279\u8d28\u5f3a\u5ea6\u7684\u7cbe\u7ec6\u63a7\u5236\u3002", "method": "\u672c\u6587\u5c06Machine Personality Inventory\uff08MPI\uff09\u6269\u5c55\u4e3a\u91c7\u752816 Personality Factor\uff0816PF\uff09\u6a21\u578b\uff0c\u4ece\u800c\u53ef\u7ec6\u81f4\u63a7\u523616\u79cd\u4e0d\u540c\u7684\u4eba\u683c\u7279\u8d28\u3002\u63d0\u51fa\u4e86Specific Attribute Control\uff08SAC\uff09\u7ed3\u6784\u5316\u6846\u67b6\uff0c\u91c7\u7528\u57fa\u4e8e\u5f62\u5bb9\u8bcd\u7684\u8bed\u4e49\u951a\u5b9a\uff0c\u5e76\u7ed3\u5408\u884c\u4e3a\u95ee\u9898\u91cf\u8868\uff08\u4e94\u79cd\u5f3a\u5ea6\u56e0\u5b50\uff09\u6765\u52a8\u6001\u8bf1\u53d1\u548c\u8bc4\u4ef7LLM\u7684\u4eba\u683c\u7279\u8d28\u5f3a\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5c06\u4eba\u683c\u7279\u8d28\u5f3a\u5ea6\u89c6\u4e3a\u8fde\u7eed\u5149\u8c31\uff08\u800c\u975e\u4e8c\u5143\u5f00\u5173\uff09\u80fd\u591f\u4f7fLLM\u5c55\u793a\u51fa\u66f4\u4e00\u81f4\u3001\u53ef\u63a7\u7684\u4eba\u683c\u8868\u8fbe\u3002\u6b64\u5916\uff0c\u7279\u8d28\u5f3a\u5ea6\u7684\u53d8\u5316\u4f1a\u4ee5\u5fc3\u7406\u5b66\u4e0a\u76f8\u5173\u7684\u65b9\u5411\u5f71\u54cd\u76f8\u8fd1\u7684\u4eba\u683c\u7279\u8d28\uff0c\u8bf4\u660eLLM\u5177\u5907\u591a\u7ef4\u4eba\u683c\u7ed3\u6784\u7684\u5185\u90e8\u5316\u80fd\u529b\u3002", "conclusion": "\u672c\u6587\u65b9\u6cd5\u63d0\u5347\u4e86LLM\u4eba\u683c\u8868\u8fbe\u7684\u7ec6\u81f4\u5ea6\u548c\u53ef\u63a7\u6027\uff0c\u4e3a\u5065\u5eb7\u533b\u7597\u3001\u6559\u80b2\u3001\u9762\u8bd5\u7b49\u9886\u57df\u5b9e\u73b0\u66f4\u5177\u4eba\u6027\u5316\u3001\u7ec6\u817b\u7684\u793e\u4f1a\u578b\u4eba\u5de5\u667a\u80fd\u4ea4\u4e92\u63d0\u4f9b\u4e86\u65b0\u8def\u5f84\u3002"}}
{"id": "2506.21031", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.21031", "abs": "https://arxiv.org/abs/2506.21031", "authors": ["Jatin Gupta", "Akhil Sharma", "Saransh Singhania", "Mohammad Adnan", "Sakshi Deo", "Ali Imam Abidi", "Keshav Gupta"], "title": "Large Language Models Acing Chartered Accountancy", "comment": "Accepted for publication at MoStart 2025: International Conference on\n  Digital Transformation in Education and Applications of Artificial\n  Intelligence, Bosnia and Herzegovina, 2025", "summary": "Advanced intelligent systems, particularly Large Language Models (LLMs), are\nsignificantly reshaping financial practices through advancements in Natural\nLanguage Processing (NLP). However, the extent to which these models\neffectively capture and apply domain-specific financial knowledge remains\nuncertain. Addressing a critical gap in the expansive Indian financial context,\nthis paper introduces CA-Ben, a Chartered Accountancy benchmark specifically\ndesigned to evaluate the financial, legal, and quantitative reasoning\ncapabilities of LLMs. CA-Ben comprises structured question-answer datasets\nderived from the rigorous examinations conducted by the Institute of Chartered\nAccountants of India (ICAI), spanning foundational, intermediate, and advanced\nCA curriculum stages. Six prominent LLMs i.e. GPT 4o, LLAMA 3.3 70B, LLAMA 3.1\n405B, MISTRAL Large, Claude 3.5 Sonnet, and Microsoft Phi 4 were evaluated\nusing standardized protocols. Results indicate variations in performance, with\nClaude 3.5 Sonnet and GPT-4o outperforming others, especially in conceptual and\nlegal reasoning. Notable challenges emerged in numerical computations and legal\ninterpretations. The findings emphasize the strengths and limitations of\ncurrent LLMs, suggesting future improvements through hybrid reasoning and\nretrieval-augmented generation methods, particularly for quantitative analysis\nand accurate legal interpretation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9762\u5411\u5370\u5ea6\u8d22\u4f1a\u9886\u57df\u7684CA-Ben\u57fa\u51c6\uff0c\u8bc4\u4f30\u516d\u5927\u4e3b\u6d41LLM\u5728\u4f1a\u8ba1\u3001\u6cd5\u5f8b\u53ca\u91cf\u5316\u63a8\u7406\u4e0a\u7684\u80fd\u529b\u3002\u7ed3\u679c\u663e\u793aClaude 3.5 Sonnet\u548cGPT-4o\u8868\u73b0\u6700\u4f73\uff0c\u5c24\u5176\u5728\u6cd5\u5f8b\u548c\u6982\u5ff5\u63a8\u7406\u4e0a\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u4f46\u6240\u6709\u6a21\u578b\u5728\u6570\u503c\u548c\u6cd5\u5f8b\u89e3\u91ca\u65b9\u9762\u4ecd\u6709\u660e\u663e\u4e0d\u8db3\uff0c\u5efa\u8bae\u901a\u8fc7\u6df7\u5408\u63a8\u7406\u548c\u589e\u5f3a\u68c0\u7d22\u65b9\u6cd5\u52a0\u4ee5\u6539\u8fdb\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u91d1\u878d\u9886\u57df\u7684\u5e94\u7528\u8d8a\u6765\u8d8a\u5e7f\u6cdb\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u5b83\u4eec\u662f\u5426\u80fd\u591f\u6709\u6548\u7406\u89e3\u548c\u5e94\u7528\u4e13\u4e1a\u7684\u91d1\u878d\u77e5\u8bc6\uff0c\u7279\u522b\u662f\u5728\u5370\u5ea6\u8fd9\u6837\u5e9e\u5927\u4e14\u590d\u6742\u7684\u91d1\u878d\u73af\u5883\u4e2d\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u4e2a\u4e13\u95e8\u7684\u57fa\u51c6\u6765\u8bc4\u4f30LLMs\u5728\u91d1\u878d\u3001\u6cd5\u5f8b\u548c\u91cf\u5316\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86CA-Ben\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u6574\u7406\u5370\u5ea6\u6ce8\u518c\u4f1a\u8ba1\u5e08\u534f\u4f1a\uff08ICAI\uff09\u8003\u8bd5\u4e2d\u7684\u5404\u7c7b\u9898\u76ee\uff0c\u6db5\u76d6\u57fa\u7840\u3001\u4e2d\u7ea7\u548c\u9ad8\u7ea7\u8bfe\u7a0b\u9636\u6bb5\uff0c\u751f\u6210\u7ed3\u6784\u5316\u95ee\u7b54\u6570\u636e\u96c6\u3002\u91c7\u7528\u7edf\u4e00\u8bc4\u6d4b\u6d41\u7a0b\uff0c\u5bf9GPT-4o\u3001LLAMA 3.3 70B\u3001LLAMA 3.1 405B\u3001MISTRAL Large\u3001Claude 3.5 Sonnet\u548cMicrosoft Phi 4\u516d\u79cd\u4e3b\u6d41LLMs\u8fdb\u884c\u8bc4\u6d4b\u3002", "result": "\u8bc4\u6d4b\u7ed3\u679c\u663e\u793a\uff0c\u4e0d\u540c\u6a21\u578b\u5728\u91d1\u878d\u3001\u6cd5\u5f8b\u548c\u91cf\u5316\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u5b58\u5728\u660e\u663e\u5dee\u5f02\uff0cClaude 3.5 Sonnet\u548cGPT-4o\u5728\u6982\u5ff5\u6027\u4e0e\u6cd5\u5f8b\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002\u6240\u6709\u6a21\u578b\u5728\u6570\u503c\u8ba1\u7b97\u548c\u6cd5\u5f8b\u89e3\u91ca\u4efb\u52a1\u4e0a\u5747\u9047\u5230\u8f83\u5927\u6311\u6218\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u8d22\u4f1a\u6cd5\u5f8b\u95ee\u7b54\u65b9\u9762\u8868\u73b0\u4f18\u52a3\u4e0d\u4e00\uff0c\u4f46\u5728\u91cf\u5316\u5206\u6790\u548c\u6cd5\u5f8b\u89e3\u91ca\u4e0a\u4ecd\u6709\u7a81\u51fa\u77ed\u677f\u3002\u672a\u6765\u53ef\u901a\u8fc7\u6df7\u5408\u63a8\u7406\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7b49\u65b9\u6cd5\u63d0\u5347LLMs\u5728\u91d1\u878d\u7b49\u9ad8\u4e13\u4e1a\u9886\u57df\u7684\u5e94\u7528\u80fd\u529b\u3002"}}
