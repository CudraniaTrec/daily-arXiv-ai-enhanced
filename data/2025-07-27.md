<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 14]
- [cs.LO](#cs.LO) [Total: 6]
- [cs.CL](#cs.CL) [Total: 14]
- [cs.DM](#cs.DM) [Total: 1]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Higher-Order Behavioural Conformances via Fibrations](https://arxiv.org/abs/2507.18509)
*Henning Urbat*

Main category: cs.PL

TL;DR: 论文提出了一种基于范畴论的通用Howe方法，用以证明高阶（概率）语言中行为一致性（如bisimilarity和行为伪度量）的同余性，提升了方法普适性和理论深度。


<details>
  <summary>Details</summary>
Motivation: 近年来，具有定量特征（如概率性）的语言兴起，对行为等价性的判定提出了更精细化的需求，如行为距离等，因此需要对现有的余归纳推理（coinductive reasoning）技术进行扩展和统一。

Method: 作者提出了一种范畴论的统一方法，用于适应Howe方法，以抽象高阶规格（Abstract Higher-Order Specification, AHOS）建模高阶语言，通过纤维化（fibration）描述行为一致性（如关系或度量），并建立在自然条件下余归纳推理可得一致性的范畴性基础。

Result: 提出了一个一般性的同余定理：在满足一定自然条件下，通过AHOS建模的操作语义中，其最大的行为一致关系（包含双向一致）为程序同余。该理论在概率高阶语言中，通过推导bisimilarity和行为伪度量的一致性得到了验证。

Conclusion: 本文以范畴论方式统一了不同高阶语言和行为度量之间的Howe方法证明，提供了证明同余性的强大工具，便于推广到更多高阶概率/定量特性语言场景。

Abstract: Coinduction is a widely used technique for establishing behavioural
equivalence of programs in higher-order languages. In recent years, the rise of
languages with quantitative (e.g.~probabilistic) features has led to extensions
of coinductive methods to more refined types of behavioural conformances, most
notably notions of behavioural distance. To guarantee soundness of coinductive
reasoning, one needs to show that the behavioural conformance at hand forms a
program congruence, i.e. it is suitably compatible with the operations of the
language. This is usually achieved by a complex proof technique known as
\emph{Howe's method}, which needs to be carefully adapted to both the specific
language and the targeted notion of behavioural conformance. We develop a
uniform categorical approach to Howe's method that features two orthogonal
dimensions of abstraction: (1) the underlying higher-order language is modelled
by an \emph{abstract higher-order specification} (AHOS), a novel and very
general categorical account of operational semantics, and (2) notions of
behavioural conformance (such as relations or metrics) are modelled via
fibrations over the base category of an AHOS. Our main result is a fundamental
congruence theorem at this level of generality: Under natural conditions on the
categorical ingredients and the operational rules of a language modelled by an
AHOS, the greatest behavioural (bi)conformance on its operational model forms a
congruence. We illustrate our theory by deriving congruence of bisimilarity and
behavioural pseudometrics for probabilistic higher-order languages.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [How Software Engineers Engage with AI: A Pragmatic Process Model and Decision Framework Grounded in Industry Observations](https://arxiv.org/abs/2507.17930)
*Vahid Garousi,Zafar Jafarov*

Main category: cs.SE

TL;DR: 本文通过现场调研和实践，总结了AI工具在软件工程实践中的典型使用模式和决策框架，为高效应用AI开发工具提供了可参考的范式。


<details>
  <summary>Details</summary>
Motivation: 随着AI工具（如GitHub Copilot和ChatGPT）融入软件工程，开发人员的开发方式发生变化，但实际工作中他们如何信任、调整或拒绝AI输出这一行为方式尚未深入研究。

Method: 基于工程师报告与在土耳其和阿塞拜疆三家企业中的直接观察，提出了一个实际AI辅助软件工程过程模型，并构建了一个帮助开发者权衡工作量节省与输出质量的二维决策框架。

Result: 提出了AI辅助软件工程的现实过程模型（涵盖提示设计、结果检查、回退及精炼等环节）和二维决策分析框架，揭示了开发者如何基于人工监督进行更有效的AI工具使用。

Conclusion: 这些结构化模型为开发者提供了实际、简明的指导，支持更有意识并高效地利用AI工具，推动人机协作在软件工程中的发展讨论。

Abstract: Artificial Intelligence (AI) has the potential to transform Software
Engineering (SE) by enhancing productivity, efficiency, and decision support.
Tools like GitHub Copilot and ChatGPT have given rise to "vibe coding"-an
exploratory, prompt-driven development style. Yet, how software engineers
engage with these tools in daily tasks, especially in deciding whether to
trust, refine, or reject AI-generated outputs, remains underexplored. This
paper presents two complementary contributions. First, a pragmatic process
model capturing real-world AI-assisted SE activities, including prompt design,
inspection, fallback, and refinement. Second, a 2D decision framework that
could help developers reason about trade-offs between effort saved and output
quality. Grounded in practitioner reports and direct observations in three
industry settings across Turkiye and Azerbaijan, our work illustrates how
engineers navigate AI use with human oversight. These models offer structured,
lightweight guidance to support more deliberate and effective use of AI tools
in SE, contributing to ongoing discussions on practical human-AI collaboration.

</details>


### [3] [Use as Directed? A Comparison of Software Tools Intended to Check Rigor and Transparency of Published Work](https://arxiv.org/abs/2507.17991)
*Peter Eckmann,Adrian Barnett,Alexandra Bannach-Brown,Elisa Pilar Bascunan Atria,Guillaume Cabanac,Louise Delwen Owen Franzen,Małgorzata Anna Gazda,Kaitlyn Hair,James Howison,Halil Kilicoglu,Cyril Labbe,Sarah McCann,Vladislav Nachev,Martijn Roelandse,Maia Salholz-Hillel,Robert Schulz,Gerben ter Riet,Colby Vorland,Anita Bandrowski,Tracey Weissgerber*

Main category: cs.SE

TL;DR: 本文系统比较了11款自动化科学严谨性检测工具在9项标准下的表现，发现部分工具或工具组合在不同场景下优势明显，并为相关工具的开发和应用提出了建议。


<details>
  <summary>Details</summary>
Motivation: 科学研究中的可重复性危机部分源自报告缺乏标准化与透明度。现有如ARRIVE和CONSORT等检查表，旨在提升透明度，但实际执行和同行评议补漏均存在不足。本文旨在通过比较现有自动化工具，评估其在提高科学研究严谨性方面的作用。

Method: 作者对来自ScreenIT小组的11种自动化工具在9项严谨标准上的表现进行了广泛对比。对比分析了各工具在检测开放数据、纳入和排除标准等方面的性能，并评价了组合工具的协同作用。

Result: 结果显示在部分标准（如检测开放数据）上，某些工具明显优于其他；而在其他标准如纳入与排除标准的检测方面，多个工具组合的表现优于单一工具。还指出了工具开发者应重点改进的领域。

Conclusion: 建议关注开发自动化检测工具的关键方向，提升工具实用性。研究结论为科学报告严谨性工具的开发者和相关利益方提供了具体建议与见解。所有代码与数据已公开。

Abstract: The causes of the reproducibility crisis include lack of standardization and
transparency in scientific reporting. Checklists such as ARRIVE and CONSORT
seek to improve transparency, but they are not always followed by authors and
peer review often fails to identify missing items. To address these issues,
there are several automated tools that have been designed to check different
rigor criteria. We have conducted a broad comparison of 11 automated tools
across 9 different rigor criteria from the ScreenIT group. We found some
criteria, including detecting open data, where the combination of tools showed
a clear winner, a tool which performed much better than other tools. In other
cases, including detection of inclusion and exclusion criteria, the combination
of tools exceeded the performance of any one tool. We also identified key areas
where tool developers should focus their effort to make their tool maximally
useful. We conclude with a set of insights and recommendations for stakeholders
in the development of rigor and transparency detection tools. The code and data
for the study is available at https://github.com/PeterEckmann1/tool-comparison.

</details>


### [4] [An Empirical Study of GenAI Adoption in Open-Source Game Development: Tools, Tasks, and Developer Challenges](https://arxiv.org/abs/2507.18029)
*Xiang Echo Chen,Wenhan Zhu,Guoshuai Albert Shi,Michael W. Godfrey*

Main category: cs.SE

TL;DR: 本文系统研究了开源社区中生成式AI在游戏开发中的应用和讨论，揭示了其与传统AI及非AI技术的不同点以及开发者面临的新挑战。


<details>
  <summary>Details</summary>
Motivation: 生成式AI（GenAI）日益强大，正逐渐改变游戏设计和开发流程，但目前对于开发者在真实环境下如何采用GenAI的实证研究较少，尤其是在开源社区中。本文旨在弥补这一研究空白。

Method: 通过分析GitHub上的issue讨论，收集并整理讨论AI相关话题的开源游戏仓库，采用开放卡片分类法和主题分析，对GenAI、传统AI（TradAI）和非AI话题的issue进行分层采样、标注和比较分析。

Result: 本文通过数据分析，展示了生成式AI、传统AI和非AI话题在使用模式、开发者关注点以及集成实践方面的差异，并揭示了GenAI对开源游戏开发者工作流程和痛点的影响。

Conclusion: 生成式AI为开源游戏开发引入了新的工具和挑战，与传统AI和非AI方式呈现出不同的采纳和集成模式。理解这些差异有助于推动更好的AI工具和开发支持。

Abstract: The growing capabilities of generative AI (GenAI) have begun to reshape how
games are designed and developed, offering new tools for content creation,
gameplay simulation, and design ideation. While prior research has explored
traditional uses of AI in games, such as controlling agents or generating
procedural content. There is limited empirical understanding of how GenAI is
adopted by developers in real-world contexts, especially within the open-source
community. This study aims to explore how GenAI technologies are discussed,
adopted, and integrated into open-source game development by analyzing issue
discussions on GitHub. We investigate the tools, tasks, and challenges
associated with GenAI by comparing GenAI-related issues to those involving
traditional AI (TradAI) and NonAI topics. Our goal is to uncover how GenAI
differs from other approaches in terms of usage patterns, developer concerns,
and integration practices. To address this objective, we construct a dataset of
open-source game repositories that discuss AI-related topics. We apply open
card sorting and thematic analysis to a stratified sample of GitHub issues,
labelling each by type and content. These annotations enable comparative
analysis across GenAI, TradAI, and NonAI groups, and provide insight into how
GenAI is shaping the workflows and pain points of open-source game developers.

</details>


### [5] [Your ATs to Ts: MITRE ATT&CK Attack Technique to P-SSCRM Task Mapping](https://arxiv.org/abs/2507.18037)
*Sivana Hamer,Jacob Bowen,Md Nazmul Haque,Chris Madden,Laurie Williams*

Main category: cs.SE

TL;DR: 通过四种方法实现MITRE ATT&CK与P-SSCRM任务及其它主要安全框架的映射，提升了软件供应链攻击防护的系统性和可操作性。


<details>
  <summary>Details</summary>
Motivation: 软件供应链攻击带来了显著的安全风险，软件组织亟需有效的防护和管理方法。面对日益复杂和多样化的攻击手法，当前缺乏将攻击技术与防护措施有效关联的实用框架，由此驱动了本研究。

Method: 本文通过四种互相独立的策略，对MITRE ATT&CK攻击技术与P-SSCRM（主动软件供应链风险管理框架）任务进行了详细映射。每个P-SSCRM任务也被关联到十大政府及行业知名框架中的相应任务，从而实现了多框架间的映射关系。

Result: 研究成果为软件组织提供了明确的任务与攻击技术对应关系，帮助其识别并实施可有效缓解特定软件供应链攻击的管理任务，同时促进了MITRE ATT&CK框架与其它主要标准间的互通性。

Conclusion: 该映射框架能够有效指导软件组织选择和实施针对性防护措施，实现更主动的软件供应链风险管理，并在业界多种主流安全框架间搭建了桥梁。

Abstract: The MITRE Adversarial Tactics, Techniques and Common Knowledge (MITRE ATT&CK)
Attack Technique to Proactive Software Supply Chain Risk Management Framework
(P-SSCRM) Task mapping described in this document helps software organizations
to determine how different tasks mitigate the attack techniques of software
supply chain attacks. The mapping was created through four independent
strategies to find agreed-upon mappings. Because each P-SSCRM task is mapped to
one or more tasks from the 10 frameworks, the mapping we provide is also a
mapping between MITRE ATT&CK and other prominent government and industry
frameworks.

</details>


### [6] [Factors Impacting Faculty Adoption of Project-Based Learning in Computing Education: a Survey](https://arxiv.org/abs/2507.18039)
*Ahmad D. Suleiman,Yiming Tang,Daqing Hou*

Main category: cs.SE

TL;DR: PjBL虽被看好但在计算教育领域实际推广受限，需制度性支持如资源、合作和激励机制来促进教师采纳和实践。


<details>
  <summary>Details</summary>
Motivation: 尽管基于项目的学习（PjBL）具有提升学生动机、参与度及关键技能的潜力，但在计算与软件工程教育中的教师采用率并不高，存在实施障碍。论文动机在于明确这些障碍和促进PjBL应用的因素。

Method: 采用混合方法：通过线上问卷收集80位计算机领域教师的数据，问题类型包括封闭式（量化障碍、促进因素和资源需求）与开放式（获得定性见解）。量化数据用统计方法分析，定性数据用主题分析。

Result: 研究发现教师普遍认可PjBL，但采用情况具有选择性，主要受限于教学设计、项目资源获取及缺乏制度支持（时间、经费、助教）。同行合作、职业发展、制度激励及通过研究、业界合作、同行借鉴获取项目能有效促进PjBL实施。

Conclusion: 推动PjBL广泛应用需建设系统性的支持结构，为教师尝试和扩展PjBL实践提供支持。

Abstract: This research full paper investigates the factors influencing computing
educators' adoption of project-based learning (PjBL) in software engineering
and computing curricula. Recognized as a student-centered pedagogical approach,
PjBL has the potential to enhance student motivation, engagement, critical
thinking, collaboration, and problem-solving skills. Despite these benefits,
faculty adoption remains inconsistent due to challenges such as insufficient
institutional support, time constraints, limited training opportunities,
designing or sourcing projects, and aligning them with course objectives. This
research explores these barriers and investigates the strategies and resources
that facilitate a successful adoption. Using a mixed-methods approach, data
from 80 computing faculty were collected through an online survey comprising
closed-ended questions to quantify barriers, enablers, and resource needs,
along with an open-ended question to gather qualitative insights. Quantitative
data were analyzed using statistical methods, while qualitative responses
underwent thematic analysis. Results reveal that while PjBL is widely valued,
its adoption is often selective and impacted by challenges in planning and
managing the learning process, designing suitable projects, and a lack of
institutional support, such as time, funding, and teaching assistants. Faculty
are more likely to adopt or sustain PjBL when they have access to peer
collaboration, professional development, and institutional incentives. In
addition, sourcing projects from research, industry partnerships, and borrowing
from peers emerged as key facilitators for new projects. These findings
underscore the need for systemic support structures to empower faculty to
experiment with and scale PjBL practices.

</details>


### [7] [An Empirical Study of Complexity, Heterogeneity, and Compliance of GitHub Actions Workflows](https://arxiv.org/abs/2507.18062)
*Edward Abrokwah,Taher A. Ghaleb*

Main category: cs.SE

TL;DR: 本文系统分析了 GitHub Actions 在实际开源项目中的工作流结构与复杂度，发现现实用法与最佳实践存在差距，建议改进文档和案例以提升 CI 工作流的可用性和简洁性。


<details>
  <summary>Details</summary>
Motivation: 尽管官方文档和社区最佳实践存在，但现实中的 CI 工作流设计是否符合这些规范尚缺乏实证研究。部分工作流过度复杂，与追求简单、高效的 CI 理念不符。作者希望通过量化分析，揭示 CI 工程现状及改进空间。

Method: 从开源的 Java、Python 和 C++ 等项目中收集大量 GitHub Actions 工作流数据，分析其复杂度、结构模式、多样性，并评估其是否符合官方和社区的最佳实践。还比较不同编程语言下 CI 流水线的设计差异。

Result: 确定了常见的复杂结构、异构模式，同时定位了不符合最佳实践的流程环节，并比较了三种主流编程语言的流程设计差异。结果显示部分领域符合最佳实践，但也有明显改进空间，CI 文档与实例建设亟需加强。

Conclusion: 研究发现，虽然有些工作流很好地遵循了最佳实践，但仍有大量工作流存在结构复杂、不够简洁等问题，CI 生态仍需改进文档和示例来降低复杂性。不同语言的 CI 流水线设计也存在显著差异。

Abstract: Continuous Integration (CI) has evolved from a tooling strategy to a
fundamental mindset in modern CI engineering. It enables teams to develop,
test, and deliver software rapidly and collaboratively. Among CI services,
GitHub Actions (GHA) has emerged as a dominant service due to its deep
integration with GitHub and a vast ecosystem of reusable workflow actions.
Although GHA provides official documentation and community-supported best
practices, there appears to be limited empirical understanding of how
open-source real-world CI workflows align with such practices. Many workflows
might be unnecessarily complex and not aligned with the simplicity goals of CI
practices. This study will investigate the structure, complexity,
heterogeneity, and compliance of GHA workflows in open-source software
repositories. Using a large dataset of GHA workflows from Java, Python, and C++
repositories, our goal is to (a) identify workflow complexities, (b) analyze
recurring and heterogeneous structuring patterns, (c) assess compliance with
GHA best practices, and (d) uncover differences in CI pipeline design across
programming languages. Our findings are expected to reveal both areas of strong
adherence to best practices and areas for improvement where needed. These
insights will also have implications for CI services, as they will highlight
the need for clearer guidelines and comprehensive examples in CI documentation.

</details>


### [8] [Identifier Name Similarities: An Exploratory Study](https://arxiv.org/abs/2507.18081)
*Carol Wong,Mai Abe,Silvia De Benedictis,Marissa Halim,Anthony Peruma*

Main category: cs.SE

TL;DR: 该文分析了软件中命名相似性问题，构建了一个分类体系，为后续分析命名相似性对理解和维护等方面的影响奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 标识符名称占代码很大比例，糟糕的命名会增加认知负担并影响协作；即使单独看似可读的名字，也可能由于与其他名字结构或功能的相似性而引发误解。

Method: 通过对软件项目中标识符命名相似性现象的调查与分析，开发了一个用于分类标识符名称相似性的初步分类法。

Result: 提出并初步验证了标识符命名相似性的分类体系，为后续影响分析和方法改进提供了工具和思路。

Conclusion: 初步构建了标识符命名相似性分类体系，并认为该体系能为未来研究代码可理解性、可维护性和开发者协作等方面提供基础。

Abstract: Identifier names, which comprise a significant portion of the codebase, are
the cornerstone of effective program comprehension. However, research has shown
that poorly chosen names can significantly increase cognitive load and hinder
collaboration. Even names that appear readable in isolation may lead to
misunderstandings in contexts when they closely resemble other names in either
structure or functionality. In this exploratory study, we present our
preliminary findings on the occurrence of identifier name similarity in
software projects through the development of a taxonomy that categorizes
different forms of identifier name similarity. We envision our initial taxonomy
providing researchers with a platform to analyze and evaluate the impact of
identifier name similarity on code comprehension, maintainability, and
collaboration among developers, while also allowing for further refinement and
expansion of the taxonomy.

</details>


### [9] [Understanding the Supply Chain and Risks of Large Language Model Applications](https://arxiv.org/abs/2507.18105)
*Yujie Ma,Lili Quan,Xiaofei Xie,Qiang Hu,Jiongchi Yu,Yao Zhang,Sen Chen*

Main category: cs.SE

TL;DR: 本文提出了首个全面的LLM供应链安全分析与基准数据集，揭示LLM生态系统中存在的深层依赖与显著安全风险，并提供了安全实践建议。


<details>
  <summary>Details</summary>
Motivation: 随着LLM相关系统在各领域的广泛部署，系统背后的复杂供应链（包括预训练模型、三方库、数据集和基础设施）的风险亟需系统性认知。目前的风险评估多集中于模型或数据本身，缺乏对更广泛供应链的研究基准和分析。

Method: 作者收集了3,859个真实LLM应用，对其模型、数据集和依赖库进行互依关系分析，梳理出109,211个模型、2,474个数据集和9,862个库，并从公开漏洞数据库汇总了1,555条相关风险事件。通过解析微调路径、数据集复用和依赖库引用，搭建系统生态结构，并进行风险实证分析。

Result: 分析揭示LLM应用普遍存在多层嵌套依赖和多处供应链安全隐患。作者认为现有安全评估远未覆盖全部风险，并据此给出针对开发者和研究人员的安全实践建议，以提升LLM系统的可信性和安全性。

Conclusion: LLM供应链存在复杂依赖与严重安全隐患，需从全局视角进行全面、安全的供应链分析和治理。新数据集为今后相关研究和加固措施提供了基础。

Abstract: The rise of Large Language Models (LLMs) has led to the widespread deployment
of LLM-based systems across diverse domains. As these systems proliferate,
understanding the risks associated with their complex supply chains is
increasingly important. LLM-based systems are not standalone as they rely on
interconnected supply chains involving pretrained models, third-party
libraries, datasets, and infrastructure. Yet, most risk assessments narrowly
focus on model or data level, overlooking broader supply chain vulnerabilities.
While recent studies have begun to address LLM supply chain risks, there
remains a lack of benchmarks for systematic research.
  To address this gap, we introduce the first comprehensive dataset for
analyzing and benchmarking LLM supply chain security. We collect 3,859
real-world LLM applications and perform interdependency analysis, identifying
109,211 models, 2,474 datasets, and 9,862 libraries. We extract model
fine-tuning paths, dataset reuse, and library reliance, mapping the ecosystem's
structure. To evaluate security, we gather 1,555 risk-related issues-50 for
applications, 325 for models, 18 for datasets, and 1,229 for libraries from
public vulnerability databases.
  Using this dataset, we empirically analyze component dependencies and risks.
Our findings reveal deeply nested dependencies in LLM applications and
significant vulnerabilities across the supply chain, underscoring the need for
comprehensive security analysis. We conclude with practical recommendations to
guide researchers and developers toward safer, more trustworthy LLM-enabled
systems.

</details>


### [10] [NoCode-bench: A Benchmark for Evaluating Natural Language-Driven Feature Addition](https://arxiv.org/abs/2507.18130)
*Le Deng,Zhonghao Jiang,Jialun Cao,Michael Pradel,Zhongxin Liu*

Main category: cs.SE

TL;DR: NoCode-bench基准显示，目前LLM在自然语言驱动的无代码开发中，成功率低、存在理解和多模块协作难题，未来有待改进。


<details>
  <summary>Details</summary>
Motivation: 自然语言驱动的无代码开发可提升开发生产力并使开发大众化，需要评价大型语言模型在相关任务上的实际能力。

Method: 提出了NoCode-bench基准，通过将真实世界文档更新和对应代码实现配对，基于114k代码变更和634个任务，利用开发者测试用例进行验证，并设有人工验证子集做高质量评估。

Result: 当前最好的LLM任务成功率仅为15.79%，尤其在跨文件编辑、理解大规模代码库和调用工具方面表现出明显挑战。

Conclusion: 现有的大型语言模型（LLM）在完全基于自然语言的无代码开发任务上表现有限，尚不能胜任可靠的软件功能开发。

Abstract: Natural language-driven no-code development allows users to specify software
functionality using natural language (NL) instead of editing source code,
promising increased productivity and democratized development. Large language
models (LLMs) show potential in enabling this paradigm. In this context,
software documentation acts as an NL specification for functionality. This work
introduces NoCode-bench, a benchmark designed to evaluate LLMs on real-world
NL-driven feature addition tasks, consisting of 634 tasks across 10 projects
and 114k code changes. Each task pairs documentation updates with corresponding
code implementations, validated by developer-written test cases. A subset of
114 high-quality, human-verified instances, NoCode-bench Verified, ensures
reliable evaluation. Our experiments reveal that, despite high token usage, the
best LLMs achieve a task success rate of only 15.79%, highlighting challenges
in cross-file editing, codebase understanding, and tool calling. These findings
indicate that LLMs are not yet ready for fully NL-driven no-code development.
NoCode-bench lays the foundation for future advances in this area.

</details>


### [11] [SMECS: A Software Metadata Extraction and Curation Software](https://arxiv.org/abs/2507.18159)
*Stephan Ferenz,Aida Jafarbigloo,Oliver Werth,Astrid Nieße*

Main category: cs.SE

TL;DR: 提出并实现了SMECS工具，可自动提取和校正研究软件元数据，降低研究者工作量，经实验证明用户体验良好，有利于FAIR原则在研究软件领域的实施。


<details>
  <summary>Details</summary>
Motivation: 元数据对于采用FAIR原则和提升研究软件的可发现性与可复用性具有重要作用，但高质量元数据的创建往往耗时、耗力，成为研究人员和工程师的负担。

Method: 本文开发了SMECS工具，该工具整合了从现有来源（如GitHub）提取元数据和用户友好的元数据整理界面。用户可以通过交互式界面对提取结果进行人工校正与完善，并导出为CodeMeta文件。

Result: 通过可用性实验评估，SMECS工具被证实具有良好的用户体验。

Conclusion: SMECS工具有助于简化研究软件元数据的创建过程，提升FAIR化水平。

Abstract: Metadata play a crucial role in adopting the FAIR principles for research
software and enables findability and reusability. However, creating
high-quality metadata can be resource-intensive for researchers and research
software engineers. To address this challenge, we developed the Software
Metadata Extraction and Curation Software (SMECS) which integrates the
extraction of metadata from existing sources together with a user-friendly
interface for metadata curation. SMECS extracts metadata from online
repositories such as GitHub and presents it to researchers through an
interactive interface for further curation and export as a CodeMeta file. The
usability of SMECS was evaluated through usability experiments which confirmed
that SMECS provides a satisfactory user experience. SMECS supports the
FAIRification of research software by simplifying metadata creation.

</details>


### [12] [GenAI for Automotive Software Development: From Requirements to Wheels](https://arxiv.org/abs/2507.18223)
*Nenad Petrovic,Fengjunjie Pan,Vahid Zolfaghari,Krzysztof Lebioda,Andre Schamschurko,Alois Knoll*

Main category: cs.SE

TL;DR: 本文提出融合生成式AI与模型驱动工程的自动化ADAS软件开发方法，实现需求到代码与测试全流程自动化，能缩短开发、合规和测试周期，提升效率，具有实际工程应用价值。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶和高级驾驶辅助系统（ADAS）开发需求日增，软件开发周期长、符合法规的可重复工程挑战突出。该论文希望利用人工智能提升开发自动化水平，缩短周期。

Method: 提出一种融合生成式AI的自动化汽车软件开发流程。以需求为输入，主输出包括仿真环境的测试场景代码和针对硬件平台的ADAS能力实现代码。流程中应用大语言模型（LLMs）进行基于模型的需求摘要、测试场景生成、Python仿真代码与C++目标代码生成。通过模型驱动工程（MDE）实现需求一致性检查，并结合检索增强生成（RAG）利用法规文档提升生成能力。

Result: 论文方法能有效提升ADAS相关能力的开发与测试效率，缩短合规与重构周期。能够自动化生成测试和目标平台代码，一定程度上保证了法规的一致性与开发自动化。

Conclusion: 生成式AI和模型驱动工程结合能提升自动驾驶和ADAS软件开发自动化和合规能力，显著缩短开发与测试周期。该方法为未来车载智能软件的目标需求、法规适配和持续迭代提供新途径。

Abstract: This paper introduces a GenAI-empowered approach to automated development of
automotive software, with emphasis on autonomous and Advanced Driver Assistance
Systems (ADAS) capabilities. The process starts with requirements as input,
while the main generated outputs are test scenario code for simulation
environment, together with implementation of desired ADAS capabilities
targeting hardware platform of the vehicle connected to testbench. Moreover, we
introduce additional steps for requirements consistency checking leveraging
Model-Driven Engineering (MDE). In the proposed workflow, Large Language Models
(LLMs) are used for model-based summarization of requirements (Ecore metamodel,
XMI model instance and OCL constraint creation), test scenario generation,
simulation code (Python) and target platform code generation (C++).
Additionally, Retrieval Augmented Generation (RAG) is adopted to enhance test
scenario generation from autonomous driving regulations-related documents. Our
approach aims shorter compliance and re-engineering cycles, as well as reduced
development and testing time when it comes to ADAS-related capabilities.

</details>


### [13] [An Empirical Study on Embodied Artificial Intelligence Robot (EAIR) Software Bugs](https://arxiv.org/abs/2507.18267)
*Zeqin Liao,Zibin Zheng,Peifan Reng,Henglong Liang,Zixu Gao,Zhixiang Chen,Wei Li,Yuhong Nan*

Main category: cs.SE

TL;DR: 首次系统性分析了具身人工智能机器人（EAIR）项目中的885个Bug，归纳出其独特的症状和成因，强调AI推理与决策复杂性导致的重大系统危险，并提出Bug类型与易受影响模块的对应关系，对未来诊断和修复EAIR系统缺陷具有指导意义。


<details>
  <summary>Details</summary>
Motivation: EAIR（具身人工智能机器人）正迅速发展，但目前缺乏对这类系统缺陷（Bug）的系统性理解，这阻碍了高效开发和维护。作者希望通过深入分析EAIR系统的Bug，推动理论与实践的进步。

Method: 作者对80个EAIR项目中收集的885个系统Bug进行了首次系统性研究，从症状、根本原因和受影响模块三方面进行归类与分析，最终将Bug分为18种根本原因、15种不同症状，并识别出13个受影响模块。还建立了原因与模块之间的映射关系。

Result: 分析发现，15种症状中有8种是EAIR系统特有，且常涉及严重功能失效和潜在物理危害。在18种根本原因中，有8种是EAIR特有的，多数源自AI体代理的推理与决策复杂性。作者还构建了Bug成因与易受影响模块的映射，有助于今后的Bug预测、检测和修复工作。

Conclusion: 本研究首次对EAIR系统Bug进行了系统分类和成因分析，揭示了许多专属于EAIR系统的严重Bug类型及其成因，提出了有针对性的诊断和修复方向，为该领域后续研究和高质量系统开发奠定了基础。

Abstract: Embodied Artificial Intelligence Robots (EAIR) is an emerging and rapidly
evolving technological domain. Ensuring their program correctness is
fundamental to their successful deployment. However, a general and in-depth
understanding of EAIR system bugs remains lacking, which hinders the
development of practices and techniques to tackle EAIR system bugs.
  To bridge this gap, we conducted the first systematic study of 885 EAIR
system bugs collected from 80 EAIR system projects to investigate their
symptoms, underlying causes, and module distribution. Our analysis takes
considerable effort, which classifies these bugs into 18 underlying causes, 15
distinct symptoms, and identifies 13 affected modules. It reveals several new
interesting findings and implications which help shed light on future research
on tackling or repairing EAIR system bugs. First, among the 15 identified
symptoms, our findings highlight 8 symptoms specific to EAIR systems, which is
characterized by severe functional failures and potential physical hazards.
Second, within the 18 underlying causes, we define 8 EAIR-specific causes, the
majority of which stem from the intricate issues of AI- agent reasoning and
decision making. Finally, to facilitate precise and efficient bug prediction,
detection, and repair, we constructed a mapping between underlying causes and
the modules in which they most frequently occur, which enables researchers to
focus diagnostic efforts on the modules most susceptible to specific bug types.

</details>


### [14] [Scheduzz: Constraint-based Fuzz Driver Generation with Dual Scheduling](https://arxiv.org/abs/2507.18289)
*Yan Li,Wenzhang Yang,Yuekun Wang,Jian Gao,Shaohua Wang,Yinxing Xue,Lijun Zhang*

Main category: cs.SE

TL;DR: 提出Scheduzz自动化库模糊测试工具，通过LLM理解库用法+调度优化，降低资源浪费，提升覆盖率，在真实项目中发现新漏洞并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有库模糊测试(Fuzzing)依赖专家手动编写高质量fuzz driver，非常耗时繁琐。而自动化方法往往不遵循合理的库使用规范，浪费计算资源，生成大量无效driver，且易引入假阳性bug报告。

Method: 提出了一种新颖的基于LLM（大语言模型）的自动化库模糊测试技术Scheduzz。该方法利用LLM理解库使用，提取API组合约束，并采用双调度框架高效管理API组合与fuzz driver生成与执行，将driver生成和测试过程建模为在线优化问题。

Result: Scheduzz在33个真实库上评测，显著降低了资源开销，比UTopia和上游SOTA工具在多数库上表现更优。覆盖率分别比CKGFuzzer、Promptfuzz、OSS-Fuzz高1.62x、1.50x、1.89x，并在这些库中发现了33个新bugs（其中3个获得CVE）。

Conclusion: LLM驱动的Scheduzz显著提升了自动化库模糊测试的效率和效果，有效利用计算资源，发现更多真实漏洞。

Abstract: Fuzzing a library requires experts to understand the library usage well and
craft high-quality fuzz drivers, which is tricky and tedious. Therefore, many
techniques have been proposed to automatically generate fuzz drivers. However,
they fail to generate rational fuzz drivers due to the lack of adherence to
proper library usage conventions, such as ensuring a resource is closed after
being opened. To make things worse, existing library fuzzing techniques
unconditionally execute each driver, resulting in numerous irrational drivers
that waste computational resources while contributing little coverage and
generating false positive bug reports.
  To tackle these challenges, we propose a novel automatic library fuzzing
technique, Scheduzz, an LLM-based library fuzzing technique. It leverages LLMs
to understand rational usage of libraries and extract API combination
constraints. To optimize computational resource utilization, a dual scheduling
framework is implemented to efficiently manage API combinations and fuzz
drivers. The framework models driver generation and the corresponding fuzzing
campaign as an online optimization problem. Within the scheduling loop,
multiple API combinations are selected to generate fuzz drivers, while
simultaneously, various optimized fuzz drivers are scheduled for execution or
suspension.
  We implemented Scheduzz and evaluated it in 33 real-world libraries. Compared
to baseline approaches, Scheduzz significantly reduces computational overhead
and outperforms UTopia on 16 out of 21 libraries. It achieves 1.62x, 1.50x, and
1.89x higher overall coverage than the state-of-the-art techniques CKGFuzzer,
Promptfuzz, and the handcrafted project OSS-Fuzz, respectively. In addition,
Scheduzz discovered 33 previously unknown bugs in these well-tested libraries,
3 of which have been assigned CVEs.

</details>


### [15] [YATE: The Role of Test Repair in LLM-Based Unit Test Generation](https://arxiv.org/abs/2507.18316)
*Michael Konstantinou,Renzo Degiovanni,Jie M. Zhang,Mark Harman,Mike Papadakis*

Main category: cs.SE

TL;DR: 该论文提出 YATE 方法，通过修复错误的LLM生成测试提升自动化测试质量，覆盖率和有效性均优于同类方法，提升幅度约20%。


<details>
  <summary>Details</summary>
Motivation: 当前利用语言模型生成单元测试的方法效果不错，但生成了许多语法或语义错误的无效测试。直接丢弃这些无效测试是一种资源浪费——实际上若能修复，它们具有较高的测试价值和后续测试生成的种子作用。

Method: 提出了一种结合规则静态分析和再次提示（re-prompting）方法，针对部分错误测试样例进行自动修复。这一方法被称为YATE。

Result: 在6个开源项目上的实验显示，YATE比单纯LLM生成方法多覆盖32.06%的代码行、多杀死21.77%的变异体。与其它四种LLM方法（HITS、SYMPROMPT、TESTSPARK、COVERUP）相比，YATE在测试覆盖率、分支覆盖率和杀死变异体数量上分别提升约20%，且调用LLM的成本相当。

Conclusion: YATE能够有效修复LLM生成的有误测试，大幅提升自动化测试效果，且资源消耗合理。

Abstract: Recent advances in automated test generation utilises language models to
produce unit tests. While effective, language models tend to generate many
incorrect tests with respect to both syntax and semantics. Although such
incorrect tests can be easily detected and discarded, they constitute a "missed
opportunity" -- if fixed, they are often valuable as they directly add testing
value (they effectively target the underlying program logic to be tested) and
indirectly form good seeds for generating additional tests. To this end, we
propose a simple technique for repairing some of these incorrect tests through
a combination of rule-based static analysis and re-prompting. We evaluate this
simple approach, named YATE, on a set of 6 open-source projects and show that
it can effectively produce tests that cover on average 32.06% more lines and
kill 21.77% more mutants than a plain LLM-based method. We also compare YATE
with four other LLM-based methods, namely HITS, SYMPROMPT, TESTSPARK and
COVERUP and show that it produces tests that cover substantially more code.
YATE achieves 22% higher line coverage, 20% higher branch coverage and kill 20%
more mutants at a comparable cost (number of calls to LLMs).

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [16] [Program Logics via Distributive Monoidal Categories](https://arxiv.org/abs/2507.18238)
*Filippo Bonchi,Elena Di Lavore,Mario Román,Sam Staton*

Main category: cs.LO

TL;DR: 本文用范畴论公理统一推导多种程序逻辑规则，并提出了支持推导的内部语言和组合子。


<details>
  <summary>Details</summary>
Motivation: 现有程序逻辑（如正确性、错误性以及关系Hoare逻辑）往往各自为政，缺乏统一基础。本文希望通过范畴论提供的抽象框架建立统一推导体系，规范与系统化逻辑规则的产生过程。

Method: 作者从命令式范畴的公理出发，利用范畴内部语言推导了程序逻辑中的组合子，并以此推导出程序逻辑的规则，包括正确性、错误性及关系Hoare逻辑。

Result: 成功地从命令式范畴的公理系统出发，统一推导出了不同类型的程序逻辑（包括正确性、错误性、关系Hoare逻辑）的规则。同时，构建了支持命令式多范畴的内部语言，并基于此语言构造了修改后的Dijkstra守卫命令语言的组合子。

Conclusion: 通过范畴论的方法，能够系统化地推导出程序逻辑的各项规则，并为不同类型的程序逻辑提供统一的基础。

Abstract: We derive multiple program logics, including correctness, incorrectness, and
relational Hoare logic, from the axioms of imperative categories: uniformly
traced distributive copy-discard categories. We introduce an internal language
for imperative multicategories, on top of which we derive combinators for an
adaptation of Dijkstra's guarded command language. Rules of program logics are
derived from this internal language.

</details>


### [17] [Resourceful Traces for Commuting Processes](https://arxiv.org/abs/2507.18246)
*Matthew Earnshaw,Chad Nester,Mario Román*

Main category: cs.LO

TL;DR: 本文将 Mazurkiewicz trace 扩展为输入到输出变换，实现了一种新型 effectful categories 的表示和图形演算，并首次给出了自由 effectful categories 的 commuting tensor product 构造，为带副作用系统建模提供了新理论工具。


<details>
  <summary>Details</summary>
Motivation: 传统 Mazurkiewicz trace 通常只记录动作的名字，忽略了动作本身的具体作用。为了更好地建模副作用计算的代数结构，需要一种可以描述输入到输出变换的过程模型，从而更准确地表示系统动作间的组合与交互。

Method: 将 Mazurkiewicz trace 的动作形式推广为变换，并据此构造 effectful categories 的表示法；通过这一新表示，发展出相应的图形演算方法，并利用此模型构造 commuting tensor product，捕捉两个系统之间动作可交换但资源可交换的组合。

Result: 提出了可用于 effectful categories 的 trace 表达与图形演算方法，进而实现了自由 effectful categories 的 commuting tensor product 构造，提供了新的工具分析可交换副作用系统的组合行为。

Conclusion: 通过将 Mazurkiewicz trace 的动作看作从输入到输出的变换（而非原子名），作者提出了一种针对 effectful categories（广义 Freyd categories）的新型表达方式，为副作用计算的语义提供了新的代数结构视角。

Abstract: We show that, when the actions of a Mazurkiewicz trace are considered not
merely as atomic (i.e., mere names) but transformations from a specified type
of inputs to a specified type of outputs, we obtain a novel notion of
presentation for effectful categories (also known as generalised Freyd
categories), a well-known algebraic structure in the semantics of
side-effecting computation. Like the usual representation of traces as graphs,
our notion of presentation gives rise to a graphical calculus for effectful
categories. We use our presentations to give a construction of the commuting
tensor product of free effectful categories, capturing the combination of
systems in which the actions of each must commute with one another, while still
permitting exchange of resources

</details>


### [18] [Distributing Retractions, Weak Distributive Laws and Applications to Monads of Hyperspaces, Continuous Valuations and Measures](https://arxiv.org/abs/2507.18418)
*Jean Goubault-Larrecq*

Main category: cs.LO

TL;DR: 本文研究了范畴上两个幺半群S和T及其弱分布律情况下如何合成新的幺半群U，引入并详细讨论了分布收缩的概念。证明了分布收缩和弱分布律之间的对应关系，并通过具体数学结构实例展示了理论的应用与重要代数结论。


<details>
  <summary>Details</summary>
Motivation: 已知两个幺半群及其间的弱分布律时，如何构造并明确展示它们相关的结合幺半群？如何识别某个具体幺半群U是否为由S和T通过分布律组合而成的？为此定义分布收缩并对其进行系统研究。

Method: 分析了结合幺半群的具体结构，定义了分布收缩的概念，并在2-范畴框架下建立与弱分布律的对应关系。用具体实例（Smyth, Hoare, Plotkin 超空间幺半群及连续赋值的幺半群）说明理论并展示如何利用分布收缩识别结合幺半群。

Result: 证明了分布收缩与弱分布律之间的一一对应关系，给出三个重要实例，阐明超线性/亚线性预视幺半群代数结构；得出结合幺半群为规范分叉幺半群（monad of normalized forks）等结论。

Conclusion: 分布收缩（distributing retraction）与弱分布律（weak distributive law）在2-范畴（2-categorical）意义下是一一对应的。通过具体示例说明相关结合幺半群（combined monad）的结构和应用。

Abstract: Given two monads $S$, $T$ on a category where idempotents split, and a weak
distributive law between them, one can build a combined monad $U$. Making
explicit what this monad $U$ is requires some effort. When we already have an
idea what $U$ should be, we show how to recognize that $U$ is indeed the
combined monad obtained from $S$ and $T$: it suffices to exhibit what we call a
distributing retraction of $ST$ onto $U$. We show that distributing retractions
and weak distributive laws are in one-to-one correspondence, in a 2-categorical
setting. We give three applications, where $S$ is the Smyth, Hoare or Plotkin
hyperspace monad, $T$ is a monad of continuous valuations, and $U$ is a monad
of previsions or of forks, depending on the case. As a byproduct, this allows
us to describe the algebras of monads of superlinear, resp. sublinear
previsions. In the category of compact Hausdorff spaces, the Plotkin hyperspace
monad is sometimes known as the Vietoris monad, the monad of probability
valuations coincides with the Radon monad, and we infer that the associated
combined monad is the monad of normalized forks.

</details>


### [19] [Well-Founded Coalgebras Meet König's Lemma](https://arxiv.org/abs/2507.18539)
*Henning Urbat,Thorsten Wißmann*

Main category: cs.LO

TL;DR: 本文推广了König引理至更一般的余代数与范畴设定，引入了基于有限生成子结构的良基余代数分解定理，提出了两种初始代数的新构造方式，理论和应用价值显著。


<details>
  <summary>Details</summary>
Motivation: König引理作为数学和计算机科学基础工具，其推广有助于统一和扩展许多结构的理论分析能力。现有结论多局限于集合范畴与树，本研究旨在推广至更广泛的范畴余代数环境，丰富理论基础和实际应用。

Method: 采用范畴论与余代数工具，将有限分支树推广到任意有限性内函子余代数，在局部有限可呈现范畴C下研究良基余代数及其子余代数的性质，结合具体证明和构造性方法，得到初始代数的两种新的构造途径。

Result: 提出了一般化的余代数König引理，证明了在宽松条件下，良基H-余代数为有向并的良基、有限生成子余代数之并。导出不同范畴下的König引理版本，并给出两种全新或更简明的初始代数构造方法，适用于传递系统、图等多种对象。

Conclusion: 本文推广了König引理到余代数框架，并展示其在不同范畴下的适用性，包括拓扑斯、名义集、凸集等，进一步揭示了良基余代数及初始代数的新构造。

Abstract: K\"onig's lemma is a fundamental result about trees with countless
applications in mathematics and computer science. In contrapositive form, it
states that if a tree is finitely branching and well-founded (i.e. has no
infinite paths), then it is finite. We present a coalgebraic version of
K\"onig's lemma featuring two dimensions of generalization: from finitely
branching trees to coalgebras for a finitary endofunctor H, and from the base
category of sets to a locally finitely presentable category C, such as the
category of posets, nominal sets, or convex sets. Our coalgebraic K\"onig's
lemma states that, under mild assumptions on C and H, every well-founded
coalgebra for H is the directed join of its well-founded subcoalgebras with
finitely generated state space -- in particular, the category of well-founded
coalgebras is locally presentable. As applications, we derive versions of
K\"onig's lemma for graphs in a topos as well as for nominal and convex
transition systems. Additionally, we show that the key construction underlying
the proof gives rise to two simple constructions of the initial algebra
(equivalently, the final recursive coalgebra) for the functor H: The initial
algebra is both the colimit of all well-founded and of all recursive coalgebras
with finitely presentable state space. Remarkably, this result holds even in
settings where well-founded coalgebras form a proper subclass of recursive
ones. The first construction of the initial algebra is entirely new, while for
the second one our approach yields a short and transparent new correctness
proof.

</details>


### [20] [Proceedings 19th International Workshop on the ACL2 Theorem Prover and Its Applications](https://arxiv.org/abs/2507.18567)
*Ruben Gamboa,Panagiotis Manolios*

Main category: cs.LO

TL;DR: ACL2 Workshop是ACL2用户和研究者的核心交流平台，促进了定理证明系统的研究和应用，ACL2也因此获得业界高度认可。


<details>
  <summary>Details</summary>
Motivation: ACL2在定理证明和自动推理领域有广泛应用，作为Boyer-Moore系列最新系统，有必要提供一个交流研究成果和应用的平台，促进该工具发展与合作。

Method: 通过举办ACL2 Workshop系列研讨会，聚集ACL2系统用户，集中展示和交流相关的研究进展和应用经验。

Result: ACL2 Workshop成为ACL2用户和研究者的主要技术交流论坛。ACL2系统及其家族成员获得了2005年ACM软件系统奖，显示了其工业级应用和学术地位。

Conclusion: ACL2 Workshop巩固了ACL2在自动定理证明领域的影响力，推动了相关研究与应用的深入发展。

Abstract: The ACL2 Workshop series is the major technical forum for users of the ACL2
theorem proving system to present research related to the ACL2 theorem prover
and its applications. ACL2 is an industrial-strength automated reasoning
system, the latest in the Boyer-Moore family of theorem provers. The 2005 ACM
Software System Award was awarded to Boyer, Kaufmann, and Moore for their work
on ACL2 and the other theorem provers in the Boyer-Moore family.

</details>


### [21] [Approximate SMT Counting Beyond Discrete Domains](https://arxiv.org/abs/2507.18612)
*Arijit Shaw,Kuldeep S. Meel*

Main category: cs.LO

TL;DR: pact是一种高效的混合领域SMT模型计数器，能够以理论保证高效近似计数，在实验中远超基准方法。


<details>
  <summary>Details</summary>
Motivation: SMT求解器在自动化推理领域表现突出，但现有的模型计数方法主要局限于离散变量，混合（离散+连续）公式的模型计数仍是难题，尤其是在离散域投影计数方面缺乏有效手段。

Method: 提出了pact，这是一种混合公式的SMT模型计数器。pact基于哈希的近似模型计数，通过对投影变量进行对数次SMT求解器调用，并采用优化哈希函数，实现理论上有保证的解空间估计。

Result: 在14,202个基准题中，pact完成了603个实例的计数，而基线方法仅完成13个实例，显示出显著性能提升。

Conclusion: pact为混合SMT公式提供了一种高效且具有理论保证的近似模型计数方法，大大提升了求解能力，并克服了传统方法在处理离散和连续混合变量时的局限。

Abstract: Satisfiability Modulo Theory (SMT) solvers have advanced automated reasoning,
solving complex formulas across discrete and continuous domains. Recent
progress in propositional model counting motivates extending SMT capabilities
toward model counting, especially for hybrid SMT formulas. Existing approaches,
like bit-blasting, are limited to discrete variables, highlighting the
challenge of counting solutions projected onto the discrete domain in hybrid
formulas.
  We introduce pact, an SMT model counter for hybrid formulas that uses
hashing-based approximate model counting to estimate solutions with theoretical
guarantees. pact makes a logarithmic number of SMT solver calls relative to the
projection variables, leveraging optimized hash functions. pact achieves
significant performance improvements over baselines on a large suite of
benchmarks. In particular, out of 14,202 instances, pact successfully finished
on 603 instances, while Baseline could only finish on 13 instances.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [22] [Shop-R1: Rewarding LLMs to Simulate Human Behavior in Online Shopping via Reinforcement Learning](https://arxiv.org/abs/2507.17842)
*Yimeng Zhang,Tian Wang,Jiri Gesi,Ziyi Wang,Yuxuan Lu,Jiacheng Lin,Sinong Zhan,Vianne Gao,Ruochen Jiao,Junze Liu,Kun Qian,Yuxin Tang,Ran Xue,Houyu Zhang,Qingjun Cui,Yufan Guo,Dakuo Wang*

Main category: cs.CL

TL;DR: 本文提出Shop-R1强化学习框架，通过分阶段奖励结构大幅提升大语言模型模拟线上购物人类行为的推理与动作预测能力，实验优于传统方法65%以上。


<details>
  <summary>Details</summary>
Motivation: 目前利用大语言模型（LLM）在网页环境中模拟“类人”行为已表现出强大潜力，但通过合成推理过程并进行有监督微调提升能力的方法，最终效果受限于模型本身的推理能力。提升LLM在模拟真实人类行为场景（如线上购物）中的推理和行为预测能力，有实际应用价值。

Method: 提出Shop-R1框架，将人类行为模拟分为推理生成和行为预测两个阶段，分别设置不同的奖励信号进行强化学习。推理阶段结合模型内部信号（如logit分布）自监督优化推理过程，行为预测阶段用分层奖励结构及难度感知缩放，精细区分奖励，既考查高层动作类型，又细化到属性值的准确度，奖励与完成难度成正比。

Result: 实验显示，所提方法在基准线上达到了65%以上的相对性能提升。

Conclusion: 通过面向推理与行为预测的分阶段奖励结构，Shop-R1能有效提升LLM在人类行为仿真任务中的推理能力和行动准确性。

Abstract: Large Language Models (LLMs) have recently demonstrated strong potential in
generating 'believable human-like' behavior in web environments. Prior work has
explored augmenting training data with LLM-synthesized rationales and applying
supervised fine-tuning (SFT) to enhance reasoning ability, which in turn can
improve downstream action prediction. However, the performance of such
approaches remains inherently bounded by the reasoning capabilities of the
model used to generate the rationales. In this paper, we introduce Shop-R1, a
novel reinforcement learning (RL) framework aimed at enhancing the reasoning
ability of LLMs for simulation of real human behavior in online shopping
environments Specifically, Shop-R1 decomposes the human behavior simulation
task into two stages: rationale generation and action prediction, each guided
by distinct reward signals. For rationale generation, we leverage internal
model signals (e.g., logit distributions) to guide the reasoning process in a
self-supervised manner. For action prediction, we propose a hierarchical reward
structure with difficulty-aware scaling to prevent reward hacking and enable
fine-grained reward assignment. This design evaluates both high-level action
types and the correctness of fine-grained sub-action details (attributes and
values), rewarding outputs proportionally to their difficulty. Experimental
results show that our method achieves a relative improvement of over 65%
compared to the baseline.

</details>


### [23] [Dynamic and Generalizable Process Reward Modeling](https://arxiv.org/abs/2507.17849)
*Zhangyue Yin,Qiushi Sun,Zhiyuan Zeng,Qinyuan Cheng,Xipeng Qiu,Xuanjing Huang*

Main category: cs.CL

TL;DR: 本文提出了一种新型的动态泛化过程奖励模型DG-PRM，在复杂和多任务场景下为大语言模型提供了更有效、细粒度的奖励指导，显著提升了模型表现和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的过程奖励模型（PRMs）大多采用启发式方法，但其跨领域泛化能力有限。虽然“LLM-as-judge”为泛化奖励提供了新思路，但如今研究主要集中于结果反馈，未能充分利用文本中的深层指导信息。此外，静态、粗粒度的评估标准难以适应复杂的流程监督需求。

Method: 本文提出Dynamic and Generalizable Process Reward Modeling（DG-PRM），该方法通过奖励树来捕捉和存储细粒度、多维度的奖励标准，并动态选择奖励信号对过程的每一步进行评分。为处理复杂的奖励信号，对比性地引入帕累托优势判别方法识别积极与消极的奖励信号对。

Result: DG-PRM在权威基准测试中表现出色，能显著提升模型在多任务、密集奖励场景下的性能。进一步分析表明，DG-PRM对分布外情形具有很好的适应性，泛化能力突出。

Conclusion: DG-PRM 通过动态、细粒度的奖励建模和创新的信号判别方式，实现了跨任务、跨领域的优秀性能，为复杂流程场景下LLM的指导带来了新突破。

Abstract: Process Reward Models (PRMs) are crucial for guiding Large Language Models
(LLMs) in complex scenarios by providing dense reward signals. However,
existing PRMs primarily rely on heuristic approaches, which struggle with
cross-domain generalization. While LLM-as-judge has been proposed to provide
generalized rewards, current research has focused mainly on feedback results,
overlooking the meaningful guidance embedded within the text. Additionally,
static and coarse-grained evaluation criteria struggle to adapt to complex
process supervision. To tackle these challenges, we propose Dynamic and
Generalizable Process Reward Modeling (DG-PRM), which features a reward tree to
capture and store fine-grained, multi-dimensional reward criteria. DG-PRM
dynamically selects reward signals for step-wise reward scoring. To handle
multifaceted reward signals, we pioneeringly adopt Pareto dominance estimation
to identify discriminative positive and negative pairs. Experimental results
show that DG-PRM achieves stunning performance on prevailing benchmarks,
significantly boosting model performance across tasks with dense rewards.
Further analysis reveals that DG-PRM adapts well to out-of-distribution
scenarios, demonstrating exceptional generalizability.

</details>


### [24] [VeriMinder: Mitigating Analytical Vulnerabilities in NL2SQL](https://arxiv.org/abs/2507.17896)
*Shubham Mohole,Sainyam Galhotra*

Main category: cs.CL

TL;DR: 本文提出并实现了VeriMinder系统，通过三大创新识别、缓解数据分析中的偏见，提高自然语言界面数据分析的科学性，效果显著且已开源。


<details>
  <summary>Details</summary>
Motivation: 自然语言数据库接口（NLIDBs）让更多人能够进行数据分析，但许多无统计背景的用户容易在分析中提出带偏见的问题。目前相关研究多集中于提升文本生成SQL的准确率，而对分析性提问中的认知偏见关注较少。

Method: 提出VeriMinder系统。该系统引入三大创新：（1）情境语义映射框架，识别与具体数据分析场景相关的偏见；（2）按照“难以变通”原则的分析框架，引导用户系统性地进行无偏误数据分析；（3）基于LLM的提示生成系统，采用多候选、批判反馈及自我反思，生成高质量、面向任务的分析提示。

Result: 基于用户测试，82.5%的用户反馈该系统对分析质量有积极提升。在分析具体性、全面性、准确性等关键指标上，VeriMinder比其他方案至少高20%。系统已实现为网页应用，开源供进一步研究和社区采用。

Conclusion: VeriMinder通过检测和缓解数据分析中的认知偏见，提高无统计基础用户的数据分析质量。其创新方法和开源实现有助于推动数据分析的公平与科学性。

Abstract: Application systems using natural language interfaces to databases (NLIDBs)
have democratized data analysis. This positive development has also brought
forth an urgent challenge to help users who might use these systems without a
background in statistical analysis to formulate bias-free analytical questions.
Although significant research has focused on text-to-SQL generation accuracy,
addressing cognitive biases in analytical questions remains underexplored. We
present VeriMinder, https://veriminder.ai, an interactive system for detecting
and mitigating such analytical vulnerabilities. Our approach introduces three
key innovations: (1) a contextual semantic mapping framework for biases
relevant to specific analysis contexts (2) an analytical framework that
operationalizes the Hard-to-Vary principle and guides users in systematic data
analysis (3) an optimized LLM-powered system that generates high-quality,
task-specific prompts using a structured process involving multiple candidates,
critic feedback, and self-reflection.
  User testing confirms the merits of our approach. In direct user experience
evaluation, 82.5% participants reported positively impacting the quality of the
analysis. In comparative evaluation, VeriMinder scored significantly higher
than alternative approaches, at least 20% better when considered for metrics of
the analysis's concreteness, comprehensiveness, and accuracy. Our system,
implemented as a web application, is set to help users avoid "wrong question"
vulnerability during data analysis. VeriMinder code base with prompts,
https://reproducibility.link/veriminder, is available as an MIT-licensed
open-source software to facilitate further research and adoption within the
community.

</details>


### [25] [One Whisper to Grade Them All](https://arxiv.org/abs/2507.17918)
*Nhan Phan,Anusha Porwal,Yaroslav Getman,Ekaterina Voskoboinik,Tamás Grósz,Mikko Kurimo*

Main category: cs.CL

TL;DR: 提出一种高效端到端ASA系统，一次性处理多段口语答题，无需转录和分部模型，准确率超越基线，推理高效，适合大规模应用，并可用更少数据取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 为了解决多部分第二语言口语测试中自动口语评估（ASA）的效率、准确性和可扩展性问题，尤其适用于大规模计算机辅助语言学习系统。

Method: 采用端到端方法，用单一的Whisper-small编码器处理全部四段口语答题，通过轻量聚合器整合全部信息，直接预测最终得分。引入数据采样策略优化训练效率和样本不平衡问题。

Result: 系统取得了0.384的RMSE，优于基于文本的基线系统（0.44）。参数数量最高为168M，仅为Whisper-small的70%。在仅使用44.8%语料库说话者数据且类别不平衡条件下，RMSE仍达0.383，性能优越且数据高效。

Conclusion: 无须转录及子模型即可高效、准确地评估多段口语测试，适合大规模应用。数据采样策略进一步提升了模型的数据效率及对类别不平衡的鲁棒性。

Abstract: We present an efficient end-to-end approach for holistic Automatic Speaking
Assessment (ASA) of multi-part second-language tests, developed for the 2025
Speak & Improve Challenge. Our system's main novelty is the ability to process
all four spoken responses with a single Whisper-small encoder, combine all
information via a lightweight aggregator, and predict the final score. This
architecture removes the need for transcription and per-part models, cuts
inference time, and makes ASA practical for large-scale Computer-Assisted
Language Learning systems.
  Our system achieved a Root Mean Squared Error (RMSE) of 0.384, outperforming
the text-based baseline (0.44) while using at most 168M parameters (about 70%
of Whisper-small). Furthermore, we propose a data sampling strategy, allowing
the model to train on only 44.8% of the speakers in the corpus and still reach
0.383 RMSE, demonstrating improved performance on imbalanced classes and strong
data efficiency.

</details>


### [26] [Evaluating the Performance of AI Text Detectors, Few-Shot and Chain-of-Thought Prompting Using DeepSeek Generated Text](https://arxiv.org/abs/2507.17944)
*Hulayyil Alshammari,Praveen Rao*

Main category: cs.CL

TL;DR: 该文分析了6种AI文本检测工具对于DeepSeek模型生成文本的识别能力，发现Copyleaks和QuillBot基线表现最好，但一旦进行类人化改写，所有检测工具准确率均明显下降，few-shot和CoT提示的检测效果则优异。指出当前检测工具对新兴LLM模型存在鲁棒性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）的迅速发展，生成文本的真实性和写作诚信引发了广泛关注，促使了各类AI文本检测工具的出现。然而，以往关于检测工具的研究主要集中在ChatGPT等主流模型，且不同检测器的表现差异较大。而新出现的DeepSeek模型在检测性能研究方面存在明显空白。

Method: 本研究选用了6种常用AI文本检测工具（AI Text Classifier、Content Detector AI、Copyleaks、QuillBot、GPT-2、GPTZero），并将DeepSeek模型产生的文本施加对抗性攻击（如标准和类人改写），考察各检测器对DeepSeek生成文本的识别能力。还通过few-shot提示与思维链推理（CoT），将DeepSeek本身用作检测器，判别AI与人类文本。实验用49组人类撰写及DeepSeek回应的问答数据，并用改写和类人化技术扩展到196份数据，最终检验检测器鲁棒性及准确率。

Result: QuillBot与Copyleaks在原始及改写后的DeepSeek文本检测上表现接近完美，但AI Text Classifier和GPT-2表现不稳定。最有效的对抗手段是类人化处理，使Copyleaks、QuillBot和GPTZero的检测准确率分别下降至71%、58%和52%。而few-shot与CoT提示的检测方式表现优异，五次提示下只有1例误判（AI召回率96%，人类召回率100%）。

Conclusion: AI文本检测工具在面对新型LLM——DeepSeek——生成文本时，存在较大性能差异。特别是在遭受类人化对抗后，市面主流检测工具准确率大幅下降。采用few-shot和CoT技术的检测方式对抗性强，识别效果更佳。未来需要研发更为鲁棒、高效的检测措施，以应对不断进化的生成式AI模型。

Abstract: Large language models (LLMs) have rapidly transformed the creation of written
materials. LLMs have led to questions about writing integrity, thereby driving
the creation of artificial intelligence (AI) detection technologies.
Adversarial attacks, such as standard and humanized paraphrasing, inhibit
detectors' ability to detect machine-generated text. Previous studies have
mainly focused on ChatGPT and other well-known LLMs and have shown varying
accuracy across detectors. However, there is a clear gap in the literature
about DeepSeek, a recently published LLM. Therefore, in this work, we
investigate whether six generally accessible AI detection tools -- AI Text
Classifier, Content Detector AI, Copyleaks, QuillBot, GPT-2, and GPTZero -- can
consistently recognize text generated by DeepSeek. The detectors were exposed
to the aforementioned adversarial attacks. We also considered DeepSeek as a
detector by performing few-shot prompting and chain-of-thought reasoning (CoT)
for classifying AI and human-written text. We collected 49 human-authored
question-answer pairs from before the LLM era and generated matching responses
using DeepSeek-v3, producing 49 AI-generated samples. Then, we applied
adversarial techniques such as paraphrasing and humanizing to add 196 more
samples. These were used to challenge detector robustness and assess accuracy
impact. While QuillBot and Copyleaks showed near-perfect performance on
original and paraphrased DeepSeek text, others -- particularly AI Text
Classifier and GPT-2 -- showed inconsistent results. The most effective attack
was humanization, reducing accuracy to 71% for Copyleaks, 58% for QuillBot, and
52% for GPTZero. Few-shot and CoT prompting showed high accuracy, with the best
five-shot result misclassifying only one of 49 samples (AI recall 96%, human
recall 100%).

</details>


### [27] [Are LLM Belief Updates Consistent with Bayes' Theorem?](https://arxiv.org/abs/2507.17951)
*Sohaib Imran,Ihor Kendiukhov,Matthew Broerman,Aditya Thomas,Riccardo Campanella,Rob Lamb,Peter M. Atkinson*

Main category: cs.CL

TL;DR: 本文提出了衡量语言模型是否更好地根据证据进行概率更新的BCC指标，通过实验发现模型规模和能力越大，其贝叶斯一致性越好，这为理解和管理大型语言模型提供了新见解。


<details>
  <summary>Details</summary>
Motivation: 探究规模更大、能力更强的语言模型在根据新证据调整概率判断时，是否更符合贝叶斯定理，从而更好地理解和管理大型语言模型（LLMs）。

Method: 提出并使用Bayesian Coherence Coefficient（BCC）指标，构建用于评估BCC的数据集，对五个不同模型家族的多种预训练语言模型的BCC进行了实证测试。

Result: 实验发现，拥有更多参数、能力更强的预训练语言模型，其“信念”与贝叶斯定理的一致性显著更高。

Conclusion: 更大的、更强大的预训练语言模型在根据贝叶斯定理调整“信念”概率时表现出更高的一致性。

Abstract: Do larger and more capable language models learn to update their "beliefs"
about propositions more consistently with Bayes' theorem when presented with
evidence in-context? To test this, we formulate a Bayesian Coherence
Coefficient (BCC) metric and generate a dataset with which to measure the BCC.
We measure BCC for multiple pre-trained-only language models across five model
families, comparing against the number of model parameters, the amount of
training data, and model scores on common benchmarks. Our results provide
evidence for our hypothesis that larger and more capable pre-trained language
models assign credences that are more coherent with Bayes' theorem. These
results have important implications for our understanding and governance of
LLMs.

</details>


### [28] [Natural Language Processing for Tigrinya: Current State and Future Directions](https://arxiv.org/abs/2507.17974)
*Fitsum Gaim,Jong C. Park*

Main category: cs.CL

TL;DR: 本文系统综述了2011-2025年间提格里尼亚语NLP研究进展，总结了资源、模型和应用的现状与挑战，明确了未来发展方向，并公开了相关研究元数据。


<details>
  <summary>Details</summary>
Motivation: 提格里尼亚语在自然语言处理领域严重资源匮乏，亟需系统性梳理和总结当前进展，为进一步研究提供依据。

Method: 系统性地回顾和分析了自2011年至2025年间40余项与提格里尼亚语NLP相关的研究，从资源、模型到应用进行了分类总结。

Result: 发现提格里尼亚NLP发展经历了从规则系统到现代神经网络的演变，且每次进步都伴随着资源建设的突破。同时，指出了形态学复杂性和资源稀缺的核心挑战，并展望了形态学感知建模、跨语言迁移和社区驱动资源开发等未来方向。

Conclusion: 本文为提格里尼亚语NLP研究提供了全面的参考，并提出了未来发展的方向。

Abstract: Despite being spoken by millions of people, Tigrinya remains severely
underrepresented in Natural Language Processing (NLP) research. This work
presents a comprehensive survey of NLP research for Tigrinya, analyzing over 40
studies spanning more than a decade of work from 2011 to 2025. We
systematically review the current state of computational resources, models, and
applications across ten distinct downstream tasks, including morphological
processing, machine translation, speech recognition, and question-answering.
Our analysis reveals a clear trajectory from foundational, rule-based systems
to modern neural architectures, with progress consistently unlocked by resource
creation milestones. We identify key challenges rooted in Tigrinya's
morphological complexity and resource scarcity, while highlighting promising
research directions, including morphology-aware modeling, cross-lingual
transfer, and community-centered resource development. This work serves as both
a comprehensive reference for researchers and a roadmap for advancing Tigrinya
NLP. A curated metadata of the surveyed studies and resources is made publicly
available.\footnote{Tigrinya NLP Anthology:
https://github.com/fgaim/tigrinya-nlp-anthology.

</details>


### [29] [Technical Report of TeleChat2, TeleChat2.5 and T1](https://arxiv.org/abs/2507.18013)
*Zihan Wang,Xinzhang Liu,Yitong Yao,Chao Wang,Yu Zhao,Zhihao Yang,Wenmin Deng,Kaipeng Jia,Jiaxin Peng,Yuyao Huang,Sishi Xiong,Zhuo Jiang,Kaidong Yu,Xiaohui Hu,Fubei Yao,Ruiyu Fang,Zhuoru Jiang,Ruiting Song,Qiyi Xie,Rui Xue,Xuewei He,Yanlei Xue,Zhu Yuan,Zhaoxi Zhang,Zilu Huang,Shiquan Wang,Xin Wang,Hanming Wu,Mingyuan Wang,Xufeng Zhan,Yuhan Sun,Zhaohu Xing,Yuhao Jiang,Bingkai Yang,Shuangyong Song,Yongxiang Li,Zhongjiang He,Xuelong Li*

Main category: cs.CL

TL;DR: TeleChat2、2.5与T1通过更大规模和多样化的训练数据及优化训练策略，在无需模型架构大改的情况下显著提升了推理和任务性能，部分模型能力已超过主流商业大模型，并全面开源。


<details>
  <summary>Details</summary>
Motivation: 现有的TeleChat模型在推理和一般任务性能方面有提升空间，希望通过新的训练策略提升模型能力，同时兼顾不同应用场景（如快速推理或复杂推理）。

Method: 在架构几乎不变的情况下，通过更大规模的高质量数据预训练（10万亿token），加上有监督微调（SFT）、偏好优化（DPO）以及领域数据的持续预训练、强化学习（RL）优化。T1针对复杂推理，TeleChat2.5针对高速推理。

Result: T1和TeleChat2.5均为Dense Transformer架构，参数量达到115B。T1在复杂推理（尤其是数学和代码推理）显示显著提升，T1-115B在多个任务上超越了OpenAI的o1-mini和GPT-4o。

Conclusion: 新一代TeleChat系列（TeleChat2、2.5、T1）采用增强训练策略，在架构基本不变的情况下实现了性能大幅提升，涵盖推理速度与复杂推理等多场景，部分模型已开源，有利于开发者和研究者广泛应用。

Abstract: We introduce the latest series of TeleChat models: \textbf{TeleChat2},
\textbf{TeleChat2.5}, and \textbf{T1}, offering a significant upgrade over
their predecessor, TeleChat. Despite minimal changes to the model architecture,
the new series achieves substantial performance gains through enhanced training
strategies in both pre-training and post-training stages. The series begins
with \textbf{TeleChat2}, which undergoes pretraining on 10 trillion
high-quality and diverse tokens. This is followed by Supervised Fine-Tuning
(SFT) and Direct Preference Optimization (DPO) to further enhance its
capabilities. \textbf{TeleChat2.5} and \textbf{T1} expand the pipeline by
incorporating a continual pretraining phase with domain-specific datasets,
combined with reinforcement learning (RL) to improve performance in code
generation and mathematical reasoning tasks. The \textbf{T1} variant is
designed for complex reasoning, supporting long Chain-of-Thought (CoT)
reasoning and demonstrating substantial improvements in mathematics and coding.
In contrast, \textbf{TeleChat2.5} prioritizes speed, delivering rapid
inference. Both flagship models of \textbf{T1} and \textbf{TeleChat2.5} are
dense Transformer-based architectures with 115B parameters, showcasing
significant advancements in reasoning and general task performance compared to
the original TeleChat. Notably, \textbf{T1-115B} outperform proprietary models
such as OpenAI's o1-mini and GPT-4o. We publicly release \textbf{TeleChat2},
\textbf{TeleChat2.5} and \textbf{T1}, including post-trained versions with 35B
and 115B parameters, to empower developers and researchers with
state-of-the-art language models tailored for diverse applications.

</details>


### [30] [NeuralDB: Scaling Knowledge Editing in LLMs to 100,000 Facts with Neural KV Database](https://arxiv.org/abs/2507.18028)
*Weizhi Fei,Hao Shi,Jing Xu,Jingchen Peng,Jiazheng Li,Jingzhao Zhang,Bo Bai,Wei Han,Zhenyuan Chen,Xueyan Niu*

Main category: cs.CL

TL;DR: 作者提出NeuralDB框架，通过神经KV数据库和门控机制，有效实现大规模事实编辑，并保留原有LLM的通用能力。大量实验验证了该方法的效果和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在实际应用中需要频繁地更新知识，但全面重新训练模型代价高昂。目前的知识编辑方法如Locate-and-Edit（L&E）虽然能大规模修改知识，但容易损害模型的整体能力，且在大规模编辑时会遗忘已编辑事实。因此，需要一种高效且不会损害模型通用能力的知识编辑方法。

Method: 作者将现有的线性L&E方法视为查询键值数据库（KV Database），据此提出了NeuralDB编辑框架。NeuralDB将编辑后的事实显式表示为神经网络化的KV数据库，并配备了非线性门控检索模块。该门控模块只在推理涉及编辑事实时启用，从而有效保护LLMs的通用能力。

Result: 在ZsRE和CounterFacts数据集上，对GPT2-XL、GPT-J (6B)、Llama-3 (8B)等模型进行了1万条事实编辑的实验。实验结果显示，NeuralDB在编辑效果、泛化能力、专一性、流畅性、一致性等方面表现优异，并能保持模型在6项代表性文本理解和生成任务中的整体性能。进一步实验表明，NeuralDB可扩展至10万条事实编辑，远超以往工作（提升50倍），依然保持效果。

Conclusion: NeuralDB为LLMs的知识大规模高效编辑提供了一种新范式，既提升了编辑效果和可扩展性，又能有效保护LLMs的通用能力，具有良好的实用前景。

Abstract: Efficiently editing knowledge stored in large language models (LLMs) enables
model updates without large-scale training. One possible solution is
Locate-and-Edit (L\&E), allowing simultaneous modifications of a massive number
of facts. However, such editing may compromise the general abilities of LLMs
and even result in forgetting edited facts when scaling up to thousands of
edits. In this paper, we model existing linear L\&E methods as querying a
Key-Value (KV) database. From this perspective, we then propose NeuralDB, an
editing framework that explicitly represents the edited facts as a neural KV
database equipped with a non-linear gated retrieval module, % In particular,
our gated module only operates when inference involves the edited facts,
effectively preserving the general abilities of LLMs. Comprehensive experiments
involving the editing of 10,000 facts were conducted on the ZsRE and
CounterFacts datasets, using GPT2-XL, GPT-J (6B) and Llama-3 (8B). The results
demonstrate that NeuralDB not only excels in editing efficacy, generalization,
specificity, fluency, and consistency, but also preserves overall performance
across six representative text understanding and generation tasks. Further
experiments indicate that NeuralDB maintains its effectiveness even when scaled
to 100,000 facts (\textbf{50x} more than in prior work).

</details>


### [31] [GrAInS: Gradient-based Attribution for Inference-Time Steering of LLMs and VLMs](https://arxiv.org/abs/2507.18043)
*Duy Nguyen,Archiki Prasad,Elias Stengel-Eskin,Mohit Bansal*

Main category: cs.CL

TL;DR: 该论文提出了可同时用于文本和多模态模型的推理时引导新方法GrAInS，通过识别和利用输入token的归因信息，精确调控模型内激活，在不微调模型参数的前提下有效提升表现、降低幻觉，并具备良好解释性。


<details>
  <summary>Details</summary>
Motivation: 现有推理时引导方法存在三大问题：1) 采用固定向量忽视了输入token的个体影响；2) 没有很好利用模型输出的梯度信号；3) 在多模态任务中未考虑视觉与文本输入的不均衡贡献。为此需研发更细致、有效且解释力更强的控制方法。

Method: 提出了一种名为GrAInS的推理时引导方法：利用Integrated Gradients等梯度归因方法，在模型生成过程中识别最具影响力的输入token，并基于正/负归因构建方向性调控向量。这些向量用于在transformer各层调整隐藏激活，并通过归一化保持表示尺度，实现细粒度调控。

Result: 与主流微调和引导方法相比，在多个基准任务上，GrAInS取得了显著提升：如在TruthfulQA数据集上准确率提升13.22%，LLaVA-1.6-7B模型的MMHal-Bench幻觉率由0.624降至0.514，SPA-VL对齐胜率提升8.11%，并且模型流畅性与通用能力不受影响。

Conclusion: GrAInS方法在不需要模型重新训练或辅助监督的情况下实现了对模型行为的精细、可解释和模块化的操控，明显优于现有的微调和引导（steering）方法。它能够提升纯文本和视觉-语言模型的任务表现，改善模型对齐性及降低幻觉现象。

Abstract: Inference-time steering methods offer a lightweight alternative to
fine-tuning large language models (LLMs) and vision-language models (VLMs) by
modifying internal activations at test time without updating model weights.
However, most existing approaches rely on fixed, global intervention vectors,
overlook the causal influence of individual input tokens, and fail to leverage
informative gradients from the model's logits, particularly in multimodal
settings where visual and textual inputs contribute unevenly. To address these
limitations, we introduce GrAInS, an inference-time steering approach that
operates across both language-only and vision-language models and tasks. GrAInS
uses contrastive, gradient-based attribution via Integrated Gradients to
identify the top-k most influential tokens, both positively and negatively
attributed based on their contribution to preferred versus dispreferred
outputs. These tokens are then used to construct directional steering vectors
that capture semantic shifts from undesirable to desirable behavior. During
inference, GrAInS adjusts hidden activations at transformer layers guided by
token-level attribution signals, and normalizes activations to preserve
representational scale. This enables fine-grained, interpretable, and modular
control over model behavior, without retraining or auxiliary supervision.
Empirically, GrAInS consistently outperforms both fine-tuning and existing
steering baselines: it achieves a 13.22% accuracy gain on TruthfulQA using
Llama-3.1-8B, reduces hallucination rates on MMHal-Bench from 0.624 to 0.514
with LLaVA-1.6-7B, and improves alignment win rates on SPA-VL by 8.11%, all
while preserving the model's fluency and general capabilities.

</details>


### [32] [Synthetic Data Generation for Phrase Break Prediction with Large Language Model](https://arxiv.org/abs/2507.18044)
*Hoyeon Lee,Sejung Son,Ye-Eun Kang,Jong-Hwan Kim*

Main category: cs.CL

TL;DR: 本论文提出利用LLM自动生成短语断句标注，减少人工成本，提升多语言短语断句预测的效果，展示了LLM在语音处理领域的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 当前短语断句预测方法需要大量人工标注音频或文本，人工成本高且数据一致性差。近年来大语言模型（LLMs）在生成合成数据、减少人工标注需求方面表现出色，激发了作者用LLM解决这些难题的兴趣。

Method: 作者探索用LLM生成合成短语断句标注，并与传统人工标注比较，评估多语言下的有效性，以此验证LLM生成的数据能否替代人工标注。

Result: LLM生成的合成数据在短语断句预测任务中能有效缓解数据短缺问题，并在多语言场景下表现良好，显示LLM作为语音领域新方案的潜力。

Conclusion: 通过LLM自动生成标注数据可减少人工标注工作，提升短语断句预测模型的数据可用性，为语音合成等领域带来便利。

Abstract: Current approaches to phrase break prediction address crucial prosodic
aspects of text-to-speech systems but heavily rely on vast human annotations
from audio or text, incurring significant manual effort and cost. Inherent
variability in the speech domain, driven by phonetic factors, further
complicates acquiring consistent, high-quality data. Recently, large language
models (LLMs) have shown success in addressing data challenges in NLP by
generating tailored synthetic data while reducing manual annotation needs.
Motivated by this, we explore leveraging LLM to generate synthetic phrase break
annotations, addressing the challenges of both manual annotation and
speech-related tasks by comparing with traditional annotations and assessing
effectiveness across multiple languages. Our findings suggest that LLM-based
synthetic data generation effectively mitigates data challenges in phrase break
prediction and highlights the potential of LLMs as a viable solution for the
speech domain.

</details>


### [33] [Privacy-Preserving Synthetic Review Generation with Diverse Writing Styles Using LLMs](https://arxiv.org/abs/2507.18055)
*Tevin Atwal,Chan Nam Tieu,Yefeng Yuan,Zhan Shi,Yuhong Liu,Liang Cheng*

Main category: cs.CL

TL;DR: 本文系统评估了多种LLM生成文本合成数据的多样性与隐私性，发现其存在显著不足，并提出了基于prompt改进的数据生成方法以提升多样性同时保护隐私。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在生成合成数据方面应用日益广泛，合成数据为模型训练带来了成本效益和可扩展性。然而，人们对于合成数据的多样性和隐私风险关注不足，因此亟需系统评估这些关键问题。

Method: 本文针对基于文本的合成数据，提出了一套全面的度量指标，用于定量评估由主流LLM生成的合成数据在多样性（包括语言表达、情感、用户视角）和隐私性（包括可重新识别风险与风格异常值）两方面的表现，并基于实验结果设计了一种基于prompt的方法以提升数据多样性且保持隐私。

Result: 实验揭示现有LLM在生成多样且隐私保护的合成数据方面存在显著局限。通过评估结果，研究者提出了一种新的prompt设计方法，有效提升了合成评论的多样性并保护了评审者隐私。

Conclusion: 尽管LLM在合成数据生成中具备潜力，但在保证数据多样性和隐私性上仍有不足，针对性设计的prompt可以在一定程度上改善这些不足。

Abstract: The increasing use of synthetic data generated by Large Language Models
(LLMs) presents both opportunities and challenges in data-driven applications.
While synthetic data provides a cost-effective, scalable alternative to
real-world data to facilitate model training, its diversity and privacy risks
remain underexplored. Focusing on text-based synthetic data, we propose a
comprehensive set of metrics to quantitatively assess the diversity (i.e.,
linguistic expression, sentiment, and user perspective), and privacy (i.e.,
re-identification risk and stylistic outliers) of synthetic datasets generated
by several state-of-the-art LLMs. Experiment results reveal significant
limitations in LLMs' capabilities in generating diverse and privacy-preserving
synthetic data. Guided by the evaluation results, a prompt-based approach is
proposed to enhance the diversity of synthetic reviews while preserving
reviewer privacy.

</details>


### [34] [TELEVAL: A Dynamic Benchmark Designed for Spoken Language Models in Chinese Interactive Scenarios](https://arxiv.org/abs/2507.18061)
*Zehan Li,Hongjie Chen,Yuxin Zhang,Jing Zhou,Xuening Wang,Hang Lv,Mengjie Du,Yaodong Song,Jie Lian,Jian Kang,Jie Li,Yongxiang Li,Zhongjiang He,Xuelong Li*

Main category: cs.CL

TL;DR: 本文提出TELEVAL基准，针对中文场景下对话型SLM进行现实互动能力评测，指出现有模型仍有待改进，框架期待促进用户体验驱动的SLM发展。


<details>
  <summary>Details</summary>
Motivation: 当前大多数口语语言模型（SLMs）的评测基准主要关注模型是否能完成类似LLMs的复杂任务，忽略了与用户真实对话场景下的互动需求。因此，现有评测不能准确反映模型在现实应用中的表现。

Method: 提出TELEVAL基准，从显性语义、超语言与隐性语义、系统能力三个维度评估SLM，并分别对文本和音频输出进行分析，尤其强调对用户语音中隐含信息的提取和回应能力，且采用真实对话格式。

Result: 使用TELEVAL进行实验后发现，现有SLMs在真实对话任务中距离理想表现仍有较大提升空间。

Conclusion: TELEVAL为SLM对话评测提供了以用户体验为中心的新框架，有助于推动对话型SLM的实用性改进。

Abstract: Spoken language models (SLMs) have seen rapid progress in recent years, along
with the development of numerous benchmarks for evaluating their performance.
However, most existing benchmarks primarily focus on evaluating whether SLMs
can perform complex tasks comparable to those tackled by large language models
(LLMs), often failing to align with how users naturally interact in real-world
conversational scenarios. In this paper, we propose TELEVAL, a dynamic
benchmark specifically designed to evaluate SLMs' effectiveness as
conversational agents in realistic Chinese interactive settings. TELEVAL
defines three evaluation dimensions: Explicit Semantics, Paralinguistic and
Implicit Semantics, and System Abilities. It adopts a dialogue format
consistent with real-world usage and evaluates text and audio outputs
separately. TELEVAL particularly focuses on the model's ability to extract
implicit cues from user speech and respond appropriately without additional
instructions. Our experiments demonstrate that despite recent progress,
existing SLMs still have considerable room for improvement in natural
conversational tasks. We hope that TELEVAL can serve as a user-centered
evaluation framework that directly reflects the user experience and contributes
to the development of more capable dialogue-oriented SLMs.

</details>


### [35] [Hybrid and Unitary Fine-Tuning of Large Language Models: Methods and Benchmarking under Resource Constraints](https://arxiv.org/abs/2507.18076)
*Haomin Qi,Zihan Dai,Chengbo Huang*

Main category: cs.CL

TL;DR: 综合评估并创新结合多种高效微调技术，显著提升大语言模型微调效率，减少资源消耗，兼具实用性与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 微调大语言模型（LLMs）因其规模和内存需求成为计算瓶颈，需要更高效的参数高效微调方法。

Method: 系统性评估了参数高效微调（PEFT）方法，包括LoRA、BOFT、LoRA-GA和uRNN，并提出一种新颖的混合策略，将BOFT的正交稳定性和LoRA-GA的梯度对齐收敛特性动态结合。通过基于每层梯度范数的自适应更新，同时首次将uRNN单元原理应用于transformer类模型以增强梯度稳定性。

Result: 混合方法在GLUE、GSM8K、MT-Bench、HumanEval四个基准测试中，针对7B至405B参数规模的模型进行了评估。结果显示，该方法在收敛效率和泛化能力上优于单独的PEFT方法，训练时间最多缩短2.1倍，内存使用减少50%，准确率接近全参数微调。

Conclusion: 提出的混合微调方法能在资源受限条件下，为大语言模型提供更高效、实用和可扩展的微调方案，适合实际部署应用。

Abstract: Fine-tuning large language models (LLMs) remains a computational bottleneck
due to their scale and memory demands. This paper presents a comprehensive
evaluation of parameter-efficient fine-tuning (PEFT) techniques, including
LoRA, BOFT, LoRA-GA, and uRNN, and introduces a novel hybrid strategy that
dynamically integrates BOFT's orthogonal stability with LoRA-GA's
gradient-aligned rapid convergence. By computing per-layer adaptive updates
guided by gradient norms, the hybrid method achieves superior convergence
efficiency and generalization across diverse tasks. We also explore, for the
first time, the adaptation of unitary RNN (uRNN) principles to
transformer-based LLMs, enhancing gradient stability through structured unitary
constraints. Empirical evaluations on four benchmarks -- GLUE, GSM8K, MT-Bench,
and HumanEval -- using models ranging from 7B to 405B parameters demonstrate
that our hybrid method consistently outperforms individual PEFT baselines,
approaching full fine-tuning accuracy while reducing resource consumption by up
to 2.1 times in training time and 50 percent in memory usage. These findings
establish the hybrid approach as a practical and scalable fine-tuning solution
for real-world deployment of LLMs under resource constraints.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [36] [In Reverie Together: Ten Years of Mathematical Discovery with a Machine Collaborator](https://arxiv.org/abs/2507.17780)
*Randy Davila,Boris Brimkov,Ryan Pepper*

Main category: cs.DM

TL;DR: 文章利用TxGraffiti自动化系统提出并验证了四个图论公开猜想，这些猜想难以解决，并鼓励人类与AI共同参与数学创新。


<details>
  <summary>Details</summary>
Motivation: 探讨自动化系统在数学创造过程中的作用，展示AI能生成具挑战性的数学猜想，并激发人类与机器共同参与数学发现。

Method: 使用自动化猜想生成系统TxGraffiti，通过自然的图不变量生成猜想，并在数百个图中进行实证验证。

Result: 提出了四个新的、经过实证验证但尚未解决的图论猜想，未能被证明真实或找到反例，展示了自动系统的创新潜力。

Conclusion: 本文未给出对提出的猜想的证明或反例，强调这些猜想仍未解决，并呼吁社区共同研究。

Abstract: We present four open conjectures in graph theory generated by the automated
conjecturing system \texttt{TxGraffiti}. Each conjecture is concise, grounded
in natural graph invariants, and empirically validated across hundreds of
graphs. Despite extensive effort, these statements remain unresolved--defying
both proof and counterexample. They are not only mathematical challenges but
creative expressions--born of symbolic pattern recognition and
mathematician-defined heuristics, refined through years of human dialogue, and
now offered back to the community as collaborative artifacts. These conjectures
invite not only formal proof, but also reflection on how machines can evoke
wonder, spark curiosity, and contribute to the raw material of discovery. By
highlighting these problems, we aim to inspire both human mathematicians and AI
systems to engage with them--not only to solve them, but to reflect on what it
means when machines participate meaningfully in the creative process of
mathematical thought.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [37] [Time for Quiescence: Modelling quiescent behaviour in testing via time-outs in timed automata](https://arxiv.org/abs/2507.18205)
*Laura Brandán Briones,Marcus Gerhold,Petra van den Bos,Mariëlle Stoelinga*

Main category: cs.FL

TL;DR: 用一个提升算子为原本不关注定时的LTS模型简便地引入超时静止判定，无需用复杂定时自动机，并能保持一致的测试判定与结果，增强MBT工程实际可用性。


<details>
  <summary>Details</summary>
Motivation: 模型基础测试（MBT）通过行为规范生成测试用例，但现实中用的简单模型如LTS不能直接处理'静止'（无外部输出）。处理静止需设定超时时间，现有方法多依赖复杂的时序自动机（TA），不利于工业应用。因此需要一种无需TA复杂性的实用定时方法，正规支持工业静止检测实践。

Method: 作者提出了一个提升算子$chi^M$，它能在不引入完整TA复杂性的情况下，为LTS模型添加定时特性。它只需引入一个时钟，用户设定一个时间界限M。输出应在时钟达到M之前发生，M时刻无输出即为静止。证明 $chi^M$ 下的测试等价性：对$ioco$一致性的实现，其提升版亦一致，且无论在标准算法前后应用$chi^M$，测试集相同，判定结论一致。

Result: 1. 实现$ioco$一致性当且仅当其提升后$tioco_M$一致。2. 算子$chi^M$应用于测试生成算法前后不影响测试结果。3. 提升后的TA测试集与原LTS测试集对每个实现给出相同判定。

Conclusion: 提出了一种简洁有效的方式，为LTS模型增加现实开发常用的超时静止判断能力，无需用到复杂的定时自动机，对工业MBT实践推动意义大。同时保证了等价判定与测试集一致性。

Abstract: Model-based testing (MBT) derives test suites from a behavioural
specification of the system under test. In practice, engineers favour simple
models, such as labelled transition systems (LTSs). However, to deal with
quiescence - the absence of observable output - in practice, a time-out needs
to be set to conclude observation of quiescence. Timed MBT exists, but it
typically relies on the full arsenal of timed automata (TA).
  We present a lifting operator $\chi^{\scriptstyle M}\!$ that adds timing
without the TA overhead: given an LTS, $\chi^{\scriptstyle M}\!$ introduces a
single clock for a user chosen time bound $M>0$ to declare quiescence. In the
timed automaton, the clock is used to model that outputs should happen before
the clock reaches value $M$, while quiescence occurs exactly at time $M$. This
way we provide a formal basis for the industrial practice of choosing a
time-out to conclude quiescence. Our contributions are threefold: (1) an
implementation conforms under $\mathbf{ioco}$ if and only if its lifted version
conforms under timed $\mathbf{tioco_M}$ (2) applying $\chi^{\scriptstyle M}\!$
before or after the standard $\mathbf{ioco}$ test-generation algorithm yields
the same set of tests, and (3) the lifted TA test suite and the original LTS
test suite deliver identical verdicts for every implementation.

</details>
