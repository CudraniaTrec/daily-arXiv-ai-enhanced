<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 1]
- [cs.CL](#cs.CL) [Total: 4]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [A Service Suite for Specifying Digital Twins for Industry 5.0](https://arxiv.org/abs/2511.07506)
*Izaque Esteves,Regina Braga,José Maria David,Victor Stroele*

Main category: cs.SE

TL;DR: 该论文提出并验证了DT-Create服务套件，可通过智能、语义和自适应方法实现数字孪生在预测性维护中的高效决策支持，具备实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 预测性维护面临的主要挑战之一是如何基于数据做出敏捷且准确的决策。数字孪生（DTs）和智能处理技术可丰富信息，支持决策。

Method: 本论文提出并规范了一套专用于数字孪生（DTs）设计的服务套件DT-Create，侧重于预测性维护中的决策支持。DT-Create套件基于智能技术、语义数据处理和自适应设计，通过设计科学研究（DSR）方法，分两轮开发并通过案例研究进行评估。

Result: DT-Create能够在以下方面有效支持DTs的规范：(i) 传感器数据的采集、存储和智能处理；(ii) 通过机器学习和本体实现信息丰富；(iii) 利用智能技术选择与数据集匹配的预测模型；(iv) 支持决策和系统自适应。

Conclusion: 实验结果表明DT-Create在数字孪生规范化与预测性维护决策支持方面具有可行性和有效性。

Abstract: One of the challenges of predictive maintenance is making decisions based on data in an agile and assertive way. Connected sensors and operational data favor intelligent processing techniques to enrich information and enable decision-making. Digital Twins (DTs) can be used to process information and support decision-making. DTs are a real-time representation of physical machines and generate data that predictive maintenance can use to make assertive and quick decisions. The main contribution of this work is the specification of a suite of services for specifying DTs, called DT-Create, focused on decision support in predictive maintenance. DT-Create suite is based on intelligent techniques, semantic data processing, and self-adaptation. This suite was developed using the Design Science Research (DSR) methodology through two development cycles and evaluated through case studies. The results demonstrate the feasibility of using DT-Create in specifying DTs considering the following aspects: (i) collection, storage, and intelligent processing of data generated by sensors, (ii) enrichment of information through machine learning and ontologies, (iii) use of intelligent techniques to select predictive models that adhere to the available data set, and (iv) decision support and self-adaptation.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [2] [A Preliminary Study of RAG for Taiwanese Historical Archives](https://arxiv.org/abs/2511.07445)
*Claire Lin,Bo-Han Feng,Xuanjun Chen,Te-Lun Yang,Hung-yi Lee,Jyh-Shing Roger Jang*

Main category: cs.CL

TL;DR: 论文首次将RAG应用于台湾历史档案，发现早期整合元数据能提升系统表现，但RAG仍存在生成幻觉及处理复杂历史查询的挑战。


<details>
  <summary>Details</summary>
Motivation: RAG方法已在知识密集任务中展现潜力，但在台湾历史文献领域尚少相关研究。本论文旨在填补这一空白，探索RAG在台湾历史档案中的应用效果。

Method: 针对两个繁体中文历史数据集（热兰遮城历史档案与台湾省议会公报）及其开放性查询，搭建RAG流程，并系统分析查询特征和元数据整合策略对检索及生成效果的影响。

Result: 早期整合元数据不仅提升了检索和答案准确率，还揭示了RAG在生成中易产生虚假信息及应对多跳、时间性历史查询上的挑战。

Conclusion: 证明了元数据在早期整合能增强RAG系统在历史文档上的表现，但仍需应对生成幻觉和复杂历史问题处理等难题。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising approach for knowledge-intensive tasks. However, few studies have examined RAG for Taiwanese Historical Archives. In this paper, we present an initial study of a RAG pipeline applied to two historical Traditional Chinese datasets, Fort Zeelandia and the Taiwan Provincial Council Gazette, along with their corresponding open-ended query sets. We systematically investigate the effects of query characteristics and metadata integration strategies on retrieval quality, answer generation, and the performance of the overall system. The results show that early-stage metadata integration enhances both retrieval and answer accuracy while also revealing persistent challenges for RAG systems, including hallucinations during generation and difficulties in handling temporal or multi-hop historical queries.

</details>


### [3] [Large Language Models for Scientific Idea Generation: A Creativity-Centered Survey](https://arxiv.org/abs/2511.07448)
*Fatemeh Shahhosseini,Arash Marioriyad,Ali Momen,Mahdieh Soleymani Baghshah,Mohammad Hossein Rohban,Shaghayegh Haghjooy Javanmard*

Main category: cs.CL

TL;DR: 本文综述了大语言模型在科学创意生成中的方法，分为五大类，并用两个创造力框架进行解读，为提升LLM在科学发现中的作用和应用提出了方向。


<details>
  <summary>Details</summary>
Motivation: 科学领域的创新性想法推动了人类进步，但科学创意不仅要求新颖性，还需实证可靠性。虽然大语言模型（LLMs）在生成科学创意方面展现出潜力，具有直觉和合理性，但其创造力表现并不稳定，相关理解也较为匮乏。本文旨在梳理和总结LLM推动科学思维生成的方法，为提高其创造力和科学性提供平台。

Method: 本文对现有LLM驱动科学创意生成的方法进行系统回顾，将其归类为五大类：外部知识增强、基于提示的分布引导、推理时扩展、多智能体协作和参数层级适配。作者采用Boden的三类创造力框架（组合性、探索性和变革性）分析各方法生成创意的水平，并用Rhodes的4Ps框架（个体、过程、环境和产品）定位各方法侧重的创造性来源。

Result: 本文对方法与创造力理论进行了对齐，理清了LLM驱动科学思维生成领域的方法现状及分类，并分析了各类方法在科学创新性与合理性之间的平衡点。

Conclusion: 通过系统梳理和理论框架分析，本文为LLM在科学创新应用的可靠性、系统性和变革性发展提供了方向和建议。

Abstract: Scientific idea generation lies at the heart of scientific discovery and has driven human progress-whether by solving unsolved problems or proposing novel hypotheses to explain unknown phenomena. Unlike standard scientific reasoning or general creative generation, idea generation in science is a multi-objective and open-ended task, where the novelty of a contribution is as essential as its empirical soundness. Large language models (LLMs) have recently emerged as promising generators of scientific ideas, capable of producing coherent and factual outputs with surprising intuition and acceptable reasoning, yet their creative capacity remains inconsistent and poorly understood. This survey provides a structured synthesis of methods for LLM-driven scientific ideation, examining how different approaches balance creativity with scientific soundness. We categorize existing methods into five complementary families: External knowledge augmentation, Prompt-based distributional steering, Inference-time scaling, Multi-agent collaboration, and Parameter-level adaptation. To interpret their contributions, we employ two complementary frameworks: Boden's taxonomy of Combinatorial, Exploratory and Transformational creativity to characterize the level of ideas each family expected to generate, and Rhodes' 4Ps framework-Person, Process, Press, and Product-to locate the aspect or source of creativity that each method emphasizes. By aligning methodological advances with creativity frameworks, this survey clarifies the state of the field and outlines key directions toward reliable, systematic, and transformative applications of LLMs in scientific discovery.

</details>


### [4] [GRIP: In-Parameter Graph Reasoning through Fine-Tuning Large Language Models](https://arxiv.org/abs/2511.07457)
*Jiarui Feng,Donghong Cai,Yixin Chen,Muhan Zhang*

Main category: cs.CL

TL;DR: 本文提出GRIP框架，通过LoRA轻量级参数和微调任务，使LLM无需原始图结构即可处理多种图相关任务，实验表明方法有效且高效。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）虽然在处理文本序列和多任务泛化方面表现出色，但在建模结构化数据（如知识图谱或网页数据）方面仍面临挑战。现有方法要么将图结构转为文本序列，导致token数量激增，对大规模图数据应用不现实；要么通过额外模块编码图为固定大小的token表示，但需要大规模图文本语料后训练，并且对齐难度大，效果往往不佳。

Method: 提出了GRIP框架，借鉴in-parameter知识注入思想，通过精心设计的微调任务，让LLM将复杂的图关系信息内化到轻量化的LoRA参数中。这样，模型在推理时无需访问原始图结构即可执行多种图相关任务。

Result: 通过多项基准测试，GRIP在有效性和效率上获得了验证，表现优异。

Conclusion: GRIP框架能够高效内化图结构知识，不需要图结构辅助即可让LLM适应并处理多种图任务，有效解决了结构数据与大语言模型融合的难题。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in modeling sequential textual data and generalizing across diverse tasks. However, adapting LLMs to effectively handle structural data, such as knowledge graphs or web data, remains a challenging problem. Some approaches adopt complex strategies to convert graphs into text sequences, resulting in significant token overhead and rendering them impractical for large-scale graphs. Others introduce additional modules to encode graphs into fixed-size token representations for LLMs. However, these methods typically require large-scale post-training on graph-text corpus and complex alignment procedures, yet often yield sub-optimal results due to poor modality alignment. Inspired by in-parameter knowledge injection for test-time adaptation of LLMs, we propose GRIP, a novel framework that equips LLMs with the ability to internalize complex relational information from graphs through carefully designed fine-tuning tasks. This knowledge is efficiently stored within lightweight LoRA parameters, enabling the fine-tuned LLM to perform a wide range of graph-related tasks without requiring access to the original graph at inference time. Extensive experiments across multiple benchmarks validate the effectiveness and efficiency of our approach.

</details>


### [5] [REFLEX: Reference-Free Evaluation of Log Summarization via Large Language Model Judgment](https://arxiv.org/abs/2511.07458)
*Priyanka Mudgal*

Main category: cs.CL

TL;DR: 本文提出REFLEX，一种基于LLM判断的无参考日志摘要评估指标，在没有参考数据或人工标注的情况下，能有效评估摘要质量，比传统ROUGE和BLEU更有区分力，适用于实际应用。


<details>
  <summary>Details</summary>
Motivation: 现有日志摘要评估受限于高质量参考摘要的缺乏和ROUGE、BLEU等指标对词汇重叠的依赖，导致评估效果有限。

Method: 采用大语言模型（LLM）作为零样本评估者，从相关性、信息性和连贯性等多个维度评价摘要，无需人工标注或黄金标准参考。

Result: REFLEX在多个日志摘要数据集上表现出稳定、可解释和细粒度的评估能力，并优于传统指标。

Conclusion: REFLEX是一种无参考的日志摘要评估指标，能够稳定且细致地区分模型输出，比传统指标更有效。

Abstract: Evaluating log summarization systems is challenging due to the lack of high-quality reference summaries and the limitations of existing metrics like ROUGE and BLEU, which depend on surface-level lexical overlap. We introduce REFLEX, a reference-free evaluation metric for log summarization based on large language model (LLM) judgment. REFLEX uses LLMs as zero-shot evaluators to assess summary quality along dimensions such as relevance, informativeness, and coherence, without requiring gold-standard references or human annotations. We show that REFLEX produces stable, interpretable, and fine-grained evaluations across multiple log summarization dataset, and more effectively distinguishes model outputs than traditional metrics. REFLEX provides a scalable alternative for evaluating log summaries in real-world settings where reference data is scarce or unavailable.

</details>
