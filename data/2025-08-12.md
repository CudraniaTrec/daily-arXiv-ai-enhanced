<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 15]
- [cs.LO](#cs.LO) [Total: 5]
- [cs.CL](#cs.CL) [Total: 25]
- [cs.DM](#cs.DM) [Total: 1]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Checking Consistency of Event-driven Traces](https://arxiv.org/abs/2508.07855)
*Parosh Aziz Abdulla,Mohamed Faouzi Atig,R. Govind,Samuel Grahn,Ramanathan S. Thinniyam*

Main category: cs.PL

TL;DR: 本文提出事件驱动程序的一致性公理化语义，理论上证明了其与操作语义的等价性，并将执行一致性判定转化为公理化判定，分析得出问题NP-完全，但在无嵌套post时可多项式解决，实验验证了方法的实用性。


<details>
  <summary>Details</summary>
Motivation: 事件驱动编程在并发程序中非常常见，但如何验证程序执行的合法性（即执行是否与语义一致）仍然是一个核心难题。现有方法大多依赖操作语义进行分析，缺乏通用的公理化框架。本文希望通过公理化的视角更本质地刻画一致性问题及其复杂性。

Method: 本文提出了一套事件驱动程序的公理化语义（基于trace/execution graph），并严格证明了其与操作语义的等价性。基于该语义，将执行一致性判定问题形式化为公理化判断问题，并分析了其计算复杂性。此外，提出了在无嵌套post的情况下的多项式时间判定算法，并结合原型工具在一系列基准上验证了方法有效性。

Result: 一致性判定问题在一般情况下是NP-完全的，即使限制handler线程数。但在不允许嵌套消息投递时，可以多项式时间解决。此外，原型工具在实验中能有效处理多种基准案例。

Conclusion: 本文系统性地提出了事件驱动程序的一般公理化语义及其在执行一致性判定中的应用，不仅理论上阐明了问题的复杂性边界，还为实际程序分析提供了有效的判定工具。

Abstract: Event-driven programming is a popular paradigm where the flow of execution is
controlled by two features: (1) shared memory and (2) sending and receiving of
messages between multiple handler threads (just called handler). Each handler
has a mailbox (modelled as a queue) for receiving messages, with the constraint
that the handler processes its messages sequentially. Executions of messages by
different handlers may be interleaved. A central problem in this setting is
checking whether a candidate execution is consistent with the semantics of
event-driven programs. In this paper, we propose an axiomatic semantics for
eventdriven programs based on the standard notion of traces (also known as
execution graphs). We prove the equivalence of axiomatic and operational
semantics. This allows us to rephrase the consistency problem axiomatically,
resulting in the event-driven consistency problem: checking whether a given
trace is consistent. We analyze the computational complexity of this problem
and show that it is NP-complete, even when the number of handler threads is
bounded. We then identify a tractable fragment: in the absence of nested
posting, where handlers do not post new messages while processing a message,
consistency checking can be performed in polynomial time. Finally, we implement
our approach in a prototype tool and report on experimental results on a wide
range of benchmarks.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [Refactoring-Aware Patch Integration Across Structurally Divergent Java Forks](https://arxiv.org/abs/2508.06718)
*Daniel Ogenrwot,John Businge*

Main category: cs.SE

TL;DR: 论文针对 GitHub 上长期维护的代码变体间的补丁集成难题，提出 Refactoring 感知的 RePatch 系统，可大幅提升跨变体补丁传递成功率，凸显语义推理在实际工程中的必要性。


<details>
  <summary>Details</summary>
Motivation: Github 上存在部分长期维护且独立发展的代码分支（变体），这些变体之间由于重构等原因导致结构漂移，传统基于语法的补丁集成方式面临巨大挑战，因此亟需新方法来应对补丁集成失败的问题。

Method: 提出并实现了 RePatch 系统，通过逆转重构和重播变换，支持在 Java 仓库中变体间的补丁传递，扩展了原有 RefMerge 框架以适配非对称补丁集成。

Result: 在 478 个 bug-fix pull request 的评测中，Git 的 cherry-pick 方法因结构对齐不一致导致 64.4% 失败，而 RePatch 系统能够成功集成其中 52.8% 原本失败的补丁，显著提升了变体间补丁传播的效果。

Conclusion: 语法基础工具在管理代码变体时存在局限性，需要通过语义推理提高补丁集成的有效性。

Abstract: While most forks on platforms like GitHub are short-lived and used for social
collaboration, a smaller but impactful subset evolve into long-lived forks,
referred to here as variants, that maintain independent development
trajectories. Integrating bug-fix patches across such divergent variants poses
challenges due to structural drift, including refactorings that rename,
relocate, or reorganize code elements and obscure semantic correspondence. This
paper presents an empirical study of patch integration failures in 14 divergent
pair of variants and introduces RePatch, a refactoring-aware integration system
for Java repositories. RePatch extends the RefMerge framework, originally
designed for symmetric merges, by supporting asymmetric patch transfer. RePatch
inverts refactorings in both the source and target to realign the patch
context, applies the patch, and replays the transformations to preserve the
intent of the variant. In our evaluation of 478 bug-fix pull requests, Git
cherry-pick fails in 64.4% of cases due to structural misalignments, while
RePatch successfully integrates 52.8% of the previously failing patches. These
results highlight the limitations of syntax-based tools and the need for
semantic reasoning in variant-aware patch propagation.

</details>


### [3] [Quo Vadis, Code Review? Exploring the Future of Code Review](https://arxiv.org/abs/2508.06879)
*Michael Dorner,Andreas Bauer,Darja Šmite,Lukas Thode,Daniel Mendez,Ricardo Britto,Stephan Lukasczyk,Ehsan Zabardast,Michael Kormann*

Main category: cs.SE

TL;DR: 本文调查了当前业界对代码审查的认知及未来发展预期，分析了这些变革可能带来的长期风险，对代码审查实践的未来演进提出了警示与建议。


<details>
  <summary>Details</summary>
Motivation: 代码审查作为协同软件工程的核心实践，已有多年历史。本文旨在探究当前从业者对代码审查的反思以及他们对未来该实践变化的预期。

Method: 通过调查、访谈或数据分析等方式收集实际从业者对代码审查现状及未来发展的观点。

Result: 揭示了业界对代码审查的现状反思和对未来变化的预期，并总结这些变化可能带来的长期风险。

Conclusion: 研究不仅展现了代码审查在业界的认知和发展趋势，还提醒相关方注意未来演变可能导致的风险，促进更好地引导实践演进。

Abstract: Code review has long been a core practice in collaborative software
engineering. In this research, we explore how practitioners reflect on code
review today and what changes they anticipate in the near future. We then
discuss the potential long-term risks of these anticipated changes for the
evolution of code review and its role in collaborative software engineering.

</details>


### [4] [Multi-Modal Requirements Data-based Acceptance Criteria Generation using LLMs](https://arxiv.org/abs/2508.06888)
*Fanyu Wang,Chetan Arora,Yonghui Liu,Kaicheng Huang,Chakkrit Tantithamthavorn,Aldeida Aleti,Dishan Sambathkumar,David Lo*

Main category: cs.SE

TL;DR: 本研究提出利用多模态RAG方法结合文字和UI信息，自动生成准确、全面的验收标准。案例研究证实，该方法有效提升相关性和正确性，减少人工参与，具有行业推广价值，实现软件验证流程智能化。


<details>
  <summary>Details</summary>
Motivation: 在软件开发中，制定准确、全面且明确的验收标准十分重要，但由于依赖领域知识及视觉语境，现有基于文字的需求描述很难满足复杂的用户界面应用场景。人工编写验收标准不仅繁琐，还容易遗漏关键信息，因此亟需自动化、智能化的解决方案。

Method: 提出RAGcceptance M2RE方法，利用检索增强生成（RAG）技术，将文字文档与视觉UI信息等多模态需求数据结合，自动生成验收标准，并在实际教育类软件系统中开展案例研究验证其有效性。

Result: 融合多模态信息能显著提升生成的验收标准的相关性、正确性和易理解性；业界使用者评价显示该方法可有效降低人工工作量、更精准捕捉利益相关方意图，并补充领域专家可能遗漏的重要标准。

Conclusion: 多模态RAG技术在优化软件验收标准制定、提升开发效率、降低人工成本方面具有实际和行业应用潜力，并推动软件验证流程的自动化和智能化。

Abstract: Acceptance criteria (ACs) play a critical role in software development by
clearly defining the conditions under which a software feature satisfies
stakeholder expectations. However, manually creating accurate, comprehensive,
and unambiguous acceptance criteria is challenging, particularly in user
interface-intensive applications, due to the reliance on domain-specific
knowledge and visual context that is not always captured by textual
requirements alone. To address these challenges, we propose RAGcceptance M2RE,
a novel approach that leverages Retrieval-Augmented Generation (RAG) to
generate acceptance criteria from multi-modal requirements data, including both
textual documentation and visual UI information. We systematically evaluated
our approach in an industrial case study involving an education-focused
software system used by approximately 100,000 users. The results indicate that
integrating multi-modal information significantly enhances the relevance,
correctness, and comprehensibility of the generated ACs. Moreover, practitioner
evaluations confirm that our approach effectively reduces manual effort,
captures nuanced stakeholder intent, and provides valuable criteria that domain
experts may overlook, demonstrating practical utility and significant potential
for industry adoption. This research underscores the potential of multi-modal
RAG techniques in streamlining software validation processes and improving
development efficiency. We also make our implementation and a dataset
available.

</details>


### [5] [Integrating Rules and Semantics for LLM-Based C-to-Rust Translation](https://arxiv.org/abs/2508.06926)
*Feng Luo,Kexing Ji,Cuiyun Gao,Shuzheng Gao,Jia Feng,Kui Liu,Xin Xia,Michael R. Lyu*

Main category: cs.SE

TL;DR: 本文提出IRENE框架，通过规则检索、结构化摘要及错误迭代，大幅提升了LLM驱动C转Rust代码的准确性及安全性。


<details>
  <summary>Details</summary>
Motivation: 传统的C代码转换到Rust以提升内存安全，但使用静态规则方法覆盖面有限，LLM方法虽能减少不安全代码却存在语法和语义一致性问题。

Method: 提出IRENE框架，包含：1）基于规则的样例检索模块，利用静态分析器生成规则提升Rust规则处理；2）结构化摘要模块，引导LLM更好理解C代码语义；3）错误驱动翻译模块，利用编译器诊断迭代优化翻译。

Result: 在两个数据集（xCodeEval公共集与HW-Bench工业集）及八种LLM上进行评估，关注翻译准确性与安全性。

Conclusion: IRENE能融合规则与语义，显著提升自动C到Rust代码翻译的准确性和安全性。

Abstract: Automated translation of legacy C code into Rust aims to ensure memory safety
while reducing the burden of manual migration. Early approaches in code
translation rely on static rule-based methods, but they suffer from limited
coverage due to dependence on predefined rule patterns. Recent works regard the
task as a sequence-to-sequence problem by leveraging large language models
(LLMs). Although these LLM-based methods are capable of reducing unsafe code
blocks, the translated code often exhibits issues in following Rust rules and
maintaining semantic consistency. On one hand, existing methods adopt a direct
prompting strategy to translate the C code, which struggles to accommodate the
syntactic rules between C and Rust. On the other hand, this strategy makes it
difficult for LLMs to accurately capture the semantics of complex code. To
address these challenges, we propose IRENE, an LLM-based framework that
Integrates RulEs aNd sEmantics to enhance translation. IRENE consists of three
modules: 1) a rule-augmented retrieval module that selects relevant translation
examples based on rules generated from a static analyzer developed by us,
thereby improving the handling of Rust rules; 2) a structured summarization
module that produces a structured summary for guiding LLMs to enhance the
semantic understanding of C code; 3) an error-driven translation module that
leverages compiler diagnostics to iteratively refine translations. We evaluate
IRENE on two datasets (xCodeEval, a public dataset, and HW-Bench, an industrial
dataset provided by Huawei) and eight LLMs, focusing on translation accuracy
and safety.

</details>


### [6] [When Prompt Engineering Meets Software Engineering: CNL-P as Natural and Robust "APIs'' for Human-AI Interaction](https://arxiv.org/abs/2508.06942)
*Zhenchang Xing,Yang Liu,Zhuo Cheng,Qing Huang,Dehai Zhao,Daniel Sun,Chenhua Liu*

Main category: cs.SE

TL;DR: 本文提出CNL-P方法，将提示工程与软件工程结合，通过模板化和规范化提升大模型提示质量，开发相关工具降低用户门槛，实验证明有效，可为自然语言新编程范式提供基础。


<details>
  <summary>Details</summary>
Motivation: 随着大模型能力提升，自然语言提示作为与大模型交互的“API”，其质量直接影响模型输出质量。当前虽然有提示工程最佳实践，但自然语言仍有歧义，影响一致性和准确性。因此需要进一步提升提示规范性和表达准确性。

Method: 提出Controlled NL for Prompt (CNL-P)方法，结合提示工程和软件工程原则，构建语法和语义规范化的模板，并开发自然语言转CNL-P转换工具和CNL-P提示lint工具，首次在自然语言静态分析。

Result: 实验证明，CNL-P方法能提升大模型输出质量，使提示更加一致和高质量。工具有效降低用户学习门槛，实现提示语法和语义校验。

Conclusion: CNL-P方法有望成为连接提示工程与传统软件工程的新桥梁，为以自然语言为中心的新编程范式奠定基础。

Abstract: With the growing capabilities of large language models (LLMs), they are
increasingly applied in areas like intelligent customer service, code
generation, and knowledge management. Natural language (NL) prompts act as the
``APIs'' for human-LLM interaction. To improve prompt quality, best practices
for prompt engineering (PE) have been developed, including writing guidelines
and templates. Building on this, we propose Controlled NL for Prompt (CNL-P),
which not only incorporates PE best practices but also draws on key principles
from software engineering (SE). CNL-P introduces precise grammar structures and
strict semantic norms, further eliminating NL's ambiguity, allowing for a
declarative but structured and accurate expression of user intent. This helps
LLMs better interpret and execute the prompts, leading to more consistent and
higher-quality outputs. We also introduce an NL2CNL-P conversion tool based on
LLMs, enabling users to write prompts in NL, which are then transformed into
CNL-P format, thus lowering the learning curve of CNL-P. In particular, we
develop a linting tool that checks CNL-P prompts for syntactic and semantic
accuracy, applying static analysis techniques to NL for the first time.
Extensive experiments demonstrate that CNL-P enhances the quality of LLM
responses through the novel and organic synergy of PE and SE. We believe that
CNL-P can bridge the gap between emerging PE and traditional SE, laying the
foundation for a new programming paradigm centered around NL.

</details>


### [7] [An Empirical Study on Method-Level Performance Evolution in Open-Source Java Projects](https://arxiv.org/abs/2508.07084)
*Kaveh Shahedi,Nana Gyambrah,Heng Li,Maxime Lamothe,Foutse Khomh*

Main category: cs.SE

TL;DR: 论文对Java开源项目的方法级代码变更与性能演化做了大规模量化分析，发现三成以上更改影响性能，且常常被低估。建议将自动化性能测试集成到持续集成流程，提高代码质量和可靠性。


<details>
  <summary>Details</summary>
Motivation: 虽然软件性能非常重要，但我们对于方法级代码修改导致的性能变化还缺乏细致的实证研究。开发者对哪些变更可能影响性能有直觉判断，但这些判断缺乏微观层面的证据支持。本文旨在精细量化方法级变更对性能的影响。

Method: 对15个成熟的开源Java项目进行大规模实证分析，选取739次提交、共1499个方法级代码更改。通过JMH基准测试精确测量性能变化，并采用字节码插装收集方法执行指标，结合统计分析探讨性能变化的显著性和幅度，并系统分析性能随时间变化、变更类型、开发者和代码复杂度、以及领域和项目体量等因素。

Result: 32.7%的方法级变更导致了可测量的性能影响，其中性能回退的发生概率是性能提升的1.3倍。不同类型的代码变更，在性能影响分布上并无显著差异。算法变更有最高的性能提升潜力，但同时也带来较高的回退风险。资深开发者的代码更稳定，极端变化较少；复杂度高的代码变更更容易引发性能回退。小型web服务项目性能最为不稳定。

Conclusion: 方法级代码变更对性能有非可忽视的影响，且常被直觉低估。不同变更类型造成的性能影响没有显著模式，建议开发流程中引入自动化性能测试以减少回退风险和盲区。

Abstract: Performance is a critical quality attribute in software development, yet the
impact of method-level code changes on performance evolution remains poorly
understood. While developers often make intuitive assumptions about which types
of modifications are likely to cause performance regressions or improvements,
these beliefs lack empirical validation at a fine-grained level. We conducted a
large-scale empirical study analyzing performance evolution in 15 mature
open-source Java projects hosted on GitHub. Our analysis encompassed 739
commits containing 1,499 method-level code changes, using Java Microbenchmark
Harness (JMH) for precise performance measurement and rigorous statistical
analysis to quantify both the significance and magnitude of performance
variations. We employed bytecode instrumentation to capture method-specific
execution metrics and systematically analyzed four key aspects: temporal
performance patterns, code change type correlations, developer and complexity
factors, and domain-size interactions. Our findings reveal that 32.7% of
method-level changes result in measurable performance impacts, with regressions
occurring 1.3 times more frequently than improvements. Contrary to conventional
wisdom, we found no significant differences in performance impact distributions
across code change categories, challenging risk-stratified development
strategies. Algorithmic changes demonstrate the highest improvement potential
but carry substantial regression risk. Senior developers produce more stable
changes with fewer extreme variations, while code complexity correlates with
increased regression likelihood. Domain-size interactions reveal significant
patterns, with web server + small projects exhibiting the highest performance
instability. Our study provides empirical evidence for integrating automated
performance testing into continuous integration pipelines.

</details>


### [8] [From Noise to Knowledge: Interactive Summaries for Developer Alerts](https://arxiv.org/abs/2508.07169)
*Burak Yetiştiren,Hong Jin Kang,Miryung Kim*

Main category: cs.SE

TL;DR: CLARITY工具通过主动学习和可定制的分组规则，帮助程序员更快、更高效地理解和归纳代码警告，提高了警告分析的速度与信心，显著减少交互成本。


<details>
  <summary>Details</summary>
Motivation: 程序员在使用bug查找工具时，通常需要逐条审核工具报告的警告，这一过程耗时且易造成认知负担。发现重复性主题与关系有助于增强理解和推理过程，激发了本文提出新方法以辅助警告归纳与解析的动机。

Method: 提出了CLARITY工具，通过用户交互反馈，自动推断与归纳可定制的分组规则，将结构相似的警告（如包容关系、子类型、调用方法、访问字段和表达式）归为一类。用户反馈（标记警告为有趣或无趣）直接影响分组规则生成。

Result: 在Infer和SpotBugs这两个主流Java工具生成的警告及两个成熟Java项目上测试CLARITY。14名参与者的对比实验中，用户借助CLARITY更快、更有信心地分析出相似无趣警告的根因。同时，不同用户期望的分组方式差异明显，验证了定制化归纳的必要性。模拟实验表明，基于规则的反馈平均只需11.8次交互（对比无规则反馈需17.8次），即可使推断规则与用户偏好一致。

Conclusion: CLARITY通过主动学习和规则归纳的方法显著提升了工具警告解释和感知效率，降低了交互成本，支持个性化和高效的警告归纳过程。此成果为程序员高效管理和理解自动化警告提供了有力辅助。

Abstract: Programmers using bug-finding tools often review their reported warnings one
by one. Based on the insight that identifying recurring themes and
relationships can enhance the cognitive process of sensemaking, we propose
CLARITY, which supports interpreting tool-generated warnings through
interactive inquiry. CLARITY derives summary rules for custom grouping of
related warnings with active feedback. As users mark warnings as interesting or
uninteresting, CLARITY's rule inference algorithm surfaces common symptoms,
highlighting structural similarities in containment, subtyping, invoked
methods, accessed fields, and expressions.
  We demonstrate CLARITY on Infer and SpotBugs warnings across two mature Java
projects. In a within-subject user study with 14 participants, users
articulated root causes for similar uninteresting warnings faster and with more
confidence using CLARITY. We observed significant individual variation in
desired grouping, reinforcing the need for customizable sensemaking. Simulation
shows that with rule-level feedback, only 11.8 interactions are needed on
average to align all inferred rules with a simulated user's labels (vs. 17.8
without). Our evaluation suggests that CLARITY's active learning-based
summarization enhances interactive warning sensemaking.

</details>


### [9] [Dynamic Benchmark Construction for Evaluating Large Language Models on Real-World Codes](https://arxiv.org/abs/2508.07180)
*Zhe Zhang,Runlin Liu,Aishan Liu,Xingyu Liu,Xiang Gao,Hailong Sun*

Main category: cs.SE

TL;DR: 本文提出CODE2BENCH，通过自动化和依赖分析方法，动态生成数据污染可控、严谨性强的代码生成基准，并构建了涵盖880个Python项目的CODE2BENCH-2505，实验证明主流LLMs在复杂和跨语言任务上表现不足。


<details>
  <summary>Details</summary>
Motivation: 现有用于大型语言模型（LLMs）代码生成任务的基准测试存在数据污染和测试严谨性不足的问题，不能有效反映模型在真实场景下的不足。

Method: 提出了CODE2BENCH，一套动态生成、抗污染的代码生成基准测试流水线。其创新点包括：（1）自动动态数据获取机制，定期从GitHub收集最新代码，减少训练集污染；（2）基于Scope Graph的依赖分析，将函数有结构性地分类为依赖程度受控的基准样本（包括完全自包含SC和弱自包含WSC）；（3）基于性质的自动化测试生成（PBT），确保测试覆盖率和评测严谨性。

Result: 借助上述方法，构建了CODE2BENCH-2505基准，覆盖880个Python真实开源项目、共1163个任务，并实现100%分支测试覆盖率。对16种主流LLMs的评测显示：模型在需要复杂逻辑和跨语言迁移的SC任务上普遍表现较弱，而在允许使用库的WSC类型任务上表现相对更好。

Conclusion: CODE2BENCH提出了一种抗污染、动态、与语言无关的基准构建方法，并首次为LLMs在真实软件开发环境下的代码生成提供了全面、现实且严谨的评测方案。其成果为推动LLMs在工程化场景中的发展奠定了坚实基础。

Abstract: As large language models LLMs) become increasingly integrated into software
development workflows, rigorously evaluating their performance on complex,
real-world code generation tasks has become essential. However, existing
benchmarks often suffer from data contamination and limited test rigor,
constraining their ability to reveal model failures effectively. To address
these, we present CODE2BENCH, a end-to-end pipeline for dynamically
constructing robust and contamination-resistant benchmarks from real-world
GitHub repositories. Specifically, CODE2BENCH introduces three key innovations:
(1) Automated Dynamism, achieved through periodic ingestion of recent code to
minimize training data contamination; (2) Scope Graph-based dependency
analysis, which enables structured classification of functions into benchmark
instances with controlled dependency levels (distinguishing between
Self-Contained (SC) tasks for cross-language evaluation and Weakly
Self-Contained (WSC) tasks involving permitted library usage); and (3)
Property-Based Testing (PBT) for the automated synthesis of rigorous test
suites to enable thorough functional verification. Using this pipeline, we
construct CODE2BENCH-2505, the first benchmark derived from 880 recent Python
projects spanning diverse domains, comprising 1,163 code generation tasks with
100% average branch coverage on ground-truth implementations. Extensive
evaluation of 16 LLMs using CODE2BENCH-2505 reveals that models consistently
struggle with SC tasks requiring complex, non-standard logic and cross-language
transfer, while showing relatively stronger performance on WSC tasks in Python.
Our work introduces a contamination-resistant, language-agnostic methodology
for dynamic benchmark construction, offering a principled foundation for the
comprehensive and realistic evaluation of LLMs on real-world software
development tasks.

</details>


### [10] [TraceLens: Question-Driven Debugging for Taint Flow Understanding](https://arxiv.org/abs/2508.07198)
*Burak Yetiştiren,Hong Jin Kang,Miryung Kim*

Main category: cs.SE

TL;DR: 现有污点分析工具难以调试和理解复杂数据流。TraceLens用问答式界面帮助用户探索和推理数据流，实验显示其准确率和用户体验均优于传统工具。


<details>
  <summary>Details</summary>
Motivation: 污点分析是一种追踪潜在危险数据流的安全分析技术，但现有工具缺乏用户友好的调试功能，难以解读数据流异常和缺失背后的原因，并不便于全局理解多源多汇之间的互联影响。

Method: 提出TraceLens，一种面向终端用户、以问答式交互为核心的污点分析调试界面，支持用户提出why、why-not、what-if等问题，从而探究可疑数据流的源头与路径、预期数据流的缺失、以及第三方库模型对整体连接性的影响，同时利用推测性分析辅助理解不同配置假设下的结果变化。

Result: 通过12人用户实验，使用TraceLens的参与者在识别相关数据流准确率方面比使用CodeQL提升了21%，心理负担降低了45%（NASA-TLX），且用户对结果的信心显著提升。

Conclusion: TraceLens通过创新的问答式调试方式，有效提升了污点分析的准确性、用户体验和全局理解，有望推动安全分析工具的可用性进步。

Abstract: Taint analysis is a security analysis technique used to track the flow of
potentially dangerous data through an application and its dependent libraries.
Investigating why certain unexpected flows appear and why expected flows are
missing is an important sensemaking process during end-user taint analysis.
Existing taint analysis tools often do not provide this end-user debugging
capability, where developers can ask why, why-not, and what-if questions about
dataflows and reason about the impact of configuring sources and sinks, and
models of 3rd-party libraries that abstract permissible and impermissible data
flows. Furthermore, a tree-view or a list-view used in existing
taint-analyzer's visualization makes it difficult to reason about the global
impact on connectivity between multiple sources and sinks.
  Inspired by the insight that sensemaking tool-generated results can be
significantly improved by a QA inquiry process, we propose TraceLens, a first
end-user question-answer style debugging interface for taint analysis. It
enables a user to ask why, why-not, and what-if questions to investigate the
existence of suspicious flows, the non-existence of expected flows, and the
global impact of third-party library models. TraceLens performs speculative
what-if analysis, to help a user in debugging how different connectivity
assumptions affect overall results. A user study with 12 participants shows
that participants using TraceLens achieved 21% higher accuracy on average,
compared to CodeQL. They also reported a 45% reduction in mental demand
(NASA-TLX) and rated higher confidence in identifying relevant flows using
TraceLens.

</details>


### [11] [AutoAssert 1: A LoRA Fine-Tuned LLM Model for Efficient Automated Assertion Generation](https://arxiv.org/abs/2508.07371)
*Yi Zhong,Hongchao Liu,Di ZHao*

Main category: cs.SE

TL;DR: 通过结合轻量级大语言模型与Unsloth平台，自动生成HDL断言，有效降低训练成本，同时提高准确率和泛化能力，为软硬件系统自动化测试和维护提供了创新工具。


<details>
  <summary>Details</summary>
Motivation: 软件系统复杂度不断提升，对自动化测试和维护工具的需求激增，需要高效且准确的自动化断言生成方式来辅助测试与维护。

Method: 提出基于硬件描述语言（HDL）的断言生成方法，结合可调参数的轻量级大语言模型（LLM）与Unsloth平台实现自动生成测试用例。其目标是降低训练成本，同时保证生成断言的准确性与泛化能力。

Result: 实证结果表明，该方法能够高效地生成严格符合硬件逻辑的断言，且具有较强的鲁棒性和灵活性。

Conclusion: 所提方法为现代软件测试与维护提供了高效、灵活的自动化解决方案，并在实际测试中表现出较好的效果。

Abstract: As the complexity of software systems continues to increase, the demand for
automated testing and maintenance tools is growing exponentially. To meet this
urgent need, we propose a new assertion generation method based on Hardware
Description Language (HDL). This method combines a lightweight,
parameter-adjustable large language model (LLM) with the Unsloth platform to
automatically generate test cases, thereby significantly reducing training
costs without sacrificing accuracy or generalization performance. Empirical
evaluation shows that our method can efficiently generate assertions that
strictly conform to the hardware logic. This framework provides a robust and
flexible solution to modern software testing and maintenance challenges.
https://github.com/liusu-orange/AutoAssert-1 and
https://gitee.com/OpenBPU/auto-assert1 are the locations of the source code.

</details>


### [12] [Extracting Overlapping Microservices from Monolithic Code via Deep Semantic Embeddings and Graph Neural Network-Based Soft Clustering](https://arxiv.org/abs/2508.07486)
*Morteza Ziabakhsh,Kiyan Rezaee,Sadegh Eskandari,Seyed Amir Hossein Tabatabaei,Mohammad M. Ghassemi*

Main category: cs.SE

TL;DR: Mo2oM用深度语义嵌入和图神经网络实现微服务软聚类抽取，支持组件重叠分配。实验结果表明其在多个维度大幅优于现有方法，提升了系统模块性和服务平衡性。


<details>
  <summary>Details</summary>
Motivation: 现代软件系统为提升可扩展性、可维护性和部署灵活性，从单体架构向微服务迁移。目前主流的微服务抽取方法使用硬聚类，将每个组件分配到单个微服务，容易导致跨服务耦合增加、服务内部内聚性下降。为解决这些问题，作者提出新的微服务抽取方法。

Method: 作者提出Mo2oM（Monolithic to Overlapping Microservices）框架，将微服务抽取建模为软聚类问题，使组件可以以概率方式归属于多个微服务。方法融合了深度语义嵌入与基于方法调用图的结构依赖，并采用图神经网络软聚类算法生成最终微服务集合。

Result: Mo2oM在四个开源单体系统基准测试上，与八种先进方法对比，结构模块性提升最多40.97%，服务间调用比提升58%，接口数量提升26.16%，服务规模分布平衡提升38.96%。

Conclusion: Mo2oM通过软聚类方法显著解决了现有微服务抽取在耦合性、内聚性和规模分布等方面的不足，大幅提升了微服务架构的整体质量和性能。

Abstract: Modern software systems are increasingly shifting from monolithic
architectures to microservices to enhance scalability, maintainability, and
deployment flexibility. Existing microservice extraction methods typically rely
on hard clustering, assigning each software component to a single microservice.
This approach often increases inter-service coupling and reduces intra-service
cohesion. We propose Mo2oM (Monolithic to Overlapping Microservices), a
framework that formulates microservice extraction as a soft clustering problem,
allowing components to belong probabilistically to multiple microservices. This
approach is inspired by expert-driven decompositions, where practitioners
intentionally replicate certain software components across services to reduce
communication overhead. Mo2oM combines deep semantic embeddings with structural
dependencies extracted from methodcall graphs to capture both functional and
architectural relationships. A graph neural network-based soft clustering
algorithm then generates the final set of microservices. We evaluate Mo2oM on
four open-source monolithic benchmarks and compare it against eight
state-of-the-art baselines. Our results demonstrate that Mo2oM achieves
improvements of up to 40.97% in structural modularity (balancing cohesion and
coupling), 58% in inter-service call percentage (communication overhead),
26.16% in interface number (modularity and decoupling), and 38.96% in
non-extreme distribution (service size balance) across all benchmarks.

</details>


### [13] [Adopting Road-Weather Open Data in Route Recommendation Engine](https://arxiv.org/abs/2508.07881)
*Henna Tammia,Benjamin Kämä,Ella Peltonen*

Main category: cs.SE

TL;DR: 本文分析了芬兰道路数据接口 DigiTraffic 的数据特性与处理流程，并提出个性化道路推荐方法，经实测可高效对不同用户进行专属路线推荐。


<details>
  <summary>Details</summary>
Motivation: Digitraffic 提供了庞大的实时道路传感数据，应用这些数据于实际场景需要深入理解数据性质、预处理过程，以及相关机器学习工具。

Method: 详细分析 DigiTraffic 路况和气象相关属性，介绍高效数据利用方法，构建并验证个性化道路推荐引擎。

Result: 利用真实世界数据，能够针对三种不同驾驶员画像，准确并高效地推荐个性化路线。

Conclusion: 有效的大规模道路和气象数据处理流程能够支持个性化道路推荐系统的实际应用。

Abstract: Digitraffic, Finland's open road data interface, provides access to
nationwide road sensors with more than 2,300 real-time attributes from 1,814
stations. However, efficiently utilizing such a versatile data API for a
practical application requires a deeper understanding of the data qualities,
preprocessing phases, and machine learning tools. This paper discusses the
challenges of large-scale road weather and traffic data. We go through the
road-weather-related attributes from DigiTraffic as a practical example of
processes required to work with such a dataset. In addition, we provide a
methodology for efficient data utilization for the target application, a
personalized road recommendation engine based on a simple routing application.
We validate our solution based on real-world data, showing we can efficiently
identify and recommend personalized routes for three different driver profiles.

</details>


### [14] [SHIELDA: Structured Handling of Exceptions in LLM-Driven Agentic Workflows](https://arxiv.org/abs/2508.07935)
*Jingwen Zhou,Jieshan Chen,Qinghua Lu,Dehai Zhao,Liming Zhu*

Main category: cs.SE

TL;DR: 本文提出SHIELDA框架，实现了对LLM代理流水线中异常的系统性、结构化处理，并通过案例验证了其实用性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM代理系统异常处理方式往往只做表面处理，不能追溯异常根本原因，且恢复策略缺乏弹性和结构化流程，导致系统鲁棒性不足。

Method: 提出了一种新的LLM代理工作流异常处理框架SHIELDA。它包括异常类型分类、异常模式选择和组合化的结构化恢复执行，关联异常与根因，并执行分阶段的、可组合的恢复策略。

Result: 通过在AutoPR代理上的案例研究，验证了SHIELDA可以有效地跨阶段恢复因推理错误引发的异常。

Conclusion: SHIELDA可为LLM驱动的代理工作流提供系统化、结构化且有效的运行时异常处理，提升了系统的鲁棒性和恢复能力。

Abstract: Large Language Model (LLM) agentic systems are software systems powered by
LLMs that autonomously reason, plan, and execute multi-step workflows to
achieve human goals, rather than merely executing predefined steps. During
execution, these workflows frequently encounter exceptions. Existing exception
handling solutions often treat exceptions superficially, failing to trace
execution-phase exceptions to their reasoning-phase root causes. Furthermore,
their recovery logic is brittle, lacking structured escalation pathways when
initial attempts fail. To tackle these challenges, we first present a
comprehensive taxonomy of 36 exception types across 12 agent artifacts.
Building on this, we propose SHIELDA (Structured Handling of Exceptions in
LLM-Driven Agentic Workflows), a modular runtime exception handling framework
for LLM agentic workflows. SHIELDA uses an exception classifier to select a
predefined exception handling pattern from a handling pattern registry. These
patterns are then executed via a structured handling executor, comprising local
handling, flow control, and state recovery, to enable phase-aware recovery by
linking exceptions to their root causes and facilitating composable strategies.
We validate SHIELDA's effectiveness through a case study on the AutoPR agent,
demonstrating effective, cross-phase recovery from a reasoning-induced
exception.

</details>


### [15] [Exploring the Challenges and Opportunities of AI-assisted Codebase Generation](https://arxiv.org/abs/2508.07966)
*Philipp Eibl,Sadra Sabouri,Souti Chattopadhyay*

Main category: cs.SE

TL;DR: 本论文调查了开发者使用整套代码库AI助手（CBAs）时的行为与反馈，发现其生成效果和用户满意度整体较低，主要因代码功能和质量不足等问题。论文总结了六大挑战和五个采纳障碍，并对现有商业CBAs进行评价，提出未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 虽然代码片段级生成的AI助手已广泛研究，但针对整套代码库生成的AI助手（CBAs）相关工作仍有限，而业界对CBAs虽有期待但实际采用率较低，因此有必要深入了解开发者与CBAs互动时的需求及痛点。

Method: 通过对16名学生与开发者进行对比用户研究与访谈，分析其与CBAs协作编程过程中的行为与反馈，并结合对市面上21个商业CBAs的调研。

Result: 参与者在提示词中包含的问题描述、功能需求、代码结构等多元信息，但无论策略如何，对生成的代码库整体满意度较低（均值2.8/5）。受访者不满意主要因功能不完善（占77%），代码质量低（42%）、沟通障碍（25%）等。论文进一步总结出六大挑战和五大采纳障碍，并与当前商业CBAs功能对比，提出改进设计建议。

Conclusion: 现有CBAs在用户满意度、代码功能与代码质量等方面表现不佳，存在多种挑战和采纳障碍。研究为更高效、实用的CBAs设计提供了基于用户行为与需求的参考建议。

Abstract: Recent AI code assistants have significantly improved their ability to
process more complex contexts and generate entire codebases based on a textual
description, compared to the popular snippet-level generation. These codebase
AI assistants (CBAs) can also extend or adapt codebases, allowing users to
focus on higher-level design and deployment decisions. While prior work has
extensively studied the impact of snippet-level code generation, this new class
of codebase generation models is relatively unexplored. Despite initial
anecdotal reports of excitement about these agents, they remain less frequently
adopted compared to snippet-level code assistants. To utilize CBAs better, we
need to understand how developers interact with CBAs, and how and why CBAs fall
short of developers' needs. In this paper, we explored these gaps through a
counterbalanced user study and interview with (n = 16) students and developers
working on coding tasks with CBAs. We found that participants varied the
information in their prompts, like problem description (48% of prompts),
required functionality (98% of prompts), code structure (48% of prompts), and
their prompt writing process. Despite various strategies, the overall
satisfaction score with generated codebases remained low (mean = 2.8, median =
3, on a scale of one to five). Participants mentioned functionality as the most
common factor for dissatisfaction (77% of instances), alongside poor code
quality (42% of instances) and communication issues (25% of instances). We
delve deeper into participants' dissatisfaction to identify six underlying
challenges that participants faced when using CBAs, and extracted five barriers
to incorporating CBAs into their workflows. Finally, we surveyed 21 commercial
CBAs to compare their capabilities with participant challenges and present
design opportunities for more efficient and useful CBAs.

</details>


### [16] [PyVeritas: On Verifying Python via LLM-Based Transpilation and Bounded Model Checking for C](https://arxiv.org/abs/2508.08171)
*Pedro Orvalho,Marta Kwiatkowska*

Main category: cs.SE

TL;DR: 本文提出PyVeritas，通过LLM高效转译Python至C，并利用C的模型检测与MaxSAT故障定位技术，使Python代码可实现自动验证与bug定位。实验显示该框架对小型复杂Python程序的转译准确率高达80-90%。


<details>
  <summary>Details</summary>
Motivation: 虽然Python是目前主流的通用编程语言，但却缺乏成熟的形式化验证工具。而像C语言这样的程序则有完善的模型检测器（比如CBMC），可以进行符号推理和故障定位。Python的复杂性和现有转译工具的不足限制了其形式化验证的普及。

Method: 提出PyVeritas框架，利用大型语言模型（LLM）将Python高层次转译为C代码，然后在生成的C代码上进行有界模型检测和基于MaxSAT的故障定位。通过C的模型检测工具，为Python代码实现验证和定位bug。

Result: 在两个Python基准测试上进行评估，LLM转译准确率达到80-90%，可有效支持断言式验证和可解释故障诊断，适用于小型但有一定复杂度的Python程序。

Conclusion: LLM辅助的高层次Python转译配合传统C模型检测器，可以显著提升Python程序的形式化验证和故障定位能力，为Python程序员提供了实用的开发环境。

Abstract: Python has become the dominant language for general-purpose programming, yet
it lacks robust tools for formal verification. In contrast, programmers working
in languages such as C benefit from mature model checkers, for example CBMC,
which enable exhaustive symbolic reasoning and fault localisation. The inherent
complexity of Python, coupled with the verbosity and low-level nature of
existing transpilers (e.g., Cython), have historically limited the
applicability of formal verification to Python programs.
  In this paper, we propose PyVeritas, a novel framework that leverages Large
Language Models (LLMs) for high-level transpilation from Python to C, followed
by bounded model checking and MaxSAT-based fault localisation in the generated
C code. PyVeritas enables verification and bug localisation for Python code
using existing model checking tools for C. Our empirical evaluation on two
Python benchmarks demonstrates that LLM-based transpilation can achieve a high
degree of accuracy, up to 80--90% for some LLMs, enabling effective development
environment that supports assertion-based verification and interpretable fault
diagnosis for small yet non-trivial Python programs.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [17] [On the fault diameter and wide diameter of the exchanged 3-ary $n$-cube](https://arxiv.org/abs/2508.07174)
*Rongshuan Geng,Wantao Ning*

Main category: cs.LO

TL;DR: 本文针对交换3元n维立方体E3C(r, s, t)网络，利用理论分析方法得到了其关键参数（故障直径与广义直径）的界限，为网络设计提供了参考。


<details>
  <summary>Details</summary>
Motivation: 在互连网络中，评估通信性能非常关键，其中故障直径和广义直径是衡量网络容错性和传输效率的重要参数。本文关注于一种新提出的网络结构——交换3元n维立方体（E3C），希望分析其相关网络参数。

Method: 作者针对交换3元n维立方体E3C(r, s, t)网络模型，研究了该结构的故障直径与广义直径问题，确定了其具体的取值区间。采用了图论和组合数学方法对网络拓扑结构进行了理论分析和推导。

Result: 作者得出了E3C(r, s, t)的(2r+1)-故障直径和(2r+2)-广义直径均有明确的上下界：n+3到n+5，其中1≤r≤s≤t。

Conclusion: 通过理论分析，为E3C(r, s, t)的容错性和通信效率提供了量化的界限，有助于该网络在实际应用中的设计与评价。

Abstract: Fault diameter and wide diameter are two critical parameters for evaluating
communication performance in interconnection networks. They measure the fault
tolerance and transmission efficiency of networks. The exchanged 3-ary $n$-cube
is a recently proposed variant of the hypercube, denoted by $E3C(r, s, t)$. In
this work, we obtain that the $(2r + 1)$-fault diameter and $(2r + 2)$-wide
diameter of $E3C(r, s, t)$ are bounded between $n + 3$ and $n + 5$ for $1 \leq
r \leq s \leq t$.

</details>


### [18] [Presburger Functional Synthesis: Complexity and Tractable Normal Forms](https://arxiv.org/abs/2508.07207)
*S. Akshay,A. R. Balasubramanian,Supratik Chakraborty,Georg Zetzsche*

Main category: cs.LO

TL;DR: 本文研究了Presburger算术下的功能性综合（PFnS）问题，证明其为EXPTIME复杂性，并提出了高效求解的规范形式PSyNF，丰富了功能性综合领域的理论基础。


<details>
  <summary>Details</summary>
Motivation: 近年来功能性综合问题在不同理论（从布尔到一般一阶逻辑）中受到广泛关注。本文关注在Presburger算术理论下的功能性综合问题，旨在填补该领域的理论空白。

Method: 作者提出Presburger Functional Synthesis（PFnS）并对其复杂性进行了理论分析，证明PFnS可在EXPTIME（指数时间）内求解，并构建了匹配的指数下界。作者进一步探索单输入单输出情况下的复杂度，并提出了PSyNF（特殊规范形式）来保证多项式时间和多项式规模的可解性，分析了其性质、判定与归约方法。最后还辨析了一种易于判定但表达能力较弱的语法规范形式。

Result: 证明了PFnS属于EXPTIME复杂性类别，具有匹配的指数下界。发现单输入单输出下的PFnS与布尔功能性综合一样难。提出的PSyNF形式可保证多项式时间和空间的可解性，并制定了相关性质和归约标准。此外明确了一种更易判定但不如PSyNF紧凑的规范形式。

Conclusion: 本文系统分析了Presburger理论下的功能性综合问题，确立了其复杂性界限，并通过规范形式提升了问题的求解效率，为理论和实际应用提供了重要参考。

Abstract: Given a relational specification between inputs and outputs as a logic
formula, the problem of functional synthesis is to automatically synthesize a
function from inputs to outputs satisfying the relation. Recently, a rich line
of work has emerged tackling this problem for specifications in different
theories, from Boolean to general first-order logic. In this paper, we launch
an investigation of this problem for the theory of Presburger Arithmetic, that
we call Presburger Functional Synthesis (PFnS). We show that PFnS can be solved
in EXPTIME and provide a matching exponential lower bound. This is unlike the
case for Boolean functional synthesis (BFnS), where only conditional
exponential lower bounds are known. Further, we show that PFnS for one input
and one output variable is as hard as BFnS in general. We then identify a
special normal form, called PSyNF, for the specification formula that
guarantees poly-time and poly-size solvability of PFnS. We prove several
properties of PSyNF, including how to check and compile to this form, and
conditions under which any other form that guarantees poly-time solvability of
PFnS can be compiled in poly-time to PSyNF. Finally, we identify a syntactic
normal form that is easier to check but is exponentially less succinct than
PSyNF.

</details>


### [19] [From Knowledge to Conjectures: A Modal Framework for Reasoning about Hypotheses](https://arxiv.org/abs/2508.07304)
*Fabio Vitali*

Main category: cs.LO

TL;DR: 本文提出了一类新的认知模态逻辑系统，通过弱克林语义和弃用Axiom T，解决了传统模态逻辑在处理假设性推理时的模态坍塌问题。新系统能清晰区分事实与猜想，在知识不完备时依然可用，且具有良好的逻辑性质。


<details>
  <summary>Details</summary>
Motivation: 传统模态逻辑无法充分表达认知中的假设性推理且容易出现模态坍塌问题，需要新的逻辑系统来合理区分事实与猜想，并支持知识不完备时的推理。

Method: 采用弱克林逻辑或描述逻辑的认知模态逻辑语义框架，提出KC和KDC等新模态系统，设计动态操作settle(φ)以描述猜想转化为事实的过程，并进行语义分析和逻辑性质证明。

Result: 新逻辑系统有效避免了模态坍塌，支持未定命题与模态断言共存，对部分知识保持鲁棒性，并且证明了其完备性和可判定性。

Conclusion: 提出了一类新的认知模态逻辑系统，能有效区分事实与猜想，避免了模态坍塌，并且这些逻辑在部分知识下依然保持完备性和可判定性。

Abstract: This paper introduces a new family of cognitive modal logics designed to
formalize conjectural reasoning: a modal system in which cognitive contexts
extend known facts with hypothetical assumptions to explore their consequences.
Unlike traditional doxastic and epistemic systems, conjectural logics rely on a
principle, called Axiom C ($\varphi \rightarrow \Box\varphi$), that ensures
that all established facts are preserved across hypothetical layers. While
Axiom C was dismissed in the past due to its association with modal collapse,
we show that the collapse only arises under classical and bivalent assumptions,
and specifically in the presence of Axiom T. Hence we avoid Axiom T and adopt a
paracomplete semantic framework, grounded in Weak Kleene logic or Description
Logic, where undefined propositions coexist with modal assertions. This
prevents the modal collapse and guarantees a layering to distinguish between
factual and conjectural statements. Under this framework we define new modal
systems, e.g., KC and KDC, and show that they are complete, decidable, and
robust under partial knowledge. Finally, we introduce a dynamic operation,
$\mathsf{settle}(\varphi)$, which formalizes the transition from conjecture to
accepted fact, capturing the event of the update of a world's cognitive state
through the resolution of uncertainty.

</details>


### [20] [A Rule-Based Approach to Specifying Preferences over Conflicting Facts and Querying Inconsistent Knowledge Bases](https://arxiv.org/abs/2508.07742)
*Meghyn Bienvenu,Camille Bourgaux,Katsumi Inoue,Robin Jean*

Main category: cs.LO

TL;DR: 该论文提出一种基于规则的优先级关系计算框架，用于提升不一致知识库查询的语义表达和结果合理性，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在处理不一致的知识库时，使用修复式语义是一种重要方法，但如何合理指定事实间的优先级还未被充分解决。该论文旨在通过引入基于规则的框架来解决优先级关系的表达与计算问题，提升查询结果的合理性。

Method: 提出了一个声明式的规则框架，用于指定和计算冲突事实之间的优先关系。分析了优先规则产生环的问题，并研究了消除环的多种技术。通过采用answer set programming实现原型系统，并进行了初步实验评估。

Result: 给出了优先规则导致环的判定方法，验证了多种环消除技术的实用性，实现了查询不一致知识库时可以优先修复的端到端系统，实验表明该方法可行。

Conclusion: 通过基于规则的方法有效表达和计算知识库事实之间的优先级关系，并通过环处理技术确保优先级关系的可用性，从而实现更合理的查询修复语义。

Abstract: Repair-based semantics have been extensively studied as a means of obtaining
meaningful answers to queries posed over inconsistent knowledge bases (KBs).
While several works have considered how to exploit a priority relation between
facts to select optimal repairs, the question of how to specify such
preferences remains largely unaddressed. This motivates us to introduce a
declarative rule-based framework for specifying and computing a priority
relation between conflicting facts. As the expressed preferences may contain
undesirable cycles, we consider the problem of determining when a set of
preference rules always yields an acyclic relation, and we also explore a
pragmatic approach that extracts an acyclic relation by applying various cycle
removal techniques. Towards an end-to-end system for querying inconsistent KBs,
we present a preliminary implementation and experimental evaluation of the
framework, which employs answer set programming to evaluate the preference
rules, apply the desired cycle resolution techniques to obtain a priority
relation, and answer queries under prioritized-repair semantics.

</details>


### [21] [Runtime Verification for LTL in Stochastic Systems](https://arxiv.org/abs/2508.07963)
*Javier Esparza,Vincent Fischer*

Main category: cs.LO

TL;DR: 本文针对LTL运行时验证，提出基于概率预测的新监测方法，克服了传统监测在某些属性上始终无法得结论的问题，实现了预测正确性和置信度持续提升。


<details>
  <summary>Details</summary>
Motivation: 传统LTL运行时验证器在面对如活性属性时，经常由于无法通过有限前缀确定结论而一直输出“未知”，因此需要更灵活且具备实用性的检测手段。

Method: 采用概率预测取代传统监测的硬性结论，同时为每一步输出一个置信度分数。方法可随着观察序列增长，提升预测的准确性并且置信度单调增加。

Result: 新提出的概率预测监测器能够处理传统方法无法得出的结论，保证预测最终正确，并且置信度从临界点之后持续提升。

Conclusion: 本文提出了一种新的线性时序逻辑（LTL）运行时验证方法，相比传统检测器只输出确定性结论，本方法通过概率预测和置信度分数，更好地处理了传统方法在活性等属性上的不足。预测结果最终收敛，并且置信度持续提升。

Abstract: Runtime verification encompasses several lightweight techniques for checking
whether a system's current execution satisfies a given specification. We focus
on runtime verification for Linear Temporal Logic (LTL). Previous work
describes monitors which produce, at every time step one of three outputs -
true, false, or inconclusive - depending on whether the observed execution
prefix definitively determines satisfaction of the formula. However, for many
LTL formulas, such as liveness properties, satisfaction cannot be concluded
from any finite prefix. For these properties traditional monitors will always
output inconclusive. In this work, we propose a novel monitoring approach that
replaces hard verdicts with probabilistic predictions and an associated
confidence score. Our method guarantees eventual correctness of the prediction
and ensures that confidence increases without bound from that point on.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [22] [Semi-automated Fact-checking in Portuguese: Corpora Enrichment using Retrieval with Claim extraction](https://arxiv.org/abs/2508.06495)
*Juliana Resplande Sant'anna Gomes,Arlindo Rodrigues Galvão Filho*

Main category: cs.CL

TL;DR: 该论文提出了一种用大型语言模型和搜索引擎API为葡萄牙语新闻数据集增强外部证据的方法，并建立了完善的数据处理流程，为葡语半自动事实核查系统发展提供关键支持。


<details>
  <summary>Details</summary>
Motivation: 当前假信息传播速度远超人工核查能力，特别是在葡萄牙语环境下，缺乏结合外部证据的公开数据集，制约了半自动事实核查系统的发展。许多现有资源仅基于文本内在特征进行分类，未利用外部证据。

Method: 提出并实施了一种能够为葡萄牙语新闻语料（如Fake.Br、COVID19.BR、MuMiN-PT）添加外部证据的方法。通过模拟用户验证过程，运用大型语言模型（如Gemini 1.5 Flash）提取文本主张，并利用搜索引擎API（Google Search API, Google FactCheck Claims Search API）检索相关外部文档。另设数据验证和预处理框架，包括近重复检测，以提升语料质量。

Result: 成功开发了丰富葡萄牙语新闻数据集的技术方案，将抽取主张与外部证据有机整合，并提高了数据集的质量；为构建更健壮的半自动事实核查系统奠定了基础。

Conclusion: 通过外部证据整合和数据质量提升，填补了葡萄牙语事实核查数据资源的空白，使葡语语境下的半自动事实核查系统建设迈出了重要一步。

Abstract: The accelerated dissemination of disinformation often outpaces the capacity
for manual fact-checking, highlighting the urgent need for Semi-Automated
Fact-Checking (SAFC) systems. Within the Portuguese language context, there is
a noted scarcity of publicly available datasets that integrate external
evidence, an essential component for developing robust AFC systems, as many
existing resources focus solely on classification based on intrinsic text
features. This dissertation addresses this gap by developing, applying, and
analyzing a methodology to enrich Portuguese news corpora (Fake.Br, COVID19.BR,
MuMiN-PT) with external evidence. The approach simulates a user's verification
process, employing Large Language Models (LLMs, specifically Gemini 1.5 Flash)
to extract the main claim from texts and search engine APIs (Google Search API,
Google FactCheck Claims Search API) to retrieve relevant external documents
(evidence). Additionally, a data validation and preprocessing framework,
including near-duplicate detection, is introduced to enhance the quality of the
base corpora.

</details>


### [23] [Retrieval augmented generation based dynamic prompting for few-shot biomedical named entity recognition using large language models](https://arxiv.org/abs/2508.06504)
*Yao Ge,Sudeshna Das,Yuting Guo,Abeed Sarker*

Main category: cs.CL

TL;DR: 利用动态检索增强生成的Prompt技术，大幅提升了大型语言模型在少样本生物医学NER中的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 生物医学命名实体识别（NER）任务在自然语言处理领域极具价值，但在训练数据有限的情况下，大型语言模型（LLM）性能尚有挑战。该文旨在解决LLM在少样本生物医学NER下的表现瓶颈。

Method: 提出基于动态检索增强生成（RAG）的提示策略，通过与输入文本相似性选取已标注上下文例子，并在推理时为每个实例动态更新Prompt。同时开发和优化了静态与动态Prompt工程，在五个生物医学NER数据集上进行评估。

Result: 结构化静态Prompt将GPT-4的平均F1分提升了12%，GPT-3.5和LLaMA 3-70B提升了11%。动态Prompt进一步提升性能，TF-IDF和SBERT检索方法在5-shot和10-shot下分别提高平均F1分7.3%和5.6%。

Conclusion: 动态、语境自适应的Prompt（通过检索增强生成实现）能够显著提升LLM在生物医学NER少样本场景下的表现。

Abstract: Biomedical named entity recognition (NER) is a high-utility natural language
processing (NLP) task, and large language models (LLMs) show promise
particularly in few-shot settings (i.e., limited training data). In this
article, we address the performance challenges of LLMs for few-shot biomedical
NER by investigating a dynamic prompting strategy involving retrieval-augmented
generation (RAG). In our approach, the annotated in-context learning examples
are selected based on their similarities with the input texts, and the prompt
is dynamically updated for each instance during inference. We implemented and
optimized static and dynamic prompt engineering techniques and evaluated them
on five biomedical NER datasets. Static prompting with structured components
increased average F1-scores by 12% for GPT-4, and 11% for GPT-3.5 and LLaMA
3-70B, relative to basic static prompting. Dynamic prompting further improved
performance, with TF-IDF and SBERT retrieval methods yielding the best results,
improving average F1-scores by 7.3% and 5.6% in 5-shot and 10-shot settings,
respectively. These findings highlight the utility of contextually adaptive
prompts via RAG for biomedical NER.

</details>


### [24] [CarbonScaling: Extending Neural Scaling Laws for Carbon Footprint in Large Language Models](https://arxiv.org/abs/2508.06524)
*Lei Jiang,Fan Chen*

Main category: cs.CL

TL;DR: 本文提出CarbonScaling框架，将碳排放纳入神经缩放定律，分析大模型训练中的碳效率问题。结果显示，硬件进步和训练优化可在一定程度上降低碳排放，但超大模型带来的通讯和资源浪费使得环保收益递减，框架为绿色AI实践提供了方向。


<details>
  <summary>Details</summary>
Motivation: 神经缩放定律推动了越来越大型的语言模型的发展，但忽视了随模型规模增大而呈指数增长的碳排放问题。本文旨在补充这一空白。

Method: 提出了CarbonScaling分析框架，结合神经缩放、GPU硬件发展、并行优化和碳估算等多个模型，定量分析模型精度与碳排放之间的关系。

Result: 发现虽然精度与碳排放之间存在幂律关系，但现实中的各种效率损失大幅提高了缩放因子。硬件进步对小型和中型模型有助于减少碳排放，对超大模型效果有限，原因是通信和GPU利用率下降。训练优化措施能部分缓解该问题。

Conclusion: CarbonScaling框架为实现更可持续和高碳效率的LLM训练提供重要洞见，指导模型训练过程中的环保决策。

Abstract: Neural scaling laws have driven the development of increasingly large
language models (LLMs) by linking accuracy improvements to growth in parameter
count, dataset size, and compute. However, these laws overlook the carbon
emissions that scale exponentially with LLM size. This paper presents
\textit{CarbonScaling}, an analytical framework that extends neural scaling
laws to incorporate both operational and embodied carbon in LLM training. By
integrating models for neural scaling, GPU hardware evolution, parallelism
optimization, and carbon estimation, \textit{CarbonScaling} quantitatively
connects model accuracy to carbon footprint. Results show that while a
power-law relationship between accuracy and carbon holds, real-world
inefficiencies significantly increase the scaling factor. Hardware technology
scaling reduces carbon emissions for small to mid-sized models, but offers
diminishing returns for extremely large LLMs due to communication overhead and
underutilized GPUs. Training optimizations-especially aggressive critical batch
size scaling-help alleviate this inefficiency. \textit{CarbonScaling} offers
key insights for training more sustainable and carbon-efficient LLMs.

</details>


### [25] [The Art of Breaking Words: Rethinking Multilingual Tokenizer Design](https://arxiv.org/abs/2508.06533)
*Aamod Thakur,Ajay Nagpal,Atharva Savarkar,Kundeshwar Pundalik,Siddhesh Dosi,Piyush Sawarkar,Viraj Thakur,Rohit Saluja,Maunendra Sankar Desarkar,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: 本文指出分词在多语言大模型开发中被忽视，提出并实验证明新的数据构成算法和预分词策略显著降低token-to-word比率，提高模型性能与推理速度，强调分词对多语言LLM效率同样关键。


<details>
  <summary>Details</summary>
Motivation: 尽管模型架构和训练目标得到充分研究，但在多语言环境下的分词，尤其在大型语言模型（LLM）开发中，仍被较大程度忽视。现有分词器存在高token-to-word比率、上下文长度利用低效和推理速度慢的问题。作者希望系统性分析分词对模型效率和质量的影响。

Method: 文章系统地分析了词表大小、预分词规则和训练语料组成对token-to-word效率和模型质量的影响。研究以印度语系文字为实验对象，针对其语言和书写复杂度开展实验。此外，提出了一种新的多语言分词训练数据平衡算法，并改进预分词策略。

Result: 所提出的数据组合算法相比传统随机方法，将平均token-to-word比减少了约6%；新分词器在平均token-to-word比上对比现有多语言印度语模型提升超过40%；这些改善带来了模型性能与推理速度的提升。

Conclusion: 分词方案在高效、可扩展的多语言LLM开发中，与模型结构和训练目标同等重要。优化分词策略和数据组成不仅提升分词效率，还能实质增强模型表现和推理效率。

Abstract: While model architecture and training objectives are well-studied,
tokenization, particularly in multilingual contexts, remains a relatively
neglected aspect of Large Language Model (LLM) development. Existing tokenizers
often exhibit high token-to-word ratios, inefficient use of context length, and
slower inference. We present a systematic study that links vocabulary size,
pre-tokenization rules, and training-corpus composition to both token-to-word
efficiency and model quality. To ground our analysis in a linguistically
diverse context, we conduct extensive experiments on Indic scripts, which
present unique challenges due to their high script diversity and orthographic
complexity. Drawing on the insights from these analyses, we propose a novel
algorithm for data composition that balances multilingual data for tokenizer
training. Our observations on pretokenization strategies significantly improve
model performance, and our data composition algorithm reduces the average
token-to-word ratio by approximately 6% with respect to the conventional data
randomization approach. Our tokenizer achieves more than 40% improvement on
average token-to-word ratio against stateof-the-art multilingual Indic models.
This improvement yields measurable gains in both model performance and
inference speed. This highlights tokenization alongside architecture and
training objectives as a critical lever for building efficient, scalable
multilingual LLMs

</details>


### [26] [Factor Augmented Supervised Learning with Text Embeddings](https://arxiv.org/abs/2508.06548)
*Zhanye Luo,Yuefeng Han,Xiufan Yu*

Main category: cs.CL

TL;DR: AEALT结合自动编码器和LLM文本嵌入，有效压缩嵌入空间，在多任务中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型生成的高维度文本嵌入虽然能捕捉丰富语义，但在下游任务中常常导致效率低下和计算成本高昂。

Method: 提出AEALT（AutoEncoder-Augmented Learning with Text）框架，将监督式、增强型自动编码器用于直接在预训练LLM的工作流中进行维度约减。具体流程为：首先提取文本嵌入向量，然后通过增强型自动编码器，学习低维、与任务高度相关的潜在表示。

Result: AEALT在分类、异常检测和预测等多种实际任务及公开数据集上的实验显示，明显优于原始嵌入及多种标准维度约减方法。

Conclusion: AEALT能有效降低文本嵌入维度，提高下游任务性能和效率，优于现有主流维度约减方法。

Abstract: Large language models (LLMs) generate text embeddings from text data,
producing vector representations that capture the semantic meaning and
contextual relationships of words. However, the high dimensionality of these
embeddings often impedes efficiency and drives up computational cost in
downstream tasks. To address this, we propose AutoEncoder-Augmented Learning
with Text (AEALT), a supervised, factor-augmented framework that incorporates
dimension reduction directly into pre-trained LLM workflows. First, we extract
embeddings from text documents; next, we pass them through a supervised
augmented autoencoder to learn low-dimensional, task-relevant latent factors.
By modeling the nonlinear structure of complex embeddings, AEALT outperforms
conventional deep-learning approaches that rely on raw embeddings. We validate
its broad applicability with extensive experiments on classification, anomaly
detection, and prediction tasks using multiple real-world public datasets.
Numerical results demonstrate that AEALT yields substantial gains over both
vanilla embeddings and several standard dimension reduction methods.

</details>


### [27] [Discerning minds or generic tutors? Evaluating instructional guidance capabilities in Socratic LLMs](https://arxiv.org/abs/2508.06583)
*Ying Liu,Can Li,Ting Zhang,Mei Wang,Qiannan Zhu,Jian Li,Hua Huang*

Main category: cs.CL

TL;DR: 本文指出大语言模型在个性化教学指导方面存在短板，提出GuideEval基准和行为引导微调，有效增强模型根据学习者状态动态调整辅导策略的能力。


<details>
  <summary>Details</summary>
Motivation: 以往对大模型教学能力的研究主要关注问题生成（如苏格拉底式提问），但忽略了根据学习者认知状态进行自适应教学。这一维度对于实现个性化和高效辅导至关重要。

Method: 提出并构建了GuideEval基准，基于真实教育对话，采用三阶段行为框架：1)感知，推断学习者状态；2)编排，调整教学策略；3)引导，激发学习者反思。同时，应用行为引导微调的策略进行优化和对比实验。

Result: 实验证明当前大语言模型在自适应教学指导方面存在明显不足。提出的行为引导微调方法有效提升了模型的教学指导效果。

Conclusion: 现有的大语言模型在面对学习者疑惑或需要引导时，往往难以有效地进行自适应的教学支持。本文提出的行为引导微调策略能够显著提升其引导表现。

Abstract: The conversational capabilities of large language models hold significant
promise for enabling scalable and interactive tutoring. While prior research
has primarily examined their capacity for Socratic questioning, it often
overlooks a critical dimension: adaptively guiding learners based on their
cognitive states. This study shifts focus from mere question generation to the
broader instructional guidance capability. We ask: Can LLMs emulate expert
tutors who dynamically adjust strategies in response to learners'
understanding? To investigate this, we propose GuideEval, a benchmark grounded
in authentic educational dialogues that evaluates pedagogical guidance through
a three-phase behavioral framework: (1) Perception, inferring learner states;
(2) Orchestration, adapting instructional strategies; and (3) Elicitation,
stimulating proper reflections. Empirical findings reveal that existing LLMs
frequently fail to provide effective adaptive scaffolding when learners exhibit
confusion or require redirection. Furthermore, we introduce a behavior-guided
finetuning strategy that leverages behavior-prompted instructional dialogues,
significantly enhancing guidance performance. By shifting the focus from
isolated content evaluation to learner-centered interaction, our work advocates
a more dialogic paradigm for evaluating Socratic LLMs.

</details>


### [28] [LLM Unlearning Without an Expert Curated Dataset](https://arxiv.org/abs/2508.06595)
*Xiaoyuan Zhu,Muru Zhang,Ollie Liu,Robin Jia,Willie Neiswanger*

Main category: cs.CL

TL;DR: 本文提出一种通过语言模型自动合成高质量“遗忘数据集”的方法，有效提升大模型去学习特定领域知识的实用性，结果接近专家整理数据，方法适用性广且开源，推动了模型安全与合规发展。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛应用，其编码了大量敏感、有害或受版权保护的信息，亟需无需完全重新训练情况下实现“去学习”某些特定领域知识的能力。而目前去学习流程中的主要瓶颈在于如何构建高效的“遗忘数据集”。

Method: 提出了一种可扩展、自动化的方法，利用语言模型自身，通过结构化提示，合成教材风格的数据集，只需输入领域名称即可生成高质量的遗忘数据集。并在生物安全、网络安全和哈利波特小说等领域进行了实验验证。通过多步生成流程提升数据多样性。

Result: 合成数据集在去学习实用性上优于基线替代方案且接近专家人工整理的数据集。消融实验显示多步生成显著提升了数据多样性，也提升了模型去学习的效果。

Conclusion: 合成数据集为无需人工干预条件下，各类新兴领域的大语言模型去学习提供了现实且可扩展的解决方案。作者开源了代码和数据集。

Abstract: Modern large language models often encode sensitive, harmful, or copyrighted
knowledge, raising the need for post-hoc unlearning-the ability to remove
specific domains of knowledge from a model without full retraining. A major
bottleneck in current unlearning pipelines is constructing effective forget
sets-datasets that approximate the target domain and guide the model to forget
it. In this work, we introduce a scalable, automated approach to generate
high-quality forget sets using language models themselves. Our method
synthesizes textbook-style data through a structured prompting pipeline,
requiring only a domain name as input. Through experiments on unlearning
biosecurity, cybersecurity, and Harry Potter novels, we show that our synthetic
datasets consistently outperform the baseline synthetic alternatives and are
comparable to the expert-curated ones. Additionally, ablation studies reveal
that the multi-step generation pipeline significantly boosts data diversity,
which in turn improves unlearning utility. Overall, our findings suggest that
synthetic datasets offer a promising path toward practical, scalable unlearning
for a wide range of emerging domains without the need for manual intervention.
We release our code and dataset at
https://github.com/xyzhu123/Synthetic_Textbook.

</details>


### [29] [BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent](https://arxiv.org/abs/2508.06600)
*Zijian Chen,Xueguang Ma,Shengyao Zhuang,Ping Nie,Kai Zou,Andrew Liu,Joshua Green,Kshama Patel,Ruoxi Meng,Mingyi Su,Sahel Sharifymoghaddam,Yanxi Li,Haoran Hong,Xinyu Shi,Xuye Liu,Nandan Thakur,Crystina Zhang,Luyu Gao,Wenhu Chen,Jimmy Lin*

Main category: cs.CL

TL;DR: 本文提出BrowseComp-Plus基准，采用固定语料，便于公平、透明地评估深度检索代理和检索方法。实验证明该基准能显著区分不同系统性能，为分析和优化相关技术提供了有效工具。


<details>
  <summary>Details</summary>
Motivation: 当前集成大语言模型（LLMs）和检索工具的深度检索代理，在处理复杂检索规划与推理方面表现出色。然而，现有基准如BrowseComp由于依赖黑盒在线搜索API，导致公平性、透明性等方面存在局限：难以可重复比较，也无法单独分析检索器性能。

Method: 作者提出BrowseComp-Plus，这是基于BrowseComp的新基准，采用固定且精心筛选的语料库。每个查询都配有人工验证的支持文档和难度较高的负例，以支持可控实验。通过这一基准，可以分别分析系统和检索器的贡献。

Result: 在BrowseComp-Plus测试中，开源模型Search-R1配合BM25检索器仅获得3.86%准确率，而GPT-5达到了55.9%。将GPT-5与Qwen3-Embedding-8B检索器结合后，准确率进一步提升至70.1%，且搜索调用次数更少，显示出不同架构和检索手段的优劣。

Conclusion: BrowseComp-Plus能够有效区分深度检索系统性能，实现可控、深入的系统及方法分析，对检索效果、引用准确性、上下文工程等具有研究与改进价值。

Abstract: Deep-Research agents, which integrate large language models (LLMs) with
search tools, have shown success in improving the effectiveness of handling
complex queries that require iterative search planning and reasoning over
search results. Evaluations on current benchmarks like BrowseComp relies on
black-box live web search APIs, have notable limitations in (1) fairness:
dynamic and opaque web APIs hinder fair comparisons and reproducibility of deep
research methods; (2) transparency: lack of control over the document corpus
makes it difficult to isolate retriever contributions. In other words, the
current evaluations may compare a complete deep research system at a given
time, but they do not foster well-controlled experiments to provide insights
into the capability of underlying deep research LLMs. To address these
challenges, we introduce BrowseComp-Plus, a benchmark derived from BrowseComp,
employing a fixed, carefully curated corpus. Each query in BrowseComp-Plus
includes human-verified supporting documents and mined challenging negatives,
enabling controlled experimentation. The benchmark is shown to be effective in
distinguishing the performance of deep research systems. For instance, the
open-source model Search-R1, when paired with the BM25 retriever, achieves
3.86% accuracy, whereas the GPT-5 achieves 55.9%. Integrating the GPT-5 with
the Qwen3-Embedding-8B retriever further enhances its accuracy to 70.1% with
fewer search calls. This benchmark allows comprehensive evaluation and
disentangled analysis of deep research agents and retrieval methods, fostering
insights into retrieval effectiveness, citation accuracy, and context
engineering in Deep-Research system.

</details>


### [30] [Train It and Forget It: Merge Lists are Unnecessary for BPE Inference in Language Models](https://arxiv.org/abs/2508.06621)
*Tomohiro Sawada,Kartik Goyal*

Main category: cs.CL

TL;DR: 本研究发现，无需依赖BPE的merge list即可实现高效分词，对模型性能影响很小，有助于提升分词隐私保护能力。


<details>
  <summary>Details</summary>
Motivation: 近年来研究显示，标准BPE分词中的merge list暴露了训练数据的信息，存在隐私风险。作者希望探索不依赖merge list的BPE推理算法对下游任务的影响，寻求更安全的分词方案。

Method: 作者设计并评估了两类不同于BPE训练的推理算法：（a）有针对性地偏离merge list，如随机合并或对merge list做删减/截断等；（b）完全不依赖merge list，采用贪心或精确压缩方案实现文本压缩。结合多语言建模任务、QA、机器翻译、开放文本生成等场景，进行了广泛实验。

Result: 针对merge list的有目标变异会导致语言模型性能明显下降；而不依赖merge list的无目标推理算法对下游任务影响极小，远低于预期。

Conclusion: 不使用merge list也能实现有效的BPE分词，且不会严重影响模型表现。这为开发更简单且更具隐私保护能力的分词方法提供了新思路。

Abstract: Standard Byte-Pair Encoding (BPE) tokenization compresses text by pairing a
learned token vocabulary with a detailed merge list. Recent work has shown that
this merge list exposes a potential attack surface for extracting information
about language model's training data. In this paper, we explore the downstream
impact of BPE inference algorithms that do not rely on this merge list at all,
and hence differ from the encoding process during BPE training. To address this
question, we investigate two broad classes of BPE inference schemes that differ
from BPE application during training: a) targeted deviation from merge-lists
including random merge orders, and various corruptions of merge list involving
deletion/truncation, and b) non-targeted BPE inference algorithms that do not
depend on the merge list but focus on compressing the text either greedily or
exactly. Extensive experiments across diverse language modeling tasks like
accuracy-based QA benchmarks, machine translation, and open-ended generation
reveal that while targeted deviation from the merge lists exhibits significant
degradation in language model performance, the non-targeted merge-list-free
inference algorithms result in minimal impact on downstream performance that is
often much smaller than expected. These findings pave way for simpler and
potentially more privacy-preserving tokenization schemes that do not
catastrophically compromise model performance.

</details>


### [31] [Measuring Stereotype and Deviation Biases in Large Language Models](https://arxiv.org/abs/2508.06649)
*Daniel Wang,Eli Brignac,Minjia Mao,Xiao Fang*

Main category: cs.CL

TL;DR: 论文系统分析了大型语言模型在涉及人口属性生成任务时易出现的刻板印象和分布偏离偏见，并通过实验证明当前主流LLM普遍存在这些问题，提示需警惕其输出中的潜在社会危害。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）广泛应用于各个领域，但其偏见和潜在风险引发关注，特别是涉及特定人群的刻板印象和与现实世界差异的偏离。

Method: 本文通过让四种先进的LLM生成个体档案，分析模型输出中各群体与政治、宗教和性取向等属性的关联，实证检验了刻板印象偏见与分布偏离偏见。

Result: 所有被测试的LLM在多个群体上都展示了显著的刻板印象偏见和分布偏离偏见。

Conclusion: LLMs在推断用户属性时会产生不同类型的偏见，这些偏见可能对其生成内容的公平性和客观性产生潜在危害。

Abstract: Large language models (LLMs) are widely applied across diverse domains,
raising concerns about their limitations and potential risks. In this study, we
investigate two types of bias that LLMs may display: stereotype bias and
deviation bias. Stereotype bias refers to when LLMs consistently associate
specific traits with a particular demographic group. Deviation bias reflects
the disparity between the demographic distributions extracted from
LLM-generated content and real-world demographic distributions. By asking four
advanced LLMs to generate profiles of individuals, we examine the associations
between each demographic group and attributes such as political affiliation,
religion, and sexual orientation. Our experimental results show that all
examined LLMs exhibit both significant stereotype bias and deviation bias
towards multiple groups. Our findings uncover the biases that occur when LLMs
infer user attributes and shed light on the potential harms of LLM-generated
outputs.

</details>


### [32] [Testing the Limits of Machine Translation from One Book](https://arxiv.org/abs/2508.06665)
*Jonathan Shaw,Dillon Mee,Timothy Khouw,Zackary Leech,Daniel Wilson*

Main category: cs.CL

TL;DR: 该研究发现在资源稀缺语言（如Kanuri）的翻译中，平行语句对大模型帮助最大，仅有语法信息远远不够，LLM更易保证语义准确但难以保证语法流畅，提示未来应注重多维度评估及语料建设。


<details>
  <summary>Details</summary>
Motivation: 针对Kanuri这种人口众多但数字资源稀缺的语言，探究如何利用大模型和有限语料资源（语法、词典、平行语句）提升其翻译质量，并了解领域特定任务如何影响翻译表现。

Method: 设计两个评估数据集（健康/人道主义术语和通用术语），向LLM提供不同组合的语言资源，测量其翻译效果，与母语者及人类语言学家译文比较，并结合自动指标及母语者流利度、准确性评价进行评估。

Result: 提供平行语句是最有效提升翻译质量的方法，无论在人类评价还是自动指标上表现最好。仅依靠语法信息虽优于零样本，但难以单独胜任领域翻译任务。LLM在传达准确意义方面优于生成语法流畅文本。

Conclusion: LLM翻译评估应采用多维度标准，单靠语法（无平行语句）难以满足有效领域翻译需求。平行语句依然是提升数字资源匮乏语言翻译质量的关键。

Abstract: Current state-of-the-art models demonstrate capacity to leverage in-context
learning to translate into previously unseen language contexts. Tanzer et al.
[2024] utilize language materials (e.g. a grammar) to improve translation
quality for Kalamang using large language models (LLMs). We focus on Kanuri, a
language that, despite having substantial speaker population, has minimal
digital resources. We design two datasets for evaluation: one focused on health
and humanitarian terms, and another containing generalized terminology,
investigating how domain-specific tasks impact LLM translation quality.
  By providing different combinations of language resources (grammar,
dictionary, and parallel sentences), we measure LLM translation effectiveness,
comparing results to native speaker translations and human linguist
performance. We evaluate using both automatic metrics and native speaker
assessments of fluency and accuracy.
  Results demonstrate that parallel sentences remain the most effective data
source, outperforming other methods in human evaluations and automatic metrics.
While incorporating grammar improves over zero-shot translation, it fails as an
effective standalone data source. Human evaluations reveal that LLMs achieve
accuracy (meaning) more effectively than fluency (grammaticality).
  These findings suggest LLM translation evaluation benefits from
multidimensional assessment beyond simple accuracy metrics, and that grammar
alone, without parallel sentences, does not provide sufficient context for
effective domain-specific translation.

</details>


### [33] [Do Biased Models Have Biased Thoughts?](https://arxiv.org/abs/2508.06671)
*Swati Rajwal,Shivank Garg,Reem Abdel-Salam,Abdelrahman Zayed*

Main category: cs.CL

TL;DR: 研究发现，大型语言模型输出的偏见并不总来源于其思维链步骤中的偏见，二者相关性较低。因此，模型产生带有偏见输出时，其推理链未必同样存在相应偏见。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型展现出色能力，但仍存在如性别、种族、社会经济地位、外貌和性取向等方面的偏见问题，这些偏见影响了模型的实际部署。因此，研究如何识别和缓解模型中的偏见具有重要意义。

Method: 本文采用chain-of-thought prompting（思维链提示法），分析模型在生成答案前的推理步骤。通过在5个主流大型语言模型上，利用公平性指标评估模型在思维链过程与最终输出中的11类偏见，并进行相关性分析。

Result: 实验发现，模型在思维链步骤中的偏见与最终输出偏见的相关性较低（相关系数小于0.6，且p值小于0.001）。这说明，与人类不同，这些模型即使输出存在偏见，其推理过程未必也都带有同样的偏见。

Conclusion: 大型语言模型在推理链中的偏见与输出偏见之间相关性较低，提示对模型偏见的分析需要同时关注输出和中间推理过程，不能仅凭表面结果判断模型本身的“思维”偏见。

Abstract: The impressive performance of language models is undeniable. However, the
presence of biases based on gender, race, socio-economic status, physical
appearance, and sexual orientation makes the deployment of language models
challenging. This paper studies the effect of chain-of-thought prompting, a
recent approach that studies the steps followed by the model before it
responds, on fairness. More specifically, we ask the following question:
\textit{Do biased models have biased thoughts}? To answer our question, we
conduct experiments on $5$ popular large language models using fairness metrics
to quantify $11$ different biases in the model's thoughts and output. Our
results show that the bias in the thinking steps is not highly correlated with
the output bias (less than $0.6$ correlation with a $p$-value smaller than
$0.001$ in most cases). In other words, unlike human beings, the tested models
with biased decisions do not always possess biased thoughts.

</details>


### [34] [Play Favorites: A Statistical Method to Measure Self-Bias in LLM-as-a-Judge](https://arxiv.org/abs/2508.06709)
*Evangelia Spiliopoulou,Riccardo Fogliato,Hanna Burnsky,Tamer Soliman,Jie Ma,Graham Horwood,Miguel Ballesteros*

Main category: cs.CL

TL;DR: 提出统计方法识别和量化LLM评判中的自偏差和家族偏差，发现常用模型有高自偏差风险，提醒使用LLM评判时需谨慎并采用偏差修正策略。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）被广泛用作评判其他模型输出的工具，但它们倾向于对自身输出赋予更高的评分，即“自偏差”现象，这会扭曲模型真实性能的评估。此前的研究往往无法分清模型实际质量差异与自偏差，也错误地假设LLM和人类的评分分布一致。

Method: 本文提出了一个统计框架，明确界定了可识别和估计自偏差的假设条件。方法通过对比LLM作为评判者时对自身输出与其他模型输出的评分分布，同时利用独立第三方（如人类专家）对输出质量进行参考，能排除模型能力差异对自偏差估计的干扰。

Result: 在包含5000多个提示-完成对的大型数据集上，实证分析发现诸如GPT-4o和Claude 3.5 Sonnet等模型存在明显自偏差，倾向于对自身及同家族模型的输出打更高分。还发现了“家族偏差”，即对源自同家族模型的输出也给予更高评分。

Conclusion: 使用LLM作为自动化评判工具时需警惕自偏差和家族偏差，否则会误判模型的实际性能。本文为识别与缓解这些偏差提供了统计方法和实践指导。

Abstract: Large language models (LLMs) can serve as judges that offer rapid and
reliable assessments of other LLM outputs. However, models may systematically
assign overly favorable ratings to their own outputs, a phenomenon known as
self-bias, which can distort evaluations of true model performance. Previous
studies often conflate genuine differences in model quality with bias or
incorrectly assume that evaluations from LLMs and humans follow the same rating
distributions. In this work, we present a statistical framework that explicitly
formalizes assumptions under which self-bias can be identified and estimated.
Our method models the difference in the scoring distribution that
LLM-as-a-judge assigns to its own completions compared to other models, while
accounting for the underlying quality of the completions provided by an
independent, third-party judge (e.g., humans). Our method reliably isolates and
quantifies self-bias, even when models vary in ability, ensuring that genuine
performance differences are not mistaken for self-bias. We conduct an empirical
analysis of self-bias on a large dataset (>5000 prompt-completion pairs)
consisting of expert human annotations and judgments from nine different LLM
judges. We find that some models, such as GPT-4o and Claude 3.5 Sonnet,
systematically assign higher scores to their own outputs. These models also
display family-bias; systematically assigning higher ratings to outputs
produced by other models of the same family. Our findings highlight potential
pitfalls of using LLM judges and offer practical guidance to mitigate biases
when interpreting automated evaluations.

</details>


### [35] [Large Language Models for Oral History Understanding with Text Classification and Sentiment Analysis](https://arxiv.org/abs/2508.06729)
*Komala Subramanyam Cherukuri,Pranav Abishai Moses,Aisa Sakata,Jiangping Chen,Haihua Chen*

Main category: cs.CL

TL;DR: 本研究提出自动化标注框架，利用ChatGPT、Llama和Qwen等LLMs对日裔美国人监禁口述历史档案进行语义和情感标注。通过多阶段流程和提示词优化，首次实现大规模语义与情感自动化分析，效果优异，并提供可复用的流程和实务指南，为文化敏感档案AI分析和集体记忆保护提供新范式。


<details>
  <summary>Details</summary>
Motivation: 口述历史能真实记录被系统性不公和历史抹除影响的群体的生活经验，但该类档案往往结构化程度低、情感复杂且人工标注成本高，导致无法大规模分析。研究动机是希望通过自动化方法提升口述历史档案的分析效率和效果，从而增强其可访问性与理解度。

Method: 提出了一套可扩展的自动化语义和情感标注框架，应用大语言模型（LLMs）对日裔美国人监禁口述历史档案进行语义和情感自动标注。方法包括专家标注、提示词设计、多模型（ChatGPT、Llama、Qwen）评估，重点测试零样本、少样本和检索增强生成（RAG）策略。先对558句来自15位讲述者的句子进行标注，然后选用最佳模型和提示配置大规模标注1,002次访谈的92,191个句子。

Result: ChatGPT在语义分类中表现最佳，F1分数为88.71%，Llama和Qwen分别为84.99%和83.72%。在情感分析上，Llama略优于Qwen（82.66%）和ChatGPT（82.29%），各模型均表现相近。展示了人类设计提示词指导下，LLMs能高效完成大规模口述历史的语义与情感标注。

Conclusion: LLMs在合理提示词设计和评价机制下，可自动化分析历史敏感语境下的大规模口述历史档案，实现高质量语义和情感标注。成果包括可复用的标注流程及实践指导，为文化敏感档案的伦理性与可扩展NLP方法结合、推动人工智能在数字人文学科及集体记忆保护中的应用奠定了基础。

Abstract: Oral histories are vital records of lived experience, particularly within
communities affected by systemic injustice and historical erasure. Effective
and efficient analysis of their oral history archives can promote access and
understanding of the oral histories. However, Large-scale analysis of these
archives remains limited due to their unstructured format, emotional
complexity, and high annotation costs. This paper presents a scalable framework
to automate semantic and sentiment annotation for Japanese American
Incarceration Oral History. Using LLMs, we construct a high-quality dataset,
evaluate multiple models, and test prompt engineering strategies in
historically sensitive contexts. Our multiphase approach combines expert
annotation, prompt design, and LLM evaluation with ChatGPT, Llama, and Qwen. We
labeled 558 sentences from 15 narrators for sentiment and semantic
classification, then evaluated zero-shot, few-shot, and RAG strategies. For
semantic classification, ChatGPT achieved the highest F1 score (88.71%),
followed by Llama (84.99%) and Qwen (83.72%). For sentiment analysis, Llama
slightly outperformed Qwen (82.66%) and ChatGPT (82.29%), with all models
showing comparable results. The best prompt configurations were used to
annotate 92,191 sentences from 1,002 interviews in the JAIOH collection. Our
findings show that LLMs can effectively perform semantic and sentiment
annotation across large oral history collections when guided by well-designed
prompts. This study provides a reusable annotation pipeline and practical
guidance for applying LLMs in culturally sensitive archival analysis. By
bridging archival ethics with scalable NLP techniques, this work lays the
groundwork for responsible use of artificial intelligence in digital humanities
and preservation of collective memory. GitHub:
https://github.com/kc6699c/LLM4OralHistoryAnalysis.

</details>


### [36] [Many-Turn Jailbreaking](https://arxiv.org/abs/2508.06755)
*Xianjun Yang,Liqiang Xiao,Shiyang Li,Faisal Ladhak,Hyokun Yun,Linda Ruth Petzold,Yi Xu,William Yang Wang*

Main category: cs.CL

TL;DR: 本研究发现，现有大语言模型在多轮对话中更易被越狱，首次构建了多轮越狱基准测试集MTJ-Bench并进行了系统测试，提醒业界多轮越狱是更现实严重的安全隐患。


<details>
  <summary>Details</summary>
Motivation: 以往的大语言模型（LLM）越狱研究仅关注于针对单一查询的一轮对话，但由于LLM可以支持多轮长对话，因此多轮越狱（multi-turn jailbreaking）可能带来更严重的安全风险。动机在于真实场景中用户常常会进行多轮交流，或连续追问相关问题，现有单轮越狱评测无法覆盖这些场景。

Method: 本文首次提出并系统化研究了多轮越狱，构建了多轮越狱基准测试集（MTJ-Bench），用于评估开源和闭源模型在多轮越狱下的表现，通过让LLM持续接受多轮潜在危险对话，分析模型在更复杂场景下的安全性。

Result: 通过在一系列主流大模型上进行多轮越狱基准测试，发现部分模型在后续轮次中仍然暴露出安全漏洞，更容易持续输出不安全内容，揭示了现有防御手段的局限性。

Conclusion: 多轮越狱对LLM安全性构成了更为严重且真实的威胁。然而当前研究与防护措施主要覆盖单轮情景，对多轮动态对话的保护有限。论文呼吁业界关注多轮越狱问题，以推动更安全的大模型研发。

Abstract: Current jailbreaking work on large language models (LLMs) aims to elicit
unsafe outputs from given prompts. However, it only focuses on single-turn
jailbreaking targeting one specific query. On the contrary, the advanced LLMs
are designed to handle extremely long contexts and can thus conduct multi-turn
conversations. So, we propose exploring multi-turn jailbreaking, in which the
jailbroken LLMs are continuously tested on more than the first-turn
conversation or a single target query. This is an even more serious threat
because 1) it is common for users to continue asking relevant follow-up
questions to clarify certain jailbroken details, and 2) it is also possible
that the initial round of jailbreaking causes the LLMs to respond to additional
irrelevant questions consistently. As the first step (First draft done at June
2024) in exploring multi-turn jailbreaking, we construct a Multi-Turn Jailbreak
Benchmark (MTJ-Bench) for benchmarking this setting on a series of open- and
closed-source models and provide novel insights into this new safety threat. By
revealing this new vulnerability, we aim to call for community efforts to build
safer LLMs and pave the way for a more in-depth understanding of jailbreaking
LLMs.

</details>


### [37] [SEVADE: Self-Evolving Multi-Agent Analysis with Decoupled Evaluation for Hallucination-Resistant Irony Detection](https://arxiv.org/abs/2508.06803)
*Ziqi Liu,Yangbin Chen,Ziyang Zhou,Yilin Li,Mingxuan Hu,Yushan Pan,Zhijie Xu*

Main category: cs.CL

TL;DR: 本文提出SEVADE框架，通过多智能体协作和推理-判决分离机制，显著提升了讽刺检测任务的准确性，减少幻觉现象，实验效果优越。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在复杂讽刺文本处理中存在单一视角、推理路径静态及幻觉风险高等问题，影响其效果和可信度。

Method: 采用基于语言学理论构建的多智能体动态推理引擎DARE，对文本进行多视角解构和推理链生成，同时引入独立轻量级的理由裁决器（RA），仅基于推理链进行最终讽刺判别，实现推理与决策的分离。

Result: 在四个基准数据集上，SEVADE在准确率和Macro-F1上分别平均提升了6.75%和6.29%，达到最新的性能水平。

Conclusion: 提出了一种新的多智能体自我演化分析框架SEVADE，能有效缓解大语言模型在讽刺检测任务中的幻觉问题，并显著提升准确性与可靠性。

Abstract: Sarcasm detection is a crucial yet challenging Natural Language Processing
task. Existing Large Language Model methods are often limited by
single-perspective analysis, static reasoning pathways, and a susceptibility to
hallucination when processing complex ironic rhetoric, which impacts their
accuracy and reliability. To address these challenges, we propose **SEVADE**, a
novel **S**elf-**Ev**olving multi-agent **A**nalysis framework with
**D**ecoupled **E**valuation for hallucination-resistant sarcasm detection. The
core of our framework is a Dynamic Agentive Reasoning Engine (DARE), which
utilizes a team of specialized agents grounded in linguistic theory to perform
a multifaceted deconstruction of the text and generate a structured reasoning
chain. Subsequently, a separate lightweight rationale adjudicator (RA) performs
the final classification based solely on this reasoning chain. This decoupled
architecture is designed to mitigate the risk of hallucination by separating
complex reasoning from the final judgment. Extensive experiments on four
benchmark datasets demonstrate that our framework achieves state-of-the-art
performance, with average improvements of **6.75%** in Accuracy and **6.29%**
in Macro-F1 score.

</details>


### [38] [Annotating Errors in English Learners' Written Language Production: Advancing Automated Written Feedback Systems](https://arxiv.org/abs/2508.06810)
*Steven Coyne,Diana Galvan-Sosa,Ryan Spring,Camélia Guerraoui,Michael Zock,Keisuke Sakaguchi,Kentaro Inui*

Main category: cs.CL

TL;DR: 本文针对面向语言学习的自动写作反馈提出新的错误注释框架与数据集，并评估了多种自动反馈生成方法，结果显示能够显著提升反馈的针对性与教学价值。


<details>
  <summary>Details</summary>
Motivation: 尽管现有自然语言处理驱动的自动写作评估系统（AWE）能有效纠正语法错误，但这些系统更多关注快速直接修正而非促进学习者深度理解。学习者根据错误类型，通常更需要解释或间接提示来掌握可泛化的语法知识。为更好服务于语言学习需求，需要开发能生成个性化间接反馈的信息系统。

Method: 作者提出了一个新的注释框架，专注于建模错误类型及其可泛化性，并引入了一种将学习者错误与具体语法模式关联、洞察知识盲区的分类方法。基于该框架，构建了一个包含人类教师标注的学习者错误及反馈（分为直接修正和提示）的数据集。随后利用大语言模型（LLMs）开展关键词引导、无关键词和模板引导三种自动生成反馈的方法实验，并由教师从相关性、事实性和可理解性等角度评估输出效果。

Result: 作者公开了该注释数据集，并比较了三种基于大语言模型的自动反馈生成方法。结果表明，基于注释框架的方法能够更有效地产生高质量、可泛化的反馈，提升了反馈的相关性及教学价值。论文中详细报告了各系统的表现对比。

Conclusion: 通过构建以通用语法知识点为核心的错误注释与反馈框架，推动了自动写作评估系统向真实语言学习场景适配的进化。实验及人类教师评估证明，该方法有助于更好地生成促进学习者理解和习得的反馈。

Abstract: Recent advances in natural language processing (NLP) have contributed to the
development of automated writing evaluation (AWE) systems that can correct
grammatical errors. However, while these systems are effective at improving
text, they are not optimally designed for language learning. They favor direct
revisions, often with a click-to-fix functionality that can be applied without
considering the reason for the correction. Meanwhile, depending on the error
type, learners may benefit most from simple explanations and strategically
indirect hints, especially on generalizable grammatical rules. To support the
generation of such feedback, we introduce an annotation framework that models
each error's error type and generalizability. For error type classification, we
introduce a typology focused on inferring learners' knowledge gaps by
connecting their errors to specific grammatical patterns. Following this
framework, we collect a dataset of annotated learner errors and corresponding
human-written feedback comments, each labeled as a direct correction or hint.
With this data, we evaluate keyword-guided, keyword-free, and template-guided
methods of generating feedback using large language models (LLMs). Human
teachers examined each system's outputs, assessing them on grounds including
relevance, factuality, and comprehensibility. We report on the development of
the dataset and the comparative performance of the systems investigated.

</details>


### [39] [Text to Speech System for Meitei Mayek Script](https://arxiv.org/abs/2508.06870)
*Gangular Singh Irengbam,Nirvash Singh Wahengbam,Lanthoiba Meitei Khumanthem,Paikhomba Oinam*

Main category: cs.CL

TL;DR: 本文提出基于Tacotron 2和HiFi-GAN的Manipuri语言TTS系统，通过Meitei Mayek到ARPAbet音素映射和单说话人数据集，成功实现了自然且清晰的语音合成，为Manipuri语言的保护和普及奠定了技术基础。


<details>
  <summary>Details</summary>
Motivation: Manipuri语言资源匮乏，且具有独特的声调现象，需要定制TTS系统以促进该语言的保护和技术应用。

Method: 采用Tacotron 2和HiFi-GAN神经网络架构，针对Manipuri语言的声调音系和资源匮乏情况，开发了Meitei Mayek到ARPAbet的音素映射，并构建了单说话人语音数据集。

Result: 主观和客观指标验证了系统能够合成清晰自然的Manipuri语音。

Conclusion: 所提出的Manipuri语言TTS系统能够自然且清晰地生成语音，并对语言保护和技术普及具有推动作用。

Abstract: This paper presents the development of a Text-to-Speech (TTS) system for the
Manipuri language using the Meitei Mayek script. Leveraging Tacotron 2 and
HiFi-GAN, we introduce a neural TTS architecture adapted to support tonal
phonology and under-resourced linguistic environments. We develop a phoneme
mapping for Meitei Mayek to ARPAbet, curate a single-speaker dataset, and
demonstrate intelligible and natural speech synthesis, validated through
subjective and objective metrics. This system lays the groundwork for
linguistic preservation and technological inclusion of Manipuri.

</details>


### [40] [ESNERA: Empirical and semantic named entity alignment for named entity dataset merging](https://arxiv.org/abs/2508.06877)
*Xiaobo Zhang,Congqing He,Ying He,Jian Peng,Dajie Fu,Tien-Ping Tan*

Main category: cs.CL

TL;DR: 针对NER领域数据集整合难题，本文提出了基于标签相似性的自动对齐方法，显著提升了低资源领域的NER性能，是一种高效且可扩展的数据集整合方案。


<details>
  <summary>Details</summary>
Motivation: 命名实体识别（NER）在自然语言处理中非常重要，并且应用广泛。然而，其性能提升高度依赖大量高质量标注数据集，而构建这些数据集的过程既昂贵又耗时。因此，如何高效整合多源数据集，成为当前的研究瓶颈。

Method: 提出了一种基于标签相似性的自动标签对齐方法。该方法结合经验和语义相似性，采用贪心的两两合并策略，对不同数据集的标签空间进行统一。研究分为两个实验阶段：首先合并三个现有NER数据集，后将统一语料与金融领域小规模自建数据集整合。

Result: 实验结果显示，该方法能高效合并数据集，并在金融领域低资源背景下提升NER任务性能。

Conclusion: 本研究提出了一种高效、可解释且可扩展的数据集整合方法，可有效促进多源NER语料的深度融合，推动低资源领域NER性能提升。

Abstract: Named Entity Recognition (NER) is a fundamental task in natural language
processing. It remains a research hotspot due to its wide applicability across
domains. Although recent advances in deep learning have significantly improved
NER performance, they rely heavily on large, high-quality annotated datasets.
However, building these datasets is expensive and time-consuming, posing a
major bottleneck for further research. Current dataset merging approaches
mainly focus on strategies like manual label mapping or constructing label
graphs, which lack interpretability and scalability. To address this, we
propose an automatic label alignment method based on label similarity. The
method combines empirical and semantic similarities, using a greedy pairwise
merging strategy to unify label spaces across different datasets. Experiments
are conducted in two stages: first, merging three existing NER datasets into a
unified corpus with minimal impact on NER performance; second, integrating this
corpus with a small-scale, self-built dataset in the financial domain. The
results show that our method enables effective dataset merging and enhances NER
performance in the low-resource financial domain. This study presents an
efficient, interpretable, and scalable solution for integrating multi-source
NER corpora.

</details>


### [41] [The ReQAP System for Question Answering over Personal Information](https://arxiv.org/abs/2508.06880)
*Philipp Christmann,Gerhard Weikum*

Main category: cs.CL

TL;DR: ReQAP系统帮助用户对设备中的各种数据进行复杂查询，递归拆分问题和运算树追踪保证结果可靠，语言模型智能辅助问题解析，充分提升用户体验和信任。


<details>
  <summary>Details</summary>
Motivation: 用户设备上有大量结构化与非结构化的个人数据，用户需要能够跨异构来源、进行过滤、连接与聚合的复杂查询，并且要保证结果的可解释性和可靠性。

Method: ReQAP采用递归问题分解与运算树增量构建，将轻量化语言模型用于问题理解及各运算符，并通过精细化微调提升效果。

Result: 实现了复杂问题支持、丰富演示功能，以及详细追踪操作过程，可将答案溯源至底层数据，增强系统的可理解性和用户信任。

Conclusion: ReQAP系统能够有效支持用户查询复杂问题，并通过递归分解与可追踪的执行过程提升答案可解释性和用户信任。

Abstract: Personal information is abundant on users' devices, from structured data in
calendar, shopping records or fitness tools, to unstructured contents in mail
and social media posts. This works presents the ReQAP system that supports
users with answers for complex questions that involve filters, joins and
aggregation over heterogeneous sources. The unique trait of ReQAP is that it
recursively decomposes questions and incrementally builds an operator tree for
execution. Both the question interpretation and the individual operators make
smart use of light-weight language models, with judicious fine-tuning. The demo
showcases the rich functionality for advanced user questions, and also offers
detailed tracking of how the answers are computed by the operators in the
execution tree. Being able to trace answers back to the underlying sources is
vital for human comprehensibility and user trust in the system.

</details>


### [42] [Score Before You Speak: Improving Persona Consistency in Dialogue Generation using Response Quality Scores](https://arxiv.org/abs/2508.06886)
*Arpita Saggar,Jonathan C. Darling,Vania Dimitrova,Duygu Sarikaya,David C. Hogg*

Main category: cs.CL

TL;DR: 作者提出SBS框架，通过给扩展回复加分并用分数辅助训练，大幅提升了模型生成个性化对话的能力，实验显示其优于传统方法，并证实输入分数至关重要。


<details>
  <summary>Details</summary>
Motivation: 个性化对话生成对于构建会话型人工智能至关重要，但由于已有对话数据多样性有限，实现高个性一致性依然具有挑战。

Method: 提出了SBS（Score-Before-Speaking）框架，通过在训练阶段将扩充后的回复与质量分数相关联，并在推理时利用此知识。扩展方法为基于名词替换，质量评分则采用语义相似度。

Result: SBS框架在百万级和十亿级参数模型上都优于现有方法，在PERSONA-CHAT与ConvAI2数据集上的实验表明，基于分数的训练能够促进模型更好地生成符合角色特质的对话。消融实验验证了训练时在输入提示中加入分数优于传统方式。

Conclusion: 通过引入评分机制与扩充方法，所提SBS框架显著提升了个性一致性对话生成的质量。

Abstract: Persona-based dialogue generation is an important milestone towards building
conversational artificial intelligence. Despite the ever-improving capabilities
of large language models (LLMs), effectively integrating persona fidelity in
conversations remains challenging due to the limited diversity in existing
dialogue data. We propose a novel framework SBS (Score-Before-Speaking), which
outperforms previous methods and yields improvements for both million and
billion-parameter models. Unlike previous methods, SBS unifies the learning of
responses and their relative quality into a single step. The key innovation is
to train a dialogue model to correlate augmented responses with a quality score
during training and then leverage this knowledge at inference. We use
noun-based substitution for augmentation and semantic similarity-based scores
as a proxy for response quality. Through extensive experiments with benchmark
datasets (PERSONA-CHAT and ConvAI2), we show that score-conditioned training
allows existing models to better capture a spectrum of persona-consistent
dialogues. Our ablation studies also demonstrate that including scores in the
input prompt during training is superior to conventional training setups. Code
and further details are available at
https://arpita2512.github.io/score_before_you_speak

</details>


### [43] [Model-Agnostic Sentiment Distribution Stability Analysis for Robust LLM-Generated Texts Detection](https://arxiv.org/abs/2508.06913)
*Siyuan Li,Xi Lin,Guangyan Li,Zehao Liu,Aodu Wulianghai,Li Ding,Jun Wu,Jianhua Li*

Main category: cs.CL

TL;DR: 本文提出了基于情感分布波动分析的LLM文本检测新方法SentiDetect，在多个模型和数据集上优于现有方法，并在多种复杂场景下表现出更高的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的迅速发展，AI生成内容日益复杂，导致人类难以区分模型生成文本与真人写作。现有检测方法泛化能力有限，容易被改写、对抗攻击和领域转移规避。

Method: 提出了SentiDetect框架，通过分析生成文本和人写文本在情感分布稳定性上的差异实现检测。定义了两个互补的指标：情感分布一致性和情感分布保持性，用以量化文本在情感和语义变换下的稳定性。该方法适用于多种模型（模型无关）。

Result: 在Gemini-1.5-Pro、Claude-3、GPT-4-0613和LLaMa-3.3等先进LLMs及五个数据集上测试，SentiDetect比当前最优检测方法F1分数提升超16%（Gemini-1.5-Pro）和11%（GPT-4-0613）；对改写、攻击、文本长度变化更具鲁棒性。

Conclusion: SentiDetect有效利用情感分布稳定性差异，以模型无关的方式提升了LLM生成文本检测性能，并显著增强了鲁棒性，优于现有检测器。

Abstract: The rapid advancement of large language models (LLMs) has resulted in
increasingly sophisticated AI-generated content, posing significant challenges
in distinguishing LLM-generated text from human-written language. Existing
detection methods, primarily based on lexical heuristics or fine-tuned
classifiers, often suffer from limited generalizability and are vulnerable to
paraphrasing, adversarial perturbations, and cross-domain shifts. In this work,
we propose SentiDetect, a model-agnostic framework for detecting LLM-generated
text by analyzing the divergence in sentiment distribution stability. Our
method is motivated by the empirical observation that LLM outputs tend to
exhibit emotionally consistent patterns, whereas human-written texts display
greater emotional variability. To capture this phenomenon, we define two
complementary metrics: sentiment distribution consistency and sentiment
distribution preservation, which quantify stability under sentiment-altering
and semantic-preserving transformations. We evaluate SentiDetect on five
diverse datasets and a range of advanced LLMs,including Gemini-1.5-Pro,
Claude-3, GPT-4-0613, and LLaMa-3.3. Experimental results demonstrate its
superiority over state-of-the-art baselines, with over 16% and 11% F1 score
improvements on Gemini-1.5-Pro and GPT-4-0613, respectively. Moreover,
SentiDetect also shows greater robustness to paraphrasing, adversarial attacks,
and text length variations, outperforming existing detectors in challenging
scenarios.

</details>


### [44] [Two-Stage Quranic QA via Ensemble Retrieval and Instruction-Tuned Answer Extraction](https://arxiv.org/abs/2508.06971)
*Mohamed Basem,Islam Oshallah,Ali Hamdi,Khaled Shaban,Hozaifa Kassab*

Main category: cs.CL

TL;DR: 该论文针对古兰经问答面临的语言和语义复杂性，提出两阶段框架：集成阿拉伯语模型进行检索、指令微调大模型进行抽取，结合少样本提升低资源领域效果，并在相关竞赛任务上取得领先结果。


<details>
  <summary>Details</summary>
Motivation: 古兰经的问答系统因古典阿拉伯语的语言复杂性和宗教文本的语义丰富性而面临独特挑战，亟需更高效的方法提升问答准确性。

Method: 提出了一个创新的两阶段框架：第一阶段通过集成微调的阿拉伯语模型实现高效文本检索；第二阶段利用指令微调的大型语言模型结合少量示例提示，解决命题微调数据量小的局限。

Result: 在Quran QA 2023 Shared Task中取得了前沿的成绩：文本检索MAP@10为0.3128，MRR@10为0.5763，答案抽取pAP@10为0.669，明显优于先前方法。

Conclusion: 模型集成与指令微调大型语言模型相结合，能有效应对特定领域低资源问答的诸多挑战，提升古兰经问答系统的性能。

Abstract: Quranic Question Answering presents unique challenges due to the linguistic
complexity of Classical Arabic and the semantic richness of religious texts. In
this paper, we propose a novel two-stage framework that addresses both passage
retrieval and answer extraction. For passage retrieval, we ensemble fine-tuned
Arabic language models to achieve superior ranking performance. For answer
extraction, we employ instruction-tuned large language models with few-shot
prompting to overcome the limitations of fine-tuning on small datasets. Our
approach achieves state-of-the-art results on the Quran QA 2023 Shared Task,
with a MAP@10 of 0.3128 and MRR@10 of 0.5763 for retrieval, and a pAP@10 of
0.669 for extraction, substantially outperforming previous methods. These
results demonstrate that combining model ensembling and instruction-tuned
language models effectively addresses the challenges of low-resource question
answering in specialized domains.

</details>


### [45] [Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models](https://arxiv.org/abs/2508.06974)
*Zhijun Tu,Hanting Chen,Siqi Liu,Chuanjian Liu,Jian Li,Jie Hu,Yunhe Wang*

Main category: cs.CL

TL;DR: 本论文提出渐进式1-bit量化方法，有效利用预训练LLM，通过新型初始化和补偿手段，在大幅降低存储/计算成本的同时，取得优异性能，无需从头训练，远超传统1-bit方法。


<details>
  <summary>Details</summary>
Motivation: 1-bit量化能大幅降低LLM的存储和计算成本，但现有方法一般只能从头训练1-bit LLM，无法利用已有的大规模预训练模型，导致训练成本高且精度损失显著。这一问题的主要根源在于全精度和1-bit表示之间差距过大，直接适配十分困难。

Method: 提出了一种一致性的渐进式（progressive）训练方法，应用于正向和反向过程，能够平滑地将浮点权重逐步转换为二值权重；此外引入了二值化感知的初始化和双尺度补偿（dual-scaling compensation）机制，降低渐进训练难度并提升模型性能。

Result: 实验表明，该方法在多种规模的LLM上优于现有方法。使用预训练模型进行鲁棒1-bit量化，获得高性能的1-bit LLM，无需再花费巨额开销从头训练。

Conclusion: 通过一致性的渐进式训练、特定初始化和补偿机制，可以利用已有预训练模型，显著提升1-bit LLM量化后的性能，同时大幅降低训练成本，突破了原先1-bit量化需从头训练、损失严重的瓶颈。

Abstract: 1-bit LLM quantization offers significant advantages in reducing storage and
computational costs. However, existing methods typically train 1-bit LLMs from
scratch, failing to fully leverage pre-trained models. This results in high
training costs and notable accuracy degradation. We identify that the large gap
between full precision and 1-bit representations makes direct adaptation
difficult. In this paper, we introduce a consistent progressive training for
both forward and backward, smoothly converting the floating-point weights into
the binarized ones. Additionally, we incorporate binary-aware initialization
and dual-scaling compensation to reduce the difficulty of progressive training
and improve the performance. Experimental results on LLMs of various sizes
demonstrate that our method outperforms existing approaches. Our results show
that high-performance 1-bit LLMs can be achieved using pre-trained models,
eliminating the need for expensive training from scratch.

</details>


### [46] [Vec2Summ: Text Summarization via Probabilistic Sentence Embeddings](https://arxiv.org/abs/2508.07017)
*Mao Li,Fred Conrad,Johann Gagnon-Bartsch*

Main category: cs.CL

TL;DR: Vec2Summ用平均嵌入压缩语料库语义，并通过反解获得文本摘要，在摘要质量和效率上接近主流大模型，尤其适合关注语义、规模和可控性的应用场景。


<details>
  <summary>Details</summary>
Motivation: 当前大模型（LLM）生成的摘要方法存在限制，如上下文长度有限、可解释性和可控性弱，以及难以高效扩展到大规模语料库。

Method: Vec2Summ方法将摘要生成建模为语义压缩过程，使用文档集合的平均嵌入向量来表示语料，再通过生成式模型将该语义向量反解成流畅的自然语言摘要。为提升摘要多样性和鲁棒性，方法中引入以平均向量为中心的高斯随机采样。

Result: 实验证明，Vec2Summ在主题集中的语料上能生成连贯、主题覆盖良好的摘要，效率与直接LLM摘要相当，但细节层面略逊一筹。

Conclusion: Vec2Summ在需要语义控制、可扩展性和语料级抽象的场景下，展现了应用潜力。

Abstract: We propose Vec2Summ, a novel method for abstractive summarization that frames
the task as semantic compression. Vec2Summ represents a document collection
using a single mean vector in the semantic embedding space, capturing the
central meaning of the corpus. To reconstruct fluent summaries, we perform
embedding inversion -- decoding this mean vector into natural language using a
generative language model. To improve reconstruction quality and capture some
degree of topical variability, we introduce stochasticity by sampling from a
Gaussian distribution centered on the mean. This approach is loosely analogous
to bagging in ensemble learning, where controlled randomness encourages more
robust and varied outputs. Vec2Summ addresses key limitations of LLM-based
summarization methods. It avoids context-length constraints, enables
interpretable and controllable generation via semantic parameters, and scales
efficiently with corpus size -- requiring only $O(d + d^2)$ parameters.
Empirical results show that Vec2Summ produces coherent summaries for topically
focused, order-invariant corpora, with performance comparable to direct LLM
summarization in terms of thematic coverage and efficiency, albeit with less
fine-grained detail. These results underscore Vec2Summ's potential in settings
where scalability, semantic control, and corpus-level abstraction are
prioritized.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [47] [Optimal Representation for Right-to-Left Parallel Scalar Point Multiplication](https://arxiv.org/abs/2508.07310)
*Kittiphon Phalakarn,Kittiphop Phalakarn,Vorapong Suppakitpaisarn*

Main category: cs.DM

TL;DR: 本文针对右到左并行椭圆曲线标量乘法，提出并分析了最优数表示方法，发现传统NAF已几乎达最优，新表示方法提升空间不到1%。


<details>
  <summary>Details</summary>
Motivation: 右到左并行椭圆曲线标量乘法虽然更易并行，但之前缺少针对该算法的数表示优化研究，本文弥补了此空白。

Method: 通过简化Robert的实现，建立了数学模型来分析计算时间，然后为任意加倍和加法时间，提出了生成数表示的算法以最小化模型中的时间。

Result: 实验证明，改进后的数表示方法在提升并行计算性能上非常有限，传统的NAF表示基本已达到最优。

Conclusion: 传统的NAF数表示在右到左并行椭圆曲线标量乘法中几乎是最优的，任何新提出的表示方法在并行计算时间上提升不到1%。

Abstract: This paper introduces an optimal representation for a right-to-left parallel
elliptic curve scalar point multiplication. The right-to-left approach is
easier to parallelize than the conventional left-to-right approach. However,
unlike the left-to-right approach, there is still no work considering number
representations for the right-to-left parallel calculation. By simplifying the
implementation by Robert, we devise a mathematical model to capture the
computation time of the calculation. Then, for any arbitrary amount of doubling
time and addition time, we propose algorithms to generate representations which
minimize the time in that model. As a result, we can show a negative result
that a conventional representation like NAF is almost optimal. The parallel
computation time obtained from any representation cannot be better than NAF by
more than 1%.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [48] [Hexagonal Picture Scanning Automata](https://arxiv.org/abs/2508.07779)
*Deepalakshmi D,Lisa Mathew*

Main category: cs.FL

TL;DR: 本文提出并系统分析了用于六边形网格的两类新型有限自动机，丰富了二维自动机理论，并揭示了其在语言识别和结构遍历上的新特性及理论关系。


<details>
  <summary>Details</summary>
Motivation: 传统有限自动机主要基于线性结构，二维自动机理论不断发展，但在六边形网格上运行的自动机模型未被充分研究。研究者希望扩展自动机理论到更复杂的几何结构，以支持特殊的遍历模式和理论分析。

Method: 提出并分析了两类新的有限自动机：普通六边形往返型有限自动机和普通六边形回返型有限自动机。这些自动机在六边形网格上运行，论文通过理论推导和模型定义分析了其计算性质、运行模式，并探讨了这些自动机所定义的语言族之间的关系与等价性。

Result: 论文建立了这两类自动机的理论基础，明确了其操作和特性。分析了它们之间语言表达能力的关系，提出了若干等价性和差异，为后续的相关研究提供了理论支持。

Conclusion: 六边形网格上的有限自动机拓展了二维自动机理论的边界，展现了新的计算能力和语言处理方法，对于理解和分析复杂几何遍历具有重要意义。

Abstract: Two new classes of finite automata, called General hexagonal Boustrophedon
finite automata and General hexagonal returning finite automata operating on
hexagonal grids, are introduced and analyzed. The work establishes the
theoretical foundations for these automata models, examines their computational
properties, and investigates the relationships and equivalences between the
language families they define. The research contributes to the broader
understanding of two-dimensional automata theory by extending classical finite
automaton concepts to hexagonal geometric structures with specialized traversal
patterns.

</details>
