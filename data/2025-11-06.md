<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 19]
- [cs.CL](#cs.CL) [Total: 37]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Analysis of AdvFusion: Adapter-based Multilingual Learning for Code Large Language Models](https://arxiv.org/abs/2511.02869)
*Amirreza Esmaeili,Fahd Seddik,Yongyi Ji,Fatemeh Fard,Fuxiang Chen*

Main category: cs.SE

TL;DR: 提出并扩展了AdvFusion多语言PEFT方法，在三项任务和多种模型中评测，结果显示各PEFT方法优劣依赖具体任务与模型，未有绝对优胜，需具体问题具体分析。


<details>
  <summary>Details</summary>
Motivation: 编程语言之间通过语言模型进行知识转移，可以提升软件工程任务的表现。此前PEFT方法（如AdapterFusion）虽能融合多语言信息，但主要关注目标语言，仍有改进空间。作者欲探索能更有效利用多语言知识的PEFT架构。

Method: 提出并扩展了一种新的PEFT方法AdvFusion：先从其他编程语言学习，再适应目标任务。该方法由原本应用于预训练Code-LM及两项任务，拓展到Code-LLM及三项新任务（代码生成、代码翻译、提交信息生成），并与其他PEFT方法（AdapterFusion、LoRA、Compacter、TaskAdapter）进行全面比较。

Result: 三项任务中，不同模型与任务表现各异：代码生成任务，AdvFusion优于AdapterFusion，但不如其他PEFT方法；提交信息生成任务，AdapterFusion优于AdvFusion，且其他PEFT方法无优势；代码翻译任务，AdvFusion整体逊于AdapterFusion，且随模型增大差距加大，其他PEFT方法则表现更好。

Conclusion: AdvFusion在多任务和模型下并非总是最优，不同任务和模型对PEFT方法敏感性强，最佳方法需结合任务与模型特性选择。扩展后的评估揭示了多语言知识转移在不同Code-LLM场景下的复杂性。

Abstract: Programming languages can benefit from one another by utilizing a language
model for software engineering tasks. Full fine-tuning and Parameter Efficient
Fine-Tuning (PEFT) of Code Language Models (Code-LMs) has been explored for
multilingual knowledge transfer. AdapterFusion is a PEFT architecture that aims
to enhance task performance by leveraging information from multiple programming
languages, but primarily focuses on the target programming language.
  In our previous work, we proposed AdvFusion, a novel PEFT-based approach that
effectively learns from other programming languages before adapting to the
target task. Though previous experiments showed that AdvFusion outperformed
AdapterFusion and LoRA, it was applied on pre-trained Code-LMs and was limited
to only two tasks, code summarization and method name prediction. In this
study, we expanded our work and investigated AdvFusion on Code Large Language
Models (Code-LLMs), considering three new tasks: code generation, code
translation, and commit message generation. We observed that different
Code-LLMs/tasks exhibit different characteristics. In code generation,
AdvFusion outperformed AdapterFusion but not other PEFT methods (LoRA,
Compacter, and TaskAdapter). In commit message generation, AdapterFusion
performed better than AdvFusion, and contrary to code generation, we found that
the other PEFT methods do not have better performance. In code translation,
AdvFusion performed worse than AdapterFusion overall, with the performance gap
marginally widening as the model size increases. However, consistent with code
generation, other PEFT methods showed better performance.

</details>


### [2] [SELF-REDRAFT: Eliciting Intrinsic Exploration-Exploitation Balance in Test-Time Scaling for Code Generation](https://arxiv.org/abs/2511.02854)
*Yixiang Chen,Tianshi Zheng,Shijue Huang,Zhitao He,Yi R. Fung*

Main category: cs.SE

TL;DR: 提出SELF-REDRAFT，用于在无测试用例场景下提升代码生成的探索-利用平衡，比已有方法表现更好，但反馈和判别能力仍需提升，是未来优化关键。


<details>
  <summary>Details</summary>
Motivation: 实际代码生成中，测试用例往往缺失，因此急需无需解释器反馈的测试时扩展能力。但现有范式在探索（采样）和利用（贪婪精炼）之间、平衡机制研究不足。

Method: 提出了SELF-REDRAFT框架，在Self-Refine基础上引导模型自我发现并重新拟定根本性错误的解答，并在不同大模型上对比了迭代收敛表现。

Result: SELF-REDRAFT在同等迭代限制下，性能优于Self-Refine，但模型在生成有效反馈和区分判断上仍存在明显不足；不同大模型平衡策略表现也各异。

Conclusion: 本研究建立了一个基线，探索了大模型在测试时无需解释器反馈场景下，平衡探索与利用的能力；并指出有效反馈生成和判别能力是当前自重写方法的主要瓶颈。

Abstract: Test-time scaling without interpreter feedback is essential for real-world
code generation scenarios where test cases are not readily available. While
existing paradigms often rely on either greedy exploitation (i.e., iterative
refinement) or stochastic exploration (i.e., relying on sample-based voting or
reranking mechanisms), the balance between these two dimensions remains
underexplored. To investigate the LLM's intrinsic ability to balance
exploitation and exploration, we introduce SELF-REDRAFT, a framework built upon
Self-Refine that encourages the model to propose new drafts for solutions that
are fundamentally flawed. Our results show that SELF-REDRAFT consistently
achieves better performance than Self-Refine when converged under the same
maximum number of iterations. Still, we observe that significant room for
improvement remains, largely due to two core aspects of current self-redraft
capabilities: constrained capacity for generating instructive feedback and
fragile discriminative judgment. We also find that balancing strategies vary
notably across different LLMs, reflecting distinct, model-specific behaviors.
Overall, our study establishes a baseline for intrinsic
exploration-exploitation balancing in test-time scaling and identifies feedback
and discrimination as key areas with potential for future advances.

</details>


### [3] [The Evolution of Agile and Hybrid Project Management Methodologies: A Systematic Literature Review](https://arxiv.org/abs/2511.02859)
*Bianca Leech,Ridewaan Hanslo*

Main category: cs.SE

TL;DR: IT项目管理从敏捷迈向混合模型，因传统方法和纯敏捷各有不足。系统综述显示，混合方法优势在于灵活与治理并重，成功离不开领导推动、流程适配及持续优化，应根据实际情况灵活应用。


<details>
  <summary>Details</summary>
Motivation: IT项目快速发展，传统瀑布和敏捷方法各有局限，而混合方法逐渐兴起。研究动机在于探究混合方法演化背景、面临的挑战及成功因素，为组织迁移混合管理提供理论与实践指导。

Method: 采用系统性文献综述方法，依据PRISMA流程，分析过去8年内的同行评议文献，归纳敏捷向混合项目管理方法的演化、挑战与成功要素。

Result: 混合方法因敏捷不适用于大型和高监管场景而出现，融合了敏捷的灵活性与传统方法的治理结构。敏捷推行存在挑战，成功依赖于领导支持、流程定制和持续改进。应用混合方法需根据具体情景调整，而非僵化套用。

Conclusion: 本研究强调在大型或受监管环境中，纯敏捷方法存在局限性，混合方法成为更优解决方案。关键成功因素包括领导支持、流程定制化整合以及持续改进机制。过于僵化的项目管理框架难以适应多变的实践环境，需注重情境适配。

Abstract: The rapid evolution of IT projects has driven the transformation of project
management methodologies, from traditional waterfall approaches to agile
frameworks and, more recently, hybrid models. This systematic literature review
investigates the evolution of agile methodologies into hybrid frameworks,
analysing their implementation challenges and success factors. We identify key
trends through PRISMA-guided analysis of peer-reviewed studies from the last 8
years. Hybrid methodologies emerge from agile limitations in large-scale and
regulated environments, combining iterative flexibility with structured
governance. Agile has several implementation challenges, leading to hybrid
methods, and the success hinges on leadership support, tailored process
integration, and continuous improvement mechanisms. The study explores the need
for contextual adaptation over rigid frameworks, offering practical insights
for organisations navigating hybrid transitions.

</details>


### [4] [LM-Fix: Lightweight Bit-Flip Detection and Rapid Recovery Framework for Language Models](https://arxiv.org/abs/2511.02866)
*Ahmad Tahmasivand,Noureldin Zahran,Saba Al-Sayouri,Mohammed Fouda,Khaled N. Khasawneh*

Main category: cs.SE

TL;DR: 提出了一套轻量级框架LM-Fix，可高效检测和快速修复LLM运行时bit-flip故障，检测率高、性能开销小，恢复速度显著优于传统方法，适用于实际生产部署。


<details>
  <summary>Details</summary>
Motivation: 随着大模型（LLMs）在实际应用中的普及，模型在运行过程中暴露于硬件故障（如bit-flip）带来的风险不断上升，现有的完整性保护方法对LLMs来说要么计算开销太大，要么检测和恢复速度过慢，难以满足生产环境的需求。

Method: 提出了LM-Fix框架，通过实现轻量级的检测（短测试向量检测+基于哈希的校验）以发现bit-flip故障，并在不重新加载整个模型的情况下快速进行局部修复。

Result: 在多种模型测试中，LM-Fix能够检测94%以上的单bit-flip故障（TVL=200），几乎100%检测到多bit-flip故障，运行时开销约1%-7.7%；恢复速度比重新加载快100倍以上。

Conclusion: LM-Fix为大模型提供了一种可行的、低开销的可靠性保障方案，能有效、迅速检测和修复bit-flip类故障，显著提升生产环境下LLMs的稳定性与可用性。

Abstract: This paper presents LM-Fix, a lightweight detection and rapid recovery
framework for faults in large language models (LLMs). Existing integrity
approaches are often heavy or slow for modern LLMs. LM-Fix runs a short
test-vector pass and uses hash-guided checks to detect bit-flip faults, then
repairs them locally without a full reload. Across multiple models, it detects
over 94% of single-bit flips at TVL=200 and nearly 100% of multi-bit flips with
approximately 1% to 7.7% runtime overhead; recovery is more than 100x faster
than reloading. These results show a practical, low-overhead solution to keep
LLMs reliable in production

</details>


### [5] [An Analysis of Early-Stage Functional Safety Analysis Methods and Their Integration into Model-Based Systems Engineering](https://arxiv.org/abs/2511.02874)
*Jannatul Shefa,Taylan G. Topcu*

Main category: cs.SE

TL;DR: 对三种安全分析方法（FMEA、FHA、FFIP）进行对比，发现FFIP更适合现代系统。MBSE集成主要聚焦FMEA，尚无统一框架，未来可推更协同的安全管理模式。


<details>
  <summary>Details</summary>
Motivation: 随着系统复杂度增加，早期进行有效的安全分析对于风险识别和缓解至关重要，论文旨在探索主流安全分析方法及其与MBSE集成现状。

Method: 采用两阶段方法，第一阶段比较FMEA、FHA和FFIP技术及优缺点，第二阶段回顾各自与MBSE集成的研究进展。

Result: FFIP在识别新兴系统行为和故障传播方面更适合现代系统；MBSE集成主要集中在FMEA，FHA和FFIP集成尚处起步阶段；FMEA与MBSE集成有多种模式，但尚无统一标准框架。

Conclusion: 目前FFIP在识别系统行为和故障传播方面表现更优，MBSE集成多数聚焦于FMEA，但尚无统一框架，未来可开发更协同的安全管理工具以推动数字工程发展。

Abstract: As systems become increasingly complex, conducting effective safety analysis
in the earlier phases of a system's lifecycle is essential to identify and
mitigate risks before they escalate. To that end, this paper investigates the
capabilities of key safety analysis techniques, namely: Failure Mode and
Effects Analysis (FMEA), Functional Hazard Analysis (FHA), and Functional
Failure Identification and Propagation (FFIP), along with the current state of
the literature in terms of their integration into Model-Based Systems
Engineering (MBSE). A two-phase approach is adopted. The first phase is focused
on contrasting FMEA, FHA, and FFIP techniques, examining their procedures,
along with a documentation of their relative strengths and limitations. Our
analysis highlights FFIP's capability in identifying emergent system behaviors,
second-order effects, and fault propagation; thus, suggesting it is better
suited for the safety needs of modern interconnected systems. Second, we review
the existing research on the efforts to integrate each of these methods into
MBSE. We find that MBSE integration efforts primarily focus on FMEA, and
integration of FHA and FFIP is nascent. Additionally, FMEA-MBSE integration
efforts could be organized into four categories: model-to-model transformation,
use of external customized algorithms, built-in MBSE packages, and manual use
of standard MBSE diagrams. While our findings indicate a variety of MBSE
integration approaches, there is no universally established framework or
standard. This leaves room for an integration approach that could support the
ongoing Digital Engineering transformation efforts by enabling a more
synergistic lifecycle safety management methods and tools.

</details>


### [6] [CS Educator challenges and their solutions : A systematic mapping study](https://arxiv.org/abs/2511.02876)
*Anjali Chouhan,Sruti Srinivasa Ragavan,Amey Karkare*

Main category: cs.SE

TL;DR: 本文系统综述了近五年CS教育中教师面临的主要挑战及应对措施，总结了已关注和不足领域，为改进教育实践和政策提供依据。


<details>
  <summary>Details</summary>
Motivation: 尽管计算机科学教育迅速发展，教师在教学中仍遇到诸多挑战，现有关于这些挑战和解决办法的分类与系统化研究较少，导致某些领域缺乏关注。作者希望系统梳理相关文献以填补这一空白。

Method: 作者通过结构化文献综述，系统梳理了近五年同行评审论文，围绕十个主题（如教学法、情感、技术与制度等）分类总结CS教育面临的挑战及应对措施。

Result: 研究揭示了评估方式、师资培训、课堂管理和情感健康等方面的重复性问题，以及通过教师专业发展计划、政策干预等手段进行缓解的多种策略。同时，发现部分领域关注不足。

Conclusion: 本研究为CS教育领域的挑战与对策提供了系统性认识，有助于为未来研究、课程设计和政策制定提供参考，以提升教学效果和教师支持。

Abstract: Computer Science (CS) education is expanding rapidly, but educators continue
to face persistent challenges in teaching and learning environments.Despite
growing interest, limited systematic work exists to categorize and synthesize
the specific challenges faced by CS educators and the remedies adopted in
response.This is problematic because it remains unclear which areas have been
thoroughly addressed and which still lack sufficient scholarly attention. In
this study, we conducted a structured literature review of peer-reviewed
research papers published over the last five years, focusing on challenges and
remedies across ten categorized themes, including pedagogical, emotional,
technological, and institutional dimensions.Our analysis revealed recurring
issues in areas such as assessment practices, teacher training, classroom
management, and emotional well-being, along with various strategies such as
professional development programs and policy interventions adopted to mitigate
them while also revealing several areas that have received insufficient
attention.This review offers a consolidated understanding of the CS education
landscape, providing valuable insights for researchers, curriculum designers,
and policymakers aiming to improve teaching effectiveness and educator support.

</details>


### [7] [AgentSLA : Towards a Service Level Agreement for AI Agents](https://arxiv.org/abs/2511.02885)
*Gwendal Jouneaux,Jordi Cabot*

Main category: cs.SE

TL;DR: AI代理在软件中日益重要，但其质量保障难以实现。本文结合ISO/IEC 25010标准，提出质量模型和SLA定义语言，为AI代理服务提供更好的质量管理方案。


<details>
  <summary>Details</summary>
Motivation: 随着AI组件在各类软件系统中扮演关键角色，AI Agent的自主性和服务模式变化带来新的开发和质量保障难题，尤其是在高质量和可控性要求下，现有方法无法有效定义和保障AI代理服务的质量。

Method: 通过分析现有AI代理开发支持的不足，结合ISO/IEC 25010国际标准，构建了AI代理的质量模型，并设计了一种领域专用语言来规范SLA的定义。

Result: 提出的质量模型和SLA定义语言为AI代理的质量保障和服务级别管理提供了系统性解决方案，可提升智能软件系统的可控性和可靠性。

Conclusion: 本文提出了一个基于ISO/IEC 25010标准的AI代理质量模型，并开发了一种用于支持定义AI代理服务SLA的领域专用语言，以应对智能软件系统开发中AI组件质量保障的挑战。

Abstract: AI components are increasingly becoming a key element of all types of
software systems to enhance their functionality. These AI components are often
implemented as AI Agents, offering more autonomy than a plain integration of
Large Language Models (LLMs), moving from a Model-as-a-Service paradigm to an
Agent-as-a-Service one, bringing new challenges to the development of smart
software systems. Indeed, while support for the design, implementation, and
deployment of those agents exist, the specification of Quality of Service (QoS)
and definition of Service Level Agreements (SLAs) aspects for those agents,
important to ensure the quality of the resulting systems, remains an open
challenge. Part of this is due to the difficulty to clearly define quality in
the context of AI components, resulting in a lack of consensus on how to best
approach Quality Assurance (QA) for these types of systems. To address this
challenge, this paper proposes both a quality model for AI agents based on the
ISO/IEC 25010 standard, and a domain specific language to support the
definition of SLAs for the services provided by these AI agents.

</details>


### [8] [Comprehension-Performance Gap in GenAI-Assisted Brownfield Programming: A Replication and Extension](https://arxiv.org/abs/2511.02922)
*Yunhan Qiao,Christopher Hundhausen,Summit Haque,Md Istiak Hossain Shihab*

Main category: cs.SE

TL;DR: Copilot能让开发者在遗留代码上更快地完成任务，但理解代码的能力并未同步提升，对教育和工具设计需关注这一差距。


<details>
  <summary>Details</summary>
Motivation: 理解生成式AI（如GitHub Copilot）对开发者在维护和增强遗留代码库时，代码理解和开发效率的实际影响。

Method: 采用被试内实验设计，18名计算机科学研究生分别在有与没有Copilot辅助下完成功能实现任务，评估他们的表现和对代码库的理解。

Result: Copilot能显著缩短任务用时，提升通过的测试用例数，但并未提升代码理解分数。代码性能和理解之间未体现出相关性，即使用Copilot后，参与者完成任务更快更好，但并不意味着对遗留代码理解能力增强。

Conclusion: 生成式AI工具虽有助于提升在遗留代码库中的开发效率，但并不会带来对代码更深的理解。这对编程教育和AI工具设计有重要启示。

Abstract: Code comprehension is essential for brownfield programming tasks, in which
developers maintain and enhance legacy code bases. Generative AI (GenAI) coding
assistants such as GitHub Copilot have been shown to improve developer
productivity, but their impact on code understanding is less clear. We
replicate and extend a previous study by exploring both performance and
comprehension in GenAI-assisted brownfield programming tasks. In a
within-subjects experimental study, 18 computer science graduate students
completed feature implementation tasks with and without Copilot. Results show
that Copilot significantly reduced task time and increased the number of test
cases passed. However, comprehension scores did not differ across conditions,
revealing a comprehension-performance gap: participants passed more test cases
with Copilot, but did not demonstrate greater understanding of the legacy
codebase. Moreover, we failed to find a correlation between comprehension and
task performance. These findings suggest that while GenAI tools can accelerate
programming progress in a legacy codebase, such progress may come without an
improved understanding of that codebase. We consider the implications of these
findings for programming education and GenAI tool design.

</details>


### [9] [Risk Estimation in Differential Fuzzing via Extreme Value Theory](https://arxiv.org/abs/2511.02927)
*Rafael Baez,Alejandro Olivas,Nathan K. Diamond,Marcelo Frias,Yannic Noller,Saeid Tizpaz-Niari*

Main category: cs.SE

TL;DR: 本文提出将极值理论应用于差分模糊测试，能够更好评估遗漏缺陷风险，并在真实项目中节省大量计算资源，部分案例效果明显优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 差分模糊测试虽然能够发现软件缺陷，但因其随机性，对缺陷‘未被发现’无法给出风险保证。研究、引入并验证统计学极值理论作为度量差分模糊测试遗漏缺陷风险的新方法，有助于提升测试的可靠性和效率。

Method: 将极值理论应用于差分模糊测试的数据分析，探索其可行性，并与传统统计方法（如马尔可夫与切比雪夫不等式、贝叶斯因子）比较分析其预测能力，并在真实Java库中进行实验验证。

Result: EVT的应用在14.3%的案例中优于基线统计方法，64.2%的案例结果持平。实际应用于Java库时，通过提前停止，实现了数千万次字节码执行的节约。

Conclusion: 极值理论（EVT）可以有效应用于差分模糊测试，以评估错失或低估缺陷的风险，不仅提升了准确性，还大大节约了计算资源。

Abstract: Differential testing is a highly effective technique for automatically
detecting software bugs and vulnerabilities when the specifications involve an
analysis over multiple executions simultaneously. Differential fuzzing, in
particular, operates as a guided randomized search, aiming to find (similar)
inputs that lead to a maximum difference in software outputs or their
behaviors. However, fuzzing, as a dynamic analysis, lacks any guarantees on the
absence of bugs: from a differential fuzzing campaign that has observed no bugs
(or a minimal difference), what is the risk of observing a bug (or a larger
difference) if we run the fuzzer for one or more steps?
  This paper investigates the application of Extreme Value Theory (EVT) to
address the risk of missing or underestimating bugs in differential fuzzing.
The key observation is that differential fuzzing as a random process resembles
the maximum distribution of observed differences. Hence, EVT, a branch of
statistics dealing with extreme values, is an ideal framework to analyze the
tail of the differential fuzzing campaign to contain the risk. We perform
experiments on a set of real-world Java libraries and use differential fuzzing
to find information leaks via side channels in these libraries. We first
explore the feasibility of EVT for this task and the optimal hyperparameters
for EVT distributions. We then compare EVT-based extrapolation against baseline
statistical methods like Markov's as well as Chebyshev's inequalities, and the
Bayes factor. EVT-based extrapolations outperform the baseline techniques in
14.3% of cases and tie with the baseline in 64.2% of cases. Finally, we
evaluate the accuracy and performance gains of EVT-enabled differential fuzzing
in real-world Java libraries, where we reported an average saving of tens of
millions of bytecode executions by an early stop.

</details>


### [10] [Assurance Case Development for Evolving Software Product Lines: A Formal Approach](https://arxiv.org/abs/2511.03026)
*Logan Murphy,Torin Viger,Alessio Di Sandro,Aren A. Babikian,Marsha Chechik*

Main category: cs.SE

TL;DR: 本研究提出了一种面向软件产品线的变异意识安全性论证方法，能高效构建及维护AC，并对演化变更进行回归分析，经实际案例验证具备可用性和实用价值。


<details>
  <summary>Details</summary>
Motivation: 在关键性软件工程中，保证系统关键属性的结构化安全性论证（Assurance Cases, AC）非常重要。但在软件产品线（SPL）中，因产品多且存在变化，为每个产品独立开发和维护AC既费力又不可持续。特别是当产品线特性变化时，逐一分析影响变得更加困难，因此需要一种高效统筹的方法。

Method: 作者提出了基于形式化的方法，构建可适应变化的软件产品线整体的变异意识AC。他们形式化了适用于SPL的AC语言，并研究了基于模板的AC开发提升，定义并实现了回归分析方法以评估产品线演化对这些AC的影响。最后，通过模型驱动的工具进行了实现，并以医疗设备产品线为案例进行说明。

Result: 提出了适用于SPL的变异意识AC开发和回归分析方法，开发了支持这些方法的模型化安全性管理工具，并通过产品线实际案例（医疗设备）展示了方法的可行性和有效性。

Conclusion: 通过形式化的变异意识AC方法，可显著提高SPL安全性论证的开发和维护效率，使其能够同步适应产品线的变化与演进，并追踪分析安全影响。该研究有效支持了大规模和高变更环境下的系统保障。

Abstract: In critical software engineering, structured assurance cases (ACs) are used
to demonstrate how key system properties are supported by evidence (e.g., test
results, proofs). Creating rigorous ACs is particularly challenging in the
context of software product lines (SPLs), i.e, sets of software products with
overlapping but distinct features and behaviours. Since SPLs can encompass very
large numbers of products, developing a rigorous AC for each product
individually is infeasible. Moreover, if the SPL evolves, e.g., by the
modification or introduction of features, it can be infeasible to assess the
impact of this change. Instead, the development and maintenance of ACs ought to
be lifted such that a single AC can be developed for the entire SPL
simultaneously, and be analyzed for regression in a variability-aware fashion.
In this article, we describe a formal approach to lifted AC development and
regression analysis. We formalize a language of variability-aware ACs for SPLs
and study the lifting of template-based AC development. We also define a
regression analysis to determine the effects of SPL evolutions on
variability-aware ACs. We describe a model-based assurance management tool
which implements these techniques, and illustrate our contributions by
developing an AC for a product line of medical devices.

</details>


### [11] [Adaptive Detection of Software Aging under Workload Shift](https://arxiv.org/abs/2511.03103)
*Rafael José Moura,Maria Gizele Nascimento,Fumio Machida,Ermeson Andrade*

Main category: cs.SE

TL;DR: 基于ADWIN的自适应机器学习模型能在动态工作负载下有效检测软件老化，优于静态模型，F1分数始终高于0.93。


<details>
  <summary>Details</summary>
Motivation: 软件老化影响长期运行的系统，导致性能下降和故障风险上升。现有检测方法对动态工作负载适应性差。

Method: 对比了静态模型与引入DDM和ADWIN两种自适应检测方法的自适应模型，在突发、渐进和重复发生的工作负载变化下进行了仿真实验。

Result: 静态模型面对新型工作负载时性能下降明显，而ADWIN自适应模型在所有测试场景下F1-Score均超过0.93，表现优异。

Conclusion: 应用ADWIN的自适应模型在各种工作负载变化场景下都能保持高精度，有效应对软件老化检测问题，优于静态模型。

Abstract: Software aging is a phenomenon that affects long-running systems, leading to
progressive performance degradation and increasing the risk of failures. To
mitigate this problem, this work proposes an adaptive approach based on machine
learning for software aging detection in environments subject to dynamic
workload conditions. We evaluate and compare a static model with adaptive
models that incorporate adaptive detectors, specifically the Drift Detection
Method (DDM) and Adaptive Windowing (ADWIN), originally developed for concept
drift scenarios and applied in this work to handle workload shifts. Experiments
with simulated sudden, gradual, and recurring workload transitions show that
static models suffer a notable performance drop when applied to unseen workload
profiles, whereas the adaptive model with ADWIN maintains high accuracy,
achieving an F1-Score above 0.93 in all analyzed scenarios.

</details>


### [12] [Automated Prompt Generation for Code Intelligence: An Empirical study and Experience in WeChat](https://arxiv.org/abs/2511.03136)
*Kexing Ji,Shiyun Fu,Cuiyun Gao,Yujia Chen,Zezhou Yang,Chaozheng Wang,Yuetang Deng*

Main category: cs.SE

TL;DR: 大模型处理代码任务时，自动化设计高质量prompt极为关键。本文实证分析并优化了指令生成与多步推理两类自动prompt方法，显著提升代码翻译、摘要和API推荐能力，并在工业数据集上大幅提升效果，对智能代码应用有重要推动。


<details>
  <summary>Details</summary>
Motivation: 当前大模型（LCMs）在代码智能领域表现突出，但其效果高度依赖prompt的质量。目前的prompt设计大多依赖人工，耗时且受具体模型和任务影响较大，而自动化prompt生成（APG）在代码智能领域尚未得到充分研究。提升APG可为开发者应对多变任务、适配黑盒模型带来巨大价值。

Method: 本文实证研究了APG的两个关键环节：指令生成（IG）和多步推理（MSR）。分别为LCMs提供指令性描述和逻辑推理指导，并在四个开源LCMs和三类任务（代码翻译、代码摘要、API推荐）上评估各自的常用方法，进一步提出结合两者最佳方法的新型APG方案。

Result: IG和MSR显著提升了模型在代码翻译、摘要和API推荐任务上的表现。综合APG方法比基础prompt分别在CodeBLEU、ROUGE-L和SuccessRate@1指标上平均提升28.38%、58.11%、84.53%；在工业场景（WeChat-Bench私有数据集）的API推荐任务上MRR提升148.89%。

Conclusion: 自动化prompt生成可大幅提升LCMs代码智能表现，结合IG与MSR的APG方案在多项任务和真实业务场景中均证实有效。推动APG在代码智能领域落地具有重要实践意义。

Abstract: Large Code Models (LCMs) show potential in code intelligence, but their
effectiveness is greatly influenced by prompt quality. Current prompt design is
mostly manual, which is time-consuming and highly dependent on specific LCMs
and tasks. While automated prompt generation (APG) exists in NLP, it is
underexplored for code intelligence. This creates a gap, as automating the
prompt process is essential for developers facing diverse tasks and black-box
LCMs.
  To mitigate this, we empirically investigate two important parts of APG:
Instruction Generation (IG) and Multi-Step Reasoning (MSR). IG provides a
task-related description to instruct LCMs, while MSR guides them to produce
logical steps before the final answer. We evaluate widely-used APG methods for
each part on four open-source LCMs and three code intelligence tasks: code
translation (PL-PL), code summarization (PL-NL), and API recommendation
(NL-PL).Experimental results indicate that both IG and MSR dramatically enhance
performance compared to basic prompts. Based on these results, we propose a
novel APG approach combining the best methods of the two parts. Experiments
show our approach achieves average improvements of 28.38% in CodeBLEU (code
translation), 58.11% in ROUGE-L (code summarization), and 84.53% in
SuccessRate@1 (API recommendation) over basic prompts. To validate its
effectiveness in an industrial scenario, we evaluate our approach on
WeChat-Bench, a proprietary dataset, achieving an average MRR improvement of
148.89% for API recommendation.

</details>


### [13] [RefAgent: A Multi-agent LLM-based Framework for Automatic Software Refactoring](https://arxiv.org/abs/2511.03153)
*Khouloud Oueslati,Maxime Lamothe,Foutse Khomh*

Main category: cs.SE

TL;DR: 该文提出基于大型语言模型多智能体的自动重构框架RefAgent，并在开源项目上验证其显著优于单智能体和部分传统工具。RefAgent能自主规划并优化重构任务，极大提高测试通过率与软件质量。


<details>
  <summary>Details</summary>
Motivation: 现有LLM重构依赖静态、细致指令，缺乏对复杂动态场景的适应力。LLM多智能体可通过交互与自我反思，提升重构自动化与代码质量。

Method: 提出RefAgent――基于LLM的多智能体自动重构框架，专用智能体负责规划、执行、测试与自我反馈重构流程。通过在8个开源Java项目上，与单智能体、搜索式工具及开发者历史重构对比评测，并进行消融实验。

Result: RefAgent提高测试通过率和代码质量，改善代码异味及可复用性。在识别重构机会方面，新方法与传统工具和开发者水平接近。相较单智能体，RefAgent综合表现明显提升。

Conclusion: 多智能体的RefAgent表现优异，单位测试通过率高达90%，代码异味减少52.5%，质量属性提升8.6%。RefAgent在识别重构机会方面与开发人员及搜索工具接近，显著优于单智能体方式（测试通过率提升64.7%，编译成功率提升40.1%），显示多智能体在自动化重构上的前景。

Abstract: Large Language Models (LLMs) have substantially influenced various software
engineering tasks. Indeed, in the case of software refactoring, traditional
LLMs have shown the ability to reduce development time and enhance code
quality. However, these LLMs often rely on static, detailed instructions for
specific tasks. In contrast, LLM-based agents can dynamically adapt to evolving
contexts and autonomously make decisions by interacting with software tools and
executing workflows. In this paper, we explore the potential of LLM-based
agents in supporting refactoring activities. Specifically, we introduce
RefAgent, a multi-agent LLM-based framework for end-to-end software
refactoring. RefAgent consists of specialized agents responsible for planning,
executing, testing, and iteratively refining refactorings using self-reflection
and tool-calling capabilities. We evaluate RefAgent on eight open-source Java
projects, comparing its effectiveness against a single-agent approach, a
search-based refactoring tool, and historical developer refactorings. Our
assessment focuses on: (1) the impact of generated refactorings on software
quality, (2) the ability to identify refactoring opportunities, and (3) the
contribution of each LLM agent through an ablation study. Our results show that
RefAgent achieves a median unit test pass rate of 90%, reduces code smells by a
median of 52.5%, and improves key quality attributes (e.g., reusability) by a
median of 8.6%. Additionally, it closely aligns with developer refactorings and
the search-based tool in identifying refactoring opportunities, attaining a
median F1-score of 79.15% and 72.7%, respectively. Compared to single-agent
approaches, RefAgent improves the median unit test pass rate by 64.7% and the
median compilation success rate by 40.1%. These findings highlight the promise
of multi-agent architectures in advancing automated software refactoring.

</details>


### [14] [Understanding Robustness of Model Editing in Code LLMs: An Empirical Study](https://arxiv.org/abs/2511.03182)
*Vinaik Chhetri,A. B Siddique,Umar Farooq*

Main category: cs.SE

TL;DR: API等环境变更下，当前主流模型编辑手段无法让代码LLM可靠地采纳新变化，性能大幅下降，准确采纳仅6%。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）虽然被广泛应用于软件开发，但其静态属性与不断变化的编程语言和API之间存在脱节，导致生成的代码容易过时或不兼容。完全重新训练模型成本高昂，因此模型编辑成为一种轻量级但潜力未被验证的替代方案。本文旨在系统性地评估主流模型编辑方法在该场景中的有效性。

Method: 对五种主流模型编辑方法（Constrained Fine-Tuning, GRACE, MEMIT, PMET, ROME）进行系统评测，选择三种常用代码生成大模型（CodeLlama, CodeQwen1.5, DeepSeek-Coder），并设计受控API弃用场景。评估分为即时编辑和序列编辑两种情形，并使用三个不重叠的测试集，从可靠性、泛化和特异性三个维度测评模型表现。代码正确性考查包括：能否编译、部分测试用例通过、全部测试用例通过。

Result: 无论即时编辑还是序列编辑，模型编辑后的性能都有明显下降。语法有效性最多下降86个百分点，功能正确性最优情况下也下降45个百分点。序列编辑引发性能进一步崩溃。大部分通过的代码只是采用了权宜之计，真正能准确采纳API变更的成功率仅约为6%。

Conclusion: 主流模型编辑手段并不能有效且可靠地让大语言模型采纳API等编程环境的变更，甚至还会大幅削弱模型本来性能；模型编辑后的大多数结果仅为表层修复，准确适应变更的效果极为有限。

Abstract: Large language models (LLMs) are increasingly used in software development.
However, while LLMs remain static after pretraining, programming languages and
APIs continue to evolve, leading to the generation of deprecated or
incompatible code that undermines reliability. Retraining LLMs from scratch to
reflect such changes is computationally expensive, making model editing a
promising lightweight alternative that updates only a small subset of
parameters. Despite its potential, it remains unclear whether model editing
yields genuine syntactic and semantic adaptations or merely superficial fixes.
In this work, we present a systematic study of five state-of-the-art model
editing methods: Constrained Fine-Tuning (FT), GRACE, MEMIT, PMET, and ROME. We
apply these methods to three leading open-source code LLMs, CodeLlama,
CodeQwen1.5, and DeepSeek-Coder, under controlled API deprecation scenarios.
Our evaluation covers both instant and sequential editing settings, using three
disjoint evaluation sets designed to assess reliability, generalization, and
specificity. We measure model correctness at three levels: successful
compilation, partial test case pass, and full test pass. Our findings show that
instant edits consistently degrade model performance, with syntactic validity
dropping by up to 86 percentage points and functional correctness declining by
45 points even in the best-performing setting. Sequential edits further amplify
this degradation, and in some cases, model performance collapses entirely.
Across all models, most passing generations relied on workarounds rather than
correctly adopting the intended changes, while faulty adoptions that result in
test failures or compilation errors were significantly more frequent. Correct
adoptions, where the model correctly integrates the intended change, occurred
in only about 6% of cases.

</details>


### [15] [Towards Realistic Project-Level Code Generation via Multi-Agent Collaboration and Semantic Architecture Modeling](https://arxiv.org/abs/2511.03404)
*Qianhui Zhao,Li Zhang,Fang Liu,Junhang Cheng,Chengru Wu,Junchen Ai,Qiaoyuanhe Meng,Lichen Zhang,Xiaoli Lian,Shubin Song,Yuanping Guo*

Main category: cs.SE

TL;DR: 本文提出了CodeProjectEval数据集和ProjectGen框架，有效提升了大模型根据复杂需求自动生成完整项目的能力，实验显著优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）在自动代码生成方面取得了巨大进展，但在实际的软件工程中，需要能根据复杂需求生成完整软件项目。然而，目前的研究在数据集真实性、评估方法有效性、需求理解与代码实现之间存在语义鸿沟、依赖管理及生成质量等方面仍有局限。

Method: 作者提出了新的项目级代码生成数据集CodeProjectEval，该数据集来源于18个真实项目，并配有文档和可执行测试用例。同时，提出了ProjectGen多智能体框架，将项目生成分解为架构设计、骨架生成、代码补全等阶段，且使用语义软件架构树（SSAT）来桥接用户需求与代码实现，并进行迭代优化及记忆性上下文管理。

Result: ProjectGen在DevBench小规模数据集上通过了52/124测试用例，比基线提升57%；在CodeProjectEval数据集上通过了310个测试用例，比基线提升了约十倍，证明方法有效且优于现有方案。

Conclusion: 该研究提出的新数据集和多智能体项目级生成方法有效解决了当前代码生成中的主要难点，并显著提升了自动生成完整项目的性能。

Abstract: In recent years, Large Language Models (LLMs) have achieved remarkable
progress in automated code generation. In real-world software engineering, the
growing demand for rapid iteration and continuous delivery underscores the
importance of project-level code generation, where LLMs are expected to
generate complete software projects directly from complex user requirements.
Although existing studies have made initial explorations, they still face key
limitations, including unrealistic datasets and unreliable evaluation metrics
that fail to reflect real-world complexity, the semantic gap between
human-written requirements and machine-interpretable structures, and
difficulties in managing hierarchical dependencies and maintaining quality
throughout the generation process. To address these limitations, we first
introduce CodeProjectEval, a project-level code generation dataset built from
18 real-world repositories with 12.7 files and 2,388.6 lines of code per task
on average, supplemented with documentation and executable test cases for
automatic evaluation. We further propose ProjectGen, a multi-agent framework
that decomposes projects into architecture design, skeleton generation, and
code filling stages with iterative refinement and memory-based context
management. Within this framework, we introduce the Semantic Software
Architecture Tree (SSAT), a structured and semantically rich representation
that effectively bridges user requirements and source code implementation.
Experiments show that ProjectGen achieves state-of-the-art performance, passing
52/124 test cases on the small-scale project-level code generation dataset
DevBench, a 57% improvement over the baseline approaches, and 310 test cases on
CodeProjectEval, representing an improvement of roughly tenfold compared to the
baselines.

</details>


### [16] [Light over Heavy: Automated Performance Requirements Quantification with Linguistic Inducement](https://arxiv.org/abs/2511.03421)
*Shihai Wang,Tao Chen*

Main category: cs.SE

TL;DR: LQPR是一种将性能需求量化转为分类问题的自动方法，针对性能需求简短且规律性强的特点，采用轻量级语言感知机制。实验表明，LQPR在大多数场景下优于现有学习型方法且成本极低。专用于该任务的方法能胜过通用LLM方案。


<details>
  <summary>Details</summary>
Motivation: 在工程任务（如配置调优和性能测试）中，需要对收集到的性能需求进行量化以便合规。现有方法多依赖人工量化，过程昂贵且易出错，因此需要一种高效且精确的自动量化方法。

Method: 提出了一种高效的自动性能需求量化方法LQPR，将性能需求量化转化为分类问题。LQPR结合全新的理论框架与轻量级语言诱导匹配机制，针对性能需求通常简短且有明显模式的特点进行设计。

Result: 在多个不同数据集上，将LQPR与九种先进的学习方法进行了对比。结果显示，LQPR在75%及以上的场景中表现最佳，且代价低两个数量级。

Conclusion: 针对性能需求量化任务，专用方法（如LQPR）在效率和准确性上优于通用的LLM驱动方法，充分证明了量体裁衣式的方法更为适合。

Abstract: Elicited performance requirements need to be quantified for compliance in
different engineering tasks, e.g., configuration tuning and performance
testing. Much existing work has relied on manual quantification, which is
expensive and error-prone due to the imprecision. In this paper, we present
LQPR, a highly efficient automatic approach for performance requirements
quantification.LQPR relies on a new theoretical framework that converts
quantification as a classification problem. Despite the prevalent applications
of Large Language Models (LLMs) for requirement analytics, LQPR takes a
different perspective to address the classification: we observed that
performance requirements can exhibit strong patterns and are often
short/concise, therefore we design a lightweight linguistically induced
matching mechanism. We compare LQPR against nine state-of-the-art
learning-based approaches over diverse datasets, demonstrating that it is
ranked as the sole best for 75% or more cases with two orders less cost. Our
work proves that, at least for performance requirement quantification,
specialized methods can be more suitable than the general LLM-driven
approaches.

</details>


### [17] [U2F: Encouraging SWE-Agent to Seize Novelty without Losing Feasibility](https://arxiv.org/abs/2511.03517)
*Wencheng Ye,Yan Liu*

Main category: cs.SE

TL;DR: 本文提出认知增强的U2F框架，有效在真实工程任务中提升创新性，表现出“未知的未知”引领软件创新的能力。


<details>
  <summary>Details</summary>
Motivation: 现有大模型驱动的软件工程智能体主要解决明确、传统问题，难以应对开放环境中的创新性挑战。为发现并利用“未知的未知”以获得创新解决方案，提出新方法满足需求。

Method: 提出了U2F多智能体框架，包含发现-探索-整合智能体系统，并融入跨领域类比推理、逆向思维与外部验证三种认知增强机制。以218个真实工程案例验证该方法，通过人工和LLM评估创新性和可行性。

Result: U2F方法带来总体新颖性提升14%，语义新颖性提升51%，可行性评价达4.02/5.0，均由人类专家和模型评估确认。

Conclusion: U2F framework有效提升了软件工程任务中解决方案的新颖性和可行性，证明了拥抱不确定性有助于激发软件创新。

Abstract: Large language models (LLMs) have shown strong capabilities in software
engineering tasks, yet most existing LLM-based SWE-Agents mainly tackle
well-defined problems using conventional methods, often overlooking alternative
or innovative solutions beyond their predefined frameworks. This limitation is
evident in open-world software environments, where emerging challenges
transcend established paradigms.
  We propose U2F (Unknown Unknowns to Functional solutions), a
cognitive-inspired, uncertainty-embracing multi-agent framework that
systematically surfaces "Unknown Unknowns" - novel solution pathways absent
from initial formulations but holding innovative potential. U2F consists of two
key components: (1) a Discovery-Exploration-Integration agent system for
uncovering and synthesizing potential solutions, and (2) cognitive enhancement
mechanisms across three dimensions: cross-domain analogical reasoning, reverse
thinking, and external validation, which strategically reframe and extend
conventional solution boundaries.
  Applied to 218 real-world software enabler stories curated from authentic
engineering tasks, U2F achieved notable improvements: human experts reported a
14 percent increase in overall novelty, 51 percent improvement in semantic
novelty, and stable feasibility (4.02/5.0), corroborated by an LLM-based
evaluator. These results highlight the potential of embracing uncertainty as a
catalyst for innovation in software engineering.

</details>


### [18] [Uncovering Code Insights: Leveraging GitHub Artifacts for Deeper Code Understanding](https://arxiv.org/abs/2511.03549)
*Ziv Nevo,Orna Raz,Karen Yorav*

Main category: cs.SE

TL;DR: 本文提出用GitHub相关自然语言上下文增强LLM代码解释能力，系统可提取、生成并验证代码目的解释，并经实际开发者评价显示效果良好。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）虽然可以自动生成代码解释，但往往缺乏与实际软件工程背景的结合，导致解释片面或不准确。为了解决代码解释准确性和实用性的问题，作者提出结合GitHub的自然语言信息以改进LLM的代码理解能力。

Method: 作者设计了一个系统，包含三个部分：一是从GitHub提取和结构化相关的上下文信息（如PR描述、Issue讨论、提交信息）；二是利用收集到的上下文为代码生成高层次的解释；三是对生成的解释进行验证。该系统既可以作为独立工具运行，也可作为服务器通过Model Context Protocol（MCP）与其他AI开发工具集成。

Result: 通过与多个开源项目和专有项目的开发者进行用户研究，结果显示系统生成的洞见通常有帮助且非平凡，且很少出现虚假内容（hallucinations）。

Conclusion: 融合GitHub自然语言上下文能有效提升LLM对源代码目的的高质量解释，所提系统能为代码解释提供全面且实用的支持，增强AI辅助开发工具的能力。

Abstract: Understanding the purpose of source code is a critical task in software
maintenance, onboarding, and modernization. While large language models (LLMs)
have shown promise in generating code explanations, they often lack grounding
in the broader software engineering context. We propose a novel approach that
leverages natural language artifacts from GitHub -- such as pull request
descriptions, issue descriptions and discussions, and commit messages -- to
enhance LLM-based code understanding. Our system consists of three components:
one that extracts and structures relevant GitHub context, another that uses
this context to generate high-level explanations of the code's purpose, and a
third that validates the explanation. We implemented this as a standalone tool,
as well as a server within the Model Context Protocol (MCP), enabling
integration with other AI-assisted development tools. Our main use case is that
of enhancing a standard LLM-based code explanation with code insights that our
system generates. To evaluate explanations' quality, we conducted a small scale
user study, with developers of several open projects, as well as developers of
proprietary projects. Our user study indicates that when insights are generated
they often are helpful and non trivial, and are free from hallucinations.

</details>


### [19] [The OpenHands Software Agent SDK: A Composable and Extensible Foundation for Production Agents](https://arxiv.org/abs/2511.03690)
*Xingyao Wang,Simon Rosenberg,Juan Michelini,Calvin Smith,Hoang Tran,Engel Nyst,Rohit Malhotra,Xuhui Zhou,Valerie Chen,Robert Brennan,Graham Neubig*

Main category: cs.SE

TL;DR: OpenHands代理SDK升级了代理架构，提升了开发灵活性、安全性和易用性，在实际测试中取得了强劲性能，是构建和部署软件开发代理的新优选。


<details>
  <summary>Details</summary>
Motivation: 现有软件工程代理开发复杂，部署要求灵活的实现和实验性支持、安全可靠的执行环境，以及便捷的人机交互接口，现有SDK在这些方面均有所不足，亟需更完善的工具包支持。

Method: 该工具包重新设计了OpenHands代理组件架构，采用简洁易扩展的接口，实现本地到远程的无缝执行，集成REST/WebSocket服务，可连接多种前端接口（如VS Code、VNC、浏览器等），并支持模型无关的多LLM路由以及安全分析。

Result: 实证结果显示，在SWE-Bench Verified和GAIA基准测试中，OpenHands SDK表现优异，并能支持快速原型设计和大规模可靠部署。

Conclusion: OpenHands软件代理SDK为构建生产级软件开发代理提供了坚实基础，实现了高灵活性、安全可靠性和高效的人机交互，具备广泛的实际应用潜力。

Abstract: Agents are now used widely in the process of software development, but
building production-ready software engineering agents is a complex task.
Deploying software agents effectively requires flexibility in implementation
and experimentation, reliable and secure execution, and interfaces for users to
interact with agents. In this paper, we present the OpenHands Software Agent
SDK, a toolkit for implementing software development agents that satisfy these
desiderata. This toolkit is a complete architectural redesign of the agent
components of the popular OpenHands framework for software development agents,
which has 64k+ GitHub stars. To achieve flexibility, we design a simple
interface for implementing agents that requires only a few lines of code in the
default case, but is easily extensible to more complex, full-featured agents
with features such as custom tools, memory management, and more. For security
and reliability, it delivers seamless local-to-remote execution portability,
integrated REST/WebSocket services. For interaction with human users, it can
connect directly to a variety of interfaces, such as visual workspaces (VS
Code, VNC, browser), command-line interfaces, and APIs. Compared with existing
SDKs from OpenAI, Claude, and Google, OpenHands uniquely integrates native
sandboxed execution, lifecycle control, model-agnostic multi-LLM routing, and
built-in security analysis. Empirical results on SWE-Bench Verified and GAIA
benchmarks demonstrate strong performance. Put together, these elements allow
the OpenHands Software Agent SDK to provide a practical foundation for
prototyping, unlocking new classes of custom applications, and reliably
deploying agents at scale.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [20] [Cache Mechanism for Agent RAG Systems](https://arxiv.org/abs/2511.02919)
*Shuhang Lin,Zhencan Peng,Lingyao Li,Xiao Lin,Xi Zhu,Yongfeng Zhang*

Main category: cs.CL

TL;DR: 本文提出ARC缓存机制，为RAG增强的LLM智能体自动维护高关联语料库，不需人工注释，显著提升检索效果，缩减存储和延迟。


<details>
  <summary>Details</summary>
Motivation: RAG增强了LLM智能体，但在高效地为每个智能体构建、维护、更新适用的紧凑相关语料库方面研究较少。

Method: 提出了ARC机制：无需人工标注，基于查询历史分布和嵌入空间几何，自动动态管理每个智能体的小型高价值语料缓存。

Result: ARC将存储需求降低到原始语料的0.015%，有高达79.8%的有答案率，检索延迟减少80%，在三个检索基准数据集上实验验证有效性。

Conclusion: ARC可以大幅提升基于RAG的大语言模型智能体的效率和效果，通过高相关性缓存机制，有效减少存储并加速检索。

Abstract: Recent advances in Large Language Model (LLM)-based agents have been
propelled by Retrieval-Augmented Generation (RAG), which grants the models
access to vast external knowledge bases. Despite RAG's success in improving
agent performance, agent-level cache management, particularly constructing,
maintaining, and updating a compact, relevant corpus dynamically tailored to
each agent's need, remains underexplored. Therefore, we introduce ARC (Agent
RAG Cache Mechanism), a novel, annotation-free caching framework that
dynamically manages small, high-value corpora for each agent. By synthesizing
historical query distribution patterns with the intrinsic geometry of cached
items in the embedding space, ARC automatically maintains a high-relevance
cache. With comprehensive experiments on three retrieval datasets, our
experimental results demonstrate that ARC reduces storage requirements to
0.015% of the original corpus while offering up to 79.8% has-answer rate and
reducing average retrieval latency by 80%. Our results demonstrate that ARC can
drastically enhance efficiency and effectiveness in RAG-powered LLM agents.

</details>


### [21] [Automatic Machine Translation Detection Using a Surrogate Multilingual Translation Model](https://arxiv.org/abs/2511.02958)
*Cristian García-Romero,Miquel Esplà-Gomis,Felipe Sánchez-Martínez*

Main category: cs.CL

TL;DR: 本文提出了一种通过MT模型内部表示区分人工和机器翻译的新方法，能有效过滤机器生成内容，提升数据质量，其准确度较现有方法提升5个百分点以上。


<details>
  <summary>Details</summary>
Motivation: 现有的平行语料库中有大量机器生成的翻译内容，过度依赖这些合成数据会降低机器翻译质量，因此迫切需要高效区分人工与机器翻译的技术。

Method: 利用多语言机器翻译模型的内部表示，判断句子是人工翻译还是机器翻译。

Result: 新方法在准确率上较现有技术提升至少5个百分点，特别是在非英语语言对中表现更优。

Conclusion: 提出的方法在区分人类与机器翻译句子方面优于现有方法，尤其在非英语语言对上提升显著。

Abstract: Modern machine translation (MT) systems depend on large parallel corpora,
often collected from the Internet. However, recent evidence indicates that (i)
a substantial portion of these texts are machine-generated translations, and
(ii) an overreliance on such synthetic content in training data can
significantly degrade translation quality. As a result, filtering out non-human
translations is becoming an essential pre-processing step in building
high-quality MT systems. In this work, we propose a novel approach that
directly exploits the internal representations of a surrogate multilingual MT
model to distinguish between human and machine-translated sentences.
Experimental results show that our method outperforms current state-of-the-art
techniques, particularly for non-English language pairs, achieving gains of at
least 5 percentage points of accuracy.

</details>


### [22] [LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation](https://arxiv.org/abs/2511.03001)
*Gyeom Hwangbo,Hyungjoo Chae,Minseok Kang,Hyeonjong Ju,Soohyun Oh,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 论文提出LEGO-Eval评估框架，以提升对3D生成场景与细粒度指令对齐度的准确评估，并构建高要求基准LEGO-Bench。实验证明现有自动生成方法在复杂场景对齐上表现极差，LEGO-Eval显示更优评测效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的3D场景自动生成方法无法模拟真实环境的空间布局和细致属性，训练出的智能体表现与现实存在偏离。当前评估方法（如CLIPScore和VLMs）对细粒度场景/指令对齐的测量效果不佳，亟需更具针对性的评估框架和基准。

Method: 设计LEGO-Eval评估框架，通过多样化工具对场景组件进行显式定位，提升评估准确性。同时，提出LEGO-Bench作为高要求的指令基准，对现有场景生成方法进行系统性实验分析。

Result: LEGO-Eval评估框架在场景指令对齐度评测上， F1分数领先现有方法0.41。基于LEGO-Bench实测，当前所有3D场景生成方法对复杂指令的完整对齐率不超过10%。

Conclusion: 提出了一种新的评估框架LEGO-Eval，能够更准确地评估3D场景与细粒度指令的对齐度，并证明当前生成方法在高度拟真和细致场景构建上的不足。

Abstract: Despite recent progress in using Large Language Models (LLMs) for
automatically generating 3D scenes, generated scenes often lack realistic
spatial layouts and object attributes found in real-world environments. As this
problem stems from insufficiently detailed, coarse-grained instructions,
advancing 3D scene synthesis guided by more detailed, fine-grained instructions
that reflect real-world environments becomes crucial. Without such realistic
scenes, training embodied agents in unrealistic environments can lead them to
learn priors that diverge significantly from real-world physics and semantics,
degrading their performance when deployed. Thus, verifying the alignment
between the fine-grained instruction and the generated scene is essential for
effective learning. However, current evaluation methods, such as CLIPScore and
vision-language models (VLMs), often fail to reliably assess such alignment.
This shortcoming arises primarily from their shallow understanding of 3D
scenes, which often leads to improperly grounded scene components. To address
this, we introduce LEGO-Eval, an evaluation framework equipped with diverse
tools designed to explicitly ground scene components, enabling more accurate
alignment assessments. We also present LEGO-Bench, a benchmark of detailed
instructions that specify complex layouts and attributes of real-world
environments. Experiments demonstrate that LEGO-Eval outperforms VLM-as-a-judge
by 0.41 F1 score in assessing scene-instruction alignment. Benchmarking with
LEGO-Bench reveals significant limitations in current generation methods.
Across all evaluated approaches, success rates reached at most 10% in
generating scenes that fully align with fine-grained instructions.

</details>


### [23] [Targeted Error Correction in Knowledge Distillation: Small Language Models Surpass GPT](https://arxiv.org/abs/2511.03005)
*Hee-Jin Lee,Zhen Guo,Luchao Jin,Morteza Moazami Goudarzi*

Main category: cs.CL

TL;DR: 作者提出ARF流程，通过错误分析、针对性修订和再微调，让小型开源语言模型在客服总结任务上超越GPT-3.5等主流模型，同时更具成本效益和数据隐私优势，适用于多任务场景。


<details>
  <summary>Details</summary>
Motivation: 小型开源模型普遍落后于大型闭源模型，尤其在实际应用场景（如客户服务摘要）下。与此同时，企业和开发者希望降低成本并保护数据隐私，因此亟需让小型开源模型具备更强的能力。

Method: 提出了Analyze-Revise-Finetune (ARF)流程：先分析和归类教师模型产生的摘要错误，再用编辑模型针对性修正这些摘要，最后用修正版数据微调小型学生模型。

Result: 通过ARF流程微调后，Llama 3.1 8B在摘要任务上的表现优于GPT-3.5，同时保持低成本和更高的数据隐私性。

Conclusion: ARF方法能让小型开源模型在客服摘要任务上超越更大型的闭源模型，且提升了成本和数据隐私优势。这个框架对于提升开源模型在多种任务中的效能具有通用价值。

Abstract: We introduce an Analyze-Revise-Finetune (ARF) pipeline that enables smaller
open-source language models (LLMs) to surpass substantially larger proprietary
models in customer service summarization tasks. The pipeline first analyzes and
categorizes common errors in summaries produced by a teacher model (GPT-3.5),
then performs a targeted revision using a compact editor model (Llama 3.1 70B)
to generate high-quality, refined training data. Fine-tuning a smaller student
model (Llama 3.1 8B) on this refined data resulted in superior summarization
performance compared to GPT-3.5. The ARF pipeline improves cost efficiency and
data privacy while maintaining competitive accuracy, illustrating a
generalizable framework for enhancing open-source LLMs across diverse
downstream applications.

</details>


### [24] [Data-Efficient Adaptation and a Novel Evaluation Method for Aspect-based Sentiment Analysis](https://arxiv.org/abs/2511.03034)
*Yan Cathy Hua,Paul Denny,Jörg Wicker,Katerina Taškova*

Main category: cs.CL

TL;DR: 论文针对ABSA在低资源领域的局限，提出了灵活的评估方法、验证了小型生成模型的有效性，并发布了用于教育领域的ABSA数据资源，显著推动了相关领域研究进展。


<details>
  <summary>Details</summary>
Motivation: 目前ABSA领域方法和资源多集中于商业领域，教育和医疗等低资源领域需求未被满足，且现有模型适应性差、评估方法刚性，有误导性。因此需要针对低资源领域和生成式模型，开发更灵活的方法和资源。

Method: 1) 提出新的评估方法 FTS-OBP，2) 采用小型解码式生成模型并在教育评论ABSA领域做系统性实验，包括无数据和少数据微调方法，以及多任务微调策略，3) 发布了首套教育评论ABSA公开资源。

Result: 多任务微调策略使1.5-3.8B参数的小模型在ABSA任务上超越专有大模型，并且在只有200-1000样本和一张GPU的条件下逼近基准结果；同时提出新评估方法和公开教育评论ABSA资源。

Conclusion: 该论文提出了新的方法和资源，推动ABSA在教育等低资源领域的发展，并展示了小型生成式语言模型在这一任务上的潜力。

Abstract: Aspect-based Sentiment Analysis (ABSA) is a fine-grained opinion mining
approach that identifies and classifies opinions associated with specific
entities (aspects) or their categories within a sentence. Despite its rapid
growth and broad potential, ABSA research and resources remain concentrated in
commercial domains, leaving analytical needs unmet in high-demand yet
low-resource areas such as education and healthcare. Domain adaptation
challenges and most existing methods' reliance on resource-intensive
in-training knowledge injection further hinder progress in these areas.
Moreover, traditional evaluation methods based on exact matches are overly
rigid for ABSA tasks, penalising any boundary variations which may misrepresent
the performance of generative models. This work addresses these gaps through
three contributions: 1) We propose a novel evaluation method, Flexible Text
Similarity Matching and Optimal Bipartite Pairing (FTS-OBP), which accommodates
realistic extraction boundary variations while maintaining strong correlation
with traditional metrics and offering fine-grained diagnostics. 2) We present
the first ABSA study of small decoder-only generative language models (SLMs;
<7B parameters), examining resource lower bounds via a case study in education
review ABSA. We systematically explore data-free (in-context learning and
weight merging) and data-light fine-tuning methods, and propose a multitask
fine-tuning strategy that significantly enhances SLM performance, enabling
1.5-3.8 B models to surpass proprietary large models and approach benchmark
results with only 200-1,000 examples on a single GPU. 3) We release the first
public set of education review ABSA resources to support future research in
low-resource domains.

</details>


### [25] [ROBoto2: An Interactive System and Dataset for LLM-assisted Clinical Trial Risk of Bias Assessment](https://arxiv.org/abs/2511.03048)
*Anthony Hevia,Sanjana Chintalapati,Veronica Ka Wai Lai,Thanh Tam Nguyen,Wai-Tat Wong,Terry Klassen,Lucy Lu Wang*

Main category: cs.CL

TL;DR: ROBOTO2是集成大语言模型与人工审核的开源平台，大幅提升了临床试验偏倚风险评估效率，并开源了高质量数据集和分析工具。


<details>
  <summary>Details</summary>
Motivation: 临床试验偏倚风险评估是系统综述中的关键环节，但目前流程繁琐、耗时，缺乏高效、自动化工具。

Method: 论文提出了ROBOTO2平台，结合PDF解析、检索增强的大语言模型（LLM）提示以及人工审核，通过可交互界面辅助偏倚风险评估，并在人机协作下生成和校正答案及证据。还使用构建的数据集对4种LLM模型进行了基准测试和能力分析。

Result: 构建并开源了包含521篇儿科临床试验报告的数据集，提出并上线了ROBOTO2系统，评测了4种LLM在ROB2任务中的表现，为自动化偏倚风险评估提供了新工具与数据基准。

Conclusion: ROBOTO2显著简化了临床试验偏倚风险（ROB2）评估流程，并为未来相关自动化研究提供了基准数据和分析。

Abstract: We present ROBOTO2, an open-source, web-based platform for large language
model (LLM)-assisted risk of bias (ROB) assessment of clinical trials. ROBOTO2
streamlines the traditionally labor-intensive ROB v2 (ROB2) annotation process
via an interactive interface that combines PDF parsing, retrieval-augmented LLM
prompting, and human-in-the-loop review. Users can upload clinical trial
reports, receive preliminary answers and supporting evidence for ROB2 signaling
questions, and provide real-time feedback or corrections to system suggestions.
ROBOTO2 is publicly available at https://roboto2.vercel.app/, with code and
data released to foster reproducibility and adoption. We construct and release
a dataset of 521 pediatric clinical trial reports (8954 signaling questions
with 1202 evidence passages), annotated using both manually and LLM-assisted
methods, serving as a benchmark and enabling future research. Using this
dataset, we benchmark ROB2 performance for 4 LLMs and provide an analysis into
current model capabilities and ongoing challenges in automating this critical
aspect of systematic review.

</details>


### [26] [Reading Between the Lines: The One-Sided Conversation Problem](https://arxiv.org/abs/2511.03056)
*Victoria Ebert,Rishabh Singh,Tuochao Chen,Noah A. Smith,Shyamnath Gollakota*

Main category: cs.CL

TL;DR: 论文提出并定义了单边对话问题（1SC），针对只记录一方对话的场景，研究了缺失发言的重建与摘要生成，提出有效方法并验证其性能，为隐私保护AI系统应用提出关键方案。


<details>
  <summary>Details</summary>
Motivation: 实际应用场景（远程医疗、呼叫中心、智能眼镜等）对话只能记录一方，需解决如何仅用一边对话文本进行信息推断与利用。

Method: 通过prompting和微调模型在MultiWOZ、DailyDialog及Candor数据集上，结合人工A/B测试与大模型评价设计实验，模拟单边对话下内容重建与摘要生成，探索未来回合访问和占位词对模型性能影响。

Result: 未来回合和话语长度信息有助于缺失内容重建，占位prompt减少幻觉，大模型可通过prompt生成有用重建，小模型需微调；生成优质摘要无需完整重建另一方发言。

Conclusion: 1SC问题为隐私保护的对话式AI带来新挑战，且已有方法取得了有希望的结果。高质量摘要可直接来自单边对话，无需完整重构缺失回合。

Abstract: Conversational AI is constrained in many real-world settings where only one
side of a dialogue can be recorded, such as telemedicine, call centers, and
smart glasses. We formalize this as the one-sided conversation problem (1SC):
inferring and learning from one side of a conversation. We study two tasks: (1)
reconstructing the missing speaker's turns for real-time use cases, and (2)
generating summaries from one-sided transcripts. Evaluating prompting and
finetuned models on MultiWOZ, DailyDialog, and Candor with both human A/B
testing and LLM-as-a-judge metrics, we find that access to one future turn and
information about utterance length improves reconstruction, placeholder
prompting helps to mitigate hallucination, and while large models generate
promising reconstructions with prompting, smaller models require finetuning.
Further, high-quality summaries can be generated without reconstructing missing
turns. We present 1SC as a novel challenge and report promising results that
mark a step toward privacy-aware conversational AI.

</details>


### [27] [PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech](https://arxiv.org/abs/2511.03080)
*Michel Wong,Ali Alshehri,Sophia Kao,Haotian He*

Main category: cs.CL

TL;DR: 作者提出基于大语言模型的PolyNorm方法，简化了文本规范化工作，并在多语种表现优异，显著降低了开发难度和词错误率，同时公开了多语种基准数据集。


<details>
  <summary>Details</summary>
Motivation: 传统文本规范化（TN）系统尽管准确率高，但需要大量的工程开发，难以扩展到多语言环境，尤其不适合低资源语种。该研究旨在简化TN系统开发，降低人工规则依赖，提高跨语言适用性。

Method: 提出PolyNorm方法，采用基于提示的方式利用大语言模型（LLMs）进行文本规范化，并设计了一套语言无关的自动数据整理与评估流程。

Result: 在八种语言上的实验表明，PolyNorm方法相比生产级系统在词错误率（WER）方面有持续下降。

Conclusion: PolyNorm减少了文本规范化系统对手工规则的依赖，提升了多语言环境下的适用性，并通过公开PolyNorm-Benchmark推动了领域研究。

Abstract: Text Normalization (TN) is a key preprocessing step in Text-to-Speech (TTS)
systems, converting written forms into their canonical spoken equivalents.
Traditional TN systems can exhibit high accuracy, but involve substantial
engineering effort, are difficult to scale, and pose challenges to language
coverage, particularly in low-resource settings. We propose PolyNorm, a
prompt-based approach to TN using Large Language Models (LLMs), aiming to
reduce the reliance on manually crafted rules and enable broader linguistic
applicability with minimal human intervention. Additionally, we present a
language-agnostic pipeline for automatic data curation and evaluation, designed
to facilitate scalable experimentation across diverse languages. Experiments
across eight languages show consistent reductions in the word error rate (WER)
compared to a production-grade-based system. To support further research, we
release PolyNorm-Benchmark, a multilingual data set covering a diverse range of
text normalization phenomena.

</details>


### [28] [A Computational Approach to Analyzing Disrupted Language in Schizophrenia: Integrating Surprisal and Coherence Measures](https://arxiv.org/abs/2511.03089)
*Gowtham Premananth,Carol Espy-Wilson*

Main category: cs.CL

TL;DR: 本文利用surprisal和语义连贯性两大计算语言学指标，量化精神分裂症患者的语言障碍，揭示其与症状严重度密切相关，促进疾病的客观评估。


<details>
  <summary>Details</summary>
Motivation: 精神分裂症患者常见语言障碍，表现为语音紊乱和语篇连贯性降低。由此推测语言异常可作为疾病诊断和严重程度的客观标志，因此需探索更科学的表征方法。

Method: 采用计算语言学方法，具体通过两个指标：surprisal（意外性）和semantic coherence（语义连贯性），利用模型分析患者与健康对照者的语言产出差异。

Result: 发现精神分裂症患者在意外性和语义连贯性指标上表现异常，这些指标随疾病严重程度变化而变化。

Conclusion: 可用计算语言学指标定量刻画精神分裂症语言紊乱，且这些指标与症状严重度相关，有助于客观评估和诊断。

Abstract: Language disruptions are one of the well-known effects of schizophrenia
symptoms. They are often manifested as disorganized speech and impaired
discourse coherence. These abnormalities in spontaneous language production
reflect underlying cognitive disturbances and have the potential to serve as
objective markers for symptom severity and diagnosis of schizophrenia. This
study focuses on how these language disruptions can be characterized in terms
of two computational linguistic measures: surprisal and semantic coherence. By
computing surprisal and semantic coherence of language using computational
models, this study investigates how they differ between subjects with
schizophrenia and healthy controls. Furthermore, this study provides further
insight into how language disruptions in terms of these linguistic measures
change with varying degrees of schizophrenia symptom severity.

</details>


### [29] [CARMA: Comprehensive Automatically-annotated Reddit Mental Health Dataset for Arabic](https://arxiv.org/abs/2511.03102)
*Saad Mankarious,Ayah Zirikly*

Main category: cs.CL

TL;DR: 论文提出并分析了首个大规模阿拉伯语心理健康数据集CARMA，有力推进了该领域的发展，显著提升了用阿拉伯语数据进行心理健康自动检测的能力。


<details>
  <summary>Details</summary>
Motivation: 心理健康障碍在世界范围内影响广泛，阿拉伯语群体因资源有限和文化对心理健康话题的避讳，早期检测尤为困难。当前相关研究主要集中在英语语境，而阿拉伯语领域因缺乏标注数据集，研究严重不足。

Method: 作者构建了CARMA，这是首个自动标注的大规模阿拉伯语Reddit心理健康数据集，涵盖焦虑、自闭症、抑郁等六类疾病和一个对照组。对用户词汇和语义特征进行了定性和定量分析，并通过从简单分类器到大模型的多种方法进行了分类实验。

Result: CARMA数据集在规模和多样性上超过现有资源。实验结果展示了不同模型在心理健康检测上的有效性，揭示了特定心理健康条件的语言标记。

Conclusion: CARMA为低资源语言心理健康检测提供了新的数据基础与方法，实现了重要突破，为相关研究进步显示出巨大潜力。

Abstract: Mental health disorders affect millions worldwide, yet early detection
remains a major challenge, particularly for Arabic-speaking populations where
resources are limited and mental health discourse is often discouraged due to
cultural stigma. While substantial research has focused on English-language
mental health detection, Arabic remains significantly underexplored, partly due
to the scarcity of annotated datasets. We present CARMA, the first
automatically annotated large-scale dataset of Arabic Reddit posts. The dataset
encompasses six mental health conditions, such as Anxiety, Autism, and
Depression, and a control group. CARMA surpasses existing resources in both
scale and diversity. We conduct qualitative and quantitative analyses of
lexical and semantic differences between users, providing insights into the
linguistic markers of specific mental health conditions. To demonstrate the
dataset's potential for further mental health analysis, we perform
classification experiments using a range of models, from shallow classifiers to
large language models. Our results highlight the promise of advancing mental
health detection in underrepresented languages such as Arabic.

</details>


### [30] [Control Barrier Function for Aligning Large Language Models](https://arxiv.org/abs/2511.03121)
*Yuya Miyaoka,Masaki Inoue*

Main category: cs.CL

TL;DR: 提出了一个控制理论驱动的CBF安全过滤器框架，可无缝嵌入LLM文本生成流程，实现无需微调的对齐和生成更符合用户需求、安全的文本。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在生成文本时容易偏离用户目标或要求，且模型微调成本较高，迫切需要一种即插即用、有效提升文本对齐的方法。

Method: 采用CBF安全过滤器对LLM生成的预测token进行干预，确保生成文本符合安全或对齐要求。该过滤器可直接应用于模型，无需微调，且可以集成现有文本评价模型到过滤器设计中。

Result: 实现在开源语言模型上的文本生成系统，能够生成更积极的文本且无需对原始LLM做微调。

Conclusion: 提出了一种利用控制屏障函数（CBF）进行大语言模型（LLM）对齐的方法，通过安全过滤器保证文本生成更符合用户期望而且无需微调模型。

Abstract: This paper proposes a control-based framework for aligning large language
models (LLMs) by leveraging a control barrier function (CBF) to ensure
user-desirable text generation. The presented framework applies the CBF safety
filter to the predicted token generated from the baseline LLM, to intervene in
the generated text. The safety filter includes two significant advantages: this
safety filter is an add-on type, allowing it to be used for alignment purposes
without fine-tuning the baseline LLM, and if there is an evaluation model
regarding the desired alignment, it can be directly applied to the filter
design. The overall text-generation system is implemented with open-source
language models, aiming to generate positive text.

</details>


### [31] [MME-CC: A Challenging Multi-Modal Evaluation Benchmark of Cognitive Capacity](https://arxiv.org/abs/2511.03146)
*Kaiyuan Zhang,Chenghao Yang,Zhoufutu Wen,Sihang Yuan,Qiuyue Wang,Chaoyi Huang,Guosheng Zhu,He Wang,Huawenyu Lu,Jianing Wen,Jianpeng Jiao,Lishu Luo,Longxiang Liu,Sijin Wu,Xiaolei Zhu,Xuanliang Zhang,Ge Zhang,Yi Lin,Guang Shi,Chaoyou Fu,Wenhao Huang*

Main category: cs.CL

TL;DR: 本文提出了面向视觉认知能力的多模态评测基准MME-CC，系统评测了16款主流MLLMs，发现主流模型空间与几何认知弱，闭源模型表现较优，总结了模型的推理模式和常见错误，并呼吁将认知能力纳入核心评测标准。


<details>
  <summary>Details</summary>
Motivation: 多模态大模型（MLLMs）如今发展迅速，但现有评测多偏重文本推理，缺乏系统考查模型以视觉为核心的认知能力，评测内容有限，难以全面衡量MLLMs的认知水平。

Method: 提出MME-CC评测基准，将11类有代表性的视觉推理任务归纳为空间、几何和知识三大类。基于该基准，对16种主流MLLMs模型进行了系统实验和细致分析。

Result: 封闭源模型在总体表现上占优，如Gemini-2.5-Pro得分42.66，GLM-4.5V仅30.45；空间与几何推理能力普遍不足（均小于等于30%）。分析发现，常见错误有朝向混淆、跨视角身份持续性脆弱及难以响应反事实指令等，模型行为倾向“提取-推理-验证”三阶段，极度依赖视觉信息抽取。

Conclusion: MME-CC系统填补了现有基准的评测盲区，推进了对MLLMs视觉认知能力的科学刻画和模型设计导向，强调这类能力未来在模型评测、优化应占核心地位。

Abstract: As reasoning models scale rapidly, the essential role of multimodality in
human cognition has come into sharp relief, driving a growing need to probe
vision-centric cognitive behaviors. Yet, existing multimodal benchmarks either
overemphasize textual reasoning or fall short of systematically capturing
vision-centric cognitive behaviors, leaving the cognitive capacity of MLLMs
insufficiently assessed. To address this limitation, we introduce MME-CC
(Multi-Modal Evaluation benchmark of Cognitive Capacity), a vision-grounded
benchmark that organizes 11 representative reasoning tasks into three
fundamental categories of visual information: spatial, geometric, and
knowledge-based reasoning, and provides fine-grained analyses of MLLMs'
cognitive capacity across these dimensions. Based on MME-CC, we conduct
extensive experiments over 16 representative MLLMs. Our study reveals that
closed-source models currently lead overall (e.g., 42.66 for Gemini-2.5-Pro vs.
30.45 for GLM-4.5V), while spatial and geometric reasoning remain broadly weak
(less than or equal to 30%). We further identify common error patterns,
including orientation mistakes, fragile cross-view identity persistence, and
poor adherence to counterfactual instructions, and observe that
Chain-of-Thought typically follows a three-stage process (extract -> reason ->
verify) with heavy reliance on visual extraction. We hope this work catalyzes a
shift toward treating the cognitive capacity of MLLMs as central to both
evaluation and model design.

</details>


### [32] [Who Sees the Risk? Stakeholder Conflicts and Explanatory Policies in LLM-based Risk Assessment](https://arxiv.org/abs/2511.03152)
*Srishti Yadav,Jasmina Gajcin,Erik Miehling,Elizabeth Daly*

Main category: cs.CL

TL;DR: 论文提出通过LLM和多元解释方法，对AI系统进行面向不同利益相关者的风险评估，揭示冲突并增强透明度，在医疗、自动驾驶和反欺诈场景中验证有效性，强调以人为本的AI治理。


<details>
  <summary>Details</summary>
Motivation: 当AI系统广泛应用于关键领域时，不同利益相关者对AI系统中的风险认知差异明显，这可能影响AI的负责任部署。因此，开发能反映多方观点的风险评估框架成为亟需。

Method: 提出使用大语言模型（LLMs）作为“评判者”来预测和解释风险，结合Risk Atlas Nexus和GloVE解释方法生成针对不同利益相关者的、可解释的政策；并通过医学AI、自动驾驶和反欺诈三个实际用例验证。还开发了一个互动可视化工具来揭示冲突产生的原因与过程。

Result: 实验发现，不同利益相关者对风险的感知和冲突模式有显著差异。框架能够揭示冲突根源，增强评估过程的透明度和可解释性。

Conclusion: 利益相关者视角对AI风险评估至关重要。提出的方法有助于提升基于LLM的风险评估透明性和解释性，对实现以人为本的AI治理具有现实意义。

Abstract: Understanding how different stakeholders perceive risks in AI systems is
essential for their responsible deployment. This paper presents a framework for
stakeholder-grounded risk assessment by using LLMs, acting as judges to predict
and explain risks. Using the Risk Atlas Nexus and GloVE explanation method, our
framework generates stakeholder-specific, interpretable policies that shows how
different stakeholders agree or disagree about the same risks. We demonstrate
our method using three real-world AI use cases of medical AI, autonomous
vehicles, and fraud detection domain. We further propose an interactive
visualization that reveals how and why conflicts emerge across stakeholder
perspectives, enhancing transparency in conflict reasoning. Our results show
that stakeholder perspectives significantly influence risk perception and
conflict patterns. Our work emphasizes the importance of these
stakeholder-aware explanations needed to make LLM-based evaluations more
transparent, interpretable, and aligned with human-centered AI governance
goals.

</details>


### [33] [Measuring Aleatoric and Epistemic Uncertainty in LLMs: Empirical Evaluation on ID and OOD QA Tasks](https://arxiv.org/abs/2511.03166)
*Kevin Wang,Subre Abdoul Moktar,Jia Li,Kangshuo Li,Feng Chen*

Main category: cs.CL

TL;DR: 本文对十二种LLM不确定性估计方法进行了对比，发现在ID数据集上信息类方法表现最佳，而在OOD任务中密度类与P(True)更佳，语义一致性方法兼容性强但并非总是最优。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）广泛应用于各行业，提升其输出的可信度至关重要，因此需研究和比较各种不确定性估计措施在不同场景下的稳健性和有效性。

Method: 对十二种不确定性估计（UE）方法和四种生成质量指标进行了综合实证研究，在问答任务中分别评估LLM在ID和OOD数据集的不确定性表现。

Result: 不同类型的UE方法在ID和OOD数据集上表现差异明显，信息类方法适合ID设置，密度类方法与P(True)适合OOD，语义一致性方法整体可靠但非万金油。

Conclusion: 信息基础方法在模型理解数据方面（ID设置）表现优异，密度基础方法和P(True)指标在分布外（OOD）任务中效果更佳。语义一致性方法在各类数据集和生成指标下表现稳定但并非每种情况都最优。

Abstract: Large Language Models (LLMs) have become increasingly pervasive, finding
applications across many industries and disciplines. Ensuring the
trustworthiness of LLM outputs is paramount, where Uncertainty Estimation (UE)
plays a key role. In this work, a comprehensive empirical study is conducted to
examine the robustness and effectiveness of diverse UE measures regarding
aleatoric and epistemic uncertainty in LLMs. It involves twelve different UE
methods and four generation quality metrics including LLMScore from LLM
criticizers to evaluate the uncertainty of LLM-generated answers in
Question-Answering (QA) tasks on both in-distribution (ID) and
out-of-distribution (OOD) datasets. Our analysis reveals that information-based
methods, which leverage token and sequence probabilities, perform exceptionally
well in ID settings due to their alignment with the model's understanding of
the data. Conversely, density-based methods and the P(True) metric exhibit
superior performance in OOD contexts, highlighting their effectiveness in
capturing the model's epistemic uncertainty. Semantic consistency methods,
which assess variability in generated answers, show reliable performance across
different datasets and generation metrics. These methods generally perform well
but may not be optimal for every situation.

</details>


### [34] [BengaliMoralBench: A Benchmark for Auditing Moral Reasoning in Large Language Models within Bengali Language and Culture](https://arxiv.org/abs/2511.03180)
*Shahriyar Zaman Ridoy,Azmine Toushik Wasi,Koushik Ahamed Tonmoy*

Main category: cs.CL

TL;DR: 首次提出孟加拉语大规模伦理评测基准，系统分析主流语言模型在本地文化伦理任务上的缺陷，为南亚及低资源多语环境下AI伦理本地化提供基础。


<details>
  <summary>Details</summary>
Motivation: 现有伦理评测大多以英语及西方框架为主，缺乏对南亚地区、孟加拉语及其文化伦理的关注，阻碍了AI在真实场景下的本地化部署。

Method: 构建孟加拉语伦理评测基准BengaliMoralBench，覆盖五个伦理领域与50个子话题，并通过母语者一致标注三种伦理视角；采用统一提示协议与标准指标对主流多语言LLM进行zero-shot评测，并分析其定性弱点。

Result: 多语言LLM在孟加拉语伦理任务上的表现差异较大（准确率50%-91%），且在文化贴近性、常识推理和道德公平性方面存在普遍不足。

Conclusion: BengaliMoralBench为多语言大型语言模型在孟加拉语和当地伦理场景下的评估提供了重要基准，有助于推动符合本地文化的AI系统发展。

Abstract: As multilingual Large Language Models (LLMs) gain traction across South Asia,
their alignment with local ethical norms, particularly for Bengali, which is
spoken by over 285 million people and ranked 6th globally, remains
underexplored. Existing ethics benchmarks are largely English-centric and
shaped by Western frameworks, overlooking cultural nuances critical for
real-world deployment. To address this, we introduce BengaliMoralBench, the
first large-scale ethics benchmark for the Bengali language and socio-cultural
contexts. It covers five moral domains, Daily Activities, Habits, Parenting,
Family Relationships, and Religious Activities, subdivided into 50 culturally
relevant subtopics. Each scenario is annotated via native-speaker consensus
using three ethical lenses: Virtue, Commonsense, and Justice ethics. We conduct
systematic zero-shot evaluation of prominent multilingual LLMs, including
Llama, Gemma, Qwen, and DeepSeek, using a unified prompting protocol and
standard metrics. Performance varies widely (50-91% accuracy), with qualitative
analysis revealing consistent weaknesses in cultural grounding, commonsense
reasoning, and moral fairness. BengaliMoralBench provides a foundation for
responsible localization, enabling culturally aligned evaluation and supporting
the deployment of ethically robust AI in diverse, low-resource multilingual
settings such as Bangladesh.

</details>


### [35] [LGM: Enhancing Large Language Models with Conceptual Meta-Relations and Iterative Retrieval](https://arxiv.org/abs/2511.03214)
*Wenchang Lei,Ping Zou,Yue Wang,Feng Sun,Lei Zhao*

Main category: cs.CL

TL;DR: 本文提出的LGM通过抽取和验证元关系，结合动态检索，有效提升了大语言模型在应对概念不清指令时的表现，优于现有RAG方法，无需截断上下文。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在理解语义上表现出色，但当用户指令中包含模糊或概念不一致的术语时，表现不佳。本文旨在提升大语言模型对概念的清晰识别和解析能力。

Method: 提出了语言图模型（LGM），该模型通过从自然语言中抽取元关系（如继承、别名和组合），并利用反思机制验证这些关系。通过一个概念迭代检索算法，将相关的关系与描述动态地供给LLM，以帮助其更好地理解概念生成准确响应。此外，LGM无需依赖超长上下文窗口，避免了截断问题。

Result: 实验证明，LGM在标准基准测试中持续优于现有的RAG基线方法。

Conclusion: LGM通过结构化的元关系提取、反思验证和动态检索机制，有效提升了大语言模型对模糊或概念性复杂指令的理解与响应能力，表现优于现有RAG方法。

Abstract: Large language models (LLMs) exhibit strong semantic understanding, yet
struggle when user instructions involve ambiguous or conceptually misaligned
terms. We propose the Language Graph Model (LGM) to enhance conceptual clarity
by extracting meta-relations-inheritance, alias, and composition-from natural
language. The model further employs a reflection mechanism to validate these
meta-relations. Leveraging a Concept Iterative Retrieval Algorithm, these
relations and related descriptions are dynamically supplied to the LLM,
improving its ability to interpret concepts and generate accurate responses.
Unlike conventional Retrieval-Augmented Generation (RAG) approaches that rely
on extended context windows, our method enables large language models to
process texts of any length without the need for truncation. Experiments on
standard benchmarks demonstrate that the LGM consistently outperforms existing
RAG baselines.

</details>


### [36] [Hybrid Fact-Checking that Integrates Knowledge Graphs, Large Language Models, and Search-Based Retrieval Agents Improves Interpretable Claim Verification](https://arxiv.org/abs/2511.03217)
*Shaghayegh Kolli,Richard Rosenbaum,Timo Cavelius,Lasse Strothe,Andrii Lata,Jana Diesner*

Main category: cs.CL

TL;DR: 本文提出一种融合大语言模型、知识图谱和实时搜索代理的事实核查系统，在准确率和发现信息能力方面大幅优于传统方法，并实现了模块化、开源和跨数据集的通用性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）虽然能够生成流利的语言表达，但欠缺可靠的事实支撑。而知识图谱驱动的事实核查工具证据精确且可解释性强，但覆盖范围有限或存在延迟。为了解决这两个技术方案的局限性，论文希望融合它们各自优点。

Method: 提出了三步混合式事实核查系统：首先通过DBpedia进行快速一跳知识图谱检索；接着用任务相关的标签提示词指导的大语言模型分类，实现具有内部规则推理的判断；当知识图谱覆盖不足时，调用网页搜索代理补充信息。整体设计为模块化、可开源、具有回退机制。

Result: 该系统在FEVER基准测试的Supported/Refuted分类上取得了F1值0.93，无需针对任务的微调。针对信息不足（NEI）样本，通过再标注发现新的有效证据，获得专家和LLM评审者确认。

Conclusion: 融合LLM、知识图谱和网路搜索的混合核查系统兼具高准确率、广泛适用性和可解释性，且通过回退机制显著提升了发现新证据的能力，表现优异。

Abstract: Large language models (LLMs) excel in generating fluent utterances but can
lack reliable grounding in verified information. At the same time,
knowledge-graph-based fact-checkers deliver precise and interpretable evidence,
yet suffer from limited coverage or latency. By integrating LLMs with knowledge
graphs and real-time search agents, we introduce a hybrid fact-checking
approach that leverages the individual strengths of each component. Our system
comprises three autonomous steps: 1) a Knowledge Graph (KG) Retrieval for rapid
one-hop lookups in DBpedia, 2) an LM-based classification guided by a
task-specific labeling prompt, producing outputs with internal rule-based
logic, and 3) a Web Search Agent invoked only when KG coverage is insufficient.
Our pipeline achieves an F1 score of 0.93 on the FEVER benchmark on the
Supported/Refuted split without task-specific fine-tuning. To address Not
enough information cases, we conduct a targeted reannotation study showing that
our approach frequently uncovers valid evidence for claims originally labeled
as Not Enough Information (NEI), as confirmed by both expert annotators and LLM
reviewers. With this paper, we present a modular, opensource fact-checking
pipeline with fallback strategies and generalization across datasets.

</details>


### [37] [Beyond Ranked Lists: The SARAL Framework for Cross-Lingual Document Set Retrieval](https://arxiv.org/abs/2511.03228)
*Shantanu Agarwal,Joel Barry,Elizabeth Boschee,Scott Miller*

Main category: cs.CL

TL;DR: 该工作提出了新的跨语言检索方法，可高效从多语言中检索相关文档集合，并在多个语言评测中取得领先表现。


<details>
  <summary>Details</summary>
Motivation: 推进跨语言信息检索（CLIR）技术的发展，满足不同语言之间的信息获取需求，响应IARPA的MATERIAL项目目标。

Method: 提出了一种新颖的方法，专注于检索与查询相关的文档集合（set），而不仅仅是生成排序的文档列表，并在具体实现中应用于Farsi、Kazakh和Georgian等多语言场景。

Result: 在MATERIAL项目第三阶段评测中，SARAL方法在三种语言的六项评测条件中五项表现优于其他团队。

Conclusion: 所提CLIR方法为跨语言检索任务提供了更优的解决思路，尤其是在需要检索相关文档集合的场景下具有明显优势。

Abstract: Machine Translation for English Retrieval of Information in Any Language
(MATERIAL) is an IARPA initiative targeted to advance the state of
cross-lingual information retrieval (CLIR). This report provides a detailed
description of Information Sciences Institute's (ISI's) Summarization and
domain-Adaptive Retrieval Across Language's (SARAL's) effort for MATERIAL.
Specifically, we outline our team's novel approach to handle CLIR with emphasis
in developing an approach amenable to retrieve a query-relevant document
\textit{set}, and not just a ranked document-list. In MATERIAL's Phase-3
evaluations, SARAL exceeded the performance of other teams in five out of six
evaluation conditions spanning three different languages (Farsi, Kazakh, and
Georgian).

</details>


### [38] [IndicSuperTokenizer: An Optimized Tokenizer for Indic Multilingual LLMs](https://arxiv.org/abs/2511.03237)
*Souvik Rana,Arul Menezes,Ashish Kulkarni,Chandra Khatri,Shubham Agarwal*

Main category: cs.CL

TL;DR: 作者提出了一种针对多语种大模型的高效新分词器，将多种分词策略结合，显著提升分词效果与推理效率，在大量语言和任务上取得最佳结果，并进行了全面实验分析。


<details>
  <summary>Details</summary>
Motivation: 多语言大模型（LLMs）在处理中印等多语种时，面临因不同文字、复杂形态变化导致的分词低效、不准确问题。目前主流的子词分词方法（如BPE）在多语种场景效果不足，且相关研究较少。

Method: 提出了IndicSuperTokenizer，将子词与多词分词结合，并引入语言特定的预分词处理，使分词结果更符合语言学特性。同时，对分词器训练数据量、词表规模、合并策略和预处理方式进行了消融实验分析。

Result: 在英文、22种印度语言及代码数据上，IndicSuperTokenizer的平均fertility score比LLaMA4提升39.5%，比当前最佳Sutra提升18%。推理吞吐量比LLaMA4提升44%，且在英文和印地语测评表现持平。

Conclusion: IndicSuperTokenizer通过创新的分词方法，有效提升多语种LLMs的分词质量与推理效率，在保留任务表现的同时极大优化了下游处理与部署成本。

Abstract: Tokenizers play a crucial role in determining the performance, training
efficiency, and the inference cost of Large Language Models (LLMs). Designing
effective tokenizers for multilingual LLMs is particularly challenging due to
diverse scripts and rich morphological variation. While subword methods such as
Byte Pair Encoding (BPE) are widely adopted, their effectiveness in
multilingual settings remains underexplored. We present IndicSuperTokenizer, a
tokenizer for Indic multilingual LLMs, that combines both subword and
multi-word tokenization, along with language-specific pre-tokenization, leading
to more linguistically aligned tokens and achieving a new state-of-the-art in
fertility score. Evaluated across English, 22 Indian languages and code data,
our tokenizer improves the average fertility score by 39.5% over LLaMA4 and by
18% over Sutra (the current best). This translates to 44% improvement in
inference throughput over LLaMA4 while maintaining comparable performance on
English and Indic benchmarks. We also present detailed ablations across
tokenizer training data size, vocabulary size, merging techniques, and
pre-tokenization strategies, demonstrating the robustness of our design
choices.

</details>


### [39] [Comparing the Performance of LLMs in RAG-based Question-Answering: A Case Study in Computer Science Literature](https://arxiv.org/abs/2511.03261)
*Ranul Dayarathne,Uvini Ranaweera,Upeksha Ganegoda*

Main category: cs.CL

TL;DR: 该研究比较了多款开源与专有LLM结合RAG技术在计算机科学领域问答任务中的表现，发现Mistral-7b-instruct在开源模型中最优，GPT-3.5整体表现最好，同时指出开源模型在良好基础设施下也能媲美专有模型。


<details>
  <summary>Details</summary>
Motivation: 鉴于生成式AI模型中虚假信息的问题，检索增强生成（RAG）技术正在被用来提升模型表现，尤其在问答领域有更高需求比较不同大语言模型（LLMs）的性能。该研究旨在系统地比较多个开源LLM与主流GPT-3.5在支持RAG的计算机科学文献问答任务中的表现。

Method: 比较了四个开源LLM（Mistral-7b-instruct、LLaMa2-7b-chat、Falcon-7b-instruct、Orca-mini-v3-7b）与OpenAI的GPT-3.5，在计算机科学文献的问答任务中应用RAG。评价指标包括：二元问题的准确率与精确率；由人工专家和Gemini AI模型完成的排名；以及长答案的余弦相似度。还分析了响应延迟。

Result: 结果显示，GPT-3.5结合RAG在回答二元与长答案问题方面表现最优，强化了其作为先进LLM的地位。在开源LLM中，Mistral-7b-instruct结合RAG在问答表现领先。Orca-mini-v3-7b生成响应平均延迟最短，LLaMa2-7b-chat则响应延迟最高。

Conclusion: 开源LLM（如Mistral-7b-instruct）在配合强大基础设施和RAG技术时，可实现接近甚至超越专有模型（如GPT-3.5）的问答表现。亦说明了开源模型与专有模型在强基础设施支持下可以齐头并进。

Abstract: Retrieval Augmented Generation (RAG) is emerging as a powerful technique to
enhance the capabilities of Generative AI models by reducing hallucination.
Thus, the increasing prominence of RAG alongside Large Language Models (LLMs)
has sparked interest in comparing the performance of different LLMs in
question-answering (QA) in diverse domains. This study compares the performance
of four open-source LLMs, Mistral-7b-instruct, LLaMa2-7b-chat,
Falcon-7b-instruct and Orca-mini-v3-7b, and OpenAI's trending GPT-3.5 over QA
tasks within the computer science literature leveraging RAG support. Evaluation
metrics employed in the study include accuracy and precision for binary
questions and ranking by a human expert, ranking by Google's AI model Gemini,
alongside cosine similarity for long-answer questions. GPT-3.5, when paired
with RAG, effectively answers binary and long-answer questions, reaffirming its
status as an advanced LLM. Regarding open-source LLMs, Mistral AI's
Mistral-7b-instruct paired with RAG surpasses the rest in answering both binary
and long-answer questions. However, among the open-source LLMs, Orca-mini-v3-7b
reports the shortest average latency in generating responses, whereas
LLaMa2-7b-chat by Meta reports the highest average latency. This research
underscores the fact that open-source LLMs, too, can go hand in hand with
proprietary models like GPT-3.5 with better infrastructure.

</details>


### [40] [SCALE: Upscaled Continual Learning of Large Language Models](https://arxiv.org/abs/2511.03270)
*Jin-woo Lee,Junhwa Choi,Bongkyu Hwang,Jinho Choo,Bogun Kim,JeongSeon Yi,Joonseok Lee,DongYoung Jung,Jaeseon Park,Kyoungwon Park,Suk-hoon Jung*

Main category: cs.CL

TL;DR: SCALE通过结构扩展并保持原权重，解决了大语言模型持续预训练中的新旧知识权衡问题，显著减少遗忘同时提升新任务表现。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型的持续预训练效果面临新挑战，单纯扩大参数规模已难进一步提升表现。作者发现模型结构的扩展比参数扩展更重要，提出需要找到合适的结构扩展方案。

Method: 提出一种SCALE宽度扩展架构，将轻量扩展插入线性模块，同时冻结所有预训练参数，从而保持模型残差与注意力结构；包括持久性保留（冻结原模型权重与保留初始化）、协同适应（训练扩展组件以获得新知识）、SCALE-Preserve、SCALE-Adapt和SCALE-Route等不同变体。

Result: 在合成传记基准测试中，SCALE减缓了传统深度扩展引起的遗忘现象，同时能学习新知识；在韩语语料持续预训练下，SCALE各变体在英文任务上遗忘更少，在韩语任务上取得有竞争力的提升，并实现最佳稳定性-可塑性权衡。

Conclusion: SCALE通过结构扩展、权重冻结以及灵活的协同机制，有效提升了大语言模型持续预训练过程中的新知识获取能力，并减少了旧知识遗忘，优化了稳定性与可塑性之间的关系。

Abstract: We revisit continual pre-training for large language models and argue that
progress now depends more on scaling the right structure than on scaling
parameters alone. We introduce SCALE, a width upscaling architecture that
inserts lightweight expansion into linear modules while freezing all
pre-trained parameters. This preserves the residual and attention topologies
and increases capacity without perturbing the base model's original
functionality. SCALE is guided by two principles: Persistent Preservation,
which maintains the base model's behavior via preservation-oriented
initialization and freezing of the pre-trained weights, and Collaborative
Adaptation, which selectively trains a subset of expansion components to
acquire new knowledge with minimal interference. We instantiate these ideas as
SCALE-Preserve (preservation-first), SCALE-Adapt (adaptation-first), and
SCALE-Route, an optional routing extension that performs token-level routing
between preservation and adaptation heads. On a controlled synthetic biography
benchmark, SCALE mitigates the severe forgetting observed with depth expansion
while still acquiring new knowledge. In continual pre-training on a Korean
corpus, SCALE variants achieve less forgetting on English evaluations and
competitive gains on Korean benchmarks, with these variants offering the best
overall stability-plasticity trade-off. Accompanying analysis clarifies when
preservation provably holds and why the interplay between preservation and
adaptation stabilizes optimization compared to standard continual learning
setups.

</details>


### [41] [How to Evaluate Speech Translation with Source-Aware Neural MT Metrics](https://arxiv.org/abs/2511.03295)
*Mauro Cettolo,Marco Gaido,Matteo Negri,Sara Papi,Luisa Bentivogli*

Main category: cs.CL

TL;DR: 论文提出了结合源信息用于语音翻译自动评测的新方法，创新性地解决了因缺乏源转录造成的对齐和代理问题，并通过两套方案（ASR转录和回译）验证了方法的有效性，提升了评测与人工标准的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的语音到文本翻译（ST）系统评估主要依赖于对比翻译假设和参考翻译，这种基于参考的评估忽略了源输入（如音频）的信息。而机器翻译领域已有研究表明，利用源文本的信息能更好地与人工评价结果一致。因此，作者希望将源信息引入ST系统的自动化评估中，但ST的源是音频，且常常没有准确的抄本或参照对齐，带来了新的难点。

Method: 提出两种生成输入音频文本代理的策略：一是利用自动语音识别（ASR）生成的转录文本，二是利用参考翻译回译生成“伪源”。此外，作者提出了一种跨语种双步重分段算法，用于缓解合成源与参考翻译之间的对齐问题，并支持在没有源转录的真实场景下，把MT评价指标有效地用于ST评估。

Result: 在两个ST基准（涵盖79种语言对和六种不同架构及性能的ST系统）上的实验表明，当ASR转录的词错误率低于20%时，ASR文本代理比回译更可靠。但回译方法在计算上更高效，在没有ASR转录时仍然有效。而提出的跨语种重分段算法显著提升了源感知评估指标在ST任务中的适用性和鲁棒性。

Conclusion: 实验验证了在真实条件下，结合源信息的机器翻译评测指标可用于ST系统自动化评价，尤其是自研的重分段算法和ASR代理源能提升评测一致性，为语音翻译领域更加精准和有理论依据的评估方法铺路。

Abstract: Automatic evaluation of speech-to-text translation (ST) systems is typically
performed by comparing translation hypotheses with one or more reference
translations. While effective to some extent, this approach inherits the
limitation of reference-based evaluation that ignores valuable information from
the source input. In machine translation (MT), recent progress has shown that
neural metrics incorporating the source text achieve stronger correlation with
human judgments. Extending this idea to ST, however, is not trivial because the
source is audio rather than text, and reliable transcripts or alignments
between source and references are often unavailable. In this work, we conduct
the first systematic study of source-aware metrics for ST, with a particular
focus on real-world operating conditions where source transcripts are not
available. We explore two complementary strategies for generating textual
proxies of the input audio, automatic speech recognition (ASR) transcripts, and
back-translations of the reference translation, and introduce a novel two-step
cross-lingual re-segmentation algorithm to address the alignment mismatch
between synthetic sources and reference translations. Our experiments, carried
out on two ST benchmarks covering 79 language pairs and six ST systems with
diverse architectures and performance levels, show that ASR transcripts
constitute a more reliable synthetic source than back-translations when word
error rate is below 20%, while back-translations always represent a
computationally cheaper but still effective alternative. Furthermore, our
cross-lingual re-segmentation algorithm enables robust use of source-aware MT
metrics in ST evaluation, paving the way toward more accurate and principled
evaluation methodologies for speech translation.

</details>


### [42] [Benchmarking the Thinking Mode of Multimodal Large Language Models in Clinical Tasks](https://arxiv.org/abs/2511.03328)
*Jindong Hong,Tianjie Chen,Lingjie Luo,Chuanyang Zheng,Ting Xu,Haibao Yu,Jianing Qiu,Qianzhong Chen,Suning Huang,Yan Xu,Yong Gui,Yijun He,Jiankai Sun*

Main category: cs.CL

TL;DR: 当前MMMLs的“思考模式”对提升医学任务效果帮助有限，复杂任务表现依然不足，需更好医学数据和方法支持。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大型语言模型（MLLMs）研究的推进，新出现的“可推理MLLMs”允许研究人员显式控制其“思考模式”，使模型能够在生成最终回答前进行逐步的内部推理。本研究旨在系统评估这些推理过程对医疗领域任务性能和可靠性的影响。

Method: 本文评测了两种主流MLLMs（Seed1.5-VL与Gemini-2.5-Flash）在医学任务中的主动“思考模式”能力。具体通过VQA-RAD和ROCOv2数据集，针对四个视觉医疗任务进行性能对比测试。

Result: 激活思考模式后，对大多数任务的性能提升有限。尤其是在复杂医学任务如开放性VQA和医学图像解读方面，表现仍不理想。

Conclusion: 当前MLLMs通过“思考模式”提升医疗任务效果有限，仍需依赖更具针对性的医学数据和更先进的医学知识融合方法来提升其专业能力。

Abstract: A recent advancement in Multimodal Large Language Models (MLLMs) research is
the emergence of "reasoning MLLMs" that offer explicit control over their
internal thinking processes (normally referred as the "thinking mode")
alongside the standard "non-thinking mode". This capability allows these models
to engage in a step-by-step process of internal deliberation before generating
a final response. With the rapid transition to and adoption of these
"dual-state" MLLMs, this work rigorously evaluated how the enhanced reasoning
processes of these MLLMs impact model performance and reliability in clinical
tasks. This paper evaluates the active "thinking mode" capabilities of two
leading MLLMs, Seed1.5-VL and Gemini-2.5-Flash, for medical applications. We
assessed their performance on four visual medical tasks using VQA-RAD and
ROCOv2 datasets. Our findings reveal that the improvement from activating the
thinking mode remains marginal compared to the standard non-thinking mode for
the majority of the tasks. Their performance on complex medical tasks such as
open-ended VQA and medical image interpretation remains suboptimal,
highlighting the need for domain-specific medical data and more advanced
methods for medical knowledge integration.

</details>


### [43] [Generative Artificial Intelligence in Bioinformatics: A Systematic Review of Models, Applications, and Methodological Advances](https://arxiv.org/abs/2511.03354)
*Riasad Alvi,Sayeem Been Zaman,Wasimul Karim,Arefin Ittesafun Abian,Mohaimenul Azam Khan Raiaan,Saddam Mukta,Md Rafi Ur Rashid,Md Rafiqul Islam,Yakub Sebastian,Sami Azam*

Main category: cs.CL

TL;DR: GenAI技术已显著推动生物信息学各领域进步，定制模型优势突出，但数据和可扩展性挑战待解。未来需关注更健壮的评估和贴合生物学机制的建模。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在生物信息学各子领域持续取得突破性进展，对已有成果进行系统梳理与客观评价十分必要，以识别最具代表性的技术路线、应用场景和存在的核心挑战。

Method: 采用系统综述和元分析方法，围绕六个研究问题（RQ1-RQ6）梳理GenAI在生物信息学中应用的进展、模型对比、应用效果、局限与未来趋势，同时基于权威数据库和基准任务进行分析验证。

Result: GenAI在序列分析、分子设计与数据整合等多领域表现优于传统技术，定制化模型（对特定任务预训练与上下文适配）显著优于通用模型。数据质量、模型泛化能力和可扩展性是制约因素。包括UniProtKB、CellxGENE等在内的数据资源支撑了模型训练与泛化能力的扩展。

Conclusion: 本文综述了生成式人工智能（GenAI）在生物信息学中的应用，并基于六大研究问题系统性总结其优势、局限及未来发展方向。GenAI模型已显著提升了结构建模、功能预测及合成数据生成等任务的表现，但其可扩展性及数据偏差问题仍需进一步解决。

Abstract: Generative artificial intelligence (GenAI) has become a transformative
approach in bioinformatics that often enables advancements in genomics,
proteomics, transcriptomics, structural biology, and drug discovery. To
systematically identify and evaluate these growing developments, this review
proposed six research questions (RQs), according to the preferred reporting
items for systematic reviews and meta-analysis methods. The objective is to
evaluate impactful GenAI strategies in methodological advancement, predictive
performance, and specialization, and to identify promising approaches for
advanced modeling, data-intensive discovery, and integrative biological
analysis. RQ1 highlights diverse applications across multiple bioinformatics
subfields (sequence analysis, molecular design, and integrative data modeling),
which demonstrate superior performance over traditional methods through pattern
recognition and output generation. RQ2 reveals that adapted specialized model
architectures outperformed general-purpose models, an advantage attributed to
targeted pretraining and context-aware strategies. RQ3 identifies significant
benefits in the bioinformatics domains, focusing on molecular analysis and data
integration, which improves accuracy and reduces errors in complex analysis.
RQ4 indicates improvements in structural modeling, functional prediction, and
synthetic data generation, validated by established benchmarks. RQ5 suggests
the main constraints, such as the lack of scalability and biases in data that
impact generalizability, and proposes future directions focused on robust
evaluation and biologically grounded modeling. RQ6 examines that molecular
datasets (such as UniProtKB and ProteinNet12), cellular datasets (such as
CELLxGENE and GTEx) and textual resources (such as PubMedQA and OMIM) broadly
support the training and generalization of GenAI models.

</details>


### [44] [Silenced Biases: The Dark Side LLMs Learned to Refuse](https://arxiv.org/abs/2511.03369)
*Rom Himelstein,Amit LeVi,Brit Youngmann,Yaniv Nemcovsky,Avi Mendelson*

Main category: cs.CL

TL;DR: 传统QA型公平性测评容易将模型拒答误判为公平。本文提出通过激活控制揭示隐藏偏见的新基准（SBB），并揭示多个大模型存在被对齐掩盖的显著公平性缺陷。


<details>
  <summary>Details</summary>
Motivation: 随着大模型逐步应用于敏感领域，模型公平性变得至关重要，但现有的公平性评估方法往往将模型拒答看作公平表现，而忽略了隐藏在对齐机制之下更深层的偏见问题。

Method: 提出Silenced Bias Benchmark（SBB），利用激活控制方法减少模型在QA中的拒答率，从而揭露隐藏在模型深层空间中的被对齐机制掩盖的偏见，实现对多种人口群体和主题的扩展性评测。

Result: 在多个大语言模型上的实验证明，模型直接回答与其内在公平性之间存在显著差异。SBB揭示了安全对齐机制无法完全消除深层偏见。

Conclusion: SBB为评估和揭示被对齐机制掩盖的模型偏见提供了新的框架，有助于推动更公平的模型开发和工具研究。

Abstract: Safety-aligned large language models (LLMs) are becoming increasingly
widespread, especially in sensitive applications where fairness is essential
and biased outputs can cause significant harm. However, evaluating the fairness
of models is a complex challenge, and approaches that do so typically utilize
standard question-answer (QA) styled schemes. Such methods often overlook
deeper issues by interpreting the model's refusal responses as positive
fairness measurements, which creates a false sense of fairness. In this work,
we introduce the concept of silenced biases, which are unfair preferences
encoded within models' latent space and are effectively concealed by
safety-alignment. Previous approaches that considered similar indirect biases
often relied on prompt manipulation or handcrafted implicit queries, which
present limited scalability and risk contaminating the evaluation process with
additional biases. We propose the Silenced Bias Benchmark (SBB), which aims to
uncover these biases by employing activation steering to reduce model refusals
during QA. SBB supports easy expansion to new demographic groups and subjects,
presenting a fairness evaluation framework that encourages the future
development of fair models and tools beyond the masking effects of alignment
training. We demonstrate our approach over multiple LLMs, where our findings
expose an alarming distinction between models' direct responses and their
underlying fairness issues.

</details>


### [45] [EQ-Negotiator: Dynamic Emotional Personas Empower Small Language Models for Edge-Deployable Credit Negotiation](https://arxiv.org/abs/2511.03370)
*Yunbo Long,Yuhan Liu,Alexandra Brintrup*

Main category: cs.CL

TL;DR: 该论文提出EQ-Negotiator框架，使小型语言模型在端侧也能高效完成复杂信贷谈判，通过动态情绪推理系统，使其性能优于更大规模模型，实现安全、高效、隐私保护的自动化AI谈判员。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然在自动化谈判中表现出色，但其高昂的计算成本和数据隐私问题使其不适合许多端侧私密应用。小型语言模型虽能部署于此，但在应对具有复杂情绪的谈判任务（如信贷谈判）时与大模型存在明显能力差距。为解决这一鸿沟，提出创新框架。

Method: 结合博弈论与隐马尔可夫模型(HMM)的推理系统，实现在线学习与追踪债务人情绪状态，无需预训练。基于该系统，赋能小型语言模型具备应对情绪复杂谈判的能力。通过大规模代理仿真实验验证效果。

Result: 配备EQ-Negotiator的7B参数小模型，在多个信贷谈判场景中，包括面对作弊、威胁、装可怜等对手策略，达到甚至优于十倍体量大模型的债务回收与谈判效率。动态情绪建模逐渐取代静态角色设定，实现兼具隐私保护和高效谈判。

Conclusion: 战略性情绪智能是自动化谈判成功的关键，而非模型的体量规模。EQ-Negotiator为小型语言模型赋能，在保护隐私的前提下，提升自动化谈判效率与效果。

Abstract: The deployment of large language models (LLMs) in automated negotiation has
set a high performance benchmark, but their computational cost and data privacy
requirements render them unsuitable for many privacy-sensitive, on-device
applications such as mobile assistants, embodied AI agents or private client
interactions. While small language models (SLMs) offer a practical alternative,
they suffer from a significant performance gap compared to LLMs in playing
emotionally charged complex personas, especially for credit negotiation. This
paper introduces EQ-Negotiator, a novel framework that bridges this capability
gap using emotional personas. Its core is a reasoning system that integrates
game theory with a Hidden Markov Model(HMM) to learn and track debtor emotional
states online, without pre-training. This allows EQ-Negotiator to equip SLMs
with the strategic intelligence to counter manipulation while de-escalating
conflict and upholding ethical standards. Through extensive agent-to-agent
simulations across diverse credit negotiation scenarios, including adversarial
debtor strategies like cheating, threatening, and playing the victim, we show
that a 7B parameter language model with EQ-Negotiator achieves better debt
recovery and negotiation efficiency than baseline LLMs more than 10 times its
size. This work advances persona modeling from descriptive character profiles
to dynamic emotional architectures that operate within privacy constraints.
Besides, this paper establishes that strategic emotional intelligence, not raw
model scale, is the critical factor for success in automated negotiation,
paving the way for effective, ethical, and privacy-preserving AI negotiators
that can operate on the edge.

</details>


### [46] [LFC-DA: Logical Formula-Controlled Data Augmentation for Enhanced Logical Reasoning](https://arxiv.org/abs/2511.03372)
*Shenghao Li*

Main category: cs.CL

TL;DR: 提出了一种用符号逻辑控制的数据增强方法LFC-DA，兼顾了自动化、逻辑多样性和严密性，有效提升大模型在逻辑推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有逻辑数据增强方法要么依赖人工标注，成本高；要么依赖大模型直接生成，导致难以解释且形式单一。为提高手动标注效率并增加数据多样性和逻辑严密性，作者提出了新的增强流程。

Method: 提出了LFC-DA符号逻辑控制流程：1）将逻辑文本转换为命题表达式；2）编译紧凑规则库；3）有限状态空间搜索系统性地发现有效公式；4）将公式还原为自然语言问题，从而兼顾多样性与逻辑严密性。最后在ReClor与LogiQA数据集上进行实验评估。

Result: 在ReClor和LogiQA两个逻辑推理任务数据集上，利用该方法增强后的模型逻辑推理准确率明显提升，验证了方法的有效性。

Conclusion: 通过引入LFC-DA符号逻辑控制流程，可以有效提升预训练模型在逻辑推理任务中的表现，验证了该方法用于大模型引导下逻辑数据增强的有效性。

Abstract: For complex logical data augmentation, heavy reliance on human annotation is
costly, whereas direct generation with large language models yields
uninterpretable and logically homogeneous examples. To address this, we present
LFC-DA, a symbolic-logic-controlled pipeline: logical text is first mapped to
propositional expressions, a compact rule library is compiled, and a bounded
state-space search systematically discovers valid formulas that are then
verbalized back into natural-language questions, ensuring both diversity and
logical rigor under propositional logic. Experiments on ReClor and LogiQA show
significant improvements in the logical-reasoning accuracy of pretrained
models, confirming the effectiveness of LFC-DA for LLM-guided logical data
augmentation.

</details>


### [47] [Segmentation Beyond Defaults: Asymmetrical Byte Pair Encoding for Optimal Machine Translation Performance](https://arxiv.org/abs/2511.03383)
*Saumitra Yadav,Manish Shrivastava*

Main category: cs.CL

TL;DR: 本研究发现对称BPE分词并非最佳选择。通过实验表明，不对称BPE（源目标合并数不同）能大幅提升低资源机器翻译效果，尤其在多语言设置下更优。


<details>
  <summary>Details</summary>
Motivation: 传统机器翻译常用对称BPE方案（源目标语言合并次数相同），但并未系统验证这种做法在不同语对和数据规模下是否最优，因此作者有动机探索更优的分词参数设置。

Method: 实验比较了对称和不对称BPE方案，在多种语料规模和包括英语-印地语在内的多对语言上进行机器翻译评测，统计分析各方案的性能差异。

Result: 在低资源环境下（5万、10万、50万句），不对称BPE方案（源语言高参数4K-32K，目标语言低参数0.5K-2K）在大多数语对上获得了显著且统计有效的提升，英-印地语最高提升5.32 CHRF++。

Conclusion: 采用源语言和目标语言不对称的BPE（不同合并次数参数）方案普遍优于传统的对称BPE，尤其是低资源语言环境，可显著提升机器翻译质量。

Abstract: Existing Machine Translation (MT) research often suggests a single, fixed set
of hyperparameters for word segmentation models, symmetric Byte Pair Encoding
(BPE), which applies the same number of merge operations (NMO) to train
tokenizers for both source and target languages. However, we demonstrate that
this uniform approach doesn't guarantee optimal MT performance across different
language pairs and data sizes. This work investigates BPE segmentation recipes
across various data volumes and language pairs to evaluate MT system
performance. We find that utilizing asymmetric BPE, where the source and target
languages have different NMOs, significantly improves results over the
symmetric approach, especially in low-resource settings (50K, 100K, and 500K
sentence pairs). Specifically, asymmetric BPE yield statistically significant
($p<0.05$) average gains of 5.32, 4.46, and 0.7 CHRF++ on English-Hindi in
low-resource setups. We validated this trend across six additional language
pairs (English and Telugu, Shona, Norwegian, Kyrgyz, Hausa, and Inuktitut),
observing statistically significant improvement in 10 out of 12 systems
compared to symmetric BPE. Our findings indicate a high NMO for the source (4K
to 32K) and a low NMO for the target (0.5K to 2K) provides optimal results,
particularly benefiting low-resource MT.

</details>


### [48] [Overcoming the Generalization Limits of SLM Finetuning for Shape-Based Extraction of Datatype and Object Properties](https://arxiv.org/abs/2511.03407)
*Célian Ringwald,Fabien Gandon,Catherine Faron,Franck Michel,Hanna Abi Akl*

Main category: cs.CL

TL;DR: 本研究针对小型语言模型抽取RDF图谱时面临的稀有属性长尾瓶颈，系统评估四种优化策略，发现提高训练集中每个属性出现次数能有效提升模型表现，并公开数据和代码促进复现。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型（SLMs）在利用SHACL形状指导关系抽取（RE）时，主要集中在通用的数据类型属性提取，取得了良好效果。但在同时抽取实体属性（object property）和数据类型属性以实现完整的RDF图谱时，面临稀有属性分布长尾效应的瓶颈。本文动机是探究并优化SLMs对全属性抽取效果、提升其平衡性和鲁棒性。

Method: 本文系统分析长尾属性瓶颈，并评估四种解决策略：分层采样（stratified sampling）、加权损失（weighted loss）、数据集扩展（dataset scaling）、基于模板的合成数据增强（template-based synthetic data augmentation）。通过调节训练集中的属性出现次数，寻找最佳平衡方法。

Result: 实验结果表明：最有效的策略是构建训练集，使每个目标属性出现次数超过设定阈值，这样可以显著提升SLMs在不均衡属性上的抽取表现。

Conclusion: 研究展示了训练集属性数量阈值对抽取效果的关键作用，为训练形状感知的SLMs、处理不均衡语义关系抽取提供了实用指导，并为未来研究指出了方向。

Abstract: Small language models (SLMs) have shown promises for relation extraction (RE)
when extracting RDF triples guided by SHACL shapes focused on common datatype
properties. This paper investigates how SLMs handle both datatype and object
properties for a complete RDF graph extraction. We show that the key bottleneck
is related to long-tail distribution of rare properties. To solve this issue,
we evaluate several strategies: stratified sampling, weighted loss, dataset
scaling, and template-based synthetic data augmentation. We show that the best
strategy to perform equally well over unbalanced target properties is to build
a training set where the number of occurrences of each property exceeds a given
threshold. To enable reproducibility, we publicly released our datasets,
experimental results and code. Our findings offer practical guidance for
training shape-aware SLMs and highlight promising directions for future work in
semantic RE.

</details>


### [49] [Efficient Reasoning via Thought-Training and Thought-Free Inference](https://arxiv.org/abs/2511.03408)
*Canhui Wu,Qiong Cao,Chao Xue,Wei Xi,Xiaodong He*

Main category: cs.CL

TL;DR: 3TF框架通过训练模型内化推理过程，实现了在推理输出简洁（无显性思路步骤）情况下，依然达到高推理准确率，显著提升模型推理效率和表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在提升推理准确性方面，多数方法侧重于通过压缩冗长的推理输出以提升效率，但这一过程中推理步骤仍需显性展现。研究动机在于探索能否仅通过简洁输出获得高质量推理能力，既提升效率又确保推理质量。

Method: 提出3TF框架，即“思维训练与无思维推理”。该方法包括：首先训练一个能在推理(显性输出)和无推理(简洁输出)两种模式下运行的混合模型；随后在带有推理标注（CoT）的数据上进一步训练，使模型内化推理能力；最后，在推断阶段采用无推理模式，直接输出简洁答案。

Result: 实验证明，3TF训练下的模型在无需显性推理步骤的情况下，在多个推理基准数据集上大幅提升了思维推理能力，实现了高质量内隐推理且输出简洁。

Conclusion: 3TF能让大模型在满足推理准确性的同时，显著减少推理文字输出，提升推理效率，证明复杂推理能力可以被模型内化，无需每步都显性展现。

Abstract: Recent advances in large language models (LLMs) have leveraged explicit
Chain-of-Thought (CoT) prompting to improve reasoning accuracy. However, most
existing methods primarily compress verbose reasoning outputs. These
Long-to-Short transformations aim to improve efficiency, but still rely on
explicit reasoning during inference. In this work, we introduce \textbf{3TF}
(\textbf{T}hought-\textbf{T}raining and \textbf{T}hought-\textbf{F}ree
inference), a framework for efficient reasoning that takes a Short-to-Long
perspective. We first train a hybrid model that can operate in both reasoning
and non-reasoning modes, and then further train it on CoT-annotated data to
internalize structured reasoning, while enforcing concise, thought-free outputs
at inference time using the no-reasoning mode. Unlike compression-based
approaches, 3TF improves the reasoning quality of non-reasoning outputs,
enabling models to perform rich internal reasoning implicitly while keeping
external outputs short. Empirically, 3TF-trained models obtain large
improvements on reasoning benchmarks under thought-free inference,
demonstrating that high quality reasoning can be learned and executed
implicitly without explicit step-by-step generation.

</details>


### [50] [Knowledge-Augmented Question Error Correction for Chinese Question Answer System with QuestionRAG](https://arxiv.org/abs/2511.03410)
*Longpeng Qiu,Ting Li,Shuai Mao,Nan Yang,Xiaohui Yan*

Main category: cs.CL

TL;DR: 本文提出了QuestionRAG，通过知识增强和强化学习对齐，有效解决了问答系统中输入误解和过度修正问题，显著提升了大语言模型的问题纠正能力。


<details>
  <summary>Details</summary>
Motivation: 现有问答系统在遇到输入错误时，常常会产生错误的回答。尤其是大语言模型（LLM）在用户意图解读和输入修正方面存在两大难题：要么误解问题（misinterpretation），要么进行过度修正（over-correction），导致答案偏离原意。

Method: 提出了QuestionRAG框架。该框架一方面通过引入外部知识（如搜索结果、相关实体等）来丰富输入，解决用户意图误解问题；另一方面利用强化学习（RL）方法，使模型在纠正输入时专注于精准修正而非简单释义，防止过度修正。

Result: 实验表明，知识增强在理解有误输入问题时至关重要。同时，基于RL的对齐方式明显优于传统的监督微调方法（SFT），显著提升了模型的指令遵循能力和泛化能力。两种策略结合后，极大提升了LLM在问题纠正任务中的表现。

Conclusion: 结合知识增强与强化学习对齐，能最大限度发挥大语言模型在问题纠正领域的潜力。QuestionRAG框架兼顾理解和修正，显著提升系统表现。

Abstract: Input errors in question-answering (QA) systems often lead to incorrect
responses. Large language models (LLMs) struggle with this task, frequently
failing to interpret user intent (misinterpretation) or unnecessarily altering
the original question's structure (over-correction). We propose QuestionRAG, a
framework that tackles these problems. To address misinterpretation, it
enriches the input with external knowledge (e.g., search results, related
entities). To prevent over-correction, it uses reinforcement learning (RL) to
align the model's objective with precise correction, not just paraphrasing. Our
results demonstrate that knowledge augmentation is critical for understanding
faulty questions. Furthermore, RL-based alignment proves significantly more
effective than traditional supervised fine-tuning (SFT), boosting the model's
ability to follow instructions and generalize. By integrating these two
strategies, QuestionRAG unlocks the full potential of LLMs for the question
correction task.

</details>


### [51] [CareMedEval dataset: Evaluating Critical Appraisal and Reasoning in the Biomedical Field](https://arxiv.org/abs/2511.03441)
*Doria Bonzi,Alexandre Guiggi,Frédéric Béchet,Carlos Ramisch,Benoit Favre*

Main category: cs.CL

TL;DR: 本文提出CareMedEval医学批判性评价数据集，发现主流大模型在该任务上表现不足，尤其在研究局限性和统计分析方面，突显模型推理能力局限，为后续AI辅助医学评价研究提供了挑战性标准。


<details>
  <summary>Details</summary>
Motivation: 在医学领域，批判性阅读和评价科学文献是重要技能，但现有大模型在处理此类专业性强的推理任务时表现有限，需要更专业化的测试工具。

Method: 提出CareMedEval数据集，收集自法国医学生真实考试，包括534个源自37篇科学论文的题目，专门用于评估大模型在医学批判性阅读和推理任务上的表现。通过对多个主流通用和医学领域大模型进行基准测试，比较在不同语境条件下的表现。

Result: 无论是开放源代码还是商业化模型，在精确匹配率上都未能超过0.5。虽然生成中间推理步骤有助提升表现，但在研究局限性和统计分析类问题上依然受挑战。

Conclusion: CareMedEval数据集为医学领域的文献批判性推理提供了专业性且难度较高的评测基准，揭示了当前大型语言模型的局限，也为未来自动化医学文献评价工具的开发奠定基础。

Abstract: Critical appraisal of scientific literature is an essential skill in the
biomedical field. While large language models (LLMs) can offer promising
support in this task, their reliability remains limited, particularly for
critical reasoning in specialized domains. We introduce CareMedEval, an
original dataset designed to evaluate LLMs on biomedical critical appraisal and
reasoning tasks. Derived from authentic exams taken by French medical students,
the dataset contains 534 questions based on 37 scientific articles. Unlike
existing benchmarks, CareMedEval explicitly evaluates critical reading and
reasoning grounded in scientific papers. Benchmarking state-of-the-art
generalist and biomedical-specialized LLMs under various context conditions
reveals the difficulty of the task: open and commercial models fail to exceed
an Exact Match Rate of 0.5 even though generating intermediate reasoning tokens
considerably improves the results. Yet, models remain challenged especially on
questions about study limitations and statistical analysis. CareMedEval
provides a challenging benchmark for grounded reasoning, exposing current LLM
limitations and paving the way for future development of automated support for
critical appraisal.

</details>


### [52] [Kastor: Fine-tuned Small Language Models for Shape-based Active Relation Extraction](https://arxiv.org/abs/2511.03466)
*Ringwald Celian,Gandon Fabien,Faron Catherine,Michel Franck,Abi Akl Hanna*

Main category: cs.CL

TL;DR: Kastor框架通过优化属性组合和迭代学习，大幅提升小语言模型在专业领域知识库关系抽取及补全的效果。


<details>
  <summary>Details</summary>
Motivation: 传统的RDF关系抽取方法面临在专业领域知识库高效补全和精炼的挑战，尤其在训练数据有限情况下。本文旨在通过改进模式，提升小语言模型（SLM）在关系抽取任务中的表现。

Method: 提出Kastor框架，将关系抽取任务由单一SHACL shape验证扩展到所有可能属性组合，通过为每个训练样本选择最优组合，提升模型泛化能力。还采用迭代学习机制，减少噪声知识基影响，持续优化模型。

Result: Kastor框架能有效提高模型在专业领域知识库中的关系抽取能力和泛化性能，并能持续优化知识库的准确性和完整性。

Conclusion: 通过RDF模式提取和Kastor框架，能够在数据有限时强化小模型的关系抽取和知识库补全能力，实现更精准、更通用的专业知识推理。

Abstract: RDF pattern-based extraction is a compelling approach for fine-tuning small
language models (SLMs) by focusing a relation extraction task on a specified
SHACL shape. This technique enables the development of efficient models trained
on limited text and RDF data. In this article, we introduce Kastor, a framework
that advances this approach to meet the demands for completing and refining
knowledge bases in specialized domains. Kastor reformulates the traditional
validation task, shifting from single SHACL shape validation to evaluating all
possible combinations of properties derived from the shape. By selecting the
optimal combination for each training example, the framework significantly
enhances model generalization and performance. Additionally, Kastor employs an
iterative learning process to refine noisy knowledge bases, enabling the
creation of robust models capable of uncovering new, relevant facts

</details>


### [53] [BanglaSTEM: A Parallel Corpus for Technical Domain Bangla-English Translation](https://arxiv.org/abs/2511.03498)
*Kazi Reyazul Hasan,Mubasshira Musarrat,A. B. M. Alim Al Islam,Muhammad Abdullah Adnan*

Main category: cs.CL

TL;DR: 为解决孟加拉语技术问题翻译准确性低及专业术语误译问题，作者构建了技术领域孟加拉语-英语高质量平行语料，并基于T5模型提升翻译质量，实验证明技术内容翻译效果大幅提升，相关数据集和模型已开源。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在英文技术问题上表现优异，但对孟加拉语技术问题翻译和理解能力差，现有机器翻译系统常常错误翻译专业术语，导致技术语境下的意图失真和答题错误。

Method: 构建包含5000对STEM领域高质量孟加拉语-英语句对的数据集BanglaSTEM，利用生成式模型自动翻译，并通过人工评估选出最佳翻译；基于T5架构训练翻译模型，并在代码生成与数学解题任务上进行评测。

Result: 在技术文本翻译准确性上取得了显著提升，促进了孟加拉语用户对以英语为主导的大语言模型的使用。BanglaSTEM数据集和训练好的模型已公开发布。

Conclusion: 通过BanglaSTEM数据集和基于T5的翻译模型，提升了技术领域术语的翻译准确性，从而帮助孟加拉语用户更好地利用基于英语的大语言模型进行技术问题求解。

Abstract: Large language models work well for technical problem solving in English but
perform poorly when the same questions are asked in Bangla. A simple solution
would be to translate Bangla questions into English first and then use these
models. However, existing Bangla-English translation systems struggle with
technical terms. They often mistranslate specialized vocabulary, which changes
the meaning of the problem and leads to wrong answers. We present BanglaSTEM, a
dataset of 5,000 carefully selected Bangla-English sentence pairs from STEM
fields including computer science, mathematics, physics, chemistry, and
biology. We generated over 12,000 translations using language models and then
used human evaluators to select the highest quality pairs that preserve
technical terminology correctly. We train a T5-based translation model on
BanglaSTEM and test it on two tasks: generating code and solving math problems.
Our results show significant improvements in translation accuracy for technical
content, making it easier for Bangla speakers to use English-focused language
models effectively. Both the BanglaSTEM dataset and the trained translation
model are publicly released at https://huggingface.co/reyazul/BanglaSTEM-T5.

</details>


### [54] [HaluMem: Evaluating Hallucinations in Memory Systems of Agents](https://arxiv.org/abs/2511.03506)
*Ding Chen,Simin Niu,Kehang Li,Peng Liu,Xiangping Zheng,Bo Tang,Xinchi Li,Feiyu Xiong,Zhiyu Li*

Main category: cs.CL

TL;DR: 论文提出HaluMem基准，从操作层面系统性评测和分析了AI记忆系统在提取、更新及问答各阶段的幻觉现象，并创建了新的大规模多回合数据集。研究发现记忆幻觉主要在提取与更新阶段产生并累积，呼吁未来关注机制性抑制幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有对记忆系统幻觉的评测多为端到端问答，难以定位幻觉出现的操作阶段，亟需能分阶段精细评测幻觉现象的新工具和数据集。

Method: 提出HaluMem基准，定义了三大操作级评测任务（记忆提取、记忆更新、记忆问答），构建了包含多回合人机交互的数据集HaluMem-Medium和HaluMem-Long，用于在不同上下文规模和任务复杂度下评测幻觉现象。

Result: HaluMem揭示了记忆系统幻觉在各操作阶段的表现，量化了幻觉积累与传播特性，为系统性抑制幻觉并提升记忆系统性能提供了实证基础。

Conclusion: 基于HaluMem的实证研究显示，现有记忆系统容易在信息提取和更新阶段产生并累积幻觉现象，最终传导至问答阶段，建议未来应聚焦于开发可解释且受约束的操作机制，系统性地压制幻觉并提升记忆可靠性。

Abstract: Memory systems are key components that enable AI systems such as LLMs and AI
agents to achieve long-term learning and sustained interaction. However, during
memory storage and retrieval, these systems frequently exhibit memory
hallucinations, including fabrication, errors, conflicts, and omissions.
Existing evaluations of memory hallucinations are primarily end-to-end question
answering, which makes it difficult to localize the operational stage within
the memory system where hallucinations arise. To address this, we introduce the
Hallucination in Memory Benchmark (HaluMem), the first operation level
hallucination evaluation benchmark tailored to memory systems. HaluMem defines
three evaluation tasks (memory extraction, memory updating, and memory question
answering) to comprehensively reveal hallucination behaviors across different
operational stages of interaction. To support evaluation, we construct
user-centric, multi-turn human-AI interaction datasets, HaluMem-Medium and
HaluMem-Long. Both include about 15k memory points and 3.5k multi-type
questions. The average dialogue length per user reaches 1.5k and 2.6k turns,
with context lengths exceeding 1M tokens, enabling evaluation of hallucinations
across different context scales and task complexities. Empirical studies based
on HaluMem show that existing memory systems tend to generate and accumulate
hallucinations during the extraction and updating stages, which subsequently
propagate errors to the question answering stage. Future research should focus
on developing interpretable and constrained memory operation mechanisms that
systematically suppress hallucinations and improve memory reliability.

</details>


### [55] [One Battle After Another: Probing LLMs' Limits on Multi-Turn Instruction Following with a Benchmark Evolving Framework](https://arxiv.org/abs/2511.03508)
*Qi Jia,Kaiwei Zhang,Xiujie Song,Ye Shen,Xiangyang Zhu,Guangtao Zhai*

Main category: cs.CL

TL;DR: 提出了一种新颖多轮对话能力评测框架和相应基准，有效检验了主流大模型在持续指令跟随上的差距，GPT-5显著领先。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）多轮对话指令跟随能力评测基准存在轮次固定、易饱和及未能充分反映用户交互体验的问题。该工作旨在提出更契合实际应用的多轮评测方法。

Method: 提出一种可扩展的多轮对话能力评测框架。该框架通过三层机制分别追踪对话中的约束、指令与主题，实现了用户意图与语言表述的分离，能够动态构建包含状态变化和回溯的基准，并通过‘用户耐心耗尽’结束会话。提出了一组新的衡量交互过程质量的指标。并据此构建了EvolIF基准，涵盖九类约束类型。

Result: 基于所建框架及EvolIF基准，评测了多款主流LLM，其中GPT-5表现最佳，平均可维持18.54轮对话，指令跟随鲁棒性为70.31%，比Gemini-2.5-Pro高出11.41%，明显优于其他模型。

Conclusion: 文中提出的多轮交互评测框架及新基准能更真实、全面地评估和区分当前LLM的持续指令跟随能力，为后续模型开发和应用设计提供了有效参考。

Abstract: Understanding how well large language models can follow users' instructions
throughout a dialogue spanning multiple topics is of great importance for
data-intensive conversational applications. Existing benchmarks are often
limited to a fixed number of turns, making them susceptible to saturation and
failing to account for the user's interactive experience. In this work, we
propose an extensible framework for assessing multi-turn instruction-following
ability. At its core, our framework decouples linguistic surface forms from
user intent simulation through a three-layer mechanism that tracks constraints,
instructions, and topics. This framework mimics User-LLM interaction by
enabling the dynamic construction of benchmarks with state changes and
tracebacks, terminating a conversation only when the model exhausts a simulated
user's patience. We define a suite of metrics capturing the quality of the
interaction process. Using this framework, we construct EvolIF, an evolving
instruction-following benchmark incorporating nine distinct constraint types.
Our results indicate that GPT-5 exhibits superior instruction-following
performance. It sustains an average of 18.54 conversational turns and
demonstrates 70.31% robustness, outperforming Gemini-2.5-Pro by a significant
margin of 11.41%, while other models lag far behind. All of the data and code
will be made publicly available online.

</details>


### [56] [SOLVE-Med: Specialized Orchestration for Leading Vertical Experts across Medical Specialties](https://arxiv.org/abs/2511.03542)
*Roberta Di Marino,Giovanni Dioguardi,Antonio Romano,Giuseppe Riccio,Mariano Barone,Marco Postiglione,Flora Amato,Vincenzo Moscato*

Main category: cs.CL

TL;DR: SOLVE-Med通过多智能体和专科定制模型，有效提升医学问答性能并支持本地部署，表现优越且公开可用。


<details>
  <summary>Details</summary>
Motivation: 医学问答系统在实际应用中面临幻觉、偏见、计算资源需求高、隐私问题以及需在多领域具备专业知识等诸多挑战。

Method: 提出SOLVE-Med多智能体架构，利用领域专精的小型语言模型协作回答复杂医学问题；系统包括动态专家分流的Router Agent、针对十个医学专科领域微调的专用模型（每模型规模为1B参数）、负责整合答案的Orchestrator Agent。

Result: 在意大利医学论坛的十个专科数据上，SOLVE-Med取得ROUGE-1分数0.301、BERTScore F1分数0.697，效果优于规模高达14B参数的单一模型，可支持本地部署。

Conclusion: SOLVE-Med系统在医学多领域问答任务中兼顾性能和部署效率，显著优于大型单一模型并解决关键实际问题，同时代码已公开。

Abstract: Medical question answering systems face deployment challenges including
hallucinations, bias, computational demands, privacy concerns, and the need for
specialized expertise across diverse domains. Here, we present SOLVE-Med, a
multi-agent architecture combining domain-specialized small language models for
complex medical queries. The system employs a Router Agent for dynamic
specialist selection, ten specialized models (1B parameters each) fine-tuned on
specific medical domains, and an Orchestrator Agent that synthesizes responses.
Evaluated on Italian medical forum data across ten specialties, SOLVE-Med
achieves superior performance with ROUGE-1 of 0.301 and BERTScore F1 of 0.697,
outperforming standalone models up to 14B parameters while enabling local
deployment. Our code is publicly available on GitHub:
https://github.com/PRAISELab-PicusLab/SOLVE-Med.

</details>
