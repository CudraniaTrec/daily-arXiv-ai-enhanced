<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]
- [cs.SE](#cs.SE) [Total: 4]
- [cs.LO](#cs.LO) [Total: 4]
- [cs.CL](#cs.CL) [Total: 4]
- [cs.DM](#cs.DM) [Total: 1]
- [cs.FL](#cs.FL) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Expanding Specification Capabilities of a Gradual Verifier with Pure Functions](https://arxiv.org/abs/2511.22075)
*Doruk Alp Mutlu*

Main category: cs.PL

TL;DR: 本文提出在Gradual C0中引入纯函数以扩展其规范能力，解决复杂表达受限及纯函数公理化问题，为逐步验证提供了新的技术手段。


<details>
  <summary>Details</summary>
Motivation: 现有的Gradual C0逐步验证系统虽然可实践，但其规范语言在表达复杂表达式时能力有限，这限制了其应用范围和灵活性。扩展表达能力成为关键需求。

Method: 提出在Gradual C0中引入纯函数支持，借鉴许多静态验证工具中的常用结构，以实现规范能力的扩展和便于观测方法的编码。同时解决了纯函数不精确定义带来的公理化技术难题。

Result: 该方法理论上扩展了Gradual C0的规范表达能力，并简化了观测方法的实现。

Conclusion: 通过引入纯函数，Gradual C0的规范能力与实用性得到提升，为逐步验证复杂程序提供了更强支持。

Abstract: Gradual verification soundly combines static checking and dynamic checking to provide an incremental approach for software verification. With gradual verification, programs can be partially specified first, and then the full specification of a program can be achieved in incremental steps. The first and only practicable gradual verifier based on symbolic execution, Gradual C0, supports recursive heap data structures. Despite recent efforts to improve the expressivity of Gradual C0's specification language, Gradual C0's specification language is still limited in its capabilities for complex expressions. This work explores an extension to Gradual C0's design with a common construct supported by many static verification tools, pure functions, which both extend the specification capabilities of Gradual C0 and increase the ease of encoding observer methods in Gradual C0. Our approach addresses the technical challenges related to the axiomatisation of pure functions with imprecise specifications.

</details>


### [2] [On Circuit Description Languages, Indexed Monads, and Resource Analysis](https://arxiv.org/abs/2511.22419)
*Ken Sakayori,Andrea Colledan,Ugo Dal Lago*

Main category: cs.PL

TL;DR: 文章构建了适用于Proto-Quipper等量子编程语言的Monad型语义模型，实现了电路生成与归约结果分离，并通过创新电路代数概念，使类型系统能有效控制和验证所生成电路的规模和属性，即便在优化过程中也能维持这些保证。


<details>
  <summary>Details</summary>
Motivation: 现有量子编程语言如Quipper在建模电路结构和控制电路大小方面面临语义上的挑战，有效模型与类型控制工具的缺乏阻碍了优化和验证。

Method: 采用Monad（单子）理论，构建电路代数，使得项归约值与生成电路副作用分离，从而支持更丰富的类型系统及定量属性验证。

Result: 提出了全新的电路代数语义框架，能够在模型与类型层面对电路的抽象和数量特性进行验证，即使在加入优化的情况下也有保证，并阐述了效应类型为保证电路定量属性提供的途径。

Conclusion: 本文提出的基于Monad的指称语义模型能够很好地刻画和验证Proto-Quipper以及相关理想化的量子编程语言的性质，尤其赋予量子电路的生成以良好的类型与数量控制能力。

Abstract: In this paper, a monad-based denotational model is introduced and shown adequate for the Proto-Quipper family of calculi, themselves being idealized versions of the Quipper programming language. The use of a monadic approach allows us to separate the value to which a term reduces from the circuit that the term itself produces as a side effect. In turn, this enables the denotational interpretation and validation of rich type systems in which the size of the produced circuit can be controlled. Notably, the proposed semantic framework, through the novel concept of circuit algebra, suggests forms of effect typing guaranteeing quantitative properties about the resulting circuit, even in presence of optimizations.

</details>


### [3] [A Synthetic Reconstruction of Multiparty Session Types (with Appendix)](https://arxiv.org/abs/2511.22692)
*David Castro-Perez,Francisco Ferreira,Sung-Shik Jongmans*

Main category: cs.PL

TL;DR: 这篇论文提出了一种同时具备高表达性和组合性的多方会话类型验证新方法，通过用类型系统直接对整体协议LTS进行验证，突破了传统方法的局限，并在实证上证明了其有效性和可推广性。


<details>
  <summary>Details</summary>
Motivation: 现有MPST方法在组合性和表达性之间存在权衡，传统方法难以表达复杂协议，而高表达性的方法又难以扩展和组合。急需一种既具高表达性又易于组合的方法。

Method: 引入了一种合成方法的新型类型系统，直接将进程和整体协议（以标签转换系统LTS表示）进行对比验证，省去了中间的本地类型和投影步骤。

Result: 该方法能验证以往组合性方法难以处理的复杂协议，能验证任意“良行为”LTS协议，并已形式化实现于Agda且有VS Code原型插件。

Conclusion: 本文提出了一种新型的多方会话类型（MPST）方法，兼具表达性和组合性，解决了现有方法难以兼顾这两者的难题。

Abstract: Multiparty session types (MPST) provide a rigorous foundation for verifying the safety and liveness of concurrent systems. However, existing approaches often force a difficult trade-off: classical, projection-based techniques are compositional but limited in expressiveness, while more recent techniques achieve higher expressiveness by relying on non-compositional, whole-system model checking, which scales poorly.
  This paper introduces a new approach to MPST that delivers both expressiveness and compositionality, called the synthetic approach. Our key innovation is a type system that verifies each process directly against a global protocol specification, represented as a labelled transition system (LTS) in general, with global types as a special case. This approach uniquely avoids the need for intermediate local types and projection.
  We demonstrate that our approach, while conceptually simpler, supports a benchmark of challenging protocols that were previously beyond the reach of compositional techniques in the MPST literature. We generalise our type system, showing that it can validate processes against any specification that constitutes a "well-behaved" LTS, supporting protocols not expressible with the standard global type syntax. The entire framework, including all theorems and many examples, has been formalised and mechanised in Agda, and we have developed a prototype implementation as an extension to VS Code.

</details>


### [4] [All for One and One for All: Program Logics for Exploiting Internal Determinism in Parallel Programs](https://arxiv.org/abs/2511.23283)
*Alexandre Moine,Sam Westrick,Joseph Tassarotti*

Main category: cs.PL

TL;DR: 本文提出了基于内部确定性的新并行程序验证框架，包括Musketeer和Angelic逻辑，有效简化了安全性的形式化证明，并通过类型系统MiniDet及Iris机械化验证了理论的有效性。


<details>
  <summary>Details</summary>
Motivation: 并行程序由于存在非确定性，难以编写和推理。内部确定性并行编程能够简化推理过程，但缺乏利用这一性质的验证框架。本文致力于提出一种新的形式化推理方法，简化对内部确定性程序的安全性验证。

Method: 提出并定义了“与调度无关的安全性”性质，结合分离逻辑Musketeer来证明并行程序满足该性质。进一步，提出了Angelic逻辑，使得只需验证一个顺序执行的路径即可。针对内部确定性编程的类型系统MiniDet进行了形式化的安全性证明，所有理论基于Iris分离逻辑在Rocq中机械化验证。

Result: 提出了Musketeer分离逻辑和Angelic逻辑，系统性地将内部确定性与形式化验证结合。证明了MiniDet类型系统能够确保程序满足与调度无关的安全性，从而简化并行程序的验证流程。所有结果已利用Iris框架实现机械化验证。

Conclusion: 通过将内部确定性、分离逻辑和新的安全性定义结合，本文显著简化了安全并行程序的形式化验证流程，并为内部确定性并行编程提供了实用的理论和工具支持。

Abstract: Nondeterminism makes parallel programs challenging to write and reason about. To avoid these challenges, researchers have developed techniques for internally deterministic parallel programming, in which the steps of a parallel computation proceed in a deterministic way. Internal determinism is useful because it lets a programmer reason about a program as if it executed in a sequential order. However, no verification framework exists to exploit this property and simplify formal reasoning about internally deterministic programs.
  To capture the essence of why internally deterministic programs should be easier to reason about, this paper defines a property called schedule-independent safety. A program satisfies schedule-independent safety, if, to show that the program is safe across all orderings, it suffices to show that one terminating execution of the program is safe. We then present a separation logic called Musketeer for proving that a program satisfies schedule-independent safety. Once a parallel program has been shown to satisfy schedule-independent safety, we can verify it with a new logic called Angelic, which allows one to dynamically select and verify just one sequential ordering of the program.
  Using Musketeer, we prove the soundness of MiniDet, an affine type system for enforcing internal determinism. MiniDet supports several core algorithmic primitives for internally deterministic programming that have been identified in the research literature, including a deterministic version of a concurrent hash set. Because any syntactically well-typed MiniDet program satisfies schedule-independent safety, we can apply Angelic to verify such programs.
  All results in this paper have been verified in Rocq using the Iris separation logic framework.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [5] [Technical knowledge and soft skills in software startups within the Colombian entrepreneurial ecosystem](https://arxiv.org/abs/2511.21769)
*Royer David Estrada-Esponda,Gerardo Matturro,Jose Reinaldo Sabogal-Pinilla*

Main category: cs.SE

TL;DR: 软件初创企业成员需具备多元技术知识（如需求工程、测试及敏捷方法）及核心软技能（沟通、领导、团队合作），这些能力随企业成长不断变化，对创业成功至关重要。


<details>
  <summary>Details</summary>
Motivation: 尽管早期创业团队成员的素质被公认为成功关键，但具体哪些技术知识和软技能最被重视，及其随企业成长的变化，仍需明确。为指导创业者与相关培养单位，需要深入分析。

Method: 通过对哥伦比亚创业生态系统中软件初创企业代表的问卷调查，收集和分析了他们对技术知识与软技能价值的评判。

Result: 最受重视的技术知识包括需求工程、软件测试、项目规划与管理、敏捷方法、市场营销、商业模式定义及预算制定；最重要的软技能则为沟通、领导力和团队合作。研究对软件创业者、孵化器和研究人员均有参考价值。

Conclusion: 软件创业团队成员的技术知识和软技能对初创企业的早期发展影响显著。团队成员素质直接关系到初创企业的成败。

Abstract: The technical knowledge and soft skills of entrepreneurial team members significantly impact the early stages of software startups. It is widely recognized that the success or failure of a startup is determined by the quality of the individuals who constitute the founding team. This article presents the findings of a study conducted within the Colombian entrepreneurial ecosystem, focusing on which technical knowledge and soft skills are the most valued by founding teams of software startups, and how the needs for knowledge and skills evolve as the startup grows. A survey of software startup representatives revealed that the most valued knowledge includes requirements engineering, software testing, project planning and management, agile methodologies, marketing, business model definition, and budgeting. The most valued soft skills are typically communication, leadership, and teamwork. The outcomes of this work are relevant to software entrepreneurs, incubators, and researchers.

</details>


### [6] [Code Refactoring with LLM: A Comprehensive Evaluation With Few-Shot Settings](https://arxiv.org/abs/2511.21788)
*Md. Raihan Tapader,Md. Mostafizer Rahman,Ariful Islam Shiplu,Md Faizul Ibne Amin,Yutaka Watanobe*

Main category: cs.SE

TL;DR: 提出基于大语言模型和提示工程的多语言代码重构框架，显著提升了Java和Python等多种语言的重构正确率和代码质量，实现结构优化同时保持语义不变。


<details>
  <summary>Details</summary>
Motivation: 现有代码重构方法依赖人工设定规则，难以在多种语言与编码风格中推广。大语言模型在代码理解和生成上的新能力为自动、多语言、智能代码重构提供了新机遇。研究探索如何利用LLM结合提示工程，有效提升代码重构的准确性和效率。

Method: 本研究提出一种结合微调、提示工程与小样本学习(few-shot learning)的多语言代码重构框架。模型接受不同参数下的提示信息(如Temperature、多轮样例)，然后针对多种语言的代码进行重构。通过实验，基于编译率、代码正确性、结构距离、相似度、行数、Token/字符数与圈复杂度等指标，以及人工评估，全面评价重构后代码的质量与改进程度。

Result: Java语言重构后代码正确率最高(最高可达99.99%)，平均可编译性也最高(94.78%)，结构与语义平衡良好。Python代码重构结构差异最小(距离约277-294)，相似性中等(44-48%)，表明其重构较为一致且扰动小。整体上，各语言的重构均有不同程度的结构与质量改进。

Conclusion: 通过微调的大语言模型(Large Language Models, LLMs)及提示工程(Temperature, Few-shot)技术，可以有效跨多种编程语言(C, C++, C#, Python, Java)进行高效、准确的代码重构。实验数据显示，Java的重构代码在正确性和可编译性方面表现突出，而Python在结构上变化最小，重构不破坏原有代码语义。总体方法能在结构改良与语义保持间取得良好平衡。

Abstract: In today's world, the focus of programmers has shifted from writing complex, error-prone code to prioritizing simple, clear, efficient, and sustainable code that makes programs easier to understand. Code refactoring plays a critical role in this transition by improving structural organization and optimizing performance. However, existing refactoring methods are limited in their ability to generalize across multiple programming languages and coding styles, as they often rely on manually crafted transformation rules. The objectives of this study are to (i) develop an Large Language Models (LLMs)-based framework capable of performing accurate and efficient code refactoring across multiple languages (C, C++, C#, Python, Java), (ii) investigate the impact of prompt engineering (Temperature, Different shot algorithm) and instruction fine-tuning on refactoring effectiveness, and (iii) evaluate the quality improvements (Compilability, Correctness, Distance, Similarity, Number of Lines, Token, Character, Cyclomatic Complexity) in refactored code through empirical metrics and human assessment. To accomplish these goals, we propose a fine-tuned prompt-engineering-based model combined with few-shot learning for multilingual code refactoring. Experimental results indicate that Java achieves the highest overall correctness up to 99.99% the 10-shot setting, records the highest average compilability of 94.78% compared to the original source code and maintains high similarity (Approx. 53-54%) and thus demonstrates a strong balance between structural modifications and semantic preservation. Python exhibits the lowest structural distance across all shots (Approx. 277-294) while achieving moderate similarity ( Approx. 44-48%) that indicates consistent and minimally disruptive refactoring.

</details>


### [7] [LLM-Empowered Event-Chain Driven Code Generation for ADAS in SDV systems](https://arxiv.org/abs/2511.21877)
*Nenad Petrovic,Norbert Kroth,Axel Torschmied,Yinglei Song,Fengjunjie Pan,Vahid Zolfaghari,Nils Purschke,Sven Kirchner,Chengdong Wu,Andre Schamschurko,Yi Zhang,Alois Knoll*

Main category: cs.SE

TL;DR: 本文提出一种结合事件链和大模型的新型汽车代码生成流程，利用信号规范检索与事件链约束，提升了自动代码生成的准确性和一致性，初步在应急制动场景验证效果良好。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的代码生成方法容易幻觉，难以保证架构与信号正确性，针对汽车自然语言需求到代码的转化需求，需要更高的准确性与一致性方法。

Method: 整合RAG检索机制，从大规模车辆信号规范中检索相关信号，作为生成代码的上下文。信号经过映射与验证后，被转化为事件链，编码因果与时序约束，并用于引导与约束代码自动生成。

Result: 在应急制动案例研究中，工作流实现了信号有效用法与行为一致代码生成，无需对LLM进行额外训练。

Conclusion: 提出的事件链驱动与大模型赋能的工作流能在无需额外训练的前提下，有效实现汽车代码从自然语言需求到有效信号、架构一致且连续代码的自动生成。

Abstract: This paper presents an event-chain-driven, LLM-empowered workflow for generating validated, automotive code from natural-language requirements. A Retrieval-Augmented Generation (RAG) layer retrieves relevant signals from large and evolving Vehicle Signal Specification (VSS) catalogs as code generation prompt context, reducing hallucinations and ensuring architectural correctness. Retrieved signals are mapped and validated before being transformed into event chains that encode causal and timing constraints. These event chains guide and constrain LLM-based code synthesis, ensuring behavioral consistency and real-time feasibility. Based on our initial findings from the emergency braking case study, with the proposed approach, we managed to achieve valid signal usage and consistent code generation without LLM retraining.

</details>


### [8] [Advancing Automated In-Isolation Validation in Repository-Level Code Translation](https://arxiv.org/abs/2511.21878)
*Kaiyao Ke,Ali Reza Ibrahimzada,Rangeet Pan,Saurabh Sinha,Reyhaneh Jabbarvand*

Main category: cs.SE

TL;DR: 该文提出TRAM方法，通过结合上下文感知类型解析和mock独立验证，提高了仓库级代码自动翻译的准确性和验证效率，在Java到Python翻译任务上取得了最佳表现。


<details>
  <summary>Details</summary>
Motivation: 现有的仓库级代码翻译虽然有所进步，但翻译结果的有效性验证仍然是一个挑战。传统方法要么成本高昂，要么依赖繁重的人力，缺乏可靠的自动化手段。

Method: 提出了TRAM方法：先自动检索源代码中每个变量类型的API文档和上下文信息，用这些信息引导大语言模型（LLM）进行精准语义类型映射。然后，通过自定义序列化与反序列化流程，在目标语言中自动构造等价mock对象，从而能在不依赖人工或代理高开销的情况下，实现每个方法片段的独立验证。

Result: TRAM在Java到Python的仓库级代码翻译中实现了业内领先的性能，无需传统高成本验证手段，提供了高质量的自动翻译与验证方案。

Conclusion: TRAM通过RAG（检索增强生成）型类型解析结合可验证的独立mock验证流程，显著提升了自动代码翻译的质量和验证效率，可以更可靠地实现跨语言迁移。

Abstract: Repository-level code translation aims to migrate entire repositories across programming languages while preserving functionality automatically. Despite advancements in repository-level code translation, validating the translations remains challenging. This paper proposes TRAM, which combines context-aware type resolution with mock-based in-isolation validation to achieve high-quality translations between programming languages. Prior to translation, TRAM retrieves API documentation and contextual code information for each variable type in the source language. It then prompts a large language model (LLM) with retrieved contextual information to resolve type mappings across languages with precise semantic interpretations. Using the automatically constructed type mapping, TRAM employs a custom serialization/deserialization workflow that automatically constructs equivalent mock objects in the target language. This enables each method fragment to be validated in isolation, without the high cost of using agents for translation validation, or the heavy manual effort required by existing approaches that rely on language interoperability. TRAM demonstrates state-of-the-art performance in Java-to-Python translation, underscoring the effectiveness of its integration of RAG-based type resolution with reliable in-isolation validation.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [9] [Nested Sequents for Intuitionistic Multi-Modal Logics: Cut-Elimination and Lyndon Interpolation](https://arxiv.org/abs/2511.22174)
*Tim S. Lyon*

Main category: cs.LO

TL;DR: 本文提出了针对直觉主义语法逻辑的统一嵌套序列演算体系，创新结构规则实现了句法化割可证性和完全性，并首次给出了单结论嵌套序列上的插值算法，证明了LIP与BDP等新性质。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在为广泛分类的直觉主义多模态逻辑（被称为直觉主义语法逻辑，IGLs）建立一种新的单结论嵌套序列演算体系。此前，关于IGLs的证明体系及其相关重要性质，特别是切除可证性与插值性质仍不完善，因此，作者希望通过新的结构性规则在证明理论和可证性方面获得突破。

Method: 作者引入并研究了针对IGLs的单结论嵌套序列演算，通过分析演算的基本可逆性与可允许性，引入一种新颖的结构规则——shift规则，该规则整合了现有模态框架条件的结构规则。此外，作者还提出了直接作用于单结论嵌套序列证明的插值算法。

Result: 通过shift结构规则，实现了对所有IGL的割可证性的统一、纯粹句法证明，确保演算体系的完全性。进一步，作者构造了插值算法，为所有IGLs及其下属直觉主义模态与时态逻辑建立了Lyndon插值性质和Beth可定义性性质的构造性证明。

Conclusion: 该研究为IGLs及其相关逻辑提供了统一的演算体系、句法上的割可证性与完全性证明，并首次提出了适用于单结论嵌套序列证明的插值算法，证明了LIP和BDP等性质，这在该领域尚属首次。

Abstract: We introduce and study single-conclusioned nested sequent calculi for a broad class of intuitionistic multi-modal logics known as intuitionistic grammar logics (IGLs). These logics serve as the intuitionistic counterparts of classical grammar logics, and subsume standard intuitionistic modal and tense logics, including IK and IKt extended with combinations of the T, B, 4, 5, and D axioms. We analyze fundamental invertibility and admissibility properties of our calculi and introduce a novel structural rule, called the shift rule, which unifies standard structural rules arising from modal frame conditions into a single rule. This rule enables a purely syntactic proof of cut-admissibility that is uniform over all IGLs, and yields completeness of our nested calculi as a corollary. Finally, we define an interpolation algorithm that operates over single-conclusioned nested sequent proofs. This gives constructive proofs of both the Lyndon interpolation property (LIP) and Beth definability property (BDP) for all IGLs and for all intuitionistic modal and tense logics they subsume. To the best of the author's knowledge, this style of interpolation algorithm (that acts on single-conclusioned nested sequent proofs) and the resulting LIP and BDP results are new.

</details>


### [10] [Conditionals Based on Selection Functions, Modal Operators and Probabilities](https://arxiv.org/abs/2511.22377)
*Tommaso Flaminio,Lluis Godo,Gluliano Rosella*

Main category: cs.LO

TL;DR: 该文用广义视角系统研究了概率更新方法与条件句之间的关系，证明了两者相互作用的一般规律，为这两个领域的进一步交叉研究奠定基础。


<details>
  <summary>Details</summary>
Motivation: 本论文关注于概率更新方法，如贝叶斯条件化，试图更深入理解概率更新与条件句之间的内在联系。以往的文献常常局限于某一类条件或某一种更新方法，缺乏一般性的理论归纳。

Method: 作者采用了一种广义的方法，对大量的条件句类型和各种概率更新方法进行理论分析，旨在证明一些关于条件句概率及其与概率更新方法关系的普遍性结果。

Result: 论文证明并刻画了一类条件联结词的概率特征，并展示了哪些概率更新过程可用具体条件联结词表示，从而丰富了一般概率更新与条件关系的理论框架。

Conclusion: 通过广义理论分析，论文扩展了以往对条件概率与概率更新法之间联系的理解，为条件句概率建模与适用的更新程序提供了一般性理论支持。

Abstract: Methods for probability updating, of which Bayesian conditionalization is the most well-known and widely used, are modeling tools that aim to represent the process of modifying an initial epistemic state, typically represented by a prior probability function P, which is adjusted in light of new information. Notably, updating methods and conditional sentences seem to intuitively share a deep connection, as is evident in the case of conditionalization. The present work contributes to this line of research and aims at shedding new light on the relationship between updating methods and conditional connectives. Departing from previous literature that often focused on a specific type of conditional or a particular updating method, our goal is to prove general results concerning the connection between conditionals and their probabilities. This will allow us to characterize the probabilities of certain conditional connectives and to understand what class of updating procedures can be represented using specific conditional connectives. Broadly, we adopt a general perspective that encompasses a large class of conditionals and a wide range of updating methods, enabling us to prove some general results concerning their interrelation.

</details>


### [11] [Hyperintensional Intention](https://arxiv.org/abs/2511.22371)
*Daniil Khaitovich,Aybüke Özgün*

Main category: cs.LO

TL;DR: 本文提出了一种超强解释性的意图逻辑系统，有效避免了传统意图逻辑在等价或蕴涵下的过度闭合问题，并为该系统构建了可靠且强完备的公理化框架，对意图推理理论有重要贡献。


<details>
  <summary>Details</summary>
Motivation: 现实生活中，意图对人类的实践推理至关重要。找到一种既能准确表达意图逻辑规律、又不会过于强大的意图逻辑一直是研究重点。传统逻辑系统容易使意图在推理过程中“闭合”，这会导致无法分清行动的本意结果和非本意后果。因此需要针对这一问题提出新的逻辑系统。

Method: 论文分析了现有意图逻辑容易过度闭合的问题，提出了超强解释性(hyperintensional)的意图逻辑，将代理人的意图限定在其决策问题之内。系统融合了探究性(inquisitive)与话题敏感型(topic-sensitive)模态逻辑的理论元素，构建了一套新的逻辑系统，并对比分析了现有体系的不足。最后，给出了该逻辑系统的公理化体系，并证明了其可靠性（soundness）和强完备性（strong completeness）。

Result: 提出了一套新的超强解释性意图逻辑系统，能够有效避免意图逻辑在蕴涵或等价下的闭合问题。证明了该系统具备可靠性与强完备性，且优于现有相关逻辑体系。指出传统相关框架在等价下仍会过度闭合，而所提方案没有该问题。

Conclusion: 建立了一个能“区分本意与非本意结果”的意图逻辑系统。该系统既遵循理性推理所需的规律，又成功避免落入等价或蕴涵过度闭合的陷阱，并在理论上完善了公理体系。此工作为意图推理和人工智能领域提供了更精细严格的模型基础。

Abstract: Intentions are crucial for our practical reasoning. The rational intention obeys some simple logical principles, such as agglomeration and consistency, among others, motivating the search for a proper logic of intention. However, such a logic should be weak enough not to force the closure under entailment; otherwise, we cannot distinguish between intended consequences of agents' choices and their unintended side-effects.  In this paper we argue that we should avoid not only the closure under entailment, but the weaker closure under equivalence as well. To achieve this, we develop a hyperintensional logic of intention, where what an agent intends is constrained by the agent's decision problem. The proposed system combines some elements of inquisitive and topic-sensitive theories of  intensional modals. Along the way, we also show that the existing closest relatives of our framework overgenerate validities by validating some instances of closure under equivalence. Finally, we provide a sound and strongly complete axiomatization for this logic.

</details>


### [12] [Distributed Knowing How](https://arxiv.org/abs/2511.22374)
*Bin Liu,Yanjing Wang*

Main category: cs.LO

TL;DR: 本文将分布式知识从“知识什么”拓展到“知识如何做”，提出了基于群体分布行动的分布式know-how逻辑，并为其证明了可靠性和强完全性。


<details>
  <summary>Details</summary>
Motivation: 当前知识逻辑中分布式知识的观念主要集中在“知道什么”（knowledge-that）方面，而关于“如何知道”（know-how）的分布式逻辑却不完善，现有方法无法全面描述群体的多步和联合行动能力。

Method: 提出了分布式know-how的逻辑，由群体的分布式知识及其多步策略为基础，结合已知的个体多步框架和联盟单步框架，构建了一套新的逻辑系统。

Result: 证明了所提出的分布式know-how逻辑系统具有可靠性和强完全性，并展示了其在公理和完全性证明方法上的优越性，与分布式“知识什么”逻辑高度相似。

Conclusion: 该文为分布式know-how逻辑建立了完整理论基础，突出群体在多步联合行动中的能力，为知识逻辑研究拓展了新方向。

Abstract: Distributed knowledge is a key concept in the standard epistemic logic of knowledge-that. In this paper, we propose a corresponding notion of distributed knowledge-how and study its logic. Our framework generalizes two existing traditions in the logic of know-how: the individual-based multi-step framework and the coalition-based single-step framework. In particular, we assume a group can accomplish more than what its individuals can jointly do. The distributed knowledge-how is based on the distributed knowledge-that of a group whose multi-step strategies derive from distributed actions that subgroups can collectively perform. As the main result, we obtain a sound and strongly complete proof system for our logic of distributed knowledge-how, which closely resembles the logic of distributed knowledge-that in both the axioms and the proof method of completeness.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [13] [EvalCards: A Framework for Standardized Evaluation Reporting](https://arxiv.org/abs/2511.21695)
*Ruchira Dhar,Danae Sanchez Villegas,Antonia Karamolegkou,Alice Schiavone,Yifei Yuan,Xinyi Chen,Jiaang Li,Stella Frank,Laura De Grazia,Monorama Swain,Stephanie Brandl,Daniel Hershcovich,Anders Søgaard,Desmond Elliott*

Main category: cs.CL

TL;DR: 本论文审视NLP评估报告的问题，发现复现性、可访问性和治理不足，提出了EvalCards来改进透明度和治理。


<details>
  <summary>Details</summary>
Motivation: 现有NLP模型评估报告存在复现性、可访问性及治理方面的不足，透明化与标准化亟需加强。

Method: 梳理当前评估与文档工作，调查并归纳报告实践的不足，并提出了一个新的工具（EvalCards）。

Result: 分析了三大缺陷，提出并设计了EvalCards工具，有望提升报告透明度与实用性，满足新兴治理需求。

Conclusion: 现有的评估报告标准难以满足NLP领域不断增长的透明化与管理需求，提出EvalCards可以有效提升评估的透明度并适应治理需求。

Abstract: Evaluation has long been a central concern in NLP, and transparent reporting practices are more critical than ever in today's landscape of rapidly released open-access models. Drawing on a survey of recent work on evaluation and documentation, we identify three persistent shortcomings in current reporting practices: reproducibility, accessibility, and governance. We argue that existing standardization efforts remain insufficient and introduce Evaluation Disclosure Cards (EvalCards) as a path forward. EvalCards are designed to enhance transparency for both researchers and practitioners while providing a practical foundation to meet emerging governance requirements.

</details>


### [14] [Cacheback: Speculative Decoding With Nothing But Cache](https://arxiv.org/abs/2511.21699)
*Zhiyao Ma,In Gim,Lin Zhong*

Main category: cs.CL

TL;DR: Cacheback是一种零训练、简洁高效、易集成的大模型推理加速方法，性能优异，适应性强。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型推理速度较慢，亟需高效、简便的加速策略，同时希望能够无须额外训练且易于集成。

Method: 提出Cacheback Decoding：一种无训练需求、模型无关的speculative decoding方法，仅利用n-gram的LRU缓存表生成草稿序列，依赖语言局部性进行加速。

Result: Cacheback方法在同类方法中达到最新的性能水平，同时由于其极简设计，能够方便集成且在新领域快速适配。

Conclusion: Cacheback既高效又易用，实现了大模型推理的加速，并且具备良好的拓展性与适应性。

Abstract: We present Cacheback Decoding, a training-free and model-agnostic speculative decoding method that exploits the locality in language to accelerate Large Language Model (LLM) inference. Cacheback leverages only Least Recently Used (LRU) cache tables of token n-grams to generate draft sequences. Cacheback achieves state-of-the-art performance among comparable methods despite its minimalist design, and its simplicity allows easy integration into existing systems. Cacheback also shows potential for fast adaptation to new domains.

</details>


### [15] [JELV: A Judge of Edit-Level Validity for Evaluation and Automated Reference Expansion in Grammatical Error Correction](https://arxiv.org/abs/2511.21700)
*Yuhao Zhan,Yuqing Zhang,Jing Yuan,Qixiang Ma,Zhiqi Yang,Yu Gu,Zemin Liu,Fei Wu*

Main category: cs.CL

TL;DR: 该论文提出JELV自动框架，从多角度验证语法纠错编辑，有效提升评测公正性和模型能力，并扩展数据集促进系统表现。


<details>
  <summary>Details</summary>
Motivation: 现有的语法纠错（GEC）系统因为参考答案多样性有限，导致评测结果被低估，并限制了模型泛化能力。该论文旨在解决这一问题。

Method: 提出了JELV（Judge of Edit-Level Validity）自动化框架，从语法性、忠实性和流畅性三个维度验证纠错编辑。使用了新构建的人类标注对比编辑有效性数据集（PEVData）作为基准。JELV有两种实现方式：一是多轮LLM评判流程，二是精炼的DeBERTa分类器。

Result: JELV的LLM评判流程有人类标注90%一致率，DeBERTa分类器在有效编辑上达到85%精确率。使用JELV纠正评测中的错误判定，并将其整合至新指标中，与人工判断有最优相关性。同时，用JELV扩展语料库训练GEC系统，也带来性能提升。

Conclusion: JELV框架可扩展地提升参考多样性，加强评测和模型泛化能力。

Abstract: Existing Grammatical Error Correction (GEC) systems suffer from limited reference diversity, leading to underestimated evaluation and restricted model generalization. To address this issue, we introduce the Judge of Edit-Level Validity (JELV), an automated framework to validate correction edits from grammaticality, faithfulness, and fluency. Using our proposed human-annotated Pair-wise Edit-level Validity Dataset (PEVData) as benchmark, JELV offers two implementations: a multi-turn LLM-as-Judges pipeline achieving 90% agreement with human annotators, and a distilled DeBERTa classifier with 85% precision on valid edits. We then apply JELV to reclassify misjudged false positives in evaluation and derive a comprehensive evaluation metric by integrating false positive decoupling and fluency scoring, resulting in state-of-the-art correlation with human judgments. We also apply JELV to filter LLM-generated correction candidates, expanding the BEA19's single-reference dataset containing 38,692 source sentences. Retraining top GEC systems on this expanded dataset yields measurable performance gains. JELV provides a scalable solution for enhancing reference diversity and strengthening both evaluation and model generalization.

</details>


### [16] [47B Mixture-of-Experts Beats 671B Dense Models on Chinese Medical Examinations](https://arxiv.org/abs/2511.21701)
*Chiung-Yi Tseng,Danyang Zhang,Tianyang Wang,Hongying Luo,Lu Chen,Junming Huang,Jibin Guan,Junfeng Hao,Junhao Song,Ziqian Bi*

Main category: cs.CL

TL;DR: 本文构建了覆盖七大专业、两个级别的2,800题中文医学考试题库，对27个LLM进行深度评测，发现Mixtral-8x7B表现最佳，模型规模与表现不总相关。数据揭示不同专业表现差异，顶尖模型在高难题目上具备良好泛化能力，对医学教育和临床辅助有参考价值。


<details>
  <summary>Details</summary>
Motivation: 近年来LLMs发展迅速，医学领域对其实际能力、适用性、弱点的全面了解需求迫切，尤其是在中文医疗场景下缺乏高质量、公平对比的评测数据与方法。

Method: 作者构建并应用了基于2,800道高质量医学考试题（涵盖七大专业，分为主治和高级职称等级）的评价框架，系统性地评估了27个主流LLM在不同医学专科和不同复杂度层级上的表现。

Result: Mixtral-8x7B取得了74.25%的最佳准确率，DeepSeek-R1-671B次之；模型规模与表现无明显相关性；在不同专科的题目上表现差异大，对心血管和神经内科表现较好，消化和肾脏领域不足；顶尖模型在复杂度更高题目上泛化能力好。

Conclusion: 本基准测试透露出现有LLMs在医学领域应用中的巨大潜力，但也突出显示了其在各子领域间表现差异和整体的局限性，尤其是在某些专业领域的专业知识掌握方面仍有提升空间。

Abstract: The rapid advancement of large language models(LLMs) has prompted significant interest in their potential applications in medical domains. This paper presents a comprehensive benchmark evaluation of 27 state-of-the-art LLMs on Chinese medical examination questions, encompassing seven medical specialties across two professional levels. We introduce a robust evaluation framework that assesses model performance on 2,800 carefully curated questions from cardiovascular, gastroenterology, hematology, infectious diseases, nephrology, neurology, and respiratory medicine domains. Our dataset distinguishes between attending physician and senior physician difficulty levels, providing nuanced insights into model capabilities across varying complexity. Our empirical analysis reveals substantial performance variations among models, with Mixtral-8x7B achieving the highest overall accuracy of 74.25%, followed by DeepSeek-R1-671B at 64.07%. Notably, we observe no consistent correlation between model size and performance, as evidenced by the strong performance of smaller mixture-of-experts architectures. The evaluation demonstrates significant performance gaps between medical specialties, with models generally performing better on cardiovascular and neurology questions compared to gastroenterology and nephrology domains. Furthermore, our analysis indicates minimal performance degradation between attending and senior physician levels for top-performing models, suggesting robust generalization capabilities. This benchmark provides critical insights for the deployment of LLMs in medical education and clinical decision support systems, highlighting both the promise and current limitations of these technologies in specialized medical contexts.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [17] [On the structure of ($4K_1$, $C_4$, $P_6$)-free graphs](https://arxiv.org/abs/2511.23195)
*Chính T. Hoàng,Ramin Javadi,Nicolas Trotignon*

Main category: cs.DM

TL;DR: 论文解决了对包含$C_6$的($4K_1, C_4, P_6$)-free图着色的难题，证明了这些图的团宽有界，从而可用多项式时间算法进行着色，并提出了一种新的有界团宽的方法。


<details>
  <summary>Details</summary>
Motivation: 着色($4K_1, C_4$)-free图的复杂性是一个长期未解的难题，最近已知对($4K_1, C_4, C_6$)-free图有多项式算法，本工作进一步探索更加一般的情况。

Method: 采用一种新的方法来界定团宽，这种方法本身也是具有独立研究价值的。

Result: 证明了对($4K_1, C_4, P_6$)-free且包含$C_6$的图，其团宽有界，因此可以用多项式时间算法进行图着色。

Conclusion: 如果图G是($4K_1, C_4, P_6$)-free且包含一个$C_6$，则其团宽(clique-width)是有界的，因此存在多项式时间算法对这样的图进行着色。

Abstract: Determining the complexity of colouring ($4K_1, C_4$)-free graph is a long open problem. Recently Penev showed that there is a polynomial-time algorithm to colour a ($4K_1, C_4, C_6$)-free graph. In this paper, we will prove that if $G$ is a ($4K_1, C_4, P_6$)-free graph that contains a $C_6$, then $G$ has bounded clique-width. To this purpose, we use a new method to bound the clique-width, that is of independent interest. As a consequence, there is a polynomial-time algorithm to colour ($4K_1, C_4, P_6$)-free graphs.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [18] [Extended branching Rauzy induction](https://arxiv.org/abs/2511.22588)
*Francesco Dolce,Christian B. Hughes*

Main category: cs.FL

TL;DR: 本文扩展了Branching Rauzy归纳法，使其可作用于任意标准区间交换变换（IET），解决了等长切分和不变分量的问题，并应用该方法证明所有IET的回归词可在Burrows-Wheeler意义下聚类。


<details>
  <summary>Details</summary>
Motivation: 传统的Branching Rauzy归纳法仅适用于规则且极小的IET，仍需扩展方法以纳入非极小、任意标准IET的情形，且需解决等长切分及不变分量问题。

Method: 通过扩展Branching Rauzy归纳法，引入“合并”和“分裂”两步处理，应用于包括非极小的任意标准IET，并通过逐步形态学证明法展示应用结果。

Result: 提出了可处理任意标准IET的扩展Branching Rauzy归纳法，并证明任意IET的语言中的所有回归词在Burrows-Wheeler意义下能够聚类。

Conclusion: 所有任意标准区间交换变换（IET）中的回归词均以Burrows-Wheeler意义聚类。

Abstract: Branching Rauzy induction is a two-sided form of Rauzy induction that acts on regular interval exchange transformations (IETs). We introduce an extended form of branching Rauzy induction that applies to arbitrary standard IETs, including non-minimal ones. The procedure generalizes the branching Rauzy method with two induction steps, merging and splitting, to handle equal-length cuts and invariant components respectively. As an application, we show, via a stepwise morphic argument, that all return words in the language of an arbitrary IET cluster in the Burrows-Wheeler sense.

</details>


### [19] [The Target Discounted-Sum Problem](https://arxiv.org/abs/2511.22979)
*Udi Boker,Thomas A. Henzinger,Jan Otop*

Main category: cs.FL

TL;DR: 本文研究目标折扣和问题，给出有限序列的算法解，证明无限序列的困难性并关联多领域开放问题，对特定无限序列情况部分解决，并应用至折扣和自动机若干长期未解的问题。


<details>
  <summary>Details</summary>
Motivation: 该问题在自动机理论、数论与动态系统等领域具有重要意义，并直接关联到一些核心难题，其判定性难以解决，故研究者希望推动相关基础理论的发展，并解答折扣和自动机领域未决的问题。

Method: 针对有限序列和无限序列，分别运用算法理论分析、关联β-展开、折扣和自动机、分段仿射映射及Cantor集的推广等数学工具；对无限序列的特定情形进行了专门讨论和分析。

Result: 有限版本的目标折扣和问题已被解决，无限版本证明为困难问题，并发现其与多个开放数学问题相关；同时对某些特殊情况（周期性序列、λ≥1/2或λ=1/n）给出了解决方案，进而解决了部分折扣和自动机的开放问题，如精确值、普适性及包含性问题。

Conclusion: 本文解决了有限版本的目标折扣和问题，并证明了无限版本的困难性，将其与数学和计算机科学中的多个领域和开放问题联系起来，同时对无限版本的特殊情况给出了部分解。

Abstract: The target discounted-sum problem is the following: Given a rational discount factor $0<λ<1$ and three rational values $a,b$, and $t$, does there exist a finite or an infinite sequence $w \in \{a,b\}^*$ or $w \in \{a,b\}^ω$, such that $\sum_{i=0}^{|w|} w(i) λ^i$ equals $t$?
  The problem turns out to relate to many fields of mathematics and computer science, and its decidability question is surprisingly hard to solve.
  We solve the finite version of the problem, and show the hardness of the infinite version, linking it to various areas and open problems in mathematics and computer science: $β$-expansions, discounted-sum automata, piecewise affine maps, and generalizations of the Cantor set. We provide some partial results to the infinite version, among which are solutions to its restriction to eventually-periodic sequences and to the cases that $λ\geq \frac{1}{2}$ or $λ=\frac{1}{n}$, for every $n\in \mathbb{N}$.
  We use our results for solving some open problems on discounted-sum automata, among which are the exact-value, universality and inclusion problems for functional automata.

</details>
