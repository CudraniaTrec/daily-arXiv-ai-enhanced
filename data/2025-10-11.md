<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 9]
- [cs.LO](#cs.LO) [Total: 7]
- [cs.CL](#cs.CL) [Total: 64]
- [cs.DM](#cs.DM) [Total: 2]
- [cs.FL](#cs.FL) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Type, Ability, and Effect Systems: Perspectives on Purity, Semantics, and Expressiveness](https://arxiv.org/abs/2510.07582)
*Yuyan Bao,Tiark Rompf*

Main category: cs.PL

TL;DR: 本文提出了衡量效果系统与能力系统表达能力的新方法，并发现二者不可比；继而提出结合三者优点的新系统，并给出形式化证明工具，提升了类型系统的理论评价标准。


<details>
  <summary>Details</summary>
Motivation: 编程需要明确区分纯粹的数学计算与与外部世界交互的副作用。现有方法如monads、类型与效果系统，以及能力系统，都试图实现这种分离，但却存在准确性与易用性之间的矛盾。每种方法都有不易察觉的优劣。

Method: 本文首先提出一种受语境等价启发的纯粹性语义定义，作为不依赖具体类型系统的基线。其次，提出用“完备度”来衡量系统的表达能力，即有多少语义上纯粹的项能被类型系统判定为纯粹。并以此衡量最小化后的效果系统和能力系统，证明二者表达能力不可比较。最后，提出结合类型、能力和效果系统的新方法，并构建形式模型与逻辑关系，为多种效果类型系统的纯粹性与性质证明提供支持。

Result: 发现最简意义下的效果系统与能力系统在表达能力上各有优缺点、无法互相包容。提出的综合性系统将三者的优势结合起来，规避了各自的弱点，并通过逻辑关系方法对多种效果类型系统的性质进行了证明。

Conclusion: 本文提升了效果类型与能力系统评估的标准，通过语义定义与新型度量方式揭示主流方案的本质差异，并提出更优的融合系统，可为类型系统的发展与理论分析提供更坚实的基础。

Abstract: Programming benefits from a clear separation between pure, mathematical
computation and impure, effectful interaction with the world. Existing
approaches to enforce this separation include monads, type-and-effect systems,
and capability systems. All share a tension between precision and usability,
and each one has non-obvious strengths and weaknesses.
  This paper aims to raise the bar in assessing such systems. First, we propose
a semantic definition of purity, inspired by contextual equivalence, as a
baseline independent of any specific typing discipline. Second, we propose that
expressiveness should be measured by the degree of completeness, i.e., how many
semantically pure terms can be typed as pure. Using this measure, we focus on
minimal meaningful effect and capability systems and show that they are
incomparable, i.e., neither subsumes the other in terms of expressiveness.
  Based on this result, we propose a synthesis and show that type, ability, and
effect systems combine their respective strengths while avoiding their
weaknesses. As part of our formal model, we provide a logical relation to
facilitate proofs of purity and other properties for a variety of effect typing
disciplines.

</details>


### [2] [The Functional Machine Calculus III: Control](https://arxiv.org/abs/2510.07851)
*Willem Heijltjes*

Main category: cs.PL

TL;DR: 该论文扩展了Functional Machine Calculus，实现了包括分支、循环等命令式流程的嵌入，同时保留了函数式特性和强类型保证，为统一函数式与命令式编程提供了直观和高效的计算模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决函数式编程与命令式编程范式的统一问题，寻求一种方法同时支持二者的计算特性与控制流。

Method: 在已有的Functional Machine Calculus基础上，将操作语义和Krivine机进行了扩展，采用多操作数栈和续延栈来模拟副作用及顺序、分支、循环控制流，并保留了lambda演算的关键特性。

Result: 成功将顺序控制流程扩展至分支和循环控制流程，实现了极小但完整的命令式语言嵌入，包括条件语句、异常处理、迭代，以及常量和代数数据类型。类型系统可保证机的终止以及强归一化（无迭代时）。

Conclusion: 提出了一种统一的函数-命令式模型，在维持简单类型、直接操作语义和归一化约化的前提下，能够有效支持两种编程范式的特性，显著推进了范式融合方向。

Abstract: The Functional Machine Calculus (Heijltjes 2022) is a new approach to
unifying the imperative and functional programming paradigms. It extends the
lambda-calculus, preserving the key features of confluent reduction and typed
termination, to embed computational effects, evaluation strategies, and control
flow operations. The first instalment modelled sequential higher-order
computation with global store, input/output, probabilities, and
non-determinism, and embedded both the call-by-name and call-by-value
lambda-calculus, as well as Moggi's computational metalanguage and Levy's
call-by-push-value. The present paper extends the calculus from sequential to
branching and looping control flow. This allows the faithful embedding of a
minimal but complete imperative language, including conditionals, exception
handling, and iteration, as well as constants and algebraic data types.
  The calculus is defined through a simple operational semantics, extending the
(simplified) Krivine machine for the lambda-calculus with multiple operand
stacks to model effects and a continuation stack to model sequential,
branching, and looping computation. It features a confluent reduction relation
and a system of simple types that guarantees termination of the machine and
strong normalization of reduction (in the absence of iteration). These
properties carry over to the embedded imperative language, providing a unified
functional-imperative model of computation that supports simple types, a direct
and intuitive operational semantics, and a confluent reduction semantics.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [Modeling Developer Burnout with GenAI Adoption](https://arxiv.org/abs/2510.07435)
*Zixuan Feng,Sadia Afroz,Anita Sarma*

Main category: cs.SE

TL;DR: 本研究发现，GenAI 虽提升生产力，却通过提升工作要求增加开发者倦怠；但工作资源和积极认知可缓解此影响，助力开发者将新技术视为机遇。


<details>
  <summary>Details</summary>
Motivation: 尽管 GenAI 带来生产力提升，但其广泛采用可能给开发者带来新的压力，影响其身心健康，因此需研究其对开发者倦怠的影响。

Method: 采用嵌入式混合方法，包括对 442 名开发者的问卷调查，运用 PLS-SEM 和回归分析建模工作要求、工作资源与倦怠之间的关系，并对开放式问题进行定性分析以补充定量发现。

Result: GenAI 增加了开发者的工作要求，提高了倦怠水平；但当配备足够的工作资源并对 GenAI 持积极态度时，这种负面影响可被减弱甚至转变为促进发展的契机。

Conclusion: GenAI 的采用通过增加工作要求加剧了开发者的倦怠，而工作资源及对 GenAI 的积极看法有助于缓解这种影响，将采用过程转变为机遇。

Abstract: Generative AI (GenAI) is rapidly reshaping software development workflows.
While prior studies emphasize productivity gains, the adoption of GenAI also
introduces new pressures that may harm developers' well-being. In this paper,
we investigate the relationship between the adoption of GenAI and developers'
burnout. We utilized the Job Demands--Resources (JD--R) model as the analytic
lens in our empirical study. We employed a concurrent embedded mixed-methods
research design, integrating quantitative and qualitative evidence. We first
surveyed 442 developers across diverse organizations, roles, and levels of
experience. We then employed Partial Least Squares--Structural Equation
Modeling (PLS-SEM) and regression to model the relationships among job demands,
job resources, and burnout, complemented by a qualitative analysis of
open-ended responses to contextualize the quantitative findings. Our results
show that GenAI adoption heightens burnout by increasing job demands, while job
resources and positive perceptions of GenAI mitigate these effects, reframing
adoption as an opportunity.

</details>


### [4] [HotBugs.jar: A Benchmark of Hot Fixes for Time-Critical Bugs](https://arxiv.org/abs/2510.07529)
*Carol Hanna,Federica Sarro,Mark Harman,Justyna Petke*

Main category: cs.SE

TL;DR: 本文构建了一个专门用于热修复研究的数据集HotBugs.jar，收集并验证了679个热修复补丁，其中110个可复现，填补了相关评测基准空白，对自动修复和容错研究具有重要推动作用。


<details>
  <summary>Details</summary>
Motivation: 现有的评测基准针对热修复缺乏关注，而热修复是解决生产系统紧急问题的重要手段，因此需要一个专门针对热修复的软件基准和数据集。

Method: 作者通过挖掘10个活跃的Apache项目的Git和Jira数据，筛选出符合热修复标准的软件补丁，并进行人工验证，最终构建出HotBugs.jar数据集，包括679个经过验证的热修复补丁，其中110个可复现并配有测试用例。所有补丁均附有详细元数据。

Result: 得到一个包含679个真实热修复实例的公开数据集HotBugs.jar，其中110个可在测试环境下复现。该数据集已被SBSE会议用作官方挑战数据集，具有较强的行业影响力。

Conclusion: HotBugs.jar为软件热修复领域提供了首个高质量、有系统性评测的数据集，可以支持快速调试、自动修复和生产级容错工具的研究，推动该领域的发展。

Abstract: Hot fixes are urgent, unplanned changes deployed to production systems to
address time-critical issues. Despite their importance, no existing evaluation
benchmark focuses specifically on hot fixes. We present HotBugs$.$jar, the
first dataset dedicated to real-world hot fixes. From an initial mining of 10
active Apache projects totaling over 190K commits and 150K issue reports, we
identified 746 software patches that met our hot-fix criteria. After manual
evaluation, 679 were confirmed as genuine hot fixes, of which 110 are
reproducible using a test suite. Building upon the Bugs$.$jar framework,
HotBugs$.$jar integrates these 110 reproducible cases and makes available all
679 manually validated hot fixes, each enriched with comprehensive metadata to
support future research. Each hot fix was systematically identified using Jira
issue data, validated by independent reviewers, and packaged in a reproducible
format with buggy and fixed versions, test suites, and metadata. HotBugs$.$jar
has already been adopted as the official challenge dataset for the Search-Based
Software Engineering (SBSE) Conference Challenge Track, demonstrating its
immediate impact. This benchmark enables the study and evaluation of tools for
rapid debugging, automated repair, and production-grade resilience in modern
software systems to drive research in this essential area forward.

</details>


### [5] [RustAssure: Differential Symbolic Testing for LLM-Transpiled C-to-Rust Code](https://arxiv.org/abs/2510.07604)
*Yubo Bai,Tapti Palit*

Main category: cs.SE

TL;DR: RustAssure 系统基于大语言模型和差异符号测试，能自动将 C 代码高效转译为安全的 Rust 代码，并保障较高的语义等价性，为代码安全升级带来自动化解决方案。


<details>
  <summary>Details</summary>
Motivation: C 语言等不安全内存语言广泛用于现有代码库，但存在内存安全隐患。为利用 Rust 的内存安全特性，有必要将这些代码自动转换为 Rust。

Method: RustAssure 利用大语言模型（LLM）自动将 C 代码库转译为 Rust，并结合提示工程优化生成的 Rust 代码安全性与规范性。同时，采用差异符号测试方法评估转译后 Rust 代码与原 C 代码的语义相似度，以发现难以通过传统测试暴露的隐藏 bug。

Result: 在五个真实世界应用和库上进行评估，RustAssure 成功为 89.8% 的 C 函数生成可编译的 Rust 代码，其中 69.9% 的函数在符号返回值上与原 C 函数等价。

Conclusion: RustAssure 能自动将多数 C 函数转译为安全且在表现上等价的 Rust 代码，为现有不安全语言代码迁移到 Rust 提供了有效的自动化工具。

Abstract: Rust is a memory-safe programming language that significantly improves
software security. Existing codebases written in unsafe memory languages, such
as C, must first be transpiled to Rust to take advantage of Rust's improved
safety guarantees. RustAssure presents a system that uses Large Language Models
(LLMs) to automatically transpile existing C codebases to Rust. RustAssure uses
prompt engineering techniques to maximize the chances of the LLM generating
idiomatic and safe Rust code. Moreover, because LLMs often generate code with
subtle bugs that can be missed under traditional unit or fuzz testing,
RustAssure performs differential symbolic testing to establish the semantic
similarity between the original C and LLM-transpiled Rust code. We evaluated
RustAssure with five real-world applications and libraries, and showed that our
system is able to generate compilable Rust functions for 89.8% of all C
functions, of which 69.9% produced equivalent symbolic return values for both
the C and Rust functions.

</details>


### [6] [AppForge: From Assistant to Independent Developer -- Are GPTs Ready for Software Development?](https://arxiv.org/abs/2510.07740)
*Dezhi Ran,Yuan Cao,Mengzhou Wu,Simin Chen,Yuzhe Guo,Jun Ren,Zihe Song,Hao Yu,Jialei Wei,Linyi Li,Wei Yang,Baishakhi Ray,Tao Xie*

Main category: cs.SE

TL;DR: 本文提出APPFORGE基准系统，用于评估LLM从头开发安卓应用的能力。实际测试结果显示，现有LLM普遍难以胜任复杂应用开发任务，功能性正确率低，揭示了模型在实际软件工程场景中的局限。


<details>
  <summary>Details</summary>
Motivation: 现有基准仅关注函数级别代码生成，尚无基准能全面评估LLM在从零构建完整软件系统方面的能力。为了填补这一空白，需要设计能够反映真实软件工程难度的新基准。

Method: 作者提出了APPFORGE基准，该基准从真实安卓应用中选取了101个软件开发问题，要求LLM根据自然语言规范从零实现安卓应用。基准通过多智能体系统自动提炼主要功能，并合成测试用例，所有测试用例经专家人工验证后，纳入自动化评测框架，可无人工干预地评估LLM表现。

Result: 在APPFORGE基准上测试的12个主流LLM，表现均较差，功能性正确的应用开发比例都不高，最佳模型GPT-5也仅为18.8%。

Conclusion: 目前的大型语言模型（LLMs）在从零开发完整安卓应用方面表现不佳，即使表现最好的GPT-5，其功能性正确的应用开发比例也仅为18.8%。这暴露了现有模型在应对复杂多组件软件工程挑战时的根本局限性。

Abstract: Large language models (LLMs) have demonstrated remarkable capability in
function-level code generation tasks. Unlike isolated functions, real-world
applications demand reasoning over the entire software system: developers must
orchestrate how different components interact, maintain consistency across
states over time, and ensure the application behaves correctly within the
lifecycle and framework constraints. Yet, no existing benchmark adequately
evaluates whether LLMs can bridge this gap and construct entire software
systems from scratch. To address this gap, we propose APPFORGE, a benchmark
consisting of 101 software development problems drawn from real-world Android
apps. Given a natural language specification detailing the app functionality, a
language model is tasked with implementing the functionality into an Android
app from scratch. Developing an Android app from scratch requires understanding
and coordinating app states, lifecycle management, and asynchronous operations,
calling for LLMs to generate context-aware, robust, and maintainable code. To
construct APPFORGE, we design a multi-agent system to automatically summarize
the main functionalities from app documents and navigate the app to synthesize
test cases validating the functional correctness of app implementation.
Following rigorous manual verification by Android development experts, APPFORGE
incorporates the test cases within an automated evaluation framework that
enables reproducible assessment without human intervention, making it easily
adoptable for future research. Our evaluation on 12 flagship LLMs show that all
evaluated models achieve low effectiveness, with the best-performing model
(GPT-5) developing only 18.8% functionally correct applications, highlighting
fundamental limitations in current models' ability to handle complex,
multi-component software engineering challenges.

</details>


### [7] [Interleaved Learning and Exploration: A Self-Adaptive Fuzz Testing Framework for MLIR](https://arxiv.org/abs/2510.07815)
*Zeyu Sun,Jingjing Liang,Weiyi Wang,Chenyao Suo,Junjie Chen,Fanjiang Xu*

Main category: cs.SE

TL;DR: 该论文提出了FLEX，一个神经网络驱动的自适应fuzzing框架，能自动生成高质量测试用例并迭代优化，在MLIR编译器测试中大幅优于现有方法，发现了众多新bug，提升代码覆盖率，为MLIR健壮性保障提供了有效新工具。


<details>
  <summary>Details</summary>
Motivation: MLIR作为现代编译器框架的基础技术，具有可扩展性，但其自身的正确性和健壮性保证仍面临挑战。现有的fuzzing方法难以生成多样且语义有效的测试用例，难以发现MLIR复杂代码中的隐蔽bug。

Method: 提出FLEX，一个自适应fuzzing框架，利用神经网络进行程序生成，采用扰动采样提升样本多样性，并通过反馈驱动的增强循环迭代优化模型，综合崩溃与非崩溃测试用例推进训练。

Result: 在MLIR编译器上的30天测试中，FLEX发现了80个未知bug（包括多个新根本原因和解析器bug）；在24小时定量对比中，检测到53个bug，比最佳基线多3.5倍，代码覆盖率28.2%，比次优工具提升42%。消融实验证明扰动生成与多样性增强对FLEX效果至关重要。

Conclusion: FLEX通过神经网络生成程序和自适应增强循环，有效提升了MLIR测试的多样性和发现bug的能力，显著优于现有fuzzing工具，能够发现深层次和复杂bug，促进MLIR更强健的发展。

Abstract: MLIR (Multi-Level Intermediate Representation) has rapidly become a
foundational technology for modern compiler frameworks, enabling extensibility
across diverse domains. However, ensuring the correctness and robustness of
MLIR itself remains challenging. Existing fuzzing approaches-based on manually
crafted templates or rule-based mutations-struggle to generate sufficiently
diverse and semantically valid test cases, making it difficult to expose subtle
or deep-seated bugs within MLIR's complex and evolving code space. In this
paper, we present FLEX, a novel self-adaptive fuzzing framework for MLIR. FLEX
leverages neural networks for program generation, a perturbed sampling strategy
to encourage diversity, and a feedback-driven augmentation loop that
iteratively improves its model using both crashing and non-crashing test cases.
Starting from a limited seed corpus, FLEX progressively learns valid syntax and
semantics and autonomously produces high-quality test inputs. We evaluate FLEX
on the upstream MLIR compiler against four state-of-the-art fuzzers. In a
30-day campaign, FLEX discovers 80 previously unknown bugs-including multiple
new root causes and parser bugs-while in 24-hour fixed-revision comparisons, it
detects 53 bugs (over 3.5x as many as the best baseline) and achieves 28.2%
code coverage, outperforming the next-best tool by 42%. Ablation studies
further confirm the critical role of both perturbed generation and diversity
augmentation in FLEX's effectiveness.

</details>


### [8] [Bug Histories as Sources of Compiler Fuzzing Mutators](https://arxiv.org/abs/2510.07834)
*Lingjun Liu,Feiran Qin,Owolabi Legunsen,Marcelo d'Amorim*

Main category: cs.SE

TL;DR: 作者提出了IssueMut系统，自动从编译器漏洞报告中提取并构建模糊测试变异器。通过在GCC和LLVM测试，成功挖掘到65个（60个确认/修复）新漏洞，验证了利用历史漏洞报告改进模糊测试的有效性。


<details>
  <summary>Details</summary>
Motivation: 编译器作为关键基础设施，其漏洞会造成严重影响。当前的编译器模糊测试（fuzzing）依赖变异器来自动生成测试用例，但变异器的设计长期未充分利用历史漏洞报告中的信息。作者希望通过利用编译器历史漏洞报告，提升模糊测试检测新漏洞的性能。

Method: 作者提出了IssueMut方法，自动从历史编译器漏洞报告中挖掘出变异器（mutator），并将这些新变异器集成进现有的模糊测试系统。具体做法是：收集并自动分析GCC和LLVM的1760份漏洞报告，提取出587个变异器，然后用这些变异器在编译器的测试输入集合进行模糊测试。

Result: 利用IssueMut方法的“漏洞历史”变异器，在GCC和LLVM分别发现了28个和37个新漏洞。这些新发现中有60个被官方确认或修复，显著优于传统模糊测试。

Conclusion: 历史漏洞报告包含了丰富的关于编译器缺陷的信息，通过自动挖掘并将这些信息转化为变异器，可以有效提升模糊测试工具发现新漏洞的能力。

Abstract: Bugs in compilers, which are critical infrastructure today, can have outsized
negative impacts. Mutational fuzzers aid compiler bug detection by
systematically mutating compiler inputs, i.e., programs. Their effectiveness
depends on the quality of the mutators used. Yet, no prior work used compiler
bug histories as a source of mutators. We propose IssueMut, the first approach
for extracting compiler fuzzing mutators from bug histories. Our insight is
that bug reports contain hints about program elements that induced compiler
bugs; they can guide fuzzers towards similar bugs. IssueMut uses an automated
method to mine mutators from bug reports and retrofit such mutators into
existing mutational compiler fuzzers. Using IssueMut, we mine 587 mutators from
1760 GCC and LLVM bug reports. Then, we run IssueMut on these compilers, with
all their test inputs as seed corpora. We find that "bug history" mutators are
effective: they find new bugs that a state-of-the-art mutational compiler
fuzzer misses-28 in GCC and 37 in LLVM. Of these, 60 were confirmed or fixed,
validating our idea that bug histories have rich information that compiler
fuzzers should leverage.

</details>


### [9] [An AUTOSAR-Aligned Architectural Study of Vulnerabilities in Automotive SoC Software](https://arxiv.org/abs/2510.07941)
*Srijita Basu,Haraldsson Bengt,Miroslaw Staron,Christian Berger,Jennifer Horkoff,Magnus Almgren*

Main category: cs.SE

TL;DR: 本文系统梳理了汽车SoC在AUTOSAR架构下的公开漏洞，分析根因、影响模块及补丁延迟，发现主要安全薄弱点，并提出优化检测与响应策略，为提升汽车CPS安全性提供实践指南。


<details>
  <summary>Details</summary>
Motivation: 随着汽车电子系统复杂度提升，SoC平台集成度变高，管理其安全性越来越困难。AUTOSAR标准虽能提升软硬件复用效率，但实际中仍面临诸多安全挑战，尤其是在实时和安全关键环境下。业界报告揭示SoC漏洞激增，且针对AUTOSAR架构下漏洞根因和影响尚缺乏系统性分析。

Method: 分析了180个公开报告的汽车SoC漏洞，并将其映射到符合AUTOSAR分层抽象和服务导向原则的软件架构模型。归纳漏洞根因，统计受影响软件模块，并对各CWE类别和架构层的补丁延迟进行研究。

Result: 识别出16种漏洞根因与56个受影响软件模块。揭示Dominant漏洞模式与补丁延迟较长的关键模块，并针对SoC车辆平台提出改进检测、优先级确定、定位策略等可行性建议。

Conclusion: 系统性揭示SoC平台安全弱点，填补AUTOSAR架构下漏洞分析缺口，并为汽车CPS平台的安全加固提供了实用参考与应对指南。

Abstract: Cooperative, Connected and Automated Mobility (CCAM) are complex
cyber-physical systems (CPS) that integrate computation, communication, and
control in safety-critical environments. At their core, System-on-Chip (SoC)
platforms consolidate processing units, communication interfaces, AI
accelerators, and security modules into a single chip. AUTOSAR (AUTomotive Open
System ARchitecture) standard was developed in the automotive domain to better
manage this complexity, defining layered software structures and interfaces to
facilitate reuse of HW/SW components. However, in practice, this integrated SoC
software architecture still poses security challenges, particularly in
real-time, safety-critical environments. Recent reports highlight a surge in
SoC-related vulnerabilities, yet systematic analysis of their root causes and
impact within AUTOSAR-aligned architectures is lacking. This study fills that
gap by analyzing 180 publicly reported automotive SoC vulnerabilities, mapped
to a representative SoC software architecture model that is aligned with
AUTOSAR principles for layered abstraction and service orientation. We identify
16 root causes and 56 affected software modules, and examine mitigation delays
across Common Weakness Enumeration (CWE) categories and architectural layers.
We uncover dominant vulnerability patterns and critical modules with prolonged
patch delays, and provide actionable insights for securing automotive CPS
platforms, including guides for improved detection, prioritization, and
localization strategies for SoC software architectures in SoC-based vehicle
platforms.

</details>


### [10] [Past, Present, and Future of Bug Tracking in the Generative AI Era](https://arxiv.org/abs/2510.08005)
*Utku Boran Torun,Mehmet Taha Demircan,Mahmut Furkan Gön,Eray Tüzün*

Main category: cs.SE

TL;DR: 本文提出用 AI/LLM 大幅自动化 bug 追踪和修复全过程，显著提升效率和用户体验，降低人力成本，为软件维护带来智能化升级。


<details>
  <summary>Details</summary>
Motivation: 传统的漏洞追踪系统中，报告、复现、分类和解决等流程由不同角色完成，导致沟通成本高、响应延迟，影响软件维护效率。现有系统依赖手工操作且高度异步，增加了用户和技术团队间的沟通障碍和用户的挫败感。

Method: 提出一个AI驱动的漏洞追踪框架，通过大型语言模型（LLM）实现自动化流程。用户用自然语言报告问题，AI自动完善报告、尝试复现、补充信息，自动分类处理无效报告并通过无代码修复有效问题，并将有效报告分派给开发者。LLM还可自动生成补丁，人工监督确保正确性。整个流程各阶段均融入自动化，减少人力成本、加快响应。

Result: 该框架在漏洞追踪过程中显著缩短了修复时间、降低人力负担，提升了协同效率与软件维护质量，实现更高效的、以用户为中心的漏洞处理机制。

Conclusion: 利用AI、尤其是LLM的自动化能力，全面优化软件 bug 追踪流程，缩短响应与修复周期、优化沟通和协作，加强软件维护的智能化水平。

Abstract: Traditional bug tracking systems rely heavily on manual reporting,
reproduction, triaging, and resolution, each carried out by different
stakeholders such as end users, customer support, developers, and testers. This
division of responsibilities requires significant coordination and widens the
communication gap between non-technical users and technical teams, slowing the
process from bug discovery to resolution. Moreover, current systems are highly
asynchronous; users often wait hours or days for a first response, delaying
fixes and contributing to frustration. This paper examines the evolution of bug
tracking, from early paper-based reporting to today's web-based and SaaS
platforms. Building on this trajectory, we propose an AI-powered bug tracking
framework that augments existing tools with intelligent, large language model
(LLM)-driven automation. Our framework addresses two main challenges: reducing
time-to-fix and minimizing human overhead. Users report issues in natural
language, while AI agents refine reports, attempt reproduction, and request
missing details. Reports are then classified, invalid ones resolved through
no-code fixes, and valid ones localized and assigned to developers. LLMs also
generate candidate patches, with human oversight ensuring correctness. By
integrating automation into each phase, our framework accelerates response
times, improves collaboration, and strengthens software maintenance practices
for a more efficient, user-centric future.

</details>


### [11] [Building Whitespace-Sensitive Languages Using Whitespace-Insensitive Components](https://arxiv.org/abs/2510.08200)
*Alexander Hellwig,Nico Jansen,Bernhard Rumpe*

Main category: cs.SE

TL;DR: 本文提出通过预处理技术实现空白敏感性语言与非空白敏感性语言模块的复用，解决了语言模块复用难题，并通过简化版Python验证了该方法提升开发效率和质量。


<details>
  <summary>Details</summary>
Motivation: 目前空白敏感性与非空白敏感性语言模块难以互相复用，导致开发新语言时往往需要从零开始，降低了开发效率和复用价值。

Method: 采用预处理技术，在解析前对语言构件进行转换，使无空白敏感性模块能够被空白敏感性语言使用。通过重建一个简化版的Python语言进行了评估。

Result: 验证了该方法能有效复用现有模块，提升语言开发质量、减少开发时间，且在简化的Python语言案例中取得了积极效果。

Conclusion: 通过预处理语言构件，本文提出了一种方法，可以利用无空白敏感性的模块构建空白敏感性的语言，从而提升语言构件的复用性。

Abstract: In Software Language Engineering, there is a trend towards reusability by
composing modular language components. However, this reusability is severely
inhibited by a gap in integrating whitespace-sensitive and
whitespace-insensitive languages. There is currently no consistent procedure
for seamlessly reusing such language components in both cases, such that
libraries often cannot be reused, and whitespacesensitive languages are
developed from scratch. This paper presents a technique for using modular,
whitespaceinsensitive language modules to construct whitespace sensitive
languages by pre-processing language artifacts before parsing. The approach is
evaluated by reconstructing a simplified version of the programming language
Python. Our solution aims to increase the reusability of existing language
components to reduce development time and increase the overall quality of
software languages.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [12] [A Zone-Based Algorithm for Timed Parity Games](https://arxiv.org/abs/2510.07361)
*Gilles Geeraerts,Frédéric Herbreteau,Jean-François Raskin,Alexis Reynouard*

Main category: cs.LO

TL;DR: 本文对 timed games 的语义进行了改进，提出了高效的 zone-based 算法，并用 UppAal 验证了其在 timed parity games 上的有效性。


<details>
  <summary>Details</summary>
Motivation: 原有的 timed games 语义在控制器综合时有些反直觉，而且希望开发出更有效的基于区域(zone)的算法。

Method: 在已有的 timed games 语义基础上做出修改，引入了新的语义，并采用基于 zone 的算法来处理 timed parity games。该算法在 UppAal 的 zone 库上实现，作为原型进行验证。

Result: 实现了一个 zone-based 的算法原型，可以有效处理 parity objectives，并展现出复杂的时序玩家交互语义。实验表明该方法是可行的。

Conclusion: 本文提出的修改后语义和基于 zone 的算法，能够更合理高效地处理 timed parity games，并为定时博弈中的控制器综合提供了新的理论与工具。

Abstract: This paper revisits timed games by building upon the semantics introduced in
"The Element of Surprise in Timed Games". We introduce some modifications to
this semantics for two primary reasons: firstly, we recognize instances where
the original semantics appears counterintuitive in the context of controller
synthesis; secondly, we present methods to develop efficient zone-based
algorithms. Our algorithm successfully addresses timed parity games, and we
have implemented it using UppAal's zone library. This prototype effectively
demonstrates the feasibility of a zone-based algorithm for parity objectives
and a rich semantics for timed interactions between the players.

</details>


### [13] [Homomorphism Problems in Graph Databases and Automatic Structures](https://arxiv.org/abs/2510.07422)
*Rémi Morvan*

Main category: cs.LO

TL;DR: 本论文研究了数据库和自动结构中的同态问题，提出了结合查询最小化的算法，揭示了自动结构同态问题普遍不可判定，但结构可描述性在特定逻辑下仍可判定。


<details>
  <summary>Details</summary>
Motivation: 了解同态问题在数据库查询和约束求解中的作用，特别是针对有限与无限结构，提高查询效率和可靠性。

Method: 第一部分研究带有正则路径谓词的结合查询，通过原子数和查询图树宽进行最小化分析；第二部分将同态问题提升至可自动化结构层面，探索其判定性，并通过代数语言理论分析逻辑可描述性。

Result: 结合查询最小化问题在两种度量下均可判定，并为实际常用查询设计了高效算法。对自动结构的同态问题表明多数情况不可判定，但在良好逻辑下结构可描述性仍可判定。

Conclusion: 论文系统分析了同态问题在数据库和自动结构中的判定性与最小化，提升了查询优化和逻辑表达能力，同时揭示了自动结构同态判定的理论界限。

Abstract: This thesis investigates the central role of homomorphism problems
(structure-preserving maps) in two complementary domains: database querying
over finite, graph-shaped data, and constraint solving over (potentially
infinite) structures. Building on the well-known equivalence between
conjunctive query evaluation and homomorphism existence, the first part focuses
on conjunctive regular path queries, a standard extension of conjunctive
queries that incorporates regular-path predicates. We study the fundamental
problem of query minimization under two measures: the number of atoms
(constraints) and the tree-width of the query graph. In both cases, we prove
the problem to be decidable, and provide efficient algorithms for a large
fragment of queries used in practice. The second part of the thesis lifts
homomorphism problems to automatic structures, which are infinite structures
describable by finite automata. We highlight a dichotomy, between homomorphism
problems over automatic structures that are decidable in non-deterministic
logarithmic space, and those that are undecidable (proving to be the more
common case). In contrast to this prevalence of undecidability, we then focus
on the language-theoretic properties of these structures, and show, relying on
a novel algebraic language theory, that for any well-behaved logic (a
pseudovariety), whether an automatic structure can be described in this logic
is decidable.

</details>


### [14] [Verifying Graph Neural Networks with Readout is Intractable](https://arxiv.org/abs/2510.08045)
*Artem Chernobrovkin,Marco Sälzer,François Schwarzentruber,Nicolas Troquard*

Main category: cs.LO

TL;DR: 提出了验证量化ACR-GNNs的新理论工具，并证明验证难度极高，同时量化模型轻量化、效果佳。


<details>
  <summary>Details</summary>
Motivation: 目前GNN的应用广泛，但量化GNN的可验证性、安全性分析工具缺乏，且需要兼顾模型效率与精度。

Method: 提出了一种新的逻辑语言，用于对量化的ACR-GNNs（具有全局readout）进行推理，并用该语言进行复杂度分析和实验对比。

Result: 证明了相关验证任务的复杂度（co）NEXPTIME完全，提示验证量化GNN极度困难；同时实验发现量化模型较轻却精度保持良好。

Conclusion: 验证带有global readout的量化ACR-GNNs在理论上属于（co）NEXPTIME完全，计算上极度复杂，且实验上其精度与非量化模型相近，模型更加轻量化。

Abstract: We introduce a logical language for reasoning about quantized
aggregate-combine graph neural networks with global readout (ACR-GNNs). We
provide a logical characterization and use it to prove that verification tasks
for quantized GNNs with readout are (co)NEXPTIME-complete. This result implies
that the verification of quantized GNNs is computationally intractable,
prompting substantial research efforts toward ensuring the safety of GNN-based
systems. We also experimentally demonstrate that quantized ACR-GNN models are
lightweight while maintaining good accuracy and generalization capabilities
with respect to non-quantized models.

</details>


### [15] [Implication Problems over Positive Semirings](https://arxiv.org/abs/2510.08112)
*Minna Hirvonen*

Main category: cs.LO

TL;DR: 本文提出利用半环团队语义作为统一框架，推广并公理化数据库及概率理论中多种依赖关系的蕴涵推理问题，不同半环能涵盖多种语义，促进依赖结构的统一分析。


<details>
  <summary>Details</summary>
Motivation: 为了在数据库理论和概率理论中对依赖关系进行更一般化和系统化的研究，作者提出使用半环团队语义框架，以统一不同类型的依赖和语义。

Method: 作者将数据库关系建模为带正半环注释的团队，并推广了功能依赖、包含依赖、边缘同一性和（概率）独立性等概念；进而研究了蕴涵问题的公理化（即如何从给定依赖集合推理得到新的依赖），对各种半环同时考察这些问题。

Result: 结果展示了半环团队语义是一个通用框架，可以让研究者针对不同半环同时分析逻辑蕴涵与推理问题，不同半环提供了语义上的多样性，从而统一了关系、包以及概率等不同语义。

Conclusion: 半环团队语义为研究各种依赖及其蕴涵问题提供了统一且灵活的理论工具，有助于更好地理解和表征不同数据库与概率语义下的依赖结构。

Abstract: We study various notions of dependency in semiring team semantics. Semiring
teams are essentially database relations, where each tuple is annotated with
some element from a positive semiring. We consider semiring generalizations of
several dependency notions from database theory and probability theory,
including functional and inclusion dependencies, marginal identity, and
(probabilistic) independence. We examine axiomatizations of implication
problems, which are rule-based characterizations for the logical implication
and inference of new dependencies from a given set of dependencies. Semiring
team semantics provides a general framework, where different implication
problems can be studied simultaneously for various semirings. The choice of the
semiring leads to a specific semantic interpretation of the dependencies, and
hence different semirings offer a way to study different semantics (e.g.,
relational, bag, and probabilistic semantics) in a unified framework.

</details>


### [16] [Complexity Results in Team Semantics: Nonemptiness Is Not So Complex](https://arxiv.org/abs/2510.08122)
*Aleksi Anttila,Juha Kontinen,Fan Yang*

Main category: cs.LO

TL;DR: 研究了在团队语义下引入非空元NE的凸逻辑，其可满足性问题是NP完全，有效性为coNP完全，模型检测为P。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索团队语义下凸逻辑的复杂性理论性质，特别关注在经典命题逻辑中加入非空元NE后的逻辑性质。该逻辑以其凸性和并封闭性著称，但相关复杂性仍需系统分析。

Method: 论文通过对所研究逻辑的满足性、有效性及模型检测问题进行复杂性分析，包括归约证明与复杂性分类。

Result: 得到三项主要结果：该逻辑的可满足性问题为NP完全，有效性问题为coNP完全，模型检测问题属于P。

Conclusion: 作者揭示了在团队语义下，加入非空元NE后的命题逻辑兼具凸性、并封闭性以及独特的复杂性特征，为后续复杂性理论分析及相关逻辑扩展提供了依据。

Abstract: We initiate the study of the complexity-theoretic properties of convex logics
in team semantics. We focus on the extension of classical propositional logic
with the nonemptiness atom NE, a logic known to be both convex and union
closed. We show that the satisfiability problem for this logic is NP-complete,
that its validity problem is coNP-complete, and that its model-checking problem
is in P.

</details>


### [17] [Compression for Coinductive Infinitary Rewriting: A Generic Approach, with Applications to Cut-Elimination for Non-Wellfounded Proofs](https://arxiv.org/abs/2510.08420)
*Rémy Cerda,Alexis Saurin*

Main category: cs.LO

TL;DR: 本文研究了无穷重写系统中的压缩性质，提出了通用的压缩证明方法，并将其应用到一阶重写、无穷λ演算和高级线性逻辑的证明系统中，推动了非终止计算理论的发展。


<details>
  <summary>Details</summary>
Motivation: 无穷重写用于描述那些不会终止但仍具有生产性的重写系统的动态行为。将此理论扩展到更加一般的、非良基推导，并探讨其中的压缩（compression）性质，有助于理解和简化非终止计算过程。

Method: 作者采用了协同归纳（coinduction）等方法，将无穷重写系统的标准表示扩展到任意非良基推导。同时，设计了一种通用压缩证明，并分析了何时重写系统具有可压缩性。

Result: 作者提出了通用压缩证明框架，阐明了可压缩的无穷重写系统的关键性质。作为示例，讨论了一阶重写和无穷λ演算，并证明了这些系统的压缩。此外，还将压缩应用到非良基证明系统μMALL∞中的割消去序列，这为更一般的割消去结果奠定了基础。

Conclusion: 该工作推广了无穷重写理论，并提出了压缩性质的通用证明。证明了协同归纳表示的合理性，也为复杂逻辑系统的割消去提供了关键技术。

Abstract: Infinitary rewriting, i.e. rewriting featuring possibly infinite terms and
sequences of reduction, is a convenient framework for describing the dynamics
of non-terminating but productive rewriting systems. In its original definition
based on metric convergence of ordinal-indexed sequences of rewriting steps, a
highly desirable property of an infinitary rewriting system is Compression,
i.e. the fact that rewriting sequences of arbitrary ordinal length can always
be 'compressed' to equivalent sequences of length at most {\omega}.
  Since then, the standard examples of infinitary rewriting systems have been
given another equivalent presentation based on coinduction. In this work, we
extend this presentation to the rewriting of arbitrary non-wellfounded
derivations and we investigate compression in this setting. We design a generic
proof of compression, relying on a characterisation factorising most of the
proof and identifying the key property a compressible infinitary rewriting
system should enjoy.
  As running examples, we discuss first-order rewriting and infinitary
{\lambda}-calculi. For the latter, compression can in particular be seen as a
justification of its coinductive presentation in the literature. As a more
advanced example, we also address compression of cut-elimination sequences in
the non-wellfounded proof system {\mu}MALL{\infty} for multiplicative-additive
linear logics with fixed points, which is a key lemma of several
cut-elimination results for similar proof systems.

</details>


### [18] [Dynamic Automated Deduction by Contradiction Separation: The Standard Extension Algorithm](https://arxiv.org/abs/2510.08468)
*Yang Xu,Xingxing He,Shuwei Chen,Jun Liu,Xiaomei Zhong*

Main category: cs.LO

TL;DR: 本文实现和证明了CSE理论的Standard Extension算法，突破了传统自动推理系统的局限，在重要竞赛中表现优异，为多子句自动推理奠定了坚实基础。


<details>
  <summary>Details</summary>
Motivation: 自动推理系统传统上依赖于二元推理，限制了在证明搜索过程中多子句协同的能力。Xu等人在2018年提出了CSE框架，理论上突破了这一限制，但并未给出具体的算法实现方法。

Method: 提出并实现了Standard Extension算法，它通过补充文字扩展动态构造矛盾，首次将CSE理论以具体的算法形式落地。该算法统一用于可满足性和不可满足性检查，并对其正确性和完备性进行了形式化证明。

Result: 算法的有效性通过CSE系列系统（CSE, CSE-E, CSI-E, CSI-Enig）在CASC等重要自动推理竞赛中的优异表现间接获得了支持。

Conclusion: Standard Extension机制不仅理论上完善了CSE框架，并且在实际自动推理系统中表现良好，成为多子句动态推理的重要基础。

Abstract: Automated deduction seeks to enable machines to reason with mathematical
precision and logical completeness. Classical resolution-based systems, such as
Prover9, E, and Vampire, rely on binary inference, which inherently limits
multi-clause synergy during proof search. The Contradiction Separation
Extension (CSE) framework, introduced by Xu et al. (2018), overcame this
theoretical limitation by extending deduction beyond binary inference. However,
the original work did not specify how contradictions are algorithmically
constructed and extended in practice. This paper presents the Standard
Extension algorithm, the first explicit procedural realization of contradiction
separation reasoning. The proposed method dynamically constructs contradictions
through complementary literal extension, thereby operationalizing the CSE
theory within a unified algorithm for satisfiability and unsatisfiability
checking. The algorithm's soundness and completeness are formally proven, and
its effectiveness is supported indirectly through the performance of CSE-based
systems, including CSE, CSE-E, CSI-E, and CSI-Enig in major automated reasoning
competitions (CASC) in the last few years. These results confirm that the
Standard Extension mechanism constitutes a robust and practically validated
foundation for dynamic, multi-clause automated deduction.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [19] [Inconsistent Affective Reaction: Sentiment of Perception and Opinion in Urban Environments](https://arxiv.org/abs/2510.07359)
*Jingfei Huang,Han Tu*

Main category: cs.CL

TL;DR: 本文结合街景图片与社交媒体文本，开发新的方法揭示北京二环内人们感知与观点情感反应的不一致性。大量数据分析显示，疫情前后居民的感知与观点存在显著变化，这为城市管理和更新提供了科学依据。


<details>
  <summary>Details</summary>
Motivation: 社交媒体的兴起改变了我们对城市环境的认识，带来了人类感知和观点中的情感反应差异，挑战了现有的城市多维情感分析方法。本文旨在探索和解释感知与观点之间的情感不一致性，为城市研究提供新的思路。

Method: 构建了一个包含140,750张百度和腾讯街景图片的感知数据集，以及984,024条微博文本观点数据。研究开发了反应指数，将目标检测和自然语言处理技术结合，用于分类北京二环2016及2022年情感。通过回归分析、图像分割和基于土地利用分布的词频分析，对分类后的情感反应进行分析与可视化。

Result: 感知情感反应趋势图显示正向情感分布趋向均衡，而观点情感趋势图则表现出更极端的变化。感知与观点之间存在显著的情感不匹配，且这种变化与高密度建筑和行人数量有密切关系。提出的情感不一致地图揭示了疫情前后感知与观点情感的变化，为环境管理和城市更新策略提供了参考。

Conclusion: 社交媒体和街景大数据结合，为城市情感分析带来新维度。本文发现，城市居民的感知和公开发表的观点在情感反应上存在显著不一致，且这些不一致与城市物理和社会环境特征密切相关，为未来城市更新和管理指明了方向。

Abstract: The ascension of social media platforms has transformed our understanding of
urban environments, giving rise to nuanced variations in sentiment reaction
embedded within human perception and opinion, and challenging existing
multidimensional sentiment analysis approaches in urban studies. This study
presents novel methodologies for identifying and elucidating sentiment
inconsistency, constructing a dataset encompassing 140,750 Baidu and Tencent
Street view images to measure perceptions, and 984,024 Weibo social media text
posts to measure opinions. A reaction index is developed, integrating object
detection and natural language processing techniques to classify sentiment in
Beijing Second Ring for 2016 and 2022. Classified sentiment reaction is
analysed and visualized using regression analysis, image segmentation, and word
frequency based on land-use distribution to discern underlying factors. The
perception affective reaction trend map reveals a shift toward more evenly
distributed positive sentiment, while the opinion affective reaction trend map
shows more extreme changes. Our mismatch map indicates significant disparities
between the sentiments of human perception and opinion of urban areas over the
years. Changes in sentiment reactions have significant relationships with
elements such as dense buildings and pedestrian presence. Our inconsistent maps
present perception and opinion sentiments before and after the pandemic and
offer potential explanations and directions for environmental management, in
formulating strategies for urban renewal.

</details>


### [20] [Haystack Engineering: Context Engineering for Heterogeneous and Agentic Long-Context Evaluation](https://arxiv.org/abs/2510.07414)
*Mufei Li,Dongqi Fu,Limei Wang,Si Zhang,Hanqing Zeng,Kaan Sancak,Ruizhong Qiu,Haoyu Wang,Xiaoxin He,Xavier Bresson,Yinglong Xia,Chonglin Sun,Pan Li*

Main category: cs.CL

TL;DR: 论文指出当前长文本评测忽略现实噪声和agent流程干扰，提出HaystackCraft基准精准模拟这些困难。实验发现即使最强模型也在真实场景下易受级联错误影响，强调了提升长文本鲁棒性的迫切性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在长文本环境下的表现常常通过“针找大海”任务（NIAH）来评估，但这些任务忽略了现实中检索偏差和智能体流程导致的噪声语境。作者认为需要精细构造干扰语境（haystack engineering），以真实反映模型在现实噪声和复杂流程下的鲁棒性。

Method: 作者提出了一种新的基准——HaystackCraft。该方法通过利用英语维基百科超级链接网络及多跳问题，模拟异质检索策略（稀疏、密集、混合、基于图的方法）对语境噪声的影响。同时，HaystackCraft拓展了标准NIAH任务，加入了依赖于LLM动态推理和agent操作的设置，如模型自我查询优化、反思推理和自决终止时机。

Result: 实验在15种长文本模型上进行，结果显示：（1）虽然强大的密集检索器会引入更具挑战性的干扰项，图排序检索既提升了效果又减少有害干扰；（2）在模拟agent操作时，即使是高级模型如Gemini 2.5 Pro和GPT-5也会因自生成干扰项或终止决策难题而出现级联错误。

Conclusion: 现实长语境推理场景中，噪声和智能体工作流对LLM是持续挑战。HaystackCraft为未来长语境鲁棒性提升提供了重要基准和测试平台。

Abstract: Modern long-context large language models (LLMs) perform well on synthetic
"needle-in-a-haystack" (NIAH) benchmarks, but such tests overlook how noisy
contexts arise from biased retrieval and agentic workflows. We argue that
haystack engineering is necessary to construct noisy long contexts that
faithfully capture key real-world factors -- distraction from heterogeneous
biased retrievers and cascading errors in agentic workflows -- to test models'
long-context robustness. We instantiate it through HaystackCraft, a new NIAH
benchmark built on the full English Wikipedia hyperlink network with multi-hop
questions. HaystackCraft evaluates how heterogeneous retrieval strategies
(e.g., sparse, dense, hybrid, and graph-based) affect distractor composition,
haystack ordering, and downstream LLM performance. HaystackCraft further
extends NIAH to dynamic, LLM-dependent settings that simulate agentic
operations, where models refine queries, reflect on their past reasonings, and
decide when to stop. Experiments with 15 long-context models show that (1)
while stronger dense retrievers can introduce more challenging distractors,
graph-based reranking simultaneously improves retrieval effectiveness and
mitigates more harmful distractors; (2) in agentic tests, even advanced models
like Gemini 2.5 Pro and GPT-5 suffer cascading failures from self-generated
distractors or struggle to perform early stops. These results highlight
persistent challenges in agentic long-context reasoning and establish
HaystackCraft as a valuable testbed for future progress.

</details>


### [21] [Lemma Dilemma: On Lemma Generation Without Domain- or Language-Specific Training Data](https://arxiv.org/abs/2510.07434)
*Olia Toporkov,Alan Akbik,Rodrigo Agerri*

Main category: cs.CL

TL;DR: 该论文研究了LLMs在词形还原任务上的表现，发现LLMs即使无需微调，仅用少量示例也能在多语言场景中达到甚至超过传统方法的效果，对低资源领域词形还原有重要启示。


<details>
  <summary>Details</summary>
Motivation: 近年来大型语言模型（LLMs）在众多NLP任务中表现优异，但尚未有其在词形还原（lemmatization）任务中的系统评估，尤其是在缺乏目标领域或语言监督数据场景下。作者旨在探究LLM在这一任务上的有效性。

Method: 作者采用实证研究方法，将最新一代LLMs用于上下文词形还原任务，并与传统的完全监督方法进行对比。具体包括：（i）仅编码器的监督方法，在非目标领域上进行微调；（ii）跨语言方法；（iii）直接用LLM进行上下文词形生成，仅提供少量示例，无需微调。实验覆盖12种形态复杂度不同的语言。

Result: 实验结果显示，当有高质量数据微调时，编码器方法在非目标领域仍具竞争力。但当前LLMs仅需少量示例、无需微调即可在大多数语言上实现最先进性能，直接生成目标词形。

Conclusion: LLMs在上下文词形还原任务中表现出强大能力，特别是在低监督或零监督场景下，通过少量示例即可超越传统方法，在多语言任务中具有广泛适用性。

Abstract: Lemmatization is the task of transforming all words in a given text to their
dictionary forms. While large language models (LLMs) have demonstrated their
ability to achieve competitive results across a wide range of NLP tasks, there
is no prior evidence of how effective they are in the contextual lemmatization
task. In this paper, we empirically investigate the capacity of the latest
generation of LLMs to perform in-context lemmatization, comparing it to the
traditional fully supervised approach. In particular, we consider the setting
in which supervised training data is not available for a target domain or
language, comparing (i) encoder-only supervised approaches, fine-tuned
out-of-domain, and (ii) cross-lingual methods, against direct in-context lemma
generation with LLMs. Our experimental investigation across 12 languages of
different morphological complexity finds that, while encoders remain
competitive in out-of-domain settings when fine-tuned on gold data, current
LLMs reach state-of-the-art results for most languages by directly generating
lemmas in-context without prior fine-tuning, provided just with a few examples.
Data and code available upon publication:
https://github.com/oltoporkov/lemma-dilemma

</details>


### [22] [LASER: An LLM-based ASR Scoring and Evaluation Rubric](https://arxiv.org/abs/2510.07437)
*Amruta Parulekar,Preethi Jyothi*

Main category: cs.CL

TL;DR: 作者提出了用大语言模型优化ASR评价的新方法，用于提升自动语音识别系统对语义误差的识别准确性，并在多种印度语言上验证了该方法的高相关性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统自动语音识别（ASR）评价指标如词错误率（WER）会对一些并不影响句子语义的形态和句法细节作出不必要的惩罚，因此，需要更合理的评价方法来反映真实语义误差。

Method: 提出了基于大语言模型（LLM）的评分标准LASER，利用最新的LLM的上下文学习能力，通过详细示例的提示学习。具体方法包括用Gemini 2.5 Pro模型对印地语进行评分，及在较小的LLM（如Llama 3）上通过微调单词对例子来自动预测应该如何惩罚ASR的错误。

Result: 使用Gemini 2.5 Pro进行的印地语LASER评分与人工标注的相关性高达94%；同一印地语示例对分析其他印度语言（马拉地语、卡纳达语、马拉雅拉姆语）的错误也很有效。微调后的Llama 3模型在预测惩罚类型时准确率接近89%。

Conclusion: LLM-based LASER评分标准能更合理地反映ASR语义误差，且模型方法具有跨语言泛化能力及高与人工标注一致性，是对传统WER的有效补充与改进。

Abstract: Standard ASR evaluation metrics like Word Error Rate (WER) tend to unfairly
penalize morphological and syntactic nuances that do not significantly alter
sentence semantics. We introduce an LLM-based scoring rubric LASER that
leverages state-of-the-art LLMs' in-context learning abilities to learn from
prompts with detailed examples. Hindi LASER scores using Gemini 2.5 Pro
achieved a very high correlation score of 94% with human annotations. Hindi
examples in the prompt were also effective in analyzing errors in other Indian
languages such as Marathi, Kannada and Malayalam. We also demonstrate how a
smaller LLM like Llama 3 can be finetuned on word-pair examples derived from
reference and ASR predictions to predict what kind of penalty should be applied
with close to 89% accuracy.

</details>


### [23] [Meaningful Pose-Based Sign Language Evaluation](https://arxiv.org/abs/2510.07453)
*Zifan Jiang,Colin Leong,Amit Moryossef,Anne Göhring,Annette Rios,Oliver Cory,Maksym Ivashechkin,Neha Tarigopula,Biao Zhang,Rico Sennrich,Sarah Ebling*

Main category: cs.CL

TL;DR: 本文系统评估了三类手语姿态的评估方法，并公开评测工具，提升了手语翻译系统的开发与研究效率。


<details>
  <summary>Details</summary>
Motivation: 现有手语生成系统缺乏标准化、易于复现且有效的评估流程，影响其实际应用发展。作者希望建立更加科学和实用的评估体系。

Method: 研究采用了关键点距离、嵌入向量和反向翻译三类评估指标，通过自动化检索和人工相关性实验，比较了这些方法在不同应用中效果。

Result: 研究展示了不同评估指标在多种场景下的优缺点，并公开了开源评估工具，有助于规范手语生成与翻译系统的开发与测试。

Conclusion: 提出了一种综合性的手语骨架姿态评估方法，并通过自动化元评估与人工相关性研究验证了不同指标的实用性与权衡，为手语系统开发与评价提供了可复现工具。

Abstract: We present a comprehensive study on meaningfully evaluating sign language
utterances in the form of human skeletal poses. The study covers keypoint
distance-based, embedding-based, and back-translation-based metrics. We show
tradeoffs between different metrics in different scenarios through automatic
meta-evaluation of sign-level retrieval and a human correlation study of
text-to-pose translation across different sign languages. Our findings and the
open-source pose-evaluation toolkit provide a practical and reproducible way of
developing and evaluating sign language translation or generation systems.

</details>


### [24] [Populism Meets AI: Advancing Populism Research with LLMs](https://arxiv.org/abs/2510.07458)
*Eduardo Ryô Tamaki,Yujin J. Jung,Julia Chatterley,Grant Mitchell,Semir Dzebo,Cristóbal Sandoval,Levente Littvay,Kirk A. Hawkins*

Main category: cs.CL

TL;DR: 本文基于全球民粹主义数据库和新的链式思考提示方法，显著提升了大模型在民粹主义文本分析上的准确性和效率，为相关领域文本测量提供了可推广的新工具。


<details>
  <summary>Details</summary>
Motivation: 衡量民粹主义的观念内容一直具有挑战性，传统的文本分析方法虽有效但成本高、耗时长且难以在多语言和大规模文本中使用。

Method: 利用全球民粹主义数据库（GPD）中已标注的领袖演讲语料，采用与人工编码员训练过程类似的评分标准和锚点引导链式思考（CoT）提示，指导大语言模型进行推理，并对多种开源及私有模型进行测试，通过复现GPD中的得分来评估模型表现。

Result: 所提出的领域特定提示策略使得大语言模型在民粹主义分类任务中能够达到与专家人工编码员相当的准确率，充分展现了模型辨析民粹主义细微语境的能力。

Conclusion: 链式思考提示结合评分标准的引导可以显著提高大语言模型在复杂文本政治语境下的表现，为民粹主义等意识形态测量提供高效、可扩展的新路径。

Abstract: Measuring the ideational content of populism remains a challenge. Traditional
strategies based on textual analysis have been critical for building the
field's foundations and providing a valid, objective indicator of populist
framing. Yet these approaches are costly, time consuming, and difficult to
scale across languages, contexts, and large corpora. Here we present the
results from a rubric and anchor guided chain of thought (CoT) prompting
approach that mirrors human coder training. By leveraging the Global Populism
Database (GPD), a comprehensive dataset of global leaders' speeches annotated
for degrees of populism, we replicate the process used to train human coders by
prompting the LLM with an adapted version of the same documentation to guide
the model's reasoning. We then test multiple proprietary and open weight models
by replicating scores in the GPD. Our findings reveal that this domain specific
prompting strategy enables the LLM to achieve classification accuracy on par
with expert human coders, demonstrating its ability to navigate the nuanced,
context sensitive aspects of populism.

</details>


### [25] [MAPRO: Recasting Multi-Agent Prompt Optimization as Maximum a Posteriori Inference](https://arxiv.org/abs/2510.07475)
*Zheyuan Zhang,Lin Ge,Hongjiang Li,Weicheng Zhu,Chuxu Zhang,Yanfang Ye*

Main category: cs.CL

TL;DR: 本文提出MAPRO框架，通过概率推断与反馈机制优化多智能体系统提示词，在多项任务中超越现有方法，推动MAS系统可靠性和自动化构建。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统（MAS）尽管可超越单一智能体，但高效协作设计受限于提示词敏感性和系统不稳定性，且手动调整成本高，缺乏系统化的多智能体提示词优化方法。

Method: 提出MAPRO框架，将MAS提示词优化建模为最大后验概率（MAP）推断，并采用基于语言的最大乘积置信传播算法求解。同时，引入拓扑感知的细化机制，通过反馈和归因选择性地更新各智能体提示，从而迭代优化系统。

Result: MAPRO在多项任务基准测试中取得最优性能，超过手工设计和最新自动化方案，同时为MAS系统设计提供一般性原则。

Conclusion: MAPRO有效提升多智能体系统的提示词协作优化效率和性能，为未来MAS更可靠、系统化的设计提供技术路线。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
diverse tasks, and LLM-based agents further extend these abilities to various
practical workflows. While recent progress shows that multi-agent systems (MAS)
can outperform single agents by coordinating specialized roles, designing
effective MAS remains difficult due to prompt sensitivity and the compounded
instability MAS creates. To cope with the challenge, recent efforts in
automated prompt design have reduced manual effort. However, multi-agent prompt
optimization remains largely unexplored. Challenges like exponentially
expanding search space and ambiguous credit assignment together make systematic
design intractable without principled methods. Therefore, we introduce
M}ulti-Agent PRompt Optimization (MAPRO), a four-stage framework that first
formulates MAS prompt optimization as a Maximum a Posteriori (MAP) inference
problem and solves it using a language-guided variant of max-product belief
propagation algorithm. To address credit assignment and updates the system
iteratively, MAPRO employs a topology-aware refinement mechanism that
integrates execution feedback and downstream blames to selectively update agent
prompts. Through this process, MAPRO progressively converges to a coordinated
set of agent-specific prompt policies. Across benchmarks in various tasks,
MAPRO achieves state-of-the-art performance, consistently surpassing manually
engineered baselines and recent automated alternatives. Beyond performance, our
MAP-based formulation also delivers general guidelines for building more
reliable and principled multi-agent systems in the future

</details>


### [26] [AsyncSpade: Efficient Test-Time Scaling with Asynchronous Sparse Decoding](https://arxiv.org/abs/2510.07486)
*Shuqing Luo,Yilin Guan,Pingzhi Li,Hanrui Wang,Tianlong Chen*

Main category: cs.CL

TL;DR: AsyncSpade针对大模型推理的KV-cache内存瓶颈与顺序依赖，通过异步框架与智能查询状态预测，实现大幅提升推理速度并保证准确率，优于目前主流方法，适用于高并发和长链思维场景。


<details>
  <summary>Details</summary>
Motivation: 在长链式思维（CoT）推理中，Test-time scaling (TTS) 可以提升大语言模型（LLM）的推理能力，但随之而来的线性KV-cache增长加剧了内存瓶颈。这一瓶颈在高并发和长CoT场景下尤为严峻，现有的稀疏解码方法又存在效率和性能的权衡限制。作者希望提升推理效率，同时解决KV-cache导致的运行时内存瓶颈。

Method: 提出AsyncSpade框架，包括两个核心组件：（1）一种新颖的轻量级时间回归预测模块，用于预估下一步查询状态；（2）一个异步与解耦的骨架，将KV缓存过滤与自回归解码分离，通过异步机制重叠token级选择和前向推理计算，从而提升整体效率。该方法实现无训练地基于短期历史查询准确建模当前查询状态。

Result: AsyncSpade能充分重叠KV缓存操作和推理流水线，实现理论上的最优每Token解码时间（TPOT）。相比于现有最优基线Quest，TPOT降低超20%；和全量Attention对比，在Qwen3-8B及Qwen3-32B模型上TPOT降低至少50%，且在多个TTS基准（如AIME-24/25, GPQA-Diamond, MATH-500）下，准确率不降反升。

Conclusion: AsyncSpade首次在不牺牲模型推理准确度的前提下，解决了推理过程中的顺序依赖和内存瓶颈难题，显著提升了长链思维大模型的推理效率，为高并发与高效率LLM推理服务提供了新的解决方案。

Abstract: Test-time scaling (TTS) boosts LLM reasoning via long chain-of-thought (CoT),
but the linear KV-cache growth amplifies the memory-bound bottleneck of LLM
decoding. Query-aware page-level sparse decoding can achieve state-of-the-art
performance under constrained FLOPs budgets, but is limited by both
sequential-dependent page filtering and coarse-grained token selection,
hampering serving efficiency and model performance on TTS tasks under high
concurrency and long CoT scenarios (consuming even higher runtime than the
forward pipeline itself). In this paper, we first find that the current-step
query state can be accurately approximated in a unified manner from a short
window of recent queries, enabling training-free query-aware sparsity without
waiting in the decoding loop. We propose AsyncSpade, an asynchronous framework
for efficient TTS built on two core components: (1) a novel light-weight
temporal-regressive module that predicts the next-token query state; (2) an
asynchronous and disaggregated framework that decouples the KV cache filtering
from the auto-regressive decoding loop, overlapping the token-level KV
selection with the forward inference computation through asynchronism. To our
knowledge, AsyncSpade is the first to eliminate the sequential dependence
without sacrificing model performance. We validate the effectiveness of
AsyncSpade on common LLM serving setups with an A100 node, where AsyncSpade
fully overlaps KV-cache operations with the inference pipeline, achieving
theoretical optimal time-per-output-token (TPOT). Specifically, AsyncSpade
delivers over 20% reduction on TPOT compared to SoTA baseline (i.e. Quest) and
at least 50% TPOT reduction compared to full attention on Qwen3-8B and
Qwen3-32B models, while matching or surpassing their accuracy on various TTS
benchmarks (AIME-24/25, GPQA-Diamond, MATH-500).

</details>


### [27] [Can Lessons From Human Teams Be Applied to Multi-Agent Systems? The Role of Structure, Diversity, and Interaction Dynamics](https://arxiv.org/abs/2510.07488)
*Rasika Muralidharan,Jaewoon Kwak,Jisun An*

Main category: cs.CL

TL;DR: 分析多智能体LLM系统团队结构、成员多样性和交互动态对任务表现的影响，发现扁平结构优于层级结构，多样性影响复杂，协作时存在协调难题。


<details>
  <summary>Details</summary>
Motivation: 受人类团队科学启发，探究大语言模型驱动智能体系统的团队结构、多样性及交互对协作表现的影响。

Method: 提出了多智能体框架，分析结构、多样性与交互动态，并在四大任务上评估团队表现。通过任务后反思和访谈进一步挖掘团队协作动态。

Result: 团队结构扁平化有更好效果，多样性作用复杂；智能体高估团队表现，但实际协作整合与对话协调存在问题。

Conclusion: 扁平化团队结构在多智能体LLM系统中效果优于层级结构；多样性影响复杂；智能体对团队表现自信但协作整合存在困难。

Abstract: Multi-Agent Systems (MAS) with Large Language Model (LLM)-powered agents are
gaining attention, yet fewer studies explore their team dynamics. Inspired by
human team science, we propose a multi-agent framework to examine core aspects
of team science: structure, diversity, and interaction dynamics. We evaluate
team performance across four tasks: CommonsenseQA, StrategyQA, Social IQa, and
Latent Implicit Hate, spanning commonsense and social reasoning. Our results
show that flat teams tend to perform better than hierarchical ones, while
diversity has a nuanced impact. Interviews suggest agents are overconfident
about their team performance, yet post-task reflections reveal both
appreciation for collaboration and challenges in integration, including limited
conversational coordination.

</details>


### [28] [Can Speech LLMs Think while Listening?](https://arxiv.org/abs/2510.07497)
*Yi-Jen Shih,Desh Raj,Chunyang Wu,Wei Zhou,SK Bong,Yashesh Gaur,Jay Mahadeokar,Ozlem Kalinli,Mike Seltzer*

Main category: cs.CL

TL;DR: 本研究通过将链式思维微调、基于熵动态推理启动及DPO技术应用于多流语音大模型，实现推理能力提升2.4倍、延迟下降70%、准确率进一步提升4%，显著改进了语音交互系统的智能水平和响应效率。


<details>
  <summary>Details</summary>
Motivation: 语音大语言模型（speech LLMs）虽然实现了无缝语音交互，但在复杂推理任务上表现有限。此前链式思维（CoT）提示或微调显著提升了文本LLM推理能力，但其对语音LLMs的效果未被充分研究。此外，语音交互中的响应延迟对体验至关重要。

Method: 1）将CoT微调应用于多流语音LLM，提升推理能力；2）提出通过“在听时思考”方式，在问题未说完时提前开始推理，用基于熵的“问题完整性”指标动态指导何时推理，以平衡准确率与延迟；3）采用直接偏好优化（DPO）优化准确率与延迟的帕累托前沿。

Result: （1）通过在文本空间推理，语音LLM平均准确率提升2.4倍；（2）在相同延迟条件下，新的推理启动时机判据带来4%的准确率提升（在ARC-Easy任务）；（3）利用DPO，在准确率无损的前提下，将响应延迟降低70%。

Conclusion: 链式思维微调、基于熵动态推理启动及DPO算法可显著提升语音LLM的推理准确率和交互效率，在复杂语音任务中兼顾高效与高精度，为语音交互智能体系统带来新的进展。

Abstract: Recent advances in speech large language models (speech LLMs) have enabled
seamless spoken interactions, but these systems still struggle with complex
reasoning tasks. Previously, chain-of-thought (CoT) prompting or fine-tuning
has been to shown to significantly improve the reasoning abilities of
text-based LLMs. In this work, we investigate the effect of CoT fine-tuning for
multi-stream speech LLMs, demonstrating that reasoning in text space improves
the accuracy of speech LLMs by 2.4x, on average, over a suite of spoken
reasoning tasks. Beyond accuracy, the latency of the spoken response is a
crucial factor for interacting with voice-based agents. Inspired by the human
behavior of "thinking while listening," we propose methods to reduce the
additional latency from reasoning by allowing the model to start reasoning
before the user query has ended. To achieve this, we introduce an entropy-based
metric, "question completeness," which acts as an indicator to guide the model
on the optimal time to start reasoning. This method provides greater control
over the accuracy-latency trade-off compared with heuristic-based approaches
and, under equivalent latency conditions, yields a 4% accuracy gain on
ARC-Easy. Finally, we use Direct Preference Optimization (DPO) on preference
data created using rejection sampling to push the accuracy-latency pareto
frontier further, resulting in a 70% reduction in latency without loss in
accuracy.

</details>


### [29] [When Thoughts Meet Facts: Reusable Reasoning for Long-Context LMs](https://arxiv.org/abs/2510.07499)
*Soyeong Jeong,Taehee Jung,Sung Ju Hwang,Joo-Kyung Kim,Dongyeop Kang*

Main category: cs.CL

TL;DR: 本文提出通过“思维模板”结构化推理过程，大幅提升长上下文语言模型处理知识密集型任务时的多跳推理效果，并验证了方法的泛用性与可透明复用性。


<details>
  <summary>Details</summary>
Motivation: 长上下文语言模型（LCLMs）具备处理大量文本（数十万tokens）的能力，为基于知识密集型推理场景带来了新的可能性，但简单地向模型输入更多文档无法有效捕捉证据间的联系。因此，本文希望解决证据整合和推理结构化的问题。

Method: 提出了一种“思维模板”（thought templates）框架，将推理过程结构化为可复用的思维缓存（thought caches），通过从已有问题解决轨迹中提取模板，指导多跳推理和证据整合，模板通过自然语言反馈机制进行迭代优化。最终将优化后的模板蒸馏至更小的开源模型，以提升广泛适用性和透明度。

Result: 在多个多样化基准和不同类型的长上下文语言模型（LCLM）中，提出的方法（ToTAL）在检索型和无需检索的任务下均显著超越强大的基线模型。并且优化后的思维模板能够成功蒸馏到小型开源模型上，证明了方法的广泛适用性和推理透明性。

Conclusion: 通过思维模板及其优化方案，显著提升了长上下文语言模型在多跳推理与证据整合上的性能，不仅提高了结果准确性，还增强了模型的透明度和可推广性。

Abstract: Recent Long-Context Language Models (LCLMs) can process hundreds of thousands
of tokens in a single prompt, enabling new opportunities for
knowledge-intensive multi-hop reasoning by integrating large sets of retrieved
documents or, in some cases, directly all necessary information. However,
simply feeding more documents into the context window fails to capture how
evidence should be connected. We address this gap with thought templates, which
recast reasoning as reusable thought caches, derived from prior problem solving
traces, structuring how evidence is combined and guiding multi-hop inference
with factual documents. To keep these templates effective, we propose an update
strategy that iteratively refines templates derived from training data through
natural-language feedback. Across diverse benchmarks and LCLM families, our
approach delivers consistent gains over strong baselines in both
retrieval-based and retrieval-free settings. Furthermore, we show that
optimized templates can be distilled into smaller open-source models,
demonstrating its broad applicability and transparent reasoning reuse. We refer
to our framework as Thought Template Augmented LCLMs (ToTAL).

</details>


### [30] [ParsTranslit: Truly Versatile Tajik-Farsi Transliteration](https://arxiv.org/abs/2510.07520)
*Rayyan Merchant,Kevin Tang*

Main category: cs.CL

TL;DR: 本文针对波斯语两种书写体系之间转写难题，提出并训练了一个具备跨领域强适应能力的序列到序列模型，创设新数据集并与公开数据联合使用。实验表现优异，超越既有方法，各项指标均达新高，为实际应用和后续研究提供了可靠技术基线。相关资源已开源。


<details>
  <summary>Details</summary>
Motivation: 波斯语作为双文字体系语言，在伊朗、阿富汗和塔吉克斯坦使用不同书写标准（Perso-Arabic与Tajik-Cyrillic），造成书写沟通障碍，影响三国之间的信息流通。以往转写模型多用自建单一领域数据集，实际可用性和通用性不足，因此亟需更广域适配、能力更强的自动转写系统。

Method: 采用序列到序列（seq2seq）模型进行塔吉克-波斯语双向转写，并使用所有公开可用的数据集进行训练，同时自建两个数据集以增强训练数据的多元性。

Result: 提出的模型在Farsi到Tajik转写任务上chrF++达到87.91，规范化字符错误率为0.05；在Tajik到Farsi任务上chrF++为92.28，规范化字符错误率仅0.04。模型、数据和代码已全部开源。

Conclusion: 提出了一个新的最先进的Tajik-Farsi（塔吉克-波斯语）转写序列到序列模型，跨所有可用数据集训练，并公布了新的数据集。该模型在不同领域数据上的实验结果设置了全面领先的基准。

Abstract: As a digraphic language, the Persian language utilizes two written standards:
Perso-Arabic in Afghanistan and Iran, and Tajik-Cyrillic in Tajikistan. Despite
the significant similarity between the dialects of each country, script
differences prevent simple one-to-one mapping, hindering written communication
and interaction between Tajikistan and its Persian-speaking ``siblings''. To
overcome this, previously-published efforts have investigated machine
transliteration models to convert between the two scripts. Unfortunately, most
efforts did not use datasets other than those they created, limiting these
models to certain domains of text such as archaic poetry or word lists. A truly
usable transliteration system must be capable of handling varied domains,
meaning that suck models lack the versatility required for real-world usage.
The contrast in domain between data also obscures the task's true difficulty.
We present a new state-of-the-art sequence-to-sequence model for Tajik-Farsi
transliteration trained across all available datasets, and present two datasets
of our own. Our results across domains provide clearer understanding of the
task, and set comprehensive comparable leading benchmarks. Overall, our model
achieves chrF++ and Normalized CER scores of 87.91 and 0.05 from Farsi to Tajik
and 92.28 and 0.04 from Tajik to Farsi. Our model, data, and code are available
at https://anonymous.4open.science/r/ParsTranslit-FB30/.

</details>


### [31] [OWL: Overcoming Window Length-Dependence in Speculative Decoding for Long-Context Inputs](https://arxiv.org/abs/2510.07535)
*Jaeseong Lee,seung-won hwang,Aurick Qiao,Gabriele Oliaro,Ye Wang,Samyam Rajbhandari*

Main category: cs.CL

TL;DR: 提出OWL新模型和LongSpecBench基准集，显著提升长上下文下大模型推理速度和实用性，填补现有方法在真实场景的缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有的 speculative decoding 方法虽然可加速大模型推理，但实际中存在通用性差、长上下文场景下速度反而下降的问题，不能满足实际工作负载需求。

Method: 本文提出长上下文基准测试集（LongSpecBench），并设计了一种新模型 OWL，通过三项创新：（1）基于最后一 token 状态的 LSTM drafter；（2）引入特定 token [SPEC] 丰富 drafter 表示；（3）结合树状和非树状的混合解码算法。

Result: 与主流方法 EAGLE3 相比，OWL 在长上下文输入下接受长度提升约 5 倍，解决了长上下文下加速无效甚至减速的问题。

Conclusion: OWL 模型及新基准集有效提升了 speculative decoding 在长上下文下的表现，为大模型高效推理提供了现实可用的新解决方案，并开源代码与数据集支持后续研究。

Abstract: Speculative decoding promises faster inference for large language models
(LLMs), yet existing methods fail to generalize to real-world settings.
Benchmarks typically assume short contexts (e.g., 2K tokens), whereas practical
workloads involve long contexts. We find current approaches degrade severely
with long contexts; for instance, EAGLE3 even slows down the generation speed
by 0.81x. We address these limitations by releasing a new long-context
benchmark (LongSpecBench) and introducing a novel model (OWL). OWL achieves
about 5x higher acceptance length than EAGLE3 on long-context inputs through
three innovations: (1) an LSTM-based drafter conditioned only on the last-token
state, making it generalize to various lengths, (2) a special token [SPEC] in
the verifier that produces richer representation for drafter, and (3) a hybrid
algorithm combining both tree and non-tree decoding methods. We release all
code and datasets to advance future research.

</details>


### [32] [Deploying Tiny LVLM Judges for Real-World Evaluation of Chart Models: Lessons Learned and Best Practices](https://arxiv.org/abs/2510.07545)
*Md Tahmid Rahman Laskar,Mohammed Saidul Islam,Ridwan Mahbub,Mizanur Rahman,Amran Bhuiyan,Israt Jahan,Mir Tafseer Nayeem,Shafiq Joty,Enamul Hoque,Jimmy Huang*

Main category: cs.CL

TL;DR: 本文针对小型视觉-语言模型在图表评审任务中性能不足问题，提出多标准提示和迁移学习方法。结果表明，经过微调的小型模型不仅成本低，还能胜任跨数据集的评审任务。同时发现高容量模型在复杂提示下易暴露鲁棒性不足，研究揭示了模型规模、提示策略和迁移能力的实际权衡，为大规模低成本图表推理自动评审提供参考。


<details>
  <summary>Details</summary>
Motivation: 现有小型LVLM（≤2B参数）在图表理解任务中的表现有限，制约了资源有限场景下的应用，需要探索更低成本有效的自动评审方法。

Method: 提出多标准提示（multi-criteria prompting）和领域自适应迁移学习（domain-adaptive transfer learning）两种方法，并在图表数据集上微调2B参数模型。

Result: 多标准提示暴露大型模型（如7B参数）的鲁棒性缺陷，导致性能大幅下降；微调后的小型模型能有效进行知识迁移，在细粒度分析中展现出模型规模、提示设计和迁移能力之间的权衡。

Conclusion: 小型LVLM（ChartJudge）经过领域自适应迁移学习后在图表推理任务中表现优异，能在跨数据集知识迁移中胜任专业评审角色。

Abstract: Large Vision-Language Models (LVLMs) with only 7B parameters have shown
promise as automated judges in chart comprehension tasks. However, tiny models
(<=2B parameters) still perform poorly as judges, limiting their real-world use
in resource-constrained settings. To address this, we propose two approaches to
ensure cost-efficient evaluation: (i) multi-criteria prompting, which combines
separate evaluation criteria into a single query, and (ii) domain-adaptive
transfer learning, in which we fine-tune a 2B-parameter LVLM on synthetic
judgments in a chart dataset to create the ChartJudge. Experiments show that
multi-criteria prompting exposes robustness gaps, which led to a huge drop in
performance for 7B models, including specialized LVLM judges like LLaVA-Critic.
In addition, we find that our tiny LVLM (ChartJudge) can effectively transfer
knowledge from one dataset to another to make it a more specialized model. Our
fine-grained analysis across chart types and query complexities offers
actionable insights into trade-offs between model size, prompt design, and
transferability, enabling scalable, low-cost evaluation for chart reasoning
tasks. Our code and the data will be made publicly available.

</details>


### [33] [Multi-Task Pre-Finetuning of Lightweight Transformer Encoders for Text Classification and NER](https://arxiv.org/abs/2510.07566)
*Junyi Zhu,Savas Ozkan,Andrea Maracani,Sinan Mutlu,Cho Jung Min,Mete Ozay*

Main category: cs.CL

TL;DR: 针对移动平台NLP部署难题，作者通过模块化设计优化多任务预微调，大幅提升了命名实体识别和文本分类任务表现，兼顾模型效率与适用性。


<details>
  <summary>Details</summary>
Motivation: 在移动平台部署NLP模型需要模型同时具备高效和强适应性，以应对多样化的应用场景。但现有方法在多任务预微调时会引发优化冲突，难以同时提升多类任务的性能。

Method: 提出基于task-primary LoRA模块的多任务预微调框架，该方法允许一个共享的轻量级BERT-like主编码器结合可插拔的适配器模块，优化多任务下的模型表现。

Result: 在21个下游任务的实验中，命名实体识别平均提升0.8%，文本分类平均提升8.8%。

Conclusion: 所提框架在满足实际移动部署需求的前提下，同时提升了多类NLP任务的性能，与单任务预微调效果相当，为多样化移动NLP应用提供了有效解决方案。

Abstract: Deploying natural language processing (NLP) models on mobile platforms
requires models that can adapt across diverse applications while remaining
efficient in memory and computation. We investigate pre-finetuning strategies
to enhance the adaptability of lightweight BERT-like encoders for two
fundamental NLP task families: named entity recognition (NER) and text
classification. While pre-finetuning improves downstream performance for each
task family individually, we find that na\"ive multi-task pre-finetuning
introduces conflicting optimization signals that degrade overall performance.
To address this, we propose a simple yet effective multi-task pre-finetuning
framework based on task-primary LoRA modules, which enables a single shared
encoder backbone with modular adapters. Our approach achieves performance
comparable to individual pre-finetuning while meeting practical deployment
constraint. Experiments on 21 downstream tasks show average improvements of
+0.8% for NER and +8.8% for text classification, demonstrating the
effectiveness of our method for versatile mobile NLP applications.

</details>


### [34] [Linguistic Patterns in Pandemic-Related Content: A Comparative Analysis of COVID-19, Constraint, and Monkeypox Datasets](https://arxiv.org/abs/2510.07579)
*Mkululi Sikosana,Sean Maudsley-Barton,Oluwaseun Ajao*

Main category: cs.CL

TL;DR: 健康错误信息相比事实性沟通，特点是可读性低、劝说和恐惧词多、修辞更复杂，有助于提升虚假信息的可信度。语言学特征可用于错误信息检测，但需更灵活和多维的方法来增强研究的适应性和准确性。


<details>
  <summary>Details</summary>
Motivation: 疫情期间，网络健康信息传播中真假难辨，特别是健康错误信息迅速扩散。研究动机是探究错误信息与真实沟通语言上的差异，帮助更好识别和应对虚假健康信息。

Method: 本研究通过计算语言学的方法，分析三组语料：COVID-19虚假叙述、一般COVID-19内容及猴痘相关帖子，重点比较可读性、修辞标记及劝说性语言的使用频率，并统计情绪及特殊符号运用。

Result: COVID-19错误信息文本可读性显著较低，劝说与恐惧相关词汇使用频率是其他数据集的两倍以上，并且表现出极少使用感叹号的特征。猴痘内容则更偏向情感表达。错误信息往往采用更复杂修辞风格和情感暗示，有助于提升其可信感。

Conclusion: 语言特征（如复杂句法、情感词汇）可作为网络健康错误信息识别的指标。成果对公共健康信息传播策略及危机沟通理论有实际参考价值。研究也指出传统可读性指标范围有限，劝说词表过窄，分析横截面不足，未来应扩展词库、采用时序设计和平台适配方法。

Abstract: This study conducts a computational linguistic analysis of pandemic-related
online discourse to examine how language distinguishes health misinformation
from factual communication. Drawing on three corpora: COVID-19 false narratives
(n = 7588), general COVID-19 content (n = 10700), and Monkeypox-related posts
(n = 5787), we identify significant differences in readability, rhetorical
markers, and persuasive language use. COVID-19 misinformation exhibited
markedly lower readability scores and contained over twice the frequency of
fear-related or persuasive terms compared to the other datasets. It also showed
minimal use of exclamation marks, contrasting with the more emotive style of
Monkeypox content. These patterns suggest that misinformation employs a
deliberately complex rhetorical style embedded with emotional cues, a
combination that may enhance its perceived credibility. Our findings contribute
to the growing body of work on digital health misinformation by highlighting
linguistic indicators that may aid detection efforts. They also inform public
health messaging strategies and theoretical models of crisis communication in
networked media environments. At the same time, the study acknowledges
limitations, including reliance on traditional readability indices, use of a
deliberately narrow persuasive lexicon, and reliance on static aggregate
analysis. Future research should therefore incorporate longitudinal designs,
broader emotion lexicons, and platform-sensitive approaches to strengthen
robustness.

</details>


### [35] [IASC: Interactive Agentic System for ConLangs](https://arxiv.org/abs/2510.07591)
*Chihiro Taguchi,Richard Sproat*

Main category: cs.CL

TL;DR: 本论文提出了基于LLM的人工语言构建系统，可自动生成音系、词典、正字法和语法手册。结果显示系统适合产生常规语言结构，稀有语言则较难把握。高资源到低资源语言翻译尚待改进，且不同LLM性能差异明显，对语言学通识理解仍有探索空间。


<details>
  <summary>Details</summary>
Motivation: 一方面为语言爱好者提供有趣的人工语言创造工具，另一方面探索LLM对一般语言与语言学概念的理解及能力。

Method: 系统采用模块化流程：先由智能体式LLM生成目标语言的音系，并多轮自我批注优化；再将英语句子转化为目标语言的形态句法标记；随后根据音系和抽取的语素生成词典；再生成相应正字法；最后系统自动写作语法手册并支持后续翻译任务。

Result: 系统对常见语言类型处理更为顺畅，而稀有语言结构的生成较难。不同LLM和不同语言规范之间能力差异显著。此外，虽然目前将高资源语言转化为低资源语言效果不佳，但显示改进后仍有应用潜力。

Conclusion: 目前系统在将高资源语言翻译成低资源语言方面效果有限，但提供了改进的方向，未来有可能取得实质性突破。

Abstract: We present a system that uses LLMs as a tool in the development of
Constructed Languages. The system is modular in that one first creates a target
phonology for the language using an agentic approach that refines its output at
each step with commentary feedback on its previous attempt. Next, a set of
sentences is 'translated' from their English original into a morphosyntactic
markup that reflects the word order and morphosyntactic feature specifications
of the desired target language, with affixes represented as morphosyntactic
feature bundles. From this translated corpus, a lexicon is constructed using
the phonological model and the set of morphemes (stems and affixes) extracted
from the 'translated' sentences. The system is then instructed to provide an
orthography for the language, using an existing script such as Latin or
Cyrillic. Finally, the system writes a brief grammatical handbook of the
language. The system can also translate further sentences into the target
language.
  Our goal is twofold. First, we hope that these tools will be fun to use for
creating artificially constructed languages. Second, we are interested in
exploring what LLMs 'know' about language-not what they know about any
particular language or linguistic phenomenon, but how much they know about and
understand language and linguistic concepts. As we shall see, there is a fairly
wide gulf in capabilities both among different LLMs and among different
linguistic specifications, with it being notably easier for systems to deal
with more common patterns than rarer ones. An additional avenue that we explore
is the application of our approach to translating from high-resource into
low-resource languages. While the results so far are mostly negative, we
provide some evidence that an improved version of the present system could
afford some real gains in such tasks.
  https://github.com/SakanaAI/IASC

</details>


### [36] [Vocabulary embeddings organize linguistic structure early in language model training](https://arxiv.org/abs/2510.07613)
*Isabel Papadimitriou,Jacob Prince*

Main category: cs.CL

TL;DR: 论文探讨了LLMs输入嵌入结构在训练中的演化规律，发现高频词和功能词嵌入收敛更快，对模型语义和句法能力的建立有重要作用，为理解模型能力提升提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 该论文关注大型语言模型（LLMs）输入词嵌入的几何结构及其在训练过程中如何演化，试图揭示词表表示和语言结构的关系。动机在于理解嵌入的发展和优化过程，以促进模型能力的提升。

Method: 作者采用表示相似性分析，通过多种实验对比输入嵌入和输出嵌入的几何结构与语义、句法以及词频等指标的相关性，分别在Pythia 12B 和 OLMo 7B这两个开源模型的训练过程中进行跟踪分析。

Result: 实验发现：1）词表嵌入的几何结构在训练早期便迅速与语义和句法特征高度相关；2）高频词和功能词的嵌入向量收敛速度快于次常用词和低频词，后者部分保留了初始随机分布的偏置。这揭示了词频和功能词在嵌入演化中的不同作用。

Conclusion: 词表嵌入在语言结构周围动态组织和收敛，词频和词类别在嵌入演化中发挥了独特作用。词汇嵌入几何的演化过程值得进一步研究，它有助于分析模型训练中能力提升的机制。

Abstract: Large language models (LLMs) work by manipulating the geometry of input
embedding vectors over multiple layers. Here, we ask: how are the input
vocabulary representations of language models structured, and how and when does
this structure evolve over training? To answer this question, we use
representational similarity analysis, running a suite of experiments that
correlate the geometric structure of the input embeddings and output embeddings
of two open-source models (Pythia 12B and OLMo 7B) with semantic, syntactic,
and frequency-based metrics over the course of training. Our key findings are
as follows: 1) During training, the vocabulary embedding geometry quickly
converges to high correlations with a suite of semantic and syntactic features;
2) Embeddings of high-frequency and function words (e.g., "the," "of") converge
to their final vectors faster than lexical and low-frequency words, which
retain some alignment with the bias in their random initializations. These
findings help map the dynamic trajectory by which input embeddings organize
around linguistic structure, revealing distinct roles for word frequency and
function. Our findings motivate a deeper study of how the evolution of
vocabulary geometry may facilitate specific capability gains during model
training.

</details>


### [37] [Toward Reliable Clinical Coding with Language Models: Verification and Lightweight Adaptation](https://arxiv.org/abs/2510.07629)
*Zhangdie Yuan,Han-Chin Shing,Mitch Strong,Chaitanya Shivade*

Main category: cs.CL

TL;DR: 本文系统分析了LLM在医疗编码中的错误来源，并通过轻量级方法和编码验证流程显著提高了编码准确率，发布了高质量门诊编码数据集，为临床自动编码实践提供了重要支持。


<details>
  <summary>Details</summary>
Motivation: 临床编码在医疗文档、账单和决策中至关重要。目前的LLM（大语言模型）常因精确匹配指标评估而忽略了部分错误，尤其是预测代码与正确代码在编码体系上接近但不完全正确的情况，这成为LLM表现差的主要原因之一。

Method: 该研究分析LLM在编码任务中的错误分布，并提出轻量级的改进方法，包括提示工程和小规模微调。此外，首次提出了临床编码验证任务，将其作为独立任务与编码流程组件。为解决现有数据集的限制，还构建并发布了一套经过专家双重标注的门诊临床笔记与ICD-10编码基准数据。

Result: 轻量级的方法如提示工程和微调能显著提升编码准确率，而无需高计算资源。编码验证作为单独流程或管道步骤，有效减少编码错误和不准。新发布的数据集补足了原有数据集如MIMIC的不足。

Conclusion: 编码验证流程对于改善基于LLM的临床编码非常有效和可靠。研究为提升LLM在医疗编码实际应用中的准确性和效率提供了新思路与优质数据资源。

Abstract: Accurate clinical coding is essential for healthcare documentation, billing,
and decision-making. While prior work shows that off-the-shelf LLMs struggle
with this task, evaluations based on exact match metrics often overlook errors
where predicted codes are hierarchically close but incorrect. Our analysis
reveals that such hierarchical misalignments account for a substantial portion
of LLM failures. We show that lightweight interventions, including prompt
engineering and small-scale fine-tuning, can improve accuracy without the
computational overhead of search-based methods. To address hierarchically
near-miss errors, we introduce clinical code verification as both a standalone
task and a pipeline component. To mitigate the limitations in existing
datasets, such as incomplete evidence and inpatient bias in MIMIC, we release
an expert double-annotated benchmark of outpatient clinical notes with ICD-10
codes. Our results highlight verification as an effective and reliable step
toward improving LLM-based medical coding.

</details>


### [38] [Role-Conditioned Refusals: Evaluating Access Control Reasoning in Large Language Models](https://arxiv.org/abs/2510.07642)
*Đorđe Klisura,Joseph Khoury,Ashish Kundu,Ram Krishnan,Anthony Rios*

Main category: cs.CL

TL;DR: 针对LLM在访问控制中的角色边界问题，本文提出并评估了三种提升模型权限遵循能力的技术，并公开了相关数据集与代码。结果显示显式验证和微调各有优势，但政策复杂性依然影响系统可靠性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在生成响应时容易模糊不同角色的权限边界，导致无法有效遵守访问控制策略。研究动机在于提升语言模型对角色权限的敏感度，使其能根据授权情况做出合适的答复或拒绝。

Method: 构建了延展自Spider和BIRD的RBAC数据集，在表和列级别加入真实的PostgreSQL基于角色的权限策略。比较了三种方法：1）零/少样本提示；2）生成-验证两步管道，显式检查SQL与策略的匹配；3）LoRA微调模型直接学习权限感知能力。

Result: 显式验证的方法在提升拒绝行为的精度和降低错误许可方面表现较好。微调模型能更好地在安全性与实用性（执行准确性）之间取得平衡。复杂和冗长的策略会降低所有系统的可靠性。

Conclusion: 通过角色条件拒绝机制和多种方法的对比，发现权权限验证和专门微调均能提升模型对访问控制的遵循能力，但策略复杂度仍是可靠性的主要挑战。公开了增强RBAC的数据集和代码。

Abstract: Access control is a cornerstone of secure computing, yet large language
models often blur role boundaries by producing unrestricted responses. We study
role-conditioned refusals, focusing on the LLM's ability to adhere to access
control policies by answering when authorized and refusing when not. To
evaluate this behavior, we created a novel dataset that extends the Spider and
BIRD text-to-SQL datasets, both of which have been modified with realistic
PostgreSQL role-based policies at the table and column levels. We compare three
designs: (i) zero or few-shot prompting, (ii) a two-step generator-verifier
pipeline that checks SQL against policy, and (iii) LoRA fine-tuned models that
learn permission awareness directly. Across multiple model families, explicit
verification (the two-step framework) improves refusal precision and lowers
false permits. At the same time, fine-tuning achieves a stronger balance
between safety and utility (i.e., when considering execution accuracy). Longer
and more complex policies consistently reduce the reliability of all systems.
We release RBAC-augmented datasets and code.

</details>


### [39] [Banking Done Right: Redefining Retail Banking with Language-Centric AI](https://arxiv.org/abs/2510.07645)
*Xin Jie Chua,Jeraelyn Ming Li Tan,Jia Xuan Tan,Soon Chang Poh,Yi Xian Goh,Debbie Hui Tian Choong,Chee Mun Foong,Sze Jue Yang,Chee Seng Chan*

Main category: cs.CL

TL;DR: 本文提出了全球首个受监管批准的AI银行平台Ryt AI，用户可用自然语言完成银行主要操作。其创新点在于由多个LLM代理协同工作，安全合规机制完善，为未来银行界AI应用树立了新标杆。


<details>
  <summary>Details</summary>
Motivation: 现有银行AI助手仅限于咨询与支持，银行核心操作依然依赖繁琐的多屏幕流程，缺乏自然语言一站式处理能力。作者希望打造一个可获监管批准且用户友好、支持核心业务的AI对话平台。

Method: Ryt AI以内部闭源LLM（ILMU）为核心，通过四个专用任务代理（Guardrails、Intent、Payment、FAQ），结合LoRA适配器，为银行提供自然语言的事务处理能力，并配有人类确认和无状态审计体系以保证安全和合规。

Result: Ryt AI已在Ryt Bank落地，替代原有多屏流程，通过自然语言完成主要银行操作，且通过多层安全与合规设计，实现了可被全球监管机构认可的实际部署。

Conclusion: Ryt Bank通过Ryt AI，实现了全球首个被监管机构批准、以自然语言为主要接口的银行服务。即能确保安全合规，又简化用户操作体验。

Abstract: This paper presents Ryt AI, an LLM-native agentic framework that powers Ryt
Bank to enable customers to execute core financial transactions through natural
language conversation. This represents the first global regulator-approved
deployment worldwide where conversational AI functions as the primary banking
interface, in contrast to prior assistants that have been limited to advisory
or support roles. Built entirely in-house, Ryt AI is powered by ILMU, a
closed-source LLM developed internally, and replaces rigid multi-screen
workflows with a single dialogue orchestrated by four LLM-powered agents
(Guardrails, Intent, Payment, and FAQ). Each agent attaches a task-specific
LoRA adapter to ILMU, which is hosted within the bank's infrastructure to
ensure consistent behavior with minimal overhead. Deterministic guardrails,
human-in-the-loop confirmation, and a stateless audit architecture provide
defense-in-depth for security and compliance. The result is Banking Done Right:
demonstrating that regulator-approved natural-language interfaces can reliably
support core financial operations under strict governance.

</details>


### [40] [OBCache: Optimal Brain KV Cache Pruning for Efficient Long-Context LLM Inference](https://arxiv.org/abs/2510.07651)
*Yuzhe Gu,Xiyu Liang,Jiaojiao Zhao,Enmao Diao*

Main category: cs.CL

TL;DR: 针对长上下文带来的KV缓存开销，本文提出OBCache方法以精确评估token对注意力输出的影响，优化缓存驱逐策略，并在主流大模型上验证了该方法提升了长上下文推理的准确性。


<details>
  <summary>Details</summary>
Motivation: 扩展上下文窗口后，KV缓存带来高昂的内存消耗。现有驱逐方法多基于注意力稀疏性，但用累计注意力权重作为驱逐依据缺乏针对注意力输出的精确度。为此提出更为科学的驱逐标准以减小缓存压力同时保证模型性能。

Method: 提出了OBCache框架，把KV缓存驱逐问题形式化为关注各层的结构化剪枝问题，并基于Optimal Brain Damage理论推导出封闭形式的分数以衡量token的重要性。实际应用于主流LLMs（如LLaMA和Qwen）中进行实证对比，替换现有启发式得分机制后效果提升。

Result: OBCache分数不仅考虑注意力权重，还结合了value状态与最终输出信息，比现有驱逐机制更合理。实验证明，利用OBCache分数驱逐token能提升长上下文任务的准确率。

Conclusion: 将传统基于启发式方法的缓存驱逐策略替换为OBCache的输出敏感分数，可以持续提升大语言模型长上下文的准确率。

Abstract: Large language models (LLMs) with extended context windows enable powerful
downstream applications but impose significant memory overhead, as caching all
key-value (KV) states scales linearly with sequence length and batch size.
Existing cache eviction methods address this by exploiting attention sparsity,
yet they typically rank tokens heuristically using accumulated attention
weights without considering their true impact on attention outputs. We propose
Optimal Brain Cache (OBCache), a principled framework that formulates cache
eviction as a layer-wise structured pruning problem. Building upon the Optimal
Brain Damage (OBD) theory, OBCache quantifies token saliency by measuring the
perturbation in attention outputs induced by pruning tokens, with closed-form
scores derived for isolated keys, isolated values, and joint key-value pairs.
Our scores account not only for attention weights but also for information from
value states and attention outputs, thereby enhancing existing eviction
strategies with output-aware signals. Experiments on LLaMA and Qwen models
demonstrate that replacing the heuristic scores in existing works, which
estimate token saliency across different query positions, with OBCache's
output-aware scores consistently improves long-context accuracy.

</details>


### [41] [Textual Entailment and Token Probability as Bias Evaluation Metrics](https://arxiv.org/abs/2510.07662)
*Virginia K. Felkner,Allison Lim,Jonathan May*

Main category: cs.CL

TL;DR: 本研究考察自然语言推理（NLI）与传统token probability（TP）在语言模型偏见测量上的异同。结果发现两者相关性低，各自优缺点明显，建议多种指标联用以提升偏见评估全面性。


<details>
  <summary>Details</summary>
Motivation: 当前使用token probability（TP）指标衡量语言模型的社会偏见，虽普遍适用，但被质疑与真实使用场景和危害的距离。作者希望探索更贴近实际的偏见评估方式。

Method: 将自然语言推理（NLI）作为偏见评估的新指标，与传统TP指标对比。通过实验评估两种方法之间的相关性和表现，并分析其对去偏见效果的检测能力与敏感性。

Result: NLI和TP偏见评估行为差异显著，相互之间以及不同NLI指标间相关性很低。NLI更容易识别“未充分去偏”的情况，但对反刻板印象句子的表述更脆弱、更敏感。

Conclusion: TP和NLI各有优势，均不是“最优”偏见指标，建议联合TP、NLI以及下游任务偏见评测，实现语言模型偏见的全面评估。

Abstract: Measurement of social bias in language models is typically by token
probability (TP) metrics, which are broadly applicable but have been criticized
for their distance from real-world langugage model use cases and harms. In this
work, we test natural language inference (NLI) as a more realistic alternative
bias metric. We show that, curiously, NLI and TP bias evaluation behave
substantially differently, with very low correlation among different NLI
metrics and between NLI and TP metrics. We find that NLI metrics are more
likely to detect "underdebiased" cases. However, NLI metrics seem to be more
brittle and sensitive to wording of counterstereotypical sentences than TP
approaches. We conclude that neither token probability nor natural language
inference is a "better" bias metric in all cases, and we recommend a
combination of TP, NLI, and downstream bias evaluations to ensure comprehensive
evaluation of language models.
  Content Warning: This paper contains examples of anti-LGBTQ+ stereotypes.

</details>


### [42] [Stress-Testing Model Specs Reveals Character Differences among Language Models](https://arxiv.org/abs/2510.07686)
*Jifan Zhang,Henry Sleight,Andi Peng,John Schulman,Esin Durmus*

Main category: cs.CL

TL;DR: 本文提出了一种系统性方法，对大型语言模型行为规范进行压力测试，揭露了多个主流模型规范中的原则冲突与歧义，并提供了改进和优化模型规范的实证数据和分析。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLM）越来越多地依赖AI宪章和模型规范来指导行为，但这些规范存在内部冲突和覆盖面不足等关键挑战，因此需要系统的方法来检测和分析这些问题。

Method: 提出了一种系统的“压力测试”方法，自动生成涉及价值权衡的多样化情景，迫使模型在无法同时满足的原则之间做出选择。分析了十二个主流LLM在这些情境下的表现分歧，并通过价值分类得分定量测量。

Result: 发现了超过7万个显著行为分歧案例，这些分歧有效预示了当前模型规范中的根本问题。定性分析揭示了直接矛盾、原则解释不明确等典型规范问题。数据还展示了明显的不一致和误拒绝案例，并总结了不同模型间的价值优先级差异。

Conclusion: 当前LLM的行为规范存在大量未被发现的内在矛盾和解释歧义。通过系统性压力测试，不仅能揭示规范缺陷，还可以比较不同模型的价值倾向，为模型行为的改进和规范优化提供可靠依据。

Abstract: Large language models (LLMs) are increasingly trained from AI constitutions
and model specifications that establish behavioral guidelines and ethical
principles. However, these specifications face critical challenges, including
internal conflicts between principles and insufficient coverage of nuanced
scenarios. We present a systematic methodology for stress-testing model
character specifications, automatically identifying numerous cases of principle
contradictions and interpretive ambiguities in current model specs.
  We stress test current model specs by generating scenarios that force
explicit tradeoffs between competing value-based principles. Using a
comprehensive taxonomy we generate diverse value tradeoff scenarios where
models must choose between pairs of legitimate principles that cannot be
simultaneously satisfied. We evaluate responses from twelve frontier LLMs
across major providers (Anthropic, OpenAI, Google, xAI) and measure behavioral
disagreement through value classification scores. Among these scenarios, we
identify over 70,000 cases exhibiting significant behavioral divergence.
Empirically, we show this high divergence in model behavior strongly predicts
underlying problems in model specifications. Through qualitative analysis, we
provide numerous example issues in current model specs such as direct
contradiction and interpretive ambiguities of several principles. Additionally,
our generated dataset also reveals both clear misalignment cases and
false-positive refusals across all of the frontier models we study. Lastly, we
also provide value prioritization patterns and differences of these models.

</details>


### [43] [Large Language Models Meet Virtual Cell: A Survey](https://arxiv.org/abs/2510.07706)
*Krinos Li,Xianglu Xiao,Shenglong Deng,Lucas He,Zijun Zhong,Yuanjie Zou,Zhonghao Zhan,Zheng Hui,Weiye Bao,Guang Yang*

Main category: cs.CL

TL;DR: 本文综述了LLMs为虚拟细胞建模带来的变革，提出了新的分类体系，明确了核心任务，总结了应用现状及面临的主要挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）正在改变细胞生物学，推动“虚拟细胞”的建立，需要系统梳理LLMs在虚拟细胞建模中的应用与挑战。

Method: 对LLMs在虚拟细胞建模中的应用进行综述，提出统一的分类法，将方法分为LLMs作为预言机（直接建模）和LLMs作为智能体（组织复杂任务）两大范式，并总结三大核心任务及模型、数据集、评测基准等。

Result: 明确了LLMs在虚拟细胞建模的两种主要应用范式，并梳理了细胞表达、扰动预测、基因调控推断三大核心任务及相关挑战。

Conclusion: LLMs对虚拟细胞研究具有深远影响，但在扩展性、泛化性和可解释性等方面依然存在关键挑战。

Abstract: Large language models (LLMs) are transforming cellular biology by enabling
the development of "virtual cells"--computational systems that represent,
predict, and reason about cellular states and behaviors. This work provides a
comprehensive review of LLMs for virtual cell modeling. We propose a unified
taxonomy that organizes existing methods into two paradigms: LLMs as Oracles,
for direct cellular modeling, and LLMs as Agents, for orchestrating complex
scientific tasks. We identify three core tasks--cellular representation,
perturbation prediction, and gene regulation inference--and review their
associated models, datasets, evaluation benchmarks, as well as the critical
challenges in scalability, generalizability, and interpretability.

</details>


### [44] [Causality Guided Representation Learning for Cross-Style Hate Speech Detection](https://arxiv.org/abs/2510.07707)
*Chengshuai Zhao,Shu Wan,Paras Sheth,Karan Patwa,K. Selçuk Candan,Huan Liu*

Main category: cs.CL

TL;DR: 本文提出因果表示学习方法CADET，通过分解仇恨言论的因果因素与反事实推理，有效提升隐性及多风格仇恨言论的检测能力，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前线上仇恨言论层出不穷，显性仇恨容易被识别，但隐性仇恨（如讽刺、刻板印象、暗语等）难以检测。现有模型主要依赖表层语言特征，难以跨不同风格泛化。同时，不同平台仇恨言论针对不同群体、采用独特风格，可能导致标签与特征之间虚假相关，对现有检测方法造成挑战。

Method: 作者提出利用因果图建模仇恨言论的生成过程，分析关键信息如语境、创作者动机、对象与风格。在此基础上，设计了CADET框架，通过因果表示学习，将仇恨言论分解为可解释的潜在因素，并控制混杂变量，从而将真实的仇恨意图与表面语言特征隔离。CADET还能通过在潜在空间对风格进行干预，实现反事实推断，提升模型在不同形式下的鲁棒性。

Result: CADET在多项实验中表现优越，验证了利用因果先验实现更具泛化能力的仇恨言论检测的潜力。

Conclusion: 利用因果表示学习和反事实推理方法，可以有效提高仇恨言论检测的泛化性与准确性，尤其是对隐性仇恨的识别。

Abstract: The proliferation of online hate speech poses a significant threat to the
harmony of the web. While explicit hate is easily recognized through overt
slurs, implicit hate speech is often conveyed through sarcasm, irony,
stereotypes, or coded language -- making it harder to detect. Existing hate
speech detection models, which predominantly rely on surface-level linguistic
cues, fail to generalize effectively across diverse stylistic variations.
Moreover, hate speech spread on different platforms often targets distinct
groups and adopts unique styles, potentially inducing spurious correlations
between them and labels, further challenging current detection approaches.
Motivated by these observations, we hypothesize that the generation of hate
speech can be modeled as a causal graph involving key factors: contextual
environment, creator motivation, target, and style. Guided by this graph, we
propose CADET, a causal representation learning framework that disentangles
hate speech into interpretable latent factors and then controls confounders,
thereby isolating genuine hate intent from superficial linguistic cues.
Furthermore, CADET allows counterfactual reasoning by intervening on style
within the latent space, naturally guiding the model to robustly identify hate
speech in varying forms. CADET demonstrates superior performance in
comprehensive experiments, highlighting the potential of causal priors in
advancing generalizable hate speech detection.

</details>


### [45] [MemWeaver: A Hierarchical Memory from Textual Interactive Behaviors for Personalized Generation](https://arxiv.org/abs/2510.07713)
*Shuo Yu,Mingyue Cheng,Daoyu Wang,Qi Liu,Zirui Liu,Ze Guo,Xiaoyu Tao*

Main category: cs.CL

TL;DR: 本文提出MemWeaver框架，用分层记忆结构将用户历史行为建模为行为记忆和认知记忆，有效提升大模型个性化生成效果，并在公开基准测试中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 随着用户与互联网互动方式从隐式反馈（如浏览和点击）转向更丰富的文本交互，如何充分挖掘和利用用户的文本历史成为提升个性化服务的关键。然而，现有方法通常将用户历史简单视为文本列表，未能捕捉用户兴趣的时序动态和语义结构。

Method: 提出了MemWeaver框架，通过将用户文本历史编织为分层记忆，实现个性化生成。具体包含两大记忆组件：行为记忆（捕捉具体用户行为）和认知记忆（表示长期偏好），分别在不同抽象层级整合时序与语义信息，供大语言模型统一推理。

Result: 在Language Model Personalization (LaMP)基准测试上，MemWeaver展现了显著效果，优于传统仅以文本列表建模用户的方法。

Conclusion: MemWeaver能够更深入地建模用户兴趣的动态及语义关联，提升了大语言模型的个性化生成表现。

Abstract: The primary form of user-internet engagement is shifting from leveraging
implicit feedback signals, such as browsing and clicks, to harnessing the rich
explicit feedback provided by textual interactive behaviors. This shift unlocks
a rich source of user textual history, presenting a profound opportunity for a
deeper form of personalization. However, prevailing approaches offer only a
shallow form of personalization, as they treat user history as a flat list of
texts for retrieval and fail to model the rich temporal and semantic structures
reflecting dynamic nature of user interests. In this work, we propose
\textbf{MemWeaver}, a framework that weaves the user's entire textual history
into a hierarchical memory to power deeply personalized generation. The core
innovation of our memory lies in its ability to capture both the temporal
evolution of interests and the semantic relationships between different
activities. To achieve this, MemWeaver builds two complementary memory
components that both integrate temporal and semantic information, but at
different levels of abstraction: behavioral memory, which captures specific
user actions, and cognitive memory, which represents long-term preferences.
This dual-component memory serves as a unified representation of the user,
allowing large language models (LLMs) to reason over both concrete behaviors
and abstracted traits. Experiments on the Language Model Personalization (LaMP)
benchmark validate the efficacy of MemWeaver. Our code is
available\footnote{https://github.com/fishsure/MemWeaver}.

</details>


### [46] [SUBQRAG: sub-question driven dynamic graph rag](https://arxiv.org/abs/2510.07718)
*Jiaoyang Li,Junhao Ruan,Shengwei Tang,Saihan Chen,Kaiyan Chang,Yuan Ge,Tong Xiao,Jingbo Zhu*

Main category: cs.CL

TL;DR: SubQRAG通过问题拆解与实时知识图谱扩展，有效提升了多跳问答的推理能力和准确率，在多个任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的Graph RAG方法虽然能通过知识图谱连接大量文档间的离散事实，但在处理复杂多跳问答（multi-hop QA）任务时，缺乏深度结构化推理，容易导致证据不完整和错误积累。为克服这些局限性，需要提升推理的深度和准确性。

Method: 提出SubQRAG框架，它通过将复杂问题分解为可验证的子问题链，每个子问题检索相关图谱三元组；若现有图谱信息不足，系统实时从原始文档中扩展并抽取新的三元组；所有三元组形成“图谱记忆”，对答复过程提供结构化、可追溯的证据路径。

Result: 在三个多跳问答基准任务上验证，SubQRAG在准确匹配（Exact Match）分数上带来持续且显著提升。

Conclusion: 通过子问题驱动图谱扩展和可追溯证据构建，SubQRAG有效提升了复杂多跳问答的推理深度和答案准确性。

Abstract: Graph Retrieval-Augmented Generation (Graph RAG) effectively builds a
knowledge graph (KG) to connect disparate facts across a large document corpus.
However, this broad-view approach often lacks the deep structured reasoning
needed for complex multi-hop question answering (QA), leading to incomplete
evidence and error accumulation. To address these limitations, we propose
SubQRAG, a sub-question-driven framework that enhances reasoning depth. SubQRAG
decomposes a complex question into an ordered chain of verifiable
sub-questions. For each sub-question, it retrieves relevant triples from the
graph. When the existing graph is insufficient, the system dynamically expands
it by extracting new triples from source documents in real time. All triples
used in the reasoning process are aggregated into a "graph memory," forming a
structured and traceable evidence path for final answer generation. Experiments
on three multi-hop QA benchmarks demonstrate that SubQRAG achieves consistent
and significant improvements, especially in Exact Match scores.

</details>


### [47] [Multilingual Knowledge Graph Completion via Efficient Multilingual Knowledge Sharing](https://arxiv.org/abs/2510.07736)
*Cunli Mao,Xiaofei Gao,Ran Song,Shizhu He,Shengxiang Gao,Kang Liu,Zhengtao Yu*

Main category: cs.CL

TL;DR: 该文提出结合专家混合和迭代重排序的新型多语言知识图谱补全框架，在多语种数据集上大幅超越现有方法，并开放资源供后续研究使用。


<details>
  <summary>Details</summary>
Motivation: 目前多语言知识图谱补全(MKGC)任务利用大语言模型(LLMs)的多语言能力有限，且忽视了跨语言知识的共享性。现有方法未能充分挖掘LLMs在多语言场景下的潜力。

Method: 作者提出了一个新的MKGC框架，依托于Knowledge-level Grouped Mixture of Experts（KL-GMoE）和Iterative Entity Reranking（IER）两大模块。KL-GMoE用于高效建模并利用多语言间的共享知识，IER进一步增强知识利用效率。为评估方法效果，构建了包含5种语言的mKG数据集，并与当前最优SOTA MKGC方法进行了全面对比实验。

Result: 实验显示，所提出框架在Hits@1、Hits@3和Hits@10指标上分别较SOTA方法提升了5.47%、3.27%、1.01%。进一步分析还揭示了知识共享在未见及数据分布不均的语言场景下的表现。

Conclusion: 新提出的MKGC框架显著提升了多语言知识图谱的补全能力，通过共享及高效利用跨语言知识，有效优于现有方法。数据集和代码已公开。

Abstract: Large language models (LLMs) based Multilingual Knowledge Graph Completion
(MKGC) aim to predict missing facts by leveraging LLMs' multilingual
understanding capabilities, improving the completeness of multilingual
knowledge graphs (KGs). However, existing MKGC research underutilizes the
multilingual capabilities of LLMs and ignores the shareability of cross-lingual
knowledge. In this paper, we propose a novel MKGC framework that leverages
multilingual shared knowledge to significantly enhance performance through two
components: Knowledge-level Grouped Mixture of Experts (KL-GMoE) and Iterative
Entity Reranking (IER). KL-GMoE efficiently models shared knowledge, while IER
significantly enhances its utilization. To evaluate our framework, we
constructed a mKG dataset containing 5 languages and conducted comprehensive
comparative experiments with existing state-of-the-art (SOTA) MKGC method. The
experimental results demonstrate that our framework achieves improvements of
5.47%, 3.27%, and 1.01% in the Hits@1, Hits@3, and Hits@10 metrics,
respectively, compared with SOTA MKGC method. Further experimental analysis
revealed the properties of knowledge sharing in settings of unseen and
unbalanced languages. We have released the dataset and code for our work on
https://github.com/gaoxiaofei07/KL-GMoE.

</details>


### [48] [ToolExpander: Extending the Frontiers of Tool-Using Reinforcement Learning to Weak LLMs](https://arxiv.org/abs/2510.07737)
*Fu Chen,Peng Wang,Xiyin Li,Wen Li,Shichi Lei,Dongdong Xiang*

Main category: cs.CL

TL;DR: 提出ToolExpander框架，有效解决GRPO训练在小规模LLM上的不稳定与性能不足，通过困难样本替换和自示例增强，显著提升了工具使用能力和训练质量。


<details>
  <summary>Details</summary>
Motivation: 使用GRPO（Group Relative Policy Optimization）训练大型语言模型时，尤其是小规模架构下，模型往往无法生成准确的回复，容易在训练中期发生崩溃，影响性能和稳定性。

Method: 提出ToolExpander框架，包含两项核心创新：1）动态多轮困难样本硬采样机制，通过用高质量few-shot示例动态替换多次未能给出正确答案的样本，并采用指数学习率衰减，减缓训练震荡；2）自示例思考机制，在改进的GRPO中去除KL散度、调整截断系数，通过微小额外奖励鼓励模型自主生成和分析few-shot示例。

Result: 实验表明，ToolExpander显著提升了LLMs，尤其小规模模型在工具使用场景下的能力，带来了更高的训练稳定性和整体性能。

Conclusion: ToolExpander通过创新的训练方法有效解决了小模型在GRPO训练中的不稳定和性能问题，提升了工具型RL能力，对资源受限的LLM训练具有实际意义。

Abstract: Training Large Language Models (LLMs) with Group Relative Policy Optimization
(GRPO) encounters a significant challenge: models often fail to produce
accurate responses, particularly in small-scale architectures. This limitation
not only diminishes performance improvements and undermines the potential of
GRPO but also frequently leads to mid-training collapse, adversely affecting
stability and final efficacy. To address these issues, we propose ToolExpander,
a novel framework that advances tool-oriented reinforcement learning for
resource-constrained LLMs through two key innovations:(1) Dynamic Multi-Round
Hard Sampling, which dynamically substitutes challenging samples(those without
correct outputs over 10 rollouts) with high-quality few-shot demonstrations
during training, coupled with an exponential learning rate decay strategy to
mitigate oscillations;(2) Self-Exemplifying Thinking, an enhanced GRPO
framework that eliminates KL divergence and incorporates adjusted clipping
coefficients, encouraging models to autonomously generate and analyze few-shot
examples via a minimal additional reward (0.01).Experimental results
demonstrate that ToolExpander significantly enhances tool-using capabilities in
LLMs, especially in weaker small-scale models, improving both training
stability and overall performance.

</details>


### [49] [OpenRubrics: Towards Scalable Synthetic Rubric Generation for Reward Modeling and LLM Alignment](https://arxiv.org/abs/2510.07743)
*Tianci Liu,Ran Xu,Tony Yu,Ilgee Hong,Carl Yang,Tuo Zhao,Haoyu Wang*

Main category: cs.CL

TL;DR: 本论文提出结构化Rubrics与对比Rubrics生成法，构建大规模数据集OpenRubrics，并显著提升LLM奖励建模效果，为大模型对齐提供了更高效可靠的方案。


<details>
  <summary>Details</summary>
Motivation: 现有基于人类反馈的强化学习（RLHF）的奖励建模多依赖简单的标量或成对判断，难以反映人类偏好的多维复杂性，最近虽然探索了用结构化自然语言标准（Rubrics）建模，但Rubrics生成的可靠性和可扩展性仍是瓶颈。

Method: 提出了OpenRubrics——一个大规模、丰富的（prompt, rubric）数据集用于训练各种Rubrics生成及基于Rubrics的奖励模型；创新性地引入对比Rubrics生成法（Contrastive Rubric Generation, CRG），通过比较优劣响应，总结显性规则与隐性原则，并通过拒绝采样剔除噪音Rubrics保证标签一致性。

Result: Rubric-RM（基于Rubrics的奖励模型）在多个基准测试上相较同体量对手的性能提升6.8%；这种提升还可迁移至下游任务如指令跟随和生物医学问答。

Conclusion: 结构化Rubrics为奖励建模提供了可扩展且更为贴近真实人类偏好的对齐信号，有效弥补了昂贵人工评价与自动奖励建模的差距，推动了大模型对齐的新范式。

Abstract: Reward modeling lies at the core of reinforcement learning from human
feedback (RLHF), yet most existing reward models rely on scalar or pairwise
judgments that fail to capture the multifaceted nature of human preferences.
Recent studies have explored rubrics-as-rewards (RaR) that uses structured
natural language criteria that capture multiple dimensions of response quality.
However, producing rubrics that are both reliable and scalable remains a key
challenge. In this work, we introduce OpenRubrics, a diverse, large-scale
collection of (prompt, rubric) pairs for training rubric-generation and
rubric-based reward models. To elicit discriminative and comprehensive
evaluation signals, we introduce Contrastive Rubric Generation (CRG), which
derives both hard rules (explicit constraints) and principles (implicit
qualities) by contrasting preferred and rejected responses. We further improve
reliability by enforcing preference-label consistency via rejection sampling to
remove noisy rubrics. Across multiple reward-modeling benchmarks, our
rubric-based reward model, Rubric-RM, surpasses strong size-matched baselines
by 6.8%. These gains transfer to policy models on instruction-following and
biomedical benchmarks. Our results show that rubrics provide scalable alignment
signals that narrow the gap between costly human evaluation and automated
reward modeling, enabling a new principle-driven paradigm for LLM alignment.

</details>


### [50] [Parallel Test-Time Scaling for Latent Reasoning Models](https://arxiv.org/abs/2510.07745)
*Runyang You,Yongqi Li,Meng Liu,Wenjie Wang,Liqiang Nie,Wenjie Li*

Main category: cs.CL

TL;DR: 这项工作研究了如何在连续空间的潜在推理模型中实现并行测试时刻缩放。通过提出新的采样方法和奖励聚合机制，作者证明其能够高效提升模型推理性能，并为大模型的可扩展推理开拓了新方向。


<details>
  <summary>Details</summary>
Motivation: 链式思考（CoT）提升大模型性能常见于离散空间并借助并行采样与投票等方法，但在连续空间的潜在推理模型上并未充分利用并行TTS，主要因缺乏连续空间的采样机制及轨迹聚合的概率信号。

Method: 引入了两种不确定性驱动的随机采样方法（Monte Carlo Dropout和加性高斯噪声），并提出了Latent Reward Model（LatentRM），通过对每步进行对比学习以评分和引导潜在推理过程。

Result: 实验结果表明，两种采样策略在算力提升下均能充分扩展，探索动态明显不同，而LatentRM能有效选优轨迹，从而实现连续潜在空间中的高效推理。

Conclusion: 作者提出了可并行测试时刻缩放（TTS）的潜在推理模型，并通过新的采样和聚合策略实现了该方法在连续空间中的应用。实验表明，该方法不仅扩展性强，而且能有效提升推理质量。

Abstract: Parallel test-time scaling (TTS) is a pivotal approach for enhancing large
language models (LLMs), typically by sampling multiple token-based
chains-of-thought in parallel and aggregating outcomes through voting or
search. Recent advances in latent reasoning, where intermediate reasoning
unfolds in continuous vector spaces, offer a more efficient alternative to
explicit Chain-of-Thought, yet whether such latent models can similarly benefit
from parallel TTS remains open, mainly due to the absence of sampling
mechanisms in continuous space, and the lack of probabilistic signals for
advanced trajectory aggregation. \ This work enables parallel TTS for latent
reasoning models by addressing the above issues. For sampling, we introduce two
uncertainty-inspired stochastic strategies: Monte Carlo Dropout and Additive
Gaussian Noise. For aggregation, we design a Latent Reward Model (LatentRM)
trained with step-wise contrastive objective to score and guide latent
reasoning. Extensive experiments and visualization analyses show that both
sampling strategies scale effectively with compute and exhibit distinct
exploration dynamics, while LatentRM enables effective trajectory selection.
Together, our explorations open a new direction for scalable inference in
continuous spaces. Code released at https://github.com/YRYangang/LatentTTS.

</details>


### [51] [Test-Time Reasoners Are Strategic Multiple-Choice Test-Takers](https://arxiv.org/abs/2510.07761)
*Nishant Balepur,Atrey Desai,Rachel Rudinger*

Main category: cs.CL

TL;DR: LLMs在多项选择题仅仅依靠选项也能取得高分，传统认为这是模型行为异常。但本文发现，推理链条显示模型实际上能合理推断缺失信息，部分输入成功不全是问题。建议未来利用推理过程区分数据和模型质量。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）在多项选择题（MCQA）中表现出色，但其成功常常不依赖对问题本身的理解，仅通过选择项就能取得高分。此前相关研究认为这种仅用部分输入获得成功是值得担忧的。本文希望通过LLM生成的推理过程来探究，这种“choices-only”策略是否真的如传统观点那样浅显和有问题。

Method: 作者让LLMs在两个条件下完成多项选择题：一是完整输入（问题+选项），二是仅输入选择项（choices-only），并生成推理过程。通过比较两种输入下准确性及推理过程的变化，并对推理链条进行忠实性测试，以判断LLM是否采用了不健康的捷径或有更合理的策略。

Result: 测试发现，在choices-only设置下，LLM生成推理链条后准确率提升显著，有一半情况接近完整输入。推理链条的长度对结果影响很小。经过忠实性测试，多数推理显示LLMs会尝试推断缺失问题而非单纯套用捷径，因此“choices-only”策略并不总是浅显或有害。

Conclusion: 本文挑战了部分输入导致模型表现异常的传统见解，证明合理的推理轨迹可帮助区分真正的问题数据与不那么有害的部分输入推理。作者建议未来可以利用推理链条来更细致地区分数据和模型的问题。

Abstract: Large language models (LLMs) now give reasoning before answering, excelling
in tasks like multiple-choice question answering (MCQA). Yet, a concern is that
LLMs do not solve MCQs as intended, as work finds LLMs sans reasoning succeed
in MCQA without using the question, i.e., choices-only. Such partial-input
success is often deemed problematic, but reasoning traces could reveal if these
strategies are truly shallow in choices-only settings. To study these
strategies, reasoning LLMs solve MCQs in full and choices-only inputs;
test-time reasoning often boosts accuracy on full and in choices-only half the
time. While possibly due to shallow shortcuts, choices-only success is barely
affected by the length of reasoning traces, and after finding traces pass
faithfulness tests, we show they use less problematic strategies like inferring
missing questions. In all, we challenge claims that partial-input success is
always a flaw, so we discuss how reasoning traces could separate problematic
data from less problematic reasoning.

</details>


### [52] [ToolLibGen: Scalable Automatic Tool Creation and Aggregation for LLM Reasoning](https://arxiv.org/abs/2510.07768)
*Murong Yue,Zhiwei Liu,Liangwei Yang,Jianguo Zhang,Zuxin Liu,Haolin Chen,Ziyu Yao,Silvio Savarese,Caiming Xiong,Shelby Heinecke,Huan Wang*

Main category: cs.CL

TL;DR: 本文提出将无序工具自动重构为结构化工具库的方法，通过智能体聚合和聚类优化工具，显著提升检索与推理性能，并增强扩展性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型通过接入外部工具在复杂推理任务上表现优异，但缺乏领域特定工具阻碍了广泛推广。尤其在物理问答等领域，专用工具稀缺，自动化工具创建虽有尝试，却存在规模扩展瓶颈。

Method: 本文提出一种系统性方法，将杂乱无序的工具集合自动重构为结构化工具库。方法包括：先生成离散、任务特定的工具并根据语义聚类，再在每个簇内采用多智能体框架，由代码代理整合、重构代码抽取共通逻辑，生成更通用工具；评审代理确保聚合工具保留原有全部功能。

Result: 实验显示，该方法在多个推理任务中显著提升了工具检索准确率和整体推理表现。同时，随着特定问题工具数量增长，其可扩展性优于现有方法。

Conclusion: 通过自动结构化工具库，本文显著提升了大语言模型工具增强推理的效能和可扩展性，为构建领域专用智能体提供了新范式。

Abstract: Large Language Models (LLMs) equipped with external tools have demonstrated
enhanced performance on complex reasoning tasks. The widespread adoption of
this tool-augmented reasoning is hindered by the scarcity of domain-specific
tools. For instance, in domains such as physics question answering, suitable
and specialized tools are often missing. Recent work has explored automating
tool creation by extracting reusable functions from Chain-of-Thought (CoT)
reasoning traces; however, these approaches face a critical scalability
bottleneck. As the number of generated tools grows, storing them in an
unstructured collection leads to significant retrieval challenges, including an
expanding search space and ambiguity between function-related tools. To address
this, we propose a systematic approach to automatically refactor an
unstructured collection of tools into a structured tool library. Our system
first generates discrete, task-specific tools and clusters them into
semantically coherent topics. Within each cluster, we introduce a multi-agent
framework to consolidate scattered functionalities: a code agent refactors code
to extract shared logic and creates versatile, aggregated tools, while a
reviewing agent ensures that these aggregated tools maintain the complete
functional capabilities of the original set. This process transforms numerous
question-specific tools into a smaller set of powerful, aggregated tools
without loss of functionality. Experimental results demonstrate that our
approach significantly improves tool retrieval accuracy and overall reasoning
performance across multiple reasoning tasks. Furthermore, our method shows
enhanced scalability compared with baselines as the number of question-specific
increases.

</details>


### [53] [Curing Miracle Steps in LLM Mathematical Reasoning with Rubric Rewards](https://arxiv.org/abs/2510.07774)
*Youliang Yuan,Qiuyang Mang,Jingbang Chen,Hong Wan,Xiaoyuan Liu,Junjielong Xu,Jen-tse Huang,Wenxuan Wang,Wenxiang Jiao,Pinjia He*

Main category: cs.CL

TL;DR: 论文揭示了传统仅奖励答案的训练方式易导致模型推理能力被高估，特别是出现“奇迹步”等不合理推理。作者提出基于过程的Rubric Reward Model，有效惩罚推理漏洞并显著提高各数学任务的性能与可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在数学推理训练中主要采用基于结果的奖励机制，仅关注最终答案，这容易导致奖励被“黑客”利用，从而高估模型的推理能力。具体表现为模型通过不合理的推理过程也能得到正确答案，出现大量假阳性结果。

Method: 通过系统的人类验证分析，对这些失败模式（如“奇迹步”——模型突然跳到正确答案但推理过程不合理）进行了分类和归因；同时设计了Rubric Reward Model（RRM），一种过程导向的奖励函数，依据问题特定评分标准评估整个推理轨迹。RRM可生成细粒度、校准的奖励，显式惩罚逻辑错误，鼓励严密推理，并集成于强化学习训练流程中。

Result: RRM训练显著优于仅基于结果的监督训练。在AIME2024数据集的Verified Pass@1024指标上从26.7%提升到62.6%；奇迹步发生率下降71%。在四个数学基准测试上均有一致提升。

Conclusion: 奖励推理过程而不仅仅是最终答案，对于培养更精确、可靠的数学推理模型至关重要。

Abstract: Large language models for mathematical reasoning are typically trained with
outcome-based rewards, which credit only the final answer. In our experiments,
we observe that this paradigm is highly susceptible to reward hacking, leading
to a substantial overestimation of a model's reasoning ability. This is
evidenced by a high incidence of false positives - solutions that reach the
correct final answer through an unsound reasoning process. Through a systematic
analysis with human verification, we establish a taxonomy of these failure
modes, identifying patterns like Miracle Steps - abrupt jumps to a correct
output without a valid preceding derivation. Probing experiments suggest a
strong association between these Miracle Steps and memorization, where the
model appears to recall the answer directly rather than deriving it. To
mitigate this systemic issue, we introduce the Rubric Reward Model (RRM), a
process-oriented reward function that evaluates the entire reasoning trajectory
against problem-specific rubrics. The generative RRM provides fine-grained,
calibrated rewards (0-1) that explicitly penalize logical flaws and encourage
rigorous deduction. When integrated into a reinforcement learning pipeline,
RRM-based training consistently outperforms outcome-only supervision across
four math benchmarks. Notably, it boosts Verified Pass@1024 on AIME2024 from
26.7% to 62.6% and reduces the incidence of Miracle Steps by 71%. Our work
demonstrates that rewarding the solution process is crucial for building models
that are not only more accurate but also more reliable.

</details>


### [54] [The Unintended Trade-off of AI Alignment:Balancing Hallucination Mitigation and Safety in LLMs](https://arxiv.org/abs/2510.07775)
*Omar Mahmoud,Ali Khalil,Buddhika Laknath Semage,Thommen George Karimpanal,Santu Rana*

Main category: cs.CL

TL;DR: 提升LLMs真实度会影响安全性，常用方法在去除幻觉时易连带减少拒绝行为。文中提出用稀疏自动编码器及子空间正交化分离特征，实验证明能同时保持事实准确性和拒绝能力，缓解真实与安全性权衡。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）中幻觉问题已被广泛研究，提升真实准确性一直是研究重点。然而，提升真实度可能会削弱模型的安全拒绝能力，这一副作用过去被忽视。本文关注在提升事实准确性和保持安全拒绝之间的矛盾。

Method: 通过分析模型内部负责幻觉和拒绝行为的组件重叠，发现常用的对齐方法可能误伤事实知识；提出用稀疏自动编码器分离幻觉与拒绝相关特征，并通过子空间正交化在微调时保留拒绝能力。

Result: 在常识推理任务和应对有害内容的基准（AdvBench和StrongReject）上的评测显示，新方法能在不增加幻觉的前提下，显著保持模型拒绝有害内容的能力和整体任务效用，有效缓解真实度与安全性之间的权衡。

Conclusion: 提升语言模型的真实度确实可能危及其安全对齐，但通过分离幻觉与拒绝相关特征，可同时实现准确性和安全性。本文方法能在保障拒绝行为的同时减少幻觉现象，为安全高效的模型调优提供新思路。

Abstract: Hallucination in large language models (LLMs) has been widely studied in
recent years, with progress in both detection and mitigation aimed at improving
truthfulness. Yet, a critical side effect remains largely overlooked: enhancing
truthfulness can negatively impact safety alignment. In this paper, we
investigate this trade-off and show that increasing factual accuracy often
comes at the cost of weakened refusal behavior. Our analysis reveals that this
arises from overlapping components in the model that simultaneously encode
hallucination and refusal information, leading alignment methods to suppress
factual knowledge unintentionally. We further examine how fine-tuning on benign
datasets, even when curated for safety, can degrade alignment for the same
reason. To address this, we propose a method that disentangles refusal-related
features from hallucination features using sparse autoencoders, and preserves
refusal behavior during fine-tuning through subspace orthogonalization. This
approach prevents hallucinations from increasing while maintaining safety
alignment.We evaluate our method on commonsense reasoning tasks and harmful
benchmarks (AdvBench and StrongReject). Results demonstrate that our approach
preserves refusal behavior and task utility, mitigating the trade-off between
truthfulness and safety.

</details>


### [55] [Instance Relation Learning Network with Label Knowledge Propagation for Few-shot Multi-label Intent Detection](https://arxiv.org/abs/2510.07776)
*Shiman Zhao,Shangyuan Li,Wei Chen,Tengjiao Wang,Jiahui Yao,Jiabin Zheng,Kam Fai Wong*

Main category: cs.CL

TL;DR: 论文提出了一种端到端的多标签联合学习方法，利用实例间关系和标签知识传播优化少样本多标签意图检测任务，显著优于现有方法，效果提升明显。


<details>
  <summary>Details</summary>
Motivation: 现有少样本多标签意图检测方法主要采用两阶段流程，依赖表征分类且忽略实例间关系，导致错误传播。基于此，本文旨在通过实例关系建模和知识传播消除错误传播，提高模型性能。

Method: 提出了一种端到端的多标签联合学习方法，构建了实例关系学习网络并实现标签知识传播，通过实例间的关系强度直接用于多标签预测，同时设计了双重关系增强损失函数以优化关系强度。

Result: 该方法能在支持集和查询集之间传播标签知识，实例之间的关系强度可直接用于表明多标签预测的准确性。实验数据在1-shot条件下显示优异表现。

Conclusion: 实验表明，该方法在1-shot场景下比强基线方法平均提升了9.54%的AUC和11.19%的Macro-F1，显著提升了少样本多标签意图检测性能。

Abstract: Few-shot Multi-label Intent Detection (MID) is crucial for dialogue systems,
aiming to detect multiple intents of utterances in low-resource dialogue
domains. Previous studies focus on a two-stage pipeline. They first learn
representations of utterances with multiple labels and then use a
threshold-based strategy to identify multi-label results. However, these
methods rely on representation classification and ignore instance relations,
leading to error propagation. To solve the above issues, we propose a
multi-label joint learning method for few-shot MID in an end-to-end manner,
which constructs an instance relation learning network with label knowledge
propagation to eliminate error propagation. Concretely, we learn the
interaction relations between instances with class information to propagate
label knowledge between a few labeled (support set) and unlabeled (query set)
instances. With label knowledge propagation, the relation strength between
instances directly indicates whether two utterances belong to the same intent
for multi-label prediction. Besides, a dual relation-enhanced loss is developed
to optimize support- and query-level relation strength to improve performance.
Experiments show that we outperform strong baselines by an average of 9.54% AUC
and 11.19% Macro-F1 in 1-shot scenarios.

</details>


### [56] [Drift No More? Context Equilibria in Multi-Turn LLM Interactions](https://arxiv.org/abs/2510.07777)
*Vardhan Dongre,Ryan A. Rossi,Viet Dac Lai,David Seunghyun Yoon,Dilek Hakkani-Tür,Trung Bui*

Main category: cs.CL

TL;DR: 本文分析了LLM在多轮互动中的上下文漂移问题，提出了将漂移视为可控均衡过程的动力学框架，并通过实验验证，发现漂移可被有效管理和干预。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在单轮任务中表现优异，但现实部署场景要求模型能够进行多轮持续互动，其用户目标和对话上下文会不断演化。在多轮互动过程中，常见问题为“上下文漂移”，即模型输出逐渐偏离与用户目标一致的行为。以往评估指标无法很好捕捉此类动态变化，亟需新的分析方法。

Method: 该研究定义了上下文漂移为测试模型与理想参考模型在每一轮上的令牌级预测分布之间的KL散度，并提出了一个递归模型，将漂移解释为有界的随机过程，其中包含恢复力和可控干预。研究通过在合成的长期文本改写任务和真实用户-代理仿真（如τ-Bench）中实例化该框架，实验测量了多种开源LLM的漂移情况。

Result: 实验发现模型漂移趋于稳定的、受噪声限制的均衡状态，而不是持续恶化。引入简单的提醒干预可显著减少分歧，且符合理论预期。

Conclusion: 多轮互动中的上下文漂移是可控的均衡现象，而非不可避免的退化，为进一步研究和缓解长时间互动中的漂移问题提供了理论基础。

Abstract: Large Language Models (LLMs) excel at single-turn tasks such as instruction
following and summarization, yet real-world deployments require sustained
multi-turn interactions where user goals and conversational context persist and
evolve. A recurring challenge in this setting is context drift: the gradual
divergence of a model's outputs from goal-consistent behavior across turns.
Unlike single-turn errors, drift unfolds temporally and is poorly captured by
static evaluation metrics. In this work, we present a study of context drift in
multi-turn interactions and propose a simple dynamical framework to interpret
its behavior. We formalize drift as the turn-wise KL divergence between the
token-level predictive distributions of the test model and a goal-consistent
reference model, and propose a recurrence model that interprets its evolution
as a bounded stochastic process with restoring forces and controllable
interventions. We instantiate this framework in both synthetic long-horizon
rewriting tasks and realistic user-agent simulations such as in $\tau$-Bench,
measuring drift for several open-weight LLMs that are used as user simulators.
Our experiments consistently reveal stable, noise-limited equilibria rather
than runaway degradation, and demonstrate that simple reminder interventions
reliably reduce divergence in line with theoretical predictions. Together,
these results suggest that multi-turn drift can be understood as a controllable
equilibrium phenomenon rather than as inevitable decay, providing a foundation
for studying and mitigating context drift in extended interactions.

</details>


### [57] [RCPU: Rotation-Constrained Error Compensation for Structured Pruning of a Large Language Model](https://arxiv.org/abs/2510.07782)
*Shuichiro Haruta,Kazunori Matsumoto,Zhi Li,Yanan Wang,Mori Kurokawa*

Main category: cs.CL

TL;DR: 本文通过旋转约束补偿和方差感知剪枝方法，有效降低了大语言模型剪枝后的误差，并取得比现有方法更好的任务表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）由于参数量大，实际应用中常需要通过结构化剪枝（pruning）进行模型压缩，但剪枝往往依赖有限的校准数据，导致输出不可避免地产生误差，影响预训练模型的语义表达能力。当前简单的误差补偿手段容易过拟合并损坏权重结构。

Method: 提出了一种旋转约束补偿方法，在剪枝时要求参数的更新满足旋转约束，从而保持输出表示的几何结构（如范数和内积），同时将剪枝后的子空间重新对齐到原输出。此外，引入方差感知的重要性评分，优先保留在主方向上贡献大的输入维度，以便更好地恢复误差。

Result: 在LLaMA-7B上测试，并在WikiText-2和多个语言理解任务上评估，结果显示相比现有基线方法，本文方法在困惑度和任务准确率方面表现更优。

Conclusion: 通过结合旋转约束的补偿策略和方差感知剪枝规则，可以有效减小结构化剪枝后大语言模型的输出误差，同时保持语义信息和表示空间结构。

Abstract: In this paper, we propose a rotation-constrained compensation method to
address the errors introduced by structured pruning of large language models
(LLMs). LLMs are trained on massive datasets and accumulate rich semantic
knowledge in their representation space. In contrast, pruning is typically
carried out with only a small amount of calibration data, which makes output
mismatches unavoidable. Although direct least-squares fitting can reduce such
errors, it tends to overfit to the limited calibration set, destructively
modifying pretrained weights. To overcome this difficulty, we update the pruned
parameters under a rotation constraint. This constrained update preserves the
geometry of output representations (i.e., norms and inner products) and
simultaneously re-aligns the pruned subspace with the original outputs.
Furthermore, in rotation-constrained compensation, removing components that
strongly contribute to the principal directions of the output makes error
recovery difficult. Since input dimensions with large variance strongly affect
these principal directions, we design a variance-aware importance score that
ensures such dimensions are preferentially kept in the pruned model. By
combining this scoring rule with rotation-constrained updates, the proposed
method effectively compensates errors while retaining the components likely to
be more important in a geometry-preserving manner. In the experiments, we apply
the proposed method to LLaMA-7B and evaluate it on WikiText-2 and multiple
language understanding benchmarks. The results demonstrate consistently better
perplexity and task accuracy compared with existing baselines.

</details>


### [58] [LLM4Cell: A Survey of Large Language and Agentic Models for Single-Cell Biology](https://arxiv.org/abs/2510.07793)
*Sajib Acharjee Dip,Adrika Zafor,Bikash Kumar Paul,Uddip Acharjee Shuvo,Muhit Islam Emon,Xuan Wang,Liqing Zhang*

Main category: cs.CL

TL;DR: 本文系统综述了58种用于单细胞研究的大模型，涵盖多种数据模态和分析任务，并建立多维评估体系，指出当前面临的标准化与可信性等挑战，为进一步提升领域模型的智能与实用性提供了方向。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）和代理架构正在促进单细胞生物学研究的变革，但在数据模态、模型架构及评估标准等方面的发展仍较为分散。缺少一个全面的综述对这些方法进行系统梳理与比较。

Method: 本文对单细胞研究领域的58个基础及代理模型（包括RNA、ATAC、多组学和空间模态）进行了系统梳理与分类。方法被划分为基础模型、文本桥接、空间、多模态、表观基因组及代理式六大类，并覆盖了注释、轨迹推断、扰动建模、药物反应预测等八大任务。作者还基于40余个公开数据集，分析了基准适用性、数据多样性、伦理及可扩展性等限制，并在10个领域维度上对模型进行了评估。

Result: 本文首次将数据集、模型和评估领域联结起来，全面展现了基于语言模型的单细胞智能现状，指出了解释性、标准化以及可信赖模型开发等方面的开放挑战。

Conclusion: LLM4Cell为单细胞生物学领域语言模型相关工作的文献和模型提供了首个系统性整合和多维评估，对未来模型的解释性与标准化发展具有指导意义。

Abstract: Large language models (LLMs) and emerging agentic frameworks are beginning to
transform single-cell biology by enabling natural-language reasoning,
generative annotation, and multimodal data integration. However, progress
remains fragmented across data modalities, architectures, and evaluation
standards. LLM4Cell presents the first unified survey of 58 foundation and
agentic models developed for single-cell research, spanning RNA, ATAC,
multi-omic, and spatial modalities. We categorize these methods into five
families-foundation, text-bridge, spatial, multimodal, epigenomic, and
agentic-and map them to eight key analytical tasks including annotation,
trajectory and perturbation modeling, and drug-response prediction. Drawing on
over 40 public datasets, we analyze benchmark suitability, data diversity, and
ethical or scalability constraints, and evaluate models across 10 domain
dimensions covering biological grounding, multi-omics alignment, fairness,
privacy, and explainability. By linking datasets, models, and evaluation
domains, LLM4Cell provides the first integrated view of language-driven
single-cell intelligence and outlines open challenges in interpretability,
standardization, and trustworthy model development.

</details>


### [59] [HiPRAG: Hierarchical Process Rewards for Efficient Agentic Retrieval Augmented Generation](https://arxiv.org/abs/2510.07794)
*Peilin Wu,Mian Zhang,Kun Wan,Wentian Zhao,Kaiyu He,Xinya Du,Zhiyu Chen*

Main category: cs.CL

TL;DR: 本工作提出HiPRAG方法，以细粒度奖励机制优化RAG智能体的搜索过程，显著提升QA准确率和检索效率，在多模型和多任务场景下展现了良好的泛化性和潜力。


<details>
  <summary>Details</summary>
Motivation: 当前基于代理的RAG方法在信息检索过程中普遍存在效率低下的问题，如过度搜索（检索已知信息）和不足搜索（未及时检索必要信息），导致资源浪费和结果不可靠。现有的训练方法以结果导向的奖励体系为主，难以对搜索过程进行细粒度优化。

Method: 提出了一种层次化过程奖励训练方法（HiPRAG），在RL框架中融入知识驱动的细粒度过程奖励。该方法通过解析推理轨迹，将智能体的推理过程分解为离散步骤，针对每一步是否需要搜索进行动态评估，利用层次化奖励函数对最优搜索与非搜索步骤比例给予额外奖励。

Result: 在Qwen2.5和Llama-3.2模型（3B和7B参数量）上进行了七个多样化QA基准测试，平均准确率分别达到65.4%和67.2%。显著提升了搜索效率，将过度搜索率降至2.3%，同时减少了不足搜索现象。进一步实验表明该方法对不同RL算法、模型家族、规模与类型具备较好的泛化能力。

Conclusion: 优化搜索智能体推理过程本身（而非仅最终结果）能显著提升推理效率和准确性。通过细粒度的RL奖励机制，对搜索决策进行过程化控制是提升RAG系统性能的有效手段。

Abstract: Agentic RAG is a powerful technique for incorporating external information
that LLMs lack, enabling better problem solving and question answering.
However, suboptimal search behaviors exist widely, such as over-search
(retrieving information already known) and under-search (failing to search when
necessary), which leads to unnecessary overhead and unreliable outputs. Current
training methods, which typically rely on outcome-based rewards in a RL
framework, lack the fine-grained control needed to address these
inefficiencies. To overcome this, we introduce Hierarchical Process Rewards for
Efficient agentic RAG (HiPRAG), a training methodology that incorporates a
fine-grained, knowledge-grounded process reward into the RL training. Our
approach evaluates the necessity of each search decision on-the-fly by
decomposing the agent's reasoning trajectory into discrete, parsable steps. We
then apply a hierarchical reward function that provides an additional bonus
based on the proportion of optimal search and non-search steps, on top of
commonly used outcome and format rewards. Experiments on the Qwen2.5 and
Llama-3.2 models across seven diverse QA benchmarks show that our method
achieves average accuracies of 65.4% (3B) and 67.2% (7B). This is accomplished
while improving search efficiency, reducing the over-search rate to just 2.3%
and concurrently lowering the under-search rate. These results demonstrate the
efficacy of optimizing the reasoning process itself, not just the final
outcome. Further experiments and analysis demonstrate that HiPRAG shows good
generalizability across a wide range of RL algorithms, model families, sizes,
and types. This work demonstrates the importance and potential of fine-grained
control through RL, for improving the efficiency and optimality of reasoning
for search agents.

</details>


### [60] [Dynamic Generation of Multi-LLM Agents Communication Topologies with Graph Diffusion Models](https://arxiv.org/abs/2510.07799)
*Eric Hanchen Jiang,Guancheng Wan,Sophia Yin,Mengting Li,Yuchen Wu,Xiao Liang,Xinfeng Li,Yizhou Sun,Wei Wang,Kai-Wei Chang,Ying Nian Wu*

Main category: cs.CL

TL;DR: 本文提出了一种名为GTD的新型生成式框架，根据任务需求动态生成高效、多目标优化的通信拓扑结构，实验显示比现有方法有显著提升。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统（MAS）借助大语言模型（LLM）实现高效协作，但通信拓扑结构极大影响其效率。合理设计通信拓扑需在任务性能、通信成本和鲁棒性之间权衡，但现有方法多用静态或人工设计结构，难以适应不同任务需求，可能导致资源浪费或性能瓶颈。

Method: 提出了一种新的生成式框架——Guided Topology Diffusion（GTD），受条件离散图扩散模型启发。GTD将拓扑的生成视为逐步构建过程，每一步都由轻量级代理模型根据多目标奖励（如准确性、效用、成本）进行引导，实现实时、无梯度的任务自适应优化。该方法区别于单步生成框架，能更好地处理复杂设计权衡。

Result: 在多项基准测试上的实验证明，GTD能生成高任务自适应性、稀疏且高效的通信拓扑结构，在LLM智能体协作中显著优于现有方法。

Conclusion: GTD是一种能够根据任务需求动态生成最优通信拓扑的生成式框架，实现了效率与灵活性的提升，有效解决了静态拓扑结构的适应性问题，推动了LLM多智能体系统的性能发展。

Abstract: The efficiency of multi-agent systems driven by large language models (LLMs)
largely hinges on their communication topology. However, designing an optimal
topology is a non-trivial challenge, as it requires balancing competing
objectives such as task performance, communication cost, and robustness.
Existing frameworks often rely on static or hand-crafted topologies, which
inherently fail to adapt to diverse task requirements, leading to either
excessive token consumption for simple problems or performance bottlenecks for
complex ones. To address this challenge, we introduce a novel generative
framework called \textit{Guided Topology Diffusion (GTD)}. Inspired by
conditional discrete graph diffusion models, GTD formulates topology synthesis
as an iterative construction process. At each step, the generation is steered
by a lightweight proxy model that predicts multi-objective rewards (e.g.,
accuracy, utility, cost), enabling real-time, gradient-free optimization
towards task-adaptive topologies. This iterative, guided synthesis process
distinguishes GTD from single-step generative frameworks, enabling it to better
navigate complex design trade-offs. We validated GTD across multiple
benchmarks, and experiments show that this framework can generate highly
task-adaptive, sparse, and efficient communication topologies, significantly
outperforming existing methods in LLM agent collaboration.

</details>


### [61] [Multilingual Generative Retrieval via Cross-lingual Semantic Compression](https://arxiv.org/abs/2510.07812)
*Yuxin Huang,Simeng Wu,Ran Song,Yan Xiang,Yantuan Xian,Shengxiang Gao,Zhengtao Yu*

Main category: cs.CL

TL;DR: 本文提出MGR-CSC框架，通过语义对齐和标识符压缩，有效提升了多语种生成式检索准确性并大幅减少冗余，方法简单高效，实验效果显著。


<details>
  <summary>Details</summary>
Motivation: 生成式信息检索在单语场景下表现优异，但在多语种检索中面临跨语种标识符错位和标识符膨胀两大挑战。

Method: 提出一种新框架MGR-CSC（通过跨语义压缩的多语种生成式检索），将语义等价的多语种关键词统一为共享原子以对齐语义并压缩标识符空间，并提出动态多步约束解码策略。

Result: MGR-CSC在mMarco100k提升6.83%，在mNQ320k提升4.77%，同时分别缩短74.51%和78.2%的文档标识符长度。

Conclusion: MGR-CSC显著提升了多语种生成式检索的准确率和标识符效率，在跨语种对齐和重复信息压缩方面效果突出。

Abstract: Generative Information Retrieval is an emerging retrieval paradigm that
exhibits remarkable performance in monolingual scenarios.However, applying
these methods to multilingual retrieval still encounters two primary
challenges, cross-lingual identifier misalignment and identifier inflation. To
address these limitations, we propose Multilingual Generative Retrieval via
Cross-lingual Semantic Compression (MGR-CSC), a novel framework that unifies
semantically equivalent multilingual keywords into shared atoms to align
semantics and compresses the identifier space, and we propose a dynamic
multi-step constrained decoding strategy during retrieval. MGR-CSC improves
cross-lingual alignment by assigning consistent identifiers and enhances
decoding efficiency by reducing redundancy. Experiments demonstrate that
MGR-CSC achieves outstanding retrieval accuracy, improving by 6.83% on
mMarco100k and 4.77% on mNQ320k, while reducing document identifiers length by
74.51% and 78.2%, respectively.

</details>


### [62] [AdaSwitch: Adaptive Switching Generation for Knowledge Distillation](https://arxiv.org/abs/2510.07842)
*Jingyu Peng,Maolin Wang,Hengyi Cai,Yuchen Li,Kai Zhang,Shuaiqiang Wang,Dawei Yin,Xiangyu Zhao*

Main category: cs.CL

TL;DR: AdaSwitch通过动态结合两种蒸馏策略，有效提升小型语言模型性能，实验验证其效果好且开销不大。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型（SLMs）适用于对延迟和算力有严格要求的场景，但其高性能实现仍具挑战性。现有知识蒸馏方法在监督质量和推理一致性之间存在权衡。

Method: 提出AdaSwitch方法，在token级动态结合on-policy和off-policy生成，依靠实时质量评估让学生模型在自我预测和教师指导之间灵活切换。

Result: 在三个数据集和两组教师-学生LLM实验中，AdaSwitch持续提升了SLM的准确率，且附加开销可接受。

Conclusion: AdaSwitch是一种有效实用的方法，可以高质量蒸馏小型语言模型，同时保持训练推理一致性和监督质量。

Abstract: Small language models (SLMs) are crucial for applications with strict latency
and computational constraints, yet achieving high performance remains
challenging. Knowledge distillation (KD) can transfer capabilities from large
teacher models, but existing methods involve trade-offs: off-policy
distillation provides high-quality supervision but introduces a
training-inference mismatch, while on-policy approaches maintain consistency
but rely on low-quality student outputs. To address these issues, we propose
AdaSwitch, a novel approach that dynamically combines on-policy and off-policy
generation at the token level. AdaSwitch allows the student to first explore
its own predictions and then selectively integrate teacher guidance based on
real-time quality assessment. This approach simultaneously preserves
consistency and maintains supervision quality. Experiments on three datasets
with two teacher-student LLM pairs demonstrate that AdaSwitch consistently
improves accuracy, offering a practical and effective method for distilling
SLMs with acceptable additional overhead.

</details>


### [63] [Ready to Translate, Not to Represent? Bias and Performance Gaps in Multilingual LLMs Across Language Families and Domains](https://arxiv.org/abs/2510.07877)
*Md. Faiyaz Abdullah Sayeedi,Md. Mahbub Alam,Subhey Sadi Rahman,Md. Adnanul Islam,Jannatul Ferdous Deepti,Tasnim Mohiuddin,Md Mofijul Islam,Swakkhar Shatabda*

Main category: cs.CL

TL;DR: 本文提出Translation Tangles框架及偏见注释数据集，系统评测开源大语言模型在多语言和多领域机器翻译的质量与公平性，并提供混合检测方法揭示模型偏见。相关资源已开源，推动后续研究。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）极大提升了机器翻译的能力，但在语言种类、专业领域和公平性方面仍存在不足，尤其是在低资源语言中。研究动机在于系统化评估LLMs翻译质量与公平性，同时检测和缓解模型中的偏见。

Method: 提出并实现Translation Tangles框架，结合多指标对24对双向语言对、多个领域的翻译质量和公平性进行评测。引入了混合偏见检测流程，包括基于规则、语义相似性过滤及LLM校验。此外，基于人工评估创建了带偏见注释的高质量数据集，共计1439组翻译-参考对。

Result: Translation Tangles统一评测了开源LLMs在不同语言对和领域的机器翻译表现，并系统暴露了其偏见与公平性问题。新提出的数据集与代码已开源，便于社区开展后续研究。

Conclusion: 大型语言模型已显著推动机器翻译进步，但仍需关注和解决其在公平性和偏见方面的问题。Translation Tangles为系统评估LLMs翻译质量及偏见检测试提供了有效、可复现的工具和数据集。

Abstract: The rise of Large Language Models (LLMs) has redefined Machine Translation
(MT), enabling context-aware and fluent translations across hundreds of
languages and textual domains. Despite their remarkable capabilities, LLMs
often exhibit uneven performance across language families and specialized
domains. Moreover, recent evidence reveals that these models can encode and
amplify different biases present in their training data, posing serious
concerns for fairness, especially in low-resource languages. To address these
gaps, we introduce Translation Tangles, a unified framework and dataset for
evaluating the translation quality and fairness of open-source LLMs. Our
approach benchmarks 24 bidirectional language pairs across multiple domains
using different metrics. We further propose a hybrid bias detection pipeline
that integrates rule-based heuristics, semantic similarity filtering, and
LLM-based validation. We also introduce a high-quality, bias-annotated dataset
based on human evaluations of 1,439 translation-reference pairs. The code and
dataset are accessible on GitHub:
https://github.com/faiyazabdullah/TranslationTangles

</details>


### [64] [Do LLMs Really Need 10+ Thoughts for "Find the Time 1000 Days Later"? Towards Structural Understanding of LLM Overthinking](https://arxiv.org/abs/2510.07880)
*Xinliang Frederick Zhang,Anhad Mohananey,Alexandra Chronopoulou,Pinelopi Papalampidi,Somit Gupta,Tsendsuren Munkhdalai,Lu Wang,Shyam Upadhyay*

Main category: cs.CL

TL;DR: 本文发现长链式思维模型在简单任务上会出现过度思考问题，并提出分析工具TRACE，细致揭示了其思维过程和主因，在此基础上对过度思考提出了全新定义，为管理大模型推理效率提供了理论工具。


<details>
  <summary>Details</summary>
Motivation: 现有使用长链式思维(CoT)推理的模型在复杂任务上表现更好，但也带来了“过度思考”（overthinking）问题，即模型在简单任务上也进行冗余推理，增加了不必要的计算，且对准确率无益。过去关于过度思考的研究多为表层分析，缺乏对大模型内部机制的深入理解。

Method: 本文提出了一种细粒度分析工具——TRACE，系统化分解大模型的思维过程。首先，利用TRACE将推理过程拆分为最小完备的子思路，并通过推断子思路之间的话语关系，构建细致的思维进程图，进一步识别出相似主题查询下的常见思维模式。

Result: 通过分析发现，开源大模型存在两大思维模式（探索者模式、后着陆模式），两者表明“过度验证”与“过度探索”是过度思考的主要原因。同时，模型在简单任务上耗时为正常模型的5到20倍且精度提升有限。

Conclusion: 本文基于思维结构，提出了一个基于效用的过度思考定义，超越传统的长度衡量标准，为理解并管理大模型过度思考问题提供了更具洞见和操作性的思路。

Abstract: Models employing long chain-of-thought (CoT) reasoning have shown superior
performance on complex reasoning tasks. Yet, this capability introduces a
critical and often overlooked inefficiency -- overthinking -- models often
engage in unnecessarily extensive reasoning even for simple queries, incurring
significant computations without accuracy improvements. While prior work has
explored solutions to mitigate overthinking, a fundamental gap remains in our
understanding of its underlying causes. Most existing analyses are limited to
superficial, profiling-based observations, failing to delve into LLMs' inner
workings. This study introduces a systematic, fine-grained analyzer of LLMs'
thought process to bridge the gap, TRACE. We first benchmark the overthinking
issue, confirming that long-thinking models are five to twenty times slower on
simple tasks with no substantial gains. We then use TRACE to first decompose
the thought process into minimally complete sub-thoughts. Next, by inferring
discourse relationships among sub-thoughts, we construct granular thought
progression graphs and subsequently identify common thinking patterns for
topically similar queries. Our analysis reveals two major patterns for
open-weight thinking models -- Explorer and Late Landing. This finding provides
evidence that over-verification and over-exploration are the primary drivers of
overthinking in LLMs. Grounded in thought structures, we propose a
utility-based definition of overthinking, which moves beyond length-based
metrics. This revised definition offers a more insightful understanding of
LLMs' thought progression, as well as practical guidelines for principled
overthinking management.

</details>


### [65] [CS3-Bench: Evaluating and Enhancing Speech-to-Speech LLMs for Mandarin-English Code-Switching](https://arxiv.org/abs/2510.07881)
*Heyang Liu,Yuhao Wang,Ziyang Cheng,Ronghua Wu,Qunshan Gu,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 该论文发现现有主流语音交互大模型在语言切换任务中表现不足，提出新基准和训练方法，显著提升了模型的知识问答准确率和理解能力，同时有效减少了发音错误。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大型语言模型在语音到语音交互方面已能实现自然单语交流，但在语言对齐（特别是代码切换场景）上有明显不足。其在知识密集型问答和开放式对话中表现出错率高、理解偏差明显，急需提升模型的语言对齐和理解能力。

Method: 提出了Code-Switching Speech-to-Speech Benchmark (CS3-Bench)用于评估模型处理代码切换语音的表现，并设计了数据构建与训练新方法，包括“识别链条”（Chain of Recognition，CoR）提升理解能力、“关键词突出”（Keyword Highlighting，KH）引导输出生成，以针对性改进模型。

Result: 实验显示原生主流模型在多语言对齐场景下知识问答性能最高下降66%。采用提出的方法后，知识准确率从25.14%提升至46.13%，开放式理解率由64.5%增至86.5%；二语的发音错误显著减少。

Conclusion: 针对多语言代码切换语音交互，CS3-Bench揭示主流模型的瓶颈，所提数据和训练方案有效提升了模型在复杂跨语种语音任务中的知识准确和理解能力。该基准可为后续模型改进提供有力工具。

Abstract: The advancement of multimodal large language models has accelerated the
development of speech-to-speech interaction systems. While natural monolingual
interaction has been achieved, we find existing models exhibit deficiencies in
language alignment. In our proposed Code-Switching Speech-to-Speech Benchmark
(CS3-Bench), experiments on 7 mainstream models demonstrate a relative
performance drop of up to 66% in knowledge-intensive question answering and
varying degrees of misunderstanding in open-ended conversations. Starting from
a model with severe performance deterioration, we propose both data
constructions and training approaches to improve the language alignment
capabilities, specifically employing Chain of Recognition (CoR) to enhance
understanding and Keyword Highlighting (KH) to guide generation. Our approach
improves the knowledge accuracy from 25.14% to 46.13%, with open-ended
understanding rate from 64.5% to 86.5%, and significantly reduces pronunciation
errors in the secondary language. CS3-Bench is available at
https://huggingface.co/datasets/VocalNet/CS3-Bench.

</details>


### [66] [Contrastive Weak-to-strong Generalization](https://arxiv.org/abs/2510.07884)
*Houcheng Jiang,Junfeng Fang,Jiaxin Wu,Tianyu Zhang,Chen Gao,Yong Li,Xiang Wang,Xiangnan He,Yang Deng*

Main category: cs.CL

TL;DR: 本文提出了对比弱-强泛化（ConG）方法，通过对比解码生成高质量样本，有效提升泛化和鲁棒性，在多个模型中验证了效果，是推动LLM训练和AGI发展的重要进展。


<details>
  <summary>Details</summary>
Motivation: 弱-强泛化方法旨在通过对齐弱模型来训练更强大的大模型，减少对人工反馈的依赖，但存在噪声与偏差导致泛化和鲁棒性不足的问题。该研究希望提升此类方法的实用性与可靠性。

Method: 作者提出利用通过对数似然比隐式模拟显式奖励的方法，进一步将该方法与已知的对比解码相结合，构建了对比弱-强泛化（ConG）框架。该框架通过对齐前后的弱模型进行对比解码，生成更高质量的训练样本，有效实现能力迁移和去噪。

Result: 通过在不同模型族上的实证验证，ConG方法在鲁棒性和泛化性方面都出现了一致性的改进，显示出广泛的适用性和有效性。

Conclusion: ConG方法不仅显著提升了弱-强泛化训练的效果，也为通往AGI的发展提供了有希望的途径。

Abstract: Weak-to-strong generalization provides a promising paradigm for scaling large
language models (LLMs) by training stronger models on samples from aligned
weaker ones, without requiring human feedback or explicit reward modeling.
However, its robustness and generalization are hindered by the noise and biases
in weak-model outputs, which limit its applicability in practice. To address
this challenge, we leverage implicit rewards, which approximate explicit
rewards through log-likelihood ratios, and reveal their structural equivalence
with Contrastive Decoding (CD), a decoding strategy shown to reduce noise in
LLM generation. Building on this connection, we propose Contrastive
Weak-to-Strong Generalization (ConG), a framework that employs contrastive
decoding between pre- and post-alignment weak models to generate higher-quality
samples. This approach enables more reliable capability transfer, denoising,
and improved robustness, substantially mitigating the limitations of
traditional weak-to-strong methods. Empirical results across different model
families confirm consistent improvements, demonstrating the generality and
effectiveness of ConG. Taken together, our findings highlight the potential of
ConG to advance weak-to-strong generalization and provide a promising pathway
toward AGI.

</details>


### [67] [Standard-to-Dialect Transfer Trends Differ across Text and Speech: A Case Study on Intent and Topic Classification in German Dialects](https://arxiv.org/abs/2510.07890)
*Verena Blaschke,Miriam Winkler,Barbara Plank*

Main category: cs.CL

TL;DR: 本研究比较了德语及方言的文本、语音与级联系统三种方法下的迁移效果，发现语音模型最适合处理方言数据。


<details>
  <summary>Details</summary>
Motivation: 过去对标准和非标准方言（方言）迁移的研究多集中于文本数据，但方言本以口语为主，文本中的非标准拼写会影响处理效果。本研究旨在探究以口语为主的方言在不同建模方式上的迁移表现。

Method: 对德语及其多个方言，分别采用三种设置（纯文本模型、纯语音模型与语音-文本级联系统）进行意图和主题分类实验，并首次发布了方言音频意图分类数据集。

Result: 实验发现，语音模型在方言任务上优于文本模型，而文本模型在标准德语任务上表现更好；级联系统依赖于转写系统质量，在方言数据上若输出标准化文本表现也可观。

Conclusion: 在跨方言迁移任务中，纯语音模型在方言数据上的表现最佳，而纯文本模型在标准德语数据上表现最好。级联系统虽然在标准德语上不敌纯文本模型，但若转写系统生成标准化文本，则在方言数据上的表现相对较好。

Abstract: Research on cross-dialectal transfer from a standard to a non-standard
dialect variety has typically focused on text data. However, dialects are
primarily spoken, and non-standard spellings are known to cause issues in text
processing. We compare standard-to-dialect transfer in three settings: text
models, speech models, and cascaded systems where speech first gets
automatically transcribed and then further processed by a text model. In our
experiments, we focus on German and multiple German dialects in the context of
written and spoken intent and topic classification. To that end, we release the
first dialectal audio intent classification dataset. We find that the
speech-only setup provides the best results on the dialect data while the
text-only setup works best on the standard data. While the cascaded systems lag
behind the text-only models for German, they perform relatively well on the
dialectal data if the transcription system generates normalized, standard-like
output.

</details>


### [68] [Metric Calculating Benchmark: Code-Verifiable Complicate Instruction Following Benchmark for Large Language Models](https://arxiv.org/abs/2510.07892)
*Hyeonseok Moon,Seongtae Hong,Jaehyung Seo,Heuiseok Lim*

Main category: cs.CL

TL;DR: MCBench基准通过客观代码可验证方式，检验大语言模型严格按说明执行指令的能力，对现有模型评测提供了更细致和客观的工具。


<details>
  <summary>Details</summary>
Motivation: 现有前沿级大模型已在许多以往困难的基准测试中表现出色，导致很难进一步区分不同模型的能力。因此有必要开发更具挑战性的基准以客观验证模型表现。

Method: 提出了MCBench这一基准，专为评估大语言模型是否能按照逐步说明严格执行字符串匹配类NLP任务。MCBench不依赖主观判断或通用推理，而是通过客观、确定性和可代码验证的评测方法，配套参考代码以评估输出准确性，并设计了三类评估指标和三种基准变体。

Result: 分析表明，MCBench能够有效且客观地评估前沿级大语言模型的精准指令理解和执行能力，特别是在逐步执行、数值计算和中间结果一致性方面表现良好。

Conclusion: MCBench为当前大语言模型的能力评估提供了更具挑战性和客观性的工具，有助于推动领域基准进一步发展和细致区分模型能力。

Abstract: Recent frontier-level LLMs have saturated many previously difficult
benchmarks, leaving little room for further differentiation. This progress
highlights the need for challenging benchmarks that provide objective
verification. In this paper, we introduce MCBench, a benchmark designed to
evaluate whether LLMs can execute string-matching NLP metrics by strictly
following step-by-step instructions. Unlike prior benchmarks that depend on
subjective judgments or general reasoning, MCBench offers an objective,
deterministic and codeverifiable evaluation. This setup allows us to
systematically test whether LLMs can maintain accurate step-by-step execution,
including instruction adherence, numerical computation, and long-range
consistency in handling intermediate results. To ensure objective evaluation of
these abilities, we provide a parallel reference code that can evaluate the
accuracy of LLM output. We provide three evaluative metrics and three benchmark
variants designed to measure the detailed instruction understanding capability
of LLMs. Our analyses show that MCBench serves as an effective and objective
tool for evaluating the capabilities of cutting-edge LLMs.

</details>


### [69] [ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual Recall](https://arxiv.org/abs/2510.07896)
*Jiayu Yang,Yuxuan Fan,Songning Lai,Shengen Wu,Jiaqi Tang,Chun Kang,Zhijiang Guo,Yutao Yue*

Main category: cs.CL

TL;DR: 本文发现多跳推理中的隐式主体实际作为查询神经元逐层激活相关价值神经元，提出ACE框架从神经元归因角度编辑关键路径，有效提升多跳知识编辑效果，并机制化阐释了模型内部推理。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法在多跳事实召回时性能严重衰减，尤其在涉及推理链中间隐式主体时更为明显。亟需一种机制化且高效的多跳知识编辑方法。

Method: 通过因果分析发现隐式主体在多跳推理中作为查询神经元激活价值神经元，提出ACE框架基于神经元归因对关键查询-价值路径进行识别和编辑。

Result: ACE框架在GPT-J上提升9.44%，在Qwen3-8B上提升37.46%，并揭示了Qwen3中更细粒度的激活模式及价值神经元的语义可解释性由查询驱动积累所主导。

Conclusion: 本研究揭示了多跳知识编辑在大语言模型中的机制，并提出了一种新的框架ACE，显著提升了多跳事实召回的性能。

Abstract: Large Language Models (LLMs) require efficient knowledge editing (KE) to
update factual information, yet existing methods exhibit significant
performance decay in multi-hop factual recall. This failure is particularly
acute when edits involve intermediate implicit subjects within reasoning
chains. Through causal analysis, we reveal that this limitation stems from an
oversight of how chained knowledge is dynamically represented and utilized at
the neuron level. We discover that during multi hop reasoning, implicit
subjects function as query neurons, which sequentially activate corresponding
value neurons across transformer layers to accumulate information toward the
final answer, a dynamic prior KE work has overlooked. Guided by this insight,
we propose ACE: Attribution-Controlled Knowledge Editing for Multi-hop Factual
Recall, a framework that leverages neuron-level attribution to identify and
edit these critical query-value (Q-V) pathways. ACE provides a mechanistically
grounded solution for multi-hop KE, empirically outperforming state-of-the-art
methods by 9.44% on GPT-J and 37.46% on Qwen3-8B. Our analysis further reveals
more fine-grained activation patterns in Qwen3 and demonstrates that the
semantic interpretability of value neurons is orchestrated by query-driven
accumulation. These findings establish a new pathway for advancing KE
capabilities based on the principled understanding of internal reasoning
mechanisms.

</details>


### [70] [Towards Human-Like Grading: A Unified LLM-Enhanced Framework for Subjective Question Evaluation](https://arxiv.org/abs/2510.07912)
*Fanwei Zhua,Jiaxuan He,Xiaoxiao Chen,Zulong Chen,Quan Lu,Chenrui Mei*

Main category: cs.CL

TL;DR: 本文提出一种基于大语言模型的自动主观题评分系统，采用四模块综合评估方式，在多场景下超越传统和现有LLM方法，并已落地实际企业培训考试。


<details>
  <summary>Details</summary>
Motivation: 主观题的自动评分长期以来都是考试评估中的难题，现有方法多针对单一题型，缺乏适应全面考试中多样主观题的通用性。

Method: 本文提出一个统一的、基于大型语言模型（LLM）增强的自动评分框架。该框架集成四个互补模块：基本文本匹配、知识点比对、基于学生答案的伪问题生成，以及模拟人工评估以发现内容相关及内容无关的优缺点，并利用LLM的推理与生成能力实现人类化评价。

Result: 在多种通用和领域数据集上的大量实验表明，所提框架在多项评分指标上均优于传统与现有LLM方法，并已成功在某大型电商企业的真实培训与认证考试中部署。

Conclusion: 该LLM增强的自动评分框架能对各种主观题型实现类人工高效评价，在实际考试中的表现优越，具备良好的通用性和应用前景。

Abstract: Automatic grading of subjective questions remains a significant challenge in
examination assessment due to the diversity in question formats and the
open-ended nature of student responses. Existing works primarily focus on a
specific type of subjective question and lack the generality to support
comprehensive exams that contain diverse question types. In this paper, we
propose a unified Large Language Model (LLM)-enhanced auto-grading framework
that provides human-like evaluation for all types of subjective questions
across various domains. Our framework integrates four complementary modules to
holistically evaluate student answers. In addition to a basic text matching
module that provides a foundational assessment of content similarity, we
leverage the powerful reasoning and generative capabilities of LLMs to: (1)
compare key knowledge points extracted from both student and reference answers,
(2) generate a pseudo-question from the student answer to assess its relevance
to the original question, and (3) simulate human evaluation by identifying
content-related and non-content strengths and weaknesses. Extensive experiments
on both general-purpose and domain-specific datasets show that our framework
consistently outperforms traditional and LLM-based baselines across multiple
grading metrics. Moreover, the proposed system has been successfully deployed
in real-world training and certification exams at a major e-commerce
enterprise.

</details>


### [71] [STEPER: Step-wise Knowledge Distillation for Enhancing Reasoning Ability in Multi-Step Retrieval-Augmented Language Models](https://arxiv.org/abs/2510.07923)
*Kyumin Lee,Minjin Jeon,Sanghwan Jang,Hwanjo Yu*

Main category: cs.CL

TL;DR: StepER通过逐步监督和难度感知训练，显著提升了多步检索增强语言模型的推理能力，使小参数模型在多跳问答任务上达到大模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的知识蒸馏方法在多步检索增强框架中未能关注各阶段不同推理能力的需求，影响了模型的迁移与推理效果。

Method: 提出了一种新的逐步知识蒸馏方法StepER，这种方法通过逐步监督以及难度感知训练，使模型在多阶段检索和推理时更有效地学习不同步骤的推理能力，并优先优化合适难度的步骤。方法适用于多种检索增强语言模型，包括通过检索查询进行推理路径或问题分解的模型。

Result: StepER在多跳问答任务基准上的表现优于现有方法，8B参数规模的模型达到与70B教师模型相当的效果。

Conclusion: StepER有效提升了多步骤检索增强语言模型的推理能力和迁移性能，实现了小模型在复杂问答任务上的显著性能提升。

Abstract: Answering complex real-world questions requires step-by-step retrieval and
integration of relevant information to generate well-grounded responses.
However, existing knowledge distillation methods overlook the need for
different reasoning abilities at different steps, hindering transfer in
multi-step retrieval-augmented frameworks. To address this, we propose Stepwise
Knowledge Distillation for Enhancing Reasoning Ability in Multi-Step
Retrieval-Augmented Language Models (StepER). StepER employs step-wise
supervision to align with evolving information and reasoning demands across
stages. Additionally, it incorporates difficulty-aware training to
progressively optimize learning by prioritizing suitable steps. Our method is
adaptable to various multi-step retrieval-augmented language models, including
those that use retrieval queries for reasoning paths or decomposed questions.
Extensive experiments show that StepER outperforms prior methods on multi-hop
QA benchmarks, with an 8B model achieving performance comparable to a 70B
teacher model.

</details>


### [72] [Comprehensiveness Metrics for Automatic Evaluation of Factual Recall in Text Generation](https://arxiv.org/abs/2510.07926)
*Adam Dejl,James Barry,Alessandra Pascale,Javier Carnerero Cano*

Main category: cs.CL

TL;DR: 本文提出三种自动化方法检测LLM输出中的信息遗漏，发现直接用LLM端到端方法最有效，但有其局限，且系统比较了多个开源LLM的全面性表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多任务表现优异，但在输出文本时常常遗漏关键信息，尤其在敏感领域会带来严重后果，需对其输出全面性进行系统评估。

Method: 提出并评估了三种自动化评测LLM文本信息全面性的方法：NLI分解法、Q&A对比法和基于LLM的端到端检测法，并用多源回答评测多款LLM。

Result: 端到端LLM方法在检测遗漏信息表现优于更复杂的NLI和Q&A方法，但结果不够稳健、难以解释和不够细致，同时还评测了多个主流开源LLM的回答全面性。

Conclusion: 简单的端到端方法在检测LLM输出遗漏信息方面表现出意外的优越性，但其鲁棒性、可解释性和细粒度结果表现较弱。

Abstract: Despite demonstrating remarkable performance across a wide range of tasks,
large language models (LLMs) have also been found to frequently produce outputs
that are incomplete or selectively omit key information. In sensitive domains,
such omissions can result in significant harm comparable to that posed by
factual inaccuracies, including hallucinations. In this study, we address the
challenge of evaluating the comprehensiveness of LLM-generated texts, focusing
on the detection of missing information or underrepresented viewpoints. We
investigate three automated evaluation strategies: (1) an NLI-based method that
decomposes texts into atomic statements and uses natural language inference
(NLI) to identify missing links, (2) a Q&A-based approach that extracts
question-answer pairs and compares responses across sources, and (3) an
end-to-end method that directly identifies missing content using LLMs. Our
experiments demonstrate the surprising effectiveness of the simple end-to-end
approach compared to more complex methods, though at the cost of reduced
robustness, interpretability and result granularity. We further assess the
comprehensiveness of responses from several popular open-weight LLMs when
answering user queries based on multiple sources.

</details>


### [73] [Vision-Enabled LLMs in Historical Lexicography: Digitising and Enriching Estonian-German Dictionaries from the 17th and 18th Centuries](https://arxiv.org/abs/2510.07931)
*Madis Jürviste,Joonatan Jakobson*

Main category: cs.CL

TL;DR: 本研究表明，LLM在爱沙尼亚17-18世纪历史字典的现代释义丰富、古文献识别等方面表现突出，能有效提升少数民族语言文献的数字化与整理效率。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型（LLMs）如何应用于17-18世纪爱沙尼亚字典，以提高数字化与现代化处理能力。

Method: 1. 利用LLM丰富历史字典的现代词形与释义；2. 使用具视觉能力的LLM对哥特字体文献进行文本识别；3. 为创建跨文献统一数据集做准备。具体实验包括为字典词条提供现代释义和识别、结构化历史文献图片中的文本内容。

Result: （1）在J. Gutslaff 1648年字典的实验中，Claude 3.7 Sonnet为81%的词条成功给出准确的现代释义；（2）在A. T. Helle 1732年字典图像识别实验中，零样本方法将41%的词条准确转为无误的JSON；（3）对于Hupel 1780年语法文献，采用切片技术结合多个LLM识别和整合结果。

Conclusion: LLM在小语种历史文献的数字化、现代化方面展示出高效潜力，可显著节省人力和资金。

Abstract: This article presents research conducted at the Institute of the Estonian
Language between 2022 and 2025 on the application of large language models
(LLMs) to the study of 17th and 18th century Estonian dictionaries. The authors
address three main areas: enriching historical dictionaries with modern word
forms and meanings; using vision-enabled LLMs to perform text recognition on
sources printed in Gothic script (Fraktur); and preparing for the creation of a
unified, cross-source dataset. Initial experiments with J. Gutslaff's 1648
dictionary indicate that LLMs have significant potential for semi-automatic
enrichment of dictionary information. When provided with sufficient context,
Claude 3.7 Sonnet accurately provided meanings and modern equivalents for 81%
of headword entries. In a text recognition experiment with A. T. Helle's 1732
dictionary, a zero-shot method successfully identified and structured 41% of
headword entries into error-free JSON-formatted output. For digitising the
Estonian-German dictionary section of A. W. Hupel's 1780 grammar, overlapping
tiling of scanned image files is employed, with one LLM being used for text
recognition and a second for merging the structured output. These findings
demonstrate that even for minor languages LLMs have a significant potential for
saving time and financial resources.

</details>


### [74] [A$^2$Search: Ambiguity-Aware Question Answering with Reinforcement Learning](https://arxiv.org/abs/2510.07958)
*Fengji Zhang,Xinyao Niu,Chengyang Ying,Guancheng Lin,Zhongkai Hao,Zhou Fan,Chengen Huang,Jacky Keung,Bei Chen,Junyang Lin*

Main category: cs.CL

TL;DR: 本文提出A$^2$Search，无需人工标注即可处理多答案的开放域问答问题，并在多个基准数据集上达到新SOTA，显示对答案模糊性的有效应对。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型和强化学习方法在开放域问答中表现强劲，但在应对答案存在多样性的模糊性问题方面仍有不足。标准问答基准假设只有唯一标准答案，忽视了实际中问题存在多种合理答案的情况，因而带来不准确的训练信号。此外，大规模数据上的人工标注成本太高，难以推广。

Method: 提出了A$^2$Search——一种无需人工标注、端到端的训练框架，能够自动检测模糊性问题，通过轨迹采样和证据验证收集多样化的合理答案。最后利用RL以及$	ext{AnsF1}$奖励函数进行优化，天然支持多答案情形。

Result: A$^2$Search在八个开放域问答基准上取得了新的SOTA成绩。在四个多跳问答任务上的平均$	ext{AnsF1}@1$得分为48.4%，显著超过了规模更大的对比模型ReSearch-32B（46.2%）。进一步分析表明该方法有效解决了答案模糊性问题，并具备跨数据集的良好泛化能力。

Conclusion: A$^2$Search无需人工标注，能自动识别与处理多答案问题，在多个问答基准上取得新突破。对模糊性问题的应对是问答系统可靠性的关键。

Abstract: Recent advances in Large Language Models (LLMs) and Reinforcement Learning
(RL) have led to strong performance in open-domain question answering (QA).
However, existing models still struggle with questions that admit multiple
valid answers. Standard QA benchmarks, which typically assume a single gold
answer, overlook this reality and thus produce inappropriate training signals.
Existing attempts to handle ambiguity often rely on costly manual annotation,
which is difficult to scale to multi-hop datasets such as HotpotQA and MuSiQue.
In this paper, we present A$^2$Search, an annotation-free, end-to-end training
framework to recognize and handle ambiguity. At its core is an automated
pipeline that detects ambiguous questions and gathers alternative answers via
trajectory sampling and evidence verification. The model is then optimized with
RL using a carefully designed $\mathrm{AnsF1}$ reward, which naturally
accommodates multiple answers. Experiments on eight open-domain QA benchmarks
demonstrate that A$^2$Search achieves new state-of-the-art performance. With
only a single rollout, A$^2$Search-7B yields an average $\mathrm{AnsF1}@1$
score of $48.4\%$ across four multi-hop benchmarks, outperforming all strong
baselines, including the substantially larger ReSearch-32B ($46.2\%$).
Extensive analyses further show that A$^2$Search resolves ambiguity and
generalizes across benchmarks, highlighting that embracing ambiguity is
essential for building more reliable QA systems. Our code, data, and model
weights can be found at https://github.com/zfj1998/A2Search

</details>


### [75] [LightReasoner: Can Small Language Models Teach Large Language Models Reasoning?](https://arxiv.org/abs/2510.07962)
*Jingyuan Wang,Yankai Chen,Zhonghang Li,Chao Huang*

Main category: cs.CL

TL;DR: LightReasoner框架利用弱模型揭示强模型推理优势，从而为强模型提供高效监督，实现更高性能和更低资源消耗的推理能力提升，无须依赖人工标注。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在推理方面表现突出，但通过监督微调（SFT）提升能力，非常耗费资源且效率低下。作者希望找到更高效、更具可扩展性的LLM推理能力提升方法。

Method: 提出了LightReasoner，利用强模型（LLM）和弱模型（SLM）的表现分歧。分为两个阶段：1）采样阶段，通过专家-业余对比法提取关键推理时刻，并构造高价值监督样本；2）微调阶段，用这些样本对强模型进行对齐和强化推理能力。无需真实标签数据。

Result: 在七个数学基准测试上，LightReasoner使LLM推理准确率最高提升28.1%，缩短90%时间消耗，减少80%采样问题量，减少99%用于微调的token消耗，无需依赖真实标签。

Conclusion: 通过让小模型为大模型提供高价值教学信号，LightReasoner实现了推理能力的增强，并且具有高度可扩展性和资源效率，推动LLM推理能力提升。

Abstract: Large language models (LLMs) have demonstrated remarkable progress in
reasoning, often through supervised fine-tuning (SFT). However, SFT is
resource-intensive, relying on large curated datasets, rejection-sampled
demonstrations, and uniform optimization across all tokens, even though only a
fraction carry meaningful learning value. In this work, we explore a
counterintuitive idea: can smaller language models (SLMs) teach larger language
models (LLMs) by revealing high-value reasoning moments that reflect the
latter's unique strength? We propose LightReasoner, a novel framework that
leverages the behavioral divergence between a stronger expert model (LLM) and a
weaker amateur model (SLM). LightReasoner operates in two stages: (1) a
sampling stage that pinpoints critical reasoning moments and constructs
supervision examples capturing the expert's advantage through expert-amateur
contrast, and (2) a fine-tuning stage that aligns the expert model with these
distilled examples, amplifying its reasoning strengths. Across seven
mathematical benchmarks, LightReasoner improves accuracy by up to 28.1%, while
reducing time consumption by 90%, sampled problems by 80%, and tuned token
usage by 99%, all without relying on ground-truth labels. By turning weaker
SLMs into effective teaching signals, LightReasoner offers a scalable and
resource-efficient approach for advancing LLM reasoning. Code is available at:
https://github.com/HKUDS/LightReasoner

</details>


### [76] [Active Confusion Expression in Large Language Models: Leveraging World Models toward Better Social Reasoning](https://arxiv.org/abs/2510.07974)
*Jialu Du,Guiyang Hou,Yihui Fu,Chen Wu,Wenqi Zhang,Yongliang Shen,Weiming Lu*

Main category: cs.CL

TL;DR: 本文针对LLMs在社会推理中的困境，提出动态世界模型干预推理机制，有效提升准确率并降低成本，在多项社会基准测试中表现显著。


<details>
  <summary>Details</summary>
Motivation: 本文发现大型语言模型（LLMs）在数学和代码推理方面表现优异，但在社会推理任务上表现不足，尤其在多主体和多时间线的情境下容易产生认知混乱、逻辑不一致及把客观世界状态与主观信念状态混为一谈。

Method: 作者通过分析DeepSeek-R1的推理轨迹，发现模型常常在多参与者的复杂情境下陷入推理僵局，并输出矛盾用语。为解决这一问题，提出了一种自适应的动态世界模型增强推理机制，通过构建文本世界模型实时监控并干预模型推理过程中的混淆点。

Result: 该机制能够有效帮助模型区分客观事件和主体信念，大幅提升社会推理准确率，并显著降低计算成本（token消耗减少）。

Conclusion: 增强推理机制为LLMs在处理涉及社会认知的任务时，提供了简单且高效的解决方案，证明了动态世界模型的有效性。

Abstract: While large language models (LLMs) excel in mathematical and code reasoning,
we observe they struggle with social reasoning tasks, exhibiting cognitive
confusion, logical inconsistencies, and conflation between objective world
states and subjective belief states. Through deteiled analysis of DeepSeek-R1's
reasoning trajectories, we find that LLMs frequently encounter reasoning
impasses and tend to output contradictory terms like "tricky" and "confused"
when processing scenarios with multiple participants and timelines, leading to
erroneous reasoning or infinite loops. The core issue is their inability to
disentangle objective reality from agents' subjective beliefs. To address this,
we propose an adaptive world model-enhanced reasoning mechanism that constructs
a dynamic textual world model to track entity states and temporal sequences. It
dynamically monitors reasoning trajectories for confusion indicators and
promptly intervenes by providing clear world state descriptions, helping models
navigate through cognitive dilemmas. The mechanism mimics how humans use
implicit world models to distinguish between external events and internal
beliefs. Evaluations on three social benchmarks demonstrate significant
improvements in accuracy (e.g., +10% in Hi-ToM) while reducing computational
costs (up to 33.8% token reduction), offering a simple yet effective solution
for deploying LLMs in social contexts.

</details>


### [77] [Leveraging Author-Specific Context for Scientific Figure Caption Generation: 3rd SciCap Challenge](https://arxiv.org/abs/2510.07993)
*Watcharapong Timklaypachara,Monrada Chiewhawan,Nopporn Lekuthai,Titipat Achakulvisut*

Main category: cs.CL

TL;DR: 该论文提出一个面向科学图注生成的系统，通过上下文理解与风格微调显著提升了图注的准确性和风格一致性。


<details>
  <summary>Details</summary>
Motivation: 科学论文的图注需要兼顾准确性和风格一致性，现有自动生成系统往往难以同时满足这两个需求。本文旨在开发一个能综合背景信息与作者风格的领域专属图注生成系统，以提升生成质量与适配性。

Method: 提出两阶段生成管线：第一阶段结合上下文过滤、类别特定的提示优化（通过DSPy's MIPROv2和SIMBA）以及图注候选筛选；第二阶段对生成图注进行少样本风格微调，利用作者个人论文集提升风格匹配度。系统使用LaMP-Cap数据集进行训练和测试。

Result: 类别特定提示优化比零样本和通用优化方法在ROUGE-1召回率上提升8.3%，精度损失仅2.8%，BLEU-4降低10.9%；风格微调带来BLEU分数提升40-48%，ROUGE提升25-27%。总体系统提升了科学准确性和风格一致性。

Conclusion: 系统证明将上下文理解与作者风格适配结合，能生成既科学准确又风格契合源论文的图注。

Abstract: Scientific figure captions require both accuracy and stylistic consistency to
convey visual information. Here, we present a domain-specific caption
generation system for the 3rd SciCap Challenge that integrates figure-related
textual context with author-specific writing styles using the LaMP-Cap dataset.
Our approach uses a two-stage pipeline: Stage 1 combines context filtering,
category-specific prompt optimization via DSPy's MIPROv2 and SIMBA, and caption
candidate selection; Stage 2 applies few-shot prompting with profile figures
for stylistic refinement. Our experiments demonstrate that category-specific
prompts outperform both zero-shot and general optimized approaches, improving
ROUGE-1 recall by +8.3\% while limiting precision loss to -2.8\% and BLEU-4
reduction to -10.9\%. Profile-informed stylistic refinement yields 40--48\%
gains in BLEU scores and 25--27\% in ROUGE. Overall, our system demonstrates
that combining contextual understanding with author-specific stylistic
adaptation can generate captions that are both scientifically accurate and
stylistically faithful to the source paper.

</details>


### [78] [Learning on the Job: An Experience-Driven Self-Evolving Agent for Long-Horizon Tasks](https://arxiv.org/abs/2510.08002)
*Cheng Yang,Xuemeng Yang,Licheng Wen,Daocheng Fu,Jianbiao Mei,Rong Wu,Pinlong Cai,Yufan Shen,Nianchen Deng,Botian Shi,Yu Qiao,Haifeng Li*

Main category: cs.CL

TL;DR: MUSE框架让大语言模型agent能自动积累经验，实现持续进化并在长周期任务中大幅超越传统静态模型，在真实世界任务自动化中展现出巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）虽然在多领域表现优异，但在实际长周期任务中作为AI agent部署时，仍面临无法基于经验自我学习和持续进化的问题。现有LLM agents通常在测试时静态，无法积累知识并工作中提升自己。

Method: 提出了MUSE框架，通过分层记忆模块组织和利用多层次经验。每完成一个子任务后，agent会反思自身轨迹，并将其转化为结构化经验，回馈到记忆模块，实现对知识的持续积累和自主进化。

Result: 在TAC长周期效率性基准上，MUSE采用轻量级Gemini-2.5 Flash模型取得了新SOTA成绩，并且展示了随着经验积累任务能力显著增强及持续学习进化能力。

Conclusion: MUSE为AI agent实现真实世界生产力任务自动化树立了新范式，其经验具备良好泛化性，能零样本迁移提升新任务表现。

Abstract: Large Language Models have demonstrated remarkable capabilities across
diverse domains, yet significant challenges persist when deploying them as AI
agents for real-world long-horizon tasks. Existing LLM agents suffer from a
critical limitation: they are test-time static and cannot learn from
experience, lacking the ability to accumulate knowledge and continuously
improve on the job. To address this challenge, we propose MUSE, a novel agent
framework that introduces an experience-driven, self-evolving system centered
around a hierarchical Memory Module. MUSE organizes diverse levels of
experience and leverages them to plan and execute long-horizon tasks across
multiple applications. After each sub-task execution, the agent autonomously
reflects on its trajectory, converting the raw trajectory into structured
experience and integrating it back into the Memory Module. This mechanism
enables the agent to evolve beyond its static pretrained parameters, fostering
continuous learning and self-evolution. We evaluate MUSE on the long-horizon
productivity benchmark TAC. It achieves new SOTA performance by a significant
margin using only a lightweight Gemini-2.5 Flash model. Sufficient Experiments
demonstrate that as the agent autonomously accumulates experience, it exhibits
increasingly superior task completion capabilities, as well as robust
continuous learning and self-evolution capabilities. Moreover, the accumulated
experience from MUSE exhibits strong generalization properties, enabling
zero-shot improvement on new tasks. MUSE establishes a new paradigm for AI
agents capable of real-world productivity task automation.

</details>


### [79] [ChatGPT as a Translation Engine: A Case Study on Japanese-English](https://arxiv.org/abs/2510.08042)
*Vincent Michael Sutanto,Giovanni Gatti De Giacomo,Toshiaki Nakazawa,Masaru Yamada*

Main category: cs.CL

TL;DR: 该研究发现，ChatGPT在日英翻译中接近主流翻译引擎，文档级翻译优于句子级，复杂提示词未表现更优，3.5更准，4更流畅。


<details>
  <summary>Details</summary>
Motivation: 评估ChatGPT在日英翻译中的实际效能，探索提示词对结果的影响及与商业引擎的差距。

Method: 对比简单/增强提示词，采用自动评估和MQM人工评估进行句子级和文档级翻译性能测试。将ChatGPT与两种主流翻译引擎进行对比分析。

Result: 文档级翻译结果优于句子级；增强提示词不一定优于简单提示词；ChatGPT-3.5在自动评估中更优，但ChatGPT-4在流畅性方面有优势；整体表现与主流翻译系统相当。

Conclusion: ChatGPT在英日翻译方面表现接近主流商业翻译引擎，文档级翻译优于句子级翻译，提示词复杂度未必影响效果。ChatGPT-3.5与ChatGPT-4在准确性和流畅性上各有优势。

Abstract: This study investigates ChatGPT for Japanese-English translation, exploring
simple and enhanced prompts and comparing against commercially available
translation engines. Performing both automatic and MQM-based human evaluations,
we found that document-level translation outperforms sentence-level translation
for ChatGPT. On the other hand, we were not able to determine if enhanced
prompts performed better than simple prompts in our experiments. We also
discovered that ChatGPT-3.5 was preferred by automatic evaluation, but a
tradeoff exists between accuracy (ChatGPT-3.5) and fluency (ChatGPT-4). Lastly,
ChatGPT yields competitive results against two widely-known translation
systems.

</details>


### [80] [Climate Knowledge in Large Language Models](https://arxiv.org/abs/2510.08043)
*Ivan Kuznetsov,Jacopo Grassi,Dmitrii Pantiukhin,Boris Shapkin,Thomas Jung,Nikolay Koldunov*

Main category: cs.CL

TL;DR: 大语言模型已能较好地再现全球气候常态，但在复杂地区和长期温度变化表达上依旧存在显著局限。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在气候相关应用中的使用日益增加，但其对气候常态参数性知识的记忆和准确性尚未系统评估。文章旨在填补这一空白，研究LLMs能否在不给予外部信息检索的情况下，准确回忆全球不同地点的标准气候统计值。

Method: 构建覆盖全球1度分辨率的地面网格查询点，针对每个点询问1991-2020年7月2米高度均温，并为LLMs提供坐标和地理信息（如国家、城市、区域）；用ERA5再分析数据作为真实值对模型输出进行评估，包括均方根误差（RMSE）和系统偏差分析，并检验不同地理上下文对模型表现影响。

Result: LLMs对气候结构有一定的编码能力，在纬度和地形模式上表现尚可，整体RMSE为3-6°C，系统偏差约±1°C，但在山地和高纬度地区误差显著（RMSE高达5-13°C）。加入地理上下文信息可平均减少27%的误差。对于历史气温变化，模型可捕捉全球均值但无法还原区域和局部温度变化格局，表明其在细致再现气候变化方面存在明显局限性。

Conclusion: LLMs在当前气候常态记忆和全球分布再现上已有非平凡表现，但无法准确捕捉区域气温变化，难以替代科学数据用于气候变化动力学研究。该评测框架为定量分析LLMs参数气候知识提供了可复现性基准，有助于完善现有气候沟通评估。

Abstract: Large language models (LLMs) are increasingly deployed for climate-related
applications, where understanding internal climatological knowledge is crucial
for reliability and misinformation risk assessment. Despite growing adoption,
the capacity of LLMs to recall climate normals from parametric knowledge
remains largely uncharacterized. We investigate the capacity of contemporary
LLMs to recall climate normals without external retrieval, focusing on a
prototypical query: mean July 2-m air temperature 1991-2020 at specified
locations. We construct a global grid of queries at 1{\deg} resolution land
points, providing coordinates and location descriptors, and validate responses
against ERA5 reanalysis. Results show that LLMs encode non-trivial climate
structure, capturing latitudinal and topographic patterns, with
root-mean-square errors of 3-6 {\deg}C and biases of $\pm$1 {\deg}C. However,
spatially coherent errors remain, particularly in mountains and high latitudes.
Performance degrades sharply above 1500 m, where RMSE reaches 5-13 {\deg}C
compared to 2-4 {\deg}C at lower elevations. We find that including geographic
context (country, city, region) reduces errors by 27% on average, with larger
models being most sensitive to location descriptors. While models capture the
global mean magnitude of observed warming between 1950-1974 and 2000-2024, they
fail to reproduce spatial patterns of temperature change, which directly relate
to assessing climate change. This limitation highlights that while LLMs may
capture present-day climate distributions, they struggle to represent the
regional and local expression of long-term shifts in temperature essential for
understanding climate dynamics. Our evaluation framework provides a
reproducible benchmark for quantifying parametric climate knowledge in LLMs and
complements existing climate communication assessments.

</details>


### [81] [A Survey of Process Reward Models: From Outcome Signals to Process Supervisions for Large Language Models](https://arxiv.org/abs/2510.08049)
*Congming Zheng,Jiachen Zhu,Zhuoying Ou,Yuxiang Chen,Kangning Zhang,Rong Shan,Zeyu Zheng,Mengyue Yang,Jianghao Lin,Yong Yu,Weinan Zhang*

Main category: cs.CL

TL;DR: 本综述系统梳理过程奖励模型（PRM）的数据生成、构建与应用流程，总结数学、代码等多个领域的应用与评测，为模型细致推理对齐指明了方向，并归纳了设计空间与未来挑战。


<details>
  <summary>Details</summary>
Motivation: 当前主流大模型对齐方法侧重于结果奖励模型（ORM），但这种方式只评判最终答案，忽略推理过程细节。为提升模型推理的细致性与鲁棒性，亟需对推理过程本身进行更精细的评价和引导。

Method: 对过程奖励模型（PRM）进行了系统综述，包括过程数据生成、PRM构建，以及在测试和强化学习阶段的具体应用。结合数学、代码、文本、多模态推理、机器人与智能体等领域实际案例，总结当前实现与新兴评测基准。

Result: 系统归纳了PRM的全流程方法，总结各领域应用，指出PRM的设计空间，归纳当前面临的挑战，并提出未来研究方向。有效推动了高粒度、鲁棒推理对齐的发展。

Conclusion: PRM为模型推理过程的微观评价与优化提供了系统方法，是推进模型细致、稳定推理与对齐的重要方向之一。该综述为相关领域研究者厘清了体系架构、开放挑战与发展路径。

Abstract: Although Large Language Models (LLMs) exhibit advanced reasoning ability,
conventional alignment remains largely dominated by outcome reward models
(ORMs) that judge only final answers. Process Reward Models(PRMs) address this
gap by evaluating and guiding reasoning at the step or trajectory level. This
survey provides a systematic overview of PRMs through the full loop: how to
generate process data, build PRMs, and use PRMs for test-time scaling and
reinforcement learning. We summarize applications across math, code, text,
multimodal reasoning, robotics, and agents, and review emerging benchmarks. Our
goal is to clarify design spaces, reveal open challenges, and guide future
research toward fine-grained, robust reasoning alignment.

</details>


### [82] [FedDTRE: Federated Dialogue Generation Models Powered by Trustworthiness Evaluation](https://arxiv.org/abs/2510.08058)
*Shule Lu,Lingxiang Wang,Sijia Wen,Ziwei Wang,Hainan Zhang*

Main category: cs.CL

TL;DR: 提出了一种新颖的联邦自适应聚合策略FedDTRE，通过可信度评估动态调节模型贡献，显著提高了对话生成性能，兼顾个性化与全局泛化。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能的发展，对话系统成为人机交互的重要方式。但在隐私保护与个性化之间，传统的集中式和完全本地化训练受制于数据隐私及设备能力差异，难以兼顾两者。联邦学习为此提供了解决思路，然而现有方法面临客户端数据有限导致过拟合，以及多轮训练后全局信息遗忘，泛化能力差的问题。

Method: 提出FedDTRE方法：通过在公平性评价数据上评估全球与本地模型可信度分数，动态调整全局模型在本地更新中的贡献比例，而不是直接用全局模型替换本地模型，从而提升个性化与泛化能力。

Result: 实验结果表明，FedDTRE能够提升对话模型性能和生成对话的质量。

Conclusion: FedDTRE有效改善了联邦学习在对话生成中的过拟合和遗忘问题，实现了更优质、更个性化的对话系统。

Abstract: With the rapid development of artificial intelligence, dialogue systems have
become a prominent form of human-computer interaction. However, traditional
centralized or fully local training approaches face challenges in balancing
privacy preservation and personalization due to data privacy concerns and
heterogeneous device capabilities. Federated learning, as a representative
distributed paradigm, offers a promising solution. However, existing methods
often suffer from overfitting under limited client data and tend to forget
global information after multiple training rounds, leading to poor
generalization. To address these issues, we propose FedDTRE, a Federated
adaptive aggregation strategy for Dialogue generation based on Trustworthiness
Evaluation. Instead of directly replacing local models with the global model,
FedDTRE leverages trustworthiness scores of both global and local models on a
fairness-oriented evaluation dataset to dynamically regulate the global model's
contribution during local updates. Experimental results demonstrate that
FedDTRE can improve dialogue model performance and enhance the quality of
dialogue generation.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [83] [Symmetric Rule-Based Achlioptas Processes for Random $k$-SAT](https://arxiv.org/abs/2510.07870)
*Arnab Chatterjee*

Main category: cs.DM

TL;DR: 提出对称非自适应子句选择规则MIDDLE-HEAVY，用精确分析证明其能提高随机k-SAT可满足性门槛，并通过混合规则保持对称性的同时达到最佳阈值，推动Achlioptas过程在CSP领域的理解。


<details>
  <summary>Details</summary>
Motivation: 受到随机图中“二选一模型”的启发，作者希望通过在线选择有限子句来改变随机k-SAT问题的可满足性门槛，探索Achlioptas过程在随机约束满足问题（CSP）中的新进展。

Method: 提出一种对称、非自适应、与拓扑无关的在线规则“MIDDLE-HEAVY”（优先选择符号分布平衡的子句），结合有偏2-SAT投影和二型分支过程分析，给出门槛的解析表达式；并进一步设计混合对称有偏规则，与已有工作进行对比。

Result: MIDDLE-HEAVY规则可以使随机k-SAT的可满足性门槛$oldsymbol{	ext{SYM}}(k,oldsymbol{	ext{	extl}})$超过传统一阶矩上界。具体地，k=4时只需选择5个子句，k=5选择4个，k≥6选择3个即可超过$2^k 	ext{ln}2$。混合对称有偏规则能达到与前人近似的门槛，同时保持对称性。

Conclusion: 有限子句选择策略，特别是对称平衡规则，能够有效提升随机k-SAT的可满足性门槛。本工作拓展了Achlioptas过程在CSP领域的理论边界，揭示了非图论场景下在线选择的重要作用。

Abstract: Inspired by the "power-of-two-choices" model from random graphs, we
investigate the possibility of limited choices of online clause choices that
could shift the satisfiability threshold in random $k$-SAT.Here, we introduce
an assignment symmetric, non-adaptive, topology-oblivious online rule called
\emph{MIDDLE-HEAVY}, that prioritizes balanced sign profile clauses.Upon
applying a biased $2$-SAT projection and a two-type branching process
certificate, we derive closed-form expressions for the shifted thresholds
$\alpha_{\textbf{SYM}}(k,\ell)$ for this algorithm.We show that minimal choices
$\ell=5$ for $k=4$, $\ell=4$ for $k=5$, and $\ell=3$ for $k\ge 6$ suffice to
exceed the asymptotic first-moment upper bound $\sim 2^k \ln 2$ for random
$k$-SAT.Moreover, to bridge the gap with biased assignment rules used in
maximum of the previous works in this context, we propose a hybrid symmetric
biased rule that achieves thresholds comparable to prior work while maintaining
symmetry.Our results advance the understanding of Achlioptas processes in
random CSPs beyond classical graph-theoretic settings.

</details>


### [84] [A Graph Width Perspective on Partially Ordered Hamiltonian Paths and Cycles II: Vertex and Edge Deletion Numbers](https://arxiv.org/abs/2510.08378)
*Jesse Beisegel,Katharina Klost,Kristin Knorr,Fabienne Ratajczak,Robert Scheffler*

Main category: cs.DM

TL;DR: 本论文研究了带有偏序约束的Hamiltonian路径与回路问题，在多种图参数下刻画了其复杂性：部分参数下问题参数化困难（W[1]-hard或para-NP-hard），部分参数下给出了高效算法（XP时间或FPT），为相关问题的复杂性分析和算法设计提供了参考。


<details>
  <summary>Details</summary>
Motivation: 研究具有顶点集偏序约束的Hamiltonian路径或回路问题，对比普通情况下该问题在某些图宽度参数下属于FPT（固定参数可解）的复杂性。

Method: 分析多种图参数，包括顶点/边距离到特定图类（如路径、团、块等）的复杂性，证明困难性或给出算法，包括W[1]-hard性证明、XP时间算法以及FPT算法等。

Result: 证明在顶点距离到路径、团的情况下问题是W[1]-hard，在顶点距离到外平面图和块的情况下问题可在XP时间内解决。对于边距离到块，提出FPT算法。考虑边团覆盖数时，证明该问题为参数化NP-hard。

Conclusion: 对于具有偏序约束的Hamiltonian路径和回路问题，部分图参数下极难求解，部分可设计高效算法，细致刻画了不同图参数下问题的复杂性边界。

Abstract: We consider the problem of finding a Hamiltonian path or cycle with
precedence constraints in the form of a partial order on the vertex set. We
study the complexity for graph width parameters for which the ordinary problems
$\mathsf{Hamiltonian\ Path}$ and $\mathsf{Hamiltonian\ Cycle}$ are in
$\mathsf{FPT}$. In particular, we focus on parameters that describe how many
vertices and edges have to be deleted to become a member of a certain graph
class. We show that the problems are $\mathsf{W[1]}$-hard for such restricted
cases as vertex distance to path and vertex distance to clique. We complement
these results by showing that the problems can be solved in $\mathsf{XP}$ time
for vertex distance to outerplanar and vertex distance to block. Furthermore,
we present some $\mathsf{FPT}$ algorithms, e.g., for edge distance to block.
Additionally, we prove para-$\mathsf{NP}$-hardness when considered with the
edge clique cover number.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [85] [Languages of Words of Low Automatic Complexity Are Hard to Compute](https://arxiv.org/abs/2510.07696)
*Joey Chen,Bjørn Kjos-Hanssen,Ivan Koswara,Linus Richter,Frank Stephan*

Main category: cs.FL

TL;DR: 提出并研究了非确定性自动机下的精确自动复杂性，定义了低复杂性语言L_q，证明其既不是上下文无关语言，也无法用特定Boolean电路识别，解决了开放性问题并证明相关Shannon效应。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究有限字的自动复杂性，关注非确定性自动机的精确自动复杂性。此前，Kjos-Hanssen提出了相关集合的复杂性问题，其中对Boolean电路的可判别性提出了开放性问题。作者希望解答这个问题，同时推广与改进相关定义。

Method: 作者通过分析非确定性自动机的性质，定义了精确非确定性自动复杂性A_{Ne}，并以此为基础，构造语言类L_q，进一步探讨这些语言的句法复杂性与电路复杂性，结合有限自动机理论和电路复杂性理论开展证明。

Result: 发现对于任何q∈(0,1/2)，L_q既不是上下文无关语言，也无法被特定类型Boolean电路识别。同时，解决了Kjos-Hanssen关于L_{1/3}的开放性问题，并在A_{Ne}意义下证明了Shannon效应。

Conclusion: 本文拓展并加深了对字串自动复杂性的理解，明确了低A_{Ne}复杂性语言类的基本复杂性特征，证实了其超越上下文无关和电路可判别的边界，丰富了自动机与复杂性领域的理论基础。

Abstract: The automatic complexity of a finite word (string) is an analogue for finite
automata of Sipser's distinguishing complexity (1983) and was introduced by
Shallit and Wang (2001). For a finite alphabet $\Sigma$ of at least two
elements, we consider the non-deterministic automatic complexity given by
exactly - yet not necessarily uniquely - accepting automata: a word $x \in
\Sigma^*$ has exact non-deterministic automatic complexity $k \in \mathbb{N}$
if there exists a non-deterministic automaton of $k$ states which accepts $x$
while rejecting every other word of the same length as $x$, and no automaton of
fewer states has this property. Importantly, and in contrast to the classical
notion, the witnessing automaton may have multiple paths of computation
accepting $x$. We denote this measure of complexity by $A_{Ne}$, and study a
class of languages of low $A_{Ne}$-complexity defined as $L_q = \{ \, x \in
\Sigma^* : A_{Ne}(x) < q|x| \, \}$, which is parameterised by rationals $q \in
(0,1/2)$ (generalising a class of sets first studied by Kjos-Hanssen). We show
that for every $q \in (0,1/2)$, this class is neither context-free nor
recognisable by certain Boolean circuits. In the process, we answer an open
question of Kjos-Hanssen quantifying the complexity of $L_{1/3}$ in terms of
Boolean circuits, and also prove the Shannon effect for $A_{Ne}$.

</details>


### [86] [On the Complexity of Language Membership for Probabilistic Words](https://arxiv.org/abs/2510.08127)
*Antoine Amarilli,Mikaël Monet,Paul Raphaël,Sylvain Salvati*

Main category: cs.FL

TL;DR: 论文系统研究了在概率性单词上上下文无关语言的成员概率计算问题，发现对部分语言（如不歧义CFL及其扩展类）可多项式时间解决，对部分（如并、计数自动机）为#P-hard，并提出知识编译电路工具以扩展 tractability 范围，同时表明在一般CFG下该问题具条件不可判定性。


<details>
  <summary>Details</summary>
Motivation: 研究给定上下文无关语言（CFL），在概率性单词（每个位置字母有概率分布，且位置相互独立）上的成员问题，即计算按照概率分布抽取的单词属于该语言的概率。此问题泛化了已知长度词计数和局部词补全问题。

Method: 分析不同类型的CFL在概率性单词上的成员问题复杂度，包括不歧义CFL、线性CFL等，并利用知识编译中的电路理论来实现可计数性。此外，研究扩展后的电路（包含否定）的应用范围，涉及具体语言如原生词和回文串拼接。最后探讨给定CFG下该成员问题的可判定性。

Result: 对于不歧义CFL和多项式分片不歧义语言，该问题可在多项式时间内解决，但对两个线性不歧义CFL的并甚至可能为#P-hard。对非确定计数自动机（如单计数Parikh自动机）同样为#P-hard。利用电路结构可覆盖部分非分片不歧义CFL的可 tractability。扩展电路包含否定后，可证明原生词和回文拼接语言的可 tractability。元问题在一般情况下具条件不可判定性。

Conclusion: 概率性单词上的CFL成员问题在部分语言类上具 tractability（可在多项式时间解决），但部分类（如非确定计数自动机等）为#P-hard，且一般情况下判定 CFG 的可 tractability 问题具条件不可判定性。

Abstract: We study the membership problem to context-free languages L (CFLs) on
probabilistic words, that specify for each position a probability distribution
on the letters (assuming independence across positions). Our task is to
compute, given a probabilistic word, what is the probability that a word drawn
according to the distribution belongs to L. This problem generalizes the
problem of counting how many words of length n belong to L, or of counting how
many completions of a partial word belong to L.
  We show that this problem is in polynomial time for unambiguous context-free
languages (uCFLs), but can be #P-hard already for unions of two linear uCFLs.
More generally, we show that the problem is in polynomial time for so-called
poly-slicewise-unambiguous languages, where given a length n we can tractably
compute an uCFL for the words of length n in the language. This class includes
some inherently ambiguous languages, and implies the tractability of bounded
CFLs and of languages recognized by unambiguous polynomial-time counter
automata; but we show that the problem can be #P-hard for nondeterministic
counter automata, even for Parikh automata with a single counter. We then
introduce classes of circuits from knowledge compilation which we use for
tractable counting, and show that this covers the tractability of
poly-slicewise-unambiguous languages and of some CFLs that are not
poly-slicewise-unambiguous. Extending these circuits with negation further
allows us to show tractability for the language of primitive words, and for the
language of concatenations of two palindromes. We finally show the conditional
undecidability of the meta-problem that asks, given a CFG, whether the
probabilistic membership problem for that CFG is tractable or #P-hard.

</details>
