<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 7]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.CL](#cs.CL) [Total: 2]
- [cs.DM](#cs.DM) [Total: 1]
- [cs.FL](#cs.FL) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Modular abstract syntax trees (MAST): substitution tensors with second-class sorts](https://arxiv.org/abs/2511.03946)
*Marcelo P. Fiore,Ohad Kammar,Georg Moser,Sam Staton*

Main category: cs.PL

TL;DR: 本文将抽象语法理论推广到支持二级类别限制的编程语言，对CBV等模型建立了新的语法基础，并通过bicategorical方法重现理论发展，证明了替换相关引理。


<details>
  <summary>Details</summary>
Motivation: 现有的抽象语法理论（如Fiore等人的方法）不能很好地处理带有二级类别（second-class sorts）的编程语言，例如CBV和CBPV。因为这些语言中，二级类别不能出现在变量上下文中，这改变了语法的刻画方式，现有理论需要扩展或调整。

Method: 将Fiore等人关于抽象语法（含绑定、替换、空洞）的理论推广到带有二级类别的语言。具体方法是：使用actegories中actions的刻画方式替代monoidal categories中的monoids，同时采用二范畴（bicategorical）论证来重现大部分发展。原理论许多结论通过新范畴工具加以再现和推广。

Result: 提出了支持带二级类别新抽象语法的理论体系，并用此理论证明了多种CBV情形下的替换引理（substitution lemma）。

Conclusion: 扩展了抽象语法理论，为具有二级类别限制的编程语言（如CBV和CBPV）提供了统一的语法处理方式，并成功推广和再现了原有理论下的重要性质。

Abstract: We adapt Fiore, Plotkin, and Turi's treatment of abstract syntax with
binding, substitution, and holes to account for languages with second-class
sorts. These situations include programming calculi such as the Call-by-Value
lambda-calculus (CBV) and Levy's Call-by-Push-Value (CBPV). Prohibiting
second-class sorts from appearing in variable contexts changes the
characterisation of the abstract syntax from monoids in monoidal categories to
actions in actegories. We reproduce much of the development through
bicategorical arguments. We apply the resulting theory by proving substitution
lemmata for varieties of CBV.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [Tutorial Debriefing: Applied Statistical Causal Inference in Requirements Engineering](https://arxiv.org/abs/2511.03875)
*Julian Frattini,Hans-Martin Heyn,Robert Feldt,Richard Torkar*

Main category: cs.SE

TL;DR: 软件工程要推动科研成果落地，必须验证工具或方法的因果效应。受控实验虽理想，但实际常受限制，因此需要采取统计因果推断，从观测数据中作有效因果分析。


<details>
  <summary>Details</summary>
Motivation: 软件工程研究希望将科研成果有效地转化为实际应用，提升软件开发者和用户的体验和效能。为了验证研究贡献的实际价值，需要明确工具、流程或指导如何真正改善相关指标。

Method: 传统方法是采用随机分组的受控实验，但在法律、伦理或实际操作上并非总是可行。因此，论文提出在无法做随机实验时，需要可靠的统计因果推断过程，利用观测数据分析因果关系。

Result: 强调因果关系证据对于科研成果转化为实践的重要性，为无法进行受控实验情况下的因果推断提出需求。

Conclusion: 论文指出，为使软件工程的研究成果更好地应用于实际，需要发展并采用可靠的统计因果推断方法，以弥补受控实验不可实施的局限。

Abstract: As any scientific discipline, the software engineering (SE) research
community strives to contribute to the betterment of the target population of
our research: software producers and consumers. We will only achieve this
betterment if we manage to transfer the knowledge acquired during research into
practice. This transferal of knowledge may come in the form of tools,
processes, and guidelines for software developers. However, the value of these
contributions hinges on the assumption that applying them causes an improvement
of the development process, user experience, or other performance metrics. Such
a promise requires evidence of causal relationships between an exposure or
intervention (i.e., the contributed tool, process or guideline) and an outcome
(i.e., performance metrics). A straight-forward approach to obtaining this
evidence is via controlled experiments in which a sample of a population is
randomly divided into a group exposed to the new tool, process, or guideline,
and a control group. However, such randomized control trials may not be
legally, ethically, or logistically feasible. In these cases, we need a
reliable process for statistical causal inference (SCI) from observational
data.

</details>


### [3] [Collaborative Agents for Automated Program Repair in Ruby](https://arxiv.org/abs/2511.03925)
*Nikta Akbarpour,Mahdieh Sadat Benis,Fatemeh Hendijani Fard,Ali Ouni,Mohamed Aymen Saied*

Main category: cs.SE

TL;DR: RAMP是一种对Ruby高效自动修复程序错误的轻量框架，通过多代理协作、测试生成和自反思机制实现高修复率，且无需庞大数据或微调，极大提升对Ruby等冷门语言的修复能力。


<details>
  <summary>Details</summary>
Motivation: 现有自动程序修复（APR）方法主要集中在少数几种语言上，并且大多计算开销高。尽管Ruby在Web开发中被广泛使用，但在APR研究中却鲜有关注。

Method: 提出RAMP，一个针对Ruby的轻量级自动程序修复框架。RAMP采用多智能体协作，通过生成针对性测试、自我反思和迭代修复，逐步找到正确修复方案。RAMP不依赖于大型多语言数据库或昂贵的微调过程，而是通过轻量化提示和测试反馈直接在Ruby上运行。

Result: 在XCodeEval基准测试上的pass@1达到67%，优于以往方法。RAMP平均在五次迭代内收敛，消融实验表明测试生成和自反思机制对性能至关重要。进一步分析显示，RAMP对错误答案、编译错误和运行时错误有较好修复效果。

Conclusion: RAMP为多智能体修复策略提供新视角，并为拓展LLM驱动的调试工具到更少研究的语言奠定基础。

Abstract: Automated Program Repair (APR) has advanced rapidly with Large Language
Models (LLMs), but most existing methods remain computationally expensive, and
focused on a small set of languages. Ruby, despite its widespread use in web
development and the persistent challenges faced by its developers, has received
little attention in APR research. In this paper, we introduce RAMP, a novel
lightweight framework that formulates program repair as a feedback-driven,
iterative process for Ruby. RAMP employs a team of collaborative agents that
generate targeted tests, reflect on errors, and refine candidate fixes until a
correct solution is found. Unlike prior approaches, RAMP is designed to avoid
reliance on large multilingual repair databases or costly fine-tuning, instead
operating directly on Ruby through lightweight prompting and test-driven
feedback. Evaluation on the XCodeEval benchmark shows that RAMP achieves a
pass@1 of 67% on Ruby, outper-forming prior approaches. RAMP converges quickly
within five iterations, and ablation studies confirm that test generation and
self-reflection are key drivers of its performance. Further analysis shows that
RAMP is particularly effective at repairing wrong answers, compilation errors,
and runtime errors. Our approach provides new insights into multi-agent repair
strategies, and establishes a foundation for extending LLM-based debugging
tools to under-studied languages.

</details>


### [4] [PEFA-AI: Advancing Open-source LLMs for RTL generation using Progressive Error Feedback Agentic-AI](https://arxiv.org/abs/2511.03934)
*Athma Narayanan,Mahesh Subedar,Omesh Tickoo*

Main category: cs.SE

TL;DR: 本文提出多智能体LLM+仿真工具协作、并融合渐进式错误反馈的自动RTL生成方案，无需人工干预，在准确率、token效率上超过现有方法，推动EDA自动化进步。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的自然语言到RTL代码生成方法，在准确性和自动化程度上存在一定局限，且难以实现完全无人干预。提升生成流程的自适应能力和调优精度，成为推动EDA自动化的重要需求。

Method: 提出了一套多智能体协作流程，将专用大语言模型（LLM）与硬件仿真工具结合，实现无需人工干预的RTL生成。核心创新为多智能体渐进式错误反馈系统（PEFA），通过迭代性错误回馈机制，不断提升代码正确率和复杂度。此外，流程内含代码编译、功能正确性与合成结构检测。基于两个自然语言到RTL的开源数据集进行实验验证，并使用开源与闭源LLM对比测试。

Result: 所提方法在通过率和token效率上均创新高，实现SOTA表现，有效缩小了开源与闭源大语言模型在此任务上的性能差距。

Conclusion: 多智能体渐进式错误反馈+硬件仿真工具结合框架能显著提升RTL自动生成的准确性与效率，为硬件设计自动化提供了新范式。

Abstract: We present an agentic flow consisting of multiple agents that combine
specialized LLMs and hardware simulation tools to collaboratively complete the
complex task of Register Transfer Level (RTL) generation without human
intervention. A key feature of the proposed flow is the progressive error
feedback system of agents (PEFA), a self-correcting mechanism that leverages
iterative error feedback to progressively increase the complexity of the
approach. The generated RTL includes checks for compilation, functional
correctness, and synthesizable constructs. To validate this adaptive approach
to code generation, benchmarking is performed using two opensource natural
language-to-RTL datasets. We demonstrate the benefits of the proposed approach
implemented on an open source agentic framework, using both open- and
closed-source LLMs, effectively bridging the performance gap between them.
Compared to previously published methods, our approach sets a new benchmark,
providing state-of-the-art pass rates while being efficient in token counts.

</details>


### [5] [PSD2Code: Automated Front-End Code Generation from Design Files via Multimodal Large Language Models](https://arxiv.org/abs/2511.04012)
*Yongxi Chen,Lei Chen*

Main category: cs.SE

TL;DR: 本文提出了PSD2Code方法，通过解析和对齐PSD设计文件，有效提升了前端代码生成的一致性、可用性和量产准备度，在多项指标显著优于传统方法，是设计自动化到代码转化领域的重要进展。


<details>
  <summary>Details</summary>
Motivation: 现有的设计到代码生成方法存在结构不一致、资源错位、和量产准备度低等问题，无法很好地从设计原型高效生成可用的前端代码。

Method: 提出了一种新的多模态方法PSD2Code，结合PSD文件解析和资源对齐，采用ParseAlignGenerate流水线，从PSD文件中提取层级结构、属性和元数据，并用约束驱动的对齐策略和结构化提示，对前端代码进行高质量、可控地生成。

Result: 在代码相似度、视觉保真度和量产准备度等多个指标上，PSD2Code方法相较现有方法有显著提升。方法在不同大语言模型下表现出较好的模型独立性。

Conclusion: 将结构化设计信息与多模态大语言模型结合，能有效提升前端自动化代码生成，为设计驱动的自动化前端开发迈出关键一步。

Abstract: Design-to-code generation has emerged as a promising approach to bridge the
gap between design prototypes and deployable frontend code. However, existing
methods often suffer from structural inconsistencies, asset misalignment, and
limited production readiness. This paper presents PSD2Code, a novel multi-modal
approach that leverages PSD file parsing and asset alignment to generate
production-ready React+SCSS code. Our method introduces a ParseAlignGenerate
pipeline that extracts hierarchical structures, layer properties, and metadata
from PSD files, providing large language models with precise spatial
relationships and semantic groupings for frontend code generation. The system
employs a constraint-based alignment strategy that ensures consistency between
generated elements and design resources, while a structured prompt construction
enhances controllability and code quality. Comprehensive evaluation
demonstrates significant improvements over existing methods across multiple
metrics including code similarity, visual fidelity, and production readiness.
The method exhibits strong model independence across different large language
models, validating the effectiveness of integrating structured design
information with multimodal large language models for industrial-grade code
generation, marking an important step toward design-driven automated frontend
development.

</details>


### [6] [Specification-Guided Vulnerability Detection with Large Language Models](https://arxiv.org/abs/2511.04014)
*Hao Zhu,Jia Li,Cuiyun Gao,Jiaru Qian,Yihong Dong,Huanyu Liu,Lecheng Wang,Ziliang Wang,Xiaolong Hu,Ge Li*

Main category: cs.SE

TL;DR: 本文提出VulInstruct方法，通过提取和利用安全规范大幅提升了大模型在代码漏洞检测中的性能，实现了准确率和实际应用能力的突破。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在代码理解方面表现优异，但在漏洞检测任务上表现有限，难以区分存在漏洞的代码和已修补的代码。论文认为主要原因是LLMs缺乏对安全规范的理解，即代码应遵循的行为预期。考虑到这些知识在训练数据中很少显式体现，模型难以推理出潜在的安全缺陷。

Method: 作者提出了VulInstruct方法，通过系统地从历史漏洞中提取安全规范，以指导漏洞检测。VulInstruct从两个方面构建安全规范知识库：（1）从各项目中的高质量补丁提取通用安全规范，涵盖基本的安全行为；（2）从特定代码仓库中反复出现的违规案例中提取领域特定规范。该方法会检索相关历史案例和规范，使LLMs能够依据期望的安全行为进行推理，而不仅仅依赖表面模式。

Result: 在PrimeVul测试集上，VulInstruct达到了45.0%的F1分数（提升32.7%），召回率为37.7%（提升50.8%），独特检测率为24.3%，是基准方法2.4倍。配对评价中相对提升32.3%。此外，VulInstruct还发现了一个高危新漏洞（CVE-2025-56538），显示了实际应用价值。

Conclusion: 安全规范的引入显著提升了LLMs在漏洞检测的准确性与实用性，VulInstruct为代码安全检测任务提供了一种可行且高效的方法。

Abstract: Large language models (LLMs) have achieved remarkable progress in code
understanding tasks. However, they demonstrate limited performance in
vulnerability detection and struggle to distinguish vulnerable code from
patched code. We argue that LLMs lack understanding of security specifications
-- the expectations about how code should behave to remain safe. When code
behavior differs from these expectations, it becomes a potential vulnerability.
However, such knowledge is rarely explicit in training data, leaving models
unable to reason about security flaws. We propose VulInstruct, a
specification-guided approach that systematically extracts security
specifications from historical vulnerabilities to detect new ones. VulInstruct
constructs a specification knowledge base from two perspectives: (i) General
specifications from high-quality patches across projects, capturing fundamental
safe behaviors; and (ii) Domain-specific specifications from repeated
violations in particular repositories relevant to the target code. VulInstruct
retrieves relevant past cases and specifications, enabling LLMs to reason about
expected safe behaviors rather than relying on surface patterns. We evaluate
VulInstruct under strict criteria requiring both correct predictions and valid
reasoning. On PrimeVul, VulInstruct achieves 45.0% F1-score (32.7% improvement)
and 37.7% recall (50.8% improvement) compared to baselines, while uniquely
detecting 24.3% of vulnerabilities -- 2.4x more than any baseline. In pair-wise
evaluation, VulInstruct achieves 32.3% relative improvement. VulInstruct also
discovered a previously unknown high-severity vulnerability (CVE-2025-56538) in
production code, demonstrating practical value for real-world vulnerability
discovery. All code and supplementary materials are available at
https://github.com/zhuhaopku/VulInstruct-temp.

</details>


### [7] [How Natural Language Proficiency Shapes GenAI Code for Software Engineering Tasks](https://arxiv.org/abs/2511.04115)
*Ruksit Rojpaisarnkit,Youmei Fan,Kenichi Matsumoto,Raula Gaikovina Kula*

Main category: cs.SE

TL;DR: 输入提示的英语水平越高，大模型生成的代码越正确稳定，开发者应重视自然语言表达能力以提升AI编程辅助的实际效果。


<details>
  <summary>Details</summary>
Motivation: 尽管目前软件工程领域广泛采用了由基础模型（FM）驱动的工具，但关于自然语言输入的英语语言能力对大模型代码生成质量的影响仍缺乏系统性研究，现有工作主要关注提示结构。本研究动机是探究输入者的英语语言水平是否会影响大模型生成代码的质量和正确性。

Method: 使用HumanEval数据集，对164个编程任务设计不同英语水平（从基础到高级）的提示，系统性评估各级提示下LLMs生成代码的专业性和正确性。

Result: 发现大语言模型默认采用中级（B2）英语水平生成内容。高水平英语提示在所有模型中都能显著提升代码正确性，代码质量的改进则依赖具体模型。

Conclusion: 自然语言输入的英语语言水平对代码生成的正确性具有重要影响，开发者可通过提升语言表达能力来优化AI代码输出的可靠性和质量。

Abstract: With the widespread adoption of Foundation Model (FM)-powered tools in
software engineering, the natural language prompt has become a critical
interface between developers and Large Language Models (LLMs). While much
research has focused on prompt structure, the natural language proficiency is
an underexplored factor that can influence the quality of generated code. This
paper investigates whether the English language proficiency itself independent
of the prompting technique affects the proficiency and correctness of code
generated by LLMs. Using the HumanEval dataset, we systematically varied the
English proficiency of prompts from basic to advanced for 164 programming tasks
and measured the resulting code proficiency and correctness. Our findings show
that LLMs default to an intermediate (B2) natural language level. While the
effect on the resulting code proficiency was model-dependent, we found that
higher-proficiency prompts consistently yielded more correct code across all
models. These results demonstrate that natural language proficiency is a key
lever for controlling code generation, helping developers tailor AI output and
improve the reliability of solutions.

</details>


### [8] [LLM-Driven Adaptive Source-Sink Identification and False Positive Mitigation for Static Analysis](https://arxiv.org/abs/2511.04023)
*Shiyin Lin*

Main category: cs.SE

TL;DR: AdaTaint结合LLM和符号分析，有效降低误报并提升召回率，实用性强。


<details>
  <summary>Details</summary>
Motivation: 静态分析常因源-汇规格不完整带来误报率高（大量假阳性），影响其发现软件漏洞的实际效果。

Method: 提出了AdaTaint框架，采用神经-符号推理，利用LLM自适应推断源/汇点规格，并通过程序事实和约束验证对其进行过滤和验证。该方法在分析过程中既保证适应性，又保证了确定性。

Result: 在Juliet 1.3、SV-COMP风格C基准和三个实际大型项目上，AdaTaint的误报率平均下降了43.7%，召回率提高了11.2%，且运行时开销可接受，比当前最优工具更优。

Conclusion: 将大语言模型（LLM）的推断与符号验证结合，可以切实提升静态漏洞分析的准确性和可靠性。

Abstract: Static analysis is effective for discovering software vulnerabilities but
notoriously suffers from incomplete source--sink specifications and excessive
false positives (FPs). We present \textsc{AdaTaint}, an LLM-driven taint
analysis framework that adaptively infers source/sink specifications and
filters spurious alerts through neuro-symbolic reasoning. Unlike LLM-only
detectors, \textsc{AdaTaint} grounds model suggestions in program facts and
constraint validation, ensuring both adaptability and determinism.
  We evaluate \textsc{AdaTaint} on Juliet 1.3, SV-COMP-style C benchmarks, and
three large real-world projects. Results show that \textsc{AdaTaint} reduces
false positives by \textbf{43.7\%} on average and improves recall by
\textbf{11.2\%} compared to state-of-the-art baselines (CodeQL, Joern, and
LLM-only pipelines), while maintaining competitive runtime overhead. These
findings demonstrate that combining LLM inference with symbolic validation
offers a practical path toward more accurate and reliable static vulnerability
analysis.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [9] [An Automated Theorem Generator with Theoretical Foundation Based on Rectangular Standard Contradiction](https://arxiv.org/abs/2511.04092)
*Yang Xu,Peiyao Liu,Shuwei Chen,Jun Liu*

Main category: cs.LO

TL;DR: 本研究首次提出并论证了矩形标准矛盾结构，围绕其性质构建了完整的自动化定理生成理论，开发了高效生成工具，使机器能系统性地发现新定理，为逻辑与AI研究带来新突破。


<details>
  <summary>Details</summary>
Motivation: 目前系统性、自动化地产生非平凡且逻辑有效定理缺乏严密方法，限制了机器从验证者到发现者的转变，迫切需要构建自动化定理生成的理论与工具。

Method: 以标准矛盾为基础，首次定义并证明了矩形标准矛盾的逻辑结构，论证了其必要不可满足性与非冗余性，并基于此理论设计高效模板化自动化定理生成算法，开发了相应生成器工具。

Result: 提出了一种新颖的自动化定理生成理论与工具。矩形标准矛盾具备不可满足性和非冗余性，可以系统性地产生逻辑等价的新定理。理论支持下实现了算法和工具，并推动了逻辑和人工智能基础研究。

Conclusion: 本研究提出了矩形标准矛盾的理论体系，并证明其核心性质，用于构建完整的自动化定理生成理论。矩形标准矛盾划分后可以系统性地产生非平凡且有效的新定理。

Abstract: Currently, there is a lack of rigorous theoretical system for systematically
generating non-trivial and logically valid theorems. Addressing this critical
gap, this paper conducts research to propose a novel automated theorem
generation theory and tool. Based on the concept of standard contradiction
which possesses unique deductive advantages, this paper defines and proves, for
the first time, a new logical structure known as rectangular standard
contradiction. Centered on this structure, a complete Automated Theorem
Generation (ATG) theory is put forward. Theoretical proofs clarify two core
properties of rectangular standard contradiction: first, it is a standard
contradiction (necessarily unsatisfiable); second, it exhibits non-redundancy
(the remaining clause set becomes satisfiable after removing any clause).
Leveraging these properties, this paper proves that partitioning a rectangular
standard contradiction into a premise subset $A$ and negation of its complement
$H$, a valid theorem $A \vdash \neg H$ can be formed, and all such theorems are
logically equivalent. To implement this theory, an efficient template-based ATG
algorithm is designed, and a Rectangular Automated Theorem Generator is
developed. This research enables machines to transition from "verifiers" to
"discoverers", opening up new avenues for fundamental research in the fields of
logic and artificial intelligence.

</details>


### [10] [Compact Quantitative Theories of Convex Algebras](https://arxiv.org/abs/2511.04201)
*Matteo Mio*

Main category: cs.LO

TL;DR: 本文提出了紧致定量方程理论概念，并证明了插值重心（凸）定量代数理论的紧致性，为相关概率分布距离的定量理论的有限可证明性提供了理论基础和范例。


<details>
  <summary>Details</summary>
Motivation: 定量方程理论在理论计算机科学和概率逻辑等领域有广泛应用，但它们的推理过程可能涉及无限证明，导致可操作性和应用受限，因此有必要研究何种定量方程理论能通过有限证明推导全部结论。

Method: 提出了“紧致定量方程理论”这一概念，并研究并证明了Mardare等人的插值重心（凸）定量代数理论的紧致性。通过对这种特定代数结构推导性质的分析，展示了有限证明能力。

Result: 证明了Mardare等人的插值重心（凸）定量代数的理论是紧致的，即其所有结论都可用有限的证明推导得出。同时，这成为探索其它与凸代数相关、描述有限支持概率分布距离的定量方程理论紧致性的范例。

Conclusion: 插值重心（凸）定量代数理论的所有推论都可以通过有限证明导出，这一性质可推广应用到更多涉及概率分布距离的凸代数量理论中。

Abstract: We introduce the concept of compact quantitative equational theory. A
quantitative equational theory is defined to be compact if all its consequences
are derivable by means of finite proofs. We prove that the theory of
interpolative barycentric (also known as convex) quantitative algebras of
Mardare et. al. is compact. This serves as a paradigmatic example, used to
obtain other compact quantitative equational theories of convex algebras, each
axiomatizing some distance on finitely supported probability distributions.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [11] [Activation-Space Personality Steering: Hybrid Layer Selection for Stable Trait Control in LLMs](https://arxiv.org/abs/2511.03738)
*Pranav Bhandari,Nicolas Fay,Sanjeevan Selvaganapathy,Amitava Datta,Usman Naseem,Mehwish Nasim*

Main category: cs.CL

TL;DR: 本文提出了一种结合大五人格理论与低秩子空间发现的LLM人格引导方法，通过动态层注入，实现精准的人格控制，同时不影响文本质量，为模型行为对齐提供了实用机制。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成文本时展示出隐含的人格特征，但如何可靠地控制和调整这些特质以满足特定需求，仍然是未解决的难题。现有文献在模型行为控制机制上存在明显空白，需要填补。人格感知型语言模型被认为可能是实现这一目标的有希望方向。

Method: 提出了一种新颖的方法管道：提取transformer层的隐藏状态激活，并结合“大五人格”理论（开放性、尽责性、外向性、宜人性和神经质）进行低秩子空间发现，识别不同模型架构中与每种人格特质相关的最优层。进一步通过动态层选择，将人格趋向的对齐方向应用于模型的行为引导，实现灵活精确地控制生成文本的人格特质。

Result: 研究发现人格特质在模型中占据一个低秩共享子空间，这些潜在结构可以转化为有效的模型行为引导机制，通过对隐藏状态的精细扰动，能够有效控制LLM的人格表现，而不会影响文本的流畅性、多样性和模型的通用能力。

Conclusion: 本工作提出并实验证明了一种基于低秩子空间和动态层选择的人格对齐与引导方法，实现了对LLM人格特质的精确操控，为心理学理论和实际模型对齐之间的桥接带来了新思路和工具。

Abstract: Large Language Models exhibit implicit personalities in their generation, but
reliably controlling or aligning these traits to meet specific needs remains an
open challenge. The need for effective mechanisms for behavioural manipulation
of the model during generation is a critical gap in the literature that needs
to be fulfilled. Personality-aware LLMs hold a promising direction towards this
objective. However, the relationship between these psychological constructs and
their representations within LLMs remains underexplored and requires further
investigation. Moreover, it is intriguing to understand and study the use of
these representations to steer the models' behaviour. We propose a novel
pipeline that extracts hidden state activations from transformer layers using
the Big Five Personality Traits (Openness, Conscientiousness, Extraversion,
Agreeableness and Neuroticism), which is a comprehensive and empirically
validated framework to model human personality applies low-rank subspace
discovery methods, and identifies trait-specific optimal layers across
different model architectures for robust injection. The resulting
personality-aligned directions are then operationalised through a flexible
steering framework with dynamic layer selection, enabling precise control of
trait expression in LLM outputs. Our findings reveal that personality traits
occupy a low-rank shared subspace, and that these latent structures can be
transformed into actionable mechanisms for effective steering through careful
perturbations without impacting the fluency, variance and general capabilities,
helping to bridge the gap between psychological theory and practical model
alignment.

</details>


### [12] [TextualVerifier: Verify TextGrad Step-by-Step](https://arxiv.org/abs/2511.03739)
*Eugenius Mario Situmorang,Adila Alfa Krisnadhi,Ari Wibisono*

Main category: cs.CL

TL;DR: 本文提出了TextualVerifier框架，结合大语言模型的链式推理和多数投票，有效提升了TextGrad系统的文本推理自我验证能力和优化结果准确性，在多个基准测试中获得显著提升。


<details>
  <summary>Details</summary>
Motivation: TextGrad已能实现基于文本的自动微分优化，但缺乏自我验证机制，难以确保推理和决策的有效性。本研究旨在填补这一验证空白。

Method: 设计了TextualVerifier框架，包含四个阶段：链式推理分解（chain-of-thought decomposition）、变体生成（variant generation）、多数投票（majority voting）以及共识聚合（consensus aggregation），并在两个实验阶段（独立和集成）使用Gemini 1.5 Pro进行评估。

Result: 实验结果显示，在独立验证阶段有效性提升29%；集成至TextGrad损失函数后准确率提升2.2个百分点，且平均调用次数增加适度（5.9次）。在GPQA、MMLU-ML、MMLU-CP的集成评测中分别提升8.08、10.71、3.92个百分点。

Conclusion: TextualVerifier为TextGrad提供了首个基于大语言模型（LLM）的自我验证框架，无需依赖数值梯度，实现了更加可靠的文本推理和优化过程。

Abstract: TextGrad is a novel approach to text-based automatic differentiation that
enables composite AI systems to perform optimization without explicit numerical
equations. However, it currently lacks self-verification mechanisms that ensure
reasoning validity in text-based decision making. This research introduces
TextualVerifier, a verification framework that leverages chain-of-thought
reasoning and majority voting with large language models to address this
verification gap. TextualVerifier implements a four-stage workflow:
chain-of-thought decomposition, variant generation, majority voting, and
consensus aggregation. It integrates non-invasively with TextGrad at both the
loss function and optimization result verification stages. Experimental
evaluation using the Gemini 1.5 Pro model is conducted in two phases: (1)
standalone evaluation on PRM800K, and (2) integrated evaluation with TextGrad
on GPQA-Diamond, MMLU-ML, and MMLU-CP benchmarks. Results show statistically
significant improvements (p < 0.001). In phase one, TextualVerifier improves
the validity of reasoning steps by 29 percent. In phase two, integration into
TextGrad loss function yields a 2.2 percentage point gain from 68.2 to 70.4
percent with a moderate overhead of 5.9 LLM calls on average. Further
evaluations of TextualVerifier versioning yield 8.08, 10.71, and 3.92
percentage point improvements on GPQA, MMLU-ML, and MMLU-CP respectively.
TextualVerifier thus presents the first self-verification framework for
TextGrad through LLM-based techniques without requiring numerical gradients,
enabling more reliable reasoning and opening new directions for verification in
text-based optimization.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [13] [Induced matching treewidth and tree-independence number, revisited](https://arxiv.org/abs/2511.03864)
*Noga Alon,Martin Milanič,Paweł Rzążewski*

Main category: cs.DM

TL;DR: 作者研究了tree-independence number 和 induced matching treewidth 两个通过树分解定义的图参数，证明对于不含固定二分团的图，这两个参数之间有多项式关联，而不是之前认为的指数关联。


<details>
  <summary>Details</summary>
Motivation: 论文关注于图分解相关的两个图参数：tree-independence number（树独立数）和induced matching treewidth（诱导匹配树宽）。其动机在于了解这些参数之间的关系，尤其在某些特殊图类（如不含固定二分团作为诱导子图的图）下的性质。

Method: 文章通过定义这两个参数，并比较它们在不同类型图上的界；其中关键方法包括应用Kovari-Sos-Turan定理以及对比已有利用Ramsey定理的方法。

Result: 作者证明了对于所有$K_{t,t}$-free图类，这两个参数之间实际上存在线性多项式界联系，而不是像之前工作中那样是指数级别的。

Conclusion: 本文大大改进了$K_{t,t}$-free图类下tree-independence number与induced matching treewidth之间的关系界，将其从指数级优化到多项式级，为相关图参数的研究提供了更精细化的理论基础。

Abstract: We study two graph parameters defined via tree decompositions:
tree-independence number and induced matching treewidth. Both parameters are
defined similarly as treewidth, but with respect to different measures of a
tree decomposition $\mathcal{T}$ of a graph $G$: for tree-independence number,
the measure is the maximum size of an independent set in $G$ included in some
bag of $\mathcal{T}$, while for the induced matching treewidth, the measure is
the maximum size of an induced matching in $G$ such that some bag of
$\mathcal{T}$ contains at least one endpoint of every edge of the matching.
  While the induced matching treewidth of any graph is bounded from above by
its tree-independence number, the family of complete bipartite graphs shows
that small induced matching treewidth does not imply small tree-independence
number. On the other hand, Abrishami, Bria\'nski, Czy\.zewska, McCarty,
Milani\v{c}, Rz\k{a}\.zewski, and Walczak~[SIAM Journal on Discrete
Mathematics, 2025] showed that, if a fixed biclique $K_{t,t}$ is excluded as an
induced subgraph, then the tree-independence number is bounded from above by
some function of the induced matching treewidth. The function resulting from
their proof is exponential even for fixed $t$, as it relies on multiple
applications of Ramsey's theorem. In this note we show, using the
K\"ov\'ari-S\'os-Tur\'an theorem, that for any class of $K_{t,t}$-free graphs,
the two parameters are in fact polynomially related.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [14] [State Complexity of Multiple Concatenation](https://arxiv.org/abs/2511.03814)
*Jozef Jirásek,Galina Jirásková*

Main category: cs.FL

TL;DR: 以更简单的方法证明了多重正则连接的状态复杂性上界，并解决了字母表大小最优相关公开问题；针对多种特殊语言均给出了紧上界或下界。


<details>
  <summary>Details</summary>
Motivation: 之前文献在多重连接（multiple concatenation）下 $k$ 个正则语言状态复杂性的上界证明较为复杂，并且关于字母表大小的相关问题尚未解决，特别是由 Caron 等人在 2018 年提出的公开问题。

Method: 作者提出了一种显著更加简单的证明方法，展示当字母表大小为 $k+1$ 时状态复杂性的上界。随后分析了部分语言由双状态自动机识别的情形，证明此时字母表可以缩减为 $k$ 个字母，并构造了合适的见证语言。进一步结合三语言连接、三元字母、二元字母的最优性与下界，以及一元循环语言的紧上界研究。

Result: 1. 证明了比文献简单的状态复杂性上界，且在有双状态自动机时可以减少字母。2. 在三语言连接时三元字母表是最优的。3. 多重连接的显式上界在三元语言下渐近紧密，二元语言情况下下界仍是指数级。4. 对一元循环语言和无尾部终态的一元自动机给出了紧上界。

Conclusion: 本论文解决了 Caron 等人提出的公开问题，通过更简方法给出多重连接状态复杂性的见证语言及字母表大小最优性，并系统分析了特殊自动机的复杂性上界。

Abstract: We describe witness languages meeting the upper bound on the state complexity
of the multiple concatenation of $k$ regular languages over an alphabet of size
$k+1$ with a significantly simpler proof than that in the literature. We also
consider the case where some languages may be recognized by two-state automata.
Then we show that one symbol can be saved, and we define witnesses for the
multiple concatenation of $k$ languages over a $k$-letter alphabet. This solves
an open problem stated by Caron et al. [2018, Fundam. Inform. 160, 255--279].
We prove that for the concatenation of three languages, the ternary alphabet is
optimal. We also show that a trivial upper bound on the state complexity of
multiple concatenation is asymptotically tight for ternary languages, and that
a lower bound remains exponential in the binary case. Finally, we obtain a
tight upper bound for unary cyclic languages and languages recognized by unary
automata that do not have final states in their tails.

</details>


### [15] [Explorability in Pushdown Automata](https://arxiv.org/abs/2511.04048)
*Ayaan Bedi,Karoliina Lehtinen*

Main category: cs.FL

TL;DR: 本文提出explorability作为推理下推自动机非确定性的新度量，层级提升带来表达能力递增但不达完全非确定性；指数级explorability正好描述上下文无关语言，并证明其比历史决定性更为简洁，推动自动机理论发展。


<details>
  <summary>Details</summary>
Motivation: 本论文旨在研究下推自动机中的非确定性度量——explorability（可探索性），以更好地理解自动机在历史决定性与完全非确定性之间的表达能力和简洁性的关系。作者希望通过定义和分析explorability，揭示自动机不同层级的表达能力，并找出新的、操作性强的非确定性度量方式。

Method: 作者定义了k-explorable自动机，即在读取输入时，仅通过k个并发运行（基于迄今为止已读输入逐步构建），就能找到一个可接受的运算（如存在）。随后引入了参数化的explorability概念，使可探索的运行数目可随输入长度变化，并通过理论分析证明不同层级之间的表达能力和简洁性关系。

Result: 1）可探索的下推自动机类在表达能力和简洁性上介于历史决定性和完全非确定性之间；2）随着explorability的提高，形成无穷的层级结构，每层表达能力递增但都不及完全非确定性；3）指数级explorability恰好覆盖所有上下文无关语言；4）可探索自动机在简洁性上可比历史决定性自动机高出双指数级，且确定性与2-explorable之间的简洁性差距不可递归枚举。

Conclusion: explorability为下推自动机中的非确定性提供了一个稳健且具操作意义的度量方式，丰富了自动机理论对表达能力和结构简洁性的理解。

Abstract: We study explorability, a measure of nondeterminism in pushdown automata,
which generalises history-determinism. An automaton is k-explorable if, while
reading the input, it suffices to follow k concurrent runs, built step-by-step
based only on the input seen so far, to construct an accepting one, if it
exists. We show that the class of explorable PDAs lies strictly between
history-deterministic and fully nondeterministic PDAs in terms of both
expressiveness and succinctness. In fact increasing explorability induces an
infinite hierarchy: each level k defines a strictly more expressive class than
level k-1, yet the entire class remains less expressive than general
nondeterministic PDAs. We then introduce a parameterized notion of
explorability, where the number of runs may depend on input length, and show
that exponential explorability precisely captures the context-free languages.
Finally, we prove that explorable PDAs can be doubly exponentially more
succinct than history-deterministic ones, and that the succinctness gap between
deterministic and 2-explorable PDAs is not recursively enumerable. These
results position explorability as a robust and operationally meaningful measure
of nondeterminism for pushdown systems.

</details>
