{"id": "2507.02870", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.02870", "abs": "https://arxiv.org/abs/2507.02870", "authors": ["Chaozhuo Li", "Pengbo Wang", "Chenxu Wang", "Litian Zhang", "Zheng Liu", "Qiwei Ye", "Yuanbo Xu", "Feiran Huang", "Xi Zhang", "Philip S. Yu"], "title": "Loki's Dance of Illusions: A Comprehensive Survey of Hallucination in Large Language Models", "comment": null, "summary": "Edgar Allan Poe noted, \"Truth often lurks in the shadow of error,\"\nhighlighting the deep complexity intrinsic to the interplay between truth and\nfalsehood, notably under conditions of cognitive and informational asymmetry.\nThis dynamic is strikingly evident in large language models (LLMs). Despite\ntheir impressive linguistic generation capabilities, LLMs sometimes produce\ninformation that appears factually accurate but is, in reality, fabricated, an\nissue often referred to as 'hallucinations'. The prevalence of these\nhallucinations can mislead users, affecting their judgments and decisions. In\nsectors such as finance, law, and healthcare, such misinformation risks causing\nsubstantial economic losses, legal disputes, and health risks, with\nwide-ranging consequences.In our research, we have methodically categorized,\nanalyzed the causes, detection methods, and solutions related to LLM\nhallucinations. Our efforts have particularly focused on understanding the\nroots of hallucinations and evaluating the efficacy of current strategies in\nrevealing the underlying logic, thereby paving the way for the development of\ninnovative and potent approaches. By examining why certain measures are\neffective against hallucinations, our study aims to foster a comprehensive\napproach to tackling this issue within the domain of LLMs.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u68b3\u7406\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u95ee\u9898\u7684\u4ea7\u751f\u539f\u56e0\u3001\u68c0\u6d4b\u65b9\u6cd5\u548c\u5e94\u5bf9\u7b56\u7565\uff0c\u8bc4\u4f30\u4e86\u73b0\u6709\u63aa\u65bd\u7684\u6709\u6548\u6027\uff0c\u4e3a\u521b\u65b0\u6027\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5bf9\u5e7b\u89c9\u95ee\u9898\u7684\u7814\u7a76\u8d77\u5230\u4e86\u63a8\u52a8\u4f5c\u7528\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u666e\u53ca\uff0c\u5176\u5728\u751f\u6210\u6587\u672c\u4fe1\u606f\u65f6\u6240\u4ea7\u751f\u7684\u201c\u5e7b\u89c9\u201d\uff08\u5373\u770b\u4f3c\u771f\u5b9e\u4f46\u5b9e\u9645\u4e3a\u865a\u5047\u7684\u4fe1\u606f\uff09\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\u3002\u8be5\u95ee\u9898\u5728\u91d1\u878d\u3001\u6cd5\u5f8b\u3001\u533b\u7597\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u53ef\u80fd\u5bfc\u81f4\u91cd\u5927\u635f\u5931\u3002\u56e0\u6b64\uff0c\u7406\u89e3\u3001\u68c0\u6d4b\u548c\u89e3\u51b3\u5e7b\u89c9\u95ee\u9898\u6210\u4e3a\u8be5\u9886\u57df\u7684\u91cd\u8981\u7814\u7a76\u52a8\u673a\u3002", "method": "\u8be5\u7814\u7a76\u7cfb\u7edf\u6027\u5730\u5bf9LLM\u5e7b\u89c9\u73b0\u8c61\u8fdb\u884c\u4e86\u5206\u7c7b\uff0c\u5206\u6790\u4e86\u5176\u6210\u56e0\uff0c\u5e76\u68b3\u7406\u4e86\u76f8\u5173\u7684\u68c0\u6d4b\u65b9\u6cd5\u548c\u89e3\u51b3\u65b9\u6848\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u7740\u91cd\u8bc4\u4f30\u4e86\u5f53\u524d\u4e3b\u6d41\u7b56\u7565\u5728\u63ed\u793a\u5e7b\u89c9\u751f\u6210\u673a\u5236\u4e0a\u7684\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u5bf9LLM\u5e7b\u89c9\u7684\u6210\u56e0\u53ca\u89e3\u51b3\u63aa\u65bd\u8fdb\u884c\u4e86\u7cfb\u7edf\u7684\u5f52\u7eb3\u548c\u8bc4\u4f30\uff0c\u6307\u51fa\u4e86\u73b0\u6709\u7b56\u7565\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u4e3a\u521b\u65b0\u6027\u66f4\u5f3a\u7684\u5e94\u5bf9\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u8be5\u7814\u7a76\u52a0\u6df1\u4e86\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u5e7b\u89c9\u73b0\u8c61\u7684\u7406\u89e3\uff0c\u603b\u7ed3\u4e86\u6709\u6548\u7684\u68c0\u6d4b\u548c\u5e72\u9884\u7b56\u7565\uff0c\u5e76\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u5f3a\u5927\u4e14\u521b\u65b0\u7684\u65b9\u6cd5\u5e94\u5bf9\u5e7b\u89c9\u95ee\u9898\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.03156", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.03156", "abs": "https://arxiv.org/abs/2507.03156", "authors": ["Amr Mohamed", "Maram Assi", "Mariam Guizani"], "title": "The Impact of LLM-Assistants on Software Developer Productivity: A Systematic Literature Review", "comment": "37 pages", "summary": "Large language model assistants (LLM-assistants) present new opportunities to\ntransform software development. Developers are increasingly adopting these\ntools across tasks, including coding, testing, debugging, documentation, and\ndesign. Yet, despite growing interest, there is no synthesis of how\nLLM-assistants affect software developer productivity. In this paper, we\npresent a systematic literature review of 37 peer-reviewed studies published\nbetween January 2014 and December 2024 that examine this impact. Our analysis\nreveals that LLM-assistants offer both considerable benefits and critical\nrisks. Commonly reported gains include minimized code search, accelerated\ndevelopment, and the automation of trivial and repetitive tasks. However,\nstudies also highlight concerns around cognitive offloading, reduced team\ncollaboration, and inconsistent effects on code quality. While the majority of\nstudies (92%) adopt a multi-dimensional perspective by examining at least two\nSPACE dimensions, reflecting increased awareness of the complexity of developer\nproductivity, only 14% extend beyond three dimensions, indicating substantial\nroom for more integrated evaluations. Satisfaction, Performance, and Efficiency\nare the most frequently investigated dimensions, whereas Communication and\nActivity remain underexplored. Most studies are exploratory (64%) and\nmethodologically diverse, but lack longitudinal and team-based evaluations.\nThis review surfaces key research gaps and provides recommendations for future\nresearch and practice. All artifacts associated with this study are publicly\navailable at https://zenodo.org/records/15788502.", "AI": {"tldr": "\u672c\u7efc\u8ff0\u5206\u6790\u4e86LLM\u52a9\u624b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5f71\u54cd\uff0c\u603b\u7ed3\u4e86\u76ca\u5904\u548c\u98ce\u9669\uff0c\u5e76\u6307\u51fa\u5f53\u524d\u7814\u7a76\u5b58\u5728\u8bc4\u4f30\u7ef4\u5ea6\u4e0d\u8db3\u548c\u7f3a\u4e4f\u957f\u671f\u5b9e\u8bc1\u7b49\u4e3b\u8981\u7f3a\u53e3\u3002\u4e3a\u672a\u6765LLM\u8f85\u52a9\u5f00\u53d1\u7814\u7a76\u63d0\u4f9b\u4e86\u53c2\u8003\u548c\u5efa\u8bae\u3002", "motivation": "\u5c3d\u7ba1LLM\u52a9\u624b\u5728\u8f6f\u4ef6\u5f00\u53d1\u7684\u591a\u4e2a\u73af\u8282\u88ab\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u5c1a\u7f3a\u4e4f\u5bf9\u5176\u5bf9\u5f00\u53d1\u8005\u751f\u4ea7\u529b\u5f71\u54cd\u7684\u7cfb\u7edf\u6027\u7efc\u8ff0\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5f52\u7eb3\u73b0\u6709\u7814\u7a76\u6210\u679c\u5e76\u6307\u51fa\u672a\u6765\u65b9\u5411\u3002", "method": "\u7cfb\u7edf\u6027\u6587\u732e\u56de\u987e\uff0c\u5bf92014\u5e74\u81f32024\u5e74\u95f437\u7bc7\u540c\u884c\u8bc4\u8bae\u6587\u7ae0\u8fdb\u884c\u7efc\u5408\u5206\u6790\uff0c\u805a\u7126LLM\u52a9\u624b\u5bf9\u5f00\u53d1\u8005\u751f\u4ea7\u529b\u7684\u5f71\u54cd\u53ca\u76f8\u5173\u7ef4\u5ea6\u3002", "result": "LLM\u52a9\u624b\u5e38\u5e26\u6765\u5f00\u53d1\u63d0\u901f\u3001\u964d\u4f4e\u91cd\u590d\u6027\u52b3\u52a8\u7b49\u597d\u5904\uff0c\u4f46\u4e5f\u53ef\u80fd\u5bfc\u81f4\u8ba4\u77e5\u61c8\u6020\u3001\u534f\u4f5c\u51cf\u5c11\u548c\u4ee3\u7801\u8d28\u91cf\u6ce2\u52a8\u7b49\u95ee\u9898\u3002\u5927\u90e8\u5206\u7814\u7a76\u5173\u6ce8SPACE\u6846\u67b6\u4e2d\u7684\u591a\u7ef4\u5ea6\u751f\u4ea7\u529b\uff0c\u4f46\u6574\u4f53\u8bc4\u4f30\u4ecd\u663e\u7247\u9762\uff0c\u5f71\u54cd\u5168\u8c8c\u5c1a\u9700\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002", "conclusion": "LLM\u52a9\u624b\u4e3a\u8f6f\u4ef6\u5f00\u53d1\u8005\u5e26\u6765\u4e86\u53ef\u89c2\u7684\u76ca\u5904\uff0c\u4f46\u4e5f\u5b58\u5728\u4e0d\u5bb9\u5ffd\u89c6\u7684\u98ce\u9669\u3002\u7814\u7a76\u5f80\u5f80\u5173\u6ce8\u4e8e\u5f00\u53d1\u8005\u7684\u6ee1\u610f\u5ea6\u3001\u7ee9\u6548\u548c\u6548\u7387\uff0c\u800c\u5728\u56e2\u961f\u534f\u4f5c\u548c\u5177\u4f53\u5f00\u53d1\u6d3b\u52a8\u4e0a\u7684\u63a2\u8ba8\u8f83\u5c11\u3002\u7f3a\u4e4f\u957f\u671f\u548c\u57fa\u4e8e\u56e2\u961f\u7684\u7cfb\u7edf\u8bc4\u4f30\uff0c\u672a\u6765\u7814\u7a76\u9700\u8865\u8db3\u8fd9\u4e9b\u4e0d\u8db3\u3002"}}
{"id": "2507.02919", "categories": ["cs.CL", "cs.CY", "cs.ET"], "pdf": "https://arxiv.org/pdf/2507.02919", "abs": "https://arxiv.org/abs/2507.02919", "authors": ["Dai Li", "Linzhuo Li", "Huilian Sophie Qiu"], "title": "ChatGPT is not A Man but Das Man: Representativeness and Structural Consistency of Silicon Samples Generated by Large Language Models", "comment": null, "summary": "Large language models (LLMs) in the form of chatbots like ChatGPT and Llama\nare increasingly proposed as \"silicon samples\" for simulating human opinions.\nThis study examines this notion, arguing that LLMs may misrepresent\npopulation-level opinions. We identify two fundamental challenges: a failure in\nstructural consistency, where response accuracy doesn't hold across demographic\naggregation levels, and homogenization, an underrepresentation of minority\nopinions. To investigate these, we prompted ChatGPT (GPT-4) and Meta's Llama\n3.1 series (8B, 70B, 405B) with questions on abortion and unauthorized\nimmigration from the American National Election Studies (ANES) 2020. Our\nfindings reveal significant structural inconsistencies and severe\nhomogenization in LLM responses compared to human data. We propose an\n\"accuracy-optimization hypothesis,\" suggesting homogenization stems from\nprioritizing modal responses. These issues challenge the validity of using\nLLMs, especially chatbots AI, as direct substitutes for human survey data,\npotentially reinforcing stereotypes and misinforming policy.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6307\u51fa\uff0c\u5f53\u524d\u4e3b\u6d41LLM\u5728\u6a21\u62df\u4eba\u7c7b\u610f\u89c1\u65f6\u5b58\u5728\u7ed3\u6784\u6027\u5931\u771f\u548c\u5c11\u6570\u58f0\u97f3\u88ab\u5ffd\u7565\u7684\u95ee\u9898\uff0c\u8b66\u60d5\u5176\u5e94\u7528\u4e8e\u793e\u4f1a\u79d1\u5b66\u8c03\u67e5\u548c\u653f\u7b56\u5236\u5b9a\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5982ChatGPT\u548cLlama\u88ab\u7528\u4f5c\u201c\u7845\u6837\u672c\u201d\u6765\u6a21\u62df\u4eba\u7c7b\u610f\u89c1\uff0c\u5b66\u754c\u5bf9\u5176\u662f\u5426\u80fd\u771f\u5b9e\u53cd\u6620\u4eba\u53e3\u610f\u89c1\u7ed3\u6784\u4ea7\u751f\u8d28\u7591\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u8ba9ChatGPT\uff08GPT-4\uff09\u548cMeta\u7684Llama 3.1\u7cfb\u5217\uff088B\u300170B\u3001405B\uff09\u56de\u7b54\u7f8e\u56fd\u56fd\u5bb6\u9009\u4e3e\u7814\u7a76\uff08ANES\uff092020\u4e2d\u5173\u4e8e\u5815\u80ce\u548c\u975e\u6cd5\u79fb\u6c11\u7684\u95ee\u9898\uff0c\u6765\u6bd4\u8f83\u5176\u4e0e\u771f\u5b9e\u4eba\u7c7b\u6570\u636e\u4e4b\u95f4\u7684\u5dee\u5f02\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cLLMs\u7684\u56de\u7b54\u5b58\u5728\u660e\u663e\u7684\u7ed3\u6784\u6027\u4e0d\u4e00\u81f4\u4ee5\u53ca\u5bf9\u5c11\u6570\u610f\u89c1\u7684\u4e25\u91cd\u540c\u8d28\u5316\uff0c\u5373\u76f8\u6bd4\u771f\u5b9e\u4eba\u7fa4\uff0c\u6a21\u578b\u66f4\u503e\u5411\u4e8e\u7ed9\u51fa\u4e3b\u6d41\u7b54\u6848\uff0c\u5ffd\u89c6\u4e86\u5c11\u6570\u610f\u89c1\u3002", "conclusion": "LLMs\u76ee\u524d\u5e76\u4e0d\u80fd\u4f5c\u4e3a\u53ef\u9760\u7684\u201c\u4eba\u7c7b\u610f\u89c1\u66ff\u4ee3\u54c1\u201d\u3002\u76f4\u63a5\u7528\u5b83\u4eec\u6a21\u62df\u8206\u60c5\u6570\u636e\u4f1a\u5931\u771f\uff0c\u751a\u81f3\u53ef\u80fd\u52a0\u5267\u523b\u677f\u5370\u8c61\u3001\u8bef\u5bfc\u653f\u7b56\u3002"}}
{"id": "2507.03160", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.03160", "abs": "https://arxiv.org/abs/2507.03160", "authors": ["Md Mahade Hasan", "Muhammad Waseem", "Kai-Kristian Kemell", "Jussi Raskua", "Juha Ala-Rantalaa", "Pekka Abrahamsson"], "title": "Assessing Small Language Models for Code Generation: An Empirical Study with Benchmarks", "comment": null, "summary": "The recent advancements of Small Language Models (SLMs) have opened new\npossibilities for efficient code generation. SLMs offer lightweight and\ncost-effective alternatives to Large Language Models (LLMs), making them\nattractive for use in resource-constrained environments. However, empirical\nunderstanding of SLMs, particularly their capabilities, limitations, and\nperformance trade-offs in code generation remains limited. This study presents\na comprehensive empirical evaluation of 20 open-source SLMs ranging from 0.4B\nto 10B parameters on five diverse code-related benchmarks (HumanEval, MBPP,\nMercury, HumanEvalPack, and CodeXGLUE). The models are assessed along three\ndimensions: i) functional correctness of generated code, ii) computational\nefficiency and iii) performance across multiple programming languages. The\nfindings of this study reveal that several compact SLMs achieve competitive\nresults while maintaining a balance between performance and efficiency, making\nthem viable for deployment in resource-constrained environments. However,\nachieving further improvements in accuracy requires switching to larger models.\nThese models generally outperform their smaller counterparts, but they require\nmuch more computational power. We observe that for 10% performance\nimprovements, models can require nearly a 4x increase in VRAM consumption,\nhighlighting a trade-off between effectiveness and scalability. Besides, the\nmultilingual performance analysis reveals that SLMs tend to perform better in\nlanguages such as Python, Java, and PHP, while exhibiting relatively weaker\nperformance in Go, C++, and Ruby. However, statistical analysis suggests these\ndifferences are not significant, indicating a generalizability of SLMs across\nprogramming languages. Based on the findings, this work provides insights into\nthe design and selection of SLMs for real-world code generation tasks.", "AI": {"tldr": "\u901a\u8fc7\u5bf920\u4e2a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u9879\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u53d1\u73b0\u90e8\u5206\u8f7b\u91cf\u6a21\u578b\u5728\u4fdd\u8bc1\u6548\u7387\u524d\u63d0\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u5408\u8d44\u6e90\u6709\u9650\u73af\u5883\u3002\u4f46\u8fdb\u4e00\u6b65\u63d0\u5347\u51c6\u786e\u6027\u9700\u66f4\u5927\u6a21\u578b\uff0c\u5e26\u6765\u66f4\u9ad8\u8ba1\u7b97\u6210\u672c\uff0c\u4e14\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u603b\u4f53\u65e0\u663e\u8457\u6027\u80fd\u5dee\u5f02\u3002", "motivation": "\u968f\u7740\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u6280\u672f\u7684\u8fdb\u6b65\uff0c\u5b83\u4eec\u5728\u4ee3\u7801\u751f\u6210\u9886\u57df\u5c55\u73b0\u4e86\u9ad8\u6548\u4e14\u7ecf\u6d4e\u7684\u4f18\u52bf\u3002\u76f8\u6bd4\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0cSLMs\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5bf9SLMs\u5728\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3001\u5c40\u9650\u6027\u53ca\u6027\u80fd\u6743\u8861\u7684\u5b9e\u8bc1\u8bc4\u4f30\u3002", "method": "\u672c\u6587\u7efc\u5408\u8bc4\u4f30\u4e8620\u4e2a\u5f00\u6e90SLMs\uff080.4B\u81f310B\u53c2\u6570\uff09\uff0c\u5728\u4e94\u4e2a\u591a\u6837\u5316\u7684\u4ee3\u7801\u76f8\u5173\u57fa\u51c6\uff08HumanEval\u3001MBPP\u3001Mercury\u3001HumanEvalPack\u548cCodeXGLUE\uff09\u4e0a\uff0c\u4ece\u751f\u6210\u4ee3\u7801\u7684\u529f\u80fd\u6b63\u786e\u6027\u3001\u8ba1\u7b97\u6548\u7387\u548c\u591a\u7f16\u7a0b\u8bed\u8a00\u6027\u80fd\u4e09\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4e00\u4e9b\u5c0f\u578bSLMs\u80fd\u591f\u5728\u4fdd\u8bc1\u6027\u80fd\u4e0e\u6548\u7387\u5e73\u8861\u7684\u524d\u63d0\u4e0b\uff0c\u53d6\u5f97\u8f83\u6709\u7ade\u4e89\u529b\u7684\u7ed3\u679c\uff0c\u9002\u5408\u90e8\u7f72\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u3002\u4f46\u7cbe\u5ea6\u8fdb\u4e00\u6b65\u63d0\u5347\u9700\u9009\u7528\u66f4\u5927\u7684\u6a21\u578b\uff0c\u7136\u800c\u5927\u6a21\u578b\u5bf9\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u663e\u8457\u63d0\u5347\u3002\u4f8b\u5982\uff0c\u6027\u80fd\u63d0\u534710%\u65f6\u663e\u5b58\u6d88\u8017\u53ef\u589e\u52a04\u500d\u3002\u6b64\u5916\uff0c\u867d\u591a\u8bed\u8a00\u5206\u6790\u663e\u793aPython\u3001Java\u548cPHP\u8868\u73b0\u8f83\u597d\uff0cGo\u3001C++\u3001Ruby\u8f83\u5f31\uff0c\u4f46\u7edf\u8ba1\u5206\u6790\u8868\u660e\u6027\u80fd\u5dee\u5f02\u4e0d\u5927\uff0cSLMs\u5177\u5907\u8de8\u8bed\u8a00\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u7efc\u5408\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSLMs\u5728\u9ad8\u6548\u4ee3\u7801\u751f\u6210\u548c\u591a\u8bed\u8a00\u4efb\u52a1\u4e2d\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u548c\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u4e86\u6307\u5bfc\u548c\u53c2\u8003\u3002"}}
{"id": "2507.02927", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.02927", "abs": "https://arxiv.org/abs/2507.02927", "authors": ["Phurich Saengthong", "Boonnithi Jiaramaneepinit", "Sheng Li", "Manabu Okumura", "Takahiro Shinozaki"], "title": "A Unified Speech LLM for Diarization and Speech Recognition in Multilingual Conversations", "comment": null, "summary": "Speech Large Language Models (Speech LLMs) have emerged as a crucial paradigm\nin recent years, extending the capabilities of traditional LLMs to speech tasks\nsuch as automatic speech recognition (ASR) and spoken dialogue modeling.\nHowever, their effectiveness in real-world multilingual conversations remains\nlimited by the scarcity of data that captures natural conversational phenomena.\nTo address this, the MLC-SLM Challenge provides a multilingual conversational\ndataset and evaluates models on two tasks: ASR with oracle segmentation (Task\nI) and joint diarization and recognition without oracle information (Task II).\nIn this paper, we focus on Task II and propose a unified speech LLM that\njointly performs diarization and ASR in an end-to-end manner. By reformulating\nthe training data format and modifying the inference procedure, our model\naddresses the ambiguity inherent in pre-segmented audio and achieves a 54.87\\%\nrelative improvement in tcpWER/tcpCER over the baseline, ranking 8th overall,\ndespite using a smaller LLM backbone. We also report results from Task I using\na fine-tuned speech LLM.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u540c\u65f6\u8fdb\u884c\u8bf4\u8bdd\u4eba\u5206\u79bb\u548c\u8bed\u97f3\u8bc6\u522b\u7684\u7edf\u4e00\u578b\u8bed\u97f3LLM\uff0c\u901a\u8fc7\u521b\u65b0\u6570\u636e\u4e0e\u63a8\u7406\u6d41\u7a0b\uff0c\u5728\u591a\u8bed\u79cd\u5bf9\u8bdd\u6311\u6218\u8d5b\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5e76\u5728\u5c0f\u6a21\u578b\u6761\u4ef6\u4e0b\u83b7\u5f97\u7b2c8\u540d\u3002", "motivation": "\u5c3d\u7ba1\u8bed\u97f3\u5927\u8bed\u8a00\u6a21\u578b\uff08Speech LLM\uff09\u63d0\u5347\u4e86\u8bed\u97f3\u8bc6\u522b\u548c\u5bf9\u8bdd\u5efa\u6a21\u7b49\u80fd\u529b\uff0c\u4f46\u76ee\u524d\u5728\u771f\u5b9e\u591a\u8bed\u79cd\u5bf9\u8bdd\u4e2d\u7684\u8868\u73b0\u53d7\u5230\u81ea\u7136\u5bf9\u8bdd\u6570\u636e\u532e\u4e4f\u7684\u9650\u5236\u3002MLC-SLM\u6311\u6218\u8d5b\u63d0\u4f9b\u4e86\u5bf9\u5e94\u7684\u6570\u636e\u96c6\u548c\u8bc4\u6d4b\u4efb\u52a1\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u8be5\u65b9\u5411\u7684\u53d1\u5c55\u3002", "method": "\u672c\u6587\u4e13\u6ce8\u4e8eTask II\uff08\u8054\u5408\u8bf4\u8bdd\u4eba\u5206\u79bb\u548c\u8bed\u97f3\u8bc6\u522b\u4efb\u52a1\uff09\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\uff08end-to-end\uff09\u7684\u7edf\u4e00\u578b\u8bed\u97f3LLM\u6a21\u578b\uff0c\u901a\u8fc7\u91cd\u65b0\u8bbe\u8ba1\u8bad\u7ec3\u6570\u636e\u683c\u5f0f\u548c\u8c03\u6574\u63a8\u7406\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u4e86\u5bf9\u672a\u9884\u5206\u5272\u97f3\u9891\u7684\u6709\u6548\u5904\u7406\u3002\u540c\u65f6\u4e5f\u5728Task I\u4e0a\u91c7\u7528\u5fae\u8c03\u7684\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\u5bf9\u6bd4\u3002", "result": "\u5728Task II\u4e0a\uff0c\u8be5\u6a21\u578b\u5728tcpWER/tcpCER\u6307\u6807\u4e0a\u5bf9\u6bd4baseline\u53d6\u5f97\u4e8654.87%\u7684\u76f8\u5bf9\u63d0\u5347\uff0c\u5e76\u5728\u6574\u4f53\u6392\u540d\u4e2d\u83b7\u5f97\u7b2c8\u540d\uff0c\u4e14\u6240\u7528LLM\u4e3b\u5e72\u5c0f\u4e8e\u5176\u4ed6\u961f\u4f0d\u3002\u6b64\u5916\uff0c\u4e5f\u62a5\u544a\u4e86Task I\u7684\u5b9e\u9a8c\u7ed3\u679c\u3002", "conclusion": "\u8054\u5408\u5efa\u6a21\u3001\u6570\u636e\u683c\u5f0f\u521b\u65b0\u4e0e\u63a8\u7406\u6d41\u7a0b\u4f18\u5316\uff0c\u4f7f\u5f97\u7aef\u5230\u7aef\u7684\u8bed\u97f3LLM\u663e\u8457\u63d0\u5347\u4e86\u591a\u8bed\u79cd\u81ea\u7136\u5bf9\u8bdd\u73af\u5883\u4e0b\u7684\u8bc6\u522b\u4e0e\u5206\u79bb\u8868\u73b0\uff0c\u5373\u4f7f\u5728\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u7684\u6761\u4ef6\u4e0b\uff08\u5c0f\u6a21\u578b\uff09\uff0c\u4e5f\u80fd\u53d6\u5f97\u8f83\u597d\u6210\u7ee9\u3002"}}
{"id": "2507.03263", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.03263", "abs": "https://arxiv.org/abs/2507.03263", "authors": ["Haiqiao Gu", "Yiliang Zhao", "Kai Gao", "Minghui Zhou"], "title": "Analyzing C/C++ Library Migrations at the Package-level: Prevalence, Domains, Targets and Rationals across Seven Package Management Tools", "comment": null, "summary": "Library migration happens when a library can not meet the project's\nrequirements and is non-trivial to accomplish. To mitigate the problem,\nsubstantial efforts have been devoted to understanding its characteristics and\nrecommending alternative libraries, especially for programming language (PL)\necosystems with a central package hosting platform, such as Python (PyPI).\nHowever, to the best of our knowledge, understanding of C/C++ library\nmigrations is still lacking, possibly due to challenges resulting from the\nfragmented and complicated dependency management practices in the C/C++\necosystem. To bridge this knowledge gap, this paper analyzes 19,943 C/C++\nprojects that utilize different package management tools and establishes the\nfirst C/C++ library migration dataset. Based on the dataset, we investigate the\nprevalence, domains, target library, and rationale of C/C++ library migrations\nand compare the results with three widely investigated PLs: Python, JavaScript,\nand Java. We find that the overall trend in the number of C/C++ library\nmigrations is similar to Java. Migrations across different package management\ntools are also observed. In C/C++, library migrations mainly occur in GUI,\nBuild, and OS development, but are rare in domains (e.g., Testing and Logging)\nthat dominate library migrations in the three compared PLs. 83.46\\% of C/C++\nsource libraries only have one migration target, suggesting that our library\nmigration dataset could be used directly to recommend migration targets. We\nfind four C/C++-specific migration reasons, such as less compile time and\nunification of dependency management, revealing the unique dependency\nmanagement requirements in C/C++ projects. We believe our findings can help\nC/C++ developers make more informed library migration decisions and shed light\non the design of C/C++ library migration tools.", "AI": {"tldr": "\u672c\u6587\u586b\u8865\u4e86C/C++\u5e93\u8fc1\u79fb\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u57fa\u4e8e\u8fd12\u4e07\u4e2a\u9879\u76ee\u6784\u5efa\u8fc1\u79fb\u6570\u636e\u96c6\uff0c\u5206\u6790\u8fc1\u79fb\u73b0\u8c61\u548c\u539f\u56e0\uff0c\u5e76\u5bf9\u6bd4\u5176\u5b83\u4e3b\u6d41\u8bed\u8a00\uff0c\u603b\u7ed3\u51faC/C++\u5e93\u8fc1\u79fb\u7684\u72ec\u7279\u6027\uff0c\u53ef\u52a9\u529b\u8fc1\u79fb\u5de5\u5177\u8bbe\u8ba1\u3002", "motivation": "\u6b64\u524d\u5173\u4e8eC/C++\u5e93\u8fc1\u79fb\u7684\u7814\u7a76\u8f83\u5c11\uff0c\u4e3b\u8981\u56e0\u4e3a\u5176\u4f9d\u8d56\u7ba1\u7406\u5b9e\u8df5\u5206\u6563\u4e14\u590d\u6742\u3002\u73b0\u6709\u7edd\u5927\u591a\u6570\u5173\u4e8e\u5e93\u8fc1\u79fb\u7684\u7814\u7a76\u96c6\u4e2d\u5728\u4f9d\u8d56\u7ba1\u7406\u96c6\u4e2d\u7684\u7f16\u7a0b\u8bed\u8a00\u751f\u6001\uff08\u5982Python\u3001JavaScript\u3001Java\uff09\uff0cC/C++\u65b9\u9762\u5c1a\u5c5e\u7a7a\u767d\u3002\u586b\u8865\u8fd9\u4e00\u77e5\u8bc6\u7a7a\u767d\u5bf9\u4e8e\u7406\u89e3C/C++\u751f\u6001\u4e0b\u7684\u5e93\u8fc1\u79fb\u53ca\u5de5\u5177\u8bbe\u8ba1\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u672c\u6587\u5206\u6790\u4e8619,943\u4e2a\u4f7f\u7528\u4e0d\u540c\u5305\u7ba1\u7406\u5de5\u5177\u7684C/C++\u9879\u76ee\uff0c\u6784\u5efa\u4e86\u9996\u4e2aC/C++\u5e93\u8fc1\u79fb\u6570\u636e\u96c6\u3002\u57fa\u4e8e\u8be5\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u6027\u5730\u8c03\u7814\u4e86C/C++\u5e93\u8fc1\u79fb\u7684\u6d41\u884c\u7a0b\u5ea6\u3001\u6d89\u53ca\u9886\u57df\u3001\u76ee\u6807\u5e93\u53ca\u8fc1\u79fb\u539f\u56e0\uff0c\u5e76\u4e0ePython\u3001JavaScript\u548cJava\u4e09\u4e2a\u4e3b\u6d41\u7f16\u7a0b\u8bed\u8a00\u8fdb\u884c\u4e86\u5bf9\u6bd4\u3002", "result": "C/C++\u5e93\u8fc1\u79fb\u7684\u6574\u4f53\u8d8b\u52bf\u4e0eJava\u76f8\u4f3c\uff0c\u4e5f\u89c2\u6d4b\u5230\u8de8\u4e0d\u540c\u5305\u7ba1\u7406\u5de5\u5177\u7684\u8fc1\u79fb\u3002C/C++\u4e2d\uff0c\u5e93\u8fc1\u79fb\u4e3b\u8981\u53d1\u751f\u5728GUI\u3001\u6784\u5efa\u548c\u64cd\u4f5c\u7cfb\u7edf\u5f00\u53d1\u9886\u57df\uff0c\u5728\u6d4b\u8bd5\u548c\u65e5\u5fd7\u7b49\u9886\u57df\u8fc1\u79fb\u5219\u8f83\u5c11\uff0c\u4e0e\u5176\u5b83\u8bed\u8a00\u6709\u663e\u8457\u4e0d\u540c\u300283.46%\u7684\u6e90\u5e93\u4ec5\u6709\u4e00\u4e2a\u8fc1\u79fb\u76ee\u6807\uff0c\u8fc1\u79fb\u539f\u56e0\u6709\u56db\u9879\u662fC/C++\u7279\u6709\u7684\uff0c\u5982\u51cf\u5c11\u7f16\u8bd1\u65f6\u95f4\u548c\u4f9d\u8d56\u7ba1\u7406\u7edf\u4e00\u3002", "conclusion": "\u7814\u7a76\u4e3aC/C++\u793e\u533a\u9996\u6b21\u5e26\u6765\u5927\u89c4\u6a21\u5e93\u8fc1\u79fb\u7684\u5b9e\u8bc1\u6570\u636e\uff0c\u63ed\u793a\u4e86\u5176\u9886\u57df\u548c\u8fc1\u79fb\u52a8\u673a\u7684\u72ec\u7279\u6027\uff0c\u5e76\u80fd\u76f4\u63a5\u4e3a\u5e93\u8fc1\u79fb\u63a8\u8350\u63d0\u4f9b\u6570\u636e\u652f\u6491\uff0c\u5bf9C/C++\u8fc1\u79fb\u5de5\u5177\u7684\u8bbe\u8ba1\u5f00\u53d1\u5177\u6709\u542f\u53d1\u4ef7\u503c\u3002"}}
{"id": "2507.02928", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02928", "abs": "https://arxiv.org/abs/2507.02928", "authors": ["Hao Yang", "Haoxuan Li", "Luyu Chen", "Haoxiang Wang", "Xu Chen", "Mingming Gong"], "title": "Mitigating Hidden Confounding by Progressive Confounder Imputation via Large Language Models", "comment": null, "summary": "Hidden confounding remains a central challenge in estimating treatment\neffects from observational data, as unobserved variables can lead to biased\ncausal estimates. While recent work has explored the use of large language\nmodels (LLMs) for causal inference, most approaches still rely on the\nunconfoundedness assumption. In this paper, we make the first attempt to\nmitigate hidden confounding using LLMs. We propose ProCI (Progressive\nConfounder Imputation), a framework that elicits the semantic and world\nknowledge of LLMs to iteratively generate, impute, and validate hidden\nconfounders. ProCI leverages two key capabilities of LLMs: their strong\nsemantic reasoning ability, which enables the discovery of plausible\nconfounders from both structured and unstructured inputs, and their embedded\nworld knowledge, which supports counterfactual reasoning under latent\nconfounding. To improve robustness, ProCI adopts a distributional reasoning\nstrategy instead of direct value imputation to prevent the collapsed outputs.\nExtensive experiments demonstrate that ProCI uncovers meaningful confounders\nand significantly improves treatment effect estimation across various datasets\nand LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faProCI\u65b9\u6cd5\uff0c\u9996\u6b21\u5c1d\u8bd5\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u51cf\u8f7b\u89c2\u6d4b\u6570\u636e\u4e2d\u9690\u85cf\u6df7\u6742\u5bfc\u81f4\u7684\u56e0\u679c\u504f\u5dee\u3002\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5904\u7406\u6548\u5e94\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u89c2\u6d4b\u6570\u636e\u4e2d\u4f30\u8ba1\u5904\u7406\u6548\u5e94\u65f6\uff0c\u9690\u85cf\u6df7\u6742\u56e0\u7d20\u4f1a\u5bfc\u81f4\u56e0\u679c\u4f30\u8ba1\u4ea7\u751f\u504f\u5dee\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5df2\u88ab\u7528\u4e8e\u56e0\u679c\u63a8\u65ad\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u65e0\u6df7\u6742\u5047\u8bbe\uff0c\u96be\u4ee5\u5e94\u5bf9\u9690\u85cf\u6df7\u6742\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86ProCI\uff08Progressive Confounder Imputation\uff09\u6846\u67b6\uff0c\u5229\u7528LLMs\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u548c\u4e16\u754c\u77e5\u8bc6\uff0c\u8fed\u4ee3\u751f\u6210\u3001\u586b\u5145\u5e76\u9a8c\u8bc1\u9690\u85cf\u6df7\u6742\u53d8\u91cf\u3002ProCI\u91c7\u53d6\u5206\u5e03\u5f0f\u63a8\u7406\u800c\u975e\u76f4\u63a5\u503c\u586b\u5145\uff0c\u4ee5\u589e\u5f3a\u9c81\u68d2\u6027\u5e76\u907f\u514d\u8f93\u51fa\u6536\u655b\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cProCI\u80fd\u591f\u53d1\u73b0\u6709\u610f\u4e49\u7684\u6df7\u6742\u53d8\u91cf\uff0c\u5e76\u4e14\u5728\u591a\u79cd\u6570\u636e\u96c6\u548cLLM\u6a21\u578b\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u5904\u7406\u6548\u5e94\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002", "conclusion": "ProCI\u901a\u8fc7\u8c03\u52a8LLMs\u7684\u77e5\u8bc6\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u9996\u6b21\u5c55\u793a\u4e86\u5229\u7528\u5927\u6a21\u578b\u51cf\u8f7b\u9690\u85cf\u6df7\u6742\u7684\u53ef\u80fd\u6027\uff0c\u4e3a\u56e0\u679c\u63a8\u65ad\u9886\u57df\u5e26\u6765\u65b0\u7684\u89e3\u51b3\u8def\u5f84\u3002"}}
{"id": "2507.03328", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.03328", "abs": "https://arxiv.org/abs/2507.03328", "authors": ["S. Lee", "C. Myers", "A. Yang", "T. Zhang", "S. J. L. Billinge"], "title": "scikit-package -- software packaging standards and roadmap for sharing reproducible scientific software", "comment": "GitHub: https://github.com/scikit-package/scikit-package Doc:\n  https://scikit-package.github.io/scikit-package/", "summary": "Scientific advancement relies on the ability to share and reproduce results.\nWhen data analysis or calculations are carried out using software written by\nscientists there are special challenges around code versions, quality and code\nsharing. scikit-package provides a roadmap to facilitate code reuse and sharing\nwith minimal effort through tutorials coupled with automated and centralized\nreusable workflows. The goal of the project is to provide pedagogical and\npractical tools for scientists who are not professionally trained software\nengineers to write more reusable and maintainable software code. Code reuse can\noccur at multiple levels of complexity-from turning a code block into a\nfunction within a single script, to publishing a publicly installable, fully\ntested, and documented software package scikit-package provides a community\nmaintained set of tools, and a roadmap, to help scientists bring their software\nhigher levels of reproducibility and shareability.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86 scikit-package\uff0c\u901a\u8fc7\u6559\u7a0b\u548c\u81ea\u52a8\u5316\u5de5\u5177\u5e2e\u52a9\u975e\u4e13\u4e1a\u7684\u8f6f\u4ef6\u5f00\u53d1\u8005\uff08\u5982\u79d1\u5b66\u5bb6\uff09\u5b9e\u73b0\u4ee3\u7801\u590d\u7528\u3001\u63d0\u9ad8\u8f6f\u4ef6\u53ef\u7ef4\u62a4\u6027\u4e0e\u53ef\u590d\u73b0\u6027\uff0c\u4fc3\u8fdb\u79d1\u5b66\u6210\u679c\u5171\u4eab\u3002", "motivation": "\u79d1\u5b66\u7814\u7a76\u7684\u8fdb\u6b65\u4f9d\u8d56\u4e8e\u7ed3\u679c\u7684\u5171\u4eab\u4e0e\u53ef\u590d\u73b0\u6027\u3002\u7136\u800c\uff0c\u5f53\u79d1\u5b66\u5bb6\u4f7f\u7528\u81ea\u5199\u8f6f\u4ef6\u8fdb\u884c\u6570\u636e\u5206\u6790\u548c\u8ba1\u7b97\u65f6\uff0c\u4ee3\u7801\u7684\u7248\u672c\u7ba1\u7406\u3001\u8d28\u91cf\u63a7\u5236\u548c\u5171\u4eab\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002", "method": "scikit-package \u901a\u8fc7\u7ed3\u5408\u6559\u7a0b\u4e0e\u81ea\u52a8\u5316\u3001\u96c6\u4e2d\u7684\u53ef\u91cd\u7528\u5de5\u4f5c\u6d41\uff0c\u4e3a\u4ee3\u7801\u590d\u7528\u548c\u5171\u4eab\u5236\u5b9a\u4e86\u8def\u5f84\u3002\u8be5\u9879\u76ee\u4e3a\u6ca1\u6709\u4e13\u4e1a\u8f6f\u4ef6\u5de5\u7a0b\u80cc\u666f\u7684\u79d1\u5b66\u5bb6\u63d0\u4f9b\u7406\u8bba\u548c\u5b9e\u8df5\u5de5\u5177\uff0c\u5e2e\u52a9\u4ed6\u4eec\u63d0\u5347\u4ee3\u7801\u7684\u53ef\u91cd\u7528\u6027\u4e0e\u53ef\u7ef4\u62a4\u6027\u3002", "result": "scikit-package \u63d0\u4f9b\u4e86\u793e\u533a\u7ef4\u62a4\u7684\u5de5\u5177\u96c6\u548c\u8def\u7ebf\u56fe\uff0c\u5e2e\u52a9\u79d1\u5b66\u5bb6\u63d0\u5347\u5176\u8f6f\u4ef6\u7684\u53ef\u590d\u73b0\u6027\u548c\u53ef\u5171\u4eab\u6027\uff0c\u652f\u6301\u4ece\u4ee3\u7801\u5757\u51fd\u6570\u5316\u5230\u6210\u719f\u8f6f\u4ef6\u5305\u53d1\u5e03\u7684\u591a\u5c42\u6b21\u4ee3\u7801\u590d\u7528\u3002", "conclusion": "scikit-package \u65e8\u5728\u964d\u4f4e\u79d1\u5b66\u5bb6\u5f00\u53d1\u53ef\u91cd\u7528\u3001\u53ef\u7ef4\u62a4\u8f6f\u4ef6\u96be\u5ea6\uff0c\u4fc3\u8fdb\u79d1\u5b66\u8f6f\u4ef6\u7684\u590d\u7528\u4e0e\u4f20\u64ad\u3002"}}
{"id": "2507.03629", "categories": ["cs.PL", "cs.FL", "F.4.3; D.3.1; D.3.4"], "pdf": "https://arxiv.org/pdf/2507.03629", "abs": "https://arxiv.org/abs/2507.03629", "authors": ["S\u00e9rgio Queiroz de Medeiros", "Fabio Mascarenhas"], "title": "Towards Automatic Error Recovery in Parsing Expression", "comment": "arXiv admin note: substantial text overlap with arXiv:1905.02145", "summary": "Error recovery is an essential feature for a parser that should be plugged in\nIntegrated Development Environments (IDEs), which must build Abstract Syntax\nTrees (ASTs) even for syntactically invalid programs in order to offer features\nsuch as automated refactoring and code completion.\n  Parsing Expressions Grammars (PEGs) are a formalism that naturally describes\nrecursive top-down parsers using a restricted form of backtracking. Labeled\nfailures are a conservative extension of PEGs that adds an error reporting\nmechanism for PEG parsers, and these labels can also be associated with\nrecovery expressions to also be an error recovery mechanism. These expressions\ncan use the full expressivity of PEGs to recover from syntactic errors.\n  Manually annotating a large grammar with labels and recovery expressions can\nbe difficult. In this work, we present an algorithm that automatically\nannotates a PEG with labels, and builds their corresponding recovery\nexpressions. We evaluate this algorithm by adding error recovery to the parser\nof the Titan programming language. The results shown that with a small amount\nof manual intervention our algorithm can be used to produce error recovering\nparsers for PEGs where most of the alternatives are disjoint.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u4e3aPEG\u6587\u6cd5\u6dfb\u52a0\u9519\u8bef\u6807\u7b7e\u548c\u6062\u590d\u8868\u8fbe\u5f0f\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u5728Titan\u8bed\u8a00\u89e3\u6790\u5668\u4e0a\u7684\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86\u7b97\u6cd5\u6709\u6548\u6027\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u5177\u5907\u9519\u8bef\u6062\u590d\u80fd\u529b\u7684\u81ea\u52a8\u5316\u89e3\u6790\u5668\u3002", "motivation": "\u5728\u96c6\u6210\u5f00\u53d1\u73af\u5883\uff08IDE\uff09\u4e2d\uff0c\u89e3\u6790\u5668\u9700\u8981\u80fd\u591f\u5904\u7406\u8bed\u6cd5\u9519\u8bef\uff0c\u4ee5\u4fbf\u5373\u4f7f\u5728\u5b58\u5728\u8bed\u6cd5\u9519\u8bef\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u6784\u5efa\u62bd\u8c61\u8bed\u6cd5\u6811\uff08AST\uff09\uff0c\u4ece\u800c\u652f\u6301\u81ea\u52a8\u91cd\u6784\u548c\u4ee3\u7801\u8865\u5168\u7b49\u529f\u80fd\u3002\u5f53\u524d\uff0c\u57fa\u4e8eParsing Expressions Grammars\uff08PEGs\uff09\u7684\u9519\u8bef\u6062\u590d\u624b\u6bb5\u9700\u8981\u624b\u52a8\u4e3a\u6587\u6cd5\u6dfb\u52a0\u6807\u7b7e\u548c\u6062\u590d\u8868\u8fbe\u5f0f\uff0c\u8fc7\u7a0b\u590d\u6742\u4e14\u7e41\u7410\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7b97\u6cd5\uff0c\u80fd\u591f\u81ea\u52a8\u4e3aPEG\u6587\u6cd5\u6dfb\u52a0\u9519\u8bef\u6807\u7b7e\u53ca\u76f8\u5e94\u7684\u9519\u8bef\u6062\u590d\u8868\u8fbe\u5f0f\uff0c\u4ece\u800c\u7b80\u5316\u9519\u8bef\u6062\u590d\u673a\u5236\u7684\u5efa\u8bbe\u3002\u4f5c\u8005\u8fd8\u901a\u8fc7\u5728Titan\u7f16\u7a0b\u8bed\u8a00\u7684\u89e3\u6790\u5668\u4e2d\u5f15\u5165\u8be5\u7b97\u6cd5\uff0c\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u4ec5\u9700\u5c11\u91cf\u4eba\u5de5\u5e72\u9884\uff0c\u5c31\u80fd\u591f\u5728\u5927\u591a\u6570\u5907\u62e9\u5206\u652f\u4e92\u65a5\u7684PEG\u6587\u6cd5\u4e2d\uff0c\u81ea\u52a8\u6784\u5efa\u5177\u5907\u9519\u8bef\u6062\u590d\u80fd\u529b\u7684\u89e3\u6790\u5668\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u57fa\u4e8ePEG\u7684\u89e3\u6790\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u81ea\u52a8\u5316\u7684\u9519\u8bef\u6062\u590d\u673a\u5236\uff0c\u6709\u52a9\u4e8e\u63d0\u5347IDE\u4e2d\u76f8\u5173\u6280\u672f\u7684\u6613\u7528\u6027\u548c\u5065\u58ee\u6027\u3002"}}
{"id": "2507.03439", "categories": ["cs.FL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.03439", "abs": "https://arxiv.org/abs/2507.03439", "authors": ["Luk\u00e1\u0161 Hol\u00edk", "Ond\u0159ej Leng\u00e1l", "Juraj Major", "Ad\u00e9la \u0160t\u011bpkov\u00e1", "Jan Strej\u010dek"], "title": "On Complementation of Nondeterministic Finite Automata without Full Determinization (Technical Report)", "comment": "Accepted at FCT'25", "summary": "Complementation of finite automata is a basic operation used in numerous\napplications. The standard way to complement a nondeterministic finite\nautomaton (NFA) is to transform it into an equivalent deterministic finite\nautomaton (DFA) and complement the DFA. The DFA can, however, be exponentially\nlarger than the corresponding NFA. In this paper, we study several alternative\napproaches to complementation, which are based either on reverse powerset\nconstruction or on two novel constructions that exploit a commonly occurring\nstructure of NFAs. Our experiment on a large data set shows that using a\ndifferent than the classical approach can in many cases yield significantly\nsmaller complements.", "AI": {"tldr": "\u4f20\u7edfNFA\u8865\u5168\u96c6\u4e2d\u8f6cDFA\u4f46\u81a8\u80c0\u4e25\u91cd\uff0c\u672c\u6587\u63d0\u51fa\u5229\u7528\u53cd\u5411\u5e42\u96c6\u53ca\u4e24\u79cd\u65b0\u7ed3\u6784\u65b9\u6848\uff0c\u5b9e\u9a8c\u663e\u793a\u53ef\u6709\u6548\u7f29\u51cf\u81ea\u52a8\u673a\u6784\u5efa\u89c4\u6a21\u3002", "motivation": "\u6709\u9650\u81ea\u52a8\u673a\u7684\u8865\u5168\uff08complementation\uff09\u662f\u5f88\u591a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u57fa\u7840\u64cd\u4f5c\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u975e\u786e\u5b9a\u6027\u6709\u9650\u81ea\u52a8\u673a\uff08NFA\uff09\uff0c\u5e38\u89c4\u7684\u8865\u5168\u65b9\u5f0f\u9700\u8981\u5148\u8f6c\u4e3a\u7b49\u4ef7\u7684\u786e\u5b9a\u6027\u6709\u9650\u81ea\u52a8\u673a\uff08DFA\uff09\uff0c\u518d\u53d6\u8865\u3002\u4f46DFA\u7684\u72b6\u6001\u6570\u53ef\u80fd\u5448\u6307\u6570\u7ea7\u81a8\u80c0\uff0c\u4ece\u800c\u5e26\u6765\u6548\u7387\u548c\u5b58\u50a8\u4e0a\u7684\u5de8\u5927\u8d1f\u62c5\u3002", "method": "\u672c\u6587\u7814\u7a76\u4e86\u51e0\u79cd\u66ff\u4ee3\u6027\u7684\u8865\u5168\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u4e8e\u53cd\u5411\u5e42\u96c6\uff08reverse powerset\uff09\u6784\u9020\u548c\u4e24\u79cd\u65b0\u63d0\u51fa\u7684\u65b9\u6cd5\uff0c\u8fd9\u4e24\u79cd\u65b0\u65b9\u6cd5\u5229\u7528\u4e86NFA\u4e2d\u5e38\u89c1\u7684\u4e00\u79cd\u7ed3\u6784\u7279\u6027\u3002\u4f5c\u8005\u5bf9\u8fd9\u4e9b\u4e0d\u540c\u65b9\u6cd5\u8fdb\u884c\u4e86\u5b9e\u9a8c\u5bf9\u6bd4\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528\u975e\u4f20\u7edf\u7684\u8865\u5168\u65b9\u6cd5\u53ef\u83b7\u5f97\u663e\u8457\u66f4\u5c0f\u7684\u8865\u81ea\u52a8\u673a\uff08complement\uff09\u3002\u8fd9\u610f\u5473\u7740\u66ff\u4ee3\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u6709\u6f5c\u5728\u7684\u6548\u7387\u63d0\u5347\u7a7a\u95f4\u3002", "conclusion": "\u672c\u6587\u8bc1\u660e\u4e86\u66ff\u4ee3\u6027\u8865\u5168\u6280\u672f\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u80fd\u6709\u6548\u51cf\u5c0f\u8865\u81ea\u52a8\u673a\u89c4\u6a21\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u7684DFA\u8865\u5168\u4e3b\u5bfc\u5730\u4f4d\uff0c\u4e3aNFA\u8865\u5168\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u65b9\u6848\u9009\u62e9\u3002"}}
{"id": "2507.03208", "categories": ["cs.LO", "F.4.1"], "pdf": "https://arxiv.org/pdf/2507.03208", "abs": "https://arxiv.org/abs/2507.03208", "authors": ["Daniel Ranalter", "Cezary Kaliszyk", "Florian Rabe", "Geoff Sutcliffe"], "title": "The Dependently Typed Higher-Order Form for the TPTP World", "comment": "16 pages excluding references, to be published in the proceedings of\n  FroCoS 25", "summary": "Much of the current research and development in the field of automated\nreasoning builds on the infrastructure provided by the TPTP World. The TPTP\nlanguage for logical formulae is central to the far-reaching adoption of the\nTPTP World. This paper introduces the Dependently Typed higher-order Form (DTF)\nof the TPTP language. It takes advantage of already established binders in the\nsyntax, and is thus a minimally intrusive extension to the Typed Higher-order\nForm (THF). A starting set of over 100 problems is provided to exhibit the\nusefulness and incite interest in DTF. Some tools that are already able to\nreason about problems in the DTF language are discussed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86TPTP\u4f9d\u8d56\u578b\u9ad8\u9636\u5f62\u5f0f\uff08DTF\uff09\uff0c\u5728\u4fdd\u7559\u539f\u8bed\u8a00\u517c\u5bb9\u6027\u7684\u57fa\u7840\u4e0a\u589e\u5f3a\u4e86\u81ea\u52a8\u63a8\u7406\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u5df2\u5728\u591a\u4e2a\u5b9e\u4f8b\u548c\u5de5\u5177\u4e2d\u5f97\u5230\u5e94\u7528\u3002", "motivation": "\u81ea\u52a8\u63a8\u7406\u9886\u57df\u5f88\u591a\u7814\u7a76\u548c\u5f00\u53d1\u57fa\u4e8eTPTP World\u3002TPTP\u8bed\u8a00\u5728\u8be5\u9886\u57df\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u9700\u8981\u6269\u5c55\u5176\u8868\u8fbe\u80fd\u529b\u4ee5\u9002\u5e94\u66f4\u9ad8\u7ea7\u7684\u63a8\u7406\u9700\u6c42\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86TPTP\u8bed\u8a00\u7684\u4f9d\u8d56\u578b\u9ad8\u9636\u5f62\u5f0f\uff08DTF\uff09\uff0c\u662f\u5bf9\u73b0\u6709Typed Higher-order Form (THF)\u7684\u6700\u5c0f\u4fb5\u5165\u6027\u6269\u5c55\uff0c\u5e76\u4e14\u91cd\u7528\u65e2\u6709\u8bed\u6cd5\u673a\u5236\u3002\u8fd8\u63d0\u4f9b\u4e86100\u591a\u4e2a\u6837\u4f8b\u95ee\u9898\u5c55\u793aDTF\u7684\u5b9e\u7528\u6027\uff0c\u5e76\u8ba8\u8bba\u4e86\u5df2\u6709\u80fd\u591f\u652f\u6301DTF\u63a8\u7406\u7684\u5de5\u5177\u3002", "result": "DTF\u5728\u8bed\u6cd5\u548c\u529f\u80fd\u4e0a\u5bf9TPTP\u8bed\u8a00\u8fdb\u884c\u4e86\u589e\u5f3a\uff0c\u5e76\u5c55\u793a\u4e86\u5b9e\u9645\u5e94\u7528\u6848\u4f8b\uff0c\u540c\u65f6\u5df2\u6709\u5de5\u5177\u80fd\u591f\u5bf9DTF\u95ee\u9898\u8fdb\u884c\u63a8\u7406\u3002", "conclusion": "DTF\u5f62\u5f0f\u589e\u5f3a\u4e86TPTP\u8bed\u8a00\u4f53\u7cfb\uff0c\u63d0\u9ad8\u4e86\u5176\u8868\u8fbe\u529b\u548c\u5de5\u5177\u517c\u5bb9\u6027\uff0c\u63a8\u8fdb\u4e86\u81ea\u52a8\u63a8\u7406\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.03980", "categories": ["cs.DM", "cs.DS"], "pdf": "https://arxiv.org/pdf/2507.03980", "abs": "https://arxiv.org/abs/2507.03980", "authors": ["Xi He", "Max. A. Little"], "title": "Combination generators with optimal cache utilization and communication free parallel execution", "comment": null, "summary": "We introduce an efficient and elegant combination generator for producing all\ncombinations of size less than or equal to K, designed for exhaustive\ngeneration and combinatorial optimization tasks. This generator can be\nimplemented to achieve what we define as optimal efficiency: constant amortized\ntime, optimal cache utilization, embarrassingly parallel execution, and a\nrecursive structure compatible with pruning-based search. These properties are\ndifficult to satisfy simultaneously in existing generators. For example,\nclassical Gray code or lexicographic generators are typically list-based and\nsequentially defined, making them difficult to vectorized, inefficient in cache\nusage, and inherently hard to parallelize. Generators based on unranking\nmethods, while easy to parallelize, are non-recursive. These limitations reduce\ntheir applicability in our target applications, where both computational\nefficiency and recursion are crucial. We adapt Bird's algebra of\nprogramming-style calculation to derive our algorithms, a formalism for\ndeveloping correct-by-construction programs from specifications. As a result,\nall generators in this paper are first formulated in their clearest\nspecification, and efficient definitions are derived constructively through\nequational reasoning, resulting in concise and elegant divide-and-conquer\ndefinitions. Beyond presenting a combination generator, we extend our approach\nto construct generators for K-permutations, nested combinations of\ncombinations, and nested permutation-combination structures. To the best of our\nknowledge, the literature has not previously reported generators for these\nnested structures. We also develop sequential variants that produce\nconfigurations in Gray code-compatible orders -- such as the revolving door\nordering -- which are particularly useful for constructing nested generators.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u6548\u7387\u3001\u5e76\u884c\u6027\u548c\u9012\u5f52\u7279\u6027\u4e0a\u5747\u5177\u6700\u4f18\u8868\u73b0\u7684\u7ec4\u5408\u751f\u6210\u5668\uff0c\u5e76\u9996\u6b21\u63a8\u5e7f\u81f3\u5d4c\u5957\u751f\u6210\u7ed3\u6784\uff0c\u517c\u987e\u7406\u8bba\u7f8e\u548c\u5b9e\u9645\u8ba1\u7b97\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u7ec4\u5408\u751f\u6210\u5668\u5728\u6548\u7387\u3001\u5e76\u884c\u6027\u3001\u7f13\u5b58\u5229\u7528\u3001\u9012\u5f52\u7ed3\u6784\u7b49\u65b9\u9762\u96be\u4ee5\u517c\u987e\uff0c\u5c24\u5176\u5728\u9700\u8981\u904d\u5386\u3001\u526a\u679d\u548c\u5e76\u884c\u7684\u7ec4\u5408\u4f18\u5316\u4efb\u52a1\u4e2d\uff0c\u7f3a\u4e4f\u6700\u4f18\u5b9e\u73b0\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u517c\u5bb9\u5e76\u884c\u548c\u9012\u5f52\u4e14\u65b9\u4fbf\u526a\u679d\u7684\u65b0\u578b\u7ec4\u5408\u751f\u6210\u5668\u3002", "method": "\u4f5c\u8005\u91c7\u7528Bird\u4ee3\u6570\u5316\u8ba1\u7b97\u65b9\u6cd5\uff0c\u4ece\u89c4\u8303\u5316\u89c4\u683c\u63a8\u5bfc\u51fa\u9ad8\u6548\u5b9e\u73b0\uff0c\u8fd0\u7528\u65b9\u7a0b\u63a8\u7406\u5c06\u9012\u5f52\u548c\u5206\u6cbb\u7b56\u7565\u7ed3\u5408\uff0c\u4e3a\u7ec4\u5408\u76f8\u5173\u751f\u6210\u95ee\u9898\u8bbe\u8ba1\u51fa\u7ed3\u6784\u4f18\u96c5\u3001\u6548\u7387\u4f18\u8d8a\u7684\u751f\u6210\u7b97\u6cd5\uff0c\u5e76\u5b9e\u73b0Gray\u7801\u987a\u5e8f\u751f\u6210\u5668\u53d8\u4f53\u3002", "result": "\u63d0\u51fa\u7684\u751f\u6210\u5668\u5b9e\u73b0\u4e86\u5e38\u6570\u644a\u9500\u65f6\u95f4\u3001\u7f13\u5b58\u9ad8\u6548\u3001\u6613\u5e76\u884c\u3001\u652f\u6301\u9012\u5f52\u548c\u526a\u679d\u7684\u6700\u4f18\u6548\u7387\u3002\u8fdb\u4e00\u6b65\u63a8\u5e7f\u5230K-\u6392\u5217\u3001\u7ec4\u5408\u5d4c\u5957\u7ed3\u6784\u7b49\uff0c\u9996\u6b21\u62a5\u9053\u4e86\u5d4c\u5957\u7ed3\u6784\u751f\u6210\u5668\uff0c\u5e76\u5f00\u53d1\u51faGray\u7801\u987a\u5e8f\u7684\u53d8\u4f53\u4ee5\u652f\u6301\u66f4\u590d\u6742\u7684\u751f\u6210\u9700\u6c42\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u4f18\u96c5\u7684\u7ec4\u5408\u751f\u6210\u5668\uff0c\u4e0d\u4ec5\u9002\u7528\u4e8e\u7ec4\u5408\u3001\u8fd8\u53ef\u6269\u5c55\u81f3\u6392\u5217\u53ca\u5d4c\u5957\u7ec4\u5408\uff0d\u6392\u5217\u7ed3\u6784\uff0c\u5728\u56de\u6eaf\u641c\u7d22\u548c\u5e76\u884c\u8ba1\u7b97\u4e2d\u5177\u6709\u72ec\u7279\u4f18\u52bf\uff0c\u5e76\u586b\u8865\u4e86\u6587\u732e\u7a7a\u767d\u3002"}}
{"id": "2507.02935", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.02935", "abs": "https://arxiv.org/abs/2507.02935", "authors": ["Fardin Saad", "Pradeep K. Murukannaiah", "Munindar P. Singh"], "title": "Theory of Mind in Action: The Instruction Inference Task", "comment": "Submitted to Artificial Intelligence Journal (under review). 51 pages\n  with appendix (28 pages article + 4 pages references + 19 pages appendix), 7\n  figures (Appendix: 26 Figures), 6 tables. Code available at:\n  https://github.com/fardinsaad/Tomcat-LLM", "summary": "The Theory of Mind (ToM) refers to an agent's capacity to infer the mental\nstates of other agents. ToM is essential for effective collaboration. To assess\nToM in a dynamic, goal-oriented, and collaborative environment, we introduce a\nnovel task, Instruction Inference, in which an agent assists a principal in\nreaching a goal by interpreting indirect or ambiguous instructions. We present\nTomcat, an LLM-based agent, designed to exhibit ToM reasoning in interpreting\nand responding to the principal's instructions. We implement two variants of\nTomcat. One, dubbed Fs-CoT, is based on a small number of examples (i.e.,\nfew-shot or Fs) demonstrating the requisite structured reasoning (i.e.,\nchain-of-thought or CoT). One, dubbed CP, relies on commonsense knowledge and\ninformation about the problem (i.e., commonsense prompt or CP). We realized\nboth variants of Tomcat on three leading large language models (LLMs), namely,\nGPT-4o, DeepSeek-R1, and Gemma-3-27B. To evaluate the effectiveness of Tomcat,\nwe conducted a study with 52 human participants in which we provided\nparticipants with the same information as the CP variant of Tomcat. We computed\nintent accuracy, action optimality, and planning optimality to measure the ToM\ncapabilities of Tomcat and our study participants. We found that Tomcat with\nFs-CoT, particularly with GPT-4o and DeepSeek-R1, achieves performance\ncomparable to the human participants, underscoring its ToM potential for\nhuman-AI collaboration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faInstruction Inference\u4efb\u52a1\uff0c\u5e76\u5b9e\u73b0\u4e86Tomcat\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63a8\u7406\u548c\u5e38\u8bc6\u63d0\u5347AI\u7684ToM\u80fd\u529b\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u5728\u67d0\u4e9b\u8bbe\u5b9a\u4e0bTomcat\u8868\u73b0\u63a5\u8fd1\u4eba\u7c7b\uff0c\u4e3a\u4eba\u673a\u534f\u4f5cAI\u53d1\u5c55\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002", "motivation": "\u7406\u8bba\u5fc3\u667a(ToM)\u662f\u667a\u80fd\u4f53\u63a8\u65ad\u4ed6\u4eba\u5fc3\u7406\u72b6\u6001\u7684\u80fd\u529b\uff0c\u5bf9\u534f\u4f5c\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5728\u52a8\u6001\u3001\u76ee\u6807\u5bfc\u5411\u3001\u534f\u540c\u73af\u5883\u4e0b\uff0c\u5bf9AI ToM\u80fd\u529b\u7684\u7cfb\u7edf\u6d4b\u8bd5\u8f83\u5c11\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u8bc4\u4f30\u7a7a\u767d\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\"Instruction Inference\"\u65b0\u4efb\u52a1\uff1a\u5728\u95f4\u63a5\u6216\u6a21\u7cca\u6307\u4ee4\u4e0b\uff0c\u6d4b\u8bc4AI\u667a\u80fd\u4f53\u534f\u52a9\u4ed6\u4eba\u8fbe\u6210\u76ee\u6807\u7684\u80fd\u529b\u3002\u63d0\u51faTomcat\u2014\u2014\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u7684ToM\u63a8\u7406\u578b\u667a\u80fd\u4f53\uff0c\u5305\u542b\u4e24\u79cd\u5b9e\u73b0\uff1a\uff081\uff09Fs-CoT(\u4ee5\u5c11\u91cf\u8303\u4f8b\u6f14\u793a\u7ed3\u6784\u5316\u63a8\u7406)\uff1b\uff082\uff09CP(\u5229\u7528\u5e38\u8bc6\u77e5\u8bc6\u548c\u4e0a\u4e0b\u6587)\u3002\u5206\u522b\u5728GPT-4o\u3001DeepSeek-R1\u3001Gemma-3-27B\u4e09\u79cdLLM\u4e0a\u5b9e\u73b0\u3002\u901a\u8fc7\u4e0e52\u540d\u4eba\u7c7b\u53c2\u4e0e\u8005\u5bf9\u6bd4\uff0c\u91c7\u7528intent accuracy\u3001action optimality\u548cplanning optimality\u4e09\u4e2a\u6307\u6807\u8bc4\u4f30\u3002", "result": "Fs-CoT\u7248\u672c\u7684Tomcat\uff08\u5c24\u5176\u5728GPT-4o\u548cDeepSeek-R1\u4e0a\uff09\u5728ToM\u76f8\u5173\u6307\u6807\u4e0a\u8868\u73b0\u4e0e\u4eba\u7c7b\u53c2\u4e0e\u8005\u76f8\u5f53\uff0c\u663e\u793a\u51faAI\u5728\u4eba\u673a\u534f\u4f5c\u4e2d\u7684\u5fc3\u667a\u63a8\u7406\u6f5c\u529b\u3002", "conclusion": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u5e76\u7ecf\u7ed3\u6784\u5316\u63a8\u7406\u8bad\u7ec3\u7684\u667a\u80fd\u4f53\uff0c\u53ef\u5c55\u73b0\u4e0e\u4eba\u7c7b\u63a5\u8fd1\u7684\u7406\u8bba\u5fc3\u667a\u63a8\u7406\u80fd\u529b\uff0c\u6709\u671b\u63d0\u5347AI\u5728\u4eba\u673a\u534f\u4f5c\u9886\u57df\u7684\u5e94\u7528\u3002"}}
{"id": "2507.03405", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.03405", "abs": "https://arxiv.org/abs/2507.03405", "authors": ["Krishna Ronanki", "Simon Arvidsson", "Johan Axell"], "title": "Prompt Engineering Guidelines for Using Large Language Models in Requirements Engineering", "comment": "Accepted for publication at the 51st Euromicro Conference Series on\n  Software Engineering and Advanced Applications (SEAA) 2025", "summary": "The rapid emergence of generative AI models like Large Language Models (LLMs)\nhas demonstrated its utility across various activities, including within\nRequirements Engineering (RE). Ensuring the quality and accuracy of\nLLM-generated output is critical, with prompt engineering serving as a key\ntechnique to guide model responses. However, existing literature provides\nlimited guidance on how prompt engineering can be leveraged, specifically for\nRE activities. The objective of this study is to explore the applicability of\nexisting prompt engineering guidelines for the effective usage of LLMs within\nRE. To achieve this goal, we began by conducting a systematic review of primary\nliterature to compile a non-exhaustive list of prompt engineering guidelines.\nThen, we conducted interviews with RE experts to present the extracted\nguidelines and gain insights on the advantages and limitations of their\napplication within RE. Our literature review indicates a shortage of prompt\nengineering guidelines for domain-specific activities, specifically for RE. Our\nproposed mapping contributes to addressing this shortage. We conclude our study\nby identifying an important future line of research within this field.", "AI": {"tldr": "LLM\u5728\u9700\u6c42\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u6b63\u589e\u957f\uff0c\u4f46\u9488\u5bf9\u6027\u63d0\u793a\u5de5\u7a0b\u6307\u5357\u7f3a\u4e4f\u3002\u672c\u6587\u901a\u8fc7\u7efc\u8ff0\u548c\u4e13\u5bb6\u8bbf\u8c08\uff0c\u603b\u7ed3\u73b0\u6709\u6307\u5357\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u51fa\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u6a21\u578b\uff08\u5982\u5927\u578b\u8bed\u8a00\u6a21\u578bLLMs\uff09\u5728\u5404\u4e2a\u9886\u57df\uff08\u5305\u62ec\u9700\u6c42\u5de5\u7a0bRE\uff09\u7684\u5e94\u7528\uff0c\u786e\u4fddLLM\u751f\u6210\u5185\u5bb9\u7684\u8d28\u91cf\u548c\u51c6\u786e\u6027\u53d8\u5f97\u975e\u5e38\u5173\u952e\u3002\u63d0\u793a\u5de5\u7a0b\u4f5c\u4e3a\u5f15\u5bfc\u6a21\u578b\u54cd\u5e94\u7684\u5173\u952e\u6280\u672f\uff0c\u4f46\u73b0\u6709\u6587\u732e\u4e2d\u5f88\u5c11\u6709\u4e13\u95e8\u9488\u5bf9\u9700\u6c42\u5de5\u7a0b\u6d3b\u52a8\u7684\u63d0\u793a\u5de5\u7a0b\u6307\u5bfc\u3002", "method": "\u672c\u7814\u7a76\u9996\u5148\u8fdb\u884c\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u6574\u7406\u73b0\u6709\u7684\u63d0\u793a\u5de5\u7a0b\u6307\u5357\u3002\u968f\u540e\u4e0e\u9700\u6c42\u5de5\u7a0b\u9886\u57df\u4e13\u5bb6\u8fdb\u884c\u8bbf\u8c08\uff0c\u7ed3\u5408\u4e13\u5bb6\u53cd\u9988\u8bc4\u4f30\u8fd9\u4e9b\u6307\u5357\u5728\u9700\u6c42\u5de5\u7a0b\u9886\u57df\u7684\u9002\u7528\u6027\u3001\u4f18\u70b9\u548c\u5c40\u9650\u6027\u3002", "result": "\u6587\u732e\u7efc\u8ff0\u663e\u793a\uff0c\u73b0\u6709\u9488\u5bf9\u9700\u6c42\u5de5\u7a0b\u7b49\u9886\u57df\u7684\u63d0\u793a\u5de5\u7a0b\u6307\u5357\u975e\u5e38\u6709\u9650\u3002\u8bba\u6587\u63d0\u51fa\u7684\u6307\u5357\u6620\u5c04\u6709\u52a9\u4e8e\u5f25\u8865\u8fd9\u4e2a\u7a7a\u767d\uff0c\u5e76\u5728\u9700\u6c42\u5de5\u7a0b\u9886\u57df\u5e94\u7528LLM\u65f6\u63d0\u4f9b\u53c2\u8003\u3002", "conclusion": "\u63d0\u793a\u5de5\u7a0b\u5bf9\u5728\u9700\u6c42\u5de5\u7a0b\u6d3b\u52a8\u4e2d\u6709\u6548\u5229\u7528LLM\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u76f8\u5173\u7684\u6307\u5357\u6709\u9650\u3002\u672c\u7814\u7a76\u901a\u8fc7\u6587\u732e\u56de\u987e\u548c\u4e13\u5bb6\u8bbf\u8c08\uff0c\u6574\u7406\u5e76\u8bc4\u4f30\u4e86\u73b0\u6709\u63d0\u793a\u5de5\u7a0b\u6307\u5357\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\uff0c\u4e3a\u8be5\u9886\u57df\u672a\u6765\u7814\u7a76\u6307\u51fa\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.03867", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.03867", "abs": "https://arxiv.org/abs/2507.03867", "authors": ["Yu Xiang Zhu", "Amos Robinson", "Sophia Roshal", "Timothy Mou", "Julian Mackay", "Jonathan Aldrich", "Alex Potanin"], "title": "Semantically Separating Nominal Wyvern for Usability and Decidability", "comment": null, "summary": "The Dependent Object Types (DOT) calculus incorporates concepts from\nfunctional languages (e.g. modules) with traditional object-oriented features\n(e.g. objects, subtyping) to achieve greater expressivity (e.g. F-bounded\npolymorphism). However, this merger of paradigms comes at the cost of subtype\ndecidability. Recent work on bringing decidability to DOT has either sacrificed\nexpressiveness or ease of use. The unrestricted construction of recursive types\nand type bounds has made subtype decidability a much harder problem than in\ntraditional object-oriented programming.\n  Recognizing this, our paper introduces Nominal Wyvern, a DOT-like dependent\ntype system that takes an alternative approach: instead of having a uniform\nstructural syntax like DOT, Nominal Wyvern is designed around a \"semantic\nseparation\" between the nominal declaration of recursive types on the one hand,\nand the structural refinement of those types when they are used on the other.\nThis design naturally guides the user to avoid writing undecidably recursive\nstructural types.\n  From a technical standpoint, this separation also makes guaranteeing\ndecidability possible by allowing for an intuitive adaptation of material/shape\nseparation, a technique for achieving subtype decidability by separating types\nresponsible for subtyping constraints from types that represent concrete data.\nThe result is a type system with syntax and structure familiar to OOP users\nthat achieves decidability without compromising the expressiveness of F-bounded\npolymorphism and module systems as they are used in practice.", "AI": {"tldr": "Nominal Wyvern \u901a\u8fc7\u5c06\u9012\u5f52\u7c7b\u578b\u58f0\u660e\u4e0e\u7ed3\u6784\u5316\u7cbe\u5316\u5206\u79bb\uff0c\u7ed3\u5408material/shape\u5206\u79bb\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u65e2\u5f3a\u8868\u8fbe\u529b\u53c8\u53ef\u5224\u5b9a\u7684\u4f9d\u8d56\u5bf9\u8c61\u7c7b\u578b\u7cfb\u7edf\uff0c\u65e0\u9700\u727a\u7272\u6613\u7528\u6027\u548cOOP\u7279\u6027\u3002", "motivation": "DOT (Dependent Object Types) \u7ed3\u5408\u4e86\u51fd\u6570\u5f0f\u8bed\u8a00\u4e0e\u4f20\u7edf\u9762\u5411\u5bf9\u8c61\u7279\u6027\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u4f46\u8fd9\u5bfc\u81f4\u5b50\u7c7b\u578b\u5224\u5b9a\u4e0d\u53ef\u5224\u5b9a\u3002\u672c\u9886\u57df\u4e3a\u63d0\u5347\u53ef\u5224\u5b9a\u6027\u5e38\u9700\u727a\u7272\u8868\u8fbe\u80fd\u529b\u6216\u6613\u7528\u6027\uff0c\u9012\u5f52\u7c7b\u578b\u53ca\u7c7b\u578b\u754c\u9650\u7684\u65e0\u7ea6\u675f\u6784\u9020\u4e5f\u52a0\u5267\u4e86\u96be\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u540d\u4e3aNominal Wyvern\u7684DOT\u98ce\u683c\u4f9d\u8d56\u7c7b\u578b\u7cfb\u7edf\uff0c\u5f15\u5165\u201c\u8bed\u4e49\u5206\u79bb\u201d\uff0c\u5373\u5728\u9012\u5f52\u7c7b\u578b\u7684\u58f0\u660e\u4e0a\u91c7\u7528\u540d\u4e49\u5316\uff0c\u5728\u7c7b\u578b\u4f7f\u7528\u65f6\u5f15\u5165\u7ed3\u6784\u5316\u7cbe\u5316\uff0c\u8f85\u4ee5material/shape\u5206\u79bb\u6280\u672f\u4ee5\u4fdd\u969c\u5b50\u7c7b\u578b\u5224\u5b9a\u6027\u3002", "result": "Nominal Wyvern\u901a\u8fc7\u540d\u4e49\u4e0e\u7ed3\u6784\u7684\u5206\u79bb\uff0c\u5b9e\u73b0\u4e86\u5b50\u7c7b\u578b\u7684\u53ef\u5224\u5b9a\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9762\u5411\u5bf9\u8c61\u5e38\u7528\u7684F-\u6709\u754c\u591a\u6001\u548c\u6a21\u5757\u7cfb\u7edf\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u5bf9OOP\u7528\u6237\u800c\u8a00\u8bed\u6cd5\u7ed3\u6784\u4e5f\u8f83\u4e3a\u719f\u6089\u3002", "conclusion": "\u901a\u8fc7\u521b\u65b0\u6027\u7684\u7c7b\u578b\u7cfb\u7edf\u8bbe\u8ba1\uff0cNominal Wyvern\u517c\u987e\u4e86\u8868\u8fbe\u6027\u548c\u5224\u5b9a\u6027\uff0c\u80fd\u89e3\u51b3DOT\u7cfb\u7edf\u96be\u4ee5\u5224\u5b9a\u5b50\u7c7b\u578b\u7684\u95ee\u9898\uff0c\u4e14\u4fbf\u4e8e\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2507.03465", "categories": ["cs.FL", "68Q45", "F.4.3"], "pdf": "https://arxiv.org/pdf/2507.03465", "abs": "https://arxiv.org/abs/2507.03465", "authors": ["Kord Eickmeyer", "Georg Schindling"], "title": "Deciding Sparseness of Regular Languages of Finite Trees and Infinite Words", "comment": null, "summary": "We study the notion of sparseness for regular languages over finite trees and\ninfinite words. A language of trees is called sparse if the relative number of\n$n$-node trees in the language tends to zero, and a language of infinite words\nis called sparse if it has measure zero in the Bernoulli probability space. We\nshow that sparseness is decidable for regular tree languages and for regular\nlanguages of infinite words. For trees, we provide characterisations in terms\nof forbidden subtrees and tree automata, leading to a linear time decision\nprocedure. For infinite words, we present a characterisation via infix\ncompleteness and give a novel proof of decidability. Moreover, in the\nnon-sparse case, our algorithm computes a measurable subset of accepted words\nthat can serve as counterexamples in almost-sure model checking. Our findings\nhave applications to automata based model checking in formal verifications and\nXML schemas, among others.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u6b63\u89c4\u6811\u8bed\u8a00\u548c\u65e0\u9650\u5b57\u6b63\u89c4\u8bed\u8a00\u7684\u201c\u7a00\u758f\u6027\u201d\u95ee\u9898\u662f\u53ef\u5224\u5b9a\u7684\uff0c\u5e76\u9488\u5bf9\u4e0d\u540c\u60c5\u5f62\u7ed9\u51fa\u4e86\u9ad8\u6548\u7b97\u6cd5\u548c\u7279\u5f81\u5316\u65b9\u6cd5\uff0c\u5bf9\u5f62\u5f0f\u9a8c\u8bc1\u548cXML\u7b49\u81ea\u52a8\u673a\u5e94\u7528\u5177\u6709\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u7a00\u758f\u6027\u4e0e\u81ea\u52a8\u673a\u7406\u8bba\u53ca\u5f62\u5f0f\u9a8c\u8bc1\u5bc6\u5207\u76f8\u5173\uff0c\u662f\u5224\u65ad\u7cfb\u7edf\u7279\u5b9a\u884c\u4e3a\u53ef\u8fbe\u6982\u7387\u548c\u8fdb\u884c\u6a21\u578b\u68c0\u6d4b\u65f6\u7684\u91cd\u8981\u5173\u6ce8\u70b9\u3002\u6b64\u5916\uff0c\u5728XML schema\u7b49\u5b9e\u9645\u5e94\u7528\u573a\u666f\uff0c\u7a00\u758f\u6027\u6709\u52a9\u4e8e\u66f4\u9ad8\u6548\u7684\u6570\u636e\u9a8c\u8bc1\u548c\u8d28\u91cf\u63a7\u5236\u3002", "method": "\u4f5c\u8005\u5bf9\u6b63\u89c4\u6811\u8bed\u8a00\u901a\u8fc7\u7981\u6b62\u5b50\u6811\u548c\u6811\u81ea\u52a8\u673a\u8fdb\u884c\u4e86\u7279\u5f81\u5316\uff0c\u63d0\u51fa\u4e86\u7ebf\u6027\u65f6\u95f4\u51b3\u7b56\u6d41\u7a0b\uff1b\u5bf9\u65e0\u9650\u5b57\u7684\u6b63\u89c4\u8bed\u8a00\u91c7\u7528inf\u4fdd\u5168\u6027\u6765\u523b\u753b\uff0c\u5e76\u7ed9\u51fa\u4e86\u65b0\u7684\u53ef\u5224\u5b9a\u6027\u8bc1\u660e\u3002\u5bf9\u4e8e\u975e\u7a00\u758f\u7684\u60c5\u51b5\uff0c\u7b97\u6cd5\u8fd8\u53ef\u6784\u9020\u51fa\u53ef\u6d4b\u7684\u53cd\u4f8b\u96c6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\u5224\u65ad\u6b63\u89c4\u6811\u8bed\u8a00\u7684\u7a00\u758f\u6027\uff0c\u4ee5\u53ca\u4e00\u79cd\u5bf9\u65e0\u9650\u5b57\u6b63\u89c4\u8bed\u8a00\u7a00\u758f\u6027\u7684\u53ef\u5224\u5b9a\u65b9\u6cd5\u3002\u7b97\u6cd5\u5206\u6790\u548c\u7279\u5f81\u5316\u4e3a\u76f8\u5173\u6a21\u578b\u68c0\u6d4b\u7b49\u9886\u57df\u63d0\u4f9b\u4e86\u5de5\u5177\uff0c\u80fd\u5728\u975e\u7a00\u758f\u60c5\u51b5\u4e0b\u627e\u5230\u53cd\u4f8b\u3002", "conclusion": "\u672c\u6587\u7814\u7a76\u4e86\u201c\u7a00\u758f\u6027\u201d\u5728\u6709\u9650\u6811\u548c\u65e0\u9650\u5b57\u4e0a\u6b63\u89c4\u8bed\u8a00\u4e2d\u7684\u5224\u5b9a\u95ee\u9898\uff0c\u5e76\u7ed9\u51fa\u4e86\u76f8\u5173\u7684\u5224\u5b9a\u7b97\u6cd5\u548c\u7279\u5f81\u5316\u65b9\u6cd5\u3002\u7a00\u758f\u6027\u5bf9\u6b63\u89c4\u6811\u8bed\u8a00\u548c\u65e0\u9650\u5b57\u8bed\u8a00\u5747\u662f\u53ef\u5224\u5b9a\u7684\uff0c\u5e76\u53ef\u9ad8\u6548\u5b9e\u73b0\u3002"}}
{"id": "2507.03314", "categories": ["cs.LO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03314", "abs": "https://arxiv.org/abs/2507.03314", "authors": ["Zsolt Zombori", "Bal\u00e1zs Indruck"], "title": "Partial Label Learning for Automated Theorem Proving", "comment": null, "summary": "We formulate learning guided Automated Theorem Proving as Partial Label\nLearning, building the first bridge across these fields of research and\nproviding a theoretical framework for dealing with alternative proofs during\nlearning. We use the plCoP theorem prover to demonstrate that methods from the\nPartial Label Learning literature tend to increase the performance of learning\nassisted theorem provers.", "AI": {"tldr": "\u672c\u8bba\u6587\u9996\u6b21\u5c06\u90e8\u5206\u6807\u7b7e\u5b66\u4e60\u7406\u8bba\u5f15\u5165\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\uff0c\u63d0\u51fa\u65b0\u9896\u7684\u7406\u8bba\u6846\u67b6\u5904\u7406\u66ff\u4ee3\u6027\u8bc1\u660e\u8def\u5f84\uff0c\u5e76\u901a\u8fc7plCoP\u8bc1\u660e\u5668\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u5b9ePLL\u65b9\u6cd5\u80fd\u63d0\u5347\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u6027\u80fd\u3002", "motivation": "\u5728\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u4e2d\uff0c\u5e38\u5e38\u5b58\u5728\u591a\u79cd\u8bc1\u660e\u8def\u5f84\uff0c\u5982\u4f55\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u6709\u6548\u5904\u7406\u548c\u5229\u7528\u8fd9\u4e9b\u4e0d\u540c\u7684\u8bc1\u660e\u9009\u62e9\u662f\u4e00\u4e2a\u6311\u6218\u3002\u90e8\u5206\u6807\u7b7e\u5b66\u4e60\u4e3a\u5904\u7406\u6709\u591a\u91cd\u6807\u7b7e\u9009\u62e9\u7684\u5b66\u4e60\u573a\u666f\u63d0\u4f9b\u4e86\u89e3\u51b3\u601d\u8def\uff0c\u56e0\u6b64\u5c1d\u8bd5\u5c06\u5176\u5e94\u7528\u5230\u5b9a\u7406\u8bc1\u660e\u9886\u57df\u3002", "method": "\u5c06\u5b66\u4e60\u9a71\u52a8\u7684\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u95ee\u9898\u5efa\u6a21\u4e3a\u90e8\u5206\u6807\u7b7e\u5b66\u4e60\u95ee\u9898\uff0c\u5e76\u5229\u7528plCoP\u5b9a\u7406\u8bc1\u660e\u5668\uff0c\u7ed3\u5408PLL\u9886\u57df\u7684\u65b9\u6cd5\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u91c7\u7528\u90e8\u5206\u6807\u7b7e\u5b66\u4e60\u65b9\u6cd5\u540e\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u53ef\u6709\u6548\u63d0\u5347\u5e26\u6709\u5b66\u4e60\u8f85\u52a9\u7684\u5b9a\u7406\u8bc1\u660e\u5668\u7684\u6027\u80fd\u3002", "conclusion": "\u5c06\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\uff08Automated Theorem Proving, ATP\uff09\u4e0e\u90e8\u5206\u6807\u7b7e\u5b66\u4e60\uff08Partial Label Learning, PLL\uff09\u7ed3\u5408\uff0c\u53ef\u4ee5\u4e3a\u5904\u7406\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u5b58\u5728\u7684\u591a\u79cd\u53ef\u80fd\u8bc1\u660e\u65b9\u5f0f\u63d0\u4f9b\u7406\u8bba\u652f\u6301\uff0c\u5e76\u63d0\u5347\u5b9a\u7406\u8bc1\u660e\u5668\u7684\u8868\u73b0\u3002"}}
{"id": "2507.02938", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02938", "abs": "https://arxiv.org/abs/2507.02938", "authors": ["Jiachen Liu", "Ziheng Geng", "Ran Cao", "Lu Cheng", "Paolo Bocchini", "Minghui Cheng"], "title": "A Large Language Model-Empowered Agent for Reliable and Robust Structural Analysis", "comment": null, "summary": "Large language models (LLMs) have exhibited remarkable capabilities across\ndiverse open-domain tasks, yet their application in specialized domains such as\ncivil engineering remains largely unexplored. This paper starts bridging this\ngap by evaluating and enhancing the reliability and robustness of LLMs in\nstructural analysis of beams. Reliability is assessed through the accuracy of\ncorrect outputs under repetitive runs of the same problems, whereas robustness\nis evaluated via the performance across varying load and boundary conditions. A\nbenchmark dataset, comprising eight beam analysis problems, is created to test\nthe Llama-3.3 70B Instruct model. Results show that, despite a qualitative\nunderstanding of structural mechanics, the LLM lacks the quantitative\nreliability and robustness for engineering applications. To address these\nlimitations, a shift is proposed that reframes the structural analysis as code\ngeneration tasks. Accordingly, an LLM-empowered agent is developed that (a)\nintegrates chain-of-thought and few-shot prompting to generate accurate\nOpeeSeesPy code, and (b) automatically executes the code to produce structural\nanalysis results. Experimental results demonstrate that the agent achieves\naccuracy exceeding 99.0% on the benchmark dataset, exhibiting reliable and\nrobust performance across diverse conditions. Ablation studies highlight the\ncomplete example and function usage examples as the primary contributors to the\nagent's enhanced performance.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86LLM\u5728\u6881\u7ed3\u6784\u5206\u6790\u4e2d\u7684\u53ef\u9760\u6027\u4e0e\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u5176\u539f\u59cb\u80fd\u529b\u6709\u9650\u3002\u901a\u8fc7\u4ee3\u7801\u751f\u6210\u65b0\u8303\u5f0f\u53ca\u81ea\u52a8\u6267\u884c\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u51c6\u786e\u7387\u8d8599%\u3002\u4e3aLLM\u5728\u5de5\u7a0b\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u5207\u5b9e\u53ef\u884c\u7684\u8def\u5f84\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8bb8\u591a\u901a\u7528\u9886\u57df\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u5982\u571f\u6728\u5de5\u7a0b\u7b49\u4e13\u4e1a\u9886\u57df\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002\u57fa\u4e8e\u6b64\uff0c\u4f5c\u8005\u5e0c\u671b\u63a2\u7d22\u5e76\u63d0\u5347LLM\u5728\u7ed3\u6784\u529b\u5b66\u5206\u6790\uff08\u5982\u6881\u7684\u5206\u6790\uff09\u4e2d\u7684\u53ef\u9760\u6027\u4e0e\u9c81\u68d2\u6027\u3002", "method": "\uff081\uff09\u8bc4\u4ef7LLM\uff08Llama-3.3 70B Instruct\uff09\u5728\u6881\u7ed3\u6784\u5206\u6790\u4e2d\u7684\u53ef\u9760\u6027\uff08\u591a\u6b21\u540c\u9898\u8f93\u51fa\u6b63\u786e\u7387\uff09\u548c\u9c81\u68d2\u6027\uff08\u5728\u4e0d\u540c\u8377\u8f7d\u548c\u8fb9\u754c\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\uff09\uff1b\uff082\uff09\u63d0\u51fa\u5c06\u7ed3\u6784\u5206\u6790\u95ee\u9898\u8f6c\u5316\u4e3a\u4ee3\u7801\u751f\u6210\u4efb\u52a1\uff0c\u5e76\u5f00\u53d1\u96c6\u6210\u94fe\u5f0f\u601d\u7ef4\u4e0efew-shot\u63d0\u793a\u7684LLM-agent\uff0c\u5b9e\u73b0\u81ea\u52a8\u751f\u4ea7\u5e76\u8fd0\u884c OpenSeesPy \u4ee3\u7801\uff1b\uff083\uff09\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u5206\u6790\u5f71\u54cd\u6027\u80fd\u63d0\u5347\u7684\u5173\u952e\u8981\u7d20\u3002", "result": "\u521d\u6b65\u6d4b\u8bd5\u663e\u793a\uff0c\u867d\u7136LLM\u5bf9\u7ed3\u6784\u529b\u5b66\u6709\u4e00\u5b9a\u5b9a\u6027\u7406\u89e3\uff0c\u4f46\u5728\u5de5\u7a0b\u5e94\u7528\u4e0a\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\u4e0d\u8db3\u3002\u57fa\u4e8e\u4ee3\u7801\u751f\u6210\u7684\u65b0\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0cLLM-agent\u5728\u57fa\u51c6\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u8d85\u8fc799.0%\uff0c\u9c81\u68d2\u6027\u4f18\u826f\u3002\u6d88\u878d\u5b9e\u9a8c\u53d1\u73b0\u5b8c\u6574\u6848\u4f8b\u548c\u51fd\u6570\u4f7f\u7528\u793a\u4f8b\u662f\u6027\u80fd\u63d0\u5347\u7684\u5173\u952e\u3002", "conclusion": "LLM\u539f\u751f\u7528\u4e8e\u571f\u6728\u5de5\u7a0b\u7ed3\u6784\u5206\u6790\u5c1a\u4e0d\u5177\u5907\u5de5\u7a0b\u7ea7\u53ef\u9760\u6027\uff0c\u4f46\u901a\u8fc7\u5c06\u4efb\u52a1\u8f6c\u5316\u4e3a\u4ee3\u7801\u751f\u6210\u5e76\u81ea\u52a8\u6267\u884c\uff0c\u53ef\u6781\u5927\u63d0\u5347\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\uff0c\u663e\u793a\u51faLLM\u5728\u4e13\u4e1a\u5de5\u7a0b\u9886\u57df\u5e94\u7528\u7684\u5de8\u5927\u6f5c\u529b\u3002\u8be5\u65b9\u6cd5\u5bf9\u5176\u4ed6\u4e13\u4e1a\u9886\u57df\u4e5f\u6709\u53c2\u8003\u610f\u4e49\u3002"}}
{"id": "2507.03515", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.03515", "abs": "https://arxiv.org/abs/2507.03515", "authors": ["Radouane Bouchekir", "Michell Guzman Cancimance"], "title": "Enhancing Uncertainty Quantification for Runtime Safety Assurance Using Causal Risk Analysis and Operational Design Domain", "comment": null, "summary": "Ensuring the runtime safety of autonomous systems remains challenging due to\ndeep learning components' inherent uncertainty and their sensitivity to\nenvironmental changes. In this paper, we propose an enhancement of traditional\nuncertainty quantification by explicitly incorporating environmental conditions\nusing risk-based causal analysis. We leverage Hazard Analysis and Risk\nAssessment (HARA) and fault tree modeling to identify critical operational\nconditions affecting system functionality. These conditions, together with\nuncertainties from the data and model, are integrated into a unified Bayesian\nNetwork (BN). At runtime, this BN is instantiated using real-time environmental\nobservations to infer a probabilistic distribution over the safety estimation.\nThis distribution enables the computation of both expected performance and its\nassociated variance, providing a dynamic and context-aware measure of\nuncertainty. We demonstrate our approach through a case study of the Object\nDetection (OD) component in an Automated Valet Parking (AVP).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u98ce\u9669\u56e0\u679c\u5206\u6790\u3001\u878d\u5408\u73af\u5883\u4fe1\u606f\u7684\u8d1d\u53f6\u65af\u7f51\u7edc\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u7cfb\u7edf\u8fd0\u884c\u65f6\u66f4\u5168\u9762\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u5b89\u5168\u6027\u5ea6\u91cf\uff0c\u5e76\u5728\u81ea\u52a8\u4ee3\u5ba2\u6cca\u8f66\u76ee\u6807\u68c0\u6d4b\u573a\u666f\u4e0b\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "motivation": "\u76ee\u524d\u81ea\u52a8\u5316\u7cfb\u7edf\u7684\u8fd0\u884c\u5b89\u5168\u6027\u9762\u5bf9\u6df1\u5ea6\u5b66\u4e60\u7ec4\u4ef6\u4e0d\u786e\u5b9a\u6027\u53ca\u5bf9\u73af\u5883\u53d8\u5316\u654f\u611f\u6027\u5b58\u5728\u6311\u6218\u3002\u672c\u6587\u63d0\u51fa\u5bf9\u73b0\u6709\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u65b9\u5f0f\u7684\u589e\u5f3a\uff0c\u65e8\u5728\u7ed3\u5408\u8fd0\u884c\u73af\u5883\u7684\u4fe1\u606f\u8fdb\u884c\u66f4\u51c6\u786e\u7684\u98ce\u9669\u91cf\u5316\uff0c\u63d0\u5347\u590d\u6742\u73af\u5883\u4e0b\u7cfb\u7edf\u7684\u5b89\u5168\u4fdd\u969c\u80fd\u529b\u3002", "method": "\u7ed3\u5408\u98ce\u9669\u5bfc\u5411\u7684\u56e0\u679c\u5206\u6790\uff0c\u4f7f\u7528HARA\uff08\u5371\u9669\u5206\u6790\u4e0e\u98ce\u9669\u8bc4\u4f30\uff09\u548c\u6545\u969c\u6811\u5efa\u6a21\uff0c\u8bc6\u522b\u5f71\u54cd\u7cfb\u7edf\u529f\u80fd\u7684\u5173\u952e\u8fd0\u884c\u6761\u4ef6\uff0c\u5e76\u5c06\u8fd9\u4e9b\u6761\u4ef6\u4e0e\u6570\u636e\u548c\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u4e00\u540c\u96c6\u6210\u5230\u7edf\u4e00\u7684\u8d1d\u53f6\u65af\u7f51\u7edc\uff08BN\uff09\u4e2d\u3002\u8fd0\u884c\u65f6\u5229\u7528\u5b9e\u65f6\u73af\u5883\u89c2\u6d4b\u5bf9BN\u8fdb\u884c\u5b9e\u4f8b\u5316\uff0c\u63a8\u65ad\u5b89\u5168\u4f30\u8ba1\u7684\u6982\u7387\u5206\u5e03\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u7ed3\u5408\u73af\u5883\u6761\u4ef6\uff0c\u5b9e\u73b0\u52a8\u6001\u3001\u591a\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u3002\u901a\u8fc7\u5bf9\u81ea\u52a8\u4ee3\u5ba2\u6cca\u8f66\uff08AVP\uff09\u4e2d\u7684\u76ee\u6807\u68c0\u6d4b\uff08OD\uff09\u7ec4\u4ef6\u6848\u4f8b\u7814\u7a76\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u73af\u5883\u56e0\u7d20\u3001\u6570\u636e\u548c\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u5230\u7edf\u4e00\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u66f4\u7cbe\u7ec6\u5316\u3001\u52a8\u6001\u7684\u5b89\u5168\u4f30\u8ba1\u624b\u6bb5\uff0c\u4e3a\u81ea\u52a8\u5316\u7cfb\u7edf\u8fd0\u884c\u5b89\u5168\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u6839\u636e\u5b9e\u65f6\u73af\u5883\u5bf9\u4e0d\u786e\u5b9a\u6027\u8fdb\u884c\u81ea\u9002\u5e94\u8c03\u6574\u3002"}}
{"id": "2507.04298", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.04298", "abs": "https://arxiv.org/abs/2507.04298", "authors": ["Youngju Song", "Minki Cho"], "title": "CCR 2.0: High-level Reasoning for Conditional Refinements", "comment": null, "summary": "In recent years, great progress has been made in the field of formal\nverification for low-level systems. Many of them are based on one of two\npopular approaches: refinement or separation logic. These two approaches are\nvery different in nature and offer complementary benefits in terms of\ncompositionality. Recently, to fuse these benefits in a unified mechanism, a\nnew approach called Conditional Contextual Refinement (CCR 1.0 for short) was\nproposed. In this paper, we advance the model of CCR 1.0 and provide novel and\nintuitive reasoning principles, resulting in: CCR 2.0. Specifically, CCR 2.0\n(i) comes with a better compositionality theorem, having the practical benefit\nof facilitating more proof reuse, and (ii) provides a proof technique that\nhides model-level (i.e., resources of the separation logic) details from the\nuser. Achieving this goal was challenging due to non-trivial counterexamples\nwhich necessitated us to devise novel notions. Our results are formalized in\nCoq.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCCR 2.0\uff0c\u6709\u6548\u878d\u5408\u7cbe\u5316\u4e0e\u5206\u79bb\u903b\u8f91\u7684\u4f18\u52bf\uff0c\u63d0\u5347\u4e86\u4f4e\u5c42\u7cfb\u7edf\u5f62\u5f0f\u9a8c\u8bc1\u4e2d\u7684\u7ec4\u5408\u6027\u4e0e\u8bc1\u660e\u590d\u7528\uff0c\u76f8\u5173\u65b9\u6cd5\u5df2\u5728Coq\u4e2d\u5f62\u5f0f\u5316\u3002", "motivation": "\u73b0\u6709\u7684\u4e24\u79cd\u4e3b\u6d41\u4f4e\u5c42\u7cfb\u7edf\u5f62\u5f0f\u9a8c\u8bc1\u65b9\u6cd5\u2014\u2014\u7cbe\u5316(refinement)\u4e0e\u5206\u79bb\u903b\u8f91(separation logic)\u2014\u2014\u5404\u81ea\u6709\u4e0d\u540c\u4e14\u4e92\u8865\u7684\u53ef\u7ec4\u5408\u6027\u4f18\u52bf\uff0c\u56e0\u6b64\u6709\u9700\u6c42\u5c06\u4e24\u8005\u4f18\u70b9\u878d\u5408\u3002\u6b64\u524d\u63d0\u51fa\u7684CCR 1.0\u521d\u6b65\u5b9e\u73b0\u4e86\u8fd9\u70b9\uff0c\u4f46\u5b58\u5728\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "\u4f5c\u8005\u6539\u8fdb\u5e76\u62d3\u5c55\u4e86CCR 1.0\u6a21\u578b\uff0c\u63d0\u51fa\u4e86CCR 2.0\uff0c\u5e76\u5728\u5176\u4e2d\u5f15\u5165\u4e86\u66f4\u65b0\u7684\u7ec4\u5408\u6027\u5b9a\u7406\u4e0e\u66f4\u9ad8\u6548\u7684\u8bc1\u660e\u6280\u672f\u3002\u8fd9\u4e9b\u65b9\u6cd5\u6709\u6548\u5730\u9690\u85cf\u4e86\u5e95\u5c42\u6a21\u578b\u7ec6\u8282\uff0c\u7ed3\u679c\u5728Coq\u4e2d\u5f97\u5230\u5f62\u5f0f\u5316\u3002", "result": "CCR 2.0\u5177\u6709\u66f4\u597d\u7684\u7ec4\u5408\u6027\u5b9a\u7406\uff0c\u80fd\u5e26\u6765\u66f4\u591a\u8bc1\u660e\u590d\u7528\uff0c\u4e14\u65b0\u8bc1\u660e\u6280\u672f\u8ba9\u7528\u6237\u514d\u4e8e\u5904\u7406\u5206\u79bb\u903b\u8f91\u5e95\u5c42\u8d44\u6e90\uff1b\u6a21\u578b\u7ecf\u8fc7Coq\u5f62\u5f0f\u9a8c\u8bc1\u3002", "conclusion": "CCR 2.0\u4e3a\u878d\u5408\u7cfb\u7edf\u9a8c\u8bc1\u7684\u4e3b\u6d41\u65b9\u6cd5\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u7406\u8bba\u57fa\u7840\u548c\u5de5\u5177\u652f\u6301\uff0c\u63d0\u5347\u4e86\u8bc1\u660e\u5de5\u4f5c\u7684\u6548\u7387\u4e0e\u53ef\u590d\u7528\u6027\u3002"}}
{"id": "2507.04080", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.04080", "abs": "https://arxiv.org/abs/2507.04080", "authors": ["Naoki Nishida", "Misaki Kojima", "Yuto Nakamura"], "title": "Difference of Constrained Patterns in Logically Constrained Term Rewrite Systems (Full Version)", "comment": "38 pages", "summary": "Considering patterns as sets of their instances, a difference operator over\npatterns computes a finite set of two given patterns, which represents the\ndifference between the dividend pattern and the divisor pattern. A complement\nof a pattern is a set of patterns, the ground constructor instances of which\ncomprise the complement set of the ground constructor instances of the former\npattern. Given finitely many unconstrained linear patterns, using a difference\noperator over linear patterns, a known complement algorithm returns a finite\nset of linear patterns as a complement of the given patterns. In this paper, we\nextend the difference operator and complement algorithm to constrained linear\npatterns used in logically constrained term rewrite systems (LCTRSs, for short)\nthat have no user-defined constructor term with a sort for built-in values.\nThen, as for left-linear TRSs, using the complement algorithm, we show that\nquasi-reducibility is decidable for such LCTRSs with decidable built-in\ntheories. For the single use of the difference operator over (constrained)\npatterns, only divisor patterns are required to be linear.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u5dee\u5f02\u4e0e\u8865\u96c6\u7b97\u6cd5\u4ee5\u8986\u76d6\u903b\u8f91\u7ea6\u675f\u91cd\u5199\u7cfb\u7edf\u4e2d\u7684\u53d7\u7ea6\u675f\u7ebf\u6027\u6a21\u5f0f\uff0c\u4ece\u800c\u4f7f\u51c6\u53ef\u7ea6\u6027\u5728\u7279\u5b9aLCTRS\u4e2d\u53ef\u5224\u5b9a\uff0c\u5e76\u63d0\u5347\u4e86\u76f8\u5173\u7b97\u5b50\u7684\u9002\u7528\u8303\u56f4\u3002", "motivation": "\u5728\u672f\u8bed\u91cd\u5199\u7cfb\u7edf\uff08\u7279\u522b\u662f\u903b\u8f91\u7ea6\u675f\u672f\u8bed\u91cd\u5199\u7cfb\u7edf\uff0cLCTRSs\uff09\u4e2d\uff0c\u51c6\u786e\u8868\u793a\u548c\u5206\u6790\u6a21\u5f0f\u4e4b\u95f4\u7684\u5dee\u5f02\u4e0e\u8865\u96c6\u5bf9\u5224\u5b9a\u67d0\u4e9b\u6027\u8d28\uff08\u5982\u51c6\u53ef\u7ea6\u6027\uff09\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u5bf9\u4e8e\u5e26\u7ea6\u675f\u7684\u7ebf\u6027\u6a21\u5f0f\uff08constrained linear patterns\uff09\u53ca\u5176\u8865\u96c6\u7b97\u6cd5\u5b58\u5728\u9650\u5236\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u6269\u5c55\u8fd9\u4e9b\u57fa\u672c\u8fd0\u7b97\uff0c\u4ee5\u589e\u5f3a\u5bf9\u66f4\u5e7f\u6cdb\u7cfb\u7edf\u7684\u5206\u6790\u80fd\u529b\u3002", "method": "\u672c\u6587\u6269\u5c55\u4e86\u73b0\u6709\u9488\u5bf9\u7ebf\u6027\u6a21\u5f0f\u7684\u201c\u5dee\u5f02\u7b97\u5b50\u201d\u548c\u201c\u8865\u96c6\u7b97\u6cd5\u201d\uff0c\u4f7f\u5176\u9002\u7528\u4e8eLCTRS\u4e2d\u53d7\u7ea6\u675f\u7684\u7ebf\u6027\u6a21\u5f0f\uff0c\u524d\u63d0\u662f\u5176\u4e2d\u4e0d\u5305\u542b\u5e26\u5185\u5efa\u503c\u7c7b\u578b\u7684\u7528\u6237\u81ea\u5b9a\u4e49\u6784\u9020\u5b50\u9879\u3002\u5e76\u501f\u52a9\u8fd9\u79cd\u6269\u5c55\u7684\u7b97\u6cd5\uff0c\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e86\u9488\u5bf9\u8fd9\u7c7bLCTRS\uff0c\u82e5\u5185\u5efa\u7406\u8bba\u53ef\u5224\u5b9a\uff0c\u5219\u51c6\u53ef\u7ea6\u6027\u4e5f\u53ef\u5224\u5b9a\u3002\u6b64\u5916\uff0c\u5bf9\u4e8e\u5dee\u5f02\u7b97\u5b50\u800c\u8a00\uff0c\u53ea\u9700\u8981\u88ab\u9664\u6570\uff08divisor\uff09\u6a21\u5f0f\u662f\u7ebf\u6027\u7684\uff0c\u800c\u88ab\u51cf\u6570\uff08dividend\uff09\u53ef\u4ee5\u66f4\u4e00\u822c\u3002", "result": "\u672c\u6587\u63d0\u51fa\u7684\u6269\u5c55\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u751f\u6210\u53d7\u7ea6\u675f\u7ebf\u6027\u6a21\u5f0f\u7684\u5dee\u5f02\u96c6\u4e0e\u8865\u96c6\uff0c\u4ece\u800c\u652f\u6301\u4e0a\u8ff0LCTRS\u4e2d\u51c6\u53ef\u7ea6\u6027\u7684\u53ef\u5224\u5b9a\u6027\u5206\u6790\uff0c\u5e76\u8fdb\u4e00\u6b65\u653e\u5bbd\u4e86\u5dee\u5f02\u7b97\u5b50\u5bf9\u88ab\u51cf\u6570\u6a21\u5f0f\u7684\u8981\u6c42\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u5dee\u5f02\u7b97\u5b50\u4e0e\u8865\u96c6\u7b97\u6cd5\u7684\u6269\u5c55\uff0c\u672c\u6587\u4f7f\u5f97LCTRS\uff08\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff09\u4e0a\u7684\u51c6\u53ef\u7ea6\u6027\u5224\u5b9a\u6210\u4e3a\u53ef\u80fd\uff0c\u5e76\u4e3a\u6b64\u7c7b\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u7406\u8bba\u5de5\u5177\u548c\u7b97\u6cd5\u57fa\u7840\u3002"}}
{"id": "2507.02940", "categories": ["cs.CL", "cs.AI", "quant-ph"], "pdf": "https://arxiv.org/pdf/2507.02940", "abs": "https://arxiv.org/abs/2507.02940", "authors": ["Tiffany Duneau"], "title": "Towards a Comparative Framework for Compositional AI Models", "comment": null, "summary": "The DisCoCirc framework for natural language processing allows the\nconstruction of compositional models of text, by combining units for individual\nwords together according to the grammatical structure of the text. The\ncompositional nature of a model can give rise to two things: compositional\ngeneralisation -- the ability of a model to generalise outside its training\ndistribution by learning compositional rules underpinning the entire data\ndistribution -- and compositional interpretability -- making sense of how the\nmodel works by inspecting its modular components in isolation, as well as the\nprocesses through which these components are combined. We present these notions\nin a framework-agnostic way using the language of category theory, and adapt a\nseries of tests for compositional generalisation to this setting.\n  Applying this to the DisCoCirc framework, we consider how well a selection of\nmodels can learn to compositionally generalise. We compare both quantum circuit\nbased models, as well as classical neural networks, on a dataset derived from\none of the bAbI tasks, extended to test a series of aspects of\ncompositionality. Both architectures score within 5% of one another on the\nproductivity and substitutivity tasks, but differ by at least 10% for the\nsystematicity task, and exhibit different trends on the overgeneralisation\ntasks. Overall, we find the neural models are more prone to overfitting the\nTrain data. Additionally, we demonstrate how to interpret a compositional model\non one of the trained models. By considering how the model components interact\nwith one another, we explain how the model behaves.", "AI": {"tldr": "\u672c\u7814\u7a76\u57fa\u4e8eDisCoCirc\u6846\u67b6\uff0c\u5229\u7528\u8303\u7574\u7406\u8bba\u5bf9\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6a21\u578b\u7684\u53ef\u7ec4\u5408\u6027\u548c\u53ef\u89e3\u91ca\u6027\u8fdb\u884c\u4e86\u5206\u6790\u4e0e\u5b9e\u9a8c\u3002\u5bf9\u6bd4\u91cf\u5b50\u4e0e\u7ecf\u5178\u6a21\u578b\uff0c\u53d1\u73b0\u4e24\u8005\u5728\u67d0\u4e9b\u53ef\u7ec4\u5408\u6027\u4efb\u52a1\u4e0a\u8868\u73b0\u63a5\u8fd1\uff0c\u4f46\u5728\u7cfb\u7edf\u6027\u548c\u6cdb\u5316\u503e\u5411\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u795e\u7ecf\u7f51\u7edc\u6613\u8fc7\u62df\u5408\uff0c\u4e14\u6a21\u578b\u53ef\u7ec4\u5408\u6027\u89e3\u91ca\u6709\u53ef\u64cd\u4f5c\u8def\u5f84\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u5bf9\u6a21\u578b\u7684\u53ef\u7ec4\u5408\u6027\u5173\u6ce8\u63d0\u9ad8\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u4e0d\u540c\u6a21\u578b\uff08\u5305\u62ec\u91cf\u5b50\u7535\u8def\u6a21\u578b\u548c\u7ecf\u5178\u795e\u7ecf\u7f51\u7edc\uff09\u5728\u6587\u672c\u53ef\u7ec4\u5408\u6027\u3001\u6cdb\u5316\u80fd\u529b\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u884c\u4e3a\u53ca\u5dee\u5f02\u3002", "method": "\u4f5c\u8005\u5728DisCoCirc\u6846\u67b6\u4e0b\uff0c\u5229\u7528\u8303\u7574\u7406\u8bba\u5f62\u5f0f\u5316\u63cf\u8ff0\u4e86\u53ef\u7ec4\u5408\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u3002\u7136\u540e\u57fa\u4e8ebAbI\u4efb\u52a1\u6269\u5c55\u51fa\u7684\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1\u5e76\u5bf9\u6bd4\u4e86\u91cf\u5b50\u7535\u8def\u7c7b\u6a21\u578b\u4e0e\u7ecf\u5178\u795e\u7ecf\u7f51\u7edc\u5728\u591a\u9879\u53ef\u7ec4\u5408\u6027\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002\u8fd8\u8fdb\u4e00\u6b65\u5206\u6790\u5176\u4e2d\u4e00\u4e2a\u8bad\u7ec3\u540e\u7684\u6a21\u578b\uff0c\u89e3\u91ca\u4e86\u5176\u6a21\u5757\u95f4\u5982\u4f55\u4ea4\u4e92\u5e76\u9a71\u52a8\u6a21\u578b\u884c\u4e3a\u3002", "result": "\u5728\u4ea7\u51fa\u6027\u548c\u53ef\u66ff\u6362\u6027\u4efb\u52a1\u4e2d\uff0c\u4e24\u7c7b\u6a21\u578b\u8868\u73b0\u76f8\u8fd1\uff0c\u5f97\u5206\u5dee\u8ddd\u57285%\u4ee5\u5185\u3002\u4f46\u5728\u7cfb\u7edf\u6027\u4efb\u52a1\u4e0a\u5dee\u8ddd\u81f3\u5c11\u8fbe\u523010%\uff0c\u5728\u8fc7\u5ea6\u6cdb\u5316\u4efb\u52a1\u4e0a\u8d8b\u52bf\u4e5f\u4e0d\u540c\u3002\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5728\u8bad\u7ec3\u96c6\u4e0a\u66f4\u5bb9\u6613\u8fc7\u62df\u5408\u3002\u4f5c\u8005\u8fd8\u5c55\u793a\u4e86\u5bf9\u4e00\u4e2a\u8bad\u7ec3\u6a21\u578b\u7684\u7ec4\u5408\u884c\u4e3a\u7684\u89e3\u91ca\u3002", "conclusion": "DisCoCirc\u6846\u67b6\u548c\u76f8\u5e94\u7684\u57fa\u51c6\u4efb\u52a1\u6709\u52a9\u4e8e\u7cfb\u7edf\u6027\u5206\u6790\u6a21\u578b\u7684\u53ef\u7ec4\u5408\u6027\u53ca\u53ef\u89e3\u91ca\u6027\u3002\u91cf\u5b50\u4e0e\u7ecf\u5178\u6a21\u578b\u5728\u53ef\u7ec4\u5408\u6cdb\u5316\u4e0a\u7684\u7ec6\u5fae\u8868\u73b0\u5dee\u5f02\u63ed\u793a\u5176\u5404\u81ea\u7684\u4f18\u52a3\u3002\u8be5\u6846\u67b6\u6709\u52a9\u4e8e\u8fdb\u4e00\u6b65\u63a2\u7d22\u548c\u63d0\u5347\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6a21\u578b\u7684\u6cdb\u5316\u53ca\u89e3\u91ca\u80fd\u529b\u3002"}}
{"id": "2507.03527", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.03527", "abs": "https://arxiv.org/abs/2507.03527", "authors": ["Dulaji Hidellaarachchi", "John Grundy", "Rashina Hoda"], "title": "The Role of Humour in Software Engineering -- A Literature Review and Preliminary Taxonomy", "comment": "Accepted to publish in Journal of Software Systems (JSS) New Idea\n  Track 2025 (23 pages, 1 figure)", "summary": "Humour has long been recognized as a key factor in enhancing creativity,\ngroup effectiveness, and employee well-being across various domains. However,\nits occurrence and impact within software engineering (SE) teams remains\nunder-explored. This paper introduces a comprehensive, literature review-based\ntaxonomy exploring the characterisation and use of humour in SE teams, with the\ngoal of boosting productivity, improving communication, and fostering a\npositive work environment while emphasising the responsible use of humour to\nmitigate its potential negative impacts. Drawing from a wide array of studies\nin psychology, sociology, and organizational behaviour, our proposed framework\ncategorizes humour into distinct theories, styles, models, and scales, offering\nSE professionals and researchers a structured approach to understanding humour\nin their work. This study also addresses the unique challenges of applying\nhumour in SE, highlighting its potential benefits while acknowledging the need\nfor further empirical validation in this context. Ultimately, our study aims to\npave the way for more cohesive, creative, and psychologically supportive SE\nenvironments through the strategic use of humour.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\uff0c\u63d0\u51fa\u4e86\u5e7d\u9ed8\u5728\u8f6f\u4ef6\u5de5\u7a0b\u56e2\u961f\u4e2d\u7684\u5206\u7c7b\u548c\u5e94\u7528\u6846\u67b6\uff0c\u6307\u51fa\u5176\u5bf9\u56e2\u961f\u6c14\u6c1b\u548c\u751f\u4ea7\u529b\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u540c\u65f6\u63d0\u9192\u9700\u8d1f\u8d23\u4efb\u4f7f\u7528\u548c\u8fdb\u4e00\u6b65\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "motivation": "\u5e7d\u9ed8\u88ab\u5e7f\u6cdb\u8ba4\u4e3a\u80fd\u63d0\u5347\u521b\u9020\u529b\u3001\u56e2\u961f\u6548\u80fd\u548c\u5458\u5de5\u5e78\u798f\u611f\uff0c\u4f46\u5728\u8f6f\u4ef6\u5de5\u7a0b\u56e2\u961f\u4e2d\u7684\u5e94\u7528\u4e0e\u5f71\u54cd\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u4f5c\u8005\u5e0c\u671b\u7cfb\u7edf\u68b3\u7406\u548c\u63a2\u8ba8\u5e7d\u9ed8\u5728\u8f6f\u4ef6\u5de5\u7a0b\u56e2\u961f\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u672c\u6587\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u7cfb\u7edf\u6c47\u603b\u5fc3\u7406\u5b66\u3001\u793e\u4f1a\u5b66\u548c\u7ec4\u7ec7\u884c\u4e3a\u5b66\u76f8\u5173\u7814\u7a76\uff0c\u63d0\u51fa\u5e7d\u9ed8\u7406\u8bba\u3001\u98ce\u683c\u3001\u6a21\u578b\u548c\u91cf\u8868\u7684\u5206\u7c7b\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u5957\u7cfb\u7edf\u7684\u5e7d\u9ed8\u5206\u7c7b\u65b9\u6cd5\uff0c\u4e3aSE\uff08\u8f6f\u4ef6\u5de5\u7a0b\uff09\u4e13\u4e1a\u4eba\u58eb\u4e0e\u7814\u7a76\u8005\u7406\u89e3\u5e76\u5e94\u7528\u5e7d\u9ed8\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u3001\u7406\u8bba\u5316\u7684\u53c2\u8003\u3002\u6587\u7ae0\u8fd8\u6307\u51fa\u5728SE\u5b9e\u8df5\u4e2d\u5e94\u7528\u5e7d\u9ed8\u9762\u4e34\u7684\u72ec\u7279\u6311\u6218\uff0c\u5e76\u5f3a\u8c03\u9700\u8981\u66f4\u591a\u5b9e\u8bc1\u7814\u7a76\u52a0\u4ee5\u9a8c\u8bc1\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5728\u8f6f\u4ef6\u5de5\u7a0b\u56e2\u961f\u4e2d\u66f4\u6709\u6548\u5730\u4f7f\u7528\u5e7d\u9ed8\u6253\u5f00\u65b0\u8def\u5f84\uff0c\u5f3a\u8c03\u5408\u7406\u4f7f\u7528\u5e7d\u9ed8\u53ef\u4ee5\u4fc3\u8fdb\u56e2\u961f\u51dd\u805a\u529b\u3001\u521b\u9020\u529b\u53ca\u5fc3\u7406\u652f\u6301\u3002\u6b64\u6846\u67b6\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u79ef\u6781\u3001\u5065\u5eb7\u7684\u5de5\u4f5c\u73af\u5883\u3002"}}
{"id": "2507.04316", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.04316", "abs": "https://arxiv.org/abs/2507.04316", "authors": ["Jay Lee"], "title": "Retargeting an Abstract Interpreter for a New Language by Partial Evaluation", "comment": "Presented at the Student Research Competition (SRC) at PLDI 2025\n  (https://pldi25.sigplan.org/details/pldi-2025-src/1/)", "summary": "It is well-known that abstract interpreters can be systematically derived\nfrom their concrete counterparts using a \"recipe,\" but developing sound static\nanalyzers remains a time-consuming task. Reducing the effort required and\nmechanizing the process of developing analyzers continues to be a significant\nchallenge. Is it possible to automatically retarget an existing abstract\ninterpreter for a new language?\n  We propose a novel technique to automatically derive abstract interpreters\nfor various languages from an existing abstract interpreter. By leveraging\npartial evaluation, we specialize an abstract interpreter for a source\nlanguage. The specialization is performed using the semantics of target\nlanguages written in the source language. Our approach eliminates the need to\ndevelop analyzers for new targets from scratch. We show that our method can\neffectively retarget an abstract interpreter for one language into a correct\nanalyzer for another language.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u504f\u7279\u5316\u81ea\u52a8\u5c06\u62bd\u8c61\u89e3\u91ca\u5668\u8fc1\u79fb\u5230\u65b0\u8bed\u8a00\u7684\u65b9\u6cd5\uff0c\u65e0\u9700\u4ece\u5934\u5f00\u53d1\u5206\u6790\u5668\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u77e5\u53ef\u4ee5\u4ece\u5177\u4f53\u89e3\u91ca\u5668\u7cfb\u7edf\u6027\u5730\u63a8\u5bfc\u51fa\u62bd\u8c61\u89e3\u91ca\u5668\uff0c\u4f46\u5f00\u53d1\u9759\u6001\u5206\u6790\u5668\u4ecd\u7136\u8017\u65f6\u4e14\u96be\u4ee5\u81ea\u52a8\u5316\u3002\u51cf\u5c11\u5f00\u53d1\u5de5\u4f5c\u91cf\u4e0e\u5b9e\u73b0\u5206\u6790\u5668\u5f00\u53d1\u81ea\u52a8\u5316\u4ecd\u662f\u6311\u6218\u3002\u80fd\u5426\u81ea\u52a8\u5c06\u73b0\u6709\u62bd\u8c61\u89e3\u91ca\u5668\u7528\u4e8e\u65b0\u8bed\u8a00\uff0c\u662f\u8be5\u7814\u7a76\u5173\u6ce8\u7684\u95ee\u9898\u3002", "method": "\u672c\u6587\u5229\u7528\u504f\u7279\u5316\uff08partial evaluation\uff09\u6280\u672f\uff0c\u5c06\u73b0\u6709\u7684\u62bd\u8c61\u89e3\u91ca\u5668\u9488\u5bf9\u6e90\u8bed\u8a00\u8fdb\u884c\u4e13\u4e1a\u5316\uff0c\u5e76\u7ed3\u5408\u5c06\u76ee\u6807\u8bed\u8a00\u8bed\u4e49\u5199\u4f5c\u6e90\u8bed\u8a00\u7684\u65b9\u5f0f\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u8f6c\u6362\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u4e0e\u65b9\u6cd5\u5c55\u793a\uff0c\u4f5c\u8005\u6210\u529f\u7528\u8be5\u6280\u672f\u5c06\u4e00\u79cd\u8bed\u8a00\u7684\u62bd\u8c61\u89e3\u91ca\u5668\u8f6c\u6362\u4e3a\u53e6\u4e00\u79cd\u8bed\u8a00\u7684\u9759\u6001\u5206\u6790\u5668\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u6b63\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u5730\u5c06\u4e00\u4e2a\u8bed\u8a00\u7684\u62bd\u8c61\u89e3\u91ca\u5668\u91cd\u5b9a\u5411\uff08retarget\uff09\u4e3a\u53e6\u4e00\u4e2a\u8bed\u8a00\u7684\u6b63\u786e\u5206\u6790\u5668\uff0c\u65e0\u9700\u4ece\u5934\u5f00\u53d1\u65b0\u7684\u5206\u6790\u5668\u3002"}}
{"id": "2507.04830", "categories": ["cs.LO", "cs.FL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.04830", "abs": "https://arxiv.org/abs/2507.04830", "authors": ["Martin Leucker"], "title": "A Note on Runtime Verification of Concurrent Systems", "comment": "14 pages, 1 figure", "summary": "To maximize the information gained from a single execution when verifying a\nconcurrent system, one can derive all concurrency-aware equivalent executions\nand check them against linear specifications. This paper offers an alternative\nperspective on verification of concurrent systems by leveraging trace-based\nlogics rather than sequence-based formalisms. Linear Temporal Logic over\nMazurkiewicz Traces (LTrL) operates on partial-order representations of\nexecutions, meaning that once a single execution is specified, all equivalent\ninterleavings are implicitly considered. This paper introduces a three valued\nversion of LTrL, indicating whether the so-far observed execution of the\nconcurrent system is one of correct, incorrect or inconclusive, together with a\nsuitable monitor synthesis procedure. To this end, the paper recalls a\nconstruction of trace-consistent B\\\"uchi automata for LTrL formulas and\nexplains how to employ it in well-understood monitor synthesis procedures. In\nthis way, a monitor results that yields for any linearization of an observed\ntrace the same verification verdict.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u90e8\u5206\u6709\u5e8f\u8f68\u8ff9\u7684\u4e09\u503cLTrL\u903b\u8f91\u548c\u76d1\u63a7\u5668\u5408\u6210\u65b9\u6cd5\uff0c\u4ee5\u63d0\u5347\u5e76\u53d1\u7cfb\u7edf\u9a8c\u8bc1\u7684\u6548\u7387\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u9a8c\u8bc1\u5e76\u53d1\u7cfb\u7edf\u65f6\u7684\u4fe1\u606f\u83b7\u53d6\u6548\u7387\uff0c\u5e0c\u671b\u4ece\u4e00\u6b21\u6267\u884c\u4e2d\u63a8\u5bfc\u51fa\u6240\u6709\u4e0e\u5e76\u53d1\u76f8\u5173\u7684\u7b49\u4ef7\u6267\u884c\uff0c\u5e76\u68c0\u67e5\u5b83\u4eec\u662f\u5426\u6ee1\u8db3\u7ebf\u6027\u89c4\u8303\u3002\u4f20\u7edf\u7684\u57fa\u4e8e\u5e8f\u5217\u7684\u65b9\u6cd5\u96be\u4ee5\u9ad8\u6548\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u7406\u8bba\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u57fa\u4e8e\u8f68\u8ff9\uff08trace-based\uff09\u7684\u903b\u8f91LTrL\uff08Linear Temporal Logic over Mazurkiewicz Traces\uff09\uff0c\u5b83\u4ee5\u90e8\u5206\u6709\u5e8f\u6267\u884c\u4e3a\u57fa\u7840\u3002\u8be5\u65b9\u6cd5\u63a8\u5e7f\u5230\u4e09\u503c\u5f62\u5f0f\uff0c\u80fd\u591f\u533a\u5206\u6b63\u786e\u3001\u9519\u8bef\u548c\u4e0d\u786e\u5b9a\u4e09\u79cd\u60c5\u51b5\uff0c\u5e76\u7ed3\u5408trace-consistent B\u00fcchi\u81ea\u52a8\u673a\u5b9e\u73b0\u76d1\u63a7\u5668\uff08monitor\uff09\u7684\u81ea\u52a8\u5316\u5408\u6210\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e09\u503cLTrL\uff0c\u5e76\u8bbe\u8ba1\u4e86\u76f8\u5e94\u7684\u76d1\u63a7\u5668\u5408\u6210\u8fc7\u7a0b\u3002\u5bf9\u4e8e\u4efb\u610f\u89c2\u6d4b\u5230\u7684\u90e8\u5206\u6709\u5e8f\u8f68\u8ff9\uff0c\u65e0\u8bba\u91c7\u7528\u54ea\u79cd\u7b49\u4ef7\u7ebf\u6027\u5316\uff0c\u76d1\u63a7\u5668\u90fd\u80fd\u7ed9\u51fa\u4e00\u81f4\u7684\u9a8c\u8bc1\u7ed3\u8bba\u3002", "conclusion": "\u57fa\u4e8e\u8f68\u8ff9\u7684\u903b\u8f91\u548c\u76d1\u63a7\u5668\u5408\u6210\u65b9\u6cd5\u80fd\u66f4\u9ad8\u6548\u5730\u9a8c\u8bc1\u5e76\u53d1\u7cfb\u7edf\u7684\u4e00\u81f4\u6027\u548c\u6b63\u786e\u6027\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u4fe1\u606f\u5229\u7528\u7387\u548c\u81ea\u52a8\u5316\u7a0b\u5ea6\u3002"}}
{"id": "2507.04286", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.04286", "abs": "https://arxiv.org/abs/2507.04286", "authors": ["S. Akshay", "Ouldouz Neysari", "\u0110or\u0111e \u017dikeli\u0107"], "title": "Omega-regular Verification and Control for Distributional Specifications in MDPs", "comment": "Accepted at CONCUR 2025", "summary": "A classical approach to studying Markov decision processes (MDPs) is to view\nthem as state transformers. However, MDPs can also be viewed as distribution\ntransformers, where an MDP under a strategy generates a sequence of probability\ndistributions over MDP states. This view arises in several applications, even\nas the probabilistic model checking problem becomes much harder compared to the\nclassical state transformer counterpart. It is known that even distributional\nreachability and safety problems become computationally intractable (Skolem-\nand positivity-hard). To address this challenge, recent works focused on sound\nbut possibly incomplete methods for verification and control of MDPs under the\ndistributional view. However, existing automated methods are applicable only to\ndistributional reachability, safety and reach-avoidance specifications.\n  In this work, we present the first automated method for verification and\ncontrol of MDPs with respect to distributional omega-regular specifications. To\nachieve this, we propose a novel notion of distributional certificates, which\nare sound and complete proof rules for proving that an MDP under a\ndistributionally memoryless strategy satisfies some distributional\nomega-regular specification. We then use our distributional certificates to\ndesign the first fully automated algorithms for verification and control of\nMDPs with respect to distributional omega-regular specifications. Our\nalgorithms follow a template-based synthesis approach and provide soundness and\nrelative completeness guarantees, while running in PSPACE. Our prototype\nimplementation demonstrates practical applicability of our algorithms to\nchallenging examples collected from the literature.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9MDP\u5206\u5e03\u6027\u03c9\u6b63\u5219\u89c4\u8303\u7684\u5168\u81ea\u52a8\u9a8c\u8bc1\u548c\u63a7\u5236\u65b9\u6cd5\uff0c\u7406\u8bba\u4e0a\u53ef\u9760\u5e76\u5728\u5b9e\u9a8c\u4e2d\u5177\u5907\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u4f20\u7edf\u5bf9\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u7684\u7814\u7a76\u4ee5\u72b6\u6001\u53d8\u6362\u4e3a\u4e3b\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0cMDP\u53ef\u4ee5\u4f5c\u4e3a\u5206\u5e03\u53d8\u6362\u5668\uff0c\u5176\u4e2d\u7b56\u7565\u4e0b\u7684MDP\u751f\u6210\u4e00\u7cfb\u5217MDP\u72b6\u6001\u7684\u6982\u7387\u5206\u5e03\u5e8f\u5217\u3002\u5206\u5e03\u89c6\u89d2\u4e0b\u7684\u6982\u7387\u9a8c\u8bc1\u548c\u63a7\u5236\u95ee\u9898\u6bd4\u7ecf\u5178\u72b6\u6001\u89c6\u89d2\u66f4\u96be\uff0c\u76f8\u5173\u57fa\u7840\u95ee\u9898\u5df2\u7ecf\u88ab\u8bc1\u660e\u5728\u8ba1\u7b97\u4e0a\u662f\u56f0\u96be\u7684\u3002\u5df2\u6709\u65b9\u6cd5\u7684\u81ea\u52a8\u5316\u9a8c\u8bc1\u4ec5\u9002\u7528\u4e8e\u7279\u5b9a\u7684\u5206\u5e03\u6027\u76ee\u6807\u548c\u89c4\u8303\u3002", "method": "\u672c\u6587\u9996\u6b21\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9MDPs\u5206\u5e03\u6027\u03c9\u6b63\u5219\u89c4\u8303\u7684\u81ea\u52a8\u5316\u9a8c\u8bc1\u4e0e\u63a7\u5236\u65b9\u6cd5\u3002\u6838\u5fc3\u521b\u65b0\u662f\u63d0\u51fa\u4e86\u5206\u5e03\u6027\u8bc1\u660e\u8bc1\u4e66\u7684\u5168\u65b0\u6982\u5ff5\uff0c\u53ef\u4f5c\u4e3a\u8bc1\u660e\u7b56\u7565\u4e0bMDP\u6ee1\u8db3\u67d0\u79cd\u5206\u5e03\u6027\u03c9\u6b63\u5219\u89c4\u8303\u7684\u5b8c\u6574\u8bc1\u660e\u89c4\u5219\u3002\u5229\u7528\u8fd9\u4e9b\u8bc1\u4e66\uff0c\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u6a21\u677f\u7efc\u5408\u6cd5\u7684\u5168\u81ea\u52a8\u7b97\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u9760\u6027\u548c\u76f8\u5bf9\u5b8c\u5907\u6027\u7684\u7406\u8bba\u4fdd\u8bc1\u3002", "result": "\u7b97\u6cd5\u5728PSPACE\u590d\u6742\u5ea6\u4e0b\u5de5\u4f5c\uff0c\u5e76\u7ecf\u8fc7\u539f\u578b\u5b9e\u73b0\uff0c\u5bf9\u591a\u4e2a\u6765\u81ea\u6587\u732e\u4e2d\u7684\u6311\u6218\u6027\u4f8b\u5b50\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u9996\u6b21\u5b9e\u73b0\u4e86\u5bf9MDP\u5206\u5e03\u6027\u03c9\u6b63\u5219\u89c4\u8303\u7684\u5168\u81ea\u52a8\u9a8c\u8bc1\u548c\u63a7\u5236\uff0c\u5e76\u63a8\u52a8\u4e86\u5206\u5e03\u89c6\u89d2\u4e0bMDP\u7406\u8bba\u548c\u5e94\u7528\u7684\u81ea\u52a8\u5316\u80fd\u529b\u3002"}}
{"id": "2507.02947", "categories": ["cs.CL", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2507.02947", "abs": "https://arxiv.org/abs/2507.02947", "authors": ["Linyan Zou"], "title": "The Application of Large Language Models on Major Depressive Disorder Support Based on African Natural Products", "comment": null, "summary": "Major depressive disorder represents one of the most significant global\nhealth challenges of the 21st century, affecting millions of people worldwide\nand creating substantial economic and social burdens. While conventional\nantidepressant therapies have provided relief for many individuals, their\nlimitations including delayed onset of action, significant side effects, and\ntreatment resistance in a substantial portion of patients have prompted\nresearchers and healthcare providers to explore alternative therapeutic\napproaches (Kasneci et al.). African traditional medicine, with its rich\nheritage of plant-based remedies developed over millennia, offers a valuable\nresource for developing novel antidepressant treatments that may address some\nof these limitations. This paper examines the integration of large language\nmodels with African natural products for depression support, combining\ntraditional knowledge with modern artificial intelligence technology to create\naccessible, evidence-based mental health support systems.\n  The research presented here encompasses a comprehensive analysis of African\nmedicinal plants with documented antidepressant properties, their\npharmacological mechanisms, and the development of an AI-powered support system\nthat leverages DeepSeek's advanced language model capabilities. The system\nprovides evidence-based information about African herbal medicines, their\nclinical applications, safety considerations, and therapeutic protocols while\nmaintaining scientific rigor and appropriate safety standards. Our findings\ndemonstrate the potential for large language models to serve as bridges between\ntraditional knowledge and modern healthcare, offering personalized, culturally\nappropriate depression support that honors both traditional wisdom and\ncontemporary medical understanding.", "AI": {"tldr": "\u672c\u7814\u7a76\u7ed3\u5408\u975e\u6d32\u4f20\u7edf\u8349\u836f\u77e5\u8bc6\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5f00\u53d1\u4e86\u667a\u80fd\u5316\u6291\u90c1\u75c7\u652f\u6301\u7cfb\u7edf\uff0c\u6709\u671b\u4e3a\u60a3\u8005\u63d0\u4f9b\u79d1\u5b66\u3001\u5b89\u5168\u3001\u4e2a\u6027\u5316\u548c\u6ce8\u91cd\u6587\u5316\u7684\u6cbb\u7597\u5efa\u8bae\u3002", "motivation": "\u4f20\u7edf\u6297\u6291\u90c1\u836f\u7269\u5b58\u5728\u8d77\u6548\u6162\u3001\u526f\u4f5c\u7528\u5927\u548c\u90e8\u5206\u60a3\u8005\u6cbb\u7597\u65e0\u6548\u7b49\u5c40\u9650\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u4eba\u5458\u5bfb\u6c42\u66ff\u4ee3\u7597\u6cd5\uff0c\u975e\u6d32\u4f20\u7edf\u533b\u5b66\u4e2d\u4e30\u5bcc\u7684\u8349\u836f\u8d44\u6e90\u6210\u4e3a\u5f00\u53d1\u65b0\u578b\u6297\u6291\u90c1\u6cbb\u7597\u624b\u6bb5\u7684\u91cd\u8981\u65b9\u5411\u3002", "method": "\u672c\u7814\u7a76\u7cfb\u7edf\u5206\u6790\u4e86\u5177\u6709\u6297\u6291\u90c1\u4f5c\u7528\u7684\u975e\u6d32\u836f\u7528\u690d\u7269\u53ca\u5176\u836f\u7406\u673a\u5236\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u5408DeepSeek\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u7684AI\u652f\u6301\u7cfb\u7edf\uff0c\u80fd\u591f\u4e3a\u7528\u6237\u63d0\u4f9b\u57fa\u4e8e\u8bc1\u636e\u7684\u975e\u6d32\u8349\u836f\u4fe1\u606f\u3001\u4e34\u5e8a\u5e94\u7528\u3001\u5b89\u5168\u6027\u548c\u6cbb\u7597\u65b9\u6848\u3002", "result": "\u8be5\u7cfb\u7edf\u80fd\u591f\u79d1\u5b66\u3001\u5408\u7406\u5730\u63d0\u4f9b\u4e0e\u975e\u6d32\u4f20\u7edf\u836f\u7269\u76f8\u5173\u7684\u6291\u90c1\u75c7\u652f\u6301\u670d\u52a1\uff0c\u5b9e\u73b0\u4f20\u7edf\u667a\u6167\u4e0e\u73b0\u4ee3\u533b\u7597\u7684\u878d\u5408\uff0c\u5e76\u786e\u4fdd\u4e2a\u6027\u5316\u548c\u6587\u5316\u9002\u5e94\u6027\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6709\u6f5c\u529b\u4f5c\u4e3a\u4f20\u7edf\u77e5\u8bc6\u4e0e\u73b0\u4ee3\u533b\u7597\u4e4b\u95f4\u7684\u91cd\u8981\u6865\u6881\uff0c\u6709\u52a9\u4e8e\u4e3a\u6291\u90c1\u75c7\u60a3\u8005\u63d0\u4f9b\u66f4\u5177\u6587\u5316\u9002\u5e94\u6027\u548c\u79d1\u5b66\u4f9d\u636e\u7684\u6cbb\u7597\u4e0e\u652f\u6301\u3002"}}
{"id": "2507.03536", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.03536", "abs": "https://arxiv.org/abs/2507.03536", "authors": ["Adam Tornhill", "Markus Borg", "Nadim Hagatulah", "Emma S\u00f6derberg"], "title": "ACE: Automated Technical Debt Remediation with Validated Large Language Model Refactorings", "comment": "Published in proceedings of the 1st International Workshop on\n  Artificial Intelligence for Integrated Development Environments (AI-IDE)\n  (2025)", "summary": "The remarkable advances in AI and Large Language Models (LLMs) have enabled\nmachines to write code, accelerating the growth of software systems. However,\nthe bottleneck in software development is not writing code but understanding\nit; program understanding is the dominant activity, consuming approximately 70%\nof developers' time. This implies that improving existing code to make it\neasier to understand has a high payoff and - in the age of AI-assisted coding -\nis an essential activity to ensure that a limited pool of developers can keep\nup with ever-growing codebases. This paper introduces Augmented Code\nEngineering (ACE), a tool that automates code improvements using validated LLM\noutput. Developed through a data-driven approach, ACE provides reliable\nrefactoring suggestions by considering both objective code quality improvements\nand program correctness. Early feedback from users suggests that AI-enabled\nrefactoring helps mitigate code-level technical debt that otherwise rarely gets\nacted upon.", "AI": {"tldr": "AI \u751f\u6210\u4ee3\u7801\u5f88\u5feb\uff0c\u4f46\u5f00\u53d1\u96be\u70b9\u5728\u4e8e\u4ee3\u7801\u7406\u89e3\u3002ACE \u5de5\u5177\u501f\u52a9 LLM \u81ea\u52a8\u5316\u4f18\u5316\u4ee3\u7801\u7ed3\u6784\u3001\u51cf\u8f7b\u6280\u672f\u503a\u52a1\uff0c\u65e2\u4fdd\u8bc1\u8d28\u91cf\u53c8\u4e0d\u5f71\u54cd\u529f\u80fd\uff0c\u83b7\u5f97\u6b63\u9762\u7528\u6237\u53cd\u9988\u3002", "motivation": "\u867d\u7136 AI \u53ca LLM \u8ba9\u673a\u5668\u81ea\u52a8\u5199\u4ee3\u7801\u80fd\u529b\u589e\u5f3a\uff0c\u4f46\u5f00\u53d1\u8005\u6d88\u8017\u6700\u591a\u7684\u65f6\u95f4\u662f\u5728\u7406\u89e3\u73b0\u6709\u4ee3\u7801\u3002\u63d0\u5347\u4ee3\u7801\u53ef\u7406\u89e3\u6027\u548c\u6613\u7ef4\u62a4\u6027\u6210\u4e3a\u4fdd\u8bc1\u5f00\u53d1\u6548\u7387\u4e0e\u9879\u76ee\u53ef\u63a7\u6027\u7684\u5173\u952e\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u901a\u8fc7\u96c6\u6210\u5e76\u9a8c\u8bc1 LLM \u7684\u751f\u6210\u7ed3\u679c\uff0c\u786e\u4fdd\u4ee3\u7801\u91cd\u6784\u5efa\u8bae\u5728\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\u7684\u540c\u65f6\u4e0d\u5f71\u54cd\u7a0b\u5e8f\u6b63\u786e\u6027\u3002", "result": "ACE \u80fd\u81ea\u52a8\u751f\u6210\u53ef\u9760\u7684\u91cd\u6784\u5efa\u8bae\uff0c\u517c\u987e\u4ee3\u7801\u8d28\u91cf\u63d0\u5347\u4e0e\u529f\u80fd\u6b63\u786e\u6027\uff0c\u5b9e\u8df5\u4e2d\u6709\u52a9\u4e8e\u51cf\u5c11\u5f00\u53d1\u8005\u5904\u7406\u6280\u672f\u503a\u52a1\u7684\u8d1f\u62c5\u3002", "conclusion": "ACE \u5de5\u5177\u5229\u7528\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8f93\u51fa\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u7684\u4ee3\u7801\u4f18\u5316\uff0c\u80fd\u591f\u6709\u6548\u51cf\u5c11\u6280\u672f\u503a\u52a1\u5e76\u63d0\u5347\u4ee3\u7801\u53ef\u7406\u89e3\u6027\u3002\u7528\u6237\u65e9\u671f\u53cd\u9988\u79ef\u6781\uff0c\u8868\u660e AI \u9a71\u52a8\u7684\u91cd\u6784\u5efa\u8bae\u786e\u5b9e\u5e2e\u52a9\u4e86\u89e3\u51b3\u65e5\u5e38\u88ab\u5ffd\u89c6\u7684\u4ee3\u7801\u5c42\u9762\u95ee\u9898\u3002"}}
{"id": "2507.05234", "categories": ["cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.05234", "abs": "https://arxiv.org/abs/2507.05234", "authors": ["Jay Lee", "Joongwon Ahn", "Kwangkeun Yi"], "title": "React-tRace: A Semantics for Understanding React Hooks", "comment": "Conditionally accepted to OOPSLA 2025", "summary": "React has become the most widely used web front-end framework, enabling the\ncreation of user interfaces in a declarative and compositional manner. Hooks\nare a set of APIs that manage side effects in functional components in React.\nHowever, their semantics are often seen as opaque to developers, leading to UI\nbugs. In this paper, we formalize the semantics of the essence of React Hooks\nwe name React-tRace, providing a framework that clarifies their behavior. We\ndemonstrate that our model captures the behavior of React, by theoretically\nshowing that it embodies essential properties of Hooks and empirically\ncomparing our React-tRace-definitional interpreter against a test suite.\nFurthermore, we showcase a practical visualization tool based on the\nformalization to demonstrate how developers can better understand the semantics\nof Hooks.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7React-tRace\u5f62\u5f0f\u5316\u6a21\u578b\u548c\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u63d0\u9ad8\u4e86\u5f00\u53d1\u8005\u628a\u63a7React Hooks\u8bed\u4e49\u53ca\u884c\u4e3a\u7684\u80fd\u529b\u3002", "motivation": "React Hooks\u62bd\u8c61\u590d\u6742\uff0c\u5f00\u53d1\u8005\u96be\u4ee5\u7406\u89e3\u5176\u771f\u5b9e\u8bed\u4e49\uff0c\u6613\u5bfc\u81f4UI bug\uff0c\u7f3a\u5c11\u6e05\u6670\u7684\u884c\u4e3a\u6a21\u5f0f\u548c\u5206\u6790\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u4e86React-tRace\uff0c\u5f62\u5f0f\u5316\u63cf\u8ff0React Hooks\u7684\u672c\u8d28\u8bed\u4e49\uff0c\u5e76\u7ed3\u5408\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u6d4b\u8bd5\u5957\u4ef6\u5bf9\u5176\u4e0e\u5b98\u65b9\u5b9e\u73b0\u8fdb\u884c\u5bf9\u6bd4\uff0c\u540c\u65f6\u57fa\u4e8e\u8be5\u5f62\u5f0f\u5316\u8bed\u4e49\u5b9e\u73b0\u4e86\u53ef\u89c6\u5316\u5de5\u5177\u5e2e\u52a9\u5f00\u53d1\u8005\u7406\u89e3\u3002", "result": "\u7406\u8bba\u5c42\u9762\u8bc1\u660eReact-tRace\u6355\u6349\u4e86Hooks\u7684\u6838\u5fc3\u5c5e\u6027\uff0c\u5b9e\u9a8c\u4e0a\u901a\u8fc7\u6d4b\u8bd5\u96c6\u5bf9\u6bd4\u8868\u660e\u5176\u51c6\u786e\u6a21\u62dfReact\u884c\u4e3a\uff0c\u5e76\u5f00\u53d1\u51fa\u914d\u5957\u53ef\u89c6\u5316\u5de5\u5177\u52a9\u529b\u7406\u89e3\u3002", "conclusion": "\u901a\u8fc7\u5f62\u5f0f\u5316\u6a21\u578b\u548c\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f00\u53d1\u8005\u5bf9React Hooks\u5de5\u4f5c\u673a\u5236\u7684\u7406\u89e3\uff0c\u6709\u52a9\u4e8e\u51cf\u5c11bug\u548c\u4f18\u5316\u5f00\u53d1\u3002"}}
{"id": "2507.04445", "categories": ["cs.LO", "math.LO"], "pdf": "https://arxiv.org/pdf/2507.04445", "abs": "https://arxiv.org/abs/2507.04445", "authors": ["Benjamin Przybocki", "Guilherme V. Toledo", "Yoni Zohar"], "title": "Shininess, strong politeness, and unicorns", "comment": "To appear in FroCoS 2025", "summary": "Shininess and strong politeness are properties related to theory combination\nprocedures. In a paper titled \"Many-sorted equivalence of shiny and strongly\npolite theories\", Casal and Rasga proved that for decidable theories, these\nproperties are equivalent. We refine their result by showing that: (i) shiny\ntheories are always decidable, and therefore strongly polite; and (ii) there\nare (undecidable) strongly polite theories that are not shiny. This line of\nresearch is tightly related to a recent series of papers that have sought to\nclassify all the relations between theory combination properties. We finally\ncomplete this project, resolving all of the remaining problems that were\npreviously left open.", "AI": {"tldr": "\u672c\u6587\u5b8c\u5584\u7406\u8bba\u7ec4\u5408\u4e2dShininess\u548cStrong Politeness\u4e24\u4e2a\u5c5e\u6027\u7684\u5173\u7cfb\u5206\u7c7b\uff0c\u8bc1\u660eShininess\u603b\u662f\u53ef\u5224\u5b9a\u4e14\u610f\u5473\u7740Strong Politeness\uff0c\u540c\u65f6\u6784\u9020\u4e86\u975eShiny\u4f46Strong Polite\u7684\u4e0d\u53ef\u5224\u5b9a\u7406\u8bba\uff0c\u5f7b\u5e95\u89e3\u51b3\u4e86\u6b64\u524d\u7684\u6240\u6709\u672a\u89e3\u95ee\u9898\u3002", "motivation": "\u7406\u8bba\u7ec4\u5408\u4e2d\u7684Shininess\u548cStrong Politeness\u5c5e\u6027\u5728\u5224\u5b9a\u6027\u548c\u7406\u8bba\u7ed3\u6784\u5206\u6790\u4e2d\u5341\u5206\u91cd\u8981\u3002\u6b64\u524d\u7814\u7a76\u672a\u80fd\u7a77\u5c3d\u6240\u6709\u4e24\u8005\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5b8c\u5584\u5206\u7c7b\u5e76\u89e3\u51b3\u5269\u4f59\u7684\u5f00\u653e\u6027\u95ee\u9898\u3002", "method": "\u5728\u5df2\u6709\u7406\u8bba\u7684\u57fa\u7840\u4e0a\uff0c\u7ec6\u81f4\u5206\u6790\u4e86Shininess\u548cStrong Politeness\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u901a\u8fc7\u6784\u9020\u53cd\u4f8b\u548c\u7406\u8bba\u8bc1\u660e\u7b49\u624b\u6bb5\uff0c\u5c55\u793a\u4e86Shininess\u603b\u662f\u53ef\u5224\u5b9a\u4e14\u610f\u5473\u7740Strong Politeness\uff0c\u4ee5\u53ca\u5b58\u5728\u4e0d\u53ef\u5224\u5b9a\u4f46Strong Politeness\u6210\u7acb\u800c\u975eShininess\u7684\u7406\u8bba\u3002", "result": "\u4e3b\u8981\u7ed3\u679c\u5305\u62ec\uff1aShininess\u603b\u662f\u53ef\u5224\u5b9a\u4e14\u56e0\u6b64\u5fc5\u7136Strong Polite\uff1b\u4f46\u5b58\u5728\u4e0d\u53ef\u5224\u5b9a\u7684Strong Polite\u7406\u8bba\u5374\u4e0d\u6ee1\u8db3Shininess\u3002\u8be5\u7814\u7a76\u5f7b\u5e95\u5b8c\u6210\u4e86\u7406\u8bba\u7ec4\u5408\u5c5e\u6027\u95f4\u5173\u7cfb\u7684\u5206\u7c7b\u5de5\u4f5c\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u5bf9\u7406\u8bba\u7ec4\u5408\u4e2dShininess\u548cStrong Politeness\u7279\u6027\u7684\u7814\u7a76\uff0c\u5b8c\u6210\u5e76\u5b8c\u5584\u4e86\u4e4b\u524d\u5173\u4e8e\u8fd9\u4e9b\u7279\u6027\u76f8\u4e92\u5173\u7cfb\u7684\u5206\u7c7b\u5de5\u4f5c\uff0c\u89e3\u51b3\u4e86\u5168\u90e8\u9057\u7559\u7684\u5f00\u653e\u95ee\u9898\u3002"}}
{"id": "2507.02949", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.02949", "abs": "https://arxiv.org/abs/2507.02949", "authors": ["Vipula Rawte", "Rajarshi Roy", "Gurpreet Singh", "Danush Khanna", "Yaswanth Narsupalli", "Basab Ghosh", "Abhay Gupta", "Argha Kamal Samanta", "Aditya Shingote", "Aadi Krishna Vikram", "Vinija Jain", "Aman Chadha", "Amit Sheth", "Amitava Das"], "title": "RADIANT: Retrieval AugmenteD entIty-context AligNmenT -- Introducing RAG-ability and Entity-Context Divergence", "comment": null, "summary": "As Large Language Models (LLMs) continue to advance, Retrieval-Augmented\nGeneration (RAG) has emerged as a vital technique to enhance factual accuracy\nby integrating external knowledge into the generation process. However, LLMs\noften fail to faithfully integrate retrieved evidence into their generated\nresponses, leading to factual inconsistencies. To quantify this gap, we\nintroduce Entity-Context Divergence (ECD), a metric that measures the extent to\nwhich retrieved information is accurately reflected in model outputs. We\nsystematically evaluate contemporary LLMs on their ability to preserve factual\nconsistency in retrieval-augmented settings, a capability we define as\nRAG-ability. Our empirical analysis reveals that RAG-ability remains low across\nmost LLMs, highlighting significant challenges in entity retention and context\nfidelity. This paper introduces Radiant (Retrieval AugmenteD entIty-context\nAligNmenT), a novel framework that merges RAG with alignment designed to\noptimize the interplay between retrieved evidence and generated content.\nRadiant extends Direct Preference Optimization (DPO) to teach LLMs how to\nintegrate provided additional information into subsequent generations. As a\nbehavior correction mechanism, Radiant boosts RAG performance across varied\nretrieval scenarios, such as noisy web contexts, knowledge conflicts, and\nhallucination reduction. This enables more reliable, contextually grounded, and\nfactually coherent content generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5ea6\u91cf LLM \u878d\u5408\u5916\u90e8\u68c0\u7d22\u4fe1\u606f\u80fd\u529b\u7684\u65b0\u6307\u6807\u53ca Radiant \u6846\u67b6\uff0c\u7cfb\u7edf\u63d0\u5347 RAG \u4e8b\u5b9e\u4e00\u81f4\u6027\u548c\u5185\u5bb9\u4fdd\u771f\u5ea6\u3002", "motivation": "\u5c3d\u7ba1 RAG \u6280\u672f\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5f15\u5165\u4e86\u5916\u90e8\u77e5\u8bc6\u4ee5\u63d0\u5347\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u4f46\u5f53\u524d LLM \u5f80\u5f80\u96be\u4ee5\u5c06\u68c0\u7d22\u5230\u7684\u8bc1\u636e\u771f\u5b9e\u3001\u51c6\u786e\u5730\u53cd\u6620\u5230\u751f\u6210\u5185\u5bb9\u4e2d\uff0c\u5bfc\u81f4\u4e8b\u5b9e\u4e0d\u4e00\u81f4\u3002\u4e3a\u6b64\u63d0\u51fa\u65b0\u7684\u5ea6\u91cf\u548c\u6539\u8fdb\u6280\u5de7\u3002", "method": "\u63d0\u51fa\u4e86\u65b0\u7684\u6307\u6807 ECD\uff08Entity-Context Divergence\uff09\u7528\u4e8e\u91cf\u5316\u68c0\u7d22\u4fe1\u606f\u4e0e\u751f\u6210\u5185\u5bb9\u7684\u504f\u79bb\u7a0b\u5ea6\uff0c\u5e76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u591a\u79cd\u4e3b\u6d41 LLM \u7684 RAG-ability\u3002\u8fdb\u4e00\u6b65\uff0c\u63d0\u51fa Radiant\uff08Retrieval AugmenteD entIty-context AligNmenT\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u6269\u5c55 Direct Preference Optimization \u6559\u4f1a\u6a21\u578b\u66f4\u597d\u5730\u878d\u5408\u68c0\u7d22\u5230\u7684\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u591a\u6570 LLM \u7684 RAG-ability \u8f83\u4f4e\uff0c\u4e8b\u5b9e\u4e00\u81f4\u6027\u548c\u5b9e\u4f53\u4fdd\u771f\u6709\u5f85\u63d0\u5347\u3002\u5f15\u5165 Radiant \u6846\u67b6\u540e\uff0c\u65e0\u8bba\u5728\u6709\u566a\u58f0\u7684\u7f51\u7edc\u73af\u5883\u3001\u77e5\u8bc6\u51b2\u7a81\u8fd8\u662f\u51cf\u7f13\u5e7b\u89c9\u7b49\u573a\u666f\u4e0b\uff0c\u6a21\u578b\u90fd\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "Radiant \u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u878d\u5408\u68c0\u7d22\u5916\u90e8\u77e5\u8bc6\u65f6\u7684\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\uff0c\u6539\u5584\u4e86\u4e8b\u5b9e\u4e00\u81f4\u6027\u548c\u4e0a\u4e0b\u6587\u4fdd\u771f\u5ea6\u3002\u8be5\u65b9\u6cd5\u4e3a\u751f\u6210\u66f4\u52a0\u53ef\u9760\u548c\u57fa\u4e8e\u8bc1\u636e\u7684\u5185\u5bb9\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u601d\u8def\u3002"}}
{"id": "2507.03620", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG", "68T50", "I.2.7; D.2.3"], "pdf": "https://arxiv.org/pdf/2507.03620", "abs": "https://arxiv.org/abs/2507.03620", "authors": ["Francisca Lemos", "Victor Alves", "Filipa Ferraz"], "title": "Is It Time To Treat Prompts As Code? A Multi-Use Case Study For Prompt Optimization Using DSPy", "comment": "20 pages with 1 figure", "summary": "Although prompt engineering is central to unlocking the full potential of\nLarge Language Models (LLMs), crafting effective prompts remains a\ntime-consuming trial-and-error process that relies on human intuition. This\nstudy investigates Declarative Self-improving Python (DSPy), an optimization\nframework that programmatically creates and refines prompts, applied to five\nuse cases: guardrail enforcement, hallucination detection in code, code\ngeneration, routing agents, and prompt evaluation. Each use case explores how\nprompt optimization via DSPy influences performance. While some cases\ndemonstrated modest improvements - such as minor gains in the guardrails use\ncase and selective enhancements in hallucination detection - others showed\nnotable benefits. The prompt evaluation criterion task demonstrated a\nsubstantial performance increase, rising accuracy from 46.2% to 64.0%. In the\nrouter agent case, the possibility of improving a poorly performing prompt and\nof a smaller model matching a stronger one through optimized prompting was\nexplored. Although prompt refinement increased accuracy from 85.0% to 90.0%,\nusing the optimized prompt with a cheaper model did not improve performance.\nOverall, this study's findings suggest that DSPy's systematic prompt\noptimization can enhance LLM performance, particularly when instruction tuning\nand example selection are optimized together. However, the impact varies by\ntask, highlighting the importance of evaluating specific use cases in prompt\noptimization research.", "AI": {"tldr": "DSPy\u81ea\u52a8\u5316\u4f18\u5316\u63d0\u793a\u53ef\u63d0\u5347LLM\u8868\u73b0\uff0c\u4f46\u6539\u8fdb\u5e45\u5ea6\u4f9d\u4efb\u52a1\u4e0d\u540c\uff0c\u6709\u4e9b\u7528\u4f8b\u660e\u663e\u589e\u76ca\uff0c\u6709\u4e9b\u4ec5\u5fae\u5e45\u63d0\u5347\u3002", "motivation": "\u63d0\u793a\u5de5\u7a0b\u5bf9\u4e8eLLM\u53d1\u6325\u5168\u90e8\u6f5c\u529b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9ad8\u6548\u63d0\u793a\u7684\u8bbe\u8ba1\u4f9d\u8d56\u4e8e\u8017\u65f6\u7684\u4eba\u5de5\u8bd5\u9519\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u7f16\u7a0b\u5316\u7684\u4f18\u5316\u6846\u67b6\u7b80\u5316\u548c\u63d0\u5347\u63d0\u793a\u8bbe\u8ba1\u6548\u7387\u3002", "method": "\u7814\u7a76\u91c7\u7528Declarative Self-improving Python\uff08DSPy\uff09\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u548c\u4f18\u5316\u63d0\u793a\uff0c\u5728\u4e94\u79cd\u7528\u4f8b\u4e0b\uff08\u89c4\u8303\u6267\u884c\u3001\u4ee3\u7801\u5e7b\u89c9\u68c0\u6d4b\u3001\u4ee3\u7801\u751f\u6210\u3001\u8def\u7531\u4ee3\u7406\u3001\u63d0\u793a\u8bc4\u4ef7\uff09\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u5206\u522b\u5206\u6790DSPy\u4f18\u5316\u63d0\u793a\u5bf9\u4e0d\u540c\u4efb\u52a1\u8868\u73b0\u7684\u5f71\u54cd\u3002", "result": "\u4e0d\u540c\u7528\u4f8b\u6539\u5584\u5e45\u5ea6\u5dee\u5f02\u8f83\u5927\uff1a\u9488\u5bf9\u63d0\u793a\u8bc4\u4ef7\u4efb\u52a1\u51c6\u786e\u7387\u4ece46.2%\u5927\u5e45\u63d0\u5347\u523064.0%\uff1b\u8def\u7531\u4ee3\u7406\u4efb\u52a1\u63d0\u793a\u4f18\u5316\u4f7f\u51c6\u786e\u7387\u4ece85.0%\u63d0\u5347\u523090.0%\uff0c\u4f46\u201c\u4fbf\u5b9c\u201d\u6a21\u578b\u501f\u52a9\u4f18\u5316\u540e\u63d0\u793a\u672a\u660e\u663e\u8d85\u8d8a\u539f\u672c\u7684\u5f3a\u6a21\u578b\u3002\u5176\u4ed6\u7528\u4f8b\u5982\u89c4\u8303\u6267\u884c\u548c\u5e7b\u89c9\u68c0\u6d4b\u5219\u53ea\u53d6\u5f97\u7ec6\u5fae\u63d0\u5347\u3002", "conclusion": "DSPy\u81ea\u52a8\u5316\u63d0\u793a\u4f18\u5316\u5728\u67d0\u4e9b\u4efb\u52a1\uff08\u5982\u63d0\u793a\u8bc4\u4ef7\uff09\u8868\u73b0\u7a81\u51fa\uff0c\u53ef\u6709\u6548\u63d0\u5347LLM\u4efb\u52a1\u8868\u73b0\uff0c\u5c24\u5176\u662f\u5728\u8bf4\u660e\u8c03\u4f18\u548c\u793a\u4f8b\u9009\u62e9\u534f\u540c\u4f18\u5316\u65f6\u3002\u4f46\u4e0d\u540c\u4efb\u52a1\u5f71\u54cd\u5dee\u5f02\u663e\u8457\uff0c\u63d0\u793a\u4f18\u5316\u5e94\u57fa\u4e8e\u5177\u4f53\u4efb\u52a1\u6548\u679c\u8bc4\u4f30\u3002"}}
{"id": "2507.03659", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.03659", "abs": "https://arxiv.org/abs/2507.03659", "authors": ["Valentina Wu", "Alexandra Mendes", "Alexandre Abreu"], "title": "Specification-Guided Repair of Arithmetic Errors in Dafny Programs using LLMs", "comment": null, "summary": "Formal verification offers strong assurances of software correctness.\nHowever, debugging and repairing the underlying faults can be complex and\ntime-consuming when verification fails. Automated Program Repair (APR) aims to\nease this by automatically identifying and fixing faults. Traditional APR\ntechniques often depend on test suites for validation, but these may fail to\ncapture all scenarios. In contrast, formal specifications provide stronger\ncorrectness criteria for effective repairs.\n  We present an innovative APR tool for Dafny, a verification-aware programming\nlanguage that uses formal specifications - including pre-conditions,\npost-conditions, and invariants - as oracles for fault localization and repair.\nAssuming the correctness of the specifications and focusing on arithmetic bugs,\nwe localize faults through a series of steps, which include using Hoare Logic\nto determine the state of each statement within the program and\nstate-of-the-art Large Language Models (LLMs) to synthesize candidate fixes.\nThe chosen models were GPT-4o mini, Llama 3, Mistral 7B, and Llemma 7B.\n  We evaluate our approach using DafnyBench, a benchmark of real-world Dafny\nprograms. Our tool achieves 89.6% accuracy in fault localization, with GPT-4o\nmini yielding the highest repair success rate (74.18%). These results highlight\nthe potential of combining formal reasoning with LLM-driven program synthesis\nfor automated program repair.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDafny\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u5de5\u5177\uff0c\u7ed3\u5408\u5f62\u5f0f\u89c4\u8303\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5b9a\u4f4d\u51c6\u786e\u738789.6%\uff0c\u6700\u9ad8\u4fee\u590d\u738774.18%\uff0c\u6548\u679c\u7a81\u51fa\u3002", "motivation": "\u5f62\u5f0f\u5316\u9a8c\u8bc1\u80fd\u4fdd\u969c\u8f6f\u4ef6\u6b63\u786e\u6027\uff0c\u4f46\u9047\u5230\u9a8c\u8bc1\u5931\u8d25\u65f6\u5b9a\u4f4d\u548c\u4fee\u590d\u9519\u8bef\u6781\u4e3a\u590d\u6742\u548c\u8017\u65f6\u3002\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u65e8\u5728\u81ea\u52a8\u5b9a\u4f4d\u548c\u4fee\u590d\u9519\u8bef\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u6d4b\u8bd5\u96c6\u6613\u51fa\u73b0\u8986\u76d6\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u7ed3\u5408\u5f62\u5f0f\u5316\u89c4\u8303\u5b9e\u73b0\u66f4\u9ad8\u6807\u51c6\u7684\u9519\u8bef\u4fee\u590d\u6210\u4e3a\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9Dafny\uff08\u9a8c\u8bc1\u611f\u77e5\u7684\u7f16\u7a0b\u8bed\u8a00\uff09\u7684\u521b\u65b0APR\u5de5\u5177\u3002\u8be5\u5de5\u5177\u5229\u7528\u5f62\u5f0f\u5316\u89c4\u8303\uff08\u524d\u7f6e\u6761\u4ef6\u3001\u540e\u7f6e\u6761\u4ef6\u3001\u4e0d\u53d8\u91cf\uff09\u4f5c\u4e3a\u5b9a\u4f4d\u548c\u4fee\u590d\u4f9d\u636e\uff0c\u4e3b\u8981\u9488\u5bf9\u7b97\u672f\u9519\u8bef\u3002\u7ed3\u5408Hoare\u903b\u8f91\u5206\u6790\u8bed\u53e5\u72b6\u6001\uff0c\u5229\u7528\u591a\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-4o mini\u3001Llama 3\u3001Mistral 7B\u548cLlemma 7B\uff09\u751f\u6210\u4fee\u590d\u5efa\u8bae\u3002", "result": "\u5728\u5b9e\u9645Dafny\u7a0b\u5e8f\u57fa\u51c6\u96c6\uff08DafnyBench\uff09\u4e0a\u6d4b\u8bd5\u663e\u793a\uff0c\u5de5\u5177\u5728\u9519\u8bef\u5b9a\u4f4d\u4e0a\u7684\u51c6\u786e\u7387\u4e3a89.6%\uff0c\u4fee\u590d\u6210\u529f\u7387\uff08GPT-4o mini\u6700\u9ad8\uff09\u4e3a74.18%\u3002", "conclusion": "\u7ed3\u5408\u6b63\u5f0f\u63a8\u7406\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6848\u53ef\u6709\u6548\u63d0\u5347\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u5de5\u5177\u5728\u5f62\u5f0f\u5316\u7f16\u7a0b\u73af\u5883\u4e2d\u7684\u5b9a\u4f4d\u53ca\u4fee\u590d\u80fd\u529b\u3002"}}
{"id": "2507.04449", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.04449", "abs": "https://arxiv.org/abs/2507.04449", "authors": ["Khashayar Irani"], "title": "Proof Analysis of A Foundational Classical Singlesuccedent Sequent Calculus", "comment": "This paper is currently in draft form; therefore, constructive\n  comments sent via email are welcome", "summary": "In this paper we investigate the question: 'How can A Foundational Classical\nSinglesuccedent Sequent Calculus be formulated?' The choice of this particular\narea of proof-theoretic study is based on a particular ground that is, to\nformulate a robust and foundational classical singlesuccedent sequent calculus\nthat includes a number of novel rules with the ultimate aim of deriving the\nsinglesuccedent sequent {\\Gamma} sequent arrow C. To this end, we argue that\namong all standard sequent calculi (at least to the best of our knowledge)\nthere is no classical singlesuccedent sequent calculus that can be considered\nthe rightful successor to Gerhard Gentzen's (1935) original LK system. However,\nwe also contend that while several classical singlesuccedent sequent calculi\nexist such as Sara Negri's and Jan von Plato's (2001 & 2011) G3ip+Gem-at and\nG0ip+Gem0-at calculi, none of these proof systems possess the classical\nproof-theoretic potential to meet the formal expectations of a dedicated\nclassical proof theorist. Conversely, we shall demonstrate that our forthcoming\nsystem, namely G-Calculus through its classical division i.e. Gc has been\nentirely designed to meet these expectations. Prior to commencing our enquiry,\na supplementary note must be made and that is in this work when discussing\nvarious sequent calculi, for proof-theoretic purposes, we are primarily\nconcerned with their propositional components rather than their predicate\ndivisions except in G-Calculus where we examine both aspects.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u7ecf\u5178\u5355\u7ed3\u8bba\u5e8f\u5217\u6f14\u7b97\u7cfb\u7edfG-Calculus\uff0c\u901a\u8fc7\u4e25\u8c28\u8bba\u8bc1\u8868\u660e\u5176\u53ef\u586b\u8865\u73b0\u6709\u7cfb\u7edf\u4e0d\u8db3\uff0c\u6210\u4e3aGentzen\u7684\u4ebaLK\u7cfb\u7edf\u7684\u7406\u60f3\u7ee7\u627f\u8005\uff0c\u5e76\u5728\u7406\u8bba\u548c\u63a8\u7406\u80fd\u529b\u4e0a\u8fbe\u5230\u7ecf\u5178\u8bc1\u660e\u8bba\u9884\u671f\u3002", "motivation": "\u76ee\u524d\u5c1a\u65e0\u4e00\u4e2a\u516c\u8ba4\u7684\u7ecf\u5178\u5355\u7ed3\u8bba\u5e8f\u5217\u6f14\u7b97\u80fd\u591f\u88ab\u89c6\u4f5cGentzen\u7684LK\u7cfb\u7edf\u7684\u6b63\u7edf\u7ee7\u627f\u8005\u3002\u73b0\u6709\u5982Negri\u548cvon Plato\u7684\u76f8\u5173\u7cfb\u7edf\uff0c\u5e76\u672a\u5145\u5206\u6ee1\u8db3\u7ecf\u5178\u8bc1\u660e\u8bba\u5bb6\u7684\u7406\u8bba\u671f\u671b\u3002\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u533a\u57df\u7684\u7406\u8bba\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5e76\u5bf9\u6bd4\u73b0\u6709\u7684\u7ecf\u5178\u5355\u7ed3\u8bba\u5e8f\u5217\u6f14\u7b97\uff0c\u7ed3\u5408\u5bf9\u5176\u4f18\u7f3a\u70b9\u7684\u68b3\u7406\uff0c\u4f5c\u8005\u5236\u5b9a\u51fa\u4e00\u5957\u65b0\u7684\u5e8f\u5217\u6f14\u7b97\u7cfb\u7edfG-Calculus\u5e76\u91cd\u70b9\u4ecb\u7ecd\u5176\u7ecf\u5178\u5316\u5206\u652f\uff08Gc\uff09\uff0c\u5e76\u5bf9\u6bd4\u5176\u4e0e\u524d\u4eba\u7cfb\u7edf\u7684\u4e0d\u540c\u53ca\u4f18\u52bf\u3002", "result": "\u63d0\u51fa\u4e86G-Calculus\u53ca\u5176\u7ecf\u5178\u5206\u652fGc\uff0c\u7cfb\u7edf\u6027\u5730\u8bba\u8bc1\u5176\u5728\u5f62\u5f0f\u3001\u63a8\u7406\u80fd\u529b\u53ca\u7406\u8bba\u5b8c\u6574\u6027\u7b49\u65b9\u9762\u6ee1\u8db3\u4e86\u7ecf\u5178\u8bc1\u660e\u8bba\u5bb6\u7684\u5404\u9879\u671f\u671b\uff0c\u5e76\u4ee5\u547d\u9898\u548c\u8c13\u8bcd\u4e24\u5c42\u9762\u8fdb\u884c\u8be6\u5c3d\u5206\u6790\u3002", "conclusion": "G-Calculus\u53ca\u5176Gc\u5206\u652f\u5df2\u7ecf\u88ab\u8bbe\u8ba1\u4e3a\u7ecf\u5178\u5355\u7ed3\u8bba\u5e8f\u5217\u6f14\u7b97\u9886\u57df\u4e2d\u8fbe\u6210\u7406\u8bba\u5b8c\u5584\u6027\u7684\u65b0\u65b9\u6848\uff0c\u53ef\u4f5c\u4e3aLK\u7cfb\u7edf\u7684\u5408\u683c\u7ee7\u4efb\u8005\u3002\u73b0\u6709\u7cfb\u7edf\u4ecd\u6709\u4e0d\u8db3\uff0c\u800c\u8be5\u7cfb\u7edf\u53ef\u5f25\u8865\u5e76\u8d85\u8d8a\u5148\u524d\u7684\u5c40\u9650\u3002"}}
{"id": "2507.02950", "categories": ["cs.CL", "cs.AI", "cs.HC", "68T50", "I.2.7; H.5.2; J.4"], "pdf": "https://arxiv.org/pdf/2507.02950", "abs": "https://arxiv.org/abs/2507.02950", "authors": ["Keita Kiuchi", "Yoshikazu Fujimoto", "Hideyuki Goto", "Tomonori Hosokawa", "Makoto Nishimura", "Yosuke Sato", "Izumi Sezai"], "title": "Evaluating AI Counseling in Japanese: Counselor, Client, and Evaluator Roles Assessed by Motivational Interviewing Criteria", "comment": "69 pages, 0 figures, 9 tables; data and code at\n  https://osf.io/p8c39/files/2e58c42f-a7ba-45f2-aa60-265e107e36db", "summary": "This study provides the first comprehensive evaluation of large language\nmodel (LLM) performance across three counseling roles in Japanese-language\ntherapeutic contexts. We simultaneously assessed counselor artificial\nintelligence (AI) systems (GPT-4-turbo with zeroshot prompting or Structured\nMulti-step Dialogue Prompts (SMDP), Claude-3-Opus-SMDP), client AI simulations,\nand evaluation AI systems (o3, Claude-3.7-Sonnet, Gemini-2.5-pro). Human\nexperts (n = 15) with extensive counseling experience evaluated AI-generated\ndialogues using the Motivational Interviewing Treatment Integrity (MITI) Coding\nManual 4.2.1.\n  Notably, SMDP implementation significantly enhanced counselor AI performance\nacross all MITI global ratings compared with zeroshot prompting, with no\nsignificant differences between GPT-SMDP and Opus-SMDP. Evaluation AIs showed\ncomparable performance to human raters for Cultivating Change Talk but\nsystematically overestimated Softening Sustain Talk and the overall quality\nmetrics. Model-specific biases emerged: Gemini emphasized power-sharing, o3\nfocused on technical proficiency, and Sonnet prioritized emotional expression.\nClient AI simulations exhibited a limited emotional range and unnaturally high\ncompliance, indicating the need for enhanced realism.\n  These findings establish benchmarks for AI-assisted counseling in non-English\ncontexts and identify critical areas for improvement through advanced prompt\nengineering, retrieval-augmented generation, and targeted fine-tuning, with\nimportant implications for developing culturally sensitive AI mental health\ntools.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65e5\u8bed\u54a8\u8be2\u573a\u666f\u4e2d\u7684\u591a\u89d2\u8272\u8868\u73b0\uff0c\u53d1\u73b0\u7ed3\u6784\u5316\u591a\u6b65\u5bf9\u8bdd\u63d0\u793a\u663e\u8457\u63d0\u5347AI\u54a8\u8be2\u8d28\u91cf\uff0c\u4e14\u73b0\u6709\u6a21\u578b\u4e0e\u6765\u8bbf\u8005\u6a21\u62df\u4ecd\u5f85\u6539\u8fdb\u3002\u540c\u65f6\uff0c\u4e3a\u975e\u82f1\u8bed\u73af\u5883\u4e0bAI\u5fc3\u7406\u5065\u5eb7\u5e94\u7528\u63d0\u4f9b\u4e86\u57fa\u51c6\u548c\u4f18\u5316\u65b9\u5411\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u5168\u9762\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u65e5\u8bed\u6cbb\u7597\u73af\u5883\u4e2d\uff0c\u62c5\u4efb\u4e09\u79cd\u54a8\u8be2\u76f8\u5173\u89d2\u8272\u65f6\u7684\u8868\u73b0\uff0c\u5e76\u63a2\u8ba8\u5176\u5728\u975e\u82f1\u8bed\u6587\u5316\u4e0b\u7684\u9002\u7528\u6027\u548c\u5c40\u9650\u6027\u3002", "method": "\u7814\u7a76\u8bc4\u4f30\u4e86\u4e0d\u540c\u89d2\u8272\u7684AI\u7cfb\u7edf\uff0c\u5305\u62ec\u8f85\u5bfc\u8005AI\uff08\u91c7\u7528GPT-4-turbo\u96f6\u6837\u672c\u63d0\u793a\u6216\u7ed3\u6784\u5316\u591a\u6b65\u5bf9\u8bdd\u63d0\u793a\uff08SMDP\uff09\u3001Claude-3-Opus-SMDP\uff09\u3001\u6765\u8bbf\u8005AI\u6a21\u62df\uff0c\u4ee5\u53ca\u8bc4\u4ef7AI\uff08o3\uff0cClaude-3.7-Sonnet\uff0cGemini-2.5-pro\uff09\u3002\u753115\u4f4d\u5177\u5907\u4e30\u5bcc\u54a8\u8be2\u7ecf\u9a8c\u7684\u4eba\u7c7b\u4e13\u5bb6\uff0c\u4f7f\u7528\u52a8\u673a\u6027\u8bbf\u8c08\u6cbb\u7597\u5b8c\u6574\u6027\uff08MITI\uff09\u7f16\u7801\u624b\u518c4.2.1\uff0c\u5bf9AI\u751f\u6210\u7684\u5bf9\u8bdd\u8fdb\u884c\u8bc4\u5206\u3002", "result": "SMDP\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u8f85\u5bfc\u8005AI\u5728\u5168\u90e8MITI\u8bc4\u5206\u6307\u6807\u4e0a\u7684\u8868\u73b0\uff0c\u8d85\u8fc7\u4e86\u96f6\u6837\u672c\u63d0\u793a\uff0c\u4e14GPT\u4e0eOpus\u7684SMDP\u6548\u679c\u65e0\u663e\u8457\u5dee\u5f02\u3002\u8bc4\u4ef7AI\u5728\u9f13\u52b1\u79ef\u6781\u53d8\u9769\u8a00\u8bed\u65b9\u9762\u4e0e\u4eba\u7c7b\u6301\u5e73\uff0c\u4f46\u5728\u51cf\u7f13\u62b5\u6297\u8a00\u8bed\u548c\u6574\u4f53\u8d28\u91cf\u4e0a\u503e\u5411\u9ad8\u4f30\u3002\u7279\u5b9a\u6a21\u578b\u504f\u597d\u660e\u786e\uff08\u5982Gemini\u91cd\u89c6\u6743\u529b\u5171\u4eab\uff0co3\u6ce8\u91cd\u6280\u672f\u89c4\u8303\uff0cSonnet\u5173\u6ce8\u60c5\u611f\u8868\u8fbe\uff09\u3002\u6765\u8bbfAI\u6a21\u62df\u60c5\u611f\u8303\u56f4\u6709\u9650\u3001\u987a\u4ece\u5ea6\u5f02\u5e38\u9ad8\uff0c\u8868\u73b0\u4e0d\u591f\u771f\u5b9e\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u975e\u82f1\u8bed\u8bed\u5883\u4e0bAI\u8f85\u5bfc\u5960\u5b9a\u4e86\u6027\u80fd\u57fa\u51c6\uff0c\u63d0\u51fa\u901a\u8fc7\u9ad8\u7ea7\u63d0\u793a\u5de5\u7a0b\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u9488\u5bf9\u6027\u5fae\u8c03\u63d0\u5347AI\u8868\u73b0\uff0c\u5f3a\u8c03\u5f00\u53d1\u5177\u6587\u5316\u654f\u611f\u6027\u7684AI\u5fc3\u7406\u5065\u5eb7\u5de5\u5177\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.02954", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02954", "abs": "https://arxiv.org/abs/2507.02954", "authors": ["Pranam Shetty", "Abhisek Upadhayaya", "Parth Mitesh Shah", "Srikanth Jagabathula", "Shilpi Nayak", "Anna Joo Fee"], "title": "Advanced Financial Reasoning at Scale: A Comprehensive Evaluation of Large Language Models on CFA Level III", "comment": "Accepted at FinLLM @ IJCAI 2025", "summary": "As financial institutions increasingly adopt Large Language Models (LLMs),\nrigorous domain-specific evaluation becomes critical for responsible\ndeployment. This paper presents a comprehensive benchmark evaluating 23\nstate-of-the-art LLMs on the Chartered Financial Analyst (CFA) Level III exam -\nthe gold standard for advanced financial reasoning. We assess both\nmultiple-choice questions (MCQs) and essay-style responses using multiple\nprompting strategies including Chain-of-Thought and Self-Discover. Our\nevaluation reveals that leading models demonstrate strong capabilities, with\ncomposite scores such as 79.1% (o4-mini) and 77.3% (Gemini 2.5 Flash) on CFA\nLevel III. These results, achieved under a revised, stricter essay grading\nmethodology, indicate significant progress in LLM capabilities for high-stakes\nfinancial applications. Our findings provide crucial guidance for practitioners\non model selection and highlight remaining challenges in cost-effective\ndeployment and the need for nuanced interpretation of performance against\nprofessional benchmarks.", "AI": {"tldr": "\u672c\u8bba\u6587\u8bc4\u6d4b\u4e8623\u4e2aLLM\u5728CFA\u4e09\u7ea7\u8003\u8bd5\u4e0a\u7684\u8868\u73b0\uff0c\u4e3b\u6d41\u6a21\u578b\u53d6\u5f97\u4e86\u63a5\u8fd1\u6216\u8d85\u8fc777%\u7684\u5206\u6570\uff0c\u663e\u793a\u51faLLM\u5728\u9ad8\u7ea7\u91d1\u878d\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u5de8\u5927\u8fdb\u6b65\uff0c\u5bf9\u73b0\u5b9e\u5e94\u7528\u548c\u6a21\u578b\u9009\u62e9\u5177\u6709\u91cd\u8981\u53c2\u8003\u610f\u4e49\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u4ecd\u9762\u4e34\u6210\u672c\u548c\u89e3\u91ca\u7b49\u96be\u9898\u3002", "motivation": "\u968f\u7740\u91d1\u878d\u673a\u6784\u8d8a\u6765\u8d8a\u591a\u5730\u91c7\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u4e3a\u4e86\u786e\u4fdd\u8d1f\u8d23\u4efb\u5730\u90e8\u7f72\uff0c\u5fc5\u987b\u8fdb\u884c\u4e25\u683c\u7684\u9886\u57df\u4e13\u5c5e\u8bc4\u4f30\u3002CFA\u8003\u8bd5\u662f\u91d1\u878d\u63a8\u7406\u9886\u57df\u7684\u91d1\u6807\u51c6\uff0c\u56e0\u6b64\u4ee5\u5176\u4e3a\u8bc4\u6d4b\u5bf9\u8c61\uff0c\u53ef\u4ee5\u76f4\u63a5\u53cd\u6620LLMs\u5728\u9ad8\u7aef\u91d1\u878d\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e8623\u4e2a\u5148\u8fdb\u7684LLM\u5728CFA\u4e09\u7ea7\u8003\u8bd5\u4e0a\u7684\u8868\u73b0\u3002\u6d4b\u8bd5\u6db5\u76d6\u4e86\u9009\u62e9\u9898\u548c\u8bba\u8ff0\u9898\uff0c\u5e76\u91c7\u7528\u4e86\u591a\u79cd\u63d0\u793a\u7b56\u7565\uff08\u5982Chain-of-Thought\u548cSelf-Discover\uff09\uff0c\u540c\u65f6\u5bf9\u8bba\u8ff0\u9898\u6210\u7ee9\u91c7\u7528\u4e86\u66f4\u4e25\u683c\u7684\u8bc4\u5206\u65b9\u6cd5\u3002", "result": "\u9886\u5148\u6a21\u578b\uff08\u5982o4-mini\u548cGemini 2.5 Flash\uff09\u5728CFA\u4e09\u7ea7\u8003\u8bd5\u4e2d\u5206\u522b\u53d6\u5f97\u4e8679.1%\u548c77.3%\u7684\u7efc\u5408\u5206\u6570\uff0c\u8fd9\u4e9b\u6210\u7ee9\u5747\u57fa\u4e8e\u4e25\u683c\u4fee\u8ba2\u8fc7\u7684\u8bba\u8ff0\u9898\u8bc4\u5206\u6807\u51c6\u3002\u8fd9\u8bf4\u660eLLMs\u5728\u9ad8\u8981\u6c42\u91d1\u878d\u4efb\u52a1\u80fd\u529b\u4e0a\u53d6\u5f97\u4e86\u660e\u663e\u8fdb\u6b65\u3002", "conclusion": "\u7814\u7a76\u4e3a\u91d1\u878d\u9886\u57df\u5b9e\u9645\u7528\u6237\u5728\u6a21\u578b\u9009\u62e9\u4e0a\u63d0\u4f9b\u4e86\u6307\u5357\uff0c\u540c\u65f6\u6307\u51fa\u5728\u6210\u672c\u6548\u76ca\u90e8\u7f72\u548c\u6a21\u578b\u8868\u73b0\u4e13\u4e1a\u89e3\u8bfb\u65b9\u9762\u4ecd\u6709\u6311\u6218\u3002"}}
{"id": "2507.04173", "categories": ["cs.SE", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.04173", "abs": "https://arxiv.org/abs/2507.04173", "authors": ["Henri A\u00efdasso", "Francis Bordeleau", "Ali Tizghadam"], "title": "Efficient Detection of Intermittent Job Failures Using Few-Shot Learning", "comment": "Accepted at the 41st International Conference on Software Maintenance\n  and Evolution - ICSME 2025, Industry Track", "summary": "One of the main challenges developers face in the use of continuous\nintegration (CI) and deployment pipelines is the occurrence of intermittent job\nfailures, which result from unexpected non-deterministic issues (e.g., flaky\ntests or infrastructure problems) rather than regular code-related errors such\nas bugs. Prior studies developed machine-learning (ML) models trained on large\ndatasets of job logs to classify job failures as either intermittent or\nregular. As an alternative to costly manual labeling of large datasets, the\nstate-of-the-art (SOTA) approach leveraged a heuristic based on\nnon-deterministic job reruns. However, this method mislabels intermittent job\nfailures as regular in contexts where rerunning suspicious job failures is not\nan explicit policy, and therefore limits the SOTA's performance in practice. In\nfact, our manual analysis of 2,125 job failures from 5 industrial and 1\nopen-source projects reveals that, on average, 32\\% of intermittent job\nfailures are mislabeled as regular. To address these limitations, this paper\nintroduces a novel approach to intermittent job failure detection using\nfew-shot learning (FSL). Specifically, we fine-tune a small language model\nusing a few number of manually labeled log examples to generate rich\nembeddings, which are then used to train an ML classifier. Our FSL-based\napproach achieves 70-88\\% F1-score with only 12 shots in all projects,\noutperforming the SOTA, which proved ineffective (34-52\\% F1-score) in 4\nprojects. Overall, this study underlines the importance of data quality over\nquantity and provides a more efficient and practical framework for the\ndetection of intermittent job failures in organizations.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u6301\u7eed\u96c6\u6210\u6d41\u6c34\u7ebf\u4e2d\u7684\u95f4\u6b47\u6027\u4f5c\u4e1a\u5931\u8d25\u68c0\u6d4b\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u5c0f\u6837\u672c\u5b66\u4e60\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u53ea\u9700\u6781\u5c11\u624b\u5de5\u6807\u6ce8\u5373\u53ef\u5927\u5e45\u63d0\u5347\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u5b9e\u9645\u5de5\u7a0b\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u901a\u8fc7\u4f5c\u4e1a\u91cd\u8fd0\u884c\u542f\u53d1\u5f0f\u6765\u6807\u7b7e\u5212\u5206\u5e38\u89c4/\u95f4\u6b47\u6027\u5931\u8d25\u7684\u6570\u636e\u96c6\u5b58\u5728\u4e25\u91cd\u8bef\u6807\u95ee\u9898\uff0c\u5f71\u54cd\u4e86\u68c0\u6d4b\u6a21\u578b\u7684\u5b9e\u9645\u6548\u679c\u3002\u4eba\u5de5\u5927\u91cf\u6807\u6ce8\u6210\u672c\u8fc7\u9ad8\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u5728\u5c0f\u6837\u672c\u6570\u636e\u4e0b\u4ecd\u6709\u826f\u597d\u8868\u73b0\u7684\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u5c0f\u6837\u672c\u5b66\u4e60\uff08FSL\uff09\u6846\u67b6\uff0c\u5148\u9009\u53d6\u5c11\u91cf\u7ecf\u8fc7\u4eba\u5de5\u6807\u6ce8\u7684\u65e5\u5fd7\u6837\u672c\uff0c\u5bf9\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u968f\u540e\u7528\u8be5\u6a21\u578b\u63d0\u53d6\u65e5\u5fd7\u5d4c\u5165\u4fe1\u606f\uff0c\u8f93\u5165\u5230\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u4e2d\u8fdb\u884c\u95f4\u6b47\u6027\u5931\u8d25\u68c0\u6d4b\u3002\u4e0e\u4f20\u7edf\u4f9d\u9760\u65e5\u5fd7\u91cd\u8fd0\u884c\u7684\u542f\u53d1\u5f0f\u65b9\u5f0f\u4f5c\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u65b9\u6cd5\u6548\u679c\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4ec5\u970012\u4e2a\u624b\u5de5\u6807\u6ce8\u6837\u672c\u5c31\u80fd\u5728\u6240\u6709\u9879\u76ee\u4e2d\u8fbe\u523070-88%\u7684F1\u5206\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff08SOTA\u57284\u4e2a\u9879\u76ee\u4e0a\u4ec534-52%\u7684F1\uff09\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u6570\u636e\u8bef\u6807\u5bfc\u81f4\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u63d0\u9ad8\u4e86\u68c0\u6d4b\u7684\u5b9e\u7528\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c0f\u6837\u672c\u5b66\u4e60\uff08FSL\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u5c11\u91cf\u624b\u5de5\u6807\u6ce8\u7684\u65e5\u5fd7\u6837\u672c\u5fae\u8c03\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u4f7f\u7528\u5176\u751f\u6210\u7684\u5d4c\u5165\u5411\u91cf\u6765\u8bad\u7ec3\u5206\u7c7b\u5668\uff0c\u53ef\u4ee5\u66f4\u52a0\u9ad8\u6548\u548c\u51c6\u786e\u5730\u68c0\u6d4bCI/CD\u4e2d\u7684\u95f4\u6b47\u6027\u4f5c\u4e1a\u5931\u8d25\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\u3002"}}
{"id": "2507.05044", "categories": ["cs.LO", "cs.CC"], "pdf": "https://arxiv.org/pdf/2507.05044", "abs": "https://arxiv.org/abs/2507.05044", "authors": ["Albert Brandl", "Christian G. Ferm\u00fcller", "Gernot Salzer"], "title": "Testing for Renamability to Classes of Clause Sets", "comment": null, "summary": "This paper investigates the problem of testing clause sets for membership in\nclasses known from literature. In particular, we are interested in classes\ndefined via renaming: Is it possible to rename the predicates in a way such\nthat positive and negative literals satisfy certain conditions? We show that\nfor classes like Horn or OCC1N, the existence of such renamings can be decided\nin polynomial time, whereas the same problem is NP-complete for class PVD. The\ndecision procedures are based on hyper-resolution; if a renaming exists, it can\nbe extracted from the final saturated clause set.", "AI": {"tldr": "\u672c\u8bba\u6587\u7814\u7a76\u4e86\u901a\u8fc7\u8c13\u8bcd\u91cd\u547d\u540d\u5224\u65ad\u5b50\u53e5\u96c6\u662f\u5426\u5c5e\u4e8e\u67d0\u4e9b\u903b\u8f91\u7c7b\uff0c\u5e76\u53d1\u73b0\u90e8\u5206\u7c7b\uff08\u5982Horn\u548cOCC1N\uff09\u53ef\u591a\u9879\u5f0f\u5224\u5b9a\uff0c\u800cPVD\u7c7b\u8be5\u95ee\u9898\u4e3aNP-\u5b8c\u5168\u3002\u91c7\u7528\u8d85\u5206\u8fa8\u7387\u5224\u5b9a\u65b9\u6cd5\u3002", "motivation": "\u8be5\u8bba\u6587\u5173\u6ce8\u903b\u8f91\u5b50\u53e5\u96c6\u662f\u5426\u5c5e\u4e8e\u67d0\u4e9b\u6587\u732e\u4e2d\u5df2\u5b9a\u4e49\u7684\u7c7b\uff0c\u5c24\u5176\u662f\u901a\u8fc7\u8c13\u8bcd\u91cd\u547d\u540d\u5b9e\u73b0\u3002\u91cd\u547d\u540d\u662f\u5426\u53ef\u5c06\u6b63\u8d1f\u6587\u5b57\u8c03\u6574\u5230\u6ee1\u8db3\u67d0\u4e9b\u6761\u4ef6\uff0c\u662f\u5224\u5b9a\u7279\u5b9a\u903b\u8f91\u8868\u8fbe\u80fd\u529b\u53ca\u81ea\u52a8\u63a8\u7406\u5212\u5206\u590d\u6742\u5ea6\u7684\u5173\u952e\u3002", "method": "\u8bba\u6587\u5206\u6790\u4e86\u901a\u8fc7\u8c13\u8bcd\u91cd\u547d\u540d\u6765\u5224\u65ad\u903b\u8f91\u5b50\u53e5\u96c6\u662f\u5426\u5c5e\u4e8e\u5982Horn\u3001OCC1N\u3001PVD\u7b49\u903b\u8f91\u7c7b\u7684\u65b9\u6cd5\u3002\u4e3b\u8981\u5229\u7528\u8d85\u5206\u8fa8\u7387\u6280\u672f\uff0c\u6784\u5efa\u5224\u5b9a\u8fc7\u7a0b\uff0c\u5e76\u80fd\u591f\u4ece\u6700\u7ec8\u7684\u9971\u548c\u5b50\u53e5\u96c6\u4e2d\u63d0\u53d6\u6709\u6548\u91cd\u547d\u540d\u3002", "result": "\u53d1\u73b0\u5bf9\u4e8eHorn\u7c7b\u548cOCC1N\u7c7b\uff0c\u901a\u8fc7\u8c13\u8bcd\u91cd\u547d\u540d\u5224\u65ad\u5176\u6210\u5458\u6027\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u5b8c\u6210\uff1b\u800c\u9488\u5bf9PVD\u7c7b\uff0c\u8be5\u5224\u5b9a\u95ee\u9898\u662fNP-\u5b8c\u5168\u7684\u3002", "conclusion": "\u8bba\u6587\u8868\u660e\uff0c\u4e0d\u540c\u903b\u8f91\u7c7b\u5728\u8c13\u8bcd\u91cd\u547d\u540d\u4e0b\u7684\u6210\u5458\u68c0\u6d4b\u590d\u6742\u5ea6\u5b58\u5728\u5de8\u5927\u5dee\u5f02\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u9ad8\u6548\u7b97\u6cd5\u548c\u590d\u6742\u6027\u4e0b\u754c\u3002"}}
{"id": "2507.02958", "categories": ["cs.CL", "I.2.7; H.3.3; I.5.4"], "pdf": "https://arxiv.org/pdf/2507.02958", "abs": "https://arxiv.org/abs/2507.02958", "authors": ["Ha Dao", "Gaurav Chawla", "Raghu Banda", "Caleb DeLeeuw"], "title": "Real-World En Call Center Transcripts Dataset with PII Redaction", "comment": "17 pages, 4 figures. Dataset publicly available at\n  https://huggingface.co/datasets/AIxBlock/91706-real-world-call-center-scripts-english\n  . Contains 91,706 real-world English call center transcripts (10,448 audio\n  hours) with PII redaction. Licensed under CC BY-NC 4.0 for non-commercial\n  research use", "summary": "We introduce CallCenterEN, a large-scale (91,706 conversations, corresponding\nto 10448 audio hours), real-world English call center transcript dataset\ndesigned to support research and development in customer support and sales AI\nsystems. This is the largest release to-date of open source call center\ntranscript data of this kind. The dataset includes inbound and outbound calls\nbetween agents and customers, with accents from India, the Philippines and the\nUnited States. The dataset includes high-quality, PII-redacted human-readable\ntranscriptions. All personally identifiable information (PII) has been\nrigorously removed to ensure compliance with global data protection laws. The\naudio is not included in the public release due to biometric privacy concerns.\nGiven the scarcity of publicly available real-world call center datasets,\nCallCenterEN fills a critical gap in the landscape of available ASR corpora,\nand is released under a CC BY-NC 4.0 license for non-commercial research use.", "AI": {"tldr": "\u4f5c\u8005\u53d1\u5e03\u4e86\u8fc4\u4eca\u6700\u5927\u89c4\u6a21\u7684\u547c\u53eb\u4e2d\u5fc3\u82f1\u6587\u8f6c\u5f55\u6570\u636e\u96c6CallCenterEN\uff0c\u53bb\u9664\u4e86\u4e2a\u4eba\u9690\u79c1\u4fe1\u606f\uff0c\u4ec5\u5f00\u653e\u6587\u672c\u8f6c\u5f55\uff0c\u4e3a\u975e\u5546\u4e1a\u8bed\u97f3AI\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\u3002", "motivation": "\u5728\u5ba2\u6237\u652f\u6301\u548c\u9500\u552eAI\u7cfb\u7edf\u9886\u57df\uff0c\u771f\u5b9e\u4e14\u89c4\u6a21\u5316\u7684\u547c\u53eb\u4e2d\u5fc3\u8bed\u97f3\u6587\u672c\u6570\u636e\u6781\u4e3a\u7a00\u7f3a\uff0c\u9650\u5236\u4e86\u8bed\u97f3\u8bc6\u522b\u4e0e\u5bf9\u8bdd\u7406\u89e3\u76f8\u5173\u7814\u7a76\u7684\u53d1\u5c55\u3002", "method": "\u4f5c\u8005\u6536\u96c6\u4e86\u771f\u5b9e\u7684\u547c\u53eb\u4e2d\u5fc3\u82f1\u6587\u901a\u8bdd\u6570\u636e\u96c6\uff0c\u7ecf\u8fc7\u9ad8\u8d28\u91cf\u4eba\u5de5\u8f6c\u5f55\u548cPII\u53bb\u9664\u5904\u7406\uff0c\u5e76\u672a\u5305\u542b\u539f\u59cb\u97f3\u9891\u3002\u6d89\u53ca\u5370\u5ea6\u3001\u83f2\u5f8b\u5bbe\u548c\u7f8e\u56fd\u7b49\u591a\u79cd\u53e3\u97f3\uff0c\u652f\u6301\u547c\u5165\u4e0e\u547c\u51fa\u7684\u5ba2\u6237\u670d\u52a1\u573a\u666f\u3002", "result": "\u6700\u7ec8\u5f97\u5230\u7684\u6570\u636e\u96c6\u5305\u542b91706\u6761\u901a\u8bdd\uff0c\u603b\u65f6\u957f10448\u5c0f\u65f6\uff0c\u662f\u8fc4\u4eca\u6700\u5927\u89c4\u6a21\u7684\u5f00\u653e\u547c\u53eb\u4e2d\u5fc3\u82f1\u6587\u8f6c\u5f55\u6570\u636e\u3002\u6240\u6709PII\u4fe1\u606f\u5df2\u88ab\u4e25\u683c\u53bb\u9664\uff0c\u6570\u636e\u96c6\u4ee5CC BY-NC 4.0\u534f\u8bae\u9762\u5411\u975e\u5546\u4e1a\u7814\u7a76\u5f00\u653e\u3002", "conclusion": "CallCenterEN\u6570\u636e\u96c6\u4e3a\u5b66\u754c\u548c\u4e1a\u754c\u5728\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u8bed\u97f3\u8bc6\u522b\u3001\u5ba2\u6237\u652f\u6301\u548c\u4f1a\u8bddAI\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\uff0c\u586b\u8865\u4e86\u516c\u5f00\u547c\u53eb\u4e2d\u5fc3\u6570\u636e\u7684\u7a7a\u767d\u3002"}}
{"id": "2507.04185", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.04185", "abs": "https://arxiv.org/abs/2507.04185", "authors": ["Aniket Kesari", "Travis Breaux", "Tom Norton", "Sarah Santos", "Anmol Singhal"], "title": "From Legal Text to Tech Specs: Generative AI's Interpretation of Consent in Privacy Law", "comment": "10 pages, 1 figure, 20th International Conference on Artificial\n  Intelligence and Law (ICAIL 2025)", "summary": "Privacy law and regulation have turned to \"consent\" as the legitimate basis\nfor collecting and processing individuals' data. As governments have rushed to\nenshrine consent requirements in their privacy laws, such as the California\nConsumer Privacy Act (CCPA), significant challenges remain in understanding how\nthese legal mandates are operationalized in software. The opaque nature of\nsoftware development processes further complicates this translation. To address\nthis, we explore the use of Large Language Models (LLMs) in requirements\nengineering to bridge the gap between legal requirements and technical\nimplementation. This study employs a three-step pipeline that involves using an\nLLM to classify software use cases for compliance, generating LLM modifications\nfor non-compliant cases, and manually validating these changes against legal\nstandards. Our preliminary findings highlight the potential of LLMs in\nautomating compliance tasks, while also revealing limitations in their\nreasoning capabilities. By benchmarking LLMs against real-world use cases, this\nresearch provides insights into leveraging AI-driven solutions to enhance legal\ncompliance of software.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5c06\u9690\u79c1\u6cd5\u201c\u540c\u610f\u201d\u8981\u6c42\u8f6c\u5316\u4e3a\u8f6f\u4ef6\u5f00\u53d1\u64cd\u4f5c\u4e2d\u7684\u4f5c\u7528\u3002\u7ed3\u679c\u8868\u660eLLM\u53ef\u90e8\u5206\u81ea\u52a8\u5316\u5408\u89c4\u6027\u5224\u65ad\uff0c\u4f46\u4ecd\u9700\u4eba\u5de5\u8f85\u52a9\u4ee5\u5f25\u8865\u903b\u8f91\u63a8\u7406\u548c\u6cd5\u5f8b\u7ec6\u8282\u4e0a\u7684\u7f3a\u9677\u3002", "motivation": "\u968f\u7740\u5404\u56fd\u9690\u79c1\u6cd5\u89c4\uff08\u5982CCPA\uff09\u5f3a\u5316\u540c\u610f\u8981\u6c42\uff0c\u5f00\u53d1\u8005\u5982\u4f55\u5c06\u6cd5\u5f8b\u4e49\u52a1\u843d\u5b9e\u5230\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u53d8\u5f97\u6781\u4e3a\u590d\u6742\uff0c\u73b0\u6709\u6d41\u7a0b\u4e0d\u900f\u660e\uff0c\u4e9f\u9700\u66f4\u9ad8\u6548\u3001\u667a\u80fd\u7684\u6280\u672f\u652f\u6301\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e09\u6b65\u6cd5\uff1a1) \u5229\u7528LLM\u5bf9\u8f6f\u4ef6\u7528\u4f8b\u8fdb\u884c\u5408\u89c4\u6027\u5206\u7c7b\uff1b2) \u5bf9\u4e0d\u5408\u89c4\u7528\u4f8b\u751f\u6210LLM\u4fee\u6539\u5efa\u8bae\uff1b3) \u624b\u52a8\u6821\u9a8c\u8fd9\u4e9b\u53d8\u52a8\u662f\u5426\u7b26\u5408\u6cd5\u5f8b\u6807\u51c6\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u663e\u793aLLMs\u53ef\u52a9\u529b\u8f6f\u4f53\u5408\u89c4\u6027\u68c0\u67e5\u81ea\u52a8\u5316\uff0c\u867d\u5c55\u73b0\u51fa\u4e00\u5b9a\u80fd\u529b\uff0c\u4f46\u5728\u6df1\u5c42\u63a8\u7406\u53ca\u4e0e\u590d\u6742\u6cd5\u5f8b\u6807\u51c6\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "conclusion": "LLMs\u5177\u5907\u81ea\u52a8\u5316\u5408\u89c4\u4efb\u52a1\u7684\u6f5c\u529b\uff0c\u4f46\u5728\u63a8\u7406\u80fd\u529b\u65b9\u9762\u4ecd\u6709\u5c40\u9650\u6027\uff0c\u9700\u8981\u914d\u5408\u4eba\u5de5\u6821\u9a8c\u4ee5\u786e\u4fdd\u7b26\u5408\u6cd5\u5f8b\u6807\u51c6\u3002"}}
{"id": "2507.02962", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.02962", "abs": "https://arxiv.org/abs/2507.02962", "authors": ["Zhiwen Tan", "Jiaming Huang", "Qintong Wu", "Hongxuan Zhang", "Chenyi Zhuang", "Jinjie Gu"], "title": "RAG-R1 : Incentivize the Search and Reasoning Capabilities of LLMs through Multi-query Parallelism", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks, while they remain prone to generating hallucinated or outdated\nresponses due to their static internal knowledge. Recent advancements in\nRetrieval-Augmented Generation (RAG) methods have explored enhancing models'\nsearch and reasoning capabilities through reinforcement learning (RL). Although\nthese methods demonstrate promising results, they face challenges in training\nstability and encounter issues such as substantial inference time and\nrestricted capabilities due to the single-query mode. In this paper, we propose\nRAG-R1, a novel training framework designed to enable LLMs to adaptively\nleverage internal and external knowledge during the reasoning process. We\nfurther expand the generation and retrieval processes within the framework from\nsingle-query mode to multi-query parallelism, aimed at reducing inference time\nand enhancing the model's capabilities. Extensive experiments on seven\nquestion-answering benchmarks demonstrate that our method outperforms the\nstrongest baseline by up to 13.2% and decreases inference time by 11.1%.", "AI": {"tldr": "RAG-R1\u901a\u8fc7\u591a\u67e5\u8be2\u5e76\u884c\u548c\u77e5\u8bc6\u81ea\u9002\u5e94\u878d\u5408\uff0c\u5927\u5e45\u63d0\u5347LLM\u95ee\u7b54\u80fd\u529b\u4e14\u63a8\u7406\u66f4\u5feb\uff0c\u4f18\u4e8e\u4e3b\u6d41RAG\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfRAG\u65b9\u6cd5\u5728\u5f3a\u5316\u5b66\u4e60\u9a71\u52a8\u4e0b\u867d\u6709\u6548\uff0c\u4f46\u63a8\u7406\u65f6\u95f4\u957f\u3001\u80fd\u529b\u53d7\u9650\u4e8e\u5355\u67e5\u8be2\uff0c\u540c\u65f6\u8bad\u7ec3\u4e0d\u7a33\u5b9a\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u5185\u5916\u90e8\u77e5\u8bc6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u6846\u67b6RAG-R1\uff0c\u4f7fLLM\u80fd\u81ea\u9002\u5e94\u5730\u7ed3\u5408\u5185\u90e8\u4e0e\u5916\u90e8\u77e5\u8bc6\uff1b\u5e76\u5c06\u751f\u6210\u4e0e\u68c0\u7d22\u8fc7\u7a0b\u4ece\u5355\u67e5\u8be2\u6269\u5c55\u4e3a\u591a\u67e5\u8be2\u5e76\u884c\uff0c\u63d0\u9ad8\u6548\u7387\u548c\u80fd\u529b\u3002\u8fdb\u884c\u4e86\u4e03\u4e2a\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "RAG-R1\u65b9\u6cd5\u57fa\u4e8e\u4e03\u4e2a\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u80fd\u63d0\u5347\u51c6\u786e\u7387\u6700\u591a13.2%\uff0c\u63a8\u7406\u65f6\u95f4\u51cf\u5c1111.1%\u3002", "conclusion": "RAG-R1\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u5347LLM\u5728\u95ee\u7b54\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u6709\u6548\u7f29\u77ed\u63a8\u7406\u65f6\u95f4\uff0c\u8d85\u8d8a\u5f53\u524d\u6700\u5f3a\u57fa\u7ebf\u3002"}}
{"id": "2507.04354", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.04354", "abs": "https://arxiv.org/abs/2507.04354", "authors": ["Yanzhou Mu", "Juan Zhai", "Chunrong Fang", "Xiang Chen", "Zhixiang Cao", "Peiran Yang", "Kexin Zhao", "An Guo", "Zhenyu Chen"], "title": "Improving Deep Learning Framework Testing with Model-Level Metamorphic Testing", "comment": "23 pages, 5 figures", "summary": "Deep learning (DL) frameworks are essential to DL-based software systems, and\nframework bugs may lead to substantial disasters, thus requiring effective\ntesting. Researchers adopt DL models or single interfaces as test inputs and\nanalyze their execution results to detect bugs. However, floating-point errors,\ninherent randomness, and the complexity of test inputs make it challenging to\nanalyze execution results effectively, leading to existing methods suffering\nfrom a lack of suitable test oracles. Some researchers utilize metamorphic\ntesting to tackle this challenge. They design Metamorphic Relations (MRs) based\non input data and parameter settings of a single framework interface to\ngenerate equivalent test inputs, ensuring consistent execution results between\noriginal and generated test inputs. Despite their promising effectiveness, they\nstill face certain limitations. (1) Existing MRs overlook structural\ncomplexity, limiting test input diversity. (2) Existing MRs focus on limited\ninterfaces, which limits generalization and necessitates additional\nadaptations. (3) Their detected bugs are related to the result consistency of\nsingle interfaces and far from those exposed in multi-interface combinations\nand runtime metrics (e.g., resource usage). To address these limitations, we\npropose ModelMeta, a model-level metamorphic testing method for DL frameworks\nwith four MRs focused on the structure characteristics of DL models. ModelMeta\naugments seed models with diverse interface combinations to generate test\ninputs with consistent outputs, guided by the QR-DQN strategy. It then detects\nbugs through fine-grained analysis of training loss/gradients, memory/GPU\nusage, and execution time.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u6a21\u578b\u7ed3\u6784\u7684\u53d8\u5f02\u6d4b\u8bd5\u65b9\u6cd5\uff08ModelMeta\uff09\u7528\u4e8e\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u591f\u901a\u8fc7\u6269\u5c55\u6a21\u578b\u548c\u591a\u63a5\u53e3\u7ec4\u5408\uff0c\u5728\u8bad\u7ec3\u635f\u5931\u548c\u8d44\u6e90\u5229\u7528\u7b49\u89d2\u5ea6\u7cbe\u51c6\u53d1\u73b0\u66f4\u591a\u7c7b\u578b\u7684\u6846\u67b6\u7f3a\u9677\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u7ed3\u6784\u590d\u6742\u6027\u548c\u63a5\u53e3\u5e7f\u6cdb\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u6d4b\u8bd5\u65b9\u6cd5\u7531\u4e8e\u6d6e\u70b9\u8bef\u5dee\u3001\u968f\u673a\u6027\u4ee5\u53ca\u6d4b\u8bd5\u8f93\u5165\u590d\u6742\u6027\uff0c\u5bfc\u81f4\u96be\u4ee5\u6709\u6548\u5206\u6790\u6267\u884c\u7ed3\u679c\uff0c\u7f3a\u4e4f\u9002\u5f53\u7684\u6d4b\u8bd5\u5224\u5b9a\u6807\u51c6\uff08test oracle\uff09\u3002\u53d8\u5f02\u6d4b\u8bd5\u867d\u7136\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u89e3\u51b3\u4e86\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f46\u5728\u7ed3\u6784\u590d\u6742\u6027\u3001\u63a5\u53e3\u6cdb\u5316\u6027\u3001\u591a\u63a5\u53e3\u7ec4\u5408\u68c0\u6d4b\u7b49\u65b9\u9762\u4ecd\u5b58\u5728\u660e\u663e\u5c40\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u7ea7\u53d8\u5f02\u6d4b\u8bd5\u7684\u65b9\u6cd5\uff08ModelMeta\uff09\uff0c\u5229\u7528\u56db\u79cd\u805a\u7126\u4e8e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7ed3\u6784\u7279\u5f81\u7684\u53d8\u5f02\u5173\u7cfb\u3002\u901a\u8fc7\u6269\u5c55\u79cd\u5b50\u6a21\u578b\u548c\u591a\u63a5\u53e3\u7ec4\u5408\u751f\u6210\u7b49\u4ef7\u6d4b\u8bd5\u8f93\u5165\uff0c\u5e76\u7ed3\u5408QR-DQN\u7b56\u7565\uff0c\u5f15\u5bfc\u6d4b\u8bd5\u751f\u6210\u3002\u8be5\u65b9\u6cd5\u8fdb\u4e00\u6b65\u901a\u8fc7\u8bad\u7ec3\u635f\u5931\u3001\u68af\u5ea6\u3001\u5185\u5b58/GPU\u8d44\u6e90\u5229\u7528\u548c\u6267\u884c\u65f6\u95f4\u7b49\u591a\u7ef4\u5ea6\u7ec6\u7c92\u5ea6\u5206\u6790\u53d1\u73b0\u6846\u67b6\u7f3a\u9677\u3002", "result": "ModelMeta\u80fd\u591f\u8986\u76d6\u66f4\u591a\u7684\u63a5\u53e3\u7ec4\u5408\u4e0e\u6a21\u578b\u7ed3\u6784\uff0c\u751f\u6210\u591a\u6837\u5316\u7684\u6d4b\u8bd5\u8f93\u5165\uff0c\u5e76\u80fd\u68c0\u6d4b\u5230\u66f4\u591a\u4e0e\u591a\u63a5\u53e3\u7ec4\u5408\u53ca\u8fd0\u884c\u65f6\u6307\u6807\u76f8\u5173\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u7f3a\u9677\uff0c\u63d0\u5347\u4e86\u7f3a\u9677\u68c0\u6d4b\u7684\u6709\u6548\u6027\u548c\u5e7f\u6cdb\u6027\u3002", "conclusion": "ModelMeta\u5f25\u8865\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6d4b\u8bd5\u8f93\u5165\u591a\u6837\u6027\u3001\u63a5\u53e3\u6cdb\u5316\u6027\u4ee5\u53ca\u68c0\u6d4b\u80fd\u8986\u76d6\u591a\u63a5\u53e3\u7ec4\u5408\u548c\u8fd0\u884c\u65f6\u6307\u6807\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4e3aDL\u6846\u67b6\u7684\u81ea\u52a8\u5316\u5b89\u5168\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u624b\u6bb5\u3002"}}
{"id": "2507.02964", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.02964", "abs": "https://arxiv.org/abs/2507.02964", "authors": ["Salahuddin Salahuddin", "Ahmed Hussain", "Jussi L\u00f6pp\u00f6nen", "Toni Jutila", "Panos Papadimitratos"], "title": "Less Data, More Security: Advancing Cybersecurity LLMs Specialization via Resource-Efficient Domain-Adaptive Continuous Pre-training with Minimal Tokens", "comment": "15 Pages and 10 Figures", "summary": "While Large Language Models (LLMs) demonstrate exceptional natural language\ncapabilities, general-purpose models lack specialized domain knowledge for\neffective cybersecurity analysis. In this work, we investigate Domain-Adaptive\nContinuous Pretraining (DAP) as a methodology for enhancing cybersecurity\nunderstanding in pretrained LLMs while preserving general language\ncapabilities. We systematically adapted three decoder-based architectures --\nLlama-3.1-8B, DeepSeek-R1-Distill-Qwen-14B, and Llama-3.3-70B-Instruct -- using\na curated 126-million-word cybersecurity corpus from standards, academic\nliterature, and various other sources. Our approach employed constrained\ntraining parameters and distributed FSDP training to balance domain\nspecialization with knowledge preservation. Evaluation across three\ncybersecurity benchmarks, namely, CTI-MCQ, CyberMetric, and SecEval,\ndemonstrates consistent improvements post-adaptation. The Llama-3.3-70B-Ins-DAP\nmodel achieved state-of-the-art accuracies of 0.718, 0.933, and 0.864,\nrespectively, outperforming specialized models, including Llama-Primus-Base.\nNotably, competitive performance was achieved using substantially smaller\ndatasets (118.8 million versus 2.77 billion tokens), demonstrating efficient\ndomain specialization viability. We establish that targeted continuous\npretraining enables effective cybersecurity domain adaptation with\ncomputational feasibility, providing foundations for specialized AI assistants\nin threat analysis, vulnerability assessment, and security documentation while\nchallenging prevailing assumptions about data requirements for LLM\nspecialization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u9886\u57df\u81ea\u9002\u5e94\u8fde\u7eed\u9884\u8bad\u7ec3\uff08DAP\uff09\u65b9\u6cd5\uff0c\u5c06\u73b0\u6709LLM\u5728\u7f51\u7edc\u5b89\u5168\u9886\u57df\u5fae\u8c03\uff0c\u5728\u6570\u636e\u91cf\u5927\u5e45\u51cf\u5c11\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u8d85\u8d8a\u73b0\u6709\u4e13\u4e1a\u6a21\u578b\u7684\u8868\u73b0\uff0c\u4e3a\u4f4e\u6210\u672c\u9ad8\u6548\u7279\u5316AI\u63d0\u4f9b\u65b0\u8def\u5f84\u3002", "motivation": "\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u901a\u7528\u6a21\u578b\u5728\u7f51\u7edc\u5b89\u5168\u5206\u6790\u9886\u57df\u7f3a\u4e4f\u4e13\u95e8\u77e5\u8bc6\u3002\u56e0\u6b64\uff0c\u63d0\u5347LLMs\u5728\u7f51\u7edc\u5b89\u5168\u9886\u57df\u7684\u4e13\u4e1a\u7406\u89e3\u80fd\u529b\u6210\u4e3a\u7814\u7a76\u7684\u52a8\u529b\u3002", "method": "\u91c7\u7528\u9886\u57df\u81ea\u9002\u5e94\u8fde\u7eed\u9884\u8bad\u7ec3\uff08DAP\uff09\u65b9\u6cd5\uff0c\u5c06\u4e09\u79cd\u4e3b\u6d41LLM\u67b6\u6784\uff08Llama-3.1-8B\u3001DeepSeek-R1-Distill-Qwen-14B\u3001Llama-3.3-70B-Instruct\uff09\u5728\u4e00\u4e2a\u7531\u6807\u51c6\u6587\u732e\u3001\u5b66\u672f\u8bba\u6587\u7b49\u7ec4\u6210\u76841.26\u4ebf\u8bcd\u7f51\u7edc\u5b89\u5168\u8bed\u6599\u5e93\u4e0a\u8fdb\u884c\u5b9a\u5411\u5fae\u8c03\uff0c\u8bad\u7ec3\u65f6\u91c7\u53d6\u53c2\u6570\u548c\u8d44\u6e90\u7ea6\u675f\u4ee5\u5e73\u8861\u9886\u57df\u7279\u5316\u548c\u77e5\u8bc6\u4fdd\u7559\u3002", "result": "\u7ecf\u8fc7DAP\u65b9\u6cd5\u8bad\u7ec3\u540e\uff0c\u6240\u6709LLM\u6a21\u578b\u5728\u4e09\u4e2a\u7f51\u7edc\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\uff08CTI-MCQ\u3001CyberMetric\u3001SecEval\uff09\u4e0a\u7684\u8868\u73b0\u5747\u6709\u663e\u8457\u63d0\u5347\u3002\u5176\u4e2dLlama-3.3-70B-Ins-DAP\u6a21\u578b\u5206\u522b\u83b7\u5f970.718\u30010.933\u30010.864\u7684\u6700\u9ad8\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u4e86\u5305\u62ecLlama-Primus-Base\u5728\u5185\u7684\u4e13\u4e1a\u6a21\u578b\u3002", "conclusion": "\u8bba\u6587\u9a8c\u8bc1\u4e86\u5728\u6570\u636e\u91cf\u8fdc\u5c0f\u4e8e\u4ee5\u5f80\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u5b9a\u5411\u7684\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u8bed\u8a00\u901a\u7528\u80fd\u529b\u7684\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u63d0\u5347LLMs\u7684\u7f51\u7edc\u5b89\u5168\u9886\u57df\u77e5\u8bc6\uff0c\u5b9e\u73b0\u9ad8\u6548\u53ef\u884c\u7684\u9886\u57df\u7279\u5316\uff0c\u4e3a\u672a\u6765\u5a01\u80c1\u5206\u6790\u7b49AI\u52a9\u624b\u5f00\u53d1\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u4e5f\u6311\u6218\u4e86LLM\u9886\u57df\u7279\u5316\u5bf9\u5927\u89c4\u6a21\u6570\u636e\u9700\u6c42\u7684\u4f20\u7edf\u8ba4\u77e5\u3002"}}
{"id": "2507.04360", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.04360", "abs": "https://arxiv.org/abs/2507.04360", "authors": ["Yanzhou Mu", "Juan Zhai", "Chunrong Fang", "Xiang Chen", "Zhixiang Cao", "Peiran Yang", "Yinglong Zou", "Tao Zheng", "Zhenyu Chen"], "title": "DevMuT: Testing Deep Learning Framework via Developer Expertise-Based Mutation", "comment": "12 pages, 8 figures", "summary": "Deep learning (DL) frameworks are the fundamental infrastructure for various\nDL applications. Framework defects can profoundly cause disastrous accidents,\nthus requiring sufficient detection. In previous studies, researchers adopt DL\nmodels as test inputs combined with mutation to generate more diverse models.\nThough these studies demonstrate promising results, most detected defects are\nconsidered trivial (i.e., either treated as edge cases or ignored by the\ndevelopers). To identify important bugs that matter to developers, we propose a\nnovel DL framework testing method DevMuT, which generates models by adopting\nmutation operators and constraints derived from developer expertise. DevMuT\nsimulates developers'common operations in development and detects more diverse\ndefects within more stages of the DL model lifecycle (e.g., model training and\ninference). We evaluate the performance of DevMuT on three widely used DL\nframeworks (i.e., PyTorch, JAX, and Mind- Spore) with 29 DL models from nine\ntypes of industry tasks. The experiment results show that DevMuT outperforms\nstate-of-the-art baselines: it can achieve at least 71.68% improvement on\naverage in the diversity of generated models and 28.20% improvement on average\nin the legal rates of generated models. Moreover, DevMuT detects 117 defects,\n63 of which are confirmed, 24 are fixed, and eight are of high value confirmed\nby developers. Finally, DevMuT has been deployed in the MindSpore community\nsince December 2023. These demonstrate the effectiveness of DevMuT in detecting\ndefects that are close to the real scenes and are of concern to developers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7ed3\u5408\u5f00\u53d1\u8005\u5b9e\u9645\u64cd\u4f5c\u7684\u65b0\u578b\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u6d4b\u8bd5\u65b9\u6cd5DevMuT\uff0c\u80fd\u68c0\u6d4b\u5230\u66f4\u6709\u610f\u4e49\u3001\u9ad8\u4ef7\u503c\u7684\u7f3a\u9677\uff0c\u5728\u591a\u4e2a\u4e3b\u6d41\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u5df2\u5728\u793e\u533a\u4e2d\u6210\u529f\u5e94\u7528\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u662f\u4f17\u591aDL\u5e94\u7528\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u6846\u67b6\u4e2d\u7684\u7f3a\u9677\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u4e8b\u6545\uff0c\u56e0\u6b64\u9700\u8981\u9ad8\u6548\u7684\u7f3a\u9677\u68c0\u6d4b\u65b9\u6cd5\u3002\u6b64\u524d\u7684\u65b9\u6cd5\u591a\u901a\u8fc7\u53d8\u5f02\u6280\u672f\u751f\u6210\u591a\u6837\u7684\u6d4b\u8bd5\u6a21\u578b\uff0c\u4f46\u5927\u591a\u53ea\u80fd\u53d1\u73b0\u8fb9\u7f18\u6216\u88ab\u5f00\u53d1\u8005\u5ffd\u7565\u7684\u7410\u788e\u7f3a\u9677\u3002\u4e9f\u9700\u4e00\u79cd\u65b9\u6cd5\u80fd\u53d1\u73b0\u5f00\u53d1\u8005\u771f\u6b63\u5173\u5fc3\u7684\u91cd\u8981\u7f3a\u9677\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u6d4b\u8bd5\u65b9\u6cd5DevMuT\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u5f00\u53d1\u8005\u7ecf\u9a8c\u8bbe\u8ba1\u53d8\u5f02\u64cd\u4f5c\u53ca\u7ea6\u675f\uff0c\u6a21\u62df\u5f00\u53d1\u8005\u5e38\u89c1\u64cd\u4f5c\uff0c\u6db5\u76d6DL\u6a21\u578b\u751f\u547d\u5468\u671f\u591a\u4e2a\u9636\u6bb5\uff08\u5982\u8bad\u7ec3\u548c\u63a8\u7406\uff09\uff0c\u4ee5\u751f\u6210\u66f4\u52a0\u591a\u6837\u4e14\u5b9e\u7528\u7684\u6d4b\u8bd5\u6a21\u578b\uff0c\u7528\u4e8e\u53d1\u73b0\u66f4\u591a\u6709\u5b9e\u9645\u610f\u4e49\u7684\u7f3a\u9677\u3002", "result": "DevMuT\u5728PyTorch\u3001JAX\u548cMindSpore\u4e09\u4e2a\u4e3b\u6d41\u6846\u67b6\u53ca\u4e5d\u7c7b\u884c\u4e1a\u4efb\u52a1\u768429\u4e2a\u6a21\u578b\u4e0a\u6d4b\u8bd5\uff0c\u6a21\u578b\u591a\u6837\u6027\u63d0\u534771.68%\uff0c\u751f\u6210\u6a21\u578b\u5408\u6cd5\u7387\u63d0\u534728.20%\uff1b\u5171\u68c0\u6d4b\u5230117\u4e2a\u7f3a\u9677\uff0c\u5176\u4e2d63\u4e2a\u88ab\u786e\u8ba4\uff0c24\u4e2a\u5df2\u4fee\u590d\uff0c8\u4e2a\u88ab\u5f00\u53d1\u8005\u8ba4\u4e3a\u662f\u9ad8\u4ef7\u503c\u7f3a\u9677\u3002", "conclusion": "DevMuT\u80fd\u53d1\u73b0\u5f00\u53d1\u8005\u5173\u5fc3\u3001\u8d34\u8fd1\u771f\u5b9e\u573a\u666f\u7684\u6846\u67b6\u7f3a\u9677\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5df2\u7ecf\u5728MindSpore\u793e\u533a\u5b9e\u9645\u90e8\u7f72\u5e94\u7528\uff0c\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.02966", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.02966", "abs": "https://arxiv.org/abs/2507.02966", "authors": ["Gonzalo Mancera", "Aythami Morales", "Julian Fierrez", "Ruben Tolosana", "Alejandro Penna", "Miguel Lopez-Duran", "Francisco Jurado", "Alvaro Ortigosa"], "title": "PB-LLMs: Privacy- and Bias-aware NLP Models using Named-Entity Recognition", "comment": "Presented at AAAI Workshop on Privacy-Preserving Artificial\n  Intelligence (PPAI) 2025, Philadelphia, PA, USA, March 2025", "summary": "The use of Natural Language Processing (NLP) in high-stakes AI-based\napplications has increased significantly in recent years, especially since the\nemergence of Large Language Models (LLMs). However, despite their strong\nperformance, LLMs introduce important legal/ethical concerns, particularly\nregarding privacy, data protection, and transparency. Due to these concerns,\nthis work explores the use of Named-Entity Recognition (NER) to facilitate the\nprivacy-preserving training (or adaptation) of LLMs. We propose a framework\nthat uses NER technologies to anonymize sensitive information in text data,\nsuch as personal identities or geographic locations. An evaluation of the\nproposed privacy-preserving learning framework was conducted to measure its\nimpact on user privacy and system performance in a particular high-stakes and\nsensitive setup: AI-based resume scoring for recruitment processes. The study\ninvolved two language models (BERT and RoBERTa) and six anonymization\nalgorithms (based on Presidio, FLAIR, BERT, and different versions of GPT)\napplied to a database of 24,000 candidate profiles. The findings indicate that\nthe proposed privacy preservation techniques effectively maintain system\nperformance while playing a critical role in safeguarding candidate\nconfidentiality, thus promoting trust in the experimented scenario. On top of\nthe proposed privacy-preserving approach, we also experiment applying an\nexisting approach that reduces the gender bias in LLMs, thus finally obtaining\nour proposed Privacy- and Bias-aware LLMs (PB-LLMs). Note that the proposed\nPB-LLMs have been evaluated in a particular setup (resume scoring), but are\ngenerally applicable to any other LLM-based AI application.", "AI": {"tldr": "\u5229\u7528NER\u6280\u672f\u548c\u591a\u79cd\u533f\u540d\u5316\u65b9\u6cd5\u5bf9\u7b80\u5386\u8bc4\u5206LLM\u8fdb\u884c\u9690\u79c1\u4fdd\u62a4\uff0c\u5e76\u5f15\u5165\u53bb\u6027\u522b\u504f\u89c1\u673a\u5236\uff0c\u6700\u7ec8\u63d0\u51fa\u53ef\u62d3\u5c55\u7684PB-LLMs\uff0c\u5728\u4fdd\u969c\u9690\u79c1\u548c\u7cfb\u7edf\u6027\u80fd\u7684\u540c\u65f6\u589e\u52a0\u516c\u5e73\u6027\u4e0e\u7528\u6237\u4fe1\u4efb\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5e7f\u6cdb\u5e94\u7528\u4e8e\u9ad8\u98ce\u9669\u7684AI\u573a\u666f\u4e2d\uff0c\u4f8b\u5982\u62db\u8058\u7b80\u5386\u8bc4\u5206\uff0c\u968f\u4e4b\u800c\u6765\u7684\u9690\u79c1\u3001\u6570\u636e\u4fdd\u62a4\u548c\u900f\u660e\u5ea6\u7b49\u6cd5\u5f8b/\u4f26\u7406\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\u3002\u4e3a\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u7814\u7a76\u8feb\u5207\u9700\u8981\u53d1\u5c55\u80fd\u5728\u4fdd\u62a4\u9690\u79c1\u524d\u63d0\u4e0b\u4ecd\u5177\u5907\u826f\u597d\u6027\u80fd\u7684NLP\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5229\u7528NER\uff08\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff09\u6280\u672f\uff0c\u533f\u540d\u5316\u6587\u672c\u6570\u636e\u4e2d\u7684\u654f\u611f\u4fe1\u606f\uff08\u5982\u4e2a\u4eba\u8eab\u4efd\u3001\u5730\u7406\u4f4d\u7f6e\u4fe1\u606f\uff09\uff0c\u5e76\u57fa\u4e8e\u516d\u79cd\u4e0d\u540c\u7684\u533f\u540d\u5316\u7b97\u6cd5\uff08Presidio\u3001FLAIR\u3001BERT\u53ca\u4e0d\u540c\u7248\u672cGPT\uff09\u5728\u4e24\u4e2a\u8bed\u8a00\u6a21\u578b\uff08BERT\u4e0eRoBERTa\uff09\u548c24000\u4efd\u5019\u9009\u4eba\u7b80\u5386\u6570\u636e\u5e93\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002\u6b64\u5916\uff0c\u7ed3\u5408\u73b0\u6709\u51cf\u5c11\u6027\u522b\u504f\u89c1\u7684\u65b9\u6cd5\uff0c\u5bf9LLM\u8fdb\u884c\u9690\u79c1\u548c\u504f\u89c1\u53cc\u91cd\u4fdd\u62a4\uff0c\u5f62\u6210PB-LLMs\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u533f\u540d\u5316\u4e0e\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u53ef\u4ee5\u6709\u6548\u4fdd\u62a4\u5019\u9009\u4eba\u9690\u79c1\uff0c\u540c\u65f6\u51e0\u4e4e\u4e0d\u5f71\u54cd\u7cfb\u7edf\u6027\u80fd\uff0c\u5373\u5728\u771f\u5b9e\u573a\u666f\u4e0b\u65e2\u80fd\u4fdd\u5bc6\u53c8\u5177\u5907\u51c6\u786e\u8bc4\u5206\u80fd\u529b\u3002\u540c\u65f6\uff0cPB-LLMs\u8fdb\u4e00\u6b65\u51cf\u5c11\u4e86\u6027\u522b\u504f\u89c1\u3002\u8be5\u65b9\u6cd5\u867d\u4ee5\u7b80\u5386\u8bc4\u5206\u4e3a\u4f8b\uff0c\u4f46\u5177\u5907\u5e7f\u6cdb\u9002\u7528\u4e8e\u5176\u4ed6LLM\u5e94\u7528\u573a\u666f\u7684\u6f5c\u529b\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408NER\u533f\u540d\u5316\u548c\u53bb\u504f\u89c1\u6280\u672f\uff0c\u53ef\u540c\u65f6\u63d0\u5347LLM\u7684\u9690\u79c1\u4fdd\u62a4\u53ca\u516c\u5e73\u6027\uff0c\u589e\u5f3a\u7528\u6237\u5bf9AI\u7cfb\u7edf\u7684\u4fe1\u4efb\u3002\u8be5\u6846\u67b6\u5728\u62db\u8058\u8bc4\u5206\u80cc\u666f\u4e0b\u9a8c\u8bc1\u6709\u6548\uff0c\u4e3a\u672a\u6765\u9ad8\u98ce\u9669AI\u573a\u666f\u4e2d\u7684\u9690\u79c1\u53ca\u9053\u5fb7\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.04390", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.04390", "abs": "https://arxiv.org/abs/2507.04390", "authors": ["Vanesya Aura Ardity", "Yusuf Sulistyo Nugroho", "Syful Islam"], "title": "Exploring React Library Related Questions on Stack Overflow: Answered vs. Unanswered", "comment": "6 pages, 9 figures, 7 tables, conference paper", "summary": "React is a popular JavaScript framework in modern web application\ndevelopment. Due to its high performance and efficiency, many developers use\nthis framework. Although React library offers many advantages, it is not\nwithout its challenges. When using React library, developers often face\nproblems where they often seek solutions through question-and-answer forums,\nsuch as Stack Overflow (SO). However, despite its high popularity, many\nReact-related questions on SO remain unanswered. Thus, this study aims to\nanalyze the factors associated with question answerability and difficulty\nlevels of React-related questions on SO. To facilitate our study, Exploratory\nData Analysis was applied to 534,820 questions, where they are filtered based\non 23 React-related tags. We implemented a quantitative approach through text\nmining and statistical analysis. A logistic regression model was used to\nidentify attributes associated with question answerability, while a simple\nlinear regression model was employed to examine the correlation between user\nreputations and performance difficulty scores (PD Score). The results show that\nsome attributes, such as number of views, code snippet inclusion, number of\nlines of code, and user reputation, positively affect the likelihood of\nquestion answerability. In contrast, the number of comments, question lengths,\nand presence of images in React-related questions reduce the probability of a\nquestion receiving responses from users. Further investigation indicates a\nnegative correlation between user reputations and PD Score, where reputation\nincrease corresponds to -0.092 reduction in PD score, signaling experienced\nusers tend to propose more complex technical inquiries. This study provides\ninsights into the characteristics of technical question-and-answer platforms,\nsuch as SO, that users need to consider the answerability factors when posting\nquestions related to React.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5bf9SO\u4e0a53\u4e07\u591a\u6761React\u95ee\u9898\u7684\u5206\u6790\uff0c\u53d1\u73b0\u6d4f\u89c8\u91cf\u3001\u4ee3\u7801\u7b49\u6709\u5229\u4e8e\u95ee\u9898\u88ab\u56de\u7b54\uff0c\u800c\u8bc4\u8bba\u6570\u3001\u957f\u5ea6\u3001\u56fe\u7247\u7b49\u4e0d\u5229\u4e8e\u53cd\u5e94\uff0c\u540c\u65f6\u6709\u7ecf\u9a8c\u7684\u4eba\u503e\u5411\u4e8e\u63d0\u51fa\u66f4\u96be\u7684\u95ee\u9898\u3002", "motivation": "\u867d\u7136React\u76f8\u5173\u7684\u95ee\u9898\u5728Stack Overflow\uff08SO\uff09\u4e0a\u6570\u91cf\u4f17\u591a\u4e14\u70ed\u95e8\uff0c\u4f46\u4ecd\u6709\u5927\u91cf\u95ee\u9898\u672a\u88ab\u56de\u7b54\uff0c\u56e0\u6b64\u8be5\u7814\u7a76\u65e8\u5728\u5206\u6790\u5f71\u54cdReact\u76f8\u5173\u95ee\u9898\u53ef\u56de\u7b54\u6027\u53ca\u96be\u5ea6\u7684\u56e0\u7d20\u3002", "method": "\u5e94\u7528\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\uff08EDA\uff09\uff0c\u7ed3\u5408\u6587\u672c\u6316\u6398\u548c\u7edf\u8ba1\u5206\u6790\uff0c\u5bf923\u4e2aReact\u76f8\u5173\u6807\u7b7e\u4e0b\u5171534,820\u4e2a\u95ee\u9898\u8fdb\u884c\u5206\u6790\u3002\u91c7\u7528\u903b\u8f91\u56de\u5f52\u6a21\u578b\u8bc6\u522b\u5f71\u54cd\u95ee\u9898\u53ef\u56de\u7b54\u6027\u7684\u5c5e\u6027\uff0c\u4f7f\u7528\u7b80\u5355\u7ebf\u6027\u56de\u5f52\u5206\u6790\u7528\u6237\u58f0\u8a89\u4e0e\u96be\u5ea6\u5206\u6570\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u6d4f\u89c8\u91cf\u3001\u4ee3\u7801\u7247\u6bb5\u3001\u4ee3\u7801\u884c\u6570\u548c\u7528\u6237\u58f0\u8a89\u63d0\u5347\u4e86\u95ee\u9898\u56de\u7b54\u7684\u6982\u7387\uff1b\u8bc4\u8bba\u6570\u91cf\u3001\u95ee\u9898\u957f\u5ea6\u4e0e\u56fe\u7247\u7684\u5b58\u5728\u5219\u964d\u4f4e\u4e86\u56de\u5e94\u6982\u7387\u3002\u7528\u6237\u58f0\u8a89\u8d8a\u9ad8\uff0c\u5176\u63d0\u51fa\u95ee\u9898\u7684PD\u5206\u6570\u8d8a\u4f4e\uff0c\u8868\u660e\u7ecf\u9a8c\u4e30\u5bcc\u7528\u6237 tend to \u63d0\u51fa\u66f4\u590d\u6742\u7684\u6280\u672f\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u95ee\u9898\u7684\u67d0\u4e9b\u7279\u5f81\uff08\u5982\u6d4f\u89c8\u91cf\u3001\u5305\u542b\u4ee3\u7801\u7247\u6bb5\u3001\u4ee3\u7801\u884c\u6570\u548c\u7528\u6237\u58f0\u8a89\uff09\u6b63\u5411\u5f71\u54cd\u95ee\u9898\u7684\u53ef\u56de\u7b54\u6027\uff0c\u800c\u8bc4\u8bba\u6570\u91cf\u3001\u95ee\u9898\u957f\u5ea6\u548c\u56fe\u7247\u7684\u5b58\u5728\u53cd\u5411\u5f71\u54cd\u56de\u7b54\u6982\u7387\u3002\u6b64\u5916\uff0c\u7528\u6237\u58f0\u8a89\u4e0e\u95ee\u9898\u96be\u5ea6\u5f97\u5206\uff08PD Score\uff09\u5448\u8d1f\u76f8\u5173\uff0c\u9ad8\u58f0\u8a89\u7528\u6237\u66f4\u53ef\u80fd\u63d0\u51fa\u590d\u6742\u6280\u672f\u95ee\u9898\u3002"}}
{"id": "2507.02982", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.02982", "abs": "https://arxiv.org/abs/2507.02982", "authors": ["Zhenquan Shen", "Xinguo Yu", "Xiaotian Cheng", "Rao Peng", "Hao Ming"], "title": "We Need Knowledge Distillation for Solving Math Word Problems", "comment": null, "summary": "The enhancement of mathematical capabilities in large language models (LLMs)\nfosters new developments in mathematics education within primary and secondary\nschools, particularly as they relate to intelligent tutoring systems. However,\nLLMs require substantial computational resources, resulting in significant\ncosts in educational contexts. To mitigate this drawback, this paper\ninvestigates the feasibility of compressing LLMs for solving math word problems\n(MWPs). We compress the embedded vectors encoded by BERT and distill a\nconsiderably smaller student model. Our findings indicate that the student\nmodel can maintain nearly 90% of the performance of the teacher model while\nutilizing only 1/12 of its parameters. In addition to achieving high accuracy,\nthe model exhibits strong generalizability, as the compressed vectors perform\nwell across all tasks related to MWPs, and the distillation process is not\ntask-specific. The success of this distillation demonstrates that the\nunderlying principles are generic and not limited to a specific task. We\nfurther explore the reasons behind the compressibility of embedded vectors,\nrevealing that part-of-speech information, rather than entity recognition, is\ncrucial for MWPs, which may significantly contribute to their compressibility.\nThe improvements in efficiency and cost reduction provide substantial value for\nintelligent tutoring systems and significantly advance the field of intelligent\neducation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06BERT\u5d4c\u5165\u5411\u91cf\u538b\u7f29\u5e76\u77e5\u8bc6\u84b8\u998f\u5230\u5c0f\u578b\u5b66\u751f\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u6570\u5b66\u6587\u5b57\u9898\uff0c\u5728\u4ec5\u75281/12\u53c2\u6570\u4e0b\u4fdd\u6301\u8fd1\u4e5d\u6210\u6027\u80fd\uff0c\u5e76\u6307\u51fa\u8bcd\u6027\u4fe1\u606f\u662f\u538b\u7f29\u53ef\u884c\u7684\u5173\u952e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u667a\u80fd\u6559\u80b2\u7cfb\u7edf\u7684\u6548\u7387\u548c\u666e\u9002\u6027\u3002", "motivation": "\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u53d7\u5230\u9ad8\u6602\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u7684\u9650\u5236\uff0c\u5c24\u5176\u662f\u5728\u4e2d\u5c0f\u5b66\u6559\u80b2\u548c\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u4e2d\u3002\u4e3a\u964d\u4f4e\u6210\u672c\uff0c\u63d0\u9ad8\u5b9e\u9645\u5e94\u7528\u53ef\u884c\u6027\uff0c\u7814\u7a76\u5c1d\u8bd5\u5bf9\u8fd9\u4e9b\u6a21\u578b\u8fdb\u884c\u538b\u7f29\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u5bf9BERT\u7f16\u7801\u7684\u5d4c\u5165\u5411\u91cf\u8fdb\u884c\u538b\u7f29\uff0c\u5e76\u91c7\u7528\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\uff0c\u8bad\u7ec3\u51fa\u4e00\u4e2a\u5c0f\u578b\u5b66\u751f\u6a21\u578b\u4ee5\u89e3\u51b3\u6570\u5b66\u6587\u5b57\u9898\uff08MWPs\uff09\uff0c\u5e76\u8bc4\u4f30\u5176\u5728\u4fdd\u6301\u6027\u80fd\u548c\u53c2\u6570\u89c4\u6a21\u4e4b\u95f4\u7684\u5e73\u8861\u3002\u8fd8\u5206\u6790\u4e86\u5d4c\u5165\u5411\u91cf\u53ef\u538b\u7f29\u7684\u539f\u56e0\u3002", "result": "\u5b66\u751f\u6a21\u578b\u4ec5\u75281/12\u53c2\u6570\uff0c\u80fd\u4fdd\u6301\u6559\u5e08\u6a21\u578b\u8fd190%\u7684\u6027\u80fd\u3002\u538b\u7f29\u540e\u7684\u5411\u91cf\u5728\u6240\u6709MWPs\u76f8\u5173\u4efb\u52a1\u8868\u73b0\u826f\u597d\uff0c\u84b8\u998f\u65b9\u6cd5\u901a\u7528\u4e14\u975e\u4efb\u52a1\u7279\u5b9a\u3002\u7814\u7a76\u53d1\u73b0\u8bcd\u6027\u4fe1\u606f\u6bd4\u5b9e\u4f53\u8bc6\u522b\u66f4\u5173\u952e\uff0c\u4fc3\u8fdb\u4e86\u538b\u7f29\u6027\u3002", "conclusion": "\u901a\u8fc7\u5411\u91cf\u538b\u7f29\u4e0e\u77e5\u8bc6\u84b8\u998f\uff0c\u53ef\u5927\u5e45\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\uff0c\u540c\u65f6\u4fdd\u7559\u9ad8\u6027\u80fd\uff0c\u5b9e\u73b0\u667a\u80fd\u6559\u80b2\u7cfb\u7edf\u6210\u672c\u6548\u76ca\u63d0\u5347\u548c\u901a\u7528\u5316\u53d1\u5c55\u3002\u5d4c\u5165\u5411\u91cf\u7684\u53ef\u538b\u7f29\u6027\u4e0e\u8bcd\u6027\u4fe1\u606f\u6709\u5173\u3002"}}
{"id": "2507.04422", "categories": ["cs.SE", "cs.AI", "D.2.7; I.2.7"], "pdf": "https://arxiv.org/pdf/2507.04422", "abs": "https://arxiv.org/abs/2507.04422", "authors": ["Guoming Long", "Jingzhi Gong", "Hui Fang", "Tao Chen"], "title": "Learning Software Bug Reports: A Systematic Literature Review", "comment": "Accepted by TOSEM", "summary": "The recent advancement of artificial intelligence, especially machine\nlearning (ML), has significantly impacted software engineering research,\nincluding bug report analysis. ML aims to automate the understanding,\nextraction, and correlation of information from bug reports. Despite its\ngrowing importance, there has been no comprehensive review in this area. In\nthis paper, we present a systematic literature review covering 1,825 papers,\nselecting 204 for detailed analysis. We derive seven key findings: 1) Extensive\nuse of CNN, LSTM, and $k$NN for bug report analysis, with advanced models like\nBERT underutilized due to their complexity. 2) Word2Vec and TF-IDF are popular\nfor feature representation, with a rise in deep learning approaches. 3) Stop\nword removal is the most common preprocessing, with structural methods rising\nafter 2020. 4) Eclipse and Mozilla are the most frequently evaluated software\nprojects. 5) Bug categorization is the most common task, followed by bug\nlocalization and severity prediction. 6) There is increasing attention on\nspecific bugs like non-functional and performance bugs. 7) Common evaluation\nmetrics are F1-score, Recall, Precision, and Accuracy, with $k$-fold\ncross-validation preferred for model evaluation. 8) Many studies lack robust\nstatistical tests. We also identify six promising future research directions to\nprovide useful insights for practitioners.", "AI": {"tldr": "\u672c\u6587\u5bf9\u673a\u5668\u5b66\u4e60\u5728\u8f6f\u4ef6\u6f0f\u6d1e\u62a5\u544a\u5206\u6790\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u7cfb\u7edf\u7efc\u8ff0\uff0c\u8be6\u7ec6\u603b\u7ed3\u4e86\u5f53\u524d\u4e3b\u6d41\u7684\u6280\u672f\u3001\u65b9\u6cd5\u548c\u9762\u4e34\u7684\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\uff0c\u7279\u522b\u662f\u673a\u5668\u5b66\u4e60\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u6f0f\u6d1e\u62a5\u544a\u5206\u6790\u9886\u57df\u5f71\u54cd\u65e5\u76ca\u663e\u8457\uff0c\u7136\u800c\u76f8\u5173\u65b9\u6cd5\u548c\u8fdb\u5c55\u5c1a\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7efc\u8ff0\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u68c0\u7d221825\u7bc7\u76f8\u5173\u8bba\u6587\uff0c\u5e76\u5bf9\u5176\u4e2d204\u7bc7\u8fdb\u884c\u4e86\u6df1\u5165\u5206\u6790\u3002", "result": "\u603b\u7ed3\u4e86\u5f53\u524d\u5e94\u7528\u7684\u4e3b\u8981\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u5982CNN\u3001LSTM\u3001kNN\uff09\u3001\u7279\u5f81\u63d0\u53d6\u65b9\u5f0f\uff08Word2Vec\u3001TF-IDF\u548c\u6df1\u5ea6\u5b66\u4e60\uff09\u3001\u9884\u5904\u7406\u624b\u6bb5\uff08\u505c\u7528\u8bcd\u5220\u9664\u7b49\uff09\uff0c\u4ee5\u53ca\u4e3b\u6d41\u8bc4\u4f30\u6570\u636e\u96c6\u3001\u4efb\u52a1\u7c7b\u578b\u3001\u5173\u6ce8\u91cd\u70b9\u3001\u8bc4\u6d4b\u6307\u6807\u4e0e\u6a21\u578b\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u5e76\u53d1\u73b0\u591a\u6570\u7814\u7a76\u7f3a\u4e4f\u4e25\u8c28\u7684\u7edf\u8ba1\u68c0\u9a8c\u3002", "conclusion": "\u672c\u6587\u7cfb\u7edf\u6027\u68b3\u7406\u4e86\u673a\u5668\u5b66\u4e60\u7528\u4e8e\u6f0f\u6d1e\u62a5\u544a\u5206\u6790\u7684\u4e3b\u8981\u65b9\u6cd5\u3001\u73b0\u72b6\u4e0e\u6311\u6218\uff0c\u6307\u660e\u4e86\u672a\u6765\u516d\u5927\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u8be5\u9886\u57df\u7684\u5b66\u672f\u7814\u7a76\u548c\u5de5\u4e1a\u5e94\u7528\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u501f\u9274\u548c\u53c2\u8003\u3002"}}
{"id": "2507.02983", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.02983", "abs": "https://arxiv.org/abs/2507.02983", "authors": ["Mohammad Anas Azeez", "Rafiq Ali", "Ebad Shabbir", "Zohaib Hasan Siddiqui", "Gautam Siddharth Kashyap", "Jiechao Gao", "Usman Naseem"], "title": "Truth, Trust, and Trouble: Medical AI on the Edge", "comment": null, "summary": "Large Language Models (LLMs) hold significant promise for transforming\ndigital health by enabling automated medical question answering. However,\nensuring these models meet critical industry standards for factual accuracy,\nusefulness, and safety remains a challenge, especially for open-source\nsolutions. We present a rigorous benchmarking framework using a dataset of over\n1,000 health questions. We assess model performance across honesty,\nhelpfulness, and harmlessness. Our results highlight trade-offs between factual\nreliability and safety among evaluated models -- Mistral-7B,\nBioMistral-7B-DARE, and AlpaCare-13B. AlpaCare-13B achieves the highest\naccuracy (91.7%) and harmlessness (0.92), while domain-specific tuning in\nBioMistral-7B-DARE boosts safety (0.90) despite its smaller scale. Few-shot\nprompting improves accuracy from 78% to 85%, and all models show reduced\nhelpfulness on complex queries, highlighting ongoing challenges in clinical QA.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9762\u5411\u533b\u5b66\u95ee\u7b54\u7684LLM\u57fa\u51c6\u8bc4\u6d4b\u65b9\u6cd5\uff0c\u5bf9\u6bd4\u4e86\u591a\u6b3e\u6a21\u578b\u5728\u51c6\u786e\u6027\u548c\u5b89\u5168\u6027\u7b49\u65b9\u9762\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5373\u4fbf\u6709\u6280\u672f\u8fdb\u6b65\uff0c\u590d\u6742\u95ee\u9898\u4ecd\u5b58\u5728\u6709\u7528\u6027\u6311\u6218\uff0c\u4e3a\u4eca\u540e\u6570\u5b57\u5065\u5eb7LLM\u7684\u53d1\u5c55\u6307\u660e\u4e86\u65b9\u5411\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u63a8\u52a8\u6570\u5b57\u5065\u5eb7\u9886\u57df\u5c24\u5176\u662f\u81ea\u52a8\u533b\u5b66\u95ee\u7b54\u65b9\u9762\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u8981\u8fbe\u5230\u884c\u4e1a\u5728\u4e8b\u5b9e\u51c6\u786e\u6027\u3001\u6709\u7528\u6027\u548c\u5b89\u5168\u6027\u4e0a\u7684\u9ad8\u6807\u51c6\u4f9d\u7136\u5177\u6709\u6311\u6218\uff0c\u5c24\u5176\u662f\u5f00\u6e90\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e25\u683c\u7684\u57fa\u51c6\u6d4b\u8bd5\u4f53\u7cfb\uff0c\u91c7\u75281000\u591a\u4e2a\u5065\u5eb7\u95ee\u9898\u5bf9\u6bd4\u8bc4\u4f30\u6a21\u578b\u7684\u8bda\u5b9e\u6027\uff08honesty\uff09\u3001\u6709\u7528\u6027\uff08helpfulness\uff09\u548c\u65e0\u5bb3\u6027\uff08harmlessness\uff09\uff0c\u5e76\u6d4b\u8bd5\u4e86Mistral-7B\u3001BioMistral-7B-DARE\u548cAlpaCare-13B\u7b49\u6a21\u578b\u3002", "result": "AlpaCare-13B\u5728\u51c6\u786e\u7387\uff0891.7%\uff09\u548c\u65e0\u5bb3\u6027\uff080.92\uff09\u4e0a\u8868\u73b0\u6700\u4f73\uff1bBioMistral-7B-DARE\u901a\u8fc7\u9886\u57df\u4e13\u5c5e\u5fae\u8c03\uff0c\u5728\u5c0f\u89c4\u6a21\u4e0b\u63d0\u5347\u4e86\u5b89\u5168\u6027\uff080.90\uff09\uff1b\u5c11\u6837\u672c\u63d0\u793a\uff08few-shot prompting\uff09\u53ef\u5c06\u51c6\u786e\u7387\u4ece78%\u63d0\u5347\u81f385%\uff1b\u6240\u6709\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u533b\u5b66\u95ee\u7b54\u65f6\u6709\u7528\u6027\u4e0b\u964d\uff0c\u53cd\u6620\u51fa\u4e34\u5e8a\u95ee\u7b54\u4e2d\u7684\u6301\u7eed\u6311\u6218\u3002", "conclusion": "\u4e0d\u540c\u6a21\u578b\u5728\u4e8b\u5b9e\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002\u5c3d\u7ba1\u90e8\u5206\u6a21\u578b\u7ecf\u8fc7\u4e13\u7528\u8c03\u4f18\u80fd\u63d0\u5347\u5b89\u5168\u6027\uff0c\u4f46\u6574\u4f53\u5728\u590d\u6742\u533b\u7597\u95ee\u7b54\u573a\u666f\u4e0b\u4ecd\u9700\u6539\u8fdb\u3002\u63d0\u51fa\u7684\u57fa\u51c6\u4f53\u7cfb\u4e3a\u672a\u6765\u533b\u5b66\u5065\u5eb7\u7c7bLLM\u8bc4\u6d4b\u63d0\u4f9b\u4e86\u6807\u51c6\u3002"}}
{"id": "2507.04548", "categories": ["cs.SE", "cs.AI", "cs.LG", "D.2.11; D.2.7; I.2.7; I.5.4"], "pdf": "https://arxiv.org/pdf/2507.04548", "abs": "https://arxiv.org/abs/2507.04548", "authors": ["Renato Cordeiro Ferreira", "Dayanne Gomes", "Vitor Tamae", "Francisco Wernke", "Alfredo Goldman"], "title": "SPIRA: Building an Intelligent System for Respiratory Insufficiency Detection", "comment": "4 pages, 1 figure (1 diagram), published at ISE 2022", "summary": "Respiratory insufficiency is a medic symptom in which a person gets a reduced\namount of oxygen in the blood. This paper reports the experience of building\nSPIRA: an intelligent system for detecting respiratory insufficiency from\nvoice. It compiles challenges faced in two succeeding implementations of the\nsame architecture, summarizing lessons learned on data collection, training,\nand inference for future projects in similar systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5229\u7528\u58f0\u97f3\u68c0\u6d4b\u547c\u5438\u529f\u80fd\u4e0d\u5168\u7684\u667a\u80fd\u7cfb\u7edfSPIRA\uff0c\u91cd\u70b9\u8ba8\u8bba\u4e86\u4e24\u6b21\u7cfb\u7edf\u5b9e\u73b0\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5e76\u603b\u7ed3\u4e86\u6570\u636e\u6536\u96c6\u3001\u8bad\u7ec3\u4e0e\u63a8\u65ad\u7684\u5b9e\u8df5\u7ecf\u9a8c\uff0c\u5bf9\u672a\u6765\u76f8\u5173\u9879\u76ee\u6709\u91cd\u8981\u53c2\u8003\u4ef7\u503c\u3002", "motivation": "\u547c\u5438\u529f\u80fd\u4e0d\u5168\u662f\u4e00\u79cd\u5bfc\u81f4\u8840\u6db2\u542b\u6c27\u91cf\u4e0b\u964d\u7684\u533b\u5b66\u75c7\u72b6\u3002\u4e3a\u9884\u8b66\u548c\u68c0\u6d4b\u8be5\u75c7\u72b6\uff0c\u5f00\u53d1\u4e00\u79cd\u57fa\u4e8e\u58f0\u97f3\u5206\u6790\u7684\u667a\u80fd\u68c0\u6d4b\u7cfb\u7edf\uff0c\u5bf9\u63d0\u9ad8\u8bca\u65ad\u6548\u7387\u5177\u6709\u91cd\u5927\u610f\u4e49\u3002", "method": "\u901a\u8fc7\u4e24\u6b21\u8fde\u7eed\u5b9e\u73b0\u540c\u4e00\u67b6\u6784\uff0c\u7cfb\u7edf\u5316\u603b\u7ed3\u4e86\u642d\u5efa\u8fc7\u7a0b\u4e2d\u7684\u6311\u6218\uff0c\u5e76\u5bf9\u6570\u636e\u6536\u96c6\u3001\u6a21\u578b\u8bad\u7ec3\u548c\u63a8\u65ad\u6d41\u7a0b\u8fdb\u884c\u4e86\u7ecf\u9a8c\u5f52\u7eb3\u3002", "result": "\u7cfb\u7edf\u603b\u7ed3\u4e86\u4e24\u6b21\u7cfb\u7edf\u5b9e\u73b0\u8fc7\u7a0b\u4e2d\u9047\u5230\u7684\u6311\u6218\uff0c\u5e76\u4e3a\u672a\u6765\u7c7b\u4f3c\u7cfb\u7edf\u7684\u7814\u7a76\u548c\u5f00\u53d1\u63d0\u4f9b\u4e86\u91cd\u8981\u7ecf\u9a8c\u548c\u7b56\u7565\u3002", "conclusion": "\u8be5\u8bba\u6587\u603b\u7ed3\u4e86\u57fa\u4e8e\u58f0\u97f3\u68c0\u6d4b\u547c\u5438\u529f\u80fd\u4e0d\u5168\u7684\u667a\u80fd\u7cfb\u7edfSPIRA\u7684\u4e24\u4ee3\u5b9e\u73b0\u7ecf\u9a8c\uff0c\u5e76\u63d0\u70bc\u4e86\u6570\u636e\u6536\u96c6\u3001\u6a21\u578b\u8bad\u7ec3\u4ee5\u53ca\u63a8\u65ad\u8fc7\u7a0b\u4e2d\u7684\u5173\u952e\u7ecf\u9a8c\u6559\u8bad\u3002"}}
{"id": "2507.02984", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.02984", "abs": "https://arxiv.org/abs/2507.02984", "authors": ["Wentao Tan", "Qiong Cao", "Yibing Zhan", "Chao Xue", "Changxing Ding"], "title": "From Answers to Rationales: Self-Aligning Multimodal Reasoning with Answer-Oriented Chain-of-Thought", "comment": null, "summary": "Achieving human-like reasoning capabilities in Multimodal Large Language\nModels (MLLMs) has long been a goal. Current methodologies primarily focus on\nsynthesizing positive rationales, while overlooking the critical role of\nnegative rationales in training models to discern flawed reasoning patterns. To\naddress this gap, we propose a novel framework: \\textbf{S}elf-Aligning\n\\textbf{M}ultimodal Reasoning with \\textbf{A}nswer-O\\textbf{r}iented\nChain-of-\\textbf{T}hought (SMART). This framework enables models to utilize\nAoT-Oriented Chain-of-Thought (AoT) prompts to automatically generate\nhigh-quality positive and negative reasoning paths, followed by self-alignment\nto enhance their reasoning abilities. Inspired by human strategies for solving\nproof-based problems, AoT uses answers as a guide to help the model extract\ncritical visual information that links questions and answers. When provided\nwith ground truth answers, the model produces strong positive rationales.\nConversely, when correct answers are replaced with misleading alternatives, the\nmodel generates an erroneous yet compelling reasoning path, serving as a form\nof discriminative negative rationale. Models trained with AoT-generated data\noutperform those trained on manually annotated datasets, demonstrating superior\nreasoning capabilities. This encourages the use of improved models to generate\nhigher-quality preference data for further optimization. Consequently, SMART\nestablishes an iterative generation-optimization method that continually\nenhances the model's reasoning skills. Experiments indicate that the SMART\nframework significantly improves various MLLMs, regardless of model\narchitecture, parameter size, or pre-training dataset. The code, datasets, and\nmodels will be released.", "AI": {"tldr": "SMART\u6846\u67b6\u4e3a\u591a\u6a21\u6001\u5927\u6a21\u578b\u5f15\u5165\u6b63\u8d1f\u63a8\u7406\u81ea\u52a8\u751f\u6210\u4e0e\u81ea\u5bf9\u9f50\uff0c\u6a21\u578b\u6cdb\u5316\u63a8\u7406\u80fd\u529b\u589e\u5f3a\uff0c\u5b9e\u9a8c\u8868\u660e\u4f18\u4e8e\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u8bad\u7ec3\u65b9\u6cd5\u3002", "motivation": "\u76ee\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u4eba\u7c7b\u7ea7\u63a8\u7406\u65b9\u9762\u8fd8\u6709\u5f88\u5927\u7684\u63d0\u5347\u7a7a\u95f4\uff0c\u73b0\u6709\u65b9\u6cd5\u504f\u91cd\u4e8e\u751f\u6210\u6b63\u5411\u63a8\u7406\u8def\u5f84\uff0c\u5ffd\u89c6\u4e86\u8d1f\u5411\u63a8\u7406\uff08\u9519\u8bef\u63a8\u7406\u8def\u5f84\uff09\u5bf9\u6a21\u578b\u8fa8\u522b\u80fd\u529b\u7684\u8bad\u7ec3\u4f5c\u7528\u3002", "method": "\u63d0\u51fa\u4e86SMART\u6846\u67b6\uff0c\u5f15\u5165Answer-oriented Chain-of-Thought (AoT)\u673a\u5236\u3002\u8be5\u65b9\u6cd5\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u6b63\u5411\u548c\u8d1f\u5411\u63a8\u7406\u8def\u5f84\uff0c\u901a\u8fc7\u81ea\u5bf9\u9f50\u6b65\u9aa4\u5f3a\u5316\u6a21\u578b\u63a8\u7406\u80fd\u529b\u3002\u5177\u4f53\u505a\u6cd5\u4e3a\uff1a\u4ee5\u7b54\u6848\u4e3a\u5bfc\u5411\u5f15\u5bfc\u6a21\u578b\u62bd\u53d6\u5173\u952e\u89c6\u89c9\u4fe1\u606f\uff0c\u5bf9\u5e94\u4e8e\u6b63\u786e\u7b54\u6848\u751f\u6210\u6b63\u5411\u63a8\u7406\u8def\u5f84\uff0c\u5bf9\u5e94\u4e8e\u9519\u8bef\u7b54\u6848\u751f\u6210\u5408\u7406\u4f46\u9519\u8bef\u7684\u63a8\u7406\u8def\u5f84\uff0c\u5b9e\u73b0\u6b63\u8d1f\u63a8\u7406\u6837\u672c\u81ea\u52a8\u6784\u5efa\u3002", "result": "\u4f7f\u7528AoT\u673a\u5236\u751f\u6210\u7684\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u5728\u63a8\u7406\u80fd\u529b\u4e0a\u663e\u8457\u8d85\u8fc7\u4f7f\u7528\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u6a21\u578b\u3002SMART\u65b9\u6cd5\u5bf9\u4e0d\u540c\u67b6\u6784\u3001\u89c4\u6a21\u3001\u9884\u8bad\u7ec3\u6570\u636e\u96c6\u7684MLLM\u90fd\u6709\u6548\u63d0\u5347\u5176\u63a8\u7406\u8868\u73b0\u3002", "conclusion": "SMART\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u6b63\u8d1f\u63a8\u7406\u8def\u5f84\u7684\u81ea\u5bf9\u9f50\u8bad\u7ec3\u53ca\u8fed\u4ee3\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4eba\u7c7b\u7ea7\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u4e3a\u540e\u7eed\u6a21\u578b\u504f\u597d\u4f18\u5316\u548c\u9ad8\u8d28\u91cf\u6570\u636e\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.04555", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.04555", "abs": "https://arxiv.org/abs/2507.04555", "authors": ["Gabriella Waters"], "title": "Testing, Evaluation, Verification and Validation (TEVV) of Digital Twins: A Comprehensive Framework", "comment": "1 figure, 41 pages, 3 tables", "summary": "Digital twins have emerged as a powerful technology for modeling and\nsimulating complex systems across various domains (Fuller et al., 2020; Tao et\nal., 2019). As virtual representations of physical assets, processes, or\nsystems, digital twins enable real-time monitoring, predictive analysis, and\noptimization. However, as digital twins become more sophisticated and integral\nto decision-making processes, ensuring their accuracy, reliability, and ethical\nimplementation is essential. This paper presents a comprehensive framework for\nthe Testing, Evaluation, Verification and Validation (TEVV) of digital twins to\naddress the unique challenges posed by these dynamic and complex virtual\nmodels.", "AI": {"tldr": "\u968f\u7740\u6570\u5b57\u5b6a\u751f\u6280\u672f\u53d1\u5c55\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u7528\u4e8e\u6570\u5b57\u5b6a\u751f\u6d4b\u8bd5\u4e0e\u9a8c\u8bc1\u7684\u6846\u67b6\uff0c\u4ee5\u63d0\u5347\u5176\u51c6\u786e\u6027\u4e0e\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u6570\u5b57\u5b6a\u751f\u5728\u591a\u4e2a\u9886\u57df\u5f97\u5230\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u65e5\u76ca\u590d\u6742\u6027\u5bf9\u51c6\u786e\u6027\u3001\u53ef\u9760\u6027\u53ca\u4f26\u7406\u5b9e\u73b0\u63d0\u51fa\u4e86\u66f4\u9ad8\u8981\u6c42\uff0c\u4e9f\u9700\u5efa\u7acb\u7cfb\u7edf\u7684\u6d4b\u8bd5\u548c\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u6587\u4e2d\u4f7f\u7528\u4e86\u6587\u732e\u56de\u987e\u4e0e\u7406\u8bba\u5206\u6790\uff0c\u603b\u7ed3\u4e86\u5f53\u524d\u6570\u5b57\u5b6a\u751f\u5e94\u7528\u4e2d\u9762\u4e34\u7684\u4e3b\u8981\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u7cfb\u7edf\u6027\u7684TEVV\u6d41\u7a0b\u6846\u67b6\u3002", "result": "\u7814\u7a76\u5f62\u6210\u4e86\u9762\u5411\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u7684TEVV\u7cfb\u7edf\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u5176\u5b89\u5168\u3001\u9ad8\u6548\u548c\u5408\u89c4\u5e94\u7528\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b8c\u5584\u7684\u6570\u5b57\u5b6a\u751f\u6d4b\u8bd5\u3001\u8bc4\u4f30\u3001\u9a8c\u8bc1\u4e0e\u786e\u8ba4\uff08TEVV\uff09\u6846\u67b6\uff0c\u7528\u4ee5\u5168\u9762\u89e3\u51b3\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u5728\u5f53\u524d\u53ca\u672a\u6765\u53d1\u5c55\u4e2d\u7684\u4e00\u7cfb\u5217\u72ec\u7279\u6311\u6218\u3002"}}
{"id": "2507.02986", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.02986", "abs": "https://arxiv.org/abs/2507.02986", "authors": ["Seshu Tirupathi", "Dhaval Salwala", "Elizabeth Daly", "Inge Vejsbjerg"], "title": "GAF-Guard: An Agentic Framework for Risk Management and Governance in Large Language Models", "comment": null, "summary": "As Large Language Models (LLMs) continue to be increasingly applied across\nvarious domains, their widespread adoption necessitates rigorous monitoring to\nprevent unintended negative consequences and ensure robustness. Furthermore,\nLLMs must be designed to align with human values, like preventing harmful\ncontent and ensuring responsible usage. The current automated systems and\nsolutions for monitoring LLMs in production are primarily centered on\nLLM-specific concerns like hallucination etc, with little consideration given\nto the requirements of specific use-cases and user preferences. This paper\nintroduces GAF-Guard, a novel agentic framework for LLM governance that places\nthe user, the use-case, and the model itself at the center. The framework is\ndesigned to detect and monitor risks associated with the deployment of LLM\nbased applications. The approach models autonomous agents that identify risks,\nactivate risk detection tools, within specific use-cases and facilitate\ncontinuous monitoring and reporting to enhance AI safety, and user\nexpectations. The code is available at\nhttps://github.com/IBM/risk-atlas-nexus-demos/tree/main/gaf-guard.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGAF-Guard\u4ee3\u7406\u5f0f\u6cbb\u7406\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u4ee5\u7528\u6237\u548c\u7528\u4f8b\u4e3a\u6838\u5fc3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u98ce\u9669\u76d1\u6d4b\uff0c\u63d0\u5347\u4e86AI\u6cbb\u7406\u7684\u5b89\u5168\u6027\u548c\u7075\u6d3b\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u4e0d\u540c\u9886\u57df\uff0c\u5728\u5b9e\u9645\u90e8\u7f72\u8fc7\u7a0b\u4e2d\u9700\u8981\u6709\u6548\u76d1\u63a7\uff0c\u4ee5\u9632\u6b62\u8d1f\u9762\u540e\u679c\u5e76\u4fdd\u8bc1\u5176\u7a33\u5065\u6027\u3002\u540c\u65f6\uff0cLLM\u9700\u8981\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\uff0c\u9632\u6b62\u6709\u5bb3\u5185\u5bb9\u3001\u4fdd\u969c\u8d1f\u8d23\u4efb\u7684\u4f7f\u7528\u3002\u73b0\u6709\u81ea\u52a8\u5316\u76d1\u63a7\u5927\u591a\u805a\u7126\u4e8e\u751f\u6210\u5e7b\u89c9\u7b49\u901a\u7528\u95ee\u9898\uff0c\u7f3a\u4e4f\u5bf9\u7279\u5b9a\u7528\u4f8b\u548c\u7528\u6237\u504f\u597d\u7684\u9488\u5bf9\u6027\u8003\u8651\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u4ee3\u7406\u5f0f\u6cbb\u7406\u6846\u67b6GAF-Guard\uff0c\u5c06\u7528\u6237\u3001\u7528\u4f8b\u548c\u6a21\u578b\u4e09\u8005\u7f6e\u4e8e\u76d1\u63a7\u6838\u5fc3\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u81ea\u4e3b\u4ee3\u7406\u5bf9\u98ce\u9669\u8fdb\u884c\u8bc6\u522b\uff0c\u5e76\u5728\u5177\u4f53\u7528\u4f8b\u4e2d\u6fc0\u6d3b\u98ce\u9669\u68c0\u6d4b\u5de5\u5177\uff0c\u5b9e\u73b0\u6301\u7eed\u76d1\u63a7\u548c\u98ce\u9669\u62a5\u544a\u3002", "result": "GAF-Guard\u80fd\u591f\u6839\u636e\u4e0d\u540c\u5e94\u7528\u573a\u666f\u548c\u7528\u6237\u9700\u6c42\uff0c\u6709\u6548\u8bc6\u522b\u3001\u68c0\u6d4b\u548c\u62a5\u544aLLM\u90e8\u7f72\u4e2d\u7684\u98ce\u9669\uff0c\u63d0\u5347\u4e86AI\u5b89\u5168\u6027\u548c\u5bf9\u7528\u6237\u671f\u671b\u7684\u6ee1\u8db3\u5ea6\u3002", "conclusion": "GAF-Guard\u6846\u67b6\u4e3aLLM\u7684\u7a33\u5065\u90e8\u7f72\u548c\u6cbb\u7406\u63d0\u4f9b\u4e86\u66f4\u5177\u9488\u5bf9\u6027\u548c\u81ea\u4e3b\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u8d23\u4efb\u5316\u3001\u98ce\u9669\u53ef\u63a7\u7684AI\u5e94\u7528\u3002"}}
