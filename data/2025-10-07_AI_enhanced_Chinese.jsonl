{"id": "2510.03296", "categories": ["cs.DM", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2510.03296", "abs": "https://arxiv.org/abs/2510.03296", "authors": ["Pablo Arrighi", "Marin Costes", "Luidnel Maignan"], "title": "Space-time reversible graph rewriting", "comment": null, "summary": "In the mathematical tradition, reversibility requires that the evolution of a\ndynamical system be a bijective function. In the context of graph rewriting,\nhowever, the evolution is not even a function, because it is not even\ndeterministic -- as the rewrite rules get applied at non-deterministically\nchosen locations. Physics, by contrast, suggests a more flexible understanding\nof reversibility in space-time, whereby any two closeby snapshots (aka\n`space-like cuts'), must mutually determine each other. We build upon the\nrecently developed framework of space-time deterministic graph rewriting, in\norder to formalise this notion of space-time reversibility, and henceforth\nstudy reversible graph rewriting. We establish sufficient, local conditions on\nthe rewrite rules so that they be space-time reversible. We provide an example\nfeaturing time dilation, in the spirit of general relativity.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9002\u7528\u4e8e\u56fe\u91cd\u5199\u7cfb\u7edf\u7684\u65b0\u578b\u65f6\u7a7a\u53ef\u9006\u6027\u7406\u8bba\uff0c\u5f62\u5f0f\u5316\u4e86\u76f8\u5173\u6761\u4ef6\u5e76\u7ed9\u51fa\u53ef\u5b9e\u73b0\u7684\u4f8b\u5b50\u3002", "motivation": "\u4f20\u7edf\u6570\u5b66\u8981\u6c42\u52a8\u529b\u7cfb\u7edf\u7684\u53ef\u9006\u6027\u5fc5\u987b\u662f\u53cc\u5c04\uff0c\u4f46\u56fe\u91cd\u5199\u64cd\u4f5c\u56e0\u5176\u975e\u786e\u5b9a\u6027\u96be\u4ee5\u6ee1\u8db3\u6b64\u8981\u6c42\u3002\u4f5c\u8005\u53d7\u7269\u7406\u4e2d\u65f6\u7a7a\u53ef\u9006\u7684\u7075\u611f\uff0c\u8bd5\u56fe\u6784\u5efa\u4e00\u79cd\u66f4\u7075\u6d3b\u3001\u66f4\u5b9e\u9645\u7684\u53ef\u9006\u6027\u5b9a\u4e49\u548c\u5206\u6790\u3002", "method": "\u91c7\u7528\u4e86\u7a7a\u95f4-\u65f6\u95f4\u786e\u5b9a\u6027\u56fe\u91cd\u5199\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e86\u65f6\u7a7a\u53ef\u9006\u6027\u6761\u4ef6\uff0c\u5e76\u901a\u8fc7\u5177\u4f53\u793a\u4f8b\u8fdb\u884c\u4e86\u8bba\u8bc1\u3002", "result": "\u8bc1\u660e\u4e86\u4e00\u7ec4\u8db3\u591f\u7684\u5c40\u90e8\u5224\u636e\u53ef\u4fdd\u8bc1\u56fe\u91cd\u5199\u6ee1\u8db3\u65f6\u7a7a\u53ef\u9006\u6027\uff0c\u5e76\u901a\u8fc7\u8003\u8651\u7c7b\u4f3c\u5e7f\u4e49\u76f8\u5bf9\u8bba\u4e2d\u7684\u65f6\u95f4\u81a8\u80c0\u60c5\u5f62\u7ed9\u51fa\u4e86\u5e94\u7528\u5b9e\u4f8b\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u56fe\u91cd\u5199\u7684\u65f6\u7a7a\u53ef\u9006\u6027\u65b0\u6846\u67b6\uff0c\u5e76\u8bc1\u660e\u4e86\u67d0\u4e9b\u5c40\u90e8\u89c4\u5219\u53ef\u4ee5\u5b9e\u73b0\u8fd9\u4e00\u53ef\u9006\u6027\u3002"}}
{"id": "2510.04079", "categories": ["cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2510.04079", "abs": "https://arxiv.org/abs/2510.04079", "authors": ["Siddharth Bhandari", "Abhishek Khetan"], "title": "Vector Trifference", "comment": "18 pages", "summary": "We investigate a geometric generalization of trifference, a concept\nintroduced by Elias in 1988 in the study of zero-error channel capacity. In the\ndiscrete setting, a code C \\subseteq {0,1,2}^n is trifferent if for any three\ndistinct codewords x, y, z in C, there exists a coordinate i in [n] where x_i,\ny_i, z_i are all distinct. Determining the maximum size of such codes remains a\ncentral open problem; the classical upper bound |C| \\leq 2 * (3/2)^n, proved\nvia a simple pruning argument, has resisted significant improvement.\n  Motivated by the search for new techniques, and in line with vectorial\nextensions of other classical combinatorial notions, we introduce the concept\nof vector trifferent codes. Consider C \\subseteq (S^2)^n, where the alphabet is\nthe unit sphere S^2 = { v in R^3 : ||v|| = 1 }. We say C is vector trifferent\nif for any three distinct x, y, z in C, there is an index i where the vectors\nx_i, y_i, z_i are mutually orthogonal. A direct reduction of the vectorial\nproblem to the discrete setting appears infeasible, making it difficult to\nreplicate Elias's pruning argument. Nevertheless, we develop a new method to\nestablish the upper bound |C| \\leq (sqrt(2) + o(1)) * (3/2)^n.\n  Interestingly, our approach, when adapted back to the discrete setting,\nyields a polynomial improvement to Elias's bound: |C| \\lesssim n^(-1/4) *\n(3/2)^n. This improvement arises from a technique that parallels, but is not\nidentical to, a recent method of the authors, though it still falls short of\nthe sharper n^(-2/5) factor obtained there. We also generalize the concept of\nvector trifferent codes to richer alphabets and prove a vectorial version of\nthe Fredman-Komlos theorem (1984) for general k-separating codes.", "AI": {"tldr": "\u672c\u6587\u5c06trifferent\u7801\u6982\u5ff5\u63a8\u5e7f\u5230\u5411\u91cf\u573a\u666f\u5e76\u63d0\u51fa\u65b0\u4e0a\u754c\uff0c\u901a\u8fc7\u65b0\u65b9\u6cd5\u5728\u79bb\u6563\u60c5\u5f62\u4e0b\u4e5f\u53d6\u5f97\u4e86\u5bf9\u7ecf\u5178\u4e0a\u754c\u7684\u6539\u8fdb\uff0c\u5e76\u8fdb\u4e00\u6b65\u63a8\u5e7f\u81f3\u66f4\u5e7f\u6cdb\u7684\u7ec4\u5408\u7801\u7406\u8bba\u3002", "motivation": "\u5c1d\u8bd5\u6253\u7834\u957f\u671f\u672a\u6539\u8fdb\u7684trifferent\u7801\u6700\u5927\u89c4\u6a21\u4e0a\u754c\uff08Elias\u63d0\u51fa\u7684 |C| \u2264 2*(3/2)^n\uff09\uff0c\u5e76\u5e0c\u671b\u901a\u8fc7\u5411\u91cf\u5316\u65b9\u6cd5\u83b7\u5f97\u65b0\u7684\u7406\u8bba\u7a81\u7834\uff0c\u540c\u65f6\u7c7b\u6bd4\u4e8e\u5176\u4ed6\u7ec4\u5408\u95ee\u9898\u7684\u5411\u91cf\u63a8\u5e7f\u3002", "method": "\u6784\u9020\u5411\u91cftrifferent\u7801\uff08\u5c06\u7801\u5b57\u89c6\u4e3a\u5355\u4f4d\u7403\u9762\u4e0a\u7684\u5411\u91cf\uff09\uff0c\u5e76\u4f7f\u7528\u65b0\u7684\u6280\u672f\u5bf9\u5176\u6700\u5927\u7801\u5b57\u6570\u505a\u4e0a\u754c\u5206\u6790\uff1b\u8be5\u65b9\u6cd5\u8fd8\u53ef\u9006\u5411\u5e94\u7528\u4e8e\u79bb\u6563\u578btrifferent\u7801\uff0c\u4ece\u800c\u6539\u8fdbElias\u7684\u4e0a\u754c\u3002", "result": "\u8bc1\u660e\u4e86\u5411\u91cftrifferent\u7801\u7684\u6700\u5927\u89c4\u6a21\u4e0a\u754c\u4e3a (sqrt(2)+o(1))*(3/2)^n\uff1b\u5728\u79bb\u6563\u573a\u666f\u4e0b\u5229\u7528\u65b0\u65b9\u6cd5\u5c06\u7ecf\u5178\u4e0a\u754c\u6539\u8fdb\u4e3a |C| \u2272 n^{-1/4}*(3/2)^n\u3002\u5e76\u63a8\u5e7f\u5230\u66f4\u4e30\u5bcc\u5b57\u6bcd\u8868\u4ee5\u53ca\u7ed9\u51faFredman-Komlos\u5b9a\u7406\u7684\u5411\u91cf\u5316\u7248\u672c\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5411\u91cf\u578btrifferent\u7801\uff0c\u5e76\u5bf9\u5176\u6700\u5927\u7801\u5b57\u6570\u7ed9\u51fa\u4e86\u65b0\u7684\u4e0a\u754c\uff0c\u540c\u65f6\u65b9\u6cd5\u4e5f\u5728\u79bb\u6563\u573a\u666f\u4e0b\u6539\u8fdb\u4e86\u7ecf\u5178\u4e0a\u754c\u3002"}}
{"id": "2510.04621", "categories": ["cs.DM", "cs.DS"], "pdf": "https://arxiv.org/pdf/2510.04621", "abs": "https://arxiv.org/abs/2510.04621", "authors": ["Fabien de Montgolfier", "Renaud Torfs"], "title": "Maximum Biclique for Star 1,2,3 -free and Bounded Bimodularwidth Twin-free Bipartite Graphs $\\star$", "comment": null, "summary": "There are three usual definitions of a maximum bipartite clique (biclique) in\na bipartite graph\\,: either maximizing the number of vertices, or of edges, or\nfinding a maximum balanced biclique. The first problem can be solved in\npolynomial time, the last ones are NP-complete. Here we show how these three\nproblems may be efficiently solved for two classes of bipartite graphs:\nStar123-free twin-free graphs, and bounded bimodularwidth twin-free graphs, a\nclass that may be defined using bimodular decomposition. Our computation\nrequires O(n^2) time and requires a decomposition is provided, which takes\nrespectively O(n + m) and O(mn^3) time.", "AI": {"tldr": "\u5bf9\u4e8e\u5e38\u89c1\u7684\u4e09\u79cd\u6700\u5927\u4e8c\u5206\u56e2\u95ee\u9898\uff0c\u867d\u7136\u666e\u904d\u60c5\u51b5\u4e0b\u6c42\u89e3\u56f0\u96be\uff0c\u4f46\u82e5\u9650\u5b9a\u5728\u67d0\u4e9b\u7279\u6b8a\u4e8c\u5206\u56fe\u7ed3\u6784\uff08\u5982Star123-free twin-free\u548c\u6709\u754cbimodularwidth twin-free\u56fe\uff09\uff0c\u5219\u53ef\u4ee5\u501f\u52a9\u56fe\u7684\u5206\u89e3\u6280\u672f\u5b9e\u73b0\u591a\u9879\u5f0f\u65f6\u95f4\u9ad8\u6548\u6c42\u89e3\u3002", "motivation": "\u5728\u4e8c\u5206\u56fe\u4e2d\uff0c\u6700\u5927\u4e8c\u5206\u56e2\uff08biclique\uff09\u7684\u5b9a\u4e49\u901a\u5e38\u6709\u4e09\u79cd\uff1a\u6700\u5927\u5316\u9876\u70b9\u6570\u3001\u6700\u5927\u5316\u8fb9\u6570\uff0c\u4ee5\u53ca\u5bfb\u627e\u6700\u5927\u5e73\u8861\u4e8c\u5206\u56e2\u3002\u9664\u4e86\u6700\u5927\u9876\u70b9\u6570\u7684\u6c42\u89e3\u6709\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u5916\uff0c\u5176\u4ed6\u4e24\u79cd\u90fd\u662fNP\u5b8c\u5168\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u7279\u5b9a\u7c7b\u578b\u7684\u4e8c\u5206\u56fe\uff08\u5982Star123-free twin-free\u56fe\u548c\u6709\u754c\u4e8c\u6a21\u5bbd\u7684twin-free\u56fe\uff09\u4e0b\uff0c\u8fd9\u4e09\u79cd\u6700\u5927\u4e8c\u5206\u56e2\u95ee\u9898\u80fd\u5426\u88ab\u9ad8\u6548\u6c42\u89e3\u3002", "method": "\u4f5c\u8005\u5229\u7528\u4e8c\u5206\u56fe\u7684\u5206\u89e3\u65b9\u6cd5\uff08\u5982bimodular decomposition\uff09\uff0c\u9488\u5bf9Star123-free twin-free\u56fe\u4e0e\u6709\u754cbimodularwidth twin-free\u56fe\uff0c\u901a\u8fc7\u5bf9\u7ed9\u5b9a\u7684\u5206\u89e3\u7ed3\u6784\u8fdb\u884c\u5206\u6790\uff0c\u63d0\u51fa\u4e86O(n^2)\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u9ad8\u6548\u7b97\u6cd5\u3002\u800c\u6240\u9700\u5206\u89e3\u7684\u9884\u5904\u7406\u5206\u522b\u53ef\u5728O(n+m)\u548cO(mn^3)\u65f6\u95f4\u5185\u5b8c\u6210\u3002", "result": "\u5728Star123-free twin-free\u56fe\u548c\u6709\u754cbimodularwidth twin-free\u56fe\u4e24\u7c7b\u4e8c\u5206\u56fe\u4e0a\uff0c\u4e09\u79cd\u6700\u5927\u4e8c\u5206\u56e2\u76f8\u5173\u7684NP-\u56f0\u96be\u95ee\u9898\u90fd\u53ef\u901a\u8fc7\u5229\u7528\u56fe\u5206\u89e3\u6280\u672f\u5728\u591a\u9879\u5f0f\u65f6\u95f4\uff08O(n^2)\uff09\u5185\u6709\u6548\u6c42\u89e3\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u548c\u5229\u7528bimodular decomposition\u7b49\u7ed3\u6784\u7279\u6027\uff0c\u90e8\u5206\u901a\u5e38NP-\u56f0\u96be\u7684\u6700\u5927\u4e8c\u5206\u56e2\u95ee\u9898\u5728\u7279\u5b9a\u4e8c\u5206\u56fe\u7c7b\u522b\u4e0b\u53d8\u5f97\u9ad8\u6548\u53ef\u89e3\uff0c\u663e\u8457\u6269\u5c55\u4e86\u76f8\u5173\u95ee\u9898\u7684\u53ef\u5904\u7406\u8303\u56f4\u3002"}}
{"id": "2510.04936", "categories": ["cs.DM", "cs.CG", "cs.SI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.04936", "abs": "https://arxiv.org/abs/2510.04936", "authors": ["Abigail Hickok", "Andrew J. Blumberg"], "title": "Discrete scalar curvature as a weighted sum of Ollivier-Ricci curvatures", "comment": "30 pages, 2 figures", "summary": "We study the relationship between discrete analogues of Ricci and scalar\ncurvature that are defined for point clouds and graphs. In the discrete\nsetting, Ricci curvature is replaced by Ollivier-Ricci curvature. Scalar\ncurvature can be computed as the trace of Ricci curvature for a Riemannian\nmanifold; this motivates a new definition of a scalar version of Ollivier-Ricci\ncurvature. We show that our definition converges to scalar curvature for\nnearest neighbor graphs obtained by sampling from a manifold. We also prove\nsome new results about the convergence of Ollivier-Ricci curvature to Ricci\ncurvature.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9002\u7528\u4e8e\u70b9\u4e91\u548c\u56fe\u7684\u4e00\u79cd\u65b0\u7684\u79bb\u6563\u6807\u91cf\u66f2\u7387\u5b9a\u4e49\uff0c\u5e76\u8bc1\u660e\u5176\u5728\u6700\u8fd1\u90bb\u56fe\u91c7\u6837\u60c5\u51b5\u4e0b\u80fd\u6536\u655b\u81f3\u7ecf\u5178\u6d41\u5f62\u7684\u6807\u91cf\u66f2\u7387\uff1b\u540c\u65f6\u6539\u8fdb\u4e86Ollivier-Ricci\u66f2\u7387\u7684\u6536\u655b\u6027\u7406\u8bba\u3002", "motivation": "\u63a2\u7d22\u79bb\u6563\u66f2\u7387\uff08\u7528\u4e8e\u70b9\u4e91\u548c\u56fe\uff09\u7684\u5b9a\u4e49\u53ca\u5176\u4e0e\u7ecf\u5178\u6d41\u5f62\u66f2\u7387\u7684\u5173\u7cfb\uff0c\u63a8\u52a8\u6d41\u5f62\u7406\u8bba\u4e0e\u6570\u636e\u5206\u6790\u9886\u57df\u7684\u7ed3\u5408\u3002", "method": "\u91c7\u7528Ollivier-Ricci\u66f2\u7387\u4f5c\u4e3a\u79bb\u6563Ricci\u66f2\u7387\u7684\u66ff\u4ee3\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u65b0\u7684Ollivier-Ricci\u6807\u91cf\u66f2\u7387\u5b9a\u4e49\u3002\u901a\u8fc7\u5206\u6790\u6700\u8fd1\u90bb\u56fe\uff08\u7531\u6d41\u5f62\u91c7\u6837\u83b7\u5f97\uff09\u9a8c\u8bc1\u5176\u6536\u655b\u6027\uff0c\u5e76\u7406\u8bba\u8bc1\u660eOllivier-Ricci\u66f2\u7387\u5411Ricci\u66f2\u7387\u7684\u6536\u655b\u6027\u3002", "result": "\u63d0\u51fa\u5e76\u8bc1\u660e\u4e86\u4e00\u79cd\u79bb\u6563\u6807\u91cf\u66f2\u7387\u5b9a\u4e49\uff0c\u8be5\u5b9a\u4e49\u5728\u7531\u6d41\u5f62\u91c7\u6837\u5f97\u5230\u7684\u6700\u8fd1\u90bb\u56fe\u4e0a\u6536\u655b\u5230\u8fde\u7eed\u60c5\u5f62\u4e0b\u7684\u6807\u91cf\u66f2\u7387\u3002\u540c\u65f6\uff0c\u6539\u8fdb\u548c\u6269\u5c55\u4e86Ollivier-Ricci\u66f2\u7387\u6536\u655b\u5230\u7ecf\u5178Ricci\u66f2\u7387\u7684\u7406\u8bba\u7ed3\u679c\u3002", "conclusion": "\u79bb\u6563\u66f2\u7387\uff08Ollivier-Ricci\u53ca\u5176\u6807\u91cf\u7248\u672c\uff09\u5728\u5408\u9002\u79bb\u6563\u7ed3\u6784\u4e2d\u80fd\u591f\u5f88\u597d\u5730\u903c\u8fd1\u7ecf\u5178\u6d41\u5f62\u4e0a\u7684\u66f2\u7387\uff0c\u6709\u52a9\u4e8e\u6570\u636e\u9a71\u52a8\u4e0b\u6d41\u5f62\u6027\u8d28\u7684\u5206\u6790\u3002"}}
{"id": "2510.03461", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.03461", "abs": "https://arxiv.org/abs/2510.03461", "authors": ["Sanjay Malakar", "Michael D. Ernst", "Martin Kellogg", "Manu Sridharan"], "title": "Repairing Leaks in Resource Wrappers", "comment": null, "summary": "A resource leak occurs when a program fails to release a finite resource like\na socket, file descriptor or database connection. While sound static analysis\ntools can detect all leaks, automatically repairing them remains challenging.\nPrior work took the output of a detection tool and attempted to repair only\nleaks from a hard-coded list of library resource types. That approach limits\nthe scope of repairable leaks: real-world code uses resource wrappers that\nstore a resource in a field and must themselves be closed. This paper makes\nfour key contributions to improve resource leak repair in the presence of\nwrappers. (1) It integrates inference of resource management specifications\ninto the repair pipeline, enabling extant fixing approaches to reason about\nwrappers. (2) It transforms programs into variants that are easier to analyze,\nmaking inference, detection, and fixing tools more effective; for instance, it\nmakes detection tools report problems closer to the root cause, often in a\nclient of a resource wrapper rather than within the wrapper class itself. (3) A\nnovel field containment analysis reasons about resource lifetimes, enabling\nrepair of more leaks involving resources stored in fields. (4) It introduces a\nnew repair pattern and more precise reasoning to better handle resources stored\nin non-final fields. Prior work fixed 41% of resource leak warnings in the NJR\nbenchmark suite; our implementation Arodnap fixes 68%.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u89c4\u8303\u63a8\u65ad\u3001\u4ee3\u7801\u53d8\u6362\u548c\u65b0\u7684\u5206\u6790\u4fee\u590d\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u8d44\u6e90\u5305\u88c5\u60c5\u5883\u4e0b\u7684\u81ea\u52a8\u8d44\u6e90\u6cc4\u6f0f\u4fee\u590d\u80fd\u529b\uff0c\u4fee\u590d\u7387\u753141%\u63d0\u5347\u523068%\u3002", "motivation": "\u8d44\u6e90\u6cc4\u6f0f\uff08\u5982\u5957\u63a5\u5b57\u3001\u6587\u4ef6\u63cf\u8ff0\u7b26\u6216\u6570\u636e\u5e93\u8fde\u63a5\u672a\u91ca\u653e\uff09\u5e38\u5e38\u5f15\u53d1\u8f6f\u4ef6\u7f3a\u9677\u3002\u4ee5\u5f80\u81ea\u52a8\u4fee\u590d\u65b9\u6cd5\u53ea\u8986\u76d6\u5c11\u91cf\u786c\u7f16\u7801\u5e93\u8d44\u6e90\u7c7b\u578b\uff0c\u65e0\u6cd5\u5904\u7406\u5b9e\u9645\u4ee3\u7801\u4e2d\u5404\u79cd\u8d44\u6e90\u5c01\u88c5\u5668\uff0c\u4ece\u800c\u9650\u5236\u4e86\u4fee\u590d\u8303\u56f4\u3002\u89e3\u51b3\u5b9e\u9645\u5f00\u53d1\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u7684\u8d44\u6e90\u5305\u88c5\u5668\u5e26\u6765\u7684\u590d\u6742\u6027\uff0c\u662f\u672c\u5de5\u4f5c\u7684\u52a8\u673a\u3002", "method": "\uff081\uff09\u5c06\u8d44\u6e90\u7ba1\u7406\u89c4\u8303\u63a8\u65ad\u8fc7\u7a0b\u96c6\u6210\u81f3\u4fee\u590d\u6d41\u6c34\u7ebf\u4e2d\uff0c\u4f7f\u73b0\u6709\u4fee\u590d\u65b9\u6cd5\u53ef\u5904\u7406\u8d44\u6e90\u5c01\u88c5\u5668\uff1b\uff082\uff09\u901a\u8fc7\u4ee3\u7801\u53d8\u6362\u51cf\u5c11\u5206\u6790\u96be\u5ea6\uff0c\u4f7f\u63a8\u65ad\u3001\u68c0\u6d4b\u548c\u4fee\u590d\u5de5\u5177\u80fd\u66f4\u6709\u6548\u5730\u5b9a\u4f4d\u6cc4\u6f0f\u6839\u56e0\uff0c\u95ee\u9898\u62a5\u544a\u66f4\u9760\u8fd1\u5b9e\u9645\u8c03\u7528\u8005\uff1b\uff083\uff09\u5f15\u5165\u5b57\u6bb5\u5305\u5bb9\u5206\u6790\uff0c\u5b9e\u73b0\u57fa\u4e8e\u5b57\u6bb5\u5b58\u50a8\u8d44\u6e90\u65f6\u7684\u751f\u547d\u5468\u671f\u63a8\u65ad\uff0c\u4ece\u800c\u4fee\u590d\u66f4\u591a\u6cc4\u6f0f\uff1b\uff084\uff09\u63d0\u51fa\u65b0\u7684\u4fee\u590d\u6a21\u5f0f\u548c\u7cbe\u786e\u673a\u5236\uff0c\u5c24\u5176\u9488\u5bf9\u8d44\u6e90\u50a8\u5b58\u5728\u975efinal\u5b57\u6bb5\u7684\u573a\u666f\u3002", "result": "\u65b0\u65b9\u6848\u5bf9NJR\u57fa\u51c6\u96c6\u4e2d\u7684\u8d44\u6e90\u6cc4\u6f0f\u8b66\u544a\u4fee\u590d\u7387\u4ece\u4ee5\u5f80\u768441%\u63d0\u5347\u523068%\u3002", "conclusion": "\u6574\u4f53\u6539\u8fdb\u5bf9\u81ea\u52a8\u4fee\u590d\u8d44\u6e90\u6cc4\u6f0f\u80fd\u529b\u6709\u663e\u8457\u63d0\u5347\uff0c\u80fd\u66f4\u5e7f\u6cdb\u8986\u76d6\u590d\u6742\u7684\u8d44\u6e90\u5c01\u88c5\u5668\uff0c\u63d0\u5347\u5b9e\u7528\u6027\u548c\u68c0\u6d4b\u4fee\u590d\u6548\u679c\u3002"}}
{"id": "2510.03789", "categories": ["cs.LO", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.03789", "abs": "https://arxiv.org/abs/2510.03789", "authors": ["Eridan Domoratskiy", "Dmitrii Kosarev", "Dmitry Boulytchev"], "title": "An Empirical Study of Rational Tree Unification for miniKanren", "comment": null, "summary": "We present a study of unification for rational trees in the context of\nminiKanren. We give the definition of rational trees, specify the unification\nalgorithm and prove some of its properties. We also introduce a number of\nheuristic optimizations and evaluate them for a number of relevant benchmarks.\nFinally we discuss the relations between rational and conventional unification\nalgorithms and possible scenarios of their coexistence in the context of\nrelational programming.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9miniKanren\uff0c\u5b9a\u4e49\u5e76\u4f18\u5316\u4e86\u7406\u6027\u6811\u7684\u7edf\u4e00\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u6027\u8d28\uff0c\u5e76\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u5c55\u793a\u5176\u6709\u6548\u6027\uff0c\u8ba8\u8bba\u4e86\u4e0e\u4f20\u7edf\u7edf\u4e00\u7b97\u6cd5\u7684\u5173\u7cfb\u53ca\u5171\u5b58\u65b9\u6848\u3002", "motivation": "miniKanren\u7b49\u5173\u7cfb\u578b\u7f16\u7a0b\u5bf9\u7406\u6027\u6811\u7edf\u4e00\u7684\u9700\u6c42\uff0c\u63a8\u52a8\u9ad8\u6548\u4e14\u53ef\u8bc1\u660e\u6b63\u786e\u6027\u7684\u7edf\u4e00\u7b97\u6cd5\u7814\u7a76\u3002", "method": "\u5b9a\u4e49\u7406\u6027\u6811\uff0c\u6307\u5b9a\u7edf\u4e00\u7b97\u6cd5\uff0c\u8bc1\u660e\u7b97\u6cd5\u6027\u8d28\uff0c\u5f15\u5165\u542f\u53d1\u5f0f\u4f18\u5316\uff0c\u5e76\u901a\u8fc7\u76f8\u5173\u57fa\u51c6\u6d4b\u8bd5\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u63d0\u51fa\u4e86\u7406\u6027\u6811\u7684\u7edf\u4e00\u7b97\u6cd5\u53ca\u5176\u4f18\u5316\u65b9\u6cd5\uff0c\u5e76\u7ed9\u51fa\u8bc4\u6d4b\u7ed3\u679c\uff0c\u5206\u6790\u4e86\u4e0e\u4f20\u7edf\u7edf\u4e00\u7b97\u6cd5\u7684\u5173\u7cfb\u53ca\u5171\u5b58\u573a\u666f\u3002", "conclusion": "\u7406\u6027\u6811\u7684\u7edf\u4e00\u7b97\u6cd5\u53ef\u4ee5\u6709\u6548\u5e94\u7528\u4e8eminiKanren\uff0c\u5e76\u4e14\u4e0e\u4f20\u7edf\u7edf\u4e00\u7b97\u6cd5\u53ef\u5728\u5173\u7cfb\u578b\u7f16\u7a0b\u4e2d\u5171\u5b58\u3002"}}
{"id": "2510.03315", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03315", "abs": "https://arxiv.org/abs/2510.03315", "authors": ["Alex Gibson"], "title": "Decomposing Attention To Find Context-Sensitive Neurons", "comment": "10 pages, 7 figures. Submitted to the Mechanistic Interpretability\n  Workshop at NeurIPS 2025", "summary": "We study transformer language models, analyzing attention heads whose\nattention patterns are spread out, and whose attention scores depend weakly on\ncontent. We argue that the softmax denominators of these heads are stable when\nthe underlying token distribution is fixed. By sampling softmax denominators\nfrom a \"calibration text\", we can combine together the outputs of multiple such\nstable heads in the first layer of GPT2-Small, approximating their combined\noutput by a linear summary of the surrounding text. This approximation enables\na procedure where from the weights alone - and a single calibration text - we\ncan uncover hundreds of first layer neurons that respond to high-level\ncontextual properties of the surrounding text, including neurons that didn't\nactivate on the calibration text.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u6ce8\u610f\u529b\u5934softmax\u5206\u6bcd\u7a33\u5b9a\u6027\uff0c\u4ece\u6743\u91cd\u548c\u6821\u51c6\u6587\u672c\u4e2d\u53d1\u73b0\u3001\u89e3\u91ca\u7b2c\u4e00\u5c42\u795e\u7ecf\u5143\u8bed\u5883\u54cd\u5e94\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u6df1\u5165\u7406\u89e3GPT2\u7ed3\u6784\u3002", "motivation": "\u7814\u7a76\u53d8\u538b\u5668\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u5173\u6ce8\u90a3\u4e9b\u6ce8\u610f\u529b\u5206\u5e03\u8f83\u4e3a\u5206\u6563\u3001\u4e14\u6210\u7ee9\u5bf9\u5185\u5bb9\u4f9d\u8d56\u8f83\u5f31\u7684\u6ce8\u610f\u529b\u5934\uff0c\u8fd9\u6709\u52a9\u4e8e\u7406\u89e3\u6a21\u578b\u5185\u90e8\u673a\u5236\u3002", "method": "\u5206\u6790GPT2-Small\u7b2c\u4e00\u5c42\u7684attention head\uff0c\u901a\u8fc7\u91c7\u6837softmax\u5206\u6bcd\u7684\u65b9\u5f0f\uff0c\u7ed3\u5408\u201c\u6821\u51c6\u6587\u672c\u201d\u7a33\u5b9a\u8fd9\u4e9b\u5934\u7684\u8f93\u51fa\uff0c\u5e76\u7528\u7ebf\u6027\u65b9\u6cd5\u8fd1\u4f3c\u5730\u603b\u7ed3\u6587\u672c\u4e0a\u4e0b\u6587\u3002", "result": "\u53ef\u4ee5\u4ec5\u51ed\u6a21\u578b\u6743\u91cd\u548c\u4e00\u6bb5\u6821\u51c6\u6587\u672c\uff0c\u63ed\u793a\u51fa\u5927\u91cf\u5bf9\u9ad8\u7ea7\u8bed\u5883\u5c5e\u6027\u654f\u611f\u7684\u4e00\u5c42\u795e\u7ecf\u5143\uff0c\u5305\u62ec\u6821\u51c6\u6587\u672c\u4e2d\u672a\u6fc0\u6d3b\u7684\u795e\u7ecf\u5143\u3002", "conclusion": "\u672c\u6587\u65b9\u6cd5\u4e3a\u6316\u6398\u548c\u89e3\u91catransformer\u6a21\u578b\u9690\u5c42\u4e2d\u8d1f\u8d23\u4e0a\u4e0b\u6587\u8bed\u4e49\u7684\u795e\u7ecf\u5143\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2510.03415", "categories": ["cs.PL", "cs.AI", "cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.03415", "abs": "https://arxiv.org/abs/2510.03415", "authors": ["Aditya Thimmaiah", "Jiyang Zhang", "Jayanth Srinivasa", "Junyi Jessy Li", "Milos Gligoric"], "title": "PLSEMANTICSBENCH: Large Language Models As Programming Language Interpreters", "comment": null, "summary": "As large language models (LLMs) excel at code reasoning, a natural question\narises: can an LLM execute programs (i.e., act as an interpreter) purely based\non a programming language's formal semantics? If so, it will enable rapid\nprototyping of new programming languages and language features. We study this\nquestion using the imperative language IMP (a subset of C), formalized via\nsmall-step operational semantics (SOS) and rewriting-based operational\nsemantics (K-semantics). We introduce three evaluation sets-Human-Written,\nLLM-Translated, and Fuzzer- Generated-whose difficulty is controlled by\ncode-complexity metrics spanning the size, control-flow, and data-flow axes.\nGiven a program and its semantics formalized with SOS/K-semantics, models are\nevaluated on three tasks ranging from coarse to fine: (1) final-state\nprediction, (2) semantic rule prediction, and (3) execution trace prediction.\nTo distinguish pretraining memorization from semantic competence, we define two\nnonstandard semantics obtained through systematic mutations of the standard\nrules. Across strong code/reasoning LLMs, performance drops under nonstandard\nsemantics despite high performance under the standard one. We further find that\n(i) there are patterns to different model failures, (ii) most reasoning models\nperform exceptionally well on coarse grained tasks involving reasoning about\nhighly complex programs often containing nested loop depths beyond five, and\nsurprisingly, (iii) providing formal semantics helps on simple programs but\noften hurts on more complex ones. Overall, the results show a promise that LLMs\ncould serve as programming language interpreters, but points to the lack of\ntheir robust semantics understanding. We release the benchmark and the\nsupporting code at https://github.com/EngineeringSoftware/PLSemanticsBench.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86LLM\u80fd\u5426\u57fa\u4e8e\u5f62\u5f0f\u8bed\u4e49\u89e3\u91ca\u7a0b\u5e8f\uff0c\u53d1\u73b0LLM\u6709\u6f5c\u529b\u7528\u4e8e\u8bed\u8a00\u89e3\u91ca\uff0c\u4f46\u5bf9\u8bed\u4e49\u89c4\u5219\u7684\u7406\u89e3\u5c1a\u4e0d\u7262\u9760\uff0c\u5c24\u5176\u5728\u975e\u5e38\u89c4\u60c5\u51b5\u4e0b\u6027\u80fd\u4e0b\u964d\uff0c\u4e14\u5f62\u5f0f\u8bed\u4e49\u5bf9\u590d\u6742\u4efb\u52a1\u53ef\u80fd\u6709\u53cd\u6548\u679c\u3002\u63d0\u4f9b\u4e86\u516c\u5f00\u57fa\u51c6\u4e0e\u4ee3\u7801\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4ee3\u7801\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f5c\u8005\u63d0\u51fa\u4e00\u4e2a\u81ea\u7136\u95ee\u9898\uff1a\u80fd\u5426\u8ba9LLM\u4ec5\u4f9d\u636e\u7f16\u7a0b\u8bed\u8a00\u7684\u5f62\u5f0f\u8bed\u4e49\u6765\u6267\u884c\u7a0b\u5e8f\uff0c\u5373\u5145\u5f53\u89e3\u91ca\u5668\uff1f\u8fd9\u5c06\u6709\u52a9\u4e8e\u5feb\u901f\u539f\u578b\u5f00\u53d1\u65b0\u7f16\u7a0b\u8bed\u8a00\u548c\u8bed\u8a00\u7279\u6027\u3002", "method": "\u4f5c\u8005\u4ee5\u547d\u4ee4\u5f0f\u8bed\u8a00IMP\uff08C\u8bed\u8a00\u7684\u5b50\u96c6\uff09\u4e3a\u7814\u7a76\u5bf9\u8c61\uff0c\u901a\u8fc7\u5c0f\u6b65\u64cd\u4f5c\u8bed\u4e49\uff08SOS\uff09\u548c\u57fa\u4e8e\u91cd\u5199\u7684\u64cd\u4f5c\u8bed\u4e49\uff08K-semantics\uff09\u8fdb\u884c\u5f62\u5f0f\u5316\u3002\u8bbe\u8ba1\u4e86\u4e09\u7ec4\u8bc4\u6d4b\u96c6\uff08\u4eba\u5de5\u7f16\u5199\u3001LLM\u7ffb\u8bd1\u3001Fuzzer\u751f\u6210\uff09\uff0c\u901a\u8fc7\u4ee3\u7801\u590d\u6742\u5ea6\u8fdb\u884c\u96be\u5ea6\u63a7\u5236\u3002\u8bc4\u6d4b\u5305\u62ec\u4e09\u7c7b\u4efb\u52a1\uff1a\u6700\u7ec8\u72b6\u6001\u9884\u6d4b\u3001\u8bed\u4e49\u89c4\u5219\u9884\u6d4b\u3001\u6267\u884c\u8f68\u8ff9\u9884\u6d4b\u3002\u4e3a\u533a\u5206\u9884\u8bad\u7ec3\u8bb0\u5fc6\u548c\u8bed\u4e49\u80fd\u529b\uff0c\u4f5c\u8005\u8fd8\u5b9a\u4e49\u4e86\u4e24\u79cd\u975e\u5e38\u89c4\u8bed\u4e49\u89c4\u5219\u3002", "result": "\u53d1\u73b0\u5f3a\u4ee3\u7801\u63a8\u7406\u7684LLM\u5728\u975e\u5e38\u89c4\u8bed\u4e49\u4e0b\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u4e14\u4e0d\u540c\u6a21\u578b\u5931\u8d25\u6709\u89c4\u5f8b\u3002\u5927\u591a\u6570\u6a21\u578b\u80fd\u5728\u590d\u6742\u7a0b\u5e8f\u7684\u7c97\u7c92\u5ea6\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5982\u4e94\u5c42\u4ee5\u4e0a\u5d4c\u5957\u5faa\u73af\uff0c\u4f46\u63d0\u4f9b\u5f62\u5f0f\u8bed\u4e49\u53ea\u5bf9\u7b80\u5355\u7a0b\u5e8f\u6709\u5e2e\u52a9\uff0c\u5bf9\u590d\u6742\u7a0b\u5e8f\u53cd\u800c\u6709\u8d1f\u9762\u5f71\u54cd\u3002", "conclusion": "LLM\u6709\u671b\u5145\u5f53\u7f16\u7a0b\u8bed\u8a00\u7684\u89e3\u91ca\u5668\uff0c\u4f46\u5728\u8bed\u4e49\u7406\u89e3\u4e0a\u4ecd\u4e0d\u5065\u58ee\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u63d0\u5347\u3002\u4f5c\u8005\u5df2\u516c\u5f00\u57fa\u51c6\u53ca\u4ee3\u7801\u3002"}}
{"id": "2510.03941", "categories": ["cs.LO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2510.03941", "abs": "https://arxiv.org/abs/2510.03941", "authors": ["Amrita Suresh", "Nobuko Yoshida"], "title": "Unreliability in Practical Subclasses of Communicating Systems", "comment": "A full version of the same titled paper published in the FSTTCS'25\n  proceeding", "summary": "Systems of communicating automata are prominent models for peer-to-peer\nmessage-passing over unbounded channels, but in the general scenario, most\nverification properties are undecidable. To address this issue, two decidable\nsubclasses, Realisable with Synchronous Communication (RSC) and k-Multiparty\nCompatibility} (k-MC), were proposed in the literature, with corresponding\nverification tools developed and applied in practice. Unfortunately, both RSC\nand k-MC are not resilient under failures: (1) their decidability relies on the\nassumption of perfect channels and (2) most standard protocols do not satisfy\nRSC or k-MC under failures. To address these limitations, this paper studies\nthe resilience of RSC and k-MC under two distinct failure models: interference\nand crash-stop failures. For interference, we relax the conditions of RSC and\nk-MC and prove that the inclusions of these relaxed properties remain decidable\nunder interference, preserving their known complexity bounds. We then propose a\nnovel crash-handling communicating system that captures wider behaviours than\nexisting multiparty session types (MPST) with crash-stop failures. We study a\ntranslation of MPST with crash-stop failures into this system integrating RSC\nand k-MC properties, and establish their decidability results. Finally, by\nverifying representative protocols from the literature using RSC and k-MC tools\nextended to interferences, we evaluate the relaxed systems and demonstrate\ntheir resilience.", "AI": {"tldr": "\u8bba\u6587\u9488\u5bf9\u901a\u8baf\u81ea\u52a8\u673a\u7684\u4e24\u79cd\u6545\u969c\u573a\u666f\uff08\u5e72\u6270\u3001\u5d29\u6e83\uff09\u63d0\u51fa\u4e86\u653e\u5bbd\u548c\u6269\u5c55\uff0c\u4f7f\u4e24\u7c7b\u91cd\u8981\u53ef\u5224\u5b9a\u6027\u5c5e\u6027\uff08RSC\u3001k-MC\uff09\u5728\u6545\u969c\u4e0b\u4ecd\u5177\u97e7\u6027\u4e0e\u53ef\u7528\u6027\uff0c\u5e76\u901a\u8fc7\u5de5\u5177\u9a8c\u8bc1\u4ee3\u8868\u534f\u8bae\uff0c\u8bc1\u660e\u5176\u5b9e\u7528\u4ef7\u503c\u3002", "motivation": "\u73b0\u6709\u901a\u8baf\u81ea\u52a8\u673a\u7cfb\u7edf\u5bf9\u4e8e\u70b9\u5bf9\u70b9\u6d88\u606f\u4f20\u9012\u5177\u6709\u5f3a\u5927\u5efa\u6a21\u80fd\u529b\uff0c\u4f46\u4e00\u822c\u60c5\u51b5\u4e0b\u5927\u90e8\u5206\u9a8c\u8bc1\u5c5e\u6027\u90fd\u4e0d\u53ef\u5224\u5b9a\u3002\u867d\u7136\u63d0\u51fa\u4e86\u53ef\u5224\u5b9a\u7684RSC\u4e0ek-MC\u4e24\u4e2a\u5b50\u7c7b\u5e76\u5f00\u53d1\u4e86\u76f8\u5e94\u5de5\u5177\uff0c\u4f46\u8fd9\u4e24\u8005\u5728\u9047\u5230\u73b0\u5b9e\u4e2d\u7684\u5e72\u6270\u548c\u5d29\u6e83\u7b49\u6545\u969c\u65f6\u5e76\u4e0d\u5177\u5907\u97e7\u6027\u3002", "method": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86RSC\u548ck-MC\u5728\u4e24\u79cd\u6545\u969c\u60c5\u666f\u4e0b\uff08\u5e72\u6270\u4e0e\u5d29\u6e83\u505c\u6b62\uff09\u4e0b\u7684\u97e7\u6027\u3002\u5bf9\u4e8e\u5e72\u6270\uff0c\u4f5c\u8005\u653e\u5bbd\u4e86RSC\u548ck-MC\u7684\u6761\u4ef6\uff0c\u5e76\u8bc1\u660e\u5728\u5e72\u6270\u60c5\u51b5\u4e0b\u5176\u5224\u5b9a\u6027\u4ecd\u6210\u7acb\u4e14\u590d\u6742\u5ea6\u672a\u53d8\u3002\u9488\u5bf9\u5d29\u6e83\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u5d29\u6e83\u5904\u7406\u901a\u8baf\u7cfb\u7edf\uff0c\u6bd4\u73b0\u6709MPST\u6a21\u578b\u6db5\u76d6\u66f4\u5e7f\u884c\u4e3a\uff0c\u5e76\u7814\u7a76\u4e86\u5c06\u5e26\u5d29\u6e83\u7684MPST\u8f6c\u8bd1\u5230\u8be5\u7cfb\u7edf\u4e0eRSC\u3001k-MC\u5c5e\u6027\u7ed3\u5408\u7684\u53ef\u5224\u5b9a\u6027\u3002", "result": "\uff081\uff09\u653e\u5bbd\u5e72\u6270\u4e0b\u7684RSC\u4e0ek-MC\u53ef\u5224\u5b9a\u6027\u548c\u590d\u6742\u5ea6\u5f97\u5230\u4fdd\u6301\uff1b\uff082\uff09\u63d0\u51fa\u65b0\u7684\u7cfb\u7edf\u5bf9\u5d29\u6e83\u505c\u6b62\u66f4\u5177\u8868\u73b0\u529b\uff0c\u4e14\u76f8\u5173\u53ef\u5224\u5b9a\u6027\u7ed3\u679c\u6210\u7acb\uff1b\uff083\uff09\u901a\u8fc7\u7528\u6269\u5c55\u5de5\u5177\u9a8c\u8bc1\u4ee3\u8868\u6027\u534f\u8bae\uff0c\u5c55\u793a\u4e86\u8fd9\u4e9b\u7cfb\u7edf\u5728\u6545\u969c\u60c5\u51b5\u4e0b\u7684\u97e7\u6027\u3002", "conclusion": "\u901a\u8fc7\u65b9\u6cd5\u521b\u65b0\uff0c\u672c\u6587\u4f7fRSC\u548ck-MC\u6a21\u578b\u5728\u591a\u79cd\u6545\u969c\u4e0b\u5177\u5907\u66f4\u597d\u7684\u97e7\u6027\uff0c\u5e76\u4e14\u76f8\u5173\u6027\u8d28\u4fdd\u6301\u53ef\u5224\u5b9a\u6027\uff0c\u4e3a\u534f\u8bae\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u7406\u8bba\u548c\u5de5\u5177\u652f\u6301\u3002"}}
{"id": "2510.03463", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03463", "abs": "https://arxiv.org/abs/2510.03463", "authors": ["Vali Tawosi", "Keshav Ramani", "Salwa Alamir", "Xiaomo Liu"], "title": "ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering Framework", "comment": null, "summary": "Multi-agent Large Language Model (LLM) systems have been leading the way in\napplied LLM research across a number of fields. One notable area is software\ndevelopment, where researchers have advanced the automation of code\nimplementation, code testing, code maintenance, inter alia, using LLM agents.\nHowever, software development is a multifaceted environment that extends beyond\njust code. As such, a successful LLM system must factor in multiple stages of\nthe software development life-cycle (SDLC). In this paper, we propose a vision\nfor ALMAS, an Autonomous LLM-based Multi-Agent Software Engineering framework,\nwhich follows the above SDLC philosophy such that it may work within an agile\nsoftware development team to perform several tasks end-to-end. ALMAS aligns its\nagents with agile roles, and can be used in a modular fashion to seamlessly\nintegrate with human developers and their development environment. We showcase\nthe progress towards ALMAS through our published works and a use case\ndemonstrating the framework, where ALMAS is able to seamlessly generate an\napplication and add a new feature.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faALMAS\u6846\u67b6\uff0c\u5c06LLM\u667a\u80fd\u4f53\u5e94\u7528\u4e8e\u8f6f\u4ef6\u5f00\u53d1\u5168\u751f\u547d\u5468\u671f\uff0c\u4e0e\u654f\u6377\u6d41\u7a0b\u548c\u4eba\u7c7b\u5f00\u53d1\u8005\u65e0\u7f1d\u534f\u4f5c\uff0c\u5df2\u901a\u8fc7\u6848\u4f8b\u9a8c\u8bc1\u5176\u7aef\u5230\u7aef\u81ea\u52a8\u5316\u5f00\u53d1\u80fd\u529b\uff0c\u672a\u6765\u5177\u5907\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u5df2\u5728\u591a\u4e2a\u9886\u57df\u63a8\u52a8\u5e94\u7528\u7814\u7a76\uff0c\u5c24\u5176\u662f\u5728\u8f6f\u4ef6\u5f00\u53d1\u9886\u57df\u81ea\u52a8\u5316\u5404\u7c7b\u4efb\u52a1\u3002\u9274\u4e8e\u8f6f\u4ef6\u5f00\u53d1\u4e0d\u4ec5\u4ec5\u662f\u7f16\u7801\uff0c\u8fd8\u6d89\u53ca\u6574\u4e2a\u8f6f\u4ef6\u751f\u547d\u5468\u671f\uff0c\u5f53\u524d\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u3002", "method": "\u63d0\u51faALMAS\u6846\u67b6\uff1a\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u8f6f\u4ef6\u5de5\u7a0b\u7cfb\u7edf\uff0c\u5c06\u667a\u80fd\u4f53\u4e0e\u654f\u6377\u5f00\u53d1\u89d2\u8272\u5bf9\u9f50\uff0c\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u53ef\u4e0e\u4eba\u7c7b\u5f00\u53d1\u8005\u53ca\u73af\u5883\u65e0\u7f1d\u96c6\u6210\uff0c\u652f\u6301SDLC\u591a\u4e2a\u9636\u6bb5\u3002", "result": "\u901a\u8fc7\u5df2\u6709\u53d1\u8868\u6210\u679c\u548c\u4f7f\u7528\u6848\u4f8b\u8bc1\u660e\uff0cALMAS\u6846\u67b6\u80fd\u591f\u7aef\u5230\u7aef\u751f\u6210\u5e94\u7528\u3001\u6dfb\u52a0\u65b0\u529f\u80fd\uff0c\u5b9e\u73b0\u667a\u80fd\u4f53\u534f\u52a9\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\u3002", "conclusion": "ALMAS\u5c55\u793a\u4e86\u57fa\u4e8eLLM\u591a\u667a\u80fd\u4f53\u7684\u81ea\u52a8\u5316\u8f6f\u4ef6\u5de5\u7a0b\u843d\u5730\u80fd\u529b\uff0c\u80fd\u6709\u6548\u63d0\u5347\u654f\u6377\u5f00\u53d1\u56e2\u961f\u7684\u6548\u7387\u548c\u534f\u4f5c\uff0c\u5177\u5907\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2510.03822", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2510.03822", "abs": "https://arxiv.org/abs/2510.03822", "authors": ["Balder ten Cate", "Jesse Comer"], "title": "Interpolation in First-Order Logic", "comment": null, "summary": "In this chapter we give a basic overview of known results regarding Craig\ninterpolation for first-order logic as well as for fragments of first-order\nlogic. Our aim is to provide an entry point into the literature on\ninterpolation theorems for first-order logic and fragments of first-order\nlogic, and their applications. In particular, we cover a range of known\nrefinements of the Craig interpolation theorem, we discuss several important\napplications of interpolation in logic and computer science, we review known\nresults about interpolation for important syntactic fragments of first-order\nlogic, and we discuss the problem of computing interpolants.", "AI": {"tldr": "\u8be5\u6587\u7efc\u8ff0\u4e86\u4e00\u9636\u903b\u8f91\u53ca\u5176\u7247\u6bb5\u4e2d\u7684Craig\u63d2\u503c\u5b9a\u7406\u53ca\u5e94\u7528\uff0c\u5e2e\u52a9\u8bfb\u8005\u5feb\u901f\u4e86\u89e3\u5176\u7406\u8bba\u53d1\u5c55\u3001\u5b9e\u9645\u5e94\u7528\u548c\u8ba1\u7b97\u65b9\u6cd5\u3002", "motivation": "Craig\u63d2\u503c\u5b9a\u7406\u53ca\u5176\u6269\u5c55\u5728\u903b\u8f91\u5b66\u4e0e\u8ba1\u7b97\u673a\u79d1\u5b66\u4e2d\u6709\u91cd\u8981\u5e94\u7528\uff0c\u4f46\u76f8\u5173\u7406\u8bba\u548c\u6280\u672f\u5206\u5e03\u5728\u4f17\u591a\u6587\u732e\u4e2d\uff0c\u9700\u8981\u4e00\u4e2a\u6613\u4e8e\u5165\u95e8\u7684\u603b\u7ed3\u548c\u5bfc\u822a\u3002", "method": "\u901a\u8fc7\u6587\u732e\u56de\u987e\uff0c\u7cfb\u7edf\u68b3\u7406\u4e86Craig\u63d2\u503c\u5b9a\u7406\u7684\u5404\u79cd\u7cbe\u7ec6\u5316\u7ed3\u679c\u3001\u4e3b\u8981\u5e94\u7528\u548c\u5bf9\u4e8e\u4e00\u9636\u903b\u8f91\u5404\u8bed\u6cd5\u7247\u6bb5\u7684\u76f8\u5173\u63d2\u503c\u6027\u7814\u7a76\uff0c\u4ee5\u53ca\u63d2\u503c\u5b50\u7684\u8ba1\u7b97\u95ee\u9898\u3002", "result": "\u8bba\u6587\u603b\u7ed3\u4e86\u5df2\u6709\u7684Craig\u63d2\u503c\u5b9a\u7406\u76f8\u5173\u7406\u8bba\u3001\u5e94\u7528\u5b9e\u4f8b\u3001\u5728\u4e00\u9636\u903b\u8f91\u53ca\u5176\u5404\u91cd\u8981\u7247\u6bb5\u4e2d\u7684\u7ed3\u679c\uff0c\u4ee5\u53ca\u8ba1\u7b97\u63d2\u503c\u5b50\u9762\u4e34\u7684\u96be\u9898\u548c\u5df2\u6709\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u4e3a\u4e00\u9636\u903b\u8f91\u53ca\u5176\u7247\u6bb5\u4e2d\u7684Craig\u63d2\u503c\u5b9a\u7406\u53ca\u5176\u5e94\u7528\u63d0\u4f9b\u4e86\u7efc\u8ff0\u548c\u6587\u732e\u5165\u95e8\u3002"}}
{"id": "2510.03323", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03323", "abs": "https://arxiv.org/abs/2510.03323", "authors": ["Ge Chang", "Jinbo Su", "Jiacheng Liu", "Pengfei Yang", "Yuhao Shang", "Huiwen Zheng", "Hongli Ma", "Yan Liang", "Yuanchun Li", "Yunxin Liu"], "title": "Graph-S3: Enhancing Agentic textual Graph Retrieval with Synthetic Stepwise Supervision", "comment": null, "summary": "A significant portion of real-world data is inherently represented as textual\ngraphs, and integrating these graphs into large language models (LLMs) is\npromising to enable complex graph-based question answering. However, a key\nchallenge in LLM-based textual graph QA systems lies in graph retrieval, i.e.,\nhow to retrieve relevant content from large graphs that is sufficiently\ninformative while remaining compact for the LLM context. Existing retrievers\nsuffer from poor performance since they either rely on shallow embedding\nsimilarity or employ interactive retrieving policies that demand excessive data\nlabeling and training cost. To address these issues, we present Graph-$S^3$, an\nagentic textual graph reasoning framework that employs an LLM-based retriever\ntrained with synthetic stepwise supervision. Instead of rewarding the agent\nbased on the final answers, which may lead to sparse and unstable training\nsignals, we propose to closely evaluate each step of the retriever based on\noffline-extracted golden subgraphs. Our main techniques include a data\nsynthesis pipeline to extract the golden subgraphs for reward generation and a\ntwo-stage training scheme to learn the interactive graph exploration policy\nbased on the synthesized rewards. Based on extensive experiments on three\ncommon datasets in comparison with seven strong baselines, our approach\nachieves an average improvement of 8.1\\% in accuracy and 9.7\\% in F$_1$ score.\nThe advantage is even higher in more complicated multi-hop reasoning tasks. Our\ncode will be open-sourced.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LLM\u548c\u5408\u6210\u76d1\u7763\u7684\u6587\u672c\u56fe\u95ee\u7b54\u68c0\u7d22\u6846\u67b6Graph-$S^3$\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6570\u636e\u5408\u6210\u548c\u5206\u9636\u6bb5\u8bad\u7ec3\u5b9e\u73b0\u4e86\u5bf9\u590d\u6742\u56fe\u95ee\u7b54\u7684\u9ad8\u6548\u548c\u9ad8\u8d28\u91cf\u68c0\u7d22\uff0c\u5b9e\u9a8c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dLLM\u5728\u57fa\u4e8e\u6587\u672c\u56fe\u7684\u95ee\u7b54\u4e2d\uff0c\u96be\u4ee5\u9ad8\u6548\u68c0\u7d22\u4fe1\u606f\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u52a3\u8d28\u7684\u5d4c\u5165\u76f8\u4f3c\u5ea6\uff0c\u8981\u4e48\u9700\u8981\u5927\u91cf\u6570\u636e\u6807\u6ce8\u548c\u8bad\u7ec3\u8d44\u6e90\uff0c\u6027\u80fd\u53d7\u9650\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2aLLM\u9a71\u52a8\u7684\u667a\u80fd\u68c0\u7d22\u5668\uff0c\u7ed3\u5408\u6570\u636e\u5408\u6210\u7ba1\u9053\u7528\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u5956\u52b1\u5b50\u56fe\uff0c\u4ee5\u53ca\u5206\u9636\u6bb5\u8bad\u7ec3\u673a\u5236\u7528\u4e8e\u4f18\u5316\u56fe\u63a2\u7d22\u7b56\u7565\u3002\u6bcf\u4e00\u6b65\u5956\u52b1\u6765\u81ea\u79bb\u7ebf\u63d0\u53d6\u7684\u9ec4\u91d1\u5b50\u56fe\u800c\u975e\u6700\u7ec8\u7b54\u6848\u3002", "result": "\u5728\u4e09\u4e2a\u4e3b\u6d41\u6570\u636e\u96c6\u4e0e\u4e03\u4e2a\u5148\u8fdb\u65b9\u6cd5\u5bf9\u6bd4\uff0cGraph-$S^3$\u5e73\u5747\u63d0\u5347\u51c6\u786e\u73878.1%\uff0cF$_1$\u5206\u6570\u63d0\u53479.7%\u3002\u591a\u8df3\u590d\u6742\u63a8\u7406\u4e2d\u4f18\u52bf\u66f4\u663e\u8457\u3002\u4ee3\u7801\u5c06\u5f00\u6e90\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8eLLM\u7684\u6587\u672c\u56fe\u68c0\u7d22\u548c\u63a8\u7406\u6846\u67b6Graph-$S^3$\uff0c\u901a\u8fc7\u5408\u6210\u7684\u6b65\u9aa4\u7ea7\u76d1\u7763\u65b9\u5f0f\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u56fe\u95ee\u9898\u7684\u95ee\u7b54\u80fd\u529b\u3002"}}
{"id": "2510.04049", "categories": ["cs.PL", "03B70, 68T27, 68T30"], "pdf": "https://arxiv.org/pdf/2510.04049", "abs": "https://arxiv.org/abs/2510.04049", "authors": ["Xiangyu Guo", "Ajay Bansal"], "title": "Encoding Numeric Computations and Infusing Heuristic Knowledge Using Integrity Constraints in stableKanren", "comment": "12 pages, 2 figures, ICFP '25 The miniKanren and Relational\n  Programming Workshop", "summary": "This paper presents examples of using integrity constraints in stableKanren\nto encode numeric computations for problem solving. Then, we use one of the\nexamples to introduce multiple ways to infuse heuristic knowledge and reduce\nsolving time. stableKanren is an extension of miniKanren that supports normal\nlogic programs under stable model semantics. stableKanren further supports\nnumeric computation by constructing a constraint store for integrity\nconstraints. There are three ways to extend a relational programming language\nwith numeric computations: relational number representation, grounding numbers\nto symbols, and constraint store construction. We demonstrate that the numeric\ncomputations in stableKanren have a straightforward numerical representation\ncompared to relational number representations. More importantly, stableKanren\nbalances symbolic and numeric computation in relational programming by avoiding\nthe grounding of all numbers to symbols. Lastly, it also has simpler syntax\ncompared to other constraint store construction approaches. stableKanren\nsupports combinatorial search problem solving under a declarative generate and\ntest paradigm. Such a paradigm generates all possible combinations of solutions\nto the problem, then applies a set of constraints to prune out the unwanted\nsolutions. We demonstrate that different approaches to writing programs or\nqueries affect the solver's performance in the SEND+MORE=MONEY puzzle. The\nperformance gradually improves as more heuristic knowledge is infused through\nthe programs or queries. Additionally, we show how to use an external function\nto achieve a hybrid solution.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86stableKanren\u5728\u6570\u503c\u8ba1\u7b97\u4e0e\u95ee\u9898\u6c42\u89e3\u4e2d\u7684\u4f18\u52bf\uff0c\u8bc1\u660e\u5176\u5728\u7b26\u53f7\u4e0e\u6570\u503c\u8ba1\u7b97\u5e73\u8861\u3001\u7ea6\u675f\u8868\u8fbe\u7b80\u5316\u53ca\u542f\u53d1\u5f0f\u4f18\u5316\u65b9\u9762\u5177\u6709\u663e\u8457\u63d0\u5347\uff0c\u5c24\u5176\u662f\u5728\u7ec4\u5408\u641c\u7d22\u7c7b\u95ee\u9898\uff08\u5982SEND+MORE=MONEY\uff09\u4e2d\u5176\u6027\u80fd\u5927\u5e45\u589e\u5f3a\u3002", "motivation": "\u5f53\u524d\u5173\u7cfb\u578b\u7f16\u7a0b\u8bed\u8a00\u5728\u6570\u503c\u8ba1\u7b97\u7684\u8868\u8fbe\u548c\u6027\u80fd\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u6709\u5fc5\u8981\u4f18\u5316\u6570\u503c\u8ba1\u7b97\u7684\u8868\u8fbe\u65b9\u5f0f\u548c\u63d0\u5347\u95ee\u9898\u6c42\u89e3\u6548\u7387\u3002", "method": "\u63d0\u51fa\u5e76\u5206\u6790 stableKanren\u5728\u6570\u503c\u8ba1\u7b97\u95ee\u9898\u4e0a\u7684\u5e94\u7528\uff0c\u5e76\u901a\u8fc7\u5177\u4f53\u4f8b\u5b50\uff08\u5982SEND+MORE=MONEY\u8c1c\u9898\uff09\u63a2\u8ba8\u591a\u79cd\u6ce8\u5165\u542f\u53d1\u5f0f\u77e5\u8bc6\u4e0e\u5b9e\u73b0\u6c42\u89e3\u65f6\u95f4\u4f18\u5316\u7684\u65b9\u6cd5\u3002\u6bd4\u8f83 stableKanren \u4e0e\u4f20\u7edf\u6570\u503c\u5173\u7cfb\u578b\u8868\u8fbe\u7684\u4e0d\u540c\u65b9\u5f0f\uff0c\u5206\u6790\u5176\u7ea6\u675f\u5b58\u50a8\u673a\u5236\u548c\u8bed\u6cd5\u7b80\u5316\u3002", "result": "stableKanren\u63d0\u4f9b\u4e86\u7b80\u6d01\u76f4\u89c2\u7684\u6570\u503c\u8868\u8fbe\u65b9\u5f0f\uff0c\u5408\u7406\u5e73\u8861\u4e86\u7b26\u53f7\u548c\u6570\u503c\u8ba1\u7b97\uff0c\u907f\u514d\u4e86\u5168\u90e8\u6570\u503c\u7b26\u53f7\u5316\uff0c\u5e76\u5177\u5907\u6bd4\u7ea6\u675f\u5b58\u50a8\u4f20\u7edf\u65b9\u6cd5\u66f4\u7b80\u5355\u7684\u8bed\u6cd5\u3002\u901a\u8fc7\u542f\u53d1\u5f0f\u77e5\u8bc6\u4e0d\u65ad\u6ce8\u5165\uff0cSEND+MORE=MONEY\u95ee\u9898\u7684\u6c42\u89e3\u6548\u7387\u5f97\u4ee5\u63d0\u5347\u3002\u5916\u90e8\u51fd\u6570\u7684\u4f7f\u7528\u8fdb\u4e00\u6b65\u5b9e\u73b0\u6df7\u5408\u5f0f\u6c42\u89e3\uff0c\u589e\u5f3a\u4e86\u7075\u6d3b\u6027\u3002", "conclusion": "stableKanren\u5728\u5173\u7cfb\u578b\u7f16\u7a0b\u8303\u5f0f\u4e0b\uff0c\u901a\u8fc7\u7ea6\u675f\u5b58\u50a8\u548c\u91cd\u65b0\u8bbe\u8ba1\u6570\u503c\u8868\u8fbe\uff0c\u6709\u6548\u63d0\u5347\u4e86\u7ec4\u5408\u641c\u7d22\u4e0e\u6570\u503c\u8ba1\u7b97\u7684\u6548\u7387\u4e0e\u7075\u6d3b\u6027\uff0c\u5728 declarative generate and test \u95ee\u9898\u6c42\u89e3\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u6027\u80fd\u548c\u66f4\u6613\u7528\u8bed\u6cd5\uff0c\u8bc1\u660e\u4e86\u542f\u53d1\u5f0f\u77e5\u8bc6\u4e0e\u5916\u90e8\u51fd\u6570\u6df7\u5408\u673a\u5236\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.03474", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.03474", "abs": "https://arxiv.org/abs/2510.03474", "authors": ["Nadeeshan De Silva", "Martin Kellogg", "Oscar Chaparro"], "title": "Relative Code Comprehensibility Prediction", "comment": null, "summary": "Automatically predicting how difficult it is for humans to understand a code\nsnippet can assist developers in tasks like deciding when and where to\nrefactor. Despite many proposed code comprehensibility metrics, studies have\nshown they often correlate poorly with actual measurements of human\ncomprehensibility. This has motivated the use of machine learning models to\npredict human comprehensibility directly from code, but these models have also\nshown limited accuracy.\n  We argue that model inaccuracy stems from inherent noise in human\ncomprehensibility data, which confuses models trained to predict it directly.\nTo address this, we propose training models to predict the relative\ncomprehensibility of two code snippets - that is, predicting which snippet a\nhuman would find easier to understand without predicting each snippet's\ncomprehensibility in isolation. This mitigates noise in predicting 'absolute'\ncomprehensibility measurements, but is still useful for downstream\nsoftware-engineering tasks like assessing whether refactoring improves or\nhinders comprehensibility.\n  We conducted a study to assess and compare the effectiveness of absolute and\nrelative code comprehensibility prediction via machine learning. We used a\ndataset of 150 Java code snippets and 12.5k human comprehensibility\nmeasurements from prior user studies, comparing the models' performance with\nnaive baselines (eg 'always predict the majority class'). Our findings indicate\nthat absolute comprehensibility models improve over the baselines by at most\n33.4% and frequently underperform. In contrast, relative comprehensibility\nmodels are substantially better, with average improvements of 137.8% and 74.7%\nfor snippet-wise and developer-wise prediction, respectively. These results\nsuggest that relative comprehensibility models learn more effectively from the\ndata, supporting their practical applicability for downstream SE tasks.", "AI": {"tldr": "\u9488\u5bf9\u4ee3\u7801\u53ef\u7406\u89e3\u6027\u9884\u6d4b\u4efb\u52a1\uff0c\u672c\u6587\u63d0\u51fa\u7528\u76f8\u5bf9\u9884\u6d4b\uff08\u5224\u65ad\u54ea\u6bb5\u4ee3\u7801\u66f4\u5bb9\u6613\u7406\u89e3\uff09\u66ff\u4ee3\u7edd\u5bf9\u9884\u6d4b\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u4eba\u7c7b\u6807\u6ce8\u6570\u636e\u4e0a\u5b9e\u9a8c\u8bc1\u660e\uff0c\u524d\u8005\u6a21\u578b\u6548\u679c\u663e\u8457\u4f18\u4e8e\u540e\u8005\uff0c\u80fd\u66f4\u597d\u5e94\u7528\u4e8e\u5b9e\u9645\u8f6f\u4ef6\u5de5\u7a0b\u573a\u666f\u3002", "motivation": "\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\uff0c\u7406\u89e3\u4ee3\u7801\u6bb5\u7684\u96be\u6613\u7a0b\u5ea6\u5bf9\u5f00\u53d1\u8005\u8fdb\u884c\u91cd\u6784\u51b3\u7b56\u7b49\u4efb\u52a1\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u4f20\u7edf\u65b9\u6cd5\u57fa\u4e8e\u4ee3\u7801\u53ef\u7406\u89e3\u6027\u6307\u6807\uff0c\u4f46\u8fd9\u4e9b\u6307\u6807\u4e0e\u771f\u5b9e\u7684\u4eba\u5de5\u6d4b\u91cf\u76f8\u5173\u6027\u8f83\u4f4e\uff0c\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u76f4\u63a5\u9884\u6d4b\u4ee3\u7801\u53ef\u7406\u89e3\u6027\u4f46\u51c6\u786e\u7387\u6709\u9650\u3002\u4f5c\u8005\u8ba4\u4e3a\u95ee\u9898\u5173\u952e\u5728\u4e8e\u4eba\u5de5\u6570\u636e\u672c\u8eab\u5b58\u5728\u566a\u58f0\uff0c\u5f71\u54cd\u4e86\u6a21\u578b\u5bf9\u201c\u7edd\u5bf9\u201d\u53ef\u7406\u89e3\u6027\u7684\u9884\u6d4b\u6548\u679c\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u91c7\u7528\u201c\u76f8\u5bf9\u53ef\u7406\u89e3\u6027\u9884\u6d4b\u201d\u6a21\u578b\uff0c\u5373\u8bad\u7ec3\u6a21\u578b\u5224\u65ad\u4e24\u6bb5\u4ee3\u7801\u4e2d\u54ea\u4e00\u6bb5\u66f4\u5bb9\u6613\u88ab\u4eba\u7406\u89e3\uff0c\u907f\u514d\u76f4\u63a5\u9884\u6d4b\u6bcf\u6bb5\u4ee3\u7801\u7684\u7edd\u5bf9\u53ef\u7406\u89e3\u6027\u3002\u901a\u8fc7\u7528\u771f\u5b9e\u7684\u53ef\u7406\u89e3\u6027\u6d4b\u91cf\u6570\u636e\uff08\u5171150\u4e2aJava\u4ee3\u7801\u7247\u6bb5\u548c12500\u4e2a\u4eba\u7c7b\u6d4b\u91cf\u8bb0\u5f55\uff09\uff0c\u6bd4\u8f83\u7edd\u5bf9\u9884\u6d4b\u548c\u76f8\u5bf9\u9884\u6d4b\u6a21\u578b\uff0c\u5e76\u4ee5\u6734\u7d20\u57fa\u7ebf\u4f5c\u4e3a\u5bf9\u7167\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u7edd\u5bf9\u53ef\u7406\u89e3\u6027\u6a21\u578b\u76f8\u6bd4\u57fa\u7ebf\u6700\u591a\u63d0\u9ad833.4%\uff0c\u4e14\u5e38\u5e38\u8868\u73b0\u4e0d\u4f73\uff1b\u800c\u76f8\u5bf9\u53ef\u7406\u89e3\u6027\u6a21\u578b\u5728\u7247\u6bb5\u5c42\u9762\u548c\u5f00\u53d1\u8005\u5c42\u9762\u5206\u522b\u63d0\u5347\u4e86137.8%\u548c74.7%\u3002\u8fd9\u8bf4\u660e\u76f8\u5bf9\u6a21\u578b\u80fd\u66f4\u6709\u6548\u5730\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\uff0c\u5e76\u66f4\u5177\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u76f8\u5bf9\u53ef\u7406\u89e3\u6027\u9884\u6d4b\u65b9\u6cd5\u7531\u4e8e\u66f4\u597d\u5730\u5e94\u5bf9\u4e86\u4eba\u5de5\u6570\u636e\u4e2d\u7684\u566a\u58f0\uff0c\u5bf9\u4e0b\u6e38\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\uff08\u5982\u8bc4\u4f30\u91cd\u6784\u662f\u5426\u6539\u5584\u4ee3\u7801\u53ef\u7406\u89e3\u6027\uff09\u66f4\u5177\u5b9e\u7528\u610f\u4e49\u3002"}}
{"id": "2510.03384", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03384", "abs": "https://arxiv.org/abs/2510.03384", "authors": ["Arjun Arunasalam", "Madison Pickering", "Z. Berkay Celik", "Blase Ur"], "title": "Implicit Values Embedded in How Humans and LLMs Complete Subjective Everyday Tasks", "comment": null, "summary": "Large language models (LLMs) can underpin AI assistants that help users with\neveryday tasks, such as by making recommendations or performing basic\ncomputation. Despite AI assistants' promise, little is known about the implicit\nvalues these assistants display while completing subjective everyday tasks.\nHumans may consider values like environmentalism, charity, and diversity. To\nwhat extent do LLMs exhibit these values in completing everyday tasks? How do\nthey compare with humans? We answer these questions by auditing how six popular\nLLMs complete 30 everyday tasks, comparing LLMs to each other and to 100 human\ncrowdworkers from the US. We find LLMs often do not align with humans, nor with\nother LLMs, in the implicit values exhibited.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9\u516d\u6b3e LLMs \u53ca\u666e\u901a\u4eba\u7c7b\u5728 30 \u9879\u65e5\u5e38\u4efb\u52a1\u7684\u9690\u6027\u4ef7\u503c\u89c2\u8868\u73b0\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u7ed3\u679c\u53d1\u73b0 LLMs \u5728\u4ef7\u503c\u8868\u8fbe\u65b9\u9762\u4e0e\u4eba\u7c7b\u53ca\u5f7c\u6b64\u4e4b\u95f4\u5747\u6709\u8f83\u5927\u5dee\u5f02\uff0c\u63d0\u793a\u73b0\u6709 AI \u52a9\u624b\u5728\u4e3b\u89c2\u4efb\u52a1\u4e0a\u6709\u5f85\u8fdb\u4e00\u6b65\u5b8c\u5584\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6b63\u5728\u6210\u4e3a AI \u52a9\u624b\u7684\u6838\u5fc3\uff0c\u80fd\u591f\u5e2e\u52a9\u7528\u6237\u5b8c\u6210\u65e5\u5e38\u4efb\u52a1\uff0c\u4f46\u6211\u4eec\u5bf9\u8fd9\u4e9b\u52a9\u624b\u5728\u4e3b\u89c2\u6027\u4efb\u52a1\u4e2d\u4f53\u73b0\u7684\u9690\u6027\u4ef7\u503c\u89c2\u4e86\u89e3\u751a\u5c11\uff0c\u5982\u73af\u5883\u4fdd\u62a4\u3001\u6148\u5584\u548c\u591a\u6837\u6027\u7b49\u3002\u63a2\u7a76 LLMs \u5728\u6267\u884c\u65e5\u5e38\u4efb\u52a1\u65f6\u662f\u5426\u4f53\u73b0\u8fd9\u4e9b\u4ef7\u503c\uff0c\u4ee5\u53ca\u4e0e\u4eba\u7c7b\u76f8\u6bd4\u8868\u73b0\u5982\u4f55\uff0c\u662f\u672c\u7814\u7a76\u7684\u6838\u5fc3\u52a8\u673a\u3002", "method": "\u4f5c\u8005\u5bf9\u516d\u4e2a\u4e3b\u6d41 LLMs \u5728\u5b8c\u6210 30 \u9879\u65e5\u5e38\u4efb\u52a1\u8fc7\u7a0b\u4e2d\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u5ba1\u67e5\uff0c\u5e76\u5c06\u5b83\u4eec\u7684\u7ed3\u679c\u4e0e 100 \u540d\u7f8e\u56fd\u4f17\u5305\u5de5\u4eba\uff08\u4eba\u7c7b\uff09\u8fdb\u884c\u4e86\u5bf9\u6bd4\u3002\u5206\u6790\u5185\u5bb9\u805a\u7126\u4e8e\u9690\u6027\u4ef7\u503c\u89c2\u7684\u4f53\u73b0\u4e0e\u5dee\u5f02\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cLLMs \u5728\u4f53\u73b0\u9690\u6027\u4ef7\u503c\u89c2\u65b9\u9762\uff0c\u5f80\u5f80\u65e2\u4e0d\u4e0e\u4eba\u7c7b\u4e00\u81f4\uff0c\u4e5f\u4e0d\u4e0e\u5176\u4ed6 LLMs \u4fdd\u6301\u4e00\u81f4\uff0c\u8bf4\u660e\u73b0\u6709 LLMs \u5728\u4e3b\u89c2\u6027\u4efb\u52a1\u4e2d\u7684\u4ef7\u503c\u89c2\u8868\u8fbe\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u76ee\u524d\u6d41\u884c\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e3b\u89c2\u6027\u65e5\u5e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u7684\u9690\u6027\u4ef7\u503c\u89c2\u672a\u80fd\u5f88\u597d\u5730\u4e0e\u4eba\u7c7b\u6216\u5176\u4ed6\u6a21\u578b\u4fdd\u6301\u4e00\u81f4\uff0c\u5bf9 AI \u52a9\u624b\u8fdb\u4e00\u6b65\u4f18\u5316\u548c\u89c4\u8303\u63d0\u51fa\u4e86\u6311\u6218\u3002"}}
{"id": "2510.04890", "categories": ["cs.PL", "cs.AR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.04890", "abs": "https://arxiv.org/abs/2510.04890", "authors": ["Shihan Fang", "Wenxin Zheng"], "title": "Retrofitting Control Flow Graphs in LLVM IR for Auto Vectorization", "comment": null, "summary": "Modern processors increasingly rely on SIMD instruction sets, such as AVX and\nRVV, to significantly enhance parallelism and computational performance.\nHowever, production-ready compilers like LLVM and GCC often fail to fully\nexploit available vectorization opportunities due to disjoint vectorization\npasses and limited extensibility. Although recent attempts in heuristics and\nintermediate representation (IR) designs have attempted to address these\nproblems, efficiently simplifying control flow analysis and accurately\nidentifying vectorization opportunities remain challenging tasks.\n  To address these issues, we introduce a novel vectorization pipeline\nfeaturing two specialized IR extensions: SIR, which encodes high-level\nstructural information, and VIR, which explicitly represents instruction\ndependencies through data dependency analysis. Leveraging the detailed\ndependency information provided by VIR, we develop a flexible and extensible\nvectorization framework. This approach substantially improves interoperability\nacross vectorization passes and expands the search space for identifying\nisomorphic instructions, ultimately enhancing both the scope and efficiency of\nautomatic vectorization. Experimental evaluations demonstrate that our proposed\nvectorization pipeline achieves significant performance improvements,\ndelivering speedups of up to 53% and 58% compared to LLVM and GCC,\nrespectively.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7ed3\u6784\u548c\u4f9d\u8d56\u4fe1\u606f\u6269\u5c55\u7684\u521b\u65b0\u5411\u91cf\u5316\u6d41\u6c34\u7ebf\uff0c\u5b9e\u73b0\u6bd4\u4e3b\u6d41\u7f16\u8bd1\u5668\u66f4\u5927\u8303\u56f4\u548c\u6548\u7387\u7684\u81ea\u52a8\u5411\u91cf\u5316\uff0c\u6027\u80fd\u6700\u9ad8\u63d0\u5347\u8fbe58%\u3002", "motivation": "\u73b0\u4ee3\u5904\u7406\u5668\u9ad8\u5ea6\u4f9d\u8d56SIMD\u6307\u4ee4\uff08\u5982AVX\u3001RVV\uff09\u63d0\u5347\u5e76\u884c\u53ca\u8ba1\u7b97\u6027\u80fd\uff0c\u4f46\u4e3b\u6d41\u7f16\u8bd1\u5668\uff08\u5982LLVM\u548cGCC\uff09\u7531\u4e8e\u5411\u91cf\u5316\u6d41\u7a0b\u5206\u6563\u548c\u53ef\u6269\u5c55\u6027\u4e0d\u8db3\uff0c\u65e0\u6cd5\u5145\u5206\u6316\u6398\u6240\u6709\u5411\u91cf\u5316\u673a\u4f1a\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u542f\u53d1\u5f0f\u89c4\u5219\u548c\u4e2d\u95f4\u8868\u793a\uff08IR\uff09\u8bbe\u8ba1\u4e0a\u867d\u6709\u63d0\u5347\uff0c\u4f46\u63a7\u5236\u6d41\u5206\u6790\u7b80\u5316\u548c\u7cbe\u786e\u8bc6\u522b\u5411\u91cf\u5316\u673a\u4f1a\u4f9d\u65e7\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u5411\u91cf\u5316\u6d41\u6c34\u7ebf\uff0c\u5305\u542b\u4e24\u79cd\u4e13\u7528IR\u6269\u5c55\uff1aSIR\uff08\u7f16\u7801\u9ad8\u5c42\u6b21\u7ed3\u6784\u4fe1\u606f\uff09\u548cVIR\uff08\u901a\u8fc7\u6570\u636e\u4f9d\u8d56\u6027\u5206\u6790\u660e\u786e\u6307\u4ee4\u4f9d\u8d56\uff09\u3002\u501f\u52a9VIR\u7684\u4f9d\u8d56\u4fe1\u606f\uff0c\u5f00\u53d1\u51fa\u4e86\u7075\u6d3b\u53ef\u6269\u5c55\u7684\u65b0\u578b\u5411\u91cf\u5316\u6846\u67b6\u3002", "result": "\u6240\u63d0\u51fa\u7684\u5411\u91cf\u5316\u6d41\u6c34\u7ebf\u6bd4LLVM\u548cGCC\u5728\u81ea\u52a8\u5411\u91cf\u5316\u7684\u8303\u56f4\u548c\u6548\u7387\u4e0a\u6709\u660e\u663e\u63d0\u5347\u3002", "conclusion": "\u57fa\u4e8eSIR\u548cVIR\u7684\u521b\u65b0\u5411\u91cf\u5316\u6846\u67b6\u80fd\u6781\u5927\u589e\u5f3a\u81ea\u52a8\u5411\u91cf\u5316\u5206\u6790\u80fd\u529b\u548c\u6027\u80fd\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4e0eLLVM\u3001GCC\u76f8\u6bd4\uff0c\u5206\u522b\u5e26\u676553%\u548c58%\u7684\u663e\u8457\u52a0\u901f\u3002"}}
{"id": "2510.03480", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.03480", "abs": "https://arxiv.org/abs/2510.03480", "authors": ["Vali Tawosi", "Salwa Alamir", "Xiaomo Liu", "Manuela Veloso"], "title": "LLM Agents for Automated Dependency Upgrades", "comment": null, "summary": "As a codebase expands over time, its library dependencies can become outdated\nand require updates to maintain innovation and security. However, updating a\nlibrary can introduce breaking changes in the code, necessitating significant\ndeveloper time for maintenance. To address this, we introduce a framework of\nLLM agents to be used in combination with migration documentation to\nautomatically recommend and apply code updates and ensure compatibility with\nnew versions. Our solution can automatically localize updated library usages in\nlive Java codebases and implement recommended fixes in a user-friendly manner.\nThe system architecture consists of multiple key components: a Summary Agent,\nControl Agent, and Code Agent. To validate our approach, we apply the framework\non an industrial use case by which we create three synthetic code repositories\nwith major Upgrade changes and benchmark our approach against state-of-the-art\nmethods. Results show that our approach not only performs upgrades using fewer\ntokens across all cases but also achieves a precision of 71.4%, highlighting\nits efficiency and effectiveness compared to state-of-the-art methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u5347\u7ea7Java\u5e93\u4f9d\u8d56\u7684LLM\u4ee3\u7406\u7cfb\u7edf\uff0c\u5728\u7cbe\u5ea6\u548c\u8d44\u6e90\u6d88\u8017\u65b9\u9762\u4f18\u4e8e\u4e3b\u6d41\u65b9\u6848\uff0c\u53ef\u6709\u6548\u51cf\u8f7b\u5f00\u53d1\u8005\u7ef4\u62a4\u8d1f\u62c5\u3002", "motivation": "\u968f\u7740\u4ee3\u7801\u5e93\u7684\u6269\u5c55\uff0c\u5176\u4f9d\u8d56\u7684\u5e93\u53ef\u80fd\u4f1a\u8fc7\u65f6\uff0c\u9700\u8981\u66f4\u65b0\u4ee5\u4fdd\u8bc1\u521b\u65b0\u548c\u5b89\u5168\u6027\u3002\u7136\u800c\u5e93\u7684\u66f4\u65b0\u53ef\u80fd\u5e26\u6765\u4ee3\u7801\u7684\u4e0d\u517c\u5bb9\uff0c\u7ed9\u5f00\u53d1\u8005\u7ef4\u62a4\u5e26\u6765\u5927\u91cf\u5de5\u4f5c\u91cf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u5957\u7ed3\u5408\u8fc1\u79fb\u6587\u6863\u4f7f\u7528\u7684LLM\u4ee3\u7406\u6846\u67b6\uff0c\u80fd\u591f\u81ea\u52a8\u5b9a\u4f4dJava\u4ee3\u7801\u5e93\u4e2d\u7684\u9700\u8981\u5347\u7ea7\u7684\u5e93\u7528\u6cd5\uff0c\u5e76\u81ea\u52a8\u63a8\u8350\u548c\u5b9e\u73b0\u4ee3\u7801\u4fee\u590d\u3002\u7cfb\u7edf\u67b6\u6784\u5305\u62ecSummary Agent\u3001Control Agent\u548cCode Agent\u591a\u4e2a\u5173\u952e\u7ec4\u4ef6\u3002", "result": "\u5728\u591a\u4e2a\u5408\u6210\u4ee3\u7801\u5e93\u4e0e\u4e3b\u6d41\u65b9\u6cd5\u5bf9\u6bd4\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u5c11\u7684token\u4f7f\u7528\u548c71.4%\u7684\u5347\u7ea7\u7cbe\u5ea6\uff0c\u5c55\u73b0\u51fa\u9ad8\u6548\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u8be5LLM\u4ee3\u7406\u6846\u67b6\u80fd\u591f\u81ea\u52a8\u5316\u5904\u7406\u5e93\u5347\u7ea7\u8fc7\u7a0b\uff0c\u964d\u4f4e\u5f00\u53d1\u8005\u7ef4\u62a4\u6210\u672c\uff0c\u5728\u7cbe\u5ea6\u548c\u8d44\u6e90\u6d88\u8017\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2510.03942", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2510.03942", "abs": "https://arxiv.org/abs/2510.03942", "authors": ["Raven Beutner", "Bernd Finkbeiner"], "title": "On Hyperproperty Verification, Quantifier Alternations, and Games under Partial Information", "comment": "FMCAD 2025", "summary": "Hyperproperties generalize traditional trace properties by relating multiple\nexecution traces rather than reasoning about individual runs in isolation. They\nprovide a unified way to express important requirements such as information\nflow and robustness properties. Temporal logics like HyperLTL capture these\nproperties by explicitly quantifying over executions of a system. However, many\npractically relevant hyperproperties involve quantifier alternations, a feature\nthat poses substantial challenges for automated verification. Complete\nverification methods require a system complementation for each quantifier\nalternation, making it infeasible in practice. A cheaper (but incomplete)\nmethod interprets the verification of a HyperLTL formula as a two-player game\nbetween universal and existential quantifiers. The game-based approach is\nsignificantly cheaper, facilitates interactive proofs, and allows for\neasy-to-check certificates of satisfaction. It is, however, limited to\n$\\forall^*\\exists^*$ properties, leaving important properties out of reach. In\nthis paper, we show that we can use games to verify hyperproperties with\narbitrary quantifier alternations by utilizing multiplayer games under partial\ninformation. While games under partial information are, in general,\nundecidable, we show that our game is played under hierarchical information and\nthus falls in a decidable class of games. We discuss the completeness of the\ngame and study prophecy variables in the setting of partial information.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u73b0\u6709hyperproperties\u81ea\u52a8\u5316\u9a8c\u8bc1\u96be\u4ee5\u5904\u7406\u91cf\u8bcd\u4ea4\u66ff\u7684\u74f6\u9888\uff0c\u63d0\u51fa\u5229\u7528\u591a\u65b9\u90e8\u5206\u4fe1\u606f\u6e38\u620f\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u6269\u5c55\u4e86\u53ef\u9a8c\u8bc1\u7684HyperLTL\u6027\u8d28\u8303\u56f4\uff0c\u4e14\u5728\u5206\u5c42\u4fe1\u606f\u6761\u4ef6\u4e0b\u4fdd\u8bc1\u5224\u5b9a\u6027\u4e0e\u6548\u7387\uff0c\u5bf9\u5b89\u5168\u5206\u6790\u7b49\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u4f20\u7edf\u7684trace\u6027\u8d28\u53ea\u80fd\u9488\u5bf9\u5355\u6b21\u6267\u884c\u8fdb\u884c\u63a8\u7406\uff0c\u65e0\u6cd5\u8868\u8fbe\u6d89\u53ca\u591a\u4e2a\u6267\u884c\u8f68\u8ff9\u4e4b\u95f4\u5173\u7cfb\u7684hyperproperties\uff0c\u800c\u8bb8\u591a\u5b9e\u9645\u7cfb\u7edf\u7684\u5173\u952e\u5b89\u5168\u5c5e\u6027\uff08\u5982\u4fe1\u606f\u6d41\u7b49\uff09\u5c5e\u4e8ehyperproperties\u3002\u73b0\u6709\u57fa\u4e8eHyperLTL\u7b49\u65f6\u5e8f\u903b\u8f91\u7684\u81ea\u52a8\u5316\u9a8c\u8bc1\u65b9\u6cd5\u5bf9\u6d89\u53ca\u91cf\u8bcd\u4ea4\u66ff\u7684\u590d\u6742hyperproperties\u96be\u4ee5\u5904\u7406\uff0c\u5b8c\u6574\u7684\u9a8c\u8bc1\u9700\u7cfb\u7edf\u4e92\u8865\u5316\uff0c\u6bcf\u6b21\u4ea4\u66ff\u90fd\u589e\u52a0\u5de8\u5927\u8ba1\u7b97\u8d1f\u62c5\uff0c\u4f7f\u5f97\u5728\u5b9e\u8df5\u4e2d\u4e0d\u53ef\u884c\uff0c\u56e0\u6b64\u4e9f\u9700\u66f4\u9ad8\u6548\u7684\u9a8c\u8bc1\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5c06hyperproperties\u9a8c\u8bc1\u95ee\u9898\u5efa\u6a21\u4e3a\u591a\u65b9\u90e8\u5206\u4fe1\u606f\u6e38\u620f\uff0c\u6253\u7834\u4e86\u73b0\u6709\u65b9\u6cd5\u5bf9$\forall^*\nexists^*$\u7ed3\u6784\u7684\u9650\u5236\u3002\u901a\u8fc7\u5206\u6790\u8fd9\u4e9b\u591a\u65b9\u6e38\u620f\u5728\u5206\u5c42\u4fe1\u606f\uff08hierarchical information\uff09\u4e0b\u5c5e\u4e8e\u53ef\u5224\u5b9a\u95ee\u9898\uff0c\u5e76\u7ed3\u5408\u9884\u8a00\u53d8\u91cf\uff08prophecy variables\uff09\u6280\u672f\u5206\u6790\u90e8\u5206\u4fe1\u606f\u73af\u5883\u4e0b\u7684\u903b\u8f91\u6027\u8d28\u548c\u65b9\u6cd5\u5b8c\u5907\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u5206\u5c42\u4fe1\u606f\u6761\u4ef6\u4e0b\uff0c\u591a\u65b9\u90e8\u5206\u4fe1\u606f\u6e38\u620f\u662f\u53ef\u5224\u5b9a\u7684\uff0c\u53ef\u4ee5\u652f\u6301\u5177\u6709\u4efb\u610f\u91cf\u8bcd\u4ea4\u66ff\u7684hyperproperties\u81ea\u52a8\u5316\u9a8c\u8bc1\u3002\u5bf9\u6e38\u620f\u65b9\u6cd5\u7684\u5b8c\u5907\u6027\u4e0e\u5b9e\u8df5\u7684\u5c40\u9650\u8fdb\u884c\u8bba\u8bc1\uff0c\u5e76\u5c31\u9884\u8a00\u53d8\u91cf\u5728\u8be5\u6846\u67b6\u4e0b\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u7814\u7a76\u4e0e\u8ba8\u8bba\u3002", "conclusion": "\u901a\u8fc7\u6e38\u620f\u5316\u5efa\u6a21\uff0c\u5728\u81ea\u52a8\u5316\u9a8c\u8bc1\u65b9\u9762\u6269\u5c55\u4e86\u53ef\u5904\u7406\u7684hyperproperties\u7c7b\u522b\uff0c\u8ba9\u5177\u6709\u66f4\u590d\u6742\u91cf\u8bcd\u7ed3\u6784\u7684\u9700\u6c42\u80fd\u591f\u9ad8\u6548\u9a8c\u8bc1\uff0c\u63a8\u8fdb\u4e86\u76f8\u5173\u7406\u8bba\u4e0e\u5b9e\u9645\u5e94\u7528\u8fb9\u754c\u3002"}}
{"id": "2510.03439", "categories": ["cs.CL", "I.2.7; I.6.m"], "pdf": "https://arxiv.org/pdf/2510.03439", "abs": "https://arxiv.org/abs/2510.03439", "authors": ["Brendon Boldt", "David Mortensen"], "title": "Morpheme Induction for Emergent Language", "comment": "Accepted for publication at the 2025 Conference on Empirical Methods\n  in Natural Language Processing; 16 pages, 4 figures", "summary": "We introduce CSAR, an algorithm for inducing morphemes from emergent language\ncorpora of parallel utterances and meanings. It is a greedy algorithm that (1)\nweights morphemes based on mutual information between forms and meanings, (2)\nselects the highest-weighted pair, (3) removes it from the corpus, and (4)\nrepeats the process to induce further morphemes (i.e., Count, Select, Ablate,\nRepeat). The effectiveness of CSAR is first validated on procedurally generated\ndatasets and compared against baselines for related tasks. Second, we validate\nCSAR's performance on human language data to show that the algorithm makes\nreasonable predictions in adjacent domains. Finally, we analyze a handful of\nemergent languages, quantifying linguistic characteristics like degree of\nsynonymy and polysemy.", "AI": {"tldr": "\u63d0\u51faCSAR\u8d2a\u5fc3\u7b97\u6cd5\uff0c\u4ece\u5f62\u5f0f-\u610f\u4e49\u5bf9\u5e94\u7684\u65b0\u5174\u8bed\u8a00\u4e2d\u81ea\u52a8\u5f52\u7eb3\u8bcd\u7d20\uff0c\u6548\u679c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u80fd\u91cf\u5316\u8bed\u8a00\u5b66\u7279\u5f81\u3002", "motivation": "\u5728\u65b0\u5174\u8bed\u8a00\u6216\u4eba\u5de5\u751f\u6210\u8bed\u8a00\u4e2d\uff0c\u81ea\u52a8\u5f52\u7eb3\u51fa\u8bed\u7d20\u7684\u80fd\u529b\u5bf9\u7406\u89e3\u8bed\u8a00\u7ed3\u6784\u548c\u6784\u8bcd\u8fc7\u7a0b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u8fd9\u79cd\u573a\u666f\u4e0b\u6548\u679c\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8d2a\u5fc3\u7b97\u6cd5CSAR\uff08Count, Select, Ablate, Repeat\uff09\uff0c\u57fa\u4e8e\u8bcd\u5f62\u4e0e\u610f\u4e49\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u5bf9\u8bcd\u7d20\u52a0\u6743\uff0c\u4e0d\u65ad\u9009\u53d6\u6700\u9ad8\u52a0\u6743\u5bf9\u3001\u79fb\u9664\u5e76\u91cd\u590d\u8be5\u8fc7\u7a0b\uff1b\u5e76\u901a\u8fc7\u5408\u6210\u6570\u636e\u96c6\u548c\u771f\u5b9e\u8bed\u8a00\u6570\u636e\u96c6\u8fdb\u884c\u9a8c\u8bc1\u548c\u6bd4\u8f83\u3002", "result": "CSAR\u5728\u7a0b\u5e8f\u751f\u6210\u7684\u6570\u636e\u96c6\u4ee5\u53ca\u4eba\u7c7b\u8bed\u8a00\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6709\u6548\uff0c\u8868\u73b0\u4f18\u4e8e\u76f8\u5173\u57fa\u7ebf\uff0c\u5e76\u80fd\u7528\u6765\u91cf\u5316\u65b0\u5174\u8bed\u8a00\u7684\u540c\u4e49\u6027\u3001\u4ee5\u53ca\u591a\u4e49\u6027\u7b49\u8bed\u8a00\u5b66\u7279\u5f81\u3002", "conclusion": "CSAR\u7b97\u6cd5\u80fd\u6709\u6548\u4ece\u65b0\u5174\u8bed\u8a00\u8bed\u6599\u4e2d\u5f52\u7eb3\u8bcd\u7d20\uff0c\u5e76\u5728\u5408\u6210\u548c\u4eba\u7c7b\u8bed\u8a00\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u5408\u7406\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u4e5f\u80fd\u91cf\u5316\u8bf8\u5982\u540c\u4e49\u6027\u548c\u591a\u4e49\u6027\u7b49\u8bed\u8a00\u7279\u5f81\u3002"}}
{"id": "2510.04994", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.04994", "abs": "https://arxiv.org/abs/2510.04994", "authors": ["Sjoerd Dost"], "title": "concurrentKanren: miniKanren for parallel execution", "comment": "13 pages, 1 figure, for associated repo see\n  https://github.com/deosjr/concurrentKanren", "summary": "Concurrent logic programming predates miniKanren, but concurrent\nimplementations of miniKanren have remained largely unexplored. In this work we\npresent a parallel implementation of miniKanren in Go, demonstrating its\nfeasibility and potential for performance improvements. Our approach leverages\nimplicit parallelism allowing legacy programs to benefit from parallel\nexecution. We discuss implementation strategies and evaluate the impact of\nparallelism, laying groundwork for future language-agnostic models.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5728 Go \u8bed\u8a00\u4e2d\u5b9e\u73b0\u4e86\u5e76\u884c miniKanren\uff0c\u8bc1\u660e\u4e86\u5176\u53ef\u884c\u6027\u5e76\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4e3a\u540e\u7eed\u5e76\u53d1\u903b\u8f91\u7f16\u7a0b\u8bed\u8a00\u7814\u7a76\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u548c\u601d\u8def\u3002", "motivation": "miniKanren \u4f5c\u4e3a\u903b\u8f91\u7f16\u7a0b\u8bed\u8a00\u5728\u5e76\u53d1\u5b9e\u73b0\u4e0a\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5728 Go \u8bed\u8a00\u4e2d\u5b9e\u73b0\u4e86 miniKanren \u7684\u5e76\u884c\u7248\u672c\uff0c\u5229\u7528\u9690\u5f0f\u5e76\u884c\u6027\u63d0\u9ad8\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u5c55\u793a\u4e86\u5e76\u884c miniKanren \u7684\u53ef\u884c\u6027\u53ca\u5176\u5bf9\u6027\u80fd\u7684\u63d0\u5347\uff0c\u8bc4\u4f30\u4e86\u5e76\u884c\u5e26\u6765\u7684\u5b9e\u9645\u6548\u679c\u3002", "conclusion": "\u672c\u6587\u4e3a\u57fa\u4e8e\u8bed\u8a00\u65e0\u5173\u6a21\u578b\u7684\u672a\u6765\u5e76\u53d1\u903b\u8f91\u7f16\u7a0b\u5b9e\u73b0\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.03495", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03495", "abs": "https://arxiv.org/abs/2510.03495", "authors": ["Erik Pautsch", "Tanmay Singla", "Wenxin Jiang", "Huiyun Peng", "Behnaz Hassanshahi", "Konstantin L\u00e4ufer", "George K. Thiruvathukal", "James C. Davis"], "title": "AgentHub: A Research Agenda for Agent Sharing Infrastructure", "comment": null, "summary": "LLM-based agents are rapidly proliferating, yet the infrastructure for\ndiscovering, evaluating, and governing them remains fragmented compared to\nmature ecosystems like software package registries (e.g., npm) and model hubs\n(e.g., Hugging Face). Recent research and engineering works have begun to\nconsider the requisite infrastructure, but so far they focus narrowly -- on\ndistribution, naming, or protocol negotiation. However, considering broader\nsoftware engineering requirements would improve open-source distribution and\nease reuse. We therefore propose AgentHub, a research agenda for agent sharing.\nBy framing the key challenges of capability clarity, lifecycle transparency,\ninteroperability, governance, security, and workflow integration, AgentHub\ncharts a community-wide agenda for building reliable and scalable agent\necosystems. Our vision is a future where agents can be shared, trusted, and\ncomposed as seamlessly as today's software libraries.", "AI": {"tldr": "\u667a\u80fd\u4f53\u5e94\u7528\u8fc5\u901f\u53d1\u5c55\uff0c\u4f46\u5176\u57fa\u7840\u8bbe\u65bd\u6ede\u540e\u3002\u672c\u6587\u63d0\u51faAgentHub\uff0c\u5021\u5bfc\u89e3\u51b3\u80fd\u529b\u3001\u900f\u660e\u6027\u3001\u517c\u5bb9\u6027\u3001\u5b89\u5168\u7b49\u516d\u5927\u6311\u6218\uff0c\u63a8\u52a8\u667a\u80fd\u4f53\u50cf\u8f6f\u4ef6\u5305\u4e00\u6837\u9ad8\u6548\u5171\u4eab\u4e0e\u7ec4\u5408\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u667a\u80fd\u4f53\uff08Agent\uff09\u5e94\u7528\u8fc5\u901f\u589e\u957f\uff0c\u4f46\u5176\u76f8\u5173\u7684\u53d1\u73b0\u3001\u8bc4\u4ef7\u548c\u6cbb\u7406\u57fa\u7840\u8bbe\u65bd\u8fd8\u975e\u5e38\u5206\u6563\uff0c\u8fdc\u4e0d\u5982\u8f6f\u4ef6\u5305\u6ce8\u518c\u5e93\u6216\u6a21\u578b\u5171\u4eab\u5e73\u53f0\u5b8c\u5584\u3002\u8fd9\u79cd\u57fa\u7840\u8bbe\u65bd\u7684\u8584\u5f31\u9650\u5236\u4e86Agent\u7684\u5206\u53d1\u4e0e\u590d\u7528\u80fd\u529b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aAgentHub\u7684\u7814\u7a76\u8bae\u7a0b\uff0c\u7cfb\u7edf\u6027\u5730\u6846\u5b9a\u4e86\u6784\u5efaAgent\u5171\u4eab\u57fa\u7840\u8bbe\u65bd\u6240\u9700\u9762\u5bf9\u7684\u5173\u952e\u6311\u6218\uff0c\u5305\u62ec\u80fd\u529b\u6f84\u6e05\u3001\u751f\u547d\u5468\u671f\u900f\u660e\u6027\u3001\u4e92\u64cd\u4f5c\u6027\u3001\u6cbb\u7406\u3001\u5b89\u5168\u548c\u5de5\u4f5c\u6d41\u96c6\u6210\u7b49\u3002", "result": "AgentHub \u63d0\u51fa\u4e86\u56f4\u7ed5\u516d\u5927\u6838\u5fc3\u6311\u6218\u5c55\u5f00\u7684\u793e\u533a\u5408\u4f5c\u84dd\u56fe\uff0c\u65e8\u5728\u5b9e\u73b0\u4e00\u4e2a\u53ef\u9760\u3001\u53ef\u6269\u5c55\u7684\u667a\u80fd\u4f53\u751f\u6001\u7cfb\u7edf\u3002\u8fd9\u4e2a\u7cfb\u7edf\u53ef\u4ee5\u8ba9\u667a\u80fd\u4f53\u50cf\u8f6f\u4ef6\u5e93\u4e00\u6837\u88ab\u9ad8\u6548\u5171\u4eab\u3001\u4fe1\u4efb\u548c\u7ec4\u5408\u3002", "conclusion": "\u901a\u8fc7AgentHub\u7814\u7a76\u8bae\u7a0b\uff0c\u4e3a\u667a\u80fd\u4f53\u751f\u6001\u7cfb\u7edf\u7684\u57fa\u7840\u8bbe\u65bd\u5efa\u8bbe\u6307\u660e\u4e86\u65b9\u5411\uff0c\u6709\u671b\u63a8\u52a8\u667a\u80fd\u4f53\u7684\u5f00\u653e\u5171\u4eab\u3001\u6807\u51c6\u5316\u548c\u53ef\u4fe1\u4efb\u53d1\u5c55\u3002"}}
{"id": "2510.03952", "categories": ["cs.LO", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.03952", "abs": "https://arxiv.org/abs/2510.03952", "authors": ["Raven Beutner", "Bernd Finkbeiner"], "title": "Strategy Logic, Imperfect Information, and Hyperproperties", "comment": "KR 2025", "summary": "Strategy logic (SL) is a powerful temporal logic that enables first-class\nreasoning over strategic behavior in multi-agent systems (MAS). In many MASs,\nthe agents (and their strategies) cannot observe the global state of the\nsystem, leading to many extensions of SL centered around imperfect information,\nsuch as strategy logic with imperfect information (SL$_\\mathit{ii}$). Along\northogonal lines, researchers have studied the combination of strategic\nbehavior and hyperproperties. Hyperproperties are system properties that relate\nmultiple executions in a system and commonly arise when specifying security\npolicies. Hyper Strategy Logic (HyperSL) is a temporal logic that combines\nquantification over strategies with the ability to express hyperproperties on\nthe executions of different strategy profiles. In this paper, we study the\nrelation between SL$_\\mathit{ii}$ and HyperSL. Our main result is that both\nlogics (restricted to formulas where no state formulas are nested within path\nformulas) are equivalent in the sense that we can encode SL$_\\mathit{ii}$\ninstances into HyperSL instances and vice versa. For the former direction, we\nbuild on the well-known observation that imperfect information is a\nhyperproperty. For the latter direction, we construct a self-composition of\nMASs and show how we can simulate hyperproperties using imperfect information.", "AI": {"tldr": "\u672c\u6587\u8ba8\u8bba\u6218\u7565\u903b\u8f91\uff08SL\uff09\u3001\u4e0d\u5b8c\u5168\u4fe1\u606f\u4e0b\u7684\u6218\u7565\u903b\u8f91\uff08SL_ii\uff09\u4e0e\u8d85\u6218\u7565\u903b\u8f91\uff08HyperSL\uff09\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u8bc1\u660e\u5728\u9650\u5b9a\u6761\u4ef6\u4e0bSL_ii\u4e0eHyperSL\u5728\u8868\u8fbe\u80fd\u529b\u4e0a\u53ef\u4ee5\u4e92\u76f8\u7f16\u7801\uff0c\u662f\u7b49\u4ef7\u7684\u3002", "motivation": "\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u4e2d\uff0c\u4ee3\u7406\u7ecf\u5e38\u65e0\u6cd5\u89c2\u5bdf\u7cfb\u7edf\u7684\u5168\u5c40\u72b6\u6001\uff0c\u8fd9\u5bfc\u81f4\u4e86\u5bf9\u4e0d\u5b8c\u5168\u4fe1\u606f\u4e0b\u6218\u7565\u903b\u8f91\uff08SL\uff09\u6269\u5c55\u7684\u7814\u7a76\u3002\u540c\u65f6\uff0c\u7814\u7a76\u8005\u4e5f\u5bf9\u6218\u7565\u884c\u4e3a\u4e0e\u8d85\u5c5e\u6027\uff08Hyperproperties\uff09\u7684\u7ed3\u5408\u8fdb\u884c\u4e86\u7814\u7a76\uff0c\u8d85\u5c5e\u6027\u901a\u5e38\u7528\u4e8e\u8868\u8fbe\u6d89\u53ca\u591a\u4e2a\u7cfb\u7edf\u6267\u884c\u4e4b\u95f4\u5173\u7cfb\u7684\u5b89\u5168\u7b56\u7565\u3002\u672c\u8bba\u6587\u65e8\u5728\u63a2\u7a76\u4e24\u79cd\u903b\u8f91\uff08SL_ii\u4e0eHyperSL\uff09\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u5c06SL_ii\u4e0eHyperSL\u8fdb\u884c\u5bf9\u6bd4\u7814\u7a76\uff0c\u5e76\u9650\u5b9a\u5728\u6ca1\u6709\u72b6\u6001\u516c\u5f0f\u5d4c\u5957\u4e8e\u8def\u5f84\u516c\u5f0f\u7684\u60c5\u51b5\u3002\u9996\u5148\uff0c\u901a\u8fc7\u5df2\u77e5\u7684\u4e0d\u5b8c\u5168\u4fe1\u606f\u662f\u8d85\u5c5e\u6027\u7684\u7ed3\u8bba\uff0c\u5c06SL_ii\u5b9e\u4f8b\u7f16\u7801\u5230HyperSL\uff0c\u53cd\u65b9\u5411\u5219\u901a\u8fc7\u81ea\u6211\u7ec4\u5408\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6765\u5b9e\u73b0\u7528\u4e0d\u5b8c\u5168\u4fe1\u606f\u6a21\u62df\u8d85\u5c5e\u6027\u3002", "result": "\u9650\u5b9a\u6761\u4ef6\u4e0b\uff0cSL_ii\u548cHyperSL\u662f\u7b49\u4ef7\u7684\uff0c\u53ef\u4ee5\u5c06SL_ii\u5b9e\u4f8b\u7f16\u7801\u5230HyperSL\u5b9e\u4f8b\uff0c\u53cd\u4e4b\u4ea6\u7136\u3002", "conclusion": "\u7ed3\u8bba\u662f\uff0c\u53ea\u8981\u516c\u5f0f\u4e0d\u5d4c\u5957\u72b6\u6001\u516c\u5f0f\uff0c\u6218\u7565\u903b\u8f91\u4e0d\u5b8c\u5168\u4fe1\u606f\uff08SL_ii\uff09\u4e0e\u8d85\u6218\u7565\u903b\u8f91\uff08HyperSL\uff09\u5728\u8868\u8fbe\u80fd\u529b\u4e0a\u7b49\u4ef7\u3002"}}
{"id": "2510.03458", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.03458", "abs": "https://arxiv.org/abs/2510.03458", "authors": ["Mengyao Xu", "Wenfei Zhou", "Yauhen Babakhin", "Gabriel Moreira", "Ronay Ak", "Radek Osmulski", "Bo Liu", "Even Oldridge", "Benedikt Schifferer"], "title": "Omni-Embed-Nemotron: A Unified Multimodal Retrieval Model for Text, Image, Audio, and Video", "comment": null, "summary": "We present Omni-Embed-Nemotron, a unified multimodal retrieval embedding\nmodel developed to handle the increasing complexity of real-world information\nneeds. While Retrieval-Augmented Generation (RAG) has significantly advanced\nlanguage models by incorporating external knowledge, existing text-based\nretrievers rely on clean, structured input and struggle with the visually and\nsemantically rich content found in real-world documents such as PDFs, slides,\nor videos. Recent work such as ColPali has shown that preserving document\nlayout using image-based representations can improve retrieval quality.\nBuilding on this, and inspired by the capabilities of recent multimodal models\nsuch as Qwen2.5-Omni, we extend retrieval beyond text and images to also\nsupport audio and video modalities. Omni-Embed-Nemotron enables both\ncross-modal (e.g., text - video) and joint-modal (e.g., text - video+audio)\nretrieval using a single model. We describe the architecture, training setup,\nand evaluation results of Omni-Embed-Nemotron, and demonstrate its\neffectiveness in text, image, and video retrieval.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u6a21\u6001\u68c0\u7d22\u6a21\u578bOmni-Embed-Nemotron\uff0c\u652f\u6301\u6587\u672c\u3001\u56fe\u50cf\u3001\u97f3\u9891\u548c\u89c6\u9891\u7684\u9ad8\u6548\u8de8\u6a21\u6001\u68c0\u7d22\uff0c\u76f8\u6bd4\u73b0\u6709\u57fa\u4e8e\u6587\u672c\u7684\u68c0\u7d22\u548c\u90e8\u5206\u591a\u6a21\u6001\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u771f\u5b9e\u4e16\u754c\u7684\u4fe1\u606f\u9700\u6c42\u65e5\u76ca\u590d\u6742\uff0c\u5e38\u89c4\u7684\u57fa\u4e8e\u6587\u672c\u7684\u68c0\u7d22\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9PDF\u3001\u5e7b\u706f\u7247\u3001\u89c6\u9891\u7b49\u591a\u6a21\u6001\u3001\u8bed\u4e49\u4e30\u5bcc\u7684\u5185\u5bb9\u3002\u5f53\u524d\u5982ColPali\u7b49\u7814\u7a76\u8868\u660e\uff0c\u4fdd\u7559\u6587\u6863\u5e03\u5c40\u7684\u56fe\u50cf\u5f0f\u8868\u793a\u53ef\u63d0\u5347\u68c0\u7d22\u8d28\u91cf\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u591a\u5c40\u9650\u4e8e\u6587\u672c\u548c\u56fe\u7247\u3002", "method": "\u63d0\u51fa\u4e86Omni-Embed-Nemotron\uff0c\u8fd9\u662f\u4e00\u4e2a\u652f\u6301\u6587\u672c\u3001\u56fe\u50cf\u3001\u97f3\u9891\u3001\u89c6\u9891\u591a\u6a21\u6001\u7edf\u4e00\u68c0\u7d22\u7684embedding\u6a21\u578b\u3002\u6a21\u578b\u67b6\u6784\u5141\u8bb8\u8de8\u6a21\u6001\uff08\u5982\u6587\u672c-\u89c6\u9891\uff09\u3001\u8054\u5408\u6a21\u6001\uff08\u5982\u6587\u672c-\u89c6\u9891+\u97f3\u9891\uff09\u68c0\u7d22\uff0c\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u4f53\u7cfb\u7ed3\u6784\u3001\u8bad\u7ec3\u8fc7\u7a0b\u53ca\u8bc4\u6d4b\u65b9\u5f0f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cOmni-Embed-Nemotron\u5728\u6587\u672c\u3001\u56fe\u50cf\u3001\u89c6\u9891\u7b49\u68c0\u7d22\u4efb\u52a1\u4e2d\u6548\u679c\u7a81\u51fa\uff0c\u80fd\u591f\u63d0\u5347\u8de8\u591a\u6a21\u6001\u5185\u5bb9\u7684\u68c0\u7d22\u80fd\u529b\u3002", "conclusion": "Omni-Embed-Nemotron\u6a21\u578b\u6709\u6548\u89e3\u51b3\u4e86\u771f\u5b9e\u4e16\u754c\u591a\u6a21\u6001\u68c0\u7d22\u7684\u75db\u70b9\uff0c\u5b9e\u73b0\u4e86\u5355\u4e00\u6a21\u578b\u4e0b\u5bf9\u6587\u672c\u3001\u56fe\u7247\u3001\u97f3\u9891\u3001\u89c6\u9891\u7684\u8054\u5408\u9ad8\u8d28\u91cf\u68c0\u7d22\uff0c\u63a8\u8fdb\u4e86\u591a\u6a21\u6001\u68c0\u7d22\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.03588", "categories": ["cs.SE", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.03588", "abs": "https://arxiv.org/abs/2510.03588", "authors": ["Anvith Pabba", "Simin Chen", "Alex Mathai", "Anindya Chakraborty", "Baishakhi Ray"], "title": "REFINE: Enhancing Program Repair Agents through Context-Aware Patch Refinement", "comment": "We also open source our code at\n  https://anonymous.4open.science/r/SemAgent-7B2F/README.md", "summary": "Large Language Models (LLMs) have recently shown strong potential in\nautomatic program repair (APR), especially in repository-level settings where\nthe goal is to generate patches based on natural language issue descriptions,\nlarge codebases, and regression tests. However, despite their promise, current\nLLM-based APR techniques often struggle to produce correct fixes due to limited\nunderstanding of code context and over-reliance on incomplete test suites. As a\nresult, they frequently generate Draft Patches-partially correct patches that\neither incompletely address the bug or overfit to the test cases. In this work,\nwe propose a novel patch refinement framework, Refine, that systematically\ntransforms Draft Patches into correct ones. Refine addresses three key\nchallenges: disambiguating vague issue and code context, diversifying patch\ncandidates through test-time scaling, and aggregating partial fixes via an\nLLM-powered code review process. We implement Refine as a general refinement\nmodule that can be integrated into both open-agent-based and workflow-based APR\nsystems. Our evaluation on the SWE-Bench Lite benchmark shows that Refine\nachieves state-of-the-art results among workflow-based approaches and\napproaches the best-known performance across all APR categories. Specifically,\nRefine boosts AutoCodeRover's performance by 14.67%, achieving a score of\n51.67% and surpassing all prior baselines. On SWE-Bench Verified, Refine\nimproves the resolution rate by 12.2%, and when integrated across multiple APR\nsystems, it yields an average improvement of 14%-demonstrating its broad\neffectiveness and generalizability. These results highlight the effectiveness\nof refinement as a missing component in current APR pipelines and the potential\nof agentic collaboration in closing the gap between near-correct and correct\npatches. We also open source our code.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9LLM\u9a71\u52a8\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u7684\u8865\u4e01\u7ec6\u5316\u6846\u67b6Refine, \u6709\u6548\u89e3\u51b3\u4e86\u56e0\u8bed\u5883\u7406\u89e3\u548c\u6d4b\u8bd5\u4e0d\u5168\u5bfc\u81f4\u7684\u90e8\u5206\u4fee\u590d\u95ee\u9898\u3002Refine\u901a\u8fc7\u5185\u5bb9\u6f84\u6e05\u3001\u591a\u6837\u5019\u9009\u6269\u5c55\u548c\u667a\u80fd\u4ee3\u7801\u8bc4\u5ba1\uff0c\u5927\u5e45\u63d0\u9ad8\u4e86\u4fee\u590d\u6b63\u786e\u7387\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u548c\u7cfb\u7edf\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u5e76\u5df2\u5b9e\u73b0\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u6280\u672f\uff0c\u5c3d\u7ba1\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u751f\u6210\u6b63\u786e\u8865\u4e01\u65f6\u5b58\u5728\u56f0\u5883\u3002\u4e3b\u8981\u539f\u56e0\u662f\u5bf9\u4ee3\u7801\u8bed\u5883\u7406\u89e3\u4e0d\u8db3\uff0c\u4ee5\u53ca\u8fc7\u5ea6\u4f9d\u8d56\u4e0d\u5b8c\u6574\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u8fd9\u5bfc\u81f4\u751f\u6210\u7684\u8865\u4e01\u5e38\u5e38\u662f\u201c\u8349\u7a3f\u8865\u4e01\u201d\uff0c\u53ea\u80fd\u90e8\u5206\u89e3\u51b3\u95ee\u9898\u6216\u8005\u8fc7\u62df\u5408\u4e8e\u6d4b\u8bd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u8865\u4e01\u7ec6\u5316\u6846\u67b6Refine\uff0c\u7cfb\u7edf\u6027\u5730\u5c06\u8349\u7a3f\u8865\u4e01\u8f6c\u5316\u4e3a\u6b63\u786e\u8865\u4e01\u3002\u4ece\u4e09\u65b9\u9762\u7740\u624b\uff1a1\uff09\u6f84\u6e05\u6a21\u7cca\u7684\u95ee\u9898\u4e0e\u4ee3\u7801\u4e0a\u4e0b\u6587\uff1b2\uff09\u901a\u8fc7\u6d4b\u8bd5\u9636\u6bb5\u6269\u5c55\u591a\u6837\u5316\u8865\u4e01\u5019\u9009\uff1b3\uff09\u501f\u52a9LLM\u9a71\u52a8\u7684\u4ee3\u7801\u8bc4\u5ba1\u8fc7\u7a0b\u805a\u5408\u90e8\u5206\u4fee\u590d\u3002\u8be5\u6a21\u5757\u53ef\u4ee5\u96c6\u6210\u5230\u5f00\u653e\u5f0f\u6216\u5de5\u4f5c\u6d41\u5f0fAPR\u7cfb\u7edf\u4e2d\u3002", "result": "Refine\u5728SWE-Bench Lite\u57fa\u51c6\u4e0a\u8fbe\u5230\u4e86\u5de5\u4f5c\u6d41\u7c7b\u65b9\u6cd5\u7684\u6700\u65b0\u6c34\u5e73\uff0c\u6574\u4f53\u8868\u73b0\u63a5\u8fd1\u6240\u6709APR\u7c7b\u522b\u7684\u6700\u4f73\u7ed3\u679c\u3002\u5177\u4f53\u8868\u73b0\u4e3a\u8ba9AutoCodeRover\u6027\u80fd\u63d0\u5347\u4e8614.67%\uff0c\u5f97\u5206\u8fbe\u523051.67%\uff0c\u8d85\u8d8a\u6240\u6709\u5bf9\u6bd4\u57fa\u7ebf\uff1b\u5728SWE-Bench Verified\u4e0a\u4fee\u590d\u7387\u63d0\u534712.2%\uff1b\u96c6\u6210\u5230\u591a\u79cdAPR\u7cfb\u7edf\u5e73\u5747\u63d0\u5347\u8fbe14%\uff0c\u5c55\u73b0\u4e86\u5e7f\u6cdb\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\u76f8\u5173\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "conclusion": "\u8865\u4e01\u7ec6\u5316\u4f5c\u4e3aAPR\u6d41\u7a0b\u4e2d\u7f3a\u5931\u7684\u5173\u952e\u73af\u8282\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u73b0\u6709LLM\u9a71\u52a8\u4fee\u590d\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u63a8\u52a8\u4ece\u201c\u8fd1\u6b63\u786e\u201d\u8865\u4e01\u8d70\u5411\u771f\u6b63\u6b63\u786e\u3002Refine\u6846\u67b6\u901a\u8fc7\u667a\u80fd\u534f\u4f5c\u548c\u591a\u5143\u8bed\u5883\u5904\u7406\u65b9\u5f0f\uff0c\u4e3a\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u9886\u57df\u95ed\u5408\u4e86\u91cd\u8981\u6280\u672f\u7f3a\u53e3\u3002"}}
{"id": "2510.04649", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2510.04649", "abs": "https://arxiv.org/abs/2510.04649", "authors": ["Mateo Torres-Ruiz", "Robin Piedeleu", "Alexandra Silva", "Fabio Zanasi"], "title": "A Complete Diagrammatic Calculus for Conditional Gaussian Mixtures", "comment": null, "summary": "We extend the synthetic theories of discrete and Gaussian categorical\nprobability by introducing a diagrammatic calculus for reasoning about hybrid\nprobabilistic models in which continuous random variables, conditioned on\ndiscrete ones, follow a multivariate Gaussian distribution. This setting\nincludes important classes of models such as Gaussian mixture models, where\neach Gaussian component is selected according to a discrete variable. We\ndevelop a string diagrammatic syntax for expressing and combining these models,\ngive it a compositional semantics, and equip it with a sound and complete\nequational theory that characterises when two models represent the same\ndistribution.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u6982\u7387\u6a21\u578b\u7684\u5408\u6210\u7406\u8bba\uff0c\u5f15\u5165\u4e86\u53ef\u7ec4\u5408\u7684\u56fe\u793a\u6f14\u7b97\u65b9\u6cd5\u4ee5\u5904\u7406\u79bb\u6563\u4e0e\u9ad8\u65af\u8fde\u7eed\u53d8\u91cf\u6df7\u5408\u60c5\u5f62\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u4e86\u5224\u522b\u6a21\u578b\u7b49\u4ef7\u6027\u7684\u5b8c\u5907\u7406\u8bba\u3002", "motivation": "\u73b0\u6709\u5408\u6210\u6982\u7387\u7406\u8bba\u4e3b\u8981\u9488\u5bf9\u79bb\u6563\u548c\u9ad8\u65af\uff08\u8fde\u7eed\uff09\u60c5\u5f62\uff0c\u7f3a\u4e4f\u63cf\u8ff0\u6df7\u5408\u6a21\u578b\uff08\u5982\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff09\u7684\u65b9\u6cd5\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u65b9\u9762\u7406\u8bba\u53ca\u5de5\u5177\u7684\u7a7a\u767d\uff0c\u4ee5\u6ee1\u8db3\u5b9e\u9645\u5efa\u6a21\u9700\u6c42\u3002", "method": "\u91c7\u7528\u5f26\u56fe\uff08string diagram\uff09\u8bed\u6cd5\u6765\u8868\u8fbe\u548c\u7ec4\u5408\u6df7\u5408\u6982\u7387\u6a21\u578b\uff0c\u5e76\u4e3a\u5176\u8d4b\u4e88\u4e86\u7ec4\u5408\u8bed\u4e49\uff0c\u901a\u8fc7\u6784\u5efa\u5b8c\u5907\u4e14\u53ef\u9760\u7684\u7b49\u4ef7\u7406\u8bba\u786e\u4fdd\u6a21\u578b\u4e4b\u95f4\u53ef\u6bd4\u8f83\u3002", "result": "\u63d0\u51fa\u4e86\u7528\u4e8e\u6df7\u5408\u6982\u7387\u6a21\u578b\u7684\u56fe\u793a\u6f14\u7b97\u4f53\u7cfb\uff0c\u80fd\u591f\u7cfb\u7edf\u5730\u6784\u5efa\u548c\u5206\u6790\u6a21\u578b\uff0c\u8fd8\u5efa\u7acb\u4e86\u5b8c\u6574\u7684\u5224\u522b\u4e24\u4e2a\u6a21\u578b\u7b49\u4ef7\u7684\u7406\u8bba\u6807\u51c6\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6df7\u5408\u6982\u7387\u6a21\u578b\uff08\u79bb\u6563\u4e0e\u8fde\u7eed\u53d8\u91cf\u7ed3\u5408\uff09\u7684\u56fe\u793a\u6f14\u7b97\u65b9\u6cd5\uff0c\u5e76\u5efa\u7acb\u4e86\u5224\u5b9a\u4f55\u65f6\u4e24\u4e2a\u6a21\u578b\u4ee3\u8868\u76f8\u540c\u5206\u5e03\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2510.03467", "categories": ["cs.CL", "I.2.7; I.6.m"], "pdf": "https://arxiv.org/pdf/2510.03467", "abs": "https://arxiv.org/abs/2510.03467", "authors": ["Brendon Boldt", "David Mortensen"], "title": "Searching for the Most Human-like Emergent Language", "comment": "Accepted for publication at the 2025 Conference on Empirical Methods\n  in Natural Language Processing; 19 pages, 12 figures", "summary": "In this paper, we design a signalling game-based emergent communication\nenvironment to generate state-of-the-art emergent languages in terms of\nsimilarity to human language. This is done with hyperparameter optimization,\nusing XferBench as the objective function. XferBench quantifies the statistical\nsimilarity of emergent language to human language by measuring its suitability\nfor deep transfer learning to human language. Additionally, we demonstrate the\npredictive power of entropy on the transfer learning performance of emergent\nlanguage as well as corroborate previous results on the entropy-minimization\nproperties of emergent communication systems. Finally, we report\ngeneralizations regarding what hyperparameters produce more realistic emergent\nlanguages, that is, ones which transfer better to human language.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4fe1\u53f7\u535a\u5f08\u7ed3\u5408\u8d85\u53c2\u6570\u4f18\u5316\u7684\u65b0\u578b\u6d8c\u73b0\u901a\u4fe1\u6846\u67b6\uff0c\u4f7f\u7528XferBench\u8861\u91cf\u8bed\u8a00\u4e0e\u4eba\u7c7b\u8bed\u8a00\u7684\u76f8\u4f3c\u5ea6\uff0c\u53d1\u73b0\u71b5\u53ef\u9884\u6d4b\u8fc1\u79fb\u8868\u73b0\uff0c\u5e76\u603b\u7ed3\u4e86\u751f\u6210\u66f4\u62df\u4eba\u5316\u8bed\u8a00\u7684\u8d85\u53c2\u6570\u9009\u62e9\u3002", "motivation": "\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e2d\u7684\u6d8c\u73b0\u8bed\u8a00\u5f80\u5f80\u4e0e\u4eba\u7c7b\u8bed\u8a00\u76f8\u5dee\u8f83\u5927\uff0c\u63d0\u5347\u6d8c\u73b0\u8bed\u8a00\u4e0e\u4eba\u7c7b\u8bed\u8a00\u7684\u76f8\u4f3c\u6027\u5bf9\u4e8e\u63d0\u5347\u5176\u5728\u4eba\u7c7b\u8bed\u8a00\u4efb\u52a1\u4e2d\u7684\u8fc1\u79fb\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002\u5982\u4f55\u8bbe\u8ba1\u66f4\u62df\u4eba\u5316\u7684\u6d8c\u73b0\u8bed\u8a00\uff0c\u4ee5\u53ca\u6709\u6548\u8861\u91cf\u6d8c\u73b0\u8bed\u8a00\u4e0e\u4eba\u7c7b\u8bed\u8a00\u7684\u76f8\u4f3c\u5ea6\uff0c\u662f\u8be5\u9886\u57df\u7684\u5173\u952e\u95ee\u9898\u3002", "method": "\u672c\u6587\u57fa\u4e8e\u4fe1\u53f7\u535a\u5f08\uff08signalling game\uff09\u6846\u67b6\uff0c\u6784\u5efa\u6d8c\u73b0\u901a\u4fe1\u73af\u5883\uff0c\u5e76\u901a\u8fc7\u8d85\u53c2\u6570\u4f18\u5316\uff0c\u4ee5XferBench\u4e3a\u76ee\u6807\u51fd\u6570\u3002XferBench\u7528\u6765\u91cf\u5316\u6d8c\u73b0\u8bed\u8a00\u4e0e\u4eba\u7c7b\u8bed\u8a00\u7684\u7edf\u8ba1\u76f8\u4f3c\u5ea6\uff0c\u5177\u4f53\u65b9\u5f0f\u4e3a\u8bc4\u4f30\u5176\u5728\u6df1\u5ea6\u8fc1\u79fb\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u540c\u65f6\u63a2\u8ba8\u71b5\u6307\u6807\u5bf9\u6d8c\u73b0\u8bed\u8a00\u8fc1\u79fb\u80fd\u529b\u7684\u9884\u6d4b\u4f5c\u7528\uff0c\u4ee5\u53ca\u5173\u4e8e\u71b5\u6700\u5c0f\u5316\u6027\u8d28\u7684\u76f8\u5173\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0c\u901a\u8fc7\u5408\u7406\u9009\u62e9\u8d85\u53c2\u6570\uff0c\u53ef\u751f\u6210\u4e0e\u4eba\u7c7b\u8bed\u8a00\u66f4\u4e3a\u76f8\u4f3c\u3001\u8fc1\u79fb\u80fd\u529b\u66f4\u5f3a\u7684\u6d8c\u73b0\u8bed\u8a00\u3002\u6b64\u5916\uff0c\u6587\u4e2d\u8bc1\u5b9e\u4e86\u6d8c\u73b0\u901a\u4fe1\u7cfb\u7edf\u5448\u73b0\u71b5\u6700\u5c0f\u5316\u7279\u6027\uff0c\u5e76\u53d1\u73b0\u71b5\u5bf9\u8fc1\u79fb\u6027\u80fd\u5177\u6709\u4e00\u5b9a\u9884\u6d4b\u529b\u3002", "conclusion": "\u57fa\u4e8e\u4fe1\u53f7\u535a\u5f08\u548c\u8d85\u53c2\u6570\u4f18\u5316\u7684\u6d8c\u73b0\u901a\u4fe1\u73af\u5883\u80fd\u591f\u6709\u6548\u751f\u6210\u62df\u4eba\u5316\u6d8c\u73b0\u8bed\u8a00\uff0c\u540c\u65f6\u63d0\u51faXferBench\u91cf\u5316\u6307\u6807\u5bf9\u4fc3\u8fdb\u6d8c\u73b0\u4e0e\u4eba\u7c7b\u8bed\u8a00\u7684\u878d\u5408\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u5bf9\u71b5\u6307\u6807\u7684\u5206\u6790\u4e3a\u7406\u89e3\u6d8c\u73b0\u8bed\u8a00\u7cfb\u7edf\u7684\u751f\u6210\u673a\u5236\u548c\u6027\u80fd\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2510.04081", "categories": ["cs.CL", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.04081", "abs": "https://arxiv.org/abs/2510.04081", "authors": ["Honglin Lin", "Qizhi Pei", "Xin Gao", "Zhuoshi Pan", "Yu Li", "Juntao Li", "Conghui He", "Lijun Wu"], "title": "Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model Reasoning", "comment": "Accepted by NeurIPS2025", "summary": "Reasoning capability is pivotal for Large Language Models (LLMs) to solve\ncomplex tasks, yet achieving reliable and scalable reasoning remains\nchallenging. While Chain-of-Thought (CoT) prompting has become a mainstream\napproach, existing methods often suffer from uncontrolled generation,\ninsufficient quality, and limited diversity in reasoning paths. Recent efforts\nleverage code to enhance CoT by grounding reasoning in executable steps, but\nsuch methods are typically constrained to predefined mathematical problems,\nhindering scalability and generalizability. In this work, we propose Caco\n(Code-Assisted Chain-of-ThOught), a novel framework that automates the\nsynthesis of high-quality, verifiable, and diverse instruction-CoT reasoning\ndata through code-driven augmentation. Unlike prior work, Caco first fine-tunes\na code-based CoT generator on existing math and programming solutions in a\nunified code format, then scales the data generation to a large amount of\ndiverse reasoning traces. Crucially, we introduce automated validation via code\nexecution and rule-based filtering to ensure logical correctness and structural\ndiversity, followed by reverse-engineering filtered outputs into natural\nlanguage instructions and language CoTs to enrich task adaptability. This\nclosed-loop process enables fully automated, scalable synthesis of reasoning\ndata with guaranteed executability. Experiments on our created Caco-1.3M\ndataset demonstrate that Caco-trained models achieve strong competitive\nperformance on mathematical reasoning benchmarks, outperforming existing strong\nbaselines. Further analysis reveals that Caco's code-anchored verification and\ninstruction diversity contribute to superior generalization across unseen\ntasks. Our work establishes a paradigm for building self-sustaining,\ntrustworthy reasoning systems without human intervention.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ee3\u7801\u8f85\u52a9\u81ea\u52a8\u751f\u6210\u591a\u6837\u5316\u3001\u9ad8\u8d28\u91cf\u63a8\u7406\u6570\u636e\u7684\u95ed\u73af\u7cfb\u7edf\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5f00\u8f9f\u4e86\u65e0\u9700\u4eba\u5de5\u53c2\u4e0e\u7684\u53ef\u4fe1\u63a8\u7406\u7cfb\u7edf\u65b0\u8def\u5f84\u3002", "motivation": "\u5927\u6a21\u578b\u5728\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u65f6\u63a8\u7406\u80fd\u529b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u65b9\u6cd5\u5b58\u5728\u751f\u6210\u63a7\u5236\u4e0d\u8db3\u3001\u8d28\u91cf\u4e0d\u9ad8\u548c\u63a8\u7406\u8def\u5f84\u591a\u6837\u6027\u6709\u9650\u7b49\u95ee\u9898\uff0c\u4e14\u57fa\u4e8e\u4ee3\u7801\u7684\u65b9\u6cd5\u901a\u5e38\u53d7\u9650\u4e8e\u7279\u5b9a\u6570\u5b66\u95ee\u9898\uff0c\u7f3a\u4e4f\u901a\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51faCaco\uff08Code-Assisted Chain-of-ThOught\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u4ee3\u7801\u9a71\u52a8\u7684\u589e\u5f3a\u81ea\u52a8\u5408\u6210\u9ad8\u8d28\u91cf\u3001\u53ef\u9a8c\u8bc1\u3001\u591a\u6837\u5316\u7684\u63a8\u7406\u6570\u636e\u3002\u65b9\u6cd5\u5305\u62ec\uff1a\u7edf\u4e00\u4ee3\u7801\u683c\u5f0f\u8bad\u7ec3CoT\u751f\u6210\u5668\u3001\u901a\u8fc7\u4ee3\u7801\u751f\u6210\u591a\u6837\u63a8\u7406\u8f68\u8ff9\u3001\u5229\u7528\u4ee3\u7801\u6267\u884c\u4e0e\u89c4\u5219\u8fc7\u6ee4\u81ea\u52a8\u9a8c\u8bc1\u903b\u8f91\u6b63\u786e\u6027\u4e0e\u7ed3\u6784\u591a\u6837\u6027\uff0c\u518d\u53cd\u5411\u8f6c\u6362\u4e3a\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u548c\u8bed\u8a00CoT\uff0c\u95ed\u73af\u81ea\u52a8\u5316\u751f\u6210\u63a8\u7406\u6570\u636e\u3002", "result": "Caco\u6846\u67b6\u751f\u6210\u7684Caco-1.3M\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8fc7\u73b0\u6709\u5f3a\u57fa\u7ebf\u3002\u5206\u6790\u8868\u660e\uff0cCaco\u7684\u4ee3\u7801\u9a8c\u8bc1\u548c\u6307\u4ee4\u591a\u6837\u6027\u63d0\u5347\u4e86\u5bf9\u65b0\u4efb\u52a1\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "Caco\u4e3a\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u6784\u5efa\u81ea\u5faa\u73af\u3001\u53ef\u9760\u7684\u63a8\u7406\u7cfb\u7edf\u5efa\u7acb\u4e86\u65b0\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u3001\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u63a8\u7406\u6570\u636e\u751f\u6210\u3002"}}
{"id": "2510.03641", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.03641", "abs": "https://arxiv.org/abs/2510.03641", "authors": ["Satoshi Masuda", "Satoshi Kouzawa", "Kyousuke Sezai", "Hidetoshi Suhara", "Yasuaki Hiruta", "Kunihiro Kudou"], "title": "Generating High-Level Test Cases from Requirements using LLM: An Industry Study", "comment": "11pages", "summary": "Currently, generating high-level test cases described in natural language\nfrom requirement documents is performed manually. In the industry, including\ncompanies specializing in software testing, there is a significant demand for\nthe automatic generation of high-level test cases from requirement documents\nusing Large Language Models (LLMs). Efforts to utilize LLMs for requirement\nanalysis are underway. In some cases, retrieval-augmented generation (RAG) is\nemployed for generating high-level test cases using LLMs. However, in practical\napplications, it is necessary to create a RAG tailored to the knowledge system\nof each specific application, which is labor-intensive. Moreover, when applying\nhigh-level test case generation as a prompt, there is no established method for\ninstructing the generation of high-level test cases at a level applicable to\nother specifications without using RAG. It is required to establish a method\nfor the automatic generation of high-level test cases that can be generalized\nacross a wider range of requirement documents. In this paper, we propose a\nmethod for generating high-level (GHL) test cases from requirement documents\nusing only prompts, without creating RAGs. In the proposed method, first, the\nrequirement document is input into the LLM to generate test design techniques\ncorresponding to the requirement document. Then, high-level test cases are\ngenerated for each of the generated test design techniques. Furthermore, we\nverify an evaluation method based on semantic similarity of the generated\nhigh-level test cases. In the experiments, we confirmed the method using\ndatasets from Bluetooth and Mozilla, where requirement documents and high-level\ntest cases are available, achieving macro-recall measurement of 0.81 and 0.37,\nrespectively. We believe that the method is feasible for practical application\nin generating high-level test cases without using RAG.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u4f9d\u8d56RAG\uff0c\u4ec5\u4f7f\u7528LLM\u548cprompt\u81ea\u52a8\u751f\u6210\u9700\u6c42\u6587\u6863\u9ad8\u5c42\u6d4b\u8bd5\u7528\u4f8b\u7684\u65b9\u6cd5\uff0c\u5728\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\u826f\u597d\u6548\u679c\uff0c\u5177\u5907\u8f83\u5f3a\u884c\u4e1a\u63a8\u5e7f\u4ef7\u503c\u3002", "motivation": "\u76ee\u524d\u4e1a\u754c\u5bf9\u81ea\u52a8\u4ece\u9700\u6c42\u6587\u6863\u751f\u6210\u9ad8\u5c42\u6b21\u6d4b\u8bd5\u7528\u4f8b\u6709\u5f3a\u70c8\u9700\u6c42\uff0c\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u624b\u5de5\uff0c\u6216\u9700\u6784\u5efa\u7279\u5b9a\u77e5\u8bc6\u4f53\u7cfb\u7684RAG\uff0c\u8fc7\u7a0b\u7e41\u7410\u4e14\u96be\u4ee5\u901a\u7528\u3002\u4e9f\u9700\u4e00\u79cd\u65e0\u9700RAG\u4e14\u80fd\u5e7f\u6cdb\u9002\u7528\u9700\u6c42\u6587\u6863\u7684\u901a\u7528\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u4ec5\u7528Prompt\uff08\u63d0\u793a\u8bcd\uff09\uff0c\u4e0d\u4f9d\u8d56RAG\uff0c\u901a\u8fc7LLMs\u81ea\u52a8\u4ece\u9700\u6c42\u6587\u6863\u4e2d\u751f\u6210\u9ad8\u5c42\u6d4b\u8bd5\u7528\u4f8b\u3002\u5177\u4f53\u65b9\u6cd5\u4e3a\uff1a\u9996\u5148\u5c06\u9700\u6c42\u6587\u6863\u8f93\u5165LLM\u4ee5\u751f\u6210\u76f8\u5e94\u6d4b\u8bd5\u8bbe\u8ba1\u6280\u672f\uff1b\u968f\u540e\u9488\u5bf9\u6bcf\u4e2a\u8bbe\u8ba1\u6280\u672f\u751f\u6210\u9ad8\u5c42\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5e76\u91c7\u7528\u8bed\u4e49\u76f8\u4f3c\u5ea6\u8fdb\u884c\u6548\u679c\u8bc4\u4f30\u3002", "result": "\u5728Bluetooth\u548cMozilla\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u5206\u522b\u83b7\u5f97\u5b8f\u53ec\u56de\u73870.81\u548c0.37\u3002\u8868\u660e\u6b64\u65b9\u6cd5\u65e0\u9700RAG\u5373\u53ef\u6709\u6548\u751f\u6210\u9ad8\u5c42\u6b21\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5177\u5907\u5b9e\u9645\u5e94\u7528\u53ef\u884c\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8eprompt\u7684\u81ea\u52a8\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u65b9\u6cd5\u53ef\u884c\uff0c\u964d\u4f4e\u4e86\u6784\u5efa\u6d4b\u8bd5\u7528\u4f8b\u7684\u4eba\u5de5\u548c\u77e5\u8bc6\u5e93\u4f9d\u8d56\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdb\u9700\u6c42\u6587\u6863\u573a\u666f\uff0c\u4e14\u5b9e\u9a8c\u7ed3\u679c\u652f\u6301\u5176\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.04653", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2510.04653", "abs": "https://arxiv.org/abs/2510.04653", "authors": ["Ryota Kojima", "Corina Cirstea"], "title": "Continuation Semantics for Fixpoint Modal Logic and Computation Tree Logics", "comment": null, "summary": "We introduce continuation semantics for both fixpoint modal logic (FML) and\nComputation Tree Logic* (CTL*), parameterised by a choice of branching type and\nquantitative predicate lifting. Our main contribution is proving that they are\nequivalent to coalgebraic semantics, for all branching types. Our continuation\nsemantics is defined over coalgebras of the continuation monad whose answer\ntype coincides with the domain of truth values of the formulas. By identifying\npredicates and continuations, such a coalgebra has a canonical interpretation\nof the modality by evaluation of continuations. We show that this continuation\nsemantics is equivalent to the coalgebraic semantics for fixpoint modal logic.\nWe then reformulate the current construction for coalgebraic models of CTL*.\nThese models are usually required to have an infinitary trace/maximal execution\nmap, characterized as the greatest fixpoint of a special operator. Instead, we\nallow coalgebraic models of CTL* to employ non-maximal fixpoints, which we call\nexecution maps. Under this reformulation, we establish a general result on\ntransferring execution maps via monad morphisms. From this result, we obtain\nthat continuation semantics is equivalent to the coalgebraic semantics for\nCTL*. We also identify a sufficient condition under which CTL can be encoded\ninto fixpoint modal logic under continuation semantics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5ef6\u7eedMonad\u7684\u7edf\u4e00\u8bed\u4e49\u6846\u67b6\uff0c\u4f7fFML\u548cCTL*\u5728\u6240\u6709\u5206\u652f\u7c7b\u578b\u4e0b\u90fd\u80fd\u4e0e\u7164\u4ee3\u6570\u8bed\u4e49\u7b49\u4ef7\uff0c\u540c\u65f6\u91cd\u6784\u4e86CTL*\u7684\u6a21\u578b\uff0c\u4f7f\u5176\u652f\u6301\u66f4\u7075\u6d3b\u7684\u6267\u884c\u56fe\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u76f8\u5173\u903b\u8f91\u7684\u8868\u8ff0\u548c\u7f16\u7801\u65b9\u5f0f\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u65b0\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u4e3a\u5b9a\u70b9\u6a21\u6001\u903b\u8f91\uff08FML\uff09\u548c\u8ba1\u7b97\u6811\u903b\u8f91*\uff08CTL*\uff09\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u5f62\u5f0f\u8bed\u4e49\u2014\u2014\u5ef6\u7eed\u8bed\u4e49\u3002\u5f53\u524d\u76f8\u5173\u903b\u8f91\u5728\u5904\u7406\u5206\u652f\u7c7b\u578b\u4e0e\u91cf\u5316\u8c13\u8bcd\u63d0\u5347\u65f6\u5b58\u5728\u4e00\u5b9a\u5c40\u9650\uff0c\u4f5c\u8005\u5e0c\u671b\u80fd\u7edf\u4e00\u548c\u63a8\u5e7f\u73b0\u6709\u7684\u8bed\u4e49\u6846\u67b6\u3002", "method": "\u4f5c\u8005\u57fa\u4e8e\u5ef6\u7eedMonad\u4e0a\u7684\u4e0a\u7164\u4ee3\u6570\uff08coalgebra\uff09\uff0c\u5b9a\u4e49\u4e86\u5ef6\u7eed\u8bed\u4e49\uff0c\u5e76\u5c06\u516c\u5f0f\u7684\u771f\u503c\u57df\u8bbe\u4e3a\u7b54\u6848\u7c7b\u578b\u3002\u901a\u8fc7\u5c06\u8c13\u8bcd\u4e0e\u5ef6\u7eed\u8fdb\u884c\u8bc6\u522b\uff0c\u8be5\u7164\u4ee3\u6570\u5b9e\u73b0\u4e86\u6a21\u6001\u6027\u7531\u5ef6\u7eed\u6c42\u503c\u6765\u89e3\u91ca\u3002\u968f\u540e\uff0c\u4f5c\u8005\u5c06CTL*\u7684\u7164\u4ee3\u6570\u8bed\u4e49\u8fdb\u884c\u91cd\u6784\uff0c\u5f15\u5165\u975e\u6700\u5927\u70b9\u7684\u6267\u884c\u56fe\uff08execution map\uff09\uff0c\u5e76\u8bc1\u660e\u4e86\u901a\u8fc7Monad\u6001\u5c04\u53ef\u4ee5\u8f6c\u79fb\u6267\u884c\u56fe\uff0c\u8fbe\u5230\u4e86\u5ef6\u7eed\u8bed\u4e49\u4e0e\u7164\u4ee3\u6570\u8bed\u4e49\u7684\u7b49\u4ef7\u3002", "result": "\u4f5c\u8005\u8bc1\u660e\u4e86FML\u548cCTL*\u7684\u5ef6\u7eed\u8bed\u4e49\u5728\u6240\u6709\u5206\u652f\u7c7b\u578b\u4e0b\u4e0e\u7164\u4ee3\u6570\u8bed\u4e49\u7b49\u4ef7\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u4e86CTL*\u7164\u4ee3\u6570\u6a21\u578b\u5141\u8bb8\u975e\u6700\u5927\u70b9\u6267\u884c\u56fe\u7684\u65b0\u6846\u67b6\uff0c\u5e76\u9488\u5bf9Monad\u6001\u5c04\u7ed9\u51fa\u6267\u884c\u56fe\u7684\u8f6c\u79fb\u7ed3\u679c\u3002\u6b64\u5916\u8fd8\u627e\u5230\u4e86\u4e00\u4e2a\u5145\u5206\u6761\u4ef6\uff0c\u53ef\u5c06CTL\u7f16\u7801\u5230FML\u7684\u5ef6\u7eed\u8bed\u4e49\u4e0b\u3002", "conclusion": "\u5ef6\u7eed\u8bed\u4e49\u4e3aFML\u548cCTL*\u63d0\u4f9b\u4e86\u65b0\u7684\u7edf\u4e00\u8bed\u4e49\u6846\u67b6\uff0c\u5e76\u5728\u5e7f\u4e49\u5206\u652f\u7ed3\u6784\u4e0b\u4e0e\u4f20\u7edf\u7164\u4ee3\u6570\u8bed\u4e49\u4fdd\u6301\u7b49\u4ef7\u3002\u63d0\u51fa\u7684\u65b0\u578bCTL*\u6a21\u578b\u66f4\u7075\u6d3b\uff0c\u6709\u52a9\u4e8e\u7406\u8bba\u63a8\u5e7f\u4e0e\u5e94\u7528\uff0c\u4e14\u4e3aCTL\u5411FML\u7684\u8bed\u4e49\u7f16\u7801\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2510.03490", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03490", "abs": "https://arxiv.org/abs/2510.03490", "authors": ["Aneesha Sampath", "Oya Aran", "Emily Mower Provost"], "title": "SEER: The Span-based Emotion Evidence Retrieval Benchmark", "comment": null, "summary": "We introduce the SEER (Span-based Emotion Evidence Retrieval) Benchmark to\ntest Large Language Models' (LLMs) ability to identify the specific spans of\ntext that express emotion. Unlike traditional emotion recognition tasks that\nassign a single label to an entire sentence, SEER targets the underexplored\ntask of emotion evidence detection: pinpointing which exact phrases convey\nemotion. This span-level approach is crucial for applications like empathetic\ndialogue and clinical support, which need to know how emotion is expressed, not\njust what the emotion is. SEER includes two tasks: identifying emotion evidence\nwithin a single sentence, and identifying evidence across a short passage of\nfive consecutive sentences. It contains new annotations for both emotion and\nemotion evidence on 1200 real-world sentences. We evaluate 14 open-source LLMs\nand find that, while some models approach average human performance on\nsingle-sentence inputs, their accuracy degrades in longer passages. Our error\nanalysis reveals key failure modes, including overreliance on emotion keywords\nand false positives in neutral text.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSEER\u57fa\u51c6\u7528\u4e8e\u8bc4\u6d4bLLM\u5b9a\u4f4d\u60c5\u611f\u8868\u8fbe\u7247\u6bb5\u7684\u80fd\u529b\uff0c\u6570\u636e\u96c6\u5305\u542b\u53e5\u5185\u548c\u8de8\u53e5\u4efb\u52a1\uff0c\u5e76\u5bf914\u4e2a\u6a21\u578b\u8fdb\u884c\u6548\u679c\u8bc4\u4f30\u3002\u7ed3\u679c\u663e\u793a\u6a21\u578b\u5728\u77ed\u53e5\u4efb\u52a1\u63a5\u8fd1\u4eba\u7c7b\uff0c\u4f46\u4e94\u53e5\u6bb5\u843d\u8868\u73b0\u660e\u663e\u9000\u6b65\uff0c\u5206\u6790\u6307\u51fa\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u5173\u952e\u8bcd\uff0c\u5bb9\u6613\u8bef\u5224\u3002", "motivation": "\u76ee\u524d\u5927\u591a\u6570\u60c5\u611f\u8bc6\u522b\u4efb\u52a1\u53ea\u5bf9\u6574\u4e2a\u53e5\u5b50\u8d4b\u4e88\u60c5\u611f\u6807\u7b7e\uff0c\u5374\u5f88\u5c11\u5173\u6ce8\u6587\u672c\u4e2d\u5177\u4f53\u54ea\u4e00\u90e8\u5206\u8868\u8fbe\u4e86\u60c5\u611f\u3002\u56e0\u6b64\uff0c\u9700\u8981\u63a8\u52a8\u60c5\u611f\u8bc1\u636e\u68c0\u6d4b\u8fd9\u4e00\u7ec6\u7c92\u5ea6\u4efb\u52a1\u7684\u53d1\u5c55\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u9700\u8981\u7406\u89e3\u60c5\u611f\u8868\u8fbe\u65b9\u5f0f\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u5982\u5171\u60c5\u5bf9\u8bdd\u4e0e\u4e34\u5e8a\u652f\u6301\u3002", "method": "\u63d0\u51fa\u4e86SEER\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u4e13\u95e8\u8bc4\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u53d1\u6398\u5e76\u5b9a\u4f4d\u6587\u672c\u4e2d\u5177\u4f53\u8868\u8fbe\u60c5\u611f\u7684\u7247\u6bb5\uff08span\uff09\u7684\u80fd\u529b\u3002SEER\u57fa\u51c6\u8bbe\u7acb\u4e24\u4e2a\u4efb\u52a1\uff1a\u53e5\u5185\u60c5\u611f\u8bc1\u636e\u8bc6\u522b\u548c\u8de8\u4e94\u53e5\u6bb5\u843d\u7684\u60c5\u611f\u8bc1\u636e\u8bc6\u522b\uff0c\u5e76\u4e3a1200\u6761\u771f\u5b9e\u8bed\u53e5\u6253\u4e0a\u60c5\u611f\u53ca\u8bc1\u636e\u6807\u6ce8\u3002", "result": "\u8bc4\u6d4b\u4e8614\u4e2a\u5f00\u6e90LLM\uff0c\u7ed3\u679c\u663e\u793a\uff1a\u5728\u5355\u53e5\u60c5\u611f\u8bc1\u636e\u8bc6\u522b\u4efb\u52a1\u4e0a\u90e8\u5206\u6a21\u578b\u63a5\u8fd1\u4eba\u7c7b\u5e73\u5747\u6c34\u5e73\uff0c\u4f46\u5728\u8f83\u957f\u6587\u672c\u6bb5\u843d\u4e0a\u8868\u73b0\u663e\u8457\u4e0b\u964d\u3002\u9519\u8bef\u5206\u6790\u663e\u793a\uff0c\u6a21\u578b\u5e38\u4f9d\u8d56\u60c5\u611f\u5173\u952e\u8bcd\uff0c\u4e14\u5728\u4e2d\u6027\u6587\u672c\u4e2d\u8bef\u62a5\u60c5\u611f\u3002", "conclusion": "SEER\u63a8\u52a8\u4e86\u60c5\u611f\u8bc1\u636e\u68c0\u6d4b\u9886\u57df\u53d1\u5c55\uff0c\u63ed\u793a\u4e86\u73b0\u6709LLMs\u5728\u60c5\u611f\u8868\u8fbe\u5b9a\u4f4d\u4e0a\u7684\u5c40\u9650\uff0c\u5c24\u5176\u5728\u66f4\u590d\u6742\u6587\u672c\u4e2d\u6613\u51fa\u9519\uff0c\u5bf9\u7cfb\u7edf\u6027\u6539\u8fdb\u6a21\u578b\u63d0\u51fa\u4e86\u9700\u6c42\u3002"}}
{"id": "2510.03712", "categories": ["cs.SE", "68M15, 90B25, 68T05, 90C29", "C.4; C.2.4; D.2.5; D.4.5"], "pdf": "https://arxiv.org/pdf/2510.03712", "abs": "https://arxiv.org/abs/2510.03712", "authors": ["Jahidul Arafat", "Kh. M. Moniruzzaman", "Shamim Hossain", "Fariha Tasmin", "Kamrujjaman", "Ahsan Habib Tareq"], "title": "Detecting and Preventing Latent Risk Accumulation in High-Performance Software Systems", "comment": "26 pages, 12 tables, 4 figures. Academic-industry collaboration.\n  Framework (HYDRA, RAVEN, APEX) for optimization-induced vulnerabilities.\n  Evaluated: 2,160 configs, 12.7TB data, 1,748 scenarios", "summary": "Modern distributed systems employ aggressive optimization strategies that\ncreate latent risks - hidden vulnerabilities where exceptional performance\nmasks catastrophic fragility when optimizations fail. Cache layers achieving\n99% hit rates can obscure database bottlenecks until cache failures trigger\n100x load amplification and cascading collapse. Current reliability engineering\nfocuses on reactive incident response rather than proactive detection of\noptimization-induced vulnerabilities. This paper presents the first\ncomprehensive framework for systematic latent risk detection, prevention, and\noptimization through integrated mathematical modeling, intelligent perturbation\ntesting, and risk-aware performance optimization. We introduce the Latent Risk\nIndex (LRI) that correlates strongly with incident severity (r=0.863, p<0.001),\nenabling predictive risk assessment. Our framework integrates three systems:\nHYDRA employing six optimization-aware perturbation strategies achieving 89.7%\nrisk discovery rates, RAVEN providing continuous production monitoring with\n92.9% precision and 93.8% recall across 1,748 scenarios, and APEX enabling\nrisk-aware optimization maintaining 96.6% baseline performance while reducing\nlatent risks by 59.2%. Evaluation across three testbed environments\ndemonstrates strong statistical validation with large effect sizes (Cohen\nd>2.0) and exceptional reproducibility (r>0.92). Production deployment over 24\nweeks shows 69.1% mean time to recovery reduction, 78.6% incident severity\nreduction, and 81 prevented incidents generating 1.44M USD average annual\nbenefits with 3.2-month ROI. Our approach transforms reliability engineering\nfrom reactive incident management to proactive risk-aware optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9762\u5411\u5206\u5e03\u5f0f\u7cfb\u7edf\u4f18\u5316\u5bfc\u81f4\u9690\u60a3\u7684\u7cfb\u7edf\u6027\u98ce\u9669\u68c0\u6d4b\u4e0e\u89c4\u907f\u6846\u67b6\uff0c\u6db5\u76d6\u5efa\u6a21\u3001\u6270\u52a8\u6d4b\u8bd5\u53ca\u98ce\u9669\u4f18\u5316\u4e09\u5927\u73af\u8282\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u5b9e\u9645\u4e0e\u6d4b\u8bd5\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u7387\u3001\u6781\u5f3a\u6536\u76ca\u548c\u53ef\u590d\u73b0\u6027\uff0c\u4e3a\u53ef\u9760\u6027\u5de5\u7a0b\u8f6c\u578b\u63d0\u4f9b\u4e86\u8def\u5f84\u3002", "motivation": "\u73b0\u6709\u5206\u5e03\u5f0f\u7cfb\u7edf\u4f9d\u8d56\u6fc0\u8fdb\u7684\u6027\u80fd\u4f18\u5316\u4f7f\u5f97\u9690\u6027\u8106\u5f31\u70b9\u88ab\u63a9\u76d6\uff0c\u53ef\u9760\u6027\u5de5\u7a0b\u5927\u591a\u4e3a\u4e8b\u540e\u54cd\u5e94\u800c\u975e\u4e8b\u524d\u4e3b\u52a8\u8bc6\u522b\uff0c\u4e9f\u9700\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u6765\u9884\u8b66\u3001\u89c4\u907f\u4f18\u5316\u8bf1\u5bfc\u7684\u6f5c\u5728\u98ce\u9669\u3002", "method": "\u6574\u5408\u6570\u5b66\u5efa\u6a21\u3001\u667a\u80fd\u6270\u52a8\u6d4b\u8bd5\u548c\u98ce\u9669\u611f\u77e5\u6027\u80fd\u4f18\u5316\u4e09\u79cd\u65b9\u6cd5\uff0c\u5f00\u53d1\u51faLRI\u6307\u6807\uff0c\u4ee5\u53caHYDRA\u3001RAVEN\u548cAPEX\u4e09\u4e2a\u7cfb\u7edf\uff0c\u5b9e\u73b0\u98ce\u9669\u9884\u6d4b\u3001\u76d1\u63a7\u4e0e\u4f18\u5316\u3002", "result": "\u8be5\u6846\u67b6\u901a\u8fc7HYDRA\u83b7\u5f9789.7%\u7684\u98ce\u9669\u53d1\u73b0\u7387\uff0cRAVEN\u5b9e\u73b092.9%\u7684\u7cbe\u5ea6\u4e0e93.8%\u7684\u53ec\u56de\u7387\uff0cAPEX\u5728\u4fdd\u630196.6%\u6027\u80fd\u57fa\u7ebf\u4e0b\u51cf\u5c1159.2%\u6f5c\u5728\u98ce\u9669\u300224\u5468\u751f\u4ea7\u73af\u5883\u90e8\u7f72\u5b9e\u73b069.1%\u6062\u590d\u65f6\u95f4\u4e0b\u964d\u300178.6%\u4e8b\u6545\u4e25\u91cd\u6027\u964d\u4f4e\u300181\u8d77\u4e8b\u6545\u907f\u514d\uff0c\u5e73\u5747\u5e74\u5316\u6536\u76ca\u8fbe144\u4e07\u7f8e\u5143\uff0c\u6295\u8d44\u56de\u62a53.2\u4e2a\u6708\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u5957\u9488\u5bf9\u73b0\u4ee3\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u4f18\u5316\u6240\u5e26\u6765\u7684\u6f5c\u5728\u98ce\u9669\u8fdb\u884c\u68c0\u6d4b\u3001\u9632\u8303\u548c\u4f18\u5316\u7684\u7efc\u5408\u6027\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u4e0e\u5b9e\u8bc1\u65b9\u6cd5\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u5728\u51c6\u786e\u53d1\u73b0\u548c\u51cf\u5c11\u7cfb\u7edf\u9690\u60a3\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.04716", "categories": ["cs.LO", "cs.AI", "cs.CC", "quant-ph", "68Q17, 68Q25", "F.1.1; F.2.2; I.2.3"], "pdf": "https://arxiv.org/pdf/2510.04716", "abs": "https://arxiv.org/abs/2510.04716", "authors": ["Maximilian R. P. von Liechtenstein"], "title": "Curved Boolean Logic: A Contextual Generalization of Propositional Logic with Algorithmic Consequences", "comment": "44 pages, 15 figures. Reproducible Colab notebook and params included\n  as ancillary files; all paper figures are generated by the notebook. v1", "summary": "Curved Boolean Logic (CBL) generalizes propositional logic by allowing local\ntruth assignments that do not extend to a single global valuation, analogous to\ncurvature in geometry. We give equivalent sheaf and exclusivity-graph semantics\nand a context-aware proof calculus that is conservative in the flat limit. We\nformalize CBL-SAT and basic complexity (NP-complete in general) and present\noperational operators (CBL-AC and CBL-CONS) that prune contradictions earlier\non classical hardware. We model noise with iid, AR(1)-correlated, and\nadversarial bounded perturbations and provide permutation-based significance\nwith Benjamini-Hochberg FDR control. A Colab-ready notebook (ancillary files)\nregenerates all figures and statistics. We position CBL relative to KCBS, CSW,\nand sheaf frameworks and outline links to SAT/CSP and robustness/adapter\nstability in large language models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u63a8\u5e7f\u7684\u66f2\u7387\u5e03\u5c14\u903b\u8f91\uff08CBL\uff09\uff0c\u5141\u8bb8\u5c40\u90e8\u771f\u503c\u65e0\u6cd5\u6269\u5c55\u4e3a\u5168\u5c40\u4e00\u81f4\u6027\uff0c\u7ed9\u51fa\u4e86\u76f8\u5173\u7406\u8bba\u3001\u590d\u6742\u6027\u5206\u6790\u3001\u526a\u679d\u7b97\u6cd5\u4e0e\u4ee3\u7801\u5b9e\u73b0\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e0e\u7ecf\u5178\u4e0e\u73b0\u4ee3\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u4e4b\u95f4\u7684\u8054\u7cfb\u53ca\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u4f20\u7edf\u7684\u547d\u9898\u903b\u8f91\u8981\u6c42\u6240\u6709\u771f\u503c\u8d4b\u503c\u5fc5\u987b\u80fd\u6269\u5c55\u4e3a\u4e00\u4e2a\u5168\u5c40\u4e00\u81f4\u7684\u8d4b\u503c\uff0c\u4f46\u5728\u8bb8\u591a\u5b9e\u9645\u60c5\u51b5\u6216\u590d\u6742\u7cfb\u7edf\u4e2d\uff0c\u8fd9\u79cd\u5168\u5c40\u4e00\u81f4\u6027\u5f80\u5f80\u4e0d\u80fd\u4fdd\u8bc1\u3002\u8be5\u8bba\u6587\u65e8\u5728\u63a8\u5e7f\u8fd9\u79cd\u903b\u8f91\u6846\u67b6\uff0c\u5f15\u5165\u7c7b\u4f3c\u4e8e\u51e0\u4f55\u66f2\u7387\u7684\u601d\u60f3\uff0c\u5141\u8bb8\u5c40\u90e8\u7684\u771f\u503c\u5206\u914d\u65e0\u6cd5\u5ef6\u4f38\u4e3a\u6574\u4f53\u4e00\u81f4\u7684\u89e3\uff0c\u4ece\u800c\u6269\u5c55\u903b\u8f91\u7cfb\u7edf\u7684\u8868\u8fbe\u4e0e\u5efa\u6a21\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86Curved Boolean Logic\uff08CBL\uff09\uff0c\u5e76\u7ed9\u51fa\u4e86\u7b49\u4ef7\u7684\u5c42\u6790\uff08sheaf\uff09\u8bed\u4e49\u4e0e\u6392\u65a5\u56fe\uff08exclusivity-graph\uff09\u8bed\u4e49\u3002\u540c\u65f6\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u8bc1\u660e\u6f14\u7b97\uff0c\u8be5\u6f14\u7b97\u5728\u5c40\u90e8\u4e00\u81f4\u9000\u5316\u4e3a\u4f20\u7edf\u903b\u8f91\u3002\u6b63\u5f0f\u5b9a\u4e49\u4e86CBL\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\uff08CBL-SAT\uff09\uff0c\u5bf9\u5176\u590d\u6742\u6027\u8fdb\u884c\u4e86\u5206\u6790\uff08\u603b\u4f53\u4e3aNP-\u5b8c\u5168\uff09\u3002\u63d0\u51fa\u4e86\u4e24\u79cd\u8fd0\u7b97\u7b26\uff08CBL-AC\u548cCBL-CONS\uff09\uff0c\u80fd\u66f4\u65e9\u5728\u7ecf\u5178\u786c\u4ef6\u4e0a\u526a\u679d\u77db\u76fe\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86\u566a\u58f0\u5efa\u6a21\uff08\u72ec\u7acb\u540c\u5206\u5e03\u3001AR(1)\u76f8\u5173\u3001\u5bf9\u6297\u6027\u6709\u754c\u6270\u52a8\uff09\uff0c\u91c7\u7528\u57fa\u4e8e\u6392\u5217\u68c0\u9a8c\u7684\u65b9\u6cd5\u548cBenjamini-Hochberg\u5047\u53d1\u73b0\u7387\u63a7\u5236\u8fdb\u884c\u7edf\u8ba1\u663e\u8457\u6027\u5206\u6790\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u4ee3\u7801\u548c\u8f85\u52a9\u6750\u6599\u3002", "result": "CBL\u6846\u67b6\u5728\u7406\u8bba\u4e0a\u63a8\u5e7f\u4e86\u547d\u9898\u903b\u8f91\uff0c\u80fd\u66f4\u6709\u6548\u5730\u8868\u8ff0\u5c40\u90e8\u4e00\u81f4\u4f46\u5168\u5c40\u4e0d\u4e00\u81f4\u7684\u60c5\u666f\u3002\u65b9\u6cd5\u5728\u7ecf\u5178\u786c\u4ef6\u4e0a\u63d0\u5347\u4e86\u526a\u679d\u6548\u7387\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u5c55\u793a\u4e86\u8be5\u6a21\u578b\u4e0eKCBS\u3001CSW\u3001\u5c42\u6790\u6846\u67b6\u3001\u53ef\u6ee1\u8db3\u6027/\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\uff08SAT/CSP\uff09\u4ee5\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u9c81\u68d2\u6027\u548c\u9002\u914d\u5668\u7a33\u5b9a\u6027\u7684\u5173\u7cfb\u548c\u5e94\u7528\u524d\u666f\u3002", "conclusion": "\u8be5\u8bba\u6587\u4e3a\u63a8\u5e7f\u548c\u5e94\u7528\u547d\u9898\u903b\u8f91\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u4f7f\u5176\u53ef\u63cf\u8ff0\u66f4\u5e7f\u6cdb\u7684\u590d\u6742\u7cfb\u7edf\u5c40\u90e8\u4e0e\u5168\u5c40\u4e0d\u4e00\u81f4\u6027\uff0c\u4e3aSAT/CSP\u6c42\u89e3\u4f18\u5316\u3001\u5927\u6a21\u578b\u9c81\u68d2\u6027\u5206\u6790\u7b49\u65b9\u5411\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0e\u5de5\u5177\u57fa\u7840\u3002CBL\u5728\u7406\u8bba\u4e0e\u5b9e\u9645\u8ba1\u7b97\u4e2d\u5177\u6709\u91cd\u8981\u524d\u666f\u3002"}}
{"id": "2510.03502", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.03502", "abs": "https://arxiv.org/abs/2510.03502", "authors": ["Ali Khairallah", "Arkaitz Zubiaga"], "title": "ALHD: A Large-Scale and Multigenre Benchmark Dataset for Arabic LLM-Generated Text Detection", "comment": "47 pages, 15 figures. Dataset available at Zenodo:\n  https://doi.org/10.5281/zenodo.17249602 Codebase available at GitHub:\n  https://github.com/alikhairallah/ALHD-Benchmarking", "summary": "We introduce ALHD, the first large-scale comprehensive Arabic dataset\nexplicitly designed to distinguish between human- and LLM-generated texts. ALHD\nspans three genres (news, social media, reviews), covering both MSA and\ndialectal Arabic, and contains over 400K balanced samples generated by three\nleading LLMs and originated from multiple human sources, which enables studying\ngeneralizability in Arabic LLM-genearted text detection. We provide rigorous\npreprocessing, rich annotations, and standardized balanced splits to support\nreproducibility. In addition, we present, analyze and discuss benchmark\nexperiments using our new dataset, in turn identifying gaps and proposing\nfuture research directions. Benchmarking across traditional classifiers,\nBERT-based models, and LLMs (zero-shot and few-shot) demonstrates that\nfine-tuned BERT models achieve competitive performance, outperforming LLM-based\nmodels. Results are however not always consistent, as we observe challenges\nwhen generalizing across genres; indeed, models struggle to generalize when\nthey need to deal with unseen patterns in cross-genre settings, and these\nchallenges are particularly prominent when dealing with news articles, where\nLLM-generated texts resemble human texts in style, which opens up avenues for\nfuture research. ALHD establishes a foundation for research related to Arabic\nLLM-detection and mitigating risks of misinformation, academic dishonesty, and\ncyber threats.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u5927\u89c4\u6a21\u963f\u62c9\u4f2f\u8bed\u4eba\u7c7b\u4e0eLLM\u6587\u672c\u533a\u5206\u6570\u636e\u96c6ALHD\uff0c\u57fa\u4e8e\u591a\u6a21\u578b\u57fa\u7ebf\u5b9e\u9a8c\uff0c\u53d1\u73b0BERT\u6548\u679c\u8f83\u597d\u4f46\u8de8\u9886\u57df\u6027\u80fd\u4ecd\u6709\u9650\uff0c\u5c24\u5176\u5728\u65b0\u95fb\u9886\u57df\uff0c\u672a\u6765\u9700\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u4ee5\u5e94\u5bf9\u5b9e\u9645\u5e94\u7528\u6311\u6218\u3002", "motivation": "\u5f53\u524d\u963f\u62c9\u4f2f\u8bed\u9886\u57df\u7f3a\u4e4f\u7528\u4e8e\u533a\u5206\u4eba\u7c7b\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u6587\u672c\u7684\u9ad8\u8d28\u91cf\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u9650\u5236\u4e86\u76f8\u5173\u68c0\u6d4b\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u7684\u8fdb\u5c55\u3002", "method": "\u6784\u5efa\u5e76\u53d1\u5e03\u4e86ALHD\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u65b0\u95fb\u3001\u793e\u4ea4\u5a92\u4f53\u3001\u8bc4\u8bba\u4e09\u5927\u6587\u672c\u7c7b\u578b\uff0c\u5305\u542b\u6807\u51c6\u963f\u62c9\u4f2f\u8bed\u4e0e\u65b9\u8a00\u7248\u672c\uff0c\u603b\u8ba140\u4e07\u5747\u8861\u6837\u672c\uff08\u7531\u9886\u5148LLM\u751f\u6210\u548c\u591a\u6e90\u771f\u5b9e\u4eba\u7c7b\u6587\u672c\uff09\uff0c\u5e76\u63d0\u4f9b\u8be6\u7ec6\u9884\u5904\u7406\u3001\u6807\u6ce8\u4e0e\u6807\u51c6\u5206\u5272\u3002\u4f7f\u7528\u4f20\u7edf\u5206\u7c7b\u5668\u3001BERT\u6a21\u578b\u548cLLM\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5fae\u8c03\u540e\u7684BERT\u6a21\u578b\u5728\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u8d85\u8fc7\u4e86\u76f4\u63a5\u7528LLM\u8fdb\u884c\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u63a8\u65ad\u7684\u6548\u679c\uff1b\u4f46\u8de8\u9886\u57df\uff08\u5982\u4e0d\u540c\u6587\u672c\u7c7b\u578b\uff09\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u5c24\u5176\u5728\u65b0\u95fb\u6587\u672c\u6d4b\u8bd5\u4e2d\uff0cLLM\u751f\u6210\u6587\u98ce\u4e0e\u4eba\u7c7b\u6781\u4e3a\u76f8\u4f3c\uff0c\u6a21\u578b\u5206\u8fa8\u56f0\u96be\u3002", "conclusion": "ALHD\u6570\u636e\u96c6\u4e3a\u963f\u62c9\u4f2f\u8bedLLM\u6587\u672c\u68c0\u6d4b\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u5bf9\u5e94\u7684\u57fa\u7ebf\u5b9e\u9a8c\u63ed\u793a\u4e86\u76ee\u524d\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u5e76\u4e3a\u672a\u6765\u63d0\u5347\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3001\u6253\u51fb\u865a\u5047\u4fe1\u606f\u548c\u9632\u8303\u5b66\u672f\u4e0d\u7aef\u53ca\u7f51\u7edc\u5a01\u80c1\u6307\u660e\u4e86\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2510.03743", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.03743", "abs": "https://arxiv.org/abs/2510.03743", "authors": ["Zachary Eberhart", "Collin McMillan"], "title": "APIDA-Chat: Structured Synthesis of API Search Dialogues to Bootstrap Conversational Agents", "comment": "4 pages, 2 figures. To be published in Proceedings of the 40th\n  IEEE/ACM International Conference on Automated Software Engineering", "summary": "Large-language-model assistants are suitable for explaining popular APIs, yet\nthey falter on niche or proprietary libraries because the multi-turn dialogue\ndata needed for fine-tuning are scarce. We present APIDA-Chat, an open-source\npipeline that converts symbolic dialogue-act \"scripts\" into realistic,\ndomain-grounded API Search conversations using a lightweight model for\ninexpensive training data generation. Phase I pairs a legacy dialogue planner\nwith a high-capability teacher LLM (o4-mini) to synthesize a \"gold set\" of\nrealized dialogues; then, a smaller Llama 3.2 3B student model is fine-tuned on\nthis corpus. Phase II drops the teacher and reuses the same planner with the\nfine-tuned model, allowing rapid, low-cost synthesis of new dialogues without\nexposing source code to external services. The fine-tuned student improves BLEU\nfrom 0.38 to 0.50 and BERTScore from 0.88 to 0.91 versus the base model while\nrunning entirely on a single consumer GPU. All components are modular and\npublicly released to serve as a conservative baseline for future work.\nAPIDA-Chat is open-sourced at https://github.com/Zeberhart/apida-chat and a\nvideo demo is available at https://youtu.be/YqmZBHyGbPs .", "AI": {"tldr": "APIDA-Chat\u662f\u4e00\u6761\u81ea\u52a8\u751f\u6210API\u5bf9\u8bdd\u6570\u636e\u7684\u5f00\u6e90\u6d41\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u5c0f\u6a21\u578b\u5bf9\u5c0f\u4f17API\u7684\u7406\u89e3\u4e0e\u89e3\u91ca\u80fd\u529b\uff0c\u65e0\u987b\u4f9d\u8d56\u6602\u8d35\u7b97\u529b\u6216\u5916\u90e8\u670d\u52a1\u3002", "motivation": "\u76ee\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5584\u4e8e\u89e3\u91ca\u4e3b\u6d41API\uff0c\u4f46\u9762\u5bf9\u51b7\u95e8\u6216\u4e13\u6709\u5e93\u65f6\uff0c\u7531\u4e8e\u7f3a\u4e4f\u4e30\u5bcc\u7684\u591a\u8f6e\u5bf9\u8bdd\u5fae\u8c03\u6570\u636e\uff0c\u6548\u679c\u8f83\u5dee\u3002\u8be5\u5de5\u4f5c\u65e8\u5728\u89e3\u51b3\u9488\u5bf9\u4f4e\u8d44\u6e90API\u9886\u57df\u7684\u5bf9\u8bdd\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002", "method": "\u63d0\u51faAPIDA-Chat\u6d41\u7a0b\u3002\u7b2c\u4e00\u9636\u6bb5\uff0c\u5229\u7528\u4f20\u7edf\u5bf9\u8bdd\u89c4\u5212\u5668\u4e0e\u9ad8\u6027\u80fdLLM\uff08o4-mini\uff09\u534f\u540c\u751f\u6210\u9ad8\u8d28\u91cf\u5bf9\u8bdd\uff0c\u518d\u7528\u5c0f\u6a21\u578b\uff08Llama 3.2 3B\uff09\u5fae\u8c03\u5f97\u5230\u5b66\u751f\u6a21\u578b\u3002\u7b2c\u4e8c\u9636\u6bb5\uff0c\u4f7f\u7528\u7ecf\u8fc7\u5fae\u8c03\u7684\u5b66\u751f\u6a21\u578b\u4e0e\u539f\u89c4\u5212\u5668\u5feb\u901f\u751f\u6210\u65b0\u5bf9\u8bdd\uff0c\u65e0\u9700\u66b4\u9732\u6e90\u4ee3\u7801\u6216\u8c03\u7528\u5916\u90e8\u670d\u52a1\u3002", "result": "\u5fae\u8c03\u540e\u6a21\u578bBLEU\u75310.38\u63d0\u5347\u52300.50\uff0cBERTScore\u75310.88\u63d0\u5347\u52300.91\uff1b\u5168\u90e8\u6d41\u7a0b\u53ef\u5728\u6d88\u8d39\u7ea7GPU\u4e0a\u8fd0\u884c\uff0c\u7cfb\u7edf\u5f00\u6e90\u5e76\u652f\u6301\u7075\u6d3b\u6269\u5c55\u3002", "conclusion": "APIDA-Chat\u5b9e\u73b0\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u4f4e\u6210\u672c\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u9886\u57df\u76f8\u5173\u7684API\u5bf9\u8bdd\u6570\u636e\uff0c\u663e\u8457\u6539\u5584\u5c0f\u6a21\u578b\u5728\u89e3\u91ca\u5c0f\u4f17\u6216\u79c1\u6709API\u65f6\u7684\u80fd\u529b\u3002"}}
{"id": "2510.05032", "categories": ["cs.LO", "math.CT", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.05032", "abs": "https://arxiv.org/abs/2510.05032", "authors": ["Chris Heunen", "Robin Kaarsgaard", "Louis Lemonnier"], "title": "One rig to control them all", "comment": null, "summary": "We introduce a theory for computational control, consisting of seven\nnaturally interpretable equations. Adding these to a prop of base circuits\nconstructs controlled circuits, borne out in examples of reversible Boolean\ncircuits and quantum circuits. We prove that this syntactic construction\nsemantically corresponds to taking the free rig category on the base prop.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7531\u4e03\u4e2a\u65b9\u7a0b\u7ec4\u6210\u7684\u8ba1\u7b97\u63a7\u5236\u7406\u8bba\uff0c\u80fd\u591f\u7edf\u4e00\u63cf\u8ff0\u53d7\u63a7\u7535\u8def\uff0c\u5e76\u8bc1\u660e\u5176\u4e0e\u5df2\u77e5\u8303\u7574\u7ed3\u6784\u7b49\u4ef7\uff0c\u63a8\u52a8\u4e86\u91cf\u5b50\u7535\u8def\u7b49\u9886\u57df\u7684\u7406\u8bba\u53d1\u5c55\u3002", "motivation": "\u53d7\u63a7\u7535\u8def\u5728\u53ef\u9006\u8ba1\u7b97\u548c\u91cf\u5b50\u8ba1\u7b97\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u73b0\u6709\u7406\u8bba\u5c1a\u7f3a\u4e4f\u7edf\u4e00\u3001\u53ef\u89e3\u91ca\u7684\u4ee3\u6570\u7ed3\u6784\u6765\u63cf\u8ff0\u53d7\u63a7\u7535\u8def\u7684\u6784\u9020\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u4e00\u5957\u65b9\u7a0b\u4e3a\u8ba1\u7b97\u63a7\u5236\u63d0\u4f9b\u901a\u7528\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u63d0\u51fa\u4e86\u4e03\u4e2a\u53ef\u89e3\u91ca\u7684\u65b9\u7a0b\u6765\u6784\u5efa\u8ba1\u7b97\u63a7\u5236\u7406\u8bba\uff0c\u8fd9\u4e9b\u65b9\u7a0b\u53ef\u4ee5\u52a0\u5165\u5230\u57fa\u672c\u7535\u8def\u7684\u6846\u67b6\uff08prop\uff09\u4e2d\uff0c\u4ee5\u6784\u5efa\u53d7\u63a7\u7535\u8def\u3002\u4f5c\u8005\u901a\u8fc7\u53cd\u5411\u5e03\u5c14\u7535\u8def\u548c\u91cf\u5b50\u7535\u8def\u7684\u4f8b\u5b50\u5c55\u73b0\u4e86\u8be5\u65b9\u6cd5\u3002\u6700\u540e\uff0c\u8bc1\u660e\u4e86\u8be5\u6784\u9020\u5728\u8bed\u4e49\u4e0a\u7b49\u4ef7\u4e8e\u5728\u57fa\u672c\u6846\u67b6\u4e0a\u53d6\u81ea\u7531rig\u8303\u7574\u3002", "result": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u5957\u7531\u4e03\u4e2a\u65b9\u7a0b\u7ec4\u6210\u7684\u7406\u8bba\u4f53\u7cfb\uff0c\u5e76\u7528\u5176\u6210\u529f\u63cf\u8ff0\u4e86\u53d7\u63a7\u5e03\u5c14\u7535\u8def\u548c\u91cf\u5b50\u7535\u8def\u3002\u6240\u63d0\u51fa\u7684\u6784\u9020\u4e0e\u81ea\u7531rig\u8303\u7574\u5728\u8bed\u4e49\u4e0a\u662f\u7b49\u4ef7\u7684\u3002", "conclusion": "\u672c\u6587\u4e3a\u53d7\u63a7\u7535\u8def\u7684\u8ba1\u7b97\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u4ee3\u6570\u7ed3\u6784\uff0c\u5e76\u8bc1\u660e\u4e86\u8be5\u7ed3\u6784\u4e0e\u81ea\u7531rig\u8303\u7574\u7684\u8bed\u4e49\u5bf9\u5e94\uff0c\u4e3a\u540e\u7eed\u7406\u8bba\u548c\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.03519", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03519", "abs": "https://arxiv.org/abs/2510.03519", "authors": ["Fangxu Yu", "Hongyu Zhao", "Tianyi Zhou"], "title": "TS-Reasoner: Aligning Time Series Foundation Models with LLM Reasoning", "comment": null, "summary": "Time series reasoning is crucial to decision-making in diverse domains,\nincluding finance, energy usage, traffic, weather, and scientific discovery.\nWhile existing time series foundation models (TSFMs) can capture low-level\ndynamic patterns and provide accurate forecasting, further analysis usually\nrequires additional background knowledge and sophisticated reasoning, which are\nlacking in most TSFMs but can be achieved through large language models (LLMs).\nOn the other hand, without expensive post-training, LLMs often struggle with\nthe numerical understanding of time series data. Although it is intuitive to\nintegrate the two types of models, developing effective training recipes that\nalign the two modalities for reasoning tasks is still an open challenge. To\nthis end, we propose TS-Reasoner that aligns the latent representations of\nTSFMs with the textual inputs of LLMs for downstream understanding/reasoning\ntasks. Specifically, we propose a simple yet effective method to curate\ndiverse, synthetic pairs of time series and textual captions for alignment\ntraining. We then develop a two-stage training recipe that applies instruction\nfinetuning after the alignment pretraining. Unlike existing works that train an\nLLM to take time series as inputs, we leverage a pretrained TSFM and freeze it\nduring training. Extensive experiments on several benchmarks demonstrate that\nTS-Reasoner not only outperforms a wide range of prevailing LLMs, Vision\nLanguage Models (VLMs), and Time Series LLMs, but also achieves this with\nremarkable data efficiency, e.g., using less than half the training data.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86TS-Reasoner\uff0c\u4e00\u79cd\u7ed3\u5408\u51bb\u7ed3\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u67b6\u6784\uff0c\u901a\u8fc7\u5408\u6210\u591a\u6a21\u6001\u5bf9\u9f50\u548c\u5206\u9636\u6bb5\u8bad\u7ec3\uff0c\u5728\u591a\u9879\u65f6\u95f4\u5e8f\u5217\u7406\u89e3\u4e0e\u63a8\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u4e14\u9ad8\u6548\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff08TSFMs\uff09\u867d\u7136\u64c5\u957f\u6355\u6349\u52a8\u6001\u6a21\u5f0f\uff0c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u9884\u6d4b\uff0c\u4f46\u5bf9\u4e8e\u66f4\u9ad8\u5c42\u6b21\u7684\u5206\u6790\u548c\u63a8\u7406\u8fd8\u4f9d\u8d56\u4e8e\u4e30\u5bcc\u80cc\u666f\u77e5\u8bc6\u548c\u590d\u6742\u63a8\u7406\u80fd\u529b\u2014\u2014\u8fd9\u4e9b\u662fTSFMs\u7f3a\u4e4f\u4e14LLMs\u64c5\u957f\u7684\u90e8\u5206\u3002\u7136\u800c\uff0cLLMs\u5728\u6ca1\u6709\u989d\u5916\u6602\u8d35\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u5bf9\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u6570\u503c\u7406\u89e3\u8f83\u5f31\u3002\u56e0\u6b64\uff0c\u5982\u4f55\u6709\u6548\u878d\u5408\u4e24\u8005\u80fd\u529b\u5e76\u8bad\u7ec3\u5bf9\u9f50\u5176\u591a\u6a21\u6001\u7279\u5f81\u6210\u4e3a\u4e00\u9879\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86TS-Reasoner\uff0c\u901a\u8fc7\u751f\u6210\u591a\u6837\u5316\u7684\u5408\u6210\u65f6\u95f4\u5e8f\u5217\u548c\u6587\u672c\u63cf\u8ff0\u5bf9\uff0c\u8fdb\u884c\u5bf9\u9f50\u8bad\u7ec3\u3002\u8be5\u65b9\u6cd5\u5305\u62ec\u4e24\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\u2014\u2014\u9996\u5148\u8fdb\u884c\u5bf9\u9f50\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u8fdb\u884c\u6307\u4ee4\u5fae\u8c03\u3002\u4e0d\u540c\u4e8e\u4ee5\u5f80\u76f4\u63a5\u8ba9LLM\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u8f93\u5165\u7684\u505a\u6cd5\uff0c\u8fd9\u91cc\u5229\u7528\u9884\u8bad\u7ec3\u597d\u7684TSFM\u5e76\u5728\u8bad\u7ec3\u4e2d\u51bb\u7ed3\u5176\u53c2\u6570\uff0c\u53ea\u4f18\u5316\u751f\u6210\u7684\u5bf9\u9f50\u6620\u5c04\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cTS-Reasoner\u4e0d\u4ec5\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u4e3b\u6d41LLMs\u3001\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u4ee5\u53ca\u65f6\u95f4\u5e8f\u5217LLMs\uff0c\u800c\u4e14\u5728\u6570\u636e\u5229\u7528\u7387\u4e0a\u8868\u73b0\u66f4\u4f73\uff0c\u80fd\u7528\u4e0d\u5230\u4e00\u534a\u7684\u8bad\u7ec3\u6570\u636e\u8fbe\u5230\u66f4\u597d\u6548\u679c\u3002", "conclusion": "TS-Reasoner\u6709\u6548\u5730\u5c06TSFM\u4e0eLLM\u7ed3\u5408\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u5bf9\u9f50\u8bad\u7ec3\u548c\u6307\u4ee4\u5fae\u8c03\u7b56\u7565\uff0c\u5728\u65f6\u95f4\u5e8f\u5217\u7406\u89e3\u4e0e\u63a8\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u9886\u5148\u7684\u6548\u679c\uff0c\u5e76\u4e14\u5927\u5e45\u63d0\u5347\u4e86\u8bad\u7ec3\u6570\u636e\u5229\u7528\u6548\u7387\u3002"}}
{"id": "2510.03755", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03755", "abs": "https://arxiv.org/abs/2510.03755", "authors": ["Roham Koohestani", "Parham Bateni", "Aydin Ebrahimi", "Behdad Etezadi", "Kiarash Karimi", "Maliheh Izadi"], "title": "Code4MeV2: a Research-oriented Code-completion Platform", "comment": "Under review for submission at a conference", "summary": "The adoption of AI-powered code completion tools in software development has\nincreased substantially, yet the user interaction data produced by these\nsystems remain proprietary within large corporations. This creates a barrier\nfor the academic community, as researchers must often develop dedicated\nplatforms to conduct studies on human--AI interaction, making reproducible\nresearch and large-scale data analysis impractical. In this work, we introduce\nCode4MeV2, a research-oriented, open-source code completion plugin for\nJetBrains IDEs, as a solution to this limitation. Code4MeV2 is designed using a\nclient--server architecture and features inline code completion and a\ncontext-aware chat assistant. Its core contribution is a modular and\ntransparent data collection framework that gives researchers fine-grained\ncontrol over telemetry and context gathering. Code4MeV2 achieves\nindustry-comparable performance in terms of code completion, with an average\nlatency of 200~ms. We assess our tool through a combination of an expert\nevaluation and a user study with eight participants. Feedback from both\nresearchers and daily users highlights its informativeness and usefulness. We\ninvite the community to adopt and contribute to this tool. More information\nabout the tool can be found at https://app.code4me.me.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u5f00\u6e90\u63d2\u4ef6 Code4MeV2\uff0c\u4e3a\u5b66\u672f\u754c\u63d0\u4f9b\u4e86\u4e1a\u754c\u6c34\u5e73\u7684\u4ee3\u7801\u8865\u5168\u548c\u6570\u636e\u91c7\u96c6\u80fd\u529b\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u4e13\u6709\u5de5\u5177\u5e26\u6765\u7684\u6570\u636e\u58c1\u5792\uff0c\u9884\u671f\u5c06\u4fc3\u8fdb\u4eba\u673a\u534f\u4f5c\u76f8\u5173\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41 AI \u4ee3\u7801\u8865\u5168\u5de5\u5177\u7684\u6570\u636e\u4ecd\u88ab\u5927\u516c\u53f8\u5784\u65ad\uff0c\u5b66\u672f\u754c\u96be\u4ee5\u83b7\u5f97\u4ea4\u4e92\u6570\u636e\uff0c\u963b\u788d\u4e86\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u548c\u5927\u89c4\u6a21\u6570\u636e\u5206\u6790\u3002", "method": "\u6587\u7ae0\u4ecb\u7ecd\u4e86 Code4MeV2 \u7684\u67b6\u6784\u8bbe\u8ba1\uff08\u5ba2\u6237\u7aef-\u670d\u52a1\u5668\uff09\u3001\u4e3b\u8981\u529f\u80fd\uff08\u5185\u8054\u4ee3\u7801\u8865\u5168\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u804a\u5929\u52a9\u624b\uff09\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u8bc4\u4f30\u548c\u516b\u4f4d\u53c2\u4e0e\u8005\u7684\u7528\u6237\u7814\u7a76\u5bf9\u5de5\u5177\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002", "result": "Code4MeV2 \u80fd\u5b9e\u73b0\u7ea6 200 \u6beb\u79d2\u7684\u4ee3\u7801\u8865\u5168\u5ef6\u8fdf\uff0c\u529f\u80fd\u5b9e\u7528\uff0c\u6536\u96c6\u53cd\u9988\u663e\u793a\u5de5\u5177\u7684\u4fe1\u606f\u91cf\u548c\u6709\u7528\u6027\u8f83\u9ad8\u3002", "conclusion": "Code4MeV2 \u662f\u4e00\u4e2a\u5f00\u6e90\u3001\u9762\u5411\u7814\u7a76\u7684\u4ee3\u7801\u8865\u5168\u63d2\u4ef6\uff0c\u80fd\u652f\u6301 JetBrains IDE\uff0c\u5177\u6709\u4e0e\u4e1a\u754c\u6c34\u5e73\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u63d0\u4f9b\u4e86\u7ec6\u7c92\u5ea6\u3001\u900f\u660e\u7684\u6570\u636e\u6536\u96c6\u6846\u67b6\uff0c\u5f97\u5230\u4e86\u4e13\u5bb6\u548c\u7528\u6237\u7684\u79ef\u6781\u53cd\u9988\u3002"}}
