<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]
- [cs.SE](#cs.SE) [Total: 5]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.CL](#cs.CL) [Total: 5]
- [cs.DM](#cs.DM) [Total: 4]
- [cs.FL](#cs.FL) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [From Tool Calling to Symbolic Thinking: LLMs in a Persistent Lisp Metaprogramming Loop](https://arxiv.org/abs/2506.10021)
*Jordi de la Torre*

Main category: cs.PL

TL;DR: 作者提出了一种把大语言模型和Lisp交互环境深度融合的新方法，使模型具备动态工具生成和反思能力，并为将神经模型与符号编程结合的AI系统设计提供了新框架。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）在交互式、持续性编程环境中的集成尚未完善，特别是在工具创建和动态反思上的能力有限。作者希望通过结合Lisp环境，挖掘神经语言模型与符号编程融合的潜力。

Method: 提出一种新架构，将LLMs与Lisp的持久、交互式环境结合。通过在生成过程中嵌入Lisp表达式，并借助中间件拦截，实现LLM可以编写、调用并进化自身工具，可支持有状态的外部记忆、反思式编程和动态工具创建。

Result: 实现了一个系统框架，使LLM能动态和可编程地扩展自身能力，并通过实例展示符号编程与神经生成模型集成带来的新功能。还提出了设计原则，指导未来类似系统的开发。

Conclusion: 将LLMs与交互式Lisp环境结合，可以显著增强AI系统的灵活性和工具创建能力。该架构为神经语言生成与符号编程融合提供了新途径，为开发更强大的交互式AI系统开启了方向。

Abstract: We propose a novel architecture for integrating large language models (LLMs)
with a persistent, interactive Lisp environment. This setup enables LLMs to
define, invoke, and evolve their own tools through programmatic interaction
with a live REPL. By embedding Lisp expressions within generation and
intercepting them via a middleware layer, the system allows for stateful
external memory, reflective programming, and dynamic tool creation. We present
a design framework and architectural principles to guide future implementations
of interactive AI systems that integrate symbolic programming with neural
language generation.

</details>


### [2] [A Language-Agnostic Logical Relation for Message-Passing Protocols](https://arxiv.org/abs/2506.10026)
*Tesla Zhang,Sonya Simkin,Rui Li,Yue Yao,Stephanie Balzer*

Main category: cs.PL

TL;DR: 本论文提出了支持异构、无类型系统的消息传递协议合规性验证框架，首次实现了语言无关的逻辑关系机械化，并在Coq中验证了其实用性。


<details>
  <summary>Details</summary>
Motivation: 当今计算领域正逐渐转向针对分布式和异构系统（如云计算与物联网）的应用，这些应用普遍采用并发、消息传递，并与外部对象（如传感器或外部代码）交互。由于缺乏统一的实现语言与类型系统，传统的协议验证方法已不再适用，因此迫切需要开发新的协议合规性验证方法。

Method: 本文提出了一个用于认证异构消息传递系统协议合规性的框架，首次实现了一种语言无关的逻辑关系（logical relation）机械化，完全基于带标签迁移的语义，能够适用于有类型、无类型甚至‘外部对象’的组件。该方法在Coq定理证明器中实现，并以具体应用或设备的实例验证与整个类型系统下有类型应用的全局验证为案例。

Result: 框架能够认证复杂异构消息传递系统遵循协议，成功在Coq中机械化，并通过两个场景（实例级和系统级）验证了方法的适用性。

Conclusion: 作者提出的方法可以打破实现语言和类型系统的限制，实现对异构分布式系统协议合规性的形式化和可机械化验证，为更广泛的系统交互安全与正确性验证提供方法论支持。

Abstract: Today's computing landscape has been gradually shifting to applications
targeting distributed and *heterogeneous* systems, such as cloud computing and
Internet of Things (IoT) applications. These applications are predominantly
*concurrent*, employ *message-passing*, and interface with *foreign objects*,
ranging from externally implemented code to actual physical devices such as
sensors. Verifying that the resulting systems adhere to the intended protocol
of interaction is challenging -- the usual assumption of a common
implementation language, let alone a type system, no longer applies, ruling out
any verification method based on them. This paper develops a framework for
certifying *protocol compliance* of heterogeneous message-passing systems. It
contributes the first mechanization of a *language-agnostic logical relation*,
asserting that its inhabitants comply with the protocol specified. This
definition relies entirely on a labelled transition-based semantics,
accommodating arbitrary inhabitants, typed and untyped alike, including foreign
objects. As a case study, the paper considers two scenarios: (1) *per-instance
verification* of a specific application or hardware device, and (2)
*once-and-for-all verification* of well-typed applications for a given type
system. The logical relation and both scenarios are mechanized in the Coq
theorem prover.

</details>


### [3] [Hazel Deriver: A Live Editor for Constructing Rule-Based Derivations](https://arxiv.org/abs/2506.10781)
*Zhiyao Zhong,Cyrus Omar*

Main category: cs.PL

TL;DR: 提出了Hazel Deriver在线工具，有效帮助学生掌握推理树构造，并提升学习体验和理解。


<details>
  <summary>Details</summary>
Motivation: 学生在编程语言和形式逻辑课程中，常因推理规则复杂、缺乏即时反馈、手写证明过程繁琐而难以构建推理树。

Method: 提出了一种基于Web的实时编辑器Hazel Deriver，依托Hazel编程环境，通过分层支撑机制和结构化、互动体验，帮助学生逐步探索并得到实时反馈。

Result: 初步用户研究显示，Hazel Deriver可以降低学生对推导任务的难度感，同时提升概念理解和学习参与度。

Conclusion: Hazel Deriver通过分层支撑和实时反馈，有助于学习者更有效地掌握规则推导任务，同时探讨了系统引导与学习者自主性之间的平衡。

Abstract: Students in programming languages and formal logic courses often struggle
with constructing rule-based derivation trees due to the complexity of applying
inference rules, the lack of immediate feedback, and the manual effort required
for handwritten proofs. We present Hazel Deriver, a live, web-based editor
designed to scaffold derivation construction through multiple layers of
support. Built on the Hazel live programming environment, it provides a
structured, interactive experience that encourages iterative exploration and
real-time feedback. A preliminary user study with former students suggests that
Hazel Deriver reduces the perceived difficulty of derivation tasks while
improving conceptual understanding and engagement. We discuss the design of its
layered scaffolding features and raise questions about balancing system
guidance with learner autonomy.

</details>


### [4] [Choreographic Quick Changes: First-Class Location (Set) Polymorphism](https://arxiv.org/abs/2506.10913)
*Ashley Samuelson,Andrew K. Hirsch,Ethan Cecchetti*

Main category: cs.PL

TL;DR: 本文提出并实现了一种新型类型化编舞语言λ_{QC}，具备一等进程名、类型/位置多态、递归类型等特性，显著增强了并发系统的表达能力，并通过机械化验证保障程序死锁自由。


<details>
  <summary>Details</summary>
Motivation: 现有的编舞式编程语言在为现代并发系统编程时缺乏一些重要特性，例如节点动态决定谁执行某项计算，并将该决定通知其他节点的能力。

Method: 提出了一种新的类型化编舞语言λ_{QC}，该语言支持一等进程名，以及对类型和节点集合的多态。该语言还引入了代数和递归数据类型、多节点值等特性，并在Rocq工具中形式化并机械化验证了这些结果。

Result: λ_{QC}提升了编舞语言的表达能力，能够实现先前工作中无法表达的并发系统行为，并保证死锁自由。

Conclusion: λ_{QC}填补了现有编舞语言在动态决策和多态性方面的空白，通过形式化验证展示其安全性和强大表达力。

Abstract: Choreographic programming is a promising new paradigm for programming
concurrent systems where a developer writes a single centralized program that
compiles to individual programs for each node. Existing choreographic
languages, however, lack critical features integral to modern systems, like the
ability of one node to dynamically compute who should perform a computation and
send that decision to others. This work addresses this gap with $\lambda_{QC}$,
the first typed choreographic language with \emph{first class process names}
and polymorphism over both types and (sets of) locations. $\lambda_{QC}$ also
improves expressive power over previous work by supporting algebraic and
recursive data types as well as multiply-located values. We formalize and
mechanically verify our results in Rocq, including the standard choreographic
guarantee of deadlock freedom.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [5] [TrioXpert: An automated incident management framework for microservice system](https://arxiv.org/abs/2506.10043)
*Yongqian Sun,Yu Luo,Xidao Wen,Yuan Yuan,Xiaohui Nie,Shenglin Zhang,Tong Liu,Xi Luo*

Main category: cs.SE

TL;DR: 论文提出了多模态数据驱动的微服务事故管理系统TrioXpert，借助大语言模型同时提升了异常检测、故障分级与根因定位任务的准确率并增强了解释性，实验效果显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模微服务系统事故管理方法通常仅依赖单一模态数据（如监控指标、日志、追踪信息），难以同时处理异常检测、故障分级和根因定位等多任务，同时解释性不足。

Method: 提出TrioXpert端到端框架，充分利用多模态数据，针对不同数据模态设计独立处理流程，并协同利用大语言模型进行多任务推理，提供清晰的推理证据。

Result: 在两个主流微服务系统数据集上评估，TrioXpert在异常检测、故障分级和根因定位上取得了显著的性能提升（提升幅度分别为4.7%-57.7%、2.1%-40.6%、1.6%-163.1%）。

Conclusion: TrioXpert能够高效融合多模态数据，显著提升多项事故管理任务表现，并具备优良的可解释性。

Abstract: Automated incident management plays a pivotal role in large-scale
microservice systems. However, many existing methods rely solely on
single-modal data (e.g., metrics, logs, and traces) and struggle to
simultaneously address multiple downstream tasks, including anomaly detection
(AD), failure triage (FT), and root cause localization (RCL). Moreover, the
lack of clear reasoning evidence in current techniques often leads to
insufficient interpretability. To address these limitations, we propose
TrioXpert, an end-to-end incident management framework capable of fully
leveraging multimodal data. TrioXpert designs three independent data processing
pipelines based on the inherent characteristics of different modalities,
comprehensively characterizing the operational status of microservice systems
from both numerical and textual dimensions. It employs a collaborative
reasoning mechanism using large language models (LLMs) to simultaneously handle
multiple tasks while providing clear reasoning evidence to ensure strong
interpretability. We conducted extensive evaluations on two popular
microservice system datasets, and the experimental results demonstrate that
TrioXpert achieves outstanding performance in AD (improving by 4.7% to 57.7%),
FT (improving by 2.1% to 40.6%), and RCL (improving by 1.6% to 163.1%) tasks.

</details>


### [6] [Online Discovery of Simulation Models for Evolving Business Processes (Extended Version)](https://arxiv.org/abs/2506.10049)
*Francesco Vinci,Gyunam Park,Wil van der Aalst,Massimiliano de Leoni*

Main category: cs.SE

TL;DR: 本文提出一种结合增量流程发现和在线机器学习的流式流程仿真发现方法，更好适应业务流程的动态变化，提升了仿真模型的稳定性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着商业环境的动态变化，企业不断优化其业务流程以提升效率、降低成本和提高客户满意度。现有的流程仿真模型自动发现技术难以适应这种实时的流程变化。

Method: 提出了一种流式流程仿真模型发现方法，将增量式流程发现与在线机器学习方法结合。该方法在适应最新数据的同时，保留历史信息，从而提升对流程动态变化的适应性。

Result: 通过在四个不同的事件日志上的实验，证明了在流程仿真中赋予最新数据更高权重且保留历史知识的重要性。该方法生成的仿真更加稳定，在处理概念漂移时表现出更强的鲁棒性。

Conclusion: 所提方法能更好适应不断演化的业务流程，在稳定性和对概念漂移的鲁棒性方面优于传统方法。

Abstract: Business Process Simulation (BPS) refers to techniques designed to replicate
the dynamic behavior of a business process. Many approaches have been proposed
to automatically discover simulation models from historical event logs,
reducing the cost and time to manually design them. However, in dynamic
business environments, organizations continuously refine their processes to
enhance efficiency, reduce costs, and improve customer satisfaction. Existing
techniques to process simulation discovery lack adaptability to real-time
operational changes. In this paper, we propose a streaming process simulation
discovery technique that integrates Incremental Process Discovery with Online
Machine Learning methods. This technique prioritizes recent data while
preserving historical information, ensuring adaptation to evolving process
dynamics. Experiments conducted on four different event logs demonstrate the
importance in simulation of giving more weight to recent data while retaining
historical knowledge. Our technique not only produces more stable simulations
but also exhibits robustness in handling concept drift, as highlighted in one
of the use cases.

</details>


### [7] [The Effects of GitHub Copilot on Computing Students' Programming Effectiveness, Efficiency, and Processes in Brownfield Programming Tasks](https://arxiv.org/abs/2506.10051)
*Md Istiak Hossain Shihab,Christopher Hundhausen,Ahsun Tariq,Summit Haque,Yunhan Qiao,Brian Mulanda*

Main category: cs.SE

TL;DR: GitHub Copilot能大幅提升学生在旧代码基础上开发时的效率，但学生对其建议缺乏深刻理解，教学应平衡效率和理解。


<details>
  <summary>Details</summary>
Motivation: 目前软件行业中新进开发者大多需要在旧有代码基础上进行开发（brownfield development），而生成式AI助理（如GitHub Copilot）正在改变开发实践，但其对学生开发者在继承型开发任务上的影响鲜有研究。

Method: 采用对照实验，邀请10名本科计算机专业学生，在一个遗留Web应用中，分别在有和无Copilot的情况下完成类似的开发任务。通过性能分析、行为分析及访谈对比两种情境下的表现。

Result: 使用Copilot时，学生完成任务速度提高35%，方案进展提升50%，手写代码时间减少11%，网络搜索时间减少12%（以上结果p<0.05均具统计意义）；但学生对Copilot建议背后的原理理解存疑。

Conclusion: 生成式AI助理在加速学生继承型开发任务、提升效率方面有显著作用，但可能削弱学生对代码理解的深入。教育者应开发新型教学法，既利用AI优势，也注重学生对AI建议本质的反思与理解。

Abstract: When graduates of computing degree programs enter the software industry, they
will most likely join teams working on legacy code bases developed by people
other than themselves. In these so-called brownfield software development
settings, generative artificial intelligence (GenAI) coding assistants like
GitHub Copilot are rapidly transforming software development practices, yet the
impact of GenAI on student programmers performing brownfield development tasks
remains underexplored. This paper investigates how GitHub Copilot influences
undergraduate students' programming performance, behaviors, and understanding
when completing brownfield programming tasks in which they add new code to an
unfamiliar code base. We conducted a controlled experiment in which 10
undergraduate computer science students completed highly similar brownfield
development tasks with and without Copilot in a legacy web application. Using a
mixed-methods approach combining performance analysis, behavioral analysis, and
exit interviews, we found that students completed tasks 35% faster (p < 0.05)
and made 50% more solution progress p (< 0.05) when using Copilot. Moreover,
our analysis revealed that, when using Copilot, students spent 11% less time
manually writing code (p < 0.05), and 12% less time conducting web searches (p
< 0.05), providing evidence of a fundamental shift in how they engaged in
programming. In exit interviews, students reported concerns about not
understanding how or why Copilot suggestions work. This research suggests the
need for computing educators to develop new pedagogical approaches that
leverage GenAI assistants' benefits while fostering reflection on how and why
GenAI suggestions address brownfield programming tasks. Complete study results
and analysis are presented at https://ghcopilot-icer.github.io/.

</details>


### [8] [Reward Models Enable Scalable Code Verification by Trading Accuracy for Throughput](https://arxiv.org/abs/2506.10056)
*Gabriel Orlanski,Nicholas Roberts,Aws Albarghouthi,Frederic Sala*

Main category: cs.SE

TL;DR: 作者系统性分析编码任务中验证机制的权衡，发现ORM能大幅提升验证速度，经过修剪后再排序的流程在保证较高准确率下显著提高效率，为大规模代码生成系统设计提供了参考。


<details>
  <summary>Details</summary>
Motivation: 当前主流观点认为，优先采用全面验证器优于只用结果奖励模型，但很少讨论两者之间的权衡。作者希望挑战这一假设，系统性探索在代码生成任务中验证速度与准确率的折中。

Method: 系统性地比较了使用ORM和全面验证器在生成、修剪和排序阶段上的速度与准确率权衡，并提出了generate-prune-then-rank新流程。

Result: 提出的generate-prune-then-rank方法，比仅使用全面验证器快11.65倍，只损失8.33%的准确率。此外，该方法可有效过滤掉高排名但错误的解答。

Conclusion: 研究表明，即使在具备全面验证器的情况下，基于结果的奖励模型（ORM）通过提高验证速度，在大规模代码生成任务中依然具有重要意义。

Abstract: The standard paradigm for solving coding tasks via large language models
(LLMs) is to generate-then-rank programs, where the latter step uses a verifier
in the ranking process. The growing consensus is that a comprehensive verifier
(e.g., a full test suite) should be prioritized over an outcome reward model
(ORM) whenever possible, with little consideration given to the trade-offs
involved. We aim to challenge this assumption by systematically exploring the
tradeoff between speed and accuracy. We find that ORMs play a crucial role in
scaling verification through trading accuracy for speed, even when a
comprehensive verifier is available. Their value becomes especially apparent
when used in a generate-prune-then-rank approach, where a faster but less
accurate verifier removes incorrect solutions prior to ranking -- leading to a
system that is 11.65x faster while only being 8.33% less accurate than the full
test suite. We analyze the generate-prune-then-rank approach and show that it
works by filtering out incorrect but highly ranked solutions. These findings
enable the design of scalable and accurate program ranking systems.

</details>


### [9] [Prompt Variability Effects On LLM Code Generation](https://arxiv.org/abs/2506.10204)
*Andrei Paleyes,Radzim Sendyka,Diana Robinson,Christian Cabrera,Neil D. Lawrence*

Main category: cs.SE

TL;DR: 该论文针对LLM生成代码对Prompt和用户背景敏感的问题，提出了通用且有效的评测方法，并通过实验验证其实用性，工具已开放共享，便于社区采纳。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）在代码生成领域应用广泛，但生成代码的质量依赖于用户输入的Prompt质量，且受用户背景和编程经验影响明显。因此需要评估和量化LLM对不同输入变化的敏感度。

Method: 提出了一套合成评测流程以及系统化以用户角色为基础的评测方法，用于测试和揭示LLM所生成代码的质量如何随不同用户背景产生变化。这些方法不依赖具体编程任务及特定LLM，实现通用化评估。

Result: 实验显示，这些方法能够有效评估和揭示LLM代码生成对输入变化的敏感性，并定量区分不同用户背景下的响应差异。相关评测工具已开源，促进社区使用。

Conclusion: 提出的评测方法通用、有效，可以帮助更全面地理解和改进LLM代码生成在实际应用中的适应性和鲁棒性。

Abstract: Code generation is one of the most active areas of application of Large
Language Models (LLMs). While LLMs lower barriers to writing code and
accelerate development process, the overall quality of generated programs
depends on the quality of given prompts. Specifically, functionality and
quality of generated code can be sensitive to user's background and familiarity
with software development. It is therefore important to quantify LLM's
sensitivity to variations in the input. To this end we propose a synthetic
evaluation pipeline for code generation with LLMs, as well as a systematic
persona-based evaluation approach to expose qualitative differences of LLM
responses dependent on prospective user background. Both proposed methods are
completely independent from specific programming tasks and LLMs, and thus are
widely applicable. We provide experimental evidence illustrating utility of our
methods and share our code for the benefit of the community.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [10] [Growing a Modular Framework for Modal Systems- HOLMS: a HOL Light Library](https://arxiv.org/abs/2506.10048)
*Antonella Bilotta*

Main category: cs.LO

TL;DR: 论文介绍了HOLMS——一个在HOL Light上进行多模态系统模块化证明的库，实现了多个模态系统的适当性定理证明及自动化工具，验证了在实际证明助手中机械化模态推理的可能性。


<details>
  <summary>Details</summary>
Motivation: 现有的模态逻辑机械化证明主要聚焦某一系统或缺乏模块化和统一框架，难以扩展至多个系统；论文希望通过HOLMS填补该空白，使多个模态系统下的推理能够模块化、统一且自动化。

Method: 作者首先介绍了模态逻辑基础及HOL Light使用方法，在框架中发展了统一且模块化的策略，直接在HOL Light内部针对多个标准模态系统（K, T, K4, GL）证明适当性定理。此外，集成自动判定过程与反例模型生成器，并评估与Boolos的《可证性逻辑》一书中的完整性证明之通用性与组合性。

Result: 论文成功在HOL Light中实现了对K、T、K4、GL等模态系统的适当性证明与反例自动生成；证明了标签序列演算及对应理论可与实际通用证明助手结合，切实推动了模态逻辑自动化证明工具的发展。

Conclusion: 该论文展示了在HOL Light证明助手中，机械化和模块化模态推理是可行且高效的。HOLMS库的发展为进一步的理论与实际应用拓展提供了坚实基础。

Abstract: The present dissertation introduces the research project on HOLMS
(\textbf{HOL} Light Library for \textbf{M}odal \textbf{S}ystems), a growing
modular framework for modal reasoning within the HOL Light proof assistant. To
provide an accessible introduction to the library, the fundamentals of modal
logic are outlined first, followed by a concise manual for the proof assistant
itself. The core contribution of this work on HOLMS is the development of a
unified and modular strategy for proving adequacy theorems with respect to
relational semantics directly within HOL Light for several normal modal
systems, currently including K, T, K4, and GL. Adequacy theorems establish a
formal connection between syntactic proof systems and their intended relational
models, ensuring that derivable statements align with valid ones. This approach
extends previous research on G\"odel-L\"ob logic (GL) by two HOLMS developers.
It also assesses the generality and compositionality of the completeness proofs
in George Boolos' monograph \textit{The logic of provability}. Beyond
theoretical contributions, HOLMS incorporates automated decision procedures and
a countermodel constructor for K, T, K4, and GL, illustrating how
general-purpose proof assistants can be effectively combined with research on
labelled sequent calculi and key insights from correspondence and bisimulation
theories. The implementation in HOL Light demonstrates the feasibility of
mechanising modal reasoning in a flexible and robust manner, paving the way for
further developments of the HOLMS framework.

</details>


### [11] [Notes on applicative matching logic](https://arxiv.org/abs/2506.10088)
*Laurentiu Leustean*

Main category: cs.LO

TL;DR: 本文系统介绍了函数式Match Logic（AML）的基本理论及重要结果，是AML理论的入门性资料，并为该领域的后续研究提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 传统的Matching Logic（ML）虽然被用于程序语言的形式语义和推理，但缺乏对函数式性质的直接支持。AML作为ML的函数式变体，有助于在函数式编程和相关理论中更好应用ML。

Method: 本文介绍了AML的基本定义和主要理论结果，整理为教程型讲义，适合作为AML理论入门教材。内容体系和风格深受Monk的数理逻辑教材影响。

Result: 梳理和总结了AML的核心理论内容，为后续研究和实际应用提供理论基础和入门资源。

Conclusion: AML丰富了ML体系，使其能更好支持函数式编程相关的推理与表达。讲义体例规范，为领域初学者提供了有价值的学习资料。

Abstract: Matching logic (ML) was developed by Grigore Ro\c{s}u and collaborators as a
logic for defining the formal semantics of programming languages and for
specifying and reasoning about the behavior of programs. These lecture notes
present basic definitions and results on applicative matching logic (AML), a
functional variant of ML introduced recently by Xiaohong Chen and Grigore
Ro\c{s}u. They can be used as an introductory text in the theory of AML. Monk's
textbook on mathematical logic has an enormous influence on the notes.

</details>


### [12] [StepProof: Step-by-step verification of natural language mathematical proofs](https://arxiv.org/abs/2506.10558)
*Xiaolin Hu,Qinghua Zhou,Bogdan Grechuk,Ivan Y. Tyukin*

Main category: cs.LO

TL;DR: 本文提出StepProof方法，实现对自然语言数学证明的逐句分解与验证，明显提升了验证成功率与效率，推动自动形式化技术取得细粒度突破。


<details>
  <summary>Details</summary>
Motivation: 交互式定理证明器（ITP）在形式化验证数学证明方面非常强大，但缺乏自然语言接口，限制了其易用性。虽然大语言模型（LLM）提升了自然语言理解能力，并使自动形式化成为可能，但现有方法多只停留在整体证明的验证，缺乏更细粒度、逐句的验证能力。

Method: 提出了一种新颖的自动形式化方法StepProof，将完整的证明拆解为多个可验证的子证明，从而实现逐句验证。同时，通过对自然语言证明进行细微人工调整，进一步优化自动形式化效果。

Result: 实验结果表明，StepProof在成功率和效率上都显著优于传统方法。对自然语言证明进行适当的手动调整还能进一步提升StepProof的表现。

Conclusion: StepProof弥补了当前自动形式化方法在细粒度验证上的不足，能够有效提升证明成功率和效率，并为自然语言到形式化证明的转换提供了更细致可靠的解决方案。

Abstract: Interactive theorem provers (ITPs) are powerful tools for the formal
verification of mathematical proofs down to the axiom level. However, their
lack of a natural language interface remains a significant limitation. Recent
advancements in large language models (LLMs) have enhanced the understanding of
natural language inputs, paving the way for autoformalization - the process of
translating natural language proofs into formal proofs that can be verified.
Despite these advancements, existing autoformalization approaches are limited
to verifying complete proofs and lack the capability for finer, sentence-level
verification. To address this gap, we propose StepProof, a novel
autoformalization method designed for granular, step-by-step verification.
StepProof breaks down complete proofs into multiple verifiable subproofs,
enabling sentence-level verification. Experimental results demonstrate that
StepProof significantly improves proof success rates and efficiency compared to
traditional methods. Additionally, we found that minor manual adjustments to
the natural language proofs, tailoring them for step-level verification,
further enhanced StepProof's performance in autoformalization.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [13] [A Survey of Automatic Evaluation Methods on Text, Visual and Speech Generations](https://arxiv.org/abs/2506.10019)
*Tian Lan,Yang-Hao Zhou,Zi-Ao Ma,Fanshu Sun,Rui-Qing Sun,Junyu Luo,Rong-Cheng Tu,Heyan Huang,Chen Xu,Zhijing Wu,Xian-Ling Mao*

Main category: cs.CL

TL;DR: 本文梳理并归类了文本、图像、音频三大模态的自动评价方法，提出五种基本评价范式，建立统一框架，为跨模态评价和后续研究提供参考。


<details>
  <summary>Details</summary>
Motivation: 深度学习推动了生成式AI在文本、图像和音频方面的能力，但自动评价这些内容的质量仍具挑战性。目前缺乏一个系统的框架，能全面组织和分类不同模态下的自动评价方法。

Method: 对现有文献进行全面回顾，提出并构建一个统一的自动评价方法分类体系。首先系统梳理文本生成的自动评价方法，然后将该框架扩展到图像和音频生成领域。

Result: 提出了一个涵盖文本、图像和音频自动评价方法的统一分类框架，并总结归纳出五个基本评价范式。证明该分类体系具有较好的通用性。

Conclusion: 通过该统一框架，有助于未来自动评价方法的发展，尤其强调了跨模态评价方法的研究潜力。

Abstract: Recent advances in deep learning have significantly enhanced generative AI
capabilities across text, images, and audio. However, automatically evaluating
the quality of these generated outputs presents ongoing challenges. Although
numerous automatic evaluation methods exist, current research lacks a
systematic framework that comprehensively organizes these methods across text,
visual, and audio modalities. To address this issue, we present a comprehensive
review and a unified taxonomy of automatic evaluation methods for generated
content across all three modalities; We identify five fundamental paradigms
that characterize existing evaluation approaches across these domains. Our
analysis begins by examining evaluation methods for text generation, where
techniques are most mature. We then extend this framework to image and audio
generation, demonstrating its broad applicability. Finally, we discuss
promising directions for future research in cross-modal evaluation
methodologies.

</details>


### [14] [TaskCraft: Automated Generation of Agentic Tasks](https://arxiv.org/abs/2506.10055)
*Dingfeng Shi,Jingyi Cao,Qianben Chen,Weichen Sun,Weizhen Li,Hongxuan Lu,Fangchen Dong,Tianrui Qin,King Zhu,Minghao Yang,Jian Yang,Ge Zhang,Jiaheng Liu,Changwang Zhang,Jun Wang,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: TaskCraft自动化生成多工具交互、难度可变的agentic任务，显著提升模型训练和评估效率，推动AI agent任务研究发展。


<details>
  <summary>Details</summary>
Motivation: 现有的自然语言处理和AI中任务需要具备自主性、工具使用能力和自适应推理能力，但现有的数据集缺乏工具交互，现有评测也依赖人工标注，成本高、难以扩展。

Method: 提出了TaskCraft，一种自动化工作流，用于生成难度可控、多工具交互且可验证的agentic任务，并带有执行轨迹。TaskCraft利用深度和广度扩展原子任务，生成结构复杂的层次化挑战。

Result: TaskCraft生成了约36,000个不同难度的agentic任务组成的大规模合成数据集，实验证明这些任务提升了模型的prompt优化及agentic基础模型的有监督微调效果。

Conclusion: TaskCraft为agent模型的调优和评估提供了可扩展、高效的基准和数据，为未来agentic任务的研究奠定了基础。

Abstract: Agentic tasks, which require multi-step problem solving with autonomy, tool
use, and adaptive reasoning, are becoming increasingly central to the
advancement of NLP and AI. However, existing instruction data lacks tool
interaction, and current agentic benchmarks rely on costly human annotation,
limiting their scalability. We introduce \textsc{TaskCraft}, an automated
workflow for generating difficulty-scalable, multi-tool, and verifiable agentic
tasks with execution trajectories. TaskCraft expands atomic tasks using
depth-based and width-based extensions to create structurally and
hierarchically complex challenges. Empirical results show that these tasks
improve prompt optimization in the generation workflow and enhance supervised
fine-tuning of agentic foundation models. We present a large-scale synthetic
dataset of approximately 36,000 tasks with varying difficulty to support future
research on agent tuning and evaluation.

</details>


### [15] [A quantum semantic framework for natural language processing](https://arxiv.org/abs/2506.10077)
*Christopher J. Agostino,Quan Le Thien,Molly Apsel,Denizhan Pak,Elina Lesyk,Ashabari Majumdar*

Main category: cs.CL

TL;DR: 论文指出自然语言存在不可避免的“语义退化”现象，随着表达复杂度提高，无论是人类还是LLM很难恢复唯一意义。实验采用类量子贝尔不等式证明语义解释具有非经典上下文相关性，挑战了传统语言观。作者建议用贝叶斯式采样方法描述语义，而非传统的频率学派分析。


<details>
  <summary>Details</summary>
Motivation: 随着语义表达复杂性增长，可能的解释数急剧增加，导致自然语言及其处理系统（如LLM）都面临语义解释歧义。该研究旨在探究复杂语义表达中意义恢复的可行性与限制，并检验经典语言观念的有效性。

Method: 理论分析基于Kolmogorov复杂度，搭配模拟贝尔不等式实验，利用多种大语言模型（LLM）在不同上下文下解释含糊词对，检测其解释是否超越经典边界。结果用CHSH期望值进行量化。

Result: 多次独立实验中，CHSH期望值平均在1.2到2.8之间，多次实验结果显著高于经典界限2（如2.3-2.4），显示解释过程具有非经典的上下文相关性。这结果与人类认知实验一致。

Conclusion: 该论文通过模拟贝尔不等式实验，发现无论是人类还是大型语言模型在解释复杂语义表达时，都会受到“语义退化”的限制，语义解释呈现出非经典的上下文相关性。因此，经典的认为语言形式本身蕴含固定意义的观点并不成立。

Abstract: Semantic degeneracy represents a fundamental property of natural language
that extends beyond simple polysemy to encompass the combinatorial explosion of
potential interpretations that emerges as semantic expressions increase in
complexity. Large Language Models (LLMs) and other modern NLP systems face
inherent limitations precisely because they operate within natural language
itself, making them subject to the same interpretive constraints imposed by
semantic degeneracy. In this work, we argue using Kolmogorov complexity that as
an expression's complexity grows, the likelihood of any interpreting agent
(human or LLM-powered AI) recovering the single intended meaning vanishes. This
computational intractability suggests the classical view that linguistic forms
possess meaning in and of themselves is flawed. We alternatively posit that
meaning is instead actualized through an observer-dependent interpretive act.
To test this, we conducted a semantic Bell inequality test using diverse LLM
agents as ``computational cognitive systems'' to interpret ambiguous word pairs
under varied contextual settings. Across several independent experiments, we
found average CHSH expectation values ranging from 1.2 to 2.8, with several
runs yielding values (e.g., 2.3-2.4) that significantly violate the classical
boundary ($|S|\leq2$). This demonstrates that linguistic interpretation under
ambiguity can exhibit non-classical contextuality, consistent with results from
human cognition experiments. These results inherently imply that classical
frequentist-based analytical approaches for natural language are necessarily
lossy. Instead, we propose that Bayesian-style repeated sampling approaches can
provide more practically useful and appropriate characterizations of linguistic
meaning in context.

</details>


### [16] [Chat-of-Thought: Collaborative Multi-Agent System for Generating Domain Specific Information](https://arxiv.org/abs/2506.10086)
*Christodoulos Constantinides,Shuxin Lin,Nianjun Zhou,Dhaval Patel*

Main category: cs.CL

TL;DR: 本文提出了Chat-of-Thought多智能体系统，通过多角色LLM智能体协作显著提升工业FMEA文档的生成效率与质量。


<details>
  <summary>Details</summary>
Motivation: FMEA文件在工业资产监控中极为重要，但传统方法生成和验证过程耗时且容易出错，需要高效、智能化的解决方案。

Method: 采用多角色的LLM智能体，结合先进AI技术和动态任务分配，通过多智能体间的互动讨论和模板驱动工作流，实现FMEA文档的自动化和迭代完善。

Result: 实验展示了Chat-of-Thought在交互式、模板化、情境感知的FMEA生成方面的潜力，有效提升了文档的生成效率和质量。

Conclusion: Chat-of-Thought系统能够利用多智能体协作优化FMEA文档的生成和验证，特别适合工业设备监控领域，有效应对实际应用中的关键挑战。

Abstract: This paper presents a novel multi-agent system called Chat-of-Thought,
designed to facilitate the generation of Failure Modes and Effects Analysis
(FMEA) documents for industrial assets. Chat-of-Thought employs multiple
collaborative Large Language Model (LLM)-based agents with specific roles,
leveraging advanced AI techniques and dynamic task routing to optimize the
generation and validation of FMEA tables. A key innovation in this system is
the introduction of a Chat of Thought, where dynamic, multi-persona-driven
discussions enable iterative refinement of content. This research explores the
application domain of industrial equipment monitoring, highlights key
challenges, and demonstrates the potential of Chat-of-Thought in addressing
these challenges through interactive, template-driven workflows and
context-aware agent collaboration.

</details>


### [17] [When Meaning Stays the Same, but Models Drift: Evaluating Quality of Service under Token-Level Behavioral Instability in LLMs](https://arxiv.org/abs/2506.10095)
*Xiao Li,Joel Kreuzwieser,Alan Peters*

Main category: cs.CL

TL;DR: 大语言模型在语义相同但表述不同的提示下表现出明显不一致，PBSS框架揭示了这一点并分析了潜在的技术原因，提示模型评估标准需增加对提示稳定性的关注。


<details>
  <summary>Details</summary>
Motivation: 目前对于大语言模型（LLMs）的评估，忽略了同一语义但不同措辞方式（token-level realization）下模型输出不一致的问题。本文希望揭示这个被忽视的维度，并系统性分析原因。

Method: 提出了一种名为Prompt-Based Semantic Shift（PBSS）的诊断框架，用于量化大语言模型在语义等价但措辞不同的提示语下行为变化。该框架被应用于十个受限任务上，对比不同模型的表现。

Result: 实验发现，主流模型在语义等价但措辞变化的提示下会发生一致且具有模型特征的输出漂移。这些变化与分词方式和解码策略相关，显示出统计上的规律性。

Conclusion: 现有模型在提示语重新表述下的稳定性存在不足。分词和解码机制可能是导致训练后服务质量不稳定的原因，因此模型评估和改进需考虑这一维度。

Abstract: We investigate how large language models respond to prompts that differ only
in their token-level realization but preserve the same semantic intent, a
phenomenon we call prompt variance. We propose Prompt-Based Semantic Shift
(PBSS), a diagnostic framework for measuring behavioral drift in LLMs under
semantically equivalent prompt rewordings. Applied to ten constrained tasks,
PBSS reveals consistent, model-specific response shifts, suggesting statistical
regularities linked to tokenization and decoding. These results highlight an
overlooked dimension of model evaluation stability under rephrasing and suggest
that tokenization strategies and decoding dynamics may contribute to
post-training quality of service instability.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [18] [The Freight Multimodal Transport Problem with Buses and Drones: An Integrated Approach for Last-Mile Delivery](https://arxiv.org/abs/2506.10311)
*E Su,Hu Qin,Jiliu Li,Rui Zhang*

Main category: cs.DM

TL;DR: 本文提出公交-无人机协同的多式联运配送优化模型，通过高级整数规划与高效算法实现了成本与效率的显著提升，展示了其在城市最后一公里配送中的优越性和应用前景。


<details>
  <summary>Details</summary>
Motivation: 传统的最后一公里配送存在效率低和成本高的问题，尤其在城市物流中。作者希望通过集成公交和无人机系统，探索如何优化包裹分配与配送，扩展无人机服务范围并提升配送效率。

Method: 作者将公交-无人机多式联运问题建模为混合整数线性规划问题，并提出具有指数变量的整数规划。为解决NP难问题，开发了结合列生成与Benders分解的Branch-Price-and-Benders-Cut算法，同时对算法进行一系列优化提升收敛速度。通过使用真实公交数据，进行算例实验验证算法表现。

Result: 实验结果表明，所提算法无论在效率还是解质量上均优于CPLEX，对比传统的串行分配方式，集成优化可节省超过6%的运营成本。同时分析了集成系统的环保优势、成本参数与储物柜配置对系统性能的影响。

Conclusion: 集成公交与无人机的城市物流方案能显著提升最后一公里配送效率，降低成本并带来环保效益，为城市物流管理者提供了有价值的决策参考。

Abstract: This paper proposes a novel freight multimodal transport problem with buses
and drones, where buses are responsible for transporting parcels to lockers at
bus stops for storage, while drones are used to deliver each parcel from the
locker to the corresponding customer. The integrated bus-drone system
synergistically expands drone service coverage using the bus network to ensure
efficient final delivery. Minimizing the total operational costs while
satisfying customer demands necessitates the joint optimization of parcel
assignments and drone flights. We model the problem into a compact
mixed-integer linear programming formulation and propose an integer programming
formulation with exponentially many variables. To address real-world scale
instances, we propose a Branch-Price-and-Benders-Cut algorithm for this
non-deterministic polynomial-time (NP)-hard problem. This algorithm,
integrating column generation and Benders decomposition within a
Branch-and-Bound framework, is developed to obtain optimal or near-optimal
solutions. Additionally, we introduce algorithmic enhancements aimed at
accelerating the convergence of the algorithm. Computational experiments on
instances generated from real-world bus data demonstrate that the proposed
algorithms outperform CPLEX regarding both efficiency and solution quality.
Moreover, our approaches can lead to over 6% cost savings compared to
situations where we determine parcel assignments and drone flights
sequentially. We evaluate the environmental advantages of integrating buses and
drones, study the impact of different cost parameters in the system, and
investigate the impact of the parcel locker configuration on performance. These
findings provide valuable managerial insights for urban logistics managers,
highlighting the potential of the integrated bus-drone system to improve
traditional last-mile delivery.

</details>


### [19] [Contributions to conjectures in planar graphs: Induced Substructures, Treewidth, and Dominating Sets](https://arxiv.org/abs/2506.10471)
*Kengo Enami,Naoki Matsumoto,Takamasa Yashima*

Main category: cs.DM

TL;DR: 本文系统梳理和比较了两个著名图论猜想的相关定义与变体，给出新反例和分析界限，提出基于treewidth的诱导子图阶上界，并为领域内相关研究提供了理论基础和新思路。


<details>
  <summary>Details</summary>
Motivation: Albertson-Berman和Matheson-Tarjan猜想是图论中两大未解难题，虽然已有局部进展和弱界限，但核心问题尚未解决。通过研究这些猜想及其变体间的结构关系，有助于推动整体性理解和进一步突破。

Method: 文献综述和理论分析，梳理现有相关猜想与变体，并通过构造反例和不等式分析等方法，给出结构性结果和界限。

Result: 澄清了不同结构概念的联系，提出并反驳了若干相关猜想，确定了在不同条件下诱导子图最大阶的优化界限，并提出了以treewidth为参数的阶上界。

Conclusion: 本文阐明了与Albertson-Berman猜想和Matheson-Tarjan猜想相关的若干概念之间的关系，讨论并修正了一些相关的猜想，同时给出了一些反例，并在不同结构条件下建立了关于诱导子图最大阶的最佳界限。此外，还给出了以treewidth为参数的诱导子图阶的一般性上界。

Abstract: Two of the most prominent unresolved conjectures in graph theory, the
Albertson-Berman conjecture and the Matheson-Tarjan conjecture, have been
extensively studied by many researchers.
  (AB) Every planar graph of order $n$ has an induced forest of order at least
$\frac{n}{2}$.
  (MT) Every plane triangulation of sufficiently large order $n$ has a
dominating set of cardinality at most $\frac{n}{4}$.
  Although partial results and weaker bounds than those originally conjectured
have been obtained, both problems remain open. To contribute to their
resolution, various generalizations and variations of the original concepts
have been investigated, such as total dominating set, induced linear forests,
and others. In this paper, we clarify the relations among several notions
related to these two major conjectures, such as connected domination and
induced outerplanar subgraphs, etc., and survey the associated conjectures. We
then provide counterexamples to some of these conjectures and establish the
best bounds on the gap between the maximum orders of induced subgraphs under
different structural conditions. In addition, we present a general upper bound
on the order of induced subgraphs in terms of treewidth, a fundamental graph
invariant.

</details>


### [20] [The LLLR generalised Langton's ant](https://arxiv.org/abs/2506.10482)
*Victor Lutfalla*

Main category: cs.DM

TL;DR: 本文简要分析了LLLR广义Langton's ant的动力学，揭示其可以有两种不同的渐近行为。


<details>
  <summary>Details</summary>
Motivation: 研究Langton's ant的一种广义变体（LLLR），分析其长期动力学行为。

Method: 对LLLR泛化Langton's ant的动力学进行了分析与描述。

Result: 发现了该系统存在两类不同的渐近动态。

Conclusion: LLLR泛化Langton's ant可以表现出两种不同的渐近行为。

Abstract: We present a short note on the dynamics of the LLLR generalised Langton's
ant. We describe two different asymptotic behaviours for the LLLR ant.

</details>


### [21] [Circulant TSP: Vertices of the Edge-Length Polytope and Superpolynomial Lower Bounds](https://arxiv.org/abs/2506.10758)
*Samuel C. Gutekunst*

Main category: cs.DM

TL;DR: 本文研究了循环TSP的边长多面体结构，发现其顶点数与输入规模n的因数分解密切相关，部分情况下“暴力法”反而高效，并联动Buratti-Horak-Rosa猜想中组合结构，丰富了TSP及组合优化问题的理论基础。


<details>
  <summary>Details</summary>
Motivation: 受到循环TSP算法研究和Buratti-Horak-Rosa猜想相关数论问题的双重驱动。循环TSP整体复杂性尚未解决，边长多面体为探索该问题提供新视角。

Method: 分析并刻画了边长多面体的顶点数量与输入规模n及其因数分解之间的关系，比较了循环TSP的多面体结构与标准TSP多面体。还对相关组合数列给出了超多项式下界，作为中间论证步骤。

Result: 证明了边长多面体的顶点数量受n的因数分解影响，在n为素数或素数平方时增长较缓，在n为2的幂时呈超多项式爆炸。提出对于特定n，暴力检验每个顶点实际上是高效的，并对与Buratti-Horak-Rosa猜想相关的组合数列给出了超多项式下界。

Conclusion: 边长多面体在求解循环TSP时与n的因数分解密切相关。对于素数n，其顶点数随n线性增长；对于n为素数的平方，顶点数随n^{3/2}增长；对于2的幂次，顶点数则呈超多项式增长。与标准对称TSP多面体的n!顶点数相比，循环TSP在某些n的因数分解情形下可用暴力算法高效求解。

Abstract: We study the edge-length polytope, motivated both by algorithmic research on
the Circulant Traveling Salesman Problem (Circulant TSP) and number-theoretic
research related to the Buratti-Horak-Rosa conjecture. Circulant TSP is a
special case of TSP whose overall complexity is a significant still-open
question, and where on an input with vertices $\{1, 2, ..., n\}$, the cost of
an edge $\{i, j\}$ depends only on its length $\min\{|i-j|, n-|i-j|\}$. The
edge-length polytope provides one path to solving circulant TSP instances, and
we show that it is intimately connected to the factorization of $n$: the number
of vertices scales with $n$ whenever $n$ is prime and with $n^{3/2}$ whenever
$n$ is a prime-squared, but there are a superpolynomial number of vertices
whenever $n$ is a power of 2. In contrast, the more-standard Symmetric TSP
Polytope has roughly $n!$ vertices. Hence, for Circulant TSP, a brute-force
algorithm checking every vertex is actually efficient in some cases, based on
the factorization of $n$. As an intermediate step, we give superpolynomial
lower-bounds on two combinatorial sequences related to the Buratti-Horak-Rosa
conjecture, which asks what combinations of edge lengths can comprise a
Hamiltonian path.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [22] [Chance and Mass Interpretations of Probabilities in Markov Decision Processes (Extended Version)](https://arxiv.org/abs/2506.10377)
*Yun Chen Tsai,Kittiphon Phalakarn,S. Akshay,Ichiro Hasuo*

Main category: cs.FL

TL;DR: 文章提出四种MDP的统一语义框架，并用CM分类器系统整合。对新语义下可达性问题给出复杂性分析及两种算法。


<details>
  <summary>Details</summary>
Motivation: 马尔可夫决策过程（MDP）作为一个在不确定性下决策的重要模型，传统语义主要关注概率分布在状态序列上的变换，并假设调度器作出随机选择。但在对动力系统建模中，已有对MDP分布转化的不同视角，但总体上缺乏统一的语义框架来囊括多种解释。

Method: 提出了一个统一的语义框架，通过定义CM（chance-mass）分类器，将四种MDP的语义自然地纳入进来。具体方法：从调度器、配置和转移三种随机性来源入手，将概率的不同解释方式（机会interpretation与质量interpretation）系统地整合。随后，针对新提出的两种语义，分别研究其可达性问题的复杂性，并提出两种算法加以求解。

Result: 成功提出了统一四种MDP语义的CM分类器数学框架。关于新提出语义下的可达性问题，证明了其复杂性，并针对性地提供了两套解决算法。

Conclusion: 本文兼容并统一了MDP在不同随机性解释下的四种语义，丰富了MDP在动力系统建模和验证中的应用基础，并为新语义条件下的可达性问题提供了理论与算法两方面的支持。

Abstract: Markov decision processes (MDPs) are a popular model for decision-making in
the presence of uncertainty. The conventional view of MDPs in verification
treats them as state transformers with probabilities defined over sequences of
states and with schedulers making random choices. An alternative view,
especially well-suited for modeling dynamical systems, defines MDPs as
distribution transformers with schedulers distributing probability masses. Our
main contribution is a unified semantical framework that accommodates these two
views and two new ones. These four semantics of MDPs arise naturally through
identifying different sources of randomness in an MDP (namely schedulers,
configurations, and transitions) and providing different ways of interpreting
these probabilities (called the chance and mass interpretations). These
semantics are systematically unified through a mathematical construct called
chance-mass (CM) classifier. As another main contribution, we study a
reachability problem in each of the two new semantics, demonstrating their
hardness and providing two algorithms for solving them.

</details>


### [23] [Minimality and computability of languages of G-shifts](https://arxiv.org/abs/2506.10610)
*Djamel Eddine Amir,Benjamin Hellouin de Menibus*

Main category: cs.FL

TL;DR: 本文提出并刻画了$G$-shifts（$G$为有限生成群）的强可计算类型，证明其理论在直积下封闭，统一和推广了现有相关理论，并为今后研究指出了新方向。


<details>
  <summary>Details</summary>
Motivation: 受到可计算分析中集合的强可计算类型概念的启发，作者希望将此思想推广到$G$-shifts（$G$为具有可判定字问题的有限生成群），以扩展理论的适用范围和理解。

Method: 定义了$G$-shifts的强可计算类型，并用与某类有界计算复杂度的性质相关的极小性来刻画具有强可计算类型的$G$-shifts。作者提供了自洽的直接证明，同时讨论了与Amir和Hoyrup对于集合的类似刻画的关系，以及与Jeandel关于闭包空间的研究联系。此外，将该刻画应用于多类与特定性质相关的极小shifts。

Result: 提出了$G$-shifts强可计算类型的新理论，并证明了与集合情形的不同点：即$G$-shifts的强可计算类型在取直积时可以保留。提供了统一和简化的刻画，并推动了相关研究的推广和深化。

Conclusion: 本文推广并统一了$G$-shifts强可计算类型的理论，为研究具有特定计算复杂度的动力系统提供了新的工具，并指出了后续的推广和研究方向。

Abstract: Motivated by the notion of strong computable type for sets in computable
analysis, we define the notion of strong computable type for $G$-shifts, where
$G$ is a finitely generated group with decidable word problem. A $G$-shift has
strong computable type if one can compute its language from the complement of
its language. We obtain a characterization of $G$-shifts with strong computable
type in terms of a notion of minimality with respect to properties with a
bounded computational complexity. We provide a self-contained direct proof, and
also explain how this characterization can be obtained from an existing similar
characterization for sets by Amir and Hoyrup, and discuss its connexions with
results by Jeandel on closure spaces. We apply this characterization to several
classes of shifts that are minimal with respect to specific properties. This
provides a unifying approach that not only generalizes many existing results
but also has the potential to yield new findings effortlessly. In contrast to
the case of sets, we prove that strong computable type for G-shifts is
preserved under products. We conclude by discussing some generalizations and
future directions.

</details>
