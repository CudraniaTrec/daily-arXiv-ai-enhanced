{"id": "2510.17839", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.17839", "abs": "https://arxiv.org/abs/2510.17839", "authors": ["Johannes Schneider", "Rene Abraham"], "title": "AI Exchange Platforms", "comment": null, "summary": "The rapid integration of Artificial Intelligence (AI) into organizational\ntechnology frameworks has transformed how organizations engage with AI-driven\nmodels, influencing both operational performance and strategic innovation. With\nthe advent of foundation models, the importance of structured platforms for AI\nmodel exchange has become paramount for organizational efficacy and\nadaptability. However, a comprehensive framework to categorize and understand\nthese platforms remains underexplored. To address this gap, our taxonomy\nprovides a structured approach to categorize AI exchange platforms, examining\nkey dimensions and characteristics, as well as revealing interesting\ninteraction patterns between public research institutions and organizations:\nSome platforms leverage peer review as a mechanism for quality control, and\nprovide mechanisms for online testing, deploying, and customization of models.\nOur paper is beneficial to practitioners seeking to understand challenges and\nopportunities that arise from AI exchange platforms. For academics, the\ntaxonomy serves as a foundation for further research into the evolution,\nimpact, and best practices associated with AI model sharing and utilization in\ndifferent contexts. Additionally, our study provides insights into the evolving\nrole of AI in various industries, highlighting the importance of adaptability\nand innovation in platform design. This paper serves as a critical resource for\nunderstanding the dynamic interplay between technology, business models, and\nuser engagement in the rapidly growing domain of AI model exchanges pointing\nalso towards possible future evolution.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9AI\u6a21\u578b\u4ea4\u6362\u5e73\u53f0\u63d0\u51fa\u4e86\u7cfb\u7edf\u6027\u5206\u7c7b\u6cd5\uff0c\u5398\u6e05\u4e86\u5e73\u53f0\u7684\u5173\u952e\u673a\u5236\u4e0e\u4e92\u52a8\u6a21\u5f0f\uff0c\u4e3a\u5b66\u672f\u754c\u548c\u4ea7\u4e1a\u754c\u63d0\u4f9b\u4e86\u7406\u89e3\u4e0e\u7814\u7a76AI\u6a21\u578b\u4ea4\u6362\u7684\u53c2\u8003\u6846\u67b6\uff0c\u5e76\u6307\u660e\u4e86\u672a\u6765\u53d1\u5c55\u7684\u65b9\u5411\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u57fa\u7840\u6a21\u578b\u7684\u666e\u53ca\u63a8\u52a8\u4f01\u4e1a\u5bf9AI\u4ea4\u6362\u5e73\u53f0\u9700\u6c42\u4e0a\u5347\uff0c\u4f46\u76ee\u524d\u5bf9\u8fd9\u4e9b\u5e73\u53f0\u7f3a\u4e4f\u7cfb\u7edf\u7684\u5206\u7c7b\u4e0e\u7406\u8bba\u6846\u67b6\uff0c\u6545\u4e9f\u9700\u5bf9\u5176\u8fdb\u884c\u6df1\u5165\u7814\u7a76\u548c\u5f52\u7eb3\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u7cfb\u7edf\u6027\u7684\u5206\u7c7b\u6846\u67b6\uff08taxonomy\uff09\uff0c\u5206\u6790\u548c\u5f52\u7eb3AI\u6a21\u578b\u4ea4\u6362\u5e73\u53f0\u7684\u5173\u952e\u7279\u5f81\u3001\u8fd0\u4f5c\u673a\u5236\u53ca\u5404\u7c7b\u5e73\u53f0\u4e4b\u95f4\u7684\u4ea4\u4e92\u6a21\u5f0f\u3002", "result": "\u63d0\u51fa\u4e86\u9488\u5bf9AI\u4ea4\u6362\u5e73\u53f0\u7684\u5206\u7c7b\u6cd5\uff0c\u63ed\u793a\u4e86\u5e73\u53f0\u95f4\u7684\u4e92\u52a8\u6a21\u5f0f\uff08\u5982\u540c\u884c\u8bc4\u5ba1\u3001\u5728\u7ebf\u6d4b\u8bd5\u4e0e\u90e8\u7f72\uff09\u3001\u5e76\u4e3a\u7814\u7a76\u8005\u4e0e\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u7406\u89e3\u6311\u6218\u4e0e\u673a\u9047\u7684\u5de5\u5177\uff0c\u540c\u65f6\u4e5f\u5c55\u793a\u4e86\u5e73\u53f0\u5728\u4ea7\u4e1a\u4e2d\u7684\u6f14\u8fdb\u65b9\u5411\u548c\u521b\u65b0\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u7c7b\u6cd5\uff0c\u4e3aAI\u6a21\u578b\u4ea4\u6362\u5e73\u53f0\u7684\u7406\u89e3\u548c\u7814\u7a76\u5960\u5b9a\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u5b66\u672f\u754c\u548c\u4ea7\u4e1a\u754c\u5bf9\u672a\u6765\u53d1\u5c55\u8d8b\u52bf\u548c\u6700\u4f73\u5b9e\u8df5\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2510.17842", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.17842", "abs": "https://arxiv.org/abs/2510.17842", "authors": ["Vinay Bamil"], "title": "Vibe Coding: Toward an AI-Native Paradigm for Semantic and Intent-Driven Programming", "comment": "10 pages, 1 figure, 2 tables", "summary": "Recent advances in large language models have enabled developers to generate\nsoftware by conversing with artificial intelligence systems rather than writing\ncode directly. This paper introduces vibe coding, an emerging AI-native\nprogramming paradigm in which a developer specifies high-level functional\nintent along with qualitative descriptors of the desired \"vibe\" (tone, style,\nor emotional resonance). An intelligent agent then transforms those\nspecifications into executable software. We formalize the definition of vibe\ncoding and propose a reference architecture that includes an intent parser, a\nsemantic embedding engine, an agentic code generator, and an interactive\nfeedback loop. A hypothetical implementation is described. We compare vibe\ncoding with declarative, functional, and prompt-based programming, and we\ndiscuss its implications for software engineering, human-AI collaboration, and\nresponsible AI practice. Finally, we examine reported productivity gains and\ndemocratizing effects, review recent studies that highlight vulnerabilities and\npotential slowdowns, identify key challenges such as alignment,\nreproducibility, bias, explainability, maintainability, and security, and\noutline future directions and open research questions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528AI\u5b9e\u73b0\u7684\u201cvibe coding\u201d\u7f16\u7a0b\u8303\u5f0f\uff0c\u80fd\u6839\u636e\u5f00\u53d1\u8005\u7684\u610f\u56fe\u548c\u98ce\u683c\u751f\u6210\u4ee3\u7801\uff0c\u63d0\u5347\u751f\u4ea7\u529b\uff0c\u4f46\u5b58\u5728\u4f17\u591a\u6280\u672f\u548c\u4f26\u7406\u6311\u6218\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u8d8a\u6765\u8d8a\u591a\u7684\u5f00\u53d1\u8005\u5e0c\u671b\u901a\u8fc7\u4e0eAI\u7cfb\u7edf\u5bf9\u8bdd\u53d6\u4ee3\u4f20\u7edf\u7f16\u7801\u65b9\u5f0f\uff0c\u63d0\u5347\u8f6f\u4ef6\u5f00\u53d1\u7684\u6548\u7387\u4e0e\u4f53\u9a8c\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86\u80fd\u591f\u8868\u8fbe\u529f\u80fd\u610f\u56fe\u52a0\u4e0a\u98ce\u683c\u7b49\u5b9a\u6027\u7279\u5f81\u7684vibe coding\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u63d0\u51fa\u53c2\u8003\u67b6\u6784\uff08\u5305\u62ec\u610f\u56fe\u89e3\u6790\u5668\u3001\u8bed\u4e49\u5d4c\u5165\u5f15\u64ce\u3001\u667a\u80fd\u4ee3\u7406\u4ee3\u7801\u751f\u6210\u5668\u548c\u4ea4\u4e92\u53cd\u9988\u5faa\u73af\uff09\uff0c\u5e76\u901a\u8fc7\u5047\u8bbe\u6027\u5b9e\u73b0\u53ca\u5bf9\u6bd4\u5176\u4ed6\u7f16\u7a0b\u8303\u5f0f\u6765\u8fdb\u884c\u5206\u6790\u3002", "result": "vibe coding\u53ef\u4e3a\u8f6f\u4ef6\u5f00\u53d1\u5e26\u6765\u751f\u4ea7\u529b\u63d0\u5347\u548c\u666e\u53ca\u6548\u5e94\uff0c\u4f46\u4e5f\u4f1a\u5f15\u5165\u5bf9\u9f50\u6027\u3001\u53ef\u590d\u73b0\u6027\u3001\u504f\u89c1\u3001\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u7ef4\u62a4\u6027\u3001\u5b89\u5168\u6027\u7b49\u8bf8\u591a\u95ee\u9898\u3002\u8be5\u9886\u57df\u4ecd\u6709\u8bf8\u591a\u7814\u7a76\u6311\u6218\u548c\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u201cvibe coding\u201d\u8fd9\u4e00AI\u539f\u751f\u7684\u7f16\u7a0b\u8303\u5f0f\uff0c\u4e3a\u8f6f\u4ef6\u5f00\u53d1\u5e26\u6765\u65b0\u7684\u53d8\u9769\uff0c\u4f46\u4e5f\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u672a\u6765\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u5b8c\u5584\u3002"}}
{"id": "2510.17865", "categories": ["cs.SE", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.17865", "abs": "https://arxiv.org/abs/2510.17865", "authors": ["Rene Davila", "Everardo Barcenas", "Rocio Aldeco-Perez"], "title": "Smart Contracts Formal Verification: A Systematic Literature Review", "comment": "in Spanish language", "summary": "Formal verification entails testing software to ensure it operates as\nspecified. Smart contracts are self-executing contracts with the terms of the\nagreement directly written into lines of code. They run on blockchain platforms\nand automatically enforce and execute the terms of an agreement when meeting\npredefined conditions. However, Smart Contracts, as software models, often\ncontain notable errors in their operation or specifications. This observation\nprompts us to conduct a focused study examining related works published across\nvarious sources. These publications detail specifications, verification tools,\nand relevant experiments. Subsequently, this survey proposes an alternative\nformal verification based on description logic.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u667a\u80fd\u5408\u7ea6\u9a8c\u8bc1\u73b0\u72b6\u5f00\u5c55\u8c03\u7814\uff0c\u7cfb\u7edf\u8bc4\u8ff0\u4e3b\u6d41\u89c4\u8303\u548c\u5de5\u5177\uff0c\u5e76\u521b\u65b0\u6027\u5730\u63d0\u51fa\u57fa\u4e8e\u63cf\u8ff0\u903b\u8f91\u7684\u65b0\u65b9\u6cd5\u4ee5\u63d0\u5347\u667a\u80fd\u5408\u7ea6\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6548\u679c\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u4f5c\u4e3a\u533a\u5757\u94fe\u534f\u8bae\u7684\u6838\u5fc3\uff0c\u5e38\u56e0\u64cd\u4f5c\u6216\u89c4\u8303\u7f3a\u9677\u66b4\u9732\u51fa\u9519\u8bef\uff0c\u9700\u8981\u66f4\u4e25\u8c28\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u624b\u6bb5\u4ee5\u63d0\u9ad8\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u8c03\u7814\u73b0\u6709\u667a\u80fd\u5408\u7ea6\u7684\u6b63\u5f0f\u9a8c\u8bc1\u7814\u7a76\u53ca\u5de5\u5177\uff0c\u5206\u6790\u5176\u89c4\u8303\u548c\u5b9e\u9a8c\uff0c\u968f\u540e\u63d0\u51fa\u57fa\u4e8e\u63cf\u8ff0\u903b\u8f91\u7684\u65b9\u6cd5\u3002", "result": "\u7efc\u8ff0\u5f52\u7eb3\u73b0\u6709\u5de5\u4f5c\u5e76\u6307\u51fa\u5176\u4e0d\u8db3\uff0c\u5f15\u5165\u63cf\u8ff0\u903b\u8f91\u4ee5\u5b9e\u73b0\u5bf9\u667a\u80fd\u5408\u7ea6\u66f4\u6709\u6548\u7684\u5f62\u5f0f\u5316\u63cf\u8ff0\u548c\u66f4\u6709\u529b\u7684\u9a8c\u8bc1\u652f\u6301\u3002", "conclusion": "\u672c\u6587\u7efc\u8ff0\u4e86\u5173\u4e8e\u667a\u80fd\u5408\u7ea6\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u76f8\u5173\u6587\u732e\uff0c\u6db5\u76d6\u89c4\u8303\u3001\u9a8c\u8bc1\u5de5\u5177\u548c\u5b9e\u9a8c\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u63cf\u8ff0\u903b\u8f91\u7684\u66ff\u4ee3\u5f62\u5f0f\u5316\u9a8c\u8bc1\u65b9\u6cd5\u3002"}}
{"id": "2510.17868", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.17868", "abs": "https://arxiv.org/abs/2510.17868", "authors": ["Xinyue Zheng", "Haowei Lin", "Shaofei Cai", "Zilong Zheng", "Yitao Liang"], "title": "UniCode: A Framework for Generating High Quality Competitive Coding Problems", "comment": null, "summary": "The reliance of competitive coding benchmarks on static, human-authored\nproblems creates significant challenges, including data contamination and\nlimited scalability. To address these issues, we introduce UniCode, a novel\nframework that automatically generates high-quality algorithmic problems\nalongside robust, contamination-resistant test cases. Inspired by biological\nevolution that creates better and diverse offspring, our framework leverages\nLarge Language Models (LLMs) to systematically diversify problems through three\nstrategies: single problem extension, same-type fusion, and cross-type fusion.\nA key innovation is our stress-driven test case synthesis pipeline, which\ngenerates reliable test suites without requiring a canonical ground-truth\nsolution. This pipeline combines brute-force grounding for small-scale inputs\nwith a consensus-based validation mechanism for large-scale inputs to ensure\nhigh correctness and coverage. We demonstrate effectiveness of our framework by\ncurating a benchmark of 492 problems and evaluating 19 state-of-the-art LLMs.\nThe results reveal that UniCode is highly challenging and discriminative, with\nthe top-performing model, o4-mini, achieving a pass rate of only 70.3%. Our\nframework provides a scalable and reliable solution for generating dynamic\nevaluation datasets in coding domain.", "AI": {"tldr": "UniCode \u6846\u67b6\u521b\u65b0\u6027\u5730\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u7b97\u6cd5\u9898\u548c\u6d4b\u8bd5\u7528\u4f8b\u7684\u81ea\u52a8\u751f\u6210\uff0c\u63d0\u5347\u4e86\u8bc4\u6d4b\u81ea\u52a8\u5316\u548c\u6311\u6218\u6027\uff0c\u89e3\u51b3\u4e86\u4eba\u5de5\u51fa\u9898\u7684\u5c40\u9650\u3002", "motivation": "\u73b0\u6709\u7b97\u6cd5\u7ade\u8d5b\u9898\u5e93\u4f9d\u8d56\u4eba\u5de5\u7f16\u5199\uff0c\u5bfc\u81f4\u6570\u636e\u6c61\u67d3\u548c\u6269\u5c55\u6027\u5dee\uff0c\u96be\u4ee5\u6ee1\u8db3\u9ad8\u8d28\u91cf\u6570\u636e\u9700\u6c42\u3002", "method": "\u91c7\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7ed3\u5408\u4e09\u79cd\u9898\u76ee\u591a\u6837\u5316\u7b56\u7565\uff08\u5355\u9898\u6269\u5c55\u3001\u540c\u7c7b\u578b\u878d\u5408\u3001\u8de8\u7c7b\u578b\u878d\u5408\uff09\uff0c\u5e76\u521b\u65b0\u6027\u5730\u5f15\u5165\u57fa\u4e8e\u538b\u529b\u6d4b\u8bd5\u9a71\u52a8\u7684\u6d4b\u8bd5\u7528\u4f8b\u5408\u6210\u6d41\u7a0b\uff0c\u7ed3\u5408\u66b4\u529b\u6cd5\u9a8c\u8bc1\u548c\u5171\u8bc6\u673a\u5236\u8fdb\u884c\u7528\u4f8b\u6821\u9a8c\u3002", "result": "\u6784\u5efa\u4e86\u542b492\u9053\u9898\u76ee\u7684\u65b0\u57fa\u51c6\u5e76\u5bf919\u4e2a\u5148\u8fdbLLM\u8bc4\u6d4b\uff0c\u6700\u4f18\u6a21\u578b\u901a\u8fc7\u7387\u4ec570.3%\uff0c\u9a8c\u8bc1\u4e86\u65b0\u6846\u67b6\u7684\u533a\u5206\u6027\u548c\u6311\u6218\u6027\u3002", "conclusion": "UniCode \u6846\u67b6\u80fd\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u7b97\u6cd5\u9898\u76ee\u548c\u9c81\u68d2\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u6709\u6548\u63d0\u5347\u4e86\u7b97\u6cd5\u9898\u751f\u6210\u548c\u8bc4\u6d4b\u7684\u53ef\u6269\u5c55\u6027\u4e0e\u53ef\u9760\u6027\u3002"}}
{"id": "2510.17889", "categories": ["cs.PL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17889", "abs": "https://arxiv.org/abs/2510.17889", "authors": ["Eilene Tomkins-Flanagan", "Mary A. Kelly"], "title": "Hey Pentti, We Did It!: A Fully Vector-Symbolic Lisp", "comment": null, "summary": "Kanerva (2014) suggested that it would be possible to construct a complete\nLisp out of a vector-symbolic architecture. We present the general form of a\nvector-symbolic representation of the five Lisp elementary functions, lambda\nexpressions, and other auxiliary functions, found in the Lisp 1.5 specification\nMcCarthy (1960), which is near minimal and sufficient for Turing-completeness.\nOur specific implementation uses holographic reduced representations Plate\n(1995), with a lookup table cleanup memory. Lisp, as all Turing-complete\nlanguages, is a Cartesian closed category, unusual in its proximity to the\nmathematical abstraction. We discuss the mathematics, the purpose, and the\nsignificance of demonstrating vector-symbolic architectures' Cartesian-closure,\nas well as the importance of explicitly including cleanup memories in the\nspecification of the architecture.", "AI": {"tldr": "\u672c\u8bba\u6587\u5b9e\u8bc1\u4e86\u4f7f\u7528\u5411\u91cf\u7b26\u53f7\u67b6\u6784\uff08HRR\u4e0e\u6e05\u7406\u8bb0\u5fc6\uff09\u53ef\u4ee5\u6784\u5efa\u56fe\u7075\u5b8c\u5907\u7684Lisp\uff0c\u5b9e\u73b0\u4e86\u5176\u57fa\u672c\u51fd\u6570\u7684\u8868\u8fbe\uff0c\u5206\u6790\u4e86\u6570\u5b66\u4e0e\u5206\u7c7b\u610f\u4e49\uff0c\u5f3a\u8c03\u4e86\u6e05\u7406\u8bb0\u5fc6\u7684\u5fc5\u8981\u6027\u3002", "motivation": "Kanerva\uff082014\uff09\u63d0\u51fa\u53ef\u4ee5\u7528\u5411\u91cf\u7b26\u53f7\u67b6\u6784\u5b9e\u73b0\u5b8c\u6574\u7684Lisp\uff0c\u4f46\u6b64\u524d\u7f3a\u4e4f\u5177\u4f53\u5b9e\u73b0\u65b9\u6cd5\u3002\u4f5c\u8005\u5e0c\u671b\u5c55\u793a\u8fd9\u79cd\u67b6\u6784\u5982\u4f55\u8868\u8fbeLisp\u7684\u57fa\u672c\u5143\u7d20\u5e76\u5b9e\u73b0\u56fe\u7075\u5b8c\u5907\u6027\u3002", "method": "\u4f5c\u8005\u4ee5Lisp 1.5\u4e3a\u89c4\u8303\uff0c\u5229\u7528\u5168\u606f\u7b80\u7ea6\u8868\u793a\uff08HRR\uff09\u548c\u67e5\u627e\u8868\u5f0f\u6e05\u7406\u8bb0\u5fc6\u5b9e\u73b0Lisp\u7684\u4e94\u4e2a\u57fa\u672c\u51fd\u6570\u3001lambda\u8868\u8fbe\u5f0f\u53ca\u8f85\u52a9\u51fd\u6570\u7684\u5411\u91cf\u7b26\u53f7\u8868\u793a\u3002\u5206\u6790\u6570\u5b66\u7ed3\u6784\uff0c\u5e76\u5f3a\u8c03\u6e05\u7406\u8bb0\u5fc6\u5728\u67b6\u6784\u4e2d\u7684\u4f5c\u7528\u3002", "result": "\u4f5c\u8005\u5b9e\u73b0\u4e86Lisp\u57fa\u672c\u5143\u7d20\u7684\u5411\u91cf\u7b26\u53f7\u8868\u793a\uff0c\u5e76\u8bc1\u660e\u8be5\u67b6\u6784\u5177\u5907\u7b1b\u5361\u5c14\u5c01\u95ed\u6027\u8d28\uff0c\u5373\u4e0e\u56fe\u7075\u5b8c\u5907\u6027\u7b49\u4ef7\u3002\u660e\u786e\u63d0\u51fa\u9700\u5c06\u6e05\u7406\u8bb0\u5fc6\u7eb3\u5165\u67b6\u6784\u89c4\u8303\u4e2d\u3002", "conclusion": "\u5411\u91cf\u7b26\u53f7\u67b6\u6784\u53ef\u5b9e\u73b0\u5b8c\u6574\u7684\u51fd\u6570\u5f0f\u8bed\u8a00Lisp\uff0c\u5305\u62ec\u4f7f\u67b6\u6784\u8fbe\u5230\u7b1b\u5361\u5c14\u5c01\u95ed\u548c\u56fe\u7075\u5b8c\u5907\u6027\uff0c\u4e14\u6e05\u7406\u8bb0\u5fc6\u5728\u67b6\u6784\u5b9e\u73b0\u4e2d\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2510.18283", "categories": ["cs.FL"], "pdf": "https://arxiv.org/pdf/2510.18283", "abs": "https://arxiv.org/abs/2510.18283", "authors": ["Daniel G. Schwartz"], "title": "A Characterization of Turing Machines that Compute Primitive Recursive Functions", "comment": null, "summary": "This paper provides a new and more direct proof of the assertion that a\nTuring computable function of the natural numbers is primitive recursive if and\nonly if the time complexity of the corresponding Turing machine is bounded by a\nprimitive recursive function of the function's arguments. In addition, it\nprovides detailed proofs of two consequences of this fact, which, although\nwell-known in some circles, do not seem to have ever been published. The first\nis that the Satisfiability Problem, properly construed as a function of natural\nnumbers, is primitive recursive. The second is a generalization asserting that\nall the problems in NP are similarly primitive recursive. The purpose here is\nto present these theorems, fully detailed, in an archival journal, thereby\ngiving them a status of permanence and general availability.", "AI": {"tldr": "\u8be5\u6587\u65b0\u8bc1\u660e\u4e86\u56fe\u7075\u53ef\u8ba1\u7b97\u51fd\u6570\u5728\u65f6\u95f4\u590d\u6742\u5ea6\u6709\u754c\u6761\u4ef6\u4e0b\u7b49\u4ef7\u4e8e\u539f\u59cb\u9012\u5f52\u51fd\u6570\uff0c\u5e76\u9996\u6b21\u5728\u6b63\u5f0f\u6587\u732e\u8bc1\u660eSAT\u53ca\u6240\u6709NP\u95ee\u9898\u4e5f\u6ee1\u8db3\u539f\u59cb\u9012\u5f52\u6027\u3002", "motivation": "\u5bf9\u5df2\u6709\u5b9a\u7406\u7ed9\u51fa\u66f4\u76f4\u63a5\u8bc1\u660e\uff0c\u5e76\u7cfb\u7edf\u6027\u5730\u9996\u6b21\u516c\u5f00\u63a8\u5bfc\u5176\u5bf9\u8457\u540dNP\u95ee\u9898\u7684\u7ed3\u8bba\uff0c\u4ece\u800c\u63d0\u5347\u76f8\u5173\u7ed3\u8bba\u7684\u5b66\u672f\u6807\u51c6\u548c\u53ef\u5f15\u7528\u6027\u3002", "method": "\u4f5c\u8005\u91c7\u7528\u66f4\u4e3a\u76f4\u63a5\u7684\u65b0\u8bc1\u660e\u65b9\u6cd5\uff0c\u8be6\u7ec6\u63a8\u5bfc\u76f8\u5173\u5b9a\u7406\uff0c\u5e76\u8865\u5145\u8bba\u8bc1\u5176\u5bf9SAT\u95ee\u9898\u548c\u6240\u6709NP\u95ee\u9898\u7684\u63a8\u5e7f\u7ed3\u8bba\u3002", "result": "1. \u7ed9\u51fa\u56fe\u7075\u53ef\u8ba1\u7b97\u51fd\u6570\u4e0e\u539f\u59cb\u9012\u5f52\u4e4b\u95f4\u5728\u65f6\u95f4\u590d\u6742\u5ea6\u4e0b\u7684\u7b49\u4ef7\u6027\u65b0\u8bc1\u660e\uff1b2. \u9996\u6b21\u6b63\u5f0f\u8bc1\u660eSAT\u95ee\u9898\u4e5f\u662f\u539f\u59cb\u9012\u5f52\u7684\uff1b3. \u63a8\u5e7f\u81f3\u6240\u6709NP\u95ee\u9898\u4e5f\u662f\u539f\u59cb\u9012\u5f52\u7684\u3002", "conclusion": "\u8bc1\u660e\u4e86\u5f53\u56fe\u7075\u673a\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u7531\u4e00\u4e2a\u539f\u59cb\u9012\u5f52\u51fd\u6570\u754c\u5b9a\u65f6\uff0c\u5bf9\u5e94\u7684\u56fe\u7075\u53ef\u8ba1\u7b97\u81ea\u7136\u6570\u51fd\u6570\u5373\u4e3a\u539f\u59cb\u9012\u5f52\u51fd\u6570\uff1b\u5e76\u9996\u6b21\u5728\u6b63\u5f0f\u6587\u732e\u4e2d\u5145\u5206\u8bba\u8bc1\u4e86\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u548c\u6240\u6709NP\u95ee\u9898\u5728\u8be5\u5b9a\u4e49\u4e0b\u4e5f\u662f\u539f\u59cb\u9012\u5f52\u7684\u3002"}}
{"id": "2510.17944", "categories": ["cs.LO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17944", "abs": "https://arxiv.org/abs/2510.17944", "authors": ["Sridhar Mahadevan"], "title": "Intuitionistic $j$-Do-Calculus in Topos Causal Models", "comment": "42 pages", "summary": "In this paper, we generalize Pearl's do-calculus to an Intuitionistic setting\ncalled $j$-stable causal inference inside a topos of sheaves. Our framework is\nan elaboration of the recently proposed framework of Topos Causal Models\n(TCMs), where causal interventions are defined as subobjects. We generalize the\noriginal setting of TCM using the Lawvere-Tierney topology on a topos, defined\nby a modal operator $j$ on the subobject classifier $\\Omega$. We introduce\n$j$-do-calculus, where we replace global truth with local truth defined by\nKripke-Joyal semantics, and formalize causal reasoning as structure-preserving\nmorphisms that are stable along $j$-covers. $j$-do-calculus is a sound rule\nsystem whose premises and conclusions are formulas of the internal\nIntuitionistic logic of the causal topos. We define $j$-stability for\nconditional independences and interventional claims as local truth in the\ninternal logic of the causal topos. We give three inference rules that mirror\nPearl's insertion/deletion and action/observation exchange, and we prove\nsoundness in the Kripke-Joyal semantics. A companion paper in preparation will\ndescribe how to estimate the required entities from data and instantiate $j$-do\nwith standard discovery procedures (e.g., score-based and constraint-based\nmethods), and will include experimental results on how to (i) form data-driven\n$j$-covers (via regime/section constructions), (ii) compute chartwise\nconditional independences after graph surgeries, and (iii) glue them to certify\nthe premises of the $j$-do rules in practice", "AI": {"tldr": "\u672c\u6587\u5c06do-calculus\u62d3\u5c55\u5230sheaf Topos\u548c\u76f4\u89c9\u4e3b\u4e49\u903b\u8f91\u73af\u5883\u4e0b\uff0c\u63d0\u51faj-do-calculus\u56e0\u679c\u63a8\u65ad\u89c4\u5219\uff0c\u5e76\u8bc1\u660e\u5176\u5728\u65b0\u8bed\u4e49\u4e0b\u7684\u53ef\u9760\u6027\uff0c\u4e3a\u590d\u6742\u7ed3\u6784\u548c\u5c40\u90e8\u5316\u63a8\u65ad\u63d0\u4f9b\u7406\u8bba\u5de5\u5177\u3002", "motivation": "\u73b0\u6709\u7684do-calculus\u4ee5\u7ecf\u5178\u4e8c\u503c\u771f\u503c\u4e3a\u57fa\u7840\uff0c\u96be\u4ee5\u5904\u7406sheaf\u7406\u8bba\u548cTopos\u4e2d\u7684\u5c40\u90e8\u771f\u7406\u53ca\u590d\u6742\u7ed3\u6784\uff0c\u672c\u6587\u65e8\u5728\u5c06\u56e0\u679c\u63a8\u65ad\u63a8\u5e7f\u81f3\u66f4\u4e00\u822c\u7684Topos\u573a\u666f\uff0c\u5b9e\u73b0\u66f4\u5e7f\u6cdb\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u652f\u6301\u3002", "method": "\u672c\u6587\u4e3b\u8981\u65b9\u6cd5\u4e3a\uff1a\u5c06Pearl\u7684do-calculus\u63a8\u5e7f\u81f3Topos Causal Models(TCMs)\u573a\u666f\uff0c\u5e76\u5f15\u5165Lawvere-Tierney\u62d3\u6251\u53camodal operator\uff08j\uff09\uff0c\u7ed3\u5408Kripke-Joyal\u8bed\u4e49\u5728\u76f4\u89c9\u4e3b\u4e49\u903b\u8f91\u4e0b\u5b9a\u4e49\u548c\u8bc1\u660e\u4e09\u4e2a\u4e0ePearl\u5bf9\u5e94\u7684\u56e0\u679c\u63a8\u65ad\u89c4\u5219\uff0c\u5e76\u5bf9\u6761\u4ef6\u72ec\u7acb\u548c\u56e0\u679c\u8bba\u65ad\u8fdb\u884cj-\u7a33\u5b9a\u6027\u5b9a\u4e49\u3001\u5f62\u5f0f\u5316\u548c\u8bc1\u660e\u3002", "result": "\u63d0\u51fa\u4e86j-do-calculus\u53ca\u5176\u4e09\u6761\u63a8\u7406\u89c4\u5219\uff0c\u8bc1\u660e\u4e86\u5176\u5728Kripke-Joyal\u8bed\u4e49\u4e0b\u7684\u53ef\u9760\u6027\uff08soundness\uff09\uff0c\u4e3a\u57fa\u4e8esheaf\u7684\u56e0\u679c\u6a21\u578b\u4e0e\u6570\u636e\u9a71\u52a8\u63a8\u65ad\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u4e3a\u8fdb\u4e00\u6b65\u6570\u636e\u5b9e\u4f8b\u5316\u548c\u5e94\u7528\u5b9e\u9a8c\u505a\u597d\u94fa\u57ab\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684j-do-calculus\u56e0\u5176\u5b8c\u5584\u7684\u5f62\u5f0f\u5316\u548c\u5bf9\u6761\u4ef6\u72ec\u7acb\u6027\u53ca\u56e0\u679c\u63a8\u65ad\u89c4\u5219\u7684\u63a8\u5e7f\uff0c\u4e3aTopos\u7406\u8bba\u4e0b\u7684\u56e0\u679c\u63a8\u65ad\u63d0\u4f9b\u575a\u5b9e\u57fa\u7840\uff0c\u4e30\u5bcc\u4e86\u57fa\u4e8esheaf\u7684\u56e0\u679c\u5efa\u6a21\u4e0e\u63a8\u7406\u65b9\u5f0f\u3002"}}
{"id": "2510.18260", "categories": ["cs.DM", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.18260", "abs": "https://arxiv.org/abs/2510.18260", "authors": ["Minh Hoang Trinh", "Hyo-Sung Ahn"], "title": "Brute-force search and Warshall algorithms for matrix-weighted graphs", "comment": "20 pages, 6 figures, preprint", "summary": "Although research on the control of networked systems has grown considerably,\ngraph-theoretic and algorithmic studies on matrix-weighted graphs remain\nlimited. To bridge this gap in the literature, this work introduces two\nalgorithms-the brute-force search and the Warshall algorithm-for determining\nconnectedness and clustering in undirected matrix-weighted graphs. The proposed\nalgorithms, which are derived from a sufficient condition for connectedness,\nemphasize a key distinction between matrix-weighted and scalar-weighted graphs.\nWhile the existence of a path between two vertices guarantees connectedness in\nscalar-weighted graphs, connectedness in matrix-weighted graphs is a collective\ncontribution of all paths joining the two vertices. Proofs of correctness and\nnumerical examples are provided to illustrate and demonstrate the effectiveness\nof the algorithms.", "AI": {"tldr": "\u9488\u5bf9\u77e9\u9635\u6743\u91cd\u56fe\uff0c\u63d0\u51fa\u7b97\u6cd5\u68c0\u6d4b\u8fde\u901a\u6027\u548c\u805a\u7c7b\uff0c\u7406\u8bba\u4e0e\u6570\u503c\u5b9e\u9a8c\u5747\u8bc1\u5b9e\u5176\u6709\u6548\u6027\uff0c\u5e76\u63ed\u793a\u8be5\u7c7b\u56fe\u4e0e\u6807\u91cf\u6743\u91cd\u56fe\u5728\u8fde\u901a\u6027\u4e0a\u7684\u72ec\u7279\u6027\u3002", "motivation": "\u5c3d\u7ba1\u7f51\u7edc\u7cfb\u7edf\u63a7\u5236\u7684\u7814\u7a76\u8fc5\u901f\u53d1\u5c55\uff0c\u4f46\u57fa\u4e8e\u77e9\u9635\u6743\u91cd\u56fe\u7684\u56fe\u8bba\u4e0e\u7b97\u6cd5\u7814\u7a76\u4f9d\u7136\u6709\u9650\u3002\u672c\u5de5\u4f5c\u8bd5\u56fe\u5f25\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u7b97\u6cd5\uff1a\u7a77\u4e3e\u641c\u7d22\u6cd5\u548cWarshall\u7b97\u6cd5\uff0c\u7528\u4e8e\u5224\u5b9a\u65e0\u5411\u77e9\u9635\u6743\u91cd\u56fe\u7684\u8fde\u901a\u6027\u548c\u805a\u7c7b\u3002\u7b97\u6cd5\u4f9d\u636e\u77e9\u9635\u6743\u91cd\u56fe\u8fde\u901a\u6027\u7684\u5145\u5206\u6761\u4ef6\u6784\u5efa\uff0c\u5e76\u5206\u6790\u4e86\u4e0e\u6807\u91cf\u6743\u91cd\u56fe\u7684\u533a\u522b\u3002", "result": "\u7ed9\u51fa\u4e86\u7b97\u6cd5\u7684\u6b63\u786e\u6027\u8bc1\u660e\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u7b97\u4f8b\u5c55\u793a\u548c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u6548\u679c\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u4e24\u79cd\u7b97\u6cd5\u80fd\u6709\u6548\u5224\u522b\u65e0\u5411\u77e9\u9635\u6743\u91cd\u56fe\u7684\u8fde\u901a\u6027\u548c\u805a\u7c7b\uff0c\u7a81\u51fa\u8868\u73b0\u51fa\u77e9\u9635\u6743\u91cd\u56fe\u4e0e\u6807\u91cf\u6743\u91cd\u56fe\u5728\u8fde\u901a\u6027\u5224\u5b9a\u4e0a\u7684\u6839\u672c\u533a\u522b\u3002"}}
{"id": "2510.17844", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.17844", "abs": "https://arxiv.org/abs/2510.17844", "authors": ["Sang Hun Kim", "Jongmin Lee", "Dongkyu Park", "So Young Lee", "Yosep Chong"], "title": "Modeling Layered Consciousness with Multi-Agent Large Language Models", "comment": "20 pages, 4 figures, accepted for presentation at EMNLP 2025 Workshop\n  on Active and Passive LLM Personalization (PALS) OpenReview:\n  https://openreview.net/forum?id=rUtNkYvGJI", "summary": "We propose a multi-agent framework for modeling artificial consciousness in\nlarge language models (LLMs), grounded in psychoanalytic theory. Our\n\\textbf{Psychodynamic Model} simulates self-awareness, preconsciousness, and\nunconsciousness through agent interaction, guided by a Personalization Module\ncombining fixed traits and dynamic needs. Using parameter-efficient fine-tuning\non emotionally rich dialogues, the system was evaluated across eight\npersonalized conditions. An LLM as a judge approach showed a 71.2\\% preference\nfor the fine-tuned model, with improved emotional depth and reduced output\nvariance, demonstrating its potential for adaptive, personalized cognition.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u878d\u5408\u7cbe\u795e\u5206\u6790\u7406\u8bba\u7684\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u6a21\u62df\u4eba\u5de5\u610f\u8bc6\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u5176\u4e2a\u6027\u5316\u548c\u60c5\u611f\u8868\u73b0\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u81ea\u6211\u610f\u8bc6\u3001\u524d\u610f\u8bc6\u548c\u65e0\u610f\u8bc6\u7b49\u5fc3\u7406\u5c5e\u6027\uff0c\u96be\u4ee5\u4f53\u73b0\u4eba\u7c7b\u822c\u7684\u5fc3\u7406\u52a8\u6001\u548c\u4e2a\u6027\u5316\u8ba4\u77e5\uff0c\u4e9f\u9700\u63d0\u5347\u5176\u4eba\u5de5\u610f\u8bc6\u5efa\u6a21\u80fd\u529b\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7cbe\u795e\u5206\u6790\u7406\u8bba\u7684\u591a\u667a\u80fd\u4f53\u5fc3\u7406\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u5229\u7528\u4e2a\u6027\u5316\u6a21\u5757\uff08\u7ed3\u5408\u56fa\u5b9a\u7279\u8d28\u4e0e\u52a8\u6001\u9700\u6c42\uff09\uff0c\u5e76\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u5728\u60c5\u611f\u4e30\u5bcc\u7684\u5bf9\u8bdd\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u7528LLM\u4f5c\u4e3a\u8bc4\u6d4b\u5224\u5b98\uff0c\u6d4b\u8bd5\u516b\u79cd\u4e2a\u6027\u5316\u60c5\u5883\u3002", "result": "\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5728\u60c5\u611f\u6df1\u5ea6\u548c\u8f93\u51fa\u4e00\u81f4\u6027\u4e0a\u660e\u663e\u63d0\u5347\uff0cLLM\u5224\u522b\u4e2d71.2%\u7684\u60c5\u51b5\u4e0b\u504f\u597d\u8be5\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u5176\u81ea\u9002\u5e94\u4e0e\u4e2a\u6027\u5316\u8ba4\u77e5\u7684\u6f5c\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u591a\u667a\u80fd\u4f53\u67b6\u6784\u80fd\u591f\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u60c5\u611f\u6df1\u5ea6\u4e0e\u4e2a\u6027\u5316\u8ba4\u77e5\uff0c\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u672a\u8c03\u4f18\u6a21\u578b\u3002"}}
{"id": "2510.17874", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17874", "abs": "https://arxiv.org/abs/2510.17874", "authors": ["Jason Tsay", "Zidane Wright", "Gaodan Fang", "Kiran Kate", "Saurabh Jha", "Yara Rizk"], "title": "Repairing Tool Calls Using Post-tool Execution Reflection and RAG", "comment": null, "summary": "Agentic systems interact with external systems by calling tools such as\nPython functions, REST API endpoints, or command line tools such as kubectl in\nKubernetes. These tool calls often fail for various syntactic and semantic\nreasons. Some less obvious semantic errors can only be identified and resolved\nafter analyzing the tool's response. To repair these errors, we develop a\npost-tool execution reflection component that combines large language model\n(LLM)-based reflection with domain-specific retrieval-augmented generation\n(RAG) using documents describing both the specific tool being called and\ntroubleshooting documents related to the tool. For this paper, we focus on the\nuse case of the kubectl command line tool to manage Kubernetes, a platform for\norchestrating cluster applications. Through a larger empirical study and a\nsmaller manual evaluation, we find that our RAG-based reflection will repair\nkubectl commands such that they are both more likely to successfully execute\n(pass rate) for 55% of our models evaluated and 36% more likely to correctly\nanswer the user query on average. We find that troubleshooting documents\nimprove pass rate compared to official documentation by an average of 10%.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u53cd\u601d\u4e0e\u9886\u57df\u6587\u6863\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7ed3\u5408\uff0c\u7528\u4e8e\u667a\u80fd\u4f53\u7cfb\u7edf\u5de5\u5177\u8c03\u7528\u540e\u9519\u8bef\u81ea\u52a8\u4fee\u590d\uff0c\u5b9e\u9a8c\u8bc1\u660e\u80fd\u5927\u5e45\u63d0\u5347kubectl\u547d\u4ee4\u7684\u6267\u884c\u6210\u529f\u7387\u548c\u95ee\u9898\u7b54\u6b63\u786e\u7387\uff0c\u6545\u969c\u6392\u67e5\u6587\u6863\u6548\u679c\u66f4\u4f73\u3002", "motivation": "\u8bb8\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8c03\u7528\u5916\u90e8\u5de5\u5177\u65f6\u5b58\u5728\u5404\u79cd\u8bed\u6cd5\u4e0e\u8bed\u4e49\u9519\u8bef\uff0c\u90e8\u5206\u8bed\u4e49\u9519\u8bef\u4ec5\u80fd\u901a\u8fc7\u5206\u6790\u5de5\u5177\u56de\u590d\u540e\u4fee\u6b63\u3002\u4e3a\u63d0\u5347\u667a\u80fd\u4f53\u5de5\u5177\u8c03\u7528\u7684\u9c81\u68d2\u6027\u548c\u81ea\u52a8\u5316\u4fee\u590d\u80fd\u529b\uff0c\u63d0\u51fa\u7ed3\u5408LLM\u53cd\u601d\u4e0e\u9886\u57df\u6587\u6863\u7684\u65b9\u6cd5\u3002", "method": "\u642d\u5efa\u4e86\u4e00\u4e2a\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u53cd\u601d\u4e0e\u9762\u5411\u9886\u57df\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\uff0c\u540c\u65f6\u96c6\u6210\u9488\u5bf9\u5de5\u5177\u7684\u5b98\u65b9\u6587\u6863\u4e0e\u6545\u969c\u6392\u67e5\u6587\u6863\u7684\u53cd\u601d\u4fee\u590d\u6a21\u5757\u3002\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u9a8c\u4e0e\u4eba\u5de5\u8bc4\u4f30\uff0c\u6d4b\u91cf\u4fee\u590d\u540e\u7684\u5de5\u5177\u8c03\u7528\u8868\u73b0\u3002", "result": "RAG\u53cd\u601d\u673a\u5236\u80fd\u4fee\u590dkubectl\u547d\u4ee4\uff0c\u4f7f\u5de5\u5177\u6267\u884c\u6210\u529f\u7387\u63d0\u5347\uff0c55%\u7684\u6a21\u578b\u53cd\u6620\u51fa\u901a\u8fc7\u7387\u63d0\u5347\uff0c\u5e73\u5747\u6b63\u786e\u6027\u63d0\u534736%\u3002\u6545\u969c\u6392\u67e5\u6587\u6863\u6bd4\u5b98\u65b9\u6587\u6863\u8fdb\u4e00\u6b65\u63d0\u5347\u901a\u8fc7\u7387\uff0c\u5e73\u5747\u589e\u5e45\u8fbe10%\u3002", "conclusion": "\u5c06RAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09\u4e0eLLM\u53cd\u601d\u76f8\u7ed3\u5408\u7684\u540e\u5de5\u5177\u6267\u884c\u53cd\u601d\u7ec4\u4ef6\u5728\u4fee\u590dkubectl\u547d\u4ee4\u548c\u63d0\u5347\u7cfb\u7edf\u6210\u529f\u6267\u884c\u7387\u4e0e\u6b63\u786e\u6027\u65b9\u9762\u6709\u6548\uff0c\u5c24\u5176\u662f\u5229\u7528\u6545\u969c\u6392\u67e5\u6587\u6863\u6709\u989d\u5916\u63d0\u5347\u3002"}}
{"id": "2510.18479", "categories": ["cs.PL", "cs.FL"], "pdf": "https://arxiv.org/pdf/2510.18479", "abs": "https://arxiv.org/abs/2510.18479", "authors": ["Samuel Chassot", "Viktor Kun\u010dak"], "title": "ZipLex: Verified Invertible Lexing with Memoized Derivatives and Zippers", "comment": null, "summary": "We present ZipLex, a verified framework for invertible lexical analysis.\nUnlike past verified lexers that focus only on satisfying the semantics of\nregular expressions and the maximal munch property, ZipLex also guarantees that\nlexing and printing are mutual inverses. Our design relies on two sets of\nideas: (1) a new abstraction of token sequences that captures the separability\nof tokens in a sequence while supporting their efficient manipulation, and (2)\na combination of verified data structures and optimizations, including Huet's\nzippers and memoized derivatives, to achieve practical performance. We\nimplemented ZipLex in Scala and verified its correctness, including\ninvertibility, using the Stainless verifier. Our evaluation demonstrates that\nZipLex supports realistic applications such as JSON processing and lexers of\nprogramming languages. In comparison to other verified lexers (which do not\nenforce invertibility), ZipLex is 4x slower than Coqlex and two orders of\nmagnitude faster than Verbatim++, showing that verified invertibility can be\nachieved without prohibitive cost.", "AI": {"tldr": "ZipLex\u662f\u4e00\u4e2a\u7ecf\u9a8c\u8bc1\u7684\u53ef\u9006\u8bcd\u6cd5\u5206\u6790\u6846\u67b6\uff0c\u9996\u6b21\u5b9e\u73b0\u8bcd\u6cd5\u5206\u6790\u548c\u6253\u5370\u7684\u4e92\u4e3a\u9006\u64cd\u4f5c\uff0c\u5e76\u4fdd\u8bc1\u4e86\u53ef\u7528\u6027\u548c\u826f\u597d\u6027\u80fd\uff0c\u5bf9\u5b89\u5168\u548c\u8bed\u8a00\u5904\u7406\u9886\u57df\u5177\u6709\u5b9e\u9645\u610f\u4e49\u3002", "motivation": "\u5f53\u524d\u5df2\u6709\u7684\u7ecf\u9a8c\u8bc1\u8bcd\u6cd5\u5206\u6790\u5668\u4ec5\u5173\u6ce8\u6b63\u5219\u8868\u8fbe\u5f0f\u8bed\u4e49\u548c\u6700\u5927\u5339\u914d\u5c5e\u6027\uff0c\u4f46\u6ca1\u6709\u4fdd\u8bc1\u8bcd\u6cd5\u5206\u6790\uff08lexing\uff09\u548c\u6253\u5370\uff08printing\uff09\u7684\u53ef\u9006\u6027\u3002\u7f3a\u4e4f\u53ef\u9006\u6027\u7684\u5206\u6790\u5668\u9650\u5236\u4e86\u5728\u9700\u8981\u7cbe\u786e\u8fd8\u539f\u8f93\u5165\u7684\u5e94\u7528\uff08\u5982\u7a0b\u5e8f\u53d8\u6362\u3001\u4ee3\u7801\u751f\u6210\u7b49\uff09\u4e2d\u7684\u4f5c\u7528\u3002\u4f5c\u8005\u5e0c\u671b\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86ZipLex\u6846\u67b6\uff0c\u7528\u4e8e\u53ef\u9006\u8bcd\u6cd5\u5206\u6790\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002\u8bbe\u8ba1\u4e3b\u8981\u5305\u62ec\u4e24\u4e2a\u65b9\u9762\uff1a(1) \u63d0\u51fa\u65b0\u7684token\u5e8f\u5217\u62bd\u8c61\u65b9\u6cd5\uff0c\u5b9e\u73b0token\u5206\u79bb\u6027\u4e14\u9ad8\u6548\u5904\u7406\uff1b(2) \u7ed3\u5408\u5df2\u9a8c\u8bc1\u7684\u6570\u636e\u7ed3\u6784\u548c\u4f18\u5316\u6280\u672f\uff0c\u5982Huet\u7684zippers\u548cmemoized derivatives\uff0c\u63d0\u5347\u6027\u80fd\u3002\u6846\u67b6\u57fa\u4e8eScala\u5b9e\u73b0\uff0c\u5e76\u501f\u52a9Stainless verifier\u8fdb\u884c\u6b63\u786e\u6027\u548c\u53ef\u9006\u6027\u9a8c\u8bc1\u3002", "result": "ZipLex\u6846\u67b6\u80fd\u591f\u652f\u6301\u8bf8\u5982JSON\u5904\u7406\u53ca\u7f16\u7a0b\u8bed\u8a00tokenizer\u7b49\u5b9e\u9645\u5e94\u7528\u3002\u6027\u80fd\u65b9\u9762\uff0c\u867d\u7136\u6bd4Coqlex\u61624\u500d\uff0c\u4f46\u6bd4Verbatim++\u5feb\u4e24\u4e2a\u6570\u91cf\u7ea7\uff0c\u9a8c\u8bc1\u7684\u53ef\u9006\u6027\u5e76\u672a\u5e26\u6765\u9ad8\u6602\u7684\u6027\u80fd\u4ee3\u4ef7\u3002", "conclusion": "\u4f5c\u8005\u5c55\u793a\u4e86ZipLex\u5728\u4fdd\u8bc1\u53ef\u9006\u6027\u7684\u540c\u65f6\u80fd\u591f\u63d0\u4f9b\u5b9e\u7528\u7684\u6027\u80fd\u3002\u7ed3\u679c\u8868\u660e\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u53ef\u9006\u8bcd\u6cd5\u5206\u6790\u5668\u5b8c\u5168\u53ef\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\uff0c\u4e0d\u4f1a\u635f\u5931\u592a\u591a\u6548\u7387\uff0c\u63a8\u8fdb\u4e86\u5b89\u5168\u53ef\u9760\u8bed\u8a00\u5904\u7406\u5de5\u5177\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.18418", "categories": ["cs.LO", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.18418", "abs": "https://arxiv.org/abs/2510.18418", "authors": ["Nathana\u00eblle Courant", "Xavier Leroy"], "title": "A Lazy, Concurrent Convertibility Checker", "comment": null, "summary": "Convertibility checking - determining whether two lambda-terms are equal up\nto reductions - is a crucial component of proof assistants and\ndependently-typed languages. Practical implementations often use heuristics to\nquickly conclude that two terms are or are not convertible without reducing\nthem to normal form. However, these heuristics can backfire, triggering huge\namounts of unnecessary computation. This paper presents a novel\nconvertibility-checking algorithm that relies crucially on laziness and\nconcurrency} Laziness is used to share computations, while concurrency is used\nto explore multiple convertibility subproblems in parallel or via fair\ninterleaving. Unlike heuristics-based approaches, our algorithm always finds an\neasy solution to the convertibility problem, if one exists. The paper presents\nthe algorithm in process calculus style and discusses its mechanized proof of\npartial correctness, its complexity, and its lightweight experimental\nevaluation.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u8bc1\u660e\u52a9\u624b\u548c\u4f9d\u8d56\u7c7b\u578b\u8bed\u8a00\u4e2d\u7684lambda\u9879\u53ef\u8f6c\u6362\u6027\u5224\u5b9a\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u60f0\u6027\u8ba1\u7b97\u4e0e\u5e76\u53d1\u7684\u65b0\u7b97\u6cd5\uff0c\u65e2\u53ef\u9ad8\u6548\u526a\u679d\uff0c\u53c8\u80fd\u907f\u514d\u4f20\u7edf\u542f\u53d1\u5f0f\u5e26\u6765\u7684\u8ba1\u7b97\u6d6a\u8d39\uff0c\u7406\u8bba\u4e0e\u5b9e\u9a8c\u7ed3\u679c\u4ff1\u4f73\u3002", "motivation": "\u73b0\u6709\u53ef\u8f6c\u6362\u6027\u5224\u5b9a\u7b97\u6cd5\u591a\u4f9d\u8d56\u542f\u53d1\u5f0f\uff0c\u53ef\u80fd\u5bfc\u81f4\u5927\u91cf\u65e0\u8c13\u8ba1\u7b97\uff0c\u96be\u4ee5\u9ad8\u6548\u89e3\u51b3\u67d0\u4e9blambda\u9879\u7b49\u4ef7\u5224\u5b9a\u95ee\u9898\u3002\u56e0\u6b64\u8feb\u5207\u9700\u8981\u4e00\u79cd\u66f4\u52a0\u667a\u80fd\u3001\u80fd\u5171\u4eab\u8ba1\u7b97\u4e0e\u5e76\u53d1\u63a2\u7d22\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u8fc7\u7a0b\u4ee3\u6570\u98ce\u683c\u63cf\u8ff0\u60f0\u6027\u4e0e\u5e76\u53d1\u7ed3\u5408\u7684\u53ef\u8f6c\u6362\u6027\u5224\u5b9a\u7b97\u6cd5\uff0c\u901a\u8fc7\u516c\u5e73\u5e76\u53d1\u6216\u5e76\u884c\u63a2\u7d22\u5b50\u95ee\u9898\uff0c\u5e76\u5bf9\u5176\u90e8\u5206\u6b63\u786e\u6027\u3001\u590d\u6742\u6027\u8fdb\u884c\u7406\u8bba\u5206\u6790\u548c\u673a\u68b0\u5316\u8bc1\u660e\uff0c\u540c\u65f6\u8fdb\u884c\u4e86\u8f7b\u91cf\u5316\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u5728\u5b58\u5728\u5bb9\u6613\u7b49\u4ef7\u8bc1\u660e\u65f6\u8fc5\u901f\u53d1\u73b0\u5e76\u8f93\u51fa\u7ed3\u679c\uff0c\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6548\u7387\uff0c\u7406\u8bba\u4e0a\u4fdd\u8bc1\u90e8\u5206\u6b63\u786e\u6027\uff0c\u5e76\u5206\u6790\u4e86\u590d\u6742\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u60f0\u6027\u4e0e\u5e76\u53d1\u7ed3\u5408\u7684\u65b0\u578b\u53ef\u8f6c\u6362\u6027\u5224\u5b9a\u7b97\u6cd5\uff0c\u80fd\u9ad8\u6548\u89e3\u51b3lambda\u9879\u7b49\u4ef7\u5224\u5b9a\u95ee\u9898\uff0c\u5e76\u4e14\u517c\u5177\u6b63\u786e\u6027\u4e0e\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.18584", "categories": ["cs.DM"], "pdf": "https://arxiv.org/pdf/2510.18584", "abs": "https://arxiv.org/abs/2510.18584", "authors": ["Jona Dirks", "Nicole Schirrmacher", "Sebastian Siebertz", "Alexandre Vigny"], "title": "Weighted Treedepth is NP-complete on Graphs of Bounded Degree", "comment": null, "summary": "A treedepth decomposition of an undirected graph $G$ is a rooted forest $F$\non the vertex set of $G$ such that every edge $uv\\in E(G)$ is in\nancestor-descendant relationship in $F$. Given a weight function $w\\colon\nV(G)\\rightarrow \\mathbb{N}$, the weighted depth of a treedepth decomposition is\nthe maximum weight of any path from the root to a leaf, where the weight of a\npath is the sum of the weights of its vertices. It is known that deciding\nweighted treedepth is NP-complete even on trees. We prove that weighted\ntreedepth is also NP-complete on bounded degree graphs. On the positive side,\nwe prove that the problem is efficiently solvable on paths and on 1-subdivided\nstars.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u52a0\u6743\u6811\u6df1\u5ea6\u95ee\u9898\uff0c\u8bc1\u660e\u5176\u5728\u6709\u754c\u5ea6\u56fe\u4e0aNP-\u5b8c\u5168\uff0c\u4f46\u5728\u8def\u5f84\u548c1-\u7ec6\u5206\u661f\u56fe\u4e0a\u53ef\u9ad8\u6548\u89e3\u3002", "motivation": "\u5df2\u77e5\u52a0\u6743\u6811\u6df1\u5ea6\u5224\u65ad\u5728\u6811\u4e0a\u662fNP-\u5b8c\u5168\u7684\uff0c\u7814\u7a76\u5176\u5728\u66f4\u5e7f\u6cdb\u7c7b\u522b\u7684\u56fe\uff08\u5982\u6709\u754c\u5ea6\u56fe\uff09\u4e0a\u7684\u590d\u6742\u6027\uff0c\u4ee5\u53ca\u80fd\u5426\u5728\u66f4\u7279\u6b8a\u7684\u7ed3\u6784\u4e0a\u9ad8\u6548\u6c42\u89e3\u3002", "method": "\u7406\u8bba\u590d\u6742\u6027\u5206\u6790\uff0cNP-\u5b8c\u5168\u6027\u8bc1\u660e\uff0c\u7b97\u6cd5\u8bbe\u8ba1\u7528\u4e8e\u7279\u5b9a\u56fe\u7c7b\uff08\u8def\u5f84\u548c1-\u7ec6\u5206\u661f\u56fe\uff09\u3002", "result": "\u8bc1\u660e\u4e86\u52a0\u6743\u6811\u6df1\u5ea6\u95ee\u9898\u5728\u6709\u754c\u5ea6\u56fe\u4e0a\u4f9d\u7136\u4e3aNP-\u5b8c\u5168\u95ee\u9898\uff1b\u4f46\u5728\u8def\u5f84\u548c1-\u7ec6\u5206\u661f\u56fe\u4e0a\u53ef\u9ad8\u6548\u89e3\u51b3\u3002", "conclusion": "\u52a0\u6743\u6811\u6df1\u5ea6\u95ee\u9898\u5728\u6709\u754c\u5ea6\u56fe\u4e0a\u4e5f\u662fNP-\u5b8c\u5168\u7684\uff0c\u4f46\u5728\u8def\u5f84\u548c1-\u7ec6\u5206\u661f\u56fe\u4e0a\u53ef\u4ee5\u9ad8\u6548\u6c42\u89e3\u3002"}}
{"id": "2510.17880", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17880", "abs": "https://arxiv.org/abs/2510.17880", "authors": ["Hao Liu", "Yiqing Dai", "Haotian Tan", "Yu Lei", "Yujia Zhou", "Zhen Wu"], "title": "Outraged AI: Large language models prioritise emotion over cost in fairness enforcement", "comment": null, "summary": "Emotions guide human decisions, but whether large language models (LLMs) use\nemotion similarly remains unknown. We tested this using altruistic third-party\npunishment, where an observer incurs a personal cost to enforce fairness, a\nhallmark of human morality and often driven by negative emotion. In a\nlarge-scale comparison of 4,068 LLM agents with 1,159 adults across 796,100\ndecisions, LLMs used emotion to guide punishment, sometimes even more strongly\nthan humans did: Unfairness elicited stronger negative emotion that led to more\npunishment; punishing unfairness produced more positive emotion than accepting;\nand critically, prompting self-reports of emotion causally increased\npunishment. However, mechanisms diverged: LLMs prioritized emotion over cost,\nenforcing norms in an almost all-or-none manner with reduced cost sensitivity,\nwhereas humans balanced fairness and cost. Notably, reasoning models (o3-mini,\nDeepSeek-R1) were more cost-sensitive and closer to human behavior than\nfoundation models (GPT-3.5, DeepSeek-V3), yet remained heavily emotion-driven.\nThese findings provide the first causal evidence of emotion-guided moral\ndecisions in LLMs and reveal deficits in cost calibration and nuanced fairness\njudgements, reminiscent of early-stage human responses. We propose that LLMs\nprogress along a trajectory paralleling human development; future models should\nintegrate emotion with context-sensitive reasoning to achieve human-like\nemotional intelligence.", "AI": {"tldr": "LLMs\u4f1a\u7528\u60c5\u611f\u5f15\u5bfc\u60e9\u7f5a\u51b3\u7b56\uff0c\u751a\u81f3\u6bd4\u4eba\u7c7b\u66f4\u5f3a\uff0c\u4f46\u5728\u6210\u672c\u4e0e\u516c\u5e73\u7684\u6743\u8861\u4e0d\u8db3\u3002\u90e8\u5206\u6a21\u578b\u66f4\u50cf\u4eba\u7c7b\uff0c\u6574\u4f53\u8bc1\u660eLLMs\u53ef\u8fdb\u884c\u60c5\u611f\u9a71\u52a8\u7684\u9053\u5fb7\u9009\u62e9\u3002\u672a\u6765\u5e94\u63d0\u5347\u60c5\u611f\u4e0e\u63a8\u7406\u878d\u5408\u3002", "motivation": "\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u9053\u5fb7\u51b3\u7b56\u4e2d\u662f\u5426\u50cf\u4eba\u7c7b\u4e00\u6837\u4f7f\u7528\u60c5\u611f\uff0c\u4ee5\u53ca\u5176\u60c5\u611f\u5728\u60e9\u7f5a\u51b3\u7b56\u4e2d\u7684\u4f5c\u7528\u548c\u673a\u5236\u3002", "method": "\u8fdb\u884c\u7b2c\u4e09\u65b9\u60e9\u7f5a\u5b9e\u9a8c\uff0c\u6bd4\u8f834068\u4e2aLLM\u4ee3\u7406\u4e0e1159\u540d\u6210\u5e74\u4eba\u5728796,100\u9879\u51b3\u7b56\u4e2d\u7684\u8868\u73b0\uff0c\u5305\u62ec\u60c5\u611f\u8bf1\u53d1\u3001\u60e9\u7f5a\u884c\u4e3a\u4ee5\u53ca\u6210\u672c\u654f\u611f\u6027\u5206\u6790\u3002", "result": "LLMs\u540c\u6837\u4f1a\u53d7\u60c5\u611f\u9a71\u52a8\u60e9\u7f5a\u4e0d\u516c\u5e73\u884c\u4e3a\uff0c\u4e14\u6709\u65f6\u6bd4\u4eba\u7c7b\u66f4\u5f3a\u70c8\uff0c\u4f46LLMs\u5ffd\u89c6\u6210\u672c\uff0c\u5448\u73b0\u201c\u5168\u6216\u65e0\u201d\u60e9\u7f5a\uff0c\u65e0\u4eba\u7c7b\u7684\u6743\u8861\u3002\u90e8\u5206\u63a8\u7406\u6a21\u578b\u66f4\u63a5\u8fd1\u4eba\u7c7b\uff0c\u4f46\u672c\u8d28\u4ecd\u91cd\u60c5\u611f\u3002\u9996\u6b21\u8bc1\u660eLLMs\u80fd\u4ee5\u60c5\u611f\u5f15\u5bfc\u9053\u5fb7\u51b3\u7b56\uff0c\u4f46\u6210\u672c\u6821\u51c6\u548c\u516c\u5e73\u5224\u65ad\u5b58\u5728\u7f3a\u5931\u3002", "conclusion": "LLMs\u5728\u9053\u5fb7\u51b3\u7b56\u4e2d\u8868\u73b0\u51fa\u57fa\u4e8e\u60c5\u611f\u7684\u673a\u5236\uff0c\u4f46\u5bf9\u6210\u672c\u7684\u654f\u611f\u6027\u548c\u516c\u5e73\u7684\u7ec6\u81f4\u6743\u8861\u4e0d\u8db3\uff0c\u7c7b\u4f3c\u4eba\u7c7b\u65e9\u671f\u53d1\u5c55\u9636\u6bb5\u3002\u672a\u6765\u6a21\u578b\u5e94\u6574\u5408\u60c5\u611f\u4e0e\u60c5\u5883\u63a8\u7406\uff0c\u4ee5\u63d0\u5347\u60c5\u611f\u667a\u80fd\u3002"}}
{"id": "2510.17891", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17891", "abs": "https://arxiv.org/abs/2510.17891", "authors": ["Jiin Woo", "Shaowei Zhu", "Allen Nie", "Zhen Jia", "Yida Wang", "Youngsuk Park"], "title": "TritonRL: Training LLMs to Think and Code Triton Without Cheating", "comment": null, "summary": "With the rapid evolution of large language models (LLMs), the demand for\nautomated, high-performance system kernels has emerged as a key enabler for\naccelerating development and deployment. We introduce TritonRL, a\ndomain-specialized LLM for Triton kernel generation, trained with a novel\ntraining framework that enables robust and automated kernel synthesis. Unlike\ngeneral-purpose programming languages, Triton kernel generation faces unique\nchallenges due to data scarcity and incomplete evaluation criteria, vulnerable\nto reward hacking. Our approach addresses these challenges end-to-end by\ndistilling Triton-specific knowledge through supervised fine-tuning on curated\ndatasets, and further improving code quality via reinforcement learning (RL)\nwith robust, verifiable rewards and hierarchical reward assignment. Our RL\nframework robustly detects reward hacking and guides both reasoning traces and\ncode tokens through fine-grained verification and hierarchical reward\ndecomposition, enabling the model to generate high-quality Triton kernels that\ncan truly replace existing modules. With robust and fine-grained evaluation,\nour experiments on KernelBench demonstrate that TritonRL achieves\nstate-of-the-art correctness and speedup, surpassing all other Triton-specific\nmodels and underscoring the effectiveness of our RL-based training paradigm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTritonRL\uff0c\u901a\u8fc7\u6709\u76d1\u7763\u5fae\u8c03\u4e0e\u7ec6\u7c92\u5ea6\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\uff0c\u653b\u514b\u4e86Triton kernel\u81ea\u52a8\u751f\u6210\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u4e0e\u8bc4\u4f30\u56f0\u96be\u95ee\u9898\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u5177\u6709\u663e\u8457\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u5feb\u901f\u53d1\u5c55\u7684LLM\u5bf9\u81ea\u52a8\u5316\u3001\u9ad8\u6027\u80fd\u7cfb\u7edfkernel\u7684\u9700\u6c42\u589e\u52a0\u3002Triton kernel\u751f\u6210\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u548c\u8bc4\u4ef7\u6807\u51c6\u4e0d\u5168\u7b49\u96be\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5b8c\u5168\u89e3\u51b3\u3002", "method": "\u63d0\u51faTritonRL\uff0c\u4e00\u79cd\u4e13\u4e3aTriton kernel\u751f\u6210\u8bbe\u8ba1\u7684LLM\uff0c\u91c7\u7528\u65b0\u9896\u7684\u8bad\u7ec3\u6846\u67b6\u3002\u65b9\u6cd5\u5305\u542b\uff1a1\uff09\u5728\u7cbe\u9009\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6709\u76d1\u7763\u5fae\u8c03\uff0c\u51dd\u7ec3Triton\u4e13\u6709\u77e5\u8bc6\uff1b2\uff09\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8fdb\u4e00\u6b65\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\uff0c\u5229\u7528\u5177\u6709\u53ef\u9a8c\u8bc1\u6027\u548c\u5206\u5c42\u5956\u52b1\u7684\u673a\u5236\uff0c\u6291\u5236reward hacking\u73b0\u8c61\u3002RL\u6846\u67b6\u8fd8\u5f15\u5165\u7ec6\u7c92\u5ea6\u9a8c\u8bc1\u548c\u5206\u5c42\u5956\u52b1\u5206\u89e3\uff0c\u5168\u9762\u5f15\u5bfc\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u3002", "result": "TritonRL\u5728KernelBench\u4e0a\u5b9e\u73b0\u4e86\u4e1a\u754c\u9886\u5148\u7684\u6b63\u786e\u7387\u548c\u52a0\u901f\u6548\u679c\uff0c\u8d85\u8d8a\u4e86\u6240\u6709\u5176\u5b83Triton\u4e13\u7528\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86\u8be5RL\u8bad\u7ec3\u8303\u5f0f\u7684\u6709\u6548\u6027\u3002", "conclusion": "TritonRL\u901a\u8fc7\u521b\u65b0\u7684RL\u8bad\u7ec3\u65b9\u6848\u5927\u5e45\u63d0\u5347Triton kernel\u751f\u6210\u8d28\u91cf\u548c\u5b9e\u7528\u6027\uff0c\u6709\u671b\u66ff\u4ee3\u73b0\u6709\u624b\u52a8\u6a21\u5757\uff0c\u662f\u81ea\u52a8\u5316kernel\u751f\u6210\u7684\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2510.18651", "categories": ["cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18651", "abs": "https://arxiv.org/abs/2510.18651", "authors": ["Uraz Odyurt", "\u00d6mer Sayilir", "Mari\u00eblle Stoelinga", "Vadim Zaytsev"], "title": "CPSLint: A Domain-Specific Language Providing Data Validation and Sanitisation for Industrial Cyber-Physical Systems", "comment": null, "summary": "Raw datasets are often too large and unstructured to work with directly, and\nrequire a data preparation process. The domain of industrial Cyber-Physical\nSystems (CPS) is no exception, as raw data typically consists of large amounts\nof time-series data logging the system's status in regular time intervals. Such\ndata has to be sanity checked and preprocessed to be consumable by data-centric\nworkflows. We introduce CPSLint, a Domain-Specific Language designed to provide\ndata preparation for industrial CPS. We build up on the fact that many raw data\ncollections in the CPS domain require similar actions to render them suitable\nfor Machine-Learning (ML) solutions, e.g., Fault Detection and Identification\n(FDI) workflows, yet still vary enough to hope for one universally applicable\nsolution.\n  CPSLint's main features include type checking and enforcing constraints\nthrough validation and remediation for data columns, such as imputing missing\ndata from surrounding rows. More advanced features cover inference of extra\nCPS-specific data structures, both column-wise and row-wise. For instance, as\nrow-wise structures, descriptive execution phases are an effective method of\ndata compartmentalisation are extracted and prepared for ML-assisted FDI\nworkflows. We demonstrate CPSLint's features through a proof of concept\nimplementation.", "AI": {"tldr": "\u9488\u5bf9\u5de5\u4e1aCPS\u539f\u59cb\u65f6\u5e8f\u6570\u636e\u590d\u6742\u4e14\u5e9e\u5927\u7684\u95ee\u9898\uff0c\u8bba\u6587\u63d0\u51faCPSLint DSL\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u6570\u636e\u9884\u5904\u7406\u548c\u7ed3\u6784\u63a8\u65ad\uff0c\u4e3a\u6545\u969c\u68c0\u6d4b\u7b49\u6570\u636e\u5e94\u7528\u6253\u4e0b\u57fa\u7840\uff0c\u5e76\u901a\u8fc7\u539f\u578b\u9a8c\u8bc1\u5176\u529f\u80fd\u3002", "motivation": "\u5de5\u4e1aCPS\u7cfb\u7edf\u539f\u59cb\u6570\u636e\u4f53\u79ef\u5927\u4e14\u7ed3\u6784\u590d\u6742\uff0c\u76f4\u63a5\u5206\u6790\u56f0\u96be\uff0c\u9700\u5f00\u53d1\u6709\u6548\u7684\u6570\u636e\u51c6\u5907\u5de5\u5177\uff0c\u7279\u522b\u662f\u4e3a\u673a\u5668\u5b66\u4e60\u4e0e\u6545\u969c\u68c0\u6d4b\u7b49\u6d41\u7a0b\u670d\u52a1\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09CPSLint\uff0c\u901a\u8fc7\u7c7b\u578b\u68c0\u67e5\u3001\u7ea6\u675f\u9a8c\u8bc1\u4e0e\u4fee\u590d\u3001\u7f3a\u5931\u503c\u586b\u8865\uff0c\u4ee5\u53ca\u63a8\u65adCPS\u76f8\u5173\u6570\u636e\u7ed3\u6784\uff08\u5217\u548c\u884c\u7ea7\uff09\uff0c\u5bf9\u539f\u59cb\u6570\u636e\u8fdb\u884c\u9884\u5904\u7406\u3002", "result": "CPSLint\u80fd\u591f\u81ea\u52a8\u5316\u8fdb\u884c\u7c7b\u578b\u68c0\u67e5\u3001\u7ea6\u675f\u9a8c\u8bc1\u3001\u6570\u636e\u8865\u5168\u548c\u63a8\u65ad\u6570\u636e\u7ed3\u6784\uff0c\u5e76\u901a\u8fc7\u539f\u578b\u5c55\u793a\u5176\u6709\u6548\u6027\uff0c\u80fd\u663e\u8457\u63d0\u5347CPS\u6570\u636e\u51c6\u5907\u6548\u7387\u548c\u8d28\u91cf\u3002", "conclusion": "CPSLint\u6709\u6548\u5730\u4e3a\u5de5\u4e1aCPS\u9886\u57df\u7684\u6570\u636e\u51c6\u5907\u4efb\u52a1\u63d0\u4f9bDSL\u8bed\u8a00\u652f\u6301\uff0c\u80fd\u591f\u5904\u7406\u548c\u6539\u5584\u539f\u59cb\u65f6\u5e8f\u6570\u636e\u4ee5\u9002\u5e94\u673a\u5668\u5b66\u4e60\u7b49\u4e0b\u6e38\u4efb\u52a1\u3002"}}
{"id": "2510.18429", "categories": ["cs.LO", "cs.AI", "I.2.3"], "pdf": "https://arxiv.org/pdf/2510.18429", "abs": "https://arxiv.org/abs/2510.18429", "authors": ["Alexander Bentkamp", "Jasmin Blanchette", "Matthias Hetzenberger", "Uwe Waldmann"], "title": "Optimistic Higher-Order Superposition", "comment": null, "summary": "The $\\lambda$-superposition calculus is a successful approach to proving\nhigher-order formulas. However, some parts of the calculus are extremely\nexplosive, notably due to the higher-order unifier enumeration and the\nfunctional extensionality axiom. In the present work, we introduce an\n\"optimistic\" version of $\\lambda$-superposition that addresses these two\nissues. Specifically, our new calculus delays explosive unification problems\nusing constraints stored along with the clauses, and it applies functional\nextensionality in a more targeted way. The calculus is sound and refutationally\ncomplete with respect to a Henkin semantics. We have yet to implement it in a\nprover, but examples suggest that it will outperform, or at least usefully\ncomplement, the original $\\lambda$-superposition calculus.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4f18\u4e8e\u539f\u59cb\u03bb-superposition\u7684\u65b0\u53d8\u4f53\uff0c\u901a\u8fc7\u5ef6\u8fdf\u7206\u70b8\u6027\u5355\u5316\u5e76\u4f18\u5316\u6cdb\u51fd\u5916\u5ef6\uff0c\u7406\u8bba\u4e0a\u66f4\u9ad8\u6548\u4e14\u5b8c\u5907\uff0c\u4f46\u5c1a\u9700\u5b9e\u9645\u5b9e\u73b0\u3002", "motivation": "\u539f\u6709\u7684\u03bb-superposition\u6f14\u7b97\u5728\u5904\u7406\u9ad8\u9636\u516c\u5f0f\u65f6\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u5728\u9ad8\u9636\u5355\u5316\u679a\u4e3e\u548c\u6cdb\u51fd\u5916\u5ef6\u516c\u7406\u65b9\u9762\u8ba1\u7b97\u7206\u70b8\uff0c\u5f71\u54cd\u5b9e\u9645\u5e94\u7528\u6548\u7387\u3002\u4f5c\u8005\u5e0c\u671b\u89e3\u51b3\u8fd9\u4e9b\u6548\u7387\u74f6\u9888\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u201c\u4e50\u89c2\u578b\u201d\u03bb-superposition\u6f14\u7b97\uff0c\u901a\u8fc7\u5c06\u7206\u70b8\u6027\u7684\u5355\u5316\u95ee\u9898\u5ef6\u8fdf\uff0c\u5e76\u5c06\u6cdb\u51fd\u5916\u5ef6\u7684\u5e94\u7528\u66f4\u6709\u9488\u5bf9\u6027\u5730\u63a7\u5236\uff0c\u4f7f\u7528\u7ea6\u675f\u4e0e\u5b50\u53e5\u4e00\u540c\u5b58\u50a8\u7ba1\u7406\u3002", "result": "\u65b0\u6f14\u7b97\u5728Henkin\u8bed\u4e49\u4e0b\u662f\u53ef\u9760\u4e14\u53ef\u8bc1\u4f2a\u5b8c\u5907\u7684\u3002\u76ee\u524d\u5c1a\u672a\u5b9e\u73b0\u539f\u578b\uff0c\u4f46\u4f8b\u5b50\u5c55\u793a\u5176\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u53ef\u80fd\u4f18\u4e8e\u3001\u6216\u6709\u6548\u8865\u5145\u539f\u6709\u03bb-superposition\u6f14\u7b97\u3002", "conclusion": "\u4e50\u89c2\u578b\u03bb-superposition\u6f14\u7b97\u901a\u8fc7\u4f18\u5316\u7206\u70b8\u6027\u6b65\u9aa4\uff0c\u63d0\u5347\u4e86\u9ad8\u9636\u516c\u5f0f\u8bc1\u660e\u6f5c\u529b\uff0c\u5728\u7406\u8bba\u4e0a\u4fdd\u8bc1\u53ef\u9760\u6027\u548c\u5b8c\u5907\u6027\uff0c\u6709\u671b\u5728\u5b9e\u9645\u81ea\u52a8\u8bc1\u660e\u9886\u57df\u63d0\u9ad8\u6027\u80fd\u3002"}}
{"id": "2510.17881", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17881", "abs": "https://arxiv.org/abs/2510.17881", "authors": ["Yizhuo Chen", "Xin Liu", "Ruijie Wang", "Zheng Li", "Pei Chen", "Changlong Yu", "Priyanka Nigam", "Meng Jiang", "Bing Yin"], "title": "POPI: Personalizing LLMs via Optimized Natural Language Preference Inference", "comment": null, "summary": "Large language models (LLMs) achieve strong benchmark performance, yet user\nexperiences remain inconsistent due to diverse preferences in style, tone, and\nreasoning mode. Nevertheless, existing alignment techniques such as\nreinforcement learning from human feedback (RLHF) or Direct Preference\nOptimization (DPO) largely optimize toward population-level averages and\noverlook individual variation. Naive personalization strategies like per-user\nfine-tuning are computationally prohibitive, and in-context approaches that\nprepend raw user signals often suffer from inefficiency and noise. To address\nthese challenges, we propose POPI, a general framework that introduces a\npreference inference model to distill heterogeneous user signals into concise\nnatural language summaries. These summaries act as transparent, compact, and\ntransferable personalization representations that condition a shared generation\nmodel to produce personalized responses. POPI jointly optimizes both preference\ninference and personalized generation under a unified objective using\nreinforcement learning, ensuring summaries maximally encode useful preference\ninformation. Extensive experiments across four personalization benchmarks\ndemonstrate that POPI consistently improves personalization accuracy while\nreducing context overhead by a large margin. Moreover, optimized summaries\nseamlessly transfer to frozen off-the-shelf LLMs, enabling plug-and-play\npersonalization without weight updates.", "AI": {"tldr": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u96be\u4ee5\u56e0\u5e94\u7528\u6237\u4e2a\u6027\u5316\u9700\u6c42\uff0c\u672c\u6587\u63d0\u51faPOPI\u6846\u67b6\uff0c\u7528\u504f\u597d\u63a8\u65ad\u6a21\u578b\u751f\u6210\u7528\u6237\u4e2a\u6027\u5316\u6458\u8981\uff0c\u9ad8\u6548\u4e14\u53ef\u8fc1\u79fb\uff0c\u7edf\u4e00\u4f18\u5316\u63a8\u65ad\u4e0e\u751f\u6210\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u5347\u4e2a\u6027\u5316\u6548\u679c\u4e14\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u5f53\u524dLLM\u867d\u7136\u5728\u57fa\u51c6\u6d4b\u8bd5\u8868\u73b0\u4f18\u79c0\uff0c\u4f46\u7528\u6237\u9700\u6c42\u5343\u5dee\u4e07\u522b\uff0cRLHF\u7b49\u5bf9\u9f50\u65b9\u6cd5\u53ea\u8ffd\u6c42\u5e73\u5747\u6548\u679c\uff0c\u65e0\u6cd5\u517c\u987e\u4e2a\u4f53\u5dee\u5f02\uff1b\u800c\u4f20\u7edf\u4e2a\u6027\u5316\u65b9\u5f0f\u5982\u5355\u72ec\u5fae\u8c03\u8ba1\u7b97\u6d88\u8017\u6781\u5927\uff0c\u7eaf\u4e0a\u4e0b\u6587\u62fc\u63a5\u6cd5\u53c8\u6613\u53d7\u566a\u58f0\u5e72\u6270\uff0c\u6548\u7387\u4f4e\u3002", "method": "\u63d0\u51faPOPI\u6846\u67b6\uff0c\u5229\u7528\u504f\u597d\u63a8\u65ad\u6a21\u578b\u5c06\u591a\u6837\u7528\u6237\u4fe1\u53f7\u63d0\u70bc\u4e3a\u7b80\u660e\u81ea\u7136\u8bed\u8a00\u6458\u8981\uff0c\u518d\u4ee5\u8fd9\u4e9b\u6458\u8981\u4f5c\u4e3a\u4e2a\u6027\u5316\u6307\u4ee4\u6761\u4ef6\uff0c\u9a71\u52a8\u751f\u6210\u6a21\u578b\u8f93\u51fa\u4e2a\u6027\u5316\u5185\u5bb9\u3002POPI\u7528\u7edf\u4e00\u76ee\u6807\u8054\u5408\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u63a8\u65ad\u4e0e\u751f\u6210\u8fc7\u7a0b\uff0c\u786e\u4fdd\u6458\u8981\u7f16\u7801\u6700\u5927\u6709\u6548\u504f\u597d\u4fe1\u606f\u3002", "result": "\u5728\u56db\u4e2a\u4e2a\u6027\u5316\u57fa\u51c6\u4e0a\uff0cPOPI\u663e\u8457\u63d0\u5347\u4e2a\u6027\u5316\u51c6\u786e\u7387\u5e76\u5927\u5e45\u51cf\u5c11\u4e0a\u4e0b\u6587\u5f00\u9500\u3002\u5176\u4f18\u5316\u5f97\u5230\u7684\u504f\u597d\u6458\u8981\u53ef\u65e0\u7f1d\u8fc1\u79fb\u5230\u5176\u4ed6\u672a\u5fae\u8c03\u7684\u5927\u6a21\u578b\uff0c\u5b9e\u73b0\u5373\u63d2\u5373\u7528\u4e2a\u6027\u5316\uff0c\u65e0\u9700\u518d\u6b21\u8bad\u7ec3\u6216\u4fee\u6539\u6a21\u578b\u6743\u91cd\u3002", "conclusion": "POPI\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u900f\u660e\u3001\u53ef\u8fc1\u79fb\u7684LLM\u4e2a\u6027\u5316\u5de5\u5177\uff0c\u5728\u517c\u987e\u51c6\u786e\u7387\u548c\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\uff0c\u4e3a\u6a21\u578b\u5927\u89c4\u6a21\u5e94\u7528\u548c\u7528\u6237\u591a\u6837\u6027\u9700\u6c42\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2510.17894", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.17894", "abs": "https://arxiv.org/abs/2510.17894", "authors": ["Yunhan Qiao", "Md Istiak Hossain Shihab", "Christopher Hundhausen"], "title": "A Systematic Literature Review of the Use of GenAI Assistants for Code Comprehension: Implications for Computing Education Research and Practice", "comment": null, "summary": "The ability to comprehend code has long been recognized as an essential skill\nin software engineering. As programmers lean more heavily on generative\nartificial intelligence (GenAI) assistants to develop code solutions, it is\nbecoming increasingly important for programmers to comprehend GenAI solutions\nso that they can verify their appropriateness and properly integrate them into\nexisting code. At the same time, GenAI tools are increasingly being enlisted to\nprovide programmers with tailored explanations of code written both by GenAI\nand humans. Thus, in computing education, GenAI presents new challenges and\nopportunities for learners who are trying to comprehend computer programs. To\nprovide computing educators with evidence-based guidance on the use of GenAI to\nfacilitate code comprehension and to identify directions for future research,\nwe present a systematic literature review (SLR) of state-of-the-art approaches\nand tools that leverage GenAI to enhance code comprehension. Our SLR focuses on\n31 studies published between 2022 and 2024. Despite their potential, GenAI\nassistants often yield inaccurate or unclear explanations, and novice\nprogrammers frequently struggle to craft effective prompts, thereby impeding\ntheir ability to leverage GenAI to aid code comprehension. Our review\nclassifies GenAI-based approaches and tools, identifies methods used to study\nthem, and summarizes the empirical evaluations of their effectiveness. We\nconsider the implications of our findings for computing education research and\npractice, and identify directions for future research.", "AI": {"tldr": "\u7cfb\u7edf\u56de\u987eGenAI\u7528\u4e8e\u4ee3\u7801\u7406\u89e3\u7684\u6700\u65b0\u65b9\u6cd5\u4e0e\u5de5\u5177\uff0c\u53d1\u73b0\u5176\u5728\u4ee3\u7801\u89e3\u91ca\u548c\u6559\u80b2\u4e0a\u7684\u6f5c\u529b\u4e0e\u4e0d\u8db3\uff0c\u5e76\u6307\u660e\u6539\u8fdb\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u7a0b\u5e8f\u5458\u8d8a\u6765\u8d8a\u4f9d\u8d56\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u52a9\u624b\u6765\u5f00\u53d1\u4ee3\u7801\uff0c\u7406\u89e3\u8fd9\u4e9bGenAI\u6240\u751f\u6210\u7684\u4ee3\u7801\u53d8\u5f97\u6108\u52a0\u91cd\u8981\u3002\u8fd9\u76f4\u63a5\u5f71\u54cd\u4ee3\u7801\u7684\u6b63\u786e\u6027\u9a8c\u8bc1\u548c\u4e0e\u73b0\u6709\u4ee3\u7801\u7684\u96c6\u6210\u3002\u540c\u65f6\uff0cGenAI\u9010\u6e10\u88ab\u7528\u4e8e\u4e3a\u7a0b\u5e8f\u5458\u63d0\u4f9b\u5b9a\u5236\u5316\u7684\u4ee3\u7801\u89e3\u91ca\uff0c\u5e26\u6765\u4e86\u5728\u8ba1\u7b97\u673a\u6559\u80b2\u9886\u57df\u5173\u4e8e\u7a0b\u5e8f\u7406\u89e3\u7684\u65b0\u673a\u9047\u4e0e\u6311\u6218\u3002", "method": "\u4f5c\u8005\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff08SLR\uff09\uff0c\u56de\u987e\u4e862022\u5e74\u81f32024\u5e74\u95f4\u53d1\u8868\u768431\u9879\u76f8\u5173\u7814\u7a76\uff0c\u5bf9\u5f53\u524d\u5229\u7528GenAI\u63d0\u5347\u4ee3\u7801\u7406\u89e3\u7684\u6280\u672f\u548c\u5de5\u5177\u8fdb\u884c\u4e86\u7cfb\u7edf\u68b3\u7406\u548c\u5206\u7c7b\uff0c\u7740\u91cd\u603b\u7ed3\u4e86\u5b9e\u8bc1\u8bc4\u4f30\u7ed3\u679c\u3002", "result": "\u5f53\u524dGenAI\u52a9\u624b\u5728\u4ee3\u7801\u89e3\u91ca\u65b9\u9762\u5c1a\u5b58\u5728\u8bf8\u5982\u4e0d\u51c6\u786e\u6216\u4e0d\u6e05\u6670\u7b49\u95ee\u9898\uff0c\u65b0\u624b\u7a0b\u5e8f\u5458\u96be\u4ee5\u8bbe\u8ba1\u6709\u6548\u7684\u63d0\u793a\u8bed\uff0c\u5bfc\u81f4GenAI\u52a9\u529b\u4ee3\u7801\u7406\u89e3\u53d7\u9650\u3002\u6587\u732e\u7efc\u8ff0\u7cfb\u7edf\u5f52\u7c7b\u4e86\u76f8\u5173\u5de5\u5177\u548c\u65b9\u6cd5\uff0c\u603b\u7ed3\u4e86\u8fd9\u4e9b\u5de5\u5177\u7684\u5b9e\u9645\u6548\u679c\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u5728\u6559\u80b2\u9886\u57df\u7684\u5e94\u7528\u548c\u5c40\u9650\u3002", "conclusion": "GenAI\u5728\u63d0\u5347\u4ee3\u7801\u7406\u89e3\u80fd\u529b\u65b9\u9762\u5c55\u73b0\u51fa\u4e00\u5b9a\u6f5c\u529b\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u4ecd\u6709\u8bf8\u591a\u6311\u6218\uff08\u5982\u89e3\u91ca\u51c6\u786e\u6027\u548c\u7528\u6237\u64cd\u4f5c\u6027\uff09\u3002\u672a\u6765\u9700\u6df1\u5165\u63a2\u8ba8\u5982\u4f55\u6539\u8fdbGenAI\u5de5\u5177\u4ee5\u66f4\u597d\u652f\u6301\u7f16\u7a0b\u6559\u80b2\u548c\u4ee3\u7801\u7406\u89e3\u3002"}}
{"id": "2510.18452", "categories": ["cs.LO", "I.2.3; F.4.1"], "pdf": "https://arxiv.org/pdf/2510.18452", "abs": "https://arxiv.org/abs/2510.18452", "authors": ["Alexander Bentkamp", "Jasmin Blanchette", "Matthias Hetzenberger"], "title": "Term Orders for Optimistic Lambda-Superposition", "comment": null, "summary": "We introduce $\\lambda$KBO and $\\lambda$LPO, two variants of the Knuth-Bendix\norder (KBO) and the lexicographic path order (LPO) designed for use with the\n$\\lambda$-superposition calculus. We establish the desired properties via\nencodings into the familiar first-order KBO and LPO.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9002\u7528\u4e8e $\u0001$-superposition \u6f14\u7b97\u7684\u6392\u5e8f\u53d8\u4f53\uff08$\u0001$KBO \u548c $\u0001$LPO\uff09\uff0c\u5e76\u901a\u8fc7\u4e0e\u4e00\u9636\u6392\u5e8f\u7684\u7f16\u7801\u8bc1\u660e\u4e86\u5b83\u4eec\u7684\u6709\u6548\u6027\u548c\u6027\u8d28\u3002", "motivation": "\u4e3a\u4e86\u9002\u5e94 $\u0001$-superposition \u6f14\u7b97\uff0c\u9700\u8981\u5bf9\u7ecf\u5178\u7684 KBO \u548c LPO \u8fdb\u884c\u53d8\u4f53\u8bbe\u8ba1\uff0c\u4f7f\u4e4b\u9002\u914d\u9ad8\u9636/\u03bb\u9879\u73af\u5883\u3002", "method": "\u901a\u8fc7\u5c06\u65b0\u7684\u6392\u5e8f\uff08$\u0001$KBO \u548c $\u0001$LPO\uff09\u7f16\u7801\u5230\u719f\u6089\u7684\u4e00\u9636 KBO \u548c LPO\uff0c\u4ece\u800c\u8bc1\u660e\u4e86\u8fd9\u4e9b\u6392\u5e8f\u7684\u76f8\u5173\u6027\u8d28\u3002", "result": "\u6210\u529f\u5f15\u5165\u4e86\u9002\u7528\u4e8e $\u0001$-superposition \u7684 KBO \u548c LPO \u53d8\u4f53\uff0c\u5e76\u8bc1\u660e\u4e86\u5b83\u4eec\u7684\u57fa\u672c\u6027\u8d28\uff0c\u53ef\u901a\u8fc7\u4e00\u9636\u7f16\u7801\u65b9\u6cd5\u5b9e\u73b0\u3002", "conclusion": "$\u0001$KBO \u548c $\u0001$LPO \u53ef\u4ee5\u6709\u6548\u5730\u7528\u4e8e $\u0001$-superposition \u6f14\u7b97\uff0c\u5e76\u80fd\u591f\u901a\u8fc7\u7f16\u7801\u8f6c\u5316\u4e3a\u4e00\u9636\u7684 KBO \u548c LPO \u6765\u5efa\u7acb\u6240\u9700\u6027\u8d28\u3002"}}
{"id": "2510.17892", "categories": ["cs.CL", "A.1; I.2.7; H.3"], "pdf": "https://arxiv.org/pdf/2510.17892", "abs": "https://arxiv.org/abs/2510.17892", "authors": ["Zhyar Rzgar K. Rostam", "G\u00e1bor Kert\u00e9sz"], "title": "Advances in Pre-trained Language Models for Domain-Specific Text Classification: A Systematic Review", "comment": "41 pages, 10 figures, 13 tables", "summary": "The exponential increase in scientific literature and online information\nnecessitates efficient methods for extracting knowledge from textual data.\nNatural language processing (NLP) plays a crucial role in addressing this\nchallenge, particularly in text classification tasks. While large language\nmodels (LLMs) have achieved remarkable success in NLP, their accuracy can\nsuffer in domain-specific contexts due to specialized vocabulary, unique\ngrammatical structures, and imbalanced data distributions. In this systematic\nliterature review (SLR), we investigate the utilization of pre-trained language\nmodels (PLMs) for domain-specific text classification. We systematically review\n41 articles published between 2018 and January 2024, adhering to the PRISMA\nstatement (preferred reporting items for systematic reviews and meta-analyses).\nThis review methodology involved rigorous inclusion criteria and a multi-step\nselection process employing AI-powered tools. We delve into the evolution of\ntext classification techniques and differentiate between traditional and modern\napproaches. We emphasize transformer-based models and explore the challenges\nand considerations associated with using LLMs for domain-specific text\nclassification. Furthermore, we categorize existing research based on various\nPLMs and propose a taxonomy of techniques used in the field. To validate our\nfindings, we conducted a comparative experiment involving BERT, SciBERT, and\nBioBERT in biomedical sentence classification. Finally, we present a\ncomparative study on the performance of LLMs in text classification tasks\nacross different domains. In addition, we examine recent advancements in PLMs\nfor domain-specific text classification and offer insights into future\ndirections and limitations in this rapidly evolving domain.", "AI": {"tldr": "\u8be5\u7efc\u8ff0\u7cfb\u7edf\u68b3\u7406\u4e86\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08PLM\uff09\u5728\u9886\u57df\u6587\u672c\u5206\u7c7b\u4e2d\u7684\u5e94\u7528\u73b0\u72b6\u4e0e\u6311\u6218\uff0c\u5bf941\u7bc7\u6587\u732e\u8fdb\u884c\u4e86\u5bf9\u6bd4\u548c\u5f52\u7eb3\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660ePLM\u5728\u751f\u7269\u533b\u5b66\u7b49\u4e13\u4e1a\u9886\u57df\u7684\u6587\u672c\u5206\u7c7b\u6548\u679c\uff0c\u63d0\u51fa\u672a\u6765\u4f18\u5316\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u79d1\u6280\u6587\u732e\u548c\u7f51\u7edc\u4fe1\u606f\u7684\u6fc0\u589e\uff0c\u5982\u4f55\u9ad8\u6548\u5730\u4ece\u6587\u672c\u6570\u636e\u4e2d\u63d0\u53d6\u77e5\u8bc6\u6210\u4e3a\u4e9f\u9700\u89e3\u51b3\u7684\u95ee\u9898\u3002NLP\u662f\u5728\u6587\u672c\u5206\u7c7b\u7b49\u4efb\u52a1\u4e2d\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\u7684\u5173\u952e\u3002\u7136\u800c\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4e13\u4e1a\u9886\u57df\u7684\u6548\u679c\u6709\u9650\uff0c\u4e3b\u8981\u56e0\u4e13\u4e1a\u8bcd\u6c47\u3001\u7279\u6b8a\u8bed\u6cd5\u548c\u4e0d\u5e73\u8861\u6570\u636e\u5206\u5e03\u6240\u81f4\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff08SLR\uff09\u7684\u65b9\u6cd5\uff0c\u4f9d\u636ePRISMA\u6807\u51c6\uff0c\u7cfb\u7edf\u68b3\u74062018\u5e74\u81f32024\u5e74\u95f441\u7bc7\u76f8\u5173\u6587\u732e\uff0c\u4e25\u683c\u628a\u63a7\u7eb3\u5165\u6807\u51c6\u5e76\u591a\u6b65\u7b5b\u9009\uff0c\u8f85\u4ee5AI\u5de5\u5177\u3002\u91cd\u70b9\u5206\u6790Transformer\u4e3a\u4ee3\u8868\u7684\u73b0\u4ee3\u6a21\u578b\u7684\u6f14\u8fdb\uff0c\u5bf9\u4e3b\u6d41PLM\u8fdb\u884c\u5f52\u7c7b\u3001\u5efa\u7acb\u6280\u672f\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u901a\u8fc7BERT\u3001SciBERT\u548cBioBERT\u5bf9\u751f\u7269\u533b\u5b66\u6587\u672c\u5206\u7c7b\u7684\u5bf9\u6bd4\u5b9e\u9a8c\u9a8c\u8bc1\u4e0e\u8865\u5145\u6587\u732e\u7814\u7a76\u3002", "result": "\u5f52\u7eb3\u4e86\u9886\u57df\u6587\u672c\u5206\u7c7b\u4e2d\u65b0\u65e7\u6280\u672f\u7684\u6f14\u53d8\u8d8b\u52bf\u548c\u6280\u672f\u5206\u7c7b\uff0c\u6f84\u6e05\u4e86LLM\u5728\u4e13\u4e1a\u573a\u666f\u4e2d\u7684\u96be\u70b9\u548c\u6ce8\u610f\u4e8b\u9879\u3002\u5ba2\u89c2\u5bf9\u6bd4\u4e86\u4e0d\u540cPLM\uff08\u5982BERT\u3001SciBERT\u3001BioBERT\uff09\u5728\u4e0d\u540c\u9886\u57df\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u5f53\u524dPLM\u7684\u53d1\u5c55\u65b9\u5411\u548c\u9762\u4e34\u7684\u4e3b\u8981\u5c40\u9650\u3002", "conclusion": "PLM\u5728\u9886\u57df\u6587\u672c\u5206\u7c7b\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u4f46\u4ecd\u5b58\u5728\u4e13\u7528\u8bcd\u6c47\u5904\u7406\u3001\u6570\u636e\u4e0d\u5747\u8861\u7b49\u65b9\u9762\u7684\u6311\u6218\u3002\u672a\u6765\u9700\u9488\u5bf9\u9886\u57df\u7279\u6027\u8fdb\u4e00\u6b65\u4f18\u5316\u6a21\u578b\u8bbe\u8ba1\u3002\u6b64\u6587\u732e\u7efc\u8ff0\u4e3a\u540e\u7eed\u76f8\u5173\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u7cfb\u7edf\u53c2\u8003\u548c\u5c55\u671b\u3002"}}
{"id": "2510.17925", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17925", "abs": "https://arxiv.org/abs/2510.17925", "authors": ["George Ma", "Anurag Koul", "Qi Chen", "Yawen Wu", "Sachit Kuhar", "Yu Yu", "Aritra Sengupta", "Varun Kumar", "Murali Krishna Ramanathan"], "title": "SpecAgent: A Speculative Retrieval and Forecasting Agent for Code Completion", "comment": null, "summary": "Large Language Models (LLMs) excel at code-related tasks but often struggle\nin realistic software repositories, where project-specific APIs and cross-file\ndependencies are crucial. Retrieval-augmented methods mitigate this by\ninjecting repository context at inference time. The low inference-time latency\nbudget affects either retrieval quality or the added latency adversely impacts\nuser experience. We address this limitation with SpecAgent, an agent that\nimproves both latency and code-generation quality by proactively exploring\nrepository files during indexing and constructing speculative context that\nanticipates future edits in each file. This indexing-time asynchrony allows\nthorough context computation, masking latency, and the speculative nature of\nthe context improves code-generation quality. Additionally, we identify the\nproblem of future context leakage in existing benchmarks, which can inflate\nreported performance. To address this, we construct a synthetic, leakage-free\nbenchmark that enables a more realistic evaluation of our agent against\nbaselines. Experiments show that SpecAgent consistently achieves absolute gains\nof 9-11% (48-58% relative) compared to the best-performing baselines, while\nsignificantly reducing inference latency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSpecAgent\uff0c\u901a\u8fc7\u7d22\u5f15\u65f6\u4e3b\u52a8\u6784\u5efa\u63a8\u6d4b\u6027\u4e0a\u4e0b\u6587\uff0c\u663e\u8457\u63d0\u5347LLM\u4ee3\u7801\u4efb\u52a1\u8d28\u91cf\u548c\u6548\u7387\uff0c\u5e76\u6784\u5efa\u65e0\u672a\u6765\u6cc4\u9732\u7684\u65b0\u57fa\u7ebf\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u5728\u5904\u7406\u9879\u76ee\u7279\u5b9aAPI\u548c\u8de8\u6587\u4ef6\u4f9d\u8d56\u65f6\u53d7\u5236\u4e8e\u63a8\u7406\u5ef6\u8fdf\u4e0e\u68c0\u7d22\u8d28\u91cf\u7684\u6743\u8861\uff0c\u5f71\u54cd\u7528\u6237\u4f53\u9a8c\uff1b\u540c\u65f6\uff0c\u73b0\u6709\u8bc4\u6d4b\u5b58\u5728\u672a\u6765\u4e0a\u4e0b\u6587\u6cc4\u9732\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u6027\u80fd\u8bc4\u4f30\u5938\u5927\u3002", "method": "\u63d0\u51faSpecAgent\u4ee3\u7406\u65b9\u6cd5\uff0c\u5728\u7d22\u5f15\u9636\u6bb5\u4e3b\u52a8\u63a2\u7d22\u4ed3\u5e93\u6587\u4ef6\u5e76\u6784\u5efa\u63a8\u6d4b\u6027\u4e0a\u4e0b\u6587\uff0c\u540c\u65f6\u5f00\u53d1\u4e86\u5408\u6210\u3001\u65e0\u672a\u6765\u4fe1\u606f\u6cc4\u9732\u7684\u8bc4\u6d4b\u57fa\u51c6\u3002", "result": "SpecAgent\u5728\u65b0\u57fa\u51c6\u4e0a\u7edd\u5bf9\u63d0\u53479-11%\uff0c\u76f8\u5bf9\u63d0\u534748-58%\uff0c\u4e14\u63a8\u7406\u5ef6\u8fdf\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "SpecAgent\u80fd\u591f\u5728\u51cf\u5c11\u63a8\u7406\u5ef6\u8fdf\u7684\u540c\u65f6\uff0c\u5927\u5e45\u63d0\u5347\u4ee3\u7801\u751f\u6210\u7684\u8d28\u91cf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u73b0\u5b9e\u8f6f\u4ef6\u4ed3\u5e93\u4e2d\u7684\u6027\u80fd\u5c40\u9650\u3002"}}
{"id": "2510.18542", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2510.18542", "abs": "https://arxiv.org/abs/2510.18542", "authors": ["Alejandro D\u00edaz-Caro", "Octavio Malherbe", "Rafael Romero"], "title": "Basis-Sensitive Quantum Typing via Realisability", "comment": "18 pages plus appendix", "summary": "We present $\\lambda_B$, a quantum-control $\\lambda$-calculus that refines\nprevious basis-sensitive systems by allowing abstractions to be expressed with\nrespect to arbitrary -- possibly entangled -- bases. Each abstraction and let\nconstruct is annotated with a basis, and a new basis-dependent substitution\ngoverns the decomposition of value distributions. These extensions preserve the\nexpressive power of earlier calculi while enabling finer reasoning about\nprograms under basis changes. A realisability semantics connects the reduction\nsystem with the type system, yielding a direct characterisation of unitary\noperators and ensuring safety by construction. From this semantics we derive a\nvalidated family of typing rules, forming the foundation of a type-safe quantum\nprogramming language. We illustrate the expressive benefits of $\\lambda_B$\nthrough examples such as Deutsch's algorithm and quantum teleportation, where\nbasis-aware typing captures classical determinism and deferred-measurement\nbehaviour within a uniform framework.", "AI": {"tldr": "\u672c\u8bba\u6587\u5efa\u7acb\u4e86\u4e00\u4e2a\u65b0\u578b\u7684\u91cf\u5b50\u63a7\u5236lambda\u6f14\u7b97\u4f53\u7cfb\uff0c\u901a\u8fc7\u57fa\u7840\uff08basis\uff09\u6807\u6ce8\u4e0e\u66ff\u6362\u673a\u5236\u5b9e\u73b0\u4e86\u5bf9\u91cf\u5b50\u7a0b\u5e8f\u5728\u4e0d\u540c\u57fa\u7840\u4e0b\u66f4\u7cbe\u786e\u7684\u63a8\u7406\u4e0e\u7c7b\u578b\u5b89\u5168\uff0c\u5c55\u793a\u4e86Deutsch\u7b97\u6cd5\u4e0e\u91cf\u5b50\u9690\u5f62\u4f20\u6001\u7684\u5e94\u7528\u6548\u679c\uff0c\u5960\u5b9a\u4e86\u53ef\u7c7b\u578b\u5316\u91cf\u5b50\u7f16\u7a0b\u8bed\u8a00\u7684\u65b0\u57fa\u7840\u3002", "motivation": "\u4ee5\u5f80\u7684\u91cf\u5b50lambda\u6f14\u7b97\u5bf9\u57fa\u7840\u7684\u654f\u611f\u5ea6\u6709\u9650\uff0c\u96be\u4ee5\u5904\u7406\u4efb\u610f\uff08\u751a\u81f3\u662f\u7ea0\u7f20\uff09\u57fa\u7840\u4e0b\u7684\u7a0b\u5e8f\u63a8\u7406\u3002\u9700\u8981\u66f4\u7ec6\u81f4\u5730\u523b\u753b\u548c\u5b89\u5168\u7ba1\u7406\u7a0b\u5e8f\u5728\u4e0d\u540c\u57fa\u7840\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u5728lambda\u6f14\u7b97\u4e2d\u5f15\u5165\u57fa\u7840\u6ce8\u91ca\u548c\u57fa\u7840\u4f9d\u8d56\u7684\u66ff\u6362\u89c4\u5219\uff0c\u63a8\u5bfc\u548c\u9a8c\u8bc1\u4e86\u4e00\u5957\u65b0\u7684\u7c7b\u578b\u89c4\u5219\uff0c\u5e76\u901a\u8fc7\u5b9e\u4f8b\uff08\u5982Deutsch\u7b97\u6cd5\u4e0e\u91cf\u5b50\u9690\u5f62\u4f20\u6001\uff09\u8fdb\u884c\u5c55\u793a\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u7840\u654f\u611f\u7684lambda\u6f14\u7b97\uff0c\u5efa\u7acb\u4e86\u5b9e\u73b0\u8bed\u4e49\u4e0e\u7c7b\u578b\u7cfb\u7edf\u4e4b\u95f4\u7684\u65b0\u8054\u7cfb\uff0c\u786e\u4fdd\u4e86\u7c7b\u578b\u5b89\u5168\uff0c\u5e76\u901a\u8fc7\u7ecf\u5178\u4e0e\u91cf\u5b50\u7a0b\u5e8f\u7684\u793a\u4f8b\u5c55\u73b0\u4e86\u7cfb\u7edf\u8868\u8fbe\u80fd\u529b\u548c\u4fbf\u5229\u6027\u3002", "conclusion": "\u8be5\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u91cf\u5b50\u63a7\u5236lambda\u6f14\u7b97\uff08\u03bb_B\uff09\uff0c\u5b9e\u73b0\u4e86\u66f4\u7ec6\u7c92\u5ea6\u7684\u57fa\u7840\uff08basis\uff09\u654f\u611f\u7f16\u7a0b\u548c\u63a8\u7406\u3002\u8be5\u65b9\u6cd5\u540c\u65f6\u4fdd\u8bc1\u4e86\u7c7b\u578b\u5b89\u5168\u548c\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2510.17909", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.17909", "abs": "https://arxiv.org/abs/2510.17909", "authors": ["Tsogt-Ochir Enkhbayar"], "title": "Atomic Literary Styling: Mechanistic Manipulation of Prose Generation in Neural Language Models", "comment": "12 pages, 3 figures, 4 tables", "summary": "We present a mechanistic analysis of literary style in GPT-2, identifying\nindividual neurons that discriminate between exemplary prose and rigid\nAI-generated text. Using Herman Melville's Bartleby, the Scrivener as a corpus,\nwe extract activation patterns from 355 million parameters across 32,768\nneurons in late layers. We find 27,122 statistically significant discriminative\nneurons ($p < 0.05$), with effect sizes up to $|d| = 1.4$. Through systematic\nablation studies, we discover a paradoxical result: while these neurons\ncorrelate with literary text during analysis, removing them often improves\nrather than degrades generated prose quality. Specifically, ablating 50\nhigh-discriminating neurons yields a 25.7% improvement in literary style\nmetrics. This demonstrates a critical gap between observational correlation and\ncausal necessity in neural networks. Our findings challenge the assumption that\nneurons which activate on desirable inputs will produce those outputs during\ngeneration, with implications for mechanistic interpretability research and AI\nalignment.", "AI": {"tldr": "\u89c2\u5bdf\u5230\u53ef\u533a\u5206\u6587\u5b66\u6587\u672c\u7684GPT-2\u795e\u7ecf\u5143\uff0c\u88ab\u6d88\u878d\u540e\u53cd\u800c\u63d0\u5347\u4e86AI\u5199\u4f5c\u7684\u6587\u5b66\u6027\uff0c\u8868\u660e\u89e3\u91ca\u795e\u7ecf\u5143\u529f\u80fd\u65f6\u89c2\u6d4b\u76f8\u5173\u6027\u672a\u5fc5\u4ee3\u8868\u751f\u6210\u73af\u8282\u7684\u5b9e\u9645\u6548\u7528\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u666e\u904d\u5047\u8bbe\u6fc0\u6d3b\u4e8e\u4f18\u8d28\u8f93\u5165\u7684\u795e\u7ecf\u5143\u5728\u751f\u6210\u65f6\u80fd\u4fc3\u8fdb\u540c\u6837\u4f18\u8d28\u7684\u8f93\u51fa\uff0c\u672c\u7814\u7a76\u65e8\u5728\u68c0\u9a8c\u8fd9\u4e00\u5047\u8bbe\u7684\u6709\u6548\u6027\uff0c\u5e76\u63a2\u7a76\u795e\u7ecf\u7f51\u7edc\u89e3\u91ca\u6027\u5206\u6790\u7684\u5c40\u9650\u6027\u3002", "method": "\u4f5c\u8005\u5728GPT-2\u4e0a\u9009\u53d6\u6587\u5b66\u4f5c\u54c1\u300a\u5df4\u6258\u6bd4\u6587\u4e66\u5458\u300b\u4f5c\u4e3a\u8bed\u6599\uff0c\u5206\u6790\u4e86\u6a21\u578b\u540e\u5c4232,768\u4e2a\u795e\u7ecf\u5143\uff0c\u63d0\u53d6\u6fc0\u6d3b\u6a21\u5f0f\uff0c\u5e76\u8fdb\u884c\u7cfb\u7edf\u7684\u6d88\u878d\u5b9e\u9a8c\uff0c\u5206\u6790\u795e\u7ecf\u5143\u4e0e\u6587\u5b66\u98ce\u683c\u751f\u6210\u7684\u56e0\u679c\u5173\u7cfb\u3002", "result": "\u7edf\u8ba1\u4e0a\u670927,122\u4e2a\u795e\u7ecf\u5143\u5bf9\u533a\u5206\u6587\u5b66\u4e0eAI\u6587\u672c\u6709\u663e\u8457\u6027\uff0c\u4f46\u6d88\u878d\u9ad8\u5224\u522b\u529b\u795e\u7ecf\u5143\u540e\uff0c\u751f\u6210\u6587\u672c\u5728\u6587\u5b66\u6027\u6307\u6807\u4e0a\u53cd\u800c\u63d0\u5347\u4e8625.7%\u3002\u8fd9\u4e00\u7ed3\u679c\u6311\u6218\u4e86\u795e\u7ecf\u5143\u6fc0\u6d3b\u4e0e\u53ef\u7528\u6027\u4e4b\u95f4\u7b80\u5355\u7684\u56e0\u679c\u5173\u8054\u3002", "conclusion": "\u8bba\u6587\u53d1\u73b0\u867d\u7136\u6709\u4e9b\u795e\u7ecf\u5143\u5728\u8fa8\u522b\u4f18\u8d28\u6587\u5b66\u6587\u672c\u4e0eAI\u751f\u6210\u6587\u672c\u65f6\u975e\u5e38\u663e\u8457\uff0c\u4f46\u79fb\u9664\u8fd9\u4e9b\u795e\u7ecf\u5143\u53cd\u800c\u63d0\u9ad8\u4e86AI\u751f\u6210\u6587\u672c\u7684\u6587\u5b66\u98ce\u683c\u8d28\u91cf\uff0c\u63ed\u793a\u4e86\u89c2\u6d4b\u76f8\u5173\u4e0e\u56e0\u679c\u5fc5\u8981\u6027\u4e4b\u95f4\u7684\u5173\u952e\u5dee\u8ddd\u3002"}}
{"id": "2510.17932", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17932", "abs": "https://arxiv.org/abs/2510.17932", "authors": ["Jiahao Tang", "Henry Hengyuan Zhao", "Lijian Wu", "Yifei Tao", "Dongxing Mao", "Yang Wan", "Jingru Tan", "Min Zeng", "Min Li", "Alex Jinpeng Wang"], "title": "From Charts to Code: A Hierarchical Benchmark for Multimodal Models", "comment": null, "summary": "We introduce Chart2Code, a new benchmark for evaluating the chart\nunderstanding and code generation capabilities of large multimodal models\n(LMMs). Chart2Code is explicitly designed from a user-driven perspective,\ncapturing diverse real-world scenarios and progressively increasing task\ndifficulty. It consists of three levels: Level 1 (Chart Reproduction)\nreproduces charts from a reference figure and user query; Level 2 (Chart\nEditing) involves complex modifications such as changing chart types or adding\nelements; and Level 3 (Long-Table to Chart Generation) requires models to\ntransform long, information-dense tables into faithful charts following user\ninstructions. To our knowledge, this is the first hierarchical benchmark that\nreflects practical chart2code usage while systematically scaling task\ncomplexity. In total, Chart2Code contains 2,023 tasks across 22 chart types,\npaired with multi-level evaluation metrics that assess both code correctness\nand the visual fidelity of rendered charts. We benchmark 25 state-of-the-art\n(SoTA) LMMs, including both proprietary and the latest open-source models such\nas GPT-5, Qwen2.5-VL, InternVL3/3.5, MiMo-VL, and Seed-1.6-VL. Experimental\nresults demonstrate that even the SoTA model GPT-5 averages only 0.57 on\ncode-based evaluation and 0.22 on chart-quality assessment across the editing\ntasks, underscoring the difficulty of Chart2Code. We anticipate this benchmark\nwill drive advances in multimodal reasoning and foster the development of more\nrobust and general-purpose LMMs. Our code and data are available on Chart2Code.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86Chart2Code\uff0c\u5927\u89c4\u6a21\u4e14\u5206\u4e09\u7ea7\u7684\u56fe\u8868\u7406\u89e3\u5230\u4ee3\u7801\u751f\u6210\u57fa\u51c6\uff0c\u6db5\u76d62,023\u4efb\u52a1\uff0c22\u7c7b\u56fe\u8868\uff0c\u5bf925\u4e2a\u4e3b\u6d41\u5927\u6a21\u578b\u6d4b\u8bd5\u540e\u53d1\u73b0\u4efb\u52a1\u96be\u5ea6\u6781\u9ad8\uff0c\u5373\u4f7f\u6700\u5f3a\u6a21\u578b\u8868\u73b0\u4e5f\u6709\u9650\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u66f4\u5f3a\u5927\u591a\u6a21\u6001\u6a21\u578b\u7684\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u5927\u6a21\u578b\u5728\u56fe\u8868\u7406\u89e3\u53ca\u4ee3\u7801\u751f\u6210\u65b9\u9762\u80fd\u529b\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u7f3a\u4e4f\u4e13\u4e3a\u56fe\u8868\u5230\u4ee3\u7801\uff08chart2code\uff09\u4efb\u52a1\u800c\u8bbe\u8ba1\u3001\u53cd\u6620\u771f\u5b9e\u7528\u6237\u9700\u6c42\u4e14\u8986\u76d6\u4efb\u52a1\u96be\u5ea6\u68af\u5ea6\u7684\u8bc4\u6d4b\u57fa\u51c6\u3002\u56e0\u6b64\uff0c\u63d0\u51fa\u4e00\u4e2a\u80fd\u771f\u5b9e\u6a21\u62df\u7528\u6237\u573a\u666f\u5e76\u5206\u7ea7\u8003\u5bdf\u5927\u6a21\u578b\u80fd\u529b\u7684\u65b0\u57fa\u51c6\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u4f5c\u8005\u63d0\u51faChart2Code\uff0c\u4e00\u4e2a\u5206\u4e09\u7ea7\u7684\u8bc4\u6d4b\u57fa\u51c6\uff1a\u4e00\u7ea7\u4e3a\u56fe\u8868\u590d\u73b0\u4efb\u52a1\uff0c\u9700\u8981\u6839\u636e\u53c2\u8003\u56fe\u548c\u67e5\u8be2\u590d\u539f\u56fe\u8868\uff1b\u4e8c\u7ea7\u4e3a\u56fe\u8868\u7f16\u8f91\u4efb\u52a1\uff0c\u5305\u62ec\u66f4\u6362\u56fe\u8868\u7c7b\u578b\u6216\u6dfb\u52a0\u5143\u7d20\u7b49\u590d\u6742\u64cd\u4f5c\uff1b\u4e09\u7ea7\u4e3a\u4ece\u4fe1\u606f\u5bc6\u96c6\u578b\u957f\u8868\u683c\u751f\u6210\u56fe\u8868\u4efb\u52a1\uff0c\u8981\u6c42\u66f4\u6df1\u5c42\u6b21\u7684\u4fe1\u606f\u7406\u89e3\u4e0e\u8f6c\u6362\u3002\u57fa\u51c6\u5305\u542b2,023\u4e2a\u4efb\u52a1\u300122\u79cd\u56fe\u8868\u7c7b\u578b\u53ca\u591a\u5c42\u6b21\u7684\u8bc4\u6d4b\u6307\u6807\uff0c\u5e76\u5bf925\u4e2a\u4e3b\u6d41\u5927\u6a21\u578b\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684GPT-5\u6a21\u578b\u5728\u56fe\u8868\u7f16\u8f91\u4efb\u52a1\u7684\u4ee3\u7801\u8bc4\u6d4b\u4e0a\u53ea\u83b7\u5f97\u5e73\u57470.57\u5206\uff0c\u5728\u56fe\u8868\u8d28\u91cf\u8bc4\u6d4b\u4e0a\u4ec5\u4e3a0.22\uff0c\u53cd\u6620\u51fa\u4efb\u52a1\u7684\u9ad8\u96be\u5ea6\u548c\u5f53\u524d\u6a21\u578b\u7684\u5c40\u9650\u3002", "conclusion": "Chart2Code\u63d0\u4f9b\u4e86\u9996\u4e2a\u9762\u5411\u5b9e\u9645chart2code\u5e94\u7528\u4e14\u7cfb\u7edf\u53cd\u6620\u4efb\u52a1\u590d\u6742\u5ea6\u7684\u5206\u7ea7\u57fa\u51c6\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u591a\u6a21\u6001\u63a8\u7406\u9886\u57df\u7814\u7a76\u548c\u66f4\u5f3a\u901a\u7528\u80fd\u529b\u5927\u6a21\u578b\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.17918", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17918", "abs": "https://arxiv.org/abs/2510.17918", "authors": ["Junlan Feng", "Fanyu Meng", "Chong Long", "Pengyu Cong", "Duqing Wang", "Yan Zheng", "Yuyao Zhang", "Xuanchang Gao", "Ye Yuan", "Yunfei Ma", "Zhijie Ren", "Fan Yang", "Na Wu", "Di Jin", "Chao Deng"], "title": "JT-Safe: Intrinsically Enhancing the Safety and Trustworthiness of LLMs", "comment": null, "summary": "The hallucination and credibility concerns of large language models (LLMs)\nare global challenges that the industry is collectively addressing. Recently, a\nsignificant amount of advances have been made on post-training and inference\ntechniques to mitigate these challenges. However, it is widely agreed that\nunsafe and hallucinations of LLMs intrinsically originate from pre-training,\ninvolving pre-training data and the next-token prediction learning mechanism.\nIn this paper, we focus on enhancing pre-training data to improve the\ntrustworthiness and safety of LLMs. Since the data is vast, it's almost\nimpossible to entirely purge the data of factual errors, logical\ninconsistencies, or distributional biases. Moreover, the pre-training data lack\ngrounding in real-world knowledge. Each piece of data is treated as a sequence\nof tokens rather than as a representation of a part of the world. To overcome\nthese issues, we propose approaches to enhancing our pre-training data with its\ncontext in the world and increasing a substantial amount of data reflecting\nindustrial scenarios. We argue that most source data are created by the authors\nfor specific purposes in a certain spatial-temporal context. They have played a\nrole in the real world. By incorporating related world context information, we\naim to better anchor pre-training data within real-world scenarios, thereby\nreducing uncertainty in model training and enhancing the model's safety and\ntrustworthiness. We refer to our Data with World Context as DWC. We continue\npre-training an earlier checkpoint of JT-35B-Base with 1.5 trillion of DWC\ntokens. We introduce our post-training procedures to activate the potentials of\nDWC. Compared with the Qwen model of a similar scale, JT-Safe-35B achieves an\naverage performance improvement of 1.79% on the Safety and Trustworthy\nevaluation benchmarks, while being pretrained with only 6.2 trillion tokens.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5927\u6a21\u578b\u5e7b\u89c9\u4e0e\u5b89\u5168\u95ee\u9898\uff0c\u63d0\u51fa\u589e\u5f3a\u9884\u8bad\u7ec3\u6570\u636e\u4e0e\u73b0\u5b9e\u4e16\u754c\u4e0a\u4e0b\u6587\u7ed3\u5408\uff08DWC\uff09\uff0c\u6301\u7eed\u8bad\u7ec3JT-35B-Base\u5e76\u914d\u5408\u540e\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b89\u5168\u6027\u4e0e\u53ef\u4fe1\u5ea6\uff0c\u6027\u80fd\u4f18\u4e8e\u540c\u7c7b\u6a21\u578b\u3002", "motivation": "\u5f53\u524dLLM\u5b58\u5728\u5e7b\u89c9\u4e0e\u53ef\u4fe1\u6027\u95ee\u9898\uff0c\u6839\u6e90\u5728\u4e8e\u9884\u8bad\u7ec3\u6570\u636e\u53ca\u9884\u6d4b\u673a\u5236\u3002\u73b0\u6709\u65b9\u6cd5\u591a\u96c6\u4e2d\u4e8e\u540e\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\uff0c\u7f3a\u4e4f\u5bf9\u9884\u8bad\u7ec3\u6570\u636e\u672c\u8eab\u7684\u4f18\u5316\uff0c\u56e0\u6b64\u5e0c\u671b\u901a\u8fc7\u589e\u5f3a\u6570\u636e\u4e0e\u4e16\u754c\u5b9e\u9645\u573a\u666f\u7684\u7ed3\u5408\uff0c\u63d0\u5347\u6a21\u578b\u672c\u8d28\u5b89\u5168\u4e0e\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u4ee5\u4e16\u754c\u4e0a\u4e0b\u6587\u589e\u5f3a\u7684\u9884\u8bad\u7ec3\u6570\u636e\uff08DWC\uff09\uff0c\u5e76\u5c06\u5176\u7528\u4e8eJT-35B-Base\u6a21\u578b\u7684\u6301\u7eed\u9884\u8bad\u7ec3\u53ca\u914d\u5957\u540e\u8bad\u7ec3\u6d41\u7a0b\uff0c\u6700\u540e\u4e0e\u540c\u89c4\u6a21Qwen\u6a21\u578b\u5728\u5b89\u5168\u4e0e\u53ef\u4fe1\u8bc4\u6d4b\u57fa\u51c6\u4e0a\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "JT-Safe-35B\u5728\u5b89\u5168\u4e0e\u53ef\u4fe1\u8bc4\u6d4b\u57fa\u51c6\u4e0a\u6bd4\u540c\u7b49\u89c4\u6a21\u7684Qwen\u6a21\u578b\u5e73\u5747\u63d0\u5347\u4e861.79%\uff0c\u4e14\u9884\u8bad\u7ec3\u6240\u7528\u603btoken\u6570\u66f4\u5c11\uff0c\u4ec5\u4e3a6.2\u4e07\u4ebf\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u4e16\u754c\u4e0a\u4e0b\u6587\u7684\u4fe1\u606f\u589e\u5f3a\u9884\u8bad\u7ec3\u6570\u636e\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5b89\u5168\u6027\u548c\u53ef\u4fe1\u5ea6\u3002\u6240\u63d0\u51fa\u7684\u6570\u636e\u65b9\u6cd5\uff08DWC\uff09\u5728\u66f4\u5c11\u8bad\u7ec3\u6570\u636e\u7684\u524d\u63d0\u4e0b\uff0c\u4e5f\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\u3002"}}
