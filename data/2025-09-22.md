<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 4]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.CL](#cs.CL) [Total: 5]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Automatic layout of railroad diagrams](https://arxiv.org/abs/2509.15834)
*Shardul Chiplunkar,Clément Pit-Claudel*

Main category: cs.PL

TL;DR: 本文首次形式化分析并实现铁路图自动布局方法，通过编译图语言到布局语言，支持换行和对齐优化，实验证明生成质量媲美手绘和现有工具，解决了铁路图自动化和规范布局的难题。


<details>
  <summary>Details</summary>
Motivation: 铁路图在文档规范可视化方面具有直观优势，但现有工具有限且缺乏形式化布局方法，通常只能手绘，影响实际应用和自动生产。作者旨在填补该形式化和工具化空白。

Method: 将铁路图布局问题形式化为将“图语言”编译为“布局语言”，并实现了一个支持自动换行、垂直对齐和水平对齐的编译器，通过优化换行过程，并提出了相应的启发式优化方法。通过将正则表达式和Backus-Naur形式转换为铁路图，进行了前端验证；通过与手绘和其他工具的成果对比，进行了后端实用性验证。

Result: 提出了一种通用且实用的铁路图编译和布局方法，实现了满足用户布局需求的自动化铁路图生产，效果与人工绘制及现有工具相当。

Conclusion: 本文首次对铁路图布局进行了形式化研究，并提供了可操作的实现方案。提出的方法可自动化生成布局良好的铁路图，且其实用性接近手绘和现有工具。

Abstract: Railroad diagrams (also called "syntax diagrams") are a common, intuitive
visualization of grammars, but limited tooling and a lack of formal attention
to their layout mostly confines them to hand-drawn documentation. We present
the first formal treatment of railroad diagram layout along with a principled,
practical implementation. We characterize the problem as compiling a *diagram
language* (specifying conceptual components and how they connect and compose)
to a *layout language* (specifying basic graphical shapes and their sizes and
positions). We then implement a compiler that performs *line wrapping* to meet
a target width, as well as vertical *alignment* and horizontal *justification*
per user-specified policies. We frame line wrapping as an optimization problem,
where we describe principled dimensions of optimality and implement
corresponding heuristics. For front-end evaluation, we show that our diagram
language is well-suited for common applications by describing how regular
expressions and Backus-Naur form can be compiled to it. For back-end
evaluation, we argue that our compiler is practical by comparing its output to
diagrams laid out by hand and by other tools.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [Evaluating the Limitations of Local LLMs in Solving Complex Programming Challenges](https://arxiv.org/abs/2509.15283)
*Kadin Matotek,Heather Cassel,Md Amiruzzaman,Linh B. Ngo*

Main category: cs.SE

TL;DR: 作者将代码生成评估流程彻底本地化，对8种开源大模型做了大规模编程题测评，发现其表现约为商用顶尖模型的一半，但能助力组织离线自评和开源模型进步。


<details>
  <summary>Details</summary>
Motivation: 随着对本地化、开源LLM需求增长，作者希望量化这些模型在实际复杂编程问题上的表现，并为离线、本地化评测提供工具基础。

Method: 改进并扩展原有的AI代码生成评估框架（FACE），实现了完全离线运行，使用Ollama runtime，高度整合目录结构并新增强大的断点续跑功能。测试8个参数量6.7-9B的本地模型，针对3589个Kattis题目自动生成、提交和评价代码解答。

Result: 本地模型的pass@1准确率相对较低，最好模型的通过率大约只有Gemini 1.5和ChatGPT-4的50%，但开源模型进步迅速，所提出评测流程有助于各机构独立、可控地评估AI编程能力。

Conclusion: 本研究表明，尽管开源本地部署大语言模型（LLMs）在解决复杂编程任务方面的表现较为有限，目前与主流专有模型（如Gemini 1.5和ChatGPT-4）仍存在显著差距，但开源模型的性能正在快速提升，本地可复现的评测体系为组织内部评估带来实际好处。

Abstract: This study examines the performance of today's open-source, locally hosted
large-language models (LLMs) in handling complex competitive programming tasks
with extended problem descriptions and contexts. Building on the original
Framework for AI-driven Code Generation Evaluation (FACE), the authors retrofit
the pipeline to work entirely offline through the Ollama runtime, collapsing
FACE's sprawling per-problem directory tree into a handful of consolidated JSON
files, and adding robust checkpointing so multi-day runs can resume after
failures. The enhanced framework generates, submits, and records solutions for
the full Kattis corpus of 3,589 problems across eight code-oriented models
ranging from 6.7-9 billion parameters. The submission results show that the
overall pass@1 accuracy is modest for the local models, with the best models
performing at approximately half the acceptance rate of the proprietary models,
Gemini 1.5 and ChatGPT-4. These findings expose a persistent gap between
private, cost-controlled LLM deployments and state-of-the-art proprietary
services, yet also highlight the rapid progress of open models and the
practical benefits of an evaluation workflow that organizations can replicate
on in-house hardware.

</details>


### [3] [LoCaL: Countering Surface Bias in Code Evaluation Metrics](https://arxiv.org/abs/2509.15397)
*Simantika Bhattacharjee Dristi,Matthew B. Dwyer*

Main category: cs.SE

TL;DR: 本文发现现有代码评估指标过于依赖表层特征，实际在兼顾表层与功能差异的新基准LoCaL上的表现明显下降。提出LoCaL基准与差分模糊测试，有望促使新型、更具功能性的代码评估方法研究。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）及基于LLM的代理越来越流行，因此对代码评估指标（CEM）的可靠性和有效性提出了更高要求。目前评估代码正确性主要依赖测试用例，但测试用例生成和执行成本高昂。基于参考的CEM虽然作为低成本替代，但它们与功能正确性的相关性较弱且原因未被深入研究。

Method: 作者批判性地评估了四种主流的参考型CEM，发现它们偏重代码的表层特征而非实际功能。针对现有数据集不足以覆盖表层相似但功能不同、或功能类似而表面不同的代码对，提出了新的评测基准LoCaL。LoCaL基准包含3117对代码片段，涵盖方法级和程序级，并通过差分模糊测试（differential fuzzing）无须预定义测试用例、且能进行大量有效测试，为每对代码标注功能相似性分数。

Result: 四个CEM在LoCaL数据集上的表现均显著弱于基线数据。功能层面的准确性下降，暴露出评估指标严重的表层偏差。

Conclusion: 现有参考型CEM易受代码表层特征影响，不能准确评估代码功能。通过LoCaL这样针对表层与功能差异设计的数据集，可以推动开发更具鲁棒性的新评估指标。

Abstract: With the increasing popularity of large language models (LLMs) and LLM-based
agents, reliable and effective code evaluation metrics (CEMs) have become
crucial for progress across several software engineering tasks. While popular
benchmarks often provide test cases to assess the correctness of generated
code, crafting and executing test cases is expensive. Reference-based CEMs
provide a cheaper alternative by scoring a candidate program based on its
functional similarity to a reference. Although prior research has focused on
reporting the weak correlation between these CEMs and functional correctness,
the causes are only assumed, and plausible solutions remain unexplored. In this
work, we critically evaluate four state-of-the-art reference-based CEMs,
revealing their strong bias towards surface-level features rather than code
functionality. Despite this surface bias, current evaluation datasets for these
CEMs rarely include code pairs that are surface-similar yet functionally
dissimilar, or functionally similar yet surface-dissimilar. To mitigate this
gap, we propose LoCaL (Looks Can Lie), a CEM evaluation benchmark, with 3117
code pairs at both the method and program levels. Each pair is labeled with a
functional similarity score and aims to target regions where CEMs are likely to
perform poorly. The functional similarity scores are calculated through
differential fuzzing, which eliminates the need for predefined test cases and,
at the same time, improves the reliability of the scores by executing an order
of magnitude more tests than prior work. We find that all four CEMs show
significant performance degradation on LoCaL, compared to the baselines.
Finally, based on our findings, we draw the implication that exposing CEMs to
LoCaL-like data might facilitate the development of metrics that are robust to
surface bias.

</details>


### [4] [Brevity is the Soul of Wit: Condensing Code Changes to Improve Commit Message Generation](https://arxiv.org/abs/2509.15567)
*Hongyu Kuang,Ning Zhang,Hui Gao,Xin Zhou,Wesley K. G. Assunção,Xiaoxing Ma,Dong Shao,Guoping Rong,He Zhang*

Main category: cs.SE

TL;DR: 通过引入定制化代码变更模板和预训练模型微调，论文提出了更有效的commit message自动生成方法，并在多项指标上超过现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动生成高质量的commit message对提高软件维护效率至关重要，但现有方法在code change表征上有改进空间。

Method: 提出基于“三部分文本模板”（代码变更摘要、提取注释、突出代码标识符）的方法，用ChangeScribe工具提取模板，并微调CodeLlama-7B进行commit message生成。

Result: 实验结果显示，该方法在BLEU-Norm、METEOR和ROUGE-L指标上分别比六个基线方法平均提升51.7%，78.7%，62.5%。消融实验及人工评估进一步证实该方案有效。

Conclusion: 结构化简明代码变更模板结合大预训练语言模型能显著提升自动commit message生成质量。

Abstract: Commit messages are valuable resources for describing why code changes are
committed to repositories in version control systems (e.g., Git). They
effectively help developers understand code changes and better perform software
maintenance tasks. Unfortunately, developers often neglect to write
high-quality commit messages in practice. Therefore, a growing body of work is
proposed to generate commit messages automatically. These works all
demonstrated that how to organize and represent code changes is vital in
generating good commit messages, including the use of fine-grained graphs or
embeddings to better represent code changes. In this study, we choose an
alternative way to condense code changes before generation, i.e., proposing
brief yet concise text templates consisting of the following three parts: (1)
summarized code changes, (2) elicited comments, and (3) emphasized code
identifiers. Specifically, we first condense code changes by using our proposed
templates with the help of a heuristic-based tool named ChangeScribe, and then
fine-tune CodeLlama-7B on the pairs of our proposed templates and corresponding
commit messages. Our proposed templates better utilize pre-trained language
models, while being naturally brief and readable to complement generated commit
messages for developers. Our evaluation based on a widely used dataset showed
that our approach can outperform six baselines in terms of BLEU-Norm, METEOR,
and ROUGE-L, with average improvements of 51.7%, 78.7%, and 62.5%,
respectively. The ablation study and human evaluation also provide further
insights into the effectiveness of our approach.

</details>


### [5] [How Far Are We? An Empirical Analysis of Current Vulnerability Localization Approaches](https://arxiv.org/abs/2509.15777)
*Haoran Xu,Zhi Chen,Junxiao Han,Xinkui Zhao,Jianwei Yin,Shuiguang Deng*

Main category: cs.SE

TL;DR: 本文针对开源软件补丁检测，提出结合版本筛选和大语言模型对话的新框架，在真实数据集上效果领先现有方法，具有推广价值。


<details>
  <summary>Details</summary>
Motivation: 当前开源软件漏洞补丁检测存在规模化困难与人为错误，传统自动化和预训练模型方法也存在准确率低和泛化能力差等问题。论文旨在解决这些根本挑战，提升软件安全与供应链完整性。

Method: 提出了一种两阶段框架，包括基于版本的候选过滤与基于大语言模型的多轮对话投票，以提升漏洞补丁检测的准确性和效率。方法设计受到四个实证发现的指导：检索空间的有效缩小、语义理解的优越性、网页爬取时效性限制和知识驱动方法的优势。

Result: 在包含750个真实漏洞的数据集上进行大量实验，结果表明该方法在准确率和效率上均优于现有的主流检测方法。

Conclusion: 论文提出的两阶段大模型方法在自动检测开源软件漏洞补丁方面取得了显著的效果，有效解决了现有方法在准确率和泛化能力方面的不足。

Abstract: Open-source software vulnerability patch detection is a critical component
for maintaining software security and ensuring software supply chain integrity.
Traditional manual detection methods face significant scalability challenges
when processing large volumes of commit histories, while being prone to human
errors and omissions. Existing automated approaches, including heuristic-based
methods and pre-trained model solutions, suffer from limited accuracy, poor
generalization capabilities, and inherent methodological constraints that
hinder their practical deployment. To address these fundamental challenges,
this paper conducts a comprehensive empirical study of existing vulnerability
patch detection methods, revealing four key insights that guide the design of
effective solutions: the critical impact of search space reduction, the
superiority of pre-trained semantic understanding over architectural
complexity, the temporal limitations of web crawling approaches, and the
advantages of knowledge-driven methods. Based on these insights, we propose a
novel two-stage framework that combines version-driven candidate filtering with
large language model-based multi-round dialogue voting to achieve accurate and
efficient vulnerability patch identification. Extensive experiments on a
dataset containing 750 real vulnerabilities demonstrate that our method
outperforms current approaches.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [6] [Two Optimizations on the Stålmarck Procedure](https://arxiv.org/abs/2509.16172)
*Sergei Leonov,Liam Davis*

Main category: cs.LO

TL;DR: 提出了基于Stå lmarck过程的现代SAT求解器StalmarckSAT，并用两个新策略（CDB和DPO）提升了解题效率，实验效果明显。


<details>
  <summary>Details</summary>
Motivation: 现有Stå lmarck过程在SAT问题上的分支和推理效率有限，亟需改进以提升求解能力。

Method: 本文重新实现了Stå lmarck求解过程，并引入了两种新策略：CDB（基于基数的分支）和DPO（基于推理优先级排序）。

Result: 采用CDB和DPO策略后，SAT求解的平均求解时间得到了改善。

Conclusion: StalmarckSAT结合了CDB和DPO两种策略，实验表明能够显著提升求解效率。

Abstract: In this paper, we introduce StalmarckSAT, the a modern re-implementation of
the St\aa lmarck Procedure for SAT solving, and present two novel strategies to
improve the Procedure, Cardinality Driven Branching (CDB) and Deductive
Priority Ordering (DPO). CDB is a heuristic to improve branching with the
dilemma rule, and DPO intelligently orders simple rules based on their
deductive potential. Our results demonstrate improved solve times with both
strategies.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [7] [Synthetic bootstrapped pretraining](https://arxiv.org/abs/2509.15248)
*Zitong Yang,Aonan Zhang,Hong Liu,Tatsunori Hashimoto,Emmanuel Candès,Chong Wang,Ruoming Pang*

Main category: cs.CL

TL;DR: 通过合成基于文档关系的新数据，SBP预训练方法显著提升了语言模型性能，对丰富和高效利用预训练数据具有重要价值。


<details>
  <summary>Details</summary>
Motivation: 传统的语言模型预训练主要学习单个文档内部的因果关系，然而这种方法无法高效建模文档间的丰富相关性，限制了预训练模型的能力提升。为了解决这一问题，需要一种能够利用文档间联系的新型预训练方式。

Method: 提出了一种合成自举预训练（SBP）方法：首先通过原始预训练数据集学习文档间的关系模型，然后利用该模型合成出大规模的新语料库，最后基于原始和合成数据联合预训练语言模型。实验以3B参数模型为例，并进行了算力对齐的训练设置。

Result: 实验结果显示，SBP方法在一组强基线模型上表现出持续提升，并接近于理想情况下使用20倍独特数据时的性能上限。同时，定性分析发现合成新文档不仅仅是简单的复述，而是能抽象核心概念并在此基础上生成新叙述。

Conclusion: SBP有效地利用文档间的知识抽象，推动了预训练模型的性能，具有自然的贝叶斯解释基础，即模型能自动发现并抽象出文档之间的潜在概念。

Abstract: We introduce Synthetic Bootstrapped Pretraining (SBP), a language model (LM)
pretraining procedure that first learns a model of relations between documents
from the pretraining dataset and then leverages it to synthesize a vast new
corpus for joint training. While the standard pretraining teaches LMs to learn
causal correlations among tokens within a single document, it is not designed
to efficiently model the rich, learnable inter-document correlations that can
potentially lead to better performance. We validate SBP by designing a
compute-matched pretraining setup and pretrain a 3B-parameter model on up to 1T
tokens from scratch. We find SBP consistently improves upon a strong repetition
baseline and delivers a significant fraction of performance improvement
attainable by an oracle upper bound with access to 20x more unique data.
Qualitative analysis reveals that the synthesized documents go beyond mere
paraphrases -- SBP first abstracts a core concept from the seed material and
then crafts a new narration on top of it. Besides strong empirical performance,
SBP admits a natural Bayesian interpretation: the synthesizer implicitly learns
to abstract the latent concepts shared between related documents.

</details>


### [8] [Comparative Analysis of Tokenization Algorithms for Low-Resource Language Dzongkha](https://arxiv.org/abs/2509.15255)
*Tandin Wangchuk,Tad Gonsalves*

Main category: cs.CL

TL;DR: 本文比较了三种分词算法用于不丹宗卡语，发现SentencePiece最有效，为低资源语言NLP提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 高资源语言的预训练分词器表现优良，但对低资源语言如宗卡语支持不足。宗卡语语言学特性复杂，分词领域研究欠缺，亟需有效算法以支持后续NLP任务及大型语言模型建设。

Method: 评估和比较了三种常见分词算法在宗卡语上的训练与表现，分别为BPE、WordPiece和SentencePiece（Unigram）；利用子词繁殖率（Subword Fertility）、连续词占比、归一化序列长度及执行时间等指标进行定量分析。

Result: 三种算法均有一定效果，但SentencePiece（Unigram）在各项指标中表现最佳，被认为最适合宗卡语。实验奠定了宗卡语语言模型与NLP应用的基础。

Conclusion: 三种主流分词算法（BPE、WordPiece、SentencePiece）均具有对宗卡语分词的潜力，但SentencePiece（Unigram）表现最优，适合宗卡语分词，推动相关NLP的发展。呼吁对低资源语言采用定制化方法并持续研究。

Abstract: Large Language Models (LLMs) are gaining popularity and improving rapidly.
Tokenizers are crucial components of natural language processing, especially
for LLMs. Tokenizers break down input text into tokens that models can easily
process while ensuring the text is accurately represented, capturing its
meaning and structure. Effective tokenizers enhance the capabilities of LLMs by
improving a model's understanding of context and semantics, ultimately leading
to better performance in various downstream tasks, such as translation,
classification, sentiment analysis, and text generation. Most pre-trained
tokenizers are suitable for high-resource languages like English but perform
poorly for low-resource languages. Dzongkha, Bhutan's national language spoken
by around seven hundred thousand people, is a low-resource language, and its
linguistic complexity poses unique NLP challenges. Despite some progress,
significant research in Dzongkha NLP is lacking, particularly in tokenization.
This study evaluates the training and performance of three common tokenization
algorithms in comparison to other popular methods. Specifically, Byte-Pair
Encoding (BPE), WordPiece, and SentencePiece (Unigram) were evaluated for their
suitability for Dzongkha. Performance was assessed using metrics like Subword
Fertility, Proportion of Continued Words, Normalized Sequence Length, and
execution time. The results show that while all three algorithms demonstrate
potential, SentencePiece is the most effective for Dzongkha tokenization,
paving the way for further NLP advancements. This underscores the need for
tailored approaches for low-resource languages and ongoing research. In this
study, we presented three tokenization algorithms for Dzongkha, paving the way
for building Dzongkha Large Language Models.

</details>


### [9] [Toxicity Red-Teaming: Benchmarking LLM Safety in Singapore's Low-Resource Languages](https://arxiv.org/abs/2509.15260)
*Yujia Hu,Ming Shan Hee,Preslav Nakov,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: 本文提出并公开了首个新加坡多语种的LLM安全测试框架和数据集SGToxicGuard，揭示了多语言环境下现有LLM安全机制的不足，为未来更安全、包容的AI系统建设提供了方向。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在自然语言处理方面取得了巨大进展，但在资源匮乏、多语种环境下的安全性机制研究不足，尤其是在新加坡这种多语言环境中。

Method: 本文提出了SGToxicGuard，这是一个新的数据集和评估框架，用于在新加坡多元语言环境（包括Singlish、中文、马来语和泰米尔语）下对LLM安全性进行基准测试。采用red-teaming方法，系统性地在对话、问答、内容创作三种真实场景中测试LLM的安全漏洞。

Result: 通过对当前先进的多语种LLM进行大量实验，发现这些模型在安全防护机制上存在重要缺口。

Conclusion: SGToxicGuard为探究多语言、多文化环境下的AI安全和包容性提供了基础，推进了文化敏感性和有害内容防护的研究。

Abstract: The advancement of Large Language Models (LLMs) has transformed natural
language processing; however, their safety mechanisms remain under-explored in
low-resource, multilingual settings. Here, we aim to bridge this gap. In
particular, we introduce \textsf{SGToxicGuard}, a novel dataset and evaluation
framework for benchmarking LLM safety in Singapore's diverse linguistic
context, including Singlish, Chinese, Malay, and Tamil. SGToxicGuard adopts a
red-teaming approach to systematically probe LLM vulnerabilities in three
real-world scenarios: \textit{conversation}, \textit{question-answering}, and
\textit{content composition}. We conduct extensive experiments with
state-of-the-art multilingual LLMs, and the results uncover critical gaps in
their safety guardrails. By offering actionable insights into cultural
sensitivity and toxicity mitigation, we lay the foundation for safer and more
inclusive AI systems in linguistically diverse environments.\footnote{Link to
the dataset: https://github.com/Social-AI-Studio/SGToxicGuard.}
\textcolor{red}{Disclaimer: This paper contains sensitive content that may be
disturbing to some readers.}

</details>


### [10] [PolBiX: Detecting LLMs' Political Bias in Fact-Checking through X-phemisms](https://arxiv.org/abs/2509.15335)
*Charlott Jakob,David Harbecke,Patrick Parschan,Pia Wenzel Neves,Vera Schmitt*

Main category: cs.CL

TL;DR: 大模型核查事实时用词好坏（如委婉或贬损）影响比政治取向更大，强调客观性也无法完全消除这一偏见。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）逐渐应用于需要客观评估的任务，但其潜在的政治偏见可能影响这些应用的公正性。目前，多项研究发现LLMs偏向左翼立场，但这些偏见对诸如事实核查等下游任务的影响尚未被充分探索。

Method: 本研究通过在德语声明中使用委婉语和贬损语替换关键词，构造政治内涵不同但事实等价的声明对，并让多种LLM对这些声明的真实性进行分类。研究共评估了六种LLM，并测试它们在政治立场及措辞倾向性下的判断一致性。

Result: 研究发现，相较于政治倾向，带有评价色彩的用词（如委婉语或贬损语）对模型的真实性判断影响更大。虽然部分模型展现出一定的政治偏见，但在提示时明确要求客观性，并未消除这种偏见。

Conclusion: LLMs在事实核查等任务中受措辞评价色彩影响较大，政治偏见虽存在但较弱，且强调客观性难以完全消除模型的判断偏见。

Abstract: Large Language Models are increasingly used in applications requiring
objective assessment, which could be compromised by political bias. Many
studies found preferences for left-leaning positions in LLMs, but downstream
effects on tasks like fact-checking remain underexplored. In this study, we
systematically investigate political bias through exchanging words with
euphemisms or dysphemisms in German claims. We construct minimal pairs of
factually equivalent claims that differ in political connotation, to assess the
consistency of LLMs in classifying them as true or false. We evaluate six LLMs
and find that, more than political leaning, the presence of judgmental words
significantly influences truthfulness assessment. While a few models show
tendencies of political bias, this is not mitigated by explicitly calling for
objectivism in prompts.

</details>


### [11] [Quantifying Self-Awareness of Knowledge in Large Language Models](https://arxiv.org/abs/2509.15339)
*Yeongbin Seo,Dongha Lee,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 大模型幻觉预测常借助问题线索，本文用AQE量化这一影响，并提出SCAO方法减少线索依赖，增强模型自我认知能力。


<details>
  <summary>Details</summary>
Motivation: 当前大模型幻觉预测能力常被视为自我认知的体现，但其实主要受到问题端线索影响，缺乏对模型真正内省能力的评估。

Method: 提出了AQE（Approximate Question-side Effect）来量化问题端对幻觉预测的影响，并引入SCAO（Semantic Compression by Answering in One word）方法进行实证分析。

Result: 实验证明许多成功案例源自模型利用问题表面特征，采用SCAO后大幅提升了模型内在信号的利用，显示更真实的自我认知。

Conclusion: SCAO方法在减少问题端提示的情况下表现出色，能更有效激发大模型的自我认知能力。

Abstract: Hallucination prediction in large language models (LLMs) is often interpreted
as a sign of self-awareness. However, we argue that such performance can arise
from question-side shortcuts rather than true model-side introspection. To
disentangle these factors, we propose the Approximate Question-side Effect
(AQE), which quantifies the contribution of question-awareness. Our analysis
across multiple datasets reveals that much of the reported success stems from
exploiting superficial patterns in questions. We further introduce SCAO
(Semantic Compression by Answering in One word), a method that enhances the use
of model-side signals. Experiments show that SCAO achieves strong and
consistent performance, particularly in settings with reduced question-side
cues, highlighting its effectiveness in fostering genuine self-awareness in
LLMs.

</details>
