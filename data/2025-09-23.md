<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.SE](#cs.SE) [Total: 20]
- [cs.LO](#cs.LO) [Total: 6]
- [cs.CL](#cs.CL) [Total: 19]
- [cs.DM](#cs.DM) [Total: 2]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [VerilogMonkey: Exploring Parallel Scaling for Automated Verilog Code Generation with LLMs](https://arxiv.org/abs/2509.16246)
*Juxin Niu,Yuxin Du,Dan Niu,Xi Wang,Zhe Jiang,Nan Guan*

Main category: cs.PL

TL;DR: VerilogMonkey表明并行采样可大幅提升LLM生成Verilog代码的表现，无须微调或复杂处理，省时省钱且优于以前的方法，其效果与LLM输出的随机性有关。


<details>
  <summary>Details</summary>
Motivation: 自动生成Verilog代码是一个较少研究的领域，且性能提升方法有限。该研究希望探索通过并行采样提升大语言模型（LLM）生成Verilog的效果与效率。

Method: 采用并行扩展（parallel scaling）方式，即在多个主流LLM同时并行采样大量输出，不使用额外的微调或智能体方法。对多种基准和LLM进行实证测试。

Result: 实验发现，在无任何额外后处理或增强情况下，并行扩展能以较低时间和金钱成本提升性能，效果优于此前LLM生成Verilog的结果。还分析了并行采样带来的性能提升原因，揭示了LLM输出的随机性对效率的影响。

Conclusion: 并行扩展是提升LLM自动生成Verilog代码有效且经济的方法，且其提升机制与输出随机性密切相关。该方法无需后训练或更复杂方法即可带来显著性能提升。

Abstract: We present VerilogMonkey, an empirical study of parallel scaling for the
under-explored task of automated Verilog generation. Parallel scaling improves
LLM performance by sampling many outputs in parallel. Across multiple
benchmarks and mainstream LLMs, we find that scaling to hundreds of samples is
cost-effective in both time and money and, even without any additional
enhancements such as post-training or agentic methods, surpasses prior results
on LLM-based Verilog generation. We further dissect why parallel scaling
delivers these gains and show how output randomness in LLMs affects its
effectiveness.

</details>


### [2] [GraphMend: Code Transformations for Fixing Graph Breaks in PyTorch 2](https://arxiv.org/abs/2509.16248)
*Savini Kashmira,Jayanaka Dantanarayana,Thamirawaran Sathiyalogeswaran,Yichao Yuan,Nishil Talati,Krisztian Flautner,Lingjia Tang,Jason Mars*

Main category: cs.PL

TL;DR: GraphMend是一款面向PyTorch 2的高层编译器，自动修复因动态控制流和Python I/O导致的FX graph切断，显著减少模型回退、降低延迟、提高吞吐，无需开发者手动重构代码。


<details>
  <summary>Details</summary>
Motivation: PyTorch 2通过TorchDynamo和TorchInductor引入了即时编译，但依然因为动态控制流和不支持的Python特性导致模型划分为多个FX graph，频繁回退到eager模式，影响性能和优化空间。

Method: GraphMend基于Jac框架，在程序执行前分析和转换源码，引入两种代码转换，专门解决因动态控制流和Python I/O函数导致的FX graph breaks，无需开发者手动重构代码。

Result: 在八个Hugging Face模型上的评测显示，GraphMend能够消除所有可修复的图切断点，其中六个模型将breaks数降为0，另一个模型从5降至2。在NVIDIA RTX 3090和A40 GPU上，GraphMend实现了最多75%的延迟降低和最多8%的端到端吞吐提升。

Conclusion: 高层次代码转换能有效提升PyTorch动态图JIT编译管线的可用性和性能，是补充和完善PyTorch编译流程的重要工具。

Abstract: This paper presents GraphMend, a high-level compiler that eliminates FX graph
breaks in PyTorch 2 programs. Although PyTorch 2 introduced TorchDynamo and
TorchInductor to enable just-in-time graph compilation, unresolved dynamic
control flow and unsupported Python constructs often fragment models into
multiple FX graphs. These fragments force frequent fallbacks to eager mode,
incur costly CPU-to-GPU synchronizations, and reduce optimization
opportunities. GraphMend addresses this limitation by analyzing and
transforming source code before execution. Built on the Jac compilation
framework, GraphMend introduces two code transformations that remove graph
breaks due to dynamic control flow and Python I/O functions. This design allows
PyTorch's compilation pipeline to capture larger, uninterrupted FX graphs
without requiring manual refactoring by developers. Evaluation across eight
Hugging Face models shows that GraphMend removes all fixable graph breaks due
to dynamic control flow and Python I/O functions, driving the break count to 0
in 6 models and reducing it from 5 to 2 in another model. On NVIDIA RTX 3090
and A40 GPUs, GraphMend achieves up to 75% latency reductions and up to 8%
higher end-to-end throughput. These results demonstrate that high-level code
transformation is an effective complement to PyTorch's dynamic JIT compilation
pipeline, substantially improving both usability and performance.

</details>


### [3] [Efficient Linearizability Monitoring](https://arxiv.org/abs/2509.17795)
*Parosh Aziz Abdulla,Samuel Grahn,Bengt Jonsson,Shankaranarayanan Krishna,Om Swostik Mishra*

Main category: cs.PL

TL;DR: 本文改进了并发堆栈、队列、集合的线性化监测算法，提升至O(n^2)、O(n log n)、O(n)效率，并实现了工具LiMo，实验证明优于现有工具，纠正了过去算法和证明的错误，显著提高了并发结构正确性验证的效率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 本文关注并发数据结构（堆栈、队列、集合、多重集合）的线性化监测问题，即如何判断一个操作历史是否是线性化的。此问题对于并发算法的正确性验证非常重要。过去的相关算法效率低（立方级时间复杂度）且存在正确性证明缺陷。

Method: 本文提出了新的监测算法，复杂度分别是O(n^2)（堆栈）、O(n log n)（队列）、O(n)（集合、多重集合）。这些算法基于数据无关性假设，并提供了详尽的正确性证明。同时实现了LiMo工具以验证所提算法。

Result: 新算法在效率和正确性上均优于以往工作，显著降低了时间复杂度。实验结果显示，LiMo在检测线性化违例时，比现有Violin工具表现更好，无论效率还是可扩展性。同时，指出了Violin的证明存在错误。

Conclusion: 该工作为并发数据结构线性化监测提供了正确且高效的新算法，并以实现和实验验证其优越性，对并发系统的正确性验证具有重要价值。

Abstract: This paper revisits the fundamental problem of monitoring the linearizability
of concurrent stacks, queues, sets, and multisets. Given a history of a library
implementing one of these abstract data types, the monitoring problem is to
answer whether the given history is linearizable. For stacks, queues, and
(multi)sets, we present monitoring algorithms with complexities
$\mathcal{O}(n^2)$, $\mathcal{O}(n\; log\, n)$, and $\mathcal{O}{(n)}$,
respectively, where $n$ is the number of operations in the input history. For
stacks and queues, our results hold under the standard assumption of {\it
data-independence}, i.e., the behavior of the library is not sensitive to the
actual values stored in the data structure. Past works to solve the same
problems have cubic time complexity and (more seriously) have correctness
issues: they either (i) lack correctness proofs or (ii) the suggested
correctness proofs are erroneous (we present counter-examples), or (iii) have
incorrect algorithms. Our improved complexity results rely on substantially
different algorithms for which we provide detailed proofs of correctness. We
have implemented our stack and queue algorithms in LiMo (Linearizability
Monitor). We evaluate LiMo and compare it with the state-of-the-art tool Violin
-- whose correctness proofs we have found errors in -- which checks for
linearizability violations. Our experimental evaluation confirms that LiMo
outperforms Violin regarding both efficiency and scalability.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [Digging Into the Internal: Causality-Based Analysis of LLM Function Calling](https://arxiv.org/abs/2509.16268)
*Zhenlan Ji,Daoyuan Wu,Wenxuan Wang,Pingchuan Ma,Shuai Wang,Lei Ma*

Main category: cs.SE

TL;DR: 本论文用因果分析解析函数调用对大语言模型行为的影响，实验验证了该方法显著提升了模型检测恶意输入的能力和安全鲁棒性，优于传统提示方法，具有实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 函数调用（FC）被证实能提升大语言模型（LLM）结构化任务的能力，但其具体如何影响模型行为尚不清楚，且作者观察到FC还显著提升了LLM对用户指令的服从性。基于这些发现，作者希望更深入分析FC在LLMs中的作用机理。

Method: 作者采用因果分析的方法展开研究，尤其在模型的层级与标记级别进行因果干预，分析FC对LLM内部计算逻辑的影响。同时，设计实验比较基于FC的指令与传统提示方法在安全鲁棒性方面的效果。涉及四种主流LLM及两个数据集。

Result: 因果分析证实了FC对LLM有显著影响，并揭示了其机制。实验结果显示，FC在检测恶意输入的任务上，较传统方法平均提升了约135%的性能。

Conclusion: 函数调用不仅提升LLM的指令服从性，还极大增强了其安全性和鲁棒性。因果分析有助于深入理解其作用方式，FC有望应用于提升LLM实际可靠性。

Abstract: Function calling (FC) has emerged as a powerful technique for facilitating
large language models (LLMs) to interact with external systems and perform
structured tasks. However, the mechanisms through which it influences model
behavior remain largely under-explored. Besides, we discover that in addition
to the regular usage of FC, this technique can substantially enhance the
compliance of LLMs with user instructions. These observations motivate us to
leverage causality, a canonical analysis method, to investigate how FC works
within LLMs. In particular, we conduct layer-level and token-level causal
interventions to dissect FC's impact on the model's internal computational
logic when responding to user queries. Our analysis confirms the substantial
influence of FC and reveals several in-depth insights into its mechanisms. To
further validate our findings, we conduct extensive experiments comparing the
effectiveness of FC-based instructions against conventional prompting methods.
We focus on enhancing LLM safety robustness, a critical LLM application
scenario, and evaluate four mainstream LLMs across two benchmark datasets. The
results are striking: FC shows an average performance improvement of around
135% over conventional prompting methods in detecting malicious inputs,
demonstrating its promising potential to enhance LLM reliability and capability
in practical applications.

</details>


### [5] [Constrained Co-evolutionary Metamorphic Differential Testing for Autonomous Systems with an Interpretability Approach](https://arxiv.org/abs/2509.16478)
*Hossein Yousefizadeh,Shenghui Gu,Lionel C. Briand,Ali Nasr*

Main category: cs.SE

TL;DR: CoCoMagic通过协同进化搜索和综合测试策略，极大提升了自主系统迭代版本间的行为差异发现效率与准确性，并结合可解释性分析，助力开发者高效定位并修复潜在安全风险。


<details>
  <summary>Details</summary>
Motivation: 自主系统（如自动驾驶系统）由于频繁更新，容易引入意外行为退化，因此需要有效的系统级测试，但由于场景空间巨大、缺乏可靠的测试判据以及需要实际可用且可解释的测试用例，测试非常困难。

Method: 提出了一种新颖的自动化测试用例生成方法CoCoMagic，将变形测试、差异测试和高级搜索技术结合，采用受约束的合作协同进化搜索，同时优化测试场景和变形扰动以发现不同版本之间的行为差异。通过约束和种群初始化保证场景现实相关性，并集成了可解释性方法帮助定位行为差异根因。

Result: 在Carla虚拟模拟器下针对ADS系统InterFuser进行评估，结果显示相较于基线搜索方法，CoCoMagic能发现多达287%更多高严重性、独特的行为差异，并保持场景的现实性。可解释性方法为开发者提供有用见解，支持定向调试和安全评估。

Conclusion: CoCoMagic为演化中的自主系统提供了一种高效、有效且可解释的差异测试方法，有助于发现和诊断版本之间的行为退化，提高系统安全性和可靠性。

Abstract: Autonomous systems, such as autonomous driving systems, evolve rapidly
through frequent updates, risking unintended behavioral degradations. Effective
system-level testing is challenging due to the vast scenario space, the absence
of reliable test oracles, and the need for practically applicable and
interpretable test cases. We present CoCoMagic, a novel automated test case
generation method that combines metamorphic testing, differential testing, and
advanced search-based techniques to identify behavioral divergences between
versions of autonomous systems. CoCoMagic formulates test generation as a
constrained cooperative co-evolutionary search, evolving both source scenarios
and metamorphic perturbations to maximize differences in violations of
predefined metamorphic relations across versions. Constraints and population
initialization strategies guide the search toward realistic, relevant
scenarios. An integrated interpretability approach aids in diagnosing the root
causes of divergences. We evaluate CoCoMagic on an end-to-end ADS, InterFuser,
within the Carla virtual simulator. Results show significant improvements over
baseline search methods, identifying up to 287\% more distinct high-severity
behavioral differences while maintaining scenario realism. The interpretability
approach provides actionable insights for developers, supporting targeted
debugging and safety assessment. CoCoMagic offers an efficient, effective, and
interpretable way for the differential testing of evolving autonomous systems
across versions.

</details>


### [6] [Causal Fuzzing for Verifying Machine Unlearning](https://arxiv.org/abs/2509.16525)
*Anna Mazhar,Sainyam Galhotra*

Main category: cs.SE

TL;DR: CAF'E框架通过因果分析，实现对黑盒机器学习模型的数据点和特征遗忘的高效、细粒度验证，显著超越现有方法，能发现残留影响。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型在决策系统中的应用日益广泛，模型需要具备“遗忘”特定数据或特征的能力，以提升模型的适应性、公平性和隐私保护。特别是在训练成本高昂时，如何有效指导模型遗忘成为重要课题。现有验证方法对模型遗忘的洞察有限，尤其在影响间接时难以检测。

Method: 提出CAF'E，一种基于因果推断的新框架，将数据点级和特征级的遗忘统一起来，用于黑盒机器学习模型的验证。CAF'E通过因果依赖分析，评估遗忘目标的直接和间接影响，实现细粒度、可操作的洞察。

Result: 在五个数据集和三种模型架构上的评估表明，CAF'E能够检测到基线方法遗漏的残留影响，同时保持计算效率。

Conclusion: CAF'E作为统一的因果验证框架，提升了机器学习模型遗忘的有效性和可解释性，适用于实际高效场景，比已有方法更全面和敏锐。

Abstract: As machine learning models become increasingly embedded in decision-making
systems, the ability to "unlearn" targeted data or features is crucial for
enhancing model adaptability, fairness, and privacy in models which involves
expensive training. To effectively guide machine unlearning, a thorough testing
is essential. Existing methods for verification of machine unlearning provide
limited insights, often failing in scenarios where the influence is indirect.
In this work, we propose CAF\'E, a new causality based framework that unifies
datapoint- and feature-level unlearning for verification of black-box ML
models. CAF\'E evaluates both direct and indirect effects of unlearning targets
through causal dependencies, providing actionable insights with fine-grained
analysis. Our evaluation across five datasets and three model architectures
demonstrates that CAF\'E successfully detects residual influence missed by
baselines while maintaining computational efficiency.

</details>


### [7] [Is Measurement Enough? Rethinking Output Validation in Quantum Program Testing](https://arxiv.org/abs/2509.16595)
*Jiaming Ye,Xiongfei Wu,Shangzhou Xia,Fuyuan Zhang,Jianjun Zhao*

Main category: cs.SE

TL;DR: 本文分析了量子程序测试领域的测量型与状态向量型验证方法，发现测量型适合简单输出值检查，状态向量型适用于复杂行为评估，为选用合适的验证技术提供了参考。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算的不断发展，量子程序的质量保障变得更加重要。当前量子程序测试方法多采用基于测量的验证，但由于量子程序的概率性，此类方法存在局限性。作者希望通过实证分析，厘清这些局限和现有方法的优缺点。

Method: 作者对近期关于量子程序测试的研究进行了经验分析，梳理并分类了文献中的测量型验证方法，并将其分为分布级别验证和输出值级别验证两类。随后与状态向量验证方法进行了比较，评估各自的优劣。

Result: 测量型验证适合进行简单的输出值检查，如确认某些输出结果的存在；而状态向量验证在复杂任务（如评估程序行为）方面更有效。

Conclusion: 基于测量的验证方法适合简单测试需求，但有局限，对于复杂场景应优先考虑状态向量验证方法。

Abstract: As quantum computing continues to emerge, ensuring the quality of quantum
programs has become increasingly critical. Quantum program testing has emerged
as a prominent research area within the scope of quantum software engineering.
While numerous approaches have been proposed to address quantum program quality
assurance, our analysis reveals that most existing methods rely on
measurement-based validation in practice. However, due to the inherently
probabilistic nature of quantum programs, measurement-based validation methods
face significant limitations.
  To investigate these limitations, we conducted an empirical study of recent
research on quantum program testing, analyzing measurement-based validation
methods in the literature. Our analysis categorizes existing measurement-based
validation methods into two groups: distribution-level validation and
output-value-level validation. We then compare measurement-based validation
with statevector-based validation methods to evaluate their pros and cons. Our
findings demonstrate that measurement-based validation is suitable for
straightforward assessments, such as verifying the existence of specific output
values, while statevector-based validation proves more effective for
complicated tasks such as assessing the program behaviors.

</details>


### [8] [Incentives and Outcomes in Bug Bounties](https://arxiv.org/abs/2509.16655)
*Serena Wang,Martino Banchio,Krzysztof Kotowicz,Katrina Ligett,R. Preston McAfee,Eduardo' Vela'' Nava*

Main category: cs.SE

TL;DR: 通过分析Google漏洞奖励计划奖金额提升对漏洞提交的影响，发现高额奖励显著提升了高价值漏洞的报告数量和参与人员的活跃度，验证了金钱激励对安全社区的正向作用。


<details>
  <summary>Details</summary>
Motivation: 现有关于奖励激励和漏洞挖掘产出的关系研究甚少，特别是在大型技术公司中的实际效果不明确。研究旨在填补激励机制与成果关系的认知空缺。

Method: 对Google漏洞奖励计划在2024年7月奖励金额提升（最高提升200%）后的漏洞提交数据进行经验分析，包括数量、质量、弹性等方面。

Result: 奖励金额提升后，高价值漏洞提交量显著增加，既有老研究者主动参与，也有新顶级安全人员被吸引进入项目。

Conclusion: 增加奖励金额能够提高提交高价值漏洞的数量和质量，且既能激励资深研究者，也能吸引新的顶级安全研究者。

Abstract: Bug bounty programs have contributed significantly to security in technology
firms in the last decade, but little is known about the role of reward
incentives in producing useful outcomes. We analyze incentives and outcomes in
Google's Vulnerability Rewards Program (VRP), one of the world's largest bug
bounty programs. We analyze the responsiveness of the quality and quantity of
bugs received to changes in payments, focusing on a change in Google's reward
amounts posted in July, 2024, in which reward amounts increased by up to 200%
for the highest impact tier. Our empirical results show an increase in the
volume of high-value bugs received after the reward increase, for which we also
compute elasticities. We further break down the sources of this increase
between veteran researchers and new researchers, showing that the reward
increase both redirected the attention of veteran researchers and attracted new
top security researchers into the program.

</details>


### [9] [Verifying User Interfaces using SPARK Ada: A Case Study of the T34 Syringe Driver](https://arxiv.org/abs/2509.16681)
*Peterson Jean*

Main category: cs.SE

TL;DR: 本研究利用SPARK Ada的形式化验证工具对医疗注射泵模型进行了建模与验证，有助于早期识别人因风险，提高医疗设备安全，但在实际应用中用户界面设计存在一定限制。


<details>
  <summary>Details</summary>
Motivation: 医疗设备因其安全风险受到严格监管，相关标准日益重视用户交互中的“人因”问题。传统测试方法难以及时捕获全部人因风险，特别是在如T34注射泵等关键设备的真实使用中。如何在产品早期开发阶段预防、减少这些潜在风险成为紧迫需求。

Method: 本研究基于SPARK Ada形式化验证工具，对T34注射泵的行为模型进行形式化验证。探索并实现了通用输注泵模型在SPARK Ada中的细化过程，通过形式化数学证明工具评估原型模型的验证水平，并分析在SPARK Ada中实现用户界面相关抽象和组件时的潜在局限。

Result: 成功实现了通用输注泵模型在SPARK Ada的建模和验证，原型系统的形式化验证水平得以评估。同时，研究揭示了模型在抽象和用户界面设计组件方面的实现限制。

Conclusion: 将形式化方法引入医疗设备开发流程（特别是通过SPARK Ada工具）有助于在早期发现并预防人因风险，提高工业安全标准集成的一致性，但在用户界面设计抽象方面存在一定的实际局限。

Abstract: The increase in safety and critical systems improved Healthcare. Due to their
risk of harm, such systems are subject to stringent guidelines and compliances.
These safety measures ensure a seamless experience and mitigate the risk to
end-users. Institutions like the Food and Drug Administration and the NHS,
respectively, established international standards and competency frameworks to
ensure industry compliance with these safety concerns. Medical device
manufacturing is mainly concerned with standards. Consequently, these standards
now advocate for better human factors considered in user interaction for
medical devices. This forces manufacturers to rely on heavy testing and review
to cover many of these factors during development. Sadly, many human factor
risks will not be caught until proper testing in real life, which might be
catastrophic in the case of an ambulatory device like the T34 syringe pump.
Therefore, effort in formal methods research may propose new solutions in
anticipating these errors in the early stages of development or even reducing
their occurrence based on the use of standard generic model. These generically
developed models will provide a common framework for safety integration in
industry and may potentially be proven using formal verification mathematical
proofs. This research uses SPARK Ada's formal verification tool against a
behavioural model of the T34 syringe driver. A Generic Infusion Pump model
refinement is explored and implemented in SPARK Ada. As a subset of the Ada
language, the verification level of the end prototype is evaluated using SPARK.
Exploring potential limitations defines the proposed model's implementation
liability when considering abstraction and components of User Interface design
in SPARK Ada.

</details>


### [10] [RelRepair: Enhancing Automated Program Repair by Retrieving Relevant Code](https://arxiv.org/abs/2509.16701)
*Shunyu Liu,Guangdong Bai,Mark Utting,Guowei Yang*

Main category: cs.SE

TL;DR: 本文提出RelRepair方法，通过检索项目相关代码提升LLM自动修复程序的表现。在主流数据集上，修复率显著提升，验证了向LLM输入项目特定信息的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）虽然在自动化修复程序（APR）等任务中表现优异，但由于预训练属性是通用的，难以应对需要项目特定信息的修复任务（如理解专属标识符、代码结构和上下文关系等）。因此，在依赖于这些信息的修复场景中，LLMs常常无法生成正确的补丁。

Method: 提出了RelRepair方法，通过检索项目相关代码提升APR效果。RelRepair首先分析函数名称和代码注释，识别相关函数签名；随后，进行更深层的代码分析，获取与修复相关的代码片段。最终，将获取到的信息集成到LLM的输入，帮助模型生成更准确的修复补丁。

Result: 在Defects4J V1.2和ManySStuBs4J两个主流数据集上评估了RelRepair，并与现有多种先进的LLM-APR方法进行对比。RelRepair在Defects4J V1.2中成功修复了101个bug，在ManySStuBs4J中修复率提升了17.1%，整体达到48.3%。

Conclusion: 向LLM提供项目特定的相关信息，对提升自动化程序修复任务性能有着关键作用。RelRepair验证了此策略的有效性，为未来在APR中应用LLM提供了新的思路。

Abstract: Automated Program Repair (APR) has emerged as a promising paradigm for
reducing debugging time and improving the overall efficiency of software
development. Recent advances in Large Language Models (LLMs) have demonstrated
their potential for automated bug fixing and other software engineering tasks.
Nevertheless, the general-purpose nature of LLM pre-training means these models
often lack the capacity to perform project-specific repairs, which require
understanding of domain-specific identifiers, code structures, and contextual
relationships within a particular codebase. As a result, LLMs may struggle to
generate correct patches when the repair depends on project-specific
information.
  To address this limitation, we introduce RelRepair, a novel approach that
retrieves relevant project-specific code to enhance automated program repair.
RelRepair first identifies relevant function signatures by analyzing function
names and code comments within the project. It then conducts deeper code
analysis to retrieve code snippets relevant to the repair context. The
retrieved relevant information is then incorporated into the LLM's input
prompt, guiding the model to generate more accurate and informed patches. We
evaluate RelRepair on two widely studied datasets, Defects4J V1.2 and
ManySStuBs4J, and compare its performance against several state-of-the-art
LLM-based APR approaches. RelRepair successfully repairs 101 bugs in Defects4J
V1.2. Furthermore, RelRepair achieves a 17.1\% improvement in the ManySStuBs4J
dataset, increasing the overall fix rate to 48.3\%. These results highlight the
importance of providing relevant project-specific information to LLMs, shedding
light on effective strategies for leveraging LLMs in APR tasks.

</details>


### [11] [Can We Trust the AI Pair Programmer? Copilot for API Misuse Detection and Correction](https://arxiv.org/abs/2509.16795)
*Saikat Mondal,Chanchal K. Roy,Hong Wang,Juan Arguello,Samantha Mathan*

Main category: cs.SE

TL;DR: 本文实证分析了GitHub Copilot对API误用的检测与修复能力，发现其在常规误用检测和自动修复上表现优异，可有效减少开发缺陷，但在复杂场景下依然有改进空间。


<details>
  <summary>Details</summary>
Motivation: API误用会引入安全漏洞、系统故障并增加维护成本，这些依然是软件开发中亟需解决的关键难题。目前的检测方法偏重于开发后阶段，导致缺陷修复延迟并提升维护难度和风险。

Method: 本研究评估了GitHub Copilot在API误用检测与修复方面的效果，使用MUBench中的基准误用案例，共构造了740个误用样本（手动与AI协助两种方式）及147个正确用例，在Visual Studio Code环境中测试Copilot的表现。

Result: Copilot在API误用检测中取得了86.2%的准确率、91.2%的精确率和92.4%的召回率，对常见误用类型（如缺失调用、空检查）表现较好，但对复杂、需上下文感知的误用则表现不足。Copilot还成功修复了95%以上其检测到的误用。

Conclusion: AI驱动的代码助手（如Copilot）在API误用实时检测和修复方面展现较大潜力，可有效用于开发阶段的配对编程和缺陷预防，但依然存在某些类型误用检测的局限性。

Abstract: API misuse introduces security vulnerabilities, system failures, and
increases maintenance costs, all of which remain critical challenges in
software development. Existing detection approaches rely on static analysis or
machine learning-based tools that operate post-development, which delays defect
resolution. Delayed defect resolution can significantly increase the cost and
complexity of maintenance and negatively impact software reliability and user
trust. AI-powered code assistants, such as GitHub Copilot, offer the potential
for real-time API misuse detection within development environments. This study
evaluates GitHub Copilot's effectiveness in identifying and correcting API
misuse using MUBench, which provides a curated benchmark of misuse cases. We
construct 740 misuse examples, manually and via AI-assisted variants, using
correct usage patterns and misuse specifications. These examples and 147
correct usage cases are analyzed using Copilot integrated in Visual Studio
Code. Copilot achieved a detection accuracy of 86.2%, precision of 91.2%, and
recall of 92.4%. It performed strongly on common misuse types (e.g.,
missing-call, null-check) but struggled with compound or context-sensitive
cases. Notably, Copilot successfully fixed over 95% of the misuses it
identified. These findings highlight both the strengths and limitations of
AI-driven coding assistants, positioning Copilot as a promising tool for
real-time pair programming and detecting and fixing API misuses during software
development.

</details>


### [12] [Implementation of the Collision Avoidance System for DO-178C Compliance](https://arxiv.org/abs/2509.16844)
*Rim Zrelli,Henrique Amaral Misson,Sorelle Kamkuimo,Maroua Ben Attia,Abdo Shabah,Felipe Gohring de Magalhaes,Gabriela Nicolescu*

Main category: cs.SE

TL;DR: 本文介绍了一个无人机碰撞规避系统的设计实现案例，采用形式化方法与自动化工具，贯穿要求、设计、开发和验证等环节，有效支持DO-178C软件安全标准的合规，对无人机安全软件的开发与认证具有参考价值。


<details>
  <summary>Details</summary>
Motivation: 随着无人机（UAV）在民用空域的广泛应用，保障其飞行安全、避免碰撞成为亟需解决的重要问题。此外，达到DO-178C飞行软件安全标准合规对于无人机系统的商业化和应用推广至关重要。

Method: 作者提出并实现了一个碰撞规避系统（CAS），采用了基于NASA Access 5项目的功能需求。开发过程结合了形式化方法、模型驱动开发和自动化验证工具（如Alloy、SPIN、Simulink Embedded Coder、LDRA），覆盖了需求、设计、编码、验证和可追溯性全流程，重点关注DO-178C 设计保证等级B的合规。

Result: 采用形式化建模和自动化工具链实现了对规范缺陷的早期发现和修正，增强了开发全过程的可追溯性和验证证据。静态和动态分析验证了代码质量和覆盖率，形式化验证方法为关键部件提供了数学正确性保证。尽管集成阶段尚未完全实现，该方法在应对无人机安全关键系统的认证挑战方面表现有效。

Conclusion: CAS开发案例证明，结合形式化方法与自动化工具，能够有效帮助无人机安全关键软件实现DO-178C合规，提升开发过程的可追溯性与验证可靠性。该方法为类似无人机系统的安全认证提供了可借鉴范例。

Abstract: This technical report presents the detailed implementation of a Collision
Avoidance System (CAS) for Unmanned Aerial Vehicles (UAVs), developed as a case
study to demonstrate a rigorous methodology for achieving DO-178C compliance in
safety-critical software. The CAS is based on functional requirements inspired
by NASA's Access 5 project and is designed to autonomously detect, evaluate,
and avoid potential collision threats in real-time, supporting the safe
integration of UAVs into civil airspace.
  The implementation environment combines formal methods, model-based
development, and automated verification tools, including Alloy, SPIN, Simulink
Embedded Coder, and the LDRA tool suite. The report documents each phase of the
software lifecycle: requirements specification and validation, architectural
and detailed design, coding, verification, and traceability, with a strong
focus on compliance with DO-178C Design Assurance Level B objectives.
  Results demonstrate that formal modelling and automated toolchains enabled
early detection and correction of specification defects, robust traceability,
and strong evidence of verification and validation across all development
stages. Static and dynamic analyses confirmed code quality and coverage, while
formal verification methods provided mathematical assurance of correctness for
critical components. Although the integration phase was not fully implemented,
the approach proved effective in addressing certification challenges for UAV
safety-critical systems.
  \keywords Collision Avoidance System (CAS), Unmanned Aerial Vehicles (UAVs),
DO-178C compliance, Safety-critical software, Formal methods, Model-based
development, Alloy, SPIN model checker, Simulink Embedded Coder, LDRA tool
suite, Software verification and validation, Traceability, Certification.

</details>


### [13] [MobileUPReg: Identifying User-Perceived Performance Regressions in Mobile OS Versions](https://arxiv.org/abs/2509.16864)
*Wei Liu,Yi Wen Heng,Feng Lin,Tse-Hsun,Chen,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 本文提出了MobileUPReg框架，通过真实用户感知指标检测移动操作系统的性能回退，准确率高、部署效果佳，优于传统检测方法。


<details>
  <summary>Details</summary>
Motivation: 移动操作系统经常更新，但更新过程中容易引入性能回退，现有检测手段依赖系统级指标或聚焦特定组件，容易遗漏真正影响用户体验的回退问题。

Method: 提出MobileUPReg黑盒测试框架，通过在不同OS版本下运行相同应用，采集和比较用户感知的性能指标（如响应时间、完成时间、启动时间、掉帧数），从而判断用户可感知的回退。

Result: MobileUPReg能高准确率地提取用户感知指标，在大规模测试中检测到用户感知回退的精度为0.96、召回率为0.91、F1分数为0.93，明显超过统计学基准方法。该工具已在工业CI流程中部署，并发现了传统工具未检测出的回退。

Conclusion: MobileUPReg框架实现了准确、可扩展、贴合用户体验的回退检测，提升了移动操作系统质量验证的效果。

Abstract: Mobile operating systems (OS) are frequently updated, but such updates can
unintentionally degrade user experience by introducing performance regressions.
Existing detection techniques often rely on system-level metrics (e.g., CPU or
memory usage) or focus on specific OS components, which may miss regressions
actually perceived by users -- such as slower responses or UI stutters. To
address this gap, we present MobileUPReg, a black-box framework for detecting
user-perceived performance regressions across OS versions. MobileUPReg runs the
same apps under different OS versions and compares user-perceived performance
metrics -- response time, finish time, launch time, and dropped frames -- to
identify regressions that are truly perceptible to users. In a large-scale
study, MobileUPReg achieves high accuracy in extracting user-perceived metrics
and detects user-perceived regressions with 0.96 precision, 0.91 recall, and
0.93 F1-score -- significantly outperforming a statistical baseline using the
Wilcoxon rank-sum test and Cliff's Delta. MobileUPReg has been deployed in an
industrial CI pipeline, where it analyzes thousands of screencasts across
hundreds of apps daily and has uncovered regressions missed by traditional
tools. These results demonstrate that MobileUPReg enables accurate, scalable,
and perceptually aligned regression detection for mobile OS validation.

</details>


### [14] [DecipherGuard: Understanding and Deciphering Jailbreak Prompts for a Safer Deployment of Intelligent Software Systems](https://arxiv.org/abs/2509.16870)
*Rui Yang,Michael Fu,Chakkrit Tantithamthavorn,Chetan Arora,Gunel Gulmammadova,Joey Chua*

Main category: cs.SE

TL;DR: 现有LLM守护方案在特定攻击方式下防御效果不佳。本文提出DecipherGuard，结合解密层与低秩机制，大幅提升了运行时防护性能，对越狱攻击有更强防御效果。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）驱动的智能软件系统在关键领域的广泛部署，其运行时安全性变得十分重要。目前的业界主流防护措施（如LlamaGuard）在面对某些攻击（如混淆与模板型越狱攻击）时防御效果显著下降，亟需更加有效的安全增强方法。

Method: 本文提出了DecipherGuard框架：通过引入解密层应对混淆型攻击，并采用低秩适应机制提升对模板型攻击的防护能力。

Result: 基于超过22,000个提示的实证评测，DecipherGuard在防御成功率（DSR）上相比LlamaGuard及其他两种守护措施提升了36%到65%，整体防护性能（OGP）提升了20%到50%。

Conclusion: DecipherGuard框架能有效提升LLM驱动软件系统在运行时防御越狱攻击的能力，相比现有方法有显著性能优势。

Abstract: Intelligent software systems powered by Large Language Models (LLMs) are
increasingly deployed in critical sectors, raising concerns about their safety
during runtime. Through an industry-academic collaboration when deploying an
LLM-powered virtual customer assistant, a critical software engineering
challenge emerged: how to enhance a safer deployment of LLM-powered software
systems at runtime? While LlamaGuard, the current state-of-the-art runtime
guardrail, offers protection against unsafe inputs, our study reveals a Defense
Success Rate (DSR) drop of 24% under obfuscation- and template-based jailbreak
attacks. In this paper, we propose DecipherGuard, a novel framework that
integrates a deciphering layer to counter obfuscation-based prompts and a
low-rank adaptation mechanism to enhance guardrail effectiveness against
template-based attacks. Empirical evaluation on over 22,000 prompts
demonstrates that DecipherGuard improves DSR by 36% to 65% and Overall
Guardrail Performance (OGP) by 20% to 50% compared to LlamaGuard and two other
runtime guardrails. These results highlight the effectiveness of DecipherGuard
in defending LLM-powered software systems against jailbreak attacks during
runtime.

</details>


### [15] [Deep Synthetic Cross-Project Approaches for Software Reliability Growth Modeling](https://arxiv.org/abs/2509.16939)
*Taehyoun Kim,Duksan Ryu,Jongmoon Baik*

Main category: cs.SE

TL;DR: 本文提出结合合成数据和跨项目迁移学习的DSC-SRGM方法，在数据稀缺场景下可大幅提升软件可靠性预测，验证了其在60个真实项目中的有效性，但合成数据比例需谨慎控制。


<details>
  <summary>Details</summary>
Motivation: 在软件测试或运行初期阶段，由于数据稀缺，传统软件可靠性增长模型（SRGM）的预测准确性较差。虽然跨项目迁移学习可优化此问题，但真实数据集的稀缺和保密性限制了其应用。论文旨在解决在数据稀缺环境下提高软件可靠性预测准确性的问题。

Method: 提出DSC-SRGM方法：首先通过传统SRGM生成合成数据集，以保持真实缺陷发现趋势的统计特性；其次利用基于相关度的聚类，选取与目标项目模式相似的合成数据集；最后用这些数据集训练深度学习模型，进行可靠性预测，并在60个真实数据集上进行对比实验。

Result: DSC-SRGM方法在预测准确率上，比传统SRGM提升最大23.3%，比只用真实数据训练的跨项目深度学习模型提升最大32.2%。但如果合成数据使用过多或与真实数据简单混合，反而会降低预测性能。

Conclusion: DSC-SRGM在数据稀缺环境下能显著提升软件可靠性预测，是一种具有潜力的新方法，但需保证合成与真实数据的适当比例。

Abstract: Software Reliability Growth Models (SRGMs) are widely used to predict
software reliability based on defect discovery data collected during testing or
operational phases. However, their predictive accuracy often degrades in
data-scarce environments, such as early-stage testing or safety-critical
systems. Although cross-project transfer learning has been explored to mitigate
this issue by leveraging data from past projects, its applicability remains
limited due to the scarcity and confidentiality of real-world datasets. To
overcome these limitations, we propose Deep Synthetic Cross-project SRGM
(DSC-SRGM), a novel approach that integrates synthetic data generation with
cross-project transfer learning. Synthetic datasets are generated using
traditional SRGMs to preserve the statistical characteristics of real-world
defect discovery trends. A cross-correlation-based clustering method is applied
to identify synthetic datasets with patterns similar to the target project.
These datasets are then used to train a deep learning model for reliability
prediction. The proposed method is evaluated on 60 real-world datasets, and its
performance is compared with both traditional SRGMs and cross-project deep
learning models trained on real-world datasets. DSC-SRGM achieves up to 23.3%
improvement in predictive accuracy over traditional SRGMs and 32.2% over
cross-project deep learning models trained on real-world datasets. However,
excessive use of synthetic data or a naive combination of synthetic and
real-world data may degrade prediction performance, highlighting the importance
of maintaining an appropriate data balance. These findings indicate that
DSC-SRGM is a promising approach for software reliability prediction in
data-scarce environments.

</details>


### [16] [SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?](https://arxiv.org/abs/2509.16941)
*Xiang Deng,Jeff Da,Edwin Pan,Yannis Yiming He,Charles Ide,Kanak Garg,Niklas Lauffer,Andrew Park,Nitin Pasari,Chetan Rane,Karmini Sampath,Maya Krishnan,Srivatsa Kundurthy,Sean Hendryx,Zifan Wang,Chen Bo Calvin Zhang,Noah Jacobson,Bing Liu,Brad Kenstler*

Main category: cs.SE

TL;DR: 该论文提出SWE-Bench PRO，一个更贴近真实企业级开发任务的自动编码模型评估基准。结果显示当前模型在复杂多变任务下表现有限，并通过问题聚类分析给出模型局限性。此基准将推动更高水平的软件开发自动化研究。


<details>
  <summary>Details</summary>
Motivation: 在自动化软件开发领域，现有基准测试如SWE-BENCH难以覆盖真实、复杂、企业级的问题。因此，作者提出更加具挑战性的基准，以更真实地评估自动代码生成模型的能力。

Method: 开发了SWE-Bench PRO基准，包括1865个来自41个活跃维护仓库的真实工程问题，并分为公开、保留及商业三类。问题均为人工审核，确保任务实际可解，以检验主流编码模型在多文件、长期任务上的表现，并对失败模式进行聚类分析。

Result: 主流自动编码模型在该基准表现较弱，最佳GPT-5模型通过率仅为23.3%，整体低于25%。通过分析失败模式，揭示了当前模型在复杂任务下的局限性。

Conclusion: SWE-Bench PRO能够有效反映复杂真实软件开发问题，是抗污染性较强的测试平台。该基准有助于推动更加自主、专业的软件工程代理的发展。

Abstract: We introduce SWE-Bench Pro, a substantially more challenging benchmark that
builds upon the best practices of SWE-BENCH [25], but is explicitly designed to
capture realistic, complex, enterprise-level problems beyond the scope of
SWE-BENCH. SWE-BENCH PRO contains 1,865 problems sourced from a diverse set of
41 actively maintained repositories spanning business applications, B2B
services, and developer tools. The benchmark is partitioned into a public set
with open access to problems sourced from 11 repositories, a held-out set of 12
repositories and a commercial set of 18 proprietary repositories where we have
formal partnership agreements with early-stage startups. Problems in the
held-out and the commercial set are not publicly accessible, but we release
results on the commercial set. Our benchmark features long-horizon tasks that
may require hours to days for a professional software engineer to complete,
often involving patches across multiple files and substantial code
modifications. All tasks are human-verified and augmented with sufficient
context to ensure resolvability. In our evaluation of widely used coding
models, under a unified scaffold, we observe that their performance on
SWE-Bench PRO remains below 25% (Pass@1), with GPT-5 achieving the highest
score to date at 23.3%. To better understand these limitations, we cluster the
failure modes observed in the collected agent trajectories for a clearer
characterization of the error patterns exhibited by current models. Overall,
SWE-BENCH PRO provides a contamination-resistant testbed that more faithfully
captures the complexity and diversity of real-world software development,
advancing the pursuit of truly autonomous software engineering agents at a
professional level.

</details>


### [17] [Static Security Vulnerability Scanning of Proprietary and Open-Source Software: An Adaptable Process with Variants and Results](https://arxiv.org/abs/2509.16985)
*James J. Cusick*

Main category: cs.SE

TL;DR: 本文提出了一套面向专有与开源软件的端到端漏洞管理流程，结合多种工具，能自动化发现和修复漏洞，有效提升软件安全性并降低风险，可灵活集成于各种开发流程中。


<details>
  <summary>Details</summary>
Motivation: 软件漏洞是实现安全目标的主要风险因素，尤其是在开发环境中包含专有或开源软件时，如何系统性、持续性地检测和修复这些漏洞成为亟需解决的问题。

Method: 提出并展示了一套端到端的通用流程，结合了工业验证的方法与工具，支持定制实例化、配置和自动化漏洞代码扫描及漏洞修复优先级处理。该方法集成了多种工具，通过迭代方法对专有与开源应用中的实例进行分析与实践，并讨论了其在全面SDLC流程中的应用。

Result: 该流程与工具集能灵活集成到不同的软件开发生命周期中，提升漏洞检测和修复能力，降低源代码和供应链风险，提升新旧解决方案的安全性。

Conclusion: 采用本文提出的方法能以较小代价、最大灵活性提升软件安全，支持自动化与AI等前沿技术未来集成，为工业与开源应用提供系统性漏洞管理方案。

Abstract: Software vulnerabilities remain a significant risk factor in achieving
security objectives within software development organizations. This is
especially true where either proprietary or open-source software (OSS) is
included in the technological environment. In this paper an end-to-end process
with supporting methods and tools is presented. This industry proven generic
process allows for the custom instantiation, configuration, and execution of
routinized code scanning for software vulnerabilities and their prioritized
remediation. A select set of tools are described for this key DevSecOps
function and placed into an iterative process. Examples of both industrial
proprietary applications and open-source applications are provided including
specific vulnerability instances and a discussion of their treatment. The
benefits of each selected tool are considered, and alternative tools are also
introduced. Application of this method in a comprehensive SDLC model is also
reviewed along with prospective enhancements from automation and the
application of advanced technologies including AI. Adoption of this method can
be achieved with minimal adjustments and with maximum flexibility for results
in reducing source code vulnerabilities, reducing supply chain risk, and
improving the security profile of new or legacy solutions.

</details>


### [18] [Prompt-with-Me: in-IDE Structured Prompt Management for LLM-Driven Software Engineering](https://arxiv.org/abs/2509.17096)
*Ziyou Li,Agnia Sergeyuk,Maliheh Izadi*

Main category: cs.SE

TL;DR: Prompt-with-Me是一款集成于开发环境的结构化提示管理系统，可自动对提示分类、优化和脱敏，实验证明其显著提升软件工程开发提示的管理效率和质量，获得开发者高度评价。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在软件工程领域的提示管理缺乏结构化和流程化，阻碍了可靠性、复用性及工业流程集成。亟需实用工具提升提示管理的专业度与效率。

Method: 提出并实现了一套集成于开发环境的Structured Prompt Management系统，通过四维分类法自动对提示进行分类，并对提示库进行模板提取、信息脱敏和语言优化。通过真实性能和用户接受度实验评估系统效果。

Result: （1）建立了涵盖意图、作者角色、开发周期阶段和提示类型的四维提示分类法；（2）1108个真实提示实验中，LLMs对软件提示具备高准确率自动分类能力；（3）用户实验（11人）显示系统易用、认知负荷低、显著提升提示质量及效率。

Conclusion: Prompt-with-Me系统在实际软件工程开发中有效提升了提示管理的可靠性、可复用性及开发效率，获得了开发者的高度认可。

Abstract: Large Language Models are transforming software engineering, yet prompt
management in practice remains ad hoc, hindering reliability, reuse, and
integration into industrial workflows. We present Prompt-with-Me, a practical
solution for structured prompt management embedded directly in the development
environment. The system automatically classifies prompts using a
four-dimensional taxonomy encompassing intent, author role, software
development lifecycle stage, and prompt type. To enhance prompt reuse and
quality, Prompt-with-Me suggests language refinements, masks sensitive
information, and extracts reusable templates from a developer's prompt library.
Our taxonomy study of 1108 real-world prompts demonstrates that modern LLMs can
accurately classify software engineering prompts. Furthermore, our user study
with 11 participants shows strong developer acceptance, with high usability
(Mean SUS=73), low cognitive load (Mean NASA-TLX=21), and reported gains in
prompt quality and efficiency through reduced repetitive effort. Lastly, we
offer actionable insights for building the next generation of prompt management
and maintenance tools for software engineering workflows.

</details>


### [19] [Clotho: Measuring Task-Specific Pre-Generation Test Adequacy for LLM Inputs](https://arxiv.org/abs/2509.17314)
*Juyeon Yoon,Somin Kim,Robert Feldt,Shin Yoo*

Main category: cs.SE

TL;DR: 本文提出CLOTHO方法，利用LLM隐藏状态和GMM，在完全无需生成输出的情况下，低成本预测输入是否会导致任务失败。实验显示仅标注少量样本即可高效提升测试输入优先级，适用范围从开源模型扩展至专有模型。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）在软件开发诸多环节的应用日益广泛，但在特定任务的测试过程中，存在成本高、效率低的问题：如缺乏真实标签、过度依赖人工判断，以及不确定性与充分性指标通常需完整推理过程，难以在生成输出前评估输入的充分性。

Method: 提出CLOTHO方法，即在生成输出前，通过分析隐藏状态，使用高斯混合模型（GMM）自适应地从大批未标注输入中选择最具信息价值的样本进行人工标注，并据此对未见输入进行失效概率排序。

Result: 实验在八个基准任务和三个开源LLM上验证：CLOTHO可用ROC-AUC 0.716高效预测失效，仅需标注平均5.4%的样本。与后生成不确定性指标互补，并可将开放权重模型的判别能力迁移至专有模型。在专有模型输入测试场景下，故障输入优先级提升显著：从100个随机输入中的18.7提升至42.5个。

Conclusion: CLOTHO方法实现了任务相关、无需生成输出即可评估输入充分性的低成本失效预测，具备较强迁移性与实际测试优先级提升效果，可与传统后生成不确定度方法互补应用。

Abstract: Software increasingly relies on the emergent capabilities of Large Language
Models (LLMs), from natural language understanding to program analysis and
generation. Yet testing them on specific tasks remains difficult and costly:
many prompts lack ground truth, forcing reliance on human judgment, while
existing uncertainty and adequacy measures typically require full inference. A
key challenge is to assess input adequacy in a way that reflects the demands of
the task, ideally before even generating any output. We introduce CLOTHO, a
task-specific, pre-generation adequacy measure that estimates input difficulty
directly from hidden LLM states. Given a large pool of unlabelled inputs for a
specific task, CLOTHO uses a Gaussian Mixture Model (GMM) to adaptively sample
the most informative cases for human labelling. Based on this reference set the
GMM can then rank unseen inputs by their likelihood of failure. In our
empirical evaluation across eight benchmark tasks and three open-weight LLMs,
CLOTHO can predict failures with a ROC-AUC of 0.716, after labelling reference
sets that are on average only 5.4% of inputs. It does so without generating any
outputs, thereby reducing costs compared to existing uncertainty measures.
Comparison of CLOTHO and post-generation uncertainty measures shows that the
two approaches complement each other. Crucially, we show that adequacy scores
learnt from open-weight LLMs transfer effectively to proprietary models,
extending the applicability of the approach. When prioritising test inputs for
proprietary models, CLOTHO increases the average number of failing inputs from
18.7 to 42.5 out of 100, compared to random prioritisation.

</details>


### [20] [BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing](https://arxiv.org/abs/2509.17335)
*Mingxuan Xiao,Yan Xiao,Shunhui Ji,Jiahe Tu,Pengcheng Zhang*

Main category: cs.SE

TL;DR: 本文提出BASFuzz，结合一致性度量与束-退火搜索，有效提升了LLM驱动NLP系统的模糊测试能力，测试效果显著优于现有方法且效率更高。


<details>
  <summary>Details</summary>
Motivation: 现有针对大语言模型（LLM）驱动的NLP软件的模糊测试方法存在与模型行为模式结合不紧密、生成任务下的测试能力下降等问题。

Method: 提出了一种针对LLM类NLP软件的高效模糊测试方法——BASFuzz。BASFuzz通过引入文本一致性指标引导测试输入变异，并结合束搜索和模拟退火的算法设计高效模糊环。同时，采用基于信息熵的自适应调整和精英策略增强测试能力。

Result: 在六个NLG和NLU代表性数据集场景下，BASFuzz测试有效性达90.335%，相比当前最优基线方法平均减少时延2163.852秒。

Conclusion: BASFuzz提升了LLM型NLP软件的鲁棒性测试效率与效果，为实际部署前提供了更优选择。

Abstract: Fuzzing has shown great success in evaluating the robustness of intelligent
natural language processing (NLP) software. As large language model (LLM)-based
NLP software is widely deployed in critical industries, existing methods still
face two main challenges: 1 testing methods are insufficiently coupled with the
behavioral patterns of LLM-based NLP software; 2 fuzzing capability for the
testing scenario of natural language generation (NLG) generally degrades. To
address these issues, we propose BASFuzz, an efficient Fuzz testing method
tailored for LLM-based NLP software. BASFuzz targets complete test inputs
composed of prompts and examples, and uses a text consistency metric to guide
mutations of the fuzzing loop, aligning with the behavioral patterns of
LLM-based NLP software. A Beam-Annealing Search algorithm, which integrates
beam search and simulated annealing, is employed to design an efficient fuzzing
loop. In addition, information entropy-based adaptive adjustment and an elitism
strategy further enhance fuzzing capability. We evaluate BASFuzz on six
datasets in representative scenarios of NLG and natural language understanding
(NLU). Experimental results demonstrate that BASFuzz achieves a testing
effectiveness of 90.335% while reducing the average time overhead by 2,163.852
seconds compared to the current best baseline, enabling more effective
robustness evaluation prior to software deployment.

</details>


### [21] [SLICET5: Static Program Slicing using Language Models with Copy Mechanism and Constrained Decoding](https://arxiv.org/abs/2509.17338)
*Pengfei He,Shaowei Wang,Tse-Hsun Chen*

Main category: cs.SE

TL;DR: 提出的切片方法融合copy机制与结构化解码约束，可明显提高对不完整代码的支持与切片准确率，在多数据集的测试中优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 现有的静态程序切片工具需要完整且可解析的源码，但现实中大量代码片段不完整或无法解析，且现有的学习型方法存在依赖识别不准确与生成结果失控的问题。该论文旨在解决这些实际应用中的关键挑战。

Method: 作者提出了一种新型的静态程序切片框架，将切片任务转化为序列到序列任务，采用轻量级语言模型（如CodeT5+）。主要技术创新包括引入copy机制提升依赖识别能力，并采用受限解码（只允许输出输入中的token，且利用语法结构约束检测不合法输出）。

Result: 在CodeNet和LeetCode数据集上，该方法的准确率（ExactMatch）相比当前最佳方法提升高达27%，且在处理不完整代码时表现稳健，具有良好的实际应用价值。

Conclusion: 该方法能够有效提升静态程序切片在真实软件工程场景下的适用性与准确性，尤其适合面对不完整或不可解析的代码。

Abstract: Static program slicing is a fundamental technique in software engineering.
Traditional static slicing tools rely on parsing complete source code, which
limits their applicability to real-world scenarios where code snippets are
incomplete or unparsable. While recent research developed learning-based
approaches to predict slices, they face critical challenges: (1) Inaccurate
dependency identification, where models fail to precisely capture data and
control dependencies between code elements; and (2) Unconstrained generation,
where models produce slices with extraneous or hallucinated tokens not present
in the input, violating the structural integrity of slices. To address these
challenges, we propose \ourtool, a novel slicing framework that reformulates
static program slicing as a sequence-to-sequence task using lightweight
language models (e.g., CodeT5+). Our approach incorporates two key innovations.
First, we introduce a copy mechanism that enables the model to more accurately
capture inter-element dependencies and directly copy relevant tokens from the
input, improving both dependency reasoning and generation constraint. Second,
we design a constrained decoding process with (a) lexical constraint,
restricting outputs to input tokens only, and (b) syntactic constraint,
leveraging Tree Similarity of Edit Distance (TSED) monotonicity to detect
structurally invalid outputs and discard them. We evaluate \ourtool on CodeNet
and LeetCode datasets and show it consistently outperforms state-of-the-art
baselines, improving ExactMatch scores by up to 27\%. Furthermore, \ourtool
demonstrates strong performance on incomplete code, highlighting its robustness
and practical utility in real-world development environments.

</details>


### [22] [Prompts as Software Engineering Artifacts: A Research Agenda and Preliminary Findings](https://arxiv.org/abs/2509.17548)
*Hugo Villamizar,Jannik Fischbach,Alexander Korn,Andreas Vogelsang,Daniel Mendez*

Main category: cs.SE

TL;DR: 随着开发者大量使用LLM，提示词逐渐成为软件工程中的重要产物。但目前提示词管理较为随意，缺乏体系化标准。作者通过问卷调查发现，大多数开发者依赖个人经验与试错方法，提示词复用率低。研究呼吁建立系统的提示词开发与管理流程，为提升工程效率与质量提供参考。


<details>
  <summary>Details</summary>
Motivation: 软件开发人员频繁使用大型语言模型（LLM）支持各类软件工程任务，促使“提示词”成为一种重要的工程产物。但目前对其实际使用和管理方式知之甚少，缺乏体系化方法。作者希望填补这一领域的研究空白。

Method: 提出一个研究计划：1）调研LLM提示词在软件工程领域的使用现状及挑战；2）将提示词作为软件工程产物进行演化、可追溯性、复用性和系统化管理权衡分析；3）开发并实证评估提示词管理指南。作为第一步，开展了针对74位软件开发者的探索性问卷调查。

Result: 调查显示，目前在软件工程中使用LLM提示词普遍缺乏系统性，大多通过反复试错进行调整，复用率低，主要依赖个人经验而非标准化流程。

Conclusion: 当前SE领域的LLM提示词管理较为随意，亟需引入更系统化的管理方法。相关调查结果为后续研究奠定了数据基础。

Abstract: Developers now routinely interact with large language models (LLMs) to
support a range of software engineering (SE) tasks. This prominent role
positions prompts as potential SE artifacts that, like other artifacts, may
require systematic development, documentation, and maintenance. However, little
is known about how prompts are actually used and managed in LLM-integrated
workflows, what challenges practitioners face, and whether the benefits of
systematic prompt management outweigh the associated effort. To address this
gap, we propose a research programme that (a) characterizes current prompt
practices, challenges, and influencing factors in SE; (b) analyzes prompts as
software artifacts, examining their evolution, traceability, reuse, and the
trade-offs of systematic management; and (c) develops and empirically evaluates
evidence-based guidelines for managing prompts in LLM-integrated workflows. As
a first step, we conducted an exploratory survey with 74 software professionals
from six countries to investigate current prompt practices and challenges. The
findings reveal that prompt usage in SE is largely ad-hoc: prompts are often
refined through trial-and-error, rarely reused, and shaped more by individual
heuristics than standardized practices. These insights not only highlight the
need for more systematic approaches to prompt management but also provide the
empirical foundation for the subsequent stages of our research programme.

</details>


### [23] [From OCL to JSX: declarative constraint modeling in modern SaaS tools](https://arxiv.org/abs/2509.17629)
*Antonio Bucchiarone,Juri Di Rocco,Damiano Di Vincenzo,Alfonso Pierantonio*

Main category: cs.SE

TL;DR: 本论文探讨在现代低代码SaaS建模环境中，使用React生态的JSX替代OCL.js进行约束表达。通过实验比较发现，JSX具备更强的表达力，更契合前端架构，展现出成为主流约束规范方式的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着Node.js和包括Angular、React、Vue.js在内的框架兴起，低代码开发平台显著发展，加速了非专业人士构建软件的能力。其中，单页应用（SPA）和前端技术对低代码工具的演进影响巨大。本研究针对如何在现代建模环境里高效实现约束表达进行了探索。

Method: 论文提出用JSX（React生态中的JavaScript/TypeScript声明式、函数式子集）替代OCL.js（基于JavaScript的对象约束语言实现）表达建模约束。通过实证评估，比较JSX和OCL.js在典型建模场景中的性能和表现。

Result: 实验结果显示，JSX在表达能力上更广泛，且更适应以前端为主的架构。JSX在语法定义、代码生成和查询方面表现出更好的组合能力，适合当前的建模工具需求。

Conclusion: JSX为现代SaaS建模工具中的约束表达提供了更具前景的方案，尤其适合组件化前端架构，推动了约束规范的前端集成。然而，增加JSX的应用还需解决标准化、工具链兼容等挑战。

Abstract: The rise of Node.js in 2010, followed by frameworks like Angular, React, and
Vue.js, has accelerated the growth of low code development platforms. These
platforms harness modern UIX paradigms, component-based architectures, and the
SaaS model to enable non-experts to build software. The widespread adoption of
single-page applications (SPAs), driven by these frameworks, has shaped
low-code tools to deliver responsive, client side experiences. In parallel,
many modeling platforms have moved to the cloud, adopting either server-centric
architectures (e.g., GSLP) or client-side intelligence via SPA frameworks,
anchoring core components in JavaScript or TypeScript. Within this context,
OCL.js, a JavaScript-based implementation of the Object Constraint Language,
offers a web aligned approach to model validation, yet faces challenges such as
partial standard coverage, limited adoption, and weak integration with modern
front-end toolchains. In this paper, we explore JSX, a declarative, functional
subset of JavaScript/TypeScript used in the React ecosystem, as an alternative
to constraint expression in SaaS-based modeling environments. Its
component-oriented structure supports inductive definitions for syntax, code
generation, and querying. Through empirical evaluation, we compare JSX-based
constraints with OCL.js across representative modeling scenarios. Results show
JSX provides broader expressiveness and better fits front-end-first
architectures, indicating a promising path for constraint specification in
modern modeling tools.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [24] [Compositional Interface Refinement Through Subtyping in Probabilistic Session Types](https://arxiv.org/abs/2509.16228)
*Paula Blechschmidt*

Main category: cs.LO

TL;DR: 本文提出基于精化子类型的多方会话类型理论，扩展了MPST以支持更灵活的组合与验证，并在概率分布式通信场景下实现了强表达力和安全性。


<details>
  <summary>Details</summary>
Motivation: 随着分布式协议复杂度的提升，对协议行为进行可扩展验证的重要性增加。传统多方会话类型（MPST）虽然能确保安全和无死锁通信，但缺乏足够的模块化和组合性，因此作者提出基于精化的子类型方法，实现协议验证的模块化和组合化。

Method: 提出并扩展了经典MPST的子类型概念，引入了概率混合选择多方会话π演算，设计了新的灵活子类型系统，使得一个接口可由多个通道精化替换，并基于混合选择多方会话类型（MCMP）以增强通信选择灵活性。通过理论证明子类型系统的正确性，包括主题归约、无错误和无死锁等性质。

Result: 提出的子类型系统非常灵活和具有表达力，任意一组类型正确的通道都可作为精化对应单一通道接口。系统证明了概率混合选择多方会话系统的正确性，确保类型正确的进程具备良好行为（无死锁、无错误）。

Conclusion: 子类型理论具备更强的精化与组合验证潜力，可支持更高表达性和模块化的概率分布式通信建模，提升了多方协议可验证性和可扩展性。

Abstract: Multiparty session types (MPST) are a robust typing framework that ensures
safe and deadlock-free communication within distributed protocols. As these
protocols grow in complexity, compositional modelling becomes increasingly
important to scalably verify their behaviour. Therefore, we propose using a
refinement-based subtyping approach to facilitate the modularity needed for
compositional verification. Subtyping in classic MPST systems inherently
represents a notion of refinement: A larger type may be safely substituted by a
smaller, refined type. The aim of this thesis is to significantly extend this
concept and discover just how flexible and expressive subtyping relations can
be. We present a probabilistic extension for MPST, the probabilistic mixed
choice multiparty session pi-calculus, with a novel, flexible subtyping system
which allows one channel (the interface) to be substituted by several channels
(the refinement). Our subtyping is remarkably expressive; any selection of
well-typed channels as the refinement has a corresponding interface in a single
channel type. To facilitate this generality, we base our system on a powerful
variant of MPST, mixed choice multiparty session types (MCMP), which offers
greater flexibility in communication choices. We establish soundness of the
probabilistic mixed choice multiparty session system through several key
results. In particular, we prove subject reduction, error-freedom and
deadlock-freedom, ensuring that well-typed processes are well-behaved. This
work demonstrates subtyping to possess great previously untapped potential for
stepwise refinement and compositional verification. The presented framework
enables highly expressive, compositional, and verifiable modelling of
probabilistic distributed communication.

</details>


### [25] [parSAT: Parallel Solving of Floating-Point Satisfiability](https://arxiv.org/abs/2509.16237)
*Markus Krahl,Matthias Güdemann,Stefan Wallentowitz*

Main category: cs.LO

TL;DR: 本文针对SMT浮点运算求解的局限，提出利用全局优化和多核并行的组合式半决策方案，以提升浮点算术约束求解能力，在实际基准测试中展现出补充传统方法的潜力。


<details>
  <summary>Details</summary>
Motivation: 目前的SMT求解器在处理非线性算术问题，特别是包含浮点运算时存在局限，这对需要高度准确和可靠的浮点计算的安全关键型应用是重大挑战。

Method: 提出了一种针对浮点计算的可满足性问题的新表述，结合全局优化方法与多核CPU上的并行执行，构建了基于组合式的半决策过程来专门处理浮点算术约束。

Result: 通过在多种基准测试上的评估，证明了该方法可以有效补充传统技术，在浮点约束求解方面展现出良好潜力。

Conclusion: 这种利用并行性和组合式优化的新方法，为安全关键型应用中的浮点约束问题提供了具有实用性的解决思路，并能够与现有方法互补，提高求解的效率和适用范围。

Abstract: Satisfiability-based verification techniques, leveraging modern Boolean
satisfiability (SAT) and Satisfiability Modulo Theories (SMT) solvers, have
demonstrated efficacy in addressing practical problem instances within program
analysis. However, current SMT solver implementations often encounter
limitations when addressing non-linear arithmetic problems, particularly those
involving floating point (FP) operations. This poses a significant challenge
for safety critical applications, where accurate and reliable calculations
based on FP numbers and elementary mathematical functions are essential.
  This paper shows how an alternative formulation of the satisfiability problem
for FP calculations allows for exploiting parallelism for FP constraint
solving. By combining global optimization approaches with parallel execution on
modern multi-core CPUs, we construct a portfolio-based semi-decision procedure
specifically tailored to handle FP arithmetic. We demonstrate the potential of
this approach to complement conventional methods through the evaluation of
various benchmarks.

</details>


### [26] [Gödel Mirror: A Formal System For Contradiction-Driven Recursion](https://arxiv.org/abs/2509.16239)
*Jhet Chan*

Main category: cs.LO

TL;DR: 作者提出了G"odel Mirror —— 一个在Lean 4中实现的形式系统，可以将矛盾当作递归结构演化的控制信号，自洽地吸收并转化悖论，为智能体处理内部矛盾提供新型计算基础。


<details>
  <summary>Details</summary>
Motivation: 现有形式系统普遍强调规范化，难以有效处理自指与悖论。作者希望通过构建能系统处理并吸收矛盾的新型符号系统，从而支持更复杂的推理与智能体。

Method: 在Lean 4中形式化定义了G"odel Mirror，并对其操作语义进行了严格机械化验证。通过非终止循环机制，系统将悖论转换为结构递归演化过程。

Result: 实现了一个可验证的最小形式架构，在其中悖论不会导致系统崩溃或爆炸，而是生成新的结构，使系统具备了吸收和转化矛盾的能力。

Conclusion: 该系统成功避免了传统逻辑爆炸，对自指悖论进行了封装和结构化处理，为能够处理内部矛盾的智能体提供了理论基础。

Abstract: We introduce the G\"odel Mirror, a formal system defined in Lean 4 that
treats contradiction as a control signal for recursive structural evolution.
  Inspired by G\"odelian self-reference, our system's operational semantics
encode symbolic paradoxes as deterministic transitions. Unlike systems designed
to guarantee normalization, the G\"odel Mirror is a minimal and verifiable
architecture that leverages a controlled, non-terminating loop as a productive
feature.
  Our Lean 4 mechanization proves that self-referential paradoxes are
deterministically encapsulated and resolved into new structures without leading
to logical explosion, yielding a paraconsistent inference loop: Paradox ->
Encapsulate -> Reenter -> Node
  We argue that this calculus opens a new class of symbolic systems in which
contradiction is metabolized into structure, providing a formal basis for
agents capable of resolving internal inconsistencies.

</details>


### [27] [Equivalence of Halting Problem to Convergence of Power Series](https://arxiv.org/abs/2509.16270)
*Antonio Joaquim Fernandes*

Main category: cs.LO

TL;DR: 本文发现停机问题与幂级数收敛问题等价，有助于将计算理论问题转化到数学分析领域，为理论研究开启新方向。


<details>
  <summary>Details</summary>
Motivation: 在可计算理论中，停机问题是基本且难以解决的问题。动力来自于寻找停机问题与其它数学领域之间的关系，希望借助分析的方法为可计算性理论带来新视角。

Method: 作者通过建立理论对应，将停机问题的判定转化为幂级数收敛性的判定，利用数学分析的方法研究计算问题。

Result: 作者证明了停机问题与幂级数收敛性在某种严格意义下等价。这种等价性桥接了计算理论与数学分析。

Conclusion: 计算理论中的停机问题与数学分析中的幂级数收敛问题存在深刻的等价关系，为理解计算和分析之间的联系提供了新的理论框架。

Abstract: This paper establishes an equivalence between the halting problem in
computability theory and the convergence of power series in mathematical
analysis.

</details>


### [28] [Adhesive category theory for graph rewriting in Rocq](https://arxiv.org/abs/2509.17392)
*Samuel Arsac,Russ Harmer,Damien Pous*

Main category: cs.LO

TL;DR: 本文设计并实现了一个胶粘范畴的Rocq库，利用HB工具搭建范畴和态射两层分级体系，覆盖基本范畴概念和胶粘范畴专用结果。通过该库形式化了两个重要图重写定理并提供多种实例，展示了层级化范畴理论工具的有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 为将胶粘范畴（adhesive categories）相关的理论和结果进行形式化，作者设计了一个Rocq库，利用HB（Hierarchy Builder）工具构建了分层结构，旨在提升范畴和重写领域的自动化程度及实用性。

Method: 基于HB工具，作者构建了两个分层体系：一是范畴的层级，包括通常范畴、胶粘范畴及其弱化版本；二是态射层级，包括同构、单态射、正则单态射等。每一层都配有接口便于实例化。库同时涵盖基本范畴概念以及胶粘范畴的特殊结果，并在实现中注重接口设计与实例化灵活性。

Result: 利用该库，作者成功形式化了范畴图重写理论中的两个核心定理：Church-Rosser定理和并发定理。此外，库提供了类型范畴、有限类型范畴、简单图范畴、预型范畴等丰富实例，并详述了具体实现选择和HB工具的使用体验。

Conclusion: 作者构建的Rocq库能够系统性地形式化胶粘范畴领域的关键定理及相关结构，为范畴理论自动化和复用打下了基础。该工作展示了层级化抽象和接口设计的可行性，并推动了胶粘范畴与图重写理论的可计算性发展。

Abstract: We design a Rocq library about adhesive categories, using Hierarchy Builder
(HB). It is built around two hierarchies. The first is for categories, with
usual categories at the bottom and adhesive categories at the top, with weaker
variants of adhesive categories in between. The second is for morphisms
(notably isomorphisms, monomorphisms and regular monomorphisms). Each level of
these hierarchies is equipped with several interfaces to define instances. We
cover basic categorical concepts such as pullbacks and equalizers, as well as
results specific to adhesive categories. Using this library, we formalize two
central theorems of categorical graph rewriting theory: the Church-Rosser
theorem and the concurrency theorem. We provide several instances, including
the category of types, the category of finite types, the category of simple
graphs and categories of presheaves. We detail the implementation choices we
made and report on the usage of HB for this formalization work.

</details>


### [29] [The Proof-Theoretic Origin of Double Negation Introduction & Elimination](https://arxiv.org/abs/2509.17623)
*Khashayar Irani*

Main category: cs.LO

TL;DR: 该论文从证明理论角度剖析了经典逻辑中的双重否定规则，指出它不仅源自反证法，还保障了逻辑体系的稳定与规范化，并非简单冗余。


<details>
  <summary>Details</summary>
Motivation: 深入探究双重否定（引入和消除）在经典逻辑中的基础，澄清其与反证法以及证明理论平衡性的关系。

Method: 该论文通过研究序列演算和自然演绎两种证明体系，分析了双重否定规则的起源及其证明结构。

Result: 证明了双重否定规则具有和谐性（引入与消除的均衡）和规范化（推导能简化为标准形式），阐明了其在理论中的重要作用。

Conclusion: 双重否定引入和消除在经典逻辑中并非冗余，而是一种保障证明理论稳定性的机制，可以系统地整合反证法。

Abstract: This paper investigates the proof-theoretic foundations of double negation
introduction (DNI) and double negation elimination (DNE) in classical logic. By
examining both sequent calculus and natural deduction, it is shown that these
rules originate in reductio ad absurdum. The paper demonstrates that both rules
possess harmony, ensuring balance between introduction and elimination, and
normalisation, which guarantees that derivations reduce to canonical form
without detours. These features reveal double negation not as a redundancy, but
as a mechanism of proof-theoretic stability, securing the disciplined
integration of RAA into classical logic.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [30] [On LLM-Based Scientific Inductive Reasoning Beyond Equations](https://arxiv.org/abs/2509.16226)
*Brian S. Lin,Jiaxin Yuan,Zihan Zhou,Shouli Wang,Shuo Wang,Cunliang Kong,Qi Shi,Yuxuan Li,Liner Yang,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: 本文提出并系统评测了大语言模型在科学归纳推理（超越方程表达式场景）的新任务和基准，实验结果揭示模型在该领域尚存明显不足，需持续研究突破。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在类人推理能力上已表现突出，但如何让其在全新环境中通过少量案例学习底层规律并应用，这一归纳推理能力仍未充分解决。尤其在超越显式数学方程的推理场景，相关研究很少结合具体实例。

Method: 提出了一个名为“基于大语言模型的科学归纳推理超越方程”的新任务，并设计了专门的评测基准SIRBench-V1，用以评估大语言模型在科学领域的归纳推理能力。

Result: 实验表明，现有的大语言模型在该科学归纳推理任务上表现不佳，仍然面临巨大挑战。

Conclusion: 当前的大语言模型在科学归纳推理（尤其非显式方程环境下）能力有限，亟需进一步改进。

Abstract: As large language models (LLMs) increasingly exhibit human-like capabilities,
a fundamental question emerges: How can we enable LLMs to learn the underlying
patterns from limited examples in entirely novel environments and apply them
effectively? This question is central to the ability of LLMs in inductive
reasoning. Existing research on LLM-based inductive reasoning can be broadly
categorized based on whether the underlying rules are expressible via explicit
mathematical equations. However, many recent studies in the beyond-equations
category have emphasized rule design without grounding them in specific
scenarios. Inspired by the parallels between inductive reasoning and human
scientific discovery, we propose the task of LLM-Based Scientific Inductive
Reasoning Beyond Equations and introduce a new benchmark, SIRBench-V1, to
evaluate the inductive reasoning abilities of LLMs in scientific settings. Our
experimental results show that current LLMs still struggle with this task,
underscoring its difficulty and the need for further advancement in this area.

</details>


### [31] [REAMS: Reasoning Enhanced Algorithm for Maths Solving](https://arxiv.org/abs/2509.16241)
*Eishkaran Singh,Tanav Singh Bajaj,Siddharth Nayak*

Main category: cs.CL

TL;DR: 针对复杂大学数学题，提出融合语言模型、零样本学习及程序合成的新方法，准确率提升至90.15%，领导业界水平。


<details>
  <summary>Details</summary>
Motivation: 目前AI在解决复杂大学数学问题（如MIT、哥伦比亚大学课程以及MATH数据集）上表现不佳，传统方法准确率有限，因此亟需更先进的解决方案。

Method: 提出一种基于语言模型的方法，结合零样本学习和数学推理，同时引入程序合成以降低对大规模训练数据的依赖，从而提高问题解决能力。

Result: 在上述复杂数学问题上达到90.15%的准确率，显著超过此前的81%基准水平。

Conclusion: 该方法大幅提升了AI自动化解决高级数学问题的能力，展示了先进AI方法在应对复杂课程和数据集方面的巨大潜力。

Abstract: The challenges of solving complex university-level mathematics problems,
particularly those from MIT, and Columbia University courses, and selected
tasks from the MATH dataset, remain a significant obstacle in the field of
artificial intelligence. Conventional methods have consistently fallen short in
this domain, highlighting the need for more advanced approaches. In this paper,
we introduce a language-based solution that leverages zero-shot learning and
mathematical reasoning to effectively solve, explain, and generate solutions
for these advanced math problems. By integrating program synthesis, our method
reduces reliance on large-scale training data while significantly improving
problem-solving accuracy. Our approach achieves an accuracy of 90.15%,
representing a substantial improvement over the previous benchmark of 81% and
setting a new standard in automated mathematical problem-solving. These
findings highlight the significant potential of advanced AI methodologies to
address and overcome the challenges presented by some of the most complex
mathematical courses and datasets.

</details>


### [32] [HausaMovieReview: A Benchmark Dataset for Sentiment Analysis in Low-Resource African Language](https://arxiv.org/abs/2509.16256)
*Asiya Ibrahim Zanga,Salisu Mamman Abdulrahman,Abubakar Ado,Abdulkadir Abubakar Bichi,Lukman Aliyu Jibril,Abdulmajid Babangida Umar,Alhassan Adamu,Shamsuddeen Hassan Muhammad,Bashir Salisu Abubakar*

Main category: cs.CL

TL;DR: 构建了Hausa影评情感数据集，实验证明决策树模型在低资源语境下优于BERT等深度学习模型，并提出经典模型作为有力基线。


<details>
  <summary>Details</summary>
Motivation: 针对低资源语言缺乏标注数据的问题，推进其NLP工具的开发。

Method: 构建并标注了包含5,000条Hausa和英哈混合YouTube评论的新数据集，并用该数据集对经典机器学习模型与微调的Transformer模型进行了对比实验。

Result: 决策树模型在准确率和F1分数上（分别为89.72%和89.60%）显著优于深度学习Transformer模型。

Conclusion: 精心特征工程的经典模型在低资源环境下可实现SOTA性能，为未来相关研究奠定了基础。

Abstract: The development of Natural Language Processing (NLP) tools for low-resource
languages is critically hindered by the scarcity of annotated datasets. This
paper addresses this fundamental challenge by introducing HausaMovieReview, a
novel benchmark dataset comprising 5,000 YouTube comments in Hausa and
code-switched English. The dataset was meticulously annotated by three
independent annotators, demonstrating a robust agreement with a Fleiss' Kappa
score of 0.85 between annotators. We used this dataset to conduct a comparative
analysis of classical models (Logistic Regression, Decision Tree, K-Nearest
Neighbors) and fine-tuned transformer models (BERT and RoBERTa). Our results
reveal a key finding: the Decision Tree classifier, with an accuracy and
F1-score 89.72% and 89.60% respectively, significantly outperformed the deep
learning models. Our findings also provide a robust baseline, demonstrating
that effective feature engineering can enable classical models to achieve
state-of-the-art performance in low-resource contexts, thereby laying a solid
foundation for future research.
  Keywords: Hausa, Kannywood, Low-Resource Languages, NLP, Sentiment Analysis

</details>


### [33] [Gender and Political Bias in Large Language Models: A Demonstration Platform](https://arxiv.org/abs/2509.16264)
*Wenjie Lin,Hange Liu,Xutao Mao,Yingying Zhuang,Jingwei Shi,Xudong Han,Tianyu Shi,Jinrui Yang*

Main category: cs.CL

TL;DR: 本论文推出一站式系统ParlAI Vote，实现欧洲议会辩论与表决数据、LLM性能和偏见分析的高度整合与可视化，对LLM在投票预测和群体分析中的偏见进行了揭示，方便研究者和公众低门槛参与政治AI分析。


<details>
  <summary>Details</summary>
Motivation: 当前，大型语言模型(LLM)在政治分析、投票预测等领域的应用日益广泛，但对模型在实际立法场景中的性能、偏见及其适用性的分析与可视化支持不足。缺乏一个集成式的平台，方便研究者、公众在真实立法数据基础上进行深入交互和分析。

Method: 提出了ParlAI Vote系统，将欧洲议会辩论及表决数据结构化，并整合了性别、年龄、国家、党派等多元人口统计信息。用户可交互式浏览辩论、演讲与表决结果，并与LLM模型预测结果进行对比，支持按人群细分分析错误分布。此外，系统可视化EuroParlVote基准任务中的性别分类和投票预测，并在统一界面下联通数据、模型和可视化工具，便于实验复现，行为审计和反事实推演。

Result: 开发的ParlAI Vote平台有效揭示了最前沿LLM在政治投票相关任务中的系统性性能偏见，支持用户探索、比较模型在不同族群上的表现，有助于量化和审视现有模型的优劣和局限。该系统显著降低了政治分析相关研究与教育实践的门槛，为社会大众与学界深入理解立法决策机制和AI参与其中提供了便利。

Conclusion: ParlAI Vote作为集数据、模型与可视化分析于一体的开放平台，不仅凸显了当前LLM在立法数据分析中的优势和潜在偏见，也为政策研究、教育和公众参与立法决策过程搭建了桥梁，为未来相关领域研究和AI模型改进提供了支持。

Abstract: We present ParlAI Vote, an interactive system for exploring European
Parliament debates and votes, and for testing LLMs on vote prediction and bias
analysis. This platform connects debate topics, speeches, and roll-call
outcomes, and includes rich demographic data such as gender, age, country, and
political group. Users can browse debates, inspect linked speeches, compare
real voting outcomes with predictions from frontier LLMs, and view error
breakdowns by demographic group. Visualizing the EuroParlVote benchmark and its
core tasks of gender classification and vote prediction, ParlAI Vote highlights
systematic performance bias in state-of-the-art LLMs. The system unifies data,
models, and visual analytics in a single interface, lowering the barrier for
reproducing findings, auditing behavior, and running counterfactual scenarios.
It supports research, education, and public engagement with legislative
decision-making, while making clear both the strengths and the limitations of
current LLMs in political analysis.

</details>


### [34] [Language Modeling with Learned Meta-Tokens](https://arxiv.org/abs/2509.16278)
*Alok N. Shah,Khush Gupta,Keshav Ramji,Pratik Chaudhari*

Main category: cs.CL

TL;DR: 本文提出在Transformer语言模型预训练阶段加入meta-tokens和meta-attention机制，仅用较少的数据即可极大提升长文本依赖能力和泛化性能，实验和理论分析均验证了该机制的有效性，并能支持超过原生窗口长度的推理操作。


<details>
  <summary>Details</summary>
Motivation: 当前Transformer语言模型在多任务泛化上取得了巨大成功，但其在捕捉长距离依赖方面往往表现不足。因此，作者希望提升模型对长文本依赖的建模能力。

Method: 作者提出了在预训练阶段引入meta-tokens（元标记），并设计了专门的meta-attention机制，引导模型在生成内容时利用这些标记。具体做法是在GPT-2架构基础上，修改模型结构以同时具备因果多头注意力和meta-attention机制，然后在数据集规模小于100B的情况下进行预训练和一系列合成任务的测试。

Result: 预训练过程中引入meta-tokens和meta-attention机制后，在少量训练数据下模型在任务测试中表现优秀。实验显示，meta-tokens能有效提升位置编码，使其像内容型地标一样压缩和缓存上下文信息。推理阶段，meta-tokens能指示相关上下文，实现上下文长度泛化，性能提升显著。同时，作者通过模型内部可视化和信息论分析对压缩质量进行了验证。

Conclusion: 在语言模型预训练阶段加入meta-tokens及meta-attention机制，能以更高的数据效率，显著增强模型对长距离依赖的捕捉能力与长文本泛化性能，并为理解模型的长距行为提供了新视角。

Abstract: While modern Transformer-based language models (LMs) have achieved major
success in multi-task generalization, they often struggle to capture long-range
dependencies within their context window. This work introduces a novel approach
using meta-tokens, special tokens injected during pre-training, along with a
dedicated meta-attention mechanism to guide LMs to use these tokens. We
pre-train a language model with a modified GPT-2 architecture equipped with
meta-attention in addition to causal multi-head attention, and study the impact
of these tokens on a suite of synthetic tasks. We find that data-efficient
language model pre-training on fewer than 100B tokens utilizing meta-tokens and
our meta-attention mechanism achieves strong performance on these tasks after
fine-tuning. We suggest that these gains arise due to the meta-tokens
sharpening the positional encoding. This enables them to operate as trainable,
content-based landmarks, implicitly compressing preceding context and "caching"
it in the meta-token. At inference-time, the meta-token points to relevant
context, facilitating length generalization up to 2$\times$ its context window,
even after extension with YaRN. We provide further evidence of these behaviors
by visualizing model internals to study the residual stream, and assessing the
compression quality by information-theoretic analysis on the rate-distortion
tradeoff. Our findings suggest that pre-training LMs with meta-tokens offers a
simple, data-efficient method to enhance long-context language modeling
performance, while introducing new insights into the nature of their behavior
towards length generalization.

</details>


### [35] [Overhearing LLM Agents: A Survey, Taxonomy, and Roadmap](https://arxiv.org/abs/2509.16325)
*Andrew Zhu,Chris Callison-Burch*

Main category: cs.CL

TL;DR: 本文首次系统探讨了“旁听式”LLM代理的概念、类型与开发实践，提出相关分类法及研究展望，为未来的静默型智能助手提供理论与方法指导。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLM）助手多依赖聊天界面直接与用户交互，但实际上，在许多协作场景下，如果AI助手能像“旁听者”一样默默关注并在关键时刻提供辅助，会更加高效且减少干扰，因此需要探索这种新型的人机交互方式。

Method: 本文首先对“旁听式”LLM代理进行了首次专门分析，提出了其交互与任务的分类法，并借助对现有相关研究及HCI探索性研究的梳理，制定了开发此类系统的最佳实践建议。

Result: 文章建立了针对“旁听式”代理的交互类型及任务的系统分类结构，总结了开发最佳实践，并指出了该领域尚未解决的关键问题及未来研究机会。

Conclusion: 旁听式LLM代理作为一种新的人机交互范式，有潜力在多种实际场景中减少对用户的干扰并提升协作效率，未来研究将进一步完善其理论基础和实际应用指引。

Abstract: Imagine AI assistants that enhance conversations without interrupting them:
quietly providing relevant information during a medical consultation,
seamlessly preparing materials as teachers discuss lesson plans, or
unobtrusively scheduling meetings as colleagues debate calendars. While modern
conversational LLM agents directly assist human users with tasks through a chat
interface, we study this alternative paradigm for interacting with LLM agents,
which we call "overhearing agents." Rather than demanding the user's attention,
overhearing agents continuously monitor ambient activity and intervene only
when they can provide contextual assistance. In this paper, we present the
first analysis of overhearing LLM agents as a distinct paradigm in human-AI
interaction and establish a taxonomy of overhearing agent interactions and
tasks grounded in a survey of works on prior LLM-powered agents and exploratory
HCI studies. Based on this taxonomy, we create a list of best practices for
researchers and developers building overhearing agent systems. Finally, we
outline the remaining research gaps and reveal opportunities for future
research in the overhearing paradigm.

</details>


### [36] [HARE: an entity and relation centric evaluation framework for histopathology reports](https://arxiv.org/abs/2509.16326)
*Yunsoo Kim,Michal W. S. Ong,Alex Shavick,Honghan Wu,Adam P. Levine*

Main category: cs.CL

TL;DR: 本文提出HARE框架用于组织病理学报告自动生成质量评估，整合了标注数据集、NER模型、RE模型及新型评估指标，在相关性与精度方面均优于现有方法，对于推动临床自动报告生成具有重要价值。


<details>
  <summary>Details</summary>
Motivation: 在医学自动文本生成领域，如何准确评估生成报告的临床质量始终是个难题，尤其在像组织病理学等领域缺乏专属评估指标的情况下更为突出。现有的通用和跨领域测评方法难以满足实际临床需求。

Method: 作者提出了HARE（Histopathology Automated Report Evaluation）框架，包含数据集标注、命名实体识别（NER）、关系抽取（RE）模型及新型评估指标。具体包括对813份去标识化临床组织病理报告和652份TCGA组织病理报告进行实体与关系的领域标注，使用针对医学领域微调后的GatorTronS语言模型开发NER与RE系统。最终利用新指标评价自动生成报告与专家参考报告的一致性。

Result: HARE-NER和HARE-RE取得了F1分数0.915，为所有测试模型中最高。HARE指标在与传统以及放射学领域专用自动评分指标（如ROUGE、Meteor、RadGraph-XL、GREEN等）对比中，具有与专家评分的最高相关性和最佳回归性能。

Conclusion: HARE框架显著提升组织病理学自动生成报告的评估精度，为这一领域的质量增强提供了新工具体系。相关模型和数据集已开源，有助于未来相关技术的进一步发展。

Abstract: Medical domain automated text generation is an active area of research and
development; however, evaluating the clinical quality of generated reports
remains a challenge, especially in instances where domain-specific metrics are
lacking, e.g. histopathology. We propose HARE (Histopathology Automated Report
Evaluation), a novel entity and relation centric framework, composed of a
benchmark dataset, a named entity recognition (NER) model, a relation
extraction (RE) model, and a novel metric, which prioritizes clinically
relevant content by aligning critical histopathology entities and relations
between reference and generated reports. To develop the HARE benchmark, we
annotated 813 de-identified clinical diagnostic histopathology reports and 652
histopathology reports from The Cancer Genome Atlas (TCGA) with domain-specific
entities and relations. We fine-tuned GatorTronS, a domain-adapted language
model to develop HARE-NER and HARE-RE which achieved the highest overall
F1-score (0.915) among the tested models. The proposed HARE metric outperformed
traditional metrics including ROUGE and Meteor, as well as radiology metrics
such as RadGraph-XL, with the highest correlation and the best regression to
expert evaluations (higher than the second best method, GREEN, a large language
model based radiology report evaluator, by Pearson $r = 0.168$, Spearman $\rho
= 0.161$, Kendall $\tau = 0.123$, $R^2 = 0.176$, $RMSE = 0.018$). We release
HARE, datasets, and the models at https://github.com/knowlab/HARE to foster
advancements in histopathology report generation, providing a robust framework
for improving the quality of reports.

</details>


### [37] [RephQA: Evaluating Readability of Large Language Models in Public Health Question Answering](https://arxiv.org/abs/2509.16360)
*Weikang Qiu,Tinglin Huang,Ryan Rullo,Yucheng Kuang,Ali Maatouk,S. Raquel Ramos,Rex Ying*

Main category: cs.CL

TL;DR: 本文专注于大型语言模型在公共卫生问答中的可读性问题，提出了RephQA基准并开展大规模评测。结果显示，大部分模型沟通效果不佳。token-adapted GRPO方法显著提升了回复的易读性，对实际健康问答有积极推动作用。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决大语言模型（LLM）在公共卫生问题回答时的可读性不足，尤其是面向无医学背景人群的简单明了回答。现有研究多聚焦于提升准确性和推理能力，忽视了高效沟通的需求。

Method: 作者提出了RephQA基准，评估LLM在公共卫生问答中的可读性。该基准包含533个专家审核的问答对，涉及13个主题，并引入多项选择题任务与两个可读性指标（Flesch-Kincaid分级和专业分）。此外，评估了25个LLM的表现，并对四种提升策略进行了实验：标准prompt、链式思维prompt、Group Relative Policy Optimization（GRPO）及token-adapted GRPO。

Result: 多数LLM在可读性标准上表现不佳，显示出推理与有效沟通之间存在明显鸿沟。token-adapted GRPO方法效果最佳，显著提升了模型的可读性和实用性。

Conclusion: 当前LLM在公共卫生问答中依然存在可读性不足问题，亟需从准确性拓展到提升沟通能力。token-adapted GRPO是一种有效提升可读性的策略，为构建更实用、用户友好的公共卫生智能体迈出了关键一步。

Abstract: Large Language Models (LLMs) hold promise in addressing complex medical
problems. However, while most prior studies focus on improving accuracy and
reasoning abilities, a significant bottleneck in developing effective
healthcare agents lies in the readability of LLM-generated responses,
specifically, their ability to answer public health problems clearly and simply
to people without medical backgrounds. In this work, we introduce RephQA, a
benchmark for evaluating the readability of LLMs in public health question
answering (QA). It contains 533 expert-reviewed QA pairs from 27 sources across
13 topics, and includes a proxy multiple-choice task to assess informativeness,
along with two readability metrics: Flesch-Kincaid grade level and professional
score. Evaluation of 25 LLMs reveals that most fail to meet readability
standards, highlighting a gap between reasoning and effective communication. To
address this, we explore four readability-enhancing strategies-standard
prompting, chain-of-thought prompting, Group Relative Policy Optimization
(GRPO), and a token-adapted variant. Token-adapted GRPO achieves the best
results, advancing the development of more practical and user-friendly public
health agents. These results represent a step toward building more practical
agents for public health.

</details>


### [38] [Whisper-UT: A Unified Translation Framework for Speech and Text](https://arxiv.org/abs/2509.16375)
*Cihan Xiao,Matthew Wiesner,Debashish Chakraborty,Reno Kriz,Keith Cunningham,Kenton Murray,Kevin Duh,Luis Tavarez-Arce,Paul McNamee,Sanjeev Khudanpur*

Main category: cs.CL

TL;DR: 提出了一个统一高效的多模态翻译适配框架Whisper-UT，通过轻量适配器和双阶段解码，有效提升了语音翻译等多模态任务性能，无需大量并行数据，方法灵活通用。


<details>
  <summary>Details</summary>
Motivation: 在语音和文本领域，encoder-decoder模型表现优异，但如何高效地适应多种单/多模态任务仍面临挑战。

Method: 提出了Whisper-UT框架，利用轻量级适配器，实现多任务（特别是多模态机翻任务）间的无缝适配。通过将ASR假设或真实转录作为提示，采用双阶段解码策略同时处理语音和文本输入。

Result: 不需要三方并行数据，通过跨模态与跨任务微调提升了多模态翻译系统的性能，验证了方法的灵活性、高效性与广泛适应性。

Conclusion: Whisper-UT为多模态翻译任务提供了统一且高效的解决思路，能有效提升语音翻译等任务的表现，且适用于各种多任务encoder-decoder模型。

Abstract: Encoder-decoder models have achieved remarkable success in speech and text
tasks, yet efficiently adapting these models to diverse uni/multi-modal
scenarios remains an open challenge. In this paper, we propose Whisper-UT, a
unified and efficient framework that leverages lightweight adapters to enable
seamless adaptation across tasks, including a multi-modal machine translation
(MMT) task that explicitly conditions translation on both speech and source
language text inputs. By incorporating ASR hypotheses or ground-truth
transcripts as prompts, this approach not only enables the system to process
both modalities simultaneously but also enhances speech translation (ST)
performance through a 2-stage decoding strategy. We demonstrate our methods
using the Whisper model, though in principle they are general and could be
applied to similar multitask models. We highlight the effectiveness of
cross-modal and cross-task fine-tuning, which improves performance without
requiring 3-way parallel data. Our results underscore the flexibility,
efficiency, and general applicability of the proposed framework for multi-modal
translation.

</details>


### [39] [Evaluating Behavioral Alignment in Conflict Dialogue: A Multi-Dimensional Comparison of LLM Agents and Humans](https://arxiv.org/abs/2509.16394)
*Deuksin Kwon,Kaleen Shrestha,Bin Han,Elena Hayoung Lee,Gale Lucas*

Main category: cs.CL

TL;DR: 本研究评估了不同大语言模型在模拟冲突协商对话时与人类行为的对齐程度。GPT-4.1在语言与情感模仿上表现较好，Claude在策略行为上更接近人类，但整体对齐尚有不足，提示当前LLMs在复杂社交任务中仍有限制。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在社会复杂、互动驱动的任务中的应用日益广泛，但其在情感和策略复杂环境下是否能模拟人类行为尚未充分研究。本文旨在探索LLMs在冲突解决对话中的行为对齐能力。

Method: 采用与人类五大性格特征匹配的人格设定对LLMs进行引导，模拟多回合带有协商特点的冲突对话，并从语言风格、情感表达（如愤怒动态）和策略行为三个维度评估模型与人类的对齐程度。

Result: GPT-4.1在语言风格和情感动态上与人类最为接近，而Claude-3.7-Sonnet在策略行为模拟方面表现最佳。但整体来看，不同模型虽有优点，但仍与人类在行为对齐方面存在较大差距。

Conclusion: 本文建立了LLMs与人类在社会复杂交互中的对齐基准，发现人格设定对对话建模有一定提升，但在高度复杂的人类对话中，模型仍有局限。

Abstract: Large Language Models (LLMs) are increasingly deployed in socially complex,
interaction-driven tasks, yet their ability to mirror human behavior in
emotionally and strategically complex contexts remains underexplored. This
study assesses the behavioral alignment of personality-prompted LLMs in
adversarial dispute resolution by simulating multi-turn conflict dialogues that
incorporate negotiation. Each LLM is guided by a matched Five-Factor
personality profile to control for individual variation and enhance realism. We
evaluate alignment across three dimensions: linguistic style, emotional
expression (e.g., anger dynamics), and strategic behavior. GPT-4.1 achieves the
closest alignment with humans in linguistic style and emotional dynamics, while
Claude-3.7-Sonnet best reflects strategic behavior. Nonetheless, substantial
alignment gaps persist. Our findings establish a benchmark for alignment
between LLMs and humans in socially complex interactions, underscoring both the
promise and the limitations of personality conditioning in dialogue modeling.

</details>


### [40] ['Rich Dad, Poor Lad': How do Large Language Models Contextualize Socioeconomic Factors in College Admission ?](https://arxiv.org/abs/2509.16400)
*Huy Nghiem,Phuong-Anh Nguyen-Le,John Prindle,Rachel Rudinger,Hal Daumé III*

Main category: cs.CL

TL;DR: 该论文用双重过程框架大规模审计了LLMs在高校招生敏感决策中的行为，发现模型普遍偏好低社会经济地位申请人，且解释模式会进一步增强这种倾向；最后提出DPAF框架用于敏感应用下模型审计。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）在涉及社会敏感决策时的推理机制尚未被深入研究。鉴于LLMs被广泛应用于诸如高等院校招生等关系重大的领域，作者希望揭示其在面对申请人社会经济地位（SES）时的决策偏好及原因。

Method: 作者设计了一个基于认知科学双重过程理论的框架，使用30,000个基于真实相关性的合成申请人数据集，对4个开源LLM（Qwen 2, Mistral v0.3, Gemma 2, Llama 3.1）在两种决策模式下（System 1：快速决策，System 2：慢速解释决策）进行了大规模审计，总共生成了500万条提示语进行实验。

Result: 实验发现，无论控制学术表现与否，LLMs普遍倾向于优先录取低SES申请人。System 2模式下，这一倾向被放大，因为模型会在解释中将SES作为补偿性的决策理由。这表明LLMs在处理敏感决策时既有潜力又具不稳定性。

Conclusion: LLMs在社会敏感场景下的决策行为表现出系统性偏好，且该偏好受解释机制影响较大。为进一步探究LLMs的推理过程，作者提出了DPAF（双重过程审计框架）以审视其推理行为。

Abstract: Large Language Models (LLMs) are increasingly involved in high-stakes
domains, yet how they reason about socially sensitive decisions remains
underexplored. We present a large-scale audit of LLMs' treatment of
socioeconomic status (SES) in college admissions decisions using a novel
dual-process framework inspired by cognitive science. Leveraging a synthetic
dataset of 30,000 applicant profiles grounded in real-world correlations, we
prompt 4 open-source LLMs (Qwen 2, Mistral v0.3, Gemma 2, Llama 3.1) under 2
modes: a fast, decision-only setup (System 1) and a slower, explanation-based
setup (System 2). Results from 5 million prompts reveal that LLMs consistently
favor low-SES applicants -- even when controlling for academic performance --
and that System 2 amplifies this tendency by explicitly invoking SES as
compensatory justification, highlighting both their potential and volatility as
decision-makers. We then propose DPAF, a dual-process audit framework to probe
LLMs' reasoning behaviors in sensitive applications.

</details>


### [41] [Pico: A Modular Framework for Hypothesis-Driven Small Language Model Research](https://arxiv.org/abs/2509.16413)
*Richard Diehl Martinez,David Demitri Africa,Yuval Weiss,Suchir Salhan,Ryan Daniels,Paula Buttery*

Main category: cs.CL

TL;DR: Pico框架帮助研究者系统、科学地设计和分析小型/中型语言模型，提供可复现、开放基线模型，推动该领域规范化发展。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型依靠规模提升效果，但小模型受限于参数预算，每个设计决策都至关重要。当前缺乏系统的方法来科学测试和优化小模型的架构与训练选择。

Method: 提出了Pico框架——包括两个库，可对模型架构和训练方法进行模块化调整，并可直接观察变化对性能的影响。同时，开源标准化训练的基线模型以支持社区复现。

Result: 开发了Pico框架以及pico-decoder基线模型，并通过案例验证了框架对小模型迭代研发的支持能力。

Conclusion: Pico为小型和中型语言模型的设计和分析提供了系统化、可重复且开放的研究工具，有助于推动更科学化的小模型开发。

Abstract: Building language models (LMs), especially small and medium ones, remains
more art than science. While large LMs often improve by sheer scale, it is
still unclear why many design choices work. For small LMs, this uncertainty is
more limiting: tight parameter budgets make each decision critical, yet
researchers still lack systematic, scientific ways to test and refine new
ideas.
  We introduce Pico, a lightweight, modular framework that enables systematic,
hypothesis-driven research for small and medium-scale language model
development. Pico consists of two libraries that together provide a practical
sandbox where researchers can make targeted changes to a model's architecture
or training procedures and directly observe their effects on the model's
behavior. To support reproducible experimentation, we also release a suite of
baseline models, pico-decoder, trained under standardized conditions and
open-sourced for the community. Case studies highlight how Pico can support
iterative small LM design and analysis.

</details>


### [42] [Evaluating CxG Generalisation in LLMs via Construction-Based NLI Fine Tuning](https://arxiv.org/abs/2509.16422)
*Tom Mackintosh,Harish Tayyar Madabushi,Claire Bonial*

Main category: cs.CL

TL;DR: 论文评估LLM对结构语法中复杂形式-意义映射的学习能力，提出新基准，显示LLM在抽象结构方面存在差距，微调有帮助但不能完全解决。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型（LLM）能否学习深层次形式-意义映射，尤其是在结构语法框架下。

Method: 提出了ConTest-NLI基准，包括80,000个句子，涵盖从高度词汇化到高度模式化的八种英语结构。数据通过模板生成和模型参与筛选，结合人工验证，确保挑战性和标签可靠性。

Result: 零样本测试显示主流LLM在自然数据和对抗性数据上的准确率分别为88%和64%，下降了24%。结构化模式最难应对。对部分数据微调可提升9%，但抽象理解仍存差距。

Conclusion: 现有LLM在抽象结构模式学习方面存在明显不足，ConTest-NLI能够推动结构语法导向学习的评估研究。

Abstract: We probe large language models' ability to learn deep form-meaning mappings
as defined by construction grammars. We introduce the ConTest-NLI benchmark of
80k sentences covering eight English constructions from highly lexicalized to
highly schematic. Our pipeline generates diverse synthetic NLI triples via
templating and the application of a model-in-the-loop filter. This provides
aspects of human validation to ensure challenge and label reliability.
Zero-shot tests on leading LLMs reveal a 24% drop in accuracy between
naturalistic (88%) and adversarial data (64%), with schematic patterns proving
hardest. Fine-tuning on a subset of ConTest-NLI yields up to 9% improvement,
yet our results highlight persistent abstraction gaps in current LLMs and offer
a scalable framework for evaluating construction-informed learning.

</details>


### [43] [PersonaMatrix: A Recipe for Persona-Aware Evaluation of Legal Summarization](https://arxiv.org/abs/2509.16449)
*Tsz Fung Pang,Maryam Berijanian,Thomas Orth,Breanna Shi,Charlotte S. Alexander*

Main category: cs.CL

TL;DR: 本文提出PersonaMatrix框架，实现了对法律摘要多角色、多维度的评价，展示了不同用户需求下摘要效果的显著分歧，推动法律AI更好服务于专家与大众，相关资源公开可用。


<details>
  <summary>Details</summary>
Motivation: 现有法律文档自动摘要评估方法未能很好地兼顾不同用户（法律专家与大众）的多样需求，导致信息覆盖及可理解性受限，亟需开发既能满足专家专业需求又能方便大众使用的评估与工具体系。

Method: 设计了PersonaMatrix，即通过多角色维度对法律文档摘要进行多标准评价，并构建了受控维度变化的美国民权案件摘要数据集，涵盖深度、可达性及程序细节，提出了Diversity-Coverage Index (DCI)来度量差异化评价。

Result: PersonaMatrix和DCI揭示了不同用户视角下法律摘要的最优特性有显著差异，可促进生成系统在专业和大众层面做定制优化，代码和数据集已公开。

Conclusion: 提出了PersonaMatrix评估框架，可以根据6类不同用户（法律和非法律用户）的需求评价法律文档的摘要，提高法律知识的可达性。

Abstract: Legal documents are often long, dense, and difficult to comprehend, not only
for laypeople but also for legal experts. While automated document
summarization has great potential to improve access to legal knowledge,
prevailing task-based evaluators overlook divergent user and stakeholder needs.
Tool development is needed to encompass the technicality of a case summary for
a litigator yet be accessible for a self-help public researching for their
lawsuit. We introduce PersonaMatrix, a persona-by-criterion evaluation
framework that scores summaries through the lens of six personas, including
legal and non-legal users. We also introduce a controlled dimension-shifted
pilot dataset of U.S. civil rights case summaries that varies along depth,
accessibility, and procedural detail as well as Diversity-Coverage Index (DCI)
to expose divergent optima of legal summary between persona-aware and
persona-agnostic judges. This work enables refinement of legal AI summarization
systems for both expert and non-expert users, with the potential to increase
access to legal knowledge. The code base and data are publicly available in
GitHub.

</details>


### [44] [Implicit Behavioral Alignment of Language Agents in High-Stakes Crowd Simulations](https://arxiv.org/abs/2509.16457)
*Yunzhe Wang,Gale M. Lucas,Burcin Becerik-Gerber,Volkan Ustun*

Main category: cs.CL

TL;DR: 提出PEBA理论和PEvo优化算法，极大提高了生成型智能体在社会模拟中的行为真实性和泛化能力，是提升高风险社会仿真可信度的新方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型（LLM）的生成型智能体在社会模拟中应用广泛，但它们的行为经常与专家预期和现实数据不符，存在显著的行为真实性差距（Behavior-Realism Gap）。作者认为解决这一差距对于提高模拟的可信度和实用价值至关重要。

Method: 作者提出了Persona-Environment Behavioral Alignment（PEBA）理论框架，将行为真实性对齐建模为分布匹配问题，基于Lewin的行为方程：行为是个体和环境的函数。在此基础上，作者设计了PersonaEvolve（PEvo）算法，这是一个基于LLM的优化方法，通过迭代优化智能体的人设，使其在特定环境下的集体行为分布隐式地与专家基准对齐。

Result: 在作者自建的“校园枪击事件”高风险社会模拟任务中，PEvo方法使行为分布偏差平均减少84%（相比无调控情形），比显式指令基线提高34%。此外，经PEvo优化的人设还能泛化到新场景，展现出较强的适应性。

Conclusion: PEBA-PEvo方法显著提升了社会模拟中智能体行为的真实性和可靠性，为开发可信赖的LLM驱动社会模拟提供了系统性解决方案。该框架在高风险、需高度仿真的场景下，展现出巨大的应用潜力。

Abstract: Language-driven generative agents have enabled large-scale social simulations
with transformative uses, from interpersonal training to aiding global
policy-making. However, recent studies indicate that generative agent behaviors
often deviate from expert expectations and real-world data--a phenomenon we
term the Behavior-Realism Gap. To address this, we introduce a theoretical
framework called Persona-Environment Behavioral Alignment (PEBA), formulated as
a distribution matching problem grounded in Lewin's behavior equation stating
that behavior is a function of the person and their environment. Leveraging
PEBA, we propose PersonaEvolve (PEvo), an LLM-based optimization algorithm that
iteratively refines agent personas, implicitly aligning their collective
behaviors with realistic expert benchmarks within a specified environmental
context. We validate PEvo in an active shooter incident simulation we
developed, achieving an 84% average reduction in distributional divergence
compared to no steering and a 34% improvement over explicit instruction
baselines. Results also show PEvo-refined personas generalize to novel, related
simulation scenarios. Our method greatly enhances behavioral realism and
reliability in high-stakes social simulations. More broadly, the PEBA-PEvo
framework provides a principled approach to developing trustworthy LLM-driven
social simulations.

</details>


### [45] [Intrinsic Meets Extrinsic Fairness: Assessing the Downstream Impact of Bias Mitigation in Large Language Models](https://arxiv.org/abs/2509.16462)
*'Mina Arzaghi','Alireza Dehghanpour Farashah','Florian Carichon',' Golnoosh Farnadi'*

Main category: cs.CL

TL;DR: 本文系统比较了大语言模型在金融任务中的内在与外在偏见缓解方法，发现通过反学习缓解模型内部偏见，既能显著降低性别偏见，又能提升下游任务公平性，不影响准确率。建议关注和优先采用早期偏见缓解技术。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）存在社会经济偏见，这些偏见可能影响下游任务的公平性。虽然之前研究质疑了模型内部偏见是否真的影响下游任务公平性，但还缺乏系统的实证研究。本论文动机在于探究LLM内部偏见与下游公平性之间的关系，并寻找有效缓解偏见的方法。

Method: 论文提出了一个统一的评估框架，系统比较了两种缓解偏见的方法：一种是通过“概念反学习”来降低模型本身的内在偏见（intrinsic bias mitigation），另一种是利用反事实数据增强（counterfactual data augmentation，CDA）来缓解任务外在偏见（extrinsic bias mitigation）。本研究在真实的金融分类任务（如薪资预测、就业状态、信用评估）中，使用三个开源大语言模型，分别作为静态嵌入提取器和微调分类器，在不同模式下进行实验评估。

Result: 结果显示，通过反学习进行内在偏见缓解，可以将性别内在偏见降低高达94.9%。同时，在下游公平性指标（如人口统计均等性）上改善高达82%，且不会影响模型准确率。即，模型偏见缓解不仅显著降低了本身偏见，还提升了下游实际应用的公平性。

Conclusion: 提出的评估框架可以为实际偏见缓解方案提供指导，尤其强调在模型部署前进行偏见缓解的重要性。早期介入能够带来最大化的公平性收益，并为后续下游应用设定更公正的基础。

Abstract: Large Language Models (LLMs) exhibit socio-economic biases that can propagate
into downstream tasks. While prior studies have questioned whether intrinsic
bias in LLMs affects fairness at the downstream task level, this work
empirically investigates the connection. We present a unified evaluation
framework to compare intrinsic bias mitigation via concept unlearning with
extrinsic bias mitigation via counterfactual data augmentation (CDA). We
examine this relationship through real-world financial classification tasks,
including salary prediction, employment status, and creditworthiness
assessment. Using three open-source LLMs, we evaluate models both as frozen
embedding extractors and as fine-tuned classifiers. Our results show that
intrinsic bias mitigation through unlearning reduces intrinsic gender bias by
up to 94.9%, while also improving downstream task fairness metrics, such as
demographic parity by up to 82%, without compromising accuracy. Our framework
offers practical guidance on where mitigation efforts can be most effective and
highlights the importance of applying early-stage mitigation before downstream
deployment.

</details>


### [46] [Computational Analysis of Conversation Dynamics through Participant Responsivity](https://arxiv.org/abs/2509.16464)
*Margaret Hughes,Brandon Roy,Elinor Poole-Dayan,Deb Roy,Jad Kabbara*

Main category: cs.CL

TL;DR: 本文提出以“响应性”为核心的对话质量评价框架，通过语义与大语言模型方法量化发言间回应关系，并发展会话层面的质量指标，有助于自动、细致地分析各类对话的结构和互动质量。


<details>
  <summary>Details</summary>
Motivation: 以往研究聚焦于对话的有害性和极化，但对“积极、有建设性的对话”刻画和自动评价方法研究较少。故本研究意在填补这一空白，为对话质量建模提出新的方向和工具。

Method: 首先，定义“响应性”为后续发言对上一次发言的回应性。然后提出两种量化方法：一是基于语义相似度，二是利用大语言模型（LLMs）判断发言之间的关系。作者通过与人工标注的对话进行对比，以评估各方法的有效性。最后采用性能更优的LLM方法，进一步分析回应的实质性，并构建多种会话层面的衍生指标。

Result: 基于LLM的方法在“响应性”判别上优于语义相似度法，且新构建的会话级指标能够有效区分不同类别的对话，为对话质量分析和自动评价提供了新工具。

Conclusion: 作者提出了“响应性”作为评价对话质量的核心指标，并提出了一系列方法和指标，以量化和区分不同对话的结构和质量。实验证明这些指标能有效区分不同类型的对话。

Abstract: Growing literature explores toxicity and polarization in discourse, with
comparatively less work on characterizing what makes dialogue prosocial and
constructive. We explore conversational discourse and investigate a method for
characterizing its quality built upon the notion of ``responsivity'' -- whether
one person's conversational turn is responding to a preceding turn. We develop
and evaluate methods for quantifying responsivity -- first through semantic
similarity of speaker turns, and second by leveraging state-of-the-art large
language models (LLMs) to identify the relation between two speaker turns. We
evaluate both methods against a ground truth set of human-annotated
conversations. Furthermore, selecting the better performing LLM-based approach,
we characterize the nature of the response -- whether it responded to that
preceding turn in a substantive way or not.
  We view these responsivity links as a fundamental aspect of dialogue but note
that conversations can exhibit significantly different responsivity structures.
Accordingly, we then develop conversation-level derived metrics to address
various aspects of conversational discourse. We use these derived metrics to
explore other conversations and show that they support meaningful
characterizations and differentiations across a diverse collection of
conversations.

</details>


### [47] [The Oracle Has Spoken: A Multi-Aspect Evaluation of Dialogue in Pythia](https://arxiv.org/abs/2509.16487)
*Zixun Chen,Petr Babkin,Akshat Gupta,Gopala Anumanchipalli,Xiaomo Liu*

Main category: cs.CL

TL;DR: 研究系统分析了Pythia大模型在对话能力上的细粒度表现，发现有监督微调远比模型规模更能提升评估指标，但现有评估方法区分不同对话维度的能力有限，未来评估体系需改进以更好地反映模型对话能力的真实水平。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）对话能力被广泛认为是其核心特征之一，但其实很少有研究具体区分对话行为在后训练阶段出现的各个关键成分。因此，本研究致力于细分地评估和理解对话行为在模型中的表现和演化。

Method: 采用一套基于模型的全面度量体系，每项指标测量对话的不同细粒度方面，这些指标受到语言学理论的启发。评估预训练的Pythia模型在不同模型规模下，以及经过对话式数据集的有监督微调后，各类指标的表现如何变化。同时，对分数分布、指标相关性和模型生成回复中的词项频率进行进一步分析。

Result: 研究发现，对大多数指标来说，模型规模的直接影响较小，而有监督微调能迅速使得大部分指标分数趋于饱和（除了规模最小的模型）。此外，许多基于同一评估模型的指标表现出非常相似的趋势，这对这些指标在衡量特定对话维度时的可靠性提出了质疑。

Conclusion: 现有的模型评估指标在度量对话能力时可能存有局限，尤其当它们依赖于相同的评估模型时，可能无法区分各具体对话维度。这提示研究者需重新考量对话能力的评估方法，并进一步完善评估体系。

Abstract: Dialogue is one of the landmark abilities of large language models (LLMs).
Despite its ubiquity, few studies actually distinguish specific ingredients
underpinning dialogue behavior emerging during post-training. We employ a
comprehensive suite of model-based metrics, each targeting a distinct
fine-grained aspect of dialogue, motivated by linguistic theory. We evaluate
how the performance of pre-trained Pythia models changes with respect to each
of those dimensions, depending on model size and as a result of supervised
fine-tuning on conversational datasets. We observe only a mild impact of raw
model size on most metrics, whereas fine-tuning quickly saturates the scores
for all but the smallest models tested. Somewhat contrary to our expectations,
many metrics show very similar trends, especially if they are all rooted in the
same evaluator model, which raises the question of their reliability in
measuring a specific dimension. To that end, we conduct additional analyses of
score distributions, metric correlations, and term frequencies in generated
responses to help explain our observations.

</details>


### [48] [Can an Individual Manipulate the Collective Decisions of Multi-Agents?](https://arxiv.org/abs/2509.16494)
*Fengyuan Liu,Rui Zhao,Shuo Chen,Guohao Li,Philip Torr,Lei Han,Jindong Gu*

Main category: cs.CL

TL;DR: 作者提出M-Spoiler框架，仅基于单一智能体知识即可生成误导整个多智能体决策系统的对抗样本，实验证明其攻击力强于现有方法，提示需加强多智能体系统安全防护。


<details>
  <summary>Details</summary>
Motivation: 个人大语言模型（LLMs）虽然在多个领域展现了强大能力，但其脆弱性和多智能体系统难以全面访问，使得安全风险突出。尤其关心：如果攻击者只了解其中一个智能体，是否仍能生成误导整个系统的对抗样本？

Method: 将问题建模为不完全信息博弈，提出M-Spoiler框架：通过代理模拟多智能体系统互动，生成针对目标智能体的对抗样本。引入“顽固智能体”帮助优化，对抗样本更有效误导系统协作决策。

Result: 大量任务实验验证：仅凭对单一智能体的知识，攻击者即可有效误导多智能体系统决策。提出的M-Spoiler优于现有基线攻击方法。部分防御机制虽被探索，但对抗框架依然更具攻击性。

Conclusion: 多智能体系统中，单一智能体的知识足以被滥用制造强力对抗样本，威胁整体协作安全。亟需更充分的防御研究应对此类风险。

Abstract: Individual Large Language Models (LLMs) have demonstrated significant
capabilities across various domains, such as healthcare and law. Recent studies
also show that coordinated multi-agent systems exhibit enhanced decision-making
and reasoning abilities through collaboration. However, due to the
vulnerabilities of individual LLMs and the difficulty of accessing all agents
in a multi-agent system, a key question arises: If attackers only know one
agent, could they still generate adversarial samples capable of misleading the
collective decision? To explore this question, we formulate it as a game with
incomplete information, where attackers know only one target agent and lack
knowledge of the other agents in the system. With this formulation, we propose
M-Spoiler, a framework that simulates agent interactions within a multi-agent
system to generate adversarial samples. These samples are then used to
manipulate the target agent in the target system, misleading the system's
collaborative decision-making process. More specifically, M-Spoiler introduces
a stubborn agent that actively aids in optimizing adversarial samples by
simulating potential stubborn responses from agents in the target system. This
enhances the effectiveness of the generated adversarial samples in misleading
the system. Through extensive experiments across various tasks, our findings
confirm the risks posed by the knowledge of an individual agent in multi-agent
systems and demonstrate the effectiveness of our framework. We also explore
several defense mechanisms, showing that our proposed attack framework remains
more potent than baselines, underscoring the need for further research into
defensive strategies.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [49] [Computation of Graph Polynomials via Tree Decomposition: Theory, Algorithms, and Python Implementation](https://arxiv.org/abs/2509.16816)
*Mehul Bafna,Shaghik Amirian*

Main category: cs.DM

TL;DR: 本文基于树和路径分解提出高效算法计算图多项式，在有界树宽和k-退化图中验证其有效性，并分析了复杂度。


<details>
  <summary>Details</summary>
Motivation: 图多项式是图论中的重要组合不变量，但其计算往往复杂。为了提升计算效率，研究如何利用图结构分解方法来简化并高效求解。

Method: 利用树和路径分解（如树宽、k-树、路径宽）的结构，通过分解顺序和状态变换映射，构建显式算法。用Python实现并验证算法有效性，同时分析了其在稀疏图和k-退化图上的复杂性。

Result: 算法适用于有界树宽的图，在稀疏图和k-退化图等类别上表现良好，Python验证结果支持理论分析。

Conclusion: 提出的算法能够高效计算有界树宽图上的图多项式，并在分解基础上取得良好复杂度表现。

Abstract: Graph polynomials encode fundamental combinatorial invariants of graphs.
Their computation is investigated using tree and path decomposition frameworks,
with formal definitions of treewidth, k-trees, and pathwidth establishing the
structural basis for algorithmic efficiency. Explicit algorithms are
constructed for each polynomial, leveraging decomposition order and state
transformation mappings to enable tractable computation on graphs of bounded
treewidth. Python implementations validate the methods, and computational
complexity is analyzed with respect to sparse and k-degenerate graph classes.
These results advance decomposition-based approaches for polynomial computation
in algebraic graph theory.

</details>


### [50] [Circular-arc H-graphs: Ordering Characterizations and Forbidden Patterns](https://arxiv.org/abs/2509.18021)
*Indrajit Paul,Ashok Kumar Das*

Main category: cs.DM

TL;DR: 作者提出并研究了圆弧H图这一新类别，从排序的角度刻画了圆弧r图，并利用顶点排序给出了它们的禁用模式，加深了对圆弧类图结构的理解。


<details>
  <summary>Details</summary>
Motivation: 为了扩展圆弧图的相关理论和应用，推动对更广泛图结构的研究。

Method: 定义并研究了一类新的图——圆弧H图，并通过顶点排序方法对其进行刻画，进一步分析其结构特征，最后用特定顶点排列给出了圆弧r图的禁用模式。

Result: 提出了圆弧H图的概念，给出了圆弧r图的两种基于排序的刻画，并明确了圆弧r图在特定顶点排序下的禁用模式。

Conclusion: 这项工作推广了圆弧图的理论，丰富了图论中基于排序的结构刻画及禁用模式研究，对相关图类型的识别与分析具有指导意义。

Abstract: We introduce the class of circular-arc H-graphs, which generalizes
circular-arc graphs, particularly circular-arc bigraphs. We investigate two
types of ordering-based characterizations of circular-arc r-graphs. Finally, we
provide forbidden patterns for circular-arc r-graphs in terms of specific
vertex orderings.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [51] [The hereditariness problem for the Černý conjecture](https://arxiv.org/abs/2509.17992)
*Emanuele Rodaro,Riccardo Venturi*

Main category: cs.FL

TL;DR: 本文通过转换幺半群的结构理论，将Černý猜想的验证归约到三个特殊同步自动机类别，并提出了系统计算方法，实现了对猜想验证工作的有效简化。


<details>
  <summary>Details</summary>
Motivation: 探讨Černý猜想中提升问题：即对于商自动机成立的猜想，能否推广到原自动机。此问题是同步自动机理论中的重要未解难题。

Method: 通过建立转换幺半群中同余与理想格之间的伽罗瓦连接，提出了系统性分析方法，继而用该工具验证特定子类自动机上的Černý猜想。

Result: 证明只需在三类特殊同步自动机（radical, simple, quasi-simple）上验证Černý猜想，即可推广到一般情形；并发现这些自动机的转换幺半群存在覆盖常映射极小理想的唯一理想。

Conclusion: 虽然尚未完全解决问题，但文中显著简化了Černý猜想的验证：将其归约到三个特定自动机构类。还建立了一套用以结构分析及计算极大理想的系统方法。

Abstract: This paper addresses the lifting problem for the \v{C}ern\'y conjecture:
namely, whether the validity of the conjecture for a quotient automaton can
always be transferred (or "lifted") to the original automaton. Although a
complete solution remains open, we show that it is sufficient to verify the
\v{C}ern\'y conjecture for three specific subclasses of reset automata:
radical, simple, and quasi-simple. Our approach relies on establishing a Galois
connection between the lattices of congruences and ideals of the transition
monoid. This connection not only serves as the main tool in our proofs but also
provides a systematic method for computing the radical ideal and for deriving
structural insights about these classes. In particular, we show that for every
simple or quasi-simple automaton $\mathcal{A}$, the transition monoid
$\text{M}(\mathcal{A})$ possesses a unique ideal covering the minimal ideal of
constant (reset) maps; a result of similar flavor holds for the class of
radical automata.

</details>
