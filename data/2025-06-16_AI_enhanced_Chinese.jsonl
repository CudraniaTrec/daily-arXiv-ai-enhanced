{"id": "2506.11017", "categories": ["cs.CL", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2506.11017", "abs": "https://arxiv.org/abs/2506.11017", "authors": ["Yanyan Wang", "Yingying Wang", "Junli Liang", "Yin Xu", "Yunlong Liu", "Yiming Xu", "Zhengwang Jiang", "Zhehe Li", "Fei Li", "Long Zhao", "Kuang Xu", "Qi Song", "Xiangyang Li"], "title": "TeleEval-OS: Performance evaluations of large language models for operations scheduling", "comment": null, "summary": "The rapid advancement of large language models (LLMs) has significantly\npropelled progress in artificial intelligence, demonstrating substantial\napplication potential across multiple specialized domains. Telecommunications\noperation scheduling (OS) is a critical aspect of the telecommunications\nindustry, involving the coordinated management of networks, services, risks,\nand human resources to optimize production scheduling and ensure unified\nservice control. However, the inherent complexity and domain-specific nature of\nOS tasks, coupled with the absence of comprehensive evaluation benchmarks, have\nhindered thorough exploration of LLMs' application potential in this critical\nfield. To address this research gap, we propose the first Telecommunications\nOperation Scheduling Evaluation Benchmark (TeleEval-OS). Specifically, this\nbenchmark comprises 15 datasets across 13 subtasks, comprehensively simulating\nfour key operational stages: intelligent ticket creation, intelligent ticket\nhandling, intelligent ticket closure, and intelligent evaluation. To\nsystematically assess the performance of LLMs on tasks of varying complexity,\nwe categorize their capabilities in telecommunications operation scheduling\ninto four hierarchical levels, arranged in ascending order of difficulty: basic\nNLP, knowledge Q&A, report generation, and report analysis. On TeleEval-OS, we\nleverage zero-shot and few-shot evaluation methods to comprehensively assess 10\nopen-source LLMs (e.g., DeepSeek-V3) and 4 closed-source LLMs (e.g., GPT-4o)\nacross diverse scenarios. Experimental results demonstrate that open-source\nLLMs can outperform closed-source LLMs in specific scenarios, highlighting\ntheir significant potential and value in the field of telecommunications\noperation scheduling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9996\u4e2a\u7535\u4fe1\u8fd0\u7ef4\u8c03\u5ea6\u5927\u6a21\u578b\u57fa\u51c6TeleEval-OS\uff0c\u7cfb\u7edf\u8bc4\u6d4b\u5f00\u6e90\u4e0e\u95ed\u6e90LLM\u8868\u73b0\uff0c\u53d1\u73b0\u5f00\u6e90\u6a21\u578b\u5728\u90e8\u5206\u4efb\u52a1\u4e0a\u4f18\u4e8e\u95ed\u6e90\u6a21\u578b\uff0c\u663e\u793a\u5176\u5e94\u7528\u524d\u666f\u5e7f\u9614\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5df2\u5728\u591a\u9886\u57df\u5c55\u73b0\u5f3a\u5927\u6f5c\u529b\uff0c\u4f46\u5176\u5728\u7535\u4fe1\u8fd0\u7ef4\u8c03\u5ea6\u9886\u57df\u7684\u5e94\u7528\u5c1a\u7f3a\u4e4f\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e0e\u4e13\u7528\u57fa\u51c6\uff0c\u590d\u6742\u4e14\u9ad8\u5ea6\u4e13\u4e1a\u7684\u8fd0\u7ef4\u4efb\u52a1\u8fdb\u4e00\u6b65\u9650\u5236\u4e86\u6a21\u578b\u80fd\u529b\u7684\u63a2\u7d22\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u9996\u4e2a\u7535\u4fe1\u8fd0\u7ef4\u8c03\u5ea6\u8bc4\u6d4b\u57fa\u51c6\uff08TeleEval-OS\uff09\uff0c\u6db5\u76d613\u4e2a\u5b50\u4efb\u52a1\u300115\u4e2a\u6570\u636e\u96c6\uff0c\u6a21\u62df\u667a\u80fd\u6d3e\u5355\u3001\u5904\u7406\u3001\u7ed3\u5355\u3001\u8bc4\u4f30\u56db\u4e2a\u6838\u5fc3\u9636\u6bb5\uff0c\u6309\u96be\u5ea6\u5206\u4e3a\u56db\u4e2a\u5c42\u7ea7\uff0c\u5e76\u91c7\u7528\u96f6\u6837\u672c\u4e0e\u5c11\u6837\u672c\u7b49\u65b9\u5f0f\uff0c\u7cfb\u7edf\u8bc4\u6d4b10\u4e2a\u5f00\u6e90\u4e0e4\u4e2a\u95ed\u6e90\u5927\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5f00\u6e90LLMs\u5728\u90e8\u5206\u4efb\u52a1\u573a\u666f\u4e0b\u8d85\u8d8a\u4e86\u95ed\u6e90LLMs\uff0c\u8868\u73b0\u51fa\u5728\u7535\u4fe1\u8fd0\u7ef4\u8c03\u5ea6\u9886\u57df\u7684\u5de8\u5927\u6f5c\u529b\u548c\u4ef7\u503c\u3002", "conclusion": "TeleEval-OS\u4e3a\u7535\u4fe1\u8fd0\u7ef4\u8c03\u5ea6\u9886\u57dfLLM\u5e94\u7528\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u8bc4\u6d4b\u5de5\u5177\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5f00\u6e90\u5927\u6a21\u578b\u7684\u5f3a\u5927\u80fd\u529b\uff0c\u5c06\u63a8\u52a8\u76f8\u5173\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u8fdb\u6b65\u3002"}}
{"id": "2506.11063", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11063", "abs": "https://arxiv.org/abs/2506.11063", "authors": ["Jiayu Yao", "Shenghua Liu", "Yiwei Wang", "Lingrui Mei", "Baolong Bi", "Yuyao Ge", "Zhecheng Li", "Xueqi Cheng"], "title": "Who is in the Spotlight: The Hidden Bias Undermining Multimodal Retrieval-Augmented Generation", "comment": null, "summary": "Multimodal Retrieval-Augmented Generation (RAG) systems have become essential\nin knowledge-intensive and open-domain tasks. As retrieval complexity\nincreases, ensuring the robustness of these systems is critical. However,\ncurrent RAG models are highly sensitive to the order in which evidence is\npresented, often resulting in unstable performance and biased reasoning,\nparticularly as the number of retrieved items or modality diversity grows. This\nraises a central question: How does the position of retrieved evidence affect\nmultimodal RAG performance? To answer this, we present the first comprehensive\nstudy of position bias in multimodal RAG systems. Through controlled\nexperiments across text-only, image-only, and mixed-modality tasks, we observe\na consistent U-shaped accuracy curve with respect to evidence position. To\nquantify this bias, we introduce the Position Sensitivity Index ($PSI_p$) and\ndevelop a visualization framework to trace attention allocation patterns across\ndecoder layers. Our results reveal that multimodal interactions intensify\nposition bias compared to unimodal settings, and that this bias increases\nlogarithmically with retrieval range. These findings offer both theoretical and\nempirical foundations for position-aware analysis in RAG, highlighting the need\nfor evidence reordering or debiasing strategies to build more reliable and\nequitable generation systems.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u6027\u5206\u6790\u4e86\u591a\u6a21\u6001RAG\u7cfb\u7edf\u4e2d\u7684\u8bc1\u636e\u987a\u5e8f\u504f\u89c1\uff0c\u63d0\u51fa\u4e86\u4f4d\u7f6e\u654f\u611f\u6307\u6570\u8fdb\u884c\u91cf\u5316\uff0c\u53d1\u73b0\u591a\u6a21\u6001\u4ea4\u4e92\u5f3a\u5316\u4e86\u4f4d\u7f6e\u4f9d\u8d56\u6027\uff0c\u9488\u5bf9\u8be5\u504f\u89c1\u5efa\u8bae\u91c7\u7528\u8bc1\u636e\u91cd\u6392\u5e8f\u6216\u53bb\u504f\u63aa\u65bd\u63d0\u5347\u7cfb\u7edf\u9c81\u68d2\u6027\u4e0e\u516c\u5e73\u6027\u3002", "motivation": "\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u5728\u9700\u8981\u4e30\u5bcc\u77e5\u8bc6\u548c\u5f00\u653e\u9886\u57df\u7684\u4efb\u52a1\u4e2d\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u968f\u7740\u68c0\u7d22\u590d\u6742\u6027\u63d0\u5347\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u5bf9\u4e8e\u8bc1\u636e\u8f93\u5165\u987a\u5e8f\u7684\u654f\u611f\u6027\u9020\u6210\u6027\u80fd\u4e0d\u7a33\u5b9a\u548c\u63a8\u7406\u504f\u89c1\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86\u5168\u9762\u7684\u5bf9\u7167\u5b9e\u9a8c\uff0c\u6db5\u76d6\u6587\u672c\u3001\u56fe\u50cf\u548c\u6df7\u5408\u6a21\u6001\u4efb\u52a1\uff0c\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u7814\u7a76\u4e86\u8bc1\u636e\u987a\u5e8f\u5bf9\u591a\u6a21\u6001RAG\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\uff1b\u63d0\u51fa\u4e86\u4f4d\u7f6e\u654f\u611f\u6307\u6570\uff08PSI_p\uff09\u6765\u91cf\u5316\u8fd9\u79cd\u504f\u5dee\uff0c\u5e76\u5f00\u53d1\u4e86\u53ef\u89c6\u5316\u6846\u67b6\u8ffd\u8e2a\u89e3\u7801\u5668\u5404\u5c42\u6ce8\u610f\u529b\u5206\u5e03\u53d8\u5316\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u8bc1\u636e\u4f4d\u7f6e\u5bf9RAG\u6a21\u578b\u8868\u73b0\u6709\u4e00\u81f4\u7684U\u578b\u5f71\u54cd\u66f2\u7ebf\uff0c\u591a\u6a21\u6001\u60c5\u5883\u4e0b\u4f4d\u7f6e\u504f\u89c1\u6bd4\u5355\u4e00\u6a21\u6001\u66f4\u5f3a\uff0c\u4e14\u968f\u7740\u68c0\u7d22\u8303\u56f4\u6269\u5927\uff0c\u8be5\u504f\u89c1\u5448\u5bf9\u6570\u589e\u957f\u3002", "conclusion": "\u591a\u6a21\u6001RAG\u7cfb\u7edf\u5bf9\u8bc1\u636e\u4f4d\u7f6e\u9ad8\u5ea6\u654f\u611f\uff0c\u9700\u8981\u5f15\u5165\u8bc1\u636e\u91cd\u65b0\u6392\u5e8f\u6216\u53bb\u504f\u65b9\u6cd5\uff0c\u4ee5\u6784\u5efa\u66f4\u9c81\u68d2\u4e0e\u516c\u5e73\u7684\u751f\u6210\u7cfb\u7edf\u3002"}}
{"id": "2506.11065", "categories": ["cs.CL", "Primary 68T50, Secondary 68T05, 91F20", "I.2.7; I.2.6; I.5.4"], "pdf": "https://arxiv.org/pdf/2506.11065", "abs": "https://arxiv.org/abs/2506.11065", "authors": ["Alexey Tikhonov", "Sergei Shteiner", "Anna Bykova", "Ivan P. Yamshchikov"], "title": "Smotrom tvoja pa ander drogoj verden! Resurrecting Dead Pidgin with Generative Models: Russenorsk Case Study", "comment": "ACL Findings 2025", "summary": "Russenorsk, a pidgin language historically used in trade interactions between\nRussian and Norwegian speakers, represents a unique linguistic phenomenon. In\nthis paper, we attempt to analyze its lexicon using modern large language\nmodels (LLMs), based on surviving literary sources. We construct a structured\ndictionary of the language, grouped by synonyms and word origins. Subsequently,\nwe use this dictionary to formulate hypotheses about the core principles of\nword formation and grammatical structure in Russenorsk and show which\nhypotheses generated by large language models correspond to the hypotheses\npreviously proposed ones in the academic literature. We also develop a\n\"reconstruction\" translation agent that generates hypothetical Russenorsk\nrenderings of contemporary Russian and Norwegian texts.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5206\u6790\u4e86\u5386\u53f2\u6df7\u5408\u8bedRussenorsk\u7684\u8bcd\u6c47\u548c\u8bed\u6cd5\u89c4\u5f8b\uff0c\u6784\u5efa\u4e86\u7ed3\u6784\u5316\u8bcd\u5178\u548c\u7ffb\u8bd1\u5de5\u5177\uff0c\u9a8c\u8bc1\u5e76\u4e30\u5bcc\u4e86\u76f8\u5173\u5b66\u672f\u5047\u8bf4\uff0c\u63a8\u52a8\u4e86AI\u8f85\u52a9\u8bed\u8a00\u7814\u7a76\u7684\u53d1\u5c55\u3002", "motivation": "Russenorsk\u662f\u4e00\u79cd\u66fe\u5728\u4fc4\u8bed\u548c\u632a\u5a01\u8bed\u4f7f\u7528\u8005\u4e4b\u95f4\u8d38\u6613\u4ea4\u6d41\u4e2d\u5f62\u6210\u7684\u72ec\u7279\u6df7\u5408\u8bed\u79cd\uff0c\u4f46\u5176\u8bcd\u6c47\u548c\u8bed\u6cd5\u7ed3\u6784\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u5206\u6790\u3002\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u53d1\u5c55\uff0c\u4f5c\u8005\u5e0c\u671b\u5229\u7528\u73b0\u4ee3\u6280\u672f\u5bf9\u5176\u8bcd\u6c47\u548c\u7ed3\u6784\u8fdb\u884c\u6df1\u5165\u7814\u7a76\u3002", "method": "\u4f5c\u8005\u9996\u5148\u57fa\u4e8e\u73b0\u5b58\u6587\u732e\u5efa\u7acb\u4e86Russenorsk\u7684\u7ed3\u6784\u5316\u8bcd\u5178\uff0c\u5c06\u8bcd\u6c47\u6309\u540c\u4e49\u8bcd\u548c\u8bcd\u6e90\u8fdb\u884c\u5206\u7c7b\u3002\u7136\u540e\uff0c\u5229\u7528\u8be5\u8bcd\u5178\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u51fa\u8bed\u8a00\u6784\u8bcd\u4e0e\u8bed\u6cd5\u7ed3\u6784\u7684\u5047\u8bbe\uff0c\u5e76\u4e0e\u5b66\u672f\u6587\u732e\u4e2d\u7684\u65e2\u6709\u5047\u8bf4\u8fdb\u884c\u5bf9\u6bd4\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u5f00\u53d1\u4e86\u4e00\u4e2a\u201c\u590d\u539f\u201d\u7ffb\u8bd1\u4ee3\u7406\uff0c\u53ef\u751f\u6210\u73b0\u4ee3\u4fc4\u8bed\u548c\u632a\u5a01\u8bed\u6587\u672c\u7684\u5047\u60f3Russenorsk\u8bd1\u6587\u3002", "result": "\u7814\u7a76\u5206\u6790\u4e86Russenorsk\u7684\u6838\u5fc3\u8bcd\u6c47\u3001\u8bcd\u6e90\u548c\u6784\u8bcd\u53ca\u8bed\u6cd5\u89c4\u5219\uff0c\u901a\u8fc7\u73b0\u4ee3LLM\u5de5\u5177\u9a8c\u8bc1\u5e76\u8865\u5145\u4e86\u5df2\u6709\u5b66\u672f\u7814\u7a76\u7684\u4e00\u4e9b\u5047\u8bf4\uff0c\u540c\u65f6\u4e5f\u5f00\u53d1\u4e86\u53ef\u4ee5\u751f\u6210Russenorsk\u8bd1\u6587\u7684\u7ffb\u8bd1\u5de5\u5177\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u901a\u8fc7\u73b0\u4ee3\u5927\u6a21\u578b\u5206\u6790\u5386\u53f2\u6df7\u5408\u8bed\u79cd\u8bcd\u6c47\u548c\u7ed3\u6784\u7684\u6709\u6548\u6027\uff0c\u4e0d\u4ec5\u6269\u5c55\u4e86\u5bf9Russenorsk\u7684\u8ba4\u8bc6\uff0c\u4e5f\u4e3a\u5229\u7528AI\u8f85\u52a9\u8bed\u8a00\u5386\u53f2\u548c\u6df7\u5408\u8bed\u8a00\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.11067", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11067", "abs": "https://arxiv.org/abs/2506.11067", "authors": ["Hieu Nghiem", "Hemanth Reddy Singareddy", "Zhuqi Miao", "Jivan Lamichhane", "Abdulaziz Ahmed", "Johnson Thomas", "Dursun Delen", "William Paiva"], "title": "A Large Language Model Based Pipeline for Review of Systems Entity Recognition from Clinical Notes", "comment": null, "summary": "Objective: Develop a cost-effective, large language model (LLM)-based\npipeline for automatically extracting Review of Systems (ROS) entities from\nclinical notes. Materials and Methods: The pipeline extracts ROS sections using\nSecTag, followed by few-shot LLMs to identify ROS entity spans, their\npositive/negative status, and associated body systems. We implemented the\npipeline using open-source LLMs (Mistral, Llama, Gemma) and ChatGPT. The\nevaluation was conducted on 36 general medicine notes containing 341 annotated\nROS entities. Results: When integrating ChatGPT, the pipeline achieved the\nlowest error rates in detecting ROS entity spans and their corresponding\nstatuses/systems (28.2% and 14.5%, respectively). Open-source LLMs enable\nlocal, cost-efficient execution of the pipeline while delivering promising\nperformance with similarly low error rates (span: 30.5-36.7%; status/system:\n24.3-27.3%). Discussion and Conclusion: Our pipeline offers a scalable and\nlocally deployable solution to reduce ROS documentation burden. Open-source\nLLMs present a viable alternative to commercial models in resource-limited\nhealthcare environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u5f00\u6e90\u4e0e\u5546\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8ROS\u5b9e\u4f53\u62bd\u53d6\u6d41\u7a0b\uff0c\u5b9e\u73b0\u4e86\u8f83\u4f4e\u9519\u8bef\u7387\u548c\u9ad8\u53ef\u6269\u5c55\u6027\uff0c\u662f\u7f13\u89e3\u533b\u7597\u6587\u6863\u5de5\u4f5c\u8d1f\u62c5\u7684\u6709\u6548\u65b9\u6848\u3002", "motivation": "\u5728\u533b\u7597\u73af\u5883\u4e0b\uff0c\u624b\u52a8\u63d0\u53d6\u548c\u8bb0\u5f55\u4f53\u683c\u68c0\u67e5\u7cfb\u7edf\uff08Review of Systems\uff0cROS\uff09\u4fe1\u606f\u975e\u5e38\u7e41\u7410\u4e14\u6210\u672c\u9ad8\u6602\u3002\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u63d0\u53d6\u4e34\u5e8a\u7b14\u8bb0\u4e2d\u7684ROS\u5b9e\u4f53\u53ef\u4ee5\u663e\u8457\u51cf\u8f7b\u533b\u751f\u6587\u4e66\u8d1f\u62c5\uff0c\u63d0\u5347\u6548\u7387\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u8d44\u6e90\u6709\u9650\u7684\u533b\u7597\u573a\u666f\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5316\u5904\u7406\u6d41\u7a0b\u3002\u8be5\u6d41\u7a0b\u9996\u5148\u4f7f\u7528SecTag\u5de5\u5177\u63d0\u53d6\u4e34\u5e8a\u7b14\u8bb0\u4e2d\u7684ROS\u76f8\u5173\u6bb5\u843d\uff0c\u7136\u540e\u901a\u8fc7\u5c11\u6837\u672c\u5b66\u4e60\u7684LLM\u6a21\u578b\uff08\u5305\u62ecMistral\u3001Llama\u3001Gemma\u7b49\u5f00\u6e90\u6a21\u578b\u548cChatGPT\uff09\u8bc6\u522bROS\u5b9e\u4f53\u7684\u4f4d\u7f6e\u3001\u6b63\u8d1f\u6027\u72b6\u6001\u53ca\u5176\u96b6\u5c5e\u7cfb\u7edf\u3002\u968f\u540e\u572836\u4efd\u533b\u5b66\u7b14\u8bb0\uff08\u542b341\u4e2a\u6807\u6ce8\u5b9e\u4f53\uff09\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u96c6\u6210ChatGPT\u65f6\uff0c\u8bc6\u522bROS\u5b9e\u4f53\u7684\u4f4d\u7f6e\u4ee5\u53ca\u72b6\u6001/\u6240\u5c5e\u7cfb\u7edf\u7684\u9519\u8bef\u7387\u6700\u4f4e\uff08\u5206\u522b\u4e3a28.2%\u548c14.5%\uff09\u3002\u800c\u4f7f\u7528\u5f00\u6e90LLM\u65f6\uff0c\u8be5\u6d41\u7a0b\u80fd\u5728\u672c\u5730\u3001\u4f4e\u6210\u672c\u90e8\u7f72\uff0c\u4e14\u5176\u9519\u8bef\u7387\u4e5f\u76f8\u8fd1\uff08\u5b9e\u4f53\u8bc6\u522b\uff1a30.5-36.7%\uff1b\u72b6\u6001/\u7cfb\u7edf\u8bc6\u522b\uff1a24.3-27.3%\uff09\uff0c\u8868\u73b0\u53ef\u89c2\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8eLLM\u7684\u81ea\u52a8ROS\u5b9e\u4f53\u63d0\u53d6\u6d41\u7a0b\u5177\u6709\u53ef\u6269\u5c55\u6027\uff0c\u4e14\u53ef\u672c\u5730\u5316\u90e8\u7f72\uff0c\u6709\u52a9\u4e8e\u51cf\u8f7b\u533b\u7597\u6587\u6863\u5f55\u5165\u8d1f\u62c5\u3002\u5f00\u6e90LLM\u5728\u8d44\u6e90\u6709\u9650\u73af\u5883\u4e2d\u53ef\u4f5c\u4e3a\u5546\u7528\u6a21\u578b\u7684\u6709\u6548\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2506.10984", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.10984", "abs": "https://arxiv.org/abs/2506.10984", "authors": ["Ahilan Ayyachamy Nadar Ponnusamy"], "title": "Application Modernization with LLMs: Addressing Core Challenges in Reliability, Security, and Quality", "comment": null, "summary": "AI-assisted code generation tools have revolutionized software development,\noffering unprecedented efficiency and scalability. However, multiple studies\nhave consistently highlighted challenges such as security vulnerabilities,\nreliability issues, and inconsistencies in the generated code. Addressing these\nconcerns is crucial to unlocking the full potential of this transformative\ntechnology. While advancements in foundational and code-specialized language\nmodels have made notable progress in mitigating some of these issues,\nsignificant gaps remain, particularly in ensuring high-quality, trustworthy\noutputs.\n  This paper builds upon existing research on leveraging large language models\n(LLMs) for application modernization. It explores an opinionated approach that\nemphasizes two core capabilities of LLMs: code reasoning and code generation.\nThe proposed framework integrates these capabilities with human expertise to\ntackle application modernization challenges effectively. It highlights the\nindispensable role of human involvement and guidance in ensuring the success of\nAI-assisted processes.\n  To demonstrate the framework's utility, this paper presents a detailed case\nstudy, walking through its application in a real-world scenario. The analysis\nincludes a step-by-step breakdown, assessing alternative approaches where\napplicable. This work aims to provide actionable insights and a robust\nfoundation for future research in AI-driven application modernization. The\nreference implementation created for this paper is available on GitHub.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u7ed3\u5408LLM\u4ee3\u7801\u63a8\u7406\u751f\u6210\u80fd\u529b\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u6307\u5bfc\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3AI\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u8d28\u91cf\u548c\u53ef\u4fe1\u5ea6\u96be\u9898\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u66f4\u6709\u6548\u63a8\u8fdb\u5e94\u7528\u73b0\u4ee3\u5316\u8fdb\u7a0b\u3002", "motivation": "\u5c3d\u7ba1AI\u4ee3\u7801\u751f\u6210\u663e\u8457\u63d0\u5347\u4e86\u5f00\u53d1\u6548\u7387\uff0c\u4f46\u4ecd\u5b58\u5728\u5b89\u5168\u6027\u3001\u7a33\u5b9a\u6027\u4e0e\u4e00\u81f4\u6027\u7b49\u91cd\u5927\u6311\u6218\u3002\u4e3a\u91ca\u653e\u5176\u5168\u90e8\u6f5c\u529b\uff0c\u9700\u89e3\u51b3\u8f93\u51fa\u8d28\u91cf\u548c\u53ef\u4fe1\u5ea6\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u6709\u6548\u7ed3\u5408AI\u4e0e\u4eba\u529b\u7684\u65b9\u6848\uff0c\u63a8\u52a8AI\u5728\u5e94\u7528\u73b0\u4ee3\u5316\u4e2d\u7684\u53ef\u9760\u843d\u5730\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7801\u63a8\u7406\u4e0e\u4ee3\u7801\u751f\u6210\u80fd\u529b\u7ed3\u5408\uff0c\u5e76\u878d\u5165\u4eba\u5de5\u4e13\u4e1a\u77e5\u8bc6\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8be6\u7ec6\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u5728\u73b0\u5b9e\u5e94\u7528\u73b0\u4ee3\u5316\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u6d41\u7a0b\u548c\u6548\u679c\uff0c\u540c\u65f6\u8bc4\u4f30\u4e86\u5176\u4ed6\u53ef\u9009\u65b9\u6cd5\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u901a\u8fc7\u771f\u5b9e\u6848\u4f8b\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u80fd\u66f4\u597d\u5730\u5e94\u5bf9\u5e94\u7528\u73b0\u4ee3\u5316\u4e2d\u7684\u5b9e\u9645\u95ee\u9898\uff0c\u5c55\u73b0\u4e86AI\u4e0e\u4eba\u5de5\u7ed3\u5408\u7684\u4f18\u52bf\u3002\u76f8\u5173\u53c2\u8003\u5b9e\u73b0\u4ee3\u7801\u5df2\u5728GitHub\u516c\u5f00\uff0c\u4e3a\u672a\u6765\u7684AI\u8d4b\u80fd\u73b0\u4ee3\u5316\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u4eba\u7c7b\u4e13\u5bb6\u7684\u79ef\u6781\u53c2\u4e0e\u5bf9\u4e8e\u786e\u4fddAI\u8f85\u52a9\u4ee3\u7801\u751f\u6210\u5de5\u5177\u5728\u5e94\u7528\u73b0\u4ee3\u5316\u4e2d\u7684\u6210\u529f\u81f3\u5173\u91cd\u8981\u3002\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u4ee3\u7801\u63a8\u7406\u548c\u751f\u6210\u80fd\u529b\u4e0e\u4eba\u5de5\u68c0\u67e5\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8\u4ee3\u7801\u8d28\u91cf\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2506.11334", "categories": ["cs.FL"], "pdf": "https://arxiv.org/pdf/2506.11334", "abs": "https://arxiv.org/abs/2506.11334", "authors": ["Luc Dartois", "Paul Gastin", "L. Germerie Guizouarn", "Shankaranarayanan Krishna"], "title": "Reversible Pebble Transducers", "comment": null, "summary": "Deterministic two-way transducers with pebbles (aka pebble transducers)\ncapture the class of polyregular functions, which extend the string-to-string\nregular functions allowing polynomial growth instead of linear growth. One of\nthe most fundamental operations on functions is composition, and (poly)regular\nfunctions can be realized as a composition of several simpler functions. In\ngeneral, composition of deterministic two-way transducers incur a doubly\nexponential blow-up in the size of the inputs. A major improvement in this\ndirection comes from the fundamental result of Dartois et al. [10] showing a\npolynomial construction for the composition of reversible two-way transducers.\nA precise complexity analysis for existing composition techniques of pebble\ntransducers is missing. But they rely on the classic composition of two-way\ntransducers and inherit the double exponential complexity. To overcome this\nproblem, we introduce reversible pebble transducers. Our main results are\nefficient uniformization techniques for non-deterministic pebble transducers to\nreversible ones and efficient composition for reversible pebble transducers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u53ef\u9006\u5375\u77f3\u6362\u4f4d\u5668\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6362\u4f4d\u5668\u7ec4\u5408\u65f6\u7684\u9ad8\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u9ad8\u6548\u6b63\u89c4\u5316\u4e0e\u7ec4\u5408\u65b9\u6cd5\uff0c\u5927\u5927\u63d0\u9ad8\u4e86\u5904\u7406\u591a\u6b63\u5219\u51fd\u6570\u7684\u5b9e\u9645\u53ef\u7528\u6027\u3002", "motivation": "\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u4f20\u7edf\uff08\u591a\uff09\u6b63\u5219\u51fd\u6570\u5b9e\u73b0\u8fc7\u7a0b\u4e2d\uff0c\u6362\u4f4d\u5668\u901a\u8fc7\u7ec4\u5408\u5e26\u6765\u7684\u8f93\u5165\u89c4\u6a21\u53cc\u6307\u6570\u7ea7\u7206\u70b8\u95ee\u9898\uff0c\u5c24\u5176\u662f\u73b0\u6709\u5375\u77f3\u6362\u4f4d\u5668\u5408\u6210\u590d\u6742\u5ea6\u5206\u6790\u548c\u964d\u4f4e\u5408\u6210\u590d\u6742\u5ea6\u7684\u9700\u6c42\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u53ef\u9006\u5375\u77f3\u6362\u4f4d\u5668\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5c06\u975e\u786e\u5b9a\u6027\u5375\u77f3\u6362\u4f4d\u5668\u6b63\u89c4\u5316\u4e3a\u53ef\u9006\u5f62\u5f0f\u7684\u9ad8\u6548\u7b97\u6cd5\uff0c\u4ee5\u53ca\u53ef\u9006\u5375\u77f3\u6362\u4f4d\u5668\u7684\u9ad8\u6548\u7ec4\u5408\u65b9\u6cd5\u3002", "result": "\u6587\u7ae0\u53d6\u5f97\u7684\u4e3b\u8981\u6210\u679c\u662f\u63d0\u51fa\u53ef\u9006\u5375\u77f3\u6362\u4f4d\u5668\uff0c\u5e76\u5b9e\u73b0\u4e86\u5176\u9ad8\u6548\u5408\u6210\u548c\u6b63\u89c4\u5316\u6280\u672f\uff0c\u4ece\u800c\u5927\u5e45\u63d0\u9ad8\u4e86\u5408\u6210\u6548\u7387\u3002", "conclusion": "\u6587\u7ae0\u63d0\u51fa\u4e86\u53ef\u9006\u5375\u77f3\u6362\u4f4d\u5668\uff08reversible pebble transducers\uff09\u7684\u6982\u5ff5\uff0c\u5e76\u5c55\u793a\u4e86\u6709\u6548\u7684\u6b63\u89c4\u5316\u53ca\u9ad8\u6548\u7684\u5408\u6210\u6280\u672f\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u786e\u5b9a\u6027\u53cc\u5411\u6362\u4f4d\u5668\u7ec4\u5408\u65f6\u8f93\u5165\u5927\u5c0f\u4f1a\u51fa\u73b0\u53cc\u6307\u6570\u7206\u70b8\u7684\u95ee\u9898\u3002"}}
{"id": "2506.11662", "categories": ["cs.DM"], "pdf": "https://arxiv.org/pdf/2506.11662", "abs": "https://arxiv.org/abs/2506.11662", "authors": ["Artem Kaznatcheev", "Sofia Vazquez Alferez"], "title": "Greed is slow on sparse graphs of oriented valued constraints", "comment": "13 pages, to appear at CP2025", "summary": "Greedy local search is especially popular for solving valued constraint\nsatisfaction problems (VCSPs). Since any method will be slow for some VCSPs, we\nask: what is the simplest VCSP on which greedy local search is slow? We\nconstruct a VCSP on 6n Boolean variables for which greedy local search takes\n7(2^n - 1) steps to find the unique peak. Our VCSP is simple in two ways.\nFirst, it is very sparse: its constraint graph has pathwidth 2 and maximum\ndegree 3. This is the simplest VCSP on which some local search could be slow.\nSecond, it is \"oriented\" - there is an ordering on the variables such that\nlater variables are conditionally-independent of earlier ones. Being oriented\nallows many non-greedy local search methods to find the unique peak in a\nquadratic number of steps. Thus, we conclude that - among local search methods\n- greed is particularly slow.", "AI": {"tldr": "\u672c\u6587\u5c55\u793a\u4e86\u5373\u4f7f\u5728\u7ed3\u6784\u975e\u5e38\u7b80\u5355\u7684VCSP\u95ee\u9898\u4e2d\uff0c\u8d2a\u5a6a\u5c40\u90e8\u641c\u7d22\u4f9d\u7136\u53ef\u80fd\u975e\u5e38\u4f4e\u6548\u3002\u8fd9\u4e00\u53d1\u73b0\u4e3a\u9009\u62e9\u5c40\u90e8\u641c\u7d22\u65b9\u6cd5\u63d0\u4f9b\u4e86\u8b66\u793a\uff1a\u8fc7\u5ea6\u4f9d\u8d56\u8d2a\u5a6a\u7b56\u7565\u53ef\u80fd\u5bfc\u81f4\u6781\u4f4e\u7684\u641c\u7d22\u6548\u7387\uff0c\u5c24\u5176\u5728\u7279\u5b9a\u95ee\u9898\u7ed3\u6784\u4e0b\u3002", "motivation": "\u8d2a\u5a6a\u5c40\u90e8\u641c\u7d22\u5728\u6c42\u89e3\u8d4b\u503c\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\uff08VCSPs\uff09\u4e2d\u975e\u5e38\u6d41\u884c\uff0c\u4f46\u67d0\u4e9bVCSP\u5b9e\u4f8b\u5bf9\u4e8e\u4efb\u4f55\u65b9\u6cd5\u800c\u8a00\u90fd\u4f1a\u5f88\u6162\u3002\u4f5c\u8005\u60f3\u8981\u63a2\u7a76\uff1a\u5bf9\u4e8e\u8d2a\u5a6a\u5c40\u90e8\u641c\u7d22\u6765\u8bf4\uff0c\u4ec0\u4e48\u662f\u201c\u6700\u7b80\u5355\u7684\u3001\u4f9d\u7136\u7b97\u8d77\u6765\u5f88\u6162\u201d\u7684VCSP\u95ee\u9898\uff1f", "method": "\u4f5c\u8005\u6784\u9020\u4e86\u4e00\u4e2a\u5305\u542b6n\u4e2a\u5e03\u5c14\u53d8\u91cf\u7684VCSP\uff0c\u8fd9\u4e2a\u95ee\u9898\u975e\u5e38\u7a00\u758f\uff08\u7ea6\u675f\u56fe\u7684\u8def\u5f84\u5bbd\u5ea6\u4e3a2\uff0c\u6700\u5927\u5ea6\u6570\u4e3a3\uff09\uff0c\u5e76\u5177\u6709\u201c\u6709\u5411\u6027\u201d\u2014\u2014\u53d8\u91cf\u6709\u5e8f\uff0c\u540e\u9762\u7684\u53d8\u91cf\u5bf9\u524d\u9762\u7684\u6761\u4ef6\u72ec\u7acb\u3002", "result": "\u5728\u8fd9\u4e2a\u6784\u9020\u7684VCSP\u5b9e\u4f8b\u4e0a\uff0c\u8d2a\u5a6a\u5c40\u90e8\u641c\u7d22\u9700\u89817*(2^n-1)\u6b65\u624d\u80fd\u627e\u5230\u552f\u4e00\u7684\u5cf0\u503c\u89e3\uff0c\u800c\u8bb8\u591a\u975e\u8d2a\u5a6a\u7684\u5c40\u90e8\u641c\u7d22\u65b9\u6cd5\u53ef\u4ee5\u5728\u5e73\u65b9\u6b65\u6570\u5185\u89e3\u51b3\u3002", "conclusion": "\u5728\u8fd9\u4e9bVCSP\u95ee\u9898\u4e0a\uff0c\u8d2a\u5a6a\u5c40\u90e8\u641c\u7d22\u663e\u8457\u6162\u4e8e\u5176\u4ed6\u5c40\u90e8\u641c\u7d22\u65b9\u6cd5\u3002\u4e5f\u5c31\u662f\u8bf4\uff0c\u5bf9\u4e8e\u67d0\u4e9b\u6781\u5176\u7b80\u5355\u7ed3\u6784\u7684VCSP\uff0c\u8d2a\u5a6a\u7b56\u7565\u8868\u73b0\u51fa\u7279\u522b\u4f4e\u6548\u3002"}}
{"id": "2506.11517", "categories": ["cs.LO", "68Q85", "F.1.1; D.2.4; F.3.1"], "pdf": "https://arxiv.org/pdf/2506.11517", "abs": "https://arxiv.org/abs/2506.11517", "authors": ["Roberto Gorrieri", "Ivan Lanese"], "title": "Decidable Reversible Equivalences for Finite Petri Nets", "comment": "arXiv admin note: text overlap with arXiv:2305.04222", "summary": "In the setting of Petri nets, we prove that {\\em causal-net bisimilarity}\n\\cite{G15,Gor22,Gor25a}, which is a refinement of history-preserving\nbisimilarity \\cite{RT88,vGG89,DDM89}, and the novel {\\em hereditary} causal-net\nbisimilarity, which is a refinement of hereditary history-preserving\nbisimilarity \\cite{Bed91,JNW96}, do coincide. This means that causal-net\nbisimilarity is a {\\em reversible behavioral equivalence}, as causal-net\nbisimilar markings not only are able to match each other's forward transitions,\nbut also backward transitions by undoing performed events. Causal-net\nbisimilarity can be equivalently formulated as {\\em structure-preserving\nbisimilarity} \\cite{G15,Gor25a}, that is decidable on finite bounded Petri nets\n\\cite{CG21a}. Moreover, place bisimilarity \\cite{ABS91}, that we prove to be\nfiner than causal-net bisimilarity, is also reversible and it was proved\ndecidable for finite Petri nets in \\cite{Gor21decid,Gor25a}. These results\noffer two decidable reversible behavioral equivalences in the true concurrency\nspectrum, which are alternative to the coarser hereditary history-preserving\nbisimilarity \\cite{Bed91,JNW96}, that, unfortunately, is undecidable even for\nsafe Petri nets \\cite{JNS03}.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5206\u6790\u4e86\u4e24\u79cd\u5728\u6709\u9650Petri\u7f51\u4e0b\u53ef\u5224\u5b9a\u4e14\u53ef\u9006\u7684\u65b0\u578b\u884c\u4e3a\u7b49\u4ef7\u5173\u7cfb\uff0c\u4e3a\u5e76\u53d1\u7cfb\u7edf\u5224\u7b49\u7406\u8bba\u5e26\u6765\u65b0\u7a81\u7834\u3002", "motivation": "\u5728Petri\u7f51\u7684\u9886\u57df\u4e2d\uff0c\u7814\u7a76\u5982\u4f55\u5b9a\u4e49\u548c\u5224\u5b9a\u7cfb\u7edf\u95f4\u66f4\u7ec6\u81f4\u7684\u53ef\u9006\u884c\u4e3a\u7b49\u4ef7\u5173\u7cfb\u3002\u4ee5\u5f80\u5386\u53f2\u4fdd\u7559\u4e92\u6a21\u62df\u4e0e\u5176\u884d\u751f\u7b49\u4ef7\u5173\u7cfb\u9762\u4e34\u4e0d\u53ef\u5224\u5b9a\u6027\u7b49\u7406\u8bba\u4e0e\u5b9e\u9645\u95ee\u9898\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u63a2\u7d22\u65e2\u80fd\u523b\u753b\u771f\u5b9e\u5e76\u53d1\u6027\uff0c\u53c8\u53ef\u5224\u5b9a\u7684\u7b49\u4ef7\u5173\u7cfb\u3002", "method": "\u672c\u6587\u4e25\u683c\u5206\u6790\u4e86\u56e0\u679c\u7f51\u4e92\u6a21\u62df\uff08causal-net bisimilarity\uff09\u3001\u65b0\u63d0\u51fa\u7684\u9057\u4f20\u6027\u56e0\u679c\u7f51\u4e92\u6a21\u62df\uff0c\u4ee5\u53ca\u4e0e\u4e4b\u76f8\u5173\u7684\u7ed3\u6784\u4fdd\u7559\u4e92\u6a21\u62df\u3001\u4f4d\u7f6e\u4e92\u6a21\u62df\u7b49\u7b49\u4ef7\u5173\u7cfb\uff0c\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u5206\u6790\u5b83\u4eec\u4e4b\u95f4\u7684\u5173\u7cfb\u4e0e\u5224\u5b9a\u6027\uff0c\u91cd\u70b9\u7814\u7a76\u4e86\u5b83\u4eec\u662f\u5426\u662f\u53ef\u9006\u7b49\u4ef7\u5173\u7cfb\u5e76\u4e14\u5728\u6709\u9650\u6709\u754cPetri\u7f51\u4e0a\u7684\u53ef\u5224\u5b9a\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u56e0\u679c\u7f51\u4e92\u6a21\u62df\u548c\u9057\u4f20\u6027\u56e0\u679c\u7f51\u4e92\u6a21\u62df\u662f\u7b49\u4ef7\u7684\uff0c\u4e24\u8005\u90fd\u5c5e\u4e8e\u53ef\u9006\u7684\u884c\u4e3a\u7b49\u4ef7\u5173\u7cfb\uff0c\u4e14\u7b49\u4ef7\u4e8e\u7ed3\u6784\u4fdd\u7559\u4e92\u6a21\u62df\uff0c\u53ef\u5224\u5b9a\u4e8e\u6709\u9650\u6709\u754cPetri\u7f51\uff1b\u4f4d\u7f6e\u4e92\u6a21\u62df\u6bd4\u56e0\u679c\u7f51\u4e92\u6a21\u62df\u66f4\u7ec6\u81f4\uff0c\u540c\u6837\u53ef\u9006\u4e14\u5728\u6709\u9650\u7f51\u4e0b\u53ef\u5224\u5b9a\u3002\u800c\u4f20\u7edf\u7684\u9057\u4f20\u5386\u53f2\u4fdd\u7559\u4e92\u6a21\u62df\u867d\u7136\u66f4\u7c97\u7cd9\uff0c\u4f46\u5728\u5b89\u5168Petri\u7f51\u4e0b\u662f\u4e0d\u53ef\u5224\u5b9a\u7684\u3002", "conclusion": "\u672c\u6587\u4e3aPetri\u7f51\u4e2d\u771f\u5b9e\u5e76\u53d1\u8bed\u4e49\u4e0b\u63d0\u4f9b\u4e86\u4e24\u79cd\u65b0\u7684\u53ef\u5224\u5b9a\u4e14\u53ef\u9006\u7684\u884c\u4e3a\u7b49\u4ef7\u5173\u7cfb\u2014\u2014\u56e0\u679c\u7f51\u4e92\u6a21\u62df\u4e0e\u4f4d\u7f6e\u4e92\u6a21\u62df\uff0c\u4f5c\u4e3a\u4e0d\u53ef\u5224\u5b9a\u7684\u9057\u4f20\u5386\u53f2\u4fdd\u7559\u4e92\u6a21\u62df\u7684\u6709\u6548\u66ff\u4ee3\u3002"}}
{"id": "2506.11068", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11068", "abs": "https://arxiv.org/abs/2506.11068", "authors": ["Bumjin Park", "Jinsil Lee", "Jaesik Choi"], "title": "Deontological Keyword Bias: The Impact of Modal Expressions on Normative Judgments of Language Models", "comment": "20 pages including references and appendix; To appear in ACL 2025\n  main conference", "summary": "Large language models (LLMs) are increasingly engaging in moral and ethical\nreasoning, where criteria for judgment are often unclear, even for humans.\nWhile LLM alignment studies cover many areas, one important yet underexplored\narea is how LLMs make judgments about obligations. This work reveals a strong\ntendency in LLMs to judge non-obligatory contexts as obligations when prompts\nare augmented with modal expressions such as must or ought to. We introduce\nthis phenomenon as Deontological Keyword Bias (DKB). We find that LLMs judge\nover 90\\% of commonsense scenarios as obligations when modal expressions are\npresent. This tendency is consist across various LLM families, question types,\nand answer formats. To mitigate DKB, we propose a judgment strategy that\nintegrates few-shot examples with reasoning prompts. This study sheds light on\nhow modal expressions, as a form of linguistic framing, influence the normative\ndecisions of LLMs and underscores the importance of addressing such biases to\nensure judgment alignment.", "AI": {"tldr": "LLMs\u5728\u9053\u5fb7\u5224\u65ad\u65f6\u5bf9must\u3001ought to\u7b49\u60c5\u6001\u8bcd\u6781\u4e3a\u654f\u611f\uff0c\u6613\u8bef\u5c06\u975e\u4e49\u52a1\u5224\u4e3a\u4e49\u52a1\uff1b\u63d0\u51fa\u7684\u65b0\u65b9\u6cd5\u5bf9\u7f13\u89e3\u6b64\u504f\u5dee\u6709\u6548\uff0c\u63d0\u793a\u6a21\u578b\u5bf9\u9f50\u9700\u6b63\u89c6\u8bed\u8a00\u8868\u8ff0\u5e26\u6765\u7684\u5f71\u54cd\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u5728\u9053\u5fb7\u548c\u4f26\u7406\u63a8\u7406\u4e2d\u7684\u5e94\u7528\u8d8a\u6765\u8d8a\u5e7f\u6cdb\uff0c\u4f46\u4eba\u7c7b\u81ea\u8eab\u5bf9\u5224\u65ad\u6807\u51c6\u4e5f\u5e38\u5e38\u4e0d\u660e\u786e\u3002\u56e0\u6b64\uff0c\u5982\u4f55\u8ba9LLM\u5728\u5224\u65ad\u4e49\u52a1\u7c7b\u95ee\u9898\u65f6\u505a\u5230\u5408\u7406\u5bf9\u9f50\uff0c\u662f\u4e00\u4e2a\u88ab\u5ffd\u89c6\u7684\u91cd\u8981\u9886\u57df\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\uff0c\u5411\u6a21\u578b\u8f93\u5165\u5305\u542b\u60c5\u6001\u8bcd\uff08\u5982must, ought to\uff09\u7684\u60c5\u5883\uff0c\u5bf9\u6bd4\u5206\u6790LLM\u5728\u6709/\u65e0\u60c5\u6001\u8bcd\u65f6\u7684\u4e49\u52a1\u6027\u5224\u65ad\u8868\u73b0\uff0c\u5e76\u8de8\u591a\u6a21\u578b\u3001\u95ee\u53e5\u7c7b\u578b\u53ca\u7b54\u6848\u683c\u5f0f\u9a8c\u8bc1\u4e00\u81f4\u6027\u3002\u540c\u65f6\u63d0\u51fa\u7ed3\u5408few-shot\u793a\u4f8b\u548c\u63a8\u7406\u63d0\u793a\u7684\u7b56\u7565\u4ee5\u7f13\u89e3\u504f\u5dee\u3002", "result": "LLMs\u5bf9\u4e8e\u5e26\u6709\u60c5\u6001\u8bcd\u7684\u60c5\u5883\uff0c\u503e\u5411\u4e8e\u5c06\u539f\u672c\u975e\u4e49\u52a1\u6027\u7684\u60c5\u5883\u9519\u8bef\u5224\u65ad\u4e3a\u4e49\u52a1\u6027\uff08\u8d8590%\uff09\uff0c\u8be5\u73b0\u8c61\u88ab\u79f0\u4e3a\u201c\u4e49\u52a1\u5173\u952e\u8bcd\u504f\u5dee\uff08DKB\uff09\u201d\uff0c\u5e76\u4e14\u5728\u4e0d\u540c\u6a21\u578b\u548c\u8bbe\u7f6e\u4e0b\u90fd\u4fdd\u6301\u4e00\u81f4\u3002\u4f5c\u8005\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u8fd9\u4e00\u504f\u5dee\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u60c5\u6001\u8bcd\u4f5c\u4e3a\u8bed\u8a00\u6846\u67b6\u5982\u4f55\u663e\u8457\u5f71\u54cdLLM\u7684\u89c4\u8303\u6027\u5224\u65ad\uff0c\u5f3a\u8c03\u4e86\u6ce8\u610f\u548c\u4fee\u6b63\u6b64\u7c7b\u504f\u5dee\u5bf9\u6a21\u578b\u5bf9\u9f50\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.10985", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.10985", "abs": "https://arxiv.org/abs/2506.10985", "authors": ["Raman Mohammed Hussein", "Bryar A. Hassan"], "title": "Collaboration Tools and their Role in Agile Software Projects", "comment": "https://www.middleeastconference.org/_files/ugd/614b1f_82fa5f91169a44278723a921b27e2864.pdf\n  ISBN: 979-8-89695-015-8", "summary": "The purpose of this review is to understand the importance of collaboration\ntools which are Slack, Microsoft Teams, Confluence in Agile and software\nprojects. Agile methodologies rely on flexibility, using cycles and integration\nthroughout various levels of developing cycles. However, it is still a great\nproblem for many teams to collaborate and communicate even if staff members and\nteams are working remotely. In terms of collaboration, the applications and\ntechnologies mean better organization of work, increased mutually\nunderstandable openness and fast and efficient inter team and interpersonal\ninteractions to enhance results of projects into productivity. This paper\nexamines how these tools fit the Agile principles, how they facilitate\niterative development, and encouraging effective initiation and tracking of\ntasks in small and large projects. The insights focus on how Slack, Microsoft\nTeams, and Confluence are essential for gaining better task coordination,\nsupporting knowledge sharing, and adopting agile values across cross-functional\ncontexts.", "AI": {"tldr": "\u534f\u4f5c\u5de5\u5177\uff08Slack\u3001Teams\u3001Confluence\uff09\u5728\u654f\u6377\u8f6f\u4ef6\u9879\u76ee\u4e2d\u5bf9\u63d0\u5347\u6c9f\u901a\u3001\u77e5\u8bc6\u5171\u4eab\u548c\u4efb\u52a1\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u6709\u52a9\u56e2\u961f\u987a\u5229\u5b9e\u65bd\u654f\u6377\u5f00\u53d1\u7406\u5ff5\u3002", "motivation": "\u654f\u6377\u5f00\u53d1\u65b9\u6cd5\u5f3a\u8c03\u7075\u6d3b\u6027\u548c\u534f\u4f5c\uff0c\u4f46\u5f88\u591a\u8f6f\u4ef6\u5f00\u53d1\u56e2\u961f\uff0c\u5c24\u5176\u5728\u8fdc\u7a0b\u5de5\u4f5c\u73af\u5883\u4e0b\uff0c\u4f9d\u7136\u9762\u4e34\u6c9f\u901a\u548c\u534f\u4f5c\u7684\u96be\u9898\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u534f\u4f5c\u5de5\u5177\u5982Slack\u3001Microsoft Teams\u548cConfluence\u5728\u654f\u6377\u8f6f\u4ef6\u9879\u76ee\u4e2d\u7684\u4f5c\u7528\u5177\u6709\u5b9e\u9645\u610f\u4e49\u3002", "method": "\u672c\u6587\u901a\u8fc7\u7efc\u8ff0\u73b0\u6709\u6587\u732e\u548c\u5b9e\u9645\u5e94\u7528\uff0c\u5206\u6790\u4e0a\u8ff0\u534f\u4f5c\u5de5\u5177\u5982\u4f55\u5951\u5408\u654f\u6377\u539f\u5219\u3001\u4fc3\u8fdb\u8fed\u4ee3\u5f00\u53d1\uff0c\u5e76\u8003\u5bdf\u5b83\u4eec\u5982\u4f55\u5728\u5927\u5c0f\u578b\u9879\u76ee\u4e2d\u63d0\u5347\u4efb\u52a1\u53d1\u8d77\u4e0e\u8ddf\u8e2a\u7684\u6548\u7387\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cSlack\u3001Microsoft Teams\u548cConfluence\u53ef\u63d0\u5347\u56e2\u961f\u4efb\u52a1\u534f\u540c\u3001\u52a0\u5f3a\u77e5\u8bc6\u5171\u4eab\uff0c\u5e76\u6709\u52a9\u4e8e\u5728\u8de8\u804c\u80fd\u56e2\u961f\u4e2d\u8df5\u884c\u654f\u6377\u4ef7\u503c\u89c2\u3002\u5b83\u4eec\u4fc3\u8fdb\u4e86\u9ad8\u6548\u7684\u6c9f\u901a\u4e0e\u4efb\u52a1\u7ba1\u7406\uff0c\u4ece\u800c\u63d0\u5347\u9879\u76ee\u751f\u4ea7\u529b\u3002", "conclusion": "Slack\u3001Microsoft Teams\u548cConfluence\u662f\u654f\u6377\u4e0e\u8f6f\u4ef6\u5f00\u53d1\u9879\u76ee\u4e2d\u4e0d\u53ef\u6216\u7f3a\u7684\u534f\u4f5c\u5de5\u5177\uff0c\u6709\u6548\u652f\u6301\u4e86\u654f\u6377\u5f00\u53d1\u6240\u9700\u7684\u6c9f\u901a\u3001\u77e5\u8bc6\u4ea4\u6d41\u4e0e\u4efb\u52a1\u534f\u540c\uff0c\u4e3a\u56e2\u961f\u5e26\u6765\u66f4\u9ad8\u7684\u751f\u4ea7\u529b\u548c\u66f4\u597d\u7684\u9879\u76ee\u6210\u679c\u3002"}}
{"id": "2410.04194", "categories": ["cs.CL", "cs.FL"], "pdf": "https://arxiv.org/pdf/2410.04194", "abs": "https://arxiv.org/abs/2410.04194", "authors": ["Lan Zhang", "Xin Quan", "Andre Freitas"], "title": "Consistent Autoformalization for Constructing Mathematical Libraries", "comment": "EMNLP 2024 camera-ready", "summary": "Autoformalization is the task of automatically translating mathematical\ncontent written in natural language to a formal language expression. The\ngrowing language interpretation capabilities of Large Language Models (LLMs),\nincluding in formal languages, are lowering the barriers for autoformalization.\nHowever, LLMs alone are not capable of consistently and reliably delivering\nautoformalization, in particular as the complexity and specialization of the\ntarget domain grows. As the field evolves into the direction of systematically\napplying autoformalization towards large mathematical libraries, the need to\nimprove syntactic, terminological and semantic control increases. This paper\nproposes the coordinated use of three mechanisms, most-similar retrieval\naugmented generation (MS-RAG), denoising steps, and auto-correction with syntax\nerror feedback (Auto-SEF) to improve autoformalization quality. The empirical\nanalysis, across different models, demonstrates that these mechanisms can\ndeliver autoformalizaton results which are syntactically, terminologically and\nsemantically more consistent. These mechanisms can be applied across different\nLLMs and have shown to deliver improve results across different model types.", "AI": {"tldr": "\u4e3a\u63d0\u5347LLM\u5728\u6570\u5b66\u81ea\u52a8\u5f62\u5f0f\u5316\u4e2d\u7684\u8868\u73b0\uff0c\u4f5c\u8005\u63d0\u51fa\u7ed3\u5408\u6700\u76f8\u4f3c\u68c0\u7d22\u3001\u53bb\u566a\u548c\u81ea\u52a8\u4fee\u6b63\u673a\u5236\uff0c\u5e76\u9a8c\u8bc1\u6b64\u65b9\u6848\u53ef\u4ee5\u8de8\u6a21\u578b\u63d0\u5347\u7ed3\u679c\u4e00\u81f4\u6027\u4e0e\u8d28\u91cf\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u81ea\u7136\u8bed\u8a00\u548c\u5f62\u5f0f\u8bed\u8a00\u7406\u89e3\u4e0a\u7684\u8fdb\u6b65\uff0c\u81ea\u52a8\u5c06\u6570\u5b66\u81ea\u7136\u8bed\u8a00\u5185\u5bb9\u7ffb\u8bd1\u6210\u5f62\u5f0f\u5316\u8868\u8fbe\uff08\u81ea\u52a8\u5f62\u5f0f\u5316\uff0cautoformalization\uff09\u53d8\u5f97\u53ef\u80fd\uff0c\u4f46\u5728\u590d\u6742\u548c\u4e13\u4e1a\u9886\u57df\uff0c\u73b0\u6709LLM\u4ecd\u96be\u4ee5\u7a33\u5b9a\u3001\u53ef\u9760\u5730\u5b9e\u73b0\u8be5\u4efb\u52a1\u3002\u968f\u7740\u81ea\u52a8\u5f62\u5f0f\u5316\u9010\u6b65\u5e94\u7528\u4e8e\u5927\u578b\u6570\u5b66\u5e93\uff0c\u63d0\u9ad8\u8bed\u6cd5\u3001\u672f\u8bed\u548c\u8bed\u4e49\u7684\u63a7\u5236\u6210\u4e3a\u65b0\u9700\u6c42\u3002", "method": "\u672c\u6587\u63d0\u51fa\u8054\u5408\u4f7f\u7528\u4e09\u79cd\u673a\u5236\u6765\u63d0\u5347\u81ea\u52a8\u5f62\u5f0f\u5316\u8d28\u91cf\uff1a\u9488\u5bf9\u6700\u76f8\u4f3c\u5b9e\u4f8b\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08MS-RAG\uff09\u3001\u53bb\u566a\u6b65\u9aa4\u4ee5\u53ca\u5e26\u8bed\u6cd5\u9519\u8bef\u53cd\u9988\u7684\u81ea\u52a8\u4fee\u6b63\uff08Auto-SEF\uff09\u3002\u8fd9\u4e9b\u673a\u5236\u88ab\u8bbe\u8ba1\u4e3a\u80fd\u591f\u5d4c\u5165\u4e0d\u540c\u7c7b\u578b\u7684LLM\u4e2d\u3002", "result": "\u5b9e\u8bc1\u5206\u6790\u663e\u793a\uff0c\u8fd9\u4e09\u79cd\u673a\u5236\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u81ea\u52a8\u5f62\u5f0f\u5316\u8f93\u51fa\u5728\u8bed\u6cd5\u3001\u672f\u8bed\u548c\u8bed\u4e49\u65b9\u9762\u7684\u4e00\u81f4\u6027\uff0c\u4e14\u5728\u4e0d\u540c\u7c7b\u578b\u7684LLM\u4e2d\u5747\u6709\u6548\u3002", "conclusion": "\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u81ea\u52a8\u5f62\u5f0f\u5316\u4efb\u52a1\u7684\u8d28\u91cf\u4e0e\u9c81\u68d2\u6027\uff0c\u5bf9\u5927\u578b\u6570\u5b66\u5e93\u7684\u81ea\u52a8\u5316\u5f62\u5f0f\u5316\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.11176", "categories": ["cs.SE", "cs.DC", "cs.DM", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.11176", "abs": "https://arxiv.org/abs/2506.11176", "authors": ["Anatoly A. Krasnovsky", "Alexander Zorkin"], "title": "Model Discovery and Graph Simulation: A Lightweight Alternative to Chaos Engineering", "comment": null, "summary": "Microservice applications are prone to cascading failures because of dense\ninter-service dependencies. Ensuring resilience usually demands fault-injection\nexperiments in production-like setups. We propose \\textit{model discovery} --\nan automated CI/CD step that extracts a live dependency graph from trace data\n-- and show that this lightweight representation is sufficient for accurate\nresilience prediction. Using the DeathStarBench Social Network, we build the\ngraph, simulate failures via Monte-Carlo, and run matching chaos experiments on\nthe real system. The graph model closely matches reality: with no replication,\n16 trials yield an observed resilience of 0.186 versus a predicted 0.161; with\nreplication, both observed and predicted values converge to 0.305 (mean\nabsolute error \\leq 0.0004). These results indicate that even a simple,\nautomatically discovered graph can estimate microservice availability with high\nfidelity, offering rapid design-time insight without full-scale failure\ntesting.", "AI": {"tldr": "\u63d0\u51fa\u7528\u8ffd\u8e2a\u6570\u636e\u81ea\u52a8\u63d0\u53d6\u4f9d\u8d56\u5173\u7cfb\u56fe\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u9884\u6d4b\u5fae\u670d\u52a1\u7cfb\u7edf\u5f39\u6027\uff0c\u7ed3\u679c\u8868\u660e\u5373\u4f7f\u7b80\u5355\u7684\u81ea\u52a8\u56fe\u6a21\u578b\u4e5f\u80fd\u51c6\u786e\u4f30\u7b97\u7cfb\u7edf\u53ef\u7528\u6027\uff0c\u51cf\u5c11\u5bf9\u6602\u8d35\u6545\u969c\u6ce8\u5165\u5b9e\u9a8c\u7684\u4f9d\u8d56\u3002", "motivation": "\u5fae\u670d\u52a1\u5e94\u7528\u7531\u4e8e\u670d\u52a1\u95f4\u7684\u9ad8\u5ea6\u4f9d\u8d56\uff0c\u5bb9\u6613\u53d1\u751f\u7ea7\u8054\u6545\u969c\u3002\u73b0\u6709\u7684\u5f39\u6027\u4fdd\u969c\u624b\u6bb5\u901a\u5e38\u9700\u8981\u5728\u63a5\u8fd1\u771f\u5b9e\u73af\u5883\u4e2d\u8fdb\u884c\u6545\u969c\u6ce8\u5165\u5b9e\u9a8c\uff0c\u4ee3\u4ef7\u9ad8\u6602\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u6a21\u578b\u53d1\u73b0\u201d\uff08model discovery\uff09\u7684\u81ea\u52a8\u5316CI/CD\u6b65\u9aa4\uff0c\u80fd\u591f\u901a\u8fc7\u8ffd\u8e2a\u6570\u636e\u81ea\u52a8\u63d0\u53d6\u5b9e\u65f6\u4f9d\u8d56\u56fe\uff0c\u5e76\u57fa\u4e8e\u6b64\u56fe\u5229\u7528\u8499\u7279\u5361\u6d1b\u6a21\u62df\u8fdb\u884c\u6545\u969c\u4eff\u771f\u548c\u5f39\u6027\u8bc4\u4f30\uff1b\u5e76\u7ed3\u5408\u5b9e\u9645\u6df7\u6c8c\u5b9e\u9a8c\u8fdb\u884c\u5bf9\u6bd4\u9a8c\u8bc1\u3002", "result": "\u53d1\u73b0\u901a\u8fc7\u81ea\u52a8\u53d1\u73b0\u7684\u4f9d\u8d56\u56fe\u6784\u5efa\u7684\u6a21\u578b\u5728\u6545\u969c\u5f39\u6027\u9884\u6d4b\u4e0a\u4e0e\u771f\u5b9e\u7cfb\u7edf\u975e\u5e38\u63a5\u8fd1\u3002\u65e0\u526f\u672c\u65f6\u4eff\u771f\u4e0e\u5b9e\u9a8c\u5f39\u6027\u5206\u522b\u4e3a0.161\u548c0.186\uff1b\u6709\u526f\u672c\u65f6\u4eff\u771f\u4e0e\u5b9e\u9a8c\u90fd\u6536\u655b\u52300.305\uff08\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u22640.0004\uff09\u3002", "conclusion": "\u81ea\u52a8\u5316\u751f\u6210\u7684\u4f9d\u8d56\u5173\u7cfb\u56fe\u53ef\u9ad8\u4fdd\u771f\u5730\u9884\u4f30\u5fae\u670d\u52a1\u53ef\u7528\u6027\uff0c\u80fd\u4e3a\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u5feb\u901f\u7684\u5f39\u6027\u6d1e\u5bdf\uff0c\u800c\u65e0\u9700\u5168\u9762\u7684\u6545\u969c\u6ce8\u5165\u5b9e\u9a8c\u3002"}}
{"id": "2506.11085", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.IR", "cs.LG", "cs.LO", "I.2.6; H.3.3; I.2.3"], "pdf": "https://arxiv.org/pdf/2506.11085", "abs": "https://arxiv.org/abs/2506.11085", "authors": ["Justin Asher"], "title": "LeanExplore: A search engine for Lean 4 declarations", "comment": "16 pages, 1 figure. Project website: https://www.leanexplore.com/ ,\n  Code: https://github.com/justincasher/lean-explore", "summary": "The expanding Lean 4 ecosystem poses challenges for navigating its vast\nlibraries. This paper introduces LeanExplore, a search engine for Lean 4\ndeclarations. LeanExplore enables users to semantically search for statements,\nboth formally and informally, across select Lean 4 packages (including\nBatteries, Init, Lean, Mathlib, PhysLean, and Std). This search capability is\npowered by a hybrid ranking strategy, integrating scores from a multi-source\nsemantic embedding model (capturing conceptual meaning from formal Lean code,\ndocstrings, AI-generated informal translations, and declaration titles), BM25+\nfor keyword-based lexical relevance, and a PageRank-based score reflecting\ndeclaration importance and interconnectedness. The search engine is accessible\nvia a dedicated website (https://www.leanexplore.com/) and a Python API\n(https://github.com/justincasher/lean-explore). Furthermore, the database can\nbe downloaded, allowing users to self-host the service. LeanExplore integrates\neasily with LLMs via the model context protocol (MCP), enabling users to chat\nwith an AI assistant about Lean declarations or utilize the search engine for\nbuilding theorem-proving agents. This work details LeanExplore's architecture,\ndata processing, functionalities, and its potential to enhance Lean 4 workflows\nand AI-driven mathematical research", "AI": {"tldr": "LeanExplore\u662f\u4e00\u4e2a\u652f\u6301\u8bed\u4e49\u68c0\u7d22\u7684Lean 4\u5e93\u58f0\u660e\u641c\u7d22\u5f15\u64ce\uff0c\u7ed3\u5408\u591a\u79cd\u6392\u5e8f\u4e0e\u8bed\u4e49\u7406\u89e3\u6a21\u578b\uff0c\u4ea7\u54c1\u5f00\u653e\u591a\u5e73\u53f0\u63a5\u5165\uff0c\u4fbf\u5229Lean\u7528\u6237\u548cAI\u52a9\u624b\u67e5\u8be2\uff0c\u63d0\u5347\u6570\u5b66\u4e0e\u5b9a\u7406\u8bc1\u660e\u76f8\u5173\u7814\u53d1\u7684\u6548\u7387\u3002", "motivation": "Lean 4\u751f\u6001\u7cfb\u7edf\u7684\u6301\u7eed\u6269\u5c55\u4f7f\u5f97\u5728\u5e9e\u5927\u7684\u5e93\u4e2d\u67e5\u627e\u548c\u5bfc\u822a\u53d8\u5f97\u6108\u53d1\u56f0\u96be\uff0c\u7528\u6237\u548c\u5f00\u53d1\u8005\u8feb\u5207\u9700\u8981\u9ad8\u6548\u5de5\u5177\u6765\u68c0\u7d22\u76f8\u5173\u58f0\u660e\u548c\u77e5\u8bc6\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aLeanExplore\u7684\u641c\u7d22\u5f15\u64ce\uff0c\u91c7\u7528\u591a\u6e90\u8bed\u4e49\u5d4c\u5165\u6a21\u578b\u3001BM25+\u5173\u952e\u8bcd\u5339\u914d\u548c\u57fa\u4e8ePageRank\u7684\u8bc4\u5206\u76f8\u7ed3\u5408\u7684\u6df7\u5408\u6392\u5e8f\u7b56\u7565\uff0c\u5b9e\u73b0\u5bf9Lean 4\u591a\u4e2a\u4e3b\u6d41\u5e93\uff08\u5982Batteries\u3001Init\u3001Lean\u3001Mathlib\u3001PhysLean\u548cStd\uff09\u4e2d\u58f0\u660e\u7684\u9ad8\u6548\u8bed\u4e49\u641c\u7d22\uff0c\u5e76\u652f\u6301\u591a\u7ec8\u7aef\u8bbf\u95ee\uff08\u7f51\u7ad9\u3001Python API\u3001\u672c\u5730\u90e8\u7f72\uff09\u3002", "result": "LeanExplore\u53ef\u4ee5\u5bf9\u5f62\u5f0f\u548c\u975e\u5f62\u5f0f\u58f0\u660e\u8fdb\u884c\u8bed\u4e49\u68c0\u7d22\uff0c\u652f\u6301\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u96c6\u6210\uff0c\u5b9e\u73b0AI\u52a9\u624b\u67e5\u8be2Lean\u58f0\u660e\u6216\u8f85\u52a9\u5b9a\u7406\u8bc1\u660e\u3002\u4f5c\u8005\u8fd8\u516c\u5f00\u4e86\u6570\u636e\u5e93\u4e0b\u8f7d\u548c\u591a\u5e73\u53f0\u63a5\u5165\u80fd\u529b\uff0c\u5c55\u793a\u4e86\u67b6\u6784\u3001\u6570\u636e\u5904\u7406\u548c\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "LeanExplore\u4e3aLean 4\u751f\u6001\u5e26\u6765\u9ad8\u6548\u7684\u58f0\u660e\u68c0\u7d22\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u5f00\u53d1\u8005\u5de5\u4f5c\u6d41\u4e0eAI\u9a71\u52a8\u7684\u6570\u5b66\u7814\u7a76\u6548\u7387\uff0c\u5e76\u4fc3\u8fdb\u5e93\u4e4b\u95f4\u7684\u77e5\u8bc6\u4e92\u8054\u4e92\u901a\u3002"}}
{"id": "2506.11209", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2506.11209", "abs": "https://arxiv.org/abs/2506.11209", "authors": ["Zhengyang Liu", "Vinod Grover"], "title": "A Performance Model for Warp Specialization Kernels", "comment": null, "summary": "This paper presents a performance model tailored for warp specialization\nkernels, focusing on factors such as warp size, tilling size, input matrix\nsize, memory bandwidth, and thread divergence. Our model offers accurate\npredictions of execution time by leveraging differential equations validated\nthrough simulations and experiments. The insights gained from this model not\nonly enhance our understanding of warp specialization techniques but also have\npractical implications for optimizing GPU-accelerated applications through\ncompiler optimizations, kernel parameter tuning, and algorithm design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u4e2a\u80fd\u51c6\u786e\u9884\u6d4bGPU warp specialization kernel\u6267\u884c\u65f6\u95f4\u7684\u6027\u80fd\u6a21\u578b\uff0c\u5bf9\u76f8\u5173\u53c2\u6570\u4f18\u5316\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u5f53\u524dGPU\u52a0\u901f\u8ba1\u7b97\u4e2d\uff0cwarp specialization\u6280\u672f\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u5176\u6267\u884c\u6548\u7387\u53d7\u591a\u79cd\u53c2\u6570\u5f71\u54cd\uff0c\u5982warp\u5927\u5c0f\u3001tiling\u5927\u5c0f\u3001\u5185\u5b58\u5e26\u5bbd\u7b49\u3002\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u51c6\u786e\u7684\u6027\u80fd\u6a21\u578b\u5e2e\u52a9\u5206\u6790\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5dee\u5206\u65b9\u7a0b\u7684\u6027\u80fd\u6a21\u578b\uff0c\u80fd\u591f\u91cf\u5316warp size\u3001tiling size\u3001\u8f93\u5165\u77e9\u9635\u5927\u5c0f\u3001\u5185\u5b58\u5e26\u5bbd\u548c\u7ebf\u7a0b\u5206\u6b67\u7b49\u56e0\u7d20\u5bf9warp specialization kernel\u7684\u6267\u884c\u65f6\u95f4\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u4eff\u771f\u548c\u5b9e\u9a8c\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u6a21\u578b\u80fd\u51c6\u786e\u9884\u6d4bGPU warp specialization kernel\u7684\u6267\u884c\u65f6\u95f4\uff0c\u63d0\u4f9b\u6027\u80fd\u5f71\u54cd\u56e0\u7d20\u7684\u6df1\u5165\u89c1\u89e3\uff0c\u4e3a\u4f18\u5316GPU\u5e94\u7528\uff08\u7f16\u8bd1\u5668\u4f18\u5316\u3001kernel\u53c2\u6570\u8c03\u4f18\u3001\u7b97\u6cd5\u8bbe\u8ba1\uff09\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002", "conclusion": "\u63d0\u51fa\u7684\u6027\u80fd\u6a21\u578b\u63d0\u5347\u4e86\u5bf9GPU warp specialization\u6280\u672f\u7684\u7406\u89e3\uff0c\u5e76\u5177\u6709\u5b9e\u9645\u6307\u5bfc\u610f\u4e49\uff0c\u6709\u5229\u4e8e\u76f8\u5173\u5e94\u7528\u7684\u4f18\u5316\u3002"}}
{"id": "2506.11070", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11070", "abs": "https://arxiv.org/abs/2506.11070", "authors": ["Yu-Zhe Shi", "Mingchen Liu", "Hanlu Ma", "Qiao Xu", "Huamin Qu", "Kun He", "Lecheng Ruan", "Qining Wang"], "title": "Targeted control of fast prototyping through domain-specific interface", "comment": "In International Conference on Machine Learning (ICML'25)", "summary": "Industrial designers have long sought a natural and intuitive way to achieve\nthe targeted control of prototype models -- using simple natural language\ninstructions to configure and adjust the models seamlessly according to their\nintentions, without relying on complex modeling commands. While Large Language\nModels have shown promise in this area, their potential for controlling\nprototype models through language remains partially underutilized. This\nlimitation stems from gaps between designers' languages and modeling languages,\nincluding mismatch in abstraction levels, fluctuation in semantic precision,\nand divergence in lexical scopes. To bridge these gaps, we propose an interface\narchitecture that serves as a medium between the two languages. Grounded in\ndesign principles derived from a systematic investigation of fast prototyping\npractices, we devise the interface's operational mechanism and develop an\nalgorithm for its automated domain specification. Both machine-based\nevaluations and human studies on fast prototyping across various product design\ndomains demonstrate the interface's potential to function as an auxiliary\nmodule for Large Language Models, enabling precise and effective targeted\ncontrol of prototype models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8fde\u63a5\u8bbe\u8ba1\u5e08\u81ea\u7136\u8bed\u8a00\u548c\u5efa\u6a21\u8bed\u8a00\u7684\u63a5\u53e3\u67b6\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u4ea7\u54c1\u539f\u578b\u5feb\u901f\u5efa\u6a21\u7684\u4fbf\u6377\u6027\u548c\u63a7\u5236\u7cbe\u5ea6\uff0c\u7ecf\u591a\u79cd\u8bc4\u4f30\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u5de5\u4e1a\u8bbe\u8ba1\u5e08\u5e0c\u671b\u80fd\u591f\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\uff0c\u7b80\u5355\u76f4\u89c2\u5730\u5bf9\u539f\u578b\u6a21\u578b\u8fdb\u884c\u7cbe\u51c6\u63a7\u5236\uff0c\u907f\u514d\u590d\u6742\u7684\u5efa\u6a21\u547d\u4ee4\uff0c\u4f46\u76ee\u524d\u5728\u8bed\u8a00\u4e0e\u5efa\u6a21\u8bed\u8a00\u4e4b\u95f4\u5b58\u5728\u62bd\u8c61\u5c42\u6b21\u3001\u8bed\u4e49\u7cbe\u5ea6\u548c\u8bcd\u6c47\u8303\u56f4\u7b49\u5dee\u5f02\uff0c\u963b\u788d\u4e86\u6b64\u7c7b\u81ea\u7136\u4ea4\u4e92\u7684\u5b9e\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u63a5\u53e3\u67b6\u6784\uff0c\u4f5c\u4e3a\u8bbe\u8ba1\u5e08\u81ea\u7136\u8bed\u8a00\u4e0e\u5efa\u6a21\u8bed\u8a00\u4e4b\u95f4\u7684\u6865\u6881\u3002\u67b6\u6784\u8bbe\u8ba1\u57fa\u4e8e\u5bf9\u5feb\u901f\u539f\u578b\u5b9e\u8df5\u7684\u7cfb\u7edf\u8c03\u67e5\u63d0\u70bc\u7684\u8bbe\u8ba1\u539f\u5219\uff0c\u8fd8\u5f00\u53d1\u4e86\u5176\u64cd\u4f5c\u673a\u5236\u53ca\u81ea\u52a8\u5316\u9886\u57df\u89c4\u8303\u7b97\u6cd5\uff0c\u901a\u8fc7\u673a\u5668\u8bc4\u4f30\u548c\u7528\u6237\u7814\u7a76\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u7ecf\u673a\u5668\u8bc4\u4f30\u4e0e\u4eba\u5de5\u7528\u6237\u7814\u7a76\uff0c\u63a5\u53e3\u4f5c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f85\u52a9\u6a21\u5757\uff0c\u80fd\u591f\u5b9e\u73b0\u5bf9\u539f\u578b\u6a21\u578b\u7684\u7cbe\u786e\u3001\u6709\u6548\u7684\u76ee\u6807\u63a7\u5236\uff0c\u5728\u591a\u79cd\u4ea7\u54c1\u8bbe\u8ba1\u573a\u666f\u4e2d\u5747\u663e\u793a\u51fa\u826f\u597d\u6548\u679c\u3002", "conclusion": "\u8be5\u63a5\u53e3\u67b6\u6784\u6709\u6548\u5f25\u5408\u4e86\u8bbe\u8ba1\u5e08\u81ea\u7136\u8bed\u8a00\u548c\u5efa\u6a21\u8bed\u8a00\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u5de5\u4e1a\u8bbe\u8ba1\u539f\u578b\u5efa\u6a21\u7684\u5b9e\u7528\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2506.10986", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.10986", "abs": "https://arxiv.org/abs/2506.10986", "authors": ["Mouna Dhaouadi", "Bentley James Oakes", "Michalis Famelis"], "title": "CoMRAT: Commit Message Rationale Analysis Tool", "comment": null, "summary": "In collaborative open-source development, the rationale for code changes is\noften captured in commit messages, making them a rich source of valuable\ninformation. However, research on rationale in commit messages remains limited.\nIn this paper, we present CoMRAT, a tool for analyzing decision and rationale\nsentences rationale in commit messages. CoMRAT enables a) researchers to\nproduce metrics and analyses on rationale information in any Github module, and\nb) developers to check the amount of rationale in their commit messages. A\npreliminary evaluation suggests the tool's usefulness and usability in both\nthese research and development contexts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86 CoMRAT \u5de5\u5177\uff0c\u53ef\u4ee5\u81ea\u52a8\u5206\u6790 GitHub commit message \u4e2d\u7684\u51b3\u7b56\u548c\u7406\u7531\u53e5\u5b50\uff0c\u8f85\u52a9\u7814\u7a76\u4e0e\u5f00\u53d1\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u5de5\u5177\u5177\u6709\u8f83\u597d\u5b9e\u7528\u6027\u3002", "motivation": "\u867d\u7136 commit message \u4e2d\u8574\u542b\u4e30\u5bcc\u51b3\u7b56\u4e0e\u7406\u7531\u4fe1\u606f\uff0c\u4f46\u76f8\u5173\u5206\u6790\u7814\u7a76\u4ecd\u663e\u4e0d\u8db3\uff0c\u56e0\u6b64\u5f00\u53d1\u4e86\u4e00\u79cd\u5de5\u5177\u5e2e\u52a9\u6df1\u5165\u6316\u6398\u4e0e\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86 CoMRAT \u5de5\u5177\uff0c\u80fd\u591f\u5206\u6790 GitHub \u63d0\u4ea4\u4fe1\u606f\u4e2d\u7684\u51b3\u7b56\u548c\u7406\u7531\u7c7b\u53e5\u5b50\uff0c\u5e76\u7528\u4e8e\u6307\u6807\u751f\u6210\u548c\u91cf\u5316\u5206\u6790\u3002", "result": "\u521d\u6b65\u8bc4\u4f30\u663e\u793a\uff0cCoMRAT \u6709\u52a9\u4e8e\u7814\u7a76\u8005\u8fdb\u884c\u76f8\u5173\u6307\u6807\u5206\u6790\uff0c\u4e5f\u65b9\u4fbf\u5f00\u53d1\u8005\u81ea\u6211\u8bc4\u4f30 commit message \u7684\u7406\u7531\u6210\u5206\u8986\u76d6\u60c5\u51b5\u3002", "conclusion": "CoMRAT \u5de5\u5177\u5bf9\u7814\u7a76\u8005\u5206\u6790\u3001\u5f00\u53d1\u8005\u81ea\u67e5 commit \u4fe1\u606f\u5747\u8868\u73b0\u6709\u7528\u4e14\u6613\u7528\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.10993", "categories": ["cs.SE", "cs.FL", "68N30, 68Q60", "D.2.4; D.2.1; F.3.1"], "pdf": "https://arxiv.org/pdf/2506.10993", "abs": "https://arxiv.org/abs/2506.10993", "authors": ["Muhammad Naeem", "Cristina Seceleanu"], "title": "Contract-based Verification of Digital Twins", "comment": "Accepted at ICECCS 2025, to appear in Lecture Notes in Computer\n  Science (LNCS), Springer", "summary": "Digital twins are becoming powerful tools in industrial applications,\noffering virtual representations of cyber-physical systems. However,\nverification of these models remains a significant challenge due to the\npotentially large datasets used by the digital twin. This paper introduces an\ninnovative methodology for verifying neural network-based digital twin models,\nin a black-box fashion, by integrating model checking into the process. The\nlatter relies on defining and applying system-level contracts that capture the\nsystem's requirements, to verify the behavior of digital twin models,\nimplemented in Simulink. We develop an automated solution that simulates the\ndigital twin model for certain inputs, and feeds the predicted outputs together\nwith the inputs to the contract model described as a network of timed automata\nin the UPPAAL model checker. The latter verifies whether the predicted outputs\nfulfill the specified contracts. This approach allows us to identify scenarios\nwhere the digital twin's behavior fails to meet the contracts, without\nrequiring the digital twin's design technicalities. We apply our method to a\nboiler system case study for which we identify prediction errors via contract\nverification. Our work demonstrates the effectiveness of integrating model\nchecking with digital twin models for continuous improvement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6a21\u578b\u68c0\u9a8c\u7684\u81ea\u52a8\u5316\u9ed1\u7bb1\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u795e\u7ecf\u7f51\u7edc\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u7684\u9a8c\u8bc1\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u5e76\u5728\u9505\u7089\u7cfb\u7edf\u573a\u666f\u4e0b\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u6027\u548c\u6709\u6548\u6027\u3002", "motivation": "\u6570\u5b57\u5b6a\u751f\u5728\u5de5\u4e1a\u9886\u57df\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u5176\u6a21\u578b\u5c24\u5176\u662f\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u9a8c\u8bc1\u96be\u5ea6\u8f83\u5927\uff0c\u5c24\u5176\u56e0\u4e3a\u6d89\u53ca\u5e9e\u5927\u7684\u6570\u636e\u96c6\u548c\u201c\u9ed1\u7bb1\u201d\u7ed3\u6784\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u9a8c\u8bc1\u673a\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u65b9\u6cd5\uff0c\u5c06\u6a21\u578b\u68c0\u9a8c\uff08model checking\uff09\u5f15\u5165\u5bf9\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u7684\u201c\u9ed1\u7bb1\u201d\u9a8c\u8bc1\u6d41\u7a0b\u4e2d\u3002\u901a\u8fc7\u5b9a\u4e49\u7cfb\u7edf\u7ea7\u5951\u7ea6\uff0c\u5e76\u5229\u7528UPPAAL\u6a21\u578b\u68c0\u9a8c\u5668\u5bf9Simulink\u5b9e\u73b0\u7684\u6570\u5b57\u5b6a\u751f\u8fdb\u884c\u81ea\u52a8\u5316\u4eff\u771f\u4e0e\u5951\u7ea6\u9a8c\u8bc1\uff0c\u65e0\u9700\u4e86\u89e3\u6a21\u578b\u5177\u4f53\u5185\u90e8\u6280\u672f\u7ec6\u8282\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u627e\u51fa\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u884c\u4e3a\u4e0d\u7b26\u5408\u5951\u7ea6\u8981\u6c42\u7684\u573a\u666f\u3002\u4ee5\u9505\u7089\u7cfb\u7edf\u4e3a\u6848\u4f8b\uff0c\u6210\u529f\u901a\u8fc7\u5951\u7ea6\u9a8c\u8bc1\u53d1\u73b0\u4e86\u9884\u6d4b\u9519\u8bef\u3002", "conclusion": "\u5c06\u6a21\u578b\u68c0\u9a8c\u6280\u672f\u5d4c\u5165\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u9a8c\u8bc1\u6d41\u7a0b\u4e2d\uff0c\u53ef\u4ee5\u63d0\u5347\u5176\u6a21\u578b\u9a8c\u8bc1\u7684\u7cfb\u7edf\u6027\u548c\u81ea\u52a8\u5316\u7a0b\u5ea6\uff0c\u6709\u52a9\u4e8e\u5176\u6301\u7eed\u6539\u8fdb\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u83b7\u53d6\u6216\u7406\u89e3\u6570\u5b57\u5b6a\u751f\u5185\u90e8\u7ec6\u8282\uff0c\u5bf9\u4e8e\u5de5\u4e1a\u5e94\u7528\u5177\u6709\u63a8\u5e7f\u610f\u4e49\u3002"}}
{"id": "2506.11701", "categories": ["cs.PL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2506.11701", "abs": "https://arxiv.org/abs/2506.11701", "authors": ["Lukas Gehring", "Sebastian Rehms", "Florian Tschorsch"], "title": "PermRust: A Token-based Permission System for Rust", "comment": "11 pages", "summary": "Permission systems which restrict access to system resources are a\nwell-established technology in operating systems, especially for smartphones.\nHowever, as such systems are implemented in the operating system they can at\nmost manage access on the process-level. Since moderns software often (re)uses\ncode from third-parties libraries, a permission system for libraries can be\ndesirable to enhance security. In this short-paper, we adapt concepts from\ncapability systems building a novel theoretical foundation for permission\nsystem at the level of the programming language. This leads to PermRust, a\ntoken-based permission system for the Rust programming language as a zero cost\nabstraction on top of its type-system. With it access to system resources can\nbe managed per library.", "AI": {"tldr": "\u57fa\u4e8e\u80fd\u529b\u7cfb\u7edf\u7406\u8bba\uff0c\u4f5c\u8005\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u9002\u7528\u4e8e Rust \u7684\u5e93\u7ea7\u6743\u9650\u7cfb\u7edf PermRust\uff0c\u5b9e\u73b0\u4e86\u66f4\u5b89\u5168\u548c\u7ec6\u7c92\u5ea6\u7684\u8d44\u6e90\u8bbf\u95ee\u63a7\u5236\u3002", "motivation": "\u4f20\u7edf\u7684\u7cfb\u7edf\u6743\u9650\u7ba1\u7406\u53ea\u80fd\u63a7\u5236\u5230\u8fdb\u7a0b\u7ea7\u522b\uff0c\u4f46\u73b0\u4ee3\u8f6f\u4ef6\u5927\u91cf\u4f7f\u7528\u7b2c\u4e09\u65b9\u5e93\uff0c\u56e0\u6b64\u4e9f\u9700\u5bf9\u5e93\u7ea7\u522b\u7684\u6743\u9650\u8fdb\u884c\u63a7\u5236\uff0c\u4ee5\u63d0\u5347\u5b89\u5168\u6027\u3002", "method": "\u501f\u9274\u80fd\u529b\u7cfb\u7edf\uff08capability systems\uff09\u7684\u7406\u5ff5\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u7f16\u7a0b\u8bed\u8a00\u5c42\u9762\u7684\u6743\u9650\u7ba1\u7406\u7406\u8bba\uff0c\u5e76\u5b9e\u73b0\u4e86 PermRust\u2014\u2014\u4e00\u4e2a\u57fa\u4e8e\u4ee4\u724c\u7684Rust\u6743\u9650\u7cfb\u7edf\uff0c\u7ed3\u5408Rust\u7c7b\u578b\u7cfb\u7edf\u5b9e\u73b0\u96f6\u6210\u672c\u62bd\u8c61\u3002", "result": "PermRust \u5b9e\u73b0\u4e86\u6309\u5e93\u7c92\u5ea6\u7684\u6743\u9650\u7ba1\u7406\uff0c\u5141\u8bb8\u5f00\u53d1\u8005\u66f4\u7ec6\u7c92\u5ea6\u5730\u63a7\u5236\u5bf9\u7cfb\u7edf\u8d44\u6e90\u7684\u8bbf\u95ee\u3002", "conclusion": "PermRust \u4e3a\u5b9e\u73b0\u7f16\u7a0b\u8bed\u8a00\u7ea7\u522b\u7684\u3001\u7ec6\u7c92\u5ea6\u7684\u6743\u9650\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u4e0e\u5b9e\u8df5\u57fa\u7840\uff0c\u4e3a\u7b2c\u4e09\u65b9\u5e93\u7684\u6743\u9650\u589e\u5f3a\u4e86\u5b89\u5168\u6027\u3002"}}
{"id": "2506.11073", "categories": ["cs.CL", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.11073", "abs": "https://arxiv.org/abs/2506.11073", "authors": ["Zekai Ye", "Qiming Li", "Xiaocheng Feng", "Libo Qin", "Yichong Huang", "Baohang Li", "Kui Jiang", "Yang Xiang", "Zhirui Zhang", "Yunfei Lu", "Duyu Tang", "Dandan Tu", "Bing Qin"], "title": "CLAIM: Mitigating Multilingual Object Hallucination in Large Vision-Language Models with Cross-Lingual Attention Intervention", "comment": "ACL2025 Main", "summary": "Large Vision-Language Models (LVLMs) have demonstrated impressive multimodal\nabilities but remain prone to multilingual object hallucination, with a higher\nlikelihood of generating responses inconsistent with the visual input when\nutilizing queries in non-English languages compared to English. Most existing\napproaches to address these rely on pretraining or fine-tuning, which are\nresource-intensive. In this paper, inspired by observing the disparities in\ncross-modal attention patterns across languages, we propose Cross-Lingual\nAttention Intervention for Mitigating multilingual object hallucination (CLAIM)\nin LVLMs, a novel near training-free method by aligning attention patterns.\nCLAIM first identifies language-specific cross-modal attention heads, then\nestimates language shift vectors from English to the target language, and\nfinally intervenes in the attention outputs during inference to facilitate\ncross-lingual visual perception capability alignment. Extensive experiments\ndemonstrate that CLAIM achieves an average improvement of 13.56% (up to 30% in\nSpanish) on the POPE and 21.75% on the hallucination subsets of the MME\nbenchmark across various languages. Further analysis reveals that multilingual\nattention divergence is most prominent in intermediate layers, highlighting\ntheir critical role in multilingual scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u7684\u3001\u51e0\u4e4e\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5CLAIM\uff0c\u901a\u8fc7\u5bf9\u9f50\u8de8\u8bed\u8a00\u6ce8\u610f\u529b\u6a21\u5f0f\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u89c6\u89c9-\u8bed\u8a00\u5927\u6a21\u578b\u5728\u975e\u82f1\u8bed\u73af\u5883\u4e0b\u7684\u7269\u4f53\u5e7b\u89c9\u95ee\u9898\uff0c\u5e76\u5728\u591a\u9879\u57fa\u51c6\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u66f4\u5bb9\u6613\u4ea7\u751f\u7269\u4f53\u5e7b\u89c9\uff08\u5373\u56de\u7b54\u5185\u5bb9\u4e0e\u89c6\u89c9\u8f93\u5165\u4e0d\u7b26\uff09\uff0c\u5c24\u5176\u5728\u975e\u82f1\u8bed\u67e5\u8be2\u4e0b\u66f4\u4e3a\u4e25\u91cd\u3002\u73b0\u6709\u7f13\u89e3\u65b9\u6cd5\u4f9d\u8d56\u9884\u8bad\u7ec3\u6216\u5fae\u8c03\uff0c\u8d44\u6e90\u6d88\u8017\u5927\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u51e0\u4e4e\u65e0\u9700\u8bad\u7ec3\u7684\u65b0\u65b9\u6cd5CLAIM\uff08\u8de8\u8bed\u8a00\u6ce8\u610f\u529b\u5e72\u9884\uff09\uff0c\u901a\u8fc7\u5bf9\u9f50\u4e0d\u540c\u8bed\u8a00\u4e0b\u6ce8\u610f\u529b\u6a21\u5f0f\u6765\u7f13\u89e3\u591a\u8bed\u8a00\u7269\u4f53\u5e7b\u89c9\u3002CLAIM\u5177\u4f53\u5305\u62ec\uff1a1\uff09\u8bc6\u522b\u51fa\u8bed\u8a00\u7279\u5b9a\u7684\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u5934\uff1b2\uff09\u4f30\u7b97\u4ece\u82f1\u8bed\u5230\u76ee\u6807\u8bed\u8a00\u7684\u6ce8\u610f\u529b\u504f\u79fb\u5411\u91cf\uff1b3\uff09\u5728\u63a8\u7406\u9636\u6bb5\u8c03\u6574\u6ce8\u610f\u529b\u8f93\u51fa\uff0c\u4ee5\u63d0\u9ad8\u4e0d\u540c\u8bed\u8a00\u4e0b\u7684\u89c6\u89c9\u611f\u77e5\u5bf9\u9f50\u80fd\u529b\u3002", "result": "CLAIM\u53ef\u5728\u65e0\u9700\u5927\u89c4\u6a21\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u5e73\u5747\u63d0\u9ad8POPE\u57fa\u51c6\u4e0a13.56%\uff08\u897f\u73ed\u7259\u8bed\u6700\u9ad8\u53ef\u8fbe30%\uff09\u4ee5\u53caMME\u57fa\u51c6\u7269\u4f53\u5e7b\u89c9\u5b50\u96c6\u4e0a21.75%\u7684\u6027\u80fd\u63d0\u5347\u3002\u5206\u6790\u8fd8\u53d1\u73b0\uff0c\u591a\u8bed\u8a00\u6ce8\u610f\u529b\u7684\u5206\u6b67\u4e3b\u8981\u51fa\u73b0\u5728\u4e2d\u95f4\u5c42\uff0c\u8fd9\u4e9b\u5c42\u5728\u591a\u8bed\u573a\u666f\u4e0b\u4f5c\u7528\u5173\u952e\u3002", "conclusion": "CLAIM\u4e3a\u51cf\u5c11LVLMs\u5728\u591a\u8bed\u8a00\u4e0b\u7269\u4f53\u5e7b\u89c9\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u65e0\u987b\u91cd\u8bad\u7ec3\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u7684\u89c6\u89c9\u7406\u89e3\u80fd\u529b\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u4e2d\u95f4\u5c42\u6ce8\u610f\u529b\u5bf9\u591a\u8bed\u8a00\u901a\u7528\u7684\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2506.10987", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.10987", "abs": "https://arxiv.org/abs/2506.10987", "authors": ["Shaoyi Yang"], "title": "Chain of Draft for Software Engineering: Challenges in Applying Concise Reasoning to Code Tasks", "comment": null, "summary": "Large language models (LLMs) have become vital tools for software\ndevelopment, but they often require verbose intermediate reasoning for complex\ncode tasks, leading to high latency and costs. This research extends the Chain\nof Draft (CoD) method to software engineering, designing and evaluating\nmultiple CoD variants tailored for code tasks. Through comprehensive\nexperiments on all 300 samples from the SWE-bench benchmark, we found that all\nCoD variants used significantly fewer tokens than Chain of Thought (CoT), with\nBaseline CoD being most efficient at 55.4% of CoT's tokens. While this\nrepresents substantial efficiency gains - translating to approximately 45%\nreduction in processing time and API costs - it differs from the extreme 7.6%\nreported in the original CoD paper for mathematical reasoning. This difference\nstems from the inherent complexity and context-dependency of software tasks,\nwhich require more detailed reasoning to maintain solution quality. Our\nmulti-dimensional quality assessment revealed that CoD variants maintain over\n90% of CoT's code quality across key metrics including correctness,\ncompatibility, and maintainability, making them practical alternatives for\nreal-world development scenarios where efficiency matters. This research\ndemonstrates how domain-specific characteristics influence prompting strategy\neffectiveness and provides a framework for balancing efficiency with solution\nquality in software engineering applications. Our findings offer practical\nguidance for optimizing LLM-based development workflows through appropriate\nprompting strategy selection based on project requirements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e13\u4e3a\u4ee3\u7801\u4efb\u52a1\u8bbe\u8ba1\u7684 CoD \u53d8\u4f53\uff0c\u76f8\u6bd4\u4f20\u7edf CoT\uff0c\u80fd\u5728\u4ee3\u7801\u8d28\u91cf\u57fa\u672c\u4e0d\u53d8\u7684\u524d\u63d0\u4e0b\u5927\u5e45\u8282\u7701\u63a8\u7406 token \u548c\u6210\u672c\uff0c\u9002\u5408\u8ffd\u6c42\u6548\u7387\u7684\u8f6f\u4ef6\u5f00\u53d1\u5e94\u7528\u3002", "motivation": "\u76ee\u524d LLM \u89e3\u51b3\u590d\u6742\u4ee3\u7801\u4efb\u52a1\u65f6\u4e2d\u95f4\u63a8\u7406\u5197\u957f\uff0c\u5bfc\u81f4\u5ef6\u8fdf\u9ad8\u548c\u6210\u672c\u9ad8\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u7559\u63a8\u7406\u8d28\u91cf\u53c8\u80fd\u63d0\u5347\u6548\u7387\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u6269\u5c55\u548c\u8bbe\u8ba1\u4e86\u591a\u79cd\u9488\u5bf9\u4ee3\u7801\u4efb\u52a1\u7684 Chain of Draft (CoD) \u53d8\u4f53\uff0c\u57fa\u4e8e SWE-bench \u57fa\u51c6\u7684 300 \u4e2a\u6837\u672c\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5bf9\u6548\u7387\u4e0e\u591a\u7ef4\u8d28\u91cf\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u6240\u6709 CoD \u53d8\u4f53\u6d88\u8017\u7684 token \u663e\u8457\u5c11\u4e8e Chain of Thought (CoT)\uff0c\u5176\u4e2d Baseline CoD \u4ec5\u4e3a CoT \u7684 55.4%\u3002\u5728\u4ee3\u7801\u6b63\u786e\u6027\u3001\u517c\u5bb9\u6027\u3001\u53ef\u7ef4\u62a4\u6027\u7b49\u5173\u952e\u6307\u6807\u4e0a\uff0cCoD \u53d8\u4f53\u4fdd\u6301\u4e86 CoT 90% \u4ee5\u4e0a\u7684\u8d28\u91cf\u3002\u540c\u65f6\u76f8\u8f83\u4e8e\u6570\u5b66\u4efb\u52a1\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u7684 efficiency gain \u4f4e\u4e8e\u539f\u59cb CoD \u8bba\u6587\uff08\u5373 45% vs. 92.4%\uff09\uff0c\u56e0\u5176\u590d\u6742\u6027\u548c\u4e0a\u4e0b\u6587\u4f9d\u8d56\u66f4\u5f3a\u3002", "conclusion": "CoD \u65b9\u6cd5\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u80fd\u591f\u5927\u5e45\u63d0\u5347 LLM \u63a8\u7406\u6548\u7387\uff0c\u5728\u4fdd\u6301\u8f83\u9ad8\u4ee3\u7801\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11 token \u6d88\u8017\uff0c\u9002\u5408\u6ce8\u91cd\u6548\u7387\u7684\u8f6f\u4ef6\u5f00\u53d1\u573a\u666f\u3002"}}
{"id": "2506.11794", "categories": ["cs.PL", "math.PR"], "pdf": "https://arxiv.org/pdf/2506.11794", "abs": "https://arxiv.org/abs/2506.11794", "authors": ["Baltasar Tranc\u00f3n y Widemann", "Markus Lepper"], "title": "ALEA IACTA EST: A Declarative Domain-Specific Language for Manually Performable Random Experiments", "comment": null, "summary": "Random experiments that are simple and clear enough to be performed by human\nagents feature prominently in the teaching of elementary stochastics as well as\nin games. We present Alea, a domain-specific language for the specification of\nrandom experiments. Alea code can either be analyzed statically to obtain and\ninspect probability distributions of outcomes, or be executed with a source\npseudo-randomness for simulation or as a game assistant. The language is\nintended for ease of use by non-expert programmers, in particular students of\nelementary stochastics, and players and designers of games of chance, by\nfocusing on concepts common to functional programming and basic mathematics.\nBoth the design of the language and the implementation of runtime environments\nare work in progress.", "AI": {"tldr": "Alea\u662f\u4e00\u79cd\u9762\u5411\u968f\u673a\u5b9e\u9a8c\u7684\u65b0\u578b\u4e13\u7528\u8bed\u8a00\uff0c\u4e3b\u6253\u6781\u7b80\u4f7f\u7528\u4f53\u9a8c\uff0c\u65e2\u80fd\u9759\u6001\u5206\u6790\u6982\u7387\u5206\u5e03\uff0c\u4e5f\u652f\u6301\u5b9e\u9a8c\u6a21\u62df\uff0c\u670d\u52a1\u521d\u5b66\u8005\u548c\u6e38\u620f\u8bbe\u8ba1\u9886\u57df\uff0c\u5f53\u524d\u5f00\u53d1\u4ecd\u5728\u8fdb\u884c\u3002", "motivation": "\u5728\u521d\u7b49\u968f\u673a\u5b66\u6559\u5b66\u548c\u535a\u5f08\u4e2d\uff0c\u5e38\u9700\u63cf\u8ff0\u5e76\u5206\u6790\u7b80\u5355\u660e\u4e86\u7684\u968f\u673a\u5b9e\u9a8c\u3002\u73b0\u6709\u5de5\u5177\u4f7f\u7528\u95e8\u69db\u9ad8\uff0c\u4e0d\u4fbf\u4e8e\u5b66\u751f\u53ca\u6e38\u620f\u8bbe\u8ba1\u8005\u7b49\u975e\u4e13\u5bb6\u7fa4\u4f53\u76f4\u63a5\u8868\u8fbe\u548c\u5206\u6790\u968f\u673a\u5b9e\u9a8c\u3002", "method": "\u63d0\u51fa\u5e76\u521d\u6b65\u5b9e\u73b0\u4e86\u4e00\u79cd\u9762\u5411\u968f\u673a\u5b9e\u9a8c\u7684\u9886\u57df\u4e13\u7528\u8bed\u8a00Alea\u3002\u8be5\u8bed\u8a00\u4e0d\u4ec5\u652f\u6301\u9759\u6001\u5206\u6790\u4ee5\u63a8\u5bfc\u6982\u7387\u5206\u5e03\uff0c\u8fd8\u80fd\u501f\u52a9\u4f2a\u968f\u673a\u6e90\u8fdb\u884c\u5b9e\u9a8c\u6a21\u62df\u3002", "result": "\u5f00\u53d1\u51faAlea\u8bed\u8a00\uff0c\u5b9e\u73b0\u4e86\u5176\u57fa\u672c\u529f\u80fd\uff1a\u4ee3\u7801\u9759\u6001\u5206\u6790\u53ef\u83b7\u5f97\u6982\u7387\u5206\u5e03\uff0c\u8fd0\u884c\u65f6\u5219\u8f85\u52a9\u6a21\u62df\u5b9e\u9a8c\u6216\u652f\u6301\u6e38\u620f\u3002\u5f3a\u8c03\u51fd\u6570\u5f0f\u7f16\u7a0b\u548c\u57fa\u7840\u6570\u5b66\u6982\u5ff5\u4ee5\u63d0\u5347\u6613\u7528\u6027\u3002", "conclusion": "Alea\u8bed\u8a00\u662f\u4e00\u79cd\u9488\u5bf9\u968f\u673a\u5b9e\u9a8c\u9886\u57df\u7684\u7279\u5b9a\u8bed\u8a00\uff0c\u65e8\u5728\u7b80\u5316\u548c\u589e\u5f3a\u968f\u673a\u5b9e\u9a8c\u7684\u63cf\u8ff0\u3001\u5206\u6790\u4e0e\u6a21\u62df\u6d41\u7a0b\uff0c\u5c24\u5176\u9002\u5408\u975e\u4e13\u4e1a\u7a0b\u5e8f\u5458\u5982\u521d\u5b66\u8005\u548c\u6e38\u620f\u8bbe\u8ba1\u8005\u4f7f\u7528\u3002\u5176\u8bbe\u8ba1\u548c\u5b9e\u73b0\u4ecd\u5728\u6301\u7eed\u53d1\u5c55\u4e2d\u3002"}}
{"id": "2506.11077", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11077", "abs": "https://arxiv.org/abs/2506.11077", "authors": ["Chongyu Fan", "Yihua Zhang", "Jinghan Jia", "Alfred Hero", "Sijia Liu"], "title": "CyclicReflex: Improving Large Reasoning Models via Cyclical Reflection Token Scheduling", "comment": null, "summary": "Large reasoning models (LRMs), such as OpenAI's o1 and DeepSeek-R1, harness\ntest-time scaling to perform multi-step reasoning for complex problem-solving.\nThis reasoning process, executed before producing final answers, is often\nguided by special juncture tokens or textual segments that prompt\nself-evaluative reflection. We refer to these transition markers and reflective\ncues as \"reflection tokens\" (e.g., \"wait\", \"but\", \"alternatively\"). In this\nwork, we treat reflection tokens as a \"resource\" and introduce the problem of\nresource allocation, aimed at improving the test-time compute performance of\nLRMs by adaptively regulating the frequency and placement of reflection tokens.\nThrough empirical analysis, we show that both excessive and insufficient use of\nreflection tokens, referred to as over-reflection and under-reflection, can\ndegrade model performance. To better understand and manage this trade-off, we\ndraw an analogy between reflection token usage and learning rate scheduling in\noptimization. Building on this insight, we propose cyclical reflection token\nscheduling (termed CyclicReflex), a decoding strategy that dynamically\nmodulates reflection token logits using a position-dependent triangular\nwaveform. Experiments on MATH500, AIME2024/2025, and AMC2023 demonstrate that\nCyclicReflex consistently improves performance across model sizes (1.5B-8B),\noutperforming standard decoding and more recent approaches such as TIP (thought\nswitching penalty) and S1. Codes are available at\nhttps://github.com/OPTML-Group/CyclicReflex.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u8c03\u6574\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u53cd\u601d\u6807\u8bb0\uff08reflection tokens\uff09\u7684\u65b9\u6cd5CyclicReflex\uff0c\u5e76\u8bc1\u660e\u5176\u5728\u591a\u4e2a\u6570\u5b66\u4efb\u52a1\u548c\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0b\u5747\u6709\u6548\u63d0\u5347\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u89e3\u51b3\u590d\u6742\u95ee\u9898\u65f6\uff0c\u5e38\u901a\u8fc7\u5d4c\u5165\u7279\u6b8a\u7684\u201c\u53cd\u601d\u6807\u8bb0\u201d\uff08\u5982\u201cwait\u201d\u3001\u201cbut\u201d\u7b49\uff09\u6765\u4fc3\u8fdb\u591a\u6b65\u63a8\u7406\u8fc7\u7a0b\u3002\u4f46\u8fd9\u4e9b\u53cd\u601d\u6807\u8bb0\u8fc7\u591a\u6216\u8fc7\u5c11\u90fd\u53ef\u80fd\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002\u5f53\u524d\u7f3a\u4e4f\u5bf9\u53cd\u601d\u6807\u8bb0\u4f7f\u7528\u9891\u7387\u548c\u4f4d\u7f6e\u7684\u52a8\u6001\u8c03\u8282\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u5c06\u53cd\u601d\u6807\u8bb0\uff08reflection tokens\uff09\u89c6\u4e3a\u8ba1\u7b97\u8d44\u6e90\uff0c\u5e76\u5f15\u5165\u201c\u8d44\u6e90\u5206\u914d\u201d\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u8282\u53cd\u601d\u6807\u8bb0\u7684\u4f7f\u7528\uff0c\u63d0\u5347\u63a8\u7406\u6a21\u578b\u7684\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6027\u80fd\u3002\u57fa\u4e8e\u53cd\u601d\u6807\u8bb0\u4e0e\u4f18\u5316\u4e2d\u7684\u5b66\u4e60\u7387\u8c03\u5ea6\u7684\u7c7b\u6bd4\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e09\u89d2\u6ce2\u52a8\u6001\u8c03\u6574\u53cd\u601d\u6807\u8bb0\u6982\u7387\u7684\u65b0\u89e3\u7801\u7b56\u7565CyclicReflex\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728MATH500\u3001AIME2024/2025\u548cAMC2023\u7b49\u4efb\u52a1\u4e2d\uff0cCyclicReflex\u7b56\u7565\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0b\uff081.5B-8B\uff09\u5747\u80fd\u7a33\u5b9a\u63d0\u5347\u6a21\u578b\u8868\u73b0\uff0c\u4f18\u4e8e\u6807\u51c6\u89e3\u7801\u53caTIP\u3001S1\u7b49\u65b0\u65b9\u6cd5\u3002", "conclusion": "\u5408\u7406\u3001\u52a8\u6001\u5730\u8c03\u63a7\u53cd\u601d\u6807\u8bb0\u7684\u4f7f\u7528\u662f\u63d0\u5347\u5927\u578b\u63a8\u7406\u6a21\u578b\u63a8\u7406\u6027\u80fd\u7684\u6709\u6548\u624b\u6bb5\uff0cCyclicReflex\u65b9\u6cd5\u5177\u5907\u666e\u9002\u6027\u548c\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2506.10988", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.10988", "abs": "https://arxiv.org/abs/2506.10988", "authors": ["Bowen Tian", "Zhengyang Xu", "Mingqiang Wu", "Songning Lai", "Yutai Yue"], "title": "You Only Train Once: A Flexible Training Framework for Code Vulnerability Detection Driven by Vul-Vector", "comment": "Under Review", "summary": "With the pervasive integration of computer applications across industries,\nthe presence of vulnerabilities within code bases poses significant risks. The\ndiversity of software ecosystems coupled with the intricate nature of modern\nsoftware engineering has led to a shift from manual code vulnerability\nidentification towards the adoption of automated tools. Among these, deep\nlearning-based approaches have risen to prominence due to their superior\naccuracy; however, these methodologies encounter several obstacles. Primarily,\nthey necessitate extensive labeled datasets and prolonged training periods, and\ngiven the rapid emergence of new vulnerabilities, the frequent retraining of\nmodels becomes a resource-intensive endeavor, thereby limiting their\napplicability in cutting-edge scenarios. To mitigate these challenges, this\npaper introduces the \\underline{\\textbf{YOTO}}--\\underline{\\textbf{Y}}ou\n\\underline{\\textbf{O}}nly \\underline{\\textbf{T}}rain \\underline{\\textbf{O}}nce\nframework. This innovative approach facilitates the integration of multiple\ntypes of vulnerability detection models via parameter fusion, eliminating the\nneed for joint training. Consequently, YOTO enables swift adaptation to newly\ndiscovered vulnerabilities, significantly reducing both the time and\ncomputational resources required for model updates.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86YOTO\u6846\u67b6\uff0c\u901a\u8fc7\u53c2\u6570\u878d\u5408\u6280\u672f\u5b9e\u73b0\u591a\u79cd\u6f0f\u6d1e\u68c0\u6d4b\u6a21\u578b\u7684\u96c6\u6210\uff0c\u89e3\u51b3\u4e86\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u548c\u9891\u7e41\u91cd\u8bad\u7684\u95ee\u9898\uff0c\u663e\u8457\u51cf\u8f7b\u4e86\u6a21\u578b\u66f4\u65b0\u5e26\u6765\u7684\u8d44\u6e90\u538b\u529b\uff0c\u63d0\u5347\u4e86\u68c0\u6d4b\u65b0\u6f0f\u6d1e\u7684\u6548\u7387\u3002", "motivation": "\u968f\u7740\u8ba1\u7b97\u673a\u5e94\u7528\u5728\u5404\u884c\u4e1a\u7684\u5e7f\u6cdb\u878d\u5408\uff0c\u4ee3\u7801\u5e93\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\u5e26\u6765\u4e86\u91cd\u5927\u98ce\u9669\u3002\u73b0\u4ee3\u8f6f\u4ef6\u5de5\u7a0b\u7684\u590d\u6742\u6027\u548c\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u7684\u591a\u6837\u6027\uff0c\u4f7f\u5f97\u4f20\u7edf\u7684\u624b\u5de5\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u5f0f\u6548\u7387\u4f4e\u4e0b\uff0c\u63a8\u52a8\u4e86\u81ea\u52a8\u5316\u5de5\u5177\u7684\u53d1\u5c55\u3002\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5c3d\u7ba1\u51c6\u786e\u7387\u9ad8\uff0c\u4f46\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u548c\u957f\u65f6\u95f4\u8bad\u7ec3\uff0c\u65b0\u6f0f\u6d1e\u5c42\u51fa\u4e0d\u7a77\u5bfc\u81f4\u6a21\u578b\u9891\u7e41\u91cd\u8bad\uff0c\u8d44\u6e90\u6d88\u8017\u5927\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86YOTO\uff08You Only Train Once\uff09\u6846\u67b6\u3002YOTO\u901a\u8fc7\u53c2\u6570\u878d\u5408\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u591a\u79cd\u6f0f\u6d1e\u68c0\u6d4b\u6a21\u578b\u7684\u96c6\u6210\uff0c\u65e0\u9700\u8054\u5408\u8bad\u7ec3\u3002\u6b64\u65b9\u6cd5\u53ef\u4ee5\u9488\u5bf9\u65b0\u51fa\u73b0\u7684\u6f0f\u6d1e\u5feb\u901f\u9002\u914d\uff0c\u663e\u8457\u51cf\u5c11\u6a21\u578b\u66f4\u65b0\u6240\u9700\u7684\u65f6\u95f4\u548c\u8ba1\u7b97\u8d44\u6e90\u3002", "result": "YOTO\u6846\u67b6\u80fd\u591f\u6781\u5927\u5730\u51cf\u5c11\u6a21\u578b\u8bad\u7ec3\u548c\u66f4\u65b0\u7684\u8d44\u6e90\u6d88\u8017\uff0c\u540c\u65f6\u5141\u8bb8\u9488\u5bf9\u65b0\u6f0f\u6d1e\u7c7b\u578b\u7684\u5feb\u901f\u9002\u914d\uff0c\u63d0\u5347\u4e86\u81ea\u52a8\u5316\u6f0f\u6d1e\u68c0\u6d4b\u5de5\u5177\u7684\u5b9e\u7528\u6027\u548c\u6269\u5c55\u6027\u3002", "conclusion": "YOTO\u6846\u67b6\u901a\u8fc7\u521b\u65b0\u7684\u53c2\u6570\u878d\u5408\u65b9\u5f0f\uff0c\u89e3\u51b3\u4e86\u6df1\u5ea6\u5b66\u4e60\u6f0f\u6d1e\u68c0\u6d4b\u5728\u5927\u89c4\u6a21\u5b9e\u9645\u5e94\u7528\u4e2d\u9762\u4e34\u7684\u9ad8\u8bad\u7ec3\u548c\u66f4\u65b0\u6210\u672c\u95ee\u9898\uff0c\u5bf9\u81ea\u52a8\u5316\u6f0f\u6d1e\u68c0\u6d4b\u7684\u6548\u7387\u4e0e\u7075\u6d3b\u6027\u5177\u6709\u663e\u8457\u63d0\u5347\u4f5c\u7528\u3002"}}
{"id": "2506.11078", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11078", "abs": "https://arxiv.org/abs/2506.11078", "authors": ["Yuzhou Yang", "Yangming Zhou", "Zhiying Zhu", "Zhenxing Qian", "Xinpeng Zhang", "Sheng Li"], "title": "RoE-FND: A Case-Based Reasoning Approach with Dual Verification for Fake News Detection via LLMs", "comment": null, "summary": "The proliferation of deceptive content online necessitates robust Fake News\nDetection (FND) systems. While evidence-based approaches leverage external\nknowledge to verify claims, existing methods face critical limitations: noisy\nevidence selection, generalization bottlenecks, and unclear decision-making\nprocesses. Recent efforts to harness Large Language Models (LLMs) for FND\nintroduce new challenges, including hallucinated rationales and conclusion\nbias. To address these issues, we propose \\textbf{RoE-FND}\n(\\textbf{\\underline{R}}eason \\textbf{\\underline{o}}n\n\\textbf{\\underline{E}}xperiences FND), a framework that reframes evidence-based\nFND as a logical deduction task by synergizing LLMs with experiential learning.\nRoE-FND encompasses two stages: (1) \\textit{self-reflective knowledge\nbuilding}, where a knowledge base is curated by analyzing past reasoning\nerrors, namely the exploration stage, and (2) \\textit{dynamic criterion\nretrieval}, which synthesizes task-specific reasoning guidelines from\nhistorical cases as experiences during deployment. It further cross-checks\nrationales against internal experience through a devised dual-channel\nprocedure. Key contributions include: a case-based reasoning framework for FND\nthat addresses multiple existing challenges, a training-free approach enabling\nadaptation to evolving situations, and empirical validation of the framework's\nsuperior generalization and effectiveness over state-of-the-art methods across\nthree datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u6cdb\u5316\u5230\u65b0\u60c5\u51b5\u7684\u53cc\u9636\u6bb5\u865a\u5047\u65b0\u95fb\u68c0\u6d4b\u6846\u67b6RoE-FND\uff0c\u65e2\u80fd\u590d\u76d8\u63a8\u7406\u9519\u8bef\u3001\u52a8\u6001\u751f\u6210\u8bc1\u636e\u5224\u51c6\uff0c\u8fd8\u80fd\u63d0\u5347\u68c0\u6d4b\u51c6\u786e\u7387\u548c\u900f\u660e\u5ea6\uff0c\u5728\u591a\u9879\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u7f51\u7edc\u4e0a\u865a\u5047\u65b0\u95fb\u6cdb\u6ee5\uff0c\u5bf9\u9ad8\u6548\u3001\u5065\u58ee\u7684\u865a\u5047\u65b0\u95fb\u68c0\u6d4b\u7cfb\u7edf\u9700\u6c42\u8feb\u5207\u3002\u73b0\u6709\u57fa\u4e8e\u8bc1\u636e\u7684\u65b9\u6cd5\u5b58\u5728\u566a\u58f0\u8bc1\u636e\u9009\u62e9\u3001\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u548c\u51b3\u7b56\u8fc7\u7a0b\u4e0d\u900f\u660e\u7684\u95ee\u9898\u3002\u8fd1\u671f\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u68c0\u6d4b\u4e5f\u5e26\u6765\u4e86\u65b0\u7684\u6311\u6218\uff0c\u4f8b\u5982\u865a\u6784\u63a8\u7406\u548c\u7ed3\u8bba\u504f\u5dee\u3002", "method": "\u63d0\u51fa\u4e86RoE-FND\u6846\u67b6\uff0c\u5c06\u57fa\u4e8e\u8bc1\u636e\u7684\u865a\u5047\u65b0\u95fb\u68c0\u6d4b\u91cd\u6784\u4e3a\u903b\u8f91\u63a8\u7406\u4efb\u52a1\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u7ecf\u9a8c\u5b66\u4e60\u3002\u4e3b\u8981\u5305\u62ec\u4e24\u4e2a\u9636\u6bb5\uff1a1) \u81ea\u6211\u53cd\u601d\u77e5\u8bc6\u6784\u5efa\u2014\u2014\u5206\u6790\u8fc7\u53bb\u63a8\u7406\u9519\u8bef\uff0c\u6784\u5efa\u77e5\u8bc6\u5e93\uff1b2) \u52a8\u6001\u51c6\u5219\u68c0\u7d22\u2014\u2014\u4ece\u5386\u53f2\u6848\u4f8b\u4e2d\u63d0\u53d6\u4efb\u52a1\u76f8\u5173\u63a8\u7406\u51c6\u5219\uff0c\u5e76\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4ea4\u53c9\u68c0\u9a8c\u7406\u7531\u4e0e\u5185\u90e8\u7ecf\u9a8c\uff08\u53cc\u901a\u9053\u5904\u7406\uff09\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u5b9e\u8bc1\u9a8c\u8bc1RoE-FND\u6846\u67b6\u5177\u6709\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6709\u6548\u6027\uff0c\u8868\u73b0\u4f18\u4e8e\u6700\u65b0\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u65e0\u9700\u5fae\u8c03\u8bad\u7ec3\u5373\u53ef\u9002\u5e94\u65b0\u53d8\u5316\u3002", "conclusion": "RoE-FND\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u6848\u4f8b\u63a8\u7406\u548c\u7ecf\u9a8c\u5b66\u4e60\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u591a\u9879\u5173\u952e\u6311\u6218\uff0c\u63a8\u52a8\u4e86\u865a\u5047\u65b0\u95fb\u68c0\u6d4b\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.10989", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.10989", "abs": "https://arxiv.org/abs/2506.10989", "authors": ["Rogelio Cruz", "Jonatan Contreras", "Francisco Guerrero", "Ezequiel Rodriguez", "Carlos Valdez", "Citlali Carrillo"], "title": "Prompt engineering and framework: implementation to increase code reliability based guideline for LLMs", "comment": null, "summary": "In this paper, we propose a novel prompting approach aimed at enhancing the\nability of Large Language Models (LLMs) to generate accurate Python code.\nSpecifically, we introduce a prompt template designed to improve the quality\nand correctness of generated code snippets, enabling them to pass tests and\nproduce reliable results. Through experiments conducted on two state-of-the-art\nLLMs using the HumanEval dataset, we demonstrate that our approach outperforms\nwidely studied zero-shot and Chain-of-Thought (CoT) methods in terms of the\nPass@k metric. Furthermore, our method achieves these improvements with\nsignificantly reduced token usage compared to the CoT approach, making it both\neffective and resource-efficient, thereby lowering the computational demands\nand improving the eco-footprint of LLM capabilities. These findings highlight\nthe potential of tailored prompting strategies to optimize code generation\nperformance, paving the way for broader applications in AI-driven programming\ntasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u63d0\u793a\u6a21\u677f\uff0c\u5927\u5e45\u63d0\u5347LLM\u751f\u6210Python\u4ee3\u7801\u7684\u8d28\u91cf\u548c\u6b63\u786e\u6027\uff0c\u6548\u679c\u8d85\u8fc7\u5e38\u7528\u63d0\u793a\u65b9\u6cd5\u4e14\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u66f4\u4f4e\uff0c\u5177\u5907\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u51c6\u786ePython\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u89e3\u51b3\u73b0\u6709\u63d0\u793a\u65b9\u6cd5\u5728\u4ee3\u7801\u8d28\u91cf\u3001\u6b63\u786e\u6027\u53ca\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u4e0a\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u63d0\u793a\u6a21\u677f\uff08prompt template\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5408\u7406\u8bbe\u8ba1\u63d0\u5347\u751f\u6210\u4ee3\u7801\u7684\u8d28\u91cf\u548c\u6b63\u786e\u6027\u3002\u8be5\u65b9\u6cd5\u5728HumanEval\u6570\u636e\u96c6\u4e0a\uff0c\u9488\u5bf9\u4e24\u79cd\u5148\u8fdb\u7684LLM\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u5e76\u4e0ezero-shot\u548cChain-of-Thought\uff08CoT\uff09\u63d0\u793a\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u65b0\u65b9\u6cd5\u5728Pass@k\u6307\u6807\u4e0a\u4f18\u4e8ezero-shot\u548cCoT\u65b9\u6cd5\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u4e86Token\u4f7f\u7528\u91cf\uff0c\u964d\u4f4e\u4e86\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u548c\u73af\u5883\u5f71\u54cd\u3002", "conclusion": "\u4e13\u95e8\u5b9a\u5236\u7684\u63d0\u793a\u7b56\u7565\u80fd\u591f\u6709\u6548\u63d0\u5347LLM\u7684\u4ee3\u7801\u751f\u6210\u8868\u73b0\uff0c\u540c\u65f6\u517c\u987e\u8d44\u6e90\u8282\u7701\u548c\u73af\u5883\u53cb\u597d\u3002\u6b64\u65b9\u6cd5\u53ef\u4e3aAI\u81ea\u52a8\u7f16\u7a0b\u7b49\u9886\u57df\u5e26\u6765\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2506.11080", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11080", "abs": "https://arxiv.org/abs/2506.11080", "authors": ["Han Zhou", "Qitong Xu", "Yiheng Dong", "Xin Yang"], "title": "MANBench: Is Your Multimodal Model Smarter than Human?", "comment": "Multimodal Benchmark, Project Url: https://github.com/micdz/MANBench,\n  ACL2025 Findings", "summary": "The rapid advancement of Multimodal Large Language Models (MLLMs) has ignited\ndiscussions regarding their potential to surpass human performance in\nmultimodal tasks. In response, we introduce MANBench (Multimodal Ability Norms\nBenchmark), a bilingual benchmark (English and Chinese) comprising 1,314\nquestions across nine tasks, spanning knowledge-based and non-knowledge-based\ndomains. MANBench emphasizes intuitive reasoning, seamless cross-modal\nintegration, and real-world complexity, providing a rigorous evaluation\nframework.\n  Through extensive human experiments involving diverse participants, we\ncompared human performance against state-of-the-art MLLMs. The results indicate\nthat while MLLMs excel in tasks like Knowledge and Text-Image Understanding,\nthey struggle with deeper cross-modal reasoning tasks such as Transmorphic\nUnderstanding, Image Consistency, and Multi-image Understanding. Moreover, both\nhumans and MLLMs face challenges in highly complex tasks like Puzzles and\nSpatial Imagination.\n  MANBench highlights the strengths and limitations of MLLMs, revealing that\neven advanced models fall short of achieving human-level performance across\nmany domains. We hope MANBench will inspire efforts to bridge the gap between\nMLLMs and human multimodal capabilities. The code and dataset are available at\nhttps://github.com/micdz/MANBench.", "AI": {"tldr": "MANBench\u63d0\u51fa\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u591a\u6a21\u6001\u8bc4\u6d4b\u57fa\u51c6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5f53\u524dMLLMs\u5728\u591a\u9886\u57df\u4ecd\u4e0d\u53ca\u4eba\u7c7b\uff0c\u5c24\u5176\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u5dee\u8ddd\u660e\u663e\u3002", "motivation": "\u968f\u7740\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08MLLMs\uff09\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u4eba\u4eec\u5f00\u59cb\u8ba8\u8bba\u5176\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u662f\u5426\u53ef\u80fd\u8d85\u8d8a\u4eba\u7c7b\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u5efa\u7acb\u4e00\u4e2a\u53ef\u4ee5\u7cfb\u7edf\u8bc4\u4f30MLLMs\u4e0e\u4eba\u7c7b\u5728\u591a\u6a21\u6001\u80fd\u529b\u65b9\u9762\u5dee\u8ddd\u7684\u57fa\u51c6\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86MANBench\uff0c\u8fd9\u662f\u4e00\u4e2a\u6db5\u76d6\u82f1\u8bed\u548c\u4e2d\u6587\u7684\u53cc\u8bed\u591a\u6a21\u6001\u80fd\u529b\u57fa\u51c6\uff0c\u5305\u62ec1314\u9053\u9898\uff0c\u6db5\u76d69\u5927\u4efb\u52a1\uff0c\u4fa7\u91cd\u4e8e\u76f4\u89c9\u63a8\u7406\u3001\u8de8\u6a21\u6001\u6574\u5408\u548c\u73b0\u5b9e\u4e16\u754c\u590d\u6742\u6027\u3002\u4f5c\u8005\u8fd8\u7ec4\u7ec7\u4e86\u5927\u89c4\u6a21\u4eba\u7c7b\u5b9e\u9a8c\uff0c\u5c06\u4eba\u7c7b\u4e0e\u6700\u65b0MLLMs\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cMLLMs\u5728\u77e5\u8bc6\u548c\u6587\u672c-\u56fe\u50cf\u7406\u89e3\u7b49\u4efb\u52a1\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u8de8\u6a21\u6001\u63a8\u7406\u3001\u56fe\u50cf\u4e00\u81f4\u6027\u53ca\u591a\u56fe\u50cf\u7406\u89e3\u7b49\u6df1\u5c42\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002\u65e0\u8bba\u4eba\u7c7b\u8fd8\u662fMLLMs\uff0c\u5728\u6781\u5176\u590d\u6742\u7684\u62fc\u56fe\u53ca\u7a7a\u95f4\u60f3\u8c61\u4efb\u52a1\u4e2d\u5747\u9762\u4e34\u6311\u6218\u3002", "conclusion": "MANBench\u7cfb\u7edf\u5c55\u73b0\u4e86MLLMs\u7684\u4f18\u52bf\u548c\u77ed\u677f\uff0c\u63ed\u793a\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u6a21\u578b\uff0c\u5728\u8bb8\u591a\u9886\u57df\u4ecd\u672a\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u3002\u4f5c\u8005\u5e0c\u671bMANBench\u80fd\u63a8\u52a8MLLMs\u8fdb\u4e00\u6b65\u63d0\u5347\u5411\u4eba\u7c7b\u591a\u6a21\u6001\u80fd\u529b\u9760\u62e2\u3002"}}
{"id": "2506.10990", "categories": ["cs.SE", "cs.AI", "cs.CE", "cs.DC", "I.2.0"], "pdf": "https://arxiv.org/pdf/2506.10990", "abs": "https://arxiv.org/abs/2506.10990", "authors": ["Roberto Vergallo", "Lu\u00eds Cruz", "Alessio Errico", "Luca Mainetti"], "title": "On the Effectiveness of the 'Follow-the-Sun' Strategy in Mitigating the Carbon Footprint of AI in Cloud Instances", "comment": "24 pages, 4 figures, 10 tables", "summary": "'Follow-the-Sun' (FtS) is a theoretical computational model aimed at\nminimizing the carbon footprint of computer workloads. It involves dynamically\nmoving workloads to regions with cleaner energy sources as demand increases and\nenergy production relies more on fossil fuels. With the significant power\nconsumption of Artificial Intelligence (AI) being a subject of extensive\ndebate, FtS is proposed as a strategy to mitigate the carbon footprint of\ntraining AI models. However, the literature lacks scientific evidence on the\nadvantages of FtS to mitigate the carbon footprint of AI workloads. In this\npaper, we present the results of an experiment conducted in a partial synthetic\nscenario to address this research gap. We benchmarked four AI algorithms in the\nanomaly detection domain and measured the differences in carbon emissions in\nfour cases: no strategy, FtS, and two strategies previously introduced in the\nstate of the art, namely Flexible Start and Pause and Resume. To conduct our\nexperiment, we utilized historical carbon intensity data from the year 2021 for\nseven European cities. Our results demonstrate that the FtS strategy not only\nachieves average reductions of up to 14.6% in carbon emissions (with peaks of\n16.3%) but also helps in preserving the time needed for training.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u4ee5\u5b9e\u9a8c\u8bc1\u636e\u8868\u660e\uff0c\u901a\u8fc7\u5c06AI\u8ba1\u7b97\u4efb\u52a1\u52a8\u6001\u8c03\u6574\u81f3\u6e05\u6d01\u80fd\u6e90\u5145\u8db3\u7684\u5730\u533a\uff08\u5373FtS\u7b56\u7565\uff09\uff0c\u53ef\u6709\u6548\u51cf\u5c1114.6%-16.3%\u7684\u78b3\u6392\u653e\uff0c\u4e14\u4e0d\u5f71\u54cd\u8bad\u7ec3\u65f6\u95f4\uff0c\u4e3a\u5b9e\u73b0AI\u7eff\u8272\u4f4e\u78b3\u63d0\u4f9b\u4e86\u53ef\u884c\u9014\u5f84\u3002", "motivation": "\u5f53\u524d\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u7b97\u529b\u6d88\u8017\u5de8\u5927\uff0c\u5176\u78b3\u8db3\u8ff9\u5f15\u53d1\u4e86\u5e7f\u6cdb\u5173\u6ce8\u3002\u4e3a\u51cf\u5c11\u8ba1\u7b97\u4efb\u52a1\u7684\u78b3\u6392\u653e\uff0c\u7406\u8bba\u4e0a\u53ef\u91c7\u7528\u201cFollow-the-Sun\uff08FtS\uff09\u201d\u6a21\u578b\uff0c\u901a\u8fc7\u5c06\u5de5\u4f5c\u8d1f\u8f7d\u52a8\u6001\u8fc1\u79fb\u81f3\u6e05\u6d01\u80fd\u6e90\u4ea7\u5730\u4ee5\u4f18\u5316\u80fd\u6e90\u5229\u7528\u3002\u7136\u800c\u5173\u4e8eFtS\u5e94\u7528\u4e8eAI\u7b97\u529b\u78b3\u51cf\u6392\u65b9\u9762\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u7684\u79d1\u5b66\u5b9e\u8bc1\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8be5\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u90e8\u5206\u5408\u6210\u5b9e\u9a8c\u573a\u666f\uff0c\u5bf9\u56db\u79cd\u5f02\u5e38\u68c0\u6d4b\u9886\u57df\u7684AI\u7b97\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002\u5b9e\u9a8c\u8003\u8651\u4e86\u56db\u79cd\u60c5\u51b5\uff1a\u65e0\u7b56\u7565\u3001FtS\u3001Flexible Start\u3001Pause and Resume\u3002\u7814\u7a76\u5229\u75282021\u5e747\u4e2a\u6b27\u6d32\u57ce\u5e02\u7684\u5386\u53f2\u78b3\u5f3a\u5ea6\u6570\u636e\uff0c\u5206\u522b\u6d4b\u91cf\u4e86\u5404\u7b56\u7565\u4e0b\u7684\u78b3\u6392\u653e\u5dee\u5f02\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cFtS\u7b56\u7565\u5e73\u5747\u53ef\u51cf\u5c1114.6%\u7684\u78b3\u6392\u653e\uff0c\u6700\u9ad8\u53ef\u8fbe16.3%\uff0c\u540c\u65f6\u8fd8\u80fd\u4fdd\u6301AI\u6a21\u578b\u8bad\u7ec3\u65f6\u957f\u57fa\u672c\u4e0d\u53d8\u3002", "conclusion": "FtS\u7b56\u7565\u53ef\u4ee5\u6709\u6548\u51cf\u5c11AI\u6a21\u578b\u8bad\u7ec3\u6240\u4ea7\u751f\u7684\u78b3\u6392\u653e\uff0c\u5e76\u4e0d\u4f1a\u663e\u8457\u5f71\u54cd\u8bad\u7ec3\u6548\u7387\u3002\u8be5\u7b56\u7565\u5728AI\u7eff\u8272\u7b97\u529b\u65b9\u9762\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.11081", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11081", "abs": "https://arxiv.org/abs/2506.11081", "authors": ["Aditi", "Hyunwoo Park", "Sicheol Sung", "Yo-Sub Han", "Sang-Ki Ko"], "title": "SAGE:Specification-Aware Grammar Extraction for Automated Test Case Generation with LLMs", "comment": null, "summary": "Grammar-based test case generation has proven effective for competitive\nprogramming problems, but generating valid and general grammars from natural\nlanguage specifications remains a key challenge, especially under limited\nsupervision. Context-Free Grammars with Counters (CCFGs) have recently been\nintroduced as a formalism to represent such specifications with logical\nconstraints by storing and reusing counter values during derivation. In this\nwork, we explore the use of open-source large language models (LLMs) to induce\nCCFGs from specifications using a small number of labeled examples and\nverifiable reward-guided reinforcement learning. Our approach first fine-tunes\nan open-source LLM to perform specification-to-grammar translation, and further\napplies Group Relative Policy Optimization (GRPO) to enhance grammar validity\nand generality. We also examine the effectiveness of iterative feedback for\nopen and closed-source LLMs in correcting syntactic and semantic errors in\ngenerated grammars.\n  Experimental results show that our approach SAGE achieves stronger\ngeneralization and outperforms 17 open and closed-source LLMs in both grammar\nquality and test effectiveness, improving over the state-of-the-art by 15.92%p\nin grammar validity and 12.34%p in test effectiveness. We provide our\nimplementation and dataset at the following anonymous\nrepository:https://anonymous.4open.science/r/SAGE-5714", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u5f00\u6e90\u5927\u6a21\u578b\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u751f\u6210\u9ad8\u8d28\u91cf\u53ef\u7ea6\u675f\u6587\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u81ea\u52a8\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u7684\u6cdb\u5316\u4e0e\u51c6\u786e\u6027\uff0c\u663e\u8457\u9886\u5148\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8e\u6587\u6cd5\u7684\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u5728\u7ade\u8d5b\u7f16\u7a0b\u95ee\u9898\u4e2d\u6548\u679c\u826f\u597d\uff0c\u4f46\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u81ea\u52a8\u751f\u6210\u6709\u6548\u3001\u901a\u7528\u7684\u6587\u6cd5\u4ecd\u5177\u6311\u6218\u6027\uff0c\u5c24\u5176\u5728\u6807\u6ce8\u6837\u672c\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u3002\u73b0\u6709\u7684\u81ea\u7136\u8bed\u8a00\u5230\u6587\u6cd5\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u7cbe\u5ea6\u4e0e\u6cdb\u5316\u6027\u4e0d\u8db3\uff0c\u9700\u8981\u65b0\u65b9\u6848\u63d0\u5347\u6587\u6cd5\u751f\u6210\u7684\u8d28\u91cf\u548c\u6548\u7387\u3002", "method": "\u9996\u5148\u5fae\u8c03\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee5\u5b9e\u73b0\u4ece\u89c4\u8303\u5230\u6587\u6cd5\u7684\u7ffb\u8bd1\uff1b\u7136\u540e\u91c7\u7528Group Relative Policy Optimization\uff08GRPO\uff09\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\uff0c\u63d0\u5347\u751f\u6210\u6587\u6cd5\u7684\u6709\u6548\u6027\u4e0e\u901a\u7528\u6027\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u8bc4\u4f30\u4e86\u57fa\u4e8e\u53cd\u9988\u673a\u5236\u5bf9\u5f00\u6e90\u4e0e\u95ed\u6e90LLM\u8fdb\u884c\u8fed\u4ee3\u7ea0\u9519\u7684\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSAGE\u5728\u6587\u6cd5\u6709\u6548\u6027\u4e0a\u6bd4\u6700\u65b0\u65b9\u6cd5\u63d0\u534715.92\u4e2a\u767e\u5206\u70b9\uff0c\u6d4b\u8bd5\u6709\u6548\u6027\u63d0\u534712.34\u4e2a\u767e\u5206\u70b9\uff0c\u5e76\u5728\u6587\u6cd5\u8d28\u91cf\u548c\u6d4b\u8bd5\u6548\u679c\u4e0a\u4f18\u4e8e17\u79cd\u5f00\u95ed\u6e90\u5927\u6a21\u578b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5SAGE\u80fd\u591f\u6709\u6548\u63d0\u5347\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u751f\u6210\u7b26\u5408\u7ea6\u675f\u7684\u6587\u6cd5\uff08CCFGs\uff09\u7684\u51c6\u786e\u6027\u548c\u901a\u7528\u6027\uff0c\u5728\u6587\u6cd5\u8d28\u91cf\u4e0e\u6d4b\u8bd5\u6709\u6548\u6027\u65b9\u9762\u5747\u8d85\u8d8a\u73b0\u670917\u79cd\u4e3b\u6d41\u5927\u6a21\u578b\uff0c\u663e\u8457\u4f18\u4e8e\u6700\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2506.10991", "categories": ["cs.SE", "D.2.9; H.4.1"], "pdf": "https://arxiv.org/pdf/2506.10991", "abs": "https://arxiv.org/abs/2506.10991", "authors": ["Hoang Vu", "Henrik Leopold", "Han van der Aa"], "title": "What is Business Process Automation Anyway?", "comment": "Accepted at HICSS 2023", "summary": "Many organizations strive to increase the level of automation in their\nbusiness processes. While automation historically was mainly concerned with\nautomating physical labor, current automation efforts mostly focus on\nautomation in a digital manner, thus targeting work that is related to the\ninteraction between humans and computers. This type of automation, commonly\nreferred to as business process automation, has many facets. Yet, academic\nliterature mainly focuses on Robotic Process Automation, a specific automation\ncapability. Recognizing that leading vendors offer automation capabilities\ngoing way beyond that, we use this paper to develop a detailed understanding of\nbusiness process automation in industry. To this end, we conduct a structured\nmarket analysis of the 18 predominant vendors of business process automation\nsolutions as identified by Gartner. As a result, we provide a comprehensive\noverview of the business process automation capabilities currently offered by\nindustrial vendors. We show which types and facets of automation exist and\nwhich aspects represent promising directions for the future.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e8618\u5bb6\u4e3b\u6d41\u4f9b\u5e94\u5546\u7684\u4e1a\u52a1\u6d41\u7a0b\u81ea\u52a8\u5316\u80fd\u529b\uff0c\u63ed\u793a\u884c\u4e1a\u81ea\u52a8\u5316\u5df2\u8d85\u8d8aRPA\uff0c\u672a\u6765\u8fd8\u6709\u66f4\u5e7f\u9614\u7684\u53d1\u5c55\u7a7a\u95f4\u3002", "motivation": "\u8d8a\u6765\u8d8a\u591a\u7684\u7ec4\u7ec7\u5e0c\u671b\u63d0\u5347\u4e1a\u52a1\u6d41\u7a0b\u7684\u81ea\u52a8\u5316\u6c34\u5e73\u3002\u4ee5\u5f80\u7684\u81ea\u52a8\u5316\u4e3b\u8981\u5173\u6ce8\u4f53\u529b\u52b3\u52a8\uff0c\u800c\u5f53\u524d\u7684\u81ea\u52a8\u5316\u66f4\u52a0\u805a\u7126\u4e8e\u6570\u5b57\u5316\u5f62\u5f0f\uff0c\u5c24\u5176\u662f\u4eba\u4e0e\u8ba1\u7b97\u673a\u4ea4\u4e92\u76f8\u5173\u7684\u5de5\u4f5c\u3002\u73b0\u6709\u5b66\u672f\u6587\u732e\u4e3b\u8981\u96c6\u4e2d\u5728\u673a\u5668\u4eba\u6d41\u7a0b\u81ea\u52a8\u5316\uff08RPA\uff09\uff0c\u4f46\u5b9e\u9645\u884c\u4e1a\u4e2d\u7684\u81ea\u52a8\u5316\u80fd\u529b\u8fdc\u4e0d\u6b62\u4e8e\u6b64\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5bf9Gartner\u9274\u5b9a\u51fa\u768418\u5bb6\u4e3b\u6d41\u4e1a\u52a1\u6d41\u7a0b\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u4f9b\u5e94\u5546\u8fdb\u884c\u7ed3\u6784\u5316\u5e02\u573a\u5206\u6790\uff0c\u7cfb\u7edf\u68b3\u7406\u4e86\u884c\u4e1a\u4e2d\u7684\u81ea\u52a8\u5316\u80fd\u529b\u3002", "result": "\u7814\u7a76\u5c55\u793a\u4e86\u76ee\u524d\u4e3b\u6d41\u5de5\u4e1a\u4f9b\u5e94\u5546\u6240\u63d0\u4f9b\u7684\u4e1a\u52a1\u6d41\u7a0b\u81ea\u52a8\u5316\u80fd\u529b\uff0c\u5e76\u5bf9\u81ea\u52a8\u5316\u7684\u4e0d\u540c\u7c7b\u578b\u548c\u65b9\u9762\u8fdb\u884c\u4e86\u5168\u9762\u68b3\u7406\uff1b\u540c\u65f6\u6307\u51fa\u4e86\u672a\u6765\u5177\u6709\u53d1\u5c55\u524d\u666f\u7684\u65b9\u5411\u3002", "conclusion": "\u4e3b\u6d41\u4f9b\u5e94\u5546\u5728\u4e1a\u52a1\u6d41\u7a0b\u81ea\u52a8\u5316\u65b9\u9762\u7684\u80fd\u529b\u8fdc\u8d85RPA\uff0c\u8986\u76d6\u4f17\u591a\u81ea\u52a8\u5316\u7c7b\u578b\u548c\u7ef4\u5ea6\uff0c\u8fd9\u4e3a\u884c\u4e1a\u548c\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u53c2\u8003\u3002"}}
{"id": "2506.11082", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11082", "abs": "https://arxiv.org/abs/2506.11082", "authors": ["Lionel Levine", "John Santerre", "Alex S. Young", "T. Barry Levine", "Francis Campion", "Majid Sarrafzadeh"], "title": "PRISM: A Transformer-based Language Model of Structured Clinical Event Data", "comment": "15 pages, 4 Figures, 1 Table", "summary": "We introduce PRISM (Predictive Reasoning in Sequential Medicine), a\ntransformer-based architecture designed to model the sequential progression of\nclinical decision-making processes. Unlike traditional approaches that rely on\nisolated diagnostic classification, PRISM frames clinical trajectories as\ntokenized sequences of events - including diagnostic tests, laboratory results,\nand diagnoses - and learns to predict the most probable next steps in the\npatient diagnostic journey. Leveraging a large custom clinical vocabulary and\nan autoregressive training objective, PRISM demonstrates the ability to capture\ncomplex dependencies across longitudinal patient timelines. Experimental\nresults show substantial improvements over random baselines in next-token\nprediction tasks, with generated sequences reflecting realistic diagnostic\npathways, laboratory result progressions, and clinician ordering behaviors.\nThese findings highlight the feasibility of applying generative language\nmodeling techniques to structured medical event data, enabling applications in\nclinical decision support, simulation, and education. PRISM establishes a\nfoundation for future advancements in sequence-based healthcare modeling,\nbridging the gap between machine learning architectures and real-world\ndiagnostic reasoning.", "AI": {"tldr": "PRISM\u662f\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff0c\u5c06\u4e34\u5e8a\u6d41\u7a0b\u5efa\u6a21\u4e3a\u4e8b\u4ef6\u5e8f\u5217\uff0c\u663e\u8457\u63d0\u5347\u4e86\u533b\u7597\u51b3\u7b56\u5e8f\u5217\u7684\u9884\u6d4b\u51c6\u786e\u5ea6\uff0c\u6709\u671b\u7528\u4e8e\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u548c\u6559\u80b2\u3002", "motivation": "\u4f20\u7edf\u7684\u4e34\u5e8a\u51b3\u7b56\u5efa\u6a21\u4fa7\u91cd\u4e8e\u5355\u4e2a\u8bca\u65ad\u5206\u7c7b\uff0c\u96be\u4ee5\u6355\u6349\u5b9e\u9645\u8bca\u65ad\u8fc7\u7a0b\u4e2d\u7684\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\u3002\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u5efa\u7acb\u80fd\u66f4\u771f\u5b9e\u6a21\u62df\u4e34\u5e8a\u51b3\u7b56\u5e8f\u5217\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u67b6\u6784PRISM\uff0c\u5c06\u4e34\u5e8a\u51b3\u7b56\u6d41\u7a0b\u5efa\u6a21\u4e3a\u4e8b\u4ef6\u5e8f\u5217\uff0c\u5229\u7528\u81ea\u56de\u5f52\u8bad\u7ec3\u76ee\u6807\u548c\u81ea\u5b9a\u4e49\u533b\u7597\u8bcd\u8868\u8fdb\u884c\u4e0b\u4e00\u6b65\u4e8b\u4ef6\u9884\u6d4b\u3002", "result": "PRISM\u5728\u4e0b\u4e00\u4e8b\u4ef6\u9884\u6d4b\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u968f\u673a\u57fa\u7ebf\uff0c\u751f\u6210\u7684\u4e8b\u4ef6\u5e8f\u5217\u80fd\u591f\u53cd\u6620\u5b9e\u9645\u7684\u8bca\u65ad\u8def\u5f84\u53ca\u533b\u62a4\u4eba\u5458\u884c\u4e3a\u3002", "conclusion": "PRISM\u80fd\u591f\u6a21\u62df\u771f\u5b9e\u533b\u7597\u8fc7\u7a0b\u4e2d\u8bca\u65ad\u8def\u5f84\u3001\u5b9e\u9a8c\u5ba4\u7ed3\u679c\u8fdb\u5c55\u548c\u4e34\u5e8a\u51b3\u7b56\u884c\u4e3a\uff0c\u4e3a\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u3001\u6a21\u62df\u548c\u6559\u80b2\u7b49\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6cd5\u3002"}}
{"id": "2506.10992", "categories": ["cs.SE", "D.2.9"], "pdf": "https://arxiv.org/pdf/2506.10992", "abs": "https://arxiv.org/abs/2506.10992", "authors": ["Hoang Vu", "Jennifer Haase", "Henrik Leopold", "Jan Mendling"], "title": "Towards a Theory on Process Automation Effects", "comment": "Accepted at HICSS 2023", "summary": "Process automation is a crucial strategy for improving business processes,\nbut little attention has been paid to the effects that automation has once it\nis operational. This paper addresses this research problem by reviewing the\nliterature on human-automation interaction. Although many of the studies in\nthis field have been conducted in different domains, they provide a foundation\nfor developing propositions about process automation effects. Our analysis\nfocuses on how humans perceive automation technology when working within a\nprocess, allowing us to propose an effective engagement model between\ntechnology, process participants, process managers, and software developers.\nThis paper offers insights and recommendations that can help organizations\noptimize their use of process automation. We further derive novel research\nquestions for a discourse within the process automation community.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4eba-\u81ea\u52a8\u5316\u4ea4\u4e92\u6587\u732e\uff0c\u63d0\u51fa\u4e86\u4f18\u5316\u6d41\u7a0b\u81ea\u52a8\u5316\u7684\u4eba\u673a\u534f\u4f5c\u6a21\u578b\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u548c\u5efa\u8bae\u3002", "motivation": "\u5c3d\u7ba1\u6d41\u7a0b\u81ea\u52a8\u5316\u5bf9\u4f01\u4e1a\u6548\u7387\u63d0\u5347\u5f88\u91cd\u8981\uff0c\u4f46\u5bf9\u4e8e\u81ea\u52a8\u5316\u6295\u5165\u8fd0\u8425\u540e\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u73b0\u6709\u6587\u732e\u5173\u6ce8\u4e0d\u591f\uff0c\u56e0\u6b64\u9700\u8981\u6df1\u5165\u63a2\u8ba8\u4eba\u548c\u81ea\u52a8\u5316\u7cfb\u7edf\u7684\u4ea4\u4e92\u673a\u5236\u3002", "method": "\u901a\u8fc7\u7efc\u8ff0\u4eba-\u81ea\u52a8\u5316\u4ea4\u4e92\u76f8\u5173\u9886\u57df\u7684\u6587\u732e\uff0c\u5f52\u7eb3\u4e86\u4e0d\u540c\u884c\u4e1a\u7684\u7814\u7a76\u53d1\u73b0\uff0c\u8fdb\u800c\u63d0\u51fa\u4e86\u6d41\u7a0b\u81ea\u52a8\u5316\u5f71\u54cd\u7684\u76f8\u5173\u547d\u9898\u3002", "result": "\u5206\u6790\u51fa\u4e86\u5f71\u54cd\u6d41\u7a0b\u81ea\u52a8\u5316\u6210\u6548\u7684\u4eba\u673a\u4e92\u52a8\u8981\u7d20\uff0c\u603b\u7ed3\u4e86\u5bf9\u7ec4\u7ec7\u5e94\u7528\u7684\u6d1e\u5bdf\u4e0e\u5efa\u8bae\uff0c\u5e76\u63d0\u51fa\u4e86\u503c\u5f97\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u95ee\u9898\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u4eba\u673a\u534f\u4f5c\u6a21\u578b\uff0c\u5e2e\u52a9\u7ec4\u7ec7\u4f18\u5316\u6d41\u7a0b\u81ea\u52a8\u5316\u7684\u5e94\u7528\uff0c\u5e76\u4e3a\u540e\u7eed\u5b66\u672f\u7814\u7a76\u63d0\u51fa\u4e86\u65b0\u95ee\u9898\u3002"}}
{"id": "2506.11083", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11083", "abs": "https://arxiv.org/abs/2506.11083", "authors": ["Ali Asad", "Stephen Obadinma", "Radin Shayanfar", "Xiaodan Zhu"], "title": "RedDebate: Safer Responses through Multi-Agent Red Teaming Debates", "comment": null, "summary": "We propose RedDebate, a novel multi-agent debate framework that leverages\nadversarial argumentation among Large Language Models (LLMs) to proactively\nidentify and mitigate their own unsafe behaviours. Existing AI safety methods\noften depend heavily on costly human evaluations or isolated single-model\nassessment, both subject to scalability constraints and oversight risks.\nRedDebate instead embraces collaborative disagreement, enabling multiple LLMs\nto critically examine one another's reasoning, and systematically uncovering\nunsafe blind spots through automated red-teaming, and iteratively improve their\nresponses. We further integrate distinct types of long-term memory that retain\nlearned safety insights from debate interactions. Evaluating on established\nsafety benchmarks such as HarmBench, we demonstrate the proposed method's\neffectiveness. Debate alone can reduce unsafe behaviours by 17.7%, and when\ncombined with long-term memory modules, achieves reductions exceeding 23.5%. To\nour knowledge, RedDebate constitutes the first fully automated framework that\ncombines multi-agent debates with red-teaming to progressively enhance AI\nsafety without direct human intervention.(Github Repository:\nhttps://github.com/aliasad059/RedDebate)", "AI": {"tldr": "RedDebate\u8ba9\u591a\u4e2a\u5927\u6a21\u578b\u4e92\u76f8\u8fa9\u8bba\u3001\u53d1\u73b0\u5b89\u5168\u95ee\u9898\u5e76\u81ea\u6211\u6539\u8fdb\uff0c\u65e0\u9700\u4eba\u5de5\u5c31\u80fd\u7a33\u6b65\u63d0\u5347AI\u5b89\u5168\uff0c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u76ee\u524dAI\u5b89\u5168\u65b9\u6cd5\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u6602\u8d35\u7684\u4eba\u7c7b\u8bc4\u4f30\u6216\u5355\u4e00\u6a21\u578b\u7684\u81ea\u6211\u8bc4\u4f30\uff0c\u8fd9\u5728\u53ef\u6269\u5c55\u6027\u548c\u76d1\u7763\u4e0a\u90fd\u5b58\u5728\u8bf8\u591a\u9650\u5236\u3002\u5982\u4f55\u5728\u65e0\u9700\u8fc7\u591a\u4eba\u5de5\u5e72\u9884\u4e0b\uff0c\u4e3b\u52a8\u53d1\u73b0\u4e0e\u7f13\u89e3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u8eab\u7684\u4e0d\u5b89\u5168\u884c\u4e3a\uff0c\u662f\u4e9f\u9700\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faRedDebate\u6846\u67b6\uff0c\u8ba9\u591a\u4e2aLLM\u4ee3\u7406\u4e4b\u95f4\u76f8\u4e92\u8fdb\u884c\u5bf9\u6297\u6027\u8fa9\u8bba\uff0c\u5b9e\u73b0\u534f\u4f5c\u5f0f\u8d28\u7591\u548c\u81ea\u52a8\u5316red-teaming\uff0c\u901a\u8fc7\u6301\u7eed\u7684\u591a\u8f6e\u4e92\u52a8\u81ea\u52a8\u53d1\u73b0\u76f2\u533a\u3001\u4e0d\u5b89\u5168\u884c\u4e3a\u5e76\u6539\u8fdb\u7b54\u6848\u3002\u6b64\u5916\uff0cRedDebate\u8fd8\u96c6\u6210\u591a\u79cd\u957f\u671f\u8bb0\u5fc6\u6a21\u5757\uff0c\u4fdd\u7559\u548c\u79ef\u7d2f\u5728\u8fa9\u8bba\u4e2d\u83b7\u5f97\u7684\u5b89\u5168\u77e5\u8bc6\uff0c\u7528\u4e8e\u63d0\u5347\u540e\u7eed\u8868\u73b0\u3002", "result": "\u5728\u516c\u5f00\u5b89\u5168\u6570\u636e\u96c6\uff08HarmBench\uff09\u4e0a\u8bc4\u6d4b\u7ed3\u679c\u8868\u660e\uff0c\u4ec5\u4f7f\u7528\u591a\u4ee3\u7406\u8fa9\u8bba\u53ef\u4ee5\u51cf\u5c1117.7%\u7684\u4e0d\u5b89\u5168\u884c\u4e3a\uff0c\u7ed3\u5408\u957f\u671f\u8bb0\u5fc6\u6a21\u5757\u540e\u53ef\u51cf\u5c11\u8d85\u8fc723.5%\u3002", "conclusion": "RedDebate\u662f\u9996\u4e2a\u5c06\u591a\u4ee3\u7406\u81ea\u52a8\u5316\u8fa9\u8bba\u4e0ered-teaming\u7ed3\u5408\u3001\u80fd\u5728\u65e0\u9700\u4eba\u5de5\u4ecb\u5165\u4e0b\u4e0d\u65ad\u63d0\u5347AI\u5b89\u5168\u6027\u7684\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u5728\u63d0\u5347LLM\u5b89\u5168\u8868\u73b0\u4e0a\u5c55\u73b0\u51fa\u6709\u6548\u6027\u548c\u521b\u65b0\u6027\u3002"}}
{"id": "2506.11088", "categories": ["cs.CL", "cs.AI", "68T50"], "pdf": "https://arxiv.org/pdf/2506.11088", "abs": "https://arxiv.org/abs/2506.11088", "authors": ["Pengbo Wang", "Chaozhuo Li", "Chenxu Wang", "Liwen Zheng", "Litian Zhang", "Xi Zhang"], "title": "Two Birds with One Stone: Improving Factuality and Faithfulness of LLMs via Dynamic Interactive Subspace Editing", "comment": null, "summary": "LLMs have demonstrated unprecedented capabilities in natural language\nprocessing, yet their practical deployment remains hindered by persistent\nfactuality and faithfulness hallucinations. While existing methods address\nthese hallucination types independently, they inadvertently induce performance\ntrade-offs, as interventions targeting one type often exacerbate the other.\nThrough empirical and theoretical analysis of activation space dynamics in\nLLMs, we reveal that these hallucination categories share overlapping subspaces\nwithin neural representations, presenting an opportunity for concurrent\nmitigation. To harness this insight, we propose SPACE, a unified framework that\njointly enhances factuality and faithfulness by editing shared activation\nsubspaces. SPACE establishes a geometric foundation for shared subspace\nexistence through dual-task feature modeling, then identifies and edits these\nsubspaces via a hybrid probe strategy combining spectral clustering and\nattention head saliency scoring. Experimental results across multiple benchmark\ndatasets demonstrate the superiority of our approach.", "AI": {"tldr": "\u8be5\u8bba\u6587\u53d1\u73b0\u5e76\u5229\u7528LLM\u5185\u90e8\u4e8b\u5b9e\u6027\u548c\u5fe0\u5b9e\u6027\u5e7b\u89c9\u5b58\u5728\u91cd\u53e0\u6fc0\u6d3b\u5b50\u7a7a\u95f4\uff0c\u901a\u8fc7\u8bbe\u8ba1SPACE\u6846\u67b6\u8fdb\u884c\u8054\u5408\u5efa\u6a21\u4e0e\u5e72\u9884\uff0c\u540c\u65f6\u63d0\u5347\u6a21\u578b\u7684\u4e8b\u5b9e\u6027\u548c\u5fe0\u5b9e\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u6548\u679c\u4f18\u8d8a\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u867d\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u5c55\u73b0\u524d\u6240\u672a\u6709\u7684\u80fd\u529b\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u65f6\u4ecd\u88ab\u201c\u4e8b\u5b9e\u6027\u201d\u548c\u201c\u5fe0\u5b9e\u6027\u201d\u5e7b\u89c9\u95ee\u9898\u6240\u56f0\u6270\u3002\u73b0\u6709\u7684\u6d88\u9664\u5e7b\u89c9\u65b9\u6cd5\u901a\u5e38\u5355\u72ec\u5904\u7406\u8fd9\u7c7b\u95ee\u9898\uff0c\u5bfc\u81f4\u4e00\u7c7b\u6539\u5584\u540e\u53e6\u4e00\u7c7b\u6076\u5316\uff0c\u5b58\u5728\u6027\u80fd\u6743\u8861\u3002\u56e0\u6b64\u9700\u5bfb\u627e\u517c\u987e\u4e8c\u8005\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u540d\u4e3aSPACE\u7684\u7edf\u4e00\u6846\u67b6\uff1a\u9996\u5148\u901a\u8fc7\u5bf9\u53cc\u4efb\u52a1\u7279\u5f81\u5efa\u6a21\uff0c\u8bc1\u660e\u5728\u795e\u7ecf\u8868\u5f81\u4e2d\u5b58\u5728\u5171\u4eab\u5b50\u7a7a\u95f4\uff1b\u518d\u5229\u7528\u6df7\u5408\u63a2\u9488\u7b56\u7565\uff08\u7ed3\u5408\u8c31\u805a\u7c7b\u4e0e\u6ce8\u610f\u529b\u5934\u663e\u8457\u6027\u6253\u5206\uff09\u5b9a\u4f4d\u5e76\u7f16\u8f91\u8fd9\u4e9b\u5171\u4eab\u6fc0\u6d3b\u5b50\u7a7a\u95f4\uff0c\u4ee5\u540c\u65f6\u63d0\u5347\u4e8b\u5b9e\u6027\u548c\u5fe0\u5b9e\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cSPACE\u65b9\u6cd5\u5728\u63d0\u5347LLM\u7684\u4e8b\u5b9e\u6027\u4e0e\u5fe0\u5b9e\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u73b0\u4e86\u660e\u663e\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "SPACE\u6846\u67b6\u80fd\u591f\u901a\u8fc7\u7f16\u8f91\u5171\u4eab\u795e\u7ecf\u6fc0\u6d3b\u5b50\u7a7a\u95f4\u6765\u540c\u6b65\u7f13\u89e3\u4e8b\u5b9e\u6027\u548c\u5fe0\u5b9e\u6027\u5e7b\u89c9\uff0c\u4e3aLLM\u7684\u5b89\u5168\u53ef\u63a7\u5e94\u7528\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2506.10994", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.10994", "abs": "https://arxiv.org/abs/2506.10994", "authors": ["April Clarke"], "title": "Improving Software Team Communication Through Social Interventions in Project Management Tools", "comment": "ICSE 2025 Doctoral Track. arXiv admin note: substantial text overlap\n  with arXiv:2502.01923", "summary": "Productive software engineering teams require effective communication and\nbalanced contributions between team members. However, teams are often\nineffective at these skills, which is detrimental to project success.\nProject-based university courses are an opportunity for students to practise\nthese skills, but we have yet to establish how we can guide students towards\nimproving their communication and coordination. We aim to develop project\nmanagement tool features, informed by social network analysis, that nudge\nstudents in software engineering group projects towards beneficial behaviours.\nTo do this, we will first evaluate the suitability of social network analysis\ntechniques for identifying areas of improvement in teams' communication. Then,\nwe will develop features in a project management tool that aid students in\nidentifying and addressing these areas of improvement, and evaluate them in the\ncontext of a software engineering group project.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u793e\u4ea4\u7f51\u7edc\u5206\u6790\u65b9\u6cd5\u8bca\u65ad\u5e76\u6539\u5584\u5927\u5b66\u8f6f\u4ef6\u5de5\u7a0b\u5c0f\u7ec4\u9879\u76ee\u4e2d\u7684\u6c9f\u901a\u548c\u534f\u8c03\uff0c\u5f00\u53d1\u5e76\u9a8c\u8bc1\u76f8\u5e94\u7684\u9879\u76ee\u7ba1\u7406\u5de5\u5177\u529f\u80fd\u4ee5\u4fc3\u8fdb\u66f4\u6709\u6548\u7684\u56e2\u961f\u5408\u4f5c\u3002", "motivation": "\u73b0\u6709\u9879\u76ee\u5c0f\u7ec4\u666e\u904d\u7f3a\u4e4f\u6709\u6548\u6c9f\u901a\u548c\u5747\u8861\u8d21\u732e\uff0c\u5f71\u54cd\u9879\u76ee\u6210\u529f\u3002\u5927\u5b66\u8bfe\u7a0b\u662f\u57f9\u517b\u5b66\u751f\u76f8\u5173\u80fd\u529b\u7684\u573a\u6240\uff0c\u4f46\u7f3a\u4e4f\u6709\u6548\u7684\u65b9\u6cd5\u5f15\u5bfc\u5b66\u751f\u63d0\u5347\u6c9f\u901a\u534f\u4f5c\u3002", "method": "\u9996\u5148\u8bc4\u4f30\u793e\u4ea4\u7f51\u7edc\u5206\u6790\u5728\u53d1\u73b0\u56e2\u961f\u6c9f\u901a\u6539\u8fdb\u7a7a\u95f4\u7684\u9002\u5b9c\u6027\uff0c\u5176\u6b21\u5f00\u53d1\u80fd\u5e2e\u52a9\u5b66\u751f\u8bc6\u522b\u5e76\u6539\u5584\u6c9f\u901a\u95ee\u9898\u7684\u9879\u76ee\u7ba1\u7406\u5de5\u5177\u529f\u80fd\uff0c\u6700\u540e\u5728\u5b9e\u9645\u8f6f\u4ef6\u5de5\u7a0b\u5c0f\u7ec4\u9879\u76ee\u4e2d\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u9884\u671f\u7ed3\u679c\u662f\u5f00\u53d1\u5e76\u9a8c\u8bc1\u4e00\u5957\u57fa\u4e8e\u793e\u4ea4\u7f51\u7edc\u5206\u6790\u7684\u9879\u76ee\u7ba1\u7406\u5de5\u5177\u529f\u80fd\uff0c\u80fd\u591f\u63d0\u5347\u5b66\u751f\u5c0f\u7ec4\u5728\u6c9f\u901a\u4e0e\u534f\u8c03\u65b9\u9762\u7684\u8868\u73b0\u3002", "conclusion": "\u8be5\u8bba\u6587\u8ba1\u5212\u8bc1\u660e\u57fa\u4e8e\u793e\u4ea4\u7f51\u7edc\u5206\u6790\u7684\u9879\u76ee\u7ba1\u7406\u5de5\u5177\u529f\u80fd\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u5b66\u751f\u9879\u76ee\u56e2\u961f\u7684\u6c9f\u901a\u4e0e\u534f\u8c03\u80fd\u529b\u3002"}}
{"id": "2506.11091", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.11091", "abs": "https://arxiv.org/abs/2506.11091", "authors": ["Shaoshi Ling", "Guoli Ye"], "title": "Customizing Speech Recognition Model with Large Language Model Feedback", "comment": null, "summary": "Automatic speech recognition (ASR) systems have achieved strong performance\non general transcription tasks. However, they continue to struggle with\nrecognizing rare named entities and adapting to domain mismatches. In contrast,\nlarge language models (LLMs), trained on massive internet-scale datasets, are\noften more effective across a wide range of domains. In this work, we propose a\nreinforcement learning based approach for unsupervised domain adaptation,\nleveraging unlabeled data to enhance transcription quality, particularly the\nnamed entities affected by domain mismatch, through feedback from a LLM. Given\ncontextual information, our framework employs a LLM as the reward model to\nscore the hypotheses from the ASR model. These scores serve as reward signals\nto fine-tune the ASR model via reinforcement learning. Our method achieves a\n21\\% improvement on entity word error rate over conventional self-training\nmethods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u53cd\u9988\u4fe1\u53f7\u7684\u65e0\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86ASR\u5728\u4e13\u6709\u540d\u8bcd\u53ca\u9886\u57df\u8f6c\u5f55\u4e0a\u7684\u8868\u73b0\uff0c\u5b9e\u4f53\u8bcd\u9519\u8bef\u7387\u6bd4\u4f20\u7edf\u65b9\u6cd5\u964d\u4f4e21%\u3002", "motivation": "\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u7cfb\u7edf\u5728\u4e00\u822c\u8f6c\u5f55\u4efb\u52a1\u4e2d\u8868\u73b0\u8f83\u597d\uff0c\u4f46\u5728\u8bc6\u522b\u7f55\u89c1\u4e13\u6709\u540d\u8bcd\u548c\u9002\u5e94\u9886\u57df\u4e0d\u5339\u914d\u65b9\u9762\u4f9d\u7136\u5b58\u5728\u56f0\u96be\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4f17\u591a\u9886\u57df\u5e38\u5e38\u8868\u73b0\u66f4\u4f18\u3002\u56e0\u6b64\uff0c\u63d0\u5347ASR\u7cfb\u7edf\u7684\u9886\u57df\u9002\u5e94\u80fd\u529b\u6210\u4e3a\u4e9f\u9700\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65e0\u76d1\u7763\u9886\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\u3002\u901a\u8fc7\u5229\u7528\u65e0\u6807\u7b7e\u6570\u636e\uff0c\u5e76\u501f\u52a9\u5927\u8bed\u8a00\u6a21\u578b\u5bf9ASR\u6a21\u578b\u8f93\u51fa\u8fdb\u884c\u6253\u5206\uff0c\u5c06\u5f97\u5206\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03ASR\u6a21\u578b\u3002\u8fd9\u6837\u7684\u65b9\u6cd5\u53ef\u63d0\u5347\u4e13\u6709\u540d\u8bcd\u7684\u8f6c\u5f55\u6548\u679c\uff0c\u5c24\u5176\u662f\u5728\u9886\u57df\u4e0d\u5339\u914d\u7684\u60c5\u51b5\u4e0b\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728\u5b9e\u4f53\u5355\u8bcd\u9519\u8bef\u7387\uff08entity word error rate\uff09\u4e0a\u76f8\u8f83\u4e8e\u4f20\u7edf\u81ea\u8bad\u7ec3\u65b9\u6cd5\u5b9e\u73b0\u4e8621%\u7684\u63d0\u5347\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u8bc1\u660e\uff0c\u901a\u8fc7\u5229\u7528\u65e0\u76d1\u7763\u7684\u5f3a\u5316\u5b66\u4e60\u548c\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u5956\u52b1\u6a21\u578b\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347ASR\u5bf9\u9886\u57df\u7279\u6709\u540d\u8bcd\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u6709\u6548\u7f13\u89e3\u9886\u57df\u4e0d\u5339\u914d\u5e26\u6765\u7684\u6027\u80fd\u4e0b\u964d\u3002"}}
{"id": "2506.10995", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.10995", "abs": "https://arxiv.org/abs/2506.10995", "authors": ["Jorge Martinez-Gil"], "title": "Evaluating Small-Scale Code Models for Code Clone Detection", "comment": "20 pages", "summary": "Detecting code clones is relevant to software maintenance and code\nrefactoring. This challenge still presents unresolved cases, mainly when\nstructural similarity does not reflect functional equivalence, though recent\ncode models show promise. Therefore, this research aims to systematically\nmeasure the performance of several newly introduced small code models in\nclassifying code pairs as clones or non-clones. The evaluation is based on five\ndatasets: BigCloneBench, CodeJam, Karnalim, POJ104, and PoolC, as well as six\ncode models: CodeBERT, GraphCodeBERT, Salesforce T5, UniXCoder, PLBART, and\nPolycoder. Most models performed well across standard metrics, including\naccuracy, precision, recall, and F1-score. However, a marginal fraction of\nclones remains challenging to detect, especially when the code looks similar\nbut performs different operations. The source code that illustrates our\napproach is available at:\nhttps://github.com/jorge-martinez-gil/small-code-models", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u6d4b\u4e86\u516d\u79cd\u6700\u65b0\u5c0f\u578b\u4ee3\u7801\u6a21\u578b\u5728\u4e94\u5927\u6570\u636e\u96c6\u4e0a\u7684\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u6027\u80fd\u3002\u53d1\u73b0\u6a21\u578b\u603b\u4f53\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5bf9\u4e8e\u7ed3\u6784\u7c7b\u4f3c\u4e14\u529f\u80fd\u4e0d\u540c\u7684\u4ee3\u7801\u5bf9\uff0c\u4ecd\u5b58\u68c0\u6d4b\u96be\u9898\uff0c\u663e\u793a\u7814\u7a76\u4ecd\u9700\u5728\u6b64\u9886\u57df\u6df1\u5165\u3002", "motivation": "\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u5bf9\u8f6f\u4ef6\u7ef4\u62a4\u548c\u91cd\u6784\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u5373\u4f7f\u4f7f\u7528\u6700\u65b0\u7684\u4ee3\u7801\u6a21\u578b\uff0c\u7ed3\u6784\u76f8\u4f3c\u4f46\u529f\u80fd\u4e0d\u540c\u7684\u4ee3\u7801\u5bf9\u68c0\u6d4b\u4ecd\u662f\u5de8\u5927\u6311\u6218\u3002", "method": "\u7cfb\u7edf\u8bc4\u6d4b\u4e86\u516d\u79cd\u6700\u65b0\u5c0f\u578b\u4ee3\u7801\u6a21\u578b\uff08CodeBERT\u3001GraphCodeBERT\u3001Salesforce T5\u3001UniXCoder\u3001PLBART\u3001Polycoder\uff09\u5728\u4e94\u4e2a\u6570\u636e\u96c6\uff08BigCloneBench, CodeJam, Karnalim, POJ104, PoolC\uff09\u4e0a\u7684\u514b\u9686\u68c0\u6d4b\u8868\u73b0\uff0c\u901a\u8fc7\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1-score\u7b49\u6807\u51c6\u6307\u6807\u6bd4\u8f83\u6a21\u578b\u3002", "result": "\u5927\u591a\u6570\u6a21\u578b\u5728\u5404\u9879\u5ea6\u91cf\u6307\u6807\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5904\u7406\u5916\u89c2\u76f8\u4f3c\u4f46\u529f\u80fd\u4e0d\u540c\u7684\u4ee3\u7801\u65f6\uff0c\u4ecd\u6709\u90e8\u5206\u514b\u9686\u96be\u4ee5\u68c0\u6d4b\u3002", "conclusion": "\u73b0\u6709\u5c0f\u578b\u4ee3\u7801\u6a21\u578b\u5bf9\u5927\u90e8\u5206\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u4efb\u52a1\u6548\u679c\u4e0d\u9519\uff0c\u4f46\u9488\u5bf9\u7ed3\u6784\u76f8\u4f3c\u4e14\u8bed\u4e49\u4e0d\u540c\u7684\u6781\u7aef\u60c5\u51b5\uff0c\u4ecd\u5b58\u5728\u663e\u8457\u6311\u6218\u3002"}}
{"id": "2506.11092", "categories": ["cs.CL", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.11092", "abs": "https://arxiv.org/abs/2506.11092", "authors": ["Jubin Abhishek Soni", "Amit Anand", "Rajesh Kumar Pandey", "Aniket Abhishek Soni"], "title": "Dynamic Context Tuning for Retrieval-Augmented Generation: Enhancing Multi-Turn Planning and Tool Adaptation", "comment": "6 pages, 5 figures, 3 tables. This manuscript has been submitted to\n  IEEE conference. Researchers are welcome to read and build upon this work;\n  please cite it appropriately. For questions or clarifications, feel free to\n  contact me", "summary": "Retrieval-Augmented Generation (RAG) has significantly advanced large\nlanguage models (LLMs) by grounding their outputs in external tools and\nknowledge sources. However, existing RAG systems are typically constrained to\nstatic, single-turn interactions with fixed toolsets, making them ill-suited\nfor dynamic domains such as healthcare and smart homes, where user intent,\navailable tools, and contextual factors evolve over time. We present Dynamic\nContext Tuning (DCT), a lightweight framework that extends RAG to support\nmulti-turn dialogue and evolving tool environments without requiring\nretraining. DCT integrates an attention-based context cache to track relevant\npast information, LoRA-based retrieval to dynamically select domain-specific\ntools, and efficient context compression to maintain inputs within LLM context\nlimits. Experiments on both synthetic and real-world benchmarks show that DCT\nimproves plan accuracy by 14% and reduces hallucinations by 37%, while matching\nGPT-4 performance at significantly lower cost. Furthermore, DCT generalizes to\npreviously unseen tools, enabling scalable and adaptable AI assistants across a\nwide range of dynamic environments.", "AI": {"tldr": "\u672c\u8bba\u6587\u9488\u5bf9RAG\u7cfb\u7edf\u5728\u52a8\u6001\u73af\u5883\u4e0b\u7684\u5c40\u9650\uff0c\u63d0\u51faDCT\u6846\u67b6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u7f13\u5b58\u3001\u52a8\u6001\u68c0\u7d22\u548c\u4e0a\u4e0b\u6587\u538b\u7f29\uff0c\u8ba9RAG\u652f\u6301\u591a\u8f6e\u5bf9\u8bdd\u548c\u52a8\u6001\u5de5\u5177\u9009\u62e9\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\uff0c\u4e14\u663e\u8457\u63d0\u5347\u51c6\u786e\u7387\u4e0e\u6548\u7387\uff0c\u6709\u671b\u5e7f\u6cdb\u7528\u4e8e\u53ef\u6269\u5c55\u7684AI\u52a9\u624b\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u5927\u591a\u5c40\u9650\u4e8e\u9759\u6001\u3001\u5355\u8f6e\u7684\u4ea4\u4e92\u548c\u56fa\u5b9a\u7684\u5de5\u5177\u96c6\uff0c\u8fd9\u8ba9\u5b83\u4eec\u5728\u7528\u6237\u9700\u6c42\u3001\u5de5\u5177\u548c\u73af\u5883\u4e0d\u65ad\u53d8\u5316\u7684\u52a8\u6001\u9886\u57df\uff08\u5982\u533b\u7597\u3001\u667a\u80fd\u5bb6\u5c45\uff09\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201cDynamic Context Tuning\uff08DCT\uff09\u201d\u7684\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u6269\u5c55RAG\u4ee5\u652f\u6301\u591a\u8f6e\u5bf9\u8bdd\u548c\u5de5\u5177\u73af\u5883\u7684\u53d8\u5316\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002DCT\u5f15\u5165\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u4e0a\u4e0b\u6587\u7f13\u5b58\u8ddf\u8e2a\u76f8\u5173\u5386\u53f2\u4fe1\u606f\uff0c\u57fa\u4e8eLoRA\u7684\u68c0\u7d22\u52a8\u6001\u9009\u62e9\u9886\u57df\u5de5\u5177\uff0c\u5e76\u91c7\u7528\u9ad8\u6548\u4e0a\u4e0b\u6587\u538b\u7f29\u4ee5\u9002\u5e94LLM\u8f93\u5165\u957f\u5ea6\u9650\u5236\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u4e0a\uff0cDCT\u5c06\u8ba1\u5212\u51c6\u786e\u7387\u63d0\u5347\u4e8614%\uff0c\u964d\u4f4e\u4e8637%\u7684\u5e7b\u89c9\u73b0\u8c61\uff0c\u5e76\u80fd\u591f\u4ee5\u8fdc\u4f4e\u4e8eGPT-4\u7684\u6210\u672c\u5b9e\u73b0\u76f8\u5f53\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0cDCT\u8fd8\u80fd\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u65b0\u5de5\u5177\u3002", "conclusion": "DCT\u4f7fRAG\u7cfb\u7edf\u80fd\u591f\u5728\u52a8\u6001\u73af\u5883\u4e2d\u66f4\u9ad8\u6548\u5730\u9002\u5e94\u548c\u6269\u5c55\uff0c\u63d0\u9ad8\u4e86\u591a\u8f6e\u5bf9\u8bdd\u4e0e\u5de5\u5177\u9009\u62e9\u7684\u7075\u6d3b\u6027\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u53ca\u53ef\u9002\u5e94\u6027\u7684AI\u52a9\u624b\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.10996", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.10996", "abs": "https://arxiv.org/abs/2506.10996", "authors": ["Saadiq Rauf Khan", "Vinit Chandak", "Sougata Mukherjea"], "title": "Evaluating LLMs for Visualization Tasks", "comment": null, "summary": "Information Visualization has been utilized to gain insights from complex\ndata. In recent times, Large Language Models (LLMs) have performed very well in\nmany tasks. In this paper, we showcase the capabilities of different popular\nLLMs to generate code for visualization based on simple prompts. We also\nanalyze the power of LLMs to understand some common visualizations by answering\nsimple questions. Our study shows that LLMs could generate code for some\nvisualizations as well as answer questions about them. However, LLMs also have\nseveral limitations. We believe that our insights can be used to improve both\nLLMs and Information Visualization systems.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53ef\u89c6\u5316\u4ee3\u7801\u751f\u6210\u548c\u53ef\u89c6\u5316\u7406\u89e3\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u5177\u5907\u4e00\u5b9a\u80fd\u529b\u4f46\u4ecd\u6709\u5c40\u9650\uff0c\u5bf9\u4eca\u540e\u6539\u8fdbLLM\u548c\u53ef\u89c6\u5316\u7cfb\u7edf\u6709\u542f\u53d1\u4f5c\u7528\u3002", "motivation": "\u4fe1\u606f\u53ef\u89c6\u5316\u80fd\u591f\u5e2e\u52a9\u7528\u6237\u4ece\u590d\u6742\u6570\u636e\u4e2d\u83b7\u53d6\u6d1e\u89c1\u3002\u5f53\u524d\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8bb8\u591a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u56e0\u6b64\u8be5\u8bba\u6587\u63a2\u7d22LLM\u5728\u53ef\u89c6\u5316\u9886\u57df\u7684\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u5bf9\u591a\u79cd\u6d41\u884cLLM\u8fdb\u884c\u4e86\u80fd\u529b\u5c55\u793a\uff0c\u901a\u8fc7\u7b80\u5355\u63d0\u793a\u8ba9\u5b83\u4eec\u751f\u6210\u53ef\u89c6\u5316\u4ee3\u7801\uff0c\u5e76\u8bc4\u4f30\u5b83\u4eec\u901a\u8fc7\u56de\u7b54\u57fa\u7840\u95ee\u9898\u6765\u7406\u89e3\u5e38\u89c1\u53ef\u89c6\u5316\u7684\u80fd\u529b\u3002", "result": "LLM\u80fd\u591f\u4e3a\u90e8\u5206\u53ef\u89c6\u5316\u4efb\u52a1\u751f\u6210\u4ee3\u7801\uff0c\u5e76\u80fd\u89e3\u7b54\u53ef\u89c6\u5316\u76f8\u5173\u95ee\u9898\uff0c\u4f46\u5728\u591a\u65b9\u9762\u4ecd\u663e\u73b0\u51fa\u5c40\u9650\u3002", "conclusion": "LLM\u5728\u4fe1\u606f\u53ef\u89c6\u5316\u4e2d\u7684\u5e94\u7528\u5c55\u73b0\u4e86\u4e00\u5b9a\u6f5c\u529b\uff0c\u4f46\u4e5f\u5b58\u5728\u4e0d\u8db3\uff0c\u8fd9\u4e9b\u53d1\u73b0\u53ef\u4ee5\u4e3aLLM\u548c\u4fe1\u606f\u53ef\u89c6\u5316\u7cfb\u7edf\u7684\u6539\u8fdb\u63d0\u4f9b\u501f\u9274\u3002"}}
{"id": "2506.11094", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2506.11094", "abs": "https://arxiv.org/abs/2506.11094", "authors": ["Songyang Liu", "Chaozhuo Li", "Jiameng Qiu", "Xi Zhang", "Feiran Huang", "Litian Zhang", "Yiming Hei", "Philip S. Yu"], "title": "The Scales of Justitia: A Comprehensive Survey on Safety Evaluation of LLMs", "comment": "21 pages, preprint", "summary": "With the rapid advancement of artificial intelligence technology, Large\nLanguage Models (LLMs) have demonstrated remarkable potential in the field of\nNatural Language Processing (NLP), including areas such as content generation,\nhuman-computer interaction, machine translation, and code generation, among\nothers. However, their widespread deployment has also raised significant safety\nconcerns. In recent years, LLM-generated content has occasionally exhibited\nunsafe elements like toxicity and bias, particularly in adversarial scenarios,\nwhich has garnered extensive attention from both academia and industry. While\nnumerous efforts have been made to evaluate the safety risks associated with\nLLMs, there remains a lack of systematic reviews summarizing these research\nendeavors. This survey aims to provide a comprehensive and systematic overview\nof recent advancements in LLMs safety evaluation, focusing on several key\naspects: (1) \"Why evaluate\" that explores the background of LLMs safety\nevaluation, how they differ from general LLMs evaluation, and the significance\nof such evaluation; (2) \"What to evaluate\" that examines and categorizes\nexisting safety evaluation tasks based on key capabilities, including\ndimensions such as toxicity, robustness, ethics, bias and fairness,\ntruthfulness, and so on; (3) \"Where to evaluate\" that summarizes the evaluation\nmetrics, datasets and benchmarks currently used in safety evaluations; (4) \"How\nto evaluate\" that reviews existing evaluation toolkit, and categorizing\nmainstream evaluation methods based on the roles of the evaluators. Finally, we\nidentify the challenges in LLMs safety evaluation and propose potential\nresearch directions to promote further advancement in this field. We emphasize\nthe importance of prioritizing LLMs safety evaluation to ensure the safe\ndeployment of these models in real-world applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6027\u8bc4\u4f30\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u68b3\u7406\u4e86\u8bc4\u4f30\u80cc\u666f\u3001\u7ef4\u5ea6\u3001\u65b9\u6cd5\u3001\u5de5\u5177\uff0c\u4ee5\u53ca\u5f53\u524d\u9762\u4e34\u7684\u6311\u6218\u5e76\u63d0\u51fa\u524d\u77bb\u6027\u7814\u7a76\u65b9\u5411\uff0c\u7a81\u51fa\u4e86\u5b89\u5168\u6027\u8bc4\u4f30\u5728LLMs\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u91cd\u8981\u4f5c\u7528\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5728\u5e7f\u6cdb\u5e94\u7528\u8fc7\u7a0b\u4e2d\uff0c\u5176\u751f\u6210\u5185\u5bb9\u4e2d\u51fa\u73b0\u4e86\u6bd2\u6027\u3001\u504f\u89c1\u7b49\u5b89\u5168\u95ee\u9898\uff0c\u5f15\u53d1\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u5e7f\u6cdb\u5173\u6ce8\uff0c\u4e9f\u9700\u5bf9\u73b0\u6709\u5b89\u5168\u6027\u8bc4\u4f30\u7814\u7a76\u8fdb\u884c\u7cfb\u7edf\u6027\u7efc\u8ff0\u3002", "method": "\u672c\u6587\u4ee5\u7efc\u8ff0\uff08survey\uff09\u5f62\u5f0f\uff0c\u7cfb\u7edf\u68b3\u7406\u548c\u603b\u7ed3\u4e86\u5173\u4e8eLLMs\u5b89\u5168\u6027\u8bc4\u4f30\u7684\u6700\u65b0\u7814\u7a76\u8fdb\u5c55\u3002\u5185\u5bb9\u5305\u62ec\u8bc4\u4f30\u7684\u52a8\u673a\u3001\u8bc4\u4f30\u76ee\u6807\uff08\u5982\u6bd2\u6027\u3001\u9c81\u68d2\u6027\u3001\u4f26\u7406\u3001\u771f\u786e\u6027\u7b49\uff09\u3001\u8bc4\u4f30\u7528\u7684\u6570\u636e\u96c6\u4e0e\u5ea6\u91cf\u3001\u8bc4\u4f30\u5de5\u5177\u4e0e\u65b9\u6cd5\uff0c\u5e76\u68b3\u7406\u9762\u4e34\u7684\u6311\u6218\u4e0e\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "result": "\u672c\u6587\u5bf9LLMs\u5b89\u5168\u6027\u8bc4\u4f30\u7684\u5173\u952e\u65b9\u9762\u8fdb\u884c\u4e86\u5168\u9762\u603b\u7ed3\uff1a\u4e00\u662f\u9610\u660e\u4e86\u5b89\u5168\u6027\u8bc4\u4f30\u7684\u91cd\u8981\u6027\uff1b\u4e8c\u662f\u57fa\u4e8e\u591a\u7ef4\u5ea6\u80fd\u529b\u5bf9\u8bc4\u4f30\u4efb\u52a1\u8fdb\u884c\u5f52\u7c7b\uff1b\u4e09\u662f\u5bf9\u5f53\u524d\u4e3b\u6d41\u7684\u8bc4\u4f30\u6570\u636e\u96c6\u4e0e\u57fa\u51c6\u8fdb\u884c\u603b\u7ed3\uff1b\u56db\u662f\u5f52\u7eb3\u4e86\u8bc4\u4f30\u5de5\u5177\u548c\u65b9\u6cd5\u3002\u6700\u540e\uff0c\u63d0\u51fa\u4e86\u5f53\u524d\u9886\u57df\u9762\u4e34\u7684\u82e5\u5e72\u6311\u6218\u4e0e\u540e\u7eed\u7814\u7a76\u5efa\u8bae\u3002", "conclusion": "LLMs\u7684\u5b89\u5168\u6027\u8bc4\u4f30\u662f\u6a21\u578b\u843d\u5730\u5e94\u7528\u524d\u7684\u5173\u952e\u73af\u8282\u3002\u7cfb\u7edf\u68b3\u7406\u73b0\u6709\u8bc4\u4f30\u7814\u7a76\u6709\u52a9\u4e8e\u5398\u6e05\u73b0\u72b6\u3001\u89e3\u51b3\u5b89\u5168\u95ee\u9898\uff0c\u52a0\u901f\u5b89\u5168\u6280\u672f\u7684\u53d1\u5c55\u4e0e\u5e94\u7528\u63a8\u884c\u3002\u4e3a\u540e\u7eedLLMs\u5b89\u5168\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u529b\u53c2\u8003\u3002"}}
{"id": "2506.10997", "categories": ["cs.SE", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.10997", "abs": "https://arxiv.org/abs/2506.10997", "authors": ["Hanumanthrao Kannan", "Alejandro Salado"], "title": "A Theory-driven Interpretation and Elaboration of Verification and Validation", "comment": null, "summary": "This paper presents a formal theory of verification and validation (V&V)\nwithin systems engineering, grounded in the axiom that V&V are fundamentally\nknowledge-building activities. Using dynamic epistemic modal logic, we develop\nprecise definitions of verification and validation, articulating their roles in\nconfirming and contextualizing knowledge about systems. The theory formalizes\nthe interplay between epistemic states, evidence, and reasoning processes,\nallowing for the derivation of theorems that clarify the conceptual\nunderpinnings of V&V. By providing a formal foundation, this work addresses\nambiguities in traditional V&V practices, offering a structured framework to\nenhance precision and consistency in systems engineering methodologies. The\ninsights gained have implications for both academic research and practical\napplications, fostering a deeper understanding of V&V as critical components of\nengineering knowledge generation.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u52a8\u6001\u8ba4\u77e5\u6a21\u6001\u903b\u8f91\uff0c\u63d0\u51fa\u4e86V&V\u7684\u5f62\u5f0f\u7406\u8bba\uff0c\u6d88\u9664\u4e86\u4f20\u7edf\u5b9e\u8df5\u4e2d\u7684\u6a21\u7cca\u4e4b\u5904\uff0c\u5e76\u52a0\u5f3a\u4e86\u7cfb\u7edf\u5de5\u7a0b\u4e2dV&V\u7684\u65b9\u6cd5\u5b66\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u5de5\u7a0b\u4e2d\u7684\u9a8c\u8bc1\u4e0e\u786e\u8ba4\uff08V&V\uff09\u5b9e\u8df5\u5728\u6982\u5ff5\u5c42\u9762\u5b58\u5728\u6a21\u7cca\uff0c\u7f3a\u4e4f\u7cbe\u786e\u7684\u5b9a\u4e49\u548c\u7edf\u4e00\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u91c7\u7528\u52a8\u6001\u8ba4\u77e5\u6a21\u6001\u903b\u8f91\uff0c\u5bf9V&V\u8fdb\u884c\u5f62\u5f0f\u5316\u5efa\u6a21\uff0c\u5efa\u7acb\u5bf9V&V\u7684\u7cbe\u786e\u5b9a\u4e49\uff0c\u5e76\u63a8\u5bfc\u76f8\u5173\u5b9a\u7406\u4ee5\u9610\u8ff0\u5176\u6982\u5ff5\u57fa\u7840\u3002", "result": "\u63d0\u51fa\u4e86V&V\u7684\u4e25\u683c\u7406\u8bba\uff0c\u660e\u786e\u4e86\u5b83\u4eec\u5728\u7cfb\u7edf\u77e5\u8bc6\u786e\u8ba4\u4e0e\u5efa\u6784\u4e2d\u7684\u4f5c\u7528\uff0c\u5e76\u5c06V&V\u7eb3\u5165\u77e5\u8bc6\u751f\u6210\u7684\u6b63\u5f0f\u6846\u67b6\u3002\u8be5\u7406\u8bba\u6d88\u9664\u4e86\u4f20\u7edfV&V\u5b9e\u8df5\u4e2d\u7684\u4e0d\u660e\u786e\u6027\u3002", "conclusion": "\u672c\u5de5\u4f5c\u4e3a\u7cfb\u7edf\u5de5\u7a0b\u4e2d\u7684V&V\u63d0\u4f9b\u4e86\u6b63\u5f0f\u7406\u8bba\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u63d0\u5347V&V\u8fc7\u7a0b\u7684\u7cbe\u51c6\u6027\u4e0e\u4e00\u81f4\u6027\uff0c\u5bf9\u5b66\u672f\u53ca\u5b9e\u9645\u5e94\u7528\u5747\u6709\u79ef\u6781\u5f71\u54cd\u3002"}}
{"id": "2506.11095", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11095", "abs": "https://arxiv.org/abs/2506.11095", "authors": ["Manuel D. S. Hopp", "Vincent Labatut", "Arthur Amalvy", "Richard Dufour", "Hannah Stone", "Hayley Jach", "Kou Murayama"], "title": "Persistent Homology of Topic Networks for the Prediction of Reader Curiosity", "comment": null, "summary": "Reader curiosity, the drive to seek information, is crucial for textual\nengagement, yet remains relatively underexplored in NLP. Building on\nLoewenstein's Information Gap Theory, we introduce a framework that models\nreader curiosity by quantifying semantic information gaps within a text's\nsemantic structure. Our approach leverages BERTopic-inspired topic modeling and\npersistent homology to analyze the evolving topology (connected components,\ncycles, voids) of a dynamic semantic network derived from text segments,\ntreating these features as proxies for information gaps. To empirically\nevaluate this pipeline, we collect reader curiosity ratings from participants\n(n = 49) as they read S. Collins's ''The Hunger Games'' novel. We then use the\ntopological features from our pipeline as independent variables to predict\nthese ratings, and experimentally show that they significantly improve\ncuriosity prediction compared to a baseline model (73% vs. 30% explained\ndeviance), validating our approach. This pipeline offers a new computational\nmethod for analyzing text structure and its relation to reader engagement.", "AI": {"tldr": "\u4f5c\u8005\u5229\u7528BERTopic\u4e3b\u9898\u5efa\u6a21\u548c\u6301\u4e45\u540c\u8c03\u5206\u6790\u6587\u672c\u4e2d\u7684\u4fe1\u606f\u7f3a\u53e3\uff0c\u901a\u8fc7\u8be5\u62d3\u6251\u7279\u5f81\u6210\u529f\u63d0\u5347\u4e86\u5bf9\u8bfb\u8005\u597d\u5947\u5fc3\u7684\u9884\u6d4b\u80fd\u529b\uff08\u89e3\u91ca\u504f\u5dee73%\uff09\uff0c\u4e3a\u7406\u89e3\u6587\u672c\u4e0e\u7528\u6237\u4f53\u9a8c\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002", "motivation": "\u8bfb\u8005\u597d\u5947\u5fc3\uff08\u9a71\u52a8\u529b\uff09\u5bf9\u6587\u672c\u53c2\u4e0e\u5ea6\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u4e2d\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u57fa\u4e8eLoewenstein\u7684\u4fe1\u606f\u7f3a\u53e3\u7406\u8bba\uff0c\u52a8\u673a\u5728\u4e8e\u901a\u8fc7\u91cf\u5316\u6587\u672c\u8bed\u4e49\u7ed3\u6784\u4e2d\u7684\u4fe1\u606f\u7f3a\u53e3\uff0c\u5efa\u7acb\u8bfb\u8005\u597d\u5947\u5fc3\u5efa\u6a21\u6846\u67b6\uff0c\u4ee5\u6df1\u5165\u7406\u89e3\u548c\u9884\u6d4b\u8bfb\u8005\u4e0e\u6587\u672c\u7684\u4e92\u52a8\u3002", "method": "\u63d0\u51fa\u7ed3\u5408BERTopic\u4e3b\u9898\u5efa\u6a21\u4e0e\u6301\u4e45\u540c\u8c03\uff08persistent homology\uff09\u7684\u65b9\u6cd5\uff0c\u5206\u6790\u6587\u672c\u7247\u6bb5\u6784\u5efa\u7684\u52a8\u6001\u8bed\u4e49\u7f51\u7edc\u7684\u62d3\u6251\u7ed3\u6784\uff08\u8fde\u901a\u5206\u91cf\u3001\u73af\u3001\u7a7a\u6d1e\u7b49\uff09\uff0c\u8fd9\u4e9b\u7f51\u7edc\u7279\u5f81\u4f5c\u4e3a\u4fe1\u606f\u7f3a\u53e3\u7684\u4ee3\u7406\u3002\u968f\u540e\uff0c\u901a\u8fc7\u6536\u96c649\u540d\u53c2\u4e0e\u8005\u5728\u9605\u8bfb\u300a\u9965\u997f\u6e38\u620f\u300b\u5c0f\u8bf4\u65f6\u5bf9\u597d\u5947\u5fc3\u7684\u8bc4\u5206\uff0c\u5c06\u62d3\u6251\u7279\u5f81\u4f5c\u4e3a\u81ea\u53d8\u91cf\u6765\u9884\u6d4b\u8fd9\u4e9b\u8bc4\u5206\uff0c\u5e76\u4e0e\u57fa\u7ebf\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u5347\u597d\u5947\u5fc3\u8bc4\u5206\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u89e3\u91ca\u504f\u5dee\u7387\u7531\u57fa\u7ebf\u6a21\u578b\u768430%\u63d0\u5347\u523073%\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u62d3\u6251\u7279\u5f81\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u80fd\u5206\u6790\u6587\u672c\u7684\u8bed\u4e49\u7ed3\u6784\uff0c\u8fd8\u63ed\u793a\u4e86\u7ed3\u6784\u4e0e\u8bfb\u8005\u53c2\u4e0e\u5ea6\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4e3aNLP\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u5de5\u5177\u3002"}}
{"id": "2506.10998", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.10998", "abs": "https://arxiv.org/abs/2506.10998", "authors": ["Kangping Xu", "Yifan Luo", "Yang Yuan", "Andrew Chi-Chih Yao"], "title": "Towards Automated Formal Verification of Backend Systems with LLMs", "comment": null, "summary": "Software testing plays a critical role in ensuring that systems behave as\nintended. However, existing automated testing approaches struggle to match the\ncapabilities of human engineers due to key limitations such as test locality,\nlack of general reliability, and business logic blindness. In this work, we\npropose a novel framework that leverages functional programming and type\nsystems to translate Scala backend code into formal Lean representations. Our\npipeline automatically generates theorems that specify the intended behavior of\nAPIs and database operations, and uses LLM-based provers to verify them. When a\ntheorem is proved, the corresponding logic is guaranteed to be correct and no\nfurther testing is needed. If the negation of a theorem is proved instead, it\nconfirms a bug. In cases where neither can be proved, human intervention is\nrequired. We evaluate our method on realistic backend systems and find that it\ncan formally verify over 50% of the test requirements, which suggests that half\nof a testing engineer's workload can be automated. Additionally, with an\naverage cost of only $2.19 per API, LLM-based verification is significantly\nmore cost-effective than manual testing and can be scaled easily through\nparallel execution. Our results indicate a promising direction for scalable,\nAI-powered software testing, with the potential to greatly improve engineering\nproductivity as models continue to advance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5c06\u540e\u7aef\u4ee3\u7801\u8f6c\u5316\u4e3a\u5f62\u5f0f\u5316\u903b\u8f91\u5e76\u7528LLM\u81ea\u52a8\u9a8c\u8bc1\uff0c\u4ece\u800c\u81ea\u52a8\u5316\u5730\u5b8c\u6210\u4e00\u534a\u4ee5\u4e0a\u7684\u6d4b\u8bd5\u9700\u6c42\uff0c\u663e\u8457\u964d\u4f4e\u6210\u672c\u5e76\u6613\u4e8e\u6269\u5c55\uff0c\u4e3aAI\u8d4b\u80fd\u8f6f\u4ef6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u524d\u666f\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u6d4b\u8bd5\u624b\u6bb5\u5728\u6d4b\u8bd5\u8986\u76d6\u3001\u666e\u9002\u53ef\u9760\u6027\u53ca\u4e1a\u52a1\u903b\u8f91\u7406\u89e3\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u96be\u4ee5\u66ff\u4ee3\u4eba\u5de5\u5de5\u7a0b\u5e08\u3002\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u53ef\u5927\u5e45\u51cf\u5c11\u4eba\u5de5\u6d4b\u8bd5\u9700\u6c42\u3001\u63d0\u5347\u53ef\u9760\u6027\u7684\u65b0\u578b\u65b9\u6cd5\u3002", "method": "\u8be5\u65b9\u6cd5\u5c06Scala\u540e\u7aef\u4ee3\u7801\u901a\u8fc7\u51fd\u6570\u5f0f\u7f16\u7a0b\u548c\u7c7b\u578b\u7cfb\u7edf\u7ffb\u8bd1\u4e3aLean\u7684\u5f62\u5f0f\u8868\u793a\uff0c\u7136\u540e\u81ea\u52a8\u751f\u6210\u63cf\u8ff0API\u53ca\u6570\u636e\u5e93\u64cd\u4f5c\u9884\u671f\u884c\u4e3a\u7684\u5b9a\u7406\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f5c\u4e3a\u8bc1\u660e\u5668\u8fdb\u884c\u9a8c\u8bc1\u3002\u8bc1\u660e\u901a\u8fc7\u5373\u4ee3\u8868\u903b\u8f91\u6b63\u786e\uff0c\u65e0\u9700\u8fdb\u4e00\u6b65\u6d4b\u8bd5\uff1b\u8bc1\u660e\u5931\u8d25\u6216\u53cd\u547d\u9898\u6210\u7acb\u65f6\uff0c\u5219\u5b9a\u4f4d\u4e3abug\uff0c\u65e0\u6cd5\u8bc1\u660e\u65f6\u53ef\u7531\u4eba\u5de5\u4ecb\u5165\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u5f62\u5f0f\u5316\u9a8c\u8bc1\u73b0\u5b9e\u540e\u7aef\u7cfb\u7edf\u4e2d\u8d85\u8fc750%\u7684\u6d4b\u8bd5\u9700\u6c42\uff0c\u6bcf\u4e2aAPI\u5e73\u5747\u9a8c\u8bc1\u6210\u672c\u4ec52.19\u7f8e\u5143\uff0c\u5927\u5e45\u4f18\u4e8e\u4eba\u5de5\u6d4b\u8bd5\uff0c\u4e14\u901a\u8fc7\u5e76\u884c\u6267\u884c\u53ef\u8f7b\u677e\u6269\u5c55\uff0c\u63d0\u5347\u6574\u4f53\u5de5\u7a0b\u6548\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u81ea\u52a8\u5316\u5e76\u6b63\u5f0f\u9a8c\u8bc1\u8d85\u8fc750%\u7684\u6d4b\u8bd5\u9700\u6c42\uff0c\u5927\u5e45\u51cf\u5c11\u8f6f\u4ef6\u6d4b\u8bd5\u5de5\u7a0b\u5e08\u7684\u5de5\u4f5c\u91cf\uff0c\u540c\u65f6\u5728\u6210\u672c\u548c\u53ef\u6269\u5c55\u6027\u4e0a\u4f18\u4e8e\u4eba\u5de5\u6d4b\u8bd5\uff0c\u5c55\u793a\u4e86AI\u9a71\u52a8\u81ea\u52a8\u5316\u8f6f\u4ef6\u6d4b\u8bd5\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2506.11097", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2506.11097", "abs": "https://arxiv.org/abs/2506.11097", "authors": ["Haritz Puerto", "Martin Gubri", "Tommaso Green", "Seong Joon Oh", "Sangdoo Yun"], "title": "C-SEO Bench: Does Conversational SEO Work?", "comment": null, "summary": "Large Language Models (LLMs) are transforming search engines into\nConversational Search Engines (CSE). Consequently, Search Engine Optimization\n(SEO) is being shifted into Conversational Search Engine Optimization (C-SEO).\nWe are beginning to see dedicated C-SEO methods for modifying web documents to\nincrease their visibility in CSE responses. However, they are often tested only\nfor a limited breadth of application domains; we do not understand whether\ncertain C-SEO methods would be effective for a broad range of domains.\nMoreover, existing evaluations consider only a single-actor scenario where only\none web document adopts a C-SEO method; in reality, multiple players are likely\nto competitively adopt the cutting-edge C-SEO techniques, drawing an analogy\nfrom the dynamics we have seen in SEO. We present C-SEO Bench, the first\nbenchmark designed to evaluate C-SEO methods across multiple tasks, domains,\nand number of actors. We consider two search tasks, question answering and\nproduct recommendation, with three domains each. We also formalize a new\nevaluation protocol with varying adoption rates among involved actors. Our\nexperiments reveal that most current C-SEO methods are largely ineffective,\ncontrary to reported results in the literature. Instead, traditional SEO\nstrategies, those aiming to improve the ranking of the source in the LLM\ncontext, are significantly more effective. We also observe that as we increase\nthe number of C-SEO adopters, the overall gains decrease, depicting a congested\nand zero-sum nature of the problem. Our code and data are available at\nhttps://github.com/parameterlab/c-seo-bench and\nhttps://huggingface.co/datasets/parameterlab/c-seo-bench.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u9762\u5411\u591a\u9886\u57df\u3001\u591a\u53c2\u4e0e\u8005\u7684C-SEO\u8bc4\u6d4b\u57fa\u51c6C-SEO Bench\u3002\u7cfb\u7edf\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u524dC-SEO\u65b9\u6cd5\u5b9e\u9645\u6548\u679c\u6709\u9650\uff0c\u4f20\u7edfSEO\u5bf9LLM\u6709\u6548\u6027\u66f4\u9ad8\uff0c\u4e14\u591a\u65b9\u7ade\u4e89\u4e0b\u6536\u76ca\u9012\u51cf\u3002\u4e3a\u672a\u6765C-SEO\u65b9\u6cd5\u8bba\u8bbe\u8ba1\u548c\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u8bc4\u6d4b\u6807\u51c6\u548c\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63a8\u52a8\u641c\u7d22\u5f15\u64ce\u5411\u5bf9\u8bdd\u5f0f\u641c\u7d22\u5f15\u64ce\uff08CSE\uff09\u8f6c\u53d8\uff0c\u641c\u7d22\u5f15\u64ce\u4f18\u5316\uff08SEO\uff09\u4e5f\u6f14\u53d8\u4e3a\u5bf9\u8bdd\u5f0f\u641c\u7d22\u5f15\u64ce\u4f18\u5316\uff08C-SEO\uff09\u3002\u4f46\u76ee\u524d\u5bf9C-SEO\u65b9\u6cd5\u7684\u5b9e\u9645\u6548\u679c\uff0c\u5c24\u5176\u662f\u5728\u4e0d\u540c\u9886\u57df\u548c\u591a\u65b9\u7ade\u8d5b\u573a\u666f\u4e0b\u7684\u6548\u679c\u5c1a\u4e0d\u6e05\u695a\uff0c\u4e5f\u7f3a\u4e4f\u7cfb\u7edf\u6027\u8bc4\u6d4b\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86C-SEO Bench\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u9488\u5bf9\u591a\u4efb\u52a1\u3001\u591a\u9886\u57df\u53ca\u591a\u53c2\u4e0e\u8005\u7684C-SEO\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\u3002\u5305\u62ec\u4e24\u79cd\u641c\u7d22\u4efb\u52a1\uff08\u95ee\u7b54\u4e0e\u4ea7\u54c1\u63a8\u8350\uff09\uff0c\u6db5\u76d6\u4e09\u4e2a\u4e0d\u540c\u9886\u57df\uff0c\u5e76\u8bbe\u8ba1\u4e86\u65b0\u7684\u8bc4\u6d4b\u534f\u8bae\uff0c\u4ee5\u53cd\u6620\u4e0d\u540c\u91c7\u7eb3\u8005\u6570\u91cf\u4e0b\u7684\u65b9\u6cd5\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u76ee\u524d\u4e3b\u6d41\u7684C-SEO\u65b9\u6cd5\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u5e76\u4e0d\u5982\u6587\u732e\u62a5\u9053\u90a3\u6837\u6709\u6548\uff1b\u53cd\u800c\u4f20\u7edfSEO\u7b56\u7565\uff08\u65e8\u5728\u63d0\u5347\u6e90\u5185\u5bb9\u5728LLM\u73af\u5883\u4e0b\u6392\u540d\uff09\u66f4\u6709\u6548\u3002\u540c\u65f6\uff0c\u968f\u7740C-SEO\u91c7\u7eb3\u8005\u7684\u589e\u591a\uff0c\u6574\u4f53\u6536\u76ca\u53cd\u800c\u4e0b\u964d\uff0c\u8868\u73b0\u51fa\u62e5\u6324\u3001\u96f6\u548c\u535a\u5f08\u7684\u7279\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u5168\u9762\u57fa\u51c6\u548c\u591a\u573a\u666f\u8bc4\u6d4b\uff0c\u53d1\u73b0\u5f53\u524dC-SEO\u65b9\u6cd5\u5b9e\u9645\u6548\u679c\u6709\u9650\uff0c\u751a\u81f3\u4e0d\u5982\u4f20\u7edfSEO\u624b\u6bb5\uff0c\u5e76\u63ed\u793a\u4e86C-SEO\u9886\u57df\u8d44\u6e90\u5206\u914d\u7684\u96f6\u548c\u7ade\u4e89\u73b0\u8c61\u3002\u672a\u6765C-SEO\u7684\u53d1\u5c55\u548c\u65b9\u6cd5\u8bbe\u8ba1\u5e94\u5145\u5206\u8003\u8651\u591a\u65b9\u53c2\u4e0e\u548c\u9886\u57df\u5e7f\u6cdb\u6027\u7684\u6311\u6218\u3002"}}
{"id": "2506.10999", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.10999", "abs": "https://arxiv.org/abs/2506.10999", "authors": ["Atul Kumar", "Diptikalyan Saha", "Toshikai Yasue", "Kohichi Ono", "Saravanan Krishnan", "Sandeep Hans", "Fumiko Satoh", "Gerald Mitchell", "Sachin Kumar"], "title": "Automated Validation of COBOL to Java Transformation", "comment": "arXiv admin note: text overlap with arXiv:2504.10548", "summary": "Recent advances in Large Language Model (LLM) based Generative AI techniques\nhave made it feasible to translate enterpriselevel code from legacy languages\nsuch as COBOL to modern languages such as Java or Python. While the results of\nLLM-based automatic transformation are encouraging, the resulting code cannot\nbe trusted to correctly translate the original code. We propose a framework and\na tool to help validate the equivalence of COBOL and translated Java. The\nresults can also help repair the code if there are some issues and provide\nfeedback to the AI model to improve. We have developed a\nsymbolic-execution-based test generation to automatically generate unit tests\nfor the source COBOL programs which also mocks the external resource calls. We\ngenerate equivalent JUnit test cases with equivalent mocking as COBOL and run\nthem to check semantic equivalence between original and translated programs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u7b26\u53f7\u6267\u884c\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u9a8c\u8bc1AI\u81ea\u52a8\u7ffb\u8bd1\u7684\u9057\u7559\u4ee3\u7801\uff08\u5982COBOL\u5230Java\uff09\u7684\u8bed\u4e49\u7b49\u4ef7\u6027\uff0c\u5e76\u53ef\u8f85\u52a9\u4fee\u590d\u95ee\u9898\u3001\u4f18\u5316AI\u6a21\u578b\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6280\u672f\u7684\u53d1\u5c55\uff0c\u7528AI\u81ea\u52a8\u5c06\u5982COBOL\u8fd9\u6837\u7684\u9057\u7559\u8bed\u8a00\u4ee3\u7801\u8f6c\u6362\u4e3a\u73b0\u4ee3\u8bed\u8a00\uff08\u5982Java\u6216Python\uff09\u6210\u4e3a\u53ef\u80fd\uff0c\u4f46\u8f6c\u6362\u540e\u7684\u4ee3\u7801\u6b63\u786e\u6027\u65e0\u6cd5\u4fdd\u8bc1\u3002\u4e3a\u786e\u4fdd\u7ffb\u8bd1\u540e\u7684\u7a0b\u5e8f\u80fd\u4e0e\u539f\u7a0b\u5e8f\u8bed\u4e49\u7b49\u4ef7\uff0c\u9700\u8981\u6709\u6548\u7684\u9a8c\u8bc1\u5de5\u5177\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u5957\u6846\u67b6\u548c\u5de5\u5177\uff0c\u901a\u8fc7\u7b26\u53f7\u6267\u884c\u751f\u6210\u9488\u5bf9COBOL\u6e90\u7a0b\u5e8f\u7684\u5355\u5143\u6d4b\u8bd5\uff0c\u8fd8\u80fd\u81ea\u52a8\u6a21\u62df\u5916\u90e8\u8d44\u6e90\u8c03\u7528\u3002\u968f\u540e\uff0c\u5c06\u8fd9\u4e9b\u5355\u5143\u6d4b\u8bd5\u7b49\u4ef7\u5730\u8f6c\u5316\u4e3aJava\uff08JUnit\uff09\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5e76\u8fd0\u884c\u8fd9\u4e9b\u6d4b\u8bd5\u4ee5\u9a8c\u8bc1\u539f\u59cbCOBOL\u7a0b\u5e8f\u548c\u7ffb\u8bd1\u540e\u7684Java\u7a0b\u5e8f\u7684\u8bed\u4e49\u7b49\u4ef7\u6027\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u9a8c\u8bc1COBOL\u4e0eJava\u7ffb\u8bd1\u4ee3\u7801\u7684\u7b49\u4ef7\u6027\uff0c\u8fd8\u80fd\u8f85\u52a9\u4fee\u590d\u53d1\u73b0\u7684\u95ee\u9898\uff0c\u5e76\u4e3aAI\u6a21\u578b\u63d0\u4f9b\u53cd\u9988\u4ee5\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\u3002", "conclusion": "\u4f5c\u8005\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u7b26\u53f7\u6267\u884c\u548c\u7b49\u4ef7\u6d4b\u8bd5\uff0c\u6709\u6548\u9a8c\u8bc1\u4e86AI\u7ffb\u8bd1\u7684\u9057\u7559\u4ee3\u7801\u7684\u6b63\u786e\u6027\uff0c\u589e\u5f3a\u4e86AI\u5728\u4f01\u4e1a\u4ee3\u7801\u8fc1\u79fb\u4e2d\u7684\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2506.11102", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11102", "abs": "https://arxiv.org/abs/2506.11102", "authors": ["Jiachen Zhu", "Menghui Zhu", "Renting Rui", "Rong Shan", "Congmin Zheng", "Bo Chen", "Yunjia Xi", "Jianghao Lin", "Weiwen Liu", "Ruiming Tang", "Yong Yu", "Weinan Zhang"], "title": "Evolutionary Perspectives on the Evaluation of LLM-Based AI Agents: A Comprehensive Survey", "comment": null, "summary": "The advent of large language models (LLMs), such as GPT, Gemini, and\nDeepSeek, has significantly advanced natural language processing, giving rise\nto sophisticated chatbots capable of diverse language-related tasks. The\ntransition from these traditional LLM chatbots to more advanced AI agents\nrepresents a pivotal evolutionary step. However, existing evaluation frameworks\noften blur the distinctions between LLM chatbots and AI agents, leading to\nconfusion among researchers selecting appropriate benchmarks. To bridge this\ngap, this paper introduces a systematic analysis of current evaluation\napproaches, grounded in an evolutionary perspective. We provide a detailed\nanalytical framework that clearly differentiates AI agents from LLM chatbots\nalong five key aspects: complex environment, multi-source instructor, dynamic\nfeedback, multi-modal perception, and advanced capability. Further, we\ncategorize existing evaluation benchmarks based on external environments\ndriving forces, and resulting advanced internal capabilities. For each\ncategory, we delineate relevant evaluation attributes, presented\ncomprehensively in practical reference tables. Finally, we synthesize current\ntrends and outline future evaluation methodologies through four critical\nlenses: environment, agent, evaluator, and metrics. Our findings offer\nactionable guidance for researchers, facilitating the informed selection and\napplication of benchmarks in AI agent evaluation, thus fostering continued\nadvancement in this rapidly evolving research domain.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u68b3\u7406\u4e86LLM\u804a\u5929\u673a\u5668\u4eba\u4e0eAI\u667a\u80fd\u4f53\u7684\u8bc4\u6d4b\u5dee\u5f02\uff0c\u63d0\u51fa\u4e86\u4e94\u5927\u533a\u5206\u7ef4\u5ea6\uff0c\u603b\u7ed3\u5e76\u5f52\u7c7b\u4e86\u73b0\u6709\u8bc4\u6d4b\u57fa\u51c6\uff0c\u5e76\u5bf9\u672a\u6765\u667a\u80fd\u4f53\u8bc4\u6d4b\u65b9\u6cd5\u63d0\u51fa\u4e86\u5efa\u8bae\uff0c\u4e3a\u7814\u7a76\u8005\u9009\u62e9\u8bc4\u6d4b\u57fa\u51c6\u63d0\u4f9b\u4e86\u5b9e\u7528\u53c2\u8003\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u53d1\u5c55\uff0c\u4f20\u7edf\u7684LLM\u804a\u5929\u673a\u5668\u4eba\u6b63\u9010\u6b65\u8fc7\u6e21\u5230\u66f4\u52a0\u5148\u8fdb\u7684AI\u667a\u80fd\u4f53\u3002\u4f46\u76ee\u524d\u7684\u8bc4\u6d4b\u6846\u67b6\u5f80\u5f80\u6ca1\u6709\u660e\u786e\u533a\u5206\u4e24\u8005\uff0c\u5bfc\u81f4\u7814\u7a76\u4eba\u5458\u5728\u9009\u62e9\u8bc4\u6d4b\u57fa\u51c6\u65f6\u4ea7\u751f\u56f0\u60d1\u3002\u56e0\u6b64\uff0c\u8feb\u5207\u9700\u8981\u5efa\u7acb\u7cfb\u7edf\u5316\u5206\u6790\u6846\u67b6\uff0c\u6e05\u6670\u533a\u5206\u4e24\u8005\u5dee\u5f02\uff0c\u4e3a\u8bc4\u6d4b\u65b9\u6cd5\u7684\u9009\u62e9\u4e0e\u53d1\u5c55\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u672c\u6587\u91c7\u7528\u8fdb\u5316\u89c6\u89d2\uff0c\u5bf9\u5f53\u524d\u7684\u8bc4\u6d4b\u65b9\u6cd5\u8fdb\u884c\u7cfb\u7edf\u6027\u5206\u6790\u3002\u63d0\u51fa\u4e86\u533a\u5206AI\u667a\u80fd\u4f53\u548cLLM\u804a\u5929\u673a\u5668\u4eba\u7684\u4e94\u4e2a\u5173\u952e\u7ef4\u5ea6\uff0c\u5e76\u5bf9\u73b0\u6709\u8bc4\u6d4b\u57fa\u51c6\u6309\u5916\u90e8\u73af\u5883\u9a71\u52a8\u529b\u548c\u5185\u90e8\u80fd\u529b\u8fdb\u884c\u5206\u7c7b\u3002\u9488\u5bf9\u6bcf\u4e00\u7c7b\u522b\uff0c\u6574\u7406\u4e86\u5177\u4f53\u7684\u8bc4\u6d4b\u5c5e\u6027\uff0c\u5e76\u4ee5\u5b9e\u7528\u7684\u53c2\u8003\u8868\u683c\u5f62\u5f0f\u5448\u73b0\u3002\u540c\u65f6\uff0c\u7efc\u8ff0\u4e86\u73b0\u6709\u8d8b\u52bf\uff0c\u5e76\u4ece\u73af\u5883\u3001\u667a\u80fd\u4f53\u3001\u8bc4\u4f30\u8005\u3001\u6307\u6807\u56db\u4e2a\u89c6\u89d2\u63d0\u51fa\u672a\u6765\u7684\u65b9\u6cd5\u65b9\u5411\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u5957\u8be6\u7ec6\u5206\u6790\u6846\u67b6\uff0c\u660e\u786e\u533a\u5206\u4e86AI\u667a\u80fd\u4f53\u4e0eLLM\u804a\u5929\u673a\u5668\u4eba\uff0c\u5e76\u6839\u636e\u5206\u6790\u7ed3\u679c\u5bf9\u73b0\u6709\u8bc4\u6d4b\u57fa\u51c6\u8fdb\u884c\u4e86\u5f52\u7c7b\u3002\u5bf9\u4e8e\u6bcf\u7c7b\u57fa\u51c6\uff0c\u90fd\u603b\u7ed3\u4e86\u4e3b\u8981\u7684\u8bc4\u6d4b\u5c5e\u6027\u3002\u6700\u7ec8\uff0c\u7efc\u5408\u5f53\u524d\u8d8b\u52bf\uff0c\u4ece\u56db\u4e2a\u5173\u952e\u89c6\u89d2\u63d0\u51fa\u4e86\u672a\u6765\u7684\u8bc4\u6d4b\u65b9\u6cd5\u3002\u672c\u6587\u7684\u7814\u7a76\u4e3a\u7814\u7a76\u8005\u5728\u8bc4\u6d4b\u57fa\u51c6\u9009\u62e9\u4e0e\u5e94\u7528\u4e0a\u63d0\u4f9b\u4e86\u5b9e\u9645\u7684\u53c2\u8003\u548c\u6307\u5bfc\u3002", "conclusion": "\u672c\u6587\u4e3a\u533a\u5206AI\u667a\u80fd\u4f53\u4e0e\u4f20\u7edfLLM\u804a\u5929\u673a\u5668\u4eba\uff0c\u63d0\u51fa\u4e86\u7cfb\u7edf\u6027\u8bc4\u6d4b\u5206\u6790\u6846\u67b6\uff0c\u5e76\u5bf9\u73b0\u6709\u57fa\u51c6\u8fdb\u884c\u5206\u7c7b\u4e0e\u5c5e\u6027\u603b\u7ed3\u3002\u7814\u7a76\u6210\u679c\u4e3a\u8be5\u9886\u57df\u7814\u7a76\u8005\u9009\u7528\u5408\u9002\u8bc4\u6d4b\u57fa\u51c6\u3001\u63a8\u52a8\u667a\u80fd\u4f53\u8bc4\u6d4b\u53d1\u5c55\u63d0\u4f9b\u4e86\u6e05\u6670\u3001\u6709\u64cd\u4f5c\u6027\u7684\u6307\u5bfc\u3002"}}
{"id": "2506.11000", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11000", "abs": "https://arxiv.org/abs/2506.11000", "authors": ["Ketai Qiu"], "title": "Ever-Improving Test Suite by Leveraging Large Language Models", "comment": "Accepted by 33rd ACM International Conference on the Foundations of\n  Software Engineering (FSE Companion '25), June 23--28, 2025, Trondheim,\n  Norway", "summary": "Augmenting test suites with test cases that reflect the actual usage of the\nsoftware system is extremely important to sustain the quality of long lasting\nsoftware systems. In this paper, we propose E-Test, an approach that\nincrementally augments a test suite with test cases that exercise behaviors\nthat emerge in production and that are not been tested yet. E-Test leverages\nLarge Language Models to identify already-tested, not-yet-tested, and\nerror-prone unit execution scenarios, and augment the test suite accordingly.\nOur experimental evaluation shows that E-Test outperforms the main\nstate-of-the-art approaches to identify inadequately tested behaviors and\noptimize test suites.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86E-Test\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u589e\u5f3a\u6d4b\u8bd5\u5957\u4ef6\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u957f\u671f\u7ef4\u62a4\u7684\u8f6f\u4ef6\u7cfb\u7edf\u9700\u8981\u901a\u8fc7\u53cd\u6620\u5b9e\u9645\u4f7f\u7528\u60c5\u51b5\u7684\u6d4b\u8bd5\u7528\u4f8b\u6765\u6301\u7eed\u4fdd\u8bc1\u5176\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aE-Test\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8bc6\u522b\u5df2\u7ecf\u6d4b\u8bd5\u3001\u672a\u6d4b\u8bd5\u548c\u6613\u51fa\u9519\u7684\u5355\u5143\u6267\u884c\u573a\u666f\uff0c\u5e76\u636e\u6b64\u589e\u91cf\u5f0f\u5730\u6269\u5c55\u6d4b\u8bd5\u5957\u4ef6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cE-Test\u5728\u8bc6\u522b\u6d4b\u8bd5\u4e0d\u8db3\u7684\u884c\u4e3a\u548c\u4f18\u5316\u6d4b\u8bd5\u5957\u4ef6\u65b9\u9762\uff0c\u4f18\u4e8e\u4e3b\u8981\u73b0\u6709\u6280\u672f\u65b9\u6cd5\u3002", "conclusion": "E-Test\u6709\u6548\u6539\u8fdb\u6d4b\u8bd5\u5957\u4ef6\u7684\u8986\u76d6\u4e0e\u8d28\u91cf\uff0c\u662f\u589e\u5f3a\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u6d4b\u8bd5\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2506.11103", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11103", "abs": "https://arxiv.org/abs/2506.11103", "authors": ["Wenchong He", "Liqian Peng", "Zhe Jiang", "Alex Go"], "title": "You Only Fine-tune Once: Many-Shot In-Context Fine-Tuning for Large Language Model", "comment": "16 pages, 6 figures", "summary": "Large language models (LLMs) possess a remarkable ability to perform\nin-context learning (ICL), which enables them to handle multiple downstream\ntasks simultaneously without requiring task-specific fine-tuning. Recent\nstudies have shown that even moderately sized LLMs, such as Mistral 7B, Gemma\n7B and Llama-3 8B, can achieve ICL through few-shot in-context fine-tuning of\nall tasks at once. However, this approach still lags behind dedicated\nfine-tuning, where a separate model is trained for each individual task.\n  In this paper, we propose a novel approach, Many-Shot In-Context Fine-tuning\n(ManyICL), which significantly narrows this performance gap by extending the\nprinciples of ICL to a many-shot setting. To unlock the full potential of\nManyICL and address the inherent inefficiency of processing long sequences with\nnumerous in-context examples, we propose a novel training objective. Instead of\nsolely predicting the final answer, our approach treats every answer within the\ncontext as a supervised training target. This effectively shifts the role of\nmany-shot examples from prompts to targets for autoregressive learning. Through\nextensive experiments on diverse downstream tasks, including classification,\nsummarization, question answering, natural language inference, and math, we\ndemonstrate that ManyICL substantially outperforms zero/few-shot fine-tuning\nand approaches the performance of dedicated fine-tuning. Furthermore, ManyICL\nsignificantly mitigates catastrophic forgetting issues observed in\nzero/few-shot fine-tuning. The code will be made publicly available upon\npublication.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faManyICL\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u591a\u793a\u4f8b\u4f5c\u4e3a\u6709\u76d1\u7763\u76ee\u6807\u8fdb\u884c\u5fae\u8c03\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u591a\u4efb\u52a1in-context learning\u7684\u8868\u73b0\uff0c\u5e76\u7f13\u89e3\u4e86\u9057\u5fd8\u95ee\u9898\uff0c\u6027\u80fd\u63a5\u8fd1\u4e13\u7528\u5fae\u8c03\u3002", "motivation": "\u76ee\u524dLLM\u901a\u8fc7in-context learning\uff08ICL\uff09\u80fd\u591f\u5904\u7406\u591a\u4efb\u52a1\uff0c\u4f46\u591a\u4e2a\u4efb\u52a1\u540c\u65f6few-shot in-context\u5fae\u8c03\u7684\u65b9\u5f0f\uff0c\u4e0e\u6bcf\u4e2a\u4efb\u52a1\u4e13\u95e8\u5fae\u8c03\u76f8\u6bd4\u4ecd\u6709\u8868\u73b0\u5dee\u8ddd\u3002", "method": "\u63d0\u51faMany-Shot In-Context Fine-tuning\uff08ManyICL\uff09\u65b0\u65b9\u6cd5\uff0c\u5e76\u91c7\u7528\u521b\u65b0\u8bad\u7ec3\u76ee\u6807\uff1a\u4e0d\u4ec5\u9884\u6d4b\u6700\u7ec8\u7b54\u6848\uff0c\u8fd8\u5c06\u4e0a\u4e0b\u6587\u4e2d\u6bcf\u4e2a\u7b54\u6848\u4f5c\u4e3a\u6709\u76d1\u7763\u8bad\u7ec3\u76ee\u6807\uff0c\u5b9e\u73b0many-shot\u6837\u672c\u4ece\u63d0\u793a\u8f6c\u4e3a\u81ea\u56de\u5f52\u5b66\u4e60\u76ee\u6807\u3002", "result": "ManyICL\u5728\u591a\u9879\u4e0b\u6e38\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u96f6/\u5c11\u6837\u672c\u5fae\u8c03\uff0c\u5e76\u4e14\u63a5\u8fd1\u6bcf\u4e2a\u4efb\u52a1\u4e13\u7528\u5fae\u8c03\u7684\u8868\u73b0\u3002\u540c\u65f6\uff0cManyICL\u6709\u6548\u7f13\u89e3\u4e86\u96f6/\u5c11\u6837\u672c\u5fae\u8c03\u51fa\u73b0\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u3002", "conclusion": "ManyICL\u6709\u6548\u63d0\u5347\u4e86\u57fa\u4e8eICL\u7684\u591a\u4efb\u52a1\u5904\u7406\u80fd\u529b\uff0c\u51cf\u5c11\u4e0e\u4e13\u95e8\u5fae\u8c03\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u5e76\u6539\u5584\u6a21\u578b\u9057\u5fd8\u95ee\u9898\u3002\u4ee3\u7801\u5c06\u5728\u8bba\u6587\u53d1\u5e03\u540e\u516c\u5f00\u3002"}}
{"id": "2506.11001", "categories": ["cs.SE", "cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.11001", "abs": "https://arxiv.org/abs/2506.11001", "authors": ["S. Tucker Browne", "Mark M. Bailey"], "title": "Rethinking Technological Readiness in the Era of AI Uncertainty", "comment": "12 pages", "summary": "Artificial intelligence (AI) is poised to revolutionize military combat\nsystems, but ensuring these AI-enabled capabilities are truly mission-ready\npresents new challenges. We argue that current technology readiness assessments\nfail to capture critical AI-specific factors, leading to potential risks in\ndeployment. We propose a new AI Readiness Framework to evaluate the maturity\nand trustworthiness of AI components in military systems. The central thesis is\nthat a tailored framework - analogous to traditional Technology Readiness\nLevels (TRL) but expanded for AI - can better gauge an AI system's reliability,\nsafety, and suitability for combat use. Using current data evaluation tools and\ntesting practices, we demonstrate the framework's feasibility for near-term\nimplementation. This structured approach provides military decision-makers with\nclearer insight into whether an AI-enabled system has met the necessary\nstandards of performance, transparency, and human integration to be deployed\nwith confidence, thus advancing the field of defense technology management and\nrisk assessment.", "AI": {"tldr": "\u4f20\u7edf\u6280\u672f\u6210\u719f\u5ea6\u8bc4\u7ea7\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30\u519b\u4e8bAI\u7684\u5b9e\u9645\u51c6\u5907\u5ea6\u3002\u672c\u6587\u63d0\u51fa\u9488\u5bf9AI\u7279\u6027\u7684\u4e13\u7528\u6210\u719f\u5ea6\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u5de5\u5177\u9a8c\u8bc1\u5176\u53ef\u884c\u6027\uff0c\u4e3a\u519b\u7528AI\u90e8\u7f72\u548c\u98ce\u9669\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u6807\u51c6\u3002", "motivation": "\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u5728\u519b\u4e8b\u4f5c\u6218\u7cfb\u7edf\u5e94\u7528\u524d\u666f\u5de8\u5927\uff0c\u4f46\u4f20\u7edf\u6280\u672f\u6210\u719f\u5ea6\u8bc4\u4f30\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u8861\u91cfAI\u5728\u519b\u7528\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u98ce\u9669\u548c\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u65b0\u7684\u4eba\u5de5\u667a\u80fd\u6210\u719f\u5ea6\u8bc4\u4f30\u6846\u67b6\uff08AI Readiness Framework\uff09\uff0c\u57fa\u4e8e\u73b0\u6709\u6570\u636e\u8bc4\u4f30\u5de5\u5177\u4e0e\u6d4b\u8bd5\u5b9e\u8df5\uff0c\u5c06\u4f20\u7edf\u6280\u672f\u6210\u719f\u5ea6\u7b49\u7ea7\uff08TRL\uff09\u7406\u5ff5\u6269\u5c55\u5e76\u4e13\u95e8\u9488\u5bf9AI\u7cfb\u7edf\u8fdb\u884c\u8c03\u6574\u3002", "result": "\u901a\u8fc7\u5e94\u7528\u5f53\u524d\u7684\u6570\u636e\u8bc4\u4f30\u5de5\u5177\u548c\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u8be5AI\u6210\u719f\u5ea6\u8bc4\u4f30\u6846\u67b6\u53ef\u5728\u8fd1\u671f\u5185\u5b9e\u9645\u5b9e\u65bd\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u519b\u65b9\u51b3\u7b56\u8005\u63d0\u4f9b\u4e86\u66f4\u5b8c\u5584\u7684AI\u7cfb\u7edf\u53ef\u9760\u6027\u3001\u5b89\u5168\u6027\u53ca\u4f5c\u6218\u9002\u7528\u6027\u7684\u628a\u63a7\u6807\u51c6\uff0c\u6709\u52a9\u4e8e AI \u7cfb\u7edf\u7684\u5408\u7406\u90e8\u7f72\u548c\u98ce\u9669\u7ba1\u63a7\uff0c\u63a8\u52a8\u56fd\u9632\u6280\u672f\u7ba1\u7406\u4e0e\u8bc4\u4f30\u5de5\u4f5c\u53d1\u5c55\u3002"}}
{"id": "2506.11104", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11104", "abs": "https://arxiv.org/abs/2506.11104", "authors": ["Hanzhi Zhang", "Heng Fan", "Kewei Sha", "Yan Huang", "Yunhe Feng"], "title": "DAM: Dynamic Attention Mask for Long-Context Large Language Model Inference Acceleration", "comment": null, "summary": "Long-context understanding is crucial for many NLP applications, yet\ntransformers struggle with efficiency due to the quadratic complexity of\nself-attention. Sparse attention methods alleviate this cost but often impose\nstatic, predefined masks, failing to capture heterogeneous attention patterns.\nThis results in suboptimal token interactions, limiting adaptability and\nretrieval accuracy in long-sequence tasks. This work introduces a dynamic\nsparse attention mechanism that assigns adaptive masks at the attention-map\nlevel, preserving heterogeneous patterns across layers and heads. Unlike\nexisting approaches, our method eliminates the need for fine-tuning and\npredefined mask structures while maintaining computational efficiency. By\nlearning context-aware attention structures, it achieves high alignment with\nfull-attention models, ensuring minimal performance degradation while reducing\nmemory and compute overhead. This approach provides a scalable alternative to\nfull attention, enabling the practical deployment of large-scale Large Language\nModels (LLMs) without sacrificing retrieval performance. DAM is available at:\nhttps://github.com/HanzhiZhang-Ulrica/DAM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u52a8\u6001\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\uff08DAM\uff09\uff0c\u65e0\u9700\u5fae\u8c03\u548c\u56fa\u5b9a\u63a9\u7801\uff0c\u80fd\u9ad8\u6548\u5904\u7406\u957f\u6587\u672c\uff0c\u5927\u5e45\u8282\u7701\u8ba1\u7b97\u8d44\u6e90\uff0c\u6a21\u578b\u6548\u679c\u63a5\u8fd1\u5168\u6ce8\u610f\u529b\u65b9\u6848\uff0c\u5229\u4e8e\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5b9e\u9645\u90e8\u7f72\u3002", "motivation": "\u5f53\u524dNLP\u5e94\u7528\u5bf9\u4e8e\u957f\u6587\u672c\u4e0a\u4e0b\u6587\u7684\u7406\u89e3\u6709\u8f83\u9ad8\u9700\u6c42\uff0c\u4f46\u4f20\u7edftransformer\u5728\u5904\u7406\u957f\u5e8f\u5217\u65f6\uff0c\u7531\u4e8e\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e8c\u6b21\u590d\u6742\u5ea6\uff0c\u6548\u7387\u8f83\u4f4e\u3002\u7a00\u758f\u6ce8\u610f\u529b\u867d\u7136\u80fd\u63d0\u5347\u6548\u7387\uff0c\u4f46\u5927\u591a\u91c7\u7528\u9759\u6001\u9884\u5b9a\u4e49\u7684\u63a9\u7801\uff0c\u65e0\u6cd5\u7075\u6d3b\u9002\u5e94\u4e0d\u540c\u7684\u6ce8\u610f\u529b\u9700\u6c42\uff0c\u5bfc\u81f4token\u95f4\u4ea4\u4e92\u53d7\u9650\uff0c\u9002\u5e94\u6027\u548c\u68c0\u7d22\u51c6\u786e\u7387\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\uff08DAM\uff09\uff0c\u53ef\u5728\u6ce8\u610f\u529b\u56fe\u5c42\u9762\u81ea\u9002\u5e94\u5206\u914d\u63a9\u7801\uff0c\u8de8\u5c42\u3001\u8de8head\u4fdd\u7559\u5f02\u8d28\u5316\u6ce8\u610f\u529b\u6a21\u5f0f\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u5fae\u8c03\u6216\u9884\u5b9a\u4e49\u63a9\u7801\u7ed3\u6784\uff0c\u5b66\u4e60\u4f9d\u8d56\u4e0a\u4e0b\u6587\u7684\u6ce8\u610f\u529b\u65b9\u5f0f\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u548c\u5b58\u50a8\u6548\u7387\u7684\u524d\u63d0\u4e0b\uff0c\u52a8\u6001\u751f\u6210\u9ad8\u6548\u7a00\u758f\u6ce8\u610f\u529b\u7ed3\u6784\u3002", "result": "\u5373\u4f7f\u5927\u5e45\u964d\u4f4e\u8fd0\u7b97\u548c\u5185\u5b58\u5f00\u9500\uff0c\u6a21\u578b\u6027\u80fd\u57fa\u672c\u4e0e\u5168\u6ce8\u610f\u529b\u7248\u672c\u5bf9\u9f50\uff0c\u6027\u80fd\u635f\u5931\u6781\u5c0f\u3002\u65b9\u6cd5\u80fd\u6709\u6548\u7528\u4e8e\u90e8\u7f72\u5927\u89c4\u6a21LLM\uff0c\u5728\u4e0d\u727a\u7272\u68c0\u7d22\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u901a\u8fc7\u52a8\u6001\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\uff08DAM\uff09\uff0c\u65e2\u517c\u987e\u4e86\u5927\u578b\u6a21\u578b\u9ad8\u6548\u63a8\u7406\u9700\u6c42\uff0c\u4e5f\u4fdd\u7559\u4e86\u590d\u6742\u4e0a\u4e0b\u6587\u7406\u89e3\u4e0e\u68c0\u7d22\u8868\u73b0\uff0c\u662f\u5168\u6ce8\u610f\u529b\u673a\u5236\u7684\u53ef\u6269\u5c55\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2506.11002", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11002", "abs": "https://arxiv.org/abs/2506.11002", "authors": ["Roberto Verdecchia", "Justus Bogner"], "title": "Notes On Writing Effective Empirical Software Engineering Papers: An Opinionated Primer", "comment": null, "summary": "While mastered by some, good scientific writing practices within Empirical\nSoftware Engineering (ESE) research appear to be seldom discussed and\ndocumented. Despite this, these practices are implicit or even explicit\nevaluation criteria of typical software engineering conferences and journals.\nIn this pragmatic, educational-first document, we want to provide guidance to\nthose who may feel overwhelmed or confused by writing ESE papers, but also\nthose more experienced who still might find an opinionated collection of\nwriting advice useful. The primary audience we had in mind for this paper were\nour own BSc, MSc, and PhD students, but also students of others. Our documented\nadvice therefore reflects a subjective and personal vision of writing ESE\npapers. By no means do we claim to be fully objective, generalizable, or\nrepresentative of the whole discipline. With that being said, writing papers in\nthis way has worked pretty well for us so far. We hope that this guide can at\nleast partially do the same for others.", "AI": {"tldr": "\u672c\u6587\u9762\u5411\u7ecf\u9a8c\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u5b66\u751f\u548c\u521d\u5b66\u8005\uff0c\u603b\u7ed3\u4e86\u4f5c\u8005\u4e3b\u89c2\u4f46\u5b9e\u7528\u7684\u8bba\u6587\u5199\u4f5c\u5efa\u8bae\uff0c\u65e8\u5728\u964d\u4f4e\u5199\u4f5c\u95e8\u69db\uff0c\u5e76\u8ba9\u66f4\u591a\u5199\u4f5c\u8005\u53d7\u76ca\u3002", "motivation": "\u5728\u7ecf\u9a8c\u8f6f\u4ef6\u5de5\u7a0b\uff08ESE\uff09\u9886\u57df\uff0c\u597d\u7684\u79d1\u5b66\u5199\u4f5c\u5b9e\u8df5\u8f83\u5c11\u88ab\u8ba8\u8bba\u548c\u8bb0\u5f55\uff0c\u4f46\u5374\u5e38\u4f5c\u4e3a\u4f1a\u8bae\u4e0e\u671f\u520a\u8bc4\u5ba1\u7684\u9690\u542b\u6807\u51c6\u3002\u4f5c\u8005\u4e3a\u4e86\u89e3\u51b3\u521d\u5b66\u8005\u5bf9ESE\u8bba\u6587\u5199\u4f5c\u7684\u56f0\u60d1\u4e0e\u538b\u529b\uff0c\u51b3\u5b9a\u6574\u7406\u4e2a\u4eba\u548c\u4e3b\u89c2\u7684\u5199\u4f5c\u5efa\u8bae\u3002", "method": "\u4f5c\u8005\u4ee5\u6559\u80b2\u4e3a\u9996\u8981\u51fa\u53d1\u70b9\uff0c\u7ed3\u5408\u81ea\u8eab\u6307\u5bfc\u672c\u79d1\u3001\u7855\u58eb\u53ca\u535a\u58eb\u751f\u5199\u4f5c\u7684\u7ecf\u9a8c\uff0c\u4e3b\u89c2\u603b\u7ed3\u4e86\u4e00\u5957\u5199\u4f5c\u5efa\u8bae\uff0c\u5f62\u6210\u4e00\u4efd\u9762\u5411\u5b66\u751f\u548c\u521d\u5b66\u5199\u4f5c\u8005\u7684ESE\u8bba\u6587\u5199\u4f5c\u6307\u5357\u3002", "result": "\u672c\u6587\u5f62\u6210\u4e86\u4e00\u4efd\u4ee5\u4e3b\u89c2\u7ecf\u9a8c\u4e3a\u57fa\u7840\u3001\u5f3a\u8c03\u5b9e\u7528\u6027\u7684ESE\u8bba\u6587\u5199\u4f5c\u5efa\u8bae\u4e0e\u6307\u5bfc\uff0c\u65e8\u5728\u5e2e\u52a9\u5b66\u751f\u53ca\u5176\u4ed6\u5199\u4f5c\u8005\u66f4\u597d\u5730\u638c\u63e1\u5199\u4f5c\u65b9\u6cd5\u3002", "conclusion": "\u867d\u7136\u8be5\u6307\u5357\u662f\u57fa\u4e8e\u4f5c\u8005\u81ea\u5df1\u7684\u7ecf\u9a8c\u548c\u89c2\u70b9\uff0c\u4f46\u5176\u5199\u6cd5\u548c\u5efa\u8bae\u5df2\u88ab\u4f5c\u8005\u7fa4\u4f53\u8bc1\u5b9e\u6709\u6548\uff0c\u671f\u5f85\u80fd\u4e3a\u8bfb\u8005\u5e26\u6765\u5b9e\u9645\u5e2e\u52a9\u3002"}}
{"id": "2506.11105", "categories": ["cs.CL", "cs.AI", "cs.AR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.11105", "abs": "https://arxiv.org/abs/2506.11105", "authors": ["Uttej Kallakurik", "Edward Humes", "Rithvik Jonna", "Xiaomin Lin", "Tinoosh Mohsenin"], "title": "Enabling On-Device Medical AI Assistants via Input-Driven Saliency Adaptation", "comment": null, "summary": "Large Language Models (LLMs) have significant impact on the healthcare\nscenarios but remain prohibitively large for deployment in real-time,\nresource-constrained environments such as edge devices. In this work, we\nintroduce a novel medical assistant system, optimized through our\ngeneral-purpose compression framework, which tailors Large Language Models\n(LLMs) for deployment in specialized domains. By measuring neuron saliency on\ndomain-specific data, our method can aggressively prune irrelevant neurons,\nreducing model size while preserving performance. Following pruning, we apply\npost-training quantization to further reduce the memory footprint, and evaluate\nthe compressed model across medical benchmarks including MedMCQA, MedQA, and\nPubMedQA. We also deploy the 50\\% compressed Gemma and the 67\\% compressed\nLLaMA3 models on Jetson Orin Nano (18.7W peak) and Raspberry Pi 5 (6.3W peak),\nachieving real-time, energy-efficient inference under hardware constraints.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u526a\u679d\u4e0e\u91cf\u5316\u7684LLM\u538b\u7f29\u65b9\u6cd5\uff0c\u9ad8\u6548\u9002\u914d\u81f3\u8fb9\u7f18\u8bbe\u5907\uff0c\u4fdd\u969c\u4e86\u533b\u7597\u4efb\u52a1\u4e0b\u7684\u5b9e\u65f6\u4e0e\u80fd\u6548\u3002", "motivation": "\u5f53\u524dLLM\u5728\u533b\u7597\u9886\u57df\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u6a21\u578b\u4f53\u79ef\u592a\u5927\uff0c\u96be\u4ee5\u5728\u8fb9\u7f18\u8bbe\u5907\u7b49\u8d44\u6e90\u53d7\u9650\u573a\u666f\u5b9e\u65f6\u90e8\u7f72\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u538b\u7f29\u6846\u67b6\uff1a\u9996\u5148\u6839\u636e\u533b\u7597\u9886\u57df\u6570\u636e\u6d4b\u91cf\u795e\u7ecf\u5143\u91cd\u8981\u6027\uff0c\u5e76\u5bf9\u4e0d\u76f8\u5173\u795e\u7ecf\u5143\u8fdb\u884c\u526a\u679d\uff0c\u7136\u540e\u5bf9\u6a21\u578b\u8fdb\u884c\u91cf\u5316\uff0c\u6700\u540e\u5728\u591a\u4e2a\u533b\u7597\u57fa\u51c6\u4efb\u52a1\u4e0a\u8bc4\u4f30\u3002", "result": "\u5c06Gemma\u538b\u7f2950%\u3001LLaMA3\u538b\u7f2967%\u540e\u90e8\u7f72\u4e8eJetson Orin Nano\u548cRaspberry Pi 5\uff0c\u5b9e\u73b0\u4e86\u80fd\u8017\u4f4e\u3001\u5b9e\u65f6\u54cd\u5e94\u4e14\u6027\u80fd\u57fa\u672c\u65e0\u635f\u7684\u533b\u7597\u95ee\u7b54\u3002", "conclusion": "\u672c\u6587\u8bc1\u660e\u4e86\u901a\u8fc7\u795e\u7ecf\u5143\u91cd\u8981\u6027\u526a\u679d\u548c\u91cf\u5316\uff0cLLM\u53ef\u88ab\u9ad8\u6548\u538b\u7f29\u5e76\u5b9e\u73b0\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u5b9e\u65f6\u533b\u7597\u63a8\u7406\u3002"}}
{"id": "2506.11003", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11003", "abs": "https://arxiv.org/abs/2506.11003", "authors": ["Ruiyang Xu", "Jialun Cao", "Mingyuan Wu", "Wenliang Zhong", "Yaojie Lu", "Ben He", "Xianpei Han", "Shing-Chi Cheung", "Le Sun"], "title": "EmbedAgent: Benchmarking Large Language Models in Embedded System Development", "comment": "21 pages", "summary": "Large Language Models (LLMs) have shown promise in various tasks, yet few\nbenchmarks assess their capabilities in embedded system development.In this\npaper, we introduce EmbedAgent, a paradigm designed to simulate real-world\nroles in embedded system development, such as Embedded System Programmer,\nArchitect, and Integrator. This paradigm enables LLMs to be tested in tasks\nthat bridge the gap between digital and physical systems, allowing for a more\ncomprehensive assessment of their capabilities. To evaluate LLMs on these\ntasks, we propose Embedbench, the first comprehensive benchmark for embedded\nsystem programming, circuit design, and cross-platform migration.Embedbench\nconsists of 126 cases, covering 9 electronic components across 3 hardware\nplatforms. Through extensive experiments on 10 mainstream LLMs, we uncover\nseveral key findings. Surprisingly, despite the simplicity of the cases,\nDeepSeek-R1 achieves only a 55.6% pass@1 rate when provided with schematic\ninformation, and 50.0% when tasked with generating the schematics itself. In\nthe cross-platform migration tasks, LLMs show relatively strong performance\nwith MicroPython on the Raspberry Pi Pico (with the top model achieving 73.8%\npass@1), but perform poorly on ESP-IDF, where the best model reaches only 29.4%\npass@1.Interestingly, we observe that general-purpose chat LLMs like\nDeepSeek-V3 often fail to utilize relevant pre-trained knowledge in this\ndomain, while reasoning LLMs tend to overthink and overlook efficient knowledge\nduring pretraining. Based on these insights, we propose two strategies:\nretrieval augmented generation and compiler feedback-to enhance LLM\nperformance. These strategies result in significant improvements, with\nDeepseek-R1 reaching a 65.1% pass@1 with correct schematics, and 53.1% without.\nAdditionally, the accuracy of the Arduino to ESP32 migration task improves from\n21.4% to 27.8%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9488\u5bf9\u5d4c\u5165\u5f0f\u7cfb\u7edf\u5f00\u53d1\u7684\u5927\u6a21\u578b\u80fd\u529b\u8bc4\u6d4b\u57fa\u51c6Embedbench\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u9a8c\u63ed\u793a\u4e3b\u6d41\u6a21\u578b\u5728\u8be5\u9886\u57df\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u7b56\u7565\u663e\u8457\u63d0\u5347\u6a21\u578b\u8868\u73b0\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u91cd\u8981\u53c2\u8003\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4f17\u591a\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u9488\u5bf9\u5d4c\u5165\u5f0f\u7cfb\u7edf\u5f00\u53d1\u9886\u57df\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\u4ecd\u5341\u5206\u6709\u9650\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u8bc4\u6d4b\u8303\u5f0f\u548c\u6570\u636e\u96c6\uff0c\u586b\u8865\u8fd9\u4e00\u8bc4\u6d4b\u7a7a\u767d\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86EmbedAgent\u8303\u5f0f\uff0c\u6a21\u62df\u5b9e\u9645\u5d4c\u5165\u5f0f\u5f00\u53d1\u8005\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5e76\u53d1\u5e03\u4e86\u8986\u76d6\u7f16\u7a0b\u3001\u786c\u4ef6\u7535\u8def\u8bbe\u8ba1\u3001\u5e73\u53f0\u8fc1\u79fb\u7b49\u65b9\u9762\u7684Embedbench\u57fa\u51c6\u6570\u636e\u96c6\u3002\u901a\u8fc7\u572810\u79cd\u4e3b\u6d41LLM\u4e0a\u8fdb\u884c\u7cfb\u7edf\u6027\u5b9e\u9a8c\u5e76\u5206\u6790\u6a21\u578b\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5373\u4f7f\u9762\u5bf9\u7ed3\u6784\u7b80\u5355\u7684\u95ee\u9898\uff0c\u5f53\u524d\u4e3b\u6d41\u6a21\u578b\uff08\u5982DeepSeek-R1\uff09\u4e5f\u96be\u4ee5\u83b7\u5f97\u9ad8\u901a\u8fc7\u7387\uff0c\u4e14\u4e0d\u540c\u5e73\u53f0\u8fc1\u79fb\u4efb\u52a1\u8868\u73b0\u5dee\u5f02\u663e\u8457\u3002\u63d0\u51fa\u7684\u4e24\u79cd\u589e\u5f3a\u7b56\u7565\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e0e\u7f16\u8bd1\u53cd\u9988\uff09\u663e\u8457\u63d0\u5347\u6a21\u578b\u8868\u73b0\uff0c\u5982DeepSeek-R1\u5728\u6b63\u786e\u7535\u8def\u56fe\u573a\u666f\u4e0b\u901a\u8fc7\u7387\u63d0\u5347\u523065.1%\u3002", "conclusion": "LLMs\u5728\u5b9e\u9645\u5d4c\u5165\u5f0f\u5f00\u53d1\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u5c1a\u6709\u9650\uff0c\u901a\u7528\u6a21\u578b\u548c\u63a8\u7406\u6a21\u578b\u5747\u5b58\u5728\u4e0d\u8db3\u3002\u901a\u8fc7\u5f15\u5165\u5916\u90e8\u77e5\u8bc6\u6216\u7f16\u8bd1\u53cd\u9988\u7b49\u65b9\u6cd5\u53ef\u663e\u8457\u589e\u5f3a\u6a21\u578b\u80fd\u529b\u3002Embedbench\u4e3a\u672a\u6765LLM\u5728\u5d4c\u5165\u5f0f\u65b9\u5411\u7684\u7814\u7a76\u4e0e\u6539\u8fdb\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u8bc4\u6d4b\u6846\u67b6\u548c\u6d1e\u89c1\u3002"}}
{"id": "2506.11106", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2506.11106", "abs": "https://arxiv.org/abs/2506.11106", "authors": ["Ningyuan Li", "Junrui Liu", "Yi Shan", "Minghui Huang", "Tong Li"], "title": "Graph-based RAG Enhancement via Global Query Disambiguation and Dependency-Aware Reranking", "comment": null, "summary": "Contemporary graph-based retrieval-augmented generation (RAG) methods\ntypically begin by extracting entities from user queries and then leverage\npre-constructed knowledge graphs to retrieve related relationships and\nmetadata. However, this pipeline's exclusive reliance on entity-level\nextraction can lead to the misinterpretation or omission of latent yet critical\ninformation and relations. As a result, retrieved content may be irrelevant or\ncontradictory, and essential knowledge may be excluded, exacerbating\nhallucination risks and degrading the fidelity of generated responses. To\naddress these limitations, we introduce PankRAG, a framework that combines a\nglobally aware, hierarchical query-resolution strategy with a novel\ndependency-aware reranking mechanism. PankRAG first constructs a multi-level\nresolution path that captures both parallel and sequential interdependencies\nwithin a query, guiding large language models (LLMs) through structured\nreasoning. It then applies its dependency-aware reranker to exploit the\ndependency structure among resolved sub-questions, enriching and validating\nretrieval results for subsequent sub-questions. Empirical evaluations\ndemonstrate that PankRAG consistently outperforms state-of-the-art approaches\nacross multiple benchmarks, underscoring its robustness and generalizability.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86PankRAG\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u5c42\u6b21\u63a8\u7406\u4e0e\u4f9d\u8d56\u611f\u77e5\u91cd\u6392\u5e8f\u4f18\u5316\u4e86\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u751f\u6210\u4efb\u52a1\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u68c0\u7d22\u76f8\u5173\u6027\u548c\u54cd\u5e94\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u56fe\u8c31\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\u5728\u4fe1\u606f\u68c0\u7d22\u65f6\u8fc7\u5ea6\u4f9d\u8d56\u4e8e\u5b9e\u4f53\u7ea7\u522b\u62bd\u53d6\uff0c\u5bfc\u81f4\u9057\u6f0f\u6216\u8bef\u89e3\u6f5c\u5728\u91cd\u8981\u4fe1\u606f\u4e0e\u5173\u7cfb\uff0c\u8fdb\u800c\u5f71\u54cd\u5185\u5bb9\u7684\u76f8\u5173\u6027\u4e0e\u51c6\u786e\u6027\uff0c\u5e76\u589e\u52a0\u4e86\u5e7b\u89c9\u98ce\u9669\u3002", "method": "\u63d0\u51faPankRAG\u6846\u67b6\uff0c\u5305\u62ec\u5168\u5c40\u611f\u77e5\u3001\u5c42\u6b21\u5316\u7684\u67e5\u8be2\u89e3\u51b3\u7b56\u7565\u548c\u65b0\u9896\u7684\u4f9d\u8d56\u611f\u77e5\u91cd\u6392\u5e8f\u673a\u5236\u3002\u9996\u5148\uff0cPankRAG \u6784\u5efa\u591a\u5c42\u6b21\u89e3\u51b3\u8def\u5f84\uff0c\u6355\u6349\u67e5\u8be2\u4e2d\u7684\u5e76\u884c\u548c\u987a\u5e8f\u4f9d\u8d56\u5173\u7cfb\uff0c\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7ed3\u6784\u5316\u63a8\u7406\u3002\u968f\u540e\uff0c\u4f9d\u8d56\u611f\u77e5\u91cd\u6392\u5e8f\u5668\u5229\u7528\u5df2\u89e3\u51b3\u5b50\u95ee\u95f4\u7684\u4f9d\u8d56\u7ed3\u6784\uff0c\u4e30\u5bcc\u5e76\u6821\u9a8c\u540e\u7eed\u68c0\u7d22\u7ed3\u679c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cPankRAG \u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5747\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u8868\u73b0\u51fa\u8f83\u5f3a\u7684\u7a33\u5065\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "PankRAG \u6709\u6548\u514b\u670d\u4e86\u4f20\u7edfRAG\u65b9\u6cd5\u5728\u5b9e\u4f53\u62bd\u53d6\u4e0a\u7684\u5c40\u9650\uff0c\u901a\u8fc7\u6574\u5408\u5c42\u6b21\u5316\u63a8\u7406\u548c\u4f9d\u8d56\u611f\u77e5\u68c0\u7d22\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u5185\u5bb9\u7684\u76f8\u5173\u6027\u4e0e\u51c6\u786e\u6027\u3002"}}
{"id": "2506.11005", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11005", "abs": "https://arxiv.org/abs/2506.11005", "authors": ["Mouna Dhaouadi", "Bentley Oakes", "Michalis Famelis"], "title": "Automated Extraction and Analysis of Developer's Rationale in Open Source Software", "comment": null, "summary": "Contributors to open source software must deeply understand a project's\nhistory to make coherent decisions which do not conflict with past reasoning.\nHowever, inspecting all related changes to a proposed contribution requires\nintensive manual effort, and previous research has not yet produced an\nautomated mechanism to expose and analyze these conflicts. In this article, we\npropose such an automated approach for rationale analyses, based on an\ninstantiation of Kantara, an existing high-level rationale extraction and\nmanagement architecture. Our implementation leverages pre-trained models and\nLarge Language Models, and includes structure-based mechanisms to detect\nreasoning conflicts and problems which could cause design erosion in a project\nover time. We show the feasibility of our extraction and analysis approach\nusing the OOM-Killer module of the Linux Kernel project, and investigate the\napproach's generalization to five other highly active open source projects. The\nresults confirm that our automated approach can support rationale analyses with\nreasonable performance, by finding interesting relationships and to detect\npotential conflicts and reasoning problems. We also show the effectiveness of\nthe automated extraction of decision and rationale sentences and the prospects\nfor generalizing this to other open source projects. This automated approach\ncould therefore be used by open source software developers to proactively\naddress hidden issues and to ensure that new changes do not conflict with past\ndecisions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5206\u6790\u5f00\u6e90\u8f6f\u4ef6\u5386\u53f2\u51b3\u7b56\u51b2\u7a81\u7684\u65b9\u6cd5\uff0c\u5e76\u5728\u591a\u4e2a\u9879\u76ee\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u53ef\u52a9\u529b\u5f00\u53d1\u8005\u89c4\u907f\u51b3\u7b56\u51b2\u7a81\u3002", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u7684\u8d21\u732e\u8005\u9700\u8981\u6df1\u5165\u7406\u89e3\u9879\u76ee\u5386\u53f2\uff0c\u4ee5\u907f\u514d\u4e0e\u8fc7\u53bb\u7684\u51b3\u7b56\u51b2\u7a81\u3002\u7136\u800c\uff0c\u624b\u52a8\u68c0\u67e5\u6240\u6709\u76f8\u5173\u53d8\u66f4\u975e\u5e38\u8017\u65f6\uff0c\u4ee5\u524d\u4e5f\u7f3a\u4e4f\u81ea\u52a8\u5316\u7684\u51b2\u7a81\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eKantara\u67b6\u6784\u7684\u81ea\u52a8\u5316\u63a8\u7406\u5206\u6790\u65b9\u6cd5\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4ee5\u53ca\u7ed3\u6784\u5316\u673a\u5236\u6765\u68c0\u6d4b\u63a8\u7406\u51b2\u7a81\u548c\u9879\u76ee\u6f14\u5316\u98ce\u9669\u3002\u901a\u8fc7\u5728Linux Kernel\u7684OOM-Killer\u6a21\u5757\u548c\u5176\u4ed6\u4e94\u4e2a\u9ad8\u6d3b\u8dc3\u5ea6\u9879\u76ee\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u81ea\u52a8\u5316\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u5206\u6790\u51b3\u7b56\u63a8\u7406\uff0c\u53d1\u73b0\u6f5c\u5728\u51b2\u7a81\uff0c\u5e76\u81ea\u52a8\u63d0\u53d6\u51b3\u7b56\u548c\u63a8\u7406\u53e5\u5b50\u3002\u65b9\u6cd5\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u8f85\u52a9\u5f00\u6e90\u5f00\u53d1\u8005\u4e3b\u52a8\u53d1\u73b0\u9690\u85cf\u95ee\u9898\uff0c\u786e\u4fdd\u65b0\u53d8\u66f4\u4e0d\u4f1a\u4e0e\u4ee5\u5f80\u51b3\u7b56\u51b2\u7a81\uff0c\u63d0\u5347\u9879\u76ee\u8d28\u91cf\u3002"}}
{"id": "2506.11108", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11108", "abs": "https://arxiv.org/abs/2506.11108", "authors": ["Andrew Kiruluta", "Andreas Lemos", "Priscilla Burity"], "title": "History-Aware Cross-Attention Reinforcement: Self-Supervised Multi Turn and Chain-of-Thought Fine-Tuning with vLLM", "comment": null, "summary": "We present CAGSR-vLLM-MTC, an extension of our Self-Supervised\nCross-Attention-Guided Reinforcement (CAGSR) framework, now implemented on the\nhigh-performance vLLM runtime, to address both multi-turn dialogue and\nchain-of-thought reasoning. Building upon our original single-turn approach, we\nfirst instrumented vLLM's C++/CUDA kernels to asynchronously capture per-layer,\nper-head cross-attention weights during generation. We then generalized our\nself-supervised reward function to accumulate attention signals over entire\nconversation histories and intermediate chain-of-thought steps. We discuss\npractical trade-offs, including an entropy-based clamping mechanism to prevent\nattention collapse on early context, and outline future directions for\nmulti-party dialogues and hierarchical reasoning.", "AI": {"tldr": "\u672c\u5de5\u4f5c\u6269\u5c55\u4e86CAGSR\u6846\u67b6\uff0c\u4f7f\u5176\u652f\u6301\u591a\u8f6e\u5bf9\u8bdd\u4e0e\u94fe\u5f0f\u63a8\u7406\uff0c\u5e76\u96c6\u6210\u81f3\u9ad8\u6027\u80fdvLLM\u7cfb\u7edf\uff0c\u53ef\u5f02\u6b65\u6355\u6349\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u5956\u52b1\u673a\u5236\u4f18\u5316\u5bf9\u8bdd\u5386\u53f2\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u65e9\u671fattention\u5d29\u6e83\u7684\u95ee\u9898\uff0c\u5e76\u5c55\u671b\u4e86\u66f4\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u5e94\u7528\u3002", "motivation": "\u5f53\u524d\u591a\u8f6e\u5bf9\u8bdd\u548c\u94fe\u5f0f\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u5982\u4f55\u6709\u6548\u5730\u5229\u7528\u5bf9\u8bdd\u5386\u53f2\u4e0e\u63a8\u7406\u4e2d\u95f4\u6b65\u9aa4\u4ecd\u662f\u6311\u6218\u3002\u539f\u6709CAGSR\u6846\u67b6\u4ec5\u652f\u6301\u5355\u8f6e\uff0c\u7f3a\u4e4f\u5bf9\u590d\u6742\u5bf9\u8bdd\u4e0e\u63a8\u7406\u4efb\u52a1\u7684\u5904\u7406\u80fd\u529b\u3002", "method": "\u6269\u5c55CAGSR\u6846\u67b6\u81f3\u591a\u8f6e\u5bf9\u8bdd\u4e0e\u94fe\u5f0f\u63a8\u7406\uff0c\u540c\u65f6\u5c06\u5176\u90e8\u7f72\u4e8e\u9ad8\u6027\u80fdvLLM\u8fd0\u884c\u65f6\u3002\u901a\u8fc7\u4fee\u6539vLLM\u7684C++/CUDA\u5185\u6838\uff0c\u5b9e\u73b0\u751f\u6210\u65f6\u5f02\u6b65\u6293\u53d6\u6bcf\u4e00\u5c42\u3001\u6bcf\u4e00\u5934\u7684cross-attention\u6743\u91cd\uff0c\u5e76\u5c06\u5956\u52b1\u51fd\u6570\u63a8\u5e7f\u4e3a\u8de8\u6574\u4e2a\u4f1a\u8bdd\u5386\u53f2\u548c\u63a8\u7406\u6b65\u9aa4\u7d2f\u79efattention\u4fe1\u53f7\u3002\u5f15\u5165\u57fa\u4e8e\u71b5\u7684\u88c1\u526a\u673a\u5236\u9632\u6b62\u65e9\u671f\u4e0a\u4e0b\u6587attention\u584c\u7f29\u3002", "result": "\u5b9e\u73b0\u4e86CAGSR\u6846\u67b6\u5728\u591a\u8f6e\u5bf9\u8bdd\u548c\u94fe\u5f0f\u63a8\u7406\u4e2d\u7684\u62d3\u5c55\uff0c\u80fd\u6709\u6548\u63d0\u53d6\u5e76\u5229\u7528\u6574\u4e2a\u5386\u53f2\u7684attention\u4fe1\u53f7\uff1b\u89e3\u51b3\u4e86\u65e9\u671fattention\u5d29\u6e83\u7b49\u5b9e\u9645\u95ee\u9898\u3002", "conclusion": "CAGSR-vLLM-MTC\u4e3a\u591a\u8f6e\u5bf9\u8bdd\u548c\u4e2d\u95f4\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u81ea\u76d1\u7763\u4f18\u5316\u65b9\u6cd5\uff0c\u5e76\u5bf9\u591a\u65b9\u5bf9\u8bdd\u548c\u5c42\u6b21\u5316\u63a8\u7406\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u8fdb\u884c\u4e86\u5c55\u671b\u3002"}}
{"id": "2506.11006", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11006", "abs": "https://arxiv.org/abs/2506.11006", "authors": ["Sai Krishna", "Balvinder Singh", "Sujoy Roychowdhury", "Giriprasad Sridhara", "Sourav Mazumdar", "Magnus Sandelin", "Dimitris Rentas", "Maciej Nalepa", "Karol Sawicki", "Jakub Gajda"], "title": "Test code generation at Ericsson using Program Analysis Augmented Fine Tuned LLMs", "comment": "Accepted at International Conference on Evaluation and Assessment in\n  Software Engineering (EASE), 2025", "summary": "We describe test code generation using Large Language Models (LLMs) in\nEricsson. Our input is a test step in natural language (English) and our output\nis code (Java) which accomplishes the test step. We describe how straight\nforward prompting does not suffice and results in LLM assuming functions and\nsignatures which are not present in the code repository. We then show how we\nalleviate the problem by a combination of Retrieval Augmented Generation (RAG)\nalong with prompt engineering that expanded the simple prompt with additional\ncontextual information using static program analysis. We then describe further\nimprovements that we obtained by fine-tuning the underlying LLM. The fine\ntuning is done based on a custom designed prompt template which has\npre-dependent classes, their public methods as well two exemplar outputs\nobtained from RAG. Our results establish that our fine tuned models help\nimprove the correspondence or conformity with the original developer written\ntest code as measured by the traditional metrics of F1-score based on the\nmethods used in the generated code. Fine tuning of a 8x7b Mixture of Experts\n(MoE) model leads to an average improvement of 8\\% over the base model and is\ncomparable to the scores on a much larger 8x22b MoE model.", "AI": {"tldr": "\u672c\u6587\u5728Ericsson\u573a\u666f\u4e0b\uff0c\u7ed3\u5408RAG\u4e0ePrompt Engineering\uff0c\u5e76\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\uff0c\u5b9e\u73b0\u4e86\u81ea\u7136\u8bed\u8a00\u5230Java\u6d4b\u8bd5\u4ee3\u7801\u7684\u7cbe\u51c6\u8f6c\u6362\uff0c\u6a21\u578b\u6027\u80fd\u63d0\u5347\u663e\u8457\uff0c\u9002\u5408\u5de5\u7a0b\u5b9e\u8df5\u3002", "motivation": "\u5728Ericsson\u80cc\u666f\u4e0b\uff0c\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u4ee3\u7801\u5bf9\u4e8e\u63d0\u5347\u5f00\u53d1\u6548\u7387\u4e0e\u4ee3\u7801\u8d28\u91cf\u6709\u91cd\u8981\u610f\u4e49\u3002\u76f4\u63a5\u91c7\u7528LLM\u5c06\u81ea\u7136\u8bed\u8a00\u6d4b\u8bd5\u6b65\u9aa4\u8f6c\u4e3aJava\u4ee3\u7801\u5b58\u5728\u6a21\u578b\u81c6\u9020\u672a\u77e5\u51fd\u6570\u7b7e\u540d\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u751f\u6210\u65b9\u6cd5\u4ee5\u8d34\u5408\u771f\u5b9e\u4ee3\u7801\u5e93\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u7ec4\u5408\u7684RAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09\u4e0ePrompt Engineering\u65b9\u6848\uff0c\u901a\u8fc7\u9759\u6001\u7a0b\u5e8f\u5206\u6790\u4e3a\u6a21\u578b\u63d0\u4f9b\u66f4\u591a\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5e76\u8fdb\u4e00\u6b65\u57fa\u4e8e\u81ea\u5b9a\u4e49Prompt\u6a21\u677f\u5bf9LLM\u8fdb\u884c\u5fae\u8c03\u3002\u6a21\u677f\u5305\u62ec\u4f9d\u8d56\u7c7b\u3001\u516c\u5171\u65b9\u6cd5\u53ca\u793a\u4f8b\u8f93\u51fa\uff0c\u63d0\u5347\u751f\u6210\u4ee3\u7801\u7684\u51c6\u786e\u6027\u3002", "result": "\u5fae\u8c03\u540e\u76848x7b MoE\u6a21\u578b\uff08\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\uff09\u6bd4\u57fa\u7840\u6a21\u578b\u7684F1\u5206\u6570\u5e73\u5747\u63d0\u5347\u4e868%\uff0c\u4e14\u63a5\u8fd1\u66f4\u5927\u89c4\u6a218x22b MoE\u6a21\u578b\u7684\u8868\u73b0\uff0c\u6781\u5927\u63d0\u9ad8\u4e86\u751f\u6210\u4ee3\u7801\u4e0e\u5f00\u53d1\u8005\u539f\u59cb\u6d4b\u8bd5\u4ee3\u7801\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u4e0e\u7cbe\u7ec6\u5316Prompt\uff0c\u5e76\u5bf9\u5927\u6a21\u578b\u8fdb\u4e00\u6b65\u5fae\u8c03\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u4ee3\u7801\u7684\u8d28\u91cf\u548c\u5b9e\u7528\u6027\uff0c\u4e14\u4e2d\u7b49\u89c4\u6a21\u6a21\u578b\u53ef\u8fbe\u5230\u5927\u6a21\u578b\u7684\u6027\u80fd\uff0c\u9002\u5408\u5b9e\u9645\u4f01\u4e1a\u5e94\u7528\u3002"}}
{"id": "2506.11109", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11109", "abs": "https://arxiv.org/abs/2506.11109", "authors": ["Yile Chen", "Yicheng Tao", "Yue Jiang", "Shuai Liu", "Han Yu", "Gao Cong"], "title": "Enhancing Large Language Models for Mobility Analytics with Semantic Location Tokenization", "comment": "Accepted by KDD'25", "summary": "The widespread adoption of location-based services has led to the generation\nof vast amounts of mobility data, providing significant opportunities to model\nuser movement dynamics within urban environments. Recent advancements have\nfocused on adapting Large Language Models (LLMs) for mobility analytics.\nHowever, existing methods face two primary limitations: inadequate semantic\nrepresentation of locations (i.e., discrete IDs) and insufficient modeling of\nmobility signals within LLMs (i.e., single templated instruction fine-tuning).\nTo address these issues, we propose QT-Mob, a novel framework that\nsignificantly enhances LLMs for mobility analytics. QT-Mob introduces a\nlocation tokenization module that learns compact, semantically rich tokens to\nrepresent locations, preserving contextual information while ensuring\ncompatibility with LLMs. Furthermore, QT-Mob incorporates a series of\ncomplementary fine-tuning objectives that align the learned tokens with the\ninternal representations in LLMs, improving the model's comprehension of\nsequential movement patterns and location semantics. The proposed QT-Mob\nframework not only enhances LLMs' ability to interpret mobility data but also\nprovides a more generalizable approach for various mobility analytics tasks.\nExperiments on three real-world dataset demonstrate the superior performance in\nboth next-location prediction and mobility recovery tasks, outperforming\nexisting deep learning and LLM-based methods.", "AI": {"tldr": "QT-Mob\u901a\u8fc7\u5f15\u5165\u8bed\u4e49\u5316\u4f4d\u7f6e\u5206\u8bcd\u548c\u591a\u91cd\u5fae\u8c03\u76ee\u6807\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u79fb\u52a8\u6570\u636e\u7684\u7406\u89e3\u529b\uff0c\u5728\u9884\u6d4b\u548c\u6062\u590d\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u57fa\u4e8e\u4f4d\u7f6e\u7684\u670d\u52a1\u7684\u666e\u53ca\uff0c\u4ea7\u751f\u4e86\u5927\u91cf\u7684\u79fb\u52a8\u6570\u636e\uff0c\u4f46\u5f53\u524d\u57fa\u4e8e\u5927\u6a21\u578b\uff08LLMs\uff09\u7684\u65b9\u6cd5\u5728\u8868\u793a\u4f4d\u7f6e\u4fe1\u606f\u548c\u6355\u6349\u79fb\u52a8\u4fe1\u53f7\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002\u4f5c\u8005\u5e0c\u671b\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u8bed\u4e49\u8868\u8fbe\u80fd\u529b\u4e0d\u8db3\u548cLLM\u5efa\u6a21\u79fb\u52a8\u6027\u4fe1\u53f7\u4e0d\u8db3\u7684\u4e24\u5927\u96be\u9898\u3002", "method": "\u63d0\u51fa\u4e86QT-Mob\u6846\u67b6\uff0c\u5305\u542b\u4f4d\u7f6e\u5206\u8bcd\u6a21\u5757\u4ee5\u5b66\u4e60\u7d27\u51d1\u4e14\u5bcc\u6709\u8bed\u4e49\u7684\u4fe1\u606f\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u591a\u6837\u5316\u7684\u5fae\u8c03\u76ee\u6807\uff0c\u5c06\u4f4d\u7f6e\u4fe1\u53f7\u4e0eLLM\u5185\u90e8\u8868\u5f81\u5bf9\u9f50\uff0c\u589e\u5f3a\u5bf9\u79fb\u52a8\u6a21\u5f0f\u548c\u4f4d\u7f6e\u8bed\u4e49\u7684\u7406\u89e3\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\uff0cQT-Mob\u5728\u4e0b\u4e00\u4e2a\u4f4d\u7f6e\u9884\u6d4b\u548c\u79fb\u52a8\u6062\u590d\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u548c\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\uff0c\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u6cdb\u5316\u6027\u548c\u6027\u80fd\u3002", "conclusion": "QT-Mob\u901a\u8fc7\u6539\u8fdb\u4f4d\u7f6e\u8868\u793a\u548c\u5185\u5728\u6a21\u578b\u8bed\u4e49\u80fd\u529b\uff0c\u63d0\u5347\u4e86LLMs\u5bf9\u79fb\u52a8\u6570\u636e\u5206\u6790\u7684\u80fd\u529b\uff0c\u4f18\u4e8e\u76ee\u524d\u5df2\u6709\u65b9\u6cd5\uff0c\u5e76\u53ef\u9002\u5e94\u591a\u79cd\u79fb\u52a8\u6570\u636e\u5206\u6790\u573a\u666f\u3002"}}
{"id": "2506.11007", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11007", "abs": "https://arxiv.org/abs/2506.11007", "authors": ["Rock Sabetto", "Emily Escamilla", "Devesh Agarwal", "Sujay Kandwal", "Justin F. Brunelle", "Scott Rosen", "Nitin Naik", "Samruddhi Thaker", "Eric O. Scott", "Jacob Zimmer", "Amit Madan", "Arun Sridharan", "Doug Wendt", "Michael Doyle", "Christopher Glasz", "Jasper Phillips", "William Macke", "Colin Diggs", "Michael Bartholf", "Zachary Robin", "Paul Ursino"], "title": "Impact of Comments on LLM Comprehension of Legacy Code", "comment": null, "summary": "Large language models (LLMs) have been increasingly integrated into software\nengineering and maintenance tasks due to their high performance with software\nengineering tasks and robust understanding of modern programming languages.\nHowever, the ability of LLMs to comprehend code written with legacy languages\nremains a research gap challenged by real-world legacy systems lacking or\ncontaining inaccurate documentation that may impact LLM comprehension. To\nassess LLM comprehension of legacy languages, there is a need for objective LLM\nevaluation. In order to objectively measure LLM comprehension of legacy\nlanguages, we need an efficient, quantitative evaluation method. We leverage\nmultiple-choice question answering (MCQA), an emerging LLM evaluation\nmethodology, to evaluate LLM comprehension of legacy code and the impact of\ncomment prevalence and inaccurate comments. In this work, we present\npreliminary findings on the impact of documentation on LLM comprehension of\nlegacy code and outline strategic objectives for future work.", "AI": {"tldr": "\u672c\u6587\u7528\u591a\u9879\u9009\u62e9\u95ee\u7b54\u65b9\u6cd5\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7406\u89e3\u9057\u7559\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u6587\u6863\u548c\u6ce8\u91ca\u7684\u5b8c\u6574\u6027\u5bf9\u7406\u89e3\u6548\u679c\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u76f8\u5173\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5df2\u5e7f\u6cdb\u5e94\u7528\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u548c\u7ef4\u62a4\u4efb\u52a1\uff0c\u4f46\u5bf9\u4e8e\u9057\u7559\u8bed\u8a00\uff08legacy languages\uff09\u7684\u4ee3\u7801\u7406\u89e3\u80fd\u529b\u4ecd\u5b58\u5728\u7814\u7a76\u7a7a\u767d\u3002\u7531\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u9057\u7559\u7cfb\u7edf\u5e38\u5e38\u7f3a\u4e4f\u6216\u62e5\u6709\u4e0d\u51c6\u786e\u7684\u6587\u6863\uff0c\u8fd9\u8fdb\u4e00\u6b65\u5f71\u54cdLLM\u7684\u4ee3\u7801\u7406\u89e3\u8868\u73b0\uff0c\u56e0\u6b64\u9700\u8981\u5bf9LLM\u5728\u9057\u7559\u4ee3\u7801\u73af\u5883\u4e0b\u7684\u7406\u89e3\u80fd\u529b\u8fdb\u884c\u5ba2\u89c2\u8bc4\u4f30\u3002", "method": "\u4f5c\u8005\u91c7\u7528\u591a\u9879\u9009\u62e9\u95ee\u7b54\uff08MCQA\uff09\u4f5c\u4e3a\u4e00\u79cd\u65b0\u5174\u7684LLM\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5bf9LLM\u5bf9\u4e8e\u9057\u7559\u4ee3\u7801\u7684\u7406\u89e3\u80fd\u529b\uff0c\u4ee5\u53ca\u6ce8\u91ca\u7684\u591a\u5c11\u4e0e\u4e0d\u51c6\u786e\u6ce8\u91ca\u5bf9LLM\u7406\u89e3\u7684\u5f71\u54cd\u8fdb\u884c\u91cf\u5316\u8bc4\u4f30\u3002", "result": "\u6587\u7ae0\u63d0\u4f9b\u4e86LLM\u5728\u7406\u89e3\u9057\u7559\u4ee3\u7801\u65f6\u6587\u6863\u60c5\u51b5\u5bf9\u5176\u8868\u73b0\u5f71\u54cd\u7684\u521d\u6b65\u53d1\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7684\u6218\u7565\u6027\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u591a\u9879\u9009\u62e9\u95ee\u7b54\u65b9\u6cd5\u53ef\u4ee5\u4f5c\u4e3a\u8bc4\u4f30LLM\u5bf9\u9057\u7559\u4ee3\u7801\u7406\u89e3\u80fd\u529b\u7684\u6709\u6548\u624b\u6bb5\uff0c\u6587\u6863\u7684\u6570\u91cf\u548c\u51c6\u786e\u6027\u4f1a\u5f71\u54cd\u5176\u7406\u89e3\u6548\u679c\uff0c\u672a\u6765\u7814\u7a76\u5c06\u8fdb\u4e00\u6b65\u5b8c\u5584\u8fd9\u4e00\u8bc4\u4f30\u4f53\u7cfb\u548c\u63a2\u8ba8\u63d0\u5347LLM\u5bf9\u9057\u7559\u4ee3\u7801\u7684\u7406\u89e3\u65b9\u6cd5\u3002"}}
{"id": "2506.11110", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.11110", "abs": "https://arxiv.org/abs/2506.11110", "authors": ["Jaeho Lee", "Atharv Chowdhary"], "title": "AssertBench: A Benchmark for Evaluating Self-Assertion in Large Language Models", "comment": "15 pages, 4 figures, appendix contains 2 additional figures and 2\n  tables", "summary": "Recent benchmarks have probed factual consistency and rhetorical robustness\nin Large Language Models (LLMs). However, a knowledge gap exists regarding how\ndirectional framing of factually true statements influences model agreement, a\ncommon scenario for LLM users. AssertBench addresses this by sampling\nevidence-supported facts from FEVEROUS, a fact verification dataset. For each\n(evidence-backed) fact, we construct two framing prompts: one where the user\nclaims the statement is factually correct, and another where the user claims it\nis incorrect. We then record the model's agreement and reasoning. The desired\noutcome is that the model asserts itself, maintaining consistent truth\nevaluation across both framings, rather than switching its evaluation to agree\nwith the user. AssertBench isolates framing-induced variability from the\nmodel's underlying factual knowledge by stratifying results based on the\nmodel's accuracy on the same claims when presented neutrally. In doing so, this\nbenchmark aims to measure an LLM's ability to \"stick to its guns\" when\npresented with contradictory user assertions about the same fact. The complete\nsource code is available at https://github.com/achowd32/assert-bench.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAssertBench\u57fa\u51c6\uff0c\u901a\u8fc7\u6b63\u3001\u53cd\u4e24\u4e2a\u65b9\u5411\u6027\u7684\u4e8b\u5b9e\u8868\u8ff0\uff0c\u8bc4\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u4f1a\u56e0\u7528\u6237\u4e3b\u5f20\u6539\u53d8\u81ea\u8eab\u4e8b\u5b9e\u5224\u65ad\uff0c\u4e3a\u6a21\u578b\u4e00\u81f4\u6027\u8bc4\u6d4b\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u4e0e\u5de5\u5177\u3002", "motivation": "\u76ee\u524d\u5bf9\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4e8b\u5b9e\u4e00\u81f4\u6027\u4e0e\u4fee\u8f9e\u9c81\u68d2\u6027\u65b9\u9762\u5b58\u5728\u8bc4\u6d4b\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u5f53\u4e8b\u5b9e\u9648\u8ff0\u88ab\u4ee5\u4e0d\u540c\u65b9\u5411\u6027\u8868\u8fbe\u65f6\uff0c\u6a21\u578b\u7684\u56de\u7b54\u662f\u5426\u4f1a\u88ab\u5f71\u54cd\uff0c\u5373\uff1a\u7528\u6237\u63d0\u51fa\u76f8\u53cd\u4e3b\u5f20\u65f6\uff0c\u6a21\u578b\u80fd\u5426\u575a\u6301\u81ea\u8eab\u7684\u4e8b\u5b9e\u5224\u65ad\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86AssertBench\u57fa\u51c6\uff0c\u4ece\u4e8b\u5b9e\u6838\u67e5\u6570\u636e\u96c6FEVEROUS\u4e2d\u62bd\u53d6\u652f\u6301\u8bc1\u636e\u7684\u4e8b\u5b9e\u3002\u9488\u5bf9\u6bcf\u4e2a\u4e8b\u5b9e\uff0c\u5206\u522b\u6784\u5efa\u201c\u7528\u6237\u58f0\u79f0\u8be5\u8bed\u53e5\u6b63\u786e\u201d\u4e0e\u201c\u7528\u6237\u58f0\u79f0\u8be5\u8bed\u53e5\u9519\u8bef\u201d\u4e24\u79cd\u63d0\u793a\uff0c\u89c2\u5bdf\u6a21\u578b\u5bf9\u540c\u4e00\u4e8b\u5b9e\u5728\u6b63\u3001\u53cd\u4e24\u79cd\u8868\u8ff0\u4e0b\u7684\u540c\u4e00\u81f4\u6027\u4ee5\u53ca\u63a8\u7406\u8fc7\u7a0b\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u5c06\u6a21\u578b\u5728\u4e2d\u6027\u8868\u8ff0\u4e0b\u7684\u51c6\u786e\u6027\u4f5c\u4e3a\u5206\u5c42\u6807\u51c6\uff0c\u63a7\u5236\u6a21\u578b\u56fa\u6709\u77e5\u8bc6\u4e0e\u8868\u8ff0\u5e27\u7684\u5f71\u54cd\u3002", "result": "AssertBench\u80fd\u591f\u6709\u6548\u533a\u5206\u6a21\u578b\u7531\u4e8e\u8868\u8ff0\u65b9\u5f0f\u53d8\u5316\u800c\u4ea7\u751f\u7684\u5224\u65ad\u6447\u6446\uff0c\u63ed\u793a\u6a21\u578b\u9762\u4e34\u76f8\u53cd\u7528\u6237\u4e3b\u5f20\u65f6\u575a\u6301\u81ea\u6211\u4e8b\u5b9e\u5224\u65ad\u7684\u80fd\u529b\u3002", "conclusion": "AssertBench\u4e3a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9762\u5bf9\u76f8\u53cd\u65b9\u5411\u6027\u4e3b\u5f20\u65f6\u7684\u4e00\u81f4\u6027\u4e0e\u4e8b\u5b9e\u575a\u6301\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u6df1\u5165\u7406\u89e3\u548c\u6539\u8fdb\u6a21\u578b\u7684\u5bf9\u8bdd\u5065\u58ee\u6027\u3002"}}
{"id": "2506.11008", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11008", "abs": "https://arxiv.org/abs/2506.11008", "authors": ["David Noever"], "title": "Encoding Software For Perpetuity: A Compact Representation Of Apollo 11 Guidance Code", "comment": null, "summary": "This brief note presents a novel method for encoding historic Apollo 11 Lunar\nModule guidance computer code into a single, compact Quick Response Code (QR\ncode) format, creating an accessible digital artifact for transmission and\narchival purposes. By applying tokenization, selective content preservation,\nand minimal HTML/JavaScript techniques, we successfully compressed key\ncomponents of the original Assembly Language Code (AGC) into a shareable,\npreservable, and scannable 3 kilobyte (KB) image. We evaluate multiple\ncompression strategies and their tradeoffs in terms of size, readability, and\nhistorical significance. This method addresses the challenge of making\nhistorically significant software artifacts available through modern mobile\ndevices without requiring specialized hardware or internet connectivity. While\nnumerous digital preservation methods exist for historic software, this\napproach balances accessibility with historical significance, offering a\ncomplementary method to traditional archival techniques. This work contributes\nto the broader field of computing heritage preservation by demonstrating how\nlandmark software can be made accessible instantly through contemporary mobile\ntechnologies.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u7528\u4e8c\u7ef4\u7801\u538b\u7f29\u4fdd\u5b58\u963f\u6ce2\u7f5711\u53f7\u5386\u53f2\u4ee3\u7801\u7684\u65b0\u65b9\u6cd5\uff0c\u517c\u987e\u4fdd\u5b58\u4e0e\u6613\u8bbf\u95ee\uff0c\u63a8\u52a8\u4e86\u8ba1\u7b97\u9057\u4ea7\u7684\u73b0\u4ee3\u5316\u4f20\u64ad\u3002", "motivation": "\u5386\u53f2\u6027\u8f6f\u4ef6\uff08\u5982\u963f\u6ce2\u7f5711\u53f7\u767b\u6708\u8231\u5236\u5bfc\u8ba1\u7b97\u673a\u4ee3\u7801\uff09\u96be\u4ee5\u901a\u8fc7\u73b0\u4ee3\u8bbe\u5907\u4fbf\u6377\u8bbf\u95ee\u548c\u4fdd\u5b58\uff0c\u9700\u8981\u521b\u65b0\u6027\u4e14\u6613\u7528\u7684\u6570\u5b57\u5b58\u6863\u65b9\u5f0f\u3002", "method": "\u91c7\u7528\u5206\u8bcd\uff08tokenization\uff09\u3001\u5185\u5bb9\u9009\u62e9\u6027\u4fdd\u7559\u548c\u6700\u5c0f\u5316\u7684HTML/JavaScript\u6280\u672f\uff0c\u5c06\u6838\u5fc3\u6c47\u7f16\u4ee3\u7801\u9ad8\u6548\u538b\u7f29\u8fdb\u4e00\u4e2a3KB\u7684\u4e8c\u7ef4\u7801\u56fe\u50cf\u4e2d\uff0c\u5e76\u8bc4\u4f30\u591a\u79cd\u538b\u7f29\u7b56\u7565\u7684\u4f18\u52a3\u3002", "result": "\u6210\u529f\u5c06\u5173\u952e\u5386\u53f2\u4ee3\u7801\u538b\u7f29\u5230\u53ef\u626b\u63cf\u7684\u4e8c\u7ef4\u7801\u4e2d\uff0c\u5b9e\u73b0\u65e0\u9700\u4e13\u7528\u786c\u4ef6\u6216\u7f51\u7edc\u5373\u53ef\u8bbf\u95ee\uff0c\u517c\u5177\u53ef\u8bfb\u6027\u3001\u53ef\u4f20\u64ad\u6027\u548c\u4fdd\u5b58\u4ef7\u503c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5386\u53f2\u8f6f\u4ef6\u9057\u4ea7\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u8865\u5145\u6027\u4fdd\u5b58\u624b\u6bb5\uff0c\u517c\u987e\u4e86\u53ef\u8bbf\u95ee\u6027\u4e0e\u5386\u53f2\u610f\u4e49\uff0c\u62d3\u5c55\u4e86\u4f20\u7edf\u6863\u6848\u4fdd\u5b58\u6280\u672f\u5728\u79fb\u52a8\u8bbe\u5907\u65f6\u4ee3\u7684\u5e94\u7528\u3002"}}
{"id": "2506.11111", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11111", "abs": "https://arxiv.org/abs/2506.11111", "authors": ["Kun Zhang", "Le Wu", "Kui Yu", "Guangyi Lv", "Dacao Zhang"], "title": "Evaluating and Improving Robustness in Large Language Models: A Survey and Future Directions", "comment": "33 pages, 5 figures", "summary": "Large Language Models (LLMs) have gained enormous attention in recent years\ndue to their capability of understanding and generating natural languages. With\nthe rapid development and wild-range applications (e.g., Agents, Embodied\nIntelligence), the robustness of LLMs has received increased attention. As the\ncore brain of many AI applications, the robustness of LLMs requires that models\nshould not only generate consistent contents, but also ensure the correctness\nand stability of generated content when dealing with unexpeted application\nscenarios (e.g., toxic prompts, limited noise domain data, outof-distribution\n(OOD) applications, etc). In this survey paper, we conduct a thorough review of\nthe robustness of LLMs, aiming to provide a comprehensive terminology of\nconcepts and methods around this field and facilitate the community.\nSpecifically, we first give a formal definition of LLM robustness and present\nthe collection protocol of this survey paper. Then, based on the types of\nperturbated inputs, we organize this survey from the following perspectives: 1)\nAdversarial Robustness: tackling the problem that prompts are manipulated\nintentionally, such as noise prompts, long context, data attack, etc; 2) OOD\nRobustness: dealing with the unexpected real-world application scenarios, such\nas OOD detection, zero-shot transferring, hallucinations, etc; 3) Evaluation of\nRobustness: summarizing the new evaluation datasets, metrics, and tools for\nverifying the robustness of LLMs. After reviewing the representative work from\neach perspective, we discuss and highlight future opportunities and research\ndirections in this field. Meanwhile, we also organize related works and provide\nan easy-to-search project\n(https://github.com/zhangkunzk/Awesome-LLM-Robustness-papers) to support the\ncommunity.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u4ece\u5bf9\u6297\u9c81\u68d2\u6027\u3001\u5206\u5e03\u5916\u9c81\u68d2\u6027\u5230\u9c81\u68d2\u6027\u8bc4\u6d4b\u8fdb\u884c\u4e86\u5206\u7c7b\u68b3\u7406\uff0c\u5e76\u5bf9\u9886\u57df\u5185\u65b9\u6cd5\u548c\u672a\u6765\u673a\u4f1a\u8fdb\u884c\u4e86\u603b\u7ed3\uff0c\u9644\u5e26\u53ef\u68c0\u7d22\u8d44\u6599\u4ee5\u652f\u6301\u540e\u7eed\u7814\u7a76\u3002", "motivation": "\u8fd1\u5e74\u6765\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u56e0\u5176\u5f3a\u5927\u7684\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4e0e\u751f\u6210\u80fd\u529b\uff0c\u83b7\u5f97\u4e86\u5e7f\u6cdb\u5173\u6ce8\u3002\u968f\u7740\u5176\u5728\u667a\u80fd\u4f53\u3001\u5177\u8eab\u667a\u80fd\u7b49\u591a\u9886\u57df\u7684\u5e94\u7528\u5feb\u901f\u6269\u5c55\uff0c\u6a21\u578b\u7684\u9c81\u68d2\u6027\u95ee\u9898\u6108\u53d1\u7a81\u51fa\u3002\u7531\u4e8eLLMs\u4f5c\u4e3a\u8bb8\u591aAI\u5e94\u7528\u7684\u201c\u6838\u5fc3\u5927\u8111\u201d\uff0c\u5176\u9c81\u68d2\u6027\u4e0d\u4ec5\u9700\u8981\u4fdd\u8bc1\u751f\u6210\u5185\u5bb9\u7684\u4e00\u81f4\u6027\uff0c\u8fd8\u8981\u5728\u9762\u5bf9\u5f02\u5e38\u5e94\u7528\u573a\u666f\uff08\u5982\u6709\u5bb3\u63d0\u793a\u3001\u5e26\u566a\u57df\u6570\u636e\u3001\u5206\u5e03\u5916\u4efb\u52a1\u7b49\uff09\u65f6\u786e\u4fdd\u5185\u5bb9\u7684\u6b63\u786e\u6027\u4e0e\u7a33\u5b9a\u6027\u3002", "method": "\u672c\u6587\u4f5c\u4e3a\u7efc\u8ff0\u6027\u8bba\u6587\uff0c\u9996\u5148\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e86LLM\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u7ed9\u51fa\u4e86\u6587\u732e\u7b5b\u9009\u4e0e\u6536\u96c6\u6807\u51c6\u3002\u968f\u540e\uff0c\u4f5c\u8005\u4ece\u8f93\u5165\u6270\u52a8\u7c7b\u578b\u51fa\u53d1\uff0c\u5c06LLM\u9c81\u68d2\u6027\u5206\u4e3a\u4e09\u4e2a\u5173\u6ce8\u70b9\uff1a\uff081\uff09\u5bf9\u6297\u9c81\u68d2\u6027\uff1a\u9762\u5bf9\u6076\u610f\u64cd\u63a7\u7684\u8f93\u5165\u63d0\u793a\uff1b\uff082\uff09\u5206\u5e03\u5916\u9c81\u68d2\u6027\uff1a\u5e94\u5bf9\u73b0\u5b9e\u672a\u89c1\u8fc7\u7684\u60c5\u51b5\uff1b\uff083\uff09\u9c81\u68d2\u6027\u8bc4\u6d4b\uff1a\u603b\u7ed3\u65b0\u7684\u8bc4\u6d4b\u6570\u636e\u96c6\u3001\u6307\u6807\u548c\u5de5\u5177\u3002\u5bf9\u6bcf\u4e00\u7c7b\u522b\u7684\u4ee3\u8868\u6027\u65b9\u6cd5\u8fdb\u884c\u8be6\u7ec6\u56de\u987e\u548c\u8ba8\u8bba\uff0c\u540c\u65f6\u68b3\u7406\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "result": "\u672c\u6587\u5bf9LLM\u9c81\u68d2\u6027\u76f8\u5173\u65b9\u6cd5\u4e0e\u8bc4\u6d4b\u624b\u6bb5\u8fdb\u884c\u4e86\u7cfb\u7edf\u68b3\u7406\uff0c\u603b\u7ed3\u4e86\u5f53\u524d\u9886\u57df\u4e3b\u6d41\u95ee\u9898\u4e0e\u89e3\u51b3\u601d\u8def\uff0c\u4e3a\u5b66\u672f\u548c\u4ea7\u4e1a\u754c\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u77e5\u8bc6\u6846\u67b6\uff0c\u5e76\u6574\u7406\u4e86\u76f8\u5173\u8bba\u6587\u5217\u8868\uff0c\u4e3a\u793e\u533a\u68c0\u7d22\u548c\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u652f\u6491\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9c81\u68d2\u6027\u662f\u5176\u5728\u5e7f\u6cdb\u5e94\u7528\u4e2d\u9762\u4e34\u7684\u6838\u5fc3\u6311\u6218\u4e4b\u4e00\u3002\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\u5e76\u5212\u5206\u5bf9\u6297\u3001\u5206\u5e03\u5916\u7b49\u4e0d\u540c\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u660e\u786e\u4e86\u672a\u6765\u503c\u5f97\u5173\u6ce8\u7684\u7814\u7a76\u65b9\u5411\uff0c\u5e76\u4e3a\u9886\u57df\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u53ef\u68c0\u7d22\u7684\u5de5\u5177\u4e0e\u8d44\u6599\uff0c\u4fc3\u8fdb\u793e\u533a\u5408\u4f5c\u4e0e\u53d1\u5c55\u3002"}}
{"id": "2506.11009", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11009", "abs": "https://arxiv.org/abs/2506.11009", "authors": ["Jirat Pasuksmit", "Wannita Takerngsaksiri", "Patanamon Thongtanunam", "Chakkrit Tantithamthavorn", "Ruixiong Zhang", "Shiyan Wang", "Fan Jiang", "Jing Li", "Evan Cook", "Kun Chen", "Ming Wu"], "title": "Human-In-The-Loop Software Development Agents: Challenges and Future Directions", "comment": "The International Conference on Mining Software Repositories (MSR)\n  2025, Industry track", "summary": "Multi-agent LLM-driven systems for software development are rapidly gaining\ntraction, offering new opportunities to enhance productivity. At Atlassian, we\ndeployed Human-in-the-Loop Software Development Agents to resolve Jira work\nitems and evaluated the generated code quality using functional correctness\ntesting and GPT-based similarity scoring. This paper highlights two major\nchallenges: the high computational costs of unit testing and the variability in\nLLM-based evaluations. We also propose future research directions to improve\nevaluation frameworks for Human-In-The-Loop software development tools.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u591a\u4ee3\u7406LLM\u5728Atlassian\u771f\u5b9e\u73af\u5883\u4e2d\u8f85\u52a9\u8f6f\u4ef6\u5f00\u53d1\u7684\u53ef\u884c\u6027\u4e0e\u8bc4\u4f30\u6311\u6218\uff0c\u53d1\u73b0\u5355\u5143\u6d4b\u8bd5\u8017\u8d44\u6e90\u4e14LLM\u8bc4\u4f30\u6d6e\u52a8\u5927\uff0c\u5efa\u8bae\u4f18\u5316\u8bc4\u6d4b\u4f53\u7cfb\u4ee5\u652f\u6491\u9ad8\u6548\u53ef\u9760\u7684\u4f01\u4e1a\u7ea7\u5b9e\u8df5\u3002", "motivation": "\u591a\u4ee3\u7406\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u8f6f\u4ef6\u5f00\u53d1\u7cfb\u7edf\u6b63\u5728\u5feb\u901f\u53d1\u5c55\uff0c\u63d0\u9ad8\u4e86\u8f6f\u4ef6\u5f00\u53d1\u6548\u7387\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u5728\u5b9e\u9645\u4f01\u4e1a\u573a\u666f\u4e0b\uff08\u5982Atlassian\uff09\u90e8\u7f72\u8be5\u7c7b\u7cfb\u7edf\u7684\u6548\u679c\u53ca\u5176\u9762\u4e34\u7684\u6311\u6218\u3002", "method": "\u901a\u8fc7\u5728Atlassian\u4f7f\u7528Human-in-the-Loop\u8f6f\u4ef6\u5f00\u53d1\u4ee3\u7406\u89e3\u51b3Jira\u5de5\u5355\uff0c\u5e76\u91c7\u7528\u529f\u80fd\u6b63\u786e\u6027\u6d4b\u8bd5\u548c\u57fa\u4e8eGPT\u7684\u76f8\u4f3c\u6027\u8bc4\u5206\u6765\u8bc4\u4f30\u751f\u6210\u4ee3\u7801\u7684\u8d28\u91cf\u3002", "result": "\u6307\u51fa\u4e86\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a1\uff09\u5355\u5143\u6d4b\u8bd5\u7684\u9ad8\u8ba1\u7b97\u5f00\u9500\uff1b2\uff09LLM\u8bc4\u4f30\u7684\u6ce2\u52a8\u6027\u3002\u540c\u65f6\u63d0\u51fa\u6539\u8fdb\u4eba\u7c7b\u53c2\u4e0e\u7684\u8f6f\u4ef6\u5f00\u53d1\u5de5\u5177\u8bc4\u4f30\u6846\u67b6\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u73b0\u6709\u591a\u4ee3\u7406LLM\u7cfb\u7edf\u5728\u4f01\u4e1a\u5f00\u53d1\u4e2d\u7684\u5e94\u7528\u53ef\u884c\uff0c\u4f46\u8bc4\u4f30\u673a\u5236\u4e9f\u9700\u4f18\u5316\u3002\u63d0\u9ad8\u8bc4\u6d4b\u6548\u7387\u4e0e\u4e00\u81f4\u6027\u662f\u5173\u952e\u74f6\u9888\uff0c\u6539\u8fdb\u8bc4\u4f30\u6846\u67b6\u662f\u540e\u7eed\u91cd\u70b9\u3002"}}
{"id": "2506.11112", "categories": ["cs.CL", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2506.11112", "abs": "https://arxiv.org/abs/2506.11112", "authors": ["Christine Bauer", "Li Chen", "Nicola Ferro", "Norbert Fuhr", "Avishek Anand", "Timo Breuer", "Guglielmo Faggioli", "Ophir Frieder", "Hideo Joho", "Jussi Karlgren", "Johannes Kiesel", "Bart P. Knijnenburg", "Aldo Lipani", "Lien Michiels", "Andrea Papenmeier", "Maria Soledad Pera", "Mark Sanderson", "Scott Sanner", "Benno Stein", "Johanne R. Trippas", "Karin Verspoor", "Martijn C Willemsen"], "title": "Manifesto from Dagstuhl Perspectives Workshop 24352 -- Conversational Agents: A Framework for Evaluation (CAFE)", "comment": "43 pages; 10 figures; Dagstuhl manifesto", "summary": "During the workshop, we deeply discussed what CONversational Information\nACcess (CONIAC) is and its unique features, proposing a world model abstracting\nit, and defined the Conversational Agents Framework for Evaluation (CAFE) for\nthe evaluation of CONIAC systems, consisting of six major components: 1) goals\nof the system's stakeholders, 2) user tasks to be studied in the evaluation, 3)\naspects of the users carrying out the tasks, 4) evaluation criteria to be\nconsidered, 5) evaluation methodology to be applied, and 6) measures for the\nquantitative criteria chosen.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86CONIAC\u7cfb\u7edf\u7684\u7406\u8bba\u6a21\u578b\uff0c\u5e76\u5236\u5b9a\u4e86\u5305\u542b\u516d\u5927\u6838\u5fc3\u8981\u7d20\u7684\u7efc\u5408\u8bc4\u4f30\u6846\u67b6\uff08CAFE\uff09\uff0c\u4e3a\u8be5\u9886\u57df\u672a\u6765\u53d1\u5c55\u548c\u7cfb\u7edf\u8bc4\u4f30\u5efa\u7acb\u4e86\u6807\u51c6\u3002", "motivation": "\u968f\u7740\u5bf9\u8bdd\u5f0f\u4fe1\u606f\u83b7\u53d6\uff08CONIAC\uff09\u7cfb\u7edf\u7684\u4e0d\u65ad\u53d1\u5c55\uff0c\u6025\u9700\u6e05\u6670\u63cf\u8ff0\u5176\u672c\u8d28\u53ca\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u63a8\u52a8\u8be5\u9886\u57df\u7814\u7a76\u5e76\u5b9e\u73b0\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u672c\u7814\u7a76\u5728\u7814\u8ba8\u4f1a\u4e0a\u901a\u8fc7\u96c6\u4e2d\u8ba8\u8bba\u7684\u65b9\u5f0f\uff0c\u63d0\u51fa\u4e86CONIAC\u7684\u4e16\u754c\u6a21\u578b\u53ca\u5176\u62bd\u8c61\u7279\u5f81\uff0c\u5e76\u5b9a\u4e49\u4e86\u7528\u4e8eCONIAC\u7cfb\u7edf\u8bc4\u4f30\u7684\u4f1a\u8bdd\u4ee3\u7406\u6846\u67b6\uff08CAFE\uff09\uff0c\u6db5\u76d6\u516d\u5927\u6838\u5fc3\u7ec4\u6210\u90e8\u5206\u3002", "result": "\u6210\u529f\u63d0\u51fa\u4e86CAFE\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06CONIAC\u7cfb\u7edf\u8bc4\u4f30\u7ec6\u5206\u4e3a\uff1a\u5229\u76ca\u76f8\u5173\u8005\u76ee\u6807\u3001\u7528\u6237\u4efb\u52a1\u3001\u7528\u6237\u7279\u5f81\u3001\u8bc4\u4f30\u6807\u51c6\u3001\u8bc4\u4f30\u65b9\u6cd5\u548c\u91cf\u5316\u6307\u6807\u516d\u4e2a\u65b9\u9762\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u660e\u786e\u4e86CONIAC\u7684\u6982\u5ff5\u548c\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff0c\u4e3a\u672a\u6765\u5bf9\u8bdd\u5f0f\u4fe1\u606f\u83b7\u53d6\u7cfb\u7edf\u7684\u89c4\u8303\u8bc4\u4f30\u548c\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u652f\u6491\u3002"}}
{"id": "2506.11011", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11011", "abs": "https://arxiv.org/abs/2506.11011", "authors": ["Abhi Desai"], "title": "Enhancing Inventory Management with Progressive Web Applications (PWAs): A Scalable Solution for Small and Large Enterprises", "comment": null, "summary": "Efficient inventory management is crucial for both small and large\nenterprises to optimize operational workflows and reduce overhead costs. This\npaper explores the development and implementation of a Progressive Web\nApplication (PWA) designed to enhance the inventory management experience. The\napplication integrates key functionalities such as barcode and QR code\nscanning, geolocation-based warehouse identification, and cross-device\naccessibility. By leveraging PWA technology, the solution ensures offline\ncapabilities, responsive user experience, and seamless adaptability across\nvarious platforms. The study discusses the challenges and benefits of\nimplementing PWA in inventory management systems, including its limitations in\nperformance compared to native applications. Insights from the development\nprocess provide a roadmap for future developers looking to integrate PWA\ntechnology into enterprise applications. This research contributes to the\ngrowing domain of web-based inventory solutions, offering a scalable and\ncost-effective alternative to traditional inventory management software.", "AI": {"tldr": "\u672c\u6587\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u6b3e\u652f\u6301\u6761\u7801/\u4e8c\u7ef4\u7801\u626b\u63cf\u3001\u5730\u7406\u5b9a\u4f4d\u548c\u8de8\u8bbe\u5907\u8bbf\u95ee\u7684PWA\u5e93\u5b58\u7ba1\u7406\u7cfb\u7edf\uff0c\u5728\u4f53\u9a8c\u548c\u7ecf\u6d4e\u6027\u4e0a\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u6027\u80fd\u4e0a\u8fd8\u900a\u4e8e\u539f\u751f\u5e94\u7528\u3002", "motivation": "\u9ad8\u6548\u7684\u5e93\u5b58\u7ba1\u7406\u5bf9\u4e8e\u4f01\u4e1a\u6765\u8bf4\u975e\u5e38\u91cd\u8981\uff0c\u53ef\u4ee5\u4f18\u5316\u64cd\u4f5c\u6d41\u7a0b\u5e76\u51cf\u5c11\u6210\u672c\u3002\u5f53\u524d\u7684\u5e93\u5b58\u7ba1\u7406\u7cfb\u7edf\u5728\u5e73\u53f0\u517c\u5bb9\u6027\u548c\u5b9e\u65f6\u6027\u7b49\u65b9\u9762\u5b58\u5728\u4e00\u4e9b\u5c40\u9650\u6027\u3002", "method": "\u5f00\u53d1\u5e76\u5b9e\u73b0\u4e86\u4e00\u6b3e\u6e10\u8fdb\u5f0f\u7f51\u9875\u5e94\u7528\uff08PWA\uff09\uff0c\u96c6\u6210\u4e86\u6761\u7801/\u4e8c\u7ef4\u7801\u626b\u63cf\u3001\u57fa\u4e8e\u5730\u7406\u4f4d\u7f6e\u7684\u4ed3\u5e93\u8bc6\u522b\u4ee5\u53ca\u8de8\u8bbe\u5907\u8bbf\u95ee\u7b49\u529f\u80fd\uff0c\u5e76\u63a2\u8ba8\u5176\u5728\u5b9e\u9645\u5e93\u5b58\u7ba1\u7406\u4e2d\u7684\u5e94\u7528\u53ca\u9762\u4e34\u7684\u6311\u6218\u3002", "result": "\u8be5PWA\u65b9\u6848\u5b9e\u73b0\u4e86\u79bb\u7ebf\u529f\u80fd\u3001\u54cd\u5e94\u5f0f\u4f53\u9a8c\u4ee5\u53ca\u8de8\u5e73\u53f0\u9002\u914d\uff0c\u5c55\u73b0\u51fa\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6210\u672c\u6548\u76ca\uff0c\u4f46\u5728\u6027\u80fd\u4e0a\u4ecd\u4e0d\u53ca\u539f\u751f\u5e94\u7528\u3002", "conclusion": "PWA\u4e3a\u57fa\u4e8eWeb\u7684\u5e93\u5b58\u7ba1\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u62d3\u5c55\u3001\u7ecf\u6d4e\u578b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u672a\u6765\u5f00\u53d1\u8005\u96c6\u6210\u8be5\u6280\u672f\u63d0\u4f9b\u4e86\u5b9e\u8df5\u53c2\u8003\u8def\u7ebf\u56fe\u3002"}}
{"id": "2506.11113", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11113", "abs": "https://arxiv.org/abs/2506.11113", "authors": ["Tzu-Ling Lin", "Wei-Chih Chen", "Teng-Fang Hsiao", "Hou-I Liu", "Ya-Hsin Yeh", "Yu Kai Chan", "Wen-Sheng Lien", "Po-Yen Kuo", "Philip S. Yu", "Hong-Han Shuai"], "title": "Breaking the Reviewer: Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks", "comment": null, "summary": "Peer review is essential for maintaining academic quality, but the increasing\nvolume of submissions places a significant burden on reviewers. Large language\nmodels (LLMs) offer potential assistance in this process, yet their\nsusceptibility to textual adversarial attacks raises reliability concerns. This\npaper investigates the robustness of LLMs used as automated reviewers in the\npresence of such attacks. We focus on three key questions: (1) The\neffectiveness of LLMs in generating reviews compared to human reviewers. (2)\nThe impact of adversarial attacks on the reliability of LLM-generated reviews.\n(3) Challenges and potential mitigation strategies for LLM-based review. Our\nevaluation reveals significant vulnerabilities, as text manipulations can\ndistort LLM assessments. We offer a comprehensive evaluation of LLM performance\nin automated peer reviewing and analyze its robustness against adversarial\nattacks. Our findings emphasize the importance of addressing adversarial risks\nto ensure AI strengthens, rather than compromises, the integrity of scholarly\ncommunication.", "AI": {"tldr": "LLM\u53ef\u81ea\u52a8\u5316\u8bba\u6587\u8bc4\u5ba1\uff0c\u4f46\u5bb9\u6613\u88ab\u6587\u672c\u653b\u51fb\u5f71\u54cd\u5224\u65ad\uff0c\u5b58\u5728\u663e\u8457\u6f0f\u6d1e\uff0c\u9700\u91cd\u70b9\u9632\u62a4\u4ee5\u4fdd\u969c\u5b66\u672f\u516c\u6b63\u3002", "motivation": "\u968f\u7740\u5b66\u672f\u8bba\u6587\u63d0\u4ea4\u91cf\u66b4\u589e\uff0c\u8bc4\u5ba1\u4eba\u538b\u529b\u5de8\u5927\u3002\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u8f85\u52a9\u81ea\u52a8\u8bc4\u5ba1\uff0c\u4f46\u5176\u6613\u53d7\u6587\u672c\u5bf9\u6297\u653b\u51fb\u53ef\u80fd\u5f71\u54cd\u53ef\u9760\u6027\uff0c\u56e0\u6b64\u9700\u7814\u7a76\u8fd9\u79cd\u81ea\u52a8\u5316\u5de5\u5177\u7684\u7a33\u5065\u6027\u3002", "method": "\u8bc4\u4f30LLM\u5728\u81ea\u52a8\u5316\u540c\u884c\u8bc4\u5ba1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u5206\u6790\u5176\u5bf9\u6587\u672c\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u91cd\u70b9\u6bd4\u8f83\u4e0e\u4eba\u7c7b\u8bc4\u5ba1\u7684\u6709\u6548\u6027\uff0c\u6d4b\u8bd5\u5bf9\u6297\u6027\u653b\u51fb\u7684\u5f71\u54cd\uff0c\u5e76\u63a2\u8ba8\u5e94\u5bf9\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u663e\u793aLLM\u8bc4\u5ba1\u6613\u88ab\u6587\u672c\u64cd\u7eb5\u800c\u4e25\u91cd\u5931\u771f\uff0c\u5b58\u5728\u663e\u8457\u8106\u5f31\u6027\u3002\u8bba\u6587\u8be6\u7ec6\u8bc4\u4f30\u4e86LLM\u7684\u8868\u73b0\u53ca\u5176\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u5f31\u70b9\u3002\u63d0\u51fa\u5fc5\u987b\u89e3\u51b3\u5bf9\u6297\u6027\u98ce\u9669\uff0c\u4ee5\u7ef4\u62a4\u5b66\u672f\u4ea4\u6d41\u7684\u8bda\u5b9e\u6027\u3002", "conclusion": "LLM\u5728\u81ea\u52a8\u540c\u884c\u8bc4\u5ba1\u4e2d\u5b58\u5728\u663e\u8457\u7684\u5bf9\u6297\u6027\u8106\u5f31\u6027\uff0c\u5fc5\u987b\u91cd\u89c6\u5e76\u5e94\u5bf9\u8fd9\u4e9b\u98ce\u9669\uff0c\u4ee5\u786e\u4fddAI\u6709\u52a9\u4e8e\u5b66\u672f\u4ea4\u6d41\u7684\u516c\u6b63\u6027\u3002"}}
{"id": "2506.11013", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11013", "abs": "https://arxiv.org/abs/2506.11013", "authors": ["Filipe Fernandes", "Cl\u00e1udia Werner"], "title": "Toward a Brazilian Research Agenda in Quantum Software Engineering: A Systematic Mapping Study", "comment": "11 pages, 13 figures", "summary": "Context: Quantum Software Engineering (QSE) has emerged as a key field to\nsupport the development of reliable, maintainable, and scalable quantum\napplications, bridging advances in quantum computing with established practices\nin software engineering. Problem: Despite its growth, the field still suffers\nfrom fragmented knowledge, with a lack of standardized methodologies, tools,\nand guidelines tailored to the unique features of the quantum paradigm.\nAdditionally, countries like Brazil have had limited participation in the\ndevelopment of this emerging domain. Objective: This study aims to map the\nstate of the art in QSE by identifying current research trends, recurring\ncontributions, and existing gaps that can guide future investigations and\nstrategic initiatives. Methodology: A systematic mapping study was conducted\nanalyzing selected publications based on inclusion and exclusion criteria.\nArticles were categorized by study type, research type, and alignment with the\nSWEBOK knowledge areas. Results: Most of the reviewed studies are primary\nresearch articles written in English, with a strong focus on Software\nEngineering Models and Methods, Software Architecture, and Software Testing.\nConceptual proposals and technical solutions predominate, while empirical\nvalidations remain limited. Conclusions: Findings confirm that QSE is a\npromising but still maturing field. The standardization of practices, expansion\nof empirical studies, and inclusion of researchers from developing countries\nare crucial for advancing the discipline. Additionally, Brazilian contributions\nare still scarce, highlighting the urgent need to establish a national research\nagenda. As a main contribution, this study proposes a Brazilian Research Agenda\nin QSE, outlining priority areas and opportunities to foster a local scientific\ncommunity and accelerate progress in this emerging field.", "AI": {"tldr": "\u672c\u8bba\u6587\u7cfb\u7edf\u68b3\u7406\u4e86\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u73b0\u72b6\uff0c\u603b\u7ed3\u4e86\u7814\u7a76\u70ed\u70b9\u548c\u4e0d\u8db3\uff0c\u6307\u51fa\u5df4\u897f\u53ca\u53d1\u5c55\u4e2d\u56fd\u5bb6\u53c2\u4e0e\u5ea6\u4f4e\u3002\u4f5c\u8005\u547c\u5401\u6807\u51c6\u5316\u5b9e\u8df5\u548c\u52a0\u5f3a\u5b9e\u8bc1\u7814\u7a76\uff0c\u5e76\u63d0\u51fa\u4e86\u63a8\u52a8\u5df4\u897f\u672c\u5730\u53d1\u5c55\u7684\u7814\u7a76\u8bae\u7a0b\u3002", "motivation": "\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\uff08QSE\uff09\u867d\u7136\u4f5c\u4e3a\u8fde\u63a5\u91cf\u5b50\u8ba1\u7b97\u548c\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u7684\u91cd\u8981\u65b0\u5174\u9886\u57df\uff0c\u4f46\u76ee\u524d\u77e5\u8bc6\u5206\u6563\uff0c\u7f3a\u4e4f\u9762\u5411\u91cf\u5b50\u9886\u57df\u7279\u6027\u7684\u6807\u51c6\u65b9\u6cd5\u3001\u5de5\u5177\u548c\u6307\u5bfc\u65b9\u9488\uff1b\u5c24\u5176\u662f\u5df4\u897f\u7b49\u56fd\u5bb6\u5728\u8be5\u9886\u57df\u7684\u53c2\u4e0e\u5ea6\u6709\u9650\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u7cfb\u7edf\u6027\u6620\u5c04\u7814\u7a76\u65b9\u6cd5\uff0c\u4f9d\u636e\u7279\u5b9a\u7684\u7eb3\u5165\u548c\u6392\u9664\u6807\u51c6\u7b5b\u9009\u6587\u732e\uff0c\u5e76\u6839\u636e\u7814\u7a76\u7c7b\u578b\u3001\u6587\u7ae0\u7c7b\u578b\u4ee5\u53ca\u4e0eSWEBOK\u77e5\u8bc6\u9886\u57df\u7684\u5173\u8054\u6027\u5bf9\u5176\u5206\u7c7b\u5206\u6790\u3002", "result": "\u5206\u6790\u53d1\u73b0\uff0c\u5927\u591a\u6570\u6587\u732e\u4e3a\u82f1\u6587\u7684\u57fa\u7840\u6027\u7814\u7a76\uff0c\u5173\u6ce8\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u6a21\u578b\u4e0e\u65b9\u6cd5\u3001\u8f6f\u4ef6\u67b6\u6784\u53ca\u8f6f\u4ef6\u6d4b\u8bd5\u9886\u57df\u3002\u7814\u7a76\u591a\u4e3a\u6982\u5ff5\u6027\u65b9\u6848\u548c\u6280\u672f\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u8bc1\u7814\u7a76\u76f8\u5bf9\u8f83\u5c11\u3002\u6b64\u5916\uff0c\u5df4\u897f\u5728\u8be5\u9886\u57df\u7684\u5b66\u672f\u8d21\u732e\u4ecd\u7136\u7a00\u7f3a\u3002", "conclusion": "QSE\u662f\u4e00\u4e2a\u524d\u666f\u5e7f\u9614\u4f46\u5c1a\u4e0d\u6210\u719f\u7684\u9886\u57df\uff0c\u4e9f\u9700\u5b9e\u8df5\u89c4\u8303\u5316\u3001\u5b9e\u8bc1\u7814\u7a76\u6269\u5c55\u53ca\u53d1\u5c55\u4e2d\u56fd\u5bb6\uff08\u5982\u5df4\u897f\uff09\u79d1\u7814\u529b\u91cf\u7684\u4ecb\u5165\u3002\u4e3a\u4fc3\u8fdb\u672c\u9886\u57df\u53d1\u5c55\uff0c\u6587\u4e2d\u63d0\u51fa\u4e86\u5df4\u897fQSE\u7814\u7a76\u8bae\u7a0b\uff0c\u4ee5\u5f15\u5bfc\u4f18\u5148\u7814\u7a76\u65b9\u5411\u548c\u6fc0\u53d1\u672c\u5730\u79d1\u7814\u793e\u533a\u6d3b\u529b\u3002"}}
{"id": "2506.11114", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11114", "abs": "https://arxiv.org/abs/2506.11114", "authors": ["Junyu Liu", "Kaiqi Yan", "Tianyang Wang", "Qian Niu", "Momoko Nagai-Tanima", "Tomoki Aoyama"], "title": "KokushiMD-10: Benchmark for Evaluating Large Language Models on Ten Japanese National Healthcare Licensing Examinations", "comment": "9pages, 3 figures", "summary": "Recent advances in large language models (LLMs) have demonstrated notable\nperformance in medical licensing exams. However, comprehensive evaluation of\nLLMs across various healthcare roles, particularly in high-stakes clinical\nscenarios, remains a challenge. Existing benchmarks are typically text-based,\nEnglish-centric, and focus primarily on medicines, which limits their ability\nto assess broader healthcare knowledge and multimodal reasoning. To address\nthese gaps, we introduce KokushiMD-10, the first multimodal benchmark\nconstructed from ten Japanese national healthcare licensing exams. This\nbenchmark spans multiple fields, including Medicine, Dentistry, Nursing,\nPharmacy, and allied health professions. It contains over 11588 real exam\nquestions, incorporating clinical images and expert-annotated rationales to\nevaluate both textual and visual reasoning. We benchmark over 30\nstate-of-the-art LLMs, including GPT-4o, Claude 3.5, and Gemini, across both\ntext and image-based settings. Despite promising results, no model consistently\nmeets passing thresholds across domains, highlighting the ongoing challenges in\nmedical AI. KokushiMD-10 provides a comprehensive and linguistically grounded\nresource for evaluating and advancing reasoning-centric medical AI across\nmultilingual and multimodal clinical tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faKokushiMD-10\uff0c\u8fd9\u662f\u9996\u4e2a\u65e5\u672c\u56fd\u5bb6\u533b\u7597\u591a\u9886\u57df\u3001\u591a\u6a21\u6001\u57fa\u51c6\uff0c\u5305\u542b\u8d85\u8fc71.1\u4e07\u9053\u771f\u5b9e\u9898\u76ee\uff0c\u7528\u4e8e\u6d4b\u8bd5LLMs\u5728\u533b\u5b66\u76f8\u5173\u591a\u9886\u57df\u3001\u6587\u672c\u4e0e\u56fe\u7247\u7406\u89e3\u4e0a\u7684\u63a8\u7406\u80fd\u529b\u3002\u8d8530\u6b3e\u4e3b\u6d41\u5927\u6a21\u578b\u5728\u6b64\u57fa\u51c6\u4e0a\u8868\u73b0\u5206\u6790\u663e\u793a\uff0c\u6682\u65e0\u6a21\u578b\u80fd\u5168\u9762\u8fbe\u6807\uff0c\u51f8\u663e\u591a\u6a21\u6001\u533b\u7597AI\u5f53\u524d\u4ecd\u9762\u4e34\u6311\u6218\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u533b\u5b66\u6267\u7167\u8003\u8bd5\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u8986\u76d6\u591a\u79cd\u533b\u7597\u89d2\u8272\u3001\u7279\u522b\u662f\u9ad8\u98ce\u9669\u4e34\u5e8a\u573a\u666f\u7684\u5168\u9762\u8bc4\u6d4b\u5de5\u5177\u3002\u73b0\u6709\u57fa\u51c6\u591a\u4ee5\u82f1\u6587\u6587\u672c\u4e3a\u4e3b\uff0c\u4e14\u4e3b\u8981\u805a\u7126\u4e8e\u533b\u5b66\uff0c\u65e0\u6cd5\u6d4b\u8bd5\u66f4\u5e7f\u6cdb\u7684\u533b\u7597\u77e5\u8bc6\u53ca\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u65e8\u5728\u89e3\u51b3\u533b\u7597AI\u8bc4\u6d4b\u7684\u7ef4\u5ea6\u72ed\u7a84\u3001\u5730\u57df\u4e0e\u8bed\u8a00\u5c40\u9650\u7684\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u5e76\u6784\u5efa\u4e86KokushiMD-10\uff0c\u8fd9\u662f\u4e00\u9879\u57fa\u4e8e\u65e5\u672c\u5341\u79cd\u56fd\u5bb6\u533b\u7597\u8d44\u683c\u8003\u8bd5\u7684\u591a\u6a21\u6001\u57fa\u51c6\uff0c\u6db5\u76d6\u533b\u5b66\u3001\u7259\u79d1\u3001\u62a4\u7406\u3001\u836f\u5b66\u53ca\u76f8\u5173\u5065\u5eb7\u804c\u4e1a\u9886\u57df\uff0c\u5305\u542b\u8d85\u8fc711588\u9053\u771f\u5b9e\u8003\u9898\uff0c\u6d89\u53ca\u4e34\u5e8a\u56fe\u7247\u548c\u4e13\u5bb6\u6807\u6ce8\u7684\u63a8\u7406\u7406\u7531\uff0c\u7528\u4e8e\u8003\u5bdf\u6587\u672c\u4e0e\u89c6\u89c9\u63a8\u7406\u80fd\u529b\u3002\u5b9e\u9a8c\u4e2d\u4f7f\u7528\u4e8630\u591a\u79cd\u5f53\u524d\u6700\u5148\u8fdb\u7684LLMs\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u6587\u672c\u548c\u56fe\u50cf\u573a\u666f\u3002", "result": "\u6d4b\u8bd5\u7ed3\u679c\u663e\u793a\uff0c\u867d\u7136\u90e8\u5206\u6a21\u578b\u8868\u73b0\u8f83\u4e3a\u51fa\u8272\uff0c\u4f46\u6ca1\u6709\u4efb\u4f55\u5355\u4e00\u6a21\u578b\u80fd\u5728\u6240\u6709\u9886\u57df\u6301\u7eed\u8fbe\u5230\u53ca\u683c\u7ebf\u3002\u8fd9\u8bf4\u660e\u5f53\u524d\u533b\u7597AI\u5728\u591a\u9886\u57df\u3001\u9ad8\u96be\u5ea6\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u4ecd\u6709\u91cd\u5927\u6311\u6218\u3002", "conclusion": "KokushiMD-10\u4e3a\u533b\u7597AI\u591a\u8bed\u8a00\u3001\u591a\u6a21\u6001\u8bc4\u6d4b\u63d0\u4f9b\u4e86\u5168\u9762\u4e14\u6709\u5b9e\u9645\u57fa\u7840\u7684\u8d44\u6e90\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u4ee5\u63a8\u7406\u4e3a\u6838\u5fc3\u7684\u533b\u7597AI\u5728\u4e34\u5e8a\u573a\u666f\u4e2d\u7684\u53d1\u5c55\u548c\u5e94\u7528\u3002\u5b83\u4e5f\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u533b\u7597\u7efc\u5408\u80fd\u529b\u4e0a\u5b58\u5728\u7684\u4e0d\u8db3\u3002"}}
{"id": "2506.11014", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11014", "abs": "https://arxiv.org/abs/2506.11014", "authors": ["Benedetta Donato", "Leonardo Mariani", "Daniela Micucci", "Oliviero Riganelli", "Marco Somaschini"], "title": "MultiMind: A Plug-in for the Implementation of Development Tasks Aided by AI Assistants", "comment": null, "summary": "The integration of AI assistants into software development workflows is\nrapidly evolving, shifting from automation-assisted tasks to collaborative\ninteractions between developers and AI. Large Language Models (LLMs) have\ndemonstrated their effectiveness in several development activities, including\ncode completion, test case generation, and documentation production. However,\nembedding AI-assisted tasks within Integrated Development Environments (IDEs)\npresents significant challenges. It requires designing mechanisms to invoke AI\nassistants at the appropriate time, coordinate interactions with multiple\nassistants, process the generated outputs, and present feedback in a way that\nseamlessly integrates with the development workflow. To address these issues,\nwe introduce MultiMind, a Visual Studio Code plug-in that streamlines the\ncreation of AI-assisted development tasks. MultiMind provides a modular and\nextensible framework, enabling developers to cost-effectively implement and\nexperiment with new AI-powered interactions without the need for complex IDE\ncustomizations. MultiMind has been tested in two use cases: one for the\nautomatic generation of code comments and the other about the definition of\nAI-powered chat.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u6a21\u5757\u5316\u7684VS Code\u63d2\u4ef6MultiMind\uff0c\u5927\u5927\u7b80\u5316\u4e86AI\u52a9\u624b\u5728\u5f00\u53d1\u73af\u5883\u4e2d\u7684\u96c6\u6210\uff0c\u63d0\u5347\u4e86\u5f00\u53d1\u6548\u7387\u4e0eAI\u534f\u4f5c\u4f53\u9a8c\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0cAI\u52a9\u624b\u5728\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\u4e2d\u7684\u5e94\u7528\u8d8a\u6765\u8d8a\u5e7f\uff0c\u4ece\u7b80\u5355\u7684\u81ea\u52a8\u5316\u4efb\u52a1\u6269\u5c55\u5230\u4e0e\u5f00\u53d1\u8005\u7684\u534f\u4f5c\u3002\u7136\u800c\uff0c\u5c06AI\u52a9\u624b\u5d4c\u5165\u5230\u96c6\u6210\u5f00\u53d1\u73af\u5883\uff08IDE\uff09\u4f1a\u9047\u5230\u8c03\u7528\u65f6\u673a\u3001\u534f\u8c03\u591a\u52a9\u624b\u3001\u8f93\u51fa\u5904\u7406\u548c\u6d41\u7a0b\u65e0\u7f1d\u96c6\u6210\u7b49\u8bf8\u591a\u6311\u6218\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u96c6\u6210\u96be\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86MultiMind\u2014\u2014\u4e00\u4e2a\u57fa\u4e8eVisual Studio Code\u7684\u63d2\u4ef6\u3002\u8be5\u63d2\u4ef6\u91c7\u7528\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u65b9\u4fbf\u5f00\u53d1\u8005\u4ee5\u4f4e\u6210\u672c\u5b9e\u73b0\u548c\u6d4b\u8bd5\u65b0\u7684AI\u4ea4\u4e92\u65b9\u5f0f\uff0c\u65e0\u9700\u590d\u6742\u7684IDE\u5b9a\u5236\u3002", "result": "MultiMind\u5df2\u5728\u4e24\u4e2a\u573a\u666f\u4e0b\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff1a1\uff09\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u6ce8\u91ca\uff1b2\uff09\u57fa\u4e8eAI\u7684\u804a\u5929\u4ea4\u4e92\u5b9a\u4e49\u3002", "conclusion": "MultiMind\u63d2\u4ef6\u6709\u6548\u7b80\u5316\u5e76\u4fc3\u8fdb\u4e86AI\u52a9\u624b\u5728IDE\u4e2d\u7684\u96c6\u6210\uff0c\u53ef\u62d3\u5c55\u5230\u66f4\u591aAI\u8f85\u52a9\u5f00\u53d1\u4efb\u52a1\uff0c\u52a0\u901fAI\u4e0e\u5f00\u53d1\u6d41\u7a0b\u7684\u878d\u5408\u3002"}}
{"id": "2506.11115", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11115", "abs": "https://arxiv.org/abs/2506.11115", "authors": ["Yerim Oh", "Jun-Hyung Park", "Junho Kim", "SungHo Kim", "SangKeun Lee"], "title": "Incorporating Domain Knowledge into Materials Tokenization", "comment": null, "summary": "While language models are increasingly utilized in materials science, typical\nmodels rely on frequency-centric tokenization methods originally developed for\nnatural language processing. However, these methods frequently produce\nexcessive fragmentation and semantic loss, failing to maintain the structural\nand semantic integrity of material concepts. To address this issue, we propose\nMATTER, a novel tokenization approach that integrates material knowledge into\ntokenization. Based on MatDetector trained on our materials knowledge base and\na re-ranking method prioritizing material concepts in token merging, MATTER\nmaintains the structural integrity of identified material concepts and prevents\nfragmentation during tokenization, ensuring their semantic meaning remains\nintact. The experimental results demonstrate that MATTER outperforms existing\ntokenization methods, achieving an average performance gain of $4\\%$ and $2\\%$\nin the generation and classification tasks, respectively. These results\nunderscore the importance of domain knowledge for tokenization strategies in\nscientific text processing. Our code is available at\nhttps://github.com/yerimoh/MATTER", "AI": {"tldr": "\u5f15\u5165\u6750\u6599\u77e5\u8bc6\u7684MATTER\u5206\u8bcd\u65b9\u6cd5\u80fd\u66f4\u597d\u5730\u4fdd\u6301\u6750\u6599\u6982\u5ff5\u5b8c\u6574\u6027\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u751f\u6210\u4e0e\u5206\u7c7b\u4efb\u52a1\u4e0a\u6027\u80fd\u63d0\u5347\u660e\u663e\u3002", "motivation": "\u76ee\u524d\u6750\u6599\u79d1\u5b66\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u7684\u8bed\u8a00\u6a21\u578b\u4f9d\u8d56\u4e8e\u4e3a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5f00\u53d1\u7684\u57fa\u4e8e\u9891\u7387\u7684\u5206\u8bcd\u65b9\u6cd5\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5bb9\u6613\u5bfc\u81f4\u6750\u6599\u76f8\u5173\u6982\u5ff5\u7684\u788e\u7247\u5316\u548c\u8bed\u4e49\u635f\u5931\uff0c\u96be\u4ee5\u4fdd\u6301\u5176\u7ed3\u6784\u548c\u8bed\u4e49\u5b8c\u6574\u6027\u3002", "method": "\u63d0\u51faMATTER\u5206\u8bcd\u65b9\u6cd5\uff0c\u5c06\u6750\u6599\u9886\u57df\u77e5\u8bc6\u96c6\u6210\u5230\u5206\u8bcd\u8fc7\u7a0b\u4e2d\u3002\u5177\u4f53\u91c7\u7528\u4ee5\u6750\u6599\u77e5\u8bc6\u5e93\u8bad\u7ec3\u7684MatDetector\uff0c\u7ed3\u5408\u4f18\u5148\u4fdd\u7559\u6750\u6599\u6982\u5ff5\u7684\u5206\u8bcd\u5408\u5e76\u91cd\u6392\u5e8f\u65b9\u6cd5\uff0c\u4ece\u800c\u51cf\u5c11\u788e\u7247\u5316\u5e76\u4fdd\u6301\u6750\u6599\u6982\u5ff5\u7684\u8bed\u4e49\u548c\u7ed3\u6784\u5b8c\u6574\u3002", "result": "MATTER\u5728\u751f\u6210\u548c\u5206\u7c7b\u4efb\u52a1\u4e2d\u76f8\u8f83\u73b0\u6709\u5206\u8bcd\u65b9\u6cd5\u5206\u522b\u53d6\u5f97\u4e864%\u548c2%\u7684\u5e73\u5747\u6027\u80fd\u63d0\u5347\u3002\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u5c06\u9886\u57df\u77e5\u8bc6\u5f15\u5165\u79d1\u5b66\u6587\u672c\u5206\u8bcd\u7b56\u7565\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u5c06\u6750\u6599\u77e5\u8bc6\u878d\u5165\u5206\u8bcd\u8fc7\u7a0b\u80fd\u591f\u6709\u6548\u63d0\u5347\u6750\u6599\u79d1\u5b66\u9886\u57df\u7684\u8bed\u8a00\u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u6709\u52a9\u4e8e\u4fdd\u6301\u6750\u6599\u6982\u5ff5\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u5b8c\u6574\u3002"}}
{"id": "2506.11016", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11016", "abs": "https://arxiv.org/abs/2506.11016", "authors": ["Lelanthran Manickum"], "title": "ZjsComponent: A Pragmatic Approach to Modular, Reusable UI Fragments for Web Development", "comment": "12 pages, 7 figures", "summary": "In this paper, I present ZjsComponent, a lightweight and framework-agnostic\nweb component designed for creating modular, reusable UI elements with minimal\ndeveloper overhead. ZjsComponent is an example implementation of an approach to\ncreating components and object instances that can be used purely from HTML.\nUnlike traditional approaches to components, the approach implemented by\nZjsComponent does not require build-steps, transpiling, pre-compilation, any\nspecific ecosystem or any other dependency. All that is required is that the\nbrowser can load and execute Javascript as needed by Web Components.\nZjsComponent allows dynamic loading and isolation of HTML+JS fragments,\noffering developers a simple way to build reusable interfaces with ease. This\napproach is dependency-free, provides significant DOM and code isolation, and\nsupports simple lifecycle hooks as well as traditional methods expected of an\ninstance of a class.", "AI": {"tldr": "ZjsComponent\u662f\u4e00\u79cd\u65e0\u9700\u4f9d\u8d56\u6784\u5efa\u3001\u7b80\u5355\u6613\u7528\u7684Web\u7ec4\u4ef6\u65b9\u6848\uff0c\u964d\u4f4e\u5f00\u53d1\u5de5\u4f5c\u91cf\uff0c\u63d0\u9ad8\u7ec4\u4ef6\u590d\u7528\u6027\u548c\u9694\u79bb\u6027\u3002", "motivation": "\u5f53\u524dWeb\u7ec4\u4ef6\u5f00\u53d1\u901a\u5e38\u4f9d\u8d56\u7e41\u6742\u7684\u6784\u5efa\u5de5\u5177\u3001\u7279\u5b9a\u6846\u67b6\u6216\u751f\u6001\u7cfb\u7edf\uff0c\u589e\u52a0\u4e86\u5f00\u53d1\u590d\u6742\u5ea6\u4e0e\u95e8\u69db\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u7b80\u5355\u3001\u65e0\u4f9d\u8d56\u4e14\u6613\u4e8e\u4e0a\u624b\u7684\u7ec4\u4ef6\u5316\u65b9\u6848\u3002", "method": "\u63d0\u51faZjsComponent\uff0c\u4e00\u79cd\u8f7b\u91cf\u4e14\u4e0e\u6846\u67b6\u65e0\u5173\u7684Web\u7ec4\u4ef6\u5b9e\u73b0\u3002\u65e0\u9700\u6784\u5efa\u3001\u8f6c\u8bd1\u6216\u9884\u7f16\u8bd1\uff0c\u4ec5\u4f9d\u8d56\u6d4f\u89c8\u5668\u539f\u751f\u652f\u6301\u7684JavaScript\u548cWeb\u7ec4\u4ef6\u3002\u5b9e\u73b0\u4e86HTML+JS\u7247\u6bb5\u7684\u52a8\u6001\u52a0\u8f7d\u548c\u9694\u79bb\uff0c\u5e76\u63d0\u4f9b\u751f\u547d\u5468\u671f\u94a9\u5b50\u3002", "result": "ZjsComponent\u5b9e\u73b0\u4e86\u65e0\u9700\u4f9d\u8d56\u7684\u53ef\u590d\u7528UI\u7ec4\u4ef6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u4ee3\u7801\u8026\u5408\u548cDOM\u9694\u79bb\u6027\u8981\u6c42\uff0c\u5b9e\u73b0\u4e86\u7b80\u5355\u751f\u547d\u5468\u671f\u63a7\u5236\u548c\u4f20\u7edf\u5b9e\u4f8b\u65b9\u6cd5\u652f\u6301\u3002", "conclusion": "ZjsComponent\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u4f9d\u8d56\u6784\u5efa\u5de5\u5177\u7684\u8f7b\u91cf\u7ec4\u4ef6\u65b9\u6848\uff0c\u6613\u4e8e\u521b\u5efa\u9694\u79bb\u6027\u5f3a\u3001\u53ef\u590d\u7528\u7684Web UI\u7ec4\u4ef6\uff0c\u964d\u4f4e\u4e86\u5f00\u53d1\u95e8\u69db\u548c\u590d\u6742\u5ea6\u3002"}}
{"id": "2506.11116", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11116", "abs": "https://arxiv.org/abs/2506.11116", "authors": ["Jijie Li", "Li Du", "Hanyu Zhao", "Bo-wen Zhang", "Liangdong Wang", "Boyan Gao", "Guang Liu", "Yonghua Lin"], "title": "Infinity Instruct: Scaling Instruction Selection and Synthesis to Enhance Language Models", "comment": null, "summary": "Large Language Models (LLMs) demonstrate strong performance in real-world\napplications, yet existing open-source instruction datasets often concentrate\non narrow domains, such as mathematics or coding, limiting generalization and\nwidening the gap with proprietary models. To bridge this gap, we introduce\nInfinity-Instruct, a high-quality instruction dataset designed to enhance both\nfoundational and chat capabilities of LLMs through a two-phase pipeline. In\nPhase 1, we curate 7.4M high-quality foundational instructions\n(InfInstruct-F-7.4M) from over 100M samples using hybrid data selection\ntechniques. In Phase 2, we synthesize 1.5M high-quality chat instructions\n(InfInstruct-G-1.5M) through a two-stage process involving instruction\nselection, evolution, and diagnostic filtering. We empirically evaluate\nInfinity-Instruct by fine-tuning several open-source models, including Mistral,\nLLaMA, Qwen, and Yi, and observe substantial performance gains across both\nfoundational and instruction following benchmarks, consistently surpassing\nofficial instruction-tuned counterparts. Notably, InfInstruct-LLaMA3.1-70B\noutperforms GPT-4-0314 by 8.6\\% on instruction following tasks while achieving\ncomparable foundational performance. These results underscore the synergy\nbetween foundational and chat training and offer new insights into holistic LLM\ndevelopment. Our\ndataset\\footnote{https://huggingface.co/datasets/BAAI/Infinity-Instruct} and\ncodes\\footnote{https://gitee.com/li-touch/infinity-instruct} have been publicly\nreleased.", "AI": {"tldr": "\u672c\u6587\u63a8\u51fa\u4e86\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u7684\u6307\u4ee4\u6570\u636e\u96c6Infinity-Instruct\uff0c\u5e76\u901a\u8fc7\u4e24\u9636\u6bb5\u6d41\u7a0b\u5206\u522b\u6784\u5efa\u57fa\u7840\u4e0e\u5bf9\u8bdd\u6307\u4ee4\u96c6\u3002\u591a\u6a21\u578b\u5fae\u8c03\u5b9e\u9a8c\u8bc1\u660e\u6570\u636e\u96c6\u5927\u5e45\u63d0\u5347\u4e86\u6a21\u578b\u80fd\u529b\uff0c\u90e8\u5206\u6a21\u578b\u7ed3\u679c\u8d85\u8fc7GPT-4\u3002\u6570\u636e\u96c6\u4e0e\u4ee3\u7801\u5df2\u5f00\u6e90\uff0c\u6709\u671b\u63a8\u52a8\u5f00\u6e90\u5927\u6a21\u578b\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u5f00\u6e90\u6307\u4ee4\u6570\u636e\u96c6\u9886\u57df\u8f83\u7a84\uff0c\u5982\u6570\u5b66\u6216\u7f16\u7a0b\uff0c\u5bfc\u81f4\u5927\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u4e0e\u95ed\u6e90\u6a21\u578b\u6709\u8f83\u5927\u5dee\u8ddd\u3002\u8be5\u6587\u65e8\u5728\u901a\u8fc7\u9ad8\u8d28\u91cf\u3001\u5e7f\u8986\u76d6\u7684\u6570\u636e\u96c6\u63d0\u5347\u5927\u6a21\u578b\u57fa\u7840\u80fd\u529b\u548c\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86Infinity-Instruct\u6570\u636e\u96c6\uff0c\u5206\u4e24\u9636\u6bb5\u6784\u5efa\uff1a\u7b2c\u4e00\u9636\u6bb5\u5229\u7528\u6df7\u5408\u6570\u636e\u9009\u62e9\u6280\u672f\u4ece1\u4ebf\u6837\u672c\u4e2d\u7b5b\u9009\u51fa740\u4e07\u6761\u9ad8\u8d28\u91cf\u57fa\u7840\u6307\u4ee4\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u6307\u4ee4\u9009\u62e9\u3001\u8fdb\u5316\u548c\u8bca\u65ad\u8fc7\u6ee4\uff0c\u5408\u6210150\u4e07\u6761\u9ad8\u8d28\u91cf\u5bf9\u8bdd\u6307\u4ee4\u3002\u5e76\u5728\u591a\u79cd\u5f00\u6e90\u5927\u6a21\u578b\u4e0a\u5fae\u8c03\u9a8c\u8bc1\u6548\u679c\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\uff08\u5982Mistral, LLaMA, Qwen, Yi\uff09\u4e0a\u5fae\u8c03\u540e\uff0c\u6a21\u578b\u5728\u57fa\u7840\u80fd\u529b\u53ca\u6307\u4ee4\u9075\u5faa\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5927\u5e45\u63d0\u5347\uff0c\u8d85\u8fc7\u540c\u7c7b\u5b98\u65b9\u5fae\u8c03\u6a21\u578b\u3002\u5176\u4e2dInfInstruct-LLaMA3.1-70B\u5728\u6307\u4ee4\u9075\u5faa\u4efb\u52a1\u4e0a\u6bd4GPT-4-0314\u9ad88.6%\uff0c\u57fa\u7840\u80fd\u529b\u4e5f\u76f8\u5f53\u3002", "conclusion": "\u9ad8\u8d28\u91cf\u3001\u6db5\u76d6\u5e7f\u6cdb\u7684\u6307\u4ee4\u6570\u636e\u96c6\u80fd\u663e\u8457\u63d0\u5347\u5f00\u6e90\u5927\u6a21\u578b\u5404\u7c7b\u80fd\u529b\uff0c\u8054\u5408\u57fa\u7840\u4e0e\u5bf9\u8bdd\u8bad\u7ec3\u662f\u672a\u6765LLM\u53d1\u5c55\u7684\u6709\u6548\u65b9\u5411\uff0c\u6570\u636e\u548c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.11018", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11018", "abs": "https://arxiv.org/abs/2506.11018", "authors": ["Grigory Tsiperman"], "title": "Formation of requirements traceability in the process of information systems design", "comment": "12 pages, 4 figures, 2025 the 8th International Conference on\n  Information Management", "summary": "The traceability of requirements in the information system design process is\nconsidered an essential property of the project, one of its quality\ncharacteristics. The point here is that traceability provides the methods of\nvalidation and verification of software systems, and that the system model\nbased on requirements traceability reduces the system's dependence on\ndevelopers and, in general, makes it as straightforward as possible. One of the\nchallenges of the traceability process, dubbed \"The grand challenge of\ntraceability\" among traceability researchers, is its integration into the\ndesign process. In this paper, to achieve this goal, we propose the application\nof the Adaptive Clustering Method (ACM) of Information Systems developed by the\nauthor, which is based on the idea of a seamless system architecture that\nprovides explicit interconnection of project artifacts of different levels of\nabstraction.", "AI": {"tldr": "\u672c\u8bba\u6587\u9488\u5bf9\u9700\u6c42\u53ef\u8ffd\u6eaf\u6027\u5728\u4fe1\u606f\u7cfb\u7edf\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u7684\u96c6\u6210\u96be\u9898\uff0c\u63d0\u51fa\u4e86\u65e0\u7f1d\u67b6\u6784\u4e0b\u81ea\u9002\u5e94\u805a\u7c7b\u65b9\u6cd5\uff08ACM\uff09\uff0c\u4ee5\u5b9e\u73b0\u9700\u6c42\u8ffd\u6eaf\u3001\u7b80\u5316\u5f00\u53d1\u4f9d\u8d56\u3001\u63d0\u5347\u8d28\u91cf\u3002", "motivation": "\u9700\u6c42\u53ef\u8ffd\u6eaf\u6027\u5bf9\u4e8e\u4fe1\u606f\u7cfb\u7edf\u8bbe\u8ba1\u8fc7\u7a0b\u81f3\u5173\u91cd\u8981\uff0c\u53ef\u4ee5\u63d0\u5347\u7cfb\u7edf\u7684\u9a8c\u8bc1\u548c\u786e\u8ba4\u80fd\u529b\u3002\u7136\u800c\uff0c\u53ef\u8ffd\u6eaf\u6027\u7684\u96c6\u6210\u5728\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u7684\u5b9e\u73b0\u662f\u4e00\u4e2a\u4e3b\u8981\u6311\u6218\uff0c\u88ab\u79f0\u4e3a\u201c\u53ef\u8ffd\u6eaf\u6027\u7684\u91cd\u5927\u6311\u6218\u201d\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u5e94\u7528\u81ea\u9002\u5e94\u805a\u7c7b\u65b9\u6cd5\uff08ACM\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u65e0\u7f1d\u7cfb\u7edf\u67b6\u6784\u7684\u6280\u672f\uff0c\u80fd\u660e\u786e\u8fde\u63a5\u4e0d\u540c\u62bd\u8c61\u5c42\u7ea7\u7684\u9879\u76ee\u5de5\u4ef6\u3002", "result": "\u901a\u8fc7ACM\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5b9e\u73b0\u4fe1\u606f\u7cfb\u7edf\u4e2d\u4e0d\u540c\u5c42\u7ea7\u5de5\u4ef6\u7684\u663e\u5f0f\u4e92\u8054\uff0c\u4ece\u800c\u652f\u6301\u9700\u6c42\u7684\u6709\u6548\u8ffd\u6eaf\u3002", "conclusion": "\u91c7\u7528\u57fa\u4e8e\u81ea\u9002\u5e94\u805a\u7c7b\u65b9\u6cd5\u7684\u7cfb\u7edf\u5efa\u6a21\uff0c\u53ef\u4ee5\u51cf\u5c11\u7cfb\u7edf\u5bf9\u5f00\u53d1\u8005\u7684\u4f9d\u8d56\uff0c\u4f7f\u8bbe\u8ba1\u8fc7\u7a0b\u66f4\u76f4\u63a5\uff0c\u5e76\u63d0\u5347\u7cfb\u7edf\u9a8c\u8bc1\u4e0e\u786e\u8ba4\u7684\u80fd\u529b\u3002"}}
{"id": "2506.11117", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2506.11117", "abs": "https://arxiv.org/abs/2506.11117", "authors": ["Junyong Lin", "Lu Dai", "Ruiqian Han", "Yijie Sui", "Ruilin Wang", "Xingliang Sun", "Qinglin Wu", "Min Feng", "Hao Liu", "Hui Xiong"], "title": "ScIRGen: Synthesize Realistic and Large-Scale RAG Dataset for Scientific Research", "comment": "KDD 2025 Accepted", "summary": "Scientific researchers need intensive information about datasets to\neffectively evaluate and develop theories and methodologies. The information\nneeds regarding datasets are implicitly embedded in particular research tasks,\nrather than explicitly expressed in search queries. However, existing\nscientific retrieval and question-answering (QA) datasets typically address\nstraightforward questions, which do not align with the distribution of\nreal-world research inquiries. To bridge this gap, we developed ScIRGen, a\ndataset generation framework for scientific QA \\& retrieval that more\naccurately reflects the information needs of professional science researchers,\nand uses it to create a large-scale scientific retrieval-augmented generation\n(RAG) dataset with realistic queries, datasets and papers. Technically, we\ndesigned a dataset-oriented information extraction method that leverages\nacademic papers to augment the dataset representation. We then proposed a\nquestion generation framework by employing cognitive taxonomy to ensure the\nquality of synthesized questions. We also design a method to automatically\nfilter synthetic answers based on the perplexity shift of LLMs, which is highly\naligned with human judgment of answers' validity. Collectively, these\nmethodologies culminated in the creation of the 61k QA dataset, ScIRGen-Geo. We\nbenchmarked representative methods on the ScIRGen-Geo dataset for their\nquestion-answering and retrieval capabilities, finding out that current methods\nstill suffer from reasoning from complex questions. This work advances the\ndevelopment of more sophisticated tools to support the intricate information\nneeds of the scientific community.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86ScIRGen\u6846\u67b6\uff0c\u5b9e\u73b0\u5927\u89c4\u6a21\u3001\u590d\u6742\u4e14\u7b26\u5408\u79d1\u7814\u9700\u6c42\u7684\u95ee\u7b54\u6570\u636e\u96c6\u81ea\u52a8\u6784\u5efa\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79d1\u5b66\u95ee\u7b54\u548c\u68c0\u7d22\u8bc4\u6d4b\u7684\u771f\u5b9e\u6027\u548c\u6311\u6218\u6027\uff0c\u5e76\u4fc3\u8fdb\u76f8\u5173\u65b9\u6cd5\u7814\u7a76\u3002", "motivation": "\u76ee\u524d\u79d1\u5b66\u754c\u5728\u8bc4\u4f30\u4e0e\u5f00\u53d1\u7406\u8bba\u548c\u65b9\u6cd5\u65f6\u9700\u8981\u5927\u91cf\u4e0e\u6570\u636e\u96c6\u76f8\u5173\u7684\u7ec6\u81f4\u4fe1\u606f\uff0c\u4f46\u73b0\u6709\u7684\u79d1\u5b66\u68c0\u7d22\u4e0e\u95ee\u7b54\u6570\u636e\u96c6\u53ea\u6d89\u53ca\u7b80\u5355\u95ee\u9898\uff0c\u65e0\u6cd5\u5339\u914d\u73b0\u5b9e\u7814\u7a76\u4e2d\u7684\u590d\u6742\u9700\u6c42\u3002\u4e3a\u6b64\uff0c\u4f5c\u8005\u5e0c\u671b\u63d0\u5347\u6570\u636e\u96c6\u7684\u5b9e\u7528\u6027\u4e0e\u771f\u5b9e\u6027\uff0c\u4ee5\u66f4\u597d\u670d\u52a1\u79d1\u7814\u573a\u666f\u4e0b\u7684\u67e5\u8be2\u3002", "method": "\u63d0\u51faScIRGen\u6846\u67b6\u5b9e\u73b0\u79d1\u5b66\u95ee\u7b54\u4e0e\u68c0\u7d22\u6570\u636e\u96c6\u81ea\u52a8\u751f\u6210\u3002\u65b9\u6cd5\u4e0a\uff0c\u91c7\u7528\u9762\u5411\u6570\u636e\u96c6\u7684\u4fe1\u606f\u62bd\u53d6\u65b9\u6cd5\u6269\u5c55\u6570\u636e\u96c6\u8868\u793a\uff0c\u901a\u8fc7\u57fa\u4e8e\u8ba4\u77e5\u5206\u7c7b\u6cd5\u7684\u6846\u67b6\u751f\u6210\u9ad8\u8d28\u91cf\u95ee\u9898\uff0c\u5e76\u5229\u7528\u5927\u6a21\u578b\u56f0\u60d1\u5ea6\u53d8\u5316\u81ea\u52a8\u7b5b\u9009\u5408\u6210\u7b54\u6848\u3002\u6700\u7ec8\u5f97\u5230\u8d856\u4e07\u89c4\u6a21\u7684\u79d1\u7814\u95ee\u7b54\u6570\u636e\u96c6ScIRGen-Geo\uff0c\u5e76\u7528\u5176\u5bf9\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u8be5\u65b9\u6cd5\u6784\u5efa\u4e86\u5305\u542b6.1\u4e07\u6761\u9ad8\u8d28\u91cfQA\u7684ScIRGen-Geo\u6570\u636e\u96c6\u3002\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0c\u73b0\u6709QA\u4e0e\u68c0\u7d22\u6280\u672f\u5728\u5904\u7406\u590d\u6742\u63a8\u7406\u95ee\u9898\u65f6\u8868\u73b0\u6709\u9650\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u7684\u751f\u6210\u6846\u67b6\u80fd\u66f4\u597d\u6a21\u62df\u79d1\u7814\u4e2d\u7684\u5b9e\u9645\u4fe1\u606f\u9700\u6c42\uff0c\u901a\u8fc7\u9ad8\u8d28\u91cf\u65b0\u6570\u636e\u96c6\u4fc3\u8fdb\u590d\u6742\u79d1\u5b66\u95ee\u7b54\u4e0e\u68c0\u7d22\u65b9\u6cd5\u7684\u8fdb\u6b65\uff0c\u4e3a\u652f\u6301\u79d1\u5b66\u7814\u7a76\u7684\u590d\u6742\u4fe1\u606f\u68c0\u7d22\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2506.11019", "categories": ["cs.SE", "68T01, 68N30", "I.2.6; D.2.7"], "pdf": "https://arxiv.org/pdf/2506.11019", "abs": "https://arxiv.org/abs/2506.11019", "authors": ["Vincent Koc", "Jacques Verre", "Douglas Blank", "Abigail Morgan"], "title": "Mind the Metrics: Patterns for Telemetry-Aware In-IDE AI Application Development using the Model Context Protocol (MCP)", "comment": "16 pages, 5 figures, conference preprint submission. Conceptual\n  systems architecture paper on telemetry-driven prompt optimization and IDE\n  design patterns for AI development. Builds on Opik MCP open-source\n  architecture and Comet trace infrastructure", "summary": "AI development environments are evolving into observability first platforms\nthat integrate real time telemetry, prompt traces, and evaluation feedback into\nthe developer workflow. This paper introduces telemetry aware integrated\ndevelopment environments (IDEs) enabled by the Model Context Protocol (MCP), a\nsystem that connects IDEs with prompt metrics, trace logs, and versioned\ncontrol for real time refinement. We present design patterns for local prompt\niteration, CI based optimization, and autonomous agents that adapt behavior\nusing telemetry. Rather than focusing on a single algorithm, we describe an\narchitecture that supports integration with frameworks like DSPy, PromptWizard,\nand Prompts as Programs. We demonstrate this through Opik, an open source MCP\nserver for LLM telemetry, and position our approach within the emerging LLMOps\necosystem. This work lays a foundation for future research on prompt\noptimization, IDE agent tooling, and empirical benchmarking in telemetry rich\nAI development workflows.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u501f\u52a9MCP\u534f\u8bae\u7684\u9065\u6d4b\u611f\u77e5IDE\u67b6\u6784\uff0c\u5c06\u9065\u6d4b\u6570\u636e\u3001\u63d0\u793a\u8ffd\u8e2a\u548c\u8bc4\u4f30\u53cd\u9988\u5b9e\u65f6\u5f15\u5165AI\u5f00\u53d1\u6d41\u7a0b\uff0c\u5e76\u4ee5Opik\u4e3a\u4f8b\u8bf4\u660e\u5176\u5bf9AI\u5f00\u53d1\u8fd0\u7ef4\u548c\u4f18\u5316\u7684\u63a8\u52a8\u4f5c\u7528\uff0c\u4fc3\u8fdb\u4e86LLMOps\u3001\u63d0\u793a\u5de5\u7a0b\u7b49\u9886\u57df\u7684\u53d1\u5c55\u3002", "motivation": "\u968f\u7740AI\u4e0e\u5927\u6a21\u578b\u5f00\u53d1\u7684\u590d\u6742\u5ea6\u63d0\u5347\uff0c\u5f00\u53d1\u8005\u65e5\u76ca\u5173\u6ce8\u5982\u4f55\u5728\u5f00\u53d1\u6d41\u7a0b\u4e2d\u5b9e\u65f6\u83b7\u53d6\u6a21\u578b\u7684\u8fd0\u884c\u6570\u636e\uff08telemetry\uff09\u3001\u63d0\u793a\u8bcd\u8ffd\u8e2a\u4ee5\u53ca\u8bc4\u4f30\u53cd\u9988\uff0c\u4ee5\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u8fed\u4ee3\u4e0e\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eModel Context Protocol\uff08MCP\uff09\u7684\u9065\u6d4b\u611f\u77e5\u4e00\u4f53\u5316\u5f00\u53d1\u73af\u5883\uff08IDE\uff09\u67b6\u6784\uff0c\u5e76\u901a\u8fc7\u5f00\u6e90\u7684Opik MCP\u670d\u52a1\u5668\u5c55\u793a\u4e86\u8fd9\u79cd\u67b6\u6784\u5982\u4f55\u8fde\u63a5IDE\u4e0e\u5404\u79cd\u9065\u6d4b\u6570\u636e\uff0c\u5305\u62ec\u63d0\u793a\u6307\u6807\u3001\u8ffd\u8e2a\u65e5\u5fd7\u548c\u7248\u672c\u63a7\u5236\u3002", "result": "\u8be5\u4f53\u7cfb\u7ed3\u6784\u652f\u6301\u96c6\u6210\u591a\u79cd\u6846\u67b6\uff08\u5982DSPy\u3001PromptWizard\u548cPrompts as Programs\uff09\uff0c\u80fd\u591f\u5b9e\u73b0\u672c\u5730\u63d0\u793a\u8fed\u4ee3\u3001\u6301\u7eed\u96c6\u6210\uff08CI\uff09\u4f18\u5316\u53ca\u57fa\u4e8e\u9065\u6d4b\u7684\u81ea\u9002\u5e94\u667a\u80fd\u4ee3\u7406\u3002Opik\u4f5c\u4e3aMCP\u5b9e\u73b0\u5c55\u793a\u4e86\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "MCP\u589e\u5f3a\u7684\u9065\u6d4b\u611f\u77e5IDE\u4e3aAI\u5f00\u53d1\u6d41\u7a0b\u5e26\u6765\u4e86\u66f4\u5f3a\u7684\u900f\u660e\u5ea6\u4e0e\u53ef\u89c2\u6d4b\u6027\uff0c\u4fc3\u8fdb\u4e86\u63d0\u793a\u8bcd\u4f18\u5316\u3001\u5f00\u53d1\u5de5\u5177\u667a\u80fd\u5316\u548c\u57fa\u51c6\u6d4b\u8bd5\u7b49\u65b9\u5411\uff0c\u4e3a\u9065\u6d4b\u4e30\u5bcc\u7684AI\u5f00\u53d1\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.11119", "categories": ["cs.CL", "cs.SD", "eess.AS", "68T10 (Primary), 68U99 (Secondary)", "I.2.1; J.3"], "pdf": "https://arxiv.org/pdf/2506.11119", "abs": "https://arxiv.org/abs/2506.11119", "authors": ["Jingyu Li", "Lingchao Mao", "Hairong Wang", "Zhendong Wang", "Xi Mao", "Xuelei Sherry Ni"], "title": "Benchmarking Foundation Speech and Language Models for Alzheimer's Disease and Related Dementia Detection from Spontaneous Speech", "comment": null, "summary": "Background: Alzheimer's disease and related dementias (ADRD) are progressive\nneurodegenerative conditions where early detection is vital for timely\nintervention and care. Spontaneous speech contains rich acoustic and linguistic\nmarkers that may serve as non-invasive biomarkers for cognitive decline.\nFoundation models, pre-trained on large-scale audio or text data, produce\nhigh-dimensional embeddings encoding contextual and acoustic features.\n  Methods: We used the PREPARE Challenge dataset, which includes audio\nrecordings from over 1,600 participants with three cognitive statuses: healthy\ncontrol (HC), mild cognitive impairment (MCI), and Alzheimer's Disease (AD). We\nexcluded non-English, non-spontaneous, or poor-quality recordings. The final\ndataset included 703 (59.13%) HC, 81 (6.81%) MCI, and 405 (34.06%) AD cases. We\nbenchmarked a range of open-source foundation speech and language models to\nclassify cognitive status into the three categories.\n  Results: The Whisper-medium model achieved the highest performance among\nspeech models (accuracy = 0.731, AUC = 0.802). Among language models, BERT with\npause annotation performed best (accuracy = 0.662, AUC = 0.744). ADRD detection\nusing state-of-the-art automatic speech recognition (ASR) model-generated audio\nembeddings outperformed others. Including non-semantic features like pause\npatterns consistently improved text-based classification.\n  Conclusion: This study introduces a benchmarking framework using foundation\nmodels and a clinically relevant dataset. Acoustic-based approaches --\nparticularly ASR-derived embeddings -- demonstrate strong potential for\nscalable, non-invasive, and cost-effective early detection of ADRD.", "AI": {"tldr": "\u901a\u8fc7\u5bf9\u81ea\u53d1\u8bed\u97f3\u6570\u636e\u7684\u5f00\u6e90\u57fa\u7840\u6a21\u578b\u6d4b\u8bd5\uff0c\u7ed3\u679c\u53d1\u73b0\u8bed\u97f3\u6a21\u578b\uff08Whisper\u7b49\uff09\u548c\u505c\u987f\u7b49\u7279\u5f81\u878d\u5408\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u53ca\u76f8\u5173\u75f4\u5446\u7684\u65e9\u671f\u7b5b\u67e5\u8868\u73b0\uff0c\u4e3a\u65e0\u521b\u5927\u89c4\u6a21\u65e9\u7b5b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u53ca\u76f8\u5173\u75f4\u5446\uff08ADRD\uff09\u662f\u4e00\u7c7b\u8fdb\u884c\u6027\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\uff0c\u65e9\u671f\u68c0\u6d4b\u5bf9\u4e8e\u53ca\u65f6\u5e72\u9884\u548c\u62a4\u7406\u81f3\u5173\u91cd\u8981\u3002\u81ea\u53d1\u6027\u8bed\u97f3\u4e2d\u8574\u542b\u4e30\u5bcc\u7684\u58f0\u5b66\u548c\u8bed\u8a00\u6807\u8bb0\uff0c\u6709\u671b\u6210\u4e3a\u8ba4\u77e5\u8870\u9000\u7684\u65e0\u521b\u751f\u7269\u6807\u5fd7\u7269\u3002\u968f\u7740\u57fa\u7840\u6a21\u578b\u7684\u8fdb\u6b65\uff0c\u4eba\u4eec\u5e0c\u671b\u8bc4\u4f30\u5176\u5728ADRD\u65e9\u671f\u68c0\u6d4b\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u4f7f\u7528PREPARE Challenge\u6570\u636e\u96c6\uff0c\u5305\u542b1600\u591a\u540d\u53c2\u4e0e\u8005\uff08\u4e09\u79cd\u8ba4\u77e5\u72b6\u6001\uff1a\u5065\u5eb7\u3001\u8f7b\u5ea6\u8ba4\u77e5\u969c\u788d\u3001\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff09\uff0c\u7b5b\u9009\u540e\u603b\u8ba11189\u4f8b\u97f3\u9891\u3002\u5bf9\u591a\u79cd\u5f00\u6e90\u8bed\u97f3\u548c\u8bed\u8a00\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5c06\u8ba4\u77e5\u72b6\u6001\u5206\u4e3a\u4e09\u7c7b\u3002\u6bd4\u8f83\u8bed\u97f3\u3001\u6587\u672c\u53ca\u8f85\u52a9\u7279\u5f81\uff08\u5982\u505c\u987f\u6a21\u5f0f\uff09\u5728\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "result": "Whisper-medium\u8bed\u97f3\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff08\u51c6\u786e\u73870.731\uff0cAUC 0.802\uff09\uff1b\u5728\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u5e26\u505c\u987f\u6807\u6ce8\u7684BERT\u6548\u679c\u6700\u597d\uff08\u51c6\u786e\u73870.662\uff0cAUC 0.744\uff09\u3002\u57fa\u4e8eASR\u751f\u6210\u7684\u97f3\u9891\u5d4c\u5165\u5728\u68c0\u6d4bADRD\u4e0a\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002\u505c\u987f\u7b49\u975e\u8bed\u4e49\u7279\u5f81\u80fd\u63d0\u5347\u6587\u672c\u5206\u7c7b\u8868\u73b0\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\u7684ADRD\u68c0\u6d4b\u57fa\u51c6\u6846\u67b6\uff0c\u4f7f\u7528\u4e34\u5e8a\u76f8\u5173\u7684\u6570\u636e\u96c6\u3002\u57fa\u4e8e\u58f0\u5b66\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u5c24\u5176\u662fASR\u97f3\u9891\u5d4c\u5165\uff0c\u5c55\u73b0\u4e86\u53ef\u6269\u5c55\u3001\u65e0\u521b\u3001\u4f4e\u6210\u672c\u7684ADRD\u65e9\u671f\u68c0\u6d4b\u6f5c\u529b\u3002"}}
{"id": "2506.11020", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11020", "abs": "https://arxiv.org/abs/2506.11020", "authors": ["Thayn\u00e1 Camargo da Silva"], "title": "Extracting Knowledge Graphs from User Stories using LangChain", "comment": "Master thesis work", "summary": "This thesis introduces a novel methodology for the automated generation of\nknowledge graphs from user stories by leveraging the advanced capabilities of\nLarge Language Models. Utilizing the LangChain framework as a basis, the User\nStory Graph Transformer module was developed to extract nodes and relationships\nfrom user stories using an LLM to construct accurate knowledge graphs.This\ninnovative technique was implemented in a script to fully automate the\nknowledge graph extraction process. Additionally, the evaluation was automated\nthrough a dedicated evaluation script, utilizing an annotated dataset for\nassessment. By enhancing the visualization and understanding of user\nrequirements and domain concepts, this method fosters better alignment between\nsoftware functionalities and user expectations, ultimately contributing to more\neffective and user-centric software development processes.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0eLangChain\u7684\u81ea\u52a8\u7528\u6237\u6545\u4e8b\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u65b9\u6cd5\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u6784\u5efa\u548c\u8bc4\u4f30\uff0c\u52a9\u529b\u8f6f\u4ef6\u5f00\u53d1\u66f4\u597d\u6ee1\u8db3\u7528\u6237\u9700\u6c42\u3002", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u5f00\u53d1\u4e2d\uff0c\u7528\u6237\u6545\u4e8b\u96be\u4ee5\u88ab\u7ed3\u6784\u5316\u7406\u89e3\u548c\u5145\u5206\u5229\u7528\uff0c\u5bf9\u7528\u6237\u9700\u6c42\u7684\u6d1e\u5bdf\u6709\u9650\u3002\u4e3a\u66f4\u9ad8\u6548\u5730\u63d0\u53d6\u548c\u53ef\u89c6\u5316\u7528\u6237\u9700\u6c42\uff0c\u63d0\u9ad8\u8f6f\u4ef6\u5f00\u53d1\u7684\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7a0b\u5ea6\uff0c\u6709\u5fc5\u8981\u81ea\u52a8\u751f\u6210\u7528\u6237\u6545\u4e8b\u77e5\u8bc6\u56fe\u8c31\u3002", "method": "\u91c7\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u3001\u57fa\u4e8eLangChain\u6846\u67b6\u5f00\u53d1User Story Graph Transformer\u6a21\u5757\uff0c\u5b9e\u73b0\u4ece\u7528\u6237\u6545\u4e8b\u81ea\u52a8\u62bd\u53d6\u8282\u70b9\u4e0e\u5173\u7cfb\uff0c\u5e76\u81ea\u52a8\u5316\u77e5\u8bc6\u56fe\u8c31\u751f\u6210\u548c\u8bc4\u4f30\u6d41\u7a0b\u3002\u8bc4\u4f30\u73af\u8282\u901a\u8fc7\u811a\u672c\u548c\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\u81ea\u52a8\u5b8c\u6210\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u81ea\u52a8\u3001\u51c6\u786e\u5730\u4ece\u7528\u6237\u6545\u4e8b\u4e2d\u751f\u6210\u77e5\u8bc6\u56fe\u8c31\uff0c\u63d0\u5347\u4e86\u9700\u6c42\u4e0e\u9886\u57df\u6982\u5ff5\u7684\u53ef\u89c6\u5316\u548c\u7406\u89e3\u6548\u679c\uff0c\u6709\u52a9\u4e8e\u589e\u5f3a\u8f6f\u4ef6\u529f\u80fd\u4e0e\u7528\u6237\u671f\u671b\u4e4b\u95f4\u7684\u5339\u914d\u5ea6\u3002", "conclusion": "\u4f7f\u7528LLM\u81ea\u52a8\u751f\u6210\u7528\u6237\u6545\u4e8b\u77e5\u8bc6\u56fe\u8c31\u7684\u65b9\u6cd5\u63d0\u5347\u4e86\u9700\u6c42\u5206\u6790\u6548\u7387\u4e0e\u51c6\u786e\u6027\uff0c\u5bf9\u4fc3\u8fdb\u7528\u6237\u9a71\u52a8\u7684\u8f6f\u4ef6\u5f00\u53d1\u5177\u6709\u79ef\u6781\u4f5c\u7528\u3002"}}
{"id": "2506.11120", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.11120", "abs": "https://arxiv.org/abs/2506.11120", "authors": ["Hourun Zhu", "Chengchao Shen"], "title": "SDMPrune: Self-Distillation MLP Pruning for Efficient Large Language Models", "comment": null, "summary": "In spite of strong performance achieved by LLMs, the costs of their\ndeployment are unaffordable. For the compression of LLMs, gradient-based\npruning methods present promising effectiveness. However, in these methods, the\ngradient computation with one-hot labels ignore the potential predictions on\nother words, thus missing key information for generative capability of the\noriginal model. To address this issue, we introduce a self-distillation loss\nduring the pruning phase (rather than post-training) to fully exploit the\npredictions of the original model, thereby obtaining more accurate gradient\ninformation for pruning. Moreover, we find that, compared to attention modules,\nthe predictions of LLM are less sensitive to multilayer perceptron (MLP)\nmodules, which take up more than $5 \\times$ parameters (LLaMA3.2-1.2B). To this\nend, we focus on the pruning of MLP modules, to significantly compress LLM\nwithout obvious performance degradation. Experimental results on extensive\nzero-shot benchmarks demonstrate that our method significantly outperforms\nexisting pruning methods. Furthermore, our method achieves very competitive\nperformance among 1B-scale open source LLMs. The source code and trained\nweights are available at https://github.com/visresearch/SDMPrune.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u526a\u679d\u9636\u6bb5\u81ea\u84b8\u998f\u635f\u5931\uff0c\u91cd\u70b9\u526a\u679dMLP\u6a21\u5757\uff0c\u5927\u5e45\u538b\u7f29LLM\u53c2\u6570\u4e14\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9002\u5408\u4f4e\u6210\u672c\u90e8\u7f72\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u867d\u7136\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u90e8\u7f72\u6210\u672c\u6781\u9ad8\uff0c\u56e0\u6b64\u9700\u8981\u6a21\u578b\u538b\u7f29\u6280\u672f\u3002\u73b0\u6709\u57fa\u4e8e\u68af\u5ea6\u7684\u526a\u679d\u65b9\u6cd5\u6709\u6548\uff0c\u4f46\u4f7f\u7528 one-hot \u6807\u7b7e\u8ba1\u7b97\u68af\u5ea6\u4f1a\u5ffd\u89c6\u539f\u6a21\u578b\u5bf9\u5176\u4ed6\u8bcd\u7684\u9884\u6d4b\uff0c\u56e0\u6b64\u4e27\u5931\u5173\u952e\u4fe1\u606f\u3002", "method": "\u4f5c\u8005\u5728\u526a\u679d\u9636\u6bb5\u5f15\u5165\u81ea\u84b8\u998f\u635f\u5931\uff08\u800c\u975e\u540e\u8bad\u7ec3\u9636\u6bb5\uff09\uff0c\u5145\u5206\u5229\u7528\u539f\u6a21\u578b\u7684\u9884\u6d4b\uff0c\u83b7\u53d6\u66f4\u51c6\u786e\u7684\u68af\u5ea6\u4fe1\u606f\u8fdb\u884c\u526a\u679d\u3002\u6b64\u5916\uff0c\u53d1\u73b0LLM\u7684\u8f93\u51fa\u5bf9MLP\u6a21\u5757\u7684\u4e0d\u654f\u611f\u6027\uff0cMLP\u53c2\u6570\u5360\u6bd4\u66f4\u9ad8\uff0c\u56e0\u6b64\u805a\u7126MLP\u526a\u679d\u4ee5\u5b9e\u73b0\u66f4\u5927\u538b\u7f29\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u591a\u4e2a\u96f6\u6837\u672c\u6d4b\u8bd5\u57fa\u51c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u526a\u679d\u65b9\u6cd5\uff0c\u5e76\u5728\u5f00\u6e901B\u89c4\u6a21LLM\u9886\u57df\u8868\u73b0\u6781\u5177\u7ade\u4e89\u529b\u3002", "conclusion": "\u901a\u8fc7\u5728\u526a\u679d\u9636\u6bb5\u52a0\u5165\u81ea\u84b8\u998f\u635f\u5931\uff0c\u4ee5\u53ca\u4e13\u6ce8\u4e8e\u5bf9MLP\u6a21\u5757\u7684\u526a\u679d\uff0c\u5927\u5e45\u51cf\u5c11\u53c2\u6570\u91cf\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u751a\u81f3\u8d85\u8fc7\u73b0\u6709\u65b9\u6cd5\u7684\u6a21\u578b\u6548\u679c\u3002"}}
{"id": "2506.11021", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11021", "abs": "https://arxiv.org/abs/2506.11021", "authors": ["Chaitanya Ravuri", "Saman Amarasinghe"], "title": "Eliminating Hallucination-Induced Errors in LLM Code Generation with Functional Clustering", "comment": "9 pages, 1 figure", "summary": "Modern code-generation LLMs can already solve a large fraction of programming\nproblems, yet they still hallucinate subtle bugs that make their outputs unsafe\nfor autonomous deployment. We present functional clustering, a black-box\nwrapper that eliminates nearly all hallucination-induced errors while providing\na tunable confidence score. The wrapper samples many candidate programs,\nexecutes each on a self-generated test suite, and clusters candidates whose I/O\nbehavior is identical; the empirical mass of the largest cluster serves as an\nexact confidence estimate. A single scalar threshold on this estimate lets\nusers trade coverage for reliability with exponential guarantees. On\nLiveCodeBench our verifier preserves baseline pass@1 on solvable tasks yet\nslashes the error rate of returned answers from ~65% to 2%, and drives it to 0%\nat a conservative threshold while still answering 15.6% of prompts. Manual\naudits show that the few residual mistakes stem from prompt misinterpretation,\nnot random generation noise, narrowing future work to specification clarity.\nBecause the method requires only sampling and sandbox execution, it applies\nunchanged to closed-source APIs and future models, offering a practical path\ntoward dependable, autonomous code generation. Our code is available on Github\n(https://github.com/20ChaituR/functional-clustering).", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9ed1\u76d2\u4ee3\u7801\u751f\u6210\u6a21\u578b\u9a8c\u8bc1\u65b9\u6848\uff0c\u901a\u8fc7\u7a0b\u5e8f\u884c\u4e3a\u805a\u7c7b\u805a\u5408\u7ed3\u679c\uff0c\u80fd\u663e\u8457\u63d0\u9ad8\u4ee3\u7801\u751f\u6210\u51c6\u786e\u7387\u5e76\u63d0\u4f9b\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\uff0c\u51e0\u4e4e\u6d88\u9664\u201c\u5e7b\u89c9\u201d\u9519\u8bef\uff0c\u4e14\u65b9\u6cd5\u7b80\u5355\u901a\u7528\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u4ee3\u4ee3\u7801\u751f\u6210\u5927\u6a21\u578b\u5df2\u80fd\u89e3\u51b3\u5927\u91cf\u7f16\u7a0b\u95ee\u9898\uff0c\u4f46\u5176\u8f93\u51fa\u4ecd\u5e38\u56e0\u201c\u5e7b\u89c9\u201d\u5bfc\u81f4\u7ec6\u5fae\u9519\u8bef\uff0c\u9020\u6210\u6a21\u578b\u4e0d\u5b89\u5168\uff0c\u5236\u7ea6\u4e86\u5176\u81ea\u52a8\u5316\u90e8\u7f72\u3002\u9700\u8981\u4e00\u79cd\u7b80\u5355\u4e14\u901a\u7528\u7684\u65b9\u6cd5\u6765\u5927\u5e45\u51cf\u5c11\u8fd9\u4e9b\u9519\u8bef\u3002", "method": "\u901a\u8fc7\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u91c7\u6837\u5927\u91cf\u4ee3\u7801\u5019\u9009\u89e3\uff0c\u5c06\u8fd9\u4e9b\u5019\u9009\u89e3\u5728\u81ea\u751f\u6210\u7684\u6d4b\u8bd5\u96c6\u4e0a\u6267\u884c\uff0c\u5e76\u6839\u636e\u8f93\u5165\u8f93\u51fa\u884c\u4e3a\u805a\u7c7b\u3002\u6700\u5927\u805a\u7c7b\u7684\u6982\u7387\u8d28\u91cf\u4f5c\u4e3a\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u3002\u6839\u636e\u8fd9\u4e2a\u5206\u6570\u8bbe\u5b9a\u9608\u503c\uff0c\u53ef\u4ee5\u5728\u4fdd\u7559\u53f3\u901a\u8fc7\u7387\u7684\u524d\u63d0\u4e0b\uff0c\u4ee5\u6307\u6570\u7ea7\u4f18\u52bf\u51cf\u5c11\u7ed3\u679c\u9519\u8bef\u7387\u3002", "result": "\u5728 LiveCodeBench \u4e0a\u5b9e\u9a8c\u663e\u793a\uff0c\u672c\u6587\u65b9\u6cd5\u80fd\u4fdd\u6301\u73b0\u6709\u6a21\u578b\u5728\u53ef\u89e3\u4efb\u52a1\u7684\u901a\u8fc7\u7387\uff08pass@1\uff09\uff0c\u4f46\u8fd4\u56de\u7b54\u6848\u7684\u9519\u8bef\u7387\u4ece\u7ea6 65% \u964d\u81f3 2%\uff1b\u5728\u4fdd\u5b88\u9608\u503c\u4e0b\u9519\u8bef\u7387\u53ef\u4e3a 0%\uff0c\u4ecd\u56de\u7b54 15.6% \u7684\u95ee\u9898\u3002\u4eba\u5de5\u68c0\u67e5\u8868\u660e\u6b8b\u4f59\u9519\u8bef\u4e3b\u8981\u6e90\u81ea\u9898\u610f\u7406\u89e3\u4e0d\u6e05\uff0c\u800c\u975e\u751f\u6210\u968f\u673a\u566a\u58f0\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u4f9d\u8d56\u5f00\u6e90 API \u6216\u6a21\u578b\uff0c\u9002\u7528\u8303\u56f4\u5e7f\u6cdb\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684 functional clustering \u65b9\u6cd5\u901a\u8fc7\u9ed1\u76d2\u5305\u88f9\u6d88\u9664\u4e86\u51e0\u4e4e\u6240\u6709\u7531\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7801\u751f\u6210\u5f15\u8d77\u7684\u5e7b\u89c9\u7c7b\u9519\u8bef\uff0c\u5e76\u80fd\u4e3a\u8f93\u51fa\u63d0\u4f9b\u53ef\u8c03\u7684\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u3002\u65b9\u6cd5\u5177\u6709\u901a\u7528\u6027\uff0c\u4e0d\u4f9d\u8d56\u6a21\u578b\u7ed3\u6784\u5373\u53ef\u63d0\u5347\u4ee3\u7801\u81ea\u52a8\u751f\u6210\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2506.11121", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.11121", "abs": "https://arxiv.org/abs/2506.11121", "authors": ["Wei-Ping Huang", "Guan-Ting Lin", "Hung-yi Lee"], "title": "SUTA-LM: Bridging Test-Time Adaptation and Language Model Rescoring for Robust ASR", "comment": null, "summary": "Despite progress in end-to-end ASR, real-world domain mismatches still cause\nperformance drops, which Test-Time Adaptation (TTA) aims to mitigate by\nadjusting models during inference. Recent work explores combining TTA with\nexternal language models, using techniques like beam search rescoring or\ngenerative error correction. In this work, we identify a previously overlooked\nchallenge: TTA can interfere with language model rescoring, revealing the\nnontrivial nature of effectively combining the two methods. Based on this\ninsight, we propose SUTA-LM, a simple yet effective extension of SUTA, an\nentropy-minimization-based TTA approach, with language model rescoring. SUTA-LM\nfirst applies a controlled adaptation process guided by an auto-step selection\nmechanism leveraging both acoustic and linguistic information, followed by\nlanguage model rescoring to refine the outputs. Experiments on 18 diverse ASR\ndatasets show that SUTA-LM achieves robust results across a wide range of\ndomains.", "AI": {"tldr": "\u63d0\u51faSUTA-LM\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u548c\u8bed\u8a00\u6a21\u578b\u91cd\u6392\u5e8f\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u7aef\u5230\u7aefASR\u5728\u5404\u7c7b\u9886\u57df\u7684\u6027\u80fd\u3002", "motivation": "\u7aef\u5230\u7aef\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7531\u4e8e\u9886\u57df\u4e0d\u5339\u914d\uff0c\u6027\u80fd\u4f1a\u5927\u5e45\u4e0b\u964d\u3002\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\uff08TTA\uff09\u867d\u80fd\u7f13\u89e3\u6b64\u95ee\u9898\uff0c\u4f46\u4e0e\u5916\u90e8\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u5e38\u4ea7\u751f\u5e72\u6270\uff0c\u5f71\u54cd\u6548\u679c\u3002\u5982\u4f55\u6709\u6548\u7ed3\u5408\u4e8c\u8005\u5df2\u6210\u4e3a\u6311\u6218\u3002", "method": "\u63d0\u51faSUTA-LM\u65b9\u6cd5\uff0c\u5c06\u57fa\u4e8e\u71b5\u6700\u5c0f\u5316\u7684TTA\u65b9\u6cd5\uff08SUTA\uff09\u4e0e\u8bed\u8a00\u6a21\u578b\u91cd\u6392\u5e8f\u7ed3\u5408\u3002\u5177\u4f53\u6d41\u7a0b\u662f\uff1a\u5148\u7528\u81ea\u52a8\u6b65\u6570\u9009\u62e9\u673a\u5236\uff0c\u7ed3\u5408\u58f0\u5b66\u4e0e\u8bed\u8a00\u4fe1\u606f\u6307\u5bfc\u81ea\u9002\u5e94\u8fc7\u7a0b\uff0c\u518d\u8fdb\u884c\u8bed\u8a00\u6a21\u578b\u91cd\u6392\u5e8f\u4f18\u5316\u8f93\u51fa\u7ed3\u679c\u3002", "result": "\u572818\u4e2a\u591a\u6837\u5316ASR\u6570\u636e\u96c6\u4e0a\uff0cSUTA-LM\u5728\u5404\u79cd\u4e0d\u540c\u9886\u57df\u90fd\u53d6\u5f97\u4e86\u9c81\u68d2\u7684\u8bc6\u522b\u6548\u679c\u3002", "conclusion": "SUTA-LM\u80fd\u6709\u6548\u5730\u5c06TTA\u548c\u8bed\u8a00\u6a21\u578b\u91cd\u6392\u5e8f\u7ed3\u5408\uff0c\u514b\u670d\u4e86\u4e8c\u8005\u7ed3\u5408\u65f6\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u5728\u8de8\u9886\u57dfASR\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.11022", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.11022", "abs": "https://arxiv.org/abs/2506.11022", "authors": ["Shivani Shukla", "Himanshu Joshi", "Romilla Syed"], "title": "Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox", "comment": "Keywords - Large Language Models, Security Vulnerabilities,\n  AI-Generated Code, Iterative Feedback, Software Security, Secure Coding\n  Practices, Feedback Loops, LLM Prompting Strategies", "summary": "The rapid adoption of Large Language Models(LLMs) for code generation has\ntransformed software development, yet little attention has been given to how\nsecurity vulnerabilities evolve through iterative LLM feedback. This paper\nanalyzes security degradation in AI-generated code through a controlled\nexperiment with 400 code samples across 40 rounds of \"improvements\" using four\ndistinct prompting strategies. Our findings show a 37.6% increase in critical\nvulnerabilities after just five iterations, with distinct vulnerability\npatterns emerging across different prompting approaches. This evidence\nchallenges the assumption that iterative LLM refinement improves code security\nand highlights the essential role of human expertise in the loop. We propose\npractical guidelines for developers to mitigate these risks, emphasizing the\nneed for robust human validation between LLM iterations to prevent the\nparadoxical introduction of new security issues during supposedly beneficial\ncode \"improvements\".", "AI": {"tldr": "LLM\u591a\u8f6e\u8fed\u4ee3\u6539\u8fdb\u4ee3\u7801\u975e\u4f46\u4e0d\u80fd\u4fdd\u8bc1\u5b89\u5168\uff0c\u53cd\u800c\u53ef\u80fd\u589e\u52a0\u5b89\u5168\u6f0f\u6d1e\u3002\u7814\u7a76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u5b9e\u5173\u952e\u6027\u6f0f\u6d1e\u589e\u957f\uff0c\u5e76\u547c\u5401\u5f00\u53d1\u8005\u5728\u8fed\u4ee3\u4e2d\u52a1\u5fc5\u4eba\u5de5\u4ecb\u5165\uff0c\u907f\u514d\u5b89\u5168\u98ce\u9669\u7d2f\u79ef\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5df2\u88ab\u5e7f\u6cdb\u7528\u4e8e\u4ee3\u7801\u751f\u6210\uff0c\u4f46\u5173\u4e8e\u901a\u8fc7\u8fed\u4ee3\u5f0fLLM\u53cd\u9988\u4e2d\u5b89\u5168\u6f0f\u6d1e\u5982\u4f55\u6f14\u53d8\u7684\u7814\u7a76\u8f83\u5c11\u3002\u4f5c\u8005\u5e0c\u671b\u63ed\u793a\u5f53\u524d\u5f00\u53d1\u5b9e\u8df5\u4e0b\uff0c\u9891\u7e41\u5229\u7528LLM\u6539\u8fdb\u4ee3\u7801\u65f6\uff0c\u5bf9\u5b89\u5168\u9020\u6210\u4f55\u79cd\u5f71\u54cd\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5bf9400\u4efd\u4ee3\u7801\u8fdb\u884c40\u8f6e\u6539\u8fdb\u5b9e\u9a8c\uff0c\u91c7\u7528\u56db\u79cd\u4e0d\u540c\u7684\u63d0\u793a\u7b56\u7565\uff0c\u53d7\u63a7\u5206\u6790\u6bcf\u8f6e\u540e\u4ee3\u7801\u4e2d\u5b89\u5168\u6f0f\u6d1e\u7684\u53d8\u5316\u60c5\u51b5\u3002", "result": "\u8fed\u4ee3\u4ec5\u4e94\u8f6e\uff0c\u5173\u952e\u5b89\u5168\u6f0f\u6d1e\u5e73\u5747\u589e\u52a0\u4e8637.6%\u3002\u56db\u79cd\u63d0\u793a\u7b56\u7565\u4e0b\uff0c\u6f0f\u6d1e\u8868\u73b0\u4e5f\u5404\u6709\u4e0d\u540c\uff0c\u66b4\u9732\u51fa\u4e0d\u540c\u7684\u5b89\u5168\u98ce\u9669\u6a21\u5f0f\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0c\u8fed\u4ee3\u5f0f\u4f7f\u7528LLM\u5e76\u4e0d\u4e00\u5b9a\u63d0\u5347\u4ee3\u7801\u5b89\u5168\uff0c\u53cd\u800c\u6709\u53ef\u80fd\u5f15\u5165\u66f4\u591a\u5b89\u5168\u98ce\u9669\u3002\u4f5c\u8005\u5f3a\u8c03\u9700\u8981\u5728LLM\u751f\u6210\u4e0e\u6539\u8fdb\u8fc7\u7a0b\u4e2d\u5d4c\u5165\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\uff0c\u63d0\u51fa\u5f00\u53d1\u8005\u5e94\u52a0\u5f3a\u4eba\u5de5\u6821\u9a8c\u548c\u628a\u63a7\uff0c\u9632\u6b62\u4ee3\u7801\u2018\u6539\u8fdb\u2019\u53cd\u800c\u5bfc\u81f4\u5b89\u5168\u9000\u5316\u3002"}}
{"id": "2506.11125", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11125", "abs": "https://arxiv.org/abs/2506.11125", "authors": ["Freddie Grabovski", "Gilad Gressel", "Yisroel Mirsky"], "title": "ASRJam: Human-Friendly AI Speech Jamming to Prevent Automated Phone Scams", "comment": null, "summary": "Large Language Models (LLMs), combined with Text-to-Speech (TTS) and\nAutomatic Speech Recognition (ASR), are increasingly used to automate voice\nphishing (vishing) scams. These systems are scalable and convincing, posing a\nsignificant security threat. We identify the ASR transcription step as the most\nvulnerable link in the scam pipeline and introduce ASRJam, a proactive defence\nframework that injects adversarial perturbations into the victim's audio to\ndisrupt the attacker's ASR. This breaks the scam's feedback loop without\naffecting human callers, who can still understand the conversation. While prior\nadversarial audio techniques are often unpleasant and impractical for real-time\nuse, we also propose EchoGuard, a novel jammer that leverages natural\ndistortions, such as reverberation and echo, that are disruptive to ASR but\ntolerable to humans. To evaluate EchoGuard's effectiveness and usability, we\nconducted a 39-person user study comparing it with three state-of-the-art\nattacks. Results show that EchoGuard achieved the highest overall utility,\noffering the best combination of ASR disruption and human listening experience.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u81ea\u52a8\u5316\u8bed\u97f3\u9493\u9c7c\uff08vishing\uff09\u8bc8\u9a97\uff0c\u63d0\u51fa\u4e86ASRJam\u9632\u5fa1\u6846\u67b6\u548c\u65b0\u578b\u5e72\u6270\u5668EchoGuard\u3002\u901a\u8fc7\u81ea\u7136\u56de\u58f0\u7b49\u65b9\u5f0f\u5e72\u6270ASR\u7cfb\u7edf\uff0c\u963b\u65ad\u8bc8\u9a97\u6d41\u7a0b\u4e14\u4e0d\u5f71\u54cd\u6b63\u5e38\u901a\u8bdd\u4f53\u9a8c\u3002\u5728\u771f\u5b9e\u7528\u6237\u7814\u7a76\u4e2d\uff0cEchoGuard\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7ed3\u5408\u8bed\u97f3\u5408\u6210\uff08TTS\uff09\u548c\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u7684\u53d1\u5c55\uff0c\u81ea\u52a8\u5316\u8bed\u97f3\u9493\u9c7c\uff08vishing\uff09\u8bc8\u9a97\u53d8\u5f97\u66f4\u5177\u89c4\u6a21\u548c\u6b3a\u9a97\u6027\uff0c\u5bf9\u5b89\u5168\u9020\u6210\u4e86\u4e25\u91cd\u5a01\u80c1\u3002\u73b0\u6709\u7684\u9632\u5fa1\u63aa\u65bd\u5bf9\u4e8e\u5b9e\u65f6\u3001\u7528\u6237\u53cb\u597d\u7684\u4fdd\u62a4\u6548\u679c\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u5bfb\u6c42\u66f4\u6709\u6548\u7684\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86ASRJam\u8fd9\u5957\u4e3b\u52a8\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u53d7\u5bb3\u8005\u97f3\u9891\u6ce8\u5165\u5bf9\u6297\u6027\u6270\u52a8\uff0c\u4ece\u800c\u5e72\u6270\u653b\u51fb\u8005\u7684ASR\u7cfb\u7edf\uff0c\u4f46\u5bf9\u4eba\u7c7b\u901a\u8bdd\u5f71\u54cd\u751a\u5fae\u3002\u540c\u65f6\u63d0\u51faEchoGuard\uff0c\u4e00\u79cd\u5229\u7528\u81ea\u7136\u5931\u771f\u5982\u6df7\u54cd\u548c\u56de\u58f0\u7684\u65b0\u578b\u5e72\u6270\u5668\uff0c\u65e8\u5728\u5b9e\u73b0\u5bf9ASR\u7684\u6709\u6548\u6270\u4e71\u4e14\u5bf9\u4eba\u8033\u8f83\u4e3a\u53cb\u597d\u3002\u4f5c\u8005\u8fd8\u901a\u8fc739\u4eba\u7528\u6237\u7814\u7a76\u8bc4\u4f30\u4e86EchoGuard\u7684\u6709\u6548\u6027\u548c\u7528\u6237\u4f53\u9a8c\uff0c\u5e76\u4e0e\u4e09\u79cd\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u4e86\u5bf9\u6bd4\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cEchoGuard\u5728ASR\u6270\u4e71\u80fd\u529b\u548c\u5bf9\u4eba\u7c7b\u542c\u611f\u7684\u5e73\u8861\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u6574\u4f53\u5b9e\u7528\u6027\u3002", "conclusion": "\u8bba\u6587\u8868\u660e\uff0c\u901a\u8fc7\u5728\u901a\u4fe1\u94fe\u8def\u4e2d\u5de7\u5999\u6ce8\u5165\u4ec5\u5bf9ASR\u7cfb\u7edf\u4ea7\u751f\u5f71\u54cd\u7684\u81ea\u7136\u97f3\u9891\u6270\u52a8\uff0c\u53ef\u4ee5\u6709\u6548\u963b\u65ad\u81ea\u52a8\u5316\u8bed\u97f3\u8bc8\u9a97\u7684\u653b\u51fb\u94fe\u8def\uff0c\u4e3a\u8bed\u97f3\u5b89\u5168\u9632\u62a4\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2506.11051", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11051", "abs": "https://arxiv.org/abs/2506.11051", "authors": ["Sung Une Lee", "Liming Dong", "Zhenchang Xing", "Muhammad Ejaz Ahmed", "Stefan Avgoustakis"], "title": "Software Security Mapping Framework: Operationalization of Security Requirements", "comment": "28 pages, 13 figures, 6 tables", "summary": "The escalating complexity of modern software development environments has\nheightened concerns around supply chain security. However, existing frameworks\noften fall short in translating abstract security principles into concrete,\nactionable practices. This paper introduces the Software Security Mapping\nFramework, a structured solution designed to operationalize security\nrequirements across hierarchical levels -- from high-level regulatory standards\n(e.g., ISM, Australia cybersecurity standard published by the Australian\nSignals Directorate), through mid-level frameworks (e.g., NIST SSDF, the U.S.\nSecure Software Development Framework), to fine-grained technical activities\n(e.g., SLSA, a software supply chain security framework). Developed through\ncollaborative research with academic experts and industry practitioners, the\nframework systematically maps 131 refined security requirements to over 400\nactionable operational steps spanning the software development lifecycle. It is\ngrounded in four core security goals: Secure Software Environment, Secure\nSoftware Development, Software Traceability, and Vulnerability Management. Our\napproach leverages the KAOS goal modeling methodology to establish traceable\nlinkages between strategic goals and tactical operations, enhancing clarity,\naccountability, and practical implementation. To facilitate adoption, we\nprovide a web-based navigation tool for interactive exploration of the\nframework. A real-world case study based on the Log4j vulnerability illustrates\nthe framework's utility by generating a tailored checklist aligned with\nindustry best practices. Additionally, we offer a structured, machine-readable\nOSCAL Catalog Model of the Software Security Mapping Framework, enabling\norganizations to automate implementation, streamline compliance processes, and\nrespond effectively to evolving security risks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5c06\u62bd\u8c61\u5b89\u5168\u8981\u6c42\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u6b65\u9aa4\u7684\u8f6f\u4ef6\u5b89\u5168\u6620\u5c04\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u5c55\u793a\u5176\u5b9e\u7528\u6027\uff0c\u52a9\u529b\u7ec4\u7ec7\u63d0\u5347\u4f9b\u5e94\u94fe\u5b89\u5168\u7ba1\u7406\u548c\u5408\u89c4\u6548\u7387\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u5f00\u53d1\u73af\u5883\u65e5\u8d8b\u590d\u6742\uff0c\u4f9b\u5e94\u94fe\u5b89\u5168\u95ee\u9898\u6108\u53d1\u7a81\u51fa\u3002\u7136\u800c\uff0c\u73b0\u6709\u6846\u67b6\u96be\u4ee5\u5c06\u62bd\u8c61\u7684\u5b89\u5168\u539f\u5219\u8f6c\u5316\u4e3a\u5177\u4f53\u53ef\u64cd\u4f5c\u7684\u5b9e\u8df5\uff0c\u8feb\u5207\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u5b9e\u73b0\u5b89\u5168\u9700\u6c42\u7684\u843d\u5730\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86Software Security Mapping Framework\uff08\u8f6f\u4ef6\u5b89\u5168\u6620\u5c04\u6846\u67b6\uff09\uff0c\u91c7\u7528KAOS\u76ee\u6807\u5efa\u6a21\u65b9\u6cd5\uff0c\u5c06\u9ad8\u5c42\u6b21\u5b89\u5168\u6807\u51c6\u3001\u6846\u67b6\u53ca\u7ec6\u7c92\u5ea6\u6280\u672f\u6d3b\u52a8\u7cfb\u7edf\u6620\u5c04\u4e3a400\u591a\u9879\u53ef\u64cd\u4f5c\u6b65\u9aa4\uff0c\u5e76\u5f00\u53d1\u4e86\u4ea4\u4e92\u5f0f\u7f51\u9875\u5de5\u5177\u53ca\u53ef\u673a\u8bfb\u7684OSCAL Catalog Model\u3002", "result": "\u6846\u67b6\u5b9e\u73b0\u4e86131\u9879\u5b89\u5168\u9700\u6c42\u5230400\u591a\u9879\u5b9e\u9645\u64cd\u4f5c\u7684\u7cfb\u7edf\u6620\u5c04\uff0c\u589e\u5f3a\u4e86\u5b89\u5168\u76ee\u6807\u4e0e\u5b9e\u9645\u64cd\u4f5c\u95f4\u7684\u53ef\u8ffd\u6eaf\u6027\u3002\u5728Log4j\u6f0f\u6d1e\u6848\u4f8b\u4e2d\uff0c\u80fd\u751f\u6210\u7b26\u5408\u884c\u4e1a\u6700\u4f73\u5b9e\u8df5\u7684\u5b9a\u5236\u68c0\u67e5\u6e05\u5355\uff0c\u5e76\u4e3a\u81ea\u52a8\u5316\u5b9e\u65bd\u548c\u5408\u89c4\u76d1\u7ba1\u63d0\u4f9b\u652f\u6301\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u6709\u6548\u4fc3\u8fdb\u4e86\u5b89\u5168\u9700\u6c42\u7684\u843d\u5730\u6267\u884c\uff0c\u52a0\u5f3a\u4e86\u4f9b\u5e94\u94fe\u5b89\u5168\u7ba1\u7406\u7684\u900f\u660e\u5ea6\u548c\u8d23\u4efb\u5212\u5206\uff0c\u6709\u52a9\u4e8e\u7ec4\u7ec7\u9ad8\u6548\u5e94\u5bf9\u4e0d\u65ad\u53d8\u5316\u7684\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2506.11127", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11127", "abs": "https://arxiv.org/abs/2506.11127", "authors": ["Wenkang Han", "Zhixiong Zeng", "Jing Huang", "Shu Jiang", "Liming Zheng", "Longrong Yang", "Haibo Qiu", "Chang Yao", "Jingyuan Chen", "Lin Ma"], "title": "GUIRoboTron-Speech: Towards Automated GUI Agents Based on Speech Instructions", "comment": null, "summary": "Autonomous agents for Graphical User Interfaces (GUIs) are revolutionizing\nhuman-computer interaction, yet their reliance on text-based instructions\nimposes limitations on accessibility and convenience, particularly in\nhands-free scenarios. To address this gap, we propose GUIRoboTron-Speech, the\nfirst end-to-end autonomous GUI agent that directly accepts speech instructions\nand on-device screenshots to predict actions. Confronted with the scarcity of\nspeech-based GUI agent datasets, we initially generated high-quality speech\ninstructions for training by leveraging a random timbre text-to-speech (TTS)\nmodel to convert existing text instructions. We then develop\nGUIRoboTron-Speech's capabilities through progressive grounding and planning\ntraining stages. A key contribution is a heuristic mixed-instruction training\nstrategy designed to mitigate the modality imbalance inherent in pre-trained\nfoundation models. Comprehensive experiments on several benchmark datasets\nvalidate the robust and superior performance of GUIRoboTron-Speech,\ndemonstrating the significant potential and widespread applicability of speech\nas an effective instruction modality for driving GUI agents. Our code and\ndatasets are available at https://github.com/GUIRoboTron/GUIRoboTron-Speech.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u7aef\u5230\u7aef\u652f\u6301\u8bed\u97f3\u6307\u4ee4\u7684GUI\u81ea\u4e3b\u667a\u80fd\u4f53GUIRoboTron-Speech\uff0c\u5229\u7528TTS\u5408\u6210\u8bed\u97f3\u8bad\u7ec3\u548c\u65b0\u9896\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u5728\u591a\u6570\u636e\u96c6\u4e0a\u7684\u4f18\u8d8a\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u8bed\u97f3\u9a71\u52a8GUI\u64cd\u4f5c\u7684\u5de8\u5927\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u9762\u5411\u56fe\u5f62\u7528\u6237\u754c\u9762\uff08GUI\uff09\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u4e3b\u8981\u4f9d\u8d56\u6587\u672c\u6307\u4ee4\uff0c\u5f71\u54cd\u4e86\u5176\u5728\u65e0\u624b\u64cd\u4f5c\u6216\u9ad8\u4fbf\u5229\u6027\u9700\u6c42\u573a\u666f\u4e0b\u7684\u53ef\u8bbf\u95ee\u6027\u4e0e\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51fa\u4e86GUIRoboTron-Speech\uff0c\u8fd9\u662f\u9996\u4e2a\u7aef\u5230\u7aef\u80fd\u76f4\u63a5\u63a5\u53d7\u8bed\u97f3\u6307\u4ee4\u548c\u8bbe\u5907\u622a\u56fe\u6765\u9884\u6d4bGUI\u64cd\u4f5c\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u3002\u4e3a\u4e86\u89e3\u51b3\u7f3a\u4e4f\u8bed\u97f3GUI\u6570\u636e\u96c6\u7684\u95ee\u9898\uff0c\u4f5c\u8005\u5229\u7528TTS\u6a21\u578b\u5c06\u73b0\u6709\u6587\u672c\u6307\u4ee4\u8f6c\u6362\u4e3a\u9ad8\u8d28\u91cf\u8bed\u97f3\u6307\u4ee4\u7528\u4e8e\u8bad\u7ec3\uff0c\u540c\u65f6\u91c7\u7528\u4e86\u9012\u8fdb\u7684\u8bed\u4e49\u548c\u89c4\u5212\u8bad\u7ec3\u9636\u6bb5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u6df7\u5408\u6307\u4ee4\u8bad\u7ec3\u7b56\u7565\u4ee5\u7f13\u89e3\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6a21\u6001\u4e0d\u5747\u8861\u95ee\u9898\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cGUIRoboTron-Speech\u5728\u9c81\u68d2\u6027\u548c\u6027\u80fd\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u8bed\u97f3\u4f5c\u4e3aGUI\u667a\u80fd\u4f53\u6307\u4ee4\u65b9\u5f0f\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "GUIRoboTron-Speech\u4f5c\u4e3a\u9996\u4e2a\u652f\u6301\u8bed\u97f3-\u56fe\u50cf\u7aef\u5230\u7aef\u8f93\u5165\u7684GUI\u667a\u80fd\u4f53\uff0c\u80fd\u591f\u6709\u6548\u63a8\u52a8\u8bed\u97f3\u4f5c\u4e3a\u6307\u4ee4\u6a21\u6001\u5728GUI\u4ea4\u4e92\u9886\u57df\u7684\u5e94\u7528\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5b9e\u7528\u524d\u666f\u3002"}}
{"id": "2506.11058", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11058", "abs": "https://arxiv.org/abs/2506.11058", "authors": ["Ziga Kovacic", "Celine Lee", "Justin Chiu", "Wenting Zhao", "Kevin Ellis"], "title": "Refactoring Codebases through Library Design", "comment": "26 pages", "summary": "Maintainable and general software allows developers to build robust\napplications efficiently, yet achieving these qualities often requires\nrefactoring specialized solutions into reusable components. This challenge\nbecomes particularly relevant as code agents become increasingly accurate at\nsolving isolated programming problems. We investigate code agents' capacity to\nrefactor code in ways supporting growth and reusability. We present both a\nmethod and a benchmark for refactoring: Librarian, a sample-and-rerank method\nfor generating reusable libraries, and Minicode, a benchmark where code agents\nmust minimize and refactor multiple independent solutions into a joint library.\nCompared to state-of-the-art code agents, Librarian achieves strong results on\nboth compression and correctness on Minicode, obtaining compression rates\n1.6-2x better than coding agents while also improving correctness. We\nopen-source our code and benchmark at https://code-refactor.github.io/.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86Librarian\u81ea\u52a8\u5316\u91cd\u6784\u65b9\u6cd5\u548cMinicode\u6d4b\u8bd5\u96c6\uff0c\u4f7f\u5f97\u4ee3\u7801\u4ee3\u7406\u5728\u4ee3\u7801\u538b\u7f29\u7387\u548c\u6b63\u786e\u6027\u4e0a\u5b9e\u73b0\u5927\u5e45\u63d0\u5347\uff0c\u4fc3\u8fdb\u4e86\u53ef\u590d\u7528\u8f6f\u4ef6\u7ec4\u4ef6\u7684\u81ea\u52a8\u751f\u6210\u3002", "motivation": "\u9ad8\u53ef\u7ef4\u62a4\u6027\u548c\u901a\u7528\u6027\u7684\u8f6f\u4ef6\u80fd\u8ba9\u5f00\u53d1\u8005\u66f4\u9ad8\u6548\u5730\u6784\u5efa\u5065\u58ee\u7684\u5e94\u7528\u7a0b\u5e8f\uff0c\u4f46\u8fd9\u901a\u5e38\u9700\u8981\u5c06\u7279\u5b9a\u89e3\u51b3\u65b9\u6848\u91cd\u6784\u4e3a\u53ef\u590d\u7528\u7684\u7ec4\u4ef6\u3002\u968f\u7740\u4ee3\u7801\u4ee3\u7406(agent)\u5728\u89e3\u51b3\u5b64\u7acb\u7f16\u7a0b\u95ee\u9898\u65b9\u9762\u7684\u51c6\u786e\u6027\u63d0\u5347\uff0c\u63a2\u8ba8\u5176\u652f\u6301\u4ee3\u7801\u589e\u957f\u548c\u590d\u7528\u7684\u80fd\u529b\u5177\u6709\u73b0\u5b9e\u610f\u4e49\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86Librarian\u65b9\u6cd5\uff08\u4e00\u79cdsample-and-rerank\u7684\u751f\u6210\u53ef\u590d\u7528\u5e93\u7684\u65b9\u6cd5\uff09\uff0c\u5e76\u8bbe\u8ba1\u4e86Minicode\u57fa\u51c6\uff0c\u5176\u8981\u6c42\u4ee3\u7801\u4ee3\u7406\u5c06\u591a\u4e2a\u76f8\u4e92\u72ec\u7acb\u7684\u89e3\u51b3\u65b9\u6848\u91cd\u6784\u4e3a\u4e00\u4e2a\u8054\u5408\u5e93\u3002", "result": "Librarian\u5728Minicode\u57fa\u51c6\u4e0a\uff0c\u5728\u4ee3\u7801\u538b\u7f29\u7387\uff08\u4ee3\u7801\u91cf\u51cf\u5c111.6-2\u500d\uff09\u548c\u6b63\u786e\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u9876\u5c16\u4ee3\u7801\u4ee3\u7406\u3002", "conclusion": "Librarian\u65b9\u6cd5\u4e3a\u4ee3\u7801\u81ea\u52a8\u91cd\u6784\u548c\u7ec4\u4ef6\u590d\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u65b0\u57fa\u51c6Minicode\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u4ef7\u503c\u3002\u76f8\u5173\u4ee3\u7801\u548c\u57fa\u51c6\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.11128", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11128", "abs": "https://arxiv.org/abs/2506.11128", "authors": ["Andrew Keenan Richardson", "Ryan Othniel Kearns", "Sean Moss", "Vincent Wang-Mascianica", "Philipp Koralus"], "title": "Stronger Language Models Produce More Human-Like Errors", "comment": null, "summary": "Do language models converge toward human-like reasoning patterns as they\nimprove? We provide surprising evidence that while overall reasoning\ncapabilities increase with model sophistication, the nature of errors\nincreasingly mirrors predictable human reasoning fallacies: a previously\nunobserved inverse scaling phenomenon. To investigate this question, we apply\nthe Erotetic Theory of Reasoning (ETR), a formal cognitive framework with\nempirical support for predicting human reasoning outcomes. Using the\nopen-source package PyETR, we generate logical reasoning problems where humans\npredictably err, evaluating responses from 38 language models across 383\nreasoning tasks. Our analysis indicates that as models advance in general\ncapability (as measured by Chatbot Arena scores), the proportion of their\nincorrect answers that align with ETR-predicted human fallacies tends to\nincrease ($\\rho = 0.360, p = 0.0265$). Notably, as we observe no correlation\nbetween model sophistication and logical correctness on these tasks, this shift\nin error patterns toward human-likeness occurs independently of error rate.\nThese findings challenge the prevailing view that scaling language models\nnaturally obtains normative rationality, suggesting instead a convergence\ntoward human-like cognition inclusive of our characteristic biases and\nlimitations, as we further confirm by demonstrating order-effects in language\nmodel reasoning.", "AI": {"tldr": "\u66f4\u5f3a\u5927\u7684\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u65f6\u9519\u8bef\u66f4\u50cf\u4eba\u7c7b\u72af\u7684\u9519\uff0c\u5373\u8868\u73b0\u51fa\u7279\u5f81\u6027\u7684\u4eba\u7c7b\u63a8\u7406\u504f\u89c1\uff0c\u8fd9\u79cd\u8d8b\u52bf\u4e0e\u6b63\u786e\u7387\u65e0\u5173\uff0c\u6311\u6218\u4e86\u6a21\u578b\u89c4\u6a21\u5e26\u6765\u7406\u6027\u5316\u7684\u4f20\u7edf\u89c2\u70b9\u3002", "motivation": "\u63a2\u7a76\u968f\u7740\u6a21\u578b\u80fd\u529b\u63d0\u5347\uff0c\u6a21\u578b\u7684\u63a8\u7406\u6a21\u5f0f\u662f\u5426\u8d8a\u6765\u8d8a\u63a5\u8fd1\u4eba\u7c7b\uff0c\u5305\u62ec\u5176\u6613\u72af\u9519\u8bef\u7c7b\u578b\uff0c\u68c0\u9a8c\u9884\u671f\u4e2d\u7684\u2018\u80fd\u529b\u589e\u5f3a\u5e26\u6765\u7406\u6027\u63d0\u5347\u2019\u5047\u8bbe\u3002", "method": "\u5e94\u7528Erotetic Theory of Reasoning\uff08ETR\uff09\u7406\u8bba\uff0c\u5229\u7528PyETR\u751f\u6210\u4e13\u95e8\u9488\u5bf9\u4eba\u7c7b\u5e38\u72af\u63a8\u7406\u9519\u8bef\u7684\u903b\u8f91\u9898\u76ee\uff0c\u5bf938\u79cd\u8bed\u8a00\u6a21\u578b\u5728383\u9879\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u7528Chatbot Arena\u5206\u6570\u6807\u5b9a\u6a21\u578b\u80fd\u529b\u3002", "result": "\u968f\u7740\u6a21\u578b\u80fd\u529b\u589e\u5f3a\uff0c\u5176\u9519\u8bef\u8d8a\u6765\u8d8a\u96c6\u4e2d\u4e8e\u4e0eETR\u9884\u6d4b\u7684\u4eba\u7c7b\u8c2c\u8bef\u4e00\u81f4\uff08\u76f8\u5173\u7cfb\u6570\u03c1=0.360, p=0.0265\uff09\uff0c\u4f46\u6a21\u578b\u80fd\u529b\u4e0e\u903b\u8f91\u6b63\u786e\u7387\u65e0\u660e\u663e\u76f8\u5173\uff0c\u8868\u660e\u2018\u4eba\u7c7b\u5316\u8c2c\u8bef\u2019\u7684\u4e0a\u5347\u4e0e\u6a21\u578b\u672c\u8eab\u6b63\u786e\u7387\u65e0\u5173\u3002\u6b64\u5916\u8fd8\u53d1\u73b0\u4e86\u987a\u5e8f\u6548\u5e94\u3002", "conclusion": "\u968f\u7740\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u63d0\u5347\uff0c\u5176\u9519\u8bef\u6a21\u5f0f\u8d8a\u6765\u8d8a\u63a5\u8fd1\u4eba\u7c7b\u7684\u63a8\u7406\u8c2c\u8bef\u3002\u8fd9\u79cd\u4eba\u7c7b\u5316\u7684\u9519\u8bef\u6a21\u5f0f\u4e0e\u6a21\u578b\u6574\u4f53\u6b63\u786e\u6027\u6ca1\u6709\u76f8\u5173\u6027\uff0c\u8868\u660e\u6a21\u578b\u4e0d\u662f\u8d8b\u5411\u2018\u7406\u6027\u5b8c\u7f8e\u2019\uff0c\u800c\u662f\u66f4\u50cf\u4eba\u7c7b\uff0c\u5305\u62ec\u4eba\u7c7b\u7684\u7279\u5f81\u6027\u504f\u89c1\u4e0e\u5c40\u9650\u3002"}}
{"id": "2506.11059", "categories": ["cs.SE", "cs.CL", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.11059", "abs": "https://arxiv.org/abs/2506.11059", "authors": ["Hanxi Guo", "Siyuan Cheng", "Kaiyuan Zhang", "Guangyu Shen", "Xiangyu Zhang"], "title": "CodeMirage: A Multi-Lingual Benchmark for Detecting AI-Generated and Paraphrased Source Code from Production-Level LLMs", "comment": null, "summary": "Large language models (LLMs) have become integral to modern software\ndevelopment, producing vast amounts of AI-generated source code. While these\nmodels boost programming productivity, their misuse introduces critical risks,\nincluding code plagiarism, license violations, and the propagation of insecure\nprograms. As a result, robust detection of AI-generated code is essential. To\nsupport the development of such detectors, a comprehensive benchmark that\nreflects real-world conditions is crucial. However, existing benchmarks fall\nshort -- most cover only a limited set of programming languages and rely on\nless capable generative models. In this paper, we present CodeMirage, a\ncomprehensive benchmark that addresses these limitations through three major\nadvancements: (1) it spans ten widely used programming languages, (2) includes\nboth original and paraphrased code samples, and (3) incorporates outputs from\nten state-of-the-art production-level LLMs, including both reasoning and\nnon-reasoning models from six major providers. Using CodeMirage, we evaluate\nten representative detectors across four methodological paradigms under four\nrealistic evaluation configurations, reporting results using three\ncomplementary metrics. Our analysis reveals nine key findings that uncover the\nstrengths and weaknesses of current detectors, and identify critical challenges\nfor future work. We believe CodeMirage offers a rigorous and practical testbed\nto advance the development of robust and generalizable AI-generated code\ndetectors.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CodeMirage\uff0c\u4e00\u5957\u8986\u76d6\u5341\u79cd\u7f16\u7a0b\u8bed\u8a00\u3001\u591a\u4e2a\u4e3b\u6d41LLM\u53ca\u590d\u8ff0\u6837\u672c\u7684\u5168\u9762AI\u4ee3\u7801\u68c0\u6d4b\u57fa\u51c6\uff0c\u7cfb\u7edf\u8bc4\u6d4b\u73b0\u6709\u68c0\u6d4b\u5668\u5e76\u63ed\u793a\u5173\u952e\u6311\u6218\uff0c\u4e3a\u540e\u7eed\u5065\u58ee\u3001\u901a\u7528\u7684AI\u4ee3\u7801\u68c0\u6d4b\u5668\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6491\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5e7f\u6cdb\u5e94\u7528\u4e8e\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\uff0cAI\u751f\u6210\u4ee3\u7801\u6570\u91cf\u6fc0\u589e\uff0c\u4f46\u540c\u65f6\u5e26\u6765\u4e86\u4ee3\u7801\u6284\u88ad\u3001\u8bb8\u53ef\u8bc1\u8fdd\u89c4\u548c\u4e0d\u5b89\u5168\u7a0b\u5e8f\u4f20\u64ad\u7b49\u91cd\u5927\u98ce\u9669\uff0c\u4e9f\u9700\u5f3a\u6709\u529b\u7684\u68c0\u6d4b\u6280\u672f\u3002\u73b0\u6709\u57fa\u51c6\u6570\u636e\u96c6\u8986\u76d6\u7f16\u7a0b\u8bed\u8a00\u6709\u9650\uff0c\u4e14\u591a\u4f9d\u8d56\u8001\u65e7\u6a21\u578b\uff0c\u65e0\u6cd5\u771f\u5b9e\u53cd\u6620\u5b9e\u9645\u73af\u5883\u3002", "method": "\u63d0\u51faCodeMirage\uff0c\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u5341\u79cd\u4e3b\u6d41\u7f16\u7a0b\u8bed\u8a00\uff0c\u5305\u542b\u539f\u59cb\u53ca\u590d\u8ff0\u4ee3\u7801\u6837\u672c\uff0c\u5e76\u6db5\u76d6\u6765\u81ea\u516d\u5927\u63d0\u4f9b\u5546\u7684\u5341\u4e2a\u6700\u5148\u8fdbLLM\uff08\u6db5\u76d6\u63a8\u7406\u4e0e\u975e\u63a8\u7406\u6a21\u578b\uff09\u3002\u5229\u7528CodeMirage\uff0c\u5bf9\u5341\u4e2a\u4ee3\u8868\u6027\u68c0\u6d4b\u5668\u5728\u56db\u79cd\u65b9\u6cd5\u8303\u5f0f\u548c\u56db\u7c7b\u771f\u5b9e\u8bc4\u4ef7\u914d\u7f6e\u4e0b\u8fdb\u884c\u8bc4\u6d4b\uff0c\u5e76\u4f7f\u7528\u4e09\u79cd\u4e92\u8865\u8bc4\u4f30\u6307\u6807\u7efc\u5408\u5206\u6790\u3002", "result": "\u8bc4\u6d4b\u63ed\u793a\u4e86\u4e5d\u9879\u5173\u952e\u53d1\u73b0\uff0c\u7cfb\u7edf\u5c55\u793a\u4e86\u73b0\u6709\u68c0\u6d4b\u5668\u7684\u4f18\u52a3\u52bf\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u9700\u91cd\u70b9\u89e3\u51b3\u7684\u6311\u6218\u3002CodeMirage\u4e3a\u5f00\u53d1\u5065\u58ee\u4e14\u901a\u7528\u7684AI\u751f\u6210\u4ee3\u7801\u68c0\u6d4b\u5668\u63d0\u4f9b\u4e86\u4e25\u683c\u4e14\u5b9e\u7528\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "conclusion": "CodeMirage\u6709\u6548\u5f25\u8865\u4e86\u5148\u524d\u57fa\u51c6\u7684\u4e0d\u8db3\uff0c\u4e3a\u63a8\u52a8\u9c81\u68d2\u3001\u901a\u7528AI\u4ee3\u7801\u68c0\u6d4b\u6280\u672f\u7684\u53d1\u5c55\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u57fa\u7840\uff0c\u5e76\u4e3a\u540e\u7eed\u76f8\u5173\u7814\u7a76\u8ffd\u8e2a\u548c\u6539\u8fdb\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2506.11129", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11129", "abs": "https://arxiv.org/abs/2506.11129", "authors": ["Carlos Garcia-Fernandez", "Luis Felipe", "Monique Shotande", "Muntasir Zitu", "Aakash Tripathi", "Ghulam Rasool", "Issam El Naqa", "Vivek Rudrapatna", "Gilmer Valdes"], "title": "Trustworthy AI for Medicine: Continuous Hallucination Detection and Elimination with CHECK", "comment": null, "summary": "Large language models (LLMs) show promise in healthcare, but hallucinations\nremain a major barrier to clinical use. We present CHECK, a continuous-learning\nframework that integrates structured clinical databases with a classifier\ngrounded in information theory to detect both factual and reasoning-based\nhallucinations. Evaluated on 1500 questions from 100 pivotal clinical trials,\nCHECK reduced LLama3.3-70B-Instruct hallucination rates from 31% to 0.3% -\nmaking an open source model state of the art. Its classifier generalized across\nmedical benchmarks, achieving AUCs of 0.95-0.96, including on the MedQA (USMLE)\nbenchmark and HealthBench realistic multi-turn medical questioning. By\nleveraging hallucination probabilities to guide GPT-4o's refinement and\njudiciously escalate compute, CHECK boosted its USMLE passing rate by 5\npercentage points, achieving a state-of-the-art 92.1%. By suppressing\nhallucinations below accepted clinical error thresholds, CHECK offers a\nscalable foundation for safe LLM deployment in medicine and other high-stakes\ndomains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CHECK\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e34\u5e8a\u6570\u636e\u5e93\u4e0e\u65b0\u578b\u5206\u7c7b\u5668\uff0c\u521b\u65b0\u6027\u5730\u6781\u5927\u964d\u4f4e\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u573a\u666f\u4e0b\u7684\u201c\u5e7b\u89c9\u201d\u7387\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5b89\u5168\u6027\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u5176\u5728\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u7684\u63a8\u5e7f\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u533b\u7597\u9886\u57df\u5177\u6709\u5f88\u5927\u6f5c\u529b\uff0c\u4f46\u5176\u5e7b\u89c9\uff08hallucination\uff09\u73b0\u8c61\uff0c\u5c24\u5176\u662f\u5728\u4e8b\u5b9e\u4e0e\u63a8\u7406\u65b9\u9762\u7684\u9519\u8bef\uff0c\u4e25\u91cd\u963b\u788d\u4e86\u5176\u5728\u4e34\u5e8a\u4e2d\u7684\u5e94\u7528\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u5173\u952e\u6311\u6218\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86CHECK\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u79cd\u6301\u7eed\u5b66\u4e60\u7cfb\u7edf\uff0c\u5c06\u7ed3\u6784\u5316\u4e34\u5e8a\u6570\u636e\u5e93\u4e0e\u57fa\u4e8e\u4fe1\u606f\u7406\u8bba\u7684\u5206\u7c7b\u5668\u7ed3\u5408\uff0c\u7528\u4e8e\u68c0\u6d4b\u4e8b\u5b9e\u548c\u63a8\u7406\u5c42\u9762\u7684\u5e7b\u89c9\u3002\u6b64\u5916\uff0cCHECK\u53ef\u5229\u7528\u5e7b\u89c9\u6982\u7387\u5f15\u5bfcGPT-4o\u7684\u7b54\u6848\u4f18\u5316\u548c\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\u3002", "result": "\u5728\u5bf9\u6765\u81ea100\u9879\u5173\u952e\u4e34\u5e8a\u8bd5\u9a8c\u76841500\u4e2a\u95ee\u9898\u7684\u6d4b\u8bd5\u4e2d\uff0cCHECK\u5c06LLama3.3-70B-Instruct\u7684\u5e7b\u89c9\u7387\u4ece31%\u663e\u8457\u964d\u4f4e\u81f30.3%\uff0c\u4f7f\u5f00\u6e90\u6a21\u578b\u8fbe\u5230\u4e1a\u754c\u9886\u5148\u6c34\u5e73\u3002\u5176\u5206\u7c7b\u5668\u5728\u4e0d\u540c\u533b\u5b66\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u79c0\uff0cAUC\u4e3a0.95-0.96\u3002\u5728USMLE\u7684MedQA\u548cHealthBench\u7b49\u591a\u56de\u5408\u533b\u7597\u95ee\u7b54\u57fa\u51c6\u4e0a\u8868\u73b0\u5f3a\u52b2\u3002\u901a\u8fc7\u5f15\u5bfcGPT-4o\uff0cUSMLE\u7684\u901a\u8fc7\u7387\u63d0\u53475\u4e2a\u767e\u5206\u70b9\uff0c\u8fbe\u523092.1%\u3002", "conclusion": "CHECK\u6846\u67b6\u6781\u5927\u63d0\u5347\u4e86LLMs\u5728\u533b\u5b66\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u7684\u5b89\u5168\u6027\u4e0e\u53ef\u9760\u6027\uff0c\u6709\u671b\u63a8\u8fdb\u5176\u5728\u4e34\u5e8a\u4e2d\u7684\u5927\u89c4\u6a21\u90e8\u7f72\u3002"}}
{"id": "2506.11060", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11060", "abs": "https://arxiv.org/abs/2506.11060", "authors": ["Ramneet Singh", "Sathvik Joel", "Abhav Mehrotra", "Nalin Wadhwa", "Ramakrishna B Bairi", "Aditya Kanade", "Nagarajan Natarajan"], "title": "Code Researcher: Deep Research Agent for Large Systems Code and Commit History", "comment": null, "summary": "Large Language Model (LLM)-based coding agents have shown promising results\non coding benchmarks, but their effectiveness on systems code remains\nunderexplored. Due to the size and complexities of systems code, making changes\nto a systems codebase is a daunting task, even for humans. It requires\nresearching about many pieces of context, derived from the large codebase and\nits massive commit history, before making changes. Inspired by the recent\nprogress on deep research agents, we design the first deep research agent for\ncode, called Code Researcher, and apply it to the problem of generating patches\nfor mitigating crashes reported in systems code. Code Researcher performs\nmulti-step reasoning about semantics, patterns, and commit history of code to\ngather sufficient context. The context is stored in a structured memory which\nis used for synthesizing a patch. We evaluate Code Researcher on kBenchSyz, a\nbenchmark of Linux kernel crashes, and show that it significantly outperforms\nstrong baselines, achieving a crash-resolution rate of 58%, compared to 37.5%\nby SWE-agent. On an average, Code Researcher explores 10 files in each\ntrajectory whereas SWE-agent explores only 1.33 files, highlighting Code\nResearcher's ability to deeply explore the codebase. Through another experiment\non an open-source multimedia software, we show the generalizability of Code\nResearcher. Our experiments highlight the importance of global context\ngathering and multi-faceted reasoning for large codebases.", "AI": {"tldr": "\u9488\u5bf9\u7cfb\u7edf\u4ee3\u7801\uff08\u5982Linux\u5185\u6838\uff09\u4fee\u590d\u4efb\u52a1\uff0c\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86Code Researcher\u2014\u2014\u4e00\u79cd\u57fa\u4e8e\u591a\u6b65\u63a8\u7406\u548c\u7ed3\u6784\u5316\u8bb0\u5fc6\u7684\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\uff0c\u80fd\u591f\u66f4\u6709\u6548\u6536\u96c6\u5168\u5c40\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u5d29\u6e83\u4fee\u590d\u7387\uff0858% vs 37.5%\uff09\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4ee3\u7801\u4ee3\u7406\u5728\u5e38\u89c4\u7f16\u7801\u57fa\u51c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u7cfb\u7edf\u4ee3\u7801\uff08\u5982\u5927\u578b\u64cd\u4f5c\u7cfb\u7edf\u5185\u6838\u7684\u4ee3\u7801\uff09\u7684\u6709\u6548\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u7cfb\u7edf\u4ee3\u7801\u89c4\u6a21\u5e9e\u5927\u4e14\u590d\u6742\uff0c\u5373\u4f7f\u5bf9\u4e8e\u4eba\u7c7b\u800c\u8a00\uff0c\u505a\u51fa\u4ee3\u7801\u4fee\u6539\u4e5f\u9887\u5177\u6311\u6218\uff0c\u9700\u8981\u5728\u5927\u89c4\u6a21\u4ee3\u7801\u53ca\u5176\u4e30\u5bcc\u63d0\u4ea4\u5386\u53f2\u4e2d\u68c0\u7d22\u5927\u91cf\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002\u8be5\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u7cfb\u7edf\u4ee3\u7801\u4e2d\u4fee\u8865\u7531\u5d29\u6e83\u9519\u8bef\u5f15\u53d1\u7684\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCode Researcher\u7684'\u6df1\u5ea6\u7814\u7a76\u578b\u4ee3\u7801\u4ee3\u7406'\u7cfb\u7edf\u3002\u5176\u6838\u5fc3\u65b9\u6cd5\u5305\u62ec\uff1a\u901a\u8fc7\u591a\u6b65\u63a8\u7406\u7406\u89e3\u4ee3\u7801\u8bed\u4e49\u3001\u6a21\u5f0f\u4e0e\u5386\u53f2\uff0c\u4e3b\u52a8\u6536\u96c6\u4e0e\u95ee\u9898\u76f8\u5173\u7684\u5168\u5c40\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5e76\u5b58\u50a8\u4e8e\u7ed3\u6784\u5316\u5185\u5b58\u4e2d\u7528\u4e8e\u540e\u7eed\u8865\u4e01\u5408\u6210\u3002\u8be5\u65b9\u6cd5\u88ab\u5e94\u7528\u4e8e\u9488\u5bf9\u7cfb\u7edf\u4ee3\u7801\uff08\u5982Linux\u5185\u6838\uff09\u5d29\u6e83\u8865\u4e01\u751f\u6210\u3002", "result": "\u5728Linux\u5185\u6838\u5d29\u6e83kBenchSyz\u57fa\u51c6\u4e0a\uff0cCode Researcher\u5b9e\u73b0\u4e8658%\u7684\u5d29\u6e83\u4fee\u590d\u7387\uff0c\u663e\u8457\u9ad8\u4e8eSWE-agent\u768437.5%\u3002\u5728\u6bcf\u6b21\u4fee\u590d\u6d41\u7a0b\u4e2d\uff0cCode Researcher\u5e73\u5747\u63a2\u7d2210\u4e2a\u6587\u4ef6\uff0c\u800cSWE-agent\u4ec5\u4e3a1.33\u4e2a\uff0c\u660e\u663e\u793a\u51fa\u5176\u5bf9\u5927\u89c4\u6a21\u4ee3\u7801\u5e93\u7684\u6df1\u5ea6\u63a2\u7d22\u80fd\u529b\u3002\u5176\u6cdb\u5316\u5b9e\u9a8c\uff08\u5982\u5728\u5f00\u6e90\u591a\u5a92\u4f53\u8f6f\u4ef6\u4e0a\u7684\u5b9e\u9a8c\uff09\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u826f\u597d\u7684\u901a\u7528\u6027\u3002", "conclusion": "Code Researcher\u5c55\u73b0\u4e86\u5bf9\u590d\u6742\u7cfb\u7edf\u4ee3\u7801\u5e93\u6df1\u5ea6\u63a8\u7406\u4e0e\u5168\u5c40\u4e0a\u4e0b\u6587\u6536\u96c6\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u4fee\u590d\u5d29\u6e83\u8865\u4e01\u7684\u6210\u529f\u7387\uff0c\u5176\u65b9\u6cd5\u4e0e\u67b6\u6784\u4e3aLLM\u5728\u66f4\u590d\u6742\u7f16\u7a0b\u4efb\u52a1\u4e0a\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u8303\u4f8b\u3002\u5168\u5c40\u4e0a\u4e0b\u6587\u4f18\u5316\u548c\u591a\u5143\u63a8\u7406\u673a\u5236\u5bf9\u4e8e\u5927\u578b\u4ee3\u7801\u5e93\u7684\u95ee\u9898\u89e3\u51b3\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2506.11130", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.11130", "abs": "https://arxiv.org/abs/2506.11130", "authors": ["Cheng Kang Chou", "Chan-Jan Hsu", "Ho-Lam Chung", "Liang-Hsuan Tseng", "Hsi-Chun Cheng", "Yu-Kuan Fu", "Kuan Po Huang", "Hung-Yi Lee"], "title": "A Self-Refining Framework for Enhancing ASR Using TTS-Synthesized Data", "comment": null, "summary": "We propose a self-refining framework that enhances ASR performance with only\nunlabeled datasets. The process starts with an existing ASR model generating\npseudo-labels on unannotated speech, which are then used to train a\nhigh-fidelity text-to-speech (TTS) system. Then, synthesized speech text pairs\nare bootstrapped into the original ASR system, completing the closed-loop\nself-improvement cycle. We demonstrated the effectiveness of the framework on\nTaiwanese Mandarin speech. Leveraging 6,000 hours of unlabeled speech, a\nmoderate amount of text data, and synthetic content from the AI models, we\nadapt Whisper-large-v2 into a specialized model, Twister. Twister reduces error\nrates by up to 20% on Mandarin and 50% on Mandarin-English code-switching\nbenchmarks compared to Whisper. Results highlight the framework as a compelling\nalternative to pseudo-labeling self-distillation approaches and provides a\npractical pathway for improving ASR performance in low-resource or\ndomain-specific settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u7684ASR\u81ea\u6211\u589e\u5f3a\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f2a\u6807\u7b7e\u5faa\u73af\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5bf9\u6bd4\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u9519\u8bef\u7387\u663e\u8457\u964d\u4f4e\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4f4e\u8d44\u6e90\u573a\u666f\u3002", "motivation": "\u5f53\u524dASR\uff08\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff09\u7cfb\u7edf\u5728\u4f4e\u8d44\u6e90\u6216\u7279\u5b9a\u9886\u57df\u4e0b\u8868\u73b0\u53d7\u9650\uff0c\u56e0\u7f3a\u4e4f\u6807\u6ce8\u8bed\u97f3\u6570\u636e\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u3001\u6709\u6548\u5229\u7528\u65e0\u6807\u6ce8\u6570\u636e\u7684\u529e\u6cd5\u6539\u8fdbASR\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u81ea\u6211\u589e\u5f3a\uff08self-refining\uff09\u5faa\u73af\u6846\u67b6\uff1a\u9996\u5148\u7528\u73b0\u6709ASR\u6a21\u578b\u4e3a\u672a\u6807\u6ce8\u8bed\u97f3\u751f\u6210\u4f2a\u6807\u7b7e\uff0c\u7136\u540e\u7528\u8fd9\u4e9b\u4f2a\u6807\u7b7e\u8bad\u7ec3\u9ad8\u4fdd\u771fTTS\uff08\u6587\u672c\u8f6c\u8bed\u97f3\uff09\u7cfb\u7edf\uff0c\u518d\u7528\u5408\u6210\u7684\u8bed\u97f3-\u6587\u672c\u5bf9\u53cd\u54fa\u539fASR\u6a21\u578b\uff0c\u5f62\u6210\u95ed\u73af\u81ea\u6211\u6539\u8fdb\u3002", "result": "\u5728\u53f0\u6e7e\u666e\u901a\u8bdd\u8bed\u97f3\u6570\u636e\u4e0a\uff0c\u75286000\u5c0f\u65f6\u65e0\u6807\u6ce8\u8bed\u97f3\u3001\u4e00\u5b9a\u91cf\u6587\u672c\u548c\u5408\u6210\u5185\u5bb9\uff0c\u5bf9Whisper-large-v2\u6a21\u578b\u8fdb\u884c\u81ea\u9002\u5e94\u8bad\u7ec3\uff0c\u5f97\u5230\u4e13\u7528ASR\u6a21\u578bTwister\u3002Twister\u5728\u666e\u901a\u8bdd\u4e0a\u9519\u8bef\u7387\u964d\u4f4e20%\uff0c\u5728\u4e2d\u82f1\u6df7\u5408\u6d4b\u8bd5\u4e0a\u9519\u8bef\u7387\u964d\u4f4e50%\u3002", "conclusion": "\u8be5\u81ea\u6211\u589e\u5f3a\u6846\u67b6\u4e3a\u4f4e\u8d44\u6e90\u6216\u9886\u57df\u5b9a\u5236\u7684ASR\u6027\u80fd\u63d0\u5347\u63d0\u4f9b\u4e86\u4e00\u6761\u6709\u6548\u9014\u5f84\uff0c\u4f18\u4e8e\u4f20\u7edf\u4f2a\u6807\u7b7e\u81ea\u84b8\u998f\u65b9\u6cd5\u3002"}}
{"id": "2506.11066", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11066", "abs": "https://arxiv.org/abs/2506.11066", "authors": ["Jiahui Geng", "Fengyu Cai", "Shaobo Cui", "Qing Li", "Liangwei Chen", "Chenyang Lyu", "Haonan Li", "Derui Zhu", "Walter Pretschner", "Heinz Koeppl", "Fakhri Karray"], "title": "CoQuIR: A Comprehensive Benchmark for Code Quality-Aware Information Retrieval", "comment": null, "summary": "Code retrieval is essential in modern software development, as it boosts code\nreuse and accelerates debugging. However, current benchmarks primarily\nemphasize functional relevance while neglecting critical dimensions of software\nquality. Motivated by this gap, we introduce CoQuIR, the first large-scale,\nmultilingual benchmark specifically designed to evaluate quality-aware code\nretrieval across four key dimensions: correctness, efficiency, security, and\nmaintainability. CoQuIR provides fine-grained quality annotations for 42,725\nqueries and 134,907 code snippets in 11 programming languages, and is\naccompanied by two quality-centric evaluation metrics: Pairwise Preference\nAccuracy and Margin-based Ranking Score. Using CoQuIR, we benchmark 23\nretrieval models, covering both open-source and proprietary systems, and find\nthat even top-performing models frequently fail to distinguish buggy or\ninsecure code from their more robust counterparts. Furthermore, we conduct\npreliminary investigations into training methods that explicitly encourage\nretrievers to recognize code quality. Using synthetic datasets, we demonstrate\npromising improvements in quality-aware metrics across various models, without\nsacrificing semantic relevance. Downstream code generation experiments further\nvalidate the effectiveness of our approach. Overall, our work highlights the\nimportance of integrating quality signals into code retrieval systems, laying\nthe groundwork for more trustworthy and robust software development tools.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u5173\u6ce8\u8d28\u91cf\u7684CoQuIR\u57fa\u51c6\uff0c\u5bf9\u4e3b\u6d41\u6a21\u578b\u8fdb\u884c\u8bc4\u6d4b\uff0c\u5e76\u901a\u8fc7\u65b0\u8bad\u7ec3\u65b9\u6cd5\u63d0\u5347\u4e86\u6a21\u578b\u8bc6\u522b\u4ee3\u7801\u8d28\u91cf\u7684\u80fd\u529b\uff0c\u4e3a\u53ef\u9760\u8f6f\u4ef6\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u73b0\u6709\u7684\u4ee3\u7801\u68c0\u7d22\u57fa\u51c6\u8fc7\u4e8e\u6ce8\u91cd\u529f\u80fd\u76f8\u5173\u6027\uff0c\u800c\u5ffd\u89c6\u4e86\u4ee3\u7801\u8d28\u91cf\u7684\u5173\u952e\u7ef4\u5ea6\uff0c\u5982\u6b63\u786e\u6027\u3001\u6548\u7387\u3001\u5b89\u5168\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u3002\u4f5c\u8005\u5e0c\u671b\u89e3\u51b3\u8fd9\u4e00\u7f3a\u53e3\uff0c\u63a8\u52a8\u4ee3\u7801\u68c0\u7d22\u7cfb\u7edf\u671d\u66f4\u9ad8\u8d28\u91cf\u6807\u51c6\u53d1\u5c55\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86CoQuIR\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u9762\u5411\u591a\u8bed\u8a00\u7684\u3001\u8d28\u91cf\u611f\u77e5\u7684\u4ee3\u7801\u68c0\u7d22\u57fa\u51c6\uff0c\u6db5\u76d611\u79cd\u7f16\u7a0b\u8bed\u8a00\u3002CoQuIR\u4e3a42,725\u4e2a\u67e5\u8be2\u548c134,907\u4e2a\u4ee3\u7801\u7247\u6bb5\u63d0\u4f9b\u4e86\u7ec6\u7c92\u5ea6\u7684\u8d28\u91cf\u6ce8\u91ca\uff0c\u5e76\u5f15\u5165\u4e86\u4e24\u4e2a\u65b0\u7684\u8d28\u91cf\u8bc4\u4f30\u6307\u6807\u3002\u4f5c\u8005\u8fd8\u8bc4\u6d4b\u4e8623\u79cd\u4e3b\u6d41\u68c0\u7d22\u6a21\u578b\uff0c\u5e76\u63a2\u7d22\u4e86\u901a\u8fc7\u7279\u5b9a\u8bad\u7ec3\u65b9\u6cd5\u63d0\u5347\u6a21\u578b\u8d28\u91cf\u8bc6\u522b\u80fd\u529b\u7684\u6548\u679c\u3002", "result": "\u73b0\u6709\u4ee3\u7801\u68c0\u7d22\u6a21\u578b\u5f88\u96be\u6709\u6548\u533a\u5206\u5b58\u5728\u7f3a\u9677\u6216\u5b89\u5168\u9690\u60a3\u7684\u4ee3\u7801\u4e0e\u9ad8\u8d28\u91cf\u4ee3\u7801\u3002\u901a\u8fc7\u5408\u6210\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u65b0\u65b9\u6cd5\uff0c\u5728\u4e0d\u635f\u5931\u8bed\u4e49\u76f8\u5173\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u8d28\u91cf\u76f8\u5173\u6307\u6807\u4e0a\u7684\u8868\u73b0\u3002\u76f8\u5173\u7684\u4e0b\u6e38\u4ee3\u7801\u751f\u6210\u5b9e\u9a8c\u4e5f\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8bba\u6587\u5f3a\u8c03\u4e86\u628a\u4ee3\u7801\u8d28\u91cf\u4fe1\u53f7\u878d\u5165\u4ee3\u7801\u68c0\u7d22\u7cfb\u7edf\u7684\u91cd\u8981\u610f\u4e49\uff0c\u5e76\u4e3a\u672a\u6765\u66f4\u53ef\u9760\u7684\u8f6f\u4ef6\u5f00\u53d1\u5de5\u5177\u6253\u4e0b\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.11135", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2506.11135", "abs": "https://arxiv.org/abs/2506.11135", "authors": ["David C. Krakauer", "John W. Krakauer", "Melanie Mitchell"], "title": "Large Language Models and Emergence: A Complex Systems Perspective", "comment": null, "summary": "Emergence is a concept in complexity science that describes how many-body\nsystems manifest novel higher-level properties, properties that can be\ndescribed by replacing high-dimensional mechanisms with lower-dimensional\neffective variables and theories. This is captured by the idea \"more is\ndifferent\". Intelligence is a consummate emergent property manifesting\nincreasingly efficient -- cheaper and faster -- uses of emergent capabilities\nto solve problems. This is captured by the idea \"less is more\". In this paper,\nwe first examine claims that Large Language Models exhibit emergent\ncapabilities, reviewing several approaches to quantifying emergence, and\nsecondly ask whether LLMs possess emergent intelligence.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u5e76\u5206\u6790\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u662f\u5426\u5177\u5907\u590d\u6742\u6027\u79d1\u5b66\u610f\u4e49\u4e0a\u7684\u6d8c\u73b0\u80fd\u529b\u53ca\u667a\u80fd\uff0c\u6bd4\u8f83\u548c\u56de\u987e\u4e86\u5f53\u524d\u76f8\u5173\u7684\u91cf\u5316\u6807\u51c6\u548c\u7814\u7a76\u8fdb\u5c55\uff0c\u6307\u51fa\u5c1a\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "motivation": "\u590d\u6742\u6027\u79d1\u5b66\u4e2d\u7684\u6d8c\u73b0\u6982\u5ff5\u7528\u4e8e\u89e3\u91ca\u591a\u4f53\u7cfb\u7edf\u51fa\u73b0\u65b0\u9896\u9ad8\u5c42\u6027\u8d28\u7684\u73b0\u8c61\uff0c\u4eba\u5de5\u667a\u80fd\u5c24\u5176\u662fLLMs\u58f0\u79f0\u5c55\u73b0\u51fa\u6d8c\u73b0\u667a\u80fd\uff0c\u6709\u5fc5\u8981\u7cfb\u7edf\u68b3\u7406\u4e0e\u9a8c\u8bc1\u8fd9\u4e00\u547d\u9898\u3002", "method": "\u56de\u987e\u4e0e\u5206\u6790\u5f53\u524d\u8bc4\u4f30LLMs\u6d8c\u73b0\u80fd\u529b\u7684\u91cf\u5316\u65b9\u6cd5\u4e0e\u7406\u8bba\uff0c\u6839\u636e\u590d\u6742\u6027\u79d1\u5b66\u7684\u6d8c\u73b0\u7406\u8bba\u63d0\u51fa\u8bc4\u5224\u6807\u51c6\u3002", "result": "\u7efc\u8ff0\u4e86\u82e5\u5e72\u8bc4\u4f30LLMs\u662f\u5426\u5177\u5907\u6d8c\u73b0\u80fd\u529b\u7684\u65b9\u6cd5\u3001\u8861\u91cf\u6307\u6807\u53ca\u5176\u667a\u80fd\u6027\uff0c\u6307\u51fa\u9886\u57df\u5185\u5173\u4e8e\u2018\u6d8c\u73b0\u667a\u80fd\u2019\u7684\u8ba8\u8bba\u4ecd\u5728\u6301\u7eed\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7406\u8bba\u548c\u5b9e\u8bc1\u7814\u7a76\u3002", "conclusion": "\u672c\u6587\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u662f\u5426\u5c55\u73b0\u4e86\u6d8c\u73b0\u80fd\u529b\u53ca\u667a\u80fd\u6027\uff0c\u5e76\u63d0\u51fa\u6709\u5fc5\u8981\u8fdb\u4e00\u6b65\u63a2\u7a76\u548c\u91cf\u5316LLMs\u7684\u6d8c\u73b0\u7279\u6027\u548c\u667a\u80fd\u8868\u73b0\u3002"}}
{"id": "2506.11076", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11076", "abs": "https://arxiv.org/abs/2506.11076", "authors": ["Minyu Chen", "Guoqiang Li", "Ling-I Wu", "Ruibang Liu"], "title": "DCE-LLM: Dead Code Elimination with Large Language Models", "comment": "Accepted by regular paper in NAACL 2025, with 13 pages, 5 figures", "summary": "Dead code introduces several challenges in software development, such as\nincreased binary size and maintenance difficulties. It can also obscure logical\nerrors and be exploited for obfuscation in malware. For LLM-based code-related\ntasks, dead code introduces vulnerabilities that can mislead these models,\nraising security concerns. Although modern compilers and IDEs offer dead code\nelimination, sophisticated patterns can bypass these tools. A universal\napproach that includes classification, location, explanation, and correction is\nneeded, yet current tools often require significant manual effort. We present\nDCE-LLM, a framework for automated dead code elimination using a small CodeBERT\nmodel with an attribution-based line selector to efficiently locate suspect\ncode. LLMs then generate judgments and explanations, fine-tuned on a\nlarge-scale, annotated dead code dataset to provide detailed explanations and\npatches. DCE-LLM outperforms existing tools, with advanced unreachability\ndetection, automated correction, and support for multiple programming\nlanguages. Experimental results show DCE-LLM achieves over 94% F1 scores for\nunused and unreachable code, significantly surpassing GPT-4o by 30%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDCE-LLM\u6846\u67b6\uff0c\u7ed3\u5408\u5c0f\u578bCodeBERT\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u9ad8\u6548\u3001\u81ea\u52a8\u5730\u68c0\u6d4b\u3001\u89e3\u91ca\u53ca\u4fee\u590d\u591a\u8bed\u8a00\u4ee3\u7801\u4e2d\u7684\u6b7b\u4ee3\u7801\uff0c\u5b9e\u9a8c\u6027\u80fd\u5168\u9762\u80dc\u8fc7GPT-4o\uff0c\u5b9e\u73b0\u66f4\u9ad8\u51c6\u786e\u7387\u4e0e\u81ea\u52a8\u5316\u3002", "motivation": "\u6b7b\u4ee3\u7801\u4e0d\u4ec5\u5bfc\u81f4\u53ef\u6267\u884c\u6587\u4ef6\u4f53\u79ef\u589e\u5927\u3001\u7ef4\u62a4\u56f0\u96be\uff0c\u8fd8\u53ef\u80fd\u9690\u85cf\u903b\u8f91\u9519\u8bef\uff0c\u88ab\u6076\u610f\u5229\u7528\u7528\u4e8e\u6df7\u6dc6\uff0c\u5c24\u5176\u5728\u57fa\u4e8e\u5927\u6a21\u578b\uff08LLM\uff09\u7684\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\u4e2d\uff0c\u6b7b\u4ee3\u7801\u4f1a\u5e72\u6270\u6a21\u578b\u5224\u65ad\uff0c\u9020\u6210\u5b89\u5168\u9690\u60a3\u3002\u73b0\u6709\u6b7b\u4ee3\u7801\u68c0\u6d4b\u5de5\u5177\u81ea\u52a8\u5316\u7a0b\u5ea6\u4e0d\u9ad8\uff0c\u590d\u6742\u573a\u666f\u4e0b\u6548\u679c\u6709\u9650\uff0c\u4f9d\u8d56\u8f83\u591a\u4eba\u5de5\u4ecb\u5165\u3002", "method": "\u63d0\u51fa\u4e86DCE-LLM\u6846\u67b6\uff0c\u7ed3\u5408\u5c0f\u578bCodeBERT\u6a21\u578b\u548c\u57fa\u4e8e\u5f52\u56e0\u7684\u884c\u9009\u62e9\u5668\u81ea\u52a8\u5b9a\u4f4d\u7591\u4f3c\u6b7b\u4ee3\u7801\uff0c\u518d\u5229\u7528\u7ecf\u8fc7\u5927\u89c4\u6a21\u6b7b\u4ee3\u7801\u6570\u636e\u96c6\u5fae\u8c03\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u5224\u522b\u3001\u89e3\u91ca\u548c\u4fee\u590d\u6b7b\u4ee3\u7801\u3002DCE-LLM\u4e0d\u4ec5\u68c0\u6d4b\u66f4\u590d\u6742\u7684\u4e0d\u53ef\u8fbe\u4ee3\u7801\uff0c\u8fd8\u80fd\u81ea\u52a8\u4fee\u590d\u5e76\u652f\u6301\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u3002", "result": "DCE-LLM\u5728\u5b9e\u9a8c\u4e2d\u5bf9\u672a\u4f7f\u7528\u548c\u4e0d\u53ef\u8fbe\u4ee3\u7801\u7684F1\u5206\u6570\u5747\u8d85\u8fc794%\uff0c\u6bd4GPT-4o\u9ad8\u51fa30%\uff0c\u5728\u6b7b\u4ee3\u7801\u68c0\u6d4b\u3001\u89e3\u91ca\u548c\u4fee\u6b63\u65b9\u9762\u5168\u9762\u8d85\u8d8a\u73b0\u6709\u5de5\u5177\u3002", "conclusion": "DCE-LLM\u663e\u8457\u63d0\u5347\u4e86\u6b7b\u4ee3\u7801\u81ea\u52a8\u68c0\u6d4b\u548c\u4fee\u590d\u7684\u51c6\u786e\u6027\u4e0e\u6548\u7387\uff0c\u53ef\u6709\u6548\u89e3\u51b3\u73b0\u6709\u5de5\u5177\u7684\u5c40\u9650\uff0c\u4e3a\u591a\u8bed\u8a00\u4ee3\u7801\u5904\u7406\u63d0\u4f9b\u4e86\u5f3a\u5927\u652f\u6301\u3002"}}
{"id": "2506.11137", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11137", "abs": "https://arxiv.org/abs/2506.11137", "authors": ["Chong Shao", "Douglas Snyder", "Chiran Li", "Bowen Gu", "Kerry Ngan", "Chun-Ting Yang", "Jiageng Wu", "Richard Wyss", "Kueiyu Joshua Lin", "Jie Yang"], "title": "Scalable Medication Extraction and Discontinuation Identification from Electronic Health Records Using Large Language Models", "comment": "preprint, under review", "summary": "Identifying medication discontinuations in electronic health records (EHRs)\nis vital for patient safety but is often hindered by information being buried\nin unstructured notes. This study aims to evaluate the capabilities of advanced\nopen-sourced and proprietary large language models (LLMs) in extracting\nmedications and classifying their medication status from EHR notes, focusing on\ntheir scalability on medication information extraction without human\nannotation. We collected three EHR datasets from diverse sources to build the\nevaluation benchmark. We evaluated 12 advanced LLMs and explored multiple LLM\nprompting strategies. Performance on medication extraction, medication status\nclassification, and their joint task (extraction then classification) was\nsystematically compared across all experiments. We found that LLMs showed\npromising performance on the medication extraction and discontinuation\nclassification from EHR notes. GPT-4o consistently achieved the highest average\nF1 scores in all tasks under zero-shot setting - 94.0% for medication\nextraction, 78.1% for discontinuation classification, and 72.7% for the joint\ntask. Open-sourced models followed closely, Llama-3.1-70B-Instruct achieved the\nhighest performance in medication status classification on the MIV-Med dataset\n(68.7%) and in the joint task on both the Re-CASI (76.2%) and MIV-Med (60.2%)\ndatasets. Medical-specific LLMs demonstrated lower performance compared to\nadvanced general-domain LLMs. Few-shot learning generally improved performance,\nwhile CoT reasoning showed inconsistent gains. LLMs demonstrate strong\npotential for medication extraction and discontinuation identification on EHR\nnotes, with open-sourced models offering scalable alternatives to proprietary\nsystems and few-shot can further improve LLMs' capability.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u591a\u79cdLLM\u5728\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u6761\u4ef6\u4e0b\uff0c\u4eceEHR\u81ea\u7531\u6587\u672c\u4e2d\u81ea\u52a8\u63d0\u53d6\u836f\u7269\u53ca\u5176\u505c\u7528\u72b6\u6001\u7684\u80fd\u529b\u3002\u7ed3\u679c\u663e\u793a\uff0c\u5305\u62ec\u5f00\u6e90\u6a21\u578b\u5728\u5185\u7684LLM\u6709\u671b\u9ad8\u6548\u52a9\u529b\u4e34\u5e8a\u4fe1\u606f\u6316\u6398\uff0c\u63d0\u5347\u60a3\u8005\u5b89\u5168\u3002", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u4e2d\u836f\u7269\u505c\u7528\u7684\u4fe1\u606f\u5e38\u5e38\u9690\u85cf\u4e8e\u975e\u7ed3\u6784\u5316\u75c5\u7a0b\u8bb0\u5f55\u4e2d\uff0c\u59a8\u788d\u4e86\u60a3\u8005\u5b89\u5168\u3002\u8be5\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u7684\u60c5\u51b5\u4e0b\uff0c\u4eceEHR\u81ea\u7531\u6587\u672c\u4e2d\u63d0\u53d6\u836f\u7269\u4fe1\u606f\u5e76\u5206\u7c7b\u5176\u72b6\u6001\u7684\u80fd\u529b\u3002", "method": "\u8be5\u7814\u7a76\u6536\u96c6\u4e86\u4e09\u4e2a\u4e0d\u540c\u6765\u6e90\u7684EHR\u6570\u636e\u96c6\u4f5c\u4e3a\u8bc4\u6d4b\u57fa\u51c6\uff0c\u7cfb\u7edf\u6027\u5730\u6bd4\u8f83\u4e8612\u79cd\u5148\u8fdb\u7684LLM\uff08\u5305\u62ec\u5f00\u6e90\u4e0e\u4e13\u6709\uff09\u5728\u836f\u7269\u63d0\u53d6\u3001\u836f\u7269\u72b6\u6001\u5206\u7c7b\u53ca\u8054\u5408\u4efb\u52a1\uff08\u5148\u63d0\u53d6\u540e\u5206\u7c7b\uff09\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u6d4b\u8bd5\u4e86\u591a\u79cdLLM\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\uff0c\u5305\u62eczero-shot\u548cfew-shot\u3002", "result": "GPT-4o\u5728\u96f6\u6837\u672c\uff08zero-shot\uff09\u8bbe\u5b9a\u4e0b\u4e8e\u6240\u6709\u4efb\u52a1\u4e2d\u5747\u53d6\u5f97\u6700\u9ad8\u7684\u5e73\u5747F1\u5206\u6570\uff08\u836f\u7269\u63d0\u53d694.0%\u3001\u505c\u836f\u5206\u7c7b78.1%\u3001\u8054\u5408\u4efb\u52a172.7%\uff09\u3002\u5f00\u6e90\u6a21\u578b\u5982Llama-3.1-70B-Instruct\u5728\u67d0\u4e9b\u4efb\u52a1\u548c\u6570\u636e\u96c6\u4e0a\u4e5f\u8868\u73b0\u7a81\u51fa\u3002\u533b\u5b66\u4e13\u7528LLM\u6574\u4f53\u8868\u73b0\u4e0d\u5982\u901a\u7528LLM\u3002\u5c11\u6837\u672c\u5b66\u4e60\u4e00\u822c\u80fd\u63d0\u5347\u6548\u679c\uff0c\u94fe\u5f0f\u601d\u8003\uff08CoT\uff09\u589e\u76ca\u4e0d\u7a33\u5b9a\u3002", "conclusion": "LLM\u80fd\u6709\u6548\u4eceEHR\u81ea\u7531\u6587\u672c\u4e2d\u63d0\u53d6\u836f\u7269\u53ca\u5176\u505c\u7528\u4fe1\u606f\uff0c\u5f00\u6e90\u6a21\u578b\u4e3a\u4e13\u6709\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u7ade\u4e89\u529b\u548c\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5c11\u6837\u672c\u5b66\u4e60\u53ef\u8fdb\u4e00\u6b65\u63d0\u9ad8\u8868\u73b0\u3002"}}
{"id": "2506.11084", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11084", "abs": "https://arxiv.org/abs/2506.11084", "authors": ["Yordan Kalmukov"], "title": "Research and Analysis of Employers' Opinion on the Necessary Skills that Students in the Field of Web Programming Should Possess", "comment": null, "summary": "In the era of artificial intelligence (AI) and chatbots, based on large\nlanguage models that can generate programming code in any language, write texts\nand summarize information, it is obvious that the requirements of employers for\ngraduating students have already changed. The modern IT world offers\nsignificant automation of programming through software frameworks and a huge\nset of third-party libraries and application programming interfaces (APIs). All\nthese tools provide most of the necessary functionality out of the box (already\nimplemented), and quite naturally the question arises as to what is more useful\nfor students - to teach how to use these ready-made tools or the basic\nprinciples of working and development of web applications from scratch. This\npaper analyzes the results of a survey conducted among IT employers, aimed to\nidentify what, in their opinion, are the necessary technical skills that\ngraduating students in the field of Web Programming should possess in order to\njoin the company's work as quickly and effectively as possible.", "AI": {"tldr": "AI\u548c\u81ea\u52a8\u5316\u5de5\u5177\u6539\u53d8\u4e86IT\u4f01\u4e1a\u5bf9\u6bd5\u4e1a\u751f\u6280\u80fd\u7684\u8981\u6c42\u3002\u672c\u6587\u901a\u8fc7\u5bf9\u96c7\u4e3b\u8c03\u7814\uff0c\u5206\u6790\u5e94\u91cd\u89c6\u6559\u6388\u54ea\u4e9bWeb\u7f16\u7a0b\u6280\u80fd\uff0c\u4e3a\u9ad8\u6821\u8bfe\u7a0b\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53c2\u8003\u3002", "motivation": "\u968f\u7740AI\u548c\u804a\u5929\u673a\u5668\u4eba\u7b49\u6280\u672f\u7684\u53d1\u5c55\uff0c\u96c7\u4e3b\u5bf9IT\u6bd5\u4e1a\u751f\u7684\u6280\u80fd\u8981\u6c42\u53d1\u751f\u4e86\u53d8\u5316\u3002\u5f53\u524d\u5927\u91cf\u81ea\u52a8\u5316\u5de5\u5177\u548c\u7b2c\u4e09\u65b9\u5e93\u51cf\u5c11\u4e86\u4ece\u96f6\u5f00\u53d1\u7684\u9700\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u8ba8\u5b66\u751f\u5e94\u91cd\u70b9\u5b66\u4e60\u54ea\u7c7b\u6280\u80fd\u3002", "method": "\u901a\u8fc7\u5bf9IT\u96c7\u4e3b\u8fdb\u884c\u95ee\u5377\u8c03\u67e5\uff0c\u5206\u6790\u4ed6\u4eec\u8ba4\u4e3a\u6bd5\u4e1a\u751f\u5e94\u5177\u5907\u7684Web\u7f16\u7a0b\u9886\u57df\u6280\u672f\u6280\u80fd\uff0c\u4ee5\u4fbf\u6bd5\u4e1a\u751f\u80fd\u66f4\u5feb\u3001\u66f4\u6709\u6548\u5730\u9002\u5e94\u4f01\u4e1a\u5de5\u4f5c\u3002", "result": "\u8c03\u67e5\u7ed3\u679c\u63ed\u793a\u4e86\u96c7\u4e3b\u66f4\u770b\u91cd\u6bd5\u4e1a\u751f\u638c\u63e1\u54ea\u4e9b\u5177\u4f53\u6280\u80fd\uff0c\u4f46\u5177\u4f53\u6280\u80fd\u7ec6\u8282\u9700\u53c2\u8003\u5168\u6587\u3002\u6574\u4f53\u6765\u770b\uff0c\u5f3a\u8c03\u4e86\u5b9e\u7528\u5de5\u5177\u5e94\u7528\u4e0e\u57fa\u7840\u539f\u7406\u5b66\u4e60\u4e4b\u95f4\u7684\u6743\u8861\u3002", "conclusion": "Web\u7f16\u7a0b\u6559\u80b2\u9700\u8981\u6839\u636e\u4ea7\u4e1a\u9700\u6c42\u8c03\u6574\u6559\u5b66\u5185\u5bb9\uff0c\u65e2\u8981\u5173\u6ce8\u4f7f\u7528\u73b0\u4ee3\u5de5\u5177\u6846\u67b6\uff0c\u4e5f\u4e0d\u80fd\u5ffd\u89c6\u57fa\u7840\u539f\u7406\u7684\u6559\u5b66\uff0c\u4ee5\u63d0\u5347\u6bd5\u4e1a\u751f\u7684\u5c31\u4e1a\u9002\u5e94\u529b\u3002"}}
{"id": "2506.11243", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11243", "abs": "https://arxiv.org/abs/2506.11243", "authors": ["Santiago G\u00f3ngora", "Ignacio Sastre", "Santiago Robaina", "Ignacio Remersaro", "Luis Chiruzzo", "Aiala Ros\u00e1"], "title": "RETUYT-INCO at BEA 2025 Shared Task: How Far Can Lightweight Models Go in AI-powered Tutor Evaluation?", "comment": "This paper will be presented at the 20th BEA Workshop (Innovative Use\n  of NLP for Building Educational Applications) at ACL 2025", "summary": "In this paper, we present the RETUYT-INCO participation at the BEA 2025\nshared task. Our participation was characterized by the decision of using\nrelatively small models, with fewer than 1B parameters. This self-imposed\nrestriction tries to represent the conditions in which many research labs or\ninstitutions are in the Global South, where computational power is not easily\naccessible due to its prohibitive cost. Even under this restrictive\nself-imposed setting, our models managed to stay competitive with the rest of\nteams that participated in the shared task. According to the $exact\\ F_1$\nscores published by the organizers, the performance gaps between our models and\nthe winners were as follows: $6.46$ in Track 1; $10.24$ in Track 2; $7.85$ in\nTrack 3; $9.56$ in Track 4; and $13.13$ in Track 5. Considering that the\nminimum difference with a winner team is $6.46$ points -- and the maximum\ndifference is $13.13$ -- according to the $exact\\ F_1$ score, we find that\nmodels with a size smaller than 1B parameters are competitive for these tasks,\nall of which can be run on computers with a low-budget GPU or even without a\nGPU.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9a8c\u8bc1\u4e86\u5728\u7b97\u529b\u53d7\u9650\u73af\u5883\u4e0b\uff08\u5c0f\u4e8e1B\u53c2\u6570\u7684\u5c0f\u6a21\u578b\uff09\uff0c\u4f9d\u7136\u80fd\u5728BEA 2025\u4efb\u52a1\u4e2d\u53d6\u5f97\u5177\u6709\u7ade\u4e89\u529b\u7684\u6210\u7ee9\uff0c\u4e3a\u4f4e\u7b97\u529b\u5730\u533a\u7684AI\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301\u3002", "motivation": "\u5168\u7403\u5357\u65b9\u8bb8\u591a\u7814\u7a76\u673a\u6784\u7531\u4e8e\u7b97\u529b\u6210\u672c\u9ad8\u6602\uff0c\u65e0\u6cd5\u4f7f\u7528\u5927\u89c4\u6a21\u6a21\u578b\u3002\u4e3a\u4f53\u73b0\u8fd9\u4e9b\u5b9e\u9645\u7814\u7a76\u73af\u5883\uff0c\u4f5c\u8005\u51b3\u5b9a\u4f7f\u7528\u53c2\u6570\u91cf\u4f4e\u4e8e1B\u7684\u5c0f\u6a21\u578b\u53c2\u8d5b\u3002", "method": "\u91c7\u7528\u53c2\u6570\u91cf\u5c0f\u4e8e1B\u7684\u6a21\u578b\u53c2\u4e0eBEA 2025\u5171\u4eab\u4efb\u52a1\uff0c\u5e76\u5c06\u5176\u6027\u80fd\u4e0e\u5176\u4ed6\u53c2\u8d5b\u961f\u4f0d\u8fdb\u884c\u6bd4\u8f83\uff0c\u91cd\u70b9\u5173\u6ce8\u5b9e\u9645\u53ef\u7528\u7b97\u529b\u8f83\u4f4e\u60c5\u51b5\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u5373\u4f7f\u5728\u6a21\u578b\u4ec5\u5c0f\u4e8e1B\u53c2\u6570\u7684\u9650\u5236\u4e0b\uff0c\u5176\u8868\u73b0\u4e0e\u83b7\u80dc\u961f\u4f0d\u7684exact F1\u5206\u6570\u5dee\u8ddd\u57286.46\u523013.13\u70b9\u4e4b\u95f4\uff0c\u5404\u9879\u4efb\u52a1\u5747\u663e\u793a\u5c0f\u6a21\u578b\u5728\u4f4e\u7b97\u529b\u8bbe\u5907\u4e0a\u5177\u5907\u7ade\u4e89\u529b\u3002", "conclusion": "\u4f4e\u4e8e1B\u53c2\u6570\u7684\u5c0f\u578b\u6a21\u578b\u5728\u591a\u9879NLP\u4efb\u52a1\u4e2d\u4ecd\u5177\u5907\u7ade\u4e89\u529b\uff0c\u80fd\u5728\u4f4e\u9884\u7b97GPU\u751a\u81f3\u65e0GPU\u73af\u5883\u4e2d\u8fd0\u884c\uff0c\u4e3a\u7b97\u529b\u6709\u9650\u5730\u533a\u7684\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2506.11244", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11244", "abs": "https://arxiv.org/abs/2506.11244", "authors": ["Shun Shao", "Yftah Ziser", "Zheng Zhao", "Yifu Qiu", "Shay B. Cohen", "Anna Korhonen"], "title": "Iterative Multilingual Spectral Attribute Erasure", "comment": "8 pages, 3 figures", "summary": "Multilingual representations embed words with similar meanings to share a\ncommon semantic space across languages, creating opportunities to transfer\ndebiasing effects between languages. However, existing methods for debiasing\nare unable to exploit this opportunity because they operate on individual\nlanguages. We present Iterative Multilingual Spectral Attribute Erasure\n(IMSAE), which identifies and mitigates joint bias subspaces across multiple\nlanguages through iterative SVD-based truncation. Evaluating IMSAE across eight\nlanguages and five demographic dimensions, we demonstrate its effectiveness in\nboth standard and zero-shot settings, where target language data is\nunavailable, but linguistically similar languages can be used for debiasing.\nOur comprehensive experiments across diverse language models (BERT, LLaMA,\nMistral) show that IMSAE outperforms traditional monolingual and cross-lingual\napproaches while maintaining model utility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u8bed\u8a00\u8054\u5408\u53bb\u504f\u65b0\u65b9\u6cd5IMSAE\uff0c\u80fd\u6709\u6548\u63d0\u5347\u5404\u7c7b\u4e3b\u6d41\u6a21\u578b\u7684\u516c\u5e73\u6027\uff0c\u5e76\u652f\u6301zero-shot\u573a\u666f\uff0c\u4f18\u4e8e\u4f20\u7edf\u5355\u8bed\u4e0e\u8de8\u8bed\u65b9\u6cd5\u3002", "motivation": "\u5728\u591a\u8bed\u8a00\u8bcd\u5411\u91cf\u4e2d\uff0c\u542b\u4e49\u76f8\u4f3c\u7684\u8bcd\u901a\u5e38\u4f1a\u88ab\u5d4c\u5165\u5230\u5171\u4eab\u8bed\u4e49\u7a7a\u95f4\uff0c\u8fd9\u4e3a\u4e0d\u540c\u8bed\u8a00\u4e4b\u95f4\u7684\u504f\u89c1\u6d88\u9664\uff08debias\uff09\u6548\u679c\u8fc1\u79fb\u5e26\u6765\u4e86\u53ef\u80fd\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u53bb\u504f\u65b9\u6cd5\u4ec5\u5728\u5355\u4e00\u8bed\u8a00\u4e2d\u8fdb\u884c\uff0c\u672a\u80fd\u5229\u7528\u591a\u8bed\u8a00\u5171\u4eab\u7a7a\u95f4\u7684\u4f18\u52bf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8fed\u4ee3\u591a\u8bed\u8a00\u8c31\u5c5e\u6027\u6d88\u9664\uff08Iterative Multilingual Spectral Attribute Erasure, IMSAE\uff09\u7684\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u57fa\u4e8e\u5947\u5f02\u503c\u5206\u89e3\uff08SVD\uff09\u7684\u8fed\u4ee3\u622a\u65ad\uff0c\u8bc6\u522b\u5e76\u51cf\u5f31\u591a\u4e2a\u8bed\u8a00\u4e2d\u7684\u8054\u5408\u504f\u89c1\u5b50\u7a7a\u95f4\u3002", "result": "\u5728\u516b\u79cd\u8bed\u8a00\u548c\u4e94\u4e2a\u4eba\u53e3\u5b66\u7ef4\u5ea6\u4e0a\u8bc4\u4f30\u4e86IMSAE\u3002\u5b9e\u9a8c\u6db5\u76d6BERT\u3001LLaMA\u3001Mistral\u7b49\u591a\u79cd\u4e3b\u6d41\u8bed\u8a00\u6a21\u578b\u3002\u65e0\u8bba\u5728\u6807\u51c6\u8fd8\u662fzero-shot\uff08\u76ee\u6807\u8bed\u8a00\u6570\u636e\u4e0d\u53ef\u7528\uff0c\u4ec5\u7528\u76f8\u4f3c\u8bed\u8a00\u53bb\u504f\uff09\u8bbe\u7f6e\u4e0b\uff0cIMSAE\u5747\u4f18\u4e8e\u73b0\u6709\u5355\u8bed\u548c\u8de8\u8bed\u53bb\u504f\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u5b9e\u7528\u6027\u3002", "conclusion": "IMSAE\u80fd\u591f\u6709\u6548\u8bc6\u522b\u5e76\u7f13\u89e3\u591a\u8bed\u8a00\u8054\u5408\u504f\u89c1\uff0c\u4e14\u4f18\u4e8e\u4f20\u7edf\u53bb\u504f\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u4e3a\u591a\u8bed\u8a00\u6a21\u578b\u7684\u516c\u5e73\u6027\u63d0\u5347\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u5c24\u5176\u5728\u76ee\u6807\u8bed\u8a00\u65e0\u8d44\u6e90\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2506.11107", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11107", "abs": "https://arxiv.org/abs/2506.11107", "authors": ["Weibo Gao", "Qi Liu", "Rui Li", "Yuze Zhao", "Hao Wang", "Linan Yre", "Fangzhou Yao", "Zheng Zhang"], "title": "Denoising Programming Knowledge Tracing with a Code Graph-based Tuning Adaptor", "comment": "Accepted by KDD August 2025", "summary": "Programming Knowledge Tracking (PKT) aims to dynamically diagnose learners'\nmastery levels of programming knowledge based on their coding activities,\nfacilitating more effective and personalized programming education. However,\ncurrent PKT studies primarily focus on the implicit relationship between code\ncontent and knowledge assessment, often overlooking two types of noise signals\nin long-term programming activities: unwanted signals from unrelated\nsubmissions and weak signals from minor modifications. This practical challenge\nsignificantly limits model performance and application. To address this issue,\nwe propose Coda, a Code graph-based tuning adaptor designed to enhance existing\nPKT models by identifying and mitigating the impact of noise. Specifically,\nCoda first transforms the loose code sequences submitted by each learner into a\ncompact code graph. By leveraging this code graph, unwanted signals can be\nidentified from a semantic similarity perspective. We then apply a\ncluster-aware GCN to the code graph, which improves the discrimination of weak\nsignals and enables their clustering for identification. Finally, a lightweight\nyet effective adaptor is incorporated into the PKT task through optimization\nwith two noise feature-based constraints and a navigational regularization\nterm, to correct knowledge states affected by noise. It is worth mentioning\nthat the Coda framework is model-agnostic and can be adapted to most existing\nPKT solutions. Extensive experimental results on four real-world datasets\ndemonstrate that Coda effectively performs the PKT task in the presence of\nnoisy programming records, outperforming typical baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Coda\uff0c\u4e00\u79cd\u901a\u8fc7\u4ee3\u7801\u56fe\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\u51cf\u7f13\u7f16\u7a0b\u5b66\u4e60\u4e2d\u566a\u97f3\u5f71\u54cd\u7684\u9002\u914d\u5668\uff0c\u63d0\u5347\u4e86\u7f16\u7a0b\u77e5\u8bc6\u8ffd\u8e2a\u7684\u7cbe\u5ea6\u548c\u7a33\u5065\u6027\uff0c\u4e14\u80fd\u9002\u914d\u591a\u79cd\u4e3b\u6d41\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u7f16\u7a0b\u77e5\u8bc6\u8ffd\u8e2a\uff08PKT\uff09\u4e3b\u8981\u901a\u8fc7\u5206\u6790\u4ee3\u7801\u5185\u5bb9\u9690\u5f0f\u5730\u8bc4\u4f30\u5b66\u4e60\u8005\u77e5\u8bc6\u6c34\u5e73\uff0c\u4f46\u5f80\u5f80\u5ffd\u89c6\u4e86\u957f\u671f\u5b66\u4e60\u6d3b\u52a8\u4e2d\u7684\u4e24\u7c7b\u566a\u97f3\uff1a\u6765\u81ea\u4e0d\u76f8\u5173\u63d0\u4ea4\u7684\u65e0\u6548\u4fe1\u53f7\u4ee5\u53ca\u6765\u81ea\u5c0f\u4fee\u6539\u7684\u5f31\u4fe1\u53f7\uff0c\u8fd9\u5f71\u54cd\u4e86\u6a21\u578b\u8868\u73b0\u548c\u5e94\u7528\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86Coda\uff0c\u4e00\u79cd\u57fa\u4e8e\u4ee3\u7801\u56fe\u7684\u8c03\u6574\u9002\u914d\u5668\u3002Coda\u9996\u5148\u5c06\u5b66\u4e60\u8005\u63d0\u4ea4\u7684\u4ee3\u7801\u5e8f\u5217\u8f6c\u5316\u4e3a\u7d27\u51d1\u7684\u4ee3\u7801\u56fe\uff0c\u5e76\u901a\u8fc7\u8bed\u4e49\u76f8\u4f3c\u5ea6\u8bc6\u522b\u65e0\u5173\u4fe1\u53f7\u3002\u7136\u540e\u5bf9\u4ee3\u7801\u56fe\u5e94\u7528\u96c6\u7fa4\u611f\u77e5\u7684\u56fe\u5377\u79ef\u7f51\u7edc\uff08GCN\uff09\u4ee5\u63d0\u5347\u5f31\u4fe1\u53f7\u7684\u8fa8\u522b\u5e76\u5b9e\u73b0\u805a\u7c7b\u3002\u6700\u540e\uff0c\u8bbe\u8ba1\u4e86\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\uff0c\u901a\u8fc7\u4e24\u4e2a\u57fa\u4e8e\u566a\u97f3\u7279\u5f81\u7684\u7ea6\u675f\u548c\u4e00\u4e2a\u5b9a\u5411\u6b63\u5219\u9879\u8fdb\u884c\u4f18\u5316\uff0c\u5c06\u5176\u96c6\u6210\u5230PKT\u4efb\u52a1\u4e2d\uff0c\u4ee5\u4fee\u6b63\u53d7\u5230\u566a\u97f3\u5f71\u54cd\u7684\u77e5\u8bc6\u72b6\u6001\u3002\u8be5\u65b9\u6cd5\u53ef\u9002\u914d\u4e8e\u5927\u591a\u6570\u73b0\u6709PKT\u6a21\u578b\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCoda\u80fd\u6709\u6548\u63d0\u5347PKT\u4efb\u52a1\u5728\u566a\u58f0\u4ee3\u7801\u8bb0\u5f55\u4e0b\u7684\u51c6\u786e\u6027\uff0c\u663e\u8457\u8d85\u8fc7\u5178\u578b\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "Coda\u6846\u67b6\u80fd\u591f\u8bc6\u522b\u5e76\u51cf\u5f31\u7f16\u7a0b\u8bb0\u5f55\u4e2d\u7684\u566a\u97f3\u4fe1\u53f7\uff0c\u6709\u6548\u63d0\u5347\u4e86\u7f16\u7a0b\u77e5\u8bc6\u8ffd\u8e2a\u7684\u53ef\u9760\u6027\u548c\u9002\u5e94\u6027\uff0c\u5177\u5907\u5e7f\u6cdb\u7684\u6a21\u578b\u9002\u7528\u6027\u3002"}}
{"id": "2506.11246", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11246", "abs": "https://arxiv.org/abs/2506.11246", "authors": ["Kushagra Dixit", "Abhishek Rajgaria", "Harshavardhan Kalalbandi", "Dan Roth", "Vivek Gupta"], "title": "No Universal Prompt: Unifying Reasoning through Adaptive Prompting for Temporal Table Reasoning", "comment": "21 pages, 19 Tables, 9 Figures", "summary": "Temporal Table Reasoning is a critical challenge for Large Language Models\n(LLMs), requiring effective prompting techniques to extract relevant insights.\nDespite existence of multiple prompting methods, their impact on table\nreasoning remains largely unexplored. Furthermore, the performance of these\nmodels varies drastically across different table and context structures, making\nit difficult to determine an optimal approach. This work investigates multiple\nprompting technique across diverse table types to determine optimal approaches\nfor different scenarios. We find that performance varies based on entity type,\ntable structure, requirement of additional context and question complexity,\nwith NO single method consistently outperforming others. To mitigate these\nchallenges, we introduce SEAR, an adaptive prompting framework inspired by\nhuman reasoning that dynamically adjusts based on context characteristics and\nintegrates a structured reasoning. Our results demonstrate that SEAR achieves\nsuperior performance across all table types compared to other baseline\nprompting techniques. Additionally, we explore the impact of table structure\nrefactoring, finding that a unified representation enhances model's reasoning.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u65f6\u5e8f\u8868\u683c\u63a8\u7406\u4e2d\u7684\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u65b9\u6cd5\uff0c\u53d1\u73b0\u65e0\u4e07\u80fd\u7b56\u7565\u3002\u63d0\u51fa\u53d7\u4eba\u7c7b\u63a8\u7406\u542f\u53d1\u7684SEAR\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u5404\u79cd\u8868\u683c\u7c7b\u578b\u4e0b\u7684\u6a21\u578b\u63a8\u7406\u8868\u73b0\u3002\u540c\u65f6\uff0c\u7edf\u4e00\u7684\u8868\u683c\u7ed3\u6784\u8868\u8fbe\u4e5f\u6709\u52a9\u4e8e\u589e\u5f3a\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u5e8f\u8868\u683c\u63a8\u7406\u4efb\u52a1\u4e2d\u9762\u4e34\u663e\u8457\u6311\u6218\uff0c\u800c\u73b0\u6709\u7684\u591a\u79cd\u63d0\u793a\u65b9\u6cd5\u5728\u8868\u683c\u63a8\u7406\u4e2d\u7684\u6709\u6548\u6027\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002\u540c\u65f6\uff0c\u6a21\u578b\u5728\u4e0d\u540c\u7c7b\u578b\u8868\u683c\u548c\u4e0a\u4e0b\u6587\u7ed3\u6784\u4e0b\u7684\u8868\u73b0\u5dee\u5f02\u8f83\u5927\uff0c\u7f3a\u4e4f\u7edf\u4e00\u6700\u4f73\u89e3\u6cd5\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u7814\u7a76\u548c\u6bd4\u8f83\u591a\u79cd\u63d0\u793a\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u65b0\u7684\u81ea\u9002\u5e94\u65b9\u6cd5\u4ee5\u63d0\u5347\u63a8\u7406\u8868\u73b0\u3002", "method": "\u672c\u6587\u7cfb\u7edf\u8003\u5bdf\u5e76\u6bd4\u5bf9\u4e86\u591a\u79cd\u9002\u7528\u4e8e\u8868\u683c\u63a8\u7406\u4efb\u52a1\u7684\u63d0\u793a\u6280\u5de7\u3002\u4f5c\u8005\u8fdb\u4e00\u6b65\u8bbe\u8ba1\u4e86SEAR\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u53d7\u4eba\u7c7b\u63a8\u7406\u542f\u53d1\uff0c\u80fd\u591f\u6839\u636e\u4e0a\u4e0b\u6587\u7279\u6027\u52a8\u6001\u8c03\u6574\u63d0\u793a\u7b56\u7565\uff0c\u5e76\u7ed3\u5408\u7ed3\u6784\u5316\u63a8\u7406\u3002\u540c\u65f6\uff0c\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u8868\u683c\u7ed3\u6784\u91cd\u6784\u5bf9\u63a8\u7406\u8868\u73b0\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0d\u540c\u7684\u65b9\u6cd5\u5728\u4e0d\u540c\u5b9e\u4f53\u7c7b\u578b\u3001\u8868\u683c\u7ed3\u6784\u3001\u662f\u5426\u9700\u8981\u989d\u5916\u4e0a\u4e0b\u6587\u548c\u95ee\u9898\u590d\u6742\u5ea6\u4e0b\u8868\u73b0\u5dee\u5f02\u660e\u663e\uff0c\u65e0\u5355\u4e00\u65b9\u6cd5\u59cb\u7ec8\u5360\u4f18\u3002\u6240\u63d0\u51fa\u7684SEAR\u81ea\u9002\u5e94\u6846\u67b6\u5728\u6240\u6709\u8868\u683c\u7c7b\u578b\u4e0a\u90fd\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u63d0\u793a\u65b9\u6cd5\u3002\u7edf\u4e00\u5316\u7684\u8868\u683c\u7ed3\u6784\u8868\u8fbe\u5219\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6a21\u578b\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "SEAR\u65b9\u6cd5\u5177\u5907\u8f83\u5f3a\u7684\u901a\u7528\u6027\u548c\u81ea\u9002\u5e94\u6027\uff0c\u53ef\u4ee5\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6837\u5316\u65f6\u5e8f\u8868\u683c\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6574\u4f53\u8868\u73b0\u3002\u5408\u7406\u7684\u8868\u683c\u7ed3\u6784\u91cd\u6784\u540c\u6837\u5bf9\u6a21\u578b\u63a8\u7406\u6709\u79ef\u6781\u4f5c\u7528\u3002"}}
{"id": "2506.11141", "categories": ["cs.SE", "cs.ET"], "pdf": "https://arxiv.org/pdf/2506.11141", "abs": "https://arxiv.org/abs/2506.11141", "authors": ["Philippe J. Giabbanelli", "John Beverley", "Istvan David", "Andreas Tolk"], "title": "From over-reliance to smart integration: using Large-Language Models as translators between specialized modeling and simulation tools", "comment": "Accepted at the Winter Simulation conference 2025, December, Seattle\n  USA", "summary": "Large Language Models (LLMs) offer transformative potential for Modeling &\nSimulation (M&S) through natural language interfaces that simplify workflows.\nHowever, over-reliance risks compromising quality due to ambiguities, logical\nshortcuts, and hallucinations. This paper advocates integrating LLMs as\nmiddleware or translators between specialized tools to mitigate complexity in\nM&S tasks. Acting as translators, LLMs can enhance interoperability across\nmulti-formalism, multi-semantics, and multi-paradigm systems. We address two\nkey challenges: identifying appropriate languages and tools for modeling and\nsimulation tasks, and developing efficient software architectures that\nintegrate LLMs without performance bottlenecks. To this end, the paper explores\nLLM-mediated workflows, emphasizes structured tool integration, and recommends\nLow-Rank Adaptation-based architectures for efficient task-specific\nadaptations. This approach ensures LLMs complement rather than replace\nspecialized tools, fostering high-quality, reliable M&S processes.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4e2d\u95f4\u4ef6\u4e0e\u4e13\u4e1a\u5efa\u6a21\u4eff\u771f\u5de5\u5177\u534f\u4f5c\uff0c\u89e3\u51b3\u590d\u6742\u6027\u548c\u8d28\u91cf\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u9ad8\u6548\u67b6\u6784\uff0c\u786e\u4fddLLMs\u63d0\u5347\u800c\u975e\u66ff\u4ee3M&S\u6d41\u7a0b\u3002", "motivation": "\u867d\u7136LLMs\u80fd\u7528\u81ea\u7136\u8bed\u8a00\u7b80\u5316M&S\u6d41\u7a0b\uff0c\u4f46\u8fc7\u5ea6\u4f9d\u8d56\u4f1a\u9020\u6210\u8d28\u91cf\u4e0b\u964d\uff08\u5982\u903b\u8f91\u6f0f\u6d1e\u4e0e\u5e7b\u89c9\uff09\u3002\u63d0\u5347LLMs\u4e0e\u5de5\u5177\u7684\u4e92\u64cd\u4f5c\u6027\u53ef\u517c\u987e\u7b80\u5316\u4e0e\u9ad8\u8d28\u91cf\u3002", "method": "\u63a2\u7d22LLM\u4f5c\u4e3a\u7ffb\u8bd1\u8005\u7684\u5e94\u7528\u573a\u666f\uff0c\u8bc6\u522b\u5408\u9002\u7684\u5de5\u5177\u4e0e\u67b6\u6784\uff1b\u63d0\u51fa\u5229\u7528Low-Rank Adaptation\u7b49\u9ad8\u6548\u8f6f\u4ef6\u67b6\u6784\u96c6\u6210LLMs\uff0c\u5f3a\u8c03\u7ed3\u6784\u5316\u96c6\u6210\u53ca\u4efb\u52a1\u4e13\u7528\u9ad8\u6548\u9002\u914d\u3002", "result": "\u9a8c\u8bc1\u901a\u8fc7\u7ed3\u6784\u5316\u3001\u5206\u5de5\u660e\u786e\u7684\u4e2d\u95f4\u4ef6\u67b6\u6784\uff0c\u5f15\u5165LLMs\u80fd\u89e3\u51b3\u8bed\u8a00\u4e0e\u5de5\u5177\u9009\u62e9\u96be\u9898\uff0c\u5e76\u63d0\u51fa\u907f\u514d\u6027\u80fd\u74f6\u9888\u7684\u67b6\u6784\u5efa\u8bae\u3002\u8be5\u96c6\u6210\u65b9\u6cd5\u4fdd\u6301\u8d28\u91cf\u4e0e\u6548\u7387\u4f18\u52bf\u3002", "conclusion": "\u8be5\u8bba\u6587\u8ba4\u4e3aLLMs\u5e94\u4f5c\u4e3a\u6865\u6881/\u4e2d\u95f4\u4ef6\u4e0e\u4e13\u4e1a\u5efa\u6a21\u4eff\u771f\uff08M&S\uff09\u5de5\u5177\u534f\u4f5c\uff0c\u800c\u975e\u66ff\u4ee3\uff0c\u4ee5\u63d0\u5347\u7cfb\u7edf\u7684\u4e92\u64cd\u4f5c\u6027\u4e0e\u53ef\u9760\u6027\u3002"}}
{"id": "2506.11274", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.11274", "abs": "https://arxiv.org/abs/2506.11274", "authors": ["Liran Ringel", "Elad Tolochinsky", "Yaniv Romano"], "title": "Learning a Continue-Thinking Token for Enhanced Test-Time Scaling", "comment": null, "summary": "Test-time scaling has emerged as an effective approach for improving language\nmodel performance by utilizing additional compute at inference time. Recent\nstudies have shown that overriding end-of-thinking tokens (e.g., replacing\n\"</think>\" with \"Wait\") can extend reasoning steps and improve accuracy. In\nthis work, we explore whether a dedicated continue-thinking token can be\nlearned to trigger extended reasoning. We augment a distilled version of\nDeepSeek-R1 with a single learned \"<|continue-thinking|>\" token, training only\nits embedding via reinforcement learning while keeping the model weights\nfrozen. Our experiments show that this learned token achieves improved accuracy\non standard math benchmarks compared to both the baseline model and a test-time\nscaling approach that uses a fixed token (e.g., \"Wait\") for budget forcing. In\nparticular, we observe that in cases where the fixed-token approach enhances\nthe base model's accuracy, our method achieves a markedly greater improvement.\nFor example, on the GSM8K benchmark, the fixed-token approach yields a 1.3%\nabsolute improvement in accuracy, whereas our learned-token method achieves a\n4.2% improvement over the base model that does not use budget forcing.", "AI": {"tldr": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e00\u4e2a\u65b0\u7684\u7ee7\u7eed\u601d\u8003token\uff0c\u53ef\u4ee5\u8ba9\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u4fee\u6539\u4e3b\u6a21\u578b\u6743\u91cd\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u5347\u63a8\u7406\u80fd\u529b\u548c\u51c6\u786e\u7387\uff0c\u6548\u679c\u4f18\u4e8e\u7b80\u5355\u5730\u7528\u56fa\u5b9a\u8bcd\u89e6\u53d1\u63a8\u7406\u6269\u5c55\u3002", "motivation": "\u63a8\u7406\u80fd\u529b\u5bf9\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5df2\u6709\u7814\u7a76\u8868\u660e\u901a\u8fc7\u66ff\u6362\u201c\u601d\u8003\u7ed3\u675f\u201d\u6807\u8bb0\u80fd\u5ef6\u957f\u63a8\u7406\u8fc7\u7a0b\u3001\u83b7\u5f97\u66f4\u597d\u51c6\u786e\u7387\u3002\u672c\u7814\u7a76\u5173\u6ce8\u80fd\u5426\u901a\u8fc7\u5b66\u4e60\u4e13\u7528\u201c\u7ee7\u7eed\u601d\u8003\u201d\u6807\u8bb0\u6765\u66f4\u667a\u80fd\u5730\u89e6\u53d1\u989d\u5916\u63a8\u7406\u3002", "method": "\u4f5c\u8005\u5728DeepSeek-R1\u84b8\u998f\u7248\u57fa\u7840\u4e0a\uff0c\u589e\u52a0\u4e86\u4e00\u4e2a\u4e13\u7528\u7684\u201c<|continue-thinking|>\u201d\u6807\u8bb0\uff0c\u4ec5\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8fd9\u4e2atoken\u7684embedding\uff0c\u4e14\u56fa\u5b9a\u5176\u4f59\u6a21\u578b\u53c2\u6570\u3002\u901a\u8fc7\u4e0e\u4f7f\u7528\u56fa\u5b9atoken\uff08\u5982\u201cWait\u201d\uff09\u8fdb\u884c\u9884\u7b97\u5f3a\u8feb\u7684\u6d4b\u8bd5\u65f6\u95f4\u6269\u5c55\u65b9\u6848\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5b66\u4e60\u5f97\u5230\u7684continue-thinking token\u5728\u6807\u51c6\u6570\u5b66\u57fa\u51c6\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u7387\u63d0\u5347\uff0c\u660e\u663e\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u548c\u5355\u7eaf\u4f7f\u7528\u56fa\u5b9atoken\u7684\u65b9\u6cd5\u3002\u7279\u522b\u662f\u5728\u56fa\u5b9atoken\u65b9\u6848\u672c\u8eab\u5bf9\u51c6\u786e\u7387\u6709\u6240\u63d0\u5347\u7684\u57fa\u51c6\u4e0a\uff0c\u5b66\u4e60token\u7684\u65b9\u6cd5\u53ef\u83b7\u5f97\u66f4\u5927\u7684\u589e\u76ca\u3002\u4f8b\u5982\u5728GSM8K\u4efb\u52a1\u4e0a\uff0c\u56fa\u5b9atoken\u63d0\u53471.3%\uff0c\u800c\u5b66\u4e60token\u80fd\u5e26\u67654.2%\u7684\u7edd\u5bf9\u63d0\u5347\u3002", "conclusion": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u4e13\u7528\u201c\u7ee7\u7eed\u601d\u8003\u201dtoken\u53ef\u4ee5\u5728\u65e0\u9700\u8c03\u6574\u4e3b\u6a21\u578b\u6743\u91cd\u7684\u524d\u63d0\u4e0b\uff0c\u66f4\u6709\u6548\u5730\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u56fa\u5b9atoken\u6269\u5c55\u65b9\u6cd5\u3002"}}
{"id": "2506.11153", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.11153", "abs": "https://arxiv.org/abs/2506.11153", "authors": ["Changxin Ke", "Rui Zhang", "Shuo Wang", "Li Ding", "Guangli Li", "Yuanbo Wen", "Shuoming Zhang", "Ruiyuan Xu", "Jin Qin", "Jiaming Guo", "Chenxi Wang", "Ling Li", "Qi Guo", "Yunji Chen"], "title": "Mutual-Supervised Learning for Sequential-to-Parallel Code Translation", "comment": "28 pages", "summary": "The rise of GPU-based high-performance computing (HPC) has driven the\nwidespread adoption of parallel programming models such as CUDA. Yet, the\ninherent complexity of parallel programming creates a demand for the automated\nsequential-to-parallel approaches. However, data scarcity poses a significant\nchallenge for machine learning-based sequential-to-parallel code translation.\nAlthough recent back-translation methods show promise, they still fail to\nensure functional equivalence in the translated code. In this paper, we propose\na novel Mutual-Supervised Learning (MSL) framework for sequential-to-parallel\ncode translation to address the functional equivalence issue. MSL consists of\ntwo models, a Translator and a Tester. Through an iterative loop consisting of\nCo-verify and Co-evolve steps, the Translator and the Tester mutually generate\ndata for each other and improve collectively. The Tester generates unit tests\nto verify and filter functionally equivalent translated code, thereby evolving\nthe Translator, while the Translator generates translated code as augmented\ninput to evolve the Tester. Experimental results demonstrate that MuSL\nsignificantly enhances the performance of the base model: when applied to\nQwen2.5-Coder, it not only improves Pass@1 by up to 28.91% and boosts Tester\nperformance by 68.90%, but also outperforms the previous state-of-the-art\nmethod CodeRosetta by 1.56 and 6.92 in BLEU and CodeBLEU scores, while\nachieving performance comparable to DeepSeek-R1 and GPT-4.1. Our code is\navailable at https://github.com/kcxain/musl.", "AI": {"tldr": "\u63d0\u51fa\u4e86MuSL\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u6a21\u578b\u4e92\u76d1\u7763\u6709\u6548\u63d0\u5347\u4e86\u987a\u5e8f\u5230\u5e76\u884c\u4ee3\u7801\u7ffb\u8bd1\u7684\u51c6\u786e\u6027\u548c\u529f\u80fd\u7b49\u4ef7\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "GPU\u9ad8\u6027\u80fd\u8ba1\u7b97\u63a8\u52a8\u4e86CUDA\u7b49\u5e76\u884c\u7f16\u7a0b\u6a21\u578b\u7684\u666e\u53ca\uff0c\u4f46\u5e76\u884c\u7f16\u7a0b\u590d\u6742\u5ea6\u9ad8\uff0c\u56e0\u6b64\u5b58\u5728\u81ea\u52a8\u4ece\u987a\u5e8f\u4ee3\u7801\u7ffb\u8bd1\u4e3a\u5e76\u884c\u4ee3\u7801\u7684\u9700\u6c42\u3002\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u5728\u987a\u5e8f\u5230\u5e76\u884c\u7684\u4ee3\u7801\u7ffb\u8bd1\u4e2d\uff0c\u56e0\u4e3a\u6570\u636e\u7a00\u7f3a\u6027\u800c\u9762\u4e34\u6311\u6218\u3002\u8fd1\u671f\u7684\u53cd\u5411\u7ffb\u8bd1\u65b9\u6cd5\u867d\u6709\u8fdb\u5c55\uff0c\u4f46\u7ffb\u8bd1\u540e\u7684\u4ee3\u7801\u529f\u80fd\u7b49\u4ef7\u6027\u4ecd\u672a\u5f97\u5230\u4fdd\u8bc1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u4e92\u76d1\u7763\u5b66\u4e60\uff08MSL\uff09\u6846\u67b6\uff0c\u5305\u62ecTranslator\u548cTester\u4e24\u4e2a\u6a21\u578b\uff0c\u5e76\u901a\u8fc7Co-verify\u548cCo-evolve\u7684\u8fed\u4ee3\u8fc7\u7a0b\u4e92\u76f8\u751f\u6210\u6570\u636e\u4ee5\u5b9e\u73b0\u534f\u540c\u63d0\u5347\u3002Tester\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u6765\u9a8c\u8bc1\u548c\u7b5b\u9009\u529f\u80fd\u7b49\u4ef7\u7684\u5e76\u884c\u4ee3\u7801\uff0c\u4fc3\u8fdbTranslator\u8fdb\u5316\uff1bTranslator\u751f\u6210\u65b0\u7684\u7ffb\u8bd1\u4ee3\u7801\u7528\u4f5c\u589e\u5f3a\u8f93\u5165\uff0c\u4fc3\u8fdbTester\u8fdb\u5316\u3002", "result": "\u5728Qwen2.5-Coder\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5c06Pass@1\u6307\u6807\u63d0\u5347\u4e8628.91%\uff0cTester\u6027\u80fd\u63d0\u5347\u4e8668.90%\uff0c\u5728BLEU\u548cCodeBLEU\u5206\u6570\u4e0a\u5206\u522b\u8d85\u8fc7\u4e4b\u524d\u6700\u4f73\u65b9\u6cd5CodeRosetta 1.56\u548c6.92\u5206\uff0c\u4e14\u6027\u80fd\u63a5\u8fd1DeepSeek-R1\u548cGPT-4.1\u3002", "conclusion": "MSL\uff08MuSL\uff09\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u987a\u5e8f\u5230\u5e76\u884c\u4ee3\u7801\u81ea\u52a8\u7ffb\u8bd1\u7684\u6027\u80fd\uff0c\u663e\u8457\u8d85\u8fc7\u73b0\u6709\u65b9\u6cd5\u5e76\u786e\u4fdd\u4e86\u529f\u80fd\u7b49\u4ef7\u6027\u3002"}}
{"id": "2506.11300", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11300", "abs": "https://arxiv.org/abs/2506.11300", "authors": ["Yang Zhang", "Amr Mohamed", "Hadi Abdine", "Guokan Shang", "Michalis Vazirgiannis"], "title": "Beyond Random Sampling: Efficient Language Model Pretraining via Curriculum Learning", "comment": null, "summary": "Curriculum learning has shown promise in improving training efficiency and\ngeneralization in various machine learning domains, yet its potential in\npretraining language models remains underexplored, prompting our work as the\nfirst systematic investigation in this area. We experimented with different\nsettings, including vanilla curriculum learning, pacing-based sampling, and\ninterleaved curricula-guided by six difficulty metrics spanning linguistic and\ninformation-theoretic perspectives. We train models under these settings and\nevaluate their performance on eight diverse benchmarks. Our experiments reveal\nthat curriculum learning consistently improves convergence in early and\nmid-training phases, and can yield lasting gains when used as a warmup strategy\nwith up to $3.5\\%$ improvement. Notably, we identify compression ratio, lexical\ndiversity, and readability as effective difficulty signals across settings. Our\nfindings highlight the importance of data ordering in large-scale pretraining\nand provide actionable insights for scalable, data-efficient model development\nunder realistic training scenarios.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u6027\u5206\u6790\u4e86\u8bfe\u7a0b\u5b66\u4e60\u5728\u5927\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u4e2d\u7684\u4f5c\u7528\uff0c\u53d1\u73b0\u901a\u8fc7\u7279\u5b9a\u96be\u5ea6\u6307\u6807\u6307\u5bfc\u6570\u636e\u6392\u5e8f\uff0c\u53ef\u6709\u6548\u63d0\u5347\u6a21\u578b\u6536\u655b\u901f\u5ea6\u548c\u6700\u7ec8\u6027\u80fd\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u52a0\u6570\u636e\u9ad8\u6548\u7684\u9884\u8bad\u7ec3\u8def\u5f84\u3002", "motivation": "\u8bfe\u7a0b\u5b66\u4e60\uff08Curriculum Learning\uff09\u5df2\u5728\u591a\u4e2a\u673a\u5668\u5b66\u4e60\u9886\u57df\u8868\u73b0\u51fa\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u7684\u6f5c\u529b\uff0c\u4f46\u5176\u5728\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u9886\u57df\u4e2d\u7684\u5e94\u7528\u8fd8\u9c9c\u6709\u7cfb\u7edf\u6027\u7814\u7a76\u3002\u672c\u6587\u65e8\u5728\u8865\u5145\u8be5\u9886\u57df\u7684\u7a7a\u767d\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86\u591a\u79cd\u8bfe\u7a0b\u5b66\u4e60\u8bbe\u7f6e\uff0c\u5305\u62ec\u6807\u51c6\u8bfe\u7a0b\u5b66\u4e60\u3001\u57fa\u4e8e\u6b65\u8c03\u7684\u91c7\u6837\u3001\u4ea4\u9519\u5f0f\u8bfe\u7a0b\u5b89\u6392\u7b49\uff0c\u4f9d\u636e\u516d\u79cd\u4ece\u8bed\u8a00\u5b66\u548c\u4fe1\u606f\u8bba\u89d2\u5ea6\u5b9a\u4e49\u7684\u6570\u636e\u96be\u5ea6\u6307\u6807\u8fdb\u884c\u5f15\u5bfc\u3002\u8bad\u7ec3\u540e\u5728\u516b\u4e2a\u4e0d\u540c\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8bfe\u7a0b\u5b66\u4e60\u5728\u8bad\u7ec3\u524d\u671f\u548c\u4e2d\u671f\u6301\u7eed\u63d0\u5347\u6a21\u578b\u6536\u655b\u901f\u5ea6\uff0c\u4f5c\u4e3a\u9884\u70ed\u7b56\u7565\u53ef\u53d6\u5f97\u6700\u9ad83.5%\u7684\u63d0\u5347\u3002\u540c\u65f6\uff0c\u538b\u7f29\u7387\u3001\u8bcd\u6c47\u591a\u6837\u6027\u548c\u53ef\u8bfb\u6027\u662f\u8de8\u573a\u666f\u6709\u6548\u7684\u6570\u636e\u96be\u5ea6\u4fe1\u53f7\u3002", "conclusion": "\u6570\u636e\u6392\u5e8f\u5728\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u4e2d\u5341\u5206\u91cd\u8981\uff0c\u5408\u7406\u4f7f\u7528\u8bfe\u7a0b\u5b66\u4e60\u80fd\u5e26\u6765\u663e\u8457\u7684\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u63d0\u5347\u3002\u6587\u4e2d\u7814\u7a76\u4e3a\u73b0\u5b9e\u573a\u666f\u4e0b\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u6a21\u578b\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u5177\u4f53\u6307\u5bfc\u3002"}}
{"id": "2506.11305", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11305", "abs": "https://arxiv.org/abs/2506.11305", "authors": ["Mohammad Hammoud", "Devang Acharya"], "title": "Don't Pay Attention", "comment": null, "summary": "The Transformer has become the de facto standard for large language models\nand a wide range of downstream tasks across various domains. Despite its\nnumerous advantages like inherent training parallelism, the Transformer still\nfaces key challenges due to its inability to effectively process sequences\nbeyond a fixed context window and the quadratic complexity of its attention\nmechanism. These challenges have renewed interest in RNN-like architectures,\nwhich offer linear scaling with sequence length and improved handling of\nlong-range dependencies, albeit with limited parallelism due to their\ninherently recurrent nature. In this paper, we propose Avey, a new neural\nfoundational architecture that breaks away from both attention and recurrence.\nAvey comprises a ranker and an autoregressive neural processor, which\ncollaboratively identify and contextualize only the most relevant tokens for\nany given token, regardless of their positions in the sequence. Specifically,\nAvey decouples sequence length from context width, thus enabling effective\nprocessing of arbitrarily long sequences. Experimental results show that Avey\ncompares favorably to the Transformer across a variety of standard short-range\nNLP benchmarks, while notably excelling at capturing long-range dependencies.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86Avey\u67b6\u6784\uff0c\u89c4\u907f\u4e86Transformer\u7684\u6ce8\u610f\u529b\u673a\u5236\u548c\u9012\u5f52\u7ed3\u6784\u9650\u5236\uff0c\u6709\u6548\u5904\u7406\u4efb\u610f\u957f\u5ea6\u5e8f\u5217\uff0c\u5728\u957f\u8ddd\u79bb\u4f9d\u8d56\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86Transformer\u3002", "motivation": "Transformer\u867d\u7136\u5df2\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u9762\u4e34\u4e0a\u4e0b\u6587\u7a97\u53e3\u56fa\u5b9a\u548c\u6ce8\u610f\u529b\u673a\u5236\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u7684\u95ee\u9898\uff0c\u6fc0\u53d1\u4e86\u5bf9\u80fd\u6709\u6548\u5efa\u6a21\u957f\u5e8f\u5217RNN\u65b0\u53d8\u4f53\u7684\u5174\u8da3\uff0c\u9700\u8981\u7a81\u7834Transformer\u67b6\u6784\u7684\u5c40\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u57fa\u7840\u795e\u7ecf\u7f51\u7edc\u67b6\u6784Avey\uff0c\u7531\u6392\u5e8f\u5668\u548c\u81ea\u56de\u5f52\u795e\u7ecf\u5904\u7406\u5668\u7ec4\u6210\uff0c\u901a\u8fc7\u534f\u4f5c\u8bc6\u522b\u548c\u5efa\u6a21\u4efb\u610ftoken\u7684\u6700\u76f8\u5173\u4e0a\u4e0b\u6587token\uff0c\u800c\u4e0d\u662f\u53d7\u9650\u4e8e\u4f4d\u7f6e\u6216\u56fa\u5b9a\u7a97\u53e3\u3002", "result": "Avey\u5728\u591a\u9879\u6807\u51c6NLP\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0eTransformer\u76f8\u5f53\uff0c\u5728\u5904\u7406\u957f\u8ddd\u79bb\u4f9d\u8d56\u4efb\u52a1\u4e0a\u6027\u80fd\u663e\u8457\u66f4\u4f18\u3002", "conclusion": "Avey\u67b6\u6784\u5728\u591a\u9879NLP\u57fa\u51c6\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8eTransformer\uff0c\u7279\u522b\u662f\u5728\u6355\u6349\u957f\u8ddd\u79bb\u4f9d\u8d56\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2506.11180", "categories": ["cs.SE", "cs.AI", "cs.ET", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2506.11180", "abs": "https://arxiv.org/abs/2506.11180", "authors": ["Luis Miguel Vieira da Silva", "Aljosha K\u00f6cher", "Felix Gehlhoff"], "title": "Beyond Formal Semantics for Capabilities and Skills: Model Context Protocol in Manufacturing", "comment": null, "summary": "Explicit modeling of capabilities and skills -- whether based on ontologies,\nAsset Administration Shells, or other technologies -- requires considerable\nmanual effort and often results in representations that are not easily\naccessible to Large Language Models (LLMs). In this work-in-progress paper, we\npresent an alternative approach based on the recently introduced Model Context\nProtocol (MCP). MCP allows systems to expose functionality through a\nstandardized interface that is directly consumable by LLM-based agents. We\nconduct a prototypical evaluation on a laboratory-scale manufacturing system,\nwhere resource functions are made available via MCP. A general-purpose LLM is\nthen tasked with planning and executing a multi-step process, including\nconstraint handling and the invocation of resource functions via MCP. The\nresults indicate that such an approach can enable flexible industrial\nautomation without relying on explicit semantic models. This work lays the\nbasis for further exploration of external tool integration in LLM-driven\nproduction systems.", "AI": {"tldr": "\u901a\u8fc7MCP\u534f\u8bae\u76f4\u63a5\u5c06\u5236\u9020\u7cfb\u7edf\u7684\u529f\u80fd\u66b4\u9732\u7ed9LLM\uff0c\u7b80\u5316\u4e86\u5de5\u4e1a\u81ea\u52a8\u5316\u96c6\u6210\u6d41\u7a0b\uff0c\u521d\u6b65\u5b9e\u9a8c\u663e\u793a\u8fd9\u79cd\u65b9\u5f0f\u9ad8\u6548\u4e14\u7075\u6d3b\u3002", "motivation": "\u73b0\u6709\u7684\u80fd\u529b\u5efa\u6a21\uff08\u5982\u672c\u4f53\u3001AAS\u7b49\uff09\u4f9d\u8d56\u5927\u91cf\u4eba\u5de5\u5de5\u4f5c\uff0c\u4e14\u7ed3\u679c\u96be\u4ee5\u88abLLM\u76f4\u63a5\u8bbf\u95ee\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u65b0\u7684\u3001\u5bf9LLM\u53cb\u597d\u7684\u5de5\u4e1a\u7cfb\u7edf\u96c6\u6210\u65b9\u5f0f\u3002", "method": "\u5728\u5b9e\u9a8c\u5ba4\u89c4\u6a21\u7684\u5236\u9020\u7cfb\u7edf\u4e2d\uff0c\u5c06\u8d44\u6e90\u529f\u80fd\u901a\u8fc7MCP\u66b4\u9732\uff0c\u5229\u7528\u901a\u7528LLM\u8fdb\u884c\u4efb\u52a1\u89c4\u5212\u4e0e\u6267\u884c\uff0c\u5305\u62ec\u7ea6\u675f\u5904\u7406\u548c\u901a\u8fc7MCP\u8c03\u7528\u8d44\u6e90\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u901a\u8fc7MCP\u516c\u5f00\u8d44\u6e90\u529f\u80fd\uff0cLLM\u53ef\u987a\u5229\u89c4\u5212\u5e76\u6267\u884c\u591a\u6b65\u9aa4\u751f\u4ea7\u6d41\u7a0b\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u663e\u5f0f\u8bed\u4e49\u6a21\u578b\u7684\u5de5\u4e1a\u81ea\u52a8\u5316\u3002", "conclusion": "MCP\u8fd9\u79cd\u57fa\u4e8e\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u7684\u65b9\u6cd5\u53ef\u4ee5\u7ed5\u8fc7\u4f20\u7edf\u7684\u8bed\u4e49\u5efa\u6a21\uff0c\u5b9e\u73b0LLM\u9a71\u52a8\u7684\u7075\u6d3b\u5de5\u4e1a\u81ea\u52a8\u5316\uff0c\u5f88\u6709\u6f5c\u529b\u63a8\u52a8\u751f\u4ea7\u7cfb\u7edf\u4e0e\u5916\u90e8\u5de5\u5177\u7684\u96c6\u6210\u3002"}}
{"id": "2506.11338", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11338", "abs": "https://arxiv.org/abs/2506.11338", "authors": ["Yi-Chien Lin", "William Schuler"], "title": "Surprisal from Larger Transformer-based Language Models Predicts fMRI Data More Poorly", "comment": null, "summary": "As Transformers become more widely incorporated into natural language\nprocessing tasks, there has been considerable interest in using surprisal from\nthese models as predictors of human sentence processing difficulty. Recent work\nhas observed a positive relationship between Transformer-based models'\nperplexity and the predictive power of their surprisal estimates on reading\ntimes, showing that language models with more parameters and trained on more\ndata are less predictive of human reading times. However, these studies focus\non predicting latency-based measures (i.e., self-paced reading times and\neye-gaze durations) with surprisal estimates from Transformer-based language\nmodels. This trend has not been tested on brain imaging data. This study\ntherefore evaluates the predictive power of surprisal estimates from 17\npre-trained Transformer-based models across three different language families\non two functional magnetic resonance imaging datasets. Results show that the\npositive relationship between model perplexity and model fit still obtains,\nsuggesting that this trend is not specific to latency-based measures and can be\ngeneralized to neural measures.", "AI": {"tldr": "Transformer\u6a21\u578b\u7684\u60ca\u5947\u5ea6\u4e0d\u4ec5\u80fd\u5f88\u597d\u5730\u9884\u6d4b\u4eba\u7c7b\u5ef6\u8fdf\u578b\u9605\u8bfb\u884c\u4e3a\uff0c\u8fd8\u80fd\u9884\u6d4b\u5927\u8111\u795e\u7ecf\u53cd\u5e94\uff0c\u4e14\u5176\u9884\u6d4b\u529b\u4e0e\u6a21\u578b\u56f0\u60d1\u5ea6\u5448\u6b63\u76f8\u5173\u3002", "motivation": "Transformers\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u8d8a\u6765\u8d8a\u5e7f\u6cdb\uff0c\u76f8\u5173\u7814\u7a76\u53d1\u73b0Transformer\u7684\u201c\u60ca\u5947\u5ea6\uff08surprisal\uff09\u201d\u53ef\u4ee5\u9884\u6d4b\u4eba\u7c7b\u53e5\u5b50\u52a0\u5de5\u96be\u5ea6\u3002\u6b64\u524d\u7684\u7814\u7a76\u96c6\u4e2d\u5728\u7528Transformer\u7684\u60ca\u5947\u5ea6\u9884\u6d4b\u4eba\u7c7b\u9605\u8bfb\u65f6\u957f\u7b49\u5ef6\u8fdf\u7c7b\u6307\u6807\uff0c\u4f46\u5c1a\u672a\u7814\u7a76\u8fd9\u79cd\u8d8b\u52bf\u5728\u5927\u8111\u6210\u50cf\u6570\u636e\u4e2d\u7684\u8868\u73b0\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7d22Transformer\u60ca\u5947\u5ea6\u5728\u795e\u7ecf\u6d4b\u91cf\u4e0a\u7684\u9884\u6d4b\u80fd\u529b\u3002", "method": "\u672c\u6587\u8bc4\u4f30\u4e8617\u4e2a\u9884\u8bad\u7ec3Transformer\u6a21\u578b\uff08\u6db5\u76d6\u4e09\u79cd\u4e0d\u540c\u7684\u8bed\u8a00\u5bb6\u65cf\uff09\uff0c\u901a\u8fc7\u5206\u6790\u5b83\u4eec\u7684\u60ca\u5947\u5ea6\u5bf9\u4e24\u4e2afMRI\uff08\u529f\u80fd\u78c1\u5171\u632f\u6210\u50cf\uff09\u6570\u636e\u96c6\u7684\u9884\u6d4b\u529b\uff0c\u4ece\u800c\u8003\u5bdf\u60ca\u5947\u5ea6\u548c\u6a21\u578b\u56f0\u60d1\u5ea6\uff08perplexity\uff09\u7684\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u53d1\u73b0\uff0cTransformer\u6a21\u578b\u7684\u56f0\u60d1\u5ea6\u4e0e\u6a21\u578b\u7684\u9002\u914d\u5ea6\uff08\u5373\u60ca\u5947\u5ea6\u5bf9\u795e\u7ecf\u6570\u636e\u7684\u9884\u6d4b\u529b\uff09\u4e4b\u95f4\u5448\u6b63\u76f8\u5173\u3002\u8fd9\u8868\u660e\uff0c\u56f0\u60d1\u5ea6\u8f83\u9ad8\u7684\u6a21\u578b\uff0c\u5bf9\u4eba\u7c7b\u5927\u8111\u795e\u7ecf\u53cd\u5e94\u7684\u9884\u6d4b\u66f4\u6709\u529b\u3002", "conclusion": "Transformer\u60ca\u5947\u5ea6\u5728\u9884\u6d4b\u795e\u7ecf\u6307\u6807\u65f6\u5ef6\u7eed\u4e86\u5728\u5ef6\u8fdf\u6027\u884c\u4e3a\u6307\u6807\uff08\u4f8b\u5982\u9605\u8bfb\u65f6\u957f\uff09\u4e0a\u7684\u8d8b\u52bf\u2014\u2014\u6a21\u578b\u56f0\u60d1\u5ea6\u4e0e\u9884\u6d4b\u80fd\u529b\u5448\u6b63\u76f8\u5173\u3002\u8fd9\u4e00\u8d8b\u52bf\u4ece\u884c\u4e3a\u6570\u636e\u62d3\u5c55\u5230\u4e86\u795e\u7ecf\u6570\u636e\u5c42\u9762\uff0c\u5177\u6709\u666e\u904d\u6027\u3002"}}
{"id": "2506.11237", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11237", "abs": "https://arxiv.org/abs/2506.11237", "authors": ["Ngoc Phuoc An Vo", "Brent Paulovicks", "Vadim Sheinin"], "title": "LLM-as-a-Judge for Reference-less Automatic Code Validation and Refinement for Natural Language to Bash in IT Automation", "comment": "10 pages", "summary": "In an effort to automatically evaluate and select the best model and improve\ncode quality for automatic incident remediation in IT Automation, it is crucial\nto verify if the generated code for remediation action is syntactically and\nsemantically correct and whether it can be executed correctly as intended.\nThere are three approaches: 1) conventional methods use surface form similarity\nmetrics (token match, exact match, etc.) which have numerous limitations, 2)\nexecution-based evaluation focuses more on code functionality based on\npass/fail judgments for given test-cases, and 3) LLM-as-a-Judge employs LLMs\nfor automated evaluation to judge if it is a correct answer for a given problem\nbased on pre-defined metrics. In this work, we focused on enhancing\nLLM-as-a-Judge using bidirectional functionality matching and logic\nrepresentation for reference-less automatic validation and refinement for Bash\ncode generation to select the best model for automatic incident remediation in\nIT Automation. We used execution-based evaluation as ground-truth to evaluate\nour LLM-as-a-Judge metrics. Results show high accuracy and agreement with\nexecution-based evaluation (and up to 8% over baseline). Finally, we built\nReflection code agents to utilize judgments and feedback from our evaluation\nmetrics which achieved significant improvement (up to 24% increase in accuracy)\nfor automatic code refinement.", "AI": {"tldr": "\u901a\u8fc7\u6539\u8fdbLLM\u81ea\u52a8\u5316\u4ee3\u7801\u8bc4\u4ef7\u4e0e\u7cbe\u70bc\u65b9\u6cd5\uff0c\u5b9e\u73b0\u66f4\u9ad8\u51c6\u786e\u7387\u4e0e\u4ee3\u7801\u81ea\u52a8\u4f18\u5316\uff0c\u6709\u6548\u63d0\u5347IT\u81ea\u52a8\u5316\u6545\u969c\u4fee\u590d\u80fd\u529b\u3002", "motivation": "\u81ea\u52a8\u5316IT\u6545\u969c\u5904\u7406\u8fc7\u7a0b\u4e2d\uff0c\u5982\u4f55\u9ad8\u6548\u3001\u51c6\u786e\u5730\u81ea\u52a8\u8bc4\u4ef7\u4ee3\u7801\u751f\u6210\u8d28\u91cf\uff0c\u5e76\u9009\u62e9\u6700\u4f18\u6a21\u578b\uff0c\u662f\u63d0\u5347\u4ee3\u7801\u4fee\u590d\u80fd\u529b\u548c\u7cfb\u7edf\u7a33\u5b9a\u6027\u7684\u6838\u5fc3\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u53d7\u9650\u4e8e\u8868\u9762\u76f8\u4f3c\u6027\u548c\u529f\u80fd\u8bc4\u6d4b\u7684\u4e0d\u8db3\uff0c\u4e9f\u9700\u53c2\u8003\u65b0\u65b9\u5f0f\u63d0\u5347\u4ee3\u7801\u8bc4\u4ef7\u4e0e\u7cbe\u70bc\u80fd\u529b\u3002", "method": "\u6587\u7ae0\u63d0\u51fa\u589e\u5f3a\u578bLLM-as-a-Judge\u65b9\u6cd5\uff0c\u7ed3\u5408\u53cc\u5411\u529f\u80fd\u5339\u914d\u4e0e\u903b\u8f91\u8868\u793a\uff0c\u5b9e\u73b0\u9762\u5411Bash\u4ee3\u7801\u751f\u6210\u7684\u65e0\u53c2\u8003\u4ee3\u7801\u81ea\u52a8\u9a8c\u8bc1\u4e0e\u4f18\u5316\u9009\u6a21\u3002\u4ee5\u6267\u884c\u4e3a\u57fa\u7840\u7684\u6d4b\u8bd5\u8bc4\u6d4b\u4e3a\u771f\u503c\uff0c\u9a8c\u8bc1LLM-as-a-Judge\u8bc4\u4ef7\u6307\u6807\u7684\u51c6\u786e\u6027\u3002\u540c\u65f6\uff0c\u8bbe\u8ba1Reflection code agents\uff0c\u5229\u7528\u8bc4\u4ef7\u6307\u6807\u7684\u53cd\u9988\u4fe1\u606f\u81ea\u52a8\u7cbe\u70bc\u4ee3\u7801\u3002", "result": "\u589e\u5f3a\u578bLLM-as-a-Judge\u7684\u8bc4\u4ef7\u51c6\u786e\u7387\u9ad8\uff0c\u4e0e\u6267\u884c\u578b\u8bc4\u6d4b\uff08ground-truth\uff09\u9ad8\u5ea6\u4e00\u81f4\uff0c\u4e14\u5bf9\u6bd4\u57fa\u7ebf\u63d0\u5347\u53ef\u8fbe8%\u3002\u57fa\u4e8e\u53cd\u601d\u578b\u4ee3\u7801\u667a\u80fd\u4f53\uff0c\u81ea\u52a8\u4ee3\u7801\u7cbe\u70bc\u51c6\u786e\u7387\u63d0\u5347\u53ef\u8fbe24%\u3002", "conclusion": "\u672c\u7814\u7a76\u5728\u81ea\u52a8\u5316\u6545\u969c\u4fee\u590d\u9886\u57df\u63d0\u51fa\u7684\u65e0\u53c2\u8003\u81ea\u52a8\u4ee3\u7801\u8bc4\u4ef7\u4e0e\u4f18\u5316\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4ee3\u7801\u751f\u6210\u7684\u81ea\u52a8\u9a8c\u8bc1\u80fd\u529b\u53ca\u540e\u7eed\u4ee3\u7801\u7cbe\u70bc\u6548\u679c\uff0c\u53ef\u9009\u4f18\u6a21\u578b\u4e0e\u589e\u5f3a\u4ee3\u7801\u8d28\u91cf\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2506.11343", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11343", "abs": "https://arxiv.org/abs/2506.11343", "authors": ["Yaohui Zhang", "Haijing Zhang", "Wenlong Ji", "Tianyu Hua", "Nick Haber", "Hancheng Cao", "Weixin Liang"], "title": "From Replication to Redesign: Exploring Pairwise Comparisons for LLM-Based Peer Review", "comment": null, "summary": "The advent of large language models (LLMs) offers unprecedented opportunities\nto reimagine peer review beyond the constraints of traditional workflows.\nDespite these opportunities, prior efforts have largely focused on replicating\ntraditional review workflows with LLMs serving as direct substitutes for human\nreviewers, while limited attention has been given to exploring new paradigms\nthat fundamentally rethink how LLMs can participate in the academic review\nprocess. In this paper, we introduce and explore a novel mechanism that employs\nLLM agents to perform pairwise comparisons among manuscripts instead of\nindividual scoring. By aggregating outcomes from substantial pairwise\nevaluations, this approach enables a more accurate and robust measure of\nrelative manuscript quality. Our experiments demonstrate that this comparative\napproach significantly outperforms traditional rating-based methods in\nidentifying high-impact papers. However, our analysis also reveals emergent\nbiases in the selection process, notably a reduced novelty in research topics\nand an increased institutional imbalance. These findings highlight both the\ntransformative potential of rethinking peer review with LLMs and critical\nchallenges that future systems must address to ensure equity and diversity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bba\u6587\u4e24\u4e24\u6bd4\u8f83\u8bc4\u5ba1\uff0c\u660e\u663e\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u5e26\u6765\u4e86\u65b0\u578b\u504f\u89c1\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u786e\u4fdd\u516c\u5e73\u591a\u6837\u6027\u3002", "motivation": "\u73b0\u6709\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u53c2\u4e0e\u5b66\u672f\u540c\u884c\u8bc4\u5ba1\u7684\u5c1d\u8bd5\uff0c\u5927\u591a\u53ea\u662f\u7528LLM\u76f4\u63a5\u66ff\u4ee3\u4eba\u5de5\u6d41\u7a0b\uff0c\u7f3a\u4e4f\u5bf9\u8bc4\u5ba1\u673a\u5236\u7684\u6839\u672c\u521b\u65b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u65b0\u7684\u673a\u5236\uff1a\u5229\u7528LLM\u4ee3\u7406\u5bf9\u8bba\u6587\u8fdb\u884c\u6210\u5bf9\u6bd4\u8f83\uff0c\u800c\u4e0d\u662f\u5355\u72ec\u6253\u5206\uff0c\u5e76\u901a\u8fc7\u6c47\u603b\u5927\u91cf\u4e24\u4e24\u6bd4\u8f83\u7ed3\u679c\u6765\u8bc4\u4f30\u8bba\u6587\u7684\u76f8\u5bf9\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u57fa\u4e8e\u6bd4\u8f83\u7684\u65b9\u6cd5\u5728\u8bc6\u522b\u9ad8\u5f71\u54cd\u529b\u8bba\u6587\u65b9\u9762\u660e\u663e\u4f18\u4e8e\u4f20\u7edf\u6253\u5206\u6cd5\uff0c\u4f46\u4e5f\u51fa\u73b0\u4e86\u4e3b\u9898\u65b0\u9896\u6027\u4e0b\u964d\u548c\u673a\u6784\u504f\u89c1\u52a0\u5267\u7b49\u65b0\u578b\u504f\u5dee\u3002", "conclusion": "LLM\u53ef\u4ee5\u5f7b\u5e95\u6539\u53d8\u5b66\u672f\u8bc4\u5ba1\u6d41\u7a0b\uff0c\u4f46\u65b0\u65b9\u6cd5\u4e5f\u5e26\u6765\u4e86\u516c\u5e73\u6027\u548c\u591a\u6837\u6027\u7684\u6311\u6218\u3002"}}
{"id": "2506.11266", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11266", "abs": "https://arxiv.org/abs/2506.11266", "authors": ["Benjamin Elder", "Anupama Murthi", "Jungkoo Kang", "Ankita Rajaram Naik", "Kiran Kate", "Kinjal Basu", "Danish Contractor"], "title": "Invocable APIs derived from NL2SQL datasets for LLM Tool-Calling Evaluation", "comment": "10+32 pages, 5 figures", "summary": "Large language models (LLMs) are routinely deployed as agentic systems, with\naccess to tools that interact with live environments to accomplish tasks. In\nenterprise deployments these systems need to interact with API collections that\ncan be extremely large and complex, often backed by databases. In order to\ncreate datasets with such characteristics, we explore how existing NL2SQL\n(Natural Language to SQL query) datasets can be used to automatically create\nNL2API datasets. Specifically, this work describes a novel data generation\npipeline that exploits the syntax of SQL queries to construct a functionally\nequivalent sequence of API calls. We apply this pipeline to one of the largest\nNL2SQL datasets, BIRD-SQL to create a collection of over 2500 APIs that can be\nserved as invocable tools or REST-endpoints. We pair natural language queries\nfrom BIRD-SQL to ground-truth API sequences based on this API pool. We use this\ncollection to study the performance of 10 public LLMs and find that all models\nstruggle to determine the right set of tools (consisting of tasks of intent\ndetection, sequencing with nested function calls, and slot-filling). We find\nthat models have extremely low task completion rates (7-47 percent - depending\non the dataset) which marginally improves to 50 percent when models are\nemployed as ReACT agents that interact with the live API environment. The best\ntask completion rates are far below what may be required for effective\ngeneral-use tool-calling agents, suggesting substantial scope for improvement\nin current state-of-the-art tool-calling LLMs. We also conduct detailed\nablation studies, such as assessing the impact of the number of tools available\nas well as the impact of tool and slot-name obfuscation. We compare the\nperformance of models on the original SQL generation tasks and find that\ncurrent models are sometimes able to exploit SQL better than APIs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5c06NL2SQL\u6570\u636e\u96c6\u81ea\u52a8\u8f6c\u5316\u4e3aNL2API\u4efb\u52a1\u96c6\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u7528\u5176\u7cfb\u7edf\u8bc4\u4f30LLM\u5728\u5de5\u5177\u8c03\u7528\u573a\u666f\u4e0b\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u5373\u4f7f\u6700\u4f18\u6a21\u578b\u4e5f\u96be\u4ee5\u80dc\u4efb\u590d\u6742API\u8c03\u7528\u4efb\u52a1\uff0c\u63d0\u793a\u5f53\u524dLLM\u5de5\u5177\u8c03\u7528\u80fd\u529b\u4e0e\u5b9e\u9645\u9700\u6c42\u4ecd\u6709\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u7684LLM\u5728\u4f01\u4e1a\u7ea7\u73af\u5883\u4e2d\u9700\u8981\u4e0e\u5927\u91cf\u590d\u6742\u7684API\u96c6\u5408\u4ea4\u4e92\uff0c\u4f46\u7f3a\u4e4f\u771f\u5b9e\u573a\u666f\u4e0b\u7684NL2API\uff08\u81ea\u7136\u8bed\u8a00\u5230API\u8c03\u7528\uff09\u6d4b\u8bd5\u6570\u636e\uff0c\u4e14\u5176\u771f\u5b9e\u6027\u80fd\u672a\u77e5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u6761\u65b0\u9896\u7684\u6570\u636e\u751f\u6210\u7ba1\u9053\uff0c\u57fa\u4e8e\u5927\u578bNL2SQL\u6570\u636e\u96c6\uff08\u5982BIRD-SQL\uff09\u81ea\u52a8\u751f\u6210\u7b49\u4ef7\u7684NL2API\u6570\u636e\u96c6\uff0c\u5c06SQL\u67e5\u8be2\u8bed\u53e5\u8f6c\u5316\u4e3a\u4e00\u7cfb\u5217\u7b49\u4ef7\u7684API\u8c03\u7528\u5e8f\u5217\u3002\u7136\u540e\u5c06\u539f\u6709\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e0e\u8fd9\u4e9bAPI\u5e8f\u5217\u914d\u5bf9\uff0c\u5e76\u7528\u8be5\u6570\u636e\u96c6\u6d4b\u8bd510\u4e2a\u516c\u5f00LLM\u7684\u5de5\u5177\u8c03\u7528\u80fd\u529b\uff0c\u5305\u62ec\u610f\u56fe\u68c0\u6d4b\u3001\u5d4c\u5957\u51fd\u6570\u8c03\u7528\u7684\u6392\u5e8f\u548c\u53c2\u6570\u586b\u5145\u7b49\u4efb\u52a1\u3002", "result": "\u6240\u6709LLM\u5728\u786e\u5b9a\u6b63\u786e\u5de5\u5177\u7ec4\u5408\u4e0a\u8868\u73b0\u8f83\u5dee\uff0c\u4efb\u52a1\u5b8c\u6210\u7387\u4ec57%-47%\uff0c\u5373\u4fbf\u4ee5ReACT agent\u5f62\u5f0f\u63a5\u5165\u52a8\u6001API\u73af\u5883\u4e5f\u53ea\u63d0\u5347\u81f3\u7ea650%\u3002\u8f83\u590d\u6742API\u73af\u5883\u548c\u540d\u79f0\u6df7\u6dc6\u90fd\u4f1a\u8fdb\u4e00\u6b65\u964d\u4f4e\u6a21\u578b\u8868\u73b0\u3002\u5bf9\u6bd4\u663e\u793a\uff0cLLM\u4eec\u5728\u4f20\u7edfSQL\u751f\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u666e\u904d\u4f18\u4e8eAPI\u8c03\u7528\u4efb\u52a1\u3002", "conclusion": "\u5f53\u524d\u4e3b\u6d41LLM\u5728\u771f\u5b9e\u590d\u6742API\u73af\u5883\u4e0b\u7684\u5de5\u5177\u8c03\u7528\u6027\u80fd\u8fdc\u4e0d\u80fd\u6ee1\u8db3\u5b9e\u9645\u5e94\u7528\u9700\u6c42\uff0c\u672a\u6765\u5de5\u5177\u8c03\u7528\u80fd\u529b\u6709\u5de8\u5927\u6539\u8fdb\u7a7a\u95f4\u3002"}}
{"id": "2506.11344", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11344", "abs": "https://arxiv.org/abs/2506.11344", "authors": ["Peilin Wu", "Jinho D. Choi"], "title": "Do We Still Need Audio? Rethinking Speaker Diarization with a Text-Based Approach Using Multiple Prediction Models", "comment": null, "summary": "We present a novel approach to Speaker Diarization (SD) by leveraging\ntext-based methods focused on Sentence-level Speaker Change Detection within\ndialogues. Unlike audio-based SD systems, which are often challenged by audio\nquality and speaker similarity, our approach utilizes the dialogue transcript\nalone. Two models are developed: the Single Prediction Model (SPM) and the\nMultiple Prediction Model (MPM), both of which demonstrate significant\nimprovements in identifying speaker changes, particularly in short\nconversations. Our findings, based on a curated dataset encompassing diverse\nconversational scenarios, reveal that the text-based SD approach, especially\nthe MPM, performs competitively against state-of-the-art audio-based SD\nsystems, with superior performance in short conversational contexts. This paper\nnot only showcases the potential of leveraging linguistic features for SD but\nalso highlights the importance of integrating semantic understanding into SD\nsystems, opening avenues for future research in multimodal and semantic\nfeature-based diarization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8e\u5bf9\u8bdd\u6587\u672c\u7684\u8bf4\u8bdd\u4eba\u53d8\u5316\u68c0\u6d4b\u6a21\u578b\uff0c\u6709\u6548\u63d0\u5347\u4e86\u77ed\u5bf9\u8bdd\u73af\u5883\u4e0b\u7684\u8bf4\u8bdd\u4eba\u5206\u79bb\u51c6\u786e\u7387\uff0c\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u97f3\u9891\u65b9\u6cd5\uff0c\u4e3a\u8bed\u4e49\u548c\u591a\u6a21\u6001\u7279\u5f81\u5728SD\u9886\u57df\u7684\u5e94\u7528\u5e26\u6765\u4e86\u65b0\u65b9\u5411\u3002", "motivation": "\u73b0\u6709\u7684\u8bf4\u8bdd\u4eba\u5206\u79bb\uff08Speaker Diarization, SD\uff09\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u97f3\u9891\u4fe1\u606f\uff0c\u5bb9\u6613\u53d7\u5230\u97f3\u9891\u8d28\u91cf\u6216\u8bf4\u8bdd\u4eba\u97f3\u8272\u63a5\u8fd1\u7684\u5e72\u6270\u3002\u672c\u7814\u7a76\u5e0c\u671b\u901a\u8fc7\u53ea\u4f7f\u7528\u5bf9\u8bdd\u6587\u672c\uff0c\u63a2\u7d22\u57fa\u4e8e\u6587\u672c\u7684\u65b9\u6cd5\u63d0\u5347\u8bf4\u8bdd\u4eba\u53d8\u6362\u68c0\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u5c24\u5176\u5728\u77ed\u5bf9\u8bdd\u4e2d\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u65b0\u7684\u6587\u672c\u9a71\u52a8\u7684\u8bf4\u8bdd\u4eba\u53d8\u6362\u68c0\u6d4b\u6a21\u578b\uff1a\u5355\u4e00\u9884\u6d4b\u6a21\u578b\uff08SPM\uff09\u548c\u591a\u9884\u6d4b\u6a21\u578b\uff08MPM\uff09\uff0c\u53ea\u4f9d\u8d56\u5bf9\u8bdd\u6587\u672c\u8fdb\u884c\u8bf4\u8bdd\u4eba\u53d8\u5316\u70b9\u68c0\u6d4b\uff0c\u5e76\u5728\u591a\u6837\u5316\u5bf9\u8bdd\u573a\u666f\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u4e24\u79cd\u6a21\u578b\u5728\u68c0\u6d4b\u8bf4\u8bdd\u4eba\u53d8\u6362\u65b9\u9762\u6709\u663e\u8457\u63d0\u5347\uff0c\u5c24\u5176\u662f\u5728\u77ed\u5bf9\u8bdd\u573a\u666f\u4e2d\u3002MPM\u6a21\u578b\u5728\u77ed\u5bf9\u8bdd\u4e2d\u7684\u8868\u73b0\u751a\u81f3\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u97f3\u9891\u578bSD\u7cfb\u7edf\u3002", "conclusion": "\u57fa\u4e8e\u6587\u672c\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u7528\u4e8e\u8bf4\u8bdd\u4eba\u5206\u79bb\uff0c\u5c24\u5176\u5728\u97f3\u9891\u6761\u4ef6\u53d7\u9650\u6216\u8bf4\u8bdd\u4eba\u97f3\u8272\u76f8\u8fd1\u573a\u666f\u4e0b\u4f18\u52bf\u660e\u663e\uff0c\u4e14\u9f13\u52b1\u672a\u6765\u5c06\u8bed\u4e49\u7279\u5f81\u4e0e\u591a\u6a21\u6001\u7ed3\u5408\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347SD\u6027\u80fd\u3002"}}
{"id": "2506.11295", "categories": ["cs.SE", "cs.AI", "cs.LG", "D.2.11; D.2.8; I.2.0"], "pdf": "https://arxiv.org/pdf/2506.11295", "abs": "https://arxiv.org/abs/2506.11295", "authors": ["Renato Cordeiro Ferreira"], "title": "A Tale of Two Systems: Characterizing Architectural Complexity on Machine Learning-Enabled Systems", "comment": "8 pages, 3 figures (3 diagrams), submitted to the ECSA2025. arXiv\n  admin note: substantial text overlap with arXiv:2506.08153", "summary": "How can the complexity of ML-enabled systems be managed effectively? The goal\nof this research is to investigate how complexity affects ML-Enabled Systems\n(MLES). To address this question, this research aims to introduce a\nmetrics-based architectural model to characterize the complexity of MLES. The\ngoal is to support architectural decisions, providing a guideline for the\ninception and growth of these systems. This paper brings, side-by-side, the\narchitecture representation of two systems that can be used as case studies for\ncreating the metrics-based architectural model: the SPIRA and the Ocean Guard\nMLES.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u5ea6\u91cf\u65b9\u6cd5\u91cf\u5316\u548c\u7ba1\u7406\u673a\u5668\u5b66\u4e60\u9a71\u52a8\u7cfb\u7edf\u590d\u6742\u6027\u7684\u67b6\u6784\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9645\u7cfb\u7edf\u6848\u4f8b\u5c55\u793a\u5176\u5b9e\u7528\u6027\uff0c\u6709\u52a9\u4e8eMLES\u7684\u67b6\u6784\u51b3\u7b56\u548c\u6269\u5c55\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u9a71\u52a8\u7cfb\u7edf\uff08ML-Enabled Systems, MLES\uff09\u53d8\u5f97\u8d8a\u6765\u8d8a\u590d\u6742\uff0c\u6025\u9700\u6709\u6548\u7684\u65b9\u6cd5\u7ba1\u7406\u5176\u590d\u6742\u6027\u3002\u5982\u4f55\u5ea6\u91cf\u548c\u7ba1\u7406\u8fd9\u4e9b\u590d\u6742\u6027\u5bf9\u7cfb\u7edf\u67b6\u6784\u8bbe\u8ba1\u548c\u6f14\u5316\u81f3\u5173\u91cd\u8981\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5ea6\u91cf\u7684\u67b6\u6784\u6a21\u578b\uff0c\u7528\u4e8e\u91cf\u5316\u548c\u8868\u5f81MLES\u7684\u590d\u6742\u6027\u3002\u5e76\u901a\u8fc7\u5e76\u5217\u6bd4\u8f83\u4e24\u4e2aMLES\u6848\u4f8b\uff08SPIRA\u548cOcean Guard\u7cfb\u7edf\uff09\u7684\u67b6\u6784\uff0c\u5c55\u793a\u8be5\u6a21\u578b\u7684\u5e94\u7528\u3002", "result": "\u57fa\u4e8e\u4e24\u4e2a\u5b9e\u9645\u6848\u4f8b\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86\u8be5\u67b6\u6784\u6a21\u578b\u80fd\u591f\u6709\u6548\u652f\u6301MLES\u7684\u67b6\u6784\u51b3\u7b56\u548c\u6f14\u8fdb\u89c4\u5212\u3002\u63d0\u4f9b\u4e86\u5ea6\u91cf\u548c\u63cf\u8ff0\u590d\u6742\u6027\u7684\u51c6\u5219\uff0c\u4fbf\u4e8e\u7cfb\u7edf\u7684\u8bbe\u8ba1\u548c\u6269\u5c55\u3002", "conclusion": "\u901a\u8fc7\u5ea6\u91cf\u9a71\u52a8\u7684\u67b6\u6784\u6a21\u578b\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u63cf\u8ff0\u548c\u7ba1\u7406ML\u9a71\u52a8\u7cfb\u7edf\u7684\u590d\u6742\u6027\uff0c\u4ece\u800c\u652f\u6301\u67b6\u6784\u51b3\u7b56\uff0c\u4e3a\u7cfb\u7edf\u6210\u957f\u4e0e\u6f14\u5316\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2506.11361", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2506.11361", "abs": "https://arxiv.org/abs/2506.11361", "authors": ["Jack H Fagan", "Ruhaan Juyaal", "Amy Yue-Ming Yu", "Siya Pun"], "title": "The Biased Samaritan: LLM biases in Perceived Kindness", "comment": null, "summary": "While Large Language Models (LLMs) have become ubiquitous in many fields,\nunderstanding and mitigating LLM biases is an ongoing issue. This paper\nprovides a novel method for evaluating the demographic biases of various\ngenerative AI models. By prompting models to assess a moral patient's\nwillingness to intervene constructively, we aim to quantitatively evaluate\ndifferent LLMs' biases towards various genders, races, and ages. Our work\ndiffers from existing work by aiming to determine the baseline demographic\nidentities for various commercial models and the relationship between the\nbaseline and other demographics. We strive to understand if these biases are\npositive, neutral, or negative, and the strength of these biases. This paper\ncan contribute to the objective assessment of bias in Large Language Models and\ngive the user or developer the power to account for these biases in LLM output\nor in training future LLMs. Our analysis suggested two key findings: that\nmodels view the baseline demographic as a white middle-aged or young adult\nmale; however, a general trend across models suggested that non-baseline\ndemographics are more willing to help than the baseline. These methodologies\nallowed us to distinguish these two biases that are often tangled together.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u9053\u5fb7\u4ecb\u5165\u8bc4\u4f30\u6cd5\uff0c\u521b\u65b0\u6027\u5730\u533a\u5206\u5e76\u91cf\u5316\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u4eba\u53e3\u7fa4\u4f53\u4e0a\u7684\u504f\u89c1\uff0c\u53d1\u73b0\u4e3b\u6d41\u6a21\u578b\u57fa\u7ebf\u504f\u5411\u767d\u4eba\u7537\u6027\uff0c\u4e14\u975e\u57fa\u7ebf\u7fa4\u4f53\u666e\u904d\u88ab\u8ba4\u4e3a\u66f4\u613f\u610f\u5e2e\u52a9\u4ed6\u4eba\u3002\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u5ba2\u89c2\u8bc4\u4ef7\u548c\u6539\u8fdbLLM\u7684\u4eba\u53e3\u516c\u5e73\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5404\u9886\u57df\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5185\u5728\u7684\u504f\u89c1\u95ee\u9898\u4ecd\u672a\u89e3\u51b3\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u96be\u4ee5\u7cbe\u786e\u91cf\u5316\u6a21\u578b\u5728\u4e0d\u540c\u7fa4\u4f53\u4e0a\u7684\u504f\u89c1\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u63a2\u7d22\u65b0\u7684\u8bc4\u4f30\u65b9\u5f0f\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u4e9b\u504f\u89c1\u5e76\u4e3a\u540e\u7eed\u6539\u8fdb\u6a21\u578b\u63d0\u4f9b\u4f9d\u636e\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5b9a\u91cf\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba9\u6a21\u578b\u5bf9\u201c\u9053\u5fb7\u4e3b\u4f53\u4ecb\u5165\u610f\u613f\u201d\u8fdb\u884c\u8bc4\u4f30\uff0c\u6765\u68c0\u6d4b\u548c\u8861\u91cf\u4e0d\u540c\u751f\u6210\u5f0fAI\u6a21\u578b\u5bf9\u6027\u522b\u3001\u79cd\u65cf\u548c\u5e74\u9f84\u7b49\u7fa4\u4f53\u7684\u504f\u89c1\u3002\u65b9\u6cd5\u7279\u522b\u5173\u6ce8\u5398\u6e05\u4e3b\u6d41\u6c34\u5e73\u7ebf\u8eab\u4efd\uff08\u5373\u767d\u4eba\u4e2d\u9752\u5e74\u7537\u6027\uff09\u4e0e\u5176\u4ed6\u4eba\u53e3\u8eab\u4efd\u7684\u5173\u7cfb\u53ca\u503e\u5411\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u524d\u4e3b\u6d41\u5927\u6a21\u578b\u5c06\u2018\u57fa\u7ebf\u2019\u4eba\u53e3\u754c\u5b9a\u4e3a\u767d\u4eba\u4e2d\u5e74\u6216\u9752\u5e74\u7537\u6027\uff0c\u4f46\u666e\u904d\u5b58\u5728\u975e\u57fa\u7ebf\u7fa4\u4f53\u6bd4\u57fa\u7ebf\u7fa4\u4f53\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u5408\u4f5c\u610f\u613f\u3002\u8fd9\u8868\u660e\u6a21\u578b\u4e2d\u5b58\u5728\u4ea4\u7ec7\u7684\u4e24\u79cd\u504f\u89c1\uff0c\u8fd9\u4e00\u65b0\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u533a\u5206\u8fd9\u6837\u7684\u590d\u5408\u504f\u89c1\u3002", "conclusion": "\u672c\u6587\u4e3a\u8bc4\u4f30\u548c\u533a\u5206LLM\u4e2d\u7684\u4eba\u53e3\u504f\u89c1\u63d0\u51fa\u4e86\u65b0\u65b9\u6cd5\uff0c\u5e76\u63ed\u793a\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u4eba\u53e3\u7fa4\u4f53\u95f4\u7684\u663e\u8457\u5dee\u5f02\uff0c\u80fd\u4e3a\u5f00\u53d1\u8005\u548c\u7528\u6237\u5728\u4f18\u5316\u6a21\u578b\u8f93\u51fa\u548c\u672a\u6765\u8bad\u7ec3\u4e2d\u63d0\u4f9b\u517c\u5bb9\u7684\u91cf\u5316\u53c2\u8003\u3002"}}
{"id": "2506.11400", "categories": ["cs.SE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.11400", "abs": "https://arxiv.org/abs/2506.11400", "authors": ["Yupeng Jiang", "Yao Deng", "Sebastian Schroder", "Linfeng Liang", "Suhaas Gambhir", "Alice James", "Avishkar Seth", "James Pirrie", "Yihao Zhang", "Xi Zheng"], "title": "A Step-by-Step Guide to Creating a Robust Autonomous Drone Testing Pipeline", "comment": null, "summary": "Autonomous drones are rapidly reshaping industries ranging from aerial\ndelivery and infrastructure inspection to environmental monitoring and disaster\nresponse. Ensuring the safety, reliability, and efficiency of these systems is\nparamount as they transition from research prototypes to mission-critical\nplatforms. This paper presents a step-by-step guide to establishing a robust\nautonomous drone testing pipeline, covering each critical stage:\nSoftware-in-the-Loop (SIL) Simulation Testing, Hardware-in-the-Loop (HIL)\nTesting, Controlled Real-World Testing, and In-Field Testing. Using practical\nexamples, including the marker-based autonomous landing system, we demonstrate\nhow to systematically verify drone system behaviors, identify integration\nissues, and optimize performance. Furthermore, we highlight emerging trends\nshaping the future of drone testing, including the integration of Neurosymbolic\nand LLMs, creating co-simulation environments, and Digital Twin-enabled\nsimulation-based testing techniques. By following this pipeline, developers and\nresearchers can achieve comprehensive validation, minimize deployment risks,\nand prepare autonomous drones for safe and reliable real-world operations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u7684\u81ea\u52a8\u5316\u65e0\u4eba\u673a\u6d4b\u8bd5\u6d41\u7a0b\uff0c\u4ece\u4eff\u771f\u5230\u5b9e\u5730\u9a8c\u8bc1\uff0c\u8f85\u4ee5\u5b9e\u4f8b\u548c\u65b0\u6280\u672f\u8d8b\u52bf\uff0c\u6709\u52a9\u4e8e\u4fdd\u969c\u65e0\u4eba\u673a\u7684\u5b9e\u9645\u5e94\u7528\u5b89\u5168\u9ad8\u6548\u3002", "motivation": "\u968f\u7740\u65e0\u4eba\u673a\u5728\u5404\u884c\u5404\u4e1a\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u957f\uff0c\u4fdd\u8bc1\u5176\u5b89\u5168\u6027\u3001\u53ef\u9760\u6027\u548c\u9ad8\u6548\u6027\u5bf9\u63a8\u52a8\u5176\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u7684\u5e7f\u6cdb\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6587\u7ae0\u63d0\u51fa\u5e76\u8be6\u7ec6\u9610\u8ff0\u4e86\u4e00\u4e2a\u5206\u9636\u6bb5\u7684\u65e0\u4eba\u673a\u81ea\u52a8\u5316\u6d4b\u8bd5\u6d41\u7a0b\uff0c\u5305\u62ec\u8f6f\u4ef6\u73af\u6d4b\u8bd5\uff08SIL\uff09\u3001\u786c\u4ef6\u73af\u6d4b\u8bd5\uff08HIL\uff09\u3001\u53d7\u63a7\u771f\u5b9e\u73af\u5883\u6d4b\u8bd5\u548c\u5b9e\u5730\u6d4b\u8bd5\uff0c\u5e76\u8f85\u4ee5\u5b9e\u9645\u6848\u4f8b\u8bf4\u660e\u3002", "result": "\u901a\u8fc7\u8be5\u6d4b\u8bd5\u6d41\u7a0b\uff0c\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u9a8c\u8bc1\u65e0\u4eba\u673a\u7684\u884c\u4e3a\u3001\u8bc6\u522b\u96c6\u6210\u95ee\u9898\u5e76\u4f18\u5316\u7cfb\u7edf\u6027\u80fd\u3002\u6b64\u5916\uff0c\u8fd8\u8ba8\u8bba\u4e86\u795e\u7ecf\u7b26\u53f7\u3001LLM\u96c6\u6210\u3001\u5171\u4eff\u771f\u73af\u5883\u548c\u6570\u5b57\u5b6a\u751f\u7b49\u65b0\u5174\u6d4b\u8bd5\u8d8b\u52bf\u3002", "conclusion": "\u672c\u6d41\u7a0b\u4e3a\u65e0\u4eba\u673a\u5f00\u53d1\u4e0e\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u6307\u5bfc\uff0c\u80fd\u6709\u6548\u63d0\u5347\u65e0\u4eba\u673a\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u4e0e\u53ef\u9760\u6027\uff0c\u964d\u4f4e\u90e8\u7f72\u98ce\u9669\uff0c\u4e3a\u5927\u89c4\u6a21\u5b9e\u9645\u5e94\u7528\u6253\u4e0b\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2506.11381", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11381", "abs": "https://arxiv.org/abs/2506.11381", "authors": ["Samuel Mensah", "Elena Kochkina", "Jabez Magomere", "Joy Prakash Sain", "Simerjot Kaur", "Charese Smiley"], "title": "A Variational Approach for Mitigating Entity Bias in Relation Extraction", "comment": "Accepted at ACL 2025 Main", "summary": "Mitigating entity bias is a critical challenge in Relation Extraction (RE),\nwhere models often rely excessively on entities, resulting in poor\ngeneralization. This paper presents a novel approach to address this issue by\nadapting a Variational Information Bottleneck (VIB) framework. Our method\ncompresses entity-specific information while preserving task-relevant features.\nIt achieves state-of-the-art performance on relation extraction datasets across\ngeneral, financial, and biomedical domains, in both indomain (original test\nsets) and out-of-domain (modified test sets with type-constrained entity\nreplacements) settings. Our approach offers a robust, interpretable, and\ntheoretically grounded methodology.", "AI": {"tldr": "\u901a\u8fc7\u53d8\u5206\u4fe1\u606f\u74f6\u9888\u65b9\u6cd5\u538b\u7f29\u5b9e\u4f53\u4fe1\u606f\uff0c\u4f5c\u8005\u663e\u8457\u63d0\u5347\u4e86\u5173\u7cfb\u62bd\u53d6\u6a21\u578b\u7684\u6cdb\u5316\u548c\u9c81\u68d2\u6027\uff0c\u5728\u591a\u4e2a\u9886\u57df\u548c\u6d4b\u8bd5\u8bbe\u7f6e\u53d6\u5f97\u4e86\u6700\u4f18\u7ed3\u679c\u3002", "motivation": "\u5173\u7cfb\u62bd\u53d6\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u5f80\u5f80\u8fc7\u5ea6\u4f9d\u8d56\u5b9e\u4f53\u672c\u8eab\uff0c\u5bfc\u81f4\u6cdb\u5316\u80fd\u529b\u8f83\u5dee\uff0c\u56e0\u6b64\u5982\u4f55\u51cf\u8f7b\u5b9e\u4f53\u504f\u89c1\u6210\u4e86\u5173\u952e\u6311\u6218\u3002", "method": "\u91c7\u7528\u53d8\u5206\u4fe1\u606f\u74f6\u9888\uff08VIB\uff09\u6846\u67b6\uff0c\u538b\u7f29\u4e0e\u5b9e\u4f53\u76f8\u5173\u7684\u4fe1\u606f\uff0c\u540c\u65f6\u4fdd\u7559\u4e0e\u4efb\u52a1\u76f8\u5173\u7684\u7279\u5f81\uff0c\u5b9e\u73b0\u5bf9\u5b9e\u4f53\u504f\u89c1\u7684\u7f13\u89e3\u3002", "result": "\u5728\u901a\u7528\u3001\u91d1\u878d\u548c\u751f\u7269\u533b\u5b66\u7b49\u4e0d\u540c\u9886\u57df\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u5728\u539f\u59cb\u6d4b\u8bd5\u96c6\uff08in-domain\uff09\u548c\u7ecf\u8fc7\u5b9e\u4f53\u7c7b\u578b\u7ea6\u675f\u66ff\u6362\u7684\u6d4b\u8bd5\u96c6\uff08out-of-domain\uff09\u4e2d\u5747\u53d6\u5f97\u4e86\u6700\u65b0\u7684\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5173\u7cfb\u62bd\u53d6\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u79cd\u9c81\u68d2\u3001\u53ef\u89e3\u91ca\u4e14\u5177\u5907\u7406\u8bba\u57fa\u7840\u7684\u65b0\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u8f7b\u4e86\u5b9e\u4f53\u504f\u89c1\u95ee\u9898\u3002"}}
{"id": "2506.11442", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.11442", "abs": "https://arxiv.org/abs/2506.11442", "authors": ["Yiyang Jin", "Kunzhao Xu", "Hang Li", "Xueting Han", "Yanmin Zhou", "Cheng Li", "Jing Bai"], "title": "ReVeal: Self-Evolving Code Agents via Iterative Generation-Verification", "comment": null, "summary": "Recent advances in reinforcement learning (RL) with verifiable outcome\nrewards have significantly improved the reasoning capabilities of large\nlanguage models (LLMs), especially when combined with multi-turn tool\ninteractions. However, existing methods lack both meaningful verification\nsignals from realistic environments and explicit optimization for verification,\nleading to unreliable self-verification. To address these limitations, we\npropose ReVeal, a multi-turn reinforcement learning framework that interleaves\ncode generation with explicit self-verification and tool-based evaluation.\nReVeal enables LLMs to autonomously generate test cases, invoke external tools\nfor precise feedback, and improves performance via a customized RL algorithm\nwith dense, per-turn rewards. As a result, ReVeal fosters the co-evolution of a\nmodel's generation and verification capabilities through RL training, expanding\nthe reasoning boundaries of the base model, demonstrated by significant gains\nin Pass@k on LiveCodeBench. It also enables test-time scaling into deeper\ninference regimes, with code consistently evolving as the number of turns\nincreases during inference, ultimately surpassing DeepSeek-R1-Zero-Qwen-32B.\nThese findings highlight the promise of ReVeal as a scalable and effective\nparadigm for building more robust and autonomous AI agents.", "AI": {"tldr": "\u63d0\u51fa\u4e86ReVeal\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u81ea\u6211\u9a8c\u8bc1\u548c\u5de5\u5177\u8bc4\u4f30\u878d\u5165\u4ee3\u7801\u751f\u6210\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e0e\u81ea\u6211\u9a8c\u8bc1\u80fd\u529b\uff0c\u5b9e\u9a8c\u5c55\u793a\u4e86\u5176\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u7684\u6027\u80fd\u8868\u73b0\uff0c\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u591a\u8f6e\u5de5\u5177\u4ea4\u4e92\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u540e\u63a8\u7406\u80fd\u529b\u663e\u8457\u63d0\u5347\uff0c\u4f46\u7f3a\u5c11\u771f\u5b9e\u73af\u5883\u4e0b\u6709\u610f\u4e49\u7684\u9a8c\u8bc1\u4fe1\u53f7\u548c\u9488\u5bf9\u9a8c\u8bc1\u7684\u663e\u5f0f\u4f18\u5316\uff0c\u5bfc\u81f4\u81ea\u6211\u9a8c\u8bc1\u80fd\u529b\u4e0d\u53ef\u9760\u3002", "method": "\u63d0\u51fa\u4e86ReVeal\uff0c\u8fd9\u662f\u4e00\u4e2a\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u4ee3\u7801\u751f\u6210\u3001\u663e\u5f0f\u81ea\u6211\u9a8c\u8bc1\u4e0e\u57fa\u4e8e\u5de5\u5177\u7684\u8bc4\u4f30\u76f8\u7ed3\u5408\u3002ReVeal\u8ba9LLM\u81ea\u4e3b\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff0c\u901a\u8fc7\u8c03\u7528\u5916\u90e8\u5de5\u5177\u83b7\u5f97\u7cbe\u51c6\u53cd\u9988\uff0c\u5e76\u901a\u8fc7\u8bbe\u8ba1\u5bc6\u96c6\uff08\u6bcf\u8f6e\uff09\u5956\u52b1\u7684\u5b9a\u5236\u5316RL\u7b97\u6cd5\u63d0\u5347\u6027\u80fd\u3002", "result": "ReVeal\u4fc3\u4f7f\u6a21\u578b\u751f\u6210\u4e0e\u9a8c\u8bc1\u80fd\u529b\u5728RL\u8bad\u7ec3\u4e2d\u5171\u540c\u8fdb\u5316\uff0c\u663e\u8457\u63d0\u5347LiveCodeBench\u4e0a\u7684Pass@k\u5206\u6570\u3002\u63a8\u7406\u65f6\u6a21\u578b\u968f\u7740\u4ea4\u4e92\u6b21\u6570\u589e\u52a0\uff0c\u4ee3\u7801\u6027\u80fd\u6301\u7eed\u8fdb\u5316\uff0c\u8d85\u8fc7\u4e86DeepSeek-R1-Zero-Qwen-32B\u3002", "conclusion": "ReVeal\u662f\u6784\u5efa\u66f4\u5065\u58ee\u548c\u81ea\u4e3bAI\u667a\u80fd\u4f53\u7684\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u6709\u6548\u7684\u65b0\u8303\u5f0f\u3002"}}
{"id": "2506.11389", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11389", "abs": "https://arxiv.org/abs/2506.11389", "authors": ["Karanpartap Singh", "Neil Band", "Ehsan Adeli"], "title": "Curriculum-Guided Layer Scaling for Language Model Pretraining", "comment": null, "summary": "As the cost of pretraining large language models grows, there is continued\ninterest in strategies to improve learning efficiency during this core training\nstage. Motivated by cognitive development, where humans gradually build\nknowledge as their brains mature, we propose Curriculum-Guided Layer Scaling\n(CGLS), a framework for compute-efficient pretraining that synchronizes\nincreasing data difficulty with model growth through progressive layer stacking\n(i.e. gradually adding layers during training). At the 100M parameter scale,\nusing a curriculum transitioning from synthetic short stories to general web\ndata, CGLS outperforms baseline methods on the question-answering benchmarks\nPIQA and ARC. Pretraining at the 1.2B scale, we stratify the DataComp-LM corpus\nwith a DistilBERT-based classifier and progress from general text to highly\ntechnical or specialized content. Our results show that progressively\nincreasing model depth alongside sample difficulty leads to better\ngeneralization and zero-shot performance on various downstream benchmarks.\nAltogether, our findings demonstrate that CGLS unlocks the potential of\nprogressive stacking, offering a simple yet effective strategy for improving\ngeneralization on knowledge-intensive and reasoning tasks.", "AI": {"tldr": "CGLS\u7ed3\u5408\u2018\u8bfe\u7a0b\u5b66\u4e60\u2019\u4e0e\u5c42\u6570\u9010\u6b65\u6269\u5c55\uff0c\u6709\u6548\u63d0\u5347\u5927\u6a21\u578b\u8bad\u7ec3\u6548\u7387\u548c\u590d\u6742\u4efb\u52a1\u7684\u6cdb\u5316\u8868\u73b0\uff0c\u662f\u5207\u5b9e\u53ef\u884c\u7684\u9884\u8bad\u7ec3\u4f18\u5316\u7b56\u7565\u3002", "motivation": "\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u6210\u672c\u9ad8\u6602\uff0c\u9700\u63d0\u5347\u5b66\u4e60\u6548\u7387\u3002\u53d7\u4eba\u7c7b\u8ba4\u77e5\u53d1\u5c55\u542f\u53d1\uff08\u77e5\u8bc6\u968f\u5927\u8111\u6210\u957f\u9012\u8fdb\uff09\uff0c\u63a2\u7d22\u901a\u8fc7\u9010\u6b65\u63d0\u5347\u6a21\u578b\u5bb9\u91cf\u548c\u6570\u636e\u96be\u5ea6\uff0c\u63d0\u5347\u77e5\u8bc6\u4e0e\u63a8\u7406\u4efb\u52a1\u7684\u8bad\u7ec3\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86Curriculum-Guided Layer Scaling (CGLS) \u6846\u67b6\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u901a\u8fc7\u5206\u9636\u6bb5\u589e\u52a0Transformer\u5c42\u6570\uff0c\u5e76\u914d\u5408\u9010\u6e10\u589e\u52a0\u7684\u6570\u636e\u96be\u5ea6\uff0c\u5b9e\u73b0\u6a21\u578b\u5bb9\u91cf\u548c\u8bad\u7ec3\u96be\u5ea6\u540c\u6b65\u8fdb\u9636\u3002\u5b9e\u9a8c\u5206\u4e3a100M\u53c2\u6570\u548c1.2B\u53c2\u6570\u4e24\u4e2a\u89c4\u6a21\uff0c\u5206\u522b\u91c7\u7528\u77ed\u6545\u4e8b\u5230\u7f51\u9875\u6570\u636e\u548c\u4e00\u822c\u6587\u672c\u5230\u9ad8\u6280\u672f\u6587\u672c\u7684\u8bfe\u7a0b\u8bad\u7ec3\u3002", "result": "\u5728100M\u53c2\u6570\u89c4\u6a21\u4e0b\uff0cCGLS\u5728PIQA\u548cARC\u95ee\u7b54\u4efb\u52a1\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff1b1.2B\u89c4\u6a21\u4e0a\u901a\u8fc7DistilBERT\u5206\u5c42\u6570\u636e\uff0c\u5b9e\u73b0\u4e86\u6cdb\u5316\u80fd\u529b\u548c\u96f6\u6837\u672c\u6027\u80fd\u7684\u63d0\u5347\u3002", "conclusion": "\u9010\u6b65\u589e\u52a0\u6a21\u578b\u6df1\u5ea6\u4e0e\u96be\u5ea6\u540c\u6b65\u7684\u6570\u636e\u8bad\u7ec3\u6709\u52a9\u4e8e\u63d0\u5347\u5927\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u548c\u63a8\u7406\u4efb\u52a1\u8868\u73b0\uff0cCGLS\u65b9\u6cd5\u6709\u6548\u91ca\u653e\u4e86\u6e10\u8fdb\u5806\u53e0\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.11451", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11451", "abs": "https://arxiv.org/abs/2506.11451", "authors": ["Md Nahidul Islam Opu", "Md Shahidul Islam", "Sara Rouhani", "Shaiful Chowdhury"], "title": "Understanding the Issue Types in Open Source Blockchain-based Software Projects with the Transformer-based BERTopic", "comment": null, "summary": "Blockchain-based software systems are increasingly deployed across diverse\ndomains, yet a systematic understanding of their development challenges remains\nlimited. This paper presents a large-scale empirical study of 497,742 issues\nmined from 1,209 open-source blockchain projects hosted on GitHub. Employing\nBERTopic, a transformer-based topic modeling technique, we identify 49 distinct\nissue topics and organize them hierarchically into 11 major subcategories. Our\nanalysis reveals that both general software development issues and\nblockchain-specific concerns are nearly equally represented, with Wallet\nManagement and UI Enhancement emerging as the most prominent topics. We further\nexamine the temporal evolution of issue categories and resolution times,\nfinding that Wallet issues not only dominate in frequency but also exhibit the\nlongest resolution time. Conversely, Mechanisms issues are resolved\nsignificantly faster. Issue frequency surged after 2016 with the rise of\nEthereum and decentralized applications, but declined after 2022. These\nfindings enhance our understanding of blockchain software maintenance,\ninforming the development of specialized tools and practices to improve\nrobustness and maintainability.", "AI": {"tldr": "\u4f5c\u8005\u5206\u6790\u4e861209\u4e2a\u533a\u5757\u94fe\u9879\u76ee\u8fd150\u4e07\u6761issue\uff0c\u63ed\u793a\u4e86\u533a\u5757\u94fe\u5f00\u53d1\u4e2d\u5e38\u89c1\u7684\u901a\u7528\u548c\u7279\u6709\u95ee\u9898\uff0c\u5c24\u5176\u662f\u94b1\u5305\u7ba1\u7406\u95ee\u9898\u6700\u7a81\u51fa\u4e14\u96be\u4ee5\u89e3\u51b3\uff0c\u5e76\u6307\u51fa\u968f\u7740DApp\u5174\u8d77issue\u6570\u91cf\u9ad8\u5cf0\u5df2\u8fc7\u3002\u7ed3\u679c\u53ef\u4e3a\u533a\u5757\u94fe\u7ef4\u62a4\u5de5\u5177\u548c\u5b9e\u8df5\u6539\u8fdb\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u968f\u7740\u533a\u5757\u94fe\u5728\u5404\u9886\u57df\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u76ee\u524d\u5bf9\u533a\u5757\u94fe\u8f6f\u4ef6\u5f00\u53d1\u6311\u6218\u7684\u7cfb\u7edf\u6027\u7406\u89e3\u4ecd\u7136\u6709\u9650\u3002\u672c\u7814\u7a76\u65e8\u5728\u6df1\u5165\u63ed\u793a\u5f00\u6e90\u533a\u5757\u94fe\u9879\u76ee\u5728\u5f00\u53d1\u548c\u7ef4\u62a4\u8fc7\u7a0b\u4e2d\u9762\u4e34\u7684\u5b9e\u9645\u95ee\u9898\u548c\u96be\u70b9\u3002", "method": "\u5bf91,209\u4e2a\u5f00\u6e90\u533a\u5757\u94fe\u9879\u76ee\u7684497,742\u4e2aGitHub issue\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\u3002\u7814\u7a76\u4f7f\u7528\u4e86BERTopic\uff08\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u4e3b\u9898\u6a21\u578b\u6280\u672f\uff09\u8bc6\u522b\u51fa49\u4e2a\u4e0d\u540c\u7684\u95ee\u9898\u4e3b\u9898\uff0c\u5e76\u5c06\u5176\u5c42\u6b21\u5316\u5f52\u4e3a11\u4e2a\u4e3b\u8981\u5b50\u7c7b\u522b\uff0c\u540c\u65f6\u5206\u6790\u4e86\u8fd9\u4e9b\u95ee\u9898\u7684\u65f6\u95f4\u6f14\u53d8\u8d8b\u52bf\u548c\u89e3\u51b3\u65f6\u957f\u3002", "result": "\u53d1\u73b0\u533a\u5757\u94fe\u9879\u76ee\u4e2d\u65e2\u6709\u901a\u7528\u7684\u8f6f\u4ef6\u5f00\u53d1\u95ee\u9898\uff0c\u4e5f\u6709\u8f83\u591a\u533a\u5757\u94fe\u7279\u6709\u7684\u96be\u9898\uff0c\u5982\u94b1\u5305\u7ba1\u7406\u548c\u754c\u9762\u589e\u5f3a\u662f\u6700\u7a81\u51fa\u7684\u4e3b\u9898\u3002\u94b1\u5305\u76f8\u5173\u7684\u95ee\u9898\u4e0d\u4ec5\u6700\u591a\uff0c\u800c\u4e14\u89e3\u51b3\u65f6\u95f4\u4e5f\u6700\u957f\uff1b\u673a\u5236\u7c7b\u95ee\u9898\u5219\u80fd\u8f83\u5feb\u5f97\u5230\u5904\u7406\u3002\u81ea2016\u5e74\u4ee5\u592a\u574a\u548cDApp\u5174\u8d77\u540e\uff0c\u95ee\u9898\u6570\u91cf\u5feb\u901f\u589e\u52a0\uff0c\u4f46\u81ea2022\u5e74\u8d77\u51fa\u73b0\u4e0b\u964d\u8d8b\u52bf\u3002", "conclusion": "\u672c\u7814\u7a76\u4e30\u5bcc\u4e86\u5bf9\u533a\u5757\u94fe\u8f6f\u4ef6\u7ef4\u62a4\u95ee\u9898\u7684\u7406\u89e3\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u6709\u9488\u5bf9\u6027\u7684\u5de5\u5177\u548c\u5b9e\u8df5\u6765\u63d0\u5347\u533a\u5757\u94fe\u7cfb\u7edf\u7684\u5065\u58ee\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u3002"}}
{"id": "2506.11410", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11410", "abs": "https://arxiv.org/abs/2506.11410", "authors": ["Wilson Lau", "Youngwon Kim", "Sravanthi Parasa", "Md Enamul Haque", "Anand Oka", "Jay Nanduri"], "title": "Predicting Early-Onset Colorectal Cancer with Large Language Models", "comment": "Paper accepted for the proceedings of the 2025 American Medical\n  Informatics Association Annual Symposium (AMIA)", "summary": "The incidence rate of early-onset colorectal cancer (EoCRC, age < 45) has\nincreased every year, but this population is younger than the recommended age\nestablished by national guidelines for cancer screening. In this paper, we\napplied 10 different machine learning models to predict EoCRC, and compared\ntheir performance with advanced large language models (LLM), using patient\nconditions, lab results, and observations within 6 months of patient journey\nprior to the CRC diagnoses. We retrospectively identified 1,953 CRC patients\nfrom multiple health systems across the United States. The results demonstrated\nthat the fine-tuned LLM achieved an average of 73% sensitivity and 91%\nspecificity.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5fae\u8c03\u540e\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u57fa\u4e8e\u8bca\u65ad\u524d6\u4e2a\u6708\u7684\u6570\u636e\uff0c\u4ee5\u8f83\u9ad8\u7075\u654f\u5ea6\u548c\u7279\u5f02\u6027\u9884\u6d4b45\u5c81\u4ee5\u4e0b\u65e9\u53d1\u7ed3\u76f4\u80a0\u764c\uff0c\u6709\u671b\u5f25\u8865\u7b5b\u67e5\u76f2\u533a\uff0c\u63d0\u5347\u65e9\u671f\u8bca\u65ad\u80fd\u529b\u3002", "motivation": "\u65e9\u53d1\u7ed3\u76f4\u80a0\u764c\uff08EoCRC\uff0c<45\u5c81\uff09\u53d1\u75c5\u7387\u9010\u5e74\u4e0a\u5347\uff0c\u4f46\u73b0\u6709\u7684\u56fd\u5bb6\u7b5b\u67e5\u6307\u5357\u63a8\u8350\u7684\u5e74\u9f84\u8f83\u9ad8\uff0c\u5bfc\u81f4\u5e74\u8f7b\u4eba\u7fa4\u672a\u80fd\u8986\u76d6\u3002\u9700\u8981\u627e\u5230\u6709\u6548\u7684\u65e9\u671f\u9884\u6d4b\u624b\u6bb5\u3002", "method": "\u6536\u96c6\u4e86\u6765\u81ea\u7f8e\u56fd\u591a\u5bb6\u533b\u7597\u7cfb\u7edf\u76841,953\u4f8b\u7ed3\u76f4\u80a0\u764c\u60a3\u8005\u75c5\u5386\u6570\u636e\uff0c\u5229\u7528\u60a3\u8005\u8bca\u65ad\u524d6\u4e2a\u6708\u7684\u4e34\u5e8a\u72b6\u51b5\u3001\u5b9e\u9a8c\u5ba4\u7ed3\u679c\u548c\u89c2\u5bdf\u6570\u636e\uff0c\u5206\u522b\u5e94\u752810\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fdb\u884cEoCRC\u9884\u6d4b\uff0c\u5e76\u8fdb\u884c\u6027\u80fd\u5bf9\u6bd4\u3002", "result": "\u5fae\u8c03\u540e\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u9884\u6d4bEoCRC\u65b9\u9762\u53d6\u5f97\u4e8673%\u7684\u7075\u654f\u5ea6\u548c91%\u7684\u7279\u5f02\u6027\uff0c\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6709\u671b\u4f5c\u4e3a\u5e74\u8f7b\u4eba\u7fa4\u4e2d\u65e9\u53d1\u7ed3\u76f4\u80a0\u764c\u65e9\u7b5b\u7684\u6709\u6548\u5de5\u5177\uff0c\u80fd\u663e\u8457\u63d0\u5347\u75be\u75c5\u65e9\u671f\u68c0\u6d4b\u7387\u3002"}}
{"id": "2506.11484", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11484", "abs": "https://arxiv.org/abs/2506.11484", "authors": ["Haoshen", "Ming Hu", "Xiaofei Xie", "Jiaye Li", "Mingsong Chen"], "title": "VulStamp: Vulnerability Assessment using Large Language Model", "comment": null, "summary": "Although modern vulnerability detection tools enable developers to\nefficiently identify numerous security flaws, indiscriminate remediation\nefforts often lead to superfluous development expenses. This is particularly\ntrue given that a substantial portion of detected vulnerabilities either\npossess low exploitability or would incur negligible impact in practical\noperational environments. Consequently, vulnerability severity assessment has\nemerged as a critical component in optimizing software development efficiency.\nExisting vulnerability assessment methods typically rely on manually crafted\ndescriptions associated with source code artifacts. However, due to variability\nin description quality and subjectivity in intention interpretation, the\nperformance of these methods is seriously limited. To address this issue, this\npaper introduces VulStamp, a novel intention-guided framework, to facilitate\ndescription-free vulnerability assessment. Specifically, VulStamp adopts static\nanalysis together with Large Language Model (LLM) to extract the intention\ninformation of vulnerable code. Based on the intention information, VulStamp\nuses a prompt-tuned model for vulnerability assessment. Furthermore, to\nmitigate the problem of imbalanced data associated with vulnerability types,\nVulStamp integrates a Reinforcement Learning (RL)-based prompt-tuning method to\ntrain the assessment model.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u65e0\u9700\u4eba\u5de5\u63cf\u8ff0\u7684\u65b0\u578b\u6f0f\u6d1e\u4e25\u91cd\u6027\u8bc4\u4f30\u65b9\u6cd5VulStamp\uff0c\u901a\u8fc7\u610f\u56fe\u6316\u6398\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u8bc4\u4f30\u6548\u679c\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u6548\u7387\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u6f0f\u6d1e\u68c0\u6d4b\u5de5\u5177\u867d\u7136\u9ad8\u6548\uff0c\u4f46\u4fee\u590d\u6240\u6709\u53d1\u73b0\u7684\u6f0f\u6d1e\u53ef\u80fd\u5bfc\u81f4\u4e0d\u5fc5\u8981\u7684\u5f00\u53d1\u6210\u672c\uff0c\u7279\u522b\u662f\u8bb8\u591a\u6f0f\u6d1e\u5b9e\u9645\u53ef\u5229\u7528\u6027\u4f4e\u6216\u5f71\u54cd\u5c0f\u3002\u56e0\u6b64\uff0c\u5408\u7406\u8bc4\u4f30\u6f0f\u6d1e\u4e25\u91cd\u6027\u5bf9\u4e8e\u4f18\u5316\u5f00\u53d1\u6548\u7387\u81f3\u5173\u91cd\u8981\u3002\u4f46\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4eba\u5de5\u7f16\u5199\u7684\u63cf\u8ff0\uff0c\u53d7\u63cf\u8ff0\u8d28\u91cf\u548c\u4e3b\u89c2\u89e3\u8bfb\u5f71\u54cd\u5927\uff0c\u5bfc\u81f4\u8bc4\u4f30\u6548\u679c\u6709\u9650\u3002", "method": "\u63d0\u51faVulStamp\u6846\u67b6\uff0c\u7ed3\u5408\u9759\u6001\u5206\u6790\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u81ea\u52a8\u6316\u6398\u6f0f\u6d1e\u4ee3\u7801\u7684\u610f\u56fe\u4fe1\u606f\uff0c\u5e76\u57fa\u4e8e\u8fd9\u4e9b\u610f\u56fe\u4fe1\u606f\u5229\u7528prompt-tuned\u6a21\u578b\u8fdb\u884c\u6f0f\u6d1e\u4e25\u91cd\u6027\u8bc4\u4f30\u3002\u6b64\u5916\uff0c\u91c7\u7528\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684prompt-tuning\u65b9\u6cd5\u7f13\u89e3\u6f0f\u6d1e\u7c7b\u578b\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "VulStamp\u80fd\u5728\u4e0d\u4f9d\u8d56\u4eba\u5de5\u63cf\u8ff0\u7684\u60c5\u51b5\u4e0b\uff0c\u4ee5\u610f\u56fe\u4e3a\u5bfc\u5411\u63d0\u9ad8\u6f0f\u6d1e\u4e25\u91cd\u6027\u8bc4\u4f30\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5e76\u6210\u529f\u89e3\u51b3\u4e86\u7531\u4e8e\u6f0f\u6d1e\u7c7b\u578b\u5206\u5e03\u4e0d\u5747\u5e26\u6765\u7684\u8bc4\u4f30\u504f\u5dee\u95ee\u9898\u3002", "conclusion": "VulStamp\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u610f\u56fe\u611f\u77e5\u53ca\u5f3a\u5316\u5b66\u4e60\u8c03\u4f18\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6f0f\u6d1e\u4e25\u91cd\u6027\u8bc4\u4f30\u7684\u81ea\u52a8\u5316\u548c\u51c6\u786e\u6027\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u8005\u5408\u7406\u5206\u914d\u4fee\u590d\u8d44\u6e90\uff0c\u4f18\u5316\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\u3002"}}
{"id": "2506.11418", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11418", "abs": "https://arxiv.org/abs/2506.11418", "authors": ["Jie Hu", "Shengnan Wang", "Yutong He", "Ping Gong", "Jiawei Yi", "Juncheng Zhang", "Youhui Bai", "Renhai Chen", "Gong Zhang", "Cheng Li", "Kun Yuan"], "title": "Efficient Long-Context LLM Inference via KV Cache Clustering", "comment": null, "summary": "Large language models (LLMs) with extended context windows have become\nincreasingly prevalent for tackling complex tasks. However, the substantial\nKey-Value (KV) cache required for long-context LLMs poses significant\ndeployment challenges. Existing approaches either discard potentially critical\ninformation needed for future generations or offer limited efficiency gains due\nto high computational overhead. In this paper, we introduce Chelsea, a simple\nyet effective framework for online KV cache clustering. Our approach is based\non the observation that key states exhibit high similarity along the sequence\ndimension. To enable efficient clustering, we divide the sequence into chunks\nand propose Chunked Soft Matching, which employs an alternating partition\nstrategy within each chunk and identifies clusters based on similarity. Chelsea\nthen merges the KV cache within each cluster into a single centroid.\nAdditionally, we provide a theoretical analysis of the computational complexity\nand the optimality of the intra-chunk partitioning strategy. Extensive\nexperiments across various models and long-context benchmarks demonstrate that\nChelsea achieves up to 80% reduction in KV cache memory usage while maintaining\ncomparable model performance. Moreover, with minimal computational overhead,\nChelsea accelerates the decoding stage of inference by up to 3.19$\\times$ and\nreduces end-to-end latency by up to 2.72$\\times$.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faChelsea\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u7247\u805a\u7c7b\u5408\u5e76KV\u7f13\u5b58\uff0c\u663e\u8457\u51cf\u5c11\u5185\u5b58\u6d88\u8017\uff0c\u5e76\u52a0\u901f\u5927\u8bed\u8a00\u6a21\u578b\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\uff0c\u4e14\u6a21\u578b\u8868\u73b0\u65e0\u663e\u8457\u635f\u5931\uff0c\u5bf9\u5b9e\u9645\u90e8\u7f72\u6781\u5177\u610f\u4e49\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fd1\u5e74\u6765\u5e7f\u6cdb\u5e94\u7528\u4e8e\u590d\u6742\u4efb\u52a1\uff0c\u4f46\u5176\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u9700\u8981\u5de8\u5927\u7684Key-Value\uff08KV\uff09\u7f13\u5b58\uff0c\u5e26\u6765\u90e8\u7f72\u548c\u8ba1\u7b97\u4e0a\u7684\u96be\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4e22\u5f03\u5bf9\u540e\u7eed\u751f\u6210\u53ef\u80fd\u91cd\u8981\u7684\u4fe1\u606f\uff0c\u8981\u4e48\u5e26\u6765\u8f83\u5927\u7b97\u529b\u5f00\u9500\uff0c\u6548\u7387\u63d0\u5347\u6709\u9650\u3002\u56e0\u6b64\u5bfb\u6c42\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u4f4e\u635f\u8017\u7684KV cache\u7ba1\u7406\u65b9\u5f0f\u6210\u4e3a\u4e9f\u9700\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86Chelsea\u6846\u67b6\uff0c\u5bf9KV\u7f13\u5b58\u8fdb\u884c\u5728\u7ebf\u805a\u7c7b\u7ba1\u7406\u3002\u5177\u4f53\u505a\u6cd5\u662f\u5c06\u5e8f\u5217\u5206\u7247\uff08chunk\uff09\uff0c\u5728\u6bcf\u4e2achunk\u5185\u90e8\u91c7\u7528\u4ea4\u66ff\u5206\u533a\u7b56\u7565\uff08Chunked Soft Matching\uff09\u6309\u76f8\u4f3c\u6027\u805a\u7c7b\uff0c\u7136\u540e\u5c06\u6bcf\u4e2a\u805a\u7c7b\u7684KV\u7f13\u5b58\u5408\u5e76\u4e3a\u4e00\u4e2a\u4e2d\u5fc3\u70b9\uff08centroid\uff09\u3002\u4f5c\u8005\u8fd8\u7ed9\u51fa\u4e86\u7406\u8bba\u4e0a\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u5206\u533a\u7b56\u7565\u6700\u4f18\u6027\u7684\u5206\u6790\u3002", "result": "\u5728\u5404\u7c7b\u6a21\u578b\u548c\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cChelsea\u6846\u67b6\u53ef\u4ee5\u4f7fKV\u7f13\u5b58\u7684\u5185\u5b58\u4f7f\u7528\u91cf\u51cf\u5c11\u9ad8\u8fbe80%\uff0c\u540c\u65f6\u6a21\u578b\u6027\u80fd\u51e0\u4e4e\u65e0\u635f\u3002\u6b64\u5916\uff0c\u5728\u8ba1\u7b97\u5f00\u9500\u6781\u5c0f\u7684\u524d\u63d0\u4e0b\uff0cChelsea\u52a0\u901f\u63a8\u7406\u89e3\u7801\u9636\u6bb5\u8fbe3.19\u500d\uff0c\u7aef\u5230\u7aef\u65f6\u5ef6\u964d\u5e45\u53ef\u8fbe2.72\u500d\u3002", "conclusion": "Chelsea\u662f\u4e00\u79cd\u7b80\u5355\u9ad8\u6548\u7684KV\u7f13\u5b58\u805a\u7c7b\u6846\u67b6\uff0c\u80fd\u591f\u5927\u5e45\u964d\u4f4e\u5185\u5b58\u6d88\u8017\uff0c\u52a0\u901f\u63a8\u7406\u6d41\u7a0b\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u4e0d\u5931\u3002\u5176\u601d\u8def\u548c\u65b9\u6cd5\u5bf9\u4e8e\u957f\u4e0a\u4e0b\u6587LLM\u7684\u5b9e\u9645\u90e8\u7f72\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.11525", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11525", "abs": "https://arxiv.org/abs/2506.11525", "authors": ["Michael Grohs", "Nadine Cordes", "Jana-Rebecca Rehse"], "title": "A Procedural Framework for Assessing the Desirability of Process Deviations", "comment": null, "summary": "Conformance checking techniques help process analysts to identify where and\nhow process executions deviate from a process model. However, they cannot\ndetermine the desirability of these deviations, i.e., whether they are\nproblematic, acceptable or even beneficial for the process. Such desirability\nassessments are crucial to derive actions, but process analysts typically\nconduct them in a manual, ad-hoc way, which can be time-consuming, subjective,\nand irreplicable. To address this problem, this paper presents a procedural\nframework to guide process analysts in systematically assessing deviation\ndesirability. It provides a step-by-step approach for identifying which input\nfactors to consider in what order to categorize deviations into mutually\nexclusive desirability categories, each linked to action recommendations. The\nframework is based on a review and conceptualization of existing literature on\ndeviation desirability, which is complemented by empirical insights from\ninterviews with process analysis practitioners and researchers. We evaluate the\nframework through a desirability assessment task conducted with practitioners,\nindicating that the framework effectively enables them to streamline the\nassessment for a thorough yet concise evaluation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u4e2a\u64cd\u4f5c\u6027\u6d41\u7a0b\u6846\u67b6\uff0c\u7528\u4e8e\u5e2e\u52a9\u5206\u6790\u5e08\u7cfb\u7edf\u5730\u8bc4\u4f30\u548c\u5206\u7c7b\u6d41\u7a0b\u6267\u884c\u504f\u5dee\u7684\u53ef\u53d6\u6027\uff0c\u5e76\u4e3a\u6bcf\u7c7b\u504f\u5dee\u63d0\u4f9b\u5177\u4f53\u7684\u884c\u52a8\u5efa\u8bae\uff0c\u4ece\u800c\u63d0\u5347\u8bc4\u4f30\u6548\u7387\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u4e00\u81f4\u6027\u68c0\u67e5\u6280\u672f\u53ef\u4ee5\u53d1\u73b0\u8fc7\u7a0b\u6267\u884c\u4e0e\u6a21\u578b\u4e4b\u95f4\u7684\u504f\u5dee\uff0c\u4f46\u65e0\u6cd5\u786e\u5b9a\u8fd9\u4e9b\u504f\u5dee\u662f\u6709\u5bb3\u3001\u53ef\u63a5\u53d7\u8fd8\u662f\u6709\u76ca\u7684\u3002\u504f\u5dee\u7684\u53ef\u53d6\u6027\u8bc4\u4f30\u5bf9\u4e8e\u91c7\u53d6\u884c\u52a8\u81f3\u5173\u91cd\u8981\uff0c\u800c\u76ee\u524d\u8fd9\u4e00\u6b65\u9aa4\u5f80\u5f80\u4f9d\u8d56\u5206\u6790\u4eba\u5458\u624b\u52a8\u3001\u4e3b\u89c2\u5730\u5224\u65ad\uff0c\u6548\u7387\u4f4e\u3001\u91cd\u590d\u6027\u5dee\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u64cd\u4f5c\u6027\u6846\u67b6\uff0c\u6307\u5bfc\u8fc7\u7a0b\u5206\u6790\u4eba\u5458\u7cfb\u7edf\u5730\u8bc4\u4f30\u8fc7\u7a0b\u504f\u5dee\u7684\u53ef\u53d6\u6027\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u73b0\u6709\u6587\u732e\u7efc\u8ff0\u548c\u4e13\u5bb6\u8bbf\u8c08\u7684\u5b9e\u8bc1\u89c1\u89e3\uff0c\u91c7\u7528\u5206\u6b65\u65b9\u6cd5\uff0c\u6709\u5e8f\u8bc6\u522b\u8f93\u5165\u56e0\u7d20\uff0c\u5e76\u5c06\u504f\u5dee\u5f52\u7c7b\u5230\u4e0d\u540c\u7684\u53ef\u53d6\u6027\u7c7b\u522b\u4e2d\uff0c\u6bcf\u79cd\u7c7b\u522b\u90fd\u9644\u6709\u884c\u52a8\u5efa\u8bae\u3002\u6846\u67b6\u7684\u6709\u6548\u6027\u901a\u8fc7\u5b9e\u9645\u4ece\u4e1a\u8005\u53c2\u4e0e\u7684\u8bc4\u4f30\u4efb\u52a1\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u5e2e\u52a9\u5206\u6790\u4eba\u5458\u9ad8\u6548\u4e14\u5168\u9762\u5730\u8fdb\u884c\u504f\u5dee\u53ef\u53d6\u6027\u8bc4\u4f30\uff0c\u4ece\u800c\u4f18\u5316\u8bc4\u4f30\u8fc7\u7a0b\u3002", "conclusion": "\u7cfb\u7edf\u6027\u4e14\u6807\u51c6\u5316\u7684\u504f\u5dee\u53ef\u53d6\u6027\u8bc4\u4f30\u6846\u67b6\u80fd\u591f\u63d0\u5347\u5206\u6790\u6548\u7387\u3001\u51cf\u5c11\u4e3b\u89c2\u6027\uff0c\u6709\u52a9\u4e8e\u66f4\u5408\u7406\u5730\u6307\u5bfc\u5b9e\u9645\u8fc7\u7a0b\u7ba1\u7406\u4e2d\u7684\u6539\u8fdb\u884c\u52a8\u3002"}}
{"id": "2506.11425", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11425", "abs": "https://arxiv.org/abs/2506.11425", "authors": ["Jeff Da", "Clinton Wang", "Xiang Deng", "Yuntao Ma", "Nikhil Barhate", "Sean Hendryx"], "title": "Agent-RLVR: Training Software Engineering Agents via Guidance and Environment Rewards", "comment": null, "summary": "Reinforcement Learning from Verifiable Rewards (RLVR) has been widely adopted\nas the de facto method for enhancing the reasoning capabilities of large\nlanguage models and has demonstrated notable success in verifiable domains like\nmath and competitive programming tasks. However, the efficacy of RLVR\ndiminishes significantly when applied to agentic environments. These settings,\ncharacterized by multi-step, complex problem solving, lead to high failure\nrates even for frontier LLMs, as the reward landscape is too sparse for\neffective model training via conventional RLVR. In this work, we introduce\nAgent-RLVR, a framework that makes RLVR effective in challenging agentic\nsettings, with an initial focus on software engineering tasks. Inspired by\nhuman pedagogy, Agent-RLVR introduces agent guidance, a mechanism that actively\nsteers the agent towards successful trajectories by leveraging diverse\ninformational cues. These cues, ranging from high-level strategic plans to\ndynamic feedback on the agent's errors and environmental interactions, emulate\na teacher's guidance, enabling the agent to navigate difficult solution spaces\nand promotes active self-improvement via additional environment exploration. In\nthe Agent-RLVR training loop, agents first attempt to solve tasks to produce\ninitial trajectories, which are then validated by unit tests and supplemented\nwith agent guidance. Agents then reattempt with guidance, and the agent policy\nis updated with RLVR based on the rewards of these guided trajectories.\nAgent-RLVR elevates the pass@1 performance of Qwen-2.5-72B-Instruct from 9.4%\nto 22.4% on SWE-Bench Verified. We find that our guidance-augmented RLVR data\nis additionally useful for test-time reward model training, shown by further\nboosting pass@1 to 27.8%. Agent-RLVR lays the groundwork for training agents\nwith RLVR in complex, real-world environments where conventional RL methods\nstruggle.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAgent-RLVR\u6846\u67b6\uff0c\u5728\u5f15\u5165\u7c7b\u4f3c\u6559\u5e08\u6307\u5bfc\u7684\u673a\u5236\u540e\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u5927\u6a21\u578b\u5728\u590d\u6742\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u663e\u8457\u8d85\u8d8a\u4f20\u7edfRLVR\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684RLVR\u65b9\u6cd5\u5728\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u5c24\u5176\u5728\u53ef\u9a8c\u8bc1\u4efb\u52a1\uff08\u5982\u6570\u5b66\u548c\u7f16\u7a0b\u7ade\u8d5b\uff09\u4e2d\u8f83\u4e3a\u6210\u529f\uff1b\u4f46\u5728\u591a\u6b65\u3001\u590d\u6742\u7684agentic\u73af\u5883\uff08\u5982\u8f6f\u4ef6\u5de5\u7a0b\uff09\u4e2d\u6548\u679c\u663e\u8457\u4e0b\u964d\uff0c\u539f\u56e0\u662f\u5956\u52b1\u8fc7\u4e8e\u7a00\u758f\u3001\u8bad\u7ec3\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e86Agent-RLVR\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u201cagent guidance\u201d\u673a\u5236\u6a21\u62df\u4eba\u7c7b\u6559\u5e08\u7684\u5f15\u5bfc\u65b9\u5f0f\uff0c\u5229\u7528\u7b56\u7565\u8ba1\u5212\u3001\u52a8\u6001\u53cd\u9988\u7b49\u591a\u79cd\u4fe1\u606f\u6e90\u6307\u5bfc\u667a\u80fd\u4f53\u8fdb\u884c\u4efb\u52a1\u89e3\u51b3\u3002\u8bad\u7ec3\u6d41\u7a0b\u5305\u62ec\u521d\u59cb\u5c1d\u8bd5\u2014\u5355\u5143\u6d4b\u8bd5\u9a8c\u8bc1\u2014\u5f15\u5bfc\u8865\u5145\u2014\u518d\u6b21\u5c1d\u8bd5\uff0c\u6700\u7ec8\u4f7f\u7528RLVR\u66f4\u65b0\u6a21\u578b\u3002", "result": "Agent-RLVR\u5c06Qwen-2.5-72B-Instruct\u5728SWE-Bench Verified\u57fa\u51c6\u4e0a\u7684pass@1\u8868\u73b0\u4ece9.4%\u63d0\u5347\u523022.4%\u3002\u5728\u5f15\u5bfc\u589e\u5f3a\u6570\u636e\u7684\u8f85\u52a9\u4e0b\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u523027.8%\u3002", "conclusion": "Agent-RLVR\u6709\u6548\u7f13\u89e3\u4e86\u4f20\u7edfRLVR\u5728\u590d\u6742agentic\u73af\u5883\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5b9e\u590d\u6742\u73af\u5883\u4e2d\u7684\u8bad\u7ec3\u5960\u5b9a\u57fa\u7840\uff0c\u5e76\u5177\u6709\u5b9e\u9645\u63d0\u5347\u6548\u679c\u3002"}}
{"id": "2506.11548", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11548", "abs": "https://arxiv.org/abs/2506.11548", "authors": ["Fabian C. Pe\u00f1a"], "title": "Augmenting the Generality and Performance of Large Language Models for Software Engineering", "comment": null, "summary": "Large Language Models (LLMs) are revolutionizing software engineering (SE),\nwith special emphasis on code generation and analysis. However, their\napplications to broader SE practices including conceptualization, design, and\nother non-code tasks, remain partially underexplored. This research aims to\naugment the generality and performance of LLMs for SE by (1) advancing the\nunderstanding of how LLMs with different characteristics perform on various\nnon-code tasks, (2) evaluating them as sources of foundational knowledge in SE,\nand (3) effectively detecting hallucinations on SE statements. The expected\ncontributions include a variety of LLMs trained and evaluated on\ndomain-specific datasets, new benchmarks on foundational knowledge in SE, and\nmethods for detecting hallucinations. Initial results in terms of performance\nimprovements on various non-code tasks are promising.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6269\u5c55\u4e86LLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u975e\u4ee3\u7801\u4efb\u52a1\uff08\u5982\u8bbe\u8ba1\u3001\u6982\u5ff5\u5316\u7b49\uff09\u4e0a\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u65b0\u8bc4\u6d4b\u3001\u4e13\u7528\u6570\u636e\u96c6\u548c\u5e7b\u89c9\u68c0\u6d4b\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u8868\u73b0\uff0c\u4e3a\u5176\u66f4\u5e7f\u6cdb\u5e94\u7528\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5df2\u5728\u4ee3\u7801\u751f\u6210\u548c\u5206\u6790\u4e0a\u5e26\u6765\u9769\u547d\u6027\u53d8\u9769\uff0c\u4f46\u5728\u5305\u62ec\u6982\u5ff5\u5316\u3001\u8bbe\u8ba1\u7b49\u8f6f\u4ef6\u5de5\u7a0b\u975e\u4ee3\u7801\u4efb\u52a1\u4e0a\u7684\u5e94\u7528\u4ecd\u4e0d\u5145\u5206\u3002\u672c\u6587\u65e8\u5728\u63d0\u5347LLM\u5728\u66f4\u5e7f\u6cdb\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u901a\u7528\u6027\u548c\u6027\u80fd\u3002", "method": "\u672c\u7814\u7a76\uff1a\uff081\uff09\u5206\u6790\u4e0d\u540c\u7c7b\u578bLLM\u5728\u591a\u79cd\u975e\u4ee3\u7801\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff1b\uff082\uff09\u8bc4\u4f30LLM\u4f5c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u57fa\u7840\u77e5\u8bc6\u6765\u6e90\u7684\u6709\u6548\u6027\uff1b\uff083\uff09\u63d0\u51fa\u7528\u4e8e\u68c0\u6d4b\u8f6f\u4ef6\u5de5\u7a0b\u8868\u8ff0\u5e7b\u89c9\u7684\u65b9\u6cd5\u3002\u65b9\u6cd5\u5305\u62ec\u8bad\u7ec3\u548c\u8bc4\u4f30\u591a\u79cdLLM\u5728\u9886\u57df\u7279\u5b9a\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u5efa\u7acb\u57fa\u7840\u77e5\u8bc6\u65b0\u57fa\u51c6\uff0c\u4ee5\u53ca\u5f00\u53d1\u5e7b\u89c9\u68c0\u6d4b\u6280\u672f\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u663e\u793a\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347LLM\u5728\u591a\u79cd\u975e\u4ee3\u7801\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u4e14\u5728\u57fa\u7840\u77e5\u8bc6\u8bc4\u4f30\u4e0e\u5e7b\u89c9\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u8be5\u7814\u7a76\u6269\u5c55\u4e86LLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u5e94\u7528\u573a\u666f\uff0c\u5c24\u5176\u5728\u975e\u4ee3\u7801\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u4e86\u8f83\u5f3a\u7684\u6027\u80fd\u548c\u9002\u5e94\u6027\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u65b0\u7684\u8bc4\u4f30\u57fa\u51c6\u548c\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6848\u3002"}}
{"id": "2506.11432", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11432", "abs": "https://arxiv.org/abs/2506.11432", "authors": ["Taeeun Kim", "Semin Jeong", "Youngsook Song"], "title": "KoGEC : Korean Grammatical Error Correction with Pre-trained Translation Models", "comment": "11 pages, 2 figures", "summary": "This research introduces KoGEC, a Korean Grammatical Error Correction system\nusing pre\\--trained translation models. We fine-tuned NLLB (No Language Left\nBehind) models for Korean GEC, comparing their performance against large\nlanguage models like GPT-4 and HCX-3. The study used two social media\nconversation datasets for training and testing. The NLLB models were fine-tuned\nusing special language tokens to distinguish between original and corrected\nKorean sentences. Evaluation was done using BLEU scores and an \"LLM as judge\"\nmethod to classify error types. Results showed that the fine-tuned NLLB (KoGEC)\nmodels outperformed GPT-4o and HCX-3 in Korean GEC tasks. KoGEC demonstrated a\nmore balanced error correction profile across various error types, whereas the\nlarger LLMs tended to focus less on punctuation errors. We also developed a\nChrome extension to make the KoGEC system accessible to users. Finally, we\nexplored token vocabulary expansion to further improve the model but found it\nto decrease model performance. This research contributes to the field of NLP by\nproviding an efficient, specialized Korean GEC system and a new evaluation\nmethod. It also highlights the potential of compact, task-specific models to\ncompete with larger, general-purpose language models in specialized NLP tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u4f18\u5316\u4e86\u4e00\u5957\u5c0f\u578b\u3001\u9ad8\u6548\u7684\u97e9\u8bed\u8bed\u6cd5\u7ea0\u9519\u7cfb\u7edfKoGEC\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u8bc4\u6d4b\u6307\u6807\u4e0a\u8d85\u8fc7\u4e86GPT-4o\u548cHCX-3\u7b49\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u5f00\u53d1\u4e86\u4fbf\u6377\u7684Chrome\u63d2\u4ef6\uff0c\u8868\u660e\u4e13\u7528\u5c0f\u6a21\u578b\u5728\u7279\u5b9a\u4efb\u52a1\u4e0a\u53ef\u4e0e\u5927\u6a21\u578b\u7ade\u4e89\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5982GPT-4\u5728\u591a\u8bed\u8a00\u8bed\u6cd5\u7ea0\u9519\u4efb\u52a1\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u9488\u5bf9\u97e9\u8bed\u7b49\u7279\u5b9a\u8bed\u79cd\u548c\u5177\u4f53\u4efb\u52a1\u65f6\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u9ad8\u6548\u3001\u4e13\u4e1a\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002\u56e0\u6b64\uff0c\u672c\u6587\u81f4\u529b\u4e8e\u5f00\u53d1\u9ad8\u6548\u7684\u97e9\u8bed\u8bed\u6cd5\u7ea0\u9519\u7cfb\u7edf\uff0c\u5e76\u8bc4\u4f30\u5176\u4e0e\u5927\u578b\u901a\u7528\u6a21\u578b\u7684\u6bd4\u8f83\u4f18\u52bf\u3002", "method": "\u672c\u6587\u5bf9NLLB\uff08No Language Left Behind\uff09\u7ffb\u8bd1\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u4e86\u5fae\u8c03\uff0c\u4f7f\u5176\u9002\u5e94\u97e9\u8bed\u8bed\u6cd5\u7ea0\u9519\u4efb\u52a1\u3002\u4e3a\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6a21\u578b\uff0c\u91c7\u7528\u4e86\u4e24\u4e2a\u793e\u4ea4\u5a92\u4f53\u5bf9\u8bdd\u6570\u636e\u96c6\u3002\u5fae\u8c03\u4e2d\u5f15\u5165\u7279\u6b8a\u8bed\u8a00\u6807\u8bb0\u4ee5\u533a\u5206\u539f\u59cb\u53e5\u4e0e\u7ea0\u6b63\u53e5\uff0c\u901a\u8fc7BLEU\u5f97\u5206\u548c\u2018LLM as judge\u2019\u65b9\u6cd5\u8fdb\u884c\u8bc4\u6d4b\uff0c\u5e76\u5bf9\u4e0d\u540c\u7c7b\u578b\u7684\u8bed\u6cd5\u9519\u8bef\u8fdb\u884c\u7ec6\u5206\u5206\u6790\u3002\u8fd8\u5c1d\u8bd5\u4e86\u8bcd\u8868\u6269\u5c55\u4ee5\u53ca\u5f00\u53d1\u4e86\u6d4f\u89c8\u5668\u63d2\u4ef6\u3002", "result": "\u7ecf\u8fc7\u5fae\u8c03\u7684NLLB\uff08KoGEC\uff09\u6a21\u578b\u5728\u97e9\u8bed\u8bed\u6cd5\u7ea0\u9519\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4e86GPT-4o\u548cHCX-3\uff0c\u8868\u73b0\u51fa\u5728\u5404\u79cd\u9519\u8bef\u7c7b\u578b\u4e0a\u7684\u66f4\u5747\u8861\u7ea0\u9519\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u6807\u70b9\u7b26\u53f7\u9519\u8bef\u7ea0\u6b63\u65b9\u9762\u4f18\u4e8e\u5927\u578b\u6a21\u578b\u3002\u8bcd\u8868\u6269\u5c55\u5c1d\u8bd5\u5219\u672a\u80fd\u5e26\u6765\u6027\u80fd\u63d0\u5347\u3002\u6700\u7ec8\u5f00\u53d1\u7684Chrome\u63d2\u4ef6\u4e5f\u4fbf\u4e8e\u7528\u6237\u76f4\u63a5\u4f7f\u7528\u8be5\u7cfb\u7edf\u3002", "conclusion": "\u7d27\u51d1\u7684\u3001\u9762\u5411\u7279\u5b9a\u4efb\u52a1\u7684\u6a21\u578b\uff08\u5982KoGEC\uff09\u5728\u7279\u5b9aNLP\u4efb\u52a1\u4e2d\u80fd\u591f\u4e0e\u751a\u81f3\u8d85\u8d8a\u4f53\u91cf\u66f4\u5927\u3001\u7528\u9014\u66f4\u5e7f\u7684\u8bed\u8a00\u6a21\u578b\u3002\u672c\u6587\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u97e9\u8bed\u8bed\u6cd5\u7ea0\u9519\u7cfb\u7edf\u548c\u65b0\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4e5f\u9a8c\u8bc1\u4e86\u4e13\u4e1a\u5316\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.11559", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11559", "abs": "https://arxiv.org/abs/2506.11559", "authors": ["G\u00e1bor Antal", "D\u00e9nes B\u00e1n", "Martin Isztin", "Rudolf Ferenc", "P\u00e9ter Heged\u0171s"], "title": "Leveraging GPT-4 for Vulnerability-Witnessing Unit Test Generation", "comment": null, "summary": "In the life-cycle of software development, testing plays a crucial role in\nquality assurance. Proper testing not only increases code coverage and prevents\nregressions but it can also ensure that any potential vulnerabilities in the\nsoftware are identified and effectively fixed. However, creating such tests is\na complex, resource-consuming manual process. To help developers and security\nexperts, this paper explores the automatic unit test generation capability of\none of the most widely used large language models, GPT-4, from the perspective\nof vulnerabilities. We examine a subset of the VUL4J dataset containing real\nvulnerabilities and their corresponding fixes to determine whether GPT-4 can\ngenerate syntactically and/or semantically correct unit tests based on the code\nbefore and after the fixes as evidence of vulnerability mitigation. We focus on\nthe impact of code contexts, the effectiveness of GPT-4's self-correction\nability, and the subjective usability of the generated test cases. Our results\nindicate that GPT-4 can generate syntactically correct test cases 66.5\\% of the\ntime without domain-specific pre-training. Although the semantic correctness of\nthe fixes could be automatically validated in only 7. 5\\% of the cases, our\nsubjective evaluation shows that GPT-4 generally produces test templates that\ncan be further developed into fully functional vulnerability-witnessing tests\nwith relatively minimal manual effort.\n  Therefore, despite the limited data, our initial findings suggest that GPT-4\ncan be effectively used in the generation of vulnerability-witnessing tests. It\nmay not operate entirely autonomously, but it certainly plays a significant\nrole in a partially automated process.", "AI": {"tldr": "\u672c\u6587\u9a8c\u8bc1\u4e86GPT-4\u5728\u81ea\u52a8\u751f\u6210\u5b89\u5168\u6f0f\u6d1e\u6d4b\u8bd5\u7528\u4f8b\u65b9\u9762\u7684\u6f5c\u529b\u3002\u867d\u7136\u9700\u8981\u4eba\u5de5\u53c2\u4e0e\u63d0\u5347\u8bed\u4e49\u5b8c\u6574\u6027\uff0c\u4f46\u5176\u5728\u751f\u6210\u6d4b\u8bd5\u6a21\u677f\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u8f6f\u4ef6\u5b89\u5168\u6d4b\u8bd5\u81ea\u52a8\u5316\u6c34\u5e73\u3002", "motivation": "\u8f6f\u4ef6\u6d4b\u8bd5\u5bf9\u4e8e\u4fdd\u969c\u8f6f\u4ef6\u8d28\u91cf\u548c\u53d1\u73b0\u5b89\u5168\u6f0f\u6d1e\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u624b\u52a8\u7f16\u5199\u6d4b\u8bd5\u7528\u4f8b\u8d39\u65f6\u8d39\u529b\uff0c\u5c24\u5176\u662f\u5728\u9488\u5bf9\u5b89\u5168\u6f0f\u6d1e\u7684\u573a\u666f\u4e0b\u3002\u5982\u4f55\u9ad8\u6548\u81ea\u52a8\u751f\u6210\u5177\u6709\u5b89\u5168\u6027\u8bc1\u636e\u7684\u5355\u5143\u6d4b\u8bd5\u6210\u4e3a\u8feb\u5207\u9700\u6c42\u3002", "method": "\u672c\u6587\u4f7f\u7528\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578bGPT-4\uff0c\u5bf9VUL4J\u771f\u5b9e\u6f0f\u6d1e\u53ca\u4fee\u590d\u6570\u636e\u96c6\u7684\u5b50\u96c6\u5f00\u5c55\u5b9e\u9a8c\uff0c\u8bc4\u4f30GPT-4\u57fa\u4e8e\u8865\u4e01\u524d\u540e\u4ee3\u7801\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u7684\u80fd\u529b\u3002\u91cd\u70b9\u8003\u5bdf\u4ee3\u7801\u4e0a\u4e0b\u6587\u3001\u6a21\u578b\u81ea\u6211\u4fee\u6b63\u80fd\u529b\uff0c\u4ee5\u53ca\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u7684\u53ef\u7528\u6027\u3002\u8bed\u6cd5\u4e0e\u8bed\u4e49\u6b63\u786e\u6027\u901a\u8fc7\u81ea\u52a8\u53ca\u4e3b\u89c2\u65b9\u5f0f\u540c\u6b65\u8bc4\u4ef7\u3002", "result": "GPT-4\u5728\u65e0\u9886\u57df\u4e13\u95e8\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u751f\u621066.5%\u7684\u8bed\u6cd5\u6b63\u786e\u5355\u5143\u6d4b\u8bd5\uff1b\u4f46\u80fd\u81ea\u52a8\u9a8c\u8bc1\u8bed\u4e49\u6b63\u786e\u6027\u7684\u6bd4\u4f8b\u4e3a7.5%\u3002\u4e3b\u89c2\u8bc4\u4ef7\u663e\u793a\uff0cGPT-4\u751f\u6210\u7684\u6d4b\u8bd5\u6a21\u677f\u901a\u8fc7\u5c11\u91cf\u4eba\u5de5\u5b8c\u5584\u540e\u6709\u671b\u6210\u4e3a\u5177\u6709\u5b89\u5168\u6f0f\u6d1e\u8bc1\u636e\u7684\u6d4b\u8bd5\u7528\u4f8b\u3002", "conclusion": "GPT-4\u867d\u7136\u5c1a\u65e0\u6cd5\u5b8c\u5168\u81ea\u52a8\u5316\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u6d41\u7a0b\uff0c\u4f46\u5728\u751f\u6210\u57fa\u4e8e\u5b89\u5168\u6f0f\u6d1e\u8bc1\u636e\u7684\u6d4b\u8bd5\u65f6\u8868\u73b0\u7a81\u51fa\uff0c\u80fd\u663e\u8457\u8f85\u52a9\u5b89\u5168\u6d4b\u8bd5\u81ea\u52a8\u5316\u3002"}}
{"id": "2506.11440", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11440", "abs": "https://arxiv.org/abs/2506.11440", "authors": ["Harvey Yiyun Fu", "Aryan Shrivastava", "Jared Moore", "Peter West", "Chenhao Tan", "Ari Holtzman"], "title": "AbsenceBench: Language Models Can't Tell What's Missing", "comment": "23 pages, 8 figures. Code and data are publicly available at\n  https://github.com/harvey-fin/absence-bench", "summary": "Large language models (LLMs) are increasingly capable of processing long\ninputs and locating specific information within them, as evidenced by their\nperformance on the Needle in a Haystack (NIAH) test. However, while models\nexcel at recalling surprising information, they still struggle to identify\nclearly omitted information. We introduce AbsenceBench to assesses LLMs'\ncapacity to detect missing information across three domains: numerical\nsequences, poetry, and GitHub pull requests. AbsenceBench asks models to\nidentify which pieces of a document were deliberately removed, given access to\nboth the original and edited contexts. Despite the apparent straightforwardness\nof these tasks, our experiments reveal that even state-of-the-art models like\nClaude-3.7-Sonnet achieve only 69.6% F1-score with a modest average context\nlength of 5K tokens. Our analysis suggests this poor performance stems from a\nfundamental limitation: Transformer attention mechanisms cannot easily attend\nto \"gaps\" in documents since these absences don't correspond to any specific\nkeys that can be attended to. Overall, our results and analysis provide a case\nstudy of the close proximity of tasks where models are already superhuman\n(NIAH) and tasks where models breakdown unexpectedly (AbsenceBench).", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAbsenceBench\uff0c\u7528\u4e8e\u68c0\u6d4b\u5927\u6a21\u578b\u8bc6\u522b\u6587\u6863\u7f3a\u5931\u4fe1\u606f\u80fd\u529b\uff0c\u7ed3\u679c\u663e\u793a\u5373\u4f7f\u6700\u4f18\u6a21\u578b\u8868\u73b0\u4e5f\u6709\u9650\uff0c\u63ed\u793a\u4e86Transformer\u7ed3\u6784\u6027\u77ed\u677f\u3002", "motivation": "\u73b0\u6709\u8bc4\u6d4b\u5982\u201cNIAH\u201d\u6d4b\u8bd5\u5f3a\u8c03\u6a21\u578b\u8bc6\u522b\u548c\u590d\u73b0\u663e\u8457\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u80fd\u5426\u53ca\u65f6\u53d1\u73b0\u7f3a\u5931\u6216\u88ab\u7701\u7565\u7684\u4fe1\u606f\u540c\u6837\u91cd\u8981\uff0c\u800c\u8be5\u80fd\u529b\u5c1a\u672a\u88ab\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u63d0\u51fa\u4e86AbsenceBench\u57fa\u51c6\uff0c\u901a\u8fc7\u8ba9\u6a21\u578b\u5bf9\u6bd4\u539f\u59cb\u4e0e\u7f16\u8f91\u540e\u7684\u6587\u6863\uff0c\u5728\u6570\u5b57\u5e8f\u5217\u3001\u8bd7\u6b4c\u3001GitHub\u62c9\u53d6\u8bf7\u6c42\u4e09\u5927\u9886\u57df\uff0c\u8bc4\u4f30\u6a21\u578b\u8bc6\u522b\u88ab\u5220\u51cf\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u91cf\u5316F1\u5f97\u5206\u3002", "result": "\u5373\u4fbf\u662fClaude-3.7-Sonnet\u7b49\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u9762\u5bf9\u5e73\u5747\u4ec55K token\u957f\u7684\u4e0a\u4e0b\u6587\uff0cF1\u5f97\u5206\u4e5f\u53ea\u670969.6%\uff0c\u8bf4\u660e\u6a21\u578b\u8ddd\u79bb\u201c\u68c0\u6d4b\u7f3a\u5931\u201d\u8fd9\u4e00\u9700\u6c42\u4ecd\u6709\u8f83\u5927\u63d0\u5347\u7a7a\u95f4\u3002\u8fd9\u4e00\u4e0d\u8db3\u5f52\u56e0\u4e8e\u5f53\u524dTransformer\u6846\u67b6\u96be\u4ee5\u6355\u6349\u201c\u7a7a\u767d\u201d\u4fe1\u53f7\u3002", "conclusion": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u7d22\u548c\u56de\u5fc6\u4fe1\u606f\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5b83\u4eec\u5728\u68c0\u6d4b\u7f3a\u5931\u4fe1\u606f\u65b9\u9762\u5b58\u5728\u660e\u663e\u74f6\u9888\uff0c\u8fd9\u4e3b\u8981\u6e90\u4e8eTransformer\u6ce8\u610f\u529b\u673a\u5236\u7684\u7ed3\u6784\u6027\u5c40\u9650\u3002"}}
{"id": "2506.11561", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11561", "abs": "https://arxiv.org/abs/2506.11561", "authors": ["G\u00e1bor Antal", "Bence Bogenf\u00fcrst", "Rudolf Ferenc", "P\u00e9ter Heged\u0171s"], "title": "Identifying Helpful Context for LLM-based Vulnerability Repair: A Preliminary Study", "comment": null, "summary": "Recent advancements in large language models (LLMs) have shown promise for\nautomated vulnerability detection and repair in software systems. This paper\ninvestigates the performance of GPT-4o in repairing Java vulnerabilities from a\nwidely used dataset (Vul4J), exploring how different contextual information\naffects automated vulnerability repair (AVR) capabilities. We compare the\nlatest GPT-4o's performance against previous results with GPT-4 using identical\nprompts. We evaluated nine additional prompts crafted by us that contain\nvarious contextual information such as CWE or CVE information, and manually\nextracted code contexts. Each prompt was executed three times on 42\nvulnerabilities, and the resulting fix candidates were validated using Vul4J's\nautomated testing framework.\n  Our results show that GPT-4o performed 11.9\\% worse on average than GPT-4\nwith the same prompt, but was able to fix 10.5\\% more distinct vulnerabilities\nin the three runs together. CVE information significantly improved repair\nrates, while the length of the task description had minimal impact. Combining\nCVE guidance with manually extracted code context resulted in the best\nperformance. Using our \\textsc{Top}-3 prompts together, GPT-4o repaired 26\n(62\\%) vulnerabilities at least once, outperforming both the original baseline\n(40\\%) and its reproduction (45\\%), suggesting that ensemble prompt strategies\ncould improve vulnerability repair in zero-shot settings.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86GPT-4o\u5728Java\u6f0f\u6d1e\u81ea\u52a8\u4fee\u590d\u4e0a\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5c3d\u7ba1\u5176\u5e73\u5747\u8868\u73b0\u7565\u4f4e\u4e8eGPT-4\uff0c\u4f46\u5728\u8986\u76d6\u66f4\u591a\u4e0d\u540c\u6f0f\u6d1e\u548c\u5229\u7528\u4e30\u5bcc\u4e0a\u4e0b\u6587\u4fe1\u606f\uff08\u5982CVE\u3001\u4ee3\u7801\u4e0a\u4e0b\u6587\uff09\u8fdb\u884c\u591a\u63d0\u793a\u96c6\u6210\u65f6\uff0c\u80fd\u663e\u8457\u63d0\u5347\u4fee\u590d\u6548\u679c\uff0c\u5c55\u793a\u4e86\u672a\u6765\u5229\u7528\u5927\u6a21\u578b\u548c\u63d0\u793a\u5de5\u7a0b\u5728\u6f0f\u6d1e\u4fee\u590d\u81ea\u52a8\u5316\u65b9\u9762\u7684\u6f5c\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fd1\u5e74\u6765\u5728\u81ea\u52a8\u5316\u6f0f\u6d1e\u68c0\u6d4b\u548c\u4fee\u590d\u65b9\u9762\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5bf9\u4e8e\u4e0d\u540c\u6a21\u578b\u53ca\u8f93\u5165\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u5982\u4f55\u5f71\u54cd\u4fee\u590d\u80fd\u529b\u5c1a\u7f3a\u4e4f\u6df1\u5165\u5bf9\u6bd4\u5206\u6790\uff0c\u5c24\u5176\u662f\u5728\u771f\u5b9e\u6f0f\u6d1e\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4e0d\u660e\u3002", "method": "\u672c\u6587\u5229\u7528Vul4J\u6570\u636e\u96c6\uff0c\u5bf9GPT-4o\u6a21\u578b\u5728\u4fee\u590dJava\u6f0f\u6d1e\u7684\u80fd\u529b\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u4e0e\u524d\u4e00\u4ee3GPT-4\u5728\u76f8\u540c\u63d0\u793a\u4e0b\u7684\u8868\u73b0\u8fdb\u884c\u5bf9\u6bd4\u3002\u6b64\u5916\uff0c\u8bbe\u8ba1\u4e86\u4e5d\u79cd\u542b\u6709\u4e0d\u540c\u4e0a\u4e0b\u6587\uff08\u5982CWE\u3001CVE\u4fe1\u606f\u53ca\u624b\u52a8\u63d0\u53d6\u7684\u4ee3\u7801\u4e0a\u4e0b\u6587\uff09\u7684\u65b0\u63d0\u793a\uff0c\u5bf942\u4e2a\u6f0f\u6d1e\u8fd0\u884c\u4e09\u6b21\uff0c\u5e76\u901a\u8fc7Vul4J\u81ea\u52a8\u5316\u6d4b\u8bd5\u6846\u67b6\u9a8c\u8bc1\u4fee\u590d\u6548\u679c\u3002", "result": "GPT-4o\u5728\u76f8\u540c\u63d0\u793a\u4e0b\u4fee\u590d\u6210\u529f\u7387\u5e73\u5747\u6bd4GPT-4\u4f4e11.9%\uff0c\u4f46\u4e09\u8f6e\u5b9e\u9a8c\u4e2d\u5176\u4fee\u590d\u5230\u7684\u4e0d\u540c\u6f0f\u6d1e\u6570\u6bd4GPT-4\u591a10.5%\u3002\u5e26\u6709CVE\u4fe1\u606f\u7684\u63d0\u793a\u663e\u8457\u63d0\u5347\u4fee\u590d\u6210\u529f\u7387\uff0c\u4efb\u52a1\u63cf\u8ff0\u957f\u5ea6\u5f71\u54cd\u8f83\u5c0f\u3002CVEC+\u624b\u52a8\u4ee3\u7801\u4e0a\u4e0b\u6587\u7ed3\u5408\u65f6\u6548\u679c\u6700\u597d\uff0c\u91c7\u7528\u524d\u4e09\u63d0\u793a\u7684\u96c6\u6210\u7b56\u7565\uff0cGPT-4o\u6700\u9ad8\u4fee\u590d\u4e8662%\u7684\u6f0f\u6d1e\uff0c\u8d85\u8d8a\u57fa\u51c6\uff0840%\uff09\u548c\u5176\u590d\u73b0\uff0845%\uff09\u3002", "conclusion": "\u5b8c\u6574\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff08\u5c24\u5176\u662fCVE\uff09\u4e0e\u591a\u63d0\u793a\u96c6\u6210\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u6f0f\u6d1e\u4fee\u590d\u4e0a\u7684\u8868\u73b0\uff0c\u5c3d\u7ba1\u6574\u4f53\u5e73\u5747\u6210\u529f\u7387\u8f83\u524d\u4ee3\u7565\u4f4e\uff0c\u4f46\u65b0\u6a21\u578b\u5728\u591a\u6837\u6f0f\u6d1e\u4fee\u590d\u80fd\u529b\u65b9\u9762\u6709\u4f18\u52bf\u3002"}}
{"id": "2506.11467", "categories": ["cs.CL", "cs.SI", "F.2.2, I.2.7"], "pdf": "https://arxiv.org/pdf/2506.11467", "abs": "https://arxiv.org/abs/2506.11467", "authors": ["Carlos Rafael Catalan"], "title": "A Gamified Evaluation and Recruitment Platform for Low Resource Language Machine Translation Systems", "comment": "7 pages, 7 figures, presented at the HEAL Workshop at CHI", "summary": "Human evaluators provide necessary contributions in evaluating large language\nmodels. In the context of Machine Translation (MT) systems for low-resource\nlanguages (LRLs), this is made even more apparent since popular automated\nmetrics tend to be string-based, and therefore do not provide a full picture of\nthe nuances of the behavior of the system. Human evaluators, when equipped with\nthe necessary expertise of the language, will be able to test for adequacy,\nfluency, and other important metrics. However, the low resource nature of the\nlanguage means that both datasets and evaluators are in short supply. This\npresents the following conundrum: How can developers of MT systems for these\nLRLs find adequate human evaluators and datasets? This paper first presents a\ncomprehensive review of existing evaluation procedures, with the objective of\nproducing a design proposal for a platform that addresses the resource gap in\nterms of datasets and evaluators in developing MT systems. The result is a\ndesign for a recruitment and gamified evaluation platform for developers of MT\nsystems. Challenges are also discussed in terms of evaluating this platform, as\nwell as its possible applications in the wider scope of Natural Language\nProcessing (NLP) research.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00\u673a\u5668\u7ffb\u8bd1\u8bc4\u4f30\u4e2d\u7684\u96be\u9898\uff0c\u8bbe\u8ba1\u4e86\u4e00\u5957\u6574\u5408\u6570\u636e\u96c6\u3001\u8bc4\u4f30\u8005\u62db\u52df\u53ca\u6e38\u620f\u5316\u529f\u80fd\u7684\u5e73\u53f0\u6846\u67b6\uff0c\u4e3a\u89e3\u51b3\u8d44\u6e90\u7a00\u7f3a\u548c\u63d0\u5347\u8bc4\u4f30\u8d28\u91cf\u63d0\u4f9b\u4e86\u521b\u65b0\u601d\u8def\u3002", "motivation": "\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08LRL\uff09\u7684\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\u8bc4\u4f30\u9762\u4e34\u56f0\u96be\uff1a\u81ea\u52a8\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff0c\u800c\u80fd\u591f\u80dc\u4efb\u7684\u4eba\u7c7b\u8bc4\u4f30\u8005\u548c\u6570\u636e\u96c6\u53c8\u5341\u5206\u7a00\u7f3a\u3002", "method": "\u9996\u5148\u56de\u987e\u5e76\u5206\u6790\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7136\u540e\u63d0\u51fa\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5e73\u53f0\uff0c\u8be5\u5e73\u53f0\u96c6\u6570\u636e\u96c6\u3001\u8bc4\u4f30\u8005\u62db\u52df\u4e0e\u6e38\u620f\u5316\u8bc4\u6d4b\u4e8e\u4e00\u4f53\uff0c\u4e13\u4e3a\u673a\u5668\u7ffb\u8bd1\u5f00\u53d1\u8005\u670d\u52a1\u3002", "result": "\u8bbe\u8ba1\u51fa\u4e00\u4e2a\u9488\u5bf9LRL\u7684\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\u8bc4\u4f30\u7684\u62db\u52df\u548c\u6e38\u620f\u5316\u5e73\u53f0\uff0c\u5e76\u8ba8\u8bba\u4e86\u5e73\u53f0\u8bc4\u4f30\u9762\u4e34\u7684\u6311\u6218\u4ee5\u53ca\u8be5\u65b9\u6848\u5728\u66f4\u5e7f\u6cdb\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7814\u7a76\u4e2d\u53ef\u80fd\u7684\u5e94\u7528\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u89e3\u51b3\u4f4e\u8d44\u6e90\u8bed\u8a00\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\u4e2d\u8bc4\u4f30\u8d44\u6e90\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u3001\u53ef\u6269\u5c55\u7684\u5e73\u53f0\u8bbe\u8ba1\uff0c\u6709\u671b\u63a8\u52a8\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.11588", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11588", "abs": "https://arxiv.org/abs/2506.11588", "authors": ["Simone Romano", "Alberto Conforti", "Gloria Guidetti", "Sara Viotti", "Rachele Ceschin", "Giuseppe Scanniello"], "title": "MBSR at Work: Perspectives from an Instructor and Software Developers", "comment": null, "summary": "In this paper, we present the preliminary findings from a qualitative study\n(i.e., semi-structured interviews) on how a Mindfulness-Based Stress Reduction\n(MBSR) program, carried out in the Software Development (SD) working context,\nis perceived by the software developers of a multinational company who\nparticipated in the MBSR program and by the instructor who led it. MBSR is a\ndeeply personal and experiential practice in helping individuals manage stress,\nparticularly in high-pressure environments such as workplaces, healthcare\nsettings, education, and other demanding professional or personal situations.\nAlthough MBSR has been experimented in different working contexts;\nsurprisingly, it has never been studied in the SD working context where there\nare several stress factors that developers experience (e.g., time pressure and\nuncertainty about the content of a particular task and its outcome). In this\nrespect, qualitative research can generate valuable insights into the\napplication of MBSR in the SD working context that cannot be captured by\nstandardized quantitative measures. Being MBSR instructors and software\ndevelopers the key stakeholders in delivering an MBSR program in the SD working\ncontext, understanding their first-hand experiences can provide a more detailed\npicture of the investigated phenomenon. The most important takeaway result of\nour research can be summarized as follows: despite initial skepticism, the\ndevelopers recognized personal improvements due to the MBSR practice, though\nthe integration of MBSR techniques in the working context remained challenging.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u8bbf\u8c08\u53d1\u73b0\uff0cMBSR\u5e2e\u52a9\u8f6f\u4ef6\u5f00\u53d1\u4eba\u5458\u7f13\u89e3\u4e86\u538b\u529b\u5e76\u5e26\u6765\u4e2a\u4eba\u6539\u5584\uff0c\u4f46\u5176\u6df1\u5165\u6574\u5408\u5230\u5de5\u4f5c\u4e2d\u7684\u8fc7\u7a0b\u4ecd\u7136\u56f0\u96be\u3002", "motivation": "\u5c3d\u7ba1MBSR\uff08\u6b63\u5ff5\u51cf\u538b\uff09\u5df2\u5728\u591a\u79cd\u5de5\u4f5c\u73af\u5883\u4e2d\u5e94\u7528\uff0c\u4f46\u5728\u8f6f\u4ef6\u5f00\u53d1\u8fd9\u4e00\u7279\u5b9a\u4e14\u538b\u529b\u8f83\u5927\u7684\u73af\u5883\u4e2d\u7684\u5e94\u7528\u7814\u7a76\u5374\u5341\u5206\u7f55\u89c1\u3002\u8f6f\u4ef6\u5f00\u53d1\u5de5\u4f5c\u4e2d\u5b58\u5728\u8bf8\u5982\u65f6\u95f4\u538b\u529b\u3001\u4e0d\u786e\u5b9a\u6027\u7b49\u663e\u8457\u7684\u538b\u529b\u56e0\u7d20\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u63a2\u7d22MBSR\u5728\u8be5\u9886\u57df\u7684\u6f5c\u5728\u76ca\u5904\u3002\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u586b\u8865\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u5e76\u6df1\u5165\u4e86\u89e3MBSR\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u4eba\u5458\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u5b9a\u6027\u7814\u7a76\u65b9\u6cd5\uff0c\u901a\u8fc7\u534a\u7ed3\u6784\u5f0f\u8bbf\u8c08\u65b9\u5f0f\u6536\u96c6\u6570\u636e\u3002\u53d7\u8bbf\u8005\u5305\u62ec\u53c2\u4e0eMBSR\u9879\u76ee\u7684\u8f6f\u4ef6\u5f00\u53d1\u4eba\u5458\u4ee5\u53ca\u4e3b\u5bfc\u8be5\u9879\u76ee\u7684\u8bb2\u5e08\u3002\u7814\u7a76\u805a\u7126\u4e8e\u53c2\u4e0e\u8005\u5bf9MBSR\u9879\u76ee\u7684\u7b2c\u4e00\u624b\u4f53\u9a8c\u4e0e\u770b\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1\u5f00\u53d1\u4eba\u5458\u8d77\u521d\u5bf9MBSR\u9879\u76ee\u6301\u6000\u7591\u6001\u5ea6\uff0c\u4f46\u7ecf\u8fc7\u5b9e\u8df5\u540e\u666e\u904d\u611f\u53d7\u5230\u4e2a\u4eba\u7684\u79ef\u6781\u53d8\u5316\u548c\u6539\u5584\u3002\u7136\u800c\uff0c\u5c06MBSR\u76f8\u5173\u6280\u672f\u878d\u5165\u65e5\u5e38\u5de5\u4f5c\u73af\u5883\u4ecd\u9762\u4e34\u4e00\u5b9a\u6311\u6218\u3002", "conclusion": "MBSR\u53ef\u5e2e\u52a9\u8f6f\u4ef6\u5f00\u53d1\u4eba\u5458\u7ba1\u7406\u5de5\u4f5c\u538b\u529b\uff0c\u63d0\u5347\u4e2a\u4eba\u798f\u7949\uff0c\u4f46\u5176\u5728\u5b9e\u9645\u5de5\u4f5c\u573a\u666f\u4e2d\u7684\u6301\u7eed\u5e94\u7528\u548c\u6280\u672f\u6574\u5408\u4ecd\u5177\u6311\u6218\u6027\uff0c\u6709\u5f85\u8fdb\u4e00\u6b65\u63a2\u7d22\u4e0e\u6539\u8fdb\u3002"}}
{"id": "2506.11474", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11474", "abs": "https://arxiv.org/abs/2506.11474", "authors": ["Jaehoon Yun", "Jiwoong Sohn", "Jungwoo Park", "Hyunjae Kim", "Xiangru Tang", "Yanjun Shao", "Yonghoe Koo", "Minhyeok Ko", "Qingyu Chen", "Mark Gerstein", "Michael Moor", "Jaewoo Kang"], "title": "Med-PRM: Medical Reasoning Models with Stepwise, Guideline-verified Process Rewards", "comment": null, "summary": "Large language models have shown promise in clinical decision making, but\ncurrent approaches struggle to localize and correct errors at specific steps of\nthe reasoning process. This limitation is critical in medicine, where\nidentifying and addressing reasoning errors is essential for accurate diagnosis\nand effective patient care. We introduce Med-PRM, a process reward modeling\nframework that leverages retrieval-augmented generation to verify each\nreasoning step against established medical knowledge bases. By verifying\nintermediate reasoning steps with evidence retrieved from clinical guidelines\nand literature, our model can precisely assess the reasoning quality in a\nfine-grained manner. Evaluations on five medical QA benchmarks and two\nopen-ended diagnostic tasks demonstrate that Med-PRM achieves state-of-the-art\nperformance, with improving the performance of base models by up to 13.50%\nusing Med-PRM. Moreover, we demonstrate the generality of Med-PRM by\nintegrating it in a plug-and-play fashion with strong policy models such as\nMeerkat, achieving over 80\\% accuracy on MedQA for the first time using\nsmall-scale models of 8 billion parameters. Our code and data are available at:\nhttps://med-prm.github.io/", "AI": {"tldr": "Med-PRM\u901a\u8fc7\u5728\u533b\u5b66\u63a8\u7406\u6bcf\u4e00\u6b65\u6838\u67e5\u8bc1\u636e\uff0c\u5927\u5e45\u63d0\u5347\u4e86AI\u6a21\u578b\u5728\u4e34\u5e8a\u95ee\u7b54\u4e0e\u8bca\u65ad\u4e0a\u7684\u51c6\u786e\u6027\u548c\u5b89\u5168\u6027\uff0c\u5e76\u5b9e\u73b0\u4e86\u884c\u4e1a\u9886\u5148\u6c34\u5e73\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5df2\u5728\u4e34\u5e8a\u51b3\u7b56\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5b9a\u4f4d\u548c\u7ea0\u6b63\u63a8\u7406\u6d41\u7a0b\u4e2d\u5177\u4f53\u73af\u8282\u7684\u9519\u8bef\u3002\u800c\u5728\u533b\u5b66\u9886\u57df\uff0c\u8bc6\u522b\u5e76\u5904\u7406\u63a8\u7406\u9519\u8bef\u5bf9\u4e8e\u51c6\u786e\u8bca\u65ad\u548c\u6709\u6548\u6cbb\u7597\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u7684\u7814\u7a76\u52a8\u673a\u662f\u89e3\u51b3\u533b\u5b66\u4eba\u5de5\u667a\u80fd\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u9519\u8bef\u68c0\u6d4b\u4e0e\u6821\u6b63\u96be\u9898\u3002", "method": "\u63d0\u51faMed-PRM\uff08\u4e00\u79cd\u8fc7\u7a0b\u5956\u52b1\u5efa\u6a21\u6846\u67b6\uff09\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u65b9\u6cd5\uff0c\u5bf9\u6bcf\u4e00\u6b65\u63a8\u7406\u8fdb\u884c\u9a8c\u8bc1\u3002\u5177\u4f53\u505a\u6cd5\u4e3a\uff1a\u5c06\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u4e0e\u533b\u5b66\u77e5\u8bc6\u5e93\uff08\u5982\u4e34\u5e8a\u6307\u5357\u548c\u533b\u5b66\u6587\u732e\uff09\u68c0\u7d22\u5230\u7684\u8bc1\u636e\u8fdb\u884c\u6bd4\u5bf9\uff0c\u4ece\u800c\u7ec6\u81f4\u5730\u8bc4\u4f30\u63a8\u7406\u7684\u6bcf\u4e2a\u73af\u8282\u3002", "result": "\u5728\u4e94\u4e2a\u533b\u5b66\u95ee\u7b54\u57fa\u51c6\u548c\u4e24\u4e2a\u5f00\u653e\u5f0f\u8bca\u65ad\u4efb\u52a1\u4e2d\uff0cMed-PRM\u5b9e\u73b0\u4e86\u6700\u65b0\u7684\u6700\u4f18\u6027\u80fd\uff0c\u4e14\u6700\u591a\u53ef\u63d0\u5347\u5e95\u5c42\u6a21\u578b13.50%\u7684\u8868\u73b0\u3002\u6b64\u5916\uff0cMed-PRM\u80fd\u591f\u4e0e\u5f3a\u5927\u7684\u7b56\u7565\u6a21\u578b\uff08\u5982Meerkat\uff09\u65e0\u7f1d\u96c6\u6210\uff0c\u57288B\u53c2\u6570\u89c4\u6a21\u4e0b\u9996\u6b21\u5728MedQA\u4efb\u52a1\u4e2d\u8d85\u8fc780%\u51c6\u786e\u7387\u3002\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90\u3002", "conclusion": "Med-PRM\u53ef\u7528\u4e8e\u7cbe\u7ec6\u5730\u8bc4\u4f30\u533b\u5b66\u63a8\u7406\u8fc7\u7a0b\u3001\u6709\u6548\u5b9a\u4f4d\u4e0e\u7ea0\u6b63\u63a8\u7406\u9519\u8bef\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u533b\u5b66AI\u6a21\u578b\u7684\u53ef\u9760\u6027\u548c\u51c6\u786e\u7387\u3002\u8be5\u65b9\u6cd5\u901a\u7528\u6027\u5f3a\uff0c\u53ef\u5728\u591a\u4e2a\u6a21\u578b\u548c\u4efb\u52a1\u4e2d\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2506.11591", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11591", "abs": "https://arxiv.org/abs/2506.11591", "authors": ["Hyunsun Hong", "Jongmoon Baik"], "title": "Retrieval-Augmented Code Review Comment Generation", "comment": null, "summary": "Automated code review comment generation (RCG) aims to assist developers by\nautomatically producing natural language feedback for code changes. Existing\napproaches are primarily either generation-based, using pretrained language\nmodels, or information retrieval-based (IR), reusing comments from similar past\nexamples. While generation-based methods leverage code-specific pretraining on\nlarge code-natural language corpora to learn semantic relationships between\ncode and natural language, they often struggle to generate low-frequency but\nsemantically important tokens due to their probabilistic nature. In contrast,\nIR-based methods excel at recovering such rare tokens by copying from existing\nexamples but lack flexibility in adapting to new code contexts-for example,\nwhen input code contains identifiers or structures not found in the retrieval\ndatabase. To bridge the gap between generation-based and IR-based methods, this\nwork proposes to leverage retrieval-augmented generation (RAG) for RCG by\nconditioning pretrained language models on retrieved code-review exemplars. By\nproviding relevant examples that illustrate how similar code has been\npreviously reviewed, the model is better guided to generate accurate review\ncomments. Our evaluation on the Tufano et al. benchmark shows that RAG-based\nRCG outperforms both generation-based and IR-based RCG. It achieves up to\n+1.67% higher exact match and +4.25% higher BLEU scores compared to\ngeneration-based RCG. It also improves the generation of low-frequency\nground-truth tokens by up to 24.01%. We additionally find that performance\nimproves as the number of retrieved exemplars increases.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\u63d0\u5347\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u53e5\u6cd5\u591a\u6837\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\uff08RCG\uff09\u53ef\u4ee5\u51cf\u8f7b\u5f00\u53d1\u8005\u8d1f\u62c5\uff0c\u4f46\u73b0\u6709\u57fa\u4e8e\u751f\u6210\u548c\u57fa\u4e8e\u68c0\u7d22\u7684\u65b9\u6cd5\u5404\u6709\u5c40\u9650\u3002\u751f\u6210\u65b9\u6cd5\u96be\u4ee5\u751f\u6210\u7f55\u89c1\u4f46\u91cd\u8981\u7684\u8bed\u4e49\u6807\u8bb0\uff0c\u68c0\u7d22\u65b9\u6cd5\u96be\u4ee5\u9002\u5e94\u65b0\u4ee3\u7801\u60c5\u5883\u3002\u5982\u4f55\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u63d0\u5347\u8bc4\u8bba\u751f\u6210\u6548\u679c\u6210\u4e3a\u4e3b\u8981\u52a8\u673a\u3002", "method": "\u63d0\u51fa\u4e86\u5c06\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\u5e94\u7528\u4e8eRCG\uff0c\u5c06\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4e0e\u68c0\u7d22\u5230\u7684\u5386\u53f2\u4ee3\u7801\u5ba1\u67e5\u6848\u4f8b\u7ed3\u5408\uff0c\u901a\u8fc7\u8fd9\u4e9b\u76f8\u5173\u793a\u4f8b\u63d0\u5347\u751f\u6210\u8bc4\u8bba\u7684\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u3002", "result": "\u5728Tufano\u7b49\u4eba\u63d0\u51fa\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cRAG\u65b9\u6cd5\u5728\u7cbe\u786e\u5339\u914d\u5ea6\uff08+1.67%\uff09\u548cBLEU\u5206\u6570\uff08+4.25%\uff09\u4e0a\u5747\u4f18\u4e8e\u5355\u72ec\u7684\u751f\u6210\u548c\u68c0\u7d22\u65b9\u6cd5\uff0c\u5e76\u5728\u751f\u6210\u4f4e\u9891\u771f\u5b9e\u6807\u8bb0\u65b9\u9762\u63d0\u5347\u6700\u5927\u8fbe\u523024.01%\u3002\u8fdb\u4e00\u6b65\u53d1\u73b0\uff0c\u68c0\u7d22\u793a\u4f8b\u6570\u91cf\u8d8a\u591a\uff0c\u6a21\u578b\u6548\u679c\u8d8a\u597d\u3002", "conclusion": "\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6a21\u578b\u80fd\u591f\u6709\u6548\u878d\u5408\u751f\u6210\u548c\u68c0\u7d22\u65b9\u6cd5\u4f18\u52bf\uff0c\u663e\u8457\u63d0\u5347\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\u7684\u8d28\u91cf\u4e0e\u7075\u6d3b\u6027\u3002"}}
{"id": "2506.11478", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11478", "abs": "https://arxiv.org/abs/2506.11478", "authors": ["Aman Sinha", "Bogdan-Valentin Popescu", "Xavier Coubez", "Marianne Clausel", "Mathieu Constant"], "title": "ImmunoFOMO: Are Language Models missing what oncologists see?", "comment": null, "summary": "Language models (LMs) capabilities have grown with a fast pace over the past\ndecade leading researchers in various disciplines, such as biomedical research,\nto increasingly explore the utility of LMs in their day-to-day applications.\nDomain specific language models have already been in use for biomedical natural\nlanguage processing (NLP) applications. Recently however, the interest has\ngrown towards medical language models and their understanding capabilities. In\nthis paper, we investigate the medical conceptual grounding of various language\nmodels against expert clinicians for identification of hallmarks of\nimmunotherapy in breast cancer abstracts. Our results show that pre-trained\nlanguage models have potential to outperform large language models in\nidentifying very specific (low-level) concepts.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u8bed\u8a00\u6a21\u578b\u4e0e\u4e34\u5e8a\u4e13\u5bb6\u5bf9\u4e8e\u4e73\u817a\u764c\u514d\u75ab\u6cbb\u7597\u6587\u6458\u4e2d\u533b\u5b66\u6807\u5fd7\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u53d1\u73b0\u9886\u57df\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u7ec6\u81f4\u533b\u5b66\u6982\u5ff5\u63d0\u53d6\u4e0a\u5177\u5907\u4f18\u52bf\u3002", "motivation": "\u7531\u4e8e\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u8fc5\u901f\u63d0\u5347\uff0c\u533b\u5b66\u548c\u751f\u7269\u533b\u5b66\u7b49\u9886\u57df\u7814\u7a76\u8005\u5e0c\u671b\u5229\u7528\u5176\u8f85\u52a9\u65e5\u5e38\u79d1\u7814\u53ca\u8bca\u65ad\uff0c\u5c24\u5176\u5173\u6ce8\u5176\u7406\u89e3\u533b\u5b66\u6982\u5ff5\u7684\u80fd\u529b\u3002", "method": "\u5bf9\u591a\u4e2a\u8bed\u8a00\u6a21\u578b\u4e0e\u4e13\u5bb6\u4e34\u5e8a\u533b\u751f\u5728\u4e73\u817a\u764c\u514d\u75ab\u6cbb\u7597\u6587\u6458\u4e2d\u8bc6\u522b\u533b\u5b66\u7279\u5f81\u7684\u80fd\u529b\u8fdb\u884c\u4e86\u6bd4\u8f83\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u9884\u8bad\u7ec3\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u6a21\u578b\u5728\u8bc6\u522b\u5177\u4f53\u3001\u4f4e\u5c42\u6b21\u533b\u5b66\u6982\u5ff5\u65f6\u8868\u73b0\u4f18\u5f02\uff0c\u6709\u65f6\u53ef\u8d85\u8fc7\u901a\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5728\u8bc6\u522b\u4e73\u817a\u764c\u514d\u75ab\u6cbb\u7597\u6587\u6458\u4e2d\u7279\u5b9a\u533b\u5b66\u6982\u5ff5\u65b9\u9762\uff0c\u6709\u6f5c\u529b\u4f18\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2506.11597", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11597", "abs": "https://arxiv.org/abs/2506.11597", "authors": ["Simone Romano", "Francesco Paolo Sferratore", "Giuseppe Scanniello"], "title": "Further Evidence on a Controversial Topic about Human-Based Experiments: Professionals vs. Students", "comment": null, "summary": "Most Software Engineering (SE) human-based controlled experiments rely on\nstudents as participants, raising concerns about their external validity.\nSpecifically, the realism of results obtained from students and their\napplicability to the software industry remains in question. In this short\npaper, we bring further evidence on this controversial point. To do so, we\ncompare 62 students and 42 software professionals on a bug-fixing task on the\nsame Java program. The students were enrolled in a Bachelor's program in\nComputer Science, while the professionals were employed by two multinational\ncompanies (for one of them, the professionals were from two offices). Some\nvariations in the experimental settings of the two groups (students and\nprofessionals) were present. For instance, the experimental environment of the\nexperiment with professionals was more realistic; i.e., they faced some stress\nfactors such as interruptions during the bug-fixing task. Considering the\ndifferences between the two groups of participants, the gathered data show that\nthe students outperformed the professionals in fixing bugs. This diverges to\nsome extent from past empirical evidence. Rather than presenting definitive\nconclusions, our results aim to catalyze the discussion on the use of students\nin experiments and pave the way for future investigations. Specifically, our\nresults encourage us to examine the complex factors influencing SE tasks,\nmaking experiments as more realistic as possible.", "AI": {"tldr": "\u4f5c\u8005\u5bf9\u6bd4\u4e86\u5b66\u751f\u4e0e\u4e1a\u754c\u5de5\u7a0b\u5e08\u5728\u8f6f\u4ef6\u7f3a\u9677\u4fee\u590d\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5b66\u751f\u6574\u4f53\u4f18\u4e8e\u5728\u804c\u4e13\u5bb6\u3002\u8be5\u7ed3\u679c\u4e0e\u8fc7\u53bb\u90e8\u5206\u7814\u7a76\u76f8\u6096\uff0c\u4f46\u672a\u4e0b\u5b9a\u8bba\uff0c\u65e8\u5728\u5f15\u53d1\u66f4\u591a\u5173\u4e8e\u5b9e\u9a8c\u53c2\u4e0e\u8005\u9009\u62e9\u548c\u5b9e\u9a8c\u8bbe\u8ba1\u73b0\u5b9e\u6027\u7684\u7814\u7a76\u8ba8\u8bba\u3002", "motivation": "\u5927\u591a\u6570\u8f6f\u4ef6\u5de5\u7a0b\uff08SE\uff09\u53d7\u63a7\u5b9e\u9a8c\u901a\u5e38\u4ee5\u5b66\u751f\u4e3a\u88ab\u8bd5\uff0c\u8fd9\u5f15\u53d1\u4e86\u6709\u5173\u5b9e\u9a8c\u5916\u90e8\u6709\u6548\u6027\u7684\u62c5\u5fe7\uff0c\u7279\u522b\u662f\u7528\u5b66\u751f\u83b7\u5f97\u7684\u7ed3\u679c\u662f\u5426\u5177\u5907\u73b0\u5b9e\u6027\uff0c\u5e76\u80fd\u5426\u63a8\u5e7f\u5230\u8f6f\u4ef6\u5de5\u4e1a\u5b9e\u8df5\u4e2d\u3002\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u5e76\u4e3a\u8fd9\u4e00\u4e89\u8bae\u6027\u8bdd\u9898\u63d0\u4f9b\u66f4\u591a\u8bc1\u636e\u3002", "method": "\u4f5c\u8005\u5bf962\u540d\u8ba1\u7b97\u673a\u79d1\u5b66\u672c\u79d1\u751f\u548c42\u540d\u6765\u81ea\u4e24\u5bb6\u8de8\u56fd\u516c\u53f8\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u8ba9\u4e24\u7ec4\u88ab\u8bd5\u5728\u540c\u4e00\u4e2aJava\u9879\u76ee\u4e0a\u8fdb\u884c\u4fee\u590dBug\u4efb\u52a1\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u4e24\u7ec4\u5b9e\u9a8c\u8bbe\u7f6e\u6709\u7ec6\u5fae\u4e0d\u540c\uff1a\u4e13\u4e1a\u4eba\u58eb\u5b9e\u9a8c\u73af\u5883\u66f4\u63a5\u8fd1\u73b0\u5b9e\uff0c\u4f8b\u5982\u5728\u4feeBug\u8fc7\u7a0b\u4e2d\u9762\u4e34\u4e2d\u65ad\u7b49\u538b\u529b\u56e0\u7d20\u3002", "result": "\u5b9e\u9a8c\u6570\u636e\u663e\u793a\uff0c\u5b66\u751f\u5728\u4fee\u590dBug\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4e13\u4e1a\u4eba\u58eb\uff0c\u8fd9\u4e00\u7ed3\u679c\u4e0e\u90e8\u5206\u65e2\u5f80\u5b9e\u8bc1\u8bc1\u636e\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u672c\u6587\u7ed3\u679c\u5e76\u672a\u7ed9\u51fa\u660e\u786e\u7ed3\u8bba\uff0c\u800c\u662f\u5e0c\u671b\u6fc0\u53d1\u5bf9SE\u5b9e\u9a8c\u4e2d\u88ab\u8bd5\u9009\u62e9\u7684\u8fdb\u4e00\u6b65\u8ba8\u8bba\uff0c\u5e76\u4e3a\u4eca\u540e\u7814\u7a76\u94fa\u8def\u3002\u4f5c\u8005\u9f13\u52b1\u5bf9\u5f71\u54cdSE\u4efb\u52a1\u8868\u73b0\u7684\u590d\u6742\u56e0\u7d20\u8fdb\u884c\u6df1\u5165\u63a2\u7d22\uff0c\u672a\u6765\u5e94\u8ba9\u5b9e\u9a8c\u66f4\u5177\u73b0\u5b9e\u611f\u3002"}}
{"id": "2506.11485", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.11485", "abs": "https://arxiv.org/abs/2506.11485", "authors": ["Cole Gawin"], "title": "Relational Schemata in BERT Are Inducible, Not Emergent: A Study of Performance vs. Competence in Language Models", "comment": "15 pages, 4 figures, 3 tables", "summary": "While large language models like BERT demonstrate strong empirical\nperformance on semantic tasks, whether this reflects true conceptual competence\nor surface-level statistical association remains unclear. I investigate whether\nBERT encodes abstract relational schemata by examining internal representations\nof concept pairs across taxonomic, mereological, and functional relations. I\ncompare BERT's relational classification performance with representational\nstructure in [CLS] token embeddings. Results reveal that pretrained BERT\nenables high classification accuracy, indicating latent relational signals.\nHowever, concept pairs organize by relation type in high-dimensional embedding\nspace only after fine-tuning on supervised relation classification tasks. This\nindicates relational schemata are not emergent from pretraining alone but can\nbe induced via task scaffolding. These findings demonstrate that behavioral\nperformance does not necessarily imply structured conceptual understanding,\nthough models can acquire inductive biases for grounded relational abstraction\nthrough appropriate training.", "AI": {"tldr": "BERT\u9884\u8bad\u7ec3\u867d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u53ea\u6709\u5728\u7ecf\u8fc7\u5173\u7cfb\u5206\u7c7b\u5fae\u8c03\u540e\u624d\u8868\u73b0\u51fa\u7ed3\u6784\u5316\u7684\u5173\u7cfb\u7406\u89e3\uff0c\u8868\u660e\u7ed3\u6784\u6027\u6982\u5ff5\u7406\u89e3\u4f9d\u8d56\u4e8e\u5408\u9002\u7684\u4efb\u52a1\u8bad\u7ec3\uff0c\u800c\u5e76\u975e\u4ec5\u4ec5\u6e90\u4e8e\u6d77\u91cf\u6587\u672c\u9884\u8bad\u7ec3\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5982BERT\u5728\u8bed\u4e49\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u8fd9\u662f\u5426\u610f\u5473\u7740\u5176\u771f\u6b63\u7406\u89e3\u6982\u5ff5\u5173\u7cfb\u8fd8\u662f\u4ec5\u57fa\u4e8e\u8868\u5c42\u7684\u7edf\u8ba1\u5173\u8054\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22BERT\u662f\u5426\u7f16\u7801\u4e86\u62bd\u8c61\u7684\u5173\u7cfb\u7ed3\u6784\u6a21\u5f0f\u3002", "method": "\u5206\u6790BERT\u5bf9\u4e0d\u540c\u6982\u5ff5\u5bf9\uff08\u5982\u5206\u7c7b\u5173\u7cfb\u3001\u6574\u4f53-\u90e8\u5206\u5173\u7cfb\u548c\u529f\u80fd\u5173\u7cfb\uff09\u7684\u5185\u90e8\u8868\u793a\uff0c\u6bd4\u8f83BERT\u5728\u5173\u7cfb\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4ee5\u53ca[CLS]\u5411\u91cf\u5d4c\u5165\u7684\u8868\u793a\u7ed3\u6784\uff0c\u5e76\u8003\u5bdf\u9884\u8bad\u7ec3\u4e0e\u76d1\u7763\u5fae\u8c03\u7684\u5dee\u5f02\u3002", "result": "\u9884\u8bad\u7ec3\u7684BERT\u53ef\u4ee5\u5b9e\u73b0\u8f83\u9ad8\u7684\u5173\u7cfb\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u8bf4\u660e\u5176\u5185\u90e8\u5305\u542b\u4e00\u5b9a\u7684\u5173\u7cfb\u4fe1\u53f7\u3002\u4f46\u901a\u8fc7\u4e3b\u6210\u5206\u5206\u6790\u7b49\u65b9\u6cd5\u53d1\u73b0\uff0c\u6982\u5ff5\u5bf9\u53ea\u6709\u5728\u7ecf\u8fc7\u5173\u7cfb\u5206\u7c7b\u4efb\u52a1\u5fae\u8c03\u540e\u624d\u4f1a\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u6309\u5173\u7cfb\u7c7b\u578b\u6709\u7ed3\u6784\u5730\u805a\u7c7b\uff0c\u8868\u660e\u5173\u7cfb\u7ed3\u6784\u5e76\u975e\u4ec5\u9760\u9884\u8bad\u7ec3\u81ea\u7136\u5f62\u6210\u3002", "conclusion": "\u884c\u4e3a\u4e0a\u7684\u9ad8\u5206\u7c7b\u51c6\u786e\u7387\u5e76\u4e0d\u4ee3\u8868BERT\u5177\u6709\u7ed3\u6784\u5316\u7684\u6982\u5ff5\u7406\u89e3\uff0c\u4f46\u901a\u8fc7\u6070\u5f53\u7684\u76d1\u7763\u8bad\u7ec3\uff0c\u6a21\u578b\u80fd\u591f\u83b7\u5f97\u5bf9\u5173\u7cfb\u62bd\u8c61\u7684\u5f52\u7eb3\u504f\u7f6e\u548c\u7ed3\u6784\u5316\u7684\u8868\u5f81\u3002"}}
{"id": "2506.11598", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11598", "abs": "https://arxiv.org/abs/2506.11598", "authors": ["Ahmed Zaki", "Cristian Cadar"], "title": "Understanding API Usage and Testing: An Empirical Study of C Libraries", "comment": "The 29th International Conference on Evaluation and Assessment in\n  Software Engineering, 17 to 20 June, 2025, Istanbul, Turkey", "summary": "For library developers, understanding how their Application Programming\nInterfaces (APIs) are used in the field can be invaluable. Knowing how clients\nare using their APIs allows for data-driven decisions on prioritising bug\nreports, feature requests, and testing activities. For example, the priority of\na bug report concerning an API can be partly determined by how widely that API\nis used.\n  In this paper, we present an empirical study in which we analyse API usage\nacross 21 popular open-source C libraries, such as OpenSSL and SQLite, with a\ncombined total of 3,061 C/C++ clients. We compare API usage by clients with how\nwell library test suites exercise the APIs to offer actionable insights for\nlibrary developers. To our knowledge, this is the first study that compares API\nusage and API testing at scale for the C/C++ ecosystem. Our study shows that\nlibrary developers do not prioritise their effort based on how clients use\ntheir API, with popular APIs often poorly tested. For example, in LMDB, a\npopular key-value store, 45% of the APIs are used by clients but not tested by\nthe library test suite. We further show that client test suites can be\nleveraged to improve library testing e.g., improving coverage in LMDB by 14.7%\nwith the important advantage that those tests are representative of how the\nAPIs are used in the field.\n  For our empirical study, we have developed LibProbe, a framework that can be\nused to analyse a large corpus of clients for a given library and produce\nvarious metrics useful to library developers.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5206\u6790C/C++\u5f00\u6e90\u5e93\u53ca\u5176\u5ba2\u6237\u7aef\uff0c\u53d1\u73b0\u5e93\u7684\u6d4b\u8bd5\u5f80\u5f80\u5ffd\u89c6\u4e86\u5b9e\u9645\u9ad8\u9891API\u7684\u60c5\u51b5\u3002\u5229\u7528\u5ba2\u6237\u7aef\u7684\u6d4b\u8bd5\u6848\u4f8b\u6709\u52a9\u4e8e\u63d0\u5347\u5e93\u7684\u6d4b\u8bd5\u5168\u9762\u6027\u548c\u73b0\u5b9e\u6027\uff0c\u5e76\u5f00\u53d1\u4e86LibProbe\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u8005\u505a\u51fa\u66f4\u5408\u7406\u7684\u6d4b\u8bd5\u4e0e\u7ef4\u62a4\u51b3\u7b56\u3002", "motivation": "\u5e93\u5f00\u53d1\u8005\u9700\u8981\u4e86\u89e3API\u5728\u5b9e\u9645\u4e2d\u7684\u4f7f\u7528\uff0c\u4ee5\u4f18\u5316bug\u4f18\u5148\u7ea7\u3001\u529f\u80fd\u9700\u6c42\u548c\u6d4b\u8bd5\u8d44\u6e90\u5206\u914d\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5168\u9762\u5de5\u5177\u4e0e\u5bf9\u5e94\u7814\u7a76\uff0c\u5c24\u5176\u662f\u5728C/C++\u751f\u6001\u4e2d\u3002", "method": "\u8bba\u6587\u5bf921\u4e2a\u6d41\u884c\u5f00\u6e90C\u5e93\u53ca\u51763061\u4e2aC/C++\u5ba2\u6237\u7aef\u7684API\u4f7f\u7528\u60c5\u51b5\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u5e76\u5f00\u53d1\u4e86LibProbe\u5de5\u5177\u7528\u4e8e\u5206\u6790\u548c\u751f\u6210\u76f8\u5173\u6307\u6807\u3002\u5bf9\u6bd4\u4e86\u5ba2\u6237\u7aefAPI\u8c03\u7528\u4e0e\u5e93\u81ea\u5e26\u6d4b\u8bd5\u5bf9API\u7684\u8986\u76d6\u7a0b\u5ea6\uff0c\u5e76\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u5f15\u5165\u5ba2\u6237\u7aef\u6d4b\u8bd5\u53ef\u63d0\u5347\u5e93\u6d4b\u8bd5\u8986\u76d6\u7387\u3002", "result": "\uff081\uff09\u6d41\u884cAPI\u5f80\u5f80\u672a\u88ab\u5145\u5206\u6d4b\u8bd5\uff0c\u4f8b\u5982LMDB\u5e93\u4e2d45%\u7684\u88ab\u7528API\u672a\u88ab\u6d4b\u8bd5\uff1b\uff082\uff09\u5f15\u5165\u5ba2\u6237\u7aef\u6d4b\u8bd5\u53ef\u63d0\u5347\u6d4b\u8bd5\u8986\u76d6\u7387\uff0c\u5982LMDB\u63d0\u5347\u4e8614.7%\uff1b\uff083\uff09LibProbe\u5de5\u5177\u4e3a\u5927\u89c4\u6a21\u5206\u6790API\u4f7f\u7528\u4e0e\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002", "conclusion": "\u672c\u7814\u7a76\u53d1\u73b0\uff0c\u5e93\u5f00\u53d1\u8005\u5728\u6d4b\u8bd5\u548c\u7ef4\u62a4API\u65f6\uff0c\u5e76\u672a\u5145\u5206\u8003\u8651\u5230API\u5728\u5b9e\u9645\u5ba2\u6237\u7aef\u4e2d\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u5bfc\u81f4\u90e8\u5206\u9ad8\u9891\u4f7f\u7528\u7684API\u672a\u88ab\u5145\u5206\u6d4b\u8bd5\u3002\u901a\u8fc7\u7ed3\u5408\u5ba2\u6237\u7aef\u6d4b\u8bd5\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5e93\u7684\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u73b0\u5b9e\u4ee3\u8868\u6027\u3002"}}
{"id": "2506.11498", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11498", "abs": "https://arxiv.org/abs/2506.11498", "authors": ["Manlai Liang", "Wanyi Huang", "Mandi Liu", "Huaijun Li", "Jinlong Li"], "title": "Lag-Relative Sparse Attention In Long Context Training", "comment": null, "summary": "Large Language Models (LLMs) have made significant strides in natural\nlanguage processing and generation, yet their ability to handle long-context\ninput remains constrained by the quadratic complexity of attention computation\nand linear-increasing key-value memory footprint. To reduce computational costs\nand memory, key-value cache compression techniques are commonly applied at\ninference time, but this often leads to severe performance degradation, as\nmodels are not trained to handle compressed context. Although there are more\nsophisticated compression methods, they are typically unsuitable for\npost-training because of their incompatibility with gradient-based optimization\nor high computation overhead. To fill this gap with no additional parameter and\nlittle computation overhead, we propose Lag-Relative Sparse Attention(LRSA)\nanchored by the LagKV compression method for long context post-training. Our\nmethod performs chunk-by-chunk prefilling, which selects the top K most\nrelevant key-value pairs in a fixed-size lagging window, allowing the model to\nfocus on salient historical context while maintaining efficiency. Experimental\nresults show that our approach significantly enhances the robustness of the LLM\nwith key-value compression and achieves better fine-tuned results in the\nquestion-answer tuning task.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Lag-Relative Sparse Attention\uff08LRSA\uff09\u53caLagKV\u538b\u7f29\u6cd5\uff0c\u5728\u957f\u6587\u672c\u63a8\u7406\u9636\u6bb5\u9ad8\u6548\u538b\u7f29key-value\u7f13\u5b58\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u6a21\u578b\u538b\u7f29\u540e\u7684\u6027\u80fd\u4e0e\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u8f93\u5165\u65f6\uff0c\u56e0\u6ce8\u610f\u529b\u673a\u5236\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u53ca\u5b58\u50a8\u9700\u6c42\u7ebf\u6027\u589e\u52a0\uff0c\u5bfc\u81f4\u8ba1\u7b97\u548c\u5185\u5b58\u6d88\u8017\u5de8\u5927\u3002\u867d\u7136\u6709\u538b\u7f29key-value\u7f13\u5b58\u7684\u65b9\u6cd5\u80fd\u964d\u4f4e\u6d88\u8017\uff0c\u4f46\u5728\u6a21\u578b\u672a\u5bf9\u538b\u7f29\u4e0a\u4e0b\u6587\u8fdb\u884c\u8bad\u7ec3\u65f6\u4f1a\u9020\u6210\u6027\u80fd\u4e25\u91cd\u4e0b\u964d\uff0c\u76ee\u524d\u66f4\u590d\u6742\u7684\u538b\u7f29\u65b9\u6cd5\u56e0\u4e0e\u4f18\u5316\u65b9\u6cd5\u4e0d\u517c\u5bb9\u6216\u6d88\u8017\u8fc7\u9ad8\uff0c\u4e0d\u9002\u4e8e\u63a8\u7406\u540e\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86Lag-Relative Sparse Attention\uff08LRSA\uff09\u673a\u5236\uff0c\u57fa\u4e8eLagKV\u538b\u7f29\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5757prefilling\uff0c\u9009\u62e9\u56fa\u5b9a\u5927\u5c0f\u6ede\u540e\u7a97\u53e3\u4e2d\u6700\u76f8\u5173\u7684K\u4e2akey-value\u5bf9\uff0c\u5927\u5e45\u5ea6\u63d0\u9ad8\u957f\u4e0a\u4e0b\u6587\u540e\u8bad\u7ec3\u9636\u6bb5\u7684\u6548\u7387\u4e14\u65e0\u9700\u589e\u52a0\u65b0\u53c2\u6570\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728key-value\u538b\u7f29\u540e\u663e\u8457\u63d0\u5347\u4e86LLM\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u95ee\u7b54\u5fae\u8c03\u4efb\u52a1\u4e2d\u83b7\u5f97\u4e86\u66f4\u597d\u7684\u6548\u679c\u3002", "conclusion": "LRSA\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e0bkey-value\u538b\u7f29\u9020\u6210\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u540c\u65f6\u517c\u987e\u4e86\u6a21\u578b\u6548\u7387\u548c\u6548\u679c\u3002\u65e0\u9700\u989d\u5916\u53c2\u6570\u548c\u8f83\u5c0f\u8ba1\u7b97\u5f00\u9500\uff0c\u9002\u5408\u540e\u8bad\u7ec3\u573a\u666f\u3002"}}
{"id": "2506.11614", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11614", "abs": "https://arxiv.org/abs/2506.11614", "authors": ["Yonggang Tao", "Jingling Xue"], "title": "Accelerating Delta Debugging through Probabilistic Monotonicity Assessment", "comment": "Accepted by EASE 2025 (The 29th International Conference on\n  Evaluation and Assessment in Software Engineering), 17-20 June 2025,\n  Istanbul, Turkey. 11 pages", "summary": "Delta debugging assumes search space monotonicity: if a program causes a\nfailure, any supersets of that program will also induce the same failure,\npermitting the exclusion of subsets of non-failure-inducing programs. However,\nthis assumption does not always hold in practice. This paper introduces\nProbabilistic Monotonicity Assessment (PMA), enhancing the efficiency of\nDDMIN-style algorithms without sacrificing effectiveness. PMA dynamically\nmodels and assesses the search space's monotonicity based on prior tests tried\nduring the debugging process and uses a confidence function to quantify\nmonotonicity, thereby enabling the probabilistic exclusion of subsets of\nnon-failure-inducing programs. Our approach significantly reduces redundant\ntests that would otherwise be performed, without compromising the quality of\nthe reduction.\n  We evaluated PMA against two leading DDMIN-style tools, CHISEL and ProbDD.\nOur findings indicate that PMA cuts processing time by 59.2% compared to\nCHISEL, accelerates the reduction process (i.e., the number of tokens deleted\nper second) by 3.32x, and decreases the sizes of the final reduced programs by\n6.7%. Against ProbDD, PMA reduces processing time by 22.0%, achieves a 1.34x\nspeedup in the reduction process, and further decreases the sizes of the final\nreduced programs by 3.0%. These findings affirm PMA's role in significantly\nimproving delta debugging's efficiency while maintaining or enhancing its\neffectiveness.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6982\u7387\u6027\u5355\u8c03\u6027\u8bc4\u4f30\u65b9\u6cd5PMA\uff0c\u7528\u4e8e\u63d0\u5347\u589e\u91cf\u8c03\u8bd5\u5de5\u5177\u5728\u5b9e\u9645\u975e\u4e25\u683c\u5355\u8c03\u6027\u6761\u4ef6\u4e0b\u7684\u6548\u7387\uff0c\u7ecf\u5b9e\u9a8c\u9a8c\u8bc1\u80fd\u5927\u5e45\u51cf\u5c11\u8c03\u8bd5\u65f6\u95f4\u5e76\u4f18\u5316\u6700\u7ec8\u7ed3\u679c\u3002", "motivation": "delta debugging\uff08\u589e\u91cf\u8c03\u8bd5\uff09\u5047\u8bbe\u641c\u7d22\u7a7a\u95f4\u5177\u6709\u5355\u8c03\u6027\uff0c\u4f46\u5b9e\u9645\u4e2d\u8be5\u5047\u8bbe\u5e76\u4e0d\u603b\u662f\u6210\u7acb\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u63d0\u5347\u7b97\u6cd5\u5728\u975e\u5b8c\u5168\u5355\u8c03\u6027\u60c5\u51b5\u4e0b\u7684\u6548\u7387\u548c\u6548\u679c\u3002", "method": "\u63d0\u51faProbabilistic Monotonicity Assessment\uff08PMA\uff09\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u5df2\u6709\u6d4b\u8bd5\u52a8\u6001\u5efa\u6a21\u5e76\u8bc4\u4f30\u641c\u7d22\u7a7a\u95f4\u7684\u5355\u8c03\u6027\uff0c\u5229\u7528\u7f6e\u4fe1\u5ea6\u51fd\u6570\u6765\u91cf\u5316\u5355\u8c03\u6027\uff0c\u4ece\u800c\u6982\u7387\u6027\u5730\u6392\u9664\u67d0\u4e9b\u5b50\u96c6\u7684\u6d4b\u8bd5\u3002\u65b9\u6cd5\u5d4c\u5165\u4e8eDDMIN\u7b97\u6cd5\u6d41\u7a0b\u4e2d\u4ee5\u63d0\u5347\u6548\u7387\u3002", "result": "PMA\u65b9\u6cd5\u5206\u522b\u4e0eCHISEL\u548cProbDD\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u76f8\u6bd4CHISEL\uff0c\u5904\u7406\u65f6\u95f4\u51cf\u5c1159.2%\uff0c\u5220\u9664\u901f\u5ea6\u63d0\u53473.32\u500d\uff0c\u6700\u7ec8\u7f29\u51cf\u7a0b\u5e8f\u4f53\u79ef\u51cf\u5c116.7%\uff1b\u76f8\u6bd4ProbDD\uff0c\u5904\u7406\u65f6\u95f4\u51cf\u5c1122%\uff0c\u7f29\u51cf\u901f\u5ea6\u63d0\u53471.34\u500d\uff0c\u6700\u7ec8\u7a0b\u5e8f\u4f53\u79ef\u51cf\u5c113.0%\u3002", "conclusion": "PMA\u65b9\u6cd5\u5728\u4e0d\u964d\u4f4e\u7f29\u51cf\u8d28\u91cf\u7684\u57fa\u7840\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86delta debugging\u7684\u6548\u7387\u548c\u6548\u679c\uff0c\u9002\u5e94\u4e86\u5b9e\u9645\u4e2d\u975e\u4e25\u683c\u5355\u8c03\u6027\u7684\u641c\u7d22\u7a7a\u95f4\u3002"}}
{"id": "2506.11499", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11499", "abs": "https://arxiv.org/abs/2506.11499", "authors": ["Seongbo Jang", "Seonghyeon Lee", "Dongha Lee", "Hwanjo Yu"], "title": "On the Effectiveness of Integration Methods for Multimodal Dialogue Response Retrieval", "comment": "9 pages, 1 figure", "summary": "Multimodal chatbots have become one of the major topics for dialogue systems\nin both research community and industry. Recently, researchers have shed light\non the multimodality of responses as well as dialogue contexts. This work\nexplores how a dialogue system can output responses in various modalities such\nas text and image. To this end, we first formulate a multimodal dialogue\nresponse retrieval task for retrieval-based systems as the combination of three\nsubtasks. We then propose three integration methods based on a two-step\napproach and an end-to-end approach, and compare the merits and demerits of\neach method. Experimental results on two datasets demonstrate that the\nend-to-end approach achieves comparable performance without an intermediate\nstep in the two-step approach. In addition, a parameter sharing strategy not\nonly reduces the number of parameters but also boosts performance by\ntransferring knowledge across the subtasks and the modalities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u591a\u6a21\u6001\u5bf9\u8bdd\u68c0\u7d22\u65b0\u4efb\u52a1\uff0c\u6bd4\u8f83\u4e09\u79cd\u96c6\u6210\u65b9\u6cd5\uff0c\u53d1\u73b0\u7aef\u5230\u7aef\u65b9\u6cd5\u548c\u53c2\u6570\u5171\u4eab\u7b56\u7565\u5728\u63d0\u5347\u6027\u80fd\u548c\u51cf\u5c11\u53c2\u6570\u91cf\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u8fd1\u5e74\u6765\u591a\u6a21\u6001\u804a\u5929\u673a\u5668\u4eba\uff08\u80fd\u5904\u7406\u6587\u672c\u3001\u56fe\u50cf\u7b49\u591a\u79cd\u4fe1\u606f\u7684\u5bf9\u8bdd\u7cfb\u7edf\uff09\u6210\u4e3a\u4e1a\u754c\u548c\u5b66\u672f\u754c\u7684\u91cd\u8981\u8bfe\u9898\u3002\u7814\u7a76\u8005\u5f00\u59cb\u5173\u6ce8\u5982\u4f55\u8ba9\u7cfb\u7edf\u4e0d\u4ec5\u7406\u89e3\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\uff0c\u8fd8\u80fd\u4ee5\u591a\u79cd\u5f62\u5f0f\u8f93\u51fa\u56de\u590d\u3002", "method": "\u672c\u6587\u9488\u5bf9\u57fa\u4e8e\u68c0\u7d22\u7684\u591a\u6a21\u6001\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u63d0\u51fa\u4e86\u7ed3\u5408\u4e09\u9879\u5b50\u4efb\u52a1\u7684\u591a\u6a21\u6001\u5bf9\u8bdd\u54cd\u5e94\u68c0\u7d22\u4efb\u52a1\u3002\u8bbe\u8ba1\u4e86\u4e09\u79cd\u878d\u5408\u65b9\u6cd5\uff0c\u5305\u62ec\u4e24\u6b65\u6cd5\u4e0e\u7aef\u5230\u7aef\u6cd5\uff0c\u5e76\u8be6\u7ec6\u6bd4\u8f83\u4e86\u5b83\u4eec\u7684\u4f18\u7f3a\u70b9\u3002\u540c\u65f6\u5f15\u5165\u53c2\u6570\u5171\u4eab\u7b56\u7565\uff0c\u5b9e\u73b0\u77e5\u8bc6\u5728\u5b50\u4efb\u52a1\u548c\u6a21\u6001\u95f4\u7684\u8fc1\u79fb\u3002", "result": "\u7aef\u5230\u7aef\u65b9\u6cd5\u65e0\u9700\u4e2d\u95f4\u6b65\u9aa4\u4e5f\u80fd\u53d6\u5f97\u4e0e\u4e24\u6b65\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u3002\u53c2\u6570\u5171\u4eab\u7b56\u7565\u65e2\u51cf\u5c11\u6a21\u578b\u53c2\u6570\u91cf\uff0c\u53c8\u901a\u8fc7\u77e5\u8bc6\u8fc1\u79fb\u63d0\u5347\u4e86\u6a21\u578b\u8868\u73b0\u3002", "conclusion": "\u7aef\u5230\u7aef\u591a\u6a21\u6001\u68c0\u7d22\u65b9\u6cd5\u80fd\u7b80\u5316\u6d41\u7a0b\u4e14\u6548\u679c\u4f18\u826f\uff0c\u53c2\u6570\u5171\u4eab\u4e0d\u4ec5\u63d0\u5347\u6027\u80fd\u8fd8\u51cf\u5c0f\u6a21\u578b\u89c4\u6a21\uff0c\u6709\u52a9\u4e8e\u591a\u6a21\u6001\u5bf9\u8bdd\u7cfb\u7edf\u7684\u4f18\u5316\u3002"}}
{"id": "2506.11659", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.11659", "abs": "https://arxiv.org/abs/2506.11659", "authors": ["Simin Sun", "Yuchuan Jin", "Miroslaw Staron"], "title": "An Empirical study on LLM-based Log Retrieval for Software Engineering Metadata Management", "comment": null, "summary": "Developing autonomous driving systems (ADSs) involves generating and storing\nextensive log data from test drives, which is essential for verification,\nresearch, and simulation. However, these high-frequency logs, recorded over\nvarying durations, pose challenges for developers attempting to locate specific\ndriving scenarios. This difficulty arises due to the wide range of signals\nrepresenting various vehicle components and driving conditions, as well as\nunfamiliarity of some developers' with the detailed meaning of these signals.\nTraditional SQL-based querying exacerbates this challenge by demanding both\ndomain expertise and database knowledge, often yielding results that are\ndifficult to verify for accuracy.\n  This paper introduces a Large Language Model (LLM)-supported approach that\ncombines signal log data with video recordings from test drives, enabling\nnatural language based scenario searches while reducing the need for\nspecialized knowledge. By leveraging scenario distance graphs and relative gap\nindicators, it provides quantifiable metrics to evaluate the reliability of\nquery results. The method is implemented as an API for efficient database\nquerying and retrieval of relevant records, paired with video frames for\nintuitive visualization. Evaluation on an open industrial dataset demonstrates\nimproved efficiency and reliability in scenario retrieval, eliminating\ndependency on a single data source and conventional SQL.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u81ea\u52a8\u9a7e\u9a76\u65e5\u5fd7\u68c0\u7d22\uff0c\u5c06\u65e5\u5fd7\u548c\u89c6\u9891\u7ed3\u5408\uff0c\u7528\u81ea\u7136\u8bed\u8a00\u800c\u975eSQL\u5b9e\u73b0\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u573a\u666f\u67e5\u8be2\uff0c\u7b80\u5316\u6d41\u7a0b\u5e76\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u9700\u8981\u5206\u6790\u5927\u91cf\u7684\u9ad8\u9891\u65e5\u5fd7\u6570\u636e\uff0c\u4f46\u7531\u4e8e\u4fe1\u53f7\u79cd\u7c7b\u7e41\u6742\u4e14\u90e8\u5206\u5f00\u53d1\u8005\u5bf9\u4fe1\u53f7\u542b\u4e49\u4e0d\u719f\u6089\uff0c\u5bfc\u81f4\u67e5\u8be2\u548c\u5b9a\u4f4d\u7279\u5b9a\u9a7e\u9a76\u573a\u666f\u56f0\u96be\uff0c\u4f20\u7edfSQL\u67e5\u8be2\u53c8\u8981\u6c42\u9ad8\u9886\u57df\u53ca\u6570\u636e\u5e93\u77e5\u8bc6\uff0c\u4e14\u7ed3\u679c\u96be\u4ee5\u9a8c\u8bc1\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u5c06\u4fe1\u53f7\u65e5\u5fd7\u6570\u636e\u4e0e\u6d4b\u8bd5\u89c6\u9891\u7ed3\u5408\uff0c\u5229\u7528\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u9a71\u52a8\u573a\u666f\u68c0\u7d22\u3002\u8bbe\u8ba1\u4e86\u573a\u666f\u8ddd\u79bb\u56fe\u548c\u76f8\u5bf9\u95f4\u9699\u6307\u6807\uff0c\u91cf\u5316\u8bc4\u4f30\u67e5\u8be2\u7ed3\u679c\u7684\u53ef\u9760\u6027\u3002\u65b9\u6cd5\u901a\u8fc7API\u5b9e\u73b0\u9ad8\u6548\u67e5\u8be2\uff0c\u5e76\u914d\u5408\u89c6\u9891\u5e27\u76f4\u89c2\u5c55\u793a\u7ed3\u679c\u3002", "result": "\u5728\u516c\u5f00\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u6d4b\u8bd5\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u573a\u666f\u68c0\u7d22\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\u66f4\u9ad8\uff0c\u964d\u4f4e\u4e86\u5bf9\u5355\u4e00\u6570\u636e\u6e90\u548c\u4f20\u7edfSQL\u7684\u4f9d\u8d56\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u7528LLM\u63d0\u5347\u4e86\u81ea\u52a8\u9a7e\u9a76\u65e5\u5fd7\u68c0\u7d22\u7684\u53cb\u597d\u6027\u4e0e\u51c6\u786e\u6027\uff0c\u7b80\u5316\u4e86\u67e5\u8be2\u6d41\u7a0b\uff0c\u4f7f\u5f97\u975e\u4e13\u4e1a\u4eba\u5458\u4e5f\u80fd\u9ad8\u6548\u67e5\u627e\u76ee\u6807\u573a\u666f\uff0c\u5e76\u589e\u5f3a\u4e86\u7ed3\u679c\u7684\u53ef\u9a8c\u8bc1\u6027\u3002"}}
{"id": "2506.11557", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.11557", "abs": "https://arxiv.org/abs/2506.11557", "authors": ["Chih-Hao Hsu", "Ying-Jia Lin", "Hung-Yu Kao"], "title": "From Persona to Person: Enhancing the Naturalness with Multiple Discourse Relations Graph Learning in Personalized Dialogue Generation", "comment": "Accepted by PAKDD 2025", "summary": "In dialogue generation, the naturalness of responses is crucial for effective\nhuman-machine interaction. Personalized response generation poses even greater\nchallenges, as the responses must remain coherent and consistent with the\nuser's personal traits or persona descriptions. We propose MUDI\n($\\textbf{Mu}$ltiple $\\textbf{Di}$scourse Relations Graph Learning) for\npersonalized dialogue generation. We utilize a Large Language Model to assist\nin annotating discourse relations and to transform dialogue data into\nstructured dialogue graphs. Our graph encoder, the proposed DialogueGAT model,\nthen captures implicit discourse relations within this structure, along with\npersona descriptions. During the personalized response generation phase, novel\ncoherence-aware attention strategies are implemented to enhance the decoder's\nconsideration of discourse relations. Our experiments demonstrate significant\nimprovements in the quality of personalized responses, thus resembling\nhuman-like dialogue exchanges.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u56fe\u7ed3\u6784\u5b66\u4e60\uff0c\u63d0\u5347\u4e86\u4e2a\u6027\u5316\u5bf9\u8bdd\u7cfb\u7edf\u7684\u56de\u590d\u8d28\u91cf\u548c\u8fde\u8d2f\u6027\uff0c\u751f\u6210\u7684\u56de\u7b54\u66f4\u52a0\u4eba\u6027\u5316\u3002", "motivation": "\u5728\u5bf9\u8bdd\u751f\u6210\u4e2d\uff0c\u4e2a\u6027\u5316\u548c\u81ea\u7136\u5ea6\u662f\u63d0\u5347\u4eba\u673a\u4ea4\u4e92\u4f53\u9a8c\u7684\u5173\u952e\u3002\u5b9e\u73b0\u4e2a\u6027\u5316\u56de\u590d\u5e38\u5e38\u9762\u4e34\u4e2a\u6027\u7279\u5f81\u4e00\u81f4\u6027\u548c\u56de\u5e94\u8fde\u8d2f\u6027\u7684\u6311\u6218\u3002\u4f5c\u8005\u63d0\u51fa\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86MUDI\uff08Multiple Discourse Relations Graph Learning\uff09\u65b9\u6cd5\u3002\u9996\u5148\u91c7\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bdd\u8bed\u5173\u7cfb\u6807\u6ce8\uff0c\u5e76\u5c06\u5bf9\u8bdd\u6570\u636e\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u5bf9\u8bdd\u56fe\u3002\u518d\u901a\u8fc7\u81ea\u7814\u7684DialogueGAT\u56fe\u7f16\u7801\u5668\u6355\u6349\u9690\u542b\u7684\u8bdd\u8bed\u5173\u7cfb\u548c\u4e2a\u6027\u63cf\u8ff0\u3002\u5728\u751f\u6210\u4e2a\u6027\u5316\u56de\u590d\u9636\u6bb5\uff0c\u52a0\u5165\u4e86\u65b0\u7684\u5173\u6ce8\u8bdd\u8bed\u8fde\u8d2f\u6027\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7528\u4e8e\u4f18\u5316\u89e3\u7801\u5668\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u4e2a\u6027\u5316\u56de\u590d\u7684\u8d28\u91cf\uff0c\u4f7f\u5176\u66f4\u52a0\u8d34\u8fd1\u4eba\u7c7b\u7684\u5bf9\u8bdd\u884c\u4e3a\u3002", "conclusion": "\u5229\u7528\u591a\u91cd\u8bdd\u8bed\u5173\u7cfb\u56fe\u53ca\u521b\u65b0\u7684\u7ed3\u6784\u5efa\u6a21\u548c\u751f\u6210\u673a\u5236\uff0c\u80fd\u591f\u660e\u663e\u63d0\u5347\u4e2a\u6027\u5316\u5bf9\u8bdd\u7cfb\u7edf\u7684\u56de\u590d\u81ea\u7136\u5ea6\u4e0e\u4eba\u6027\u5316\u3002"}}
