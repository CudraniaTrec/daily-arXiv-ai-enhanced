<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]
- [cs.SE](#cs.SE) [Total: 12]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.CL](#cs.CL) [Total: 25]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Filling the Gaps of Polarity: Implementing Dependent Data and Codata Types with Implicit Arguments](https://arxiv.org/abs/2511.15819)
*Bohdan Liesnikov,David Binder,Tim Süberkrüb*

Main category: cs.PL

TL;DR: 本文为Polarity这种对称支持归纳/余归纳类型的语言，设计并实现了算法型类型系统和隐式参数推理算法，提升了语言实用性，相关算法和决策可作为其他依赖类型语言的范例。


<details>
  <summary>Details</summary>
Motivation: 目前大多数依赖类型语言对扩展操作（如代数数据类型）支持良好，但对新构造器（如实现接口的对象）支持不足，特别在隐式参数等功能方面有缺陷。Polarity试图对两种类型扩展提供对称支持，解决表达能力与可用性之间的矛盾。

Method: 作者提出并描述了支持归纳与余归纳类型的类型系统算法及推理算法，包括归约语义、等价性判定和支持模式匹配的统一算法，并进行相关实现。

Result: 实现了用于Polarity的完整类型系统与推理算法，包括归约语义、转换检查和统一算法，并已有原型系统上线。该方案可为其他同类语言提供参考。

Conclusion: 本文介绍了为Polarity语言设计的完整算法型类型系统和推理算法，特别是针对隐式参数，成功解决了其在处理归纳与余归纳类型时的统一性问题，提升了语言的实用性和泛用性。

Abstract: The expression problem describes a fundamental tradeoff between two types of extensibility: extending a type with new operations, such as by pattern matching on an algebraic data type in functional programming, and extending a type with new constructors, such as by adding a new object implementing an interface in object-oriented programming. Most dependently typed languages have good support for the former style through inductive types, but support for the latter style through coinductive types is usually much poorer. Polarity is a language that treats both kinds of types symmetrically and allows the developer to switch between type representations.However, it currently lacks several features expected of a state-of-the-art dependently typed language, such as implicit arguments. The central aim of this paper is to provide an algorithmic type system and inference algorithm for implicit arguments that respect the core symmetry of the language. Our work provides two key contributions: a complete algorithmic description of the type system backing Polarity, and a comprehensive description of a unification algorithm that covers arbitrary inductive and coinductive types. We give rules for reduction semantics, conversion checking, and a unification algorithm for pattern-matching, which are essential for a usable implementation. A work-in-progress implementation of the algorithms in this paper is available at https://polarity-lang.github.io/. We expect that the comprehensive account of the unification algorithm and our design decisions can serve as a blueprint for other dependently typed languages that support inductive and coinductive types symmetrically.

</details>


### [2] [Chorex: Restartable, Language-Integrated Choreographies](https://arxiv.org/abs/2511.15820)
*Ashton Wiersdorf,Ben Greenman*

Main category: cs.PL

TL;DR: Chorex将编舞式编程引入Elixir，实现了对Actor崩溃自动恢复及网络自适应的新机制，利用元编程深度集成，静态异常检查，实验证明其高可用与低开销，对提升分布式系统健壮性有推动作用。


<details>
  <summary>Details</summary>
Motivation: 分布式应用在面对节点故障时，通常缺乏友好的容错机制，而编写健壮的分布式系统代码极具挑战性。作者希望通过引入编舞式编程（choreographic programming）到Elixir语言，提升分布式系统的健壮性和可维护性。

Method: 提出了Chorex语言，将编舞式编程原理与Elixir进行集成，并利用元编程技术实现紧密集成。Chorex 能在演员崩溃时自动重启进程、恢复检查点状态、自动更新网络配置。此外，系统可以静态检查协议实现和编排要求间的差异。论文通过多个例子演示其功能，并测量了检查点操作带来的系统开销。

Result: Chorex 成功支持了容错重启，每当演员发生崩溃时可自动恢复并保持网络一致。通过元编程实现保证了与宿主语言的良好集成。实验表明，Chorex 能在Elixir下实现包含高级特性的编舞式应用，并有效地支持可重启的分布式进程结构。

Conclusion: Chorex证明了编舞式编程及其元编程实现不仅可用于Elixir，还可以为其他语言提供可被重启的无状态Actor支持，为构建高健壮性的分布式应用提供了一种新范式。

Abstract: We built Chorex, a language that brings choreographic programming to Elixir as a path toward robust distributed applications. Chorex is unique among choreographic languages because it tolerates failure among actors: when an actor crashes, Chorex spawns a new process, restores state using a checkpoint, and updates the network configuration for all actors. Chorex also proves that full-featured choreographies can be implemented via metaprogramming, and that doing so achieves tight integration with the host language. For example, mismatches between choreography requirements and an actor implementation are reported statically and in terms of source code rather than macro-expanded code. This paper illustrates Chorex on several examples, ranging from a higher-order bookseller to a secure remote password protocol, details its implementation, and measures the overhead of checkpointing. We conjecture that Chorex's projection strategy, which outputs sets of stateless functions, is a viable approach for other languages to support restartable actors.

</details>


### [3] [BlueScript: A Disaggregated Virtual Machine for Microcontrollers](https://arxiv.org/abs/2511.15821)
*Fumika Mochizuki,Tetsuro Yamazaki,Shigeru Chiba*

Main category: cs.PL

TL;DR: 本论文提出将微控制器虚拟机的组件最大化卸载到主机，利用其资源提升虚拟机的功能和性能，并以BlueScript VM为实例，通过影子机结构减少通信开销，实验证明卸载后性能优于主流方案，同时不损失交互体验。


<details>
  <summary>Details</summary>
Motivation: 微控制器开发对虚拟机（VM）有极大需求，尤其是交互式编程环境和高执行速度能够极大提升开发体验与应用范围。但由于微控制器内存有限，现有虚拟机功能受限，缺乏响应性和高效执行能力。尽管有研究尝试将部分VM组件卸载到其他机器，但可卸载组件类型仍有限。

Method: 提出了一种解除耦合（disaggregated）的虚拟机架构，将尽可能多的VM组件卸载到主机上。以此为原型，设计并实现了BlueScript虚拟机，通过“影子机”机制在主机上同步微控制器执行状态，减少通信开销。开展实验对比卸载后的编译器执行速度和交互性。

Result: 卸载VM组件并没有显著影响预期效能。卸载的增量编译器执行速度快于MicroPython和Espruino，交互性与MicroPython持平。卸载动态编译器也提升了VM性能。

Conclusion: 微控制器虚拟机可通过组件卸载充分利用主机资源，不仅可实现丰富功能，还能在受限内存下保障性能与交互体验。本文方案可为面向内存约束设备的VM创新提供新思路。

Abstract: Virtual machines (VMs) are highly beneficial for microcontroller development. 
In particular, interactive programming environments greatly facilitate iterative development processes, 
and higher execution speeds expand the range of applications that can be developed. 
However, due to their limited memory size, microcontroller VMs provide a limited set of features. 
Widely used VMs for microcontrollers often lack interactive responsiveness and/or high execution speed. 
While researchers have investigated offloading certain VM components to other machines,the types of components that can be offloaded are still restricted. 
In this paper, we propose a disaggregated VM that offloads as many components as possible to a host machine. 
This makes it possible to exploit the abundant memory of the host machine and its powerful processing capability to provide rich features through the VM. 
As an instance of a disaggregated VM, we design and implement a BlueScript VM. 
The BlueScript VM is a virtual machine for microcontrollers that provides an interactive development environment. 
We offload most of the components of the BlueScript VM to a host machine. 
To reduce communication overhead between the host machine and the microcontroller,  
we employed a data structure called a shadow machine on the host machine, 
which mirrors the execution state of the microcontroller. 
Through our experiments, we confirmed that offloading components does not seriously compromise their expected benefits.  
We assess that an offloaded incremental compiler results in faster execution speed than MicroPython and Espruino,  
while keeping interactivity comparable with MicroPython.  
In addition, our experiments observe that the offloaded dynamic compiler improves VM performance. 
Through this investigation, we demonstrate the feasibility of providing rich features even on VMs for memory-limited microcontrollers.

</details>


### [4] [Operon: Incremental Construction of Ragged Data via Named Dimensions](https://arxiv.org/abs/2511.16080)
*Sungbin Moon,Jiho Park,Suyoung Hwang,Donghyun Koh,Seunghyun Moon,Minhyeong Lee*

Main category: cs.PL

TL;DR: Operon是一个面向不规则数据的高效Rust工作流引擎，通过自动化维度依赖管理和高并行调度，显著提升了数据处理效率，特别适用于机器学习等大规模数据生成任务。


<details>
  <summary>Details</summary>
Motivation: 现代数据处理流程中经常遇到不规则（ragged）数据，即包含可变长度元素的数据集合。这类数据在自然语言处理、科学测量和自主AI等领域普遍存在。现有流程引擎不具备原生支持这种数据形状与依赖追踪的能力，导致用户不得不手动管理复杂的索引和依赖关系。

Method: 提出了名为Operon的Rust工作流引擎，通过明确命名维度及依赖关系，实现对不规则数据的自动追踪和管理。用户可用领域专用语言声明流程及维度，系统在运行时根据数据形状动态调度任务，并保证形状和任务关系的静态正确性。作者还数学化了部分已知形状的推理基础，并证明了系统可以在并行环境下保证确定性和收敛性。

Result: Operon通过显式建模部分已知的状态，实现了强健的数据持久化和恢复机制，采用多队列并行架构提高任务效率。实验证明，与现有引擎相比，Operon能减少14.94倍的基线开销，输出速率几乎随工作负载线性提升，尤其适合大规模机器学习数据生成管道。

Conclusion: Operon创新性地解决了不规则数据流程管理难题，提供了强大的自动化依赖跟踪、并行任务调度和高可扩展性，显著提升了大规模数据生成应用的效率和可靠性。

Abstract: Modern data processing workflows frequently encounter ragged data: collections with variable-length elements that arise naturally in domains like natural language processing, scientific measurements, and autonomous AI agents. Existing workflow engines lack native support for tracking the shapes and dependencies inherent to ragged data, forcing users to manage complex indexing and dependency bookkeeping manually. We present Operon, a Rust-based workflow engine that addresses these challenges through a novel formalism of named dimensions with explicit dependency relations. Operon provides a domain-specific language where users declare pipelines with dimension annotations that are statically verified for correctness, while the runtime system dynamically schedules tasks as data shapes are incrementally discovered during execution. We formalize the mathematical foundation for reasoning about partial shapes and prove that Operon's incremental construction algorithm guarantees deterministic and confluent execution in parallel settings. The system's explicit modeling of partially-known states enables robust persistence and recovery mechanisms, while its per-task multi-queue architecture achieves efficient parallelism across heterogeneous task types. Empirical evaluation demonstrates that Operon outperforms an existing workflow engine with 14.94x baseline overhead reduction while maintaining near-linear end-to-end output rates as workloads scale, making it particularly suitable for large-scale data generation pipelines in machine learning applications.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [5] [Technique to Baseline QE Artefact Generation Aligned to Quality Metrics](https://arxiv.org/abs/2511.15733)
*Eitan Farchi,Kiran Nayak,Papia Ghosh Majumdar,Saritha Route*

Main category: cs.SE

TL;DR: 文章提出一种结合LLM与反向生成及量化评估的新方法，从而系统性提升自动化生成的质量工程工件的质量，并通过实验证明其实用性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM已用于自动生成需求、测试用例等工件，但如何确保这些工件的高质量依然是个挑战。

Method: 结合了LLM驱动生成、反向生成和基于量化度量指标的逐步细化优化（rubrics）方法，对工件的清晰度、完整性、一致性、可测试性进行评价和提升。

Result: 在12个项目中的实验结果表明，反向生成的工件不仅能优于低质量输入，还能在高质量输入时保持标准，有效提升工件整体质量。

Conclusion: 该论文提出的框架能实现可扩展、可靠的质量工程（QE）工件验证，将自动化与问责制相结合。

Abstract: Large Language Models (LLMs) are transforming Quality Engineering (QE) by automating the generation of artefacts such as requirements, test cases, and Behavior Driven Development (BDD) scenarios. However, ensuring the quality of these outputs remains a challenge. This paper presents a systematic technique to baseline and evaluate QE artefacts using quantifiable metrics. The approach combines LLM-driven generation, reverse generation , and iterative refinement guided by rubrics technique for clarity, completeness, consistency, and testability. Experimental results across 12 projects show that reverse-generated artefacts can outperform low-quality inputs and maintain high standards when inputs are strong. The framework enables scalable, reliable QE artefact validation, bridging automation with accountability.

</details>


### [6] [Rethinking Kernel Program Repair: Benchmarking and Enhancing LLMs with RGym](https://arxiv.org/abs/2511.15757)
*Kareem Shehada,Yifan Wu,Wyatt D. Feng,Adithya Iyer,Gryphon Kumfert,Yangruibo Ding,Zhiyun Qian*

Main category: cs.SE

TL;DR: 针对内核APR难题，本文提出了RGym评测框架和经济高效的修复管线，专用定位策略和本地化执行显著提升修复率，对Linux内核Bug修复具有实际意义。


<details>
  <summary>Details</summary>
Motivation: 现有APR基准过于侧重用户空间，忽略了Linux内核这类复杂、难以调试和修复的场景。现有工作在内核APR上成功率低，依赖昂贵、复杂的计算资源。

Method: 提出了RGym，一个轻量、平台无关的Linux内核自动程序修复评测框架，利用专门的定位技术（如调用堆栈与相关提交）替代传统oracle方法，并在本地硬件上运行。还进行了消融实验分析定位策略、提示结构和模型选择的贡献。

Result: 在143个已筛选和校验的内核bug上，RGym配合GPT-5 Thinking，修复通过率高达43.36%，单bug平均成本低于0.2美元。反馈式重试机制显著提升了修复成功率。

Conclusion: RGym框架在Linux内核APR任务上提供有效且经济的解决方案，与现有方法相比提升了修复率和可及性。

Abstract: Large Language Models (LLMs) have revolutionized automated program repair (APR) but current benchmarks like SWE-Bench predominantly focus on userspace applications and overlook the complexities of kernel-space debugging and repair. The Linux kernel poses unique challenges due to its monolithic structure, concurrency, and low-level hardware interactions. Prior efforts such as KGym and CrashFixer have highlighted the difficulty of APR in this domain, reporting low success rates or relying on costly and complex pipelines and pricey cloud infrastructure. In this work, we introduce RGym, a lightweight, platform-agnostic APR evaluation framework for the Linux kernel designed to operate on local commodity hardware. Built on RGym, we propose a simple yet effective APR pipeline leveraging specialized localization techniques (e.g., call stacks and blamed commits) to overcome the unrealistic usage of oracles in KGym. We test on a filtered and verified dataset of 143 bugs. Our method achieves up to a 43.36% pass rate with GPT-5 Thinking while maintaining a cost of under $0.20 per bug. We further conduct an ablation study to analyze contributions from our proposed localization strategy, prompt structure, and model choice, and demonstrate that feedback-based retries can significantly enhance success rates.

</details>


### [7] [A Causal Perspective on Measuring, Explaining and Mitigating Smells in \llm-Generated Code](https://arxiv.org/abs/2511.15817)
*Alejandro Velasco,Daniel Rodriguez-Cardenas,Dipin Khati,David N. Palacio,Luftar Rahman Alif,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: 本文提出并验证了PSC指标，量化分析了LLM生成代码的结构性异味问题，发现通过改进提示词和模型架构可有效缓解，PSC亦有助于开发者质量判断，为高质量代码生成奠定基础。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）在软件工程中应用广泛，但其生成代码的结构性质量存在争议，特别是容易产生代码异味（影响代码可读性、可维护性或设计完整性的模式），且目前对生成代码中这些问题的产生和机制缺乏深入了解。

Method: 本文系统性地测量、解释并缓解LLM生成代码中的异味倾向。作者提出并利用了一种概率性指标——Propensity Smelly Score（PSC），用于量化和分析不同生成策略、模型规模、结构及提示词设计对代码结构性质量的影响，同时通过因果分析揭示各因素对代码异味的影响机制。此外，通过用户研究评估PSC对开发者理解模型行为和代码质量判断的帮助。

Result: 研究发现，提示设计和模型架构对代码异味的产生起决定性作用，改进这些方面能有效降低异味倾向。PSC被证实能帮助开发者更好地解释模型行为和评估生成代码的质量。

Conclusion: PSC作为一种结构质量衡量指标对评估和部署LLM生成代码具有重要作用，有助于将质量感知评估集成到LLM研发和实际应用中，为提升自动化编程工具的实用价值提供了基础。

Abstract: Recent advances in large language models (LLMs) have accelerated their adoption in software engineering contexts. However, concerns persist about the structural quality of the code they produce. In particular, LLMs often replicate poor coding practices, introducing code smells (i.e., patterns that hinder readability, maintainability, or design integrity). Although prior research has examined the detection or repair of smells, we still lack a clear understanding of how and when these issues emerge in generated code.
  This paper addresses this gap by systematically measuring, explaining and mitigating smell propensity in LLM-generated code. We build on the Propensity Smelly Score (PSC), a probabilistic metric that estimates the likelihood of generating particular smell types, and establish its robustness as a signal of structural quality. Using PSC as an instrument for causal analysis, we identify how generation strategy, model size, model architecture and prompt formulation shape the structural properties of generated code. Our findings show that prompt design and architectural choices play a decisive role in smell propensity and motivate practical mitigation strategies that reduce its occurrence. A user study further demonstrates that PSC helps developers interpret model behavior and assess code quality, providing evidence that smell propensity signals can support human judgement. Taken together, our work lays the groundwork for integrating quality-aware assessments into the evaluation and deployment of LLMs for code.

</details>


### [8] [AI-Enabled Orchestration of Event-Driven Business Processes in Workday ERP for Healthcare Enterprises](https://arxiv.org/abs/2511.15852)
*Monu Sharma*

Main category: cs.SE

TL;DR: 该研究提出并验证了一种AI增强的事件驱动ERP架构，通过智能算法提升了医疗行业的业务协同能力和自动化水平，显著改善了效率和决策。


<details>
  <summary>Details</summary>
Motivation: 现有ERP系统的传统工作流逻辑难以应对医疗环境中的事件驱动和数据密集的需求，亟需更智能、可适应的流程管理方式。

Method: 提出一种AI赋能的事件驱动调度框架，通过机器学习触发器、异常检测和流程挖掘分析来协同财务与供应链操作，并以多组织案例分析验证。

Result: 多组织案例分析显示流程效率、成本可见性和决策准确性均有显著提升。

Conclusion: 将AI能力嵌入Workday等云ERP的事件驱动架构，可提升医疗企业的运营韧性、治理和可扩展性。该模型为智能ERP集成和下一代自动化战略提供了参考。

Abstract: The adoption of cloud-based Enterprise Resource Planning (ERP) platforms such as Workday has transformed healthcare operations by integrating financial, supply-chain, and workforce processes into a unified ecosystem. However, traditional workflow logic in ERP systems often lacks the adaptability required to manage event-driven and data-intensive healthcare environments.
  This study proposes an AI-enabled event-driven orchestration framework within Workday ERP that intelligently synchronizes financial and supply-chain workflows across distributed healthcare entities. The framework employs machine-learning triggers, anomaly detection, and process mining analytics to anticipate and automate responses to operational events such as inventory depletion, payment delays, or patient demand fluctuations. A multi-organization case analysis demonstrates measurable gains in process efficiency, cost visibility, and decision accuracy.
  Results confirm that embedding AI capabilities into Workday's event-based architecture enhances operational resilience, governance, and scalability. The proposed model contributes to the broader understanding of intelligent ERP integration and establishes a reference for next-generation automation strategies in healthcare enterprises.

</details>


### [9] [RE for AI in Practice: Managing Data Annotation Requirements for AI Autonomous Driving Systems](https://arxiv.org/abs/2511.15859)
*Hina Saeeda,Mazen Mohamad,Eric Knauss,Jennifer Horkoff,Ali Nouri*

Main category: cs.SE

TL;DR: 本论文通过行业与学界访谈，系统分析了自动驾驶AI系统数据标注需求的定义、挑战与改进建议，总结五大挑战和三类最佳实践，并首次以实证方式给出提升标注需求质量和可靠性的具体指导，对AI需求工程领域具有重要推动作用。


<details>
  <summary>Details</summary>
Motivation: 高质量数据标注需求对自动驾驶AI系统的安全和可靠性至关重要，但其制定和管理仍缺乏深入研究，易导致不一致性、安全风险及合规问题。

Method: 采用定性研究方法，通过19次半结构化访谈，涉及六家国际公司及四家研究机构，结合主题分析揭示关键挑战与最佳实践。

Result: 发现了标注需求定义与实践中的五大挑战：模糊性、边界例复杂性、需求演化、不一致性和资源受限；总结了三大最佳实践：规范合规、完善标注需求指南及嵌入式质量保证。揭示了标注需求与实践、数据质量及系统性能之间的关键关联，以及需求缺陷如何影响整个系统开发流程。

Conclusion: 该研究首次为改进数据标注需求提供了实证性的指导，提出可操作性建议以提高标注质量、合规性及系统可靠性，并填补了人工智能领域需求工程的研究空白。

Abstract: High-quality data annotation requirements are crucial for the development of safe and reliable AI-enabled perception systems (AIePS) in autonomous driving. Although these requirements play a vital role in reducing bias and enhancing performance, their formulation and management remain underexplored, leading to inconsistencies, safety risks, and regulatory concerns. Our study investigates how annotation requirements are defined and used in practice, the challenges in ensuring their quality, practitioner-recommended improvements, and their impact on AIePS development and performance. We conducted $19$ semi-structured interviews with participants from six international companies and four research organisations. Our thematic analysis reveals five main key challenges: ambiguity, edge case complexity, evolving requirements, inconsistencies, and resource constraints and three main categories of best practices, including ensuring compliance with ethical standards, improving data annotation requirements guidelines, and embedded quality assurance for data annotation requirements. We also uncover critical interrelationships between annotation requirements, annotation practices, annotated data quality, and AIePS performance and development, showing how requirement flaws propagate through the AIePS development pipeline. To the best of our knowledge, this study is the first to offer empirically grounded guidance on improving annotation requirements, offering actionable insights to enhance annotation quality, regulatory compliance, and system reliability. It also contributes to the emerging fields of Software Engineering (SE for AI) and Requirements Engineering (RE for AI) by bridging the gap between RE and AI in a timely and much-needed manner.

</details>


### [10] [InfCode: Adversarial Iterative Refinement of Tests and Patches for Reliable Software Issue Resolution](https://arxiv.org/abs/2511.16004)
*KeFan Li,Mengfei Wang,Hengzhi Zhang,Zhichao Li,Yuan Yuan,Mu Li,Xiang Gao,Hailong Sun,Chunming Hu,Weifeng Lv*

Main category: cs.SE

TL;DR: InfCode创新性地通过多智能体对抗与选择，改进了自动化代码修复测试流程，在公开基准上表现领先，并已面向社区开源。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型推动了软件工程自动化，但真实世界的软件问题处理仍面临挑战，因为它需要仓库级推理、准确诊断和强验证信号。现有方法多依赖于不充分的测试，导致补丁表面通过验证实际却未修复缺陷。

Method: 提出InfCode，一种对抗性多智能体框架，通过测试补丁生成器与代码补丁生成器进行对抗交互，迭代优化测试与补丁，且有选择器智能体选出最可靠修复。框架在容器化环境下运行，支持真实仓库检查、修改和验证。

Result: 在SWE-bench Lite和SWE-bench Verified基准测试上，InfCode与DeepSeek-V3和Claude 4.5 Sonnet等模型结合，都优于强基线方法。在SWE-bench Verified上性能达79.4%，创下新纪录。

Conclusion: InfCode显著提升了自动仓库级问题解决的性能，为软件工程自动化提供高效可靠的新方法。项目已开源。

Abstract: Large language models have advanced software engineering automation, yet resolving real-world software issues remains difficult because it requires repository-level reasoning, accurate diagnostics, and strong verification signals. Existing agent-based and pipeline-based methods often rely on insufficient tests, which can lead to patches that satisfy verification but fail to fix the underlying defect. We present InfCode, an adversarial multi-agent framework for automated repository-level issue resolution. InfCode iteratively refines both tests and patches through adversarial interaction between a Test Patch Generator and a Code Patch Generator, while a Selector agent identifies the most reliable fix. The framework runs inside a containerized environment that supports realistic repository inspection, modification, and validation. Experiments on SWE-bench Lite and SWE-bench Verified using models such as DeepSeek-V3 and Claude 4.5 Sonnet show that InfCode consistently outperforms strong baselines. It achieves 79.4% performance on SWE-bench Verified, establishing a new state-of-the-art. We have released InfCode as an open-source project at https://github.com/Tokfinity/InfCode.

</details>


### [11] [InfCode-C++: Intent-Guided Semantic Retrieval and AST-Structured Search for C++ Issue Resolution](https://arxiv.org/abs/2511.16005)
*Qingao Dong,Mengfei Wang,Hengzhi Zhang,Zhichao Li,Yuan Yuan,Mu Li,Xiang Gao,Hailong Sun,Chunming Hu,Weifeng Lv*

Main category: cs.SE

TL;DR: 现有LLM自动代码修复主要支持Python，面对C++时效果极差。本文提出结合语义与AST结构检索的INFCODE-C++系统，在C++专属基准上大幅提升修复率，树立了针对复杂静态类型语言的自动化修复新方向。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型（LLM）的代码自动修复主要针对Python，且依赖词法检索和浅层代码导航，但这些方法在面对C++等复杂、静态类型强、语法嵌套深的语言时，效果骤降。尤其是在MultiSWE-bench的数据集上，现有针对Python的系统在C++上的表现不佳，亟需更适合C++的解决方案。

Method: 提出了INFCODE-C++，一个首个面向C++的自治端到端问题修复系统。该系统结合了语义代码意图检索和基于抽象语法树（AST）的结构化查询，两种互补的检索机制，能够为代码修复构建准确、语言相关的上下文，提高错误定位和补丁合成的能力。

Result: 在MultiSWE-bench-CPP基准上，INFCODE-C++实现了25.58%的问题解决率，比最强的先前代理高出10.85个百分点，是MSWE-agent性能的两倍以上。消融实验和行为研究进一步验证了系统中语义检索、结构分析和代码准确复现的重要性。

Conclusion: INFCODE-C++展示了针对C++这类复杂、静态类型语言进行语言感知推理的必要性，并为后续在复杂代码生态下基于LLM的自动修复研究奠定了基础。

Abstract: Large language model (LLM) agents have recently shown strong performance on repository-level issue resolution, but existing systems are almost exclusively designed for Python and rely heavily on lexical retrieval and shallow code navigation. These approaches transfer poorly to C++ projects, where overloaded identifiers, nested namespaces, template instantiations, and deep control-flow structures make context retrieval and fault localization substantially more difficult. As a result, state-of-the-art Python-oriented agents show a drastic performance drop on the C++ subset of MultiSWE-bench. We introduce INFCODE-C++, the first C++-aware autonomous system for end-to-end issue resolution. The system combines two complementary retrieval mechanisms -- semantic code-intent retrieval and deterministic AST-structured querying -- to construct accurate, language-aware context for repair.These components enable precise localization and robust patch synthesis in large, statically typed C++ repositories. Evaluated on the \texttt{MultiSWE-bench-CPP} benchmark, INFCODE-C++ achieves a resolution rate of 25.58\%, outperforming the strongest prior agent by 10.85 percentage points and more than doubling the performance of MSWE-agent. Ablation and behavioral studies further demonstrate the critical role of semantic retrieval, structural analysis, and accurate reproduction in C++ issue resolution. INFCODE-C++ highlights the need for language-aware reasoning in multi-language software agents and establishes a foundation for future research on scalable, LLM-driven repair for complex, statically typed ecosystems.

</details>


### [12] [The Future of Development Environments with AI Foundation Models: NII Shonan Meeting 222 Report](https://arxiv.org/abs/2511.16092)
*Xing Hu,Raula Gaikovina Kula,Christoph Treude*

Main category: cs.SE

TL;DR: 通过专家研讨，总结了GenAI对集成开发环境变革的挑战与机遇，并展望了未来发展。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能（GenAI）在诸如代码生成、测试、代码审查和程序修复等方面取得了显著进展，但其对集成开发环境（IDE）中人机交互的影响尚不明确。

Method: 召集了来自软件工程、人工智能和人机交互领域的33位专家，在一次专题会议（Shonan Meeting 222）上共同讨论GenAI对IDE的挑战与机遇。

Result: 本论文（报告）总结了专家讨论的主要观点，指出了GenAI为IDE带来的变革、现存问题及未来发展方向。

Conclusion: GenAI将提升开发任务抽象层次，有望改变IDE中的人机交互模式，但需关注相关挑战，如技术集成、用户体验和工程实践的适应。

Abstract: Generative Artificial Intelligence (GenAI) models are achieving remarkable performance in various tasks, including code generation, testing, code review, and program repair. The ability to increase the level of abstraction away from writing code has the potential to change the Human-AI interaction within the integrated development environment (IDE). To explore the impact of GenAI on IDEs, 33 experts from the Software Engineering, Artificial Intelligence, and Human-Computer Interaction domains gathered to discuss challenges and opportunities at Shonan Meeting 222. This is the report

</details>


### [13] [Domain-constrained Synthesis of Inconsistent Key Aspects in Textual Vulnerability Descriptions](https://arxiv.org/abs/2511.16123)
*Linyi Han,Shidong Pan,Zhenchang Xing,Sofonias Yitagesu,Xiaowang Zhang,Zhiyong Feng,Jiamou Sun,Qing Huang*

Main category: cs.SE

TL;DR: 针对漏洞描述信息不一致问题，本文提出LLM驱动的三阶段统一与增强方法，显著提升覆盖率、理解与使用效率，并开发实用可视化工具。


<details>
  <summary>Details</summary>
Motivation: 现有安全漏洞文本描述在不同数据仓库间存在关键信息不一致，影响漏洞理解与应对；以往方案信息损失严重，难以获得全面统一表达。

Method: 该方法采用基于LLM的三阶段框架：1)利用规则模板抽取关键细节；2)使用领域锚词自评语义变化；3)借助信息熵融合并优先相关细节。

Result: 框架使F1分数从0.82提升到0.87，综合理解与效率提高30%以上，并通过Digest Labels工具显著增强可用性。

Conclusion: 提出的框架能够有效统一不同来源的漏洞描述关键信息，并提升信息理解与处理效率。

Abstract: Textual Vulnerability Descriptions (TVDs) are crucial for security analysts to understand and address software vulnerabilities. However, the key aspect inconsistencies in TVDs from different repositories pose challenges for achieving a comprehensive understanding of vulnerabilities. Existing approaches aim to mitigate inconsistencies by aligning TVDs with external knowledge bases, but they often discard valuable information and fail to synthesize comprehensive representations. In this paper, we propose a domain-constrained LLM-based synthesis framework for unifying key aspects of TVDs. Our framework consists of three stages: 1) Extraction, guided by rule-based templates to ensure all critical details are captured; 2) Self-evaluation, using domain-specific anchor words to assess semantic variability across sources; and 3) Fusion, leveraging information entropy to reconcile inconsistencies and prioritize relevant details. This framework improves synthesis performance, increasing the F1 score for key aspect augmentation from 0.82 to 0.87, while enhancing comprehension and efficiency by over 30\%. We further develop Digest Labels, a practical tool for visualizing TVDs, which human evaluations show significantly boosts usability.

</details>


### [14] [Beyond Code Similarity: Benchmarking the Plausibility, Efficiency, and Complexity of LLM-Generated Smart Contracts](https://arxiv.org/abs/2511.16224)
*Francesco Salzano,Simone Scalabrino,Rocco Oliveto,Simone Scalabrino*

Main category: cs.SE

TL;DR: 大语言模型生成的Solidity智能合约在语义相似度上表现良好，但功能正确率较低，检索增强方法可提升性能，然而生成高质量、可生产的智能合约仍存在重大挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）在一般代码生成方面表现优异，但智能合约代码具有诸如gas消耗、安全性和确定性等特殊约束，目前相关研究尚缺乏对这些关键功能性和非功能性属性的全面评估。

Method: 本研究在零样本和检索增强生成（RAG）两种设置下，对4个最先进模型生成的500个真实智能合约函数进行了基准测试。采用多维度评估，包括代码相似度、语义嵌入、自动化测试、gas消耗分析以及认知和圈复杂度分析。

Result: 结果显示，LLMs生成的代码虽然语义相似度高，但功能正确率低，只有20%到26%的零样本生成代码在测试中与真实实现的行为一致。生成代码普遍更简单，复杂度和gas消耗更低，但常因省略验证逻辑。RAG方法显著提升表现，功能正确率提升至45%，生成代码更简洁高效。

Conclusion: 尽管检索增强生成有效提升了LLM生成智能合约的质量，但与真实代码相比仍存在较大差距，实现真正稳健、生产级代码生成仍需大量专家验证与改进。

Abstract: Smart Contracts are critical components of blockchain ecosystems, with Solidity as the dominant programming language. While LLMs excel at general-purpose code generation, the unique constraints of Smart Contracts, such as gas consumption, security, and determinism, raise open questions about the reliability of LLM-generated Solidity code. Existing studies lack a comprehensive evaluation of these critical functional and non-functional properties. We benchmark four state-of-the-art models under zero-shot and retrieval-augmented generation settings across 500 real-world functions. Our multi-faceted assessment employs code similarity metrics, semantic embeddings, automated test execution, gas profiling, and cognitive and cyclomatic complexity analysis. Results show that while LLMs produce code with high semantic similarity to real contracts, their functional correctness is low: only 20% to 26% of zero-shot generations behave identically to ground-truth implementations under testing. The generated code is consistently simpler, with significantly lower complexity and gas consumption, often due to omitted validation logic. Retrieval-Augmented Generation markedly improves performance, boosting functional correctness by up to 45% and yielding more concise and efficient code. Our findings reveal a significant gap between semantic similarity and functional plausibility in LLM-generated Smart Contracts. We conclude that while RAG is a powerful enhancer, achieving robust, production-ready code generation remains a substantial challenge, necessitating careful expert validation.

</details>


### [15] [Data Annotation Quality Problems in AI-Enabled Perception System Development](https://arxiv.org/abs/2511.16410)
*Hina Saeeda,Tommy Johansson,Mazen Mohamad,Eric Knauss*

Main category: cs.SE

TL;DR: 本文通过欧洲与英国的多家公司和研究机构，分析自动驾驶数据标注常见的18类错误，总结成分类法，并在业界验证其实用性，为AI感知系统构建提供质量改进工具和共享术语。


<details>
  <summary>Details</summary>
Motivation: 尽管数据标注质量对自动驾驶AI感知系统的性能、安全和可靠性至关重要，但工业界对注释错误如何在多组织汽车供应链中产生和传播缺乏实证理解。

Method: 采用多组织案例研究方法，涵盖6家企业和4个研究机构，通过19次半结构化访谈(20位专家，50小时访谈记录)及六阶段主题分析法，归纳出数据标注常见错误类型，并与业界从业者共同验证其实用性。

Result: 提出了跨越三个数据质量维度（完整性、准确性、一致性）的18类注释错误类型分类法，并被业界认可其工具价值和可操作性。

Conclusion: 该研究提出了一个涵盖18种注释错误类型的分类法，并获得业界从业者的认可，证明其对根本原因分析、供应商质量评估、人员培训和改进注释准则具有实践意义。该成果为建立可信赖的AI感知系统提供了共享的术语体系和诊断工具。

Abstract: Data annotation is essential but highly error-prone in the development of AI-enabled perception systems (AIePS) for automated driving, and its quality directly influences model performance, safety, and reliability. However, the industry lacks empirical insights into how annotation errors emerge and spread across the multi-organisational automotive supply chain. This study addresses this gap through a multi-organisation case study involving six companies and four research institutes across Europe and the UK. Based on 19 semi-structured interviews with 20 experts (50 hours of transcripts) and a six-phase thematic analysis, we develop a taxonomy of 18 recurring annotation error types across three data-quality dimensions: completeness (e.g., attribute omission, missing feedback loops, edge-case omissions, selection bias), accuracy (e.g., mislabelling, bounding-box inaccuracies, granularity mismatches, bias-driven errors), and consistency (e.g., inter-annotator disagreement, ambiguous instructions, misaligned hand-offs, cross-modality inconsistencies). The taxonomy was validated with industry practitioners, who reported its usefulness for root-cause analysis, supplier quality reviews, onboarding, and improving annotation guidelines. They described it as a failure-mode catalogue similar to FMEA. By conceptualising annotation quality as a lifecycle and supply-chain issue, this study contributes to SE4AI by offering a shared vocabulary, diagnostic toolset, and actionable guidance for building trustworthy AI-enabled perception systems.

</details>


### [16] [Green Resilience of Cyber-Physical Systems: Doctoral Dissertation](https://arxiv.org/abs/2511.16593)
*Diaeddin Rimawi*

Main category: cs.SE

TL;DR: 本文针对在线协作人工智能系统的韧性与绿色性平衡问题，提出状态建模、GResilience多策略恢复框架和度量方法，实证分析显示策略有效提升系统恢复同时控制能耗，且容器化部署有助于减排。


<details>
  <summary>Details</summary>
Motivation: 在线协作人工智能系统（OL-CAIS）在与人类协作并实现目标的过程中易受干扰性事件影响，从而降低系统性能。决策者需要在恢复系统性能与控制能耗（绿色性）之间做权衡，因此需要解决系统韧性与绿色性之间的平衡问题。

Method: 论文提出了三种工作状态模型（稳定、受扰、最终），并建立了GResilience恢复框架，基于多目标优化（一代理）、博弈论（两代理）及强化学习（RL代理）开发恢复策略，同时设计度量框架来量化韧性与绿色性。

Result: 实证结果表明韧性建模能够捕捉扰动引发的性能转变，GResilience策略可提升绿色恢复能力——缩短恢复时长、稳定性能、减少人类依赖。RL代理策略效果最好，但CO2排放略有增加。多次扰动下出现灾难性遗忘，但策略有助于保持系统稳定。容器化部署可将CO2排放减半。

Conclusion: 本研究构建了可量化OL-CAIS韧性与绿色性的模型、指标及策略，提出了实现绿色恢复的解决方案。

Abstract: Cyber-physical systems (CPS) combine computational and physical components. Online Collaborative AI System (OL-CAIS) is a type of CPS that learn online in collaboration with humans to achieve a common goal, which makes it vulnerable to disruptive events that degrade performance. Decision-makers must therefore restore performance while limiting energy impact, creating a trade-off between resilience and greenness. This research addresses how to balance these two properties in OL-CAIS. It aims to model resilience for automatic state detection, develop agent-based policies that optimize the greenness-resilience trade-off, and understand catastrophic forgetting to maintain performance consistency. We model OL-CAIS behavior through three operational states: steady, disruptive, and final. To support recovery during disruptions, we introduce the GResilience framework, which provides recovery strategies through multi-objective optimization (one-agent), game-theoretic decision-making (two-agent), and reinforcement learning (RL-agent). We also design a measurement framework to quantify resilience and greenness. Empirical evaluation uses real and simulated experiments with a collaborative robot learning object classification from human demonstrations. Results show that the resilience model captures performance transitions during disruptions, and that GResilience policies improve green recovery by shortening recovery time, stabilizing performance, and reducing human dependency. RL-agent policies achieve the strongest results, although with a marginal increase in CO2 emissions. We also observe catastrophic forgetting after repeated disruptions, while our policies help maintain steadiness. A comparison with containerized execution shows that containerization cuts CO2 emissions by half. Overall, this research provides models, metrics, and policies that ensure the green recovery of OL-CAIS.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [17] [Synthesis of Safety Specifications for Probabilistic Systems](https://arxiv.org/abs/2511.16579)
*Gaspard Ohlmann,Edwin Hamel-De le Court,Francesco Belardinelli*

Main category: cs.LO

TL;DR: 本文提出了支持更丰富PCTL安全时序属性的控制器合成理论及算法，扩展了现有方法的表达力，并严谨证明了解决方案的有效性与完备性。


<details>
  <summary>Details</summary>
Motivation: 在安全关键环境下，确保智能体满足安全规范非常重要。现有方法多为基于概率规避约束，难以表达更通用和复杂的安全性时序规定。因此，需要一种支持更丰富安全时序属性、能表达为PCTL逻辑的方法。

Method: 1. 提出一个支持以PCTL表达更一般性安全时序属性的形式化理论框架，定义了CPCTL（safe-PCTL片段）并将全局规范满足问题分解为局部约束。2. 基于此理论，提出了新的值迭代（Value Iteration）算法，用于求解该类综合问题，并证明其有效性和完备性。

Result: 理论上构建了CPCTL安全规范的综合框架，将复杂时序属性归约为可管理的子问题；在算法层面，提出了适用于这些属性的值迭代方法，并严格证明了其正确性和完备性。

Conclusion: 该论文实现了比现有方法更具表达力的时序安全规范综合，能够形式化并合成满足更复杂PCTL属性要求的安全控制器。通过理论和算法创新，为安全关键系统智能体的安全规范合成提供了新的解决方案。

Abstract: Ensuring that agents satisfy safety specifications can be crucial in safety-critical environments. While methods exist for controller synthesis with safe temporal specifications, most existing methods restrict safe temporal specifications to probabilistic-avoidance constraints. Formal methods typically offer more expressive ways to express safety in probabilistic systems, such as Probabilistic Computation Tree Logic (PCTL) formulas. Thus, in this paper, we develop a new approach that supports more general temporal properties expressed in PCTL. Our contribution is twofold. First, we develop a theoretical framework for the Synthesis of safe-PCTL specifications. We show how the reducing global specification satisfaction to local constraints, and define CPCTL, a fragment of safe-PCTL. We demonstrate how the expressiveness of CPCTL makes it a relevant fragment for the Synthesis Problem. Second, we leverage these results and propose a new Value Iteration-based algorithm to solve the synthesis problem for these more general temporal properties, and we prove the soundness and completeness of our method.

</details>


### [18] [Faster Certified Symmetry Breaking Using Orders With Auxiliary Variables](https://arxiv.org/abs/2511.16637)
*Markus Anders,Bart Bogaerts,Benjamin Bogø,Arthur Gontier,Wietze Koops,Ciaran McCreesh,Magnus O. Myreen,Jakob Nordström,Andy Oertel,Adrian Rebola-Pardo,Yong Kiam Tan*

Main category: cs.LO

TL;DR: 论文提出用辅助变量编码代替大整数编码字典序，极大提升了SAT对称性打破证明效率，在实际工具链中获得显著加速。


<details>
  <summary>Details</summary>
Motivation: 在组合问题求解中，对称性打破技术非常重要，但其正确实现非常困难。目前主流方法是让求解器输出解及其正确性的数学证明，以便通过经过形式验证的检查器进行验证。关键挑战在于如何高效地在证明中合理引入对称性推理。

Method: 相比于之前用大整数编码字典序的新通用方法，本研究提出利用辅助变量来编码顺序，从而优化对称性打破证明过程。

Result: 理论和实验均显示，该方法在证明记录和检查方面实现了数量级的加速。实验包括在SAT对称性打破场景下，结合satsuma对称性打破工具和VeriPB证明检查工具链。

Conclusion: 辅助变量编码顺序显著提升了对称性打破证明的效率，是解决相关领域验证难题的有力手段。

Abstract: Symmetry breaking is a crucial technique in modern combinatorial solving, but it is difficult to be sure it is implemented correctly. The most successful approach to deal with bugs is to make solvers certifying, so that they output not just a solution, but also a mathematical proof of correctness in a standard format, which can then be checked by a formally verified checker. This requires justifying symmetry reasoning within the proof, but developing efficient methods for this has remained a long-standing open challenge. A fully general approach was recently proposed by Bogaerts et al. (2023), but it relies on encoding lexicographic orders with big integers, which quickly becomes infeasible for large symmetries. In this work, we develop a method for instead encoding orders with auxiliary variables. We show that this leads to orders-of-magnitude speed-ups in both theory and practice by running experiments on proof logging and checking for SAT symmetry breaking using the state-of-the-art satsuma symmetry breaker and the VeriPB proof checking toolchain.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [19] [What Really Counts? Examining Step and Token Level Attribution in Multilingual CoT Reasoning](https://arxiv.org/abs/2511.15886)
*Jeremias Ferrao,Ezgi Basar,Khondoker Ittehadul Islam,Mahrokh Hassani*

Main category: cs.CL

TL;DR: 本研究分析了多语种LLM中CoT推理的归因模式，发现归因易偏向最后一步，对高资源语言效果较好，但面对语言扰动表现较差，显示CoT提示的多语种鲁棒性和可解释性有限。


<details>
  <summary>Details</summary>
Motivation: 尽管CoT提示可提升任务表现，但其推理链条的忠实性和可解释性令人担忧，特别是在多语种任务下效果不明确。

Method: 应用ContextCite进行步骤级归因和Inseq进行标记级归因，分析Qwen2.5 1.5B-Instruct模型在MGSM数据集上的推理过程。

Result: 1）归因分数过度聚焦最后一步推理，尤其是在错误样本中；2）结构化CoT提示显著提升高资源拉丁语系语言的准确率；3）通过否定和干扰句子扰动，模型准确率和归因连贯性均下降。

Conclusion: CoT prompting在多语种环境中的表现存在局限，尤其在模型解释性与不同语言鲁棒性方面。

Abstract: This study investigates the attribution patterns underlying Chain-of-Thought (CoT) reasoning in multilingual LLMs. While prior works demonstrate the role of CoT prompting in improving task performance, there are concerns regarding the faithfulness and interpretability of the generated reasoning chains. To assess these properties across languages, we applied two complementary attribution methods--ContextCite for step-level attribution and Inseq for token-level attribution--to the Qwen2.5 1.5B-Instruct model using the MGSM benchmark. Our experimental results highlight key findings such as: (1) attribution scores excessively emphasize the final reasoning step, particularly in incorrect generations; (2) structured CoT prompting significantly improves accuracy primarily for high-resource Latin-script languages; and (3) controlled perturbations via negation and distractor sentences reduce model accuracy and attribution coherence. These findings highlight the limitations of CoT prompting, particularly in terms of multilingual robustness and interpretive transparency.

</details>


### [20] [Mind the Motions: Benchmarking Theory-of-Mind in Everyday Body Language](https://arxiv.org/abs/2511.15887)
*Seungbeen Lee,Jinhong Jeong,Donghyun Kim,Yejin Son,Youngjae Yu*

Main category: cs.CL

TL;DR: 提出了Motion2Mind大规模非言语线索-心智状态数据集和评测框架，揭示了当前AI在非言语心理解读方面与人类有显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有理论心智（ToM）基准主要集中在虚假信念任务和非对称信息推理，忽略了除信念以外的其他心理状态以及人类丰富的非言语交流，因此需要拓展AI在非言语线索解读能力的评测框架。

Method: 提出了Motion2Mind框架。该框架利用专家整理的身体语言参考作为知识库，制作了含有细致非言语线索标注和心理解释的视频数据集。数据集涵盖222种非言语线索和397类心理状态。

Result: 评估结果显示，当前AI系统在非言语线索识别（Detection）上与人类有较大性能差距，并在心理解释（Explanation）环节表现出过度解释现象。

Conclusion: 当前AI在通过非言语线索解读他人心理方面依然存在显著不足。因此，Motion2Mind为未来提升AI社会智能和心智建模能力提供了重要的基准和方向。

Abstract: Our ability to interpret others' mental states through nonverbal cues (NVCs) is fundamental to our survival and social cohesion. While existing Theory of Mind (ToM) benchmarks have primarily focused on false-belief tasks and reasoning with asymmetric information, they overlook other mental states beyond belief and the rich tapestry of human nonverbal communication. We present Motion2Mind, a framework for evaluating the ToM capabilities of machines in interpreting NVCs. Leveraging an expert-curated body-language reference as a proxy knowledge base, we build Motion2Mind, a carefully curated video dataset with fine-grained nonverbal cue annotations paired with manually verified psychological interpretations. It encompasses 222 types of nonverbal cues and 397 mind states. Our evaluation reveals that current AI systems struggle significantly with NVC interpretation, exhibiting not only a substantial performance gap in Detection, as well as patterns of over-interpretation in Explanation compared to human annotators.

</details>


### [21] [TOD-ProcBench: Benchmarking Complex Instruction-Following in Task-Oriented Dialogues](https://arxiv.org/abs/2511.15976)
*Sarik Ghazarian,Abhinav Gullapalli,Swair Shah,Anurag Beniwal,Nanyun Peng,Narayanan Sadagopan,Zhou Yu*

Main category: cs.CL

TL;DR: 该论文提出用于测评大模型遵循复杂对话指令的新数据集TOD-ProcBench，包含丰富、多层次的复杂约束和任务。作者设计了三项任务对模型的理解和执行力进行全面检验，并从多语言和格式等多个维度分析模型表现，显著提升了对任务型对话场景的真实评测能力。


<details>
  <summary>Details</summary>
Motivation: 现实中的任务型对话往往涉及复杂、多层次的自然语言指令，但现有LLM评测基准对指令复杂性和执行约束考虑不足，不能有效反映模型真实应用能力，因此急需更严苛且贴近实际场景的评测方案。

Method: 从ABCD高质量数据集中提取指令文档，并配有人类质量控制对话。设计了三项任务：1）检索相关指令并预测行动；2）制造违反指令的响应并分析识别能力；3）基于复杂条件进行合规响应生成。同时考察多语言及指令格式对模型表现的影响。

Result: TOD-ProcBench能更精细地揭示LLM在复杂指令下的理解和执行能力。通过三项细化任务对模型表现进行全面评估，并考虑多语言和不同格式因素，为未来模型优化和现实应用提供重要参考。

Conclusion: 提出了TOD-ProcBench，一个专门用于评测LLM处理复杂任务型对话指令能力的新基准。实验证明，该数据集能有效衡量LLM在多轮复杂指令遵循任务中的表现，对比现有基准展现出更高挑战性与实用性。

Abstract: In real-world task-oriented dialogue (TOD) settings, agents are required to strictly adhere to complex instructions while conducting multi-turn conversations with customers. These instructions are typically presented in natural language format and include general guidelines and step-by-step procedures with complex constraints. Existing TOD benchmarks often oversimplify the complex nature of these instructions by reducing them to simple schemas composed of intents, slots, and API call configurations. To address this gap and systematically benchmark LLMs' instruction-following capabilities, we propose TOD-ProcBench, a challenging benchmark featuring complex process instructions with intricate, fine-grained constraints that evaluates various LLMs' abilities to understand and follow instructions in multi-turn TODs. Our benchmark dataset comprises instruction documents derived from the high-quality ABCD dataset with corresponding conversations under human quality control. We formulate fine-grained constraints and action procedures as multi-level condition-action instruction statements. We design three tasks to comprehensively benchmark LLMs' complex instruction-following capabilities in multi-turn TODs. Task 1 evaluates how LLMs retrieve the most relevant statement from a complex instruction and predict the corresponding next action. In Task 2, we synthesize instruction-violating responses by injecting inconsistencies and manipulating the original instructions, and then we analyze how effectively LLMs can identify instruction-violating responses. Task 3 investigates LLMs' abilities in conditional generation of instruction-following responses based on the original complex instructions. Additionally, we conduct studies on the impact of multilingual settings and different instruction text formats on compliance performance. We release our benchmark under the Llama 3.3 Community License Agreement.

</details>


### [22] [Liars' Bench: Evaluating Lie Detectors for Language Models](https://arxiv.org/abs/2511.16035)
*Kieron Kretschmar,Walter Laurito,Sharan Maiya,Samuel Marks*

Main category: cs.CL

TL;DR: 本文提出涵盖多类谎言的大规模LLM谎言检测测试集LIARS' BENCH，发现现有方法难以识别多样化谎言，测试集可促进检测方法进步。


<details>
  <summary>Details</summary>
Motivation: 以往针对大语言模型生成谎言（模型明知为假却仍生成的陈述）的检测技术多在狭窄场景验证，无法涵盖LLM可生成的多样谎言。

Method: 作者提出了LIARS' BENCH测试集，包含72,863个由4个开源模型在7个数据集上生成的谎言与真实响应，用以系统覆盖不同类型的谎言（包括谎言动机和针对对象）。并用三种主流谎言检测技术（黑盒、白盒）在该测试集上测试。

Result: 现有主流检测技术在LIARS' BENCH上普遍对某些类型谎言检测效果较差，尤其是无法仅从对话文本判断是否说谎时表现低下。

Conclusion: LIARS' BENCH暴露了以往谎言检测方法的局限，并为后续相关技术研究提供了标准化、实用的评测基准。

Abstract: Prior work has introduced techniques for detecting when large language models (LLMs) lie, that is, generating statements they believe are false. However, these techniques are typically validated in narrow settings that do not capture the diverse lies LLMs can generate. We introduce LIARS' BENCH, a testbed consisting of 72,863 examples of lies and honest responses generated by four open-weight models across seven datasets. Our settings capture qualitatively different types of lies and vary along two dimensions: the model's reason for lying and the object of belief targeted by the lie. Evaluating three black- and white-box lie detection techniques on LIARS' BENCH, we find that existing techniques systematically fail to identify certain types of lies, especially in settings where it's not possible to determine whether the model lied from the transcript alone. Overall, LIARS' BENCH reveals limitations in prior techniques and provides a practical testbed for guiding progress in lie detection.

</details>


### [23] [Learning Tractable Distributions Of Language Model Continuations](https://arxiv.org/abs/2511.16054)
*Gwen Yidou-Weng,Ian Li,Anji Liu,Oliver Broadrick,Guy Van den Broeck,Benjie Wang*

Main category: cs.CL

TL;DR: LTLA结合强语言模型和高效代理模型，提升了受控文本生成的上下文感知与约束满足率，效率高、泛用性强。


<details>
  <summary>Details</summary>
Motivation: 当前受控文本生成需要对文本进行序列级约束（例如句法、风格、安全性），而这些约束有时依赖于未来的词元，导致直接在自回归语言模型中进行约束极难处理。以往的方法（如HMM）尽管可行，但上下文感知能力较弱，影响生成质量。

Method: 提出了一种“Learning to Look Ahead（LTLA）”的混合方法，将基础强大的语言模型用于丰富的前缀编码，再配合固定且可处理的代理模型（如HMM）来计算精确的续写概率。LTLA通过批量处理HMM更新避免了每步遍历全词表的问题，并仅用语言模型的隐藏状态对HMM的潜在状态先验进行条件化，同时保持HMM解码器固定，使得不同前缀间的计算可重复利用，提升了效率。

Result: LTLA方法在受控文本生成任务中，在保证流畅度的同时大幅提升了约束满足率，并且只有极小的推理开销。相比于无条件HMM，其条件概率更高，并能在视觉-语言模型下近似更复杂的续写分布。

Conclusion: LTLA有效提升了受控生成任务中的上下文感知能力及约束满足率，同时保持了推理效率，拓展了代理模型在多模态（如视觉-语言）任务中的适用性。

Abstract: Controlled language generation conditions text on sequence-level constraints (for example, syntax, style, or safety). These constraints may depend on future tokens, which makes directly conditioning an autoregressive language model (LM) generally intractable. Prior work uses tractable surrogates such as hidden Markov models (HMMs) to approximate the distribution over continuations and adjust the model's next-token logits at decoding time. However, we find that these surrogates are often weakly context aware, which reduces query quality. We propose Learning to Look Ahead (LTLA), a hybrid approach that pairs the same base language model for rich prefix encoding with a fixed tractable surrogate model that computes exact continuation probabilities. Two efficiency pitfalls arise when adding neural context: (i) naively rescoring the prefix with every candidate next token requires a sweep over the entire vocabulary at each step, and (ii) predicting fresh surrogate parameters for each prefix, although tractable at a single step, forces recomputation of future probabilities for every new prefix and eliminates reuse. LTLA avoids both by using a single batched HMM update to account for all next-token candidates at once, and by conditioning only the surrogate's latent state prior on the LM's hidden representations while keeping the surrogate decoder fixed, so computations can be reused across prefixes. Empirically, LTLA attains higher conditional likelihood than an unconditional HMM, approximates continuation distributions for vision-language models where a standalone HMM cannot encode visual context, and improves constraint satisfaction at comparable fluency on controlled-generation tasks, with minimal inference overhead.

</details>


### [24] [Early science acceleration experiments with GPT-5](https://arxiv.org/abs/2511.16072)
*Sébastien Bubeck,Christian Coester,Ronen Eldan,Timothy Gowers,Yin Tat Lee,Alexandru Lupsasca,Mehtaab Sawhney,Robert Scherrer,Mark Sellke,Brian K. Spears,Derya Unutmaz,Kevin Weil,Steven Yin,Nikita Zhivotovskiy*

Main category: cs.CL

TL;DR: 本论文跨学科展示GPT-5协助科研案例，包括数学新成果，说明AI工具能显著加速科学研究，但仍需人类专家把关和参与。


<details>
  <summary>Details</summary>
Motivation: 当前许多科学家对前沿AI能力认知有限，作者希望通过展示GPT-5在多领域科研中的应用，提升科学界对AI工具价值和局限的理解。

Method: 通过多个学科的短案例分析，记录人类作者与GPT-5的协作过程，包括AI加速和不足的具体实例。

Result: GPT-5在数学领域产生了四项由人类作者仔细验证的新结果，展示了AI协助解决复杂问题的潜力，并且总结了AI提升科研效率和限制之处。

Conclusion: GPT-5等前沿AI在科研中提供了实际帮助，能够加速研究进程并产生新成果，但人类专家仍在验证与指导上发挥不可或缺的作用。

Abstract: AI models like GPT-5 are an increasingly valuable tool for scientists, but many remain unaware of the capabilities of frontier AI. We present a collection of short case studies in which GPT-5 produced new, concrete steps in ongoing research across mathematics, physics, astronomy, computer science, biology, and materials science. In these examples, the authors highlight how AI accelerated their work, and where it fell short; where expert time was saved, and where human input was still key. We document the interactions of the human authors with GPT-5, as guiding examples of fruitful collaboration with AI. Of note, this paper includes four new results in mathematics (carefully verified by the human authors), underscoring how GPT-5 can help human mathematicians settle previously unsolved problems. These contributions are modest in scope but profound in implication, given the rate at which frontier AI is progressing.

</details>


### [25] [ELPO: Ensemble Learning Based Prompt Optimization for Large Language Models](https://arxiv.org/abs/2511.16122)
*Qing Zhang,Bing Xu,Xudong Zhang,Yifan Shi,Yang Li,Chen Zhang,Yik Chung Wu,Ngai Wong,Yijie Chen,Hong Dai,Xiansen Chen,Mian Zhang*

Main category: cs.CL

TL;DR: 本文提出将集成学习应用到大语言模型的自动提示优化，通过多种生成与搜索策略集成，有效突破现有方法瓶颈，实验显示在不同任务上的性能都明显领先。


<details>
  <summary>Details</summary>
Motivation: 手工设计大语言模型（LLM）提示词过程繁琐且费时，成为其实际应用的瓶颈，促使自动化提示优化（APO）发展。现有APO方法多受限于单一模型或算法，难以在复杂任务上发挥更好性能。

Method: 提出了一种基于集成学习的提示优化框架ELPO，结合投票机制、共享生成策略以及不同搜索方法，提升提示生成和搜索效率。

Result: ELPO在多个任务上的表现优于当前最先进方法，例如在ArSarcasm数据集上F1分数提升了7.6。

Conclusion: 集成学习思想提升了提示优化的准确性与鲁棒性，ELPO能显著优于现有主流APO方法。

Abstract: The remarkable performance of Large Language Models (LLMs) highly relies on crafted prompts. However, manual prompt engineering is a laborious process, creating a core bottleneck for practical application of LLMs. This phenomenon has led to the emergence of a new research area known as Automatic Prompt Optimization (APO), which develops rapidly in recent years. Existing APO methods such as those based on evolutionary algorithms or trial-and-error approaches realize an efficient and accurate prompt optimization to some extent. However, those researches focus on a single model or algorithm for the generation strategy and optimization process, which limits their performance when handling complex tasks. To address this, we propose a novel framework called Ensemble Learning based Prompt Optimization (ELPO) to achieve more accurate and robust results. Motivated by the idea of ensemble learning, ELPO conducts voting mechanism and introduces shared generation strategies along with different search methods for searching superior prompts. Moreover, ELPO creatively presents more efficient algorithms for the prompt generation and search process. Experimental results demonstrate that ELPO outperforms state-of-the-art prompt optimization methods across different tasks, e.g., improving F1 score by 7.6 on ArSarcasm dataset.

</details>


### [26] [TS-PEFT: Token-Selective Parameter-Efficient Fine-Tuning with Learnable Threshold Gating](https://arxiv.org/abs/2511.16147)
*Dabiao Ma,Ziming Dai,Zhimin Xin,Shu Wang,Ye Wang,Haojun Fei*

Main category: cs.CL

TL;DR: 本文提出通过选择性地对部分token位置应用参数高效微调，而不是全部，能更好地提升大模型下游任务表现，挑战了传统PEFT的“一刀切”做法。


<details>
  <summary>Details</summary>
Motivation: 参数高效微调（PEFT）被广泛用于NLP和CV领域的大模型微调，但传统PEFT对所有位置进行修改，是否有必要尚存疑问。

Method: 提出一种新的Token-Selective PEFT（TS-PEFT）范式，通过一个函数S，仅对选定的部分位置索引施加PEFT修改，而不是全部。

Result: 实验表明，对所有位置索引一视同仁地应用PEFT不仅多余，有时还可能适得其反。

Conclusion: 对PEFT的应用应更有针对性，并提供了优化大模型微调的新思路和方法框架。

Abstract: In the field of large models (LMs) for natural language processing (NLP) and computer vision (CV), Parameter-Efficient Fine-Tuning (PEFT) has emerged as a resource-efficient method that modifies a limited number of parameters while keeping the pretrained weights fixed. This paper investigates the traditional PEFT approach, which applies modifications to all position indices, and questions its necessity. We introduce a new paradigm called Token-Selective PEFT (TS-PEFT), in which a function S selectively applies PEFT modifications to a subset of position indices, potentially enhancing performance on downstream tasks. Our experimental results reveal that the indiscriminate application of PEFT to all indices is not only superfluous, but may also be counterproductive. This study offers a fresh perspective on PEFT, advocating for a more targeted approach to modifications and providing a framework for future research to optimize the fine-tuning process for large models.

</details>


### [27] [SemanticCite: Citation Verification with AI-Powered Full-Text Analysis and Evidence-Based Reasoning](https://arxiv.org/abs/2511.16198)
*Sebastian Haan*

Main category: cs.CL

TL;DR: 该论文提出并开源了一套AI驱动的自动验证引用准确性系统，通过语义分析和分类显著提升学术引用质量，促进研究诚信与AI内容的质量管理。


<details>
  <summary>Details</summary>
Motivation: 学术文献中引用准确性面临诸多挑战，如语义引用错误、AI生成的虚假引用，以及传统引用格式无法指示具体支持论点的内容。

Method: 提出了一套基于AI的系统SemanticCite，通过全文检索和四分类机制（支持、部分支持、不支持、不确定），结合多种检索方法和详细的推理信息及相关文本片段，实现引用验证与语境丰富展示。还开发了细致对齐、功能分类、语义标注和计量元数据的综合数据集，以及经过微调的语言模型。

Result: 微调的轻量级语言模型在性能上可媲美大型商业系统，且计算资源需求大幅降低，使大规模引用验证变得可行。该系统可透明地解释证据，增强用户理解和信任。

Conclusion: SemanticCite解决了学术诚信中的核心问题，可用于规模化引用验证、简化同行评审和AI内容质量控制，为维护引用准确性提供了开源基础。

Abstract: Effective scientific communication depends on accurate citations that validate sources and guide readers to supporting evidence. Yet academic literature faces mounting challenges: semantic citation errors that misrepresent sources, AI-generated hallucinated references, and traditional citation formats that point to entire papers without indicating which sections substantiate specific claims. We introduce SemanticCite, an AI-powered system that verifies citation accuracy through full-text source analysis while providing rich contextual information via detailed reasoning and relevant text snippets. Our approach combines multiple retrieval methods with a four-class classification system (Supported, Partially Supported, Unsupported, Uncertain) that captures nuanced claim-source relationships and enables appropriate remedial actions for different error types. Our experiments show that fine-tuned lightweight language models achieve performance comparable to large commercial systems with significantly lower computational requirements, making large-scale citation verification practically feasible. The system provides transparent, evidence-based explanations that support user understanding and trust. We contribute a comprehensive dataset of over 1,000 citations with detailed alignments, functional classifications, semantic annotations, and bibliometric metadata across eight disciplines, alongside fine-tuned models and the complete verification framework as open-source software. SemanticCite addresses critical challenges in research integrity through scalable citation verification, streamlined peer review, and quality control for AI-generated content, providing an open-source foundation for maintaining citation accuracy at scale.

</details>


### [28] [SeSE: A Structural Information-Guided Uncertainty Quantification Framework for Hallucination Detection in LLMs](https://arxiv.org/abs/2511.16275)
*Xingtao Zhao,Hao Peng,Dingli Su,Xianghua Zeng,Chunyang Liu,Jinzhi Liao,Philip S. Yu*

Main category: cs.CL

TL;DR: 本文提出SeSE结构熵框架，通过语义结构建模显著提升大语言模型抗幻觉能力和不确定性估计效果，实验验证优于现有方法，可应用于安全关键场景。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在安全关键场景部署时，亟需可靠的不确定性估计方法，以便在模型不确定时拒绝回答，避免产生虚假内容。然而，目前主流的不确定性估计方法过度依赖概率分布或语义距离，忽略了潜在的语义结构信息，难以实现精细的不确定性量化。

Method: 提出了一种新的语义结构熵（SeSE）框架，从结构信息角度对模型的内在语义不确定性进行量化。具体方法包括：1）提出自适应稀疏有向语义图构建算法，捕捉语义依赖关系并自动剪枝以减少负面干扰；2）通过层次化抽象，定义在最优语义编码树上的结构熵，表达经过压缩后的语义空间的不确定性；3）将SeSE扩展至长文本生成中的细粒度不确定性评估，具体对单个 claim 进行随机语义交互建模，实现可解释的幻觉检测。

Result: 在29组模型-数据集的广泛实验中，SeSE在幻觉检测及不确定性评估方面显著优于当前主流基线，包括强监督方法和最新提出的KLE方法。

Conclusion: SeSE为大语言模型幻觉检测与不确定性量化提供了理论完备且效果显著的新方法，尤其在细粒度长文本生成任务中表现突出，可帮助模型在不确定时做出更安全的决策。

Abstract: Reliable uncertainty quantification (UQ) is essential for deploying large language models (LLMs) in safety-critical scenarios, as it enables them to abstain from responding when uncertain, thereby avoiding hallucinating falsehoods. However, state-of-the-art UQ methods primarily rely on semantic probability distributions or pairwise distances, overlooking latent semantic structural information that could enable more precise uncertainty estimates. This paper presents Semantic Structural Entropy (SeSE), a principled UQ framework that quantifies the inherent semantic uncertainty of LLMs from a structural information perspective for hallucination detection. Specifically, to effectively model semantic spaces, we first develop an adaptively sparsified directed semantic graph construction algorithm that captures directional semantic dependencies while automatically pruning unnecessary connections that introduce negative interference. We then exploit latent semantic structural information through hierarchical abstraction: SeSE is defined as the structural entropy of the optimal semantic encoding tree, formalizing intrinsic uncertainty within semantic spaces after optimal compression. A higher SeSE value corresponds to greater uncertainty, indicating that LLMs are highly likely to generate hallucinations. In addition, to enhance fine-grained UQ in long-form generation -- where existing methods often rely on heuristic sample-and-count techniques -- we extend SeSE to quantify the uncertainty of individual claims by modeling their random semantic interactions, providing theoretically explicable hallucination detection. Extensive experiments across 29 model-dataset combinations show that SeSE significantly outperforms advanced UQ baselines, including strong supervised methods and the recently proposed KLE.

</details>


### [29] [SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning](https://arxiv.org/abs/2511.16324)
*Wei Xia,Zhi-Hong Deng*

Main category: cs.CL

TL;DR: 本文提出了一个无需再训练即可用于各种开源LLM的对齐方法SDA，在有用性、诚实性与无害性等多维度上取得了显著提升，能灵活适应不同用户需求，且方法高效泛用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在实际应用中需求不断增长，如何在推理阶段高效、有效地对齐模型输出与用户意图，而无需重新训练或大量人工监督，是当前的关键挑战。

Method: 提出了一种无需训练、与模型无关的对齐框架——SDA（Steering-Driven Distribution Alignment），通过用户设定的对齐指令动态调整输出概率，可独立运行或与训练型对齐方法结合，且支持个性化偏好对齐。

Result: 在8个不同规模和来源的开源LLM上，SDA在有用性、无害性和诚实性（3H指标）上分别获得了64.4%、30%、11.5%的平均提升，显示出了良好的通用性和有效性。

Conclusion: SDA是一种轻量、高效且具有广泛兼容性的LLM对齐方案，可显著提升模型输出与人类意图的匹配程度，无需重新训练即可实现各种应用场景下的需求。

Abstract: With the rapid advancement of large language models (LLMs), their deployment in real-world applications has become increasingly widespread. LLMs are expected to deliver robust performance across diverse tasks, user preferences, and practical scenarios. However, as demands grow, ensuring that LLMs produce responses aligned with human intent remains a foundational challenge. In particular, aligning model behavior effectively and efficiently during inference, without costly retraining or extensive supervision, is both a critical requirement and a non-trivial technical endeavor. To address the challenge, we propose SDA (Steering-Driven Distribution Alignment), a training-free and model-agnostic alignment framework designed for open-source LLMs. SDA dynamically redistributes model output probabilities based on user-defined alignment instructions, enhancing alignment between model behavior and human intents without fine-tuning. The method is lightweight, resource-efficient, and compatible with a wide range of open-source LLMs. It can function independently during inference or be integrated with training-based alignment strategies. Moreover, SDA supports personalized preference alignment, enabling flexible control over the model response behavior. Empirical results demonstrate that SDA consistently improves alignment performance across 8 open-source LLMs with varying scales and diverse origins, evaluated on three key alignment dimensions, helpfulness, harmlessness, and honesty (3H). Specifically, SDA achieves average gains of 64.4% in helpfulness, 30% in honesty and 11.5% in harmlessness across the tested models, indicating its effectiveness and generalization across diverse models and application scenarios.

</details>


### [30] [Incorporating Self-Rewriting into Large Language Model Reasoning Reinforcement](https://arxiv.org/abs/2511.16331)
*Jiashu Yao,Heyan Huang,Shuang Zeng,Chuwei Luo,WangJie You,Jie Tang,Qingsong Liu,Yuhang Guo,Yangyang Kang*

Main category: cs.CL

TL;DR: 本文提出通过让模型自我重写推理过程文本并学习之，可显著优化大型推理模型的内部思维质量及效率，在广泛实验中展现出更高准确率和更优推理质量，明显优于传统强化学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的推理模型在复杂推理任务上取得了显著成功，但只利用最终正确性的单侧奖励，无法对推理过程内部进行细致监督，导致推理过程质量不佳，如过度、欠缺、冗余或混乱思考等问题。

Method: 提出了self-rewriting框架：模型自我重写推理过程文本，并通过学习重写后的推理来提升内部思维质量。具体采用选择性重写，仅针对“简单”样本（模型反复预测正确的样本）进行重写，并融合重写生成和普通生成到同一训练批次，保持算法扩展性，计算开销仅增加约10%。

Result: 在多项任务和不同模型规模上，self-rewriting方法在精度-长度权衡方面较强基线提升：在未显式缩短推理长度指令下，准确率提升0.6%，推理长度显著缩短46%；在内部质量上，LLM评判分数显著提升7.2，有效缓解推理过程缺陷。

Conclusion: self-rewriting能够提升大模型推理过程的内部质量和推理效率，优于现有强基线，并能有效缓解过度、冗余、混乱等思考问题。

Abstract: Through reinforcement learning (RL) with outcome correctness rewards, large reasoning models (LRMs) with scaled inference computation have demonstrated substantial success on complex reasoning tasks. However, the one-sided reward, focused solely on final correctness, limits its ability to provide detailed supervision over internal reasoning process. This deficiency leads to suboptimal internal reasoning quality, manifesting as issues like over-thinking, under-thinking, redundant-thinking, and disordered-thinking. Inspired by the recent progress in LRM self-rewarding, we introduce self-rewriting framework, where a model rewrites its own reasoning texts, and subsequently learns from the rewritten reasoning to improve the internal thought process quality. For algorithm design, we propose a selective rewriting approach wherein only "simple" samples, defined by the model's consistent correctness, are rewritten, thereby preserving all original reward signals of GRPO. For practical implementation, we compile rewriting and vanilla generation within one single batch, maintaining the scalability of the RL algorithm and introducing only ~10% overhead. Extensive experiments on diverse tasks with different model sizes validate the effectiveness of self-rewriting. In terms of the accuracy-length tradeoff, the self-rewriting approach achieves improved accuracy (+0.6) with substantially shorter reasoning (-46%) even without explicit instructions in rewriting prompts to reduce reasoning length, outperforming existing strong baselines. In terms of internal reasoning quality, self-rewriting achieves significantly higher scores (+7.2) under the LLM-as-a-judge metric, successfully mitigating internal reasoning flaws.

</details>


### [31] [NLP Datasets for Idiom and Figurative Language Tasks](https://arxiv.org/abs/2511.16345)
*Blake Matheny,Phuong Minh Nguyen,Minh Le Nguyen,Stephanie Reynolds*

Main category: cs.CL

TL;DR: 本文提出、构建并整合了多个习语和比喻性语言数据集，并利用这些数据集测试了预训练语言模型在习语识别任务中的表现，为提升模型处理非字面语言能力提供了新的数据资源和评估方法。


<details>
  <summary>Details</summary>
Motivation: 习语和比喻性语言在口语和书面语中占据很大比例，而由于社交媒体的发展，这种非正式语言变得更加容易被观察到。尽管大型语料库为机器学习和NLP带来了巨大优势，但习语和比喻性语言仍然令大语言模型难以处理。为了进一步缩小这一差距，需要更好、更大的相关数据集。

Method: 作者首先收集并融合了近来的习语与比喻性语言数据集，形成一个习语列表，并从大语料库中检索相关语境序列。随后，构建了一个大规模潜在习语和比喻性表达的数据集，以及两个已人工标注的习语和比喻性表达数据集。通过这些数据集评估预训练语言模型对比喻性含义的处理能力，包括习语识别（检测）任务，并对数据集进行后处理使其适配各种模型，最后应用于槽标注和序列标注的训练与评估。

Result: 成功构建了三个新的数据集，并通过这些数据集训练和评估了预训练语言模型在识别习语和比喻性表达上的能力。为后续模型开发和新方法的探索提供了多样化的数据基础。

Conclusion: 更大且更优质的习语和比喻性语言数据集能够有效提升大语言模型对非字面含义理解的能力，为相关NLP任务奠定了可靠的数据支持与评估基础。

Abstract: Idiomatic and figurative language form a large portion of colloquial speech and writing. With social media, this informal language has become more easily observable to people and trainers of large language models (LLMs) alike. While the advantage of large corpora seems like the solution to all machine learning and Natural Language Processing (NLP) problems, idioms and figurative language continue to elude LLMs. Finetuning approaches are proving to be optimal, but better and larger datasets can help narrow this gap even further. The datasets presented in this paper provide one answer, while offering a diverse set of categories on which to build new models and develop new approaches. A selection of recent idiom and figurative language datasets were used to acquire a combined idiom list, which was used to retrieve context sequences from a large corpus. One large-scale dataset of potential idiomatic and figurative language expressions and two additional human-annotated datasets of definite idiomatic and figurative language expressions were created to evaluate the baseline ability of pre-trained language models in handling figurative meaning through idiom recognition (detection) tasks. The resulting datasets were post-processed for model agnostic training compatibility, utilized in training, and evaluated on slot labeling and sequence tagging.

</details>


### [32] [Learning from Sufficient Rationales: Analysing the Relationship Between Explanation Faithfulness and Token-level Regularisation Strategies](https://arxiv.org/abs/2511.16353)
*Jonathan Kamp,Lisa Beinborn,Antske Fokkens*

Main category: cs.CL

TL;DR: 文章系统比较了推理充分性等指标对模型推理解释的适用性，发现高信息解释并不一定有助于分类，跨领域泛化效果任务依赖性大，现有指标难以全面衡量推理片段作用。


<details>
  <summary>Details</summary>
Motivation: 现有自然语言推理解释（rationale）评价方法，如sufficiency，无法全面反映推理片段对模型表现的实际影响。作者希望厘清推理片段信息与模型推理、分类性能之间的真实关联，推动对rationale作用更精细的理解。

Method: 1. 分析了推理充分性（sufficiency）评价指标在模型推理解释中的作用。2. 采用两种建模范式：（a）通过token分类识别推理片段所在位置；（b）通过注意力机制正则化，将推理片段嵌入输入以提升模型表现。3. 研究了推理片段信息对模型跨领域表现的影响，并对比了不同任务和模型类型中的一致性。4. 检验了推理fully和token分类性能之间的关系。

Result: 1. 信息量高的推理片段未必有助于提升实例分类准确率。2. 充分性反映了未被标记为解释的背景部分对分类的影响，这部分信息可能会干扰推理片段。3. 在输入中显式引入推理片段有时能提升跨领域分类，但任务与模型类型不同，提升效果不一致。4. 发现推理充分性与token分类能力之间无明显关联。

Conclusion: 推理解释的表达及其与模型表现的关系远比单一指标更复杂。应发展更全面的度量体系，以揭示解释内容、输入信息和模型推理间的多维相互影响。

Abstract: Human explanations of natural language, rationales, form a tool to assess whether models learn a label for the right reasons or rely on dataset-specific shortcuts. Sufficiency is a common metric for estimating the informativeness of rationales, but it provides limited insight into the effects of rationale information on model performance. We address this limitation by relating sufficiency to two modelling paradigms: the ability of models to identify which tokens are part of the rationale (through token classification) and the ability of improving model performance by incorporating rationales in the input (through attention regularisation). We find that highly informative rationales are not likely to help classify the instance correctly. Sufficiency conversely captures the classification impact of the non-rationalised context, which interferes with rationale information in the same input. We also find that incorporating rationale information in model inputs can boost cross-domain classification, but results are inconsistent per task and model type. Finally, sufficiency and token classification appear to be unrelated. These results exemplify the complexity of rationales, showing that metrics capable of systematically capturing this type of information merit further investigation.

</details>


### [33] [AICC: Parse HTML Finer, Make Models Better -- A 7.3T AI-Ready Corpus Built by a Model-Based HTML Parser](https://arxiv.org/abs/2511.16397)
*Ren Ma,Jiantao Qiu,Chao Xu,Pei Chu,Kaiwen Liu,Pengli Ren,Yuan Qu,Jiahui Peng,Linfeng Hou,Mengjie Liu,Lindong Lu,Wenchang Ning,Jia Yu,Rui Min,Jin Shi,Haojiong Chen,Peng Zhang,Wenjian Zhang,Qian Jiang,Zengjie Hu,Guoqiang Yang,Zhenxiang Li,Fukai Shang,Zhongying Tu,Wentao Zhang,Dahua Lin,Conghui He*

Main category: cs.CL

TL;DR: 网页HTML到文本的抽取环节对大语言模型性能影响巨大。作者提出矿工式、模型驱动的抽取工具MinerU-HTML，显著提升结构化信息保留和文本质量，并在大规模语料和预训练模型测试中刷新标杆。高质量HTML抽取对构建优质语料库不可或缺。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型对于网页数据质量要求极高，但主要精力集中在过滤和去重上，HTML转文本的提取通常作为固定的预处理步骤，并未充分关注。现有网页语料库多依赖基于启发式的提取工具，如Trafilatura，这类方法难以保留文档结构且常损坏公式、代码、表格等结构化元素。作者认为提升文本抽取质量对下游表现的影响能与激进过滤策略比肩。

Method: 提出MinerU-HTML，一种新颖的网页文本抽取流程，将内容提取问题重构为序列标注，由一个0.6B参数的语言模型完成。不同于传统基于密度启发式的方式，MinerU-HTML采用语义理解，并通过两阶段格式化流程将语义元素明确分类，最终转换为Markdown格式。此模型驱动方法具有固有可扩展性，相较于启发式方案更有提升空间。

Result: 在MainWebBench（7,887个标注网页）测试集上，MinerU-HTML的ROUGE-N F1为81.8%，显著优于Trafilatura的63.6%。对于结构化元素保留率，如代码块（90.9%）、公式（94.0%）表现尤其突出。利用MinerU-HTML构建了AICC语料（7.3万亿token），与Trafilatura版本同等过滤下，预训练模型在13项基准测试上平均准确率达50.8%，比TfCC高1.08个百分点，并在关键测试超越RefinedWeb和FineWeb。

Conclusion: HTML文本抽取质量对大语料库和下游大模型效果具有重大影响，且往往被低估。通过引入基于模型的提取方法MinerU-HTML，作者证明高质量抽取对模型能力提升至关重要，并公开相关工具与语料库，促进领域发展。

Abstract: While web data quality is crucial for large language models, most curation efforts focus on filtering and deduplication,treating HTML-to-text extraction as a fixed pre-processing step. Existing web corpora rely on heuristic-based extractors like Trafilatura, which struggle to preserve document structure and frequently corrupt structured elements such as formulas, codes, and tables. We hypothesize that improving extraction quality can be as impactful as aggressive filtering strategies for downstream performance. We introduce MinerU-HTML, a novel extraction pipeline that reformulates content extraction as a sequence labeling problem solved by a 0.6B-parameter language model. Unlike text-density heuristics, MinerU-HTML leverages semantic understanding and employs a two-stage formatting pipeline that explicitly categorizes semantic elements before converting to Markdown. Crucially, its model-based approach is inherently scalable, whereas heuristic methods offer limited improvement pathways. On MainWebBench, our benchmark of 7,887 annotated web pages, MinerU-HTML achieves 81.8\% ROUGE-N F1 compared to Trafilatura's 63.6\%, with exceptional structured element preservation (90.9\% for code blocks, 94.0\% for formulas). Using MinerU-HTML, we construct AICC (AI-ready Common Crawl), a 7.3-trillion token multilingual corpus from two Common Crawl snapshots. In controlled pretraining experiments where AICC and Trafilatura-extracted TfCC undergo identical filtering, models trained on AICC (62B tokens) achieve 50.8\% average accuracy across 13 benchmarks, outperforming TfCC by 1.08pp-providing direct evidence that extraction quality significantly impacts model capabilities. AICC also surpasses RefinedWeb and FineWeb on key benchmarks. We publicly release MainWebBench, MinerU-HTML, and AICC, demonstrating that HTML extraction is a critical, often underestimated component of web corpus construction.

</details>


### [34] [Classification of worldwide news articles by perceived quality, 2018-2024](https://arxiv.org/abs/2511.16416)
*Connor McElroy,Thiago E. A. de Oliveira,Chris Brogly*

Main category: cs.CL

TL;DR: 本文利用近141万篇英文新闻数据集，将高低质量新闻分为两类，用三种机器学习算法和三种深度学习模型分类。传统模型如随机森林效果尚好（准确率0.74），深度学习如ModernBERT-large达到0.87以上准确率。结果表明，无论传统或深度学习方法，均可有效区分全球新闻质量高低。


<details>
  <summary>Details</summary>
Motivation: 新闻质量良莠不齐，需要自动化工具区分高低质量新闻，提高信息筛选效率。

Method: 构建了包含近141万篇英语新闻的大型数据集，依据专家对579个新闻源网站一致性打分将其分为高低质量类别，分别用3种机器学习和3种深度学习模型进行分类性能评估。

Result: 随机森林等传统模型准确率为0.7355（ROC AUC为0.8131）。深度学习模型表现更佳，ModernBERT-large模型准确率达0.8744（ROC AUC为0.9593），F1为0.8739；DistilBERT-base（512 context长度）准确率0.8685（ROC AUC为0.9554）；其他BERT变体也有较高性能。

Conclusion: 传统机器学习算法和深度学习模型均能较为有效地区分高质量与低质量新闻，尤其深度学习模型表现优异。

Abstract: This study explored whether supervised machine learning and deep learning models can effectively distinguish perceived lower-quality news articles from perceived higher-quality news articles. 3 machine learning classifiers and 3 deep learning models were assessed using a newly created dataset of 1,412,272 English news articles from the Common Crawl over 2018-2024. Expert consensus ratings on 579 source websites were split at the median, creating perceived low and high-quality classes of about 706,000 articles each, with 194 linguistic features per website-level labelled article. Traditional machine learning classifiers such as the Random Forest demonstrated capable performance (0.7355 accuracy, 0.8131 ROC AUC). For deep learning, ModernBERT-large (256 context length) achieved the best performance (0.8744 accuracy; 0.9593 ROC-AUC; 0.8739 F1), followed by DistilBERT-base (512 context length) at 0.8685 accuracy and 0.9554 ROC-AUC. DistilBERT-base (256 context length) reached 0.8478 accuracy and 0.9407 ROC-AUC, while ModernBERT-base (256 context length) attained 0.8569 accuracy and 0.9470 ROC-AUC. These results suggest that the perceived quality of worldwide news articles can be effectively differentiated by traditional CPU-based machine learning classifiers and deep learning classifiers.

</details>


### [35] [ESGBench: A Benchmark for Explainable ESG Question Answering in Corporate Sustainability Reports](https://arxiv.org/abs/2511.16438)
*Sherine George,Nithish Saji*

Main category: cs.CL

TL;DR: 本文推出了用于评估可解释的ESG问答系统的新基准ESGBench，并分析了现有模型的主要难点，有助于推动ESG相关AI的透明和负责任发展。


<details>
  <summary>Details</summary>
Motivation: 现有ESG问答系统在透明性和可解释性方面存在不足，缺少标准化评估基准，亟需推动相关AI系统的可靠发展。

Method: 构建了一个涵盖多种ESG主题的问题与答案基准数据集，并配有人类标注的支持性证据，同时对现有主流大模型进行了性能分析。

Result: 分析显示当前主流大模型在事实一致性、可追溯性和领域适应性方面存在显著挑战。

Conclusion: ESGBench能有效推动透明和负责任的ESG领域AI系统的研究。

Abstract: We present ESGBench, a benchmark dataset and evaluation framework designed to assess explainable ESG question answering systems using corporate sustainability reports. The benchmark consists of domain-grounded questions across multiple ESG themes, paired with human-curated answers and supporting evidence to enable fine-grained evaluation of model reasoning. We analyze the performance of state-of-the-art LLMs on ESGBench, highlighting key challenges in factual consistency, traceability, and domain alignment. ESGBench aims to accelerate research in transparent and accountable ESG-focused AI systems.

</details>


### [36] [Anatomy of an Idiom: Tracing Non-Compositionality in Language Models](https://arxiv.org/abs/2511.16467)
*Andrew Gomes*

Main category: cs.CL

TL;DR: 本文提出新技术分析transformer模型如何处理成语，发现了特定的注意力头和增强的内部连接机制，揭示了非组合性语言处理中计算效率与鲁棒性的平衡机制。


<details>
  <summary>Details</summary>
Motivation: 探究transformer类语言模型如何处理成语（惯用语）这种非组合性语言现象，目前相关理解有限。

Method: 提出并使用一种新的电路发现与分析方法（基于改进的path patching算法），对transformer模型内部处理流程进行分析。

Result: 发现处理成语时存在特殊的计算模式，包括“成语头”——在多种成语中频繁激活的注意力头，以及“增强接收”——模型在先前处理后，成语各词之间注意力增强。并分析这些现象在效率与鲁棒性平衡中的作用。

Conclusion: 这些发现揭示了transformer处理非组合性语言的机制，并为理解更复杂语法结构的处理方式提供了可能的研究方向。

Abstract: We investigate the processing of idiomatic expressions in transformer-based language models using a novel set of techniques for circuit discovery and analysis. First discovering circuits via a modified path patching algorithm, we find that idiom processing exhibits distinct computational patterns. We identify and investigate ``Idiom Heads,'' attention heads that frequently activate across different idioms, as well as enhanced attention between idiom tokens due to earlier processing, which we term ``augmented reception.'' We analyze these phenomena and the general features of the discovered circuits as mechanisms by which transformers balance computational efficiency and robustness. Finally, these findings provide insights into how transformers handle non-compositional language and suggest pathways for understanding the processing of more complex grammatical constructions.

</details>


### [37] [Arctic-Extract Technical Report](https://arxiv.org/abs/2511.16470)
*Mateusz Chiliński,Julita Ołtusek,Wojciech Jaśkowski*

Main category: cs.CL

TL;DR: Arctic-Extract是一款小体积、性能强的文档结构数据抽取模型，支持在显存有限的GPU上高效处理大量文档，兼顾部署与准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的结构化文档理解模型多偏重于性能且模型体积较大，不适合部署于硬件资源有限的场景。

Method: 设计并训练了一种体积仅为6.6 GiB的模型，具备在A10 GPU等资源有限设备上的部署能力。论文详细介绍了其训练流程及评估方法。

Result: 模型在资源受限的GPU（如24GB显存的A10）上可以并行处理长文档（最多125页A4纸），评测显示具备优异的文档理解能力。

Conclusion: Arctic-Extract模型在结构化数据（包括问答、实体识别和表格）抽取任务中表现优异，并可以在资源受限的硬件上高效部署。

Abstract: Arctic-Extract is a state-of-the-art model designed for extracting structural data (question answering, entities and tables) from scanned or digital-born business documents. Despite its SoTA capabilities, the model is deployable on resource-constrained hardware, weighting only 6.6 GiB, making it suitable for deployment on devices with limited resources, such as A10 GPUs with 24 GB of memory. Arctic-Extract can process up to 125 A4 pages on those GPUs, making suitable for long document processing. This paper highlights Arctic-Extract's training protocols and evaluation results, demonstrating its strong performance in document understanding.

</details>


### [38] [TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval](https://arxiv.org/abs/2511.16528)
*Özay Ezerceli,Mahmoud El Hussieni,Selva Taş,Reyhan Bayraktar,Fatma Betül Terzioğlu,Yusuf Çelebi,Yağız Asker*

Main category: cs.CL

TL;DR: TurkColBERT首次系统比较稠密编码器与晚交互模型用于土耳其语检索，发现晚交互模型在小规模、领域任务下参数效率高且性能优越，MUVERA+Rerank索引算法提升速度与准确率。公布相关资源，但当前评估受限于中等规模和翻译基准，未来需在更大规模真实数据测试。


<details>
  <summary>Details</summary>
Motivation: 以往土耳其语IR多采用稠密编码器，晚交互模型尚缺乏系统性评估，希望探索在该低资源、形态丰富语言场景下晚交互模型的表现及优势。

Method: 提出TurkColBERT基准，采用两阶段迁移管道：先对英文和多语种编码器在土耳其NLI/STS任务微调，再转换为ColBERT风格的检索器，并用PyLate在MS MARCO-TR上训练。对10个模型在5个领域数据集（科学、金融、争议等）进行系统对比。

Result: ColBERT晚交互模型参数量仅1.0M，比600M稠密编码器小600倍，但能保留超过71%的mAP性能。总体上，参数量小3-5倍的晚交互模型超越稠密模型；ColmmBERT-base-TR在特殊领域任务最高提升13.8% mAP。MUVERA+Rerank索引比PLAID快3.33倍，并提升1.7%相对mAP。实际低延迟检索可达0.54毫秒。

Conclusion: 晚交互模型在土耳其语检索中具有显著参数效率和性能优势。MUVERA+Rerank索引算法在速度和效果上均优于传统方法。

Abstract: Neural information retrieval systems excel in high-resource languages but remain underexplored for morphologically rich, lower-resource languages such as Turkish. Dense bi-encoders currently dominate Turkish IR, yet late-interaction models -- which retain token-level representations for fine-grained matching -- have not been systematically evaluated. We introduce TurkColBERT, the first comprehensive benchmark comparing dense encoders and late-interaction models for Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders on Turkish NLI/STS tasks, then converts them into ColBERT-style retrievers using PyLate trained on MS MARCO-TR. We evaluate 10 models across five Turkish BEIR datasets covering scientific, financial, and argumentative domains. Results show strong parameter efficiency: the 1.0M-parameter colbert-hash-nano-tr is 600$\times$ smaller than the 600M turkish-e5-large dense encoder while preserving over 71\% of its average mAP. Late-interaction models that are 3--5$\times$ smaller than dense encoders significantly outperform them; ColmmBERT-base-TR yields up to +13.8\% mAP on domain-specific tasks. For production-readiness, we compare indexing algorithms: MUVERA+Rerank is 3.33$\times$ faster than PLAID and offers +1.7\% relative mAP gain. This enables low-latency retrieval, with ColmmBERT-base-TR achieving 0.54 ms query times under MUVERA. We release all checkpoints, configs, and evaluation scripts. Limitations include reliance on moderately sized datasets ($\leq$50K documents) and translated benchmarks, which may not fully reflect real-world Turkish retrieval conditions; larger-scale MUVERA evaluations remain necessary.

</details>


### [39] [Beyond Tokens in Language Models: Interpreting Activations through Text Genre Chunks](https://arxiv.org/abs/2511.16540)
*Éloïse Benito-Rodriguez,Einar Urdshals,Jasmina Nasufi,Nicky Pochinkov*

Main category: cs.CL

TL;DR: 该研究表明可用LLM激活值与经典分类器准确预测文本体裁，有助于提升模型可解释性与安全应用。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型结构难以解释，且不可能对所有输出进行人工评估，提高模型的可理解性对于其安全和有效部署至关重要。因此作者尝试通过预测框架来理解模型。

Method: 使用Mistral-7B大型语言模型，通过读取其激活值，结合scikit-learn分类器来预测输入文本的体裁。使用了两个数据集进行实验。

Result: 通过激活值提取，结合浅层学习方法（scikit-learn分类器），能够以最高达98%和71%的F1分数准确预测文本的体裁，两组数据均显著优于对照任务。

Conclusion: 论文展示了利用LLM激活值与浅层学习模型推断文本体裁的可行性，为建立可预测的模型解释框架奠定了基础，并为未来安全应用大型语言模型提供了新思路。

Abstract: Understanding Large Language Models (LLMs) is key to ensure their safe and beneficial deployment. This task is complicated by the difficulty of interpretability of LLM structures, and the inability to have all their outputs human-evaluated. In this paper, we present the first step towards a predictive framework, where the genre of a text used to prompt an LLM, is predicted based on its activations. Using Mistral-7B and two datasets, we show that genre can be extracted with F1-scores of up to 98% and 71% using scikit-learn classifiers. Across both datasets, results consistently outperform the control task, providing a proof of concept that text genres can be inferred from LLMs with shallow learning models.

</details>


### [40] [WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue](https://arxiv.org/abs/2511.16544)
*Zachary Ellis,Jared Joselowitz,Yash Deo,Yajie He,Anna Kalygina,Aisling Higham,Mana Rahimzadeh,Yan Jia,Ibrahim Habli,Ernest Lim*

Main category: cs.CL

TL;DR: ASR在医疗领域常用评估指标（如WER）难以衡量实际转录错误带来的临床风险。该研究建立专家标注基准，发现传统指标与风险相关性差。作者提出用优化后的LLM评估临床风险，达到了与专家相当的准确度，为ASR安全评价提供自动化新方法。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别（ASR）在临床对话中越来越常用，但评估标准仍主要依赖单一的词错误率（WER），而WER未必体现转录错误对临床的真实影响。作者旨在评估现有指标与实际临床风险的相关性，并提出更合适的评估框架。

Method: 作者建立了一个金标准基准，通过专家临床医生对比真实话语和ASR转写结果，在两组医生-病人对话数据集上标注转录错误的临床影响等级（无、轻微、显著）。随后分析了WER和其他常规指标与风险等级的相关性，并提出采用LLM（大语言模型）作为判断者，通过GEPA方法对其进行优化，使其可以自动评估临床风险。

Result: 结果显示，无论WER还是其他评估指标，与临床医生标注的风险等级相关性很差。优化后的LLM（Gemini-2.5-Pro）评估临床风险时，与专家标注一致性高（准确率达90%，Cohen's κ为0.816），可实现人与机器的相当表现。

Conclusion: 本研究表明现有ASR文本评估指标无法充分反映临床转录的安全性，提出并验证了一个基于大语言模型的自动评估框架，推动ASR临床应用评估迈向更有效、可扩展的安全性衡量方法。

Abstract: As Automatic Speech Recognition (ASR) is increasingly deployed in clinical dialogue, standard evaluations still rely heavily on Word Error Rate (WER). This paper challenges that standard, investigating whether WER or other common metrics correlate with the clinical impact of transcription errors. We establish a gold-standard benchmark by having expert clinicians compare ground-truth utterances to their ASR-generated counterparts, labeling the clinical impact of any discrepancies found in two distinct doctor-patient dialogue datasets. Our analysis reveals that WER and a comprehensive suite of existing metrics correlate poorly with the clinician-assigned risk labels (No, Minimal, or Significant Impact). To bridge this evaluation gap, we introduce an LLM-as-a-Judge, programmatically optimized using GEPA to replicate expert clinical assessment. The optimized judge (Gemini-2.5-Pro) achieves human-comparable performance, obtaining 90% accuracy and a strong Cohen's $κ$ of 0.816. This work provides a validated, automated framework for moving ASR evaluation beyond simple textual fidelity to a necessary, scalable assessment of safety in clinical dialogue.

</details>


### [41] [Integrating Symbolic Natural Language Understanding and Language Models for Word Sense Disambiguation](https://arxiv.org/abs/2511.16577)
*Kexin Zhao,Ken Forbus*

Main category: cs.CL

TL;DR: 本文提出利用大型语言模型自动进行词义消歧的方法，无需人工标注，能支持更丰富的语义系统，并在实际数据验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前词义消歧主要依赖粗粒度语义表示且需要人工注释训练数据，这限制了更为丰富语义表示（如OpenCyc）的自动消歧能力，阻碍高级推理。

Method: 提出了一种利用统计语言模型（如大型语言模型）作为消歧“预言机”的方法：不依赖人工注释，而是把符号NLP系统生成的多种候选含义转为可区分的自然语言表述，用于查询LLM，并根据上下文让LLM选择最合适解释，并将结果反馈至符号NLP系统。

Result: 用人工标注金标准数据进行了评估，证明了该方法的有效性。

Conclusion: 无需人工标注训练数据，利用语言模型辅助实现了丰富语义表示下的自动词义消歧，在实验中效果良好。

Abstract: Word sense disambiguation is a fundamental challenge in natural language understanding. Current methods are primarily aimed at coarse-grained representations (e.g. WordNet synsets or FrameNet frames) and require hand-annotated training data to construct. This makes it difficult to automatically disambiguate richer representations (e.g. built on OpenCyc) that are needed for sophisticated inference. We propose a method that uses statistical language models as oracles for disambiguation that does not require any hand-annotation of training data. Instead, the multiple candidate meanings generated by a symbolic NLU system are converted into distinguishable natural language alternatives, which are used to query an LLM to select appropriate interpretations given the linguistic context. The selected meanings are propagated back to the symbolic NLU system. We evaluate our method against human-annotated gold answers to demonstrate its effectiveness.

</details>


### [42] [Comparison of Text-Based and Image-Based Retrieval in Multimodal Retrieval Augmented Generation Large Language Model Systems](https://arxiv.org/abs/2511.16654)
*Elias Lumer,Alex Cardenas,Matt Melich,Myles Mason,Sara Dieter,Vamse Kumar Subbiah,Pradeep Honaganahalli Basavaraju,Roberto Hernandez*

Main category: cs.CL

TL;DR: 将金融文档中的图像直接作为多模态向量存储和检索，显著优于传统的图像文本总结方法，在准确性和事实一致性上表现更佳，为多模态RAG系统带来更强实际价值。


<details>
  <summary>Details</summary>
Motivation: 当前多模态RAG系统在将图像转为文本后仅存储文本信息，导致视觉和上下文信息丢失，影响后续检索与问答质量，因此需要比较不同的检索策略以提升系统性能。

Method: 对比分析两种多模态RAG检索方法：（1）文本分块检索（图像总结为文本后再嵌入），（2）直接多模态嵌入检索（原生存储图像和文本）；在新创建的金融问答基准集上，结合6个LLM和2个多模态嵌入模型进行实验评估。

Result: 实验结果显示：直接多模态嵌入检索在mAP@5和nDCG@5上分别绝对提升13%、11%，相对提升32%、20%，并在事实一致性和答案准确性上优于LLM总结法。

Conclusion: 直接多模态嵌入检索方法能更好地保留视觉上下文，有效提升多模态RAG系统在复杂任务下的问答和检索能力。

Abstract: Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models (LLMs) to access multimodal knowledge bases containing both text and visual information such as charts, diagrams, and tables in financial documents. However, existing multimodal RAG systems rely on LLM-based summarization to convert images into text during preprocessing, storing only text representations in vector databases, which causes loss of contextual information and visual details critical for downstream retrieval and question answering. To address this limitation, we present a comprehensive comparative analysis of two retrieval approaches for multimodal RAG systems, including text-based chunk retrieval (where images are summarized into text before embedding) and direct multimodal embedding retrieval (where images are stored natively in the vector space). We evaluate all three approaches across 6 LLM models and a two multi-modal embedding models on a newly created financial earnings call benchmark comprising 40 question-answer pairs, each paired with 2 documents (1 image and 1 text chunk). Experimental results demonstrate that direct multimodal embedding retrieval significantly outperforms LLM-summary-based approaches, achieving absolute improvements of 13% in mean average precision (mAP@5) and 11% in normalized discounted cumulative gain. These gains correspond to relative improvements of 32% in mAP@5 and 20% in nDCG@5, providing stronger evidence of their practical impact. We additionally find that direct multimodal retrieval produces more accurate and factually consistent answers as measured by LLM-as-a-judge pairwise comparisons. We demonstrate that LLM summarization introduces information loss during preprocessing, whereas direct multimodal embeddings preserve visual context for retrieval and inference.

</details>


### [43] [Nemotron Elastic: Towards Efficient Many-in-One Reasoning LLMs](https://arxiv.org/abs/2511.16664)
*Ali Taghibakhshi,Sharath Turuvekere Sreenivas,Saurav Muralidharan,Ruisi Cai,Marcin Chochowski,Ameya Sunil Mahabaleshwarkar,Yoshi Suhara,Oluwatobi Olabiyi,Daniel Korzekwa,Mostofa Patwary,Mohammad Shoeybi,Jan Kautz,Bryan Catanzaro,Ashwath Aithal,Nima Tajbakhsh,Pavlo Molchanov*

Main category: cs.CL

TL;DR: Nemotron Elastic实现嵌套子模型零样本提取和多预算优化，极大降低训练和部署成本，性能优异。


<details>
  <summary>Details</summary>
Motivation: 针对传统多规模大模型需要分别训练成本高、压缩费用巨大等问题，寻求一种高效、低成本、多配置适用的通用建模方案。

Method: 融合混合Mamba-Attention架构、端到端训练路由器、两阶段训练规划、结构约束保持的组感知SSM弹性化、异构MLP弹性化、归一化MSE层重要性深度选择以及多预算知识蒸馏。

Result: 仅用110B训练tokens即可同时获得12B、9B和6B的子模型，相比从零训练多模型可节约约360倍成本，相较最优压缩技术节约约7倍成本，性能优越且部署内存不随模型数量增加。

Conclusion: Nemotron Elastic框架可以在单一模型中嵌入多个不同规模的子模型，并能在部署时直接零样本提取，无需额外训练或微调，各子模型性能和现有最优方法持平或更佳。

Abstract: Training a family of large language models targeting multiple scales and deployment objectives is prohibitively expensive, requiring separate training runs for each different size. Recent work on model compression through pruning and knowledge distillation has reduced this cost; however, this process still incurs hundreds of billions of tokens worth of training cost per compressed model. In this paper, we present Nemotron Elastic, a framework for building reasoning-oriented LLMs, including hybrid Mamba-Attention architectures, that embed multiple nested submodels within a single parent model, each optimized for different deployment configurations and budgets. Each of these submodels shares weights with the parent model and can be extracted zero-shot during deployment without additional training or fine-tuning. We enable this functionality through an end-to-end trained router, tightly coupled to a two-stage training curriculum designed specifically for reasoning models. We additionally introduce group-aware SSM elastification that preserves Mamba's structural constraints, heterogeneous MLP elastification, normalized MSE-based layer importance for improved depth selection, and knowledge distillation enabling simultaneous multi-budget optimization. We apply Nemotron Elastic to the Nemotron Nano V2 12B model, simultaneously producing a 9B and a 6B model using only 110B training tokens; this results in over 360x cost reduction compared to training model families from scratch, and around 7x compared to SoTA compression techniques. Each of the nested models performs on par or better than the SoTA in accuracy. Moreover, unlike other compression methods, the nested capability of our approach allows having a many-in-one reasoning model that has constant deployment memory against the number of models in the family.

</details>
