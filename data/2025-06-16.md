<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.SE](#cs.SE) [Total: 64]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.CL](#cs.CL) [Total: 69]
- [cs.DM](#cs.DM) [Total: 1]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [A Performance Model for Warp Specialization Kernels](https://arxiv.org/abs/2506.11209)
*Zhengyang Liu,Vinod Grover*

Main category: cs.PL

TL;DR: 本文提出并验证了一个能准确预测GPU warp specialization kernel执行时间的性能模型，对相关参数优化具有实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 当前GPU加速计算中，warp specialization技术能提升性能，但其执行效率受多种参数影响，如warp大小、tiling大小、内存带宽等。因此需要一个准确的性能模型帮助分析优化。

Method: 提出基于差分方程的性能模型，能够量化warp size、tiling size、输入矩阵大小、内存带宽和线程分歧等因素对warp specialization kernel的执行时间的影响，通过仿真和实验进行验证。

Result: 模型能准确预测GPU warp specialization kernel的执行时间，提供性能影响因素的深入见解，为优化GPU应用（编译器优化、kernel参数调优、算法设计）提供理论依据。

Conclusion: 提出的性能模型提升了对GPU warp specialization技术的理解，并具有实际指导意义，有利于相关应用的优化。

Abstract: This paper presents a performance model tailored for warp specialization
kernels, focusing on factors such as warp size, tilling size, input matrix
size, memory bandwidth, and thread divergence. Our model offers accurate
predictions of execution time by leveraging differential equations validated
through simulations and experiments. The insights gained from this model not
only enhance our understanding of warp specialization techniques but also have
practical implications for optimizing GPU-accelerated applications through
compiler optimizations, kernel parameter tuning, and algorithm design.

</details>


### [2] [PermRust: A Token-based Permission System for Rust](https://arxiv.org/abs/2506.11701)
*Lukas Gehring,Sebastian Rehms,Florian Tschorsch*

Main category: cs.PL

TL;DR: 基于能力系统理论，作者提出并实现了适用于 Rust 的库级权限系统 PermRust，实现了更安全和细粒度的资源访问控制。


<details>
  <summary>Details</summary>
Motivation: 传统的系统权限管理只能控制到进程级别，但现代软件大量使用第三方库，因此亟需对库级别的权限进行控制，以提升安全性。

Method: 借鉴能力系统（capability systems）的理念，提出了基于编程语言层面的权限管理理论，并实现了 PermRust——一个基于令牌的Rust权限系统，结合Rust类型系统实现零成本抽象。

Result: PermRust 实现了按库粒度的权限管理，允许开发者更细粒度地控制对系统资源的访问。

Conclusion: PermRust 为实现编程语言级别的、细粒度的权限控制提供了新的理论与实践基础，为第三方库的权限增强了安全性。

Abstract: Permission systems which restrict access to system resources are a
well-established technology in operating systems, especially for smartphones.
However, as such systems are implemented in the operating system they can at
most manage access on the process-level. Since moderns software often (re)uses
code from third-parties libraries, a permission system for libraries can be
desirable to enhance security. In this short-paper, we adapt concepts from
capability systems building a novel theoretical foundation for permission
system at the level of the programming language. This leads to PermRust, a
token-based permission system for the Rust programming language as a zero cost
abstraction on top of its type-system. With it access to system resources can
be managed per library.

</details>


### [3] [ALEA IACTA EST: A Declarative Domain-Specific Language for Manually Performable Random Experiments](https://arxiv.org/abs/2506.11794)
*Baltasar Trancón y Widemann,Markus Lepper*

Main category: cs.PL

TL;DR: Alea是一种面向随机实验的新型专用语言，主打极简使用体验，既能静态分析概率分布，也支持实验模拟，服务初学者和游戏设计领域，当前开发仍在进行。


<details>
  <summary>Details</summary>
Motivation: 在初等随机学教学和博弈中，常需描述并分析简单明了的随机实验。现有工具使用门槛高，不便于学生及游戏设计者等非专家群体直接表达和分析随机实验。

Method: 提出并初步实现了一种面向随机实验的领域专用语言Alea。该语言不仅支持静态分析以推导概率分布，还能借助伪随机源进行实验模拟。

Result: 开发出Alea语言，实现了其基本功能：代码静态分析可获得概率分布，运行时则辅助模拟实验或支持游戏。强调函数式编程和基础数学概念以提升易用性。

Conclusion: Alea语言是一种针对随机实验领域的特定语言，旨在简化和增强随机实验的描述、分析与模拟流程，尤其适合非专业程序员如初学者和游戏设计者使用。其设计和实现仍在持续发展中。

Abstract: Random experiments that are simple and clear enough to be performed by human
agents feature prominently in the teaching of elementary stochastics as well as
in games. We present Alea, a domain-specific language for the specification of
random experiments. Alea code can either be analyzed statically to obtain and
inspect probability distributions of outcomes, or be executed with a source
pseudo-randomness for simulation or as a game assistant. The language is
intended for ease of use by non-expert programmers, in particular students of
elementary stochastics, and players and designers of games of chance, by
focusing on concepts common to functional programming and basic mathematics.
Both the design of the language and the implementation of runtime environments
are work in progress.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [Application Modernization with LLMs: Addressing Core Challenges in Reliability, Security, and Quality](https://arxiv.org/abs/2506.10984)
*Ahilan Ayyachamy Nadar Ponnusamy*

Main category: cs.SE

TL;DR: 本文提出并验证了一种结合LLM代码推理生成能力与人类专家指导的方法，用于解决AI代码生成中的质量和可信度难题。实验证明该方法能更有效推进应用现代化进程。


<details>
  <summary>Details</summary>
Motivation: 尽管AI代码生成显著提升了开发效率，但仍存在安全性、稳定性与一致性等重大挑战。为释放其全部潜力，需解决输出质量和可信度问题。本文旨在探索有效结合AI与人力的方案，推动AI在应用现代化中的可靠落地。

Method: 提出了一个将大语言模型的代码推理与代码生成能力结合，并融入人工专业知识的框架，通过详细案例研究展示了该框架在现实应用现代化任务中的应用流程和效果，同时评估了其他可选方法。

Result: 所提出的框架通过真实案例得到了验证，能更好地应对应用现代化中的实际问题，展现了AI与人工结合的优势。相关参考实现代码已在GitHub公开，为未来的AI赋能现代化研究奠定了基础。

Conclusion: 人类专家的积极参与对于确保AI辅助代码生成工具在应用现代化中的成功至关重要。结合大语言模型（LLMs）的代码推理和生成能力与人工检查，可以有效提高代码质量和可信度。

Abstract: AI-assisted code generation tools have revolutionized software development,
offering unprecedented efficiency and scalability. However, multiple studies
have consistently highlighted challenges such as security vulnerabilities,
reliability issues, and inconsistencies in the generated code. Addressing these
concerns is crucial to unlocking the full potential of this transformative
technology. While advancements in foundational and code-specialized language
models have made notable progress in mitigating some of these issues,
significant gaps remain, particularly in ensuring high-quality, trustworthy
outputs.
  This paper builds upon existing research on leveraging large language models
(LLMs) for application modernization. It explores an opinionated approach that
emphasizes two core capabilities of LLMs: code reasoning and code generation.
The proposed framework integrates these capabilities with human expertise to
tackle application modernization challenges effectively. It highlights the
indispensable role of human involvement and guidance in ensuring the success of
AI-assisted processes.
  To demonstrate the framework's utility, this paper presents a detailed case
study, walking through its application in a real-world scenario. The analysis
includes a step-by-step breakdown, assessing alternative approaches where
applicable. This work aims to provide actionable insights and a robust
foundation for future research in AI-driven application modernization. The
reference implementation created for this paper is available on GitHub.

</details>


### [5] [Collaboration Tools and their Role in Agile Software Projects](https://arxiv.org/abs/2506.10985)
*Raman Mohammed Hussein,Bryar A. Hassan*

Main category: cs.SE

TL;DR: 协作工具（Slack、Teams、Confluence）在敏捷软件项目中对提升沟通、知识共享和任务管理至关重要，有助团队顺利实施敏捷开发理念。


<details>
  <summary>Details</summary>
Motivation: 敏捷开发方法强调灵活性和协作，但很多软件开发团队，尤其在远程工作环境下，依然面临沟通和协作的难题。因此，研究协作工具如Slack、Microsoft Teams和Confluence在敏捷软件项目中的作用具有实际意义。

Method: 本文通过综述现有文献和实际应用，分析上述协作工具如何契合敏捷原则、促进迭代开发，并考察它们如何在大小型项目中提升任务发起与跟踪的效率。

Result: 研究发现，Slack、Microsoft Teams和Confluence可提升团队任务协同、加强知识共享，并有助于在跨职能团队中践行敏捷价值观。它们促进了高效的沟通与任务管理，从而提升项目生产力。

Conclusion: Slack、Microsoft Teams和Confluence是敏捷与软件开发项目中不可或缺的协作工具，有效支持了敏捷开发所需的沟通、知识交流与任务协同，为团队带来更高的生产力和更好的项目成果。

Abstract: The purpose of this review is to understand the importance of collaboration
tools which are Slack, Microsoft Teams, Confluence in Agile and software
projects. Agile methodologies rely on flexibility, using cycles and integration
throughout various levels of developing cycles. However, it is still a great
problem for many teams to collaborate and communicate even if staff members and
teams are working remotely. In terms of collaboration, the applications and
technologies mean better organization of work, increased mutually
understandable openness and fast and efficient inter team and interpersonal
interactions to enhance results of projects into productivity. This paper
examines how these tools fit the Agile principles, how they facilitate
iterative development, and encouraging effective initiation and tracking of
tasks in small and large projects. The insights focus on how Slack, Microsoft
Teams, and Confluence are essential for gaining better task coordination,
supporting knowledge sharing, and adopting agile values across cross-functional
contexts.

</details>


### [6] [Model Discovery and Graph Simulation: A Lightweight Alternative to Chaos Engineering](https://arxiv.org/abs/2506.11176)
*Anatoly A. Krasnovsky,Alexander Zorkin*

Main category: cs.SE

TL;DR: 提出用追踪数据自动提取依赖关系图，并通过模拟预测微服务系统弹性，结果表明即使简单的自动图模型也能准确估算系统可用性，减少对昂贵故障注入实验的依赖。


<details>
  <summary>Details</summary>
Motivation: 微服务应用由于服务间的高度依赖，容易发生级联故障。现有的弹性保障手段通常需要在接近真实环境中进行故障注入实验，代价高昂。

Method: 提出了一种名为“模型发现”（model discovery）的自动化CI/CD步骤，能够通过追踪数据自动提取实时依赖图，并基于此图利用蒙特卡洛模拟进行故障仿真和弹性评估；并结合实际混沌实验进行对比验证。

Result: 发现通过自动发现的依赖图构建的模型在故障弹性预测上与真实系统非常接近。无副本时仿真与实验弹性分别为0.161和0.186；有副本时仿真与实验都收敛到0.305（平均绝对误差≤0.0004）。

Conclusion: 自动化生成的依赖关系图可高保真地预估微服务可用性，能为系统设计提供快速的弹性洞察，而无需全面的故障注入实验。

Abstract: Microservice applications are prone to cascading failures because of dense
inter-service dependencies. Ensuring resilience usually demands fault-injection
experiments in production-like setups. We propose \textit{model discovery} --
an automated CI/CD step that extracts a live dependency graph from trace data
-- and show that this lightweight representation is sufficient for accurate
resilience prediction. Using the DeathStarBench Social Network, we build the
graph, simulate failures via Monte-Carlo, and run matching chaos experiments on
the real system. The graph model closely matches reality: with no replication,
16 trials yield an observed resilience of 0.186 versus a predicted 0.161; with
replication, both observed and predicted values converge to 0.305 (mean
absolute error \leq 0.0004). These results indicate that even a simple,
automatically discovered graph can estimate microservice availability with high
fidelity, offering rapid design-time insight without full-scale failure
testing.

</details>


### [7] [LeanExplore: A search engine for Lean 4 declarations](https://arxiv.org/abs/2506.11085)
*Justin Asher*

Main category: cs.SE

TL;DR: LeanExplore是一个支持语义检索的Lean 4库声明搜索引擎，结合多种排序与语义理解模型，产品开放多平台接入，便利Lean用户和AI助手查询，提升数学与定理证明相关研发的效率。


<details>
  <summary>Details</summary>
Motivation: Lean 4生态系统的持续扩展使得在庞大的库中查找和导航变得愈发困难，用户和开发者迫切需要高效工具来检索相关声明和知识。

Method: 论文提出了一个名为LeanExplore的搜索引擎，采用多源语义嵌入模型、BM25+关键词匹配和基于PageRank的评分相结合的混合排序策略，实现对Lean 4多个主流库（如Batteries、Init、Lean、Mathlib、PhysLean和Std）中声明的高效语义搜索，并支持多终端访问（网站、Python API、本地部署）。

Result: LeanExplore可以对形式和非形式声明进行语义检索，支持与大型语言模型（LLM）集成，实现AI助手查询Lean声明或辅助定理证明。作者还公开了数据库下载和多平台接入能力，展示了架构、数据处理和应用潜力。

Conclusion: LeanExplore为Lean 4生态带来高效的声明检索工具，有助于提升开发者工作流与AI驱动的数学研究效率，并促进库之间的知识互联互通。

Abstract: The expanding Lean 4 ecosystem poses challenges for navigating its vast
libraries. This paper introduces LeanExplore, a search engine for Lean 4
declarations. LeanExplore enables users to semantically search for statements,
both formally and informally, across select Lean 4 packages (including
Batteries, Init, Lean, Mathlib, PhysLean, and Std). This search capability is
powered by a hybrid ranking strategy, integrating scores from a multi-source
semantic embedding model (capturing conceptual meaning from formal Lean code,
docstrings, AI-generated informal translations, and declaration titles), BM25+
for keyword-based lexical relevance, and a PageRank-based score reflecting
declaration importance and interconnectedness. The search engine is accessible
via a dedicated website (https://www.leanexplore.com/) and a Python API
(https://github.com/justincasher/lean-explore). Furthermore, the database can
be downloaded, allowing users to self-host the service. LeanExplore integrates
easily with LLMs via the model context protocol (MCP), enabling users to chat
with an AI assistant about Lean declarations or utilize the search engine for
building theorem-proving agents. This work details LeanExplore's architecture,
data processing, functionalities, and its potential to enhance Lean 4 workflows
and AI-driven mathematical research

</details>


### [8] [CoMRAT: Commit Message Rationale Analysis Tool](https://arxiv.org/abs/2506.10986)
*Mouna Dhaouadi,Bentley James Oakes,Michalis Famelis*

Main category: cs.SE

TL;DR: 本文提出并实现了 CoMRAT 工具，可以自动分析 GitHub commit message 中的决策和理由句子，辅助研究与开发，评估显示其工具具有较好实用性。


<details>
  <summary>Details</summary>
Motivation: 虽然 commit message 中蕴含丰富决策与理由信息，但相关分析研究仍显不足，因此开发了一种工具帮助深入挖掘与利用这些信息。

Method: 提出并实现了 CoMRAT 工具，能够分析 GitHub 提交信息中的决策和理由类句子，并用于指标生成和量化分析。

Result: 初步评估显示，CoMRAT 有助于研究者进行相关指标分析，也方便开发者自我评估 commit message 的理由成分覆盖情况。

Conclusion: CoMRAT 工具对研究者分析、开发者自查 commit 信息均表现有用且易用，具有实际应用价值。

Abstract: In collaborative open-source development, the rationale for code changes is
often captured in commit messages, making them a rich source of valuable
information. However, research on rationale in commit messages remains limited.
In this paper, we present CoMRAT, a tool for analyzing decision and rationale
sentences rationale in commit messages. CoMRAT enables a) researchers to
produce metrics and analyses on rationale information in any Github module, and
b) developers to check the amount of rationale in their commit messages. A
preliminary evaluation suggests the tool's usefulness and usability in both
these research and development contexts.

</details>


### [9] [Contract-based Verification of Digital Twins](https://arxiv.org/abs/2506.10993)
*Muhammad Naeem,Cristina Seceleanu*

Main category: cs.SE

TL;DR: 本文提出基于模型检验的自动化黑箱验证方法，提升了神经网络数字孪生模型的验证效率和准确性，并在锅炉系统场景下验证了其实用性和有效性。


<details>
  <summary>Details</summary>
Motivation: 数字孪生在工业领域应用广泛，但其模型尤其是基于神经网络的数字孪生模型验证难度较大，尤其因为涉及庞大的数据集和“黑箱”结构，缺乏系统性验证机制。

Method: 提出了一种创新的方法，将模型检验（model checking）引入对基于神经网络的数字孪生模型的“黑箱”验证流程中。通过定义系统级契约，并利用UPPAAL模型检验器对Simulink实现的数字孪生进行自动化仿真与契约验证，无需了解模型具体内部技术细节。

Result: 该方法能有效找出数字孪生模型行为不符合契约要求的场景。以锅炉系统为案例，成功通过契约验证发现了预测错误。

Conclusion: 将模型检验技术嵌入数字孪生模型验证流程中，可以提升其模型验证的系统性和自动化程度，有助于其持续改进。该方法无需获取或理解数字孪生内部细节，对于工业应用具有推广意义。

Abstract: Digital twins are becoming powerful tools in industrial applications,
offering virtual representations of cyber-physical systems. However,
verification of these models remains a significant challenge due to the
potentially large datasets used by the digital twin. This paper introduces an
innovative methodology for verifying neural network-based digital twin models,
in a black-box fashion, by integrating model checking into the process. The
latter relies on defining and applying system-level contracts that capture the
system's requirements, to verify the behavior of digital twin models,
implemented in Simulink. We develop an automated solution that simulates the
digital twin model for certain inputs, and feeds the predicted outputs together
with the inputs to the contract model described as a network of timed automata
in the UPPAAL model checker. The latter verifies whether the predicted outputs
fulfill the specified contracts. This approach allows us to identify scenarios
where the digital twin's behavior fails to meet the contracts, without
requiring the digital twin's design technicalities. We apply our method to a
boiler system case study for which we identify prediction errors via contract
verification. Our work demonstrates the effectiveness of integrating model
checking with digital twin models for continuous improvement.

</details>


### [10] [Chain of Draft for Software Engineering: Challenges in Applying Concise Reasoning to Code Tasks](https://arxiv.org/abs/2506.10987)
*Shaoyi Yang*

Main category: cs.SE

TL;DR: 本文提出并验证了专为代码任务设计的 CoD 变体，相比传统 CoT，能在代码质量基本不变的前提下大幅节省推理 token 和成本，适合追求效率的软件开发应用。


<details>
  <summary>Details</summary>
Motivation: 目前 LLM 解决复杂代码任务时中间推理冗长，导致延迟高和成本高。需要一种既能保留推理质量又能提升效率的新方法。

Method: 扩展和设计了多种针对代码任务的 Chain of Draft (CoD) 变体，基于 SWE-bench 基准的 300 个样本进行实验，对效率与多维质量进行了评估。

Result: 所有 CoD 变体消耗的 token 显著少于 Chain of Thought (CoT)，其中 Baseline CoD 仅为 CoT 的 55.4%。在代码正确性、兼容性、可维护性等关键指标上，CoD 变体保持了 CoT 90% 以上的质量。同时相较于数学任务，软件工程任务的 efficiency gain 低于原始 CoD 论文（即 45% vs. 92.4%），因其复杂性和上下文依赖更强。

Conclusion: CoD 方法在软件工程中能够大幅提升 LLM 推理效率，在保持较高代码质量的同时显著减少 token 消耗，适合注重效率的软件开发场景。

Abstract: Large language models (LLMs) have become vital tools for software
development, but they often require verbose intermediate reasoning for complex
code tasks, leading to high latency and costs. This research extends the Chain
of Draft (CoD) method to software engineering, designing and evaluating
multiple CoD variants tailored for code tasks. Through comprehensive
experiments on all 300 samples from the SWE-bench benchmark, we found that all
CoD variants used significantly fewer tokens than Chain of Thought (CoT), with
Baseline CoD being most efficient at 55.4% of CoT's tokens. While this
represents substantial efficiency gains - translating to approximately 45%
reduction in processing time and API costs - it differs from the extreme 7.6%
reported in the original CoD paper for mathematical reasoning. This difference
stems from the inherent complexity and context-dependency of software tasks,
which require more detailed reasoning to maintain solution quality. Our
multi-dimensional quality assessment revealed that CoD variants maintain over
90% of CoT's code quality across key metrics including correctness,
compatibility, and maintainability, making them practical alternatives for
real-world development scenarios where efficiency matters. This research
demonstrates how domain-specific characteristics influence prompting strategy
effectiveness and provides a framework for balancing efficiency with solution
quality in software engineering applications. Our findings offer practical
guidance for optimizing LLM-based development workflows through appropriate
prompting strategy selection based on project requirements.

</details>


### [11] [You Only Train Once: A Flexible Training Framework for Code Vulnerability Detection Driven by Vul-Vector](https://arxiv.org/abs/2506.10988)
*Bowen Tian,Zhengyang Xu,Mingqiang Wu,Songning Lai,Yutai Yue*

Main category: cs.SE

TL;DR: 本文提出了YOTO框架，通过参数融合技术实现多种漏洞检测模型的集成，解决了需要大量标注数据和频繁重训的问题，显著减轻了模型更新带来的资源压力，提升了检测新漏洞的效率。


<details>
  <summary>Details</summary>
Motivation: 随着计算机应用在各行业的广泛融合，代码库中的安全漏洞带来了重大风险。现代软件工程的复杂性和软件生态系统的多样性，使得传统的手工漏洞检测方式效率低下，推动了自动化工具的发展。深度学习方法尽管准确率高，但需要大量标注数据和长时间训练，新漏洞层出不穷导致模型频繁重训，资源消耗大，限制了实际应用。

Method: 本文提出了YOTO（You Only Train Once）框架。YOTO通过参数融合技术，实现了多种漏洞检测模型的集成，无需联合训练。此方法可以针对新出现的漏洞快速适配，显著减少模型更新所需的时间和计算资源。

Result: YOTO框架能够极大地减少模型训练和更新的资源消耗，同时允许针对新漏洞类型的快速适配，提升了自动化漏洞检测工具的实用性和扩展性。

Conclusion: YOTO框架通过创新的参数融合方式，解决了深度学习漏洞检测在大规模实际应用中面临的高训练和更新成本问题，对自动化漏洞检测的效率与灵活性具有显著提升作用。

Abstract: With the pervasive integration of computer applications across industries,
the presence of vulnerabilities within code bases poses significant risks. The
diversity of software ecosystems coupled with the intricate nature of modern
software engineering has led to a shift from manual code vulnerability
identification towards the adoption of automated tools. Among these, deep
learning-based approaches have risen to prominence due to their superior
accuracy; however, these methodologies encounter several obstacles. Primarily,
they necessitate extensive labeled datasets and prolonged training periods, and
given the rapid emergence of new vulnerabilities, the frequent retraining of
models becomes a resource-intensive endeavor, thereby limiting their
applicability in cutting-edge scenarios. To mitigate these challenges, this
paper introduces the \underline{\textbf{YOTO}}--\underline{\textbf{Y}}ou
\underline{\textbf{O}}nly \underline{\textbf{T}}rain \underline{\textbf{O}}nce
framework. This innovative approach facilitates the integration of multiple
types of vulnerability detection models via parameter fusion, eliminating the
need for joint training. Consequently, YOTO enables swift adaptation to newly
discovered vulnerabilities, significantly reducing both the time and
computational resources required for model updates.

</details>


### [12] [Prompt engineering and framework: implementation to increase code reliability based guideline for LLMs](https://arxiv.org/abs/2506.10989)
*Rogelio Cruz,Jonatan Contreras,Francisco Guerrero,Ezequiel Rodriguez,Carlos Valdez,Citlali Carrillo*

Main category: cs.SE

TL;DR: 本文提出了一种新提示模板，大幅提升LLM生成Python代码的质量和正确性，效果超过常用提示方法且计算资源消耗更低，具备实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 提升大型语言模型（LLM）生成准确Python代码的能力，解决现有提示方法在代码质量、正确性及计算资源消耗上的不足。

Method: 提出了一种新颖的提示模板（prompt template）方法，通过合理设计提升生成代码的质量和正确性。该方法在HumanEval数据集上，针对两种先进的LLM进行实验评估，并与zero-shot和Chain-of-Thought（CoT）提示方法进行比较。

Result: 新方法在Pass@k指标上优于zero-shot和CoT方法，同时大幅减少了Token使用量，降低了计算资源需求和环境影响。

Conclusion: 专门定制的提示策略能够有效提升LLM的代码生成表现，同时兼顾资源节省和环境友好。此方法可为AI自动编程等领域带来更广泛的应用前景。

Abstract: In this paper, we propose a novel prompting approach aimed at enhancing the
ability of Large Language Models (LLMs) to generate accurate Python code.
Specifically, we introduce a prompt template designed to improve the quality
and correctness of generated code snippets, enabling them to pass tests and
produce reliable results. Through experiments conducted on two state-of-the-art
LLMs using the HumanEval dataset, we demonstrate that our approach outperforms
widely studied zero-shot and Chain-of-Thought (CoT) methods in terms of the
Pass@k metric. Furthermore, our method achieves these improvements with
significantly reduced token usage compared to the CoT approach, making it both
effective and resource-efficient, thereby lowering the computational demands
and improving the eco-footprint of LLM capabilities. These findings highlight
the potential of tailored prompting strategies to optimize code generation
performance, paving the way for broader applications in AI-driven programming
tasks.

</details>


### [13] [On the Effectiveness of the 'Follow-the-Sun' Strategy in Mitigating the Carbon Footprint of AI in Cloud Instances](https://arxiv.org/abs/2506.10990)
*Roberto Vergallo,Luís Cruz,Alessio Errico,Luca Mainetti*

Main category: cs.SE

TL;DR: 本研究首次以实验证据表明，通过将AI计算任务动态调整至清洁能源充足的地区（即FtS策略），可有效减少14.6%-16.3%的碳排放，且不影响训练时间，为实现AI绿色低碳提供了可行途径。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能（AI）算力消耗巨大，其碳足迹引发了广泛关注。为减少计算任务的碳排放，理论上可采用“Follow-the-Sun（FtS）”模型，通过将工作负载动态迁移至清洁能源产地以优化能源利用。然而关于FtS应用于AI算力碳减排方面，缺乏系统的科学实证。本文旨在填补该研究空白。

Method: 作者设计了一个部分合成实验场景，对四种异常检测领域的AI算法进行基准测试。实验考虑了四种情况：无策略、FtS、Flexible Start、Pause and Resume。研究利用2021年7个欧洲城市的历史碳强度数据，分别测量了各策略下的碳排放差异。

Result: 实验结果显示，FtS策略平均可减少14.6%的碳排放，最高可达16.3%，同时还能保持AI模型训练时长基本不变。

Conclusion: FtS策略可以有效减少AI模型训练所产生的碳排放，并不会显著影响训练效率。该策略在AI绿色算力方面具有实际应用潜力。

Abstract: 'Follow-the-Sun' (FtS) is a theoretical computational model aimed at
minimizing the carbon footprint of computer workloads. It involves dynamically
moving workloads to regions with cleaner energy sources as demand increases and
energy production relies more on fossil fuels. With the significant power
consumption of Artificial Intelligence (AI) being a subject of extensive
debate, FtS is proposed as a strategy to mitigate the carbon footprint of
training AI models. However, the literature lacks scientific evidence on the
advantages of FtS to mitigate the carbon footprint of AI workloads. In this
paper, we present the results of an experiment conducted in a partial synthetic
scenario to address this research gap. We benchmarked four AI algorithms in the
anomaly detection domain and measured the differences in carbon emissions in
four cases: no strategy, FtS, and two strategies previously introduced in the
state of the art, namely Flexible Start and Pause and Resume. To conduct our
experiment, we utilized historical carbon intensity data from the year 2021 for
seven European cities. Our results demonstrate that the FtS strategy not only
achieves average reductions of up to 14.6% in carbon emissions (with peaks of
16.3%) but also helps in preserving the time needed for training.

</details>


### [14] [What is Business Process Automation Anyway?](https://arxiv.org/abs/2506.10991)
*Hoang Vu,Henrik Leopold,Han van der Aa*

Main category: cs.SE

TL;DR: 本文系统分析了18家主流供应商的业务流程自动化能力，揭示行业自动化已超越RPA，未来还有更广阔的发展空间。


<details>
  <summary>Details</summary>
Motivation: 越来越多的组织希望提升业务流程的自动化水平。以往的自动化主要关注体力劳动，而当前的自动化更加聚焦于数字化形式，尤其是人与计算机交互相关的工作。现有学术文献主要集中在机器人流程自动化（RPA），但实际行业中的自动化能力远不止于此。

Method: 本文通过对Gartner鉴定出的18家主流业务流程自动化解决方案供应商进行结构化市场分析，系统梳理了行业中的自动化能力。

Result: 研究展示了目前主流工业供应商所提供的业务流程自动化能力，并对自动化的不同类型和方面进行了全面梳理；同时指出了未来具有发展前景的方向。

Conclusion: 主流供应商在业务流程自动化方面的能力远超RPA，覆盖众多自动化类型和维度，这为行业和后续研究提供了丰富的参考。

Abstract: Many organizations strive to increase the level of automation in their
business processes. While automation historically was mainly concerned with
automating physical labor, current automation efforts mostly focus on
automation in a digital manner, thus targeting work that is related to the
interaction between humans and computers. This type of automation, commonly
referred to as business process automation, has many facets. Yet, academic
literature mainly focuses on Robotic Process Automation, a specific automation
capability. Recognizing that leading vendors offer automation capabilities
going way beyond that, we use this paper to develop a detailed understanding of
business process automation in industry. To this end, we conduct a structured
market analysis of the 18 predominant vendors of business process automation
solutions as identified by Gartner. As a result, we provide a comprehensive
overview of the business process automation capabilities currently offered by
industrial vendors. We show which types and facets of automation exist and
which aspects represent promising directions for the future.

</details>


### [15] [Towards a Theory on Process Automation Effects](https://arxiv.org/abs/2506.10992)
*Hoang Vu,Jennifer Haase,Henrik Leopold,Jan Mendling*

Main category: cs.SE

TL;DR: 本文综述人-自动化交互文献，提出了优化流程自动化的人机协作模型，并为未来研究提供了方向和建议。


<details>
  <summary>Details</summary>
Motivation: 尽管流程自动化对企业效率提升很重要，但对于自动化投入运营后的实际影响，现有文献关注不够，因此需要深入探讨人和自动化系统的交互机制。

Method: 通过综述人-自动化交互相关领域的文献，归纳了不同行业的研究发现，进而提出了流程自动化影响的相关命题。

Result: 分析出了影响流程自动化成效的人机互动要素，总结了对组织应用的洞察与建议，并提出了值得进一步研究的问题。

Conclusion: 本文提出了一个有效的人机协作模型，帮助组织优化流程自动化的应用，并为后续学术研究提出了新问题。

Abstract: Process automation is a crucial strategy for improving business processes,
but little attention has been paid to the effects that automation has once it
is operational. This paper addresses this research problem by reviewing the
literature on human-automation interaction. Although many of the studies in
this field have been conducted in different domains, they provide a foundation
for developing propositions about process automation effects. Our analysis
focuses on how humans perceive automation technology when working within a
process, allowing us to propose an effective engagement model between
technology, process participants, process managers, and software developers.
This paper offers insights and recommendations that can help organizations
optimize their use of process automation. We further derive novel research
questions for a discourse within the process automation community.

</details>


### [16] [Improving Software Team Communication Through Social Interventions in Project Management Tools](https://arxiv.org/abs/2506.10994)
*April Clarke*

Main category: cs.SE

TL;DR: 本文提出用社交网络分析方法诊断并改善大学软件工程小组项目中的沟通和协调，开发并验证相应的项目管理工具功能以促进更有效的团队合作。


<details>
  <summary>Details</summary>
Motivation: 现有项目小组普遍缺乏有效沟通和均衡贡献，影响项目成功。大学课程是培养学生相关能力的场所，但缺乏有效的方法引导学生提升沟通协作。

Method: 首先评估社交网络分析在发现团队沟通改进空间的适宜性，其次开发能帮助学生识别并改善沟通问题的项目管理工具功能，最后在实际软件工程小组项目中进行评估。

Result: 预期结果是开发并验证一套基于社交网络分析的项目管理工具功能，能够提升学生小组在沟通与协调方面的表现。

Conclusion: 该论文计划证明基于社交网络分析的项目管理工具功能可以有效提升学生项目团队的沟通与协调能力。

Abstract: Productive software engineering teams require effective communication and
balanced contributions between team members. However, teams are often
ineffective at these skills, which is detrimental to project success.
Project-based university courses are an opportunity for students to practise
these skills, but we have yet to establish how we can guide students towards
improving their communication and coordination. We aim to develop project
management tool features, informed by social network analysis, that nudge
students in software engineering group projects towards beneficial behaviours.
To do this, we will first evaluate the suitability of social network analysis
techniques for identifying areas of improvement in teams' communication. Then,
we will develop features in a project management tool that aid students in
identifying and addressing these areas of improvement, and evaluate them in the
context of a software engineering group project.

</details>


### [17] [Evaluating Small-Scale Code Models for Code Clone Detection](https://arxiv.org/abs/2506.10995)
*Jorge Martinez-Gil*

Main category: cs.SE

TL;DR: 本文系统评测了六种最新小型代码模型在五大数据集上的代码克隆检测性能。发现模型总体表现优异，但对于结构类似且功能不同的代码对，仍存检测难题，显示研究仍需在此领域深入。


<details>
  <summary>Details</summary>
Motivation: 代码克隆检测对软件维护和重构非常重要，但即使使用最新的代码模型，结构相似但功能不同的代码对检测仍是巨大挑战。

Method: 系统评测了六种最新小型代码模型（CodeBERT、GraphCodeBERT、Salesforce T5、UniXCoder、PLBART、Polycoder）在五个数据集（BigCloneBench, CodeJam, Karnalim, POJ104, PoolC）上的克隆检测表现，通过准确率、精确率、召回率、F1-score等标准指标比较模型。

Result: 大多数模型在各项度量指标上表现良好，但在处理外观相似但功能不同的代码时，仍有部分克隆难以检测。

Conclusion: 现有小型代码模型对大部分代码克隆检测任务效果不错，但针对结构相似且语义不同的极端情况，仍存在显著挑战。

Abstract: Detecting code clones is relevant to software maintenance and code
refactoring. This challenge still presents unresolved cases, mainly when
structural similarity does not reflect functional equivalence, though recent
code models show promise. Therefore, this research aims to systematically
measure the performance of several newly introduced small code models in
classifying code pairs as clones or non-clones. The evaluation is based on five
datasets: BigCloneBench, CodeJam, Karnalim, POJ104, and PoolC, as well as six
code models: CodeBERT, GraphCodeBERT, Salesforce T5, UniXCoder, PLBART, and
Polycoder. Most models performed well across standard metrics, including
accuracy, precision, recall, and F1-score. However, a marginal fraction of
clones remains challenging to detect, especially when the code looks similar
but performs different operations. The source code that illustrates our
approach is available at:
https://github.com/jorge-martinez-gil/small-code-models

</details>


### [18] [Evaluating LLMs for Visualization Tasks](https://arxiv.org/abs/2506.10996)
*Saadiq Rauf Khan,Vinit Chandak,Sougata Mukherjea*

Main category: cs.SE

TL;DR: 本文评估了主流大语言模型在可视化代码生成和可视化理解任务中的表现，发现其具备一定能力但仍有局限，对今后改进LLM和可视化系统有启发作用。


<details>
  <summary>Details</summary>
Motivation: 信息可视化能够帮助用户从复杂数据中获取洞见。当前，大型语言模型（LLMs）在许多任务上表现出色，因此该论文探索LLM在可视化领域的能力。

Method: 作者对多种流行LLM进行了能力展示，通过简单提示让它们生成可视化代码，并评估它们通过回答基础问题来理解常见可视化的能力。

Result: LLM能够为部分可视化任务生成代码，并能解答可视化相关问题，但在多方面仍显现出局限。

Conclusion: LLM在信息可视化中的应用展现了一定潜力，但也存在不足，这些发现可以为LLM和信息可视化系统的改进提供借鉴。

Abstract: Information Visualization has been utilized to gain insights from complex
data. In recent times, Large Language Models (LLMs) have performed very well in
many tasks. In this paper, we showcase the capabilities of different popular
LLMs to generate code for visualization based on simple prompts. We also
analyze the power of LLMs to understand some common visualizations by answering
simple questions. Our study shows that LLMs could generate code for some
visualizations as well as answer questions about them. However, LLMs also have
several limitations. We believe that our insights can be used to improve both
LLMs and Information Visualization systems.

</details>


### [19] [A Theory-driven Interpretation and Elaboration of Verification and Validation](https://arxiv.org/abs/2506.10997)
*Hanumanthrao Kannan,Alejandro Salado*

Main category: cs.SE

TL;DR: 本文基于动态认知模态逻辑，提出了V&V的形式理论，消除了传统实践中的模糊之处，并加强了系统工程中V&V的方法学基础。


<details>
  <summary>Details</summary>
Motivation: 现有系统工程中的验证与确认（V&V）实践在概念层面存在模糊，缺乏精确的定义和统一的理论基础。

Method: 采用动态认知模态逻辑，对V&V进行形式化建模，建立对V&V的精确定义，并推导相关定理以阐述其概念基础。

Result: 提出了V&V的严格理论，明确了它们在系统知识确认与建构中的作用，并将V&V纳入知识生成的正式框架。该理论消除了传统V&V实践中的不明确性。

Conclusion: 本工作为系统工程中的V&V提供了正式理论基础，有助于提升V&V过程的精准性与一致性，对学术及实际应用均有积极影响。

Abstract: This paper presents a formal theory of verification and validation (V&V)
within systems engineering, grounded in the axiom that V&V are fundamentally
knowledge-building activities. Using dynamic epistemic modal logic, we develop
precise definitions of verification and validation, articulating their roles in
confirming and contextualizing knowledge about systems. The theory formalizes
the interplay between epistemic states, evidence, and reasoning processes,
allowing for the derivation of theorems that clarify the conceptual
underpinnings of V&V. By providing a formal foundation, this work addresses
ambiguities in traditional V&V practices, offering a structured framework to
enhance precision and consistency in systems engineering methodologies. The
insights gained have implications for both academic research and practical
applications, fostering a deeper understanding of V&V as critical components of
engineering knowledge generation.

</details>


### [20] [Towards Automated Formal Verification of Backend Systems with LLMs](https://arxiv.org/abs/2506.10998)
*Kangping Xu,Yifan Luo,Yang Yuan,Andrew Chi-Chih Yao*

Main category: cs.SE

TL;DR: 论文提出将后端代码转化为形式化逻辑并用LLM自动验证，从而自动化地完成一半以上的测试需求，显著降低成本并易于扩展，为AI赋能软件测试提供了前景。


<details>
  <summary>Details</summary>
Motivation: 现有自动化测试手段在测试覆盖、普适可靠性及业务逻辑理解上存在不足，难以替代人工工程师。动机在于探索可大幅减少人工测试需求、提升可靠性的新型方法。

Method: 该方法将Scala后端代码通过函数式编程和类型系统翻译为Lean的形式表示，然后自动生成描述API及数据库操作预期行为的定理，并利用大语言模型（LLM）作为证明器进行验证。证明通过即代表逻辑正确，无需进一步测试；证明失败或反命题成立时，则定位为bug，无法证明时可由人工介入。

Result: 实验表明该方法能够形式化验证现实后端系统中超过50%的测试需求，每个API平均验证成本仅2.19美元，大幅优于人工测试，且通过并行执行可轻松扩展，提升整体工程效率。

Conclusion: 提出的方法能够自动化并正式验证超过50%的测试需求，大幅减少软件测试工程师的工作量，同时在成本和可扩展性上优于人工测试，展示了AI驱动自动化软件测试的巨大潜力。

Abstract: Software testing plays a critical role in ensuring that systems behave as
intended. However, existing automated testing approaches struggle to match the
capabilities of human engineers due to key limitations such as test locality,
lack of general reliability, and business logic blindness. In this work, we
propose a novel framework that leverages functional programming and type
systems to translate Scala backend code into formal Lean representations. Our
pipeline automatically generates theorems that specify the intended behavior of
APIs and database operations, and uses LLM-based provers to verify them. When a
theorem is proved, the corresponding logic is guaranteed to be correct and no
further testing is needed. If the negation of a theorem is proved instead, it
confirms a bug. In cases where neither can be proved, human intervention is
required. We evaluate our method on realistic backend systems and find that it
can formally verify over 50% of the test requirements, which suggests that half
of a testing engineer's workload can be automated. Additionally, with an
average cost of only $2.19 per API, LLM-based verification is significantly
more cost-effective than manual testing and can be scaled easily through
parallel execution. Our results indicate a promising direction for scalable,
AI-powered software testing, with the potential to greatly improve engineering
productivity as models continue to advance.

</details>


### [21] [Automated Validation of COBOL to Java Transformation](https://arxiv.org/abs/2506.10999)
*Atul Kumar,Diptikalyan Saha,Toshikai Yasue,Kohichi Ono,Saravanan Krishnan,Sandeep Hans,Fumiko Satoh,Gerald Mitchell,Sachin Kumar*

Main category: cs.SE

TL;DR: 本文提出基于符号执行的自动化测试框架，用于验证AI自动翻译的遗留代码（如COBOL到Java）的语义等价性，并可辅助修复问题、优化AI模型。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI和大型语言模型技术的发展，用AI自动将如COBOL这样的遗留语言代码转换为现代语言（如Java或Python）成为可能，但转换后的代码正确性无法保证。为确保翻译后的程序能与原程序语义等价，需要有效的验证工具。

Method: 作者提出了一套框架和工具，通过符号执行生成针对COBOL源程序的单元测试，还能自动模拟外部资源调用。随后，将这些单元测试等价地转化为Java（JUnit）测试用例，并运行这些测试以验证原始COBOL程序和翻译后的Java程序的语义等价性。

Result: 该框架能够有效验证COBOL与Java翻译代码的等价性，还能辅助修复发现的问题，并为AI模型提供反馈以提升翻译质量。

Conclusion: 作者提出并实现了一个自动化框架，通过符号执行和等价测试，有效验证了AI翻译的遗留代码的正确性，增强了AI在企业代码迁移中的可信度。

Abstract: Recent advances in Large Language Model (LLM) based Generative AI techniques
have made it feasible to translate enterpriselevel code from legacy languages
such as COBOL to modern languages such as Java or Python. While the results of
LLM-based automatic transformation are encouraging, the resulting code cannot
be trusted to correctly translate the original code. We propose a framework and
a tool to help validate the equivalence of COBOL and translated Java. The
results can also help repair the code if there are some issues and provide
feedback to the AI model to improve. We have developed a
symbolic-execution-based test generation to automatically generate unit tests
for the source COBOL programs which also mocks the external resource calls. We
generate equivalent JUnit test cases with equivalent mocking as COBOL and run
them to check semantic equivalence between original and translated programs.

</details>


### [22] [Ever-Improving Test Suite by Leveraging Large Language Models](https://arxiv.org/abs/2506.11000)
*Ketai Qiu*

Main category: cs.SE

TL;DR: 作者提出了E-Test方法，利用大语言模型自动增强测试套件，实验表明其效果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 长期维护的软件系统需要通过反映实际使用情况的测试用例来持续保证其质量。

Method: 提出了一种名为E-Test的方法，利用大语言模型识别已经测试、未测试和易出错的单元执行场景，并据此增量式地扩展测试套件。

Result: 实验结果显示，E-Test在识别测试不足的行为和优化测试套件方面，优于主要现有技术方法。

Conclusion: E-Test有效改进测试套件的覆盖与质量，是增强实际生产环境测试的有效工具。

Abstract: Augmenting test suites with test cases that reflect the actual usage of the
software system is extremely important to sustain the quality of long lasting
software systems. In this paper, we propose E-Test, an approach that
incrementally augments a test suite with test cases that exercise behaviors
that emerge in production and that are not been tested yet. E-Test leverages
Large Language Models to identify already-tested, not-yet-tested, and
error-prone unit execution scenarios, and augment the test suite accordingly.
Our experimental evaluation shows that E-Test outperforms the main
state-of-the-art approaches to identify inadequately tested behaviors and
optimize test suites.

</details>


### [23] [Rethinking Technological Readiness in the Era of AI Uncertainty](https://arxiv.org/abs/2506.11001)
*S. Tucker Browne,Mark M. Bailey*

Main category: cs.SE

TL;DR: 传统技术成熟度评级无法充分评估军事AI的实际准备度。本文提出针对AI特性的专用成熟度框架，并通过实际工具验证其可行性，为军用AI部署和风险评估提供了新标准。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能在军事作战系统应用前景巨大，但传统技术成熟度评估方法难以有效衡量AI在军用系统中的关键风险和挑战。

Method: 提出了新的人工智能成熟度评估框架（AI Readiness Framework），基于现有数据评估工具与测试实践，将传统技术成熟度等级（TRL）理念扩展并专门针对AI系统进行调整。

Result: 通过应用当前的数据评估工具和测试方法，验证该AI成熟度评估框架可在近期内实际实施。

Conclusion: 该框架为军方决策者提供了更完善的AI系统可靠性、安全性及作战适用性的把控标准，有助于 AI 系统的合理部署和风险管控，推动国防技术管理与评估工作发展。

Abstract: Artificial intelligence (AI) is poised to revolutionize military combat
systems, but ensuring these AI-enabled capabilities are truly mission-ready
presents new challenges. We argue that current technology readiness assessments
fail to capture critical AI-specific factors, leading to potential risks in
deployment. We propose a new AI Readiness Framework to evaluate the maturity
and trustworthiness of AI components in military systems. The central thesis is
that a tailored framework - analogous to traditional Technology Readiness
Levels (TRL) but expanded for AI - can better gauge an AI system's reliability,
safety, and suitability for combat use. Using current data evaluation tools and
testing practices, we demonstrate the framework's feasibility for near-term
implementation. This structured approach provides military decision-makers with
clearer insight into whether an AI-enabled system has met the necessary
standards of performance, transparency, and human integration to be deployed
with confidence, thus advancing the field of defense technology management and
risk assessment.

</details>


### [24] [Notes On Writing Effective Empirical Software Engineering Papers: An Opinionated Primer](https://arxiv.org/abs/2506.11002)
*Roberto Verdecchia,Justus Bogner*

Main category: cs.SE

TL;DR: 本文面向经验软件工程领域的学生和初学者，总结了作者主观但实用的论文写作建议，旨在降低写作门槛，并让更多写作者受益。


<details>
  <summary>Details</summary>
Motivation: 在经验软件工程（ESE）领域，好的科学写作实践较少被讨论和记录，但却常作为会议与期刊评审的隐含标准。作者为了解决初学者对ESE论文写作的困惑与压力，决定整理个人和主观的写作建议。

Method: 作者以教育为首要出发点，结合自身指导本科、硕士及博士生写作的经验，主观总结了一套写作建议，形成一份面向学生和初学写作者的ESE论文写作指南。

Result: 本文形成了一份以主观经验为基础、强调实用性的ESE论文写作建议与指导，旨在帮助学生及其他写作者更好地掌握写作方法。

Conclusion: 虽然该指南是基于作者自己的经验和观点，但其写法和建议已被作者群体证实有效，期待能为读者带来实际帮助。

Abstract: While mastered by some, good scientific writing practices within Empirical
Software Engineering (ESE) research appear to be seldom discussed and
documented. Despite this, these practices are implicit or even explicit
evaluation criteria of typical software engineering conferences and journals.
In this pragmatic, educational-first document, we want to provide guidance to
those who may feel overwhelmed or confused by writing ESE papers, but also
those more experienced who still might find an opinionated collection of
writing advice useful. The primary audience we had in mind for this paper were
our own BSc, MSc, and PhD students, but also students of others. Our documented
advice therefore reflects a subjective and personal vision of writing ESE
papers. By no means do we claim to be fully objective, generalizable, or
representative of the whole discipline. With that being said, writing papers in
this way has worked pretty well for us so far. We hope that this guide can at
least partially do the same for others.

</details>


### [25] [EmbedAgent: Benchmarking Large Language Models in Embedded System Development](https://arxiv.org/abs/2506.11003)
*Ruiyang Xu,Jialun Cao,Mingyuan Wu,Wenliang Zhong,Yaojie Lu,Ben He,Xianpei Han,Shing-Chi Cheung,Le Sun*

Main category: cs.SE

TL;DR: 提出了针对嵌入式系统开发的大模型能力评测基准Embedbench，通过大规模实验揭示主流模型在该领域的不足，并提出策略显著提升模型表现，为后续研究提供重要参考。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）在众多任务中表现突出，但针对嵌入式系统开发领域能力的基准测试仍十分有限。本文旨在通过引入新的评测范式和数据集，填补这一评测空白。

Method: 作者提出了EmbedAgent范式，模拟实际嵌入式开发者的工作流程，并发布了覆盖编程、硬件电路设计、平台迁移等方面的Embedbench基准数据集。通过在10种主流LLM上进行系统性实验并分析模型表现。

Result: 研究发现，即使面对结构简单的问题，当前主流模型（如DeepSeek-R1）也难以获得高通过率，且不同平台迁移任务表现差异显著。提出的两种增强策略（检索增强生成与编译反馈）显著提升模型表现，如DeepSeek-R1在正确电路图场景下通过率提升到65.1%。

Conclusion: LLMs在实际嵌入式开发任务中的能力尚有限，通用模型和推理模型均存在不足。通过引入外部知识或编译反馈等方法可显著增强模型能力。Embedbench为未来LLM在嵌入式方向的研究与改进提供了标准化评测框架和洞见。

Abstract: Large Language Models (LLMs) have shown promise in various tasks, yet few
benchmarks assess their capabilities in embedded system development.In this
paper, we introduce EmbedAgent, a paradigm designed to simulate real-world
roles in embedded system development, such as Embedded System Programmer,
Architect, and Integrator. This paradigm enables LLMs to be tested in tasks
that bridge the gap between digital and physical systems, allowing for a more
comprehensive assessment of their capabilities. To evaluate LLMs on these
tasks, we propose Embedbench, the first comprehensive benchmark for embedded
system programming, circuit design, and cross-platform migration.Embedbench
consists of 126 cases, covering 9 electronic components across 3 hardware
platforms. Through extensive experiments on 10 mainstream LLMs, we uncover
several key findings. Surprisingly, despite the simplicity of the cases,
DeepSeek-R1 achieves only a 55.6% pass@1 rate when provided with schematic
information, and 50.0% when tasked with generating the schematics itself. In
the cross-platform migration tasks, LLMs show relatively strong performance
with MicroPython on the Raspberry Pi Pico (with the top model achieving 73.8%
pass@1), but perform poorly on ESP-IDF, where the best model reaches only 29.4%
pass@1.Interestingly, we observe that general-purpose chat LLMs like
DeepSeek-V3 often fail to utilize relevant pre-trained knowledge in this
domain, while reasoning LLMs tend to overthink and overlook efficient knowledge
during pretraining. Based on these insights, we propose two strategies:
retrieval augmented generation and compiler feedback-to enhance LLM
performance. These strategies result in significant improvements, with
Deepseek-R1 reaching a 65.1% pass@1 with correct schematics, and 53.1% without.
Additionally, the accuracy of the Arduino to ESP32 migration task improves from
21.4% to 27.8%.

</details>


### [26] [Automated Extraction and Analysis of Developer's Rationale in Open Source Software](https://arxiv.org/abs/2506.11005)
*Mouna Dhaouadi,Bentley Oakes,Michalis Famelis*

Main category: cs.SE

TL;DR: 提出了一种利用大语言模型自动分析开源软件历史决策冲突的方法，并在多个项目验证其有效性和泛化能力，可助力开发者规避决策冲突。


<details>
  <summary>Details</summary>
Motivation: 开源软件的贡献者需要深入理解项目历史，以避免与过去的决策冲突。然而，手动检查所有相关变更非常耗时，以前也缺乏自动化的冲突分析方法。

Method: 提出一种基于Kantara架构的自动化推理分析方法，利用预训练模型和大语言模型，以及结构化机制来检测推理冲突和项目演化风险。通过在Linux Kernel的OOM-Killer模块和其他五个高活跃度项目上进行实验。

Result: 实验结果表明，该自动化方法能够有效地分析决策推理，发现潜在冲突，并自动提取决策和推理句子。方法具有良好的泛化能力。

Conclusion: 该方法能辅助开源开发者主动发现隐藏问题，确保新变更不会与以往决策冲突，提升项目质量。

Abstract: Contributors to open source software must deeply understand a project's
history to make coherent decisions which do not conflict with past reasoning.
However, inspecting all related changes to a proposed contribution requires
intensive manual effort, and previous research has not yet produced an
automated mechanism to expose and analyze these conflicts. In this article, we
propose such an automated approach for rationale analyses, based on an
instantiation of Kantara, an existing high-level rationale extraction and
management architecture. Our implementation leverages pre-trained models and
Large Language Models, and includes structure-based mechanisms to detect
reasoning conflicts and problems which could cause design erosion in a project
over time. We show the feasibility of our extraction and analysis approach
using the OOM-Killer module of the Linux Kernel project, and investigate the
approach's generalization to five other highly active open source projects. The
results confirm that our automated approach can support rationale analyses with
reasonable performance, by finding interesting relationships and to detect
potential conflicts and reasoning problems. We also show the effectiveness of
the automated extraction of decision and rationale sentences and the prospects
for generalizing this to other open source projects. This automated approach
could therefore be used by open source software developers to proactively
address hidden issues and to ensure that new changes do not conflict with past
decisions.

</details>


### [27] [Test code generation at Ericsson using Program Analysis Augmented Fine Tuned LLMs](https://arxiv.org/abs/2506.11006)
*Sai Krishna,Balvinder Singh,Sujoy Roychowdhury,Giriprasad Sridhara,Sourav Mazumdar,Magnus Sandelin,Dimitris Rentas,Maciej Nalepa,Karol Sawicki,Jakub Gajda*

Main category: cs.SE

TL;DR: 本文在Ericsson场景下，结合RAG与Prompt Engineering，并对大语言模型微调，实现了自然语言到Java测试代码的精准转换，模型性能提升显著，适合工程实践。


<details>
  <summary>Details</summary>
Motivation: 在Ericsson背景下，自动生成测试代码对于提升开发效率与代码质量有重要意义。直接采用LLM将自然语言测试步骤转为Java代码存在模型臆造未知函数签名的问题，因此需要改进生成方法以贴合真实代码库需求。

Method: 提出组合的RAG（检索增强生成）与Prompt Engineering方案，通过静态程序分析为模型提供更多上下文信息，并进一步基于自定义Prompt模板对LLM进行微调。模板包括依赖类、公共方法及示例输出，提升生成代码的准确性。

Result: 微调后的8x7b MoE模型（混合专家模型）比基础模型的F1分数平均提升了8%，且接近更大规模8x22b MoE模型的表现，极大提高了生成代码与开发者原始测试代码的一致性。

Conclusion: 结合检索增强与精细化Prompt，并对大模型进一步微调，能够显著提升自动生成测试代码的质量和实用性，且中等规模模型可达到大模型的性能，适合实际企业应用。

Abstract: We describe test code generation using Large Language Models (LLMs) in
Ericsson. Our input is a test step in natural language (English) and our output
is code (Java) which accomplishes the test step. We describe how straight
forward prompting does not suffice and results in LLM assuming functions and
signatures which are not present in the code repository. We then show how we
alleviate the problem by a combination of Retrieval Augmented Generation (RAG)
along with prompt engineering that expanded the simple prompt with additional
contextual information using static program analysis. We then describe further
improvements that we obtained by fine-tuning the underlying LLM. The fine
tuning is done based on a custom designed prompt template which has
pre-dependent classes, their public methods as well two exemplar outputs
obtained from RAG. Our results establish that our fine tuned models help
improve the correspondence or conformity with the original developer written
test code as measured by the traditional metrics of F1-score based on the
methods used in the generated code. Fine tuning of a 8x7b Mixture of Experts
(MoE) model leads to an average improvement of 8\% over the base model and is
comparable to the scores on a much larger 8x22b MoE model.

</details>


### [28] [Impact of Comments on LLM Comprehension of Legacy Code](https://arxiv.org/abs/2506.11007)
*Rock Sabetto,Emily Escamilla,Devesh Agarwal,Sujay Kandwal,Justin F. Brunelle,Scott Rosen,Nitin Naik,Samruddhi Thaker,Eric O. Scott,Jacob Zimmer,Amit Madan,Arun Sridharan,Doug Wendt,Michael Doyle,Christopher Glasz,Jasper Phillips,William Macke,Colin Diggs,Michael Bartholf,Zachary Robin,Paul Ursino*

Main category: cs.SE

TL;DR: 本文用多项选择问答方法评估了大型语言模型理解遗留代码的能力，发现文档和注释的完整性对理解效果有显著影响，并提出了未来相关研究方向。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）已广泛应用于软件工程和维护任务，但对于遗留语言（legacy languages）的代码理解能力仍存在研究空白。由于现实世界的遗留系统常常缺乏或拥有不准确的文档，这进一步影响LLM的代码理解表现，因此需要对LLM在遗留代码环境下的理解能力进行客观评估。

Method: 作者采用多项选择问答（MCQA）作为一种新兴的LLM评估方法，对LLM对于遗留代码的理解能力，以及注释的多少与不准确注释对LLM理解的影响进行量化评估。

Result: 文章提供了LLM在理解遗留代码时文档情况对其表现影响的初步发现，并提出了未来的战略性研究方向。

Conclusion: 多项选择问答方法可以作为评估LLM对遗留代码理解能力的有效手段，文档的数量和准确性会影响其理解效果，未来研究将进一步完善这一评估体系和探讨提升LLM对遗留代码的理解方法。

Abstract: Large language models (LLMs) have been increasingly integrated into software
engineering and maintenance tasks due to their high performance with software
engineering tasks and robust understanding of modern programming languages.
However, the ability of LLMs to comprehend code written with legacy languages
remains a research gap challenged by real-world legacy systems lacking or
containing inaccurate documentation that may impact LLM comprehension. To
assess LLM comprehension of legacy languages, there is a need for objective LLM
evaluation. In order to objectively measure LLM comprehension of legacy
languages, we need an efficient, quantitative evaluation method. We leverage
multiple-choice question answering (MCQA), an emerging LLM evaluation
methodology, to evaluate LLM comprehension of legacy code and the impact of
comment prevalence and inaccurate comments. In this work, we present
preliminary findings on the impact of documentation on LLM comprehension of
legacy code and outline strategic objectives for future work.

</details>


### [29] [Encoding Software For Perpetuity: A Compact Representation Of Apollo 11 Guidance Code](https://arxiv.org/abs/2506.11008)
*David Noever*

Main category: cs.SE

TL;DR: 论文提出用二维码压缩保存阿波罗11号历史代码的新方法，兼顾保存与易访问，推动了计算遗产的现代化传播。


<details>
  <summary>Details</summary>
Motivation: 历史性软件（如阿波罗11号登月舱制导计算机代码）难以通过现代设备便捷访问和保存，需要创新性且易用的数字存档方式。

Method: 采用分词（tokenization）、内容选择性保留和最小化的HTML/JavaScript技术，将核心汇编代码高效压缩进一个3KB的二维码图像中，并评估多种压缩策略的优劣。

Result: 成功将关键历史代码压缩到可扫描的二维码中，实现无需专用硬件或网络即可访问，兼具可读性、可传播性和保存价值。

Conclusion: 该方法为历史软件遗产提供了一种新的补充性保存手段，兼顾了可访问性与历史意义，拓展了传统档案保存技术在移动设备时代的应用。

Abstract: This brief note presents a novel method for encoding historic Apollo 11 Lunar
Module guidance computer code into a single, compact Quick Response Code (QR
code) format, creating an accessible digital artifact for transmission and
archival purposes. By applying tokenization, selective content preservation,
and minimal HTML/JavaScript techniques, we successfully compressed key
components of the original Assembly Language Code (AGC) into a shareable,
preservable, and scannable 3 kilobyte (KB) image. We evaluate multiple
compression strategies and their tradeoffs in terms of size, readability, and
historical significance. This method addresses the challenge of making
historically significant software artifacts available through modern mobile
devices without requiring specialized hardware or internet connectivity. While
numerous digital preservation methods exist for historic software, this
approach balances accessibility with historical significance, offering a
complementary method to traditional archival techniques. This work contributes
to the broader field of computing heritage preservation by demonstrating how
landmark software can be made accessible instantly through contemporary mobile
technologies.

</details>


### [30] [Human-In-The-Loop Software Development Agents: Challenges and Future Directions](https://arxiv.org/abs/2506.11009)
*Jirat Pasuksmit,Wannita Takerngsaksiri,Patanamon Thongtanunam,Chakkrit Tantithamthavorn,Ruixiong Zhang,Shiyan Wang,Fan Jiang,Jing Li,Evan Cook,Kun Chen,Ming Wu*

Main category: cs.SE

TL;DR: 本文分析了多代理LLM在Atlassian真实环境中辅助软件开发的可行性与评估挑战，发现单元测试耗资源且LLM评估浮动大，建议优化评测体系以支撑高效可靠的企业级实践。


<details>
  <summary>Details</summary>
Motivation: 多代理大型语言模型（LLM）驱动的软件开发系统正在快速发展，提高了软件开发效率。论文旨在探索在实际企业场景下（如Atlassian）部署该类系统的效果及其面临的挑战。

Method: 通过在Atlassian使用Human-in-the-Loop软件开发代理解决Jira工单，并采用功能正确性测试和基于GPT的相似性评分来评估生成代码的质量。

Result: 指出了两个主要挑战：1）单元测试的高计算开销；2）LLM评估的波动性。同时提出改进人类参与的软件开发工具评估框架的未来研究方向。

Conclusion: 现有多代理LLM系统在企业开发中的应用可行，但评估机制亟需优化。提高评测效率与一致性是关键瓶颈，改进评估框架是后续重点。

Abstract: Multi-agent LLM-driven systems for software development are rapidly gaining
traction, offering new opportunities to enhance productivity. At Atlassian, we
deployed Human-in-the-Loop Software Development Agents to resolve Jira work
items and evaluated the generated code quality using functional correctness
testing and GPT-based similarity scoring. This paper highlights two major
challenges: the high computational costs of unit testing and the variability in
LLM-based evaluations. We also propose future research directions to improve
evaluation frameworks for Human-In-The-Loop software development tools.

</details>


### [31] [Enhancing Inventory Management with Progressive Web Applications (PWAs): A Scalable Solution for Small and Large Enterprises](https://arxiv.org/abs/2506.11011)
*Abhi Desai*

Main category: cs.SE

TL;DR: 本文设计并实现了一款支持条码/二维码扫描、地理定位和跨设备访问的PWA库存管理系统，在体验和经济性上具有优势，但性能上还逊于原生应用。


<details>
  <summary>Details</summary>
Motivation: 高效的库存管理对于企业来说非常重要，可以优化操作流程并减少成本。当前的库存管理系统在平台兼容性和实时性等方面存在一些局限性。

Method: 开发并实现了一款渐进式网页应用（PWA），集成了条码/二维码扫描、基于地理位置的仓库识别以及跨设备访问等功能，并探讨其在实际库存管理中的应用及面临的挑战。

Result: 该PWA方案实现了离线功能、响应式体验以及跨平台适配，展现出良好的可扩展性和成本效益，但在性能上仍不及原生应用。

Conclusion: PWA为基于Web的库存管理系统提供了一种可拓展、经济型的解决方案，为未来开发者集成该技术提供了实践参考路线图。

Abstract: Efficient inventory management is crucial for both small and large
enterprises to optimize operational workflows and reduce overhead costs. This
paper explores the development and implementation of a Progressive Web
Application (PWA) designed to enhance the inventory management experience. The
application integrates key functionalities such as barcode and QR code
scanning, geolocation-based warehouse identification, and cross-device
accessibility. By leveraging PWA technology, the solution ensures offline
capabilities, responsive user experience, and seamless adaptability across
various platforms. The study discusses the challenges and benefits of
implementing PWA in inventory management systems, including its limitations in
performance compared to native applications. Insights from the development
process provide a roadmap for future developers looking to integrate PWA
technology into enterprise applications. This research contributes to the
growing domain of web-based inventory solutions, offering a scalable and
cost-effective alternative to traditional inventory management software.

</details>


### [32] [Toward a Brazilian Research Agenda in Quantum Software Engineering: A Systematic Mapping Study](https://arxiv.org/abs/2506.11013)
*Filipe Fernandes,Cláudia Werner*

Main category: cs.SE

TL;DR: 本论文系统梳理了量子软件工程领域的现状，总结了研究热点和不足，指出巴西及发展中国家参与度低。作者呼吁标准化实践和加强实证研究，并提出了推动巴西本地发展的研究议程。


<details>
  <summary>Details</summary>
Motivation: 量子软件工程（QSE）虽然作为连接量子计算和传统软件工程的重要新兴领域，但目前知识分散，缺乏面向量子领域特性的标准方法、工具和指导方针；尤其是巴西等国家在该领域的参与度有限。

Method: 本研究采用系统性映射研究方法，依据特定的纳入和排除标准筛选文献，并根据研究类型、文章类型以及与SWEBOK知识领域的关联性对其分类分析。

Result: 分析发现，大多数文献为英文的基础性研究，关注于软件工程模型与方法、软件架构及软件测试领域。研究多为概念性方案和技术解决方案，实证研究相对较少。此外，巴西在该领域的学术贡献仍然稀缺。

Conclusion: QSE是一个前景广阔但尚不成熟的领域，亟需实践规范化、实证研究扩展及发展中国家（如巴西）科研力量的介入。为促进本领域发展，文中提出了巴西QSE研究议程，以引导优先研究方向和激发本地科研社区活力。

Abstract: Context: Quantum Software Engineering (QSE) has emerged as a key field to
support the development of reliable, maintainable, and scalable quantum
applications, bridging advances in quantum computing with established practices
in software engineering. Problem: Despite its growth, the field still suffers
from fragmented knowledge, with a lack of standardized methodologies, tools,
and guidelines tailored to the unique features of the quantum paradigm.
Additionally, countries like Brazil have had limited participation in the
development of this emerging domain. Objective: This study aims to map the
state of the art in QSE by identifying current research trends, recurring
contributions, and existing gaps that can guide future investigations and
strategic initiatives. Methodology: A systematic mapping study was conducted
analyzing selected publications based on inclusion and exclusion criteria.
Articles were categorized by study type, research type, and alignment with the
SWEBOK knowledge areas. Results: Most of the reviewed studies are primary
research articles written in English, with a strong focus on Software
Engineering Models and Methods, Software Architecture, and Software Testing.
Conceptual proposals and technical solutions predominate, while empirical
validations remain limited. Conclusions: Findings confirm that QSE is a
promising but still maturing field. The standardization of practices, expansion
of empirical studies, and inclusion of researchers from developing countries
are crucial for advancing the discipline. Additionally, Brazilian contributions
are still scarce, highlighting the urgent need to establish a national research
agenda. As a main contribution, this study proposes a Brazilian Research Agenda
in QSE, outlining priority areas and opportunities to foster a local scientific
community and accelerate progress in this emerging field.

</details>


### [33] [MultiMind: A Plug-in for the Implementation of Development Tasks Aided by AI Assistants](https://arxiv.org/abs/2506.11014)
*Benedetta Donato,Leonardo Mariani,Daniela Micucci,Oliviero Riganelli,Marco Somaschini*

Main category: cs.SE

TL;DR: 本文提出了一种可扩展、模块化的VS Code插件MultiMind，大大简化了AI助手在开发环境中的集成，提升了开发效率与AI协作体验。


<details>
  <summary>Details</summary>
Motivation: 近年来，AI助手在软件开发流程中的应用越来越广，从简单的自动化任务扩展到与开发者的协作。然而，将AI助手嵌入到集成开发环境（IDE）会遇到调用时机、协调多助手、输出处理和流程无缝集成等诸多挑战。本文旨在解决这些集成难题。

Method: 本文提出并实现了MultiMind——一个基于Visual Studio Code的插件。该插件采用模块化、可扩展的框架，方便开发者以低成本实现和测试新的AI交互方式，无需复杂的IDE定制。

Result: MultiMind已在两个场景下进行了测试：1）自动生成代码注释；2）基于AI的聊天交互定义。

Conclusion: MultiMind插件有效简化并促进了AI助手在IDE中的集成，可拓展到更多AI辅助开发任务，加速AI与开发流程的融合。

Abstract: The integration of AI assistants into software development workflows is
rapidly evolving, shifting from automation-assisted tasks to collaborative
interactions between developers and AI. Large Language Models (LLMs) have
demonstrated their effectiveness in several development activities, including
code completion, test case generation, and documentation production. However,
embedding AI-assisted tasks within Integrated Development Environments (IDEs)
presents significant challenges. It requires designing mechanisms to invoke AI
assistants at the appropriate time, coordinate interactions with multiple
assistants, process the generated outputs, and present feedback in a way that
seamlessly integrates with the development workflow. To address these issues,
we introduce MultiMind, a Visual Studio Code plug-in that streamlines the
creation of AI-assisted development tasks. MultiMind provides a modular and
extensible framework, enabling developers to cost-effectively implement and
experiment with new AI-powered interactions without the need for complex IDE
customizations. MultiMind has been tested in two use cases: one for the
automatic generation of code comments and the other about the definition of
AI-powered chat.

</details>


### [34] [ZjsComponent: A Pragmatic Approach to Modular, Reusable UI Fragments for Web Development](https://arxiv.org/abs/2506.11016)
*Lelanthran Manickum*

Main category: cs.SE

TL;DR: ZjsComponent是一种无需依赖构建、简单易用的Web组件方案，降低开发工作量，提高组件复用性和隔离性。


<details>
  <summary>Details</summary>
Motivation: 当前Web组件开发通常依赖繁杂的构建工具、特定框架或生态系统，增加了开发复杂度与门槛，因此需要一种更简单、无依赖且易于上手的组件化方案。

Method: 提出ZjsComponent，一种轻量且与框架无关的Web组件实现。无需构建、转译或预编译，仅依赖浏览器原生支持的JavaScript和Web组件。实现了HTML+JS片段的动态加载和隔离，并提供生命周期钩子。

Result: ZjsComponent实现了无需依赖的可复用UI组件，显著降低了代码耦合和DOM隔离性要求，实现了简单生命周期控制和传统实例方法支持。

Conclusion: ZjsComponent为开发者提供了一种无需依赖构建工具的轻量组件方案，易于创建隔离性强、可复用的Web UI组件，降低了开发门槛和复杂度。

Abstract: In this paper, I present ZjsComponent, a lightweight and framework-agnostic
web component designed for creating modular, reusable UI elements with minimal
developer overhead. ZjsComponent is an example implementation of an approach to
creating components and object instances that can be used purely from HTML.
Unlike traditional approaches to components, the approach implemented by
ZjsComponent does not require build-steps, transpiling, pre-compilation, any
specific ecosystem or any other dependency. All that is required is that the
browser can load and execute Javascript as needed by Web Components.
ZjsComponent allows dynamic loading and isolation of HTML+JS fragments,
offering developers a simple way to build reusable interfaces with ease. This
approach is dependency-free, provides significant DOM and code isolation, and
supports simple lifecycle hooks as well as traditional methods expected of an
instance of a class.

</details>


### [35] [Formation of requirements traceability in the process of information systems design](https://arxiv.org/abs/2506.11018)
*Grigory Tsiperman*

Main category: cs.SE

TL;DR: 本论文针对需求可追溯性在信息系统设计过程中的集成难题，提出了无缝架构下自适应聚类方法（ACM），以实现需求追溯、简化开发依赖、提升质量。


<details>
  <summary>Details</summary>
Motivation: 需求可追溯性对于信息系统设计过程至关重要，可以提升系统的验证和确认能力。然而，可追溯性的集成在设计过程中的实现是一个主要挑战，被称为“可追溯性的重大挑战”。

Method: 作者提出应用自适应聚类方法（ACM），这是一种基于无缝系统架构的技术，能明确连接不同抽象层级的项目工件。

Result: 通过ACM方法，可以实现信息系统中不同层级工件的显式互联，从而支持需求的有效追溯。

Conclusion: 采用基于自适应聚类方法的系统建模，可以减少系统对开发者的依赖，使设计过程更直接，并提升系统验证与确认的能力。

Abstract: The traceability of requirements in the information system design process is
considered an essential property of the project, one of its quality
characteristics. The point here is that traceability provides the methods of
validation and verification of software systems, and that the system model
based on requirements traceability reduces the system's dependence on
developers and, in general, makes it as straightforward as possible. One of the
challenges of the traceability process, dubbed "The grand challenge of
traceability" among traceability researchers, is its integration into the
design process. In this paper, to achieve this goal, we propose the application
of the Adaptive Clustering Method (ACM) of Information Systems developed by the
author, which is based on the idea of a seamless system architecture that
provides explicit interconnection of project artifacts of different levels of
abstraction.

</details>


### [36] [Mind the Metrics: Patterns for Telemetry-Aware In-IDE AI Application Development using the Model Context Protocol (MCP)](https://arxiv.org/abs/2506.11019)
*Vincent Koc,Jacques Verre,Douglas Blank,Abigail Morgan*

Main category: cs.SE

TL;DR: 本文提出了一种借助MCP协议的遥测感知IDE架构，将遥测数据、提示追踪和评估反馈实时引入AI开发流程，并以Opik为例说明其对AI开发运维和优化的推动作用，促进了LLMOps、提示工程等领域的发展。


<details>
  <summary>Details</summary>
Motivation: 随着AI与大模型开发的复杂度提升，开发者日益关注如何在开发流程中实时获取模型的运行数据（telemetry）、提示词追踪以及评估反馈，以实现更高效的迭代与优化。

Method: 提出了一种基于Model Context Protocol（MCP）的遥测感知一体化开发环境（IDE）架构，并通过开源的Opik MCP服务器展示了这种架构如何连接IDE与各种遥测数据，包括提示指标、追踪日志和版本控制。

Result: 该体系结构支持集成多种框架（如DSPy、PromptWizard和Prompts as Programs），能够实现本地提示迭代、持续集成（CI）优化及基于遥测的自适应智能代理。Opik作为MCP实现展示了其实用性。

Conclusion: MCP增强的遥测感知IDE为AI开发流程带来了更强的透明度与可观测性，促进了提示词优化、开发工具智能化和基准测试等方向，为遥测丰富的AI开发奠定了基础。

Abstract: AI development environments are evolving into observability first platforms
that integrate real time telemetry, prompt traces, and evaluation feedback into
the developer workflow. This paper introduces telemetry aware integrated
development environments (IDEs) enabled by the Model Context Protocol (MCP), a
system that connects IDEs with prompt metrics, trace logs, and versioned
control for real time refinement. We present design patterns for local prompt
iteration, CI based optimization, and autonomous agents that adapt behavior
using telemetry. Rather than focusing on a single algorithm, we describe an
architecture that supports integration with frameworks like DSPy, PromptWizard,
and Prompts as Programs. We demonstrate this through Opik, an open source MCP
server for LLM telemetry, and position our approach within the emerging LLMOps
ecosystem. This work lays a foundation for future research on prompt
optimization, IDE agent tooling, and empirical benchmarking in telemetry rich
AI development workflows.

</details>


### [37] [Extracting Knowledge Graphs from User Stories using LangChain](https://arxiv.org/abs/2506.11020)
*Thayná Camargo da Silva*

Main category: cs.SE

TL;DR: 提出一种基于大型语言模型与LangChain的自动用户故事知识图谱生成方法，实现自动化构建和评估，助力软件开发更好满足用户需求。


<details>
  <summary>Details</summary>
Motivation: 传统软件开发中，用户故事难以被结构化理解和充分利用，对用户需求的洞察有限。为更高效地提取和可视化用户需求，提高软件开发的以用户为中心程度，有必要自动生成用户故事知识图谱。

Method: 采用大型语言模型（LLM）、基于LangChain框架开发User Story Graph Transformer模块，实现从用户故事自动抽取节点与关系，并自动化知识图谱生成和评估流程。评估环节通过脚本和人工标注数据集自动完成。

Result: 该方法能够自动、准确地从用户故事中生成知识图谱，提升了需求与领域概念的可视化和理解效果，有助于增强软件功能与用户期望之间的匹配度。

Conclusion: 使用LLM自动生成用户故事知识图谱的方法提升了需求分析效率与准确性，对促进用户驱动的软件开发具有积极作用。

Abstract: This thesis introduces a novel methodology for the automated generation of
knowledge graphs from user stories by leveraging the advanced capabilities of
Large Language Models. Utilizing the LangChain framework as a basis, the User
Story Graph Transformer module was developed to extract nodes and relationships
from user stories using an LLM to construct accurate knowledge graphs.This
innovative technique was implemented in a script to fully automate the
knowledge graph extraction process. Additionally, the evaluation was automated
through a dedicated evaluation script, utilizing an annotated dataset for
assessment. By enhancing the visualization and understanding of user
requirements and domain concepts, this method fosters better alignment between
software functionalities and user expectations, ultimately contributing to more
effective and user-centric software development processes.

</details>


### [38] [Eliminating Hallucination-Induced Errors in LLM Code Generation with Functional Clustering](https://arxiv.org/abs/2506.11021)
*Chaitanya Ravuri,Saman Amarasinghe*

Main category: cs.SE

TL;DR: 提出一种黑盒代码生成模型验证方案，通过程序行为聚类聚合结果，能显著提高代码生成准确率并提供置信度估计，几乎消除“幻觉”错误，且方法简单通用。


<details>
  <summary>Details</summary>
Motivation: 尽管现代代码生成大模型已能解决大量编程问题，但其输出仍常因“幻觉”导致细微错误，造成模型不安全，制约了其自动化部署。需要一种简单且通用的方法来大幅减少这些错误。

Method: 通过对大语言模型采样大量代码候选解，将这些候选解在自生成的测试集上执行，并根据输入输出行为聚类。最大聚类的概率质量作为置信度估计。根据这个分数设定阈值，可以在保留右通过率的前提下，以指数级优势减少结果错误率。

Result: 在 LiveCodeBench 上实验显示，本文方法能保持现有模型在可解任务的通过率（pass@1），但返回答案的错误率从约 65% 降至 2%；在保守阈值下错误率可为 0%，仍回答 15.6% 的问题。人工检查表明残余错误主要源自题意理解不清，而非生成随机噪声。该方法无需依赖开源 API 或模型，适用范围广泛。

Conclusion: 本文提出的 functional clustering 方法通过黑盒包裹消除了几乎所有由大语言模型代码生成引起的幻觉类错误，并能为输出提供可调的置信度评估。方法具有通用性，不依赖模型结构即可提升代码自动生成的可靠性。

Abstract: Modern code-generation LLMs can already solve a large fraction of programming
problems, yet they still hallucinate subtle bugs that make their outputs unsafe
for autonomous deployment. We present functional clustering, a black-box
wrapper that eliminates nearly all hallucination-induced errors while providing
a tunable confidence score. The wrapper samples many candidate programs,
executes each on a self-generated test suite, and clusters candidates whose I/O
behavior is identical; the empirical mass of the largest cluster serves as an
exact confidence estimate. A single scalar threshold on this estimate lets
users trade coverage for reliability with exponential guarantees. On
LiveCodeBench our verifier preserves baseline pass@1 on solvable tasks yet
slashes the error rate of returned answers from ~65% to 2%, and drives it to 0%
at a conservative threshold while still answering 15.6% of prompts. Manual
audits show that the few residual mistakes stem from prompt misinterpretation,
not random generation noise, narrowing future work to specification clarity.
Because the method requires only sampling and sandbox execution, it applies
unchanged to closed-source APIs and future models, offering a practical path
toward dependable, autonomous code generation. Our code is available on Github
(https://github.com/20ChaituR/functional-clustering).

</details>


### [39] [Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox](https://arxiv.org/abs/2506.11022)
*Shivani Shukla,Himanshu Joshi,Romilla Syed*

Main category: cs.SE

TL;DR: LLM多轮迭代改进代码非但不能保证安全，反而可能增加安全漏洞。研究通过实验证实关键性漏洞增长，并呼吁开发者在迭代中务必人工介入，避免安全风险累积。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型（LLMs）已被广泛用于代码生成，但关于通过迭代式LLM反馈中安全漏洞如何演变的研究较少。作者希望揭示当前开发实践下，频繁利用LLM改进代码时，对安全造成何种影响。

Method: 作者通过对400份代码进行40轮改进实验，采用四种不同的提示策略，受控分析每轮后代码中安全漏洞的变化情况。

Result: 迭代仅五轮，关键安全漏洞平均增加了37.6%。四种提示策略下，漏洞表现也各有不同，暴露出不同的安全风险模式。

Conclusion: 结果表明，迭代式使用LLM并不一定提升代码安全，反而有可能引入更多安全风险。作者强调需要在LLM生成与改进过程中嵌入人类专业知识，提出开发者应加强人工校验和把控，防止代码‘改进’反而导致安全退化。

Abstract: The rapid adoption of Large Language Models(LLMs) for code generation has
transformed software development, yet little attention has been given to how
security vulnerabilities evolve through iterative LLM feedback. This paper
analyzes security degradation in AI-generated code through a controlled
experiment with 400 code samples across 40 rounds of "improvements" using four
distinct prompting strategies. Our findings show a 37.6% increase in critical
vulnerabilities after just five iterations, with distinct vulnerability
patterns emerging across different prompting approaches. This evidence
challenges the assumption that iterative LLM refinement improves code security
and highlights the essential role of human expertise in the loop. We propose
practical guidelines for developers to mitigate these risks, emphasizing the
need for robust human validation between LLM iterations to prevent the
paradoxical introduction of new security issues during supposedly beneficial
code "improvements".

</details>


### [40] [Software Security Mapping Framework: Operationalization of Security Requirements](https://arxiv.org/abs/2506.11051)
*Sung Une Lee,Liming Dong,Zhenchang Xing,Muhammad Ejaz Ahmed,Stefan Avgoustakis*

Main category: cs.SE

TL;DR: 本文提出了将抽象安全要求转化为可操作步骤的软件安全映射框架，并通过实际案例展示其实用性，助力组织提升供应链安全管理和合规效率。


<details>
  <summary>Details</summary>
Motivation: 随着软件开发环境日趋复杂，供应链安全问题愈发突出。然而，现有框架难以将抽象的安全原则转化为具体可操作的实践，迫切需要新的方法实现安全需求的落地。

Method: 论文提出了Software Security Mapping Framework（软件安全映射框架），采用KAOS目标建模方法，将高层次安全标准、框架及细粒度技术活动系统映射为400多项可操作步骤，并开发了交互式网页工具及可机读的OSCAL Catalog Model。

Result: 框架实现了131项安全需求到400多项实际操作的系统映射，增强了安全目标与实际操作间的可追溯性。在Log4j漏洞案例中，能生成符合行业最佳实践的定制检查清单，并为自动化实施和合规监管提供支持。

Conclusion: 所提框架有效促进了安全需求的落地执行，加强了供应链安全管理的透明度和责任划分，有助于组织高效应对不断变化的安全风险。

Abstract: The escalating complexity of modern software development environments has
heightened concerns around supply chain security. However, existing frameworks
often fall short in translating abstract security principles into concrete,
actionable practices. This paper introduces the Software Security Mapping
Framework, a structured solution designed to operationalize security
requirements across hierarchical levels -- from high-level regulatory standards
(e.g., ISM, Australia cybersecurity standard published by the Australian
Signals Directorate), through mid-level frameworks (e.g., NIST SSDF, the U.S.
Secure Software Development Framework), to fine-grained technical activities
(e.g., SLSA, a software supply chain security framework). Developed through
collaborative research with academic experts and industry practitioners, the
framework systematically maps 131 refined security requirements to over 400
actionable operational steps spanning the software development lifecycle. It is
grounded in four core security goals: Secure Software Environment, Secure
Software Development, Software Traceability, and Vulnerability Management. Our
approach leverages the KAOS goal modeling methodology to establish traceable
linkages between strategic goals and tactical operations, enhancing clarity,
accountability, and practical implementation. To facilitate adoption, we
provide a web-based navigation tool for interactive exploration of the
framework. A real-world case study based on the Log4j vulnerability illustrates
the framework's utility by generating a tailored checklist aligned with
industry best practices. Additionally, we offer a structured, machine-readable
OSCAL Catalog Model of the Software Security Mapping Framework, enabling
organizations to automate implementation, streamline compliance processes, and
respond effectively to evolving security risks.

</details>


### [41] [Refactoring Codebases through Library Design](https://arxiv.org/abs/2506.11058)
*Ziga Kovacic,Celine Lee,Justin Chiu,Wenting Zhao,Kevin Ellis*

Main category: cs.SE

TL;DR: 作者提出了Librarian自动化重构方法和Minicode测试集，使得代码代理在代码压缩率和正确性上实现大幅提升，促进了可复用软件组件的自动生成。


<details>
  <summary>Details</summary>
Motivation: 高可维护性和通用性的软件能让开发者更高效地构建健壮的应用程序，但这通常需要将特定解决方案重构为可复用的组件。随着代码代理(agent)在解决孤立编程问题方面的准确性提升，探讨其支持代码增长和复用的能力具有现实意义。

Method: 作者提出了Librarian方法（一种sample-and-rerank的生成可复用库的方法），并设计了Minicode基准，其要求代码代理将多个相互独立的解决方案重构为一个联合库。

Result: Librarian在Minicode基准上，在代码压缩率（代码量减少1.6-2倍）和正确性方面均优于现有顶尖代码代理。

Conclusion: Librarian方法为代码自动重构和组件复用提供了高效解决方案，并通过新基准Minicode验证了其实用价值。相关代码和基准已开源。

Abstract: Maintainable and general software allows developers to build robust
applications efficiently, yet achieving these qualities often requires
refactoring specialized solutions into reusable components. This challenge
becomes particularly relevant as code agents become increasingly accurate at
solving isolated programming problems. We investigate code agents' capacity to
refactor code in ways supporting growth and reusability. We present both a
method and a benchmark for refactoring: Librarian, a sample-and-rerank method
for generating reusable libraries, and Minicode, a benchmark where code agents
must minimize and refactor multiple independent solutions into a joint library.
Compared to state-of-the-art code agents, Librarian achieves strong results on
both compression and correctness on Minicode, obtaining compression rates
1.6-2x better than coding agents while also improving correctness. We
open-source our code and benchmark at https://code-refactor.github.io/.

</details>


### [42] [CodeMirage: A Multi-Lingual Benchmark for Detecting AI-Generated and Paraphrased Source Code from Production-Level LLMs](https://arxiv.org/abs/2506.11059)
*Hanxi Guo,Siyuan Cheng,Kaiyuan Zhang,Guangyu Shen,Xiangyu Zhang*

Main category: cs.SE

TL;DR: 本文提出了CodeMirage，一套覆盖十种编程语言、多个主流LLM及复述样本的全面AI代码检测基准，系统评测现有检测器并揭示关键挑战，为后续健壮、通用的AI代码检测器研究提供了重要支撑。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）广泛应用于现代软件开发，AI生成代码数量激增，但同时带来了代码抄袭、许可证违规和不安全程序传播等重大风险，亟需强有力的检测技术。现有基准数据集覆盖编程语言有限，且多依赖老旧模型，无法真实反映实际环境。

Method: 提出CodeMirage，一个全面的基准数据集，涵盖十种主流编程语言，包含原始及复述代码样本，并涵盖来自六大提供商的十个最先进LLM（涵盖推理与非推理模型）。利用CodeMirage，对十个代表性检测器在四种方法范式和四类真实评价配置下进行评测，并使用三种互补评估指标综合分析。

Result: 评测揭示了九项关键发现，系统展示了现有检测器的优劣势，并指出了未来研究需重点解决的挑战。CodeMirage为开发健壮且通用的AI生成代码检测器提供了严格且实用的测试平台。

Conclusion: CodeMirage有效弥补了先前基准的不足，为推动鲁棒、通用AI代码检测技术的发展奠定了坚实的基础，并为后续相关研究追踪和改进指明了方向。

Abstract: Large language models (LLMs) have become integral to modern software
development, producing vast amounts of AI-generated source code. While these
models boost programming productivity, their misuse introduces critical risks,
including code plagiarism, license violations, and the propagation of insecure
programs. As a result, robust detection of AI-generated code is essential. To
support the development of such detectors, a comprehensive benchmark that
reflects real-world conditions is crucial. However, existing benchmarks fall
short -- most cover only a limited set of programming languages and rely on
less capable generative models. In this paper, we present CodeMirage, a
comprehensive benchmark that addresses these limitations through three major
advancements: (1) it spans ten widely used programming languages, (2) includes
both original and paraphrased code samples, and (3) incorporates outputs from
ten state-of-the-art production-level LLMs, including both reasoning and
non-reasoning models from six major providers. Using CodeMirage, we evaluate
ten representative detectors across four methodological paradigms under four
realistic evaluation configurations, reporting results using three
complementary metrics. Our analysis reveals nine key findings that uncover the
strengths and weaknesses of current detectors, and identify critical challenges
for future work. We believe CodeMirage offers a rigorous and practical testbed
to advance the development of robust and generalizable AI-generated code
detectors.

</details>


### [43] [Code Researcher: Deep Research Agent for Large Systems Code and Commit History](https://arxiv.org/abs/2506.11060)
*Ramneet Singh,Sathvik Joel,Abhav Mehrotra,Nalin Wadhwa,Ramakrishna B Bairi,Aditya Kanade,Nagarajan Natarajan*

Main category: cs.SE

TL;DR: 针对系统代码（如Linux内核）修复任务，本文提出并验证了Code Researcher——一种基于多步推理和结构化记忆的深度研究代理，能够更有效收集全局上下文信息，显著提升了自动崩溃修复率（58% vs 37.5%），并验证了其泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的代码代理在常规编码基准上表现良好，但在系统代码（如大型操作系统内核的代码）的有效性尚未得到充分探索。系统代码规模庞大且复杂，即使对于人类而言，做出代码修改也颇具挑战，需要在大规模代码及其丰富提交历史中检索大量上下文信息。该论文旨在解决系统代码中修补由崩溃错误引发的问题。

Method: 作者提出了一种名为Code Researcher的'深度研究型代码代理'系统。其核心方法包括：通过多步推理理解代码语义、模式与历史，主动收集与问题相关的全局上下文信息，并存储于结构化内存中用于后续补丁合成。该方法被应用于针对系统代码（如Linux内核）崩溃补丁生成。

Result: 在Linux内核崩溃kBenchSyz基准上，Code Researcher实现了58%的崩溃修复率，显著高于SWE-agent的37.5%。在每次修复流程中，Code Researcher平均探索10个文件，而SWE-agent仅为1.33个，明显示出其对大规模代码库的深度探索能力。其泛化实验（如在开源多媒体软件上的实验）表明，该方法具有良好的通用性。

Conclusion: Code Researcher展现了对复杂系统代码库深度推理与全局上下文收集能力，显著提升了自动修复崩溃补丁的成功率，其方法与架构为LLM在更复杂编程任务上的应用提供了有效范例。全局上下文优化和多元推理机制对于大型代码库的问题解决至关重要。

Abstract: Large Language Model (LLM)-based coding agents have shown promising results
on coding benchmarks, but their effectiveness on systems code remains
underexplored. Due to the size and complexities of systems code, making changes
to a systems codebase is a daunting task, even for humans. It requires
researching about many pieces of context, derived from the large codebase and
its massive commit history, before making changes. Inspired by the recent
progress on deep research agents, we design the first deep research agent for
code, called Code Researcher, and apply it to the problem of generating patches
for mitigating crashes reported in systems code. Code Researcher performs
multi-step reasoning about semantics, patterns, and commit history of code to
gather sufficient context. The context is stored in a structured memory which
is used for synthesizing a patch. We evaluate Code Researcher on kBenchSyz, a
benchmark of Linux kernel crashes, and show that it significantly outperforms
strong baselines, achieving a crash-resolution rate of 58%, compared to 37.5%
by SWE-agent. On an average, Code Researcher explores 10 files in each
trajectory whereas SWE-agent explores only 1.33 files, highlighting Code
Researcher's ability to deeply explore the codebase. Through another experiment
on an open-source multimedia software, we show the generalizability of Code
Researcher. Our experiments highlight the importance of global context
gathering and multi-faceted reasoning for large codebases.

</details>


### [44] [CoQuIR: A Comprehensive Benchmark for Code Quality-Aware Information Retrieval](https://arxiv.org/abs/2506.11066)
*Jiahui Geng,Fengyu Cai,Shaobo Cui,Qing Li,Liangwei Chen,Chenyang Lyu,Haonan Li,Derui Zhu,Walter Pretschner,Heinz Koeppl,Fakhri Karray*

Main category: cs.SE

TL;DR: 作者提出了关注质量的CoQuIR基准，对主流模型进行评测，并通过新训练方法提升了模型识别代码质量的能力，为可靠软件开发提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 现有的代码检索基准过于注重功能相关性，而忽视了代码质量的关键维度，如正确性、效率、安全性和可维护性。作者希望解决这一缺口，推动代码检索系统朝更高质量标准发展。

Method: 作者提出了CoQuIR，这是第一个大规模、面向多语言的、质量感知的代码检索基准，涵盖11种编程语言。CoQuIR为42,725个查询和134,907个代码片段提供了细粒度的质量注释，并引入了两个新的质量评估指标。作者还评测了23种主流检索模型，并探索了通过特定训练方法提升模型质量识别能力的效果。

Result: 现有代码检索模型很难有效区分存在缺陷或安全隐患的代码与高质量代码。通过合成数据集训练的新方法，在不损失语义相关性的前提下，显著提升了模型在质量相关指标上的表现。相关的下游代码生成实验也证明了该方法的有效性。

Conclusion: 论文强调了把代码质量信号融入代码检索系统的重要意义，并为未来更可靠的软件开发工具打下了基础。

Abstract: Code retrieval is essential in modern software development, as it boosts code
reuse and accelerates debugging. However, current benchmarks primarily
emphasize functional relevance while neglecting critical dimensions of software
quality. Motivated by this gap, we introduce CoQuIR, the first large-scale,
multilingual benchmark specifically designed to evaluate quality-aware code
retrieval across four key dimensions: correctness, efficiency, security, and
maintainability. CoQuIR provides fine-grained quality annotations for 42,725
queries and 134,907 code snippets in 11 programming languages, and is
accompanied by two quality-centric evaluation metrics: Pairwise Preference
Accuracy and Margin-based Ranking Score. Using CoQuIR, we benchmark 23
retrieval models, covering both open-source and proprietary systems, and find
that even top-performing models frequently fail to distinguish buggy or
insecure code from their more robust counterparts. Furthermore, we conduct
preliminary investigations into training methods that explicitly encourage
retrievers to recognize code quality. Using synthetic datasets, we demonstrate
promising improvements in quality-aware metrics across various models, without
sacrificing semantic relevance. Downstream code generation experiments further
validate the effectiveness of our approach. Overall, our work highlights the
importance of integrating quality signals into code retrieval systems, laying
the groundwork for more trustworthy and robust software development tools.

</details>


### [45] [DCE-LLM: Dead Code Elimination with Large Language Models](https://arxiv.org/abs/2506.11076)
*Minyu Chen,Guoqiang Li,Ling-I Wu,Ruibang Liu*

Main category: cs.SE

TL;DR: 本文提出DCE-LLM框架，结合小型CodeBERT和大语言模型，高效、自动地检测、解释及修复多语言代码中的死代码，实验性能全面胜过GPT-4o，实现更高准确率与自动化。


<details>
  <summary>Details</summary>
Motivation: 死代码不仅导致可执行文件体积增大、维护困难，还可能隐藏逻辑错误，被恶意利用用于混淆，尤其在基于大模型（LLM）的代码相关任务中，死代码会干扰模型判断，造成安全隐患。现有死代码检测工具自动化程度不高，复杂场景下效果有限，依赖较多人工介入。

Method: 提出了DCE-LLM框架，结合小型CodeBERT模型和基于归因的行选择器自动定位疑似死代码，再利用经过大规模死代码数据集微调的大语言模型，实现判别、解释和修复死代码。DCE-LLM不仅检测更复杂的不可达代码，还能自动修复并支持多种编程语言。

Result: DCE-LLM在实验中对未使用和不可达代码的F1分数均超过94%，比GPT-4o高出30%，在死代码检测、解释和修正方面全面超越现有工具。

Conclusion: DCE-LLM显著提升了死代码自动检测和修复的准确性与效率，可有效解决现有工具的局限，为多语言代码处理提供了强大支持。

Abstract: Dead code introduces several challenges in software development, such as
increased binary size and maintenance difficulties. It can also obscure logical
errors and be exploited for obfuscation in malware. For LLM-based code-related
tasks, dead code introduces vulnerabilities that can mislead these models,
raising security concerns. Although modern compilers and IDEs offer dead code
elimination, sophisticated patterns can bypass these tools. A universal
approach that includes classification, location, explanation, and correction is
needed, yet current tools often require significant manual effort. We present
DCE-LLM, a framework for automated dead code elimination using a small CodeBERT
model with an attribution-based line selector to efficiently locate suspect
code. LLMs then generate judgments and explanations, fine-tuned on a
large-scale, annotated dead code dataset to provide detailed explanations and
patches. DCE-LLM outperforms existing tools, with advanced unreachability
detection, automated correction, and support for multiple programming
languages. Experimental results show DCE-LLM achieves over 94% F1 scores for
unused and unreachable code, significantly surpassing GPT-4o by 30%.

</details>


### [46] [Research and Analysis of Employers' Opinion on the Necessary Skills that Students in the Field of Web Programming Should Possess](https://arxiv.org/abs/2506.11084)
*Yordan Kalmukov*

Main category: cs.SE

TL;DR: AI和自动化工具改变了IT企业对毕业生技能的要求。本文通过对雇主调研，分析应重视教授哪些Web编程技能，为高校课程设计提供了参考。


<details>
  <summary>Details</summary>
Motivation: 随着AI和聊天机器人等技术的发展，雇主对IT毕业生的技能要求发生了变化。当前大量自动化工具和第三方库减少了从零开发的需求，因此需要探讨学生应重点学习哪类技能。

Method: 通过对IT雇主进行问卷调查，分析他们认为毕业生应具备的Web编程领域技术技能，以便毕业生能更快、更有效地适应企业工作。

Result: 调查结果揭示了雇主更看重毕业生掌握哪些具体技能，但具体技能细节需参考全文。整体来看，强调了实用工具应用与基础原理学习之间的权衡。

Conclusion: Web编程教育需要根据产业需求调整教学内容，既要关注使用现代工具框架，也不能忽视基础原理的教学，以提升毕业生的就业适应力。

Abstract: In the era of artificial intelligence (AI) and chatbots, based on large
language models that can generate programming code in any language, write texts
and summarize information, it is obvious that the requirements of employers for
graduating students have already changed. The modern IT world offers
significant automation of programming through software frameworks and a huge
set of third-party libraries and application programming interfaces (APIs). All
these tools provide most of the necessary functionality out of the box (already
implemented), and quite naturally the question arises as to what is more useful
for students - to teach how to use these ready-made tools or the basic
principles of working and development of web applications from scratch. This
paper analyzes the results of a survey conducted among IT employers, aimed to
identify what, in their opinion, are the necessary technical skills that
graduating students in the field of Web Programming should possess in order to
join the company's work as quickly and effectively as possible.

</details>


### [47] [Denoising Programming Knowledge Tracing with a Code Graph-based Tuning Adaptor](https://arxiv.org/abs/2506.11107)
*Weibo Gao,Qi Liu,Rui Li,Yuze Zhao,Hao Wang,Linan Yre,Fangzhou Yao,Zheng Zhang*

Main category: cs.SE

TL;DR: 本文提出了Coda，一种通过代码图和图神经网络减缓编程学习中噪音影响的适配器，提升了编程知识追踪的精度和稳健性，且能适配多种主流模型。


<details>
  <summary>Details</summary>
Motivation: 当前编程知识追踪（PKT）主要通过分析代码内容隐式地评估学习者知识水平，但往往忽视了长期学习活动中的两类噪音：来自不相关提交的无效信号以及来自小修改的弱信号，这影响了模型表现和应用效果。

Method: 提出了Coda，一种基于代码图的调整适配器。Coda首先将学习者提交的代码序列转化为紧凑的代码图，并通过语义相似度识别无关信号。然后对代码图应用集群感知的图卷积网络（GCN）以提升弱信号的辨别并实现聚类。最后，设计了轻量级适配器，通过两个基于噪音特征的约束和一个定向正则项进行优化，将其集成到PKT任务中，以修正受到噪音影响的知识状态。该方法可适配于大多数现有PKT模型。

Result: 在四个真实世界数据集上的大量实验结果表明，Coda能有效提升PKT任务在噪声代码记录下的准确性，显著超过典型基线方法。

Conclusion: Coda框架能够识别并减弱编程记录中的噪音信号，有效提升了编程知识追踪的可靠性和适应性，具备广泛的模型适用性。

Abstract: Programming Knowledge Tracking (PKT) aims to dynamically diagnose learners'
mastery levels of programming knowledge based on their coding activities,
facilitating more effective and personalized programming education. However,
current PKT studies primarily focus on the implicit relationship between code
content and knowledge assessment, often overlooking two types of noise signals
in long-term programming activities: unwanted signals from unrelated
submissions and weak signals from minor modifications. This practical challenge
significantly limits model performance and application. To address this issue,
we propose Coda, a Code graph-based tuning adaptor designed to enhance existing
PKT models by identifying and mitigating the impact of noise. Specifically,
Coda first transforms the loose code sequences submitted by each learner into a
compact code graph. By leveraging this code graph, unwanted signals can be
identified from a semantic similarity perspective. We then apply a
cluster-aware GCN to the code graph, which improves the discrimination of weak
signals and enables their clustering for identification. Finally, a lightweight
yet effective adaptor is incorporated into the PKT task through optimization
with two noise feature-based constraints and a navigational regularization
term, to correct knowledge states affected by noise. It is worth mentioning
that the Coda framework is model-agnostic and can be adapted to most existing
PKT solutions. Extensive experimental results on four real-world datasets
demonstrate that Coda effectively performs the PKT task in the presence of
noisy programming records, outperforming typical baselines.

</details>


### [48] [From over-reliance to smart integration: using Large-Language Models as translators between specialized modeling and simulation tools](https://arxiv.org/abs/2506.11141)
*Philippe J. Giabbanelli,John Beverley,Istvan David,Andreas Tolk*

Main category: cs.SE

TL;DR: 论文主张将大语言模型作为中间件与专业建模仿真工具协作，解决复杂性和质量问题，并提出高效架构，确保LLMs提升而非替代M&S流程。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs能用自然语言简化M&S流程，但过度依赖会造成质量下降（如逻辑漏洞与幻觉）。提升LLMs与工具的互操作性可兼顾简化与高质量。

Method: 探索LLM作为翻译者的应用场景，识别合适的工具与架构；提出利用Low-Rank Adaptation等高效软件架构集成LLMs，强调结构化集成及任务专用高效适配。

Result: 验证通过结构化、分工明确的中间件架构，引入LLMs能解决语言与工具选择难题，并提出避免性能瓶颈的架构建议。该集成方法保持质量与效率优势。

Conclusion: 该论文认为LLMs应作为桥梁/中间件与专业建模仿真（M&S）工具协作，而非替代，以提升系统的互操作性与可靠性。

Abstract: Large Language Models (LLMs) offer transformative potential for Modeling &
Simulation (M&S) through natural language interfaces that simplify workflows.
However, over-reliance risks compromising quality due to ambiguities, logical
shortcuts, and hallucinations. This paper advocates integrating LLMs as
middleware or translators between specialized tools to mitigate complexity in
M&S tasks. Acting as translators, LLMs can enhance interoperability across
multi-formalism, multi-semantics, and multi-paradigm systems. We address two
key challenges: identifying appropriate languages and tools for modeling and
simulation tasks, and developing efficient software architectures that
integrate LLMs without performance bottlenecks. To this end, the paper explores
LLM-mediated workflows, emphasizes structured tool integration, and recommends
Low-Rank Adaptation-based architectures for efficient task-specific
adaptations. This approach ensures LLMs complement rather than replace
specialized tools, fostering high-quality, reliable M&S processes.

</details>


### [49] [Mutual-Supervised Learning for Sequential-to-Parallel Code Translation](https://arxiv.org/abs/2506.11153)
*Changxin Ke,Rui Zhang,Shuo Wang,Li Ding,Guangli Li,Yuanbo Wen,Shuoming Zhang,Ruiyuan Xu,Jin Qin,Jiaming Guo,Chenxi Wang,Ling Li,Qi Guo,Yunji Chen*

Main category: cs.SE

TL;DR: 提出了MuSL框架，通过双模型互监督有效提升了顺序到并行代码翻译的准确性和功能等价性，实验证明其在多个指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: GPU高性能计算推动了CUDA等并行编程模型的普及，但并行编程复杂度高，因此存在自动从顺序代码翻译为并行代码的需求。基于机器学习的方法在顺序到并行的代码翻译中，因为数据稀缺性而面临挑战。近期的反向翻译方法虽有进展，但翻译后的代码功能等价性仍未得到保证。

Method: 提出了一个新的互监督学习（MSL）框架，包括Translator和Tester两个模型，并通过Co-verify和Co-evolve的迭代过程互相生成数据以实现协同提升。Tester生成单元测试来验证和筛选功能等价的并行代码，促进Translator进化；Translator生成新的翻译代码用作增强输入，促进Tester进化。

Result: 在Qwen2.5-Coder模型上的实验表明，该方法将Pass@1指标提升了28.91%，Tester性能提升了68.90%，在BLEU和CodeBLEU分数上分别超过之前最佳方法CodeRosetta 1.56和6.92分，且性能接近DeepSeek-R1和GPT-4.1。

Conclusion: MSL（MuSL）框架能有效提升顺序到并行代码自动翻译的性能，显著超过现有方法并确保了功能等价性。

Abstract: The rise of GPU-based high-performance computing (HPC) has driven the
widespread adoption of parallel programming models such as CUDA. Yet, the
inherent complexity of parallel programming creates a demand for the automated
sequential-to-parallel approaches. However, data scarcity poses a significant
challenge for machine learning-based sequential-to-parallel code translation.
Although recent back-translation methods show promise, they still fail to
ensure functional equivalence in the translated code. In this paper, we propose
a novel Mutual-Supervised Learning (MSL) framework for sequential-to-parallel
code translation to address the functional equivalence issue. MSL consists of
two models, a Translator and a Tester. Through an iterative loop consisting of
Co-verify and Co-evolve steps, the Translator and the Tester mutually generate
data for each other and improve collectively. The Tester generates unit tests
to verify and filter functionally equivalent translated code, thereby evolving
the Translator, while the Translator generates translated code as augmented
input to evolve the Tester. Experimental results demonstrate that MuSL
significantly enhances the performance of the base model: when applied to
Qwen2.5-Coder, it not only improves Pass@1 by up to 28.91% and boosts Tester
performance by 68.90%, but also outperforms the previous state-of-the-art
method CodeRosetta by 1.56 and 6.92 in BLEU and CodeBLEU scores, while
achieving performance comparable to DeepSeek-R1 and GPT-4.1. Our code is
available at https://github.com/kcxain/musl.

</details>


### [50] [Beyond Formal Semantics for Capabilities and Skills: Model Context Protocol in Manufacturing](https://arxiv.org/abs/2506.11180)
*Luis Miguel Vieira da Silva,Aljosha Köcher,Felix Gehlhoff*

Main category: cs.SE

TL;DR: 通过MCP协议直接将制造系统的功能暴露给LLM，简化了工业自动化集成流程，初步实验显示这种方式高效且灵活。


<details>
  <summary>Details</summary>
Motivation: 现有的能力建模（如本体、AAS等）依赖大量人工工作，且结果难以被LLM直接访问，因此需要探索新的、对LLM友好的工业系统集成方式。

Method: 在实验室规模的制造系统中，将资源功能通过MCP暴露，利用通用LLM进行任务规划与执行，包括约束处理和通过MCP调用资源。

Result: 实验表明，通过MCP公开资源功能，LLM可顺利规划并执行多步骤生产流程，实现了无需显式语义模型的工业自动化。

Conclusion: MCP这种基于模型上下文协议的方法可以绕过传统的语义建模，实现LLM驱动的灵活工业自动化，很有潜力推动生产系统与外部工具的集成。

Abstract: Explicit modeling of capabilities and skills -- whether based on ontologies,
Asset Administration Shells, or other technologies -- requires considerable
manual effort and often results in representations that are not easily
accessible to Large Language Models (LLMs). In this work-in-progress paper, we
present an alternative approach based on the recently introduced Model Context
Protocol (MCP). MCP allows systems to expose functionality through a
standardized interface that is directly consumable by LLM-based agents. We
conduct a prototypical evaluation on a laboratory-scale manufacturing system,
where resource functions are made available via MCP. A general-purpose LLM is
then tasked with planning and executing a multi-step process, including
constraint handling and the invocation of resource functions via MCP. The
results indicate that such an approach can enable flexible industrial
automation without relying on explicit semantic models. This work lays the
basis for further exploration of external tool integration in LLM-driven
production systems.

</details>


### [51] [LLM-as-a-Judge for Reference-less Automatic Code Validation and Refinement for Natural Language to Bash in IT Automation](https://arxiv.org/abs/2506.11237)
*Ngoc Phuoc An Vo,Brent Paulovicks,Vadim Sheinin*

Main category: cs.SE

TL;DR: 通过改进LLM自动化代码评价与精炼方法，实现更高准确率与代码自动优化，有效提升IT自动化故障修复能力。


<details>
  <summary>Details</summary>
Motivation: 自动化IT故障处理过程中，如何高效、准确地自动评价代码生成质量，并选择最优模型，是提升代码修复能力和系统稳定性的核心问题。现有方法受限于表面相似性和功能评测的不足，亟需参考新方式提升代码评价与精炼能力。

Method: 文章提出增强型LLM-as-a-Judge方法，结合双向功能匹配与逻辑表示，实现面向Bash代码生成的无参考代码自动验证与优化选模。以执行为基础的测试评测为真值，验证LLM-as-a-Judge评价指标的准确性。同时，设计Reflection code agents，利用评价指标的反馈信息自动精炼代码。

Result: 增强型LLM-as-a-Judge的评价准确率高，与执行型评测（ground-truth）高度一致，且对比基线提升可达8%。基于反思型代码智能体，自动代码精炼准确率提升可达24%。

Conclusion: 本研究在自动化故障修复领域提出的无参考自动代码评价与优化框架，有效提升了代码生成的自动验证能力及后续代码精炼效果，可选优模型与增强代码质量，具有实际应用前景。

Abstract: In an effort to automatically evaluate and select the best model and improve
code quality for automatic incident remediation in IT Automation, it is crucial
to verify if the generated code for remediation action is syntactically and
semantically correct and whether it can be executed correctly as intended.
There are three approaches: 1) conventional methods use surface form similarity
metrics (token match, exact match, etc.) which have numerous limitations, 2)
execution-based evaluation focuses more on code functionality based on
pass/fail judgments for given test-cases, and 3) LLM-as-a-Judge employs LLMs
for automated evaluation to judge if it is a correct answer for a given problem
based on pre-defined metrics. In this work, we focused on enhancing
LLM-as-a-Judge using bidirectional functionality matching and logic
representation for reference-less automatic validation and refinement for Bash
code generation to select the best model for automatic incident remediation in
IT Automation. We used execution-based evaluation as ground-truth to evaluate
our LLM-as-a-Judge metrics. Results show high accuracy and agreement with
execution-based evaluation (and up to 8% over baseline). Finally, we built
Reflection code agents to utilize judgments and feedback from our evaluation
metrics which achieved significant improvement (up to 24% increase in accuracy)
for automatic code refinement.

</details>


### [52] [Invocable APIs derived from NL2SQL datasets for LLM Tool-Calling Evaluation](https://arxiv.org/abs/2506.11266)
*Benjamin Elder,Anupama Murthi,Jungkoo Kang,Ankita Rajaram Naik,Kiran Kate,Kinjal Basu,Danish Contractor*

Main category: cs.SE

TL;DR: 提出一种将NL2SQL数据集自动转化为NL2API任务集的新方法，并用其系统评估LLM在工具调用场景下的性能，发现即使最优模型也难以胜任复杂API调用任务，提示当前LLM工具调用能力与实际需求仍有显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在企业级环境中需要与大量复杂的API集合交互，但缺乏真实场景下的NL2API（自然语言到API调用）测试数据，且其真实性能未知。

Method: 作者提出了一条新颖的数据生成管道，基于大型NL2SQL数据集（如BIRD-SQL）自动生成等价的NL2API数据集，将SQL查询语句转化为一系列等价的API调用序列。然后将原有自然语言查询与这些API序列配对，并用该数据集测试10个公开LLM的工具调用能力，包括意图检测、嵌套函数调用的排序和参数填充等任务。

Result: 所有LLM在确定正确工具组合上表现较差，任务完成率仅7%-47%，即便以ReACT agent形式接入动态API环境也只提升至约50%。较复杂API环境和名称混淆都会进一步降低模型表现。对比显示，LLM们在传统SQL生成任务上表现普遍优于API调用任务。

Conclusion: 当前主流LLM在真实复杂API环境下的工具调用性能远不能满足实际应用需求，未来工具调用能力有巨大改进空间。

Abstract: Large language models (LLMs) are routinely deployed as agentic systems, with
access to tools that interact with live environments to accomplish tasks. In
enterprise deployments these systems need to interact with API collections that
can be extremely large and complex, often backed by databases. In order to
create datasets with such characteristics, we explore how existing NL2SQL
(Natural Language to SQL query) datasets can be used to automatically create
NL2API datasets. Specifically, this work describes a novel data generation
pipeline that exploits the syntax of SQL queries to construct a functionally
equivalent sequence of API calls. We apply this pipeline to one of the largest
NL2SQL datasets, BIRD-SQL to create a collection of over 2500 APIs that can be
served as invocable tools or REST-endpoints. We pair natural language queries
from BIRD-SQL to ground-truth API sequences based on this API pool. We use this
collection to study the performance of 10 public LLMs and find that all models
struggle to determine the right set of tools (consisting of tasks of intent
detection, sequencing with nested function calls, and slot-filling). We find
that models have extremely low task completion rates (7-47 percent - depending
on the dataset) which marginally improves to 50 percent when models are
employed as ReACT agents that interact with the live API environment. The best
task completion rates are far below what may be required for effective
general-use tool-calling agents, suggesting substantial scope for improvement
in current state-of-the-art tool-calling LLMs. We also conduct detailed
ablation studies, such as assessing the impact of the number of tools available
as well as the impact of tool and slot-name obfuscation. We compare the
performance of models on the original SQL generation tasks and find that
current models are sometimes able to exploit SQL better than APIs.

</details>


### [53] [A Tale of Two Systems: Characterizing Architectural Complexity on Machine Learning-Enabled Systems](https://arxiv.org/abs/2506.11295)
*Renato Cordeiro Ferreira*

Main category: cs.SE

TL;DR: 本文提出了一种用度量方法量化和管理机器学习驱动系统复杂性的架构模型，并通过两个实际系统案例展示其实用性，有助于MLES的架构决策和扩展。


<details>
  <summary>Details</summary>
Motivation: 机器学习驱动系统（ML-Enabled Systems, MLES）变得越来越复杂，急需有效的方法管理其复杂性。如何度量和管理这些复杂性对系统架构设计和演化至关重要。

Method: 该研究提出了一种基于度量的架构模型，用于量化和表征MLES的复杂性。并通过并列比较两个MLES案例（SPIRA和Ocean Guard系统）的架构，展示该模型的应用。

Result: 基于两个实际案例系统，展示了该架构模型能够有效支持MLES的架构决策和演进规划。提供了度量和描述复杂性的准则，便于系统的设计和扩展。

Conclusion: 通过度量驱动的架构模型，可以更好地描述和管理ML驱动系统的复杂性，从而支持架构决策，为系统成长与演化提供指导。

Abstract: How can the complexity of ML-enabled systems be managed effectively? The goal
of this research is to investigate how complexity affects ML-Enabled Systems
(MLES). To address this question, this research aims to introduce a
metrics-based architectural model to characterize the complexity of MLES. The
goal is to support architectural decisions, providing a guideline for the
inception and growth of these systems. This paper brings, side-by-side, the
architecture representation of two systems that can be used as case studies for
creating the metrics-based architectural model: the SPIRA and the Ocean Guard
MLES.

</details>


### [54] [A Step-by-Step Guide to Creating a Robust Autonomous Drone Testing Pipeline](https://arxiv.org/abs/2506.11400)
*Yupeng Jiang,Yao Deng,Sebastian Schroder,Linfeng Liang,Suhaas Gambhir,Alice James,Avishkar Seth,James Pirrie,Yihao Zhang,Xi Zheng*

Main category: cs.SE

TL;DR: 本文提出了一个系统性的自动化无人机测试流程，从仿真到实地验证，辅以实例和新技术趋势，有助于保障无人机的实际应用安全高效。


<details>
  <summary>Details</summary>
Motivation: 随着无人机在各行各业中的应用日益增长，保证其安全性、可靠性和高效性对推动其在实际任务中的广泛部署至关重要。

Method: 文章提出并详细阐述了一个分阶段的无人机自动化测试流程，包括软件环测试（SIL）、硬件环测试（HIL）、受控真实环境测试和实地测试，并辅以实际案例说明。

Result: 通过该测试流程，能够系统性地验证无人机的行为、识别集成问题并优化系统性能。此外，还讨论了神经符号、LLM集成、共仿真环境和数字孪生等新兴测试趋势。

Conclusion: 本流程为无人机开发与验证提供了系统化的指导，能有效提升无人机系统的安全性与可靠性，降低部署风险，为大规模实际应用打下坚实基础。

Abstract: Autonomous drones are rapidly reshaping industries ranging from aerial
delivery and infrastructure inspection to environmental monitoring and disaster
response. Ensuring the safety, reliability, and efficiency of these systems is
paramount as they transition from research prototypes to mission-critical
platforms. This paper presents a step-by-step guide to establishing a robust
autonomous drone testing pipeline, covering each critical stage:
Software-in-the-Loop (SIL) Simulation Testing, Hardware-in-the-Loop (HIL)
Testing, Controlled Real-World Testing, and In-Field Testing. Using practical
examples, including the marker-based autonomous landing system, we demonstrate
how to systematically verify drone system behaviors, identify integration
issues, and optimize performance. Furthermore, we highlight emerging trends
shaping the future of drone testing, including the integration of Neurosymbolic
and LLMs, creating co-simulation environments, and Digital Twin-enabled
simulation-based testing techniques. By following this pipeline, developers and
researchers can achieve comprehensive validation, minimize deployment risks,
and prepare autonomous drones for safe and reliable real-world operations.

</details>


### [55] [ReVeal: Self-Evolving Code Agents via Iterative Generation-Verification](https://arxiv.org/abs/2506.11442)
*Yiyang Jin,Kunzhao Xu,Hang Li,Xueting Han,Yanmin Zhou,Cheng Li,Jing Bai*

Main category: cs.SE

TL;DR: 提出了ReVeal多轮强化学习框架，将自我验证和工具评估融入代码生成，有效提升了大语言模型推理与自我验证能力，实验展示了其明显优于现有模型的性能表现，具有良好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）在多轮工具交互结合强化学习后推理能力显著提升，但缺少真实环境下有意义的验证信号和针对验证的显式优化，导致自我验证能力不可靠。

Method: 提出了ReVeal，这是一个多轮强化学习框架，将代码生成、显式自我验证与基于工具的评估相结合。ReVeal让LLM自主生成测试用例，通过调用外部工具获得精准反馈，并通过设计密集（每轮）奖励的定制化RL算法提升性能。

Result: ReVeal促使模型生成与验证能力在RL训练中共同进化，显著提升LiveCodeBench上的Pass@k分数。推理时模型随着交互次数增加，代码性能持续进化，超过了DeepSeek-R1-Zero-Qwen-32B。

Conclusion: ReVeal是构建更健壮和自主AI智能体的一种可扩展且有效的新范式。

Abstract: Recent advances in reinforcement learning (RL) with verifiable outcome
rewards have significantly improved the reasoning capabilities of large
language models (LLMs), especially when combined with multi-turn tool
interactions. However, existing methods lack both meaningful verification
signals from realistic environments and explicit optimization for verification,
leading to unreliable self-verification. To address these limitations, we
propose ReVeal, a multi-turn reinforcement learning framework that interleaves
code generation with explicit self-verification and tool-based evaluation.
ReVeal enables LLMs to autonomously generate test cases, invoke external tools
for precise feedback, and improves performance via a customized RL algorithm
with dense, per-turn rewards. As a result, ReVeal fosters the co-evolution of a
model's generation and verification capabilities through RL training, expanding
the reasoning boundaries of the base model, demonstrated by significant gains
in Pass@k on LiveCodeBench. It also enables test-time scaling into deeper
inference regimes, with code consistently evolving as the number of turns
increases during inference, ultimately surpassing DeepSeek-R1-Zero-Qwen-32B.
These findings highlight the promise of ReVeal as a scalable and effective
paradigm for building more robust and autonomous AI agents.

</details>


### [56] [Understanding the Issue Types in Open Source Blockchain-based Software Projects with the Transformer-based BERTopic](https://arxiv.org/abs/2506.11451)
*Md Nahidul Islam Opu,Md Shahidul Islam,Sara Rouhani,Shaiful Chowdhury*

Main category: cs.SE

TL;DR: 作者分析了1209个区块链项目近50万条issue，揭示了区块链开发中常见的通用和特有问题，尤其是钱包管理问题最突出且难以解决，并指出随着DApp兴起issue数量高峰已过。结果可为区块链维护工具和实践改进提供指导。


<details>
  <summary>Details</summary>
Motivation: 随着区块链在各领域的应用日益广泛，目前对区块链软件开发挑战的系统性理解仍然有限。本研究旨在深入揭示开源区块链项目在开发和维护过程中面临的实际问题和难点。

Method: 对1,209个开源区块链项目的497,742个GitHub issue进行了大规模实证分析。研究使用了BERTopic（一种基于Transformer的主题模型技术）识别出49个不同的问题主题，并将其层次化归为11个主要子类别，同时分析了这些问题的时间演变趋势和解决时长。

Result: 发现区块链项目中既有通用的软件开发问题，也有较多区块链特有的难题，如钱包管理和界面增强是最突出的主题。钱包相关的问题不仅最多，而且解决时间也最长；机制类问题则能较快得到处理。自2016年以太坊和DApp兴起后，问题数量快速增加，但自2022年起出现下降趋势。

Conclusion: 本研究丰富了对区块链软件维护问题的理解，有助于开发更有针对性的工具和实践来提升区块链系统的健壮性和可维护性。

Abstract: Blockchain-based software systems are increasingly deployed across diverse
domains, yet a systematic understanding of their development challenges remains
limited. This paper presents a large-scale empirical study of 497,742 issues
mined from 1,209 open-source blockchain projects hosted on GitHub. Employing
BERTopic, a transformer-based topic modeling technique, we identify 49 distinct
issue topics and organize them hierarchically into 11 major subcategories. Our
analysis reveals that both general software development issues and
blockchain-specific concerns are nearly equally represented, with Wallet
Management and UI Enhancement emerging as the most prominent topics. We further
examine the temporal evolution of issue categories and resolution times,
finding that Wallet issues not only dominate in frequency but also exhibit the
longest resolution time. Conversely, Mechanisms issues are resolved
significantly faster. Issue frequency surged after 2016 with the rise of
Ethereum and decentralized applications, but declined after 2022. These
findings enhance our understanding of blockchain software maintenance,
informing the development of specialized tools and practices to improve
robustness and maintainability.

</details>


### [57] [VulStamp: Vulnerability Assessment using Large Language Model](https://arxiv.org/abs/2506.11484)
*Haoshen,Ming Hu,Xiaofei Xie,Jiaye Li,Mingsong Chen*

Main category: cs.SE

TL;DR: 本论文提出无需人工描述的新型漏洞严重性评估方法VulStamp，通过意图挖掘和强化学习优化，大幅提升了评估效果，有助于开发效率提升。


<details>
  <summary>Details</summary>
Motivation: 现有漏洞检测工具虽然高效，但修复所有发现的漏洞可能导致不必要的开发成本，特别是许多漏洞实际可利用性低或影响小。因此，合理评估漏洞严重性对于优化开发效率至关重要。但现有方法主要依赖人工编写的描述，受描述质量和主观解读影响大，导致评估效果有限。

Method: 提出VulStamp框架，结合静态分析与大语言模型（LLM），自动挖掘漏洞代码的意图信息，并基于这些意图信息利用prompt-tuned模型进行漏洞严重性评估。此外，采用基于强化学习的prompt-tuning方法缓解漏洞类型数据不平衡问题。

Result: VulStamp能在不依赖人工描述的情况下，以意图为导向提高漏洞严重性评估的有效性和鲁棒性，并成功解决了由于漏洞类型分布不均带来的评估偏差问题。

Conclusion: VulStamp框架通过引入意图感知及强化学习调优，有效提升了漏洞严重性评估的自动化和准确性，有助于开发者合理分配修复资源，优化软件开发流程。

Abstract: Although modern vulnerability detection tools enable developers to
efficiently identify numerous security flaws, indiscriminate remediation
efforts often lead to superfluous development expenses. This is particularly
true given that a substantial portion of detected vulnerabilities either
possess low exploitability or would incur negligible impact in practical
operational environments. Consequently, vulnerability severity assessment has
emerged as a critical component in optimizing software development efficiency.
Existing vulnerability assessment methods typically rely on manually crafted
descriptions associated with source code artifacts. However, due to variability
in description quality and subjectivity in intention interpretation, the
performance of these methods is seriously limited. To address this issue, this
paper introduces VulStamp, a novel intention-guided framework, to facilitate
description-free vulnerability assessment. Specifically, VulStamp adopts static
analysis together with Large Language Model (LLM) to extract the intention
information of vulnerable code. Based on the intention information, VulStamp
uses a prompt-tuned model for vulnerability assessment. Furthermore, to
mitigate the problem of imbalanced data associated with vulnerability types,
VulStamp integrates a Reinforcement Learning (RL)-based prompt-tuning method to
train the assessment model.

</details>


### [58] [A Procedural Framework for Assessing the Desirability of Process Deviations](https://arxiv.org/abs/2506.11525)
*Michael Grohs,Nadine Cordes,Jana-Rebecca Rehse*

Main category: cs.SE

TL;DR: 本文提出并验证了一个操作性流程框架，用于帮助分析师系统地评估和分类流程执行偏差的可取性，并为每类偏差提供具体的行动建议，从而提升评估效率和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的一致性检查技术可以发现过程执行与模型之间的偏差，但无法确定这些偏差是有害、可接受还是有益的。偏差的可取性评估对于采取行动至关重要，而目前这一步骤往往依赖分析人员手动、主观地判断，效率低、重复性差。

Method: 提出了一个操作性框架，指导过程分析人员系统地评估过程偏差的可取性。该框架结合了现有文献综述和专家访谈的实证见解，采用分步方法，有序识别输入因素，并将偏差归类到不同的可取性类别中，每种类别都附有行动建议。框架的有效性通过实际从业者参与的评估任务进行了验证。

Result: 结果表明，该框架能够有效帮助分析人员高效且全面地进行偏差可取性评估，从而优化评估过程。

Conclusion: 系统性且标准化的偏差可取性评估框架能够提升分析效率、减少主观性，有助于更合理地指导实际过程管理中的改进行动。

Abstract: Conformance checking techniques help process analysts to identify where and
how process executions deviate from a process model. However, they cannot
determine the desirability of these deviations, i.e., whether they are
problematic, acceptable or even beneficial for the process. Such desirability
assessments are crucial to derive actions, but process analysts typically
conduct them in a manual, ad-hoc way, which can be time-consuming, subjective,
and irreplicable. To address this problem, this paper presents a procedural
framework to guide process analysts in systematically assessing deviation
desirability. It provides a step-by-step approach for identifying which input
factors to consider in what order to categorize deviations into mutually
exclusive desirability categories, each linked to action recommendations. The
framework is based on a review and conceptualization of existing literature on
deviation desirability, which is complemented by empirical insights from
interviews with process analysis practitioners and researchers. We evaluate the
framework through a desirability assessment task conducted with practitioners,
indicating that the framework effectively enables them to streamline the
assessment for a thorough yet concise evaluation.

</details>


### [59] [Augmenting the Generality and Performance of Large Language Models for Software Engineering](https://arxiv.org/abs/2506.11548)
*Fabian C. Peña*

Main category: cs.SE

TL;DR: 本文系统扩展了LLM在软件工程非代码任务（如设计、概念化等）上的应用，通过新评测、专用数据集和幻觉检测，有效提升了LLM表现，为其更广泛应用提供了基础。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）已在代码生成和分析上带来革命性变革，但在包括概念化、设计等软件工程非代码任务上的应用仍不充分。本文旨在提升LLM在更广泛软件工程任务中的通用性和性能。

Method: 本研究：（1）分析不同类型LLM在多种非代码任务上的表现；（2）评估LLM作为软件工程领域基础知识来源的有效性；（3）提出用于检测软件工程表述幻觉的方法。方法包括训练和评估多种LLM在领域特定数据集上的表现，建立基础知识新基准，以及开发幻觉检测技术。

Result: 初步结果显示，提出的方法能显著提升LLM在多种非代码任务上的性能，且在基础知识评估与幻觉检测方面表现良好。

Conclusion: 该研究扩展了LLM在软件工程领域的应用场景，尤其在非代码任务上表现出了较强的性能和适应性，同时提供了新的评估基准和幻觉检测方案。

Abstract: Large Language Models (LLMs) are revolutionizing software engineering (SE),
with special emphasis on code generation and analysis. However, their
applications to broader SE practices including conceptualization, design, and
other non-code tasks, remain partially underexplored. This research aims to
augment the generality and performance of LLMs for SE by (1) advancing the
understanding of how LLMs with different characteristics perform on various
non-code tasks, (2) evaluating them as sources of foundational knowledge in SE,
and (3) effectively detecting hallucinations on SE statements. The expected
contributions include a variety of LLMs trained and evaluated on
domain-specific datasets, new benchmarks on foundational knowledge in SE, and
methods for detecting hallucinations. Initial results in terms of performance
improvements on various non-code tasks are promising.

</details>


### [60] [Leveraging GPT-4 for Vulnerability-Witnessing Unit Test Generation](https://arxiv.org/abs/2506.11559)
*Gábor Antal,Dénes Bán,Martin Isztin,Rudolf Ferenc,Péter Hegedűs*

Main category: cs.SE

TL;DR: 本文验证了GPT-4在自动生成安全漏洞测试用例方面的潜力。虽然需要人工参与提升语义完整性，但其在生成测试模板方面表现良好，有助于提升软件安全测试自动化水平。


<details>
  <summary>Details</summary>
Motivation: 软件测试对于保障软件质量和发现安全漏洞至关重要，但手动编写测试用例费时费力，尤其是在针对安全漏洞的场景下。如何高效自动生成具有安全性证据的单元测试成为迫切需求。

Method: 本文使用主流大语言模型GPT-4，对VUL4J真实漏洞及修复数据集的子集开展实验，评估GPT-4基于补丁前后代码生成单元测试的能力。重点考察代码上下文、模型自我修正能力，以及生成测试用例的可用性。语法与语义正确性通过自动及主观方式同步评价。

Result: GPT-4在无领域专门训练的情况下，能生成66.5%的语法正确单元测试；但能自动验证语义正确性的比例为7.5%。主观评价显示，GPT-4生成的测试模板通过少量人工完善后有望成为具有安全漏洞证据的测试用例。

Conclusion: GPT-4虽然尚无法完全自动化单元测试生成流程，但在生成基于安全漏洞证据的测试时表现突出，能显著辅助安全测试自动化。

Abstract: In the life-cycle of software development, testing plays a crucial role in
quality assurance. Proper testing not only increases code coverage and prevents
regressions but it can also ensure that any potential vulnerabilities in the
software are identified and effectively fixed. However, creating such tests is
a complex, resource-consuming manual process. To help developers and security
experts, this paper explores the automatic unit test generation capability of
one of the most widely used large language models, GPT-4, from the perspective
of vulnerabilities. We examine a subset of the VUL4J dataset containing real
vulnerabilities and their corresponding fixes to determine whether GPT-4 can
generate syntactically and/or semantically correct unit tests based on the code
before and after the fixes as evidence of vulnerability mitigation. We focus on
the impact of code contexts, the effectiveness of GPT-4's self-correction
ability, and the subjective usability of the generated test cases. Our results
indicate that GPT-4 can generate syntactically correct test cases 66.5\% of the
time without domain-specific pre-training. Although the semantic correctness of
the fixes could be automatically validated in only 7. 5\% of the cases, our
subjective evaluation shows that GPT-4 generally produces test templates that
can be further developed into fully functional vulnerability-witnessing tests
with relatively minimal manual effort.
  Therefore, despite the limited data, our initial findings suggest that GPT-4
can be effectively used in the generation of vulnerability-witnessing tests. It
may not operate entirely autonomously, but it certainly plays a significant
role in a partially automated process.

</details>


### [61] [Identifying Helpful Context for LLM-based Vulnerability Repair: A Preliminary Study](https://arxiv.org/abs/2506.11561)
*Gábor Antal,Bence Bogenfürst,Rudolf Ferenc,Péter Hegedűs*

Main category: cs.SE

TL;DR: 本文评估了GPT-4o在Java漏洞自动修复上的能力，发现尽管其平均表现略低于GPT-4，但在覆盖更多不同漏洞和利用丰富上下文信息（如CVE、代码上下文）进行多提示集成时，能显著提升修复效果，展示了未来利用大模型和提示工程在漏洞修复自动化方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）近年来在自动化漏洞检测和修复方面表现出潜力，但对于不同模型及输入的上下文信息如何影响修复能力尚缺乏深入对比分析，尤其是在真实漏洞数据集上的表现不明。

Method: 本文利用Vul4J数据集，对GPT-4o模型在修复Java漏洞的能力进行评估，并与前一代GPT-4在相同提示下的表现进行对比。此外，设计了九种含有不同上下文（如CWE、CVE信息及手动提取的代码上下文）的新提示，对42个漏洞运行三次，并通过Vul4J自动化测试框架验证修复效果。

Result: GPT-4o在相同提示下修复成功率平均比GPT-4低11.9%，但三轮实验中其修复到的不同漏洞数比GPT-4多10.5%。带有CVE信息的提示显著提升修复成功率，任务描述长度影响较小。CVEC+手动代码上下文结合时效果最好，采用前三提示的集成策略，GPT-4o最高修复了62%的漏洞，超越基准（40%）和其复现（45%）。

Conclusion: 完整的上下文信息（尤其是CVE）与多提示集成，有助于提升大语言模型在自动化漏洞修复上的表现，尽管整体平均成功率较前代略低，但新模型在多样漏洞修复能力方面有优势。

Abstract: Recent advancements in large language models (LLMs) have shown promise for
automated vulnerability detection and repair in software systems. This paper
investigates the performance of GPT-4o in repairing Java vulnerabilities from a
widely used dataset (Vul4J), exploring how different contextual information
affects automated vulnerability repair (AVR) capabilities. We compare the
latest GPT-4o's performance against previous results with GPT-4 using identical
prompts. We evaluated nine additional prompts crafted by us that contain
various contextual information such as CWE or CVE information, and manually
extracted code contexts. Each prompt was executed three times on 42
vulnerabilities, and the resulting fix candidates were validated using Vul4J's
automated testing framework.
  Our results show that GPT-4o performed 11.9\% worse on average than GPT-4
with the same prompt, but was able to fix 10.5\% more distinct vulnerabilities
in the three runs together. CVE information significantly improved repair
rates, while the length of the task description had minimal impact. Combining
CVE guidance with manually extracted code context resulted in the best
performance. Using our \textsc{Top}-3 prompts together, GPT-4o repaired 26
(62\%) vulnerabilities at least once, outperforming both the original baseline
(40\%) and its reproduction (45\%), suggesting that ensemble prompt strategies
could improve vulnerability repair in zero-shot settings.

</details>


### [62] [MBSR at Work: Perspectives from an Instructor and Software Developers](https://arxiv.org/abs/2506.11588)
*Simone Romano,Alberto Conforti,Gloria Guidetti,Sara Viotti,Rachele Ceschin,Giuseppe Scanniello*

Main category: cs.SE

TL;DR: 本研究通过访谈发现，MBSR帮助软件开发人员缓解了压力并带来个人改善，但其深入整合到工作中的过程仍然困难。


<details>
  <summary>Details</summary>
Motivation: 尽管MBSR（正念减压）已在多种工作环境中应用，但在软件开发这一特定且压力较大的环境中的应用研究却十分罕见。软件开发工作中存在诸如时间压力、不确定性等显著的压力因素，因此有必要探索MBSR在该领域的潜在益处。研究动机在于填补该领域的研究空白，并深入了解MBSR对软件开发人员的实际影响。

Method: 本研究采用定性研究方法，通过半结构式访谈方式收集数据。受访者包括参与MBSR项目的软件开发人员以及主导该项目的讲师。研究聚焦于参与者对MBSR项目的第一手体验与看法。

Result: 研究发现，尽管开发人员起初对MBSR项目持怀疑态度，但经过实践后普遍感受到个人的积极变化和改善。然而，将MBSR相关技术融入日常工作环境仍面临一定挑战。

Conclusion: MBSR可帮助软件开发人员管理工作压力，提升个人福祉，但其在实际工作场景中的持续应用和技术整合仍具挑战性，有待进一步探索与改进。

Abstract: In this paper, we present the preliminary findings from a qualitative study
(i.e., semi-structured interviews) on how a Mindfulness-Based Stress Reduction
(MBSR) program, carried out in the Software Development (SD) working context,
is perceived by the software developers of a multinational company who
participated in the MBSR program and by the instructor who led it. MBSR is a
deeply personal and experiential practice in helping individuals manage stress,
particularly in high-pressure environments such as workplaces, healthcare
settings, education, and other demanding professional or personal situations.
Although MBSR has been experimented in different working contexts;
surprisingly, it has never been studied in the SD working context where there
are several stress factors that developers experience (e.g., time pressure and
uncertainty about the content of a particular task and its outcome). In this
respect, qualitative research can generate valuable insights into the
application of MBSR in the SD working context that cannot be captured by
standardized quantitative measures. Being MBSR instructors and software
developers the key stakeholders in delivering an MBSR program in the SD working
context, understanding their first-hand experiences can provide a more detailed
picture of the investigated phenomenon. The most important takeaway result of
our research can be summarized as follows: despite initial skepticism, the
developers recognized personal improvements due to the MBSR practice, though
the integration of MBSR techniques in the working context remained challenging.

</details>


### [63] [Retrieval-Augmented Code Review Comment Generation](https://arxiv.org/abs/2506.11591)
*Hyunsun Hong,Jongmoon Baik*

Main category: cs.SE

TL;DR: 本文提出利用检索增强生成（RAG）方法提升自动化代码审查评论生成的准确性和句法多样性，并在多个指标上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动化代码审查评论生成（RCG）可以减轻开发者负担，但现有基于生成和基于检索的方法各有局限。生成方法难以生成罕见但重要的语义标记，检索方法难以适应新代码情境。如何结合两者优势提升评论生成效果成为主要动机。

Method: 提出了将检索增强生成（RAG）方法应用于RCG，将预训练语言模型与检索到的历史代码审查案例结合，通过这些相关示例提升生成评论的准确性和适应性。

Result: 在Tufano等人提出的基准数据集上，RAG方法在精确匹配度（+1.67%）和BLEU分数（+4.25%）上均优于单独的生成和检索方法，并在生成低频真实标记方面提升最大达到24.01%。进一步发现，检索示例数量越多，模型效果越好。

Conclusion: 检索增强生成模型能够有效融合生成和检索方法优势，显著提升自动化代码审查评论生成的质量与灵活性。

Abstract: Automated code review comment generation (RCG) aims to assist developers by
automatically producing natural language feedback for code changes. Existing
approaches are primarily either generation-based, using pretrained language
models, or information retrieval-based (IR), reusing comments from similar past
examples. While generation-based methods leverage code-specific pretraining on
large code-natural language corpora to learn semantic relationships between
code and natural language, they often struggle to generate low-frequency but
semantically important tokens due to their probabilistic nature. In contrast,
IR-based methods excel at recovering such rare tokens by copying from existing
examples but lack flexibility in adapting to new code contexts-for example,
when input code contains identifiers or structures not found in the retrieval
database. To bridge the gap between generation-based and IR-based methods, this
work proposes to leverage retrieval-augmented generation (RAG) for RCG by
conditioning pretrained language models on retrieved code-review exemplars. By
providing relevant examples that illustrate how similar code has been
previously reviewed, the model is better guided to generate accurate review
comments. Our evaluation on the Tufano et al. benchmark shows that RAG-based
RCG outperforms both generation-based and IR-based RCG. It achieves up to
+1.67% higher exact match and +4.25% higher BLEU scores compared to
generation-based RCG. It also improves the generation of low-frequency
ground-truth tokens by up to 24.01%. We additionally find that performance
improves as the number of retrieved exemplars increases.

</details>


### [64] [Further Evidence on a Controversial Topic about Human-Based Experiments: Professionals vs. Students](https://arxiv.org/abs/2506.11597)
*Simone Romano,Francesco Paolo Sferratore,Giuseppe Scanniello*

Main category: cs.SE

TL;DR: 作者对比了学生与业界工程师在软件缺陷修复任务中的表现，发现学生整体优于在职专家。该结果与过去部分研究相悖，但未下定论，旨在引发更多关于实验参与者选择和实验设计现实性的研究讨论。


<details>
  <summary>Details</summary>
Motivation: 大多数软件工程（SE）受控实验通常以学生为被试，这引发了有关实验外部有效性的担忧，特别是用学生获得的结果是否具备现实性，并能否推广到软件工业实践中。本文旨在探讨并为这一争议性话题提供更多证据。

Method: 作者对62名计算机科学本科生和42名来自两家跨国公司的软件工程师进行对比实验，让两组被试在同一个Java项目上进行修复Bug任务。值得注意的是，两组实验设置有细微不同：专业人士实验环境更接近现实，例如在修Bug过程中面临中断等压力因素。

Result: 实验数据显示，学生在修复Bug任务中表现优于专业人士，这一结果与部分既往实证证据不一致。

Conclusion: 本文结果并未给出明确结论，而是希望激发对SE实验中被试选择的进一步讨论，并为今后研究铺路。作者鼓励对影响SE任务表现的复杂因素进行深入探索，未来应让实验更具现实感。

Abstract: Most Software Engineering (SE) human-based controlled experiments rely on
students as participants, raising concerns about their external validity.
Specifically, the realism of results obtained from students and their
applicability to the software industry remains in question. In this short
paper, we bring further evidence on this controversial point. To do so, we
compare 62 students and 42 software professionals on a bug-fixing task on the
same Java program. The students were enrolled in a Bachelor's program in
Computer Science, while the professionals were employed by two multinational
companies (for one of them, the professionals were from two offices). Some
variations in the experimental settings of the two groups (students and
professionals) were present. For instance, the experimental environment of the
experiment with professionals was more realistic; i.e., they faced some stress
factors such as interruptions during the bug-fixing task. Considering the
differences between the two groups of participants, the gathered data show that
the students outperformed the professionals in fixing bugs. This diverges to
some extent from past empirical evidence. Rather than presenting definitive
conclusions, our results aim to catalyze the discussion on the use of students
in experiments and pave the way for future investigations. Specifically, our
results encourage us to examine the complex factors influencing SE tasks,
making experiments as more realistic as possible.

</details>


### [65] [Understanding API Usage and Testing: An Empirical Study of C Libraries](https://arxiv.org/abs/2506.11598)
*Ahmed Zaki,Cristian Cadar*

Main category: cs.SE

TL;DR: 论文通过分析C/C++开源库及其客户端，发现库的测试往往忽视了实际高频API的情况。利用客户端的测试案例有助于提升库的测试全面性和现实性，并开发了LibProbe工具，有助于开发者做出更合理的测试与维护决策。


<details>
  <summary>Details</summary>
Motivation: 库开发者需要了解API在实际中的使用，以优化bug优先级、功能需求和测试资源分配，但目前缺乏全面工具与对应研究，尤其是在C/C++生态中。

Method: 论文对21个流行开源C库及其3061个C/C++客户端的API使用情况进行了大规模实证研究，并开发了LibProbe工具用于分析和生成相关指标。对比了客户端API调用与库自带测试对API的覆盖程度，并进一步验证了引入客户端测试可提升库测试覆盖率。

Result: （1）流行API往往未被充分测试，例如LMDB库中45%的被用API未被测试；（2）引入客户端测试可提升测试覆盖率，如LMDB提升了14.7%；（3）LibProbe工具为大规模分析API使用与测试提供了新方法。

Conclusion: 本研究发现，库开发者在测试和维护API时，并未充分考虑到API在实际客户端中的使用情况，导致部分高频使用的API未被充分测试。通过结合客户端测试，可以显著提升库的测试覆盖率和现实代表性。

Abstract: For library developers, understanding how their Application Programming
Interfaces (APIs) are used in the field can be invaluable. Knowing how clients
are using their APIs allows for data-driven decisions on prioritising bug
reports, feature requests, and testing activities. For example, the priority of
a bug report concerning an API can be partly determined by how widely that API
is used.
  In this paper, we present an empirical study in which we analyse API usage
across 21 popular open-source C libraries, such as OpenSSL and SQLite, with a
combined total of 3,061 C/C++ clients. We compare API usage by clients with how
well library test suites exercise the APIs to offer actionable insights for
library developers. To our knowledge, this is the first study that compares API
usage and API testing at scale for the C/C++ ecosystem. Our study shows that
library developers do not prioritise their effort based on how clients use
their API, with popular APIs often poorly tested. For example, in LMDB, a
popular key-value store, 45% of the APIs are used by clients but not tested by
the library test suite. We further show that client test suites can be
leveraged to improve library testing e.g., improving coverage in LMDB by 14.7%
with the important advantage that those tests are representative of how the
APIs are used in the field.
  For our empirical study, we have developed LibProbe, a framework that can be
used to analyse a large corpus of clients for a given library and produce
various metrics useful to library developers.

</details>


### [66] [Accelerating Delta Debugging through Probabilistic Monotonicity Assessment](https://arxiv.org/abs/2506.11614)
*Yonggang Tao,Jingling Xue*

Main category: cs.SE

TL;DR: 本论文提出了一种概率性单调性评估方法PMA，用于提升增量调试工具在实际非严格单调性条件下的效率，经实验验证能大幅减少调试时间并优化最终结果。


<details>
  <summary>Details</summary>
Motivation: delta debugging（增量调试）假设搜索空间具有单调性，但实际中该假设并不总是成立，因此有必要提升算法在非完全单调性情况下的效率和效果。

Method: 提出Probabilistic Monotonicity Assessment（PMA）方法，该方法基于已有测试动态建模并评估搜索空间的单调性，利用置信度函数来量化单调性，从而概率性地排除某些子集的测试。方法嵌入于DDMIN算法流程中以提升效率。

Result: PMA方法分别与CHISEL和ProbDD进行了对比实验，相比CHISEL，处理时间减少59.2%，删除速度提升3.32倍，最终缩减程序体积减少6.7%；相比ProbDD，处理时间减少22%，缩减速度提升1.34倍，最终程序体积减少3.0%。

Conclusion: PMA方法在不降低缩减质量的基础上显著提高了delta debugging的效率和效果，适应了实际中非严格单调性的搜索空间。

Abstract: Delta debugging assumes search space monotonicity: if a program causes a
failure, any supersets of that program will also induce the same failure,
permitting the exclusion of subsets of non-failure-inducing programs. However,
this assumption does not always hold in practice. This paper introduces
Probabilistic Monotonicity Assessment (PMA), enhancing the efficiency of
DDMIN-style algorithms without sacrificing effectiveness. PMA dynamically
models and assesses the search space's monotonicity based on prior tests tried
during the debugging process and uses a confidence function to quantify
monotonicity, thereby enabling the probabilistic exclusion of subsets of
non-failure-inducing programs. Our approach significantly reduces redundant
tests that would otherwise be performed, without compromising the quality of
the reduction.
  We evaluated PMA against two leading DDMIN-style tools, CHISEL and ProbDD.
Our findings indicate that PMA cuts processing time by 59.2% compared to
CHISEL, accelerates the reduction process (i.e., the number of tokens deleted
per second) by 3.32x, and decreases the sizes of the final reduced programs by
6.7%. Against ProbDD, PMA reduces processing time by 22.0%, achieves a 1.34x
speedup in the reduction process, and further decreases the sizes of the final
reduced programs by 3.0%. These findings affirm PMA's role in significantly
improving delta debugging's efficiency while maintaining or enhancing its
effectiveness.

</details>


### [67] [An Empirical study on LLM-based Log Retrieval for Software Engineering Metadata Management](https://arxiv.org/abs/2506.11659)
*Simin Sun,Yuchuan Jin,Miroslaw Staron*

Main category: cs.SE

TL;DR: 本文提出用大语言模型辅助自动驾驶日志检索，将日志和视频结合，用自然语言而非SQL实现高效且可靠的场景查询，简化流程并验证有效性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统开发过程中需要分析大量的高频日志数据，但由于信号种类繁杂且部分开发者对信号含义不熟悉，导致查询和定位特定驾驶场景困难，传统SQL查询又要求高领域及数据库知识，且结果难以验证。

Method: 提出一种结合大语言模型（LLM）的新方法，将信号日志数据与测试视频结合，利用自然语言查询驱动场景检索。设计了场景距离图和相对间隙指标，量化评估查询结果的可靠性。方法通过API实现高效查询，并配合视频帧直观展示结果。

Result: 在公开工业数据集上的测试表明，该方法场景检索的效率和可靠性更高，降低了对单一数据源和传统SQL的依赖。

Conclusion: 该工作用LLM提升了自动驾驶日志检索的友好性与准确性，简化了查询流程，使得非专业人员也能高效查找目标场景，并增强了结果的可验证性。

Abstract: Developing autonomous driving systems (ADSs) involves generating and storing
extensive log data from test drives, which is essential for verification,
research, and simulation. However, these high-frequency logs, recorded over
varying durations, pose challenges for developers attempting to locate specific
driving scenarios. This difficulty arises due to the wide range of signals
representing various vehicle components and driving conditions, as well as
unfamiliarity of some developers' with the detailed meaning of these signals.
Traditional SQL-based querying exacerbates this challenge by demanding both
domain expertise and database knowledge, often yielding results that are
difficult to verify for accuracy.
  This paper introduces a Large Language Model (LLM)-supported approach that
combines signal log data with video recordings from test drives, enabling
natural language based scenario searches while reducing the need for
specialized knowledge. By leveraging scenario distance graphs and relative gap
indicators, it provides quantifiable metrics to evaluate the reliability of
query results. The method is implemented as an API for efficient database
querying and retrieval of relevant records, paired with video frames for
intuitive visualization. Evaluation on an open industrial dataset demonstrates
improved efficiency and reliability in scenario retrieval, eliminating
dependency on a single data source and conventional SQL.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [68] [Decidable Reversible Equivalences for Finite Petri Nets](https://arxiv.org/abs/2506.11517)
*Roberto Gorrieri,Ivan Lanese*

Main category: cs.LO

TL;DR: 本文提出并分析了两种在有限Petri网下可判定且可逆的新型行为等价关系，为并发系统判等理论带来新突破。


<details>
  <summary>Details</summary>
Motivation: 在Petri网的领域中，研究如何定义和判定系统间更细致的可逆行为等价关系。以往历史保留互模拟与其衍生等价关系面临不可判定性等理论与实际问题，因此有必要探索既能刻画真实并发性，又可判定的等价关系。

Method: 本文严格分析了因果网互模拟（causal-net bisimilarity）、新提出的遗传性因果网互模拟，以及与之相关的结构保留互模拟、位置互模拟等等价关系，通过理论证明分析它们之间的关系与判定性，重点研究了它们是否是可逆等价关系并且在有限有界Petri网上的可判定性。

Result: 证明了因果网互模拟和遗传性因果网互模拟是等价的，两者都属于可逆的行为等价关系，且等价于结构保留互模拟，可判定于有限有界Petri网；位置互模拟比因果网互模拟更细致，同样可逆且在有限网下可判定。而传统的遗传历史保留互模拟虽然更粗糙，但在安全Petri网下是不可判定的。

Conclusion: 本文为Petri网中真实并发语义下提供了两种新的可判定且可逆的行为等价关系——因果网互模拟与位置互模拟，作为不可判定的遗传历史保留互模拟的有效替代。

Abstract: In the setting of Petri nets, we prove that {\em causal-net bisimilarity}
\cite{G15,Gor22,Gor25a}, which is a refinement of history-preserving
bisimilarity \cite{RT88,vGG89,DDM89}, and the novel {\em hereditary} causal-net
bisimilarity, which is a refinement of hereditary history-preserving
bisimilarity \cite{Bed91,JNW96}, do coincide. This means that causal-net
bisimilarity is a {\em reversible behavioral equivalence}, as causal-net
bisimilar markings not only are able to match each other's forward transitions,
but also backward transitions by undoing performed events. Causal-net
bisimilarity can be equivalently formulated as {\em structure-preserving
bisimilarity} \cite{G15,Gor25a}, that is decidable on finite bounded Petri nets
\cite{CG21a}. Moreover, place bisimilarity \cite{ABS91}, that we prove to be
finer than causal-net bisimilarity, is also reversible and it was proved
decidable for finite Petri nets in \cite{Gor21decid,Gor25a}. These results
offer two decidable reversible behavioral equivalences in the true concurrency
spectrum, which are alternative to the coarser hereditary history-preserving
bisimilarity \cite{Bed91,JNW96}, that, unfortunately, is undecidable even for
safe Petri nets \cite{JNS03}.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [69] [TeleEval-OS: Performance evaluations of large language models for operations scheduling](https://arxiv.org/abs/2506.11017)
*Yanyan Wang,Yingying Wang,Junli Liang,Yin Xu,Yunlong Liu,Yiming Xu,Zhengwang Jiang,Zhehe Li,Fei Li,Long Zhao,Kuang Xu,Qi Song,Xiangyang Li*

Main category: cs.CL

TL;DR: 本文提出首个电信运维调度大模型基准TeleEval-OS，系统评测开源与闭源LLM表现，发现开源模型在部分任务上优于闭源模型，显示其应用前景广阔。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）已在多领域展现强大潜力，但其在电信运维调度领域的应用尚缺乏系统性评估与专用基准，复杂且高度专业的运维任务进一步限制了模型能力的探索。

Method: 作者提出首个电信运维调度评测基准（TeleEval-OS），涵盖13个子任务、15个数据集，模拟智能派单、处理、结单、评估四个核心阶段，按难度分为四个层级，并采用零样本与少样本等方式，系统评测10个开源与4个闭源大模型。

Result: 实验显示，开源LLMs在部分任务场景下超越了闭源LLMs，表现出在电信运维调度领域的巨大潜力和价值。

Conclusion: TeleEval-OS为电信运维调度领域LLM应用提供了标准化评测工具，并验证了开源大模型的强大能力，将推动相关研究和实际应用进步。

Abstract: The rapid advancement of large language models (LLMs) has significantly
propelled progress in artificial intelligence, demonstrating substantial
application potential across multiple specialized domains. Telecommunications
operation scheduling (OS) is a critical aspect of the telecommunications
industry, involving the coordinated management of networks, services, risks,
and human resources to optimize production scheduling and ensure unified
service control. However, the inherent complexity and domain-specific nature of
OS tasks, coupled with the absence of comprehensive evaluation benchmarks, have
hindered thorough exploration of LLMs' application potential in this critical
field. To address this research gap, we propose the first Telecommunications
Operation Scheduling Evaluation Benchmark (TeleEval-OS). Specifically, this
benchmark comprises 15 datasets across 13 subtasks, comprehensively simulating
four key operational stages: intelligent ticket creation, intelligent ticket
handling, intelligent ticket closure, and intelligent evaluation. To
systematically assess the performance of LLMs on tasks of varying complexity,
we categorize their capabilities in telecommunications operation scheduling
into four hierarchical levels, arranged in ascending order of difficulty: basic
NLP, knowledge Q&A, report generation, and report analysis. On TeleEval-OS, we
leverage zero-shot and few-shot evaluation methods to comprehensively assess 10
open-source LLMs (e.g., DeepSeek-V3) and 4 closed-source LLMs (e.g., GPT-4o)
across diverse scenarios. Experimental results demonstrate that open-source
LLMs can outperform closed-source LLMs in specific scenarios, highlighting
their significant potential and value in the field of telecommunications
operation scheduling.

</details>


### [70] [Who is in the Spotlight: The Hidden Bias Undermining Multimodal Retrieval-Augmented Generation](https://arxiv.org/abs/2506.11063)
*Jiayu Yao,Shenghua Liu,Yiwei Wang,Lingrui Mei,Baolong Bi,Yuyao Ge,Zhecheng Li,Xueqi Cheng*

Main category: cs.CL

TL;DR: 本文首次系统性分析了多模态RAG系统中的证据顺序偏见，提出了位置敏感指数进行量化，发现多模态交互强化了位置依赖性，针对该偏见建议采用证据重排序或去偏措施提升系统鲁棒性与公平性。


<details>
  <summary>Details</summary>
Motivation: 多模态检索增强生成（RAG）系统在需要丰富知识和开放领域的任务中非常重要，但随着检索复杂性提升，这些系统对于证据输入顺序的敏感性造成性能不稳定和推理偏见。

Method: 作者设计了全面的对照实验，涵盖文本、图像和混合模态任务，首次系统性地研究了证据顺序对多模态RAG系统性能的影响；提出了位置敏感指数（PSI_p）来量化这种偏差，并开发了可视化框架追踪解码器各层注意力分布变化。

Result: 实验显示证据位置对RAG模型表现有一致的U型影响曲线，多模态情境下位置偏见比单一模态更强，且随着检索范围扩大，该偏见呈对数增长。

Conclusion: 多模态RAG系统对证据位置高度敏感，需要引入证据重新排序或去偏方法，以构建更鲁棒与公平的生成系统。

Abstract: Multimodal Retrieval-Augmented Generation (RAG) systems have become essential
in knowledge-intensive and open-domain tasks. As retrieval complexity
increases, ensuring the robustness of these systems is critical. However,
current RAG models are highly sensitive to the order in which evidence is
presented, often resulting in unstable performance and biased reasoning,
particularly as the number of retrieved items or modality diversity grows. This
raises a central question: How does the position of retrieved evidence affect
multimodal RAG performance? To answer this, we present the first comprehensive
study of position bias in multimodal RAG systems. Through controlled
experiments across text-only, image-only, and mixed-modality tasks, we observe
a consistent U-shaped accuracy curve with respect to evidence position. To
quantify this bias, we introduce the Position Sensitivity Index ($PSI_p$) and
develop a visualization framework to trace attention allocation patterns across
decoder layers. Our results reveal that multimodal interactions intensify
position bias compared to unimodal settings, and that this bias increases
logarithmically with retrieval range. These findings offer both theoretical and
empirical foundations for position-aware analysis in RAG, highlighting the need
for evidence reordering or debiasing strategies to build more reliable and
equitable generation systems.

</details>


### [71] [Smotrom tvoja pa ander drogoj verden! Resurrecting Dead Pidgin with Generative Models: Russenorsk Case Study](https://arxiv.org/abs/2506.11065)
*Alexey Tikhonov,Sergei Shteiner,Anna Bykova,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: 本文利用大型语言模型分析了历史混合语Russenorsk的词汇和语法规律，构建了结构化词典和翻译工具，验证并丰富了相关学术假说，推动了AI辅助语言研究的发展。


<details>
  <summary>Details</summary>
Motivation: Russenorsk是一种曾在俄语和挪威语使用者之间贸易交流中形成的独特混合语种，但其词汇和语法结构尚未得到系统分析。随着大型语言模型（LLMs）的发展，作者希望利用现代技术对其词汇和结构进行深入研究。

Method: 作者首先基于现存文献建立了Russenorsk的结构化词典，将词汇按同义词和词源进行分类。然后，利用该词典与大型语言模型，提出语言构词与语法结构的假设，并与学术文献中的既有假说进行对比。此外，作者还开发了一个“复原”翻译代理，可生成现代俄语和挪威语文本的假想Russenorsk译文。

Result: 研究分析了Russenorsk的核心词汇、词源和构词及语法规则，通过现代LLM工具验证并补充了已有学术研究的一些假说，同时也开发了可以生成Russenorsk译文的翻译工具。

Conclusion: 该研究展示了通过现代大模型分析历史混合语种词汇和结构的有效性，不仅扩展了对Russenorsk的认识，也为利用AI辅助语言历史和混合语言研究提供了新思路。

Abstract: Russenorsk, a pidgin language historically used in trade interactions between
Russian and Norwegian speakers, represents a unique linguistic phenomenon. In
this paper, we attempt to analyze its lexicon using modern large language
models (LLMs), based on surviving literary sources. We construct a structured
dictionary of the language, grouped by synonyms and word origins. Subsequently,
we use this dictionary to formulate hypotheses about the core principles of
word formation and grammatical structure in Russenorsk and show which
hypotheses generated by large language models correspond to the hypotheses
previously proposed ones in the academic literature. We also develop a
"reconstruction" translation agent that generates hypothetical Russenorsk
renderings of contemporary Russian and Norwegian texts.

</details>


### [72] [A Large Language Model Based Pipeline for Review of Systems Entity Recognition from Clinical Notes](https://arxiv.org/abs/2506.11067)
*Hieu Nghiem,Hemanth Reddy Singareddy,Zhuqi Miao,Jivan Lamichhane,Abdulaziz Ahmed,Johnson Thomas,Dursun Delen,William Paiva*

Main category: cs.CL

TL;DR: 本文提出一种结合开源与商用大语言模型的自动ROS实体抽取流程，实现了较低错误率和高可扩展性，是缓解医疗文档工作负担的有效方案。


<details>
  <summary>Details</summary>
Motivation: 在医疗环境下，手动提取和记录体格检查系统（Review of Systems，ROS）信息非常繁琐且成本高昂。利用大语言模型（LLM）自动提取临床笔记中的ROS实体可以显著减轻医生文书负担，提升效率，尤其适用于资源有限的医疗场景。

Method: 作者设计了一个基于LLM的自动化处理流程。该流程首先使用SecTag工具提取临床笔记中的ROS相关段落，然后通过少样本学习的LLM模型（包括Mistral、Llama、Gemma等开源模型和ChatGPT）识别ROS实体的位置、正负性状态及其隶属系统。随后在36份医学笔记（含341个标注实体）上进行了评估。

Result: 集成ChatGPT时，识别ROS实体的位置以及状态/所属系统的错误率最低（分别为28.2%和14.5%）。而使用开源LLM时，该流程能在本地、低成本部署，且其错误率也相近（实体识别：30.5-36.7%；状态/系统识别：24.3-27.3%），表现可观。

Conclusion: 提出的基于LLM的自动ROS实体提取流程具有可扩展性，且可本地化部署，有助于减轻医疗文档录入负担。开源LLM在资源有限环境中可作为商用模型的有效替代方案。

Abstract: Objective: Develop a cost-effective, large language model (LLM)-based
pipeline for automatically extracting Review of Systems (ROS) entities from
clinical notes. Materials and Methods: The pipeline extracts ROS sections using
SecTag, followed by few-shot LLMs to identify ROS entity spans, their
positive/negative status, and associated body systems. We implemented the
pipeline using open-source LLMs (Mistral, Llama, Gemma) and ChatGPT. The
evaluation was conducted on 36 general medicine notes containing 341 annotated
ROS entities. Results: When integrating ChatGPT, the pipeline achieved the
lowest error rates in detecting ROS entity spans and their corresponding
statuses/systems (28.2% and 14.5%, respectively). Open-source LLMs enable
local, cost-efficient execution of the pipeline while delivering promising
performance with similarly low error rates (span: 30.5-36.7%; status/system:
24.3-27.3%). Discussion and Conclusion: Our pipeline offers a scalable and
locally deployable solution to reduce ROS documentation burden. Open-source
LLMs present a viable alternative to commercial models in resource-limited
healthcare environments.

</details>


### [73] [Deontological Keyword Bias: The Impact of Modal Expressions on Normative Judgments of Language Models](https://arxiv.org/abs/2506.11068)
*Bumjin Park,Jinsil Lee,Jaesik Choi*

Main category: cs.CL

TL;DR: LLMs在道德判断时对must、ought to等情态词极为敏感，易误将非义务判为义务；提出的新方法对缓解此偏差有效，提示模型对齐需正视语言表述带来的影响。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型(LLMs)在道德和伦理推理中的应用越来越广泛，但人类自身对判断标准也常常不明确。因此，如何让LLM在判断义务类问题时做到合理对齐，是一个被忽视的重要领域。

Method: 通过实验，向模型输入包含情态词（如must, ought to）的情境，对比分析LLM在有/无情态词时的义务性判断表现，并跨多模型、问句类型及答案格式验证一致性。同时提出结合few-shot示例和推理提示的策略以缓解偏差。

Result: LLMs对于带有情态词的情境，倾向于将原本非义务性的情境错误判断为义务性（超90%），该现象被称为“义务关键词偏差（DKB）”，并且在不同模型和设置下都保持一致。作者提出的方法能有效缓解这一偏差。

Conclusion: 本研究揭示了情态词作为语言框架如何显著影响LLM的规范性判断，强调了注意和修正此类偏差对模型对齐的重要性。

Abstract: Large language models (LLMs) are increasingly engaging in moral and ethical
reasoning, where criteria for judgment are often unclear, even for humans.
While LLM alignment studies cover many areas, one important yet underexplored
area is how LLMs make judgments about obligations. This work reveals a strong
tendency in LLMs to judge non-obligatory contexts as obligations when prompts
are augmented with modal expressions such as must or ought to. We introduce
this phenomenon as Deontological Keyword Bias (DKB). We find that LLMs judge
over 90\% of commonsense scenarios as obligations when modal expressions are
present. This tendency is consist across various LLM families, question types,
and answer formats. To mitigate DKB, we propose a judgment strategy that
integrates few-shot examples with reasoning prompts. This study sheds light on
how modal expressions, as a form of linguistic framing, influence the normative
decisions of LLMs and underscores the importance of addressing such biases to
ensure judgment alignment.

</details>


### [74] [Consistent Autoformalization for Constructing Mathematical Libraries](https://arxiv.org/abs/2410.04194)
*Lan Zhang,Xin Quan,Andre Freitas*

Main category: cs.CL

TL;DR: 为提升LLM在数学自动形式化中的表现，作者提出结合最相似检索、去噪和自动修正机制，并验证此方案可以跨模型提升结果一致性与质量。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）在自然语言和形式语言理解上的进步，自动将数学自然语言内容翻译成形式化表达（自动形式化，autoformalization）变得可能，但在复杂和专业领域，现有LLM仍难以稳定、可靠地实现该任务。随着自动形式化逐步应用于大型数学库，提高语法、术语和语义的控制成为新需求。

Method: 本文提出联合使用三种机制来提升自动形式化质量：针对最相似实例的检索增强生成（MS-RAG）、去噪步骤以及带语法错误反馈的自动修正（Auto-SEF）。这些机制被设计为能够嵌入不同类型的LLM中。

Result: 实证分析显示，这三种机制可以显著提升自动形式化输出在语法、术语和语义方面的一致性，且在不同类型的LLM中均有效。

Conclusion: 方法能够有效提升自动形式化任务的质量与鲁棒性，对大型数学库的自动化形式化具有实际应用价值。

Abstract: Autoformalization is the task of automatically translating mathematical
content written in natural language to a formal language expression. The
growing language interpretation capabilities of Large Language Models (LLMs),
including in formal languages, are lowering the barriers for autoformalization.
However, LLMs alone are not capable of consistently and reliably delivering
autoformalization, in particular as the complexity and specialization of the
target domain grows. As the field evolves into the direction of systematically
applying autoformalization towards large mathematical libraries, the need to
improve syntactic, terminological and semantic control increases. This paper
proposes the coordinated use of three mechanisms, most-similar retrieval
augmented generation (MS-RAG), denoising steps, and auto-correction with syntax
error feedback (Auto-SEF) to improve autoformalization quality. The empirical
analysis, across different models, demonstrates that these mechanisms can
deliver autoformalizaton results which are syntactically, terminologically and
semantically more consistent. These mechanisms can be applied across different
LLMs and have shown to deliver improve results across different model types.

</details>


### [75] [Targeted control of fast prototyping through domain-specific interface](https://arxiv.org/abs/2506.11070)
*Yu-Zhe Shi,Mingchen Liu,Hanlu Ma,Qiao Xu,Huamin Qu,Kun He,Lecheng Ruan,Qining Wang*

Main category: cs.CL

TL;DR: 本文提出了一种连接设计师自然语言和建模语言的接口架构，显著提升了利用大语言模型实现产品原型快速建模的便捷性和控制精度，经多种评估验证有效。


<details>
  <summary>Details</summary>
Motivation: 工业设计师希望能够通过自然语言指令，简单直观地对原型模型进行精准控制，避免复杂的建模命令，但目前在语言与建模语言之间存在抽象层次、语义精度和词汇范围等差异，阻碍了此类自然交互的实现。

Method: 提出了一种接口架构，作为设计师自然语言与建模语言之间的桥梁。架构设计基于对快速原型实践的系统调查提炼的设计原则，还开发了其操作机制及自动化领域规范算法，通过机器评估和用户研究进行测试。

Result: 经机器评估与人工用户研究，接口作为大语言模型的辅助模块，能够实现对原型模型的精确、有效的目标控制，在多种产品设计场景中均显示出良好效果。

Conclusion: 该接口架构有效弥合了设计师自然语言和建模语言之间的差异，提高了大语言模型辅助工业设计原型建模的实用性和准确性。

Abstract: Industrial designers have long sought a natural and intuitive way to achieve
the targeted control of prototype models -- using simple natural language
instructions to configure and adjust the models seamlessly according to their
intentions, without relying on complex modeling commands. While Large Language
Models have shown promise in this area, their potential for controlling
prototype models through language remains partially underutilized. This
limitation stems from gaps between designers' languages and modeling languages,
including mismatch in abstraction levels, fluctuation in semantic precision,
and divergence in lexical scopes. To bridge these gaps, we propose an interface
architecture that serves as a medium between the two languages. Grounded in
design principles derived from a systematic investigation of fast prototyping
practices, we devise the interface's operational mechanism and develop an
algorithm for its automated domain specification. Both machine-based
evaluations and human studies on fast prototyping across various product design
domains demonstrate the interface's potential to function as an auxiliary
module for Large Language Models, enabling precise and effective targeted
control of prototype models.

</details>


### [76] [CLAIM: Mitigating Multilingual Object Hallucination in Large Vision-Language Models with Cross-Lingual Attention Intervention](https://arxiv.org/abs/2506.11073)
*Zekai Ye,Qiming Li,Xiaocheng Feng,Libo Qin,Yichong Huang,Baohang Li,Kui Jiang,Yang Xiang,Zhirui Zhang,Yunfei Lu,Duyu Tang,Dandan Tu,Bing Qin*

Main category: cs.CL

TL;DR: 本文提出一种高效的、几乎无需训练的方法CLAIM，通过对齐跨语言注意力模式，有效缓解了视觉-语言大模型在非英语环境下的物体幻觉问题，并在多项基准上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 大型视觉-语言模型（LVLMs）在多模态任务中表现突出，但在多语言环境下更容易产生物体幻觉（即回答内容与视觉输入不符），尤其在非英语查询下更为严重。现有缓解方法依赖预训练或微调，资源消耗大。

Method: 作者提出了一种几乎无需训练的新方法CLAIM（跨语言注意力干预），通过对齐不同语言下注意力模式来缓解多语言物体幻觉。CLAIM具体包括：1）识别出语言特定的跨模态注意力头；2）估算从英语到目标语言的注意力偏移向量；3）在推理阶段调整注意力输出，以提高不同语言下的视觉感知对齐能力。

Result: CLAIM可在无需大规模训练的情况下，平均提高POPE基准上13.56%（西班牙语最高可达30%）以及MME基准物体幻觉子集上21.75%的性能提升。分析还发现，多语言注意力的分歧主要出现在中间层，这些层在多语场景下作用关键。

Conclusion: CLAIM为减少LVLMs在多语言下物体幻觉问题提供了一种高效、无须重训练的解决方案，显著提升了多语言环境下的视觉理解能力，同时揭示了中间层注意力对多语言通用的重要作用。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated impressive multimodal
abilities but remain prone to multilingual object hallucination, with a higher
likelihood of generating responses inconsistent with the visual input when
utilizing queries in non-English languages compared to English. Most existing
approaches to address these rely on pretraining or fine-tuning, which are
resource-intensive. In this paper, inspired by observing the disparities in
cross-modal attention patterns across languages, we propose Cross-Lingual
Attention Intervention for Mitigating multilingual object hallucination (CLAIM)
in LVLMs, a novel near training-free method by aligning attention patterns.
CLAIM first identifies language-specific cross-modal attention heads, then
estimates language shift vectors from English to the target language, and
finally intervenes in the attention outputs during inference to facilitate
cross-lingual visual perception capability alignment. Extensive experiments
demonstrate that CLAIM achieves an average improvement of 13.56% (up to 30% in
Spanish) on the POPE and 21.75% on the hallucination subsets of the MME
benchmark across various languages. Further analysis reveals that multilingual
attention divergence is most prominent in intermediate layers, highlighting
their critical role in multilingual scenarios.

</details>


### [77] [CyclicReflex: Improving Large Reasoning Models via Cyclical Reflection Token Scheduling](https://arxiv.org/abs/2506.11077)
*Chongyu Fan,Yihua Zhang,Jinghan Jia,Alfred Hero,Sijia Liu*

Main category: cs.CL

TL;DR: 本文提出了一种动态调整大型推理模型中反思标记（reflection tokens）的方法CyclicReflex，并证明其在多个数学任务和不同模型规模下均有效提升推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在解决复杂问题时，常通过嵌入特殊的“反思标记”（如“wait”、“but”等）来促进多步推理过程。但这些反思标记过多或过少都可能影响模型性能。当前缺乏对反思标记使用频率和位置的动态调节方法。

Method: 作者提出将反思标记（reflection tokens）视为计算资源，并引入“资源分配”问题，通过动态调节反思标记的使用，提升推理模型的测试时计算性能。基于反思标记与优化中的学习率调度的类比，提出了一种基于三角波动态调整反思标记概率的新解码策略CyclicReflex。

Result: 实验表明，在MATH500、AIME2024/2025和AMC2023等任务中，CyclicReflex策略在不同模型规模下（1.5B-8B）均能稳定提升模型表现，优于标准解码及TIP、S1等新方法。

Conclusion: 合理、动态地调控反思标记的使用是提升大型推理模型推理性能的有效手段，CyclicReflex方法具备普适性和实际价值。

Abstract: Large reasoning models (LRMs), such as OpenAI's o1 and DeepSeek-R1, harness
test-time scaling to perform multi-step reasoning for complex problem-solving.
This reasoning process, executed before producing final answers, is often
guided by special juncture tokens or textual segments that prompt
self-evaluative reflection. We refer to these transition markers and reflective
cues as "reflection tokens" (e.g., "wait", "but", "alternatively"). In this
work, we treat reflection tokens as a "resource" and introduce the problem of
resource allocation, aimed at improving the test-time compute performance of
LRMs by adaptively regulating the frequency and placement of reflection tokens.
Through empirical analysis, we show that both excessive and insufficient use of
reflection tokens, referred to as over-reflection and under-reflection, can
degrade model performance. To better understand and manage this trade-off, we
draw an analogy between reflection token usage and learning rate scheduling in
optimization. Building on this insight, we propose cyclical reflection token
scheduling (termed CyclicReflex), a decoding strategy that dynamically
modulates reflection token logits using a position-dependent triangular
waveform. Experiments on MATH500, AIME2024/2025, and AMC2023 demonstrate that
CyclicReflex consistently improves performance across model sizes (1.5B-8B),
outperforming standard decoding and more recent approaches such as TIP (thought
switching penalty) and S1. Codes are available at
https://github.com/OPTML-Group/CyclicReflex.

</details>


### [78] [RoE-FND: A Case-Based Reasoning Approach with Dual Verification for Fake News Detection via LLMs](https://arxiv.org/abs/2506.11078)
*Yuzhou Yang,Yangming Zhou,Zhiying Zhu,Zhenxing Qian,Xinpeng Zhang,Sheng Li*

Main category: cs.CL

TL;DR: 本文提出了无需训练即可泛化到新情况的双阶段虚假新闻检测框架RoE-FND，既能复盘推理错误、动态生成证据判准，还能提升检测准确率和透明度，在多项数据集上超越现有最优方法。


<details>
  <summary>Details</summary>
Motivation: 当前网络上虚假新闻泛滥，对高效、健壮的虚假新闻检测系统需求迫切。现有基于证据的方法存在噪声证据选择、泛化能力不足和决策过程不透明的问题。近期利用大语言模型进行检测也带来了新的挑战，例如虚构推理和结论偏差。

Method: 提出了RoE-FND框架，将基于证据的虚假新闻检测重构为逻辑推理任务，结合大语言模型与经验学习。主要包括两个阶段：1) 自我反思知识构建——分析过去推理错误，构建知识库；2) 动态准则检索——从历史案例中提取任务相关推理准则，并在推理过程中交叉检验理由与内部经验（双通道处理）。

Result: 在三个公开数据集上实证验证RoE-FND框架具有更强的泛化能力和有效性，表现优于最新方法。此外，该方法无需微调训练即可适应新变化。

Conclusion: RoE-FND框架通过结合案例推理和经验学习，有效解决了现有方法的多项关键挑战，推动了虚假新闻检测的发展。

Abstract: The proliferation of deceptive content online necessitates robust Fake News
Detection (FND) systems. While evidence-based approaches leverage external
knowledge to verify claims, existing methods face critical limitations: noisy
evidence selection, generalization bottlenecks, and unclear decision-making
processes. Recent efforts to harness Large Language Models (LLMs) for FND
introduce new challenges, including hallucinated rationales and conclusion
bias. To address these issues, we propose \textbf{RoE-FND}
(\textbf{\underline{R}}eason \textbf{\underline{o}}n
\textbf{\underline{E}}xperiences FND), a framework that reframes evidence-based
FND as a logical deduction task by synergizing LLMs with experiential learning.
RoE-FND encompasses two stages: (1) \textit{self-reflective knowledge
building}, where a knowledge base is curated by analyzing past reasoning
errors, namely the exploration stage, and (2) \textit{dynamic criterion
retrieval}, which synthesizes task-specific reasoning guidelines from
historical cases as experiences during deployment. It further cross-checks
rationales against internal experience through a devised dual-channel
procedure. Key contributions include: a case-based reasoning framework for FND
that addresses multiple existing challenges, a training-free approach enabling
adaptation to evolving situations, and empirical validation of the framework's
superior generalization and effectiveness over state-of-the-art methods across
three datasets.

</details>


### [79] [MANBench: Is Your Multimodal Model Smarter than Human?](https://arxiv.org/abs/2506.11080)
*Han Zhou,Qitong Xu,Yiheng Dong,Xin Yang*

Main category: cs.CL

TL;DR: MANBench提出了一个大规模多模态评测基准，实验证明当前MLLMs在多领域仍不及人类，尤其在复杂推理任务中差距明显。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大模型（MLLMs）的快速发展，人们开始讨论其在多模态任务上是否可能超越人类。因此，有必要建立一个可以系统评估MLLMs与人类在多模态能力方面差距的基准。

Method: 作者提出了MANBench，这是一个涵盖英语和中文的双语多模态能力基准，包括1314道题，涵盖9大任务，侧重于直觉推理、跨模态整合和现实世界复杂性。作者还组织了大规模人类实验，将人类与最新MLLMs在这些任务上的表现进行了对比分析。

Result: 实验结果显示，MLLMs在知识和文本-图像理解等任务表现优异，但在跨模态推理、图像一致性及多图像理解等深层任务中表现不佳。无论人类还是MLLMs，在极其复杂的拼图及空间想象任务中均面临挑战。

Conclusion: MANBench系统展现了MLLMs的优势和短板，揭示即使是最先进的模型，在许多领域仍未达到人类水平。作者希望MANBench能推动MLLMs进一步提升向人类多模态能力靠拢。

Abstract: The rapid advancement of Multimodal Large Language Models (MLLMs) has ignited
discussions regarding their potential to surpass human performance in
multimodal tasks. In response, we introduce MANBench (Multimodal Ability Norms
Benchmark), a bilingual benchmark (English and Chinese) comprising 1,314
questions across nine tasks, spanning knowledge-based and non-knowledge-based
domains. MANBench emphasizes intuitive reasoning, seamless cross-modal
integration, and real-world complexity, providing a rigorous evaluation
framework.
  Through extensive human experiments involving diverse participants, we
compared human performance against state-of-the-art MLLMs. The results indicate
that while MLLMs excel in tasks like Knowledge and Text-Image Understanding,
they struggle with deeper cross-modal reasoning tasks such as Transmorphic
Understanding, Image Consistency, and Multi-image Understanding. Moreover, both
humans and MLLMs face challenges in highly complex tasks like Puzzles and
Spatial Imagination.
  MANBench highlights the strengths and limitations of MLLMs, revealing that
even advanced models fall short of achieving human-level performance across
many domains. We hope MANBench will inspire efforts to bridge the gap between
MLLMs and human multimodal capabilities. The code and dataset are available at
https://github.com/micdz/MANBench.

</details>


### [80] [SAGE:Specification-Aware Grammar Extraction for Automated Test Case Generation with LLMs](https://arxiv.org/abs/2506.11081)
*Aditi,Hyunwoo Park,Sicheol Sung,Yo-Sub Han,Sang-Ki Ko*

Main category: cs.CL

TL;DR: 本文提出用开源大模型结合强化学习生成高质量可约束文法，有效提升自动测试用例生成的泛化与准确性，显著领先现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 尽管基于文法的测试用例生成在竞赛编程问题中效果良好，但从自然语言规范自动生成有效、通用的文法仍具挑战性，尤其在标注样本有限的情况下。现有的自然语言到文法的自动化方法精度与泛化性不足，需要新方案提升文法生成的质量和效率。

Method: 首先微调开源大语言模型（LLM）以实现从规范到文法的翻译；然后采用Group Relative Policy Optimization（GRPO）进行强化学习，提升生成文法的有效性与通用性。此外，作者还评估了基于反馈机制对开源与闭源LLM进行迭代纠错的效果。

Result: 实验表明，SAGE在文法有效性上比最新方法提升15.92个百分点，测试有效性提升12.34个百分点，并在文法质量和测试效果上优于17种开闭源大模型。

Conclusion: 本文提出的方法SAGE能够有效提升从自然语言规范生成符合约束的文法（CCFGs）的准确性和通用性，在文法质量与测试有效性方面均超越现有17种主流大模型，显著优于最新方法。

Abstract: Grammar-based test case generation has proven effective for competitive
programming problems, but generating valid and general grammars from natural
language specifications remains a key challenge, especially under limited
supervision. Context-Free Grammars with Counters (CCFGs) have recently been
introduced as a formalism to represent such specifications with logical
constraints by storing and reusing counter values during derivation. In this
work, we explore the use of open-source large language models (LLMs) to induce
CCFGs from specifications using a small number of labeled examples and
verifiable reward-guided reinforcement learning. Our approach first fine-tunes
an open-source LLM to perform specification-to-grammar translation, and further
applies Group Relative Policy Optimization (GRPO) to enhance grammar validity
and generality. We also examine the effectiveness of iterative feedback for
open and closed-source LLMs in correcting syntactic and semantic errors in
generated grammars.
  Experimental results show that our approach SAGE achieves stronger
generalization and outperforms 17 open and closed-source LLMs in both grammar
quality and test effectiveness, improving over the state-of-the-art by 15.92%p
in grammar validity and 12.34%p in test effectiveness. We provide our
implementation and dataset at the following anonymous
repository:https://anonymous.4open.science/r/SAGE-5714

</details>


### [81] [PRISM: A Transformer-based Language Model of Structured Clinical Event Data](https://arxiv.org/abs/2506.11082)
*Lionel Levine,John Santerre,Alex S. Young,T. Barry Levine,Francis Campion,Majid Sarrafzadeh*

Main category: cs.CL

TL;DR: PRISM是一种基于Transformer的模型，将临床流程建模为事件序列，显著提升了医疗决策序列的预测准确度，有望用于临床决策支持和教育。


<details>
  <summary>Details</summary>
Motivation: 传统的临床决策建模侧重于单个诊断分类，难以捕捉实际诊断过程中的复杂依赖关系。研究动机在于建立能更真实模拟临床决策序列的建模方法。

Method: 该研究提出了一种基于Transformer的架构PRISM，将临床决策流程建模为事件序列，利用自回归训练目标和自定义医疗词表进行下一步事件预测。

Result: PRISM在下一事件预测任务上显著优于随机基线，生成的事件序列能够反映实际的诊断路径及医护人员行为。

Conclusion: PRISM能够模拟真实医疗过程中诊断路径、实验室结果进展和临床决策行为，为临床决策支持、模拟和教育等应用提供了可行方法。

Abstract: We introduce PRISM (Predictive Reasoning in Sequential Medicine), a
transformer-based architecture designed to model the sequential progression of
clinical decision-making processes. Unlike traditional approaches that rely on
isolated diagnostic classification, PRISM frames clinical trajectories as
tokenized sequences of events - including diagnostic tests, laboratory results,
and diagnoses - and learns to predict the most probable next steps in the
patient diagnostic journey. Leveraging a large custom clinical vocabulary and
an autoregressive training objective, PRISM demonstrates the ability to capture
complex dependencies across longitudinal patient timelines. Experimental
results show substantial improvements over random baselines in next-token
prediction tasks, with generated sequences reflecting realistic diagnostic
pathways, laboratory result progressions, and clinician ordering behaviors.
These findings highlight the feasibility of applying generative language
modeling techniques to structured medical event data, enabling applications in
clinical decision support, simulation, and education. PRISM establishes a
foundation for future advancements in sequence-based healthcare modeling,
bridging the gap between machine learning architectures and real-world
diagnostic reasoning.

</details>


### [82] [RedDebate: Safer Responses through Multi-Agent Red Teaming Debates](https://arxiv.org/abs/2506.11083)
*Ali Asad,Stephen Obadinma,Radin Shayanfar,Xiaodan Zhu*

Main category: cs.CL

TL;DR: RedDebate让多个大模型互相辩论、发现安全问题并自我改进，无需人工就能稳步提升AI安全，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 目前AI安全方法高度依赖于昂贵的人类评估或单一模型的自我评估，这在可扩展性和监督上都存在诸多限制。如何在无需过多人工干预下，主动发现与缓解大型语言模型（LLM）自身的不安全行为，是亟需解决的问题。

Method: 提出RedDebate框架，让多个LLM代理之间相互进行对抗性辩论，实现协作式质疑和自动化red-teaming，通过持续的多轮互动自动发现盲区、不安全行为并改进答案。此外，RedDebate还集成多种长期记忆模块，保留和积累在辩论中获得的安全知识，用于提升后续表现。

Result: 在公开安全数据集（HarmBench）上评测结果表明，仅使用多代理辩论可以减少17.7%的不安全行为，结合长期记忆模块后可减少超过23.5%。

Conclusion: RedDebate是首个将多代理自动化辩论与red-teaming结合、能在无需人工介入下不断提升AI安全性的框架。该方法在提升LLM安全表现上展现出有效性和创新性。

Abstract: We propose RedDebate, a novel multi-agent debate framework that leverages
adversarial argumentation among Large Language Models (LLMs) to proactively
identify and mitigate their own unsafe behaviours. Existing AI safety methods
often depend heavily on costly human evaluations or isolated single-model
assessment, both subject to scalability constraints and oversight risks.
RedDebate instead embraces collaborative disagreement, enabling multiple LLMs
to critically examine one another's reasoning, and systematically uncovering
unsafe blind spots through automated red-teaming, and iteratively improve their
responses. We further integrate distinct types of long-term memory that retain
learned safety insights from debate interactions. Evaluating on established
safety benchmarks such as HarmBench, we demonstrate the proposed method's
effectiveness. Debate alone can reduce unsafe behaviours by 17.7%, and when
combined with long-term memory modules, achieves reductions exceeding 23.5%. To
our knowledge, RedDebate constitutes the first fully automated framework that
combines multi-agent debates with red-teaming to progressively enhance AI
safety without direct human intervention.(Github Repository:
https://github.com/aliasad059/RedDebate)

</details>


### [83] [Two Birds with One Stone: Improving Factuality and Faithfulness of LLMs via Dynamic Interactive Subspace Editing](https://arxiv.org/abs/2506.11088)
*Pengbo Wang,Chaozhuo Li,Chenxu Wang,Liwen Zheng,Litian Zhang,Xi Zhang*

Main category: cs.CL

TL;DR: 该论文发现并利用LLM内部事实性和忠实性幻觉存在重叠激活子空间，通过设计SPACE框架进行联合建模与干预，同时提升模型的事实性和忠实性，实验显示效果优越。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）虽在自然语言处理领域展现前所未有的能力，但实际部署时仍被“事实性”和“忠实性”幻觉问题所困扰。现有的消除幻觉方法通常单独处理这类问题，导致一类改善后另一类恶化，存在性能权衡。因此需寻找兼顾二者的解决方案。

Method: 论文提出名为SPACE的统一框架：首先通过对双任务特征建模，证明在神经表征中存在共享子空间；再利用混合探针策略（结合谱聚类与注意力头显著性打分）定位并编辑这些共享激活子空间，以同时提升事实性和忠实性。

Result: 实验结果表明，在多个基准数据集上，SPACE方法在提升LLM的事实性与忠实性方面优于现有方法，展现了明显的性能提升。

Conclusion: SPACE框架能够通过编辑共享神经激活子空间来同步缓解事实性和忠实性幻觉，为LLM的安全可控应用提供新思路。

Abstract: LLMs have demonstrated unprecedented capabilities in natural language
processing, yet their practical deployment remains hindered by persistent
factuality and faithfulness hallucinations. While existing methods address
these hallucination types independently, they inadvertently induce performance
trade-offs, as interventions targeting one type often exacerbate the other.
Through empirical and theoretical analysis of activation space dynamics in
LLMs, we reveal that these hallucination categories share overlapping subspaces
within neural representations, presenting an opportunity for concurrent
mitigation. To harness this insight, we propose SPACE, a unified framework that
jointly enhances factuality and faithfulness by editing shared activation
subspaces. SPACE establishes a geometric foundation for shared subspace
existence through dual-task feature modeling, then identifies and edits these
subspaces via a hybrid probe strategy combining spectral clustering and
attention head saliency scoring. Experimental results across multiple benchmark
datasets demonstrate the superiority of our approach.

</details>


### [84] [Customizing Speech Recognition Model with Large Language Model Feedback](https://arxiv.org/abs/2506.11091)
*Shaoshi Ling,Guoli Ye*

Main category: cs.CL

TL;DR: 该论文通过引入基于大语言模型反馈信号的无监督强化学习方法，有效提升了ASR在专有名词及领域转录上的表现，实体词错误率比传统方法降低21%。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别（ASR）系统在一般转录任务中表现较好，但在识别罕见专有名词和适应领域不匹配方面依然存在困难。相比之下，大型语言模型（LLM）在众多领域常常表现更优。因此，提升ASR系统的领域适应能力成为亟需解决的问题。

Method: 本文提出了一种基于强化学习的无监督领域自适应方法。通过利用无标签数据，并借助大语言模型对ASR模型输出进行打分，将得分作为奖励信号，用于强化学习微调ASR模型。这样的方法可提升专有名词的转录效果，尤其是在领域不匹配的情况下。

Result: 所提方法在实体单词错误率（entity word error rate）上相较于传统自训练方法实现了21%的提升。

Conclusion: 该工作证明，通过利用无监督的强化学习和大语言模型作为奖励模型，可以显著提升ASR对领域特有名词的识别能力，有效缓解领域不匹配带来的性能下降。

Abstract: Automatic speech recognition (ASR) systems have achieved strong performance
on general transcription tasks. However, they continue to struggle with
recognizing rare named entities and adapting to domain mismatches. In contrast,
large language models (LLMs), trained on massive internet-scale datasets, are
often more effective across a wide range of domains. In this work, we propose a
reinforcement learning based approach for unsupervised domain adaptation,
leveraging unlabeled data to enhance transcription quality, particularly the
named entities affected by domain mismatch, through feedback from a LLM. Given
contextual information, our framework employs a LLM as the reward model to
score the hypotheses from the ASR model. These scores serve as reward signals
to fine-tune the ASR model via reinforcement learning. Our method achieves a
21\% improvement on entity word error rate over conventional self-training
methods.

</details>


### [85] [Dynamic Context Tuning for Retrieval-Augmented Generation: Enhancing Multi-Turn Planning and Tool Adaptation](https://arxiv.org/abs/2506.11092)
*Jubin Abhishek Soni,Amit Anand,Rajesh Kumar Pandey,Aniket Abhishek Soni*

Main category: cs.CL

TL;DR: 本论文针对RAG系统在动态环境下的局限，提出DCT框架，通过上下文缓存、动态检索和上下文压缩，让RAG支持多轮对话和动态工具选择，无需重新训练，且显著提升准确率与效率，有望广泛用于可扩展的AI助手。


<details>
  <summary>Details</summary>
Motivation: 现有的基于检索增强生成（RAG）系统大多局限于静态、单轮的交互和固定的工具集，这让它们在用户需求、工具和环境不断变化的动态领域（如医疗、智能家居）中表现不佳。

Method: 提出了一种名为“Dynamic Context Tuning（DCT）”的轻量级框架，扩展RAG以支持多轮对话和工具环境的变化，无需重新训练。DCT引入基于注意力的上下文缓存跟踪相关历史信息，基于LoRA的检索动态选择领域工具，并采用高效上下文压缩以适应LLM输入长度限制。

Result: 在合成和真实世界基准上，DCT将计划准确率提升了14%，降低了37%的幻觉现象，并能够以远低于GPT-4的成本实现相当的性能。此外，DCT还能泛化到未见过的新工具。

Conclusion: DCT使RAG系统能够在动态环境中更高效地适应和扩展，提高了多轮对话与工具选择的灵活性和准确性，为大规模及可适应性的AI助手奠定了基础。

Abstract: Retrieval-Augmented Generation (RAG) has significantly advanced large
language models (LLMs) by grounding their outputs in external tools and
knowledge sources. However, existing RAG systems are typically constrained to
static, single-turn interactions with fixed toolsets, making them ill-suited
for dynamic domains such as healthcare and smart homes, where user intent,
available tools, and contextual factors evolve over time. We present Dynamic
Context Tuning (DCT), a lightweight framework that extends RAG to support
multi-turn dialogue and evolving tool environments without requiring
retraining. DCT integrates an attention-based context cache to track relevant
past information, LoRA-based retrieval to dynamically select domain-specific
tools, and efficient context compression to maintain inputs within LLM context
limits. Experiments on both synthetic and real-world benchmarks show that DCT
improves plan accuracy by 14% and reduces hallucinations by 37%, while matching
GPT-4 performance at significantly lower cost. Furthermore, DCT generalizes to
previously unseen tools, enabling scalable and adaptable AI assistants across a
wide range of dynamic environments.

</details>


### [86] [The Scales of Justitia: A Comprehensive Survey on Safety Evaluation of LLMs](https://arxiv.org/abs/2506.11094)
*Songyang Liu,Chaozhuo Li,Jiameng Qiu,Xi Zhang,Feiran Huang,Litian Zhang,Yiming Hei,Philip S. Yu*

Main category: cs.CL

TL;DR: 该论文系统综述了大语言模型安全性评估领域的研究进展，梳理了评估背景、维度、方法、工具，以及当前面临的挑战并提出前瞻性研究方向，突出了安全性评估在LLMs实际部署中的重要作用。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在自然语言处理领域展现出巨大潜力，但在广泛应用过程中，其生成内容中出现了毒性、偏见等安全问题，引发学术界和工业界广泛关注，亟需对现有安全性评估研究进行系统性综述。

Method: 本文以综述（survey）形式，系统梳理和总结了关于LLMs安全性评估的最新研究进展。内容包括评估的动机、评估目标（如毒性、鲁棒性、伦理、真确性等）、评估用的数据集与度量、评估工具与方法，并梳理面临的挑战与未来研究方向。

Result: 本文对LLMs安全性评估的关键方面进行了全面总结：一是阐明了安全性评估的重要性；二是基于多维度能力对评估任务进行归类；三是对当前主流的评估数据集与基准进行总结；四是归纳了评估工具和方法。最后，提出了当前领域面临的若干挑战与后续研究建议。

Conclusion: LLMs的安全性评估是模型落地应用前的关键环节。系统梳理现有评估研究有助于厘清现状、解决安全问题，加速安全技术的发展与应用推行。为后续LLMs安全性研究提供了有力参考。

Abstract: With the rapid advancement of artificial intelligence technology, Large
Language Models (LLMs) have demonstrated remarkable potential in the field of
Natural Language Processing (NLP), including areas such as content generation,
human-computer interaction, machine translation, and code generation, among
others. However, their widespread deployment has also raised significant safety
concerns. In recent years, LLM-generated content has occasionally exhibited
unsafe elements like toxicity and bias, particularly in adversarial scenarios,
which has garnered extensive attention from both academia and industry. While
numerous efforts have been made to evaluate the safety risks associated with
LLMs, there remains a lack of systematic reviews summarizing these research
endeavors. This survey aims to provide a comprehensive and systematic overview
of recent advancements in LLMs safety evaluation, focusing on several key
aspects: (1) "Why evaluate" that explores the background of LLMs safety
evaluation, how they differ from general LLMs evaluation, and the significance
of such evaluation; (2) "What to evaluate" that examines and categorizes
existing safety evaluation tasks based on key capabilities, including
dimensions such as toxicity, robustness, ethics, bias and fairness,
truthfulness, and so on; (3) "Where to evaluate" that summarizes the evaluation
metrics, datasets and benchmarks currently used in safety evaluations; (4) "How
to evaluate" that reviews existing evaluation toolkit, and categorizing
mainstream evaluation methods based on the roles of the evaluators. Finally, we
identify the challenges in LLMs safety evaluation and propose potential
research directions to promote further advancement in this field. We emphasize
the importance of prioritizing LLMs safety evaluation to ensure the safe
deployment of these models in real-world applications.

</details>


### [87] [Persistent Homology of Topic Networks for the Prediction of Reader Curiosity](https://arxiv.org/abs/2506.11095)
*Manuel D. S. Hopp,Vincent Labatut,Arthur Amalvy,Richard Dufour,Hannah Stone,Hayley Jach,Kou Murayama*

Main category: cs.CL

TL;DR: 作者利用BERTopic主题建模和持久同调分析文本中的信息缺口，通过该拓扑特征成功提升了对读者好奇心的预测能力（解释偏差73%），为理解文本与用户体验提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 读者好奇心（驱动力）对文本参与度至关重要，但在自然语言处理（NLP）中尚未得到充分探索。本文基于Loewenstein的信息缺口理论，动机在于通过量化文本语义结构中的信息缺口，建立读者好奇心建模框架，以深入理解和预测读者与文本的互动。

Method: 提出结合BERTopic主题建模与持久同调（persistent homology）的方法，分析文本片段构建的动态语义网络的拓扑结构（连通分量、环、空洞等），这些网络特征作为信息缺口的代理。随后，通过收集49名参与者在阅读《饥饿游戏》小说时对好奇心的评分，将拓扑特征作为自变量来预测这些评分，并与基线模型进行对比。

Result: 实验结果显示，该方法能够显著提升好奇心评分的预测能力，解释偏差率由基线模型的30%提升到73%，验证了方法的有效性。

Conclusion: 该研究提出了一种新颖的基于拓扑特征的计算方法，不仅能分析文本的语义结构，还揭示了结构与读者参与度之间的关系，为NLP领域提供了新的研究工具。

Abstract: Reader curiosity, the drive to seek information, is crucial for textual
engagement, yet remains relatively underexplored in NLP. Building on
Loewenstein's Information Gap Theory, we introduce a framework that models
reader curiosity by quantifying semantic information gaps within a text's
semantic structure. Our approach leverages BERTopic-inspired topic modeling and
persistent homology to analyze the evolving topology (connected components,
cycles, voids) of a dynamic semantic network derived from text segments,
treating these features as proxies for information gaps. To empirically
evaluate this pipeline, we collect reader curiosity ratings from participants
(n = 49) as they read S. Collins's ''The Hunger Games'' novel. We then use the
topological features from our pipeline as independent variables to predict
these ratings, and experimentally show that they significantly improve
curiosity prediction compared to a baseline model (73% vs. 30% explained
deviance), validating our approach. This pipeline offers a new computational
method for analyzing text structure and its relation to reader engagement.

</details>


### [88] [C-SEO Bench: Does Conversational SEO Work?](https://arxiv.org/abs/2506.11097)
*Haritz Puerto,Martin Gubri,Tommaso Green,Seong Joon Oh,Sangdoo Yun*

Main category: cs.CL

TL;DR: 本文提出了首个面向多领域、多参与者的C-SEO评测基准C-SEO Bench。系统实验表明，当前C-SEO方法实际效果有限，传统SEO对LLM有效性更高，且多方竞争下收益递减。为未来C-SEO方法论设计和研究提供了新的评测标准和方向。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）推动搜索引擎向对话式搜索引擎（CSE）转变，搜索引擎优化（SEO）也演变为对话式搜索引擎优化（C-SEO）。但目前对C-SEO方法的实际效果，尤其是在不同领域和多方竞赛场景下的效果尚不清楚，也缺乏系统性评测。

Method: 论文提出了C-SEO Bench，这是第一个针对多任务、多领域及多参与者的C-SEO基准测试工具。包括两种搜索任务（问答与产品推荐），涵盖三个不同领域，并设计了新的评测协议，以反映不同采纳者数量下的方法有效性。

Result: 实验结果显示，目前主流的C-SEO方法在大多数情况下并不如文献报道那样有效；反而传统SEO策略（旨在提升源内容在LLM环境下排名）更有效。同时，随着C-SEO采纳者的增多，整体收益反而下降，表现出拥挤、零和博弈的特性。

Conclusion: 本研究通过全面基准和多场景评测，发现当前C-SEO方法实际效果有限，甚至不如传统SEO手段，并揭示了C-SEO领域资源分配的零和竞争现象。未来C-SEO的发展和方法设计应充分考虑多方参与和领域广泛性的挑战。

Abstract: Large Language Models (LLMs) are transforming search engines into
Conversational Search Engines (CSE). Consequently, Search Engine Optimization
(SEO) is being shifted into Conversational Search Engine Optimization (C-SEO).
We are beginning to see dedicated C-SEO methods for modifying web documents to
increase their visibility in CSE responses. However, they are often tested only
for a limited breadth of application domains; we do not understand whether
certain C-SEO methods would be effective for a broad range of domains.
Moreover, existing evaluations consider only a single-actor scenario where only
one web document adopts a C-SEO method; in reality, multiple players are likely
to competitively adopt the cutting-edge C-SEO techniques, drawing an analogy
from the dynamics we have seen in SEO. We present C-SEO Bench, the first
benchmark designed to evaluate C-SEO methods across multiple tasks, domains,
and number of actors. We consider two search tasks, question answering and
product recommendation, with three domains each. We also formalize a new
evaluation protocol with varying adoption rates among involved actors. Our
experiments reveal that most current C-SEO methods are largely ineffective,
contrary to reported results in the literature. Instead, traditional SEO
strategies, those aiming to improve the ranking of the source in the LLM
context, are significantly more effective. We also observe that as we increase
the number of C-SEO adopters, the overall gains decrease, depicting a congested
and zero-sum nature of the problem. Our code and data are available at
https://github.com/parameterlab/c-seo-bench and
https://huggingface.co/datasets/parameterlab/c-seo-bench.

</details>


### [89] [Evolutionary Perspectives on the Evaluation of LLM-Based AI Agents: A Comprehensive Survey](https://arxiv.org/abs/2506.11102)
*Jiachen Zhu,Menghui Zhu,Renting Rui,Rong Shan,Congmin Zheng,Bo Chen,Yunjia Xi,Jianghao Lin,Weiwen Liu,Ruiming Tang,Yong Yu,Weinan Zhang*

Main category: cs.CL

TL;DR: 本文系统梳理了LLM聊天机器人与AI智能体的评测差异，提出了五大区分维度，总结并归类了现有评测基准，并对未来智能体评测方法提出了建议，为研究者选择评测基准提供了实用参考。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）的发展，传统的LLM聊天机器人正逐步过渡到更加先进的AI智能体。但目前的评测框架往往没有明确区分两者，导致研究人员在选择评测基准时产生困惑。因此，迫切需要建立系统化分析框架，清晰区分两者差异，为评测方法的选择与发展提供指导。

Method: 本文采用进化视角，对当前的评测方法进行系统性分析。提出了区分AI智能体和LLM聊天机器人的五个关键维度，并对现有评测基准按外部环境驱动力和内部能力进行分类。针对每一类别，整理了具体的评测属性，并以实用的参考表格形式呈现。同时，综述了现有趋势，并从环境、智能体、评估者、指标四个视角提出未来的方法方向。

Result: 提出了一套详细分析框架，明确区分了AI智能体与LLM聊天机器人，并根据分析结果对现有评测基准进行了归类。对于每类基准，都总结了主要的评测属性。最终，综合当前趋势，从四个关键视角提出了未来的评测方法。本文的研究为研究者在评测基准选择与应用上提供了实际的参考和指导。

Conclusion: 本文为区分AI智能体与传统LLM聊天机器人，提出了系统性评测分析框架，并对现有基准进行分类与属性总结。研究成果为该领域研究者选用合适评测基准、推动智能体评测发展提供了清晰、有操作性的指导。

Abstract: The advent of large language models (LLMs), such as GPT, Gemini, and
DeepSeek, has significantly advanced natural language processing, giving rise
to sophisticated chatbots capable of diverse language-related tasks. The
transition from these traditional LLM chatbots to more advanced AI agents
represents a pivotal evolutionary step. However, existing evaluation frameworks
often blur the distinctions between LLM chatbots and AI agents, leading to
confusion among researchers selecting appropriate benchmarks. To bridge this
gap, this paper introduces a systematic analysis of current evaluation
approaches, grounded in an evolutionary perspective. We provide a detailed
analytical framework that clearly differentiates AI agents from LLM chatbots
along five key aspects: complex environment, multi-source instructor, dynamic
feedback, multi-modal perception, and advanced capability. Further, we
categorize existing evaluation benchmarks based on external environments
driving forces, and resulting advanced internal capabilities. For each
category, we delineate relevant evaluation attributes, presented
comprehensively in practical reference tables. Finally, we synthesize current
trends and outline future evaluation methodologies through four critical
lenses: environment, agent, evaluator, and metrics. Our findings offer
actionable guidance for researchers, facilitating the informed selection and
application of benchmarks in AI agent evaluation, thus fostering continued
advancement in this rapidly evolving research domain.

</details>


### [90] [You Only Fine-tune Once: Many-Shot In-Context Fine-Tuning for Large Language Model](https://arxiv.org/abs/2506.11103)
*Wenchong He,Liqian Peng,Zhe Jiang,Alex Go*

Main category: cs.CL

TL;DR: 本文提出ManyICL方法，通过将多示例作为有监督目标进行微调，显著提升了LLM多任务in-context learning的表现，并缓解了遗忘问题，性能接近专用微调。


<details>
  <summary>Details</summary>
Motivation: 目前LLM通过in-context learning（ICL）能够处理多任务，但多个任务同时few-shot in-context微调的方式，与每个任务专门微调相比仍有表现差距。

Method: 提出Many-Shot In-Context Fine-tuning（ManyICL）新方法，并采用创新训练目标：不仅预测最终答案，还将上下文中每个答案作为有监督训练目标，实现many-shot样本从提示转为自回归学习目标。

Result: ManyICL在多项下游任务中显著优于零/少样本微调，并且接近每个任务专用微调的表现。同时，ManyICL有效缓解了零/少样本微调出现的灾难性遗忘问题。

Conclusion: ManyICL有效提升了基于ICL的多任务处理能力，减少与专门微调的性能差距，并改善模型遗忘问题。代码将在论文发布后公开。

Abstract: Large language models (LLMs) possess a remarkable ability to perform
in-context learning (ICL), which enables them to handle multiple downstream
tasks simultaneously without requiring task-specific fine-tuning. Recent
studies have shown that even moderately sized LLMs, such as Mistral 7B, Gemma
7B and Llama-3 8B, can achieve ICL through few-shot in-context fine-tuning of
all tasks at once. However, this approach still lags behind dedicated
fine-tuning, where a separate model is trained for each individual task.
  In this paper, we propose a novel approach, Many-Shot In-Context Fine-tuning
(ManyICL), which significantly narrows this performance gap by extending the
principles of ICL to a many-shot setting. To unlock the full potential of
ManyICL and address the inherent inefficiency of processing long sequences with
numerous in-context examples, we propose a novel training objective. Instead of
solely predicting the final answer, our approach treats every answer within the
context as a supervised training target. This effectively shifts the role of
many-shot examples from prompts to targets for autoregressive learning. Through
extensive experiments on diverse downstream tasks, including classification,
summarization, question answering, natural language inference, and math, we
demonstrate that ManyICL substantially outperforms zero/few-shot fine-tuning
and approaches the performance of dedicated fine-tuning. Furthermore, ManyICL
significantly mitigates catastrophic forgetting issues observed in
zero/few-shot fine-tuning. The code will be made publicly available upon
publication.

</details>


### [91] [DAM: Dynamic Attention Mask for Long-Context Large Language Model Inference Acceleration](https://arxiv.org/abs/2506.11104)
*Hanzhi Zhang,Heng Fan,Kewei Sha,Yan Huang,Yunhe Feng*

Main category: cs.CL

TL;DR: 本文提出了动态稀疏注意力机制（DAM），无需微调和固定掩码，能高效处理长文本，大幅节省计算资源，模型效果接近全注意力方案，利于大规模语言模型实际部署。


<details>
  <summary>Details</summary>
Motivation: 当前NLP应用对于长文本上下文的理解有较高需求，但传统transformer在处理长序列时，由于自注意力机制的二次复杂度，效率较低。稀疏注意力虽然能提升效率，但大多采用静态预定义的掩码，无法灵活适应不同的注意力需求，导致token间交互受限，适应性和检索准确率不足。

Method: 提出了一种动态稀疏注意力机制（DAM），可在注意力图层面自适应分配掩码，跨层、跨head保留异质化注意力模式。该方法无需微调或预定义掩码结构，学习依赖上下文的注意力方式，在保持计算和存储效率的前提下，动态生成高效稀疏注意力结构。

Result: 即使大幅降低运算和内存开销，模型性能基本与全注意力版本对齐，性能损失极小。方法能有效用于部署大规模LLM，在不牺牲检索性能的前提下显著提升可扩展性。

Conclusion: 通过动态稀疏注意力机制（DAM），既兼顾了大型模型高效推理需求，也保留了复杂上下文理解与检索表现，是全注意力机制的可扩展替代方案。

Abstract: Long-context understanding is crucial for many NLP applications, yet
transformers struggle with efficiency due to the quadratic complexity of
self-attention. Sparse attention methods alleviate this cost but often impose
static, predefined masks, failing to capture heterogeneous attention patterns.
This results in suboptimal token interactions, limiting adaptability and
retrieval accuracy in long-sequence tasks. This work introduces a dynamic
sparse attention mechanism that assigns adaptive masks at the attention-map
level, preserving heterogeneous patterns across layers and heads. Unlike
existing approaches, our method eliminates the need for fine-tuning and
predefined mask structures while maintaining computational efficiency. By
learning context-aware attention structures, it achieves high alignment with
full-attention models, ensuring minimal performance degradation while reducing
memory and compute overhead. This approach provides a scalable alternative to
full attention, enabling the practical deployment of large-scale Large Language
Models (LLMs) without sacrificing retrieval performance. DAM is available at:
https://github.com/HanzhiZhang-Ulrica/DAM.

</details>


### [92] [Enabling On-Device Medical AI Assistants via Input-Driven Saliency Adaptation](https://arxiv.org/abs/2506.11105)
*Uttej Kallakurik,Edward Humes,Rithvik Jonna,Xiaomin Lin,Tinoosh Mohsenin*

Main category: cs.CL

TL;DR: 本文提出了一种自适应剪枝与量化的LLM压缩方法，高效适配至边缘设备，保障了医疗任务下的实时与能效。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在医疗领域应用广泛，但模型体积太大，难以在边缘设备等资源受限场景实时部署。

Method: 提出了一种通用压缩框架：首先根据医疗领域数据测量神经元重要性，并对不相关神经元进行剪枝，然后对模型进行量化，最后在多个医疗基准任务上评估。

Result: 将Gemma压缩50%、LLaMA3压缩67%后部署于Jetson Orin Nano和Raspberry Pi 5，实现了能耗低、实时响应且性能基本无损的医疗问答。

Conclusion: 本文证明了通过神经元重要性剪枝和量化，LLM可被高效压缩并实现在资源受限设备上的实时医疗推理。

Abstract: Large Language Models (LLMs) have significant impact on the healthcare
scenarios but remain prohibitively large for deployment in real-time,
resource-constrained environments such as edge devices. In this work, we
introduce a novel medical assistant system, optimized through our
general-purpose compression framework, which tailors Large Language Models
(LLMs) for deployment in specialized domains. By measuring neuron saliency on
domain-specific data, our method can aggressively prune irrelevant neurons,
reducing model size while preserving performance. Following pruning, we apply
post-training quantization to further reduce the memory footprint, and evaluate
the compressed model across medical benchmarks including MedMCQA, MedQA, and
PubMedQA. We also deploy the 50\% compressed Gemma and the 67\% compressed
LLaMA3 models on Jetson Orin Nano (18.7W peak) and Raspberry Pi 5 (6.3W peak),
achieving real-time, energy-efficient inference under hardware constraints.

</details>


### [93] [Graph-based RAG Enhancement via Global Query Disambiguation and Dependency-Aware Reranking](https://arxiv.org/abs/2506.11106)
*Ningyuan Li,Junrui Liu,Yi Shan,Minghui Huang,Tong Li*

Main category: cs.CL

TL;DR: 该论文提出了PankRAG新框架，通过多层次推理与依赖感知重排序优化了基于知识图谱的生成任务，大幅提升了检索相关性和响应准确率，优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 现有图谱增强生成（RAG）方法在信息检索时过度依赖于实体级别抽取，导致遗漏或误解潜在重要信息与关系，进而影响内容的相关性与准确性，并增加了幻觉风险。

Method: 提出PankRAG框架，包括全局感知、层次化的查询解决策略和新颖的依赖感知重排序机制。首先，PankRAG 构建多层次解决路径，捕捉查询中的并行和顺序依赖关系，引导大语言模型进行结构化推理。随后，依赖感知重排序器利用已解决子问间的依赖结构，丰富并校验后续检索结果。

Result: 实验证明，PankRAG 在多个基准数据集上均优于当前最先进的方法，表现出较强的稳健性和泛化能力。

Conclusion: PankRAG 有效克服了传统RAG方法在实体抽取上的局限，通过整合层次化推理和依赖感知检索显著提升了生成内容的相关性与准确性。

Abstract: Contemporary graph-based retrieval-augmented generation (RAG) methods
typically begin by extracting entities from user queries and then leverage
pre-constructed knowledge graphs to retrieve related relationships and
metadata. However, this pipeline's exclusive reliance on entity-level
extraction can lead to the misinterpretation or omission of latent yet critical
information and relations. As a result, retrieved content may be irrelevant or
contradictory, and essential knowledge may be excluded, exacerbating
hallucination risks and degrading the fidelity of generated responses. To
address these limitations, we introduce PankRAG, a framework that combines a
globally aware, hierarchical query-resolution strategy with a novel
dependency-aware reranking mechanism. PankRAG first constructs a multi-level
resolution path that captures both parallel and sequential interdependencies
within a query, guiding large language models (LLMs) through structured
reasoning. It then applies its dependency-aware reranker to exploit the
dependency structure among resolved sub-questions, enriching and validating
retrieval results for subsequent sub-questions. Empirical evaluations
demonstrate that PankRAG consistently outperforms state-of-the-art approaches
across multiple benchmarks, underscoring its robustness and generalizability.

</details>


### [94] [History-Aware Cross-Attention Reinforcement: Self-Supervised Multi Turn and Chain-of-Thought Fine-Tuning with vLLM](https://arxiv.org/abs/2506.11108)
*Andrew Kiruluta,Andreas Lemos,Priscilla Burity*

Main category: cs.CL

TL;DR: 本工作扩展了CAGSR框架，使其支持多轮对话与链式推理，并集成至高性能vLLM系统，可异步捕捉注意力权重，通过自监督奖励机制优化对话历史与推理能力，解决了早期attention崩溃的问题，并展望了更复杂推理任务的应用。


<details>
  <summary>Details</summary>
Motivation: 当前多轮对话和链式推理任务中，模型如何有效地利用对话历史与推理中间步骤仍是挑战。原有CAGSR框架仅支持单轮，缺乏对复杂对话与推理任务的处理能力。

Method: 扩展CAGSR框架至多轮对话与链式推理，同时将其部署于高性能vLLM运行时。通过修改vLLM的C++/CUDA内核，实现生成时异步抓取每一层、每一头的cross-attention权重，并将奖励函数推广为跨整个会话历史和推理步骤累积attention信号。引入基于熵的裁剪机制防止早期上下文attention塌缩。

Result: 实现了CAGSR框架在多轮对话和链式推理中的拓展，能有效提取并利用整个历史的attention信号；解决了早期attention崩溃等实际问题。

Conclusion: CAGSR-vLLM-MTC为多轮对话和中间推理提供了一种高效、可扩展的自监督优化方法，并对多方对话和层次化推理的未来研究方向进行了展望。

Abstract: We present CAGSR-vLLM-MTC, an extension of our Self-Supervised
Cross-Attention-Guided Reinforcement (CAGSR) framework, now implemented on the
high-performance vLLM runtime, to address both multi-turn dialogue and
chain-of-thought reasoning. Building upon our original single-turn approach, we
first instrumented vLLM's C++/CUDA kernels to asynchronously capture per-layer,
per-head cross-attention weights during generation. We then generalized our
self-supervised reward function to accumulate attention signals over entire
conversation histories and intermediate chain-of-thought steps. We discuss
practical trade-offs, including an entropy-based clamping mechanism to prevent
attention collapse on early context, and outline future directions for
multi-party dialogues and hierarchical reasoning.

</details>


### [95] [Enhancing Large Language Models for Mobility Analytics with Semantic Location Tokenization](https://arxiv.org/abs/2506.11109)
*Yile Chen,Yicheng Tao,Yue Jiang,Shuai Liu,Han Yu,Gao Cong*

Main category: cs.CL

TL;DR: QT-Mob通过引入语义化位置分词和多重微调目标，显著提升了大语言模型对移动数据的理解力，在预测和恢复任务中超越了现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 随着基于位置的服务的普及，产生了大量的移动数据，但当前基于大模型（LLMs）的方法在表示位置信息和捕捉移动信号方面存在不足。作者希望解决现有方法语义表达能力不足和LLM建模移动性信号不足的两大难题。

Method: 提出了QT-Mob框架，包含位置分词模块以学习紧凑且富有语义的信息表示，并通过多样化的微调目标，将位置信号与LLM内部表征对齐，增强对移动模式和位置语义的理解。

Result: 在三个真实世界数据集上，QT-Mob在下一个位置预测和移动恢复任务上均优于现有深度学习和基于LLM的方法，表现出更强的泛化性和性能。

Conclusion: QT-Mob通过改进位置表示和内在模型语义能力，提升了LLMs对移动数据分析的能力，优于目前已有方法，并可适应多种移动数据分析场景。

Abstract: The widespread adoption of location-based services has led to the generation
of vast amounts of mobility data, providing significant opportunities to model
user movement dynamics within urban environments. Recent advancements have
focused on adapting Large Language Models (LLMs) for mobility analytics.
However, existing methods face two primary limitations: inadequate semantic
representation of locations (i.e., discrete IDs) and insufficient modeling of
mobility signals within LLMs (i.e., single templated instruction fine-tuning).
To address these issues, we propose QT-Mob, a novel framework that
significantly enhances LLMs for mobility analytics. QT-Mob introduces a
location tokenization module that learns compact, semantically rich tokens to
represent locations, preserving contextual information while ensuring
compatibility with LLMs. Furthermore, QT-Mob incorporates a series of
complementary fine-tuning objectives that align the learned tokens with the
internal representations in LLMs, improving the model's comprehension of
sequential movement patterns and location semantics. The proposed QT-Mob
framework not only enhances LLMs' ability to interpret mobility data but also
provides a more generalizable approach for various mobility analytics tasks.
Experiments on three real-world dataset demonstrate the superior performance in
both next-location prediction and mobility recovery tasks, outperforming
existing deep learning and LLM-based methods.

</details>


### [96] [AssertBench: A Benchmark for Evaluating Self-Assertion in Large Language Models](https://arxiv.org/abs/2506.11110)
*Jaeho Lee,Atharv Chowdhary*

Main category: cs.CL

TL;DR: 本文提出AssertBench基准，通过正、反两个方向性的事实表述，评测大语言模型是否会因用户主张改变自身事实判断，为模型一致性评测提供了新视角与工具。


<details>
  <summary>Details</summary>
Motivation: 目前对于大语言模型（LLM）在事实一致性与修辞鲁棒性方面存在评测，但尚不清楚当事实陈述被以不同方向性表达时，模型的回答是否会被影响，即：用户提出相反主张时，模型能否坚持自身的事实判断。

Method: 作者设计了AssertBench基准，从事实核查数据集FEVEROUS中抽取支持证据的事实。针对每个事实，分别构建“用户声称该语句正确”与“用户声称该语句错误”两种提示，观察模型对同一事实在正、反两种表述下的同一致性以及推理过程。同时，通过将模型在中性表述下的准确性作为分层标准，控制模型固有知识与表述帧的影响。

Result: AssertBench能够有效区分模型由于表述方式变化而产生的判断摇摆，揭示模型面临相反用户主张时坚持自我事实判断的能力。

Conclusion: AssertBench为评估大语言模型在面对相反方向性主张时的一致性与事实坚持性提供了新的工具，有助于深入理解和改进模型的对话健壮性。

Abstract: Recent benchmarks have probed factual consistency and rhetorical robustness
in Large Language Models (LLMs). However, a knowledge gap exists regarding how
directional framing of factually true statements influences model agreement, a
common scenario for LLM users. AssertBench addresses this by sampling
evidence-supported facts from FEVEROUS, a fact verification dataset. For each
(evidence-backed) fact, we construct two framing prompts: one where the user
claims the statement is factually correct, and another where the user claims it
is incorrect. We then record the model's agreement and reasoning. The desired
outcome is that the model asserts itself, maintaining consistent truth
evaluation across both framings, rather than switching its evaluation to agree
with the user. AssertBench isolates framing-induced variability from the
model's underlying factual knowledge by stratifying results based on the
model's accuracy on the same claims when presented neutrally. In doing so, this
benchmark aims to measure an LLM's ability to "stick to its guns" when
presented with contradictory user assertions about the same fact. The complete
source code is available at https://github.com/achowd32/assert-bench.

</details>


### [97] [Evaluating and Improving Robustness in Large Language Models: A Survey and Future Directions](https://arxiv.org/abs/2506.11111)
*Kun Zhang,Le Wu,Kui Yu,Guangyi Lv,Dacao Zhang*

Main category: cs.CL

TL;DR: 本文系统综述了大语言模型的鲁棒性，从对抗鲁棒性、分布外鲁棒性到鲁棒性评测进行了分类梳理，并对领域内方法和未来机会进行了总结，附带可检索资料以支持后续研究。


<details>
  <summary>Details</summary>
Motivation: 近年来大语言模型（LLMs）因其强大的自然语言理解与生成能力，获得了广泛关注。随着其在智能体、具身智能等多领域的应用快速扩展，模型的鲁棒性问题愈发突出。由于LLMs作为许多AI应用的“核心大脑”，其鲁棒性不仅需要保证生成内容的一致性，还要在面对异常应用场景（如有害提示、带噪域数据、分布外任务等）时确保内容的正确性与稳定性。

Method: 本文作为综述性论文，首先形式化定义了LLM的鲁棒性，并给出了文献筛选与收集标准。随后，作者从输入扰动类型出发，将LLM鲁棒性分为三个关注点：（1）对抗鲁棒性：面对恶意操控的输入提示；（2）分布外鲁棒性：应对现实未见过的情况；（3）鲁棒性评测：总结新的评测数据集、指标和工具。对每一类别的代表性方法进行详细回顾和讨论，同时梳理未来研究方向。

Result: 本文对LLM鲁棒性相关方法与评测手段进行了系统梳理，总结了当前领域主流问题与解决思路，为学术和产业界提供了完整的知识框架，并整理了相关论文列表，为社区检索和后续研究提供支撑。

Conclusion: 大语言模型的鲁棒性是其在广泛应用中面临的核心挑战之一。本文通过系统综述并划分对抗、分布外等不同鲁棒性问题，明确了未来值得关注的研究方向，并为领域研究者提供了可检索的工具与资料，促进社区合作与发展。

Abstract: Large Language Models (LLMs) have gained enormous attention in recent years
due to their capability of understanding and generating natural languages. With
the rapid development and wild-range applications (e.g., Agents, Embodied
Intelligence), the robustness of LLMs has received increased attention. As the
core brain of many AI applications, the robustness of LLMs requires that models
should not only generate consistent contents, but also ensure the correctness
and stability of generated content when dealing with unexpeted application
scenarios (e.g., toxic prompts, limited noise domain data, outof-distribution
(OOD) applications, etc). In this survey paper, we conduct a thorough review of
the robustness of LLMs, aiming to provide a comprehensive terminology of
concepts and methods around this field and facilitate the community.
Specifically, we first give a formal definition of LLM robustness and present
the collection protocol of this survey paper. Then, based on the types of
perturbated inputs, we organize this survey from the following perspectives: 1)
Adversarial Robustness: tackling the problem that prompts are manipulated
intentionally, such as noise prompts, long context, data attack, etc; 2) OOD
Robustness: dealing with the unexpected real-world application scenarios, such
as OOD detection, zero-shot transferring, hallucinations, etc; 3) Evaluation of
Robustness: summarizing the new evaluation datasets, metrics, and tools for
verifying the robustness of LLMs. After reviewing the representative work from
each perspective, we discuss and highlight future opportunities and research
directions in this field. Meanwhile, we also organize related works and provide
an easy-to-search project
(https://github.com/zhangkunzk/Awesome-LLM-Robustness-papers) to support the
community.

</details>


### [98] [Manifesto from Dagstuhl Perspectives Workshop 24352 -- Conversational Agents: A Framework for Evaluation (CAFE)](https://arxiv.org/abs/2506.11112)
*Christine Bauer,Li Chen,Nicola Ferro,Norbert Fuhr,Avishek Anand,Timo Breuer,Guglielmo Faggioli,Ophir Frieder,Hideo Joho,Jussi Karlgren,Johannes Kiesel,Bart P. Knijnenburg,Aldo Lipani,Lien Michiels,Andrea Papenmeier,Maria Soledad Pera,Mark Sanderson,Scott Sanner,Benno Stein,Johanne R. Trippas,Karin Verspoor,Martijn C Willemsen*

Main category: cs.CL

TL;DR: 本研究提出了CONIAC系统的理论模型，并制定了包含六大核心要素的综合评估框架（CAFE），为该领域未来发展和系统评估建立了标准。


<details>
  <summary>Details</summary>
Motivation: 随着对话式信息获取（CONIAC）系统的不断发展，急需清晰描述其本质及评估框架，以推动该领域研究并实现实际应用。

Method: 本研究在研讨会上通过集中讨论的方式，提出了CONIAC的世界模型及其抽象特征，并定义了用于CONIAC系统评估的会话代理框架（CAFE），涵盖六大核心组成部分。

Result: 成功提出了CAFE评估框架，将CONIAC系统评估细分为：利益相关者目标、用户任务、用户特征、评估标准、评估方法和量化指标六个方面。

Conclusion: 该工作明确了CONIAC的概念和关键组成部分，为未来对话式信息获取系统的规范评估和研究提供了基础支撑。

Abstract: During the workshop, we deeply discussed what CONversational Information
ACcess (CONIAC) is and its unique features, proposing a world model abstracting
it, and defined the Conversational Agents Framework for Evaluation (CAFE) for
the evaluation of CONIAC systems, consisting of six major components: 1) goals
of the system's stakeholders, 2) user tasks to be studied in the evaluation, 3)
aspects of the users carrying out the tasks, 4) evaluation criteria to be
considered, 5) evaluation methodology to be applied, and 6) measures for the
quantitative criteria chosen.

</details>


### [99] [Breaking the Reviewer: Assessing the Vulnerability of Large Language Models in Automated Peer Review Under Textual Adversarial Attacks](https://arxiv.org/abs/2506.11113)
*Tzu-Ling Lin,Wei-Chih Chen,Teng-Fang Hsiao,Hou-I Liu,Ya-Hsin Yeh,Yu Kai Chan,Wen-Sheng Lien,Po-Yen Kuo,Philip S. Yu,Hong-Han Shuai*

Main category: cs.CL

TL;DR: LLM可自动化论文评审，但容易被文本攻击影响判断，存在显著漏洞，需重点防护以保障学术公正。


<details>
  <summary>Details</summary>
Motivation: 随着学术论文提交量暴增，评审人压力巨大。大语言模型可辅助自动评审，但其易受文本对抗攻击可能影响可靠性，因此需研究这种自动化工具的稳健性。

Method: 评估LLM在自动化同行评审中的表现，并分析其对文本对抗攻击的鲁棒性，重点比较与人类评审的有效性，测试对抗性攻击的影响，并探讨应对策略。

Result: 实验显示LLM评审易被文本操纵而严重失真，存在显著脆弱性。论文详细评估了LLM的表现及其在对抗攻击下的弱点。提出必须解决对抗性风险，以维护学术交流的诚实性。

Conclusion: LLM在自动同行评审中存在显著的对抗性脆弱性，必须重视并应对这些风险，以确保AI有助于学术交流的公正性。

Abstract: Peer review is essential for maintaining academic quality, but the increasing
volume of submissions places a significant burden on reviewers. Large language
models (LLMs) offer potential assistance in this process, yet their
susceptibility to textual adversarial attacks raises reliability concerns. This
paper investigates the robustness of LLMs used as automated reviewers in the
presence of such attacks. We focus on three key questions: (1) The
effectiveness of LLMs in generating reviews compared to human reviewers. (2)
The impact of adversarial attacks on the reliability of LLM-generated reviews.
(3) Challenges and potential mitigation strategies for LLM-based review. Our
evaluation reveals significant vulnerabilities, as text manipulations can
distort LLM assessments. We offer a comprehensive evaluation of LLM performance
in automated peer reviewing and analyze its robustness against adversarial
attacks. Our findings emphasize the importance of addressing adversarial risks
to ensure AI strengthens, rather than compromises, the integrity of scholarly
communication.

</details>


### [100] [KokushiMD-10: Benchmark for Evaluating Large Language Models on Ten Japanese National Healthcare Licensing Examinations](https://arxiv.org/abs/2506.11114)
*Junyu Liu,Kaiqi Yan,Tianyang Wang,Qian Niu,Momoko Nagai-Tanima,Tomoki Aoyama*

Main category: cs.CL

TL;DR: 本文提出KokushiMD-10，这是首个日本国家医疗多领域、多模态基准，包含超过1.1万道真实题目，用于测试LLMs在医学相关多领域、文本与图片理解上的推理能力。超30款主流大模型在此基准上表现分析显示，暂无模型能全面达标，凸显多模态医疗AI当前仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在医学执照考试上表现出色，但目前缺乏覆盖多种医疗角色、特别是高风险临床场景的全面评测工具。现有基准多以英文文本为主，且主要聚焦于医学，无法测试更广泛的医疗知识及多模态推理能力。因此，作者旨在解决医疗AI评测的维度狭窄、地域与语言局限的问题。

Method: 作者提出并构建了KokushiMD-10，这是一项基于日本十种国家医疗资格考试的多模态基准，涵盖医学、牙科、护理、药学及相关健康职业领域，包含超过11588道真实考题，涉及临床图片和专家标注的推理理由，用于考察文本与视觉推理能力。实验中使用了30多种当前最先进的LLMs进行基准测试，涵盖文本和图像场景。

Result: 测试结果显示，虽然部分模型表现较为出色，但没有任何单一模型能在所有领域持续达到及格线。这说明当前医疗AI在多领域、高难度任务中的能力仍有重大挑战。

Conclusion: KokushiMD-10为医疗AI多语言、多模态评测提供了全面且有实际基础的资源，有助于推动以推理为核心的医疗AI在临床场景中的发展和应用。它也揭示了当前模型在医疗综合能力上存在的不足。

Abstract: Recent advances in large language models (LLMs) have demonstrated notable
performance in medical licensing exams. However, comprehensive evaluation of
LLMs across various healthcare roles, particularly in high-stakes clinical
scenarios, remains a challenge. Existing benchmarks are typically text-based,
English-centric, and focus primarily on medicines, which limits their ability
to assess broader healthcare knowledge and multimodal reasoning. To address
these gaps, we introduce KokushiMD-10, the first multimodal benchmark
constructed from ten Japanese national healthcare licensing exams. This
benchmark spans multiple fields, including Medicine, Dentistry, Nursing,
Pharmacy, and allied health professions. It contains over 11588 real exam
questions, incorporating clinical images and expert-annotated rationales to
evaluate both textual and visual reasoning. We benchmark over 30
state-of-the-art LLMs, including GPT-4o, Claude 3.5, and Gemini, across both
text and image-based settings. Despite promising results, no model consistently
meets passing thresholds across domains, highlighting the ongoing challenges in
medical AI. KokushiMD-10 provides a comprehensive and linguistically grounded
resource for evaluating and advancing reasoning-centric medical AI across
multilingual and multimodal clinical tasks.

</details>


### [101] [Incorporating Domain Knowledge into Materials Tokenization](https://arxiv.org/abs/2506.11115)
*Yerim Oh,Jun-Hyung Park,Junho Kim,SungHo Kim,SangKeun Lee*

Main category: cs.CL

TL;DR: 引入材料知识的MATTER分词方法能更好地保持材料概念完整性，相比现有方法在生成与分类任务上性能提升明显。


<details>
  <summary>Details</summary>
Motivation: 目前材料科学中广泛使用的语言模型依赖于为自然语言处理开发的基于频率的分词方法，但这些方法容易导致材料相关概念的碎片化和语义损失，难以保持其结构和语义完整性。

Method: 提出MATTER分词方法，将材料领域知识集成到分词过程中。具体采用以材料知识库训练的MatDetector，结合优先保留材料概念的分词合并重排序方法，从而减少碎片化并保持材料概念的语义和结构完整。

Result: MATTER在生成和分类任务中相较现有分词方法分别取得了4%和2%的平均性能提升。实验结果验证了将领域知识引入科学文本分词策略的重要性。

Conclusion: 将材料知识融入分词过程能够有效提升材料科学领域的语言模型在下游任务中的性能，有助于保持材料概念的结构和语义完整。

Abstract: While language models are increasingly utilized in materials science, typical
models rely on frequency-centric tokenization methods originally developed for
natural language processing. However, these methods frequently produce
excessive fragmentation and semantic loss, failing to maintain the structural
and semantic integrity of material concepts. To address this issue, we propose
MATTER, a novel tokenization approach that integrates material knowledge into
tokenization. Based on MatDetector trained on our materials knowledge base and
a re-ranking method prioritizing material concepts in token merging, MATTER
maintains the structural integrity of identified material concepts and prevents
fragmentation during tokenization, ensuring their semantic meaning remains
intact. The experimental results demonstrate that MATTER outperforms existing
tokenization methods, achieving an average performance gain of $4\%$ and $2\%$
in the generation and classification tasks, respectively. These results
underscore the importance of domain knowledge for tokenization strategies in
scientific text processing. Our code is available at
https://github.com/yerimoh/MATTER

</details>


### [102] [Infinity Instruct: Scaling Instruction Selection and Synthesis to Enhance Language Models](https://arxiv.org/abs/2506.11116)
*Jijie Li,Li Du,Hanyu Zhao,Bo-wen Zhang,Liangdong Wang,Boyan Gao,Guang Liu,Yonghua Lin*

Main category: cs.CL

TL;DR: 本文推出了大规模高质量的指令数据集Infinity-Instruct，并通过两阶段流程分别构建基础与对话指令集。多模型微调实验证明数据集大幅提升了模型能力，部分模型结果超过GPT-4。数据集与代码已开源，有望推动开源大模型发展。


<details>
  <summary>Details</summary>
Motivation: 现有开源指令数据集领域较窄，如数学或编程，导致大模型泛化能力有限，与闭源模型有较大差距。该文旨在通过高质量、广覆盖的数据集提升大模型基础能力和指令遵循能力。

Method: 提出了Infinity-Instruct数据集，分两阶段构建：第一阶段利用混合数据选择技术从1亿样本中筛选出740万条高质量基础指令；第二阶段通过指令选择、进化和诊断过滤，合成150万条高质量对话指令。并在多种开源大模型上微调验证效果。

Result: 在多个模型（如Mistral, LLaMA, Qwen, Yi）上微调后，模型在基础能力及指令遵循基准测试上大幅提升，超过同类官方微调模型。其中InfInstruct-LLaMA3.1-70B在指令遵循任务上比GPT-4-0314高8.6%，基础能力也相当。

Conclusion: 高质量、涵盖广泛的指令数据集能显著提升开源大模型各类能力，联合基础与对话训练是未来LLM发展的有效方向，数据和代码已开源。

Abstract: Large Language Models (LLMs) demonstrate strong performance in real-world
applications, yet existing open-source instruction datasets often concentrate
on narrow domains, such as mathematics or coding, limiting generalization and
widening the gap with proprietary models. To bridge this gap, we introduce
Infinity-Instruct, a high-quality instruction dataset designed to enhance both
foundational and chat capabilities of LLMs through a two-phase pipeline. In
Phase 1, we curate 7.4M high-quality foundational instructions
(InfInstruct-F-7.4M) from over 100M samples using hybrid data selection
techniques. In Phase 2, we synthesize 1.5M high-quality chat instructions
(InfInstruct-G-1.5M) through a two-stage process involving instruction
selection, evolution, and diagnostic filtering. We empirically evaluate
Infinity-Instruct by fine-tuning several open-source models, including Mistral,
LLaMA, Qwen, and Yi, and observe substantial performance gains across both
foundational and instruction following benchmarks, consistently surpassing
official instruction-tuned counterparts. Notably, InfInstruct-LLaMA3.1-70B
outperforms GPT-4-0314 by 8.6\% on instruction following tasks while achieving
comparable foundational performance. These results underscore the synergy
between foundational and chat training and offer new insights into holistic LLM
development. Our
dataset\footnote{https://huggingface.co/datasets/BAAI/Infinity-Instruct} and
codes\footnote{https://gitee.com/li-touch/infinity-instruct} have been publicly
released.

</details>


### [103] [ScIRGen: Synthesize Realistic and Large-Scale RAG Dataset for Scientific Research](https://arxiv.org/abs/2506.11117)
*Junyong Lin,Lu Dai,Ruiqian Han,Yijie Sui,Ruilin Wang,Xingliang Sun,Qinglin Wu,Min Feng,Hao Liu,Hui Xiong*

Main category: cs.CL

TL;DR: 作者提出了ScIRGen框架，实现大规模、复杂且符合科研需求的问答数据集自动构建，显著提升了科学问答和检索评测的真实性和挑战性，并促进相关方法研究。


<details>
  <summary>Details</summary>
Motivation: 目前科学界在评估与开发理论和方法时需要大量与数据集相关的细致信息，但现有的科学检索与问答数据集只涉及简单问题，无法匹配现实研究中的复杂需求。为此，作者希望提升数据集的实用性与真实性，以更好服务科研场景下的查询。

Method: 提出ScIRGen框架实现科学问答与检索数据集自动生成。方法上，采用面向数据集的信息抽取方法扩展数据集表示，通过基于认知分类法的框架生成高质量问题，并利用大模型困惑度变化自动筛选合成答案。最终得到超6万规模的科研问答数据集ScIRGen-Geo，并用其对现有方法进行基准测试。

Result: 该方法构建了包含6.1万条高质量QA的ScIRGen-Geo数据集。基准测试显示，现有QA与检索技术在处理复杂推理问题时表现有限。

Conclusion: 研究提出的生成框架能更好模拟科研中的实际信息需求，通过高质量新数据集促进复杂科学问答与检索方法的进步，为支持科学研究的复杂信息检索提供了新工具。

Abstract: Scientific researchers need intensive information about datasets to
effectively evaluate and develop theories and methodologies. The information
needs regarding datasets are implicitly embedded in particular research tasks,
rather than explicitly expressed in search queries. However, existing
scientific retrieval and question-answering (QA) datasets typically address
straightforward questions, which do not align with the distribution of
real-world research inquiries. To bridge this gap, we developed ScIRGen, a
dataset generation framework for scientific QA \& retrieval that more
accurately reflects the information needs of professional science researchers,
and uses it to create a large-scale scientific retrieval-augmented generation
(RAG) dataset with realistic queries, datasets and papers. Technically, we
designed a dataset-oriented information extraction method that leverages
academic papers to augment the dataset representation. We then proposed a
question generation framework by employing cognitive taxonomy to ensure the
quality of synthesized questions. We also design a method to automatically
filter synthetic answers based on the perplexity shift of LLMs, which is highly
aligned with human judgment of answers' validity. Collectively, these
methodologies culminated in the creation of the 61k QA dataset, ScIRGen-Geo. We
benchmarked representative methods on the ScIRGen-Geo dataset for their
question-answering and retrieval capabilities, finding out that current methods
still suffer from reasoning from complex questions. This work advances the
development of more sophisticated tools to support the intricate information
needs of the scientific community.

</details>


### [104] [Benchmarking Foundation Speech and Language Models for Alzheimer's Disease and Related Dementia Detection from Spontaneous Speech](https://arxiv.org/abs/2506.11119)
*Jingyu Li,Lingchao Mao,Hairong Wang,Zhendong Wang,Xi Mao,Xuelei Sherry Ni*

Main category: cs.CL

TL;DR: 通过对自发语音数据的开源基础模型测试，结果发现语音模型（Whisper等）和停顿等特征融合方法能有效提升阿尔茨海默病及相关痴呆的早期筛查表现，为无创大规模早筛提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病及相关痴呆（ADRD）是一类进行性神经退行性疾病，早期检测对于及时干预和护理至关重要。自发性语音中蕴含丰富的声学和语言标记，有望成为认知衰退的无创生物标志物。随着基础模型的进步，人们希望评估其在ADRD早期检测中的实用性。

Method: 使用PREPARE Challenge数据集，包含1600多名参与者（三种认知状态：健康、轻度认知障碍、阿尔茨海默病），筛选后总计1189例音频。对多种开源语音和语言基础模型进行基准测试，将认知状态分为三类。比较语音、文本及辅助特征（如停顿模式）在分类任务上的表现。

Result: Whisper-medium语音模型表现最佳（准确率0.731，AUC 0.802）；在语言模型中，带停顿标注的BERT效果最好（准确率0.662，AUC 0.744）。基于ASR生成的音频嵌入在检测ADRD上优于其他模型。停顿等非语义特征能提升文本分类表现。

Conclusion: 本研究提出了一个基于基础模型的ADRD检测基准框架，使用临床相关的数据集。基于声学的自动化方法，尤其是ASR音频嵌入，展现了可扩展、无创、低成本的ADRD早期检测潜力。

Abstract: Background: Alzheimer's disease and related dementias (ADRD) are progressive
neurodegenerative conditions where early detection is vital for timely
intervention and care. Spontaneous speech contains rich acoustic and linguistic
markers that may serve as non-invasive biomarkers for cognitive decline.
Foundation models, pre-trained on large-scale audio or text data, produce
high-dimensional embeddings encoding contextual and acoustic features.
  Methods: We used the PREPARE Challenge dataset, which includes audio
recordings from over 1,600 participants with three cognitive statuses: healthy
control (HC), mild cognitive impairment (MCI), and Alzheimer's Disease (AD). We
excluded non-English, non-spontaneous, or poor-quality recordings. The final
dataset included 703 (59.13%) HC, 81 (6.81%) MCI, and 405 (34.06%) AD cases. We
benchmarked a range of open-source foundation speech and language models to
classify cognitive status into the three categories.
  Results: The Whisper-medium model achieved the highest performance among
speech models (accuracy = 0.731, AUC = 0.802). Among language models, BERT with
pause annotation performed best (accuracy = 0.662, AUC = 0.744). ADRD detection
using state-of-the-art automatic speech recognition (ASR) model-generated audio
embeddings outperformed others. Including non-semantic features like pause
patterns consistently improved text-based classification.
  Conclusion: This study introduces a benchmarking framework using foundation
models and a clinically relevant dataset. Acoustic-based approaches --
particularly ASR-derived embeddings -- demonstrate strong potential for
scalable, non-invasive, and cost-effective early detection of ADRD.

</details>


### [105] [SDMPrune: Self-Distillation MLP Pruning for Efficient Large Language Models](https://arxiv.org/abs/2506.11120)
*Hourun Zhu,Chengchao Shen*

Main category: cs.CL

TL;DR: 本文提出剪枝阶段自蒸馏损失，重点剪枝MLP模块，大幅压缩LLM参数且性能优于现有方法，适合低成本部署。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）虽然表现优异，但部署成本极高，因此需要模型压缩技术。现有基于梯度的剪枝方法有效，但使用 one-hot 标签计算梯度会忽视原模型对其他词的预测，因此丧失关键信息。

Method: 作者在剪枝阶段引入自蒸馏损失（而非后训练阶段），充分利用原模型的预测，获取更准确的梯度信息进行剪枝。此外，发现LLM的输出对MLP模块的不敏感性，MLP参数占比更高，因此聚焦MLP剪枝以实现更大压缩。

Result: 实验证明，在多个零样本测试基准上，该方法优于现有剪枝方法，并在开源1B规模LLM领域表现极具竞争力。

Conclusion: 通过在剪枝阶段加入自蒸馏损失，以及专注于对MLP模块的剪枝，大幅减少参数量的同时，保持甚至超过现有方法的模型效果。

Abstract: In spite of strong performance achieved by LLMs, the costs of their
deployment are unaffordable. For the compression of LLMs, gradient-based
pruning methods present promising effectiveness. However, in these methods, the
gradient computation with one-hot labels ignore the potential predictions on
other words, thus missing key information for generative capability of the
original model. To address this issue, we introduce a self-distillation loss
during the pruning phase (rather than post-training) to fully exploit the
predictions of the original model, thereby obtaining more accurate gradient
information for pruning. Moreover, we find that, compared to attention modules,
the predictions of LLM are less sensitive to multilayer perceptron (MLP)
modules, which take up more than $5 \times$ parameters (LLaMA3.2-1.2B). To this
end, we focus on the pruning of MLP modules, to significantly compress LLM
without obvious performance degradation. Experimental results on extensive
zero-shot benchmarks demonstrate that our method significantly outperforms
existing pruning methods. Furthermore, our method achieves very competitive
performance among 1B-scale open source LLMs. The source code and trained
weights are available at https://github.com/visresearch/SDMPrune.

</details>


### [106] [SUTA-LM: Bridging Test-Time Adaptation and Language Model Rescoring for Robust ASR](https://arxiv.org/abs/2506.11121)
*Wei-Ping Huang,Guan-Ting Lin,Hung-yi Lee*

Main category: cs.CL

TL;DR: 提出SUTA-LM方法，通过自适应和语言模型重排序结合，显著提升端到端ASR在各类领域的性能。


<details>
  <summary>Details</summary>
Motivation: 端到端自动语音识别（ASR）在实际应用中由于领域不匹配，性能会大幅下降。测试时自适应（TTA）虽能缓解此问题，但与外部语言模型结合常产生干扰，影响效果。如何有效结合二者已成为挑战。

Method: 提出SUTA-LM方法，将基于熵最小化的TTA方法（SUTA）与语言模型重排序结合。具体流程是：先用自动步数选择机制，结合声学与语言信息指导自适应过程，再进行语言模型重排序优化输出结果。

Result: 在18个多样化ASR数据集上，SUTA-LM在各种不同领域都取得了鲁棒的识别效果。

Conclusion: SUTA-LM能有效地将TTA和语言模型重排序结合，克服了二者结合时的负面影响，在跨领域ASR任务中表现优异。

Abstract: Despite progress in end-to-end ASR, real-world domain mismatches still cause
performance drops, which Test-Time Adaptation (TTA) aims to mitigate by
adjusting models during inference. Recent work explores combining TTA with
external language models, using techniques like beam search rescoring or
generative error correction. In this work, we identify a previously overlooked
challenge: TTA can interfere with language model rescoring, revealing the
nontrivial nature of effectively combining the two methods. Based on this
insight, we propose SUTA-LM, a simple yet effective extension of SUTA, an
entropy-minimization-based TTA approach, with language model rescoring. SUTA-LM
first applies a controlled adaptation process guided by an auto-step selection
mechanism leveraging both acoustic and linguistic information, followed by
language model rescoring to refine the outputs. Experiments on 18 diverse ASR
datasets show that SUTA-LM achieves robust results across a wide range of
domains.

</details>


### [107] [ASRJam: Human-Friendly AI Speech Jamming to Prevent Automated Phone Scams](https://arxiv.org/abs/2506.11125)
*Freddie Grabovski,Gilad Gressel,Yisroel Mirsky*

Main category: cs.CL

TL;DR: 本文针对自动化语音钓鱼（vishing）诈骗，提出了ASRJam防御框架和新型干扰器EchoGuard。通过自然回声等方式干扰ASR系统，阻断诈骗流程且不影响正常通话体验。在真实用户研究中，EchoGuard表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）结合语音合成（TTS）和自动语音识别（ASR）的发展，自动化语音钓鱼（vishing）诈骗变得更具规模和欺骗性，对安全造成了严重威胁。现有的防御措施对于实时、用户友好的保护效果有限，因此需要寻求更有效的防御方法。

Method: 作者提出了ASRJam这套主动防御框架，通过对受害者音频注入对抗性扰动，从而干扰攻击者的ASR系统，但对人类通话影响甚微。同时提出EchoGuard，一种利用自然失真如混响和回声的新型干扰器，旨在实现对ASR的有效扰乱且对人耳较为友好。作者还通过39人用户研究评估了EchoGuard的有效性和用户体验，并与三种现有方法进行了对比。

Result: 实验结果显示，EchoGuard在ASR扰乱能力和对人类听感的平衡方面表现最佳，实现了最高的整体实用性。

Conclusion: 论文表明，通过在通信链路中巧妙注入仅对ASR系统产生影响的自然音频扰动，可以有效阻断自动化语音诈骗的攻击链路，为语音安全防护领域提供了新的思路。

Abstract: Large Language Models (LLMs), combined with Text-to-Speech (TTS) and
Automatic Speech Recognition (ASR), are increasingly used to automate voice
phishing (vishing) scams. These systems are scalable and convincing, posing a
significant security threat. We identify the ASR transcription step as the most
vulnerable link in the scam pipeline and introduce ASRJam, a proactive defence
framework that injects adversarial perturbations into the victim's audio to
disrupt the attacker's ASR. This breaks the scam's feedback loop without
affecting human callers, who can still understand the conversation. While prior
adversarial audio techniques are often unpleasant and impractical for real-time
use, we also propose EchoGuard, a novel jammer that leverages natural
distortions, such as reverberation and echo, that are disruptive to ASR but
tolerable to humans. To evaluate EchoGuard's effectiveness and usability, we
conducted a 39-person user study comparing it with three state-of-the-art
attacks. Results show that EchoGuard achieved the highest overall utility,
offering the best combination of ASR disruption and human listening experience.

</details>


### [108] [GUIRoboTron-Speech: Towards Automated GUI Agents Based on Speech Instructions](https://arxiv.org/abs/2506.11127)
*Wenkang Han,Zhixiong Zeng,Jing Huang,Shu Jiang,Liming Zheng,Longrong Yang,Haibo Qiu,Chang Yao,Jingyuan Chen,Lin Ma*

Main category: cs.CL

TL;DR: 本文提出了首个端到端支持语音指令的GUI自主智能体GUIRoboTron-Speech，利用TTS合成语音训练和新颖的训练策略，实现了在多数据集上的优越性能，验证了语音驱动GUI操作的巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的面向图形用户界面（GUI）的自主智能体主要依赖文本指令，影响了其在无手操作或高便利性需求场景下的可访问性与实用性。

Method: 提出了GUIRoboTron-Speech，这是首个端到端能直接接受语音指令和设备截图来预测GUI操作的自主智能体。为了解决缺乏语音GUI数据集的问题，作者利用TTS模型将现有文本指令转换为高质量语音指令用于训练，同时采用了递进的语义和规划训练阶段，并设计了混合指令训练策略以缓解预训练模型的模态不均衡问题。

Result: 在多个基准数据集上的实验显示，GUIRoboTron-Speech在鲁棒性和性能上均优于现有方法，验证了语音作为GUI智能体指令方式的可行性和有效性。

Conclusion: GUIRoboTron-Speech作为首个支持语音-图像端到端输入的GUI智能体，能够有效推动语音作为指令模态在GUI交互领域的应用，具有广泛的实用前景。

Abstract: Autonomous agents for Graphical User Interfaces (GUIs) are revolutionizing
human-computer interaction, yet their reliance on text-based instructions
imposes limitations on accessibility and convenience, particularly in
hands-free scenarios. To address this gap, we propose GUIRoboTron-Speech, the
first end-to-end autonomous GUI agent that directly accepts speech instructions
and on-device screenshots to predict actions. Confronted with the scarcity of
speech-based GUI agent datasets, we initially generated high-quality speech
instructions for training by leveraging a random timbre text-to-speech (TTS)
model to convert existing text instructions. We then develop
GUIRoboTron-Speech's capabilities through progressive grounding and planning
training stages. A key contribution is a heuristic mixed-instruction training
strategy designed to mitigate the modality imbalance inherent in pre-trained
foundation models. Comprehensive experiments on several benchmark datasets
validate the robust and superior performance of GUIRoboTron-Speech,
demonstrating the significant potential and widespread applicability of speech
as an effective instruction modality for driving GUI agents. Our code and
datasets are available at https://github.com/GUIRoboTron/GUIRoboTron-Speech.

</details>


### [109] [Stronger Language Models Produce More Human-Like Errors](https://arxiv.org/abs/2506.11128)
*Andrew Keenan Richardson,Ryan Othniel Kearns,Sean Moss,Vincent Wang-Mascianica,Philipp Koralus*

Main category: cs.CL

TL;DR: 更强大的语言模型在推理时错误更像人类犯的错，即表现出特征性的人类推理偏见，这种趋势与正确率无关，挑战了模型规模带来理性化的传统观点。


<details>
  <summary>Details</summary>
Motivation: 探究随着模型能力提升，模型的推理模式是否越来越接近人类，包括其易犯错误类型，检验预期中的‘能力增强带来理性提升’假设。

Method: 应用Erotetic Theory of Reasoning（ETR）理论，利用PyETR生成专门针对人类常犯推理错误的逻辑题目，对38种语言模型在383项推理任务中的表现进行评估，并用Chatbot Arena分数标定模型能力。

Result: 随着模型能力增强，其错误越来越集中于与ETR预测的人类谬误一致（相关系数ρ=0.360, p=0.0265），但模型能力与逻辑正确率无明显相关，表明‘人类化谬误’的上升与模型本身正确率无关。此外还发现了顺序效应。

Conclusion: 随着语言模型能力提升，其错误模式越来越接近人类的推理谬误。这种人类化的错误模式与模型整体正确性没有相关性，表明模型不是趋向‘理性完美’，而是更像人类，包括人类的特征性偏见与局限。

Abstract: Do language models converge toward human-like reasoning patterns as they
improve? We provide surprising evidence that while overall reasoning
capabilities increase with model sophistication, the nature of errors
increasingly mirrors predictable human reasoning fallacies: a previously
unobserved inverse scaling phenomenon. To investigate this question, we apply
the Erotetic Theory of Reasoning (ETR), a formal cognitive framework with
empirical support for predicting human reasoning outcomes. Using the
open-source package PyETR, we generate logical reasoning problems where humans
predictably err, evaluating responses from 38 language models across 383
reasoning tasks. Our analysis indicates that as models advance in general
capability (as measured by Chatbot Arena scores), the proportion of their
incorrect answers that align with ETR-predicted human fallacies tends to
increase ($\rho = 0.360, p = 0.0265$). Notably, as we observe no correlation
between model sophistication and logical correctness on these tasks, this shift
in error patterns toward human-likeness occurs independently of error rate.
These findings challenge the prevailing view that scaling language models
naturally obtains normative rationality, suggesting instead a convergence
toward human-like cognition inclusive of our characteristic biases and
limitations, as we further confirm by demonstrating order-effects in language
model reasoning.

</details>


### [110] [Trustworthy AI for Medicine: Continuous Hallucination Detection and Elimination with CHECK](https://arxiv.org/abs/2506.11129)
*Carlos Garcia-Fernandez,Luis Felipe,Monique Shotande,Muntasir Zitu,Aakash Tripathi,Ghulam Rasool,Issam El Naqa,Vivek Rudrapatna,Gilmer Valdes*

Main category: cs.CL

TL;DR: 本文提出了CHECK系统，结合临床数据库与新型分类器，创新性地极大降低了大型语言模型在医疗场景下的“幻觉”率，实现了更高的安全性和准确性，为其在临床实践中的推广奠定了坚实基础。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在医疗领域具有很大潜力，但其幻觉（hallucination）现象，尤其是在事实与推理方面的错误，严重阻碍了其在临床中的应用。本文旨在解决这一关键挑战。

Method: 作者提出了CHECK框架，这是一种持续学习系统，将结构化临床数据库与基于信息理论的分类器结合，用于检测事实和推理层面的幻觉。此外，CHECK可利用幻觉概率引导GPT-4o的答案优化和计算资源分配。

Result: 在对来自100项关键临床试验的1500个问题的测试中，CHECK将LLama3.3-70B-Instruct的幻觉率从31%显著降低至0.3%，使开源模型达到业界领先水平。其分类器在不同医学基准上表现优秀，AUC为0.95-0.96。在USMLE的MedQA和HealthBench等多回合医疗问答基准上表现强劲。通过引导GPT-4o，USMLE的通过率提升5个百分点，达到92.1%。

Conclusion: CHECK框架极大提升了LLMs在医学等高风险领域的安全性与可靠性，有望推进其在临床中的大规模部署。

Abstract: Large language models (LLMs) show promise in healthcare, but hallucinations
remain a major barrier to clinical use. We present CHECK, a continuous-learning
framework that integrates structured clinical databases with a classifier
grounded in information theory to detect both factual and reasoning-based
hallucinations. Evaluated on 1500 questions from 100 pivotal clinical trials,
CHECK reduced LLama3.3-70B-Instruct hallucination rates from 31% to 0.3% -
making an open source model state of the art. Its classifier generalized across
medical benchmarks, achieving AUCs of 0.95-0.96, including on the MedQA (USMLE)
benchmark and HealthBench realistic multi-turn medical questioning. By
leveraging hallucination probabilities to guide GPT-4o's refinement and
judiciously escalate compute, CHECK boosted its USMLE passing rate by 5
percentage points, achieving a state-of-the-art 92.1%. By suppressing
hallucinations below accepted clinical error thresholds, CHECK offers a
scalable foundation for safe LLM deployment in medicine and other high-stakes
domains.

</details>


### [111] [A Self-Refining Framework for Enhancing ASR Using TTS-Synthesized Data](https://arxiv.org/abs/2506.11130)
*Cheng Kang Chou,Chan-Jan Hsu,Ho-Lam Chung,Liang-Hsuan Tseng,Hsi-Chun Cheng,Yu-Kuan Fu,Kuan Po Huang,Hung-Yi Lee*

Main category: cs.CL

TL;DR: 本文提出无需人工标注的ASR自我增强方法，通过伪标签循环提升模型性能。实验证明，对比强基线模型，错误率显著降低，特别适用于低资源场景。


<details>
  <summary>Details</summary>
Motivation: 当前ASR（自动语音识别）系统在低资源或特定领域下表现受限，因缺乏标注语音数据。作者希望通过无需人工标注、有效利用无标注数据的办法改进ASR性能。

Method: 提出一个自我增强（self-refining）循环框架：首先用现有ASR模型为未标注语音生成伪标签，然后用这些伪标签训练高保真TTS（文本转语音）系统，再用合成的语音-文本对反哺原ASR模型，形成闭环自我改进。

Result: 在台湾普通话语音数据上，用6000小时无标注语音、一定量文本和合成内容，对Whisper-large-v2模型进行自适应训练，得到专用ASR模型Twister。Twister在普通话上错误率降低20%，在中英混合测试上错误率降低50%。

Conclusion: 该自我增强框架为低资源或领域定制的ASR性能提升提供了一条有效途径，优于传统伪标签自蒸馏方法。

Abstract: We propose a self-refining framework that enhances ASR performance with only
unlabeled datasets. The process starts with an existing ASR model generating
pseudo-labels on unannotated speech, which are then used to train a
high-fidelity text-to-speech (TTS) system. Then, synthesized speech text pairs
are bootstrapped into the original ASR system, completing the closed-loop
self-improvement cycle. We demonstrated the effectiveness of the framework on
Taiwanese Mandarin speech. Leveraging 6,000 hours of unlabeled speech, a
moderate amount of text data, and synthetic content from the AI models, we
adapt Whisper-large-v2 into a specialized model, Twister. Twister reduces error
rates by up to 20% on Mandarin and 50% on Mandarin-English code-switching
benchmarks compared to Whisper. Results highlight the framework as a compelling
alternative to pseudo-labeling self-distillation approaches and provides a
practical pathway for improving ASR performance in low-resource or
domain-specific settings.

</details>


### [112] [Large Language Models and Emergence: A Complex Systems Perspective](https://arxiv.org/abs/2506.11135)
*David C. Krakauer,John W. Krakauer,Melanie Mitchell*

Main category: cs.CL

TL;DR: 本文综述并分析大型语言模型（LLMs）是否具备复杂性科学意义上的涌现能力及智能，比较和回顾了当前相关的量化标准和研究进展，指出尚需进一步研究。


<details>
  <summary>Details</summary>
Motivation: 复杂性科学中的涌现概念用于解释多体系统出现新颖高层性质的现象，人工智能尤其是LLMs声称展现出涌现智能，有必要系统梳理与验证这一命题。

Method: 回顾与分析当前评估LLMs涌现能力的量化方法与理论，根据复杂性科学的涌现理论提出评判标准。

Result: 综述了若干评估LLMs是否具备涌现能力的方法、衡量指标及其智能性，指出领域内关于‘涌现智能’的讨论仍在持续，需要进一步理论和实证研究。

Conclusion: 本文评估了大型语言模型（LLMs）是否展现了涌现能力及智能性，并提出有必要进一步探究和量化LLMs的涌现特性和智能表现。

Abstract: Emergence is a concept in complexity science that describes how many-body
systems manifest novel higher-level properties, properties that can be
described by replacing high-dimensional mechanisms with lower-dimensional
effective variables and theories. This is captured by the idea "more is
different". Intelligence is a consummate emergent property manifesting
increasingly efficient -- cheaper and faster -- uses of emergent capabilities
to solve problems. This is captured by the idea "less is more". In this paper,
we first examine claims that Large Language Models exhibit emergent
capabilities, reviewing several approaches to quantifying emergence, and
secondly ask whether LLMs possess emergent intelligence.

</details>


### [113] [Scalable Medication Extraction and Discontinuation Identification from Electronic Health Records Using Large Language Models](https://arxiv.org/abs/2506.11137)
*Chong Shao,Douglas Snyder,Chiran Li,Bowen Gu,Kerry Ngan,Chun-Ting Yang,Jiageng Wu,Richard Wyss,Kueiyu Joshua Lin,Jie Yang*

Main category: cs.CL

TL;DR: 本研究评估了多种LLM在无需人工标注条件下，从EHR自由文本中自动提取药物及其停用状态的能力。结果显示，包括开源模型在内的LLM有望高效助力临床信息挖掘，提升患者安全。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）中药物停用的信息常常隐藏于非结构化病程记录中，妨碍了患者安全。该研究旨在评估先进的大型语言模型（LLM）在无需人工标注的情况下，从EHR自由文本中提取药物信息并分类其状态的能力。

Method: 该研究收集了三个不同来源的EHR数据集作为评测基准，系统性地比较了12种先进的LLM（包括开源与专有）在药物提取、药物状态分类及联合任务（先提取后分类）上的表现，并测试了多种LLM提示工程策略，包括zero-shot和few-shot。

Result: GPT-4o在零样本（zero-shot）设定下于所有任务中均取得最高的平均F1分数（药物提取94.0%、停药分类78.1%、联合任务72.7%）。开源模型如Llama-3.1-70B-Instruct在某些任务和数据集上也表现突出。医学专用LLM整体表现不如通用LLM。少样本学习一般能提升效果，链式思考（CoT）增益不稳定。

Conclusion: LLM能有效从EHR自由文本中提取药物及其停用信息，开源模型为专有系统提供了有竞争力和可扩展的替代方案，少样本学习可进一步提高表现。

Abstract: Identifying medication discontinuations in electronic health records (EHRs)
is vital for patient safety but is often hindered by information being buried
in unstructured notes. This study aims to evaluate the capabilities of advanced
open-sourced and proprietary large language models (LLMs) in extracting
medications and classifying their medication status from EHR notes, focusing on
their scalability on medication information extraction without human
annotation. We collected three EHR datasets from diverse sources to build the
evaluation benchmark. We evaluated 12 advanced LLMs and explored multiple LLM
prompting strategies. Performance on medication extraction, medication status
classification, and their joint task (extraction then classification) was
systematically compared across all experiments. We found that LLMs showed
promising performance on the medication extraction and discontinuation
classification from EHR notes. GPT-4o consistently achieved the highest average
F1 scores in all tasks under zero-shot setting - 94.0% for medication
extraction, 78.1% for discontinuation classification, and 72.7% for the joint
task. Open-sourced models followed closely, Llama-3.1-70B-Instruct achieved the
highest performance in medication status classification on the MIV-Med dataset
(68.7%) and in the joint task on both the Re-CASI (76.2%) and MIV-Med (60.2%)
datasets. Medical-specific LLMs demonstrated lower performance compared to
advanced general-domain LLMs. Few-shot learning generally improved performance,
while CoT reasoning showed inconsistent gains. LLMs demonstrate strong
potential for medication extraction and discontinuation identification on EHR
notes, with open-sourced models offering scalable alternatives to proprietary
systems and few-shot can further improve LLMs' capability.

</details>


### [114] [RETUYT-INCO at BEA 2025 Shared Task: How Far Can Lightweight Models Go in AI-powered Tutor Evaluation?](https://arxiv.org/abs/2506.11243)
*Santiago Góngora,Ignacio Sastre,Santiago Robaina,Ignacio Remersaro,Luis Chiruzzo,Aiala Rosá*

Main category: cs.CL

TL;DR: 该论文验证了在算力受限环境下（小于1B参数的小模型），依然能在BEA 2025任务中取得具有竞争力的成绩，为低算力地区的AI研究提供了实证支持。


<details>
  <summary>Details</summary>
Motivation: 全球南方许多研究机构由于算力成本高昂，无法使用大规模模型。为体现这些实际研究环境，作者决定使用参数量低于1B的小模型参赛。

Method: 采用参数量小于1B的模型参与BEA 2025共享任务，并将其性能与其他参赛队伍进行比较，重点关注实际可用算力较低情况下的表现。

Result: 即使在模型仅小于1B参数的限制下，其表现与获胜队伍的exact F1分数差距在6.46到13.13点之间，各项任务均显示小模型在低算力设备上具备竞争力。

Conclusion: 低于1B参数的小型模型在多项NLP任务中仍具备竞争力，能在低预算GPU甚至无GPU环境中运行，为算力有限地区的研究人员提供了可行方案。

Abstract: In this paper, we present the RETUYT-INCO participation at the BEA 2025
shared task. Our participation was characterized by the decision of using
relatively small models, with fewer than 1B parameters. This self-imposed
restriction tries to represent the conditions in which many research labs or
institutions are in the Global South, where computational power is not easily
accessible due to its prohibitive cost. Even under this restrictive
self-imposed setting, our models managed to stay competitive with the rest of
teams that participated in the shared task. According to the $exact\ F_1$
scores published by the organizers, the performance gaps between our models and
the winners were as follows: $6.46$ in Track 1; $10.24$ in Track 2; $7.85$ in
Track 3; $9.56$ in Track 4; and $13.13$ in Track 5. Considering that the
minimum difference with a winner team is $6.46$ points -- and the maximum
difference is $13.13$ -- according to the $exact\ F_1$ score, we find that
models with a size smaller than 1B parameters are competitive for these tasks,
all of which can be run on computers with a low-budget GPU or even without a
GPU.

</details>


### [115] [Iterative Multilingual Spectral Attribute Erasure](https://arxiv.org/abs/2506.11244)
*Shun Shao,Yftah Ziser,Zheng Zhao,Yifu Qiu,Shay B. Cohen,Anna Korhonen*

Main category: cs.CL

TL;DR: 本文提出了一种多语言联合去偏新方法IMSAE，能有效提升各类主流模型的公平性，并支持zero-shot场景，优于传统单语与跨语方法。


<details>
  <summary>Details</summary>
Motivation: 在多语言词向量中，含义相似的词通常会被嵌入到共享语义空间，这为不同语言之间的偏见消除（debias）效果迁移带来了可能。然而，现有的去偏方法仅在单一语言中进行，未能利用多语言共享空间的优势。

Method: 提出了一种迭代多语言谱属性消除（Iterative Multilingual Spectral Attribute Erasure, IMSAE）的方法。该方法通过基于奇异值分解（SVD）的迭代截断，识别并减弱多个语言中的联合偏见子空间。

Result: 在八种语言和五个人口学维度上评估了IMSAE。实验涵盖BERT、LLaMA、Mistral等多种主流语言模型。无论在标准还是zero-shot（目标语言数据不可用，仅用相似语言去偏）设置下，IMSAE均优于现有单语和跨语去偏方法，同时保持了模型实用性。

Conclusion: IMSAE能够有效识别并缓解多语言联合偏见，且优于传统去偏方法。该方法为多语言模型的公平性提升提供了新途径，尤其在目标语言无资源的情况下表现突出。

Abstract: Multilingual representations embed words with similar meanings to share a
common semantic space across languages, creating opportunities to transfer
debiasing effects between languages. However, existing methods for debiasing
are unable to exploit this opportunity because they operate on individual
languages. We present Iterative Multilingual Spectral Attribute Erasure
(IMSAE), which identifies and mitigates joint bias subspaces across multiple
languages through iterative SVD-based truncation. Evaluating IMSAE across eight
languages and five demographic dimensions, we demonstrate its effectiveness in
both standard and zero-shot settings, where target language data is
unavailable, but linguistically similar languages can be used for debiasing.
Our comprehensive experiments across diverse language models (BERT, LLaMA,
Mistral) show that IMSAE outperforms traditional monolingual and cross-lingual
approaches while maintaining model utility.

</details>


### [116] [No Universal Prompt: Unifying Reasoning through Adaptive Prompting for Temporal Table Reasoning](https://arxiv.org/abs/2506.11246)
*Kushagra Dixit,Abhishek Rajgaria,Harshavardhan Kalalbandi,Dan Roth,Vivek Gupta*

Main category: cs.CL

TL;DR: 本文系统研究时序表格推理中的多种大语言模型提示方法，发现无万能策略。提出受人类推理启发的SEAR自适应框架，有效提升各种表格类型下的模型推理表现。同时，统一的表格结构表达也有助于增强推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在时序表格推理任务中面临显著挑战，而现有的多种提示方法在表格推理中的有效性尚未被充分研究。同时，模型在不同类型表格和上下文结构下的表现差异较大，缺乏统一最佳解法。本文旨在系统研究和比较多种提示策略的有效性，并提出新的自适应方法以提升推理表现。

Method: 本文系统考察并比对了多种适用于表格推理任务的提示技巧。作者进一步设计了SEAR框架，该框架受人类推理启发，能够根据上下文特性动态调整提示策略，并结合结构化推理。同时，研究还探讨了表格结构重构对推理表现的影响。

Result: 实验结果显示，不同的方法在不同实体类型、表格结构、是否需要额外上下文和问题复杂度下表现差异明显，无单一方法始终占优。所提出的SEAR自适应框架在所有表格类型上都优于现有主流提示方法。统一化的表格结构表达则进一步提升了模型推理能力。

Conclusion: SEAR方法具备较强的通用性和自适应性，可以提升大语言模型在多样化时序表格推理任务中的整体表现。合理的表格结构重构同样对模型推理有积极作用。

Abstract: Temporal Table Reasoning is a critical challenge for Large Language Models
(LLMs), requiring effective prompting techniques to extract relevant insights.
Despite existence of multiple prompting methods, their impact on table
reasoning remains largely unexplored. Furthermore, the performance of these
models varies drastically across different table and context structures, making
it difficult to determine an optimal approach. This work investigates multiple
prompting technique across diverse table types to determine optimal approaches
for different scenarios. We find that performance varies based on entity type,
table structure, requirement of additional context and question complexity,
with NO single method consistently outperforming others. To mitigate these
challenges, we introduce SEAR, an adaptive prompting framework inspired by
human reasoning that dynamically adjusts based on context characteristics and
integrates a structured reasoning. Our results demonstrate that SEAR achieves
superior performance across all table types compared to other baseline
prompting techniques. Additionally, we explore the impact of table structure
refactoring, finding that a unified representation enhances model's reasoning.

</details>


### [117] [Learning a Continue-Thinking Token for Enhanced Test-Time Scaling](https://arxiv.org/abs/2506.11274)
*Liran Ringel,Elad Tolochinsky,Yaniv Romano*

Main category: cs.CL

TL;DR: 通过强化学习训练一个新的继续思考token，可以让语言模型在不修改主模型权重情况下显著提升推理能力和准确率，效果优于简单地用固定词触发推理扩展。


<details>
  <summary>Details</summary>
Motivation: 推理能力对语言模型的性能有显著影响，已有研究表明通过替换“思考结束”标记能延长推理过程、获得更好准确率。本研究关注能否通过学习专用“继续思考”标记来更智能地触发额外推理。

Method: 作者在DeepSeek-R1蒸馏版基础上，增加了一个专用的“<|continue-thinking|>”标记，仅通过强化学习训练这个token的embedding，且固定其余模型参数。通过与使用固定token（如“Wait”）进行预算强迫的测试时间扩展方案进行对比实验。

Result: 实验证明，学习得到的continue-thinking token在标准数学基准任务上的准确率提升，明显优于基线模型和单纯使用固定token的方法。特别是在固定token方案本身对准确率有所提升的基准上，学习token的方法可获得更大的增益。例如在GSM8K任务上，固定token提升1.3%，而学习token能带来4.2%的绝对提升。

Conclusion: 使用强化学习训练的专用“继续思考”token可以在无需调整主模型权重的前提下，更有效地提升语言模型推理能力，优于传统的固定token扩展方法。

Abstract: Test-time scaling has emerged as an effective approach for improving language
model performance by utilizing additional compute at inference time. Recent
studies have shown that overriding end-of-thinking tokens (e.g., replacing
"</think>" with "Wait") can extend reasoning steps and improve accuracy. In
this work, we explore whether a dedicated continue-thinking token can be
learned to trigger extended reasoning. We augment a distilled version of
DeepSeek-R1 with a single learned "<|continue-thinking|>" token, training only
its embedding via reinforcement learning while keeping the model weights
frozen. Our experiments show that this learned token achieves improved accuracy
on standard math benchmarks compared to both the baseline model and a test-time
scaling approach that uses a fixed token (e.g., "Wait") for budget forcing. In
particular, we observe that in cases where the fixed-token approach enhances
the base model's accuracy, our method achieves a markedly greater improvement.
For example, on the GSM8K benchmark, the fixed-token approach yields a 1.3%
absolute improvement in accuracy, whereas our learned-token method achieves a
4.2% improvement over the base model that does not use budget forcing.

</details>


### [118] [Beyond Random Sampling: Efficient Language Model Pretraining via Curriculum Learning](https://arxiv.org/abs/2506.11300)
*Yang Zhang,Amr Mohamed,Hadi Abdine,Guokan Shang,Michalis Vazirgiannis*

Main category: cs.CL

TL;DR: 本文首次系统性分析了课程学习在大语言模型预训练中的作用，发现通过特定难度指标指导数据排序，可有效提升模型收敛速度和最终性能，提供了一种更加数据高效的预训练路径。


<details>
  <summary>Details</summary>
Motivation: 课程学习（Curriculum Learning）已在多个机器学习领域表现出提升训练效率和泛化能力的潜力，但其在语言模型预训练领域中的应用还鲜有系统性研究。本文旨在补充该领域的空白。

Method: 作者设计了多种课程学习设置，包括标准课程学习、基于步调的采样、交错式课程安排等，依据六种从语言学和信息论角度定义的数据难度指标进行引导。训练后在八个不同的基准测试上进行性能评估。

Result: 实验证明，课程学习在训练前期和中期持续提升模型收敛速度，作为预热策略可取得最高3.5%的提升。同时，压缩率、词汇多样性和可读性是跨场景有效的数据难度信号。

Conclusion: 数据排序在大规模语言模型预训练中十分重要，合理使用课程学习能带来显著的训练效率和模型性能提升。文中研究为现实场景下高效、可扩展模型的开发提供了具体指导。

Abstract: Curriculum learning has shown promise in improving training efficiency and
generalization in various machine learning domains, yet its potential in
pretraining language models remains underexplored, prompting our work as the
first systematic investigation in this area. We experimented with different
settings, including vanilla curriculum learning, pacing-based sampling, and
interleaved curricula-guided by six difficulty metrics spanning linguistic and
information-theoretic perspectives. We train models under these settings and
evaluate their performance on eight diverse benchmarks. Our experiments reveal
that curriculum learning consistently improves convergence in early and
mid-training phases, and can yield lasting gains when used as a warmup strategy
with up to $3.5\%$ improvement. Notably, we identify compression ratio, lexical
diversity, and readability as effective difficulty signals across settings. Our
findings highlight the importance of data ordering in large-scale pretraining
and provide actionable insights for scalable, data-efficient model development
under realistic training scenarios.

</details>


### [119] [Don't Pay Attention](https://arxiv.org/abs/2506.11305)
*Mohammad Hammoud,Devang Acharya*

Main category: cs.CL

TL;DR: 作者提出了Avey架构，规避了Transformer的注意力机制和递归结构限制，有效处理任意长度序列，在长距离依赖任务上超越了Transformer。


<details>
  <summary>Details</summary>
Motivation: Transformer虽然已广泛应用，但面临上下文窗口固定和注意力机制计算复杂度高的问题，激发了对能有效建模长序列RNN新变体的兴趣，需要突破Transformer架构的局限。

Method: 提出了一种新型基础神经网络架构Avey，由排序器和自回归神经处理器组成，通过协作识别和建模任意token的最相关上下文token，而不是受限于位置或固定窗口。

Result: Avey在多项标准NLP任务中表现与Transformer相当，在处理长距离依赖任务上性能显著更优。

Conclusion: Avey架构在多项NLP基准任务上表现优于Transformer，特别是在捕捉长距离依赖方面表现突出。

Abstract: The Transformer has become the de facto standard for large language models
and a wide range of downstream tasks across various domains. Despite its
numerous advantages like inherent training parallelism, the Transformer still
faces key challenges due to its inability to effectively process sequences
beyond a fixed context window and the quadratic complexity of its attention
mechanism. These challenges have renewed interest in RNN-like architectures,
which offer linear scaling with sequence length and improved handling of
long-range dependencies, albeit with limited parallelism due to their
inherently recurrent nature. In this paper, we propose Avey, a new neural
foundational architecture that breaks away from both attention and recurrence.
Avey comprises a ranker and an autoregressive neural processor, which
collaboratively identify and contextualize only the most relevant tokens for
any given token, regardless of their positions in the sequence. Specifically,
Avey decouples sequence length from context width, thus enabling effective
processing of arbitrarily long sequences. Experimental results show that Avey
compares favorably to the Transformer across a variety of standard short-range
NLP benchmarks, while notably excelling at capturing long-range dependencies.

</details>


### [120] [Surprisal from Larger Transformer-based Language Models Predicts fMRI Data More Poorly](https://arxiv.org/abs/2506.11338)
*Yi-Chien Lin,William Schuler*

Main category: cs.CL

TL;DR: Transformer模型的惊奇度不仅能很好地预测人类延迟型阅读行为，还能预测大脑神经反应，且其预测力与模型困惑度呈正相关。


<details>
  <summary>Details</summary>
Motivation: Transformers模型在自然语言处理任务中的应用越来越广泛，相关研究发现Transformer的“惊奇度（surprisal）”可以预测人类句子加工难度。此前的研究集中在用Transformer的惊奇度预测人类阅读时长等延迟类指标，但尚未研究这种趋势在大脑成像数据中的表现。因此，本文旨在探索Transformer惊奇度在神经测量上的预测能力。

Method: 本文评估了17个预训练Transformer模型（涵盖三种不同的语言家族），通过分析它们的惊奇度对两个fMRI（功能磁共振成像）数据集的预测力，从而考察惊奇度和模型困惑度（perplexity）的关系。

Result: 实验结果发现，Transformer模型的困惑度与模型的适配度（即惊奇度对神经数据的预测力）之间呈正相关。这表明，困惑度较高的模型，对人类大脑神经反应的预测更有力。

Conclusion: Transformer惊奇度在预测神经指标时延续了在延迟性行为指标（例如阅读时长）上的趋势——模型困惑度与预测能力呈正相关。这一趋势从行为数据拓展到了神经数据层面，具有普遍性。

Abstract: As Transformers become more widely incorporated into natural language
processing tasks, there has been considerable interest in using surprisal from
these models as predictors of human sentence processing difficulty. Recent work
has observed a positive relationship between Transformer-based models'
perplexity and the predictive power of their surprisal estimates on reading
times, showing that language models with more parameters and trained on more
data are less predictive of human reading times. However, these studies focus
on predicting latency-based measures (i.e., self-paced reading times and
eye-gaze durations) with surprisal estimates from Transformer-based language
models. This trend has not been tested on brain imaging data. This study
therefore evaluates the predictive power of surprisal estimates from 17
pre-trained Transformer-based models across three different language families
on two functional magnetic resonance imaging datasets. Results show that the
positive relationship between model perplexity and model fit still obtains,
suggesting that this trend is not specific to latency-based measures and can be
generalized to neural measures.

</details>


### [121] [From Replication to Redesign: Exploring Pairwise Comparisons for LLM-Based Peer Review](https://arxiv.org/abs/2506.11343)
*Yaohui Zhang,Haijing Zhang,Wenlong Ji,Tianyu Hua,Nick Haber,Hancheng Cao,Weixin Liang*

Main category: cs.CL

TL;DR: 本文提出用大语言模型进行论文两两比较评审，明显优于传统方法，但带来了新型偏见，需要进一步优化以确保公平多样性。


<details>
  <summary>Details</summary>
Motivation: 现有利用大语言模型（LLM）参与学术同行评审的尝试，大多只是用LLM直接替代人工流程，缺乏对评审机制的根本创新。

Method: 提出了一种全新的机制：利用LLM代理对论文进行成对比较，而不是单独打分，并通过汇总大量两两比较结果来评估论文的相对质量。

Result: 实验表明，这种基于比较的方法在识别高影响力论文方面明显优于传统打分法，但也出现了主题新颖性下降和机构偏见加剧等新型偏差。

Conclusion: LLM可以彻底改变学术评审流程，但新方法也带来了公平性和多样性的挑战。

Abstract: The advent of large language models (LLMs) offers unprecedented opportunities
to reimagine peer review beyond the constraints of traditional workflows.
Despite these opportunities, prior efforts have largely focused on replicating
traditional review workflows with LLMs serving as direct substitutes for human
reviewers, while limited attention has been given to exploring new paradigms
that fundamentally rethink how LLMs can participate in the academic review
process. In this paper, we introduce and explore a novel mechanism that employs
LLM agents to perform pairwise comparisons among manuscripts instead of
individual scoring. By aggregating outcomes from substantial pairwise
evaluations, this approach enables a more accurate and robust measure of
relative manuscript quality. Our experiments demonstrate that this comparative
approach significantly outperforms traditional rating-based methods in
identifying high-impact papers. However, our analysis also reveals emergent
biases in the selection process, notably a reduced novelty in research topics
and an increased institutional imbalance. These findings highlight both the
transformative potential of rethinking peer review with LLMs and critical
challenges that future systems must address to ensure equity and diversity.

</details>


### [122] [Do We Still Need Audio? Rethinking Speaker Diarization with a Text-Based Approach Using Multiple Prediction Models](https://arxiv.org/abs/2506.11344)
*Peilin Wu,Jinho D. Choi*

Main category: cs.CL

TL;DR: 本文提出了两种基于对话文本的说话人变化检测模型，有效提升了短对话环境下的说话人分离准确率，表现优于传统音频方法，为语义和多模态特征在SD领域的应用带来了新方向。


<details>
  <summary>Details</summary>
Motivation: 现有的说话人分离（Speaker Diarization, SD）方法大多依赖音频信息，容易受到音频质量或说话人音色接近的干扰。本研究希望通过只使用对话文本，探索基于文本的方法提升说话人变换检测的准确性，尤其在短对话中。

Method: 提出两种新的文本驱动的说话人变换检测模型：单一预测模型（SPM）和多预测模型（MPM），只依赖对话文本进行说话人变化点检测，并在多样化对话场景数据集上进行实验评估。

Result: 实验显示，两种模型在检测说话人变换方面有显著提升，尤其是在短对话场景中。MPM模型在短对话中的表现甚至优于当前最先进的音频型SD系统。

Conclusion: 基于文本的方法能有效用于说话人分离，尤其在音频条件受限或说话人音色相近场景下优势明显，且鼓励未来将语义特征与多模态结合以进一步提升SD性能。

Abstract: We present a novel approach to Speaker Diarization (SD) by leveraging
text-based methods focused on Sentence-level Speaker Change Detection within
dialogues. Unlike audio-based SD systems, which are often challenged by audio
quality and speaker similarity, our approach utilizes the dialogue transcript
alone. Two models are developed: the Single Prediction Model (SPM) and the
Multiple Prediction Model (MPM), both of which demonstrate significant
improvements in identifying speaker changes, particularly in short
conversations. Our findings, based on a curated dataset encompassing diverse
conversational scenarios, reveal that the text-based SD approach, especially
the MPM, performs competitively against state-of-the-art audio-based SD
systems, with superior performance in short conversational contexts. This paper
not only showcases the potential of leveraging linguistic features for SD but
also highlights the importance of integrating semantic understanding into SD
systems, opening avenues for future research in multimodal and semantic
feature-based diarization.

</details>


### [123] [The Biased Samaritan: LLM biases in Perceived Kindness](https://arxiv.org/abs/2506.11361)
*Jack H Fagan,Ruhaan Juyaal,Amy Yue-Ming Yu,Siya Pun*

Main category: cs.CL

TL;DR: 本研究通过道德介入评估法，创新性地区分并量化了大语言模型在不同人口群体上的偏见，发现主流模型基线偏向白人男性，且非基线群体普遍被认为更愿意帮助他人。该方法有助于客观评价和改进LLM的人口公平性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）在各领域广泛应用，但其内在的偏见问题仍未解决。现有的方法难以精确量化模型在不同群体上的偏见，因此有必要探索新的评估方式，以更好地理解这些偏见并为后续改进模型提供依据。

Method: 该论文提出了一种新颖的定量方法，通过让模型对“道德主体介入意愿”进行评估，来检测和衡量不同生成式AI模型对性别、种族和年龄等群体的偏见。方法特别关注厘清主流水平线身份（即白人中青年男性）与其他人口身份的关系及倾向。

Result: 实验表明，当前主流大模型将‘基线’人口界定为白人中年或青年男性，但普遍存在非基线群体比基线群体表现出更高的合作意愿。这表明模型中存在交织的两种偏见，这一新方法能够有效区分这样的复合偏见。

Conclusion: 本文为评估和区分LLM中的人口偏见提出了新方法，并揭示了模型在不同人口群体间的显著差异，能为开发者和用户在优化模型输出和未来训练中提供兼容的量化参考。

Abstract: While Large Language Models (LLMs) have become ubiquitous in many fields,
understanding and mitigating LLM biases is an ongoing issue. This paper
provides a novel method for evaluating the demographic biases of various
generative AI models. By prompting models to assess a moral patient's
willingness to intervene constructively, we aim to quantitatively evaluate
different LLMs' biases towards various genders, races, and ages. Our work
differs from existing work by aiming to determine the baseline demographic
identities for various commercial models and the relationship between the
baseline and other demographics. We strive to understand if these biases are
positive, neutral, or negative, and the strength of these biases. This paper
can contribute to the objective assessment of bias in Large Language Models and
give the user or developer the power to account for these biases in LLM output
or in training future LLMs. Our analysis suggested two key findings: that
models view the baseline demographic as a white middle-aged or young adult
male; however, a general trend across models suggested that non-baseline
demographics are more willing to help than the baseline. These methodologies
allowed us to distinguish these two biases that are often tangled together.

</details>


### [124] [A Variational Approach for Mitigating Entity Bias in Relation Extraction](https://arxiv.org/abs/2506.11381)
*Samuel Mensah,Elena Kochkina,Jabez Magomere,Joy Prakash Sain,Simerjot Kaur,Charese Smiley*

Main category: cs.CL

TL;DR: 通过变分信息瓶颈方法压缩实体信息，作者显著提升了关系抽取模型的泛化和鲁棒性，在多个领域和测试设置取得了最优结果。


<details>
  <summary>Details</summary>
Motivation: 关系抽取任务中，模型往往过度依赖实体本身，导致泛化能力较差，因此如何减轻实体偏见成了关键挑战。

Method: 采用变分信息瓶颈（VIB）框架，压缩与实体相关的信息，同时保留与任务相关的特征，实现对实体偏见的缓解。

Result: 在通用、金融和生物医学等不同领域的数据集上，在原始测试集（in-domain）和经过实体类型约束替换的测试集（out-of-domain）中均取得了最新的最优性能。

Conclusion: 该方法为关系抽取领域提供了一种鲁棒、可解释且具备理论基础的新方法，显著减轻了实体偏见问题。

Abstract: Mitigating entity bias is a critical challenge in Relation Extraction (RE),
where models often rely excessively on entities, resulting in poor
generalization. This paper presents a novel approach to address this issue by
adapting a Variational Information Bottleneck (VIB) framework. Our method
compresses entity-specific information while preserving task-relevant features.
It achieves state-of-the-art performance on relation extraction datasets across
general, financial, and biomedical domains, in both indomain (original test
sets) and out-of-domain (modified test sets with type-constrained entity
replacements) settings. Our approach offers a robust, interpretable, and
theoretically grounded methodology.

</details>


### [125] [Curriculum-Guided Layer Scaling for Language Model Pretraining](https://arxiv.org/abs/2506.11389)
*Karanpartap Singh,Neil Band,Ehsan Adeli*

Main category: cs.CL

TL;DR: CGLS结合‘课程学习’与层数逐步扩展，有效提升大模型训练效率和复杂任务的泛化表现，是切实可行的预训练优化策略。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型预训练成本高昂，需提升学习效率。受人类认知发展启发（知识随大脑成长递进），探索通过逐步提升模型容量和数据难度，提升知识与推理任务的训练效果。

Method: 提出了Curriculum-Guided Layer Scaling (CGLS) 框架，在训练过程中通过分阶段增加Transformer层数，并配合逐渐增加的数据难度，实现模型容量和训练难度同步进阶。实验分为100M参数和1.2B参数两个规模，分别采用短故事到网页数据和一般文本到高技术文本的课程训练。

Result: 在100M参数规模下，CGLS在PIQA和ARC问答任务上优于基线方法；1.2B规模上通过DistilBERT分层数据，实现了泛化能力和零样本性能的提升。

Conclusion: 逐步增加模型深度与难度同步的数据训练有助于提升大模型泛化能力和推理任务表现，CGLS方法有效释放了渐进堆叠的潜力。

Abstract: As the cost of pretraining large language models grows, there is continued
interest in strategies to improve learning efficiency during this core training
stage. Motivated by cognitive development, where humans gradually build
knowledge as their brains mature, we propose Curriculum-Guided Layer Scaling
(CGLS), a framework for compute-efficient pretraining that synchronizes
increasing data difficulty with model growth through progressive layer stacking
(i.e. gradually adding layers during training). At the 100M parameter scale,
using a curriculum transitioning from synthetic short stories to general web
data, CGLS outperforms baseline methods on the question-answering benchmarks
PIQA and ARC. Pretraining at the 1.2B scale, we stratify the DataComp-LM corpus
with a DistilBERT-based classifier and progress from general text to highly
technical or specialized content. Our results show that progressively
increasing model depth alongside sample difficulty leads to better
generalization and zero-shot performance on various downstream benchmarks.
Altogether, our findings demonstrate that CGLS unlocks the potential of
progressive stacking, offering a simple yet effective strategy for improving
generalization on knowledge-intensive and reasoning tasks.

</details>


### [126] [Predicting Early-Onset Colorectal Cancer with Large Language Models](https://arxiv.org/abs/2506.11410)
*Wilson Lau,Youngwon Kim,Sravanthi Parasa,Md Enamul Haque,Anand Oka,Jay Nanduri*

Main category: cs.CL

TL;DR: 研究发现，微调后的大型语言模型能够基于诊断前6个月的数据，以较高灵敏度和特异性预测45岁以下早发结直肠癌，有望弥补筛查盲区，提升早期诊断能力。


<details>
  <summary>Details</summary>
Motivation: 早发结直肠癌（EoCRC，<45岁）发病率逐年上升，但现有的国家筛查指南推荐的年龄较高，导致年轻人群未能覆盖。需要找到有效的早期预测手段。

Method: 收集了来自美国多家医疗系统的1,953例结直肠癌患者病历数据，利用患者诊断前6个月的临床状况、实验室结果和观察数据，分别应用10种机器学习模型和先进的大型语言模型（LLM）进行EoCRC预测，并进行性能对比。

Result: 微调后的大型语言模型（LLM）在预测EoCRC方面取得了73%的灵敏度和91%的特异性，表现优于其他传统机器学习模型。

Conclusion: 大型语言模型有望作为年轻人群中早发结直肠癌早筛的有效工具，能显著提升疾病早期检测率。

Abstract: The incidence rate of early-onset colorectal cancer (EoCRC, age < 45) has
increased every year, but this population is younger than the recommended age
established by national guidelines for cancer screening. In this paper, we
applied 10 different machine learning models to predict EoCRC, and compared
their performance with advanced large language models (LLM), using patient
conditions, lab results, and observations within 6 months of patient journey
prior to the CRC diagnoses. We retrospectively identified 1,953 CRC patients
from multiple health systems across the United States. The results demonstrated
that the fine-tuned LLM achieved an average of 73% sensitivity and 91%
specificity.

</details>


### [127] [Efficient Long-Context LLM Inference via KV Cache Clustering](https://arxiv.org/abs/2506.11418)
*Jie Hu,Shengnan Wang,Yutong He,Ping Gong,Jiawei Yi,Juncheng Zhang,Youhui Bai,Renhai Chen,Gong Zhang,Cheng Li,Kun Yuan*

Main category: cs.CL

TL;DR: 本文提出Chelsea框架，通过分片聚类合并KV缓存，显著减少内存消耗，并加速大语言模型长上下文推理，且模型表现无显著损失，对实际部署极具意义。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）近年来广泛应用于复杂任务，但其长上下文处理需要巨大的Key-Value（KV）缓存，带来部署和计算上的难题。现有方法要么丢弃对后续生成可能重要的信息，要么带来较大算力开销，效率提升有限。因此寻求一种更高效、低损耗的KV cache管理方式成为亟需解决的问题。

Method: 本文提出了Chelsea框架，对KV缓存进行在线聚类管理。具体做法是将序列分片（chunk），在每个chunk内部采用交替分区策略（Chunked Soft Matching）按相似性聚类，然后将每个聚类的KV缓存合并为一个中心点（centroid）。作者还给出了理论上的计算复杂度和分区策略最优性的分析。

Result: 在各类模型和长上下文基准测试中，Chelsea框架可以使KV缓存的内存使用量减少高达80%，同时模型性能几乎无损。此外，在计算开销极小的前提下，Chelsea加速推理解码阶段达3.19倍，端到端时延降幅可达2.72倍。

Conclusion: Chelsea是一种简单高效的KV缓存聚类框架，能够大幅降低内存消耗，加速推理流程，同时保持模型性能不失。其思路和方法对于长上下文LLM的实际部署具有实用价值。

Abstract: Large language models (LLMs) with extended context windows have become
increasingly prevalent for tackling complex tasks. However, the substantial
Key-Value (KV) cache required for long-context LLMs poses significant
deployment challenges. Existing approaches either discard potentially critical
information needed for future generations or offer limited efficiency gains due
to high computational overhead. In this paper, we introduce Chelsea, a simple
yet effective framework for online KV cache clustering. Our approach is based
on the observation that key states exhibit high similarity along the sequence
dimension. To enable efficient clustering, we divide the sequence into chunks
and propose Chunked Soft Matching, which employs an alternating partition
strategy within each chunk and identifies clusters based on similarity. Chelsea
then merges the KV cache within each cluster into a single centroid.
Additionally, we provide a theoretical analysis of the computational complexity
and the optimality of the intra-chunk partitioning strategy. Extensive
experiments across various models and long-context benchmarks demonstrate that
Chelsea achieves up to 80% reduction in KV cache memory usage while maintaining
comparable model performance. Moreover, with minimal computational overhead,
Chelsea accelerates the decoding stage of inference by up to 3.19$\times$ and
reduces end-to-end latency by up to 2.72$\times$.

</details>


### [128] [Agent-RLVR: Training Software Engineering Agents via Guidance and Environment Rewards](https://arxiv.org/abs/2506.11425)
*Jeff Da,Clinton Wang,Xiang Deng,Yuntao Ma,Nikhil Barhate,Sean Hendryx*

Main category: cs.CL

TL;DR: 本文提出Agent-RLVR框架，在引入类似教师指导的机制后，大幅提升了大模型在复杂软件工程任务中的表现，显著超越传统RLVR方法。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法在提升大语言模型推理能力方面取得进展，尤其在可验证任务（如数学和编程竞赛）中较为成功；但在多步、复杂的agentic环境（如软件工程）中效果显著下降，原因是奖励过于稀疏、训练困难。

Method: 提出了Agent-RLVR框架，通过引入“agent guidance”机制模拟人类教师的引导方式，利用策略计划、动态反馈等多种信息源指导智能体进行任务解决。训练流程包括初始尝试—单元测试验证—引导补充—再次尝试，最终使用RLVR更新模型。

Result: Agent-RLVR将Qwen-2.5-72B-Instruct在SWE-Bench Verified基准上的pass@1表现从9.4%提升到22.4%。在引导增强数据的辅助下，进一步提升到27.8%。

Conclusion: Agent-RLVR有效缓解了传统RLVR在复杂agentic环境中的局限性，为大语言模型在真实复杂环境中的训练奠定基础，并具有实际提升效果。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has been widely adopted
as the de facto method for enhancing the reasoning capabilities of large
language models and has demonstrated notable success in verifiable domains like
math and competitive programming tasks. However, the efficacy of RLVR
diminishes significantly when applied to agentic environments. These settings,
characterized by multi-step, complex problem solving, lead to high failure
rates even for frontier LLMs, as the reward landscape is too sparse for
effective model training via conventional RLVR. In this work, we introduce
Agent-RLVR, a framework that makes RLVR effective in challenging agentic
settings, with an initial focus on software engineering tasks. Inspired by
human pedagogy, Agent-RLVR introduces agent guidance, a mechanism that actively
steers the agent towards successful trajectories by leveraging diverse
informational cues. These cues, ranging from high-level strategic plans to
dynamic feedback on the agent's errors and environmental interactions, emulate
a teacher's guidance, enabling the agent to navigate difficult solution spaces
and promotes active self-improvement via additional environment exploration. In
the Agent-RLVR training loop, agents first attempt to solve tasks to produce
initial trajectories, which are then validated by unit tests and supplemented
with agent guidance. Agents then reattempt with guidance, and the agent policy
is updated with RLVR based on the rewards of these guided trajectories.
Agent-RLVR elevates the pass@1 performance of Qwen-2.5-72B-Instruct from 9.4%
to 22.4% on SWE-Bench Verified. We find that our guidance-augmented RLVR data
is additionally useful for test-time reward model training, shown by further
boosting pass@1 to 27.8%. Agent-RLVR lays the groundwork for training agents
with RLVR in complex, real-world environments where conventional RL methods
struggle.

</details>


### [129] [KoGEC : Korean Grammatical Error Correction with Pre-trained Translation Models](https://arxiv.org/abs/2506.11432)
*Taeeun Kim,Semin Jeong,Youngsook Song*

Main category: cs.CL

TL;DR: 本文提出并优化了一套小型、高效的韩语语法纠错系统KoGEC，在多个数据集和评测指标上超过了GPT-4o和HCX-3等大型语言模型，并开发了便捷的Chrome插件，表明专用小模型在特定任务上可与大模型竞争。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型如GPT-4在多语言语法纠错任务表现突出，但针对韩语等特定语种和具体任务时，现有方法缺乏高效、专业化的解决方案。因此，本文致力于开发高效的韩语语法纠错系统，并评估其与大型通用模型的比较优势。

Method: 本文对NLLB（No Language Left Behind）翻译预训练模型进行了微调，使其适应韩语语法纠错任务。为训练和测试模型，采用了两个社交媒体对话数据集。微调中引入特殊语言标记以区分原始句与纠正句，通过BLEU得分和‘LLM as judge’方法进行评测，并对不同类型的语法错误进行细分分析。还尝试了词表扩展以及开发了浏览器插件。

Result: 经过微调的NLLB（KoGEC）模型在韩语语法纠错任务中超越了GPT-4o和HCX-3，表现出在各种错误类型上的更均衡纠错能力，尤其是在标点符号错误纠正方面优于大型模型。词表扩展尝试则未能带来性能提升。最终开发的Chrome插件也便于用户直接使用该系统。

Conclusion: 紧凑的、面向特定任务的模型（如KoGEC）在特定NLP任务中能够与甚至超越体量更大、用途更广的语言模型。本文不仅提供了高效的韩语语法纠错系统和新评估方法，也验证了专业化模型在实际应用中的重要性。

Abstract: This research introduces KoGEC, a Korean Grammatical Error Correction system
using pre\--trained translation models. We fine-tuned NLLB (No Language Left
Behind) models for Korean GEC, comparing their performance against large
language models like GPT-4 and HCX-3. The study used two social media
conversation datasets for training and testing. The NLLB models were fine-tuned
using special language tokens to distinguish between original and corrected
Korean sentences. Evaluation was done using BLEU scores and an "LLM as judge"
method to classify error types. Results showed that the fine-tuned NLLB (KoGEC)
models outperformed GPT-4o and HCX-3 in Korean GEC tasks. KoGEC demonstrated a
more balanced error correction profile across various error types, whereas the
larger LLMs tended to focus less on punctuation errors. We also developed a
Chrome extension to make the KoGEC system accessible to users. Finally, we
explored token vocabulary expansion to further improve the model but found it
to decrease model performance. This research contributes to the field of NLP by
providing an efficient, specialized Korean GEC system and a new evaluation
method. It also highlights the potential of compact, task-specific models to
compete with larger, general-purpose language models in specialized NLP tasks.

</details>


### [130] [AbsenceBench: Language Models Can't Tell What's Missing](https://arxiv.org/abs/2506.11440)
*Harvey Yiyun Fu,Aryan Shrivastava,Jared Moore,Peter West,Chenhao Tan,Ari Holtzman*

Main category: cs.CL

TL;DR: 本文提出AbsenceBench，用于检测大模型识别文档缺失信息能力，结果显示即使最优模型表现也有限，揭示了Transformer结构性短板。


<details>
  <summary>Details</summary>
Motivation: 现有评测如“NIAH”测试强调模型识别和复现显著信息的能力，但实际应用中，能否及时发现缺失或被省略的信息同样重要，而该能力尚未被系统评估。

Method: 提出了AbsenceBench基准，通过让模型对比原始与编辑后的文档，在数字序列、诗歌、GitHub拉取请求三大领域，评估模型识别被删减信息的能力，量化F1得分。

Result: 即便是Claude-3.7-Sonnet等最先进模型，面对平均仅5K token长的上下文，F1得分也只有69.6%，说明模型距离“检测缺失”这一需求仍有较大提升空间。这一不足归因于当前Transformer框架难以捕捉“空白”信号。

Conclusion: 尽管大型语言模型在检索和回忆信息方面表现优异，但它们在检测缺失信息方面存在明显瓶颈，这主要源于Transformer注意力机制的结构性局限。

Abstract: Large language models (LLMs) are increasingly capable of processing long
inputs and locating specific information within them, as evidenced by their
performance on the Needle in a Haystack (NIAH) test. However, while models
excel at recalling surprising information, they still struggle to identify
clearly omitted information. We introduce AbsenceBench to assesses LLMs'
capacity to detect missing information across three domains: numerical
sequences, poetry, and GitHub pull requests. AbsenceBench asks models to
identify which pieces of a document were deliberately removed, given access to
both the original and edited contexts. Despite the apparent straightforwardness
of these tasks, our experiments reveal that even state-of-the-art models like
Claude-3.7-Sonnet achieve only 69.6% F1-score with a modest average context
length of 5K tokens. Our analysis suggests this poor performance stems from a
fundamental limitation: Transformer attention mechanisms cannot easily attend
to "gaps" in documents since these absences don't correspond to any specific
keys that can be attended to. Overall, our results and analysis provide a case
study of the close proximity of tasks where models are already superhuman
(NIAH) and tasks where models breakdown unexpectedly (AbsenceBench).

</details>


### [131] [A Gamified Evaluation and Recruitment Platform for Low Resource Language Machine Translation Systems](https://arxiv.org/abs/2506.11467)
*Carlos Rafael Catalan*

Main category: cs.CL

TL;DR: 本文分析了低资源语言机器翻译评估中的难题，设计了一套整合数据集、评估者招募及游戏化功能的平台框架，为解决资源稀缺和提升评估质量提供了创新思路。


<details>
  <summary>Details</summary>
Motivation: 低资源语言（LRL）的机器翻译系统评估面临困难：自动评估方法存在局限，而能够胜任的人类评估者和数据集又十分稀缺。

Method: 首先回顾并分析了现有评估方法，然后提出并设计了一个平台，该平台集数据集、评估者招募与游戏化评测于一体，专为机器翻译开发者服务。

Result: 设计出一个针对LRL的机器翻译系统评估的招募和游戏化平台，并讨论了平台评估面临的挑战以及该方案在更广泛的自然语言处理研究中可能的应用。

Conclusion: 本研究为解决低资源语言机器翻译系统中评估资源稀缺的问题，提出了一个系统化、可扩展的平台设计，有望推动该领域的发展。

Abstract: Human evaluators provide necessary contributions in evaluating large language
models. In the context of Machine Translation (MT) systems for low-resource
languages (LRLs), this is made even more apparent since popular automated
metrics tend to be string-based, and therefore do not provide a full picture of
the nuances of the behavior of the system. Human evaluators, when equipped with
the necessary expertise of the language, will be able to test for adequacy,
fluency, and other important metrics. However, the low resource nature of the
language means that both datasets and evaluators are in short supply. This
presents the following conundrum: How can developers of MT systems for these
LRLs find adequate human evaluators and datasets? This paper first presents a
comprehensive review of existing evaluation procedures, with the objective of
producing a design proposal for a platform that addresses the resource gap in
terms of datasets and evaluators in developing MT systems. The result is a
design for a recruitment and gamified evaluation platform for developers of MT
systems. Challenges are also discussed in terms of evaluating this platform, as
well as its possible applications in the wider scope of Natural Language
Processing (NLP) research.

</details>


### [132] [Med-PRM: Medical Reasoning Models with Stepwise, Guideline-verified Process Rewards](https://arxiv.org/abs/2506.11474)
*Jaehoon Yun,Jiwoong Sohn,Jungwoo Park,Hyunjae Kim,Xiangru Tang,Yanjun Shao,Yonghoe Koo,Minhyeok Ko,Qingyu Chen,Mark Gerstein,Michael Moor,Jaewoo Kang*

Main category: cs.CL

TL;DR: Med-PRM通过在医学推理每一步核查证据，大幅提升了AI模型在临床问答与诊断上的准确性和安全性，并实现了行业领先水平。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型已在临床决策中展现出潜力，但现有方法难以定位和纠正推理流程中具体环节的错误。而在医学领域，识别并处理推理错误对于准确诊断和有效治疗至关重要。本文的研究动机是解决医学人工智能推理过程中的错误检测与校正难题。

Method: 提出Med-PRM（一种过程奖励建模框架），结合检索增强生成的方法，对每一步推理进行验证。具体做法为：将中间推理步骤与医学知识库（如临床指南和医学文献）检索到的证据进行比对，从而细致地评估推理的每个环节。

Result: 在五个医学问答基准和两个开放式诊断任务中，Med-PRM实现了最新的最优性能，且最多可提升底层模型13.50%的表现。此外，Med-PRM能够与强大的策略模型（如Meerkat）无缝集成，在8B参数规模下首次在MedQA任务中超过80%准确率。代码和数据已开源。

Conclusion: Med-PRM可用于精细地评估医学推理过程、有效定位与纠正推理错误，从而显著提升医学AI模型的可靠性和准确率。该方法通用性强，可在多个模型和任务中广泛应用。

Abstract: Large language models have shown promise in clinical decision making, but
current approaches struggle to localize and correct errors at specific steps of
the reasoning process. This limitation is critical in medicine, where
identifying and addressing reasoning errors is essential for accurate diagnosis
and effective patient care. We introduce Med-PRM, a process reward modeling
framework that leverages retrieval-augmented generation to verify each
reasoning step against established medical knowledge bases. By verifying
intermediate reasoning steps with evidence retrieved from clinical guidelines
and literature, our model can precisely assess the reasoning quality in a
fine-grained manner. Evaluations on five medical QA benchmarks and two
open-ended diagnostic tasks demonstrate that Med-PRM achieves state-of-the-art
performance, with improving the performance of base models by up to 13.50%
using Med-PRM. Moreover, we demonstrate the generality of Med-PRM by
integrating it in a plug-and-play fashion with strong policy models such as
Meerkat, achieving over 80\% accuracy on MedQA for the first time using
small-scale models of 8 billion parameters. Our code and data are available at:
https://med-prm.github.io/

</details>


### [133] [ImmunoFOMO: Are Language Models missing what oncologists see?](https://arxiv.org/abs/2506.11478)
*Aman Sinha,Bogdan-Valentin Popescu,Xavier Coubez,Marianne Clausel,Mathieu Constant*

Main category: cs.CL

TL;DR: 本文比较了语言模型与临床专家对于乳腺癌免疫治疗文摘中医学标志的识别能力，发现领域预训练模型在细致医学概念提取上具备优势。


<details>
  <summary>Details</summary>
Motivation: 由于语言模型能力迅速提升，医学和生物医学等领域研究者希望利用其辅助日常科研及诊断，尤其关注其理解医学概念的能力。

Method: 对多个语言模型与专家临床医生在乳腺癌免疫治疗文摘中识别医学特征的能力进行了比较评估。

Result: 结果显示，预训练的领域特定语言模型在识别具体、低层次医学概念时表现优异，有时可超过通用大型语言模型。

Conclusion: 预训练语言模型在识别乳腺癌免疫治疗文摘中特定医学概念方面，有潜力优于大型语言模型。

Abstract: Language models (LMs) capabilities have grown with a fast pace over the past
decade leading researchers in various disciplines, such as biomedical research,
to increasingly explore the utility of LMs in their day-to-day applications.
Domain specific language models have already been in use for biomedical natural
language processing (NLP) applications. Recently however, the interest has
grown towards medical language models and their understanding capabilities. In
this paper, we investigate the medical conceptual grounding of various language
models against expert clinicians for identification of hallmarks of
immunotherapy in breast cancer abstracts. Our results show that pre-trained
language models have potential to outperform large language models in
identifying very specific (low-level) concepts.

</details>


### [134] [Relational Schemata in BERT Are Inducible, Not Emergent: A Study of Performance vs. Competence in Language Models](https://arxiv.org/abs/2506.11485)
*Cole Gawin*

Main category: cs.CL

TL;DR: BERT预训练虽表现优异，但只有在经过关系分类微调后才表现出结构化的关系理解，表明结构性概念理解依赖于合适的任务训练，而并非仅仅源于海量文本预训练。


<details>
  <summary>Details</summary>
Motivation: 大语言模型如BERT在语义任务上表现优异，但这是否意味着其真正理解概念关系还是仅基于表层的统计关联尚不明确。本文旨在探索BERT是否编码了抽象的关系结构模式。

Method: 分析BERT对不同概念对（如分类关系、整体-部分关系和功能关系）的内部表示，比较BERT在关系分类任务上的表现以及[CLS]向量嵌入的表示结构，并考察预训练与监督微调的差异。

Result: 预训练的BERT可以实现较高的关系分类准确率，说明其内部包含一定的关系信号。但通过主成分分析等方法发现，概念对只有在经过关系分类任务微调后才会在嵌入空间中按关系类型有结构地聚类，表明关系结构并非仅靠预训练自然形成。

Conclusion: 行为上的高分类准确率并不代表BERT具有结构化的概念理解，但通过恰当的监督训练，模型能够获得对关系抽象的归纳偏置和结构化的表征。

Abstract: While large language models like BERT demonstrate strong empirical
performance on semantic tasks, whether this reflects true conceptual competence
or surface-level statistical association remains unclear. I investigate whether
BERT encodes abstract relational schemata by examining internal representations
of concept pairs across taxonomic, mereological, and functional relations. I
compare BERT's relational classification performance with representational
structure in [CLS] token embeddings. Results reveal that pretrained BERT
enables high classification accuracy, indicating latent relational signals.
However, concept pairs organize by relation type in high-dimensional embedding
space only after fine-tuning on supervised relation classification tasks. This
indicates relational schemata are not emergent from pretraining alone but can
be induced via task scaffolding. These findings demonstrate that behavioral
performance does not necessarily imply structured conceptual understanding,
though models can acquire inductive biases for grounded relational abstraction
through appropriate training.

</details>


### [135] [Lag-Relative Sparse Attention In Long Context Training](https://arxiv.org/abs/2506.11498)
*Manlai Liang,Wanyi Huang,Mandi Liu,Huaijun Li,Jinlong Li*

Main category: cs.CL

TL;DR: 本文提出了Lag-Relative Sparse Attention（LRSA）及LagKV压缩法，在长文本推理阶段高效压缩key-value缓存，显著提升了大模型压缩后的性能与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）在处理长上下文输入时，因注意力机制计算复杂度高及存储需求线性增加，导致计算和内存消耗巨大。虽然有压缩key-value缓存的方法能降低消耗，但在模型未对压缩上下文进行训练时会造成性能严重下降，目前更复杂的压缩方法因与优化方法不兼容或消耗过高，不适于推理后应用。

Method: 提出了Lag-Relative Sparse Attention（LRSA）机制，基于LagKV压缩方法，通过分块prefilling，选择固定大小滞后窗口中最相关的K个key-value对，大幅度提高长上下文后训练阶段的效率且无需增加新参数。

Result: 实验表明，该方法在key-value压缩后显著提升了LLM的鲁棒性，并在问答微调任务中获得了更好的效果。

Conclusion: LRSA方法有效解决了长上下文场景下key-value压缩造成性能下降的问题，同时兼顾了模型效率和效果。无需额外参数和较小计算开销，适合后训练场景。

Abstract: Large Language Models (LLMs) have made significant strides in natural
language processing and generation, yet their ability to handle long-context
input remains constrained by the quadratic complexity of attention computation
and linear-increasing key-value memory footprint. To reduce computational costs
and memory, key-value cache compression techniques are commonly applied at
inference time, but this often leads to severe performance degradation, as
models are not trained to handle compressed context. Although there are more
sophisticated compression methods, they are typically unsuitable for
post-training because of their incompatibility with gradient-based optimization
or high computation overhead. To fill this gap with no additional parameter and
little computation overhead, we propose Lag-Relative Sparse Attention(LRSA)
anchored by the LagKV compression method for long context post-training. Our
method performs chunk-by-chunk prefilling, which selects the top K most
relevant key-value pairs in a fixed-size lagging window, allowing the model to
focus on salient historical context while maintaining efficiency. Experimental
results show that our approach significantly enhances the robustness of the LLM
with key-value compression and achieves better fine-tuned results in the
question-answer tuning task.

</details>


### [136] [On the Effectiveness of Integration Methods for Multimodal Dialogue Response Retrieval](https://arxiv.org/abs/2506.11499)
*Seongbo Jang,Seonghyeon Lee,Dongha Lee,Hwanjo Yu*

Main category: cs.CL

TL;DR: 本文提出多模态对话检索新任务，比较三种集成方法，发现端到端方法和参数共享策略在提升性能和减少参数量方面具有显著优势。


<details>
  <summary>Details</summary>
Motivation: 近年来多模态聊天机器人（能处理文本、图像等多种信息的对话系统）成为业界和学术界的重要课题。研究者开始关注如何让系统不仅理解多模态上下文，还能以多种形式输出回复。

Method: 本文针对基于检索的多模态对话系统，提出了结合三项子任务的多模态对话响应检索任务。设计了三种融合方法，包括两步法与端到端法，并详细比较了它们的优缺点。同时引入参数共享策略，实现知识在子任务和模态间的迁移。

Result: 端到端方法无需中间步骤也能取得与两步法相当的性能。参数共享策略既减少模型参数量，又通过知识迁移提升了模型表现。

Conclusion: 端到端多模态检索方法能简化流程且效果优良，参数共享不仅提升性能还减小模型规模，有助于多模态对话系统的优化。

Abstract: Multimodal chatbots have become one of the major topics for dialogue systems
in both research community and industry. Recently, researchers have shed light
on the multimodality of responses as well as dialogue contexts. This work
explores how a dialogue system can output responses in various modalities such
as text and image. To this end, we first formulate a multimodal dialogue
response retrieval task for retrieval-based systems as the combination of three
subtasks. We then propose three integration methods based on a two-step
approach and an end-to-end approach, and compare the merits and demerits of
each method. Experimental results on two datasets demonstrate that the
end-to-end approach achieves comparable performance without an intermediate
step in the two-step approach. In addition, a parameter sharing strategy not
only reduces the number of parameters but also boosts performance by
transferring knowledge across the subtasks and the modalities.

</details>


### [137] [From Persona to Person: Enhancing the Naturalness with Multiple Discourse Relations Graph Learning in Personalized Dialogue Generation](https://arxiv.org/abs/2506.11557)
*Chih-Hao Hsu,Ying-Jia Lin,Hung-Yu Kao*

Main category: cs.CL

TL;DR: 本文提出结合大语言模型与图结构学习，提升了个性化对话系统的回复质量和连贯性，生成的回答更加人性化。


<details>
  <summary>Details</summary>
Motivation: 在对话生成中，个性化和自然度是提升人机交互体验的关键。实现个性化回复常常面临个性特征一致性和回应连贯性的挑战。作者提出解决这些挑战的新方法。

Method: 提出了MUDI（Multiple Discourse Relations Graph Learning）方法。首先采用大语言模型进行话语关系标注，并将对话数据转化为结构化对话图。再通过自研的DialogueGAT图编码器捕捉隐含的话语关系和个性描述。在生成个性化回复阶段，加入了新的关注话语连贯性的注意力机制，用于优化解码器。

Result: 实验表明，所提出的方法能显著提升个性化回复的质量，使其更加贴近人类的对话行为。

Conclusion: 利用多重话语关系图及创新的结构建模和生成机制，能够明显提升个性化对话系统的回复自然度与人性化。

Abstract: In dialogue generation, the naturalness of responses is crucial for effective
human-machine interaction. Personalized response generation poses even greater
challenges, as the responses must remain coherent and consistent with the
user's personal traits or persona descriptions. We propose MUDI
($\textbf{Mu}$ltiple $\textbf{Di}$scourse Relations Graph Learning) for
personalized dialogue generation. We utilize a Large Language Model to assist
in annotating discourse relations and to transform dialogue data into
structured dialogue graphs. Our graph encoder, the proposed DialogueGAT model,
then captures implicit discourse relations within this structure, along with
persona descriptions. During the personalized response generation phase, novel
coherence-aware attention strategies are implemented to enhance the decoder's
consideration of discourse relations. Our experiments demonstrate significant
improvements in the quality of personalized responses, thus resembling
human-like dialogue exchanges.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [138] [Greed is slow on sparse graphs of oriented valued constraints](https://arxiv.org/abs/2506.11662)
*Artem Kaznatcheev,Sofia Vazquez Alferez*

Main category: cs.DM

TL;DR: 本文展示了即使在结构非常简单的VCSP问题中，贪婪局部搜索依然可能非常低效。这一发现为选择局部搜索方法提供了警示：过度依赖贪婪策略可能导致极低的搜索效率，尤其在特定问题结构下。


<details>
  <summary>Details</summary>
Motivation: 贪婪局部搜索在求解赋值约束满足问题（VCSPs）中非常流行，但某些VCSP实例对于任何方法而言都会很慢。作者想要探究：对于贪婪局部搜索来说，什么是“最简单的、依然算起来很慢”的VCSP问题？

Method: 作者构造了一个包含6n个布尔变量的VCSP，这个问题非常稀疏（约束图的路径宽度为2，最大度数为3），并具有“有向性”——变量有序，后面的变量对前面的条件独立。

Result: 在这个构造的VCSP实例上，贪婪局部搜索需要7*(2^n-1)步才能找到唯一的峰值解，而许多非贪婪的局部搜索方法可以在平方步数内解决。

Conclusion: 在这些VCSP问题上，贪婪局部搜索显著慢于其他局部搜索方法。也就是说，对于某些极其简单结构的VCSP，贪婪策略表现出特别低效。

Abstract: Greedy local search is especially popular for solving valued constraint
satisfaction problems (VCSPs). Since any method will be slow for some VCSPs, we
ask: what is the simplest VCSP on which greedy local search is slow? We
construct a VCSP on 6n Boolean variables for which greedy local search takes
7(2^n - 1) steps to find the unique peak. Our VCSP is simple in two ways.
First, it is very sparse: its constraint graph has pathwidth 2 and maximum
degree 3. This is the simplest VCSP on which some local search could be slow.
Second, it is "oriented" - there is an ordering on the variables such that
later variables are conditionally-independent of earlier ones. Being oriented
allows many non-greedy local search methods to find the unique peak in a
quadratic number of steps. Thus, we conclude that - among local search methods
- greed is particularly slow.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [139] [Reversible Pebble Transducers](https://arxiv.org/abs/2506.11334)
*Luc Dartois,Paul Gastin,L. Germerie Guizouarn,Shankaranarayanan Krishna*

Main category: cs.FL

TL;DR: 本文提出了可逆卵石换位器，解决了传统换位器组合时的高复杂度问题，并提出了相应的高效正规化与组合方法，大大提高了处理多正则函数的实际可用性。


<details>
  <summary>Details</summary>
Motivation: 动机在于解决传统（多）正则函数实现过程中，换位器通过组合带来的输入规模双指数级爆炸问题，尤其是现有卵石换位器合成复杂度分析和降低合成复杂度的需求。

Method: 作者引入了可逆卵石换位器，并设计了将非确定性卵石换位器正规化为可逆形式的高效算法，以及可逆卵石换位器的高效组合方法。

Result: 文章取得的主要成果是提出可逆卵石换位器，并实现了其高效合成和正规化技术，从而大幅提高了合成效率。

Conclusion: 文章提出了可逆卵石换位器（reversible pebble transducers）的概念，并展示了有效的正规化及高效的合成技术，克服了传统确定性双向换位器组合时输入大小会出现双指数爆炸的问题。

Abstract: Deterministic two-way transducers with pebbles (aka pebble transducers)
capture the class of polyregular functions, which extend the string-to-string
regular functions allowing polynomial growth instead of linear growth. One of
the most fundamental operations on functions is composition, and (poly)regular
functions can be realized as a composition of several simpler functions. In
general, composition of deterministic two-way transducers incur a doubly
exponential blow-up in the size of the inputs. A major improvement in this
direction comes from the fundamental result of Dartois et al. [10] showing a
polynomial construction for the composition of reversible two-way transducers.
A precise complexity analysis for existing composition techniques of pebble
transducers is missing. But they rely on the classic composition of two-way
transducers and inherit the double exponential complexity. To overcome this
problem, we introduce reversible pebble transducers. Our main results are
efficient uniformization techniques for non-deterministic pebble transducers to
reversible ones and efficient composition for reversible pebble transducers.

</details>
