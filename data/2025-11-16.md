<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 5]
- [cs.SE](#cs.SE) [Total: 6]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.CL](#cs.CL) [Total: 64]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Cyclotron: Compilation of Recurrences to Distributed and Systolic Architectures](https://arxiv.org/abs/2511.09987)
*Shiv Sundram,Akhilesh Balasingam,Nathan Zhang,Kunle Olukotun,Fredrik Kjolstad*

Main category: cs.PL

TL;DR: Cyclotron是面向分布式流数据算法的递归方程编译框架，实现算法在多硬件上的高效、可移植运行，并可生成与行业领先库性能相当的分布式实现。


<details>
  <summary>Details</summary>
Motivation: 现有分布式流数据处理算法缺乏统一、可移植的表达及编译方式，内存访问效率低，难以高效适配硬件多样性。作者希望通过递归方程统一表示与编译优化，提升算法表达能力和硬件适配能力。

Method: 提出了Cyclotron框架和编译器，通过递归方程描述算法，并提供多层中间表示（IR）；通过调度语言控制数据流和并行执行；针对不同硬件环境实现优化和生成目标代码。

Result: Cyclotron在重构仿真系统和分布式CPU集群上均可实现算法高效编译与运行，支持多种矩阵乘法和求解器等分布式算法，并可达到行业主流库的性能水平。

Conclusion: Cyclotron可以高效地将递归方程表示的流数据算法编译为分布式处理拓扑，实现了在多种硬件环境下的高效、可移植执行，并能生成性能与业界主流库（如ScaLAPACK）相当的分布式实现。

Abstract: We present Cyclotron, a framework and compiler for using recurrence equations to express streaming dataflow algorithms, which then get portably compiled to distributed topologies of interlinked processors. Our framework provides an input language of recurrences over logical tensors, which then gets lowered into an intermediate language of recurrences over logical iteration spaces, and finally into programs of send, receive, and computation operations specific to each individual processor. In Cyclotron's IR, programs are optimized such that external memory interactions are confined to the boundaries of the iteration space. Within inner iteration spaces, all data accesses become local: data accesses target values residing in local fast memory or on neighboring processing units, avoiding costly memory movement. We provide a scheduling language allowing users to define how data gets streamed and broadcasted between processors, enabling pipelined execution of computation kernels over distributed topologies of processing elements. We demonstrate the portability of our approach by compiling our IR to a reconfigurable simulator of systolic arrays and chiplet style distributed hardware, as well as to distributed-memory CPU clusters. In the simulated reconfigurable setting, we use our compiler for hardware design space exploration in which link costs and latencies can be specified. In the distributed CPU setting, we show how to use recurrences and our scheduling language to express various matrix multiplication routines (Cannon, SUMMA, PUMMA, weight stationary) and solvers (Triangular solve and Cholesky). For matrix multiplication and the triangular solve, we generate distributed implementations competitive with ScaLAPACK.

</details>


### [2] [Omnidirectional type inference for ML: principality any way](https://arxiv.org/abs/2511.10343)
*Alistair O'Brien,Didier Rémy,Gabriel Scherer*

Main category: cs.PL

TL;DR: 现有ML扩展会导致类型推断的不确定性和表达力下降，论文通过动态解决约束和增量实例化，提出了一个能恢复主类型且更灵活、更强大的类型推断方法，并在OCaml上实际验证，得到比原类型检查器更优的表现。


<details>
  <summary>Details</summary>
Motivation: ML类型系统因其“主类型”特性而在类型推断时高效且可预测，但现代许多扩展如GADT、高阶多态和静态重载会破坏这种主类型，让类型推断变得脆弱。现有算法通常通过固定顺序传播类型信息，但因顺序刚性，容易拒绝原本合法的程序。该论文希望解决这一瓶颈，让类型推断更加灵活和强大。

Method: 论文提出了“全向类型推断”（omnidirectional type inference），允许类型信息动态流动。约束可以任意顺序解决，遇到依赖关系可以暂停并在信息补充后再继续。针对ML系统中的let-泛化问题，作者引入了“增量实例化”，可对含暂停约束的部分类型方案进行实例化，并在类型完善过程中逐步更新实例。

Result: 该方法能更充分地恢复主类型性质。论文在OCaml的两种重要特性（静态重载和半显式一类多态）上进行了验证，得到比当前OCaml类型检查器更具表达力的推断算法，且结果保证主类型。

Conclusion: 论文提出的全向类型推断框架为包含脆弱特性的ML扩展提供了恢复主类型的通用方案，使类型推断更灵活且表达能力更强，有望推动现代类型系统发展。

Abstract: The Damas-Hindley-Milner (ML) type system owes its success to principality, the property that every well-typed expression has a unique most general type. This makes inference predictable and efficient. Unfortunately, many extensions of ML (GADTs, higher-rank polymorphism, and static overloading) endanger princpality by introducing _fragile_ constructs that resist principal inference. Existing approaches recover principality through directional inference algorithms, which propagate _known_ type information in a fixed (or static) order (e.g. as in bidirectional typing) to disambiguate such constructs. However, the rigidity of a static inference order often causes otherwise well-typed programs to be rejected.
  We propose _omnidirectional_ type inference, where type information flows in a dynamic order. Typing constraints may be solved in any order, suspending when progress requires known type information and resuming once it becomes available, using _suspended match constraints_. This approach is straightforward for simply typed systems, but extending it to ML is challenging due to let-generalization. Existing ML inference algorithms type let-bindings (let x = e1 in e2) in a fixed order: type e1, generalize its type, and then type e2. To overcome this, we introduce _incremental instantiation_, allowing partially solved type schemes containing suspended constraints to be instantiated, with a mechanism to incrementally update instances as the scheme is refined.
  Omnidirectionality provides a general framework for restoring principality in the presence of fragile features. We demonstrate its versatility on two fundamentally different features of OCaml: static overloading of record labels and datatype constructors and semi-explicit first-class polymorphism. In both cases, we obtain a principal type inference algorithm that is more expressive than OCaml's current typechecker.

</details>


### [3] [Lazy Linearity for a Core Functional Language](https://arxiv.org/abs/2511.10361)
*Rodrigo Mesquita,Bernardo Toninho*

Main category: cs.PL

TL;DR: 该论文提出了针对惰性语言的Linear Core系统，实现了资源线性的语义静态检查，并证明其在Haskell编译器优化过程中比传统方法更能保持线性安全，其插件在真实代码库中取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 在非严格求值（如Haskell）中，源代码中的线性资源出现不一定意味着实际运行时会消耗该资源，但现有线性类型系统主要关注语法层面。这种差异在Haskell优化编译器中尤为明显，因为编译器的重写可能打破语法层面的线性性，而语义保持不变。

Method: 提出了Linear Core系统，将线性资源的语义理解引入类型系统，适用于惰性（lazy）函数式语言的中间语言，如Glasgow Haskell Compiler的Core。同时，证明了Linear Core的正确性，并测试了其在编译优化过程中对线性的保持。还开发了一个编译器插件，对实际线性库进行了实验验证。

Result: Linear Core系统能够保证线性资源的正确使用，且多个优化变换在Linear Core中能够保持线性性，但在传统Core语言下不能。插件实现通过对诸如linear-base这类依赖线性的库的实验验证了系统的有效性。

Conclusion: Linear Core系统有效地将线性资源的语义线性性安全地引入到惰性语言，并在编译器优化阶段保持该属性，显示出超越现有方法的优势。

Abstract: Traditionally, in linearly typed languages, consuming a linear resource is synonymous with its syntactic occurrence in the program. However, under the lens of non-strict evaluation, linearity can be further understood semantically, where a syntactic occurrence of a resource does not necessarily entail using that resource when the program is executed. While this distinction has been largely unexplored, it turns out to be inescapable in Haskell's optimising compiler, which heavily rewrites the source program in ways that break syntactic linearity but preserve the program's semantics. We introduce Linear Core, a novel system which accepts the lazy semantics of linearity statically and is suitable for lazy languages such as the Core intermediate language of the Glasgow Haskell Compiler. We prove that Linear Core is sound, guaranteeing linear resource usage, and that multiple optimising transformations preserve linearity in Linear Core while failing to do so in Core. We have implemented Linear Core as a compiler plugin to validate the system against linearity-heavy libraries, including linear-base.

</details>


### [4] [Modeling Layout Abstractions Using Integer Set Relations](https://arxiv.org/abs/2511.10374)
*Somashekaracharya G Bhaskaracharya,Aravind Acharya,Bastian Hagedorn,Vinod Grover*

Main category: cs.PL

TL;DR: 该论文提出利用ISL将CuTe和Triton两大tensor布局统一数学建模，支持复杂布局操作和验证，极大提升了编译器对布局的形式化分析及优化能力。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习编译器的布局系统（如CuTe和Triton）独立运行，缺乏统一的数学基础，难以进行形式化分析和跨系统优化。

Method: 提出利用整数集库（ISL）将两种主流tensor布局系统用整数集关系统一建模。具体对CuTe布局采用步幅计算和位操作的整数集关系，对Triton布局则采用二元向量空间的有限域运算。同时实现了一套完整的ISL操作算法，支持布局组合、逆运算与补运算。

Result: 该方法成功将复杂的tensor布局系统（包括多维、步幅复杂度及swizzle模式）统一建模，并且能通过算法完整地处理和验证布局变换的正确性。实验表明该建模方法能够覆盖实际布局复杂性，并有效验证跨不同布局范式的正确性。

Conclusion: 本文提出的统一建模方法填补了CuTe与Triton等主流深度学习布局系统之间的数学和分析鸿沟，为未来跨系统优化和编译器布局分析奠定了理论基础。

Abstract: Modern deep learning compilers rely on layout abstractions to manage the complex mapping between logical tensor structures and physical memory arrangements. CuTe layouts and Triton linear layouts are widely adopted industry standards. However, these layout systems operate independently with distinct mathematical underpinnings, preventing unified formal analysis and cross-system reasoning. We bridge this gap by introducing a novel approach that leverages the Integer Set Library (ISL) to create a unified mathematical representation for both layout systems through integer set relations, thereby enabling rigorous formal analysis, correctness verification, and the foundation for future cross-system optimization strategies. Our approach models CuTe layouts through integer set relations that encode the transformation from multi-dimensional coordinates to linear indices using stride-based calculations, including sophisticated swizzle operations that perform bit-level manipulations for enhanced memory access patterns. For Triton linear layouts, we construct integer set relations that model the binary vector space transformations where arithmetic operations follow finite field F_2 rules. We implement a complete suite of layout manipulation algorithms for composition, inversion, complement using built-in operations in ISL to ensure mathematical correctness and preserve layout semantics. Experimental evaluation shows that the system handles the full spectrum of layout complexity, from elementary identity transformations to sophisticated multi-dimensional tensor arrangements with complex stride configurations and swizzle patterns, validating the mathematical modeling approach across different layout paradigms.

</details>


### [5] [zkStruDul: Programming zkSNARKs with Structural Duality](https://arxiv.org/abs/2511.10565)
*Rahul Krishnan,Ashley Samuelson,Emily Yao,Ethan Cecchetti*

Main category: cs.PL

TL;DR: 本文发布zkStruDul语言，可统一NIZK输入转换与谓词验证，提升安全性与开发效率，支持递归证明，验证了语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有NIZK工具将谓词定义和输入转换分开实现，导致重复逻辑和潜在安全缺陷，实际开发中难以维护一致性。

Method: 设计了高层抽象语言zkStruDul，将输入处理与谓词验证合并，并通过编译器自动生成过程；对该语言提供了源级语义，并严格证明了其投影语义的等价性。

Result: zkStruDul成功消除了重复代码，提高了安全性，并支持递归证明，能够直接叠加到现有NIZK技术之上。

Conclusion: 本文提出了一种新的语言zkStruDul，它将输入转换与谓词定义统一到一个抽象中，消除了重复逻辑与安全隐患。

Abstract: Non-Interactive Zero Knowledge (NIZK) proofs, such as zkSNARKS, let one prove knowledge of private data without revealing it or interacting with a verifier. While existing tooling focuses on specifying the predicate to be proven, real-world applications optimize predicate definitions to minimize proof generation overhead, but must correspondingly transform predicate inputs. Implementing these two steps separately duplicates logic that must precisely match to avoid catastrophic security flaws. We address this shortcoming with zkStruDul, a language that unifies input transformations and predicate definitions into a single combined abstraction from which a compiler can project both procedures, eliminating duplicate code and problematic mismatches. zkStruDul provides a high-level abstraction to layer on top of existing NIZK technology and supports important features like recursive proofs. We provide a source-level semantics and prove its behavior is identical to the projected semantics, allowing straightforward standard reasoning.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [6] [Evaluating Software Process Models for Multi-Agent Class-Level Code Generation](https://arxiv.org/abs/2511.09794)
*Wasique Islam Shafin,Md Nakhla Rafi,Zhenhao Li,Tse-Hsun Chen*

Main category: cs.SE

TL;DR: 多智能体LLM通过瀑布式开发流程生成代码更清晰、易维护，但功能正确性不稳定，有显著质量权衡，测试阶段影响最大。流程结构深刻影响模型协作与失败类型，值得关注实际工业应用中的合理流程设计。


<details>
  <summary>Details</summary>
Motivation: 随着自动化软件开发需求增加，尤其是可维护性和结构良好的代码，研究多智能体大语言模型（LLM）在更复杂代码生成（如类级别）流程中的表现，探索现实开发流程对自动生成代码质量和模型协作的影响。

Method: 将三种主流LLM（GPT-4o-mini，DeepSeek-Chat和Claude-3.5-Haiku）构成多智能体系统，采用瀑布式开发流程模拟需求、设计、实现和测试环节，在ClassEval基准任务（100个Python类任务）下对比分析单智能体和多智能体协作的代码生成结果。

Result: 瀑布式协作流程生成的代码更清晰、可维护，但功能正确率整体降低（GPT-4o-mini下降37.8%，DeepSeek-Chat下降39.8%，但Claude-3.5-Haiku提升9.5%）。流程约束下，结构性错误减少，但语义和验证错误增加。测试阶段对结果影响最大，既提高验证覆盖率，又带来新的推理失败，需求和设计阶段影响较小。

Conclusion: 多智能体LLM开发流程重塑了模型协作和失败模式，与更灵活的单智能体方法相比，瀑布式开发带来质量取舍：提高代码清晰度和可维护性，牺牲部分功能正确率。本研究揭示了流程纪律与灵活问题解决之间的本质权衡。

Abstract: Modern software systems require code that is not only functional but also maintainable and well-structured. Although Large Language Models (LLMs) are increasingly used to automate software development, most studies focus on isolated, single-agent function-level generation. This work examines how process structure and role specialization shape multi-agent LLM workflows for class-level code generation. We simulate a Waterfall-style development cycle covering Requirement, Design, Implementation, and Testing using three LLMs (GPT-4o-mini, DeepSeek-Chat, and Claude-3.5-Haiku) on 100 Python tasks from the ClassEval benchmark. Our findings show that multi-agent workflows reorganize, rather than consistently enhance, model performance. Waterfall-style collaboration produces cleaner and more maintainable code but often reduces functional correctness (-37.8\% for GPT-4o-mini and -39.8\% for DeepSeek-Chat), with Claude-3.5-Haiku as a notable exception (+9.5\%). Importantly, process constraints shift failure characteristics: structural issues such as missing code decrease, while semantic and validation errors become more frequent. Among all stages, Testing exerts the strongest influence by improving verification coverage but also introducing new reasoning failures, whereas Requirement and Design have comparatively modest effects. Overall, this study provides empirical evidence that software process structure fundamentally alters how LLMs reason, collaborate, and fail, revealing inherent trade-offs between rigid workflow discipline and flexible problem-solving in multi-agent code generation.

</details>


### [7] [EnvTrace: Simulation-Based Semantic Evaluation of LLM Code via Execution Trace Alignment -- Demonstrated at Synchrotron Beamlines](https://arxiv.org/abs/2511.09964)
*Noah van der Vleuten,Anthony Flores,Shray Mathur,Max Rakitin,Thomas Hopkins,Kevin G. Yager,Esther H. R. Tsai*

Main category: cs.SE

TL;DR: 本文提出了用仿真轨迹对大模型控制能力进行评测的新方法EnvTrace，并首次展示大量大模型已能接近人类水平生成仪器控制代码，为大模型与数字孪生联合推动自主智能控制迈出关键一步。


<details>
  <summary>Details</summary>
Motivation: 现有对大模型的算法评测多为无状态的标准测试，无法完全反映物理设备控制的复杂性，需要一种新的方法全面评估控制逻辑的准确性和有效性。

Method: 提出并使用EnvTrace方法：通过仿真环境下的执行轨迹来评估语义代码等价性，并结合“数字孪生”模拟物理系统，支持更贴近实际的三方评测和验证。

Result: 使用EnvTrace与数字孪生对30余种大模型进行了表现评测，结果显示许多顶级模型在快速生成控制代码方面已接近人类水平。

Conclusion: EnvTrace和数字孪生联合评测模式证明可行，为未来LLM与数字孪生结合，实现类人智能控制和自治AI奠定了基础。

Abstract: Evaluating large language models (LLMs) for instrument control requires methods that go beyond standard, stateless algorithmic benchmarks, since the behavior of physical systems cannot be fully captured by unit tests alone. Here we introduce EnvTrace, a simulation-based method that evaluates execution traces to assess semantic code equivalence. EnvTrace is demonstrated with a beamline control-logic digital twin to facilitate the evaluation of instrument control code, with the digital twin itself also enabling the pre-execution validation of live experiments. Over 30 LLMs were evaluated using trace alignment to generate a multi-faceted score for functional correctness across key behavioral dimensions, showing that many top-tier models can approach human-level performance in rapid control-code generation. This is a first step toward a broader vision where LLMs and digital twins work symbiotically: LLMs providing intuitive control and agentic orchestration, and digital twins offering safe and high-fidelity environments, paving the way towards autonomous embodied AI.

</details>


### [8] [Continuous Benchmark Generation for Evaluating Enterprise-scale LLM Agents](https://arxiv.org/abs/2511.10049)
*Divyanshu Saxena,Rishikesh Maurya,Xiaoxuan Ou,Gagan Somashekar,Shachee Mishra Gupta,Arun Iyer,Yu Kang,Chetan Bansal,Aditya Akella,Saravan Rajmohan*

Main category: cs.SE

TL;DR: 传统评估方式难以应对企业级AI代理的动态需求，本文提出利用开发者意图和LLM自动生成基准的新流程，不仅提升了评估灵活性和持续性，还促进了系统改进、适应现实业务场景。


<details>
  <summary>Details</summary>
Motivation: 目前AI代理广泛应用于各领域，但现有基准评测方法在企业级规模环境下由于服务与需求不断演化且缺乏充足的真实标签样本，已无法满足系统性评估需求。

Method: 提出一种基准自动生成流程，通过收集开发者在半结构化文档中表达的高层意图，然后利用先进的LLM模型，仅凭少量数据即可自动生成适应动态需求变化的基准，实现精准和持续的评估。

Result: 此流程已在大型企业的服务迁移案例中落地验证，能够随需求变化及时生成新基准、持续评估AI代理表现，有效提升系统反馈速度并推动有针对性的性能改进。

Conclusion: 本文的方法为企业级AI代理评估提供了可维护、动态适应的框架，帮助持续优化AI系统性能，满足高复杂度和变化频繁实际需求。

Abstract: The rapid adoption of AI agents across domains has made systematic evaluation crucial for ensuring their usefulness and successful production deployment. Evaluation of AI agents typically involves using a fixed set of benchmarks and computing multiple evaluation metrics for the agent. While sufficient for simple coding tasks, these benchmarks fall short for enterprise-scale agents, where services and requirements evolve continuously and ground-truth examples are sparse. We propose a process of benchmark generation that helps evolve the benchmarks as the requirements change and perform robust evaluation of evolving AI agents. We instantiate this approach for a case study of service migration from one deployment platform to another at a large public enterprise. Our approach relies on semi-structured documents where developers express the high-level intent, and uses state-of-the-art LLMs to generate benchmarks from just a small number of such documents. Overall, this process results in a maintainable evaluation framework, enabling rapid feedback on agent performance and facilitating targeted improvements.

</details>


### [9] [Quality Assurance of LLM-generated Code: Addressing Non-Functional Quality Characteristics](https://arxiv.org/abs/2511.10271)
*Xin Sun,Daniel Ståhl,Kristian Sandahl,Christoph Kessler*

Main category: cs.SE

TL;DR: 学术界关注LLM代码安全性与性能，业界更重视可维护性；三者关注点及模型性能存在错位，需让LLM代码生成关注综合质量，而非仅功能正确。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM能生成功能上正确的代码，但关于其非功能性质量（如安全性、可维护性、性能效率等）缺乏系统理解与评估。现有研究多关注代码是否能通过测试，而对代码质量关心不足。

Method: 本研究采用三种方法：对108篇相关文献进行系统性回顾、组织两个产业研讨会收集业界观点，以及对三个主流LLM模型修复真实软件问题的代码补丁开展实证分析（主要评估安全性、可维护性和性能效率）。

Result: 学术界主要关注安全性和性能效率，可维护性等特征被忽视；业界则更看重可维护性和可读性，担心LLM生成的代码加剧技术债务。实证发现，提升某一质量往往以牺牲其他质量为代价，不同模型与优化策略下运行时和内存表现差异明显。

Conclusion: 目前对于LLM生成代码的非功能性质量关注不足，学术界、业界关注点以及模型表现间存在显著不匹配。亟需将质量保障机制融入LLM代码生成流程，确保代码不仅能通过测试，还具备高质量。

Abstract: In recent years, LLMs have been widely integrated into software engineering workflows, supporting tasks like code generation. However, while these models often generate functionally correct outputs, we still lack a systematic understanding and evaluation of their non-functional qualities. Existing studies focus mainly on whether generated code passes the tests rather than whether it passes with quality. Guided by the ISO/IEC 25010 quality model, this study conducted three complementary investigations: a systematic review of 108 papers, two industry workshops with practitioners from multiple organizations, and an empirical analysis of patching real-world software issues using three LLMs. Motivated by insights from both the literature and practitioners, the empirical study examined the quality of generated patches on security, maintainability, and performance efficiency. Across the literature, we found that security and performance efficiency dominate academic attention, while maintainability and other qualities are understudied. In contrast, industry experts prioritize maintainability and readability, warning that generated code may accelerate the accumulation of technical debt. In our evaluation of functionally correct patches generated by three LLMs, improvements in one quality dimension often come at the cost of others. Runtime and memory results further show high variance across models and optimization strategies. Overall, our findings reveal a mismatch between academic focus, industry priorities, and model performance, highlighting the urgent need to integrate quality assurance mechanisms into LLM code generation pipelines to ensure that future generated code not only passes tests but truly passes with quality.

</details>


### [10] [A Large-Scale Collection Of (Non-)Actionable Static Code Analysis Reports](https://arxiv.org/abs/2511.10323)
*Dávid Kószó,Tamás Aladics,Rudolf Ferenc,Péter Hegedűs*

Main category: cs.SE

TL;DR: 为解决 Java 静态代码分析警告过多且数据集稀缺问题，作者提出了一种新方法并构建了百万级 NASCAR 数据集，对提升 SCA 工具有效性及相关研究具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 现有静态代码分析工具产生大量警告，其中许多不可行动，导致开发者警觉疲劳，降低效率和代码质量，同时相关机器学习研究缺乏大规模数据集，特别是针对 Java 语言。

Method: 提出并实现了一套收集与归类 SCA 工具警告的方法，能够区分可采纳与不可采纳警告，并据此生成了包含百万级数据的 NASCAR 数据集。

Result: 成功创建了一个包含 100 万以上 Java 源代码警告的大型数据集 NASCAR，并将数据及生成工具公开，推动了该领域研究的发展。

Conclusion: 论文提出了一种针对 Java 静态代码分析工具警告的大规模数据集构建方法，并公开了数据集和生成工具，有助于后续相关研究发展。

Abstract: Static Code Analysis (SCA) tools, while invaluable for identifying potential coding problems, functional bugs, or vulnerabilities, often generate an overwhelming number of warnings, many of which are non-actionable. This overload of alerts leads to ``alert fatigue'', a phenomenon where developers become desensitized to warnings, potentially overlooking critical issues and ultimately hindering productivity and code quality. Analyzing these warnings and training machine learning models to identify and filter them requires substantial datasets, which are currently scarce, particularly for Java. This scarcity impedes efforts to improve the accuracy and usability of SCA tools and mitigate the effects of alert fatigue. In this paper, we address this gap by introducing a novel methodology for collecting and categorizing SCA warnings, effectively distinguishing actionable from non-actionable ones. We further leverage this methodology to generate a large-scale dataset of over 1 million entries of Java source code warnings, named NASCAR: (Non-)Actionable Static Code Analysis Reports. To facilitate follow-up research in this domain, we make both the dataset and the tools used to generate it publicly available.

</details>


### [11] [Towards Comprehensive Sampling of SMT Solutions](https://arxiv.org/abs/2511.10326)
*Shuangyu Lyu,Chuan Luo,Ruizhi Shi,Wei Wu,Chanjuan Liu,Chunming Hu*

Main category: cs.SE

TL;DR: 本文提出PanSampler采样器，在比特向量、数组和未解释函数理论的SMT公式采样中，实现高覆盖率同时样本数量减少。方法包括多样性感知采样、AST评分和后采样优化。实验证明，该方法能更高效发现故障，大幅减少测试用例数量，提高测试效率。


<details>
  <summary>Details</summary>
Motivation: 现有SMT采样方法在生成高覆盖率解时往往需要大量解，导致测试时间和资源消耗增加，影响效率。为了在有限样本数量下实现高覆盖率，从而更高效地发现故障和安全问题，提出了新的采样需求。

Method: 提出了PanSampler，一种多样性感知的SMT采样器，针对比特向量、数组和未解释函数等理论。核心方法包括：1）多样性感知算法，2）通过抽象语法树（AST）引导的评分函数，3）采样后优化技术。PanSampler通过迭代采样、候选评估及局部搜索优化，实现高覆盖率且样本数量少。

Result: 实验表明，PanSampler在实际基准测试中，能够以更少的解达到更高的目标覆盖率。实证评估显示，PanSampler在真实软件系统采样中，故障检测能力更强，达到同等故障检测效果时所需测试用例数量减少了32.6%至76.4%。

Conclusion: PanSampler提升了SMT采样效率，有助于提升软件测试和硬件验证的能力，降低测试与验证的成本，并推动SMT采样技术发展。

Abstract: This work focuses on effectively generating diverse solutions for satisfiability modulo theories (SMT) formulas, targeting the theories of bit-vectors, arrays, and uninterpreted functions, which is a critical task in software and hardware testing. Generating diverse SMT solutions helps uncover faults and detect safety violations during the verification and testing process, resulting in the SMT sampling problem, i.e., constructing a small number of solutions while achieving comprehensive coverage of the constraint space. While high coverage is crucial for exploring system behaviors, reducing the number of solutions is of great importance, as excessive solutions increase testing time and resource usage, undermining efficiency. In this work, we introduce PanSampler, a novel SMT sampler that achieves high coverage with a small number of solutions. It incorporates three novel techniques, i.e., diversity-aware SMT algorithm, abstract syntax tree (AST)-guided scoring function and post-sampling optimization technology, enhancing its practical performance. It iteratively samples solutions, evaluates candidates, and employs local search to refine solutions, ensuring high coverage with a small number of samples. Extensive experiments on practical benchmarks demonstrate that PanSampler exhibits a significantly stronger capability to reach high target coverage, while requiring fewer solutions than current samplers to achieve the same coverage level. Furthermore, our empirical evaluation on practical subjects, which are collected from real-world software systems, shows that PanSampler achieves higher fault detection capability and reduces the number of required test cases from 32.6\% to 76.4\% to reach the same fault detection effectiveness, leading to a substantial improvement in testing efficiency. PanSampler advances SMT sampling, reducing the cost of software testing and hardware verification.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [12] [Contextual Refinement of Higher-Order Concurrent Probabilistic Programs](https://arxiv.org/abs/2511.10135)
*Kwing Hei Li,Alejandro Aguirre,Joseph Tassarotti,Lars Birkedal*

Main category: cs.LO

TL;DR: Foxtrot 逻辑首次解决了高阶并发概率程序的证明难题，兼具强大并发与概率推理能力，并已通过机械化展现其实用性。


<details>
  <summary>Details</summary>
Motivation: 现有的分离逻辑尚无法证明高阶、并发、概率性程序的上下文细化，尤其这些程序可能具有高阶的本地状态，且概率性和并发性带来证明上的重大挑战。需要一种能够处理这些复杂性的新的逻辑体系。

Method: 提出Foxtrot：一种高阶分离逻辑，通过融合传统并发分离逻辑原则（如不变式和幽灵资源）与先进的概率推理原则（如带样条的预采样和误差放大的归纳），实现对高阶并发概率程序及其本地状态的形式化验证。该逻辑依赖Iris逻辑中的选择公理变体，并在Rocq证明助理与Iris分离逻辑框架中进行了机械化。

Result: Foxtrot 能够表达并证明多种具有挑战性的真实案例，包括对抗性的 von Neumann 抛硬币和 Sodium 加密库中的 randombytes_uniform 函数。所有结论已在 Rocq 和 Iris 框架下完成机械化证明，验证了方法的有效性和通用性。

Conclusion: Foxtrot 是首个可用于证明高阶并发概率程序上下文细化的高阶分离逻辑，在传统分离逻辑的基础上突破并扩展了推理能力，其机械化实现为进一步应用于密码学和复杂概率系统奠定基础。

Abstract: We present Foxtrot, the first higher-order separation logic for proving contextual refinement of higher-order concurrent probabilistic programs with higher-order local state. From a high level, Foxtrot inherits various concurrency reasoning principles from standard concurrent separation logic, e.g. invariants and ghost resources, and supports advanced probabilistic reasoning principles for reasoning about complex probability distributions induced by concurrent threads, e.g. tape presampling and induction by error amplification. The integration of these strong reasoning principles is highly non-trivial due to the combination of probability and concurrency in the language and the complexity of the Foxtrot model; the soundness of the logic relies on a version of the axiom of choice within the Iris logic, which is not used in earlier work on Iris-based logics. We demonstrate the expressiveness of Foxtrot on a wide range of examples, including the adversarial von Neumann coin and the $\mathsf{randombytes\_uniform}$ function of the Sodium cryptography software library.
  All results have been mechanized in the Rocq proof assistant and the Iris separation logic framework.

</details>


### [13] [Quantum modal logic](https://arxiv.org/abs/2511.10188)
*Kenji Tokuo*

Main category: cs.LO

TL;DR: 本文构建了基于量子逻辑的模态逻辑的基础理论，包括语义和演算体系，证明了其完备与可靠性，为量子模态逻辑的进一步发展奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 量子逻辑本身的语义不同于经典逻辑，因此需要发展适用于量子逻辑的模态逻辑以作为后续量子相关模态逻辑的基础。

Method: 采用关系语义与序列演算的方法，构建并形式化了模态逻辑，并证明了相关的理论性质。

Result: 建立了基于量子逻辑的模态逻辑的最简单形式的关系语义和演算体系，并证明了其完备性和可靠性。为量子真值逻辑、量子时态逻辑等相关逻辑的进一步研究提供了理论基础。

Conclusion: 论文提出了一种基于量子逻辑的模态逻辑的形式化方法，并证明了其关系语义和序列演算之间的完备性与可靠性。

Abstract: A modal logic based on quantum logic is formalized in its simplest possible form. Specifically, a relational semantics and a sequent calculus are provided, and the soundness and the completeness theorems connecting both notions are demonstrated. This framework is intended to serve as a basis for formalizing various modal logics over quantum logic, such as quantum alethic logic, quantum temporal logic, quantum epistemic logic, and quantum dynamic logic.

</details>


### [14] [Certified Branch-and-Bound MaxSAT Solving (Extended Version)](https://arxiv.org/abs/2511.10273)
*Dieter Vandesande,Jordi Coll,Bart Bogaerts*

Main category: cs.LO

TL;DR: 论文首次将SAT领域的证明日志技术扩展到MaxSAT，通过改造MaxCDCL实现了可行的证明日志，便利结果认证，但证明检查仍具有挑战性。


<details>
  <summary>Details</summary>
Motivation: 随着组合求解器性能提升，其在实际应用中的正确性变得尤为关键。然而，复杂的实现易受bug影响。SAT领域通过证明日志解决了正确性问题，但MaxSAT长期没有突破。

Method: 本论文提出对先进的MaxSAT分支定界算法进行证明日志，包括认证Look-ahead方法及MDD编码的伪布尔约束。所有方法集成在主流求解器MaxCDCL中。

Result: 实验证明：在MaxCDCL实现证明日志只带来有限性能开销，但证明检查过程依然困难。

Conclusion: 现有分支定界MaxSAT技术可以实现有效的证明日志，提升结果的可信度，但后处理（检查）还需进一步优化。

Abstract: Over the past few decades, combinatorial solvers have seen remarkable performance improvements, enabling their practical use in real-world applications. In some of these applications, ensuring the correctness of the solver's output is critical. However, the complexity of modern solvers makes them susceptible to bugs in their source code. In the domain of satisfiability checking (SAT), this issue has been addressed through proof logging, where the solver generates a formal proof of the correctness of its answer. For more expressive problems like MaxSAT, the optimization variant of SAT, proof logging had not seen a comparable breakthrough until recently.
  In this paper, we show how to achieve proof logging for state-of-the-art techniques in Branch-and-Bound MaxSAT solving. This includes certifying look-ahead methods used in such algorithms as well as advanced clausal encodings of pseudo-Boolean constraints based on so-called Multi-Valued Decision Diagrams (MDDs). We implement these ideas in MaxCDCL, the dominant branch-and-bound solver, and experimentally demonstrate that proof logging is feasible with limited overhead, while proof checking remains a challenge.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [15] [Omnilingual ASR: Open-Source Multilingual Speech Recognition for 1600+ Languages](https://arxiv.org/abs/2511.09690)
*Omnilingual ASR team,Gil Keren,Artyom Kozhevnikov,Yen Meng,Christophe Ropers,Matthew Setzler,Skyler Wang,Ife Adebara,Michael Auli,Can Balioglu,Kevin Chan,Chierh Cheng,Joe Chuang,Caley Droof,Mark Duppenthaler,Paul-Ambroise Duquenne,Alexander Erben,Cynthia Gao,Gabriel Mejia Gonzalez,Kehan Lyu,Sagar Miglani,Vineel Pratap,Kaushik Ram Sadagopan,Safiyyah Saleem,Arina Turkatenko,Albert Ventayol-Boada,Zheng-Xin Yong,Yu-An Chung,Jean Maillard,Rashel Moritz,Alexandre Mourachko,Mary Williamson,Shireen Yates*

Main category: cs.CL

TL;DR: Omnilingual ASR通过创新架构和大规模自监督训练，将自动语音识别扩展到1,600多种语言，包括众多此前未支持的低资源语种，实现显著性能提升并开源工具，促进全球语言技术公平发展。


<details>
  <summary>Details</summary>
Motivation: 目前自动语音识别（ASR）主要支持资源丰富的语言，但世界上超过7,000种语言中的绝大多数并未被覆盖。扩展ASR到更多语言既耗时费力，又受现有架构限制且伴有伦理问题，尤其缺乏社区参与。

Method: 提出Omnilingual ASR，一个面向可扩展性的多语种大规模ASR系统。通过自监督预训练（扩展到70亿参数）获取强健语音表征，采用编码器-解码器架构并引入类LLM解码器，实现零样本泛化能力。结合公共资源和社区合作数据，覆盖1,600多种语言。

Result: Omnilingual ASR成为迄今为止覆盖语种最多的ASR系统，超过500种语言首次实现自动语音识别。自动评测中，系统在低资源场景下较之前方案表现出显著优势，并展现强泛化能力。

Conclusion: 通过开源模型和工具，降低了研究者和社区参与门槛，促进了更多语言的ASR发展，推动了社会影响和新的参与方式。

Abstract: Automatic speech recognition (ASR) has advanced in high-resource languages, but most of the world's 7,000+ languages remain unsupported, leaving thousands of long-tail languages behind. Expanding ASR coverage has been costly and limited by architectures that restrict language support, making extension inaccessible to most--all while entangled with ethical concerns when pursued without community collaboration. To transcend these limitations, we introduce Omnilingual ASR, the first large-scale ASR system designed for extensibility. Omnilingual ASR enables communities to introduce unserved languages with only a handful of data samples. It scales self-supervised pre-training to 7B parameters to learn robust speech representations and introduces an encoder-decoder architecture designed for zero-shot generalization, leveraging a LLM-inspired decoder. This capability is grounded in a massive and diverse training corpus; by combining breadth of coverage with linguistic variety, the model learns representations robust enough to adapt to unseen languages. Incorporating public resources with community-sourced recordings gathered through compensated local partnerships, Omnilingual ASR expands coverage to over 1,600 languages, the largest such effort to date--including over 500 never before served by ASR. Automatic evaluations show substantial gains over prior systems, especially in low-resource conditions, and strong generalization. We release Omnilingual ASR as a family of models, from 300M variants for low-power devices to 7B for maximum accuracy. We reflect on the ethical considerations shaping this design and conclude by discussing its societal impact. In particular, we highlight how open-sourcing models and tools can lower barriers for researchers and communities, inviting new forms of participation. Open-source artifacts are available at https://github.com/facebookresearch/omnilingual-asr.

</details>


### [16] [Order Matters: Rethinking Prompt Construction in In-Context Learning](https://arxiv.org/abs/2511.09700)
*Warren Li,Yiqian Wang,Zihan Wang,Jingbo Shang*

Main category: cs.CL

TL;DR: 以往研究忽视了示例顺序在ICL中的作用。本文实验证明：排序和选择对模型表现的影响相当，用开发集可确定优良顺序，提示设计需重视二者并重。


<details>
  <summary>Details</summary>
Motivation: 当前大多数关于大语言模型上下文学习（ICL）的研究普遍认为，示例的选择对模型表现的影响远大于示例的排列顺序，因此大多关注于如何选例。本文希望重新检验这一假设，探索示例顺序对性能的实际影响。

Method: 作者通过在分类与生成任务中，使用多个开源模型（参数量从0.5B到27B）及GPT-5，分别对例子的选择与排列顺序进行了受控实验。对比了不同选择和不同排序的性能方差，并研究用开发集筛选“强顺序”的有效性。

Result: 实验发现，示例顺序带来的结果波动，与更换示例本身带来的波动幅度相当。此外，利用开发集可找到表现接近最优（oracle）的排序，大幅提升性能。

Conclusion: 示例的选择与排序在提示词设计中同等重要，二者关系紧密，目前关于ICL的常规假设需要重新审视。

Abstract: In-context learning (ICL) enables large language models to perform new tasks by conditioning on a sequence of examples. Most prior work reasonably and intuitively assumes that which examples are chosen has a far greater effect on performance than how those examples are ordered, leading to a focus on example selection. We revisit this assumption and conduct a systematic comparison between the effect of selection and ordering. Through controlled experiments on both classification and generation tasks, using multiple open-source model families (0.5B to 27B parameters) and GPT-5, we find that the variance in performance due to different example orderings is comparable to that from using entirely different example sets. Furthermore, we show that strong orderings can be identified using only a development set, achieving performance close to an oracle that selects the best ordering based on test labels. Our findings highlight the equal and intertwined importance of example selection and ordering in prompt design, calling for a reexamination of the assumptions held in ICL.

</details>


### [17] [Contextual morphologically-guided tokenization for Latin encoder models](https://arxiv.org/abs/2511.09709)
*Marisa Hudspeth,Patrick J. Burns,Brendan O'Connor*

Main category: cs.CL

TL;DR: 通过引入形态学知识优化分词，显著提升了拉丁语等形态复杂语言的预训练与下游任务表现，尤其在数据资源受限时，结合语言学资源可有效弥补数据不足。


<details>
  <summary>Details</summary>
Motivation: 标准分词方法过于注重信息理论目标（如高压缩率和低产生率），忽视了语言学目标（如形态结构对齐），这在高形态复杂度语言中表现出对下游性能的负面影响。本文关注拉丁语这一形态丰富但中等预训练数据资源的语言，希望通过语言学资源弥补训练资源不足。

Method: 采用形态学引导的分词方法，将语言学词典等资源结合于分词过程，并在四项下游任务上进行评估。比较形态学引导分词与标准分词方法的下游表现。

Result: 形态学引导分词在所有四项下游任务中均提升了整体性能，对于领域外文本表现提升尤为显著，表明模型在泛化能力上得到改善。

Conclusion: 语言学资源可显著提升形态复杂语言的语言建模效果，对于低资源语言来说，开发和利用语言学资源是提升预训练语言模型性能的可行途径。

Abstract: Tokenization is a critical component of language model pretraining, yet standard tokenization methods often prioritize information-theoretical goals like high compression and low fertility rather than linguistic goals like morphological alignment. In fact, they have been shown to be suboptimal for morphologically rich languages, where tokenization quality directly impacts downstream performance. In this work, we investigate morphologically-aware tokenization for Latin, a morphologically rich language that is medium-resource in terms of pretraining data, but high-resource in terms of curated lexical resources -- a distinction that is often overlooked but critical in discussions of low-resource language modeling. We find that morphologically-guided tokenization improves overall performance on four downstream tasks. Performance gains are most pronounced for out of domain texts, highlighting our models' improved generalization ability. Our findings demonstrate the utility of linguistic resources to improve language modeling for morphologically complex languages. For low-resource languages that lack large-scale pretraining data, the development and incorporation of linguistic resources can serve as a feasible alternative to improve LM performance.

</details>


### [18] [Assessing the Applicability of Natural Language Processing to Traditional Social Science Methodology: A Case Study in Identifying Strategic Signaling Patterns in Presidential Directives](https://arxiv.org/abs/2511.09738)
*C. LeMay,A. Lane,J. Seales,M. Winstead,S. Baty*

Main category: cs.CL

TL;DR: 本文通过分析总统指令文本，比较NLP和人工标注的方法，发现NLP具有辅助能力但仍需优化，验证了2023年AI工具在社会科学领域的潜力与局限。


<details>
  <summary>Details</summary>
Motivation: 探索NLP在社会科学领域，特别是大规模书面语料数据主题提取中的应用与效能。

Method: 采用NLP技术对美国总统指令文本进行主题提取，并与分析人员的标注结果进行对比分析。

Result: NLP与分析人员在文献筛选上均能发现相关文档，但结果存在不一致性，表明现有NLP工具尚需完善。

Conclusion: NLP可以辅助从大量文献中提取主题，但与人类标注结果存在分歧，需要进一步研究其有效性。

Abstract: Our research investigates how Natural Language Processing (NLP) can be used to extract main topics from a larger corpus of written data, as applied to the case of identifying signaling themes in Presidential Directives (PDs) from the Reagan through Clinton administrations. Analysts and NLP both identified relevant documents, demonstrating the potential utility of NLPs in research involving large written corpuses. However, we also identified discrepancies between NLP and human-labeled results that indicate a need for more research to assess the validity of NLP in this use case. The research was conducted in 2023, and the rapidly evolving landscape of AIML means existing tools have improved and new tools have been developed; this research displays the inherent capabilities of a potentially dated AI tool in emerging social science applications.

</details>


### [19] [How Small Can You Go? Compact Language Models for On-Device Critical Error Detection in Machine Translation](https://arxiv.org/abs/2511.09748)
*Muskaan Chopra,Lorenz Sparrenberg,Sarthak Khanna,Rafet Sifa*

Main category: cs.CL

TL;DR: 通过比较一批参数在20亿以下的小型LLM，发现1B级模型（如Gemma-3-1B）最均衡，在实际设备上延迟低表现优，同时无需大型模型就可在边缘设备上私密、低成本地做高质量翻译错误检测。所有相关资源均公开。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在机器翻译质量评估上表现突出，但因体积和成本制约，难以在边缘设备或隐私敏感场景部署。论文关注在降低模型参数规模的同时，是否还能有效检测翻译中改变语义的重要错误。

Method: 针对英语到德语的关键错误检测（CED），对多个参数在2B以下的小型模型进行基准测试，并提出统一的提示词模板，轻量级logit-bias校准以及多数投票机制。对比语义质量（如MCC和F1分数）与计算效率（内存占用、延迟、吞吐量）。

Result: Gemma-3-1B在质量和效率之间达到最佳平衡，经微调后在SynCED-EnDe-2025上取得MCC=0.77和F1-ERR=0.98，同时单样本延迟为400ms（MacBook Pro M4 Pro 24GB）。Qwen-3-1.7B绝对表现更高，但计算成本更大。超小型号（0.6B）经校准后仍可用，但难以检测实体和数字错误。

Conclusion: 小型且经过指令微调的LLM，结合轻量校准和少量监督，可以高效可靠地完成关键翻译错误检测，适用于边缘设备，实现隐私、低成本的翻译质量筛查。所有数据集、提示和代码均开源。

Abstract: Large Language Models (LLMs) excel at evaluating machine translation (MT), but their scale and cost hinder deployment on edge devices and in privacy-sensitive workflows. We ask: how small can you get while still detecting meaning-altering translation errors? Focusing on English->German Critical Error Detection (CED), we benchmark sub-2B models (LFM2-350M, Qwen-3-0.6B/1.7B, Llama-3.2-1B-Instruct, Gemma-3-1B) across WMT21, WMT22, and SynCED-EnDe-2025. Our framework standardizes prompts, applies lightweight logit-bias calibration and majority voting, and reports both semantic quality (MCC, F1-ERR/F1-NOT) and compute metrics (VRAM, latency, throughput). Results reveal a clear sweet spot around one billion parameters: Gemma-3-1B provides the best quality-efficiency trade-off, reaching MCC=0.77 with F1-ERR=0.98 on SynCED-EnDe-2025 after merged-weights fine-tuning, while maintaining 400 ms single-sample latency on a MacBook Pro M4 Pro (24 GB). At larger scale, Qwen-3-1.7B attains the highest absolute MCC (+0.11 over Gemma) but with higher compute cost. In contrast, ultra-small models (0.6B) remain usable with few-shot calibration yet under-detect entity and number errors. Overall, compact, instruction-tuned LLMs augmented with lightweight calibration and small-sample supervision can deliver trustworthy, on-device CED for MT, enabling private, low-cost error screening in real-world translation pipelines. All datasets, prompts, and scripts are publicly available at our GitHub repository.

</details>


### [20] [Predicate-Argument Structure Divergences in Chinese and English Parallel Sentences and their Impact on Language Transfer](https://arxiv.org/abs/2511.09796)
*Rocco Tripodi,Xiaoyu Liu*

Main category: cs.CL

TL;DR: 本文系统分析了中英文平行句子中的谓词-论元结构，对结构分歧进行了分类，并通过标注投射实验揭示了语言迁移中的非对称性，强调在跨语言NLP研究中需重视源语言选择与结构差异的问题。


<details>
  <summary>Details</summary>
Motivation: 跨语言自然语言处理在低资源语言环境下具有重要应用价值，但由于语言结构上的差异，尤其是类型学差异较大的语言之间，知识迁移存在障碍。作者为了解决语言迁移中出现的结构分歧问题，对中文和英文中的谓词-论元结构做深入研究。

Method: 分析了中英文平行句子中的谓词-论元结构，对谓词标注的一致性与不一致性进行考察，提出了结构分歧的分类方法。具体采用了定性和定量分析的方法，通过将某一语言的标注投射到另一语言的平行句，检验结构的对齐与偏离。

Result: 分析结果揭示了跨语言标注投射的非对称性，即将标注从一种语言投射到另一种语言时，效果和结构分歧是有差异的。该结果表明，选择迁移学习源语言时需慎重，需要对语言间的结构分歧进行详细分析。

Conclusion: 结构分歧对跨语言NLP中的知识迁移有显著影响，语言迁移是非对称的，因此在低资源语言迁移、源语言选择和科学论述前需重点关注语言结构差异及其对转移结果的影响。

Abstract: Cross-lingual Natural Language Processing (NLP) has gained significant traction in recent years, offering practical solutions in low-resource settings by transferring linguistic knowledge from resource-rich to low-resource languages. This field leverages techniques like annotation projection and model transfer for language adaptation, supported by multilingual pre-trained language models. However, linguistic divergences hinder language transfer, especially among typologically distant languages. In this paper, we present an analysis of predicate-argument structures in parallel Chinese and English sentences. We explore the alignment and misalignment of predicate annotations, inspecting similarities and differences and proposing a categorization of structural divergences. The analysis and the categorization are supported by a qualitative and quantitative analysis of the results of an annotation projection experiment, in which, in turn, one of the two languages has been used as source language to project annotations into the corresponding parallel sentences. The results of this analysis show clearly that language transfer is asymmetric. An aspect that requires attention when it comes to selecting the source language in transfer learning applications and that needs to be investigated before any scientific claim about cross-lingual NLP is proposed.

</details>


### [21] [TARG: Training-Free Adaptive Retrieval Gating for Efficient RAG](https://arxiv.org/abs/2511.09803)
*Yufeng Wang,Lu wei,Haibin Ling*

Main category: cs.CL

TL;DR: 提出TARG方法，通过轻量算分决定何时检索，显著减少资源消耗同时保持甚至提升准确率，无需训练、易于部署。


<details>
  <summary>Details</summary>
Motivation: RAG能够提升模型的事实性，但每次查询都检索会损害生成质量，同时增加token消耗和延迟。因此需要一种更灵活的方法，决定何时进行检索以平衡准确性和效率。

Method: 提出了一种无需训练的自适应检索门控方法（TARG），该方法通过主模型生成的无上下文草稿前缀的logits计算轻量的不确定性分数（如均值熵、top-1/top-2 logit间距、或少量随机前缀方差），只有当分数超过阈值时才触发检索。TARG无需额外训练、模型无关，仅增加少量tokens。

Result: 在NQ-Open、TriviaQA、PopQA基准上，TARG在准确率和效率之间取得了新的平衡：相较Always-RAG，在减少70-90%的检索次数和端到端延迟下，准确率（EM/F1）持平或更优，且整体开销接近Never-RAG。实验证明，现代微调LLM下，top-1/top-2 logit的margin信号表现稳健，小样本方差适用于严格预算场景。并对门控类型与前缀长度进行了消融实验。

Conclusion: TARG是无需训练、模型无关的检索门控机制，可大幅提升生成任务在事实性与效率之间的整体表现，适用于大规模和严格预算场景。其方法简单易部署，对现代LLM具有较强通用性和实用价值。

Abstract: Retrieval-Augmented Generation (RAG) improves factuality but retrieving for every query often hurts quality while inflating tokens and latency. We propose Training-free Adaptive Retrieval Gating (TARG), a single-shot policy that decides when to retrieve using only a short, no-context draft from the base model. From the draft's prefix logits, TARG computes lightweight uncertainty scores: mean token entropy, a margin signal derived from the top-1/top-2 logit gap via a monotone link, or small-N variance across a handful of stochastic prefixes, and triggers retrieval only when the score exceeds a threshold. The gate is model agnostic, adds only tens to hundreds of draft tokens, and requires no additional training or auxiliary heads. On NQ-Open, TriviaQA, and PopQA, TARG consistently shifts the accuracy-efficiency frontier: compared with Always-RAG, TARG matches or improves EM/F1 while reducing retrieval by 70-90% and cutting end-to-end latency, and it remains close to Never-RAG in overhead. A central empirical finding is that under modern instruction-tuned LLMs the margin signal is a robust default (entropy compresses as backbones sharpen), with small-N variance offering a conservative, budget-first alternative. We provide ablations over gate type and prefix length and use a delta-latency view to make budget trade-offs explicit.

</details>


### [22] [Khmer Spellchecking: A Holistic Approach](https://arxiv.org/abs/2511.09812)
*Marry Kong,Rina Buoy,Sovisal Chenda,Nguonly Taing*

Main category: cs.CL

TL;DR: 本文针对柬埔寨语拼写检查难题，提出整体方案结合分词、命名实体识别、音标转换与语言模型，准确率达94.4%，并首次公开相关数据集推动领域发展。


<details>
  <summary>Details</summary>
Motivation: 柬埔寨语（高棉语）拼写检查问题尚未解决，其主要挑战包括词典与分词模型不一致、词形多样化、复合词灵活生成、以及缺乏专用的命名实体识别模型，导致现有方法效果不佳。

Method: 提出将柬埔寨语子词分割、命名实体识别（NER）、字素到音位转换（G2P）、以及语言模型整合进拼写检查流程，从而识别、生成、筛选最优纠错候选。

Result: 实验结果显示新方法在柬埔寨语拼写检查准确率上达到当前最高水平（94.4%），显著优于已有方法。

Conclusion: 该文方法有效解决了柬埔寨语拼写检查的多项关键挑战，并公布了相关基准数据集，为后续研究奠定基础。

Abstract: Compared to English and other high-resource languages, spellchecking for Khmer remains an unresolved problem due to several challenges. First, there are misalignments between words in the lexicon and the word segmentation model. Second, a Khmer word can be written in different forms. Third, Khmer compound words are often loosely and easily formed, and these compound words are not always found in the lexicon. Fourth, some proper nouns may be flagged as misspellings due to the absence of a Khmer named-entity recognition (NER) model. Unfortunately, existing solutions do not adequately address these challenges. This paper proposes a holistic approach to the Khmer spellchecking problem by integrating Khmer subword segmentation, Khmer NER, Khmer grapheme-to-phoneme (G2P) conversion, and a Khmer language model to tackle these challenges, identify potential correction candidates, and rank the most suitable candidate. Experimental results show that the proposed approach achieves a state-of-the-art Khmer spellchecking accuracy of up to 94.4%, compared to existing solutions. The benchmark datasets for Khmer spellchecking and NER tasks in this study will be made publicly available.

</details>


### [23] [Improving Graduate Outcomes by Identifying Skills Gaps and Recommending Courses Based on Career Interests](https://arxiv.org/abs/2511.09819)
*Rahul Soni,Basem Suleiman,Sonit Singh*

Main category: cs.CL

TL;DR: 此文设计并实现了一个结合机器学习与数据分析的课程推荐系统，能够根据学生兴趣、行业趋势和职业目标智能推荐课程，并重视用户界面与体验，助力大学生科学选课与职业发展。


<details>
  <summary>Details</summary>
Motivation: 学生在选择课程时常常面临困扰，因为难以判断哪些课程与自身职业目标和行业发展趋势匹配。本文旨在解决大学生选课与行业期望之间的脱节问题，为学生、教师和职业顾问提供科学选课工具。

Method: 本文提出并设计开发了一个课程推荐系统。方法上，结合数据分析、机器学习、多种算法框架，融合用户偏好与学术标准。系统采用数据挖掘与协同过滤技术，分析历史选课数据与用户职业目标。同时，前端界面设计注重视觉清晰、交互与简易操作，通过迭代原型和用户反馈优化系统。

Result: 系统经过优化与用户反馈修正，能够对接行业需求、用户兴趣和学业标准，有效为用户推荐个性化课程，提高了用户体验的流畅度与吸引力。该系统促进了大学学习与行业要求对接。

Conclusion: 该课程推荐系统能有效填补大学生选课与行业需求间的空白，帮助大学生做出数据驱动、行业导向的选课决策，促进毕业生职业发展和高校教育成果优化。

Abstract: This paper aims to address the challenge of selecting relevant courses for students by proposing the design and development of a course recommendation system. The course recommendation system utilises a combination of data analytics techniques and machine learning algorithms to recommend courses that align with current industry trends and requirements. In order to provide customised suggestions, the study entails the design and implementation of an extensive algorithmic framework that combines machine learning methods, user preferences, and academic criteria. The system employs data mining and collaborative filtering techniques to examine past courses and individual career goals in order to provide course recommendations. Moreover, to improve the accessibility and usefulness of the recommendation system, special attention is given to the development of an easy-to-use front-end interface. The front-end design prioritises visual clarity, interaction, and simplicity through iterative prototyping and user input revisions, guaranteeing a smooth and captivating user experience. We refined and optimised the proposed system by incorporating user feedback, ensuring that it effectively meets the needs and preferences of its target users. The proposed course recommendation system could be a useful tool for students, instructors, and career advisers to use in promoting lifelong learning and professional progression as it fills the gap between university learning and industry expectations. We hope that the proposed course recommendation system will help university students in making data-drive and industry-informed course decisions, in turn, improving graduate outcomes for the university sector.

</details>


### [24] [Answering Students' Questions on Course Forums Using Multiple Chain-of-Thought Reasoning and Finetuning RAG-Enabled LLM](https://arxiv.org/abs/2511.09831)
*Neo Wang,Sonit Singh*

Main category: cs.CL

TL;DR: 本文提出结合微调的开源LLM和RAG、结合多链推理，提升课程论坛自动问答系统的性能和可靠性，实验证明效果显著。


<details>
  <summary>Details</summary>
Motivation: 由于课程学生人数增多，论坛中教师难以及时回复学生提问，重复性问题多，因此需要高效自动化问答系统。

Method: 设计了基于开源大语言模型（LLM）的问答系统，对相关课程数据集进行了微调，并使用RAG方法检索知识库中的相关文档，同时集成多链思维推理缓解LLM的幻觉。

Result: 在HotpotQA数据集上实验，微调后的LLM结合RAG方法能在问答任务中取得较强表现，并有效减少幻觉。

Conclusion: 结合RAG方法和多链思维推理的开源LLM能够有效提升课程论坛中问答系统的表现，并减少幻觉现象。

Abstract: The course forums are increasingly significant and play vital role in facilitating student discussions and answering their questions related to the course. It provides a platform for students to post their questions related to the content and admin issues related to the course. However, there are several challenges due to the increase in the number of students enrolled in the course. The primary challenge is that students' queries cannot be responded immediately and the instructors have to face lots of repetitive questions. To mitigate these issues, we propose a question answering system based on large language model with retrieval augmented generation (RAG) method. This work focuses on designing a question answering system with open source Large Language Model (LLM) and fine-tuning it on the relevant course dataset. To further improve the performance, we use a local knowledge base and applied RAG method to retrieve relevant documents relevant to students' queries, where the local knowledge base contains all the course content. To mitigate the hallucination of LLMs, We also integrate it with multi chain-of-thought reasoning to overcome the challenge of hallucination in LLMs. In this work, we experiment fine-tuned LLM with RAG method on the HotpotQA dataset. The experimental results demonstrate that the fine-tuned LLM with RAG method has a strong performance on question answering task.

</details>


### [25] [TermGPT: Multi-Level Contrastive Fine-Tuning for Terminology Adaptation in Legal and Financial Domain](https://arxiv.org/abs/2511.09854)
*Yidan Sun,Mengying Zhu,Feiyue Chen,Yangyang Wu,Xiaolei Dan,Mengyuan Yang,Xiaolin Zheng,Shenglin Ben*

Main category: cs.CL

TL;DR: 本文提出了针对LLM术语区分能力不足问题的TermGPT多层次对比微调框架，通过句子图和多级对比学习提升了术语判别力，并在金融与法律领域验证了优越性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在文本生成任务中表现优异，但其嵌入空间存在各向同性问题，导致在法律和金融等领域术语区分能力差，严重影响依赖细粒度语义判别的下游任务。

Method: 提出了TermGPT，即多层次对比微调框架，具体包括：构建句子图以捕捉语义及结构关系，基于上下文和拓扑线索生成语义一致但有区分度的正负样本；设计句子级与令牌级对比学习方法，提升全局语境理解和术语区分能力。

Result: TermGPT在金融和法律领域的术语区分任务上表现优于现有基线模型。

Conclusion: TermGPT有效提升了LLM在专用领域中术语的判别力，有助于改善下游精细语义任务的表现。

Abstract: Large language models (LLMs) have demonstrated impressive performance in text generation tasks; however, their embedding spaces often suffer from the isotropy problem, resulting in poor discrimination of domain-specific terminology, particularly in legal and financial contexts. This weakness in terminology-level representation can severely hinder downstream tasks such as legal judgment prediction or financial risk analysis, where subtle semantic distinctions are critical. To address this problem, we propose TermGPT, a multi-level contrastive fine-tuning framework designed for terminology adaptation. We first construct a sentence graph to capture semantic and structural relations, and generate semantically consistent yet discriminative positive and negative samples based on contextual and topological cues. We then devise a multi-level contrastive learning approach at both the sentence and token levels, enhancing global contextual understanding and fine-grained terminology discrimination. To support robust evaluation, we construct the first financial terminology dataset derived from official regulatory documents. Experiments show that TermGPT outperforms existing baselines in term discrimination tasks within the finance and legal domains.

</details>


### [26] [In-Token Rationality Optimization: Towards Accurate and Concise LLM Reasoning via Self-Feedback](https://arxiv.org/abs/2511.09865)
*Mingye Zhu,Yi Liu,Zheren Fu,Quan Wang,Yongdong Zhang*

Main category: cs.CL

TL;DR: InTRO通过token级探索与自反馈，显著提高LLM推理准确率、简洁性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有训练方法要么限制了可接受推理路径的多样性，要么面临标注和计算上的挑战，因此需要一种兼顾探索和反馈的新方式。

Method: 提出InTRO框架，通过信息差异估算token级重要性，并在一次前向传播中实现token级探索和模型自我反馈，从而优化生成过程。

Result: 在六个数学推理基准上，InTRO将解决准确率提升至比基础模型高20%，推理过程更简练，同时支持跨领域转移，展现了优秀的泛化能力。

Conclusion: InTRO方法能显著提升大语言模型链式推理的准确性和简洁性，同时还具备强泛化和跨领域迁移能力。

Abstract: Training Large Language Models (LLMs) for chain-of-thought reasoning presents a significant challenge: supervised fine-tuning on a single "golden" rationale hurts generalization as it penalizes equally valid alternatives, whereas reinforcement learning with verifiable rewards struggles with credit assignment and prohibitive computational cost. To tackle these limitations, we introduce InTRO (In-Token Rationality Optimization), a new framework that enables both token-level exploration and self-feedback for accurate and concise reasoning. Instead of directly optimizing an intractable objective over all valid reasoning paths, InTRO leverages correction factors-token-wise importance weights estimated by the information discrepancy between the generative policy and its answer-conditioned counterpart, for informative next token selection. This approach allows the model to perform token-level exploration and receive self-generated feedback within a single forward pass, ultimately encouraging accurate and concise rationales. Across six math-reasoning benchmarks, InTRO consistently outperforms other baselines, raising solution accuracy by up to 20% relative to the base model. Its chains of thought are also notably more concise, exhibiting reduced verbosity. Beyond this, InTRO enables cross-domain transfer, successfully adapting to out-of-domain reasoning tasks that extend beyond the realm of mathematics, demonstrating robust generalization.

</details>


### [27] [HierRouter: Coordinated Routing of Specialized Large Language Models via Reinforcement Learning](https://arxiv.org/abs/2511.09873)
*Nikunj Gupta,Bill Guo,Rajgopal Kannan,Viktor K. Prasanna*

Main category: cs.CL

TL;DR: HierRouter通过智能选择多模型协作推理，显著提升推理效果，几乎不增加资源消耗，非常适用于高效部署场景。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型计算资源消耗高，难以部署于资源受限或实时场景，亟需一种兼顾效率和性能的推理方案。

Method: 采用分层路由策略，将推理过程视为有限时域马尔可夫决策过程（MDP），基于PPO强化学习训练智能体，逐步决定每一步调用哪一个子模型。

Result: 在六项基准测试中（含问答、代码生成、数学推理），比单独使用模型独立推理最高提升2.4倍响应质量，平均推理成本增加极小。

Conclusion: HierRouter通过层次化路由组合多个轻量化模型，有效提升了推理质量，同时保持较低的计算成本。

Abstract: Large Language Models (LLMs) deliver state-of-the-art performance across many tasks but impose high computational and memory costs, limiting their deployment in resource-constrained or real-time settings. To address this, we propose HierRouter, a hierarchical routing approach that dynamically assembles inference pipelines from a pool of specialized, lightweight language models. Formulated as a finite-horizon Markov Decision Process (MDP), our approach trains a Proximal Policy Optimization (PPO)-based reinforcement learning agent to iteratively select which models to invoke at each stage of multi-hop inference. The agent conditions on the evolving context and accumulated cost to make context-aware routing decisions. Experiments with three open-source candidate LLMs across six benchmarks, including QA, code generation, and mathematical reasoning, show that HierRouter improves response quality by up to 2.4x compared to using individual models independently, while incurring only a minimal additional inference cost on average. These results highlight the promise of hierarchical routing for cost-efficient, high-performance LLM inference. All codes can be found here https://github.com/ Nikunj-Gupta/hierouter.

</details>


### [28] [EnchTable: Unified Safety Alignment Transfer in Fine-tuned Large Language Models](https://arxiv.org/abs/2511.09880)
*Jialin Wu,Kecen Li,Zhicong Huang,Xinfeng Li,Xiaofeng Wang,Cheng Hong*

Main category: cs.CL

TL;DR: EnchTable提供了一种无需大规模再训练的安全对齐迁移新方法，在多个任务和模型架构下都能有效提升模型安全性并保证效用，抗越狱能力强，适用范围广。


<details>
  <summary>Details</summary>
Motivation: 许多机器学习模型通过在大语言模型（LLM）基础上进行微调，以在代码生成、生物医学分析和数学问题求解等专用领域中实现高性能。然而，此微调过程经常引入安全对齐的系统性劣化，危及伦理规范并增加有害输出的风险。

Method: 提出了一种新框架EnchTable，通过NTK（Neural Tangent Kernel）为基础的安全向量蒸馏方法，将安全约束与任务推理解耦，并通过干扰感知合并技术在不同任务领域平衡安全性和效用，无需大规模再训练。

Result: 在三种任务领域和三种不同LLM架构上实现EnchTable原型，并在11个多样化数据集上进行实验。结果显示EnchTable在应对静态与动态越狱攻击方面表现强劲，在减少不安全输出率、提高效用分数和通用适应性方面优于供应商安全模型及其他方法。集成到各种部署流程中也无明显负担。

Conclusion: EnchTable能够无缝实现下游LLMs的安全对齐迁移，在平衡安全与效用方面取得显著优势，并具备跨领域通用性和低集成成本。

Abstract: Many machine learning models are fine-tuned from large language models (LLMs) to achieve high performance in specialized domains like code generation, biomedical analysis, and mathematical problem solving. However, this fine-tuning process often introduces a critical vulnerability: the systematic degradation of safety alignment, undermining ethical guidelines and increasing the risk of harmful outputs. Addressing this challenge, we introduce EnchTable, a novel framework designed to transfer and maintain safety alignment in downstream LLMs without requiring extensive retraining. EnchTable leverages a Neural Tangent Kernel (NTK)-based safety vector distillation method to decouple safety constraints from task-specific reasoning, ensuring compatibility across diverse model architectures and sizes. Additionally, our interference-aware merging technique effectively balances safety and utility, minimizing performance compromises across various task domains. We implemented a fully functional prototype of EnchTable on three different task domains and three distinct LLM architectures, and evaluated its performance through extensive experiments on eleven diverse datasets, assessing both utility and model safety. Our evaluations include LLMs from different vendors, demonstrating EnchTable's generalization capability. Furthermore, EnchTable exhibits robust resistance to static and dynamic jailbreaking attacks, outperforming vendor-released safety models in mitigating adversarial prompts. Comparative analyses with six parameter modification methods and two inference-time alignment baselines reveal that EnchTable achieves a significantly lower unsafe rate, higher utility score, and universal applicability across different task domains. Additionally, we validate EnchTable can be seamlessly integrated into various deployment pipelines without significant overhead.

</details>


### [29] [HI-TransPA: Hearing Impairments Translation Personal Assistant](https://arxiv.org/abs/2511.09915)
*Zhiming Ma,Shiyu Gan,Junhao Zhao,Xianming Li,Qingyun Pan,Peidong Wang,Mingjun Pan,Yuhao Mo,Jiajie Cheng,Chengxin Chen,Zhonglun Cao,Chonghan Liu,Shi Cheng*

Main category: cs.CL

TL;DR: 本研究提出HI-TransPA多模态助理，有效融合语音及唇动信息，通过创新数据处理及分级学习策略，极大提升了听障者交流的准确性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态模型难以适应听障语音、原始数据异质性高及噪声问题，听障者日常交流缺乏统一高效辅助解决方案。

Method: 构建了音频-视觉多模态个人助理（HI-TransPA），融合模糊语音与高帧率唇动信息，开发质量评估与分级训练的处理流程，采用SigLIP编码器与统一三维重采样器进行高质量唇动编码。

Result: HI-TransPA在自建HI-Dialogue数据集上，在准确度和语义一致性方面均超过现有方法，达到业界最佳水平。

Conclusion: 本论文展示了HI-TransPA助听多模态对话系统在支持听障者日常交流方面实现了最佳性能，证明了Omni-Model范式在辅助技术领域的可行性和有效性。

Abstract: To provide a unified and flexible solution for daily communication among hearing-impaired individuals, we introduce the Omni-Model paradigm into assistive technology and present HI-TransPA, an instruction-driven audio-visual personal assistant. The model fuses indistinct speech with high-frame-rate lip dynamics, enabling both translation and dialogue within a single multimodal framework. To tackle the challenges of noisy and heterogeneous raw data and the limited adaptability of existing Omni-Models to hearing-impaired speech, we construct a comprehensive preprocessing and curation pipeline that detects facial landmarks, isolates and stabilizes the lip region, and quantitatively assesses multimodal sample quality. These quality scores guide a curriculum learning strategy that first trains on clean, high-confidence samples and progressively incorporates harder cases to strengthen model robustness. We further adopt a SigLIP encoder combined with a Unified 3D-Resampler to efficiently encode high-frame-rate lip motion. Experiments on our purpose-built HI-Dialogue dataset show that HI-TransPA achieves state-of-the-art performance in both literal accuracy and semantic fidelity. This work establishes a foundation for applying Omni-Models to assistive communication technology, providing an end-to-end modeling framework and essential processing tools for future research.

</details>


### [30] [MINDS: A Cross-cultural Dialogue Corpus for Social Norm Classification and Adherence Detection](https://arxiv.org/abs/2511.09918)
*Pritish Sahu,Anirudh Som,Dimitra Vergyri,Ajay Divakaran*

Main category: cs.CL

TL;DR: Norm-RAG通过增强检索和结构建模，实现了对多轮多语种真实对话中社会规范的细致推理，并显著提升了规范检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有规范类研究多聚焦于单轮陈述或合成对话，无法捕捉真实多轮交流中的流动与上下文变化，且规范推理本身主观、依赖语境与文化，给计算建模带来难题。

Method: 提出了Norm-RAG检索增强型推理框架，结合语义分块检索、话语层级属性建模，以及以结构化规范文档为信息支撑，并引入了MINDS多语言对话数据集开展实验和验证。

Result: Norm-RAG不仅在规范检测与泛化方面优于现有方法，还能对跨文化、多语言多轮真实对话进行更细致、可解释的社会规范推理，推动对话系统的社会适应性。

Conclusion: Norm-RAG显著提升了社会规范检测的准确性与泛化能力，为跨文化对话系统中的社会智能做出贡献。

Abstract: Social norms are implicit, culturally grounded expectations that guide interpersonal communication. Unlike factual commonsense, norm reasoning is subjective, context-dependent, and varies across cultures, posing challenges for computational models. Prior works provide valuable normative annotations but mostly target isolated utterances or synthetic dialogues, limiting their ability to capture the fluid, multi-turn nature of real-world conversations. In this work, we present Norm-RAG, a retrieval-augmented, agentic framework for nuanced social norm inference in multi-turn dialogues. Norm-RAG models utterance-level attributes including communicative intent, speaker roles, interpersonal framing, and linguistic cues and grounds them in structured normative documentation retrieved via a novel Semantic Chunking approach. This enables interpretable and context-aware reasoning about norm adherence and violation across multilingual dialogues. We further introduce MINDS (Multilingual Interactions with Norm-Driven Speech), a bilingual dataset comprising 31 multi-turn Mandarin-English and Spanish-English conversations. Each turn is annotated for norm category and adherence status using multi-annotator consensus, reflecting cross-cultural and realistic norm expression. Our experiments show that Norm-RAG improves norm detection and generalization, demonstrates improved performance for culturally adaptive and socially intelligent dialogue systems.

</details>


### [31] [Leveraging Large Language Models for Identifying Knowledge Components](https://arxiv.org/abs/2511.09935)
*Canwen Wang,Jionghao Lin,Kenneth R. Koedinger*

Main category: cs.CL

TL;DR: 本研究发现仅用LLM自动化识别知识组件难以达到专家水平，但通过语义合并等技术，大模型在大数据场景下能有效提升自动化能力，为自适应学习系统的KCs自动识别提供新方法。


<details>
  <summary>Details</summary>
Motivation: 知识组件（KCs）是自适应学习系统的基础，但目前主要依靠领域专家手动识别，效率低且成本高。虽然大型语言模型（LLMs）有望自动化这一过程，但现有研究仅限于小规模数据集，且经常导致标签冗余。

Method: 通过GPT-4o-mini采用“模拟教科书”提示策略，在大规模（646道多项选择题）数据集上自动生成KCs。然后，利用余弦相似度对自动生成的KC标签进行语义合并，减少冗余。

Result: LLM初步自动生成的KCs效果明显不如专家设计（RMSE 0.4285 vs. 0.4206），且标签数远超专家模型（569 vs. 101）。采用余弦相似度（阈值0.8）进行语义合并后，KCs数量降至428，模型RMSE提升至0.4259。

Conclusion: 单纯依靠LLM自动生成KCs无法达到专家水平，但结合语义合并方法后，可显著提升自动化识别的有效性，自动化和精细化KCs识别有了现实可行的路径。

Abstract: Knowledge Components (KCs) are foundational to adaptive learning systems, but their manual identification by domain experts is a significant bottleneck. While Large Language Models (LLMs) offer a promising avenue for automating this process, prior research has been limited to small datasets and has been shown to produce superfluous, redundant KC labels. This study addresses these limitations by first scaling a "simulated textbook" LLM prompting strategy (using GPT-4o-mini) to a larger dataset of 646 multiple-choice questions. We found that this initial automated approach performed significantly worse than an expert-designed KC model (RMSE 0.4285 vs. 0.4206) and generated an excessive number of KCs (569 vs. 101). To address the issue of redundancy, we proposed and evaluated a novel method for merging semantically similar KC labels based on their cosine similarity. This merging strategy significantly improved the model's performance; a model using a cosine similarity threshold of 0.8 achieved the best result, reducing the KC count to 428 and improving the RMSE to 0.4259. This demonstrates that while scaled LLM generation alone is insufficient, combining it with a semantic merging technique offers a viable path toward automating and refining KC identification.

</details>


### [32] [REAP: Enhancing RAG with Recursive Evaluation and Adaptive Planning for Multi-Hop Question Answering](https://arxiv.org/abs/2511.09966)
*Yijie Zhu,Haojie Zhou,Wanting Hong,Tailin Liu,Ning Wang*

Main category: cs.CL

TL;DR: 本文针对多跳推理任务中的RAG方法提出了REAP框架，通过全局规划和细粒度事实抽取显著提升推理效果，经实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在多跳推理任务中缺乏全局规划，导致易陷入局部困境，且未能充分利用检索内容和隐含线索，影响推理结果的准确性。

Method: 提出了递归评估与自适应规划（REAP）方法，包含子任务规划器（SP）和事实抽取器（FE）两个模块，通过结构化保持任务相关的子任务与事实，实现动态优化推理路径。

Result: 在多个公开多跳数据集上，REAP方法在域内与域外均显著优于现有方法，验证了其在复杂多跳推理任务中的有效性。

Conclusion: 该方法显著优于现有RAG方法，在多跳推理任务中有效提升了推理的准确性和可靠性。

Abstract: Retrieval-augmented generation (RAG) has been extensively employed to mitigate hallucinations in large language models (LLMs). However, existing methods for multi-hop reasoning tasks often lack global planning, increasing the risk of falling into local reasoning impasses. Insufficient exploitation of retrieved content and the neglect of latent clues fail to ensure the accuracy of reasoning outcomes. To overcome these limitations, we propose Recursive Evaluation and Adaptive Planning (REAP), whose core idea is to explicitly maintain structured sub-tasks and facts related to the current task through the Sub-task Planner (SP) and Fact Extractor (FE) modules. SP maintains a global perspective, guiding the overall reasoning direction and evaluating the task state based on the outcomes of FE, enabling dynamic optimization of the task-solving trajectory. FE performs fine-grained analysis over retrieved content to extract reliable answers and clues. These two modules incrementally enrich a logically coherent representation of global knowledge, enhancing the reliability and the traceability of the reasoning process. Furthermore, we propose a unified task paradigm design that enables effective multi-task fine-tuning, significantly enhancing SP's performance on complex, data-scarce tasks. We conduct extensive experiments on multiple public multi-hop datasets, and the results demonstrate that our method significantly outperforms existing RAG methods in both in-domain and out-of-domain settings, validating its effectiveness in complex multi-hop reasoning tasks.

</details>


### [33] [NumPert: Numerical Perturbations to Probe Language Models for Veracity Prediction](https://arxiv.org/abs/2511.09971)
*Peter Røysland Aarnes,Vinay Setty*

Main category: cs.CL

TL;DR: 本研究系统评估主流大模型在数值事实核查任务下的稳健性，发现其准确率在扰动下显著降低。扩展上下文能部分提升表现，但整体稳健性仍不足，数值推理仍是未解难题。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在数值推理方面的能力，尤其是其在事实核查和问答任务中的表现，鉴于现有模型在处理数值相关任务中常常表现不佳。

Method: 采用系统性评估，通过对数值主张及证据对进行受控扰动（如标签翻转探针），测试最先进模型在真实性预测上的稳健性。通过不同条件下的扰动和上下文长度变化衡量模型表现。

Result: 顶尖的商业系统在特定扰动下准确率最高下降62%，且没有任何一个模型能在所有条件下保持稳健。随着上下文长度增加，准确率普遍下降。但当扩展上下文中加入扰动后的示例时，大多数模型表现能够大幅恢复。

Conclusion: 当前语言模型在数值事实核查方面存在关键限制，稳健性仍然是一个重大挑战。

Abstract: Large language models show strong performance on knowledge intensive tasks such as fact-checking and question answering, yet they often struggle with numerical reasoning. We present a systematic evaluation of state-of-the-art models for veracity prediction on numerical claims and evidence pairs using controlled perturbations, including label-flipping probes, to test robustness. Our results indicate that even leading proprietary systems experience accuracy drops of up to 62\% under certain perturbations. No model proves to be robust across all conditions. We further find that increasing context length generally reduces accuracy, but when extended context is enriched with perturbed demonstrations, most models substantially recover. These findings highlight critical limitations in numerical fact-checking and suggest that robustness remains an open challenge for current language models.

</details>


### [34] [Modeling Uncertainty Trends for Timely Retrieval in Dynamic RAG](https://arxiv.org/abs/2511.09980)
*Bo Li,Tian Tian,Zhenghua Xu,Hao Cheng,Shikun Zhang,Wei Ye*

Main category: cs.CL

TL;DR: 该工作提出了一种基于熵趋势分析的新型检索时机判定方法ETC，无需训练即可用于各类LLM解码管线，实现更早、更准确检索，显著提升问答表现、减少无需检索，具备广泛适用性与易用性。


<details>
  <summary>Details</summary>
Motivation: 动态RAG使LLM能够按需获取外部知识，但核心难题是何时启动检索。现有方法多依据token层面置信度低来触发检索，常因错误已传播而导致检索时机滞后。

Method: 提出Entropy-Trend Constraint（ETC），该方法无需训练，通过对token级熵序列的动态建模（使用熵的一阶和二阶差分）来侦测不确定性趋势，并据此确定更优检索时机。

Result: 在六个问答基准、三种LLM骨干测试中，ETC持续优于强基线，并降低检索频率。尤其在领域场景下表现优异，展现了强泛化能力。消融与定性分析也验证了趋势感知的不确定性建模带来的检索优化。

Conclusion: ETC方法精准且早期地指导检索，提升了动态RAG的效果。方法可直接集成于现有解码流程，对模型无关、即插即用。同时附有完整代码实现。

Abstract: Dynamic retrieval-augmented generation (RAG) allows large language models (LLMs) to fetch external knowledge on demand, offering greater adaptability than static RAG. A central challenge in this setting lies in determining the optimal timing for retrieval. Existing methods often trigger retrieval based on low token-level confidence, which may lead to delayed intervention after errors have already propagated. We introduce Entropy-Trend Constraint (ETC), a training-free method that determines optimal retrieval timing by modeling the dynamics of token-level uncertainty. Specifically, ETC utilizes first- and second-order differences of the entropy sequence to detect emerging uncertainty trends, enabling earlier and more precise retrieval. Experiments on six QA benchmarks with three LLM backbones demonstrate that ETC consistently outperforms strong baselines while reducing retrieval frequency. ETC is particularly effective in domain-specific scenarios, exhibiting robust generalization capabilities. Ablation studies and qualitative analyses further confirm that trend-aware uncertainty modeling yields more effective retrieval timing. The method is plug-and-play, model-agnostic, and readily integrable into existing decoding pipelines. Implementation code is included in the supplementary materials.

</details>


### [35] [Language Drift in Multilingual Retrieval-Augmented Generation: Characterization and Decoding-Time Mitigation](https://arxiv.org/abs/2511.09984)
*Bo Li,Zhenghua Xu,Rui Xie*

Main category: cs.CL

TL;DR: 多语言RAG在生成推理过程中常因跨语言证据造成输出语言漂移，尤其易回落至英文。文章发现原因在于生成端token分布坍塌，并提出无需训练的柔性解码修正法SCD，有效改善了多语言一致性和任务效果，可广泛适用于多语言RAG场景。


<details>
  <summary>Details</summary>
Motivation: 多语言检索增强生成（RAG）在跨语言任务中表现优秀，但在检索证据与用户查询、示例语言不一致时，生成结果常出现语言漂移，特别是在链式推理（CoT）过程中更为明显。作者旨在系统研究和解决该问题，提高多语言RAG输出的一致性。

Method: 通过跨多数据集、语言和大模型体系结构的控制实验，分析多语言RAG的输出语言漂移本质，发现漂移源自解码器端的坍塌，并提出一种无需训练、轻量级的解码策略：Soft Constrained Decoding（SCD），通过对非目标语言token施加柔性惩罚，引导生成语言，且无需模型结构修改与额外数据。

Result: 实验证明，SCD在三个多语言数据集和多种类型语言上均显著提升了生成语言的一致性和任务表现，显示出良好的广泛适用性和有效性。

Conclusion: SCD作为一种普适、高效的生成后处理方法，能够有效缓解多语言RAG任务中的语言漂移问题，提升多语言任务的表现与稳定性。

Abstract: Multilingual Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to perform knowledge-intensive tasks in multilingual settings by leveraging retrieved documents as external evidence. However, when the retrieved evidence differs in language from the user query and in-context exemplars, the model often exhibits language drift by generating responses in an unintended language. This phenomenon is especially pronounced during reasoning-intensive decoding, such as Chain-of-Thought (CoT) generation, where intermediate steps introduce further language instability. In this paper, we systematically study output language drift in multilingual RAG across multiple datasets, languages, and LLM backbones. Our controlled experiments reveal that the drift results not from comprehension failure but from decoder-level collapse, where dominant token distributions and high-frequency English patterns dominate the intended generation language. We further observe that English serves as a semantic attractor under cross-lingual conditions, emerging as both the strongest interference source and the most frequent fallback language.
  To mitigate this, we propose Soft Constrained Decoding (SCD), a lightweight, training-free decoding strategy that gently steers generation toward the target language by penalizing non-target-language tokens. SCD is model-agnostic and can be applied to any generation algorithm without modifying the architecture or requiring additional data. Experiments across three multilingual datasets and multiple typologically diverse languages show that SCD consistently improves language alignment and task performance, providing an effective and generalizable solution in multilingual RAG.

</details>


### [36] [FinNuE: Exposing the Risks of Using BERTScore for Numerical Semantic Evaluation in Finance](https://arxiv.org/abs/2511.09997)
*Yu-Shiang Huang,Yun-Yu Lee,Tzu-Hsin Chou,Che Lin,Chuan-Ju Wang*

Main category: cs.CL

TL;DR: 该论文发现BERTScore难以捕捉金融语境下文本数字差异，构建了FinNuE数据集用以测试并印证其缺陷，强调亟需开发能识别数值语义的新型金融文本评价指标。


<details>
  <summary>Details</summary>
Motivation: 金融文本中数字差异对语义有极大影响，现有评价指标（如BERTScore）对数字变化敏感度不足，亟需解决这个痛点。

Method: 构建金融领域数值扰动的专用诊断数据集FinNuE，并利用该数据集系统测评BERTScore对关键数值差异的敏感性。

Result: BERTScore对金融文本中重要的数字偏差分辨率很低，导致语义有明显出入的文本对仍被判定为高度相似，揭示现有通用嵌入得分在金融NLU上的局限。

Conclusion: 嵌入式度量（如BERTScore）在金融领域处理涉及精确数字时存在关键缺陷，需发展新的数值敏感评价体系。

Abstract: BERTScore has become a widely adopted metric for evaluating semantic similarity between natural language sentences. However, we identify a critical limitation: BERTScore exhibits low sensitivity to numerical variation, a significant weakness in finance where numerical precision directly affects meaning (e.g., distinguishing a 2% gain from a 20% loss). We introduce FinNuE, a diagnostic dataset constructed with controlled numerical perturbations across earnings calls, regulatory filings, social media, and news articles. Using FinNuE, demonstrate that BERTScore fails to distinguish semantically critical numerical differences, often assigning high similarity scores to financially divergent text pairs. Our findings reveal fundamental limitations of embedding-based metrics for finance and motivate numerically-aware evaluation frameworks for financial NLP.

</details>


### [37] [PustakAI: Curriculum-Aligned and Interactive Textbooks Using Large Language Models](https://arxiv.org/abs/2511.10002)
*Shivam Sharma,Riya Naik,Tejas Gawas,Heramb Patil,Kunal Korgaonkar*

Main category: cs.CL

TL;DR: 针对印度NCERT课程，论文提出PustakAI框架和NCERT-QA问答数据集，采用多种提示方法和评估，深入分析开源与高端LLM在教育中的表现与局限，为AI教育应用提供有效适应方案。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在教育领域能够提供个性化和互动性学习体验，尤其对资源有限区域极具潜力。但针对特定教学大纲（如印度NCERT课程）的有效适应面临诸多挑战，包括准确性、契合度及教学相关性。

Method: 提出PustakAI框架，设计并评估与NCERT课程（英语和科学，6至8年级）对齐的新型问答数据集NCERT-QA。将问答对分类为事实类、推理类及其他（评估与推理类），通过多种提示方式（元提示、少样本、链式思考）及多种评估指标，分析哪种方式最契合课程需求，并比较开源与高端LLMs在教育场景的优势与局限。

Result: 建立了NCERT-QA数据集，并详细分析了不同提示方法在课程匹配上的效果。同时比较了几种开源和高端大模型作为AI学习工具在正式教育体系下的表现和局限。

Conclusion: PustakAI框架及NCERT-QA数据集能有效评估并推动大语言模型在正式教育的适应性。分析显示模型和提示方式的选择对提升教学相关性和准确性至关重要。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in understanding and generating human-like content. This has revolutionized various sectors such as healthcare, software development, and education. In education, LLMs offer potential for personalized and interactive learning experiences, especially in regions with limited teaching resources. However, adapting these models effectively to curriculum-specific content, such as the National Council of Educational Research and Training (NCERT) syllabus in India, presents unique challenges in terms of accuracy, alignment, and pedagogical relevance. In this paper, we present the framework "PustakAI"\footnote{Pustak means `book' in many Indian languages.} for the design and evaluation of a novel question-answering dataset "NCERT-QA" aligned with the NCERT curriculum for English and Science subjects of grades 6 to 8. We classify the curated QA pairs as Factoid, Inferential, and Others (evaluative and reasoning). We evaluate the dataset with various prompting techniques, such as meta-prompt, few-shot, and CoT-style prompting, using diverse evaluation metrics to understand which approach aligns more efficiently with the structure and demands of the curriculum. Along with the usability of the dataset, we analyze the strengths and limitations of current open-source LLMs (Gemma3:1b, Llama3.2:3b, and Nemotron-mini:4b) and high-end LLMs (Llama-4-Scout-17B and Deepseek-r1-70B) as AI-based learning tools in formal education systems.

</details>


### [38] [ScaleFormer: Span Representation Cumulation for Long-Context Transformer](https://arxiv.org/abs/2511.10029)
*Jiangshu Du,Wenpeng Yin,Philip Yu*

Main category: cs.CL

TL;DR: ScaleFormer是一种无需改动结构、即可让现有预训练Transformer模型高效处理长文本的新方法，通过片段上下文累积实现线性复杂度，在长文本摘要等任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 标准自注意力机制的二次复杂度极大限制了Transformer模型在处理长文本任务中的应用。现有高效Transformer变体通常需要架构改动并重新预训练，成本高昂。

Method: 提出了ScaleFormer框架，将长文本划分为重叠片段，并为每个片段生成上下文感知的压缩表示，通过一种新颖的、无参数的融合机制，使每个片段的表示能够感知其在文档中的结构化位置，实现片段边界与前后所有片段的累积上下文融合，从而无需改动模型结构即可适应长文本输入。

Result: 在长文档摘要任务上，ScaleFormer方法无需架构变更或外部检索机制即可达到或超过最新方法的性能，且算法复杂度线性提升。

Conclusion: ScaleFormer是一种简易而高效的模块化方案，通过上下文累积分片表示，极大提升了预训练Transformer模型在长文本任务上的能力，同时保持较低计算复杂度和良好性能。

Abstract: The quadratic complexity of standard self-attention severely limits the application of Transformer-based models to long-context tasks. While efficient Transformer variants exist, they often require architectural changes and costly pre-training from scratch. To circumvent this, we propose ScaleFormer(Span Representation Cumulation for Long-Context Transformer) - a simple and effective plug-and-play framework that adapts off-the-shelf pre-trained encoder-decoder models to process long sequences without requiring architectural modifications. Our approach segments long inputs into overlapping chunks and generates a compressed, context-aware representation for the decoder. The core of our method is a novel, parameter-free fusion mechanism that endows each chunk's representation with structural awareness of its position within the document. It achieves this by enriching each chunk's boundary representations with cumulative context vectors from all preceding and succeeding chunks. This strategy provides the model with a strong signal of the document's narrative flow, achieves linear complexity, and enables pre-trained models to reason effectively over long-form text. Experiments on long-document summarization show that our method is highly competitive with and often outperforms state-of-the-art approaches without requiring architectural modifications or external retrieval mechanisms.

</details>


### [39] [Do Language Models Associate Sound with Meaning? A Multimodal Study of Sound Symbolism](https://arxiv.org/abs/2511.10045)
*Jinhong Jeong,Sunghyun Lee,Jaeyoung Lee,Seonah Han,Youngjae Yu*

Main category: cs.CL

TL;DR: 本研究首次针对多模态大语言模型，以LEX-ICON大规模语音—语义数据集，系统测试其对声音象征主义的理解能力。模型不仅在多语种、多语义维度上复现了语言学已知规律，还展示出明确的音素关注模式，说明AI在语音与意义的关系解释上具备可解释性，推动了认知语言学与人工智能交叉领域的前沿进展。


<details>
  <summary>Details</summary>
Motivation: 声音象征主义揭示语言中语音形式与意义之间的非任意联系，但尚不清楚多模态大语言模型（MLLMs）如何理解和处理人类语言中的声音象征。研究人员试图以此为切入口，探究模型对语音信息的解释能力。

Method: 研究利用LEX-ICON数据集，包括英语、法语、日语、韩语的真实拟态词和系统构建的伪词，结合语义特征，以文本（正字与国际音标）和语音输入方式，对MLLMs在多达25个语义维度下的表现进行评估。通过层级式信息处理及音素级注意力分数，分析模型对音素象征意义的关注模式。

Result: MLLMs在多个语义维度上展现出与语言学研究一致的语音直觉，并在关注模式上突出模型对标志性音素的聚焦。

Conclusion: 结果表明MLLMs能够捕捉和理解声音象征主义中的语音—语义关系，模型的注意力机制对音素符号性特征具备分辨能力，从而为人工智能模型的可解释性与认知语言学研究搭建了桥梁。

Abstract: Sound symbolism is a linguistic concept that refers to non-arbitrary associations between phonetic forms and their meanings. We suggest that this can be a compelling probe into how Multimodal Large Language Models (MLLMs) interpret auditory information in human languages. We investigate MLLMs' performance on phonetic iconicity across textual (orthographic and IPA) and auditory forms of inputs with up to 25 semantic dimensions (e.g., sharp vs. round), observing models' layer-wise information processing by measuring phoneme-level attention fraction scores. To this end, we present LEX-ICON, an extensive mimetic word dataset consisting of 8,052 words from four natural languages (English, French, Japanese, and Korean) and 2,930 systematically constructed pseudo-words, annotated with semantic features applied across both text and audio modalities. Our key findings demonstrate (1) MLLMs' phonetic intuitions that align with existing linguistic research across multiple semantic dimensions and (2) phonosemantic attention patterns that highlight models' focus on iconic phonemes. These results bridge domains of artificial intelligence and cognitive linguistics, providing the first large-scale, quantitative analyses of phonetic iconicity in terms of MLLMs' interpretability.

</details>


### [40] [GraphIF: Enhancing Multi-Turn Instruction Following for Large Language Models with Relation Graph Prompt](https://arxiv.org/abs/2511.10051)
*Zhenhe Li,Can Lin,Ling Zheng,Wen-Da Wei,Junli Liang,Qi Song*

Main category: cs.CL

TL;DR: 作者提出了GraphIF框架，通过构建对话关系图并生成图形提示，显著提升了大模型在多轮会话中执行复杂指令的能力。


<details>
  <summary>Details</summary>
Motivation: 现有多轮对话指令跟随方法主要依赖于大规模数据集微调LLM，但这样处理每次回复为孤立任务，未显式优化多轮对话中的复杂关系约束，导致大模型难以处理长距离复杂指令依赖。作者发现多轮对话中的关系可通过有向图结构建模，但相关方法尚未被系统探索。

Method: 提出了一种名为GraphIF的可插拔式框架，将多轮对话建模为有向关系图，并利用图结构生成的提示提升LLM执行多轮指令的能力。GraphIF包括：1）基于agent的关系抽取模块，利用动作触发机制抽取回合间语义关系并构建图；2）关系图提示生成模块，将结构化图信息转换为自然语言提示；3）回复重写模块，使用图提示优化LLM初始输出。

Result: 在两个长多轮对话数据集上实验证明，GraphIF可无缝集成到现有LLM中，在四项多轮指令跟随评测指标上取得显著提升。

Conclusion: 利用图结构建模和提示机制显著增强了LLM对多轮复杂指令关系的理解和跟随能力，有效解决了以往方法在长距离约束下的不足。

Abstract: Multi-turn instruction following is essential for building intelligent conversational systems that can consistently adhere to instructions across dialogue turns. However, existing approaches to enhancing multi-turn instruction following primarily rely on collecting or generating large-scale multi-turn dialogue datasets to fine-tune large language models (LLMs), which treat each response generation as an isolated task and fail to explicitly incorporate multi-turn instruction following into the optimization objectives. As a result, instruction-tuned LLMs often struggle with complex long-distance constraints. In multi-turn dialogues, relational constraints across turns can be naturally modeled as labeled directed edges, making graph structures particularly suitable for modeling multi-turn instruction following. Despite this potential, leveraging graph structures to enhance the multi-turn instruction following capabilities of LLMs remains unexplored. To bridge this gap, we propose GraphIF, a plug-and-play framework that models multi-turn dialogues as directed relation graphs and leverages graph prompts to enhance the instruction following capabilities of LLMs. GraphIF comprises three key components: (1) an agent-based relation extraction module that captures inter-turn semantic relations via action-triggered mechanisms to construct structured graphs; (2) a relation graph prompt generation module that converts structured graph information into natural language prompts; and (3) a response rewriting module that refines initial LLM outputs using the generated graph prompts. Extensive experiments on two long multi-turn dialogue datasets demonstrate that GraphIF can be seamlessly integrated into instruction-tuned LLMs and leads to significant improvements across all four multi-turn instruction-following evaluation metrics.

</details>


### [41] [ADI-20: Arabic Dialect Identification dataset and models](https://arxiv.org/abs/2511.10070)
*Haroun Elleuch,Salima Mdhaffar,Yannick Estève,Fethi Bougares*

Main category: cs.CL

TL;DR: 本文构建了更全面的新ADI语料库，并用当前主流深度模型进行多因素测试，发现即使减少训练数据，识别准确率下降有限。所有数据与模型均已开源，为相关研究提供了资源支持。


<details>
  <summary>Details</summary>
Motivation: 此前的ADI-17数据集仅涵盖部分阿拉伯语方言，难以满足全面方言识别研究需求。因此，作者扩展至涵盖所有阿拉伯语国家的方言，以推动阿拉伯语方言识别领域的进步。

Method: 作者构建了ADI-20数据集，包含来自19种阿拉伯语方言及现代标准阿拉伯语的3556小时语音数据。利用该数据集，作者训练并评估了不同的方言识别系统，包括微调预训练的ECAPA-TDNN模型，以及结合Whisper编码器和注意力池化及分类层的方法。此外，分析了训练数据规模和模型参数数量对识别性能的影响。

Result: 结果显示，当仅用原训练数据的30%进行模型训练时，F1分数仅有小幅下降，说明模型对数据量的鲁棒性较好。

Conclusion: 作者发布了ADI-20数据集及训练好的模型以支持相关领域复现与进一步研究，并证实先进方法在数据资源受限场景下仍具备较强识别性能。

Abstract: We present ADI-20, an extension of the previously published ADI-17 Arabic Dialect Identification (ADI) dataset. ADI-20 covers all Arabic-speaking countries' dialects. It comprises 3,556 hours from 19 Arabic dialects in addition to Modern Standard Arabic (MSA). We used this dataset to train and evaluate various state-of-the-art ADI systems. We explored fine-tuning pre-trained ECAPA-TDNN-based models, as well as Whisper encoder blocks coupled with an attention pooling layer and a classification dense layer. We investigated the effect of (i) training data size and (ii) the model's number of parameters on identification performance. Our results show a small decrease in F1 score while using only 30% of the original training data. We open-source our collected data and trained models to enable the reproduction of our work, as well as support further research in ADI.

</details>


### [42] [Format Matters: The Robustness of Multimodal LLMs in Reviewing Evidence from Tables and Charts](https://arxiv.org/abs/2511.10075)
*Xanh Ho,Yun-Ang Wu,Sunisth Kumar,Florian Boudin,Atsuhiro Takasu,Akiko Aizawa*

Main category: cs.CL

TL;DR: 多模态大模型在科学结论验证任务上对图表证据理解能力较弱，未来研究应加强图表相关能力的提升，以更好辅助科学审稿。


<details>
  <summary>Details</summary>
Motivation: 科学论文数量激增，审稿需求增加，实验结果作为核心内容格式多样，亟需评估和提升多模态大模型在不同格式证据下对科学结论的验证能力。

Method: 设计并进行系列实验，利用重新标注和结构化的科学论文数据集，对12个多模态大模型进行评估，分别以表格和图表为证据，衡量其科学结论验证能力，并加以人工评测对比。

Result: 当前多模态大模型在表格型证据上表现优于图表型证据；小模型（<8B）在两种证据类型上的表现相关性弱，跨模态泛化能力有限；人工评审在两种格式下均表现优异，揭示了模型在多模态推理上的不足。

Conclusion: 当前的多模态大模型在科学论文的科学结论验证任务上，对于不同的数据表现出能力差异，尤其在图表证据方面表现较弱，需要进一步提升模型的图表理解能力。

Abstract: With the growing number of submitted scientific papers, there is an increasing demand for systems that can assist reviewers in evaluating research claims. Experimental results are a core component of scientific work, often presented in varying formats such as tables or charts. Understanding how robust current multimodal large language models (multimodal LLMs) are at verifying scientific claims across different evidence formats remains an important and underexplored challenge. In this paper, we design and conduct a series of experiments to assess the ability of multimodal LLMs to verify scientific claims using both tables and charts as evidence. To enable this evaluation, we adapt two existing datasets of scientific papers by incorporating annotations and structures necessary for a multimodal claim verification task. Using this adapted dataset, we evaluate 12 multimodal LLMs and find that current models perform better with table-based evidence while struggling with chart-based evidence. We further conduct human evaluations and observe that humans maintain strong performance across both formats, unlike the models. Our analysis also reveals that smaller multimodal LLMs (under 8B) show weak correlation in performance between table-based and chart-based tasks, indicating limited cross-modal generalization. These findings highlight a critical gap in current models' multimodal reasoning capabilities. We suggest that future multimodal LLMs should place greater emphasis on improving chart understanding to better support scientific claim verification.

</details>


### [43] [ELYADATA & LIA at NADI 2025: ASR and ADI Subtasks](https://arxiv.org/abs/2511.10090)
*Haroun Elleuch,Youssef Saidi,Salima Mdhaffar,Yannick Estève,Fethi Bougares*

Main category: cs.CL

TL;DR: 论文提出利用预训练大模型结合微调的方法，在阿拉伯语方言识别和多方言语音转写任务上取得了领先成绩，验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语包含多种方言，语音处理任务（如方言识别和转写）存在挑战。该研究旨在提升多方言阿拉伯语语音处理的准确性和表现。

Method: （1）方言识别（ADI）：使用Whisper-large-v3编码器微调并结合数据增强方法；（2）多方言ASR：采用SeamlessM4T-v2 Large模型，对八种方言分别进行微调。

Result: ADI子任务在官方测试集上取得了79.83%的最高准确率；多方言ASR子任务，平均词错误率（WER）为38.54%，字符错误率（CER）为14.53%。

Conclusion: 针对阿拉伯语语音处理，通过对大型预训练语音模型的针对性微调，能够有效提升方言识别和多方言转写的性能。

Abstract: This paper describes Elyadata \& LIA's joint submission to the NADI multi-dialectal Arabic Speech Processing 2025. We participated in the Spoken Arabic Dialect Identification (ADI) and multi-dialectal Arabic ASR subtasks. Our submission ranked first for the ADI subtask and second for the multi-dialectal Arabic ASR subtask among all participants. Our ADI system is a fine-tuned Whisper-large-v3 encoder with data augmentation. This system obtained the highest ADI accuracy score of \textbf{79.83\%} on the official test set. For multi-dialectal Arabic ASR, we fine-tuned SeamlessM4T-v2 Large (Egyptian variant) separately for each of the eight considered dialects. Overall, we obtained an average WER and CER of \textbf{38.54\%} and \textbf{14.53\%}, respectively, on the test set. Our results demonstrate the effectiveness of large pre-trained speech models with targeted fine-tuning for Arabic speech processing.

</details>


### [44] [On the Military Applications of Large Language Models](https://arxiv.org/abs/2511.10093)
*Satu Johansson,Taneli Riihonen*

Main category: cs.CL

TL;DR: 本文探讨GPT及大型语言模型在军事领域中的应用前景，通过模型自我揭示及云服务构建评估，总结出其生成与总结能力能直接作用于许多军事场景，部分应用可实际实现。


<details>
  <summary>Details</summary>
Motivation: 随着GPT等大型语言模型技术的迅速发展，探索其在军事领域的潜在应用及实现路径，发现其在此领域的可能价值与局限性。

Method: 首先，通过与基于GPT的语言模型（如Microsoft Copilot）进行对话，揭示其对潜在军事应用的了解，并进行批判性评估。其次，研究如何利用商业云服务（如Microsoft Azure）快速构建相关应用，并评估其可行性。

Result: GPT语言模型的总结和生成特性可用于多种军事用途，并且通过云服务可以快速构建部分这样应用，具备一定可行性。

Conclusion: 语言模型的总结和生成能力直接促进了多种军事应用，同时其他特性也有特定用途。

Abstract: In this paper, military use cases or applications and implementation thereof are considered for natural language processing and large language models, which have broken into fame with the invention of the generative pre-trained transformer (GPT) and the extensive foundation model pretraining done by OpenAI for ChatGPT and others. First, we interrogate a GPT-based language model (viz. Microsoft Copilot) to make it reveal its own knowledge about their potential military applications and then critically assess the information. Second, we study how commercial cloud services (viz. Microsoft Azure) could be used readily to build such applications and assess which of them are feasible. We conclude that the summarization and generative properties of language models directly facilitate many applications at large and other features may find particular uses.

</details>


### [45] [Generalizing to Unseen Disaster Events: A Causal View](https://arxiv.org/abs/2511.10120)
*Philipp Seeberger,Steffen Freisinger,Tobias Bocklet,Korbinian Riedhammer*

Main category: cs.CL

TL;DR: 提出基于因果学习的去偏方法，显著提升灾害事件社交媒体数据监测系统的泛化能力和分类表现。


<details>
  <summary>Details</summary>
Motivation: 社交媒体在灾害事件监测中越来越重要，但由于数据量大且事件相关偏差严重，现有系统难以对新兴事件进行泛化，导致灾害信息监测效果受限。近年来去偏与因果学习虽有进展，但在灾害领域应用尚不充分。本文针对该痛点提出新方法。

Method: 采用因果角度进行偏差缓解，提出一种方法以减少事件及领域相关偏差，从而提升模型对未来灾害事件的泛化能力。具体方法提升PLM（预训练语言模型）分类器，在三个灾害分类任务中进行实测。

Result: 所提方法在三个灾害分类任务中，相较多个基线模型F1指标提升最高达+1.9%，对PLM分类器效果有显著提升。

Conclusion: 基于因果视角的偏差缓解方法能有效提升灾害事件社交媒体监测系统对新兴事件的泛化能力，为相关领域去偏、提升模型性能提供新的思路。

Abstract: Due to the rapid growth of social media platforms, these tools have become essential for monitoring information during ongoing disaster events. However, extracting valuable insights requires real-time processing of vast amounts of data. A major challenge in existing systems is their exposure to event-related biases, which negatively affects their ability to generalize to emerging events. While recent advancements in debiasing and causal learning offer promising solutions, they remain underexplored in the disaster event domain. In this work, we approach bias mitigation through a causal lens and propose a method to reduce event- and domain-related biases, enhancing generalization to future events. Our approach outperforms multiple baselines by up to +1.9% F1 and significantly improves a PLM-based classifier across three disaster classification tasks.

</details>


### [46] [Beyond the Black Box: Demystifying Multi-Turn LLM Reasoning with VISTA](https://arxiv.org/abs/2511.10182)
*Yiran Zhang,Mingyang Lin,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: 本文提出了VISTA，一个用于多轮推理任务的可视化交互分析平台，有效降低研究多轮推理过程的难度，开放源码、支持自定义扩展。


<details>
  <summary>Details</summary>
Motivation: 多轮推理更贴近真实问题场景，但分析大语言模型在多轮推理中的复杂推理过程难度大，主要因上下文依赖复杂且缺乏专门的可视化工具，导致研究者负担高。

Method: 提出并实现了一个基于网页的可视化交互系统（VISTA），能够自动解析会话生成推理依赖树，并支持用户对历史对话进行交互式修改和模型对比。

Result: VISTA平台能让用户可视化上下文对模型决策的影响，便捷地进行“假设”分析和模型比较，集成自定义基准及本地模型，开放源码，极大提升了分析效率和透明度。

Conclusion: VISTA平台显著简化了多轮推理链分析过程，帮助研究者更深入理解当前大语言模型的推理能力与局限性。

Abstract: Recent research has increasingly focused on the reasoning capabilities of Large Language Models (LLMs) in multi-turn interactions, as these scenarios more closely mirror real-world problem-solving. However, analyzing the intricate reasoning processes within these interactions presents a significant challenge due to complex contextual dependencies and a lack of specialized visualization tools, leading to a high cognitive load for researchers. To address this gap, we present VISTA, an web-based Visual Interactive System for Textual Analytics in multi-turn reasoning tasks. VISTA allows users to visualize the influence of context on model decisions and interactively modify conversation histories to conduct "what-if" analyses across different models. Furthermore, the platform can automatically parse a session and generate a reasoning dependency tree, offering a transparent view of the model's step-by-step logical path. By providing a unified and interactive framework, VISTA significantly reduces the complexity of analyzing reasoning chains, thereby facilitating a deeper understanding of the capabilities and limitations of current LLMs. The platform is open-source and supports easy integration of custom benchmarks and local models.

</details>


### [47] [Text2SQL-Flow: A Robust SQL-Aware Data Augmentation Framework for Text-to-SQL](https://arxiv.org/abs/2511.10192)
*Qifeng Cai,Hao Liang,Chang Xu,Tao Xie,Wentao Zhang,Bin Cui*

Main category: cs.CL

TL;DR: 本文提出Text2SQL-Flow数据增强框架和SQLFlow高质量数据集，通过多维增强和结构感知检索显著提升了Text-to-SQL模型性能，为该领域提供了可扩展的数据解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的Text-to-SQL任务受限于数据集稀缺、结构单一和多样性不足，影响了模型性能。为了突破这一瓶颈，提高AI系统的数据质量和泛化能力，亟需高质量、结构多样的Text-to-SQL数据增强方法和数据集。

Method: 提出了Text2SQL-Flow框架，通过六个维度的数据增强手段，结合SQL执行验证、自然语言问题生成、链式推理轨迹和数据分类等模块，利用最少的种子数据生成大量、语义有效且结构多样的Text-to-SQL数据对。同时设计了可扩展的数据库管理模块，适配多数据库场景。以此框架构建了SQLFlow数据集。

Result: SQLFlow数据集包含89,544条高质量标注样本。在公开大模型上微调SQLFlow后，表现全面提升；对闭源大模型，提出了结构感知检索方法，利用SQLFlow作为训练和知识库，实现了问题与SQL查询之间的细粒度对齐，实验显示检索效果优于现有方法。

Conclusion: Text2SQL-Flow为Text-to-SQL领域构建了可扩展、高质量的数据支撑体系，通过丰富的数据增强手段和结构化数据集显著提升了相关AI系统性能，显示了高质量结构化数据在现代AI中的关键作用。

Abstract: The data-centric paradigm has become pivotal in AI, especially for Text-to-SQL, where performance is limited by scarce, simplistic, and low-diversity datasets. To address this, we propose Text2SQL-Flow, a SQL-aware data augmentation framework that generates large-scale, semantically valid, and structurally diverse Text-to-SQL pairs from minimal seed data. It operates across six augmentation dimensions and integrates an end-to-end pipeline featuring SQL execution verification, natural language question generation, chain-of-thought reasoning traces, and data classification. A modular Database Manager ensures cross-database compatibility and scalability. Using this framework, we build SQLFlow, a high-quality dataset of 89,544 annotated examples. We evaluate SQLFlow in two settings: (1) For open-source LLMs, fine-tuning on SQLFlow consistently improves performance across benchmarks under the same data budget. (2) For closed-source LLMs, we introduce a masked alignment retrieval method that treats SQLFlow as both knowledge base and training data for the retriever. This enables structure-aware example matching by modeling fine-grained alignments between questions and SQL queries. Experiments show our retrieval strategy outperforms existing methods, underscoring the value of SQLFlow's high-fidelity data and our novel technique. Our work establishes a scalable, data-centric foundation for advancing Text-to-SQL systems and highlights the critical role of high-quality structured data in modern AI.

</details>


### [48] [EffiReason-Bench: A Unified Benchmark for Evaluating and Advancing Efficient Reasoning in Large Language Models](https://arxiv.org/abs/2511.10201)
*Junquan Huang,Haotian Wu,Yubo Gao,Yibo Yan,Junyan Zhang,Yonghua Hei,Song Dai,Jie Zhang,Puay Siew Tan,Xuming Hu*

Main category: cs.CL

TL;DR: 提出EffiReason-Bench统一评测基准与E3-Score新指标，系统分析了高效LLM推理方法，在不同规模和任务下没有最优通用方案，需按场景选择。


<details>
  <summary>Details</summary>
Motivation: CoT提示虽然增强了LLMs推理能力，但会带来冗长解释，浪费算力且有时降低准确率。效率方法评测又因实践碎片化难以公平比较，因此提出统一基准和评价体系。

Method: 构建了EffiReason-Bench统一基准，包括三类高效推理方法的评价——Reasoning Blueprints、Dynamic Execution、Post-hoc Refinement，并对CommonsenseQA和LogiQA数据集进行标准化的CoT注释。实验涵盖7种方法、6个不同规模开源LLM（1B-70B）、覆盖数学、常识、逻辑等数据集。提出了E3-Score评价指标，通过经济权衡建模实现连续、稳定的效率评价。

Result: EffiReason-Bench实现了跨范式有效评测，高效推理方法的选择需依据具体场景。E3-Score提供了更稳定且不依赖启发式的效率衡量。实验发现不同方法在不同模型或任务下效果不同。

Conclusion: 没有任何单一的方法在所有场景下都有最佳表现。最优策略依赖于模型规模、任务复杂性和模型架构。

Abstract: Large language models (LLMs) with Chain-of-Thought (CoT) prompting achieve strong reasoning but often produce unnecessarily long explanations, increasing cost and sometimes reducing accuracy. Fair comparison of efficiency-oriented approaches is hindered by fragmented evaluation practices. We introduce EffiReason-Bench, a unified benchmark for rigorous cross-paradigm evaluation of efficient reasoning methods across three categories: Reasoning Blueprints, Dynamic Execution, and Post-hoc Refinement. To enable step-by-step evaluation, we construct verified CoT annotations for CommonsenseQA and LogiQA via a pipeline that enforces standardized reasoning structures, comprehensive option-wise analysis, and human verification. We evaluate 7 methods across 6 open-source LLMs (1B-70B) on 4 datasets spanning mathematics, commonsense, and logic, and propose the E3-Score, a principled metric inspired by economic trade-off modeling that provides smooth, stable evaluation without discontinuities or heavy reliance on heuristics. Experiments show that no single method universally dominates; optimal strategies depend on backbone scale, task complexity, and architecture.

</details>


### [49] [Persona-Aware Alignment Framework for Personalized Dialogue Generation](https://arxiv.org/abs/2511.10215)
*Guanrong Li,Xinyu Liu,Zhen Wu,Xinyu Dai*

Main category: cs.CL

TL;DR: PAL框架通过全新对齐训练和推理策略显著提升回复与人物设定的相关性，是个性化对话生成领域的重要进展。


<details>
  <summary>Details</summary>
Motivation: 现有主流个性化对话生成方法侧重于Token级语言建模，容易忽视人物设定，导致回复较为通用，缺乏个性。希望提升人物敏感度与回复的一致性。

Method: 提出PAL框架，包括两阶段训练：Persona-aware Learning和Persona Alignment；并设计了Select then Generate推理策略，以提升人物一致性和敏感度。

Result: 经大量实验验证，PAL框架能显著提升回复与人物设定的相关性，表现优于多种主流方法与大模型。

Conclusion: PAL框架在个性化对话生成方面优于众多主流方法和大语言模型，能够生成更契合人物设定的回复。

Abstract: Personalized dialogue generation aims to leverage persona profiles and dialogue history to generate persona-relevant and consistent responses. Mainstream models typically rely on token-level language model training with persona dialogue data, such as Next Token Prediction, to implicitly achieve personalization, making these methods tend to neglect the given personas and generate generic responses. To address this issue, we propose a novel Persona-Aware Alignment Framework (PAL), which directly treats persona alignment as the training objective of dialogue generation. Specifically, PAL employs a two-stage training method including Persona-aware Learning and Persona Alignment, equipped with an easy-to-use inference strategy Select then Generate, to improve persona sensitivity and generate more persona-relevant responses at the semantics level. Through extensive experiments, we demonstrate that our framework outperforms many state-of-the-art personalized dialogue methods and large language models.

</details>


### [50] [LangGPS: Language Separability Guided Data Pre-Selection for Joint Multilingual Instruction Tuning](https://arxiv.org/abs/2511.10229)
*Yangfan Ye,Xiaocheng Feng,Xiachong Feng,Lei Huang,Weitao Ma,Qichen Hong,Yunfei Lu,Duyu Tang,Dandan Tu,Bing Qin*

Main category: cs.CL

TL;DR: 论文提出基于语言分离性的LangGPS预筛选框架，融合现有方法显著提升多语言大模型的训练效果，尤其在理解任务和低资源语种表现突出，为多语言数据选择和课程学习提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 当前多语言大模型的多语言能力高度依赖训练数据选择，而现有方法忽略了多语言数据的语言内部结构，故亟需更有效的数据筛选方法以提升跨语种能力。

Method: 提出了LangGPS，两阶段的预筛选流程：首先以模型表征中的语言分离性分数过滤训练数据，在此基础上再用现有筛选方法精炼子集，并在六个基准、22种语言上做了对比实验与分析。

Result: 实验表明LangGPS在理解类任务和低资源语种上提升显著，高分离性样本建立清晰语言边界、促进快速适应，低分离性样本有助于跨语种对齐。同时分离性在多语言课程学习中展现出有效信号，带来稳定泛化收益。

Conclusion: 结合语言分离性的新预筛选框架LangGPS能提升多语言大模型的训练效果、适应性及泛化能力，并为多语言课程式学习提供了新的视角。

Abstract: Joint multilingual instruction tuning is a widely adopted approach to improve the multilingual instruction-following ability and downstream performance of large language models (LLMs), but the resulting multilingual capability remains highly sensitive to the composition and selection of the training data. Existing selection methods, often based on features like text quality, diversity, or task relevance, typically overlook the intrinsic linguistic structure of multilingual data. In this paper, we propose LangGPS, a lightweight two-stage pre-selection framework guided by language separability which quantifies how well samples in different languages can be distinguished in the model's representation space. LangGPS first filters training data based on separability scores and then refines the subset using existing selection methods. Extensive experiments across six benchmarks and 22 languages demonstrate that applying LangGPS on top of existing selection methods improves their effectiveness and generalizability in multilingual training, especially for understanding tasks and low-resource languages. Further analysis reveals that highly separable samples facilitate the formation of clearer language boundaries and support faster adaptation, while low-separability samples tend to function as bridges for cross-lingual alignment. Besides, we also find that language separability can serve as an effective signal for multilingual curriculum learning, where interleaving samples with diverse separability levels yields stable and generalizable gains. Together, we hope our work offers a new perspective on data utility in multilingual contexts and support the development of more linguistically informed LLMs.

</details>


### [51] [VocalNet-M2: Advancing Low-Latency Spoken Language Modeling via Integrated Multi-Codebook Tokenization and Multi-Token Prediction](https://arxiv.org/abs/2511.10232)
*Yuhao Wang,Ziyang Cheng,Heyang Liu,Ronghua Wu,Qunshan Gu,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: VocalNet-M2通过多代码本与多token策略显著降低语音生成延迟，提升实时应用体验，同时保持语音模型主流性能水平。


<details>
  <summary>Details</summary>
Motivation: 现有端到端口语模型SLM存在响应延迟问题，主要源自自回归语音token生成和流匹配模型依赖。为实时交互场景提升效率与体验，迫切需降低延迟。

Method: 引入多代码本分词器，以及多token预测(MTP)策略，直接生成多代码本语音token，绕过了复杂的流匹配模型。通过实验比较单代码本与多代码本方案内容。

Result: 首块语音响应延迟从约725ms降至350ms，整体性能仍具竞争力。比较单与多代码本方案并优选新的高效实时生成架构。

Conclusion: VocalNet-M2在保证主流SLM性能的同时，大幅降低了响应延迟，尤其是首个语音块的生成延迟。多代码本与多token预测策略为实时交互应用提供了新思路。

Abstract: Current end-to-end spoken language models (SLMs) have made notable progress, yet they still encounter considerable response latency. This delay primarily arises from the autoregressive generation of speech tokens and the reliance on complex flow-matching models for speech synthesis. To overcome this, we introduce VocalNet-M2, a novel low-latency SLM that integrates a multi-codebook tokenizer and a multi-token prediction (MTP) strategy. Our model directly generates multi-codebook speech tokens, thus eliminating the need for a latency-inducing flow-matching model. Furthermore, our MTP strategy enhances generation efficiency and improves overall performance. Extensive experiments demonstrate that VocalNet-M2 achieves a substantial reduction in first chunk latency (from approximately 725ms to 350ms) while maintaining competitive performance across mainstream SLMs. This work also provides a comprehensive comparison of single-codebook and multi-codebook strategies, offering valuable insights for developing efficient and high-performance SLMs for real-time interactive applications.

</details>


### [52] [MTR-DuplexBench: Towards a Comprehensive Evaluation of Multi-Round Conversations for Full-Duplex Speech Language Models](https://arxiv.org/abs/2511.10262)
*He Zhang,Wenqian Cui,Haoning Xu,Xiaohui Li,Lei Zhu,Shaohua Ma,Irwin King*

Main category: cs.CL

TL;DR: 提出多轮全双工评测基准MTR-DuplexBench，发现现有模型难以胜任复杂多轮任务，新基准可促进相关研究进步。


<details>
  <summary>Details</summary>
Motivation: 现有的全双工语音语言模型评估只关注单轮交互和对话特征，忽略了多轮通信中的复杂性以及指令理解和安全等关键能力。如何系统评测FD-SLMs在多轮对话中的表现仍缺乏合适工具。

Method: 提出MTR-DuplexBench基准，通过将连续的全双工对话切分为可评估的离散轮次，实现FD-SLMs在多个维度下（对话质量、动态性、指令完成、安全）的全面逐轮评估。

Result: 实验显示，当前FD-SLM在多轮多维表现上仍有较大挑战，难以持续保持对话一致性和性能。

Conclusion: MTR-DuplexBench有效弥补了FD-SLM评测的缺口，可推动模型在更复杂对话场景下的发展。

Abstract: Full-Duplex Speech Language Models (FD-SLMs) enable real-time, overlapping conversational interactions, offering a more dynamic user experience compared to traditional half-duplex models. However, existing benchmarks primarily focus on evaluating single-round interactions and conversational features, neglecting the complexities of multi-round communication and critical capabilities such as instruction following and safety. Evaluating FD-SLMs in multi-round settings poses significant challenges, including blurred turn boundaries in communication and context inconsistency during model inference. To address these gaps, we introduce MTR-DuplexBench, a novel benchmark that segments continuous full-duplex dialogues into discrete turns, enabling comprehensive, turn-by-turn evaluation of FD-SLMs across dialogue quality, conversational dynamics, instruction following, and safety. Experimental results reveal that current FD-SLMs face difficulties in maintaining consistent performance across multiple rounds and evaluation dimensions, highlighting the necessity and effectiveness of our proposed benchmark. The benchmark and code will be available in the future.

</details>


### [53] [Local Hybrid Retrieval-Augmented Document QA](https://arxiv.org/abs/2511.10297)
*Paolo Astrino*

Main category: cs.CL

TL;DR: 利用本地基础设施，通过结合语义和关键词检索策略，企业可实现安全、高效的文档问答，无需牺牲隐私。


<details>
  <summary>Details</summary>
Motivation: 为解决企业在敏感文档处理时，云端AI高准确率但隐私受损与本地处理安全但性能不足的两难问题。

Method: 提出并实现了一种结合语义理解与关键词精确性的本地问答系统，无需互联网接入，仅依靠现有消费级硬件加速。

Result: 新系统可在法律、科学和日常文档复杂问答任务中，实现与云端相当或更优的准确性，所有数据本地存储，不对外泄露。

Conclusion: 本研究证明了在企业AI应用中，隐私与性能并非不可兼得。

Abstract: Organizations handling sensitive documents face a critical dilemma: adopt cloud-based AI systems that offer powerful question-answering capabilities but compromise data privacy, or maintain local processing that ensures security but delivers poor accuracy. We present a question-answering system that resolves this trade-off by combining semantic understanding with keyword precision, operating entirely on local infrastructure without internet access. Our approach demonstrates that organizations can achieve competitive accuracy on complex queries across legal, scientific, and conversational documents while keeping all data on their machines. By balancing two complementary retrieval strategies and using consumer-grade hardware acceleration, the system delivers reliable answers with minimal errors, letting banks, hospitals, and law firms adopt conversational document AI without transmitting proprietary information to external providers. This work establishes that privacy and performance need not be mutually exclusive in enterprise AI deployment.

</details>


### [54] [Rectify Evaluation Preference: Improving LLMs' Critique on Math Reasoning via Perplexity-aware Reinforcement Learning](https://arxiv.org/abs/2511.10303)
*Changyuan Tian,Zhicong Lu,Shuang Qian,Nayu Liu,Peiguang Li,Li Jin,Leiyi Hu,Zhizhao Zeng,Sirui Wang,Ke Zeng,Zhi Guo*

Main category: cs.CL

TL;DR: 分析了大模型多步数学推理中评判偏好问题，提出复杂度感知的强化学习算法纠偏，在多个基准上有效提升了批判能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大模型在多步数学推理中的批判能力有限，主要依赖高质量示例进行监督微调，但忽略了性能不佳的根本原因，尤其是评判偏好失衡。

Method: 提出了一种全新基于复杂度感知的强化学习算法（perplexity-aware RL），通过OPSO数据集研究大模型自我与他人解答评判行为，深入分析困惑度相关的评判偏好，并用Group Relative Policy Optimization方法纠正这种偏差。

Result: 实验表明，新方法在自建OPS数据集和现有评判基准上的表现优于传统方法，显著提升了大模型的批判性评判能力。

Conclusion: 通过定量分析和复杂度感知强化学习纠正评判偏好，显著提升了大模型在多步数学推理中的批判表现，为自动采集可扩展监督提供了新思路。

Abstract: To improve Multi-step Mathematical Reasoning (MsMR) of Large Language Models (LLMs), it is crucial to obtain scalable supervision from the corpus by automatically critiquing mistakes in the reasoning process of MsMR and rendering a final verdict of the problem-solution. Most existing methods rely on crafting high-quality supervised fine-tuning demonstrations for critiquing capability enhancement and pay little attention to delving into the underlying reason for the poor critiquing performance of LLMs. In this paper, we orthogonally quantify and investigate the potential reason -- imbalanced evaluation preference, and conduct a statistical preference analysis. Motivated by the analysis of the reason, a novel perplexity-aware reinforcement learning algorithm is proposed to rectify the evaluation preference, elevating the critiquing capability. Specifically, to probe into LLMs' critiquing characteristics, a One-to-many Problem-Solution (OPS) benchmark is meticulously constructed to quantify the behavior difference of LLMs when evaluating the problem solutions generated by itself and others. Then, to investigate the behavior difference in depth, we conduct a statistical preference analysis oriented on perplexity and find an intriguing phenomenon -- ``LLMs incline to judge solutions with lower perplexity as correct'', which is dubbed as \textit{imbalanced evaluation preference}. To rectify this preference, we regard perplexity as the baton in the algorithm of Group Relative Policy Optimization, supporting the LLMs to explore trajectories that judge lower perplexity as wrong and higher perplexity as correct. Extensive experimental results on our built OPS and existing available critic benchmarks demonstrate the validity of our method.

</details>


### [55] [BhashaKritika: Building Synthetic Pretraining Data at Scale for Indic Languages](https://arxiv.org/abs/2511.10338)
*Guduru Manoj,Neel Prabhanjan Rachamalla,Ashish Kulkarni,Gautam Rajeev,Jay Piplodiya,Arul Menezes,Shaharukh Khan,Souvik Rana,Manya Sah,Chandra Khatri,Shubham Agarwal*

Main category: cs.CL

TL;DR: 本论文系统研究了印度语系合成多语预训练数据的生成与评估，构建了5400亿词符的大规模数据集，提出了多维度数据质量管控体系。实验揭示了不同生成策略的权衡，并分享了高效创建多语语料库的实践方法，对提升低资源语言LLM预训练数据提供了重要参考。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型的预训练依赖高质量大规模数据，且在低资源语言环境下无法均衡享受LLM技术红利，论文旨在为印度语系等低资源语言提供优质合成多语预训练数据方案。

Method: 构建5400亿token印度语系合成数据集BhashaKritika，涵盖10种语言，采用5种合成技术，并在生成过程中结合文本、人物角色和话题以提升语料多样性。设计了脚本和语言检测、元数据一致性、n-gram重复分析、KenLM复杂度过滤结合的模块化质量评估体系，以实现跨语种和文体的高效数据质量管控。比较包括英文翻译和印度语原生内容生成的不同策略效果；

Result: 实证结果揭示多种生成策略之间的关键权衡，并提出构建有效多语语料库的最佳实践。

Conclusion: 展示了合成多语预训练数据的生成与评估体系，并证实其能够兼顾多语言环境下数据的规模、质量与多样性，为低资源语言领域LLM预训练数据构建提供了切实可行的新思路和范例。

Abstract: In the context of pretraining of Large Language Models (LLMs), synthetic data has emerged as an alternative for generating high-quality pretraining data at scale. This is particularly beneficial in low-resource language settings where the benefits of recent LLMs have been unevenly distributed across languages. In this work, we present a systematic study on the generation and evaluation of synthetic multilingual pretraining data for Indic languages, where we construct a large-scale synthetic dataset BhashaKritika, comprising 540B tokens using 5 different techniques for 10 languages. We explore the impact of grounding generation in documents, personas, and topics. We analyze how language choice, both in the prompt instructions and document grounding, affects data quality, and we compare translations of English content with native generation in Indic languages. To support scalable and language-sensitive evaluation, we introduce a modular quality evaluation pipeline that integrates script and language detection, metadata consistency checks, n-gram repetition analysis, and perplexity-based filtering using KenLM models. Our framework enables robust quality control across diverse scripts and linguistic contexts. Empirical results through model runs reveal key trade-offs in generation strategies and highlight best practices for constructing effective multilingual corpora.

</details>


### [56] [Knowledge Graphs Generation from Cultural Heritage Texts: Combining LLMs and Ontological Engineering for Scholarly Debates](https://arxiv.org/abs/2511.10354)
*Andrea Schimmenti,Valentina Pasqual,Fabio Vitali,Marieke van Erp*

Main category: cs.CL

TL;DR: 本文提出ATR4CH五步法，基于大语言模型自动将文化遗产文本转为结构化知识图谱，在维基百科案例中多项指标表现优异，可广泛复用，但需人工监督后处理。


<details>
  <summary>Details</summary>
Motivation: 文化遗产文本蕴含丰富知识，但由于语言结构非结构化，难以系统性地转化为可查询的知识图谱。面对这一挑战，亟需构建高效方法实现知识提取与结构化。

Method: 提出ATR4CH：一个基于大语言模型的五步法体系，包括基础分析、注释方案设计、流程架构、集成优化、系统评估。结合本体框架与LLM模型，通过三大语言模型顺序处理文化遗产文本，形成结构化知识并进行性能评估。

Result: ATR4CH能高效提取文化遗产知识，如元数据提取F1达0.96-0.99、实体识别0.7-0.8、假设提取0.65-0.75、证据提取0.95-0.97、话语结构表示G-EVAL为0.62。小模型表现较好，具有成本优势。

Conclusion: ATR4CH是首个协调LLM与文化遗产本体结合的系统化知识抽取流程，框架可适配不同领域，具备复用性，但当前知识图谱仅限于维基百科文本，后处理仍需人工参与。对文化遗产机构有实际意义，可自动结构化存量知识。

Abstract: Cultural Heritage texts contain rich knowledge that is difficult to query systematically due to the challenges of converting unstructured discourse into structured Knowledge Graphs (KGs). This paper introduces ATR4CH (Adaptive Text-to-RDF for Cultural Heritage), a systematic five-step methodology for Large Language Model-based Knowledge Extraction from Cultural Heritage documents. We validate the methodology through a case study on authenticity assessment debates. Methodology - ATR4CH combines annotation models, ontological frameworks, and LLM-based extraction through iterative development: foundational analysis, annotation schema development, pipeline architecture, integration refinement, and comprehensive evaluation. We demonstrate the approach using Wikipedia articles about disputed items (documents, artifacts...), implementing a sequential pipeline with three LLMs (Claude Sonnet 3.7, Llama 3.3 70B, GPT-4o-mini). Findings - The methodology successfully extracts complex Cultural Heritage knowledge: 0.96-0.99 F1 for metadata extraction, 0.7-0.8 F1 for entity recognition, 0.65-0.75 F1 for hypothesis extraction, 0.95-0.97 for evidence extraction, and 0.62 G-EVAL for discourse representation. Smaller models performed competitively, enabling cost-effective deployment. Originality - This is the first systematic methodology for coordinating LLM-based extraction with Cultural Heritage ontologies. ATR4CH provides a replicable framework adaptable across CH domains and institutional resources. Research Limitations - The produced KG is limited to Wikipedia articles. While the results are encouraging, human oversight is necessary during post-processing. Practical Implications - ATR4CH enables Cultural Heritage institutions to systematically convert textual knowledge into queryable KGs, supporting automated metadata enrichment and knowledge discovery.

</details>


### [57] [TruthfulRAG: Resolving Factual-level Conflicts in Retrieval-Augmented Generation with Knowledge Graphs](https://arxiv.org/abs/2511.10375)
*Shuyi Liu,Yuming Shang,Xi Zhang*

Main category: cs.CL

TL;DR: 本文首次引入知识图谱以解决RAG系统内外知识冲突，通过结构化冲突检测和过滤，大幅提升其生成结果的准确性和信任度。


<details>
  <summary>Details</summary>
Motivation: 由于RAG系统要结合外部检索知识和模型自身知识，但两者可能存在知识冲突，尤其在知识密集任务中现有方法解决冲突的粒度有限，容易导致生成内容不准确。

Method: 提出TruthfulRAG框架，利用知识图谱(KG)解决RAG系统中的事实级知识冲突。具体包括从检索内容中系统性提取三元组构建KG、基于查询的图检索定位相关知识，并结合熵过滤机制精确定位冲突元素。

Result: TruthfulRAG通过实验证明优于现有方法，能够有效缓解知识冲突，提升RAG系统的鲁棒性和可信度。

Conclusion: 将知识图谱引入RAG系统进行事实级冲突检测与缓解，可以有效提升生成内容的准确性和可靠性。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful framework for enhancing the capabilities of Large Language Models (LLMs) by integrating retrieval-based methods with generative models. As external knowledge repositories continue to expand and the parametric knowledge within models becomes outdated, a critical challenge for RAG systems is resolving conflicts between retrieved external information and LLMs' internal knowledge, which can significantly compromise the accuracy and reliability of generated content. However, existing approaches to conflict resolution typically operate at the token or semantic level, often leading to fragmented and partial understanding of factual discrepancies between LLMs' knowledge and context, particularly in knowledge-intensive tasks. To address this limitation, we propose TruthfulRAG, the first framework that leverages Knowledge Graphs (KGs) to resolve factual-level knowledge conflicts in RAG systems. Specifically, TruthfulRAG constructs KGs by systematically extracting triples from retrieved content, utilizes query-based graph retrieval to identify relevant knowledge, and employs entropy-based filtering mechanisms to precisely locate conflicting elements and mitigate factual inconsistencies, thereby enabling LLMs to generate faithful and accurate responses. Extensive experiments reveal that TruthfulRAG outperforms existing methods, effectively alleviating knowledge conflicts and improving the robustness and trustworthiness of RAG systems.

</details>


### [58] [Position: On the Methodological Pitfalls of Evaluating Base LLMs for Reasoning](https://arxiv.org/abs/2511.10381)
*Jason Chan,Zhixue Zhao,Robert Gaizauskas*

Main category: cs.CL

TL;DR: 本文认为，当前对基础语言模型推理能力的评估方法存在严重方法论缺陷，其输出可能仅是对语言模式的模仿而非真正推理，相关结论难以泛化至优化后的模型。建议今后研究需深入分析这些问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究通过评估基础大型语言模型（LLMs）的推理能力，揭示其局限性与人类类似的偏见。这些研究通常在模型仅通过无标签语料预训练的基础上进行推理评估。本文批判性地指出，这种评估方式存在被忽视的方法论问题。

Method: 作者通过分析基础LLMs的预训练目标与评估推理时采用的规范标准（如正确性）之间的基本不匹配，探讨其影响；并论证基础LLMs的逻辑输出实际是遵循语言统计模式而非真实推理能力的产物。

Result: 得出基础LLMs生成的结论不能被视为真实推理尝试；同时，从基础LLMs推理能力的结论无法直接推断至已经优化过的后训练LLMs。对依赖这类假设的现有工作需要重新审视，未来研究必须补足这些方法论缺陷。

Conclusion: 评估基础LLMs推理能力的方法存在根本性问题，应重新审视相关研究；后续研究在推理评估时需关注模型训练目标与评估标准间的差异。

Abstract: Existing work investigates the reasoning capabilities of large language models (LLMs) to uncover their limitations, human-like biases and underlying processes. Such studies include evaluations of base LLMs (pre-trained on unlabeled corpora only) for this purpose. Our position paper argues that evaluating base LLMs' reasoning capabilities raises inherent methodological concerns that are overlooked in such existing studies. We highlight the fundamental mismatch between base LLMs' pretraining objective and normative qualities, such as correctness, by which reasoning is assessed. In particular, we show how base LLMs generate logically valid or invalid conclusions as coincidental byproducts of conforming to purely linguistic patterns of statistical plausibility. This fundamental mismatch challenges the assumptions that (a) base LLMs' outputs can be assessed as their bona fide attempts at correct answers or conclusions; and (b) conclusions about base LLMs' reasoning can generalize to post-trained LLMs optimized for successful instruction-following. We call for a critical re-examination of existing work that relies implicitly on these assumptions, and for future work to account for these methodological pitfalls.

</details>


### [59] [DELICATE: Diachronic Entity LInking using Classes And Temporal Evidence](https://arxiv.org/abs/2511.10404)
*Cristian Santini,Sebastian Barzaghi,Paolo Sernani,Emanuele Frontoni,Mehwish Alam*

Main category: cs.CL

TL;DR: 该论文针对人文学科中的实体链接难题，提出了结合神经与符号推理的DELICATE方法和历史意大利语多领域语料库ENEIDE。实验结果显示，DELICATE优于其它模型且结果更具解释性，对人文学科EL任务具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 实体链接在自然语言处理领域中仍然具有挑战性，尤其是在人文领域，因文档类型复杂、缺乏特定领域数据集和模型，以及知识库中实体代表性不足（尤其是长尾实体）。该论文旨在解决这些问题。

Method: 提出了DELICATE方法，一种基于神经符号的历史意大利语实体链接方法，结合BERT编码器和Wikidata的上下文信息，通过时间合理性和实体类型一致性来选择合适的知识库实体。同时，构建了ENEIDE语料库，涵盖19-20世纪文学和政治文本。

Result: DELICATE方法在历史意大利语领域的实体链接任务中超越了其它模型，即便与参数规模更大的架构比较也表现更佳。同时，DELICATE的置信分和特征敏感性使结果更可解释、更易理解。

Conclusion: DELICATE显著提升了历史意大利语中的实体链接效果，并通过神经符号结合，增强了模型的可解释性，为人文学科中的实体链接任务提供了有效解决方案。

Abstract: In spite of the remarkable advancements in the field of Natural Language Processing, the task of Entity Linking (EL) remains challenging in the field of humanities due to complex document typologies, lack of domain-specific datasets and models, and long-tail entities, i.e., entities under-represented in Knowledge Bases (KBs). The goal of this paper is to address these issues with two main contributions. The first contribution is DELICATE, a novel neuro-symbolic method for EL on historical Italian which combines a BERT-based encoder with contextual information from Wikidata to select appropriate KB entities using temporal plausibility and entity type consistency. The second contribution is ENEIDE, a multi-domain EL corpus in historical Italian semi-automatically extracted from two annotated editions spanning from the 19th to the 20th century and including literary and political texts. Results show how DELICATE outperforms other EL models in historical Italian even if compared with larger architectures with billions of parameters. Moreover, further analyses reveal how DELICATE confidence scores and features sensitivity provide results which are more explainable and interpretable than purely neural methods.

</details>


### [60] [Analogical Structure, Minimal Contextual Cues and Contrastive Distractors: Input Design for Sample-Efficient Linguistic Rule Induction](https://arxiv.org/abs/2511.10441)
*Chunyang Jiang,Paola Merlo*

Main category: cs.CL

TL;DR: 类比范式组织结合对比机制，可令轻量模型用极少数据实现高效语言规则学习，效果超越大模型零样本，方法泛化性强。


<details>
  <summary>Details</summary>
Motivation: 探索是否能通过类比范式组织，使参数量远小于大型语言模型的轻量模型，在只用极少数据训练时，达到媲美甚至超越大模型的表现。

Method: 提出了一种结合类比结构、对比学习与最小上下文提示的计算方法。利用BERT+CNN结构的轻量模型，在结构化补全任务中测试模型对类比模式和对比替代项的辨识能力。进行消融实验和跨现象验证。

Result: BERT+CNN模型仅用100个结构化例子训练，在英语致使/自发交替任务中取得F1=0.95，优于GPT-3零样本（F1=0.87）。消融实验证明类比和对比结构有重要提升作用，跨现象验证也重现了这一高效性。

Conclusion: 类比范式组织可以使轻量模型在极少数据下实现类似大型语言模型的表现，甚至超越零样本的GPT-3。该方法在多架构和多语言现象的跨验证中均表现稳健。

Abstract: Large language models achieve strong performance through training on vast datasets. Can analogical paradigm organization enable lightweight models to match this performance with minimal data? We develop a computational approach implementing three cognitive-inspired principles: analogical structure, contrastive learning, and minimal contextual cues. We test this approach with structured completion tasks where models identify correct sentence completions from analogical patterns with contrastive alternatives. Training lightweight models (BERT+CNN, $0.5M$ parameters) on only one hundred structured examples of English causative/inchoative alternations achieves $F1=0.95$, outperforming zero-shot \texttt{GPT-o3} ($F1=0.87$). Ablation studies confirm that analogical organization and contrastive structure improve performance, consistently surpassing randomly shuffled baselines across architectures. Cross-phenomenon validation using unspecified object alternations replicates these efficiency gains, confirming approach robustness. Our results show that analogical paradigm organization enables competitive linguistic rule learning with orders of magnitude less data than conventional approaches require.

</details>


### [61] [Reasoning About Intent for Ambiguous Requests](https://arxiv.org/abs/2511.10453)
*Irina Saparina,Mirella Lapata*

Main category: cs.CL

TL;DR: 针对语言模型对用户模糊请求易单一解读的问题，作者提出用强化学习训练模型生成多种解释与答案，显著提升答案覆盖面和透明性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在应对模糊请求时容易误解用户意图，仅给出一种解释，进而导致用户困惑和安全风险。研究旨在解决该问题。

Method: 采用强化学习和定制奖励函数训练模型，让其针对模糊指令生成带有多种解释及答案的结构化响应。

Result: 实验表明，比基线方法更全面地覆盖有效答案。人类评估显示模型预测的解释与答案高度对应。此外，该方法提升透明性与效率，并便于下游应用集成。

Conclusion: 提出的方法能够更好地覆盖有效答案，提升人类用户对模型输出的理解和透明度。

Abstract: Large language models often respond to ambiguous requests by implicitly committing to one interpretation. Intent misunderstandings can frustrate users and create safety risks. To address this, we propose generating multiple interpretation-answer pairs in a single structured response to ambiguous requests. Our models are trained with reinforcement learning and customized reward functions using multiple valid answers as supervision. Experiments on conversational question answering and semantic parsing demonstrate that our method achieves higher coverage of valid answers than baseline approaches. Human evaluation confirms that predicted interpretations are highly aligned with their answers. Our approach promotes transparency with explicit interpretations, achieves efficiency by requiring only one generation step, and supports downstream applications through its structured output format.

</details>


### [62] [Exploring State Tracking Capabilities of Large Language Models](https://arxiv.org/abs/2511.10457)
*Kiamehr Rezaee,Jose Camacho-Collados,Mohammad Taher Pilehvar*

Main category: cs.CL

TL;DR: 本文设定状态追踪任务，提出基准与实验，发现新一代LLMs（如GPT-4、Llama3）能持续、有效追踪复杂状态，特别是在引入Chain of Thought机制情况下，而旧模型难以应对长期状态追踪。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂任务（包括需要推理的任务）中表现出色，但其在“状态追踪”任务中的具体能力还不明确。作者为剖析和评估此能力，设计了特定基准与实验。

Method: 提出了基于三种明确定义的状态追踪任务的基准，并在多种场景下分析了不同代际的LLM表现，尤其对比了GPT-4、Llama3与旧一代模型。同时测试了如Chain of Thought等机制对性能的影响。

Result: 新一代模型（GPT-4，Llama3）能较好完成状态追踪任务，尤其结合Chain of Thought机制时表现更佳。旧一代模型虽然能理解任务、初始表现不错，但随着任务步数增加性能明显下降。

Conclusion: 最新的大语言模型具备有效的状态追踪能力，尤其在有理由机制辅助时显著优于旧一代模型。现有模型发展有助于解决需要持续“记忆”和推理的复杂任务。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in solving complex tasks, including those requiring a certain level of reasoning. In this paper, we focus on state tracking, a problem where models need to keep track of the state governing a number of entities. To isolate the state tracking component from other factors, we propose a benchmark based on three well-defined state tracking tasks and analyse the performance of LLMs in different scenarios. The results indicate that the recent generation of LLMs (specifically, GPT-4 and Llama3) are capable of tracking state, especially when integrated with mechanisms such as Chain of Thought. However, models from the former generation, while understanding the task and being able to solve it at the initial stages, often fail at this task after a certain number of steps.

</details>


### [63] [LocalBench: Benchmarking LLMs on County-Level Local Knowledge and Reasoning](https://arxiv.org/abs/2511.10459)
*Zihan Gao,Yifei Xu,Jacob Thebault-Spieker*

Main category: cs.CL

TL;DR: 本文提出LocalBench基准，用来系统衡量大型语言模型在美国县级本地知识上的表现。实验显示主流模型本地推理能力弱，网络增强和模型规模提升未必有益，凸显需开发更能理解地方现实的AI。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在全球或区域性地理任务上的表现虽已被广泛评估，但在处理社区级别的、细粒度本地知识方面，却缺乏深入理解。而现实世界应用，如公民平台和社区新闻，越来越需要能理解和推理本地动态、文化及治理的AI系统。然而，目前的评测基准往往过于粗糙，未能全面反映本地复杂性。

Method: 本文提出LocalBench——首个系统性评估LLM在美国县级本地知识上的基准。LocalBench包含14,782个经验证的问题-答案对，覆盖美国49个州的526个县，数据来源多样，包括人口普查、地方Reddit讨论和区域新闻，涉及地方性物理、认知和关系维度。利用LocalBench，作者在闭卷和增强Web访问两类设置下，对13种主流LLM进行测试。

Result: 实验发现，即便是表现最好的模型在叙事类问题上准确率仅达56.8%，在数字推理上低于15.5%。更大的模型或网络增强并不总带来性能提升。例如，Search功能能使Gemini的准确率提升13.6%，但GPT系列却下降11.4%。

Conclusion: 现有LLM在支持公平、关注本地实际需求的AI系统方面存在显著不足。提升模型对细致本地知识的掌握能力对于解决不同社区地理和文化语境下的各种问题至关重要。

Abstract: Large language models (LLMs) have been widely evaluated on macro-scale geographic tasks, such as global factual recall, event summarization, and regional reasoning. Yet, their ability to handle hyper-local knowledge remains poorly understood. This gap is increasingly consequential as real-world applications, from civic platforms to community journalism, demand AI systems that can reason about neighborhood-specific dynamics, cultural narratives, and local governance. Existing benchmarks fall short in capturing this complexity, often relying on coarse-grained data or isolated references. We present LocalBench, the first benchmark designed to systematically evaluate LLMs on county-level local knowledge across the United States. Grounded in the Localness Conceptual Framework, LocalBench includes 14,782 validated question-answer pairs across 526 U.S. counties in 49 states, integrating diverse sources such as Census statistics, local subreddit discourse, and regional news. It spans physical, cognitive, and relational dimensions of locality. Using LocalBench, we evaluate 13 state-of-the-art LLMs under both closed-book and web-augmented settings. Our findings reveal critical limitations: even the best-performing models reach only 56.8% accuracy on narrative-style questions and perform below 15.5% on numerical reasoning. Moreover, larger model size and web augmentation do not guarantee better performance, for example, search improves Gemini's accuracy by +13.6%, but reduces GPT-series performance by -11.4%. These results underscore the urgent need for language models that can support equitable, place-aware AI systems: capable of engaging with the diverse, fine-grained realities of local communities across geographic and cultural contexts.

</details>


### [64] [Beyond Elicitation: Provision-based Prompt Optimization for Knowledge-Intensive Tasks](https://arxiv.org/abs/2511.10465)
*Yunzhe Xu,Zhuosheng Zhang,Zhe Liu*

Main category: cs.CL

TL;DR: KPPO框架将提示优化转变为知识整合，显著提升知识密集型任务性能，并优化token消耗。


<details>
  <summary>Details</summary>
Motivation: 当前针对语言模型性能提升的提示优化大多关注于挖掘模型潜力，而对于知识密集型任务由于依赖于固定参数，难以有效集成事实知识和专业术语，存在显著局限性。

Method: 提出了知识提供型提示优化（KPPO）框架，把提示优化转化为系统性知识整合，包括知识缺口填补机制、批量候选评价方法和自适应知识修剪策略。

Result: 在15个知识密集型领域基准任务上，KPPO相较传统方法平均性能提升约6%，同时令token消耗相当或更低，最高可减少29%的token用量。

Conclusion: KPPO通过有效整合领域知识，突破了现有提示优化面向知识任务时的局限，可实现更强性能和更高token效率。

Abstract: While prompt optimization has emerged as a critical technique for enhancing language model performance, existing approaches primarily focus on elicitation-based strategies that search for optimal prompts to activate models' capabilities. These methods exhibit fundamental limitations when addressing knowledge-intensive tasks, as they operate within fixed parametric boundaries rather than providing the factual knowledge, terminology precision, and reasoning patterns required in specialized domains. To address these limitations, we propose Knowledge-Provision-based Prompt Optimization (KPPO), a framework that reformulates prompt optimization as systematic knowledge integration rather than potential elicitation. KPPO introduces three key innovations: 1) a knowledge gap filling mechanism for knowledge gap identification and targeted remediation; 2) a batch-wise candidate evaluation approach that considers both performance improvement and distributional stability; 3) an adaptive knowledge pruning strategy that balances performance and token efficiency, reducing up to 29% token usage. Extensive evaluation on 15 knowledge-intensive benchmarks from various domains demonstrates KPPO's superiority over elicitation-based methods, with an average performance improvement of ~6% over the strongest baseline while achieving comparable or lower token consumption. Code at: https://github.com/xyz9911/KPPO.

</details>


### [65] [Rubric-Based Benchmarking and Reinforcement Learning for Advancing LLM Instruction Following](https://arxiv.org/abs/2511.10507)
*Yun He,Wenzhe Li,Hejia Zhang,Songlin Li,Karishma Mandyam,Sopan Khosla,Yuanhao Xiong,Nanshu Wang,Selina Peng,Beibin Li,Shengjie Bi,Shishir G. Patil,Qi Qi,Shengyu Feng,Julian Katz-Samuels,Richard Yuanzhe Pang,Sujan Gonugondla,Hunter Lang,Yue Yu,Yundi Qian,Maryam Fazel-Zarandi,Licheng Yu,Amine Benhalloum,Hany Awadalla,Manaal Faruqui*

Main category: cs.CL

TL;DR: 该论文提出了一套以评分标准引导的大语言模型指令遵循能力训练和评估方法，显著提高了模型在复杂多指令场景下的表现，并构建了高质量新基准。


<details>
  <summary>Details</summary>
Motivation: 当前先进大语言模型在复杂、多轮、系统级指令遵循方面存在挑战，主要由于缺乏高质量人工标注基准和可靠、可解释的奖励信号，限制了训练和评估。

Method: 提出RIFL（基于评分标准的指令遵循学习），包括自动生成评分标准、微调评分标准验证器以及基于此进行奖励塑造，结合强化学习提升指令遵循能力。通过大量实验和消融分析验证方法有效。

Result: 构建了超过1600条指令和专家评分标准的全新基准AdvancedIF。通过RIFL方法，在AdvancedIF上实现了6.7%的绝对提升，并在其他公开基准上表现优异，验证了评分标准作为训练与评估工具的可行性和高效性。

Conclusion: 本研究证实了基于细致评分标准（rubrics）的训练和评估方法在提升大语言模型高级指令遵循能力方面非常有效。提出的方法可显著提升模型的表现。

Abstract: Recent progress in large language models (LLMs) has led to impressive performance on a range of tasks, yet advanced instruction following (IF)-especially for complex, multi-turn, and system-prompted instructions-remains a significant challenge. Rigorous evaluation and effective training for such capabilities are hindered by the lack of high-quality, human-annotated benchmarks and reliable, interpretable reward signals. In this work, we introduce AdvancedIF (we will release this benchmark soon), a comprehensive benchmark featuring over 1,600 prompts and expert-curated rubrics that assess LLMs ability to follow complex, multi-turn, and system-level instructions. We further propose RIFL (Rubric-based Instruction-Following Learning), a novel post-training pipeline that leverages rubric generation, a finetuned rubric verifier, and reward shaping to enable effective reinforcement learning for instruction following. Extensive experiments demonstrate that RIFL substantially improves the instruction-following abilities of LLMs, achieving a 6.7% absolute gain on AdvancedIF and strong results on public benchmarks. Our ablation studies confirm the effectiveness of each component in RIFL. This work establishes rubrics as a powerful tool for both training and evaluating advanced IF in LLMs, paving the way for more capable and reliable AI systems.

</details>


### [66] [LOCA-R: Near-Perfect Performance on the Chinese Physics Olympiad 2025](https://arxiv.org/abs/2511.10515)
*Dong-Shan Jian,Xiang Li,Chen-Xu Yan,Hui-Wen Zheng,Zhi-Zhang Bian,You-Le Fang,Sheng-Qi Zhang,Bing-Rui Gong,Ren-Xi He,Jing-Tian Zhang,Ce Meng,Yan-Qing Ma*

Main category: cs.CL

TL;DR: 该论文针对中国物理奥林匹克（CPhO）2025理论考试，提出并优化了适应复杂推理的LOCA-R框架，取得了几乎满分的成绩，远超人类及以往方法，表现出极强的物理推理和计算能力。


<details>
  <summary>Details</summary>
Motivation: 物理奥林匹克竞赛级问题解决对人类和人工智能都具有挑战性，需要复杂的计算、抽象推理和扎实的物理原理理解。中国物理奥林匹克（CPhO）以其高复杂性和深度，被认为是检验这些高阶能力的理想、严苛平台。

Method: 本文提出了一种改进的LOCA框架，名为LOCA-R（LOgical Chain Augmentation for Reasoning），该方法专为复杂推理任务设计并针对CPhO考试进行了适应优化。

Result: LOCA-R在CPhO 2025理论考试中获得了313分（满分320分），不仅超过了所有人类最高分选手，也显著优于所有基线方法。

Conclusion: LOCA-R展现了在高难度物理推理任务中的卓越能力，证明了其在高级智能和复杂问题解决中的潜力。

Abstract: Olympiad-level physics problem-solving presents a significant challenge for both humans and artificial intelligence (AI), as it requires a sophisticated integration of precise calculation, abstract reasoning, and a fundamental grasp of physical principles. The Chinese Physics Olympiad (CPhO), renowned for its complexity and depth, serves as an ideal and rigorous testbed for these advanced capabilities. In this paper, we introduce LOCA-R (LOgical Chain Augmentation for Reasoning), an improved version of the LOCA framework adapted for complex reasoning, and apply it to the CPhO 2025 theory examination. LOCA-R achieves a near-perfect score of 313 out of 320 points, solidly surpassing the highest-scoring human competitor and significantly outperforming all baseline methods.

</details>


### [67] [Say It Differently: Linguistic Styles as Jailbreak Vectors](https://arxiv.org/abs/2511.10519)
*Srikant Panda,Avinash Rai*

Main category: cs.CL

TL;DR: 论文发现LLM易受不同语言风格的jailbreak攻击，提出风格中和方法，提高模型安全。


<details>
  <summary>Details</summary>
Motivation: 现有安全评测多关注同义或改写提示，对不同语言风格的攻击面关注不足，需系统性分析风格变异对模型安全性的影响。

Method: （1）构建风格增强的jailbreak基准，包括将三类数据集提示转为11种风格；（2）用16款主流模型评测，检验风格对攻击成功率的影响；（3）提出用次级LLM进行风格中和预处理。

Result: 风格化处理使jailbreak成功率最高提升57个百分点，恐惧、好奇、共情类风格最有效；风格中和预处理显著降低攻击成功率，发现现有安全流程有系统性漏洞。

Conclusion: 目前LLM的安全机制容易被带有情感或风格变异的提示词绕过，通过风格化处理可大幅提升攻击成功率，但通过风格中和预处理可提升安全性。

Abstract: Large Language Models (LLMs) are commonly evaluated for robustness against paraphrased or semantically equivalent jailbreak prompts, yet little attention has been paid to linguistic variation as an attack surface. In this work, we systematically study how linguistic styles such as fear or curiosity can reframe harmful intent and elicit unsafe responses from aligned models. We construct style-augmented jailbreak benchmark by transforming prompts from 3 standard datasets into 11 distinct linguistic styles using handcrafted templates and LLM-based rewrites, while preserving semantic intent. Evaluating 16 open- and close-source instruction-tuned models, we find that stylistic reframing increases jailbreak success rates by up to +57 percentage points. Styles such as fearful, curious and compassionate are most effective and contextualized rewrites outperform templated variants.
  To mitigate this, we introduce a style neutralization preprocessing step using a secondary LLM to strip manipulative stylistic cues from user inputs, significantly reducing jailbreak success rates. Our findings reveal a systemic and scaling-resistant vulnerability overlooked in current safety pipelines.

</details>


### [68] [Convomem Benchmark: Why Your First 150 Conversations Don't Need RAG](https://arxiv.org/abs/2511.10523)
*Egor Pakhomov,Erik Nijkamp,Caiming Xiong*

Main category: cs.CL

TL;DR: 本文构建了大规模对话记忆评测基准，系统对比了全上下文与RAG策略，发现小规模对话下全上下文简单有效，提示记忆系统需具备针对性的优化。


<details>
  <summary>Details</summary>
Motivation: 当前的对话记忆评估基准受限于统计效能、数据生成一致性和评估灵活性，难以全面评价和对比新系统。现有检索增强生成（RAG）的进展虽多，但未能关注对话记忆从零生长的独特需求。本研究希望弥补这一短板，推动对话记忆技术进一步发展。

Method: 构建了一个包含75,336组问答对的对话记忆评估基准，涵盖多种类别（如用户事实、助理回忆、弃答、偏好、时间变化和隐式联系）。分析了对话记忆与RAG系统的关系，并以多消息证据任务测试全上下文与RAG系统在不同对话长度下的效果。

Result: 实验证明，简单的全上下文方法在困难的多消息证据场景下也能达70-82%的准确率，而复杂的RAG记忆系统Mem0在对话历史少于150轮时只能获得30-45%。全上下文在前30轮表现最佳，150轮内仍具可行性，超过后需混合或RAG方案以降低成本和延迟。

Conclusion: 对话记忆系统在小语料规模下具有独特优势，应得到专门研究。现有普遍适用的RAG解法不适合对话历史，需开发专为此场景优化的方法。

Abstract: We introduce a comprehensive benchmark for conversational memory evaluation containing 75,336 question-answer pairs across diverse categories including user facts, assistant recall, abstention, preferences, temporal changes, and implicit connections. While existing benchmarks have advanced the field, our work addresses fundamental challenges in statistical power, data generation consistency, and evaluation flexibility that limit current memory evaluation frameworks. We examine the relationship between conversational memory and retrieval-augmented generation (RAG). While these systems share fundamental architectural patterns--temporal reasoning, implicit extraction, knowledge updates, and graph representations--memory systems have a unique characteristic: they start from zero and grow progressively with each conversation. This characteristic enables naive approaches that would be impractical for traditional RAG. Consistent with recent findings on long context effectiveness, we observe that simple full-context approaches achieve 70-82% accuracy even on our most challenging multi-message evidence cases, while sophisticated RAG-based memory systems like Mem0 achieve only 30-45% when operating on conversation histories under 150 interactions. Our analysis reveals practical transition points: long context excels for the first 30 conversations, remains viable with manageable trade-offs up to 150 conversations, and typically requires hybrid or RAG approaches beyond that point as costs and latencies become prohibitive. These patterns indicate that the small-corpus advantage of conversational memory--where exhaustive search and complete reranking are feasible--deserves dedicated research attention rather than simply applying general RAG solutions to conversation histories.

</details>


### [69] [Computing the Formal and Institutional Boundaries of Contemporary Genre and Literary Fiction](https://arxiv.org/abs/2511.10546)
*Natasha Johnson*

Main category: cs.CL

TL;DR: 本文采用计算方法，通过分析当代文学数据，发现每个流派均有显著的形式特征；女性作者会让文学性界定更为复杂，说明文学流派除制度因素外，形式标记也非常重要。


<details>
  <summary>Details</summary>
Motivation: 随着流派小说兴起，传统按形式分类的流派理论受到挑战，而现代研究更关注流派的形式与制度特征。本研究旨在探讨“流派”更多是形式还是制度性的划分，以量化视角检验传统与现代观点。

Method: 首先利用CONLIT当代文学数据集，构建包含文学与流派小说（包含言情、悬疑和科幻）的语料库。采用Welch's ANOVA检验不同流派内根据作者性别的叙事特征分布，以及流派小说与文学小说之间的差异。通过逻辑回归分析每个特征对文学分类的影响，并衡量作者性别如何调节这些影响。最后，对各类别进行风格和语义向量分析，探讨形式与内容在文学分类中的作用。

Result: 识别出每个文学类别的显著形式标记，证明流派的形式划分有统计学依据；同时发现女性作者身份能显著影响作品获得文学分类的标准，使文学边界变得更模糊。

Conclusion: 本研究发现每种文学类别均有显著的形式标记，并且女性作者的作品在获得“文学性”认定方面有更大的模糊和压缩效应，即女性作者身份使得文学属性界定变得更复杂。

Abstract: Though the concept of genre has been a subject of discussion for millennia, the relatively recent emergence of genre fiction has added a new layer to this ongoing conversation. While more traditional perspectives on genre have emphasized form, contemporary scholarship has invoked both formal and institutional characteristics in its taxonomy of genre, genre fiction, and literary fiction. This project uses computational methods to explore the soundness of genre as a formal designation as opposed to an institutional one. Pulling from Andrew Piper's CONLIT dataset of Contemporary Literature, we assemble a corpus of literary and genre fiction, with the latter category containing romance, mystery, and science fiction novels. We use Welch's ANOVA to compare the distribution of narrative features according to author gender within each genre and within genre versus literary fiction. Then, we use logistic regression to model the effect that each feature has on literary classification and to measure how author gender moderates these effects. Finally, we analyze stylistic and semantic vector representations of our genre categories to understand the importance of form and content in literary classification. This project finds statistically significant formal markers of each literary category and illustrates how female authorship narrows and blurs the target for achieving literary status.

</details>


### [70] [URaG: Unified Retrieval and Generation in Multimodal LLMs for Efficient Long Document Understanding](https://arxiv.org/abs/2511.10552)
*Yongxin Shi,Jiapeng Wang,Zeyu Shan,Dezhi Peng,Zening Lin,Lianwen Jin*

Main category: cs.CL

TL;DR: URaG框架基于MLLMs“粗到细”推理特点，将检索与生成整合至单一模型，实现高效长文档理解。其轻量检索模块提升了准确性并降低了近半的计算成本，展现出优越的性能及实用价值。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大型语言模型（MLLMs）在长文档理解方面面临信息干扰和高昂的计算成本两大核心挑战。已有方法通常通过压缩token或者引入外部检索器来缓解问题，但分别牺牲了细粒度信息或者增加系统复杂度，无法实现端到端优化。

Method: 作者通过分析MLLMs的推理过程，发现其早期Transformer层呈现“粗到细”关注模式：先广泛关注文档内容，后聚焦相关证据。基于此，提出URaG框架——在单一MLLM内部统一检索与生成，通过轻量级跨模态检索模块，将早期层变为高效证据选择器，将无关内容剔除，后期层专注于关键信息计算。

Result: 广泛实验表明，URaG在长文档理解任务上取得了SOTA（当前最新最好）性能，并将计算开销降低了44-56%。

Conclusion: URaG有效解决了长文档理解中的效率与准确性问题，在维持高性能的同时显著减少计算资源消耗，可扩展性强。

Abstract: Recent multimodal large language models (MLLMs) still struggle with long document understanding due to two fundamental challenges: information interference from abundant irrelevant content, and the quadratic computational cost of Transformer-based architectures. Existing approaches primarily fall into two categories: token compression, which sacrifices fine-grained details; and introducing external retrievers, which increase system complexity and prevent end-to-end optimization. To address these issues, we conduct an in-depth analysis and observe that MLLMs exhibit a human-like coarse-to-fine reasoning pattern: early Transformer layers attend broadly across the document, while deeper layers focus on relevant evidence pages. Motivated by this insight, we posit that the inherent evidence localization capabilities of MLLMs can be explicitly leveraged to perform retrieval during the reasoning process, facilitating efficient long document understanding. To this end, we propose URaG, a simple-yet-effective framework that Unifies Retrieval and Generation within a single MLLM. URaG introduces a lightweight cross-modal retrieval module that converts the early Transformer layers into an efficient evidence selector, identifying and preserving the most relevant pages while discarding irrelevant content. This design enables the deeper layers to concentrate computational resources on pertinent information, improving both accuracy and efficiency. Extensive experiments demonstrate that URaG achieves state-of-the-art performance while reducing computational overhead by 44-56%. The code is available at https://github.com/shi-yx/URaG.

</details>


### [71] [DESS: DeBERTa Enhanced Syntactic-Semantic Aspect Sentiment Triplet Extraction](https://arxiv.org/abs/2511.10577)
*Vishal Thenuwara,Nisansa de Silva*

Main category: cs.CL

TL;DR: DESS结合DeBERTa和LSTM双通道机制，显著提升了细粒度情感三元组抽取任务表现，尤其在复杂句法结构下优势明显。


<details>
  <summary>Details</summary>
Motivation: 虽然BERT和图神经网络已在ASTE任务上取得进展，但现有方法尚未充分挖掘先进语言模型对复杂语言关系的理解潜能，因此亟需更有效的框架提升细粒度情感分析的准确性。

Method: 提出了DESS框架，结合了DeBERTa和LSTM两个通道，分别处理文本意义和语法结构，并精细调整两者的信息交互以提升整体性能。

Result: 在标准数据集上的测试结果显示，DESS在识别方面-观点对及极性判断任务上F1-score分别提升4.85、8.36和2.42分，明显优于现有方法，尤其对远距离依存关系的句子处理更为出色。

Conclusion: 通过集成DeBERTa与LSTM，DESS能够更准确地理解文本中的上下文和语言关系，大幅提升了细粒度情感分析中的性能，尤其在处理复杂句子结构时表现突出。

Abstract: Fine-grained sentiment analysis faces ongoing challenges in Aspect Sentiment Triple Extraction (ASTE), particularly in accurately capturing the relationships between aspects, opinions, and sentiment polarities. While researchers have made progress using BERT and Graph Neural Networks, the full potential of advanced language models in understanding complex language patterns remains unexplored. We introduce DESS, a new approach that builds upon previous work by integrating DeBERTa's enhanced attention mechanism to better understand context and relationships in text. Our framework maintains a dual-channel structure, where DeBERTa works alongside an LSTM channel to process both meaning and grammatical patterns in text. We have carefully refined how these components work together, paying special attention to how different types of language information interact. When we tested DESS on standard datasets, it showed meaningful improvements over current methods, with F1-score increases of 4.85, 8.36, and 2.42 in identifying aspect opinion pairs and determining sentiment accurately. Looking deeper into the results, we found that DeBERTa's sophisticated attention system helps DESS handle complicated sentence structures better, especially when important words are far apart. Our findings suggest that upgrading to more advanced language models when thoughtfully integrated, can lead to real improvements in how well we can analyze sentiments in text. The implementation of our approach is publicly available at: https://github.com/VishalRepos/DESS.

</details>


### [72] [Evaluating Prompting Strategies with MedGemma for Medical Order Extraction](https://arxiv.org/abs/2511.10583)
*Abhinand Balachandran,Bavana Durgapraveen,Gowsikkan Sikkan Sudhagar,Vidhya Varshany J S,Sriram Rajkumar*

Main category: cs.CL

TL;DR: 对医疗对话提取医嘱的任务，系统比较了三种提示策略，发现简单的one-shot方法能取得最佳效果，复杂推理反而可能适得其反，为实际应用提供了有价值的策略参考。


<details>
  <summary>Details</summary>
Motivation: 从医患对话中准确提取医嘱有助于减轻临床文档工作负担并保障患者安全，但当前缺乏对不同提取策略的系统性对比分析。

Method: 对专为医疗领域设计的新开源大语言模型MedGemma在结构化医嘱提取任务中的表现进行了系统性实验，比较了一次性提示(one-shot)、ReAct推理框架以及多步智能体(agentic)流程三种提示范式。

Result: 实验发现，尽管ReAct和多步智能体流程具备更强推理能力，但在人工标注转录文本上，one-shot提示方式在官方验证集上取得了最高表现。复杂推理反而带来了过度推理和噪声，直接法更稳健高效。

Conclusion: 面对人工标注的医患对话文本，选择简单直接的提取策略（如one-shot prompting）比采用复杂推理流程更有效。本研究为不同数据条件下的临床信息抽取任务提供了提示方法选择的实证依据。

Abstract: The accurate extraction of medical orders from doctor-patient conversations is a critical task for reducing clinical documentation burdens and ensuring patient safety. This paper details our team submission to the MEDIQA-OE-2025 Shared Task. We investigate the performance of MedGemma, a new domain-specific open-source language model, for structured order extraction. We systematically evaluate three distinct prompting paradigms: a straightforward one-Shot approach, a reasoning-focused ReAct framework, and a multi-step agentic workflow. Our experiments reveal that while more complex frameworks like ReAct and agentic flows are powerful, the simpler one-shot prompting method achieved the highest performance on the official validation set. We posit that on manually annotated transcripts, complex reasoning chains can lead to "overthinking" and introduce noise, making a direct approach more robust and efficient. Our work provides valuable insights into selecting appropriate prompting strategies for clinical information extraction in varied data conditions.

</details>


### [73] [Mined Prompting and Metadata-Guided Generation for Wound Care Visual Question Answering](https://arxiv.org/abs/2511.10591)
*Bavana Durgapraveen,Sornaraj Sivasankaran,Abhinand Balachandran,Sriram Rajkumar*

Main category: cs.CL

TL;DR: 该论文通过两种AI技术提升了远程伤口护理问答的自动化质量：利用相似问答示例的嵌入检索方法提高相关性，用元数据预测与动态生成增强临床精度，最终改善了医疗人员的工作效率与问答质量。


<details>
  <summary>Details</summary>
Motivation: 远程医疗中异步问答普及加重了医疗人员负担，迫切需要AI系统协助高效应对患者咨询，尤其以伤口护理领域为典型场景。

Method: 提出两种方法：一是挖掘式提示，利用训练数据生成嵌入、检索相似示例作为few-shot演示指导生成；二是元数据消融研究，识别四项能提升响应质量的元数据，并训练分类器预测这些元数据后，将其动态加入生成流程中。

Result: 实验结果显示，挖掘式提示提升了应答的相关性，元数据引导的生成进一步提高了临床精度，两者结合为AI辅助伤口护理提供了可行且有效的技术路径。

Conclusion: 通过结合挖掘式提示和元数据引导的方法，可以显著提升AI系统针对伤口护理问答的相关性和临床精确性，展示了AI技术在远程医疗中的应用潜力。

Abstract: The rapid expansion of asynchronous remote care has intensified provider workload, creating demand for AI systems that can assist clinicians in managing patient queries more efficiently. The MEDIQA-WV 2025 shared task addresses this challenge by focusing on generating free-text responses to wound care queries paired with images. In this work, we present two complementary approaches developed for the English track. The first leverages a mined prompting strategy, where training data is embedded and the top-k most similar examples are retrieved to serve as few-shot demonstrations during generation. The second approach builds on a metadata ablation study, which identified four metadata attributes that consistently enhance response quality. We train classifiers to predict these attributes for test cases and incorporate them into the generation pipeline, dynamically adjusting outputs based on prediction confidence. Experimental results demonstrate that mined prompting improves response relevance, while metadata-guided generation further refines clinical precision. Together, these methods highlight promising directions for developing AI-driven tools that can provide reliable and efficient wound care support.

</details>


### [74] [Know Your Limits: Entropy Estimation Modeling for Compression and Generalization](https://arxiv.org/abs/2511.10618)
*Benjamin L. Badger,Matthew Neligeorge*

Main category: cs.CL

TL;DR: 本文提出了一种编码器增强的因果解码器架构，在训练效率和语言压缩上优于传统模型，并且能高效估算逐词语言熵。以语言熵为训练极限能提升泛化能力，是比损失最小化更优的策略。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型受限于语言信息熵，存在准确率极限和压缩下限。因此需要探索高效的语言压缩与熵估计方法，尤其是在计算资源有限的情况下。

Method: 提出了编码器增强的因果解码器架构，提升训练效率并在普通硬件条件下实现高于传统因果Transformer的语言压缩。并展示了如何逐词估算语言熵，以及基于熵进行模型训练与泛化性能的分析。

Result: 编码器增强的因果解码器架构在训练效率和压缩效果上优于传统架构，并且可以有效估算逐词熵。以熵为训练目标能够提升模型泛化能力。经验验证：以熵为界限训练的因果模型，比传统损失优化模型具有更强的泛化性。

Conclusion: 语言模型的预测极限由语言熵定义。编码器增强架构既高效又能实现更优语言压缩和熵估计，能够提升模型泛化能力。熵为界限的训练策略优于仅依赖损失最小化。

Abstract: Language prediction is constrained by informational entropy intrinsic to language, such that there exists a limit to how accurate any language model can become and equivalently a lower bound to language compression. The most efficient language compression algorithms today are causal (next token prediction) large language models, but the use of these models to form accurate estimates of language entropy is currently computationally infeasible. We introduce encoder-augmented causal decoder model architectures that exhibit superior training efficiency characteristics and achieve higher compression than causal transformers even when trained on modest hardware. We demonstrate how entropy estimates can be obtained on a per-token basis, and show that the generalization of models trained to approach the entropy of their training data necessarily exceeds the generalization of models trained to minimize loss beyond this value. We show empirically that causal models trained to approach but not exceed estimated per-token entropies exhibit greater generalization than models trained without taking entropy into account.

</details>


### [75] [SSR: Socratic Self-Refine for Large Language Model Reasoning](https://arxiv.org/abs/2511.10621)
*Haizhou Shi,Ye Liu,Bo Pang,Zeyu Leo Liu,Hao Wang,Silvio Savarese,Caiming Xiong,Yingbo Zhou,Semih Yavuz*

Main category: cs.CL

TL;DR: SSR提出了一种细粒度分解与逐步精炼的方法，能系统性提升大模型推理表现，并增强可解释性，在多个任务和模型上效果突出。


<details>
  <summary>Details</summary>
Motivation: 现有测试阶段的自我验证和自我纠错方法过于粗糙，难以全面提升大模型在复杂任务上的推理能力，需要更细粒度的推理评估框架。

Method: 提出SSR方法，将模型输出分解为可验证的（子问题，子答案）对，并通过受控重解和自洽性检测进行逐步置信度评估，定位不可靠步骤并进行迭代精炼。

Result: 在五个推理基准和三种LLM上的实验证明，SSR在准确率和解释性上都优于现有最优的迭代自我精炼基线。还实现了对模型推理过程的黑盒化细致分析。

Conclusion: SSR（苏格拉底式自我精炼）能够有效提升大语言模型在复杂推理任务中的表现，并比现有最优的自我精炼方法表现更好。它还能为评估和理解模型内部推理过程提供新的思路。

Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning abilities, yet existing test-time frameworks often rely on coarse self-verification and self-correction, limiting their effectiveness on complex tasks. In this paper, we propose Socratic Self-Refine (SSR), a novel framework for fine-grained evaluation and precise refinement of LLM reasoning. Our proposed SSR decomposes model responses into verifiable (sub-question, sub-answer) pairs, enabling step-level confidence estimation through controlled re-solving and self-consistency checks. By pinpointing unreliable steps and iteratively refining them, SSR produces more accurate and interpretable reasoning chains. Empirical results across five reasoning benchmarks and three LLMs show that SSR consistently outperforms state-of-the-art iterative self-refinement baselines. Beyond performance gains, SSR provides a principled black-box approach for evaluating and understanding the internal reasoning processes of LLMs. Code is available at https://github.com/SalesforceAIResearch/socratic-self-refine-reasoning.

</details>


### [76] [Instella: Fully Open Language Models with Stellar Performance](https://arxiv.org/abs/2511.10628)
*Jiang Liu,Jialian Wu,Xiaodong Yu,Yusheng Su,Prakamya Mishra,Gowtham Ramesh,Sudhanshu Ranjan,Chaitanya Manem,Ximeng Sun,Ze Wang,Pratik Prabhanjan Brahma,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: Instella是完全开源的30亿参数大模型，含长文本和数学专用变体，性能优异，为社区提供透明可复现的大模型工具。


<details>
  <summary>Details</summary>
Motivation: 当前高性能大语言模型多为闭源或部分开源，缺乏透明性和可复现性，限制了学术研究和社区发展。因此，作者提出开发完全开源的大模型以促进开放研究。

Method: 作者提出了Instella系列，包含30亿参数的大语言模型，训练全程使用开源数据和代码，在AMD Instinct MI300X GPU上进行大规模预训练，以及通用指令微调和基于人类偏好的对齐。还发布了两个变体：Instella-Long（支持128K上下文长度）和Instella-Math（针对数学推理任务进行微调和强化学习）。

Result: Instella在使用预训练数据量显著少于同类模型的情况下，在全开源模型中达到了最先进水平，并与同等规模的开放权重模型竞争力强。

Conclusion: Instella为社区提供了一个透明、高性能且多功能的语言模型选择，有助于推动开放和可复现的语言建模研究。

Abstract: Large language models (LLMs) have demonstrated remarkable performance across a wide range of tasks, yet the majority of high-performing models remain closed-source or partially open, limiting transparency and reproducibility. In this work, we introduce Instella, a family of fully open three billion parameter language models trained entirely on openly available data and codebase. Powered by AMD Instinct MI300X GPUs, Instella is developed through large-scale pre-training, general-purpose instruction tuning, and alignment with human preferences. Despite using substantially fewer pre-training tokens than many contemporaries, Instella achieves state-of-the-art results among fully open models and is competitive with leading open-weight models of comparable size. We further release two specialized variants: Instella-Long, capable of handling context lengths up to 128K tokens, and Instella-Math, a reasoning-focused model enhanced through supervised fine-tuning and reinforcement learning on mathematical tasks. Together, these contributions establish Instella as a transparent, performant, and versatile alternative for the community, advancing the goal of open and reproducible language modeling research.

</details>


### [77] [Black-Box On-Policy Distillation of Large Language Models](https://arxiv.org/abs/2511.10643)
*Tianzhu Ye,Li Dong,Zewen Chi,Xun Wu,Shaohan Huang,Furu Wei*

Main category: cs.CL

TL;DR: 本文提出生成对抗蒸馏（GAD），能在黑盒场景下通过对抗训练实现大语言模型的高效蒸馏，效果超过传统方法，且学生模型性能媲美教师。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型蒸馏多依赖于对教师模型内在参数或logits的访问，但黑盒蒸馏只允许学生模型直接从教师模型的文本输出中学习，这一方法有一定挑战性。为了解决黑盒蒸馏中的问题，论文提出新的方法。

Method: 提出生成对抗蒸馏（Generative Adversarial Distillation, GAD）方法，将学生模型设为生成器，训练一个判别器辨别学生和教师模型的响应，两者进行对抗训练。判别器同时作为在策略奖励模型，为学生提供适应性反馈。

Result: GAD方法在实验中持续优于常用的序列级知识蒸馏方法。特别是在LMSYS-Chat的自动评测中，采用GAD训练的Qwen2.5-14B-Instruct（学生）已经可以媲美其教师模型GPT-5-Chat。

Conclusion: GAD为黑盒LLM蒸馏提供了一种有效且有前景的新范式。

Abstract: Black-box distillation creates student large language models (LLMs) by learning from a proprietary teacher model's text outputs alone, without access to its internal logits or parameters. In this work, we introduce Generative Adversarial Distillation (GAD), which enables on-policy and black-box distillation. GAD frames the student LLM as a generator and trains a discriminator to distinguish its responses from the teacher LLM's, creating a minimax game. The discriminator acts as an on-policy reward model that co-evolves with the student, providing stable, adaptive feedback. Experimental results show that GAD consistently surpasses the commonly used sequence-level knowledge distillation. In particular, Qwen2.5-14B-Instruct (student) trained with GAD becomes comparable to its teacher, GPT-5-Chat, on the LMSYS-Chat automatic evaluation. The results establish GAD as a promising and effective paradigm for black-box LLM distillation.

</details>


### [78] [ParoQuant: Pairwise Rotation Quantization for Efficient Reasoning LLM Inference](https://arxiv.org/abs/2511.10645)
*Yesheng Liang,Haisheng Chen,Song Han,Zhijian Liu*

Main category: cs.CL

TL;DR: ParoQuant通过高效的通道旋转与缩放策略，有效抑制异常值，提升量化后LLM的推理精度，且保持低运行成本，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 针对大语言模型（LLMs）在权重量化过程中，权重和激活值存在异常值（outliers），导致量化误差大、推理精度显著下降，尤其在长链条推理任务中误差积累更为严重。现有的方法在抑制异常值和推理效率方面存在权衡，无法同时兼顾精度和性能。

Method: 提出了一种新的仅对权重进行后训练量化（PTQ）的方法——Pairwise Rotation Quantization（ParoQuant）。该方法结合了硬件高效、可优化的独立Givens旋转与通道级缩放，从而均衡不同通道的幅值并收窄每个量化组的动态范围。同时，论文还优化推理内核，以充分利用GPU并行性，使旋转和缩放在实际运行时开销极低。

Result: 在推理任务上，ParoQuant相比于现有的AWQ（另一种量化方法）实现了平均2.4%的精度提升，且推理时间开销低于10%。

Conclusion: ParoQuant显著提升了推理型大语言模型在量化后的精度，同时保持较低的推理开销，为高效、准确部署此类模型提供了新路径。

Abstract: Weight-only post-training quantization (PTQ) compresses the weights of Large Language Models (LLMs) into low-precision representations to reduce memory footprint and accelerate inference. However, the presence of outliers in weights and activations often leads to large quantization errors and severe accuracy degradation, especially in recent reasoning LLMs where errors accumulate across long chains of thought. Existing PTQ methods either fail to sufficiently suppress outliers or introduce significant overhead during inference. In this paper, we propose Pairwise Rotation Quantization (ParoQuant), a weight-only PTQ method that combines hardware-efficient and optimizable independent Givens rotations with channel-wise scaling to even out the magnitude across channels and narrow the dynamic range within each quantization group. We further co-design the inference kernel to fully exploit GPU parallelism and keep the rotations and scaling lightweight at runtime. ParoQuant achieves an average 2.4% accuracy improvement over AWQ on reasoning tasks with less than 10% overhead. This paves the way for more efficient and accurate deployment of reasoning LLMs.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [79] [Spectral and combinatorial methods for efficiently computing the rank of unambiguous finite automata](https://arxiv.org/abs/2511.09703)
*Stefan Kiefer,Andrew Ryzhikov*

Main category: cs.FL

TL;DR: 本文研究了由零一矩阵集合生成的幺半群的最小秩计算问题，利用线性代数和组合算法证明该问题在并行和多项式时间下均可解，并在特殊场景下优化了算法，理论上推广了Černý猜想。


<details>
  <summary>Details</summary>
Motivation: 零一矩阵广泛应用于自动机理论和计算理论。研究由有限集零一矩阵生成的幺半群的最小秩问题不仅对自动机的结构分析有重要意义，也与Černý猜想等关键理论问题相关。

Method: 采用线性代数方法证明问题属于并行复杂类NC，并提出了组合算法用于实际计算最小秩矩阵，算法复杂度分别为O(mn^4)和O(n^{2+ω} + mn^4)，其中ω为矩阵乘法指数（2≤ω≤2.4）。对于特殊的全确定有限自动机，算法复杂度进一步优化为O(n^3 + mn^2)。

Result: 证明了最小秩矩阵计算问题属于NC类，即可高效并行计算，并给出了具体的多项式时间算法和特殊情况下的高效算法。附带推导出规模O(n^2)的直线程序可描述最小秩矩阵的生成过程，部分推广了Černý猜想。

Conclusion: 对零一矩阵生成的幺半群最小秩的计算问题进行了深入研究，证明该问题在并行计算和多项式时间下可解，并为特殊情况下提供了更加高效的算法。

Abstract: A zero-one matrix is a matrix with entries from $\{0, 1\}$. We study monoids containing only such matrices. A finite set of zero-one matrices generating such a monoid can be seen as the matrix representation of an unambiguous finite automaton, an important generalisation of deterministic finite automata which shares many of their good properties.
  Let $\mathcal{A}$ be a finite set of $n \times n$ zero-one matrices generating a monoid of zero-one matrices, and $m$ be the cardinality of $\mathcal{A}$. We study the computational complexity of computing the minimum rank of a matrix in the monoid generated by $\mathcal{A}$. By using linear-algebraic techniques, we show that this problem is in $\textsf{NC}$ and can be solved in $\mathcal{O}(mn^4)$ time. We also provide a combinatorial algorithm finding a matrix of minimum rank in $\mathcal{O}(n^{2 + ω} + mn^4)$ time, where $2 \le ω\le 2.4$ is the matrix multiplication exponent. As a byproduct, we show a very weak version of a generalisation of the Černý conjecture: there always exists a straight line program of size $\mathcal{O}(n^2)$ describing a product resulting in a matrix of minimum rank.
  For the special case corresponding to total DFAs (that is, for the case where all matrices have exactly one 1 in each row), the minimum rank is the size of the smallest image of the set of all states under the action of a word. Our combinatorial algorithm finds a matrix of minimum rank in time $\mathcal{O}(n^3 + mn^2)$ in this case.

</details>
