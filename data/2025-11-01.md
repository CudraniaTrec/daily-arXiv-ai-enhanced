<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 21]
- [cs.LO](#cs.LO) [Total: 4]
- [cs.CL](#cs.CL) [Total: 27]
- [cs.DM](#cs.DM) [Total: 1]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Fair intersection of seekable iterators](https://arxiv.org/abs/2510.26016)
*Michael Arntzenius*

Main category: cs.PL

TL;DR: 本文借鉴 miniKanren 的公平切换思想，实现了适用于函数式语言、最坏情况下最优的组合式连接查询方法。


<details>
  <summary>Details</summary>
Motivation: miniKanren 相比 Prolog 的核心改进是公平高效地在分支间切换搜索。作者希望将这一思想用于关系连接操作的高效实现，解决嵌入式函数式语言中的连接效率和公平性问题。

Method: 提出了一种基于可查找迭代器接口的组合式实现，通过在分支之间公平地分配工作，实现了高效且公平的搜索和连接操作。

Result: 证明了有限工作量的公平分配能带来优美的组合式实现，并达到连接查询的最坏情况下的最优性能。

Conclusion: 利用有限工作量的公平切换思想，可以为函数式语言中浅层嵌入的连接查询实现最坏情况下的最优效率。

Abstract: miniKanren's key semantic advance over Prolog is to implement a complete yet
efficient search strategy, fairly interleaving execution between disjuncts.
This fairness is accomplished by bounding how much work is done exploring one
disjunct before switching to the next. We show that the same idea -- fairness
via bounded work -- underlies an elegant compositional approach to implementing
worst-case optimal joins using a seekable iterator interface, suitable for
shallow embedding in functional languages.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [Internal Vulnerabilities, External Threats: A Grounded Framework for Enterprise Open Source Risk Governance](https://arxiv.org/abs/2510.25882)
*Wenhao Yang,Minghui Zhou,Daniel Izquierdo Cortázar,Yehui Wang*

Main category: cs.SE

TL;DR: 企业越来越多地深度融入开源，面临超越代码层面的复杂风险。本文提出并验证了一个面向企业的整体开源风险治理框架，促使风险治理从战术反应转向系统性、主动的决策与能力建设。


<details>
  <summary>Details</summary>
Motivation: 随着企业与开源的深度融合，面临的风险从单纯的技术问题扩展至更复杂的治理和生态风险，但传统风险管理手段无法覆盖这些系统性威胁，亟需一个系统化解决方案。

Method: 采用扎根理论方法，对15位实践者进行了深度访谈，提炼了风险治理理论，并通过专家案例回顾法对框架实用性进行验证。

Result: 构建了基于“OTVM”逻辑链的治理框架；提出了“战略目标矩阵”；梳理了外部威胁与内部脆弱点的分类；设计了匹配缓解措施的路径，并经真实案例验证其实用性和有效性。

Conclusion: 本文提出了一个全面的开源风险治理框架，能够帮助企业从被动应对转向主动防御，实现系统化风险管理。其理论和实践价值获得了行业专家的验证。

Abstract: Enterprise engagement with open source has evolved from tactical adoption to
strategic deep integration, exposing them to a complex risk landscape far
beyond mere code. However, traditional risk management, narrowly focused on
technical tools, is structurally inadequate for systemic threats like upstream
"silent fixes", community conflicts, or sudden license changes, creating a
dangerous governance blind spot. To address this governance vacuum and enable
the necessary shift from tactical risk management to holistic risk governance,
we conducted a grounded theory study with 15 practitioners to develop a
holistic risk governance framework. Our study formalizes an analytical
framework built on a foundational risk principle: an uncontrollable External
Threat (e.g., a sudden license change in a key dependency) only becomes a
critical risk when it exploits a controllable Internal Vulnerability (e.g., an
undefined risk appetite for single-vendor projects), which then amplifies the
impact.The framework operationalizes this principle through a clear logical
chain: "Objectives -> Threats -> Vulnerabilities -> Mitigation" (OTVM). This
provides a holistic decision model that transcends mere technical checklists.
Based on this logic, our contributions are: (1) a "Strategic Objectives Matrix"
to clarify goals; (2) a systematic dual taxonomy of External Threats (Ex-Tech,
Ex-Comm, Ex-Eco) and Internal Vulnerabilities (In-Strat, In-Ops, In-Tech); and
(3) an actionable mitigation framework mapping capability-building to these
vulnerabilities. The framework's analytical utility was validated by three
industry experts through retrospective case studies on real-world incidents.
This work provides a novel diagnostic lens and a systematic path for
enterprises to shift from reactive "firefighting" to proactively building an
organizational "immune system".

</details>


### [3] [PRISM: Proof-Carrying Artifact Generation through LLM x MDE Synergy and Stratified Constraints](https://arxiv.org/abs/2510.25890)
*Tong Ma,Hui Lai,Hui Wang,Zhenhu Tian,Jizhou Wang,Haichao Wu,Yongfan Gao,Chaochao Li,Fengjie Xu,Ling Fang*

Main category: cs.SE

TL;DR: PRISM系统结合大语言模型与模型驱动工程，通过统一元模型、约束驱动和可验证生成，能够自动生成合规并可机器校验的工件，大幅降低人工审核和返工，为安全与合规关键领域带来高效自动化解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在合规和安全关键领域的应用，亟需自动生成能满足监管和标准要求的工件和证据，减少人工返工成本，并保证生成结果可靠、可追溯和机器可校验。

Method: PRISM集成了三个核心：1）统一元模型（UMM）将异构结构和法规文本融合到统一语义空间；2）集成约束模型（ICM）把结构和语义要求编译为可执行的生成时和生成后工件如自动机和校验器；3）约束引导的可验证生成（CVG），通过两层约束执行确保生成内容机器可验证，并在发现偏差时进行修复和追溯记录。系统在汽车软件工程（AUTOSAR）和跨境法律管辖测试场景中进行了评估。

Result: PRISM在汽车软件和跨国司法领域测试中，成功生成结构有效、内容可审计且能与现有工具链无缝集成的工件，显著降低了人工干预需求，高效实现了自动化合规生成。

Conclusion: PRISM能够自动生成可供监管机构审查的工件和可机器校验的证据，为高安全性和合规性领域提供了自动化保障，显著减少了手工返工和人工审查的工作量，能够与现有工具链集成。

Abstract: PRISM unifies Large Language Models with Model-Driven Engineering to generate
regulator-ready artifacts and machine-checkable evidence for safety- and
compliance-critical domains. PRISM integrates three pillars: a Unified
Meta-Model (UMM) reconciles heterogeneous schemas and regulatory text into a
single semantic space; an Integrated Constraint Model (ICM) compiles structural
and semantic requirements into enforcement artifacts including generation-time
automata (GBNF, DFA) and post-generation validators (e.g., SHACL, SMT); and
Constraint-Guided Verifiable Generation (CVG) applies these through two-layer
enforcement - structural constraints drive prefix-safe decoding while
semantic/logical validation produces machine-checkable certificates. When
violations occur, PRISM performs audit-guided repair and records generation
traces for compliance review. We evaluate PRISM in automotive software
engineering (AUTOSAR) and cross-border legal jurisdiction (Brussels I bis).
PRISM produces structurally valid, auditable artifacts that integrate with
existing tooling and substantially reduce manual remediation effort, providing
a practical path toward automated artifact generation with built-in assurance.

</details>


### [4] [A Process Mining-Based System For The Analysis and Prediction of Software Development Workflows](https://arxiv.org/abs/2510.25935)
*Antía Dorado,Iván Folgueira,Sofía Martín,Gonzalo Martín,Álvaro Porto,Alejandro Ramos,John Wallace*

Main category: cs.SE

TL;DR: CodeSight利用GitHub数据和过程挖掘，结合LSTM模型，高效预测PR处理时间与截止合规性，精度高，能显著帮助项目管理与提前预警。


<details>
  <summary>Details</summary>
Motivation: 随着软件开发流程日益复杂，项目按时完成面临很大挑战。开发团队迫切需要能够提前预警PR（Pull Request）是否能如期完成的工具，帮助管理与优化开发进度。

Method: CodeSight 首先从 GitHub 自动收集开发与部署相关数据，转换为过程挖掘日志，再提取出有用的开发流程特征与指标。其核心通过搭建 LSTM 模型，将日志中的时序活动与静态特征结合，实现预测PR剩余处理时间，以及提前识别可能延期场景。

Result: 实验表明，系统在预测PR能否按时完成方面有很高的精准率和F1得分，能有效辅助开发团队提前采取管理措施。

Conclusion: 将过程挖掘和机器学习结合到软件项目流程管理中，能够实现对开发进度的主动监控和预警，提高团队执行效率，降低项目逾期风险。

Abstract: CodeSight is an end-to-end system designed to anticipate deadline compliance
in software development workflows. It captures development and deployment data
directly from GitHub, transforming it into process mining logs for detailed
analysis. From these logs, the system generates metrics and dashboards that
provide actionable insights into PR activity patterns and workflow efficiency.
Building on this structured representation, CodeSight employs an LSTM model
that predicts remaining PR resolution times based on sequential activity traces
and static features, enabling early identification of potential deadline
breaches. In tests, the system demonstrates high precision and F1 scores in
predicting deadline compliance, illustrating the value of integrating process
mining with machine learning for proactive software project management.

</details>


### [5] [Beyond Synthetic Benchmarks: Evaluating LLM Performance on Real-World Class-Level Code Generation](https://arxiv.org/abs/2510.26130)
*Musfiqur Rahman,SayedHassan Khatoonabadi,Emad Shihab*

Main category: cs.SE

TL;DR: 当前大型语言模型在真实类级编码任务上的表现远低于合成基准，主要瓶颈在于上下文理解不足与错误类型多样化。检索增强和文档完善可带来有限改进，但依赖冲突等新问题。论文提供新基准和诊断，为提升生产工具性能提出建议。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在函数级代码生成取得显著进展，但其在真实软件项目中的类级实现能力尚未充分研究，迫切需要更贴近实际应用的评估方法。

Method: 提出一个基于开源仓库的全新基准，包含真实类的分区（已见和未见），用于在实际条件下评估LLM的泛化能力。评估涵盖多种输入规范、检索增强配置和文档完整度。

Result: LLM在合成基准正确率高达84%-89%，但在真实类任务仅有25%-34%，且对新旧代码库表现差异很小。完善文档可带来1%-3%的准确率提升，但统计意义有限。检索增强在文档部分缺失时提升4%-7%的准确率。主要错误类型为属性、类型和断言错误。检索增强减少逻辑错误但可能引入依赖冲突。

Conclusion: 目前LLM在类级别代码生成面临显著挑战，基准及分析为提升上下文建模、文档策略和检索集成等提出方向，对生产级代码工具有应用参考价值。

Abstract: Large language models (LLMs) have advanced code generation at the function
level, yet their ability to produce correct class-level implementations in
authentic software projects remains poorly understood. This work introduces a
novel benchmark derived from open-source repositories, comprising real-world
classes divided into seen and unseen partitions to evaluate generalization
under practical conditions. The evaluation examines multiple LLMs under varied
input specifications, retrieval-augmented configurations, and documentation
completeness levels.
  Results reveal a stark performance disparity: LLMs achieve 84% to 89%
correctness on established synthetic benchmarks but only 25% to 34% on
real-world class tasks, with negligible differences between familiar and novel
codebases. Comprehensive docstrings yield modest gains of 1% to 3% in
functional accuracy, though statistical significance is rare.
Retrieval-augmented generation proves most effective with partial
documentation, improving correctness by 4% to 7% by supplying concrete
implementation patterns absent from specifications. Error profiling identifies
AttributeError, TypeError, and AssertionError as dominant failure modes (84% of
cases), with synthetic tests overemphasizing assertion issues and real-world
scenarios highlighting type and attribute mismatches. Retrieval augmentation
reduces logical flaws but can introduce dependency conflicts.
  The benchmark and analysis expose critical limitations in current LLM
capabilities for class-level engineering, offering actionable insights for
enhancing context modelling, documentation strategies, and retrieval
integration in production code assistance tools.

</details>


### [6] [Reduction of Test Re-runs by Prioritizing Potential Order Dependent Flaky Tests](https://arxiv.org/abs/2510.26171)
*Hasnain Iqbal,Zerina Begum,Kazi Sakib*

Main category: cs.SE

TL;DR: 本文提出了一种基于共享静态字段分析的方法，优先识别顺序依赖测试，显著减少了测试运行次数与检测成本，在实际项目中验证了方法的高效性。


<details>
  <summary>Details</summary>
Motivation: 现有OD测试检测方法需要多次重复运行所有测试用例，效率低下且浪费资源，因此亟需找到更高效的优先排序方法，以减少不必要的重复测试。

Method: 采用静态分析方法，识别测试类中的共享静态字段，优先筛选出顺序依赖可能性较高的测试用例，从而减少OD测试的多次重复执行。

Result: 在27个项目模块的实验中，所提方法在23个项目中成功优先排序了所有OD测试，平均减少了65.92%的测试执行次数以及72.19%的不必要重复运行，显著降低了检测成本。

Conclusion: 通过分析测试类中的共享静态字段，提出了一种优先排序潜在顺序依赖测试（OD测试）的方法，有效提升了OD测试检测的效率。

Abstract: Flaky tests can make automated software testing unreliable due to their
unpredictable behavior. These tests can pass or fail on the same code base on
multiple runs. However, flaky tests often do not refer to any fault, even
though they can cause the continuous integration (CI) pipeline to fail. A
common type of flaky test is the order-dependent (OD) test. The outcome of an
OD test depends on the order in which it is run with respect to other test
cases. Several studies have explored the detection and repair of OD tests.
However, their methods require re-runs of tests multiple times, that are not
related to the order dependence. Hence, prioritizing potential OD tests is
necessary to reduce the re-runs. In this paper, we propose a method to
prioritize potential order-dependent tests. By analyzing shared static fields
in test classes, we identify tests that are more likely to be order-dependent.
In our experiment on 27 project modules, our method successfully prioritized
all OD tests in 23 cases, reducing test executions by an average of 65.92% and
unnecessary re-runs by 72.19%. These results demonstrate that our approach
significantly improves the efficiency of OD test detection by lowering
execution costs.

</details>


### [7] [The "4W+1H" of Software Supply Chain Security Checklist for Critical Infrastructure](https://arxiv.org/abs/2510.26174)
*Liming Dong,Sung Une Lee,Zhenchang Xing,Muhammad Ejaz Ahmed,Stefan Avgoustakis*

Main category: cs.SE

TL;DR: 本研究通过多渠道综述和‘4W+1H’方法，总结软件供应链安全实践，提出多层次自评清单，指出现有框架与关键基础设施需求的脱节，建议行业采用更综合灵活的安全对策。


<details>
  <summary>Details</summary>
Motivation: 随着软件供应链攻击频率和复杂性的增加，关键基础设施面临严重威胁，但现有安全实践往往零散且不足，难以针对关键基础设施的特定需求。

Method: 作者通过多声道文献综述，综合国际框架、澳大利亚监管和学术研究，采用‘4W+1H’分析方法，梳理和比对现有软件供应链安全实践。

Result: 总结了十大类核心安全实践，分析了其在各生命周期、相关角色和执行层级的分布，并提出了结构化的80问清单，帮助利益相关方自评并提升安全性，同时揭示了框架与行业实际需求间的差距。

Conclusion: 当前大多安全框架未能充分覆盖关键基础设施需求，需更具集成性和情境感知性的综合方法以防范日益复杂的软件供应链风险。

Abstract: The increasing frequency and sophistication of software supply chain attacks
pose severe risks to critical infrastructure sectors, threatening national
security, economic stability, and public safety. Despite growing awareness,
existing security practices remain fragmented and insufficient, with most
frameworks narrowly focused on isolated life cycle stages or lacking alignment
with the specific needs of critical infrastructure (CI) sectors. In this paper,
we conducted a multivocal literature review across international frameworks,
Australian regulatory sources, and academic studies to identify and analyze
security practices across the software supply chain, especially specific CI
sector. Our analysis found that few existing frameworks are explicitly tailored
to CI domains. We systematically leveraged identified software supply chain
security frameworks, using a "4W+1H" analytical approach, we synthesized ten
core categories (what) of software supply chain security practices, mapped them
across life-cycle phases (when), stakeholder roles (who), and implementation
levels (how), and examined their coverage across existing frameworks (where).
Building on these insights, the paper culminates in structured, multi-layered
checklist of 80 questions designed to relevant stakeholders evaluate and
enhance their software supply chain security. Our findings reveal gaps between
framework guidance and sector-specific needs, highlight the need for
integrated, context-aware approaches to safeguard critical infrastructure from
evolving software supply chain risks.

</details>


### [8] [A Research Roadmap for Augmenting Software Engineering Processes and Software Products with Generative AI](https://arxiv.org/abs/2510.26275)
*Domenico Amalfitano,Andreas Metzger,Marco Autili,Tommaso Fulcini,Tobias Hey,Jan Keim,Patrizio Pelliccione,Vincenzo Scotti,Anne Koziolek,Raffaela Mirandola,Andreas Vogelsang*

Main category: cs.SE

TL;DR: 本论文系统构建了生成式AI增强软件工程的研究路线图，梳理了影响、挑战与机遇，并提出了2030年的十个发展预测，为未来相关研究提供了清晰框架和方向。


<details>
  <summary>Details</summary>
Motivation: 生成式AI（GenAI）迅速改变了软件工程（SE）的实践方式，对流程、系统开发、运维等环节产生深远影响。当前学界和业界急需系统性地理解GenAI给软件工程带来的变革及其未来发展趋势。

Method: 采用设计科学研究方法，分三轮整合FSE 2025“Software Engineering 2030”研讨会讨论、快速文献综述和外部同行反馈。通过McLuhan四象限分析法系统梳理GenAI对SE流程和产品的影响，最终形成研究路线图。

Result: 提出了GenAI增强SE的四种基本形态，并系统总结其相关研究挑战和机遇，凝练为未来研究方向。此外，基于路线图和协同验证，提出了2030年软件工程的十个预测。

Conclusion: 本研究通过多轮证据整合和系统性方法，建立了一个透明、可复现的GenAI增强软件工程研究路线图，为理解GenAI对SE的影响及未来研究提供了坚实基础。

Abstract: Generative AI (GenAI) is rapidly transforming software engineering (SE)
practices, influencing how SE processes are executed, as well as how software
systems are developed, operated, and evolved. This paper applies design science
research to build a roadmap for GenAI-augmented SE. The process consists of
three cycles that incrementally integrate multiple sources of evidence,
including collaborative discussions from the FSE 2025 "Software Engineering
2030" workshop, rapid literature reviews, and external feedback sessions
involving peers. McLuhan's tetrads were used as a conceptual instrument to
systematically capture the transforming effects of GenAI on SE processes and
software products.The resulting roadmap identifies four fundamental forms of
GenAI augmentation in SE and systematically characterizes their related
research challenges and opportunities. These insights are then consolidated
into a set of future research directions. By grounding the roadmap in a
rigorous multi-cycle process and cross-validating it among independent author
teams and peers, the study provides a transparent and reproducible foundation
for analyzing how GenAI affects SE processes, methods and tools, and for
framing future research within this rapidly evolving area. Based on these
findings, the article finally makes ten predictions for SE in the year 2030.

</details>


### [9] [Empowering RepoQA-Agent based on Reinforcement Learning Driven by Monte-carlo Tree Search](https://arxiv.org/abs/2510.26287)
*Guochang Li,Yuchen Liu,Zhen Qin,Yunkun Wang,Jianping Zhong,Chen Zhi,Binhua Li,Fei Huang,Yongbin Li,Shuiguang Deng*

Main category: cs.SE

TL;DR: RepoSearch-R1利用MCTS实现无需外部数据的自监督训练，显著提升了代码仓库问答的完整性和效率，同时解决了数据合规性问题。


<details>
  <summary>Details</summary>
Motivation: 在复杂代码库的多轮工具交互中，大语言模型需要高效提取和导航信息。目前无训练和有训练的方法均存在局限，如指导能力不足、成本高昂以及合规性问题。需要一种高效且合规的新方法。

Method: 提出RepoSearch-R1框架，基于蒙特卡洛树搜索（MCTS），让代理通过自主训练生成多样化、优质的推理路径，无需模型蒸馏或外部监督。同时，基于该框架开发了针对代码仓库问答的RepoQA-Agent。

Result: RepoSearch-R1在代码仓库问答任务上提升了回答完整性：比无检索方法高16%，比迭代检索方法高19.5%，比通用agentic RL训练方法训练效率高33%。冷启动训练方式消除了数据合规性问题，同时保持了多样的探索和高回答完整性。

Conclusion: RepoSearch-R1通过新颖的自监督强化学习思路，提升了代码仓库级任务的回答质量和训练效率，并有效规避了企业在合规性方面的顾虑。

Abstract: Repository-level software engineering tasks require large language models
(LLMs) to efficiently navigate and extract information from complex codebases
through multi-turn tool interactions. Existing approaches face significant
limitations: training-free, in-context learning methods struggle to guide
agents effectively in tool utilization and decision-making based on
environmental feedback, while training-based approaches typically rely on
costly distillation from larger LLMs, introducing data compliance concerns in
enterprise environments. To address these challenges, we introduce
RepoSearch-R1, a novel agentic reinforcement learning framework driven by
Monte-carlo Tree Search (MCTS). This approach allows agents to generate
diverse, high-quality reasoning trajectories via self-training without
requiring model distillation or external supervision. Based on RepoSearch-R1,
we construct a RepoQA-Agent specifically designed for repository
question-answering tasks. Comprehensive evaluation on repository
question-answering tasks demonstrates that RepoSearch-R1 achieves substantial
improvements of answer completeness: 16.0% enhancement over no-retrieval
methods, 19.5% improvement over iterative retrieval methods, and 33% increase
in training efficiency compared to general agentic reinforcement learning
approaches. Our cold-start training methodology eliminates data compliance
concerns while maintaining robust exploration diversity and answer completeness
across repository-level reasoning tasks.

</details>


### [10] [CHCVerif: A Portfolio-Based Solver for Constrained Horn Clauses](https://arxiv.org/abs/2510.26431)
*Mihály Dobos-Kovács,Levente Bajczi,András Vörös*

Main category: cs.SE

TL;DR: CHCVERIF是一种利用组合软件验证工具的新型CHC求解器，尤其在bitvector相关问题上表现出一定优势，验证了相关工具复用策略的潜力。


<details>
  <summary>Details</summary>
Motivation: CHC作为中间表示常用于多种验证任务，但直接高效求解带有bitvectors和底层语义的CHC依然存在挑战，因此作者尝试通过复用成熟的软件验证工具来改进CHC求解效率和适用性。

Method: 提出了一种基于组合策略的CHC求解器CHCVERIF，将现有的软件验证工具复用于CHC求解任务。通过实验证明了该方法在bitvector基准测试中的有效性。

Result: 对比实验表明，所提出方法在整数线性算术上效果一般，但在bitvector基准测试中取得了一定成功，并为进一步利用软件验证工具的能力奠定了基础。

Conclusion: 本文证明了将软件验证工具作为CHC求解的后端具备可行性和潜力，尤其是在结合合理设计的工具组合时效果更佳。

Abstract: Constrained Horn Clauses (CHCs) are widely adopted as intermediate
representations for a variety of verification tasks, including safety checking,
invariant synthesis, and interprocedural analysis. This paper introduces
CHCVERIF, a portfolio-based CHC solver that adopts a software verification
approach for solving CHCs. This approach enables us to reuse mature software
verification tools to tackle CHC benchmarks, particularly those involving
bitvectors and low-level semantics. Our evaluation shows that while the method
enjoys only moderate success with linear integer arithmetic, it achieves modest
success on bitvector benchmarks. Moreover, our results demonstrate the
viability and potential of using software verification tools as backends for
CHC solving, particularly when supported by a carefully constructed portfolio.

</details>


### [11] [Environmental Impact of CI/CD Pipelines](https://arxiv.org/abs/2510.26413)
*Nuno Saavedra,Alexandra Mendes,João F. Ferreira*

Main category: cs.SE

TL;DR: GitHub Actions在开源项目的广泛使用，显著增加了碳足迹和水足迹。通过对大量工作流数据分析，作者估算出环境影响，并提出优化地区选择、资源合理分配等减缓措施。


<details>
  <summary>Details</summary>
Motivation: 随着云计算环境影响加剧，CI/CD服务（如GitHub Actions）的碳/水足迹未被开发者广泛认知，推动了本研究对其环境影响的深入量化和分析。

Method: 采用了Cloud Carbon Footprint框架的方法，对2.2百万个workflow runs（来自18,000多个开源仓库）进行环境影响估算分析。

Result: 2024年GitHub Actions碳足迹介于150.5至994.9 MTCO2e，水足迹介于1,989.6至37,664.5千升。最可能值分别为456.9 MTCO2e和5,738.2千升，相当于7615棵城市树一年的碳捕获和一个美国家庭5053年的用水。提出多项减缓策略，如地区选择与资源使用优化。

Conclusion: 本文结论显示：GitHub Actions 的大规模使用显著增加了碳足迹和水足迹，且这些环境影响数值非常可观，开发者对此基本无感知。应优先采取资源利用优化与配置调整措施以降低其影响。

Abstract: CI/CD pipelines are widely used in software development, yet their
environmental impact, particularly carbon and water footprints (CWF), remains
largely unknown to developers, as CI service providers typically do not
disclose such information. With the growing environmental impact of cloud
computing, understanding the CWF of CI/CD services has become increasingly
important.
  This work investigates the CWF of using GitHub Actions, focusing on
open-source repositories where usage is free and unlimited for standard
runners. We build upon a methodology from the Cloud Carbon Footprint framework
and we use the largest dataset of workflow runs reported in the literature to
date, comprising over 2.2 million workflow runs from more than 18,000
repositories.
  Our analysis reveals that the GitHub Actions ecosystem results in a
substantial CWF. Our estimates for the carbon footprint in 2024 range from
150.5 MTCO2e in the most optimistic scenario to 994.9 MTCO2e in the most
pessimistic scenario, while the water footprint ranges from 1,989.6 to 37,664.5
kiloliters. The most likely scenario estimates are 456.9 MTCO2e for carbon
footprint and 5,738.2 kiloliters for water footprint. To provide perspective,
the carbon footprint in the most likely scenario is equivalent to the carbon
captured by 7,615 urban trees in a year, and the water footprint is comparable
to the water consumed by an average American family over 5,053 years.
  We explore strategies to mitigate this impact, primarily by reducing wasted
computational resources. Key recommendations include deploying runners in
regions whose energy production has a low environmental impact such as France
and the United Kingdom, implementing stricter deactivation policies for
scheduled runs and aligning their execution with periods when the regional
energy mix is more environmentally favorable, and reducing the size of
repositories.

</details>


### [12] [Nexus: Execution-Grounded Multi-Agent Test Oracle Synthesis](https://arxiv.org/abs/2510.26423)
*Dong Huang,Mingzhe Du,Jie M. Zhang,Zheng Lin,Meng Luo,Qianru Zhang,See-Kiong Ng*

Main category: cs.SE

TL;DR: Nexus利用多智能体协同和自我修正自动生成高质量测试oracle，显著提升准确率与相关下游任务效果，比现有方法更优。


<details>
  <summary>Details</summary>
Motivation: 在软件工程的非回归测试中，自动生成能够准确判断测试函数行为的测试oracle一直是一个难题。现有方法往往精度有限，影响下游任务，如自动程序修复和错误检测。

Method: 提出了Nexus——一种多智能体框架，通过引入四种不同测试哲学的专家智能体，共同对初始测试oracle进行批判和修正。在验证阶段，Nexus生成被测函数的候选实现，并在安全沙箱环境下执行oracle。若oracle执行失败，会自动进入自我修正环节，利用错误调试并重新验证。

Result: 在七个基准测试上，Nexus显著超越现有方法。例如，测试级oracle准确率在LiveCodeBench上由GPT-4.1-Mini的46.30%提升至57.73%；在人类评测集上的错误检测率从90.91%升至95.45%；自动程序修复成功率由35.23%提升到69.32%。

Conclusion: Nexus通过多智能体协同和自我修正机制，能够提升测试oracle的准确率，从而显著改善错误检测和程序修复等关键下游任务表现。

Abstract: Test oracle generation in non-regression testing is a longstanding challenge
in software engineering, where the goal is to produce oracles that can
accurately determine whether a function under test (FUT) behaves as intended
for a given input. In this paper, we introduce Nexus, a novel multi-agent
framework to address this challenge. Nexus generates test oracles by leveraging
a diverse set of specialized agents that synthesize test oracles through a
structured process of deliberation, validation, and iterative self-refinement.
During the deliberation phase, a panel of four specialist agents, each
embodying a distinct testing philosophy, collaboratively critiques and refines
an initial set of test oracles. Then, in the validation phase, Nexus generates
a plausible candidate implementation of the FUT and executes the proposed
oracles against it in a secure sandbox. For any oracle that fails this
execution-based check, Nexus activates an automated selfrefinement loop, using
the specific runtime error to debug and correct the oracle before
re-validation. Our extensive evaluation on seven diverse benchmarks
demonstrates that Nexus consistently and substantially outperforms
state-of-theart baselines. For instance, Nexus improves the test-level oracle
accuracy on the LiveCodeBench from 46.30% to 57.73% for GPT-4.1-Mini. The
improved accuracy also significantly enhances downstream tasks: the bug
detection rate of GPT4.1-Mini generated test oracles on HumanEval increases
from 90.91% to 95.45% for Nexus compared to baselines, and the success rate of
automated program repair improves from 35.23% to 69.32%.

</details>


### [13] [SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning](https://arxiv.org/abs/2510.26457)
*Fang Liu,Simiao Liu,Yinghao Zhu,Xiaoli Lian,Li Zhang*

Main category: cs.SE

TL;DR: 本文提出SecureReviewer，通过数据集构建、安全微调、知识增强及新评价指标，有效提升大语言模型在安全代码审查中的能力，实验表明其在检测准确率与评论质量上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在软件开发早期阶段识别和解决安全问题对于减少长期负面影响至关重要。然而，目前自动化代码审查方法很少专注于安全相关问题，其有效性有待探索。此外，改造现有方法适用于安全问题面临数据稀缺和评估标准不足等挑战。

Method: 提出SecureReviewer，包括：1）构建一个专门用于安全代码审查的数据集；2）基于此数据集，对大语言模型进行安全感知微调，使其能够生成能发现安全问题并给出修复建议的审查评论；3）结合RAG技术，以安全领域知识支撑生成结果，减少幻觉并增加可靠性；4）提出新的评价标准SecureBLEU，专门评估安全审查评论的效果。

Result: 实验结果显示，SecureReviewer无论在安全问题检测的准确率，还是在生成评论的质量与实用性上，都优于现有最先进基线方法。

Conclusion: SecureReviewer通过针对性数据集、安全感知微调、知识增强及新评价指标的结合，有效提升了大语言模型在安全代码审查中的表现。该方法能更好地识别安全问题并给出修复建议，推进了自动化安全代码审查的发展。

Abstract: Identifying and addressing security issues during the early phase of the
development lifecycle is critical for mitigating the long-term negative impacts
on software systems. Code review serves as an effective practice that enables
developers to check their teammates' code before integration into the codebase.
To streamline the generation of review comments, various automated code review
approaches have been proposed, where LLM-based methods have significantly
advanced the capabilities of automated review generation. However, existing
models primarily focus on general-purpose code review, their effectiveness in
identifying and addressing security-related issues remains underexplored.
Moreover, adapting existing code review approaches to target security issues
faces substantial challenges, including data scarcity and inadequate evaluation
metrics. To address these limitations, we propose SecureReviewer, a new
approach designed for enhancing LLMs' ability to identify and resolve
security-related issues during code review. Specifically, we first construct a
dataset tailored for training and evaluating secure code review capabilities.
Leveraging this dataset, we fine-tune LLMs to generate code review comments
that can effectively identify security issues and provide fix suggestions with
our proposed secure-aware fine-tuning strategy. To mitigate hallucination in
LLMs and enhance the reliability of their outputs, we integrate the RAG
technique, which grounds the generated comments in domain-specific security
knowledge. Additionally, we introduce SecureBLEU, a new evaluation metric
designed to assess the effectiveness of review comments in addressing security
issues. Experimental results demonstrate that SecureReviewer outperforms
state-of-the-art baselines in both security issue detection accuracy and the
overall quality and practical utility of generated review comments.

</details>


### [14] [Automated Extract Method Refactoring with Open-Source LLMs: A Comparative Study](https://arxiv.org/abs/2510.26480)
*Sivajeet Chand,Melih Kilic,Roland Würsching,Sushant Kumar Pandey,Alexander Pretschner*

Main category: cs.SE

TL;DR: 该论文系统评测开源LLM在Python代码EMR自动化重构上表现，发现使用RCI提示方法能显著提升正确率和质量，并得到开发者高接受度。提出开源基准，有助于后续自动化重构研究。


<details>
  <summary>Details</summary>
Motivation: 自动化Extract Method重构（EMR）提升代码质量，但现有工具手动化程度高，自动化难度大。最新开源LLM可能提供高效自动化方法，需系统评估其在EMR任务的表现与方法优劣。

Method: 对五个开源3B到8B参数量的LLM进行EMR任务评测，包括功能正确性、代码质量自动度量（TPP、LOC、CC），并比较一次性提示和RCI递归批评改进提示方式，同时通过开发者问卷调查主观感受。

Result: RCI提示下Deepseek-Coder和Qwen2.5-Coder在TPP达到0.829和0.808，方法平均代码行数减少、复杂度降低，且开发者主观接受度达70%以上，Qwen2.5-Coder综合评分最高。开源LLM表现优于原始代码，自动化重构效果显著提升。

Conclusion: RCI递归批评改进式提示能够显著提升EMR重构的自动化质量与正确率，优于传统一次性提示。LLM驱动的自动重构得到开发者高接受度。代码可读性与可维护性大幅提高。传统代码质量指标与人工评价存在分歧，需人机结合评估。论文提出开源评测基准。

Abstract: Automating the Extract Method refactoring (EMR) remains challenging and
largely manual despite its importance in improving code readability and
maintainability. Recent advances in open-source, resource-efficient Large
Language Models (LLMs) offer promising new approaches for automating such
high-level tasks. In this work, we critically evaluate five state-of-the-art
open-source LLMs, spanning 3B to 8B parameter sizes, on the EMR task for Python
code. We systematically assess functional correctness and code quality using
automated metrics and investigate the impact of prompting strategies by
comparing one-shot prompting to a Recursive criticism and improvement (RCI)
approach. RCI-based prompting consistently outperforms one-shot prompting in
test pass rates and refactoring quality. The best-performing models,
Deepseek-Coder-RCI and Qwen2.5-Coder-RCI, achieve test pass percentage (TPP)
scores of 0.829 and 0.808, while reducing lines of code (LOC) per method from
12.103 to 6.192 and 5.577, and cyclomatic complexity (CC) from 4.602 to 3.453
and 3.294, respectively. A developer survey on RCI-generated refactorings shows
over 70% acceptance, with Qwen2.5-Coder rated highest across all evaluation
criteria. In contrast, the original code scored below neutral, particularly in
readability and maintainability, underscoring the benefits of automated
refactoring guided by quality prompts. While traditional metrics like CC and
LOC provide useful signals, they often diverge from human judgments,
emphasizing the need for human-in-the-loop evaluation. Our open-source
benchmark offers a foundation for future research on automated refactoring with
LLMs.

</details>


### [15] [Envisioning Future Interactive Web Development: Editing Webpage with Natural Language](https://arxiv.org/abs/2510.26516)
*Truong Hai Dang,Jingyu Xiao,Yintong Huo*

Main category: cs.SE

TL;DR: 作者提出了一套自动化流程生成网页编辑微调数据集，用以提升现有LLMs对网页代码编辑的能力，微调后的小模型可媲美商用系统，并全部开源。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）虽能生成UI代码，但自动编辑已有代码以满足新的设计需求（如“居中logo”）仍有难度，主要因为缺少大规模高质量微调数据，难以让模型表现符合人类预期。

Method: 提出了一套自动化数据生成流程，利用LLMs生成高质量网页编辑微调数据集（Instruct4Edit），该流程包括多样化指令生成、相应代码修改、视觉验证确保准确性，并用该数据集微调模型。

Result: 用Instruct4Edit数据微调的模型在将用户意图转化为结构合理且视觉准确的代码修改方面表现持续提升，微调后的开源小模型能达到与商业系统相竞争的效果。

Conclusion: 本文提供了一套可扩展且透明的自然语言网页编辑基础，证明了通过高质量自动化微调数据集可以提升开源模型表现，并公开全部数据、代码和模型结果方便复现实验。

Abstract: The evolution of web applications relies on iterative code modifications, a
process that is traditionally manual and time-consuming. While Large Language
Models (LLMs) can generate UI code, their ability to edit existing code from
new design requirements (e.g., "center the logo") remains a challenge. This is
largely due to the absence of large-scale, high-quality tuning data to align
model performance with human expectations. In this paper, we introduce a novel,
automated data generation pipeline that uses LLMs to synthesize a high-quality
fine-tuning dataset for web editing, named Instruct4Edit. Our approach
generates diverse instructions, applies the corresponding code modifications,
and performs visual verification to ensure correctness. By fine-tuning models
on Instruct4Edit, we demonstrate consistent improvement in translating human
intent into precise, structurally coherent, and visually accurate code changes.
This work provides a scalable and transparent foundation for natural language
based web editing, demonstrating that fine-tuning smaller open-source models
can achieve competitive performance with proprietary systems. We release all
data, code implementations, and model checkpoints for reproduction.

</details>


### [16] [Reflecting on Empirical and Sustainability Aspects of Software Engineering Research in the Era of Large Language Models](https://arxiv.org/abs/2510.26538)
*David Williams,Max Hort,Maria Kechagia,Aldeida Aleti,Justyna Petke,Federica Sarro*

Main category: cs.SE

TL;DR: 本文梳理了ICSE大会关于LLM应用于软件工程的研究现状，指出其面临的挑战与不足，并给出相关改进建议。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在软件工程领域应用的增多，出现了严谨性、基准测试污染、可复现性和可持续性等新挑战，因此需引导学界系统反思与改进。

Method: 通过系统地梳理、分析ICSE会议上与LLM相关的软件工程研究，总结其中优秀实践和存在的问题。

Result: 当前LLM在软件工程中的实践有亮点，但在基准测试、可复现性、财务和环境可持续性等方面仍有突出不足。

Conclusion: 研究总结了当前ICSE会议上LLM在软件工程应用中的优点与不足，并提出了加强基准测试严谨性、提升可复现性以及关注财务和环境影响的建议。

Abstract: Software Engineering (SE) research involving the use of Large Language Models
(LLMs) has introduced several new challenges related to rigour in benchmarking,
contamination, replicability, and sustainability. In this paper, we invite the
research community to reflect on how these challenges are addressed in SE. Our
results provide a structured overview of current LLM-based SE research at ICSE,
highlighting both encouraging practices and persistent shortcomings. We
conclude with recommendations to strengthen benchmarking rigour, improve
replicability, and address the financial and environmental costs of LLM-based
SE.

</details>


### [17] ["Show Me You Comply... Without Showing Me Anything": Zero-Knowledge Software Auditing for AI-Enabled Systems](https://arxiv.org/abs/2510.26576)
*Filippo Scaramuzza,Renato Cordeiro Ferreira,Tomaz Maia Suller,Giovanni Quattrocchi,Damian Andrew Tamburri,Willem-Jan van den Heuvel*

Main category: cs.SE

TL;DR: 本文提出基于零知识证明的ZKMLOps框架，解决AI模型审计需兼顾合规证明和数据保密的难题，在金融风控中展现有效性，并分析了性能表现。


<details>
  <summary>Details</summary>
Motivation: AI系统在关键领域的广泛应用导致对可验证信任与合规的高要求，但传统软件验证方法难以兼顾透明性与资产保护，两者矛盾成为现实难题。

Method: 提出ZKMLOps框架，将零知识证明（ZKP）与传统软件工程模式结合，实现ML操作流程中的合规和验证。通过实际金融风控合规场景进行案例研究，并对主流ZKP协议在不同复杂度ML模型下进行了性能评估。

Result: ZKMLOps实现了在不泄露敏感信息的前提下为合规提供加密可验证证明，并在金融风险审计场景下展现了其实用性，通过实验证明了主流ZKP协议在ML模型应用中的可行性和性能表现权衡。

Conclusion: ZKMLOps框架能够在ML生命周期内提供可验证的合规证明，同时保护数据和模型的机密性，解决了AI系统可审计性和资产保护间的冲突。

Abstract: The increasing exploitation of Artificial Intelligence (AI) enabled systems
in critical domains has made trustworthiness concerns a paramount showstopper,
requiring verifiable accountability, often by regulation (e.g., the EU AI Act).
Classical software verification and validation techniques, such as procedural
audits, formal methods, or model documentation, are the mechanisms used to
achieve this. However, these methods are either expensive or heavily manual and
ill-suited for the opaque, "black box" nature of most AI models. An intractable
conflict emerges: high auditability and verifiability are required by law, but
such transparency conflicts with the need to protect assets being audited-e.g.,
confidential data and proprietary models-leading to weakened accountability. To
address this challenge, this paper introduces ZKMLOps, a novel MLOps
verification framework that operationalizes Zero-Knowledge Proofs
(ZKPs)-cryptographic protocols allowing a prover to convince a verifier that a
statement is true without revealing additional information-within
Machine-Learning Operations lifecycles. By integrating ZKPs with established
software engineering patterns, ZKMLOps provides a modular and repeatable
process for generating verifiable cryptographic proof of compliance. We
evaluate the framework's practicality through a study of regulatory compliance
in financial risk auditing and assess feasibility through an empirical
evaluation of top ZKP protocols, analyzing performance trade-offs for ML models
of increasing complexity.

</details>


### [18] [Online and Interactive Bayesian Inference Debugging](https://arxiv.org/abs/2510.26579)
*Nathanael Nussbaumer,Markus Böck,Jürgen Cito*

Main category: cs.SE

TL;DR: 作者提出并验证了一种高效便捷的贝叶斯推断调试工具，大幅降低了调试难度和知识门槛。


<details>
  <summary>Details</summary>
Motivation: 概率编程能够让贝叶斯建模和推断自动化，拓展了其应用领域，但推断调试困难、耗时且需要深厚专业知识，极大制约了其实用性。

Method: 提出并实现了一种新颖的贝叶斯推断调试方法，并开发了直接集成于开发环境的调试工具。

Result: 在包含18名有经验参与者的实验研究中，验证了提出的在线、交互式贝叶斯推断调试方法显著减少了调试所需的时间和难度。

Conclusion: 本文方法有效降低了概率编程中贝叶斯推断调试的门槛和难度，为实际应用与推广开辟了新路径。

Abstract: Probabilistic programming is a rapidly developing programming paradigm which
enables the formulation of Bayesian models as programs and the automation of
posterior inference. It facilitates the development of models and conducting
Bayesian inference, which makes these techniques available to practitioners
from multiple fields. Nevertheless, probabilistic programming is notoriously
difficult as identifying and repairing issues with inference requires a lot of
time and deep knowledge. Through this work, we introduce a novel approach to
debugging Bayesian inference that reduces time and required knowledge
significantly. We discuss several requirements a Bayesian inference debugging
framework has to fulfill, and propose a new tool that meets these key
requirements directly within the development environment. We evaluate our
results in a study with 18 experienced participants and show that our approach
to online and interactive debugging of Bayesian inference significantly reduces
time and difficulty on inference debugging tasks.

</details>


### [19] [Stitch: Step-by-step LLM Guided Tutoring for Scratch](https://arxiv.org/abs/2510.26634)
*Yuan Si,Kyle Qi,Daming Li,Hanyuan Shi,Jialu Zhang*

Main category: cs.SE

TL;DR: Stitch系统在Scratch编程学习中，以分步讲解与互动辅导代替直接给标准答案，显著促进学习者问题解决能力和学习效果，优于主流反馈工具。


<details>
  <summary>Details</summary>
Motivation: 现有的积木式编程环境（如Scratch）虽然减少了语法错误，但新手仍容易遇到语义上的Bug，且调试困难。现有的调试辅助系统多直接给出正确程序，这种做法虽然能纠正错误，却削弱了学习者的问题解决能力。

Method: 提出了Stitch交互式辅导系统，通过Diff-Analyze模块对比学习者项目和参考实现，找出关键差异并用大语言模型解释原因，引导学习者逐步理解问题并分步修正。系统采用自定义渲染引擎高亮关键代码块，实现理解与有选择的修复，直至实现目标功能。

Result: 通过经验研究，Stitch显著优于传统的直接给出答案和现有自动反馈生成工具。分步引导系统能显著提升学习效果，促进学习者能力发展。

Conclusion: 直接展示正确答案并非有效教学反馈。分步、交互式的反馈机制能更好地提升编程教育中的学习成果。Stitch系统为积木式编程反馈方式提供了新证据，验证了分步辅导的优效性。

Abstract: Block-based environments such as Scratch are increasingly popular in
programming education. While block syntax reduces surface errors, semantic bugs
remain common and challenging for novices to resolve. Existing debugging
workflows typically show the correct program directly to learners, a strategy
that may fix errors but undermines the development of problem-solving skills.
  We present Stitch, an interactive tutoring system that replaces "showing the
answer" with step-by-step scaffolding. The system's Diff-Analyze module
contrasts a student's project with a reference implementation, identifies the
most critical differences, and uses a large language model to explain why these
changes matter. Learners inspect highlighted blocks through a custom rendering
engine, understand the explanations, and selectively apply partial fixes. This
iterative process continues until the intended functionality is achieved.
  We evaluate Stitch in an empirical study, comparing it against a
state-of-the-art automated feedback generation tool for Scratch. Our key
insight is that simply presenting the correct program is pedagogically
ineffective. In contrast, our interactive, step-by-step guided system promotes
a more effective learning experience. More broadly, what constitutes effective
feedback in block-based programming remains an open question. Our evaluation
provides new evidence that step-by-step tutoring significantly enhances
learning outcomes, outperforming both direct-answer approaches and current
automated feedback generation tools.

</details>


### [20] [Process-based Indicators of Vulnerability Re-Introducing Code Changes: An Exploratory Case Study](https://arxiv.org/abs/2510.26676)
*Samiha Shimmi,Nicholas M. Synovic,Mona Rahimi,George K. Thiruvathukal*

Main category: cs.SE

TL;DR: 本研究以ImageMagick项目为例，结合过程与代码度量分析漏洞再引入。结果显示，团队响应降低和问题管理低效易导致漏洞复现，强调需同时关注开发过程和代码本身以提升软件安全。


<details>
  <summary>Details</summary>
Motivation: 尽管修复了软件漏洞，但这些漏洞往往会持续存在或重新出现，这反映了代码演化与社会技术因素之间的复杂关系。目前，虽然源代码度量能预测漏洞，但很少有研究探讨过程度量是否能揭示长期高风险开发活动，而这对于预防和缓解漏洞再引入至关重要。

Method: 作者通过对ImageMagick项目进行案例研究，追踪与漏洞再引入相关的纵向过程度量（如总线因子、问题密度、问题陈旧度），并分析76个漏洞再引入实例，将这些度量与安全补丁的提交级别变更相结合，重点探讨长时间内的开发活动序列对漏洞再现的影响。

Result: 研究发现，漏洞再引入通常与问题陈旧度增加和问题密度波动有关，这表明短期内问题管理效率低下和团队响应能力不足会导致漏洞高发。

Conclusion: 漏洞再引入并非单一事件的结果，而是累计的开发活动和社会技术条件共同作用的产物。结合过程和代码度量有助于预测高风险修复并提升软件安全性。

Abstract: Software vulnerabilities often persist or re-emerge even after being fixed,
revealing the complex interplay between code evolution and socio-technical
factors. While source code metrics provide useful indicators of
vulnerabilities, software engineering process metrics can uncover patterns that
lead to their introduction. Yet few studies have explored whether process
metrics can reveal risky development activities over time -- insights that are
essential for anticipating and mitigating software vulnerabilities. This work
highlights the critical role of process metrics along with code changes in
understanding and mitigating vulnerability reintroduction. We move beyond
file-level prediction and instead analyze security fixes at the commit level,
focusing not only on whether a single fix introduces a vulnerability but also
on the longer sequences of changes through which vulnerabilities evolve and
re-emerge. Our approach emphasizes that reintroduction is rarely the result of
one isolated action, but emerges from cumulative development activities and
socio-technical conditions. To support this analysis, we conducted a case study
on the ImageMagick project by correlating longitudinal process metrics such as
bus factor, issue density, and issue spoilage with vulnerability reintroduction
activities, encompassing 76 instances of reintroduced vulnerabilities. Our
findings show that reintroductions often align with increased issue spoilage
and fluctuating issue density, reflecting short-term inefficiencies in issue
management and team responsiveness. These observations provide a foundation for
broader studies that combine process and code metrics to predict risky fixes
and strengthen software security.

</details>


### [21] [Using Copilot Agent Mode to Automate Library Migration: A Quantitative Assessment](https://arxiv.org/abs/2510.26699)
*Aylton Almeida,Laerte Xavier,Marco Tulio Valente*

Main category: cs.SE

TL;DR: LLM工具自动化迁移SQLAlchemy库，API迁移完全但功能恢复有限，需进一步提升自动化迁移质量。


<details>
  <summary>Details</summary>
Motivation: 库和框架更新过程繁琐且容易出错，亟需自动化手段简化维护工作，LLMs和代理式编程工具为此提供了新机遇。

Method: 对10个使用SQLAlchemy的Python客户端应用进行实验，利用Github's Copilot Agent Mode自动进行库迁移，并提出迁移覆盖率指标衡量API迁移效果，通过测试用例评估功能保持情况。

Result: LLM代理成功将SQLAlchemy库API迁移至较新版本（迁移覆盖率：中位数100%），但未能充分保障应用功能（测试通过率：中位数39.75%）。

Conclusion: LLM代理在迁移SQLAlchemy库API使用方面表现理想，实现了100%的迁移覆盖率，但在维持应用功能方面表现不佳，测试通过率仅为39.75%。

Abstract: Keeping software systems up to date is essential to avoid technical debt,
security vulnerabilities, and the rigidity typical of legacy systems. However,
updating libraries and frameworks remains a time consuming and error-prone
process. Recent advances in Large Language Models (LLMs) and agentic coding
systems offer new opportunities for automating such maintenance tasks. In this
paper, we evaluate the update of a well-known Python library, SQLAlchemy,
across a dataset of ten client applications. For this task, we use the Github's
Copilot Agent Mode, an autonomous AI systema capable of planning and executing
multi-step migration workflows. To assess the effectiveness of the automated
migration, we also introduce Migration Coverage, a metric that quantifies the
proportion of API usage points correctly migrated. The results of our study
show that the LLM agent was capable of migrating functionalities and API usages
between SQLAlchemy versions (migration coverage: 100%, median), but failed to
maintain the application functionality, leading to a low test-pass rate
(39.75%, median).

</details>


### [22] [Optimized Log Parsing with Syntactic Modifications](https://arxiv.org/abs/2510.26793)
*Nafid Enan,Gias Uddin*

Main category: cs.SE

TL;DR: 对主流日志解析方法开展对比实验，提出两阶段SynLog+方案大幅提升解析准确性且无额外算力消耗，为日志分析系统的发展提供参考。


<details>
  <summary>Details</summary>
Motivation: 日志作为软件运行的重要数据基础，识别和分析日志格式对于自动化日志分析流程至关重要。当前存在多种日志解析技术，如何评价它们的效果和优缺点成为一个亟需解决的问题。

Method: 通过实证研究，系统对比分析了基于语法和基于语义的两种主要日志解析方法，以及单阶段和两阶段解析架构，并通过实验验证性能和准确性的差异。

Result: 语义方法在模板识别方面表现更好，但语法方法在效率（10到1000倍）和聚合准确率上占优；两阶段架构相比单阶段架构在准确性上有明显提升。提出的SynLog+模块作为第二阶段加入后，使语法方法的准确率提升236%，语义方法提升20%，且基本不增加运行时间。

Conclusion: 通过详尽对比实验，明确了不同日志解析方法与架构的优缺点，提出的SynLog+可有效提升日志解析准确性，并兼顾效率，为日志解析提供了新的解决思路。

Abstract: Logs provide valuable insights into system runtime and assist in software
development and maintenance. Log parsing, which converts semi-structured log
data into structured log data, is often the first step in automated log
analysis. Given the wide range of log parsers utilizing diverse techniques, it
is essential to evaluate them to understand their characteristics and
performance. In this paper, we conduct a comprehensive empirical study
comparing syntax- and semantic-based log parsers, as well as single-phase and
two-phase parsing architectures. Our experiments reveal that semantic-based
methods perform better at identifying the correct templates and syntax-based
log parsers are 10 to 1,000 times more efficient and provide better grouping
accuracy although they fall short in accurate template identification.
Moreover, two-phase architecture consistently improves accuracy compared to
single-phase architecture. Based on the findings of this study, we propose
SynLog+, a template identification module that acts as the second phase in a
two-phase log parsing architecture. SynLog+ improves the parsing accuracy of
syntax-based and semantic-based log parsers by 236\% and 20\% on average,
respectively, with virtually no additional runtime cost.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [23] [Finding Regular Herbrand Models for CHCs using Answer Set Programming](https://arxiv.org/abs/2510.26428)
*Gregoire Maire,Thomas Genet*

Main category: cs.LO

TL;DR: 作者提出用ASP工具Clingo，通过问题转换方式，用树自动机判定带代数数据类型的CHCs可满足性，并实现了半完备检测。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖像CVC4这样的SMT求解器找到有限模型，但这一方法有局限性。作者希望提出一种新的、基于ASP编码的方法来判定CHCs在ADTs上的可满足性，以增强现有工具的能力。

Method: 将CHCs与ADTs转换为ASP问题，借助Clingo工具寻找树自动机或不满足的反例，从而判定CHCs的可满足性。

Result: 实现了CHCs（含ADTs）到ASP问题的翻译，实测框架能在存在正则模型时找到树自动机，在不可满足时给出反例，达成了半完备的可满足性检测。

Conclusion: 通过将带有代数数据类型（ADT）的受约束Horn子句（CHCs）问题编码为Clingo可求解的ASP问题，可以构建出判定Herbrand模型为正则的树自动机，从而实现半完备的可满足性判定。

Abstract: We are interested in proving satisfiability of Constrained Horn Clauses
(CHCs) over Algebraic Data Types (ADTs). We propose to prove satisfiability by
building a tree automaton recognizing the Herbrand model of the CHCs. If such
an automaton exists then the model is said to be regular, i.e., the Herbrand
model is a regular set of atoms. Kostyukov et al. have shown how to derive an
automaton when CVC4 finds a finite model of the CHCs. We propose an alternative
way to build the automaton using an encoding into a SAT problem using Clingo,
an Answer Set Programming (ASP) tool. We implemented a translation of CHCs with
ADTs into an ASP problem. Combined with Clingo, we obtain a semi-complete
satisfiability checker: it finds a tree automaton if a regular Herbrand model
exists or finds a counter-example if the problem is unsatisfiable.

</details>


### [24] [Semantic Properties of Computations Defined by Elementary Inference Systems](https://arxiv.org/abs/2510.26429)
*Salvador Lucas*

Main category: cs.LO

TL;DR: 本文提出了一种基于elementary inference systems和第一阶逻辑模型的分析方法，可在一般模型下证明或反驳对象的语义属性，突破了典范模型不可计算的限制，适用于多种编程语言和系统的性质分析。


<details>
  <summary>Details</summary>
Motivation: 克服典范模型不可计算的问题，寻找在可计算模型下判定由elementary inference systems定义对象语义性质的方法，并将其应用于程序语言与推演系统的性质分析。

Method: 将Smullyan的elementary formal systems与Gentzen的推理规则结合，针对以elementary inference systems（I）定义的集合、关系或计算进行建模。利用第一阶理论Th(I)（即一组确定的Horn子句）表达对象性质，并通过在不同模型下的满足性检验（M |= F）证明这些性质。重点分析了在任意模型而非不可计算的典范模型中判定语义属性的策略。

Result: 提出了可行的模型理论分析法，使得在一般模型中对由elementary inference systems定义的集合或计算的语义属性进行（反）证成为可能，并展示了该方法在程序语言与重写系统性质分析中的应用潜力。

Conclusion: 通过在任意模型A中对Th(I)进行满足性检验，可以证明或反驳I所定义对象的语义属性F，从而规避了构造不可计算的典范模型的难题，这一理论方法特别适用于程序语言和以推演系统描述计算过程的系统的性质分析。

Abstract: We consider sets/relations/computations defined by *Elementary Inference
Systems* I, which are obtained from Smullyan's *elementary formal systems*
using Gentzen's notation for inference rules, and proof trees for atoms
P(t_1,...,t_n), where predicate P represents the considered
set/relation/computation. A first-order theory Th(I), actually a set of
definite Horn clauses, is given to I. Properties of objects defined by I are
expressed as first-order sentences F, which are proved true or false by
*satisfaction* M |= F of F in a *canonical* model M of Th(I). For this reason,
we call F a *semantic property* of I. Since canonical models are, in general,
incomputable, we show how to (dis)prove semantic properties by satisfiability
in an *arbitrary* model A of Th(I). We apply these ideas to the analysis of
properties of programming languages and systems whose computations can be
described by means of an elementary inference system. In particular,
rewriting-based systems.

</details>


### [25] [Theta as a Horn Solver](https://arxiv.org/abs/2510.26430)
*Levente Bajczi,Milán Mondok,Vince Molnár*

Main category: cs.LO

TL;DR: 本文系统描述了Theta工具在CHC验证中的方法、优势和劣势，并在配置优化后展示其真实性能，对比分析强调其独特地位。


<details>
  <summary>Details</summary>
Motivation: 虽然Theta在竞赛中表现活跃，但其验证技术、设计取舍及局限性尚未被系统性评估，因此本文填补相关研究空白。

Method: 论文详细描述了Theta所用算法，将CHCs 转换为CFAs进行分析，并通过修正配置后在竞赛基准集上的实际表现来评估工具能力。

Result: 经过配置纠正后，Theta 在基准集上的性能得到了如实反映，通过系统性剖析，突显了Theta与其他CHC解算器的差异与独特性。

Conclusion: Theta 在 CHC-COMP 竞赛中的表现因配置问题受到影响，但纠正后展示出更真实的性能水平。本论文全面分析了其优缺点，为今后的改进和工具对比提供了参考。

Abstract: Theta is a verification framework that has participated in the CHC-COMP
competition since 2023. While its core approach -- based on transforming
constrained Horn clauses (CHCs) into control-flow automata (CFAs) for analysis
-- has remained mostly unchanged, Theta's verification techniques, design
trade-offs, and limitations have remained mostly unexplored in the context of
CHCs. This paper fills that gap: we provide a detailed description of the
algorithms employed by Theta, highlighting the unique features that distinguish
it from other CHC solvers. We also analyze the strengths and weaknesses of the
tool in the context of CHC-COMP benchmarks. Notably, in the 2025 edition of the
competition, Theta's performance was impacted by a configuration issue, leading
to suboptimal results. To provide a clearer picture of Theta's actual
capabilities, we re-execute the tool on the competition benchmarks under
corrected settings and report on the resulting performance.

</details>


### [26] [Bridge and Bound: A Logic-Based Framework for Abstracting (Preliminary Report)](https://arxiv.org/abs/2510.26654)
*Andrzej Szalas*

Main category: cs.LO

TL;DR: 本文提出了基于经典逻辑的抽象建模新框架，支持必要与充分条件、近似与分层抽象，并分析其推理任务的复杂性，为复杂系统建模与推理提供理论支持。


<details>
  <summary>Details</summary>
Motivation: 抽象作为简化复杂性的核心方法，广泛应用于科学建模与知识构建，但现有研究多侧重于必要条件的推理，对抽象的充分条件和多层次抽象的探讨不足。本文旨在提出一种基于逻辑的新型抽象建模框架，以更全面支持现实建模和不完备信息的处理。

Method: 本文提出了一个基于经典逻辑的框架，用于对抽象过程进行建模。该框架形式化了源表示到抽象表示的转化，定义了近似抽象，对其最紧和精确形式进行了分析，并扩展至分层抽象体系，可以用于复杂系统的层级简化。同时，讨论了涉及相关推理任务的计算复杂性。

Result: 提出了新的逻辑抽象框架，系统定义了近似抽象及其形式，扩展到分层抽象，能够实现复杂系统和模型的层级化简。还分析了该框架相应推理任务的计算复杂性。

Conclusion: 本文构建了一套以经典逻辑为基础的新型抽象过程建模框架，能刻画必要与充分条件，不仅支持近似和分层抽象，也利于理解与开发高效的抽象推理算法，对实际系统建模和推理任务具有理论和应用价值。

Abstract: At its core, abstraction is the process of generalizing from specific
instances to broader concepts or models, with the primary objective of reducing
complexity while preserving properties essential to the intended purpose. It is
a fundamental, often implicit, principle that structures the understanding,
communication, and development of both scientific knowledge and everyday
beliefs. Studies on abstraction have evolved from its origins in Ancient Greek
philosophy through methodological approaches in psychological and philosophical
theories to computational frameworks.
  Formally, abstraction can be understood as the transformation of a source
representation into an abstract representation that discards certain details
while retaining desirable features. In real-world modeling and reasoning,
abstraction is crucial, particularly when managing imperfect or incomplete
information that calls for approximate representations. This paper introduces a
novel logic-based framework for modeling abstraction processes that goes beyond
the traditional entailment of necessary conditions to encompass sufficient
conditions as well. We define approximate abstractions, study their tightest
and exact forms, and extend the approach to layered abstractions, enabling
hierarchical simplification of complex systems and models. The computational
complexity of the related reasoning tasks is also discussed.
  For clarity, our framework is developed within classical logic, chosen for
its simplicity, expressiveness, and computational friendliness.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [27] [StreetMath: Study of LLMs' Approximation Behaviors](https://arxiv.org/abs/2510.25776)
*Chiung-Yi Tseng,Somshubhra Roy,Maisha Thasin,Danyang Zhang,Blessing Effiong*

Main category: cs.CL

TL;DR: 提出StreetMath基准，系统分析LLM在近似数学任务中的表现，发现其缺乏人类的直觉化近似能力，精确与近似运算依赖不同神经模块，成果已开源。


<details>
  <summary>Details</summary>
Motivation: 现有大量文献关注大型语言模型（LLM）在自回归结构下执行精确算术运算的能力，但其在快速、非正式的数学运算中进行近似推理的能力研究较少，尤其是在非自回归解码器模型中。本研究旨在填补这一研究空白。

Method: 我们提出了StreetMath基准，用于评估模型在真实世界近似场景下的推理能力。对不同架构的LLM进行了广泛的评测，同时应用机理可解释性技术来探测其内部计算状态。此外，还进行了精确算术与近似算术操作的神经组成分析。

Result: 研究发现，LLM即使面对需要近似答案的任务时，仍往往尝试精确计算或调用外部工具；部分模型会在早期层或步骤中得到正确答案，但解决近似任务时仍需消耗更多的token。精确与近似运算主要依靠不同的神经单元。

Conclusion: LLM在街头数学情境下并不如人类那样表现出“认知吝啬”，即优先采用近似与捷径。本文公开了StreetMath数据集和分析工具。

Abstract: There is a substantial body of literature examining the mathematical
reasoning capabilities of large language models (LLMs), particularly their
performance on precise arithmetic operations in autoregressive architectures.
However, their ability to perform approximate reasoning in informal, fast-paced
mathematical operations has received far less attention, especially among
non-autoregressive decoder models. Our work addresses this gap by introducing
StreetMath, a benchmark designed to evaluate models' approximation abilities
under real-world approximation scenarios. We conduct extensive evaluations
across different LLM architectures: Qwen3-4B-Instruct-2507,
Qwen3-4B-Thinking-2507, Dream-v0-Instruct-7B, Falcon-Mamba-7B-Instruct, and
Mamba-GPT-3B. Furthermore, we apply mechanistic interpretability techniques to
probe their internal computational states. Our analysis reveals that LLMs
generally attempt to compute exact values or invoke external tools even in
tasks that call for approximation. Moreover, while models sometimes reach the
correct answer in early layers or steps, they still consume more tokens when
solving approximation tasks. Additional experiments indicate that exact and
approximate arithmetic operations rely on largely separate neural components.
Drawing upon research on cognitive psychology, we argue that LLMs do not
exhibit cognitive miserliness in the same way humans do in street math
settings. We open source our work https://github.com/ctseng777/StreetMath

</details>


### [28] [SymCode: A Neurosymbolic Approach to Mathematical Reasoning via Verifiable Code Generation](https://arxiv.org/abs/2510.25975)
*Sina Bagheri Nezhad,Yao Li,Ameeta Agrawal*

Main category: cs.CL

TL;DR: 本文提出SymCode框架，通过生成可验证的SymPy代码显著提升LLM在数学推理任务上的准确性与透明度，表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在复杂数学推理中，文字生成易出错且难以验证，现有策略如Chain of Thought缺乏确定性验证方法，导致结果不可靠。

Method: 提出神经符号结合框架SymCode，让LLM生成可通过SymPy库验证的代码，将模型推理建立在确定性符号引擎的基础上。

Result: 在MATH-500和OlympiadBench等高难度基准上，SymCode相较于传统方法准确率最高提升了13.6个百分点，且模型推理更高效透明，将错误转化为易于检测的程序性错误。

Conclusion: SymCode通过将数学问题求解转化为可验证的代码生成任务，有效提升了LLM的数学推理准确性和可信度。

Abstract: Large Language Models (LLMs) often struggle with complex mathematical
reasoning, where prose-based generation leads to unverified and arithmetically
unsound solutions. Current prompting strategies like Chain of Thought still
operate within this unreliable medium, lacking a mechanism for deterministic
verification. To address these limitations, we introduce SymCode, a
neurosymbolic framework that reframes mathematical problem-solving as a task of
verifiable code generation using the SymPy library. We evaluate SymCode on
challenging benchmarks, including MATH-500 and OlympiadBench, demonstrating
significant accuracy improvements of up to 13.6 percentage points over
baselines. Our analysis shows that SymCode is not only more token-efficient but
also fundamentally shifts model failures from opaque logical fallacies towards
transparent, programmatic errors. By grounding LLM reasoning in a deterministic
symbolic engine, SymCode represents a key step towards more accurate and
trustworthy AI in formal domains.

</details>


### [29] [Review Based Entity Ranking using Fuzzy Logic Algorithmic Approach: Analysis](https://arxiv.org/abs/2510.25778)
*Pratik N. Kalamkar,Anupama G. Phakatkar*

Main category: cs.CL

TL;DR: 本文提出了一种结合模糊逻辑和依存分析的方法，对用户评论中的情感强度进行细分和排序，提升了情感分析的精度和实用性。


<details>
  <summary>Details</summary>
Motivation: 传统的情感分析方法（如全局词典法）未能考虑意见强度（如非常强烈的正面或负面、中度等），导致实体情感排序不够细致和精确。

Method: 本文提出了一种结合意见用词（副词、形容词、名词和动词）并基于模糊逻辑算法，将实体评论和用户查询按照情感程度（非常弱、弱、中等、强、非常强）进行分级分类，并利用句法依存关系解析相关方面词的关系，从而实现更细粒度的情感分析。

Result: 通过对相关方面的意见词进行强度分类及依存关系分析，可以有效计算并排序各实体在特定方面上的情感得分，使评测结果更加精确和支持细粒度决策。

Conclusion: 提出的方法能够细致区分评论情感强度，结合模糊逻辑和句法依存树，有效提升实体情感排序的表现，有助于更准确地理解用户意见及指导产品/服务优化。

Abstract: Opinion mining, also called sentiment analysis, is the field of study that
analyzes people opinions, sentiments, evaluations, appraisals, attitudes, and
emotions towards entities such as products, services, organizations,
individuals, issues, events, topics, and their attributes. Holistic
lexicon-based approach does not consider the strength of each opinion, i.e.,
whether the opinion is very strongly negative (or positive), strongly negative
(or positive), moderate negative (or positive), very weakly negative (or
positive) and weakly negative (or positive). In this paper, we propose approach
to rank entities based on orientation and strength of the entity reviews and
user's queries by classifying them in granularity levels (i.e. very weak, weak,
moderate, very strong and strong) by combining opinion words (i.e. adverb,
adjective, noun and verb) that are related to aspect of interest of certain
product. We shall use fuzzy logic algorithmic approach in order to classify
opinion words into different category and syntactic dependency resolution to
find relations for desired aspect words. Opinion words related to certain
aspects of interest are considered to find the entity score for that aspect in
the review.

</details>


### [30] [QCoder Benchmark: Bridging Language Generation and Quantum Hardware through Simulator-Based Feedback](https://arxiv.org/abs/2510.26101)
*Taku Mikuriya,Tatsuya Ishigaki,Masayuki Kawarada,Shunya Minami,Tadashi Kadowaki,Yohichi Suzuki,Soshun Naito,Shunya Takata,Takumi Kato,Tamotsu Basseda,Reo Yamada,Hiroya Takamura*

Main category: cs.CL

TL;DR: 本文提出了针对量子编程领域的LLMs代码生成基准QCoder Benchmark，支持量子特有评测和与人类代码对比。结果显示现有LLMs表现有限，推理型模型优于常规LLMs和人类基线。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLMs）虽然已广泛应用于自动代码生成，但在需要与硬件交互（如量子编程）领域的探索依然有限。量子编程要求编写能在量子计算机上运行的Python代码，当前尚无完善基准来评估LLMs在这一领域的能力。

Method: 本文提出了QCoder Benchmark，这是一个用于评估LLMs在量子编程代码生成任务上的基准框架。框架包括：1）基于量子模拟器环境的多样化反馈，包括电路深度、执行时间和错误分类等领域特定指标；2）收集自真实编程竞赛的人类代码样本，用于定量和定性比较LLMs与人类代码。

Result: 实验显示，即使是先进的GPT-4o模型在该基准上的准确率也仅为18.97%，而基于推理的模型如o3模型的准确率可达78%，远超人类代码平均成功率39.98%。

Conclusion: 本工作表明当前主流LLMs在量子编程领域仍有很大提升空间，但专门设计的推理型模型表现突出。QCoder Benchmark数据集和评测API为今后相关研究提供了标准和便利。

Abstract: Large language models (LLMs) have increasingly been applied to automatic
programming code generation. This task can be viewed as a language generation
task that bridges natural language, human knowledge, and programming logic.
However, it remains underexplored in domains that require interaction with
hardware devices, such as quantum programming, where human coders write Python
code that is executed on a quantum computer. To address this gap, we introduce
QCoder Benchmark, an evaluation framework that assesses LLMs on quantum
programming with feedback from simulated hardware devices. Our benchmark offers
two key features. First, it supports evaluation using a quantum simulator
environment beyond conventional Python execution, allowing feedback of
domain-specific metrics such as circuit depth, execution time, and error
classification, which can be used to guide better generation. Second, it
incorporates human-written code submissions collected from real programming
contests, enabling both quantitative comparisons and qualitative analyses of
LLM outputs against human-written codes. Our experiments reveal that even
advanced models like GPT-4o achieve only around 18.97% accuracy, highlighting
the difficulty of the benchmark. In contrast, reasoning-based models such as o3
reach up to 78% accuracy, outperforming averaged success rates of human-written
codes (39.98%). We release the QCoder Benchmark dataset and public evaluation
API to support further research.

</details>


### [31] [LASTIST: LArge-Scale Target-Independent STance dataset](https://arxiv.org/abs/2510.25783)
*DongJae Kim,Yaejin Lee,Minsu Park,Eunil Park*

Main category: cs.CL

TL;DR: 本文填补了韩语立场检测领域的研究空白，公开了大规模目标无关韩语数据集LASTIST，为相关任务和模型提供了重要资源支持。


<details>
  <summary>Details</summary>
Motivation: 当前立场检测研究几乎都集中在英文资源且多为目标相关任务，低资源语言（如韩语）及目标无关任务存在明显研究空缺。

Method: 从韩国两大政党的新闻稿中收集563,299条标注句子，构建大型韩语立场检测数据集，并结合先进的立场检测与深度学习模型做实验。

Result: 成功构建了563,299条标注韩语句子的LASTIST数据集，适用于目标无关和历时立场检测任务，并公开上线供研究者使用。

Conclusion: 本文提出了一个面向韩语、目标无关的立场检测数据集LASTIST，并使用最新深度学习模型进行了训练和验证。

Abstract: Stance detection has emerged as an area of research in the field of
artificial intelligence. However, most research is currently centered on the
target-dependent stance detection task, which is based on a person's stance in
favor of or against a specific target. Furthermore, most benchmark datasets are
based on English, making it difficult to develop models in low-resource
languages such as Korean, especially for an emerging field such as stance
detection. This study proposes the LArge-Scale Target-Independent STance
(LASTIST) dataset to fill this research gap. Collected from the press releases
of both parties on Korean political parties, the LASTIST dataset uses 563,299
labeled Korean sentences. We provide a detailed description of how we collected
and constructed the dataset and trained state-of-the-art deep learning and
stance detection models. Our LASTIST dataset is designed for various tasks in
stance detection, including target-independent stance detection and diachronic
evolution stance detection. We deploy our dataset on
https://anonymous.4open.science/r/LASTIST-3721/.

</details>


### [32] [zFLoRA: Zero-Latency Fused Low-Rank Adapters](https://arxiv.org/abs/2510.25784)
*Dhananjaya Gowda,Seoha Song,Harshith Goka,Junhyun Lee*

Main category: cs.CL

TL;DR: 本文提出zFLoRA，无显著延迟地提升LLM适配器推理效率，实验优于主流适配方法，在NPU与GPU上均达零或极低延迟。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）普遍采用适配器（adapter）用于多任务微调，虽然适配器参数占比很小，但在推理时带来的计算开销却异常突出，甚至可达基线模型的2.5倍。这对实际部署带来挑战，需要减小适配器的推理开销。

Method: 提出一种新的零延迟低秩融合适配器（zFLoRA），该方法能在保持模型原有性能的同时，不带来额外或仅带来极小的推理延迟。zFLoRA利用结构改进实现适配器与基座模型的高效融合。

Result: 在1B、3B和7B参数量的LLM上，zFLoRA在常识推理、数学推理和摘要-对话三类共18个任务上效果优异。延迟测试表明，zFLoRA在NPU（Samsung Galaxy S25+）和GPU（NVIDIA H100）平台上的推理延迟开销为零或可忽略。

Conclusion: zFLoRA能在多个下游任务和硬件平台中，几乎无延迟地实现LLM适配，优于已有的LoRA和全参数微调方法。该方案对实际部署低延迟、多任务LLM极具参考价值。

Abstract: Large language models (LLMs) are increasingly deployed with task-specific
adapters catering to multiple downstream applications. In such a scenario, the
additional compute associated with these apparently insignificant number of
adapter parameters (typically less than 1% of the base model) turns out to be
disproportionately significant during inference time (upto 2.5x times that of
the base model). In this paper, we propose a new zero-latency fused low-rank
adapter (zFLoRA) that introduces zero or negligible latency overhead on top of
the base model. Experimental results on LLMs of size 1B, 3B and 7B show that
zFLoRA compares favorably against the popular supervised fine-tuning benchmarks
including low-rank adapters (LoRA) as well as full fine-tuning (FFT).
Experiments are conducted on 18 different tasks across three different
categories namely commonsense reasoning, math reasoning and summary-dialogue.
Latency measurements made on NPU (Samsung Galaxy S25+) as well as GPU (NVIDIA
H100) platforms show that the proposed zFLoRA adapters introduce zero to
negligible latency overhead.

</details>


### [33] [BlackboxNLP-2025 MIB Shared Task: Improving Circuit Faithfulness via Better Edge Selection](https://arxiv.org/abs/2510.25786)
*Yaniv Nikankin,Dana Arad,Itay Itzhak,Anja Reusch,Adi Simhi,Gal Kesten-Pomeranz,Yonatan Belinkov*

Main category: cs.CL

TL;DR: 作者针对电路发现难题，提出自助法筛选边、基于比率的选择策略和整数线性规划三项改进，在基准测试上优于现有方法，大幅提升机制可解释性工具的有效性。


<details>
  <summary>Details</summary>
Motivation: 机制可解释性中的一大难题是电路发现，即确定模型中哪些部分在完成特定任务时发挥作用。针对现有方法的不足，作者提出改进以提升发现的准确性和可解释性。

Method: 在MIB基准下：1）使用自助法（Bootstrapping）筛选出归因分数一致的边；2）引入基于比率的选择策略，优先选择得分高且为正的边，以在性能和可靠性间权衡；3）用整数线性规划代替传统贪心策略。

Result: 提出的三项新方法能获得更具真实性、表现更佳的电路结构，在多个任务和模型上均超过领先方法，提升了机制可解释性领域的技术水平。

Conclusion: 本文提出的三项改进方法使得电路发现更为可靠和有效，在多个基准任务和模型上优于现有方法。

Abstract: One of the main challenges in mechanistic interpretability is circuit
discovery, determining which parts of a model perform a given task. We build on
the Mechanistic Interpretability Benchmark (MIB) and propose three key
improvements to circuit discovery. First, we use bootstrapping to identify
edges with consistent attribution scores. Second, we introduce a simple
ratio-based selection strategy to prioritize strong positive-scoring edges,
balancing performance and faithfulness. Third, we replace the standard greedy
selection with an integer linear programming formulation. Our methods yield
more faithful circuits and outperform prior approaches across multiple MIB
tasks and models. Our code is available at:
https://github.com/technion-cs-nlp/MIB-Shared-Task.

</details>


### [34] [LISTEN to Your Preferences: An LLM Framework for Multi-Objective Selection](https://arxiv.org/abs/2510.25799)
*Adam S. Jovine,Tinghan Ye,Francis Bahk,Jingjing Wang,David B. Shmoys,Peter I. Frazier*

Main category: cs.CL

TL;DR: 该文提出LISTEN框架，利用大语言模型根据专家自然语言偏好辅助复杂多目标选择，并分别通过参数化与非参数化两种算法实现，验证有效性，降低专家负担。


<details>
  <summary>Details</summary>
Motivation: 在人类专家进行多目标决策时，由于很难将复杂且隐性的偏好形式化，选择最佳方案成为瓶颈。该论文希望降低偏好表达难度，直接通过自然语言引导决策。

Method: 提出LISTEN框架，利用大型语言模型（LLM）作为零样本偏好指导，只需专家用自然语言描述高层次目标。具体包括两种算法：LISTEN-U（用LLM迭代优化参数化效用函数）和LISTEN-T（用LLM在小批量方案中做锦标赛式选择，无需参数化）。

Result: 在航班预订、购物和考试排程等多类任务上实证，LISTEN-U在偏好易用参数化表达时效果优异，而LISTEN-T表现更稳健。还提出了偏好参数化一致性的创新度量指标，用于判断何种情况下哪种方式更优。

Conclusion: LISTEN框架可直接用自然语言引导复杂的多目标决策，降低传统偏好获取的认知负担，对多目标选择问题提供了新方向。

Abstract: Human experts often struggle to select the best option from a large set of
items with multiple competing objectives, a process bottlenecked by the
difficulty of formalizing complex, implicit preferences. To address this, we
introduce LISTEN, a framework that leverages a Large Language Model (LLM) as a
zero-shot preference oracle, guided only by an expert's high-level priorities
in natural language. To operate within LLM constraints like context windows and
inference costs, we propose two iterative algorithms: LISTEN-U, which uses the
LLM to refine a parametric utility function, and LISTEN-T, a non-parametric
method that performs tournament-style selections over small batches of
solutions. Evaluated on diverse tasks including flight booking, shopping, and
exam scheduling, our results show LISTEN-U excels when preferences are
parametrically aligned (a property we measure with a novel concordance metric),
while LISTEN-T offers more robust performance. This work explores a promising
direction for steering complex multi-objective decisions directly with natural
language, reducing the cognitive burden of traditional preference elicitation.

</details>


### [35] [Beyond Length: Quantifying Long-Range Information for Long-Context LLM Pretraining Data](https://arxiv.org/abs/2510.25804)
*Haoran Deng,Yingyu Lin,Zhenghao Lin,Xiao Liu,Yizhou Sun,Yi-An Ma,Yeyun Gong*

Main category: cs.CL

TL;DR: 本论文提出LongFilter数据筛选框架，通过度量长文本信息增益，提升长上下文语言模型训练效率和效果，并在多个基准上取得明显进步。


<details>
  <summary>Details</summary>
Motivation: 随着长上下文语言模型的发展，模型在推理、代码生成和文档总结等任务中表现出更强的能力，但大量可用的长文本数据实际上只包含局部依赖，缺乏真正有意义的长距离依赖，导致模型训练效率低下。因此，急需一种有效筛选对长上下文预训练有价值的数据的方法。

Method: 提出LongFilter框架，通过对比模型在长上下文和短上下文下的预测，衡量长上下文带来的信息增益，从而筛选出对长程依赖有重要作用的数据样本。

Result: 使用LLaMA-3-8B模型将上下文长度从8K扩展到64K，并通过LongFilter筛选数据，在HELMET、LongBench和RULER等基准上取得了显著性能提升。

Conclusion: LongFilter能够高效筛选高质量、有长距离依赖的数据，提高长上下文语言模型的预训练效率和下游任务表现。

Abstract: Long-context language models unlock advanced capabilities in reasoning, code
generation, and document summarization by leveraging dependencies across
extended spans of text. However, a significant portion of readily available
long-text data lacks meaningful long-distance dependencies; most spans can be
predicted using only local context. Training on such data is inefficient,
making careful data selection crucial. Therefore, we introduce LongFilter, a
framework for curating training data tailored to long-context pretraining.
LongFilter measures the information gain provided by extended context by
contrasting model predictions under long-context versus short-context settings,
thereby identifying samples where long-range dependencies are essential.
Experiments with LLaMA-3-8B, extending its context length from 8K to 64K, show
that LongFilter efficiently selects high-quality data and yields substantial
improvements on benchmarks such as HELMET, LongBench, and RULER.

</details>


### [36] [Ideology-Based LLMs for Content Moderation](https://arxiv.org/abs/2510.25805)
*Stefano Civelli,Pietro Bernardelle,Nardiena A. Pratama,Gianluca Demartini*

Main category: cs.CL

TL;DR: 角色设定会导致大型语言模型在内容审核时产生微妙的意识形态偏见，威胁公正性，尤其容易强化党派立场，需警惕其在敏感应用中的风险。


<details>
  <summary>Details</summary>
Motivation: 在内容审核系统中，保障AI公平和中立性日益重要。作者关注角色设定（persona adoption）是否会改变LLM对有害内容的判断，进而影响系统公正性。

Method: 分析不同LLM架构、规模和内容模态下，采用不同政治倾向角色对有害内容分类的一致性与公平性影响，包括主观一致性、准确度评估及一个面向政治议题的额外实验。

Result: 表面上Persona影响整体分类准确率甚微，但更深入分析显示，带有不同政治倾向的Persona对有害内容判定有显著差异。尤其大模型在接纳与其理念一致Persona时，一致性更高，但与其他分歧更大，展现了角色对输出的深层影响。

Conclusion: 采用不同角色（persona）会引入微妙的意识形态偏见，使大型语言模型的输出在表面中立下强化党派观点，给内容审核等中立性要求高的应用带来风险。

Abstract: Large language models (LLMs) are increasingly used in content moderation
systems, where ensuring fairness and neutrality is essential. In this study, we
examine how persona adoption influences the consistency and fairness of harmful
content classification across different LLM architectures, model sizes, and
content modalities (language vs. vision). At first glance, headline performance
metrics suggest that personas have little impact on overall classification
accuracy. However, a closer analysis reveals important behavioral shifts.
Personas with different ideological leanings display distinct propensities to
label content as harmful, showing that the lens through which a model "views"
input can subtly shape its judgments. Further agreement analyses highlight that
models, particularly larger ones, tend to align more closely with personas from
the same political ideology, strengthening within-ideology consistency while
widening divergence across ideological groups. To show this effect more
directly, we conducted an additional study on a politically targeted task,
which confirmed that personas not only behave more coherently within their own
ideology but also exhibit a tendency to defend their perspective while
downplaying harmfulness in opposing views. Together, these findings highlight
how persona conditioning can introduce subtle ideological biases into LLM
outputs, raising concerns about the use of AI systems that may reinforce
partisan perspectives under the guise of neutrality.

</details>


### [37] [Beyond Long Context: When Semantics Matter More than Tokens](https://arxiv.org/abs/2510.25816)
*Tarun Kumar Chawdhury,Jon D. Duke*

Main category: cs.CL

TL;DR: 提出了适用于EHR的实体增强检索（CLEAR）方法，显著提升了长篇临床文档问答的准确率与效率，证明实体感知是提升医疗语义问答的关键路径。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）中的临床文档以base64编码的附件形式存储在FHIR DocumentReference资源中，这导致语义问答任务变得困难。同时，传统的向量数据库方法常常无法捕捉到细微的临床关系。

Method: 引入了Clinical Entity Augmented Retrieval（CLEAR）方法，这种方法利用了实体感知的检索。研究团队还开发了一个临床笔记问答评估平台，用于验证CLEAR方法与零样本大上下文推理方法以及传统分块检索增强生成方法的效果。评估平台在12份真实临床笔记上进行了测试，笔记长度从10,000到65,000 tokens不等。

Result: CLEAR方法在F1分数上达到0.90（相比基础向量检索方法的0.86），且减少了70%以上的token使用量。在评估平台的测试中，CLEAR总体胜率为58.3%，平均语义相似度为0.878，使用的token比大上下文处理少78%。对于长度超过65,000 tokens的长文档，胜率提高到75%。

Conclusion: 实体感知检索能够极大提升临床自然语言处理中的效率和准确性。提出的评估框架也为注重语义精度和计算效率的临床问答系统评测提供了可复用且透明的标准。

Abstract: Electronic Health Records (EHR) store clinical documentation as base64
encoded attachments in FHIR DocumentReference resources, which makes semantic
question answering difficult. Traditional vector database methods often miss
nuanced clinical relationships. The Clinical Entity Augmented Retrieval (CLEAR)
method, introduced by Lopez et al. 2025, uses entity aware retrieval and
achieved improved performance with an F1 score of 0.90 versus 0.86 for
embedding based retrieval, while using over 70 percent fewer tokens. We
developed a Clinical Notes QA Evaluation Platform to validate CLEAR against
zero shot large context inference and traditional chunk based retrieval
augmented generation. The platform was tested on 12 clinical notes ranging from
10,000 to 65,000 tokens representing realistic EHR content. CLEAR achieved a
58.3 percent win rate, an average semantic similarity of 0.878, and used 78
percent fewer tokens than wide context processing. The largest performance
gains occurred on long notes, with a 75 percent win rate for documents
exceeding 65,000 tokens. These findings confirm that entity aware retrieval
improves both efficiency and accuracy in clinical natural language processing.
The evaluation framework provides a reusable and transparent benchmark for
assessing clinical question answering systems where semantic precision and
computational efficiency are critical.

</details>


### [38] [A Survey on Efficient Large Language Model Training: From Data-centric Perspectives](https://arxiv.org/abs/2510.25817)
*Junyu Luo,Bohan Wu,Xiao Luo,Zhiping Xiao,Yiqiao Jin,Rong-Cheng Tu,Nan Yin,Yifan Wang,Jingyang Yuan,Wei Ju,Ming Zhang*

Main category: cs.CL

TL;DR: 本综述围绕如何高效利用数据进行大语言模型后训练进行了系统梳理，概括了方法分类与核心突破，总结了挑战，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 目前LLM后训练成本高、标注数据难获、数据扩增边际收益递减，业界急需提升数据利用率，从而降低成本并充分发挥大模型潜力。

Method: 提出了数据高效后训练方法的分类体系，从数据选择、质量提升、合成数据生成、数据蒸馏与压缩、自进化数据生态等方面进行系统梳理，并对代表性方法逐一总结。

Result: 系统总结了数据高效LLM后训练领域的主要方法和挑战，指出了未解决的关键问题，并为未来研究指明了方向，还给出了相关方法的代表论文列表。

Conclusion: 本文系统地调研了提高大语言模型（LLM）后训练阶段数据利用效率的各类方法，并对未来方向提出了展望。强调了数据高效性在实现大模型能力最大化中的关键作用。

Abstract: Post-training of Large Language Models (LLMs) is crucial for unlocking their
task generalization potential and domain-specific capabilities. However, the
current LLM post-training paradigm faces significant data challenges, including
the high costs of manual annotation and diminishing marginal returns on data
scales. Therefore, achieving data-efficient post-training has become a key
research question. In this paper, we present the first systematic survey of
data-efficient LLM post-training from a data-centric perspective. We propose a
taxonomy of data-efficient LLM post-training methods, covering data selection,
data quality enhancement, synthetic data generation, data distillation and
compression, and self-evolving data ecosystems. We summarize representative
approaches in each category and outline future research directions. By
examining the challenges in data-efficient LLM post-training, we highlight open
problems and propose potential research avenues. We hope our work inspires
further exploration into maximizing the potential of data utilization in
large-scale model training. Paper List:
https://github.com/luo-junyu/Awesome-Data-Efficient-LLM

</details>


### [39] [Evaluating the Impact of LLM-Assisted Annotation in a Perspectivized Setting: the Case of FrameNet Annotation](https://arxiv.org/abs/2510.25904)
*Frederico Belcavello,Ely Matos,Arthur Lorenzi,Lisandra Bonoto,Lívia Ruiz,Luiz Fernando Pereira,Victor Herbst,Yulla Navarro,Helen de Andrade Abreu,Lívia Dutra,Tiago Timponi Torrent*

Main category: cs.CL

TL;DR: LLM在语义角色标注上的完全自动化不及人工；半自动结合可提高效率并增强多样性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM已被广泛用于数据集和语言资源的创建，但在以特定视角（如语义框架）下，系统评价其在语义注释上的表现及影响的研究仍较为缺乏。

Method: 设计三种实验（人工、自动、半自动），对比分析注释时间、覆盖度和多样性三项指标，使用LLM作为语义角色标注工具。

Result: 半自动设置下，注释多样性提升、覆盖度与人工接近，而完全自动化虽然快，但多样性和覆盖度均大幅下降。

Conclusion: 半自动（人工+LLM）语义注释方式在保持覆盖度的同时提升了框架多样性，而完全自动化方法除了标注速度快，其他指标均表现不佳。

Abstract: The use of LLM-based applications as a means to accelerate and/or substitute
human labor in the creation of language resources and dataset is a reality.
Nonetheless, despite the potential of such tools for linguistic research,
comprehensive evaluation of their performance and impact on the creation of
annotated datasets, especially under a perspectivized approach to NLP, is still
missing. This paper contributes to reduction of this gap by reporting on an
extensive evaluation of the (semi-)automatization of FrameNet-like semantic
annotation by the use of an LLM-based semantic role labeler. The methodology
employed compares annotation time, coverage and diversity in three experimental
settings: manual, automatic and semi-automatic annotation. Results show that
the hybrid, semi-automatic annotation setting leads to increased frame
diversity and similar annotation coverage, when compared to the human-only
setting, while the automatic setting performs considerably worse in all
metrics, except for annotation time.

</details>


### [40] [RECAP: Reproducing Copyrighted Data from LLMs Training with an Agentic Pipeline](https://arxiv.org/abs/2510.25941)
*André V. Duarte,Xuying li,Bin Zeng,Arlindo L. Oliveira,Lei Li,Zhuo Li*

Main category: cs.CL

TL;DR: 提出了RECAP流程，通过反馈引导和破解拒答模块，能更有效挖掘LLM记忆的训练数据，并在实际基准测试中效果明显提升。


<details>
  <summary>Details</summary>
Motivation: 在无法直接检查大型语言模型（LLM）训练数据的情况下，如何判断模型见过哪些内容是一个有挑战性的问题。作者认为，最有说服力的证据是模型能够自发准确复现目标内容，因此提出了本研究。

Method: 提出了RECAP方案：通过代理流程反复引导LLM输出目标内容，并利用第二个语言模型与参考原文比对，发现不一致后生成最小化修正提示，再反馈引导LLM继续生成；为应对LLM对敏感内容的拒答行为，还加入了破解模块。

Result: 在新的EchoTrace基准（涵盖30余本完整书籍）上评估，RECAP方法在多轮引导下，模型复现目标内容的准确度大幅提升。例如，用GPT-4.1提取受版权保护文本，其ROUGE-L分数从0.38增至0.47，提升近24%。

Conclusion: RECAP方法能有效挖掘和验证LLM被记住的训练数据片段，显著优于单次生成，推进了LLM可追溯性与安全性研究。

Abstract: If we cannot inspect the training data of a large language model (LLM), how
can we ever know what it has seen? We believe the most compelling evidence
arises when the model itself freely reproduces the target content. As such, we
propose RECAP, an agentic pipeline designed to elicit and verify memorized
training data from LLM outputs. At the heart of RECAP is a feedback-driven
loop, where an initial extraction attempt is evaluated by a secondary language
model, which compares the output against a reference passage and identifies
discrepancies. These are then translated into minimal correction hints, which
are fed back into the target model to guide subsequent generations. In
addition, to address alignment-induced refusals, RECAP includes a jailbreaking
module that detects and overcomes such barriers. We evaluate RECAP on
EchoTrace, a new benchmark spanning over 30 full books, and the results show
that RECAP leads to substantial gains over single-iteration approaches. For
instance, with GPT-4.1, the average ROUGE-L score for the copyrighted text
extraction improved from 0.38 to 0.47 - a nearly 24% increase.

</details>


### [41] [Revisiting Multilingual Data Mixtures in Language Model Pretraining](https://arxiv.org/abs/2510.25947)
*Negar Foroutan,Paul Teiletche,Ayush Kumar Tarun,Antoine Bosselut*

Main category: cs.CL

TL;DR: 多语种数据合理分布能提升LLM性能，不存在预期的多语种魔咒，英语作为中心语言对所有语种都有效。


<details>
  <summary>Details</summary>
Motivation: 探讨在大型语言模型预训练中，不同多语种数据混合对模型表现和语言覆盖的影响，并验证‘多语种魔咒’的普遍假设。

Method: 训练了1.1B和3B参数的大型语言模型，使用包含25到400种语言的多样化多语种语料，分析不同数据混合对模型性能的影响。

Result: 结合英语和多语种数据不会显著降低任何一种语言组的性能，只要语料中各语言有足够的token。英语作为枢纽语言对各语言家族均有帮助，但从某一语言家族内选择pivot语言未必提升家族内部表现；在此规模下，随着训练语言数量增加，并未观察到明显的‘多语种魔咒’。

Conclusion: 只要预训练语料分配均衡，多语种数据不仅不会损害模型性能，甚至在低资源情境下也可提升模型能力。

Abstract: The impact of different multilingual data mixtures in pretraining large
language models (LLMs) has been a topic of ongoing debate, often raising
concerns about potential trade-offs between language coverage and model
performance (i.e., the curse of multilinguality). In this work, we investigate
these assumptions by training 1.1B and 3B parameter LLMs on diverse
multilingual corpora, varying the number of languages from 25 to 400. Our study
challenges common beliefs surrounding multilingual training. First, we find
that combining English and multilingual data does not necessarily degrade the
in-language performance of either group, provided that languages have a
sufficient number of tokens included in the pretraining corpus. Second, we
observe that using English as a pivot language (i.e., a high-resource language
that serves as a catalyst for multilingual generalization) yields benefits
across language families, and contrary to expectations, selecting a pivot
language from within a specific family does not consistently improve
performance for languages within that family. Lastly, we do not observe a
significant "curse of multilinguality" as the number of training languages
increases in models at this scale. Our findings suggest that multilingual data,
when balanced appropriately, can enhance language model capabilities without
compromising performance, even in low-resource settings

</details>


### [42] [Semantic Label Drift in Cross-Cultural Translation](https://arxiv.org/abs/2510.25967)
*Mohsinul Kabir,Tasnim Ahmed,Md Mezbaur Rahman,Polydoros Giannouris,Sophia Ananiadou*

Main category: cs.CL

TL;DR: 本文发现，源-目标语言的文化差异会导致机器翻译中的语义标签漂移，特别是在文化敏感领域。大语言模型编码的文化知识可能放大这一风险，呼吁未来机器翻译研究关注文化对语义标签的影响。


<details>
  <summary>Details</summary>
Motivation: 低资源语言机器翻译常通过高资源语言生成合成数据，现有研究关注翻译的情感保留，但文化对语义标签影响研究不足，本文旨在填补这一空白。

Method: 通过对不同文化敏感性领域的数据进行翻译实验，比较传统神经/统计机器翻译系统与大语言模型的表现，分析语义标签在不同翻译场景下的漂移情况。

Result: （1）现有机器翻译系统特别是在文化敏感领域会产生标签漂移；（2）现代大语言模型内部包含文化知识，利用这些知识可能加剧标签漂移；（3）源语言与目标语言之间的文化相似度是影响语义标签保留的关键因素。

Conclusion: 文化因素在机器翻译过程中对语义标签的保留有显著影响，忽视文化因素可能带来标签偏移甚至文化误解。

Abstract: Machine Translation (MT) is widely employed to address resource scarcity in
low-resource languages by generating synthetic data from high-resource
counterparts. While sentiment preservation in translation has long been
studied, a critical but underexplored factor is the role of cultural alignment
between source and target languages. In this paper, we hypothesize that
semantic labels are drifted or altered during MT due to cultural divergence.
Through a series of experiments across culturally sensitive and neutral
domains, we establish three key findings: (1) MT systems, including modern
Large Language Models (LLMs), induce label drift during translation,
particularly in culturally sensitive domains; (2) unlike earlier statistical MT
tools, LLMs encode cultural knowledge, and leveraging this knowledge can
amplify label drift; and (3) cultural similarity or dissimilarity between
source and target languages is a crucial determinant of label preservation. Our
findings highlight that neglecting cultural factors in MT not only undermines
label fidelity but also risks misinterpretation and cultural conflict in
downstream applications.

</details>


### [43] [NeuronMM: High-Performance Matrix Multiplication for LLM Inference on AWS Trainium](https://arxiv.org/abs/2510.25977)
*Dinghong Song,Jierui Xu,Weichu Yang,Pengfei Su,Dong Li*

Main category: cs.CL

TL;DR: 论文针对AWS Trainium加速器在LLM推理中的性能瓶颈，提出专用矩阵乘法优化方法，显著提升推理速度，相较官方方案提升最高达2.49倍。


<details>
  <summary>Details</summary>
Motivation: 由于AWS最新开发的AI加速器Trainium在大模型训练和推理方面有强大的性能潜力，但其独特的体系结构（如脉动阵列和特殊数据布局要求）导致高效利用具有挑战性。提升Trainium在LLM推理场景下的性能成为迫切需求。

Method: 本文针对LLM推理的核心计算单元——矩阵乘法（matmul），研发并优化了适配Trainium的高性能实现，提出了融合内核与新型缓存策略，以减少跨层数据移动、提升SRAM带宽利用率，并规避昂贵的矩阵转置操作。

Result: 在九个数据集和四个主流LLM上的实验验证显示，相比AWS官方实现，本文方案在matmul核层面平均提升1.35倍（最高2.22倍），在端到端LLM推理任务上平均提升1.66倍（最高2.49倍）。

Conclusion: 通过面向Trainium的专用内核融合与缓存优化，大幅提升了LLM推理性能，为AI加速器的软硬融合优化提供了有效路径。

Abstract: AI accelerators, customized to AI workloads, provide cost-effective and
high-performance solutions for training and inference. Trainium, an AI
accelerator recently developed by Amazon Web Services (AWS), provides an
attractive option for LLM training and inference through its heterogeneous
architecture. However, leveraging Trainium architecture for high performance
can be challenging because of its systolic array architecture and special
requirement on data layout. In this paper, we design high-performance matrix
multiplication (matmul), a critical compute kernel, for LLM inference on
Trainium. We introduce a series of techniques customized to Trainium based on
kernel fusion and novel caching strategies to reduce data movement across the
software-managed memory hierarchy, maximize SRAM bandwidth, and avoid expensive
matrix transpose. Evaluating with nine datasets and four recent LLMs, we show
that our system largely outperforms the state-of-the-art matmul implemented by
AWS on Trainium: at the level of matmul kernel, it achieves an average 1.35x
speedup (up to 2.22x), which translates to an average 1.66x speedup (up to
2.49x) for end-to-end LLM inference.

</details>


### [44] [AttnCache: Accelerating Self-Attention Inference for LLM Prefill via Attention Cache](https://arxiv.org/abs/2510.25979)
*Dinghong Song,Yuan Feng,Yiwei Wang,Shangye Chen,Cyril Guyot,Filip Blagojevic,Hyeran Jeon,Pengfei Su,Dong Li*

Main category: cs.CL

TL;DR: 本文提出一种名为AttnCache的注意力图缓存框架，通过记忆与复用相似注意力图，显著提升大模型推理前填阶段计算速度，几乎无精度损失。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在推理前填阶段（prefill），如分类、问答等任务，常因自注意力机制计算复杂度高而成为性能瓶颈。

Method: 作者观察到不同语义句子产生的注意力图往往相似，据此提出AttnCache框架，建立注意力图缓存数据库，通过高效缓存和相似性搜索，在推理阶段复用已缓存的注意力图，减少重复计算。

Result: 在CPU上实现了平均1.2倍整体加速和2倍注意力加速，在GPU上实现了1.6倍整体加速和3倍注意力加速，准确率损失极低。

Conclusion: AttnCache可以有效加速大模型推理前填阶段的自注意力计算，大幅提升实际应用效率。

Abstract: Large Language Models (LLMs) are widely used in generative applications such
as chatting, code generation, and reasoning. However, many realworld workloads
such as classification, question answering, recommendation, and text embedding
rely solely on the prefill stage of inference, where the model encodes input
sequences without performing autoregressive decoding. In these prefill only
scenarios, the self-attention computation becomes the primary performance
bottleneck due to its quadratic complexity with respect to sequence length. In
this paper, we observe that semantically different sentences often produce
similar attention maps across layers and heads. Building on this insight, we
propose AttnCache, a framework that accelerates the prefill stage of LLM
inference by retrieving and reusing similar attention maps. Based on an
attention map memorization database, AttnCache employs efficient caching and
similarity search techniques to identify and reuse pre-cached attention maps
during inference, thereby reducing the computational overhead of
self-attention. Experimental results show that AttnCache achieves an average of
1.2x end-to-end and 2x attention speedup on CPU, and 1.6x end-to-end and 3x
attention speedup on GPU, with negligible accuracy degradation.

</details>


### [45] [Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning](https://arxiv.org/abs/2510.25992)
*Yihe Deng,I-Hung Hsu,Jun Yan,Zifeng Wang,Rujun Han,Gufeng Zhang,Yanfei Chen,Wei Wang,Tomas Pfister,Chen-Yu Lee*

Main category: cs.CL

TL;DR: SRL通过引入专家式逐步奖励和推理独白，结合SFT和RL思路，增强小模型复杂推理能力，性能优于以往方法，适用面广。


<details>
  <summary>Details</summary>
Motivation: 大模型在需要多步推理的问题上常常表现不足，现有的方法如RLVR和SFT各有明显局限：RLVR在正确解极难采样时常常无效，SFT容易过拟合且死板。因此，作者希望提出一种兼顾灵活推理与丰富学习信号的新方法。

Method: 作者提出了Supervised Reinforcement Learning (SRL)框架，将问题求解过程视为生成一系列逻辑“动作”。SRL通过训练模型在行动前生成内部推理独白，并基于模型动作与专家动作的逐步相似性给予奖励，从而以更细腻、丰富的监督信号引导学习。

Result: SRL能让小型开源模型学会之前SFT或RLVR无法胜任的复杂推理问题。先用SRL预训练再用RLVR微调，整体表现最佳。此外，SRL在软件工程等任务也具有良好泛化能力。

Conclusion: SRL是一种强大且通用的训练框架，能够显著提升小型LLM在推理类任务和工程类任务上的表现，为解决复杂推理问题提供了重要思路。

Abstract: Large Language Models (LLMs) often struggle with problems that require
multi-step reasoning. For small-scale open-source models, Reinforcement
Learning with Verifiable Rewards (RLVR) fails when correct solutions are rarely
sampled even after many attempts, while Supervised Fine-Tuning (SFT) tends to
overfit long demonstrations through rigid token-by-token imitation. To address
this gap, we propose Supervised Reinforcement Learning (SRL), a framework that
reformulates problem solving as generating a sequence of logical "actions". SRL
trains the model to generate an internal reasoning monologue before committing
to each action. It provides smoother rewards based on the similarity between
the model's actions and expert actions extracted from the SFT dataset in a
step-wise manner. This supervision offers richer learning signals even when all
rollouts are incorrect, while encouraging flexible reasoning guided by expert
demonstrations. As a result, SRL enables small models to learn challenging
problems previously unlearnable by SFT or RLVR. Moreover, initializing training
with SRL before refining with RLVR yields the strongest overall performance.
Beyond reasoning benchmarks, SRL generalizes effectively to agentic software
engineering tasks, establishing it as a robust and versatile training framework
for reasoning-oriented LLMs.

</details>


### [46] [PORTool: Tool-Use LLM Training with Rewarded Tree](https://arxiv.org/abs/2510.26020)
*Feijie Wu,Weiwu Zhu,Yuxiang Zhang,Soumya Chatterjee,Jiarong Zhu,Fan Mo,Rodin Luo,Jing Gao*

Main category: cs.CL

TL;DR: 该论文提出PORTool，一种基于强化学习的新训练方法，有效提升了大语言模型在复杂工具使用场景下的准确率与效率。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）在工具使用方面主要依赖于静态数据集训练，能够与外部工具协作实现多步推理，但存在仅模仿通用工具调用流程、在动态工具调用环境下探索能力有限和性能受限的问题。

Method: 提出了PORTool，这是一种基于强化学习（RL）的方法。PORTool首先为每个查询生成多条推理轨迹（rollouts），这些轨迹在前若干步可能重合，形成树状结构；然后，针对每个步骤根据其生成正确答案及调用工具的成功与否分配奖励；在不同分叉下的步骤奖励也有所不同。最终，利用步骤级奖励与轨迹级奖励结合来训练LLM。

Result: 实验证明PORTool在涉及17个工具、涵盖时效性和时不变主题的多工具调用任务中，在终极准确率及工具调用步数方面相较于其他训练方法均有显著提升。应用消融实验也证明了步骤级奖励机制的必要性和设计的鲁棒性。

Conclusion: PORTool强化了LLM对多种正确解题路径的探索能力，在动态和复杂的工具调用环境下取得优异表现，展现了强化学习结合步级奖励机制在提升LLM工具使用效果方面的巨大潜力。

Abstract: Current tool-use large language models (LLMs) are trained on static datasets,
enabling them to interact with external tools and perform multi-step,
tool-integrated reasoning, which produces tool-call trajectories. However,
these models imitate how a query is resolved in a generic tool-call routine,
thereby failing to explore possible solutions and demonstrating limited
performance in an evolved, dynamic tool-call environment. In this work, we
propose PORTool, a reinforcement learning (RL) method that encourages a
tool-use LLM to explore various trajectories yielding the correct answer.
Specifically, this method starts with generating multiple rollouts for a given
query, and some of them share the first few tool-call steps, thereby forming a
tree-like structure. Next, we assign rewards to each step, based on its ability
to produce a correct answer and make successful tool calls. A shared step
across different trajectories receives the same reward, while different steps
under the same fork receive different rewards. Finally, these step-wise rewards
are used to calculate fork-relative advantages, blended with
trajectory-relative advantages, to train the LLM for tool use. The experiments
utilize 17 tools to address user queries, covering both time-sensitive and
time-invariant topics. We conduct ablation studies to systematically justify
the necessity and the design robustness of step-wise rewards. Furthermore, we
compare the proposed PORTool with other training approaches and demonstrate
significant improvements in final accuracy and the number of tool-call steps.

</details>


### [47] [Rethinking Cross-lingual Alignment: Balancing Transfer and Cultural Erasure in Multilingual LLMs](https://arxiv.org/abs/2510.26024)
*HyoJung Han,Sweta Agrawal,Eleftheria Briakou*

Main category: cs.CL

TL;DR: 跨语种对齐虽提升事实迁移但弱化文化本土化，作者提出Surgical Steering方法，通过分层激活，有效解决这一权衡，提升结果表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型跨语种对齐虽提升了多语种知识迁移能力，但导致“文化抹除”，即模型难以输出与目标语言文化相关的答案。为此，有必要系统性分析知识迁移与文化本土化之间的权衡，并设计更优方法平衡二者。

Method: 提出并应用transfer-localization plane评价框架，量化跨语种知识迁移与文化抹除的权衡。进一步通过模型层级分析，分别在不同层实现目标的激活引导（Surgical Steering），实现在推理阶段分离两种目标。

Result: 实验表明，现有CLA方法在所有六种语言下都会用文化本土化的损失换取事实知识迁移的提升。Surgical Steering方法通过分层激活引导，实现了两者的更优平衡。

Conclusion: 现有跨语种对齐方法在提升事实性知识迁移的同时，往往以文化本土化能力的损失为代价，两者存在明显的权衡。作者提出的Surgical Steering方法能够有效平衡两者，克服传统方法的局限。

Abstract: Cross-lingual alignment (CLA) aims to align multilingual representations,
enabling Large Language Models (LLMs) to seamlessly transfer knowledge across
languages. While intuitive, we hypothesize, this pursuit of representational
convergence can inadvertently cause "cultural erasure", the functional loss of
providing culturally-situated responses that should diverge based on the query
language. In this work, we systematically analyze this trade-off by introducing
a holistic evaluation framework, the transfer-localization plane, which
quantifies both desirable knowledge transfer and undesirable cultural erasure.
Using this framework, we re-evaluate recent CLA approaches and find that they
consistently improve factual transfer at the direct cost of cultural
localization across all six languages studied. Our investigation into the
internal representations of these models reveals a key insight: universal
factual transfer and culturally-specific knowledge are optimally steerable at
different model layers. Based on this finding, we propose Surgical Steering, a
novel inference-time method that disentangles these two objectives. By applying
targeted activation steering to distinct layers, our approach achieves a better
balance between the two competing dimensions, effectively overcoming the
limitations of current alignment techniques.

</details>


### [48] [Artificial Intelligence-Enabled Analysis of Radiology Reports: Epidemiology and Consequences of Incidental Thyroid Findings](https://arxiv.org/abs/2510.26032)
*Felipe Larios,Mariana Borras-Osorio,Yuqi Wu,Ana Gabriela Claros,David Toro-Tobon,Esteban Cabezas,Ricardo Loor-Torres,Maria Mateo Chavez,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Maria Lizarazo Jimenez,Ivan Mateo Alzamora,Misk Al Zahidy,Marcelo Montero,Ana Cristina Proano,Cristian Soto Jacome,Jungwei W. Fan,Oscar J. Ponce-Ponte,Megan E. Branda,Naykky Singh Ospina,Juan P. Brito*

Main category: cs.CL

TL;DR: 研究开发了NLP流程识别影像报告中的偶发甲状腺异常，发现ITF普遍存在且明显提高患者接受后续甲状腺检查、治疗甚至被诊断为癌症的可能，强调了甲状腺癌过度诊断风险和优化随访流程的必要性。


<details>
  <summary>Details</summary>
Motivation: 随着医学影像技术的发展，偶然发现甲状腺异常（ITFs）的病例越来越多，但其发生率、影像特征、临床后果尚不明确。该研究旨在通过自然语言处理（NLP）技术系统性分析ITFs在影像学报告中的特征以及对患者临床路径的影响。

Method: 研究采用回顾性队列设计，对2017年至2023年在Mayo Clinic拍摄的带有甲状腺的影像报告进行分析。利用基于transformer的NLP流程自动识别影像报告中的ITFs，并提取结节相关特征。通过逻辑回归分析人口统计学和影像学相关因素对ITFs检出的影响。

Result: 在115,683名无甲状腺病史的成人影像中，共检出9,077例ITF（检出率7.8%），其中92.9%为结节。ITFs检出率在女性、老年人、高BMI、肿瘤科和内科医师开单者显著增加。与胸部CT相比，颈部CT、PET及核医学扫描更易检出ITF。报告中结节特征记录不完整，仅结节大小在44%报告中出现，其他特征（如钙化）不到15%。有ITF患者较无ITF者检出甲状腺结节、穿刺、手术和癌症诊断的风险更高。多数癌症为乳头状癌，并且，在ITF被发现后癌症体积更大。

Conclusion: ITFs在非甲状腺相关影像中较为常见，且易引发后续检查，导致小、低风险甲状腺癌的检出增加，加强了甲状腺癌过度诊断的问题。建议推进影像报告标准化及更具选择性的后续随访。

Abstract: Importance Incidental thyroid findings (ITFs) are increasingly detected on
imaging performed for non-thyroid indications. Their prevalence, features, and
clinical consequences remain undefined. Objective To develop, validate, and
deploy a natural language processing (NLP) pipeline to identify ITFs in
radiology reports and assess their prevalence, features, and clinical outcomes.
Design, Setting, and Participants Retrospective cohort of adults without prior
thyroid disease undergoing thyroid-capturing imaging at Mayo Clinic sites from
July 1, 2017, to September 30, 2023. A transformer-based NLP pipeline
identified ITFs and extracted nodule characteristics from image reports from
multiple modalities and body regions. Main Outcomes and Measures Prevalence of
ITFs, downstream thyroid ultrasound, biopsy, thyroidectomy, and thyroid cancer
diagnosis. Logistic regression identified demographic and imaging-related
factors. Results Among 115,683 patients (mean age, 56.8 [SD 17.2] years; 52.9%
women), 9,077 (7.8%) had an ITF, of which 92.9% were nodules. ITFs were more
likely in women, older adults, those with higher BMI, and when imaging was
ordered by oncology or internal medicine. Compared with chest CT, ITFs were
more likely via neck CT, PET, and nuclear medicine scans. Nodule
characteristics were poorly documented, with size reported in 44% and other
features in fewer than 15% (e.g. calcifications). Compared with patients
without ITFs, those with ITFs had higher odds of thyroid nodule diagnosis,
biopsy, thyroidectomy and thyroid cancer diagnosis. Most cancers were
papillary, and larger when detected after ITFs vs no ITF. Conclusions ITFs were
common and strongly associated with cascades leading to the detection of small,
low-risk cancers. These findings underscore the role of ITFs in thyroid cancer
overdiagnosis and the need for standardized reporting and more selective
follow-up.

</details>


### [49] [Reasoning Path Divergence: A New Metric and Curation Strategy to Unlock LLM Diverse Thinking](https://arxiv.org/abs/2510.26122)
*Feng Ju,Zeyu Qin,Rui Min,Zhitao He,Lingpeng Kong,Yi R. Fung*

Main category: cs.CL

TL;DR: 通过引入“一个问题多种解法”训练方法和推理路径分歧指标RPD，提升了大语言模型的输出多样性和解题能力，取得了显著的pass@k提升。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）在Test-Time Scaling（TTS）方面有进步，但其输出结果多样性较低，主要原因之一是普遍采用的“一个问题一个答案”（1P1S）训练方式，导致模型的推理路径比较单一。为了解决这个局限，需要探索能提高输出多样性的训练策略。

Method: 提出了一种“一个问题多种解法”（1PNS）的训练范式，通过让模型暴露在各种有效推理路径下，提高模型推理的多样性。同时，提出Reasoning Path Divergence（RPD）指标，可以逐步对比和评估多步推理链之间的语义差异，并据此挑选每个问题最具多样性的解法集合对模型进行微调。此外，他们使用Qwen3-4B-Base进行实验。

Result: 实验结果表明，采用RPD挑选训练样本下训练的模型在输出多样性和pass@k指标上均有提升，相较于1P1S基线，pass@16平均提升2.8%，在AIME24测试集上提升4.99%。这说明1PNS训练范式能进一步增强TTS效果。

Conclusion: 1PNS训练范式结合RPD度量可以显著提升LLM推理路径的多样性和推理能力，为大语言模型的推理能力提升开辟了新途径。论文方法有效增强了TTS技术的表现。

Abstract: While Test-Time Scaling (TTS) has proven effective in improving the reasoning
ability of large language models (LLMs), low diversity in model outputs often
becomes a bottleneck; this is partly caused by the common "one problem, one
solution" (1P1S) training practice, which provides a single canonical answer
and can push models toward a narrow set of reasoning paths. To address this, we
propose a "one problem, multiple solutions" (1PNS) training paradigm that
exposes the model to a variety of valid reasoning trajectories and thus
increases inference diversity. A core challenge for 1PNS is reliably measuring
semantic differences between multi-step chains of thought, so we introduce
Reasoning Path Divergence (RPD), a step-level metric that aligns and scores
Long Chain-of-Thought solutions to capture differences in intermediate
reasoning. Using RPD, we curate maximally diverse solution sets per problem and
fine-tune Qwen3-4B-Base. Experiments show that RPD-selected training yields
more varied outputs and higher pass@k, with an average +2.80% gain in pass@16
over a strong 1P1S baseline and a +4.99% gain on AIME24, demonstrating that
1PNS further amplifies the effectiveness of TTS. Our code is available at
https://github.com/fengjujf/Reasoning-Path-Divergence .

</details>


### [50] [On the Influence of Discourse Relations in Persuasive Texts](https://arxiv.org/abs/2510.26124)
*Nawar Turk,Sevag Kaspar,Leila Kosseim*

Main category: cs.CL

TL;DR: 利用大语言模型及集成策略，论文将既有说服技巧数据自动标注为高质量的话语关系数据，揭示了说服技巧与六类关键话语关系间的密切关系，对网络虚假信息检测等具有一定启示作用。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏同时标注说服技巧（PTs）与话语关系（DRs）的数据集，阻碍了对二者关系的深入研究。有效识别二者之间关联有助于理解说服性文本的结构，也对网络宣传、虚假信息检测等实际应用具有重要意义。

Method: 以已有的SemEval 2023 Task 3 说服技巧数据集为基础，利用四种大语言模型（LLMs）和十种不同提示词工程，开发共40种话语关系分类器，并采用多种集成模型（多数投票）生成五个“银标”数据集，这些数据集中每条样本均被标注为一种说服技巧和一种PDTB 3.0 二级话语关系。随后对这些数据集进行统计分析。

Result: 创建了五个不同大小（1281到204个样本）的银标数据集，并通过统计分析发现：因果、目的、对比、因果+信念、让步和条件等六类话语关系在说服性文本中至关重要，尤其与Loaded Language、夸大/缩小、重复和引发怀疑等说服技巧密切相关。

Conclusion: 论文验证了说服技巧与特定话语关系间的紧密关联，为理解说服性文本和检测网络宣传、虚假信息等提供了数据支持和理论依据。也为后续研究提供了宝贵资源。

Abstract: This paper investigates the relationship between Persuasion Techniques (PTs)
and Discourse Relations (DRs) by leveraging Large Language Models (LLMs) and
prompt engineering. Since no dataset annotated with both PTs and DRs exists, we
took the SemEval 2023 Task 3 dataset labelled with 19 PTs as a starting point
and developed LLM-based classifiers to label each instance of the dataset with
one of the 22 PDTB 3.0 level-2 DRs. In total, four LLMs were evaluated using 10
different prompts, resulting in 40 unique DR classifiers. Ensemble models using
different majority-pooling strategies were used to create 5 silver datasets of
instances labelled with both persuasion techniques and level-2 PDTB senses. The
silver dataset sizes vary from 1,281 instances to 204 instances, depending on
the majority pooling technique used. Statistical analysis of these silver
datasets shows that six discourse relations (namely Cause, Purpose, Contrast,
Cause+Belief, Concession, and Condition) play a crucial role in persuasive
texts, especially in the use of Loaded Language, Exaggeration/Minimisation,
Repetition and to cast Doubt. This insight can contribute to detecting online
propaganda and misinformation, as well as to our general understanding of
effective communication.

</details>


### [51] [MossNet: Mixture of State-Space Experts is a Multi-Head Attention](https://arxiv.org/abs/2510.26182)
*Shikhar Tuli,James Seale Smith,Haris Jeelani,Chi-Heng Lin,Abhishek Patel,Vasili Ramanishka,Yen-Chang Hsu,Hongxia Jin*

Main category: cs.CL

TL;DR: MossNet通过混合状态空间专家，类比多头注意力机制，实现了高效、强表现力的循环大语言模型，不仅在实验、下游任务效果上优于同类模型，也具备良好设备适配和资源效率，是高效LLM架构的新方向。


<details>
  <summary>Details</summary>
Motivation: 现有SSM/GRM方法仅模拟单一注意力头，限制了模型的表现力。作者尝试通过混合专家和多头机制，提升模型效率和性能。

Method: 提出了MossNet，通过在通道混合的MLP块和时序混合的SSM核中引入混合专家机制，从而类比实现多头注意力，用以提升模型表达力。

Result: MossNet在语言建模和下游任务中均超越了同体量下的变换器和SSM架构。在更大规模（万亿级数据）训练下也显示出良好的可扩展性和性能优势。在实际设备（手机及GPU）上运行速度和资源消耗表现也优于同等规模基线模型。

Conclusion: MossNet是一种高效且性能优越的新型混合状态空间专家（mixture-of-state-space-experts）架构，能够超越当前主流变换器和状态空间模型，适合用于高效的循环大型语言模型。

Abstract: Large language models (LLMs) have significantly advanced generative
applications in natural language processing (NLP). Recent trends in model
architectures revolve around efficient variants of transformers or
state-space/gated-recurrent models (SSMs, GRMs). However, prevailing
SSM/GRM-based methods often emulate only a single attention head, potentially
limiting their expressiveness. In this work, we propose MossNet, a novel
mixture-of-state-space-experts architecture that emulates a linear multi-head
attention (MHA). MossNet leverages a mixture-of-experts (MoE) implementation
not only in channel-mixing multi-layered perceptron (MLP) blocks but also in
the time-mixing SSM kernels to realize multiple "attention heads." Extensive
experiments on language modeling and downstream evaluations show that MossNet
outperforms both transformer- and SSM-based architectures of similar model size
and data budgets. Larger variants of MossNet, trained on trillions of tokens,
further confirm its scalability and superior performance. In addition,
real-device profiling on a Samsung Galaxy S24 Ultra and an Nvidia A100 GPU
demonstrate favorable runtime speed and resource usage compared to similarly
sized baselines. Our results suggest that MossNet is a compelling new direction
for efficient, high-performing recurrent LLM architectures.

</details>


### [52] [Similarity-Distance-Magnitude Language Models](https://arxiv.org/abs/2510.26183)
*Allen Schmaltz*

Main category: cs.CL

TL;DR: 提出了SDM激活层方法以改进预训练语言模型在指令跟随任务中的校准和回答率，实验表明显著减少拒绝现象，相比强基线更具统计效率。


<details>
  <summary>Details</summary>
Motivation: 希望改进语言模型在指令跟随任务上的校准性和生成效率，减少模型拒绝回答（abstentions）的情况。

Method: 提出了SDM（Similarity-Distance-Magnitude）语言模型：在预训练的解码器式Transformer基础上，通过有监督微调和对比编码，将最后一层激活作为二分类判断指令跟随的依据，并在训练过程中生成硬负样本以提升训练效率。

Result: 与现有的强有监督基线相比，SDM方法能减少拒绝回答次数，提高统计效率。

Conclusion: 预训练Transformer模型可以通过简单的有监督微调和最后一层SDM激活层，转化为性能优异、拒绝率低的指令跟随模型。

Abstract: We introduce Similarity-Distance-Magnitude (SDM) language models (LMs), which
are sequence prediction models fine-tuned to maximize the proportion of
generations in the well-calibrated, high-probability region partitioned by a
final-layer SDM activation layer used for binary classification of
instruction-following. We demonstrate that existing pre-trained decoder-only
Transformer LMs can be readily converted into SDM LMs via supervised
fine-tuning, using the final-layer SDM activation layer during training to
estimate a change-of-base for a supervised next-token loss over a contrastive
input encoding scheme, with additional hard negative examples generated online
during training. This results in reduced abstentions (i.e., improved
statistical efficiency) compared to strong supervised baselines.

</details>


### [53] [RCScore: Quantifying Response Consistency in Large Language Models](https://arxiv.org/abs/2510.26193)
*Dongjun Jang,Youngchae Ahn,Hyopil Shin*

Main category: cs.CL

TL;DR: 评估LLM只用单一模板不够，RCScore框架通过多指令风格展现模型鲁棒性和一致性评价，更贴合真实应用。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLM）评测通常只采用单一指令模板，忽视了模型对不同指令风格的敏感性，而这对于真实应用场景非常关键。作者希望更全面评估LLM在不同指令风格下的稳定性和表现。

Method: 本文提出RCScore，一个多维度评估框架，将基准问题系统性地转化为多种指令风格，量化指令表达方式对模型输出的影响。同时引入Cross-Response Similarity（CRS）方法，用以衡量模型在不同指令风格下输出的一致性。

Result: 实验表明，不同指令风格下，LLM的准确率最高可有16.7个百分点的波动。CRS与任务准确率高度相关，显示输出一致性可以作为模型可靠性的代理指标。另外，确定性解码能产生风格上更稳定的输出，且模型参数规模越大，跨风格一致性越好。

Conclusion: RCScore为评估LLM的指令鲁棒性提供了更系统和可靠的方法，有助于发现传统单一评测方式无法检测的性能差异。

Abstract: Current LLM evaluations often rely on a single instruction template,
overlooking models' sensitivity to instruction style-a critical aspect for
real-world deployments. We present RCScore, a multi-dimensional framework
quantifying how instruction formulation affects model responses. By
systematically transforming benchmark problems into multiple instruction
styles, RCScore reveals performance variations undetected by conventional
metrics. Our experiments across ten LLMs on four reasoning benchmarks
demonstrate that instruction style can shift accuracy by up to 16.7% points. We
introduce Cross-Response Similarity (CRS), a method applying RCScore metrics to
measure stylistic self-consistency, and establish its strong correlation with
task accuracy, suggesting consistency as a valuable proxy for model
reliability. Additional findings show that deterministic decoding produces more
stylistically stable outputs, and model scale correlates positively with
cross-style consistency. RCScore offers a principled approach to assess
instruction robustness.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [54] [On the number of non-degenerate canalizing Boolean functions](https://arxiv.org/abs/2510.26556)
*Claus Kadelka*

Main category: cs.DM

TL;DR: 本文推导了具指定变量和管道化属性的布尔函数计数公式，明晰了管道化和简并性的重要组合基础，为理解生物网络中稳健性和功能分化提供理论支持。


<details>
  <summary>Details</summary>
Motivation: 管道化和简并性影响离散动力系统的稳定性和动力学，但其组合结构基础尚不清晰。明确这些属性在布尔函数中的出现频率，有助于理解生物网络中的稳健性和功能分化。

Method: 通过递推公式，枚举了具有指定本质变量数和管道化属性的布尔函数，并扩展了此前关于管道化和嵌套管道化函数的计数结果。

Result: 得出了所有变量都是本质且至少一个变量为管道化的布尔函数（非简并管道化函数）的数量公式。为评估随机布尔函数中管道化发生的频率和该现象在生物网络模型中的突出表现提供了依据。

Conclusion: 我们推导出了有关布尔函数的分类计数公式，为研究复杂系统中管道化和简并性的组合基础提供了新见解。这为定量分析生物网络中管道化现象的普遍性提供了理论支撑。

Abstract: Canalization is a key organizing principle in complex systems, particularly
in gene regulatory networks. It describes how certain input variables exert
dominant control over a function's output, thereby imposing hierarchical
structure and conferring robustness to perturbations. Degeneracy, in contrast,
captures redundancy among input variables and reflects the complete dominance
of some variables by others. Both properties influence the stability and
dynamics of discrete dynamical systems, yet their combinatorial underpinnings
remain incompletely understood. Here, we derive recursive formulas for counting
Boolean functions with prescribed numbers of essential variables and given
canalizing properties. In particular, we determine the number of non-degenerate
canalizing Boolean functions -- that is, functions for which all variables are
essential and at least one variable is canalizing. Our approach extends earlier
enumeration results on canalizing and nested canalizing functions. It provides
a rigorous foundation for quantifying how frequently canalization occurs among
random Boolean functions and for assessing its pronounced over-representation
in biological network models, where it contributes to both robustness and to
the emergence of distinct regulatory roles.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [55] [Unambiguous Acceptance of Thin Coalgebras](https://arxiv.org/abs/2510.26371)
*Anton Chernev,Corina Cîrstea,Helle Hvid Hansen,Clemens Kupke*

Main category: cs.FL

TL;DR: 本文将非歧义自动机的构造形式化推广到更一般的余代数（analytic functor下的thin coalgebra），并通过coherent algebra理论，统一了余代数语言识别与自动机理论，对有限coherent algebra识别的语言给出自动机构造与刻画。


<details>
  <summary>Details</summary>
Motivation: 非歧义自动机兼具确定性自动机的良好性质和更强的表达能力。在验证与建模中常用，然而其传统构造局限于特定结构（thin tree），有必要将其一般化到更大的结构类并提升理论的统一性和清晰性。

Method: 采用范畴论和余代数方法推广非歧义自动机的构造，利用coherent algebra与薄余代数语言识别的联系，形式化并普适化了自动机构造过程。

Result: 实现了从thin trees到thin coalgebra的非歧义自动机推广；正式建立了自动机、thin coalgebra与coherent algebra之间的联系，并为有限coherent algebra识别的语言给出了自动机理论刻画。

Conclusion: 本文成功将非歧义自动机的经典构造方法从thin tree拓展到了analytic functor的thin coalgebra框架中，并将其与coherent algebra的语言识别联系起来，为有限coherent algebra识别的语言给出了自动机理论刻画。

Abstract: Automata admitting at most one accepting run per structure, known as
unambiguous automata, find applications in verification of reactive systems as
they extend the class of deterministic automata whilst maintaining some of
their desirable properties. In this paper, we generalise a classical
construction of unambiguous automata from thin trees to thin coalgebras for
analytic functors. This achieves two goals: extending the existing construction
to a larger class of structures, and providing conceptual clarity and
parametricity to the construction by formalising it in the coalgebraic
framework. As part of the construction, we link automaton acceptance of
languages of thin coalgebras to language recognition via so-called coherent
algebras, which were previously introduced for studying thin coalgebras. This
link also allows us to establish an automata-theoretic characterisation of
languages recognised by finite coherent algebras.

</details>
