<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.SE](#cs.SE) [Total: 11]
- [cs.LO](#cs.LO) [Total: 4]
- [cs.CL](#cs.CL) [Total: 46]
- [cs.DM](#cs.DM) [Total: 2]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Optimism in Equality Saturation](https://arxiv.org/abs/2511.20782)
*Russel Arbore,Alvin Cheung,Max Willsey*

Main category: cs.PL

TL;DR: 本文提出了一种抽象解释算法，可在平等饱和过程中对循环程序进行更精确的分析，尤其适用于SSA形式的程序。原型工具在部分示例上比clang和gcc更精确。


<details>
  <summary>Details</summary>
Motivation: 当前e-class分析对循环程序分析效果不佳（较为悲观），限制了平等饱和技术应用的广度和优化能力。

Method: 采用抽象解释算法，融合乐观分析和非破坏性重写，并在新的SSA语义下构建原型分析器。

Result: 新算法能够比主流编译器（如clang和gcc）更精准地分析一定范围内的示例程序，实现对循环结构的有效处理。

Conclusion: 通过将抽象解释与非破坏性重写结合，作者实现了对带有环路的SSA程序的精确分析，提升了分析性能。

Abstract: Equality saturation is a technique for program optimization based on non-destructive rewriting and a form of program analysis called e-class analysis. The current form of e-class analysis is pessimistic and therefore ineffective at analyzing cyclic programs, such as those in SSA form. We propose an abstract interpretation algorithm that can precisely analyze cycles during equality saturation. This results in a unified algorithm for optimistic analysis and non-destructive rewriting. We instantiate this approach on a prototype abstract interpreter for SSA programs using a new semantics of SSA. Our prototype can analyze simple example programs more precisely than clang and gcc.

</details>


### [2] [Towards Computational UIP in Cubical Agda](https://arxiv.org/abs/2511.21209)
*Yee-Jian Tan,Andreas Nuyts,Dominique Devriese*

Main category: cs.PL

TL;DR: 研究了如何在Cubical Agda中构建既支持QITs和泛函外延性，同时仅保留h-Set平等层级的类型理论。提出去除Glue类型和假定UIP为实现路径，并实现了相关系统变体。


<details>
  <summary>Details</summary>
Motivation: 探讨Cubical Type Theory（立方类型理论）在保持QITs与泛函外延性等优势的同时，解决HoTT中平等层级无限带来的形式化负担，尤其在去除univalence并引入UIP公理后，如何实现h-Set Cubical Type Theory的可行方案。

Method: 1. 分析和比较HoTT与Cubical Type Theory中各类公理（univalence与UIP）及其后果。2. 探索、实现并测试Cubical Agda在去除Glue类型（即无univalence）与引入UIP条件下的变体效果。3. 推导和评估各形式化UIP的计算规则，以及它们对实际实现的适配及优劣。

Result: 实现了一种变体的Cubical Agda（无Glue），该变体本身兼容UIP公理，为将来在Cubical Agda中自动实现UIP铺路。同时分析了UIP的形式及其在Cubical Agda中的计算规则，并评估了其实现适配性。

Conclusion: Cubical Type Theory即使在平等关系“集化”（即UIP成立）后，许多原有的重要特性（如函数外延性和QITs）仍可保留。文章实现的变体已可兼容UIP，方便日后自动化实现，促进理论与实际证明助理的结合。

Abstract: Some advantages of Cubical Type Theory, as implemented by Cubical Agda, over intensional Martin-Löf Type Theory include Quotient Inductive Types (QITs), which exist as instances of Higher Inductive Types, and functional extensionality, which is provable in Cubical Type Theory. However, HoTT features an infinite hierarchy of equalities that may become unwieldy in formalisations. Fortunately, QITs and functional extensionality are both preserved even if the equality levels of Cubical Type Theory are truncated to only homotopical Sets (h-Sets). In other words, removing the univalence axiom from Cubical Type Theory and instead postulating a conflicting axiom: the Uniqueness of Identity Proofs (UIP) postulate. Since univalence is proved in Cubical Type Theory from the so-called Glue Types, therefore, it is known that one can first remove the Glue Types (thus removing univalence) and then set-truncate all equalities (essentially assuming UIP), à la XTT. The result is a "h-Set Cubical Type Theory" that retains features such as functional extensionality and QITs.
  However, in Cubical Agda, there are currently only two unsatisfying ways to achieve h-Set Cubical Type Theory. The first is to give up on the canonicity of the theory and simply postulate the UIP axiom, while the second way is to use a standard result stating "type formers preserve h-levels" to manually prove UIP for every defined type. The latter is, however, laborious work best suited for an automatic implementation by the proof assistant. In this project, we analyse formulations of UIP and detail their computation rules for Cubical Agda, and evaluate their suitability for implementation. We also implement a variant of Cubical Agda without Glue, which is already compatible with postulated UIP, in anticipation of a future implementation of UIP in Cubical Agda.

</details>


### [3] [SV-LIB 1.0: A Standard Exchange Format for Software-Verification Tasks](https://arxiv.org/abs/2511.21509)
*Dirk Beyer,Gidon Ernst,Martin Jonáš,Marian Lingsch-Rosenfeld*

Main category: cs.PL

TL;DR: SV-LIB是一种通用的中间语言和交换格式，方便软件验证任务在不同工具和语言间转移与复用，已发布1.0版，支持表达验证目标、结果见证，并计划后续扩展。


<details>
  <summary>Details</summary>
Motivation: 目前软件验证工具多针对特定编程语言（如C、C++、Java），但基本验证方法具备通用性，若能实现跨语言的技术转移，将大大提升验证工具的适用性和效率。缺少统一的、可扩展的验证任务中间表示已成为技术进步的瓶颈。

Method: 提出SV-LIB：一种统一的软件验证任务中间语言及交换格式，基于命令式编程语言核心概念，采用SMT-LIB来表达程序中的表达式和类型。SV-LIB还制定了包含规范和验证见证的格式，并支持见证验证任务，便于集成到现有以SMT求解器为基础的验证工具中。

Result: 开发并发布了SV-LIB 1.0版，详细阐述其设计目标、语法和非正式语义，扩展支持了正确与错误程序的见证格式，以及见证验证的任务描述。后续将继续扩展其形式语义和对并发性的支持。

Conclusion: SV-LIB为软件验证任务提供了通用的中间表示格式，打通了多编程语言验证工具间的壁垒，便于技术复用和独立见证验证，推动了验证技术的进一步发展。

Abstract: In the past two decades, significant research and development effort went into the development of verification tools for individual languages, such asC, C++, and Java. Many of the used verification approaches are in fact language-agnostic and it would be beneficial for the technology transfer to allow for using the implementations also for other programming and modeling languages. To address the problem, we propose SV-LIB, an exchange format and intermediate language for software-verification tasks, including programs, specifications, and verification witnesses. SV-LIBis based on well-known concepts from imperative programming languages and uses SMT-LIB to represent expressions and sorts used in the program. This makes it easy to parse and to build into existing infrastructure, since many verification tools are based on SMT solvers already. Furthermore, SV-LIBdefines a witness format for both correct and incorrect SV-LIB programs, together with means for specifying witness-validation tasks. This makes it possible both to implement independent witness validators and to reuse some verifiers also as validators for witnesses. This paper presents version 1.0 of the SV-LIBformat, including its design goals, the syntax, and informal semantics. Formal semantics and further extensions to concurrency are planned for future versions.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [DUALGUAGE: Automated Joint Security-Functionality Benchmarking for Secure Code Generation](https://arxiv.org/abs/2511.20709)
*Abhijeet Pathak,Suvadra Barua,Dinesh Gudimetla,Rupam Patir,Jiawei Guo,Hongxin Hu,Haipeng Cai*

Main category: cs.SE

TL;DR: 提出了可同步自动评估LLM生成代码安全性与正确性的框架及数据集，用于提升现有安全代码生成评测的标准和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有的安全代码生成评测只关注漏洞减少，忽视功能正确性，或者安全与功能性分开评估，不能满足实际需要。亟需能同时并严格考量安全性与正确性的评测标准和工具，以促进LLM代码生成的落地和发展。

Method: 1. 设计并实现自动化框架DUALGAUGE，实现沙盒测试和LLM辅助结果判定；2. 构建DUALGAUGE-BENCH，覆盖安全与功能性需求的测试集；3. 对主流LLM进行大规模实证评测。

Result: 本文提出了DUALGAUGE，这是首个专为联合评估大语言模型（LLM）生成代码的安全性和正确性而设计的全自动化基准测试框架。作者还构建了DUALGAUGE-BENCH，一套覆盖安全与功能性验证的多样化编程任务及人工校验测试集。通过将程序在沙盒环境中执行并结合LLM评估结果，实现了代码安全性和正确性的同步评估。针对十种主流LLM在该数据集下的表现进行了大规模实证分析。

Conclusion: 当前主流LLM在安全且正确地生成代码上存在显著不足。DUALGAUGE和DUALGAUGE-BENCH为社区提供了可复现、可扩展且严格的评测工具，有助于推动安全代码生成领域的进步。

Abstract: Large language models (LLMs) and autonomous coding agents are increasingly used to generate software across a wide range of domains. Yet a core requirement remains unmet: ensuring that generated code is secure without compromising its functional correctness. Existing benchmarks and evaluations for secure code generation fall short-many measure only vulnerability reduction, disregard correctness preservation, or evaluate security and functionality on separate datasets, violating the fundamental need for simultaneous joint evaluation. We present DUALGAUGE, the first fully automated benchmarking framework designed to rigorously evaluate the security and correctness of LLM-generated code in unison. Given the lack of datasets enabling joint evaluation of secure code generation, we also present DUALGAUGE-BENCH, a curated benchmark suite of diverse coding tasks, each paired with manually validated test suites for both security and functionality, designed for full coverage of specification requirements. At the core of DUALGAUGE is an agentic program executor, which runs a program against given tests in sandboxed environments, and an LLM-based evaluator, which assesses both correctness and vulnerability behavior against expected outcomes. We rigorously evaluated and ensured the quality of DUALGAUGE-BENCH and the accuracy of DUALGAUGE, and applied DUALGAUGE to benchmarking ten leading LLMs on DUALGAUGE-BENCH across thousands of test scenarios. Our results reveal critical gaps in correct and secure code generation by these LLMs, for which our open-source system and datasets help accelerate progress via reproducible, scalable, and rigorous evaluation.

</details>


### [5] [Data-Driven Methods and AI in Engineering Design: A Systematic Literature Review Focusing on Challenges and Opportunities](https://arxiv.org/abs/2511.20730)
*Nehal Afifi,Christoph Wittig,Lukas Paehler,Andreas Lindenmann,Kai Wolter,Felix Leitenberger,Melih Dogru,Patric Grauberger,Tobias Düser,Albert Albers,Sven Matthiesen*

Main category: cs.SE

TL;DR: 本文通过系统性综述，总结了数据驱动方法（机器学习、统计方法、深度学习）在产品开发各阶段的应用现状；发现设计、实施、集成阶段应用广泛，验证阶段较弱。面临的挑战包括方法可解释性差和实际验证不足。建议推动可解释混合模型开发与跨学科指导方针。


<details>
  <summary>Details</summary>
Motivation: 数据驱动方法（DDM）在产品开发中应用越来越多，但目前的应用方式较为零散，且缺乏明确的指导，如应该在哪个开发阶段使用何种方法。为理解DDM在工程设计中的实际应用，需要梳理哪些方法被采用、应用于哪些开发阶段以及具体用途。

Method: 采用PRISMA系统性文献综述，基于简化版V模型作为产品开发框架，将整个过程划分为系统设计、系统实施、系统集成和验证四个阶段。检索了Scopus、Web of Science和IEEE Xplore等数据库2014-2024年的相关文献，共筛选1,689条记录，最终对114篇全文进行了分析。

Result: 当前工程设计领域以机器学习和统计方法为主，深度学习应用虽少但呈增长趋势。设计、实施、集成阶段常用监督学习、聚类、回归分析、代理建模等方法，但在验证阶段研究贡献有限。主要挑战包括模型可解释性低、跨阶段追踪差、现实条件下验证不足。

Conclusion: 该综述厘清了工程设计领域DDM的应用现状、挑战和机会，指出需要开发可解释的混合模型，并为未来制定设计阶段指导方针奠定了基础。后续工作应将计算机科学算法与具体工程设计问题和活动进行映射。

Abstract: The increasing availability of data and advancements in computational intelligence have accelerated the adoption of data-driven methods (DDMs) in product development. However, their integration into product development remains fragmented. This fragmentation stems from uncertainty, particularly the lack of clarity on what types of DDMs to use and when to employ them across the product development lifecycle. To address this, a necessary first step is to investigate the usage of DDM in engineering design by identifying which methods are being used, at which development stages, and for what application. This paper presents a PRISMA systematic literature review. The V-model as a product development framework was adopted and simplified into four stages: system design, system implementation, system integration, and validation. A structured search across Scopus, Web of Science, and IEEE Xplore (2014--2024) retrieved 1{,}689 records. After screening, 114 publications underwent full-text analysis. Findings show that machine learning (ML) and statistical methods dominate current practice, whereas deep learning (DL), though still less common, exhibits a clear upward trend in adoption. Additionally, supervised learning, clustering, regression analysis, and surrogate modeling are prevalent in design, implementation, and integration system stages but contributions to validation remain limited. Key challenges in existing applications include limited model interpretability, poor cross-stage traceability, and insufficient validation under real-world conditions. Additionally, it highlights key limitations and opportunities such as the need for interpretable hybrid models. This review is a first step toward design-stage guidelines; a follow-up synthesis should map computer science algorithms to engineering design problems and activities.

</details>


### [6] [Train While You Fight -- Technical Requirements for Advanced Distributed Learning Platforms](https://arxiv.org/abs/2511.20813)
*Simon Hacks*

Main category: cs.SE

TL;DR: 本文分析了‘与战斗同步训练’对分布式学习平台的技术要求，总结出七大挑战，并通过系统性方法对接成熟设计模式，一定程度上推动了实战中“边战边学”的能力落地。


<details>
  <summary>Details</summary>
Motivation: 推动连续学习理念“与战斗同步训练”（TWYF），以满足现代军事或大型分布式组织在实战中持续提升能力的需求。

Method: 采用设计科学研究（Design Science Research）方法：一是从PfPC/NATO文档及实际案例中归纳挑战；二是定义解决目标；三是将挑战与成熟的软件工程模式进行系统性映射。

Result: 识别出高级分布式学习（ADL）平台需要解决的七项技术挑战：互操作性、弹性、多语言支持、数据安全与隐私、可扩展性、平台无关性和模块化，并通过德国国防军的国家级应用场景进行了实例说明。

Conclusion: 通过采用软件工程中成熟的设计模式，能够有效支持ADL平台满足TWYF连续学习的技术需求，有望提升军队等组织在作战中的实时学习与适应能力。

Abstract: "Train While You Fight" (TWYF) advocates for continuous learning that occurs during operations, not just before or after. This paper examines the technical requirements that advanced distributed learning (ADL) platforms must meet to support TWYF, and how existing software engineering patterns can fulfill these requirements. Using a Design Science Research approach, we (i) derive challenges from PfPC/NATO documentation and recent practice, (ii) define solution objectives, and (iii) conduct a systematic mapping from challenges to proven patterns. We identify seven technical challenges: interoperability, resilience, multilingual support, data security and privacy, scalability, platform independence, and modularity. We illustrate the patterns with a national use case from the German armed forces.

</details>


### [7] [Application of machine learning for infrastructure reconstruction programs management](https://arxiv.org/abs/2511.20916)
*Illia Khudiakov,Vladyslav Pliuhin,Sergiy Plankovskyy,Yevgen Tsegelnyk*

Main category: cs.SE

TL;DR: 本文提出一种利用神经网络和系统建模的自适应决策支持模型，通过历史数据预测和模型参数调整，提升工程基础设施重建项目管理的效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有管理工具在工程基础设施重建项目的架构与WBS制定上存在效率与适应性不足，因此研究旨在提升重建项目管理的决策效率和效果。

Method: 采用系统建模方法与机器学习（人工神经网络），结合历史数据，对工程基础设施重建项目的架构与工作分解结构（WBS）进行预测与决策支持，并基于不同对象类型调整模型参数，使决策过程具备适应性。

Result: 分析了目前的适应性计划管理工具，验证了基础设施系统建模工具的合理性，定义模型主要部件，并在Microsoft Azure Machine Learning Studio实现功能组合，给出神经网络参数与评估结果，证实了模型在热力、燃气、电力、水务、排水等系统重建项目管理中的应用价值。

Conclusion: 所开发的适应性决策支持模型能有效提升工程基础设施重建项目管理效率，适用于多种公共事业系统。模型可根据项目对象类型自适应调整，具有较高的实际应用价值。

Abstract: The purpose of this article is to describe an adaptive decision-making support model aimed at improving the efficiency of engineering infrastructure reconstruction program management in the context of developing the architecture and work breakdown structure of programs. As part of the study, the existing adaptive program management tools are analyzed, the use of infrastructure systems modelling tools is justified for program architecture and WBS creation. Existing models and modelling methods are viewed, and machine learning and artificial neural networks are selected for the model. The main components of the model are defined, which include a set of decision-maker preferences, decision-making tasks, sets of input data, and applied software components of the model. To support decision-making, the adaptive model applies the method of system modeling and predicting the value of the objective function at a given system configuration. Prediction is done using machine learning methods based on a dataset consisting of historical data related to existing engineering systems. The work describes the components of the redistribution of varied model parameters, which modify the model dataset based on the selected object type, which allows adapting the decision-making process to the existing program implementation goals. The functional composition done in Microsoft Azure Machine Learning Studio is described. The neural network parameters and evaluation results are given. The application of the developed adaptive model is possible in the management of programs for the reconstruction of such engineering systems as systems of heat, gas, electricity supply, water supply, and drainage, etc.

</details>


### [8] [Hierarchical Evaluation of Software Design Capabilities of Large Language Models of Code](https://arxiv.org/abs/2511.20933)
*Mootez Saad,Boqi Chen,José Antonio Hernández López,Dániel Varró,Tushar Sharma*

Main category: cs.SE

TL;DR: 大型语言模型对软件设计概念（内聚和耦合）在理想环境下理解力较好，但在噪声或缺乏指导的现实环境中表现有限，尤其是对耦合概念识别更脆弱，展现‘认知捷径’问题，需要更强健的模型能力提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在软件工程领域应用广泛，但其对核心软件设计概念（内聚与耦合）的把握情况尚不明确。作者希望系统性评估这些模型在不同任务和环境下对这两大概念的理解能力。

Method: 作者采用程序化生成差设计代码片段，基于DeepSeek-R1模型家族，设计多种任务（验证、指导、开放生成）并通过增加上下文噪声测试模型对内聚与耦合理解能力，结合性能指标（如F1分数）与推理痕迹分析得出结论。

Result: 在理想条件下，模型对内聚和耦合都表现良好，但在复杂或噪声较大的环境中，模型表现脆弱，尤其是对耦合的理解能力急剧下降，F1分数下降超过50%。而对内聚的分析在有指导任务下表现更为稳健，但在完全开放式任务中同样失效。

Conclusion: 虽然LLMs可以辅助识别软件设计缺陷，但在真实、复杂环境下自主推理的能力有限，需要进一步提升模型在实际程序理解任务中的鲁棒性和扩展性。

Abstract: Large language models (LLMs) are being increasingly adopted in the software engineering domain, yet the robustness of their grasp on core software design concepts remains unclear. We conduct an empirical study to systematically evaluate their understanding of cohesion (intra-module) and coupling (inter-module). We programmatically generate poorly designed code fragments and test the DeepSeek-R1 model family ($14$B, $32$B, $70$B) under varying levels of guidance, from simple \textit{Verification} to \textit{Guided} and \textit{Open-ended Generation}, while varying contextual noise by injecting distractor elements. While models exhibit a solid baseline understanding of both concepts in ideal conditions, their practical knowledge is fragile and highly asymmetrical. Reasoning about coupling proves brittle; performance collapses in noisy, open-ended scenarios, with F1 scores dropping by over $50\%$. In contrast, the models' analysis of cohesion is remarkably robust to internal noise in guided tasks, showing little performance degradation. However, this resilience also fails when all guidance is removed. Reasoning-trace analysis confirms these failure modes, revealing \textit{cognitive shortcutting} for coupling versus a more exhaustive (yet still failing) analysis for cohesion. To summarize, while LLMs can provide reliable assistance for recognizing design flaws, their ability to reason autonomously in noisy, realistic contexts is limited, highlighting the critical need for more scalable and robust program understanding capabilities.

</details>


### [9] [SpaceX: Exploring metrics with the SPACE model for developer productivity](https://arxiv.org/abs/2511.20955)
*Sanchit Kaul,Kevin Nhu,Jason Eissayou,Ivan Eser,Victor Borup*

Main category: cs.SE

TL;DR: 文章通过SPACE框架和对开源仓库的数据深度挖掘，提出了多维度的生产力度量方法，揭示了情绪与开发活动之间的相关性，并改进了团队协作分析方式。


<details>
  <summary>Details</summary>
Motivation: 当前对开发者生产力的评价方式过于单一、确定性强，不能全面反映开发者效能，需引入多角度和情绪因素优化度量框架。

Method: 通过开源仓库挖掘，利用广义线性混合模型（GLMM）和基于RoBERTa的情绪分类，结合空间拓扑分析，构建多维度生产力指标。

Result: 发现消极情绪与提交频率显著正相关，团队协作网络拓扑能更真实映射协作动态，多维度指标优于传统简单度量。

Conclusion: 以复合生产力分数（CPS）作为兼容开发者效能异质性的评估工具，比传统单维度或体量型指标更有效。

Abstract: This empirical investigation elucidates the limitations of deterministic, unidimensional productivity heuristics by operationalizing the SPACE framework through extensive repository mining. Utilizing a dataset derived from open-source repositories, the study employs rigorous statistical methodologies including Generalized Linear Mixed Models (GLMM) and RoBERTa-based sentiment classification to synthesize a holistic, multi-faceted productivity metric. Analytical results reveal a statistically significant positive correlation between negative affective states and commit frequency, implying a cycle of iterative remediation driven by frustration. Furthermore, the investigation has demonstrated that analyzing the topology of contributor interactions yields superior fidelity in mapping collaborative dynamics compared to traditional volume-based metrics. Ultimately, this research posits a Composite Productivity Score (CPS) to address the heterogeneity of developer efficacy.

</details>


### [10] [Lightweight Model Editing for LLMs to Correct Deprecated API Recommendations](https://arxiv.org/abs/2511.21022)
*Guancheng Lin,Xiao Yu,Jacky Keung,Xing Hu,Xin Xia,Alex X. Liu*

Main category: cs.SE

TL;DR: 本文系统评估了主流模型编辑方法用于更新LLMs过时API知识的能力，提出了EDAPIBench基准与改进方法AdaLoRA-L。实验证明AdaLoRA-L能精确、高效地编辑API知识，对模型其他知识影响较小。


<details>
  <summary>Details</summary>
Motivation: LLMs在代码补全领域表现出色，但因训练数据不及时，往往嵌入过时API知识，导致生成代码时推荐弃用API，而重新训练开销巨大。轻量级模型编辑方法虽被提出，但对更新API知识的有效性尚未得到系统验证。

Method: 系统性地应用了10种主流模型编辑方法在三大代码LLM上（Qwen2.5-Coder、StarCoder2、DeepSeek-Coder），并提出了EDAPIBench基准。重点研究了参数高效微调（AdaLoRA）及其改进版（AdaLoRA-L）在API知识更新中的表现。

Result: AdaLoRA在更新API方面表现最佳，但会影响模型其他知识。改进后的AdaLoRA-L方法通过限定编辑范围，大幅提升了编辑的特异性，且在总体性能上保持竞争力。

Conclusion: 提出了一种新的模型编辑方法AdaLoRA-L，通过区分模型内部通用和特定API层，仅在特定层进行编辑，有效提升了更新API知识的特异性，同时保持了优秀的性能。

Abstract: Pre-trained or fine-tuned on large code corpora, Large Language Models (LLMs) have demonstrated strong performance in code completion tasks. However, their embedded knowledge is constrained by the timeliness of training data, which often includes code using deprecated APIs. Consequently, LLMs frequently generate deprecated APIs that will no longer be supported in future versions of third-party libraries. While retraining LLMs on updated codebases could refresh their API knowledge, this approach is computationally expensive. Recently, lightweight model editing methods have emerged to efficiently correct specific knowledge in LLMs. However, it remains unclear whether these methods can effectively update deprecated API knowledge and enable edited models to generate up-to-date APIs. To address this gap, we conduct the first systematic study applying 10 state-of-the-art model editing techniques to update deprecated API knowledge in three LLMs: Qwen2.5-Coder, StarCoder2, and DeepSeek-Coder. We introduce EDAPIBench, a dedicated benchmark featuring over 70 deprecated APIs from 8 popular Python libraries, with more than 3,000 editing instances. Our results show that the parameter-efficient fine-tuning method AdaLoRA achieves the best performance in enabling edited models to generate correct, up-to-date APIs, but falls short in Specificity (i.e., the editing influences untargeted knowledge). To resolve this, we propose AdaLoRA-L, which defines "Common API Layers" (layers within the LLMs with high importance across all APIs, storing general knowledge and excluded from editing) and restricts edits exclusively to "Specific API Layers" (layers with high importance only for the target API, storing the API-specific knowledge). Experimental results demonstrate that AdaLoRA-L significantly improves Specificity while maintaining comparable performance across other evaluation metrics.

</details>


### [11] [Exploring Hidden Geographic Disparities in Android Apps](https://arxiv.org/abs/2511.21151)
*M. Alecci,P. Jiménez,J. Samhi,T. Bissyandé,J. Klein*

Main category: cs.SE

TL;DR: 作者通过跨地区大规模数据收集，揭示了同品牌移动应用在不同国家的权利、隐私及基础APK存在差异，这可能影响安全评估和功能表现，并带来再现性和伦理问题。


<details>
  <summary>Details</summary>
Motivation: 虽然移动应用的发展已被广泛研究，但地理位置对应用行为的影响却鲜有关注。因此，作者希望揭示不同地区在同一品牌应用间的差异，评估对安全、公平及隐私的影响。

Method: 构建了跨区域的分布式应用收集管道，分析了数千个应用，并发布了8万多个“GeoTwins”（带区域特征的同品牌功能相似应用）数据集，用于探测和量化地区差异。

Result: 发现了两大重要现象：1）GeoTwins现象，即同一品牌在不同国家发行的应用功能相似但在权限、第三方库和隐私披露上差异显著；2）即便是Android App Bundle中的base.apk也呈现明显的地区差异，存在隐藏定制。

Conclusion: 地区性的应用差异会导致相同应用在安全、隐私和功能评价上出现偏差，影响再现性并带来伦理问题。研究人员、开发者和决策者需关注并应对移动软件的地区性不一致。

Abstract: While mobile app evolution has been widely studied, geographical variation in app behavior remains largely unexplored. This paper presents a large-scale study of location-based Android app differentiation, uncovering two important and underexamined phenomena with security and fairness implications. First, we introduce GeoTwins: apps that are functionally similar and share branding but are released under different package names across countries. Despite their similarity, GeoTwins often diverge in requested permissions, third-party libraries, and privacy disclosures. Second, we examine the Android App Bundle ecosystem and reveal unexpected regional differences in supposedly consistent base.apk files. Contrary to common assumptions, even base.apk files vary by region, exposing hidden customizations that may affect app behavior or security.
  These discrepancies have concrete consequences. Geographically distinct variants can lead the same app to be labeled benign in one malware study but suspicious in another, depending on the region of download. Such hidden variation undermines reproducibility and introduces geographic bias into assessments of security, privacy, and functionality. It also raises ethical concerns about transparency and consent: visually identical Google Play listings may mask subtle but important differences.
  To study these issues, we built a distributed app collection pipeline spanning multiple regions and analyzed thousands of apps. We also release a dataset of 81,963 GeoTwins to support future work. Our findings reveal systemic regional disparities in mobile software, with implications for researchers, developers, platform architects, and policymakers.

</details>


### [12] [Bug Detective and Quality Coach: Developers' Mental Models of AI-Assisted IDE Tools](https://arxiv.org/abs/2511.21197)
*Paolo Buono,Mary Cerullo,Stefano Cirillo,Giuseppe Desolda,Francesco Greco,Emanuela Guglielmi,Grazia Margarella,Giuseppe Polese,Simone Scalabrino,Cesare Tucci*

Main category: cs.SE

TL;DR: 本文调研了开发者对AI辅助漏洞检测和代码可读性工具的心理模型及其对信任和采用的影响，并提出了以人为本的工具设计原则。


<details>
  <summary>Details</summary>
Motivation: 尽管AI辅助工具在帮助开发者完成如漏洞检测和代码可读性评估等复杂任务方面取得了技术进步，但关于开发者如何构建这些工具的心理模型，以及心理模型不匹配如何影响信任、控制和采用，了解较少。

Method: 研究采用了六场协同设计研讨会，邀请58位开发者，聚焦其对AI辅助漏洞检测和可读性工具的心理建构和体验，归纳其心理预期，并根据调研内容提出设计建议。

Result: 开发者把故障检测工具看作“漏洞侦探”，只在发现严重问题时发出警告，并保证透明、可操作反馈和信心支持。可读性评估工具则被视为“质量教练”，需要提供具情境性、个性化及渐进式指导。信任度取决于解释的清晰度、时机和用户控制。研究总结出一组“以人为本”的AI工具设计原则，关注在开发环境中平衡打断与支持、简洁与深入、自动化与人为掌控。

Conclusion: 设计AI工具应关注开发者的心理预期，如透明度、鼓励性反馈及用户主导控制，有助于提升信任与使用率，并基于此提出IDE中人本AI的设计原则。

Abstract: AI-assisted tools support developers in performing cognitively demanding tasks such as bug detection and code readability assessment. Despite the advancements in the technical characteristics of these tools, little is known about how developers mentally model them and how mismatches affect trust, control, and adoption. We conducted six co-design workshops with 58 developers to elicit their mental models about AI-assisted bug detection and readability features. It emerged that developers conceive bug detection tools as \textit{bug detectives}, which warn users only in case of critical issues, guaranteeing transparency, actionable feedback, and confidence cues. Readability assessment tools, on the other hand, are envisioned as \textit{quality coaches}, which provide contextual, personalized, and progressive guidance. Trust, in both tasks, depends on the clarity of explanations, timing, and user control. A set of design principles for Human-Centered AI in IDEs has been distilled, aiming to balance disruption with support, conciseness with depth, and automation with human agency.

</details>


### [13] [Multi-Agent Systems for Dataset Adaptation in Software Engineering: Capabilities, Limitations, and Future Directions](https://arxiv.org/abs/2511.21380)
*Jingyi Chen,Xiaoyan Guo,Songqiang Chen,Shing-Chi Cheung,Jiasi Shen*

Main category: cs.SE

TL;DR: 本文首次对多智能体大语言模型（LLM）系统在软件工程（SE）研究成果跨数据集适配任务上的表现进行了实证研究。


<details>
  <summary>Details</summary>
Motivation: 随着SE研究中成果适配不同数据集需求增加，自动化适配对于可扩展性和可复现性意义重大。但目前对LLM多智能体系统在数据集适配中的能力研究甚少。

Method: 作者基于五阶段评估流程（文件理解、代码编辑、命令生成、验证、最终执行），选用GitHub Copilot（GPT-4.1和Claude Sonnet 4）在多个基准库上的适配任务进行实验，测量成功率、失败模式并评估不同提示干预（如错误反馈和参考代码）的效果。

Result: 多智能体系统能识别关键文件并产生部分适配，但很难生成完全功能正确的实现。若提供执行错误信息和参考代码，结构相似度可从7.25%提升至67.14%。

Conclusion: 当前多智能体LLM系统在识别文件和部分适配方面有能力，但在生成功能正确的实现上仍有限。在提示中加入执行错误信息和参考代码可以显著提升其与标准答案的结构相似度。未来需开发更可靠的自纠错代理以提升适配效果。

Abstract: Automating the adaptation of software engineering (SE) research artifacts across datasets is essential for scalability and reproducibility, yet it remains largely unstudied. Recent advances in large language model (LLM)-based multi-agent systems, such as GitHub Copilot's agent mode, promise to automate complex development workflows through coordinated reasoning, code generation, and tool interaction. This paper presents the first empirical study on how state-of-the-art multi-agent systems perform in dataset adaptation tasks. We evaluate Copilot, backed by GPT-4.1 and Claude Sonnet 4, on adapting SE research artifacts from benchmark repositories including ROCODE and LogHub2.0. Through a five-stage evaluation pipeline (file comprehension, code editing, command generation, validation, and final execution), we measure success rates, analyze failure patterns, and assess prompt-based interventions designed to enhance agent performance. Results show that current systems can identify key files and generate partial adaptations but rarely produce functionally correct implementations. Prompt-level interventions, especially providing execution error messages and reference code, substantially improve structural similarity to ground truth (from 7.25% to 67.14%), highlighting the importance of contextual and feedback-driven guidance. Our findings reveal both the promise and limitations of today's multi-agent LLM systems for dataset adaptation, and suggest concrete directions for building more reliable, self-correcting agents in future SE research.

</details>


### [14] [Large Language Models for Unit Test Generation: Achievements, Challenges, and the Road Ahead](https://arxiv.org/abs/2511.21382)
*Bei Chu,Yang Feng,Kui Liu,Zifan Nan,Zhaoqiang Guo,Baowen Xu*

Main category: cs.SE

TL;DR: 本文综述了LLM在单元测试生成中的应用现状，明确了主流技术路径和挑战，并为后续研究指明了方向。


<details>
  <summary>Details</summary>
Motivation: 单元测试对于保证软件质量至关重要，但传统自动化方法由于缺乏语义信息，难以生成真实有效的测试输入和断言。大语言模型(LLM)的引入则有望解决这一难题。

Method: 作者通过系统性文献综述，梳理了2021年5月至2025年8月间的115篇相关文献，提出以LLM为核心、基于单元测试生成生命周期的统一分类法，系统分析了生成策略及优化手段。

Result: 通过综述发现，Prompt工程已成为主流方法（占89%），而迭代式验证及修复循环显著提升了生成测试的可用性和成功率，但在故障检测能力和标准化评估基准方面仍存在挑战。

Conclusion: 虽然LLM极大提升了单元测试自动化的能力，但还需解决检测能力弱和评估标准缺失等关键问题。未来研究应着重发展自主测试代理和LLM与传统工具结合的混合系统。

Abstract: Unit testing is an essential yet laborious technique for verifying software and mitigating regression risks. Although classic automated methods effectively explore program structures, they often lack the semantic information required to produce realistic inputs and assertions. Large Language Models (LLMs) address this limitation by utilizing by leveraging their data-driven knowledge of code semantics and programming patterns. To analyze the state of the art in this domain, we conducted a systematic literature review of 115 publications published between May 2021 and August 2025. We propose a unified taxonomy based on the unit test generation lifecycle that treats LLMs as stochastic generators requiring systematic engineering constraints. This framework analyzes the literature regarding core generative strategies and a set of enhancement techniques ranging from pre-generation context enrichment to post-generation quality assurance. Our analysis reveals that prompt engineering has emerged as the dominant utilization strategy and accounts for 89% of the studies due to its flexibility. We find that iterative validation and repair loops have become the standard mechanism to ensure robust usability and lead to significant improvements in compilation and execution pass rates. However, critical challenges remain regarding the weak fault detection capabilities of generated tests and the lack of standardized evaluation benchmarks. We conclude with a roadmap for future research that emphasizes the progression towards autonomous testing agents and hybrid systems combining LLMs with traditional software engineering tools. This survey provides researchers and practitioners with a comprehensive perspective on converting the potential of LLMs into industrial-grade testing solutions.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [15] [Coco: Corecursion with Compositional Heterogeneous Productivity](https://arxiv.org/abs/2511.21093)
*Jaewoo Kim,Yeonwoo Nam,Chung-Kil Hur*

Main category: cs.LO

TL;DR: 论文提出了CHP理论框架，既实现了高度自动化，也扩大了对核心递归定义的支持范围，并开发了Coco库，用于自动计算可生产性和生成不动点。


<details>
  <summary>Details</summary>
Motivation: 现有定理证明助理对核心递归定义施加了严格的语法限制，许多合法定义被拒绝，现有提升方法在范围和自动化之间存在权衡。论文旨在解决这一难题，实现高覆盖和高自动化。

Method: 首先提出CHP理论，强调通过分解和组合方法系统地计算复合函数的可生产性。框架支持异质的函数类型。基于该理论开发了Coco自动化库，实现了生产力计算和不动点生成的自动化。

Result: CHP框架实现了对多种函数类型和复杂递归模式的支持，Coco库为相关领域提供了强大且自动化的工具，大大提升了生产力和可验证性。

Conclusion: 通过CHP框架和Coco库，可以对复杂的核心递归函数进行模块化和高效的验证，提升了生产力和表达能力，超越了传统系统的限制。

Abstract: Contemporary proof assistants impose restrictive syntactic guardedness conditions that reject many valid corecursive definitions. Existing approaches to overcome these restrictions present a fundamental trade-off between coverage and automation.
  We present Compositional Heterogeneous Productivity (CHP), a theoretical framework that unifies high automation with extensive coverage for corecursive definitions. CHP introduces heterogeneous productivity applicable to functions with diverse domain and codomain types, including non-coinductive types. Its key innovation is compositionality: the productivity of composite functions is systematically computed from their components, enabling modular reasoning about complex corecursive patterns.
  Building on CHP, we develop Coco, a corecursion library for Rocq that provides extensive automation for productivity computation and fixed-point generation.

</details>


### [16] [Common Knowledge, Sailboats, and Publicity](https://arxiv.org/abs/2511.21261)
*Sena Bozdag,Olivier Roy*

Main category: cs.LO

TL;DR: 论文提出，Lewisian常识知识比传统定义更适合解释“公开事件”，并以沙船案例为例，给出哲学与形式化论证。


<details>
  <summary>Details</summary>
Motivation: 解决沙船案例中的常识知识难题：某些事实在直觉上是“公开的”，但在传统迭代式定义下却不是常识知识。旨在解释什么才算事件对所有人公开。

Method: 通过非正式和形式化的方式，讨论并提出Lewisian常识知识（Lewisian common knowledge）与事件“公开性”（public）的关系。先用非正式论证澄清哲学立场，再用认知-可能性模型形式化该理论。

Result: Lewisian常识知识理论能够合理解释事件“公开”的含义，并能用形式化的认知-可能性模型加以表达，为此理论提供了哲学及形式上的证据。

Conclusion: Lewisian常识知识为事件“公开性”提供了更具说服力的理论解释，可看作对公共事实的新理解。

Abstract: We revisit a recent puzzle about common knowledge, the ``sailboat" case (Lederman, 2018), and argue that Lewisian common knowledge allows us to reconcile the pre-theoretical intuition that certain facts are ``public" in such situations, while these facts cannot be common knowledge in the classical, iterative sense. The crux of the argument is to understand Lewisian common knowledge as an account of what it means for an event to be public. We first formulate this argument informally to clarify its philosophical commitment and then propose one way to capture it formally in epistemic-plausibility models. Taken together, we take the philosophical and the formal arguments as providing evidence that Lewisian common knowledge is a plausible account of what it means for an event to be public.

</details>


### [17] [Bifurcation Logic: Separation Through Ordering](https://arxiv.org/abs/2511.21263)
*Didier Galmiche,Timo Lang,Daniel Méry,David Pym*

Main category: cs.LO

TL;DR: 本文提出了一种新的逻辑系统——分叉逻辑（BL），结合了经典模态性和乘积连接词（separating conjunction *），并给出了它的演算和应用。


<details>
  <summary>Details</summary>
Motivation: 现有逻辑体系在处理分离性及分支结构、多主体协同或访问控制场景时存在不足，BL通过新的语义和连接词来增强表达力，满足实际需求。

Method: 提出BL逻辑系统，定义了其语义；设计了带标签的表格演算，证明了其相对于关系语义的可靠性（完备性和一致性）；分析有限模型性质，并讨论可判定性；用一个多智能体访问控制案例进行展示。

Result: BL体系下，标准的有限模型性质不成立。但只考虑 * ，不含乘积蕴涵时每个模型都能缩减到有限，被证明是可判定的。其语法和语义适合建模复杂的多主体关系和访问控制问题。

Conclusion: BL在一般情形下不具有限模型性质，但去除乘积蕴涵后，模型可以等价缩减为有限，从而达到可判定性。BL在多智能体访问控制建模等场景表现出广泛的应用潜力。

Abstract: We introduce Bifurcation Logic, BL, which combines a basic classical modality with separating conjunction * together with its naturally associated multiplicative implication, that is defined using the modal ordering. Specifically, a formula A*B is true at a world w if and only if each of A,B holds at worlds that are each above w, on separate branches of the order, and have no common upper bound. We provide a labelled tableaux calculus for BL and establish soundness and completeness relative to its relational semantics. The standard finite model property fails for BL. However, we show that, in the absence of multiplicative implication, but in the presence of *, every model has an equivalent finite representation and that this is sufficient to obtain decidability. We illustrate the use of BL through an example of modelling multi-agent access control that is quite generic in its form, suggesting many applications.

</details>


### [18] [Two behavioural pseudometrics for continuous-time Markov processes](https://arxiv.org/abs/2511.21621)
*Linan Chen,Florence Clerc,Prakash Panangaden*

Main category: cs.LO

TL;DR: 本文针对连续时间马尔科夫过程，提出了一种新的基于轨迹的行为伪度量，并在理论上进行了全面分析，增强了系统行为相似性度量的能力。


<details>
  <summary>Details</summary>
Motivation: 二模拟是一种衡量状态之间行为等价性的概念，已在离散时间系统中被广泛研究，但对连续时间马尔科夫过程中的行为相似性度量方法还不充分。随着对系统行为精细分析的需求提升，亟需推广和比较连续时间下的行为度量方法。

Method: 本文在前期工作的基础上，提出了针对扩散过程的、基于轨迹的第二类行为伪度量。具体做法是在函数视角和实值逻辑视角下分别构造并分析该伪度量，并将其与先前提出的基于瞬时状态的伪度量进行对比。

Result: 作者构建了新的行为伪度量，并通过两种方法（函数和逻辑）进行了理论分析，证明了其合理性，同时对比了基于瞬时状态和基于轨迹两种度量的异同及适用场景。

Conclusion: 论文扩展了连续时间马尔科夫过程行为度量的工具箱，为模型行为分析提供了更精准的理论支持，并展示了基于轨迹的度量在描述扩散过程中的优势。

Abstract: Bisimulation is a concept that captures behavioural equivalence of states in a variety of types of transition systems. It has been widely studied in discrete-time settings where a key notion is the bisimulation metric which quantifies "how similar two states are". In [ 11], we generalized the concept of bisimulation metric in order to metrize the behaviour of continuous-time Markov processes. Similarly to the discrete-time case, we constructed a pseudometric following two iterative approaches - through a functional and through a real-valued logic, and showed that the outcomes coincide: the pseudometric obtained from the logic is a specific fixpoint of the functional which yields our first pseudometric. However, different from the discrete-time setting, in which the process has a step-by-step dynamics, the behavioural pseudometric we constructed applies to Markov processes that evolve continuously through time, such as diffusions and jump diffusions. While our treatment of the pseudometric in [11] relied on the time-indexed Markov kernels, in [ 8 , 9, 10 ], we showed the importance of trajectories in the consideration of behavioural equivalences for true continuous-time Markov processes. In this paper, we take the work from [11 ] further and propose a second behavioural pseudometric for diffusions based on trajectories. We conduct a similar study of this pseudometric from both the perspective of a functional and the viewpoint of a real-valued logic. We also compare this pseudometric with the first pseudometric obtained in [11].

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [19] [Democratizing LLM Efficiency: From Hyperscale Optimizations to Universal Deployability](https://arxiv.org/abs/2511.20662)
*Hen-Hsen Huang*

Main category: cs.CL

TL;DR: 研究呼吁转变LLM效率优化思路，提出针对低资源环境的新方向，包括无需重新训练的结构优化、轻量微调等，以降低技术门槛、减少碳浪费，实现大模型技术的公平普及。


<details>
  <summary>Details</summary>
Motivation: 当前最有效的大语言模型加速方法（如MoE、推测解码、复杂RAG）主要服务于少数大公司，资源有限的机构难以受益。这导致技术红利无法惠及更广泛的用户群体，如学校、医院等。

Method: 提出一项新的研究议程，包括：1）无需重新训练情况下对预训练模型结构进行优化；2）发明轻量级微调技术，兼顾效果和一致性；3）提升高效推理能力，适应复杂的思考链条；4）支持无需重型RAG的数据动态管理；5）倡导以OAE（开销感知效率）为新基准评测标准。

Result: 如果效率定义中加入部署成本、可持续性和公平性三要素，可以让LLM部署走向民主化，从而减少技术不平等和碳排放浪费。

Conclusion: 未来效率提升应关注简单鲁棒、面向一般用户而非大企业，呼吁社区探索适合有限资源场景下的可用与经济高效的大模型优化方法。

Abstract: Large language models (LLMs) have become indispensable, but the most celebrated efficiency methods -- mixture-of-experts (MoE), speculative decoding, and complex retrieval-augmented generation (RAG) -- were built for hyperscale providers with vast infrastructure and elite teams. Outside that context, their benefits collapse into overhead, fragility, and wasted carbon. The result is that a handful of Big Tech companies benefit, while thousands of hospitals, schools, governments, and enterprises are left without viable options. We argue that the next frontier is not greater sophistication at scale, but robust simplicity: efficiency that thrives under modest resources and minimal expertise. We propose a new research agenda: retrofitting pretrained models with more efficient architectures without retraining, inventing lightweight fine-tuning that preserves alignment, making reasoning economical despite long chains of thought, enabling dynamic knowledge management without heavy RAG pipelines, and adopting Overhead-Aware Efficiency (OAE) as a standard benchmark. By redefining efficiency to include adoption cost, sustainability, and fairness, we can democratize LLM deployment -- ensuring that optimization reduces inequality and carbon waste rather than amplifying them.

</details>


### [20] [Harmonic Token Projection (HTP): A Vocabulary-Free, Training-Free, Deterministic, and Reversible Embedding Methodology](https://arxiv.org/abs/2511.20665)
*Tcharlies Schmitz*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练与词表的新型文本嵌入方法HTP，可逆且解释性强，实验证明其能以极低计算成本达到与主流方法可比的语义相似性效果。


<details>
  <summary>Details</summary>
Motivation: 当前主流的文本嵌入方法依赖于神经网络和大规模数据训练，难以解释且资源消耗较高，因此作者希望设计一种无需训练、不依赖词表且具备可解释性的文本嵌入方法。

Method: 方法基于Unicode整数推导出谐波轨迹，将每个token解析为位相一致的几何向量，实现了离散符号到连续向量空间的可逆、解释性投影。

Result: 提出的Harmonic Token Projection方法在STS-B及其多语言扩展数据集上获得了Spearman相关系数0.68，且十种语言表现稳定，计算消耗极低，实现了高效且可逆的文本表达。

Conclusion: HTP表明即便不借助手工训练和概率统计，仅通过符号到空间的确定性几何映射，也能获取有意义的语义关系，从而为传统的数据驱动型嵌入方法提供了透明、高效的替代方案。

Abstract: This paper introduces the Harmonic Token Projection (HTP), a reversible and deterministic framework for generating text embeddings without training, vocabularies, or stochastic parameters. Unlike neural embeddings that rely on statistical co-occurrence or optimization, HTP encodes each token analytically as a harmonic trajectory derived from its Unicode integer representation, establishing a bijective and interpretable mapping between discrete symbols and continuous vector space. The harmonic formulation provides phase-coherent projections that preserve both structure and reversibility, enabling semantic similarity estimation from purely geometric alignment. Experimental evaluation on the Semantic Textual Similarity Benchmark (STS-B) and its multilingual extension shows that HTP achieves a Spearman correlation of \r{ho} = 0.68 in English, maintaining stable performance across ten languages with negligible computational cost and sub-millisecond latency per sentence pair. This demonstrates that meaningful semantic relations can emerge from deterministic geometry, offering a transparent and efficient alternative to data-driven embeddings. Keywords: Harmonic Token Projection, reversible embedding, deterministic encoding, semantic similarity, multilingual representation.

</details>


### [21] [A centroid based framework for text classification in itsm environments](https://arxiv.org/abs/2511.20667)
*Hossein Mohanna,Ali Ait-Bachir*

Main category: cs.CL

TL;DR: 本文提出了一种用于IT服务管理系统（ITSM）中树状层级分类的新框架：双嵌入质心分类方法，结合语义和词汇的质心表示，推断时通过互惠排序融合。


<details>
  <summary>Details</summary>
Motivation: ITSM系统需求高效且可解释的层级文本分类方法。现有方法在可扩展性、速度和可解释性上仍有不足。

Method: 为每个类别分别维护语义和词汇两种质心表示，分类时使用互惠排序融合两者信息。对8,968条ITSM服务单、123个类别进行评估，比较支持向量机，分析训练速度和增量更新时间。

Result: 分类F1得分达到0.731（SVM为0.727），训练速度提升5.9倍，增量更新最快152倍，排除嵌入计算后整体速度提升8.6-8.8倍，表明该方法在分类效果和工程效率上均有优势。

Conclusion: 该方法在实际ITSM服务类别分配任务中取得了与支持向量机相当的分类性能，并显著提升了训练和增量更新的速度，具有良好的可解释性和高效性，适合实际生产环境。

Abstract: Text classification with hierarchical taxonomies is a fundamental requirement in IT Service Management (ITSM) systems, where support tickets must be categorized into tree-structured taxonomies. We present a dual-embedding centroid-based classification framework that maintains separate semantic and lexical centroid representations per category, combining them through reciprocal rank fusion at inference time. The framework achieves performance competitive with Support Vector Machines (hierarchical F1: 0.731 vs 0.727) while providing interpretability through centroid representations. Evaluated on 8,968 ITSM tickets across 123 categories, this method achieves 5.9 times faster training and up to 152 times faster incremental updates. With 8.6-8.8 times speedup across batch sizes (100-1000 samples) when excluding embedding computation. These results make the method suitable for production ITSM environments prioritizing interpretability and operational efficiency.

</details>


### [22] [PIRA: Preference-Oriented Instruction-Tuned Reward Models with Dual Aggregation](https://arxiv.org/abs/2511.20668)
*Yongfu Xue*

Main category: cs.CL

TL;DR: PIRA提出新的训练策略，通过优化奖励模型的任务表达、奖励聚合与输出稳定性，有效提升LLM的对齐效率与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM奖励模型面临输入低效和奖励过优化问题，亟需新方法提高任务表达清晰度、抗偏能力和输出稳定性。

Method: 1. 将问答组改写为偏好指令，以明确任务需求；2. 聚合多元偏好任务奖励，减少偏差与提升鲁棒性；3. 在不同dropout率下平均value-head输出，稳定奖励评估。

Result: 使用PIRA后，奖励模型在多个实验中表现优越，解决了数据效率低、易过优化和奖励不稳定等关键问题。

Conclusion: PIRA通过三项策略显著改善了奖励模型的性能，在数据效率、抵御奖励过优化、输出稳定性方面取得明显成效。实验结果充分证明了其优越性。

Abstract: Reward models are crucial for aligning Large Language Models (LLMs) with human preferences but face two representative challenges. First, traditional discriminative reward models usually concatenate questions and responses directly as input, resulting in low data efficiency. Second, reward models are vulnerable to reward overoptimization. We propose PIRA, a training paradigm addressing these issues through three strategies: (1) Reformulating question-answer pairs into preference-based instructions for clearer and more explicit task specification, (2) aggregating rewards from diverse preference tasks to reduce bias and improve robustness, and (3) averaging value-head outputs under varying dropout rates to stabilize rewards. Extensive experiments have demonstrated the effectiveness of PIRA.

</details>


### [23] [Structured Definitions and Segmentations for Legal Reasoning in LLMs: A Study on Indian Legal Data](https://arxiv.org/abs/2511.20669)
*Mann Khatri,Mirza Yusuf,Rajiv Ratn Shah,Ponnurangam Kumaraguru*

Main category: cs.CL

TL;DR: 通过文档结构重组和法律概念解释，LLM在零样本法律任务上的F1分数提升最高达4.36%，显著优于基线，无需大量领域预训练。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）展现出良好的推理能力，但在法律等专业领域表现不佳，主要原因在于缺乏领域特定的预训练。法律文本长度大、结构复杂，导致模型难以高效理解全文。作者希望借助结构化信息和专业术语提升LLM在法律任务中的表现。

Method: 作者设计了三类实验：1）将法律文档基于修辞角色进行重组，以评估结构化信息对长文本处理和决策的影响；2）定义修辞角色，帮助模型熟悉法律领域相关术语；3）模拟法院基于修辞角色的逐步推理，提升模型推理能力。所有实验均在零样本设置下于印度三大法律判决预测数据集上进行。

Result: 在所有实验中，结构化文档或解释法律关键术语都能显著提升模型表现。相较于基线，F1分数最低提升1.5%，最高提升4.36%。

Conclusion: 结构重组或专业术语解释均能有效提升LLM在法律任务中的表现，表明模型能受益于领域结构化信息和知识注入，无需全量领域对齐即可取得显著提升。

Abstract: Large Language Models (LLMs), trained on extensive datasets from the web, exhibit remarkable general reasoning skills. Despite this, they often struggle in specialized areas like law, mainly because they lack domain-specific pretraining. The legal field presents unique challenges, as legal documents are generally long and intricate, making it hard for models to process the full text efficiently. Previous studies have examined in-context approaches to address the knowledge gap, boosting model performance in new domains without full domain alignment. In our paper, we analyze model behavior on legal tasks by conducting experiments in three areas: (i) reorganizing documents based on rhetorical roles to assess how structured information affects long context processing and model decisions, (ii) defining rhetorical roles to familiarize the model with legal terminology, and (iii) emulating the step-by-step reasoning of courts regarding rhetorical roles to enhance model reasoning. These experiments are conducted in a zero-shot setting across three Indian legal judgment prediction datasets. Our results reveal that organizing data or explaining key legal terms significantly boosts model performance, with a minimum increase of ~1.5% and a maximum improvement of 4.36% in F1 score compared to the baseline.

</details>


### [24] [MindSET: Advancing Mental Health Benchmarking through Large-Scale Social Media Data](https://arxiv.org/abs/2511.20672)
*Saad Mankarious,Ayah Zirikly,Daniel Wiechmann,Elma Kerz,Edward Kempa,Yu Qiao*

Main category: cs.CL

TL;DR: 本文提出了比以往更大且质量更高的心理健康社交媒体数据集MindSET，并展示其在诊断任务上的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有社交媒体心理健康分析基准数据集受限于数据量不足、数据清洗不到位和内容多样性，已难以满足研究发展需要。

Method: 从Reddit收集自述诊断的帖子，创建MindSET数据集，并进行严格的数据预处理（如语言过滤、去除NSFW及重复内容），采用LIWC进行语言分析，并用该数据集在分类任务中对比传统方法表现。

Result: 创建了包含7类心理健康状况、超1300万个标注帖子的MindSET数据集，模型在诊断检测任务上优于旧数据集，某些任务F1提升高达18分。

Conclusion: MindSET数据集为社交媒体与心理健康研究提供了坚实基础，有助于风险早期识别及心理趋势分析。

Abstract: Social media data has become a vital resource for studying mental health, offering real-time insights into thoughts, emotions, and behaviors that traditional methods often miss. Progress in this area has been facilitated by benchmark datasets for mental health analysis; however, most existing benchmarks have become outdated due to limited data availability, inadequate cleaning, and the inherently diverse nature of social media content (e.g., multilingual and harmful material). We present a new benchmark dataset, \textbf{MindSET}, curated from Reddit using self-reported diagnoses to address these limitations. The annotated dataset contains over \textbf{13M} annotated posts across seven mental health conditions, more than twice the size of previous benchmarks. To ensure data quality, we applied rigorous preprocessing steps, including language filtering, and removal of Not Safe for Work (NSFW) and duplicate content. We further performed a linguistic analysis using LIWC to examine psychological term frequencies across the eight groups represented in the dataset. To demonstrate the dataset utility, we conducted binary classification experiments for diagnosis detection using both fine-tuned language models and Bag-of-Words (BoW) features. Models trained on MindSET consistently outperformed those trained on previous benchmarks, achieving up to an \textbf{18-point} improvement in F1 for Autism detection. Overall, MindSET provides a robust foundation for researchers exploring the intersection of social media and mental health, supporting both early risk detection and deeper analysis of emerging psychological trends.

</details>


### [25] [Semantics Meet Signals: Dual Codebook Representationl Learning for Generative Recommendation](https://arxiv.org/abs/2511.20673)
*Zheng Hui,Xiaokai Wei,Reza Shirkavand,Chen Wang,Weizhi Zhang,Alejandro Peláez,Michelle Gong*

Main category: cs.CL

TL;DR: FlexCode是一种能兼顾热门项目和长尾项目的生成式推荐新方法，显著提升了整体与长尾推荐效果。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐统一使用单一代码本，导致热门和长尾项目的表征和泛化能力受限，FlexCode旨在解决此类表征不均衡和泛化能力差的问题。

Method: 该方法根据项目受欢迎度，将总token预算智能分配给CF代码本和语义代码本，并通过门控机制（MoE）动态平衡精细记忆与泛化，采用对齐与平滑目标函数保障不同受欢迎度项目间的表征连贯性。

Result: 提出了一种名为FlexCode的新生成式推荐方法，通过自适应地将编码预算分配给协同过滤和语义信息，提升了推荐精度和长尾项目的表现。实验证实该方法优于现有主流方法，在大规模数据集上表现突出。

Conclusion: FlexCode通过引入受受欢迎度调控的双代码本机制，改进了现有生成式推荐模型，提升了推理准确性和长尾稳健性，并为token表征和泛化提供了新思路。

Abstract: Generative recommendation has recently emerged as a powerful paradigm that unifies retrieval and generation, representing items as discrete semantic tokens and enabling flexible sequence modeling with autoregressive models. Despite its success, existing approaches rely on a single, uniform codebook to encode all items, overlooking the inherent imbalance between popular items rich in collaborative signals and long-tail items that depend on semantic understanding. We argue that this uniform treatment limits representational efficiency and hinders generalization. To address this, we introduce FlexCode, a popularity-aware framework that adaptively allocates a fixed token budget between a collaborative filtering (CF) codebook and a semantic codebook. A lightweight MoE dynamically balances CF-specific precision and semantic generalization, while an alignment and smoothness objective maintains coherence across the popularity spectrum. We perform experiments on both public and industrial-scale datasets, showing that FlexCode consistently outperform strong baselines. FlexCode provides a new mechanism for token representation in generative recommenders, achieving stronger accuracy and tail robustness, and offering a new perspective on balancing memorization and generalization in token-based recommendation models.

</details>


### [26] [Prompt Engineering Techniques for Context-dependent Text-to-SQL in Arabic](https://arxiv.org/abs/2511.20677)
*Saleh Almohaimeed,May Alsofyani,Saad Almohaimeed,Mansour Al Ghanim,Liqiang Wang*

Main category: cs.CL

TL;DR: 首次提出阿拉伯语text-to-SQL大规模数据集，验证了新方法GAT corrector能显著提升生成SQL的准确率，为该领域阿拉伯语研究奠定基础。


<details>
  <summary>Details</summary>
Motivation: 现有跨领域、上下文相关的text-to-SQL研究多集中在英文和部分中文，但目前尚无阿拉伯语相关的数据集与研究。为填补这一空白，作者提出了针对阿拉伯语的研究。

Method: 构建了大规模阿拉伯语text-to-SQL数据集，基于GPT-3.5/4.5-turbo模型，设计了10种提示工程技术，并提出并验证了GAT corrector方法，通过消融实验深入分析效果。

Result: 提出了首个阿拉伯语跨领域、上下文相关的text-to-SQL数据集Ar-SParC，包含3450个问题序列共10225个问答对。通过GPT-3.5-turbo和GPT-4.5-turbo模型、10种提示工程方法以及新模型GAT corrector进行了40组实验。GAT corrector在零样本和上下文学习设置下，分别提升了执行准确率和交互准确率1.9%和1.9%，1.72%和0.92%。并通过消融实验解释了GAT corrector对阿拉伯语的优越性。

Conclusion: Ar-SParC数据集解决了阿拉伯语text-to-SQL研究的资源匮乏，新方法GAT corrector显著提升了现有技术的表现，尤其在阿拉伯语场景下效果突出，有助于推动该领域发展。

Abstract: In recent years, the task of cross-domain, context-dependent text-to-SQL has received significant attention. Enables users with no prior knowledge of SQL to have a conversation with databases using natural language. However, most of the available datasets and research have been conducted in English, along with some work in Chinese. To this date, no effort has been made to address this task in the Arabic language. In this paper, we introduce Ar-SParC, the first Arabic cross-domain, context-dependent text-to-SQL dataset. The dataset consists of 3,450 sequences of interrelated questions, each sequence containing an average of approximately three questions, which results in a total of 10225 questions along with their corresponding SQL queries. We conducted 40 experiments on the Ar-SParC dataset using two large language models, GPT-3.5-turbo and GPT-4.5-turbo, applying 10 different prompt engineering techniques, including four question representation methods and six in-context learning techniques. Furthermore, we developed a novel approach named GAT corrector, which enhanced the performance across all 40 experiments, yielding an average improvement of 1.9% in execution accuracy (EX) and 1.9% in interaction accuracy (IX) under zero-shot settings, and an average increase of 1.72% EX and 0.92% IX under in-context learning settings. Finally, we conducted an ablation study with two more experiments to explain why the GAT corrector outperformed the previous GAT verifier technique, particularly for the Arabic language.

</details>


### [27] [Cognitive bias in LLM reasoning compromises interpretation of clinical oncology notes](https://arxiv.org/abs/2511.20680)
*Matthew W. Kenaston,Umair Ayub,Mihir Parmar,Muhammad Umair Anjum,Syed Arsalan Ahmed Naqvi,Priya Kumar,Samarth Rawal,Aadel A. Chaudhuri,Yousef Zakharia,Elizabeth I. Heath,Tanios S. Bekaii-Saab,Cui Tao,Eliezer M. Van Allen,Ben Zhou,YooJung Choi,Chitta Baral,Irbaz Bin Riaz*

Main category: cs.CL

TL;DR: 大语言模型在肿瘤临床推理中存在显著推理错误，可能导致不安全临床推荐。研究开发了可通用的推理错误分类体系，有助于提升模型临床应用前的推理可靠性评估。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型（LLM）在临床基准测试中表现优异，但其高分可能源于错误的推理过程，现有基于准确率的评估不足以发现此类安全风险。尤其在肿瘤学决策支持应用中，理解推理错误对确保安全至关重要。

Method: 开发并应用了一个分层的推理错误分类法，对GPT-4在肿瘤临床笔记推理过程中的错误进行识别和分析。首先在乳腺癌及胰腺癌CORAL数据集上标注推理轨迹，建立三级错误分类体系，并将此体系应用于前列腺癌咨询笔记上验证其有效性，任务包括信息提取、分析和临床推荐。

Result: 推理错误在23%的分析中出现，并且在全部错误中占主导地位，最常见的是确认性偏见和定锚偏见。推理错误常与不符合临床指南和有潜在危害的推荐相关，特别在晚期疾病管理中。自动化评估器能检测到错误但不能有效分类具体错误类型。

Conclusion: 大型语言模型在临床推理任务中，尽管表述流畅，但因推理错误频发，存在安全隐患。通过构建并验证推理错误分类体系，可以为临床部署前评估和改进模型的推理可靠性提供关键工具和方法。

Abstract: Despite high performance on clinical benchmarks, large language models may reach correct conclusions through faulty reasoning, a failure mode with safety implications for oncology decision support that is not captured by accuracy-based evaluation. In this two-cohort retrospective study, we developed a hierarchical taxonomy of reasoning errors from GPT-4 chain-of-thought responses to real oncology notes and tested its clinical relevance. Using breast and pancreatic cancer notes from the CORAL dataset, we annotated 600 reasoning traces to define a three-tier taxonomy mapping computational failures to cognitive bias frameworks. We validated the taxonomy on 822 responses from prostate cancer consult notes spanning localized through metastatic disease, simulating extraction, analysis, and clinical recommendation tasks. Reasoning errors occurred in 23 percent of interpretations and dominated overall errors, with confirmation bias and anchoring bias most common. Reasoning failures were associated with guideline-discordant and potentially harmful recommendations, particularly in advanced disease management. Automated evaluators using state-of-the-art language models detected error presence but could not reliably classify subtypes. These findings show that large language models may provide fluent but clinically unsafe recommendations when reasoning is flawed. The taxonomy provides a generalizable framework for evaluating and improving reasoning fidelity before clinical deployment.

</details>


### [28] [Dynamic Template Selection for Output Token Generation Optimization: MLP-Based and Transformer Approaches](https://arxiv.org/abs/2511.20683)
*Bharadwaj Yadavalli*

Main category: cs.CL

TL;DR: 本论文提出动态模板选择（DTS）方法，能根据问题复杂度灵活选用回答模板，实验证明其可在主要大模型平台上普遍减少三分之一token消耗且保持高准确率，有效降低使用成本。


<details>
  <summary>Details</summary>
Motivation: 当前大模型通常对各种类型的问题采用统一的提示策略，无论复杂分析任务还是简单事实问答都输出冗长的回答，导致token消耗效率低，且输出token的价格远高于输入token，加剧了成本压力。

Method: 提出了动态模板选择（DTS），根据查询复杂度自适应匹配回答模板。实现了两种路由方法：一种是使用预计算嵌入的简单MLP，另一种是经过微调的RoBERTa transformer。对比评估了这两种方法在不同主流LLM提供商下的效果。

Result: 在1,000个MMLU问题上，MLP路由器以90.5%的准确率超过RoBERTa的89.5%，且参数量更少。在三个主流LLM平台（OpenAI GPT-4, Google Gemini, Claude）上，DTS能将token消耗减少32.6%~33.9%，且路由准确率在90.5%保持一致。

Conclusion: 动态模板选择（DTS）可在保障输出质量的同时大幅降低token消耗和成本，具有很强的跨平台适用性。

Abstract: Contemporary large language model deployments typically employ uniform prompting strategies across diverse query types, applying verbose response patterns to both complex analytical tasks and straightforward factual questions. This one-size-fits-all methodology leads to substantial token inefficiency, a concern amplified by the significant cost differential between input and output tokens--the latter commanding 4-8x higher prices across major providers. We present Dynamic Template Selection (DTS), which adaptively matches response templates to query complexity, achieving significant cost reductions without compromising response quality.
  We compared two routing approaches: a simple MLP that uses pre-computed embeddings and a more complex fine-tuned RoBERTa transformer. Through comprehensive evaluation on 1,000 MMLU questions, we find that the MLP router achieves 90.5% routing accuracy on held-out test data, marginally exceeding RoBERTa's performance (89.5%) despite utilizing 125M fewer parameters. Notably, our empirical analysis reveals provider-agnostic behavior in template selection--routing decisions generalize effectively across 3 major LLM providers (OpenAI GPT-4, Google Gemini, and Anthropic Claude), as validated through 9,000 production API calls. While routing accuracy remains consistent at 90.5% across providers, observed token reductions vary from 32.6% to 33.9%, reflecting provider-specific generation characteristics.
  This work contributes several key elements: formal problem formulation with theoretical grounding in machine learning, four algorithms with corresponding complexity analyses, and extensive empirical validation across production systems.

</details>


### [29] [LLMs-Powered Accurate Extraction, Querying and Intelligent Management of Literature derived 2D Materials Data](https://arxiv.org/abs/2511.20691)
*Lijun Shang,Yadong Yu,Wenqiang Kang,Jian Zhou,Dongyue Gao,Pan Xiang,Zhe Liu,Mengyan Dai,Zhonglu Guo,Zhimei Sun*

Main category: cs.CL

TL;DR: 二维材料在能量存储和转换方面有广泛应用，但相关信息分散。本文系统整理了这些材料的性能和制备方法，有助于促进该领域发展。


<details>
  <summary>Details</summary>
Motivation: 二维材料因其独特的物理化学和电子特性，在储能与能量转换领域被广泛应用。尽管关于这些材料的性质和制备方法的关键信息大量散见于已发表的论文中，但相关数据分散，难以系统整合与获取，限制了研究与开发。

Method: 本论文通过系统梳理与分析已发表研究论文中关于二维材料的性质和制备方法的信息，尝试构建更加集中和易于获取的信息资源。

Result: 论文总结、集成了当前关于二维材料在能量存储和转换中的相关研究进展及其制备与性能数据，形成了有利于进一步研究和应用的信息基础。

Conclusion: 通过对已发表文献的归纳和分析，有助于研究者快速获取二维材料在能量领域的相关信息，推进后续的材料开发与应用。

Abstract: Two-dimensional (2D) materials have showed widespread applications in energy storage and conversion owning to their unique physicochemical, and electronic properties. Most of the valuable information for the materials, such as their properties and preparation methods, is included in the published research papers. However, due to the dispersion of synthe

</details>


### [30] [Memories Retrieved from Many Paths: A Multi-Prefix Framework for Robust Detection of Training Data Leakage in Large Language Models](https://arxiv.org/abs/2511.20799)
*Trung Cuong Dang,David Mohaisen*

Main category: cs.CL

TL;DR: 作者提出多前缀记忆定义，为检测LLMs的数据泄漏提供更健壮的工具，实验证明有效。


<details>
  <summary>Details</summary>
Motivation: 现有记忆定义无法全面描述LLMs在隐私和版权风险方面的深度记忆，尤其是在对齐模型上。作者希望提出更准确且实用的记忆检测方法。

Method: 通过设置目标前缀数量，用外部对抗性搜索判定序列是否被深度记忆，并在多种开源及对齐模型上进行实验对比。

Result: 本文提出了一种新的关于大语言模型（LLMs）训练时记忆现象的定义——多前缀记忆框架。该框架通过考察多少不同前缀能成功召回某序列，量化序列被深度记忆的程度，并在开源及对齐模型上实验证明其能够区分记忆与非记忆内容。

Conclusion: 多前缀记忆框架比传统方法更有效地区分模型记忆的数据，并为审计数据泄漏提供了更实用的途径。

Abstract: Large language models, trained on massive corpora, are prone to verbatim memorization of training data, creating significant privacy and copyright risks. While previous works have proposed various definitions for memorization, many exhibit shortcomings in comprehensively capturing this phenomenon, especially in aligned models. To address this, we introduce a novel framework: multi-prefix memorization. Our core insight is that memorized sequences are deeply encoded and thus retrievable via a significantly larger number of distinct prefixes than non-memorized content. We formalize this by defining a sequence as memorized if an external adversarial search can identify a target count of distinct prefixes that elicit it. This framework shifts the focus from single-path extraction to quantifying the robustness of a memory, measured by the diversity of its retrieval paths. Through experiments on open-source and aligned chat models, we demonstrate that our multi-prefix definition reliably distinguishes memorized from non-memorized data, providing a robust and practical tool for auditing data leakage in LLMs.

</details>


### [31] [SAGE: An Agentic Explainer Framework for Interpreting SAE Features in Language Models](https://arxiv.org/abs/2511.20820)
*Jiaojiao Han,Wujiang Xu,Mingyu Jin,Mengnan Du*

Main category: cs.CL

TL;DR: 本文提出了一种新的特征解释框架SAGE，用于提升对大型语言模型（LLMs）中稀疏自动编码器（SAE）特征的解释能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs的内部机制不透明，SAE可提升模型表征可解释性，但SAE特征本身依然难以解释。因此，亟需更有效的特征解释方法以促进模型安全与可靠部署。

Method: SAGE将特征解释过程由以往的被动单次生成任务转变为主动、驱动解释的多轮过程：系统性地为每个特征制定多种解释，通过设计针对性的实验进行验证，并根据激活反馈迭代优化解释。

Result: SAGE在生成和预测解释方面均大幅超越了当前最优基线方法，提升了LLMs特征解释的准确性和可靠性。

Conclusion: 通过在多种语言模型的SAE特征上进行实验，SAGE产生的解释在生成准确率和预测准确率上均明显优于现有方法。

Abstract: Large language models (LLMs) have achieved remarkable progress, yet their internal mechanisms remain largely opaque, posing a significant challenge to their safe and reliable deployment. Sparse autoencoders (SAEs) have emerged as a promising tool for decomposing LLM representations into more interpretable features, but explaining the features captured by SAEs remains a challenging task. In this work, we propose SAGE (SAE AGentic Explainer), an agent-based framework that recasts feature interpretation from a passive, single-pass generation task into an active, explanation-driven process. SAGE implements a rigorous methodology by systematically formulating multiple explanations for each feature, designing targeted experiments to test them, and iteratively refining explanations based on empirical activation feedback. Experiments on features from SAEs of diverse language models demonstrate that SAGE produces explanations with significantly higher generative and predictive accuracy compared to state-of-the-art baselines.an agent-based framework that recasts feature interpretation from a passive, single-pass generation task into an active, explanationdriven process. SAGE implements a rigorous methodology by systematically formulating multiple explanations for each feature, designing targeted experiments to test them, and iteratively refining explanations based on empirical activation feedback. Experiments on features from SAEs of diverse language models demonstrate that SAGE produces explanations with significantly higher generative and predictive accuracy compared to state-of-the-art baselines.

</details>


### [32] [Structured Prompting Enables More Robust, Holistic Evaluation of Language Models](https://arxiv.org/abs/2511.20836)
*Asad Aali,Muhammad Ahmed Mohsin,Vasiliki Bikia,Arnav Singhvi,Richard Gaus,Suhana Bedi,Hejie Cui,Miguel Fuentes,Alyssa Unell,Yifan Mai,Jordan Cahoon,Michael Pfeffer,Roxana Daneshjou,Sanmi Koyejo,Emily Alsentzer,Percy Liang,Christopher Potts,Nigam H. Shah,Akshay S. Chaudhari*

Main category: cs.CL

TL;DR: 开源DSPy+HELM框架，通过结构化prompt和链式思维方法提升语言模型评测准确性，发现未考虑prompt优化易低估性能，并改变模型间的性能比较结果。


<details>
  <summary>Details</summary>
Motivation: 当前广泛采用的语言模型(LMs)在实际应用前，迫切需要高质量的评估基准框架，现有如HELM框架虽可广泛比较任务，但多依赖固定prompt，难以泛化到不同模型，易低估模型真实能力。

Method: 提出可复现实验框架，将结构化prompt（如DSPy）与HELM结合，设计四种prompt方法，评测四款主流模型在七个基准测试（覆盖一般/医疗领域），与原HELM结果对比分析。

Result: 实验发现，无结构化prompt时，HELM平均低估模型性能4%，性能估计在不同基准间波动更大（标准差增加2%），性能排名有误（3/7数据集排名翻转），引入链式思维后，模型对prompt设计的敏感性减弱。

Conclusion: 通过结构化prompt和推理流程优化，能够更加真实、可扩展地估算模型性能上限，从而为模型部署决策提供更有用的基准；所提框架已开源。

Abstract: As language models (LMs) are increasingly adopted across domains, high-quality benchmarking frameworks that accurately estimate performance are essential for guiding deployment decisions. While frameworks such as Holistic Evaluation of Language Models (HELM) enable broad evaluation across tasks, they often rely on fixed prompts that fail to generalize across LMs, yielding unrepresentative performance estimates. Unless we estimate each LM's ceiling (maximum achievable via changes to the prompt), we risk underestimating performance. Declarative prompting frameworks, such as DSPy, offer a scalable alternative to manual prompt engineering by crafting structured prompts that can be optimized per task. However, such frameworks have not been systematically evaluated across established benchmarks. We present a reproducible DSPy+HELM framework that introduces structured prompting methods which elicit reasoning, enabling more accurate LM benchmarking. Using four prompting methods, we evaluate four frontier LMs across seven benchmarks (general/medical domain) against existing HELM baseline scores. We find that without structured prompting: (i) HELM underestimates LM performance (by 4% average), (ii) performance estimates vary more across benchmarks (+2% standard deviation), (iii) performance gaps are misrepresented (leaderboard rankings flip on 3/7 benchmarks), and (iv) introducing reasoning (chain-of-thought) reduces LM sensitivity to prompt design (smaller Δ across prompts). To our knowledge, this is the first large-scale benchmarking study to empirically characterize LM behavior across benchmarks and prompting methods, showing that scalable performance ceiling estimation enables more decision-useful benchmarks. We open-source (i) DSPy+HELM Integration (https://github.com/stanford-crfm/helm/pull/3893) and (ii) Prompt Optimization Pipeline (https://github.com/StanfordMIMI/dspy-helm).

</details>


### [33] [Length-MAX Tokenizer for Language Models](https://arxiv.org/abs/2511.20849)
*Dong Dong,Weijie Su*

Main category: cs.CL

TL;DR: 提出了一种新的高效分词器Length-MAX，优化语言模型编码效率，在各任务和推理过程中显著减少分词数和内存占用，提高模型速度和表现。


<details>
  <summary>Details</summary>
Motivation: 现有分词方法（如BPE）主要关注分词频率，分词数较多，导致训练和推理时间长、内存占用高，因此需开发一种能优化分词数且不损失下游任务表现的新分词方法。

Method: 将最大化分词平均长度的问题建模为图划分问题，并提出一种贪心近似算法以构建分词词表。

Result: 在FineWeb及多领域测试，Length-MAX Tokenizer分词数比BPE减少13-18%，同样模型达到固定验证损失训练步数减少约17-18%，推理延迟降低约13%，吞吐提升16%，下游任务如LAMBADA困惑度下降11.7%，HellaSwag准确率提升4.3%，同时词表覆盖率高达99.62%，oov率仅0.12%，推理时嵌入与KV-cache内存减小18%。

Conclusion: 优化平均分词长度能有效提升语言模型训练和推理效率，且Length-MAX在多项下游任务上表现优异，能与现有系统兼容。

Abstract: We introduce a new tokenizer for language models that minimizes the average tokens per character, thereby reducing the number of tokens needed to represent text during training and to generate text during inference. Our method, which we refer to as the Length-MAX tokenizer, obtains its vocabulary by casting a length-weighted objective maximization as a graph partitioning problem and developing a greedy approximation algorithm. On FineWeb and diverse domains, it yields 14--18\% fewer tokens than Byte Pair Encoding (BPE) across vocabulary sizes from 10K to 50K, and the reduction is 13.0\% when the size is 64K. Training GPT-2 models at 124M, 355M, and 1.3B parameters from scratch with five runs each shows 18.5\%, 17.2\%, and 18.5\% fewer steps, respectively, to reach a fixed validation loss, and 13.7\%, 12.7\%, and 13.7\% lower inference latency, together with a 16\% throughput gain at 124M, while consistently improving on downstream tasks including reducing LAMBADA perplexity by 11.7\% and enhancing HellaSwag accuracy by 4.3\%. Moreover, the Length-MAX tokenizer achieves 99.62\% vocabulary coverage and the out-of-vocabulary rate remains low at 0.12\% on test sets. These results demonstrate that optimizing for average token length, rather than frequency alone, offers an effective approach to more efficient language modeling without sacrificing -- and often improving -- downstream performance. The tokenizer is compatible with production systems and reduces embedding and KV-cache memory by 18\% at inference.

</details>


### [34] [Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory](https://arxiv.org/abs/2511.20857)
*Tianxin Wei,Noveen Sachdeva,Benjamin Coleman,Zhankui He,Yuanchen Bei,Xuying Ning,Mengting Ai,Yunzhe Li,Jingrui He,Ed H. Chi,Chi Wang,Shuo Chen,Fernando Pereira,Wang-Cheng Kang,Derek Zhiyuan Cheng*

Main category: cs.CL

TL;DR: 本文提出Evo-Memory评测框架，解决LLM模型在连续任务流中的记忆进化问题，并通过多种记忆模块统一测试与创新流水线方法，促进模型持续能力提升。


<details>
  <summary>Details</summary>
Motivation: 目前大量大语言模型(LLMs)的记忆机制多针对静态对话场景设计，缺乏适用于动态、连续任务流情境中的记忆管理和进化能力评测。实际应用如智能助理、具身智能体等，经常需要模型自我进化，能在运行过程中不断积累、整合和更新经验，但现有系统常常丢失上下文信息，无法有效复用历史经验。

Method: 作者提出了Evo-Memory，这是一个面向LLM智能体自进化记忆能力的流式评测基准和框架，将数据集构造成顺序任务流，要求模型在每次交互后主动搜索、适应并更新记忆。框架下统一实现了超过十种典型记忆模块，并在十大多轮目标任务和单轮推理与问答数据集上进行评测。同时，提出了ExpRAG基线方法用于经验检索，以及ReMem流程，集成了推理、任务操作与记忆更新以促进持续提升。

Result: Evo-Memory框架展示了在动态任务流下各类记忆模块的统一评测能力，以及经验复用对提升模型自我进化和问题解决性能的作用。ReMem流程在持续推理和任务行动中表现出更强的经验整合与记忆进化能力，有助于LLMs在实际环境中更好地处理连续任务。

Conclusion: Evo-Memory为检验与推进LLM智能体记忆管理与自进化提供了标准化工具，有力推动了面向现实应用场景的持续智能研究。

Abstract: Statefulness is essential for large language model (LLM) agents to perform long-term planning and problem-solving. This makes memory a critical component, yet its management and evolution remain largely underexplored. Existing evaluations mostly focus on static conversational settings, where memory is passively retrieved from dialogue to answer queries, overlooking the dynamic ability to accumulate and reuse experience across evolving task streams. In real-world environments such as interactive problem assistants or embodied agents, LLMs are required to handle continuous task streams, yet often fail to learn from accumulated interactions, losing valuable contextual insights, a limitation that calls for test-time evolution, where LLMs retrieve, integrate, and update memory continuously during deployment. To bridge this gap, we introduce Evo-Memory, a comprehensive streaming benchmark and framework for evaluating self-evolving memory in LLM agents. Evo-Memory structures datasets into sequential task streams, requiring LLMs to search, adapt, and evolve memory after each interaction. We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets. To better benchmark experience reuse, we provide a baseline method, ExpRAG, for retrieving and utilizing prior experience, and further propose ReMem, an action-think-memory refine pipeline that tightly integrates reasoning, task actions, and memory updates to achieve continual improvement.

</details>


### [35] [Winning with Less for Low Resource Languages: Advantage of Cross-Lingual English_Persian Argument Mining Model over LLM Augmentation](https://arxiv.org/abs/2511.20872)
*Ali Jahan,Masood Ghayoomi,Annette Hautli-Janisz*

Main category: cs.CL

TL;DR: 用英语数据和跨语言方法可显著提升低资源语言的论证挖掘效果，尤其英语波斯混合模型性能最佳，优于LLM增强方法。


<details>
  <summary>Details</summary>
Motivation: 低资源语言因缺乏高质量标注数据，论证挖掘任务受限。本文动机是在低资源情境下（如波斯语）利用高资源语言（英语）知识和跨语言技术，提升论证挖掘性能。

Method: 论文构建了三种训练模式用于低资源语言的论证挖掘任务，包括零样本迁移、基于LLM生成的增强样本、以及英语与手工翻译的波斯语数据混合的跨语言模型。评估基于英文Microtext语料库及其波斯语平行文本展开。

Result: 零样本迁移F1分数约为50%，LLM增强后提升至59.2%（英文）和69.3%（波斯语），而跨语言模型在波斯语上达到74.8%，超过LLM增强。

Conclusion: 轻量级跨语言混合方案，在数据稀缺的低资源语言环境下，比资源消耗较大的增强方法更有效，为低资源语言的论证挖掘任务提供了实用路径。

Abstract: Argument mining is a subfield of natural language processing to identify and extract the argument components, like premises and conclusions, within a text and to recognize the relations between them. It reveals the logical structure of texts to be used in tasks like knowledge extraction. This paper aims at utilizing a cross-lingual approach to argument mining for low-resource languages, by constructing three training scenarios. We examine the models on English, as a high-resource language, and Persian, as a low-resource language. To this end, we evaluate the models based on the English Microtext corpus \citep{PeldszusStede2015}, and its parallel Persian translation. The learning scenarios are as follow: (i) zero-shot transfer, where the model is trained solely with the English data, (ii) English-only training enhanced by synthetic examples generated by Large Language Models (LLMs), and (iii) a cross-lingual model that combines the original English data with manually translated Persian sentences. The zero-shot transfer model attains F1 scores of 50.2\% on the English test set and 50.7\% on the Persian test set. LLM-based augmentation model improves the performance up to 59.2\% on English and 69.3\% on Persian. The cross-lingual model, trained on both languages but evaluated solely on the Persian test set, surpasses the LLM-based variant, by achieving a F1 of 74.8\%. Results indicate that a lightweight cross-lingual blend can outperform considerably the more resource-intensive augmentation pipelines, and it offers a practical pathway for the argument mining task to overcome data resource shortage on low-resource languages.

</details>


### [36] [Emergence and Localisation of Semantic Role Circuits in LLMs](https://arxiv.org/abs/2511.20910)
*Nura Aljaafari,Danilo S. Carvalho,André Freitas*

Main category: cs.CL

TL;DR: 作者设计方法分析LLM内部抽象语义结构，发现其机制高度集中且相对独立，结构优化呈渐进变化，不同规模和架构间存在部分可迁移性。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型具备语义能力，但其内部实现抽象语义结构的机制尚缺乏深入刻画。作者希望揭示LLM内部语义机制的具体构成和迁移情况。

Method: 该论文提出结合角色交叉最小对、时序涌现分析和跨模型比较的方法，用于研究大语言模型如何实现语义角色。

Result: 分析表明：LLM语义机制高度集中（89-94%的归因集中于28个节点）；结构渐进优化而非阶段性突变；较大模型有时绕过局部电路。此外，跨比例和架构下组件仅部分重合（24-59%），但谱相似性高。

Conclusion: LLM内部形成紧凑且因果隔离的抽象语义结构机制，这些机制在不同规模和模型架构之间部分保留和迁移，揭示了模型语义能力的深层机制。

Abstract: Despite displaying semantic competence, large language models' internal mechanisms that ground abstract semantic structure remain insufficiently characterised. We propose a method integrating role-cross minimal pairs, temporal emergence analysis, and cross-model comparison to study how LLMs implement semantic roles. Our analysis uncovers: (i) highly concentrated circuits (89-94% attribution within 28 nodes); (ii) gradual structural refinement rather than phase transitions, with larger models sometimes bypassing localised circuits; and (iii) moderate cross-scale conservation (24-59% component overlap) alongside high spectral similarity. These findings suggest that LLMs form compact, causally isolated mechanisms for abstract semantic structure, and these mechanisms exhibit partial transfer across scales and architectures.

</details>


### [37] [Chatty-KG: A Multi-Agent AI System for On-Demand Conversational Question Answering over Knowledge Graphs](https://arxiv.org/abs/2511.20940)
*Reham Omar,Abdelghny Orogat,Ibrahim Abdelaziz,Omij Mangukiya,Panos Kalnis,Essam Mansour*

Main category: cs.CL

TL;DR: 提出了Chatty-KG，一种多智能体模块化系统，通过专门任务的LLM代理协同生成SPARQL查询，实现高效、多轮的知识图谱对话问答。实验结果显示，在准确率、速度和对话连贯性上优于主流方法，无需微调，且兼容多种模型。


<details>
  <summary>Details</summary>
Motivation: 传统KGQA和RAG方法各有不足，难以同时支持多轮对话、结构化检索、低延迟和上下文追踪。随着企业级和领域知识图谱广泛应用，亟需一种既具多轮交互能力，又能高效结构化检索知识的新系统。

Method: 利用多智能体的大语言模型进行任务分工（上下文解读、对话追踪、实体与关系链接、查询规划），协同生成SPARQL查询，实现自然语言到可执行查询的转换。融合RAG式检索与结构化执行，提升准确率和速度。

Result: Chatty-KG能在结构化知识图谱上进行多轮对话式问答。通过实验，Chatty-KG在多个大规模和多样化知识图谱上的单轮和多轮问答场景中，都显著优于现有系统，F1和P@1得分更高。该系统结构化设计确保了对话连贯性、无须额外微调和预处理即可支持不断发展的知识图谱，且兼容多种主流与开源大模型。

Conclusion: Chatty-KG结合多智能体协作和结构化检索，成功将对话灵活性与知识图谱的结构化优势统一，为多轮知识图谱问答提供了可扩展、可靠的新范式。

Abstract: Conversational Question Answering over Knowledge Graphs (KGs) combines the factual grounding of KG-based QA with the interactive nature of dialogue systems. KGs are widely used in enterprise and domain applications to provide structured, evolving, and reliable knowledge. Large language models (LLMs) enable natural and context-aware conversations, but lack direct access to private and dynamic KGs. Retrieval-augmented generation (RAG) systems can retrieve graph content but often serialize structure, struggle with multi-turn context, and require heavy indexing. Traditional KGQA systems preserve structure but typically support only single-turn QA, incur high latency, and struggle with coreference and context tracking. To address these limitations, we propose Chatty-KG, a modular multi-agent system for conversational QA over KGs. Chatty-KG combines RAG-style retrieval with structured execution by generating SPARQL queries through task-specialized LLM agents. These agents collaborate for contextual interpretation, dialogue tracking, entity and relation linking, and efficient query planning, enabling accurate and low-latency translation of natural questions into executable queries. Experiments on large and diverse KGs show that Chatty-KG significantly outperforms state-of-the-art baselines in both single-turn and multi-turn settings, achieving higher F1 and P@1 scores. Its modular design preserves dialogue coherence and supports evolving KGs without fine-tuning or pre-processing. Evaluations with commercial (e.g., GPT-4o, Gemini-2.0) and open-weight (e.g., Phi-4, Gemma 3) LLMs confirm broad compatibility and stable performance. Overall, Chatty-KG unifies conversational flexibility with structured KG grounding, offering a scalable and extensible approach for reliable multi-turn KGQA.

</details>


### [38] [TrackList: Tracing Back Query Linguistic Diversity for Head and Tail Knowledge in Open Large Language Models](https://arxiv.org/abs/2511.21006)
*Ioana Buhnila,Aman Sinha,Mathieu Constant*

Main category: cs.CL

TL;DR: LLM适合回答定义类问题，但在例证、释义等其他类型问题上表现不足，且依赖于知识的热度和频率，对技术性、冷门知识表现较差。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）在回答定义类问题上表现良好，但在回答例子、释义等非定义类问题时表现较差。人类可以轻松地给出多种类型的答案，而LLM难以做到。本文旨在分析LLM在不同语义类型问题上的表现差异，并思考预训练数据的影响。

Method: 作者提出TrackList分析流程，对LLM回答多种语言学问题的表现进行了细致的统计和语言分析，并引入了RefoMed-EN数据集用于实验，采用句法和语义相似度等多种度量方式评估输出质量。

Result: 实验结果表明，LLM在定义类型问题上的任务表现最好，在例证类型上的表现最差。对于定义类问题，LLM更倾向于对热门、高频知识进行释义，而对边缘、技术性知识的释义能力较弱，特别是在专业文本中。

Conclusion: 现有LLM虽能处理定义类知识，但其多样化回答能力（如例证、解释）仍有限，而且对低频、技术性知识的理解尤其欠缺。

Abstract: Large Language Models (LLMs) have proven efficient in giving definition-type answers to user input queries. While for humans giving various types of answers, such as examples and paraphrases, is an easy task, LLMs struggle to provide correct answers for other than definition-type queries. In this study, we evaluated this drop in performance using TrackList, a fine-grained linguistic and statistical analysis pipeline to investigate the impact of the pre-training data on LLMs answers to diverse linguistic queries. We also introduce RefoMed-EN, an English dataset consisting of 6170 human-annotated medical terms alongside their corresponding definitions, denominations, exemplifications, explanations, or paraphrases. We studied whether the high frequency of a concept (head) or low frequency (tail) impacts the language model's performance. We evaluated the quality of the LLM's output using syntactic and semantic similarity metrics, statistical correlations and embeddings. Results showed that the LLM's task performance for definition type questions is the highest, while for the exemplification type it is the lowest. Additionally, we showed that for definition-type questions, large language models are prone to paraphrase more on popular and frequent knowledge and less on tail and technical knowledge, especially in the expert texts.

</details>


### [39] [Semantic Anchors in In-Context Learning: Why Small LLMs Cannot Flip Their Labels](https://arxiv.org/abs/2511.21038)
*Anantha Padmanaban Krishna Kumar*

Main category: cs.CL

TL;DR: LLM的ICL机制主要强化预训练语义，难以彻底挑战或覆盖原有标签语义，表明few-shot提示下内在的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 核心问题为：在上下文学习（ICL）中，模型能否突破预训练的标签语义，还是仅仅在既有的语义基础上微调？研究意在厘清ICL的根本极限，理解模型对提示语义的适应程度。

Method: 本文通过将大型语言模型（LLMs）视为基于提示（prompt-induced）的分类器，比较其在正确标签（natural）和标签被系统颠倒（inverted）两种演示下的行为差异，利用三种对齐指标（真实、先验、提示对齐）和语义覆盖率（semantic override rate）分析ICL能力。试验覆盖八项分类任务、八个参数规模（1-12B）的开源LLMs。

Result: 实验证明，ICL更多是强化预训练形成的稳定语义方向，而难以灵活地重新映射标签语义。在自然演示下，ICL提升准确率且保持与零样本一致的先验对齐；在标签反转下，模型无法学到一致的反语义分类器，提示对齐的提升仅以准确率为代价，覆盖率始终为零。

Conclusion: ICL在few-shot（1-12B）设定下，难以超越预训练的语义锚点。覆盖标签语义需采用比目前ICL更强的干预方式，这为理解和提升LLMs基于提示的学习能力指明了新方向。

Abstract: Can in-context learning (ICL) override pre-trained label semantics, or does it merely refine an existing semantic backbone? We address this question by treating LLMs as prompt-induced classifiers and contrasting their behavior under \emph{natural} demonstrations (with correct labels) and \emph{inverted} demonstrations (systematically flipping label meanings). We decompose ICL behavior into three alignment metrics (truth, prior, and prompt alignment) and introduce a semantic override rate, defined as correctness under flipped semantics. Across eight classification tasks and eight open-source LLMs (1--12B parameters), we find consistent evidence for a semantic anchor view. With natural demonstrations, ICL improves accuracy while maintaining strong prior alignment; most correct predictions coincide with zero-shot behavior, even when the prior is weak. With inverted demonstrations, models cannot learn coherent anti-semantic classifiers: prompt alignment increases only by sacrificing accuracy, and semantic override rates remain exactly zero in our few-shot 1--12B setting. Rather than flexibly remapping label meanings, ICL primarily adjusts how inputs project onto stable semantic directions learned during pre-training, clarifying fundamental limits of few-shot prompting and suggesting that overriding label semantics at these scales requires interventions beyond ICL. All code is available at: https://github.com/AnanthaPadmanaban-KrishnaKumar/semantic-anchors-icl.

</details>


### [40] [Context-Aware Pragmatic Metacognitive Prompting for Sarcasm Detection](https://arxiv.org/abs/2511.21066)
*Michael Iskandardinata,William Christian,Derwin Suhartono*

Main category: cs.CL

TL;DR: 集成外部检索和自有知识提升讽刺文本识别，宏F1显著提高。


<details>
  <summary>Details</summary>
Motivation: 讽刺文本语义复杂且具文化多样性，现有大模型对背景知识及语境依赖的词或短语检测不准确，亟须依赖更丰富的外部与自有知识来提升检测能力。

Method: 基于Pragmatic Metacognitive Prompting（PMP）方法，引入两种补充上下文管道：一是通过网页检索获取模型缺乏的非参数知识，二是激发模型自身的内在知识。对三种主流讽刺检测数据集进行测试，分析不同知识源对检测准确率的提升。

Result: 提出了一种结合检索增强的背景知识与大模型自身知识的讽刺检测方法，比现有方法有显著性能提升。

Conclusion: 提供上下文知识，尤其是检索获得的相关背景信息，能大幅提升大型语言模型在讽刺检测中的表现，尤其是在文化特定术语与俚语环境下效果更佳。

Abstract: Detecting sarcasm remains a challenging task in the areas of Natural Language Processing (NLP) despite recent advances in neural network approaches. Currently, Pre-trained Language Models (PLMs) and Large Language Models (LLMs) are the preferred approach for sarcasm detection. However, the complexity of sarcastic text, combined with linguistic diversity and cultural variation across communities, has made the task more difficult even for PLMs and LLMs. Beyond that, those models also exhibit unreliable detection of words or tokens that require extra grounding for analysis. Building on a state-of-the-art prompting method in LLMs for sarcasm detection called Pragmatic Metacognitive Prompting (PMP), we introduce a retrieval-aware approach that incorporates retrieved contextual information for each target text. Our pipeline explores two complementary ways to provide context: adding non-parametric knowledge using web-based retrieval when the model lacks necessary background, and eliciting the model's own internal knowledge for a self-knowledge awareness strategy. We evaluated our approach with three datasets, such as Twitter Indonesia Sarcastic, SemEval-2018 Task 3, and MUStARD. Non-parametric retrieval resulted in a significant 9.87% macro-F1 improvement on Twitter Indonesia Sarcastic compared to the original PMP method. Self-knowledge retrieval improves macro-F1 by 3.29% on Semeval and by 4.08% on MUStARD. These findings highlight the importance of context in enhancing LLMs performance in sarcasm detection task, particularly the involvement of culturally specific slang, references, or unknown terms to the LLMs. Future work will focus on optimizing the retrieval of relevant contextual information and examining how retrieval quality affects performance. The experiment code is available at: https://github.com/wllchrst/sarcasm-detection_pmp_knowledge-base.

</details>


### [41] [Enhancing Burmese News Classification with Kolmogorov-Arnold Network Head Fine-tuning](https://arxiv.org/abs/2511.21081)
*Thura Aung,Eaint Kay Khaing Kyaw,Ye Kyaw Thu,Thazin Myint Oo,Thepchai Supnithi*

Main category: cs.CL

TL;DR: KAN模型（如EfficientKAN和FasterKAN）在低资源语言分类中能有效替代传统MLP分类头，表现更优或持平且计算更高效，推荐作为新选择。


<details>
  <summary>Details</summary>
Motivation: 低资源语言在分类任务中通常只微调最后的分类层，并冻结预训练编码器参数。传统的MLP头因非线性固定且计算成本较高，表达能力受限，因此需要探索更高效且更具表现力的替代方案。

Method: 本文探讨了Kolmogorov-Arnold Networks (KANs) 作为低资源语言（如缅甸语）分类任务中替代常用MLP的新型分类头。具体实验对比了三种KAN模型（FourierKAN, EfficientKAN, FasterKAN），并测试了多种嵌入方式，包括TF-IDF、fastText以及多语言Transformer嵌入（mBERT, Distil-mBERT）。

Result: 实验结果显示，KAN类模型作为分类头与传统MLP相比，具有竞争力甚至更优表现。EfficientKAN结合fastText嵌入获得了最高F1分数（0.928），FasterKAN则在速度和准确率之间实现了最佳平衡。在Transformer嵌入上，EfficientKAN与MLP表现持平或略优（mBERT上F1为0.917）。

Conclusion: 本文证实KAN是一种表现力强、效率高的MLP替代方案，在低资源语言任务，尤其是分类领域中有较大应用潜力。

Abstract: In low-resource languages like Burmese, classification tasks often fine-tune only the final classification layer, keeping pre-trained encoder weights frozen. While Multi-Layer Perceptrons (MLPs) are commonly used, their fixed non-linearity can limit expressiveness and increase computational cost. This work explores Kolmogorov-Arnold Networks (KANs) as alternative classification heads, evaluating Fourier-based FourierKAN, Spline-based EfficientKAN, and Grid-based FasterKAN-across diverse embeddings including TF-IDF, fastText, and multilingual transformers (mBERT, Distil-mBERT). Experimental results show that KAN-based heads are competitive with or superior to MLPs. EfficientKAN with fastText achieved the highest F1-score (0.928), while FasterKAN offered the best trade-off between speed and accuracy. On transformer embeddings, EfficientKAN matched or slightly outperformed MLPs with mBERT (0.917 F1). These findings highlight KANs as expressive, efficient alternatives to MLPs for low-resource language classification.

</details>


### [42] [Orthographic Constraint Satisfaction and Human Difficulty Alignment in Large Language Models](https://arxiv.org/abs/2511.21086)
*Bryan E. Tuck,Rakesh M. Verma*

Main category: cs.CL

TL;DR: 本文系统评估了三种不同大语言模型架构在严格拼写约束任务上的表现，发现架构创新比单纯扩展参数或算力更关键，尤其是在处理非常规拼写表达时。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在受控文本生成时，需满足严格的拼写约束。然而，不同模型架构下系统性的评估还很有限。本文探讨不同模型架构和参数扩展对拼写约束任务的影响。

Method: 通过58个需要字符级约束满足的单词谜题，对Qwen3、Claude Haiku-4.5、GPT-5-mini三个模型家族的28种配置进行测试，并引入10000名人类解谜者的难度评价作为对比。

Result: 模型架构差异带来的性能差异远大于参数扩展（2.0-2.2倍 vs. 83%提升）。高容量模型‘思考预算’增加时性能提升显著，而中等容量模型则出现饱和或退化。所有模型对难度的校准一致但有限(r=0.24-0.38)。常见但拼写不寻常的词模型错误率极高（89-96%），说明过度依赖分布式合理性。

Conclusion: 要提升拼写约束表现，不能单纯靠模型规模或算力扩展，需从架构或训练目标进行专业化创新。

Abstract: Large language models must satisfy hard orthographic constraints during controlled text generation, yet systematic cross-architecture evaluation remains limited. We evaluate 28 configurations spanning three model families (Qwen3, Claude Haiku-4.5, GPT-5-mini) on 58 word puzzles requiring character-level constraint satisfaction. Architectural differences produce substantially larger performance gaps (2.0-2.2x, F1=0.761 vs. 0.343) than parameter scaling within families (83% gain from eightfold scaling), suggesting that constraint satisfaction may require specialized architectural features or training objectives beyond standard language model scaling. Thinking budget sensitivity proves heterogeneous: high-capacity models show strong returns (+0.102 to +0.136 F1), while mid-sized variants saturate or degrade. These patterns are inconsistent with uniform compute benefits. Using difficulty ratings from 10,000 human solvers per puzzle, we establish modest but consistent calibration (r=0.24-0.38) across all families, yet identify systematic failures on common words with unusual orthography ("data", "poop", "loll": 86-95% human success, 89-96% model miss rate). These failures reveal over-reliance on distributional plausibility that penalizes orthographically atypical but constraint-valid patterns, suggesting architectural innovations may be required beyond simply scaling parameters or computational budgets.

</details>


### [43] [ASR Error Correction in Low-Resource Burmese with Alignment-Enhanced Transformers using Phonetic Features](https://arxiv.org/abs/2511.21088)
*Ye Bhone Lin,Thura Aung,Ye Kyaw Thu,Thazin Myint Oo*

Main category: cs.CL

TL;DR: 提出适用于缅甸语低资源场景的ASR错误纠正模型，通过结合IPA和对齐特征显著降低了识别错误率。


<details>
  <summary>Details</summary>
Motivation: 缅甸语属于低资源语言，在自动语音识别（ASR）中错误率较高，缺乏有针对性的错误纠正研究。本文旨在通过新的特征集成方法提升缅甸语ASR结果准确率。

Method: 采用序列到序列的Transformer模型，结合国际音标（IPA）和对齐信息等多种特征，设计并评估ASR误差纠正（AEC）模型。测试了五种不同的ASR主模型，并对比有无纠错模型时的表现。

Result: 组合IPA及对齐特征的AEC模型将ASR的平均词错误率（WER）从51.56降至39.82（增强前），增强后降至43.59；chrF++分数则从0.5864提升到0.627，各项指标均优于无纠错时的基线模型。

Conclusion: AEC方法稳健有效，能够明显提升低资源环境下缅甸语的ASR输出，特征设计对性能提升至关重要。

Abstract: This paper investigates sequence-to-sequence Transformer models for automatic speech recognition (ASR) error correction in low-resource Burmese, focusing on different feature integration strategies including IPA and alignment information. To our knowledge, this is the first study addressing ASR error correction specifically for Burmese. We evaluate five ASR backbones and show that our ASR Error Correction (AEC) approaches consistently improve word- and character-level accuracy over baseline outputs. The proposed AEC model, combining IPA and alignment features, reduced the average WER of ASR models from 51.56 to 39.82 before augmentation (and 51.56 to 43.59 after augmentation) and improving chrF++ scores from 0.5864 to 0.627, demonstrating consistent gains over the baseline ASR outputs without AEC. Our results highlight the robustness of AEC and the importance of feature design for improving ASR outputs in low-resource settings.

</details>


### [44] [MortgageLLM: Domain-Adaptive Pretraining with Residual Instruction Transfer, Alignment Tuning, and Task-Specific Routing](https://arxiv.org/abs/2511.21101)
*Manish Jain,Satheesh Kumar Ponnambalam,Salman Faroz,Chandrakanth Lns,Vinay Sharma*

Main category: cs.CL

TL;DR: 本文提出MortgageLLM，一种专为抵押贷款金融领域设计的大语言模型，在保证模型任务能力的同时，强化了领域知识，采用双专家（dual-expert）架构，有效解决多任务模型中能力权衡问题，并通过智能任务路由提升整体性能。


<details>
  <summary>Details</summary>
Motivation: 应对大模型在特定行业应用中因领域知识不足和多任务性能权衡所带来的挑战，尤其是在金融抵押贷款这样高度专业化的场景下，需提升模型在专业任务和对话指令上的双重能力。

Method: 采用从单一基础模型LLaMA-3.1-8B发展出的双轨道专业化（dual-track specialization）框架，分别针对结构化任务与对话任务训练专门模型，并利用instruction residual技术恢复领域适应后丧失的指令跟随性，同时引入专家模型自我完成的智能任务路由机制。

Result: MortgageLLM在专业基准数据集上，摘要、问答和分类等任务表现显著超越基础模型，LLM-as-a-Judge评测中分别提升0.59（摘要）、0.09（问答）与1.4（分类），BERTScore也有明显增长，充分验证方法有效性。

Conclusion: 实验证明，MortgageLLM在领域内的问答、摘要和分类任务上均大幅超过基础模型，有效提升了在抵押贷款金融领域的应用能力。

Abstract: Large Language Models (LLMs) demonstrate exceptional capabilities across general domains, yet their application to specialized sectors such as mortgage finance requires domain-specific knowledge augmentation while preserving instruction-following fidelity. We present MortgageLLM, a novel domain-specific large language model that addresses this dual challenge. It is developed using a dual-track specialization framework from a single base model (LLaMA-3.1-8B). We opted for this dual-expert approach as a single multi-task model suffers from performance trade-offs, where optimizing for structured tasks (via SFT) degrades conversational fidelity (via DPO). Our dual-track method solves this by creating two specialists, allowing each to be optimally trained for its distinct capability. Our approach applies the instruction residual technique to restore instruction-following capabilities post-domain adaptation without supervised fine-tuning. We contribute: (1) application of this residual technique to the highly specialized mortgage finance domain; (2) a dual-expert architecture combining a conversational Q&A model and a structured task model for classification and summarization; and (3) an intelligent task routing mechanism using few-shot classification performed by one of the expert models itself. We validate our approach on domain-specific benchmarks, where our final model (MLM v2) significantly outperforms the base LLaMA-3.1-8B-Instruct, achieving an LLM-as-a-Judge summarization score of 4.58 (vs. 3.99), a Q&A score of 4.09 (vs. 4.0), and a classification score of 2.6 (vs. 1.2). On semantic similarity, our model achieved a BERTScore of 0.77 for summarization (vs. 0.74), 0.68 for Q&A (vs. 0.58), and 0.75 for classification (vs. 0.73), substantially outperforming baseline approaches.

</details>


### [45] [Self-Guided Defense: Adaptive Safety Alignment for Reasoning Models via Synthesized Guidelines](https://arxiv.org/abs/2511.21214)
*Yuhang Wang,Yanxu Zhu,Dongyuan Lu,Jitao Sang*

Main category: cs.CL

TL;DR: 本文提出了SGASA框架，通过模型生成的安全准则，加强了模型对有害对抗性提示的鲁棒性，同时减少对良性请求的无必要拒绝。实验证明该方法显著提升了模型安全性。


<details>
  <summary>Details</summary>
Motivation: 当前推理模型易被隐藏和欺骗性的越狱提示规避安全机制，诱发有害内容生成，因此需要一种能自适应加强模型安全性的机制来抵御此类攻击。

Method: SGASA包含两个阶段：1）数据预合成，自动生成安全指南及扩增提示；2）对齐微调，利用有监督微调（SFT）和直接偏好优化（DPO）将安全准则嵌入模型中。

Result: 通过对多个数据集的广泛实验，SGASA显著提升了模型在对抗性提示下的安全性，并有效减少了对正常请求的误拒绝。

Conclusion: SGASA方法能够有效提高推理模型面对对抗性越狱提示时的安全性，对各类数据集均表现出适应性和可扩展性。

Abstract: Reasoning models have demonstrated remarkable capabilities in complex reasoning tasks. However, ensuring their safety against adversarial jailbreak prompts remains a critical challenge. Due to the covert and deceptive nature of such prompts, they can often evade built-in safety mechanisms and lead to the generation of harmful content. This underscores the need for an adaptive safety alignment approach that enables models to autonomously reinforce their defenses in response to adversarial inputs. This paper introduces the Synthesized Guideline-based Adaptive Safety Alignment (SGASA) framework, which internalizes model-generated safety guidelines to strengthen models' ability to enhance robustness against harmful adversarial prompts while minimizing unnecessary refusals of benign requests. SGASA consists of two key stages: Data Pre-synthesis, which generates safety guidelines and augmented prompts; and Alignment Fine-tuning, which leverages Supervised Fine-tuning (SFT) and Direct Preference Optimization (DPO) to embed these guidelines into the model. Extensive experiments across multiple datasets demonstrate that SGASA significantly improves model safety, validating its adaptive and scalable effectiveness.

</details>


### [46] [Can Finetuing LLMs on Small Human Samples Increase Heterogeneity, Alignment, and Belief-Action Coherence?](https://arxiv.org/abs/2511.21218)
*Steven Wang,Kyle Hunt,Shaojie Tang,Kenneth Joseph*

Main category: cs.CL

TL;DR: 小样本微调能够提升LLM模拟人的多样性与群体对齐，但其生成的数据在正式统计分析上仍不能替代人类。


<details>
  <summary>Details</summary>
Motivation: 鉴于LLM在模拟人类行为上的显著偏差及局限，作者探讨能否通过微调（使用小规模人类数据）来提升其模拟真实人类行为的能力，特别关注微调对统计分析结果的影响。

Method: 作者采用信息披露行为实验，比较人类与LLM（基础与微调模型）在分布差异、群体对齐、信念-行为一致性以及回归系数方面的表现。微调采用了真实人类调查小样本数据。

Result: 本文发现，通过在一小部分人类调查数据上微调大型语言模型（LLM），的确可以在回应异质性（多样性）、与人类小群体的对齐、以及信念与行为的一致性等方面显著提升LLM的表现。这说明微调能一定程度纠正基础模型与人类实际行为之间的偏差。但即便是表现最好的微调模型，也未能再现原始研究中的回归系数，显示LLM在正式的推断分析中仍无法完全替代真实的人类参与者。

Conclusion: 微调后的LLM可更好模拟人类在有限方面的行为，但其数据在严格的统计推断分析中依然不可靠，不能作为人类数据的替代品。

Abstract: There is ongoing debate about whether large language models (LLMs) can serve as substitutes for human participants in survey and experimental research. While recent work in fields such as marketing and psychology has explored the potential of LLM-based simulation, a growing body of evidence cautions against this practice: LLMs often fail to align with real human behavior, exhibiting limited diversity, systematic misalignment for minority subgroups, insufficient within-group variance, and discrepancies between stated beliefs and actions. This study examines an important and distinct question in this domain: whether fine-tuning on a small subset of human survey data, such as that obtainable from a pilot study, can mitigate these issues and yield realistic simulated outcomes. Using a behavioral experiment on information disclosure, we compare human and LLM-generated responses across multiple dimensions, including distributional divergence, subgroup alignment, belief-action coherence, and the recovery of regression coefficients. We find that fine-tuning on small human samples substantially improves heterogeneity, alignment, and belief-action coherence relative to the base model. However, even the best-performing fine-tuned models fail to reproduce the regression coefficients of the original study, suggesting that LLM-generated data remain unsuitable for replacing human participants in formal inferential analyses.

</details>


### [47] [Developing an Open Conversational Speech Corpus for the Isan Language](https://arxiv.org/abs/2511.21229)
*Adisai Na-Thalang,Chanakan Wittayasakpan,Kritsadha Phatcharoen,Supakit Buakaw*

Main category: cs.CL

TL;DR: 本文首次面向伊善语开发了开放的自然会话语音数据集，克服了书写体系不统一等难题，提出了平衡语言真实性与计算需求的转录方案，并以开放资源推动包容性的AI与少数语言研究。


<details>
  <summary>Details</summary>
Motivation: 目前伊善语等泰国区域方言缺乏高质量、自然会话语音数据集，尤其缺少能反映真实语言现象的资源，制约了相关语言技术和AI发展的包容性。作者希望通过建设开放资源来推动弱势语言的研究与应用。

Method: 开发伊善语自然会话语音数据集，分析语言现象，制定实用转录协议以应对无统一书写体系带来的技术挑战，然后发布数据集供研究与应用。

Result: 本文开发了第一个公开的伊善语会话语音数据集，这是泰国应用最广泛的地方方言之一。该数据集基于自然会话语音，捕捉到真实的语言现象如口语表达、自发韵律、语音不流畅以及与标准泰语的频繁语码转换。研究重点在于缺乏统一的伊善语书写体系，且由于泰语和伊善语间的音调差异，现有书写方式存在较大差异，这给转录规范的制定和一致性、实用性以及语言真实性的发展带来了挑战。为此，作者制定了兼顾语言准确性与计算处理需求的实用转录协议。

Conclusion: 开放发布的伊善语会话语音数据集可促进包容性AI发展、支持弱势语言的研究，并成为解决会话语音建模语言及技术挑战的基础。

Abstract: This paper introduces the development of the first open conversational speech dataset for the Isan language, the most widely spoken regional dialect in Thailand. Unlike existing speech corpora that are primarily based on read or scripted speech, this dataset consists of natural speech, thereby capturing authentic linguistic phenomena such as colloquials, spontaneous prosody, disfluencies, and frequent code-switching with central Thai. A key challenge in building this resource lies in the lack of a standardized orthography for Isan. Current writing practices vary considerably, due to the different lexical tones between Thai and Isan. This variability complicates the design of transcription guidelines and poses questions regarding consistency, usability, and linguistic authenticity. To address these issues, we establish practical transcription protocols that balance the need for representational accuracy with the requirements of computational processing. By releasing this dataset as an open resource, we aim to contribute to inclusive AI development, support research on underrepresented languages, and provide a basis for addressing the linguistic and technical challenges inherent in modeling conversational speech.

</details>


### [48] [PEFT-Bench: A Parameter-Efficient Fine-Tuning Methods Benchmark](https://arxiv.org/abs/2511.21285)
*Robert Belanec,Branislav Pecher,Ivan Srba,Maria Bielikova*

Main category: cs.CL

TL;DR: 作者开发了PEFT-Bench基准，综合评测多种PEFT方法在多数据集上的效果，并提出了新的评测指标PSCP，可量化参数、速度和内存等多方面表现。


<details>
  <summary>Details</summary>
Motivation: 尽管PEFT方法日趋丰富，但缺乏系统、全面且易复现的评测体系，现有评估在模型、数据集和可复现性方面都有局限，因此需要一个统一基准来对PEFT技术进行公平、科学的比较。

Method: 作者构建了一个标准化评测基准PEFT-Bench，支持多模型、多数据集、多方法的自动化评测，并整合了新的量化指标（PSCP），系统地衡量不同PEFT方法的性能及资源占用。

Result: 本文提出了PEFT-Bench，一个统一的端到端基准，用于全面评估各种参数高效微调（PEFT）方法在自回归式大语言模型（LLM）上的表现。实验涵盖27个NLP数据集和6种PEFT方法，并引入了PEFT Soft Score Penalties（PSCP）指标，从参数数量、推理速度和训练显存三个维度，综合评估PEFT方法的效率与性能。

Conclusion: PEFT-Bench为 PEFT 方法的公平、可复现和广泛评估提供了平台，并通过PSCP指标促进了多维度效率的量化比较，推动了高效微调技术的进一步发展。

Abstract: Despite the state-of-the-art performance of Large Language Models (LLMs) achieved on many tasks, their massive scale often leads to high computational and environmental costs, limiting their accessibility. Parameter-efficient fine-tuning (PEFT) methods address this challenge by reducing the number of trainable parameters while maintaining strong downstream performance. Despite the increased development in PEFT methods, current evaluations remain limited (in terms of evaluated models and datasets) and difficult to reproduce. To bridge this gap, we introduce PEFT-Bench, a unified end-to-end benchmark for evaluating diverse PEFT methods on autoregressive LLMs. We demonstrate its usage across 27 NLP datasets and 6 PEFT methods. To account for different PEFT training and inference factors, we also introduce the PEFT Soft Score Penalties (PSCP) metric, which takes trainable parameters, inference speed, and training memory usage into account.

</details>


### [49] [Emergent Lexical Semantics in Neural Language Models: Testing Martin's Law on LLM-Generated Text](https://arxiv.org/abs/2511.21334)
*Kai Kugler*

Main category: cs.CL

TL;DR: 首次系统性揭示LLM训练过程中Martin定律的动态变化，指出其并非随训练单调增强，而是在特定阶段达最优窗口。提出并验证了监测神经语言结构新方法。


<details>
  <summary>Details</summary>
Motivation: 目前关于神经语言模型生成文本中，词频和多义词数量的关系（即Martin定律）尚缺乏系统性研究。理解这种关系的演化对揭示大语言模型的语言结构能力具有重要意义。

Method: 采用DBSCAN算法对词的上下文嵌入进行聚类，从而操作性地定义词义数量。分析了四个不同参数规模（70M-1B）的Pythia模型，在30个训练过程中的检查点表现。重点监测Martin定律（词频与多义性关系）的出现、强化与衰减过程。

Result: 发现Martin定律在约第100个checkpoint时出现，104时达峰值（相关系数r>0.6），之后在105衰减。小模型（70M、160M）后期出现语义灾难性塌缩，而大模型（410M、1B）语义表现下降较为平缓。词频-词义特异性权衡在所有模型中基本稳定（r≈-0.3）。

Conclusion: LLM生成文本对语言规律（如Martin定律）的契合度随训练呈非单调变化，并有最优表现窗口。规模较小模型易在后期出现语义结构塌缩，大模型则较为稳健。这为后续模型训练与评价提供了新思路。

Abstract: We present the first systematic investigation of Martin's Law - the empirical relationship between word frequency and polysemy - in text generated by neural language models during training. Using DBSCAN clustering of contextualized embeddings as an operationalization of word senses, we analyze four Pythia models (70M-1B parameters) across 30 training checkpoints. Our results reveal a non-monotonic developmental trajectory: Martin's Law emerges around checkpoint 100, reaches peak correlation (r > 0.6) at checkpoint 104, then degrades by checkpoint 105. Smaller models (70M, 160M) experience catastrophic semantic collapse at late checkpoints, while larger models (410M, 1B) show graceful degradation. The frequency-specificity trade-off remains stable (r $\approx$ -0.3) across all models. These findings suggest that compliance with linguistic regularities in LLM-generated text is not monotonically increasing with training, but instead follows a balanced trajectory with an optimal semantic window. This work establishes a novel methodology for evaluating emergent linguistic structure in neural language models.

</details>


### [50] [Training Introspective Behavior: Fine-Tuning Induces Reliable Internal State Detection in a 7B Model](https://arxiv.org/abs/2511.21399)
*Joshua Fonseca Rivera*

Main category: cs.CL

TL;DR: 通过专门训练，语言模型能可靠地自我报告被注入的“思维”，显著提升对应的检测准确率，且泛化能力良好。


<details>
  <summary>Details</summary>
Motivation: 探究语言模型的内省自觉能力是否可以通过直接训练获得，而不是依靠自然涌现，从而提升模型解释性与透明度，回应前人提出的模型间内省能力显著差异的问题。

Method: 4组实验，重点是对模型进行微调，让其学习识别和报告被注入的瞬时“思维”激活，以提升自我觉察表现。对比微调前后模型在检测准确率和假阳性上的差异，并评估泛化能力。

Result: 通过微调，作者成功显著提升了语言模型检测单点激活“思维”注入的能力，由原始极低准确率提升至85%，并消除假阳性。模型可以检测并记忆瞬时注入的信息，并在后续生成中准确报告其内容，还能将学习到的检测能力泛化到未见过的概念向量。

Conclusion: 直接训练可以使模型具备内省检测能力，实现部分透明性；相关能力可迁移，但未必具备深层的自我元认知表征。这项方法有效解决了之前关于模型间内省能力差异的问题。

Abstract: Lindsey (2025) investigates introspective awareness in language models through four experiments, finding that models can sometimes detect and identify injected activation patterns -- but unreliably (~20% success in the best model). We focus on the first of these experiments -- self-report of injected "thoughts" -- and ask whether this capability can be directly trained rather than waiting for emergence. Through fine-tuning on transient single-token injections, we transform a 7B parameter model from near-complete failure (0.4% accuracy, 6.7% false positive rate) to reliable detection (85% accuracy on held-out concepts at α=40, 0% false positives). Our model detects fleeting "thoughts" injected at a single token position, retains that information, and reports the semantic content across subsequent generation steps. On this task, our trained model satisfies three of Lindsey's criteria: accuracy (correct identification), grounding (0/60 false positives), and internality (detection precedes verbalization). Generalization to unseen concept vectors (7.5pp gap) demonstrates the model learns a transferable skill rather than memorizing specific vectors, though this does not establish metacognitive representation in Lindsey's sense. These results address an open question raised by Lindsey: whether "training for introspection would help eliminate cross-model differences." We show that at least one component of introspective behavior can be directly induced, offering a pathway to built-in AI transparency.

</details>


### [51] [Can LLMs extract human-like fine-grained evidence for evidence-based fact-checking?](https://arxiv.org/abs/2511.21401)
*Antonín Jarolím,Martin Fajčík,Lucia Makaiová*

Main category: cs.CL

TL;DR: 本文针对捷克语和斯洛伐克语评论的精细化证据提取任务，构建了新数据集，并评估了多种大语言模型（LLM）的表现。


<details>
  <summary>Details</summary>
Motivation: 用户评论常传播虚假信息，目前缺乏高效方法判别评论信息的真伪，尤其是自动提取支持或反驳评论的文本证据。本文关注捷克语、斯洛伐克语场景，提升精准证据自动化提取能力。

Method: 1. 新建包含细粒度证据的双向人工标注数据集；2. 使用此数据集评估多种LLM在精确复制和提取证据上的准确率及与人工标注的一致性；3. 统计分析不同模型的输出错误率。

Result: 结果显示，大模型不一定比小模型表现更优；llama3.1:8b模型在证据提取上表现突出，gpt-oss-120b则效果不佳。模型如qwen3:14b、deepseek-r1:32b、gpt-oss:20b在体积和性能间达成良好平衡。

Conclusion: 部分中小型模型在证据提取与人工标注的一致性方面表现优秀，大模型未必效果最佳。某些大模型（如gpt-oss-120b）表现不佳，而部分体积较小的模型（如llama3.1:8b）表现出高正确率。

Abstract: Misinformation frequently spreads in user comments under online news articles, highlighting the need for effective methods to detect factually incorrect information. To strongly support or refute claims extracted from such comments, it is necessary to identify relevant documents and pinpoint the exact text spans that justify or contradict each claim. This paper focuses on the latter task -- fine-grained evidence extraction for Czech and Slovak claims. We create new dataset, containing two-way annotated fine-grained evidence created by paid annotators. We evaluate large language models (LLMs) on this dataset to assess their alignment with human annotations. The results reveal that LLMs often fail to copy evidence verbatim from the source text, leading to invalid outputs. Error-rate analysis shows that the {llama3.1:8b model achieves a high proportion of correct outputs despite its relatively small size, while the gpt-oss-120b model underperforms despite having many more parameters. Furthermore, the models qwen3:14b, deepseek-r1:32b, and gpt-oss:20b demonstrate an effective balance between model size and alignment with human annotations.

</details>


### [52] [Text-to-SQL as Dual-State Reasoning: Integrating Adaptive Context and Progressive Generation](https://arxiv.org/abs/2511.21402)
*Zhifeng Hao,Qibin Song,Ruichu Cai,Boyan Xu*

Main category: cs.CL

TL;DR: 针对大型企业数据库，DSR-SQL通过双状态推理提升Text-to-SQL模型推理性和执行准确率，无需额外训练即可获得竞争性结果。


<details>
  <summary>Details</summary>
Motivation: 现有CoT等分治式推理方法在处理复杂企业数据库时，由于上下文容量、小样本数据库链接和语义基础弱等问题，难以输出合理的SQL。因此需要更具语义扎根和自我优化能力的方法。

Method: DSR-SQL框架包括：1）通过自适应上下文状态对庞大数据库schema进行精炼及相关结构选择，2）采用递进生成状态，根据反馈动态调整SQL生成过程，从而自我纠正并对齐用户意图。

Result: 本文提出了一种名为DSR-SQL的双状态推理框架，用于提升大型语言模型在Text-to-SQL任务中的表现。DSR-SQL通过两个状态：自适应上下文状态优化数据库schema表示以提升语义相关性，递进生成状态则通过反馈式状态转移指导SQL合成和自我纠错。该方法在无需额外训练或上下文示例的情况下，于Spider 2.0-Snow和BIRD数据集上达到了较高的执行准确率。

Conclusion: DSR-SQL显著缓解了大模型在复杂数据库场景中的推理和语义扎根难题，提升了Text-to-SQL的准确率和鲁棒性，为实际应用提供了更强支持。

Abstract: Recent divide-and-conquer reasoning approaches, particularly those based on Chain-of-Thought (CoT), have substantially improved the Text-to-SQL capabilities of Large Language Models (LLMs). However, when applied to complex enterprise databases, such methods struggle to maintain coherent reasoning due to limited context capacity, unreliable schema linking, and weak grounding in database semantics. To overcome these issues, we introduce DSR-SQL, a \textbf{D}ual-\textbf{S}tate \textbf{R}easoning framework that models Text-to-SQL as an interaction between an adaptive context state and a progressive generation state. The first constructs a compact, semantically faithful environment by refining large schemas and selecting relevant structures, while the second formalizes SQL synthesis as feedback-guided state transitions, enabling the model to self-correct and align with user intent. Without any post-training or in-context examples, DSR-SQL achieves competitive performance, reaching 35.28\% execution accuracy on Spider 2.0-Snow and 68.32\% on BIRD development set. Our implementation will be open-sourced at: https://github.com/DMIRLAB-Group/DSR-SQL.

</details>


### [53] [Odin: Oriented Dual-module Integration for Text-rich Network Representation Learning](https://arxiv.org/abs/2511.21416)
*Kaifeng Hong,Yinglong Zhang,Xiaoying Hong,Xuewen Xia,Xing Xu*

Main category: cs.CL

TL;DR: Odin是一种创新模型，将结构信息直接注入Transformer层，突破GNN与纯Transformer的局限，提升了文本属性图的理解能力。其轻量版本还能大大加快训练与推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有文本属性图（text-attributed graphs）方法要么依赖GNN，受限于过平滑和多跳扩散问题；要么采用Transformer，但忽视图结构、将节点视为孤立序列。如何融合文本理解与结构推理，且兼顾性能和效率，是待解决的难题。

Method: Odin（Oriented Dual-module INtegration）在Transformer的特定层次引入图结构，通过双模块机制进行结构信息注入，形成低、中、高层次的结构抽象，而不是传统的GNN消息传递或多跳扩散。同时，结合全局[CLS]聚合方式避免过平滑；并提出轻量化版本Light Odin，以适用于大规模或低资源环境。

Result: Odin在多个文本丰富图基准上获得了最新的准确率，轻量版Light Odin则能以显著降低计算成本的情形下达到有竞争力的表现。

Conclusion: Odin与Light Odin共同构建了一个无跳（hop-free）、高效、统一的结构-文本融合框架，优于纯GNN或Transformer模型，并已开源，便于实际应用。

Abstract: Text-attributed graphs require models to effectively combine strong textual understanding with structurally informed reasoning. Existing approaches either rely on GNNs--limited by over-smoothing and hop-dependent diffusion--or employ Transformers that overlook graph topology and treat nodes as isolated sequences. We propose Odin (Oriented Dual-module INtegration), a new architecture that injects graph structure into Transformers at selected depths through an oriented dual-module mechanism.Unlike message-passing GNNs, Odin does not rely on multi-hop diffusion; instead, multi-hop structures are integrated at specific Transformer layers, yielding low-, mid-, and high-level structural abstraction aligned with the model's semantic hierarchy. Because aggregation operates on the global [CLS] representation, Odin fundamentally avoids over-smoothing and decouples structural abstraction from neighborhood size or graph topology. We further establish that Odin's expressive power strictly contains that of both pure Transformers and GNNs.To make the design efficient in large-scale or low-resource settings, we introduce Light Odin, a lightweight variant that preserves the same layer-aligned structural abstraction for faster training and inference. Experiments on multiple text-rich graph benchmarks show that Odin achieves state-of-the-art accuracy, while Light Odin delivers competitive performance with significantly reduced computational cost. Together, Odin and Light Odin form a unified, hop-free framework for principled structure-text integration. The source code of this model has been released at https://github.com/hongkaifeng/Odin.

</details>


### [54] [A Systematic Study of Model Merging Techniques in Large Language Models](https://arxiv.org/abs/2511.21437)
*Oğuz Kağan Hitit,Leander Girrbach,Zeynep Akata*

Main category: cs.CL

TL;DR: 当前模型融合方法大多无法适用于现代大语言模型，仅有Task Arithmetic能稳定提升性能，这凸显了开发专门针对LLM的融合算法和微调方法的必要性。


<details>
  <summary>Details</summary>
Motivation: 模型融合在无需额外训练的前提下，将多个微调模型合并为一个，能够高效提升性能，且便于模型复用。然而，目前尚不清楚这种方法在大语言模型（LLM）上的适用性，以及此前在小模型和分类器上报告的优势能否推广到LLM。

Method: 大规模、系统化地评估了六种主流融合方法，在多个LLM及其微调模型上，使用标准化基准任务对融合效果进行对比分析，考察了融合模型超越基础模型及最佳单一检查点的概率和性能提升幅度。

Result: 系统评测了六种最先进的融合方法，包括最近的子空间方法，在四个开源LLM、每个基础模型十二个微调检查点、十六个标准LLM基准任务上。结果发现，最古老且最简单的Task Arithmetic方法是唯一在LLM上能稳定带来性能提升的方法。而其他考虑干扰或子空间的融合方法通常会导致性能显著下降。

Conclusion: 现有模型融合技术不能直接迁移到现代LLM，亟需设计LLM专用的模型融合算法及融合感知型微调方法。

Abstract: Model merging combines multiple fine-tuned checkpoints into a single model without additional training, offering an attractive approach to reusing models and efficiently improving performance. However, it remains unclear whether the advantages reported for smaller models and classifiers generalize to LLMs. We present a large-scale, systematic evaluation of six state-of-the-art merging methods, including recent subspace methods, across four open-weight LLMs, twelve fine-tuned checkpoints per base model, and sixteen standard LLM benchmarks. Evaluating through standardized benchmarks, we measure both the probability that a merged model outperforms the base model and relative gains over the best individual checkpoint. Our results show that the oldest and simplest method, Task Arithmetic, is the only approach that reliably yields performance gains on LLMs. Other interference-aware and subspace merging methods typically result in significant performance drops. Our findings indicate that current merging techniques do not directly transfer to modern LLMs. This motivates the design of LLM-specific merging algorithms and merging-aware fine-tuning methods. Code will be released upon acceptance of this paper.

</details>


### [55] [Hierarchical Ranking Neural Network for Long Document Readability Assessment](https://arxiv.org/abs/2511.21473)
*Yurui Zheng,Yijun Chen,Shaohong Zhang*

Main category: cs.CL

TL;DR: 本论文提出了一种新的可读性评估机制，能够更好地预测文本的阅读难度，并且在中文和英文数据集上表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在文本可读性评估中未能充分考虑文本长度和可读性标签的序关系，影响评估准确性。

Method: 采用双向机制捕获上下文信息，识别语义丰富区域，对句子级进行可读性预测，并借助句子级标签辅助整体文档级的可读性判断；同时引入配对排序算法，通过标签差建模可读性等级的序关系。

Result: 在中文和英文可读性数据集上的实验结果表明，所提出模型性能优越，显著优于各类基线方法。

Conclusion: 该模型有效结合了句子级和文档级的可读性判断，并通过排序算法建模标签的序关系，在多个数据集上超越了现有方法。

Abstract: Readability assessment aims to evaluate the reading difficulty of a text. In recent years, while deep learning technology has been gradually applied to readability assessment, most approaches fail to consider either the length of the text or the ordinal relationship of readability labels. This paper proposes a bidirectional readability assessment mechanism that captures contextual information to identify regions with rich semantic information in the text, thereby predicting the readability level of individual sentences. These sentence-level labels are then used to assist in predicting the overall readability level of the document. Additionally, a pairwise sorting algorithm is introduced to model the ordinal relationship between readability levels through label subtraction. Experimental results on Chinese and English datasets demonstrate that the proposed model achieves competitive performance and outperforms other baseline models.

</details>


### [56] [Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation](https://arxiv.org/abs/2511.21517)
*Lina Conti,Dennis Fucci,Marco Gaido,Matteo Negri,Guillaume Wisniewski,Luisa Bentivogli*

Main category: cs.CL

TL;DR: 本文分析了语音翻译系统在将英语翻译为西班牙语、法语和意大利语时，如何基于说话者的声音特征进行性别分配，揭示了模型不仅仅依赖训练数据中的性别关联，还受到语音特征的影响。


<details>
  <summary>Details</summary>
Motivation: 由于语音传递性别信息，语音翻译中会存在将说话者误性别化的风险，尤其在某些目标语言须强制分配性别时，声学特征可能影响性别分配，相关机制尚未充分被理解。

Method: 研究采用了对比性特征归因方法分析语谱图，通过考察训练数据模式、语言模型内部偏见和声音信息的交互，深入理解性别分配机制。

Result: 发现模型不仅复制训练数据中的特定性别关联，还学习更广泛的阳性优先模式。虽然语言模型本身有明显的阳性偏见，但融合语音信息后可以修正此偏好。

Conclusion: 具备更高性别准确性的模型会通过第一人称代词将带性别术语与说话者关联，并利用分布在整个频谱的性别信息，而不仅仅依赖于音高。

Abstract: Unlike text, speech conveys information about the speaker, such as gender, through acoustic cues like pitch. This gives rise to modality-specific bias concerns. For example, in speech translation (ST), when translating from languages with notional gender, such as English, into languages where gender-ambiguous terms referring to the speaker are assigned grammatical gender, the speaker's vocal characteristics may play a role in gender assignment. This risks misgendering speakers, whether through masculine defaults or vocal-based assumptions. Yet, how ST models make these decisions remains poorly understood. We investigate the mechanisms ST models use to assign gender to speaker-referring terms across three language pairs (en-es/fr/it), examining how training data patterns, internal language model (ILM) biases, and acoustic information interact. We find that models do not simply replicate term-specific gender associations from training data, but learn broader patterns of masculine prevalence. While the ILM exhibits strong masculine bias, models can override these preferences based on acoustic input. Using contrastive feature attribution on spectrograms, we reveal that the model with higher gender accuracy relies on a previously unknown mechanism: using first-person pronouns to link gendered terms back to the speaker, accessing gender information distributed across the frequency spectrum rather than concentrated in pitch.

</details>


### [57] [Bangla Sign Language Translation: Dataset Creation Challenges, Benchmarking and Prospects](https://arxiv.org/abs/2511.21533)
*Husne Ara Rubaiyeat,Hasan Mahmud,Md Kamrul Hasan*

Main category: cs.CL

TL;DR: 孟加拉语手语翻译因资源匮乏发展缓慢。本文构建并公开了新的句子级数据集及其子集，为相关AI应用和研究提供了重要资源。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语手语翻译长期受限，主要原因是缺乏相关资源。为推动面向孟加拉语社区听障人士的AI辅助工具开发，标准化句子级数据集的建立变得尤为重要。

Method: 构建数据集，分析数据集开发挑战，采用landmark和RQE嵌入方法进行基准测试，开展词汇消融和规范化实验，公开所有数据集供研究使用。

Result: 本文发布了IsharaKhobor数据集及其两个子集，该数据集旨在推动孟加拉语手语翻译研究。作者公开了数据集，并通过词汇限制和规范化进行了消融实验，生成了两个额外的数据集。还以landmark和RQE嵌入进行了基准测试。

Conclusion: IsharaKhobor及其子集数据集的发布，为孟加拉语手语翻译及相关辅助工具开发打下了基础，并指明了未来研究方向。

Abstract: Bangla Sign Language Translation (BdSLT) has been severely constrained so far as the language itself is very low resource. Standard sentence level dataset creation for BdSLT is of immense importance for developing AI based assistive tools for deaf and hard of hearing people of Bangla speaking community. In this paper, we present a dataset, IsharaKhobor , and two subset of it for enabling research. We also present the challenges towards developing the dataset and present some way forward by benchmarking with landmark based raw and RQE embedding. We do some ablation on vocabulary restriction and canonicalization of the same within the dataset, which resulted in two more datasets, IsharaKhobor_small and IsharaKhobor_canonical_small. The dataset is publicly available at: www.kaggle.com/datasets/hasanssl/isharakhobor [1].

</details>


### [58] [RoParQ: Paraphrase-Aware Alignment of Large Language Models Towards Robustness to Paraphrased Questions](https://arxiv.org/abs/2511.21568)
*Minjoon Choi*

Main category: cs.CL

TL;DR: 通过RoParQ基准和机制创新，提高了LLM在不同表达方式下的鲁棒性和一致性，特别让轻量模型表现显著提升，缓解了只记忆表层问题的缺陷。


<details>
  <summary>Details</summary>
Motivation: LLM在处理语义接近但表达不同的问题时表现出行为不一致，这说明其未达到真正的语义理解，亟需提升模型在“语义不变性”和鲁棒性上的能力。

Method: - 构建RoParQ基准，通过专有模型生成问题复述，并筛选出能引起模型信心不一致的问题。
- 提出XParaCon指标，用标准差衡量不同表述下模型准确率的波动。
- 采用复述感知的推理型有监督微调方法，训练模型提升语义不变性。

Result: 本文提出了RoParQ基准，用于评估大语言模型（LLMs）在回答复述（paraphrase）问题时的一致性，并提出了XParaCon评价指标用于量化模型在不同问题变体上的鲁棒性。同时，作者设计了融合问题复述的推理能力的有监督微调（SFT）方法，显著提升了小型模型的一致性，与大型预训练模型相当。

Conclusion: 融合复述推理微调策略能有效提升模型在不同问题变体上的一致性和鲁棒性，轻量模型的效果大幅提高，表现可与大型模型媲美。

Abstract: Large Language Models (LLMs) often exhibit inconsistent behavior when answering paraphrased questions, suggesting a reliance on surface-level patterns rather than true semantic understanding. To address this limitation, we introduce RoParQ, a benchmark specifically constructed to evaluate cross-paraphrase consistency in closed-book multiple-choice QA. This benchmark is derived from standard datasets by generating paraphrases via proprietary models and selectively retaining examples that elicit inconsistent confidence from a judge model. We further propose XParaCon, a novel evaluation metric that quantifies a model's robustness by measuring the standard deviation of accuracies across question variants. Additionally, we implement a reasoning-based, paraphrase-aware Supervised Fine-Tuning (SFT) strategy designed to align models toward semantic invariance. Our experiments demonstrate that this targeted alignment significantly enhances robustness. Notably, fine-tuned lightweight models achieved consistency levels comparable to much larger pre-trained models. These results highlight the efficacy of our approach in mitigating superficial memorization and fostering more robust, reliable LLMs.

</details>


### [59] [Auxiliary Metrics Help Decoding Skill Neurons in the Wild](https://arxiv.org/abs/2511.21610)
*Yixiu Zhao,Xiaozhi Wang,Zijun Yao,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: 该文提出了一种无需手工聚合的新方法，通过神经元激活与外部或内部指标的相关性来识别和解释大模型内部技能神经元，在多种复杂任务上验证了其实用性和科学意义。


<details>
  <summary>Details</summary>
Motivation: 大语言模型尽管在多种任务中表现出色，但其内部机制不透明。鉴于现有方法多局限于分类任务，且难以扩展到复杂多技能场景，需一种更通用、自动化的解释性分析方法。

Method: 提出一种简单轻量、适用范围广的方法，通过分析神经元激活与辅助指标（如外部标签、模型置信度）之间的相关性，隔离出编码特定技能的神经元。相比于以往依靠软提示训练找到“技能神经元”的方法，本方法可应用于包含多技能的复杂任务，并不需要手工聚合token。

Result: 在开放文本生成和自然语言推理等任务上实验证明，该方法不仅能检测出驱动已知技能的神经元，还能发现模型在BigBench算术推理等任务上的潜在“捷径”。

Conclusion: 该方法为解析大语言模型内部机制提供了便捷工具，有助于进一步理解和调控模型在实际任务中的表现。

Abstract: Large language models (LLMs) exhibit remarkable capabilities across a wide range of tasks, yet their internal mechanisms remain largely opaque. In this paper, we introduce a simple, lightweight, and broadly applicable method with a focus on isolating neurons that encode specific skills. Building upon prior work that identified "skill neurons" via soft prompt training on classification tasks, our approach extends the analysis to complex scenarios involving multiple skills. We correlate neuron activations with auxiliary metrics -- such as external labels and the model's own confidence score -- thereby uncovering interpretable and task-specific behaviors without the need for manual token aggregation. We empirically validate our method on tasks spanning open-ended text generation and natural language inference, demonstrating its ability to detect neurons that not only drive known skills but also reveal previously unidentified shortcuts in arithmetic reasoning on BigBench.

</details>


### [60] [Beyond URLs: Metadata Diversity and Position for Efficient LLM Pretraining](https://arxiv.org/abs/2511.21613)
*Dongyang Fan,Diba Hashemi,Sai Praneeth Karimireddy,Martin Jaggi*

Main category: cs.CL

TL;DR: 研究发现，不止URL，许多细粒度、能反映文档质量的元数据能有效加速LLM预训练。提出元数据附加和可学习元标记等方式，能进一步提升训练效率，并分析了其机理，给出实用集成建议。


<details>
  <summary>Details</summary>
Motivation: 此前相关研究仅证明了URL元数据有助于加速预训练，但尚未揭示其他类型元数据的作用。本文旨在探索更多元数据类型，验证其能否带来更大加速效益，并提供实用指导。

Method: 探究多种类型元数据在大型语言模型（LLM）预训练中的影响，包括元数据前置、元数据附加、使用可学习元标记，通过辅助任务和掩码损失促进训练效率。利用探查方法分析潜在表示。

Result: 细粒度、高质量的元数据同样能够有效提升预训练效率。通过使用元数据附加和可学习元标记等方法，可以进一步加速学习过程。实验用探查分析了元数据如何塑造模型潜在表示。

Conclusion: 有效整合细粒度和高质量元数据密切相关的机制，可以显著提升大型语言模型预训练的速度和表现，并为实际应用提供具体方法和指导。

Abstract: Incorporating metadata in Large Language Models (LLMs) pretraining has recently emerged as a promising approach to accelerate training. However prior work highlighted only one useful signal-URLs, leaving open the question of whether other forms of metadata could yield greater benefits. In this study, we investigate a wider range of metadata types and find other types of metadata, such as fine-grained indicators of document quality that can also accelerate pretraining when prepended. We identify a common feature among effective metadata: they encode information at a finer granularity. We further introduce metadata appending as a means of improving training efficiency, where predicting an appropriate metadata as auxiliary task can help speed up pretraining. In addition, learnable meta-tokens trained with masked loss can recover part of the speedup by inducing quality-aware latent structure. Using probing, we analyze latent representations to understand how metadata shapes learning. Together, these results yield practical guidelines for integrating metadata to improve both the efficiency and effectiveness of LLM pretraining.

</details>


### [61] [The author is dead, but what if they never lived? A reception experiment on Czech AI- and human-authored poetry](https://arxiv.org/abs/2511.21629)
*Anna Marklová,Ondřej Vinš,Martina Vokáčová,Jiří Milička*

Main category: cs.CL

TL;DR: AI能创作与人类难以区分的捷克语诗歌，被认为是AI创作时评价更低，实际评价相当甚至更好。作者归属感影响美学评价，对识别无帮助。


<details>
  <summary>Details</summary>
Motivation: 现有AI诗歌研究多聚焦于英语，忽略较少见且形态复杂的语言（如捷克语）；旨在考察AI诗歌在低资源语言中的表现及其被人类识别和评价的情况。

Method: 通过让捷克语母语者辨认AI创作与人类创作的诗歌，并对诗歌进行美学评价，同时采用逻辑回归分析影响要素。

Result: 参与者对诗歌作者的辨认接近随机（正确率45.8%），表明AI生成的捷克语诗歌与人类作品难以区分。同时存在强烈的作者偏见：如果认为诗歌是AI创作，评价会较低，但实际上AI诗歌总体评价与人类诗歌持平甚至更高。喜欢某首诗越多，判断作者准确率反而越低；文学背景对辨认准确率无影响。

Conclusion: AI在复杂、资源有限的语言中同样能够创作高质量诗歌。读者对作者身份的主观判断影响对诗歌的美学评估，但识别作者和文学背景关系不大。

Abstract: Large language models are increasingly capable of producing creative texts, yet most studies on AI-generated poetry focus on English -- a language that dominates training data. In this paper, we examine the perception of AI- and human-written Czech poetry. We ask if Czech native speakers are able to identify it and how they aesthetically judge it. Participants performed at chance level when guessing authorship (45.8\% correct on average), indicating that Czech AI-generated poems were largely indistinguishable from human-written ones. Aesthetic evaluations revealed a strong authorship bias: when participants believed a poem was AI-generated, they rated it as less favorably, even though AI poems were in fact rated equally or more favorably than human ones on average. The logistic regression model uncovered that the more the people liked a poem, the less probable was that they accurately assign the authorship. Familiarity with poetry or literary background had no effect on recognition accuracy. Our findings show that AI can convincingly produce poetry even in a morphologically complex, low-resource (with respect of the training data of AI models) Slavic language such as Czech. The results suggest that readers' beliefs about authorship and the aesthetic evaluation of the poem are interconnected.

</details>


### [62] [Matrix: Peer-to-Peer Multi-Agent Synthetic Data Generation Framework](https://arxiv.org/abs/2511.21686)
*Dong Wang,Yang Li,Ansong Ni,Ching-Feng Yeh,Youssef Emad,Xinjie Lei,Liam Robbins,Karthik Padthe,Hu Xu,Xian Li,Asli Celikyilmaz,Ramya Raghavendra,Lifei Huang,Carole-Jean Wu,Shang-Wen Li*

Main category: cs.CL

TL;DR: Matrix是一个无中心点的多智能体数据合成框架，利用点对点消息队列和分布式服务，在多任务场景中，在不降低数据质量的前提下，实现了2到15倍的数据生成效率提升。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体合成框架依赖中心协调器，导致扩展性受限，或为特定领域而设计，缺乏灵活性。合成高质量、多样性和结构丰富的数据尤其需要更高效和灵活的多智能体协作方案，且在真实数据稀缺或敏感时，合成数据需求显著提升。

Method: 本文提出了Matrix，一个去中心化的多智能体合成数据框架。Matrix 将控制流和数据流以序列化消息形式通过分布式队列传递，实现点对点（P2P）设计，消除中心协调器。任务由轻量级代理独立推进，计算密集型子任务则由分布式服务（如LLM推断或容器环境）处理。系统基于Ray，实现高并发和模块化、可配置设计，可灵活适应各种数据生成流程。

Result: Matrix 在多种合成场景下（如多智能体对话、网络推理数据提取、客户服务工具轨迹生成）进行评估。实验显示，在相同硬件资源条件下，Matrix 的数据生成吞吐量达2至15倍提升，且不影响输出质量。

Conclusion: Matrix 框架通过去中心化设计，有效提升了多智能体数据合成的扩展性和灵活性，显著加快了生成效率，适用于多种数据生成任务场景。

Abstract: Synthetic data has become increasingly important for training large language models, especially when real data is scarce, expensive, or privacy-sensitive. Many such generation tasks require coordinated multi-agent workflows, where specialized agents collaborate to produce data that is higher quality, more diverse, and structurally richer. However, existing frameworks for multi-agent synthesis often depend on a centralized orchestrator, creating scalability bottlenecks, or are hardcoded for specific domains, limiting flexibility. We present \textbf{Matrix}, a decentralized framework that represents both control and data flow as serialized messages passed through distributed queues. This peer-to-peer design eliminates the central orchestrator. Each task progresses independently through lightweight agents, while compute-intensive operations, such as LLM inference or containerized environments, are handled by distributed services. Built on Ray, Matrix scales to tens of thousands of concurrent agentic workflows and provides a modular, configurable design that enables easy adaptation to a wide range of data generation workflows. We evaluate Matrix across diverse synthesis scenarios, such as multi-agent collaborative dialogue, web-based reasoning data extraction, and tool-use trajectory generation in customer service environments. In all cases, Matrix achieves $2$--$15\times$ higher data generation throughput under identical hardware resources, without compromising output quality.

</details>


### [63] [ToolOrchestra: Elevating Intelligence via Efficient Model and Tool Orchestration](https://arxiv.org/abs/2511.21689)
*Hongjin Su,Shizhe Diao,Ximing Lu,Mingjie Liu,Jiacheng Xu,Xin Dong,Yonggan Fu,Peter Belcak,Hanrong Ye,Hongxu Yin,Yi Dong,Evelina Bakhturina,Tao Yu,Yejin Choi,Jan Kautz,Pavlo Molchanov*

Main category: cs.CL

TL;DR: 小型调度器ToolOrchestra协调多工具，比大模型更有效、成本更低地解决复杂问题，在多项任务中优于GPT-5，展现了实用可扩展性。


<details>
  <summary>Details</summary>
Motivation: 大模型虽然强大，但解决复杂问题（如Humanity's Last Exam, HLE）既具挑战又开销高。因此希望借助小型调度器管理不同模型和工具，提高智能上限和效率。

Method: 提出ToolOrchestra方法，训练小型调度器（orchestrators）协调智能工具，显式采用基于结果、效率和用户偏好奖励的强化学习；以此训练出8B参数的Orchestrator模型。

Result: Orchestrator在HLE上取得37.1%分数，优于GPT-5（35.1%），效率高2.5倍；在tau2-Bench和FRAMES上也以约30%的成本大幅超过GPT-5。分析显示其性能与成本之间权衡最佳，且可对新工具较好泛化。

Conclusion: 用轻量调度模型编排多样工具，比现有方法更高效且更有效，有望实现高效可扩展的工具增强推理系统。

Abstract: Large language models are powerful generalists, yet solving deep and complex problems such as those of the Humanity's Last Exam (HLE) remains both conceptually challenging and computationally expensive. We show that small orchestrators managing other models and a variety of tools can both push the upper bound of intelligence and improve efficiency in solving difficult agentic tasks. We introduce ToolOrchestra, a method for training small orchestrators that coordinate intelligent tools. ToolOrchestra explicitly uses reinforcement learning with outcome-, efficiency-, and user-preference-aware rewards. Using ToolOrchestra, we produce Orchestrator, an 8B model that achieves higher accuracy at lower cost than previous tool-use agents while aligning with user preferences on which tools are to be used for a given query. On HLE, Orchestrator achieves a score of 37.1%, outperforming GPT-5 (35.1%) while being 2.5x more efficient. On tau2-Bench and FRAMES, Orchestrator surpasses GPT-5 by a wide margin while using only about 30% of the cost. Extensive analysis shows that Orchestrator achieves the best trade-off between performance and cost under multiple metrics, and generalizes robustly to unseen tools. These results demonstrate that composing diverse tools with a lightweight orchestration model is both more efficient and more effective than existing methods, paving the way for practical and scalable tool-augmented reasoning systems.

</details>


### [64] [Revisiting Generalization Across Difficulty Levels: It's Not So Easy](https://arxiv.org/abs/2511.21692)
*Yeganeh Kordi,Nihal V. Nayak,Max Zuo,Ilana Nguyen,Stephen H. Bach*

Main category: cs.CL

TL;DR: 单独依赖易或难样例进行训练，不能让大模型在所有难度层面都表现优异，模型数据需涵盖各类难度以保障泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究对训练易或难数据的效果结论不一，特别是在针对不同难度测试数据时效果尚不清楚，需要系统性方法客观评估难度影响，以指导数据筛选和模型训练。

Method: 通过采集数千个不同大模型在六个公开任务上的输出，结合项目反应理论（IRT），客观打分各样例难度，并分析模型在不同难度上的表现和泛化能力。

Result: 通过在六个数据集上，利用数千个大模型的输出和项目反应理论（IRT）来衡量样例难度，系统性地评估了大语言模型在不同任务难度上的泛化能力。结果发现，无论是训练数据选用简单样例还是难样例，都无法在全部难度范围内取得一致提升，跨难度泛化效果有限。

Conclusion: 训练和评估过程中，必须包含不同难度的样本，否则模型泛化能力受限，不能通过“难度快捷方式”提升性能。

Abstract: We investigate how well large language models (LLMs) generalize across different task difficulties, a key question for effective data curation and evaluation. Existing research is mixed regarding whether training on easier or harder data leads to better results, and whether those gains come on easier or harder test data. We address this question by conducting a systematic evaluation of LLMs' generalization across models, datasets, and fine-grained groups of example difficulty. We rank examples in six datasets using the outputs of thousands of different LLMs and Item Response Theory (IRT), a well-established difficulty metric in educational testing. Unlike prior work, our difficulty ratings are therefore determined solely by the abilities of many different LLMs, excluding human opinions of difficulty. With a more objective, larger-scale, and finer-grained analysis, we show that cross-difficulty generalization is often limited; training on either easy or hard data cannot achieve consistent improvements across the full range of difficulties. These results show the importance of having a range of difficulties in both training and evaluation data for LLMs, and that taking shortcuts with respect to difficulty is risky.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [65] [Local generation of languages](https://arxiv.org/abs/2511.21226)
*Mathieu Hoyrup*

Main category: cs.DM

TL;DR: 本文通过单纯形复框架，量化和建模字符串生成过程中各位置之间的通信需求，并理论分析哪些通信结构可以生成特定语言。


<details>
  <summary>Details</summary>
Motivation: 在处理字符串集合（语言）时，每个位置都有自己的局部规则，如何确定各位置间需要多少通信，以生成指定语言是一个有趣的问题。本文旨在建立一种度量各位置之间通信需求的方法，从而分析语言生成过程中的通信结构。

Method: 首先将语言抽象为定长字符串集合，然后构建每个字符串位置的局部生成规则。以单纯形复表示各位置间的通信关系，理论分析哪些单纯形复可实现目标语言的生成，并通过实际语言案例进行应用检验。

Result: 提出了一个用单纯形复（simplicial complex）来建模字符串各位置之间通信关系的框架，将每个位置作为顶点、通信通道作为单纯形，并分析了哪些单纯形复能够生成给定的语言。该理论已在多个不同语言示例上获得应用验证。

Conclusion: 通过建立通信结构与单纯形复的对应关系，本文实现了对语言生成机制的理论分析。结果表明，能够生成语言的通信结构具有一定特征，为理解分布式生成过程中的通信复杂性提供新视角。

Abstract: Given a language, which in this article is a set of strings of some fixed length, we study the problem of producing its elements by a procedure in which each position has its own local rule. We introduce a way of measuring how much communication is needed between positions. The communication structure is captured by a simplicial complex whose vertices are the positions and the simplices are the communication channels between positions. The main problem is then to identify the simplicial complexes that can be used to generate a given language. We develop the theory and apply it to a number of languages.

</details>


### [66] [$k$-path graphs: experiments and conjectures about algebraic connectivity and $α$-index](https://arxiv.org/abs/2511.21524)
*Rafael L. de Paula,Claudia M. Justel,Carla S. Oliveira,Milena S. Carauba*

Main category: cs.DM

TL;DR: 论文通过构造和枚举k-路径图，实证探索了与代数连通性和α-指数相关的极值问题，并据此提出了新的图结构猜想。


<details>
  <summary>Details</summary>
Motivation: 探索与k-路径图相关的矩阵的特征值，强调Laplacian矩阵的代数连通性和A_α矩阵的α-指数对研究图结构的重要性。发掘特征值极值图的结构规律。

Method: 采用Pereira等人的方法生成所有非同构2-路径、3-路径和4-路径图，并在指定阶数范围内进行详尽搜索，寻找在特征值指标下的极值图，进而提出结构猜想。

Result: 通过生成k-路径图列表并进行详尽遍历，获得了关于极值图结构的新实证数据，并据此提出了极值k-路径图相关特征值的结构猜想。

Conclusion: 根据实证结果，作者提出了极值k-路径图的结构猜想，为相关特征值的图结构研究提供了新的视角和方法。

Abstract: This work presents conjectures about eigenvalues of matrices associated with $k$-path graphs, the algebraic connectivity, defined as the second smallest eigenvalue of the Laplacian matrix, and the $α$-index, as the largest eigenvalue of the $A_α$-matrix. For this purpose, a process based in Pereira et al., is presented to generate lists of $k$-path graphs containing all non-isomorphic 2-paths, 3-paths, and 4-paths of order $n$, for $6 \leq n \leq 26, 8 \leq n \leq 19$, and $10 \leq n \leq 18$, respectively. Using these lists, exhaustive searches for extremal graphs of fixed order for the mentioned eigenvalues were performed. Based on the empirical results, conjectures are suggested about the structure of extremal $k$-path graphs for these eigenvalues.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [67] [General Decidability Results for Systems with Continuous Counters](https://arxiv.org/abs/2511.21559)
*A. R. Balasubramanian,Matthew Hague,Rupak Majumdar,Ramanathan S. Thinniyam,Georg Zetzsche*

Main category: cs.FL

TL;DR: 连续计数器的可达性问题可判定且能有效用有限自动机表示其指令序列，但自动机大小可能非常大。


<details>
  <summary>Details</summary>
Motivation: 离散计数器虽然广泛应用于系统建模和验证，但高复杂度成巨大障碍。希望找出有效的近似模型，兼具效率与理论可分析性，这推动了对连续计数器判定性的系统研究。

Method: 将离散计数器放宽为连续计数器（取非负有理数），分析目标配置可达的指令序列集合，通过形式化证明其正则性，并给出有限自动机的构造及其非初等下界。

Result: 本文的核心成果在于证明连续计数器在判定性（decidability）方面具有优越性。具体结果为：尽管连续计数器属于无限状态系统，但到达某个目标配置可接受的计数器指令序列组成的语言是正则的，并且可以有效地构造出相应的有限自动机。此外，还证明了所构造的有限自动机构造规模的非初等下界。

Conclusion: 连续计数器不仅能作为高效的离散计数器近似工具，而且其相关重要性质（如可达性）依然保持判定性和可构造性，适用于如高阶递归系统和可判定拓展离散计数系统等。

Abstract: Counters that hold natural numbers are ubiquitous in modeling and verifying software systems; for example, they model dynamic creation and use of resources in concurrent programs. Unfortunately, such discrete counters often lead to extremely high complexity. Continuous counters are an efficient over-approximation of discrete counters. They are obtained by relaxing the original counters to hold values over the non-negative rational numbers.
  This work shows that continuous counters are extraordinarily well-behaved in terms of decidability. Our main result is that, despite continuous counters being infinite-state, the language of sequences of counter instructions that can arrive in a given target configuration, is regular. Moreover, a finite automaton for this language can be computed effectively. This implies that a wide variety of transition systems can be equipped with continuous counters, while maintaining decidability of reachability properties. Examples include higher-order recursion schemes, well-structured transition systems, and decidable extensions of discrete counter systems.
  We also prove a non-elementary lower bound for the size of the resulting finite automaton.

</details>
