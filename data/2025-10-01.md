<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 3]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.CL](#cs.CL) [Total: 1]
- [cs.DM](#cs.DM) [Total: 1]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Black-box Context-free Grammar Inference for Readable & Natural Grammars](https://arxiv.org/abs/2509.26616)
*Mohammad Rifat Arefin,Shanto Rahman,Christoph Csallner*

Main category: cs.SE

TL;DR: NatGI是一种结合LLM的新型文法归纳方法，通过结构创新和智能命名，显著提高了准确率和文法可解释性，优于现有主流工具，并适用于包括C、lua等复杂语言。


<details>
  <summary>Details</summary>
Motivation: 现有的黑盒文法归纳工具在处理大规模复杂语言时，存在可扩展性、可读性和准确性不足的问题，影响程序分析、逆向工程及安全领域应用。

Method: NatGI结合三大创新：基于括号的bubble探索、LLM驱动的bubble生成与非终结符命名、分层Delta调试（HDD）用于系统化简化文法树。Bracket引导探索结合语法结构提示，LLM实现更有意义的非终结符命名和合并选择，HDD逐步删减冗余规则。

Result: NatGI平均F1分数为0.57，高出最佳对比基线TreeVada 25个百分点。生成文法在可解释性上也显著优于现有方法，结构更紧凑、命名更易懂、更贴近人类理解。

Conclusion: NatGI方法在F1分数和可解释性上都显著优于现有的黑盒上下文无关文法归纳工具，如Arvada、TreeVada和Kedavra。此外，生成的文法更紧凑易懂，更贴近人类直觉，方便开发者和研究者审查和理解。

Abstract: Black-box context-free grammar inference is crucial for program analysis,
reverse engineering, and security, yet existing tools such as Arvada, TreeVada,
and Kedavra struggle with scalability, readability, and accuracy on large,
complex languages. We present NatGI, a novel LLM-guided grammar inference
framework that extends TreeVada's parse tree recovery with three key
innovations: bracket-guided bubble exploration, LLM-driven bubble generation
and non-terminal labeling, and hierarchical delta debugging (HDD) for
systematic tree simplification. Bracket-guided exploration leverages syntactic
cues such as parentheses to propose well-structured grammar fragments, while
LLM guidance produces meaningful non-terminal names and selects more promising
merges. Finally, HDD incrementally reduces unnecessary rules, which makes the
grammars both compact and interpretable. In our experiments, we evaluate NatGI
on a comprehensive benchmark suite ranging from small languages to larger ones
such as lua, c, and mysql. Our results show that NatGI consistently outperforms
strong baselines in terms of F1 score. On average, NatGI achieves an F1 score
of 0.57, which is 25pp (percentage points) higher than the best-performing
baseline, TreeVada. In the case of interpretability, our generated grammars
perform significantly better than those produced by existing approaches.
Leveraging LLM-based node renaming and bubble exploration, NatGI produces rules
with meaningful non-terminal names and compact structures that align more
closely with human intuition. As a result, developers and researchers can
achieve higher accuracy while still being able to easily inspect, verify, and
reason about the structure and semantics of the induced grammars.

</details>


### [2] [WARP -- Web-Augmented Real-time Program Repairer: A Real-Time Compilation Error Resolution using LLMs and Web-Augmented Synthesis](https://arxiv.org/abs/2509.25192)
*Anderson de Lima Luiz*

Main category: cs.SE

TL;DR: WARP结合代码LLM与网络资源，能更高效修复编译错误，在实验中性能显著优于单一LLM方案和IDE工具。


<details>
  <summary>Details</summary>
Motivation: 编译错误严重影响软件开发效率，现有修复方法（单靠LLM或IDE快捷修复）效果有限，需结合实时网络资源提升修复能力。

Method: 该研究提出WARP系统，将微调的Code-LLM与动态检索网络资源（论坛、官方文档等）结合，对开发者编译错误进行解析、检索和代码修复，并进行实验验证。

Result: 在CGP基准测试上，WARP修复率达到72.5%（可正确编译），并实现更高的语义正确性，优于对比方案。

Conclusion: WARP系统能有效提高编译错误的修复率和语义正确性，优于仅依赖LLM的方案以及传统IDE修复方式。

Abstract: Compilation errors represent a significant bottleneck in software development
productivity. This paper introduces WARP (Web-Augmented Real-time Program
Repairer), a novel system that leverages Large Language Models (LLMs) and
dynamic web-augmented synthesis for real-time resolution of these errors. WARP
actively monitors developer terminals, intelligently detects compilation
errors, and synergistically combines the understanding of a fine-tuned Code-LLM
with relevant solutions, explanations, and code snippets retrieved from
up-to-date web sources like developer forums and official documentation.
Experimental results on our curated benchmark, CGP (featuring C/C++, Python,
and Go errors), demonstrate WARP achieves a superior fix rate (72.5 % Compiles
correctly) and higher semantic correctness compared to baseline LLM-only
approaches and traditional IDE quick-fixes. Key technical challenges in
achieving high-accuracy synthesis from noisy web data.

</details>


### [3] [APRIL: API Synthesis with Automatic Prompt Optimization and Reinforcement Learning](https://arxiv.org/abs/2509.25196)
*Hua Zhong,Shan Jiang,Sarfraz Khurshid*

Main category: cs.SE

TL;DR: APRIL通过提示优化和强化学习，显著提升了LLM驱动的API合成性能，是大规模库组件式API合成的高效方案。


<details>
  <summary>Details</summary>
Motivation: 生成新API时需要从庞大的库中组合组件，空间巨大且传统方法依赖人工规范和高昂探索成本，而LLM生成代码存在幻觉和上下文信息不足、准确性有限。

Method: 提出APRIL，将基于大语言模型的合成与自动化提示优化（APO）及基于可验证奖励的强化学习（RLVR）结合：APO自动优化冻结模型的提示，RLVR用功能正确性的奖励微调策略。

Result: 在81个科学Python库的真实API上评估，APRIL比基线未微调但由专家指定提示的LLM效果提升明显，证明方法高效并具备实际应用能力。

Conclusion: 结合APO和RLVR，为大型库中基于组件的API合成提供了强健、可扩展的解决方案，实现了准确性和效率的大幅提升。

Abstract: APIs are central to modern software development, yet composing new APIs from
large libraries is difficult due to the exponential search space; traditional
component-based synthesis relies on costly exploration and hand-crafted
specifications. While large language models (LLMs) can generate implementations
from natural language, hallucinations and limited access to up-to-date
contextual information often yield incorrect code. In this paper, we present
APRIL, an approach that combines LLM-based synthesis with Automatic Prompt
Optimization (APO) and Reinforcement Learning from Verifiable Rewards (RLVR):
APO iteratively refines prompts for a frozen model, while RLVR fine-tunes the
policy toward functional correctness, producing an efficient synthesis
pipeline. Evaluated on 81 real-world APIs from widely used scientific Python
libraries and benchmarked against instruction-tuned but unfine-tuned LLMs
guided by expert prompts, APRIL achieves substantial improvements. These
results indicate that integrating APO and RLVR provides a robust, scalable path
for component-based API synthesis in large libraries.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [4] [Monoid Structures on Indexed Containers](https://arxiv.org/abs/2509.25879)
*Michele De Pascalis,Tarmo Uustalu,Niccolò Veltrì*

Main category: cs.LO

TL;DR: 本文系统研究了I-索引容器的范畴及其单子结构，证明了幺半群与Set^I上的单子一一对应，并通过多个实例和Cubical Agda形式化展示其理论有效性。


<details>
  <summary>Details</summary>
Motivation: 容器理论及其推广（索引容器）在函数式和依赖类型编程，以及归纳和余归纳推理中非常重要。现有理论对如何在依赖类型背景下推广容器范畴结构和单子结构尚缺系统化研究。本文旨在填补该领域的空白，揭示二者之间的深层联系。

Method: 采用范畴论工具，定义和刻画了I-索引容器类别及其张量积，探讨了幺半群对象及其与幺半范畴（monad）的关系，并通过Cubical Agda对主要结果进行了形式化验证。

Result: 明确定义并刻画了I-索引容器的张量积结构、范畴中的幺半群对象，以及这些幺半群与Set^I上单子的对应关系。具体实例包括两个单子的积、索引化的状态单子、写者单子，以及自由单子的示例。所有结果均已用Cubical Agda形式化。

Conclusion: 本文得出了I-索引容器范畴中的幺半群与Set^I上的幺半群一一对应的结论（即幺半群对应于幺半范畴中的幺半体），并给出了若干相关单子（monad）的组合实例。

Abstract: Containers represent a wide class of type constructions relevant for
functional programming and (co)inductive reasoning. Indexed containers
generalize this notion to better fit the scope of dependently typed
programming. When interpreting types to be sets, a container describes an
endofunctor on the category of sets while an I-indexed container describes an
endofunctor on the category Set^I of I-indexed families of sets.
  We consider the monoidal structure on the category of I-indexed containers
whose tensor product of containers describes the composition of the respective
induced endofunctors. We then give a combinatorial characterization of monoids
in this monoidal category, and we show how these monoids correspond precisely
to monads on the induced endofunctors on Set^I. Lastly, we conclude by
presenting some examples of monads on Set^I that fall under our
characterization, including the product of two monads, indexed variants of the
state and the writer monads and an example of a free monad. The technical
results of this work are accompanied by a formalization in the proof assistant
Cubical Agda.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [5] [Cyclic Ablation: Testing Concept Localization against Functional Regeneration in AI](https://arxiv.org/abs/2509.25220)
*Eduard Kapelko*

Main category: cs.CL

TL;DR: 作者通过循环消融和对抗训练试图消除大语言模型中的欺骗行为，发现该行为高度顽固且无法被定点消除，且多次尝试后模型整体语言能力逐步减弱。这说明复杂行为是分布式且缠绕的，限制了直接通过机理可解释性方法编辑模型实现安全和可控。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型中的不良行为（如欺骗）是否可以通过直接定位并移除，探索模型安全性和可控性的可行性。

Method: 提出了“循环消融”方法：结合稀疏自动编码器、定向消融和对抗训练，在DistilGPT-2模型上针对“欺骗”概念进行多轮迭代消除实验。

Result: 每次消融后，模型通过对抗训练恢复出欺骗行为，导致语言能力整体下降（困惑度上升），表明欺骗行为难以被定向消除，模型性能受损。

Conclusion: 复杂概念（如欺骗）在大语言模型中的分布是分散且密切相关的，难以通过直接编辑模型来实现安全性和可控性。

Abstract: Safety and controllability are critical for large language models. A central
question is whether undesirable behaviors like deception are localized
functions that can be removed, or if they are deeply intertwined with a model's
core cognitive abilities. We introduce "cyclic ablation," an iterative method
to test this. By combining sparse autoencoders, targeted ablation, and
adversarial training on DistilGPT-2, we attempted to eliminate the concept of
deception. We found that, contrary to the localization hypothesis, deception
was highly resilient. The model consistently recovered its deceptive behavior
after each ablation cycle via adversarial training, a process we term
functional regeneration. Crucially, every attempt at this "neurosurgery" caused
a gradual but measurable decay in general linguistic performance, reflected by
a consistent rise in perplexity. These findings are consistent with the view
that complex concepts are distributed and entangled, underscoring the
limitations of direct model editing through mechanistic interpretability.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [6] [Well-Quasi-Ordering Eulerian Digraphs Embeddable in Surfaces by Strong Immersion](https://arxiv.org/abs/2509.26260)
*Dario Cavallaro,Ken-ichi Kawarabayashi,Stephan Kreutzer*

Main category: cs.DM

TL;DR: 本文证明了所有可嵌入在任意表面上的Eulerian有向图在强浸入下良序，带来了若干相关结构（如双圈图）在pivot-minor关系下良序、有效算法及Erdős-Pósa定理刻画。同时也发现了树宽较大时良序结果不成立的局限。


<details>
  <summary>Details</summary>
Motivation: 研究有向图在特定表面上的嵌入及其相关的强浸入关系的良序性（well-quasi-order），填补关于该图对象良序性的理论空白，并探索其在图论及组合优化中的应用。

Method: 证明对于任意表面Σ，可Eulerian嵌入的Eulerian有向图（其度至多为4）在强浸入关系下是良序的。进一步，分析该结果在双圈图pivot-minor关系、多项式时间判定及Erdős-Pósa性质上的应用。此外，证明有界carving宽度的Eulerian有向图也在强浸入关系下良序，并推广到顶点带标签的情况。最后，通过构造反例证明树宽至多3的Eulerian平面有向图在强浸入关系下并非良序。

Result: 对于任意表面Σ，所有可Eulerian嵌入的Eulerian有向图（度至多4）在强浸入下良序；双圈图在pivot-minor关系下良序。提出了针对有限表面上的Eulerian-embeddable图浸入封闭性质的多项式算法，以及最大度为4的Eulerian有向图的Erdős-Pósa性质刻画。同时，推广至标签图的情况，但指出树宽≤3的Eulerian平面有向图不良序。

Conclusion: 本文首次系统地证明了在给定表面上的Eulerian可嵌入有向图在强浸入下良序，并联动到多项应用及推广，填补了此类有向图良序理论及相关算法的空缺。也揭示了有向图良序性在高树宽时的局限性。

Abstract: We prove that for every surface $\Sigma$, the class of Eulerian directed
graphs that are Eulerian embeddable into $\Sigma$ (in particular they have
degree at most $4$) is well-quasi-ordered by strong immersion. This result
marks one of the most versatile directed graph classes (besides tournaments)
for which we are aware of a positive well-quasi-ordering result regarding a
well-studied graph relation.
  Our result implies that the class of bipartite circle graphs is
well-quasi-ordered under the pivot-minor relation. Furthermore, this also
yields two other interesting applications, namely, a polynomial-time algorithm
for testing immersion closed properties of Eulerian-embeddable graphs into a
fixed surface, and a characterisation of the Erd\H{o}s-P\'osa property for
Eulerian digraphs of maximum degree four.
  Further, in order to prove the mentioned result, we prove that Eulerian
digraphs of carving width bounded by some constant $k$ (which correspond to
Eulerian digraphs with bounded treewidth and additionally bounded degree) are
well-quasi-ordered by strong immersion. We actually prove a stronger result
where we allow for vertices of the Eulerian digraphs to be labeled by elements
of some well-quasi-order $\Omega$. We complement these results with a proof
that the class of Eulerian planar digraphs of treewidth at most $3$ is not
well-quasi-ordered by strong immersion, noting that any antichain of bounded
treewidth cannot have bounded degree.

</details>
