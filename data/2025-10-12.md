<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 9]
- [cs.LO](#cs.LO) [Total: 7]
- [cs.CL](#cs.CL) [Total: 37]
- [cs.DM](#cs.DM) [Total: 2]
- [cs.FL](#cs.FL) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Type, Ability, and Effect Systems: Perspectives on Purity, Semantics, and Expressiveness](https://arxiv.org/abs/2510.07582)
*Yuyan Bao,Tiark Rompf*

Main category: cs.PL

TL;DR: 论文分析了现有实现纯与副作用分离的方式，提出了新的纯度语义定义，评估了表达能力，并证明类型、能力和效应系统相结合更加完善，进一步提供了形式化证明工具支持。


<details>
  <summary>Details</summary>
Motivation: 现有程序语言中纯计算与副作用交互的分离存在方法（如monads、type-and-effect、能力系统），但这些方法在精确性与易用性之间存在权衡，各自有优缺点。论文旨在系统评估相关分离方法，并提出更合理的方案。

Method: 首先提出了不依赖具体类型系统的语义化纯度定义。随后通过提出“完整性”这一新度量标准，分析和比较了最简化的效应系统和能力系统的表达能力，最后提出结合三者的系统并构建了相关逻辑关系用于正式论证。

Result: 证明了最小化的效应系统和能力系统在表达能力上不可互相取代。提出的新系统有效结合了各种系统优点，并能方便进行形式化证明。

Conclusion: 该论文提出了一种结合型系统，可以兼具类型、能力和效应系统的优点，克服各自不足，并提出了形式化模型和逻辑关系用于证明纯度等性质。

Abstract: Programming benefits from a clear separation between pure, mathematical
computation and impure, effectful interaction with the world. Existing
approaches to enforce this separation include monads, type-and-effect systems,
and capability systems. All share a tension between precision and usability,
and each one has non-obvious strengths and weaknesses.
  This paper aims to raise the bar in assessing such systems. First, we propose
a semantic definition of purity, inspired by contextual equivalence, as a
baseline independent of any specific typing discipline. Second, we propose that
expressiveness should be measured by the degree of completeness, i.e., how many
semantically pure terms can be typed as pure. Using this measure, we focus on
minimal meaningful effect and capability systems and show that they are
incomparable, i.e., neither subsumes the other in terms of expressiveness.
  Based on this result, we propose a synthesis and show that type, ability, and
effect systems combine their respective strengths while avoiding their
weaknesses. As part of our formal model, we provide a logical relation to
facilitate proofs of purity and other properties for a variety of effect typing
disciplines.

</details>


### [2] [The Functional Machine Calculus III: Control](https://arxiv.org/abs/2510.07851)
*Willem Heijltjes*

Main category: cs.PL

TL;DR: 本文扩展了功能机器演算，实现对分支和循环控制流的支持，完整嵌入了最小但完整的命令式语言，同时保持了归一性和类型安全终止性，促进了命令式与函数式计算的统一。


<details>
  <summary>Details</summary>
Motivation: 现有编程语言或模型难以同时有效表达函数式和命令式特性，且很难做到在保留归一性和终止性同时支持丰富的控制流和副作用，因此需要一种统一且可扩展的理论框架。

Method: 通过扩展简化的Krivine机器，采用多操作数栈和续体栈，定义简单的操作语义，结合类型系统保证计算终止和归一性。论文将演算从顺序计算拓展到支持分支和循环控制流，实现更完整的命令式语言嵌入。

Result: 扩展后的演算不仅能嵌入顺序和命令式语言的特性，还确保了归一性和类型安全下的终止性，为函数命令式统一模型提供了直观、直接的操作语义和归一性语义。

Conclusion: 该论文提出了一种新的统一命令式和函数式编程范式的方法：功能机器演算，并且在保留λ演算主要特性的基础上，能够有效嵌入和解释复杂命令式特性。

Abstract: The Functional Machine Calculus (Heijltjes 2022) is a new approach to
unifying the imperative and functional programming paradigms. It extends the
lambda-calculus, preserving the key features of confluent reduction and typed
termination, to embed computational effects, evaluation strategies, and control
flow operations. The first instalment modelled sequential higher-order
computation with global store, input/output, probabilities, and
non-determinism, and embedded both the call-by-name and call-by-value
lambda-calculus, as well as Moggi's computational metalanguage and Levy's
call-by-push-value. The present paper extends the calculus from sequential to
branching and looping control flow. This allows the faithful embedding of a
minimal but complete imperative language, including conditionals, exception
handling, and iteration, as well as constants and algebraic data types.
  The calculus is defined through a simple operational semantics, extending the
(simplified) Krivine machine for the lambda-calculus with multiple operand
stacks to model effects and a continuation stack to model sequential,
branching, and looping computation. It features a confluent reduction relation
and a system of simple types that guarantees termination of the machine and
strong normalization of reduction (in the absence of iteration). These
properties carry over to the embedded imperative language, providing a unified
functional-imperative model of computation that supports simple types, a direct
and intuitive operational semantics, and a confluent reduction semantics.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [Modeling Developer Burnout with GenAI Adoption](https://arxiv.org/abs/2510.07435)
*Zixuan Feng,Sadia Afroz,Anita Sarma*

Main category: cs.SE

TL;DR: GenAI提升了开发者工作压力并加剧倦怠，但资源充足或对GenAI持积极态度时，这些负面影响可被减弱，从而使GenAI带来正面机会。


<details>
  <summary>Details</summary>
Motivation: 此前研究强调GenAI提升生产力，但其普及可能给开发者带来新的压力，影响身心健康。因此，研究GenAI采用与开发者职业倦怠间的关系具有重要意义。

Method: 采用混合方法研究设计，结合定量和定性证据。先调查了442名开发者，使用PLS-SEM和回归分析工作需求、工作资源与倦怠的关系，并对开放式回答进行了质性分析来补充定量结果。

Result: GenAI提升了开发者的工作压力，导致倦怠升高，但工作资源和积极看法能有效减缓倦怠表现，使开发者对GenAI的采用更为正面。

Conclusion: GenAI的采用通过增加工作需求会加剧开发者的职业倦怠；但充足的工作资源和对GenAI的积极看法可以缓解这些负面影响，使GenAI的采用变成一种机会。

Abstract: Generative AI (GenAI) is rapidly reshaping software development workflows.
While prior studies emphasize productivity gains, the adoption of GenAI also
introduces new pressures that may harm developers' well-being. In this paper,
we investigate the relationship between the adoption of GenAI and developers'
burnout. We utilized the Job Demands--Resources (JD--R) model as the analytic
lens in our empirical study. We employed a concurrent embedded mixed-methods
research design, integrating quantitative and qualitative evidence. We first
surveyed 442 developers across diverse organizations, roles, and levels of
experience. We then employed Partial Least Squares--Structural Equation
Modeling (PLS-SEM) and regression to model the relationships among job demands,
job resources, and burnout, complemented by a qualitative analysis of
open-ended responses to contextualize the quantitative findings. Our results
show that GenAI adoption heightens burnout by increasing job demands, while job
resources and positive perceptions of GenAI mitigate these effects, reframing
adoption as an opportunity.

</details>


### [4] [HotBugs.jar: A Benchmark of Hot Fixes for Time-Critical Bugs](https://arxiv.org/abs/2510.07529)
*Carol Hanna,Federica Sarro,Mark Harman,Justyna Petke*

Main category: cs.SE

TL;DR: 本论文首次提出面向hot fixes的专用数据集HotBugs.jar。通过对开源项目大规模挖掘与筛选，人工确认和复现，最终构建了679个高质量紧急修复案例，并已成为顶会挑战数据集，为自动化调试与修复研究提供了强有力支撑。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏专门针对紧急生产修复（hot fixes）评测基准。hot fixes 是为了解决生产环境的紧急且关键问题而进行的、未计划的代码修补，具有很高的实际应用价值，但相关数据集和评测资源不足。

Method: 作者对10个活跃的Apache项目进行了初步挖掘，包括超过19万次提交和15万条issue报告，筛选出746个符合hot-fix标准的软件补丁。经过人工评审确认了679个真实hot fixes，其中110个可以通过测试套件复现。基于Bugs.jar框架，将这110个可复现案例与全部679个经过人工验证的hot fixes和全面元数据整合，形成数据集。

Result: 最终构建了HotBugs.jar数据集，收录了110个可复现和679个人工确认的hot fixes，并附带详细元数据。每个hot fix都经系统性筛选、人工复查及复现格式封装，包括缺陷与修复版本、测试套件和元数据。该数据集已成为SBSE大会官方挑战数据集。

Conclusion: HotBugs.jar数据集填补了生产环境紧急修复相关数据资源空白，有助于推动自动化调试、自动修复和生产级系统韧性领域的研究，对学术和工业界具有直接影响力。

Abstract: Hot fixes are urgent, unplanned changes deployed to production systems to
address time-critical issues. Despite their importance, no existing evaluation
benchmark focuses specifically on hot fixes. We present HotBugs$.$jar, the
first dataset dedicated to real-world hot fixes. From an initial mining of 10
active Apache projects totaling over 190K commits and 150K issue reports, we
identified 746 software patches that met our hot-fix criteria. After manual
evaluation, 679 were confirmed as genuine hot fixes, of which 110 are
reproducible using a test suite. Building upon the Bugs$.$jar framework,
HotBugs$.$jar integrates these 110 reproducible cases and makes available all
679 manually validated hot fixes, each enriched with comprehensive metadata to
support future research. Each hot fix was systematically identified using Jira
issue data, validated by independent reviewers, and packaged in a reproducible
format with buggy and fixed versions, test suites, and metadata. HotBugs$.$jar
has already been adopted as the official challenge dataset for the Search-Based
Software Engineering (SBSE) Conference Challenge Track, demonstrating its
immediate impact. This benchmark enables the study and evaluation of tools for
rapid debugging, automated repair, and production-grade resilience in modern
software systems to drive research in this essential area forward.

</details>


### [5] [RustAssure: Differential Symbolic Testing for LLM-Transpiled C-to-Rust Code](https://arxiv.org/abs/2510.07604)
*Yubo Bai,Tapti Palit*

Main category: cs.SE

TL;DR: RustAssure集成大语言模型和符号测试自动将C代码转译为安全的Rust代码，且大部分转译结果可编译并与原C代码语义一致。


<details>
  <summary>Details</summary>
Motivation: C语言普遍存在内存安全隐患，而Rust提供了更好的安全性。为使原有C代码库受益于Rust的安全优势，需要能自动高效地转译C到Rust，并保证语义一致性。

Method: 利用大语言模型（LLM）自动转译C代码为Rust，结合prompt工程提升Rust代码的规范性及安全性，并采用差分符号测试对比原始C函数与转译后Rust函数的语义一致性。

Result: 在五个真实应用和库上评估，系统能将89.8%的C函数自动转译为可编译的Rust函数，其中有69.9%的函数在符号返回值上与原C函数等价。

Conclusion: RustAssure能自动将C代码库转译为内存安全的Rust代码，且生成的代码在很大程度上与原始C代码语义一致。

Abstract: Rust is a memory-safe programming language that significantly improves
software security. Existing codebases written in unsafe memory languages, such
as C, must first be transpiled to Rust to take advantage of Rust's improved
safety guarantees. RustAssure presents a system that uses Large Language Models
(LLMs) to automatically transpile existing C codebases to Rust. RustAssure uses
prompt engineering techniques to maximize the chances of the LLM generating
idiomatic and safe Rust code. Moreover, because LLMs often generate code with
subtle bugs that can be missed under traditional unit or fuzz testing,
RustAssure performs differential symbolic testing to establish the semantic
similarity between the original C and LLM-transpiled Rust code. We evaluated
RustAssure with five real-world applications and libraries, and showed that our
system is able to generate compilable Rust functions for 89.8% of all C
functions, of which 69.9% produced equivalent symbolic return values for both
the C and Rust functions.

</details>


### [6] [AppForge: From Assistant to Independent Developer -- Are GPTs Ready for Software Development?](https://arxiv.org/abs/2510.07740)
*Dezhi Ran,Yuan Cao,Mengzhou Wu,Simin Chen,Yuzhe Guo,Jun Ren,Zihe Song,Hao Yu,Jialei Wei,Linyi Li,Wei Yang,Baishakhi Ray,Tao Xie*

Main category: cs.SE

TL;DR: 本文提出APPFORGE基准，发现当前LLMs在完整软件系统开发上能力有限，最好的模型GPT-5也仅能生成不到20%功能正确的安卓应用，表明模型在系统级软件工程方面存在明显短板。


<details>
  <summary>Details</summary>
Motivation: 尽管现有LLMs在函数级别代码生成表现突出，但真实开发需求是能够生成完整的软件系统，现有基准无法评估模型在这方面的能力，故需开发新基准。

Method: 提出了一个名为APPFORGE的新基准，涵盖101个真实安卓应用开发问题，并设计了多智能体系统自动从应用文档中提炼功能、生成测试用例，并通过专家审核和自动化框架验证模型生成应用的功能正确性。

Result: 在12个先进LLM上实证评测，发现所有模型在构建完整安卓应用时效果都很低，最佳模型也仅有18.8%的应用功能正确。

Conclusion: 当前的大型语言模型（LLMs）在开发完整、复杂的多组件软件系统方面表现有限，即使最好的模型也只能正确生成少量完整应用。

Abstract: Large language models (LLMs) have demonstrated remarkable capability in
function-level code generation tasks. Unlike isolated functions, real-world
applications demand reasoning over the entire software system: developers must
orchestrate how different components interact, maintain consistency across
states over time, and ensure the application behaves correctly within the
lifecycle and framework constraints. Yet, no existing benchmark adequately
evaluates whether LLMs can bridge this gap and construct entire software
systems from scratch. To address this gap, we propose APPFORGE, a benchmark
consisting of 101 software development problems drawn from real-world Android
apps. Given a natural language specification detailing the app functionality, a
language model is tasked with implementing the functionality into an Android
app from scratch. Developing an Android app from scratch requires understanding
and coordinating app states, lifecycle management, and asynchronous operations,
calling for LLMs to generate context-aware, robust, and maintainable code. To
construct APPFORGE, we design a multi-agent system to automatically summarize
the main functionalities from app documents and navigate the app to synthesize
test cases validating the functional correctness of app implementation.
Following rigorous manual verification by Android development experts, APPFORGE
incorporates the test cases within an automated evaluation framework that
enables reproducible assessment without human intervention, making it easily
adoptable for future research. Our evaluation on 12 flagship LLMs show that all
evaluated models achieve low effectiveness, with the best-performing model
(GPT-5) developing only 18.8% functionally correct applications, highlighting
fundamental limitations in current models' ability to handle complex,
multi-component software engineering challenges.

</details>


### [7] [Interleaved Learning and Exploration: A Self-Adaptive Fuzz Testing Framework for MLIR](https://arxiv.org/abs/2510.07815)
*Zeyu Sun,Jingjing Liang,Weiyi Wang,Chenyao Suo,Junjie Chen,Fanjiang Xu*

Main category: cs.SE

TL;DR: 针对MLIR编译器的模糊测试挑战，本文提出FLEX框架，结合神经程序生成和反馈驱动优化，显著提升了bug发现数量和测试覆盖率，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: MLIR作为现代编译器的核心技术，需要保证其正确性和健壮性。但现有的fuzzing方法难以生成多样且语义有效的测试用例，无法有效发现MLIR中的隐蔽或复杂缺陷。

Method: 提出FLEX：一种自适应的MLIR模糊测试框架。FLEX利用神经网络进行程序生成，通过扰动采样策略提升测试用例多样性，并通过反馈驱动的增强循环，利用崩溃和非崩溃样例不断优化模型。

Result: 在MLIR主线编译器上与四个当前最先进的模糊测试工具对比。30天测试发现80个新bug，24小时测试发现53个bug（是最优基线的3.5倍），代码覆盖率达28.2%，比第二名高42%。消融实验确认扰动生成与多样性增强对效果至关重要。

Conclusion: FLEX显著提升了MLIR模糊测试的有效性，不仅发现更多bug，还改善了测试覆盖面。其自适应生成和多样化机制在编译器测试领域具有重要意义。

Abstract: MLIR (Multi-Level Intermediate Representation) has rapidly become a
foundational technology for modern compiler frameworks, enabling extensibility
across diverse domains. However, ensuring the correctness and robustness of
MLIR itself remains challenging. Existing fuzzing approaches-based on manually
crafted templates or rule-based mutations-struggle to generate sufficiently
diverse and semantically valid test cases, making it difficult to expose subtle
or deep-seated bugs within MLIR's complex and evolving code space. In this
paper, we present FLEX, a novel self-adaptive fuzzing framework for MLIR. FLEX
leverages neural networks for program generation, a perturbed sampling strategy
to encourage diversity, and a feedback-driven augmentation loop that
iteratively improves its model using both crashing and non-crashing test cases.
Starting from a limited seed corpus, FLEX progressively learns valid syntax and
semantics and autonomously produces high-quality test inputs. We evaluate FLEX
on the upstream MLIR compiler against four state-of-the-art fuzzers. In a
30-day campaign, FLEX discovers 80 previously unknown bugs-including multiple
new root causes and parser bugs-while in 24-hour fixed-revision comparisons, it
detects 53 bugs (over 3.5x as many as the best baseline) and achieves 28.2%
code coverage, outperforming the next-best tool by 42%. Ablation studies
further confirm the critical role of both perturbed generation and diversity
augmentation in FLEX's effectiveness.

</details>


### [8] [Bug Histories as Sources of Compiler Fuzzing Mutators](https://arxiv.org/abs/2510.07834)
*Lingjun Liu,Feiran Qin,Owolabi Legunsen,Marcelo d'Amorim*

Main category: cs.SE

TL;DR: 本文提出通过历史bug报告自动挖掘变异器的方法IssueMut，并在GCC和LLVM上取得了比传统方法更多的新bug发现效果，显示bug历史是提升fuzzer有效性的宝贵资源。


<details>
  <summary>Details</summary>
Motivation: 现有编译器fuzzer高度依赖变异器质量，但未充分利用bug报告这一丰富信息源。通过挖掘bug报告，可以指导fuzzer发现更多真正意义上的编译器缺陷。

Method: 提出IssueMut方法，从编译器bug报告中自动挖掘程序元素，生成用于编译器fuzzing的新变异器，并将这些变异器集成到现有变异型fuzzer中。

Result: IssueMut从1760份GCC和LLVM的bug报告中自动挖掘出587个变异器，实际运行时发现了65个新bug（GCC 28个、LLVM 37个），其中60个已被确认或修复，验证了方法有效性。

Conclusion: 利用编译器历史bug报告中的信息，可以有效提取并构建新的fuzzing变异工具，进而提升编译器fuzzing发现新bug的能力。

Abstract: Bugs in compilers, which are critical infrastructure today, can have outsized
negative impacts. Mutational fuzzers aid compiler bug detection by
systematically mutating compiler inputs, i.e., programs. Their effectiveness
depends on the quality of the mutators used. Yet, no prior work used compiler
bug histories as a source of mutators. We propose IssueMut, the first approach
for extracting compiler fuzzing mutators from bug histories. Our insight is
that bug reports contain hints about program elements that induced compiler
bugs; they can guide fuzzers towards similar bugs. IssueMut uses an automated
method to mine mutators from bug reports and retrofit such mutators into
existing mutational compiler fuzzers. Using IssueMut, we mine 587 mutators from
1760 GCC and LLVM bug reports. Then, we run IssueMut on these compilers, with
all their test inputs as seed corpora. We find that "bug history" mutators are
effective: they find new bugs that a state-of-the-art mutational compiler
fuzzer misses-28 in GCC and 37 in LLVM. Of these, 60 were confirmed or fixed,
validating our idea that bug histories have rich information that compiler
fuzzers should leverage.

</details>


### [9] [An AUTOSAR-Aligned Architectural Study of Vulnerabilities in Automotive SoC Software](https://arxiv.org/abs/2510.07941)
*Srijita Basu,Haraldsson Bengt,Miroslaw Staron,Christian Berger,Jennifer Horkoff,Magnus Almgren*

Main category: cs.SE

TL;DR: 本文系统分析了车载AUTOSAR SoC架构下的安全漏洞，发现主要问题根因和补丁延迟，指出亟需优化检测与修复机制，为汽车CPS安全提供具体建议。


<details>
  <summary>Details</summary>
Motivation: 随着CCAM系统中SoC集成化加深，安全挑战突出，尤其是在关键实时环境下。缺乏对AUTOSAR框架内SoC漏洞的系统性根因与影响分析。

Method: 分析了180个公开报道的汽车SoC漏洞，将其映射到与AUTOSAR原则相对齐的分层软件架构模型，统计漏洞根因、受影响的软件模块、修复延迟等。

Result: 识别出16种漏洞根因，56个受影响软件模块，发现主要漏洞模式及关键模块补丁延时，提出检测、优先级排序及定位的安全改进建议。

Conclusion: 研究揭示了AUTOSAR对齐架构中的SoC漏洞根因和影响模式，并提出了提升车载CPS平台安全性的可行建议。

Abstract: Cooperative, Connected and Automated Mobility (CCAM) are complex
cyber-physical systems (CPS) that integrate computation, communication, and
control in safety-critical environments. At their core, System-on-Chip (SoC)
platforms consolidate processing units, communication interfaces, AI
accelerators, and security modules into a single chip. AUTOSAR (AUTomotive Open
System ARchitecture) standard was developed in the automotive domain to better
manage this complexity, defining layered software structures and interfaces to
facilitate reuse of HW/SW components. However, in practice, this integrated SoC
software architecture still poses security challenges, particularly in
real-time, safety-critical environments. Recent reports highlight a surge in
SoC-related vulnerabilities, yet systematic analysis of their root causes and
impact within AUTOSAR-aligned architectures is lacking. This study fills that
gap by analyzing 180 publicly reported automotive SoC vulnerabilities, mapped
to a representative SoC software architecture model that is aligned with
AUTOSAR principles for layered abstraction and service orientation. We identify
16 root causes and 56 affected software modules, and examine mitigation delays
across Common Weakness Enumeration (CWE) categories and architectural layers.
We uncover dominant vulnerability patterns and critical modules with prolonged
patch delays, and provide actionable insights for securing automotive CPS
platforms, including guides for improved detection, prioritization, and
localization strategies for SoC software architectures in SoC-based vehicle
platforms.

</details>


### [10] [Past, Present, and Future of Bug Tracking in the Generative AI Era](https://arxiv.org/abs/2510.08005)
*Utku Boran Torun,Mehmet Taha Demircan,Mahmut Furkan Gön,Eray Tüzün*

Main category: cs.SE

TL;DR: 提出利用LLM自动化改造缺陷跟踪流程，提升效率和合作，减少人力消耗。


<details>
  <summary>Details</summary>
Motivation: 目前缺陷跟踪系统严重依赖人工分工，沟通成本高、响应慢，用户与技术团队之间存在协作障碍，亟需自动化手段提升整个流程效率。

Method: 分析现有缺陷跟踪系统演变、阐述其局限，设计整合LLM自动化的缺陷跟踪流程，包括智能报告解析、自动复现、分类处理、候选修复生成及分配。

Result: 本文提出了一个基于大型语言模型（LLM）驱动的智能化缺陷跟踪框架，旨在加速软件缺陷报告、复现、分类、修复等流程，通过自动化减轻人工负担并提升协作效率。该框架支持用户以自然语言报告问题，AI自动优化报告并尝试复现、补全信息，分类和指派任务给开发者，生成修复建议并由人工最终核查。这样整合自动化各环节，显著提升了响应速度与维护质量。

Conclusion: AI赋能的自动化缺陷跟踪框架可有效缩短修复时间、降低人工介入，并促进开发团队与用户之间更高效的协作。该框架推动软件维护更智能、以用户为中心的发展。

Abstract: Traditional bug tracking systems rely heavily on manual reporting,
reproduction, triaging, and resolution, each carried out by different
stakeholders such as end users, customer support, developers, and testers. This
division of responsibilities requires significant coordination and widens the
communication gap between non-technical users and technical teams, slowing the
process from bug discovery to resolution. Moreover, current systems are highly
asynchronous; users often wait hours or days for a first response, delaying
fixes and contributing to frustration. This paper examines the evolution of bug
tracking, from early paper-based reporting to today's web-based and SaaS
platforms. Building on this trajectory, we propose an AI-powered bug tracking
framework that augments existing tools with intelligent, large language model
(LLM)-driven automation. Our framework addresses two main challenges: reducing
time-to-fix and minimizing human overhead. Users report issues in natural
language, while AI agents refine reports, attempt reproduction, and request
missing details. Reports are then classified, invalid ones resolved through
no-code fixes, and valid ones localized and assigned to developers. LLMs also
generate candidate patches, with human oversight ensuring correctness. By
integrating automation into each phase, our framework accelerates response
times, improves collaboration, and strengthens software maintenance practices
for a more efficient, user-centric future.

</details>


### [11] [Building Whitespace-Sensitive Languages Using Whitespace-Insensitive Components](https://arxiv.org/abs/2510.08200)
*Alexander Hellwig,Nico Jansen,Bernhard Rumpe*

Main category: cs.SE

TL;DR: 本文提出用预处理技术让原本不可复用的空格不敏感语言组件用于构造空格敏感语言，实验证明能提升复用性和开发效率。


<details>
  <summary>Details</summary>
Motivation: 当前模块化语言组件的复用受限于空格敏感与不敏感语言集成的差异，导致相关库常无法复用，空格敏感语言需重新开发，亟需一致且可复用的解决方案。

Method: 通过对语言构件进行预处理，将空格信息在解析前处理，使原本只适用于空格不敏感语言的模块能够构建空格敏感语言，并通过简化版Python的重建进行方法评估。

Result: 通过预处理技术成功实现了空格敏感语言的重建，提高了语言组件的可复用性，减少了开发时间并提高了软件语言的整体质量。

Conclusion: 该论文提出了一种通过预处理语言构件，在解析之前将模块化、对空格不敏感的语言模块用于构造对空格敏感的语言的方法，提升了语言组件的复用性。

Abstract: In Software Language Engineering, there is a trend towards reusability by
composing modular language components. However, this reusability is severely
inhibited by a gap in integrating whitespace-sensitive and
whitespace-insensitive languages. There is currently no consistent procedure
for seamlessly reusing such language components in both cases, such that
libraries often cannot be reused, and whitespacesensitive languages are
developed from scratch. This paper presents a technique for using modular,
whitespaceinsensitive language modules to construct whitespace sensitive
languages by pre-processing language artifacts before parsing. The approach is
evaluated by reconstructing a simplified version of the programming language
Python. Our solution aims to increase the reusability of existing language
components to reduce development time and increase the overall quality of
software languages.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [12] [A Zone-Based Algorithm for Timed Parity Games](https://arxiv.org/abs/2510.07361)
*Gilles Geeraerts,Frédéric Herbreteau,Jean-François Raskin,Alexis Reynouard*

Main category: cs.LO

TL;DR: 本文改进了 timed games 语义，提出高效的基于 zone 的算法，验证了其在 timed parity games 应用中的可行性。


<details>
  <summary>Details</summary>
Motivation: 原有的 timed games 语义在控制器综合背景下有时表现得不太直观，且需要高效的区域算法支持。

Method: 对现有实时博弈（timed games）语义作出修改，确保语义直观，并提出高效的基于 zone 的算法，基于 UppAal 的 zone 库实现原型。

Result: 算法能有效处理 timed parity games，并通过原型展示了基于区间（zone）的算法可行性和丰富的实时互动语义。

Conclusion: 提出的语义和算法弥补了原有 timed games 的不足，提高了在 parity 目标与实时互动中的实用性。

Abstract: This paper revisits timed games by building upon the semantics introduced in
"The Element of Surprise in Timed Games". We introduce some modifications to
this semantics for two primary reasons: firstly, we recognize instances where
the original semantics appears counterintuitive in the context of controller
synthesis; secondly, we present methods to develop efficient zone-based
algorithms. Our algorithm successfully addresses timed parity games, and we
have implemented it using UppAal's zone library. This prototype effectively
demonstrates the feasibility of a zone-based algorithm for parity objectives
and a rich semantics for timed interactions between the players.

</details>


### [13] [Homomorphism Problems in Graph Databases and Automatic Structures](https://arxiv.org/abs/2510.07422)
*Rémi Morvan*

Main category: cs.LO

TL;DR: 本论文系统分析了同态问题在结合正则路径查询和自动结构上的决策复杂性，既给出了数据库领域实际可用的高效最小化算法，也揭示了无限自动结构同态问题的判定界限，并创新性地解决了其逻辑可描述性判定问题。


<details>
  <summary>Details</summary>
Motivation: 同态问题是数据库查询和约束求解理论的基础，理解其算法复杂性与可判定性对于提升查询效率和理论研究具有重要意义。尤其扩展到结构更丰富的查询与无限结构模型后，实际应用与理论挑战并存，驱动本论文系统深入分析。

Method: 第一部分基于结合查询与同态存在性等价理论，研究结合正则路径查询（CRPQ）的最小化问题，包括约束数量和树宽两个指标，并为实际常用片段提供高效算法。第二部分将同态问题拓展到自动结构（可由有限自动机描述的无限结构），分析了算法复杂性和可判定性的二分性，并通过新型代数语言理论探讨结构的逻辑可描述性。

Result: （1）结合正则路径查询最小化问题在约束数和树宽两方面都是可判定的，并为常用查询片段给出有效算法；（2）自动结构上的同态问题展示出可判定与不可判定的二分性，大部分情况不可判定；（3）建立了代数语言理论，对自动结构在特定逻辑（伪类）可描述性问题提供了可判定性结论。

Conclusion: 论文总结了同态问题在有限图型数据的数据库查询和约束求解（包含无限结构）两个领域中的核心作用，并分别给出了对应的决策性结果和高效算法。

Abstract: This thesis investigates the central role of homomorphism problems
(structure-preserving maps) in two complementary domains: database querying
over finite, graph-shaped data, and constraint solving over (potentially
infinite) structures. Building on the well-known equivalence between
conjunctive query evaluation and homomorphism existence, the first part focuses
on conjunctive regular path queries, a standard extension of conjunctive
queries that incorporates regular-path predicates. We study the fundamental
problem of query minimization under two measures: the number of atoms
(constraints) and the tree-width of the query graph. In both cases, we prove
the problem to be decidable, and provide efficient algorithms for a large
fragment of queries used in practice. The second part of the thesis lifts
homomorphism problems to automatic structures, which are infinite structures
describable by finite automata. We highlight a dichotomy, between homomorphism
problems over automatic structures that are decidable in non-deterministic
logarithmic space, and those that are undecidable (proving to be the more
common case). In contrast to this prevalence of undecidability, we then focus
on the language-theoretic properties of these structures, and show, relying on
a novel algebraic language theory, that for any well-behaved logic (a
pseudovariety), whether an automatic structure can be described in this logic
is decidable.

</details>


### [14] [Verifying Graph Neural Networks with Readout is Intractable](https://arxiv.org/abs/2510.08045)
*Artem Chernobrovkin,Marco Sälzer,François Schwarzentruber,Nicolas Troquard*

Main category: cs.LO

TL;DR: 本文提出了一种用于量化ACR-GNNs推理的逻辑语言，证明了它们的验证问题计算上极其困难（coNEXPTIME完全），但量化模型依然能在保证准确性和泛化能力的情况下减少资源消耗。推动了安全、高效GNN研究的发展。


<details>
  <summary>Details</summary>
Motivation: 随着图神经网络（GNNs）在复杂任务中的应用越来越广泛，如何验证其安全性和有效性成为重要挑战。对于量化的GNNs，尤其是带有全局读出操作的ACR-GNN，缺乏专门的逻辑工具来进行推理和验证。本文旨在填补这一空白，推动安全GNN系统的研究。

Method: 本文提出了一种逻辑语言，可以对量化的ACR-GNNs进行推理。借助该逻辑框架，作者对量化GNN的验证问题进行了逻辑刻画，并证明了其复杂性为（co）NEXPTIME完全。此外，还通过实验分析了模型的轻量化与性能表现。

Result: 从理论上，验证量化GNN（尤其是带有读出操作的ACR-GNN）的复杂性达到（co）NEXPTIME完全，说明这一任务非常困难。从实验上，量化的ACR-GNN模型能够在保持准确率和泛化能力的基础上，显著减小模型大小和计算量。

Conclusion: 针对量化ACR-GNNs，提出了面向验证的逻辑语言和复杂性理论分析，明确了其验证难度，并通过实验展示了量化模型的实际优势。未来GNN系统的安全保障需要新的理论和工具支持。

Abstract: We introduce a logical language for reasoning about quantized
aggregate-combine graph neural networks with global readout (ACR-GNNs). We
provide a logical characterization and use it to prove that verification tasks
for quantized GNNs with readout are (co)NEXPTIME-complete. This result implies
that the verification of quantized GNNs is computationally intractable,
prompting substantial research efforts toward ensuring the safety of GNN-based
systems. We also experimentally demonstrate that quantized ACR-GNN models are
lightweight while maintaining good accuracy and generalization capabilities
with respect to non-quantized models.

</details>


### [15] [Implication Problems over Positive Semirings](https://arxiv.org/abs/2510.08112)
*Minna Hirvonen*

Main category: cs.LO

TL;DR: 本文提出了基于正半环的团队语义模型，统一研究各类依赖性及其蕴含问题，在数据库与概率语义之间架起了一座桥梁。


<details>
  <summary>Details</summary>
Motivation: 当前数据库关系和概率理论中有多种依赖性定义，但分散在各自的语境下；动机在于统一这些依赖性的表达和推理方法，以便在不同的注解结构（如概率、计数等）下共同研究。

Method: 提出了semiring team semantics的框架，将数据库关系中的每个元组用一个正半环的元素进行注解，进而在此基础上推广各种依赖性定义，并研究这些依赖性的蕴含问题的公理化表达和推理规则，为不同半环结构下的语义提供统一的推理机制。

Result: 成功构建了一个能够包容多种依赖性（如函数依赖、包含依赖、边际一致性、概率独立性等）在不同半环结构下的统一表达框架，并给出了相关蕴含问题的公理化和推理规则，使其在关系、计数和概率语义等场景下均可适用。

Conclusion: semiring team semantics为依赖性表达和推理提供了一个通用、统一的框架，能够应对数据库和概率理论中的不同语义场景，为后续依赖性分析和推理机制的统一研究铺平了道路。

Abstract: We study various notions of dependency in semiring team semantics. Semiring
teams are essentially database relations, where each tuple is annotated with
some element from a positive semiring. We consider semiring generalizations of
several dependency notions from database theory and probability theory,
including functional and inclusion dependencies, marginal identity, and
(probabilistic) independence. We examine axiomatizations of implication
problems, which are rule-based characterizations for the logical implication
and inference of new dependencies from a given set of dependencies. Semiring
team semantics provides a general framework, where different implication
problems can be studied simultaneously for various semirings. The choice of the
semiring leads to a specific semantic interpretation of the dependencies, and
hence different semirings offer a way to study different semantics (e.g.,
relational, bag, and probabilistic semantics) in a unified framework.

</details>


### [16] [Complexity Results in Team Semantics: Nonemptiness Is Not So Complex](https://arxiv.org/abs/2510.08122)
*Aleksi Anttila,Juha Kontinen,Fan Yang*

Main category: cs.LO

TL;DR: 论文揭示了团队语义下带NE原子的凸逻辑的三大基本问题复杂度：可满足性（NP-完全）、有效性（coNP-完全）、模型检测（P），填补了相关领域复杂性理论空白。


<details>
  <summary>Details</summary>
Motivation: 探讨在团队语义下，凸逻辑的复杂性理论性质，特别关注带有非空原子（NE）的经典命题逻辑扩展。该类逻辑具有凸性和并封闭性，之前相关复杂性分析尚缺乏。

Method: 分析凸逻辑与团队语义结合下的计算复杂度，分别对可满足性、有效性和模型检测问题进行复杂性分类与证明。

Result: 证明了该逻辑的可满足性问题是NP-完全的，有效性问题是coNP-完全的，模型检测问题属于P类。

Conclusion: 该工作系统分析了带有NE原子的凸逻辑在团队语义下的复杂性，明确给出了不同问题的复杂度归属，为团队语义逻辑的复杂性理论打下了基础。

Abstract: We initiate the study of the complexity-theoretic properties of convex logics
in team semantics. We focus on the extension of classical propositional logic
with the nonemptiness atom NE, a logic known to be both convex and union
closed. We show that the satisfiability problem for this logic is NP-complete,
that its validity problem is coNP-complete, and that its model-checking problem
is in P.

</details>


### [17] [Compression for Coinductive Infinitary Rewriting: A Generic Approach, with Applications to Cut-Elimination for Non-Wellfounded Proofs](https://arxiv.org/abs/2510.08420)
*Rémy Cerda,Alexis Saurin*

Main category: cs.LO

TL;DR: 本文扩展了共归式无穷重写理论到非良基推导，提出了统一的压缩性证明方法，并在一级重写、无穷λ演算及线性逻辑证明系统中进行应用，理论与实践意义突出。


<details>
  <summary>Details</summary>
Motivation: 无穷重写（Infinitary rewriting）能够描述非终止但可产出的重写系统的动态。以往压缩（Compression）性质是重要特征，即任意序数长度的重写序列都可压缩为长度至多为ω的等价序列。本论文动机为扩展重写理论到非良基（non-wellfounded）推导，并探究在这种背景下的压缩性质。

Method: 通过将重写系统的共归式（coinductive）定义扩展到任意非良基推导下，设计了泛化的压缩证明。该证明依赖于对可压缩重写系统特性的一个关键刻画，将证明工作标准化和简化，并明确了实现可压缩性所需的核心属性。

Result: 结果展示了在任意非良基推导下重写系统的压缩性质成立。具体讨论了一级重写和无穷λ演算的压缩性，尤其对于λ演算，该性质也从理论上证明了文献中的共归式定义的合理性。高级应用还包括对于含不动点的非良基证明系统μMALL∞中的cut-elimination序列的压缩性，为相关证明系统的消割定理提供了关键工具。

Conclusion: 论文不仅推广了共归式重写系统压缩性质理论，还为压缩性的泛化证明提供了结构化方法，并在多个领域（如λ演算和线性逻辑证明系统）得到有效应用。该结果有助于理解非终止推导中的结构简化及其理论基础。

Abstract: Infinitary rewriting, i.e. rewriting featuring possibly infinite terms and
sequences of reduction, is a convenient framework for describing the dynamics
of non-terminating but productive rewriting systems. In its original definition
based on metric convergence of ordinal-indexed sequences of rewriting steps, a
highly desirable property of an infinitary rewriting system is Compression,
i.e. the fact that rewriting sequences of arbitrary ordinal length can always
be 'compressed' to equivalent sequences of length at most {\omega}.
  Since then, the standard examples of infinitary rewriting systems have been
given another equivalent presentation based on coinduction. In this work, we
extend this presentation to the rewriting of arbitrary non-wellfounded
derivations and we investigate compression in this setting. We design a generic
proof of compression, relying on a characterisation factorising most of the
proof and identifying the key property a compressible infinitary rewriting
system should enjoy.
  As running examples, we discuss first-order rewriting and infinitary
{\lambda}-calculi. For the latter, compression can in particular be seen as a
justification of its coinductive presentation in the literature. As a more
advanced example, we also address compression of cut-elimination sequences in
the non-wellfounded proof system {\mu}MALL{\infty} for multiplicative-additive
linear logics with fixed points, which is a key lemma of several
cut-elimination results for similar proof systems.

</details>


### [18] [Dynamic Automated Deduction by Contradiction Separation: The Standard Extension Algorithm](https://arxiv.org/abs/2510.08468)
*Yang Xu,Xingxing He,Shuwei Chen,Jun Liu,Xiaomei Zhong*

Main category: cs.LO

TL;DR: 本文提出了自动推理领域首个实现CSE理论的算法，用以解决多子句推理效率瓶颈。算法理论证明完备，并在主流竞赛中取得优异效果，显示其实用性和创新性价值。


<details>
  <summary>Details</summary>
Motivation: 传统的自动推理系统普遍采用基于二元推理的归结方法，但这种方法在证明搜索过程中多子句协同作用有限，影响了演绎效率和能力。之前的CSE理论突破了二元推理的限制，但缺乏具体的算法实现细节，尤其是在如何实际构造和扩展矛盾方面。本文意在填补这一空白，将理论落地为实际可用的算法。

Method: 提出了标准扩展算法，这是CSE理论首次被具体实现的动态构造矛盾的方法。该算法采用互补文字扩展机制，实现了统一的可满足性和不可满足性检查，同时对算法的完整性和正确性做了严格的理论证明。

Result: 算法的有效性通过近年来在主要自动推理比赛（CASC）中多个基于CSE体系的系统（CSE、CSE-E、CSI-E、CSI-Enig）的表现得以间接验证。显示该方法在实际多子句自动推理任务中表现稳健且高效。

Conclusion: 标准扩展机制有效地实现了理论上的矛盾分离推理方法，为多子句、动态自动推理系统提供了经过理论和实际检验的坚实基础。

Abstract: Automated deduction seeks to enable machines to reason with mathematical
precision and logical completeness. Classical resolution-based systems, such as
Prover9, E, and Vampire, rely on binary inference, which inherently limits
multi-clause synergy during proof search. The Contradiction Separation
Extension (CSE) framework, introduced by Xu et al. (2018), overcame this
theoretical limitation by extending deduction beyond binary inference. However,
the original work did not specify how contradictions are algorithmically
constructed and extended in practice. This paper presents the Standard
Extension algorithm, the first explicit procedural realization of contradiction
separation reasoning. The proposed method dynamically constructs contradictions
through complementary literal extension, thereby operationalizing the CSE
theory within a unified algorithm for satisfiability and unsatisfiability
checking. The algorithm's soundness and completeness are formally proven, and
its effectiveness is supported indirectly through the performance of CSE-based
systems, including CSE, CSE-E, CSI-E, and CSI-Enig in major automated reasoning
competitions (CASC) in the last few years. These results confirm that the
Standard Extension mechanism constitutes a robust and practically validated
foundation for dynamic, multi-clause automated deduction.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [19] [Inconsistent Affective Reaction: Sentiment of Perception and Opinion in Urban Environments](https://arxiv.org/abs/2510.07359)
*Jingfei Huang,Han Tu*

Main category: cs.CL

TL;DR: 本研究通过街景图像和微博文本数据，分析北京二环区域2016与2022年感知与意见情感反应，发现疫情前后两者有显著不一致性，并探讨其与城市环境要素的关系，为城市管理和更新提供实际参考。


<details>
  <summary>Details</summary>
Motivation: 社交媒体的发展推动了对城市环境中人类感知和意见情感的深入研究。现有多维情感分析方法面临挑战，需创新方法揭示感知与意见情感反应的不一致性，并为城市更新和环境管理提供新视角。

Method: 通过整合图像对象检测与自然语言处理技术，对城市区域街景图片与社交媒体文本进行情感分类。利用回归分析、图像分割和词频分析，结合土地利用分布，分析并可视化感知与意见情感反应，对比疫情前后变化。

Result: 街景感知情感反应分布趋于更均衡的正面情绪，而社交媒体意见情感变化更为极端。感知与意见情感反应存在明显不匹配，且与建筑密度及行人分布等相关，疫情前后差异更大。相关成果为城市环境管理和更新策略提供了理论基础。

Conclusion: 研究发现，城市环境中感知与意见两种情感反应在空间分布和时间变化上存在显著不一致，并与建筑密度及行人活动等元素密切相关。疫情前后，这种不一致更为突出，对城市环境管理与更新策略具有重要参考价值。

Abstract: The ascension of social media platforms has transformed our understanding of
urban environments, giving rise to nuanced variations in sentiment reaction
embedded within human perception and opinion, and challenging existing
multidimensional sentiment analysis approaches in urban studies. This study
presents novel methodologies for identifying and elucidating sentiment
inconsistency, constructing a dataset encompassing 140,750 Baidu and Tencent
Street view images to measure perceptions, and 984,024 Weibo social media text
posts to measure opinions. A reaction index is developed, integrating object
detection and natural language processing techniques to classify sentiment in
Beijing Second Ring for 2016 and 2022. Classified sentiment reaction is
analysed and visualized using regression analysis, image segmentation, and word
frequency based on land-use distribution to discern underlying factors. The
perception affective reaction trend map reveals a shift toward more evenly
distributed positive sentiment, while the opinion affective reaction trend map
shows more extreme changes. Our mismatch map indicates significant disparities
between the sentiments of human perception and opinion of urban areas over the
years. Changes in sentiment reactions have significant relationships with
elements such as dense buildings and pedestrian presence. Our inconsistent maps
present perception and opinion sentiments before and after the pandemic and
offer potential explanations and directions for environmental management, in
formulating strategies for urban renewal.

</details>


### [20] [Haystack Engineering: Context Engineering for Heterogeneous and Agentic Long-Context Evaluation](https://arxiv.org/abs/2510.07414)
*Mufei Li,Dongqi Fu,Limei Wang,Si Zhang,Hanqing Zeng,Kaan Sancak,Ruizhong Qiu,Haoyu Wang,Xiaoxin He,Xavier Bresson,Yinglong Xia,Chonglin Sun,Pan Li*

Main category: cs.CL

TL;DR: 论文提出基于真实链路结构的HaystackCraft基准，分析各种检索策略对模型长上下文表现的影响，发现现有模型在复杂、动态任务中仍面临干扰信息和错误积累的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有长上下文NIAH测试过于合成化，忽略了真实环境里的检索偏差与流程性错误。需要构造现实、更嘈杂的测试场景，全面评估大模型在复杂环境中的稳健性。

Method: 作者提出了"HaystackCraft"，利用英文维基百科的超链接网络制作多跳问题，并通过不同的检索策略（稀疏、密集、混合、图检索）构造干扰项，评估检索对模型表现的影响。同时拓展为动态、依赖于LLM反馈的环境，模拟智能体的实际任务流程（包括查询精炼、推理反思、停止决策）。

Result: 实验表明，密集检索器会带来更具挑战性干扰，图检索可有效减弱有害干扰并提升检索效果。即使是先进的Gemini 2.5 Pro和GPT-5，在模拟智能体任务中也会因自生成干扰信息或错误累积而失败，特别是在何时应停止任务上表现不佳。

Conclusion: HaystackCraft是一个更贴合实际环境的长上下文基准，揭示了当前模型在嘈杂、动态环境下依然存在显著挑战。即使是最先进的模型在复杂任务中也难以避免错误的累积和分辨干扰信息。

Abstract: Modern long-context large language models (LLMs) perform well on synthetic
"needle-in-a-haystack" (NIAH) benchmarks, but such tests overlook how noisy
contexts arise from biased retrieval and agentic workflows. We argue that
haystack engineering is necessary to construct noisy long contexts that
faithfully capture key real-world factors -- distraction from heterogeneous
biased retrievers and cascading errors in agentic workflows -- to test models'
long-context robustness. We instantiate it through HaystackCraft, a new NIAH
benchmark built on the full English Wikipedia hyperlink network with multi-hop
questions. HaystackCraft evaluates how heterogeneous retrieval strategies
(e.g., sparse, dense, hybrid, and graph-based) affect distractor composition,
haystack ordering, and downstream LLM performance. HaystackCraft further
extends NIAH to dynamic, LLM-dependent settings that simulate agentic
operations, where models refine queries, reflect on their past reasonings, and
decide when to stop. Experiments with 15 long-context models show that (1)
while stronger dense retrievers can introduce more challenging distractors,
graph-based reranking simultaneously improves retrieval effectiveness and
mitigates more harmful distractors; (2) in agentic tests, even advanced models
like Gemini 2.5 Pro and GPT-5 suffer cascading failures from self-generated
distractors or struggle to perform early stops. These results highlight
persistent challenges in agentic long-context reasoning and establish
HaystackCraft as a valuable testbed for future progress.

</details>


### [21] [Lemma Dilemma: On Lemma Generation Without Domain- or Language-Specific Training Data](https://arxiv.org/abs/2510.07434)
*Olia Toporkov,Alan Akbik,Rodrigo Agerri*

Main category: cs.CL

TL;DR: 本研究实证对比了LLMs与传统方法在多语言词形还原上的表现，发现LLMs无需微调且只需少量例子即可优于主流方法，标志着词形还原任务由微调编码器向少样例LLMs迁移。


<details>
  <summary>Details</summary>
Motivation: 鉴于LLMs在多种NLP任务中的优秀表现，但未有关于其在词形还原这一上下文敏感任务上的效果探索，作者希望检验LLMs在无目标领域或语言训练数据时的词形还原能力。

Method: 通过实验对比LLMs直接进行上下文词形还原（仅需少量示例输入）和传统编码器方法（包括跨语言及领域外微调方式）在12种不同形态复杂度语言上的表现。

Result: 实验显示，在无法获得目标领域/语言监督数据的情形下，传统编码器在领域外微调后表现仍具竞争力，但最新LLMs只需少量示例而无需微调，即在绝大多数语言上达到乃至超过现有方法的性能。

Conclusion: 当前的大型语言模型（LLMs）在无需提前微调，仅凭少量例子即可在多数语言的词形还原任务中取得最先进的结果，优于传统监督式方法。

Abstract: Lemmatization is the task of transforming all words in a given text to their
dictionary forms. While large language models (LLMs) have demonstrated their
ability to achieve competitive results across a wide range of NLP tasks, there
is no prior evidence of how effective they are in the contextual lemmatization
task. In this paper, we empirically investigate the capacity of the latest
generation of LLMs to perform in-context lemmatization, comparing it to the
traditional fully supervised approach. In particular, we consider the setting
in which supervised training data is not available for a target domain or
language, comparing (i) encoder-only supervised approaches, fine-tuned
out-of-domain, and (ii) cross-lingual methods, against direct in-context lemma
generation with LLMs. Our experimental investigation across 12 languages of
different morphological complexity finds that, while encoders remain
competitive in out-of-domain settings when fine-tuned on gold data, current
LLMs reach state-of-the-art results for most languages by directly generating
lemmas in-context without prior fine-tuning, provided just with a few examples.
Data and code available upon publication:
https://github.com/oltoporkov/lemma-dilemma

</details>


### [22] [LASER: An LLM-based ASR Scoring and Evaluation Rubric](https://arxiv.org/abs/2510.07437)
*Amruta Parulekar,Preethi Jyothi*

Main category: cs.CL

TL;DR: 提出LLM-Based的LASER评分方法提升ASR评估语义合理性，在主流和小型LLM上均取得高相关性和准确率，对多种印度语言具有良好迁移能力。


<details>
  <summary>Details</summary>
Motivation: 传统的自动语音识别（ASR）评价指标如词错误率（WER）会对某些形态和句法上的细微差别给予过高的惩罚，而这些差异实际上并不会显著改变句子语义。为提升评估的合理性，作者希望构建更语义敏感的评价方式。

Method: 1. 提出基于大语言模型（LLM）的评分标准LASER，利用LLM的上下文学习能力，通过详细示例式提示进行训练。2. 以Gemini 2.5 Pro为主，用Hindi语言训练并应用于其他印度语言。3. 对较小的LLM（如Llama 3）进行微调，通过词对示例来预测应施加的惩罚类型和程度。

Result: Hindi LASER评分在Gemini 2.5 Pro上与人工标注的相关性高达94%。Hindi示例也能有效分析Marathi、Kannada和Malayalam等其他印度语言的错误。微调后的Llama 3在预测合理惩罚方面准确率接近89%。

Conclusion: 基于大语言模型的LASER评分方法可显著提升ASR评估的语义相关性，并能高效迁移至多个印度语言。微调较小模型后也有较好的表现，为自动评估和低资源语言扩展提供了新路径。

Abstract: Standard ASR evaluation metrics like Word Error Rate (WER) tend to unfairly
penalize morphological and syntactic nuances that do not significantly alter
sentence semantics. We introduce an LLM-based scoring rubric LASER that
leverages state-of-the-art LLMs' in-context learning abilities to learn from
prompts with detailed examples. Hindi LASER scores using Gemini 2.5 Pro
achieved a very high correlation score of 94% with human annotations. Hindi
examples in the prompt were also effective in analyzing errors in other Indian
languages such as Marathi, Kannada and Malayalam. We also demonstrate how a
smaller LLM like Llama 3 can be finetuned on word-pair examples derived from
reference and ASR predictions to predict what kind of penalty should be applied
with close to 89% accuracy.

</details>


### [23] [Meaningful Pose-Based Sign Language Evaluation](https://arxiv.org/abs/2510.07453)
*Zifan Jiang,Colin Leong,Amit Moryossef,Anne Göhring,Annette Rios,Oliver Cory,Maksym Ivashechkin,Neha Tarigopula,Biao Zhang,Rico Sennrich,Sarah Ebling*

Main category: cs.CL

TL;DR: 本文系统比较了认知手语骨架姿态的多种评价方法，实证揭示其优势与局限，并发布了开源工具推动手语翻译系统开发。


<details>
  <summary>Details</summary>
Motivation: 手语翻译系统的评价缺乏统一标准，现有方法各有局限，亟需可比较和实用的姿态评估方案以促进相关研究。

Method: 采用三种评估指标：关键点距离、嵌入表示和反向翻译，通过自动化元评估和人工相关性分析比较这些方法在不同手语和场景下的优劣。

Result: 三种评估方法之间存在权衡，不同场景下效果不同，研究通过实验和人工评估明确了各自适用性，并开放了工具包供社区使用。

Conclusion: 该研究提出了一种评估手语骨架姿态的综合方法，并开发了开源评估工具，有助于实际和可复现地研究手语翻译相关系统。

Abstract: We present a comprehensive study on meaningfully evaluating sign language
utterances in the form of human skeletal poses. The study covers keypoint
distance-based, embedding-based, and back-translation-based metrics. We show
tradeoffs between different metrics in different scenarios through automatic
meta-evaluation of sign-level retrieval and a human correlation study of
text-to-pose translation across different sign languages. Our findings and the
open-source pose-evaluation toolkit provide a practical and reproducible way of
developing and evaluating sign language translation or generation systems.

</details>


### [24] [Populism Meets AI: Advancing Populism Research with LLMs](https://arxiv.org/abs/2510.07458)
*Eduardo Ryô Tamaki,Yujin J. Jung,Julia Chatterley,Grant Mitchell,Semir Dzebo,Cristóbal Sandoval,Levente Littvay,Kirk A. Hawkins*

Main category: cs.CL

TL;DR: 论文用类人工方法引导大模型分析民粹主义文本，准确率和专家编码员持平，解决了自动化测量成本和规模问题，模型具备实际应用前景。


<details>
  <summary>Details</summary>
Motivation: 衡量民粹主义的思想内容一直是一个挑战，现有的文本分析方法虽然有效，但存在耗时、成本高、难以跨语言和大规模应用的问题。

Method: 论文提出了一种评分标准和锚点引导的链式思考（CoT）提示方法，模拟人工编码员的训练过程。通过利用全球民粹主义数据库（GPD），使用与人工编码员培训相适应的文档来引导LLM模型的推理。同时测试了多种专有和开源模型，通过复现GPD中的评分来进行验证。

Result: 该领域专用的提示策略使得LLM在民粹主义文本分类准确率上达到与专家人工编码员相当的水平，能够把握民粹主义的细微和情境性特征。

Conclusion: 针对民粹主义文本分析，该方法具备高效、可扩展的优点，有望替代或辅助传统的人类编码文本分析手段。

Abstract: Measuring the ideational content of populism remains a challenge. Traditional
strategies based on textual analysis have been critical for building the
field's foundations and providing a valid, objective indicator of populist
framing. Yet these approaches are costly, time consuming, and difficult to
scale across languages, contexts, and large corpora. Here we present the
results from a rubric and anchor guided chain of thought (CoT) prompting
approach that mirrors human coder training. By leveraging the Global Populism
Database (GPD), a comprehensive dataset of global leaders' speeches annotated
for degrees of populism, we replicate the process used to train human coders by
prompting the LLM with an adapted version of the same documentation to guide
the model's reasoning. We then test multiple proprietary and open weight models
by replicating scores in the GPD. Our findings reveal that this domain specific
prompting strategy enables the LLM to achieve classification accuracy on par
with expert human coders, demonstrating its ability to navigate the nuanced,
context sensitive aspects of populism.

</details>


### [25] [MAPRO: Recasting Multi-Agent Prompt Optimization as Maximum a Posteriori Inference](https://arxiv.org/abs/2510.07475)
*Zheyuan Zhang,Lin Ge,Hongjiang Li,Weicheng Zhu,Chuxu Zhang,Yanfang Ye*

Main category: cs.CL

TL;DR: 本文提出MAPRO框架，实现多智能体提示自动优化，利用信念传播算法和反馈迭代，有效解决了搜索空间和信用分配难题，在多任务下表现优越，并为MAS系统设计提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）已在多任务上表现出色，LLM驱动的智能体进一步拓展了其实际应用。但对于多智能体系统（MAS），由于提示工程敏感性和系统不稳定性，设计更为复杂且困难。现有自动化提示设计已减轻部分手动工作，但多智能体优化仍缺乏系统方法，因搜索空间大和奖励分配模糊等问题难以推进。

Method: 提出了Multi-Agent Prompt Optimization (MAPRO)四阶段框架，将MAS提示优化形式化为最大后验推断问题，并使用语言引导的max-product信念传播算法进行求解。MAPRO引入拓扑感知的细化机制，结合执行反馈和责任归因，迭代优化各智能体提示，实现系统协调收敛。

Result: MAPRO在多项任务基准中取得了最先进的性能，显著超越人工基线与最新自动化方法。

Conclusion: MAPRO提供了通用且可扩展的MAS提示优化方案，不仅提升了多智能体系统性能，还为未来可靠、严谨系统设计提供理论指导。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
diverse tasks, and LLM-based agents further extend these abilities to various
practical workflows. While recent progress shows that multi-agent systems (MAS)
can outperform single agents by coordinating specialized roles, designing
effective MAS remains difficult due to prompt sensitivity and the compounded
instability MAS creates. To cope with the challenge, recent efforts in
automated prompt design have reduced manual effort. However, multi-agent prompt
optimization remains largely unexplored. Challenges like exponentially
expanding search space and ambiguous credit assignment together make systematic
design intractable without principled methods. Therefore, we introduce
M}ulti-Agent PRompt Optimization (MAPRO), a four-stage framework that first
formulates MAS prompt optimization as a Maximum a Posteriori (MAP) inference
problem and solves it using a language-guided variant of max-product belief
propagation algorithm. To address credit assignment and updates the system
iteratively, MAPRO employs a topology-aware refinement mechanism that
integrates execution feedback and downstream blames to selectively update agent
prompts. Through this process, MAPRO progressively converges to a coordinated
set of agent-specific prompt policies. Across benchmarks in various tasks,
MAPRO achieves state-of-the-art performance, consistently surpassing manually
engineered baselines and recent automated alternatives. Beyond performance, our
MAP-based formulation also delivers general guidelines for building more
reliable and principled multi-agent systems in the future

</details>


### [26] [AsyncSpade: Efficient Test-Time Scaling with Asynchronous Sparse Decoding](https://arxiv.org/abs/2510.07486)
*Shuqing Luo,Yilin Guan,Pingzhi Li,Hanrui Wang,Tianlong Chen*

Main category: cs.CL

TL;DR: AsyncSpade通过异步KV缓存筛选机制，显著减少大模型推理时延，同时保持甚至提升推理准确率，对长链思维应用尤为有效。


<details>
  <summary>Details</summary>
Motivation: 长链式思维（CoT）提升了大模型推理能力，但KV缓存线性增长导致了内存瓶颈，影响解码效率。在高并发和长CoT推理场景下，现有稀疏解码方法受限于顺序依赖和粗粒度筛选，进一步加剧了运行时和性能问题。

Method: 提出AsyncSpade异步框架，包括两个核心组件：1）轻量级时序回归模块，用于预测下一步查询状态；2）解耦KV缓存过滤和自回归解码，通过异步操作在推理过程中重叠KV选择与前向计算，摆脱解码循环的顺序依赖。

Result: 在A100节点上的LLM服务实验验证AsyncSpade可完全重叠KV缓存操作与推理流程，理论上实现输出token的最优时延。对比当前最优基线Quest，TPOT减少20%以上，相较全注意力机制在Qwen3-8B和Qwen3-32B上TPOT减少至少50%，且在多个TTS基准测试中精度持平或超过现有方法。

Conclusion: AsyncSpade 是首个能在无需牺牲模型性能的前提下，彻底消除顺序依赖的异步TTS推理框架，大幅提升推理效率和内存利用率，助力高并发及长链思维推理应用的落地。

Abstract: Test-time scaling (TTS) boosts LLM reasoning via long chain-of-thought (CoT),
but the linear KV-cache growth amplifies the memory-bound bottleneck of LLM
decoding. Query-aware page-level sparse decoding can achieve state-of-the-art
performance under constrained FLOPs budgets, but is limited by both
sequential-dependent page filtering and coarse-grained token selection,
hampering serving efficiency and model performance on TTS tasks under high
concurrency and long CoT scenarios (consuming even higher runtime than the
forward pipeline itself). In this paper, we first find that the current-step
query state can be accurately approximated in a unified manner from a short
window of recent queries, enabling training-free query-aware sparsity without
waiting in the decoding loop. We propose AsyncSpade, an asynchronous framework
for efficient TTS built on two core components: (1) a novel light-weight
temporal-regressive module that predicts the next-token query state; (2) an
asynchronous and disaggregated framework that decouples the KV cache filtering
from the auto-regressive decoding loop, overlapping the token-level KV
selection with the forward inference computation through asynchronism. To our
knowledge, AsyncSpade is the first to eliminate the sequential dependence
without sacrificing model performance. We validate the effectiveness of
AsyncSpade on common LLM serving setups with an A100 node, where AsyncSpade
fully overlaps KV-cache operations with the inference pipeline, achieving
theoretical optimal time-per-output-token (TPOT). Specifically, AsyncSpade
delivers over 20% reduction on TPOT compared to SoTA baseline (i.e. Quest) and
at least 50% TPOT reduction compared to full attention on Qwen3-8B and
Qwen3-32B models, while matching or surpassing their accuracy on various TTS
benchmarks (AIME-24/25, GPQA-Diamond, MATH-500).

</details>


### [27] [Can Lessons From Human Teams Be Applied to Multi-Agent Systems? The Role of Structure, Diversity, and Interaction Dynamics](https://arxiv.org/abs/2510.07488)
*Rasika Muralidharan,Jaewoon Kwak,Jisun An*

Main category: cs.CL

TL;DR: 本文设计了大语言模型驱动的多智能体团队框架，分析团队结构和多样性，发现在多个任务中平级结构胜于分层结构，多样性的作用复杂，协作有优势但融合有难题。


<details>
  <summary>Details</summary>
Motivation: 当前基于大型语言模型的多智能体系统逐渐流行，但团队动态的研究较少，因此借鉴人类团队科学理论，探索智能体团队的基本特征。

Method: 提出了一个多智能体框架，仿照人类团队科学，考察团队结构、多样性与互动动态，并在四项任务上评估团队表现。

Result: 平级团队在多项推理任务中优于分层团队，多样性不是单纯利好。代理在事后反思时既认可协作优势也发现沟通整合等协调障碍。

Conclusion: 平级团队比分层团队表现更好，团队多样性对表现有复杂影响，代理间存在协作与整合上的挑战。

Abstract: Multi-Agent Systems (MAS) with Large Language Model (LLM)-powered agents are
gaining attention, yet fewer studies explore their team dynamics. Inspired by
human team science, we propose a multi-agent framework to examine core aspects
of team science: structure, diversity, and interaction dynamics. We evaluate
team performance across four tasks: CommonsenseQA, StrategyQA, Social IQa, and
Latent Implicit Hate, spanning commonsense and social reasoning. Our results
show that flat teams tend to perform better than hierarchical ones, while
diversity has a nuanced impact. Interviews suggest agents are overconfident
about their team performance, yet post-task reflections reveal both
appreciation for collaboration and challenges in integration, including limited
conversational coordination.

</details>


### [28] [Can Speech LLMs Think while Listening?](https://arxiv.org/abs/2510.07497)
*Yi-Jen Shih,Desh Raj,Chunyang Wu,Wei Zhou,SK Bong,Yashesh Gaur,Jay Mahadeokar,Ozlem Kalinli,Mike Seltzer*

Main category: cs.CL

TL;DR: 本论文提出链式思维微调和熵指标，显著提升语音大模型的推理准确率，并通过提前推理和偏好优化，有效降低语音交互响应时延，实现高效语音智能体。


<details>
  <summary>Details</summary>
Motivation: 语音大语言模型近期取得进步，使得语音交互更顺畅。但这些系统在复杂推理任务上表现不佳。受文本链式思维（CoT）提升文本LLM推理能力的启发，论文旨在探索CoT方法对多流语音LLM推理性能的影响，并解决语音响应的时延问题。

Method: 采用链式思维（CoT）微调对多流语音LLM进行训练，提升推理能力。提出“问题完整性”熵指标，以指导模型在用户语音问题未结束前提前开始推理，从而降低响应时延。同时，利用直接偏好优化（DPO）技术进一步优化准确率—时延的帕累托前沿，基于拒绝采样生成偏好数据进行训练。

Result: 链式思维微调使语音LLM在语音推理任务上的准确率平均提升2.4倍。问题完整性指标比启发式算法能更好地平衡准确率与时延，在同等时延情况下，ARC-Easy准确率提高4%。通过DPO微调模型，在保持准确率的前提下，时延减少了70%。

Conclusion: 链式思维微调可显著提升语音LLM的推理能力，问题完整性指标能智能调节推理时机有效兼顾时延与准确率。结合DPO优化，实现语音LLM在准确率与时延上的大幅提升，将助力语音智能体更高效智能地响应复杂查询。

Abstract: Recent advances in speech large language models (speech LLMs) have enabled
seamless spoken interactions, but these systems still struggle with complex
reasoning tasks. Previously, chain-of-thought (CoT) prompting or fine-tuning
has been to shown to significantly improve the reasoning abilities of
text-based LLMs. In this work, we investigate the effect of CoT fine-tuning for
multi-stream speech LLMs, demonstrating that reasoning in text space improves
the accuracy of speech LLMs by 2.4x, on average, over a suite of spoken
reasoning tasks. Beyond accuracy, the latency of the spoken response is a
crucial factor for interacting with voice-based agents. Inspired by the human
behavior of "thinking while listening," we propose methods to reduce the
additional latency from reasoning by allowing the model to start reasoning
before the user query has ended. To achieve this, we introduce an entropy-based
metric, "question completeness," which acts as an indicator to guide the model
on the optimal time to start reasoning. This method provides greater control
over the accuracy-latency trade-off compared with heuristic-based approaches
and, under equivalent latency conditions, yields a 4% accuracy gain on
ARC-Easy. Finally, we use Direct Preference Optimization (DPO) on preference
data created using rejection sampling to push the accuracy-latency pareto
frontier further, resulting in a 70% reduction in latency without loss in
accuracy.

</details>


### [29] [When Thoughts Meet Facts: Reusable Reasoning for Long-Context LMs](https://arxiv.org/abs/2510.07499)
*Soyeong Jeong,Taehee Jung,Sung Ju Hwang,Joo-Kyung Kim,Dongyeop Kang*

Main category: cs.CL

TL;DR: 通过构建和优化思考模板，引导长上下文语言模型实现更优的多跳推理，显著提升了性能，且可迁移至小型开源模型。


<details>
  <summary>Details</summary>
Motivation: 长上下文语言模型（LCLMs）能够处理大量token，但简单地输入更多文档并不能有效地连接证据，因此如何提升模型多跳推理能力成为挑战。

Method: 提出了“思考模板”（thought templates）框架，将推理过程转化为可复用的思考缓存，并通过迭代自然语言反馈持续优化模板，从而结构化整合证据，指导多跳推理。该方法可在训练数据基础上更新模板。

Result: 在多种基准测试和不同LCLM模型中，方法在基于检索和非检索场景下均优于强基线。此外，优化后的思考模板也可被精炼到较小的开源模型，展现其广泛适用性和推理过程透明性。

Conclusion: 提出的ToTAL框架通过思考模板增强了长上下文语言模型的多跳推理能力，并能够被迁移到小模型，提升模型性能和推理可解释性。

Abstract: Recent Long-Context Language Models (LCLMs) can process hundreds of thousands
of tokens in a single prompt, enabling new opportunities for
knowledge-intensive multi-hop reasoning by integrating large sets of retrieved
documents or, in some cases, directly all necessary information. However,
simply feeding more documents into the context window fails to capture how
evidence should be connected. We address this gap with thought templates, which
recast reasoning as reusable thought caches, derived from prior problem solving
traces, structuring how evidence is combined and guiding multi-hop inference
with factual documents. To keep these templates effective, we propose an update
strategy that iteratively refines templates derived from training data through
natural-language feedback. Across diverse benchmarks and LCLM families, our
approach delivers consistent gains over strong baselines in both
retrieval-based and retrieval-free settings. Furthermore, we show that
optimized templates can be distilled into smaller open-source models,
demonstrating its broad applicability and transparent reasoning reuse. We refer
to our framework as Thought Template Augmented LCLMs (ToTAL).

</details>


### [30] [ParsTranslit: Truly Versatile Tajik-Farsi Transliteration](https://arxiv.org/abs/2510.07520)
*Rayyan Merchant,Kevin Tang*

Main category: cs.CL

TL;DR: 本文提出了用于塔吉克语与波斯语（Farsi）双向音译的新序列到序列模型，结合所有可用数据集并自建新数据集，实现了跨领域高性能音译（chrF++最高92.28），首次设立全面基准，并开源模型与数据，助力相关交流与研究。


<details>
  <summary>Details</summary>
Motivation: 波斯语有两种主要书写标准：阿富汗和伊朗使用的Perso-Arabic脚本，以及塔吉克斯坦使用的Tajik-Cyrillic脚本。虽然三国口语方言差异不大，但不同书写系统导致文本无法简单一对一映射，妨碍了书面沟通及交流。当前机器音译系统仅限于自己创建的数据集（如古诗或词表），缺乏广泛的适用性，且各数据域的差异掩盖了任务的真实难度。作者动机是建立能处理多域文本的普适音译模型。

Method: 作者提出了新的序列到序列（sequence-to-sequence）模型，采用所有已公开数据集，并额外自建两个新数据集。模型旨在实现Tajik-Farsi之间的高效音译，并进行跨领域性能评估。

Result: 模型在不同域上均取得良好效果，为任务难度提供更清晰认识，建立了综合性可比基准。从Farsi到Tajik的chrF++和标准化CER分别达到87.91和0.05，从Tajik到Farsi分别为92.28和0.04。

Conclusion: 作者提出的音译模型在多数据域均表现优异，并公开了数据集和代码，为Tajik-Farsi机器音译任务提供了全面基准和实用工具，有助于促进波斯语语种间的交流。

Abstract: As a digraphic language, the Persian language utilizes two written standards:
Perso-Arabic in Afghanistan and Iran, and Tajik-Cyrillic in Tajikistan. Despite
the significant similarity between the dialects of each country, script
differences prevent simple one-to-one mapping, hindering written communication
and interaction between Tajikistan and its Persian-speaking ``siblings''. To
overcome this, previously-published efforts have investigated machine
transliteration models to convert between the two scripts. Unfortunately, most
efforts did not use datasets other than those they created, limiting these
models to certain domains of text such as archaic poetry or word lists. A truly
usable transliteration system must be capable of handling varied domains,
meaning that suck models lack the versatility required for real-world usage.
The contrast in domain between data also obscures the task's true difficulty.
We present a new state-of-the-art sequence-to-sequence model for Tajik-Farsi
transliteration trained across all available datasets, and present two datasets
of our own. Our results across domains provide clearer understanding of the
task, and set comprehensive comparable leading benchmarks. Overall, our model
achieves chrF++ and Normalized CER scores of 87.91 and 0.05 from Farsi to Tajik
and 92.28 and 0.04 from Tajik to Farsi. Our model, data, and code are available
at https://anonymous.4open.science/r/ParsTranslit-FB30/.

</details>


### [31] [OWL: Overcoming Window Length-Dependence in Speculative Decoding for Long-Context Inputs](https://arxiv.org/abs/2510.07535)
*Jaeseong Lee,seung-won hwang,Aurick Qiao,Gabriele Oliaro,Ye Wang,Samyam Rajbhandari*

Main category: cs.CL

TL;DR: 本文发现现有大语言模型快速推理方案在长文本上效率大幅下滑，提出了OWL新模型和长上下文评测基准，针对性创新设计后，OWL在长文本下生成速度和接受长度均显著优于主流方法。


<details>
  <summary>Details</summary>
Motivation: 现有的Speculative decoding方法在主流评测场景（短上下文）表现良好，但在实际长上下文处理任务中效果大幅下降，有时甚至比不使用该方法还慢。因此需要新的方法与公开评测基准来解决长上下文推理中的性能瓶颈。

Method: 提出了OWL新模型，其包含三个关键创新：1）基于LSTM、仅依赖最后token状态的drafter结构，2）在verifier中引入特殊[SPEC] token，使drafter能获得更丰富表征，3）将树状与非树状推理算法进行混合以提升性能。同时发布了长上下文专用评测集LongSpecBench。

Result: OWL在长上下文输入下，接受长度约为EAGLE3的5倍，且推理速度显著优于现有方法。

Conclusion: OWL模型显著提升了大语言模型在长上下文推理下的生成速度和效率，远超主流现有方法。

Abstract: Speculative decoding promises faster inference for large language models
(LLMs), yet existing methods fail to generalize to real-world settings.
Benchmarks typically assume short contexts (e.g., 2K tokens), whereas practical
workloads involve long contexts. We find current approaches degrade severely
with long contexts; for instance, EAGLE3 even slows down the generation speed
by 0.81x. We address these limitations by releasing a new long-context
benchmark (LongSpecBench) and introducing a novel model (OWL). OWL achieves
about 5x higher acceptance length than EAGLE3 on long-context inputs through
three innovations: (1) an LSTM-based drafter conditioned only on the last-token
state, making it generalize to various lengths, (2) a special token [SPEC] in
the verifier that produces richer representation for drafter, and (3) a hybrid
algorithm combining both tree and non-tree decoding methods. We release all
code and datasets to advance future research.

</details>


### [32] [Deploying Tiny LVLM Judges for Real-World Evaluation of Chart Models: Lessons Learned and Best Practices](https://arxiv.org/abs/2510.07545)
*Md Tahmid Rahman Laskar,Mohammed Saidul Islam,Ridwan Mahbub,Mizanur Rahman,Amran Bhuiyan,Israt Jahan,Mir Tafseer Nayeem,Shafiq Joty,Enamul Hoque,Jimmy Huang*

Main category: cs.CL

TL;DR: 本文针对小型视觉语言模型（≤2B参数）在图表评测中的低性能提出多标准提示和领域适应微调两种方法。实验发现这些策略显著提升了小模型ChartJudge的通用性与鲁棒性，且在低成本评测需求下优于传统大模型；多标准提示揭示大模型在复合任务上的弱点。


<details>
  <summary>Details</summary>
Motivation: 现有7B参数LVLM虽能在图表理解中胜任自动评审，但小型模型（≤2B参数）在资源受限环境下表现不佳，阻碍真实场景应用。论文旨在通过降低评估成本，提升小模型性能。

Method: 采用多标准提示，将多个评测标准合并为一个查询；领域自适应迁移学习，在合成图表判断数据上对2B参数的LVLM微调；详细跨图表类型与查询复杂度分析模型表现。

Result: 多标准提示揭示了鲁棒性缺陷，导致7B参数模型（如LLaVA-Critic）性能大幅下降；领域适应微调后2B参数ChartJudge可在跨数据集知识迁移中有效提升专用性，展现优秀低成本评测能力。

Conclusion: 通过多标准提示和领域自适应迁移学习方法，2B参数的小型LVLM（ChartJudge）能实现高效、低成本的图表推理评测。微调后的ChartJudge在跨数据集的知识迁移及专用性上表现突出，模型规模、提示设计和迁移能力的权衡可提升评测系统的实用性。

Abstract: Large Vision-Language Models (LVLMs) with only 7B parameters have shown
promise as automated judges in chart comprehension tasks. However, tiny models
(<=2B parameters) still perform poorly as judges, limiting their real-world use
in resource-constrained settings. To address this, we propose two approaches to
ensure cost-efficient evaluation: (i) multi-criteria prompting, which combines
separate evaluation criteria into a single query, and (ii) domain-adaptive
transfer learning, in which we fine-tune a 2B-parameter LVLM on synthetic
judgments in a chart dataset to create the ChartJudge. Experiments show that
multi-criteria prompting exposes robustness gaps, which led to a huge drop in
performance for 7B models, including specialized LVLM judges like LLaVA-Critic.
In addition, we find that our tiny LVLM (ChartJudge) can effectively transfer
knowledge from one dataset to another to make it a more specialized model. Our
fine-grained analysis across chart types and query complexities offers
actionable insights into trade-offs between model size, prompt design, and
transferability, enabling scalable, low-cost evaluation for chart reasoning
tasks. Our code and the data will be made publicly available.

</details>


### [33] [Multi-Task Pre-Finetuning of Lightweight Transformer Encoders for Text Classification and NER](https://arxiv.org/abs/2510.07566)
*Junyi Zhu,Savas Ozkan,Andrea Maracani,Sinan Mutlu,Cho Jung Min,Mete Ozay*

Main category: cs.CL

TL;DR: 作者针对移动端 NLP 任务，提出基于 LoRA 的多任务预微调框架，有效提升了 NER 和文本分类性能，并解决了传统多任务冲突问题，兼具实用性和效率。


<details>
  <summary>Details</summary>
Motivation: 移动端部署 NLP 模型需要兼顾任务适应性和计算、存储效率。传统多任务预微调方法存在优化冲突，影响整体表现。

Method: 提出了一种基于任务主导 LoRA 模块的多任务预微调框架，将轻量化 BERT 编码器与模块化适配器结合，采用单一共享主干的微调方式，实现任务之间的可适配性和效率。

Result: 该方法在21个下游任务上，实体识别（NER）平均提升0.8%，文本分类平均提升8.8%，接近单独预调的效果，同时满足移动端部署需求。

Conclusion: 所提方法能在保持模型轻量化的基础上，大幅提升不同 NLP 任务的适应性和表现，适用于多样化的移动端应用。

Abstract: Deploying natural language processing (NLP) models on mobile platforms
requires models that can adapt across diverse applications while remaining
efficient in memory and computation. We investigate pre-finetuning strategies
to enhance the adaptability of lightweight BERT-like encoders for two
fundamental NLP task families: named entity recognition (NER) and text
classification. While pre-finetuning improves downstream performance for each
task family individually, we find that na\"ive multi-task pre-finetuning
introduces conflicting optimization signals that degrade overall performance.
To address this, we propose a simple yet effective multi-task pre-finetuning
framework based on task-primary LoRA modules, which enables a single shared
encoder backbone with modular adapters. Our approach achieves performance
comparable to individual pre-finetuning while meeting practical deployment
constraint. Experiments on 21 downstream tasks show average improvements of
+0.8% for NER and +8.8% for text classification, demonstrating the
effectiveness of our method for versatile mobile NLP applications.

</details>


### [34] [Linguistic Patterns in Pandemic-Related Content: A Comparative Analysis of COVID-19, Constraint, and Monkeypox Datasets](https://arxiv.org/abs/2510.07579)
*Mkululi Sikosana,Sean Maudsley-Barton,Oluwaseun Ajao*

Main category: cs.CL

TL;DR: 本文用计算语言学方法分析疫情网络话语，发现虚假健康信息可读性较低且情感化强，可能更具欺骗性；语言风格特征可辅助检测，同时为公共卫生传播与危机沟通理论提供启示，但目前分析方法仍需改进。


<details>
  <summary>Details</summary>
Motivation: 应对网络上的健康虚假信息和事实性传播之间的语言差异，提升检测虚假健康信息的能力，并改善公共卫生传播策略。

Method: 计算语言学方法分析三组疫情相关语料库，分别是COVID-19虚假叙述、一般COVID-19内容、以及猴痘相关帖子，通过可读性、修辞标记和劝服性语言的比较，统计并分析其差异。

Result: COVID-19虚假信息的可读性显著较低，恐惧或劝服性词汇的出现频率为其他数据集的两倍，感叹号使用极少（与猴痘内容的更具情绪化风格形成对比），显示虚假信息文本更复杂，情感化特征明显，这可能增强其可信度。

Conclusion: 文章发现语言风格（复杂叙述和情感线索的结合）可作为识别数字健康虚假信息的指示器，有助于检测技术和理论建模，但分析也存在方法上的局限，后续研究需改进语料库和方法。

Abstract: This study conducts a computational linguistic analysis of pandemic-related
online discourse to examine how language distinguishes health misinformation
from factual communication. Drawing on three corpora: COVID-19 false narratives
(n = 7588), general COVID-19 content (n = 10700), and Monkeypox-related posts
(n = 5787), we identify significant differences in readability, rhetorical
markers, and persuasive language use. COVID-19 misinformation exhibited
markedly lower readability scores and contained over twice the frequency of
fear-related or persuasive terms compared to the other datasets. It also showed
minimal use of exclamation marks, contrasting with the more emotive style of
Monkeypox content. These patterns suggest that misinformation employs a
deliberately complex rhetorical style embedded with emotional cues, a
combination that may enhance its perceived credibility. Our findings contribute
to the growing body of work on digital health misinformation by highlighting
linguistic indicators that may aid detection efforts. They also inform public
health messaging strategies and theoretical models of crisis communication in
networked media environments. At the same time, the study acknowledges
limitations, including reliance on traditional readability indices, use of a
deliberately narrow persuasive lexicon, and reliance on static aggregate
analysis. Future research should therefore incorporate longitudinal designs,
broader emotion lexicons, and platform-sensitive approaches to strengthen
robustness.

</details>


### [35] [IASC: Interactive Agentic System for ConLangs](https://arxiv.org/abs/2510.07591)
*Chihiro Taguchi,Richard Sproat*

Main category: cs.CL

TL;DR: 本文提出了利用大语言模型自动构造人工语言的系统流程，展示了LLM在音系、词汇和语法生成等环节的应用潜力，但也指出不同模型和任务间存在能力差异，尤其在低资源语言翻译上仍有提升空间。


<details>
  <summary>Details</summary>
Motivation: 本文旨在利用大语言模型（LLM）辅助构造人工语言，探索其在语言学知识和能力上的表现，同时也关注其对高资源语言到低资源语言翻译的潜力。

Method: 系统采用模块化流程：先由LLM基于反馈机制构建目标语言音系，再由英文句子转换成具备形态句法特征的标注语料，进而构建词典和正字法（使用现有文字系统），最终自动生成语法手册，并可持续进行句子翻译。

Result: 发现不同LLM及不同语言学设定之间能力差异较大，常见语言结构处理较易，罕见结构较难。用于高到低资源语言翻译目前效果一般，但有潜在改进空间。

Conclusion: LLM在构造语言和处理语言学任务时表现出一定能力，尤其在常见语言结构上，但在低资源语言翻译和复杂语言学规则方面尚需提升。作者认为未来系统优化有望带来实质进步。

Abstract: We present a system that uses LLMs as a tool in the development of
Constructed Languages. The system is modular in that one first creates a target
phonology for the language using an agentic approach that refines its output at
each step with commentary feedback on its previous attempt. Next, a set of
sentences is 'translated' from their English original into a morphosyntactic
markup that reflects the word order and morphosyntactic feature specifications
of the desired target language, with affixes represented as morphosyntactic
feature bundles. From this translated corpus, a lexicon is constructed using
the phonological model and the set of morphemes (stems and affixes) extracted
from the 'translated' sentences. The system is then instructed to provide an
orthography for the language, using an existing script such as Latin or
Cyrillic. Finally, the system writes a brief grammatical handbook of the
language. The system can also translate further sentences into the target
language.
  Our goal is twofold. First, we hope that these tools will be fun to use for
creating artificially constructed languages. Second, we are interested in
exploring what LLMs 'know' about language-not what they know about any
particular language or linguistic phenomenon, but how much they know about and
understand language and linguistic concepts. As we shall see, there is a fairly
wide gulf in capabilities both among different LLMs and among different
linguistic specifications, with it being notably easier for systems to deal
with more common patterns than rarer ones. An additional avenue that we explore
is the application of our approach to translating from high-resource into
low-resource languages. While the results so far are mostly negative, we
provide some evidence that an improved version of the present system could
afford some real gains in such tasks.
  https://github.com/SakanaAI/IASC

</details>


### [36] [Vocabulary embeddings organize linguistic structure early in language model training](https://arxiv.org/abs/2510.07613)
*Isabel Papadimitriou,Jacob Prince*

Main category: cs.CL

TL;DR: 本文分析了LLMs在训练中词汇嵌入向量的几何结构变化，发现嵌入很快“学会”语义和句法特征，高频词与功能词收敛快，低频词与实词保持更多初始特性。这揭示了词嵌入结构的动态演化路径及其与语言能力提升之间的联系。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型（LLMs）在训练过程中输入词汇嵌入向量的几何结构如何形成、变化，以及这些嵌入结构与语言的语义、句法和词频等特征的相关性。

Method: 使用表示相似性分析方法，对开放源代码的Pythia 12B和OLMo 7B两个模型的输入嵌入和输出嵌入进行实验。研究训练过程中嵌入向量几何结构与语义、句法及词频特征的相关性变化。

Result: （1）词汇嵌入的几何结构在训练初期快速与语义和句法特征高度相关；（2）高频词和功能词的嵌入向量较低频词和实词更快收敛到最终形态，而后者在训练结束仍保留部分初始随机偏置。

Conclusion: 词汇嵌入结构形成过程中，语义、句法和词频扮演着不同角色，高频和功能词收敛更快。研究嵌入几何结构的演化有助于理解语言模型能力提升的机制。

Abstract: Large language models (LLMs) work by manipulating the geometry of input
embedding vectors over multiple layers. Here, we ask: how are the input
vocabulary representations of language models structured, and how and when does
this structure evolve over training? To answer this question, we use
representational similarity analysis, running a suite of experiments that
correlate the geometric structure of the input embeddings and output embeddings
of two open-source models (Pythia 12B and OLMo 7B) with semantic, syntactic,
and frequency-based metrics over the course of training. Our key findings are
as follows: 1) During training, the vocabulary embedding geometry quickly
converges to high correlations with a suite of semantic and syntactic features;
2) Embeddings of high-frequency and function words (e.g., "the," "of") converge
to their final vectors faster than lexical and low-frequency words, which
retain some alignment with the bias in their random initializations. These
findings help map the dynamic trajectory by which input embeddings organize
around linguistic structure, revealing distinct roles for word frequency and
function. Our findings motivate a deeper study of how the evolution of
vocabulary geometry may facilitate specific capability gains during model
training.

</details>


### [37] [Toward Reliable Clinical Coding with Language Models: Verification and Lightweight Adaptation](https://arxiv.org/abs/2510.07629)
*Zhangdie Yuan,Han-Chin Shing,Mitch Strong,Chaitanya Shivade*

Main category: cs.CL

TL;DR: 作者提出通过轻量级方法（如提示词调整和微调）和临床编码验证任务提升LLM在医学编码中的准确性，并推出了新门诊编码数据集，实验证明能显著改善层级接近但错误类型的编码问题。


<details>
  <summary>Details</summary>
Motivation: 准确的临床编码对于医疗文档、计费和决策非常重要，然而现有的大型语言模型（LLMs）在此任务上表现不佳，且常用的完全匹配评估方法忽略了模型预测结果在编码层级上的接近但仍然错误的情况。作者关注于提升编码准确性，并减少这类‘层级接近型错误’。

Method: 分析现有LLM编码错误类型，采取轻量级干预方法（如提示词工程和小规模微调），并引入临床编码验证任务作为独立或管道步骤。此外，发布了一个由专家双重注释、包含ICD-10编码的门诊病历新基准数据集。

Result: 轻量级干预（提示词工程和小规模微调）能在不增加计算资源的情况下提升编码准确性。编码验证作为独立步骤或管道环节，有效减少了‘层级接近但错误’的编码失误。新数据集更好地缓解了现有数据集存在的证据不完整和住院偏向的问题。

Conclusion: 临床编码验证不仅能有效提升基于LLM的医疗编码准确率，也是构建医学编码系统时可靠和实用的一步。作者的数据集和方法为进一步优化自动编码提供了重要资源和方向。

Abstract: Accurate clinical coding is essential for healthcare documentation, billing,
and decision-making. While prior work shows that off-the-shelf LLMs struggle
with this task, evaluations based on exact match metrics often overlook errors
where predicted codes are hierarchically close but incorrect. Our analysis
reveals that such hierarchical misalignments account for a substantial portion
of LLM failures. We show that lightweight interventions, including prompt
engineering and small-scale fine-tuning, can improve accuracy without the
computational overhead of search-based methods. To address hierarchically
near-miss errors, we introduce clinical code verification as both a standalone
task and a pipeline component. To mitigate the limitations in existing
datasets, such as incomplete evidence and inpatient bias in MIMIC, we release
an expert double-annotated benchmark of outpatient clinical notes with ICD-10
codes. Our results highlight verification as an effective and reliable step
toward improving LLM-based medical coding.

</details>


### [38] [Role-Conditioned Refusals: Evaluating Access Control Reasoning in Large Language Models](https://arxiv.org/abs/2510.07642)
*Đorđe Klisura,Joseph Khoury,Ashish Kundu,Ram Krishnan,Anthony Rios*

Main category: cs.CL

TL;DR: 本文针对大型语言模型访问控制问题，提出了基于角色权限的数据集和三种应对方案。生成-验证流程有助于提升模型拒绝未授权请求的能力，微调则兼顾安全与准确性。复杂权限规则仍是难题，相关数据和代码已公开。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在实际应用中的访问控制问题，即它们有时会违反安全策略，输出不受限制的内容。作者希望提升模型在不同权限角色下的拒绝能力，使其能够根据授权做出正确反应。

Method: 作者扩展了Spider和BIRD text-to-SQL数据集，为其增添了真实的PostgreSQL基于角色的访问控制策略。并采用三种方案进行对比：1）零样本或少样本提示，2）生成-验证两步流程，通过专门流程对SQL合规性进行检查，3）通过LoRA微调模型，使模型直接学习权限意识。

Result: 显式验证框架（生成-验证两步流程）提升了拒绝精度，减少了错误授权；微调模型实现了安全性和实用性之间的更好平衡，尤其在执行准确性上更强。所有方法在面对更长更复杂的访问控制策略时表现都会下降。

Conclusion: 研究显示生成-验证流程对于达到高拒绝精度更有效，微调则有助于提升安全与实用性的平衡。同时，复杂策略对所有方案都形成挑战。研究还发布了RBAC增强数据集和代码，促进领域发展。

Abstract: Access control is a cornerstone of secure computing, yet large language
models often blur role boundaries by producing unrestricted responses. We study
role-conditioned refusals, focusing on the LLM's ability to adhere to access
control policies by answering when authorized and refusing when not. To
evaluate this behavior, we created a novel dataset that extends the Spider and
BIRD text-to-SQL datasets, both of which have been modified with realistic
PostgreSQL role-based policies at the table and column levels. We compare three
designs: (i) zero or few-shot prompting, (ii) a two-step generator-verifier
pipeline that checks SQL against policy, and (iii) LoRA fine-tuned models that
learn permission awareness directly. Across multiple model families, explicit
verification (the two-step framework) improves refusal precision and lowers
false permits. At the same time, fine-tuning achieves a stronger balance
between safety and utility (i.e., when considering execution accuracy). Longer
and more complex policies consistently reduce the reliability of all systems.
We release RBAC-augmented datasets and code.

</details>


### [39] [Banking Done Right: Redefining Retail Banking with Language-Centric AI](https://arxiv.org/abs/2510.07645)
*Xin Jie Chua,Jeraelyn Ming Li Tan,Jia Xuan Tan,Soon Chang Poh,Yi Xian Goh,Debbie Hui Tian Choong,Chee Mun Foong,Sze Jue Yang,Chee Seng Chan*

Main category: cs.CL

TL;DR: Ryt AI是全球首个被监管批准的银行级对话AI，基于内部自研LLM，通过多代理和安全合规机制，让顾客用自然语言安全完成核心金融交易，改变传统银行交互模式。


<details>
  <summary>Details</summary>
Motivation: 现有银行对话系统受限于仅能提供建议或支持功能，缺乏直接执行核心金融交易的能力；亟需能作为主界面的AI系统，提升银行业务体验与效率。

Method: 提出了基于大模型的agent框架Ryt AI，由四个子代理协作完成核心银行任务，采用自研LLM ILMU及LoRA适配器，并结合确定性护栏、人机确认与无状态审计体系保障合规与安全。

Result: Ryt AI已在全球范围内作为主银行界面部署，实现客户可通过自然语言完成金融交易，且满足监管严格要求，实现安全合规与高效操作。

Conclusion: Ryt AI成功实现了全球首个被监管机构批准的银行自然语言对话界面，证明了自然语言接口能安全、合规地执行核心金融业务。

Abstract: This paper presents Ryt AI, an LLM-native agentic framework that powers Ryt
Bank to enable customers to execute core financial transactions through natural
language conversation. This represents the first global regulator-approved
deployment worldwide where conversational AI functions as the primary banking
interface, in contrast to prior assistants that have been limited to advisory
or support roles. Built entirely in-house, Ryt AI is powered by ILMU, a
closed-source LLM developed internally, and replaces rigid multi-screen
workflows with a single dialogue orchestrated by four LLM-powered agents
(Guardrails, Intent, Payment, and FAQ). Each agent attaches a task-specific
LoRA adapter to ILMU, which is hosted within the bank's infrastructure to
ensure consistent behavior with minimal overhead. Deterministic guardrails,
human-in-the-loop confirmation, and a stateless audit architecture provide
defense-in-depth for security and compliance. The result is Banking Done Right:
demonstrating that regulator-approved natural-language interfaces can reliably
support core financial operations under strict governance.

</details>


### [40] [OBCache: Optimal Brain KV Cache Pruning for Efficient Long-Context LLM Inference](https://arxiv.org/abs/2510.07651)
*Yuzhe Gu,Xiyu Liang,Jiaojiao Zhao,Enmao Diao*

Main category: cs.CL

TL;DR: 该论文提出了一种基于输出感知的缓存驱逐算法OBCache，使大语言模型在长序列处理时更高效、准确，相比现有启发式方法取得了卓越效果。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）上下文窗口的扩展，缓存全部key-value（KV）状态带来了显著的内存开销，现有方法通常利用注意力稀疏性进行缓存驱逐，但主要依赖启发式方法排名token，未能充分考虑token对注意力输出的真实影响。

Method: 提出Optimal Brain Cache（OBCache）框架，将缓存驱逐视为一种逐层结构化剪枝问题。借鉴Optimal Brain Damage（OBD）理论，通过量化token对注意力输出的扰动，为孤立的key、孤立的value及key-value对推导出封闭形式评分，从而衡量token显著性。这些评分同时结合注意力权重、value状态和注意力输出等信息，实现输出感知的驱逐评分。

Result: 在LLaMA和Qwen等大模型上的实验表明，用OBCache提出的输出感知评分替换现有工作的启发式评分后，无论是在不同query位置估算token显著性，都能持续提升长上下文场景下的准确率。

Conclusion: OBCache有效改善长上下文大模型KV缓存驱逐的效果，相较于传统启发式方法，能够更好地权衡token实际影响与驱逐策略，显著提升推理表现。

Abstract: Large language models (LLMs) with extended context windows enable powerful
downstream applications but impose significant memory overhead, as caching all
key-value (KV) states scales linearly with sequence length and batch size.
Existing cache eviction methods address this by exploiting attention sparsity,
yet they typically rank tokens heuristically using accumulated attention
weights without considering their true impact on attention outputs. We propose
Optimal Brain Cache (OBCache), a principled framework that formulates cache
eviction as a layer-wise structured pruning problem. Building upon the Optimal
Brain Damage (OBD) theory, OBCache quantifies token saliency by measuring the
perturbation in attention outputs induced by pruning tokens, with closed-form
scores derived for isolated keys, isolated values, and joint key-value pairs.
Our scores account not only for attention weights but also for information from
value states and attention outputs, thereby enhancing existing eviction
strategies with output-aware signals. Experiments on LLaMA and Qwen models
demonstrate that replacing the heuristic scores in existing works, which
estimate token saliency across different query positions, with OBCache's
output-aware scores consistently improves long-context accuracy.

</details>


### [41] [Textual Entailment and Token Probability as Bias Evaluation Metrics](https://arxiv.org/abs/2510.07662)
*Virginia K. Felkner,Allison Lim,Jonathan May*

Main category: cs.CL

TL;DR: 本研究比较了两种常用语言模型偏见度量方式（TP和NLI），发现两者差异显著且各有局限，建议结合使用多种评估方法。


<details>
  <summary>Details</summary>
Motivation: 目前语言模型中的社会偏见主要通过token probability（TP）指标来测量，但这一指标与实际应用场景和潜在危害间存在距离。本文尝试探索自然语言推断（NLI）作为更贴近现实的偏见测量方法，寻找更有效的评估工具。

Method: 以TP和NLI为主要偏见衡量指标，进行对比实验，并分析各类NLI指标与TP之间的相关性，以及在检测“去偏见不足”情形时的表现。进一步探讨不同指标对反刻板印象句子表述的敏感性和稳定性。

Result: 实验发现，NLI与TP评估结果相差明显，且不同NLI指标之间和NLI与TP之间相关性很低。NLI指标在检测“去偏见不足”方面更敏感，但容易受反刻板印象表述影响，表现较脆弱。

Conclusion: TP和NLI都不能完美衡量语言模型偏见，无统一“最佳”指标。建议结合TP、NLI及下游任务偏见评估，统一多指标以确保模型偏见评估全面性。

Abstract: Measurement of social bias in language models is typically by token
probability (TP) metrics, which are broadly applicable but have been criticized
for their distance from real-world langugage model use cases and harms. In this
work, we test natural language inference (NLI) as a more realistic alternative
bias metric. We show that, curiously, NLI and TP bias evaluation behave
substantially differently, with very low correlation among different NLI
metrics and between NLI and TP metrics. We find that NLI metrics are more
likely to detect "underdebiased" cases. However, NLI metrics seem to be more
brittle and sensitive to wording of counterstereotypical sentences than TP
approaches. We conclude that neither token probability nor natural language
inference is a "better" bias metric in all cases, and we recommend a
combination of TP, NLI, and downstream bias evaluations to ensure comprehensive
evaluation of language models.
  Content Warning: This paper contains examples of anti-LGBTQ+ stereotypes.

</details>


### [42] [Stress-Testing Model Specs Reveals Character Differences among Language Models](https://arxiv.org/abs/2510.07686)
*Jifan Zhang,Henry Sleight,Andi Peng,John Schulman,Esin Durmus*

Main category: cs.CL

TL;DR: 本论文提出自动化方法压力测试大型语言模型的行为规范，发现超7万例原则冲突及模型分歧，揭示现有规范中的矛盾和解释模糊，为改进AI行为准则提供数据和模式分析。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型（LLM）在训练时越来越多依赖基于AI宪章和模型规范来设定行为准则和伦理原则，但这些规范经常存在内部原则冲突和对复杂场景覆盖不全的问题。为解决这些问题，需要对模型的规范进行系统性压力测试，以发现潜在冲突和不一致。

Method: 作者提出了一套系统性压力测试模型规范的方法，通过自动生成涉及原则权衡的多样化场景，要求模型在无法同时满足多个合法原则时进行选择，并以系统分类法生成多种价值权衡场景。然后，作者对12个主流前沿模型（涵盖Anthropic、OpenAI、Google、xAI等）进行评估，利用价值分类得分测量模型行为分歧。

Result: 压力测试生成了超过70,000个显著行为分歧的案例，实证分析表明这种高分歧强烈预测了模型规范存在底层问题。通过定性分析，发现现有规范中存在原则直接矛盾和解释模糊。此外，生成数据集也揭示了所有前沿模型中的明显不对齐和误拒绝案例，并分析了各模型的价值优先顺序及差异。

Conclusion: 研究提出了一种自动化、多角度压力测试模型规范的方法，有效暴露了现有AI宪章和模型规格中的冲突和不足，为优化LLM行为准则和伦理原则的设定提供了有力工具。

Abstract: Large language models (LLMs) are increasingly trained from AI constitutions
and model specifications that establish behavioral guidelines and ethical
principles. However, these specifications face critical challenges, including
internal conflicts between principles and insufficient coverage of nuanced
scenarios. We present a systematic methodology for stress-testing model
character specifications, automatically identifying numerous cases of principle
contradictions and interpretive ambiguities in current model specs.
  We stress test current model specs by generating scenarios that force
explicit tradeoffs between competing value-based principles. Using a
comprehensive taxonomy we generate diverse value tradeoff scenarios where
models must choose between pairs of legitimate principles that cannot be
simultaneously satisfied. We evaluate responses from twelve frontier LLMs
across major providers (Anthropic, OpenAI, Google, xAI) and measure behavioral
disagreement through value classification scores. Among these scenarios, we
identify over 70,000 cases exhibiting significant behavioral divergence.
Empirically, we show this high divergence in model behavior strongly predicts
underlying problems in model specifications. Through qualitative analysis, we
provide numerous example issues in current model specs such as direct
contradiction and interpretive ambiguities of several principles. Additionally,
our generated dataset also reveals both clear misalignment cases and
false-positive refusals across all of the frontier models we study. Lastly, we
also provide value prioritization patterns and differences of these models.

</details>


### [43] [Large Language Models Meet Virtual Cell: A Survey](https://arxiv.org/abs/2510.07706)
*Krinos Li,Xianglu Xiao,Shenglong Deng,Lucas He,Zijun Zhong,Yuanjie Zou,Zhonghao Zhan,Zheng Hui,Weiye Bao,Guang Yang*

Main category: cs.CL

TL;DR: 本文综述了LLM在虚拟细胞建模领域的应用，建立了应用分类法，系统介绍三大核心任务，指出模型与评测现状及主要挑战。


<details>
  <summary>Details</summary>
Motivation: 当前细胞生物学研究面临对复杂细胞行为建模的挑战，LLMs作为新兴工具，有潜力在虚拟细胞建模与科学任务自动化上带来突破，因此需总结现有进展与挑战，为后续研究提供方向。

Method: 通过文献综合回顾，总结了目前LLMs在虚拟细胞建模中的两种典型应用模式，并针对细胞表征、扰动预测、基因调控三大任务进行系统梳理。

Result: 提出了一套统一的LLM建模分类法，以及针对代表性任务的模型、数据集和评测方法，同时明确了当前在可扩展性、泛化性及可解释性等方面的主要挑战。

Conclusion: 大语言模型（LLMs）在细胞生物学领域可作为强大的工具，用于表征和推断细胞状态，同时帮助科学家完成复杂科研任务。该领域已提出统一的分类法，将现有方法分为Oracle（直接建模细胞）和Agent（协助科学任务）两大模式。

Abstract: Large language models (LLMs) are transforming cellular biology by enabling
the development of "virtual cells"--computational systems that represent,
predict, and reason about cellular states and behaviors. This work provides a
comprehensive review of LLMs for virtual cell modeling. We propose a unified
taxonomy that organizes existing methods into two paradigms: LLMs as Oracles,
for direct cellular modeling, and LLMs as Agents, for orchestrating complex
scientific tasks. We identify three core tasks--cellular representation,
perturbation prediction, and gene regulation inference--and review their
associated models, datasets, evaluation benchmarks, as well as the critical
challenges in scalability, generalizability, and interpretability.

</details>


### [44] [Causality Guided Representation Learning for Cross-Style Hate Speech Detection](https://arxiv.org/abs/2510.07707)
*Chengshuai Zhao,Shu Wan,Paras Sheth,Karan Patwa,K. Selçuk Candan,Huan Liu*

Main category: cs.CL

TL;DR: 本文提出了基于因果图的CADET框架，通过表示学习剖析仇恨言论关键因素，有效提升了模型对多样化与隐性仇恨言论的检测能力，在实验中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论检测模型过于依赖表层语言特征，难以应对不同平台、风格多样化及隐性仇恨言论，且易受标签与平台风格虚假关联影响。

Method: 提出了一种基于因果图的因果表示学习框架CADET，将仇恨言论分解为可解释的潜在因素，并通过控制混杂因素隔离真实仇恨意图，实现反事实推理以识别形式多样的仇恨言论。

Result: CADET能够高度鲁棒地识别不同形式和风格的仇恨言论，在跨平台、风格多样性等挑战性实验中超过了现有方法。

Conclusion: CADET框架在多项实验中表现优异，证明了因果先验在提升泛化性仇恨言论检测方面的潜力。

Abstract: The proliferation of online hate speech poses a significant threat to the
harmony of the web. While explicit hate is easily recognized through overt
slurs, implicit hate speech is often conveyed through sarcasm, irony,
stereotypes, or coded language -- making it harder to detect. Existing hate
speech detection models, which predominantly rely on surface-level linguistic
cues, fail to generalize effectively across diverse stylistic variations.
Moreover, hate speech spread on different platforms often targets distinct
groups and adopts unique styles, potentially inducing spurious correlations
between them and labels, further challenging current detection approaches.
Motivated by these observations, we hypothesize that the generation of hate
speech can be modeled as a causal graph involving key factors: contextual
environment, creator motivation, target, and style. Guided by this graph, we
propose CADET, a causal representation learning framework that disentangles
hate speech into interpretable latent factors and then controls confounders,
thereby isolating genuine hate intent from superficial linguistic cues.
Furthermore, CADET allows counterfactual reasoning by intervening on style
within the latent space, naturally guiding the model to robustly identify hate
speech in varying forms. CADET demonstrates superior performance in
comprehensive experiments, highlighting the potential of causal priors in
advancing generalizable hate speech detection.

</details>


### [45] [MemWeaver: A Hierarchical Memory from Textual Interactive Behaviors for Personalized Generation](https://arxiv.org/abs/2510.07713)
*Shuo Yu,Mingyue Cheng,Daoyu Wang,Qi Liu,Zirui Liu,Ze Guo,Xiaoyu Tao*

Main category: cs.CL

TL;DR: 提出了MemWeaver，通过层次化记忆结构（行为与认知记忆）更深入建模用户文本交互历史，实现更强个性化，实验效果显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着用户与互联网交互从隐式信号（如点击、浏览）转向丰富的显式文本反馈，现有方法未能深度挖掘其中丰富的时间与语义结构，因此需要新的框架从更深入的角度展现和利用用户兴趣动态。

Method: 设计了包含行为记忆和认知记忆的分层记忆架构，将用户所有文本历史整合，捕获时间和语义变化；随后结合LLMs进行生成与推理，并在LaMP基准上实验验证。

Result: MemWeaver 是一个新框架，用于提升文本交互行为驱动下的用户个性化生成任务。它通过将用户的完整文本历史构建为层次化记忆，有效捕捉兴趣随时间的演变及不同活动间的语义联系。框架包含两个互补的记忆单元：行为记忆（具体行为层面）和认知记忆（长期偏好层面），共同为大语言模型（LLMs）提供更深入的个性化推理能力。实验基于LaMP基准，结果证实了MemWeaver 的有效性。

Conclusion: MemWeaver 能以层次化、统一方式存储和利用用户文本历史，使大语言模型在用户个性化任务上表现提升，实验验证了其有效性。

Abstract: The primary form of user-internet engagement is shifting from leveraging
implicit feedback signals, such as browsing and clicks, to harnessing the rich
explicit feedback provided by textual interactive behaviors. This shift unlocks
a rich source of user textual history, presenting a profound opportunity for a
deeper form of personalization. However, prevailing approaches offer only a
shallow form of personalization, as they treat user history as a flat list of
texts for retrieval and fail to model the rich temporal and semantic structures
reflecting dynamic nature of user interests. In this work, we propose
\textbf{MemWeaver}, a framework that weaves the user's entire textual history
into a hierarchical memory to power deeply personalized generation. The core
innovation of our memory lies in its ability to capture both the temporal
evolution of interests and the semantic relationships between different
activities. To achieve this, MemWeaver builds two complementary memory
components that both integrate temporal and semantic information, but at
different levels of abstraction: behavioral memory, which captures specific
user actions, and cognitive memory, which represents long-term preferences.
This dual-component memory serves as a unified representation of the user,
allowing large language models (LLMs) to reason over both concrete behaviors
and abstracted traits. Experiments on the Language Model Personalization (LaMP)
benchmark validate the efficacy of MemWeaver. Our code is
available\footnote{https://github.com/fishsure/MemWeaver}.

</details>


### [46] [SUBQRAG: sub-question driven dynamic graph rag](https://arxiv.org/abs/2510.07718)
*Jiaoyang Li,Junhao Ruan,Shengwei Tang,Saihan Chen,Kaiyan Chang,Yuan Ge,Tong Xiao,Jingbo Zhu*

Main category: cs.CL

TL;DR: 本文提出子问题驱动的多跳问答框架SubQRAG，通过动态扩展知识图和聚合推理证据，有效提升复杂问答的精度和推理深度。


<details>
  <summary>Details</summary>
Motivation: 现有的图检索增强生成（Graph RAG）方法虽然能利用知识图连接大型语料库中的不同事实，但对于复杂的多跳问答任务，往往在深层结构性推理上表现不足，导致证据不完整和错误积累。

Method: 本文提出了一种名为SubQRAG的子问题驱动的框架，通过将复杂问题分解为可验证的有序子问题链，并针对每个子问题从知识图中检索相关三元组。当图中的信息不足时，系统可实时扩展图结构，从源文件中抽取新的三元组，所有用于推理的三元组被聚合到“图记忆”中，形成结构化且可追溯的证据路径，辅助最终答案生成。

Result: 在三个多跳问答基准数据集上的实验表明，SubQRAG在准确匹配（Exact Match）得分等方面取得了持续且显著的提升，表现优于传统的方法。

Conclusion: SubQRAG能够有效提升多跳复杂问答任务的推理深度和可追溯性，相比传统的Graph RAG，能够获得更完整的推理证据和更高的问答准确率。

Abstract: Graph Retrieval-Augmented Generation (Graph RAG) effectively builds a
knowledge graph (KG) to connect disparate facts across a large document corpus.
However, this broad-view approach often lacks the deep structured reasoning
needed for complex multi-hop question answering (QA), leading to incomplete
evidence and error accumulation. To address these limitations, we propose
SubQRAG, a sub-question-driven framework that enhances reasoning depth. SubQRAG
decomposes a complex question into an ordered chain of verifiable
sub-questions. For each sub-question, it retrieves relevant triples from the
graph. When the existing graph is insufficient, the system dynamically expands
it by extracting new triples from source documents in real time. All triples
used in the reasoning process are aggregated into a "graph memory," forming a
structured and traceable evidence path for final answer generation. Experiments
on three multi-hop QA benchmarks demonstrate that SubQRAG achieves consistent
and significant improvements, especially in Exact Match scores.

</details>


### [47] [Multilingual Knowledge Graph Completion via Efficient Multilingual Knowledge Sharing](https://arxiv.org/abs/2510.07736)
*Cunli Mao,Xiaofei Gao,Ran Song,Shizhu He,Shengxiang Gao,Kang Liu,Zhengtao Yu*

Main category: cs.CL

TL;DR: 本文提出通过共享跨语言知识的新MKGC方法（KL-GMoE和IER），在多语言知识图谱补全任务上较现有方法有显著提升，并公开了相关数据和代码。


<details>
  <summary>Details</summary>
Motivation: 现有的MKGC研究低估了LLMs的多语言能力和跨语言知识共享的潜力，难以充分提升多语言知识图谱的完整性。

Method: 提出了KL-GMoE（知识级专家混合模型）和IER（迭代实体重排）两个关键组件，并建设了包含5种语言的mKG数据集进行评测。

Result: 在Hits@1、Hits@3、Hits@10指标上分别较SOTA方法提升了5.47%、3.27%、1.01%；并进一步分析了在未见语言和不平衡语言情况下的知识共享特性。

Conclusion: 新提出的MKGC框架利用跨语言的共享知识，可显著提升知识图谱的多语言补全性能。

Abstract: Large language models (LLMs) based Multilingual Knowledge Graph Completion
(MKGC) aim to predict missing facts by leveraging LLMs' multilingual
understanding capabilities, improving the completeness of multilingual
knowledge graphs (KGs). However, existing MKGC research underutilizes the
multilingual capabilities of LLMs and ignores the shareability of cross-lingual
knowledge. In this paper, we propose a novel MKGC framework that leverages
multilingual shared knowledge to significantly enhance performance through two
components: Knowledge-level Grouped Mixture of Experts (KL-GMoE) and Iterative
Entity Reranking (IER). KL-GMoE efficiently models shared knowledge, while IER
significantly enhances its utilization. To evaluate our framework, we
constructed a mKG dataset containing 5 languages and conducted comprehensive
comparative experiments with existing state-of-the-art (SOTA) MKGC method. The
experimental results demonstrate that our framework achieves improvements of
5.47%, 3.27%, and 1.01% in the Hits@1, Hits@3, and Hits@10 metrics,
respectively, compared with SOTA MKGC method. Further experimental analysis
revealed the properties of knowledge sharing in settings of unseen and
unbalanced languages. We have released the dataset and code for our work on
https://github.com/gaoxiaofei07/KL-GMoE.

</details>


### [48] [ToolExpander: Extending the Frontiers of Tool-Using Reinforcement Learning to Weak LLMs](https://arxiv.org/abs/2510.07737)
*Fu Chen,Peng Wang,Xiyin Li,Wen Li,Shichi Lei,Dongdong Xiang*

Main category: cs.CL

TL;DR: 该论文提出了ToolExpander方法，通过两项创新策略解决弱小模型在GRPO训练中的稳定性和性能不足问题，实验证明能显著提高模型工具使用能力。


<details>
  <summary>Details</summary>
Motivation: GRPO在训练大语言模型时，尤其是小规模模型，易出现响应不准和中途训练崩溃，导致性能提升有限和不稳定。解决这一问题可以扩大GRPO应用价值并提升弱模型能力。

Method: 提出了ToolExpander框架，包含动态多轮硬采样（将难样本替换为高质量示例，并用指数衰减策略降低训练振荡）和自示例化思考（改进GRPO，去除KL损失，引入微弱奖励激励模型生成分析示例），并在实验中进行评估。

Result: ToolExpander在提升LLM工具使用能力方面有显著效果，尤其在小规模模型上，训练稳定性和最终性能均获得改善。

Conclusion: ToolExpander框架能够显著提升资源受限的大语言模型使用工具的能力，尤其对小规模模型提升训练稳定性和整体性能效果更明显。

Abstract: Training Large Language Models (LLMs) with Group Relative Policy Optimization
(GRPO) encounters a significant challenge: models often fail to produce
accurate responses, particularly in small-scale architectures. This limitation
not only diminishes performance improvements and undermines the potential of
GRPO but also frequently leads to mid-training collapse, adversely affecting
stability and final efficacy. To address these issues, we propose ToolExpander,
a novel framework that advances tool-oriented reinforcement learning for
resource-constrained LLMs through two key innovations:(1) Dynamic Multi-Round
Hard Sampling, which dynamically substitutes challenging samples(those without
correct outputs over 10 rollouts) with high-quality few-shot demonstrations
during training, coupled with an exponential learning rate decay strategy to
mitigate oscillations;(2) Self-Exemplifying Thinking, an enhanced GRPO
framework that eliminates KL divergence and incorporates adjusted clipping
coefficients, encouraging models to autonomously generate and analyze few-shot
examples via a minimal additional reward (0.01).Experimental results
demonstrate that ToolExpander significantly enhances tool-using capabilities in
LLMs, especially in weaker small-scale models, improving both training
stability and overall performance.

</details>


### [49] [OpenRubrics: Towards Scalable Synthetic Rubric Generation for Reward Modeling and LLM Alignment](https://arxiv.org/abs/2510.07743)
*Tianci Liu,Ran Xu,Tony Yu,Ilgee Hong,Carl Yang,Tuo Zhao,Haoyu Wang*

Main category: cs.CL

TL;DR: 提出并验证了基于结构性评分准则的奖励建模框架和数据集，有效提升了大模型的自动奖励对齐性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于人类反馈的强化学习奖励模型只依赖标量或双选打分，无法捕捉人类复杂的、多维度价值观；而设计既可靠又可规模化的多维评分准则仍是挑战。

Method: 提出OpenRubrics大规模评分准则数据集及Rubric-RM奖励模型，并结合对比式评分准则生成（CRG）和拒绝采样来保障评分的辨识性和一致性，在多个基准任务上进行实验验证。

Result: Rubric-RM在多个奖励建模基准上比同规模强基线提升6.8%，且用于实际策略模型时能在指令跟随和生物医学领域显著迁移提升。

Conclusion: 利用结构化自然语言评分准则（rubrics）能有效提升自动化奖励建模的多维度可靠性，使其更接近人工评价效果，推动LLM对齐的新范式。

Abstract: Reward modeling lies at the core of reinforcement learning from human
feedback (RLHF), yet most existing reward models rely on scalar or pairwise
judgments that fail to capture the multifaceted nature of human preferences.
Recent studies have explored rubrics-as-rewards (RaR) that uses structured
natural language criteria that capture multiple dimensions of response quality.
However, producing rubrics that are both reliable and scalable remains a key
challenge. In this work, we introduce OpenRubrics, a diverse, large-scale
collection of (prompt, rubric) pairs for training rubric-generation and
rubric-based reward models. To elicit discriminative and comprehensive
evaluation signals, we introduce Contrastive Rubric Generation (CRG), which
derives both hard rules (explicit constraints) and principles (implicit
qualities) by contrasting preferred and rejected responses. We further improve
reliability by enforcing preference-label consistency via rejection sampling to
remove noisy rubrics. Across multiple reward-modeling benchmarks, our
rubric-based reward model, Rubric-RM, surpasses strong size-matched baselines
by 6.8%. These gains transfer to policy models on instruction-following and
biomedical benchmarks. Our results show that rubrics provide scalable alignment
signals that narrow the gap between costly human evaluation and automated
reward modeling, enabling a new principle-driven paradigm for LLM alignment.

</details>


### [50] [Parallel Test-Time Scaling for Latent Reasoning Models](https://arxiv.org/abs/2510.07745)
*Runyang You,Yongqi Li,Meng Liu,Wenjie Wang,Liqiang Nie,Wenjie Li*

Main category: cs.CL

TL;DR: 本文首次系统性地实现了潜在推理模型的并行测试时标度，通过新颖的采样和聚合方法，使连续空间推理更具扩展性和高效性，对后续可扩展推理研究具有重要推动作用。


<details>
  <summary>Details</summary>
Motivation: 虽然潜在推理在效率上优于显式链式思考（CoT），但在并行测试时推理上面临缺乏连续空间采样机制和高阶轨迹聚合信号的问题，因此需要新的方法以扩展其推理能力和可扩展性。

Method: 提出了两种基于不确定性启发的随机采样策略：蒙特卡洛Dropout和加性高斯噪声；并设计了Latent Reward Model（LatentRM），通过逐步对比目标训练，用于评分和引导潜在推理轨迹。

Result: 实验和可视化分析表明，两种采样策略能够有效地提高推理性能，并展现不同的探索动态，而LatentRM能够实现有效的推理轨迹选择。代码已公布。

Conclusion: 本研究通过新颖的采样和聚合机制，成功将并行测试时标度（TTS）的思想应用于潜在推理模型，实现了在连续空间中可扩展的推理效果。

Abstract: Parallel test-time scaling (TTS) is a pivotal approach for enhancing large
language models (LLMs), typically by sampling multiple token-based
chains-of-thought in parallel and aggregating outcomes through voting or
search. Recent advances in latent reasoning, where intermediate reasoning
unfolds in continuous vector spaces, offer a more efficient alternative to
explicit Chain-of-Thought, yet whether such latent models can similarly benefit
from parallel TTS remains open, mainly due to the absence of sampling
mechanisms in continuous space, and the lack of probabilistic signals for
advanced trajectory aggregation. \ This work enables parallel TTS for latent
reasoning models by addressing the above issues. For sampling, we introduce two
uncertainty-inspired stochastic strategies: Monte Carlo Dropout and Additive
Gaussian Noise. For aggregation, we design a Latent Reward Model (LatentRM)
trained with step-wise contrastive objective to score and guide latent
reasoning. Extensive experiments and visualization analyses show that both
sampling strategies scale effectively with compute and exhibit distinct
exploration dynamics, while LatentRM enables effective trajectory selection.
Together, our explorations open a new direction for scalable inference in
continuous spaces. Code released at https://github.com/YRYangang/LatentTTS.

</details>


### [51] [Test-Time Reasoners Are Strategic Multiple-Choice Test-Takers](https://arxiv.org/abs/2510.07761)
*Nishant Balepur,Atrey Desai,Rachel Rudinger*

Main category: cs.CL

TL;DR: 本研究分析了大语言模型在选择题只用选项获得正确答案的现象，发现当加入推理过程时，部分成功并非依赖问题数据中的浅层偏差，而是展现了复杂推断能力，进而挑战了只用选项成功就等同于模型缺陷的观点。


<details>
  <summary>Details</summary>
Motivation: 部分研究发现LLM可以只用选项而忽略问题内容来解答选择题，因此质疑模型是否真正理解问题，作者希望通过分析推理过程澄清这种担忧。

Method: 比较LLM在完整问题与仅有选项输入时的表现，并分析其推理过程，包括准确率提升与推理痕迹的长度和可信度测试。

Result: 在测试中，模型在完整输入和仅选项输入条件下推理均能提升准确率（约一半情况下）；且推理长度对仅选项成功影响不大，通过合理性测试后发现，模型能够推断缺失问题而非仅依赖浅层线索。

Conclusion: 作者认为大语言模型在仅有选项输入下取得成功并不总是代表缺陷，有些情况下模型推理过程展现了更合理的解决策略。

Abstract: Large language models (LLMs) now give reasoning before answering, excelling
in tasks like multiple-choice question answering (MCQA). Yet, a concern is that
LLMs do not solve MCQs as intended, as work finds LLMs sans reasoning succeed
in MCQA without using the question, i.e., choices-only. Such partial-input
success is often deemed problematic, but reasoning traces could reveal if these
strategies are truly shallow in choices-only settings. To study these
strategies, reasoning LLMs solve MCQs in full and choices-only inputs;
test-time reasoning often boosts accuracy on full and in choices-only half the
time. While possibly due to shallow shortcuts, choices-only success is barely
affected by the length of reasoning traces, and after finding traces pass
faithfulness tests, we show they use less problematic strategies like inferring
missing questions. In all, we challenge claims that partial-input success is
always a flaw, so we discuss how reasoning traces could separate problematic
data from less problematic reasoning.

</details>


### [52] [ToolLibGen: Scalable Automatic Tool Creation and Aggregation for LLM Reasoning](https://arxiv.org/abs/2510.07768)
*Murong Yue,Zhiwei Liu,Liangwei Yang,Jianguo Zhang,Zuxin Liu,Haolin Chen,Ziyu Yao,Silvio Savarese,Caiming Xiong,Shelby Heinecke,Huan Wang*

Main category: cs.CL

TL;DR: 提出自动化结构化工具库系统，将分散和问题特定工具聚合为功能强大的通用工具，提高检索准确率和推理性能，解决工具数量扩展瓶颈。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）结合外部工具后能力显著提升，但在专业领域如物理问答中，缺乏合适的领域工具限制了其普及。现有自动化工具生成方法随着工具数量增加，在检索和管理上效率急剧下降。

Method: 系统先自动生成任务特定工具，并按语义聚类分类。随后以多智能体框架整合和重构工具功能：代码智能体负责代码抽象整合为通用工具，审核智能体保障聚合工具功能无缺失。最终实现从大量不同问题工具生成少量功能完备通用工具。

Result: 实验结果表明，该方法在多个推理任务中的工具检索准确率和整体推理表现都有显著提升，并且在面对大量问题特定工具时展现了优越的可扩展性。

Conclusion: 通过结构化和聚合工具，有效提升了模型在复杂推理任务中的工具使用效率和性能，为领域工具自动化构建提供了新思路。

Abstract: Large Language Models (LLMs) equipped with external tools have demonstrated
enhanced performance on complex reasoning tasks. The widespread adoption of
this tool-augmented reasoning is hindered by the scarcity of domain-specific
tools. For instance, in domains such as physics question answering, suitable
and specialized tools are often missing. Recent work has explored automating
tool creation by extracting reusable functions from Chain-of-Thought (CoT)
reasoning traces; however, these approaches face a critical scalability
bottleneck. As the number of generated tools grows, storing them in an
unstructured collection leads to significant retrieval challenges, including an
expanding search space and ambiguity between function-related tools. To address
this, we propose a systematic approach to automatically refactor an
unstructured collection of tools into a structured tool library. Our system
first generates discrete, task-specific tools and clusters them into
semantically coherent topics. Within each cluster, we introduce a multi-agent
framework to consolidate scattered functionalities: a code agent refactors code
to extract shared logic and creates versatile, aggregated tools, while a
reviewing agent ensures that these aggregated tools maintain the complete
functional capabilities of the original set. This process transforms numerous
question-specific tools into a smaller set of powerful, aggregated tools
without loss of functionality. Experimental results demonstrate that our
approach significantly improves tool retrieval accuracy and overall reasoning
performance across multiple reasoning tasks. Furthermore, our method shows
enhanced scalability compared with baselines as the number of question-specific
increases.

</details>


### [53] [Curing Miracle Steps in LLM Mathematical Reasoning with Rubric Rewards](https://arxiv.org/abs/2510.07774)
*Youliang Yuan,Qiuyang Mang,Jingbang Chen,Hong Wan,Xiaoyuan Liu,Junjielong Xu,Jen-tse Huang,Wenxuan Wang,Wenxiang Jiao,Pinjia He*

Main category: cs.CL

TL;DR: 此文发现只奖励最终答案会导致大模型在数学领域推理不真实，并提出基于全过程评分的Rubric Reward Model，有效减少“跳步”现象，大幅提升解题质量和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型进行数学推理时，通常只通过结果导向的奖励（即仅根据最终答案打分）进行训练。作者发现这种做法容易导致奖励黑客现象，模型在推理能力上被高估，经常给出通过不合理推理却得到正确答案的“假阳性”结果。

Method: 研究通过系统分析并经人工验证，建立了模型失败模式的分类，识别了如“奇迹步骤”（Miracle Steps）等现象——即模型突然跳到正确答案但缺乏合理推理过程。作者设计了Rubric Reward Model（RRM），一种基于过程的奖励机制，根据问题特定的评分标准，对完整推理过程进行0-1的细致、校准评分，明确惩罚逻辑错误、鼓励严格推理，并将其应用于强化学习训练流程中。

Result: 采用RRM奖励模型并融入强化学习后，在四个数学基准测试上表现均优于仅结果监督的方法。其中AIME2024基准上Verified Pass@1024从26.7%提升至62.6%，Miracle Steps发生率下降71%。

Conclusion: 通过对推理全过程而非单一结果进行奖励，可以有效提升数学推理大模型的准确性和可靠性。

Abstract: Large language models for mathematical reasoning are typically trained with
outcome-based rewards, which credit only the final answer. In our experiments,
we observe that this paradigm is highly susceptible to reward hacking, leading
to a substantial overestimation of a model's reasoning ability. This is
evidenced by a high incidence of false positives - solutions that reach the
correct final answer through an unsound reasoning process. Through a systematic
analysis with human verification, we establish a taxonomy of these failure
modes, identifying patterns like Miracle Steps - abrupt jumps to a correct
output without a valid preceding derivation. Probing experiments suggest a
strong association between these Miracle Steps and memorization, where the
model appears to recall the answer directly rather than deriving it. To
mitigate this systemic issue, we introduce the Rubric Reward Model (RRM), a
process-oriented reward function that evaluates the entire reasoning trajectory
against problem-specific rubrics. The generative RRM provides fine-grained,
calibrated rewards (0-1) that explicitly penalize logical flaws and encourage
rigorous deduction. When integrated into a reinforcement learning pipeline,
RRM-based training consistently outperforms outcome-only supervision across
four math benchmarks. Notably, it boosts Verified Pass@1024 on AIME2024 from
26.7% to 62.6% and reduces the incidence of Miracle Steps by 71%. Our work
demonstrates that rewarding the solution process is crucial for building models
that are not only more accurate but also more reliable.

</details>


### [54] [The Unintended Trade-off of AI Alignment:Balancing Hallucination Mitigation and Safety in LLMs](https://arxiv.org/abs/2510.07775)
*Omar Mahmoud,Ali Khalil,Buddhika Laknath Semage,Thommen George Karimpanal,Santu Rana*

Main category: cs.CL

TL;DR: 提升LLM事实性常导致安全拒绝能力下降。论文分析了机制原因，提出特征解耦和正交化方法，实现事实性提升且安全性不降，经多项评测验证有效。


<details>
  <summary>Details</summary>
Motivation: 尽管提升大语言模型的事实性已取得大量进展，但事实性增强可能带来拒绝行为的弱化，威胁到安全性，一直未被充分关注。本文旨在分析并解决事实性提升与安全性退化之间的权衡问题。

Method: 使用稀疏自编码器将拒绝行为特征与幻觉特征进行解耦，并通过子空间正交化技术，在微调过程中保持拒绝行为，从而防止事实性提升导致安全一致性下降。

Result: 在常识推理和有害内容评测（AdvBench和StrongReject）上，所提方法能够同时保留拒绝行为和任务实用性，缓解了事实性与安全性之间的权衡。

Conclusion: 提出的方法能够有效缓解提升LLM事实性与安全性一致性之间的矛盾，即在提升事实准确率的同时也能保持模型拒绝不安全内容的能力。

Abstract: Hallucination in large language models (LLMs) has been widely studied in
recent years, with progress in both detection and mitigation aimed at improving
truthfulness. Yet, a critical side effect remains largely overlooked: enhancing
truthfulness can negatively impact safety alignment. In this paper, we
investigate this trade-off and show that increasing factual accuracy often
comes at the cost of weakened refusal behavior. Our analysis reveals that this
arises from overlapping components in the model that simultaneously encode
hallucination and refusal information, leading alignment methods to suppress
factual knowledge unintentionally. We further examine how fine-tuning on benign
datasets, even when curated for safety, can degrade alignment for the same
reason. To address this, we propose a method that disentangles refusal-related
features from hallucination features using sparse autoencoders, and preserves
refusal behavior during fine-tuning through subspace orthogonalization. This
approach prevents hallucinations from increasing while maintaining safety
alignment.We evaluate our method on commonsense reasoning tasks and harmful
benchmarks (AdvBench and StrongReject). Results demonstrate that our approach
preserves refusal behavior and task utility, mitigating the trade-off between
truthfulness and safety.

</details>


### [55] [Instance Relation Learning Network with Label Knowledge Propagation for Few-shot Multi-label Intent Detection](https://arxiv.org/abs/2510.07776)
*Shiman Zhao,Shangyuan Li,Wei Chen,Tengjiao Wang,Jiahui Yao,Jiabin Zheng,Kam Fai Wong*

Main category: cs.CL

TL;DR: 该论文针对低资源对话的少样本多标签意图识别问题，提出基于实例关系和标签知识联合学习的新方法，不仅端到端解决了错误传播，还在1-shot下显著优于主流方法。


<details>
  <summary>Details</summary>
Motivation: 在低资源对话领域，针对少样本场景识别用户发言中的多重意图（Few-shot Multi-label Intent Detection, MID）极为重要。以往方法采用两阶段流程，忽略了实例之间的关系，导致错误传播。

Method: 提出一种端到端多标签联合学习方法，构建实例关系学习网络，通过标签知识传播消除错误传播。具体包括利用类别信息学习实例间的相互关系，实现支持集与查询集之间标签知识的传播，同时设计双重关系增强损失优化支持集和查询集的关系强度。

Result: 实验显示，在1-shot场景下，提出方法相较于强基线平均提升9.54%的AUC和11.19%的Macro-F1。

Conclusion: 端到端的实例关系学习与标签知识传播显著提升了少样本多标签意图识别的准确性和鲁棒性，尤其在低资源环境下效果突出。

Abstract: Few-shot Multi-label Intent Detection (MID) is crucial for dialogue systems,
aiming to detect multiple intents of utterances in low-resource dialogue
domains. Previous studies focus on a two-stage pipeline. They first learn
representations of utterances with multiple labels and then use a
threshold-based strategy to identify multi-label results. However, these
methods rely on representation classification and ignore instance relations,
leading to error propagation. To solve the above issues, we propose a
multi-label joint learning method for few-shot MID in an end-to-end manner,
which constructs an instance relation learning network with label knowledge
propagation to eliminate error propagation. Concretely, we learn the
interaction relations between instances with class information to propagate
label knowledge between a few labeled (support set) and unlabeled (query set)
instances. With label knowledge propagation, the relation strength between
instances directly indicates whether two utterances belong to the same intent
for multi-label prediction. Besides, a dual relation-enhanced loss is developed
to optimize support- and query-level relation strength to improve performance.
Experiments show that we outperform strong baselines by an average of 9.54% AUC
and 11.19% Macro-F1 in 1-shot scenarios.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [56] [Symmetric Rule-Based Achlioptas Processes for Random $k$-SAT](https://arxiv.org/abs/2510.07870)
*Arnab Chatterjee*

Main category: cs.DM

TL;DR: 论文提出并分析了随机k-SAT的有限在线选择规则，证明其能在极小选择数下大幅提升可满足性阈值，并给出了理论推导与新规则，为随机CSP的Achlioptas过程提供了新见解。


<details>
  <summary>Details</summary>
Motivation: 受“两选模型”启发，作者关注在随机k-SAT中有限选择是否可提升阈值，以及如何借助在线选择规则实现超过传统界限的可满足性阈值。该问题关乎随机CSP的基本理解。

Method: 作者引入了名为MIDDLE-HEAVY的分配对称、非自适应、与拓扑无关的在线选择规则，并结合偏置的2-SAT投影及两类分支过程证书进行分析，推导出可满足性阈值的闭式表达。同时设计了混合对称偏置规则作进一步对比。

Result: 证明了当k=4时选择数5，k=5时选择4，k≥6时选择3即足以令阈值超越经典的2^k ln 2界。混合对称偏置规则也能保持对称性的同时达到现有的高阈值。

Conclusion: 论文提出了一种对在线随机k-SAT中限选择规则的新理解，显示在满足特定条件下，有限选择即可提升可满足性阈值，甚至超越一阶矩界。

Abstract: Inspired by the "power-of-two-choices" model from random graphs, we
investigate the possibility of limited choices of online clause choices that
could shift the satisfiability threshold in random $k$-SAT.Here, we introduce
an assignment symmetric, non-adaptive, topology-oblivious online rule called
\emph{MIDDLE-HEAVY}, that prioritizes balanced sign profile clauses.Upon
applying a biased $2$-SAT projection and a two-type branching process
certificate, we derive closed-form expressions for the shifted thresholds
$\alpha_{\textbf{SYM}}(k,\ell)$ for this algorithm.We show that minimal choices
$\ell=5$ for $k=4$, $\ell=4$ for $k=5$, and $\ell=3$ for $k\ge 6$ suffice to
exceed the asymptotic first-moment upper bound $\sim 2^k \ln 2$ for random
$k$-SAT.Moreover, to bridge the gap with biased assignment rules used in
maximum of the previous works in this context, we propose a hybrid symmetric
biased rule that achieves thresholds comparable to prior work while maintaining
symmetry.Our results advance the understanding of Achlioptas processes in
random CSPs beyond classical graph-theoretic settings.

</details>


### [57] [A Graph Width Perspective on Partially Ordered Hamiltonian Paths and Cycles II: Vertex and Edge Deletion Numbers](https://arxiv.org/abs/2510.08378)
*Jesse Beisegel,Katharina Klost,Kristin Knorr,Fabienne Ratajczak,Robert Scheffler*

Main category: cs.DM

TL;DR: 本文研究带偏序约束的哈密尔顿路径/回路问题的参数化复杂度，针对不同顶点或边距离参数给出W[1]-hard、XP可解、FPT算法与para-NP难的全面分析，表明添加约束后问题整体复杂性提升。


<details>
  <summary>Details</summary>
Motivation: 传统哈密尔顿路径/回路问题在某些参数下拥有固定参数可解（FPT）算法，但实际应用中常存在顶点间的优先级或顺序约束，因此研究加入偏序约束后的复杂度情况，以及哪些参数仍能保证高效算法，是理论与实际的重要问题。

Method: 对哈密尔顿路径/回路问题引入偏序约束，并以图宽度相关参数作为复杂度衡量，分别分析顶点/边删除到指定图类（路径、团、块、外平面图）的情形，探讨其参数化复杂度，给出W[1]-hard、XP算法、FPT算法与para-NP难的结果证明。

Result: 证明了加偏序约束后，哈密尔顿路径/回路问题相较于无约束情形变得更难，在以顶点距离参数衡量时为W[1]难，但某些参数下可在XP时间解决或有FPT算法，同时也展示了在边团覆盖数参数下问题达到para-NP难度。

Conclusion: 在研究加有偏序约束的哈密尔顿路径和回路问题时，通过对不同图宽度参数分析，发现问题在某些参数下为W[1]难（如到路径或团的顶点距离），但在其他参数下可在XP时间解决（如到外平面图或块的顶点距离），并获得针对某些参数（如到块的边距离）的FPT算法。针对边团覆盖数参数，还证明了问题为para-NP难。

Abstract: We consider the problem of finding a Hamiltonian path or cycle with
precedence constraints in the form of a partial order on the vertex set. We
study the complexity for graph width parameters for which the ordinary problems
$\mathsf{Hamiltonian\ Path}$ and $\mathsf{Hamiltonian\ Cycle}$ are in
$\mathsf{FPT}$. In particular, we focus on parameters that describe how many
vertices and edges have to be deleted to become a member of a certain graph
class. We show that the problems are $\mathsf{W[1]}$-hard for such restricted
cases as vertex distance to path and vertex distance to clique. We complement
these results by showing that the problems can be solved in $\mathsf{XP}$ time
for vertex distance to outerplanar and vertex distance to block. Furthermore,
we present some $\mathsf{FPT}$ algorithms, e.g., for edge distance to block.
Additionally, we prove para-$\mathsf{NP}$-hardness when considered with the
edge clique cover number.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [58] [Languages of Words of Low Automatic Complexity Are Hard to Compute](https://arxiv.org/abs/2510.07696)
*Joey Chen,Bjørn Kjos-Hanssen,Ivan Koswara,Linus Richter,Frank Stephan*

Main category: cs.FL

TL;DR: 本文提出并系统研究了精确非确定性自动复杂度A_{Ne}，刻画了低复杂度语言的性质，并证明这些语言超越了上下文无关语言和传统布尔电路的识别能力，解决了相关开放问题。


<details>
  <summary>Details</summary>
Motivation: 自动复杂度作为自动机理论中的复杂度度量，‘精确’非确定性版本具有自然的推广意义。此前对于低自动复杂度的语言结构缺乏深入理论分析和针对布尔电路识别能力的刻画。

Method: 以逐字长度比较的方式定义精确非确定性自动复杂度A_{Ne}，研究了参数化语言类L_q，并通过理论证明排除了其为上下文无关语言及可用布尔电路识别的可能性。

Result: 证实了L_q对于所有q∈(0,1/2)都不是上下文无关语言，也不可被某些布尔电路识别，并对L_{1/3}的复杂性给出了明确的布尔电路度量。同时，证明了精确非确定性自动复杂度下的Shannon效应。

Conclusion: 论文介绍了一种名为精确非确定性自动复杂度的新复杂度度量，并证明了基于该复杂度定义的语言类既不是上下文无关语言，也无法被某些布尔电路识别。同时，解决了关于L_{1/3}的开放问题，并证明了Shannon效应在该度量下成立。

Abstract: The automatic complexity of a finite word (string) is an analogue for finite
automata of Sipser's distinguishing complexity (1983) and was introduced by
Shallit and Wang (2001). For a finite alphabet $\Sigma$ of at least two
elements, we consider the non-deterministic automatic complexity given by
exactly - yet not necessarily uniquely - accepting automata: a word $x \in
\Sigma^*$ has exact non-deterministic automatic complexity $k \in \mathbb{N}$
if there exists a non-deterministic automaton of $k$ states which accepts $x$
while rejecting every other word of the same length as $x$, and no automaton of
fewer states has this property. Importantly, and in contrast to the classical
notion, the witnessing automaton may have multiple paths of computation
accepting $x$. We denote this measure of complexity by $A_{Ne}$, and study a
class of languages of low $A_{Ne}$-complexity defined as $L_q = \{ \, x \in
\Sigma^* : A_{Ne}(x) < q|x| \, \}$, which is parameterised by rationals $q \in
(0,1/2)$ (generalising a class of sets first studied by Kjos-Hanssen). We show
that for every $q \in (0,1/2)$, this class is neither context-free nor
recognisable by certain Boolean circuits. In the process, we answer an open
question of Kjos-Hanssen quantifying the complexity of $L_{1/3}$ in terms of
Boolean circuits, and also prove the Shannon effect for $A_{Ne}$.

</details>


### [59] [On the Complexity of Language Membership for Probabilistic Words](https://arxiv.org/abs/2510.08127)
*Antoine Amarilli,Mikaël Monet,Paul Raphaël,Sylvain Salvati*

Main category: cs.FL

TL;DR: 本研究分析概率性单词属于上下文自由语言的判定问题，在不同语言类中给出多项式可解性和#P难性的边界，提出知识编译电路扩展部分可解问题，并证明判定整个问题复杂度本身是不可判定的。


<details>
  <summary>Details</summary>
Motivation: 现有关于上下文自由语言的成员判定多关注确定性单词或计数问题，而实际情况常见单词带有概率不确定性，因此作者动机在于推广判定模型至概率性单词，分析不同语言类别下的复杂性边界，扩展理论和算法工具箱。

Method: 作者将概率单词的成员资格问题推广为对概率分布采样产生的单词是否属于某上下文自由语言进行概率计算，分析其复杂度。分别对无歧义CFL、多重线性CFL、poly-slicewise-unambiguous、计数自动机等语言类别逐一讨论复杂性，并结合知识编译电路方法实现部分情况的可解性扩展，最后对判定该问题复杂度的元问题进行讨论。

Result: 对于无歧义上下文自由语言和poly-slicewise-unambiguous语言，概率成员资格问题可多项式解决，对某些计数自动机问题#P难。利用知识编译电路可扩展到部分新的CFL问题。最终，给定CFG判定该问题是否可解或#P难本身是条件性不可判定的。

Conclusion: 研究表明，对于上下文无歧义自由语言（uCFLs），概率性单词的成员资格判定问题可以在多项式时间内解决，但对于两个线性uCFL的并集，这个问题已经是#P难的。更一般地，对于所谓的poly-slicewise-unambiguous语言，该问题仍然是可多项式时间解决的，但对于非确定性计数自动机甚至含单一计数器的Parikh自动机则是#P难。引入知识编译中的电路模型可覆盖一些新可解情况，但最终给出是否可解或#P难的判定是条件性不可判定的。

Abstract: We study the membership problem to context-free languages L (CFLs) on
probabilistic words, that specify for each position a probability distribution
on the letters (assuming independence across positions). Our task is to
compute, given a probabilistic word, what is the probability that a word drawn
according to the distribution belongs to L. This problem generalizes the
problem of counting how many words of length n belong to L, or of counting how
many completions of a partial word belong to L.
  We show that this problem is in polynomial time for unambiguous context-free
languages (uCFLs), but can be #P-hard already for unions of two linear uCFLs.
More generally, we show that the problem is in polynomial time for so-called
poly-slicewise-unambiguous languages, where given a length n we can tractably
compute an uCFL for the words of length n in the language. This class includes
some inherently ambiguous languages, and implies the tractability of bounded
CFLs and of languages recognized by unambiguous polynomial-time counter
automata; but we show that the problem can be #P-hard for nondeterministic
counter automata, even for Parikh automata with a single counter. We then
introduce classes of circuits from knowledge compilation which we use for
tractable counting, and show that this covers the tractability of
poly-slicewise-unambiguous languages and of some CFLs that are not
poly-slicewise-unambiguous. Extending these circuits with negation further
allows us to show tractability for the language of primitive words, and for the
language of concatenations of two palindromes. We finally show the conditional
undecidability of the meta-problem that asks, given a CFG, whether the
probabilistic membership problem for that CFG is tractable or #P-hard.

</details>
