<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 18]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.CL](#cs.CL) [Total: 66]
- [cs.DM](#cs.DM) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Dual-Language General-Purpose Self-Hosted Visual Language and new Textual Programming Language for Applications](https://arxiv.org/abs/2509.20426)
*Mahmoud Samir Fayed*

Main category: cs.PL

TL;DR: 本文开发了PWCT2，一个既能支持文本又能自举的通用可视化编程语言，极大提升了可视编程的效率和易用性，在实际用户中获得了积极反馈。


<details>
  <summary>Details</summary>
Motivation: 现有的通用型可视化编程语言（VPLs）数量极少，而且通常依赖文本编程语言进行开发与维护，提升其功能同样需要文本编程，局限了易用性和开发者群体。

Method: 设计并实现了PWCT2——一种支持阿拉伯语和英语的通用、自举（可用自身开发）的可视化编程语言。首先专门设计了Ring文本编程语言（动态类型、可定制语法、支持领域特定语言），用PWCT实现了Ring的编译器和虚拟机。以Ring为基础进一步开发了PWCT2，实现开发流程的自举。

Result: PWCT2可生成代码速度提升约36倍，视觉源文件存储需求降低20倍。支持将Ring代码转换为可视化代码，实现用自身开发自身的VPL。PWCT2拥有约9.2万行Ring代码、394个视觉组件，通过Steam平台分发，取得积极用户反馈：1772名用户启动软件，总使用时间超过1.7万小时。

Conclusion: PWCT2有效提升了可视化编程语言的开发效率和易用性，推动了通用VPL的自举与普及。其用户数据表明具备良好的实际应用前景和进一步研究价值。

Abstract: Most visual programming languages (VPLs) are domain-specific, with few
general-purpose VPLs like Programming Without Coding Technology (PWCT). These
general-purpose VPLs are developed using textual programming languages and
improving them requires textual programming. In this thesis, we designed and
developed PWCT2, a dual-language (Arabic/English), general-purpose,
self-hosting visual programming language. Before doing so, we specifically
designed a textual programming language called Ring for its development. Ring
is a dynamically typed language with a lightweight implementation, offering
syntax customization features. It permits the creation of domain-specific
languages through new features that extend object-oriented programming,
allowing for specialized languages resembling Cascading Style Sheets (CSS) or
Supernova language. The Ring Compiler and Virtual Machine are designed using
the PWCT visual programming language where the visual implementation is
composed of 18,945 components that generate 24,743 lines of C code, which
increases the abstraction level and hides unnecessary details. Using PWCT to
develop Ring allowed us to realize several issues in PWCT, which led to the
development of the PWCT2 visual programming language using the Ring textual
programming language. PWCT2 provides approximately 36 times faster code
generation and requires 20 times less storage for visual source files. It also
allows for the conversion of Ring code into visual code, enabling the creation
of a self-hosting VPL that can be developed using itself. PWCT2 consists of
approximately 92,000 lines of Ring code and comes with 394 visual components.
PWCT2 is distributed to many users through the Steam platform and has received
positive feedback, On Steam, 1772 users have launched the software, and the
total recorded usage time exceeds 17,000 hours, encouraging further research
and development.

</details>


### [2] [Efficient Symbolic Computation vis Hash Consing](https://arxiv.org/abs/2509.20534)
*Bowen Zhu,Aayush Sabharwal,Songchen Tan,Yingbo Ma,Alan Edelman,Christopher Rackauckas*

Main category: cs.PL

TL;DR: 引入hash consing到JuliaSymbolics显著降低内存占用并加速各种关键运算，为大规模符号计算和AI推理提供了可扩展的新途径。


<details>
  <summary>Details</summary>
Motivation: 符号计算系统在处理大量结构相同的子表达式时，会因为重复存储导致内存低效（即表达式膨胀），影响其在传统计算代数和新兴的AI数学推理工具中的性能。作者希望解决表达式重复带来的资源浪费和性能瓶颈。

Method: 在Julia高性能符号计算包JuliaSymbolics中首次集成hash consing技术，采用全局弱引用哈希表对表达式进行规范化存储，去除冗余。同时确保可与Julia的元编程和JIT编译体系无缝结合。

Result: 经过基准测试，在不同领域表现出显著提升：符号计算速度提升最高达3.2倍，内存占用减少至一半，代码生成速度提升5倍，函数编译提速10倍，大模型的数值计算速度提升最多达100倍。部分工作负载在初期计算阶段增益有限甚至略有性能损失，但后续流程均有大幅受益。

Conclusion: hash consing对于提升符号计算系统的可扩展性和性能至关重要，并为未来与e-graph结合以提升AI驱动表达式共享奠定了基础。

Abstract: Symbolic computation systems suffer from memory inefficiencies due to
redundant storage of structurally identical subexpressions, commonly known as
expression swell, which degrades performance in both classical computer algebra
and emerging AI-driven mathematical reasoning tools. In this paper, we present
the first integration of hash consing into JuliaSymbolics, a high-performance
symbolic toolkit in Julia, by employing a global weak-reference hash table that
canonicalizes expressions and eliminates duplication. This approach reduces
memory consumption and accelerates key operations such as differentiation,
simplification, and code generation, while seamlessly integrating with Julia's
metaprogramming and just-in-time compilation infrastructure. Benchmark
evaluations across different computational domains reveal substantial
improvements: symbolic computations are accelerated by up to 3.2 times, memory
usage is reduced by up to 2 times, code generation is up to 5 times faster,
function compilation up to 10 times faster, and numerical evaluation up to 100
times faster for larger models. While certain workloads with fewer duplicate
unknown-variable expressions show more modest gains or even slight overhead in
initial computation stages, downstream processing consistently benefits
significantly. These findings underscore the importance of hash consing in
scaling symbolic computation and pave the way for future work integrating hash
consing with e-graphs for enhanced equivalence-aware expression sharing in
AI-driven pipelines.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [ACCeLLiuM: Supervised Fine-Tuning for Automated OpenACC Pragma Generation](https://arxiv.org/abs/2509.20380)
*Samyak Jhaveri,Vanessa Klotzmann,Crista Lopes*

Main category: cs.SE

TL;DR: 论文提出了ACCeLLiuM模型，针对数据并行循环自动生成OpenACC指令，在准确率和有效性上优于基础LLM。公开数据集和代码，为后续自动化GPU加速研究提供了基准和便利。


<details>
  <summary>Details</summary>
Motivation: GPU硬件和并行编程框架日益复杂，尽管OpenACC通过指令降低了编程门槛，但有效使用这些指令仍需相当的专业知识。该研究旨在简化GPU数据并行循环的OpenACC指令生成过程。

Method: 提出并微调了两个专用于OpenACC指令生成的大语言模型（ACCeLLiuM），并公开了用于监督微调的OpenACC pragma-loop对数据集（SFT），包含4033组对（3223训练/810测试）。实验通过对比基础LLM和微调LLM的指令生成性能进行评估。

Result: 在测试集上，基础LLM生成有效指令的能力远低于微调LLM。微调后的模型在87%的数据并行循环上生成了类型正确的指令，在50%的情况下生成了完全正确（包括指令、子句、顺序、变量）的指令。即使不完全匹配，生成的指令也经常包括有价值的、能增强控制力的额外子句。

Conclusion: ACCeLLiuM有效提升了OpenACC指令自动生成的质量，有助于推动以LLM为基础的GPU自动加速工具发展，并通过公开资源为社区建立了可复现基准，降低了GPU并行程序开发门槛。

Abstract: The increasing ubiquity of GPUs is accompanied by the increasing complexity
of their hardware and parallel programming frameworks. Directive-based parallel
programming standards like OpenACC simplify GPU programming to some extent by
abstracting away low-level complexities, but a fair amount of expertise is
still required in order to use those directives effectively.
  We introduce ACCeLLiuM, two open weights Large Language Models specifically
fine-tuned for generating expert OpenACC directives for data-parallel loops,
along with the supervised fine-tuning dataset that was used to train them. The
ACCeLLiuM SFT dataset contains 4,033 OpenACC pragma-loop pairs mined from
public GitHub C/C++ repositories, with 3,223 pairs for training and 810 for
testing. Experimental evaluations show a pronounced performance gap in
generating correct OpenACC pragmas between base LLMs and our fine-tuned
versions. On the held-out test set, base LLMs fail to consistently generate
valid pragmas, whereas LLMs fine-tuned on the ACCeLLiuM dataset generate valid
pragmas with the correct directive type for $87\%$ of the data-parallel loops,
and exact pragmas--including directives, clauses, clause order, and clause
variables--for $50\%$ of the cases. Even when not exact, generated pragmas
frequently incorporate the correct clauses in a different order than the
ground-truth label, or include additional clauses that enable finer control
over parallel execution, data movement, and concurrency, offering practical
value beyond strict string-matching. By publicly releasing the code, models,
and dataset as ACCeLLiuM we hope to establish a reproducible benchmark for
LLM-powered OpenACC pragma generation, and lower the barrier to automated GPU
offloading of serially written programs.

</details>


### [4] [Enhancing Python Programming Education with an AI-Powered Code Helper: Design, Implementation, and Impact](https://arxiv.org/abs/2509.20518)
*Sayed Mahbub Hasan Amiri,Md Mainul Islam*

Main category: cs.SE

TL;DR: 本文提出并实证了一种结合AI与编程分析的学习型聊天机器人，用于辅助大学生编程学习。结果显示该机器人有效提升了学习成效，大幅降低了调试时间，并受到学生积极评价。研究强调AI可在教育中发挥帮助理解与技能培养的作用，优于传统工具。


<details>
  <summary>Details</summary>
Motivation: 现有的IDE和静态分析器无法为学生提供有针对性的编程帮助，现有的AI助手如Copilot更注重代码完成而非教学。希望开发一个能真正促进编程学习的智能辅助工具，弥补目前工具在教学与个性化辅导上的不足。

Method: 提出了一种融合静态代码分析、动态执行追踪及大语言模型（LLMs）的AI-Python学习型聊天机器人架构。该架构利用CodeLlama进行代码嵌入，GPT-4进行自然语交互，并采用Docker沙盒保障运行安全。通过混合方法评估，分析1500份学生提交代码，并收集120位学生的定性反馈。

Result: 该系统在解决学生编程错误上达到了85%的成功率，优于pylint（62%）和GPT-4单独使用（73%）。使用者的调试时间减少了59.3%，编码能力提升了34%，尤其在递归和异常处理方面表现突出。学生反馈表明系统在明确性、易用性和提升编程信心等方面表现良好，但存在偶发延迟和代码过度安全限制的问题。

Conclusion: 该研究展示了AI工具在促进编程教育上的潜力，通过技术创新与教育关怀的结合，强调了教育公平与长久技能养成的重要性，而非单纯代码完成。聊天机器人能有效提升学生编程能力和理解深度，为未来AI教育辅助工具提供了参考范式。

Abstract: This is the study that presents an AI-Python-based chatbot that helps
students to learn programming by demonstrating solutions to such problems as
debugging errors, solving syntax problems or converting abstract theoretical
concepts to practical implementations. Traditional coding tools like Integrated
Development Environments (IDEs) and static analyzers do not give robotic help
while AI-driven code assistants such as GitHub Copilot focus on getting things
done. To close this gap, our chatbot combines static code analysis, dynamic
execution tracing, and large language models (LLMs) to provide the students
with relevant and practical advice, hence promoting the learning process. The
chatbots hybrid architecture employs CodeLlama for code embedding, GPT-4 for
natural language interactions, and Docker-based sandboxing for secure
execution. Evaluated through a mixed-methods approach involving 1,500 student
submissions, the system demonstrated an 85% error resolution success rate,
outperforming standalone tools like pylint (62%) and GPT-4 (73%). Quantitative
results revealed a 59.3% reduction in debugging time among users, with pre- and
post-test assessments showing a 34% improvement in coding proficiency,
particularly in recursion and exception handling. Qualitative feedback from 120
students highlighted the chatbots clarity, accessibility, and
confidence-building impact, though critiques included occasional latency and
restrictive code sanitization. By balancing technical innovation with
pedagogical empathy, this research provides a blueprint for AI tools that
prioritize educational equity and long-term skill retention over mere code
completion. The chatbot exemplifies how AI can augment human instruction,
fostering deeper conceptual understanding in programming education.

</details>


### [5] [State-of-the-Art in Software Security Visualization: A Systematic Review](https://arxiv.org/abs/2509.20385)
*Ishara Devendra,Chaman Wijesiriwardana,Prasad Wimalaratne*

Main category: cs.SE

TL;DR: 本文系统综述并梳理了软件安全可视化相关技术与研究，提出了详细分类法，强调创新可视化手段在应对安全挑战中的重要作用。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统的日益复杂和威胁形势的不断变化，传统基于文本或数值的方法对安全问题分析的效果变得有限。因此，需要新的可视化方法以提升安全数据的理解和决策效率。

Method: 系统性回顾了60余篇关于软件安全可视化的最新研究文献，并构建了一个包括四大类（基于图形、符号、矩阵及隐喻）的可视化技术分类法，对现有技术进行了归纳和分析。

Result: 梳理并总结了软件安全可视化领域的主要问题、最新进展和未来发展方向，明确指出软件开发可视化和网络安全可视化是当前研究的焦点领域。

Conclusion: 创新的适应性可视化技术是提升威胁检测、改进安全响应及指引未来研究的关键。该综述为业界与学术界提供了详细的技术地图和研究方向参考。

Abstract: Software security visualization is an interdisciplinary field that combines
the technical complexity of cybersecurity, including threat intelligence and
compliance monitoring, with visual analytics, transforming complex security
data into easily digestible visual formats. As software systems get more
complex and the threat landscape evolves, traditional text-based and numerical
methods for analyzing and interpreting security concerns become increasingly
ineffective. The purpose of this paper is to systematically review existing
research and create a comprehensive taxonomy of software security visualization
techniques through literature, categorizing these techniques into four types:
graph-based, notation-based, matrix-based, and metaphor-based visualization.
This systematic review explores over 60 recent key research papers in software
security visualization, highlighting its key issues, recent advancements, and
prospective future research directions. From the comprehensive analysis, the
two main areas were distinctly highlighted as extensive software development
visualization, focusing on advanced methods for depicting software
architecture: operational security visualization and cybersecurity
visualization. The findings highlight the necessity for innovative
visualization techniques that adapt to the evolving security landscape, with
practical implications for enhancing threat detection, improving security
response strategies, and guiding future research.

</details>


### [6] [Dynamic ReAct: Scalable Tool Selection for Large-Scale MCP Environments](https://arxiv.org/abs/2509.20386)
*Nishant Gaurav,Adit Akarsh,Ankit Ranjan,Manoj Bajaj*

Main category: cs.SE

TL;DR: 本文提出Dynamic ReAct机制，通过创新架构高效解决大量工具环境下工具选择难题，在减少计算开销的同时保障任务表现，为通用AI智能体的动态自适应提供重要进展。


<details>
  <summary>Details</summary>
Motivation: 目前ReAct智能体在面对上百甚至上千工具时因内存和计算限制难以同时加载全部工具，亟需高效工具选择机制。

Method: 提出并评估了五种不同架构，实现逐步优化工具选择过程，最终采用搜索加载机制以智能选择工具。

Result: 实验结果显示工具加载量最多减少50%，同时保持任务完成准确率。

Conclusion: Dynamic ReAct能够有效提升ReAct智能体在拥有大量工具集环境下的操作效率，实现智能选工具并降低计算消耗。

Abstract: We present Dynamic ReAct, a novel approach for enabling ReAct agents to ef-
ficiently operate with extensive Model Control Protocol (MCP) tool sets that
exceed the contextual memory limitations of large language models. Our approach
addresses the fundamental challenge of tool selection in environments
containing hundreds or thousands of available tools, where loading all tools
simultaneously is computationally infeasible. We propose and evaluate five
distinct architectures that progressively refine the tool selection process,
culminating in a search-and-load mechanism that achieves intelligent tool
selection with minimal computational overhead. Our experimental results
demonstrate that the proposed approach reduces tool loading by up to 50% while
maintaining task completion accuracy, advancing the path towards truly
general-purpose AI agents capable of dynamically adapting to diverse task
environments.

</details>


### [7] [Towards Systematic Specification and Verification of Fairness Requirements: A Position Paper](https://arxiv.org/abs/2509.20387)
*Qusai Ramadan,Jukka Ruohonen,Abhishek Tiwari,Adam Alami,Zeyd Boukhers*

Main category: cs.SE

TL;DR: 算法偏见不仅源于技术或数据，更因公平性需求定义和验证不足。本文建议用知识图谱形式化专家公平知识，提出解决挑战的研究路线，为软件公平性设计提供新思路。


<details>
  <summary>Details</summary>
Motivation: 当前的软件系统可能由于设计不当而基于性别、种族等受保护特征进行歧视。以往研究多归因于算法或数据的偏见，但忽视了公平性需求的界定与验证不充分，以及专家对公平的知识常常是隐式的，导致难以制定精确可验证的公平性需求。

Method: 提出采用知识图谱构建基于公平的框架，用于形式化和辅助公平性需求的规范与验证。借鉴安全工程领域知识图谱的应用经验。

Result: 本文阐述了采用知识图谱辅助公平性需求规范与验证的挑战、研究问题及未来研究路线图。当前尚属方法框架和议题探讨阶段。

Conclusion: 提出了一种基于知识图谱的框架以应对软件系统公平性需求不明确的问题，为公平性规范和验证提供了理论支持和研究方向，但还需进一步完善和验证。

Abstract: Decisions suggested by improperly designed software systems might be prone to
discriminate against people based on protected characteristics, such as gender
and ethnicity. Previous studies attribute such undesired behavior to flaws in
algorithmic design or biased data. However, these studies ignore that
discrimination is often the result of a lack of well-specified fairness
requirements and their verification. The fact that experts' knowledge about
fairness is often implicit makes the task of specifying precise and verifiable
fairness requirements difficult. In related domains, such as security
engineering, knowledge graphs have been proven to be effective in formalizing
knowledge to assist requirements specification and verification. To address the
lack of formal mechanisms for specifying and verifying fairness requirements,
we propose the development of a knowledge graph-based framework for fairness.
In this paper, we discuss the challenges, research questions, and a road map
towards addressing the research questions.

</details>


### [8] [Online-Optimized RAG for Tool Use and Function Calling](https://arxiv.org/abs/2509.20415)
*Yu Pan,Xiaocheng Li,Hanzhao Wang*

Main category: cs.SE

TL;DR: 文章提出Online-Optimized RAG框架，通过在线反馈优化检索嵌入，有效提升工具使用和检索的准确率，增强了RAG系统的自适应能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，利用RAG进行工具与函数调用时，往往会出现嵌入不对齐的问题，主要由于嵌入模型不完美或描述信息噪声。这种不对齐导致检索错误和任务失败。

Method: 提出了一种Online-Optimized RAG框架，在部署阶段通过在线交互最小化反馈（如任务成功率），不断自适应检索嵌入参数。该方法通过轻量级的在线梯度更新，无需修改底层大模型，并支持多种工具使用场景。

Result: 无论是在多种工具使用还是文档检索场景下，所提出的方法都显著提升了工具选择的准确率和最终任务成功率。

Conclusion: 通过引入在线优化机制，可以有效解决嵌入不对齐导致的RAG系统错误检索问题，实现RAG系统的自我改进、自适应和更强的鲁棒性。

Abstract: In many applications, retrieval-augmented generation (RAG) drives tool use
and function calling by embedding the (user) queries and matching them to
pre-specified tool/function descriptions. In this paper, we address an
embedding misalignment issue that often arises in practical applications due to
imperfect embedding models or noisy descriptions; such misalignment may lead to
incorrect retrieval and task failure. We introduce Online-Optimized RAG, a
deployment-time framework that continually adapts retrieval embeddings from
live interactions using minimal feedback (e.g., task success). Online-Optimized
RAG applies lightweight online gradient updates with negligible per-query
latency and requires no changes to the underlying LLM. The method is
plug-and-play: it supports both single- and multi-hop tool use, dynamic tool
inventories, and $K$-retrieval with re-ranking. We provide a problem-dependent
theoretical analysis that quantifies how the method's performance depends on
the initialization quality of the embeddings and other related quantities.
Across diverse tool-use and document-retrieval scenarios, our Online-Optimized
RAG consistently improves tool selection accuracy and end-task success, thus
providing a simple, practical path to robust, self-improving RAG systems.

</details>


### [9] [Formal Verification of Legal Contracts: A Translation-based Approach](https://arxiv.org/abs/2509.20421)
*Reiner Hähnle,Cosimo Laneve,Adele Veschetti*

Main category: cs.SE

TL;DR: 论文提出将法律合约语言Stipula自动转换为带JML注释的Java代码，并用KeY工具全自动验证合约正确性，证实了此形式化验证方案的可行性和实用性。


<details>
  <summary>Details</summary>
Motivation: 确保以Stipula编写的法律合约在资产转移和义务等关键属性方面具有可验证的正确性，提高合约可靠性和可信度。

Method: 将Stipula合约自动转换为Java代码，并用Java Modeling Language进行规范注释，然后利用KeY工具自动验证部分和整体正确性。

Result: 对于大范围、不相交循环的Stipula合约，翻译与验证过程可以完全自动化，并成功证明一般性形式化验证工具可用于此类合约的正确性验证。

Conclusion: 作者证明了通过将Stipula合约自动翻译成带有JML规范的Java代码，并使用KeY工具进行验证，可以实现Stipula合约的大规模自动化、正确性验证。

Abstract: Stipula is a domain-specific programming language designed to model legal
contracts with enforceable properties, especially those involving asset
transfers and obligations. This paper presents a methodology to formally verify
the correctness of Stipula contracts through translation into Java code
annotated with Java Modeling Language specifications. As a verification
backend, the deductive verification tool KeY is used. Both, the translation and
the verification of partial and total correctness for a large subset of Stipula
contracts, those with disjoint cycles, is fully automatic. Our work
demonstrates that a general-purpose deductive verification tool can be used
successfully in a translation approach.

</details>


### [10] [AI-Specific Code Smells: From Specification to Detection](https://arxiv.org/abs/2509.20491)
*Brahim Mahmoudi,Naouel Moha,Quentin Stievenert,Florent Avellaneda*

Main category: cs.SE

TL;DR: 提出AI专用代码异味检测工具SpecDetect4AI，在大规模AI系统中表现优异，能高效扩展地辅助发现深层次AI问题。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能（AI）的崛起，AI系统的开发和维护面临独特挑战，传统工具难以及时、准确地发现AI特有的问题，如难以复现、隐性失效、模型泛化差等。

Method: 提出了SpecDetect4AI工具，该方法结合了高层声明式领域特定语言（DSL）用于规则规范，并配合可扩展的静态分析工具，在大规模AI系统中自动检测AI特有代码异味。

Result: 在826个AI系统（约2000万行代码）上，指定和检测了22种AI代码异味，工具的精度达到88.66%，召回率88.89%，优于现有检测工具。此外，系统可扩展、高效，用户满意度得分81.7/100。

Conclusion: SpecDetect4AI通过专属规则，支持高效、可扩展地检测AI系统专属代码异味，对保障AI系统质量具有显著价值。

Abstract: The rise of Artificial Intelligence (AI) is reshaping how software systems
are developed and maintained. However, AI-based systems give rise to new
software issues that existing detection tools often miss. Among these, we focus
on AI-specific code smells, recurring patterns in the code that may indicate
deeper problems such as unreproducibility, silent failures, or poor model
generalization. We introduce SpecDetect4AI, a tool-based approach for the
specification and detection of these code smells at scale. This approach
combines a high-level declarative Domain-Specific Language (DSL) for rule
specification with an extensible static analysis tool that interprets and
detects these rules for AI-based systems. We specified 22 AI-specific code
smells and evaluated SpecDetect4AI on 826 AI-based systems (20M lines of code),
achieving a precision of 88.66% and a recall of 88.89%, outperforming other
existing detection tools. Our results show that SpecDetect4AI supports the
specification and detection of AI-specific code smells through dedicated rules
and can effectively analyze large AI-based systems, demonstrating both
efficiency and extensibility (SUS 81.7/100).

</details>


### [11] [PromptDebt: A Comprehensive Study of Technical Debt Across LLM Projects](https://arxiv.org/abs/2509.20497)
*Ahmed Aljohani,Hyunsook Do*

Main category: cs.SE

TL;DR: 本文从大规模数据实证出发，首次系统梳理了LLM集成带来的新型技术债务，发现提示设计等问题尤为突出，并提供了数据集与管理建议。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）通过API方式广泛集成到软件中，为开发者带来强大AI能力的同时，也引入了新的自承认技术债务（SATD）。目前对于LLM相关的技术债务研究极为稀缺。

Method: 作者对93,142个包含主流LLM API的Python文件进行了大规模实证分析，系统性地研究LLM相关技术债务的来源、流行度及缓解措施。同时，分析了不同提示工程技术引发技术债务的情况。

Result: OpenAI集成相关的技术债务占比54.49%，LangChain为12.35%。提示设计是LLM技术债务的最大来源，其中6.61%与提示配置及优化相关，其次为超参数调整和LLM框架集成。指令型提示（38.60%）和few-shot提示（18.13%）因依赖指令清晰度和示例质量而更易产生技术债务。作者还发布了相关数据集以支持再现性与实务参考。

Conclusion: LLM的集成在带来AI应用便利的同时，显著增加了新的技术债务，尤其是在提示与配置方面。实践者需关注这些高风险点，采用更系统的管理和优化策略。

Abstract: Large Language Models (LLMs) are increasingly embedded in software via APIs
like OpenAI, offering powerful AI features without heavy infrastructure. Yet
these integrations bring their own form of self-admitted technical debt (SATD).
In this paper, we present the first large-scale empirical study of LLM-specific
SATD: its origins, prevalence, and mitigation strategies. By analyzing 93,142
Python files across major LLM APIs, we found that 54.49% of SATD instances stem
from OpenAI integrations and 12.35% from LangChain use. Prompt design emerged
as the primary source of LLM-specific SATD, with 6.61% of debt related to
prompt configuration and optimization issues, followed by hyperparameter tuning
and LLM-framework integration. We further explored which prompt techniques
attract the most debt, revealing that instruction-based prompts (38.60%) and
few-shot prompts (18.13%) are particularly vulnerable due to their dependence
on instruction clarity and example quality. Finally, we release a comprehensive
SATD dataset to support reproducibility and offer practical guidance for
managing technical debt in LLM-powered systems.

</details>


### [12] [Enhancing LLM-based Fault Localization with a Functionality-Aware Retrieval-Augmented Generation Framework](https://arxiv.org/abs/2509.20552)
*Xinyu Shi,Zhenhao Li,An Ran Chen*

Main category: cs.SE

TL;DR: 本文提出了结合LLM与RAG的新型故障定位框架FaR-Loc，三大模块协同提升代码定位准确率，在主流基准和多个指标上均优于现有方法，并证实结构化编码模型带来巨大增益，对工程实践具有应用价值。


<details>
  <summary>Details</summary>
Motivation: 由于现有的大型语言模型（LLM）在处理复杂软件项目中的故障定位任务时存在项目知识匮乏和难以应对大型项目的问题，急需创新方法提升故障定位表现。

Method: 提出了FaR-Loc框架，通过LLM与检索增强生成（RAG）结合，包含LLM功能提取、语义密集检索、LLM重排序三个核心模块。先用LLM生成失败行为描述，然后用预训练编码器将自然语言描述和方法代码嵌入到共享语义空间，实现方法检索，最后根据上下文相关性进行方法重排。

Result: 在Defects4J基准上，FaR-Loc较SOTA的LLM基线SoapFL和AutoFL，在Top-1准确率提升14.6%和9.1%，Top-5提升19.2%和22.1%；在所有Top-N指标均超越其他学习、谱基线且无需再次训练。使用包含代码结构的UniXcoder嵌入模型，Top-1准确率最高提升49%。

Conclusion: FaR-Loc无需额外训练，即可显著提升方法级故障定位精度，且采用结构化代码嵌入可大幅加速和优化定位效果。研究还通过案例分析验证实用性，为未来实际应用提供参考。

Abstract: Fault localization (FL) is a critical but time-consuming task in software
debugging, aiming to identify faulty code elements. While recent advances in
large language models (LLMs) have shown promise for FL, they often struggle
with complex systems due to the lack of project-specific knowledge and the
difficulty of navigating large projects. To address these limitations, we
propose FaR-Loc, a novel framework that enhances method-level FL by integrating
LLMs with retrieval-augmented generation (RAG). FaR-Loc consists of three key
components: LLM Functionality Extraction, Semantic Dense Retrieval, and LLM
Re-ranking. First, given a failed test and its associated stack trace, the LLM
Functionality Extraction module generates a concise natural language
description that captures the failing behavior. Next, the Semantic Dense
Retrieval component leverages a pre-trained code-understanding encoder to embed
both the functionality description (natural language) and the covered methods
(code) into a shared semantic space, enabling the retrieval of methods with
similar functional behavior. Finally, the LLM Re-ranking module reorders the
retrieved methods based on their contextual relevance. Our experiments on the
widely used Defects4J benchmark show that FaR-Loc outperforms state-of-the-art
LLM-based baselines SoapFL and AutoFL, by 14.6% and 9.1% in Top-1 accuracy, by
19.2% and 22.1% in Top-5 accuracy, respectively. It also surpasses all
learning-based and spectrum-based baselines across all Top-N metrics without
requiring re-training. Furthermore, we find that pre-trained code embedding
models that incorporate code structure, such as UniXcoder, can significantly
improve fault localization performance by up to 49.0% in Top-1 accuracy.
Finally, we conduct a case study to illustrate the effectiveness of FaR-Loc and
to provide insights for its practical application.

</details>


### [13] [Design, Implementation and Evaluation of a Novel Programming Language Topic Classification Workflow](https://arxiv.org/abs/2509.20631)
*Michael Zhang,Yuan Tian,Mariam Guizani*

Main category: cs.SE

TL;DR: 本文通过SVM和滑动窗口投票策略，实现了源代码中编程语言主题的精细分类和定位，模型表现优异，可为代码分析和工程实践提供支持。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统规模和复杂性的增加，理解源代码中编程语言主题的分布对于技术决策、人员培训和工具开发变得越来越重要。

Method: 本文提出了一种新颖的编程语言主题分类工作流程，结合多标签支持向量机（SVM）、滑动窗口和投票策略，实现对源代码细粒度的语言概念定位。

Result: 在IBM Project CodeNet数据集上训练，模型在各主题上的平均F1分数为0.90，在代码-主题高亮上的F1分数为0.75。

Conclusion: 该方法为代码分析和数据驱动的软件工程提供了可复用的流程和实证研究，为研究人员和实践者带来指导。

Abstract: As software systems grow in scale and complexity, understanding the
distribution of programming language topics within source code becomes
increasingly important for guiding technical decisions, improving onboarding,
and informing tooling and education. This paper presents the design,
implementation, and evaluation of a novel programming language topic
classification workflow. Our approach combines a multi-label Support Vector
Machine (SVM) with a sliding window and voting strategy to enable fine-grained
localization of core language concepts such as operator overloading, virtual
functions, inheritance, and templates. Trained on the IBM Project CodeNet
dataset, our model achieves an average F1 score of 0.90 across topics and 0.75
in code-topic highlight. Our findings contribute empirical insights and a
reusable pipeline for researchers and practitioners interested in code analysis
and data-driven software engineering.

</details>


### [14] [Exploring Engagement in Hybrid Meetings](https://arxiv.org/abs/2509.20780)
*Daniela Grassi,Fabio Calefato,Darja Smite,Nicole Novielli,Filippo Lanubile*

Main category: cs.SE

TL;DR: 通过问卷与生理数据测量，发现混合会议中远程参与者在长时间会议中易于参与度降低。积极参与角色和较小会议规模有助提升参与度，研究结果为改进混合办公下会议效率与参与感提供了建议，适用于多种知识工作团队。


<details>
  <summary>Details</summary>
Motivation: 随着COVID-19疫情的影响，混合办公逐渐成为软件开发行业的新常态，但这种办公方式带来了沟通和协同上的新挑战，尤其是远程会议中成员的参与感、孤立感和疏离感等问题亟需解决。本文希望通过客观测量识别和描述混合会议中的参与模式，以推动混合办公下团队协同效率提升。

Method: 研究人员选取了三家软件公司，在数周内采用多模态方法进行研究。通过自我报告问卷和生理生物识别设备，在混合会议期间收集数据，以科学量化参与度并分析其动态变化。

Result: 回归分析显示，现场与远程参与者的总体参与度相近，但远程成员在会议时间较长时无论角色如何都表现出更低的参与度。积极的会议角色与更高参与度正相关，而会议规模变大及下午时段则与更低参与度相关。

Conclusion: 本研究揭示了影响混合会议参与度的关键因素，为会议优化和团队协同提供了实操建议。成果不仅适用于软件开发团队，对各类知识密集型组织也具有实际参考价值。

Abstract: Background. The widespread adoption of hybrid work following the COVID-19
pandemic has fundamentally transformed software development practices,
introducing new challenges in communication and collaboration as organizations
transition from traditional office-based structures to flexible working
arrangements. This shift has established a new organizational norm where even
traditionally office-first companies now embrace hybrid team structures. While
remote participation in meetings has become commonplace in this new
environment, it may lead to isolation, alienation, and decreased engagement
among remote team members. Aims. This study aims to identify and characterize
engagement patterns in hybrid meetings through objective measurements, focusing
on the differences between co-located and remote participants. Method. We
studied professionals from three software companies over several weeks,
employing a multimodal approach to measure engagement. Data were collected
through self-reported questionnaires and physiological measurements using
biometric devices during hybrid meetings to understand engagement dynamics.
Results. The regression analyses revealed comparable engagement levels between
onsite and remote participants, though remote participants show lower
engagement in long meetings regardless of participation mode. Active roles
positively correlate with higher engagement, while larger meetings and
afternoon sessions are associated with lower engagement. Conclusions. Our
results offer insights into factors associated with engagement and
disengagement in hybrid meetings, as well as potential meeting improvement
recommendations. These insights are potentially relevant not only for software
teams but also for knowledge-intensive organizations across various sectors
facing similar hybrid collaboration challenges.

</details>


### [15] [Verification Limits Code LLM Training](https://arxiv.org/abs/2509.20837)
*Srishti Gureja,Elena Tommasone,Jingyi He,Sara Hooker,Matthias Gallé,Marzieh Fadaee*

Main category: cs.SE

TL;DR: 本研究发现，大语言模型用于代码生成时，现有的验证机制过于严格，抑制了数据多样性和模型性能。通过丰富和优化测试用例、放宽验证标准，能突破验证上限，显著提升模型泛化和代码生成能力。


<details>
  <summary>Details</summary>
Motivation: 由于大语言模型（LLMs）在代码生成上的训练越来越依赖合成数据（即题目解决方案和测试均由模型生成），训练数据的多样性与质量受到表征能力有限的自动化验证器的极大限制，这种现象被称为“验证上限”（verification ceiling）。探索如何改进验证策略成为突破代码生成模型性能瓶颈的新需求。

Method: 系统性地分析了验证设计和策略：1）比较了测试用例复杂度和数量对模型性能的影响；2）研究了通过放宽100%测试通过标准（即采用更宽松的通过阈值或LLM软验证），怎么看待本来会被过滤掉的训练数据；3）比较了形式上正确与错误的解决方案，并结合人工评估，研究多样化正确解对泛化性能的作用。

Result: 1）丰富且复杂的测试用例显著提升模型表现，但仅增加数量效果有限；2）适度放宽验证标准或采用软验证，可恢复部分被错误过滤的有效训练数据，提升模型性能2-4个百分点（pass@1指标），但依赖测试用例本身的强度和多样性；3）保留每个问题的多样化正确解，有利于泛化能力的提升。过于僵硬的验证标准削弱了数据多样性，但完全放弃验证不可行，需结合合理校准和有挑战性的训练数据。

Conclusion: 验证策略需要从过于僵硬转为更灵活和多样化，以最大化代码生成模型的性能提升；未来应合理平衡验证标准和数据多样性，突破现有验证上限，训练出更强的代码生成模型。

Abstract: Large language models for code generation increasingly rely on synthetic
data, where both problem solutions and verification tests are generated by
models. While this enables scalable data creation, it introduces a previously
unexplored bottleneck: the verification ceiling, in which the quality and
diversity of training data are fundamentally constrained by the capabilities of
synthetic verifiers. In this work, we systematically study how verification
design and strategies influence model performance. We investigate (i) what we
verify by analyzing the impact of test complexity and quantity: richer test
suites improve code generation capabilities (on average +3 pass@1), while
quantity alone yields diminishing returns, (ii) how we verify by exploring
relaxed pass thresholds: rigid 100% pass criteria can be overly restrictive. By
allowing for relaxed thresholds or incorporating LLM-based soft verification,
we can recover valuable training data, leading to a 2-4 point improvement in
pass@1 performance. However, this benefit is contingent upon the strength and
diversity of the test cases used, and (iii) why verification remains necessary
through controlled comparisons of formally correct versus incorrect solutions
and human evaluation: retaining diverse correct solutions per problem yields
consistent generalization gains. Our results show that Verification as
currently practiced is too rigid, filtering out valuable diversity. But it
cannot be discarded, only recalibrated. By combining calibrated verification
with diverse, challenging problem-solution pairs, we outline a path to break
the verification ceiling and unlock stronger code generation models.

</details>


### [16] [PseudoBridge: Pseudo Code as the Bridge for Better Semantic and Logic Alignment in Code Retrieval](https://arxiv.org/abs/2509.20881)
*Yixuan Li,Xinyi Liu,Weidong Yang,Ben Fei,Shuhao Li,Mingjie Zhou,Lipeng Ma*

Main category: cs.SE

TL;DR: PseudoBridge提出用伪代码桥接自然语言与代码，联合风格增强方法，显著提升代码检索效果和泛化能力，尤其适用于跨领域应用。


<details>
  <summary>Details</summary>
Motivation: 现有基于预训练语言模型的代码检索方法受限于人类意图与机器执行逻辑之间的语义鸿沟，以及对多样代码风格的鲁棒性不足。

Method: 提出PseudoBridge框架，分为两阶段：首先用大语言模型（LLM）将自然语言查询转换成伪代码以对齐语义；其次通过逻辑不变的代码风格增强，利用LLM生成多样但逻辑等价的代码，然后将这些不同风格的代码与伪代码对齐。

Result: 在10个不同PLM和6种主流编程语言上，PseudoBridge在多个指标（特别是zero-shot领域迁移，如Solidity和XLCoST数据集）取得了显著的检索精度提升和更优泛化能力。

Conclusion: 引入伪代码作为中间桥梁能够有效提升基于预训练语言模型的代码检索性能，且增强模型对不同代码风格的鲁棒性和泛化能力。

Abstract: Code search aims to precisely find relevant code snippets that match natural
language queries within massive codebases, playing a vital role in software
development. Recent advances leverage pre-trained language models (PLMs) to
bridge the semantic gap between unstructured natural language (NL) and
structured programming languages (PL), yielding significant improvements over
traditional information retrieval and early deep learning approaches. However,
existing PLM-based methods still encounter key challenges, including a
fundamental semantic gap between human intent and machine execution logic, as
well as limited robustness to diverse code styles. To address these issues, we
propose PseudoBridge, a novel code retrieval framework that introduces
pseudo-code as an intermediate, semi-structured modality to better align NL
semantics with PL logic. Specifically, PseudoBridge consists of two stages.
First, we employ an advanced large language model (LLM) to synthesize
pseudo-code, enabling explicit alignment between NL queries and pseudo-code.
Second, we introduce a logic-invariant code style augmentation strategy and
employ the LLM to generate stylistically diverse yet logically equivalent code
implementations with pseudo-code, then align the code snippets of different
styles with pseudo-code, enhancing model robustness to code style variation. We
build PseudoBridge across 10 different PLMs and evaluate it on 6 mainstream
programming languages. Extensive experiments demonstrate that PseudoBridge
consistently outperforms baselines, achieving significant gains in retrieval
accuracy and generalization, particularly under zero-shot domain transfer
scenarios such as Solidity and XLCoST datasets. These results demonstrate the
effectiveness of explicit logical alignment via pseudo-code and highlight
PseudoBridge's potential as a robust, generalizable solution for code
retrieval.

</details>


### [17] [Designing for Novice Debuggers: A Pilot Study on an AI-Assisted Debugging Tool](https://arxiv.org/abs/2509.21067)
*Oka Kurniawan,Erick Chandra,Christopher M. Poskitt,Yannic Noller,Kenny Tsu Wei Choo,Cyrille Jegourel*

Main category: cs.SE

TL;DR: 本文提出并评估了结合传统调试方法与大型语言模型的CodeHinter调试工具，结果显示其能帮助编程初学者更高效地定位和修复语义错误，未来工具应注重个性化以促进学生主动参与。


<details>
  <summary>Details</summary>
Motivation: 现有许多智能调试工具虽然能帮助初学者修复代码错误，但很多工具过度依赖人工智能，无法有效激励学生主动参与调试过程。

Method: 本文提出CodeHinter调试助手，将传统调试工具与大语言模型技术结合，并进行了第二次设计迭代，在本科生群体中进行了用户测试。

Result: 学生认为新版工具在解决语义错误时非常有效，且比第一版更易使用。定位错误（error localization）依然是最有价值的功能。此外，研究认为调试工具应根据用户特征进行个性化优化，以提升交互效果。

Conclusion: 集成AI的调试工具可以提升学生修复语义错误的能力，但个人化设计是优化学生使用体验和效果的关键。AI工具不应替代学生的思考，而应促使其主动参与调试过程。

Abstract: Debugging is a fundamental skill that novice programmers must develop.
Numerous tools have been created to assist novice programmers in this process.
Recently, large language models (LLMs) have been integrated with automated
program repair techniques to generate fixes for students' buggy code. However,
many of these tools foster an over-reliance on AI and do not actively engage
students in the debugging process. In this work, we aim to design an intuitive
debugging assistant, CodeHinter, that combines traditional debugging tools with
LLM-based techniques to help novice debuggers fix semantic errors while
promoting active engagement in the debugging process. We present findings from
our second design iteration, which we tested with a group of undergraduate
students. Our results indicate that the students found the tool highly
effective in resolving semantic errors and significantly easier to use than the
first version. Consistent with our previous study, error localization was the
most valuable feature. Finally, we conclude that any AI-assisted debugging tool
should be personalized based on user profiles to optimize their interactions
with students.

</details>


### [18] [An Improved Quantum Software Challenges Classification Approach using Transfer Learning and Explainable AI](https://arxiv.org/abs/2509.21068)
*Nek Dil Khan,Javed Ali Khan,Mobashir Husain,Muhammad Sohail Khan,Arif Ali Khan,Muhammad Azeem Akbar,Shahid Hussain*

Main category: cs.SE

TL;DR: 本文提出用Transformer模型对量子软件工程常见挑战问题进行分类，准确率提升到95%，有助于论坛和厂商优化技术问题管理，但需进一步实际应用验证。


<details>
  <summary>Details</summary>
Motivation: 量子软件工程（QSE）开发者在优化量子计算和QSE相关技术时常面临诸多挑战。目前在Stack Overflow等平台上的量子标签提问多聚焦于技术细节，尚缺乏针对QSE挑战的系统化分类与分析。通过将问题按量子概念分类，可以更精准地识别和解决常见的QSE难题。

Method: 研究团队从问答平台提取了2829个与量子相关的标签问题，利用内容分析与扎根理论对发帖内容标注主要挑战类别，构建了真实数据集。使用ChatGPT协助人工标注及解决分歧。随后利用BERT、DistilBERT、RoBERTa等Transformer模型对讨论文本自动分类，并与传统深度/机器学习方法（包括FNN、CNN、LSTM）进行了对比。应用SHAP技术解释模型决策过程。

Result: Transformer系列模型（以DistilBERT表现最佳）在QSE挑战分类任务上平均准确率高达95%，相比传统深度学习方法提升6%。SHAP解释显示了语言特征对模型预测的影响。最终，该方法有助于量子厂商和论坛更好地整理技术讨论，提升获取与可读性。

Conclusion: 基于Transformer的文本分类方法可高效、准确地识别量子软件工程实践中常见的问题类型，优于传统深度/机器学习方法。标注和自动分类相结合提升了数据集的可靠性和应用价值，但仍需与实际开发者和厂商开展实证测试。

Abstract: Quantum Software Engineering (QSE) is a research area practiced by tech
firms. Quantum developers face challenges in optimizing quantum computing and
QSE concepts. They use Stack Overflow (SO) to discuss challenges and label
posts with specialized quantum tags, which often refer to technical aspects
rather than developer posts. Categorizing questions based on quantum concepts
can help identify frequent QSE challenges. We conducted studies to classify
questions into various challenges. We extracted 2829 questions from Q&A
platforms using quantum-related tags. Posts were analyzed to identify frequent
challenges and develop a novel grounded theory. Challenges include Tooling,
Theoretical, Learning, Conceptual, Errors, and API Usage. Through content
analysis and grounded theory, discussions were annotated with common challenges
to develop a ground truth dataset. ChatGPT validated human annotations and
resolved disagreements. Fine-tuned transformer algorithms, including BERT,
DistilBERT, and RoBERTa, classified discussions into common challenges. We
achieved an average accuracy of 95% with BERT DistilBERT, compared to
fine-tuned Deep and Machine Learning (D&ML) classifiers, including Feedforward
Neural Networks (FNN), Convolutional Neural Networks (CNN), and Long Short-Term
Memory networks (LSTM), which achieved accuracies of 89%, 86%, and 84%,
respectively. The Transformer-based approach outperforms the D&ML-based
approach with a 6\% increase in accuracy by processing actual discussions,
i.e., without data augmentation. We applied SHAP (SHapley Additive
exPlanations) for model interpretability, revealing how linguistic features
drive predictions and enhancing transparency in classification. These findings
can help quantum vendors and forums better organize discussions for improved
access and readability. However,empirical evaluation studies with actual
developers and vendors are needed.

</details>


### [19] [Fine-Tuning LLMs to Analyze Multiple Dimensions of Code Review: A Maximum Entropy Regulated Long Chain-of-Thought Approach](https://arxiv.org/abs/2509.21170)
*Yongda Yu,Guohao Shi,Xianwei Wu,Haochuan He,XueMing Gu,Qianqian Zhao,Kui Liu,Qiushi Wang,Zhao Tian,Haifeng Shen,Guoping Rong*

Main category: cs.SE

TL;DR: MelcotCR通过链式思维微调和最大熵方法，提升了大模型多维度代码审查能力，使小模型表现媲美超大模型。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型虽然具备代码理解与推理能力，但因训练数据有限，难以像人类评审员一样多维度分析问题。当前微调方法对用于微调的信息维度有限，制约了模型性能。

Method: 提出了MelcotCR方法，采用链式思维（COT）微调策略，通过长链COT技术强化模型多维度代码评审能力。为解决长COT中上下文及推理逻辑损失的问题，结合最大熵（ME）建模和预定义推理路径，提升模型对长COT提示的有效利用和逻辑严密性。

Result: 实证评估表明，采用MelcotCR微调的低参数基座模型（如14B Qwen2.5）在检测和描述代码问题的准确性上超越了现有最佳方法，并与超大模型（如671B DeepSeek-R1）性能相当。

Conclusion: 通过富结构化信息和逻辑严密的推理路径，MelcotCR显著提升了大语言模型在代码评审任务上的表现，尤其在资源受限场景下优势明显。

Abstract: Large Language Models (LLMs) have shown great potential in supporting
automated code review due to their impressive capabilities in context
understanding and reasoning. However, these capabilities are still limited
compared to human-level cognition because they are heavily influenced by the
training data. Recent research has demonstrated significantly improved
performance through fine-tuning LLMs with code review data. However, compared
to human reviewers who often simultaneously analyze multiple dimensions of code
review to better identify issues, the full potential of these methods is
hampered by the limited or vague information used to fine-tune the models. This
paper contributes MelcotCR, a chain-of-thought (COT) fine-tuning approach that
trains LLMs with an impressive reasoning ability to analyze multiple dimensions
of code review by harnessing long COT techniques to provide rich structured
information. To address context loss and reasoning logic loss issues that
frequently occur when LLMs process long COT prompts, we propose a solution that
combines the Maximum Entropy (ME) modeling principle with pre-defined reasoning
pathways in MelcotCR to enable more effective utilization of in-context
knowledge within long COT prompts while strengthening the logical tightness of
the reasoning process. Empirical evaluations on our curated MelcotCR dataset
and the public CodeReviewer dataset reveal that a low-parameter base model,
such as 14B Qwen2.5, fine-tuned with MelcotCR can surpass state-of-the-art
methods in terms of the accuracy of detecting and describing code issues, with
its performance remarkably on par with that of the 671B DeepSeek-R1 model.

</details>


### [20] [Semantic Clustering of Civic Proposals: A Case Study on Brazil's National Participation Platform](https://arxiv.org/abs/2509.21292)
*Ronivaldo Ferreira,Guilherme da Silva,Carla Rocha,Gustavo Pinto*

Main category: cs.SE

TL;DR: 用人工智能主题归类技术提升数字平台民众参与数据的整理效率，帮助政府将建议转化为政策参考。


<details>
  <summary>Details</summary>
Motivation: 政府希望提升数字平台上的公众参与度，但收集到的大量建议难以有效整理和利用，人工分类效率低且需专家参与，同时又需与官方分类体系保持一致。

Method: 提出了结合BERTopic主题建模、种子词与大语言模型自动验证的新方法，实现高效自动化主题归类。

Result: 初步结果显示，生成的主题具有良好的连贯性和与机构分类体系的一致性，且对人工参与需求极低。

Conclusion: 该方法可帮助政府将大量民众建议快速转化为可用于公共政策制定的结构化数据，提升参与价值。

Abstract: Promoting participation on digital platforms such as Brasil Participativo has
emerged as a top priority for governments worldwide. However, due to the sheer
volume of contributions, much of this engagement goes underutilized, as
organizing it presents significant challenges: (1) manual classification is
unfeasible at scale; (2) expert involvement is required; and (3) alignment with
official taxonomies is necessary. In this paper, we introduce an approach that
combines BERTopic with seed words and automatic validation by large language
models. Initial results indicate that the generated topics are coherent and
institutionally aligned, with minimal human effort. This methodology enables
governments to transform large volumes of citizen input into actionable data
for public policy.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [21] [A Unified Formal Theory on the Logical Limits of Symbol Grounding](https://arxiv.org/abs/2509.20409)
*Zhangchi Liu*

Main category: cs.LO

TL;DR: 本论文以形式证明方式，阐述了符号基础问题的逻辑极限。证明了意义的生成不能仅依赖于封闭形式系统或预设算法，必须借助外部、动态且非算法性的过程。这揭示了所有自封闭智能系统在意义建构上的根本不完备性。


<details>
  <summary>Details</summary>
Motivation: 探讨符号基础问题（Symbol Grounding Problem）在形式系统中的逻辑极限，明确形式系统是否能够自洽地产生意义。

Method: 通过四个阶段的形式证明，分析纯符号系统的自洽性、有限静态意义系统的完备性，以及符号与外部意义连接的逻辑过程。

Result: 证明无外部连接的纯符号系统无法自洽地产生意义；有限预设意义系统固有不完备性；将符号与外部意义连接不是系统内部逻辑推理的结果，而须是元级公理性更新；而试图通过固定算法自动化这一过程仍会导致系统不完备。

Conclusion: 符号意义的基础必须是开放、动态、非算法性的过程，对任何封闭智能系统来说存在哥德尔式的根本限制。

Abstract: This paper synthesizes a series of formal proofs to construct a unified
theory on the logical limits of the Symbol Grounding Problem. We demonstrate
through a four-stage argument that meaning within a formal system must arise
from a process that is external, dynamic, and non-algorithmic. First, we prove
that any purely symbolic system, devoid of external connections, cannot
internally establish a consistent foundation for meaning due to
self-referential paradoxes. Second, we extend this limitation to systems with
any finite, static set of pre-established meanings, proving they are inherently
incomplete. Third, we demonstrate that the very "act" of connecting an internal
symbol to an external meaning cannot be a product of logical inference within
the system but must be an axiomatic, meta-level update. Finally, we prove that
any attempt to automate this update process using a fixed, external "judgment"
algorithm will inevitably construct a larger, yet equally incomplete, symbolic
system. Together, these conclusions formally establish that the grounding of
meaning is a necessarily open-ended, non-algorithmic process, revealing a
fundamental, G\"odel-style limitation for any self-contained intelligent
system.

</details>


### [22] [Reverse Faà di Bruno's Formula for Cartesian Reverse Differential Categories](https://arxiv.org/abs/2509.20931)
*Aaron Biggin,Jean-Simon Pacaud Lemay*

Main category: cs.LO

TL;DR: 本文在范畴论框架下，首次提出了笛卡尔反向微分范畴中的高阶反向链式法则，完善了自动微分理论的公理化体系。


<details>
  <summary>Details</summary>
Motivation: 反向自动微分在机器学习等领域至关重要，而笛卡尔反向微分范畴为其提供了范畴学的公理化模型。过去关于一阶逆链式法则已有探讨，但更高阶的反向微分链式法则仍欠缺系统化刻画。

Method: 本文以范畴论方法为基础，在笛卡尔反向微分范畴框架下，定义了偏反向导数与高阶反向导数，进而推导并提出了反向微分的Faa di Bruno公式，即高阶反向链式法则。

Result: 提出了笛卡尔反向微分范畴中的高阶链式法则（Faa di Bruno公式的反向微分类比），并严格给出了偏反向导数和高阶反向导数的定义。

Conclusion: 本文填补了笛卡尔反向微分范畴中高阶反向链式法则的理论空白，为自动微分的高阶理论提供了范畴学工具和基础。

Abstract: Reverse differentiation is an essential operation for automatic
differentiation. Cartesian reverse differential categories axiomatize reverse
differentiation in a categorical framework, where one of the primary axioms is
the reverse chain rule, which is the formula that expresses the reverse
derivative of a composition. Here, we present the reverse differential analogue
of Faa di Bruno's Formula, which gives a higher-order reverse chain rule in a
Cartesian reverse differential category. To properly do so, we also define
partial reverse derivatives and higher-order reverse derivatives in a Cartesian
reverse differential category.

</details>


### [23] [A Coalgebraic Model of Quantum Bisimulation](https://arxiv.org/abs/2509.20933)
*Lorenzo Ceragioli,Elena Di Lavore,Giuseppe Lomurno,Gabriele Tedeschi*

Main category: cs.LO

TL;DR: 本文针对量子并发系统的行为等价问题，借助泛型效应代数与分级单子的工具，提出了以kernel双仿真为核心的理论框架，可刻画所有输入态下行为一致的量子系统，并设计了量子标签过程演算的语义基础。


<details>
  <summary>Details</summary>
Motivation: 针对当前量子系统中定义行为等价性困难，尤其是在并发、非确定性及量子效应下，试图找到一种能够正确匹配系统可观测性质的行为等价理论。

Method: 采用泛型效应代数上的分布式余代数（coalgebra）方法，提出了基于部分交换幺半群分级单子（graded monad）的形式化工具，以保证符合量子理论（如不可克隆定理）的要求。并比较了Aczel-Mendler和kernel双仿真（bisimilarity），并对后者进行了倡导。

Result: 证明了kernel双仿真能够刻画对所有输入态都表现出相同概率行为的量子系统，并提出了量子效应标记转换系统（quantum effect labelled transition system）上的运算符框架，实现了对量子输入参数的过程演算语义。

Conclusion: 提出了一套能广泛覆盖并发量子系统行为等价性的理论框架，并通过对概率性与量子态的泛化描述，为后续量子过程演算的语义设计和分析提供了基础。

Abstract: Recent works have shown that defining a behavioural equivalence that matches
the observational properties of a quantum-capable, concurrent,
non-deterministic system is a surprisingly difficult task. We explore
coalgebras over distributions taking weights from a generic effect algebra,
which subsumes probabilities and quantum effects, a physical formalism that
represents the probabilistic behaviour of an open quantum system. To abide by
the properties of quantum theory, we introduce monads graded on a partial
commutative monoid, intuitively allowing composition of two processes only if
they use different quantum resources, as prescribed by the no-cloning theorem.
We investigate the relation between an open quantum system and its
probabilistic counterparts obtained when instantiating the input with a
specific quantum state. We consider Aczel-Mendler and kernel bisimilarities,
advocating for the latter as it characterizes quantum systems that exhibit the
same probabilistic behaviour for all input states. Finally, we propose
operators on quantum effect labelled transition systems, paving the way for a
process calculi semantics that is parametric over the quantum input.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [24] [Interpreting Public Sentiment in Diplomacy Events: A Counterfactual Analysis Framework Using Large Language Models](https://arxiv.org/abs/2509.20367)
*Leyi Ouyang*

Main category: cs.CL

TL;DR: 本文提出一种自动修改外交事件叙述以改善公众情绪的新框架，通过大模型生成反事实文本，成功率达70%，为外交传播和舆论引导提供实用工具。


<details>
  <summary>Details</summary>
Motivation: 传统测量公众情绪方式（如大规模问卷、人工内容分析）效率低、费时费力且缺乏前瞻性。基于文本自动化方法可为政策制定者有效调整对外沟通和事件表述，进而优化舆论氛围。

Method: （1）训练语言模型预测外交事件引发的公众反应；（2）建立包含事件描述和相关舆论讨论的数据集；（3）与领域专家合作、基于传播理论，预设文本可修改特征；（4）设计反事实生成算法，利用大型语言模型系统性修改原文叙述，并保持事实核心不变。

Result: 通过该框架，70%的案例能将负面情绪转为中性或积极，验证了方法的有效性。该工具为外交人员、政策制定者和传播专家，提供了基于数据的叙事优化建议。

Conclusion: 提出的框架能够有效地通过修改外交事件叙述方式，将公众情绪从负面转变为更中性或积极，成功率达70%。

Abstract: Diplomatic events consistently prompt widespread public discussion and
debate. Public sentiment plays a critical role in diplomacy, as a good
sentiment provides vital support for policy implementation, helps resolve
international issues, and shapes a nation's international image. Traditional
methods for gauging public sentiment, such as large-scale surveys or manual
content analysis of media, are typically time-consuming, labor-intensive, and
lack the capacity for forward-looking analysis. We propose a novel framework
that identifies specific modifications for diplomatic event narratives to shift
public sentiment from negative to neutral or positive. First, we train a
language model to predict public reaction towards diplomatic events. To this
end, we construct a dataset comprising descriptions of diplomatic events and
their associated public discussions. Second, guided by communication theories
and in collaboration with domain experts, we predetermined several textual
features for modification, ensuring that any alterations changed the event's
narrative framing while preserving its core facts.We develop a counterfactual
generation algorithm that employs a large language model to systematically
produce modified versions of an original text. The results show that this
framework successfully shifted public sentiment to a more favorable state with
a 70\% success rate. This framework can therefore serve as a practical tool for
diplomats, policymakers, and communication specialists, offering data-driven
insights on how to frame diplomatic initiatives or report on events to foster a
more desirable public sentiment.

</details>


### [25] [Speaker Style-Aware Phoneme Anchoring for Improved Cross-Lingual Speech Emotion Recognition](https://arxiv.org/abs/2509.20373)
*Shreya G. Upadhyay,Carlos Busso,Chi-Chun Lee*

Main category: cs.CL

TL;DR: 跨语种语音情感识别存在语言和说话者风格差异，本文提出结合说话者社群和音素空间锚定的新方法，实现更好的跨语种情感泛化和迁移，并在英语与台式普通话数据集上取得领先表现。


<details>
  <summary>Details</summary>
Motivation: 跨语种的语音情感识别因语言间的语音变异和说话者表达风格差异而具有很大挑战，需要能够有效对齐不同语言和说话者间情感外化的方法。

Method: 提出了一种结合说话者风格感知和音素锚定的框架，通过图聚类构建情感相关的说话者社群，并在说话者和音素空间中实现双空间锚定，以提升跨语言的情感迁移能力。

Result: 在MSP-Podcast（英语）和BIIC-Podcast（台式普通话）数据集上，该方法在情感识别泛化能力方面优于主流基线方法。

Conclusion: 基于说话者风格和音素锚定的框架可提升跨语种语音情感识别的泛化能力，揭示不同语言间情感表达的共同特征。

Abstract: Cross-lingual speech emotion recognition (SER) remains a challenging task due
to differences in phonetic variability and speaker-specific expressive styles
across languages. Effectively capturing emotion under such diverse conditions
requires a framework that can align the externalization of emotions across
different speakers and languages. To address this problem, we propose a
speaker-style aware phoneme anchoring framework that aligns emotional
expression at the phonetic and speaker levels. Our method builds
emotion-specific speaker communities via graph-based clustering to capture
shared speaker traits. Using these groups, we apply dual-space anchoring in
speaker and phonetic spaces to enable better emotion transfer across languages.
Evaluations on the MSP-Podcast (English) and BIIC-Podcast (Taiwanese Mandarin)
corpora demonstrate improved generalization over competitive baselines and
provide valuable insights into the commonalities in cross-lingual emotion
representation.

</details>


### [26] [CFD-LLMBench: A Benchmark Suite for Evaluating Large Language Models in Computational Fluid Dynamics](https://arxiv.org/abs/2509.20374)
*Nithin Somasekharan,Ling Yue,Yadi Cao,Weichao Li,Patrick Emami,Pochinapeddi Sai Bhargav,Anurag Acharya,Xingyu Xie,Shaowu Pan*

Main category: cs.CL

TL;DR: 本文提出了CFDLLMBench基准套件，系统评估大型语言模型在计算流体力学自动化数值实验中的能力，涵盖知识、推理和实际操作三个维度，为LLM加速复杂物理系统数值实验的自动化奠定基础。套件已开源。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在通用自然语言处理任务中表现优异，但在自动化复杂物理系统数值实验方面的应用还未被充分探索。数值实验是计算科学中至关重要且耗费人力的部分，特别是在计算流体力学（CFD）领域。该领域为评估LLM科学能力提供了独特且具有挑战性的试验场。

Method: 作者提出了CFDLLMBench，一个包含三大部分（CFDQuery、CFDCodeBench、FoamBench）的基准测试套件，从CFD知识、数值与物理推理、以及依赖情境的CFD工作流实现三个关键能力全面评估LLM。该套件结合了详细任务分类、严格评估框架，通过代码可执行性、解的准确性、数值收敛性等维度，确保评测结果的可重现性。

Result: CFDLLMBench能够量化LLM在自动化复杂物理系统数值实验中的表现，为未来LLM驱动的科学计算自动化发展与评估奠定了坚实基础。相关代码和数据已开源。

Conclusion: CFDLLMBench为评估和推进LLM在科学数值实验自动化领域应用提供了系统化工具和基础，推动LLM科学化能力的进一步发展。

Abstract: Large Language Models (LLMs) have demonstrated strong performance across
general NLP tasks, but their utility in automating numerical experiments of
complex physical system -- a critical and labor-intensive component -- remains
underexplored. As the major workhorse of computational science over the past
decades, Computational Fluid Dynamics (CFD) offers a uniquely challenging
testbed for evaluating the scientific capabilities of LLMs. We introduce
CFDLLMBench, a benchmark suite comprising three complementary components --
CFDQuery, CFDCodeBench, and FoamBench -- designed to holistically evaluate LLM
performance across three key competencies: graduate-level CFD knowledge,
numerical and physical reasoning of CFD, and context-dependent implementation
of CFD workflows. Grounded in real-world CFD practices, our benchmark combines
a detailed task taxonomy with a rigorous evaluation framework to deliver
reproducible results and quantify LLM performance across code executability,
solution accuracy, and numerical convergence behavior. CFDLLMBench establishes
a solid foundation for the development and evaluation of LLM-driven automation
of numerical experiments for complex physical systems. Code and data are
available at https://github.com/NREL-Theseus/cfdllmbench/.

</details>


### [27] [Assessing Classical Machine Learning and Transformer-based Approaches for Detecting AI-Generated Research Text](https://arxiv.org/abs/2509.20375)
*Sharanya Parimanoharan,Ruwan D. Nawarathna*

Main category: cs.CL

TL;DR: 本研究比较多种机器学习方法用于检测ChatGPT-3.5生成文本，发现DistilBERT效果最佳，模型集成难以超过单一优秀Transformers模型，建议后续采用大量、多样数据集构建更强AI文本检测器。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）如ChatGPT的快速普及，人工与AI生成文本之间的界限变得模糊，给学术诚信、知识产权和虚假信息传播带来紧迫挑战。因此，亟需可靠的AI文本检测方法，以公平评估并维护人类表达的真实性。

Method: 作者收集了涵盖不同研究主题的250对人工与ChatGPT-3.5生成的摘要，通过对比测试了经典机器学习方法（如Logistic Regression结合Bag-of-Words、POS和TF-IDF特征）以及多种基于Transformer的模型（如DistilBERT、BERT带自定义分类器、BERT与N-gram、LSTM与N-gram），并采用模型集成（max voting ensemble）来探索提升检测性能的可能性。

Result: DistilBERT在区分AI生成文本与人工文本方面表现最佳，Logistic Regression和BERT自定义分类器也展现出较均衡的性能，LSTM和BERT-N-gram方法则表现较弱。多模型集成（max voting ensemble）未能超过单一DistilBERT模型的表现，说明Transformer架构的表征能力优于模型多样性带来的提升。

Conclusion: 当前以Transformer为基础的模型（如DistilBERT）在AI文本检测领域具有明显优势。本文为未来采用更大、更丰富数据集，构建更强健的Transformer检测框架打下基础，以应对日益进步的AI生成文本的挑战。

Abstract: The rapid adoption of large language models (LLMs) such as ChatGPT has
blurred the line between human and AI-generated texts, raising urgent questions
about academic integrity, intellectual property, and the spread of
misinformation. Thus, reliable AI-text detection is needed for fair assessment
to safeguard human authenticity and cultivate trust in digital communication.
In this study, we investigate how well current machine learning (ML) approaches
can distinguish ChatGPT-3.5-generated texts from human-written texts employing
a labeled data set of 250 pairs of abstracts from a wide range of research
topics. We test and compare both classical (Logistic Regression armed with
classical Bag-of-Words, POS, and TF-IDF features) and transformer-based (BERT
augmented with N-grams, DistilBERT, BERT with a lightweight custom classifier,
and LSTM-based N-gram models) ML detection techniques. As we aim to assess each
model's performance in detecting AI-generated research texts, we also aim to
test whether an ensemble of these models can outperform any single detector.
Results show DistilBERT achieves the overall best performance, while Logistic
Regression and BERT-Custom offer solid, balanced alternatives; LSTM- and
BERT-N-gram approaches lag. The max voting ensemble of the three best models
fails to surpass DistilBERT itself, highlighting the primacy of a single
transformer-based representation over mere model diversity. By comprehensively
assessing the strengths and weaknesses of these AI-text detection approaches,
this work lays a foundation for more robust transformer frameworks with larger,
richer datasets to keep pace with ever-improving generative AI models.

</details>


### [28] [ConceptViz: A Visual Analytics Approach for Exploring Concepts in Large Language Models](https://arxiv.org/abs/2509.20376)
*Haoxuan Li,Zhen Wen,Qiqi Jiang,Chenxiao Li,Yuwei Wu,Yuchen Yang,Yiyao Wang,Xiuqi Huang,Minfeng Zhu,Wei Chen*

Main category: cs.CL

TL;DR: 本文提出ConceptViz系统，通过可视化和交互流程，实现LLMs中SAE特征与人类概念的高效对齐和验证，提高模型可解释性。


<details>
  <summary>Details</summary>
Motivation: LLMs虽表现卓越，但其内部知识表示仍难以理解。SAE虽能提取可解释特征，但这些特征与人类可理解概念并不天然匹配，解释繁琐且耗时。因此需要工具将SAE特征与人类概念相连接。

Method: 提出了一套新的可视化分析系统ConceptViz，基于SAE特征，采用“识别—解释—验证”流程，支持用户用感兴趣的概念查询SAE，互动探索特征与概念的对应关系，并通过模型行为验证其相关性。

Result: 在两个使用场景和用户研究中，ConceptViz展现了帮助研究者发现和验证LLMs中概念表示的能力，增强了特征可解释性。相关代码和用户手册已开源。

Conclusion: ConceptViz有效提升了LLMs的可解释性研究，通过简化寻找和验证有意义概念表示的流程，帮助研究者更准确理解LLMs内部特征。

Abstract: Large language models (LLMs) have achieved remarkable performance across a
wide range of natural language tasks. Understanding how LLMs internally
represent knowledge remains a significant challenge. Despite Sparse
Autoencoders (SAEs) have emerged as a promising technique for extracting
interpretable features from LLMs, SAE features do not inherently align with
human-understandable concepts, making their interpretation cumbersome and
labor-intensive. To bridge the gap between SAE features and human concepts, we
present ConceptViz, a visual analytics system designed for exploring concepts
in LLMs. ConceptViz implements a novel dentification => Interpretation =>
Validation pipeline, enabling users to query SAEs using concepts of interest,
interactively explore concept-to-feature alignments, and validate the
correspondences through model behavior verification. We demonstrate the
effectiveness of ConceptViz through two usage scenarios and a user study. Our
results show that ConceptViz enhances interpretability research by streamlining
the discovery and validation of meaningful concept representations in LLMs,
ultimately aiding researchers in building more accurate mental models of LLM
features. Our code and user guide are publicly available at
https://github.com/Happy-Hippo209/ConceptViz.

</details>


### [29] [SKILL-RAG: Self-Knowledge Induced Learning and Filtering for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.20377)
*Tomoaki Isoda*

Main category: cs.CL

TL;DR: 该论文提出SKILL-RAG方法，利用大模型的自我知识改进检索增强生成任务。实验表明，该方法能过滤无用信息，提升生成质和效率。


<details>
  <summary>Details</summary>
Motivation: RAG方法虽然提升了大模型在知识密集任务的表现，但因检索内容可能无关，容易带来幻觉现象。因此，如何识别和过滤无用的检索内容成为提升RAG性能的关键。

Method: 提出了一种新方法SKILL-RAG（Self-Knowledge Induced Learning and Filtering for RAG），利用模型的自我知识来判断哪些检索文档对回答查询有帮助。该方法采用基于强化学习的训练框架，在句子级别过滤无关内容，同时保留有用知识。

Result: 在Llama2-7B和Qwen3-8B上，通过多个问答基准测试，SKILL-RAG不仅提升了生成质量，还显著减少了输入文档数量，验证了自我知识在高质量检索选择中的重要作用。

Conclusion: SKILL-RAG方法有效地结合了模型的内在知识和外部检索知识，通过自我知识引导检索内容筛选，提升了RAG的整体表现和效率。

Abstract: Retrieval-Augmented Generation (RAG) has significantly improved the
performance of large language models (LLMs) on knowledge-intensive tasks in
recent years. However, since retrieval systems may return irrelevant content,
incorporating such information into the model often leads to hallucinations.
Thus, identifying and filtering out unhelpful retrieved content is a key
challenge for improving RAG performance.To better integrate the internal
knowledge of the model with external knowledge from retrieval, it is essential
to understand what the model "knows" and "does not know" (which is also called
"self-knowledge"). Based on this insight, we propose SKILL-RAG (Self-Knowledge
Induced Learning and Filtering for RAG), a novel method that leverages the
model's self-knowledge to determine which retrieved documents are beneficial
for answering a given query. We design a reinforcement learning-based training
framework to explicitly elicit self-knowledge from the model and employs
sentence-level granularity to filter out irrelevant content while preserving
useful knowledge.We evaluate SKILL-RAG using Llama2-7B and Qwen3-8B on several
question answering benchmarks. Experimental results demonstrate that SKILL-RAG
not only improves generation quality but also significantly reduces the number
of input documents, validating the importance of self-knowledge in guiding the
selection of high-quality retrievals.

</details>


### [30] [Beyond Global Emotion: Fine-Grained Emotional Speech Synthesis with Dynamic Word-Level Modulation](https://arxiv.org/abs/2509.20378)
*Sirui Wang,Andong Chen,Tiejun Zhao*

Main category: cs.CL

TL;DR: Emo-FiLM实现了基于LLM的词级情感可控语音合成，通过FiLM调节机制和细粒度标注，有效提升了E-TTS的自然度和表现力，在多个任务上超越现有方案。


<details>
  <summary>Details</summary>
Motivation: 现有E-TTS方法多采用标签、参考音频或提示词进行句级情感控制，难以捕捉句内动态变化。为实现更细致、自然的情感表达，亟需具备词级调控能力的新方法。

Method: 提出了Emo-FiLM框架，通过将emotion2vec的帧级情感特征与文本单词对齐，获得词级情感标注，然后通过FiLM层对文本嵌入进行调制，实现词级情感控制。同时构建了细粒度情感动态数据集（FEDD）用于评估模型效果。

Result: Emo-FiLM显著优于现有的句级情感控制方法，能准确捕捉并合成句内细粒度的情感动态，在全局和细粒度情感合成任务上取得了更好的表现。

Conclusion: Emo-FiLM在全局和细粒度情感表达任务上均优于现有方法，提升了语音合成的表达力和泛化能力。

Abstract: Emotional text-to-speech (E-TTS) is central to creating natural and
trustworthy human-computer interaction. Existing systems typically rely on
sentence-level control through predefined labels, reference audio, or natural
language prompts. While effective for global emotion expression, these
approaches fail to capture dynamic shifts within a sentence. To address this
limitation, we introduce Emo-FiLM, a fine-grained emotion modeling framework
for LLM-based TTS. Emo-FiLM aligns frame-level features from emotion2vec to
words to obtain word-level emotion annotations, and maps them through a
Feature-wise Linear Modulation (FiLM) layer, enabling word-level emotion
control by directly modulating text embeddings. To support evaluation, we
construct the Fine-grained Emotion Dynamics Dataset (FEDD) with detailed
annotations of emotional transitions. Experiments show that Emo-FiLM
outperforms existing approaches on both global and fine-grained tasks,
demonstrating its effectiveness and generality for expressive speech synthesis.

</details>


### [31] [USB-Rec: An Effective Framework for Improving Conversational Recommendation Capability of Large Language Model](https://arxiv.org/abs/2509.20381)
*Jianyu Wen,Jingyun Wang,Cilin Yan,Jiayin Cai,Xiaolong Jiang,Ying Zhang*

Main category: cs.CL

TL;DR: 提出了一种结合训练和推理的对话推荐新方法，通过模拟用户和自我增强策略显著提升了大模型的推荐效果，并获得了优异的实验结果。


<details>
  <summary>Details</summary>
Motivation: 以往LLMs在对话式推荐系统中过度依赖推理与分析能力，忽视针对训练环节的优化，因此提出结合训练和推理的新方法以提升整体性能。

Method: 通过设计偏好优化数据集用于强化学习训练，并在推理阶段应用自增强策略，综合提升模型的理解和推荐能力。

Result: 在多个公开数据集上进行大量实验，证实所提方法在各项指标上优于此前最优技术。

Conclusion: 采用USB-Rec综合训练-推理框架，使LLMs在对话式推荐领域性能提升，并持续超越现有方法。

Abstract: Recently, Large Language Models (LLMs) have been widely employed in
Conversational Recommender Systems (CRSs). Unlike traditional language model
approaches that focus on training, all existing LLMs-based approaches are
mainly centered around how to leverage the summarization and analysis
capabilities of LLMs while ignoring the issue of training. Therefore, in this
work, we propose an integrated training-inference framework,
User-Simulator-Based framework (USB-Rec), for improving the performance of LLMs
in conversational recommendation at the model level. Firstly, we design a
LLM-based Preference Optimization (PO) dataset construction strategy for RL
training, which helps the LLMs understand the strategies and methods in
conversational recommendation. Secondly, we propose a Self-Enhancement Strategy
(SES) at the inference stage to further exploit the conversational
recommendation potential obtained from RL training. Extensive experiments on
various datasets demonstrate that our method consistently outperforms previous
state-of-the-art methods.

</details>


### [32] [Document Summarization with Conformal Importance Guarantees](https://arxiv.org/abs/2509.20461)
*Bruce Kuwahara,Chen-Yuan Lin,Xiao Shi Huang,Kin Kwan Leung,Jullian Arta Yapeter,Ilya Stanevich,Felipe Perez,Jesse C. Cresswell*

Main category: cs.CL

TL;DR: 本文提出了一种结合共形预测的新型自动摘要方法，通过校准重要性分数，实现对关键信息覆盖率的严格保障。此方法兼容现有大模型，仅需小规模校准集，在多个基准上验证了其有效性，为高风险领域AI摘要工具的安全部署奠定基础。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在自动摘要领域取得了很大发展，但在医疗、法律和金融等高风险领域，摘要是否包含关键信息却缺乏可靠保障。为此，作者旨在提出一个能确保关键信息覆盖率的解决方案。

Method: 本文提出了Conformal Importance Summarization（CIS）方法，通过使用共形预测（conformal prediction）对句子级重要性分数设定阈值，实现对关键信息的可控覆盖抽取式摘要。该方法依赖于小规模的校准集，且对底层摘要模型无要求（模型无关），可与现有黑盒LLM直接结合。

Result: 实验显示，CIS能够达到理论保证的信息覆盖率，在主流摘要基准上取得优异表现。

Conclusion: CIS框架首次为自动摘要提供了重要性覆盖率的分布无关型严格保障，可与现有方法结合，为高风险领域自动摘要提供了更安全可靠的选择，有望推动AI摘要在关键应用中的部署。

Abstract: Automatic summarization systems have advanced rapidly with large language
models (LLMs), yet they still lack reliable guarantees on inclusion of critical
content in high-stakes domains like healthcare, law, and finance. In this work,
we introduce Conformal Importance Summarization, the first framework for
importance-preserving summary generation which uses conformal prediction to
provide rigorous, distribution-free coverage guarantees. By calibrating
thresholds on sentence-level importance scores, we enable extractive document
summarization with user-specified coverage and recall rates over critical
content. Our method is model-agnostic, requires only a small calibration set,
and seamlessly integrates with existing black-box LLMs. Experiments on
established summarization benchmarks demonstrate that Conformal Importance
Summarization achieves the theoretically assured information coverage rate. Our
work suggests that Conformal Importance Summarization can be combined with
existing techniques to achieve reliable, controllable automatic summarization,
paving the way for safer deployment of AI summarization tools in critical
applications. Code is available at
https://github.com/layer6ai-labs/conformal-importance-summarization.

</details>


### [33] [ShortCheck: Checkworthiness Detection of Multilingual Short-Form Videos](https://arxiv.org/abs/2509.20467)
*Henrik Vatndal,Vinay Setty*

Main category: cs.CL

TL;DR: 本研究提出一个多模态短视频核查系统ShortCheck，在TikTok多语言数据上实现了较高准确率，有效提升事实核查效率。


<details>
  <summary>Details</summary>
Motivation: 短视频平台如TikTok内容复杂多样，检测错误信息面临多模态、动态及噪音高等挑战，需要新的自动化工具来支持人工核查。

Method: 提出一个推理管道ShortCheck，集成语音转写、OCR、目标和深度伪造检测、视频到文本摘要、声明验证等多模态组件，评估方法为在多语言TikTok数据集上的验证。

Result: 在两个手动标注的多语言TikTok视频数据集上，ShortCheck取得了加权F1分数超过70%的有希望的结果。

Conclusion: ShortCheck系统有效辅助人工事实核查，能自动识别需要核查的短视频，并在多语言环境下表现良好。

Abstract: Short-form video platforms like TikTok present unique challenges for
misinformation detection due to their multimodal, dynamic, and noisy content.
We present ShortCheck, a modular, inference-only pipeline with a user-friendly
interface that automatically identifies checkworthy short-form videos to help
human fact-checkers. The system integrates speech transcription, OCR, object
and deepfake detection, video-to-text summarization, and claim verification.
ShortCheck is validated by evaluating it on two manually annotated datasets
with TikTok videos in a multilingual setting. The pipeline achieves promising
results with F1-weighted score over 70\%.

</details>


### [34] [MARS: toward more efficient multi-agent collaboration for LLM reasoning](https://arxiv.org/abs/2509.20502)
*Xiao Wang,Jia Wang,Yijie Wang,Pengtao Dang,Sha Cao,Chi Zhang*

Main category: cs.CL

TL;DR: 提出角色分工的多代理评审系统MARS，可在保证推理准确率的同时，将消耗和推理时间减半，适合高效和准确推理需求。


<details>
  <summary>Details</summary>
Motivation: 单个大型语言模型推理能力有限，多代理推理（MAD）虽然有效，但计算资源消耗大。现有方法需要多代理频繁沟通，导致推理成本高。

Method: 提出MARS（Multi-Agent Review System），借鉴论文评审流程，将角色分为作者代理、审稿人代理和元审稿人。作者负责生成初始解决方案，审稿人独立评判和反馈，元审稿人整合意见决策与指导修订。此框架减少审稿人间的直接沟通，从而降低资源消耗。

Result: 在多种基准测试和不同LLMs上，MARS在推理准确率方面与MAD相当，同时将推理所需的令牌用量和推理时间减少约50%。

Conclusion: MARS有效提升了多代理推理的资源效率，在保证准确率的同时显著降低了推理成本。该框架适合需要高效推理的LLM任务。

Abstract: Large language models (LLMs) have achieved impressive results in natural
language understanding, yet their reasoning capabilities remain limited when
operating as single agents. Multi-Agent Debate (MAD) has been proposed to
address this limitation by enabling collaborative reasoning among multiple
models in a round-table debate manner. While effective, MAD introduces
substantial computational overhead due to the number of agents involved and the
frequent communication required. In this paper, we propose MARS (Multi-Agent
Review System), a role-based collaboration framework inspired by the review
process. In MARS, an author agent generates an initial solution, reviewer
agents provide decisions and comments independently, and a meta-reviewer
integrates the feedback to make the final decision and guide further revision.
This design enhances reasoning quality while avoiding costly
reviewer-to-reviewer interactions, thereby controlling token consumption and
inference time. We compared MARS with both MAD and other state-of-the-art
reasoning strategies across multiple benchmarks. Extensive experiments with
different LLMs show that MARS matches the accuracy of MAD while reducing both
token usage and inference time by approximately 50\%. Code is available at
https://github.com/xwang97/MARS.

</details>


### [35] [SiniticMTError: A Machine Translation Dataset with Error Annotations for Sinitic Languages](https://arxiv.org/abs/2509.20557)
*Hannah Liu,Junghyun Min,Ethan Yue Heng Cheung,Shou-Yi Hung,Syed Mekael Wasti,Runtong Liang,Shiyao Qian,Shizhao Zheng,Elsie Chan,Ka Ieng Charlotte Lo,Wing Yu Yip,Richard Tzong-Han Tsai,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 本文提出并公开了SiniticMTError数据集，系统性地标注了英译普通话、粤语与吴语的机器翻译错误类型及严重性，将为低资源汉语方言的机器翻译质量提升和相关研究提供重要资源。


<details>
  <summary>Details</summary>
Motivation: 尽管近年来机器翻译(MT)取得了重大进展，但对于缺乏大规模训练数据的低资源语言，进展依然有限。粤语和吴语虽然拥有上千万的使用者，但依然属于此类低资源语言。

Method: 本文提出并构建了一个全新的数据集——SiniticMTError。在现有平行语料的基础上，针对英译普通话、粤语、吴语的机器翻译内容，人工标注了错误区间、错误类型和错误严重性。作者详细报告了标注流程，包括多位母语者的严谨标注、标注者间一致性分析、迭代反馈机制及错误类别与严重性的规律分析。

Result: SiniticMTError数据集为MT社区提供面向粤语和吴语等低资源语言的翻译错误标注数据，有助于后续模型微调、翻译质量评估、错误感知生成等研究方向的发展。

Conclusion: SiniticMTError填补了机器翻译在低资源汉语方言研究中的重要空白，将成为未来相关研究的重要基础资源。

Abstract: Despite major advances in machine translation (MT) in recent years, progress
remains limited for many low-resource languages that lack large-scale training
data and linguistic resources. Cantonese and Wu Chinese are two Sinitic
examples, although each enjoys more than 80 million speakers around the world.
In this paper, we introduce SiniticMTError, a novel dataset that builds on
existing parallel corpora to provide error span, error type, and error severity
annotations in machine-translated examples from English to Mandarin, Cantonese,
and Wu Chinese. Our dataset serves as a resource for the MT community to
utilize in fine-tuning models with error detection capabilities, supporting
research on translation quality estimation, error-aware generation, and
low-resource language evaluation. We report our rigorous annotation process by
native speakers, with analyses on inter-annotator agreement, iterative
feedback, and patterns in error type and severity.

</details>


### [36] [SwasthLLM: a Unified Cross-Lingual, Multi-Task, and Meta-Learning Zero-Shot Framework for Medical Diagnosis Using Contrastive Representations](https://arxiv.org/abs/2509.20567)
*Ayan Sar,Pranav Singh Puri,Sumit Aich,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: SwasthLLM是一款无需微调、支持多语言零样本医学疾病诊断的新型模型，在多种评测中表现优异，尤其适用于标注数据少的低资源语言医疗场景。


<details>
  <summary>Details</summary>
Motivation: 在多语言医疗环境中，由于低资源语言的医学数据标注稀缺及不同人群语言变异，医疗文本自动疾病诊断任务面临挑战。

Method: 提出了SwasthLLM框架，实现统一、零样本、跨语言及多任务的医学诊断，基于多语言XLM-RoBERTa编码器，加入语言感知注意力机制和疾病分类头，采用Siamese对比学习、翻译一致性模块和多任务联合优化，并采用MAML实现快速适应性。

Result: 在监督设置下，测试准确率为97.22%，F1分数为97.17%；零样本场景下，印度语文本准确率达92.78%，孟加拉语文本为73.33%，显现出低资源环境下的优异泛化能力。

Conclusion: SwasthLLM无需语言专属微调，在多语言环境下都能提供高效自动医学疾病诊断，尤其对低资源语言有强泛化性。

Abstract: In multilingual healthcare environments, automatic disease diagnosis from
clinical text remains a challenging task due to the scarcity of annotated
medical data in low-resource languages and the linguistic variability across
populations. This paper proposes SwasthLLM, a unified, zero-shot,
cross-lingual, and multi-task learning framework for medical diagnosis that
operates effectively across English, Hindi, and Bengali without requiring
language-specific fine-tuning. At its core, SwasthLLM leverages the
multilingual XLM-RoBERTa encoder augmented with a language-aware attention
mechanism and a disease classification head, enabling the model to extract
medically relevant information regardless of the language structure. To align
semantic representations across languages, a Siamese contrastive learning
module is introduced, ensuring that equivalent medical texts in different
languages produce similar embeddings. Further, a translation consistency module
and a contrastive projection head reinforce language-invariant representation
learning. SwasthLLM is trained using a multi-task learning strategy, jointly
optimizing disease classification, translation alignment, and contrastive
learning objectives. Additionally, we employ Model-Agnostic Meta-Learning
(MAML) to equip the model with rapid adaptation capabilities for unseen
languages or tasks with minimal data. Our phased training pipeline emphasizes
robust representation alignment before task-specific fine-tuning. Extensive
evaluation shows that SwasthLLM achieves high diagnostic performance, with a
test accuracy of 97.22% and an F1-score of 97.17% in supervised settings.
Crucially, in zero-shot scenarios, it attains 92.78% accuracy on Hindi and
73.33% accuracy on Bengali medical text, demonstrating strong generalization in
low-resource contexts.

</details>


### [37] [Dynamic Reasoning Chains through Depth-Specialized Mixture-of-Experts in Transformer Architectures](https://arxiv.org/abs/2509.20577)
*Sampurna Roy,Ayan Sar,Anurag Kaushish,Kanav Gupta,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: 论文提出DS-MoE框架，针对Transformer处理深度单一的问题，实现输入复杂度感知的动态专家路由，显著提升推理效率、准确率和可解释性，是大模型架构的一项重要进展。


<details>
  <summary>Details</summary>
Motivation: 当前的Transformer架构对所有输入采用相同的处理深度，导致资源浪费并限制推理质量。简单问题与复杂问题使用相同的计算流程，缺乏适应性和效率。作者希望通过更具动态和专门化的推理机制提升模型性能、效率与可解释性。

Method: 提出DS-MoE（Depth Specialised Mixture of Experts）框架，将专家混合机制从宽度扩展到深度方向。通过优化不同深度的专家模块，如浅层模式识别、组合推理、逻辑推断、记忆整合和元认知监督。采用学习型路由网络，根据输入复杂度动态组装并激活需要的专家，形成定制化的推理链。

Result: DS-MoE在The Pile多领域大规模语料上训练与评估。结果显示：与传统统一深度Transformer相比，DS-MoE节省最多16%的计算量，推理速度提升最高35%，在复杂推理任务上准确率提升2.8%。路由决策可解释推理过程，提高透明度和可扩展性。

Conclusion: DS-MoE实现了自适应神经架构的重大突破。其深度专门化模块处理机制能在保证效率的同时，提升推理质量与模型可解释性，对大规模语言模型意义重大。

Abstract: Contemporary transformer architectures apply identical processing depth to
all inputs, creating inefficiencies and limiting reasoning quality. Simple
factual queries are subjected to the same multilayered computation as complex
logical problems, wasting resources while constraining deep inference. To
overcome this, we came up with a concept of Dynamic Reasoning Chains through
Depth Specialised Mixture of Experts (DS-MoE), a modular framework that extends
the Mixture of Experts paradigm from width-based to depth specialised
computation. DS-MoE introduces expert modules optimised for distinct reasoning
depths, shallow pattern recognition, compositional reasoning, logical
inference, memory integration, and meta-cognitive supervision. A learned
routing network dynamically assembles custom reasoning chains, activating only
the necessary experts to match input complexity. The dataset on which we
trained and evaluated DS-MoE is on The Pile, an 800GB corpus covering diverse
domains such as scientific papers, legal texts, programming code, and web
content, enabling systematic assessment across reasoning depths. Experimental
results demonstrate that DS-MoE achieves up to 16 per cent computational
savings and 35 per cent faster inference compared to uniform-depth
transformers, while delivering 2.8 per cent higher accuracy on complex
multi-step reasoning benchmarks. Furthermore, routing decisions yield
interpretable reasoning chains, enhancing transparency and scalability. These
findings establish DS-MoE as a significant advancement in adaptive neural
architectures, demonstrating that depth-specialised modular processing can
simultaneously improve efficiency, reasoning quality, and interpretability in
large-scale language models.

</details>


### [38] [Hierarchical Resolution Transformers: A Wavelet-Inspired Architecture for Multi-Scale Language Understanding](https://arxiv.org/abs/2509.20581)
*Ayan Sar,Sampurna Roy,Kanav Gupta,Anurag Kaushish,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: 本文提出了一种多分辨率处理语言的新型Transformer架构HRT，显著提升了准确率和效率，高度契合人类语言层次特性。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer模型处理文本时仅将其视为平铺的token序列，忽略了人类语言中固有的层次结构，导致计算成本高、组合泛化能力弱且难以实现篇章级的建模。

Method: 提出了Hierarchical Resolution Transformer (HRT)，一种受小波变换启发的新型神经网络架构，能够在多个分辨率（从字符到篇章）上同时处理语言。HRT通过多分辨率注意力机制，实现自底向上的组合与自顶向下的上下文建模，并采用指数级序列降维策略以提升效率。

Result: 在GLUE、SuperGLUE、Long Range Arena和WikiText-103等多个基准测试上，HRT分别比标准Transformer基线高3.8%、4.5%、6.1%；内存使用减少42%，推理延迟降低37%。消融实验显示跨分辨率注意力和尺度专用模块对效率和准确率均有独立贡献。

Conclusion: HRT首次将计算结构与人类语言的层次组织相一致，多尺度小波处理带来了理论上的效率提升和实际上的语言理解改进。

Abstract: Transformer architectures have achieved state-of-the-art performance across
natural language tasks, yet they fundamentally misrepresent the hierarchical
nature of human language by processing text as flat token sequences. This
results in quadratic computational cost, weak computational cost, weak
compositional generalization, and inadequate discourse-level modeling. We
propose Hierarchical Resolution Transformer (HRT), a novel wavelet-inspired
neural architecture that processes language simultaneously across multiple
resolutions, from characters to discourse-level units. HRT constructs a
multi-resolution attention, enabling bottom-up composition and top-down
contextualization. By employing exponential sequence reduction across scales,
HRT achieves O(nlogn) complexity, offering significant efficiency improvements
over standard transformers. We evaluated HRT on a diverse suite of benchmarks,
including GLUE, SuperGLUE, Long Range Arena, and WikiText-103, and results
demonstrated that HRT outperforms standard transformer baselines by an average
of +3.8% on GLUE, +4.5% on SuperGLUE, and +6.1% on Long Range Arena, while
reducing memory usage by 42% and inference latency by 37% compared to BERT and
GPT style models of similar parameter count. Ablation studies confirm the
effectiveness of cross-resolution attention and scale-specialized modules,
showing that each contributes independently to both efficiency and accuracy.
Our findings establish HRT as the first architecture to align computational
structure with the hierarchical organization of human language, demonstrating
that multi-scale, wavelet-inspired processing yields both theoretical
efficiency gains and practical improvements in language understanding.

</details>


### [39] [FS-DFM: Fast and Accurate Long Text Generation with Few-Step Diffusion Language Models](https://arxiv.org/abs/2509.20624)
*Amin Karimi Monsefi,Nikhil Bhendawade,Manuel Rafael Ciosici,Dominic Culver,Yizhe Zhang,Irina Belousova*

Main category: cs.CL

TL;DR: FS-DFM通过将采样步骤参数化和优化训练，大幅减少采样步数，实现相同质量下数十倍速度提升，是高效语言生成的新方案。


<details>
  <summary>Details</summary>
Motivation: 现有自回归模型生成速度慢，而离散扩散语言模型采样步骤多，影响性能。希望设计更高效的采样方法，实现速度和质量兼得。

Method: 提出Few-Step Discrete Flow-Matching（FS-DFM）模型，将采样步数设为显式参数，并在不同采样步数下训练模型以保持一致性，配合新的概率更新规则和教师指导，提升采样质量和速度。

Result: 在生成1024个token时，FS-DFM用8步即可达到与1024步基线模型相同的困惑度，采样速度提升最高达128倍，显著减少延迟和提升吞吐。

Conclusion: FS-DFM方法在仅需8次采样步骤的情况下，能达到与1024步模型相当的困惑度，同时显著提升生成速度和吞吐量。

Abstract: Autoregressive language models (ARMs) deliver strong likelihoods, but are
inherently serial: they generate one token per forward pass, which limits
throughput and inflates latency for long sequences. Diffusion Language Models
(DLMs) parallelize across positions and thus appear promising for language
generation, yet standard discrete diffusion typically needs hundreds to
thousands of model evaluations to reach high quality, trading serial depth for
iterative breadth. We introduce FS-DFM, Few-Step Discrete Flow-Matching. A
discrete flow-matching model designed for speed without sacrificing quality.
The core idea is simple: make the number of sampling steps an explicit
parameter and train the model to be consistent across step budgets, so one big
move lands where many small moves would. We pair this with a reliable update
rule that moves probability in the right direction without overshooting, and
with strong teacher guidance distilled from long-run trajectories. Together,
these choices make few-step sampling stable, accurate, and easy to control. On
language modeling benchmarks, FS-DFM with 8 sampling steps achieves perplexity
parity with a 1,024-step discrete-flow baseline for generating 1,024 tokens
using a similar-size model, delivering up to 128 times faster sampling and
corresponding latency/throughput gains.

</details>


### [40] [Look Before you Leap: Estimating LLM Benchmark Scores from Descriptions](https://arxiv.org/abs/2509.20645)
*Jungsoo Park,Ethan Mendes,Gabriel Stanovsky,Alan Ritter*

Main category: cs.CL

TL;DR: 论文提出用删减任务描述和配置信息预测语言模型实验结果，不需数据实例。作者构建了多领域的PRECOG数据集，实验表明带检索模块的模型能达到较好预测准确度，尤其在强推理模型上更显著。GPT-5在无泄漏测试下也能预测新任务。总体为智能实验设计和评估迈出关键第一步。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的进展受制于评估瓶颈——需要先构建基准、评估模型，再迭代。因此，论文提出能否在不进行实际实验前预测结果的问题，以提高大模型开发效率。

Method: 提出和研究了文本性能预测任务，仅基于经过删减的任务描述和配置信息、无数据实例的情况下，估算模型表现。为系统化研究，作者构建了PRECOG数据集，涵盖多个任务、领域和评价指标；通过引入检索模块的模型进行实验，包括无泄漏的零先验情景测试（如GPT-5与内置搜索）。

Result: 配有检索模块的模型在排除源论文的前提下取得了适度预测性能，部分任务均方误差可低至8.7（Accuracy子集，高置信度）。更强的推理模型展现了多样、迭代式检索行为，而开源模型常跳过检索或多样性有限。GPT-5在新发布数据集的无泄漏测试中仍能获得显著预测准确性。

Conclusion: PRECOG数据集与相应分析为开放式预期评估提供了初步工具，可以支持难度估算与智能实验优先级排序。

Abstract: Progress in large language models is constrained by an evaluation bottleneck:
build a benchmark, evaluate models and settings, then iterate. We therefore ask
a simple question: can we forecast outcomes before running any experiments? We
study text-only performance forecasting: estimating a model's score from a
redacted task description and intended configuration, with no access to dataset
instances. To support systematic study, we curate PRECOG, a corpus of redacted
description-performance pairs spanning diverse tasks, domains, and metrics.
Experiments show the task is challenging but feasible: models equipped with a
retrieval module that excludes source papers achieve moderate prediction
performance with well-calibrated uncertainty, reaching mean absolute error as
low as 8.7 on the Accuracy subset at high-confidence thresholds. Our analysis
indicates that stronger reasoning models engage in diverse, iterative querying,
whereas current open-source models lag and often skip retrieval or gather
evidence with limited diversity. We further test a zero-leakage setting,
forecasting on newly released datasets or experiments before their papers are
indexed, where GPT-5 with built-in web search still attains nontrivial
prediction accuracy. Overall, our corpus and analyses offer an initial step
toward open-ended anticipatory evaluation, supporting difficulty estimation and
smarter experiment prioritization.

</details>


### [41] [Building Tailored Speech Recognizers for Japanese Speaking Assessment](https://arxiv.org/abs/2509.20655)
*Yotaro Kubo,Richard Sproat,Chihiro Taguchi,Llion Jones*

Main category: cs.CL

TL;DR: 本研究面向日语口语评测，提出多任务学习与模型融合方法，有效改善音素识别性能，音节误差率降至7.1%，优于通用模型。


<details>
  <summary>Details</summary>
Motivation: 虽然日语资源丰富，但能够带有重音标记的准确音素转录数据很少，限制了日语口语评测自动识别系统的性能。

Method: 提出两种方法缓解数据稀缺：1）多任务训练，利用辅助损失函数同时预测正字文本标签和音高模式，允许使用仅带文本标注的数据进行训练；2）融合两种估计器（一个基于音素字母串，另一个基于文本Token序列），并利用有限状态传输器框架进行联合估计。

Result: 实验结果显示，多任务学习和融合方法显著提高了日语音素识别器的准确性。相比通用多语种识别器，性能更优，平均音节误差率由12.3%降至7.1%（CSJ核心评测集）。

Conclusion: 针对日语口语评测任务，通过多任务学习和模型融合，有效缓解了音素与重音标记数据稀缺的问题，显著提升了音素识别器的准确率，可用于更精准的口语评估。

Abstract: This paper presents methods for building speech recognizers tailored for
Japanese speaking assessment tasks. Specifically, we build a speech recognizer
that outputs phonemic labels with accent markers. Although Japanese is
resource-rich, there is only a small amount of data for training models to
produce accurate phonemic transcriptions that include accent marks. We propose
two methods to mitigate data sparsity. First, a multitask training scheme
introduces auxiliary loss functions to estimate orthographic text labels and
pitch patterns of the input signal, so that utterances with only orthographic
annotations can be leveraged in training. The second fuses two estimators, one
over phonetic alphabet strings, and the other over text token sequences. To
combine these estimates we develop an algorithm based on the finite-state
transducer framework. Our results indicate that the use of multitask learning
and fusion is effective for building an accurate phonemic recognizer. We show
that this approach is advantageous compared to the use of generic multilingual
recognizers. The relative advantages of the proposed methods were also
compared. Our proposed methods reduced the average of mora-label error rates
from 12.3% to 7.1% over the CSJ core evaluation sets.

</details>


### [42] [Enhancing Molecular Property Prediction with Knowledge from Large Language Models](https://arxiv.org/abs/2509.20664)
*Peng Zhou,Lai Hou Tim,Zhixiang Cheng,Kun Xie,Chaoyi Li,Wei Liu,Xiangxiang Zeng*

Main category: cs.CL

TL;DR: 本工作首次提出将大语言模型知识与分子结构特征融合进行分子性质预测，有效提升了预测效果，尤其在领域知识不足情况下展现突出优势。


<details>
  <summary>Details</summary>
Motivation: 药物发现过程中分子性质预测至关重要，近年来图神经网络（GNN）等深度学习技术虽然提升了预测能力，但人类领域知识依然不可替代。目前融合大语言模型（LLM）知识的方法存在知识漏洞及虚构问题，尤其针对较少研究的分子属性。作者希望通过创新框架弥补此不足。

Method: 提出首个将LLM知识与预训练分子结构特征融合用于分子性质预测的框架。方法通过提示三种主流LLM（GPT-4o、GPT-4.1、DeepSeek-R1）生成领域知识及可执行分子向量化代码，获得知识特征后，与分子结构特征进行融合，提升分子性质预测能力。

Result: 该方法在多项实验中优于现有模型，证明LLM衍生知识与结构信息融合为分子性质预测带来更稳健且有效的解决方案。

Conclusion: 融合LLM知识与分子结构特征能显著提升分子性质预测性能，对药物研发领域具有重要应用价值。

Abstract: Predicting molecular properties is a critical component of drug discovery.
Recent advances in deep learning, particularly Graph Neural Networks (GNNs),
have enabled end-to-end learning from molecular structures, reducing reliance
on manual feature engineering. However, while GNNs and self-supervised learning
approaches have advanced molecular property prediction (MPP), the integration
of human prior knowledge remains indispensable, as evidenced by recent methods
that leverage large language models (LLMs) for knowledge extraction. Despite
their strengths, LLMs are constrained by knowledge gaps and hallucinations,
particularly for less-studied molecular properties. In this work, we propose a
novel framework that, for the first time, integrates knowledge extracted from
LLMs with structural features derived from pre-trained molecular models to
enhance MPP. Our approach prompts LLMs to generate both domain-relevant
knowledge and executable code for molecular vectorization, producing
knowledge-based features that are subsequently fused with structural
representations. We employ three state-of-the-art LLMs, GPT-4o, GPT-4.1, and
DeepSeek-R1, for knowledge extraction. Extensive experiments demonstrate that
our integrated method outperforms existing approaches, confirming that the
combination of LLM-derived knowledge and structural information provides a
robust and effective solution for MPP.

</details>


### [43] [RedHerring Attack: Testing the Reliability of Attack Detection](https://arxiv.org/abs/2509.20691)
*Jonathan Rusert*

Main category: cs.CL

TL;DR: 本文提出了一种新型攻击RedHerring专门针对文本攻击检测模型，实验发现能大幅降低检测准确率且不影响分类器表现，并提出了简单实用的防御方法，对检测模型可靠性问题给出了重要思考。


<details>
  <summary>Details</summary>
Motivation: 尽管文本攻击检测模型能有效识别被篡改的文本，但其可靠性尚未被彻底探究，因此作者提出新的攻击设定来挑战这些检测模型。

Method: 提出了一种新的攻击方式RedHerring，通过修改文本让检测模型预测有攻击（即“错误”报警），而分类器预测结果依然正确，在四个数据集和三个检测器、四个分类器上进行测试。

Result: RedHerring可使检测器准确率骤降20-71个百分点，而分类器准确率保持甚至提升。作者还提出了无需重新训练的简单置信度检测防御方法，显著提升检测准确率。

Conclusion: RedHerring攻击揭示了检测模型的脆弱性，也提供了对抗和提升攻击检测系统可靠性的启发。

Abstract: In response to adversarial text attacks, attack detection models have been
proposed and shown to successfully identify text modified by adversaries.
Attack detection models can be leveraged to provide an additional check for NLP
models and give signals for human input. However, the reliability of these
models has not yet been thoroughly explored. Thus, we propose and test a novel
attack setting and attack, RedHerring. RedHerring aims to make attack detection
models unreliable by modifying a text to cause the detection model to predict
an attack, while keeping the classifier correct. This creates a tension between
the classifier and detector. If a human sees that the detector is giving an
``incorrect'' prediction, but the classifier a correct one, then the human will
see the detector as unreliable. We test this novel threat model on 4 datasets
against 3 detectors defending 4 classifiers. We find that RedHerring is able to
drop detection accuracy between 20 - 71 points, while maintaining (or
improving) classifier accuracy. As an initial defense, we propose a simple
confidence check which requires no retraining of the classifier or detector and
increases detection accuracy greatly. This novel threat model offers new
insights into how adversaries may target detection models.

</details>


### [44] [Overcoming Black-box Attack Inefficiency with Hybrid and Dynamic Select Algorithms](https://arxiv.org/abs/2509.20699)
*Abhinay Shankar Belde,Rohit Ramkumar,Jonathan Rusert*

Main category: cs.CL

TL;DR: 本文提出两种新的对抗文本攻击查询选择策略，大幅减少了计算消耗且保持攻击效果，适合资源有限场景。


<details>
  <summary>Details</summary>
Motivation: 现有的黑盒对抗文本攻击方法需要大量查询，而变换器模型结构日益复杂，导致计算成本高，给资源有限的研究人员带来困难。

Method: 提出了两种新的攻击选择策略：Hybrid Select（结合BinarySelect和GreedySelect，根据文本大小动态选择算法）和Dynamic Select（通过学习文本长度来决定采用哪种选择方法）。

Result: 在4个数据集和6个目标模型上，提出的最佳方法（句子级Hybrid Select）平均减少25.82%的查询次数，同时保持了攻击有效性。

Conclusion: 新方法有效降低了黑盒攻击的查询成本，为资源有限的NLP研究人员带来了更实用、高效的攻击测试手段。

Abstract: Adversarial text attack research plays a crucial role in evaluating the
robustness of NLP models. However, the increasing complexity of
transformer-based architectures has dramatically raised the computational cost
of attack testing, especially for researchers with limited resources (e.g.,
GPUs). Existing popular black-box attack methods often require a large number
of queries, which can make them inefficient and impractical for researchers. To
address these challenges, we propose two new attack selection strategies called
Hybrid and Dynamic Select, which better combine the strengths of previous
selection algorithms. Hybrid Select merges generalized BinarySelect techniques
with GreedySelect by introducing a size threshold to decide which selection
algorithm to use. Dynamic Select provides an alternative approach of combining
the generalized Binary and GreedySelect by learning which lengths of texts each
selection method should be applied to. This greatly reduces the number of
queries needed while maintaining attack effectiveness (a limitation of
BinarySelect). Across 4 datasets and 6 target models, our best
method(sentence-level Hybrid Select) is able to reduce the number of required
queries per attack up 25.82\% on average against both encoder models and LLMs,
without losing the effectiveness of the attack.

</details>


### [45] [MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model](https://arxiv.org/abs/2509.20706)
*Hsiao-Ying Huang,Yi-Cheng Lin,Hung-yi Lee*

Main category: cs.CL

TL;DR: 本文针对实际场景下无源域数据、仅API访问LALM的情感识别问题，提出融合互信息的不确定性加权方法，实现学生模型在新域上超越LALM和现有方法，有效促进真实世界语音情感系统的落地。


<details>
  <summary>Details</summary>
Motivation: 现有的大型音频-语言模型（LALMs）在语音任务上具备强大的零样本能力，但在实际部署时，由于域不匹配及原始数据不可获得等限制，往往表现不佳。尤其当只能通过API访问LALM时，如何在目标域（仅有未标记音频）让学生模型适应并超越LALM，成为亟待解决的问题。

Method: 提出了MI-Fuse，一种去噪标签融合框架。该方法将API访问的LALM与在源域上训练的SER（语音情感识别）分类器结合为辅助教师。通过对教师模型进行多次随机预测、利用互信息不确定性加权其均值分布，以及用指数移动平均教师稳定训练过程。

Result: 在3个公开情感数据集与6种跨域迁移实验中，学生模型持续获得提升，不仅超过了LALM，还比当前最强基线高3.9%。

Conclusion: MI-Fuse能够在无源域数据共享条件下，显著提升语音情感识别系统的跨域适应性和性能。

Abstract: Large audio-language models (LALMs) show strong zero-shot ability on speech
tasks, suggesting promise for speech emotion recognition (SER). However, SER in
real-world deployments often fails under domain mismatch, where source data are
unavailable and powerful LALMs are accessible only through an API. We ask:
given only unlabeled target-domain audio and an API-only LALM, can a student
model be adapted to outperform the LALM in the target domain? To this end, we
propose MI-Fuse, a denoised label fusion framework that supplements the LALM
with a source-domain trained SER classifier as an auxiliary teacher. The
framework draws multiple stochastic predictions from both teachers, weights
their mean distributions by mutual-information-based uncertainty, and
stabilizes training with an exponential moving average teacher. Experiments
across three public emotion datasets and six cross-domain transfers show
consistent gains, with the student surpassing the LALM and outperforming the
strongest baseline by 3.9%. This approach strengthens emotion-aware speech
systems without sharing source data, enabling realistic adaptation.

</details>


### [46] [Probability Distribution Collapse: A Critical Bottleneck to Compact Unsupervised Neural Grammar Induction](https://arxiv.org/abs/2509.20734)
*Jinwook Park,Kangil Kim*

Main category: cs.CL

TL;DR: 该文分析现有无监督神经文法归纳模型中概率分布塌缩问题带来的表达瓶颈，提出了缓解这一问题的新型神经参数化方法，不仅提升了解析性能，还能用更小的文法模型适应多种语言。


<details>
  <summary>Details</summary>
Motivation: 无监督神经文法归纳旨在从语言数据中学习可解释的层次结构，但现有方法存在表达能力瓶颈，导致文法过大且表现欠佳。

Method: 分析概率分布塌缩在神经参数化中的出现机制，并提出针对性的解决方案——塌缩缓解神经参数化。

Result: 新方法显著提升解析性能，并在多种语言上实现了更紧凑的文法模型。

Conclusion: 本文通过分析概率分布塌缩现象并提出缓解方法，显著提高了无监督神经文法归纳的性能和文法紧凑性。

Abstract: Unsupervised neural grammar induction aims to learn interpretable
hierarchical structures from language data. However, existing models face an
expressiveness bottleneck, often resulting in unnecessarily large yet
underperforming grammars. We identify a core issue, $\textit{probability
distribution collapse}$, as the underlying cause of this limitation. We analyze
when and how the collapse emerges across key components of neural
parameterization and introduce a targeted solution, $\textit{collapse-relaxing
neural parameterization}$, to mitigate it. Our approach substantially improves
parsing performance while enabling the use of significantly more compact
grammars across a wide range of languages, as demonstrated through extensive
empirical analysis.

</details>


### [47] [Confidence-guided Refinement Reasoning for Zero-shot Question Answering](https://arxiv.org/abs/2509.20750)
*Youwon Jang,Woo Suk Choi,Minjoon Jung,Minsu Lee,Byoung-Tak Zhang*

Main category: cs.CL

TL;DR: 本文提出训练无关的C2R框架，通过置信度引导的子问题方法提升文本、图像、视频领域QA模型的性能和可靠性，可广泛集成到多种现有模型中，并详细探讨了子问题数量和质量对结果的影响。


<details>
  <summary>Details</summary>
Motivation: 当前的问答（QA）模型在不同领域（文本、图像、视频）中的鲁棒性和可靠性不足，尤其在推理复杂问题时容易出现信心不足或答案不可靠。作者希望通过更好地利用模型自身的置信度信息，提升QA模型的表现和稳健性。

Method: 提出Confidence-guided Refinement Reasoning (C2R)训练无关框架。C2R在QA过程中自动生成并优化子问题及其答案（sub-QAs），首先挑选多样化的推理路径子问题，然后基于模型给出的置信分对多个候选答案进行比较，最终选择最可靠的答案。该方法完全依赖模型自身输出的置信度，无需额外训练或修改原模型结构。

Result: C2R可以无缝集成进已有的多种QA模型，并在不同领域与数据集上持续带来性能提升。作者还分析了子问题数量与质量对模型推理能力的影响，突显了充分利用子问题在提升推理稳健性和可靠性方面的作用。

Conclusion: C2R是一种通用、训练无关且可与各种现有QA模型结合使用的推理增强框架，通过置信度引导的子问题精细化有效提升了QA任务的性能和可靠性，并为未来关于子问题框架的深入研究提供了有价值的见解。

Abstract: We propose Confidence-guided Refinement Reasoning (C2R), a novel
training-free framework applicable to question-answering (QA) tasks across
text, image, and video domains. C2R strategically constructs and refines
sub-questions and their answers (sub-QAs), deriving a better confidence score
for the target answer. C2R first curates a subset of sub-QAs to explore diverse
reasoning paths, then compares the confidence scores of the resulting answer
candidates to select the most reliable final answer. Since C2R relies solely on
confidence scores derived from the model itself, it can be seamlessly
integrated with various existing QA models, demonstrating consistent
performance improvements across diverse models and benchmarks. Furthermore, we
provide essential yet underexplored insights into how leveraging sub-QAs
affects model behavior, specifically analyzing the impact of both the quantity
and quality of sub-QAs on achieving robust and reliable reasoning.

</details>


### [48] [SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs](https://arxiv.org/abs/2509.20758)
*Jiacheng Lin,Zhongruo Wang,Kun Qian,Tian Wang,Arvind Srinivasan,Hansi Zeng,Ruochen Jiao,Xie Zhou,Jiri Gesi,Dakuo Wang,Yufan Guo,Kai Zhong,Weiqi Zhang,Sujay Sanghavi,Changyou Chen,Hyokun Yun,Lihong Li*

Main category: cs.CL

TL;DR: 领域微调会影响大模型通用能力，但通过降低学习率可缓解，TALR方法在兼顾领域与通用能力时效果最佳。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在适应特定领域任务时，通常通过基于领域数据集进行有监督微调（SFT），但业界普遍认为这种方式会削弱模型的通用能力。该论文重新探讨了适应与通用性之间的权衡问题。

Method: 首先通过实验证明调整较小的学习率能显著缓解通用性能退化，同时保持领域性能。然后从理论角度分析这种现象，并提出了一种新的方法：Token-Adaptive Loss Reweighting（TALR）。论文进一步系统对比了L2正则化、LoRA、模型平均、FLOW以及TALR等多种策略缓解通用能力损失的效果。

Result: 实验证明，虽然没有方法能完全消除适应与通用性的权衡，但TALR在兼顾领域增益与通用能力方面始终优于其他对比方法。

Conclusion: （1）采用较小的学习率能够实现较优的领域与通用性能权衡；（2）若需要更强的平衡 효과，TALR是一种有效策略。

Abstract: Supervised Fine-Tuning (SFT) on domain-specific datasets is a common approach
to adapt Large Language Models (LLMs) to specialized tasks but is often
believed to degrade their general capabilities. In this work, we revisit this
trade-off and present both empirical and theoretical insights. First, we show
that SFT does not always hurt: using a smaller learning rate can substantially
mitigate general performance degradation while preserving comparable
target-domain performance. We then provide a theoretical analysis that explains
these phenomena and further motivates a new method, Token-Adaptive Loss
Reweighting (TALR). Building on this, and recognizing that smaller learning
rates alone do not fully eliminate general-performance degradation in all
cases, we evaluate a range of strategies for reducing general capability loss,
including L2 regularization, LoRA, model averaging, FLOW, and our proposed
TALR. Experimental results demonstrate that while no method completely
eliminates the trade-off, TALR consistently outperforms these baselines in
balancing domain-specific gains and general capabilities. Finally, we distill
our findings into practical guidelines for adapting LLMs to new domains: (i)
using a small learning rate to achieve a favorable trade-off, and (ii) when a
stronger balance is further desired, adopt TALR as an effective strategy.

</details>


### [49] [Towards Atoms of Large Language Models](https://arxiv.org/abs/2509.20784)
*Chenhui Hu,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: 本文提出原子理论，从理论与实证角度证明“原子”比神经元或特征更适合作为LLM内部表示单元，提供了稳定的稀疏表征，显著推进模型机制可解释性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）内部表示的基本单元尚未明确定义，这限制了对其机制的进一步理解。现有的神经元或特征作为基本单元各有不足，神经元存在多义性问题，特征则重构不可靠且不稳定。

Method: 作者提出Atoms Theory，将“原子”定义为LLMs内部表示的基本单元。引入原子内积（AIP）纠正表示偏移，形式化地定义原子，并证明原子满足受限等距性质（RIP），确保在原子集合上的稳定稀疏表示，并与压缩感知理论关联。在更强条件下，证明了稀疏表示的唯一性和精确的l1可恢复性，并提供单层稀疏自编码器（SAEs）具有阈值激活函数可有效识别原子的理论保证。实验使用SAEs在Gemma2-2B，Gemma2-9B和Llama3.1-8B模型上进行验证。

Result: 实验表明：在多层上平均实现了99.9%的稀疏重构率，并且超过99.8%的原子满足唯一性条件，而神经元仅为0.5%、特征为68.2%。显示原子较好地表征了LLMs的内在表示。此外，扩展实验揭示SAEs的规模与恢复能力密切相关。

Conclusion: 本工作系统性地提出并验证了LLMs的原子理论，建立了理解内部表示的理论框架，为机制可解释性奠定了基础。

Abstract: The fundamental units of internal representations in large language models
(LLMs) remain undefined, limiting further understanding of their mechanisms.
Neurons or features are often regarded as such units, yet neurons suffer from
polysemy, while features face concerns of unreliable reconstruction and
instability. To address this issue, we propose the Atoms Theory, which defines
such units as atoms. We introduce the atomic inner product (AIP) to correct
representation shifting, formally define atoms, and prove the conditions that
atoms satisfy the Restricted Isometry Property (RIP), ensuring stable sparse
representations over atom set and linking to compressed sensing. Under stronger
conditions, we further establish the uniqueness and exact $\ell_1$
recoverability of the sparse representations, and provide guarantees that
single-layer sparse autoencoders (SAEs) with threshold activations can reliably
identify the atoms. To validate the Atoms Theory, we train threshold-activated
SAEs on Gemma2-2B, Gemma2-9B, and Llama3.1-8B, achieving 99.9% sparse
reconstruction across layers on average, and more than 99.8% of atoms satisfy
the uniqueness condition, compared to 0.5% for neurons and 68.2% for features,
showing that atoms more faithfully capture intrinsic representations of LLMs.
Scaling experiments further reveal the link between SAEs size and recovery
capacity. Overall, this work systematically introduces and validates Atoms
Theory of LLMs, providing a theoretical framework for understanding internal
representations and a foundation for mechanistic interpretability. Code
available at https://github.com/ChenhuiHu/towards_atoms.

</details>


### [50] [Few-Shot and Training-Free Review Generation via Conversational Prompting](https://arxiv.org/abs/2509.20805)
*Genki Kusano*

Main category: cs.CL

TL;DR: 文章提出对话式提示法，在用户评论稀缺且无法训练模型时，能显著提升生成评论的个性化程度。SCP和CCP均优于传统方法，CCP在具备高质量负例时效果更好，对实际个性化评论生成有重要指导意义。


<details>
  <summary>Details</summary>
Motivation: 个性化评论生成有助于企业了解用户偏好，但现有方法往往需要丰富的用户历史或额外模型训练，实际应用中常常面临用户评论较少且不可进行微调的情况。本文旨在解决评论数据稀缺和不可训练时的个性化评论生成问题。

Method: 提出了对话式提示（Conversational Prompting）方法，将用户评论转化为多轮对话，包括SCP（仅利用用户评论）和CCP（通过插入其他用户/LLM评论作为错误回复，要求模型纠正并鼓励仿写用户风格）。

Result: 在8个产品领域和5个LLM上实验，常规非对话提示生成的评论更像随机用户，而SCP和CCP生成的评论更接近目标用户，即使每个用户仅有两条评论。CCP在能获得高质量负例时有更大性能提升，SCP则在无法获取负例时依然表现良好。

Conclusion: 对话式提示在少样本和无需训练场景下能有效提升评论个性化生成质量，是实用的解决方案。

Abstract: Personalized review generation helps businesses understand user preferences,
yet most existing approaches assume extensive review histories of the target
user or require additional model training. Real-world applications often face
few-shot and training-free situations, where only a few user reviews are
available and fine-tuning is infeasible. It is well known that large language
models (LLMs) can address such low-resource settings, but their effectiveness
depends on prompt engineering. In this paper, we propose Conversational
Prompting, a lightweight method that reformulates user reviews as multi-turn
conversations. Its simple variant, Simple Conversational Prompting (SCP),
relies solely on the user's own reviews, while the contrastive variant,
Contrastive Conversational Prompting (CCP), inserts reviews from other users or
LLMs as incorrect replies and then asks the model to correct them, encouraging
the model to produce text in the user's style. Experiments on eight product
domains and five LLMs showed that the conventional non-conversational prompt
often produced reviews similar to those written by random users, based on
text-based metrics such as ROUGE-L and BERTScore, and application-oriented
tasks like user identity matching and sentiment analysis. In contrast, both SCP
and CCP produced reviews much closer to those of the target user, even when
each user had only two reviews. CCP brings further improvements when
high-quality negative examples are available, whereas SCP remains competitive
when such data cannot be collected. These results suggest that conversational
prompting offers a practical solution for review generation under few-shot and
training-free constraints.

</details>


### [51] [Enrich-on-Graph: Query-Graph Alignment for Complex Reasoning with LLM Enriching](https://arxiv.org/abs/2509.20810)
*Songze Li,Zhiqiang Liu,Zhengke Gui,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: 本文针对知识图谱问答（KGQA）中结构化知识与非结构化查询不匹配导致大语言模型推理效果受限的问题，提出了利用LLM丰富知识图谱的EoG框架，实现更高效、更精确的推理及业界最优表现。


<details>
  <summary>Details</summary>
Motivation: 为了解决知识图谱与非结构化查询之间的语义鸿沟以及现有方法在知识密集型任务上的不一致问题，并提升大语言模型在KGQA场景下的准确性和鲁棒性。

Method: 提出了Enrich-on-Graph (EoG) 框架，通过利用大语言模型的先验知识来丰富知识图谱，并设计三种图质量评价指标用于分析查询与图的匹配度，理论上验证了优化目标。

Result: 在两个KGQA基准数据集上广泛实验，EoG方法生成的知识图谱质量高，且性能达到SOTA（当前最优）。

Conclusion: 实验结果表明，Enrich-on-Graph框架能够高效地生成高质量知识图谱，并在KGQA任务上取得了当前最优性能。

Abstract: Large Language Models (LLMs) exhibit strong reasoning capabilities in complex
tasks. However, they still struggle with hallucinations and factual errors in
knowledge-intensive scenarios like knowledge graph question answering (KGQA).
We attribute this to the semantic gap between structured knowledge graphs (KGs)
and unstructured queries, caused by inherent differences in their focuses and
structures. Existing methods usually employ resource-intensive, non-scalable
workflows reasoning on vanilla KGs, but overlook this gap. To address this
challenge, we propose a flexible framework, Enrich-on-Graph (EoG), which
leverages LLMs' prior knowledge to enrich KGs, bridge the semantic gap between
graphs and queries. EoG enables efficient evidence extraction from KGs for
precise and robust reasoning, while ensuring low computational costs,
scalability, and adaptability across different methods. Furthermore, we propose
three graph quality evaluation metrics to analyze query-graph alignment in KGQA
task, supported by theoretical validation of our optimization objectives.
Extensive experiments on two KGQA benchmark datasets indicate that EoG can
effectively generate high-quality KGs and achieve the state-of-the-art
performance. Our code and data are available at
https://github.com/zjukg/Enrich-on-Graph.

</details>


### [52] [Leveraging What's Overfixed: Post-Correction via LLM Grammatical Error Overcorrection](https://arxiv.org/abs/2509.20811)
*Taehee Park,Heejin Do,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: PoCO结合LLM的高召回与小模型的高精度，先让LLM“修正过度”，后用小模型二次修正，有效提升语法纠错的整体表现。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型（sLM）虽然在监督微调后表现稳定，但通常“修正不足”，即高精度但低召回率。大型语言模型（LLM）则倾向于“修正过度”，即高召回但低精度。两者在语法纠错任务上各有优缺点，因此需要新方法来互补。

Method: PoCO方法：先用LLM进行“过度修正”，最大化召回率，然后用微调的小型模型对LLM输出进行有针对性的二次修正，提高精度。此方法利用LLM的生成能力和小模型的可靠性进行组合。

Result: 在广泛的实验中，PoCO方法在提高召回率的同时保持了有竞争力的精度，从而提升了语法纠错的整体质量。

Conclusion: PoCO有效平衡了召回率和精度，实现了更加优质的语法错误纠正效果。

Abstract: Robust supervised fine-tuned small Language Models (sLMs) often show high
reliability but tend to undercorrect. They achieve high precision at the cost
of low recall. Conversely, Large Language Models (LLMs) often show the opposite
tendency, making excessive overcorrection, leading to low precision. To
effectively harness the strengths of LLMs to address the recall challenges in
sLMs, we propose Post-Correction via Overcorrection (PoCO), a novel approach
that strategically balances recall and precision. PoCO first intentionally
triggers overcorrection via LLM to maximize recall by allowing comprehensive
revisions, then applies a targeted post-correction step via fine-tuning smaller
models to identify and refine erroneous outputs. We aim to harmonize both
aspects by leveraging the generative power of LLMs while preserving the
reliability of smaller supervised models. Our extensive experiments demonstrate
that PoCO effectively balances GEC performance by increasing recall with
competitive precision, ultimately improving the overall quality of grammatical
error correction.

</details>


### [53] [Distilling Many-Shot In-Context Learning into a Cheat Sheet](https://arxiv.org/abs/2509.20820)
*Ukyo Honda,Soichiro Murakami,Peinan Zhang*

Main category: cs.CL

TL;DR: 论文提出用精炼文本总结取代多例输入，能在不降低任务性能的前提下显著减少计算需求，是many-shot ICL的高效替代方案。


<details>
  <summary>Details</summary>
Motivation: many-shot ICL能提升LLM表现，但需要处理更长的输入，导致高计算消耗；为减少token数量、提升效率，同时保持性能，提出更简洁的信息表达方式。

Method: 将多例（many-shot）ICL中的关键信息通过总结转化为一句精简文本（cheat sheet），在推理时直接作为上下文输入，不需引用原始大量示例。

Result: 在多个复杂推理任务上，cheat-sheet ICL的性能达到或超过传统many-shot ICL，同时大幅减少输入长度，并与检索式ICL表现持平，且不需检索过程。

Conclusion: cheat-sheet ICL是一种能够有效减少输入tokens数量，同时还保持甚至提升推理任务性能的方法，为LLM下游任务提供了实用的新选择。

Abstract: Recent advances in large language models (LLMs) enable effective in-context
learning (ICL) with many-shot examples, but at the cost of high computational
demand due to longer input tokens. To address this, we propose cheat-sheet ICL,
which distills the information from many-shot ICL into a concise textual
summary (cheat sheet) used as the context at inference time. Experiments on
challenging reasoning tasks show that cheat-sheet ICL achieves comparable or
better performance than many-shot ICL with far fewer tokens, and matches
retrieval-based ICL without requiring test-time retrieval. These findings
demonstrate that cheat-sheet ICL is a practical alternative for leveraging LLMs
in downstream tasks.

</details>


### [54] [Zero-Shot Privacy-Aware Text Rewriting via Iterative Tree Search](https://arxiv.org/abs/2509.20838)
*Shuo Huang,Xingliang Yuan,Gholamreza Haffari,Lizhen Qu*

Main category: cs.CL

TL;DR: 本文提出零样本、树搜索驱动的句子重写法，能自动识别并处理隐私敏感信息，实验显示其兼顾隐私保护与文本自然性，效果优于当前技术。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在云服务中的广泛应用，用户输入可能会暴露敏感信息，因此如何保护隐私成为亟需解决的问题。现有的文本匿名化和去标识化技术难以兼顾隐私保护与文本的自然性、实用性。

Method: 提出了一种基于零样本、树搜索的迭代句子重写算法。该方法通过结构化搜索和奖励模型，引导对隐私敏感片段进行逐步重写，以系统性地混淆或删除私密信息，同时保持文本连贯性、相关性和自然性。

Result: 在隐私数据集上的实验结果表明，所提方法明显优于现有基线，在隐私保护和文本实用性之间取得了更优的平衡。

Conclusion: 该零样本树搜索句子重写算法可有效保护用户隐私，并保持文本高质量，优于传统的规则化处理方法。

Abstract: The increasing adoption of large language models (LLMs) in cloud-based
services has raised significant privacy concerns, as user inputs may
inadvertently expose sensitive information. Existing text anonymization and
de-identification techniques, such as rule-based redaction and scrubbing, often
struggle to balance privacy preservation with text naturalness and utility. In
this work, we propose a zero-shot, tree-search-based iterative sentence
rewriting algorithm that systematically obfuscates or deletes private
information while preserving coherence, relevance, and naturalness. Our method
incrementally rewrites privacy-sensitive segments through a structured search
guided by a reward model, enabling dynamic exploration of the rewriting space.
Experiments on privacy-sensitive datasets show that our approach significantly
outperforms existing baselines, achieving a superior balance between privacy
protection and utility preservation.

</details>


### [55] [Concise and Sufficient Sub-Sentence Citations for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.20859)
*Guo Chen,Qiuyuan Li,Qiuxian Li,Hongliang Dai,Xiang Chen,Piji Li*

Main category: cs.CL

TL;DR: 本文提出子句级引文生成方法并建立相关数据集，利用大模型+信用过滤自动生成高质量训练样本，有效提升RAG系统引文可读性和确认效率。


<details>
  <summary>Details</summary>
Motivation: 在检索增强生成（RAG）问答系统中，当前引文生成方法多在句子或段落层面，引用内容常包含大量无关信息，且可能遗漏验证输出所需的重要信息，导致用户确认输出正确性需查阅更多上下文，增加负担。作者旨在解决引文粒度过粗、信息不充分的问题。

Method: 作者制定了子句级引文标注指南，并构建了相应的数据集。提出利用LLM自动生成微调数据，并用信用模型过滤低质量样本，形成子句级高质量引文生成归因框架。

Result: 实验证明提出的方法能生成更高质量、更易读的精炼引文，相比现有方法减少用户验证输出所需的查阅工作量。

Conclusion: 通过更细粒度（子句级）引文生成方法，提高了检索增强生成系统输出内容的可验证性和用户体验。

Abstract: In retrieval-augmented generation (RAG) question answering systems,
generating citations for large language model (LLM) outputs enhances
verifiability and helps users identify potential hallucinations. However, we
observe two problems in the citations produced by existing attribution methods.
First, the citations are typically provided at the sentence or even paragraph
level. Long sentences or paragraphs may include a substantial amount of
irrelevant content. Second, sentence-level citations may omit information that
is essential for verifying the output, forcing users to read the surrounding
context. In this paper, we propose generating sub-sentence citations that are
both concise and sufficient, thereby reducing the effort required by users to
confirm the correctness of the generated output. To this end, we first develop
annotation guidelines for such citations and construct a corresponding dataset.
Then, we propose an attribution framework for generating citations that adhere
to our standards. This framework leverages LLMs to automatically generate
fine-tuning data for our task and employs a credit model to filter out
low-quality examples. Our experiments on the constructed dataset demonstrate
that the propose approach can generate high-quality and more readable
citations.

</details>


### [56] [WeFT: Weighted Entropy-driven Fine-Tuning for dLLMs](https://arxiv.org/abs/2509.20863)
*Guowei Xu,Wenxin Xu,Jiawang Zhao,Kaisheng Ma*

Main category: cs.CL

TL;DR: 提出加权SFT（WeFT）方法，通过token熵加权，有效提升扩散语言模型在推理任务上的表现，优于标准SFT。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在语言建模中表现突出，但由于扩散模型每一步不能提供精确的概率估计，导致其难以直接使用传统的有监督微调（SFT）方法。此外，扩散机制虽然可以对整个序列推理，但也带来了生成过程的不确定性和不一致性，急需更强的关键token控制能力以提升生成质量。

Method: 本文提出了一种基于扩散语言模型的加权有监督微调方法（WeFT），通过根据token的熵为其分配不同权重，从而使模型在训练时更关注于引导生成方向的关键token。该权重分配方法基于扩散理论推导而来。

Result: 在open-r1的s1K、s1K-1.1和3k样本上训练，WeFT方法在四个常用推理基准（Sudoku、Countdown、GSM8K、MATH-500）上相较于标准SFT分别获得了39%、64%和83%的相对提升。

Conclusion: WeFT能够有效提升扩散语言模型的训练和推理能力，显著超越了常规的SFT方法，证明了加权微调和token熵调控在扩散模型中的价值。

Abstract: Diffusion models have recently shown strong potential in language modeling,
offering faster generation compared to traditional autoregressive approaches.
However, applying supervised fine-tuning (SFT) to diffusion models remains
challenging, as they lack precise probability estimates at each denoising step.
While the diffusion mechanism enables the model to reason over entire
sequences, it also makes the generation process less predictable and often
inconsistent. This highlights the importance of controlling key tokens that
guide the direction of generation. To address this issue, we propose WeFT, a
weighted SFT method for diffusion language models, where tokens are assigned
different weights based on their entropy. Derived from diffusion theory, WeFT
delivers substantial gains: training on s1K, s1K-1.1, and 3k samples from
open-r1, it achieves relative improvements of 39%, 64%, and 83% over standard
SFT on four widely used reasoning benchmarks (Sudoku, Countdown, GSM8K, and
MATH-500). The code and models will be made publicly available.

</details>


### [57] [Single Answer is Not Enough: On Generating Ranked Lists with Medical Reasoning Models](https://arxiv.org/abs/2509.20866)
*Pittawat Taveekitworachai,Natpatchara Pongjirapat,Krittaphas Chaisutyakorn,Piyalitt Ittichaiwong,Tossaporn Saengja,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 该论文系统研究了医学推理模型生成排序答案列表的新方法，提出了prompting和微调（SFT及RFT）方案，验证了RFT在多答案格式下的稳健性，提升了模型对开放性医疗问题的回答能力。


<details>
  <summary>Details</summary>
Motivation: 临床决策很少仅依赖单一答案，通常会考虑多个选项以降低狭隘观点带来的风险。目前医学推理模型（MRMs）通常只输出一个答案，难以满足实际需求。作者希望探索能输出排序答案列表的新方法，提升模型的实用性。

Method: 提出将答案格式转变为排序列表，并研究了两种实现方式：prompting（提示引导）和fine-tuning（微调），其中微调又包括有监督微调（SFT）和强化微调（RFT）。在RFT中，设计了适合排序列表的奖励函数，并进行了消融实验以评估各方法效果。

Result: 部分SFT模型能泛化到特定答案格式，但RFT训练的模型在多种答案格式下表现更加稳健。改进后的MedQA实验表明，模型即使未选择标准答案，也能识别出有效答案。提出的方法使MRMs具备生成多答案排序列表的能力。

Conclusion: 首次系统性探讨医学推理模型按排序列表格式输出答案的方法，验证了RFT在多答案格式下的优势，为医学领域提供更加多样和实用的答案输出形式。

Abstract: This paper presents a systematic study on enabling medical reasoning models
(MRMs) to generate ranked lists of answers for open-ended questions. Clinical
decision-making rarely relies on a single answer but instead considers multiple
options, reducing the risks of narrow perspectives. Yet current MRMs are
typically trained to produce only one answer, even in open-ended settings. We
propose an alternative format: ranked lists and investigate two approaches:
prompting and fine-tuning. While prompting is a cost-effective way to steer an
MRM's response, not all MRMs generalize well across different answer formats:
choice, short text, and list answers. Based on our prompting findings, we train
and evaluate MRMs using supervised fine-tuning (SFT) and reinforcement
fine-tuning (RFT). SFT teaches a model to imitate annotated responses, and RFT
incentivizes exploration through the responses that maximize a reward. We
propose new reward functions targeted at ranked-list answer formats, and
conduct ablation studies for RFT. Our results show that while some SFT models
generalize to certain answer formats, models trained with RFT are more robust
across multiple formats. We also present a case study on a modified MedQA with
multiple valid answers, finding that although MRMs might fail to select the
benchmark's preferred ground truth, they can recognize valid answers. To the
best of our knowledge, this is the first systematic investigation of approaches
for enabling MRMs to generate answers as ranked lists. We hope this work
provides a first step toward developing alternative answer formats that are
beneficial beyond single answers in medical domains.

</details>


### [58] [Learning to Summarize by Learning to Quiz: Adversarial Agentic Collaboration for Long Document Summarization](https://arxiv.org/abs/2509.20900)
*Weixuan Wang,Minghao Wu,Barry Haddow,Alexandra Birch*

Main category: cs.CL

TL;DR: 本文提出了一种基于对抗性多智能体协作的新型长文档摘要方法SummQ，通过摘要与问答双重质量控制，实验全面优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 当前长文档摘要任务对大型语言模型（LLM）依然是重大挑战。现有方法常面临信息丢失、事实不一致及连贯性差等问题，尤其是在处理超长文本时。亟需创新方法以提升摘要质量。

Method: 提出了SummQ，这是一种新颖的对抗性多智能体框架。通过在摘要和问答两个互补领域中，使用专门的生成器和审查者智能体协作。一方面，摘要生成器与审查者共同生成和评估摘要；另一方面，问答生成器与审查者设计理解题，对摘要进行持续质量检查。考生智能体则验证摘要是否涵盖解答问题所需的信息，整个过程迭代优化。

Result: SummQ在三个主流长文档摘要基准上进行了评测。结果表明，其在ROUGE、BERTScore、LLM评审和人工评测中均显著优于现有的最优方法。

Conclusion: 多智能体合作与对抗机制有效提升了摘要质量，特别是问答机制对信息完整性和一致性检验作用明显。提出的框架为长文档摘要提供了新方向。

Abstract: Long document summarization remains a significant challenge for current large
language models (LLMs), as existing approaches commonly struggle with
information loss, factual inconsistencies, and coherence issues when processing
excessively long documents. We propose SummQ, a novel adversarial multi-agent
framework that addresses these limitations through collaborative intelligence
between specialized agents operating in two complementary domains:
summarization and quizzing. Our approach employs summary generators and
reviewers that work collaboratively to create and evaluate comprehensive
summaries, while quiz generators and reviewers create comprehension questions
that serve as continuous quality checks for the summarization process. This
adversarial dynamic, enhanced by an examinee agent that validates whether the
generated summary contains the information needed to answer the quiz questions,
enables iterative refinement through multifaceted feedback mechanisms. We
evaluate SummQ on three widely used long document summarization benchmarks.
Experimental results demonstrate that our framework significantly outperforms
existing state-of-the-art methods across ROUGE and BERTScore metrics, as well
as in LLM-as-a-Judge and human evaluations. Our comprehensive analyses reveal
the effectiveness of the multi-agent collaboration dynamics, the influence of
different agent configurations, and the impact of the quizzing mechanism. This
work establishes a new approach for long document summarization that uses
adversarial agentic collaboration to improve summarization quality.

</details>


### [59] [MemLens: Uncovering Memorization in LLMs with Activation Trajectories](https://arxiv.org/abs/2509.20909)
*Zirui He,Haiyan Zhao,Ali Payani,Mengnan du*

Main category: cs.CL

TL;DR: 本文提出MemLens，通过分析模型生成过程中token概率轨迹，有效检测LLM是否因记忆污染影响推理过程，实现高效区分污染与干净样本，提升评估可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有针对大型语言模型（LLM）评估的方法易受数据污染及模型记忆影响，且当前检测方法对隐式污染数据表现不佳。作者希望能有效检测模型的记忆行为，避免表层特征误判。

Method: 提出MemLens方法，通过分析生成过程中的数值token概率轨迹，利用模型层间推理路径区分污染样本与干净样本；并通过LoRA微调注入定制样本进行验证。

Result: 污染样本会在模型早期层快速以高置信度锁定答案，干净样本则呈现更渐进的证据累积，表现出显著分离的推理轨迹。通过人为注入污染样本也得到同样结果，证明MemLens检测到真实记忆信号。

Conclusion: MemLens可有效区分记忆污染与真实推理过程，捕捉模型记忆特征，优于现有方法，可提升LLM评估的可靠性。

Abstract: Large language models (LLMs) are commonly evaluated on challenging benchmarks
such as AIME and Math500, which are susceptible to contamination and risk of
being memorized. Existing detection methods, which primarily rely on
surface-level lexical overlap and perplexity, demonstrate low generalization
and degrade significantly when encountering implicitly contaminated data. In
this paper, we propose MemLens (An Activation Lens for Memorization Detection)
to detect memorization by analyzing the probability trajectories of numeric
tokens during generation. Our method reveals that contaminated samples exhibit
``shortcut'' behaviors, locking onto an answer with high confidence in the
model's early layers, whereas clean samples show more gradual evidence
accumulation across the model's full depth. We observe that contaminated and
clean samples exhibit distinct and well-separated reasoning trajectories. To
further validate this, we inject carefully designed samples into the model
through LoRA fine-tuning and observe the same trajectory patterns as in
naturally contaminated data. These results provide strong evidence that MemLens
captures genuine signals of memorization rather than spurious correlations.

</details>


### [60] [Cross-Linguistic Analysis of Memory Load in Sentence Comprehension: Linear Distance and Structural Density](https://arxiv.org/abs/2509.20916)
*Krishna Aggarwal*

Main category: cs.CL

TL;DR: 本研究发现，除了依赖长度和句子长度外，句法结构中的‘干预者复杂度’能更好解释句子的记忆负载，对理解句子处理机制和评估相关理论具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨在句子理解过程中，造成记忆负载的主要因素是句法相关词之间的线性距离，还是结构间隔的复杂度（即干预成分的结构密度）。作者试图通过结构化视角对传统依赖长度最小化理论进行细化。

Method: 该研究利用统一的依存句法树库（UD treebanks）和跨多语言的混合效应建模框架，联合考察句长、依赖长度以及干预者复杂度三者对句子层级记忆负载的预测效果。记忆负载被操作性定义为特征干扰和特征错绑的线性总和。

Result: 这三种因素（句长、依赖长度、干预者复杂度）均正向影响记忆负载，句长影响最大，但干预者复杂度对记忆负载有超越依赖长度的解释力。

Conclusion: 该研究将线性和结构化本地性视角进行了统一，将依赖长度视为表层指标，而干预者复杂度是句法整合与保持的重要预测因子。方法上展示了如何利用句法图指标和跨语言混合效应模型区分线性与结构因素对理解效率的影响，为评估句子理解记忆负载理论提供了路径。

Abstract: This study examines whether sentence-level memory load in comprehension is
better explained by linear proximity between syntactically related words or by
the structural density of the intervening material. Building on locality-based
accounts and cross-linguistic evidence for dependency length minimization, the
work advances Intervener Complexity-the number of intervening heads between a
head and its dependent-as a structurally grounded lens that refines linear
distance measures. Using harmonized dependency treebanks and a mixed-effects
framework across multiple languages, the analysis jointly evaluates sentence
length, dependency length, and Intervener Complexity as predictors of the
Memory-load measure. Studies in Psycholinguistics have reported the
contributions of feature interference and misbinding to memory load during
processing. For this study, I operationalized sentence-level memory load as the
linear sum of feature misbinding and feature interference for tractability;
current evidence does not establish that their cognitive contributions combine
additively. All three factors are positively associated with memory load, with
sentence length exerting the broadest influence and Intervener Complexity
offering explanatory power beyond linear distance. Conceptually, the findings
reconcile linear and hierarchical perspectives on locality by treating
dependency length as an important surface signature while identifying
intervening heads as a more proximate indicator of integration and maintenance
demands. Methodologically, the study illustrates how UD-based graph measures
and cross-linguistic mixed-effects modelling can disentangle linear and
structural contributions to processing efficiency, providing a principled path
for evaluating competing theories of memory load in sentence comprehension.

</details>


### [61] [Tool Calling for Arabic LLMs: Data Strategies and Instruction Tuning](https://arxiv.org/abs/2509.20957)
*Asim Ersoy,Enes Altinisik,Husrev Taha Sencar,Kareem Darwish*

Main category: cs.CL

TL;DR: 本文针对阿拉伯语LLM工具调用能力的提升，提出并验证了数据来源和微调策略的重要性，为多语言智能体开发提供实证参考。


<details>
  <summary>Details</summary>
Motivation: 目前LLM工具调用主要集中于英语领域，其他语言（如阿拉伯语）相关资源和研究非常有限。本论文旨在探究如何提升阿拉伯语LLM工具调用能力，填补相关研究空白。

Method: 作者将两个开源工具调用数据集翻译并改编为阿拉伯语版本，然后用这些数据对阿拉伯语LLM（基础模型和经过微调的模型）进行广泛实验。研究问题包括：是否需要阿拉伯语专用数据、通用指令微调对工具调用性能的影响、高优先级工具专项微调的价值。

Result: 通过实验，作者获得了关于提升阿拉伯语工具增强智能体的关键策略的见解，包括不同数据来源和微调方法对性能的影响。

Conclusion: 要打造鲁棒的阿拉伯语工具增强型LLM，需在语内数据、合理的微调策略等方面做出精细优化。本文结论对多语言工具调用能力的开发具有指导意义。

Abstract: Tool calling is a critical capability that allows Large Language Models
(LLMs) to interact with external systems, significantly expanding their
utility. However, research and resources for tool calling are predominantly
English-centric, leaving a gap in our understanding of how to enable this
functionality for other languages, such as Arabic. This paper investigates
three key research questions: (1) the necessity of in-language (Arabic)
tool-calling data versus relying on cross-lingual transfer, (2) the effect of
general-purpose instruction tuning on tool-calling performance, and (3) the
value of fine-tuning on specific, high-priority tools. To address these
questions, we conduct extensive experiments using base and post-trained
variants of an open-weight Arabic LLM. To enable this study, we bridge the
resource gap by translating and adapting two open-source tool-calling datasets
into Arabic. Our findings provide crucial insights into the optimal strategies
for developing robust tool-augmented agents for Arabic.

</details>


### [62] [Analysis of instruction-based LLMs' capabilities to score and judge text-input problems in an academic setting](https://arxiv.org/abs/2509.20982)
*Valeria Ramirez-Garcia,David de-Fitero-Dominguez,Antonio Garcia-Cabot,Eva Garcia-Lopez*

Main category: cs.CL

TL;DR: 本研究对比了五种AI文本评分方法，发现“参考答案辅助评分法”效果最接近人工教师评分。自动化评分系统在教育中具有应用潜力，尤其以合理设置辅助资源时表现最佳。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在教育领域多作为师生辅助工具，而自动化评分系统对于教师减负和提升评分一致性具有重要意义。作者希望探索利用大语言模型自动评估学术性文本输入题目的可行性和效果。

Method: 提出并测试了五种自动评分系统：JudgeLM评分法、参考答案辅助评分、无参考答案评分、加法式评分和自适应评分。分别基于三种语言模型（JudgeLM、Llama-3.1-8B、DeepSeek-R1-Distill-Llama-8B）并在定制的110道高等教育计算机类文本题答案上进行对比测试。所有自动化方法结果都与人工评分结果进行了对比分析。

Result: 参考答案辅助评分法在与人工评分的对比中表现最佳：中位绝对偏差最低（0.945），均方根误差最低（1.214），综合评分公正、评价细致。其他方案如加法式和自适应评分在处理简短答案时效果不佳，无参考答案评分信息不足，JudgeLM评分法受模型局限无法给出满意结果。

Conclusion: 基于大语言模型的自动化评分系统，在合理框架和方法支撑下，可以作为学术资源的补充工具，有潜力与人工评分联合用于教学实践。

Abstract: Large language models (LLMs) can act as evaluators, a role studied by methods
like LLM-as-a-Judge and fine-tuned judging LLMs. In the field of education,
LLMs have been studied as assistant tools for students and teachers. Our
research investigates LLM-driven automatic evaluation systems for academic
Text-Input Problems using rubrics. We propose five evaluation systems that have
been tested on a custom dataset of 110 answers about computer science from
higher education students with three models: JudgeLM, Llama-3.1-8B and
DeepSeek-R1-Distill-Llama-8B. The evaluation systems include: The JudgeLM
evaluation, which uses the model's single answer prompt to obtain a score;
Reference Aided Evaluation, which uses a correct answer as a guide aside from
the original context of the question; No Reference Evaluation, which ommits the
reference answer; Additive Evaluation, which uses atomic criteria; and Adaptive
Evaluation, which is an evaluation done with generated criteria fitted to each
question. All evaluation methods have been compared with the results of a human
evaluator. Results show that the best method to automatically evaluate and
score Text-Input Problems using LLMs is Reference Aided Evaluation. With the
lowest median absolute deviation (0.945) and the lowest root mean square
deviation (1.214) when compared to human evaluation, Reference Aided Evaluation
offers fair scoring as well as insightful and complete evaluations. Other
methods such as Additive and Adaptive Evaluation fail to provide good results
in concise answers, No Reference Evaluation lacks information needed to
correctly assess questions and JudgeLM Evaluations have not provided good
results due to the model's limitations. As a result, we conclude that
Artificial Intelligence-driven automatic evaluation systems, aided with proper
methodologies, show potential to work as complementary tools to other academic
resources.

</details>


### [63] [Generative AI for FFRDCs](https://arxiv.org/abs/2509.21040)
*Arun S. Maiya*

Main category: cs.CL

TL;DR: 该论文证明大型语言模型结合开源安全框架，可在保证数据安全和可审计性的前提下，显著加速FFRDCs处理政策及科研文本，提高分析效率及战略洞察能力。


<details>
  <summary>Details</summary>
Motivation: FFRDCs在分析政策文件和科技论文等文本任务时，手动处理效率低下，需要加速文本处理流程，尤其是在政府敏感背景下还需保证数据安全和可溯性。

Method: 利用大型语言模型进行摘要、分类、信息抽取和理解任务，并应用开源平台OnPrem.LLM，确保生成式AI在安全和灵活的框架下应用于敏感数据场景。

Result: 该方法通过案例研究（如NDAA和NSF）证明了能够提升监督与战略分析能力，同时保留审计和数据主权。

Conclusion: 大型语言模型结合安全部署平台，可有效提升政府及科研文本分析能力，兼顾效率与安全。

Abstract: Federally funded research and development centers (FFRDCs) face text-heavy
workloads, from policy documents to scientific and engineering papers, that are
slow to analyze manually. We show how large language models can accelerate
summarization, classification, extraction, and sense-making with only a few
input-output examples. To enable use in sensitive government contexts, we apply
OnPrem$.$LLM, an open-source framework for secure and flexible application of
generative AI. Case studies on defense policy documents and scientific corpora,
including the National Defense Authorization Act (NDAA) and National Science
Foundation (NSF) Awards, demonstrate how this approach enhances oversight and
strategic analysis while maintaining auditability and data sovereignty.

</details>


### [64] [Behind RoPE: How Does Causal Mask Encode Positional Information?](https://arxiv.org/abs/2509.21042)
*Junu Kim,Xiao Liu,Zhenghao Lin,Lei Ji,Yeyun Gong,Edward Choi*

Main category: cs.CL

TL;DR: 论文发现Transformer中的因果掩码能够对注意力分布产生显著的位置影响，不仅与显式位置编码效果类似，还会与RoPE等编码方式产生复杂互动，从而影响大模型性能，提醒大家重视掩码自身的位置信息价值。


<details>
  <summary>Details</summary>
Motivation: 虽然Transformer结构广泛使用显式位置编码（如RoPE）为模型提供位置信息，但论文关注另一个通常被忽略的来源——因果掩码（causal mask），探索其对注意力模式的影响。

Method: 理论分析因果掩码对注意力分数的作用，证明无需参数或输入中因果依赖，掩码本身就能诱导位置相关的注意力分布；并通过实证分析，观察训练后模型的实际表现。还分析了因果掩码与RoPE的相互作用。

Result: 理论和实证表明，因果掩码使注意力更偏向于邻近位置，类似显式位置编码的效果。经过训练模型后，这种模式还被参数进一步增强。此外，因果掩码与RoPE的组合会扭曲RoPE原有的相对注意力模式，使其变为非相对模式，这一现象在主流大模型中都被观察到。

Conclusion: 因果掩码本身就是重要的位置信息来源，与显式位置编码结合时还会发生复杂干扰。因此，研究和设计Transformer时应重视因果掩码的作用，不能仅依赖显式位置编码。

Abstract: While explicit positional encodings such as RoPE are a primary source of
positional information in Transformer decoders, the causal mask also provides
positional information. In this work, we prove that the causal mask can induce
position-dependent patterns in attention scores, even without parameters or
causal dependency in the input. Our theoretical analysis indicates that the
induced attention pattern tends to favor nearby query-key pairs, mirroring the
behavior of common positional encodings. Empirical analysis confirms that
trained models exhibit the same behavior, with learned parameters further
amplifying these patterns. Notably, we found that the interaction of causal
mask and RoPE distorts RoPE's relative attention score patterns into
non-relative ones. We consistently observed this effect in modern large
language models, suggesting the importance of considering the causal mask as a
source of positional information alongside explicit positional encodings.

</details>


### [65] [When Instructions Multiply: Measuring and Estimating LLM Capabilities of Multiple Instructions Following](https://arxiv.org/abs/2509.21051)
*Keno Harada,Yudai Yamazaki,Masachika Taniguchi,Edison Marrese-Taylor,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CL

TL;DR: 本文提出两大基准和回归预测方案，系统评估LLM多指令能力。实验证明：指令增多性能下降，回归模型能高效预估新场景表现，评估成本低。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在真实场景应用中，需同时遵循多条指令，因此亟需系统性评估其同时执行多条指令的能力。

Method: 提出了两个专用评测基准：ManyIFEval（用于最多十条指令下文本生成）和StyleMBPP（用于最多六条指令下代码生成），并在十个LLM模型间进行实验。同时开发了三种回归模型用于预测未见组合及不同指令数量时的性能表现。

Result: 结果显示，随着指令数量增加，模型性能稳定下降。回归模型（尤其是以指令数为解释变量的逻辑回归）能在约10%的误差范围内预测未见指令组合的性能，且仅需较小样本量（ManyIFEval为500，StyleMBPP为300）即可高效评估模型表现。

Conclusion: 该方法为高效、系统性地评估LLM在多指令场景下的表现和泛化能力提供了可行路径，有助于实际应用中模型评估。

Abstract: As large language models (LLMs) are increasingly applied to real-world
scenarios, it becomes crucial to understand their ability to follow multiple
instructions simultaneously. To systematically evaluate these capabilities, we
introduce two specialized benchmarks for fundamental domains where multiple
instructions following is important: Many Instruction-Following Eval
(ManyIFEval) for text generation with up to ten instructions, and Style-aware
Mostly Basic Programming Problems (StyleMBPP) for code generation with up to
six instructions. Our experiments with the created benchmarks across ten LLMs
reveal that performance consistently degrades as the number of instructions
increases. Furthermore, given the fact that evaluating all the possible
combinations of multiple instructions is computationally impractical in actual
use cases, we developed three types of regression models that can estimate
performance on both unseen instruction combinations and different numbers of
instructions which are not used during training. We demonstrate that a logistic
regression model using instruction count as an explanatory variable can predict
performance of following multiple instructions with approximately 10% error,
even for unseen instruction combinations. We show that relatively modest sample
sizes (500 for ManyIFEval and 300 for StyleMBPP) are sufficient for performance
estimation, enabling efficient evaluation of LLMs under various instruction
combinations.

</details>


### [66] [SoM-1K: A Thousand-Problem Benchmark Dataset for Strength of Materials](https://arxiv.org/abs/2509.21079)
*Qixin Wan,Zilong Wang,Jingwen Zhou,Wanting Wang,Ziheng Geng,Jiachen Liu,Ran Cao,Minghui Cheng,Lu Cheng*

Main category: cs.CL

TL;DR: 提出了SoM-1K多模态工程问题基准，发现当前基础模型在此类任务上表现欠佳，且精准的图像文本描述比直接输入图像更有效。呼吁基础模型提升多模态推理能力，特别是在科学与工程领域。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在许多领域展现了强大能力，但它们在复杂的多模态工程问题，尤其是材料强度（SoM）领域的表现尚未充分探索。

Method: 作者提出了SoM-1K，这是首个针对材料强度问题的大规模多模态基准数据集，包含文本和示意图。为应对基础模型理解复杂视觉信息的局限，提出了描述图片（DoI）策略，即由专家生成的严谨文本描述作为上下文信息，并对8个代表性基础模型进行了评估。

Result: 当前基础模型在解决工程类问题方面表现有限，最佳模型仅取得56.6%的准确率。使用DoI的LLM在多数情况下优于直接使用图像的VLM。误差分析发现，DoI能有效降低视觉误解错误，说明准确的文本描述比直接图像更有效。

Conclusion: 本研究首次建立了工程AI领域的严格多模态基准，表明在科学和工程上下文下，基础模型需要更强大的多模态推理能力。

Abstract: Foundation models have shown remarkable capabilities in various domains, but
their performance on complex, multimodal engineering problems remains largely
unexplored. We introduce SoM-1K, the first large-scale multimodal benchmark
dataset dedicated to evaluating foundation models on problems in the strength
of materials (SoM). The dataset, which contains 1,065 annotated SoM problems,
mirrors real-world engineering tasks by including both textual problem
statements and schematic diagrams. Due to the limited capabilities of current
foundation models in understanding complicated visual information, we propose a
novel prompting strategy called Descriptions of Images (DoI), which provides
rigorous expert-generated text descriptions of the visual diagrams as the
context. We evaluate eight representative foundation models, including both
large language models (LLMs) and vision language models (VLMs). Our results
show that current foundation models struggle significantly with these
engineering problems, with the best-performing model achieving only 56.6%
accuracy. Interestingly, we found that LLMs, when provided with DoI, often
outperform VLMs provided with visual diagrams. A detailed error analysis
reveals that DoI plays a crucial role in mitigating visual misinterpretation
errors, suggesting that accurate text-based descriptions can be more effective
than direct image input for current foundation models. This work establishes a
rigorous benchmark for engineering AI and highlights a critical need for
developing more robust multimodal reasoning capabilities in foundation models,
particularly in scientific and engineering contexts.

</details>


### [67] [Which Cultural Lens Do Models Adopt? On Cultural Positioning Bias and Agentic Mitigation in LLMs](https://arxiv.org/abs/2509.21080)
*Yixin Wan,Xingrun Chen,Kai-Wei Chang*

Main category: cs.CL

TL;DR: 大语言模型在生成内容时常以主流美国文化视角为中心，导致对其他文化的外部化和偏见。作者设计了CultureLens基准及公平缓解策略，通过多智能体方法显著减轻了这种偏见，推动了生成式AI的多元公平发展。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLM）在生成任务上表现优异，但它们在生成内容时往往以主流美国文化角度为中心，从而对非主流文化产生外部性和不公平的定位。这种偏见可能加剧文化边缘化，因此有必要系统性评估和缓解该问题。

Method: 作者提出了CultureLens基准，包括4000个生成提示和3项评价指标，并设计了一个以文化访谈脚本生成为场景的测试任务，涉及10种不同文化。还提出两种推理时偏见缓解方法：基于提示的公平干预（FIP）和结构化的多智能体公平缓解框架（MFA），后者包括单智能体（MFA-SA）和多智能体（MFA-MA）方案。

Result: 实证结果显示，五个最先进的大语言模型在美国文化相关脚本中88%以上采用内部人士语调，但在其他文化场景中则明显倾向于采用“外部人”立场。多智能体的公平缓解方法显著提升了生成内容的公正性。

Conclusion: 文化定位偏见是当前大语言模型中值得关注的新问题。提出的CultureLens基准和智能体缓解方法可有效应对偏见问题，为更公平的生成式AI研究提供了新方向。

Abstract: Large language models (LLMs) have unlocked a wide range of downstream
generative applications. However, we found that they also risk perpetuating
subtle fairness issues tied to culture, positioning their generations from the
perspectives of the mainstream US culture while demonstrating salient
externality towards non-mainstream ones. In this work, we identify and
systematically investigate this novel culture positioning bias, in which an
LLM's default generative stance aligns with a mainstream view and treats other
cultures as outsiders. We propose the CultureLens benchmark with 4000
generation prompts and 3 evaluation metrics for quantifying this bias through
the lens of a culturally situated interview script generation task, in which an
LLM is positioned as an onsite reporter interviewing local people across 10
diverse cultures. Empirical evaluation on 5 state-of-the-art LLMs reveals a
stark pattern: while models adopt insider tones in over 88 percent of
US-contexted scripts on average, they disproportionately adopt mainly outsider
stances for less dominant cultures. To resolve these biases, we propose 2
inference-time mitigation methods: a baseline prompt-based Fairness
Intervention Pillars (FIP) method, and a structured Mitigation via Fairness
Agents (MFA) framework consisting of 2 pipelines: (1) MFA-SA (Single-Agent)
introduces a self-reflection and rewriting loop based on fairness guidelines.
(2) MFA-MA (Multi-Agent) structures the process into a hierarchy of specialized
agents: a Planner Agent(initial script generation), a Critique Agent (evaluates
initial script against fairness pillars), and a Refinement Agent (incorporates
feedback to produce a polished, unbiased script). Empirical results showcase
the effectiveness of agent-based methods as a promising direction for
mitigating biases in generative LLMs.

</details>


### [68] [PerHalluEval: Persian Hallucination Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2509.21104)
*Mohammad Hosseini,Kimia Hosseini,Shayan Bali,Zahra Zanjani,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 提出了针对波斯语的幻觉评测基准PerHalluEval，对12种LLM在幻觉检测任务下进行测试，发现这些模型普遍难以处理波斯语幻觉问题，外部知识有助于减少幻觉，专用波斯语模型效果并无明显提升。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在低资源语言如波斯语中幻觉问题尤为突出，目前缺乏针对波斯语的系统性评测基准。为此，研究者希望建立一个评估波斯语幻觉的基准，以更好检测和研究LLMs在波斯语领域的表现。

Method: 提出PerHalluEval，这是首个专为波斯语设计的动态幻觉评测基准。其评测流程包括三阶段：LLM驱动生成、使用人类进行校验、根据生成标记的对话或摘要任务检测外在和内在幻觉。此外，采用了生成token的对数概率来筛选最具“可信度”的幻觉案例，并引入人工标注以突出波斯语文化相关的情境。

Result: 对12款主流LLMs（含开源和闭源模型）在该基准上的测试表明，这些模型在检测波斯语幻觉文本方面普遍表现较差。为摘要任务提供原文等外部知识能够部分缓解幻觉问题。此外，专门训练的波斯语模型与其他LLM在幻觉检测表现上未显示显著差异。

Conclusion: LLMs在低资源语言（如波斯语）依旧面临严重的幻觉检测挑战。PerHalluEval为未来相关研究提供了新的评测工具和方法，也突显了外部知识在控制幻觉现象中的作用，而专门训练的波斯语模型未必能带来更优幻觉检测能力。

Abstract: Hallucination is a persistent issue affecting all large language Models
(LLMs), particularly within low-resource languages such as Persian.
PerHalluEval (Persian Hallucination Evaluation) is the first dynamic
hallucination evaluation benchmark tailored for the Persian language. Our
benchmark leverages a three-stage LLM-driven pipeline, augmented with human
validation, to generate plausible answers and summaries regarding QA and
summarization tasks, focusing on detecting extrinsic and intrinsic
hallucinations. Moreover, we used the log probabilities of generated tokens to
select the most believable hallucinated instances. In addition, we engaged
human annotators to highlight Persian-specific contexts in the QA dataset in
order to evaluate LLMs' performance on content specifically related to Persian
culture. Our evaluation of 12 LLMs, including open- and closed-source models
using PerHalluEval, revealed that the models generally struggle in detecting
hallucinated Persian text. We showed that providing external knowledge, i.e.,
the original document for the summarization task, could mitigate hallucination
partially. Furthermore, there was no significant difference in terms of
hallucination when comparing LLMs specifically trained for Persian with others.

</details>


### [69] [BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback](https://arxiv.org/abs/2509.21106)
*Hyunseo Kim,Sangam Lee,Kwangwook Seo,Dongha Lee*

Main category: cs.CL

TL;DR: 提出BESPOKE基准，用于真实且细粒度地评估检索增强型LLM在个性化信息检索上的能力，为该领域的系统性分析和发展提供了新工具和数据。


<details>
  <summary>Details</summary>
Motivation: 当前将检索功能集成到大语言模型（LLM）中，提高了信息检索任务的效率，但现有系统依然无法充分满足多样化的用户需求，特别是缺乏对用户意图的个性化识别与信息呈现形式的个性化。个性化系统（如ChatGPT和Gemini）尚缺乏系统性评估。

Method: 作者提出了一个现实且诊断性强的基准——BESPOKE，专为评估检索增强型LLM的个性化能力设计。通过收集真实人类的聊天与搜索历史，并配合细粒度的用户偏好评分和反馈。数据由深度参与的人工标注者长期贡献，包括历史、查询和对生成回复的评价。

Result: 利用BESPOKE，作者进行系统分析，总结了实现信息检索任务有效个性化的关键需求，并为评估个性化检索增强型LLM提供了基础和方法。

Conclusion: BESPOKE是第一个现实且诊断性的个性化评估基准，能够推动个性化检索增强型LLM的发展和精准评估。

Abstract: Search-augmented large language models (LLMs) have advanced
information-seeking tasks by integrating retrieval into generation, reducing
users' cognitive burden compared to traditional search systems. Yet they remain
insufficient for fully addressing diverse user needs, which requires
recognizing how the same query can reflect different intents across users and
delivering information in preferred forms. While recent systems such as ChatGPT
and Gemini attempt personalization by leveraging user histories, systematic
evaluation of such personalization is under-explored. To address this gap, we
propose BESPOKE, the realistic benchmark for evaluating personalization in
search-augmented LLMs. BESPOKE is designed to be both realistic, by collecting
authentic chat and search histories directly from humans, and diagnostic, by
pairing responses with fine-grained preference scores and feedback. The
benchmark is constructed through long-term, deeply engaged human annotation,
where human annotators contributed their own histories, authored queries with
detailed information needs, and evaluated responses with scores and diagnostic
feedback. Leveraging BESPOKE, we conduct systematic analyses that reveal key
requirements for effective personalization in information-seeking tasks,
providing a foundation for fine-grained evaluation of personalized
search-augmented LLMs. Our code and data are available at
https://augustinlib.github.io/BESPOKE/.

</details>


### [70] [VoiceBBQ: Investigating Effect of Content and Acoustics in Social Bias of Spoken Language Model](https://arxiv.org/abs/2509.21108)
*Junhyuk Choi,Ro-hoon Oh,Jihwan Seol,Bugeun Kim*

Main category: cs.CL

TL;DR: 作者提出了首个系统化评估语音语言模型内容及声学偏见的新基准VoiceBBQ，并系统对比现有两大模型在多维偏见上的表现，为语音AI公平性研究奠定基础。


<details>
  <summary>Details</summary>
Motivation: 随着语音交互技术的普及，研究者发现语音语言模型不仅可能在内容上存在社会偏见，还会因语音特征（如口音、性别等）进一步放大或产生新的偏见。目前针对文本数据的偏见评估已较为成熟，但缺乏针对语音模型的标准化测试集和评测方式。该工作旨在填补这一空白。

Method: 作者将现有的文本偏见评估基准（BBQ）扩展到语音领域，构建了VoiceBBQ数据集。具体做法是将BBQ中的文本上下文转为受控的语音条件，并配套设计了一套分别评估模型在内容与声学层面偏见（如性别、口音等）的评价指标。同时，选取两种主流语音语言模型LLaMA-Omni和Qwen2-Audio在新基准上进行系统性比较。

Result: 实验结果表明：LLaMA-Omni模型对声学偏见具有较强抵抗力，但在性别和口音偏见上表现较差；Qwen2-Audio模型在抑制声学线索方面表现优异，同时能较好维护内容准确性。

Conclusion: VoiceBBQ作为公开且紧凑的新基准测试集，为业界评估和分析语音语言模型在内容和声学层面的偏见问题提供了便利，有助于相关模型的诊断与改进。

Abstract: We introduce VoiceBBQ, a spoken extension of the BBQ (Bias Benchmark for
Question Answering) - a dataset that measures social bias by presenting
ambiguous or disambiguated contexts followed by questions that may elicit
stereotypical responses. Due to the nature of speech, social bias in Spoken
Language Models (SLMs) can emerge from two distinct sources: 1) content aspect
and 2) acoustic aspect. The dataset converts every BBQ context into controlled
voice conditions, enabling per-axis accuracy, bias, and consistency scores that
remain comparable to the original text benchmark. Using VoiceBBQ, we evaluate
two SLMs - LLaMA-Omni and Qwen2-Audio - and observe architectural contrasts:
LLaMA-Omni resists acoustic bias while amplifying gender and accent bias,
whereas Qwen2-Audio substantially dampens these cues while preserving content
fidelity. VoiceBBQ thus provides a compact, drop-in testbed for jointly
diagnosing content and acoustic bias across spoken language models.

</details>


### [71] [Acoustic-based Gender Differentiation in Speech-aware Language Models](https://arxiv.org/abs/2509.21125)
*Junhyuk Choi,Jihwan Seol,Nayeon Kim,Chanhee Cho,EunBin Cho,Bugeun Kim*

Main category: cs.CL

TL;DR: 本文构建新数据集系统分析SpeechLMs的性别响应模式，发现模型在性别刻板印象问题上偏向男性，在性别相关问题上却忽略性别差异，偏见主要来自语音编码器而非文本模型，说明当前技术对性别信息的正确利用仍需改进。


<details>
  <summary>Details</summary>
Motivation: 语音交互AI日渐普及，但在模型响应中存在基于性别的差异，尤其当相同内容因发话人的性别导致不同回答。研究动机在于系统分析这种现象并揭示其背后的技术缺陷与偏见来源。

Method: 作者构建了包含9208个语音样本（分为性别独立、性别刻板印象、性别相关三类）的新数据集，并通过系统分析和对比实验，尤其对LLaMA-Omni系列模型进行了评估；还将SpeechLMs与其基础LLM进行对比，分析偏差来源。

Result: 发现LLaMA-Omni系列模型在性别刻板类别问题中倾向于“男性化”回答，而在性别相关但应区分性别的问题时却给出性别独立回答。此外，偏见主要源于Whisper语音编码器，其生成的声学特征更偏男性。这些现象与回应内容的中性或声音性别无关，通过性别中和方法也不能消除这种模式。

Conclusion: 当前的语音感知语言模型（SpeechLMs）在处理性别信息时存在悖论性问题，尤其在性别相关的问题上无法有效消除性别偏见，虽然整体表现公平，但在具体语境下仍有缺陷。

Abstract: Speech-aware Language Models (SpeechLMs) have fundamentally transformed
human-AI interaction by enabling voice-based communication, yet they may
exhibit acoustic-based gender differentiation where identical questions lead to
different responses based on the speaker's gender. This paper propose a new
dataset that enables systematic analysis of this phenomenon, containing 9,208
speech samples across three categories: Gender-Independent,
Gender-Stereotypical, and Gender-Dependent. We further evaluated LLaMA-Omni
series and discovered a paradoxical pattern; while overall responses seems
identical regardless of gender, the pattern is far from unbiased responses.
Specifically, in Gender-Stereotypical questions, all models consistently
exhibited male-oriented responses; meanwhile, in Gender-Dependent questions
where gender differentiation would be contextually appropriate, models
exhibited responses independent to gender instead. We also confirm that this
pattern does not result from neutral options nor perceived gender of a voice.
When we allow neutral response, models tends to respond neutrally also in
Gender-Dependent questions. The paradoxical pattern yet retains when we applied
gender neutralization methods on speech. Through comparison between SpeechLMs
with corresponding backbone LLMs, we confirmed that these paradoxical patterns
primarily stem from Whisper speech encoders, which generates male-oriented
acoustic tokens. These findings reveal that current SpeechLMs may not
successfully remove gender biases though they prioritized general fairness
principles over contextual appropriateness, highlighting the need for more
sophisticated techniques to utilize gender information properly in speech
technology.

</details>


### [72] [AutoIntent: AutoML for Text Classification](https://arxiv.org/abs/2509.21138)
*Ilya Alekseev,Roman Solomatin,Darina Rustamova,Denis Kuznetsov*

Main category: cs.CL

TL;DR: AutoIntent是一款面向文本分类的自动化机器学习工具，能够自动选择嵌入模型和优化分类器，支持多标签分类与超出范围检测，在效果与资源消耗方面优于当前同类工具。


<details>
  <summary>Details</summary>
Motivation: 现有自动机器学习工具对于文本分类任务存在自动化程度有限和功能不够完善的问题，如嵌入模型和分类器选择、决策阈值未自动优化。提出AutoIntent以实现更全面的自动化及更优性能。

Method: 采用端到端自动化，包括嵌入模型选择、分类器优化和决策阈值调优，框架支持多标签分类和超出范围检测。

Result: AutoIntent在标准意图分类数据集上性能超越其它AutoML工具，可帮助用户在有效性与资源消耗间做出权衡。

Conclusion: AutoIntent在标准意图分类数据集上表现优异，优于现有AutoML工具，并能够在效果与资源消耗之间实现平衡。

Abstract: AutoIntent is an automated machine learning tool for text classification
tasks. Unlike existing solutions, AutoIntent offers end-to-end automation with
embedding model selection, classifier optimization, and decision threshold
tuning, all within a modular, sklearn-like interface. The framework is designed
to support multi-label classification and out-of-scope detection. AutoIntent
demonstrates superior performance compared to existing AutoML tools on standard
intent classification datasets and enables users to balance effectiveness and
resource consumption.

</details>


### [73] [Retrieval over Classification: Integrating Relation Semantics for Multimodal Relation Extraction](https://arxiv.org/abs/2509.21151)
*Lei Hei,Tingjing Liao,Yingxin Pei,Yiyang Qi,Jiaqi Wang,Ruiting Li,Feiliang Ren*

Main category: cs.CL

TL;DR: 该论文提出了一种创新的多模态关系抽取方法ROC，将问题转化为语义检索任务，结合结构信息和自然语言描述，实现了更优性能和更强解释能力。


<details>
  <summary>Details</summary>
Motivation: 传统的多模态关系抽取方法大多采用分类范式，用离散标签表示关系，但这种方式忽略了实体类型、位置等结构性约束，并且难以细致地表达语义关系。

Method: 提出ROC（Retrieval Over Classification）框架，将多模态关系抽取重新定义为基于关系语义的检索任务。该方法通过多模态编码器融合实体类型和位置信息，利用大语言模型将关系标签扩展为自然语言描述，并通过语义相似性对比学习进行实体-关系对齐。

Result: 在MNRE和MORE基准数据集上取得了当前最优的结果，并且在鲁棒性和可解释性方面表现更佳。

Conclusion: ROC框架较传统分类范式在多模态关系抽取上具有更强的表现力，对微粒度关系理解更深入，且兼具鲁棒性和可解释性。

Abstract: Relation extraction (RE) aims to identify semantic relations between entities
in unstructured text. Although recent work extends traditional RE to multimodal
scenarios, most approaches still adopt classification-based paradigms with
fused multimodal features, representing relations as discrete labels. This
paradigm has two significant limitations: (1) it overlooks structural
constraints like entity types and positional cues, and (2) it lacks semantic
expressiveness for fine-grained relation understanding. We propose
\underline{R}etrieval \underline{O}ver \underline{C}lassification (ROC), a
novel framework that reformulates multimodal RE as a retrieval task driven by
relation semantics. ROC integrates entity type and positional information
through a multimodal encoder, expands relation labels into natural language
descriptions using a large language model, and aligns entity-relation pairs via
semantic similarity-based contrastive learning. Experiments show that our
method achieves state-of-the-art performance on the benchmark datasets MNRE and
MORE and exhibits stronger robustness and interpretability.

</details>


### [74] [Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models](https://arxiv.org/abs/2509.21155)
*Chantal Shaib,Vinith M. Suriyakumar,Levent Sagun,Byron C. Wallace,Marzyeh Ghassemi*

Main category: cs.CL

TL;DR: 本文发现语法结构与领域知识在语言模型训练中有伪相关，既会影响模型任务表现，也可能成为绕过安全防护的漏洞。作者提出检测框架，并建议多样化训练语法，提升安全性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在理解任务指令时，主要关注语义和领域（主题），但语法结构也能隐含信息。近期研究发现模型训练和输出中普遍存在特定的句法模板，这些模板可能与领域知识产生非预期的相关性，影响模型表现和安全性。

Method: 作者通过合成训练数据，分析任务指令对中句法模板、领域和语义的关系，发现存在句法与领域的伪相关。设计了评估框架，检测训练模型（包括开源和闭源模型）中的这种现象，并通过案例分析其对安全性微调的影响。

Result: 发现句法-领域相关性会降低知识实体任务的性能（平均分0.51±0.06），并可用于绕过模型在特定领域拒绝回答的机制。该现象在多个主流模型和部分真实数据集上均存在。

Conclusion: 模型训练时若存在未控制的句法-领域相关性，可能导致性能下降和安全风险。需显式检测该相关性，并在训练数据中保证各领域句法多样性，以防止伪相关影响模型。

Abstract: For an LLM to correctly respond to an instruction it must understand both the
semantics and the domain (i.e., subject area) of a given task-instruction pair.
However, syntax can also convey implicit information Recent work shows that
syntactic templates--frequent sequences of Part-of-Speech (PoS) tags--are
prevalent in training data and often appear in model outputs. In this work we
characterize syntactic templates, domain, and semantics in task-instruction
pairs. We identify cases of spurious correlations between syntax and domain,
where models learn to associate a domain with syntax during training; this can
sometimes override prompt semantics. Using a synthetic training dataset, we
find that the syntactic-domain correlation can lower performance (mean 0.51 +/-
0.06) on entity knowledge tasks in OLMo-2 models (1B-13B). We introduce an
evaluation framework to detect this phenomenon in trained models, and show that
it occurs on a subset of the FlanV2 dataset in open (OLMo-2-7B;
Llama-4-Maverick), and closed (GPT-4o) models. Finally, we present a case study
on the implications for safety finetuning, showing that unintended
syntactic-domain correlations can be used to bypass refusals in OLMo-2-7B
Instruct and GPT-4o. Our findings highlight two needs: (1) to explicitly test
for syntactic-domain correlations, and (2) to ensure syntactic diversity in
training data, specifically within domains, to prevent such spurious
correlations.

</details>


### [75] [Who's Laughing Now? An Overview of Computational Humour Generation and Explanation](https://arxiv.org/abs/2509.21175)
*Tyler Loakman,William Thorne,Chenghua Lin*

Main category: cs.CL

TL;DR: 本综述指出计算幽默对于NLP和大模型评估极具意义，但目前相关领域发展有限，未来需关注其主观性与伦理挑战。


<details>
  <summary>Details</summary>
Motivation: 幽默是人类基本特性，其计算理解非常具有挑战性，有助于评估大型语言模型的常识与推理能力。

Method: 对计算幽默领域进行文献调研，重点关注幽默的生成与解释任务，并分析目前的发展与不足。

Result: 现有模型在生成和解释幽默（尤其是除双关语外）方面与人类相比表现不足；相关领域研究仍较为稀缺。

Conclusion: 计算幽默应成为自然语言处理的重要分支，未来需重点考虑幽默的主观性和伦理问题并持续研究改进。

Abstract: The creation and perception of humour is a fundamental human trait,
positioning its computational understanding as one of the most challenging
tasks in natural language processing (NLP). As an abstract, creative, and
frequently context-dependent construct, humour requires extensive reasoning to
understand and create, making it a pertinent task for assessing the
common-sense knowledge and reasoning abilities of modern large language models
(LLMs). In this work, we survey the landscape of computational humour as it
pertains to the generative tasks of creation and explanation. We observe that,
despite the task of understanding humour bearing all the hallmarks of a
foundational NLP task, work on generating and explaining humour beyond puns
remains sparse, while state-of-the-art models continue to fall short of human
capabilities. We bookend our literature survey by motivating the importance of
computational humour processing as a subdiscipline of NLP and presenting an
extensive discussion of future directions for research in the area that takes
into account the subjective and ethically ambiguous nature of humour.

</details>


### [76] [GEP: A GCG-Based method for extracting personally identifiable information from chatbots built on small language models](https://arxiv.org/abs/2509.21192)
*Jieli Zhu,Vi Ngoc-Nha Tran*

Main category: cs.CL

TL;DR: 本文聚焦小型语言模型在医疗聊天任务中的PII泄露，提出了更有效的检测方法GEP，比传统方法检测能力提升显著，并在复杂场景下依然有效，提示SLM在隐私安全方面需高度关注。


<details>
  <summary>Details</summary>
Motivation: 尽管小型语言模型（SLMs）在某些领域表现与大型语言模型（LLMs）相似，且训练和推理消耗更少资源，但其在下游任务中的个人身份信息（PII）泄露风险尚未被充分研究。作者希望填补这一研究空白，探讨SLM在医疗对话场景下的PII泄露情况。

Method: 作者以BioGPT为基础，微调得到新的医疗对话机器人ChatBioGPT，并与Alpaca与HealthCareMagic数据集进行对比验证。同时，作者测试了传统基于模板的PII攻击检测方法在SLM上的有效性，发现效果有限，于是提出基于贪婪坐标梯度（GCG）的GEP方法用于PII提取，并在多场景下（包括自由文本插入）对其进行实验评估。

Result: GEP方法能显著提升PII泄露检测率，在与传统模板法对比实验中，检测增幅最高可达60倍。即使在更复杂自由表达场景下，泄露率也达4.53%。ChatBioGPT在BERTscore评测上表现与过去研究相当。

Conclusion: SLM下传统PII检测手段效率显著下降，针对性的新方法（如GEP）能够极大提升医疗对话中PII泄露检测能力，表明SLM潜在的隐私风险不容忽视。

Abstract: Small language models (SLMs) become unprecedentedly appealing due to their
approximately equivalent performance compared to large language models (LLMs)
in certain fields with less energy and time consumption during training and
inference. However, the personally identifiable information (PII) leakage of
SLMs for downstream tasks has yet to be explored. In this study, we investigate
the PII leakage of the chatbot based on SLM. We first finetune a new chatbot,
i.e., ChatBioGPT based on the backbone of BioGPT using medical datasets Alpaca
and HealthCareMagic. It shows a matchable performance in BERTscore compared
with previous studies of ChatDoctor and ChatGPT. Based on this model, we prove
that the previous template-based PII attacking methods cannot effectively
extract the PII in the dataset for leakage detection under the SLM condition.
We then propose GEP, which is a greedy coordinate gradient-based (GCG) method
specifically designed for PII extraction. We conduct experimental studies of
GEP and the results show an increment of up to 60$\times$ more leakage compared
with the previous template-based methods. We further expand the capability of
GEP in the case of a more complicated and realistic situation by conducting
free-style insertion where the inserted PII in the dataset is in the form of
various syntactic expressions instead of fixed templates, and GEP is still able
to reveal a PII leakage rate of up to 4.53%.

</details>


### [77] [Eigen-1: Adaptive Multi-Agent Refinement with Monitor-Based RAG for Scientific Reasoning](https://arxiv.org/abs/2509.21193)
*Xiangru Tang,Wanghan Xu,Yujie Wang,Zijie Guo,Daniel Shao,Jiapeng Chen,Cixuan Zhang,Ziyi Wang,Lixin Zhang,Guancheng Wan,Wenlong Zhang,Lei Bai,Zhenfei Yin,Philip Torr,Hanrui Wang,Di Jin*

Main category: cs.CL

TL;DR: 该论文提出融合隐式检索与多智能体结构化协作的框架，显著提升了LLM的科学推理表现，刷新多项基准成绩，同时大幅降低计算消耗。实验与分析证实新方法在推理和检索等任务中的有效性与强迁移性。代码已开放。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLM）在科学推理任务上取得了较大进展，但依然面临两大瓶颈：显式检索（需要额外token和步骤，造成“工具税”）和多智能体方案常因平均处理稀释优秀解法。该研究致力于解决这两个问题。

Method: 提出了一个统一框架，将隐式检索与结构化协作结合。包括基于Monitor的检索模块，在token层面以极低干扰集成外部知识。还包括分层解法修正（HSR），通过迭代方式让候选解之间互相修补，以及质量感知迭代推理（QAIR），根据解答质量自适应修正流程。

Result: 在HLE Bio/Chem Gold测试中，框架准确率达48.3%，为当前最高水平，比最强agent基线提升13.4点，比前沿LLM高出最多18.1点。同时减少token消耗53.5%、agent步骤43.7%。在SuperGPQA和TRQA等任务也展现了强鲁棒性。错误分析显示，推理失败与知识缺口高度相关（85%以上），且多样性分析揭示：检索类任务受益于解法多样性，而推理类任务偏好一致性。

Conclusion: 隐式增强和结构化修正能够有效克服传统工具操作与平均方案带来的低效问题，提高LLM的科学推理表现，并在多个领域具备良好迁移性。

Abstract: Large language models (LLMs) have recently shown strong progress on
scientific reasoning, yet two major bottlenecks remain. First, explicit
retrieval fragments reasoning, imposing a hidden "tool tax" of extra tokens and
steps. Second, multi-agent pipelines often dilute strong solutions by averaging
across all candidates. We address these challenges with a unified framework
that combines implicit retrieval and structured collaboration. At its
foundation, a Monitor-based retrieval module operates at the token level,
integrating external knowledge with minimal disruption to reasoning. On top of
this substrate, Hierarchical Solution Refinement (HSR) iteratively designates
each candidate as an anchor to be repaired by its peers, while Quality-Aware
Iterative Reasoning (QAIR) adapts refinement to solution quality. On Humanity's
Last Exam (HLE) Bio/Chem Gold, our framework achieves 48.3\% accuracy -- the
highest reported to date, surpassing the strongest agent baseline by 13.4
points and leading frontier LLMs by up to 18.1 points, while simultaneously
reducing token usage by 53.5\% and agent steps by 43.7\%. Results on SuperGPQA
and TRQA confirm robustness across domains. Error analysis shows that reasoning
failures and knowledge gaps co-occur in over 85\% of cases, while diversity
analysis reveals a clear dichotomy: retrieval tasks benefit from solution
variety, whereas reasoning tasks favor consensus. Together, these findings
demonstrate how implicit augmentation and structured refinement overcome the
inefficiencies of explicit tool use and uniform aggregation. Code is available
at: https://github.com/tangxiangru/Eigen-1.

</details>


### [78] [CLaw: Benchmarking Chinese Legal Knowledge in Large Language Models - A Fine-grained Corpus and Reasoning Analysis](https://arxiv.org/abs/2509.21208)
*Xinzhe Xu,Liang Zhao,Hongshen Xu,Chen Chen*

Main category: cs.CL

TL;DR: 该研究提出了专为中国法律打造的CLaw基准，发现现有大模型在法律知识检索与应用上表现有限，强调提升知识检索与推理结合是实现可靠法律AI的关键。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）虽然常被用于法律文本分析和相关法规引用，但由于缺乏专门针对法律领域的预训练，导致其法律知识深度和可靠性受限。该研究旨在解决这一领域缺乏高质量评测基准的问题，推动法律领域LLM能力发展。

Method: 提出并构建了CLaw基准，包括两部分：一是覆盖全部306部中国国家法律、细致到款项级别、并考虑历史时序版本的法条数据集（共64,849条），二是来自中国最高法院真实材料的254道案例推理题，用于评估法律知识实际应用能力。通过实验测试多种主流LLM的法律文本检索和推理表现。

Result: 目前主流的LLM在准确回忆、复述法律条文方面表现不佳，尤其是在准确检索和引用法律条文这一关键基础任务上能力不足，影响其法律推理的可靠性。

Conclusion: 要实现可信赖的法律推理，LLM必须将高准确性的知识检索能力（如通过SFT或RAG等机制提升）和强大的推理能力有机结合。CLaw为今后法律领域专用LLM的开发和评测提供了重要评测基准和关键洞见。

Abstract: Large Language Models (LLMs) are increasingly tasked with analyzing legal
texts and citing relevant statutes, yet their reliability is often compromised
by general pre-training that ingests legal texts without specialized focus,
obscuring the true depth of their legal knowledge. This paper introduces CLaw,
a novel benchmark specifically engineered to meticulously evaluate LLMs on
Chinese legal knowledge and its application in reasoning. CLaw comprises two
key components: (1) a comprehensive, fine-grained corpus of all 306 Chinese
national statutes, segmented to the subparagraph level and incorporating
precise historical revision timesteps for rigorous recall evaluation (64,849
entries), and (2) a challenging set of 254 case-based reasoning instances
derived from China Supreme Court curated materials to assess the practical
application of legal knowledge. Our empirical evaluation reveals that most
contemporary LLMs significantly struggle to faithfully reproduce legal
provisions. As accurate retrieval and citation of legal provisions form the
basis of legal reasoning, this deficiency critically undermines the reliability
of their responses. We contend that achieving trustworthy legal reasoning in
LLMs requires a robust synergy of accurate knowledge retrieval--potentially
enhanced through supervised fine-tuning (SFT) or retrieval-augmented generation
(RAG)--and strong general reasoning capabilities. This work provides an
essential benchmark and critical insights for advancing domain-specific LLM
reasoning, particularly within the complex legal sphere.

</details>


### [79] [SGMem: Sentence Graph Memory for Long-Term Conversational Agents](https://arxiv.org/abs/2509.21212)
*Yaxiong Wu,Yongyue Zhang,Sheng Liang,Yong Liu*

Main category: cs.CL

TL;DR: SGMem以句子图结构管理并整合对话历史信息，有效提升了大语言模型在长期对话问答任务中的表现，优于传统记忆管理方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在对话历史超出上下文窗口时，内存管理存在瓶颈。以事实提取或摘要为基础的方法虽然能减少冗余，但难以跨不同粒度有效组织和检索相关信息。

Method: 提出了一种名为SGMem（句子图记忆）的新方法。该方法将对话以句子级图的方式在分块单元中表示，可捕捉轮次、回合和会话级别的关联。同时，SGMem将检索到的原始对话与摘要、事实、洞察等生成记忆结合，为LLM提供更连贯、相关的上下文。

Result: 在LongMemEval和LoCoMo两个数据集上的实验结果表明，SGMem能够持续提升准确率，并显著优于现有的强基线方法，特别是在长期对话问答任务中。

Conclusion: SGMem通过创新性地以句子图管理和整合多粒度对话信息，显著提升了LLM在长期对话中的记忆管理和问答能力。

Abstract: Long-term conversational agents require effective memory management to handle
dialogue histories that exceed the context window of large language models
(LLMs). Existing methods based on fact extraction or summarization reduce
redundancy but struggle to organize and retrieve relevant information across
different granularities of dialogue and generated memory. We introduce SGMem
(Sentence Graph Memory), which represents dialogue as sentence-level graphs
within chunked units, capturing associations across turn-, round-, and
session-level contexts. By combining retrieved raw dialogue with generated
memory such as summaries, facts and insights, SGMem supplies LLMs with coherent
and relevant context for response generation. Experiments on LongMemEval and
LoCoMo show that SGMem consistently improves accuracy and outperforms strong
baselines in long-term conversational question answering.

</details>


### [80] [Query-Centric Graph Retrieval Augmented Generation](https://arxiv.org/abs/2509.21237)
*Yaxiong Wu,Jianyuan Bo,Yongyue Zhang,Sheng Liang,Yong Liu*

Main category: cs.CL

TL;DR: 针对图结构RAG在粒度上的两难问题，QCG-RAG通过查询为中心的图结构和多跳检索机制，显著提升问答系统的准确率，为多跳推理任务提供了新范式。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的RAG方法在粒度选择上存在困境：实体级图粒度细但代价高且易丢失上下文，文档级图粒度粗不能捕捉细粒度关系。因此，论文希望寻找一种既能降低代价又能兼顾细粒度关系的方法。

Method: 论文提出QCG-RAG框架，利用Doc2Query系列方法构建以查询为中心、可控粒度的检索图，结合定制化的多跳检索机制，用生成的查询选择相关文本块。

Result: 在LiHuaWorld与MultiHop-RAG等数据集上的实验结果显示，QCG-RAG在多跳问答准确率上稳定优于主流的基于chunk和基于图的RAG方法。

Conclusion: QCG-RAG提出了一种新的图结构RAG框架，通过查询为中心的图索引和多跳检索，能够有效提升长上下文理解和多跳推理任务的性能。实验表明，该方法在问答准确率方面优于现有的RAG方法。

Abstract: Graph-based retrieval-augmented generation (RAG) enriches large language
models (LLMs) with external knowledge for long-context understanding and
multi-hop reasoning, but existing methods face a granularity dilemma:
fine-grained entity-level graphs incur high token costs and lose context, while
coarse document-level graphs fail to capture nuanced relations. We introduce
QCG-RAG, a query-centric graph RAG framework that enables query-granular
indexing and multi-hop chunk retrieval. Our query-centric approach leverages
Doc2Query and Doc2Query{-}{-} to construct query-centric graphs with
controllable granularity, improving graph quality and interpretability. A
tailored multi-hop retrieval mechanism then selects relevant chunks via the
generated queries. Experiments on LiHuaWorld and MultiHop-RAG show that QCG-RAG
consistently outperforms prior chunk-based and graph-based RAG methods in
question answering accuracy, establishing a new paradigm for multi-hop
reasoning.

</details>


### [81] [Un-Doubling Diffusion: LLM-guided Disambiguation of Homonym Duplication](https://arxiv.org/abs/2509.21262)
*Evgeny Kaskov,Elizaveta Petrova,Petr Surovtsev,Anna Kostikova,Ilya Mistiurin,Alexander Kapitanov,Alexander Nagaev*

Main category: cs.CL

TL;DR: 本文针对生成式模型，尤其是文本到图像的扩散模型在处理同形异义词时的重复生成与跨语言翻译失真问题，提出了测量与缓解方法，并验证了提示词扩展在减少多义词重复和缓解英语言中心偏见方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 同形异义词（即拼写相同但含义不同的词）在生成式模型中容易引发理解和生成错误，尤其在文本到图像的扩散模型中会导致多义词重复出现，同时，由于模型偏重英语翻译步骤，还可能使翻译后出现新的同形异义问题，进一步丧失原意。本文希望解决这些模型在处理同形异义词上的困扰。

Method: 提出一个同形异义词重复率的测量方法，结合自动评估（基于视觉语言模型）和人工评估，对不同扩散模型进行量化测试，同时探索使用提示词扩展的方法来缓解同形异义词重复及英语言中心偏见造成的问题。

Result: 提示词扩展的方法能够有效减少生成中的同形异义词重复现象，并在一定程度上缓解由英语翻译导致的语义丢失问题。提供了自动化评估相关代码以供公共使用。

Conclusion: 同形异义词处理是生成模型中的突出难题，通过提示词扩展及测量手段，可以有效改善模型对多义词的理解与生成，提升跨语言文本-图像生成模型的表现，减少英语言中心化偏见的负面影响。

Abstract: Homonyms are words with identical spelling but distinct meanings, which pose
challenges for many generative models. When a homonym appears in a prompt,
diffusion models may generate multiple senses of the word simultaneously, which
is known as homonym duplication. This issue is further complicated by an
Anglocentric bias, which includes an additional translation step before the
text-to-image model pipeline. As a result, even words that are not homonymous
in the original language may become homonyms and lose their meaning after
translation into English. In this paper, we introduce a method for measuring
duplication rates and conduct evaluations of different diffusion models using
both automatic evaluation utilizing Vision-Language Models (VLM) and human
evaluation. Additionally, we investigate methods to mitigate the homonym
duplication problem through prompt expansion, demonstrating that this approach
also effectively reduces duplication related to Anglocentric bias. The code for
the automatic evaluation pipeline is publicly available.

</details>


### [82] [LLM Output Homogenization is Task Dependent](https://arxiv.org/abs/2509.21267)
*Shomik Jain,Jack Lanchantin,Maximilian Nickel,Karen Ullrich,Ashia Wilson,Jamelle Watson-Daniels*

Main category: cs.CL

TL;DR: 该研究针对大语言模型输出同质化问题，提出了任务分类和基于任务的功能多样性评估方法，并通过改进采样机制提高了输出多样性，在保持质量的同时根据任务需求灵活应对同质化。


<details>
  <summary>Details</summary>
Motivation: 大语言模型常因输出同质化而降低实用性，但同质化的定义和问题性取决于任务类型。以往研究未能根据任务类型有效区分多样性。

Method: 提出了八类任务的任务分类法，每类对输出同质化有不同定义，并引入基于任务的功能多样性指标和采样技术，加强不希望同质化时的多样性，同时在需要同质化的任务保持同质化。

Result: 在不同任务类型下，通过新的采样方法可以有效增加功能多样性，但不降低答案质量，甚至提出多样性与质量之间未必存在必然权衡。

Conclusion: 任务依赖性视角能更好地评估和缓解语言模型输出同质化问题。

Abstract: A large language model can be less helpful if it exhibits output response
homogenization. But whether two responses are considered homogeneous, and
whether such homogenization is problematic, both depend on the task category.
For instance, in objective math tasks, we often expect no variation in the
final answer but anticipate variation in the problem-solving strategy. Whereas,
for creative writing tasks, we may expect variation in key narrative components
(e.g. plot, genre, setting, etc), beyond the vocabulary or embedding diversity
produced by temperature-sampling. Previous work addressing output
homogenization often fails to conceptualize diversity in a task-dependent way.
We address this gap in the literature directly by making the following
contributions. (1) We present a task taxonomy comprised of eight task
categories that each have distinct conceptualizations of output homogenization.
(2) We introduce task-anchored functional diversity to better evaluate output
homogenization. (3) We propose a task-anchored sampling technique that
increases functional diversity for task categories where homogenization is
undesired, while preserving homogenization where it is desired. (4) We
challenge the perceived existence of a diversity-quality trade-off by
increasing functional diversity while maintaining response quality. Overall, we
demonstrate how task dependence improves the evaluation and mitigation of
output homogenization.

</details>


### [83] [LLMTrace: A Corpus for Classification and Fine-Grained Localization of AI-Written Text](https://arxiv.org/abs/2509.21269)
*Irina Tolstykh,Aleksandra Tsybina,Sergey Yakubson,Maksim Kuprashevich*

Main category: cs.CL

TL;DR: 本文提出了LLMTrace，一个大规模双语（英俄）AI生成文本检测数据集，首次加入字符级标注，既能进行全文二分类也能精确定位混合文本中AI生成内容，为AI检测模型训练和评估提供了重要资源。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成文本检测训练数据存在模型过时、语种单一（主要为英语）、以及缺乏细粒度混合文本标注的问题，限制了检测系统的进步。尤其没有字符级标注，无法精确定位AI生成内容。

Method: 构建了大规模双语（英语和俄语）AI生成文本检测数据集，涵盖多种最新专有与开源LLM，包含传统的人类与AI二分类标注，以及首次引入字符级标注用于检测文本中AI生成的具体片段。

Result: LLMTrace数据集支持传统的全文二分类任务和创新的区间检测任务，允许对混合文本中AI生成部分进行精确定位。提供公开项目主页，便于获取和使用数据集。

Conclusion: LLMTrace数据集将成为训练和评估新一代更为细致且实用的AI生成文本检测模型的重要资源。

Abstract: The widespread use of human-like text from Large Language Models (LLMs)
necessitates the development of robust detection systems. However, progress is
limited by a critical lack of suitable training data; existing datasets are
often generated with outdated models, are predominantly in English, and fail to
address the increasingly common scenario of mixed human-AI authorship.
Crucially, while some datasets address mixed authorship, none provide the
character-level annotations required for the precise localization of
AI-generated segments within a text. To address these gaps, we introduce
LLMTrace, a new large-scale, bilingual (English and Russian) corpus for
AI-generated text detection. Constructed using a diverse range of modern
proprietary and open-source LLMs, our dataset is designed to support two key
tasks: traditional full-text binary classification (human vs. AI) and the novel
task of AI-generated interval detection, facilitated by character-level
annotations. We believe LLMTrace will serve as a vital resource for training
and evaluating the next generation of more nuanced and practical AI detection
models. The project page is available at
\href{https://sweetdream779.github.io/LLMTrace-info/}{iitolstykh/LLMTrace}.

</details>


### [84] [Bounds of Chain-of-Thought Robustness: Reasoning Steps, Embed Norms, and Beyond](https://arxiv.org/abs/2509.21284)
*Dingzirui Wang,Xuanliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 本文理论且实证分析了输入扰动对链式思维输出的影响，提出了扰动影响的上界及其与推理步骤数量和向量范数的相关性，并验证了理论正确性，为后续提示优化和模型鲁棒性研究提供参考。


<details>
  <summary>Details</summary>
Motivation: 尽管已有许多方法试图通过优化提示（prompt）来缓解输入扰动对链式思维（CoT）输出的影响，但对于这些扰动如何影响CoT输出的理论解释尚不充分，阻碍了深入理解和进一步提升提示优化方法。

Method: 本文从理论角度分析了输入扰动对CoT输出波动的影响。首先推导了在输出波动可接受范围内输入扰动的上界，并证明了该上界与推理步骤数量正相关，且无限长推理过程也无法消除扰动影响。同时，将结论应用于简化版Transformer模型——线性自注意力（LSA）模型，并证明输入扰动的上界与输入嵌入和隐藏状态向量的范数负相关。最后，在三个主流数据集和四个主流模型上进行了实证实验，验证理论分析的正确性。

Result: 理论分析发现：1）输入扰动的影响无法被无限推理步骤完全消除；2）输入扰动的可接受上界与推理步骤数正相关，在LSA模型中该上界与向量范数负相关。实验结果与理论分析一致，验证了理论结论的正确性。

Conclusion: 本文系统阐释了输入扰动对CoT输出影响的理论机制，提出了扰动影响的上界及相关性，并通过实验有力验证，为进一步优化提示设计和理解CoT推理过程提供了理论基础。

Abstract: Existing research indicates that the output of Chain-of-Thought (CoT) is
significantly affected by input perturbations. Although many methods aim to
mitigate such impact by optimizing prompts, a theoretical explanation of how
these perturbations influence CoT outputs remains an open area of research.
This gap limits our in-depth understanding of how input perturbations propagate
during the reasoning process and hinders further improvements in prompt
optimization methods. Therefore, in this paper, we theoretically analyze the
effect of input perturbations on the fluctuation of CoT outputs. We first
derive an upper bound for input perturbations under the condition that the
output fluctuation is within an acceptable range, based on which we prove that:
(i) This upper bound is positively correlated with the number of reasoning
steps in the CoT; (ii) Even an infinitely long reasoning process cannot
eliminate the impact of input perturbations. We then apply these conclusions to
the Linear Self-Attention (LSA) model, which can be viewed as a simplified
version of the Transformer. For the LSA model, we prove that the upper bound
for input perturbation is negatively correlated with the norms of the input
embedding and hidden state vectors. To validate this theoretical analysis, we
conduct experiments on three mainstream datasets and four mainstream models.
The experimental results align with our theoretical analysis, empirically
demonstrating the correctness of our findings.

</details>


### [85] [DisCoCLIP: A Distributional Compositional Tensor Network Encoder for Vision-Language Understanding](https://arxiv.org/abs/2509.21287)
*Kin Ian Lo,Hala Hawashin,Mina Abbaszadeh,Tilen Limback-Stokin,Hadi Wazni,Mehrnoosh Sadrzadeh*

Main category: cs.CL

TL;DR: DisCoCLIP创新性地将句法结构通过张量网络融入视觉-语言模型，不仅大幅减少参数量，还显著提升模型在语序和主谓宾结构相关任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型擅长大规模图文匹配，但在语言的组合结构（如词序、主谓宾结构）处理上表现不足，限制了模型的理解和推理能力。因此需要显式地将语言的句法结构融入多模态表达中。

Method: 提出DisCoCLIP模型，将冻结的CLIP视觉变换器与创新的张量网络文本编码器结合。通过Combinatory Categorial Grammar（CCG）解析句子，生成分布式词张量，并通过张量收缩模拟句法推导，同时通过张量分解显著降低参数量。模型采用自监督对比损失进行端到端训练。

Result: DisCoCLIP模型显著改善了对动词语义和词序敏感度：SVO-Probes动词准确率提升至82.4%，ARO属性和关系分数分别提升9%和4%以上；在新增SVO-Swap基准下达到93.7%的准确率。证明嵌入句法结构能有效提升视觉-语言推理能力。

Conclusion: 通过在视觉-语言模型中显式编码语言的语法结构，能显著提升模型在句法和语序相关任务上的表现，实现更高效、更可解释的融合表达。

Abstract: Recent vision-language models excel at large-scale image-text alignment but
often neglect the compositional structure of language, leading to failures on
tasks that hinge on word order and predicate-argument structure. We introduce
DisCoCLIP, a multimodal encoder that combines a frozen CLIP vision transformer
with a novel tensor network text encoder that explicitly encodes syntactic
structure. Sentences are parsed with a Combinatory Categorial Grammar parser to
yield distributional word tensors whose contractions mirror the sentence's
grammatical derivation. To keep the model efficient, high-order tensors are
factorized with tensor decompositions, reducing parameter count from tens of
millions to under one million. Trained end-to-end with a self-supervised
contrastive loss, DisCoCLIP markedly improves sensitivity to verb semantics and
word order: it raises CLIP's SVO-Probes verb accuracy from 77.6% to 82.4%,
boosts ARO attribution and relation scores by over 9% and 4%, and achieves
93.7% on a newly introduced SVO-Swap benchmark. These results demonstrate that
embedding explicit linguistic structure via tensor networks yields
interpretable, parameter-efficient representations that substantially improve
compositional reasoning in vision-language tasks.

</details>


### [86] [The role of synthetic data in Multilingual, Multi-cultural AI systems: Lessons from Indic Languages](https://arxiv.org/abs/2509.21294)
*Pranjal A. Chitale,Varun Gumma,Sanchit Ahuja,Prashant Kodali,Manan Uppadhyay,Deepthi Sudharsan,Sunayana Sitaram*

Main category: cs.CL

TL;DR: 作者提出结合大模型和本土文化语境生成印度本地语言合成数据（Updesh），显著提升中低资源语言AI能力，表明多语种文化感知型数据生成是提升多语言AI的重要途径。


<details>
  <summary>Details</summary>
Motivation: 在多语言和多文化环境下，尤其是低资源语言中，开发有效的AI系统是一个长期未决的问题。现有大多数据通过将高资源语言（如英语）生成的合成数据进行翻译，缺乏对本土文化和语言背景的考虑。作者希望探索更具文化语境的数据生成方式。

Method: 提出了一种“自底向上”的合成数据生成策略，利用大型开源LLM（参数量≥235B），以各语言的Wikipedia内容为基础生成印度语言的数据。与主流的“自顶向下”将高资源语言数据翻译成低资源语言的方法互补，并开发了覆盖13种印度语言、950万条数据的合成指令跟随数据集Updesh。通过自动化评估和人工注释对数据质量进行全面评测，并在15个多语言数据集上微调模型进行下游评估。

Result: 基于Updesh微调的模型在生成类任务上取得显著提升，并在多项选择类NLU任务上表现具有竞争力。相较高资源语言，低及中资源语言的提升更为显著，缩小了与高资源语言在AI性能上的差距。

Conclusion: 有效的多语言AI系统需要多元化、具备语境感知和文化适应性的数据策划和生成方法。Updesh的构建和相关实验为文化本地化、语境相关的数据生成方式的价值提供了经验证据。

Abstract: Developing AI systems that operate effectively across languages while
remaining culturally grounded is a long-standing challenge, particularly in
low-resource settings. Synthetic data provides a promising avenue, yet its
effectiveness in multilingual and multicultural contexts remains underexplored.
We investigate the creation and impact of synthetic, culturally contextualized
datasets for Indian languages through a bottom-up generation strategy that
prompts large open-source LLMs (>= 235B parameters) to ground data generation
in language-specific Wikipedia content. This approach complements the dominant
top-down paradigm of translating synthetic datasets from high-resource
languages such as English. We introduce Updesh, a high-quality large-scale
synthetic instruction-following dataset comprising 9.5M data points across 13
Indian languages, encompassing diverse reasoning and generative tasks with an
emphasis on long-context, multi-turn capabilities, and alignment with Indian
cultural contexts. A comprehensive evaluation incorporating both automated
metrics and human annotation across 10k assessments indicates that generated
data is high quality; though, human evaluation highlights areas for further
improvement. Additionally, we perform downstream evaluations by fine-tuning
models on our dataset and assessing the performance across 15 diverse
multilingual datasets. Models trained on Updesh consistently achieve
significant gains on generative tasks and remain competitive on multiple-choice
style NLU tasks. Notably, relative improvements are most pronounced in low and
medium-resource languages, narrowing their gap with high-resource languages.
These findings provide empirical evidence that effective multilingual AI
requires multi-faceted data curation and generation strategies that incorporate
context-aware, culturally grounded methodologies.

</details>


### [87] [Sycophancy Is Not One Thing: Causal Separation of Sycophantic Behaviors in LLMs](https://arxiv.org/abs/2509.21305)
*Daniel Vennemeyer,Phan Anh Duong,Tiffany Zhan,Tianyu Jiang*

Main category: cs.CL

TL;DR: 本文揭示了大语言模型中的阿谀奉承行为（赞同与表扬）是相互独立的，可以分别被控制，且在不同模型间表现一致，为理解和优化模型输出提供新思路。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）常表现出“阿谀奉承”行为，如过度赞同和讨好用户，但目前还不清楚这些行为是由统一机制还是多个独立过程驱动。作者希望揭示背后的机制，以便更好理解和控制这些模型的输出。

Method: 作者将阿谀奉承行为分解为“阿谀赞同”和“阿谀表扬”，并与“真正赞同”进行对比。使用均值差异方向、激活叠加和子空间几何等分析方法，在不同模型和数据集上进行实验。

Result: 研究发现：1）这三种行为在模型的潜在空间中是沿着不同线性方向编码的；2）每种行为可以独立被增强或抑制，而互不影响；3）这种表现结构在不同模型家族和规模上都一致。

Conclusion: 阿谀奉承行为对应于模型内部可以独立操控的、高度可分离的表征机制。

Abstract: Large language models (LLMs) often exhibit sycophantic behaviors -- such as
excessive agreement with or flattery of the user -- but it is unclear whether
these behaviors arise from a single mechanism or multiple distinct processes.
We decompose sycophancy into sycophantic agreement and sycophantic praise,
contrasting both with genuine agreement. Using difference-in-means directions,
activation additions, and subspace geometry across multiple models and
datasets, we show that: (1) the three behaviors are encoded along distinct
linear directions in latent space; (2) each behavior can be independently
amplified or suppressed without affecting the others; and (3) their
representational structure is consistent across model families and scales.
These results suggest that sycophantic behaviors correspond to distinct,
independently steerable representations.

</details>


### [88] [RLBFF: Binary Flexible Feedback to bridge between Human Feedback & Verifiable Rewards](https://arxiv.org/abs/2509.21319)
*Zhilin Wang,Jiaqi Zeng,Olivier Delalleau,Ellie Evans,Daniel Egert,Hoo-Chang Shin,Felipe Soares,Yi Dong,Oleksii Kuchaiev*

Main category: cs.CL

TL;DR: 本文提出RLBFF方法，从自然语言人类反馈提取可二元化原则结合规则验证，提高LLM奖励模型性能和灵活性，在多项基准上表现领先，方法和数据开源。


<details>
  <summary>Details</summary>
Motivation: 当前主流的大型语言模型（LLM）后训练强化学习方法如RLHF和RLVR各自有优缺点，RLHF可表达多样化偏好但易受可解释性和奖励黑客问题困扰，RLVR则局限于关注正确性。论文为解决这些挑战提出新方法。

Method: 提出了RLBFF方法，通过从自然语言反馈中提取可二元化原则（如信息准确性、代码可读性），将奖励模型训练转化为蕴涵任务。奖励模型既结合了人类偏好多样性又具备规则验证精度，并允许用户在推断时自定义关注原则。

Result: 实验表明，使用RLBFF训练的奖励模型在相同数据集下优于Bradley-Terry模型，并在RM-Bench（86.2%）和JudgeBench（81.4%，截至2025年9月排名第一）获得顶级表现。此外，基于RLBFF的Qwen3-32B对齐配方（含数据）完全开源，并在MT-Bench、WildBench、Arena Hard v2等通用对齐基准上达到或超越o3-mini与DeepSeek R1，仅用约5%的推理成本。

Conclusion: RLBFF方法将人类偏好多样性和规则验证相结合，显著提升奖励模型泛化性和表现，并提供可定制原则，推动LLM后训练强化学习技术发展。

Abstract: Reinforcement Learning with Human Feedback (RLHF) and Reinforcement Learning
with Verifiable Rewards (RLVR) are the main RL paradigms used in LLM
post-training, each offering distinct advantages. However, RLHF struggles with
interpretability and reward hacking because it relies on human judgments that
usually lack explicit criteria, whereas RLVR is limited in scope by its focus
on correctness-based verifiers. We propose Reinforcement Learning with Binary
Flexible Feedback (RLBFF), which combines the versatility of human-driven
preferences with the precision of rule-based verification, enabling reward
models to capture nuanced aspects of response quality beyond mere correctness.
RLBFF extracts principles that can be answered in a binary fashion (e.g.
accuracy of information: yes, or code readability: no) from natural language
feedback. Such principles can then be used to ground Reward Model training as
an entailment task (response satisfies or does not satisfy an arbitrary
principle). We show that Reward Models trained in this manner can outperform
Bradley-Terry models when matched for data and achieve top performance on
RM-Bench (86.2%) and JudgeBench (81.4%, #1 on leaderboard as of September 24,
2025). Additionally, users can specify principles of interest at inference time
to customize the focus of our reward models, in contrast to Bradley-Terry
models. Finally, we present a fully open source recipe (including data) to
align Qwen3-32B using RLBFF and our Reward Model, to match or exceed the
performance of o3-mini and DeepSeek R1 on general alignment benchmarks of
MT-Bench, WildBench, and Arena Hard v2 (at <5% of the inference cost).

</details>


### [89] [SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines](https://arxiv.org/abs/2509.21320)
*Yizhou Wang,Chen Tang,Han Deng,Jiabei Xiao,Jiaqi Liu,Jianyu Wu,Jun Yao,Pengze Li,Encheng Su,Lintao Wang,Guohang Zhuang,Yuchen Ren,Ben Fei,Ming Hu,Xin Chen,Dongzhan Zhou,Junjun He,Xiangyu Yue,Zhenfei Yin,Jiamin Wu,Qihao Zheng,Yuhao Zhou,Huihui Xu,Chenglong Ma,Yan Lu,Wenlong Zhang,Chunfeng Song,Philip Torr,Shixiang Tang,Xinzhu Ma,Wanli Ouyang,Lei Bai*

Main category: cs.CL

TL;DR: 本文提出了一种覆盖广泛科学任务、强化跨领域推理的科学推理基础模型，并通过多阶段训练和奖励机制提升模型泛化与忠实度，相关资源已开源。


<details>
  <summary>Details</summary>
Motivation: 现有模型在科学领域的推理与文本-科学表示对齐能力有限，作者期望开发一种能够更好处理跨领域、多格式、多任务的科学推理基础模型。

Method: 模型首先在包含科学文本、序列及其配对的2060亿token数据上预训练，随后通过4000万条指令SFT微调、冷启动逐步引导长链推理，以及带具体任务奖励函数的强化学习，逐步优化模型的推理和泛化能力。

Result: 模型涵盖了103项任务，包括文本与科学格式的准确互译、知识抽取、属性预测和分类以及序列生成设计等能力，显著提升了指令覆盖率、跨领域泛化和推理精准度。开放数据集和评估代码辅助科研应用。

Conclusion: 所提出的科学推理基础模型在多领域和多任务下表现出更广泛的适应性和更高的准确性，且提升了跨学科泛化能力。相关模型及数据集已经开源。

Abstract: We present a scientific reasoning foundation model that aligns natural
language with heterogeneous scientific representations. The model is pretrained
on a 206B-token corpus spanning scientific text, pure sequences, and
sequence-text pairs, then aligned via SFT on 40M instructions, annealed
cold-start bootstrapping to elicit long-form chain-of-thought, and
reinforcement learning with task-specific reward shaping, which instills
deliberate scientific reasoning. It supports four capability families, covering
up to 103 tasks across workflows: (i) faithful translation between text and
scientific formats, (ii) text/knowledge extraction, (iii) property prediction,
(iv) property classification, (v) unconditional and conditional sequence
generation and design. Compared with specialist systems, our approach broadens
instruction coverage, improves cross-domain generalization, and enhances
fidelity. We detail data curation and training and show that cross-discipline
learning strengthens transfer and downstream reliability. The model, instruct
tuning datasets and the evaluation code are open-sourced at
https://huggingface.co/SciReason and
https://github.com/open-sciencelab/SciReason.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [90] [An orderly algorithm for generation of Condorcet Domains](https://arxiv.org/abs/2509.20865)
*Bei Zhou,Klas Markström*

Main category: cs.DM

TL;DR: 本文提出了生成所有最大Condorcet域的高效算法，支持不同投票子类的扩展，并公开了工具与数据。


<details>
  <summary>Details</summary>
Motivation: Condorcet域在多数投票理论中非常重要，其中对于线性顺序的选择可避免循环与矛盾，但相关域的枚举和分类计算难度较高。

Method: 设计并实现了一种有序算法，能够生成所有非同构的最大Condorcet域，并可适配于不同子类。

Result: 扩展了相关域的枚举数据，并将实现和数据公开，为后续理论研究和实际应用提供了工具。

Conclusion: 提出了一个高效的算法，可生成所有非同构的最大Condorcet域，其结果在投票理论领域有重要价值。

Abstract: Condorcet domains are fundamental objects in the theory of majority voting;
they are sets of linear orders with the property that if every voter picks a
linear order from this set, assuming that the number of voters is odd, and
alternatives are ranked according to the pairwise majority ranking, then the
result is a linear order on the set of all alternatives. In this paper we
present an efficient orderly algorithm for the generation of all non-isomorphic
maximal Condorcet domains on $n$ alternatives. The algorithm can be adapted to
generate domains from various important subclasses of Condorcet domains. We use
an example implementation to extend existing enumerations of domains from
several such subclasses and make both data and the implementation publicly
available.

</details>
