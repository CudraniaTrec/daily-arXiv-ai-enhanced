{"id": "2512.02197", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02197", "abs": "https://arxiv.org/abs/2512.02197", "authors": ["Moussa Moussaoui", "Tarik Houichime", "Abdelalim Sadiq"], "title": "Bin2Vec: Interpretable and Auditable Multi-View Binary Analysis for Code Plagiarism Detection", "comment": null, "summary": "We introduce Bin2Vec, a new framework that helps compare software programs in a clear and explainable way. Instead of focusing only on one type of information, Bin2Vec combines what a program looks like (its built-in functions, imports, and exports) with how it behaves when it runs (its instructions and memory usage). This gives a more complete picture when deciding whether two programs are similar or not. Bin2Vec represents these different types of information as views that can be inspected separately using easy-to-read charts, and then brings them together into an overall similarity score. Bin2Vec acts as a bridge between binary representations and machine learning techniques by generating feature representations that can be efficiently processed by machine-learning models. We tested Bin2Vec on multiple versions of two well-known Windows programs, PuTTY and 7-Zip. The primary results strongly confirmed that our method compute an optimal and visualization-friendly representation of the analyzed software. For example, PuTTY versions showed more complex behavior and memory activity, while 7-Zip versions focused more on performance-related patterns. Overall, Bin2Vec provides decisions that are both reliable and explainable to humans. Because it is modular and easy to extend, it can be applied to tasks like auditing, verifying software origins, or quickly screening large numbers of programs in cybersecurity and reverse-engineering work.", "AI": {"tldr": "Bin2Vec\u6846\u67b6\u7ed3\u5408\u9759\u6001\u4e0e\u52a8\u6001\u7279\u5f81\uff0c\u5b9e\u73b0\u8f6f\u4ef6\u76f8\u4f3c\u6027\u53ef\u89c6\u5316\u548c\u673a\u5668\u5b66\u4e60\u8868\u793a\uff0c\u5b9e\u9a8c\u652f\u6301\u5176\u4f18\u8d8a\u6027\uff0c\u9002\u7528\u5b89\u5168\u5ba1\u8ba1\u3001\u6eaf\u6e90\u7b49\u591a\u79cd\u5b9e\u9645\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u8f6f\u4ef6\u76f8\u4f3c\u6027\u5206\u6790\u65b9\u6cd5\u5f80\u5f80\u53ea\u4fa7\u91cd\u5355\u4e00\u7ef4\u5ea6\uff0c\u7f3a\u4e4f\u5bf9\u8f6f\u4ef6\u884c\u4e3a\u7684\u5168\u9762\u3001\u53ef\u89e3\u91ca\u878d\u5408\u3002Bin2Vec\u65e8\u5728\u6539\u5584\u8fd9\u4e00\u4e0d\u8db3\uff0c\u4e3a\u5b89\u5168\u5ba1\u8ba1\u3001\u6eaf\u6e90\u548c\u81ea\u52a8\u5316\u7b5b\u9009\u63d0\u4f9b\u66f4\u5f3a\u7684\u6280\u672f\u652f\u6491\u3002", "method": "\u8be5\u6846\u67b6\u5c06\u8f6f\u4ef6\u7684\u9759\u6001\u4fe1\u606f\uff08\u5982\u5185\u7f6e\u51fd\u6570\u3001\u5bfc\u5165\u548c\u5bfc\u51fa\uff09\u4e0e\u52a8\u6001\u8fd0\u884c\u884c\u4e3a\uff08\u5982\u6307\u4ee4\u548c\u5185\u5b58\u7528\u6cd5\uff09\u878d\u5408\uff0c\u901a\u8fc7\u591a\u89c6\u56fe\u7279\u5f81\u63d0\u53d6\u5e76\u4ee5\u6613\u4e8e\u53ef\u89c6\u5316\u7684\u5f62\u5f0f\u5c55\u73b0\uff0c\u6700\u7ec8\u5408\u6210\u4e3a\u6574\u4f53\u76f8\u4f3c\u6027\u8bc4\u5206\uff0c\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u5728PuTTY\u548c7-Zip\u591a\u4e2a\u7248\u672c\u4e0a\u9a8c\u8bc1\u4e86Bin2Vec\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u4e0d\u540c\u8f6f\u4ef6\u5728\u884c\u4e3a\u548c\u5185\u5b58\u6d3b\u52a8\u4e0a\u7684\u53ef\u89c6\u5dee\u5f02\uff0c\u83b7\u5f97\u4e86\u4f18\u5316\u4e14\u6613\u4e8e\u89e3\u8bfb\u7684\u5206\u6790\u7ed3\u679c\uff0c\u5e76\u786e\u8ba4\u4e86\u65b9\u6cd5\u7684\u53ef\u62d3\u5c55\u6027\u3002", "conclusion": "Bin2Vec\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u5bf9\u4e8c\u8fdb\u5236\u8f6f\u4ef6\u7684\u53ef\u9760\u4e14\u53ef\u89e3\u91ca\u7684\u76f8\u4f3c\u6027\u8bc4\u4f30\uff0c\u5e76\u4e14\u9002\u7528\u4e8e\u591a\u79cd\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2512.02329", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.02329", "abs": "https://arxiv.org/abs/2512.02329", "authors": ["Hoa Khanh Dam", "Geeta Mahala", "Rashina Hoda", "Xi Zheng", "Cristina Conati"], "title": "Towards autonomous normative multi-agent systems for Human-AI software engineering teams", "comment": null, "summary": "This paper envisions a transformative paradigm in software engineering, where Artificial Intelligence, embodied in fully autonomous agents, becomes the primary driver of the core software development activities. We introduce a new class of software engineering agents, empowered by Large Language Models and equipped with beliefs, desires, intentions, and memory to enable human-like reasoning. These agents collaborate with humans and other agents to design, implement, test, and deploy software systems with a level of speed, reliability, and adaptability far beyond the current software development processes. Their coordination and collaboration are governed by norms expressed as deontic modalities - commitments, obligations, prohibitions and permissions - that regulate interactions and ensure regulatory compliance. These innovations establish a scalable, transparent and trustworthy framework for future Human-AI software engineering teams.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8d4b\u4e88AI\u4ee3\u7406\u4eba\u7c7b\u4f3c\u4eba\u7c7b\u8ba4\u77e5\u4e0e\u534f\u4f5c\u89c4\u8303\u7684\u65b0\u8303\u5f0f\uff0c\u4f7f\u5176\u6210\u4e3a\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\u7684\u4e3b\u5bfc\u8005\uff0c\u5927\u5e45\u63d0\u5347\u9879\u76ee\u901f\u5ea6\u4e0e\u8d28\u91cf\uff0c\u5b9e\u73b0\u53ef\u4fe1\u8d56\u7684\u672a\u6765\u4eba\u673a\u8f6f\u4ef6\u5de5\u7a0b\u56e2\u961f\u3002", "motivation": "\u73b0\u6709\u7684\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u5728\u901f\u5ea6\u3001\u53ef\u9760\u6027\u548c\u9002\u5e94\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002\u501f\u52a9AI\u53ef\u4ee5\u5e26\u6765\u7a81\u7834\u6027\u7684\u8f6c\u53d8\uff0c\u4f46\u4eba\u673a\u534f\u4f5c\u3001AI\u80fd\u529b\u548c\u5408\u89c4\u6027\u4ecd\u9762\u4e34\u6311\u6218\u3002\u8be5\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u5168\u65b0\u7684\u8f6f\u4ef6\u5de5\u7a0b\u8303\u5f0f\uff0c\u5229\u7528\u5148\u8fdbAI\u63a8\u52a8\u6838\u5fc3\u5f00\u53d1\u6d3b\u52a8\u3002", "method": "\u63d0\u51fa\u5e76\u8bbe\u8ba1\u4e86\u4e00\u7c7b\u65b0\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\uff08\u4ee3\u7406\u4eba\uff09\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u8d4b\u4e88\u5176\u4fe1\u5ff5\u3001\u6b32\u671b\u3001\u610f\u56fe\u548c\u8bb0\u5fc6\uff0c\u4f7f\u5176\u5177\u5907\u7c7b\u4eba\u63a8\u7406\u80fd\u529b\u3002\u4ee3\u7406\u4eba\u4e4b\u95f4\u53ca\u4e0e\u4eba\u7c7b\u534f\u4f5c\uff0c\u901a\u8fc7\u89c4\u8303\uff08\u7531\u627f\u8bfa\u3001\u4e49\u52a1\u3001\u7981\u6b62\u548c\u5141\u8bb8\u7b49\u6a21\u6001\u8868\u8fbe\uff09\u8fdb\u884c\u534f\u8c03\uff0c\u786e\u4fdd\u5f00\u53d1\u6d41\u7a0b\u5408\u89c4\u3002", "result": "\u8fd9\u4e9b\u5177\u5907\u9ad8\u7ea7\u8ba4\u77e5\u548c\u89c4\u8303\u534f\u540c\u80fd\u529b\u7684AI\u4ee3\u7406\u4eba\u80fd\u4e0e\u4eba\u7c7b\u548c\u5176\u4ed6\u4ee3\u7406\u4eba\u9ad8\u6548\u534f\u4f5c\u5f00\u5c55\u8f6f\u4ef6\u8bbe\u8ba1\u3001\u5b9e\u73b0\u3001\u6d4b\u8bd5\u548c\u90e8\u7f72\uff0c\u663e\u8457\u63d0\u5347\u5f00\u53d1\u901f\u5ea6\u3001\u53ef\u9760\u6027\u548c\u9002\u5e94\u6027\u3002\u5728\u56e2\u961f\u89c4\u6a21\u3001\u534f\u4f5c\u900f\u660e\u6027\u548c\u53ef\u4fe1\u6027\u65b9\u9762\u5e26\u6765\u7a81\u7834\u3002", "conclusion": "\u5229\u7528\u5177\u5907\u4eba\u7c7b\u601d\u7ef4\u7279\u5f81\u548c\u5408\u89c4\u4ea4\u4e92\u7684AI\u4ee3\u7406\u4eba\uff0c\u63a8\u52a8\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u9769\u65b0\uff0c\u5b9e\u73b0\u66f4\u52a0\u667a\u80fd\u3001\u9ad8\u6548\u3001\u53ef\u9760\u4e14\u53ef\u4fe1\u8d56\u7684\u4eba\u673a\u534f\u540c\u5f00\u53d1\u4f53\u7cfb\u3002"}}
{"id": "2512.02393", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.02393", "abs": "https://arxiv.org/abs/2512.02393", "authors": ["Shuyang Liu", "Yang Chen", "Rahul Krishna", "Saurabh Sinha", "Jatin Ganhotra", "Reyhan Jabbarvand"], "title": "Process-Centric Analysis of Agentic Software Systems", "comment": null, "summary": "Agentic systems are modern software systems: they consist of orchestrated modules, expose interfaces, and are deployed in software pipelines. Unlike conventional programs, their execution (i.e., trajectories) is inherently stochastic and adaptive to the problem they are solving. Evaluation of such systems is often outcome-centric, judging their performance based on success or failure at the final step. This narrow focus overlooks detailed insights about such systems, failing to explain how agents reason, plan, act, or change their strategies over time. Inspired by the structured representation of conventional software systems as graphs, we introduce Graphectory to systematically encode the temporal and semantic relations in such software systems. Graphectory facilitates the design of process-centric metrics and analyses to assess the quality of agentic workflows independent of final success.\n  Using Graphectory, we analyze 4000 trajectories of two dominant agentic programming workflows, namely SWE-agent and OpenHands, with a combination of four backbone Large Language Models (LLMs), attempting to resolve SWE-bench Verified issues. Our fully automated analyses reveal that: (1) agents using richer prompts or stronger LLMs exhibit more complex Graphectory, reflecting deeper exploration, broader context gathering, and more thorough validation before patch submission; (2) agents' problem-solving strategies vary with both problem difficulty and the underlying LLM -- for resolved issues, the strategies often follow coherent localization-patching-validation steps, while unresolved ones exhibit chaotic, repetitive, or backtracking behaviors; (3) even when successful, agentic programming systems often display inefficient processes, leading to unnecessarily prolonged trajectories.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGraphectory\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u548c\u8bc4\u4f30\u667a\u80fd\u4f53\u7cfb\u7edf\u884c\u4e3a\u8fc7\u7a0b\uff0c\u5bf9\u6bd4\u4e0d\u540c\u6a21\u578b\u548c\u63d0\u793a\u6761\u4ef6\u3001\u6d41\u7a0b\u590d\u6742\u5ea6\u548c\u6548\u7387\uff0c\u63ed\u793a\u73b0\u6709\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u8fc7\u7a0b\u5c42\u9762\u5b58\u5728\u7684\u95ee\u9898\uff0c\u6bd4\u4f20\u7edf\u4ec5\u770b\u7ed3\u679c\u7684\u8bc4\u4f30\u66f4\u52a0\u7ec6\u81f4\u548c\u5168\u9762\u3002", "motivation": "\u76ee\u524d\u5bf9\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u8bc4\u4f30\u8fc7\u4e8e\u6ce8\u91cd\u7ed3\u679c\uff0c\u5ffd\u89c6\u4e86\u6267\u884c\u8fc7\u7a0b\u4e2d\u7684\u51b3\u7b56\u3001\u8ba1\u5212\u4e0e\u884c\u4e3a\u53d8\u5316\uff0c\u7f3a\u4e4f\u8fc7\u7a0b\u5c42\u9762\u7684\u8d28\u91cf\u5206\u6790\u65b9\u6cd5\u3002\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u5dee\u8ddd\uff0c\u7cfb\u7edf\u6027\u3001\u53ef\u89e3\u91ca\u6027\u5730\u523b\u753b\u548c\u8bc4\u4f30\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u884c\u4e3a\u4e0e\u6d41\u7a0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGraphectory\u7684\u65b0\u578b\u56fe\u7ed3\u6784\uff0c\u7cfb\u7edf\u6027\u5730\u7f16\u7801\u5e76\u5206\u6790\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u65f6\u5e8f\u4e0e\u8bed\u4e49\u5173\u7cfb\u3002\u5229\u7528Graphectory\uff0c\u5bf94000\u6761SWE-agent\u4e0eOpenHands\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u8f68\u8ff9\u8fdb\u884c\u4e86\u81ea\u52a8\u5316\u5206\u6790\uff0c\u7ed3\u54084\u79cd\u4e3b\u6d41\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u8bc4\u4f30\u5176\u5728SWE-bench\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e0e\u8fc7\u7a0b\u7279\u5f81\u3002", "result": "\u53d1\u73b0\u63d0\u793a\u66f4\u4e30\u5bcc\u6216\u6a21\u578b\u66f4\u5f3a\u5927\u7684\u667a\u80fd\u4f53\u4f1a\u5c55\u73b0\u51fa\u66f4\u590d\u6742\u4e14\u9ad8\u6548\u7684\u6d41\u7a0b\u7ed3\u6784\uff0c\u5177\u5907\u66f4\u6df1\u5165\u7684\u63a2\u7d22\u548c\u66f4\u5168\u9762\u7684\u9a8c\u8bc1\u73af\u8282\uff1b\u89e3\u51b3\u96be\u9898\u6216\u8005\u5e95\u5c42\u6a21\u578b\u80fd\u529b\u4e0d\u540c\u4f1a\u5bfc\u81f4\u667a\u80fd\u4f53\u91c7\u7528\u4e0d\u540c\u6d41\u7a0b\u7b56\u7565\uff1b\u5373\u4fbf\u4efb\u52a1\u6210\u529f\uff0c\u8bb8\u591a\u667a\u80fd\u4f53\u6d41\u7a0b\u4ecd\u6709\u4f4e\u6548\u3001\u5197\u957f\u7684\u95ee\u9898\u3002", "conclusion": "\u57fa\u4e8eGraphectory\u5206\u6790\uff0c\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u95ee\u9898\u89e3\u51b3\u8fc7\u7a0b\u4e2d\uff0c\u5373\u4f7f\u53d6\u5f97\u6210\u529f\uff0c\u4f9d\u7136\u53ef\u80fd\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u548c\u6d41\u7a0b\u5197\u957f\u7684\u95ee\u9898\u3002\u4e0d\u540c\u6a21\u578b\u548c\u63d0\u793a\u7684\u590d\u6742\u5ea6\u5bf9\u667a\u80fd\u4f53\u7684\u63a2\u7d22\u6df1\u5ea6\u3001\u95ee\u9898\u7b56\u7565\u548c\u8f68\u8ff9\u7ed3\u6784\u6709\u663e\u8457\u5f71\u54cd\u3002\u4f20\u7edf\u4ee5\u7ed3\u679c\u4e3a\u4e2d\u5fc3\u7684\u8bc4\u4f30\u6307\u6807\u4f4e\u4f30\u4e86\u6d41\u7a0b\u4e2d\u53d1\u751f\u7684\u590d\u6742\u667a\u80fd\u884c\u4e3a\u3002"}}
{"id": "2512.02567", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02567", "abs": "https://arxiv.org/abs/2512.02567", "authors": ["Martin Weiss", "Jesko Hecking-Harbusch", "Jochen Quante", "Matthias Woehrle"], "title": "Feedback Loops and Code Perturbations in LLM-based Software Engineering: A Case Study on a C-to-Rust Translation System", "comment": "10 pages, 9 figures", "summary": "The advent of strong generative AI has a considerable impact on various software engineering tasks such as code repair, test generation, or language translation. While tools like GitHub Copilot are already in widespread use in interactive settings, automated approaches require a higher level of reliability before being usable in industrial practice. In this paper, we focus on three aspects that directly influence the quality of the results: a) the effect of automated feedback loops, b) the choice of Large Language Model (LLM), and c) the influence of behavior-preserving code changes.\n  We study the effect of these three variables on an automated C-to-Rust translation system. Code translation from C to Rust is an attractive use case in industry due to Rust's safety guarantees. The translation system is based on a generate-and-check pattern, in which Rust code generated by the LLM is automatically checked for compilability and behavioral equivalence with the original C code. For negative checking results, the LLM is re-prompted in a feedback loop to repair its output. These checks also allow us to evaluate and compare the respective success rates of the translation system when varying the three variables.\n  Our results show that without feedback loops LLM selection has a large effect on translation success. However, when the translation system uses feedback loops the differences across models diminish. We observe this for the average performance of the system as well as its robustness under code perturbations. Finally, we also identify that diversity provided by code perturbations can even result in improved system performance.", "AI": {"tldr": "\u81ea\u52a8\u53cd\u9988\u73af\u548c\u4ee3\u7801\u6270\u52a8\u63d0\u5347\u4e86C\u5230Rust\u7ffb\u8bd1\u7684\u81ea\u52a8\u7cfb\u7edf\u6027\u80fd\uff0c\u4e0d\u540c\u5927\u6a21\u578b\u7684\u8868\u73b0\u5dee\u8ddd\u968f\u7740\u53cd\u9988\u589e\u52a0\u800c\u53d8\u5c0f\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u4ee3\u7801\u751f\u6210\u3001\u7ffb\u8bd1\u5de5\u5177\u9700\u66f4\u9ad8\u53ef\u9760\u6027\u624d\u53ef\u5e94\u7528\u4e8e\u5de5\u4e1a\u9886\u57df\uff0c\u81ea\u52a8\u53cd\u9988\u673a\u5236\u3001LLM\u6a21\u578b\u9009\u62e9\u3001\u4ee5\u53ca\u4ee3\u7801\u5e72\u6270\u5bf9\u81ea\u52a8\u5316\u7cfb\u7edf\u5b9e\u9645\u8868\u73b0\u5f71\u54cd\u672a\u660e\uff0c\u9700\u6df1\u5165\u5b9e\u9a8c\u6d4b\u8bc4\u3002", "method": "\u57fa\u4e8e\u751f\u6210\u4e0e\u6821\u9a8c\u7684\u81ea\u52a8\u7ffb\u8bd1\u7cfb\u7edf\uff0c\u81ea\u52a8\u68c0\u6d4bLLM\u751f\u6210\u7684Rust\u4ee3\u7801\u80fd\u5426\u901a\u8fc7\u7f16\u8bd1\u5e76\u884c\u4e3a\u7b49\u4ef7\u4e8e\u539fC\u4ee3\u7801\uff0c\u8d1f\u9762\u7ed3\u679c\u89e6\u53d1LLM\u53cd\u9988\u4fee\u590d\uff0c\u7cfb\u7edf\u5728\u4e0d\u540cLLM\u3001\u53cd\u9988\u73af\u6570\u3001\u4ee3\u7801\u6270\u52a8\u7b49\u8bbe\u5b9a\u4e0b\u8fdb\u884c\u591a\u7ec4\u5b9e\u9a8c\u5bf9\u6bd4\u3002", "result": "a) \u4e0d\u7528\u53cd\u9988\u73af\u65f6\uff0cLLM\u5dee\u5f02\u5bf9\u7ffb\u8bd1\u6210\u529f\u7387\u5f71\u54cd\u5927\uff1bb) \u52a0\u5165\u53cd\u9988\u73af\u540e\uff0c\u4e0d\u540cLLM\u8868\u73b0\u5dee\u8ddd\u7f29\u5c0f\uff1bc) \u4ee3\u7801\u6270\u52a8\u63d0\u5347\u4e86\u7cfb\u7edf\u591a\u6837\u6027\u5e76\u53ef\u5e26\u6765\u66f4\u597d\u7684\u603b\u4f53\u8868\u73b0\u3002", "conclusion": "\u5f15\u5165\u81ea\u52a8\u5316\u53cd\u9988\u73af\u8282\u540e\uff0cC\u5230Rust\u81ea\u52a8\u7ffb\u8bd1\u7cfb\u7edf\u5728\u4e0d\u540c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e4b\u95f4\u7684\u8868\u73b0\u5dee\u8ddd\u663e\u8457\u51cf\u5c11\uff0c\u7cfb\u7edf\u6574\u4f53\u6027\u80fd\u548c\u9c81\u68d2\u6027\u63d0\u5347\u3002\u540c\u65f6\uff0c\u4ee3\u7801\u6270\u52a8\u5e26\u6765\u7684\u591a\u6837\u6027\u8fd8\u53ef\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u7cfb\u7edf\u8868\u73b0\u3002"}}
{"id": "2512.02873", "categories": ["cs.FL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.02873", "abs": "https://arxiv.org/abs/2512.02873", "authors": ["Luca Di Stefano"], "title": "Symbolic \u03c9-automata with obligations", "comment": "15 pages. Under review. For associated tool, see https://github.com/lou1306/hoapp", "summary": "Extensions of \u03c9-automata to infinite alphabets typically rely on symbolic guards to keep the transition relation finite, and on registers or memory cells to preserve information from past symbols. Symbolic transitions alone are ill-suited to act on this information, and register automata have intricate formal semantics and issues with tractability. We propose a slightly different approach based on obligations, i.e., assignment-like constructs attached to transitions. Whenever a transition with an obligation is taken, the obligation is evaluated against the current symbol and yields a constraint on the next symbol that the automaton will read. We formalize obligation automata with existential and universal branching and Emerson-Lei acceptance conditions, which subsume classic families such as B\u00fcchi, Rabin, Strett, and parity automata. We show that these automata recognise a strict superset of \u03c9-regular languages. To illustrate the practicality of our proposal, we also introduce a machine-readable format to express obligation automata and describe a tool implementing several operations over them, including automata product and emptiness checking.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faobligation\u81ea\u52a8\u673a\u6765\u63d0\u5347\u5904\u7406\u65e0\u9650\u5b57\u6bcd\u8868\u7684\u80fd\u529b\uff0c\u6a21\u578b\u6bd4\u73b0\u6709\u81ea\u52a8\u673a\u66f4\u7b80\u4fbf\u4e14\u8868\u8fbe\u529b\u66f4\u5f3a\uff0c\u5e76\u53ef\u901a\u8fc7\u76f8\u5173\u5de5\u5177\u8fdb\u884c\u81ea\u52a8\u5316\u64cd\u4f5c\u3002", "motivation": "\u89e3\u51b3\u9762\u5bf9\u65e0\u9650\u5b57\u6bcd\u8868\u65f6\uff0c\u73b0\u6709\u03c9-\u81ea\u52a8\u673a\u5982\u7b26\u53f7\u5316\u8dc3\u8fc1\u548c\u5bc4\u5b58\u5668\u81ea\u52a8\u673a\u5728\u4fe1\u606f\u5904\u7406\u548c\u53ef\u5b9e\u73b0\u6027\u4e0a\u7684\u4e0d\u8db3\u3002", "method": "\u7ed3\u5408\u5b58\u5728\u4e0e\u5168\u79f0\u5206\u652f\u53caEmerson-Lei\u63a5\u53d7\u6761\u4ef6\uff0c\u5f62\u5f0f\u5316obligation\u81ea\u52a8\u673a\uff0c\u5e76\u5f00\u53d1\u4e86\u5bf9\u5e94\u7684\u64cd\u4f5c\u5de5\u5177\u3002", "result": "\u8bc1\u660eobligation\u81ea\u52a8\u673a\u80fd\u8986\u76d6B\u00fcchi\u3001Rabin\u3001Strett\u548cparity\u81ea\u52a8\u673a\u7b49\u7ecf\u5178\u6a21\u578b\uff0c\u5e76\u8bc6\u522b\u66f4\u5e7f\u6cdb\u7684\u8bed\u8a00\uff1b\u5b9e\u73b0\u4e86\u76f8\u5173\u81ea\u52a8\u673a\u64cd\u4f5c\u5de5\u5177\u3002", "conclusion": "\u63d0\u51fa\u4e86\u57fa\u4e8eobligation\u7684\u81ea\u52a8\u673a\u6a21\u578b\uff0c\u5e76\u8bf4\u660e\u8be5\u6a21\u578b\u80fd\u8bc6\u522b\u4e25\u683c\u8d85\u51fa\u03c9-\u6b63\u5219\u8bed\u8a00\u7684\u8bed\u8a00\u7c7b\u522b\uff0c\u5177\u6709\u7406\u8bba\u548c\u5b9e\u9645\u5e94\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.02371", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2512.02371", "abs": "https://arxiv.org/abs/2512.02371", "authors": ["Yihong Zhang", "Derek Gerstmann", "Andrew Adams", "Maaz Bin Safeer Ahmad"], "title": "Pushing Tensor Accelerators Beyond MatMul in a User-Schedulable Language", "comment": "CGO 2026", "summary": "Tensor accelerators now represent a growing share of compute resources in modern CPUs and GPUs. However, they are hard to program, leading developers to use vendor-provided kernel libraries that support tensor accelerators. As a result, the usage of tensor accelerators is limited to the provided interface, mainly designed for traditional ML and scientific computing workloads.\n  In this paper, we show that tensor accelerators can improve the performance of applications beyond simple variants of MatMul. For example, many image processing pipelines are linear transformations over matrices in disguise and can therefore utilize such specialized hardware. This is nonetheless hindered by the difficulties in programming tensor accelerators. We tackle this problem with compiler-based techniques. We use the Halide user-schedulable language and express operations as Halide algorithms succinctly. To this end, we implement a flexible tensor instruction selector based on equality saturation. The tensor instruction selector supports both CPU- and GPU-attached tensor accelerators and works with existing scheduling operations (e.g., producer-consumer fusion). Together, this enables developers to write diverse accelerator-leveraging applications in a few dozen lines.\n  Using our system, we demonstrate the potential of tensor accelerators beyond their traditional domains. We implement several image processing pipelines (e.g., filtering, resampling, and denoising) in our system and evaluate them against non-accelerator-leveraging baselines. We show that these pipelines can achieve significant speedups. For example, a downsampling routine is sped up by $6.1\\times$ by utilizing Tensor Cores on an Nvidia RTX 4070 GPU.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7f16\u8bd1\u5668\u65b9\u6cd5\uff0c\u663e\u8457\u7b80\u5316\u4e86\u5f20\u91cf\u52a0\u901f\u5668\u7684\u7f16\u7a0b\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u56fe\u50cf\u5904\u7406\u7b49\u9886\u57df\uff0c\u5b9e\u73b0\u4e86\u6700\u9ad86.1\u500d\u7684\u6027\u80fd\u63d0\u5347\uff0c\u62d3\u5c55\u4e86\u52a0\u901f\u5668\u7684\u4f7f\u7528\u573a\u666f\u3002", "motivation": "\u5f20\u91cf\u52a0\u901f\u5668\u5728\u73b0\u4ee3CPU\u548cGPU\u4e2d\u7684\u6bd4\u91cd\u4e0d\u65ad\u589e\u52a0\uff0c\u4f46\u7531\u4e8e\u7f16\u7a0b\u590d\u6742\uff0c\u5f00\u53d1\u8005\u4e3b\u8981\u4f9d\u8d56\u5382\u5546\u63d0\u4f9b\u7684\u5e93\uff0c\u4f7f\u7528\u8303\u56f4\u53d7\u5230\u9650\u5236\uff0c\u4ec5\u9650\u4e8e\u9762\u5411\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u79d1\u5b66\u8ba1\u7b97\u5de5\u4f5c\u8d1f\u8f7d\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8e\u7f16\u8bd1\u5668\u7684\u6280\u672f\uff0c\u5229\u7528Halide\u8c03\u5ea6\u8bed\u6cd5\u8868\u8fbe\u64cd\u4f5c\uff0c\u5e76\u5b9e\u73b0\u4e86\u57fa\u4e8e\u7b49\u5f0f\u9971\u548c\u5ea6\uff08equality saturation\uff09\u7684\u7075\u6d3b\u5f20\u91cf\u6307\u4ee4\u9009\u62e9\u5668\uff0c\u652f\u6301CPU\u548cGPU\u4e0a\u7684\u5f20\u91cf\u52a0\u901f\u5668\uff0c\u4e0e\u73b0\u6709\u7684\u8c03\u5ea6\u64cd\u4f5c\u517c\u5bb9\uff0c\u65b9\u4fbf\u5f00\u53d1\u8005\u9ad8\u6548\u7f16\u5199\u591a\u6837\u5316\u52a0\u901f\u5668\u5e94\u7528\u3002", "result": "\u901a\u8fc7\u7cfb\u7edf\u5b9e\u73b0\u591a\u79cd\u56fe\u50cf\u5904\u7406\u7ba1\u7ebf\uff08\u5982\u6ee4\u6ce2\u3001\u91cd\u91c7\u6837\u548c\u53bb\u566a\uff09\uff0c\u5e76\u4e0e\u975e\u52a0\u901f\u57fa\u7ebf\u8fdb\u884c\u5bf9\u6bd4\uff0c\u7ed3\u679c\u663e\u793a\u663e\u8457\u63d0\u901f\uff0c\u5982\u5728Nvidia RTX 4070 GPU\u5229\u7528Tensor Cores\u5bf9\u4e0b\u91c7\u6837\u4f8b\u7a0b\u52a0\u901f6.1\u500d\u3002", "conclusion": "\u5f20\u91cf\u52a0\u901f\u5668\u4e0d\u4ec5\u9002\u7528\u4e8e\u4f20\u7edf\u77e9\u9635\u4e58\u6cd5\u4e0e\u673a\u5668\u5b66\u4e60\u5e94\u7528\uff0c\u501f\u52a9\u672c\u6587\u63d0\u51fa\u7684\u7f16\u8bd1\u5668\u7ea7\u522b\u65b9\u6cd5\uff0c\u53ef\u5927\u5e45\u62d3\u5c55\u5f20\u91cf\u52a0\u901f\u5668\u5728\u56fe\u50cf\u5904\u7406\u7b49\u9886\u57df\u7684\u5e94\u7528\u8303\u56f4\u5e76\u83b7\u53d6\u8f83\u9ad8\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2512.02024", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.02024", "abs": "https://arxiv.org/abs/2512.02024", "authors": ["Yan Yang", "Mouxiao Bian", "Peiling Li", "Bingjian Wen", "Ruiyao Chen", "Kangkun Mao", "Xiaojun Ye", "Tianbin Li", "Pengcheng Chen", "Bing Han", "Jie Xu", "Kaifeng Qiu", "Junyan Wu"], "title": "Human-Level and Beyond: Benchmarking Large Language Models Against Clinical Pharmacists in Prescription Review", "comment": null, "summary": "The rapid advancement of large language models (LLMs) has accelerated their integration into clinical decision support, particularly in prescription review. To enable systematic and fine-grained evaluation, we developed RxBench, a comprehensive benchmark that covers common prescription review categories and consolidates 14 frequent types of prescription errors drawn from authoritative pharmacy references. RxBench consists of 1,150 single-choice, 230 multiple-choice, and 879 short-answer items, all reviewed by experienced clinical pharmacists. We benchmarked 18 state-of-the-art LLMs and identified clear stratification of performance across tasks. Notably, Gemini-2.5-pro-preview-05-06, Grok-4-0709, and DeepSeek-R1-0528 consistently formed the first tier, outperforming other models in both accuracy and robustness. Comparisons with licensed pharmacists indicated that leading LLMs can match or exceed human performance in certain tasks. Furthermore, building on insights from our benchmark evaluation, we performed targeted fine-tuning on a mid-tier model, resulting in a specialized model that rivals leading general-purpose LLMs in performance on short-answer question tasks. The main contribution of RxBench lies in establishing a standardized, error-type-oriented framework that not only reveals the capabilities and limitations of frontier LLMs in prescription review but also provides a foundational resource for building more reliable and specialized clinical tools.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRxBench\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e8618\u4e2a\u8bed\u8a00\u6a21\u578b\u5728\u836f\u7269\u5904\u65b9\u5ba1\u6838\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u90e8\u5206\u6a21\u578b\u5df2\u4f18\u4e8e\u836f\u5e08\uff0c\u4e14\u57fa\u51c6\u53ef\u52a9\u529b\u5f00\u53d1\u66f4\u4e13\u7528\u4e34\u5e8aAI\u5de5\u5177\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\uff0c\u5c24\u5176\u662f\u5904\u65b9\u5ba1\u6838\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u548c\u7ec6\u81f4\u5316\u7684\u8bc4\u4f30\u5de5\u5177\u3002\u672c\u6587\u4e3a\u6b64\u5f00\u53d1\u5e76\u63d0\u51faRxBench\uff0c\u4ee5\u6807\u51c6\u5316\u3001\u7ec6\u5206\u5904\u65b9\u9519\u8bef\u7c7b\u578b\uff0c\u4e3a\u6a21\u578b\u8bc4\u4f30\u548c\u4e13\u7528\u5de5\u5177\u5f00\u53d1\u63d0\u4f9b\u57fa\u7840\u3002", "method": "\u6784\u5efa\u4e86\u8986\u76d6\u5e38\u89c1\u5904\u65b9\u5ba1\u6838\u7c7b\u522b\u7684RxBench\u57fa\u51c6\uff0c\u6db5\u76d614\u79cd\u5e38\u89c1\u5904\u65b9\u9519\u8bef\u7c7b\u578b\u3002\u9898\u5e93\u5305\u62ec\u5355\u9879\u9009\u62e9\u9898\u3001\u591a\u9879\u9009\u62e9\u9898\u548c\u7b80\u7b54\u9898\u5e76\u7531\u4e34\u5e8a\u836f\u5e08\u5ba1\u6838\u3002\u57fa\u4e8eRxBench\u8bc4\u6d4b\u4e8618\u79cd\u6700\u5148\u8fdbLLM\uff0c\u5e76\u5bf9\u8868\u73b0\u8fdb\u884c\u4e86\u5206\u5c42\u5206\u6790\u3002\u6bd4\u8f83LLMs\u4e0e\u836f\u5e08\u5b9e\u9645\u8868\u73b0\uff0c\u5e76\u9488\u5bf9\u4e2d\u95f4\u5c42\u6a21\u578b\u8fdb\u884c\u4e86\u5fae\u8c03\u3002", "result": "Gemini-2.5-pro-preview-05-06\u3001Grok-4-0709\u548cDeepSeek-R1-0528\u7b49\u6a21\u578b\u5728\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u53ef\u4e0e\u836f\u5e08\u5ab2\u7f8e\u751a\u81f3\u8d85\u8fc7\u3002\u5fae\u8c03\u540e\u7684\u4e2d\u5c42\u6a21\u578b\u5728\u7b80\u7b54\u9898\u4efb\u52a1\u4e0a\u8868\u73b0\u63a5\u8fd1\u9876\u5c16\u901a\u7528\u6a21\u578b\u3002", "conclusion": "RxBench\u5960\u5b9a\u4e86\u9762\u5411\u5904\u65b9\u9519\u8bef\u7c7b\u578b\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u524d\u6cbfLLMs\u5728\u4e34\u5e8a\u5904\u65b9\u5ba1\u6838\u80fd\u529b\u548c\u5c40\u9650\uff0c\u4e3a\u5f00\u53d1\u66f4\u53ef\u9760\u3001\u4e13\u4e1a\u7684\u4e34\u5e8a\u5de5\u5177\u63d0\u4f9b\u57fa\u7840\u8d44\u6e90\u3002"}}
{"id": "2512.02617", "categories": ["cs.LO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2512.02617", "abs": "https://arxiv.org/abs/2512.02617", "authors": ["Rutger Campbell", "Noleen K\u00f6hler"], "title": "The role of counting quantifiers in laminar set systems", "comment": "19 pages, 3 figures", "summary": "Laminar set systems consist of non-crossing subsets of a universe with set inclusion essentially corresponding to the descendant relationship of a tree, the so-called laminar tree. Laminar set systems lie at the core of many graph decompositions such as modular decompositions, split decompositions, and bi-join decompositions. We show that from a laminar set system we can obtain the corresponding laminar tree by means of a monadic second order logic (MSO) transduction. This resolves an open question originally asked by Courcelle and is a satisfying resolution as MSO is the natural logic for set systems and is sufficient to define the property ``laminar''. Using results from Campbell et al. [STACS 2025], we can now obtain transductions for obtaining modular decompositions, co-trees, split decompositions and bi-join decompositions using MSO instead of CMSO. We further gain some insight into the expressive power of counting quantifiers and provide some results towards determining when counting quantifiers can be simulated in MSO in laminar set systems and when they cannot.", "AI": {"tldr": "\u672c\u8bba\u6587\u8bc1\u660e\u5229\u7528\u5355\u4e00\u7684MSO\u903b\u8f91\u5373\u53ef\u5b8c\u6210\u5c42\u72b6\u96c6\u7cfb\u7edf\u4e0e\u5c42\u72b6\u6811\u8f6c\u6362\uff0c\u4fc3\u8fdb\u4e86\u56fe\u5206\u89e3\u7406\u8bba\u7684\u7b80\u5316\uff0c\u540c\u65f6\u5bf9MSO\u80fd\u5426\u6a21\u62df\u8ba1\u6570\u91cf\u8bcd\u505a\u4e86\u6df1\u5165\u63a2\u8ba8\uff0c\u5bf9\u56fe\u7b97\u6cd5\u548c\u903b\u8f91\u9886\u57df\u6709\u79ef\u6781\u63a8\u52a8\u4f5c\u7528\u3002", "motivation": "\u5c42\u72b6\u96c6\u7cfb\u7edf\u662f\u8bb8\u591a\u56fe\u5206\u89e3\uff08\u5982\u6a21\u5206\u89e3\u3001\u5206\u88c2\u5206\u89e3\u3001\u53cc\u8fde\u63a5\u5206\u89e3\u7b49\uff09\u7684\u57fa\u7840\u7ed3\u6784\u3002\u8fc7\u53bb\u76f8\u5173\u5206\u89e3\u901a\u5e38\u4f9d\u8d56\u66f4\u590d\u6742\u7684\u903b\u8f91\u5982CMSO\uff0c\u800cMSO\u66f4\u52a0\u81ea\u7136\u4e14\u5145\u5206\uff0c\u56e0\u800c\u7814\u7a76\u5176\u8868\u8fbe\u548c\u6784\u9020\u80fd\u529b\u5bf9\u4e8e\u7406\u8bba\u548c\u5e94\u7528\u90fd\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u4e3b\u8981\u65b9\u6cd5\u662f\u5229\u7528\u4e00\u9636\u7edf\u8ba1\u7b97\u672f\u5f52\u7eb3\u903b\u8f91\uff08MSO transduction\uff09\u4ece\u5c42\u72b6\u96c6\u7cfb\u7edf\u6784\u9020\u5176\u5bf9\u5e94\u5c42\u72b6\u6811\uff0c\u5e76\u7ed3\u5408\u5df2\u6709\u5de5\u5177\u63a8\u5e7fMSO\u5728\u56fe\u5206\u89e3\u9886\u57df\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u4f5c\u8005\u8bc1\u660e\u4e86\u53ef\u4ee5\u7528MSO\u903b\u8f91\u5b8c\u6210\u4ece\u5c42\u72b6\u96c6\u7cfb\u7edf\u5230\u5c42\u72b6\u6811\u7684\u8f6c\u6362\uff0c\u5e76\u4f9d\u6258\u8fd1\u671f\u7ed3\u679c\u53ef\u4ee5\u5b9e\u73b0\u4f20\u7edf\u5206\u89e3\u7684MSO\u523b\u753b\u3002\u6b64\u5916\uff0c\u5bf9MSO\u7684\u8868\u8fbe\u529b\u505a\u4e86\u8ba1\u6570\u91cf\u8bcd\u89d2\u5ea6\u7684\u5206\u6790\u3002", "conclusion": "\u8bba\u6587\u89e3\u51b3\u4e86Courcelle\u63d0\u51fa\u7684\u5f00\u653e\u95ee\u9898\uff0c\u5373\u5982\u4f55\u901a\u8fc7MSO\u903b\u8f91\u5c06\u5c42\u72b6\u96c6\u7cfb\u7edf\u8f6c\u6362\u4e3a\u5bf9\u5e94\u7684\u5c42\u72b6\u6811\u3002\u540c\u65f6\u8bba\u6587\u5bf9\u8ba1\u6570\u91cf\u8bcd\u5728MSO\u4e0b\u7684\u8868\u8fbe\u80fd\u529b\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u53ef\u4ee5\u4ee5\u53ca\u4e0d\u80fd\u6a21\u62df\u7684\u60c5\u5f62\u3002"}}
{"id": "2512.02707", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02707", "abs": "https://arxiv.org/abs/2512.02707", "authors": ["Thomas Georges", "Marianne Huchard", "M\u00e9lanie K\u00f6nig", "Cl\u00e9mentine Nebut", "Chouki Tibermacine"], "title": "Empirical Assessment of the Perception of Software Product Line Engineering by an SME before Migrating its Code Base", "comment": "34 pages", "summary": "Migrating a set of software variants into a software product line (SPL) is an expensive and potentially challenging endeavor. Indeed, SPL engineering can significantly impact a company's development process and often requires changes to established developer practices. The work presented in this paper stems from a collaboration with a Small and Medium-sized Enterprise (SME) that decided to migrate its existing code base into an SPL. In this study, we conducted an in-depth evaluation of the company's current development processes and practices, as well as the anticipated benefits and risks associated with the migration. Key stakeholders involved in software development participated in this evaluation to provide insight into their perceptions of the migration and their potential resistance to change. This paper describes the design of the interviews conducted with these stakeholders and presents an analysis of the results. Among the qualitative findings, we observed that all participants, regardless of their role in the development process, identified benefits of the migration relevant to their own activities. Furthermore, our results suggest that an effective risk mitigation strategy involves keeping stakeholders informed and engaged throughout the process, preserving as many good practices as possible, and actively involving them in the migration to ensure a smooth transition and minimize potential challenges.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9\u4e00\u5bb6\u4e2d\u5c0f\u4f01\u4e1a\u4ece\u73b0\u6709\u4ee3\u7801\u8fc1\u79fb\u5230SPL\u7684\u8fc7\u7a0b\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u53d1\u73b0\u8ba9\u5168\u5458\u6301\u7eed\u53c2\u4e0e\u5e76\u4fdd\u6301\u6c9f\u901a\uff0c\u6709\u52a9\u4e8e\u5e73\u7a33\u8fc7\u6e21\u548c\u964d\u4f4e\u98ce\u9669\u3002", "motivation": "\u8f6f\u4ef6\u53d8\u4f53\u8fc1\u79fb\u5230\u8f6f\u4ef6\u4ea7\u54c1\u7ebf\u867d\u6709\u76ca\u5904\u4f46\u8fc7\u7a0b\u590d\u6742\u4e14\u6210\u672c\u9ad8\uff0c\u5c24\u5176\u4f1a\u5bf9\u4f01\u4e1a\u5185\u90e8\u6d41\u7a0b\u548c\u5f00\u53d1\u4eba\u5458\u5b9e\u8df5\u4ea7\u751f\u663e\u8457\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8bc4\u4f30\u98ce\u9669\u548c\u6536\u76ca\u3002", "method": "\u5bf9\u5408\u4f5c\u4f01\u4e1a\u7684\u5f00\u53d1\u6d41\u7a0b\u8fdb\u884c\u4e86\u6df1\u5165\u8bc4\u4f30\u3002\u91c7\u7528\u9762\u5411\u4e3b\u8981\u5f00\u53d1\u76f8\u5173\u5229\u76ca\u76f8\u5173\u8005\u7684\u8bbf\u8c08\uff0c\u5e76\u5bf9\u8bbf\u8c08\u7ed3\u679c\u8fdb\u884c\u4e86\u5b9a\u6027\u5206\u6790\u3002", "result": "\u53c2\u4e0e\u5404\u73af\u8282\u7684\u5229\u76ca\u76f8\u5173\u8005\u7686\u53d1\u73b0\u8fc1\u79fbSPL\u5bf9\u672c\u804c\u5de5\u4f5c\u6709\u597d\u5904\u3002\u7814\u7a76\u8868\u660e\uff0c\u8ba9\u5229\u76ca\u76f8\u5173\u8005\u6301\u7eed\u53c2\u4e0e\u548c\u4fdd\u6301\u6c9f\u901a\u3001\u7ed3\u5408\u5df2\u6709\u4f18\u826f\u5f00\u53d1\u5b9e\u8df5\uff0c\u662f\u6709\u6548\u7684\u98ce\u9669\u7f13\u89e3\u7b56\u7565\u3002", "conclusion": "\u6240\u6709\u53c2\u4e0e\u8005\u90fd\u8ba4\u8bc6\u5230\u8fc1\u79fb\u81f3SPL\u5e26\u6765\u7684\u76ca\u5904\uff0c\u5e76\u4e14\u901a\u8fc7\u8ba9\u5229\u76ca\u76f8\u5173\u8005\u5168\u7a0b\u53c2\u4e0e\u3001\u4fdd\u6301\u6c9f\u901a\u4ee5\u53ca\u5c3d\u91cf\u4fdd\u7559\u539f\u6709\u4f18\u79c0\u5b9e\u8df5\uff0c\u6709\u52a9\u4e8e\u5e73\u7a33\u8fc1\u79fb\u53ca\u964d\u4f4e\u98ce\u9669\u3002"}}
{"id": "2512.02738", "categories": ["cs.PL", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.02738", "abs": "https://arxiv.org/abs/2512.02738", "authors": ["Joel Nyholm", "Wojciech Mostowski", "Christoph Reichenbach"], "title": "Probabilistic energy profiler for statically typed JVM-based programming languages", "comment": null, "summary": "Energy consumption is a growing concern in several fields, from mobile devices to large data centers. Developers need detailed data on the energy consumption of their software to mitigate consumption issues. Previous approaches have a broader focus, such as on specific functions or programs, rather than source code statements. They primarily focus on estimating the CPU's energy consumption using point estimates, thereby disregarding other hardware effects and limiting their use for statistical reasoning and explainability. We developed a novel methodology to address the limitations of measuring only the CPU's consumption and using point estimates, focusing on predicting the energy usage of statically typed JVM-based programming languages, such as Java and Scala. We measure the energy consumption of Bytecode patterns, the translation from the programming language's source code statement to their Java Bytecode representation. With the energy measurements, we construct a statistical model using Bayesian statistics, which allows us to predict the energy consumption through statistical distributions and analyze individual factors. The model includes three factors we obtain statically from the code: data size, data type, operation, and one factor about the hardware platform the code executes on: device. To validate our methodology, we implemented it for Java and evaluated its energy predictions on unseen programs. We observe that all four factors are influential, notably that two devices of the same model may differ in energy consumption and that the operations and data types cause consumption differences. The experiments also show that the energy prediction of programs closely follows the program's real energy consumption, validating our approach. Our work presents a methodology for constructing an energy model that future work, such as verification tools, can use for their energy estimates.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u5b57\u8282\u7801\u4e0e\u8d1d\u53f6\u65af\u7edf\u8ba1\u7684\u8bed\u53e5\u7ea7\u80fd\u8017\u5efa\u6a21\u65b9\u6cd5\uff0c\u80fd\u9ad8\u6548\u51c6\u786e\u9884\u6d4bJava/Scala\u7a0b\u5e8f\u80fd\u8017\uff0c\u5e76\u63ed\u793a\u4e86\u64cd\u4f5c\u3001\u6570\u636e\u7c7b\u578b\u548c\u8bbe\u5907\u7b49\u56e0\u7d20\u5bf9\u80fd\u8017\u7684\u6df1\u8fdc\u5f71\u54cd\uff0c\u4e3a\u540e\u7eed\u80fd\u8017\u5206\u6790\u5de5\u5177\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u57fa\u7840\u3002", "motivation": "\u5f53\u524d\u5404\u9886\u57df\uff08\u5982\u79fb\u52a8\u8bbe\u5907\u4e0e\u6570\u636e\u4e2d\u5fc3\uff09\u5bf9\u80fd\u6e90\u6d88\u8017\u65e5\u76ca\u5173\u6ce8\uff0c\u5f00\u53d1\u8005\u8feb\u5207\u9700\u8981\u7ec6\u7c92\u5ea6\u7684\u80fd\u8017\u6570\u636e\u4ee5\u4f18\u5316\u8f6f\u4ef6\u80fd\u8017\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u805a\u7126\u4e8eCPU\u548c\u51fd\u6570/\u7a0b\u5e8f\u5c42\u9762\uff0c\u65e0\u6cd5\u6ee1\u8db3\u6e90\u4ee3\u7801\u8bed\u53e5\u7ea7\u522b\u7684\u80fd\u8017\u5efa\u6a21\u4e0e\u66f4\u5e7f\u6cdb\u7684\u786c\u4ef6\u89e3\u91ca\u548c\u7edf\u8ba1\u63a8\u65ad\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u9759\u6001\u7c7b\u578bJVM\u7f16\u7a0b\u8bed\u8a00\uff08\u5982Java\u3001Scala\uff09\u7684\u80fd\u8017\u5efa\u6a21\u65b0\u65b9\u6cd5\uff1a1\uff09\u901a\u8fc7\u6d4b\u91cfJava Bytecode\u6a21\u5f0f\u7684\u80fd\u8017\uff0c\u5c06\u6e90\u4ee3\u7801\u8bed\u53e5\u6620\u5c04\u5230\u5b57\u8282\u7801\u80fd\u8017\uff0c2\uff09\u4f7f\u7528\u8d1d\u53f6\u65af\u7edf\u8ba1\u65b9\u6cd5\u5efa\u7acb\u80fd\u8017\u7684\u7edf\u8ba1\u6a21\u578b\uff0c\u80fd\u591f\u5bf9\u80fd\u8017\u8fdb\u884c\u6982\u7387\u5206\u5e03\u5efa\u6a21\u4e0e\u56e0\u5b50\u5206\u6790\uff0c\u6a21\u578b\u5305\u62ec\u6570\u636e\u89c4\u6a21\u3001\u6570\u636e\u7c7b\u578b\u3001\u64cd\u4f5c\u7c7b\u578b\u548c\u786c\u4ef6\u5e73\u53f0\u7b49\u56db\u7c7b\u9759\u6001\u56e0\u5b50\uff0c3\uff09\u5728Java\u5b9e\u73b0\u5e76\u5728\u672a\u89c1\u7a0b\u5e8f\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u6a21\u578b\u4e2d\u6240\u6709\u56db\u4e2a\u56e0\u7d20\u5bf9\u80fd\u8017\u5747\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5305\u62ec\u540c\u578b\u53f7\u8bbe\u5907\u4e4b\u95f4\u7684\u5dee\u5f02\u3001\u64cd\u4f5c\u7c7b\u578b\u548c\u6570\u636e\u7c7b\u578b\u7684\u80fd\u8017\u5dee\u522b\uff0c\u4ee5\u53ca\u7a0b\u5e8f\u80fd\u8017\u7684\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u80fd\u529b\uff0c\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u672a\u6765\u5982\u9a8c\u8bc1\u5de5\u5177\u7b49\u80fd\u8017\u4f30\u7b97\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u7528\u7684\u80fd\u8017\u5efa\u6a21\u8303\u5f0f\uff0c\u80fd\u5728\u8bed\u53e5\u7ea7\u522b\u652f\u6301\u66f4\u7cbe\u7ec6\u3001\u53ef\u89e3\u91ca\u4e14\u7edf\u8ba1\u4f9d\u636e\u5145\u5206\u7684\u80fd\u8017\u4f30\u7b97\uff0c\u4e3a\u5f00\u53d1\u8005\u4f18\u5316\u8f6f\u4ef6\u80fd\u8017\u548c\u7406\u89e3\u786c\u4ef6\u591a\u6837\u6027\u5f71\u54cd\u63d0\u4f9b\u4e86\u65b0\u624b\u6bb5\u3002"}}
{"id": "2512.02038", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.02038", "abs": "https://arxiv.org/abs/2512.02038", "authors": ["Zhengliang Shi", "Yiqun Chen", "Haitao Li", "Weiwei Sun", "Shiyu Ni", "Yougang Lyu", "Run-Ze Fan", "Bowen Jin", "Yixuan Weng", "Minjun Zhu", "Qiujie Xie", "Xinyu Guo", "Qu Yang", "Jiayi Wu", "Jujia Zhao", "Xiaqiang Tang", "Xinbei Ma", "Cunxiang Wang", "Jiaxin Mao", "Qingyao Ai", "Jen-Tse Huang", "Wenxuan Wang", "Yue Zhang", "Yiming Yang", "Zhaopeng Tu", "Zhaochun Ren"], "title": "Deep Research: A Systematic Survey", "comment": null, "summary": "Large language models (LLMs) have rapidly evolved from text generators into powerful problem solvers. Yet, many open tasks demand critical thinking, multi-source, and verifiable outputs, which are beyond single-shot prompting or standard retrieval-augmented generation. Recently, numerous studies have explored Deep Research (DR), which aims to combine the reasoning capabilities of LLMs with external tools, such as search engines, thereby empowering LLMs to act as research agents capable of completing complex, open-ended tasks. This survey presents a comprehensive and systematic overview of deep research systems, including a clear roadmap, foundational components, practical implementation techniques, important challenges, and future directions. Specifically, our main contributions are as follows: (i) we formalize a three-stage roadmap and distinguish deep research from related paradigms; (ii) we introduce four key components: query planning, information acquisition, memory management, and answer generation, each paired with fine-grained sub-taxonomies; (iii) we summarize optimization techniques, including prompting, supervised fine-tuning, and agentic reinforcement learning; and (iv) we consolidate evaluation criteria and open challenges, aiming to guide and facilitate future development. As the field of deep research continues to evolve rapidly, we are committed to continuously updating this survey to reflect the latest progress in this area.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6027\u7efc\u8ff0\u4e86Deep Research\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u5305\u62ec\u67b6\u6784\u3001\u7ec4\u4ef6\u3001\u4f18\u5316\u3001\u8bc4\u4f30\u6807\u51c6\u53ca\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u4e0e\u66f4\u65b0\u8def\u7ebf\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u63d0\u5347\uff0c\u5355\u4e00\u63d0\u793a\u6216\u6807\u51c6\u68c0\u7d22\u751f\u6210\u5df2\u96be\u4ee5\u6ee1\u8db3\u590d\u6742\u4efb\u52a1\u9700\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u6574\u5408\u63a8\u7406\u4e0e\u5916\u90e8\u5de5\u5177\u4ee5\u5b9e\u73b0\u590d\u6742\u95ee\u9898\u6c42\u89e3\u3002", "method": "\u91c7\u7528\u7efc\u8ff0\u548c\u7cfb\u7edf\u6027\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u68b3\u7406\u548c\u5206\u7c7b\u4e86Deep Research\u7cfb\u7edf\u7684\u67b6\u6784\u3001\u5173\u952e\u7ec4\u4ef6\u3001\u4f18\u5316\u6280\u672f\u53ca\u8bc4\u4ef7\u6807\u51c6\u3002", "result": "\u63d0\u51fa\u4e86Deep Research\u7684\u4e09\u9636\u6bb5\u8def\u7ebf\u56fe\uff0c\u8be6\u7ec6\u533a\u5206\u5176\u4e0e\u76f8\u5173\u8303\u5f0f\uff0c\u6784\u5efa\u4e86\u56db\u5927\u6838\u5fc3\u7ec4\u4ef6\u7684\u7ec6\u81f4\u5206\u7c7b\uff0c\u603b\u7ed3\u4e86\u4f18\u5316\u4e0e\u8bad\u7ec3\u6280\u672f\uff0c\u5e76\u6574\u5408\u4e86\u8bc4\u4f30\u6807\u51c6\u4e0e\u6311\u6218\u3002", "conclusion": "\u8bba\u6587\u603b\u7ed3\u4e86Deep Research\u7cfb\u7edf\u7684\u6574\u4f53\u8fdb\u5c55\u548c\u9762\u4e34\u7684\u6311\u6218\uff0c\u5f3a\u8c03\u5176\u672a\u6765\u53d1\u5c55\u65b9\u5411\u548c\u6301\u7eed\u66f4\u65b0\u7684\u627f\u8bfa\uff0c\u4ee5\u4fc3\u8fdb\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2512.02728", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.02728", "abs": "https://arxiv.org/abs/2512.02728", "authors": ["Sabrina Delmondes da Costa Feitosa"], "title": "Integrative Analysis of Risk Management Methodologies in Data Science Projects", "comment": "13 p\u00e1ginas, in Portuguese language", "summary": "Data science initiatives frequently exhibit high failure rates, driven by technical constraints, organizational limitations and insufficient risk management practices. Challenges such as low data maturity, lack of governance, misalignment between technical and business teams, and the absence of structured mechanisms to address ethical and sociotechnical risks have been widely identified in the literature. In this context, the purpose of this study is to conduct a comparative analysis of the main risk management methodologies applied to data science projects, aiming to identify, classify, and synthesize their similarities, differences and existing gaps. An integrative literature review was performed using indexed databases and a structured protocol for selection and content analysis. The study examines widely adopted risk management standards ISO 31000, PMBOK Risk Management and NIST RMF, as well as frameworks specific to data science workflows, such as CRISP DM and the recently proposed DS EthiCo RMF, which incorporates ethical and sociotechnical dimensions into the project life cycle. The findings reveal that traditional approaches provide limited coverage of emerging risks, whereas contemporary models propose multidimensional structures capable of integrating ethical oversight, governance and continuous monitoring. As a contribution, this work offers theoretical support for the development of hybrid frameworks that balance technical efficiency, organizational alignment and responsible data practices, while highlighting research gaps that can guide future investigations.", "AI": {"tldr": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u6bd4\u8f83\u4e3b\u6d41\u6570\u636e\u79d1\u5b66\u98ce\u9669\u7ba1\u7406\u65b9\u6cd5\uff0c\u53d1\u73b0\u4f20\u7edf\u6cd5\u6709\u9650\u4e14\u65b0\u5174\u6846\u67b6\u80fd\u66f4\u597d\u5e94\u5bf9\u4f26\u7406\u4e0e\u6cbb\u7406\u98ce\u9669\uff0c\u5e76\u5efa\u8bae\u53d1\u5c55\u6280\u672f\u3001\u7ec4\u7ec7\u3001\u4f26\u7406\u517c\u987e\u7684\u6df7\u5408\u578b\u65b9\u6cd5\u3002", "motivation": "\u6570\u636e\u79d1\u5b66\u9879\u76ee\u5e38\u5e38\u7531\u4e8e\u6280\u672f\u3001\u7ec4\u7ec7\u548c\u98ce\u9669\u7ba1\u7406\u4e0d\u8db3\u800c\u5931\u8d25\uff0c\u6587\u732e\u6307\u51fa\u6570\u636e\u6210\u719f\u5ea6\u4f4e\u3001\u6cbb\u7406\u7f3a\u5931\u3001\u6280\u672f\u548c\u4e1a\u52a1\u56e2\u961f\u5931\u8c03\u3001\u7f3a\u4e4f\u5e94\u5bf9\u4f26\u7406\u548c\u793e\u4f1a\u6280\u672f\u98ce\u9669\u7684\u7ed3\u6784\u6027\u673a\u5236\u7b49\u95ee\u9898\u3002\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u68b3\u7406\u548c\u6bd4\u8f83\u6570\u636e\u79d1\u5b66\u9879\u76ee\u6240\u5e94\u7528\u7684\u4e3b\u8981\u98ce\u9669\u7ba1\u7406\u65b9\u6cd5\uff0c\u660e\u786e\u5176\u4f18\u52bf\u3001\u77ed\u677f\u548c\u7a7a\u767d\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u4e86\u7cfb\u7edf\u6027\u7684\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5728\u6570\u636e\u5e93\u4e2d\u4ee5\u7ed3\u6784\u5316\u534f\u8bae\u7b5b\u9009\u548c\u5206\u6790\u6587\u732e\uff0c\u91cd\u70b9\u8bc4\u4f30ISO 31000\u3001PMBOK\u98ce\u9669\u7ba1\u7406\u3001NIST RMF\u4ee5\u53ca\u6570\u636e\u79d1\u5b66\u7279\u6709\u7684CRISP DM\u548cDS EthiCo RMF\u7b49\u6807\u51c6\u548c\u6846\u67b6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4f20\u7edf\u98ce\u9669\u7ba1\u7406\u65b9\u6cd5\u5bf9\u65b0\u5174\u98ce\u9669\u7684\u8986\u76d6\u6709\u5c40\u9650\u6027\uff0c\u800c\u65b0\u8fd1\u6a21\u578b\u80fd\u66f4\u597d\u5730\u878d\u5408\u4f26\u7406\u76d1\u7ba1\u3001\u6cbb\u7406\u548c\u6301\u7eed\u76d1\u7763\u7b49\u591a\u7ef4\u5ea6\u7ed3\u6784\u3002\u5bf9\u6bd4\u5206\u6790\u8868\u660e\uff0c\u4e0d\u540c\u6846\u67b6\u5728\u98ce\u9669\u5e94\u5bf9\u7ef4\u5ea6\u548c\u5b9e\u65bd\u7ec6\u8282\u4e0a\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u672c\u6587\u4e3a\u5f00\u53d1\u6574\u5408\u6280\u672f\u6548\u7387\u3001\u7ec4\u7ec7\u534f\u540c\u4e0e\u8d1f\u8d23\u4efb\u6570\u636e\u5b9e\u8df5\u4e8e\u4e00\u4f53\u7684\u6df7\u5408\u578b\u98ce\u9669\u7ba1\u7406\u6846\u67b6\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5e76\u6307\u51fa\u4e86\u5f53\u524d\u65b9\u6cd5\u5b58\u5728\u7684\u7814\u7a76\u7a7a\u767d\u4e0e\u672a\u6765\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2512.02966", "categories": ["cs.PL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.02966", "abs": "https://arxiv.org/abs/2512.02966", "authors": ["Isha Chaudhary", "Vedaant Jain", "Avaljot Singh", "Kavya Sachdeva", "Sayan Ranu", "Gagandeep Singh"], "title": "Lumos: Let there be Language Model System Certification", "comment": null, "summary": "We introduce the first principled framework, Lumos, for specifying and formally certifying Language Model System (LMS) behaviors. Lumos is an imperative probabilistic programming DSL over graphs, with constructs to generate independent and identically distributed prompts for LMS. It offers a structured view of prompt distributions via graphs, forming random prompts from sampled subgraphs. Lumos supports certifying LMS for arbitrary prompt distributions via integration with statistical certifiers. We provide hybrid (operational and denotational) semantics for Lumos, providing a rigorous way to interpret the specifications. Using only a small set of composable constructs, Lumos can encode existing LMS specifications, including complex relational and temporal specifications. It also facilitates specifying new properties - we present the first safety specifications for vision-language models (VLMs) in autonomous driving scenarios developed with Lumos. Using these, we show that the state-of-the-art VLM Qwen-VL exhibits critical safety failures, producing incorrect and unsafe responses with at least 90% probability in right-turn scenarios under rainy driving conditions, revealing substantial safety risks. Lumos's modular structure allows easy modification of the specifications, enabling LMS certification to stay abreast with the rapidly evolving threat landscape. We further demonstrate that specification programs written in Lumos enable finding specific failure cases exhibited by state-of-the-art LMS. Lumos is the first systematic and extensible language-based framework for specifying and certifying LMS behaviors, paving the way for a wider adoption of LMS certification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLumos\u6846\u67b6\uff0c\u9996\u6b21\u7528\u5f62\u5f0f\u5316\u65b9\u6cd5\u89c4\u8303\u5e76\u8ba4\u8bc1\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u884c\u4e3a\uff0c\u80fd\u53d1\u73b0\u5e76\u91cf\u5316\u9876\u5c16VLM\u5728\u81ea\u52a8\u9a7e\u9a76\u7b49\u573a\u666f\u4e0b\u7684\u663e\u8457\u5b89\u5168\u7f3a\u9677\uff0c\u4e3aLMS\u5b89\u5168\u8ba4\u8bc1\u63d0\u4f9b\u65b0\u8def\u5f84\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u7cfb\u7edf\u5316\u3001\u53ef\u6269\u5c55\u4e14\u53ef\u8ba4\u8bc1\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u884c\u4e3a\u7684\u5de5\u5177\u3002\u968f\u7740LMS\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u5c24\u5176\u662f\u5728\u5173\u952e\u9886\u57df\uff08\u5982\u81ea\u52a8\u9a7e\u9a76\uff09\uff0c\u5bf9\u5176\u5b89\u5168\u6027\u548c\u884c\u4e3a\u89c4\u8303\u5316\u7684\u9700\u6c42\u66f4\u4e3a\u8feb\u5207\u3002", "method": "\u65b9\u6cd5\u8bba\u4e0a\uff0c\u63d0\u51fa\u4e86Lumos\u8bed\u8a00\uff1a\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u547d\u4ee4\u5f0f\u6982\u7387\u7f16\u7a0bDSL\uff0c\u901a\u8fc7\u62bd\u8c61\u751f\u6210IID\u4efb\u52a1\u63d0\u793a\uff0c\u5e76\u7ed3\u5408\u7edf\u8ba1\u8ba4\u8bc1\u5668\uff0c\u5b9e\u73b0\u9488\u5bf9\u4efb\u610f\u63d0\u793a\u5206\u5e03\u4e0b\u7684LMS\u8ba4\u8bc1\u3002\u8be5\u6846\u67b6\u5177\u5907\u7ec4\u5408\u6027\uff0c\u53ef\u7f16\u7801\u590d\u6742\u65f6\u5e8f\u548c\u5173\u7cfb\u89c4\u8303\uff0c\u5e76\u652f\u6301\u6df7\u5408\u8bed\u4e49\uff08\u64cd\u4f5c\u8bed\u4e49+\u6307\u79f0\u8bed\u4e49\uff09\u89e3\u91ca\u89c4\u8303\u3002", "result": "1. \u5229\u7528Lumos\u63d0\u51fa\u9996\u5957\u9488\u5bf9\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08\u5982\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u4e0bVLM\uff09\u7684\u5b89\u5168\u89c4\u8303\u30022. \u5b9e\u8bc1\u53d1\u73b0\u9876\u5c16VLM\uff08Qwen-VL\uff09\u5728\u96e8\u5929\u53f3\u8f6c\u9a7e\u9a76\u573a\u666f\u4e0b\u81f3\u5c1190%\u6982\u7387\u7ed9\u51fa\u9519\u8bef\u6216\u4e0d\u5b89\u5168\u54cd\u5e94\uff0c\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u98ce\u9669\u30023. Lumos\u9ad8\u53ef\u6269\u5c55\u6027\uff0c\u80fd\u8f85\u52a9\u5feb\u901f\u5b9a\u4f4d\u7f3a\u9677\u548c\u9002\u5e94\u5a01\u80c1\u53d8\u5316\u3002", "conclusion": "Lumos\u662f\u9996\u4e2a\u7cfb\u7edf\u5316\u3001\u53ef\u6269\u5c55\u7684\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\uff08LMS\uff09\u884c\u4e3a\u89c4\u8303\u548c\u8ba4\u8bc1\u6846\u67b6\uff0c\u4e3aLMS\u8ba4\u8bc1\u7684\u5e7f\u6cdb\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2512.02043", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.02043", "abs": "https://arxiv.org/abs/2512.02043", "authors": ["Dina Sayed", "Heiko Schuldt"], "title": "Mirror, Mirror on the Wall -- Which is the Best Model of Them All?", "comment": null, "summary": "Large Language Models (LLMs) have become one of the most transformative tools across many applications, as they have significantly boosted productivity and achieved impressive results in various domains such as finance, healthcare, education, telecommunications, and law, among others. Typically, state-of-the-art (SOTA) foundation models are developed by large corporations based on large data collections and substantial computational and financial resources required to pretrain such models from scratch. These foundation models then serve as the basis for further development and domain adaptation for specific use cases or tasks. However, given the dynamic and fast-paced nature of launching new foundation models, the process of selecting the most suitable model for a particular use case, application, or domain becomes increasingly complex. We argue that there are two main dimensions that need to be taken into consideration when selecting a model for further training: a qualitative dimension (which model is best suited for a task based on information, for instance, taken from model cards) and a quantitative dimension (which is the best performing model). The quantitative performance of models is assessed through leaderboards, which rank models based on standardized benchmarks and provide a consistent framework for comparing different LLMs. In this work, we address the analysis of the quantitative dimension by exploring the current leaderboards and benchmarks. To illustrate this analysis, we focus on the medical domain as a case study, demonstrating the evolution, current landscape, and practical significance of this quantitative evaluation dimension. Finally, we propose a Model Selection Methodology (MSM), a systematic approach designed to guide the navigation, prioritization, and selection of the model that best aligns with a given use case.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5f53\u524dLLM\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u9009\u578b\u65f6\u7684\u590d\u6742\u6027\uff0c\u91cd\u70b9\u8ba8\u8bba\u5b9a\u91cf\u7ef4\u5ea6\uff08\u6392\u884c\u699c/\u57fa\u51c6\uff09\uff0c\u4ee5\u533b\u7597\u9886\u57df\u4e3e\u6848\u4f8b\uff0c\u63d0\u51fa\u4e86\u7cfb\u7edf\u5316\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\uff08MSM\uff09\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u9762\u5bf9\u4e0d\u65ad\u66f4\u65b0\u7684\u57fa\u7840\u6a21\u578b\u548c\u591a\u9886\u57df\u9700\u6c42\uff0c\u5982\u4f55\u79d1\u5b66\u9009\u578bLLM\u53d8\u5f97\u65e5\u76ca\u590d\u6742\uff0c\u4e9f\u9700\u4e00\u5957\u7cfb\u7edf\u6027\u9009\u62e9\u65b9\u6cd5\u6765\u6307\u5bfc\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u5206\u6790\u73b0\u6709\u7684LLM\u6392\u884c\u699c\u4e0e\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7279\u522b\u4ee5\u533b\u5b66\u9886\u57df\u4e3a\u6848\u4f8b\uff0c\u7efc\u5408\u5b9a\u6027\u548c\u5b9a\u91cf\u7ef4\u5ea6\uff0c\u63d0\u51fa\u6a21\u578b\u9009\u62e9\u6d41\u7a0b\u3002", "result": "\u5b9a\u91cf\u7ef4\u5ea6\u5206\u6790\uff08\u5982\u6392\u884c\u699c\u3001\u6807\u51c6\u5316\u57fa\u51c6\uff09\u5df2\u6210\u4e3a\u9009\u578b\u91cd\u8981\u4f9d\u636e\uff0c\u4f5c\u8005\u4ee5\u533b\u5b66\u9886\u57df\u6f14\u793a\u4e86\u57fa\u4e8e\u8fd9\u4e9b\u6570\u636e\u7684\u6a21\u578b\u7b5b\u9009\u6d41\u7a0b\uff0c\u5e76\u7ed9\u51fa\u5177\u4f53\u5b9e\u7528\u7684\u65b9\u6cd5\u8bba\u3002", "conclusion": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u6027\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\uff08MSM\uff09\uff0c\u5e2e\u52a9\u7528\u6237\u5728\u5feb\u901f\u53d8\u5316\u7684\u57fa\u7840\u6a21\u578b\u9886\u57df\uff0c\u9009\u62e9\u6700\u9002\u5408\u7279\u5b9a\u5e94\u7528\u573a\u666f\u7684LLM\u3002"}}
{"id": "2512.02898", "categories": ["cs.SE", "cs.AI", "cs.LO", "cs.SC"], "pdf": "https://arxiv.org/pdf/2512.02898", "abs": "https://arxiv.org/abs/2512.02898", "authors": ["Pedro Orvalho", "Marta Kwiatkowska", "Mikol\u00e1\u0161 Janota", "Vasco Manquinho"], "title": "Model-Based Diagnosis with Multiple Observations: A Unified Approach for C Software and Boolean Circuits", "comment": "50 pages, 9 figures, 6 tables, 5 listings", "summary": "Debugging is one of the most time-consuming and expensive tasks in software development and circuit design. Several formula-based fault localisation (FBFL) methods have been proposed, but they fail to guarantee a set of diagnoses across all failing tests or may produce redundant diagnoses that are not subset-minimal, particularly for programs/circuits with multiple faults.\n  This paper introduces CFaults, a novel fault localisation tool for C software and Boolean circuits with multiple faults. CFaults leverages Model-Based Diagnosis (MBD) with multiple observations and aggregates all failing test cases into a unified Maximum Satisfiability (MaxSAT) formula. Consequently, our method guarantees consistency across observations and simplifies the fault localisation procedure. Experimental results on three benchmark sets, two of C programs, TCAS and C-Pack-IPAs, and one of Boolean circuits, ISCAS85, show that CFaults is faster at localising faults in C software than other FBFL approaches such as BugAssist, SNIPER, and HSD. On the ISCAS85 benchmark, CFaults is generally slower than HSD; however, it localises faults in only 6% fewer circuits, demonstrating that it remains competitive in this domain. Furthermore, CFaults produces only subset-minimal diagnoses of faulty statements, whereas the other approaches tend to enumerate redundant diagnoses (e.g., BugAssist and SNIPER).", "AI": {"tldr": "CFaults\u662f\u4e00\u79cd\u878d\u5408MaxSAT\u4e0eMBD\u7684\u65b0\u578b\u6545\u969c\u5b9a\u4f4d\u5de5\u5177\uff0c\u9488\u5bf9\u591a\u6545\u969c\u573a\u666f\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8bca\u65ad\u4e00\u81f4\u6027\u548c\u51cf\u5c11\u5197\u4f59\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728C\u7a0b\u5e8f\u4e0a\u4f18\u4e8e\u4e3b\u6d41\u5de5\u5177\uff0c\u5bf9\u7535\u8def\u573a\u666f\u4e5f\u8f83\u4e3a\u7ade\u4e89\u3002", "motivation": "\u73b0\u6709\u516c\u5f0f\u5316\u6545\u969c\u5b9a\u4f4d\u65b9\u6cd5\u5728\u591a\u6545\u969c\u60c5\u51b5\u4e0b\u5f80\u5f80\u65e0\u6cd5\u4fdd\u8bc1\u6240\u6709\u5931\u8d25\u6d4b\u8bd5\u7684\u8bca\u65ad\u4e00\u81f4\u6027\uff0c\u4e14\u6613\u4ea7\u751f\u5197\u4f59\u3001\u975e\u6700\u5c0f\u5316\u7684\u8bca\u65ad\u96c6\u5408\uff0c\u5f71\u54cd\u6548\u7387\u548c\u51c6\u786e\u6027\u3002\u4f5c\u8005\u65e8\u5728\u89e3\u51b3\u8be5\u75db\u70b9\u3002", "method": "\u63d0\u51faCFaults\u5de5\u5177\uff0c\u5c06\u6240\u6709\u5931\u8d25\u6d4b\u8bd5\u6848\u4f8b\u8f6c\u5316\u4e3a\u7edf\u4e00\u7684MaxSAT\u516c\u5f0f\uff0c\u5e76\u5229\u7528\u6a21\u578b\u8bca\u65ad\u65b9\u6cd5\uff08MBD\uff09\u5728\u591a\u89c2\u6d4b\u70b9\u4e0b\u8fdb\u884c\u6545\u969c\u5b9a\u4f4d\uff0c\u4fdd\u8bc1\u8bca\u65ad\u7ed3\u679c\u7684\u4e00\u81f4\u6027\u4e0e\u6700\u5c0f\u5197\u4f59\u6027\u3002\u5bf9TCAS\u3001C-Pack-IPAs\u3001ISCAS85\u7b49\u57fa\u51c6\u96c6\u8fdb\u884c\u5b9e\u8bc1\u5bf9\u6bd4\u5206\u6790\u3002", "result": "CFaults\u5728C\u8f6f\u4ef6\u57fa\u51c6\u4e0a\u5b9a\u4f4d\u901f\u5ea6\u5feb\u4e8eBugAssist\u3001SNIPER\u3001HSD\uff0c\u5728ISCAS85\u7535\u8def\u57fa\u51c6\u4e0a\u5b9a\u4f4d\u8986\u76d6\u7387\u4ec5\u6bd4HSD\u4f4e6%\u3002\u4e14CFaults\u80fd\u751f\u6210\u53bb\u5197\u4f59\u3001\u5b50\u96c6\u6700\u5c0f\u7684\u6545\u969c\u8bca\u65ad\u96c6\u5408\uff0c\u5176\u4f59\u65b9\u6cd5\u6613\u4ea7\u751f\u5197\u4f59\u3002", "conclusion": "CFaults\u5de5\u5177\u5229\u7528\u591a\u89c2\u6d4b\u70b9\u7684\u6a21\u578b\u8bca\u65ad\u65b9\u6cd5\uff0c\u5bf9\u5931\u8d25\u6d4b\u8bd5\u8fdb\u884c\u7edf\u4e00\u5904\u7406\uff0c\u63d0\u9ad8\u4e86\u591a\u6545\u969c\u573a\u666f\u4e0b\u7684\u5b9a\u4f4d\u4e00\u81f4\u6027\u548c\u8bca\u65ad\u7b80\u6d01\u6027\u3002\u76f8\u6bd4\u73b0\u6709\u5de5\u5177\uff0cCFaults\u5728C\u8f6f\u4ef6\u8bca\u65ad\u901f\u5ea6\u66f4\u5feb\uff0c\u4e14\u8f93\u51fa\u53bb\u5197\u4f59\u7684\u6545\u969c\u96c6\u5408\uff0c\u4ec5\u7565\u900a\u4e8e\u5176\u4ed6\u65b9\u6cd5\u5728\u90e8\u5206\u7535\u8def\uff08\u5982ISCAS85\uff09\u4e0a\u7684\u8986\u76d6\u7387\u3002"}}
{"id": "2512.02750", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.02750", "abs": "https://arxiv.org/abs/2512.02750", "authors": ["Kiev Gama", "Filipe Calegario", "Victoria Jackson", "Alexander Nolte", "Luiz Augusto Morais", "Vinicius Garcia"], "title": "\"Can you feel the vibes?\": An exploration of novice programmer engagement with vibe coding", "comment": "International Conference on Software Engineering, Education Track (SEET) 2026", "summary": "Emerging alongside generative AI and the broader trend of AI-assisted coding, the term \"vibe coding\" refers to creating software via natural language prompts rather than direct code authorship. This approach promises to democratize software development, but its educational implications remain underexplored. This paper reports on a one-day educational hackathon investigating how novice programmers and mixed-experience teams engage with vibe coding. We organized an inclusive event at a Brazilian public university with 31 undergraduate participants from computing and non-computing disciplines, divided into nine teams. Through observations, an exit survey, and semi-structured interviews, we examined creative processes, tool usage patterns, collaboration dynamics, and learning outcomes. Findings reveal that vibe coding enabled rapid prototyping and cross-disciplinary collaboration, with participants developing prompt engineering skills and delivering functional demonstrations within time constraints. However, we observed premature convergence in ideation, uneven code quality requiring rework, and limited engagement with core software engineering practices. Teams adopted sophisticated workflows combining multiple AI tools in pipeline configurations, with human judgment remaining essential for critical refinement. The short format (9 hours) proved effective for confidence-building among newcomers while accommodating participants with limited availability. We conclude that vibe coding hackathons can serve as valuable low-stakes learning environments when coupled with explicit scaffolds for divergent thinking, critical evaluation of AI outputs, and realistic expectations about production quality.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u9ed1\u5ba2\u677e\u63a2\u8ba8vibe coding\u5bf9\u65b0\u624b\u548c\u6df7\u5408\u7ecf\u9a8c\u56e2\u4f53\u7684\u6559\u80b2\u5f71\u54cd\uff0c\u663e\u793a\u5176\u4fc3\u8fdb\u5feb\u901f\u539f\u578b\u3001\u8de8\u5b66\u79d1\u534f\u4f5c\u548c\u4fe1\u5fc3\u63d0\u5347\uff0c\u4f46\u9700\u6709\u6548\u5f15\u5bfc\u9632\u6b62\u601d\u7ef4\u6536\u655b\u548c\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\uff0c\u5f3a\u8c03\u4eba\u673a\u534f\u4f5c\u4e0e\u6279\u5224\u6027\u8bc4\u4ef7\u3002", "motivation": "\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5174\u8d77\u4ee5\u53caAI\u8f85\u52a9\u7f16\u7a0b\u666e\u53ca\uff0c\u5e26\u6765\u4e86\u201cvibe coding\u201d\u65b0\u8d8b\u52bf\uff0c\u8be5\u65b9\u6cd5\u5141\u8bb8\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u800c\u975e\u76f4\u63a5\u7f16\u7a0b\u5f00\u53d1\u8f6f\u4ef6\u3002\u5176\u6709\u671b\u666e\u53ca\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\uff0c\u4f46\u5bf9\u6559\u80b2\u5f71\u54cd\u5c1a\u672a\u6df1\u5165\u7814\u7a76\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u573a\u4e3a\u671f\u4e00\u5929\u7684\u6559\u80b2\u9ed1\u5ba2\u677e\u6d3b\u52a8\uff0c\u5728\u5df4\u897f\u4e00\u6240\u516c\u7acb\u5927\u5b66\u4e3e\u529e\uff0c\u53ec\u96c6\u4e8631\u540d\u6765\u81ea\u8ba1\u7b97\u673a\u53ca\u975e\u8ba1\u7b97\u673a\u5b66\u79d1\u7684\u672c\u79d1\u751f\uff0c\u5206\u4e3a\u4e5d\u4e2a\u56e2\u961f\u3002\u901a\u8fc7\u89c2\u5bdf\u3001\u95ee\u5377\u8c03\u67e5\u548c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u5206\u6790\u4e86\u521b\u610f\u8fc7\u7a0b\u3001\u5de5\u5177\u4f7f\u7528\u6a21\u5f0f\u3001\u534f\u4f5c\u52a8\u529b\u548c\u5b66\u4e60\u6210\u679c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cvibe coding\u6709\u52a9\u4e8e\u5feb\u901f\u539f\u578b\u5b9e\u73b0\u548c\u8de8\u5b66\u79d1\u534f\u4f5c\uff0c\u53c2\u4e0e\u8005\u57f9\u517b\u4e86\u63d0\u793a\u5de5\u7a0b\u80fd\u529b\uff0c\u5e76\u80fd\u5728\u6709\u9650\u65f6\u95f4\u5185\u5b8c\u6210\u529f\u80fd\u5c55\u793a\u3002\u4f46\u4e5f\u5b58\u5728\u601d\u60f3\u6536\u655b\u8fc7\u5feb\u3001\u4ee3\u7801\u8d28\u91cf\u4e0d\u5747\u9700\u8fd4\u5de5\u3001\u6838\u5fc3\u8f6f\u5de5\u5b9e\u8df5\u53c2\u4e0e\u5ea6\u6709\u9650\u7b49\u95ee\u9898\u3002\u56e2\u961f\u91c7\u7528\u591aAI\u5de5\u5177\u8054\u7528\u7684\u590d\u6742\u5de5\u4f5c\u6d41\uff0c\u5e76\u4e14\u4eba\u5de5\u5224\u65ad\u4ecd\u5bf9\u5173\u952e\u4f18\u5316\u4e0d\u53ef\u6216\u7f3a\u3002\u77ed\u65f6\u95f4\u6d3b\u52a8\u6709\u6548\u6fc0\u53d1\u65b0\u624b\u81ea\u4fe1\uff0c\u9002\u5408\u65f6\u95f4\u6709\u9650\u53c2\u4e0e\u8005\u3002", "conclusion": "vibe coding\u9ed1\u5ba2\u677e\u4e3a\u4f4e\u98ce\u9669\u5b66\u4e60\u73af\u5883\uff0c\u82e5\u8f85\u4ee5\u9f13\u52b1\u53d1\u6563\u601d\u7ef4\u3001\u6279\u5224AI\u8f93\u51fa\u548c\u73b0\u5b9e\u8d28\u91cf\u9884\u671f\u7684\u5f15\u5bfc\u63aa\u65bd\uff0c\u5c06\u4e3a\u7f16\u7a0b\u6559\u80b2\u63d0\u4f9b\u6709\u4ef7\u503c\u652f\u6301\u3002"}}
{"id": "2512.02044", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.02044", "abs": "https://arxiv.org/abs/2512.02044", "authors": ["Kecheng Chen", "Ziru Liu", "Xijia Tao", "Hui Liu", "Xinyu Fu", "Suiyun Zhang", "Dandan Tu", "Lingpeng Kong", "Rui Liu", "Haoliang Li"], "title": "Beyond Confidence: Adaptive and Coherent Decoding for Diffusion Language Models", "comment": null, "summary": "Diffusion Language Models (DLMs) have recently achieved significant success due to their any-order generation capabilities. However, existing inference methods typically rely on local, immediate-step metrics such as confidence or entropy which inherently lack a more reliable perspective. This limitation frequently leads to inconsistent sampling trajectories and suboptimal generation quality. To address this, we propose Coherent Contextual Decoding (CCD), a novel inference framework built upon two core innovations. First, CCD employs a trajectory rectification mechanism that leverages historical context to enhance sequence coherence, enabling the early rejection of suboptimal paths. We demonstrate that this mechanism is theoretically equivalent to modeling the consistency of historical steps via the conditional mutual information between context and token predictions. Building on this theoretical insight, we further address the inefficiency of conventional uniform decoding budgets. Instead of rigid allocations based on diffusion steps, we introduce an adaptive sampling strategy that dynamically adjusts the unmasking budget for each step according to our consistency metric. Consequently, our method significantly improves the quality of generation trajectories while accelerating the sampling process. Empirically, our method achieves a simultaneous enhancement in both inference speed and performance across diverse benchmarks on Dream and LLaDA, delivering up to 3.48x speedup alongside 3.91% performance improvement.", "AI": {"tldr": "\u63d0\u51fa\u7684CCD\u65b9\u6cd5\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u8f68\u8ff9\u4fee\u6b63\u548c\u81ea\u9002\u5e94\u91c7\u6837\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u901f\u5ea6\u548c\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u6269\u6563\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5c40\u90e8\u5373\u65f6\u6307\u6807\uff08\u5982\u7f6e\u4fe1\u5ea6\u548c\u71b5\uff09\uff0c\u7f3a\u4e4f\u6574\u4f53\u548c\u8fde\u8d2f\u7684\u8bc4\u4ef7\u89c6\u89d2\uff0c\u5bfc\u81f4\u751f\u6210\u8f68\u8ff9\u4e0d\u53ef\u9760\u53ca\u8d28\u91cf\u4e0b\u964d\u3002\u672c\u7814\u7a76\u65e8\u5728\u63d0\u5347\u751f\u6210\u5e8f\u5217\u7684\u6574\u4f53\u4e00\u81f4\u6027\u548c\u63a8\u7406\u6548\u7387\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\u7684\u8f68\u8ff9\u4fee\u6b63\u673a\u5236\u548c\u81ea\u9002\u5e94\u91c7\u6837\u7b56\u7565\uff0c\u52a8\u6001\u8c03\u6574\u89e3\u7801\u9884\u7b97\uff0c\u63d0\u5347\u751f\u6210\u5e8f\u5217\u7684\u8fde\u8d2f\u6027\u548c\u91c7\u6837\u6548\u7387\u3002\u7406\u8bba\u4e0a\uff0c\u8be5\u673a\u5236\u7b49\u4ef7\u4e8e\u5229\u7528\u6761\u4ef6\u4e92\u4fe1\u606f\u8bc4\u4f30\u5386\u53f2\u6b65\u9aa4\u7684\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\u3002", "result": "\u6240\u63d0CCD\u65b9\u6cd5\u5728Dream\u548cLLaDA\u7b49\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u540c\u65f6\u53d6\u5f97\u4e86\u63a8\u7406\u901f\u5ea6\u548c\u751f\u6210\u6027\u80fd\u7684\u5927\u5e45\u63d0\u5347\uff0c\u4e3a\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u751f\u6210\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u9ad8\u6548\u89e3\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684Coherent Contextual Decoding\uff08CCD\uff09\u663e\u8457\u63d0\u5347\u4e86DLM\u6a21\u578b\u7684\u751f\u6210\u8d28\u91cf\u548c\u63a8\u7406\u901f\u5ea6\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e863.48\u500d\u7684\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u548c3.91%\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2512.02795", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.02795", "abs": "https://arxiv.org/abs/2512.02795", "authors": ["Marcus Kessel"], "title": "Towards Observation Lakehouses: Living, Interactive Archives of Software Behavior", "comment": null, "summary": "Code-generating LLMs are trained largely on static artifacts (source, comments, specifications) and rarely on materializations of run-time behavior. As a result, they readily internalize buggy or mislabeled code. Since non-trivial semantic properties are undecidable in general, the only practical way to obtain ground-truth functionality is by dynamic observation of executions. In prior work, we addressed representation with Sequence Sheets, Stimulus-Response Matrices (SRMs), and Stimulus-Response Cubes (SRCs) to capture and compare behavior across tests, implementations, and contexts. These structures make observation data analyzable offline and reusable, but they do not by themselves provide persistence, evolution, or interactive analytics at scale. In this paper, therefore, we introduce observation lakehouses that operationalize continual SRCs: a tall, append-only observations table storing every actuation (stimulus, response, context) and SQL queries that materialize SRC slices on demand. Built on Apache Parquet + Iceberg + DuckDB, the lakehouse ingests data from controlled pipelines (LASSO) and CI pipelines (e.g., unit test executions), enabling n-version assessment, behavioral clustering, and consensus oracles without re-execution. On a 509-problem benchmark, we ingest $\\approx$8.6M observation rows ($<$51MiB) and reconstruct SRM/SRC views and clusters in $<$100ms on a laptop, demonstrating that continual behavior mining is practical without a distributed cluster of machines. This makes behavioral ground truth first-class alongside other run-time data and provides an infrastructure path toward behavior-aware evaluation and training. The Observation Lakehouse, together with the accompanying dataset, is publicly available as an open-source project on GitHub: https://github.com/SoftwareObservatorium/observation-lakehouse", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u89c2\u5bdf\u6e56\u4ed3\uff0c\u6301\u7eed\u6536\u96c6\u548c\u5b58\u50a8\u4ee3\u7801\u8fd0\u884c\u884c\u4e3a\uff0c\u6613\u4e8e\u5206\u6790\u4e0e\u6269\u5c55\uff0c\u5e76\u80fd\u5728\u5355\u673a\u9ad8\u6548\u5de5\u4f5c\uff0c\u4e3a\u884c\u4e3a\u9a71\u52a8\u7684\u4ee3\u7801\u8bc4\u4f30\u548c\u8bad\u7ec3\u6253\u5f00\u65b0\u8def\u5f84\u3002", "motivation": "\u4f20\u7edf\u4ee3\u7801\u751f\u6210\u578b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u5b66\u4e60\u9759\u6001\u4fe1\u606f\uff0c\u5bb9\u6613\u5438\u6536\u9519\u8bef\u4ee3\u7801\uff0c\u65e0\u6cd5\u6709\u6548\u9a8c\u8bc1\u8bed\u4e49\u529f\u80fd\u3002\u7531\u4e8e\u590d\u6742\u8bed\u4e49\u5c5e\u6027\u4e00\u822c\u662f\u4e0d\u53ef\u5224\u5b9a\u7684\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u52a8\u6001\u8fd0\u884c\u884c\u4e3a\u7684\u89c2\u6d4b\uff0c\u4f5c\u4e3a\u4ee3\u7801\u884c\u4e3a\u7684\u771f\u5b9e\u4f9d\u636e\uff0c\u7528\u4e8e\u66f4\u9ad8\u8d28\u91cf\u7684\u6a21\u578b\u8bc4\u4f30\u548c\u8bad\u7ec3\u3002", "method": "\u63d0\u51fa\u4e86\u89c2\u5bdf\u6e56\u4ed3\uff08Observation Lakehouse\uff09\u4f53\u7cfb\uff0c\u6301\u7eed\u6027\u5730\u6536\u96c6\u548c\u5b58\u50a8SRC\uff08Stimulus-Response Cube\uff09\u7684\u539f\u59cb\u89c2\u6d4b\u6570\u636e\uff0c\u5b9e\u73b0\u6570\u636e\u7684\u6301\u4e45\u5316\u3001\u53ef\u6269\u5c55\u6f14\u5316\u4e0e\u4ea4\u4e92\u5206\u6790\uff1b\u5177\u4f53\u6280\u672f\u5b9e\u73b0\u5305\u62ec\u57fa\u4e8eApache Parquet\u3001Iceberg\u548cDuckDB\uff0c\u7ed3\u5408\u4ece\u81ea\u52a8\u5316\u6d41\u7a0b\u548cCI\u7ba1\u9053\u91c7\u96c6\u7684\u884c\u4e3a\u6570\u636e\uff0c\u5e76\u901a\u8fc7SQL\u67e5\u8be2\u6309\u9700\u751f\u6210\u5206\u6790\u89c6\u56fe\u3002", "result": "\u65b9\u6848\u5728509\u4e2a\u95ee\u9898\u7684\u57fa\u51c6\u4e0a\u6210\u529f\u91c7\u96c6\u5e76\u5b58\u50a8\u4e86\u7ea68.6\u767e\u4e07\u884c\u89c2\u6d4b\u884c\u4e3a\u6570\u636e\uff08<51MiB\uff09\uff0c\u53ef\u5728\u666e\u901a\u7b14\u8bb0\u672c\u7535\u8111\u4e0a\u4ee5<100ms\u7684\u901f\u5ea6\u91cd\u5efa\u5206\u6790\u89c6\u56fe\u4e0e\u805a\u7c7b\uff0c\u65e0\u9700\u5206\u5e03\u5f0f\u96c6\u7fa4\u3002\u7cfb\u7edf\u53ca\u6570\u636e\u5df2\u5f00\u6e90\u3002", "conclusion": "\u89c2\u5bdf\u6e56\u4ed3\u4f7f\u884c\u4e3a\u578b\u6570\u636e\u6210\u4e3a\u4e0e\u5176\u4ed6\u8fd0\u884c\u65f6\u6570\u636e\u540c\u7b49\u91cd\u8981\u7684\u4e00\u7b49\u516c\u6c11\uff0c\u5e76\u4e3a\u884c\u4e3a\u611f\u77e5\u7684\u8bc4\u4f30\u4e0e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u57fa\u7840\u8bbe\u65bd\u3002"}}
