{"id": "2508.07855", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.07855", "abs": "https://arxiv.org/abs/2508.07855", "authors": ["Parosh Aziz Abdulla", "Mohamed Faouzi Atig", "R. Govind", "Samuel Grahn", "Ramanathan S. Thinniyam"], "title": "Checking Consistency of Event-driven Traces", "comment": null, "summary": "Event-driven programming is a popular paradigm where the flow of execution is\ncontrolled by two features: (1) shared memory and (2) sending and receiving of\nmessages between multiple handler threads (just called handler). Each handler\nhas a mailbox (modelled as a queue) for receiving messages, with the constraint\nthat the handler processes its messages sequentially. Executions of messages by\ndifferent handlers may be interleaved. A central problem in this setting is\nchecking whether a candidate execution is consistent with the semantics of\nevent-driven programs. In this paper, we propose an axiomatic semantics for\neventdriven programs based on the standard notion of traces (also known as\nexecution graphs). We prove the equivalence of axiomatic and operational\nsemantics. This allows us to rephrase the consistency problem axiomatically,\nresulting in the event-driven consistency problem: checking whether a given\ntrace is consistent. We analyze the computational complexity of this problem\nand show that it is NP-complete, even when the number of handler threads is\nbounded. We then identify a tractable fragment: in the absence of nested\nposting, where handlers do not post new messages while processing a message,\nconsistency checking can be performed in polynomial time. Finally, we implement\nour approach in a prototype tool and report on experimental results on a wide\nrange of benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e8b\u4ef6\u9a71\u52a8\u7a0b\u5e8f\u7684\u4e00\u81f4\u6027\u516c\u7406\u5316\u8bed\u4e49\uff0c\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u5176\u4e0e\u64cd\u4f5c\u8bed\u4e49\u7684\u7b49\u4ef7\u6027\uff0c\u5e76\u5c06\u6267\u884c\u4e00\u81f4\u6027\u5224\u5b9a\u8f6c\u5316\u4e3a\u516c\u7406\u5316\u5224\u5b9a\uff0c\u5206\u6790\u5f97\u51fa\u95ee\u9898NP-\u5b8c\u5168\uff0c\u4f46\u5728\u65e0\u5d4c\u5957post\u65f6\u53ef\u591a\u9879\u5f0f\u89e3\u51b3\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u4e8b\u4ef6\u9a71\u52a8\u7f16\u7a0b\u5728\u5e76\u53d1\u7a0b\u5e8f\u4e2d\u975e\u5e38\u5e38\u89c1\uff0c\u4f46\u5982\u4f55\u9a8c\u8bc1\u7a0b\u5e8f\u6267\u884c\u7684\u5408\u6cd5\u6027\uff08\u5373\u6267\u884c\u662f\u5426\u4e0e\u8bed\u4e49\u4e00\u81f4\uff09\u4ecd\u7136\u662f\u4e00\u4e2a\u6838\u5fc3\u96be\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u64cd\u4f5c\u8bed\u4e49\u8fdb\u884c\u5206\u6790\uff0c\u7f3a\u4e4f\u901a\u7528\u7684\u516c\u7406\u5316\u6846\u67b6\u3002\u672c\u6587\u5e0c\u671b\u901a\u8fc7\u516c\u7406\u5316\u7684\u89c6\u89d2\u66f4\u672c\u8d28\u5730\u523b\u753b\u4e00\u81f4\u6027\u95ee\u9898\u53ca\u5176\u590d\u6742\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u4e8b\u4ef6\u9a71\u52a8\u7a0b\u5e8f\u7684\u516c\u7406\u5316\u8bed\u4e49\uff08\u57fa\u4e8etrace/execution graph\uff09\uff0c\u5e76\u4e25\u683c\u8bc1\u660e\u4e86\u5176\u4e0e\u64cd\u4f5c\u8bed\u4e49\u7684\u7b49\u4ef7\u6027\u3002\u57fa\u4e8e\u8be5\u8bed\u4e49\uff0c\u5c06\u6267\u884c\u4e00\u81f4\u6027\u5224\u5b9a\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u516c\u7406\u5316\u5224\u65ad\u95ee\u9898\uff0c\u5e76\u5206\u6790\u4e86\u5176\u8ba1\u7b97\u590d\u6742\u6027\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86\u5728\u65e0\u5d4c\u5957post\u7684\u60c5\u51b5\u4e0b\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u5224\u5b9a\u7b97\u6cd5\uff0c\u5e76\u7ed3\u5408\u539f\u578b\u5de5\u5177\u5728\u4e00\u7cfb\u5217\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\u3002", "result": "\u4e00\u81f4\u6027\u5224\u5b9a\u95ee\u9898\u5728\u4e00\u822c\u60c5\u51b5\u4e0b\u662fNP-\u5b8c\u5168\u7684\uff0c\u5373\u4f7f\u9650\u5236handler\u7ebf\u7a0b\u6570\u3002\u4f46\u5728\u4e0d\u5141\u8bb8\u5d4c\u5957\u6d88\u606f\u6295\u9012\u65f6\uff0c\u53ef\u4ee5\u591a\u9879\u5f0f\u65f6\u95f4\u89e3\u51b3\u3002\u6b64\u5916\uff0c\u539f\u578b\u5de5\u5177\u5728\u5b9e\u9a8c\u4e2d\u80fd\u6709\u6548\u5904\u7406\u591a\u79cd\u57fa\u51c6\u6848\u4f8b\u3002", "conclusion": "\u672c\u6587\u7cfb\u7edf\u6027\u5730\u63d0\u51fa\u4e86\u4e8b\u4ef6\u9a71\u52a8\u7a0b\u5e8f\u7684\u4e00\u822c\u516c\u7406\u5316\u8bed\u4e49\u53ca\u5176\u5728\u6267\u884c\u4e00\u81f4\u6027\u5224\u5b9a\u4e2d\u7684\u5e94\u7528\uff0c\u4e0d\u4ec5\u7406\u8bba\u4e0a\u9610\u660e\u4e86\u95ee\u9898\u7684\u590d\u6742\u6027\u8fb9\u754c\uff0c\u8fd8\u4e3a\u5b9e\u9645\u7a0b\u5e8f\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5224\u5b9a\u5de5\u5177\u3002"}}
{"id": "2508.06718", "categories": ["cs.SE", "K.6.3; D.2.7"], "pdf": "https://arxiv.org/pdf/2508.06718", "abs": "https://arxiv.org/abs/2508.06718", "authors": ["Daniel Ogenrwot", "John Businge"], "title": "Refactoring-Aware Patch Integration Across Structurally Divergent Java Forks", "comment": "12 pages, 3 figures", "summary": "While most forks on platforms like GitHub are short-lived and used for social\ncollaboration, a smaller but impactful subset evolve into long-lived forks,\nreferred to here as variants, that maintain independent development\ntrajectories. Integrating bug-fix patches across such divergent variants poses\nchallenges due to structural drift, including refactorings that rename,\nrelocate, or reorganize code elements and obscure semantic correspondence. This\npaper presents an empirical study of patch integration failures in 14 divergent\npair of variants and introduces RePatch, a refactoring-aware integration system\nfor Java repositories. RePatch extends the RefMerge framework, originally\ndesigned for symmetric merges, by supporting asymmetric patch transfer. RePatch\ninverts refactorings in both the source and target to realign the patch\ncontext, applies the patch, and replays the transformations to preserve the\nintent of the variant. In our evaluation of 478 bug-fix pull requests, Git\ncherry-pick fails in 64.4% of cases due to structural misalignments, while\nRePatch successfully integrates 52.8% of the previously failing patches. These\nresults highlight the limitations of syntax-based tools and the need for\nsemantic reasoning in variant-aware patch propagation.", "AI": {"tldr": "\u8bba\u6587\u9488\u5bf9 GitHub \u4e0a\u957f\u671f\u7ef4\u62a4\u7684\u4ee3\u7801\u53d8\u4f53\u95f4\u7684\u8865\u4e01\u96c6\u6210\u96be\u9898\uff0c\u63d0\u51fa Refactoring \u611f\u77e5\u7684 RePatch \u7cfb\u7edf\uff0c\u53ef\u5927\u5e45\u63d0\u5347\u8de8\u53d8\u4f53\u8865\u4e01\u4f20\u9012\u6210\u529f\u7387\uff0c\u51f8\u663e\u8bed\u4e49\u63a8\u7406\u5728\u5b9e\u9645\u5de5\u7a0b\u4e2d\u7684\u5fc5\u8981\u6027\u3002", "motivation": "Github \u4e0a\u5b58\u5728\u90e8\u5206\u957f\u671f\u7ef4\u62a4\u4e14\u72ec\u7acb\u53d1\u5c55\u7684\u4ee3\u7801\u5206\u652f\uff08\u53d8\u4f53\uff09\uff0c\u8fd9\u4e9b\u53d8\u4f53\u4e4b\u95f4\u7531\u4e8e\u91cd\u6784\u7b49\u539f\u56e0\u5bfc\u81f4\u7ed3\u6784\u6f02\u79fb\uff0c\u4f20\u7edf\u57fa\u4e8e\u8bed\u6cd5\u7684\u8865\u4e01\u96c6\u6210\u65b9\u5f0f\u9762\u4e34\u5de8\u5927\u6311\u6218\uff0c\u56e0\u6b64\u4e9f\u9700\u65b0\u65b9\u6cd5\u6765\u5e94\u5bf9\u8865\u4e01\u96c6\u6210\u5931\u8d25\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86 RePatch \u7cfb\u7edf\uff0c\u901a\u8fc7\u9006\u8f6c\u91cd\u6784\u548c\u91cd\u64ad\u53d8\u6362\uff0c\u652f\u6301\u5728 Java \u4ed3\u5e93\u4e2d\u53d8\u4f53\u95f4\u7684\u8865\u4e01\u4f20\u9012\uff0c\u6269\u5c55\u4e86\u539f\u6709 RefMerge \u6846\u67b6\u4ee5\u9002\u914d\u975e\u5bf9\u79f0\u8865\u4e01\u96c6\u6210\u3002", "result": "\u5728 478 \u4e2a bug-fix pull request \u7684\u8bc4\u6d4b\u4e2d\uff0cGit \u7684 cherry-pick \u65b9\u6cd5\u56e0\u7ed3\u6784\u5bf9\u9f50\u4e0d\u4e00\u81f4\u5bfc\u81f4 64.4% \u5931\u8d25\uff0c\u800c RePatch \u7cfb\u7edf\u80fd\u591f\u6210\u529f\u96c6\u6210\u5176\u4e2d 52.8% \u539f\u672c\u5931\u8d25\u7684\u8865\u4e01\uff0c\u663e\u8457\u63d0\u5347\u4e86\u53d8\u4f53\u95f4\u8865\u4e01\u4f20\u64ad\u7684\u6548\u679c\u3002", "conclusion": "\u8bed\u6cd5\u57fa\u7840\u5de5\u5177\u5728\u7ba1\u7406\u4ee3\u7801\u53d8\u4f53\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u901a\u8fc7\u8bed\u4e49\u63a8\u7406\u63d0\u9ad8\u8865\u4e01\u96c6\u6210\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2508.06495", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.06495", "abs": "https://arxiv.org/abs/2508.06495", "authors": ["Juliana Resplande Sant'anna Gomes", "Arlindo Rodrigues Galv\u00e3o Filho"], "title": "Semi-automated Fact-checking in Portuguese: Corpora Enrichment using Retrieval with Claim extraction", "comment": "Master Thesis in Computer Science at Federal University on Goias\n  (UFG). Written in Portuguese", "summary": "The accelerated dissemination of disinformation often outpaces the capacity\nfor manual fact-checking, highlighting the urgent need for Semi-Automated\nFact-Checking (SAFC) systems. Within the Portuguese language context, there is\na noted scarcity of publicly available datasets that integrate external\nevidence, an essential component for developing robust AFC systems, as many\nexisting resources focus solely on classification based on intrinsic text\nfeatures. This dissertation addresses this gap by developing, applying, and\nanalyzing a methodology to enrich Portuguese news corpora (Fake.Br, COVID19.BR,\nMuMiN-PT) with external evidence. The approach simulates a user's verification\nprocess, employing Large Language Models (LLMs, specifically Gemini 1.5 Flash)\nto extract the main claim from texts and search engine APIs (Google Search API,\nGoogle FactCheck Claims Search API) to retrieve relevant external documents\n(evidence). Additionally, a data validation and preprocessing framework,\nincluding near-duplicate detection, is introduced to enhance the quality of the\nbase corpora.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u641c\u7d22\u5f15\u64ceAPI\u4e3a\u8461\u8404\u7259\u8bed\u65b0\u95fb\u6570\u636e\u96c6\u589e\u5f3a\u5916\u90e8\u8bc1\u636e\u7684\u65b9\u6cd5\uff0c\u5e76\u5efa\u7acb\u4e86\u5b8c\u5584\u7684\u6570\u636e\u5904\u7406\u6d41\u7a0b\uff0c\u4e3a\u8461\u8bed\u534a\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u53d1\u5c55\u63d0\u4f9b\u5173\u952e\u652f\u6301\u3002", "motivation": "\u5f53\u524d\u5047\u4fe1\u606f\u4f20\u64ad\u901f\u5ea6\u8fdc\u8d85\u4eba\u5de5\u6838\u67e5\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u8461\u8404\u7259\u8bed\u73af\u5883\u4e0b\uff0c\u7f3a\u4e4f\u7ed3\u5408\u5916\u90e8\u8bc1\u636e\u7684\u516c\u5f00\u6570\u636e\u96c6\uff0c\u5236\u7ea6\u4e86\u534a\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u7684\u53d1\u5c55\u3002\u8bb8\u591a\u73b0\u6709\u8d44\u6e90\u4ec5\u57fa\u4e8e\u6587\u672c\u5185\u5728\u7279\u5f81\u8fdb\u884c\u5206\u7c7b\uff0c\u672a\u5229\u7528\u5916\u90e8\u8bc1\u636e\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u65bd\u4e86\u4e00\u79cd\u80fd\u591f\u4e3a\u8461\u8404\u7259\u8bed\u65b0\u95fb\u8bed\u6599\uff08\u5982Fake.Br\u3001COVID19.BR\u3001MuMiN-PT\uff09\u6dfb\u52a0\u5916\u90e8\u8bc1\u636e\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u6a21\u62df\u7528\u6237\u9a8c\u8bc1\u8fc7\u7a0b\uff0c\u8fd0\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982Gemini 1.5 Flash\uff09\u63d0\u53d6\u6587\u672c\u4e3b\u5f20\uff0c\u5e76\u5229\u7528\u641c\u7d22\u5f15\u64ceAPI\uff08Google Search API, Google FactCheck Claims Search API\uff09\u68c0\u7d22\u76f8\u5173\u5916\u90e8\u6587\u6863\u3002\u53e6\u8bbe\u6570\u636e\u9a8c\u8bc1\u548c\u9884\u5904\u7406\u6846\u67b6\uff0c\u5305\u62ec\u8fd1\u91cd\u590d\u68c0\u6d4b\uff0c\u4ee5\u63d0\u5347\u8bed\u6599\u8d28\u91cf\u3002", "result": "\u6210\u529f\u5f00\u53d1\u4e86\u4e30\u5bcc\u8461\u8404\u7259\u8bed\u65b0\u95fb\u6570\u636e\u96c6\u7684\u6280\u672f\u65b9\u6848\uff0c\u5c06\u62bd\u53d6\u4e3b\u5f20\u4e0e\u5916\u90e8\u8bc1\u636e\u6709\u673a\u6574\u5408\uff0c\u5e76\u63d0\u9ad8\u4e86\u6570\u636e\u96c6\u7684\u8d28\u91cf\uff1b\u4e3a\u6784\u5efa\u66f4\u5065\u58ee\u7684\u534a\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u901a\u8fc7\u5916\u90e8\u8bc1\u636e\u6574\u5408\u548c\u6570\u636e\u8d28\u91cf\u63d0\u5347\uff0c\u586b\u8865\u4e86\u8461\u8404\u7259\u8bed\u4e8b\u5b9e\u6838\u67e5\u6570\u636e\u8d44\u6e90\u7684\u7a7a\u767d\uff0c\u4f7f\u8461\u8bed\u8bed\u5883\u4e0b\u7684\u534a\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u5efa\u8bbe\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2508.06879", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.06879", "abs": "https://arxiv.org/abs/2508.06879", "authors": ["Michael Dorner", "Andreas Bauer", "Darja \u0160mite", "Lukas Thode", "Daniel Mendez", "Ricardo Britto", "Stephan Lukasczyk", "Ehsan Zabardast", "Michael Kormann"], "title": "Quo Vadis, Code Review? Exploring the Future of Code Review", "comment": null, "summary": "Code review has long been a core practice in collaborative software\nengineering. In this research, we explore how practitioners reflect on code\nreview today and what changes they anticipate in the near future. We then\ndiscuss the potential long-term risks of these anticipated changes for the\nevolution of code review and its role in collaborative software engineering.", "AI": {"tldr": "\u672c\u6587\u8c03\u67e5\u4e86\u5f53\u524d\u4e1a\u754c\u5bf9\u4ee3\u7801\u5ba1\u67e5\u7684\u8ba4\u77e5\u53ca\u672a\u6765\u53d1\u5c55\u9884\u671f\uff0c\u5206\u6790\u4e86\u8fd9\u4e9b\u53d8\u9769\u53ef\u80fd\u5e26\u6765\u7684\u957f\u671f\u98ce\u9669\uff0c\u5bf9\u4ee3\u7801\u5ba1\u67e5\u5b9e\u8df5\u7684\u672a\u6765\u6f14\u8fdb\u63d0\u51fa\u4e86\u8b66\u793a\u4e0e\u5efa\u8bae\u3002", "motivation": "\u4ee3\u7801\u5ba1\u67e5\u4f5c\u4e3a\u534f\u540c\u8f6f\u4ef6\u5de5\u7a0b\u7684\u6838\u5fc3\u5b9e\u8df5\uff0c\u5df2\u6709\u591a\u5e74\u5386\u53f2\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76\u5f53\u524d\u4ece\u4e1a\u8005\u5bf9\u4ee3\u7801\u5ba1\u67e5\u7684\u53cd\u601d\u4ee5\u53ca\u4ed6\u4eec\u5bf9\u672a\u6765\u8be5\u5b9e\u8df5\u53d8\u5316\u7684\u9884\u671f\u3002", "method": "\u901a\u8fc7\u8c03\u67e5\u3001\u8bbf\u8c08\u6216\u6570\u636e\u5206\u6790\u7b49\u65b9\u5f0f\u6536\u96c6\u5b9e\u9645\u4ece\u4e1a\u8005\u5bf9\u4ee3\u7801\u5ba1\u67e5\u73b0\u72b6\u53ca\u672a\u6765\u53d1\u5c55\u7684\u89c2\u70b9\u3002", "result": "\u63ed\u793a\u4e86\u4e1a\u754c\u5bf9\u4ee3\u7801\u5ba1\u67e5\u7684\u73b0\u72b6\u53cd\u601d\u548c\u5bf9\u672a\u6765\u53d8\u5316\u7684\u9884\u671f\uff0c\u5e76\u603b\u7ed3\u8fd9\u4e9b\u53d8\u5316\u53ef\u80fd\u5e26\u6765\u7684\u957f\u671f\u98ce\u9669\u3002", "conclusion": "\u7814\u7a76\u4e0d\u4ec5\u5c55\u73b0\u4e86\u4ee3\u7801\u5ba1\u67e5\u5728\u4e1a\u754c\u7684\u8ba4\u77e5\u548c\u53d1\u5c55\u8d8b\u52bf\uff0c\u8fd8\u63d0\u9192\u76f8\u5173\u65b9\u6ce8\u610f\u672a\u6765\u6f14\u53d8\u53ef\u80fd\u5bfc\u81f4\u7684\u98ce\u9669\uff0c\u4fc3\u8fdb\u66f4\u597d\u5730\u5f15\u5bfc\u5b9e\u8df5\u6f14\u8fdb\u3002"}}
{"id": "2508.06504", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06504", "abs": "https://arxiv.org/abs/2508.06504", "authors": ["Yao Ge", "Sudeshna Das", "Yuting Guo", "Abeed Sarker"], "title": "Retrieval augmented generation based dynamic prompting for few-shot biomedical named entity recognition using large language models", "comment": "31 pages, 4 figures, 15 tables", "summary": "Biomedical named entity recognition (NER) is a high-utility natural language\nprocessing (NLP) task, and large language models (LLMs) show promise\nparticularly in few-shot settings (i.e., limited training data). In this\narticle, we address the performance challenges of LLMs for few-shot biomedical\nNER by investigating a dynamic prompting strategy involving retrieval-augmented\ngeneration (RAG). In our approach, the annotated in-context learning examples\nare selected based on their similarities with the input texts, and the prompt\nis dynamically updated for each instance during inference. We implemented and\noptimized static and dynamic prompt engineering techniques and evaluated them\non five biomedical NER datasets. Static prompting with structured components\nincreased average F1-scores by 12% for GPT-4, and 11% for GPT-3.5 and LLaMA\n3-70B, relative to basic static prompting. Dynamic prompting further improved\nperformance, with TF-IDF and SBERT retrieval methods yielding the best results,\nimproving average F1-scores by 7.3% and 5.6% in 5-shot and 10-shot settings,\nrespectively. These findings highlight the utility of contextually adaptive\nprompts via RAG for biomedical NER.", "AI": {"tldr": "\u5229\u7528\u52a8\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684Prompt\u6280\u672f\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5c11\u6837\u672c\u751f\u7269\u533b\u5b66NER\u4e2d\u7684\u8bc6\u522b\u51c6\u786e\u7387\u3002", "motivation": "\u751f\u7269\u533b\u5b66\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08NER\uff09\u4efb\u52a1\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u6781\u5177\u4ef7\u503c\uff0c\u4f46\u5728\u8bad\u7ec3\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6027\u80fd\u5c1a\u6709\u6311\u6218\u3002\u8be5\u6587\u65e8\u5728\u89e3\u51b3LLM\u5728\u5c11\u6837\u672c\u751f\u7269\u533b\u5b66NER\u4e0b\u7684\u8868\u73b0\u74f6\u9888\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u52a8\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u63d0\u793a\u7b56\u7565\uff0c\u901a\u8fc7\u4e0e\u8f93\u5165\u6587\u672c\u76f8\u4f3c\u6027\u9009\u53d6\u5df2\u6807\u6ce8\u4e0a\u4e0b\u6587\u4f8b\u5b50\uff0c\u5e76\u5728\u63a8\u7406\u65f6\u4e3a\u6bcf\u4e2a\u5b9e\u4f8b\u52a8\u6001\u66f4\u65b0Prompt\u3002\u540c\u65f6\u5f00\u53d1\u548c\u4f18\u5316\u4e86\u9759\u6001\u4e0e\u52a8\u6001Prompt\u5de5\u7a0b\uff0c\u5728\u4e94\u4e2a\u751f\u7269\u533b\u5b66NER\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7ed3\u6784\u5316\u9759\u6001Prompt\u5c06GPT-4\u7684\u5e73\u5747F1\u5206\u63d0\u5347\u4e8612%\uff0cGPT-3.5\u548cLLaMA 3-70B\u63d0\u5347\u4e8611%\u3002\u52a8\u6001Prompt\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\uff0cTF-IDF\u548cSBERT\u68c0\u7d22\u65b9\u6cd5\u57285-shot\u548c10-shot\u4e0b\u5206\u522b\u63d0\u9ad8\u5e73\u5747F1\u52067.3%\u548c5.6%\u3002", "conclusion": "\u52a8\u6001\u3001\u8bed\u5883\u81ea\u9002\u5e94\u7684Prompt\uff08\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5b9e\u73b0\uff09\u80fd\u591f\u663e\u8457\u63d0\u5347LLM\u5728\u751f\u7269\u533b\u5b66NER\u5c11\u6837\u672c\u573a\u666f\u4e0b\u7684\u8868\u73b0\u3002"}}
{"id": "2508.07779", "categories": ["cs.FL", "68Q45, 52C20, 68U05, 68U10", "F.1.1"], "pdf": "https://arxiv.org/pdf/2508.07779", "abs": "https://arxiv.org/abs/2508.07779", "authors": ["Deepalakshmi D", "Lisa Mathew"], "title": "Hexagonal Picture Scanning Automata", "comment": "9 pages, 2 figures, 2 tables", "summary": "Two new classes of finite automata, called General hexagonal Boustrophedon\nfinite automata and General hexagonal returning finite automata operating on\nhexagonal grids, are introduced and analyzed. The work establishes the\ntheoretical foundations for these automata models, examines their computational\nproperties, and investigates the relationships and equivalences between the\nlanguage families they define. The research contributes to the broader\nunderstanding of two-dimensional automata theory by extending classical finite\nautomaton concepts to hexagonal geometric structures with specialized traversal\npatterns.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u7cfb\u7edf\u5206\u6790\u4e86\u7528\u4e8e\u516d\u8fb9\u5f62\u7f51\u683c\u7684\u4e24\u7c7b\u65b0\u578b\u6709\u9650\u81ea\u52a8\u673a\uff0c\u4e30\u5bcc\u4e86\u4e8c\u7ef4\u81ea\u52a8\u673a\u7406\u8bba\uff0c\u5e76\u63ed\u793a\u4e86\u5176\u5728\u8bed\u8a00\u8bc6\u522b\u548c\u7ed3\u6784\u904d\u5386\u4e0a\u7684\u65b0\u7279\u6027\u53ca\u7406\u8bba\u5173\u7cfb\u3002", "motivation": "\u4f20\u7edf\u6709\u9650\u81ea\u52a8\u673a\u4e3b\u8981\u57fa\u4e8e\u7ebf\u6027\u7ed3\u6784\uff0c\u4e8c\u7ef4\u81ea\u52a8\u673a\u7406\u8bba\u4e0d\u65ad\u53d1\u5c55\uff0c\u4f46\u5728\u516d\u8fb9\u5f62\u7f51\u683c\u4e0a\u8fd0\u884c\u7684\u81ea\u52a8\u673a\u6a21\u578b\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002\u7814\u7a76\u8005\u5e0c\u671b\u6269\u5c55\u81ea\u52a8\u673a\u7406\u8bba\u5230\u66f4\u590d\u6742\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u4ee5\u652f\u6301\u7279\u6b8a\u7684\u904d\u5386\u6a21\u5f0f\u548c\u7406\u8bba\u5206\u6790\u3002", "method": "\u63d0\u51fa\u5e76\u5206\u6790\u4e86\u4e24\u7c7b\u65b0\u7684\u6709\u9650\u81ea\u52a8\u673a\uff1a\u666e\u901a\u516d\u8fb9\u5f62\u5f80\u8fd4\u578b\u6709\u9650\u81ea\u52a8\u673a\u548c\u666e\u901a\u516d\u8fb9\u5f62\u56de\u8fd4\u578b\u6709\u9650\u81ea\u52a8\u673a\u3002\u8fd9\u4e9b\u81ea\u52a8\u673a\u5728\u516d\u8fb9\u5f62\u7f51\u683c\u4e0a\u8fd0\u884c\uff0c\u8bba\u6587\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u548c\u6a21\u578b\u5b9a\u4e49\u5206\u6790\u4e86\u5176\u8ba1\u7b97\u6027\u8d28\u3001\u8fd0\u884c\u6a21\u5f0f\uff0c\u5e76\u63a2\u8ba8\u4e86\u8fd9\u4e9b\u81ea\u52a8\u673a\u6240\u5b9a\u4e49\u7684\u8bed\u8a00\u65cf\u4e4b\u95f4\u7684\u5173\u7cfb\u4e0e\u7b49\u4ef7\u6027\u3002", "result": "\u8bba\u6587\u5efa\u7acb\u4e86\u8fd9\u4e24\u7c7b\u81ea\u52a8\u673a\u7684\u7406\u8bba\u57fa\u7840\uff0c\u660e\u786e\u4e86\u5176\u64cd\u4f5c\u548c\u7279\u6027\u3002\u5206\u6790\u4e86\u5b83\u4eec\u4e4b\u95f4\u8bed\u8a00\u8868\u8fbe\u80fd\u529b\u7684\u5173\u7cfb\uff0c\u63d0\u51fa\u4e86\u82e5\u5e72\u7b49\u4ef7\u6027\u548c\u5dee\u5f02\uff0c\u4e3a\u540e\u7eed\u7684\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002", "conclusion": "\u516d\u8fb9\u5f62\u7f51\u683c\u4e0a\u7684\u6709\u9650\u81ea\u52a8\u673a\u62d3\u5c55\u4e86\u4e8c\u7ef4\u81ea\u52a8\u673a\u7406\u8bba\u7684\u8fb9\u754c\uff0c\u5c55\u73b0\u4e86\u65b0\u7684\u8ba1\u7b97\u80fd\u529b\u548c\u8bed\u8a00\u5904\u7406\u65b9\u6cd5\uff0c\u5bf9\u4e8e\u7406\u89e3\u548c\u5206\u6790\u590d\u6742\u51e0\u4f55\u904d\u5386\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2508.07174", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.07174", "abs": "https://arxiv.org/abs/2508.07174", "authors": ["Rongshuan Geng", "Wantao Ning"], "title": "On the fault diameter and wide diameter of the exchanged 3-ary $n$-cube", "comment": null, "summary": "Fault diameter and wide diameter are two critical parameters for evaluating\ncommunication performance in interconnection networks. They measure the fault\ntolerance and transmission efficiency of networks. The exchanged 3-ary $n$-cube\nis a recently proposed variant of the hypercube, denoted by $E3C(r, s, t)$. In\nthis work, we obtain that the $(2r + 1)$-fault diameter and $(2r + 2)$-wide\ndiameter of $E3C(r, s, t)$ are bounded between $n + 3$ and $n + 5$ for $1 \\leq\nr \\leq s \\leq t$.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u4ea4\u63623\u5143n\u7ef4\u7acb\u65b9\u4f53E3C(r, s, t)\u7f51\u7edc\uff0c\u5229\u7528\u7406\u8bba\u5206\u6790\u65b9\u6cd5\u5f97\u5230\u4e86\u5176\u5173\u952e\u53c2\u6570\uff08\u6545\u969c\u76f4\u5f84\u4e0e\u5e7f\u4e49\u76f4\u5f84\uff09\u7684\u754c\u9650\uff0c\u4e3a\u7f51\u7edc\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53c2\u8003\u3002", "motivation": "\u5728\u4e92\u8fde\u7f51\u7edc\u4e2d\uff0c\u8bc4\u4f30\u901a\u4fe1\u6027\u80fd\u975e\u5e38\u5173\u952e\uff0c\u5176\u4e2d\u6545\u969c\u76f4\u5f84\u548c\u5e7f\u4e49\u76f4\u5f84\u662f\u8861\u91cf\u7f51\u7edc\u5bb9\u9519\u6027\u548c\u4f20\u8f93\u6548\u7387\u7684\u91cd\u8981\u53c2\u6570\u3002\u672c\u6587\u5173\u6ce8\u4e8e\u4e00\u79cd\u65b0\u63d0\u51fa\u7684\u7f51\u7edc\u7ed3\u6784\u2014\u2014\u4ea4\u63623\u5143n\u7ef4\u7acb\u65b9\u4f53\uff08E3C\uff09\uff0c\u5e0c\u671b\u5206\u6790\u5176\u76f8\u5173\u7f51\u7edc\u53c2\u6570\u3002", "method": "\u4f5c\u8005\u9488\u5bf9\u4ea4\u63623\u5143n\u7ef4\u7acb\u65b9\u4f53E3C(r, s, t)\u7f51\u7edc\u6a21\u578b\uff0c\u7814\u7a76\u4e86\u8be5\u7ed3\u6784\u7684\u6545\u969c\u76f4\u5f84\u4e0e\u5e7f\u4e49\u76f4\u5f84\u95ee\u9898\uff0c\u786e\u5b9a\u4e86\u5176\u5177\u4f53\u7684\u53d6\u503c\u533a\u95f4\u3002\u91c7\u7528\u4e86\u56fe\u8bba\u548c\u7ec4\u5408\u6570\u5b66\u65b9\u6cd5\u5bf9\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\u548c\u63a8\u5bfc\u3002", "result": "\u4f5c\u8005\u5f97\u51fa\u4e86E3C(r, s, t)\u7684(2r+1)-\u6545\u969c\u76f4\u5f84\u548c(2r+2)-\u5e7f\u4e49\u76f4\u5f84\u5747\u6709\u660e\u786e\u7684\u4e0a\u4e0b\u754c\uff1an+3\u5230n+5\uff0c\u5176\u4e2d1\u2264r\u2264s\u2264t\u3002", "conclusion": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u4e3aE3C(r, s, t)\u7684\u5bb9\u9519\u6027\u548c\u901a\u4fe1\u6548\u7387\u63d0\u4f9b\u4e86\u91cf\u5316\u7684\u754c\u9650\uff0c\u6709\u52a9\u4e8e\u8be5\u7f51\u7edc\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8bbe\u8ba1\u4e0e\u8bc4\u4ef7\u3002"}}
{"id": "2508.07310", "categories": ["cs.DM"], "pdf": "https://arxiv.org/pdf/2508.07310", "abs": "https://arxiv.org/abs/2508.07310", "authors": ["Kittiphon Phalakarn", "Kittiphop Phalakarn", "Vorapong Suppakitpaisarn"], "title": "Optimal Representation for Right-to-Left Parallel Scalar Point Multiplication", "comment": null, "summary": "This paper introduces an optimal representation for a right-to-left parallel\nelliptic curve scalar point multiplication. The right-to-left approach is\neasier to parallelize than the conventional left-to-right approach. However,\nunlike the left-to-right approach, there is still no work considering number\nrepresentations for the right-to-left parallel calculation. By simplifying the\nimplementation by Robert, we devise a mathematical model to capture the\ncomputation time of the calculation. Then, for any arbitrary amount of doubling\ntime and addition time, we propose algorithms to generate representations which\nminimize the time in that model. As a result, we can show a negative result\nthat a conventional representation like NAF is almost optimal. The parallel\ncomputation time obtained from any representation cannot be better than NAF by\nmore than 1%.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u53f3\u5230\u5de6\u5e76\u884c\u692d\u5706\u66f2\u7ebf\u6807\u91cf\u4e58\u6cd5\uff0c\u63d0\u51fa\u5e76\u5206\u6790\u4e86\u6700\u4f18\u6570\u8868\u793a\u65b9\u6cd5\uff0c\u53d1\u73b0\u4f20\u7edfNAF\u5df2\u51e0\u4e4e\u8fbe\u6700\u4f18\uff0c\u65b0\u8868\u793a\u65b9\u6cd5\u63d0\u5347\u7a7a\u95f4\u4e0d\u52301%\u3002", "motivation": "\u53f3\u5230\u5de6\u5e76\u884c\u692d\u5706\u66f2\u7ebf\u6807\u91cf\u4e58\u6cd5\u867d\u7136\u66f4\u6613\u5e76\u884c\uff0c\u4f46\u4e4b\u524d\u7f3a\u5c11\u9488\u5bf9\u8be5\u7b97\u6cd5\u7684\u6570\u8868\u793a\u4f18\u5316\u7814\u7a76\uff0c\u672c\u6587\u5f25\u8865\u4e86\u6b64\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u7b80\u5316Robert\u7684\u5b9e\u73b0\uff0c\u5efa\u7acb\u4e86\u6570\u5b66\u6a21\u578b\u6765\u5206\u6790\u8ba1\u7b97\u65f6\u95f4\uff0c\u7136\u540e\u4e3a\u4efb\u610f\u52a0\u500d\u548c\u52a0\u6cd5\u65f6\u95f4\uff0c\u63d0\u51fa\u4e86\u751f\u6210\u6570\u8868\u793a\u7684\u7b97\u6cd5\u4ee5\u6700\u5c0f\u5316\u6a21\u578b\u4e2d\u7684\u65f6\u95f4\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u6539\u8fdb\u540e\u7684\u6570\u8868\u793a\u65b9\u6cd5\u5728\u63d0\u5347\u5e76\u884c\u8ba1\u7b97\u6027\u80fd\u4e0a\u975e\u5e38\u6709\u9650\uff0c\u4f20\u7edf\u7684NAF\u8868\u793a\u57fa\u672c\u5df2\u8fbe\u5230\u6700\u4f18\u3002", "conclusion": "\u4f20\u7edf\u7684NAF\u6570\u8868\u793a\u5728\u53f3\u5230\u5de6\u5e76\u884c\u692d\u5706\u66f2\u7ebf\u6807\u91cf\u4e58\u6cd5\u4e2d\u51e0\u4e4e\u662f\u6700\u4f18\u7684\uff0c\u4efb\u4f55\u65b0\u63d0\u51fa\u7684\u8868\u793a\u65b9\u6cd5\u5728\u5e76\u884c\u8ba1\u7b97\u65f6\u95f4\u4e0a\u63d0\u5347\u4e0d\u52301%\u3002"}}
{"id": "2508.06888", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.06888", "abs": "https://arxiv.org/abs/2508.06888", "authors": ["Fanyu Wang", "Chetan Arora", "Yonghui Liu", "Kaicheng Huang", "Chakkrit Tantithamthavorn", "Aldeida Aleti", "Dishan Sambathkumar", "David Lo"], "title": "Multi-Modal Requirements Data-based Acceptance Criteria Generation using LLMs", "comment": null, "summary": "Acceptance criteria (ACs) play a critical role in software development by\nclearly defining the conditions under which a software feature satisfies\nstakeholder expectations. However, manually creating accurate, comprehensive,\nand unambiguous acceptance criteria is challenging, particularly in user\ninterface-intensive applications, due to the reliance on domain-specific\nknowledge and visual context that is not always captured by textual\nrequirements alone. To address these challenges, we propose RAGcceptance M2RE,\na novel approach that leverages Retrieval-Augmented Generation (RAG) to\ngenerate acceptance criteria from multi-modal requirements data, including both\ntextual documentation and visual UI information. We systematically evaluated\nour approach in an industrial case study involving an education-focused\nsoftware system used by approximately 100,000 users. The results indicate that\nintegrating multi-modal information significantly enhances the relevance,\ncorrectness, and comprehensibility of the generated ACs. Moreover, practitioner\nevaluations confirm that our approach effectively reduces manual effort,\ncaptures nuanced stakeholder intent, and provides valuable criteria that domain\nexperts may overlook, demonstrating practical utility and significant potential\nfor industry adoption. This research underscores the potential of multi-modal\nRAG techniques in streamlining software validation processes and improving\ndevelopment efficiency. We also make our implementation and a dataset\navailable.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u5229\u7528\u591a\u6a21\u6001RAG\u65b9\u6cd5\u7ed3\u5408\u6587\u5b57\u548cUI\u4fe1\u606f\uff0c\u81ea\u52a8\u751f\u6210\u51c6\u786e\u3001\u5168\u9762\u7684\u9a8c\u6536\u6807\u51c6\u3002\u6848\u4f8b\u7814\u7a76\u8bc1\u5b9e\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u76f8\u5173\u6027\u548c\u6b63\u786e\u6027\uff0c\u51cf\u5c11\u4eba\u5de5\u53c2\u4e0e\uff0c\u5177\u6709\u884c\u4e1a\u63a8\u5e7f\u4ef7\u503c\uff0c\u5b9e\u73b0\u8f6f\u4ef6\u9a8c\u8bc1\u6d41\u7a0b\u667a\u80fd\u5316\u3002", "motivation": "\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\uff0c\u5236\u5b9a\u51c6\u786e\u3001\u5168\u9762\u4e14\u660e\u786e\u7684\u9a8c\u6536\u6807\u51c6\u5341\u5206\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u4f9d\u8d56\u9886\u57df\u77e5\u8bc6\u53ca\u89c6\u89c9\u8bed\u5883\uff0c\u73b0\u6709\u57fa\u4e8e\u6587\u5b57\u7684\u9700\u6c42\u63cf\u8ff0\u5f88\u96be\u6ee1\u8db3\u590d\u6742\u7684\u7528\u6237\u754c\u9762\u5e94\u7528\u573a\u666f\u3002\u4eba\u5de5\u7f16\u5199\u9a8c\u6536\u6807\u51c6\u4e0d\u4ec5\u7e41\u7410\uff0c\u8fd8\u5bb9\u6613\u9057\u6f0f\u5173\u952e\u4fe1\u606f\uff0c\u56e0\u6b64\u4e9f\u9700\u81ea\u52a8\u5316\u3001\u667a\u80fd\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faRAGcceptance M2RE\u65b9\u6cd5\uff0c\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\uff0c\u5c06\u6587\u5b57\u6587\u6863\u4e0e\u89c6\u89c9UI\u4fe1\u606f\u7b49\u591a\u6a21\u6001\u9700\u6c42\u6570\u636e\u7ed3\u5408\uff0c\u81ea\u52a8\u751f\u6210\u9a8c\u6536\u6807\u51c6\uff0c\u5e76\u5728\u5b9e\u9645\u6559\u80b2\u7c7b\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u5f00\u5c55\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "result": "\u878d\u5408\u591a\u6a21\u6001\u4fe1\u606f\u80fd\u663e\u8457\u63d0\u5347\u751f\u6210\u7684\u9a8c\u6536\u6807\u51c6\u7684\u76f8\u5173\u6027\u3001\u6b63\u786e\u6027\u548c\u6613\u7406\u89e3\u6027\uff1b\u4e1a\u754c\u4f7f\u7528\u8005\u8bc4\u4ef7\u663e\u793a\u8be5\u65b9\u6cd5\u53ef\u6709\u6548\u964d\u4f4e\u4eba\u5de5\u5de5\u4f5c\u91cf\u3001\u66f4\u7cbe\u51c6\u6355\u6349\u5229\u76ca\u76f8\u5173\u65b9\u610f\u56fe\uff0c\u5e76\u8865\u5145\u9886\u57df\u4e13\u5bb6\u53ef\u80fd\u9057\u6f0f\u7684\u91cd\u8981\u6807\u51c6\u3002", "conclusion": "\u591a\u6a21\u6001RAG\u6280\u672f\u5728\u4f18\u5316\u8f6f\u4ef6\u9a8c\u6536\u6807\u51c6\u5236\u5b9a\u3001\u63d0\u5347\u5f00\u53d1\u6548\u7387\u3001\u964d\u4f4e\u4eba\u5de5\u6210\u672c\u65b9\u9762\u5177\u6709\u5b9e\u9645\u548c\u884c\u4e1a\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u63a8\u52a8\u8f6f\u4ef6\u9a8c\u8bc1\u6d41\u7a0b\u7684\u81ea\u52a8\u5316\u548c\u667a\u80fd\u5316\u3002"}}
{"id": "2508.06524", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06524", "abs": "https://arxiv.org/abs/2508.06524", "authors": ["Lei Jiang", "Fan Chen"], "title": "CarbonScaling: Extending Neural Scaling Laws for Carbon Footprint in Large Language Models", "comment": "8 pages", "summary": "Neural scaling laws have driven the development of increasingly large\nlanguage models (LLMs) by linking accuracy improvements to growth in parameter\ncount, dataset size, and compute. However, these laws overlook the carbon\nemissions that scale exponentially with LLM size. This paper presents\n\\textit{CarbonScaling}, an analytical framework that extends neural scaling\nlaws to incorporate both operational and embodied carbon in LLM training. By\nintegrating models for neural scaling, GPU hardware evolution, parallelism\noptimization, and carbon estimation, \\textit{CarbonScaling} quantitatively\nconnects model accuracy to carbon footprint. Results show that while a\npower-law relationship between accuracy and carbon holds, real-world\ninefficiencies significantly increase the scaling factor. Hardware technology\nscaling reduces carbon emissions for small to mid-sized models, but offers\ndiminishing returns for extremely large LLMs due to communication overhead and\nunderutilized GPUs. Training optimizations-especially aggressive critical batch\nsize scaling-help alleviate this inefficiency. \\textit{CarbonScaling} offers\nkey insights for training more sustainable and carbon-efficient LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCarbonScaling\u6846\u67b6\uff0c\u5c06\u78b3\u6392\u653e\u7eb3\u5165\u795e\u7ecf\u7f29\u653e\u5b9a\u5f8b\uff0c\u5206\u6790\u5927\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u78b3\u6548\u7387\u95ee\u9898\u3002\u7ed3\u679c\u663e\u793a\uff0c\u786c\u4ef6\u8fdb\u6b65\u548c\u8bad\u7ec3\u4f18\u5316\u53ef\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u964d\u4f4e\u78b3\u6392\u653e\uff0c\u4f46\u8d85\u5927\u6a21\u578b\u5e26\u6765\u7684\u901a\u8baf\u548c\u8d44\u6e90\u6d6a\u8d39\u4f7f\u5f97\u73af\u4fdd\u6536\u76ca\u9012\u51cf\uff0c\u6846\u67b6\u4e3a\u7eff\u8272AI\u5b9e\u8df5\u63d0\u4f9b\u4e86\u65b9\u5411\u3002", "motivation": "\u795e\u7ecf\u7f29\u653e\u5b9a\u5f8b\u63a8\u52a8\u4e86\u8d8a\u6765\u8d8a\u5927\u578b\u7684\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u4f46\u5ffd\u89c6\u4e86\u968f\u6a21\u578b\u89c4\u6a21\u589e\u5927\u800c\u5448\u6307\u6570\u589e\u957f\u7684\u78b3\u6392\u653e\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u8865\u5145\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e86CarbonScaling\u5206\u6790\u6846\u67b6\uff0c\u7ed3\u5408\u795e\u7ecf\u7f29\u653e\u3001GPU\u786c\u4ef6\u53d1\u5c55\u3001\u5e76\u884c\u4f18\u5316\u548c\u78b3\u4f30\u7b97\u7b49\u591a\u4e2a\u6a21\u578b\uff0c\u5b9a\u91cf\u5206\u6790\u6a21\u578b\u7cbe\u5ea6\u4e0e\u78b3\u6392\u653e\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u53d1\u73b0\u867d\u7136\u7cbe\u5ea6\u4e0e\u78b3\u6392\u653e\u4e4b\u95f4\u5b58\u5728\u5e42\u5f8b\u5173\u7cfb\uff0c\u4f46\u73b0\u5b9e\u4e2d\u7684\u5404\u79cd\u6548\u7387\u635f\u5931\u5927\u5e45\u63d0\u9ad8\u4e86\u7f29\u653e\u56e0\u5b50\u3002\u786c\u4ef6\u8fdb\u6b65\u5bf9\u5c0f\u578b\u548c\u4e2d\u578b\u6a21\u578b\u6709\u52a9\u4e8e\u51cf\u5c11\u78b3\u6392\u653e\uff0c\u5bf9\u8d85\u5927\u6a21\u578b\u6548\u679c\u6709\u9650\uff0c\u539f\u56e0\u662f\u901a\u4fe1\u548cGPU\u5229\u7528\u7387\u4e0b\u964d\u3002\u8bad\u7ec3\u4f18\u5316\u63aa\u65bd\u80fd\u90e8\u5206\u7f13\u89e3\u8be5\u95ee\u9898\u3002", "conclusion": "CarbonScaling\u6846\u67b6\u4e3a\u5b9e\u73b0\u66f4\u53ef\u6301\u7eed\u548c\u9ad8\u78b3\u6548\u7387\u7684LLM\u8bad\u7ec3\u63d0\u4f9b\u91cd\u8981\u6d1e\u89c1\uff0c\u6307\u5bfc\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u73af\u4fdd\u51b3\u7b56\u3002"}}
{"id": "2508.07207", "categories": ["cs.LO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07207", "abs": "https://arxiv.org/abs/2508.07207", "authors": ["S. Akshay", "A. R. Balasubramanian", "Supratik Chakraborty", "Georg Zetzsche"], "title": "Presburger Functional Synthesis: Complexity and Tractable Normal Forms", "comment": "Full version of conference paper at KR 2025 (22nd International\n  Conference on Principles of Knowledge Representation and Reasoning)", "summary": "Given a relational specification between inputs and outputs as a logic\nformula, the problem of functional synthesis is to automatically synthesize a\nfunction from inputs to outputs satisfying the relation. Recently, a rich line\nof work has emerged tackling this problem for specifications in different\ntheories, from Boolean to general first-order logic. In this paper, we launch\nan investigation of this problem for the theory of Presburger Arithmetic, that\nwe call Presburger Functional Synthesis (PFnS). We show that PFnS can be solved\nin EXPTIME and provide a matching exponential lower bound. This is unlike the\ncase for Boolean functional synthesis (BFnS), where only conditional\nexponential lower bounds are known. Further, we show that PFnS for one input\nand one output variable is as hard as BFnS in general. We then identify a\nspecial normal form, called PSyNF, for the specification formula that\nguarantees poly-time and poly-size solvability of PFnS. We prove several\nproperties of PSyNF, including how to check and compile to this form, and\nconditions under which any other form that guarantees poly-time solvability of\nPFnS can be compiled in poly-time to PSyNF. Finally, we identify a syntactic\nnormal form that is easier to check but is exponentially less succinct than\nPSyNF.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Presburger\u7b97\u672f\u4e0b\u7684\u529f\u80fd\u6027\u7efc\u5408\uff08PFnS\uff09\u95ee\u9898\uff0c\u8bc1\u660e\u5176\u4e3aEXPTIME\u590d\u6742\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u9ad8\u6548\u6c42\u89e3\u7684\u89c4\u8303\u5f62\u5f0fPSyNF\uff0c\u4e30\u5bcc\u4e86\u529f\u80fd\u6027\u7efc\u5408\u9886\u57df\u7684\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u8fd1\u5e74\u6765\u529f\u80fd\u6027\u7efc\u5408\u95ee\u9898\u5728\u4e0d\u540c\u7406\u8bba\uff08\u4ece\u5e03\u5c14\u5230\u4e00\u822c\u4e00\u9636\u903b\u8f91\uff09\u4e2d\u53d7\u5230\u5e7f\u6cdb\u5173\u6ce8\u3002\u672c\u6587\u5173\u6ce8\u5728Presburger\u7b97\u672f\u7406\u8bba\u4e0b\u7684\u529f\u80fd\u6027\u7efc\u5408\u95ee\u9898\uff0c\u65e8\u5728\u586b\u8865\u8be5\u9886\u57df\u7684\u7406\u8bba\u7a7a\u767d\u3002", "method": "\u4f5c\u8005\u63d0\u51faPresburger Functional Synthesis\uff08PFnS\uff09\u5e76\u5bf9\u5176\u590d\u6742\u6027\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\uff0c\u8bc1\u660ePFnS\u53ef\u5728EXPTIME\uff08\u6307\u6570\u65f6\u95f4\uff09\u5185\u6c42\u89e3\uff0c\u5e76\u6784\u5efa\u4e86\u5339\u914d\u7684\u6307\u6570\u4e0b\u754c\u3002\u4f5c\u8005\u8fdb\u4e00\u6b65\u63a2\u7d22\u5355\u8f93\u5165\u5355\u8f93\u51fa\u60c5\u51b5\u4e0b\u7684\u590d\u6742\u5ea6\uff0c\u5e76\u63d0\u51fa\u4e86PSyNF\uff08\u7279\u6b8a\u89c4\u8303\u5f62\u5f0f\uff09\u6765\u4fdd\u8bc1\u591a\u9879\u5f0f\u65f6\u95f4\u548c\u591a\u9879\u5f0f\u89c4\u6a21\u7684\u53ef\u89e3\u6027\uff0c\u5206\u6790\u4e86\u5176\u6027\u8d28\u3001\u5224\u5b9a\u4e0e\u5f52\u7ea6\u65b9\u6cd5\u3002\u6700\u540e\u8fd8\u8fa8\u6790\u4e86\u4e00\u79cd\u6613\u4e8e\u5224\u5b9a\u4f46\u8868\u8fbe\u80fd\u529b\u8f83\u5f31\u7684\u8bed\u6cd5\u89c4\u8303\u5f62\u5f0f\u3002", "result": "\u8bc1\u660e\u4e86PFnS\u5c5e\u4e8eEXPTIME\u590d\u6742\u6027\u7c7b\u522b\uff0c\u5177\u6709\u5339\u914d\u7684\u6307\u6570\u4e0b\u754c\u3002\u53d1\u73b0\u5355\u8f93\u5165\u5355\u8f93\u51fa\u4e0b\u7684PFnS\u4e0e\u5e03\u5c14\u529f\u80fd\u6027\u7efc\u5408\u4e00\u6837\u96be\u3002\u63d0\u51fa\u7684PSyNF\u5f62\u5f0f\u53ef\u4fdd\u8bc1\u591a\u9879\u5f0f\u65f6\u95f4\u548c\u7a7a\u95f4\u7684\u53ef\u89e3\u6027\uff0c\u5e76\u5236\u5b9a\u4e86\u76f8\u5173\u6027\u8d28\u548c\u5f52\u7ea6\u6807\u51c6\u3002\u6b64\u5916\u660e\u786e\u4e86\u4e00\u79cd\u66f4\u6613\u5224\u5b9a\u4f46\u4e0d\u5982PSyNF\u7d27\u51d1\u7684\u89c4\u8303\u5f62\u5f0f\u3002", "conclusion": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86Presburger\u7406\u8bba\u4e0b\u7684\u529f\u80fd\u6027\u7efc\u5408\u95ee\u9898\uff0c\u786e\u7acb\u4e86\u5176\u590d\u6742\u6027\u754c\u9650\uff0c\u5e76\u901a\u8fc7\u89c4\u8303\u5f62\u5f0f\u63d0\u5347\u4e86\u95ee\u9898\u7684\u6c42\u89e3\u6548\u7387\uff0c\u4e3a\u7406\u8bba\u548c\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2508.06926", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.06926", "abs": "https://arxiv.org/abs/2508.06926", "authors": ["Feng Luo", "Kexing Ji", "Cuiyun Gao", "Shuzheng Gao", "Jia Feng", "Kui Liu", "Xin Xia", "Michael R. Lyu"], "title": "Integrating Rules and Semantics for LLM-Based C-to-Rust Translation", "comment": "Accepted in ICSME 25 Industry Track", "summary": "Automated translation of legacy C code into Rust aims to ensure memory safety\nwhile reducing the burden of manual migration. Early approaches in code\ntranslation rely on static rule-based methods, but they suffer from limited\ncoverage due to dependence on predefined rule patterns. Recent works regard the\ntask as a sequence-to-sequence problem by leveraging large language models\n(LLMs). Although these LLM-based methods are capable of reducing unsafe code\nblocks, the translated code often exhibits issues in following Rust rules and\nmaintaining semantic consistency. On one hand, existing methods adopt a direct\nprompting strategy to translate the C code, which struggles to accommodate the\nsyntactic rules between C and Rust. On the other hand, this strategy makes it\ndifficult for LLMs to accurately capture the semantics of complex code. To\naddress these challenges, we propose IRENE, an LLM-based framework that\nIntegrates RulEs aNd sEmantics to enhance translation. IRENE consists of three\nmodules: 1) a rule-augmented retrieval module that selects relevant translation\nexamples based on rules generated from a static analyzer developed by us,\nthereby improving the handling of Rust rules; 2) a structured summarization\nmodule that produces a structured summary for guiding LLMs to enhance the\nsemantic understanding of C code; 3) an error-driven translation module that\nleverages compiler diagnostics to iteratively refine translations. We evaluate\nIRENE on two datasets (xCodeEval, a public dataset, and HW-Bench, an industrial\ndataset provided by Huawei) and eight LLMs, focusing on translation accuracy\nand safety.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faIRENE\u6846\u67b6\uff0c\u901a\u8fc7\u89c4\u5219\u68c0\u7d22\u3001\u7ed3\u6784\u5316\u6458\u8981\u53ca\u9519\u8bef\u8fed\u4ee3\uff0c\u5927\u5e45\u63d0\u5347\u4e86LLM\u9a71\u52a8C\u8f6cRust\u4ee3\u7801\u7684\u51c6\u786e\u6027\u53ca\u5b89\u5168\u6027\u3002", "motivation": "\u4f20\u7edf\u7684C\u4ee3\u7801\u8f6c\u6362\u5230Rust\u4ee5\u63d0\u5347\u5185\u5b58\u5b89\u5168\uff0c\u4f46\u4f7f\u7528\u9759\u6001\u89c4\u5219\u65b9\u6cd5\u8986\u76d6\u9762\u6709\u9650\uff0cLLM\u65b9\u6cd5\u867d\u80fd\u51cf\u5c11\u4e0d\u5b89\u5168\u4ee3\u7801\u5374\u5b58\u5728\u8bed\u6cd5\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faIRENE\u6846\u67b6\uff0c\u5305\u542b\uff1a1\uff09\u57fa\u4e8e\u89c4\u5219\u7684\u6837\u4f8b\u68c0\u7d22\u6a21\u5757\uff0c\u5229\u7528\u9759\u6001\u5206\u6790\u5668\u751f\u6210\u89c4\u5219\u63d0\u5347Rust\u89c4\u5219\u5904\u7406\uff1b2\uff09\u7ed3\u6784\u5316\u6458\u8981\u6a21\u5757\uff0c\u5f15\u5bfcLLM\u66f4\u597d\u7406\u89e3C\u4ee3\u7801\u8bed\u4e49\uff1b3\uff09\u9519\u8bef\u9a71\u52a8\u7ffb\u8bd1\u6a21\u5757\uff0c\u5229\u7528\u7f16\u8bd1\u5668\u8bca\u65ad\u8fed\u4ee3\u4f18\u5316\u7ffb\u8bd1\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\uff08xCodeEval\u516c\u5171\u96c6\u4e0eHW-Bench\u5de5\u4e1a\u96c6\uff09\u53ca\u516b\u79cdLLM\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u5173\u6ce8\u7ffb\u8bd1\u51c6\u786e\u6027\u4e0e\u5b89\u5168\u6027\u3002", "conclusion": "IRENE\u80fd\u878d\u5408\u89c4\u5219\u4e0e\u8bed\u4e49\uff0c\u663e\u8457\u63d0\u5347\u81ea\u52a8C\u5230Rust\u4ee3\u7801\u7ffb\u8bd1\u7684\u51c6\u786e\u6027\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2508.06533", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06533", "abs": "https://arxiv.org/abs/2508.06533", "authors": ["Aamod Thakur", "Ajay Nagpal", "Atharva Savarkar", "Kundeshwar Pundalik", "Siddhesh Dosi", "Piyush Sawarkar", "Viraj Thakur", "Rohit Saluja", "Maunendra Sankar Desarkar", "Ganesh Ramakrishnan"], "title": "The Art of Breaking Words: Rethinking Multilingual Tokenizer Design", "comment": null, "summary": "While model architecture and training objectives are well-studied,\ntokenization, particularly in multilingual contexts, remains a relatively\nneglected aspect of Large Language Model (LLM) development. Existing tokenizers\noften exhibit high token-to-word ratios, inefficient use of context length, and\nslower inference. We present a systematic study that links vocabulary size,\npre-tokenization rules, and training-corpus composition to both token-to-word\nefficiency and model quality. To ground our analysis in a linguistically\ndiverse context, we conduct extensive experiments on Indic scripts, which\npresent unique challenges due to their high script diversity and orthographic\ncomplexity. Drawing on the insights from these analyses, we propose a novel\nalgorithm for data composition that balances multilingual data for tokenizer\ntraining. Our observations on pretokenization strategies significantly improve\nmodel performance, and our data composition algorithm reduces the average\ntoken-to-word ratio by approximately 6% with respect to the conventional data\nrandomization approach. Our tokenizer achieves more than 40% improvement on\naverage token-to-word ratio against stateof-the-art multilingual Indic models.\nThis improvement yields measurable gains in both model performance and\ninference speed. This highlights tokenization alongside architecture and\ntraining objectives as a critical lever for building efficient, scalable\nmultilingual LLMs", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u5206\u8bcd\u5728\u591a\u8bed\u8a00\u5927\u6a21\u578b\u5f00\u53d1\u4e2d\u88ab\u5ffd\u89c6\uff0c\u63d0\u51fa\u5e76\u5b9e\u9a8c\u8bc1\u660e\u65b0\u7684\u6570\u636e\u6784\u6210\u7b97\u6cd5\u548c\u9884\u5206\u8bcd\u7b56\u7565\u663e\u8457\u964d\u4f4etoken-to-word\u6bd4\u7387\uff0c\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u4e0e\u63a8\u7406\u901f\u5ea6\uff0c\u5f3a\u8c03\u5206\u8bcd\u5bf9\u591a\u8bed\u8a00LLM\u6548\u7387\u540c\u6837\u5173\u952e\u3002", "motivation": "\u5c3d\u7ba1\u6a21\u578b\u67b6\u6784\u548c\u8bad\u7ec3\u76ee\u6807\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u4f46\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u7684\u5206\u8bcd\uff0c\u5c24\u5176\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5f00\u53d1\u4e2d\uff0c\u4ecd\u88ab\u8f83\u5927\u7a0b\u5ea6\u5ffd\u89c6\u3002\u73b0\u6709\u5206\u8bcd\u5668\u5b58\u5728\u9ad8token-to-word\u6bd4\u7387\u3001\u4e0a\u4e0b\u6587\u957f\u5ea6\u5229\u7528\u4f4e\u6548\u548c\u63a8\u7406\u901f\u5ea6\u6162\u7684\u95ee\u9898\u3002\u4f5c\u8005\u5e0c\u671b\u7cfb\u7edf\u6027\u5206\u6790\u5206\u8bcd\u5bf9\u6a21\u578b\u6548\u7387\u548c\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "method": "\u6587\u7ae0\u7cfb\u7edf\u5730\u5206\u6790\u4e86\u8bcd\u8868\u5927\u5c0f\u3001\u9884\u5206\u8bcd\u89c4\u5219\u548c\u8bad\u7ec3\u8bed\u6599\u7ec4\u6210\u5bf9token-to-word\u6548\u7387\u548c\u6a21\u578b\u8d28\u91cf\u7684\u5f71\u54cd\u3002\u7814\u7a76\u4ee5\u5370\u5ea6\u8bed\u7cfb\u6587\u5b57\u4e3a\u5b9e\u9a8c\u5bf9\u8c61\uff0c\u9488\u5bf9\u5176\u8bed\u8a00\u548c\u4e66\u5199\u590d\u6742\u5ea6\u5f00\u5c55\u5b9e\u9a8c\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u8bed\u8a00\u5206\u8bcd\u8bad\u7ec3\u6570\u636e\u5e73\u8861\u7b97\u6cd5\uff0c\u5e76\u6539\u8fdb\u9884\u5206\u8bcd\u7b56\u7565\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6570\u636e\u7ec4\u5408\u7b97\u6cd5\u76f8\u6bd4\u4f20\u7edf\u968f\u673a\u65b9\u6cd5\uff0c\u5c06\u5e73\u5747token-to-word\u6bd4\u51cf\u5c11\u4e86\u7ea66%\uff1b\u65b0\u5206\u8bcd\u5668\u5728\u5e73\u5747token-to-word\u6bd4\u4e0a\u5bf9\u6bd4\u73b0\u6709\u591a\u8bed\u8a00\u5370\u5ea6\u8bed\u6a21\u578b\u63d0\u5347\u8d85\u8fc740%\uff1b\u8fd9\u4e9b\u6539\u5584\u5e26\u6765\u4e86\u6a21\u578b\u6027\u80fd\u4e0e\u63a8\u7406\u901f\u5ea6\u7684\u63d0\u5347\u3002", "conclusion": "\u5206\u8bcd\u65b9\u6848\u5728\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u591a\u8bed\u8a00LLM\u5f00\u53d1\u4e2d\uff0c\u4e0e\u6a21\u578b\u7ed3\u6784\u548c\u8bad\u7ec3\u76ee\u6807\u540c\u7b49\u91cd\u8981\u3002\u4f18\u5316\u5206\u8bcd\u7b56\u7565\u548c\u6570\u636e\u7ec4\u6210\u4e0d\u4ec5\u63d0\u5347\u5206\u8bcd\u6548\u7387\uff0c\u8fd8\u80fd\u5b9e\u8d28\u589e\u5f3a\u6a21\u578b\u8868\u73b0\u548c\u63a8\u7406\u6548\u7387\u3002"}}
{"id": "2508.07304", "categories": ["cs.LO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07304", "abs": "https://arxiv.org/abs/2508.07304", "authors": ["Fabio Vitali"], "title": "From Knowledge to Conjectures: A Modal Framework for Reasoning about Hypotheses", "comment": null, "summary": "This paper introduces a new family of cognitive modal logics designed to\nformalize conjectural reasoning: a modal system in which cognitive contexts\nextend known facts with hypothetical assumptions to explore their consequences.\nUnlike traditional doxastic and epistemic systems, conjectural logics rely on a\nprinciple, called Axiom C ($\\varphi \\rightarrow \\Box\\varphi$), that ensures\nthat all established facts are preserved across hypothetical layers. While\nAxiom C was dismissed in the past due to its association with modal collapse,\nwe show that the collapse only arises under classical and bivalent assumptions,\nand specifically in the presence of Axiom T. Hence we avoid Axiom T and adopt a\nparacomplete semantic framework, grounded in Weak Kleene logic or Description\nLogic, where undefined propositions coexist with modal assertions. This\nprevents the modal collapse and guarantees a layering to distinguish between\nfactual and conjectural statements. Under this framework we define new modal\nsystems, e.g., KC and KDC, and show that they are complete, decidable, and\nrobust under partial knowledge. Finally, we introduce a dynamic operation,\n$\\mathsf{settle}(\\varphi)$, which formalizes the transition from conjecture to\naccepted fact, capturing the event of the update of a world's cognitive state\nthrough the resolution of uncertainty.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u7c7b\u65b0\u7684\u8ba4\u77e5\u6a21\u6001\u903b\u8f91\u7cfb\u7edf\uff0c\u901a\u8fc7\u5f31\u514b\u6797\u8bed\u4e49\u548c\u5f03\u7528Axiom T\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6a21\u6001\u903b\u8f91\u5728\u5904\u7406\u5047\u8bbe\u6027\u63a8\u7406\u65f6\u7684\u6a21\u6001\u574d\u584c\u95ee\u9898\u3002\u65b0\u7cfb\u7edf\u80fd\u6e05\u6670\u533a\u5206\u4e8b\u5b9e\u4e0e\u731c\u60f3\uff0c\u5728\u77e5\u8bc6\u4e0d\u5b8c\u5907\u65f6\u4f9d\u7136\u53ef\u7528\uff0c\u4e14\u5177\u6709\u826f\u597d\u7684\u903b\u8f91\u6027\u8d28\u3002", "motivation": "\u4f20\u7edf\u6a21\u6001\u903b\u8f91\u65e0\u6cd5\u5145\u5206\u8868\u8fbe\u8ba4\u77e5\u4e2d\u7684\u5047\u8bbe\u6027\u63a8\u7406\u4e14\u5bb9\u6613\u51fa\u73b0\u6a21\u6001\u574d\u584c\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u903b\u8f91\u7cfb\u7edf\u6765\u5408\u7406\u533a\u5206\u4e8b\u5b9e\u4e0e\u731c\u60f3\uff0c\u5e76\u652f\u6301\u77e5\u8bc6\u4e0d\u5b8c\u5907\u65f6\u7684\u63a8\u7406\u3002", "method": "\u91c7\u7528\u5f31\u514b\u6797\u903b\u8f91\u6216\u63cf\u8ff0\u903b\u8f91\u7684\u8ba4\u77e5\u6a21\u6001\u903b\u8f91\u8bed\u4e49\u6846\u67b6\uff0c\u63d0\u51faKC\u548cKDC\u7b49\u65b0\u6a21\u6001\u7cfb\u7edf\uff0c\u8bbe\u8ba1\u52a8\u6001\u64cd\u4f5csettle(\u03c6)\u4ee5\u63cf\u8ff0\u731c\u60f3\u8f6c\u5316\u4e3a\u4e8b\u5b9e\u7684\u8fc7\u7a0b\uff0c\u5e76\u8fdb\u884c\u8bed\u4e49\u5206\u6790\u548c\u903b\u8f91\u6027\u8d28\u8bc1\u660e\u3002", "result": "\u65b0\u903b\u8f91\u7cfb\u7edf\u6709\u6548\u907f\u514d\u4e86\u6a21\u6001\u574d\u584c\uff0c\u652f\u6301\u672a\u5b9a\u547d\u9898\u4e0e\u6a21\u6001\u65ad\u8a00\u5171\u5b58\uff0c\u5bf9\u90e8\u5206\u77e5\u8bc6\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u5e76\u4e14\u8bc1\u660e\u4e86\u5176\u5b8c\u5907\u6027\u548c\u53ef\u5224\u5b9a\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u7c7b\u65b0\u7684\u8ba4\u77e5\u6a21\u6001\u903b\u8f91\u7cfb\u7edf\uff0c\u80fd\u6709\u6548\u533a\u5206\u4e8b\u5b9e\u4e0e\u731c\u60f3\uff0c\u907f\u514d\u4e86\u6a21\u6001\u574d\u584c\uff0c\u5e76\u4e14\u8fd9\u4e9b\u903b\u8f91\u5728\u90e8\u5206\u77e5\u8bc6\u4e0b\u4f9d\u7136\u4fdd\u6301\u5b8c\u5907\u6027\u548c\u53ef\u5224\u5b9a\u6027\u3002"}}
{"id": "2508.06942", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06942", "abs": "https://arxiv.org/abs/2508.06942", "authors": ["Zhenchang Xing", "Yang Liu", "Zhuo Cheng", "Qing Huang", "Dehai Zhao", "Daniel Sun", "Chenhua Liu"], "title": "When Prompt Engineering Meets Software Engineering: CNL-P as Natural and Robust \"APIs'' for Human-AI Interaction", "comment": null, "summary": "With the growing capabilities of large language models (LLMs), they are\nincreasingly applied in areas like intelligent customer service, code\ngeneration, and knowledge management. Natural language (NL) prompts act as the\n``APIs'' for human-LLM interaction. To improve prompt quality, best practices\nfor prompt engineering (PE) have been developed, including writing guidelines\nand templates. Building on this, we propose Controlled NL for Prompt (CNL-P),\nwhich not only incorporates PE best practices but also draws on key principles\nfrom software engineering (SE). CNL-P introduces precise grammar structures and\nstrict semantic norms, further eliminating NL's ambiguity, allowing for a\ndeclarative but structured and accurate expression of user intent. This helps\nLLMs better interpret and execute the prompts, leading to more consistent and\nhigher-quality outputs. We also introduce an NL2CNL-P conversion tool based on\nLLMs, enabling users to write prompts in NL, which are then transformed into\nCNL-P format, thus lowering the learning curve of CNL-P. In particular, we\ndevelop a linting tool that checks CNL-P prompts for syntactic and semantic\naccuracy, applying static analysis techniques to NL for the first time.\nExtensive experiments demonstrate that CNL-P enhances the quality of LLM\nresponses through the novel and organic synergy of PE and SE. We believe that\nCNL-P can bridge the gap between emerging PE and traditional SE, laying the\nfoundation for a new programming paradigm centered around NL.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCNL-P\u65b9\u6cd5\uff0c\u5c06\u63d0\u793a\u5de5\u7a0b\u4e0e\u8f6f\u4ef6\u5de5\u7a0b\u7ed3\u5408\uff0c\u901a\u8fc7\u6a21\u677f\u5316\u548c\u89c4\u8303\u5316\u63d0\u5347\u5927\u6a21\u578b\u63d0\u793a\u8d28\u91cf\uff0c\u5f00\u53d1\u76f8\u5173\u5de5\u5177\u964d\u4f4e\u7528\u6237\u95e8\u69db\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6709\u6548\uff0c\u53ef\u4e3a\u81ea\u7136\u8bed\u8a00\u65b0\u7f16\u7a0b\u8303\u5f0f\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u968f\u7740\u5927\u6a21\u578b\u80fd\u529b\u63d0\u5347\uff0c\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u4f5c\u4e3a\u4e0e\u5927\u6a21\u578b\u4ea4\u4e92\u7684\u201cAPI\u201d\uff0c\u5176\u8d28\u91cf\u76f4\u63a5\u5f71\u54cd\u6a21\u578b\u8f93\u51fa\u8d28\u91cf\u3002\u5f53\u524d\u867d\u7136\u6709\u63d0\u793a\u5de5\u7a0b\u6700\u4f73\u5b9e\u8df5\uff0c\u4f46\u81ea\u7136\u8bed\u8a00\u4ecd\u6709\u6b67\u4e49\uff0c\u5f71\u54cd\u4e00\u81f4\u6027\u548c\u51c6\u786e\u6027\u3002\u56e0\u6b64\u9700\u8981\u8fdb\u4e00\u6b65\u63d0\u5347\u63d0\u793a\u89c4\u8303\u6027\u548c\u8868\u8fbe\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faControlled NL for Prompt (CNL-P)\u65b9\u6cd5\uff0c\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u548c\u8f6f\u4ef6\u5de5\u7a0b\u539f\u5219\uff0c\u6784\u5efa\u8bed\u6cd5\u548c\u8bed\u4e49\u89c4\u8303\u5316\u7684\u6a21\u677f\uff0c\u5e76\u5f00\u53d1\u81ea\u7136\u8bed\u8a00\u8f6cCNL-P\u8f6c\u6362\u5de5\u5177\u548cCNL-P\u63d0\u793alint\u5de5\u5177\uff0c\u9996\u6b21\u5728\u81ea\u7136\u8bed\u8a00\u9759\u6001\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cCNL-P\u65b9\u6cd5\u80fd\u63d0\u5347\u5927\u6a21\u578b\u8f93\u51fa\u8d28\u91cf\uff0c\u4f7f\u63d0\u793a\u66f4\u52a0\u4e00\u81f4\u548c\u9ad8\u8d28\u91cf\u3002\u5de5\u5177\u6709\u6548\u964d\u4f4e\u7528\u6237\u5b66\u4e60\u95e8\u69db\uff0c\u5b9e\u73b0\u63d0\u793a\u8bed\u6cd5\u548c\u8bed\u4e49\u6821\u9a8c\u3002", "conclusion": "CNL-P\u65b9\u6cd5\u6709\u671b\u6210\u4e3a\u8fde\u63a5\u63d0\u793a\u5de5\u7a0b\u4e0e\u4f20\u7edf\u8f6f\u4ef6\u5de5\u7a0b\u7684\u65b0\u6865\u6881\uff0c\u4e3a\u4ee5\u81ea\u7136\u8bed\u8a00\u4e3a\u4e2d\u5fc3\u7684\u65b0\u7f16\u7a0b\u8303\u5f0f\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2508.06548", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.06548", "abs": "https://arxiv.org/abs/2508.06548", "authors": ["Zhanye Luo", "Yuefeng Han", "Xiufan Yu"], "title": "Factor Augmented Supervised Learning with Text Embeddings", "comment": null, "summary": "Large language models (LLMs) generate text embeddings from text data,\nproducing vector representations that capture the semantic meaning and\ncontextual relationships of words. However, the high dimensionality of these\nembeddings often impedes efficiency and drives up computational cost in\ndownstream tasks. To address this, we propose AutoEncoder-Augmented Learning\nwith Text (AEALT), a supervised, factor-augmented framework that incorporates\ndimension reduction directly into pre-trained LLM workflows. First, we extract\nembeddings from text documents; next, we pass them through a supervised\naugmented autoencoder to learn low-dimensional, task-relevant latent factors.\nBy modeling the nonlinear structure of complex embeddings, AEALT outperforms\nconventional deep-learning approaches that rely on raw embeddings. We validate\nits broad applicability with extensive experiments on classification, anomaly\ndetection, and prediction tasks using multiple real-world public datasets.\nNumerical results demonstrate that AEALT yields substantial gains over both\nvanilla embeddings and several standard dimension reduction methods.", "AI": {"tldr": "AEALT\u7ed3\u5408\u81ea\u52a8\u7f16\u7801\u5668\u548cLLM\u6587\u672c\u5d4c\u5165\uff0c\u6709\u6548\u538b\u7f29\u5d4c\u5165\u7a7a\u95f4\uff0c\u5728\u591a\u4efb\u52a1\u4e2d\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u9ad8\u7ef4\u5ea6\u6587\u672c\u5d4c\u5165\u867d\u7136\u80fd\u6355\u6349\u4e30\u5bcc\u8bed\u4e49\uff0c\u4f46\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u5e38\u5e38\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002", "method": "\u63d0\u51faAEALT\uff08AutoEncoder-Augmented Learning with Text\uff09\u6846\u67b6\uff0c\u5c06\u76d1\u7763\u5f0f\u3001\u589e\u5f3a\u578b\u81ea\u52a8\u7f16\u7801\u5668\u7528\u4e8e\u76f4\u63a5\u5728\u9884\u8bad\u7ec3LLM\u7684\u5de5\u4f5c\u6d41\u4e2d\u8fdb\u884c\u7ef4\u5ea6\u7ea6\u51cf\u3002\u5177\u4f53\u6d41\u7a0b\u4e3a\uff1a\u9996\u5148\u63d0\u53d6\u6587\u672c\u5d4c\u5165\u5411\u91cf\uff0c\u7136\u540e\u901a\u8fc7\u589e\u5f3a\u578b\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u5b66\u4e60\u4f4e\u7ef4\u3001\u4e0e\u4efb\u52a1\u9ad8\u5ea6\u76f8\u5173\u7684\u6f5c\u5728\u8868\u793a\u3002", "result": "AEALT\u5728\u5206\u7c7b\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u9884\u6d4b\u7b49\u591a\u79cd\u5b9e\u9645\u4efb\u52a1\u53ca\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u660e\u663e\u4f18\u4e8e\u539f\u59cb\u5d4c\u5165\u53ca\u591a\u79cd\u6807\u51c6\u7ef4\u5ea6\u7ea6\u51cf\u65b9\u6cd5\u3002", "conclusion": "AEALT\u80fd\u6709\u6548\u964d\u4f4e\u6587\u672c\u5d4c\u5165\u7ef4\u5ea6\uff0c\u63d0\u9ad8\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u548c\u6548\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u7ef4\u5ea6\u7ea6\u51cf\u65b9\u6cd5\u3002"}}
{"id": "2508.07742", "categories": ["cs.LO", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2508.07742", "abs": "https://arxiv.org/abs/2508.07742", "authors": ["Meghyn Bienvenu", "Camille Bourgaux", "Katsumi Inoue", "Robin Jean"], "title": "A Rule-Based Approach to Specifying Preferences over Conflicting Facts and Querying Inconsistent Knowledge Bases", "comment": "This is an extended version of a paper appearing at the 22nd\n  International Conference on Principles of Knowledge Representation and\n  Reasoning (KR 2025). 24 pages", "summary": "Repair-based semantics have been extensively studied as a means of obtaining\nmeaningful answers to queries posed over inconsistent knowledge bases (KBs).\nWhile several works have considered how to exploit a priority relation between\nfacts to select optimal repairs, the question of how to specify such\npreferences remains largely unaddressed. This motivates us to introduce a\ndeclarative rule-based framework for specifying and computing a priority\nrelation between conflicting facts. As the expressed preferences may contain\nundesirable cycles, we consider the problem of determining when a set of\npreference rules always yields an acyclic relation, and we also explore a\npragmatic approach that extracts an acyclic relation by applying various cycle\nremoval techniques. Towards an end-to-end system for querying inconsistent KBs,\nwe present a preliminary implementation and experimental evaluation of the\nframework, which employs answer set programming to evaluate the preference\nrules, apply the desired cycle resolution techniques to obtain a priority\nrelation, and answer queries under prioritized-repair semantics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u89c4\u5219\u7684\u4f18\u5148\u7ea7\u5173\u7cfb\u8ba1\u7b97\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u4e0d\u4e00\u81f4\u77e5\u8bc6\u5e93\u67e5\u8be2\u7684\u8bed\u4e49\u8868\u8fbe\u548c\u7ed3\u679c\u5408\u7406\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5728\u5904\u7406\u4e0d\u4e00\u81f4\u7684\u77e5\u8bc6\u5e93\u65f6\uff0c\u4f7f\u7528\u4fee\u590d\u5f0f\u8bed\u4e49\u662f\u4e00\u79cd\u91cd\u8981\u65b9\u6cd5\uff0c\u4f46\u5982\u4f55\u5408\u7406\u6307\u5b9a\u4e8b\u5b9e\u95f4\u7684\u4f18\u5148\u7ea7\u8fd8\u672a\u88ab\u5145\u5206\u89e3\u51b3\u3002\u8be5\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u89c4\u5219\u7684\u6846\u67b6\u6765\u89e3\u51b3\u4f18\u5148\u7ea7\u5173\u7cfb\u7684\u8868\u8fbe\u4e0e\u8ba1\u7b97\u95ee\u9898\uff0c\u63d0\u5347\u67e5\u8be2\u7ed3\u679c\u7684\u5408\u7406\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u58f0\u660e\u5f0f\u7684\u89c4\u5219\u6846\u67b6\uff0c\u7528\u4e8e\u6307\u5b9a\u548c\u8ba1\u7b97\u51b2\u7a81\u4e8b\u5b9e\u4e4b\u95f4\u7684\u4f18\u5148\u5173\u7cfb\u3002\u5206\u6790\u4e86\u4f18\u5148\u89c4\u5219\u4ea7\u751f\u73af\u7684\u95ee\u9898\uff0c\u5e76\u7814\u7a76\u4e86\u6d88\u9664\u73af\u7684\u591a\u79cd\u6280\u672f\u3002\u901a\u8fc7\u91c7\u7528answer set programming\u5b9e\u73b0\u539f\u578b\u7cfb\u7edf\uff0c\u5e76\u8fdb\u884c\u4e86\u521d\u6b65\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u7ed9\u51fa\u4e86\u4f18\u5148\u89c4\u5219\u5bfc\u81f4\u73af\u7684\u5224\u5b9a\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u591a\u79cd\u73af\u6d88\u9664\u6280\u672f\u7684\u5b9e\u7528\u6027\uff0c\u5b9e\u73b0\u4e86\u67e5\u8be2\u4e0d\u4e00\u81f4\u77e5\u8bc6\u5e93\u65f6\u53ef\u4ee5\u4f18\u5148\u4fee\u590d\u7684\u7aef\u5230\u7aef\u7cfb\u7edf\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u53ef\u884c\u3002", "conclusion": "\u901a\u8fc7\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u6709\u6548\u8868\u8fbe\u548c\u8ba1\u7b97\u77e5\u8bc6\u5e93\u4e8b\u5b9e\u4e4b\u95f4\u7684\u4f18\u5148\u7ea7\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u73af\u5904\u7406\u6280\u672f\u786e\u4fdd\u4f18\u5148\u7ea7\u5173\u7cfb\u7684\u53ef\u7528\u6027\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u5408\u7406\u7684\u67e5\u8be2\u4fee\u590d\u8bed\u4e49\u3002"}}
{"id": "2508.07084", "categories": ["cs.SE", "cs.PF"], "pdf": "https://arxiv.org/pdf/2508.07084", "abs": "https://arxiv.org/abs/2508.07084", "authors": ["Kaveh Shahedi", "Nana Gyambrah", "Heng Li", "Maxime Lamothe", "Foutse Khomh"], "title": "An Empirical Study on Method-Level Performance Evolution in Open-Source Java Projects", "comment": null, "summary": "Performance is a critical quality attribute in software development, yet the\nimpact of method-level code changes on performance evolution remains poorly\nunderstood. While developers often make intuitive assumptions about which types\nof modifications are likely to cause performance regressions or improvements,\nthese beliefs lack empirical validation at a fine-grained level. We conducted a\nlarge-scale empirical study analyzing performance evolution in 15 mature\nopen-source Java projects hosted on GitHub. Our analysis encompassed 739\ncommits containing 1,499 method-level code changes, using Java Microbenchmark\nHarness (JMH) for precise performance measurement and rigorous statistical\nanalysis to quantify both the significance and magnitude of performance\nvariations. We employed bytecode instrumentation to capture method-specific\nexecution metrics and systematically analyzed four key aspects: temporal\nperformance patterns, code change type correlations, developer and complexity\nfactors, and domain-size interactions. Our findings reveal that 32.7% of\nmethod-level changes result in measurable performance impacts, with regressions\noccurring 1.3 times more frequently than improvements. Contrary to conventional\nwisdom, we found no significant differences in performance impact distributions\nacross code change categories, challenging risk-stratified development\nstrategies. Algorithmic changes demonstrate the highest improvement potential\nbut carry substantial regression risk. Senior developers produce more stable\nchanges with fewer extreme variations, while code complexity correlates with\nincreased regression likelihood. Domain-size interactions reveal significant\npatterns, with web server + small projects exhibiting the highest performance\ninstability. Our study provides empirical evidence for integrating automated\nperformance testing into continuous integration pipelines.", "AI": {"tldr": "\u8bba\u6587\u5bf9Java\u5f00\u6e90\u9879\u76ee\u7684\u65b9\u6cd5\u7ea7\u4ee3\u7801\u53d8\u66f4\u4e0e\u6027\u80fd\u6f14\u5316\u505a\u4e86\u5927\u89c4\u6a21\u91cf\u5316\u5206\u6790\uff0c\u53d1\u73b0\u4e09\u6210\u4ee5\u4e0a\u66f4\u6539\u5f71\u54cd\u6027\u80fd\uff0c\u4e14\u5e38\u5e38\u88ab\u4f4e\u4f30\u3002\u5efa\u8bae\u5c06\u81ea\u52a8\u5316\u6027\u80fd\u6d4b\u8bd5\u96c6\u6210\u5230\u6301\u7eed\u96c6\u6210\u6d41\u7a0b\uff0c\u63d0\u9ad8\u4ee3\u7801\u8d28\u91cf\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u867d\u7136\u8f6f\u4ef6\u6027\u80fd\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u6211\u4eec\u5bf9\u4e8e\u65b9\u6cd5\u7ea7\u4ee3\u7801\u4fee\u6539\u5bfc\u81f4\u7684\u6027\u80fd\u53d8\u5316\u8fd8\u7f3a\u4e4f\u7ec6\u81f4\u7684\u5b9e\u8bc1\u7814\u7a76\u3002\u5f00\u53d1\u8005\u5bf9\u54ea\u4e9b\u53d8\u66f4\u53ef\u80fd\u5f71\u54cd\u6027\u80fd\u6709\u76f4\u89c9\u5224\u65ad\uff0c\u4f46\u8fd9\u4e9b\u5224\u65ad\u7f3a\u4e4f\u5fae\u89c2\u5c42\u9762\u7684\u8bc1\u636e\u652f\u6301\u3002\u672c\u6587\u65e8\u5728\u7cbe\u7ec6\u91cf\u5316\u65b9\u6cd5\u7ea7\u53d8\u66f4\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u5bf915\u4e2a\u6210\u719f\u7684\u5f00\u6e90Java\u9879\u76ee\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\uff0c\u9009\u53d6739\u6b21\u63d0\u4ea4\u3001\u51711499\u4e2a\u65b9\u6cd5\u7ea7\u4ee3\u7801\u66f4\u6539\u3002\u901a\u8fc7JMH\u57fa\u51c6\u6d4b\u8bd5\u7cbe\u786e\u6d4b\u91cf\u6027\u80fd\u53d8\u5316\uff0c\u5e76\u91c7\u7528\u5b57\u8282\u7801\u63d2\u88c5\u6536\u96c6\u65b9\u6cd5\u6267\u884c\u6307\u6807\uff0c\u7ed3\u5408\u7edf\u8ba1\u5206\u6790\u63a2\u8ba8\u6027\u80fd\u53d8\u5316\u7684\u663e\u8457\u6027\u548c\u5e45\u5ea6\uff0c\u5e76\u7cfb\u7edf\u5206\u6790\u6027\u80fd\u968f\u65f6\u95f4\u53d8\u5316\u3001\u53d8\u66f4\u7c7b\u578b\u3001\u5f00\u53d1\u8005\u548c\u4ee3\u7801\u590d\u6742\u5ea6\u3001\u4ee5\u53ca\u9886\u57df\u548c\u9879\u76ee\u4f53\u91cf\u7b49\u56e0\u7d20\u3002", "result": "32.7%\u7684\u65b9\u6cd5\u7ea7\u53d8\u66f4\u5bfc\u81f4\u4e86\u53ef\u6d4b\u91cf\u7684\u6027\u80fd\u5f71\u54cd\uff0c\u5176\u4e2d\u6027\u80fd\u56de\u9000\u7684\u53d1\u751f\u6982\u7387\u662f\u6027\u80fd\u63d0\u5347\u76841.3\u500d\u3002\u4e0d\u540c\u7c7b\u578b\u7684\u4ee3\u7801\u53d8\u66f4\uff0c\u5728\u6027\u80fd\u5f71\u54cd\u5206\u5e03\u4e0a\u5e76\u65e0\u663e\u8457\u5dee\u5f02\u3002\u7b97\u6cd5\u53d8\u66f4\u6709\u6700\u9ad8\u7684\u6027\u80fd\u63d0\u5347\u6f5c\u529b\uff0c\u4f46\u540c\u65f6\u4e5f\u5e26\u6765\u8f83\u9ad8\u7684\u56de\u9000\u98ce\u9669\u3002\u8d44\u6df1\u5f00\u53d1\u8005\u7684\u4ee3\u7801\u66f4\u7a33\u5b9a\uff0c\u6781\u7aef\u53d8\u5316\u8f83\u5c11\uff1b\u590d\u6742\u5ea6\u9ad8\u7684\u4ee3\u7801\u53d8\u66f4\u66f4\u5bb9\u6613\u5f15\u53d1\u6027\u80fd\u56de\u9000\u3002\u5c0f\u578bweb\u670d\u52a1\u9879\u76ee\u6027\u80fd\u6700\u4e3a\u4e0d\u7a33\u5b9a\u3002", "conclusion": "\u65b9\u6cd5\u7ea7\u4ee3\u7801\u53d8\u66f4\u5bf9\u6027\u80fd\u6709\u975e\u53ef\u5ffd\u89c6\u7684\u5f71\u54cd\uff0c\u4e14\u5e38\u88ab\u76f4\u89c9\u4f4e\u4f30\u3002\u4e0d\u540c\u53d8\u66f4\u7c7b\u578b\u9020\u6210\u7684\u6027\u80fd\u5f71\u54cd\u6ca1\u6709\u663e\u8457\u6a21\u5f0f\uff0c\u5efa\u8bae\u5f00\u53d1\u6d41\u7a0b\u4e2d\u5f15\u5165\u81ea\u52a8\u5316\u6027\u80fd\u6d4b\u8bd5\u4ee5\u51cf\u5c11\u56de\u9000\u98ce\u9669\u548c\u76f2\u533a\u3002"}}
{"id": "2508.06583", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06583", "abs": "https://arxiv.org/abs/2508.06583", "authors": ["Ying Liu", "Can Li", "Ting Zhang", "Mei Wang", "Qiannan Zhu", "Jian Li", "Hua Huang"], "title": "Discerning minds or generic tutors? Evaluating instructional guidance capabilities in Socratic LLMs", "comment": null, "summary": "The conversational capabilities of large language models hold significant\npromise for enabling scalable and interactive tutoring. While prior research\nhas primarily examined their capacity for Socratic questioning, it often\noverlooks a critical dimension: adaptively guiding learners based on their\ncognitive states. This study shifts focus from mere question generation to the\nbroader instructional guidance capability. We ask: Can LLMs emulate expert\ntutors who dynamically adjust strategies in response to learners'\nunderstanding? To investigate this, we propose GuideEval, a benchmark grounded\nin authentic educational dialogues that evaluates pedagogical guidance through\na three-phase behavioral framework: (1) Perception, inferring learner states;\n(2) Orchestration, adapting instructional strategies; and (3) Elicitation,\nstimulating proper reflections. Empirical findings reveal that existing LLMs\nfrequently fail to provide effective adaptive scaffolding when learners exhibit\nconfusion or require redirection. Furthermore, we introduce a behavior-guided\nfinetuning strategy that leverages behavior-prompted instructional dialogues,\nsignificantly enhancing guidance performance. By shifting the focus from\nisolated content evaluation to learner-centered interaction, our work advocates\na more dialogic paradigm for evaluating Socratic LLMs.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e2a\u6027\u5316\u6559\u5b66\u6307\u5bfc\u65b9\u9762\u5b58\u5728\u77ed\u677f\uff0c\u63d0\u51faGuideEval\u57fa\u51c6\u548c\u884c\u4e3a\u5f15\u5bfc\u5fae\u8c03\uff0c\u6709\u6548\u589e\u5f3a\u6a21\u578b\u6839\u636e\u5b66\u4e60\u8005\u72b6\u6001\u52a8\u6001\u8c03\u6574\u8f85\u5bfc\u7b56\u7565\u7684\u80fd\u529b\u3002", "motivation": "\u4ee5\u5f80\u5bf9\u5927\u6a21\u578b\u6559\u5b66\u80fd\u529b\u7684\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u95ee\u9898\u751f\u6210\uff08\u5982\u82cf\u683c\u62c9\u5e95\u5f0f\u63d0\u95ee\uff09\uff0c\u4f46\u5ffd\u7565\u4e86\u6839\u636e\u5b66\u4e60\u8005\u8ba4\u77e5\u72b6\u6001\u8fdb\u884c\u81ea\u9002\u5e94\u6559\u5b66\u3002\u8fd9\u4e00\u7ef4\u5ea6\u5bf9\u4e8e\u5b9e\u73b0\u4e2a\u6027\u5316\u548c\u9ad8\u6548\u8f85\u5bfc\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u5e76\u6784\u5efa\u4e86GuideEval\u57fa\u51c6\uff0c\u57fa\u4e8e\u771f\u5b9e\u6559\u80b2\u5bf9\u8bdd\uff0c\u91c7\u7528\u4e09\u9636\u6bb5\u884c\u4e3a\u6846\u67b6\uff1a1)\u611f\u77e5\uff0c\u63a8\u65ad\u5b66\u4e60\u8005\u72b6\u6001\uff1b2)\u7f16\u6392\uff0c\u8c03\u6574\u6559\u5b66\u7b56\u7565\uff1b3)\u5f15\u5bfc\uff0c\u6fc0\u53d1\u5b66\u4e60\u8005\u53cd\u601d\u3002\u540c\u65f6\uff0c\u5e94\u7528\u884c\u4e3a\u5f15\u5bfc\u5fae\u8c03\u7684\u7b56\u7565\u8fdb\u884c\u4f18\u5316\u548c\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u9002\u5e94\u6559\u5b66\u6307\u5bfc\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\u3002\u63d0\u51fa\u7684\u884c\u4e3a\u5f15\u5bfc\u5fae\u8c03\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6559\u5b66\u6307\u5bfc\u6548\u679c\u3002", "conclusion": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9762\u5bf9\u5b66\u4e60\u8005\u7591\u60d1\u6216\u9700\u8981\u5f15\u5bfc\u65f6\uff0c\u5f80\u5f80\u96be\u4ee5\u6709\u6548\u5730\u8fdb\u884c\u81ea\u9002\u5e94\u7684\u6559\u5b66\u652f\u6301\u3002\u672c\u6587\u63d0\u51fa\u7684\u884c\u4e3a\u5f15\u5bfc\u5fae\u8c03\u7b56\u7565\u80fd\u591f\u663e\u8457\u63d0\u5347\u5176\u5f15\u5bfc\u8868\u73b0\u3002"}}
{"id": "2508.07963", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.07963", "abs": "https://arxiv.org/abs/2508.07963", "authors": ["Javier Esparza", "Vincent Fischer"], "title": "Runtime Verification for LTL in Stochastic Systems", "comment": null, "summary": "Runtime verification encompasses several lightweight techniques for checking\nwhether a system's current execution satisfies a given specification. We focus\non runtime verification for Linear Temporal Logic (LTL). Previous work\ndescribes monitors which produce, at every time step one of three outputs -\ntrue, false, or inconclusive - depending on whether the observed execution\nprefix definitively determines satisfaction of the formula. However, for many\nLTL formulas, such as liveness properties, satisfaction cannot be concluded\nfrom any finite prefix. For these properties traditional monitors will always\noutput inconclusive. In this work, we propose a novel monitoring approach that\nreplaces hard verdicts with probabilistic predictions and an associated\nconfidence score. Our method guarantees eventual correctness of the prediction\nand ensures that confidence increases without bound from that point on.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9LTL\u8fd0\u884c\u65f6\u9a8c\u8bc1\uff0c\u63d0\u51fa\u57fa\u4e8e\u6982\u7387\u9884\u6d4b\u7684\u65b0\u76d1\u6d4b\u65b9\u6cd5\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u76d1\u6d4b\u5728\u67d0\u4e9b\u5c5e\u6027\u4e0a\u59cb\u7ec8\u65e0\u6cd5\u5f97\u7ed3\u8bba\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9884\u6d4b\u6b63\u786e\u6027\u548c\u7f6e\u4fe1\u5ea6\u6301\u7eed\u63d0\u5347\u3002", "motivation": "\u4f20\u7edfLTL\u8fd0\u884c\u65f6\u9a8c\u8bc1\u5668\u5728\u9762\u5bf9\u5982\u6d3b\u6027\u5c5e\u6027\u65f6\uff0c\u7ecf\u5e38\u7531\u4e8e\u65e0\u6cd5\u901a\u8fc7\u6709\u9650\u524d\u7f00\u786e\u5b9a\u7ed3\u8bba\u800c\u4e00\u76f4\u8f93\u51fa\u201c\u672a\u77e5\u201d\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u7075\u6d3b\u4e14\u5177\u5907\u5b9e\u7528\u6027\u7684\u68c0\u6d4b\u624b\u6bb5\u3002", "method": "\u91c7\u7528\u6982\u7387\u9884\u6d4b\u53d6\u4ee3\u4f20\u7edf\u76d1\u6d4b\u7684\u786c\u6027\u7ed3\u8bba\uff0c\u540c\u65f6\u4e3a\u6bcf\u4e00\u6b65\u8f93\u51fa\u4e00\u4e2a\u7f6e\u4fe1\u5ea6\u5206\u6570\u3002\u65b9\u6cd5\u53ef\u968f\u7740\u89c2\u5bdf\u5e8f\u5217\u589e\u957f\uff0c\u63d0\u5347\u9884\u6d4b\u7684\u51c6\u786e\u6027\u5e76\u4e14\u7f6e\u4fe1\u5ea6\u5355\u8c03\u589e\u52a0\u3002", "result": "\u65b0\u63d0\u51fa\u7684\u6982\u7387\u9884\u6d4b\u76d1\u6d4b\u5668\u80fd\u591f\u5904\u7406\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u5f97\u51fa\u7684\u7ed3\u8bba\uff0c\u4fdd\u8bc1\u9884\u6d4b\u6700\u7ec8\u6b63\u786e\uff0c\u5e76\u4e14\u7f6e\u4fe1\u5ea6\u4ece\u4e34\u754c\u70b9\u4e4b\u540e\u6301\u7eed\u63d0\u5347\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\uff08LTL\uff09\u8fd0\u884c\u65f6\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edf\u68c0\u6d4b\u5668\u53ea\u8f93\u51fa\u786e\u5b9a\u6027\u7ed3\u8bba\uff0c\u672c\u65b9\u6cd5\u901a\u8fc7\u6982\u7387\u9884\u6d4b\u548c\u7f6e\u4fe1\u5ea6\u5206\u6570\uff0c\u66f4\u597d\u5730\u5904\u7406\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u6d3b\u6027\u7b49\u5c5e\u6027\u4e0a\u7684\u4e0d\u8db3\u3002\u9884\u6d4b\u7ed3\u679c\u6700\u7ec8\u6536\u655b\uff0c\u5e76\u4e14\u7f6e\u4fe1\u5ea6\u6301\u7eed\u63d0\u5347\u3002"}}
{"id": "2508.07169", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.07169", "abs": "https://arxiv.org/abs/2508.07169", "authors": ["Burak Yeti\u015ftiren", "Hong Jin Kang", "Miryung Kim"], "title": "From Noise to Knowledge: Interactive Summaries for Developer Alerts", "comment": null, "summary": "Programmers using bug-finding tools often review their reported warnings one\nby one. Based on the insight that identifying recurring themes and\nrelationships can enhance the cognitive process of sensemaking, we propose\nCLARITY, which supports interpreting tool-generated warnings through\ninteractive inquiry. CLARITY derives summary rules for custom grouping of\nrelated warnings with active feedback. As users mark warnings as interesting or\nuninteresting, CLARITY's rule inference algorithm surfaces common symptoms,\nhighlighting structural similarities in containment, subtyping, invoked\nmethods, accessed fields, and expressions.\n  We demonstrate CLARITY on Infer and SpotBugs warnings across two mature Java\nprojects. In a within-subject user study with 14 participants, users\narticulated root causes for similar uninteresting warnings faster and with more\nconfidence using CLARITY. We observed significant individual variation in\ndesired grouping, reinforcing the need for customizable sensemaking. Simulation\nshows that with rule-level feedback, only 11.8 interactions are needed on\naverage to align all inferred rules with a simulated user's labels (vs. 17.8\nwithout). Our evaluation suggests that CLARITY's active learning-based\nsummarization enhances interactive warning sensemaking.", "AI": {"tldr": "CLARITY\u5de5\u5177\u901a\u8fc7\u4e3b\u52a8\u5b66\u4e60\u548c\u53ef\u5b9a\u5236\u7684\u5206\u7ec4\u89c4\u5219\uff0c\u5e2e\u52a9\u7a0b\u5e8f\u5458\u66f4\u5feb\u3001\u66f4\u9ad8\u6548\u5730\u7406\u89e3\u548c\u5f52\u7eb3\u4ee3\u7801\u8b66\u544a\uff0c\u63d0\u9ad8\u4e86\u8b66\u544a\u5206\u6790\u7684\u901f\u5ea6\u4e0e\u4fe1\u5fc3\uff0c\u663e\u8457\u51cf\u5c11\u4ea4\u4e92\u6210\u672c\u3002", "motivation": "\u7a0b\u5e8f\u5458\u5728\u4f7f\u7528bug\u67e5\u627e\u5de5\u5177\u65f6\uff0c\u901a\u5e38\u9700\u8981\u9010\u6761\u5ba1\u6838\u5de5\u5177\u62a5\u544a\u7684\u8b66\u544a\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u8017\u65f6\u4e14\u6613\u9020\u6210\u8ba4\u77e5\u8d1f\u62c5\u3002\u53d1\u73b0\u91cd\u590d\u6027\u4e3b\u9898\u4e0e\u5173\u7cfb\u6709\u52a9\u4e8e\u589e\u5f3a\u7406\u89e3\u548c\u63a8\u7406\u8fc7\u7a0b\uff0c\u6fc0\u53d1\u4e86\u672c\u6587\u63d0\u51fa\u65b0\u65b9\u6cd5\u4ee5\u8f85\u52a9\u8b66\u544a\u5f52\u7eb3\u4e0e\u89e3\u6790\u7684\u52a8\u673a\u3002", "method": "\u63d0\u51fa\u4e86CLARITY\u5de5\u5177\uff0c\u901a\u8fc7\u7528\u6237\u4ea4\u4e92\u53cd\u9988\uff0c\u81ea\u52a8\u63a8\u65ad\u4e0e\u5f52\u7eb3\u53ef\u5b9a\u5236\u7684\u5206\u7ec4\u89c4\u5219\uff0c\u5c06\u7ed3\u6784\u76f8\u4f3c\u7684\u8b66\u544a\uff08\u5982\u5305\u5bb9\u5173\u7cfb\u3001\u5b50\u7c7b\u578b\u3001\u8c03\u7528\u65b9\u6cd5\u3001\u8bbf\u95ee\u5b57\u6bb5\u548c\u8868\u8fbe\u5f0f\uff09\u5f52\u4e3a\u4e00\u7c7b\u3002\u7528\u6237\u53cd\u9988\uff08\u6807\u8bb0\u8b66\u544a\u4e3a\u6709\u8da3\u6216\u65e0\u8da3\uff09\u76f4\u63a5\u5f71\u54cd\u5206\u7ec4\u89c4\u5219\u751f\u6210\u3002", "result": "\u5728Infer\u548cSpotBugs\u8fd9\u4e24\u4e2a\u4e3b\u6d41Java\u5de5\u5177\u751f\u6210\u7684\u8b66\u544a\u53ca\u4e24\u4e2a\u6210\u719fJava\u9879\u76ee\u4e0a\u6d4b\u8bd5CLARITY\u300214\u540d\u53c2\u4e0e\u8005\u7684\u5bf9\u6bd4\u5b9e\u9a8c\u4e2d\uff0c\u7528\u6237\u501f\u52a9CLARITY\u66f4\u5feb\u3001\u66f4\u6709\u4fe1\u5fc3\u5730\u5206\u6790\u51fa\u76f8\u4f3c\u65e0\u8da3\u8b66\u544a\u7684\u6839\u56e0\u3002\u540c\u65f6\uff0c\u4e0d\u540c\u7528\u6237\u671f\u671b\u7684\u5206\u7ec4\u65b9\u5f0f\u5dee\u5f02\u660e\u663e\uff0c\u9a8c\u8bc1\u4e86\u5b9a\u5236\u5316\u5f52\u7eb3\u7684\u5fc5\u8981\u6027\u3002\u6a21\u62df\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u89c4\u5219\u7684\u53cd\u9988\u5e73\u5747\u53ea\u970011.8\u6b21\u4ea4\u4e92\uff08\u5bf9\u6bd4\u65e0\u89c4\u5219\u53cd\u9988\u970017.8\u6b21\uff09\uff0c\u5373\u53ef\u4f7f\u63a8\u65ad\u89c4\u5219\u4e0e\u7528\u6237\u504f\u597d\u4e00\u81f4\u3002", "conclusion": "CLARITY\u901a\u8fc7\u4e3b\u52a8\u5b66\u4e60\u548c\u89c4\u5219\u5f52\u7eb3\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u5de5\u5177\u8b66\u544a\u89e3\u91ca\u548c\u611f\u77e5\u6548\u7387\uff0c\u964d\u4f4e\u4e86\u4ea4\u4e92\u6210\u672c\uff0c\u652f\u6301\u4e2a\u6027\u5316\u548c\u9ad8\u6548\u7684\u8b66\u544a\u5f52\u7eb3\u8fc7\u7a0b\u3002\u6b64\u6210\u679c\u4e3a\u7a0b\u5e8f\u5458\u9ad8\u6548\u7ba1\u7406\u548c\u7406\u89e3\u81ea\u52a8\u5316\u8b66\u544a\u63d0\u4f9b\u4e86\u6709\u529b\u8f85\u52a9\u3002"}}
{"id": "2508.06595", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06595", "abs": "https://arxiv.org/abs/2508.06595", "authors": ["Xiaoyuan Zhu", "Muru Zhang", "Ollie Liu", "Robin Jia", "Willie Neiswanger"], "title": "LLM Unlearning Without an Expert Curated Dataset", "comment": null, "summary": "Modern large language models often encode sensitive, harmful, or copyrighted\nknowledge, raising the need for post-hoc unlearning-the ability to remove\nspecific domains of knowledge from a model without full retraining. A major\nbottleneck in current unlearning pipelines is constructing effective forget\nsets-datasets that approximate the target domain and guide the model to forget\nit. In this work, we introduce a scalable, automated approach to generate\nhigh-quality forget sets using language models themselves. Our method\nsynthesizes textbook-style data through a structured prompting pipeline,\nrequiring only a domain name as input. Through experiments on unlearning\nbiosecurity, cybersecurity, and Harry Potter novels, we show that our synthetic\ndatasets consistently outperform the baseline synthetic alternatives and are\ncomparable to the expert-curated ones. Additionally, ablation studies reveal\nthat the multi-step generation pipeline significantly boosts data diversity,\nwhich in turn improves unlearning utility. Overall, our findings suggest that\nsynthetic datasets offer a promising path toward practical, scalable unlearning\nfor a wide range of emerging domains without the need for manual intervention.\nWe release our code and dataset at\nhttps://github.com/xyzhu123/Synthetic_Textbook.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5408\u6210\u9ad8\u8d28\u91cf\u201c\u9057\u5fd8\u6570\u636e\u96c6\u201d\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u5927\u6a21\u578b\u53bb\u5b66\u4e60\u7279\u5b9a\u9886\u57df\u77e5\u8bc6\u7684\u5b9e\u7528\u6027\uff0c\u7ed3\u679c\u63a5\u8fd1\u4e13\u5bb6\u6574\u7406\u6570\u636e\uff0c\u65b9\u6cd5\u9002\u7528\u6027\u5e7f\u4e14\u5f00\u6e90\uff0c\u63a8\u52a8\u4e86\u6a21\u578b\u5b89\u5168\u4e0e\u5408\u89c4\u53d1\u5c55\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u7f16\u7801\u4e86\u5927\u91cf\u654f\u611f\u3001\u6709\u5bb3\u6216\u53d7\u7248\u6743\u4fdd\u62a4\u7684\u4fe1\u606f\uff0c\u4e9f\u9700\u65e0\u9700\u5b8c\u5168\u91cd\u65b0\u8bad\u7ec3\u60c5\u51b5\u4e0b\u5b9e\u73b0\u201c\u53bb\u5b66\u4e60\u201d\u67d0\u4e9b\u7279\u5b9a\u9886\u57df\u77e5\u8bc6\u7684\u80fd\u529b\u3002\u800c\u76ee\u524d\u53bb\u5b66\u4e60\u6d41\u7a0b\u4e2d\u7684\u4e3b\u8981\u74f6\u9888\u5728\u4e8e\u5982\u4f55\u6784\u5efa\u9ad8\u6548\u7684\u201c\u9057\u5fd8\u6570\u636e\u96c6\u201d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u81ea\u52a8\u5316\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u8bed\u8a00\u6a21\u578b\u81ea\u8eab\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\uff0c\u5408\u6210\u6559\u6750\u98ce\u683c\u7684\u6570\u636e\u96c6\uff0c\u53ea\u9700\u8f93\u5165\u9886\u57df\u540d\u79f0\u5373\u53ef\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u9057\u5fd8\u6570\u636e\u96c6\u3002\u5e76\u5728\u751f\u7269\u5b89\u5168\u3001\u7f51\u7edc\u5b89\u5168\u548c\u54c8\u5229\u6ce2\u7279\u5c0f\u8bf4\u7b49\u9886\u57df\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\u3002\u901a\u8fc7\u591a\u6b65\u751f\u6210\u6d41\u7a0b\u63d0\u5347\u6570\u636e\u591a\u6837\u6027\u3002", "result": "\u5408\u6210\u6570\u636e\u96c6\u5728\u53bb\u5b66\u4e60\u5b9e\u7528\u6027\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u66ff\u4ee3\u65b9\u6848\u4e14\u63a5\u8fd1\u4e13\u5bb6\u4eba\u5de5\u6574\u7406\u7684\u6570\u636e\u96c6\u3002\u6d88\u878d\u5b9e\u9a8c\u663e\u793a\u591a\u6b65\u751f\u6210\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u591a\u6837\u6027\uff0c\u4e5f\u63d0\u5347\u4e86\u6a21\u578b\u53bb\u5b66\u4e60\u7684\u6548\u679c\u3002", "conclusion": "\u5408\u6210\u6570\u636e\u96c6\u4e3a\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u6761\u4ef6\u4e0b\uff0c\u5404\u7c7b\u65b0\u5174\u9886\u57df\u7684\u5927\u8bed\u8a00\u6a21\u578b\u53bb\u5b66\u4e60\u63d0\u4f9b\u4e86\u73b0\u5b9e\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002\u4f5c\u8005\u5f00\u6e90\u4e86\u4ee3\u7801\u548c\u6570\u636e\u96c6\u3002"}}
{"id": "2508.07180", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07180", "abs": "https://arxiv.org/abs/2508.07180", "authors": ["Zhe Zhang", "Runlin Liu", "Aishan Liu", "Xingyu Liu", "Xiang Gao", "Hailong Sun"], "title": "Dynamic Benchmark Construction for Evaluating Large Language Models on Real-World Codes", "comment": null, "summary": "As large language models LLMs) become increasingly integrated into software\ndevelopment workflows, rigorously evaluating their performance on complex,\nreal-world code generation tasks has become essential. However, existing\nbenchmarks often suffer from data contamination and limited test rigor,\nconstraining their ability to reveal model failures effectively. To address\nthese, we present CODE2BENCH, a end-to-end pipeline for dynamically\nconstructing robust and contamination-resistant benchmarks from real-world\nGitHub repositories. Specifically, CODE2BENCH introduces three key innovations:\n(1) Automated Dynamism, achieved through periodic ingestion of recent code to\nminimize training data contamination; (2) Scope Graph-based dependency\nanalysis, which enables structured classification of functions into benchmark\ninstances with controlled dependency levels (distinguishing between\nSelf-Contained (SC) tasks for cross-language evaluation and Weakly\nSelf-Contained (WSC) tasks involving permitted library usage); and (3)\nProperty-Based Testing (PBT) for the automated synthesis of rigorous test\nsuites to enable thorough functional verification. Using this pipeline, we\nconstruct CODE2BENCH-2505, the first benchmark derived from 880 recent Python\nprojects spanning diverse domains, comprising 1,163 code generation tasks with\n100% average branch coverage on ground-truth implementations. Extensive\nevaluation of 16 LLMs using CODE2BENCH-2505 reveals that models consistently\nstruggle with SC tasks requiring complex, non-standard logic and cross-language\ntransfer, while showing relatively stronger performance on WSC tasks in Python.\nOur work introduces a contamination-resistant, language-agnostic methodology\nfor dynamic benchmark construction, offering a principled foundation for the\ncomprehensive and realistic evaluation of LLMs on real-world software\ndevelopment tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCODE2BENCH\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u548c\u4f9d\u8d56\u5206\u6790\u65b9\u6cd5\uff0c\u52a8\u6001\u751f\u6210\u6570\u636e\u6c61\u67d3\u53ef\u63a7\u3001\u4e25\u8c28\u6027\u5f3a\u7684\u4ee3\u7801\u751f\u6210\u57fa\u51c6\uff0c\u5e76\u6784\u5efa\u4e86\u6db5\u76d6880\u4e2aPython\u9879\u76ee\u7684CODE2BENCH-2505\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4e3b\u6d41LLMs\u5728\u590d\u6742\u548c\u8de8\u8bed\u8a00\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u6570\u636e\u6c61\u67d3\u548c\u6d4b\u8bd5\u4e25\u8c28\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e0d\u80fd\u6709\u6548\u53cd\u6620\u6a21\u578b\u5728\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86CODE2BENCH\uff0c\u4e00\u5957\u52a8\u6001\u751f\u6210\u3001\u6297\u6c61\u67d3\u7684\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u6d41\u6c34\u7ebf\u3002\u5176\u521b\u65b0\u70b9\u5305\u62ec\uff1a\uff081\uff09\u81ea\u52a8\u52a8\u6001\u6570\u636e\u83b7\u53d6\u673a\u5236\uff0c\u5b9a\u671f\u4eceGitHub\u6536\u96c6\u6700\u65b0\u4ee3\u7801\uff0c\u51cf\u5c11\u8bad\u7ec3\u96c6\u6c61\u67d3\uff1b\uff082\uff09\u57fa\u4e8eScope Graph\u7684\u4f9d\u8d56\u5206\u6790\uff0c\u5c06\u51fd\u6570\u6709\u7ed3\u6784\u6027\u5730\u5206\u7c7b\u4e3a\u4f9d\u8d56\u7a0b\u5ea6\u53d7\u63a7\u7684\u57fa\u51c6\u6837\u672c\uff08\u5305\u62ec\u5b8c\u5168\u81ea\u5305\u542bSC\u548c\u5f31\u81ea\u5305\u542bWSC\uff09\uff1b\uff083\uff09\u57fa\u4e8e\u6027\u8d28\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u751f\u6210\uff08PBT\uff09\uff0c\u786e\u4fdd\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u8bc4\u6d4b\u4e25\u8c28\u6027\u3002", "result": "\u501f\u52a9\u4e0a\u8ff0\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86CODE2BENCH-2505\u57fa\u51c6\uff0c\u8986\u76d6880\u4e2aPython\u771f\u5b9e\u5f00\u6e90\u9879\u76ee\u3001\u51711163\u4e2a\u4efb\u52a1\uff0c\u5e76\u5b9e\u73b0100%\u5206\u652f\u6d4b\u8bd5\u8986\u76d6\u7387\u3002\u5bf916\u79cd\u4e3b\u6d41LLMs\u7684\u8bc4\u6d4b\u663e\u793a\uff1a\u6a21\u578b\u5728\u9700\u8981\u590d\u6742\u903b\u8f91\u548c\u8de8\u8bed\u8a00\u8fc1\u79fb\u7684SC\u4efb\u52a1\u4e0a\u666e\u904d\u8868\u73b0\u8f83\u5f31\uff0c\u800c\u5728\u5141\u8bb8\u4f7f\u7528\u5e93\u7684WSC\u7c7b\u578b\u4efb\u52a1\u4e0a\u8868\u73b0\u76f8\u5bf9\u66f4\u597d\u3002", "conclusion": "CODE2BENCH\u63d0\u51fa\u4e86\u4e00\u79cd\u6297\u6c61\u67d3\u3001\u52a8\u6001\u3001\u4e0e\u8bed\u8a00\u65e0\u5173\u7684\u57fa\u51c6\u6784\u5efa\u65b9\u6cd5\uff0c\u5e76\u9996\u6b21\u4e3aLLMs\u5728\u771f\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u73af\u5883\u4e0b\u7684\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u5168\u9762\u3001\u73b0\u5b9e\u4e14\u4e25\u8c28\u7684\u8bc4\u6d4b\u65b9\u6848\u3002\u5176\u6210\u679c\u4e3a\u63a8\u52a8LLMs\u5728\u5de5\u7a0b\u5316\u573a\u666f\u4e2d\u7684\u53d1\u5c55\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2508.06600", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.06600", "abs": "https://arxiv.org/abs/2508.06600", "authors": ["Zijian Chen", "Xueguang Ma", "Shengyao Zhuang", "Ping Nie", "Kai Zou", "Andrew Liu", "Joshua Green", "Kshama Patel", "Ruoxi Meng", "Mingyi Su", "Sahel Sharifymoghaddam", "Yanxi Li", "Haoran Hong", "Xinyu Shi", "Xuye Liu", "Nandan Thakur", "Crystina Zhang", "Luyu Gao", "Wenhu Chen", "Jimmy Lin"], "title": "BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent", "comment": null, "summary": "Deep-Research agents, which integrate large language models (LLMs) with\nsearch tools, have shown success in improving the effectiveness of handling\ncomplex queries that require iterative search planning and reasoning over\nsearch results. Evaluations on current benchmarks like BrowseComp relies on\nblack-box live web search APIs, have notable limitations in (1) fairness:\ndynamic and opaque web APIs hinder fair comparisons and reproducibility of deep\nresearch methods; (2) transparency: lack of control over the document corpus\nmakes it difficult to isolate retriever contributions. In other words, the\ncurrent evaluations may compare a complete deep research system at a given\ntime, but they do not foster well-controlled experiments to provide insights\ninto the capability of underlying deep research LLMs. To address these\nchallenges, we introduce BrowseComp-Plus, a benchmark derived from BrowseComp,\nemploying a fixed, carefully curated corpus. Each query in BrowseComp-Plus\nincludes human-verified supporting documents and mined challenging negatives,\nenabling controlled experimentation. The benchmark is shown to be effective in\ndistinguishing the performance of deep research systems. For instance, the\nopen-source model Search-R1, when paired with the BM25 retriever, achieves\n3.86% accuracy, whereas the GPT-5 achieves 55.9%. Integrating the GPT-5 with\nthe Qwen3-Embedding-8B retriever further enhances its accuracy to 70.1% with\nfewer search calls. This benchmark allows comprehensive evaluation and\ndisentangled analysis of deep research agents and retrieval methods, fostering\ninsights into retrieval effectiveness, citation accuracy, and context\nengineering in Deep-Research system.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faBrowseComp-Plus\u57fa\u51c6\uff0c\u91c7\u7528\u56fa\u5b9a\u8bed\u6599\uff0c\u4fbf\u4e8e\u516c\u5e73\u3001\u900f\u660e\u5730\u8bc4\u4f30\u6df1\u5ea6\u68c0\u7d22\u4ee3\u7406\u548c\u68c0\u7d22\u65b9\u6cd5\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u57fa\u51c6\u80fd\u663e\u8457\u533a\u5206\u4e0d\u540c\u7cfb\u7edf\u6027\u80fd\uff0c\u4e3a\u5206\u6790\u548c\u4f18\u5316\u76f8\u5173\u6280\u672f\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002", "motivation": "\u5f53\u524d\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u68c0\u7d22\u5de5\u5177\u7684\u6df1\u5ea6\u68c0\u7d22\u4ee3\u7406\uff0c\u5728\u5904\u7406\u590d\u6742\u68c0\u7d22\u89c4\u5212\u4e0e\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002\u7136\u800c\uff0c\u73b0\u6709\u57fa\u51c6\u5982BrowseComp\u7531\u4e8e\u4f9d\u8d56\u9ed1\u76d2\u5728\u7ebf\u641c\u7d22API\uff0c\u5bfc\u81f4\u516c\u5e73\u6027\u3001\u900f\u660e\u6027\u7b49\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff1a\u96be\u4ee5\u53ef\u91cd\u590d\u6bd4\u8f83\uff0c\u4e5f\u65e0\u6cd5\u5355\u72ec\u5206\u6790\u68c0\u7d22\u5668\u6027\u80fd\u3002", "method": "\u4f5c\u8005\u63d0\u51faBrowseComp-Plus\uff0c\u8fd9\u662f\u57fa\u4e8eBrowseComp\u7684\u65b0\u57fa\u51c6\uff0c\u91c7\u7528\u56fa\u5b9a\u4e14\u7cbe\u5fc3\u7b5b\u9009\u7684\u8bed\u6599\u5e93\u3002\u6bcf\u4e2a\u67e5\u8be2\u90fd\u914d\u6709\u4eba\u5de5\u9a8c\u8bc1\u7684\u652f\u6301\u6587\u6863\u548c\u96be\u5ea6\u8f83\u9ad8\u7684\u8d1f\u4f8b\uff0c\u4ee5\u652f\u6301\u53ef\u63a7\u5b9e\u9a8c\u3002\u901a\u8fc7\u8fd9\u4e00\u57fa\u51c6\uff0c\u53ef\u4ee5\u5206\u522b\u5206\u6790\u7cfb\u7edf\u548c\u68c0\u7d22\u5668\u7684\u8d21\u732e\u3002", "result": "\u5728BrowseComp-Plus\u6d4b\u8bd5\u4e2d\uff0c\u5f00\u6e90\u6a21\u578bSearch-R1\u914d\u5408BM25\u68c0\u7d22\u5668\u4ec5\u83b7\u5f973.86%\u51c6\u786e\u7387\uff0c\u800cGPT-5\u8fbe\u5230\u4e8655.9%\u3002\u5c06GPT-5\u4e0eQwen3-Embedding-8B\u68c0\u7d22\u5668\u7ed3\u5408\u540e\uff0c\u51c6\u786e\u7387\u8fdb\u4e00\u6b65\u63d0\u5347\u81f370.1%\uff0c\u4e14\u641c\u7d22\u8c03\u7528\u6b21\u6570\u66f4\u5c11\uff0c\u663e\u793a\u51fa\u4e0d\u540c\u67b6\u6784\u548c\u68c0\u7d22\u624b\u6bb5\u7684\u4f18\u52a3\u3002", "conclusion": "BrowseComp-Plus\u80fd\u591f\u6709\u6548\u533a\u5206\u6df1\u5ea6\u68c0\u7d22\u7cfb\u7edf\u6027\u80fd\uff0c\u5b9e\u73b0\u53ef\u63a7\u3001\u6df1\u5165\u7684\u7cfb\u7edf\u53ca\u65b9\u6cd5\u5206\u6790\uff0c\u5bf9\u68c0\u7d22\u6548\u679c\u3001\u5f15\u7528\u51c6\u786e\u6027\u3001\u4e0a\u4e0b\u6587\u5de5\u7a0b\u7b49\u5177\u6709\u7814\u7a76\u4e0e\u6539\u8fdb\u4ef7\u503c\u3002"}}
{"id": "2508.07198", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.07198", "abs": "https://arxiv.org/abs/2508.07198", "authors": ["Burak Yeti\u015ftiren", "Hong Jin Kang", "Miryung Kim"], "title": "TraceLens: Question-Driven Debugging for Taint Flow Understanding", "comment": null, "summary": "Taint analysis is a security analysis technique used to track the flow of\npotentially dangerous data through an application and its dependent libraries.\nInvestigating why certain unexpected flows appear and why expected flows are\nmissing is an important sensemaking process during end-user taint analysis.\nExisting taint analysis tools often do not provide this end-user debugging\ncapability, where developers can ask why, why-not, and what-if questions about\ndataflows and reason about the impact of configuring sources and sinks, and\nmodels of 3rd-party libraries that abstract permissible and impermissible data\nflows. Furthermore, a tree-view or a list-view used in existing\ntaint-analyzer's visualization makes it difficult to reason about the global\nimpact on connectivity between multiple sources and sinks.\n  Inspired by the insight that sensemaking tool-generated results can be\nsignificantly improved by a QA inquiry process, we propose TraceLens, a first\nend-user question-answer style debugging interface for taint analysis. It\nenables a user to ask why, why-not, and what-if questions to investigate the\nexistence of suspicious flows, the non-existence of expected flows, and the\nglobal impact of third-party library models. TraceLens performs speculative\nwhat-if analysis, to help a user in debugging how different connectivity\nassumptions affect overall results. A user study with 12 participants shows\nthat participants using TraceLens achieved 21% higher accuracy on average,\ncompared to CodeQL. They also reported a 45% reduction in mental demand\n(NASA-TLX) and rated higher confidence in identifying relevant flows using\nTraceLens.", "AI": {"tldr": "\u73b0\u6709\u6c61\u70b9\u5206\u6790\u5de5\u5177\u96be\u4ee5\u8c03\u8bd5\u548c\u7406\u89e3\u590d\u6742\u6570\u636e\u6d41\u3002TraceLens\u7528\u95ee\u7b54\u5f0f\u754c\u9762\u5e2e\u52a9\u7528\u6237\u63a2\u7d22\u548c\u63a8\u7406\u6570\u636e\u6d41\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u51c6\u786e\u7387\u548c\u7528\u6237\u4f53\u9a8c\u5747\u4f18\u4e8e\u4f20\u7edf\u5de5\u5177\u3002", "motivation": "\u6c61\u70b9\u5206\u6790\u662f\u4e00\u79cd\u8ffd\u8e2a\u6f5c\u5728\u5371\u9669\u6570\u636e\u6d41\u7684\u5b89\u5168\u5206\u6790\u6280\u672f\uff0c\u4f46\u73b0\u6709\u5de5\u5177\u7f3a\u4e4f\u7528\u6237\u53cb\u597d\u7684\u8c03\u8bd5\u529f\u80fd\uff0c\u96be\u4ee5\u89e3\u8bfb\u6570\u636e\u6d41\u5f02\u5e38\u548c\u7f3a\u5931\u80cc\u540e\u7684\u539f\u56e0\uff0c\u5e76\u4e0d\u4fbf\u4e8e\u5168\u5c40\u7406\u89e3\u591a\u6e90\u591a\u6c47\u4e4b\u95f4\u7684\u4e92\u8054\u5f71\u54cd\u3002", "method": "\u63d0\u51faTraceLens\uff0c\u4e00\u79cd\u9762\u5411\u7ec8\u7aef\u7528\u6237\u3001\u4ee5\u95ee\u7b54\u5f0f\u4ea4\u4e92\u4e3a\u6838\u5fc3\u7684\u6c61\u70b9\u5206\u6790\u8c03\u8bd5\u754c\u9762\uff0c\u652f\u6301\u7528\u6237\u63d0\u51fawhy\u3001why-not\u3001what-if\u7b49\u95ee\u9898\uff0c\u4ece\u800c\u63a2\u7a76\u53ef\u7591\u6570\u636e\u6d41\u7684\u6e90\u5934\u4e0e\u8def\u5f84\u3001\u9884\u671f\u6570\u636e\u6d41\u7684\u7f3a\u5931\u3001\u4ee5\u53ca\u7b2c\u4e09\u65b9\u5e93\u6a21\u578b\u5bf9\u6574\u4f53\u8fde\u63a5\u6027\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u5229\u7528\u63a8\u6d4b\u6027\u5206\u6790\u8f85\u52a9\u7406\u89e3\u4e0d\u540c\u914d\u7f6e\u5047\u8bbe\u4e0b\u7684\u7ed3\u679c\u53d8\u5316\u3002", "result": "\u901a\u8fc712\u4eba\u7528\u6237\u5b9e\u9a8c\uff0c\u4f7f\u7528TraceLens\u7684\u53c2\u4e0e\u8005\u5728\u8bc6\u522b\u76f8\u5173\u6570\u636e\u6d41\u51c6\u786e\u7387\u65b9\u9762\u6bd4\u4f7f\u7528CodeQL\u63d0\u5347\u4e8621%\uff0c\u5fc3\u7406\u8d1f\u62c5\u964d\u4f4e\u4e8645%\uff08NASA-TLX\uff09\uff0c\u4e14\u7528\u6237\u5bf9\u7ed3\u679c\u7684\u4fe1\u5fc3\u663e\u8457\u63d0\u5347\u3002", "conclusion": "TraceLens\u901a\u8fc7\u521b\u65b0\u7684\u95ee\u7b54\u5f0f\u8c03\u8bd5\u65b9\u5f0f\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6c61\u70b9\u5206\u6790\u7684\u51c6\u786e\u6027\u3001\u7528\u6237\u4f53\u9a8c\u548c\u5168\u5c40\u7406\u89e3\uff0c\u6709\u671b\u63a8\u52a8\u5b89\u5168\u5206\u6790\u5de5\u5177\u7684\u53ef\u7528\u6027\u8fdb\u6b65\u3002"}}
{"id": "2508.06621", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.06621", "abs": "https://arxiv.org/abs/2508.06621", "authors": ["Tomohiro Sawada", "Kartik Goyal"], "title": "Train It and Forget It: Merge Lists are Unnecessary for BPE Inference in Language Models", "comment": "Submitted to EMNLP", "summary": "Standard Byte-Pair Encoding (BPE) tokenization compresses text by pairing a\nlearned token vocabulary with a detailed merge list. Recent work has shown that\nthis merge list exposes a potential attack surface for extracting information\nabout language model's training data. In this paper, we explore the downstream\nimpact of BPE inference algorithms that do not rely on this merge list at all,\nand hence differ from the encoding process during BPE training. To address this\nquestion, we investigate two broad classes of BPE inference schemes that differ\nfrom BPE application during training: a) targeted deviation from merge-lists\nincluding random merge orders, and various corruptions of merge list involving\ndeletion/truncation, and b) non-targeted BPE inference algorithms that do not\ndepend on the merge list but focus on compressing the text either greedily or\nexactly. Extensive experiments across diverse language modeling tasks like\naccuracy-based QA benchmarks, machine translation, and open-ended generation\nreveal that while targeted deviation from the merge lists exhibits significant\ndegradation in language model performance, the non-targeted merge-list-free\ninference algorithms result in minimal impact on downstream performance that is\noften much smaller than expected. These findings pave way for simpler and\npotentially more privacy-preserving tokenization schemes that do not\ncatastrophically compromise model performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u73b0\uff0c\u65e0\u9700\u4f9d\u8d56BPE\u7684merge list\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u5206\u8bcd\uff0c\u5bf9\u6a21\u578b\u6027\u80fd\u5f71\u54cd\u5f88\u5c0f\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u5206\u8bcd\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\u3002", "motivation": "\u8fd1\u5e74\u6765\u7814\u7a76\u663e\u793a\uff0c\u6807\u51c6BPE\u5206\u8bcd\u4e2d\u7684merge list\u66b4\u9732\u4e86\u8bad\u7ec3\u6570\u636e\u7684\u4fe1\u606f\uff0c\u5b58\u5728\u9690\u79c1\u98ce\u9669\u3002\u4f5c\u8005\u5e0c\u671b\u63a2\u7d22\u4e0d\u4f9d\u8d56merge list\u7684BPE\u63a8\u7406\u7b97\u6cd5\u5bf9\u4e0b\u6e38\u4efb\u52a1\u7684\u5f71\u54cd\uff0c\u5bfb\u6c42\u66f4\u5b89\u5168\u7684\u5206\u8bcd\u65b9\u6848\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u5e76\u8bc4\u4f30\u4e86\u4e24\u7c7b\u4e0d\u540c\u4e8eBPE\u8bad\u7ec3\u7684\u63a8\u7406\u7b97\u6cd5\uff1a\uff08a\uff09\u6709\u9488\u5bf9\u6027\u5730\u504f\u79bbmerge list\uff0c\u5982\u968f\u673a\u5408\u5e76\u6216\u5bf9merge list\u505a\u5220\u51cf/\u622a\u65ad\u7b49\uff1b\uff08b\uff09\u5b8c\u5168\u4e0d\u4f9d\u8d56merge list\uff0c\u91c7\u7528\u8d2a\u5fc3\u6216\u7cbe\u786e\u538b\u7f29\u65b9\u6848\u5b9e\u73b0\u6587\u672c\u538b\u7f29\u3002\u7ed3\u5408\u591a\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u3001QA\u3001\u673a\u5668\u7ffb\u8bd1\u3001\u5f00\u653e\u6587\u672c\u751f\u6210\u7b49\u573a\u666f\uff0c\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\u3002", "result": "\u9488\u5bf9merge list\u7684\u6709\u76ee\u6807\u53d8\u5f02\u4f1a\u5bfc\u81f4\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u660e\u663e\u4e0b\u964d\uff1b\u800c\u4e0d\u4f9d\u8d56merge list\u7684\u65e0\u76ee\u6807\u63a8\u7406\u7b97\u6cd5\u5bf9\u4e0b\u6e38\u4efb\u52a1\u5f71\u54cd\u6781\u5c0f\uff0c\u8fdc\u4f4e\u4e8e\u9884\u671f\u3002", "conclusion": "\u4e0d\u4f7f\u7528merge list\u4e5f\u80fd\u5b9e\u73b0\u6709\u6548\u7684BPE\u5206\u8bcd\uff0c\u4e14\u4e0d\u4f1a\u4e25\u91cd\u5f71\u54cd\u6a21\u578b\u8868\u73b0\u3002\u8fd9\u4e3a\u5f00\u53d1\u66f4\u7b80\u5355\u4e14\u66f4\u5177\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\u7684\u5206\u8bcd\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.07371", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07371", "abs": "https://arxiv.org/abs/2508.07371", "authors": ["Yi Zhong", "Hongchao Liu", "Di ZHao"], "title": "AutoAssert 1: A LoRA Fine-Tuned LLM Model for Efficient Automated Assertion Generation", "comment": "16pages,6figures", "summary": "As the complexity of software systems continues to increase, the demand for\nautomated testing and maintenance tools is growing exponentially. To meet this\nurgent need, we propose a new assertion generation method based on Hardware\nDescription Language (HDL). This method combines a lightweight,\nparameter-adjustable large language model (LLM) with the Unsloth platform to\nautomatically generate test cases, thereby significantly reducing training\ncosts without sacrificing accuracy or generalization performance. Empirical\nevaluation shows that our method can efficiently generate assertions that\nstrictly conform to the hardware logic. This framework provides a robust and\nflexible solution to modern software testing and maintenance challenges.\nhttps://github.com/liusu-orange/AutoAssert-1 and\nhttps://gitee.com/OpenBPU/auto-assert1 are the locations of the source code.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u8f7b\u91cf\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\u4e0eUnsloth\u5e73\u53f0\uff0c\u81ea\u52a8\u751f\u6210HDL\u65ad\u8a00\uff0c\u6709\u6548\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\uff0c\u540c\u65f6\u63d0\u9ad8\u51c6\u786e\u7387\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u8f6f\u786c\u4ef6\u7cfb\u7edf\u81ea\u52a8\u5316\u6d4b\u8bd5\u548c\u7ef4\u62a4\u63d0\u4f9b\u4e86\u521b\u65b0\u5de5\u5177\u3002", "motivation": "\u8f6f\u4ef6\u7cfb\u7edf\u590d\u6742\u5ea6\u4e0d\u65ad\u63d0\u5347\uff0c\u5bf9\u81ea\u52a8\u5316\u6d4b\u8bd5\u548c\u7ef4\u62a4\u5de5\u5177\u7684\u9700\u6c42\u6fc0\u589e\uff0c\u9700\u8981\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u81ea\u52a8\u5316\u65ad\u8a00\u751f\u6210\u65b9\u5f0f\u6765\u8f85\u52a9\u6d4b\u8bd5\u4e0e\u7ef4\u62a4\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u786c\u4ef6\u63cf\u8ff0\u8bed\u8a00\uff08HDL\uff09\u7684\u65ad\u8a00\u751f\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408\u53ef\u8c03\u53c2\u6570\u7684\u8f7b\u91cf\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0eUnsloth\u5e73\u53f0\u5b9e\u73b0\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u3002\u5176\u76ee\u6807\u662f\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u8bc1\u751f\u6210\u65ad\u8a00\u7684\u51c6\u786e\u6027\u4e0e\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u5730\u751f\u6210\u4e25\u683c\u7b26\u5408\u786c\u4ef6\u903b\u8f91\u7684\u65ad\u8a00\uff0c\u4e14\u5177\u6709\u8f83\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u4e3a\u73b0\u4ee3\u8f6f\u4ef6\u6d4b\u8bd5\u4e0e\u7ef4\u62a4\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5728\u5b9e\u9645\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8f83\u597d\u7684\u6548\u679c\u3002"}}
{"id": "2508.06649", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.06649", "abs": "https://arxiv.org/abs/2508.06649", "authors": ["Daniel Wang", "Eli Brignac", "Minjia Mao", "Xiao Fang"], "title": "Measuring Stereotype and Deviation Biases in Large Language Models", "comment": null, "summary": "Large language models (LLMs) are widely applied across diverse domains,\nraising concerns about their limitations and potential risks. In this study, we\ninvestigate two types of bias that LLMs may display: stereotype bias and\ndeviation bias. Stereotype bias refers to when LLMs consistently associate\nspecific traits with a particular demographic group. Deviation bias reflects\nthe disparity between the demographic distributions extracted from\nLLM-generated content and real-world demographic distributions. By asking four\nadvanced LLMs to generate profiles of individuals, we examine the associations\nbetween each demographic group and attributes such as political affiliation,\nreligion, and sexual orientation. Our experimental results show that all\nexamined LLMs exhibit both significant stereotype bias and deviation bias\ntowards multiple groups. Our findings uncover the biases that occur when LLMs\ninfer user attributes and shed light on the potential harms of LLM-generated\noutputs.", "AI": {"tldr": "\u8bba\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6d89\u53ca\u4eba\u53e3\u5c5e\u6027\u751f\u6210\u4efb\u52a1\u65f6\u6613\u51fa\u73b0\u7684\u523b\u677f\u5370\u8c61\u548c\u5206\u5e03\u504f\u79bb\u504f\u89c1\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5f53\u524d\u4e3b\u6d41LLM\u666e\u904d\u5b58\u5728\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u793a\u9700\u8b66\u60d5\u5176\u8f93\u51fa\u4e2d\u7684\u6f5c\u5728\u793e\u4f1a\u5371\u5bb3\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5404\u4e2a\u9886\u57df\uff0c\u4f46\u5176\u504f\u89c1\u548c\u6f5c\u5728\u98ce\u9669\u5f15\u53d1\u5173\u6ce8\uff0c\u7279\u522b\u662f\u6d89\u53ca\u7279\u5b9a\u4eba\u7fa4\u7684\u523b\u677f\u5370\u8c61\u548c\u4e0e\u73b0\u5b9e\u4e16\u754c\u5dee\u5f02\u7684\u504f\u79bb\u3002", "method": "\u672c\u6587\u901a\u8fc7\u8ba9\u56db\u79cd\u5148\u8fdb\u7684LLM\u751f\u6210\u4e2a\u4f53\u6863\u6848\uff0c\u5206\u6790\u6a21\u578b\u8f93\u51fa\u4e2d\u5404\u7fa4\u4f53\u4e0e\u653f\u6cbb\u3001\u5b97\u6559\u548c\u6027\u53d6\u5411\u7b49\u5c5e\u6027\u7684\u5173\u8054\uff0c\u5b9e\u8bc1\u68c0\u9a8c\u4e86\u523b\u677f\u5370\u8c61\u504f\u89c1\u4e0e\u5206\u5e03\u504f\u79bb\u504f\u89c1\u3002", "result": "\u6240\u6709\u88ab\u6d4b\u8bd5\u7684LLM\u5728\u591a\u4e2a\u7fa4\u4f53\u4e0a\u90fd\u5c55\u793a\u4e86\u663e\u8457\u7684\u523b\u677f\u5370\u8c61\u504f\u89c1\u548c\u5206\u5e03\u504f\u79bb\u504f\u89c1\u3002", "conclusion": "LLMs\u5728\u63a8\u65ad\u7528\u6237\u5c5e\u6027\u65f6\u4f1a\u4ea7\u751f\u4e0d\u540c\u7c7b\u578b\u7684\u504f\u89c1\uff0c\u8fd9\u4e9b\u504f\u89c1\u53ef\u80fd\u5bf9\u5176\u751f\u6210\u5185\u5bb9\u7684\u516c\u5e73\u6027\u548c\u5ba2\u89c2\u6027\u4ea7\u751f\u6f5c\u5728\u5371\u5bb3\u3002"}}
{"id": "2508.07486", "categories": ["cs.SE", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.07486", "abs": "https://arxiv.org/abs/2508.07486", "authors": ["Morteza Ziabakhsh", "Kiyan Rezaee", "Sadegh Eskandari", "Seyed Amir Hossein Tabatabaei", "Mohammad M. Ghassemi"], "title": "Extracting Overlapping Microservices from Monolithic Code via Deep Semantic Embeddings and Graph Neural Network-Based Soft Clustering", "comment": null, "summary": "Modern software systems are increasingly shifting from monolithic\narchitectures to microservices to enhance scalability, maintainability, and\ndeployment flexibility. Existing microservice extraction methods typically rely\non hard clustering, assigning each software component to a single microservice.\nThis approach often increases inter-service coupling and reduces intra-service\ncohesion. We propose Mo2oM (Monolithic to Overlapping Microservices), a\nframework that formulates microservice extraction as a soft clustering problem,\nallowing components to belong probabilistically to multiple microservices. This\napproach is inspired by expert-driven decompositions, where practitioners\nintentionally replicate certain software components across services to reduce\ncommunication overhead. Mo2oM combines deep semantic embeddings with structural\ndependencies extracted from methodcall graphs to capture both functional and\narchitectural relationships. A graph neural network-based soft clustering\nalgorithm then generates the final set of microservices. We evaluate Mo2oM on\nfour open-source monolithic benchmarks and compare it against eight\nstate-of-the-art baselines. Our results demonstrate that Mo2oM achieves\nimprovements of up to 40.97% in structural modularity (balancing cohesion and\ncoupling), 58% in inter-service call percentage (communication overhead),\n26.16% in interface number (modularity and decoupling), and 38.96% in\nnon-extreme distribution (service size balance) across all benchmarks.", "AI": {"tldr": "Mo2oM\u7528\u6df1\u5ea6\u8bed\u4e49\u5d4c\u5165\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u5fae\u670d\u52a1\u8f6f\u805a\u7c7b\u62bd\u53d6\uff0c\u652f\u6301\u7ec4\u4ef6\u91cd\u53e0\u5206\u914d\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5176\u5728\u591a\u4e2a\u7ef4\u5ea6\u5927\u5e45\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u7cfb\u7edf\u6a21\u5757\u6027\u548c\u670d\u52a1\u5e73\u8861\u6027\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u7cfb\u7edf\u4e3a\u63d0\u5347\u53ef\u6269\u5c55\u6027\u3001\u53ef\u7ef4\u62a4\u6027\u548c\u90e8\u7f72\u7075\u6d3b\u6027\uff0c\u4ece\u5355\u4f53\u67b6\u6784\u5411\u5fae\u670d\u52a1\u8fc1\u79fb\u3002\u76ee\u524d\u4e3b\u6d41\u7684\u5fae\u670d\u52a1\u62bd\u53d6\u65b9\u6cd5\u4f7f\u7528\u786c\u805a\u7c7b\uff0c\u5c06\u6bcf\u4e2a\u7ec4\u4ef6\u5206\u914d\u5230\u5355\u4e2a\u5fae\u670d\u52a1\uff0c\u5bb9\u6613\u5bfc\u81f4\u8de8\u670d\u52a1\u8026\u5408\u589e\u52a0\u3001\u670d\u52a1\u5185\u90e8\u5185\u805a\u6027\u4e0b\u964d\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u65b0\u7684\u5fae\u670d\u52a1\u62bd\u53d6\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51faMo2oM\uff08Monolithic to Overlapping Microservices\uff09\u6846\u67b6\uff0c\u5c06\u5fae\u670d\u52a1\u62bd\u53d6\u5efa\u6a21\u4e3a\u8f6f\u805a\u7c7b\u95ee\u9898\uff0c\u4f7f\u7ec4\u4ef6\u53ef\u4ee5\u4ee5\u6982\u7387\u65b9\u5f0f\u5f52\u5c5e\u4e8e\u591a\u4e2a\u5fae\u670d\u52a1\u3002\u65b9\u6cd5\u878d\u5408\u4e86\u6df1\u5ea6\u8bed\u4e49\u5d4c\u5165\u4e0e\u57fa\u4e8e\u65b9\u6cd5\u8c03\u7528\u56fe\u7684\u7ed3\u6784\u4f9d\u8d56\uff0c\u5e76\u91c7\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u8f6f\u805a\u7c7b\u7b97\u6cd5\u751f\u6210\u6700\u7ec8\u5fae\u670d\u52a1\u96c6\u5408\u3002", "result": "Mo2oM\u5728\u56db\u4e2a\u5f00\u6e90\u5355\u4f53\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0c\u4e0e\u516b\u79cd\u5148\u8fdb\u65b9\u6cd5\u5bf9\u6bd4\uff0c\u7ed3\u6784\u6a21\u5757\u6027\u63d0\u5347\u6700\u591a40.97%\uff0c\u670d\u52a1\u95f4\u8c03\u7528\u6bd4\u63d0\u534758%\uff0c\u63a5\u53e3\u6570\u91cf\u63d0\u534726.16%\uff0c\u670d\u52a1\u89c4\u6a21\u5206\u5e03\u5e73\u8861\u63d0\u534738.96%\u3002", "conclusion": "Mo2oM\u901a\u8fc7\u8f6f\u805a\u7c7b\u65b9\u6cd5\u663e\u8457\u89e3\u51b3\u4e86\u73b0\u6709\u5fae\u670d\u52a1\u62bd\u53d6\u5728\u8026\u5408\u6027\u3001\u5185\u805a\u6027\u548c\u89c4\u6a21\u5206\u5e03\u7b49\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u5fae\u670d\u52a1\u67b6\u6784\u7684\u6574\u4f53\u8d28\u91cf\u548c\u6027\u80fd\u3002"}}
{"id": "2508.06665", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.06665", "abs": "https://arxiv.org/abs/2508.06665", "authors": ["Jonathan Shaw", "Dillon Mee", "Timothy Khouw", "Zackary Leech", "Daniel Wilson"], "title": "Testing the Limits of Machine Translation from One Book", "comment": null, "summary": "Current state-of-the-art models demonstrate capacity to leverage in-context\nlearning to translate into previously unseen language contexts. Tanzer et al.\n[2024] utilize language materials (e.g. a grammar) to improve translation\nquality for Kalamang using large language models (LLMs). We focus on Kanuri, a\nlanguage that, despite having substantial speaker population, has minimal\ndigital resources. We design two datasets for evaluation: one focused on health\nand humanitarian terms, and another containing generalized terminology,\ninvestigating how domain-specific tasks impact LLM translation quality.\n  By providing different combinations of language resources (grammar,\ndictionary, and parallel sentences), we measure LLM translation effectiveness,\ncomparing results to native speaker translations and human linguist\nperformance. We evaluate using both automatic metrics and native speaker\nassessments of fluency and accuracy.\n  Results demonstrate that parallel sentences remain the most effective data\nsource, outperforming other methods in human evaluations and automatic metrics.\nWhile incorporating grammar improves over zero-shot translation, it fails as an\neffective standalone data source. Human evaluations reveal that LLMs achieve\naccuracy (meaning) more effectively than fluency (grammaticality).\n  These findings suggest LLM translation evaluation benefits from\nmultidimensional assessment beyond simple accuracy metrics, and that grammar\nalone, without parallel sentences, does not provide sufficient context for\neffective domain-specific translation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\u5728\u8d44\u6e90\u7a00\u7f3a\u8bed\u8a00\uff08\u5982Kanuri\uff09\u7684\u7ffb\u8bd1\u4e2d\uff0c\u5e73\u884c\u8bed\u53e5\u5bf9\u5927\u6a21\u578b\u5e2e\u52a9\u6700\u5927\uff0c\u4ec5\u6709\u8bed\u6cd5\u4fe1\u606f\u8fdc\u8fdc\u4e0d\u591f\uff0cLLM\u66f4\u6613\u4fdd\u8bc1\u8bed\u4e49\u51c6\u786e\u4f46\u96be\u4ee5\u4fdd\u8bc1\u8bed\u6cd5\u6d41\u7545\uff0c\u63d0\u793a\u672a\u6765\u5e94\u6ce8\u91cd\u591a\u7ef4\u5ea6\u8bc4\u4f30\u53ca\u8bed\u6599\u5efa\u8bbe\u3002", "motivation": "\u9488\u5bf9Kanuri\u8fd9\u79cd\u4eba\u53e3\u4f17\u591a\u4f46\u6570\u5b57\u8d44\u6e90\u7a00\u7f3a\u7684\u8bed\u8a00\uff0c\u63a2\u7a76\u5982\u4f55\u5229\u7528\u5927\u6a21\u578b\u548c\u6709\u9650\u8bed\u6599\u8d44\u6e90\uff08\u8bed\u6cd5\u3001\u8bcd\u5178\u3001\u5e73\u884c\u8bed\u53e5\uff09\u63d0\u5347\u5176\u7ffb\u8bd1\u8d28\u91cf\uff0c\u5e76\u4e86\u89e3\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u5982\u4f55\u5f71\u54cd\u7ffb\u8bd1\u8868\u73b0\u3002", "method": "\u8bbe\u8ba1\u4e24\u4e2a\u8bc4\u4f30\u6570\u636e\u96c6\uff08\u5065\u5eb7/\u4eba\u9053\u4e3b\u4e49\u672f\u8bed\u548c\u901a\u7528\u672f\u8bed\uff09\uff0c\u5411LLM\u63d0\u4f9b\u4e0d\u540c\u7ec4\u5408\u7684\u8bed\u8a00\u8d44\u6e90\uff0c\u6d4b\u91cf\u5176\u7ffb\u8bd1\u6548\u679c\uff0c\u4e0e\u6bcd\u8bed\u8005\u53ca\u4eba\u7c7b\u8bed\u8a00\u5b66\u5bb6\u8bd1\u6587\u6bd4\u8f83\uff0c\u5e76\u7ed3\u5408\u81ea\u52a8\u6307\u6807\u53ca\u6bcd\u8bed\u8005\u6d41\u5229\u5ea6\u3001\u51c6\u786e\u6027\u8bc4\u4ef7\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u63d0\u4f9b\u5e73\u884c\u8bed\u53e5\u662f\u6700\u6709\u6548\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\u7684\u65b9\u6cd5\uff0c\u65e0\u8bba\u5728\u4eba\u7c7b\u8bc4\u4ef7\u8fd8\u662f\u81ea\u52a8\u6307\u6807\u4e0a\u8868\u73b0\u6700\u597d\u3002\u4ec5\u4f9d\u9760\u8bed\u6cd5\u4fe1\u606f\u867d\u4f18\u4e8e\u96f6\u6837\u672c\uff0c\u4f46\u96be\u4ee5\u5355\u72ec\u80dc\u4efb\u9886\u57df\u7ffb\u8bd1\u4efb\u52a1\u3002LLM\u5728\u4f20\u8fbe\u51c6\u786e\u610f\u4e49\u65b9\u9762\u4f18\u4e8e\u751f\u6210\u8bed\u6cd5\u6d41\u7545\u6587\u672c\u3002", "conclusion": "LLM\u7ffb\u8bd1\u8bc4\u4f30\u5e94\u91c7\u7528\u591a\u7ef4\u5ea6\u6807\u51c6\uff0c\u5355\u9760\u8bed\u6cd5\uff08\u65e0\u5e73\u884c\u8bed\u53e5\uff09\u96be\u4ee5\u6ee1\u8db3\u6709\u6548\u9886\u57df\u7ffb\u8bd1\u9700\u6c42\u3002\u5e73\u884c\u8bed\u53e5\u4f9d\u7136\u662f\u63d0\u5347\u6570\u5b57\u8d44\u6e90\u532e\u4e4f\u8bed\u8a00\u7ffb\u8bd1\u8d28\u91cf\u7684\u5173\u952e\u3002"}}
{"id": "2508.07881", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.07881", "abs": "https://arxiv.org/abs/2508.07881", "authors": ["Henna Tammia", "Benjamin K\u00e4m\u00e4", "Ella Peltonen"], "title": "Adopting Road-Weather Open Data in Route Recommendation Engine", "comment": null, "summary": "Digitraffic, Finland's open road data interface, provides access to\nnationwide road sensors with more than 2,300 real-time attributes from 1,814\nstations. However, efficiently utilizing such a versatile data API for a\npractical application requires a deeper understanding of the data qualities,\npreprocessing phases, and machine learning tools. This paper discusses the\nchallenges of large-scale road weather and traffic data. We go through the\nroad-weather-related attributes from DigiTraffic as a practical example of\nprocesses required to work with such a dataset. In addition, we provide a\nmethodology for efficient data utilization for the target application, a\npersonalized road recommendation engine based on a simple routing application.\nWe validate our solution based on real-world data, showing we can efficiently\nidentify and recommend personalized routes for three different driver profiles.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u82ac\u5170\u9053\u8def\u6570\u636e\u63a5\u53e3 DigiTraffic \u7684\u6570\u636e\u7279\u6027\u4e0e\u5904\u7406\u6d41\u7a0b\uff0c\u5e76\u63d0\u51fa\u4e2a\u6027\u5316\u9053\u8def\u63a8\u8350\u65b9\u6cd5\uff0c\u7ecf\u5b9e\u6d4b\u53ef\u9ad8\u6548\u5bf9\u4e0d\u540c\u7528\u6237\u8fdb\u884c\u4e13\u5c5e\u8def\u7ebf\u63a8\u8350\u3002", "motivation": "Digitraffic \u63d0\u4f9b\u4e86\u5e9e\u5927\u7684\u5b9e\u65f6\u9053\u8def\u4f20\u611f\u6570\u636e\uff0c\u5e94\u7528\u8fd9\u4e9b\u6570\u636e\u4e8e\u5b9e\u9645\u573a\u666f\u9700\u8981\u6df1\u5165\u7406\u89e3\u6570\u636e\u6027\u8d28\u3001\u9884\u5904\u7406\u8fc7\u7a0b\uff0c\u4ee5\u53ca\u76f8\u5173\u673a\u5668\u5b66\u4e60\u5de5\u5177\u3002", "method": "\u8be6\u7ec6\u5206\u6790 DigiTraffic \u8def\u51b5\u548c\u6c14\u8c61\u76f8\u5173\u5c5e\u6027\uff0c\u4ecb\u7ecd\u9ad8\u6548\u6570\u636e\u5229\u7528\u65b9\u6cd5\uff0c\u6784\u5efa\u5e76\u9a8c\u8bc1\u4e2a\u6027\u5316\u9053\u8def\u63a8\u8350\u5f15\u64ce\u3002", "result": "\u5229\u7528\u771f\u5b9e\u4e16\u754c\u6570\u636e\uff0c\u80fd\u591f\u9488\u5bf9\u4e09\u79cd\u4e0d\u540c\u9a7e\u9a76\u5458\u753b\u50cf\uff0c\u51c6\u786e\u5e76\u9ad8\u6548\u5730\u63a8\u8350\u4e2a\u6027\u5316\u8def\u7ebf\u3002", "conclusion": "\u6709\u6548\u7684\u5927\u89c4\u6a21\u9053\u8def\u548c\u6c14\u8c61\u6570\u636e\u5904\u7406\u6d41\u7a0b\u80fd\u591f\u652f\u6301\u4e2a\u6027\u5316\u9053\u8def\u63a8\u8350\u7cfb\u7edf\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2508.06671", "categories": ["cs.CL", "cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.06671", "abs": "https://arxiv.org/abs/2508.06671", "authors": ["Swati Rajwal", "Shivank Garg", "Reem Abdel-Salam", "Abdelrahman Zayed"], "title": "Do Biased Models Have Biased Thoughts?", "comment": "Accepted at main track of the Second Conference on Language Modeling\n  (COLM 2025)", "summary": "The impressive performance of language models is undeniable. However, the\npresence of biases based on gender, race, socio-economic status, physical\nappearance, and sexual orientation makes the deployment of language models\nchallenging. This paper studies the effect of chain-of-thought prompting, a\nrecent approach that studies the steps followed by the model before it\nresponds, on fairness. More specifically, we ask the following question:\n\\textit{Do biased models have biased thoughts}? To answer our question, we\nconduct experiments on $5$ popular large language models using fairness metrics\nto quantify $11$ different biases in the model's thoughts and output. Our\nresults show that the bias in the thinking steps is not highly correlated with\nthe output bias (less than $0.6$ correlation with a $p$-value smaller than\n$0.001$ in most cases). In other words, unlike human beings, the tested models\nwith biased decisions do not always possess biased thoughts.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7684\u504f\u89c1\u5e76\u4e0d\u603b\u6765\u6e90\u4e8e\u5176\u601d\u7ef4\u94fe\u6b65\u9aa4\u4e2d\u7684\u504f\u89c1\uff0c\u4e8c\u8005\u76f8\u5173\u6027\u8f83\u4f4e\u3002\u56e0\u6b64\uff0c\u6a21\u578b\u4ea7\u751f\u5e26\u6709\u504f\u89c1\u8f93\u51fa\u65f6\uff0c\u5176\u63a8\u7406\u94fe\u672a\u5fc5\u540c\u6837\u5b58\u5728\u76f8\u5e94\u504f\u89c1\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c55\u73b0\u51fa\u8272\u80fd\u529b\uff0c\u4f46\u4ecd\u5b58\u5728\u5982\u6027\u522b\u3001\u79cd\u65cf\u3001\u793e\u4f1a\u7ecf\u6d4e\u5730\u4f4d\u3001\u5916\u8c8c\u548c\u6027\u53d6\u5411\u7b49\u65b9\u9762\u7684\u504f\u89c1\u95ee\u9898\uff0c\u8fd9\u4e9b\u504f\u89c1\u5f71\u54cd\u4e86\u6a21\u578b\u7684\u5b9e\u9645\u90e8\u7f72\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u5982\u4f55\u8bc6\u522b\u548c\u7f13\u89e3\u6a21\u578b\u4e2d\u7684\u504f\u89c1\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u672c\u6587\u91c7\u7528chain-of-thought prompting\uff08\u601d\u7ef4\u94fe\u63d0\u793a\u6cd5\uff09\uff0c\u5206\u6790\u6a21\u578b\u5728\u751f\u6210\u7b54\u6848\u524d\u7684\u63a8\u7406\u6b65\u9aa4\u3002\u901a\u8fc7\u57285\u4e2a\u4e3b\u6d41\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\uff0c\u5229\u7528\u516c\u5e73\u6027\u6307\u6807\u8bc4\u4f30\u6a21\u578b\u5728\u601d\u7ef4\u94fe\u8fc7\u7a0b\u4e0e\u6700\u7ec8\u8f93\u51fa\u4e2d\u768411\u7c7b\u504f\u89c1\uff0c\u5e76\u8fdb\u884c\u76f8\u5173\u6027\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0c\u6a21\u578b\u5728\u601d\u7ef4\u94fe\u6b65\u9aa4\u4e2d\u7684\u504f\u89c1\u4e0e\u6700\u7ec8\u8f93\u51fa\u504f\u89c1\u7684\u76f8\u5173\u6027\u8f83\u4f4e\uff08\u76f8\u5173\u7cfb\u6570\u5c0f\u4e8e0.6\uff0c\u4e14p\u503c\u5c0f\u4e8e0.001\uff09\u3002\u8fd9\u8bf4\u660e\uff0c\u4e0e\u4eba\u7c7b\u4e0d\u540c\uff0c\u8fd9\u4e9b\u6a21\u578b\u5373\u4f7f\u8f93\u51fa\u5b58\u5728\u504f\u89c1\uff0c\u5176\u63a8\u7406\u8fc7\u7a0b\u672a\u5fc5\u4e5f\u90fd\u5e26\u6709\u540c\u6837\u7684\u504f\u89c1\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u94fe\u4e2d\u7684\u504f\u89c1\u4e0e\u8f93\u51fa\u504f\u89c1\u4e4b\u95f4\u76f8\u5173\u6027\u8f83\u4f4e\uff0c\u63d0\u793a\u5bf9\u6a21\u578b\u504f\u89c1\u7684\u5206\u6790\u9700\u8981\u540c\u65f6\u5173\u6ce8\u8f93\u51fa\u548c\u4e2d\u95f4\u63a8\u7406\u8fc7\u7a0b\uff0c\u4e0d\u80fd\u4ec5\u51ed\u8868\u9762\u7ed3\u679c\u5224\u65ad\u6a21\u578b\u672c\u8eab\u7684\u201c\u601d\u7ef4\u201d\u504f\u89c1\u3002"}}
{"id": "2508.07935", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.07935", "abs": "https://arxiv.org/abs/2508.07935", "authors": ["Jingwen Zhou", "Jieshan Chen", "Qinghua Lu", "Dehai Zhao", "Liming Zhu"], "title": "SHIELDA: Structured Handling of Exceptions in LLM-Driven Agentic Workflows", "comment": null, "summary": "Large Language Model (LLM) agentic systems are software systems powered by\nLLMs that autonomously reason, plan, and execute multi-step workflows to\nachieve human goals, rather than merely executing predefined steps. During\nexecution, these workflows frequently encounter exceptions. Existing exception\nhandling solutions often treat exceptions superficially, failing to trace\nexecution-phase exceptions to their reasoning-phase root causes. Furthermore,\ntheir recovery logic is brittle, lacking structured escalation pathways when\ninitial attempts fail. To tackle these challenges, we first present a\ncomprehensive taxonomy of 36 exception types across 12 agent artifacts.\nBuilding on this, we propose SHIELDA (Structured Handling of Exceptions in\nLLM-Driven Agentic Workflows), a modular runtime exception handling framework\nfor LLM agentic workflows. SHIELDA uses an exception classifier to select a\npredefined exception handling pattern from a handling pattern registry. These\npatterns are then executed via a structured handling executor, comprising local\nhandling, flow control, and state recovery, to enable phase-aware recovery by\nlinking exceptions to their root causes and facilitating composable strategies.\nWe validate SHIELDA's effectiveness through a case study on the AutoPR agent,\ndemonstrating effective, cross-phase recovery from a reasoning-induced\nexception.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSHIELDA\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u5bf9LLM\u4ee3\u7406\u6d41\u6c34\u7ebf\u4e2d\u5f02\u5e38\u7684\u7cfb\u7edf\u6027\u3001\u7ed3\u6784\u5316\u5904\u7406\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u7684LLM\u4ee3\u7406\u7cfb\u7edf\u5f02\u5e38\u5904\u7406\u65b9\u5f0f\u5f80\u5f80\u53ea\u505a\u8868\u9762\u5904\u7406\uff0c\u4e0d\u80fd\u8ffd\u6eaf\u5f02\u5e38\u6839\u672c\u539f\u56e0\uff0c\u4e14\u6062\u590d\u7b56\u7565\u7f3a\u4e4f\u5f39\u6027\u548c\u7ed3\u6784\u5316\u6d41\u7a0b\uff0c\u5bfc\u81f4\u7cfb\u7edf\u9c81\u68d2\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684LLM\u4ee3\u7406\u5de5\u4f5c\u6d41\u5f02\u5e38\u5904\u7406\u6846\u67b6SHIELDA\u3002\u5b83\u5305\u62ec\u5f02\u5e38\u7c7b\u578b\u5206\u7c7b\u3001\u5f02\u5e38\u6a21\u5f0f\u9009\u62e9\u548c\u7ec4\u5408\u5316\u7684\u7ed3\u6784\u5316\u6062\u590d\u6267\u884c\uff0c\u5173\u8054\u5f02\u5e38\u4e0e\u6839\u56e0\uff0c\u5e76\u6267\u884c\u5206\u9636\u6bb5\u7684\u3001\u53ef\u7ec4\u5408\u7684\u6062\u590d\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u5728AutoPR\u4ee3\u7406\u4e0a\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u9a8c\u8bc1\u4e86SHIELDA\u53ef\u4ee5\u6709\u6548\u5730\u8de8\u9636\u6bb5\u6062\u590d\u56e0\u63a8\u7406\u9519\u8bef\u5f15\u53d1\u7684\u5f02\u5e38\u3002", "conclusion": "SHIELDA\u53ef\u4e3aLLM\u9a71\u52a8\u7684\u4ee3\u7406\u5de5\u4f5c\u6d41\u63d0\u4f9b\u7cfb\u7edf\u5316\u3001\u7ed3\u6784\u5316\u4e14\u6709\u6548\u7684\u8fd0\u884c\u65f6\u5f02\u5e38\u5904\u7406\uff0c\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u6062\u590d\u80fd\u529b\u3002"}}
{"id": "2508.06709", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06709", "abs": "https://arxiv.org/abs/2508.06709", "authors": ["Evangelia Spiliopoulou", "Riccardo Fogliato", "Hanna Burnsky", "Tamer Soliman", "Jie Ma", "Graham Horwood", "Miguel Ballesteros"], "title": "Play Favorites: A Statistical Method to Measure Self-Bias in LLM-as-a-Judge", "comment": null, "summary": "Large language models (LLMs) can serve as judges that offer rapid and\nreliable assessments of other LLM outputs. However, models may systematically\nassign overly favorable ratings to their own outputs, a phenomenon known as\nself-bias, which can distort evaluations of true model performance. Previous\nstudies often conflate genuine differences in model quality with bias or\nincorrectly assume that evaluations from LLMs and humans follow the same rating\ndistributions. In this work, we present a statistical framework that explicitly\nformalizes assumptions under which self-bias can be identified and estimated.\nOur method models the difference in the scoring distribution that\nLLM-as-a-judge assigns to its own completions compared to other models, while\naccounting for the underlying quality of the completions provided by an\nindependent, third-party judge (e.g., humans). Our method reliably isolates and\nquantifies self-bias, even when models vary in ability, ensuring that genuine\nperformance differences are not mistaken for self-bias. We conduct an empirical\nanalysis of self-bias on a large dataset (>5000 prompt-completion pairs)\nconsisting of expert human annotations and judgments from nine different LLM\njudges. We find that some models, such as GPT-4o and Claude 3.5 Sonnet,\nsystematically assign higher scores to their own outputs. These models also\ndisplay family-bias; systematically assigning higher ratings to outputs\nproduced by other models of the same family. Our findings highlight potential\npitfalls of using LLM judges and offer practical guidance to mitigate biases\nwhen interpreting automated evaluations.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u8ba1\u65b9\u6cd5\u8bc6\u522b\u548c\u91cf\u5316LLM\u8bc4\u5224\u4e2d\u7684\u81ea\u504f\u5dee\u548c\u5bb6\u65cf\u504f\u5dee\uff0c\u53d1\u73b0\u5e38\u7528\u6a21\u578b\u6709\u9ad8\u81ea\u504f\u5dee\u98ce\u9669\uff0c\u63d0\u9192\u4f7f\u7528LLM\u8bc4\u5224\u65f6\u9700\u8c28\u614e\u5e76\u91c7\u7528\u504f\u5dee\u4fee\u6b63\u7b56\u7565\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u88ab\u5e7f\u6cdb\u7528\u4f5c\u8bc4\u5224\u5176\u4ed6\u6a21\u578b\u8f93\u51fa\u7684\u5de5\u5177\uff0c\u4f46\u5b83\u4eec\u503e\u5411\u4e8e\u5bf9\u81ea\u8eab\u8f93\u51fa\u8d4b\u4e88\u66f4\u9ad8\u7684\u8bc4\u5206\uff0c\u5373\u201c\u81ea\u504f\u5dee\u201d\u73b0\u8c61\uff0c\u8fd9\u4f1a\u626d\u66f2\u6a21\u578b\u771f\u5b9e\u6027\u80fd\u7684\u8bc4\u4f30\u3002\u6b64\u524d\u7684\u7814\u7a76\u5f80\u5f80\u65e0\u6cd5\u5206\u6e05\u6a21\u578b\u5b9e\u9645\u8d28\u91cf\u5dee\u5f02\u4e0e\u81ea\u504f\u5dee\uff0c\u4e5f\u9519\u8bef\u5730\u5047\u8bbeLLM\u548c\u4eba\u7c7b\u7684\u8bc4\u5206\u5206\u5e03\u4e00\u81f4\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u8ba1\u6846\u67b6\uff0c\u660e\u786e\u754c\u5b9a\u4e86\u53ef\u8bc6\u522b\u548c\u4f30\u8ba1\u81ea\u504f\u5dee\u7684\u5047\u8bbe\u6761\u4ef6\u3002\u65b9\u6cd5\u901a\u8fc7\u5bf9\u6bd4LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u65f6\u5bf9\u81ea\u8eab\u8f93\u51fa\u4e0e\u5176\u4ed6\u6a21\u578b\u8f93\u51fa\u7684\u8bc4\u5206\u5206\u5e03\uff0c\u540c\u65f6\u5229\u7528\u72ec\u7acb\u7b2c\u4e09\u65b9\uff08\u5982\u4eba\u7c7b\u4e13\u5bb6\uff09\u5bf9\u8f93\u51fa\u8d28\u91cf\u8fdb\u884c\u53c2\u8003\uff0c\u80fd\u6392\u9664\u6a21\u578b\u80fd\u529b\u5dee\u5f02\u5bf9\u81ea\u504f\u5dee\u4f30\u8ba1\u7684\u5e72\u6270\u3002", "result": "\u5728\u5305\u542b5000\u591a\u4e2a\u63d0\u793a-\u5b8c\u6210\u5bf9\u7684\u5927\u578b\u6570\u636e\u96c6\u4e0a\uff0c\u5b9e\u8bc1\u5206\u6790\u53d1\u73b0\u8bf8\u5982GPT-4o\u548cClaude 3.5 Sonnet\u7b49\u6a21\u578b\u5b58\u5728\u660e\u663e\u81ea\u504f\u5dee\uff0c\u503e\u5411\u4e8e\u5bf9\u81ea\u8eab\u53ca\u540c\u5bb6\u65cf\u6a21\u578b\u7684\u8f93\u51fa\u6253\u66f4\u9ad8\u5206\u3002\u8fd8\u53d1\u73b0\u4e86\u201c\u5bb6\u65cf\u504f\u5dee\u201d\uff0c\u5373\u5bf9\u6e90\u81ea\u540c\u5bb6\u65cf\u6a21\u578b\u7684\u8f93\u51fa\u4e5f\u7ed9\u4e88\u66f4\u9ad8\u8bc4\u5206\u3002", "conclusion": "\u4f7f\u7528LLM\u4f5c\u4e3a\u81ea\u52a8\u5316\u8bc4\u5224\u5de5\u5177\u65f6\u9700\u8b66\u60d5\u81ea\u504f\u5dee\u548c\u5bb6\u65cf\u504f\u5dee\uff0c\u5426\u5219\u4f1a\u8bef\u5224\u6a21\u578b\u7684\u5b9e\u9645\u6027\u80fd\u3002\u672c\u6587\u4e3a\u8bc6\u522b\u4e0e\u7f13\u89e3\u8fd9\u4e9b\u504f\u5dee\u63d0\u4f9b\u4e86\u7edf\u8ba1\u65b9\u6cd5\u548c\u5b9e\u8df5\u6307\u5bfc\u3002"}}
{"id": "2508.07966", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.07966", "abs": "https://arxiv.org/abs/2508.07966", "authors": ["Philipp Eibl", "Sadra Sabouri", "Souti Chattopadhyay"], "title": "Exploring the Challenges and Opportunities of AI-assisted Codebase Generation", "comment": null, "summary": "Recent AI code assistants have significantly improved their ability to\nprocess more complex contexts and generate entire codebases based on a textual\ndescription, compared to the popular snippet-level generation. These codebase\nAI assistants (CBAs) can also extend or adapt codebases, allowing users to\nfocus on higher-level design and deployment decisions. While prior work has\nextensively studied the impact of snippet-level code generation, this new class\nof codebase generation models is relatively unexplored. Despite initial\nanecdotal reports of excitement about these agents, they remain less frequently\nadopted compared to snippet-level code assistants. To utilize CBAs better, we\nneed to understand how developers interact with CBAs, and how and why CBAs fall\nshort of developers' needs. In this paper, we explored these gaps through a\ncounterbalanced user study and interview with (n = 16) students and developers\nworking on coding tasks with CBAs. We found that participants varied the\ninformation in their prompts, like problem description (48% of prompts),\nrequired functionality (98% of prompts), code structure (48% of prompts), and\ntheir prompt writing process. Despite various strategies, the overall\nsatisfaction score with generated codebases remained low (mean = 2.8, median =\n3, on a scale of one to five). Participants mentioned functionality as the most\ncommon factor for dissatisfaction (77% of instances), alongside poor code\nquality (42% of instances) and communication issues (25% of instances). We\ndelve deeper into participants' dissatisfaction to identify six underlying\nchallenges that participants faced when using CBAs, and extracted five barriers\nto incorporating CBAs into their workflows. Finally, we surveyed 21 commercial\nCBAs to compare their capabilities with participant challenges and present\ndesign opportunities for more efficient and useful CBAs.", "AI": {"tldr": "\u672c\u8bba\u6587\u8c03\u67e5\u4e86\u5f00\u53d1\u8005\u4f7f\u7528\u6574\u5957\u4ee3\u7801\u5e93AI\u52a9\u624b\uff08CBAs\uff09\u65f6\u7684\u884c\u4e3a\u4e0e\u53cd\u9988\uff0c\u53d1\u73b0\u5176\u751f\u6210\u6548\u679c\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u6574\u4f53\u8f83\u4f4e\uff0c\u4e3b\u8981\u56e0\u4ee3\u7801\u529f\u80fd\u548c\u8d28\u91cf\u4e0d\u8db3\u7b49\u95ee\u9898\u3002\u8bba\u6587\u603b\u7ed3\u4e86\u516d\u5927\u6311\u6218\u548c\u4e94\u4e2a\u91c7\u7eb3\u969c\u788d\uff0c\u5e76\u5bf9\u73b0\u6709\u5546\u4e1aCBAs\u8fdb\u884c\u8bc4\u4ef7\uff0c\u63d0\u51fa\u672a\u6765\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u867d\u7136\u4ee3\u7801\u7247\u6bb5\u7ea7\u751f\u6210\u7684AI\u52a9\u624b\u5df2\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u9488\u5bf9\u6574\u5957\u4ee3\u7801\u5e93\u751f\u6210\u7684AI\u52a9\u624b\uff08CBAs\uff09\u76f8\u5173\u5de5\u4f5c\u4ecd\u6709\u9650\uff0c\u800c\u4e1a\u754c\u5bf9CBAs\u867d\u6709\u671f\u5f85\u4f46\u5b9e\u9645\u91c7\u7528\u7387\u8f83\u4f4e\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u6df1\u5165\u4e86\u89e3\u5f00\u53d1\u8005\u4e0eCBAs\u4e92\u52a8\u65f6\u7684\u9700\u6c42\u53ca\u75db\u70b9\u3002", "method": "\u901a\u8fc7\u5bf916\u540d\u5b66\u751f\u4e0e\u5f00\u53d1\u8005\u8fdb\u884c\u5bf9\u6bd4\u7528\u6237\u7814\u7a76\u4e0e\u8bbf\u8c08\uff0c\u5206\u6790\u5176\u4e0eCBAs\u534f\u4f5c\u7f16\u7a0b\u8fc7\u7a0b\u4e2d\u7684\u884c\u4e3a\u4e0e\u53cd\u9988\uff0c\u5e76\u7ed3\u5408\u5bf9\u5e02\u9762\u4e0a21\u4e2a\u5546\u4e1aCBAs\u7684\u8c03\u7814\u3002", "result": "\u53c2\u4e0e\u8005\u5728\u63d0\u793a\u8bcd\u4e2d\u5305\u542b\u7684\u95ee\u9898\u63cf\u8ff0\u3001\u529f\u80fd\u9700\u6c42\u3001\u4ee3\u7801\u7ed3\u6784\u7b49\u591a\u5143\u4fe1\u606f\uff0c\u4f46\u65e0\u8bba\u7b56\u7565\u5982\u4f55\uff0c\u5bf9\u751f\u6210\u7684\u4ee3\u7801\u5e93\u6574\u4f53\u6ee1\u610f\u5ea6\u8f83\u4f4e\uff08\u5747\u503c2.8/5\uff09\u3002\u53d7\u8bbf\u8005\u4e0d\u6ee1\u610f\u4e3b\u8981\u56e0\u529f\u80fd\u4e0d\u5b8c\u5584\uff08\u536077%\uff09\uff0c\u4ee3\u7801\u8d28\u91cf\u4f4e\uff0842%\uff09\u3001\u6c9f\u901a\u969c\u788d\uff0825%\uff09\u7b49\u3002\u8bba\u6587\u8fdb\u4e00\u6b65\u603b\u7ed3\u51fa\u516d\u5927\u6311\u6218\u548c\u4e94\u5927\u91c7\u7eb3\u969c\u788d\uff0c\u5e76\u4e0e\u5f53\u524d\u5546\u4e1aCBAs\u529f\u80fd\u5bf9\u6bd4\uff0c\u63d0\u51fa\u6539\u8fdb\u8bbe\u8ba1\u5efa\u8bae\u3002", "conclusion": "\u73b0\u6709CBAs\u5728\u7528\u6237\u6ee1\u610f\u5ea6\u3001\u4ee3\u7801\u529f\u80fd\u4e0e\u4ee3\u7801\u8d28\u91cf\u7b49\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u5b58\u5728\u591a\u79cd\u6311\u6218\u548c\u91c7\u7eb3\u969c\u788d\u3002\u7814\u7a76\u4e3a\u66f4\u9ad8\u6548\u3001\u5b9e\u7528\u7684CBAs\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u57fa\u4e8e\u7528\u6237\u884c\u4e3a\u4e0e\u9700\u6c42\u7684\u53c2\u8003\u5efa\u8bae\u3002"}}
{"id": "2508.06729", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06729", "abs": "https://arxiv.org/abs/2508.06729", "authors": ["Komala Subramanyam Cherukuri", "Pranav Abishai Moses", "Aisa Sakata", "Jiangping Chen", "Haihua Chen"], "title": "Large Language Models for Oral History Understanding with Text Classification and Sentiment Analysis", "comment": null, "summary": "Oral histories are vital records of lived experience, particularly within\ncommunities affected by systemic injustice and historical erasure. Effective\nand efficient analysis of their oral history archives can promote access and\nunderstanding of the oral histories. However, Large-scale analysis of these\narchives remains limited due to their unstructured format, emotional\ncomplexity, and high annotation costs. This paper presents a scalable framework\nto automate semantic and sentiment annotation for Japanese American\nIncarceration Oral History. Using LLMs, we construct a high-quality dataset,\nevaluate multiple models, and test prompt engineering strategies in\nhistorically sensitive contexts. Our multiphase approach combines expert\nannotation, prompt design, and LLM evaluation with ChatGPT, Llama, and Qwen. We\nlabeled 558 sentences from 15 narrators for sentiment and semantic\nclassification, then evaluated zero-shot, few-shot, and RAG strategies. For\nsemantic classification, ChatGPT achieved the highest F1 score (88.71%),\nfollowed by Llama (84.99%) and Qwen (83.72%). For sentiment analysis, Llama\nslightly outperformed Qwen (82.66%) and ChatGPT (82.29%), with all models\nshowing comparable results. The best prompt configurations were used to\nannotate 92,191 sentences from 1,002 interviews in the JAIOH collection. Our\nfindings show that LLMs can effectively perform semantic and sentiment\nannotation across large oral history collections when guided by well-designed\nprompts. This study provides a reusable annotation pipeline and practical\nguidance for applying LLMs in culturally sensitive archival analysis. By\nbridging archival ethics with scalable NLP techniques, this work lays the\ngroundwork for responsible use of artificial intelligence in digital humanities\nand preservation of collective memory. GitHub:\nhttps://github.com/kc6699c/LLM4OralHistoryAnalysis.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u81ea\u52a8\u5316\u6807\u6ce8\u6846\u67b6\uff0c\u5229\u7528ChatGPT\u3001Llama\u548cQwen\u7b49LLMs\u5bf9\u65e5\u88d4\u7f8e\u56fd\u4eba\u76d1\u7981\u53e3\u8ff0\u5386\u53f2\u6863\u6848\u8fdb\u884c\u8bed\u4e49\u548c\u60c5\u611f\u6807\u6ce8\u3002\u901a\u8fc7\u591a\u9636\u6bb5\u6d41\u7a0b\u548c\u63d0\u793a\u8bcd\u4f18\u5316\uff0c\u9996\u6b21\u5b9e\u73b0\u5927\u89c4\u6a21\u8bed\u4e49\u4e0e\u60c5\u611f\u81ea\u52a8\u5316\u5206\u6790\uff0c\u6548\u679c\u4f18\u5f02\uff0c\u5e76\u63d0\u4f9b\u53ef\u590d\u7528\u7684\u6d41\u7a0b\u548c\u5b9e\u52a1\u6307\u5357\uff0c\u4e3a\u6587\u5316\u654f\u611f\u6863\u6848AI\u5206\u6790\u548c\u96c6\u4f53\u8bb0\u5fc6\u4fdd\u62a4\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002", "motivation": "\u53e3\u8ff0\u5386\u53f2\u80fd\u771f\u5b9e\u8bb0\u5f55\u88ab\u7cfb\u7edf\u6027\u4e0d\u516c\u548c\u5386\u53f2\u62b9\u9664\u5f71\u54cd\u7684\u7fa4\u4f53\u7684\u751f\u6d3b\u7ecf\u9a8c\uff0c\u4f46\u8be5\u7c7b\u6863\u6848\u5f80\u5f80\u7ed3\u6784\u5316\u7a0b\u5ea6\u4f4e\u3001\u60c5\u611f\u590d\u6742\u4e14\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\uff0c\u5bfc\u81f4\u65e0\u6cd5\u5927\u89c4\u6a21\u5206\u6790\u3002\u7814\u7a76\u52a8\u673a\u662f\u5e0c\u671b\u901a\u8fc7\u81ea\u52a8\u5316\u65b9\u6cd5\u63d0\u5347\u53e3\u8ff0\u5386\u53f2\u6863\u6848\u7684\u5206\u6790\u6548\u7387\u548c\u6548\u679c\uff0c\u4ece\u800c\u589e\u5f3a\u5176\u53ef\u8bbf\u95ee\u6027\u4e0e\u7406\u89e3\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u5957\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u8bed\u4e49\u548c\u60c5\u611f\u6807\u6ce8\u6846\u67b6\uff0c\u5e94\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5bf9\u65e5\u88d4\u7f8e\u56fd\u4eba\u76d1\u7981\u53e3\u8ff0\u5386\u53f2\u6863\u6848\u8fdb\u884c\u8bed\u4e49\u548c\u60c5\u611f\u81ea\u52a8\u6807\u6ce8\u3002\u65b9\u6cd5\u5305\u62ec\u4e13\u5bb6\u6807\u6ce8\u3001\u63d0\u793a\u8bcd\u8bbe\u8ba1\u3001\u591a\u6a21\u578b\uff08ChatGPT\u3001Llama\u3001Qwen\uff09\u8bc4\u4f30\uff0c\u91cd\u70b9\u6d4b\u8bd5\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7b56\u7565\u3002\u5148\u5bf9558\u53e5\u6765\u81ea15\u4f4d\u8bb2\u8ff0\u8005\u7684\u53e5\u5b50\u8fdb\u884c\u6807\u6ce8\uff0c\u7136\u540e\u9009\u7528\u6700\u4f73\u6a21\u578b\u548c\u63d0\u793a\u914d\u7f6e\u5927\u89c4\u6a21\u6807\u6ce81,002\u6b21\u8bbf\u8c08\u768492,191\u4e2a\u53e5\u5b50\u3002", "result": "ChatGPT\u5728\u8bed\u4e49\u5206\u7c7b\u4e2d\u8868\u73b0\u6700\u4f73\uff0cF1\u5206\u6570\u4e3a88.71%\uff0cLlama\u548cQwen\u5206\u522b\u4e3a84.99%\u548c83.72%\u3002\u5728\u60c5\u611f\u5206\u6790\u4e0a\uff0cLlama\u7565\u4f18\u4e8eQwen\uff0882.66%\uff09\u548cChatGPT\uff0882.29%\uff09\uff0c\u5404\u6a21\u578b\u5747\u8868\u73b0\u76f8\u8fd1\u3002\u5c55\u793a\u4e86\u4eba\u7c7b\u8bbe\u8ba1\u63d0\u793a\u8bcd\u6307\u5bfc\u4e0b\uff0cLLMs\u80fd\u9ad8\u6548\u5b8c\u6210\u5927\u89c4\u6a21\u53e3\u8ff0\u5386\u53f2\u7684\u8bed\u4e49\u4e0e\u60c5\u611f\u6807\u6ce8\u3002", "conclusion": "LLMs\u5728\u5408\u7406\u63d0\u793a\u8bcd\u8bbe\u8ba1\u548c\u8bc4\u4ef7\u673a\u5236\u4e0b\uff0c\u53ef\u81ea\u52a8\u5316\u5206\u6790\u5386\u53f2\u654f\u611f\u8bed\u5883\u4e0b\u7684\u5927\u89c4\u6a21\u53e3\u8ff0\u5386\u53f2\u6863\u6848\uff0c\u5b9e\u73b0\u9ad8\u8d28\u91cf\u8bed\u4e49\u548c\u60c5\u611f\u6807\u6ce8\u3002\u6210\u679c\u5305\u62ec\u53ef\u590d\u7528\u7684\u6807\u6ce8\u6d41\u7a0b\u53ca\u5b9e\u8df5\u6307\u5bfc\uff0c\u4e3a\u6587\u5316\u654f\u611f\u6863\u6848\u7684\u4f26\u7406\u6027\u4e0e\u53ef\u6269\u5c55NLP\u65b9\u6cd5\u7ed3\u5408\u3001\u63a8\u52a8\u4eba\u5de5\u667a\u80fd\u5728\u6570\u5b57\u4eba\u6587\u5b66\u79d1\u53ca\u96c6\u4f53\u8bb0\u5fc6\u4fdd\u62a4\u4e2d\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.08171", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08171", "abs": "https://arxiv.org/abs/2508.08171", "authors": ["Pedro Orvalho", "Marta Kwiatkowska"], "title": "PyVeritas: On Verifying Python via LLM-Based Transpilation and Bounded Model Checking for C", "comment": "14 pages, 6 tables, 1 figure", "summary": "Python has become the dominant language for general-purpose programming, yet\nit lacks robust tools for formal verification. In contrast, programmers working\nin languages such as C benefit from mature model checkers, for example CBMC,\nwhich enable exhaustive symbolic reasoning and fault localisation. The inherent\ncomplexity of Python, coupled with the verbosity and low-level nature of\nexisting transpilers (e.g., Cython), have historically limited the\napplicability of formal verification to Python programs.\n  In this paper, we propose PyVeritas, a novel framework that leverages Large\nLanguage Models (LLMs) for high-level transpilation from Python to C, followed\nby bounded model checking and MaxSAT-based fault localisation in the generated\nC code. PyVeritas enables verification and bug localisation for Python code\nusing existing model checking tools for C. Our empirical evaluation on two\nPython benchmarks demonstrates that LLM-based transpilation can achieve a high\ndegree of accuracy, up to 80--90% for some LLMs, enabling effective development\nenvironment that supports assertion-based verification and interpretable fault\ndiagnosis for small yet non-trivial Python programs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPyVeritas\uff0c\u901a\u8fc7LLM\u9ad8\u6548\u8f6c\u8bd1Python\u81f3C\uff0c\u5e76\u5229\u7528C\u7684\u6a21\u578b\u68c0\u6d4b\u4e0eMaxSAT\u6545\u969c\u5b9a\u4f4d\u6280\u672f\uff0c\u4f7fPython\u4ee3\u7801\u53ef\u5b9e\u73b0\u81ea\u52a8\u9a8c\u8bc1\u4e0ebug\u5b9a\u4f4d\u3002\u5b9e\u9a8c\u663e\u793a\u8be5\u6846\u67b6\u5bf9\u5c0f\u578b\u590d\u6742Python\u7a0b\u5e8f\u7684\u8f6c\u8bd1\u51c6\u786e\u7387\u9ad8\u8fbe80-90%\u3002", "motivation": "\u867d\u7136Python\u662f\u76ee\u524d\u4e3b\u6d41\u7684\u901a\u7528\u7f16\u7a0b\u8bed\u8a00\uff0c\u4f46\u5374\u7f3a\u4e4f\u6210\u719f\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5de5\u5177\u3002\u800c\u50cfC\u8bed\u8a00\u8fd9\u6837\u7684\u7a0b\u5e8f\u5219\u6709\u5b8c\u5584\u7684\u6a21\u578b\u68c0\u6d4b\u5668\uff08\u6bd4\u5982CBMC\uff09\uff0c\u53ef\u4ee5\u8fdb\u884c\u7b26\u53f7\u63a8\u7406\u548c\u6545\u969c\u5b9a\u4f4d\u3002Python\u7684\u590d\u6742\u6027\u548c\u73b0\u6709\u8f6c\u8bd1\u5de5\u5177\u7684\u4e0d\u8db3\u9650\u5236\u4e86\u5176\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u666e\u53ca\u3002", "method": "\u63d0\u51faPyVeritas\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5c06Python\u9ad8\u5c42\u6b21\u8f6c\u8bd1\u4e3aC\u4ee3\u7801\uff0c\u7136\u540e\u5728\u751f\u6210\u7684C\u4ee3\u7801\u4e0a\u8fdb\u884c\u6709\u754c\u6a21\u578b\u68c0\u6d4b\u548c\u57fa\u4e8eMaxSAT\u7684\u6545\u969c\u5b9a\u4f4d\u3002\u901a\u8fc7C\u7684\u6a21\u578b\u68c0\u6d4b\u5de5\u5177\uff0c\u4e3aPython\u4ee3\u7801\u5b9e\u73b0\u9a8c\u8bc1\u548c\u5b9a\u4f4dbug\u3002", "result": "\u5728\u4e24\u4e2aPython\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0cLLM\u8f6c\u8bd1\u51c6\u786e\u7387\u8fbe\u523080-90%\uff0c\u53ef\u6709\u6548\u652f\u6301\u65ad\u8a00\u5f0f\u9a8c\u8bc1\u548c\u53ef\u89e3\u91ca\u6545\u969c\u8bca\u65ad\uff0c\u9002\u7528\u4e8e\u5c0f\u578b\u4f46\u6709\u4e00\u5b9a\u590d\u6742\u5ea6\u7684Python\u7a0b\u5e8f\u3002", "conclusion": "LLM\u8f85\u52a9\u7684\u9ad8\u5c42\u6b21Python\u8f6c\u8bd1\u914d\u5408\u4f20\u7edfC\u6a21\u578b\u68c0\u6d4b\u5668\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347Python\u7a0b\u5e8f\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u548c\u6545\u969c\u5b9a\u4f4d\u80fd\u529b\uff0c\u4e3aPython\u7a0b\u5e8f\u5458\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5f00\u53d1\u73af\u5883\u3002"}}
{"id": "2508.06755", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06755", "abs": "https://arxiv.org/abs/2508.06755", "authors": ["Xianjun Yang", "Liqiang Xiao", "Shiyang Li", "Faisal Ladhak", "Hyokun Yun", "Linda Ruth Petzold", "Yi Xu", "William Yang Wang"], "title": "Many-Turn Jailbreaking", "comment": null, "summary": "Current jailbreaking work on large language models (LLMs) aims to elicit\nunsafe outputs from given prompts. However, it only focuses on single-turn\njailbreaking targeting one specific query. On the contrary, the advanced LLMs\nare designed to handle extremely long contexts and can thus conduct multi-turn\nconversations. So, we propose exploring multi-turn jailbreaking, in which the\njailbroken LLMs are continuously tested on more than the first-turn\nconversation or a single target query. This is an even more serious threat\nbecause 1) it is common for users to continue asking relevant follow-up\nquestions to clarify certain jailbroken details, and 2) it is also possible\nthat the initial round of jailbreaking causes the LLMs to respond to additional\nirrelevant questions consistently. As the first step (First draft done at June\n2024) in exploring multi-turn jailbreaking, we construct a Multi-Turn Jailbreak\nBenchmark (MTJ-Bench) for benchmarking this setting on a series of open- and\nclosed-source models and provide novel insights into this new safety threat. By\nrevealing this new vulnerability, we aim to call for community efforts to build\nsafer LLMs and pave the way for a more in-depth understanding of jailbreaking\nLLMs.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u73b0\uff0c\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u66f4\u6613\u88ab\u8d8a\u72f1\uff0c\u9996\u6b21\u6784\u5efa\u4e86\u591a\u8f6e\u8d8a\u72f1\u57fa\u51c6\u6d4b\u8bd5\u96c6MTJ-Bench\u5e76\u8fdb\u884c\u4e86\u7cfb\u7edf\u6d4b\u8bd5\uff0c\u63d0\u9192\u4e1a\u754c\u591a\u8f6e\u8d8a\u72f1\u662f\u66f4\u73b0\u5b9e\u4e25\u91cd\u7684\u5b89\u5168\u9690\u60a3\u3002", "motivation": "\u4ee5\u5f80\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8d8a\u72f1\u7814\u7a76\u4ec5\u5173\u6ce8\u4e8e\u9488\u5bf9\u5355\u4e00\u67e5\u8be2\u7684\u4e00\u8f6e\u5bf9\u8bdd\uff0c\u4f46\u7531\u4e8eLLM\u53ef\u4ee5\u652f\u6301\u591a\u8f6e\u957f\u5bf9\u8bdd\uff0c\u56e0\u6b64\u591a\u8f6e\u8d8a\u72f1\uff08multi-turn jailbreaking\uff09\u53ef\u80fd\u5e26\u6765\u66f4\u4e25\u91cd\u7684\u5b89\u5168\u98ce\u9669\u3002\u52a8\u673a\u5728\u4e8e\u771f\u5b9e\u573a\u666f\u4e2d\u7528\u6237\u5e38\u5e38\u4f1a\u8fdb\u884c\u591a\u8f6e\u4ea4\u6d41\uff0c\u6216\u8fde\u7eed\u8ffd\u95ee\u76f8\u5173\u95ee\u9898\uff0c\u73b0\u6709\u5355\u8f6e\u8d8a\u72f1\u8bc4\u6d4b\u65e0\u6cd5\u8986\u76d6\u8fd9\u4e9b\u573a\u666f\u3002", "method": "\u672c\u6587\u9996\u6b21\u63d0\u51fa\u5e76\u7cfb\u7edf\u5316\u7814\u7a76\u4e86\u591a\u8f6e\u8d8a\u72f1\uff0c\u6784\u5efa\u4e86\u591a\u8f6e\u8d8a\u72f1\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff08MTJ-Bench\uff09\uff0c\u7528\u4e8e\u8bc4\u4f30\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\u5728\u591a\u8f6e\u8d8a\u72f1\u4e0b\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u8ba9LLM\u6301\u7eed\u63a5\u53d7\u591a\u8f6e\u6f5c\u5728\u5371\u9669\u5bf9\u8bdd\uff0c\u5206\u6790\u6a21\u578b\u5728\u66f4\u590d\u6742\u573a\u666f\u4e0b\u7684\u5b89\u5168\u6027\u3002", "result": "\u901a\u8fc7\u5728\u4e00\u7cfb\u5217\u4e3b\u6d41\u5927\u6a21\u578b\u4e0a\u8fdb\u884c\u591a\u8f6e\u8d8a\u72f1\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u90e8\u5206\u6a21\u578b\u5728\u540e\u7eed\u8f6e\u6b21\u4e2d\u4ecd\u7136\u66b4\u9732\u51fa\u5b89\u5168\u6f0f\u6d1e\uff0c\u66f4\u5bb9\u6613\u6301\u7eed\u8f93\u51fa\u4e0d\u5b89\u5168\u5185\u5bb9\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u9632\u5fa1\u624b\u6bb5\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u591a\u8f6e\u8d8a\u72f1\u5bf9LLM\u5b89\u5168\u6027\u6784\u6210\u4e86\u66f4\u4e3a\u4e25\u91cd\u4e14\u771f\u5b9e\u7684\u5a01\u80c1\u3002\u7136\u800c\u5f53\u524d\u7814\u7a76\u4e0e\u9632\u62a4\u63aa\u65bd\u4e3b\u8981\u8986\u76d6\u5355\u8f6e\u60c5\u666f\uff0c\u5bf9\u591a\u8f6e\u52a8\u6001\u5bf9\u8bdd\u7684\u4fdd\u62a4\u6709\u9650\u3002\u8bba\u6587\u547c\u5401\u4e1a\u754c\u5173\u6ce8\u591a\u8f6e\u8d8a\u72f1\u95ee\u9898\uff0c\u4ee5\u63a8\u52a8\u66f4\u5b89\u5168\u7684\u5927\u6a21\u578b\u7814\u53d1\u3002"}}
{"id": "2508.06803", "categories": ["cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.06803", "abs": "https://arxiv.org/abs/2508.06803", "authors": ["Ziqi Liu", "Yangbin Chen", "Ziyang Zhou", "Yilin Li", "Mingxuan Hu", "Yushan Pan", "Zhijie Xu"], "title": "SEVADE: Self-Evolving Multi-Agent Analysis with Decoupled Evaluation for Hallucination-Resistant Irony Detection", "comment": null, "summary": "Sarcasm detection is a crucial yet challenging Natural Language Processing\ntask. Existing Large Language Model methods are often limited by\nsingle-perspective analysis, static reasoning pathways, and a susceptibility to\nhallucination when processing complex ironic rhetoric, which impacts their\naccuracy and reliability. To address these challenges, we propose **SEVADE**, a\nnovel **S**elf-**Ev**olving multi-agent **A**nalysis framework with\n**D**ecoupled **E**valuation for hallucination-resistant sarcasm detection. The\ncore of our framework is a Dynamic Agentive Reasoning Engine (DARE), which\nutilizes a team of specialized agents grounded in linguistic theory to perform\na multifaceted deconstruction of the text and generate a structured reasoning\nchain. Subsequently, a separate lightweight rationale adjudicator (RA) performs\nthe final classification based solely on this reasoning chain. This decoupled\narchitecture is designed to mitigate the risk of hallucination by separating\ncomplex reasoning from the final judgment. Extensive experiments on four\nbenchmark datasets demonstrate that our framework achieves state-of-the-art\nperformance, with average improvements of **6.75%** in Accuracy and **6.29%**\nin Macro-F1 score.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSEVADE\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u63a8\u7406-\u5224\u51b3\u5206\u79bb\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bbd\u523a\u68c0\u6d4b\u4efb\u52a1\u7684\u51c6\u786e\u6027\uff0c\u51cf\u5c11\u5e7b\u89c9\u73b0\u8c61\uff0c\u5b9e\u9a8c\u6548\u679c\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u8bbd\u523a\u6587\u672c\u5904\u7406\u4e2d\u5b58\u5728\u5355\u4e00\u89c6\u89d2\u3001\u63a8\u7406\u8def\u5f84\u9759\u6001\u53ca\u5e7b\u89c9\u98ce\u9669\u9ad8\u7b49\u95ee\u9898\uff0c\u5f71\u54cd\u5176\u6548\u679c\u548c\u53ef\u4fe1\u5ea6\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u8bed\u8a00\u5b66\u7406\u8bba\u6784\u5efa\u7684\u591a\u667a\u80fd\u4f53\u52a8\u6001\u63a8\u7406\u5f15\u64ceDARE\uff0c\u5bf9\u6587\u672c\u8fdb\u884c\u591a\u89c6\u89d2\u89e3\u6784\u548c\u63a8\u7406\u94fe\u751f\u6210\uff0c\u540c\u65f6\u5f15\u5165\u72ec\u7acb\u8f7b\u91cf\u7ea7\u7684\u7406\u7531\u88c1\u51b3\u5668\uff08RA\uff09\uff0c\u4ec5\u57fa\u4e8e\u63a8\u7406\u94fe\u8fdb\u884c\u6700\u7ec8\u8bbd\u523a\u5224\u522b\uff0c\u5b9e\u73b0\u63a8\u7406\u4e0e\u51b3\u7b56\u7684\u5206\u79bb\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cSEVADE\u5728\u51c6\u786e\u7387\u548cMacro-F1\u4e0a\u5206\u522b\u5e73\u5747\u63d0\u5347\u4e866.75%\u548c6.29%\uff0c\u8fbe\u5230\u6700\u65b0\u7684\u6027\u80fd\u6c34\u5e73\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u667a\u80fd\u4f53\u81ea\u6211\u6f14\u5316\u5206\u6790\u6846\u67b6SEVADE\uff0c\u80fd\u6709\u6548\u7f13\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bbd\u523a\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u5e76\u663e\u8457\u63d0\u5347\u51c6\u786e\u6027\u4e0e\u53ef\u9760\u6027\u3002"}}
{"id": "2508.06810", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.06810", "abs": "https://arxiv.org/abs/2508.06810", "authors": ["Steven Coyne", "Diana Galvan-Sosa", "Ryan Spring", "Cam\u00e9lia Guerraoui", "Michael Zock", "Keisuke Sakaguchi", "Kentaro Inui"], "title": "Annotating Errors in English Learners' Written Language Production: Advancing Automated Written Feedback Systems", "comment": "Pre-review version of DOI 10.1007/978-3-031-98459-4_21, presented at\n  AIED 2025. All content is as of submission time except for de-anonymization,\n  ensuing layout fixes, use of the current code repository link, and BibTeX\n  fixes. Readers are encouraged to refer to the published version", "summary": "Recent advances in natural language processing (NLP) have contributed to the\ndevelopment of automated writing evaluation (AWE) systems that can correct\ngrammatical errors. However, while these systems are effective at improving\ntext, they are not optimally designed for language learning. They favor direct\nrevisions, often with a click-to-fix functionality that can be applied without\nconsidering the reason for the correction. Meanwhile, depending on the error\ntype, learners may benefit most from simple explanations and strategically\nindirect hints, especially on generalizable grammatical rules. To support the\ngeneration of such feedback, we introduce an annotation framework that models\neach error's error type and generalizability. For error type classification, we\nintroduce a typology focused on inferring learners' knowledge gaps by\nconnecting their errors to specific grammatical patterns. Following this\nframework, we collect a dataset of annotated learner errors and corresponding\nhuman-written feedback comments, each labeled as a direct correction or hint.\nWith this data, we evaluate keyword-guided, keyword-free, and template-guided\nmethods of generating feedback using large language models (LLMs). Human\nteachers examined each system's outputs, assessing them on grounds including\nrelevance, factuality, and comprehensibility. We report on the development of\nthe dataset and the comparative performance of the systems investigated.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u9762\u5411\u8bed\u8a00\u5b66\u4e60\u7684\u81ea\u52a8\u5199\u4f5c\u53cd\u9988\u63d0\u51fa\u65b0\u7684\u9519\u8bef\u6ce8\u91ca\u6846\u67b6\u4e0e\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u4e86\u591a\u79cd\u81ea\u52a8\u53cd\u9988\u751f\u6210\u65b9\u6cd5\uff0c\u7ed3\u679c\u663e\u793a\u80fd\u591f\u663e\u8457\u63d0\u5347\u53cd\u9988\u7684\u9488\u5bf9\u6027\u4e0e\u6559\u5b66\u4ef7\u503c\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u6709\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9a71\u52a8\u7684\u81ea\u52a8\u5199\u4f5c\u8bc4\u4f30\u7cfb\u7edf\uff08AWE\uff09\u80fd\u6709\u6548\u7ea0\u6b63\u8bed\u6cd5\u9519\u8bef\uff0c\u4f46\u8fd9\u4e9b\u7cfb\u7edf\u66f4\u591a\u5173\u6ce8\u5feb\u901f\u76f4\u63a5\u4fee\u6b63\u800c\u975e\u4fc3\u8fdb\u5b66\u4e60\u8005\u6df1\u5ea6\u7406\u89e3\u3002\u5b66\u4e60\u8005\u6839\u636e\u9519\u8bef\u7c7b\u578b\uff0c\u901a\u5e38\u66f4\u9700\u8981\u89e3\u91ca\u6216\u95f4\u63a5\u63d0\u793a\u6765\u638c\u63e1\u53ef\u6cdb\u5316\u7684\u8bed\u6cd5\u77e5\u8bc6\u3002\u4e3a\u66f4\u597d\u670d\u52a1\u4e8e\u8bed\u8a00\u5b66\u4e60\u9700\u6c42\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u751f\u6210\u4e2a\u6027\u5316\u95f4\u63a5\u53cd\u9988\u7684\u4fe1\u606f\u7cfb\u7edf\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6ce8\u91ca\u6846\u67b6\uff0c\u4e13\u6ce8\u4e8e\u5efa\u6a21\u9519\u8bef\u7c7b\u578b\u53ca\u5176\u53ef\u6cdb\u5316\u6027\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u79cd\u5c06\u5b66\u4e60\u8005\u9519\u8bef\u4e0e\u5177\u4f53\u8bed\u6cd5\u6a21\u5f0f\u5173\u8054\u3001\u6d1e\u5bdf\u77e5\u8bc6\u76f2\u533a\u7684\u5206\u7c7b\u65b9\u6cd5\u3002\u57fa\u4e8e\u8be5\u6846\u67b6\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u4eba\u7c7b\u6559\u5e08\u6807\u6ce8\u7684\u5b66\u4e60\u8005\u9519\u8bef\u53ca\u53cd\u9988\uff08\u5206\u4e3a\u76f4\u63a5\u4fee\u6b63\u548c\u63d0\u793a\uff09\u7684\u6570\u636e\u96c6\u3002\u968f\u540e\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5f00\u5c55\u5173\u952e\u8bcd\u5f15\u5bfc\u3001\u65e0\u5173\u952e\u8bcd\u548c\u6a21\u677f\u5f15\u5bfc\u4e09\u79cd\u81ea\u52a8\u751f\u6210\u53cd\u9988\u7684\u65b9\u6cd5\u5b9e\u9a8c\uff0c\u5e76\u7531\u6559\u5e08\u4ece\u76f8\u5173\u6027\u3001\u4e8b\u5b9e\u6027\u548c\u53ef\u7406\u89e3\u6027\u7b49\u89d2\u5ea6\u8bc4\u4f30\u8f93\u51fa\u6548\u679c\u3002", "result": "\u4f5c\u8005\u516c\u5f00\u4e86\u8be5\u6ce8\u91ca\u6570\u636e\u96c6\uff0c\u5e76\u6bd4\u8f83\u4e86\u4e09\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u53cd\u9988\u751f\u6210\u65b9\u6cd5\u3002\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u6ce8\u91ca\u6846\u67b6\u7684\u65b9\u6cd5\u80fd\u591f\u66f4\u6709\u6548\u5730\u4ea7\u751f\u9ad8\u8d28\u91cf\u3001\u53ef\u6cdb\u5316\u7684\u53cd\u9988\uff0c\u63d0\u5347\u4e86\u53cd\u9988\u7684\u76f8\u5173\u6027\u53ca\u6559\u5b66\u4ef7\u503c\u3002\u8bba\u6587\u4e2d\u8be6\u7ec6\u62a5\u544a\u4e86\u5404\u7cfb\u7edf\u7684\u8868\u73b0\u5bf9\u6bd4\u3002", "conclusion": "\u901a\u8fc7\u6784\u5efa\u4ee5\u901a\u7528\u8bed\u6cd5\u77e5\u8bc6\u70b9\u4e3a\u6838\u5fc3\u7684\u9519\u8bef\u6ce8\u91ca\u4e0e\u53cd\u9988\u6846\u67b6\uff0c\u63a8\u52a8\u4e86\u81ea\u52a8\u5199\u4f5c\u8bc4\u4f30\u7cfb\u7edf\u5411\u771f\u5b9e\u8bed\u8a00\u5b66\u4e60\u573a\u666f\u9002\u914d\u7684\u8fdb\u5316\u3002\u5b9e\u9a8c\u53ca\u4eba\u7c7b\u6559\u5e08\u8bc4\u4f30\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u751f\u6210\u4fc3\u8fdb\u5b66\u4e60\u8005\u7406\u89e3\u548c\u4e60\u5f97\u7684\u53cd\u9988\u3002"}}
{"id": "2508.06870", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2508.06870", "abs": "https://arxiv.org/abs/2508.06870", "authors": ["Gangular Singh Irengbam", "Nirvash Singh Wahengbam", "Lanthoiba Meitei Khumanthem", "Paikhomba Oinam"], "title": "Text to Speech System for Meitei Mayek Script", "comment": null, "summary": "This paper presents the development of a Text-to-Speech (TTS) system for the\nManipuri language using the Meitei Mayek script. Leveraging Tacotron 2 and\nHiFi-GAN, we introduce a neural TTS architecture adapted to support tonal\nphonology and under-resourced linguistic environments. We develop a phoneme\nmapping for Meitei Mayek to ARPAbet, curate a single-speaker dataset, and\ndemonstrate intelligible and natural speech synthesis, validated through\nsubjective and objective metrics. This system lays the groundwork for\nlinguistic preservation and technological inclusion of Manipuri.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eTacotron 2\u548cHiFi-GAN\u7684Manipuri\u8bed\u8a00TTS\u7cfb\u7edf\uff0c\u901a\u8fc7Meitei Mayek\u5230ARPAbet\u97f3\u7d20\u6620\u5c04\u548c\u5355\u8bf4\u8bdd\u4eba\u6570\u636e\u96c6\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u81ea\u7136\u4e14\u6e05\u6670\u7684\u8bed\u97f3\u5408\u6210\uff0c\u4e3aManipuri\u8bed\u8a00\u7684\u4fdd\u62a4\u548c\u666e\u53ca\u5960\u5b9a\u4e86\u6280\u672f\u57fa\u7840\u3002", "motivation": "Manipuri\u8bed\u8a00\u8d44\u6e90\u532e\u4e4f\uff0c\u4e14\u5177\u6709\u72ec\u7279\u7684\u58f0\u8c03\u73b0\u8c61\uff0c\u9700\u8981\u5b9a\u5236TTS\u7cfb\u7edf\u4ee5\u4fc3\u8fdb\u8be5\u8bed\u8a00\u7684\u4fdd\u62a4\u548c\u6280\u672f\u5e94\u7528\u3002", "method": "\u91c7\u7528Tacotron 2\u548cHiFi-GAN\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u9488\u5bf9Manipuri\u8bed\u8a00\u7684\u58f0\u8c03\u97f3\u7cfb\u548c\u8d44\u6e90\u532e\u4e4f\u60c5\u51b5\uff0c\u5f00\u53d1\u4e86Meitei Mayek\u5230ARPAbet\u7684\u97f3\u7d20\u6620\u5c04\uff0c\u5e76\u6784\u5efa\u4e86\u5355\u8bf4\u8bdd\u4eba\u8bed\u97f3\u6570\u636e\u96c6\u3002", "result": "\u4e3b\u89c2\u548c\u5ba2\u89c2\u6307\u6807\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u80fd\u591f\u5408\u6210\u6e05\u6670\u81ea\u7136\u7684Manipuri\u8bed\u97f3\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684Manipuri\u8bed\u8a00TTS\u7cfb\u7edf\u80fd\u591f\u81ea\u7136\u4e14\u6e05\u6670\u5730\u751f\u6210\u8bed\u97f3\uff0c\u5e76\u5bf9\u8bed\u8a00\u4fdd\u62a4\u548c\u6280\u672f\u666e\u53ca\u5177\u6709\u63a8\u52a8\u4f5c\u7528\u3002"}}
{"id": "2508.06877", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.06877", "abs": "https://arxiv.org/abs/2508.06877", "authors": ["Xiaobo Zhang", "Congqing He", "Ying He", "Jian Peng", "Dajie Fu", "Tien-Ping Tan"], "title": "ESNERA: Empirical and semantic named entity alignment for named entity dataset merging", "comment": "30 pages, 12 figures", "summary": "Named Entity Recognition (NER) is a fundamental task in natural language\nprocessing. It remains a research hotspot due to its wide applicability across\ndomains. Although recent advances in deep learning have significantly improved\nNER performance, they rely heavily on large, high-quality annotated datasets.\nHowever, building these datasets is expensive and time-consuming, posing a\nmajor bottleneck for further research. Current dataset merging approaches\nmainly focus on strategies like manual label mapping or constructing label\ngraphs, which lack interpretability and scalability. To address this, we\npropose an automatic label alignment method based on label similarity. The\nmethod combines empirical and semantic similarities, using a greedy pairwise\nmerging strategy to unify label spaces across different datasets. Experiments\nare conducted in two stages: first, merging three existing NER datasets into a\nunified corpus with minimal impact on NER performance; second, integrating this\ncorpus with a small-scale, self-built dataset in the financial domain. The\nresults show that our method enables effective dataset merging and enhances NER\nperformance in the low-resource financial domain. This study presents an\nefficient, interpretable, and scalable solution for integrating multi-source\nNER corpora.", "AI": {"tldr": "\u9488\u5bf9NER\u9886\u57df\u6570\u636e\u96c6\u6574\u5408\u96be\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u6807\u7b7e\u76f8\u4f3c\u6027\u7684\u81ea\u52a8\u5bf9\u9f50\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f4e\u8d44\u6e90\u9886\u57df\u7684NER\u6027\u80fd\uff0c\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u6570\u636e\u96c6\u6574\u5408\u65b9\u6848\u3002", "motivation": "\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08NER\uff09\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u975e\u5e38\u91cd\u8981\uff0c\u5e76\u4e14\u5e94\u7528\u5e7f\u6cdb\u3002\u7136\u800c\uff0c\u5176\u6027\u80fd\u63d0\u5347\u9ad8\u5ea6\u4f9d\u8d56\u5927\u91cf\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u800c\u6784\u5efa\u8fd9\u4e9b\u6570\u636e\u96c6\u7684\u8fc7\u7a0b\u65e2\u6602\u8d35\u53c8\u8017\u65f6\u3002\u56e0\u6b64\uff0c\u5982\u4f55\u9ad8\u6548\u6574\u5408\u591a\u6e90\u6570\u636e\u96c6\uff0c\u6210\u4e3a\u5f53\u524d\u7684\u7814\u7a76\u74f6\u9888\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6807\u7b7e\u76f8\u4f3c\u6027\u7684\u81ea\u52a8\u6807\u7b7e\u5bf9\u9f50\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u7ecf\u9a8c\u548c\u8bed\u4e49\u76f8\u4f3c\u6027\uff0c\u91c7\u7528\u8d2a\u5fc3\u7684\u4e24\u4e24\u5408\u5e76\u7b56\u7565\uff0c\u5bf9\u4e0d\u540c\u6570\u636e\u96c6\u7684\u6807\u7b7e\u7a7a\u95f4\u8fdb\u884c\u7edf\u4e00\u3002\u7814\u7a76\u5206\u4e3a\u4e24\u4e2a\u5b9e\u9a8c\u9636\u6bb5\uff1a\u9996\u5148\u5408\u5e76\u4e09\u4e2a\u73b0\u6709NER\u6570\u636e\u96c6\uff0c\u540e\u5c06\u7edf\u4e00\u8bed\u6599\u4e0e\u91d1\u878d\u9886\u57df\u5c0f\u89c4\u6a21\u81ea\u5efa\u6570\u636e\u96c6\u6574\u5408\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u9ad8\u6548\u5408\u5e76\u6570\u636e\u96c6\uff0c\u5e76\u5728\u91d1\u878d\u9886\u57df\u4f4e\u8d44\u6e90\u80cc\u666f\u4e0b\u63d0\u5347NER\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u4e14\u53ef\u6269\u5c55\u7684\u6570\u636e\u96c6\u6574\u5408\u65b9\u6cd5\uff0c\u53ef\u6709\u6548\u4fc3\u8fdb\u591a\u6e90NER\u8bed\u6599\u7684\u6df1\u5ea6\u878d\u5408\uff0c\u63a8\u52a8\u4f4e\u8d44\u6e90\u9886\u57dfNER\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2508.06880", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.06880", "abs": "https://arxiv.org/abs/2508.06880", "authors": ["Philipp Christmann", "Gerhard Weikum"], "title": "The ReQAP System for Question Answering over Personal Information", "comment": "Accepted at CIKM 2025 (demonstration paper)", "summary": "Personal information is abundant on users' devices, from structured data in\ncalendar, shopping records or fitness tools, to unstructured contents in mail\nand social media posts. This works presents the ReQAP system that supports\nusers with answers for complex questions that involve filters, joins and\naggregation over heterogeneous sources. The unique trait of ReQAP is that it\nrecursively decomposes questions and incrementally builds an operator tree for\nexecution. Both the question interpretation and the individual operators make\nsmart use of light-weight language models, with judicious fine-tuning. The demo\nshowcases the rich functionality for advanced user questions, and also offers\ndetailed tracking of how the answers are computed by the operators in the\nexecution tree. Being able to trace answers back to the underlying sources is\nvital for human comprehensibility and user trust in the system.", "AI": {"tldr": "ReQAP\u7cfb\u7edf\u5e2e\u52a9\u7528\u6237\u5bf9\u8bbe\u5907\u4e2d\u7684\u5404\u79cd\u6570\u636e\u8fdb\u884c\u590d\u6742\u67e5\u8be2\uff0c\u9012\u5f52\u62c6\u5206\u95ee\u9898\u548c\u8fd0\u7b97\u6811\u8ffd\u8e2a\u4fdd\u8bc1\u7ed3\u679c\u53ef\u9760\uff0c\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u8f85\u52a9\u95ee\u9898\u89e3\u6790\uff0c\u5145\u5206\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u548c\u4fe1\u4efb\u3002", "motivation": "\u7528\u6237\u8bbe\u5907\u4e0a\u6709\u5927\u91cf\u7ed3\u6784\u5316\u4e0e\u975e\u7ed3\u6784\u5316\u7684\u4e2a\u4eba\u6570\u636e\uff0c\u7528\u6237\u9700\u8981\u80fd\u591f\u8de8\u5f02\u6784\u6765\u6e90\u3001\u8fdb\u884c\u8fc7\u6ee4\u3001\u8fde\u63a5\u4e0e\u805a\u5408\u7684\u590d\u6742\u67e5\u8be2\uff0c\u5e76\u4e14\u8981\u4fdd\u8bc1\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "ReQAP\u91c7\u7528\u9012\u5f52\u95ee\u9898\u5206\u89e3\u4e0e\u8fd0\u7b97\u6811\u589e\u91cf\u6784\u5efa\uff0c\u5c06\u8f7b\u91cf\u5316\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u95ee\u9898\u7406\u89e3\u53ca\u5404\u8fd0\u7b97\u7b26\uff0c\u5e76\u901a\u8fc7\u7cbe\u7ec6\u5316\u5fae\u8c03\u63d0\u5347\u6548\u679c\u3002", "result": "\u5b9e\u73b0\u4e86\u590d\u6742\u95ee\u9898\u652f\u6301\u3001\u4e30\u5bcc\u6f14\u793a\u529f\u80fd\uff0c\u4ee5\u53ca\u8be6\u7ec6\u8ffd\u8e2a\u64cd\u4f5c\u8fc7\u7a0b\uff0c\u53ef\u5c06\u7b54\u6848\u6eaf\u6e90\u81f3\u5e95\u5c42\u6570\u636e\uff0c\u589e\u5f3a\u7cfb\u7edf\u7684\u53ef\u7406\u89e3\u6027\u548c\u7528\u6237\u4fe1\u4efb\u3002", "conclusion": "ReQAP\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u652f\u6301\u7528\u6237\u67e5\u8be2\u590d\u6742\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u9012\u5f52\u5206\u89e3\u4e0e\u53ef\u8ffd\u8e2a\u7684\u6267\u884c\u8fc7\u7a0b\u63d0\u5347\u7b54\u6848\u53ef\u89e3\u91ca\u6027\u548c\u7528\u6237\u4fe1\u4efb\u3002"}}
{"id": "2508.06886", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.06886", "abs": "https://arxiv.org/abs/2508.06886", "authors": ["Arpita Saggar", "Jonathan C. Darling", "Vania Dimitrova", "Duygu Sarikaya", "David C. Hogg"], "title": "Score Before You Speak: Improving Persona Consistency in Dialogue Generation using Response Quality Scores", "comment": "Camera-Ready version for ECAI 2025. 8 pages", "summary": "Persona-based dialogue generation is an important milestone towards building\nconversational artificial intelligence. Despite the ever-improving capabilities\nof large language models (LLMs), effectively integrating persona fidelity in\nconversations remains challenging due to the limited diversity in existing\ndialogue data. We propose a novel framework SBS (Score-Before-Speaking), which\noutperforms previous methods and yields improvements for both million and\nbillion-parameter models. Unlike previous methods, SBS unifies the learning of\nresponses and their relative quality into a single step. The key innovation is\nto train a dialogue model to correlate augmented responses with a quality score\nduring training and then leverage this knowledge at inference. We use\nnoun-based substitution for augmentation and semantic similarity-based scores\nas a proxy for response quality. Through extensive experiments with benchmark\ndatasets (PERSONA-CHAT and ConvAI2), we show that score-conditioned training\nallows existing models to better capture a spectrum of persona-consistent\ndialogues. Our ablation studies also demonstrate that including scores in the\ninput prompt during training is superior to conventional training setups. Code\nand further details are available at\nhttps://arpita2512.github.io/score_before_you_speak", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51faSBS\u6846\u67b6\uff0c\u901a\u8fc7\u7ed9\u6269\u5c55\u56de\u590d\u52a0\u5206\u5e76\u7528\u5206\u6570\u8f85\u52a9\u8bad\u7ec3\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u6a21\u578b\u751f\u6210\u4e2a\u6027\u5316\u5bf9\u8bdd\u7684\u80fd\u529b\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u8bc1\u5b9e\u8f93\u5165\u5206\u6570\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u4e2a\u6027\u5316\u5bf9\u8bdd\u751f\u6210\u5bf9\u4e8e\u6784\u5efa\u4f1a\u8bdd\u578b\u4eba\u5de5\u667a\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u5df2\u6709\u5bf9\u8bdd\u6570\u636e\u591a\u6837\u6027\u6709\u9650\uff0c\u5b9e\u73b0\u9ad8\u4e2a\u6027\u4e00\u81f4\u6027\u4f9d\u7136\u5177\u6709\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86SBS\uff08Score-Before-Speaking\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u8bad\u7ec3\u9636\u6bb5\u5c06\u6269\u5145\u540e\u7684\u56de\u590d\u4e0e\u8d28\u91cf\u5206\u6570\u76f8\u5173\u8054\uff0c\u5e76\u5728\u63a8\u7406\u65f6\u5229\u7528\u6b64\u77e5\u8bc6\u3002\u6269\u5c55\u65b9\u6cd5\u4e3a\u57fa\u4e8e\u540d\u8bcd\u66ff\u6362\uff0c\u8d28\u91cf\u8bc4\u5206\u5219\u91c7\u7528\u8bed\u4e49\u76f8\u4f3c\u5ea6\u3002", "result": "SBS\u6846\u67b6\u5728\u767e\u4e07\u7ea7\u548c\u5341\u4ebf\u7ea7\u53c2\u6570\u6a21\u578b\u4e0a\u90fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728PERSONA-CHAT\u4e0eConvAI2\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u5206\u6570\u7684\u8bad\u7ec3\u80fd\u591f\u4fc3\u8fdb\u6a21\u578b\u66f4\u597d\u5730\u751f\u6210\u7b26\u5408\u89d2\u8272\u7279\u8d28\u7684\u5bf9\u8bdd\u3002\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8bad\u7ec3\u65f6\u5728\u8f93\u5165\u63d0\u793a\u4e2d\u52a0\u5165\u5206\u6570\u4f18\u4e8e\u4f20\u7edf\u65b9\u5f0f\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u8bc4\u5206\u673a\u5236\u4e0e\u6269\u5145\u65b9\u6cd5\uff0c\u6240\u63d0SBS\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u4e2a\u6027\u4e00\u81f4\u6027\u5bf9\u8bdd\u751f\u6210\u7684\u8d28\u91cf\u3002"}}
{"id": "2508.06913", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.06913", "abs": "https://arxiv.org/abs/2508.06913", "authors": ["Siyuan Li", "Xi Lin", "Guangyan Li", "Zehao Liu", "Aodu Wulianghai", "Li Ding", "Jun Wu", "Jianhua Li"], "title": "Model-Agnostic Sentiment Distribution Stability Analysis for Robust LLM-Generated Texts Detection", "comment": null, "summary": "The rapid advancement of large language models (LLMs) has resulted in\nincreasingly sophisticated AI-generated content, posing significant challenges\nin distinguishing LLM-generated text from human-written language. Existing\ndetection methods, primarily based on lexical heuristics or fine-tuned\nclassifiers, often suffer from limited generalizability and are vulnerable to\nparaphrasing, adversarial perturbations, and cross-domain shifts. In this work,\nwe propose SentiDetect, a model-agnostic framework for detecting LLM-generated\ntext by analyzing the divergence in sentiment distribution stability. Our\nmethod is motivated by the empirical observation that LLM outputs tend to\nexhibit emotionally consistent patterns, whereas human-written texts display\ngreater emotional variability. To capture this phenomenon, we define two\ncomplementary metrics: sentiment distribution consistency and sentiment\ndistribution preservation, which quantify stability under sentiment-altering\nand semantic-preserving transformations. We evaluate SentiDetect on five\ndiverse datasets and a range of advanced LLMs,including Gemini-1.5-Pro,\nClaude-3, GPT-4-0613, and LLaMa-3.3. Experimental results demonstrate its\nsuperiority over state-of-the-art baselines, with over 16% and 11% F1 score\nimprovements on Gemini-1.5-Pro and GPT-4-0613, respectively. Moreover,\nSentiDetect also shows greater robustness to paraphrasing, adversarial attacks,\nand text length variations, outperforming existing detectors in challenging\nscenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u60c5\u611f\u5206\u5e03\u6ce2\u52a8\u5206\u6790\u7684LLM\u6587\u672c\u68c0\u6d4b\u65b0\u65b9\u6cd5SentiDetect\uff0c\u5728\u591a\u4e2a\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728\u591a\u79cd\u590d\u6742\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8fc5\u901f\u53d1\u5c55\uff0cAI\u751f\u6210\u5185\u5bb9\u65e5\u76ca\u590d\u6742\uff0c\u5bfc\u81f4\u4eba\u7c7b\u96be\u4ee5\u533a\u5206\u6a21\u578b\u751f\u6210\u6587\u672c\u4e0e\u771f\u4eba\u5199\u4f5c\u3002\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u5bb9\u6613\u88ab\u6539\u5199\u3001\u5bf9\u6297\u653b\u51fb\u548c\u9886\u57df\u8f6c\u79fb\u89c4\u907f\u3002", "method": "\u63d0\u51fa\u4e86SentiDetect\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u751f\u6210\u6587\u672c\u548c\u4eba\u5199\u6587\u672c\u5728\u60c5\u611f\u5206\u5e03\u7a33\u5b9a\u6027\u4e0a\u7684\u5dee\u5f02\u5b9e\u73b0\u68c0\u6d4b\u3002\u5b9a\u4e49\u4e86\u4e24\u4e2a\u4e92\u8865\u7684\u6307\u6807\uff1a\u60c5\u611f\u5206\u5e03\u4e00\u81f4\u6027\u548c\u60c5\u611f\u5206\u5e03\u4fdd\u6301\u6027\uff0c\u7528\u4ee5\u91cf\u5316\u6587\u672c\u5728\u60c5\u611f\u548c\u8bed\u4e49\u53d8\u6362\u4e0b\u7684\u7a33\u5b9a\u6027\u3002\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u591a\u79cd\u6a21\u578b\uff08\u6a21\u578b\u65e0\u5173\uff09\u3002", "result": "\u5728Gemini-1.5-Pro\u3001Claude-3\u3001GPT-4-0613\u548cLLaMa-3.3\u7b49\u5148\u8fdbLLMs\u53ca\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0cSentiDetect\u6bd4\u5f53\u524d\u6700\u4f18\u68c0\u6d4b\u65b9\u6cd5F1\u5206\u6570\u63d0\u5347\u8d8516%\uff08Gemini-1.5-Pro\uff09\u548c11%\uff08GPT-4-0613\uff09\uff1b\u5bf9\u6539\u5199\u3001\u653b\u51fb\u3001\u6587\u672c\u957f\u5ea6\u53d8\u5316\u66f4\u5177\u9c81\u68d2\u6027\u3002", "conclusion": "SentiDetect\u6709\u6548\u5229\u7528\u60c5\u611f\u5206\u5e03\u7a33\u5b9a\u6027\u5dee\u5f02\uff0c\u4ee5\u6a21\u578b\u65e0\u5173\u7684\u65b9\u5f0f\u63d0\u5347\u4e86LLM\u751f\u6210\u6587\u672c\u68c0\u6d4b\u6027\u80fd\uff0c\u5e76\u663e\u8457\u589e\u5f3a\u4e86\u9c81\u68d2\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u68c0\u6d4b\u5668\u3002"}}
{"id": "2508.06971", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.06971", "abs": "https://arxiv.org/abs/2508.06971", "authors": ["Mohamed Basem", "Islam Oshallah", "Ali Hamdi", "Khaled Shaban", "Hozaifa Kassab"], "title": "Two-Stage Quranic QA via Ensemble Retrieval and Instruction-Tuned Answer Extraction", "comment": "8 pages , 4 figures , Accepted in Aiccsa 2025 ,\n  https://conferences.sigappfr.org/aiccsa2025/", "summary": "Quranic Question Answering presents unique challenges due to the linguistic\ncomplexity of Classical Arabic and the semantic richness of religious texts. In\nthis paper, we propose a novel two-stage framework that addresses both passage\nretrieval and answer extraction. For passage retrieval, we ensemble fine-tuned\nArabic language models to achieve superior ranking performance. For answer\nextraction, we employ instruction-tuned large language models with few-shot\nprompting to overcome the limitations of fine-tuning on small datasets. Our\napproach achieves state-of-the-art results on the Quran QA 2023 Shared Task,\nwith a MAP@10 of 0.3128 and MRR@10 of 0.5763 for retrieval, and a pAP@10 of\n0.669 for extraction, substantially outperforming previous methods. These\nresults demonstrate that combining model ensembling and instruction-tuned\nlanguage models effectively addresses the challenges of low-resource question\nanswering in specialized domains.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u53e4\u5170\u7ecf\u95ee\u7b54\u9762\u4e34\u7684\u8bed\u8a00\u548c\u8bed\u4e49\u590d\u6742\u6027\uff0c\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u96c6\u6210\u963f\u62c9\u4f2f\u8bed\u6a21\u578b\u8fdb\u884c\u68c0\u7d22\u3001\u6307\u4ee4\u5fae\u8c03\u5927\u6a21\u578b\u8fdb\u884c\u62bd\u53d6\uff0c\u7ed3\u5408\u5c11\u6837\u672c\u63d0\u5347\u4f4e\u8d44\u6e90\u9886\u57df\u6548\u679c\uff0c\u5e76\u5728\u76f8\u5173\u7ade\u8d5b\u4efb\u52a1\u4e0a\u53d6\u5f97\u9886\u5148\u7ed3\u679c\u3002", "motivation": "\u53e4\u5170\u7ecf\u7684\u95ee\u7b54\u7cfb\u7edf\u56e0\u53e4\u5178\u963f\u62c9\u4f2f\u8bed\u7684\u8bed\u8a00\u590d\u6742\u6027\u548c\u5b97\u6559\u6587\u672c\u7684\u8bed\u4e49\u4e30\u5bcc\u6027\u800c\u9762\u4e34\u72ec\u7279\u6311\u6218\uff0c\u4e9f\u9700\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u63d0\u5347\u95ee\u7b54\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u521b\u65b0\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u96c6\u6210\u5fae\u8c03\u7684\u963f\u62c9\u4f2f\u8bed\u6a21\u578b\u5b9e\u73b0\u9ad8\u6548\u6587\u672c\u68c0\u7d22\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5229\u7528\u6307\u4ee4\u5fae\u8c03\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u5c11\u91cf\u793a\u4f8b\u63d0\u793a\uff0c\u89e3\u51b3\u547d\u9898\u5fae\u8c03\u6570\u636e\u91cf\u5c0f\u7684\u5c40\u9650\u3002", "result": "\u5728Quran QA 2023 Shared Task\u4e2d\u53d6\u5f97\u4e86\u524d\u6cbf\u7684\u6210\u7ee9\uff1a\u6587\u672c\u68c0\u7d22MAP@10\u4e3a0.3128\uff0cMRR@10\u4e3a0.5763\uff0c\u7b54\u6848\u62bd\u53d6pAP@10\u4e3a0.669\uff0c\u660e\u663e\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002", "conclusion": "\u6a21\u578b\u96c6\u6210\u4e0e\u6307\u4ee4\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u76f8\u7ed3\u5408\uff0c\u80fd\u6709\u6548\u5e94\u5bf9\u7279\u5b9a\u9886\u57df\u4f4e\u8d44\u6e90\u95ee\u7b54\u7684\u8bf8\u591a\u6311\u6218\uff0c\u63d0\u5347\u53e4\u5170\u7ecf\u95ee\u7b54\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2508.06974", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.06974", "abs": "https://arxiv.org/abs/2508.06974", "authors": ["Zhijun Tu", "Hanting Chen", "Siqi Liu", "Chuanjian Liu", "Jian Li", "Jie Hu", "Yunhe Wang"], "title": "Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models", "comment": "16 pages, 5 figures", "summary": "1-bit LLM quantization offers significant advantages in reducing storage and\ncomputational costs. However, existing methods typically train 1-bit LLMs from\nscratch, failing to fully leverage pre-trained models. This results in high\ntraining costs and notable accuracy degradation. We identify that the large gap\nbetween full precision and 1-bit representations makes direct adaptation\ndifficult. In this paper, we introduce a consistent progressive training for\nboth forward and backward, smoothly converting the floating-point weights into\nthe binarized ones. Additionally, we incorporate binary-aware initialization\nand dual-scaling compensation to reduce the difficulty of progressive training\nand improve the performance. Experimental results on LLMs of various sizes\ndemonstrate that our method outperforms existing approaches. Our results show\nthat high-performance 1-bit LLMs can be achieved using pre-trained models,\neliminating the need for expensive training from scratch.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u6e10\u8fdb\u5f0f1-bit\u91cf\u5316\u65b9\u6cd5\uff0c\u6709\u6548\u5229\u7528\u9884\u8bad\u7ec3LLM\uff0c\u901a\u8fc7\u65b0\u578b\u521d\u59cb\u5316\u548c\u8865\u507f\u624b\u6bb5\uff0c\u5728\u5927\u5e45\u964d\u4f4e\u5b58\u50a8/\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\uff0c\u53d6\u5f97\u4f18\u5f02\u6027\u80fd\uff0c\u65e0\u9700\u4ece\u5934\u8bad\u7ec3\uff0c\u8fdc\u8d85\u4f20\u7edf1-bit\u65b9\u6cd5\u3002", "motivation": "1-bit\u91cf\u5316\u80fd\u5927\u5e45\u964d\u4f4eLLM\u7684\u5b58\u50a8\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4e00\u822c\u53ea\u80fd\u4ece\u5934\u8bad\u7ec31-bit LLM\uff0c\u65e0\u6cd5\u5229\u7528\u5df2\u6709\u7684\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5bfc\u81f4\u8bad\u7ec3\u6210\u672c\u9ad8\u4e14\u7cbe\u5ea6\u635f\u5931\u663e\u8457\u3002\u8fd9\u4e00\u95ee\u9898\u7684\u4e3b\u8981\u6839\u6e90\u5728\u4e8e\u5168\u7cbe\u5ea6\u548c1-bit\u8868\u793a\u4e4b\u95f4\u5dee\u8ddd\u8fc7\u5927\uff0c\u76f4\u63a5\u9002\u914d\u5341\u5206\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e00\u81f4\u6027\u7684\u6e10\u8fdb\u5f0f\uff08progressive\uff09\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5e94\u7528\u4e8e\u6b63\u5411\u548c\u53cd\u5411\u8fc7\u7a0b\uff0c\u80fd\u591f\u5e73\u6ed1\u5730\u5c06\u6d6e\u70b9\u6743\u91cd\u9010\u6b65\u8f6c\u6362\u4e3a\u4e8c\u503c\u6743\u91cd\uff1b\u6b64\u5916\u5f15\u5165\u4e86\u4e8c\u503c\u5316\u611f\u77e5\u7684\u521d\u59cb\u5316\u548c\u53cc\u5c3a\u5ea6\u8865\u507f\uff08dual-scaling compensation\uff09\u673a\u5236\uff0c\u964d\u4f4e\u6e10\u8fdb\u8bad\u7ec3\u96be\u5ea6\u5e76\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u89c4\u6a21\u7684LLM\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u9c81\u68d21-bit\u91cf\u5316\uff0c\u83b7\u5f97\u9ad8\u6027\u80fd\u76841-bit LLM\uff0c\u65e0\u9700\u518d\u82b1\u8d39\u5de8\u989d\u5f00\u9500\u4ece\u5934\u8bad\u7ec3\u3002", "conclusion": "\u901a\u8fc7\u4e00\u81f4\u6027\u7684\u6e10\u8fdb\u5f0f\u8bad\u7ec3\u3001\u7279\u5b9a\u521d\u59cb\u5316\u548c\u8865\u507f\u673a\u5236\uff0c\u53ef\u4ee5\u5229\u7528\u5df2\u6709\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u663e\u8457\u63d0\u53471-bit LLM\u91cf\u5316\u540e\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\uff0c\u7a81\u7834\u4e86\u539f\u51481-bit\u91cf\u5316\u9700\u4ece\u5934\u8bad\u7ec3\u3001\u635f\u5931\u4e25\u91cd\u7684\u74f6\u9888\u3002"}}
{"id": "2508.07017", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.07017", "abs": "https://arxiv.org/abs/2508.07017", "authors": ["Mao Li", "Fred Conrad", "Johann Gagnon-Bartsch"], "title": "Vec2Summ: Text Summarization via Probabilistic Sentence Embeddings", "comment": null, "summary": "We propose Vec2Summ, a novel method for abstractive summarization that frames\nthe task as semantic compression. Vec2Summ represents a document collection\nusing a single mean vector in the semantic embedding space, capturing the\ncentral meaning of the corpus. To reconstruct fluent summaries, we perform\nembedding inversion -- decoding this mean vector into natural language using a\ngenerative language model. To improve reconstruction quality and capture some\ndegree of topical variability, we introduce stochasticity by sampling from a\nGaussian distribution centered on the mean. This approach is loosely analogous\nto bagging in ensemble learning, where controlled randomness encourages more\nrobust and varied outputs. Vec2Summ addresses key limitations of LLM-based\nsummarization methods. It avoids context-length constraints, enables\ninterpretable and controllable generation via semantic parameters, and scales\nefficiently with corpus size -- requiring only $O(d + d^2)$ parameters.\nEmpirical results show that Vec2Summ produces coherent summaries for topically\nfocused, order-invariant corpora, with performance comparable to direct LLM\nsummarization in terms of thematic coverage and efficiency, albeit with less\nfine-grained detail. These results underscore Vec2Summ's potential in settings\nwhere scalability, semantic control, and corpus-level abstraction are\nprioritized.", "AI": {"tldr": "Vec2Summ\u7528\u5e73\u5747\u5d4c\u5165\u538b\u7f29\u8bed\u6599\u5e93\u8bed\u4e49\uff0c\u5e76\u901a\u8fc7\u53cd\u89e3\u83b7\u5f97\u6587\u672c\u6458\u8981\uff0c\u5728\u6458\u8981\u8d28\u91cf\u548c\u6548\u7387\u4e0a\u63a5\u8fd1\u4e3b\u6d41\u5927\u6a21\u578b\uff0c\u5c24\u5176\u9002\u5408\u5173\u6ce8\u8bed\u4e49\u3001\u89c4\u6a21\u548c\u53ef\u63a7\u6027\u7684\u5e94\u7528\u573a\u666f\u3002", "motivation": "\u5f53\u524d\u5927\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u7684\u6458\u8981\u65b9\u6cd5\u5b58\u5728\u9650\u5236\uff0c\u5982\u4e0a\u4e0b\u6587\u957f\u5ea6\u6709\u9650\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u63a7\u6027\u5f31\uff0c\u4ee5\u53ca\u96be\u4ee5\u9ad8\u6548\u6269\u5c55\u5230\u5927\u89c4\u6a21\u8bed\u6599\u5e93\u3002", "method": "Vec2Summ\u65b9\u6cd5\u5c06\u6458\u8981\u751f\u6210\u5efa\u6a21\u4e3a\u8bed\u4e49\u538b\u7f29\u8fc7\u7a0b\uff0c\u4f7f\u7528\u6587\u6863\u96c6\u5408\u7684\u5e73\u5747\u5d4c\u5165\u5411\u91cf\u6765\u8868\u793a\u8bed\u6599\uff0c\u518d\u901a\u8fc7\u751f\u6210\u5f0f\u6a21\u578b\u5c06\u8be5\u8bed\u4e49\u5411\u91cf\u53cd\u89e3\u6210\u6d41\u7545\u7684\u81ea\u7136\u8bed\u8a00\u6458\u8981\u3002\u4e3a\u63d0\u5347\u6458\u8981\u591a\u6837\u6027\u548c\u9c81\u68d2\u6027\uff0c\u65b9\u6cd5\u4e2d\u5f15\u5165\u4ee5\u5e73\u5747\u5411\u91cf\u4e3a\u4e2d\u5fc3\u7684\u9ad8\u65af\u968f\u673a\u91c7\u6837\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cVec2Summ\u5728\u4e3b\u9898\u96c6\u4e2d\u7684\u8bed\u6599\u4e0a\u80fd\u751f\u6210\u8fde\u8d2f\u3001\u4e3b\u9898\u8986\u76d6\u826f\u597d\u7684\u6458\u8981\uff0c\u6548\u7387\u4e0e\u76f4\u63a5LLM\u6458\u8981\u76f8\u5f53\uff0c\u4f46\u7ec6\u8282\u5c42\u9762\u7565\u900a\u4e00\u7b79\u3002", "conclusion": "Vec2Summ\u5728\u9700\u8981\u8bed\u4e49\u63a7\u5236\u3001\u53ef\u6269\u5c55\u6027\u548c\u8bed\u6599\u7ea7\u62bd\u8c61\u7684\u573a\u666f\u4e0b\uff0c\u5c55\u73b0\u4e86\u5e94\u7528\u6f5c\u529b\u3002"}}
