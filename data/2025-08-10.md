<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 12]
- [cs.CL](#cs.CL) [Total: 20]
- [cs.DM](#cs.DM) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Consistent Updates for Scalable Microservices](https://arxiv.org/abs/2508.04829)
*Devora Chait-Roth,Kedar S. Namjoshi,Thomas Wies*

Main category: cs.PL

TL;DR: 该论文提出并证明了一套利用语义信息保证微服务系统在混合模式更新（一边处理请求一边升级服务）下一致性的算法和理论，解决了长期存在的实际与理论难题。


<details>
  <summary>Details</summary>
Motivation: 在微服务架构下，为了保证服务不间断，功能修改通常需在服务运行时动态进行。但这种“混合模式”会出现新旧版本同时运行，易因相互作用导致一致性问题。现有方法要么牺牲效率避免混合模式，要么在逐步替换时无法控制一致性风险，促使作者提出新算法以安全实现在线更新。

Method: 提出了一套算法，利用服务操作里的语义属性（如可交换性），保障混合模式下的数据一致性。作者还建立了理论框架，形式化混合模式一致性并作为推理基础，对现有和新算法进行正确性证明。

Result: 证明依赖于操作语义的信息，对于混合模式下的一致性保障是必须的；仅根据状态无法避免不一致。所提算法能保证对每个客户端看来，服务更新如同原子性生效，消除了混合模式下的不一致风险。

Conclusion: 本文首次提出通过语义感知算法，系统性解决了微服务混合模式在线更新中的一致性难题，并给出了理论基础、算法及其正确性证明。

Abstract: Online services are commonly implemented with a scalable microservice
architecture, where isomorphic worker processes service client requests,
recording persistent state in a backend data store. To maintain service, any
modifications to the service functionality must be made on the fly -- i.e., as
the service continues to process client requests -- but doing so is
challenging. The central difficulty is that of avoiding potential
inconsistencies caused by ''mixed mode'' operation, where workers of current
and new versions are concurrently active and interact via the data store. Some
update methods avoid mixed mode altogether, but only at the cost of substantial
inefficiency -- by doubling resources (memory and compute), or by halving
throughput. The alternative is a so-called ''rolling'' update, which is
uncontrolled and runs the risk of serious service failures arising from
inconsistent mixed-mode behavior.
  In this paper, we present the first algorithms that guarantee consistency for
mixed mode updates. The algorithms rely on semantic properties of service
actions, such as commutativity. We show that semantic awareness is required, by
proving that any semantically oblivious, mixed-mode update method cannot avoid
inconsistencies. Ideally, it should appear to every client that a service
update takes effect atomically; this ensures that a client is not exposed to
inconsistent mixed-mode behavior. We introduce a framework that formalizes this
intuition and develop foundational theory for reasoning about the consistency
of mixed-mode updates, applying that theory to derive the new algorithms and
establish their correctness.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [Automated File-Level Logging Generation for Machine Learning Applications using LLMs: A Case Study using GPT-4o Mini](https://arxiv.org/abs/2508.04820)
*Mayra Sofia Ruiz Rodriguez,SayedHassan Khatoonabadi,Emad Shihab*

Main category: cs.SE

TL;DR: GPT-4o mini对ML代码文件级日志生成的准确性有限，存在严重过度记录和规范不符问题，目前难以直接实用。


<details>
  <summary>Details</summary>
Motivation: 日志记录对软件开发至关重要，有助于监控系统行为和排查错误。尽管大语言模型（LLMs）在自然语言和代码生成方面表现突出，但人们主要聚焦于其在函数级别日志生成的能力，而对文件级别日志生成研究较少，特别是在机器学习（ML）领域。全面的文件级日志生成能提升项目可靠性。因此，作者希望评估LLM对ML项目文件级日志生成的能力和面临的挑战。

Method: 作者以GPT-4o mini为案例，收集了171个包含日志语句的ML开源项目，共计4,073个Python文件。其方法为：移除原始日志，用LLM为每个文件生成新的日志语句，然后对比分析这些LLM生成日志与人工日志在添加位置、日志级别、涉及变量与文本质量等方面的异同。此外，人工抽样分析LLM生成日志，探究常见模式与难点。

Result: LLM在63.91%的情况下能将日志添加在与人工相同位置，但存在高达82.66%的过度日志（overlogging）问题。手工分析发现，LLM倾向于在函数开头或结尾生成日志、难以处理大代码块内部日志、以及不符合项目定制化日志标准。

Conclusion: LLM文件级日志生成初步展现潜力，但过度日志、位置选择不当及难以遵循项目日志规范等问题亟待解决，当前还难以直接应用于实际开发中。

Abstract: Logging is essential in software development, helping developers monitor
system behavior and aiding in debugging applications. Given the ability of
large language models (LLMs) to generate natural language and code, researchers
are exploring their potential to generate log statements. However, prior work
focuses on evaluating logs introduced in code functions, leaving file-level log
generation underexplored -- especially in machine learning (ML) applications,
where comprehensive logging can enhance reliability. In this study, we evaluate
the capacity of GPT-4o mini as a case study to generate log statements for ML
projects at file level. We gathered a set of 171 ML repositories containing
4,073 Python files with at least one log statement. We identified and removed
the original logs from the files, prompted the LLM to generate logs for them,
and evaluated both the position of the logs and log level, variables, and text
quality of the generated logs compared to human-written logs. In addition, we
manually analyzed a representative sample of generated logs to identify common
patterns and challenges. We find that the LLM introduces logs in the same place
as humans in 63.91% of cases, but at the cost of a high overlogging rate of
82.66%. Furthermore, our manual analysis reveals challenges for file-level
logging, which shows overlogging at the beginning or end of a function,
difficulty logging within large code blocks, and misalignment with
project-specific logging conventions. While the LLM shows promise for
generating logs for complete files, these limitations remain to be addressed
for practical implementation.

</details>


### [3] [Automated Bug Frame Retrieval from Gameplay Videos Using Vision-Language Models](https://arxiv.org/abs/2508.04895)
*Wentao Lu,Alexander Senchenko,Abram Hindle,Cor-Paul Bezemer*

Main category: cs.SE

TL;DR: 提出一种结合关键帧提取和多模态模型的自动化流程，实现Bug视频自动归档定位，显著提升开发团队效率。


<details>
  <summary>Details</summary>
Motivation: 现代游戏工作室更新频繁，产生大量包含视频的Bug报告。开发者验证这些报告时需观看大量视频，费时费力且难以扩展。

Method: 提出了一条自动化流程，利用FFmpeg提取关键帧，再用视觉-语言模型（GPT-4o）根据文本Bug描述对关键帧排序并选取最具代表性的帧。

Result: 在真实FPS游戏Bug数据上，关键帧过滤到1.9%的帧，98.79%的Bug时刻被捕捉，最终主帧提取F1为0.79、准确率0.89。不同Bug种类表现各异，照明与阴影类别F1最高达0.94，动效最低为0.51。

Conclusion: 本方法用单帧图像代替视频人工审核，大幅降低QA和开发团队的人力和时间成本，对于游戏行业的Bug管理具有实际价值。

Abstract: Modern game studios deliver new builds and patches at a rapid pace,
generating thousands of bug reports, many of which embed gameplay videos. To
verify and triage these bug reports, developers must watch the submitted
videos. This manual review is labour-intensive, slow, and hard to scale. In
this paper, we introduce an automated pipeline that reduces each video to a
single frame that best matches the reported bug description, giving developers
instant visual evidence that pinpoints the bug.
  Our pipeline begins with FFmpeg for keyframe extraction, reducing each video
to a median of just 1.90% of its original frames while still capturing bug
moments in 98.79 of cases. These keyframes are then evaluated by a
vision--language model (GPT-4o), which ranks them based on how well they match
the textual bug description and selects the most representative frame. We
evaluated this approach using real-world developer-submitted gameplay videos
and JIRA bug reports from a popular First-Person Shooter (FPS) game. The
pipeline achieves an overall F1 score of 0.79 and Accuracy of 0.89 for the
top-1 retrieved frame. Performance is highest for the Lighting & Shadow (F1 =
0.94), Physics & Collision (0.86), and UI & HUD (0.83) bug categories, and
lowest for Animation & VFX (0.51).
  By replacing video viewing with an immediately informative image, our
approach dramatically reduces manual effort and speeds up triage and regression
checks, offering practical benefits to quality assurance (QA) teams and
developers across the game industry.

</details>


### [4] [Charting Uncertain Waters: A Socio-Technical Framework for Navigating GenAI's Impact on Open Source Communities](https://arxiv.org/abs/2508.04921)
*Zixuan Feng,Reed Milewicz,Emerson Murphy-Hill,Tyler Menezes,Alexander Serebrenik,Igor Steinmacher,Anita Sarma*

Main category: cs.SE

TL;DR: 本文以社会技术视角，提出开源社区应主动采用分析框架，以应对生成式AI可能带来的挑战和机遇，提升其韧性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正快速重塑软件开发、维护和治理，不清晰的应对框架会让开源社区被技术复杂性和不确定性压倒，威胁其协作基础。

Method: 采用情景驱动的概念性探索，结合社会技术框架对开源社区面临的AI影响进行分析，涵盖软件实践、文档、社区参与和治理四大领域。

Result: 揭示了AI驱动背景下开源软件社区在相关领域面临的风险和机遇，并为社区领导者和研究人员提供了应对技术剧变的分析框架。

Conclusion: 通过采用麦克卢汉Tetrad启发的社会技术框架，开源社区能够及早识别并应对由生成式AI带来的挑战，从而更有韧性地发展。

Abstract: Open Source Software communities face a wave of uncertainty as Generative AI
rapidly transforms how software is created, maintained, and governed. Without
clear frameworks, communities risk being overwhelmed by the complexity and
ambiguity introduced by GenAI, threatening the collaborative ethos that
underpins OSS. We conduct a scenario-driven, conceptual exploration using a
socio-technical framework inspired by McLuhan's Tetrad to surface both risks
and opportunities for community resilience amid GenAI-driven disruption of OSS
development across four domains: software practices, documentation, community
engagement, and governance. By adopting this lens, OSS leaders and researchers
can proactively shape the future of their ecosystems, rather than simply
reacting to technological upheaval.

</details>


### [5] [Taxonomy of Faults in Attention-Based Neural Networks](https://arxiv.org/abs/2508.04925)
*Sigma Jahan,Saurabh Singh Rajput,Tushar Sharma,Mohammad Masudur Rahman*

Main category: cs.SE

TL;DR: 当前深度学习模型中的故障分类体系无法识别注意力机制引发的独特故障。本文通过大规模数据分析，提出了七类专属故障类别及对应的诊断启发规则，显著提升了注意力机制神经网络的可诊断性和修复指导。


<details>
  <summary>Details</summary>
Motivation: 随着注意力机制在神经网络中的广泛应用（如ChatGPT、自动驾驶等），相关故障对经济和现实应用产生了重大影响。然而，目前深度学习中的故障分类体系无法有效覆盖注意力机制引起的特殊故障，导致开发者在故障定位和诊断时缺乏针对性的指导。

Method: 作者对使用注意力机制的神经网络（ABNNs）在十个主流框架下、来自96个项目（如GitHub、Hugging Face和Stack Overflow）收集的555个实际故障样本进行了系统实证分析。通过归纳总结，构建了新的注意力机制专属故障分类法，并进一步分析了这些故障的根因与表现症状。

Result: 研究提出了七类注意力机制特有的故障类型，这些类型在现有分类体系中未被覆盖。数据分析显示，超过一半的实际故障与注意力架构的独特机制有关。进一步针对症状和根因的关联性，作者提出了四条循证诊断启发式规则，能够系统性解释33%的注意力特有故障。

Conclusion: 本文首次系统梳理了注意力机制神经网络中的故障类型与诊断方法，提出新的分类法和实证启发，为相关模型的诊断和改进提供了可靠依据。

Abstract: Attention mechanisms are at the core of modern neural architectures, powering
systems ranging from ChatGPT to autonomous vehicles and driving a major
economic impact. However, high-profile failures, such as ChatGPT's nonsensical
outputs or Google's suspension of Gemini's image generation due to attention
weight errors, highlight a critical gap: existing deep learning fault
taxonomies might not adequately capture the unique failures introduced by
attention mechanisms. This gap leaves practitioners without actionable
diagnostic guidance. To address this gap, we present the first comprehensive
empirical study of faults in attention-based neural networks (ABNNs). Our work
is based on a systematic analysis of 555 real-world faults collected from 96
projects across ten frameworks, including GitHub, Hugging Face, and Stack
Overflow. Through our analysis, we develop a novel taxonomy comprising seven
attention-specific fault categories, not captured by existing work. Our results
show that over half of the ABNN faults arise from mechanisms unique to
attention architectures. We further analyze the root causes and manifestations
of these faults through various symptoms. Finally, by analyzing symptom-root
cause associations, we identify four evidence-based diagnostic heuristics that
explain 33.0% of attention-specific faults, offering the first systematic
diagnostic guidance for attention-based models.

</details>


### [6] [Generative AI for Object-Oriented Programming: Writing the Right Code and Reasoning the Right Logic](https://arxiv.org/abs/2508.05005)
*Gang Xu,Airong Wang,Yushan Pan*

Main category: cs.SE

TL;DR: 大语言模型（LLMs）与面向对象编程（OOP）的结合尚处于早期探索阶段。本文分析了不同利益相关者的需求，指出LLMs在OOP学习及编码流程中的关键作用和提升点，并提出了一些增强代码能力和推理的方法。


<details>
  <summary>Details</summary>
Motivation: 人工智能，尤其是大语言模型（LLMs）的研究迅速发展，并已应用于多个领域。然而，大语言模型在面向对象编程（OOP）领域的作用与结合目前尚未被充分探讨。缺乏对LLMs在提升OOP学习和代码编写效率方面的理解，以及相关AI工具的有效评估方法。

Method: 从面向对象编程任务中不同关键利益相关者（如程序初学者、进阶学习者和经验丰富的程序员）的角度出发，分析在典型编码工作流程中LLMs可以被整合的关键节点，识别其潜在提升点。同时提出增强现有逻辑推理能力和代码编写效率的方法。

Result: 识别了LLMs可为OOP学习与编程工作流带来显著提升的关键环节，并提出了整合与增强LLMs能力的具体建议，以改进编程体验和效率。

Conclusion: LLMs在面向对象编程领域的整合具有巨大潜力，可以提升编程学习与代码开发，但相关研究和工具评估尚不完善。本文提供了理论基础和实践指南，为后续开发更高效的AI辅助编程工具提供了方向。

Abstract: We find ourselves in the midst of an explosion in artificial intelligence
research, particularly with large language models (LLMs). These models have
diverse applications spanning finance, commonsense knowledge graphs, medicine,
and visual analysis. In the world of Object-Oriented Programming(OOP), a robust
body of knowledge and methods has been developed for managing complex tasks
through object-oriented thinking. However, the intersection of LLMs with OOP
remains an underexplored territory. Empirically, we currently possess limited
understanding of how LLMs can enhance the effectiveness of OOP learning and
code writing, as well as how we can evaluate such AI-powered tools. Our work
aims to address this gap by presenting a vision from the perspectives of key
stakeholders involved in an OOP task: programmers, mariners, and experienced
programmers. We identify critical junctures within typical coding workflows
where the integration of LLMs can offer significant benefits. Furthermore, we
propose ways to augment existing logical reasoning and code writing, ultimately
enhancing the programming experience.

</details>


### [7] [An ML-based Approach to Predicting Software Change Dependencies: Insights from an Empirical Study on OpenStack](https://arxiv.org/abs/2508.05034)
*Arabat,Ali,Sayagh,Mohammed,Hassine,Jameleddine*

Main category: cs.SE

TL;DR: 本文针对大型软件系统变更依赖识别难题，分析了OpenStack的历史数据，发现当前识别依赖效率低下。作者提出了基于机器学习的依赖预测方法，实验结果显示模型在准确性和召回率方面表现良好，可显著提升依赖管理效率。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统日益复杂，变更之间的依赖关系识别与管理变得尤为重要，尤其是在CI/CD流程中，依赖关系错误可能导致构建失败或功能部署不完整。跨团队、多组件的依赖管理难度大，且依赖形式多样。作者发现实际系统中，开发者识别这些依赖的效率低下，因此亟需提升依赖识别的自动化和准确性。

Method: 通过对大型开源软件OpenStack的10年变更数据进行实证研究，分析了变更依赖的实际情况。针对依赖识别耗时、准确率低等问题，提出了基于机器学习的半自动方法：第一个模型预测变更之间存在依赖的可能性，第二个模型进一步确定具体的依赖变更对。

Result: 数据显示，OpenStack中大约一半变更具有依赖，且大多是在code review阶段才被识别出来，平均识别一对依赖需花费57.12小时。所提出的两个机器学习模型分别达到了平均AUC 79.33%和91.89%，Brier分数0.11和0.014，显示出良好的依赖预测性能。

Conclusion: 半自动依赖识别方法在变更管理中有效提升了依赖识别的效率和准确率，能够帮助开发团队更及时、准确地发现关键依赖关系，对大规模软件协作开发具有重要意义。

Abstract: As software systems grow in complexity, accurately identifying and managing
dependencies among changes becomes increasingly critical. For instance, a
change that leverages a function must depend on the change that introduces it.
Establishing such dependencies allows CI/CD pipelines to build and orchestrate
changes effectively, preventing build failures and incomplete feature
deployments. In modern software systems, dependencies often span multiple
components across teams, creating challenges for development and deployment.
They serve various purposes, from enabling new features to managing
configurations, and can even involve traditionally independent changes like
documentation updates. To address these challenges, we conducted a preliminary
study on dependency management in OpenStack, a large-scale software system. Our
study revealed that a substantial portion of software changes in OpenStack over
the past 10 years are interdependent. Surprisingly, 51.08% of these
dependencies are identified during the code review phase-after a median delay
of 5.06 hours-rather than at the time of change creation. Developers often
spend a median of 57.12 hours identifying dependencies, searching among a
median of 463 other changes. To help developers proactively identify
dependencies, we propose a semi-automated approach that leverages two ML
models. The first model predicts the likelihood of dependencies among changes,
while the second identifies the exact pairs of dependent changes. Our proposed
models demonstrate strong performance, achieving average AUC scores of 79.33%
and 91.89%, and Brier scores of 0.11 and 0.014, respectively. Indeed, the
second model has a good top-k recall across all types of pairs, while the top-k
precision has room for improvement.

</details>


### [8] [LadyBug: A GitHub Bot for UI-Enhanced Bug Localization in Mobile Apps](https://arxiv.org/abs/2508.05085)
*Junayed Mahmud,James Chen,Terry Achille,Camilo Alvarez-Velez,Darren Dean Bansil,Patrick Ijieh,Samar Karanch,Nadeeshan De Silva,Oscar Chaparro,Andrian Marcus,Kevin Moran*

Main category: cs.SE

TL;DR: 提出了结合UI轨迹与文本描述的开源自动化bug定位工具LadyBug，实验表明其在定位准确性上优于传统方法，对于Android项目开发者有很大帮助。


<details>
  <summary>Details</summary>
Motivation: 在移动应用开发中，快速准确地定位bug是提升开发效率和用户体验的关键，但传统的文本检索方法在bug定位时常常不够准确。本研究旨在结合UI交互信息，提升安卓应用的bug定位精度。

Method: 提出LadyBug工具，集成于Github，能自动响应bug报告。开发者在报告bug后，可上传重现该bug的UI交互轨迹，LadyBug结合原始文本描述与UI信息，从项目文件中检索并排名最可能含有bug的文件。该方法通过RedWing自动化测试基准进行评估。

Result: 实验显示，LadyBug在bug定位准确率上优于基于文本的传统方法，UI信息的引入对提升定位效果有显著作用。

Conclusion: LadyBug通过融合文本与UI痕迹，实现Android应用bug更高效精准定位，其开源实现和评测结果表明该工具具有实际应用价值。

Abstract: This paper introduces LadyBug, a GitHub bot that automatically localizes bugs
for Android apps by combining UI interaction information with text retrieval.
LadyBug connects to an Android app's GitHub repository, and is triggered when a
bug is reported in the corresponding issue tracker. Developers can then record
a reproduction trace for the bug on a device or emulator and upload the trace
to LadyBug via the GitHub issue tracker. This enables LadyBug to utilize both
the text from the original bug description, and UI information from the
reproduction trace to accurately retrieve a ranked list of files from the
project that most likely contain the reported bug.
  We empirically evaluated LadyBug using an automated testing pipeline and
benchmark called RedWing that contains 80 fully-localized and reproducible bug
reports from 39 Android apps. Our results illustrate that LadyBug outperforms
text-retrieval-based baselines and that the utilization of UI information leads
to a substantial increase in localization accuracy. LadyBug is an open-source
tool, available at https://github.com/LadyBugML/ladybug.
  A video showing the capabilities of Ladybug can be viewed here:
https://youtu.be/hI3tzbRK0Cw

</details>


### [9] [Posterior-GRPO: Rewarding Reasoning Processes in Code Generation](https://arxiv.org/abs/2508.05170)
*Lishui Fan,Yu Zhang,Mouxiang Chen,Zhongxin Liu*

Main category: cs.SE

TL;DR: 本论文提出一种新型强化学习框架，通过构建推理质量基准与优化-退化奖励训练，结合新型P-GRPO方法，有效提升代码生成模型推理质量和结果准确率，超越现有方法并接近GPT-4-Turbo性能，方法可扩展到数学任务。


<details>
  <summary>Details</summary>
Motivation: 强化学习已推动大模型的代码生成进步，但现有方法只注重测试结果，忽视了中间推理过程的质量。直接对推理过程进行监督虽有前景，但容易被模型“奖励黑客”利用，导致推理奖励信号被滥用而无法提升最终结果。

Method: 提出了一个统一框架，把推理过程的质量有效融入强化学习。包括：(1) 构建了LCB-RB基准，包括优劣推理过程的偏好对；(2) 用优化-退化（OD-based）方法训练奖励模型，通过在推理过程中系统性优化和退化生成高质量的偏好数据对，提升奖励模型的区分能力；(3) 提出了Posterior-GRPO (P-GRPO)强化学习方法，只对最终成功结果的推理过程赋予奖励，从而减弱奖励黑客问题。

Result: 7B参数奖励模型在LCB-RB和其他基准上表现出色。采用P-GRPO的7B模型在各种代码生成任务中表现优异，比只用结果的基线高出4.5%，性能接近GPT-4-Turbo，并能推广到数学任务。

Conclusion: 结合推理过程质量和任务结果进行强化学习，能有效提升代码生成模型的表现，抑制奖励黑客，且方法具有良好的泛化能力。数据集与代码已公开，方便后续研究。

Abstract: Reinforcement learning (RL) has significantly advanced code generation for
large language models (LLMs). However, current paradigms rely on outcome-based
rewards from test cases, neglecting the quality of the intermediate reasoning
process. While supervising the reasoning process directly is a promising
direction, it is highly susceptible to reward hacking, where the policy model
learns to exploit the reasoning reward signal without improving final outcomes.
To address this, we introduce a unified framework that can effectively
incorporate the quality of the reasoning process during RL. First, to enable
reasoning evaluation, we develop LCB-RB, a benchmark comprising preference
pairs of superior and inferior reasoning processes. Second, to accurately score
reasoning quality, we introduce an Optimized-Degraded based (OD-based) method
for reward model training. This method generates high-quality preference pairs
by systematically optimizing and degrading initial reasoning paths along
curated dimensions of reasoning quality, such as factual accuracy, logical
rigor, and coherence. A 7B parameter reward model with this method achieves
state-of-the-art (SOTA) performance on LCB-RB and generalizes well to other
benchmarks. Finally, we introduce Posterior-GRPO (P-GRPO), a novel RL method
that conditions process-based rewards on task success. By selectively applying
rewards to the reasoning processes of only successful outcomes, P-GRPO
effectively mitigates reward hacking and aligns the model's internal reasoning
with final code correctness. A 7B parameter model with P-GRPO achieves superior
performance across diverse code generation tasks, outperforming outcome-only
baselines by 4.5%, achieving comparable performance to GPT-4-Turbo. We further
demonstrate the generalizability of our approach by extending it to
mathematical tasks. Our models, dataset, and code are publicly available.

</details>


### [10] [AI-assisted JSON Schema Creation and Mapping](https://arxiv.org/abs/2508.05192)
*Felix Neubauer,Jürgen Pleiss,Benjamin Uekermann*

Main category: cs.SE

TL;DR: 该论文提出了一种结合AI与确定性技术的方法，让非专业用户通过自然语言输入即可创建和映射JSON Schema，已集成至开源工具MetaConfigurator，并在化学领域示例中验证有效，大幅降低了数据建模与集成门槛。


<details>
  <summary>Details</summary>
Motivation: 在许多领域，缺乏标准化的数据模型，非专业人士很难创建、修改和映射数据模型。模型驱动工程（MDE）虽重要，但实际推广过程中存在门槛，特别是面向研究数据时。

Method: 提出一种混合方法，将大语言模型（LLM）与确定性技术结合，支持用户通过自然语言输入，实现JSON Schema的创建、修改和映射。该方法已集成到开源工具MetaConfigurator中，结合可视化编辑、验证、代码生成等功能。数据集成环节，通过LLM生成异构数据（JSON、CSV、XML、YAML）的Schema映射，并用确定性方式执行映射规则以保证可扩展性和可靠性。

Result: 本方法在化学领域应用实例中得到了验证。通过自然语言交互和确定性保障，显著降低了非专业人士进行结构化数据建模和数据集成的门槛。

Conclusion: 结合LLM与确定性方法的混合方案，能够大幅简化数据模型创建和映射过程，让非专业用户也能轻松实现结构化数据管理和数据集成，有助于广泛领域的数据标准化工作推进。

Abstract: Model-Driven Engineering (MDE) places models at the core of system and data
engineering processes. In the context of research data, these models are
typically expressed as schemas that define the structure and semantics of
datasets. However, many domains still lack standardized models, and creating
them remains a significant barrier, especially for non-experts. We present a
hybrid approach that combines large language models (LLMs) with deterministic
techniques to enable JSON Schema creation, modification, and schema mapping
based on natural language inputs by the user. These capabilities are integrated
into the open-source tool MetaConfigurator, which already provides visual model
editing, validation, code generation, and form generation from models. For data
integration, we generate schema mappings from heterogeneous JSON, CSV, XML, and
YAML data using LLMs, while ensuring scalability and reliability through
deterministic execution of generated mapping rules. The applicability of our
work is demonstrated in an application example in the field of chemistry. By
combining natural language interaction with deterministic safeguards, this work
significantly lowers the barrier to structured data modeling and data
integration for non-experts.

</details>


### [11] [STEPWISE-CODEX-Bench: Evaluating Complex Multi-Function Comprehension and Fine-Grained Execution Reasoning](https://arxiv.org/abs/2508.05193)
*Kaiwen Yan,Yuhang Chang,Zirui Guo,Yaling Mou,Jiang Ming,Jingwei Sun*

Main category: cs.SE

TL;DR: 本文提出SX-Bench新基准，能细致考察大语言模型在复杂多函数代码场景下的推理与理解能力，并发现即便最强模型在此项任务仍显不足，揭示了新挑战，为未来模型改进与评估指明方向。


<details>
  <summary>Details</summary>
Motivation: 现有主流的代码智能基准（如HumanEval和MBPP）主要考察代码的功能正确性，而用于推理能力评估的基准（如CRUXEVAL）又只涵盖单函数、低复杂度场景，导致先进模型分数趋于饱和，失去区分度。当前缺少能全面评估大模型复杂代码理解和细粒度推理能力的标准化工具。

Method: 提出了STEPWISE-CODEX-Bench（SX-Bench）基准，通过多子函数协作（如链式调用、嵌套循环）的代码任务，定义并要求模型预测“计算步骤”数量，从而考察模型对复杂控制流与数据流的动态执行理解。基准的生成结合了程序合成、符号执行与大模型辅助验证，实现自动化与高质量保障。

Result: 在20余种主流大模型（含14种推理增强模型）上的评测显示，SX-Bench能有效区分模型能力。例如，OpenAI最新模型在SX-Bench的复杂推理任务上的准确率仅为78.37%，远低于其在旧基准上的饱和分数，显著揭示了模型在复杂推理场景中的瓶颈。

Conclusion: SX-Bench将代码评测从“单函数验证”提升到“多函数动态推理”，为评估和推动高级代码智能模型提供了关键工具。研究发现当前大模型在复杂、多步骤推理能力上仍不够理想，有待进一步突破。

Abstract: In recent years, large language models (LLMs) have made significant progress
in code intelligence, yet systematically evaluating their code understanding
and reasoning abilities remains challenging. Mainstream benchmarks such as
HumanEval and MBPP primarily assess functional correctness, while reasoning
benchmarks like CRUXEVAL are limited to single-function, low-complexity
scenarios. As a result, advanced models achieve nearly saturated scores,
limiting their discriminative power. To address this, we present
STEPWISE-CODEX-Bench (SX-Bench), a novel benchmark designed for complex
multi-function understanding and fine-grained execution reasoning. SX-Bench
features tasks involving collaboration among multiple sub-functions (e.g.,
chained calls, nested loops), shifting evaluation towards overall control and
data flow modeling. It defines "computation steps" as the minimal execution
unit and requires models to predict the total number of steps in reasoning
tasks, thereby assessing a model's in-depth understanding of dynamic execution
beyond simple I/O matching. Evaluation on over 20 mainstream models (including
14 reasoning-enhanced models) demonstrates that SX-Bench is highly
discriminative: even the state-of-the-art OpenAI-O3 achieves only 78.37 percent
accuracy on Hard-Reasoning tasks, much lower than its saturated scores on
previous benchmarks, thereby revealing bottlenecks in complex and fine-grained
reasoning. We also release an automated pipeline combining program synthesis,
symbolic execution, and LLM-aided validation for efficient benchmark generation
and quality assurance. SX-Bench advances code evaluation from "single-function
verification" to "multi-function dynamic reasoning," providing a key tool for
the in-depth assessment of advanced code intelligence models.

</details>


### [12] [EvoGraph: Hybrid Directed Graph Evolution toward Software 3.0](https://arxiv.org/abs/2508.05199)
*Igor Costa,Christopher Baran*

Main category: cs.SE

TL;DR: EvoGraph 能自动进化多种软件 artefacts，通过小型专用语言模型有效提升性能与可控性，大幅提升自动化现代化效率，显著降低计算资源消耗，为软件3.0的实现提供技术支撑。


<details>
  <summary>Details</summary>
Motivation: 软件系统在现实应用中需要不断进化，包括源代码、构建流水线、文档和问题票等多种 artefacts 的演化。然而，传统的遗留系统现代化面临隐式契约、性能保持和集成演化等实证失败模式。现有大模型成本高，自动化程度与可控性有限，因此需要新的高效、可控且低成本的系统自动化进化方法。

Method: 提出 EvoGraph 框架，将所有软件 artefacts 表示为有类型的有向图，采用专用的小型语言模型（SLM）驱动的学习型变异操作符进行变异，并用多目标适应度选择机制筛选“幸存者”；并支持跨多种编程语言（如.NET、Lisp、COBOL、Java、Python、C 等）的现代化。对比大模型方法，利用 SLM 降低计算成本。

Result: 在三个基准测试上，EvoGraph 能修复 83% 的已知安全漏洞，COBOL 到 Java 翻译达 93% 测试验证等效，文档实时性保证在 2 分钟内；与强基线相比，实验显示延迟降低 40%，新功能上线时间缩短 7 倍。evoGraph 可用于多个语言，实现 82-96% 的语义等效且成本低 90%。

Conclusion: EvoGraph 框架为系统软件 3.0 发展提供了可行路径，实现了系统可持续自我进化和可测控的自动化现代化，特别是在遗留系统现代化的关键难题上具备实用性和先进性。

Abstract: We introduce **EvoGraph**, a framework that enables software systems to
evolve their own source code, build pipelines, documentation, and tickets.
EvoGraph represents every artefact in a typed directed graph, applies learned
mutation operators driven by specialized small language models (SLMs), and
selects survivors with a multi-objective fitness. On three benchmarks, EvoGraph
fixes 83% of known security vulnerabilities, translates COBOL to Java with 93%
functional equivalence (test verified), and maintains documentation freshness
within two minutes. Experiments show a 40% latency reduction and a sevenfold
drop in feature lead time compared with strong baselines. We extend our
approach to **evoGraph**, leveraging language-specific SLMs for modernizing
.NET, Lisp, CGI, ColdFusion, legacy Python, and C codebases, achieving 82-96%
semantic equivalence across languages while reducing computational costs by 90%
compared to large language models. EvoGraph's design responds to empirical
failure modes in legacy modernization, such as implicit contracts, performance
preservation, and integration evolution. Our results suggest a practical path
toward Software 3.0, where systems adapt continuously yet remain under
measurable control.

</details>


### [13] [A Conceptual Model and Methodology for Sustainability-aware, IoT-enhanced Business Processes](https://arxiv.org/abs/2508.05301)
*Victoria Torres Bosch,Ronny Seiger,Manuela Albert Albiol,Antoni Mestre Gascon,Pedro Jose Valderas Aranda*

Main category: cs.SE

TL;DR: 该论文提出了将物联网引入业务流程以提升可持续性的分析框架和结构化方法，突破传统仅限环境维度的限制。通过案例研究，验证了物联网在旅游和医疗领域提升业务流程全方位可持续性的潜力和方法有效性。


<details>
  <summary>Details</summary>
Motivation: 物联网（IoT）实时数据收集和自动化能力正在重塑并提升业务流程（BP），显现出提高可持续性的巨大潜力。然而，目前可持续性研究主要集中于环境方面，要实现全面且持久的影响，则需要系统性方法涵盖环境以外的其他维度。

Method: 提出了一个概念模型和结构化方法，用于系统性分析IoT在衡量和提升业务流程可持续性方面的潜力。该模型正式化地描述了关键可持续性概念，连接了业务流程管理（BPM）与IoT，突出物联网设备如何支持和促进可持续性。该方法指导对现有业务流程的分析，识别优化机会，并实施可持续性导向的、IoT增强的业务流程，同时以旅游和医疗领域实例加以说明。

Result: 构建了业务流程可持续性分析的概念框架和方法论，通过案例验证其可行性和应用价值，展示了IoT技术提升多维度业务可持续性的能力。

Conclusion: 通过将BPM与IoT结合并提出系统性分析模型，可以更全面地识别及实现业务流程的可持续发展，大大扩展了可持续性研究的覆盖范围和实际应用场景。

Abstract: The real-time data collection and automation capabilities offered by the
Internet of Things (IoT) are revolutionizing and transforming Business
Processes (BPs) into IoT-enhanced BPs, showing high potential for improving
sustainability. Although already studied in Business Process Management (BPM),
sustainability research has primarily focused on environmental concerns.
However, achieving a holistic and lasting impact requires a systematic approach
to address sustainability beyond the environmental dimension. This work
proposes a conceptual model and a structured methodology with the goal of
analyzing the potential of IoT to measure and improve the sustainability of
BPs. The conceptual model formally represents key sustainability concepts,
linking BPM and IoT by highlighting how IoT devices support and contribute to
sustainability. The methodology guides the systematic analysis of existing BPs,
identifies opportunities, and implements sustainability-aware, IoT-enhanced
BPs. The approach is illustrated through a running example from the tourism
domain and a case study in healthcare.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [14] [Enhancing Dialogue Annotation with Speaker Characteristics Leveraging a Frozen LLM](https://arxiv.org/abs/2508.04795)
*Thomas Thebaud,Yen-Ju Lu,Matthew Wiesner,Peter Viechnicki,Najim Dehak*

Main category: cs.CL

TL;DR: 本文提出了一种结合音频基础模型和语言模型的对话元数据标注方法，无需微调即可高效、准确地识别说话人属性，且方法结构高效且模块化。


<details>
  <summary>Details</summary>
Motivation: 当前的对话转录流程主要利用大模型提升文本的语法、标点和可读性，但缺乏对说话者属性（如年龄、性别、情感等）元数据的丰富标注，这些信息对于后续分析和应用十分重要。

Method: 将冻结的音频基础模型（如Whisper或WavLM）与冻结的LLAMA语言模型进行结合，通过轻量级、高效的连接器桥接音频与文本表征，无需针对具体任务进行模型微调。部分元数据是全局性的，部分是随时间变化的。

Result: 在说话人属性识别等相关任务上取得了有竞争力的性能，同时保障了模型结构的模块化和运行速度。此外，LLAMA模型甚至能够直接比较x-vector，在某些场景下等错误率(EER)可达到8.8%。

Conclusion: 该方法能够在无需模型微调的情况下，有效地为对话文本添加丰富的说话人属性元数据标签，在准确性和效率之间取得了良好平衡。

Abstract: In dialogue transcription pipelines, Large Language Models (LLMs) are
frequently employed in post-processing to improve grammar, punctuation, and
readability. We explore a complementary post-processing step: enriching
transcribed dialogues by adding metadata tags for speaker characteristics such
as age, gender, and emotion. Some of the tags are global to the entire
dialogue, while some are time-variant. Our approach couples frozen audio
foundation models, such as Whisper or WavLM, with a frozen LLAMA language model
to infer these speaker attributes, without requiring task-specific fine-tuning
of either model. Using lightweight, efficient connectors to bridge audio and
language representations, we achieve competitive performance on speaker
profiling tasks while preserving modularity and speed. Additionally, we
demonstrate that a frozen LLAMA model can compare x-vectors directly, achieving
an Equal Error Rate of 8.8% in some scenarios.

</details>


### [15] [Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization](https://arxiv.org/abs/2508.04796)
*Negar Foroutan,Clara Meister,Debjit Paul,Joel Niklaus,Sina Ahmadi,Antoine Bosselut,Rico Sennrich*

Main category: cs.CL

TL;DR: 传统分词器损害低资源语言，Pariy-aware BPE通过关注最弱语言提升分词公平性，实现更均衡的多语言处理且基本不影响下游表现。


<details>
  <summary>Details</summary>
Motivation: 传统的分词器训练方法基于频率目标，通常偏向于训练数据中占主导地位的语言，导致低资源语言的分词结果更长、形态不合理，甚至出现大量<UNK>占位符。这加剧了不同语言背景用户之间的计算和经济不平等。

Method: 提出了Parity-aware BPE（基于公平性的BPE变体），在每次合并步骤中，最大化当前压缩最差语言的压缩增益，通过牺牲少量全局压缩率，提升跨语言间的分词公平性。

Result: 实验证明，Parity-aware BPE在各语言间获得了更公平的分词长度，对全局压缩率影响可以忽略，并且不会对下游任务中的语言模型性能造成实质性影响。

Conclusion: Parity-aware BPE能够有效提升多语言间的分词公平性，而对整体系统性能影响甚微，是多语言NLP系统中更公平有效的分词方法。

Abstract: Tokenization is the first -- and often least scrutinized -- step of most NLP
pipelines. Standard algorithms for learning tokenizers rely on frequency-based
objectives, which favor languages dominant in the training data and
consequently leave lower-resource languages with tokenizations that are
disproportionately longer, morphologically implausible, or even riddled with
<UNK> placeholders. This phenomenon ultimately amplifies computational and
financial inequalities between users from different language backgrounds. To
remedy this, we introduce Parity-aware Byte Pair Encoding (BPE), a variant of
the widely-used BPE algorithm. At every merge step, Parity-aware BPE maximizes
the compression gain of the currently worst-compressed language, trading a
small amount of global compression for cross-lingual parity. We find
empirically that Parity-aware BPE leads to more equitable token counts across
languages, with negligible impact on global compression rate and no substantial
effect on language-model performance in downstream tasks.

</details>


### [16] [Pitch Accent Detection improves Pretrained Automatic Speech Recognition](https://arxiv.org/abs/2508.04814)
*David Sasu,Natalie Schluter*

Main category: cs.CL

TL;DR: 该论文证明结合音高重音检测模块能显著提升ASR系统表现，音高重音检测F1分数提升41%，ASR词错误率下降28.3%。强调预训练语音模型保留韵律信息的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的自动语音识别（ASR）系统在语音表示学习上已经取得进展，但忽略了韵律特征（如重音），而这些特征对识别效果可能有显著提升。作者希望通过引入韵律特征检测模块，提升ASR系统表现。

Method: 提出联合的ASR与音高重音检测模型，在半监督语音表示基础上，结合音高重音检测模块进行训练，并在有限资源下进行微调。

Result: 音高重音检测组件在相关任务上F1分数提升41%，超越现有方法；在LibriSpeech测试集和有限资源微调条件下，联合训练的ASR系统词错误率（WER）降低了28.3%。

Conclusion: 整合和重学韵律信息（比如重音），可以显著提升语音预训练模型在ASR任务中的表现。

Abstract: We show the performance of Automatic Speech Recognition (ASR) systems that
use semi-supervised speech representations can be boosted by a complimentary
pitch accent detection module, by introducing a joint ASR and pitch accent
detection model. The pitch accent detection component of our model achieves a
significant improvement on the state-of-the-art for the task, closing the gap
in F1-score by 41%. Additionally, the ASR performance in joint training
decreases WER by 28.3% on LibriSpeech, under limited resource fine-tuning. With
these results, we show the importance of extending pretrained speech models to
retain or re-learn important prosodic cues such as pitch accent.

</details>


### [17] [Persistent Instability in LLM's Personality Measurements: Effects of Scale, Reasoning, and Conversation History](https://arxiv.org/abs/2508.04826)
*Tommaso Tosato,Saskia Helbling,Yorguin-Jose Mantilla-Ramos,Mahmood Hegazy,Alberto Tosato,David John Lemay,Irina Rish,Guillaume Dumas*

Main category: cs.CL

TL;DR: PERSIST框架评估显示，主流开源LLM在人格一致性上极不稳定，常用的提升稳定性方法也无效，表明基于人格的安全对齐策略在现有LLM上并不可行。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）在部署时需要行为上的一致性，尤其是应用于安全关键场景。然而，LLMs 具有类似人格的特征，但这些特征的稳定性和规律性还未被充分理解。作者希望系统性地评估现代LLMs在人格测量中的表现，并检验人格一致性假设。

Method: 作者提出了PERSIST评估框架，对25种以上开源LLM（参数规模1B到671B），进行了系统性测试。方法包括使用传统（BFI-44，SD3）和针对LLM改编的人格量表，围绕提问顺序、问题措辞、角色扮演和推理方式进行扰动和对比，总计收集了50万余条模型回复。

Result: 研究发现: 1）即使是400B以上参数模型，输出的人格相关表现仍有较大变异性（标准差 > 0.4）；2）仅仅通过更换提问顺序就可以导致人格测量结果20％的变化；3）一些被期望可以增强一致性的干预（如链式推理、详细人格设定、加入对话历史）反而会增加不稳定性；4）LLM专用的人格量表与传统人类量表具有同等的不稳定性，说明这种不一致更多来自于架构本身而不是测量工具。

Conclusion: 当前大型语言模型在行为表现的一致性（如人格）上存在根本性问题，多种常用提高一致性的标准方法均未能解决或甚至加剧了这种不稳定。因此，用人格或行为测量来对模型进行安全对齐对当前LLM架构而言可能并不适用。

Abstract: Large language models require consistent behavioral patterns for safe
deployment, yet their personality-like traits remain poorly understood. We
present PERSIST (PERsonality Stability in Synthetic Text), a comprehensive
evaluation framework testing 25+ open-source models (1B-671B parameters) across
500,000+ responses. Using traditional (BFI-44, SD3) and novel LLM-adapted
personality instruments, we systematically vary question order, paraphrasing,
personas, and reasoning modes. Our findings challenge fundamental deployment
assumptions: (1) Even 400B+ models exhibit substantial response variability (SD
> 0.4); (2) Minor prompt reordering alone shifts personality measurements by up
to 20%; (3) Interventions expected to stabilize behavior, such as
chain-of-thought reasoning, detailed personas instruction, inclusion of
conversation history, can paradoxically increase variability; (4) LLM-adapted
instruments show equal instability to human-centric versions, confirming
architectural rather than translational limitations. This persistent
instability across scales and mitigation strategies suggests current LLMs lack
the foundations for genuine behavioral consistency. For safety-critical
applications requiring predictable behavior, these findings indicate that
personality-based alignment strategies may be fundamentally inadequate.

</details>


### [18] [RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory](https://arxiv.org/abs/2508.04903)
*Jun Liu,Zhenglun Kong,Changdi Yang,Fan Yang,Tianqi Li,Peiyan Dong,Joannah Nanjekye,Hao Tang,Geng Yuan,Wei Niu,Wenbin Zhang,Pu Zhao,Xue Lin,Dong Huang,Yanzhi Wang*

Main category: cs.CL

TL;DR: 本文提出了一种高效的多智能体大模型上下文路由框架RCR-Router，通过动态分配相关记忆片段实现token节约和答案质量提升，实验结果验证了其实用性。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体LLM系统中的上下文路由方式往往导致 token 浪费、记忆冗余暴露、以及在多轮交互中的适应性不足。因此需要更高效且具适应性的路由机制，以提升协作效率并降低资源消耗。

Method: 提出了RCR-Router框架，实现基于角色和任务阶段的动态上下文路由，通过轻量打分策略选择相关记忆，且严格遵守 token 限制。记忆在多轮交互中逐步整合和优化，并引入了新的答案质量评分（Answer Quality Score）指标来评估模型生成的解释质量。

Result: 在HotPotQA、MuSiQue 和 2WikiMultihop 三个多跳问答基准测试上，RCR-Router 相较传统方法，token使用量降低最多可达30%，答案质量则有所提升或保持。

Conclusion: RCR-Router 能够有效减少 token 使用量，同时提升或保持答案质量，展现了结构化记忆路由和注重输出质量评估在提升可扩展多智能体大语言模型系统中的重要性。

Abstract: Multi-agent large language model (LLM) systems have shown strong potential in
complex reasoning and collaborative decision-making tasks. However, most
existing coordination schemes rely on static or full-context routing
strategies, which lead to excessive token consumption, redundant memory
exposure, and limited adaptability across interaction rounds. We introduce
RCR-Router, a modular and role-aware context routing framework designed to
enable efficient, adaptive collaboration in multi-agent LLMs. To our knowledge,
this is the first routing approach that dynamically selects semantically
relevant memory subsets for each agent based on its role and task stage, while
adhering to a strict token budget. A lightweight scoring policy guides memory
selection, and agent outputs are iteratively integrated into a shared memory
store to facilitate progressive context refinement. To better evaluate model
behavior, we further propose an Answer Quality Score metric that captures
LLM-generated explanations beyond standard QA accuracy. Experiments on three
multi-hop QA benchmarks -- HotPotQA, MuSiQue, and 2WikiMultihop -- demonstrate
that RCR-Router reduces token usage (up to 30%) while improving or maintaining
answer quality. These results highlight the importance of structured memory
routing and output-aware evaluation in advancing scalable multi-agent LLM
systems.

</details>


### [19] [I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations](https://arxiv.org/abs/2508.04939)
*Julia Kharchenko,Tanya Roosta,Aman Chadha,Chirag Shah*

Main category: cs.CL

TL;DR: 本文提出了评估LLM对语言隐性区分（如性别、阶层语气等）偏见的基准，发现模型普遍对委婉表达存在较大分数惩罚，为AI公平性评测提供了基础工具。


<details>
  <summary>Details</summary>
Motivation: LLM在生成自然语言时，无意间可能通过微妙的语言特征（如措辞、语气词等）透露出用户的社会背景信息，造成自动化评价或筛选中的不公平。因此，亟需建立系统性基准，用于检测和衡量这类偏见，推动AI决策的公平性。

Method: 作者设计了一个包含100组经过验证的问答对，通过模拟面试情景，生成有控制的语言变体，保持语义等价，仅更改特定的语言现象，并用这些数据评测LLM的输出状况，专注识别和量化与性别、社会阶层和地域有关的语言隐性线索带来的系统性偏见。

Result: 结果显示，即便语义内容等价，带有'hedging'（委婉语气）的回答受到系统性惩罚，平均评分比无hedging语言降低25.6%；该基准还能精确识别不同模型具体的偏见表现。

Conclusion: 本文建立了一个基础框架，可以检测和量化大语言模型（LLM）在语言细节上的偏见，对AI系统中的语言歧视进行精确测量。

Abstract: This paper introduces a comprehensive benchmark for evaluating how Large
Language Models (LLMs) respond to linguistic shibboleths: subtle linguistic
markers that can inadvertently reveal demographic attributes such as gender,
social class, or regional background. Through carefully constructed interview
simulations using 100 validated question-response pairs, we demonstrate how
LLMs systematically penalize certain linguistic patterns, particularly hedging
language, despite equivalent content quality. Our benchmark generates
controlled linguistic variations that isolate specific phenomena while
maintaining semantic equivalence, which enables the precise measurement of
demographic bias in automated evaluation systems. We validate our approach
along multiple linguistic dimensions, showing that hedged responses receive
25.6% lower ratings on average, and demonstrate the benchmark's effectiveness
in identifying model-specific biases. This work establishes a foundational
framework for detecting and measuring linguistic discrimination in AI systems,
with broad applications to fairness in automated decision-making contexts.

</details>


### [20] [Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity with Sense Clustering](https://arxiv.org/abs/2508.04945)
*Louie Hong Yao,Nicholas Jarvis,Tianyu Jiang*

Main category: cs.CL

TL;DR: 本文提出通过动词义集群为视觉活动识别系统建立更具鲁棒性的评估框架，以弥补传统评估忽略语义歧义和多样解读的不足，经数据和人评验证后发现新方法更合理、更贴近人类认知。


<details>
  <summary>Details</summary>
Motivation: 单一标准答案的评估方法无法充分反映描述视觉活动时动词语义和图片解读上的歧义，从而导致对模型表现的评价不完整。

Method: 提出了视觉-语言集群框架，通过动词义集群来进行评估，而不是依赖单一标准答案。

Result: 在imSitu数据集上的分析显示，每幅图像平均对应2.8个动词义集群，不同集群代表图像的不同解读视角。集群评估方法与传统方法对多个模型评估对比后，发现集群评估与人类判断一致性更高，评估结果更细致、合理。

Conclusion: 基于集群的评估方法比传统的精确匹配评估更能贴合人类判断，能更全面地评价视觉活动识别模型表现。

Abstract: Evaluating visual activity recognition systems is challenging due to inherent
ambiguities in verb semantics and image interpretation. When describing actions
in images, synonymous verbs can refer to the same event (e.g., brushing vs.
grooming), while different perspectives can lead to equally valid but distinct
verb choices (e.g., piloting vs. operating). Standard exact-match evaluation,
which relies on a single gold answer, fails to capture these ambiguities,
resulting in an incomplete assessment of model performance. To address this, we
propose a vision-language clustering framework that constructs verb sense
clusters, providing a more robust evaluation. Our analysis of the imSitu
dataset shows that each image maps to an average of 2.8 sense clusters, with
each cluster representing a distinct perspective of the image. We evaluate
multiple activity recognition models and compare our cluster-based evaluation
with standard evaluation methods. Additionally, our human alignment analysis
suggests that the cluster-based evaluation better aligns with human judgements,
offering a more nuanced assessment of model performance.

</details>


### [21] [A Multi-Stage Large Language Model Framework for Extracting Suicide-Related Social Determinants of Health](https://arxiv.org/abs/2508.05003)
*Song Wang,Yishu Wei,Haotian Ma,Max Lovitt,Kelly Deng,Yuan Meng,Zihan Xu,Jingze Zhang,Yunyu Xiao,Ying Ding,Xuhai Xu,Joydeep Ghosh,Yifan Peng*

Main category: cs.CL

TL;DR: 作者提出多阶段大语言模型框架，显著提升从文本中抽取自杀相关健康社会决定因素的准确性和可解释性。相比主流语言模型，方案在性能和推理成本上更优，有助于实现早期风险筛查和更有效的自杀预防策略。


<details>
  <summary>Details</summary>
Motivation: 自杀事件的早期干预和预防，需要了解健康的社会决定因素（SDoH）。目前主流数据驱动方法面临如长尾分布、分析自杀发生前关键压力源和模型可解释性有限等挑战。

Method: 提出了一种多阶段大语言模型框架，从非结构化文本中提升SDoH要素抽取能力。与BioBERT、GPT-3.5-turbo等预训练语言模型，以及DeepSeek-R1等推理模型进行了对比。此外，评估了模型解释功能对于快速、准确人工标注SDoH的帮助，并进行了自动化比较和用户试点研究。

Result: 多阶段框架在SDoH抽取任务和细粒度相关环境检索中均取得性能提升。针对任务微调的小型模型，在效果和推理成本上能与更大模型媲美甚至更好。多阶段设计提升了抽取效果，同时增强可解释性。

Conclusion: 该方法提升了从非结构化文本中抽取自杀相关SDoH的准确性和透明性，有助于早期筛查高风险个体，并推动更有效的预防策略实施。

Abstract: Background: Understanding social determinants of health (SDoH) factors
contributing to suicide incidents is crucial for early intervention and
prevention. However, data-driven approaches to this goal face challenges such
as long-tailed factor distributions, analyzing pivotal stressors preceding
suicide incidents, and limited model explainability. Methods: We present a
multi-stage large language model framework to enhance SDoH factor extraction
from unstructured text. Our approach was compared to other state-of-the-art
language models (i.e., pre-trained BioBERT and GPT-3.5-turbo) and reasoning
models (i.e., DeepSeek-R1). We also evaluated how the model's explanations help
people annotate SDoH factors more quickly and accurately. The analysis included
both automated comparisons and a pilot user study. Results: We show that our
proposed framework demonstrated performance boosts in the overarching task of
extracting SDoH factors and in the finer-grained tasks of retrieving relevant
context. Additionally, we show that fine-tuning a smaller, task-specific model
achieves comparable or better performance with reduced inference costs. The
multi-stage design not only enhances extraction but also provides intermediate
explanations, improving model explainability. Conclusions: Our approach
improves both the accuracy and transparency of extracting suicide-related SDoH
from unstructured texts. These advancements have the potential to support early
identification of individuals at risk and inform more effective prevention
strategies.

</details>


### [22] [Dialogues Aspect-based Sentiment Quadruple Extraction via Structural Entropy Minimization Partitioning](https://arxiv.org/abs/2508.05023)
*Kun Peng,Cong Cao,Hao Peng,Zhifeng Hao,Lei Jiang,Kongjing Gu,Yanbing Liu,Philip S. Yu*

Main category: cs.CL

TL;DR: 本文针对对话四元组抽取噪声问题，提出用结构熵分割对话子结构，并用分步抽取框架实现高效且更精确的四元组提取，实验效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前对话四元组抽取方法通常在整个对话级别进行词关系的学习，忽略了对话内部存在多个语义独立子对话，导致噪声增加。单靠回复关系分割子对话效果不佳。

Method: 提出通过结构熵最小化算法对对话进行子对话分割，最大程度区分相关与无关语句。之后采用两步框架，先在话语级提取情感要素，再在子对话级进行四元组匹配。

Result: 所提方法在DiaASQ任务中达到了业界最优，并显著降低了计算成本。

Conclusion: 对话结构细粒度划分结合分步抽取极大提升了四元组抽取效果和效率。

Abstract: Dialogues Aspect-based Sentiment Quadruple Extraction (DiaASQ) aims to
extract all target-aspect-opinion-sentiment quadruples from a given
multi-round, multi-participant dialogue. Existing methods typically learn word
relations across entire dialogues, assuming a uniform distribution of sentiment
elements. However, we find that dialogues often contain multiple semantically
independent sub-dialogues without clear dependencies between them. Therefore,
learning word relationships across the entire dialogue inevitably introduces
additional noise into the extraction process. To address this, our method
focuses on partitioning dialogues into semantically independent sub-dialogues.
Achieving completeness while minimizing these sub-dialogues presents a
significant challenge. Simply partitioning based on reply relationships is
ineffective. Instead, we propose utilizing a structural entropy minimization
algorithm to partition the dialogues. This approach aims to preserve relevant
utterances while distinguishing irrelevant ones as much as possible.
Furthermore, we introduce a two-step framework for quadruple extraction: first
extracting individual sentiment elements at the utterance level, then matching
quadruples at the sub-dialogue level. Extensive experiments demonstrate that
our approach achieves state-of-the-art performance in DiaASQ with much lower
computational costs.

</details>


### [23] [Evaluation of LLMs in AMR Parsing](https://arxiv.org/abs/2508.05028)
*Shu Han Ho*

Main category: cs.CL

TL;DR: 本文验证了通过直接微调主流decoder-only大语言模型实现AMR解析的可行性。这一方案结构简单，性能却可达到与最先进复杂模型相当的水平，为AMR解析方法提供了新方向。


<details>
  <summary>Details</summary>
Motivation: AMR解析是一项重要的语义表示任务，传统上需要复杂的模型。本文旨在探索通过直接微调decoder-only大语言模型提升AMR解析的可行性，简化模型结构。

Method: 作者对四种不同架构的解码器大语言模型（Phi 3.5、Gemma 2、LLaMA 3.2和DeepSeek R1 LLaMA Distilled）进行微调，在标准的LDC2020T02 Gold AMR3.0测试集上综合评估其效果。

Result: 微调后的decoder-only LLMs性能可与复杂的最新AMR解析器媲美。LLaMA 3.2模型表现尤为突出，SMATCH F1分数为0.804，与市面上的强大模型APT + Silver持平，接近Graphene Smatch（0.854）。LLaMA 3.2在语义性能领先，Phi 3.5在结构有效性方面表现最佳。

Conclusion: 直接微调decoder-only大语言模型是一种高效、有效的AMR解析途径，可与当前复杂SOTA解析器抗衡。特别是LLaMA 3.2和Phi 3.5模型在语义和结构解析维度分别表现出色。

Abstract: Meaning Representation (AMR) is a semantic formalism that encodes sentence
meaning as rooted, directed, acyclic graphs, where nodes represent concepts and
edges denote semantic relations. Finetuning decoder only Large Language Models
(LLMs) represent a promising novel straightfoward direction for AMR parsing.
This paper presents a comprehensive evaluation of finetuning four distinct LLM
architectures, Phi 3.5, Gemma 2, LLaMA 3.2, and DeepSeek R1 LLaMA Distilled
using the LDC2020T02 Gold AMR3.0 test set. Our results have shown that
straightfoward finetuning of decoder only LLMs can achieve comparable
performance to complex State of the Art (SOTA) AMR parsers. Notably, LLaMA 3.2
demonstrates competitive performance against SOTA AMR parsers given a
straightforward finetuning approach. We achieved SMATCH F1: 0.804 on the full
LDC2020T02 test split, on par with APT + Silver (IBM) at 0.804 and approaching
Graphene Smatch (MBSE) at 0.854. Across our analysis, we also observed a
consistent pattern where LLaMA 3.2 leads in semantic performance while Phi 3.5
excels in structural validity.

</details>


### [24] [Align, Don't Divide: Revisiting the LoRA Architecture in Multi-Task Learning](https://arxiv.org/abs/2508.05078)
*Jinda Liu,Bo Cheng,Yi Chang,Yuan Wu*

Main category: cs.CL

TL;DR: Align-LoRA通过增强共享表征和对齐loss，在多任务参数高效微调中有显著优势，挑战了任务特异性结构的主流做法。


<details>
  <summary>Details</summary>
Motivation: 在大模型的多任务学习中，现有的主流方法倾向于使用结构多样化的LoRA多适配器或多头架构，旨在捕获任务特定知识，但这种复杂性可能并非必要。

Method: 作者提出Align-LoRA：在单一LoRA适配器中引入对任务表征显式对齐的loss，从而强化任务间共享表征的学习；并通过实验验证了多头结构的高相似度和单一高秩LoRA的有效性。

Result: 简化的多头架构（头间高相似度）优于复杂的多适配器或多头系统；单一高秩LoRA也能取得高度竞争力；Align-LoRA在多任务学习下超越全部基线，表现最佳。

Conclusion: 多任务泛化不依赖于任务特异性特征的隔离，而取决于高质量共享表征的学习；Align-LoRA为多任务LLMs微调提供了更简单高效的新范式。

Abstract: Parameter-Efficient Fine-Tuning (PEFT) is essential for adapting Large
Language Models (LLMs). In practice, LLMs are often required to handle a
diverse set of tasks from multiple domains, a scenario naturally addressed by
multi-task learning (MTL). Within this MTL context, a prevailing trend involves
LoRA variants with multiple adapters or heads, which advocate for structural
diversity to capture task-specific knowledge. Our findings present a direct
challenge to this paradigm. We first show that a simplified multi-head
architecture with high inter-head similarity substantially outperforms complex
multi-adapter and multi-head systems. This leads us to question the
multi-component paradigm itself, and we further demonstrate that a standard
single-adapter LoRA, with a sufficiently increased rank, also achieves highly
competitive performance. These results lead us to a new hypothesis: effective
MTL generalization hinges on learning robust shared representations, not
isolating task-specific features. To validate this, we propose Align-LoRA,
which incorporates an explicit loss to align task representations within the
shared adapter space. Experiments confirm that Align-LoRA significantly
surpasses all baselines, establishing a simpler yet more effective paradigm for
adapting LLMs to multiple tasks. The code is available at
https://github.com/jinda-liu/Align-LoRA.

</details>


### [25] [Multimodal Fact Checking with Unified Visual, Textual, and Contextual Representations](https://arxiv.org/abs/2508.05097)
*Aditya Kishore,Gaurav Kumar,Jasabanta Patro*

Main category: cs.CL

TL;DR: 针对文本和图片混合的虚假信息，作者提出MultiCheck框架，通过多模态专用编码器、融合模块及对比学习，实现更准确的事实核查，在权威数据集上成绩显著。


<details>
  <summary>Details</summary>
Motivation: 随着多模态虚假信息（即同时包含文本和图片的虚假声明）增加，依赖文本证据的事实核查系统面临显著挑战。

Method: 提出了一个统一的细粒度多模态事实核查框架MultiCheck，集成文本和图像专用编码器，并使用融合模块捕捉跨模态关系，通过元素级交互实现。此外，分类头预测声明的真实性，配合对比学习目标以促进声明与证据对的语义一致性。

Result: 在Factify 2数据集上，MultiCheck取得加权F1分数0.84，显著优于基线模型。

Conclusion: 显式多模态推理能够有效提升事实核查性能，证明了该方法在复杂真实场景下的可扩展性和可解释性潜力。

Abstract: The growing rate of multimodal misinformation, where claims are supported by
both text and images, poses significant challenges to fact-checking systems
that rely primarily on textual evidence. In this work, we have proposed a
unified framework for fine-grained multimodal fact verification called
"MultiCheck", designed to reason over structured textual and visual signals.
Our architecture combines dedicated encoders for text and images with a fusion
module that captures cross-modal relationships using element-wise interactions.
A classification head then predicts the veracity of a claim, supported by a
contrastive learning objective that encourages semantic alignment between
claim-evidence pairs in a shared latent space. We evaluate our approach on the
Factify 2 dataset, achieving a weighted F1 score of 0.84, substantially
outperforming the baseline. These results highlight the effectiveness of
explicit multimodal reasoning and demonstrate the potential of our approach for
scalable and interpretable fact-checking in complex, real-world scenarios.

</details>


### [26] [BEE-RAG: Balanced Entropy Engineering for Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05100)
*Yuhao Wang,Ruiyang Ren,Yucheng Wang,Jing Liu,Wayne Xin Zhao,Hua Wu,Haifeng Wang*

Main category: cs.CL

TL;DR: 本文提出BEE-RAG，通过熵平衡机制和新颖的推理与微调策略，显著提升了RAG在长上下文条件下的表现。


<details>
  <summary>Details</summary>
Motivation: RAG用于补充大语言模型（LLM）知识不足，但检索内容多导致上下文过长，存在熵膨胀和注意力稀释这两个性能瓶颈。作者希望解决上下文长度变长带来的性能下降问题。

Method: 提出了一个平衡熵工程化RAG（BEE-RAG）框架，通过保持熵不变性来改善RAG系统对长上下文的适应性，并重构注意力机制以解耦注意力敏感度与上下文长度。同时引入了多重要性估计的零样本推理策略和一种参数高效的自适应微调机制。

Result: 实验证明该框架在多个RAG任务中有效提升了系统性能，实现了稳定的熵水平与更佳的注意力分配。

Conclusion: BEE-RAG在解决长上下文带来的熵膨胀和注意力稀释问题上表现优异，并显著增强了RAG系统的鲁棒性和适应性。

Abstract: With the rapid advancement of large language models (LLMs),
retrieval-augmented generation (RAG) has emerged as a critical approach to
supplement the inherent knowledge limitations of LLMs. However, due to the
typically large volume of retrieved information, RAG tends to operate with long
context lengths. From the perspective of entropy engineering, we identify
unconstrained entropy growth and attention dilution due to long retrieval
context as significant factors affecting RAG performance. In this paper, we
propose the balanced entropy-engineered RAG (BEE-RAG) framework, which improves
the adaptability of RAG systems to varying context lengths through the
principle of entropy invariance. By leveraging balanced context entropy to
reformulate attention dynamics, BEE-RAG separates attention sensitivity from
context length, ensuring a stable entropy level. Building upon this, we
introduce a zero-shot inference strategy for multi-importance estimation and a
parameter-efficient adaptive fine-tuning mechanism to obtain the optimal
balancing factor for different settings. Extensive experiments across multiple
RAG tasks demonstrate the effectiveness of BEE-RAG.

</details>


### [27] [Attention Basin: Why Contextual Position Matters in Large Language Models](https://arxiv.org/abs/2508.05128)
*Zihao Yi,Delong Zeng,Zhenqing Ling,Haohao Luo,Zhe Xu,Wei Liu,Jian Luan,Wanxia Cao,Ying Shen*

Main category: cs.CL

TL;DR: 大语言模型更关注输入的首尾。作者提出AttnRank方法重排序输入，把重要内容放到模型最在意的位置，提升了多种大模型的效果，且无需训练或修改模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的输入信息在不同位置会影响模型的表现，但其背后机制不清楚。论文动机是探究这种称为位置偏置（positional bias）的现象及其影响。

Method: 提出了一种两阶段的注意力驱动重排序框架（AttnRank）：首先用小规模校准集估计模型对于不同输入位置的注意力分布，然后根据分布结果重新排列关键内容，使其位于模型注意力集中的位置。该方法无需模型训练、参数修改，计算成本低，且对模型结构无关。

Result: AttnRank在多跳问答和少样本上下文学习任务上，对10种不同结构与规模的大语言模型均带来显著性能提升。

Conclusion: 通过研究发现，大模型习惯性更关注序列首尾的信息，忽略中间内容。基于这一现象，提出的AttnRank可以通过调整输入顺序，让关键内容处于高关注位置，从而提升不同大模型的下游任务表现。

Abstract: The performance of Large Language Models (LLMs) is significantly sensitive to
the contextual position of information in the input. To investigate the
mechanism behind this positional bias, our extensive experiments reveal a
consistent phenomenon we term the attention basin: when presented with a
sequence of structured items (e.g., retrieved documents or few-shot examples),
models systematically assign higher attention to the items at the beginning and
end of the sequence, while neglecting those in the middle. Crucially, our
analysis further reveals that allocating higher attention to critical
information is key to enhancing model performance. Based on these insights, we
introduce Attention-Driven Reranking (AttnRank), a two-stage framework that (i)
estimates a model's intrinsic positional attention preferences using a small
calibration set, and (ii) reorders retrieved documents or few-shot examples to
align the most salient content with these high-attention positions. AttnRank is
a model-agnostic, training-free, and plug-and-play method with minimal
computational overhead. Experiments on multi-hop QA and few-shot in-context
learning tasks demonstrate that AttnRank achieves substantial improvements
across 10 large language models of varying architectures and scales, without
modifying model parameters or training procedures.

</details>


### [28] [Towards Assessing Medical Ethics from Knowledge to Practice](https://arxiv.org/abs/2508.05132)
*Chang Hong,Minghao Wu,Qingying Xiao,Yuchi Wang,Xiang Wan,Guangjun Yu,Benyou Wang,Yan Hu*

Main category: cs.CL

TL;DR: 本文提出了PrinciplismQA基准，系统测评大模型的医疗伦理推理能力。实验发现模型伦理知识与实际应用存在显著差距，尤其是在动态应用伦理原则时表现不足。前沿闭源模型效果最佳，医疗领域微调有所改善，但总体仍需更好地与医学伦理知识对齐。该基准为推动更负责任的医疗AI提供了诊断工具。


<details>
  <summary>Details</summary>
Motivation: 当前医疗领域对大模型伦理能力评估不足，迫切需要系统性工具来衡量模型在医疗伦理推理上的表现，推动更负责任和均衡的医疗AI发展。

Method: 提出PrinciplismQA基准，包括3648个多项选择与开放性问题，由医学专家和权威教材验证，用于系统评估大模型伦理推理能力。

Result: 闭源前沿模型表现较优，医疗领域微调能提升伦理能力，但大多数模型尤其在“行善”原则上表现弱，PrinciplismQA能有效诊断和量化具体伦理弱点。

Conclusion: 现有主流大模型存在医疗伦理知识与实际应用之间的差距，特别是在具体情境下应用伦理原则方面表现不足，需进一步对齐医疗伦理知识。

Abstract: The integration of large language models into healthcare necessitates a
rigorous evaluation of their ethical reasoning, an area current benchmarks
often overlook. We introduce PrinciplismQA, a comprehensive benchmark with
3,648 questions designed to systematically assess LLMs' alignment with core
medical ethics. Grounded in Principlism, our benchmark features a high-quality
dataset. This includes multiple-choice questions curated from authoritative
textbooks and open-ended questions sourced from authoritative medical ethics
case study literature, all validated by medical experts. Our experiments reveal
a significant gap between models' ethical knowledge and their practical
application, especially in dynamically applying ethical principles to
real-world scenarios. Most LLMs struggle with dilemmas concerning Beneficence,
often over-emphasizing other principles. Frontier closed-source models, driven
by strong general capabilities, currently lead the benchmark. Notably, medical
domain fine-tuning can enhance models' overall ethical competence, but further
progress requires better alignment with medical ethical knowledge.
PrinciplismQA offers a scalable framework to diagnose these specific ethical
weaknesses, paving the way for more balanced and responsible medical AI.

</details>


### [29] [ATLANTIS at SemEval-2025 Task 3: Detecting Hallucinated Text Spans in Question Answering](https://arxiv.org/abs/2508.05179)
*Catherine Kobus,François Lancelot,Marion-Cécile Martin,Nawal Ould Amer*

Main category: cs.CL

TL;DR: 本文提出了多种用于检测问答系统中幻觉文本片段的方法，结合上下文、微调大模型和提示工程，取得了优异的评测排名，显示了综合手段在提升LLM可靠性方面的重要性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言生成中取得进展，但容易生成虚假或误导性内容（即“幻觉”），需要更加有效的方法来检测和缓解幻觉文本。

Method: 结合有无外部上下文的方法，采用少样本提示（few-shot prompting）、基于令牌级分类和在合成数据上微调LLM的方法来检测问答系统中的幻觉文本片段。

Result: 所提出方法在西班牙语任务中取得最高排名，在英语和德语任务中也获得了有竞争力的表现。

Conclusion: 合理整合相关上下文信息，有助于缓解LLM生成的幻觉现象。微调模型和提示工程在幻觉检测中展现了巨大潜力。

Abstract: This paper presents the contributions of the ATLANTIS team to SemEval-2025
Task 3, focusing on detecting hallucinated text spans in question answering
systems. Large Language Models (LLMs) have significantly advanced Natural
Language Generation (NLG) but remain susceptible to hallucinations, generating
incorrect or misleading content. To address this, we explored methods both with
and without external context, utilizing few-shot prompting with a LLM,
token-level classification or LLM fine-tuned on synthetic data. Notably, our
approaches achieved top rankings in Spanish and competitive placements in
English and German. This work highlights the importance of integrating relevant
context to mitigate hallucinations and demonstrate the potential of fine-tuned
models and prompt engineering.

</details>


### [30] [Resource-Limited Joint Multimodal Sentiment Reasoning and Classification via Chain-of-Thought Enhancement and Distillation](https://arxiv.org/abs/2508.05234)
*Haonan Shangguan,Xiaocui Yang,Shi Feng,Daling Wang,Yifei Zhang,Ge Yu*

Main category: cs.CL

TL;DR: 提出 MulCoT-RD 轻量模型，采用多模态链式推理蒸馏，能在资源有限下实现多模态情感推理与分类，性能强、泛化与可解释性优。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多依赖参数庞大的（多模态）大语言模型，难以在资源有限场景下部署，并忽略了自主的多模态情感推理生成。为此，作者关注在资源受限环境下的联合多模态情感推理与分类任务（JMSRC），并寻求轻量化解决方案。

Method: 提出了 MulCoT-RD 模型，采用“教师-助理-学生”蒸馏范式。首先用高性能多模态大语言模型（MLLM）生成推理数据集，训练中型助理模型进行多任务学习，最终联合训练轻量学生模型，实现高效的多模态情感推理生成与分类。

Result: 在四个公开数据集上，MulCoT-RD 仅用 3B 参数，在 JMSRC 任务上取得了强劲的表现，同时具备良好的泛化性和更强的可解释性。

Conclusion: MulCoT-RD 仅用 3B 参数就在资源受限环境下实现了强大的联合多模态情感推理与分类（JMSRC）表现，具有良好的泛化能力与可解释性。

Abstract: The surge in rich multimodal content on social media platforms has greatly
advanced Multimodal Sentiment Analysis (MSA), with Large Language Models (LLMs)
further accelerating progress in this field. Current approaches primarily
leverage the knowledge and reasoning capabilities of parameter-heavy
(Multimodal) LLMs for sentiment classification, overlooking autonomous
multimodal sentiment reasoning generation in resource-constrained environments.
Therefore, we focus on the Resource-Limited Joint Multimodal Sentiment
Reasoning and Classification task, JMSRC, which simultaneously performs
multimodal sentiment reasoning chain generation and sentiment classification
only with a lightweight model. We propose a Multimodal Chain-of-Thought
Reasoning Distillation model, MulCoT-RD, designed for JMSRC that employs a
"Teacher-Assistant-Student" distillation paradigm to address deployment
constraints in resource-limited environments. We first leverage a
high-performance Multimodal Large Language Model (MLLM) to generate the initial
reasoning dataset and train a medium-sized assistant model with a multi-task
learning mechanism. A lightweight student model is jointly trained to perform
efficient multimodal sentiment reasoning generation and classification.
Extensive experiments on four datasets demonstrate that MulCoT-RD with only 3B
parameters achieves strong performance on JMSRC, while exhibiting robust
generalization and enhanced interpretability.

</details>


### [31] [Pruning Large Language Models by Identifying and Preserving Functional Networks](https://arxiv.org/abs/2508.05239)
*Yiheng Liu,Junhao Ning,Sichen Xia,Xiaohui Gao,Ning Qiang,Bao Ge,Junwei Han,Xintao Hu*

Main category: cs.CL

TL;DR: 本文提出了一种受人脑功能网络启发的LLM结构化剪枝方法，通过保留关键功能网络和神经元，实现高效剪枝，且性能优于传统重要性评估方法。


<details>
  <summary>Details</summary>
Motivation: 结构化剪枝技术在压缩大型语言模型（LLM）以降低GPU内存消耗和加速推理速度方面具有重要价值。然而，现有方法主要依赖结构单元重要性评估，忽略了人工神经元之间的互动和协作，导致模型功能结构被破坏，影响剪枝性能。

Method: 受人脑功能神经网络与人工神经网络相似性的启发，作者将LLM视为数字大脑，通过分解LLM为功能网络（类似于神经影像学中的功能脑网络），并保留这些功能网络中的关键神经元进行剪枝。

Result: 实验结果显示该方法能够有效识别和定位LLM中的功能网络及关键神经元，实现高效的模型剪枝。

Conclusion: 通过针对LLM功能网络进行结构化剪枝，显著缓解了因忽略神经元协作带来的性能下降，提升了模型精简后的推理效率。

Abstract: Structured pruning is one of the representative techniques for compressing
large language models (LLMs) to reduce GPU memory consumption and accelerate
inference speed. It offers significant practical value in improving the
efficiency of LLMs in real-world applications. Current structured pruning
methods typically rely on assessment of the importance of the structure units
and pruning the units with less importance. Most of them overlooks the
interaction and collaboration among artificial neurons that are crucial for the
functionalities of LLMs, leading to a disruption in the macro functional
architecture of LLMs and consequently a pruning performance degradation.
Inspired by the inherent similarities between artificial neural networks and
functional neural networks in the human brain, we alleviate this challenge and
propose to prune LLMs by identifying and preserving functional networks within
LLMs in this study. To achieve this, we treat an LLM as a digital brain and
decompose the LLM into functional networks, analogous to identifying functional
brain networks in neuroimaging data. Afterwards, an LLM is pruned by preserving
the key neurons within these functional networks. Experimental results
demonstrate that the proposed method can successfully identify and locate
functional networks and key neurons in LLMs, enabling efficient model pruning.
Our code is available at https://github.com/WhatAboutMyStar/LLM_ACTIVATION.

</details>


### [32] [CodeBoost: Boosting Code LLMs by Squeezing Knowledge from Code Snippets with RL](https://arxiv.org/abs/2508.05242)
*Sijie Wang,Quanjiang Guo,Kai Zhao,Yawei Zhang,Xin Li,Xiang Li,Siqi Li,Rui She,Shangshu Yu,Wee Peng Tay*

Main category: cs.CL

TL;DR: 本文提出CodeBoost框架创新性地利用代码片段，而非依赖人工指令，提升代码大语言模型的性能，实验证实其有效且易于扩展。


<details>
  <summary>Details</summary>
Motivation: 现有的代码大语言模型（LLMs）在进行强化学习后训练时，依赖于人工标注的“指令-答案”对。但高质量代码指令的人工收集费时费力且难以规模化，成为提升代码LLM性能的瓶颈。而代码片段在网络上随处可得，因此如何充分利用代码片段进行训练值得研究。

Method: 提出CodeBoost后训练框架，仅利用大量现成代码片段（不依赖人工指令）增强代码LLMs。方法包含：最大团筛选用于多样且代表性的训练语料；双向预测（正向、反向）；错误感知预测（融合正确和错误输出）；异构增强（提升训练分布多样性和代码语义丰富性）；异构奖励（结合格式正确性、执行成功与失败等多样反馈）。

Result: 多项代码大模型和基准测试上的广泛实验表明，CodeBoost训练方法能持续提升模型性能，验证了该框架的有效性和可扩展性。

Conclusion: CodeBoost能在无需人工指令的情况下，从海量代码片段中挖掘有效训练信号，显著提升代码LLMs的性能，是一种高效、可扩展的后训练方案。

Abstract: Code large language models (LLMs) have become indispensable tools for
building efficient and automated coding pipelines. Existing models are
typically post-trained using reinforcement learning (RL) from general-purpose
LLMs using "human instruction-final answer" pairs, where the instructions are
usually from manual annotations. However, collecting high-quality coding
instructions is both labor-intensive and difficult to scale. On the other hand,
code snippets are abundantly available from various sources. This imbalance
presents a major bottleneck in instruction-based post-training. We propose
CodeBoost, a post-training framework that enhances code LLMs purely from code
snippets, without relying on human-annotated instructions. CodeBoost introduces
the following key components: (1) maximum-clique curation, which selects a
representative and diverse training corpus from code; (2) bi-directional
prediction, which enables the model to learn from both forward and backward
prediction objectives; (3) error-aware prediction, which incorporates learning
signals from both correct and incorrect outputs; (4) heterogeneous
augmentation, which diversifies the training distribution to enrich code
semantics; and (5) heterogeneous rewarding, which guides model learning through
multiple reward types including format correctness and execution feedback from
both successes and failures. Extensive experiments across several code LLMs and
benchmarks verify that CodeBoost consistently improves performance,
demonstrating its effectiveness as a scalable and effective training pipeline.

</details>


### [33] [ASCoT: An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs](https://arxiv.org/abs/2508.05282)
*Dongxu Zhang,Ning Yang,Jihua Zhu,Jinnan Yang,Miao Xin,Baoliang Tian*

Main category: cs.CL

TL;DR: 本论文发现LLM推理链后期错误影响更大，并提出针对性自适应纠错方法ASCoT，有效提升推理准确率，建议未来推理校验聚焦于关键脆弱步骤而非整体均匀对待。


<details>
  <summary>Details</summary>
Motivation: CoT方法提升了LLM的推理能力，但推理链的稳定性和可靠性仍是难题，特别关注错误在推理链中的传播影响。现有理论认为链开头出错影响最大，论文挑战此假设。

Method: 系统性地进行错误注入实验，分析不同位置错误的影响；提出Adaptive Self-Correction Chain-of-Thought (ASCoT)方法，包括Adaptive Verification Manager (AVM)与Multi-Perspective Self-Correction Engine (MSCE)：AVM通过位置影响分数函数识别高风险步骤，MSCE针对这些关键区域进行双路径纠错。

Result: 实验显示，后期（late-stage）错误对最终答案的影响更大，即“Late-Stage Fragility”现象。ASCoT方法能显著提升推理准确率，在GSM8K和MATH基准测试上优于现有CoT基线方法。

Conclusion: 推理链的后期环节更为脆弱，应采用位置和脆弱性自适应的纠错机制而非一刀切地校验策略。此机制极大增强了LLM推理结果的可靠性和准确率。

Abstract: Chain-of-Thought (CoT) prompting has significantly advanced the reasoning
capabilities of Large Language Models (LLMs), yet the reliability of these
reasoning chains remains a critical challenge. A widely held "cascading
failure" hypothesis suggests that errors are most detrimental when they occur
early in the reasoning process. This paper challenges that assumption through
systematic error-injection experiments, revealing a counter-intuitive
phenomenon we term "Late-Stage Fragility": errors introduced in the later
stages of a CoT chain are significantly more likely to corrupt the final answer
than identical errors made at the beginning. To address this specific
vulnerability, we introduce the Adaptive Self-Correction Chain-of-Thought
(ASCoT) method. ASCoT employs a modular pipeline in which an Adaptive
Verification Manager (AVM) operates first, followed by the Multi-Perspective
Self-Correction Engine (MSCE). The AVM leverages a Positional Impact Score
function I(k) that assigns different weights based on the position within the
reasoning chains, addressing the Late-Stage Fragility issue by identifying and
prioritizing high-risk, late-stage steps. Once these critical steps are
identified, the MSCE applies robust, dual-path correction specifically to the
failure parts. Extensive experiments on benchmarks such as GSM8K and MATH
demonstrate that ASCoT achieves outstanding accuracy, outperforming strong
baselines, including standard CoT. Our work underscores the importance of
diagnosing specific failure modes in LLM reasoning and advocates for a shift
from uniform verification strategies to adaptive, vulnerability-aware
correction mechanisms.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [34] [Aircraft routing: periodicity and complexity](https://arxiv.org/abs/2508.05532)
*Frédéric Meunier,Axel Parmentier,Nour ElHouda Tellache*

Main category: cs.DM

TL;DR: 1. 证明了周期性实例下，强周期性解的存在性（维护周期≤4天）；2. 首次证明非周期性航线分配问题的NP-困难性，并发现某些特例可多项式解决。


<details>
  <summary>Details</summary>
Motivation: 飞机航线分配问题是运筹学中的经典问题，涉及如何合理安排航班与飞机，确保飞机定期接受维护。此前文献普遍假设“周期性实例”要求“周期性解”，但此假设未被严密讨论及验证。

Method: 该论文首先分析了周期性实例与周期性解的关系，对文献中的隐含假设提出质疑并进行严格证明。其次，论文深入探讨了该问题的计算复杂性，对非周期性版本进行了NP-困难性证明，并对某些特殊情况进行了多项式复杂度证明。

Result: 作者证明了当维护周期最长为四天时，一定存在符合强周期性约束的解。此外，作者首次对非周期性航线分配问题进行了NP-困难性证明，并证明了某些自然特殊情况下该问题可用多项式时间解决。

Conclusion: 论文对周期性航线实例与解的假设进行了理论验证，并拓展了问题的计算复杂性分析范围，为相关领域提供了更全面的理论基础。

Abstract: The aircraft routing problem is one of the most studied problems of
operations research applied to aircraft management. It involves assigning
flights to aircraft while ensuring regular visits to maintenance bases. This
paper examines two aspects of the problem.
  First, we explore the relationship between periodic instances, where flights
are the same every day, and periodic solutions. The literature has implicitly
assumed-without discussion-that periodic instances necessitate periodic
solutions, and even periodic solutions in a stronger form, where every two
airplanes perform either the exact same cyclic sequence of flights, or
completely disjoint cyclic sequences. However, enforcing such periodicity may
eliminate feasible solutions. We prove that, when regular maintenance is
required at most every four days, there always exist periodic solutions of this
form.
  Second, we consider the computational hardness of the problem. Even if many
papers in this area refer to the NP-hardness of the aircraft routing problem,
such a result is only available in the literature for periodic instances. We
establish its NP-hardness for a non-periodic version. Polynomiality of a
special but natural case is also proven.

</details>
