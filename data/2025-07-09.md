<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 16]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.CL](#cs.CL) [Total: 33]
- [cs.DM](#cs.DM) [Total: 1]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [CORE: Benchmarking LLMs Code Reasoning Capabilities through Static Analysis Tasks](https://arxiv.org/abs/2507.05269)
*Danning Xie,Mingwei Zheng,Xuwei Liu,Jiannan Wang,Chengpeng Wang,Lin Tan,Xiangyu Zhang*

Main category: cs.SE

TL;DR: 本文提出了CoRe基准，用于衡量大模型对程序的依赖分析和信息流等静态分析推理能力。评测结果显示主流大模型在深层次语义推理和复杂依赖分析能力上存在挑战，未来需进一步提升相关推理水平。


<details>
  <summary>Details</summary>
Motivation: 当前大模型广泛应用于代码生成、程序修复和漏洞检测等软件工程任务，但现有基准多聚焦于最终结果，如代码生成或修复是否正确，缺乏对模型程序语义推理能力的深度考察。

Method: 作者提出了CoRe高质量基准，用以评估大模型在基本静态分析任务（数据依赖、控制依赖、信息流）的推理能力。基准覆盖C/C++、Java和Python，通过语义感知的多样性采样策略，提升任务实例的结构覆盖度和依赖深度，并对10个主流大模型进行评测和定性分析。

Result: 各主流大模型在依赖识别任务表现良好，但在需要更复杂语义理解和多步推理的任务上仍面临挑战，尤其是对复杂控制结构和逆向依赖模式难以处理。

Conclusion: 提出的CoRe基准有效补齐评测大模型程序推理能力的短板。当前模型在复杂语义推理和多步分析上表现有限，为后续提升大模型代码理解与推理能力指明方向。

Abstract: Large language models (LLMs) have been widely adopted across diverse software
engineering domains, such as code generation, program repair, and vulnerability
detection. These applications require understanding beyond surface-level code
patterns: value propagation, control flow, and interdependence between program
elements. However, existing benchmarks primarily evaluate end-to-end outcomes,
such as whether code is correctly repaired or generated, leaving the models
ability for program semantic reasoning underexplored. This work presents CoRe,
a high-quality, human-verified benchmark designed to evaluate LLMs on
fundamental static analysis tasks. CoRe includes 12,553 task instances spanning
data dependency, control dependency, and information flow across programs
written in C/C++, Java, and Python. To ensure semantic diversity and reasoning
complexity, we propose a semantics-aware diverse sampling strategy that selects
targets and task instances based on structural coverage and dependency depth.
We evaluate 10 mainstream LLMs and show that, while they perform well at
identifying dependencies, models still struggle with tasks that require deeper
semantic understanding and multi-step reasoning. We further conduct qualitative
analyses to uncover key challenges, such as complex control structures and
backward dependency patterns, offering insights into improving LLMs code
reasoning capabilities.

</details>


### [2] [FuzzFeed: An Automatic Approach to Weakest Precondition Generation using LLMs and Fuzzing](https://arxiv.org/abs/2507.05272)
*Daragh King,Vasileios Koutavas,Laura Kovacs*

Main category: cs.SE

TL;DR: 本文提出结合LLM与模糊测试，通过Fuzzing Guidance反馈机制，有效提升了程序WP的自动生成质量，在Java数组程序测试集上效果显著。


<details>
  <summary>Details</summary>
Motivation: 弱前置条件（WP）是程序验证与运行时错误检测等应用中的关键生成任务，现有自动化方法面临准确性与高效性挑战，因此研究结合AI辅助与程序测试的新方法。

Method: 将大语言模型（LLM）与模糊测试结合，提出Fuzzing Guidance（FG）机制，通过程序执行反馈引导LLM优化WP生成；利用模糊测试检查候选WP的有效性与弱度，再将信息反馈回LLM进行上下文优化。

Result: LLM能有效生成可行的WP，结合FG反馈后，其生成结果在Java数组程序基准测试中表现优越。

Conclusion: LLM生成的WP在FG方法的辅助下，其准确性和实用性得到了明显提升。

Abstract: The weakest precondition (WP) of a program describes the largest set of
initial states from which all terminating executions of the program satisfy a
given postcondition. The generation of WPs is an important task with practical
applications in areas ranging from verification to run-time error checking.
  This paper proposes the combination of Large Language Models (LLMs) and fuzz
testing for generating WPs. In pursuit of this goal, we introduce Fuzzing
Guidance (FG); FG acts as a means of directing LLMs towards correct WPs using
program execution feedback. FG utilises fuzz testing for approximately checking
the validity and weakness of candidate WPs, this information is then fed back
to the LLM as a means of context refinement.
  We demonstrate the effectiveness of our approach on a comprehensive benchmark
set of deterministic array programs in Java. Our experiments indicate that LLMs
are capable of producing viable candidate WPs, and that this ability can be
practically enhanced through FG.

</details>


### [3] [Open Source, Hidden Costs: A Systematic Literature Review on OSS License Management](https://arxiv.org/abs/2507.05270)
*Boyuan Li,Chengwei Liu,Lingling Fan,Sen Chen,Zhenlin Zhang,Zheli Liu*

Main category: cs.SE

TL;DR: 本文系统梳理了开源软件许可的识别、风险及缓解三大方向，总结当前挑战并展望未来，旨在帮助软件工程领域更好应对相关法律及合规风险。


<details>
  <summary>Details</summary>
Motivation: 随着现代软件开发越来越依赖第三方软件组件，虽然能提高效率和创新性，但也带来了复杂的软件许可风险和法律问题。当前学术界与工业界虽有所应对，但仍有重大局限，尤其面临开源许可证快速变化与生成式人工智能新技术的挑战。

Method: 本论文对80篇与开源软件许可相关的论文进行了系统性文献综述（Systematic Literature Review, SLR），将现有研究分为三个主要类别：许可识别、许可风险评估和许可风险缓解。

Result: 通过分类梳理现有研究，论文总结并讨论了当前解决方案的挑战，提出了未来研究方向，并为从业者提供了实践建议。

Conclusion: 本综述有助于学术界和业界了解软件许可风险治理的现状与挑战，缩小两者间的沟通鸿沟，并推动整个软件工程社区对合法性风险的治理。

Abstract: Integrating third-party software components is a common practice in modern
software development, offering significant advantages in terms of efficiency
and innovation. However, this practice is fraught with risks related to
software licensing. A lack of understanding may lead to disputes, which can
pose serious legal and operational challenges. To these ends, both academia and
industry have conducted various investigations and proposed solutions and tools
to deal with these challenges. However, significant limitations still remain.
Moreover, the rapid evolution of open-source software (OSS) licenses, as well
as the rapidly incorporated generative software engineering techniques, such as
large language models for code (CodeLLMs), are placing greater demands on the
systematic management of software license risks. To unveil the severe
challenges and explore possible future directions, we conduct the first
systematic literature review (SLR) on 80 carefully selected OSS license-related
papers, classifying existing research into three key categories, i.e., license
identification, license risk assessment, and license risk mitigation. Based on
these, we discuss challenges in existing solutions, conclude the opportunities
to shed light on future research directions and offer practical recommendations
for practitioners. We hope this thorough review will help bridge the gaps
between academia and industry and accelerate the ecosystem-wide governance of
legitimate software risks within the software engineering community.

</details>


### [4] [ReservoirChat: Interactive Documentation Enhanced with LLM and Knowledge Graph for ReservoirPy](https://arxiv.org/abs/2507.05279)
*Virgile Boraud,Yannis Bendi-Ouis,Paul Bernard,Xavier Hinaut*

Main category: cs.SE

TL;DR: 该研究提出结合RAG和知识图谱增强LLM用于ReservoirPy领域的代码辅助及问答系统，结果显示其在编程任务中优于主流LLM，并有效提升了基础模型的能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在编码辅助和复杂领域知识问答中存在幻觉和准确性问题，尤其是在专用领域如Reservoir Computing。为提升LLM帮助开发和知识问答的质量，需要引入更可靠的外部知识和工具。

Method: 本文提出了一种结合检索增强生成（RAG）与知识图谱的方法，将外部领域知识引入LLM，专门针对ReservoirPy库。该系统具有类似ChatGPT的交互体验，用户可用其编写、调试和理解Python代码，并获取高可信度的领域知识答案。

Result: 在实验评估中，虽然商业模型（如ChatGPT-4o、NotebookLM）在一般知识问答上略优，但该模型在编码任务上优于上述模型，并显著提升了自身基础模型（Codestral-22B）的性能。

Conclusion: 通过将RAG和知识图谱引入LLM，能够显著增强其在ReservoirPy相关编码和专有领域知识问答中的能力，减少幻觉，提升准确性。

Abstract: We introduce a tool designed to improve the capabilities of Large Language
Models (LLMs) in assisting with code development using the ReservoirPy library,
as well as in answering complex questions in the field of Reservoir Computing.
By incorporating external knowledge through Retrieval-Augmented Generation
(RAG) and knowledge graphs, our approach aims to reduce hallucinations and
increase the factual accuracy of generated responses. The system provides an
interactive experience similar to ChatGPT, tailored specifically for
ReservoirPy, enabling users to write, debug, and understand Python code while
accessing reliable domain-specific insights. In our evaluation, while
proprietary models such as ChatGPT-4o and NotebookLM performed slightly better
on general knowledge questions, our model outperformed them on coding tasks and
showed a significant improvement over its base model, Codestral-22B.

</details>


### [5] [CoreCodeBench: A Configurable Multi-Scenario Repository-Level Benchmark](https://arxiv.org/abs/2507.05281)
*Lingyue Fu,Hao Guan,Bolun Zhang,Haowei Yuan,Yaoming Zhu,Jun Xu,Zongyu Wang,Lin Qiu,Xunliang Cai,Xuezhi Cao,Weiwen Liu,Weinan Zhang,Yong Yu*

Main category: cs.SE

TL;DR: 该论文提出了自动生成仓库级代码基准的CorePipe方法及综合性评测集CoreCodeBench，更好地覆盖真实工程场景，对16种大语言模型实证，展现了其在复杂多样工程任务下的能力与不足。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在处理代码任务上表现出越来越强的能力，但现有的评测基准主要集中在单一场景，如代码生成或修复，难以覆盖真实工程项目中的多样性和复杂性。此外，现有基准也存在问题，如题目定位不易控制、测试用例可靠性不足。作者希望解决这些不足，从而更合理地评估和促进LLMs在真实工程任务中的应用。

Method: 作者提出了CorePipe——一个全自动化流程，将开源代码库转化为全面的测试用例，并基于此构建了CoreCodeBench，一个可配置的多场景、仓库级别的评测基准。CorePipe会针对核心代码段生成三种原子问题（开发、修复、测试驱动开发），并可组合成不同类型的复合问题，难度可通过超参数灵活调整。

Result: 利用CorePipe和CoreCodeBench，作者对16种主流LLM模型进行了实验，在不同场景下展示了模型能力的多样性，提供了工程场景下模型表现的多维度洞察。

Conclusion: CorePipe与CoreCodeBench显著提升了对LLM在工程级代码任务评测的全面性与可靠性，可有效支持后续相关模型的开发和研究。

Abstract: As Large Language Models (LLMs) demonstrate increasingly sophisticated code
processing capabilities, evaluating their performance on engineering-level code
remains challenging. Existing repository-level benchmarks primarily focus on
single scenarios, such as code generation or bug fixing, without adequately
capturing the diversity and complexity of real-world software or project
engineering workflows. Furthermore, these benchmarks suffer from limited
controllability in question positioning and reliability issues in their
generated test cases. To address these limitations, we present CorePipe, a
fully automated pipeline that converts repositories into comprehensive test
cases, and introduce CoreCodeBench, a configurable multi-scenario
repository-level benchmark. To simulate real engineering scenarios, CorePipe
generates three types of atomic questions (Development, BugFix, and Test-Driven
Development) specifically targeting core code segments. These atomic questions
are further combined into three types of composite questions, with difficulty
levels flexibly adjusted through hyperparameter tuning. CoreCodeBench provides
a comprehensive and extensive repository-level benchmark to investigate the
applicability of LLMs in real-world engineering projects. Experiments with 16
LLMs across diverse scenarios reveal varying capabilities and offer
multi-dimensional insights into LLM performance in engineering contexts. The
code for CorePipe is available at
https://github.com/AGI-Eval-Official/CoreCodeBench, and the data for
CoreCodeBench can be accessed at
https://huggingface.co/collections/tubehhh/corecodebench-68256d2faabf4b1610a08caa.

</details>


### [6] [Measuring how changes in code readability attributes affect code quality evaluation by Large Language Models](https://arxiv.org/abs/2507.05289)
*Igor Regis da Silva Simoes,Elaine Venson*

Main category: cs.SE

TL;DR: 本文展示LLM可有效、客观地评估代码可读性，对不同类型代码改动有敏感反应，进一步丰富了代码质量智能化分析手段。


<details>
  <summary>Details</summary>
Motivation: 代码可读性是代码质量的重要方面，但在工业界和学术界很难进行标准化、客观的衡量。目前常用的静态分析和人工代码评审方法各有局限，缺乏统一且易复现的手段。这激发了作者探索采用大型语言模型（LLM）作为评估工具的动机。

Method: 作者基于准实验方法，利用九个大型语言模型评估三种代码变更对可读性的影响：1）移除注释，2）用晦涩的名字替换标识符，3）重构代码以消除坏味道。每个模型对每类干预分别进行10组批量分析，同时与一个已知参考模型和工具对比，收集响应差异性等相关数据，并对LLM回应的推理过程做主题分析。

Result: 实验发现所有LLM对代码变更都较为敏感，并且在原始与重构代码情景下较好地与参考分类器达成一致。LLM展现出较强的语义敏感性（如识别标识符、注释与代码目的间一致性），而参考模型对此把控有限。尽管9.37%-14.58%的执行结果有一定波动，但统计意义通常未受影响。

Conclusion: LLM在评估代码可读性等语义质量属性方面表现出较高潜力，可实现标准化、可复现、结果一致的分析，是静态分析与人工评审的有益补充。

Abstract: Code readability is one of the main aspects of code quality, influenced by
various properties like identifier names, comments, code structure, and
adherence to standards. However, measuring this attribute poses challenges in
both industry and academia. While static analysis tools assess attributes such
as code smells and comment percentage, code reviews introduce an element of
subjectivity. This paper explores using Large Language Models (LLMs) to
evaluate code quality attributes related to its readability in a standardized,
reproducible, and consistent manner. We conducted a quasi-experiment study to
measure the effects of code changes on Large Language Model (LLM)s
interpretation regarding its readability quality attribute. Nine LLMs were
tested, undergoing three interventions: removing comments, replacing identifier
names with obscure names, and refactoring to remove code smells. Each
intervention involved 10 batch analyses per LLM, collecting data on response
variability. We compared the results with a known reference model and tool. The
results showed that all LLMs were sensitive to the interventions, with
agreement with the reference classifier being high for the original and
refactored code scenarios. The LLMs demonstrated a strong semantic sensitivity
that the reference model did not fully capture. A thematic analysis of the LLMs
reasoning confirmed their evaluations directly reflected the nature of each
intervention. The models also exhibited response variability, with 9.37% to
14.58% of executions showing a standard deviation greater than zero, indicating
response oscillation, though this did not always compromise the statistical
significance of the results. LLMs demonstrated potential for evaluating
semantic quality aspects, such as coherence between identifier names, comments,
and documentation with code purpose.

</details>


### [7] [zkSDK: Streamlining zero-knowledge proof development through automated trace-driven ZK-backend selection](https://arxiv.org/abs/2507.05294)
*William Law*

Main category: cs.SE

TL;DR: 现有ZK开发工具众多，选择困难。zkSDK通过抽象和自动选择最优后端，极大简化了开发流程，提高开发者体验。


<details>
  <summary>Details</summary>
Motivation: 随着零知识（ZK）程序开发的快速发展，市面上涌现了多种支持开发者的ZK工具和后端。由于选择众多，开发者面临较高的学习门槛与分裂的开发体验，往往被迫绑定在单一后端，影响开发效率与灵活性。

Method: 本论文提出zkSDK，一个模块化框架，通过抽象ZK后端的复杂性来简化ZK应用开发。zkSDK核心为自定义Python风格语言Presto，可分析程序工作负载，并结合用户标准，动态自动选择最优ZK证明后端。

Result: 通过对真实世界工作负载的分析与评测，zkSDK能够从多个支持的ZK后端中自动选择最适合的，显著提升了开发体验的一致性与便捷性。

Conclusion: zkSDK框架有效简化了ZK应用开发流程，消除了后端碎片化带来的门槛，让开发者无需被迫绑定单一后端，增强开发自由和效率。

Abstract: The rapid advancement of creating Zero-Knowledge (ZK) programs has led to the
development of numerous tools designed to support developers. Popular options
include being able to write in general-purpose programming languages like Rust
from Risc Zero. Other languages exist like Circom, Lib-snark, and Cairo.
However, developers entering the ZK space are faced with many different ZK
backends to choose from, leading to a steep learning curve and a fragmented
developer experience across different platforms. As a result, many developers
tend to select a single ZK backend and remain tied to it. This thesis
introduces zkSDK, a modular framework that streamlines ZK application
development by abstracting the backend complexities. At the core of zkSDK is
Presto, a custom Python-like programming language that enables the profiling
and analysis of a program to assess its computational workload intensity.
Combined with user-defined criteria, zkSDK employs a dynamic selection
algorithm to automatically choose the optimal ZK-proving backend. Through an
in-depth analysis and evaluation of real-world workloads, we demonstrate that
zkSDK effectively selects the best-suited backend from a set of supported ZK
backends, delivering a seamless and user-friendly development experience.

</details>


### [8] [ASSURE: Metamorphic Testing for AI-powered Browser Extensions](https://arxiv.org/abs/2507.05307)
*Xuanqi Gao,Juan Zhai,Shiqing Ma,Siyi Xie,Chao Shen*

Main category: cs.SE

TL;DR: ASSURE是为AI驱动浏览器扩展专门设计的自动化测试框架，兼具模块化生成、自动化执行和灵活验证功能。实验显示，其在发现问题数量和效率上远超人工测试，能够有效应对浏览器AI扩展的复杂测试需求。


<details>
  <summary>Details</summary>
Motivation: 当前LLM驱动的浏览器扩展为网页浏览带来了创新功能，如内容摘要、智能翻译和上下文感知写作辅助，但也引入了测试和可靠性保证方面的全新挑战。传统的浏览器扩展测试方法不适应LLM扩展的非确定性行为和复杂集成，现有LLM测试方法又脱离浏览器上下文，导致评估框架存在关键缺口。

Method: 提出了ASSURE：一个专为AI驱动浏览器扩展设计的模块化自动化测试框架。ASSURE包括三个主要组成部分：（1）支持插件扩展测试场景的测试用例生成引擎；（2）自动执行框架，协调网页内容、扩展流程与AI模型行为的复杂交互；（3）可配置的验证流程，用于系统性评估行为一致性和安全性，而非仅靠输出结果精确匹配。

Result: 在六款主流AI浏览器扩展上的评估显示，ASSURE发现了531个不同问题，包括安全漏洞、变形关系违反和内容对齐问题。与人工测试相比，ASSURE测试吞吐量提高了6.4倍，平均12.4分钟内即可发现关键安全漏洞。

Conclusion: ASSURE框架能有效解决AI驱动浏览器扩展测试中的独特挑战，在准确性和效率上均优于传统人工方法，适合集成进实际开发流程，提升测试的全面性和实用性。

Abstract: The integration of Large Language Models (LLMs) into browser extensions has
revolutionized web browsing, enabling sophisticated functionalities like
content summarization, intelligent translation, and context-aware writing
assistance. However, these AI-powered extensions introduce unprecedented
challenges in testing and reliability assurance. Traditional browser extension
testing approaches fail to address the non-deterministic behavior,
context-sensitivity, and complex web environment integration inherent to
LLM-powered extensions. Similarly, existing LLM testing methodologies operate
in isolation from browser-specific contexts, creating a critical gap in
effective evaluation frameworks. To bridge this gap, we present ASSURE, a
modular automated testing framework specifically designed for AI-powered
browser extensions. ASSURE comprises three principal components: (1) a modular
test case generation engine that supports plugin-based extension of testing
scenarios, (2) an automated execution framework that orchestrates the complex
interactions between web content, extension processing, and AI model behavior,
and (3) a configurable validation pipeline that systematically evaluates
behavioral consistency and security invariants rather than relying on exact
output matching. Our evaluation across six widely-used AI browser extensions
demonstrates ASSURE's effectiveness, identifying 531 distinct issues spanning
security vulnerabilities, metamorphic relation violations, and content
alignment problems. ASSURE achieves 6.4x improved testing throughput compared
to manual approaches, detecting critical security vulnerabilities within 12.4
minutes on average. This efficiency makes ASSURE practical for integration into
development pipelines, offering a comprehensive solution to the unique
challenges of testing AI-powered browser extensions.

</details>


### [9] [OASBuilder: Generating OpenAPI Specifications from Online API Documentation with Large Language Models](https://arxiv.org/abs/2507.05316)
*Koren Lazar,Matan Vetzler,Kiran Kate,Jason Tsay,David Boaz Himanshu Gupta,Avraham Shinnar,Rohith D Vallam,David Amid Esther Goldbraich,Guy Uziel,Jim Laredo,Ateret Anaby Tavor*

Main category: cs.SE

TL;DR: OASBuilder自动将复杂API文档转化为标准化机器可读的OpenAPI规格，助力企业大幅节省人工、提升API可用性。


<details>
  <summary>Details</summary>
Motivation: 现有的API文档多以非结构化HTML网页形式存在，人工转换为标准机器可读的API规格耗时费力，影响AI代理和自动化工具的接入效率。

Method: 提出OASBuilder框架，将大量不同风格的API文档网页自动转化为标准化、机器可读的API规格(OpenAPI)。该框架结合了大语言模型与基于规则的算法，并融合了文档网页结构的领域知识。

Result: OASBuilder在数百个API上泛化性良好，能够生成有效、覆盖原始文档关键信息的OpenAPI规格。已在企业环境中成功应用，显著节省了人工工时并提升了API可用性。

Conclusion: OASBuilder实现了API文档自动化转化为标准规格的流程，大幅提高了API接入效率，对企业和AI工具具有实际价值。

Abstract: AI agents and business automation tools interacting with external web
services require standardized, machine-readable information about their APIs in
the form of API specifications. However, the information about APIs available
online is often presented as unstructured, free-form HTML documentation,
requiring external users to spend significant time manually converting it into
a structured format. To address this, we introduce OASBuilder, a novel
framework that transforms long and diverse API documentation pages into
consistent, machine-readable API specifications. This is achieved through a
carefully crafted pipeline that integrates large language models and rule-based
algorithms which are guided by domain knowledge of the structure of
documentation webpages. Our experiments demonstrate that OASBuilder generalizes
well across hundreds of APIs, and produces valid OpenAPI specifications that
encapsulate most of the information from the original documentation. OASBuilder
has been successfully implemented in an enterprise environment, saving
thousands of hours of manual effort and making hundreds of complex enterprise
APIs accessible as tools for LLMs.

</details>


### [10] [Exploring Empathy in Software Engineering: Insights from a Grey Literature Analysis of Practitioners' Perspectives](https://arxiv.org/abs/2507.05325)
*Lidiany Cerqueira,João Pedro Bastos,Danilo Neves,Glauco Carneiro,Rodrigo Spínola,Sávio Freire,José Amancio Macedo Santos,Manoel Mendonça*

Main category: cs.SE

TL;DR: 本研究系统分析了软件工程领域内同理心概念、障碍、促进方法及效果，构建并验证了同理心框架，为提升团队协作和沟通提供了新的理论支持和实践方向。


<details>
  <summary>Details</summary>
Motivation: 同理心是关键的社会技能，对于沟通与协作至关重要，但在软件工程（SE）领域仍然研究不足。该研究旨在探讨实践者视角下的同理心内涵、障碍、实践方法及其影响。

Method: 定性内容分析55篇业界社区文章，随后通过同理心专家问卷进一步验证和完善发现。

Result: 提出了软件工程中同理心的定义，识别了阻碍（如有毒文化、过度技术导向）、促进团队同理心的实践方式，以及提升团队协作、沟通、缓解压力和焦虑的效果，最终综合为一个概念框架。

Conclusion: 研究提出的同理心框架被认为清晰且具有价值，提高了开发者对同理心的关注，并有助于团队协作氛围优化。未来的研究将在软件工程实践中进一步探讨同理心的更广泛影响。

Abstract: Context. Empathy, a key social skill, is essential for communication and
collaboration in SE but remains an under-researched topic. Aims. This study
investigates empathy in SE from practitioners' perspectives, aiming to
characterize its meaning, identify barriers, discuss practices to overcome
them, and explore its effects. Method. A qualitative content analysis was
conducted on 55 web articles from DEV and Medium, two communities widely used
by practitioners. To strengthen our findings, we conducted a follow-up survey
with empathy experts. Results. The study proposes a definition of empathy in
SE, identifies barriers such as toxic culture and excessive technical focus,
practices to foster empathy in teams, and outcomes, including improved
collaboration, communication, and reduced anxiety, frustration, and stress.
These findings are synthesized into a conceptual framework. Conclusion. Survey
results indicate the framework is clear, valuable, and raises empathy
awareness, with suggestions for improvements and integration into training.
This study paves the way for improving team dynamics by addressing barriers and
offering strategies to cultivate empathy. Future work will explore empathy's
broader implications in SE practice.

</details>


### [11] [Tool for Supporting Debugging and Understanding of Normative Requirements Using LLMs](https://arxiv.org/abs/2507.05504)
*Alex Kleijwegt,Sinem Getir Yaman,Radu Calinescu*

Main category: cs.SE

TL;DR: 本文提出了SLEEC-LLM，利用大语言模型为社会、法律、伦理等规范性需求的一致性分析提供自然语言解释，极大提升了非技术用户的理解与参与效率。


<details>
  <summary>Details</summary>
Motivation: 随着社会、法律、伦理、共情和文化（SLEEC）规范要求日益增多，系统需严格遵守这些规范。但这些需求常由非技术领域的利益相关者提出，需求归纳和一致性管理过程既复杂又易出错，现有形式化方法结果难以被非技术用户理解，影响需求提炼和验证效率。

Method: 提出SLEEC-LLM工具，利用大语言模型（LLM）对模型检测得到的SLEEC规则不一致的反例，给予自然语言解释。提升非技术用户对正式验证结果的理解。并通过两个实际案例进行方法效果的展示。

Result: SLEEC-LLM显著提升了SLEEC规范性需求归纳与一致性分析的效率、可解释性和用户体验，经真实案例验证，该工具对非技术利益相关者有良好适用性。

Conclusion: SLEEC-LLM通过将复杂的形式化验证结果转化为易于理解的自然语言解释，有效增强了规范性需求的提炼与一致性分析流程，能更好服务非技术领域用户。

Abstract: Normative requirements specify social, legal, ethical, empathetic, and
cultural (SLEEC) norms that must be observed by a system. To support the
identification of SLEEC requirements, numerous standards and regulations have
been developed. These requirements are typically defined by stakeholders in the
non-technical system with diverse expertise (e.g., ethicists, lawyers, social
scientists). Hence, ensuring their consistency and managing the requirement
elicitation process are complex and error-prone tasks. Recent research has
addressed this challenge using domain-specific languages to specify normative
requirements as rules, whose consistency can then be analyzed with formal
methods. Nevertheless, these approaches often present the results from formal
verification tools in a way that is inaccessible to non-technical users. This
hinders understanding and makes the iterative process of eliciting and
validating these requirements inefficient in terms of both time and effort. To
address this problem, we introduce SLEEC-LLM, a tool that uses large language
models (LLMs) to provide natural-language interpretations for model-checking
counterexamples corresponding to SLEEC rule inconsistencies. SLEEC-LLM improves
the efficiency and explainability of normative requirements elicitation and
consistency analysis. To demonstrate its effectiveness, we summarise its use in
two real-world case studies involving non-technical stakeholders.

</details>


### [12] [Search-based Selection of Metamorphic Relations for Optimized Robustness Testing of Large Language Models](https://arxiv.org/abs/2507.05565)
*Sangwon Hyun,Shaukat Ali,M. Ali Babar*

Main category: cs.SE

TL;DR: 提出基于搜索的MR组合优化方法，用于提升LLM鲁棒性测试效率和效果，MOEA/D算法效果最佳，还发现通用且强效的干扰MR组合。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）稳健性测试主要依赖于变形关系（MRs）测试，但需要大量高质量的MRs，并面临如何优化MR选择以提升失败检测能力、降低测试成本的问题。同时，多数研究仅关注单一扰动的测试空间，覆盖有限。

Method: 本文提出一种基于搜索的方法，通过四种搜索算法（Single-GA、NSGA-II、SPEA2、MOEA/D），对MR组合进行优化选择，兼顾提高失败检测（鲁棒性测试的效能）能力和降低LLM运行成本。方法创新地涵盖了多重组合扰动MR，扩大了评测空间，并引入新的编码方式来解决MR选择优化问题。

Result: 在两个主流LLM和主要Text-to-Text任务上进行实验，系统比较四种搜索算法与随机搜索的效果，结果显示MOEA/D算法在LLM稳健性测试的MR空间优化上表现最佳。此外，发现了具有‘银弹’效果的MRs，它们在不同任务中都能有效迷惑LLM。

Conclusion: 搜索式MR优化能明显提升LLM鲁棒性测试效率和效果，特别是MOEA/D算法在MR组合选择上具有优势，实验也揭示部分组合扰动MR具备通用的混淆能力，对鲁棒性评测研究具有重要启发。

Abstract: Assessing the trustworthiness of Large Language Models (LLMs), such as
robustness, has garnered significant attention. Recently, metamorphic testing
that defines Metamorphic Relations (MRs) has been widely applied to evaluate
the robustness of LLM executions. However, the MR-based robustness testing
still requires a scalable number of MRs, thereby necessitating the optimization
of selecting MRs. Most extant LLM testing studies are limited to automatically
generating test cases (i.e., MRs) to enhance failure detection. Additionally,
most studies only considered a limited test space of single perturbation MRs in
their evaluation of LLMs. In contrast, our paper proposes a search-based
approach for optimizing the MR groups to maximize failure detection and
minimize the LLM execution cost. Moreover, our approach covers the
combinatorial perturbations in MRs, facilitating the expansion of test space in
the robustness assessment. We have developed a search process and implemented
four search algorithms: Single-GA, NSGA-II, SPEA2, and MOEA/D with novel
encoding to solve the MR selection problem in the LLM robustness testing. We
conducted comparative experiments on the four search algorithms along with a
random search, using two major LLMs with primary Text-to-Text tasks. Our
statistical and empirical investigation revealed two key findings: (1) the
MOEA/D algorithm performed the best in optimizing the MR space for LLM
robustness testing, and (2) we identified silver bullet MRs for the LLM
robustness testing, which demonstrated dominant capabilities in confusing LLMs
across different Text-to-Text tasks. In LLM robustness assessment, our research
sheds light on the fundamental problem for optimized testing and provides
insights into search-based solutions.

</details>


### [13] [TigAug: Data Augmentation for Testing Traffic Light Detection in Autonomous Driving Systems](https://arxiv.org/abs/2507.05932)
*You Lu,Dingji Wang,Kaifeng Huang,Bihuan Chen,Xin Peng*

Main category: cs.SE

TL;DR: 本文提出的TigAug系统可自动增强交通灯图像，用于自动驾驶交通灯检测模型的高效测试和性能提升，实验验证了其有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 尽管自动驾驶系统（ADS）在多个模块测试上取得了进展，但交通灯检测模型的自动化测试受到忽视。现有方法依赖人工收集和标注交通灯数据，既费时费力，也难以覆盖多样化环境。急需一种更高效的测试和数据增强方法以提升ADS的可靠性。

Method: 提出并实现了TigAug系统，能够自动增强已标注交通灯图像用于ADS交通灯检测模型的测试。TigAug基于对天气环境、相机属性和交通灯属性的系统理解，构建了两类变形关系和三类图像变换方法。此外，通过特定变换的变形关系检测模型错误行为，并利用增强数据再次训练以提升模型表现。

Result: 在4种最前沿交通灯检测模型和2个交通灯数据集上的大规模实验表明：TigAug在测试交通灯检测模型方面有效，在交通灯图像合成方面高效，并能生成具有可接受自然度的交通灯图像。

Conclusion: TigAug为交通灯检测模型的测试和改进提供了一种高效、自动化的数据增强方法，能显著提升模型的健壮性和性能，有助于保障自动驾驶系统的可靠性。

Abstract: Autonomous vehicle technology has been developed in the last decades with
recent advances in sensing and computing technology. There is an urgent need to
ensure the reliability and robustness of autonomous driving systems (ADSs).
Despite the recent achievements in testing various ADS modules, little
attention has been paid on the automated testing of traffic light detection
models in ADSs. A common practice is to manually collect and label traffic
light data. However, it is labor-intensive, and even impossible to collect
diverse data under different driving environments.
  To address these problems, we propose and implement TigAug to automatically
augment labeled traffic light images for testing traffic light detection models
in ADSs. We construct two families of metamorphic relations and three families
of transformations based on a systematic understanding of weather environments,
camera properties, and traffic light properties. We use augmented images to
detect erroneous behaviors of traffic light detection models by
transformation-specific metamorphic relations, and to improve the performance
of traffic light detection models by retraining. Large-scale experiments with
four state-of-the-art traffic light detection models and two traffic light
datasets have demonstrated that i) TigAug is effective in testing traffic light
detection models, ii) TigAug is efficient in synthesizing traffic light images,
and iii) TigAug generates traffic light images with acceptable naturalness.

</details>


### [14] [Multi-Agent Debate Strategies to Enhance Requirements Engineering with Large Language Models](https://arxiv.org/abs/2507.05981)
*Marc Oriol,Quim Motger,Jordi Marco,Xavier Franch*

Main category: cs.SE

TL;DR: 本论文探索多LLM代理辩论（MAD）策略在需求工程任务中的应用，建立并实证测试了相关分类框架，结果显示MAD有助于提高任务准确性，为今后的研究提供了理论和方法基础。


<details>
  <summary>Details</summary>
Motivation: 目前用于需求工程（RE）任务的大型语言模型（LLM）提高准确率的方法主要有提示工程、模型微调和检索增强生成。这些方法通常把模型当作孤立的黑盒处理，依赖单次输出，缺乏迭代优化或协同，导致鲁棒性和适应性有限。作者认为，人类的辩论能够通过多样化观点提升RE任务中的准确性和降低偏见，因此希望验证多LLM代理间辩论是否也能带来类似效果。

Method: 本研究对现有多代理辩论（MAD）策略在不同领域的应用进行了系统性梳理，总结其主要特征，并构建了初步的基于MAD的RE任务分类框架，进行实证测试。

Result: 研究归纳并分类了多种MAD策略，提出了相关的属性分类体系。实验表明，将MAD方法应用于RE任务分类是可行的。

Conclusion: 多代理辩论（MAD）为提升LLM在需求工程任务准确度提供了一种有前景的方法，本研究为MAD策略在该领域的应用和未来研究奠定了基础。

Abstract: Context: Large Language Model (LLM) agents are becoming widely used for
various Requirements Engineering (RE) tasks. Research on improving their
accuracy mainly focuses on prompt engineering, model fine-tuning, and retrieval
augmented generation. However, these methods often treat models as isolated
black boxes - relying on single-pass outputs without iterative refinement or
collaboration, limiting robustness and adaptability. Objective: We propose
that, just as human debates enhance accuracy and reduce bias in RE tasks by
incorporating diverse perspectives, different LLM agents debating and
collaborating may achieve similar improvements. Our goal is to investigate
whether Multi-Agent Debate (MAD) strategies can enhance RE performance. Method:
We conducted a systematic study of existing MAD strategies across various
domains to identify their key characteristics. To assess their applicability in
RE, we implemented and tested a preliminary MAD-based framework for RE
classification. Results: Our study identified and categorized several MAD
strategies, leading to a taxonomy outlining their core attributes. Our
preliminary evaluation demonstrated the feasibility of applying MAD to RE
classification. Conclusions: MAD presents a promising approach for improving
LLM accuracy in RE tasks. This study provides a foundational understanding of
MAD strategies, offering insights for future research and refinements in RE
applications.

</details>


### [15] [PromiseTune: Unveiling Causally Promising and Explainable Configuration Tuning](https://arxiv.org/abs/2507.05995)
*Pengzhou Chen,Tao Chen*

Main category: cs.SE

TL;DR: 本论文提出了PromiseTune方法，利用因果规则净化技术，在保证系统性能优化的同时，提升了结果的可解释性。实验证明PromiseTune在多个系统上均优于已有调优器。


<details>
  <summary>Details</summary>
Motivation: 现代软件系统高度可配置，使得配置调优成为保障系统性能（如延迟、吞吐量）的关键步骤。但巨大的配置空间和测量成本以及复杂的配置地形，导致现有调优方法在探索和利用之间难以平衡，且结果可解释性不足。

Method: 提出PromiseTune方法，通过学习规则并结合因果推断进行规则净化，识别并聚焦于配置空间中有前景的区域进行调优。净化后的规则用作有前景区域的近似反映，调优过程优先考察这些区域，并能够提供空间层面的可解释性。

Result: 与11种主流调优器在12个系统、不同预算下进行比较，PromiseTune的效果显著更好，总体优于第二名42%，同时能更好地解释系统的隐藏特性。

Conclusion: PromiseTune通过因果规则指导配置调优，有效改善了探索与利用的矛盾，不仅提升了调优效果，还增强了对系统特性的解释能力。

Abstract: The high configurability of modern software systems has made configuration
tuning a crucial step for assuring system performance, e.g., latency or
throughput. However, given the expensive measurements, large configuration
space, and rugged configuration landscape, existing tuners suffer
ineffectiveness due to the difficult balance of budget utilization between
exploring uncertain regions (for escaping from local optima) and exploiting
guidance of known good configurations (for fast convergence). The root cause is
that we lack knowledge of where the promising regions lay, which also causes
challenges in the explainability of the results.
  In this paper, we propose PromiseTune that tunes configuration guided by
causally purified rules. PromiseTune is unique in the sense that we learn
rules, which reflect certain regions in the configuration landscape, and purify
them with causal inference. The remaining rules serve as approximated
reflections of the promising regions, bounding the tuning to emphasize these
places in the landscape. This, as we demonstrate, can effectively mitigate the
impact of the exploration and exploitation trade-off. Those purified regions
can then be paired with the measured configurations to provide spatial
explainability at the landscape level. Comparing with 11 state-of-the-art
tuners on 12 systems and varying budgets, we show that PromiseTune performs
significantly better than the others with $42\%$ superior rank to the overall
second best while providing richer information to explain the hidden system
characteristics.

</details>


### [16] [Model Cards Revisited: Bridging the Gap Between Theory and Practice for Ethical AI Requirements](https://arxiv.org/abs/2507.06014)
*Tim Puhlfürß,Julia Butzke,Walid Maalej*

Main category: cs.SE

TL;DR: AI模型文档普遍忽视伦理要求，论文通过系统性分析归纳出43条伦理需求，建立了改进文档的伦理分类法，并呼吁开发者增加对可解释性、公平性等方面的重视。


<details>
  <summary>Details</summary>
Motivation: 现有的人工智能模型文档（Model cards）未能充分满足道德与合规性需求，开发者和使用者难以获得充分的道德信息，导致AI系统难以确保符合相关法律、标准。需要明确AI道德要求与现有文档实践之间的差距，并提出改进建议。

Method: 作者对26份AI伦理指南、3套AI文档框架、3篇Model cards定量研究和10份实际Model cards进行了主题分析，从中归纳出与文档相关的43项伦理要求，并建立了包含4个主题和12个子主题的伦理原则分类法。

Result: 论文发现开发者在Model cards文档中主要关注模型能力和可靠性，常常忽略了具体的伦理要求，如可解释性、用户自主性和公平性等。作者据此提出了一个更全面反映伦理要求的新分类法，为改进Model cards文档提供了基础。

Conclusion: 当前AI模型文档尚未充分包括所有伦理维度。作者提出的伦理分类法为模型文档结构的改进和更好地满足伦理要求提供了理论基础，强调需要在Model cards中加强对伦理问题的支持。

Abstract: Model cards are the primary documentation framework for developers of
artificial intelligence (AI) models to communicate critical information to
their users. Those users are often developers themselves looking for relevant
documentation to ensure that their AI systems comply with the ethical
requirements of existing laws, guidelines, and standards. Recent studies
indicate inadequate model documentation practices, suggesting a gap between AI
requirements and current practices in model documentation. To understand this
gap and provide actionable guidance to bridge it, we conducted a thematic
analysis of 26 guidelines on ethics and AI, three AI documentation frameworks,
three quantitative studies of model cards, and ten actual model cards. We
identified a total of 43 ethical requirements relevant to model documentation
and organized them into a taxonomy featuring four themes and twelve sub-themes
representing ethical principles. Our findings indicate that model developers
predominantly emphasize model capabilities and reliability in the documentation
while overlooking other ethical aspects, such as explainability, user autonomy,
and fairness. This underscores the need for enhanced support in documenting
ethical AI considerations. Our taxonomy serves as a foundation for a revised
model card framework that holistically addresses ethical AI requirements.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [17] [Verified Certificates via SAT and Computer Algebra Systems for the Ramsey $R(3, 8)$ and $R(3, 9)$ Problems](https://arxiv.org/abs/2502.06055)
*Zhengyu Li,Conor Duggan,Curtis Bright,Vijay Ganesh*

Main category: cs.LO

TL;DR: 本文提出了基于SAT+CAS的新方法，有效且高效地求解并验证了R(3,8)和R(3,9)等Ramsey数，首次提供了可验证证书，并大幅提升计算速度。


<details>
  <summary>Details</summary>
Motivation: Ramsey问题R(3, k)在组合数学和图论中很重要，但此前对如R(3,8)和R(3,9)等问题的计算结果缺乏形式化验证。作者希望解决这一可靠性和可验证性问题。

Method: 作者采用MathCheck工具，将布尔可满足性(SAT)求解器与计算机代数系统(CAS)结合，提出SAT+CAS方法，并通过并行化cube-and-conquer技术进一步提升性能。

Result: SAT+CAS方法在R(3,8)（59小时）和R(8,3)（11小时）上远快于传统SAT方法（7天仍未完成），对于更难的问题R(3,9)和R(9,3)也通过优化并行化处理。首次为这些Ramsey数提供可独立验证的证书，确保过程完整性和正确性。

Conclusion: SAT+CAS法不仅大幅加速了Ramsey数计算，并通过可验证证书实现了形式化验证，提升了计算数学的结果可靠性。

Abstract: The Ramsey problem $R(3, k)$ seeks to determine the smallest value of $n$
such that any red/blue edge coloring of the complete graph on $n$ vertices must
either contain a blue triangle (3-clique) or a red clique of size $k$. Despite
its significance, many previous computational results for the Ramsey $R(3, k)$
problem such as $R(3, 8)$ and $R(3, 9)$ lack formal verification. To address
this issue, we use the software MathCheck to generate certificates for Ramsey
problems $R(3, 8)$ and $R(3, 9)$ (and symmetrically $R(8, 3)$ and $R(9, 3)$) by
integrating a Boolean satisfiability (SAT) solver with a computer algebra
system (CAS). Our SAT+CAS approach significantly outperforms traditional
SAT-only methods, demonstrating an improvement of several orders of magnitude
in runtime. For instance, our SAT+CAS approach solves $R(3, 8)$ (resp., $R(8,
3)$) sequentially in 59 hours (resp., in 11 hours), while a SAT-only approach
using state-of-the-art CaDiCaL solver times out after 7 days. Additionally, in
order to be able to scale to harder Ramsey problems $R(3, 9)$ and $R(9, 3)$ we
further optimized our SAT+CAS tool using a parallelized cube-and-conquer
approach. Our results provide the first independently verifiable certificates
for these Ramsey numbers, ensuring both correctness and completeness of the
exhaustive search process of our SAT+CAS tool.

</details>


### [18] [A Formalization of Divided Powers in Lean](https://arxiv.org/abs/2507.05327)
*Antoine Chambert-Loir,María Inés de Frutos-Fernández*

Main category: cs.LO

TL;DR: 本文首次在Lean 4中形式化了分式幂结构理论，包括代数操作与基础构造，并扩展了多元幂级数环的形式化工具，丰富了数学领域自动证明的支持工具。


<details>
  <summary>Details</summary>
Motivation: 在许多数学领域（如代数拓扑、数论和代数几何）中，分式幂结构是一种关键工具，但其理论尚未在形式化证明系统中系统实现。该工作旨在填补分式幂结构在自动定理证明器中缺乏正式基础设施的空白。

Method: 作者在Lean 4定理证明器中对分式幂结构的基本理论进行形式化，包括分式幂态射和子分式幂理想，并给出了商、直和等基础构造。此外，作者还扩展了多元幂级数环的形式化理论，实现了其拓扑结构、幂级数的赋值与替换定义。

Result: 作者首次在任何定理证明器中形式化了分式幂结构的理论，并完善了相关多元幂级数环的基础设施，支持形式化分式幂相关操作。

Conclusion: 本文为自动定理证明领域中的分式幂结构理论提供了首个系统的形式化实现，为相关领域的进一步发展奠定了基础。

Abstract: Given an ideal $I$ in a commutative ring $A$, a divided power structure on
$I$ is a collection of maps $\{\gamma_n \colon I \to A\}_{n \in \mathbb{N}}$,
subject to axioms that imply that it behaves like the family $\{x \mapsto
\frac{x^n}{n!}\}_{n \in \mathbb{N}}$, but which can be defined even when
division by factorials is not possible in $A$. Divided power structures have
important applications in diverse areas of mathematics, including algebraic
topology, number theory and algebraic geometry.
  In this article we describe a formalization in Lean 4 of the basic theory of
divided power structures, including divided power morphisms and sub-divided
power ideals, and we provide several fundamental constructions, in particular
quotients and sums. This constitutes the first formalization of this theory in
any theorem prover.
  As a prerequisite of general interest, we expand the formalized theory of
multivariate power series rings, endowing them with a topology and defining
evaluation and substitution of power series.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [19] [TokenShapley: Token Level Context Attribution with Shapley Value](https://arxiv.org/abs/2507.05261)
*Yingtai Xiao,Yuqing Zhu,Sirat Samyoun,Wanrong Zhang,Jiachen T. Wang,Jian Du*

Main category: cs.CL

TL;DR: 本文提出了TokenShapley，一种将Shapley值归因与KNN检索相结合的新型token级归因方法。实验显示，该方法在精确度上显著优于现有技术，推进了LLM响应细粒度验证的发展。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）在上下文学习方面能力强，但其生成响应内容的正确性难以验证。现有方法多针对于句子级归因，难以满足用户针对关键词（如数字、年份、姓名）层面的归因需求。

Method: 提出了一种新的token级归因方法TokenShapley，结合了基于Shapley值的数据归因和KNN检索技术。通过预计算数据存储进行上下文检索，并用Shapley值量化每个token的重要性，实现更细粒度的数据归因。

Result: 在四个基准数据集上的广泛评测表明，TokenShapley在token级归因准确率上比最先进的基线方法高出11-23%。

Conclusion: TokenShapley为大语言模型提供了更细致且有效的token级数据归因方法，大幅提高了归因准确性。

Abstract: Large language models (LLMs) demonstrate strong capabilities in in-context
learning, but verifying the correctness of their generated responses remains a
challenge. Prior work has explored attribution at the sentence level, but these
methods fall short when users seek attribution for specific keywords within the
response, such as numbers, years, or names. To address this limitation, we
propose TokenShapley, a novel token-level attribution method that combines
Shapley value-based data attribution with KNN-based retrieval techniques
inspired by recent advances in KNN-augmented LLMs. By leveraging a precomputed
datastore for contextual retrieval and computing Shapley values to quantify
token importance, TokenShapley provides a fine-grained data attribution
approach. Extensive evaluations on four benchmarks show that TokenShapley
outperforms state-of-the-art baselines in token-level attribution, achieving an
11-23% improvement in accuracy.

</details>


### [20] [User Behavior Prediction as a Generic, Robust, Scalable, and Low-Cost Evaluation Strategy for Estimating Generalization in LLMs](https://arxiv.org/abs/2507.05266)
*Sougata Saha,Monojit Choudhury*

Main category: cs.CL

TL;DR: 本文认为现有泛化能力评测受数据污染影响，提出用用户行为预测作为更合适的评测方式，并通过实验证明该方法可行，GPT-4o表现最好，但整体仍有较大提升空间。


<details>
  <summary>Details</summary>
Motivation: 当前，大语言模型的泛化能力测量因数据污染问题变得困难，随着模型体量增大和计算成本降低，确保测试任务和数据未在训练中出现变得几乎不可能。因此，现有基于知识检索与推理的泛化评估方式并不理想。

Method: 论文提出将用户行为预测作为一种新颖且健全的泛化能力评测方法，并构建了相应的评测框架。作者在电影与音乐推荐数据集上，对GPT-4o、GPT-4o-mini以及Llama-3.1-8B-Instruct进行了实证测试。

Result: 测试结果显示，GPT-4o优于GPT-4o-mini和Llama-3.1-8B-Instruct，但所有模型（特别是Llama）在推荐任务中的表现都还有显著提升空间。

Conclusion: 用户行为预测作为泛化能力的评测方式，具有理论合理性、可扩展性和鲁棒性，更符合大模型未来的评测需求。框架的实证结果也支持其有效性。

Abstract: Measuring the generalization ability of Large Language Models (LLMs) is
challenging due to data contamination. As models grow and computation becomes
cheaper, ensuring tasks and test cases are unseen during training phases will
become nearly impossible. We argue that knowledge-retrieval and reasoning tasks
are not ideal for measuring generalization, as LLMs are not trained for
specific tasks. Instead, we propose user behavior prediction, also a key aspect
of personalization, as a theoretically sound, scalable, and robust alternative.
We introduce a novel framework for this approach and test it on movie and music
recommendation datasets for GPT-4o, GPT-4o-mini, and Llama-3.1-8B-Instruct.
Results align with our framework's predictions, showing GPT-4o outperforms
GPT-4o-mini and Llama, though all models have much room for improvement,
especially Llama.

</details>


### [21] [An Adaptive Supervised Contrastive Learning Framework for Implicit Sexism Detection in Digital Social Networks](https://arxiv.org/abs/2507.05271)
*Mohammad Zia Ur Rehman,Aditya Shah,Nagendra Kumar*

Main category: cs.CL

TL;DR: 该论文提出了一种基于自适应监督对比学习的新方法ASCEND，用于检测社交媒体中的隐性性别歧视，通过创新对比机制、特征增强和多种损失优化，显著优于现有主流模型。


<details>
  <summary>Details</summary>
Motivation: 现有传统的检测方法往往难以识别社交媒体中隐含的性别歧视言论，这类内容传播广泛却常被忽视。

Method: 提出了一种自适应监督对比学习框架（ASCEND）用于隐性性别歧视检测。方法核心为基于阈值的对比学习，通过计算嵌入间余弦相似度，仅将相似度超过学习阈值的样本对作为正样本，以优化语义相似文本的嵌入分布，并拉大与不相似文本的距离，从而减少误报和漏报。最终模型采用对比损失和交叉熵损失联合优化，并引入词级注意力机制以及情感、情绪和有害性特征提升表现。

Result: 在EXIST2021和MLSC两个数据集上，所提方法在多个任务的Macro F1上分别提升了9.86%、29.63%和32.51%，效果显著优于现有方法。

Conclusion: ASCEND能够更有效地捕捉语句中的隐性性别歧视信号，对比现有检测方法具有明显优势。

Abstract: The global reach of social media has amplified the spread of hateful content,
including implicit sexism, which is often overlooked by conventional detection
methods. In this work, we introduce an Adaptive Supervised Contrastive lEarning
framework for implicit sexism detectioN (ASCEND). A key innovation of our
method is the incorporation of threshold-based contrastive learning: by
computing cosine similarities between embeddings, we selectively treat only
those sample pairs as positive if their similarity exceeds a learnable
threshold. This mechanism refines the embedding space by robustly pulling
together representations of semantically similar texts while pushing apart
dissimilar ones, thus reducing false positives and negatives. The final
classification is achieved by jointly optimizing a contrastive loss with a
cross-entropy loss. Textual features are enhanced through a word-level
attention module. Additionally, we employ sentiment, emotion, and toxicity
features. Evaluations on the EXIST2021 and MLSC datasets demonstrate that
ASCEND significantly outperforms existing methods, with average Macro F1
improvements of 9.86%, 29.63%, and 32.51% across multiple tasks, highlighting
its efficacy in capturing the subtle cues of implicit sexist language.

</details>


### [22] [Beyond classical and contemporary models: a transformative ai framework for student dropout prediction in distance learning using rag, prompt engineering, and cross-modal fusion](https://arxiv.org/abs/2507.05285)
*Miloud Mihoubi,Meriem Zerkouk,Belkacem Chikhaoui*

Main category: cs.CL

TL;DR: 本文提出基于RAG、Prompt工程和多模态融合的新型AI方法，大幅提升远程学习辍学预测准确率，并能自动生成个性化干预建议，实现辍学防控的智能化和可操作化。


<details>
  <summary>Details</summary>
Motivation: 远程学习中的学生辍学率高，产生重大的社会和经济影响。传统机器学习模型虽然利用了结构化的人口统计和行为数据，但难以捕捉到学生交流中的情感及背景因素。因此，亟需一种能结合多模态数据和更深层情感分析的新方法，提升辍学预警的准确性和实用性。

Method: 提出一个创新性AI框架，包括三大创新：1）基于Retrieval-Augmented Generation（RAG）的领域特定情感分析模型，将BERT与教育内容知识库结合，提升对学生评论的上下文理解；2）通过Prompt工程，专门提取学业压力相关特征（如孤立、焦虑等）；3）采用跨模态注意力融合机制，将文本情感、行为数据及人口学特征动态整合，形成全方位学生风险画像。

Result: 在包含4,423名学生的纵向数据集上，该框架实现了89%的准确率和0.88的F1分数，比传统模型提高7%，假阴性率降低21%。同时系统能够检索与学生具体困境相匹配的干预建议，提高了操作性和实际教育指导意义。

Conclusion: 文中AI框架不仅提升了远程学习辍学预测的精度和解释性，还能基于实际学情提供针对性干预策略，实现从数据预测到教育行动的有效衔接，具有推广和实际应用价值，为全球教育体系的辍学风险防控提供了可扩展解决方案。

Abstract: Student dropout in distance learning remains a critical challenge, with
profound societal and economic consequences. While classical machine learning
models leverage structured socio-demographic and behavioral data, they often
fail to capture the nuanced emotional and contextual factors embedded in
unstructured student interactions. This paper introduces a transformative AI
framework that redefines dropout prediction through three synergistic
innovations: Retrieval-Augmented Generation (RAG) for domain-specific sentiment
analysis, prompt engineering to decode academic stressors, and cross-modal
attention fusion to dynamically align textual, behavioral, and
socio-demographic insights. By grounding sentiment analysis in a curated
knowledge base of pedagogical content, our RAG-enhanced BERT model interprets
student comments with unprecedented contextual relevance, while optimized
prompts isolate indicators of academic distress (e.g., "isolation," "workload
anxiety"). A cross-modal attention layer then fuses these insights with
temporal engagement patterns, creating holistic risk profiles. Evaluated on a
longitudinal dataset of 4 423 students, the framework achieves 89% accuracy and
an F1-score of 0.88, outperforming conventional models by 7% and reducing false
negatives by 21%. Beyond prediction, the system generates interpretable
interventions by retrieving contextually aligned strategies (e.g., mentorship
programs for isolated learners). This work bridges the gap between predictive
analytics and actionable pedagogy, offering a scalable solution to mitigate
dropout risks in global education systems

</details>


### [23] [LCDS: A Logic-Controlled Discharge Summary Generation System Supporting Source Attribution and Expert Review](https://arxiv.org/abs/2507.05319)
*Cheng Yuan,Xinkai Rui,Yongqi Fan,Yawei Fan,Boyang Zhong,Jiacheng Wang,Weiyan Zhang,Tong Ruan*

Main category: cs.CL

TL;DR: 本文提出的LCDS系统结合文本相似度和逻辑规则显著减少了LLM生成出院小结时的幻觉现象，实现了来源可追踪且便于专家纠错的文本总结流程，并可用于迭代提升语言模型能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在自动生成出院小结方面表现优异，但它们仍受幻觉问题困扰，例如生成不准确或凭空捏造的信息。此外，电子病历（EMR）通常为长文本数据，使得语言模型难以追溯和归因生成内容来源。为解决这些问题，提出了新的方法。

Method: 提出了一个名为LCDS的“逻辑控制出院小结生成系统”。该系统通过计算EMR与出院小结之间的文本相似度构建来源映射表，从而约束总结内容的范围。另外，系统整合了完善的逻辑规则，提高了生成的出院小结在不同临床领域的可靠性。LCDS还能实现内容生成的来源归因，便于专家审核与纠错。最终生成的高质量小结被用于增量微调LLM模型。

Result: LCDS实现了更可靠、可追溯和易于审核的自动出院小结生成，可以减少幻觉现象，并可持续改进大型语言模型。

Conclusion: 逻辑控制结合来源归因机制，可有效提升自动出院小结生成质量，同时优化LLM的微调流程。

Abstract: Despite the remarkable performance of Large Language Models (LLMs) in
automated discharge summary generation, they still suffer from hallucination
issues, such as generating inaccurate content or fabricating information
without valid sources. In addition, electronic medical records (EMRs) typically
consist of long-form data, making it challenging for LLMs to attribute the
generated content to the sources. To address these challenges, we propose LCDS,
a Logic-Controlled Discharge Summary generation system. LCDS constructs a
source mapping table by calculating textual similarity between EMRs and
discharge summaries to constrain the scope of summarized content. Moreover,
LCDS incorporates a comprehensive set of logical rules, enabling it to generate
more reliable silver discharge summaries tailored to different clinical fields.
Furthermore, LCDS supports source attribution for generated content, allowing
experts to efficiently review, provide feedback, and rectify errors. The
resulting golden discharge summaries are subsequently recorded for incremental
fine-tuning of LLMs. Our project and demo video are in the GitHub repository
https://github.com/ycycyc02/LCDS.

</details>


### [24] [MindFlow: Revolutionizing E-commerce Customer Support with Multimodal LLM Agents](https://arxiv.org/abs/2507.05330)
*Ming Gong,Xucheng Huang,Chenghan Yang,Xianhan Peng,Haoxin Wang,Yang Liu,Ling Jiang*

Main category: cs.CL

TL;DR: MindFlow是首个开源电商专用多模态LLM智能体，结合多模块并进行实证评测，显著提升复杂客户服务表现。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在复杂多模态电商客服场景下能力有限，缺乏面向实际复杂任务的多模态智能体解决方案。

Method: 基于CoALA框架，设计了集成记忆、决策和行动模块的多模态LLM agent，采用"MLLM-as-Tool"模块化策略，实现高效的视觉-文本推理。通过线上A/B测试和仿真消融实验进行评估。

Result: MindFlow在实际部署中实现了93.53%的相对改进，显著提升了复杂查询处理能力、用户满意度，并降低了运营成本。

Conclusion: MindFlow显著提升了电商复杂客户服务场景下多模态智能体的表现，有效提升了用户满意度和降低了运营成本。

Abstract: Recent advances in large language models (LLMs) have enabled new applications
in e-commerce customer service. However, their capabilities remain constrained
in complex, multimodal scenarios. We present MindFlow, the first open-source
multimodal LLM agent tailored for e-commerce. Built on the CoALA framework, it
integrates memory, decision-making, and action modules, and adopts a modular
"MLLM-as-Tool" strategy for effect visual-textual reasoning. Evaluated via
online A/B testing and simulation-based ablation, MindFlow demonstrates
substantial gains in handling complex queries, improving user satisfaction, and
reducing operational costs, with a 93.53% relative improvement observed in
real-world deployments.

</details>


### [25] [LoRA-Augmented Generation (LAG) for Knowledge-Intensive Language Tasks](https://arxiv.org/abs/2507.05346)
*William Fleshman,Benjamin Van Durme*

Main category: cs.CL

TL;DR: 本文提出LAG方法，高效整合多个LoRA专家，无需数据和再训练，实验证明在知识密集任务上效果领先，并能与其他增强方案结合。


<details>
  <summary>Details</summary>
Motivation: 当前针对特定任务和领域的微调语言模型专家越来越多，需要更高效的方法进行选择和组合。

Method: 提出了一种LoRA-Augmented Generation（LAG）方法，能够利用大型知识库和特定任务的LoRA适配器。LAG不需要额外训练或访问数据，能够在每个token和层级基础上高效筛选、检索、应用专家模型。

Result: 在多种知识密集型任务上，LAG优于现有的数据无关方法；此外在有额外数据的情况下，LAG还能兼容如检索增强生成（RAG）等其他解决方案。

Conclusion: LAG是一种高效且灵活的新方法，能够在无需数据和训练的情况下利用多专家模型，性能领先，并可结合其他方法使用。

Abstract: The proliferation of fine-tuned language model experts for specific tasks and
domains signals the need for efficient selection and combination methods. We
propose LoRA-Augmented Generation (LAG) for leveraging large libraries of
knowledge and task-specific LoRA adapters. LAG requires no additional training
or access to data, and efficiently filters, retrieves, and applies experts on a
per-token and layer basis. We evaluate LAG on various knowledge-intensive
tasks, achieving superior performance over existing data-free methods. We
explore scenarios where additional data is available, demonstrating LAG's
compatibility with alternative solutions such as retrieval-augmented generation
(RAG).

</details>


### [26] [On the Bias of Next-Token Predictors Toward Systematically Inefficient Reasoning: A Shortest-Path Case Study](https://arxiv.org/abs/2507.05362)
*Riccardo Alberghi,Elizaveta Demyanenko,Luca Biggio,Luca Saglietti*

Main category: cs.CL

TL;DR: 对比最优和冗长递进推理轨迹训练Transformer，发现连贯且递进的长trace能提升模型泛化，长度本身或随机冗余无效，关键在于推理信号的结构性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理能力提升涉及两个关键：测试时增加算力往往导致推理轨迹冗余，而系统性、递进式的推理（如有结构的Chain-of-Thought）又与人类推理类似，能够提升推理质量，论文旨在剖析这两因素在模型泛化中的作用。

Method: 在多层图的最短路径任务上，设计了受控的实验环境，采用定制tokenizer和decoder-only transformer，训练于问题-推理轨迹-答案三元组。对比了用最优动态规划trace和包含回溯的冗长但有效trace进行训练的表现，并探讨了引入随机冗余对性能的影响。

Result: 用冗长但递进的推理轨迹进行训练的模型，比用最优trace训练的模型对新图有更好的泛化能力。该提升并非trace长度导致，随机冗余反而有害，关键在于推理过程的连贯性与局部增量性。泛化效果与模型在预测下一个token时的置信度正相关。

Conclusion: 模型在训练过程中，如果采用冗长但逻辑连贯、局部递进式的推理轨迹（而不是最优或随机冗余轨迹），其泛化能力会更好。泛化提升与trace长度本身无关，而在于推理过程的连贯性和增量性，这样的训练信号更易于模型优化。

Abstract: Recent advances in natural language processing highlight two key factors for
improving reasoning in large language models (LLMs): (i) allocating more
test-time compute tends to help on harder problems but often introduces
redundancy in the reasoning trace, and (ii) compute is most effective when
reasoning is systematic and incremental, forming structured chains of thought
(CoTs) akin to human problem-solving. To study these factors in isolation, we
introduce a controlled setting based on shortest-path tasks in layered graphs.
We train decoder-only transformers on question-trace-answer triples using a
custom tokenizer, comparing models trained on optimal bottom-up dynamic
programming traces with those trained on longer, valid traces involving
backtracking. Surprisingly, with the same training-token budget, models trained
on inefficient traces generalize better to unseen graphs. This benefit is not
due to length alone-injecting arbitrary redundancy into reasoning traces fails
to help and can even hurt performance. Instead, we find that generalization
correlates with the model's confidence in next-token prediction, suggesting
that long, coherent, and locally incremental traces make the training signal
easier to optimize.

</details>


### [27] [EduCoder: An Open-Source Annotation System for Education Transcript Data](https://arxiv.org/abs/2507.05385)
*Guanzhong Pan,Mei Tan,Hyunji Nam,Lucía Langlois,James Malamut,Liliana Deonizio,Dorottya Demszky*

Main category: cs.CL

TL;DR: EduCoder是一个面向教育对话逐句标注的开源平台，支持复杂代码本定义、多种标注类型及多标注者对比，极大提升了教育领域对话标注的效率与可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本标注工具难以满足教育对话的复杂标注需求，例如多样的师生和同伴互动、复杂的教学性特征编码，以及结合语境信息（如课程目的、教学价值）。因此，亟需一个专门支持教育对话逐句标注的工具。

Method: 研发了EduCoder，一个支持教育对话逐句标注的平台，该平台允许用户协作定义复杂代码本、支持多种标注类型（分类和开放式）、结合上下文信息，并能多标注者并排对比进行标注校准。

Result: EduCoder不仅能够满足复杂教育对话的标注需求，还提升了标注结果的可靠性，目前已开源，并有演示视频。

Conclusion: EduCoder平台有效地解决了教育对话标注中的一系列难点，为相关领域研究人员和专家合作标注提供了强有力工具。

Abstract: We introduce EduCoder, a domain-specialized tool designed to support
utterance-level annotation of educational dialogue. While general-purpose text
annotation tools for NLP and qualitative research abound, few address the
complexities of coding education dialogue transcripts -- with diverse
teacher-student and peer interactions. Common challenges include defining
codebooks for complex pedagogical features, supporting both open-ended and
categorical coding, and contextualizing utterances with external features, such
as the lesson's purpose and the pedagogical value of the instruction. EduCoder
is designed to address these challenges by providing a platform for researchers
and domain experts to collaboratively define complex codebooks based on
observed data. It incorporates both categorical and open-ended annotation types
along with contextual materials. Additionally, it offers a side-by-side
comparison of multiple annotators' responses, allowing comparison and
calibration of annotations with others to improve data reliability. The system
is open-source, with a demo video available.

</details>


### [28] [The Generalization Ridge: Information Flow in Natural Language Generation](https://arxiv.org/abs/2507.05387)
*Ruidi Chang,Chunyuan Deng,Hanjie Chen*

Main category: cs.CL

TL;DR: 本文通过信息论视角（InfoRidge）分析Transformer模型，发现模型泛化能力依赖于中上层（而非最终层），并提出残差缩放系数作为功能性探针验证了该机制。


<details>
  <summary>Details</summary>
Motivation: 虽然Transformer模型在自然语言生成任务中表现出色，但其内部的任务相关信息整合机制尚不清楚，尤其是中间层如何实现泛化能力以及相关信息如何随层传播。

Method: 提出InfoRidge这一信息论框架，通过估算Transformer中隐表示与目标输出之间的互信息，追踪模型训练过程中任务相关信息在各层的流动。同时引入可训练的残差缩放系数，以功能性探针评估各层相对重要性并研究在分布偏移下的作用变化。

Result: 实验证明，任务相关的预测信息在中上层达到峰值（形成“泛化脊”，generalization ridge），在最终层下降，表明模型由泛化转向记忆。残差缩放系数分析表明，面对分布偏移时，模型会减弱对最终层的依赖，更依赖于脊层，凸显中间层在泛化中的关键作用。

Conclusion: 提出了可量化和可解释的分析方法，揭示了Transformer模型泛化能力主要依赖于中间层，并对其内部机制提供了新的洞见。

Abstract: Transformer-based language models have achieved state-of-the-art performance
in natural language generation (NLG) tasks, yet their internal mechanisms for
synthesizing task-relevant information remain insufficiently understood. While
prior studies suggest that intermediate layers often yield more generalizable
representations than final layers, how this generalization ability emerges and
propagates across layers during training remains unclear. To address this gap,
we propose InfoRidge, an information-theoretic framework, to characterize how
predictive information-the mutual information between hidden representations
and target outputs-varies across depth. Estimating this quantity enables us to
trace the flow of task-relevant information throughout the model during
training. Our experiments across various models and datasets reveal a
consistent non-monotonic trend: predictive information peaks in upper-middle
layers-forming a generalization ridge-before declining in final layers,
reflecting a transition between generalization and memorization. To further
investigate this phenomenon, we introduce residual scaling
coefficients-trainable scalar parameters applied to each residual block-which
serve as functional probes for assessing the relative importance of individual
transformer layers. These coefficients reveal that, under distribution shift,
models downweight final layers and increasingly rely on ridge layers,
highlighting their role in generalization. Together, these findings offer new
insights into the internal mechanisms of transformers and underscore the
critical role of intermediate layers in supporting generalization.

</details>


### [29] [Controlling What You Share: Assessing Language Model Adherence to Privacy Preferences](https://arxiv.org/abs/2507.05391)
*Guillem Ramírez,Alexandra Birch,Ivan Titov*

Main category: cs.CL

TL;DR: 本文提出利用自然语言隐私指令重写查询以保护隐私的框架，并以PEEP数据集支持实验。结果显示，轻量级LLMs在隐私遵循上仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 面对通过商业API访问LLM时用户数据隐私泄露的风险，旨在为用户提供更大数据控制权，并平衡隐私保护与模型性能。

Method: 提出并实现了一个利用本地模型根据用户自然语言隐私指令重写查询的框架，引入了PEEP多语言数据集，用于训练和评估隐私内容的标注与处理能力。在实验中，采用轻量级LLMs评估系统性能。

Result: 实验表明，当前轻量级LLMs能够按照隐私指令部分隐藏敏感信息，对隐私偏好的理解与遵循能力有待提升。

Conclusion: 轻量级大语言模型（LLMs）能够在一定程度上按照用户自然语言隐私指令对查询进行重写，但在理解和服从用户隐私偏好方面仍存在明显挑战。

Abstract: Large language models (LLMs) are primarily accessed via commercial APIs, but
this often requires users to expose their data to service providers. In this
paper, we explore how users can stay in control of their data by using privacy
profiles: simple natural language instructions that say what should and should
not be revealed. We build a framework where a local model uses these
instructions to rewrite queries, only hiding details deemed sensitive by the
user, before sending them to an external model, thus balancing privacy with
performance. To support this research, we introduce PEEP, a multilingual
dataset of real user queries annotated to mark private content and paired with
synthetic privacy profiles. Our experiments with lightweight LLMs show they can
follow these instructions to some extent, but also face consistent challenges,
highlighting the need for models that better understand and comply with
user-defined privacy preferences.

</details>


### [30] [Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning](https://arxiv.org/abs/2507.05418)
*Jaedong Hwang,Kumar Tanmay,Seok-Jin Lee,Ayush Agrawal,Hamid Palangi,Kumar Ayush,Ila Fiete,Paul Pu Liang*

Main category: cs.CL

TL;DR: 论文提出了新的多语言推理基准GeoFact-X和BRIDGE训练方法，通过引入语言一致性约束和自动评测机制，显著提升了LLM在多语言，特别是低资源语言下的推理能力和一致性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在诸如数学、事实问答和代码生成等领域表现出色，但其在多语言推理能力，尤其是在低资源语言（如斯瓦希里语或泰语）方面仍然薄弱，常常将推理过程默认为英语。传统多语言基准只关注最终答案，忽略了模型是否实际在目标语言进行推理，这影响了准确性和可信度。

Method: 提出了GeoFact-X，一个包含五种语言（英语、印地语、日语、斯瓦希里语和泰语）的地理常识多语言推理基准，并提供标注推理过程。同时，提出BRIDGE训练方法，通过引入语言一致性奖励，结合有监督微调和测试时强化学习，将模型推理过程与输入语言更好对齐。最后，利用LLM自动评判系统，评价答案正确性及推理过程的语言一致性和质量。

Result: 实验表明，BRIDGE方法显著提升了多语言推理的准确性和一致性，尤其在低资源语言上表现突出，强化了跨语言泛化能力。

Conclusion: 推理感知的多语言强化学习对于提升大模型跨语言推理能力至关重要，提出的方法有效提升了多语言推理的表现和可信度。

Abstract: Large Language Models (LLMs) have achieved strong performance in domains like
mathematics, factual QA, and code generation, yet their multilingual reasoning
capabilities in these tasks remain underdeveloped. Especially for low-resource
languages such as Swahili or Thai, LLMs can often misinterpret prompts or
default to reasoning in English. This implicit bias toward high-resource
languages undermines factual accuracy, interpretability, and trust. Current
multilingual benchmarks focus only on final answers, overlooking whether models
actually reason in the target language. To address this gap, we introduce
GeoFact-X, a geography-based multilingual factual reasoning benchmark with
annotated reasoning traces in five languages: English, Hindi, Japanese,
Swahili, and Thai. We further propose BRIDGE, a novel training method that
guides supervised fine-tuning and test-time reinforcement learning with a
language-consistency reward to align reasoning with the input language.
Finally, we develop an automatic evaluation protocol using LLM-as-a-judge to
assess answer correctness and the quality and language consistency of reasoning
traces, enabling nuanced and scalable analysis beyond surface-level metrics.
Our results show that BRIDGE significantly enhances multilingual reasoning
fidelity, demonstrating that reasoning-aware multilingual reinforcement
learning is crucial for robust cross-lingual generalization.
https://jd730.github.io/projects/GeoFact-X_BRIDGE

</details>


### [31] ["Lost-in-the-Later": Framework for Quantifying Contextual Grounding in Large Language Models](https://arxiv.org/abs/2507.05424)
*Yufei Tao,Adam Hiatt,Rahul Seetharaman,Ameeta Agrawal*

Main category: cs.CL

TL;DR: 本论文提出CoPE评测框架，发现大语言模型在理解上下文时易忽略后部信息，链式思考不但无效反而有害。合理设计提示词能改善事实准确性和减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型可利用参数知识和语境知识，但两者如何被整合和优先级分配尚缺乏系统性研究，尤其是在多语言条件和复杂推理任务下。

Method: 作者提出了CoPE评测框架，结合MultiWikiAtomic多语言数据集，定量分析了大语言模型中情境知识（CK）和参数知识（PK）的整合方式，同时设计案例（如摘要任务）对提升模型的上下文利用进行实验。

Result: 发现模型存在明显的位置信息偏向，对后部上下文利用不足（lost-in-the-later现象），且链式思考提示未能缓解该问题。通过CK导向的提问设计，显著提升了事实性和减少了幻觉。

Conclusion: 通过构建CoPE评测框架，论文发现大语言模型存在“lost-in-the-later”现象，即模型对于语境中较晚出现的信息容易忽略或低估，表现出较强的位置性偏差，影响了其对上下文的利用和事实准确性。链式思考（CoT）提示反而进一步弱化了对语境的利用。基于这些发现，论文设计了基于提示的方法，更有效地利用输入语境。

Abstract: Large language models are capable of leveraging both contextual and
parametric knowledge but how they prioritize and integrate these sources
remains underexplored. We introduce CoPE, a novel evaluation framework that
systematically measures contextual knowledge (CK) and parametric knowledge (PK)
across models and languages. Using our MultiWikiAtomic dataset in English,
Spanish, and Danish, we analyze how large language models (LLMs) integrate
context, prioritize information, and incorporate PK in open-ended question
answering. Our analysis uncovers a phenomenon we call lost-in-the-later, where
LLMs tend to overlook or deprioritize information that appears later in a given
context, revealing a strong positional bias that affects contextual grounding.
We further find that reasoning models, as well as non-reasoning models prompted
with chain-of-thought (CoT), use context even less than non-reasoning models
without CoT and fail to mitigate the lost-in-the-later effect. CoT prompting,
in particular, results in lower recall and shorter responses, leading to
degraded contextual grounding. Based on these insights, we design prompt-based
methods to effectively leverage input context. A case study applying CoPE to
summarization demonstrates that CK-informed prompting improves factual
grounding and reduces hallucination.

</details>


### [32] [Gendered Divides in Online Discussions about Reproductive Rights](https://arxiv.org/abs/2507.05443)
*Ashwin Rao,Sze Yuh Nina Wang,Kristina Lerman*

Main category: cs.CL

TL;DR: 本研究分析X平台近千万条堕胎相关帖子，揭示性别在堕胎态度及情感表达中的调节作用，尤其在保守地区使性别分歧扩大，Dobbs裁决泄露更动员了女性参与，显示性别和地方特征在堕胎争论与政治表达中的核心角色。


<details>
  <summary>Details</summary>
Motivation: 最高法院2022年在Dobbs v. Jackson Women's Health Organization的裁决加剧了围绕堕胎权利的国家争论，学界已关注到意识形态分歧，但性别和地方社会政治背景的交互对堕胎态度及情绪表达的影响仍了解有限。

Method: 收集分析近1000万条与堕胎有关、含有推断性别、意识形态和地理位置信息的X（前Twitter）平台用户帖子，考察性别、意识形态和地区如何共同影响公众关于堕胎的态度及情绪表达。

Result: 研究发现，性别对堕胎态度和情感表达具有显著调节作用，这种影响在保守地区尤为突出且独立于意识形态，导致保守地区堕胎态度的性别差距扩大。Dobbs裁决泄露进一步激发了网上讨论，尤其动员了受威胁地区的支持堕胎女性。

Conclusion: 堕胎相关话语不仅呈现意识形态两极分化，还受到性别与区域的深刻结构性影响，身份因素在制度性变动期间对政治表达有重要作用。

Abstract: The U.S. Supreme Court's 2022 ruling in Dobbs v. Jackson Women's Health
Organization marked a turning point in the national debate over reproductive
rights. While the ideological divide over abortion is well documented, less is
known about how gender and local sociopolitical contexts interact to shape
public discourse. Drawing on nearly 10 million abortion-related posts on X
(formerly Twitter) from users with inferred gender, ideology and location, we
show that gender significantly moderates abortion attitudes and emotional
expression, particularly in conservative regions, and independently of
ideology. This creates a gender gap in abortion attitudes that grows more
pronounced in conservative regions. The leak of the Dobbs draft opinion further
intensified online engagement, disproportionately mobilizing pro-abortion women
in areas where access was under threat. These findings reveal that abortion
discourse is not only ideologically polarized but also deeply structured by
gender and place, highlighting the central role of identity in shaping
political expression during moments of institutional disruption.

</details>


### [33] [PhoniTale: Phonologically Grounded Mnemonic Generation for Typologically Distant Language Pairs](https://arxiv.org/abs/2507.05444)
*Sana Kang,Myeongseok Gwon,Su Young Kwon,Jaewook Lee,Andrew Lan,Bhiksha Raj,Rita Singh*

Main category: cs.CL

TL;DR: 本文提出了一种基于声韵相似与大语言模型的跨语种助记法自动生成系统PhoniTale，并通过多种评测手段证实其效果与人工助记法相当，为二语词汇习得提供了有效的新工具，并指出了未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 第二语言学习者在习得词汇时，尤其是在学习如英语和韩语等类型距离较远的语言时，会面临声韵和结构上的障碍。利用大语言模型（LLMs）通过母语关键词辅助记忆来促进词汇习得是个新兴方向，但多数已有研究关注的是英语母语者学习他语，而不是反向情形。

Method: 提出了PhoniTale系统，该系统利用声韵相似性在学习者母语中检索关键词序列，并结合LLMs生成助记法。通过自动化指标和人工评估将PhoniTale与人工生成和以往自动化方法的助记法进行对比，同时设计了短期回忆测试评估其实际效果。

Result: PhoniTale系统在助记法效果上与人类作者的结果持平，显示出良好的应用前景。

Conclusion: PhoniTale系统在帮助二语学习者习得词汇方面有效，且其自动生成的助记法与人工生成结果相当。研究同时指出了未来在助记法质量与方法改进上的关键方向。

Abstract: Vocabulary acquisition poses a significant challenge for second-language (L2)
learners, especially when learning typologically distant languages such as
English and Korean, where phonological and structural mismatches complicate
vocabulary learning. Recently, large language models (LLMs) have been used to
generate keyword mnemonics by leveraging similar keywords from a learner's
first language (L1) to aid in acquiring L2 vocabulary. However, most of this
research has focused on native English speakers learning other languages,
rather than the reverse. In this paper, we present PhoniTale, a novel
cross-lingual mnemonic generation system that retrieves L1 keyword sequence
based on phonological similarity and uses LLMs to generate mnemonics. We
evaluate PhoniTale using both automated metrics and human evaluations,
comparing its output to mnemonics created by humans and by previous automated
approaches. To assess practical effectiveness, we also conduct a short-term
recall test measuring mnemonic helpfulness. Our findings show that PhoniTale
performs comparably to human-authored mnemonics. We also highlight key areas
for future improvement in mnemonic quality and methodology.

</details>


### [34] [On the Semantics of Large Language Models](https://arxiv.org/abs/2507.05448)
*Martin Schuele*

Main category: cs.CL

TL;DR: 本文通过理论与实证分析，讨论了大语言模型在词句语义上的理解水平，并指出其虽然具备一定的语义处理能力，但距离真正的语言理解仍有差距。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）如ChatGPT在仿真人类语言能力方面表现出色，但它们是否真正理解语言仍然存在争议。本文希望通过深入研究LLM在词汇和句子层面的语义能力，厘清其“理解”程度。

Method: 作者通过分析LLM的内部机制及其生成的语言表征，并结合Frege和Russell等经典语义理论，对比LLM语义能力与传统语言学理论进行深入探讨。

Result: 研究揭示了LLM在生成语言和表示语义时的一些潜在能力，同时通过与经典语义理论的对比，发现LLM在某些方面表现出接近传统语义理解的特性，但在“真正理解”语言方面仍存在一定局限。

Conclusion: LLM在词汇和句子层面上展现出复杂的语义表征能力，但尚未完全达到人类对语言“真正理解”的标准。该研究为认知LLM的语义能力提供了更细致的视角。

Abstract: Large Language Models (LLMs) such as ChatGPT demonstrated the potential to
replicate human language abilities through technology, ranging from text
generation to engaging in conversations. However, it remains controversial to
what extent these systems truly understand language. We examine this issue by
narrowing the question down to the semantics of LLMs at the word and sentence
level. By examining the inner workings of LLMs and their generated
representation of language and by drawing on classical semantic theories by
Frege and Russell, we get a more nuanced picture of the potential semantic
capabilities of LLMs.

</details>


### [35] [ModelCitizens:Representing Community Voices in Online Safety](https://arxiv.org/abs/2507.05455)
*Ashima Suvarna,Christina Chance,Hamid Palangi,Sophie Hao,Thomas Hartvigsen,Saadia Gabriel*

Main category: cs.CL

TL;DR: 该论文提出了多身份、多语境的毒性检测数据集，证明主流模型在该任务上表现有限，并通过微调新模型显著提升了检测性能，强调了社区语境和差异化标注的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的有毒语言检测模型大多将不同注释者的观点合并为单一标准，忽视了不同社区和身份群体对有毒语言的多样理解，特别是在社交媒体环境下，语境和群体体验对毒性判定有重要影响。该研究希望解决主流数据集和模型在语境适应性和包容性上的局限。

Method: 该研究构建了MODELCITIZENS数据集，包含6800条社交媒体帖子和4万条跨多元身份群体的毒性标注，并通过大语言模型（LLM）生成对话语境增强原始帖子。作者还基于MODELCITIZENS微调了LLaMA和Gemma模型，分别发布了LLAMACITIZEN-8B和GEMMACITIZEN-12B。

Result: 主流毒性检测工具（如OpenAI Moderation API，GPT-o4-mini）在MODELCITIZENS数据集上的表现较差，并且在加入对话语境后表现进一步下降。作者训练的LLAMACITIZEN-8B和GEMMACITIZEN-12B模型在分布内评估中比GPT-o4-mini高出5.5%。

Conclusion: 社区知情的标注和针对性建模对于实现更具包容性的内容审核至关重要，通用模型在多元语境和人群下效果有限。通过丰富多元和有上下文的信息，能够显著提升毒性检测的准确性和公平性。

Abstract: Automatic toxic language detection is critical for creating safe, inclusive
online spaces. However, it is a highly subjective task, with perceptions of
toxic language shaped by community norms and lived experience. Existing
toxicity detection models are typically trained on annotations that collapse
diverse annotator perspectives into a single ground truth, erasing important
context-specific notions of toxicity such as reclaimed language. To address
this, we introduce MODELCITIZENS, a dataset of 6.8K social media posts and 40K
toxicity annotations across diverse identity groups. To capture the role of
conversational context on toxicity, typical of social media posts, we augment
MODELCITIZENS posts with LLM-generated conversational scenarios.
State-of-the-art toxicity detection tools (e.g. OpenAI Moderation API,
GPT-o4-mini) underperform on MODELCITIZENS, with further degradation on
context-augmented posts. Finally, we release LLAMACITIZEN-8B and
GEMMACITIZEN-12B, LLaMA- and Gemma-based models finetuned on MODELCITIZENS,
which outperform GPT-o4-mini by 5.5% on in-distribution evaluations. Our
findings highlight the importance of community-informed annotation and modeling
for inclusive content moderation.

</details>


### [36] [Empowering Healthcare Practitioners with Language Models: Structuring Speech Transcripts in Two Real-World Clinical Applications](https://arxiv.org/abs/2507.05517)
*Jean-Philippe Corbeil,Asma Ben Abacha,George Michalopoulos,Phillip Swazinna,Miguel Del-Agua,Jerome Tremblay,Akila Jeeson Daniel,Cari Bader,Kevin Cho,Pooja Krishnan,Nathan Bodenstab,Thomas Lin,Wenxuan Teng,Francois Beaulieu,Paul Vozila*

Main category: cs.CL

TL;DR: 本文首次系统研究了护士口述结构化报告和医疗医嘱抽取两大医疗NLP任务，提出代理流程生成数据，实测多种大语言模型，发布了重要的开源数据集，为领域研究和实际应用带来重要推动。


<details>
  <summary>Details</summary>
Motivation: 护士口述生成结构化表格和医生-患者会诊中医疗医嘱抽取这两项高影响力任务因数据稀缺和敏感始终未得到充分探究。有效解决这些实际问题，可减少医护文书负担，让护理人员更专注于病患护理。

Method: 针对真实世界的临床NLP任务，评估了开源和私有的大语言模型在护士口述结构化报告和医生医嘱抽取上的表现，并设计了一种生成现实、非敏感护士口述的代理性流程。

Result: 提出了创新的代理流程用于生成护士口述，验证了不同LLMs在两大任务上的性能，并首次公开了相关的开源数据集SYNUR和SIMORD，促进社区后续研究。

Conclusion: 本文提出的方法和开放数据集能够有效推动护士口述结构化报告和医疗医嘱抽取两大医疗NLP任务的研究，并有望缓解医疗文档工作负担。

Abstract: Large language models (LLMs) such as GPT-4o and o1 have demonstrated strong
performance on clinical natural language processing (NLP) tasks across multiple
medical benchmarks. Nonetheless, two high-impact NLP tasks - structured tabular
reporting from nurse dictations and medical order extraction from
doctor-patient consultations - remain underexplored due to data scarcity and
sensitivity, despite active industry efforts. Practical solutions to these
real-world clinical tasks can significantly reduce the documentation burden on
healthcare providers, allowing greater focus on patient care. In this paper, we
investigate these two challenging tasks using private and open-source clinical
datasets, evaluating the performance of both open- and closed-weight LLMs, and
analyzing their respective strengths and limitations. Furthermore, we propose
an agentic pipeline for generating realistic, non-sensitive nurse dictations,
enabling structured extraction of clinical observations. To support further
research in both areas, we release SYNUR and SIMORD, the first open-source
datasets for nurse observation extraction and medical order extraction.

</details>


### [37] [Enhancing Test-Time Scaling of Large Language Models with Hierarchical Retrieval-Augmented MCTS](https://arxiv.org/abs/2507.05557)
*Alex ZH Dou,Zhongwei Wan,Dongfei Cui,Xin Wang,Jing Xiong,Haokun Lin,Chaofan Tao,Shen Yan,Mi Zhang*

Main category: cs.CL

TL;DR: 提出R2-LLMs，一种无须模型蒸馏的分层检索增强推理方法，通过粗细两级检索和推理增强，显著提升了大模型在数学及复杂问题上的推理能力，实验验证其效果优越。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在推理和复杂数学问题上，通常需要更多样的数据或更强模型的知识蒸馏来提升推理能力，推理增强与测试时扩展尚未充分挖掘高效利用检索的信息。

Method: 提出R2-LLMs，一个分层的基于检索增强推理的推理框架。具体做法：1）在粗粒度层面，从复杂问题中抽象模板，检索类似的问题-答案对以实现高层次的in-context学习；2）在细粒度层面，MCTS搜索过程中从参考数据集中检索类似的中间过程步骤，并通过过程奖励模型（PRM）评分，提升逐步推理。该方法可无缝与树搜索结合，并利用PRM优化候选生成和决策过程。

Result: 在MATH500、GSM8K和OlympiadBench-TO等数据集上，使用LLaMA-3.1-8B模型，R2-LLMs在复杂推理任务中相较于基线方案取得了高达16%的相对提升。

Conclusion: R2-LLMs作为一种分层的检索增强推理方法，无需高阶模型的蒸馏，即可显著提升大语言模型在复杂推理任务上的泛化和推理表现。

Abstract: Test-time scaling has emerged as a promising paradigm in language modeling,
leveraging additional computational resources at inference time to enhance
model performance. In this work, we introduce R2-LLMs, a novel and versatile
hierarchical retrieval-augmented reasoning framework designed to improve
test-time scaling in large language models (LLMs) without requiring
distillation from more advanced models to obtain chain-of-thought (CoT)
training data. R2-LLMs enhances inference-time generalization by integrating
dual-level retrieval-based in-context learning: (1) At the coarse level, our
approach extracts abstract templates from complex reasoning problems and
retrieves similar problem-answer pairs to facilitate high-level in-context
learning; (2) At the fine level, during Monte Carlo Tree Search (MCTS), R2-LLMs
efficiently retrieves analogous intermediate solution steps from reference
mathematical problem datasets, refining step-wise reasoning with the aid of a
process reward model (PRM) for scoring. R2-LLMs is a robust hierarchical
reasoning-augmentation method that enhances in-context-level reasoning while
seamlessly integrating with step-level tree search methods. Utilizing PRM, it
refines both candidate generation and decision-making for improved reasoning
accuracy. Empirical evaluations on the MATH500, GSM8K, and OlympiadBench-TO
datasets achieve substantial relative improvement with an increase of up to 16%
using LLaMA-3.1-8B compared to the baselines, showcasing the effectiveness of
our approach in complex reasoning tasks.

</details>


### [38] [Self-Review Framework for Enhancing Instruction Following Capability of LLM](https://arxiv.org/abs/2507.05598)
*Sihyun Park*

Main category: cs.CL

TL;DR: 为解决大语言模型遵循复杂指令难、修订成本高的问题，作者提出了Re5自评与修订框架，通过分步结构化自评和选择性内容修订，实验证明其在保持高输出质量的同时，提升了模型的指令遵循表现，且资源高效。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在遵循格式和指令约束方面存在不足，且高质量生成数据依赖强大模型但成本高，迭代修订方法虽然有效但是金钱和效率成本很大。现有利用外部评价工具的替代方法又容易导致内容质量下降。

Method: 提出了一种名为Re5的自评与修订框架。Re5从用户指令中提取任务及约束部分，进行结构化评估以防止错误累积，并进行细粒度的约束相关内容评估与选择性修订，以保证生成内容的高质量。最终输出还用于模型对齐微调，以实现数据驱动的逐步优化。

Result: 实验表明，Re5能够在仅使用少量数据的情况下，其指令遵循能力可媲美基于更高性能模型（如GPT-4o-mini）生成数据训练出的模型，同时在回复质量上，相比未修订的初始输出有64.24%的胜率。

Conclusion: Re5能高效提升大模型对指令的遵循度，并在较低的外部监督和资源成本下，实现了优质内容生成和持续对齐优化。

Abstract: Various techniques have been proposed to improve large language models (LLMs)
adherence to formatting and instruction constraints. One of the most effective
approaches involves utilizing high-quality data generated by powerful models.
However, such models often fail to fully comply with complex instructions in a
single generation. To address this limitation, iterative revision methods have
been introduced. Nevertheless, as the number of data points and revision
iterations increases, the associated monetary costs grow significantly. As a
resource-efficient alternative, methods have been proposed that leverage
high-performance evaluation tools to compensate for the limited self-evaluation
capabilities of open-source LLMs. However, these approaches often lead to a
degradation in output quality due to excessive revision. To overcome these
challenges, we propose Re5, a self-evaluation and revision framework designed
to enhance instruction-following performance while preserving the quality of
the generated content. Re5 extracts task and constraint components from user
instructions, performs structural evaluations to prevent error accumulation,
and applies fine-grained constraint-specific content evaluations followed by
selective revisions. This process ensures precise and quality-preserving
improvements. The final high-quality outputs are used for alignment tuning,
enabling long-term alignment improvements through a data-centric iterative
refinement loop. Experimental results demonstrate that Re5 achieves
instruction-following performance comparable to models trained on data
generated by GPT-4o-mini, a high-performance model, even with a small amount of
data while maintaining response quality with a 64.24%-win rate over the
non-revised initial responses. These results validate Re5 as an efficient and
effective solution for enhancing instruction adherence with minimal external
supervision.

</details>


### [39] [Flipping Knowledge Distillation: Leveraging Small Models' Expertise to Enhance LLMs in Text Matching](https://arxiv.org/abs/2507.05617)
*Mingzhe Li,Jing Xiang,Qishen Zhang,Kaiyang Wan,Xiuying Chen*

Main category: cs.CL

TL;DR: 该论文提出大模型向小模型学习的反向知识蒸馏方法，通过结构适配和新型对比损失，有效提升大模型在领域特定任务中的表现，并已验证其实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 在文本匹配等任务中，经过微调的小模型往往能获得更有效的领域相关表示，尽管目前知识蒸馏大多是从大模型向小模型传递知识。论文尝试结合小模型的特长和大模型的语义理解能力。

Method: 提出了一种“反向知识蒸馏”范式，让大语言模型（LLM）向小语言模型（SLM）学习。采用LoRA重新解释大模型为编码器-解码器结构，设计Margin-aware Contrastive Learning（MCL）方法对正负样本的相似度进行精细化对齐。

Result: 在金融和医疗等基准数据集及真实场景中实验验证了新范式的有效性，并已实现线上部署。

Conclusion: 反向知识蒸馏可以兼顾大模型和小模型的优点，提升了LLM在特定任务中的表现，方法已在实际生产环境中取得成效。

Abstract: Knowledge distillation typically involves transferring knowledge from a Large
Language Model (LLM) to a Smaller Language Model (SLM). However, in tasks such
as text matching, fine-tuned smaller models often yield more effective
domain-specific representations, as they focus on optimizing the similarity of
input pairs. To leverage both the specialized strengths of small models and the
rich semantic understanding of LLMs, we introduce a flipped knowledge
distillation paradigm, where LLM learns from SLM. Specifically, we address the
architectural gap between decoder-only LLMs and smaller encoder-based models by
reinterpreting LLMs in an encoder-decoder manner using LoRA. The encoder
generates compressed representations, while the decoder maps them to the output
space. During training, the encoder produces representations and their
similarities, which are then aligned with the similarity scores produced by the
teacher, using our proposed Margin-aware Contrastive Learning (MCL) approach.
The MCL ensures accurate similarity for both positive and negative pairs, and
adaptively handles the internal differences within positive and negative
samples. Our paradigm requires only a reasonably good-performing SLM, allowing
the LLM to achieve improved performance. Experiments on financial and
healthcare benchmarks, as well as real-world applications, confirm its
effectiveness, and the model has been fully deployed in an online environment.

</details>


### [40] [SARA: Selective and Adaptive Retrieval-augmented Generation with Context Compression](https://arxiv.org/abs/2507.05633)
*Yiqiao Jin,Kartik Sharma,Vineeth Rakesh,Yingtong Dou,Menghai Pan,Mahashweta Das,Srijan Kumar*

Main category: cs.CL

TL;DR: SARA是一种结合文本与语义压缩向量的新型RAG方法，在有限上下文下显著提升了答案准确性与相关性，适用于多种开源大模型。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）方法在利用外部知识提升大语言模型能力时，往往受限于有效上下文长度有限以及检索文档冗余问题。简单依靠压缩虽然能减少输入大小，但会丢失事实性强的细粒度细节，影响准确性。

Method: 提出SARA，一个统一的RAG框架，通过结合自然语言片段和语义压缩向量，使得在有限的上下文预算下，能够兼顾本地精度和全局知识覆盖。SARA将上下文表示为细粒度文本片段与高层语义压缩向量，并采用迭代证据选择模块进行动态上下文重排。

Result: 在9个数据集、5个开源大语言模型（涵盖Mistral、Llama、Gemma三大模型家族）中，SARA在答案相关性、正确性和语义相似性上分别提高了+17.71、+13.72、+15.53，有效提升了RAG系统在有限上下文下的表现。

Conclusion: SARA通过整合文本与压缩表示，有效提升了RAG的上下文利用效率和答案准确性，展现出更强的鲁棒性和推广能力。

Abstract: Retrieval-augmented Generation (RAG) extends large language models (LLMs)
with external knowledge but faces key challenges: restricted effective context
length and redundancy in retrieved documents. Pure compression-based approaches
reduce input size but often discard fine-grained details essential for factual
accuracy. We propose SARA, a unified RAG framework that balances local
precision and global knowledge coverage under tight context budgets. SARA
combines natural-language text snippets with semantic compression vectors to
jointly enhance context efficiency and answer correctness. It represents
contexts at two complementary levels: 1) fine-grained natural-language spans
that preserve critical entities and numerical values, and 2) compact,
interpretable vectors that summarize high-level semantics. An iterative
evidence-selection module employs the compression vectors for dynamic reranking
of contexts. Across 9 datasets and 5 open-source LLMs spanning 3 model families
(Mistral, Llama, and Gemma), SARA consistently improves answer relevance
(+17.71), answer correctness (+13.72), and semantic similarity (+15.53),
demonstrating the importance of integrating textual and compressed
representations for robust, context-efficient RAG.

</details>


### [41] [ECom-Bench: Can LLM Agent Resolve Real-World E-commerce Customer Support Issues?](https://arxiv.org/abs/2507.05639)
*Haoxin Wang,Xianhan Peng,Xucheng Huang,Yizhe Huang,Ming Gong,Chenghan Yang,Yang Liu,Ling Jiang*

Main category: cs.CL

TL;DR: 本文提出了电商客户支持领域首个多模态LLM评测基准ECom-Bench，结合真实数据和复杂任务，挑战性极高，有助于推动行业发展，后续将开源。


<details>
  <summary>Details</summary>
Motivation: 当前电商客户支持场景的多模态大模型（LLM agent）尚缺乏专门且具有挑战性的评测基准。现有基准无法有效衡量模型在真实电商环境的综合能力。

Method: 提出了一个名为ECom-Bench的评测框架，其中包含基于真实电商对话数据构建的用户画像动态模拟器及任务集合。涵盖多样且复杂的电商业务场景，并用真实用户数据与对话作为任务样本。

Result: 即使是最先进的大模型（如GPT-4o）在该基准上的通过率（pass^3 metric）仅为10%-20%，证明此框架极具挑战性、切合实际场景。

Conclusion: ECom-Bench填补了多模态大模型在电商客户支持领域评测的空白，有助于推动该领域方法的进步。相关代码与数据将开源，便于进一步的学术研究和技术开发。

Abstract: In this paper, we introduce ECom-Bench, the first benchmark framework for
evaluating LLM agent with multimodal capabilities in the e-commerce customer
support domain. ECom-Bench features dynamic user simulation based on persona
information collected from real e-commerce customer interactions and a
realistic task dataset derived from authentic e-commerce dialogues. These
tasks, covering a wide range of business scenarios, are designed to reflect
real-world complexities, making ECom-Bench highly challenging. For instance,
even advanced models like GPT-4o achieve only a 10-20% pass^3 metric in our
benchmark, highlighting the substantial difficulties posed by complex
e-commerce scenarios. Upon publication, the code and data will be open-sourced
to facilitate further research and development in this domain.

</details>


### [42] [Smoothie-Qwen: Post-Hoc Smoothing to Reduce Language Bias in Multilingual LLMs](https://arxiv.org/abs/2507.05686)
*SeungWon Ji,Jungyup Lee,Jemin Kim,Sang Park,SeungJae Lee*

Main category: cs.CL

TL;DR: Smoothie-Qwen是一种无需重训练的后处理方法，能显著减少模型生成的语言偏差，提升在多语言任务下的可靠性。


<details>
  <summary>Details</summary>
Motivation: 多语言大模型容易出现语言混淆现象，即无视提示语的语言而倾向于用主导语言生成回答。这导致在多语言场景下模型的实际应用表现不佳，需要提高不同语言的可控性。

Method: 提出Smoothie-Qwen方法，这是一种轻量化的后处理技术，无需重新训练模型。该方法通过选择性调整token级输出概率，有效抑制非期望语言的生成。

Result: 在Qwen模型上应用该方法后，减少了95%以上的非期望中文输出，并且在多语言基准测试上保持了任务准确度。

Conclusion: Smoothie-Qwen方法可大幅度提升大模型的语言可控性，适用于全球多语言应用场景，并不影响模型任务表现。

Abstract: Multilingual large language models (LLMs) often exhibit language confusion, a
tendency to generate responses in a dominant language irrespective of the
prompt's language. To address this, we propose Smoothie-Qwen, a lightweight,
post-hoc method that mitigates language bias without retraining. This technique
selectively adjusts token-level output probabilities to effectively suppress
undesired language generation. Applied to the Qwen model, our method reduces
unintended Chinese output by over 95% while preserving task accuracy on
multilingual benchmarks. This work provides a practical and efficient solution
for enhancing the language controllability of LLMs, making them more reliable
for global applications.

</details>


### [43] [Agentic-R1: Distilled Dual-Strategy Reasoning](https://arxiv.org/abs/2507.05707)
*Weihua Du,Pranjal Aggarwal,Sean Welleck,Yiming Yang*

Main category: cs.CL

TL;DR: DualDistill框架融合多种推理策略，训练出能动态选取推理方式的Agentic-R1，大幅提升了复杂推理任务的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有长链条推理模型在数学推理上表现优异，但依赖自然语言推导过程，速度慢且易出错；而工具增强的智能体虽然可以通过代码执行解决算数问题，但面对复杂逻辑任务时常常失效。因此需要一种能整合多种推理方式的方法，以提升整体推理能力。

Method: 本文提出了一种名为DualDistill的微调框架，该框架能够从多个教师模型提取互补的推理策略，融合到一个统一的学生模型中。最终训练得到Agentic-R1模型，能够针对不同类型的问题动态选择最佳推理方式，包括调用工具处理算术和算法问题，以及使用文本推理处理抽象问题。

Result: 所提出的方法不仅在计算密集型任务上取得了提升，在标准推理基准测试上同样表现优异，有效验证了多策略蒸馏方案在增强推理鲁棒性和效率方面的价值。

Conclusion: DualDistill方法能够有效提升模型在多种推理任务上的表现，特别是在涉及复杂逻辑和算法计算的问题上，通过融合多种推理策略，提高了推理的准确性和效率。

Abstract: Current long chain-of-thought (long-CoT) models excel at mathematical
reasoning but rely on slow and error-prone natural language traces.
Tool-augmented agents address arithmetic via code execution, but often falter
on complex logical tasks. We introduce a fine-tuning framework, DualDistill,
that distills complementary reasoning strategies from multiple teachers into a
unified student model. Using this approach, we train Agentic-R1, which
dynamically selects the optimal strategy for each query, invoking tools for
arithmetic and algorithmic problems, and using text-based reasoning for
abstract ones. Our method improves accuracy across a range of tasks, including
both computation-intensive and standard benchmarks, demonstrating the
effectiveness of multi-strategy distillation in achieving robust and efficient
reasoning. Our project is available at https://github.com/StigLidu/DualDistill

</details>


### [44] [DRAGON: Dynamic RAG Benchmark On News](https://arxiv.org/abs/2507.05713)
*Fedor Chernogorskii,Sergei Averkiev,Liliya Kudraleeva,Zaven Martirosian,Maria Tikhonova,Valentin Malykh,Alena Fenogenova*

Main category: cs.CL

TL;DR: 本文提出首个基于俄文新闻语料、自动动态更新的问题生成与评测体系DRAGON，公开评测工具和排行榜，推动RAG在非英文动态环境下的标准化研究。


<details>
  <summary>Details</summary>
Motivation: 现有RAG基准多集中于英文，其他语言（如俄语）相关评测资源稀缺且静态，无法反映实际应用中知识和语料动态变化的场景，因此亟需更贴近真实动态环境的俄文RAG评测资源。

Method: DRAGON基于定期更新的俄文新闻和公共文档语料，采用知识图谱自动生成多种类型的问题，通过自动化流程对RAG的检索和生成组件进行全面评测，并提供了自动问题生成管道和评测脚本。

Result: 成功构建了俄语新闻领域动态RAG评测基准DRAGON，并发布了完整的评测套件和动态排行榜，为研究社区提供了标准化、可扩展的多语言RAG评测工具。

Conclusion: 本文提出了DRAGON，这是首个针对俄文新闻语料实现动态评测的RAG系统基准。该基准为外部知识增强生成（RAG）系统在俄语环境下提供了系统性、动态的评测资源。框架及数据集已公开，并建立了排行榜鼓励社区参与。

Abstract: Retrieval-Augmented Generation (RAG) is a widely adopted approach for
improving the factuality of large language models (LLMs) by incorporating
external knowledge at inference time. Although there exist multiple RAG
benchmarks for English, evaluation resources for other languages, including
Russian, remain scarce and static, failing to capture the dynamic nature of
real-world deployments.
  In this work, we present DRAGON (Dynamic RAG Benchmark On News), the first
dynamic benchmark for evaluating RAG systems in Russian on a changing news
corpora. DRAGON is built upon a regularly updated corpus of Russian news and
public documents and supports comprehensive evaluation of both the retriever
and generator components. Question generation is performed automatically with
the use of Knowledge Graph constructed from the corpus and enables the
extraction of four core question types aligned with distinct subgraph patterns.
We release a complete evaluation framework comprising the pipeline for
automatic question generation, evaluation scripts, which are potentially
reusable for other languages and multilingual settings, and benchmark data. We
also launch a public leaderboard to encourage community participation and
comparison.

</details>


### [45] [HIRAG: Hierarchical-Thought Instruction-Tuning Retrieval-Augmented Generation](https://arxiv.org/abs/2507.05714)
*YiHan Jiao,ZheHao Tan,Dan Yang,DuoLin Sun,Jie Feng,Jian Wang,Peng Wei*

Main category: cs.CL

TL;DR: 本文提出了分层思维指令微调（HIRAG）RAG方法，通过渐进式Chain-of-Thought提升RAG生成质量，在多个基准任务上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG系统在提升生成模型处理实时信息和领域问题能力上存在不足，尤其是在细致关注于RAG任务和深入利用Chain-of-Thought思维流程方面研究较少。

Method: 提出了一种新的RAG模型指令微调方法——分层思维指令微调RAG（HIRAG）。该方法将“先思考后回答”策略与多层次渐进式Chain-of-Thought结合，分为过滤、信息组合和RAG特定推理三个层次能力。

Result: 实验表明，HIRAG训练策略在RGB、PopQA、MuSiQue、HotpotQA和PubmedQA等数据集上显著提升了模型表现。

Conclusion: 通过分层的思维链，HIRAG方法能够有效增强RAG模型的信息过滤、融合与推理能力，克服了传统RAG系统由于微调不深入而导致的性能瓶颈。

Abstract: Retrieval-augmented generation (RAG) has become a fundamental paradigm for
addressing the challenges faced by large language models in handling real-time
information and domain-specific problems. Traditional RAG systems primarily
rely on the in-context learning (ICL) capabilities of the large language model
itself. Still, in-depth research on the specific capabilities needed by the RAG
generation model is lacking, leading to challenges with inconsistent document
quality and retrieval system imperfections. Even the limited studies that
fine-tune RAG generative models often \textit{lack a granular focus on RAG
task} or \textit{a deeper utilization of chain-of-thought processes}. To
address this, we propose that RAG models should possess three progressively
hierarchical abilities (1) Filtering: the ability to select relevant
information; (2) Combination: the ability to combine semantic information
across paragraphs; and (3) RAG-specific reasoning: the ability to further
process external knowledge using internal knowledge. Thus, we introduce our new
RAG instruction fine-tuning method, Hierarchical-Thought Instruction-Tuning
Retrieval-Augmented Generation (HIRAG) incorporates a "think before answering"
strategy. This method enhances the model's open-book examination capability by
utilizing multi-level progressive chain-of-thought. Experiments show that the
HIRAG training strategy significantly improves the model's performance on
datasets such as RGB, PopQA, MuSiQue, HotpotQA, and PubmedQA.

</details>


### [46] [Omni-Router: Sharing Routing Decisions in Sparse Mixture-of-Experts for Speech Recognition](https://arxiv.org/abs/2507.05724)
*Zijin Gu,Tatiana Likhomanenko,Navdeep Jaitly*

Main category: cs.CL

TL;DR: 本文提出Omni-router Transformer，通过在MoE层间共享路由器增强多层专家合作，在ASR任务中表现优于传统密集和Switch Transformer模型，显著降低了词错误率并提升了鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统MoE（混合专家）方法中，每层的路由器是独立工作的，不同层之间的专家分配选择相关性弱。这限制了专家间的协作和专门化能力。

Method: 提出了一种在不同MoE层间共享路由器的架构，被称为“Omni-router Transformer”，以增强不同层之间专家的协作与专门化能力。

Result: 在大规模伪标注数据集和10个不同类别的ASR基准测试中，该模型表现优越，训练损失更低，平均词错误率相比Dense模型降低11.2%，相比Switch Transformer降低8.2%。并且专家分配结构性更强，对多样化数据更具鲁棒性。

Conclusion: Omni-router Transformer通过共享路由器增强了不同层专家的配合和专精度，在自动语音识别任务中取得了比现有模型更好的效果和泛化能力。

Abstract: Mixture-of-experts (MoE) architectures have expanded from language modeling
to automatic speech recognition (ASR). Traditional MoE methods, such as the
Switch Transformer, route experts independently within each layer. Our analysis
reveals that routers in most layers make expert choices that are not strongly
correlated with the choices of the routers in other layers. To increase the
cooperation between experts in different layers and encourage greater
specialization, we use a shared router across different MoE layers. We call
this model \emph{Omni-router Transformer}. Extensive experiments on a
large-scale pseudo-labeled dataset and evaluations across 10 diverse,
out-of-domain ASR benchmarks demonstrate that the Omni-router Transformer is
able to achieve lower training loss and consistently outperform dense and
Switch Transformer models, reducing average word error rates by 11.2% and 8.2%,
respectively, while providing structured expert usage and improved robustness
to diverse data.

</details>


### [47] [GPTKB v1.5: A Massive Knowledge Base for Exploring Factual LLM Knowledge](https://arxiv.org/abs/2507.05740)
*Yujia Hu,Tuan-Phong Nguyen,Shrestha Ghosh,Moritz Müller,Simon Razniewski*

Main category: cs.CL

TL;DR: 本文提出GPTKB v1.5，利用递归式大模型知识萃取技术，从GPT-4.1低成本高效生成了1亿三元组的知识库，可用于知识浏览、查询与分析，对理解和利用LLM知识具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型虽强大，但其内部事实知识难以被系统理解、浏览或统计分析，因此需开发新方法揭示其知识体系与边界。

Method: 采用 massive-recursive LLM knowledge materialization（大规模递归式LLM知识实化）方法，通过GPT-4.1生成了一个包含1亿条三元组的知识库。用户可通过链接遍历、SPARQL查询和对比探索进行知识浏览与分析。

Result: 成功从GPT-4.1以约14000美元成本构建了GPTKB v1.5知识库，实现了结构化查询、连通性分析和知识弱点探索等功能，推动了LLM知识的可解释性与自动化知识库构建研究。

Conclusion: GPTKB v1.5 提供了一种全新且高效的方法，对大型语言模型(LLM)的事实知识进行系统解析、自动化知识库( KB )构建和互动式探索。

Abstract: Language models are powerful tools, yet their factual knowledge is still
poorly understood, and inaccessible to ad-hoc browsing and scalable statistical
analysis. This demonstration introduces GPTKB v1.5, a densely interlinked
100-million-triple knowledge base (KB) built for $14,000 from GPT-4.1, using
the GPTKB methodology for massive-recursive LLM knowledge materialization (Hu
et al., ACL 2025). The demonstration experience focuses on three use cases: (1)
link-traversal-based LLM knowledge exploration, (2) SPARQL-based structured LLM
knowledge querying, (3) comparative exploration of the strengths and weaknesses
of LLM knowledge. Massive-recursive LLM knowledge materialization is a
groundbreaking opportunity both for the research area of systematic analysis of
LLM knowledge, as well as for automated KB construction. The GPTKB demonstrator
is accessible at https://gptkb.org.

</details>


### [48] [DocTalk: Scalable Graph-based Dialogue Synthesis for Enhancing LLM Conversational Capabilities](https://arxiv.org/abs/2507.05750)
*Jing Yang Lee,Hamed Bonab,Nasser Zalmout,Ming Zeng,Sanket Lokegaonkar,Colin Lockard,Binxuan Huang,Ritesh Sarkhel,Haodong Wang*

Main category: cs.CL

TL;DR: 本文针对LLMs多轮对话任务与预训练数据不匹配的问题，通过从文档聚类中自动合成信息型多轮对话语料DocTalk，在实验中显著提升了模型的上下文记忆与理解能力，并已开放该数据集。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）主要以连贯的书面文本作为预训练数据，但实际应用中常需处理多轮对话任务，这导致能力和训练范式之间存在不匹配。

Method: 提出了一种从现有文本语料中合成对话数据的新方法，构建了一个流水线，将相关文档集转化为多轮多话题的信息型对话。以Wikipedia为例，生成了名为DocTalk的多轮对话预训练语料。

Result: 在预训练中引入DocTalk后，LLMs在上下文记忆和理解能力上最多提升了40%，且未损失基本性能。

Conclusion: 合成的多轮对话语料可显著增强LLMs的多轮对话能力。DocTalk语料库已开放获取。

Abstract: Large Language Models (LLMs) are increasingly employed in multi-turn
conversational tasks, yet their pre-training data predominantly consists of
continuous prose, creating a potential mismatch between required capabilities
and training paradigms. We introduce a novel approach to address this
discrepancy by synthesizing conversational data from existing text corpora. We
present a pipeline that transforms a cluster of multiple related documents into
an extended multi-turn, multi-topic information-seeking dialogue. Applying our
pipeline to Wikipedia articles, we curate DocTalk, a multi-turn pre-training
dialogue corpus consisting of over 730k long conversations. We hypothesize that
exposure to such synthesized conversational structures during pre-training can
enhance the fundamental multi-turn capabilities of LLMs, such as context memory
and understanding. Empirically, we show that incorporating DocTalk during
pre-training results in up to 40% gain in context memory and understanding,
without compromising base performance. DocTalk is available at
https://huggingface.co/datasets/AmazonScience/DocTalk.

</details>


### [49] [Flippi: End To End GenAI Assistant for E-Commerce](https://arxiv.org/abs/2507.05788)
*Anand A. Rajasekar,Praveen Tangarajan,Anjali Nainani,Amogh Batwal,Vinay Rao Dandin,Anusua Trivedi,Ozan Ersoy*

Main category: cs.CL

TL;DR: 本文提出新型电商对话助手Flippi，基于LLMs实现精准理解与个性化推荐，通过多项NLP技术提升用户购物体验和商家转化效能，显著优于传统电商搜索方式。


<details>
  <summary>Details</summary>
Motivation: 传统电商平台产品繁杂，用户在搜索商品时往往面临信息过载，难以高效发现和比较商品，个性化程度有限。现有方法难以同时满足用户的主观和客观需求，影响购物体验和转化率。

Method: 提出了基于大型语言模型（LLMs）的端到端对话式助手Flippi，专为电商场景优化。采用了自然语言处理技术，包括查询重构（Query Reformulation）、意图检测（Intent Detection）、检索增强生成（RAG）、命名实体识别（NER）、上下文简化等。系统架构针对多电商平台易于集成，支持比较分析、特价识别、个性化推荐等功能。

Result: Flippi有效提升了商品发现效率，为用户提供了更加个性化和便捷的购物体验。在精确推荐、价格/功能对比和吸引力优惠发现等方面表现优异。通过用户满意度、转化率和交互指标的综合评估，表明系统能显著提升客户参与度和购买转化。

Conclusion: Flippi将大型语言模型的对话理解能力与电商场景深度结合，实现了线上购物个性化和智能化，为数字市场树立了更高的客户满意度和参与标准。

Abstract: The emergence of conversational assistants has fundamentally reshaped user
interactions with digital platforms. This paper introduces Flippi-a
cutting-edge, end-to-end conversational assistant powered by large language
models (LLMs) and tailored for the e-commerce sector. Flippi addresses the
challenges posed by the vast and often overwhelming product landscape, enabling
customers to discover products more efficiently through natural language
dialogue. By accommodating both objective and subjective user requirements,
Flippi delivers a personalized shopping experience that surpasses traditional
search methods. This paper details how Flippi interprets customer queries to
provide precise product information, leveraging advanced NLP techniques such as
Query Reformulation, Intent Detection, Retrieval-Augmented Generation (RAG),
Named Entity Recognition (NER), and Context Reduction. Flippi's unique
capability to identify and present the most attractive offers on an e-commerce
site is also explored, demonstrating how it empowers users to make
cost-effective decisions. Additionally, the paper discusses Flippi's
comparative analysis features, which help users make informed choices by
contrasting product features, prices, and other relevant attributes. The
system's robust architecture is outlined, emphasizing its adaptability for
integration across various e-commerce platforms and the technological choices
underpinning its performance and accuracy. Finally, a comprehensive evaluation
framework is presented, covering performance metrics, user satisfaction, and
the impact on customer engagement and conversion rates. By bridging the
convenience of online shopping with the personalized assistance traditionally
found in physical stores, Flippi sets a new standard for customer satisfaction
and engagement in the digital marketplace.

</details>


### [50] [Bridging Perception and Language: A Systematic Benchmark for LVLMs' Understanding of Amodal Completion Reports](https://arxiv.org/abs/2507.05799)
*Amane Watahiki,Tomoki Doi,Taiga Shinozaki,Satoshi Nishida,Takuya Niikawa,Katsunori Miyahara,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 本文提出了一个系统性评测LVLM对超模态补全相关文本推理能力的基准，发现模型在日语等特定语境下表现不佳，揭示了其语言和推理能力的局限。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉-语言模型（LVLMs）在多模态任务上表现突出，但对于“超模态补全”（amodal completion, 即人类在物体部分被遮挡时对完整性物体的感知）相关文本的理解与推理能力尚未被系统性评估。

Method: 作者基于Basic Formal Ontology构建了一个用于系统分类与评测超模态补全能力的基准数据集，对多种LVLMs在该任务上的表现进行了评测与分析，特别关注不同类别以及日语提示下的表现。

Result: 多种LVLM整体上能达到与人类相当的表现，但模型在完成不同类别物体时的准确率存在差异。特别是在日语指令下，部分模型如LLaVA-NeXT变体和Claude 3.5 Sonnet在原始图像上的表现竟然低于无视觉内容的空白刺激，反映模型在日语多模态理解上的不足。

Conclusion: LVLMs虽然整体上具有较强的超模态补全文字理解能力，但在细分场景和特定语言（如日语）下存在短板，提示后续研究需要进一步针对多语言与多类型物体补全能力优化模型。

Abstract: One of the main objectives in developing large vision-language models (LVLMs)
is to engineer systems that can assist humans with multimodal tasks, including
interpreting descriptions of perceptual experiences. A central phenomenon in
this context is amodal completion, in which people perceive objects even when
parts of those objects are hidden. Although numerous studies have assessed
whether computer-vision algorithms can detect or reconstruct occluded regions,
the inferential abilities of LVLMs on texts related to amodal completion remain
unexplored. To address this gap, we constructed a benchmark grounded in Basic
Formal Ontology to achieve a systematic classification of amodal completion.
Our results indicate that while many LVLMs achieve human-comparable performance
overall, their accuracy diverges for certain types of objects being completed.
Notably, in certain categories, some LLaVA-NeXT variants and Claude 3.5 Sonnet
exhibit lower accuracy on original images compared to blank stimuli lacking
visual content. Intriguingly, this disparity emerges only under Japanese
prompting, suggesting a deficiency in Japanese-specific linguistic competence
among these models.

</details>


### [51] [How to Evaluate Automatic Speech Recognition: Comparing Different Performance and Bias Measures](https://arxiv.org/abs/2507.05885)
*Tanvina Patel,Wiebke Hutiri,Aaron Yi Ding,Odette Scharenborg*

Main category: cs.CL

TL;DR: ASR系统存在针对不同说话群体的偏见，仅靠平均错误率指标不足以全面评估。本文比较多种衡量方法，建议采用多样指标，并规范结果报告，以更好反映系统偏见和群体表现。


<details>
  <summary>Details</summary>
Motivation: 当前自动语音识别（ASR）系统在性别、年龄、口音等方面对不同说话人或群体存在偏见。虽然已有大量关于偏见的检测和缓解研究，但如何衡量系统性能和偏见依然缺乏规范。

Method: 将文献中已有和新提出的多种性能及偏见衡量指标进行对比，用于评估现代端到端荷兰语ASR系统，并通过不同偏见缓解策略处理针对不同说话群体的偏见。

Result: 研究发现，ASR领域常用的平均错误率指标不足以全面反映系统性能，建议用其他衡量方式补充。并给出关于ASR系统性能和偏见报告的建议，以更好地体现对多样化说话人群体的表现和整体系统偏见。

Conclusion: 单一的平均错误率指标对衡量ASR系统中的偏见和多样人群表现是不够的。需要多元化的评估标准，并给出规范化的报告建议来减少未被发现的偏见。

Abstract: There is increasingly more evidence that automatic speech recognition (ASR)
systems are biased against different speakers and speaker groups, e.g., due to
gender, age, or accent. Research on bias in ASR has so far primarily focused on
detecting and quantifying bias, and developing mitigation approaches. Despite
this progress, the open question is how to measure the performance and bias of
a system. In this study, we compare different performance and bias measures,
from literature and proposed, to evaluate state-of-the-art end-to-end ASR
systems for Dutch. Our experiments use several bias mitigation strategies to
address bias against different speaker groups. The findings reveal that
averaged error rates, a standard in ASR research, alone is not sufficient and
should be supplemented by other measures. The paper ends with recommendations
for reporting ASR performance and bias to better represent a system's
performance for diverse speaker groups, and overall system bias.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [52] [Axiomatic characterizations of dissimilarity orderings and distances between sets](https://arxiv.org/abs/2507.05919)
*Thierry Marchant,Sandip Sarkar*

Main category: cs.DM

TL;DR: 本文系统分析了Hamming、Jaccard、Sorensen-Dice和Overlap四种集合距离指标在集合对排序中的具体特性及其相互关系，为实际应用选择合适的集合距离度量提供了理论依据。


<details>
  <summary>Details</summary>
Motivation: 研究集合之间的距离（相似性/差异性度量）在数据分析、信息检索等领域具有广泛应用，但不同距离度量（如Hamming、Jaccard、Sorensen-Dice、Overlap）之间的排序关系不明确。本文旨在系统刻画这些常用距离度量对集合对排序的影响及其相互关系。

Method: 通过理论分析方法，对Hamming、Jaccard、Sorensen-Dice和Overlap这几种主流集合距离进行形式化描述，并对由这些距离定义的集合对排序进行系统刻画和对比。

Result: 成功刻画了Hamming、Jaccard、Sorensen-Dice与Overlap距离度量在集合对排序中的表现，并揭示了这些距离的相关性质。

Conclusion: 研究为集合距离的理解和应用提供了理论基础，明确了不同集合距离度量的排序特性及其之间的关系，为实际选择合适的距离方法提供了理论指导。

Abstract: We characterize the orderings of pairs of sets induced by several distances:
Hamming, Jaccard, S\o rensen-Dice and Overlap. We also characterize these
distances.

</details>
