<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 18]
- [cs.LO](#cs.LO) [Total: 5]
- [cs.CL](#cs.CL) [Total: 17]
- [cs.DM](#cs.DM) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [TensorRight: Automated Verification of Tensor Graph Rewrites](https://arxiv.org/abs/2511.17838)
*Jai Arora,Sirui Lu,Devansh Jain,Tianfan Xu,Farzin Houshmand,Phitchaya Mangpo Phothilimthana,Mohsen Lesani,Praveen Narayanan,Karthik Srinivasa Murthy,Rastislav Bodik,Amit Sabne,Charith Mendis*

Main category: cs.PL

TL;DR: 本文提出TensorRight，首个可自动验证任意维度/大小张量计算图重写规则的系统，通过创新算法和DSL语言，将无界验证归约为有限任务，显著提升了验证范围和能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型需要高效的代码生成，因此张量编译器对张量计算图进行优化重写。然而，目前缺乏一种能够自动验证这些重写在任意维度和大小张量下语义正确性的系统。过去的验证工具仅能处理具体维度，而不能为无界场景提供可靠保证。

Method: 本文提出了TensorRight系统，包含一个基于“聚合轴”定义的核心DSL语言，用于表示和推理无界轴的重写规则。通过分析DSL的指称语义，推导出一个算法，确定只需验证有限数量的有界情形，即可证明无界情况的正确性。系统利用符号执行将有限的验证任务传递给SMT求解器，实现自动化验证。

Result: TensorRight可以自动化验证XLA算术简化器中的175条重写规则中115条的完全正确性。而之前最领先的系统只能验证其中18条规则，极大扩展了自动化验证的能力范围。

Conclusion: TensorRight首次实现了任意维度和大小张量重写规则的自动化正确性验证，为深度学习编译器的可靠优化奠定基础。

Abstract: Tensor compilers, essential for generating efficient code for deep learning models across various applications, employ tensor graph rewrites as one of the key optimizations. These rewrites optimize tensor computational graphs with the expectation of preserving semantics for tensors of arbitrary rank and size. Despite this expectation, to the best of our knowledge, there does not exist a fully automated verification system to prove the soundness of these rewrites for tensors of arbitrary rank and size. Previous works, while successful in verifying rewrites with tensors of concrete rank, do not provide guarantees in the unbounded setting.
  To fill this gap, we introduce TensorRight, the first automatic verification system that can verify tensor graph rewrites for input tensors of arbitrary rank and size. We introduce a core language, TensorRight DSL, to represent rewrite rules using a novel axis definition, called aggregated-axis, which allows us to reason about an unbounded number of axes. We achieve unbounded verification by proving that there exists a bound on tensor ranks, under which bounded verification of all instances implies the correctness of the rewrite rule in the unbounded setting. We derive an algorithm to compute this rank using the denotational semantics of TensorRight DSL. TensorRight employs this algorithm to generate a finite number of bounded-verification proof obligations, which are then dispatched to an SMT solver using symbolic execution to automatically verify the correctness of the rewrite rules. We evaluate TensorRight's verification capabilities by implementing rewrite rules present in XLA's algebraic simplifier. The results demonstrate that TensorRight can prove the correctness of 115 out of 175 rules in their full generality, while the closest automatic, bounded-verification system can express only 18 of these rules.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [The Software Engineering Simulations Lab: Agentic AI for RE Quality Simulations](https://arxiv.org/abs/2511.17762)
*Henning Femmer,Ivan Esau*

Main category: cs.SE

TL;DR: 本文提出用Agentic AI模拟技术支持需求工程质量评估，突破传统经验、直觉驱动的限制。研究初步表明该方法可行，未来可拓展和完善以提升RE领域的科学性和实证基础。


<details>
  <summary>Details</summary>
Motivation: 需求工程（RE）中的质量问题缺乏系统、实证的研究，主要依赖经验和直觉，而高质量的需求模型需要大量的实证数据。特别是在AI介入开发过程的背景下，需求质量因素可能发生变化，需求的使用对象不仅是人类，AI也开始参与需求的消费。

Method: 提出利用Agentic AI模拟方法，将标准化智能体应用于软件工程过程，通过随机、动态、事件驱动、定性模拟来评估需求质量。这种方法简单高效，并给出了初步概念、研究路线图、原型系统和可行性研究。

Result: 初步可行性研究表明，即使采用较为简单的实现方式，也能够得到可执行的模拟结果，鼓舞了需求工程研究进一步技术改进和更广泛的应用。

Conclusion: Agentic AI模拟为需求工程质量研究提供了新的工具和方向，尽管仍需研究如何更好地复现人类行为，但其方法已证明具备潜力，有望支持需求工程领域更系统的质量评估。

Abstract: Context and motivation. Quality in Requirements Engineering (RE) is still predominantly anecdotal and intuition-driven. Creating a solid requirements quality model requires broad sets of empirical evidence to evaluate quality factors and their context. Problem. However, empirical data on the detailed effects of requirements quality defects is scarce, since it is costly to obtain. Furthermore, with the advent of AI-based development, the requirements quality factors may change: Requirements are no longer only consumed by humans, but increasingly also by AI agents, which might lead to a different efficient and effective requirements style. Principal ideas. We propose to extend the RE research toolbox with Agentic AI simulations, in which software engineering (SE) processes are replicated by standardized agents in stochastic, dynamic, event-driven, qualitative simulations. We argue that their speed and simplicity makes them a valuable addition to RE research, although limitations in replicating human behavior need to be studied and understood. Contribution. This paper contributes a first concept, a research roadmap, a prototype, and a first feasibility study for RE simulations with agentic AI. Study results indicate that even a naive implementation leads to executable simulations, encouraging technical improvements along with broader application in RE research.

</details>


### [3] [SLMFix: Leveraging Small Language Models for Error Fixing with Reinforcement Learning](https://arxiv.org/abs/2511.19422)
*David Jiahao Fu,Aryan Gupta,Aaron Councilman,David Grove,Yu-Xiong Wang,Vikram Adve*

Main category: cs.SE

TL;DR: 本文提出SLMFix方法，通过强化学习微调的小模型修复LLM生成的错误代码，有效提升低资源编程语言的代码生成质量，实验通过率超95%，且优于有监督微调。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型（LLM）在多语言代码生成方面展现出强大能力，但在低资源编程语言（LRPL）中仍常出现语法错误且无法完成任务。LLM微调所需的高昂成本也限制了其在代码生成上的应用效果。

Method: 提出了一种新的代码生成流程SLMFix，通过使用以强化学习（RL）技术微调的小型语言模型（SLM）对LLM生成的代码进行语法修复。奖励机制综合利用静态验证器和语义相似度指标。

Result: 在多个领域专用语言（DSL）上的实验显示，SLMFix方法可使静态验证器通过率超过95%，在低资源编程语言下也优于传统的有监督微调方案，包括在7B模型上。

Conclusion: SLMFix方法不仅能显著提升基础模型的代码质量，而且为应对高成本微调难题提供了一种可行替代方案，展现了良好的泛化能力和实际应用潜力。

Abstract: Recent advancements in large language models (LLMs) have shown very impressive capabilities in code generation across many programming languages. However, even state-of-the-art LLMs generate programs that contains syntactic errors and fail to complete the given tasks, especially for low-resource programming languages (LRPLs). In addition, high training cost makes finetuning LLMs unaffordable with constrained computational resources, further undermining the effectiveness of LLMs for code generation. In this work, we propose SLMFix, a novel code generation pipeline that leverages a small language model (SLM) finetuned using reinforcement learning (RL) techniques to fix syntactic errors in LLM-generated programs to improve the quality of LLM-generated programs for domain-specific languages (DSLs). In specific, we applied RL on the SLM for the program repair task using a reward calculated using both a static validator and a static semantic similarity metric. Our experimental results demonstrate the effectiveness and generalizability of our approach across multiple DSLs, achieving more than 95% pass rate on the static validator. Notably, SLMFix brings substantial improvement to the base model and outperforms supervised finetuning approach even for 7B models on a LRPL, showing the potential of our approach as an alternative to traditional finetuning approaches.

</details>


### [4] [Validating API Design Requirements for Interoperability: A Static Analysis Approach Using OpenAPI](https://arxiv.org/abs/2511.17836)
*Edwin Sundberg,Thea Ekmark,Workneh Yilma Ayele*

Main category: cs.SE

TL;DR: 本文提出了一种基于规则引擎的API设计质量自动化验证工具，通过配置和扩展设计原则，提高RESTful API开发的质量、一致性和标准化。该方法减少人工工作负担，支持企业级需求工程与治理，未来将拓展更多场景和实现持续合规。


<details>
  <summary>Details</summary>
Motivation: RESTful API在企业软件系统中至关重要，但API设计质量的评估目前多依赖人工、缺乏自动化工具，尤其是在早期开发阶段。这影响了系统的演化、服务互操作性与治理。因此，亟需一种自动化方案来提升API设计一致性和质量。

Method: 采用设计科学研究（DSR）方法，收集用户需求，通过文献综述提出75条API设计规则，并实现可配置的规则引擎来检测OpenAPI规范中的结构违规。工具支持自定义规则、集成领域标准，并通过结构化实验和行业专家专题分析进行评估。

Result: 实验结果表明，所提出的工具（S.E.O.R.A）能在API开发早期自动验证非功能性需求，提供可操作和可追溯反馈，与需求收集和质量保障流程高度契合，提升了一致性和可复用性。

Conclusion: S.E.O.R.A工具将API设计原则转化为可验证约束，并集成到实际验证工具中，实现API设计质量自动化检验。该方法促进企业系统间的互操作与治理，推动需求工程的发展。未来计划包括集成开发环境（IDE）支持、扩展规则范围和实际部署，以实现敏捷开发中持续合规。

Abstract: RESTful APIs are central in developing interoperable, modular, and maintainable software systems in enterprises today. Also, it is essential to support system evolution, service interoperability, and governance across organizational boundaries to ensure good quality and consistency of these APIs. However, evaluating API design quality, which is part of non-functional requirement tasks, remains a largely manual and ad hoc process, particularly during early development. Using a Design Science Research (DSR) methodology, we elicited user needs, identified 75 API design rules using a literature review, and implemented a configurable rule engine to detect structural violations in OpenAPI specifications. The proposed tool supports organizational adaptability by allowing rules to be customized, enabled, or disabled, enabling integration of domain-specific standards. The evaluation was conducted through structured experiments and thematic analysis involving industry experts. API quality validation contributes to aligning technical designs with requirements and enterprise architecture by strengthening interoperability and governance between enterprise systems. The results show that S.E.O.R.A facilitates early validation of non-functional API requirements, provides actionable and traceable feedback, and aligns well with requirements elicitation and quality assurance processes. It improves the API design process by automating checks that would otherwise require manual inspection, thus supporting consistent and reusable conformance practices. This work contributes to requirements engineering by operationalizing design principles as verifiable constraints and embedding them into a practical validation tool. Future directions include IDE integration, expanded rule coverage, and real-world deployment to support continuous compliance in agile API development lifecycles.

</details>


### [5] [A Low-Code Methodology for Developing AI Kiosks: a Case Study with the DIZEST Platform](https://arxiv.org/abs/2511.17853)
*SunMin Moon,Jangwon Gim,Chaerin Kim,Yeeun Kim,YoungJoo Kim,Kang Choi*

Main category: cs.SE

TL;DR: 本文提出并验证了基于DIZEST平台的低代码AI自助终端方案，在系统性能、易用性与集成性方面优于主流平台，并有效提升了实际场景下的应用体验。


<details>
  <summary>Details</summary>
Motivation: 现代自助终端系统（kiosk systems）面临系统集成难、结构僵化、性能瓶颈和缺乏协作等一系列挑战，现有方案难以满足多变需求。

Method: 提出了一种基于DIZEST的低代码架构方法，该平台支持直观的工作流设计与AI模块无缝集成，并通过与主流低代码平台（如Jupyter Notebook、ComfyUI和Orange3）对比分析其优势。

Result: DIZEST在关键性能指标上显著优于现有平台，且在照片自助终端案例中有效提升了系统互操作性、用户体验和部署灵活性。

Conclusion: 基于DIZEST的低代码架构能有效解决现有自助终端系统的集成与性能难题，促进AI能力整合，为用户和开发者带来更优交互与更高效率。

Abstract: This paper presents a comprehensive study on enhancing kiosk systems through a low-code architecture, with a focus on AI-based implementations. Modern kiosk systems are confronted with significant challenges, including a lack of integration, structural rigidity, performance bottlenecks, and the absence of collaborative frameworks. To overcome these limitations, we propose a DIZEST-based approach methodology, a specialized low-code platform that enables intuitive workflow design and seamless AI integration. Through a comparative analysis with existing platforms, including Jupyter Notebook, ComfyUI, and Orange3, we demonstrate that DIZEST delivers superior performance across key evaluation criteria. Our photo kiosk case study further validates the effectiveness of this approach in improving interoperability, enhancing user experience, and increasing deployment flexibility.

</details>


### [6] [Synthesizing Precise Protocol Specs from Natural Language for Effective Test Generation](https://arxiv.org/abs/2511.17977)
*Kuangxiangzi Liu,Dhiman Chakraborty,Alexander Liggesmeyer,Andreas Zeller*

Main category: cs.SE

TL;DR: 作者提出基于LLM的两阶段流水线，实现自然语言协议规范到形式化规范的自动转化，有效支持协议的自动化大规模测试，原型系统AUTOSPEC在多协议实验中取得了优异效果。


<details>
  <summary>Details</summary>
Motivation: 目前安全和保障关键系统的测试主要依赖人工从自然语言规范中手动提取测试用例，过程繁琐且易出错、不易扩展；而形式化规范虽适合自动化生成测试，但编写维护成本高昂。作者旨在解决自然语言规范与形式规范之间的鸿沟，实现高效且可追溯的自动化测试。

Method: 提出一个两阶段流水线：第一阶段用大语言模型（LLMs）从自然语言规范中提取协议关键要素；第二阶段结合协议实现，基于这些要素自动合成和优化形式化协议规范。最终可用这些形式规范批量测试各类协议实现。

Result: 原型系统AUTOSPEC被应用于五个主流互联网协议（SMTP、POP3、IMAP、FTP、ManageSieve）的 RFC 文档测试，平均可恢复92.8%的客户端消息类型和80.2%的服务端消息类型，消息接受率达81.5%。

Conclusion: 该方法实现了自然语言到形式化协议规范的高质量自动转化，有效提升了测试自动化、可追溯性与扩展能力，并能够建立对LLM进一步训练有益的映射语料库。

Abstract: Safety- and security-critical systems have to be thoroughly tested against their specifications. The state of practice is to have _natural language_ specifications, from which test cases are derived manually - a process that is slow, error-prone, and difficult to scale. _Formal_ specifications, on the other hand, are well-suited for automated test generation, but are tedious to write and maintain. In this work, we propose a two-stage pipeline that uses large language models (LLMs) to bridge the gap: First, we extract _protocol elements_ from natural-language specifications; second, leveraging a protocol implementation, we synthesize and refine a formal _protocol specification_ from these elements, which we can then use to massively test further implementations.
  We see this two-stage approach to be superior to end-to-end LLM-based test generation, as 1. it produces an _inspectable specification_ that preserves traceability to the original text; 2. the generation of actual test cases _no longer requires an LLM_; 3. the resulting formal specs are _human-readable_, and can be reviewed, version-controlled, and incrementally refined; and 4. over time, we can build a _corpus_ of natural-language-to-formal-specification mappings that can be used to further train and refine LLMs for more automatic translations.
  Our prototype, AUTOSPEC, successfully demonstrated the feasibility of our approach on five widely used _internet protocols_ (SMTP, POP3, IMAP, FTP, and ManageSieve) by applying its methods on their _RFC specifications_ written in natural-language, and the recent _I/O grammar_ formalism for protocol specification and fuzzing. In its evaluation, AUTOSPEC recovers on average 92.8% of client and 80.2% of server message types, and achieves 81.5% message acceptance across diverse, real-world systems.

</details>


### [7] [Enhancing Automated Program Repair via Faulty Token Localization and Quality-Aware Patch Refinement](https://arxiv.org/abs/2511.18001)
*Jiaolong Kong,Xiaofei Xie,Yiheng Xiong,Yuekun Wang,Jian Wang*

Main category: cs.SE

TL;DR: TokenRepair通过引入内部反思和外部反馈双重机制，提高了程序自动修复的效率和准确率，在基准测试中实现了最佳表现。


<details>
  <summary>Details</summary>
Motivation: 现有LLM自动修复主要依赖外部粗粒度反馈，缺乏对错误来源的细致定位，导致修复效率低、错误传播和修复表现不佳。为此，引入细粒度的内部信号提升修复质量。

Method: 方法包括两级精修：先通过分析token级别的不确定性进行内部反思，在patch中定位可疑token；然后仅对这些token进行Chain-of-Thought指导下的局部重写。此外，结合质量感知的外部反馈机制，筛选高质量候选补丁。

Result: TokenRepair在两个主流数据集上均取得显著提升：Defects4J 1.2修复88个bug（提升8.2%-34.9%），HumanEval-Java修复139个bug（提升3.3%-16.1%），均为新SOTA。

Conclusion: TokenRepair提出了一种结合内外反馈的新框架，实现了更精细和高效的自动程序修复，并在多个基准上取得了新的最优表现。

Abstract: Large language models (LLMs) have recently demonstrated strong potential for automated program repair (APR). However, existing LLM-based techniques primarily rely on coarse-grained external feedback (e.g.,test results) to guide iterative patch generation, while lacking fine-grained internal signals that reveal why a patch fails or which parts of the generated code are likely incorrect. This limitation often leads to inefficient refinement, error propagation, and suboptimal repair performance. In this work, we propose TokenRepair, a novel two-level refinement framework that enhances APR by integrating internal reflection for localizing potentially faulty tokens with external feedback for quality-aware patch refinement. Specifically, TokenRepair first performs internal reflection by analyzing context-aware token-level uncertainty fluctuations to identify suspicious or low-confidence tokens within a patch. It then applies Chain-of-Thought guided rewriting to refine only these localized tokens, enabling targeted and fine-grained correction. To further stabilize the iterative repair loop, TokenRepair incorporates a quality-aware external feedback mechanism that evaluates patch quality and filters out low-quality candidates before refinement. Experimental results show that TokenRepair achieves new state-of-the-art repair performance, correctly fixing 88 bugs on Defects4J 1.2 and 139 bugs on HumanEval-Java, demonstrating substantial improvements ranging from 8.2% to 34.9% across all models on Defects4J 1.2 and from 3.3% to 16.1% on HumanEval-Java.

</details>


### [8] [MASTEST: A LLM-Based Multi-Agent System For RESTful API Tests](https://arxiv.org/abs/2511.18038)
*Xiaoke Han,Hong Zhu*

Main category: cs.SE

TL;DR: 本文提出并实证了结合 LLM 的自动化 RESTful API 测试工具链 MASTEST，在多款模型上取得良好效果，展示了高覆盖率与脚本质量，可大幅提升云原生应用的测试效率。


<details>
  <summary>Details</summary>
Motivation: 随着云原生应用的普及，RESTful API 测试在质量保障中变得越来越重要。近年来，大型语言模型（LLM）在自动化测试方面表现出较高准确性，激励了将机器学习技术应用于 API 测试，从而提升测试效率和覆盖范围。

Method: 本文开发了一个多智能体系统 MASTEST，将基于 LLM 的智能体与编程智能体结合，形成覆盖 API 测试全流程的完整工具链。本系统能够从 OpenAPI Swagger 规范生成单元测试和系统测试场景，生成 Pytest 脚本，执行脚本与 Web 服务交互，并分析响应消息以判定测试正确性及覆盖率。还支持人工干预校正测试成果，提高测试质量。研究还在两种 LLM（GPT-4o 和 DeepSeek V3.1 Reasoner）及五个公开 API 上进行实验评估。

Result: 实验测量了多项指标，包括测试场景和 API 操作覆盖率、数据类型正确性、状态码覆盖、脚本语法正确性及缺陷检测能力等。结果显示两款 LLM 都有较高综合表现，DeepSeek 在数据类型与状态码检测上表现更强，GPT-4o 在 API 操作覆盖率上最好，两者生成的脚本均保持 100% 语法正确，仅需少量人工修正语义。

Conclusion: MASTEST 系统能有效自动化 API 测试，表现优异且可行，验证了 LLM 在自动生成测试脚本和场景中的可用性与效率，为未来大规模 API 测试自动化提供了可靠方案。

Abstract: Testing RESTful API is increasingly important in quality assurance of cloud-native applications. Recent advances in machine learning (ML) techniques have demonstrated that various testing activities can be performed automatically by large language models (LLMs) with reasonable accuracy. This paper develops a multi-agent system called MASTEST that combines LLM-based and programmed agents to form a complete tool chain that covers the whole workflow of API test starting from generating unit and system test scenarios from API specification in the OpenAPI Swagger format, to generating of Pytest test scripts, executing test scripts to interact with web services, to analysing web service response messages to determine test correctness and calculate test coverage. The system also supports the incorporation of human testers in reviewing and correcting LLM generated test artefacts to ensure the quality of testing activities. MASTEST system is evaluated on two LLMs, GPT-4o and DeepSeek V3.1 Reasoner with five public APIs. The performances of LLMs on various testing activities are measured by a wide range of metrics, including unit and system test scenario coverage and API operation coverage for the quality of generated test scenarios, data type correctness, status code coverage and script syntax correctness for the quality of LLM generated test scripts, as well as bug detection ability and usability of LLM generated test scenarios and scripts. Experiment results demonstrated that both DeepSeek and GPT-4o achieved a high overall performance. DeepSeek excels in data type correctness and status code detection, while GPT-4o performs best in API operation coverage. For both models, LLM generated test scripts maintained 100\% syntax correctness and only required minimal manual edits for semantic correctness. These findings indicate the effectiveness and feasibility of MASTEST.

</details>


### [9] [Event-Chain Analysis for Automated Driving and ADAS Systems: Ensuring Safety and Meeting Regulatory Timing Requirements](https://arxiv.org/abs/2511.18092)
*Sebastian Dingler,Philip Rehkop,Florian Mayer,Ralf Muenzenberger*

Main category: cs.SE

TL;DR: 本文提出用事件链白盒分析法解决自动驾驶及辅助系统的时序合规性难题，支持架构级建模与仿真，案例显示可早期发现合规问题并系统优化设计。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统（ADS）及高级驾驶辅助系统（ADAS）必须不仅满足高功能预期，还要符合国际法规和标准对系统响应时间的严格要求。当前法规（如联合国法规、NCAP标准、ISO规范、NHTSA指南）对系统反应时间有明确界定，确保车辆安全运行，因此业界亟需能够满足并验证这些时序要求的分析和开发方法。

Method: 本文提出了一种基于事件链建模的白盒方法来解决ADS和ADAS的系统时序挑战。该方法通过事件链分析，透明地揭示从感知、规划到执行以及人机交互各功能部件的时序行为，有别于以往的黑盒分析方法。此外，该方法可在架构层次推导、建模并验证端到端的时序约束，并支持仿真的早期验证。

Result: 通过详细的案例研究，证明了该基于事件链建模的方法能够增强系统的法规合规性，优化系统设计，提升模型化安全分析的支持力度，能够在早期识别合规性问题，实现参数的系统性优化，并通过概率分析提供定量证据。

Conclusion: 事件链导向的白盒时序分析方法能够支持ADS/ADAS系统满足国际法规的时序要求，提高设计透明度与合规性，辅助早期预验证和系统性优化。

Abstract: Automated Driving Systems (ADS), including Advanced Driver Assistance Systems (ADAS), must fulfill not only high functional expectations but also stringent timing constraints mandated by international regulations and standards. Regulatory frameworks such as UN regulations, NCAP standards, ISO norms, and NHTSA guidelines impose strict bounds on system reaction times to ensure safe vehicle operation. This paper presents a structured, White-Box methodology based on Event-Chain Modeling to address these timing challenges. Unlike Black-Box approaches, Event-Chain Analysis offers transparent insights into the timing behavior of each functional component - from perception and planning to actuation and human interaction. This perspective is also aligned with multiple regulations, which require that homologation dossiers provide evidence that the chosen system architecture is suitable to ensure compliance with the specified requirements. Our methodology enables the derivation, modeling, and validation of end-to-end timing constraints at the architectural level and facilitates early verification through simulation. Through a detailed case study, we demonstrate how this Event-Chain-centric approach enhances regulatory compliance, optimizes system design, and supports model-based safety analysis techniques, with results showing early identification of compliance issues, systematic parameter optimization, and quantitative evidence generation through probabilistic analysis.

</details>


### [10] [Towards a General Framework for HTN Modeling with LLMs](https://arxiv.org/abs/2511.18165)
*Israel Puerta-Merino,Carlos Núñez-Molina,Pablo Mesejo,Juan Fernández-Olivares*

Main category: cs.SE

TL;DR: LLMs自动生成层次规划模型受限，语法有效性极低，需更多研究改进HP模型生成技术。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs自动生成非层次规划模型已有较好进展，但对层次规划的支持非常有限。本研究旨在填补该领域空白，提高HP模型自动化生成水平。

Method: 提出L2HP扩展库，基于LLM自动生成HP模型，同时与非层次规划模型（AP）能力进行对比实验。实验采用PlanBench数据集。

Result: 两者解析成功率相当（均约36%），但语法有效性在HP仅为1%，显著低于AP的20%。HP生成质量面临更大挑战。

Conclusion: LLMs在自动规划模型生成方面表现较好，但在层次规划模型生成时仍有明显不足，解析成功率虽相近但语法有效性大幅下降，需进一步研究提升HP模型生成质量。

Abstract: The use of Large Language Models (LLMs) for generating Automated Planning (AP) models has been widely explored; however, their application to Hierarchical Planning (HP) is still far from reaching the level of sophistication observed in non-hierarchical architectures. In this work, we try to address this gap. We present two main contributions. First, we propose L2HP, an extension of L2P (a library to LLM-driven PDDL models generation) that support HP model generation and follows a design philosophy of generality and extensibility. Second, we apply our framework to perform experiments where we compare the modeling capabilities of LLMs for AP and HP. On the PlanBench dataset, results show that parsing success is limited but comparable in both settings (around 36\%), while syntactic validity is substantially lower in the hierarchical case (1\% vs. 20\% of instances). These findings underscore the unique challenges HP presents for LLMs, highlighting the need for further research to improve the quality of generated HP models.

</details>


### [11] [Establishing Traceability Links between Release Notes & Software Artifacts: Practitioners' Perspectives](https://arxiv.org/abs/2511.18187)
*Sristy Sumana Nath,Banani Roy,Munima Jahan*

Main category: cs.SE

TL;DR: 该研究发现开源项目发布说明与开发工件间的可追溯性链接严重不足，提出并验证了基于大语言模型自动建立链接的新方法，有效提升了可追溯性准确率，对技术债管理和项目维护具有现实影响。


<details>
  <summary>Details</summary>
Motivation: 开源软件远程、异步协作环境下，发布说明与开发工件之间的可追溯性链接维护困难，易遗漏且耗时，影响技术债管理和项目可维护性。既有方法不足以解决大量缺失和破损的链接问题，亟需自动化、准确的解决方案。

Method: 通过分析GitHub仓库，构建了包含3500个经筛选和验证的可追溯性链接数据集，并采用基于大语言模型（如Gemini 1.5 Pro），结合时间邻近性特征，自动提取发布说明与PRs、issues之间的关联。最终通过Precision@1指标评估效果。并进行了在线问卷调查以考察工具实际可用性。

Result: 分析发现47%的发布说明缺失可追溯性链接，12%存在破损链接。所提方法在PR可追溯性恢复的Precision@1达到0.73。问卷结果显示，84%的开源实践者认为建立可追溯性链接较为重要。

Conclusion: 利用大语言模型（LLM）结合时间特征，可以显著提高自动建立发布说明与开发工件（如PRs、issues）的可追溯性链接的准确性和有效性。

Abstract: Maintaining traceability links between software release notes and corresponding development artifacts, e.g., pull requests (PRs), commits, and issues, is essential for managing technical debt and ensuring maintainability. However, in open-source environments where contributors work remotely and asynchronously, establishing and maintaining these links is often error-prone, time-consuming, and frequently overlooked. Our empirical study of GitHub repositories revealed that 47% of release artifacts lacked traceability links, and 12% contained broken links. To address this gap, we first analyzed release notes to identify their What, Why, and How information and assessed how these align with PRs, commits, and issues. We curated a benchmark dataset consisting of 3,500 filtered and validated traceability link instances. Then, we implemented LLM-based approaches to automatically establish traceability links of three pairs between release note contents & PRs, release note contents & PRs and release note contents & issues. By combining the time proximity feature, the LLM-based approach, e.g., Gemini 1.5 Pro, achieved a high Precision@1 value of 0.73 for PR traceability recovery. To evaluate the usability and adoption potential of this approach, we conducted an online survey involving 33 open-source practitioners. 16% of respondents rated as very important, and 68% as somewhat important for traceability maintenance.

</details>


### [12] [LLM Assisted Coding with Metamorphic Specification Mutation Agent](https://arxiv.org/abs/2511.18249)
*Mostafijur Rahman Akhond,Gias Uddin*

Main category: cs.SE

TL;DR: 面对LLM在软件开发任务规范下表现不一致的问题，论文提出以变形关系驱动的CMA框架，有效提升代码生成的可靠性与覆盖率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在软件工程中的应用日益广泛，但由于用户规范不明确而导致其生成结果常出现模糊和不一致性，影响了可靠性。因此，亟需方式来提升生成的一致性和准确性。

Method: 提出了CodeMetaAgent（CMA）框架，通过结合变形关系(MR)与大型语言模型，系统性地细化任务规范，并生成语义受限的测试样例。MR在框架中不仅用于生成数据，还指导规范细化和用例生成，区别于传统只用于验证。

Result: 在HumanEval-Pro、MBPP-Pro和SWE-Bench_Lite数据集上，以GPT-4o、Mistral Large、GPT-OSS和Qwen3-Coder模型为基准，CMA框架代码生成准确率最高提升17%，代码覆盖率最高达99.81%。

Conclusion: 变形关系作为指导机制可简便有效提升基于LLM的软件开发一致性与效率。

Abstract: Metamorphic Relations (MRs) serve as a foundational mechanism for generating semantically equivalent mutations. Software engineering has advanced significantly in recent years with the advent of Large Language Models (LLMs). However, the reliability of LLMs in software engineering is often compromised by ambiguities and inconsistencies due to improper user specification. To address this challenge, we present CodeMetaAgent (CMA), a metamorphic relation-driven LLM agent that systematically refines task specifications and generates semantically constrained test cases. Our proposed framework uses MRs with LLMs to improve generation consistency and reduce variability caused by specifications, unlike the traditional use of MRs as post validations. Our framework has been evaluated on the HumanEval-Pro, MBPP-Pro, and SWE-Bench_Lite datasets using the GPT-4o, Mistral Large, GPT-OSS, and Qwen3-Coder models. It improved code generation accuracy by up to 17% and achieved code coverage gains of up to 99.81%. These results show that metamorphic relations can be a simple but effective guide in assisting LLM-based software development.

</details>


### [13] [Can Large Language Models Solve Path Constraints in Symbolic Execution?](https://arxiv.org/abs/2511.18288)
*Wenhan Wang,Kaibo Liu,Zeyu Sun,An Ran Chen,Ge Li,Gang Huang,Lei Ma*

Main category: cs.SE

TL;DR: 本文首次系统评估了大语言模型在符号执行路径约束求解中的能力，结果显示LLM能有效生成测试用例并提升真实软件的测试覆盖，突破了传统符号执行的若干局限，为相关技术升级提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 传统符号执行依赖SMT求解器，难以处理复杂数据结构或外部API调用的执行路径限制，这限制了其在真实世界软件中的应用。本文针对该问题，探索是否可利用大语言模型（LLM）来替代传统的约束求解方法。

Method: 本文通过实证研究，评估LLM在两种路径约束求解任务中的能力：一是为特定执行路径生成测试输入；二是判断给定路径能否被满足且不触发bug。为此构建了新的评估流程和基准，包括竞赛级程序和真实仓库的数据源，用于测试用例生成与路径分类两个任务。

Result: 实验显示，最先进的LLM能够在生成和分类任务中解决路径约束，生成测试用例准确覆盖目标执行路径的比例高达60%。此外，LLM还能在传统符号执行工具无法覆盖的真实仓库路径中提升测试覆盖率。

Conclusion: LLM有潜力扩展符号执行技术，提升其能力和通用性，对未来符号执行技术的改进具有重要意义。

Abstract: Symbolic execution is an important software analysis technique which benefits downstream tasks such as software testing and debugging. However, several limitations hinder symbolic execution from application on real-world software. One of the limitations is the inability to solve diverse execution path constraints: traditional symbolic execution based on SMT solvers is difficult to handle execution paths with complex data structures or external API calls. In this paper, we focus on investigating the possibility of adopting large language models (LLM) for path constraint solving instead of traditional solver-based techniques in symbolic execution. We conduct an empirical study to evaluate the ability of LLMs in two types of path constraint solving: generating test inputs to facilitate an execution path, and determining whether a given execution path can be satisfied without triggering any bugs. We build new evaluation pipelines and benchmarks for two tasks: test case generation and path classification, which include data sources from both competition-level programs and real-world repositories. Our experiment results show that state-of-the-art LLMs are able to solve path constraints in both generation and classification tasks, with 60% of generated test cases that accurately cover the given execution path. Moreover, LLMs are capable of improving test coverage by covering execution paths in real-world repositories where traditional symbolic execution tools cannot be applied. These findings highlight the possibility of extending symbolic execution techniques with LLMs in the future to improve the ability and generalizability of symbolic execution.

</details>


### [14] [A Needle in a Haystack: Intent-driven Reusable Artifacts Recommendation with LLMs](https://arxiv.org/abs/2511.18343)
*Dongming Jin,Zhi Jin,Xiaohong Chen,Zheng Fang,Linyu Li,Yuanpeng He,Jia Li,Yirang Zhang,Yingtao Fang*

Main category: cs.SE

TL;DR: LLM虽提升了开源构件推荐效果但仍存在短板。TreeRec通过语义特征树优化LLM推荐，兼顾效率与精度，在多环境下表现优异，有望实际落地。


<details>
  <summary>Details</summary>
Motivation: 在开源软件开发中，虽然可复用构件能提高开发效率和质量，但海量可选构件让开发者难以快速准确地找到满足需求的组件。已有基于检索和学习的方法存在不足，近年来大语言模型（LLM）被认为具有新的潜力，但其效果未被系统验证。

Method: 构建了意图驱动的推荐基准IntentRecBench，涵盖三个主流开源生态系统，并基于此对五种主流LLM与六种传统方法在精度和效率上做了全面对比。随后，受本体论思想启发，提出了TreeRec——结合LLM语义抽象的层级特征树推荐框架，实现构件语义组织，并通过树结构加速推理和提高对齐精度。

Result: 实验显示，各类LLM虽然优于传统方法，但仍存在精度不足和推理开销高的问题。TreeRec显著提升了多种LLM在不同生态系统下的推荐性能，改善了推理效率和准确性，表现出较好的通用性。

Conclusion: TreeRec以特征树为引导，有效融合了LLM能力与语义结构组织，缓解了大候选空间带来的低精度与高计算消耗问题，有望在实际开源推荐场景中部署应用。

Abstract: In open source software development, the reuse of existing artifacts has been widely adopted to avoid redundant implementation work. Reusable artifacts are considered more efficient and reliable than developing software components from scratch. However, when faced with a large number of reusable artifacts, developers often struggle to find artifacts that can meet their expected needs. To reduce this burden, retrieval-based and learning-based techniques have been proposed to automate artifact recommendations. Recently, Large Language Models (LLMs) have shown the potential to understand intentions, perform semantic alignment, and recommend usable artifacts. Nevertheless, their effectiveness has not been thoroughly explored. To fill this gap, we construct an intent-driven artifact recommendation benchmark named IntentRecBench, covering three representative open source ecosystems. Using IntentRecBench, we conduct a comprehensive comparative study of five popular LLMs and six traditional approaches in terms of precision and efficiency. Our results show that although LLMs outperform traditional methods, they still suffer from low precision and high inference cost due to the large candidate space. Inspired by the ontology-based semantic organization in software engineering, we propose TreeRec, a feature tree-guided recommendation framework to mitigate these issues. TreeRec leverages LLM-based semantic abstraction to organize artifacts into a hierarchical semantic tree, enabling intent and function alignment and reducing reasoning time. Extensive experiments demonstrate that TreeRec consistently improves the performance of diverse LLMs across ecosystems, highlighting its generalizability and potential for practical deployment.

</details>


### [15] [Evaluating perturbation robustnessof generative systems that use COBOL code inputs](https://arxiv.org/abs/2511.18488)
*Samuel Ackerman,Wesam Ibraheem,Orna Raz,Marcel Zalmanovici*

Main category: cs.SE

TL;DR: 本文提出了一套评估和提升以COBOL为输入的LLM系统鲁棒性的框架，包括数据扰动库和动态可视化分析工具，适用于代码翻译、生成等任务，助力系统稳定性优化。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）被广泛应用于系统中，但对输入的小幅变化（即使不改变含义）十分敏感，影响了系统的稳定性和实际可用性。COBOL作为商业关键应用的重要语言，虽然应用广泛，但相关代码多为私有，难以用于LLM训练，针对COBOL输入的系统鲁棒性亟需研究。

Method: 提出一个评价COBOL代码作为输入的LLM系统鲁棒性的框架，包括：1）编写COBOL段落和完整程序的扰动方法库；2）利用上述方法扩展基准数据集，生成多样化变体；3）通过输出的个体和总体指标的变化量，评估系统鲁棒性。此外，设计了一套动态可视化仪表板，用于调试系统输出、监控以及分析输入敏感性的根本原因。

Result: 构建了针对COBOL编程语言输入进行鲁棒性评估的工具和流程，并开发了动态表格与可视化仪表板，有助于系统分析和优化。该方案不仅适用于COBOL到Java等语言间的翻译，也可扩展到代码生成或解释等任务。

Conclusion: 该研究提出并实现了一个系统性框架，专为评估及提升LLM系统在处理COBOL代码输入时的鲁棒性，尤其针对商业关键但训练数据稀缺的领域，并通过工具化手段提高了系统分析和优化能力。

Abstract: Systems incorporating large language models (LLMs) as a component are known to be sensitive (i.e., non-robust) to minor input variations that do not change the meaning of the input; such sensitivity may reduce the system's usefulness. Here, we present a framework to evaluate robustness of systems using COBOL code as input; our application is translation between COBOL and Java programming languages, but the approach extends to other tasks such as code generation or explanation. Targeting robustness of systems with COBOL as input is essential yet challenging. Many business-critical applications are written in COBOL, yet these are typically proprietary legacy applications and their code is unavailable to LLMs for training. We develop a library of COBOL paragraph and full-program perturbation methods, and create variant-expanded versions of a benchmark dataset of examples for a specific task. The robustness of the LLM-based system is evaluated by measuring changes in values of individual and aggregate metrics calculated on the system's outputs. Finally, we present a series of dynamic table and chart visualization dashboards that assist in debugging the system's outputs, and monitoring and understanding root causes of the system's sensitivity to input variation. These tools can be further used to improve the system by, for instance, indicating variations that should be handled by pre-processing steps.

</details>


### [16] [HQPEF-Py: Metrics, Python Patterns, and Guidance for Evaluating Hybrid Quantum Programs](https://arxiv.org/abs/2511.18506)
*Michael Adjei Osei,Sidney Shapiro*

Main category: cs.SE

TL;DR: 该论文将混合量子程序作为完整工作流进行评估，提出规范化的评估指标和审计方法，并用Python实现了参考实例，从而提升了量子管道的评估标准化和可复现性。


<details>
  <summary>Details</summary>
Motivation: 目前对混合量子程序的评估多针对单一设备或算法，而缺乏对整个端到端工作流系统性的评价方法。该研究旨在填补此类评估工具的空白，提高混合量子管道的可用性和应用推广。

Method: 构建了HQPEF框架，形式化了工作流感知的量子准备度（QRL）得分、在质量约束下的量子效用归一化加速比（UQ），并设计了针对混合管道的计时和漂移审计。通过Python参考实现说明如何用主流经典与量子求解器进行具体实例化。

Result: 提出了QRL得分、UQ归一化加速比及计时漂移审计方法，并给出了Python实现，验证了这些评估指标可适用于实际主流的量子与经典求解器，提升了评估工作的规范性和可复现性。

Conclusion: 该论文提出了一种面向工作流的混合量子程序评估方法，实现了更系统、可复现的混合量子管道性能评价。

Abstract: We study how to evaluate hybrid quantum programs as end-to-end workflows rather than as isolated devices or algorithms. Building on the Hybrid Quantum Program Evaluation Framework (HQPEF), we formalize a workflow-aware Quantum Readiness Level (QRL) score; define a normalized speedup under quality constraints for the Utility of Quantumness (UQ); and provide a timing-and-drift audit for hybrid pipelines. We complement these definitions with concise Python reference implementations that illustrate how to instantiate the metrics and audit procedures with state-of-the-art classical and quantum solvers (e.g., via Qiskit or PennyLane), while preserving matched-budget discipline and reproducibility.

</details>


### [17] [End-to-End Automated Logging via Multi-Agent Framework](https://arxiv.org/abs/2511.18528)
*Renyi Zhong,Yintong Huo,Wenwei Gu,Yichen Li,Michael R. Lyu*

Main category: cs.SE

TL;DR: Autologger是一个端到端的自动化日志生成框架，结合分类器和多智能体系统，显著提升了“是否需要日志”决策和日志质量，在开源项目实测中效果优异，具有较强通用性。


<details>
  <summary>Details</summary>
Motivation: 软件日志对于系统可观察性至关重要。然而，开发者面临着过度日志带来的高昂成本与日志不足的风险。现有自动化日志工具往往忽略了“是否需要日志”这个根本性决策，同时难以处理日志的多方面复杂性。因此，迫切需要更有效、智能的日志自动化方案，解决完整的日志生成流程。

Method: 本文提出Autologger，一个端到端的混合框架。首先通过微调的分类器Judger判断方法是否需要新增日志；如果需要，则启动多智能体系统，包括Locator用于确定日志位置、Generator决定日志内容，两者配合设计的程序分析和检索工具。系统可适配多种大型语言模型（LLM）。

Result: 在三个成熟开源项目的日志数据上进行评估，Autologger在“是否需要日志”决策上达到96.63%的F1分数。在端到端日志生成质量上，较最佳基线提升16.13%（LLM-as-a-judge评分）。此外，框架在多种主流LLM下均有稳定提升效果，表现出良好泛化能力。

Conclusion: Autologger显著提升了日志自动化的准确性与质量，解决了日志生成中的多个关键环节，可广泛提升各类大型语言模型的日志能力。

Abstract: Software logging is critical for system observability, yet developers face a dual crisis of costly overlogging and risky underlogging. Existing automated logging tools often overlook the fundamental whether-to-log decision and struggle with the composite nature of logging. In this paper, we propose Autologger, a novel hybrid framework that addresses the complete the end-to-end logging pipeline. Autologger first employs a fine-tuned classifier, the Judger, to accurately determine if a method requires new logging statements. If logging is needed, a multi-agent system is activated. The system includes specialized agents: a Locator dedicated to determining where to log, and a Generator focused on what to log. These agents work together, utilizing our designed program analysis and retrieval tools. We evaluate Autologger on a large corpus from three mature open-source projects against state-of-the-art baselines. Our results show that Autologger achieves 96.63\% F1-score on the crucial whether-to-log decision. In an end-to-end setting, Autologger improves the overall quality of generated logging statements by 16.13\% over the strongest baseline, as measured by an LLM-as-a-judge score. We also demonstrate that our framework is generalizable, consistently boosting the performance of various backbone LLMs.

</details>


### [18] [From Code Foundation Models to Agents and Applications: A Practical Guide to Code Intelligence](https://arxiv.org/abs/2511.18538)
*Jian Yang,Wei Zhang,Shark Liu,Jiajun Wu,Shawn Guo,Yizhi Li*

Main category: cs.SE

TL;DR: 本文全面综述并实证分析了大语言模型在代码生成领域的技术进展与实际挑战，涵盖模型训练全流程和主流模型的性能比较，关注学术与实际应用的脱节，并为后续研究和应用实践提出下一个阶段的方向建议。


<details>
  <summary>Details</summary>
Motivation: 当前生成式大模型（LLMs）推动了自动化软件开发，能够将自然语言直接转换为功能性代码，广泛应用于实际商业工具中。由于技术快速进步以及学术界与工业界之间存在较大差距，对LLMs在代码生成领域的系统性分析需求强烈。

Method: 本文采用系统性综述和实验方法，对代码相关的大模型生命周期进行全面分析，包括数据处理、高级提示、预训练、微调、强化学习以及自主编码等环节。对主流通用大模型与专用代码大模型进行了技术和实施方面的比较评估，并通过一系列实验分析模型的扩展规律、架构选择、超参数敏感性及数据集影响。

Result: 研究系统评估了主流通用及专用代码生成模型的能力，对现有技术进行深入比较，揭示了学术基准与实际应用之间的差距，包括代码正确性、安全性、大型代码库的上下文感知能力及开发流程集成。论文还探索了未来有潜力的研究方向与行业实际需求的对接。

Conclusion: 大语言模型已极大推动代码自动生成的发展，本文通过全方位的分析和大量实证实验，厘清了该领域的发展现状及面临挑战，并提出了缩小学界与业界之间差距的建议，为未来代码生成模型研究与实际部署提供指导参考。

Abstract: Large language models (LLMs) have fundamentally transformed automated software development by enabling direct translation of natural language descriptions into functional code, driving commercial adoption through tools like Github Copilot (Microsoft), Cursor (Anysphere), Trae (ByteDance), and Claude Code (Anthropic). While the field has evolved dramatically from rule-based systems to Transformer-based architectures, achieving performance improvements from single-digit to over 95\% success rates on benchmarks like HumanEval. In this work, we provide a comprehensive synthesis and practical guide (a series of analytic and probing experiments) about code LLMs, systematically examining the complete model life cycle from data curation to post-training through advanced prompting paradigms, code pre-training, supervised fine-tuning, reinforcement learning, and autonomous coding agents. We analyze the code capability of the general LLMs (GPT-4, Claude, LLaMA) and code-specialized LLMs (StarCoder, Code LLaMA, DeepSeek-Coder, and QwenCoder), critically examining the techniques, design decisions, and trade-offs. Further, we articulate the research-practice gap between academic research (e.g., benchmarks and tasks) and real-world deployment (e.g., software-related code tasks), including code correctness, security, contextual awareness of large codebases, and integration with development workflows, and map promising research directions to practical needs. Last, we conduct a series of experiments to provide a comprehensive analysis of code pre-training, supervised fine-tuning, and reinforcement learning, covering scaling law, framework selection, hyperparameter sensitivity, model architectures, and dataset comparisons.

</details>


### [19] [Strategic Decision Framework for Enterprise LLM Adoption](https://arxiv.org/abs/2511.18589)
*Michael Trusov,Minha Hwang,Zainab Jamal,Swarup Chandra*

Main category: cs.SE

TL;DR: 本文提出并验证了一个六步决策框架，帮助企业有序、安全地采纳和应用大语言模型，应对数据安全、开发和部署等核心难题，已通过实际案例验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型为企业带来创新机会，但在数据安全、开发方法、基础设施和部署策略等方面面临诸多挑战，特别是在敏感行业如医疗、金融和软件开发领域。

Method: 通过对成功和失败案例的广泛访谈和分析，总结并提出了六步决策框架，并结合B2B、B2C不同场景的真实案例，验证其实用性。

Result: 研究总结了企业在采纳LLM过程中面临的关键问题，并提出具体实用的决策框架，使企业能更有针对性地实施LLM，确保合规、安全与业务目标的统一。

Conclusion: 提出了一个系统的六步决策框架，帮助企业安全、高效地采纳和部署大语言模型（LLMs），指导企业完成从应用选择到最终部署的全过程决策。

Abstract: Organizations are rapidly adopting Large Language Models (LLMs) to transform their operations, yet they lack clear guidance on key decisions for adoption and implementation. While LLMs offer powerful capabilities in content generation, assisted coding, and process automation, businesses face critical challenges in data security, LLM solution development approach, infrastructure requirements, and deployment strategies. Healthcare providers must protect patient data while leveraging LLMs for medical analysis, financial institutions need to balance automated customer service with regulatory compliance, and software companies seek to enhance development productivity while maintaining code security.
  This article presents a systematic six-step decision framework for LLM adoption, helping organizations navigate from initial application selection to final deployment. Based on extensive interviews and analysis of successful and failed implementations, our framework provides practical guidance for business leaders to align technological capabilities with business objectives. Through key decision points and real-world examples from both B2B and B2C contexts, organizations can make informed decisions about LLM adoption while ensuring secure and efficient integration across various use cases, from customer service automation to content creation and advanced analytics.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [20] [Uncertainty Removal in Verification of Nonlinear Systems against Signal Temporal Logic via Incremental Reachability Analysis](https://arxiv.org/abs/2511.17617)
*Antoine Besset,Joris Tillet,Julien Alexandre dit Sandretto*

Main category: cs.LO

TL;DR: 本文提出一种用于不确定非线性系统STL规范验证的新方法，利用可达性分析和不确定性标记，有效降低了满足性模糊性，实现了更加精准高效的系统监控。


<details>
  <summary>Details</summary>
Motivation: 在非线性连续时间系统中，由于可达集的过度逼近或仿真不完备，STL规范验证常出现满足性不确定的问题，有必要提出一种方法提升验证的精度和效率。

Method: 方法基于可达性分析，将STL语义扩展为布尔区间运算，并通过不确定性标记传播，实现精细追踪。通过分解满足性信号，并针对带有不确定性的可达集进行细致化处理，提高验证效率，支持系统增量演化下的在线或离线监控。

Result: 案例分析表明，当应用于非线性振荡器时，该框架显著减少了满足性判定中的模糊性，验证了所提方法的有效性。

Conclusion: 文中提出的基于可达性分析的框架能够有效减少对非线性系统信号时序逻辑(STL)规范验证中的满足性不确定性。通过精细化仅与不确定性相关的可达集，大幅提升了验证的精度和效率。案例分析显示，该方法能显著降低满足性模糊性。

Abstract: A framework is presented for the verification of Signal Temporal Logic (STL) specifications over continuous-time nonlinear systems under uncertainty. Based on reachability analysis, the proposed method addresses indeterminate satisfaction caused by over-approximated reachable sets or incomplete simulations. STL semantics is extended via Boolean interval arithmetic, enabling the decomposition of satisfaction signals into unitary components with traceable uncertainty markers. These are propagated through the satisfaction tree, supporting precise identification even in nested formulas. To improve efficiency, only the reachable sets contributing to uncertainty are refined, identified through the associated markers. The framework allows online or offline monitoring to adapt to incremental system evolution while avoiding unnecessary recomputation. A case study on a nonlinear oscillator demonstrates a significant reduction in satisfaction ambiguity, highlighting the effectiveness of the approach.

</details>


### [21] [Comparing Labeled Markov Chains: A Cantor-Kantorovich Approach](https://arxiv.org/abs/2511.18103)
*Adrien Banse,Alessandro Abate,Raphaël M. Jungers*

Main category: cs.LO

TL;DR: 本文分析了用于比较概率模型的Cantor-Kantorovich距离：揭示其计算为#P-hard，给出上界及误差关系，并提出实用的近似计算方法，为概率语言建模与模型评估提供理论支持。


<details>
  <summary>Details</summary>
Motivation: Labeled Markov Chains (LMCs)广泛用于建模复杂概率语言，但如何比较两个LMCs，评估抽象的精度或量化模型扰动的影响，是一个核心挑战。最近提出的Cantor-Kantorovich (CK)距离为解决该问题提供了新视角，因而需要深入研究该距离的理论和计算属性。

Method: 首先，将CK距离表述为有限视界下总变差距离的贴现和，这是贴现线性距离的一种。然后，从计算复杂性、连续性属性和近似方法三个角度分析CK距离。具体包括证明CK距离的精确计算是#P-hard，提出可计算近似方案，并解析该方案的复杂性及与概率误差的内在关系。

Result: 证明了CK距离的精确计算为#P-hard；给出了CK距离的上界（与两个LMC的近似关系相关）；展示了有界的CK距离可推出有限视界轨迹的概率误差也有上界；最后提出了可行的计算近似方案，该方案同样是#P-hard。

Conclusion: 本文系统阐述了CK距离的理论基础、关联性质以及与现有距离度量的关系，为LMC模型比较提供了严密的数学依据和计算策略。

Abstract: Labeled Markov Chains (or LMCs for short) are useful mathematical objects to model complex probabilistic languages. A central challenge is to compare two LMCs, for example to assess the accuracy of an abstraction or to quantify the effect of model perturbations. In this work, we study the recently introduced Cantor-Kantorovich (or CK) distance. In particular we show that the latter can be framed as a discounted sum of finite-horizon Total Variation distances, making it an instance of discounted linear distance, but arising from the natural Cantor topology. Building on the latter observation, we analyze the properties of the CK distance along three dimensions: computational complexity, continuity properties and approximation. More precisely, we show that the exact computation of the CK distance is #P-hard. We also provide an upper bound on the CK distance as a function of the approximation relation between the two LMCs, and show that a bounded CK distance implies a bounded error between probabilities of finite-horizon traces. Finally, we provide a computable approximation scheme, and show that the latter is also #P-hard. Altogether, our results provide a rigorous theoretical foundation for the CK distance and clarify its relationship with existing distances.

</details>


### [22] [Formalizing Computational Paths and Fundamental Groups in Lean](https://arxiv.org/abs/2511.19142)
*Arthur F. Ramos,Anjolina G. de Oliveira,Ruy J. G. B. de Queiroz,Tiago M. L. de Veras*

Main category: cs.LO

TL;DR: 通过计算路径框架在Lean 4中形式化命题等价，构建了支持复杂同伦计算的工具库，并应用于代数拓扑的典型例子，实现可复用和自动化证明。这推动了类型理论在同伦计算的实际应用。


<details>
  <summary>Details</summary>
Motivation: 以往关于命题等价的处理方式不够明确、难以进行具体的同伦计算。通过将等价视为带标签的推理步骤和重写规则构建的“计算路径”，可以将同伦类型理论的思想与实际计算结合，实现更具体的构造。

Method: 在Lean 4证明助理中实现并机械化了计算路径框架，具体包括路径构造、组合、逆元素和重写系统，实现了冗余/平凡路径的判别。并将相关内容整理为可复用的Lean库（ComputationalPathsLean），提供路径、重写和环空间等接口。最后，用两个经典代数拓扑例子展示了其应用能力：证明圆的基本群与整数同构，环面的基本群与两个整数乘积同构。

Result: 论文展示了计算路径理论在Lean 4中的完整形式化，实现了弱群体结构并支持复杂的同伦论计算。还以具体代数拓扑问题为例，表明这种方法实用性强、可扩展性高，并已开源全部定义和证明。

Conclusion: 利用计算路径框架，既保留了原有的群体结构和同伦动力学，又能实际解决非平凡的拓扑问题，还方便在自动化证明环境中使用和扩展，从而推动了同伦型理论在具体计算中的应用。

Abstract: Computational paths treat propositional equality as explicit paths built from labelled deduction steps and rewrite rules. This view originates in work by de Queiroz and collaborators and yields a weak groupoid structure for equality, together with a computational account of homotopy inspired by homotopy type theory. In this paper we present a complete mechanization of this framework in Lean 4 and show how it supports concrete homotopy theoretic computations. Our contributions are threefold. First, we formalize the theory of computational paths in Lean, including path formation, composition, inverses, and a rewrite system that identifies redundant or trivial paths. We prove that equality types with computational paths carry a weak groupoid structure in the sense of the original theory. Second, we organize this material into a reusable Lean library, ComputationalPathsLean, which exposes an interface for paths, rewrites, and loop spaces. This library allows later developments to treat computational paths as a drop-in replacement for propositional equality when reasoning about homotopical structure. Third, we apply the library to two canonical examples in algebraic topology. We give Lean proofs that the fundamental group of the circle is isomorphic to the integers and that the fundamental group of the torus is isomorphic to the product of two copies of the integers, both via computational paths. These case studies demonstrate that the computational paths approach scales to nontrivial homotopical computations in a modern proof assistant. All the definitions and proofs described here are available in an open-source Lean 4 repository.

</details>


### [23] [A General (Uniform) Relational Semantics for Sentential Logics](https://arxiv.org/abs/2511.18458)
*Chrysafis Hartonas*

Main category: cs.LO

TL;DR: 通过推广Jónsson-Tarski理论，本文提出了统一描述经典与非经典句子逻辑的关系语义框架，实现了更广义的完备性和对应性证明。


<details>
  <summary>Details</summary>
Motivation: 目前缺少一种能同时覆盖经典与非经典逻辑的统一关系语义框架，因此需要构建更通用的语义工具，并保证在等价代数语义下的完备性与对应性。

Method: 通过推广Jónsson-Tarski表征理论，将关系结构应用于偏序集、半格、有界格及其带有拟算子的情况。使用无选择公理的典范扩张构造实现完备性证明，利用广义Sahlqvist-van Benthem算法获得对应性结果。

Result: 本文构建了一种通用的关系语义框架，证明了在广泛的逻辑体系中的完备性和对应性，同时推广了现有的模态逻辑技术。

Conclusion: 本文提出的通用关系语义框架能够统一描述经典和非经典句子逻辑，并为其提供完备性和对应性结果。

Abstract: We present a general relational semantics framework which, by varying the axiomatization and components of the relational structures, provides a uniform semantics for sentential logics, classical and non-classical alike. The approach we take rests on a generalization of the Jónsson-Tarski representation (and duality) for Boolean algebras with operators to the cases of posets, semilattices, or bounded lattices (with, or without distribution) with quasi-operators. Completeness proofs rely on a choice-free construction of canonical extensions for the algebras in the quasivarieties of the equivalent algebraic semantics of the logics. Correspondence results for axiomatic extensions of the logics of implication that we study rely on a fully abstract translation into their modal companions and they are calculated using a generalized Sahlqvist - van Benthem algorithm.

</details>


### [24] [A SAT-based Approach for Specification, Analysis, and Justification of Reductions between NP-complete Problems](https://arxiv.org/abs/2511.18639)
*Predrag Janičić*

Main category: cs.LO

TL;DR: 提出了一种利用URSA系统的自动化方法，能高效开发、分析和验证NP完全问题之间的归约，区别于传统系统，提升归约工具的能力。


<details>
  <summary>Details</summary>
Motivation: 论文旨在提出一种创新的方法，用于开发、分析和验证NP完全问题之间的归约。归约在理论计算机科学中非常关键，是理解NP完全性和解决复杂问题的基础。作者希望通过提高归约过程的自动化和可验证性来促进该领域的发展。

Method: 该方法利用URSA系统，一个基于SAT的约束求解器，并且结合了一些区别于现有系统的新特性。通过这种系统化和自动化工具，可以更有效地进行NP完全问题归约相关的工作。

Result: 使用URSA系统的方法能够实现对NP完全问题归约的开发、分析和验证，提供了区别于已有工具的新途径，可能提高归约的效率和准确性。

Conclusion: 论文提出的方法可以系统化、自动地进行NP完全问题的归约开发与验证，有望在理论计算机科学及相关应用领域提供更优的解决方案。

Abstract: We propose a novel approach for the development, analysis, and verification of reductions between NP-complete problems. This method uses the URSA system, a SAT-based constraint solver and incorporates features that distinguish it from existing related systems.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [25] [SCARE: A Benchmark for SQL Correction and Question Answerability Classification for Reliable EHR Question Answering](https://arxiv.org/abs/2511.17559)
*Gyubok Lee,Woosog Chay,Edward Choi*

Main category: cs.CL

TL;DR: 本文提出SCARE基准，用于评估电子健康记录问答系统中的SQL事后验证机制，包括问题可答性判定和SQL验证/纠错。涵盖多数据库及多模型，实验证明SCARE揭示了问题分类和SQL纠错之间的重大挑战，为未来研究指明方向。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型使得临床医生可以使用自然语言查询电子健康记录（EHR）中的结构化数据，但将这些模型用于临床安全关键环境依然困难，主要原因是生成或输入错误的SQL查询可能损害临床决策与患者安全。而目前缺乏用于评估事后验证机制（即在SQL执行前检查和验证生成结果）的统一基准。

Method: 提出了SCARE这个新基准，用于评测EHR问答系统中的事后安全层。SCARE评估两个联合任务：（1）判断问题是否可回答、含糊或无法回答；（2）验证或修正候选SQL查询。SCARE包含来自MIMIC-III、MIMIC-IV和eICU数据库的4200个问题-候选SQL-期望输出三元组，覆盖七种主流text-to-SQL模型生成的数据。对多种方法进行了对比实验，包括两阶段方法和agentic框架。

Result: 通过实验，揭示了问题分类与SQL错误纠正之间存在关键权衡，并指出了目前面临的主要挑战及未来研究方向。

Conclusion: SCARE为EHR问答系统的安全部署提供了统一基准，有助于系统性评估和改进SQL验证机制，推动在临床安全关键应用中的LLM落地。

Abstract: Recent advances in Large Language Models (LLMs) have enabled the development of text-to-SQL models that allow clinicians to query structured data stored in Electronic Health Records (EHRs) using natural language. However, deploying these models for EHR question answering (QA) systems in safety-critical clinical environments remains challenging: incorrect SQL queries-whether caused by model errors or problematic user inputs-can undermine clinical decision-making and jeopardize patient care. While prior work has mainly focused on improving SQL generation accuracy or filtering questions before execution, there is a lack of a unified benchmark for evaluating independent post-hoc verification mechanisms (i.e., a component that inspects and validates the generated SQL before execution), which is crucial for safe deployment. To fill this gap, we introduce SCARE, a benchmark for evaluating methods that function as a post-hoc safety layer in EHR QA systems. SCARE evaluates the joint task of (1) classifying question answerability (i.e., determining whether a question is answerable, ambiguous, or unanswerable) and (2) verifying or correcting candidate SQL queries. The benchmark comprises 4,200 triples of questions, candidate SQL queries, and expected model outputs, grounded in the MIMIC-III, MIMIC-IV, and eICU databases. It covers a diverse set of questions and corresponding candidate SQL queries generated by seven different text-to-SQL models, ensuring a realistic and challenging evaluation. Using SCARE, we benchmark a range of approaches-from two-stage methods to agentic frameworks. Our experiments reveal a critical trade-off between question classification and SQL error correction, highlighting key challenges and outlining directions for future research.

</details>


### [26] [$A^3$: Attention-Aware Accurate KV Cache Fusion for Fast Large Language Model Serving](https://arxiv.org/abs/2511.17560)
*Yuechi Zhou,Yi Su,Jianxin Zhang,Juntao Li,Qingrong Xia,Zhefeng Wang,Xinyu Duan,Baoxing Huai*

Main category: cs.CL

TL;DR: LLM处理长文本时现有KV Cache重复利用技术易降性能，A^3算法通过关注相关性实现准确高效地信息融合，使系统更快且表现更优。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型（LLMs）虽能处理长文本，但在处理如多轮对话、法律文档或RAG系统等长输入时，解码延迟和内存开销很大，阻碍实际部署。现有KV Cache重复利用方法虽然能缓解开销，但会导致性能下降。

Method: 作者深入分析了基于重计算的KV Cache重复利用方法，发现重算的token常常与问题最相关的上下文片段对齐不佳，影响了关键语境表达的更新。为解决这一问题，提出了A^3（Attention-Aware Accurate KV Cache Fusion）算法——预先计算各文本片段的KV Cache，并基于其与问题的相关性选择性地融合，以实现高效、准确的KV信息整合。

Result: 多项基准测试和不同LLM实验表明，A^3算法在保证最佳任务表现的同时（优于四个基线算法），可将“首token生成延迟”降低一半。

Conclusion: A^3算法有效解决了长文本处理时KV Cache重复利用导致的性能下降问题，实现了更高效且准确的上下文表达融合，为长文本任务在实际部署提供了可行的解决方案。

Abstract: Large language models (LLMs) have demonstrated strong capabilities in processing long contexts, enabling them to tackle tasks involving long textual inputs such as multi-turn conversations, legal documents, or retrieved documents in Retrieval-Augmented Generation (RAG) systems. However, despite their ability to handle long sequences, the resulting decoding latency and memory overhead remain substantial, posing challenges for real-world deployment. Recent advances in KV Cache reuse have shown potential to mitigate these costs, but still suffer from notable performance degradation. To address this issue, we conduct an in-depth investigation of recomputation-based reuse methods and observe that the recomputed tokens often fail to align with the context segments most relevant to the question. This misalignment hinders proper updates to the critical contextual representations. Therefore, we propose the $\textbf{A}$ttention-$\textbf{A}$ware $\textbf{A}$ccurate KV Cache Fusion algorithm ($A^3$), which precomputes and selectively fuses the KV Cache of text chunks based on their relevance to the question, achieving accurate integration with minimal computational overhead. Extensive experiments on various benchmarks and LLMs demonstrate that $A^3$ achieves the best task performance compared to four baselines while reducing the time-to-first-token (TTFT) by 2$\times$.

</details>


### [27] [LexInstructEval: Lexical Instruction Following Evaluation for Large Language Models](https://arxiv.org/abs/2511.17561)
*Huimin Ren,Yan Liang,Baiqiao Su,Chaobo Sun,Hengtong Lu,Kaike Zhang,Chen Wei*

Main category: cs.CL

TL;DR: 本文提出LexInstructEval框架，通过程序化和规则化语法细粒度评估大语言模型指令遵循能力，弥补了人工和自动评测的不足，并公开了相关数据和工具，助力模型可控性研究。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在精确执行复杂、高精度词汇指令方面能力出众，但对这种能力的评估仍存在挑战。现有方法要么依赖主观且昂贵的人工评估，要么基于自动化的LLM评审系统，但存在偏见和不可靠问题。现有程序化基准普遍缺乏表达能力，难以细致测试复杂组合约束。为此，需要一个更高效、细致和客观的评估方法。

Method: 作者提出了LexInstructEval评测框架。该框架基于正式的规则语法，将复杂指令分解为<Procedure, Relation, Value>三元组。通过多阶段、人工参与的数据生成流程，系统性构建多样化数据集，并利用透明的程序化引擎实现客观验证。

Result: LexInstructEval能够细粒度评估LLMs对词汇指令的跟随能力，并且可自动化、客观地验证模型输出。作者公开了数据集和评测工具，为后续相关研究提供了便利。

Conclusion: LexInstructEval提升了对LLMs可控性和可靠性的评测水平，填补了现有评测主观性或表达能力不足的空白，为相关领域研究提供了关键资源和工具。

Abstract: The ability of Large Language Models (LLMs) to precisely follow complex and fine-grained lexical instructions is a cornerstone of their utility and controllability. However, evaluating this capability remains a significant challenge. Current methods either rely on subjective and costly human evaluation or on automated LLM-as-a-judge systems, which suffer from inherent biases and unreliability. Existing programmatic benchmarks, while objective, often lack the expressiveness to test intricate, compositional constraints at a granular level. To address these limitations, we introduce LexInstructEval, a new benchmark and evaluation framework for fine-grained lexical instruction following. Our framework is built upon a formal, rule-based grammar that deconstructs complex instructions into a canonical <Procedure, Relation, Value> triplet. This grammar enables the systematic generation of a diverse dataset through a multi-stage, human-in-the-loop pipeline and facilitates objective verification via a transparent, programmatic engine. We release our dataset and open-source evaluation tools to facilitate further research into the controllability and reliability of LLMs.

</details>


### [28] [ChineseErrorCorrector3-4B: State-of-the-Art Chinese Spelling and Grammar Corrector](https://arxiv.org/abs/2511.17562)
*Wei Tian,YuhaoZhou*

Main category: cs.CL

TL;DR: 提出ChineseErrorCorrector3-4B，一个基于Qwen3-4B的中文拼写和语法纠错统一模型，在多个权威基准集上纠错成绩超过现有模型，拼写与语法纠错均获第一。


<details>
  <summary>Details</summary>
Motivation: 尽管汉语中拼写和语法错误纠正技术取得了一定进展，但现有模型在统一处理两种错误时性能有限，且在权威数据集上的表现有待提升。为提升汉语拼写和语法纠正的准确性与实用性，亟需一个表现更优、通用性更强的模型。

Method: 本文在Qwen3-4B基础上，提出了ChineseErrorCorrector3-4B模型，将拼写纠正（CSC）和语法纠正（CGC）统一于同一架构，并在多个权威数据集上进行综合评测。

Result: 在SIGHAN-2015、EC-LAW、MCSC和NaCGEC等数据集上，该模型F1与F0.5分数均显著超过现有公开模型，无论拼写还是语法纠正任务均排名第一，显示优异的综合能力。

Conclusion: ChineseErrorCorrector3-4B在中文拼写与语法错误统一纠正领域取得最新最优表现，提升了中文文本自动纠错效果，并为相关任务提供了强有力的解决方案。

Abstract: This paper introduces ChineseErrorCorrector3-4B, a unified model for Chinese spelling and grammatical error correction based on Qwen3-4B. The model demonstrates outstanding performance in general text correction tasks and achieves state-of-the-art results in both spelling correction (CSC) and grammatical correction (CGC). On several authoritative benchmark datasets -- including SIGHAN-2015, EC-LAW, MCSC, and NaCGEC -- the model's F1 and F0.5 scores significantly surpass existing publicly available models, ranking first in both spelling and grammatical error correction tasks.

</details>


### [29] [Generative Caching for Structurally Similar Prompts and Responses](https://arxiv.org/abs/2511.17565)
*Sarthak Chakraborty,Suman Nath,Xuchao Zhang,Chetan Bansal,Indranil Gupta*

Main category: cs.CL

TL;DR: 针对结构相似但细节不同的提示缓存需求，提出生成式缓存方法，显著提升命中率与响应效率，减少错误缓存。


<details>
  <summary>Details</summary>
Motivation: 传统缓存方法无法很好地处理结构相似但细节不同的提示。精确匹配过于严格，语义匹配又可能忽略重要差异，容易导致缓存错误。

Method: 提出了一种生成式缓存方法，通过识别结构相似提示间可复用的响应模式，为新请求综合定制化输出。

Result: 新方法在无重复提示的数据集上实现了83%的缓存命中率且几乎无错误命中。在代理性工作流场景下，缓存命中率提升约20%，端到端执行延迟降低约34%。

Conclusion: 新方法能够对结构相似的提示进行缓存，有效提升缓存命中率且错误率低，显著优化执行效率。

Abstract: Large Language Models (LLMs) are increasingly being used to plan, reason, and execute tasks across diverse scenarios. In use cases like repeatable workflows and agentic settings, prompts are often reused with minor variations while having a similar structure for recurring tasks. This opens up opportunities for caching. However, exact prompt matching fails on such structurally similar prompts, while semantic caching may produce incorrect responses by ignoring critical differences. To address this, we introduce \ourmethod{}, a generative cache that produces variation-aware responses for structurally similar prompts. \ourmethod{} identifies reusable response patterns across similar prompt structures and synthesizes customized outputs for new requests. We show that \ourmethod{} achieves 83\% cache hit rate, while having minimal incorrect hits on datasets without prompt repetition. In agentic workflows, it improves cache hit rate by $\sim$20\% and reduces end-to-end execution latency by $\sim$34\% compared to standard prompt matching.

</details>


### [30] [Community-Aligned Behavior Under Uncertainty: Evidence of Epistemic Stance Transfer in LLMs](https://arxiv.org/abs/2511.17572)
*Patrick Gerard,Aiden Chang,Svitlana Volkova*

Main category: cs.CL

TL;DR: 本研究发现对齐后的大语言模型在缺乏知识时仍会展现社区特有的行为模式，说明其对齐超越了简单模仿，并为检测偏见与提升安全性提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 探讨与特定网络社区对齐的大型语言模型（LLM），其行为模式是一般可归纳的，还是仅仅是训练数据的回忆。

Method: 提出了验证LLM是否具备知识迁移能力的框架，包括对事件知识的有针对性删除、多重探针验证，并在无知识情境下评估其是否仍再现社区行为模式。实验数据来自俄乌军事讨论和美国Twitter党派言论。

Result: 即使在大规模事实删除后，对齐的LLM依然保持了稳定且具有社区特征的行为模式，能稳健应对不确定性。

Conclusion: 结果表明LLM的对齐不仅仅是表面模仿，模型内部编码了结构化、可迁移的行为倾向。该方法为检测模型偏见提供了新工具，助力于更安全透明的应用。

Abstract: When large language models (LLMs) are aligned to a specific online community, do they exhibit generalizable behavioral patterns that mirror that community's attitudes and responses to new uncertainty, or are they simply recalling patterns from training data? We introduce a framework to test epistemic stance transfer: targeted deletion of event knowledge, validated with multiple probes, followed by evaluation of whether models still reproduce the community's organic response patterns under ignorance. Using Russian--Ukrainian military discourse and U.S. partisan Twitter data, we find that even after aggressive fact removal, aligned LLMs maintain stable, community-specific behavioral patterns for handling uncertainty. These results provide evidence that alignment encodes structured, generalizable behaviors beyond surface mimicry. Our framework offers a systematic way to detect behavioral biases that persist under ignorance, advancing efforts toward safer and more transparent LLM deployments.

</details>


### [31] [Random Text, Zipf's Law, Critical Length,and Implications for Large Language Models](https://arxiv.org/abs/2511.17575)
*Vladimir Berman*

Main category: cs.CL

TL;DR: 该文建立了不含任何语言属性的随机符号模型，通过概率和组合学分析显示，Zipf词频规律、词长分布等语言常见结构可在纯随机文本中自然产生，为理解哪些语言统计现象需要更深层解释提供了理论下限。


<details>
  <summary>Details</summary>
Motivation: 探究在完全无语法、语义及形态结构的极简符号系统下，文本的基本结构性质，以及著名的Zipf词频分布能否由纯粹的分割与组合机制生成，从而为复杂语言现象与大型语言模型中的统计结构提供数学基线。

Method: 构建了一个极简的非语言化文本模型：字母表有限，文本为独立符号（包括空格）的随机抽取，单词定义为不含空格的最大连续符号块。分析得到单词长度的分布、词表增长规律、关键字长、以及词频-排名的Zipf规律。所有结果利用概率论与组合学推导，部分采用coupon-collector论证。

Result: 1）单词长度服从由空格概率决定的几何分布；2）给出了指定长度单词总数与不同类型单词数量的闭式计算式，并推导关键字长k*；3）通过组合可能字符串数量与每种概率的指数关系，严格推导出Zipf型p(r) ~ r^{-alpha}分布，指数alpha与字母表大小及空格概率明确相关。强化了Zipf分布可由随机分割与组合学涌现的观点。

Conclusion: Zipf-like词频规律可以仅通过符号的组合学和分割机制在一个非语言化、随机文本模型中自然涌现，无需诉诸语言的优化或复杂结构。该模型可作为自然语言与大型语言模型的词统计的基本对照。

Abstract: We study a deliberately simple, fully non-linguistic model of text: a sequence of independent draws from a finite alphabet of letters plus a single space symbol. A word is defined as a maximal block of non-space symbols. Within this symbol-level framework, which assumes no morphology, syntax, or semantics, we derive several structural results. First, word lengths follow a geometric distribution governed solely by the probability of the space symbol. Second, the expected number of words of a given length, and the expected number of distinct words of that length, admit closed-form expressions based on a coupon-collector argument. This yields a critical word length k* at which word types transition from appearing many times on average to appearing at most once. Third, combining the exponential growth of the number of possible strings of length k with the exponential decay of the probability of each string, we obtain a Zipf-type rank-frequency law p(r) proportional to r^{-alpha}, with an exponent determined explicitly by the alphabet size and the space probability.
  Our contribution is twofold. Mathematically, we give a unified derivation linking word lengths, vocabulary growth, critical length, and rank-frequency structure in a single explicit model. Conceptually, we argue that this provides a structurally grounded null model for both natural-language word statistics and token statistics in large language models. The results show that Zipf-like patterns can arise purely from combinatorics and segmentation, without optimization principles or linguistic organization, and help clarify which phenomena require deeper explanation beyond random-text structure.

</details>


### [32] [Computational frame analysis revisited: On LLMs for studying news coverage](https://arxiv.org/abs/2511.17746)
*Sharaj Kunjar,Alyssa Hasegawa Smith,Tyler R Mckenzie,Rushali Mohbe,Samuel V Scarpino,Brooke Foucault Welles*

Main category: cs.CL

TL;DR: 本文比较了生成式LLMs、传统机器学习模型和人工编码在新闻媒体框架分析中的表现。结果表明，虽然LLMs有应用潜力，但人工方法和小模型在多任务下表现更优，人类验证依然不可或缺。建议采用方法多元与工具互补，推动该领域发展。


<details>
  <summary>Details</summary>
Motivation: 生成式大语言模型（LLMs）如GPT和Claude越来越多地用于内容分析工具，但它们在媒体框架分析中的有效性尚未明确，需要与传统的计算方法和人工编码进行系统比较。

Method: 系统评估生成式LLMs、词袋模型、仅编码器的变换器模型以及人工编码方法，并在一份针对2022年美国Mpox疫情的六个月新闻报道的新金标准数据集上进行比较。

Result: 生成式LLMs在某些应用上显示出潜力，但总体上被人工编码者和部分小型语言模型超越。所有情况下都需要某种形式的人类验证来决定模型选择。

Conclusion: 鼓励方法多元化，结合多种工具协同使用，并提出了未来研究的计算框架分析路线图。

Abstract: Computational approaches have previously shown various promises and pitfalls when it comes to the reliable identification of media frames. Generative LLMs like GPT and Claude are increasingly being used as content analytical tools, but how effective are they for frame analysis? We address this question by systematically evaluating them against their computational predecessors: bag-of-words models and encoder-only transformers; and traditional manual coding procedures. Our analysis rests on a novel gold standard dataset that we inductively and iteratively developed through the study, investigating six months of news coverage of the US Mpox epidemic of 2022. While we discover some potential applications for generative LLMs, we demonstrate that they were consistently outperformed by manual coders, and in some instances, by smaller language models. Some form of human validation was always necessary to determine appropriate model choice. Additionally, by examining how the suitability of various approaches depended on the nature of different tasks that were part of our frame analytical workflow, we provide insights as to how researchers may leverage the complementarity of these approaches to use them in tandem. We conclude by endorsing a methodologically pluralistic approach and put forth a roadmap for computational frame analysis for researchers going forward.

</details>


### [33] [PoETa v2: Toward More Robust Evaluation of Large Language Models in Portuguese](https://arxiv.org/abs/2511.17808)
*Thales Sales Almeida,Rodrigo Nogueira,Hélio Pedrini*

Main category: cs.CL

TL;DR: 本文开发并发布了葡萄牙语大模型的最大规模基准PoETa v2，通过40多个任务评测了20款主流模型，总结资源和适配对性能的影响，并与英语任务表现进行对比，为葡萄牙语NLP研究提供了基础工具和数据。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在不同语言和文化环境中的表现存在显著差异，因此需要对多语种进行系统性评测。葡萄牙语作为一种被广泛使用但评测资源有限的语言，亟需大规模系统性测试和基准。

Method: 提出并利用了PoETa v2这一全新的葡萄牙语大型基准套件，涵盖了40多个任务，对20余种不同训练规模和计算资源的大语言模型进行了全面评估，并将葡萄牙语和英语在同类任务上的表现进行了对比分析。

Result: 研究显示，模型的计算投入和针对葡萄牙语的适应训练会对其葡萄牙语表现产生重要影响，并量化了葡萄牙语与英语任务的性能差距。PoETa v2为未来葡萄牙语语言建模与评估提供了基础和参考。

Conclusion: PoETa v2基准实现了葡萄牙语大语言模型迄今为止最全面的评测，为模型性能提升和多语种NLP研究奠定了坚实基础，促进了低资源语种的系统研究。

Abstract: Large Language Models (LLMs) exhibit significant variations in performance across linguistic and cultural contexts, underscoring the need for systematic evaluation in diverse languages. In this work, we present the most extensive evaluation of LLMs for the Portuguese language to date. Leveraging our newly introduced PoETa v2 benchmark -- a comprehensive suite of over 40 tasks in Portuguese -- we assess more than 20 models covering a broad spectrum of training scales and computational resources. Our study reveals how computational investment and language-specific adaptation impact performance in Portuguese, while also analyzing performance gaps in comparison to equivalent tasks in English. Through this benchmark and analysis, PoETa v2 lays the groundwork for future research on Portuguese language modeling and evaluation. The benchmark is available at https://github.com/PoETaV2/PoETaV2.

</details>


### [34] [Point of Order: Action-Aware LLM Persona Modeling for Realistic Civic Simulation](https://arxiv.org/abs/2511.17813)
*Scott Merrill,Shashank Srivastava*

Main category: cs.CL

TL;DR: 本研究提出将Zoom会议公开录音转为带身份标签及语用信息的转录数据，并在地方政府多方讨论场景下微调LLM，有效提升了模型对现实讨论及角色的模拟能力，为人工智能社会模拟提供了坚实的数据基础。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型能够模拟多方讨论，但由于缺乏带有发言者归属的数据，现实建模效果有限。现有ASR转录通常只提供匿名发言者标签，阻碍了模型对一致性的人类行为进行捕捉。

Method: 提出了一个可复现的数据处理流程，将公开Zoom录音转化为包含发言者身份、人物画像以及语用动作标签（如[propose_motion]）的转录数据。并公布了三个地方政府审议的高质量数据集。将大语言模型在该数据上进行微调，用于建模特定角色化参与者。

Result: 基于“动作感知”数据进行微调后，模型困惑度(PPL)降低了67%，发言人一致性和真实性的分类指标近乎翻倍。图灵式人工评估显示，模型生成的讨论与真实讨论往往难以区分。

Conclusion: 引入的新流程与数据极大提升了多方讨论模拟的现实性和参与者一致性，为复杂现实公民情景的可扩展性模拟提供了实际工具和方法。

Abstract: Large language models offer opportunities to simulate multi-party deliberation, but realistic modeling remains limited by a lack of speaker-attributed data. Transcripts produced via automatic speech recognition (ASR) assign anonymous speaker labels (e.g., Speaker_1), preventing models from capturing consistent human behavior. This work introduces a reproducible pipeline to transform public Zoom recordings into speaker-attributed transcripts with metadata like persona profiles and pragmatic action tags (e.g., [propose_motion]). We release three local government deliberation datasets: Appellate Court hearings, School Board meetings, and Municipal Council sessions. Fine-tuning LLMs to model specific participants using this "action-aware" data produces a 67% reduction in perplexity and nearly doubles classifier-based performance metrics for speaker fidelity and realism. Turing-style human evaluations show our simulations are often indistinguishable from real deliberations, providing a practical and scalable method for complex realistic civic simulations.

</details>


### [35] [A superpersuasive autonomous policy debating system](https://arxiv.org/abs/2511.17854)
*Allen Roush,Devin Gonier,John Hines,Judah Goldfeder,Philippe Martin Wyder,Sanjay Basu,Ravid Shwartz Ziv*

Main category: cs.CL

TL;DR: DeepDebater是一款能够自主参与标准政策辩论并胜出的人机协作AI辩论系统，通过分层多代理架构与大语言模型驱动，结合证据检索及自我校正机制，实现了完整流程自动化。实验证明其论证能力已超越人类专家，全部资源已开源。


<details>
  <summary>Details</summary>
Motivation: 现有人工智能在复杂、高度证据化和策略自适应说服方面存在显著挑战。此前如IBM Project Debater等系统仅适用于简化的辩论场景，难以应对完整和真实的政策辩论。为推动AI说服与推理能力的实用应用，需要能够处理真实辩论规则、内容复杂且对抗性强的系统。

Method: 提出了DeepDebater系统，采用分层架构和多代理（multi-agent）协作，每个代理由大语言模型（LLM）驱动，分别承担论证任务。系统通过迭代检索、信息综合和自我校正，利用大型政策辩论证据库完成完整辩论流程，包括演讲、交叉质询和反驳，同时支持文本转语音并配以动画头像视频的端到端直播展示。支持全自动AI对战、人机混合参与及全人类参与多种辩论模式。

Result: DeepDebater在与人类撰写的辩题对抗中展现出优质的论证能力，持续在模拟辩论中胜出（有独立AI评审判定），其生成的论点和证据受到专家教练的高度评价。提供了完整的开源代码、演讲文本、音频及视频材料。

Conclusion: DeepDebater首次使AI能自主完成复杂的真实政策辩论，并能取得超越人类的表现，实现了AI在说服推理层面的重大突破，也为人机混合高阶认知协作树立了新范式。

Abstract: The capacity for highly complex, evidence-based, and strategically adaptive persuasion remains a formidable great challenge for artificial intelligence. Previous work, like IBM Project Debater, focused on generating persuasive speeches in simplified and shortened debate formats intended for relatively lay audiences. We introduce DeepDebater, a novel autonomous system capable of participating in and winning a full, unmodified, two-team competitive policy debate. Our system employs a hierarchical architecture of specialized multi-agent workflows, where teams of LLM-powered agents collaborate and critique one another to perform discrete argumentative tasks. Each workflow utilizes iterative retrieval, synthesis, and self-correction using a massive corpus of policy debate evidence (OpenDebateEvidence) and produces complete speech transcripts, cross-examinations, and rebuttals. We introduce a live, interactive end-to-end presentation pipeline that renders debates with AI speech and animation: transcripts are surface-realized and synthesized to audio with OpenAI TTS, and then displayed as talking-head portrait videos with EchoMimic V1. Beyond fully autonomous matches (AI vs AI), DeepDebater supports hybrid human-AI operation: human debaters can intervene at any stage, and humans can optionally serve as opponents against AI in any speech, allowing AI-human and AI-AI rounds. In preliminary evaluations against human-authored cases, DeepDebater produces qualitatively superior argumentative components and consistently wins simulated rounds as adjudicated by an independent autonomous judge. Expert human debate coaches also prefer the arguments, evidence, and cases constructed by DeepDebater. We open source all code, generated speech transcripts, audio and talking head video here: https://github.com/Hellisotherpeople/DeepDebater/tree/main

</details>


### [36] [Principled Context Engineering for RAG: Statistical Guarantees via Conformal Prediction](https://arxiv.org/abs/2511.17908)
*Debashish Chakraborty,Eugene Yang,Daniel Khashabi,Dawn Lawrie,Kevin Duh*

Main category: cs.CL

TL;DR: 提出了基于conformal prediction的证据过滤方法，稳定控制相关内容的覆盖率，减少冗余上下文并提升RAG生成的事实准确性证明其有效性。


<details>
  <summary>Details</summary>
Motivation: RAG模式虽然增强了大语言模型的事实基础，但在面对过长或噪声较多的上下文时准确率下降。现有过滤方法缺乏统计保障，无法有效控制保留证据的质量。

Method: 采用保覆盖率的conformal prediction过滤框架，在嵌入和LLM评分下筛选和控制检索结果的相关性，并在NeuCLIR与RAGTIME数据集上进行实证评估。

Result: 该方法能稳定达到设定的相关性覆盖率，仅保留目标比例的有效片段，相对于不过滤检索内容，可减少2-3倍上下文长度，并在NeuCLIR数据集上显著提升下游事实准确性。

Conclusion: conformal prediction为RAG提供了可靠、模型无关且原理支撑的上下文过滤方式，能有效控制相关性覆盖并优化生成模型的事实准确性。

Abstract: Retrieval-Augmented Generation (RAG) enhances factual grounding in large language models (LLMs) by incorporating retrieved evidence, but LLM accuracy declines when long or noisy contexts exceed the model's effective attention span. Existing pre-generation filters rely on heuristics or uncalibrated LLM confidence scores, offering no statistical control over retained evidence. We evaluate and demonstrate context engineering through conformal prediction, a coverage-controlled filtering framework that removes irrelevant content while preserving recall of supporting evidence. Using both embedding- and LLM-based scoring functions, we test this approach on the NeuCLIR and RAGTIME collections. Conformal filtering consistently meets its target coverage, ensuring that a specified fraction of relevant snippets are retained, and reduces retained context by 2-3x relative to unfiltered retrieval. On NeuCLIR, downstream factual accuracy measured by ARGUE F1 improves under strict filtering and remains stable at moderate coverage, indicating that most discarded material is redundant or irrelevant. These results demonstrate that conformal prediction enables reliable, coverage-controlled context reduction in RAG, offering a model-agnostic and principled approach to context engineering.

</details>


### [37] [L2V-CoT: Cross-Modal Transfer of Chain-of-Thought Reasoning via Latent Intervention](https://arxiv.org/abs/2511.17910)
*Yuliang Zhan,Xinyu Tang,Han Wan,Jian Li,Ji-Rong Wen,Hao Sun*

Main category: cs.CL

TL;DR: 本论文提出了一种无需训练、通过潜表征迁移的L2V-CoT方法，将LLMs的推理能力有效转移到VLMs，在多模态推理任务上优于现有无监督和部分监督基线。


<details>
  <summary>Details</summary>
Motivation: Vision-Language Models（VLMs）在多步推理任务上表现不佳，主要原因是缺乏多模态推理数据。已有方法尝试从LLMs向VLMs迁移Chain-of-Thought（CoT）推理能力，但需要高昂的训练成本或架构对齐。该工作旨在提出一种无需额外训练或架构变更的、高效的推理迁移方法。

Method: 利用Linear Artificial Tomography（LAT）展示LLMs和VLMs在CoT推理方面共享低频潜在表征，并在此基础上提出L2V-CoT方法：从LLMs中在频率域抽取并重采低频CoT表征，实现与VLMs维度上的匹配，然后在推理过程中将这些潜表征注入VLMs，无需额外训练，提升其推理能力。

Result: 大量实验证明，L2V-CoT方法在无需训练的基线方法与部分监督方法之上取得了更好的推理表现。

Conclusion: L2V-CoT能够以训练无关且高效的方式，将CoT推理能力从LLMs迁移至VLMs，显著提升VLMs的多步推理能力，具有重要应用与理论意义。

Abstract: Recently, Chain-of-Thought (CoT) reasoning has significantly enhanced the capabilities of large language models (LLMs), but Vision-Language Models (VLMs) still struggle with multi-step reasoning tasks due to limited multimodal reasoning data. To bridge this gap, researchers have explored methods to transfer CoT reasoning from LLMs to VLMs. However, existing approaches either need high training costs or require architectural alignment. In this paper, we use Linear Artificial Tomography (LAT) to empirically show that LLMs and VLMs share similar low-frequency latent representations of CoT reasoning despite architectural differences. Based on this insight, we propose L2V-CoT, a novel training-free latent intervention approach that transfers CoT reasoning from LLMs to VLMs. L2V-CoT extracts and resamples low-frequency CoT representations from LLMs in the frequency domain, enabling dimension matching and latent injection into VLMs during inference to enhance reasoning capabilities. Extensive experiments demonstrate that our approach consistently outperforms training-free baselines and even surpasses supervised methods.

</details>


### [38] [Towards Efficient LLM-aware Heterogeneous Graph Learning](https://arxiv.org/abs/2511.17923)
*Wenda Li,Tongya Zheng,Shunyu Liu,Yu Wang,Kaixuan Chen,Hanyang Yuan,Bingde Hu,Zujie Ren,Mingli Song,Gang Chen*

Main category: cs.CL

TL;DR: 本文提出高效的LLM异构图学习框架ELLA，通过结构改进和提示优化显著提升性能与效率，优于现有方法，适配大规模LLM场景。


<details>
  <summary>Details</summary>
Motivation: 异构图广泛存在于现实世界复杂网络中，节点与关系类型多样导致语义复杂。现有方法受限于预定义语义依赖和监督信号稀缺，主流利用自监督信号但存在语义鸿沟。大语言模型（LLM）能提升异构图中关系与任务的语义建模，但由于计算复杂性难以有效融合。

Method: 提出了一种高效的LLM感知的异构图学习框架ELLA。该框架主要包括三个核心机制：1）LLM-aware Relation Tokenizer，利用LLM对多跳、多类型关系进行编码，捕捉复杂语义；2）Hop-level Relation Graph Transformer，将LLM感知的关系推理计算复杂度由指数级降为线性级；3）基于任务的细粒度链式思维提示（CoT prompt），弥合预训练和微调任务间的语义鸿沟。

Result: 在四个异构图数据集上开展大量实验，显示ELLA在性能和效率上均超越最新方法，能扩展至13B参数规模的LLM，并实现最多4倍速度提升。代码已经开源。

Conclusion: ELLA框架高效整合了大语言模型进异构图学习，兼顾关系语义建模深度与计算效率，并有效解决了预训练和下游任务的语义对齐问题。

Abstract: Heterogeneous graphs are widely present in real-world complex networks, where the diversity of node and relation types leads to complex and rich semantics. Efforts for modeling complex relation semantics in heterogeneous graphs are restricted by the limitations of predefined semantic dependencies and the scarcity of supervised signals. The advanced pre-training and fine-tuning paradigm leverages graph structure to provide rich self-supervised signals, but introduces semantic gaps between tasks. Large Language Models (LLMs) offer significant potential to address the semantic issues of relations and tasks in heterogeneous graphs through their strong reasoning capabilities in textual modality, but their incorporation into heterogeneous graphs is largely limited by computational complexity. Therefore, in this paper, we propose an Efficient LLM-Aware (ELLA) framework for heterogeneous graphs, addressing the above issues. To capture complex relation semantics, we propose an LLM-aware Relation Tokenizer that leverages LLM to encode multi-hop, multi-type relations. To reduce computational complexity, we further employ a Hop-level Relation Graph Transformer, which help reduces the complexity of LLM-aware relation reasoning from exponential to linear. To bridge semantic gaps between pre-training and fine-tuning tasks, we introduce the fine-grained task-aware textual Chain-of-Thought (CoT) prompts. Extensive experiments on four heterogeneous graphs show that our proposed ELLA outperforms state-of-the-art methods in the performance and efficiency. In particular, ELLA scales up to 13b-parameter LLMs and achieves up to a 4x speedup compared with existing LLM-based methods. Our code is publicly available at https://github.com/l-wd/ELLA.

</details>


### [39] [SPINE: Token-Selective Test-Time Reinforcement Learning with Entropy-Band Regularization](https://arxiv.org/abs/2511.17938)
*Jianghao Wu,Yasmeen George,Jin Ye,Yicheng Wu,Daniel F. Schmidt,Jianfei Cai*

Main category: cs.CL

TL;DR: 提出SPINE，针对测试时适应LLM/MLLM推理表现，仅更新关键分叉令牌并控熵，显著提升性能且稳定，无需标签或奖励模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）和多模态LLM（MLLM）在链式思维（chain-of-thought）推理方面表现强劲，但它们在实际测试中面临分布转移和缺乏可验证监督的问题。现有的测试时强化学习（TTRL）方法虽然能通过自洽投票获得无标签伪奖励，但往往导致奖励结构坍缩和性能下降。因此亟需稳定、无标签且有效的测试时适应机制。

Method: 提出了SPINE——一种令牌选择性测试时强化学习框架。其核心分别为：只更新分叉令牌（通过前向传播统计识别的高熵节点），并在这些令牌上施加熵带正则化（当熵过低时促进探索，熵过高时抑制噪声监督）。SPINE可嵌入GRPO风格目标，无需标签或奖励模型。

Result: 在包含多模态问答、通用及专家问答、数学推理和医学问答的十个基准上，SPINE在LLM和MLLM后端均稳定提升了Pass@1表现，避免了响应长度坍缩，训练动态更加稳定。

Conclusion: 仅针对链式思维分叉点进行更新，是实现理性模型稳定、有效且无标签测试时适应的一种简洁方式。

Abstract: Large language models (LLMs) and multimodal LLMs (MLLMs) excel at chain-of-thought reasoning but face distribution shift at test-time and a lack of verifiable supervision. Recent test-time reinforcement learning (TTRL) methods derive label-free pseudo-rewards from self-consistency voting over sampled trajectories, yet they often collapse: the majority-vote reward prevails, responses shorten, and Pass@1 declines. We trace this to uniform sequence updates in which most tokens are low-entropy followers, while a small high-entropy subset determines the reasoning branches. Thus we propose SPINE, a token-selective test-time reinforcement learning framework that (i) updates only forking tokens, the high-entropy branch points identified from forward-pass statistics, and (ii) applies an entropy-band regularizer at those tokens to sustain exploration when entropy is too low and to suppress noisy supervision when it is too high. SPINE plugs into GRPO-style objectives, optionally with a KL anchor, and requires no labels or reward models. Across ten benchmarks spanning multimodal VQA, general and expert QA, mathematical reasoning, and medical QA, SPINE consistently improves Pass@1 over TTRL while avoiding response-length collapse and yielding more stable training dynamics on both LLM and MLLM backbones. These results indicate that aligning updates with chain-of-thought branch points is a simple and label-free mechanism for stable and effective test-time adaptation in reasoning models. Code is available at https://github.com/JianghaoWu/SPINE.

</details>


### [40] [Measuring the Impact of Lexical Training Data Coverage on Hallucination Detection in Large Language Models](https://arxiv.org/abs/2511.17946)
*Shuo Zhang,Fabrizio Gotti,Fengran Mo,Jian-Yun Nie*

Main category: cs.CL

TL;DR: 本文探讨了训练数据覆盖信息在检测大模型幻觉中的作用。研究发现，尽管单独使用相关特征检测效果一般，但与概率等信号结合后能提升检测性能，对提升开放问答幻觉识别具有补充价值。


<details>
  <summary>Details</summary>
Motivation: 大模型在开放域问答中的幻觉问题是一个重大挑战。虽然已有研究用模型内部特征（如生成一致性等）来检测幻觉，但预训练数据的覆盖与幻觉之间的关系还未被充分探讨，尤其是长尾知识上的表现较差。本文提出研究数据覆盖是否也能作为幻觉检测信号。

Method: 作者基于RedPajama的1.3万亿token预训练语料，构建了可扩展的后缀数组，检索prompt和生成回答的n-gram统计信息，并在三个问答基准集上，对基于数据出现特征进行幻觉检测能力的评估。

Result: 单独使用数据出现特征预测幻觉能力较弱，但和log-probability等信号结合时，尤其在模型不确定性较大的数据集上，有一定提升。

Conclusion: 词汇覆盖特征能为幻觉检测提供互补信号。相关代码与工具已开源。

Abstract: Hallucination in large language models (LLMs) is a fundamental challenge, particularly in open-domain question answering. Prior work attempts to detect hallucination with model-internal signals such as token-level entropy or generation consistency, while the connection between pretraining data exposure and hallucination is underexplored. Existing studies show that LLMs underperform on long-tail knowledge, i.e., the accuracy of the generated answer drops for the ground-truth entities that are rare in pretraining. However, examining whether data coverage itself can serve as a detection signal is overlooked. We propose a complementary question: Does lexical training-data coverage of the question and/or generated answer provide additional signal for hallucination detection? To investigate this, we construct scalable suffix arrays over RedPajama's 1.3-trillion-token pretraining corpus to retrieve $n$-gram statistics for both prompts and model generations. We evaluate their effectiveness for hallucination detection across three QA benchmarks. Our observations show that while occurrence-based features are weak predictors when used alone, they yield modest gains when combined with log-probabilities, particularly on datasets with higher intrinsic model uncertainty. These findings suggest that lexical coverage features provide a complementary signal for hallucination detection. All code and suffix-array infrastructure are provided at https://github.com/WWWonderer/ostd.

</details>


### [41] [MTikGuard System: A Transformer-Based Multimodal System for Child-Safe Content Moderation on TikTok](https://arxiv.org/abs/2511.17955)
*Dat Thanh Nguyen,Nguyen Hung Lam,Anh Hoang-Thi Nguyen,Trong-Hop Do*

Main category: cs.CL

TL;DR: 本文提出了一种集视觉、音频、文本多模态于一体的有害内容检测系统MTikGuard，在TikTok实际数据集上表现优异，并实现了可用于现实应用的大规模实时处理能力。


<details>
  <summary>Details</summary>
Motivation: 短视频平台（如TikTok）在青少年中的流行带来了有害内容传播的新挑战，传统内容审核方法难以应对实时和大规模的视频上传。

Method: 提出MTikGuard系统，该系统利用扩展的TikHarm数据集，集成视觉、音频与文本多模态特征，实现高性能分类，并通过Apache Kafka与Spark构建可扩展的实时处理架构。

Result: MTikGuard系统在数据集上取得了89.37%准确率与89.45% F1分数，证明了多模态融合和系统架构的有效性。

Conclusion: 通过扩展数据集和多模态检测方法可以有效提升短视频有害内容检测的准确性，并实现可扩展的实际部署，有望用于大规模社交媒体内容治理。

Abstract: With the rapid rise of short-form videos, TikTok has become one of the most influential platforms among children and teenagers, but also a source of harmful content that can affect their perception and behavior. Such content, often subtle or deceptive, challenges traditional moderation methods due to the massive volume and real-time nature of uploads. This paper presents MTikGuard, a real-time multimodal harmful content detection system for TikTok, with three key contributions: (1) an extended TikHarm dataset expanded to 4,723 labeled videos by adding diverse real-world samples, (2) a multimodal classification framework integrating visual, audio, and textual features to achieve state-of-the-art performance with 89.37% accuracy and 89.45% F1-score, and (3) a scalable streaming architecture built on Apache Kafka and Apache Spark for real-time deployment. The results demonstrate the effectiveness of combining dataset expansion, advanced multimodal fusion, and robust deployment for practical large-scale social media content moderation. The dataset is available at https://github.com/ntdat-8324/MTikGuard-System.git.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [42] [Graph burning: an overview of mathematical programs](https://arxiv.org/abs/2511.18292)
*Lourdes Beatriz Cajica-Maceda,Freddy Alejandro Chaurra-Gutiérrez,Julio César Pérez-Sansalvador,Jesús García-Díaz*

Main category: cs.DM

TL;DR: 本文围绕图烧问题，提出多种高效数学优化模型，模型更简洁易算，实验结果显示可快速求解超大规模实例，理论与应用价值兼具，尤其对量子优化领域有积极意义。


<details>
  <summary>Details</summary>
Motivation: 图烧问题（GBP）作为评估图对传播易感性的工具，理论意义重大，且问题复杂性高（决策版NP-完全，优化版NP-困难）。不过，相关数学优化模型仍有进一步简化和高效求解的需求。

Method: 本文提出了多种数学优化模型用于经典GBP的优化求解，包括：混合整数线性规划（MILP）、约束满足问题（CSP）、两个整数线性规划（ILP）和两个二次无约束二元优化（QUBO）模型。这些模型采用了更精简的变量设计，便于应用主流优化算法和求解器。

Result: 新提出的数学优化模型相比以往模型更为简洁，变量更少，因而在实际应用中效率更高。通过实际实验，作者展示了在分钟级时间内求解百万级顶点的大型实例。

Conclusion: 通过设计新型数学优化模型，本文显著提升了图烧问题的可行性和实际求解效率，对于量子计算及优化算法发展也具重要推动作用。

Abstract: The Graph Burning Problem (GBP) is a combinatorial optimization problem that has gained relevance as a tool for quantifying a graph's vulnerability to contagion. Although it is based on a very simple propagation model, its decision version is NP-complete, and its optimization version is NP-hard. Many of its theoretical properties across different graph families have been thoroughly explored, and numerous interesting variants have been proposed. This paper reports novel mathematical programs for the optimization version of the classical GBP. Among the presented programs are a Mixed-Integer Linear Program (MILP), a Constraint Satisfaction Problem (CSP), two Integer Linear Programs (ILP), and two Quadratic Unconstrained Binary Optimization (QUBO) problems. Most optimization solvers can handle these, being QUBO problems of a capital interest in quantum computing. The primary aim of this paper is to gain a comprehensive understanding of the GBP by examining its different formulations. Compared to other mathematical programs from the literature, the ones presented here are conceptually simpler and involve fewer variables. These make them more practical for finding optimal solutions using optimization algorithms and solvers, as we show by solving some instances with millions of vertices in just a few minutes.

</details>


### [43] [Using random spanning trees in survivable networks design](https://arxiv.org/abs/2511.19018)
*Blazej Wrobel,Dominik Bojko*

Main category: cs.DM

TL;DR: 本文提出在完全图上连接若干随机生成树构造k-边连通图的方法，分析了生成图边数的期望及集中性，并基于此设计了近似最优且高效的算法解决生存网络设计问题。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过连接多个随机生成的生成树来构造高连通性图，尤其针对任意大k的k-边连通图生成，以解决特定生存网络设计问题。该问题在网络可靠性和设计中有实际应用价值。

Method: 在完全图K_n上，联合k棵随机生成树，允许树间有重叠边，但最终图是简单图（无重边）。分析随机变量$S_k$（生成图中边的数目），推导其期望公式，并给出集中系数的上界。基于理论分析，设计了一种生成k-边连通图的算法，并评估算法性能。

Result: 得到了$S_k$的严格期望公式，给出了集中系数的上界。设计的算法能生成任意大k-边连通图，并在每对节点要求k连通性情况下，算法计算生成的边数严格低于2倍最优值，且运行时间为$O(kn\,log\,n)$。

Conclusion: 通过随机树法，可高效构造k-边连通图，并求解生存网络设计问题的一个特例，兼顾算法的近似质量和运行效率，为大规模网络可靠性设计提供新思路。

Abstract: We investigate a process of joining $k$ random spanning trees on a fixed clique $K_n$. The joined trees may not be disjoint and multiple edges are replaced by one simple edge. This process produces a simple graph $G$ on $n$~vertices with an edge set, which is a union of edge sets of the joined trees. We study a random variable $S_{k}$ of the number of edges in the generated graph $G$. The exact formula is derived for the expected value of the random variable $S_{k}$. In addition, an upper bound on the concentration coefficient of the random variable $S_{k}$ is provided. We use results of our analysis to design an algorithm to generate $k$-edge connected graphs for arbitrarily large values of $k \geq 2$. The designed algorithm solves a particular case of the Survivable Network Design Problem, where the cost of each edge is $c_{e} = 1$ and the connectivity requirement for each pair of vertices $u, v \in V(G)$ is $k$.The proposed algorithm is within a factor strictly less than $2$ of the optimal value (i.e., the number of edges in the generated graph) and its running time is $O(kn\log{n})$.

</details>
