<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.SE](#cs.SE) [Total: 9]
- [cs.LO](#cs.LO) [Total: 5]
- [cs.CL](#cs.CL) [Total: 6]
- [cs.DM](#cs.DM) [Total: 2]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Hey Pentti, We Did It!: A Fully Vector-Symbolic Lisp](https://arxiv.org/abs/2510.17889)
*Eilene Tomkins-Flanagan,Mary A. Kelly*

Main category: cs.PL

TL;DR: 本论文实证了使用向量符号架构（HRR与清理记忆）可以构建图灵完备的Lisp，实现了其基本函数的表达，分析了数学与分类意义，强调了清理记忆的必要性。


<details>
  <summary>Details</summary>
Motivation: Kanerva（2014）提出可以用向量符号架构实现完整的Lisp，但此前缺乏具体实现方法。作者希望展示这种架构如何表达Lisp的基本元素并实现图灵完备性。

Method: 作者以Lisp 1.5为规范，利用全息简约表示（HRR）和查找表式清理记忆实现Lisp的五个基本函数、lambda表达式及辅助函数的向量符号表示。分析数学结构，并强调清理记忆在架构中的作用。

Result: 作者实现了Lisp基本元素的向量符号表示，并证明该架构具备笛卡尔封闭性质，即与图灵完备性等价。明确提出需将清理记忆纳入架构规范中。

Conclusion: 向量符号架构可实现完整的函数式语言Lisp，包括使架构达到笛卡尔封闭和图灵完备性，且清理记忆在架构实现中至关重要。

Abstract: Kanerva (2014) suggested that it would be possible to construct a complete
Lisp out of a vector-symbolic architecture. We present the general form of a
vector-symbolic representation of the five Lisp elementary functions, lambda
expressions, and other auxiliary functions, found in the Lisp 1.5 specification
McCarthy (1960), which is near minimal and sufficient for Turing-completeness.
Our specific implementation uses holographic reduced representations Plate
(1995), with a lookup table cleanup memory. Lisp, as all Turing-complete
languages, is a Cartesian closed category, unusual in its proximity to the
mathematical abstraction. We discuss the mathematics, the purpose, and the
significance of demonstrating vector-symbolic architectures' Cartesian-closure,
as well as the importance of explicitly including cleanup memories in the
specification of the architecture.

</details>


### [2] [ZipLex: Verified Invertible Lexing with Memoized Derivatives and Zippers](https://arxiv.org/abs/2510.18479)
*Samuel Chassot,Viktor Kunčak*

Main category: cs.PL

TL;DR: ZipLex是一个经验证的可逆词法分析框架，首次实现词法分析和打印的互为逆操作，并保证了可用性和良好性能，对安全和语言处理领域具有实际意义。


<details>
  <summary>Details</summary>
Motivation: 当前已有的经验证词法分析器仅关注正则表达式语义和最大匹配属性，但没有保证词法分析（lexing）和打印（printing）的可逆性。缺乏可逆性的分析器限制了在需要精确还原输入的应用（如程序变换、代码生成等）中的作用。作者希望解决这个问题。

Method: 提出了ZipLex框架，用于可逆词法分析的形式化验证。设计主要包括两个方面：(1) 提出新的token序列抽象方法，实现token分离性且高效处理；(2) 结合已验证的数据结构和优化技术，如Huet的zippers和memoized derivatives，提升性能。框架基于Scala实现，并借助Stainless verifier进行正确性和可逆性验证。

Result: ZipLex框架能够支持诸如JSON处理及编程语言tokenizer等实际应用。性能方面，虽然比Coqlex慢4倍，但比Verbatim++快两个数量级，验证的可逆性并未带来高昂的性能代价。

Conclusion: 作者展示了ZipLex在保证可逆性的同时能够提供实用的性能。结果表明经过验证的可逆词法分析器完全可用于实际应用，不会损失太多效率，推进了安全可靠语言处理工具的发展。

Abstract: We present ZipLex, a verified framework for invertible lexical analysis.
Unlike past verified lexers that focus only on satisfying the semantics of
regular expressions and the maximal munch property, ZipLex also guarantees that
lexing and printing are mutual inverses. Our design relies on two sets of
ideas: (1) a new abstraction of token sequences that captures the separability
of tokens in a sequence while supporting their efficient manipulation, and (2)
a combination of verified data structures and optimizations, including Huet's
zippers and memoized derivatives, to achieve practical performance. We
implemented ZipLex in Scala and verified its correctness, including
invertibility, using the Stainless verifier. Our evaluation demonstrates that
ZipLex supports realistic applications such as JSON processing and lexers of
programming languages. In comparison to other verified lexers (which do not
enforce invertibility), ZipLex is 4x slower than Coqlex and two orders of
magnitude faster than Verbatim++, showing that verified invertibility can be
achieved without prohibitive cost.

</details>


### [3] [CPSLint: A Domain-Specific Language Providing Data Validation and Sanitisation for Industrial Cyber-Physical Systems](https://arxiv.org/abs/2510.18651)
*Uraz Odyurt,Ömer Sayilir,Mariëlle Stoelinga,Vadim Zaytsev*

Main category: cs.PL

TL;DR: 针对工业CPS原始时序数据复杂且庞大的问题，论文提出CPSLint DSL，实现高效的数据预处理和结构推断，为故障检测等数据应用打下基础，并通过原型验证其功能。


<details>
  <summary>Details</summary>
Motivation: 工业CPS系统原始数据体积大且结构复杂，直接分析困难，需开发有效的数据准备工具，特别是为机器学习与故障检测等流程服务。

Method: 提出并实现了一个领域特定语言（DSL）CPSLint，通过类型检查、约束验证与修复、缺失值填补，以及推断CPS相关数据结构（列和行级），对原始数据进行预处理。

Result: CPSLint能够自动化进行类型检查、约束验证、数据补全和推断数据结构，并通过原型展示其有效性，能显著提升CPS数据准备效率和质量。

Conclusion: CPSLint有效地为工业CPS领域的数据准备任务提供DSL语言支持，能够处理和改善原始时序数据以适应机器学习等下游任务。

Abstract: Raw datasets are often too large and unstructured to work with directly, and
require a data preparation process. The domain of industrial Cyber-Physical
Systems (CPS) is no exception, as raw data typically consists of large amounts
of time-series data logging the system's status in regular time intervals. Such
data has to be sanity checked and preprocessed to be consumable by data-centric
workflows. We introduce CPSLint, a Domain-Specific Language designed to provide
data preparation for industrial CPS. We build up on the fact that many raw data
collections in the CPS domain require similar actions to render them suitable
for Machine-Learning (ML) solutions, e.g., Fault Detection and Identification
(FDI) workflows, yet still vary enough to hope for one universally applicable
solution.
  CPSLint's main features include type checking and enforcing constraints
through validation and remediation for data columns, such as imputing missing
data from surrounding rows. More advanced features cover inference of extra
CPS-specific data structures, both column-wise and row-wise. For instance, as
row-wise structures, descriptive execution phases are an effective method of
data compartmentalisation are extracted and prepared for ML-assisted FDI
workflows. We demonstrate CPSLint's features through a proof of concept
implementation.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [AI Exchange Platforms](https://arxiv.org/abs/2510.17839)
*Johannes Schneider,Rene Abraham*

Main category: cs.SE

TL;DR: 本文针对AI模型交换平台提出了系统性分类法，厘清了平台的关键机制与互动模式，为学术界和产业界提供了理解与研究AI模型交换的参考框架，并指明了未来发展的方向。


<details>
  <summary>Details</summary>
Motivation: 人工智能基础模型的普及推动企业对AI交换平台需求上升，但目前对这些平台缺乏系统的分类与理论框架，故亟需对其进行深入研究和归纳。

Method: 通过构建系统性的分类框架（taxonomy），分析和归纳AI模型交换平台的关键特征、运作机制及各类平台之间的交互模式。

Result: 提出了针对AI交换平台的分类法，揭示了平台间的互动模式（如同行评审、在线测试与部署）、并为研究者与实践者提供了理解挑战与机遇的工具，同时也展示了平台在产业中的演进方向和创新。

Conclusion: 本文提出了一个分类法，为AI模型交换平台的理解和研究奠定基础，有助于学术界和产业界对未来发展趋势和最佳实践的进一步研究。

Abstract: The rapid integration of Artificial Intelligence (AI) into organizational
technology frameworks has transformed how organizations engage with AI-driven
models, influencing both operational performance and strategic innovation. With
the advent of foundation models, the importance of structured platforms for AI
model exchange has become paramount for organizational efficacy and
adaptability. However, a comprehensive framework to categorize and understand
these platforms remains underexplored. To address this gap, our taxonomy
provides a structured approach to categorize AI exchange platforms, examining
key dimensions and characteristics, as well as revealing interesting
interaction patterns between public research institutions and organizations:
Some platforms leverage peer review as a mechanism for quality control, and
provide mechanisms for online testing, deploying, and customization of models.
Our paper is beneficial to practitioners seeking to understand challenges and
opportunities that arise from AI exchange platforms. For academics, the
taxonomy serves as a foundation for further research into the evolution,
impact, and best practices associated with AI model sharing and utilization in
different contexts. Additionally, our study provides insights into the evolving
role of AI in various industries, highlighting the importance of adaptability
and innovation in platform design. This paper serves as a critical resource for
understanding the dynamic interplay between technology, business models, and
user engagement in the rapidly growing domain of AI model exchanges pointing
also towards possible future evolution.

</details>


### [5] [Vibe Coding: Toward an AI-Native Paradigm for Semantic and Intent-Driven Programming](https://arxiv.org/abs/2510.17842)
*Vinay Bamil*

Main category: cs.SE

TL;DR: 论文提出了一种利用AI实现的“vibe coding”编程范式，能根据开发者的意图和风格生成代码，提升生产力，但存在众多技术和伦理挑战，需进一步研究。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，越来越多的开发者希望通过与AI系统对话取代传统编码方式，提升软件开发的效率与体验，因此提出了能够表达功能意图加上风格等定性特征的vibe coding。

Method: 论文通过提出参考架构（包括意图解析器、语义嵌入引擎、智能代理代码生成器和交互反馈循环），并通过假设性实现及对比其他编程范式来进行分析。

Result: vibe coding可为软件开发带来生产力提升和普及效应，但也会引入对齐性、可复现性、偏见、可解释性、可维护性、安全性等诸多问题。该领域仍有诸多研究挑战和未来发展方向。

Conclusion: 该论文提出了“vibe coding”这一AI原生的编程范式，为软件开发带来新的变革，但也面临诸多挑战，未来需要进一步研究和完善。

Abstract: Recent advances in large language models have enabled developers to generate
software by conversing with artificial intelligence systems rather than writing
code directly. This paper introduces vibe coding, an emerging AI-native
programming paradigm in which a developer specifies high-level functional
intent along with qualitative descriptors of the desired "vibe" (tone, style,
or emotional resonance). An intelligent agent then transforms those
specifications into executable software. We formalize the definition of vibe
coding and propose a reference architecture that includes an intent parser, a
semantic embedding engine, an agentic code generator, and an interactive
feedback loop. A hypothetical implementation is described. We compare vibe
coding with declarative, functional, and prompt-based programming, and we
discuss its implications for software engineering, human-AI collaboration, and
responsible AI practice. Finally, we examine reported productivity gains and
democratizing effects, review recent studies that highlight vulnerabilities and
potential slowdowns, identify key challenges such as alignment,
reproducibility, bias, explainability, maintainability, and security, and
outline future directions and open research questions.

</details>


### [6] [Smart Contracts Formal Verification: A Systematic Literature Review](https://arxiv.org/abs/2510.17865)
*Rene Davila,Everardo Barcenas,Rocio Aldeco-Perez*

Main category: cs.SE

TL;DR: 本文针对智能合约验证现状开展调研，系统评述主流规范和工具，并创新性地提出基于描述逻辑的新方法以提升智能合约的形式化验证效果。


<details>
  <summary>Details</summary>
Motivation: 智能合约作为区块链协议的核心，常因操作或规范缺陷暴露出错误，需要更严谨的形式化验证手段以提高安全性和可靠性。

Method: 调研现有智能合约的正式验证研究及工具，分析其规范和实验，随后提出基于描述逻辑的方法。

Result: 综述归纳现有工作并指出其不足，引入描述逻辑以实现对智能合约更有效的形式化描述和更有力的验证支持。

Conclusion: 本文综述了关于智能合约形式化验证的相关文献，涵盖规范、验证工具和实验，并提出了一种基于描述逻辑的替代形式化验证方法。

Abstract: Formal verification entails testing software to ensure it operates as
specified. Smart contracts are self-executing contracts with the terms of the
agreement directly written into lines of code. They run on blockchain platforms
and automatically enforce and execute the terms of an agreement when meeting
predefined conditions. However, Smart Contracts, as software models, often
contain notable errors in their operation or specifications. This observation
prompts us to conduct a focused study examining related works published across
various sources. These publications detail specifications, verification tools,
and relevant experiments. Subsequently, this survey proposes an alternative
formal verification based on description logic.

</details>


### [7] [UniCode: A Framework for Generating High Quality Competitive Coding Problems](https://arxiv.org/abs/2510.17868)
*Xinyue Zheng,Haowei Lin,Shaofei Cai,Zilong Zheng,Yitao Liang*

Main category: cs.SE

TL;DR: UniCode 框架创新性地实现了高质量算法题和测试用例的自动生成，提升了评测自动化和挑战性，解决了人工出题的局限。


<details>
  <summary>Details</summary>
Motivation: 现有算法竞赛题库依赖人工编写，导致数据污染和扩展性差，难以满足高质量数据需求。

Method: 采用大语言模型（LLM）结合三种题目多样化策略（单题扩展、同类型融合、跨类型融合），并创新性地引入基于压力测试驱动的测试用例合成流程，结合暴力法验证和共识机制进行用例校验。

Result: 构建了含492道题目的新基准并对19个先进LLM评测，最优模型通过率仅70.3%，验证了新框架的区分性和挑战性。

Conclusion: UniCode 框架能自动生成高质量算法题目和鲁棒的测试用例，有效提升了算法题生成和评测的可扩展性与可靠性。

Abstract: The reliance of competitive coding benchmarks on static, human-authored
problems creates significant challenges, including data contamination and
limited scalability. To address these issues, we introduce UniCode, a novel
framework that automatically generates high-quality algorithmic problems
alongside robust, contamination-resistant test cases. Inspired by biological
evolution that creates better and diverse offspring, our framework leverages
Large Language Models (LLMs) to systematically diversify problems through three
strategies: single problem extension, same-type fusion, and cross-type fusion.
A key innovation is our stress-driven test case synthesis pipeline, which
generates reliable test suites without requiring a canonical ground-truth
solution. This pipeline combines brute-force grounding for small-scale inputs
with a consensus-based validation mechanism for large-scale inputs to ensure
high correctness and coverage. We demonstrate effectiveness of our framework by
curating a benchmark of 492 problems and evaluating 19 state-of-the-art LLMs.
The results reveal that UniCode is highly challenging and discriminative, with
the top-performing model, o4-mini, achieving a pass rate of only 70.3%. Our
framework provides a scalable and reliable solution for generating dynamic
evaluation datasets in coding domain.

</details>


### [8] [Repairing Tool Calls Using Post-tool Execution Reflection and RAG](https://arxiv.org/abs/2510.17874)
*Jason Tsay,Zidane Wright,Gaodan Fang,Kiran Kate,Saurabh Jha,Yara Rizk*

Main category: cs.SE

TL;DR: 提出将大语言模型反思与领域文档检索增强生成结合，用于智能体系统工具调用后错误自动修复，实验证明能大幅提升kubectl命令的执行成功率和问题答正确率，故障排查文档效果更佳。


<details>
  <summary>Details</summary>
Motivation: 许多智能体系统调用外部工具时存在各种语法与语义错误，部分语义错误仅能通过分析工具回复后修正。为提升智能体工具调用的鲁棒性和自动化修复能力，提出结合LLM反思与领域文档的方法。

Method: 搭建了一个结合大语言模型（LLM）反思与面向领域的检索增强生成（RAG），同时集成针对工具的官方文档与故障排查文档的反思修复模块。通过大规模实验与人工评估，测量修复后的工具调用表现。

Result: RAG反思机制能修复kubectl命令，使工具执行成功率提升，55%的模型反映出通过率提升，平均正确性提升36%。故障排查文档比官方文档进一步提升通过率，平均增幅达10%。

Conclusion: 将RAG（检索增强生成）与LLM反思相结合的后工具执行反思组件在修复kubectl命令和提升系统成功执行率与正确性方面有效，尤其是利用故障排查文档有额外提升。

Abstract: Agentic systems interact with external systems by calling tools such as
Python functions, REST API endpoints, or command line tools such as kubectl in
Kubernetes. These tool calls often fail for various syntactic and semantic
reasons. Some less obvious semantic errors can only be identified and resolved
after analyzing the tool's response. To repair these errors, we develop a
post-tool execution reflection component that combines large language model
(LLM)-based reflection with domain-specific retrieval-augmented generation
(RAG) using documents describing both the specific tool being called and
troubleshooting documents related to the tool. For this paper, we focus on the
use case of the kubectl command line tool to manage Kubernetes, a platform for
orchestrating cluster applications. Through a larger empirical study and a
smaller manual evaluation, we find that our RAG-based reflection will repair
kubectl commands such that they are both more likely to successfully execute
(pass rate) for 55% of our models evaluated and 36% more likely to correctly
answer the user query on average. We find that troubleshooting documents
improve pass rate compared to official documentation by an average of 10%.

</details>


### [9] [TritonRL: Training LLMs to Think and Code Triton Without Cheating](https://arxiv.org/abs/2510.17891)
*Jiin Woo,Shaowei Zhu,Allen Nie,Zhen Jia,Yida Wang,Youngsuk Park*

Main category: cs.SE

TL;DR: 本文提出TritonRL，通过有监督微调与细粒度强化学习结合，攻克了Triton kernel自动生成中的数据稀缺与评估困难问题，实验显示其性能优于现有模型，具有显著应用前景。


<details>
  <summary>Details</summary>
Motivation: 快速发展的LLM对自动化、高性能系统kernel的需求增加。Triton kernel生成面临数据稀缺和评价标准不全等难题，现有方法难以完全解决。

Method: 提出TritonRL，一种专为Triton kernel生成设计的LLM，采用新颖的训练框架。方法包含：1）在精选数据集上进行有监督微调，凝练Triton专有知识；2）通过强化学习（RL）进一步提升代码质量，利用具有可验证性和分层奖励的机制，抑制reward hacking现象。RL框架还引入细粒度验证和分层奖励分解，全面引导推理和代码生成。

Result: TritonRL在KernelBench上实现了业界领先的正确率和加速效果，超越了所有其它Triton专用模型，验证了该RL训练范式的有效性。

Conclusion: TritonRL通过创新的RL训练方案大幅提升Triton kernel生成质量和实用性，有望替代现有手动模块，是自动化kernel生成的重要进展。

Abstract: With the rapid evolution of large language models (LLMs), the demand for
automated, high-performance system kernels has emerged as a key enabler for
accelerating development and deployment. We introduce TritonRL, a
domain-specialized LLM for Triton kernel generation, trained with a novel
training framework that enables robust and automated kernel synthesis. Unlike
general-purpose programming languages, Triton kernel generation faces unique
challenges due to data scarcity and incomplete evaluation criteria, vulnerable
to reward hacking. Our approach addresses these challenges end-to-end by
distilling Triton-specific knowledge through supervised fine-tuning on curated
datasets, and further improving code quality via reinforcement learning (RL)
with robust, verifiable rewards and hierarchical reward assignment. Our RL
framework robustly detects reward hacking and guides both reasoning traces and
code tokens through fine-grained verification and hierarchical reward
decomposition, enabling the model to generate high-quality Triton kernels that
can truly replace existing modules. With robust and fine-grained evaluation,
our experiments on KernelBench demonstrate that TritonRL achieves
state-of-the-art correctness and speedup, surpassing all other Triton-specific
models and underscoring the effectiveness of our RL-based training paradigm.

</details>


### [10] [A Systematic Literature Review of the Use of GenAI Assistants for Code Comprehension: Implications for Computing Education Research and Practice](https://arxiv.org/abs/2510.17894)
*Yunhan Qiao,Md Istiak Hossain Shihab,Christopher Hundhausen*

Main category: cs.SE

TL;DR: 系统回顾GenAI用于代码理解的最新方法与工具，发现其在代码解释和教育上的潜力与不足，并指明改进和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着程序员越来越依赖生成式人工智能（GenAI）助手来开发代码，理解这些GenAI所生成的代码变得愈加重要。这直接影响代码的正确性验证和与现有代码的集成。同时，GenAI逐渐被用于为程序员提供定制化的代码解释，带来了在计算机教育领域关于程序理解的新机遇与挑战。

Method: 作者采用系统性文献综述方法（SLR），回顾了2022年至2024年间发表的31项相关研究，对当前利用GenAI提升代码理解的技术和工具进行了系统梳理和分类，着重总结了实证评估结果。

Result: 当前GenAI助手在代码解释方面尚存在诸如不准确或不清晰等问题，新手程序员难以设计有效的提示语，导致GenAI助力代码理解受限。文献综述系统归类了相关工具和方法，总结了这些工具的实际效果，并探讨了其在教育领域的应用和局限。

Conclusion: GenAI在提升代码理解能力方面展现出一定潜力，但实际应用中仍有诸多挑战（如解释准确性和用户操作性）。未来需深入探讨如何改进GenAI工具以更好支持编程教育和代码理解。

Abstract: The ability to comprehend code has long been recognized as an essential skill
in software engineering. As programmers lean more heavily on generative
artificial intelligence (GenAI) assistants to develop code solutions, it is
becoming increasingly important for programmers to comprehend GenAI solutions
so that they can verify their appropriateness and properly integrate them into
existing code. At the same time, GenAI tools are increasingly being enlisted to
provide programmers with tailored explanations of code written both by GenAI
and humans. Thus, in computing education, GenAI presents new challenges and
opportunities for learners who are trying to comprehend computer programs. To
provide computing educators with evidence-based guidance on the use of GenAI to
facilitate code comprehension and to identify directions for future research,
we present a systematic literature review (SLR) of state-of-the-art approaches
and tools that leverage GenAI to enhance code comprehension. Our SLR focuses on
31 studies published between 2022 and 2024. Despite their potential, GenAI
assistants often yield inaccurate or unclear explanations, and novice
programmers frequently struggle to craft effective prompts, thereby impeding
their ability to leverage GenAI to aid code comprehension. Our review
classifies GenAI-based approaches and tools, identifies methods used to study
them, and summarizes the empirical evaluations of their effectiveness. We
consider the implications of our findings for computing education research and
practice, and identify directions for future research.

</details>


### [11] [SpecAgent: A Speculative Retrieval and Forecasting Agent for Code Completion](https://arxiv.org/abs/2510.17925)
*George Ma,Anurag Koul,Qi Chen,Yawen Wu,Sachit Kuhar,Yu Yu,Aritra Sengupta,Varun Kumar,Murali Krishna Ramanathan*

Main category: cs.SE

TL;DR: 本文提出SpecAgent，通过索引时主动构建推测性上下文，显著提升LLM代码任务质量和效率，并构建无未来泄露的新基线，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统检索增强方法在处理项目特定API和跨文件依赖时受制于推理延迟与检索质量的权衡，影响用户体验；同时，现有评测存在未来上下文泄露的问题，导致性能评估夸大。

Method: 提出SpecAgent代理方法，在索引阶段主动探索仓库文件并构建推测性上下文，同时开发了合成、无未来信息泄露的评测基准。

Result: SpecAgent在新基准上绝对提升9-11%，相对提升48-58%，且推理延迟显著降低。

Conclusion: SpecAgent能够在减少推理延迟的同时，大幅提升代码生成的质量，解决了现有方法在现实软件仓库中的性能局限。

Abstract: Large Language Models (LLMs) excel at code-related tasks but often struggle
in realistic software repositories, where project-specific APIs and cross-file
dependencies are crucial. Retrieval-augmented methods mitigate this by
injecting repository context at inference time. The low inference-time latency
budget affects either retrieval quality or the added latency adversely impacts
user experience. We address this limitation with SpecAgent, an agent that
improves both latency and code-generation quality by proactively exploring
repository files during indexing and constructing speculative context that
anticipates future edits in each file. This indexing-time asynchrony allows
thorough context computation, masking latency, and the speculative nature of
the context improves code-generation quality. Additionally, we identify the
problem of future context leakage in existing benchmarks, which can inflate
reported performance. To address this, we construct a synthetic, leakage-free
benchmark that enables a more realistic evaluation of our agent against
baselines. Experiments show that SpecAgent consistently achieves absolute gains
of 9-11% (48-58% relative) compared to the best-performing baselines, while
significantly reducing inference latency.

</details>


### [12] [From Charts to Code: A Hierarchical Benchmark for Multimodal Models](https://arxiv.org/abs/2510.17932)
*Jiahao Tang,Henry Hengyuan Zhao,Lijian Wu,Yifei Tao,Dongxing Mao,Yang Wan,Jingru Tan,Min Zeng,Min Li,Alex Jinpeng Wang*

Main category: cs.SE

TL;DR: 作者提出了Chart2Code，大规模且分三级的图表理解到代码生成基准，涵盖2,023任务，22类图表，对25个主流大模型测试后发现任务难度极高，即使最强模型表现也有限，有助于推动更强大多模态模型的研究。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在图表理解及代码生成方面能力发展迅速，但缺乏专为图表到代码（chart2code）任务而设计、反映真实用户需求且覆盖任务难度梯度的评测基准。因此，提出一个能真实模拟用户场景并分级考察大模型能力的新基准有重要意义。

Method: 作者提出Chart2Code，一个分三级的评测基准：一级为图表复现任务，需要根据参考图和查询复原图表；二级为图表编辑任务，包括更换图表类型或添加元素等复杂操作；三级为从信息密集型长表格生成图表任务，要求更深层次的信息理解与转换。基准包含2,023个任务、22种图表类型及多层次的评测指标，并对25个主流大模型进行了基准测试。

Result: 实验结果显示，即使是最先进的GPT-5模型在图表编辑任务的代码评测上只获得平均0.57分，在图表质量评测上仅为0.22，反映出任务的高难度和当前模型的局限。

Conclusion: Chart2Code提供了首个面向实际chart2code应用且系统反映任务复杂度的分级基准，有助于推动多模态推理领域研究和更强通用能力大模型的发展。

Abstract: We introduce Chart2Code, a new benchmark for evaluating the chart
understanding and code generation capabilities of large multimodal models
(LMMs). Chart2Code is explicitly designed from a user-driven perspective,
capturing diverse real-world scenarios and progressively increasing task
difficulty. It consists of three levels: Level 1 (Chart Reproduction)
reproduces charts from a reference figure and user query; Level 2 (Chart
Editing) involves complex modifications such as changing chart types or adding
elements; and Level 3 (Long-Table to Chart Generation) requires models to
transform long, information-dense tables into faithful charts following user
instructions. To our knowledge, this is the first hierarchical benchmark that
reflects practical chart2code usage while systematically scaling task
complexity. In total, Chart2Code contains 2,023 tasks across 22 chart types,
paired with multi-level evaluation metrics that assess both code correctness
and the visual fidelity of rendered charts. We benchmark 25 state-of-the-art
(SoTA) LMMs, including both proprietary and the latest open-source models such
as GPT-5, Qwen2.5-VL, InternVL3/3.5, MiMo-VL, and Seed-1.6-VL. Experimental
results demonstrate that even the SoTA model GPT-5 averages only 0.57 on
code-based evaluation and 0.22 on chart-quality assessment across the editing
tasks, underscoring the difficulty of Chart2Code. We anticipate this benchmark
will drive advances in multimodal reasoning and foster the development of more
robust and general-purpose LMMs. Our code and data are available on Chart2Code.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [13] [Intuitionistic $j$-Do-Calculus in Topos Causal Models](https://arxiv.org/abs/2510.17944)
*Sridhar Mahadevan*

Main category: cs.LO

TL;DR: 本文将do-calculus拓展到sheaf Topos和直觉主义逻辑环境下，提出j-do-calculus因果推断规则，并证明其在新语义下的可靠性，为复杂结构和局部化推断提供理论工具。


<details>
  <summary>Details</summary>
Motivation: 现有的do-calculus以经典二值真值为基础，难以处理sheaf理论和Topos中的局部真理及复杂结构，本文旨在将因果推断推广至更一般的Topos场景，实现更广泛的结构和语义支持。

Method: 本文主要方法为：将Pearl的do-calculus推广至Topos Causal Models(TCMs)场景，并引入Lawvere-Tierney拓扑及modal operator（j），结合Kripke-Joyal语义在直觉主义逻辑下定义和证明三个与Pearl对应的因果推断规则，并对条件独立和因果论断进行j-稳定性定义、形式化和证明。

Result: 提出了j-do-calculus及其三条推理规则，证明了其在Kripke-Joyal语义下的可靠性（soundness），为基于sheaf的因果模型与数据驱动推断提供了理论基础，为进一步数据实例化和应用实验做好铺垫。

Conclusion: 本文提出的j-do-calculus因其完善的形式化和对条件独立性及因果推断规则的推广，为Topos理论下的因果推断提供坚实基础，丰富了基于sheaf的因果建模与推理方式。

Abstract: In this paper, we generalize Pearl's do-calculus to an Intuitionistic setting
called $j$-stable causal inference inside a topos of sheaves. Our framework is
an elaboration of the recently proposed framework of Topos Causal Models
(TCMs), where causal interventions are defined as subobjects. We generalize the
original setting of TCM using the Lawvere-Tierney topology on a topos, defined
by a modal operator $j$ on the subobject classifier $\Omega$. We introduce
$j$-do-calculus, where we replace global truth with local truth defined by
Kripke-Joyal semantics, and formalize causal reasoning as structure-preserving
morphisms that are stable along $j$-covers. $j$-do-calculus is a sound rule
system whose premises and conclusions are formulas of the internal
Intuitionistic logic of the causal topos. We define $j$-stability for
conditional independences and interventional claims as local truth in the
internal logic of the causal topos. We give three inference rules that mirror
Pearl's insertion/deletion and action/observation exchange, and we prove
soundness in the Kripke-Joyal semantics. A companion paper in preparation will
describe how to estimate the required entities from data and instantiate $j$-do
with standard discovery procedures (e.g., score-based and constraint-based
methods), and will include experimental results on how to (i) form data-driven
$j$-covers (via regime/section constructions), (ii) compute chartwise
conditional independences after graph surgeries, and (iii) glue them to certify
the premises of the $j$-do rules in practice

</details>


### [14] [A Lazy, Concurrent Convertibility Checker](https://arxiv.org/abs/2510.18418)
*Nathanaëlle Courant,Xavier Leroy*

Main category: cs.LO

TL;DR: 本文针对证明助手和依赖类型语言中的lambda项可转换性判定问题，提出了一种结合惰性计算与并发的新算法，既可高效剪枝，又能避免传统启发式带来的计算浪费，理论与实验结果俱佳。


<details>
  <summary>Details</summary>
Motivation: 现有可转换性判定算法多依赖启发式，可能导致大量无谓计算，难以高效解决某些lambda项等价判定问题。因此迫切需要一种更加智能、能共享计算与并发探索的新方法。

Method: 采用过程代数风格描述惰性与并发结合的可转换性判定算法，通过公平并发或并行探索子问题，并对其部分正确性、复杂性进行理论分析和机械化证明，同时进行了轻量化实验评估。

Result: 提出的算法能在存在容易等价证明时迅速发现并输出结果，在实验中表现出良好的效率，理论上保证部分正确性，并分析了复杂性。

Conclusion: 本文提出的惰性与并发结合的新型可转换性判定算法，能高效解决lambda项等价判定问题，并且兼具正确性与实用性。

Abstract: Convertibility checking - determining whether two lambda-terms are equal up
to reductions - is a crucial component of proof assistants and
dependently-typed languages. Practical implementations often use heuristics to
quickly conclude that two terms are or are not convertible without reducing
them to normal form. However, these heuristics can backfire, triggering huge
amounts of unnecessary computation. This paper presents a novel
convertibility-checking algorithm that relies crucially on laziness and
concurrency} Laziness is used to share computations, while concurrency is used
to explore multiple convertibility subproblems in parallel or via fair
interleaving. Unlike heuristics-based approaches, our algorithm always finds an
easy solution to the convertibility problem, if one exists. The paper presents
the algorithm in process calculus style and discusses its mechanized proof of
partial correctness, its complexity, and its lightweight experimental
evaluation.

</details>


### [15] [Optimistic Higher-Order Superposition](https://arxiv.org/abs/2510.18429)
*Alexander Bentkamp,Jasmin Blanchette,Matthias Hetzenberger,Uwe Waldmann*

Main category: cs.LO

TL;DR: 提出了优于原始λ-superposition的新变体，通过延迟爆炸性单化并优化泛函外延，理论上更高效且完备，但尚需实际实现。


<details>
  <summary>Details</summary>
Motivation: 原有的λ-superposition演算在处理高阶公式时表现突出，但在高阶单化枚举和泛函外延公理方面计算爆炸，影响实际应用效率。作者希望解决这些效率瓶颈。

Method: 提出了一种“乐观型”λ-superposition演算，通过将爆炸性的单化问题延迟，并将泛函外延的应用更有针对性地控制，使用约束与子句一同存储管理。

Result: 新演算在Henkin语义下是可靠且可证伪完备的。目前尚未实现原型，但例子展示其在某些场景下可能优于、或有效补充原有λ-superposition演算。

Conclusion: 乐观型λ-superposition演算通过优化爆炸性步骤，提升了高阶公式证明潜力，在理论上保证可靠性和完备性，有望在实际自动证明领域提高性能。

Abstract: The $\lambda$-superposition calculus is a successful approach to proving
higher-order formulas. However, some parts of the calculus are extremely
explosive, notably due to the higher-order unifier enumeration and the
functional extensionality axiom. In the present work, we introduce an
"optimistic" version of $\lambda$-superposition that addresses these two
issues. Specifically, our new calculus delays explosive unification problems
using constraints stored along with the clauses, and it applies functional
extensionality in a more targeted way. The calculus is sound and refutationally
complete with respect to a Henkin semantics. We have yet to implement it in a
prover, but examples suggest that it will outperform, or at least usefully
complement, the original $\lambda$-superposition calculus.

</details>


### [16] [Term Orders for Optimistic Lambda-Superposition](https://arxiv.org/abs/2510.18452)
*Alexander Bentkamp,Jasmin Blanchette,Matthias Hetzenberger*

Main category: cs.LO

TL;DR: 该论文提出了适用于 $$-superposition 演算的排序变体（$$KBO 和 $$LPO），并通过与一阶排序的编码证明了它们的有效性和性质。


<details>
  <summary>Details</summary>
Motivation: 为了适应 $$-superposition 演算，需要对经典的 KBO 和 LPO 进行变体设计，使之适配高阶/λ项环境。

Method: 通过将新的排序（$$KBO 和 $$LPO）编码到熟悉的一阶 KBO 和 LPO，从而证明了这些排序的相关性质。

Result: 成功引入了适用于 $$-superposition 的 KBO 和 LPO 变体，并证明了它们的基本性质，可通过一阶编码方法实现。

Conclusion: $$KBO 和 $$LPO 可以有效地用于 $$-superposition 演算，并能够通过编码转化为一阶的 KBO 和 LPO 来建立所需性质。

Abstract: We introduce $\lambda$KBO and $\lambda$LPO, two variants of the Knuth-Bendix
order (KBO) and the lexicographic path order (LPO) designed for use with the
$\lambda$-superposition calculus. We establish the desired properties via
encodings into the familiar first-order KBO and LPO.

</details>


### [17] [Basis-Sensitive Quantum Typing via Realisability](https://arxiv.org/abs/2510.18542)
*Alejandro Díaz-Caro,Octavio Malherbe,Rafael Romero*

Main category: cs.LO

TL;DR: 本论文建立了一个新型的量子控制lambda演算体系，通过基础（basis）标注与替换机制实现了对量子程序在不同基础下更精确的推理与类型安全，展示了Deutsch算法与量子隐形传态的应用效果，奠定了可类型化量子编程语言的新基础。


<details>
  <summary>Details</summary>
Motivation: 以往的量子lambda演算对基础的敏感度有限，难以处理任意（甚至是纠缠）基础下的程序推理。需要更细致地刻画和安全管理程序在不同基础下的表现。

Method: 在lambda演算中引入基础注释和基础依赖的替换规则，推导和验证了一套新的类型规则，并通过实例（如Deutsch算法与量子隐形传态）进行展示。

Result: 提出了一种基础敏感的lambda演算，建立了实现语义与类型系统之间的新联系，确保了类型安全，并通过经典与量子程序的示例展现了系统表达能力和便利性。

Conclusion: 该文提出了一种新的量子控制lambda演算（λ_B），实现了更细粒度的基础（basis）敏感编程和推理。该方法同时保证了类型安全和表达能力。

Abstract: We present $\lambda_B$, a quantum-control $\lambda$-calculus that refines
previous basis-sensitive systems by allowing abstractions to be expressed with
respect to arbitrary -- possibly entangled -- bases. Each abstraction and let
construct is annotated with a basis, and a new basis-dependent substitution
governs the decomposition of value distributions. These extensions preserve the
expressive power of earlier calculi while enabling finer reasoning about
programs under basis changes. A realisability semantics connects the reduction
system with the type system, yielding a direct characterisation of unitary
operators and ensuring safety by construction. From this semantics we derive a
validated family of typing rules, forming the foundation of a type-safe quantum
programming language. We illustrate the expressive benefits of $\lambda_B$
through examples such as Deutsch's algorithm and quantum teleportation, where
basis-aware typing captures classical determinism and deferred-measurement
behaviour within a uniform framework.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [18] [Modeling Layered Consciousness with Multi-Agent Large Language Models](https://arxiv.org/abs/2510.17844)
*Sang Hun Kim,Jongmin Lee,Dongkyu Park,So Young Lee,Yosep Chong*

Main category: cs.CL

TL;DR: 该论文提出一种融合精神分析理论的多智能体方法，用于在大语言模型中模拟人工意识，大幅提升了其个性化和情感表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型缺乏自我意识、前意识和无意识等心理属性，难以体现人类般的心理动态和个性化认知，亟需提升其人工意识建模能力。

Method: 构建了一个基于精神分析理论的多智能体心理动力学模型，利用个性化模块（结合固定特质与动态需求），并通过参数高效微调在情感丰富的对话数据集上进行训练，用LLM作为评测判官，测试八种个性化情境。

Result: 微调后的模型在情感深度和输出一致性上明显提升，LLM判别中71.2%的情况下偏好该模型，展示了其自适应与个性化认知的潜力。

Conclusion: 提出的多智能体架构能够有效提升大语言模型的情感深度与个性化认知，模型表现优于未调优模型。

Abstract: We propose a multi-agent framework for modeling artificial consciousness in
large language models (LLMs), grounded in psychoanalytic theory. Our
\textbf{Psychodynamic Model} simulates self-awareness, preconsciousness, and
unconsciousness through agent interaction, guided by a Personalization Module
combining fixed traits and dynamic needs. Using parameter-efficient fine-tuning
on emotionally rich dialogues, the system was evaluated across eight
personalized conditions. An LLM as a judge approach showed a 71.2\% preference
for the fine-tuned model, with improved emotional depth and reduced output
variance, demonstrating its potential for adaptive, personalized cognition.

</details>


### [19] [Outraged AI: Large language models prioritise emotion over cost in fairness enforcement](https://arxiv.org/abs/2510.17880)
*Hao Liu,Yiqing Dai,Haotian Tan,Yu Lei,Yujia Zhou,Zhen Wu*

Main category: cs.CL

TL;DR: LLMs会用情感引导惩罚决策，甚至比人类更强，但在成本与公平的权衡不足。部分模型更像人类，整体证明LLMs可进行情感驱动的道德选择。未来应提升情感与推理融合。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型（LLM）在道德决策中是否像人类一样使用情感，以及其情感在惩罚决策中的作用和机制。

Method: 进行第三方惩罚实验，比较4068个LLM代理与1159名成年人在796,100项决策中的表现，包括情感诱发、惩罚行为以及成本敏感性分析。

Result: LLMs同样会受情感驱动惩罚不公平行为，且有时比人类更强烈，但LLMs忽视成本，呈现“全或无”惩罚，无人类的权衡。部分推理模型更接近人类，但本质仍重情感。首次证明LLMs能以情感引导道德决策，但成本校准和公平判断存在缺失。

Conclusion: LLMs在道德决策中表现出基于情感的机制，但对成本的敏感性和公平的细致权衡不足，类似人类早期发展阶段。未来模型应整合情感与情境推理，以提升情感智能。

Abstract: Emotions guide human decisions, but whether large language models (LLMs) use
emotion similarly remains unknown. We tested this using altruistic third-party
punishment, where an observer incurs a personal cost to enforce fairness, a
hallmark of human morality and often driven by negative emotion. In a
large-scale comparison of 4,068 LLM agents with 1,159 adults across 796,100
decisions, LLMs used emotion to guide punishment, sometimes even more strongly
than humans did: Unfairness elicited stronger negative emotion that led to more
punishment; punishing unfairness produced more positive emotion than accepting;
and critically, prompting self-reports of emotion causally increased
punishment. However, mechanisms diverged: LLMs prioritized emotion over cost,
enforcing norms in an almost all-or-none manner with reduced cost sensitivity,
whereas humans balanced fairness and cost. Notably, reasoning models (o3-mini,
DeepSeek-R1) were more cost-sensitive and closer to human behavior than
foundation models (GPT-3.5, DeepSeek-V3), yet remained heavily emotion-driven.
These findings provide the first causal evidence of emotion-guided moral
decisions in LLMs and reveal deficits in cost calibration and nuanced fairness
judgements, reminiscent of early-stage human responses. We propose that LLMs
progress along a trajectory paralleling human development; future models should
integrate emotion with context-sensitive reasoning to achieve human-like
emotional intelligence.

</details>


### [20] [POPI: Personalizing LLMs via Optimized Natural Language Preference Inference](https://arxiv.org/abs/2510.17881)
*Yizhuo Chen,Xin Liu,Ruijie Wang,Zheng Li,Pei Chen,Changlong Yu,Priyanka Nigam,Meng Jiang,Bing Yin*

Main category: cs.CL

TL;DR: 现有大语言模型（LLM）难以因应用户个性化需求，本文提出POPI框架，用偏好推断模型生成用户个性化摘要，高效且可迁移，统一优化推断与生成任务，显著提升个性化效果且降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前LLM虽然在基准测试表现优秀，但用户需求千差万别，RLHF等对齐方法只追求平均效果，无法兼顾个体差异；而传统个性化方式如单独微调计算消耗极大，纯上下文拼接法又易受噪声干扰，效率低。

Method: 提出POPI框架，利用偏好推断模型将多样用户信号提炼为简明自然语言摘要，再以这些摘要作为个性化指令条件，驱动生成模型输出个性化内容。POPI用统一目标联合强化学习优化推断与生成过程，确保摘要编码最大有效偏好信息。

Result: 在四个个性化基准上，POPI显著提升个性化准确率并大幅减少上下文开销。其优化得到的偏好摘要可无缝迁移到其他未微调的大模型，实现即插即用个性化，无需再次训练或修改模型权重。

Conclusion: POPI是一种高效、透明、可迁移的LLM个性化工具，在兼顾准确率和计算效率的同时，为模型大规模应用和用户多样性需求提供了新思路。

Abstract: Large language models (LLMs) achieve strong benchmark performance, yet user
experiences remain inconsistent due to diverse preferences in style, tone, and
reasoning mode. Nevertheless, existing alignment techniques such as
reinforcement learning from human feedback (RLHF) or Direct Preference
Optimization (DPO) largely optimize toward population-level averages and
overlook individual variation. Naive personalization strategies like per-user
fine-tuning are computationally prohibitive, and in-context approaches that
prepend raw user signals often suffer from inefficiency and noise. To address
these challenges, we propose POPI, a general framework that introduces a
preference inference model to distill heterogeneous user signals into concise
natural language summaries. These summaries act as transparent, compact, and
transferable personalization representations that condition a shared generation
model to produce personalized responses. POPI jointly optimizes both preference
inference and personalized generation under a unified objective using
reinforcement learning, ensuring summaries maximally encode useful preference
information. Extensive experiments across four personalization benchmarks
demonstrate that POPI consistently improves personalization accuracy while
reducing context overhead by a large margin. Moreover, optimized summaries
seamlessly transfer to frozen off-the-shelf LLMs, enabling plug-and-play
personalization without weight updates.

</details>


### [21] [Advances in Pre-trained Language Models for Domain-Specific Text Classification: A Systematic Review](https://arxiv.org/abs/2510.17892)
*Zhyar Rzgar K. Rostam,Gábor Kertész*

Main category: cs.CL

TL;DR: 该综述系统梳理了预训练语言模型（PLM）在领域文本分类中的应用现状与挑战，对41篇文献进行了对比和归纳，并通过实验证明PLM在生物医学等专业领域的文本分类效果，提出未来优化方向。


<details>
  <summary>Details</summary>
Motivation: 随着科技文献和网络信息的激增，如何高效地从文本数据中提取知识成为亟需解决的问题。NLP是在文本分类等任务中应对这一挑战的关键。然而，大型语言模型（LLM）在专业领域的效果有限，主要因专业词汇、特殊语法和不平衡数据分布所致。

Method: 采用系统性文献综述（SLR）的方法，依据PRISMA标准，系统梳理2018年至2024年间41篇相关文献，严格把控纳入标准并多步筛选，辅以AI工具。重点分析Transformer为代表的现代模型的演进，对主流PLM进行归类、建立技术分类体系，并通过BERT、SciBERT和BioBERT对生物医学文本分类的对比实验验证与补充文献研究。

Result: 归纳了领域文本分类中新旧技术的演变趋势和技术分类，澄清了LLM在专业场景中的难点和注意事项。客观对比了不同PLM（如BERT、SciBERT、BioBERT）在不同领域文本分类任务上的表现，并提出当前PLM的发展方向和面临的主要局限。

Conclusion: PLM在领域文本分类中展现出显著优势，但仍存在专用词汇处理、数据不均衡等方面的挑战。未来需针对领域特性进一步优化模型设计。此文献综述为后续相关研究和实际应用提供系统参考和展望。

Abstract: The exponential increase in scientific literature and online information
necessitates efficient methods for extracting knowledge from textual data.
Natural language processing (NLP) plays a crucial role in addressing this
challenge, particularly in text classification tasks. While large language
models (LLMs) have achieved remarkable success in NLP, their accuracy can
suffer in domain-specific contexts due to specialized vocabulary, unique
grammatical structures, and imbalanced data distributions. In this systematic
literature review (SLR), we investigate the utilization of pre-trained language
models (PLMs) for domain-specific text classification. We systematically review
41 articles published between 2018 and January 2024, adhering to the PRISMA
statement (preferred reporting items for systematic reviews and meta-analyses).
This review methodology involved rigorous inclusion criteria and a multi-step
selection process employing AI-powered tools. We delve into the evolution of
text classification techniques and differentiate between traditional and modern
approaches. We emphasize transformer-based models and explore the challenges
and considerations associated with using LLMs for domain-specific text
classification. Furthermore, we categorize existing research based on various
PLMs and propose a taxonomy of techniques used in the field. To validate our
findings, we conducted a comparative experiment involving BERT, SciBERT, and
BioBERT in biomedical sentence classification. Finally, we present a
comparative study on the performance of LLMs in text classification tasks
across different domains. In addition, we examine recent advancements in PLMs
for domain-specific text classification and offer insights into future
directions and limitations in this rapidly evolving domain.

</details>


### [22] [Atomic Literary Styling: Mechanistic Manipulation of Prose Generation in Neural Language Models](https://arxiv.org/abs/2510.17909)
*Tsogt-Ochir Enkhbayar*

Main category: cs.CL

TL;DR: 观察到可区分文学文本的GPT-2神经元，被消融后反而提升了AI写作的文学性，表明解释神经元功能时观测相关性未必代表生成环节的实际效用。


<details>
  <summary>Details</summary>
Motivation: 现有工作普遍假设激活于优质输入的神经元在生成时能促进同样优质的输出，本研究旨在检验这一假设的有效性，并探究神经网络解释性分析的局限性。

Method: 作者在GPT-2上选取文学作品《巴托比文书员》作为语料，分析了模型后层32,768个神经元，提取激活模式，并进行系统的消融实验，分析神经元与文学风格生成的因果关系。

Result: 统计上有27,122个神经元对区分文学与AI文本有显著性，但消融高判别力神经元后，生成文本在文学性指标上反而提升了25.7%。这一结果挑战了神经元激活与可用性之间简单的因果关联。

Conclusion: 论文发现虽然有些神经元在辨别优质文学文本与AI生成文本时非常显著，但移除这些神经元反而提高了AI生成文本的文学风格质量，揭示了观测相关与因果必要性之间的关键差距。

Abstract: We present a mechanistic analysis of literary style in GPT-2, identifying
individual neurons that discriminate between exemplary prose and rigid
AI-generated text. Using Herman Melville's Bartleby, the Scrivener as a corpus,
we extract activation patterns from 355 million parameters across 32,768
neurons in late layers. We find 27,122 statistically significant discriminative
neurons ($p < 0.05$), with effect sizes up to $|d| = 1.4$. Through systematic
ablation studies, we discover a paradoxical result: while these neurons
correlate with literary text during analysis, removing them often improves
rather than degrades generated prose quality. Specifically, ablating 50
high-discriminating neurons yields a 25.7% improvement in literary style
metrics. This demonstrates a critical gap between observational correlation and
causal necessity in neural networks. Our findings challenge the assumption that
neurons which activate on desirable inputs will produce those outputs during
generation, with implications for mechanistic interpretability research and AI
alignment.

</details>


### [23] [JT-Safe: Intrinsically Enhancing the Safety and Trustworthiness of LLMs](https://arxiv.org/abs/2510.17918)
*Junlan Feng,Fanyu Meng,Chong Long,Pengyu Cong,Duqing Wang,Yan Zheng,Yuyao Zhang,Xuanchang Gao,Ye Yuan,Yunfei Ma,Zhijie Ren,Fan Yang,Na Wu,Di Jin,Chao Deng*

Main category: cs.CL

TL;DR: 本文针对大模型幻觉与安全问题，提出增强预训练数据与现实世界上下文结合（DWC），持续训练JT-35B-Base并配合后训练，显著提升了安全性与可信度，性能优于同类模型。


<details>
  <summary>Details</summary>
Motivation: 当前LLM存在幻觉与可信性问题，根源在于预训练数据及预测机制。现有方法多集中于后训练和推理阶段，缺乏对预训练数据本身的优化，因此希望通过增强数据与世界实际场景的结合，提升模型本质安全与可靠性。

Method: 提出以世界上下文增强的预训练数据（DWC），并将其用于JT-35B-Base模型的持续预训练及配套后训练流程，最后与同规模Qwen模型在安全与可信评测基准上进行对比。

Result: JT-Safe-35B在安全与可信评测基准上比同等规模的Qwen模型平均提升了1.79%，且预训练所用总token数更少，仅为6.2万亿。

Conclusion: 通过引入世界上下文的信息增强预训练数据，有效提升了大语言模型（LLM）的安全性和可信度。所提出的数据方法（DWC）在更少训练数据的前提下，也实现了性能提升。

Abstract: The hallucination and credibility concerns of large language models (LLMs)
are global challenges that the industry is collectively addressing. Recently, a
significant amount of advances have been made on post-training and inference
techniques to mitigate these challenges. However, it is widely agreed that
unsafe and hallucinations of LLMs intrinsically originate from pre-training,
involving pre-training data and the next-token prediction learning mechanism.
In this paper, we focus on enhancing pre-training data to improve the
trustworthiness and safety of LLMs. Since the data is vast, it's almost
impossible to entirely purge the data of factual errors, logical
inconsistencies, or distributional biases. Moreover, the pre-training data lack
grounding in real-world knowledge. Each piece of data is treated as a sequence
of tokens rather than as a representation of a part of the world. To overcome
these issues, we propose approaches to enhancing our pre-training data with its
context in the world and increasing a substantial amount of data reflecting
industrial scenarios. We argue that most source data are created by the authors
for specific purposes in a certain spatial-temporal context. They have played a
role in the real world. By incorporating related world context information, we
aim to better anchor pre-training data within real-world scenarios, thereby
reducing uncertainty in model training and enhancing the model's safety and
trustworthiness. We refer to our Data with World Context as DWC. We continue
pre-training an earlier checkpoint of JT-35B-Base with 1.5 trillion of DWC
tokens. We introduce our post-training procedures to activate the potentials of
DWC. Compared with the Qwen model of a similar scale, JT-Safe-35B achieves an
average performance improvement of 1.79% on the Safety and Trustworthy
evaluation benchmarks, while being pretrained with only 6.2 trillion tokens.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [24] [Brute-force search and Warshall algorithms for matrix-weighted graphs](https://arxiv.org/abs/2510.18260)
*Minh Hoang Trinh,Hyo-Sung Ahn*

Main category: cs.DM

TL;DR: 针对矩阵权重图，提出算法检测连通性和聚类，理论与数值实验均证实其有效性，并揭示该类图与标量权重图在连通性上的独特性。


<details>
  <summary>Details</summary>
Motivation: 尽管网络系统控制的研究迅速发展，但基于矩阵权重图的图论与算法研究依然有限。本工作试图弥补这一空白。

Method: 提出了两种算法：穷举搜索法和Warshall算法，用于判定无向矩阵权重图的连通性和聚类。算法依据矩阵权重图连通性的充分条件构建，并分析了与标量权重图的区别。

Result: 给出了算法的正确性证明，并通过数值算例展示和验证了算法效果。

Conclusion: 本文提出的两种算法能有效判别无向矩阵权重图的连通性和聚类，突出表现出矩阵权重图与标量权重图在连通性判定上的根本区别。

Abstract: Although research on the control of networked systems has grown considerably,
graph-theoretic and algorithmic studies on matrix-weighted graphs remain
limited. To bridge this gap in the literature, this work introduces two
algorithms-the brute-force search and the Warshall algorithm-for determining
connectedness and clustering in undirected matrix-weighted graphs. The proposed
algorithms, which are derived from a sufficient condition for connectedness,
emphasize a key distinction between matrix-weighted and scalar-weighted graphs.
While the existence of a path between two vertices guarantees connectedness in
scalar-weighted graphs, connectedness in matrix-weighted graphs is a collective
contribution of all paths joining the two vertices. Proofs of correctness and
numerical examples are provided to illustrate and demonstrate the effectiveness
of the algorithms.

</details>


### [25] [Weighted Treedepth is NP-complete on Graphs of Bounded Degree](https://arxiv.org/abs/2510.18584)
*Jona Dirks,Nicole Schirrmacher,Sebastian Siebertz,Alexandre Vigny*

Main category: cs.DM

TL;DR: 本文研究加权树深度问题，证明其在有界度图上NP-完全，但在路径和1-细分星图上可高效解。


<details>
  <summary>Details</summary>
Motivation: 已知加权树深度判断在树上是NP-完全的，研究其在更广泛类别的图（如有界度图）上的复杂性，以及能否在更特殊的结构上高效求解。

Method: 理论复杂性分析，NP-完全性证明，算法设计用于特定图类（路径和1-细分星图）。

Result: 证明了加权树深度问题在有界度图上依然为NP-完全问题；但在路径和1-细分星图上可高效解决。

Conclusion: 加权树深度问题在有界度图上也是NP-完全的，但在路径和1-细分星图上可以高效求解。

Abstract: A treedepth decomposition of an undirected graph $G$ is a rooted forest $F$
on the vertex set of $G$ such that every edge $uv\in E(G)$ is in
ancestor-descendant relationship in $F$. Given a weight function $w\colon
V(G)\rightarrow \mathbb{N}$, the weighted depth of a treedepth decomposition is
the maximum weight of any path from the root to a leaf, where the weight of a
path is the sum of the weights of its vertices. It is known that deciding
weighted treedepth is NP-complete even on trees. We prove that weighted
treedepth is also NP-complete on bounded degree graphs. On the positive side,
we prove that the problem is efficiently solvable on paths and on 1-subdivided
stars.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [26] [A Characterization of Turing Machines that Compute Primitive Recursive Functions](https://arxiv.org/abs/2510.18283)
*Daniel G. Schwartz*

Main category: cs.FL

TL;DR: 该文新证明了图灵可计算函数在时间复杂度有界条件下等价于原始递归函数，并首次在正式文献证明SAT及所有NP问题也满足原始递归性。


<details>
  <summary>Details</summary>
Motivation: 对已有定理给出更直接证明，并系统性地首次公开推导其对著名NP问题的结论，从而提升相关结论的学术标准和可引用性。

Method: 作者采用更为直接的新证明方法，详细推导相关定理，并补充论证其对SAT问题和所有NP问题的推广结论。

Result: 1. 给出图灵可计算函数与原始递归之间在时间复杂度下的等价性新证明；2. 首次正式证明SAT问题也是原始递归的；3. 推广至所有NP问题也是原始递归的。

Conclusion: 证明了当图灵机的时间复杂度由一个原始递归函数界定时，对应的图灵可计算自然数函数即为原始递归函数；并首次在正式文献中充分论证了可满足性问题和所有NP问题在该定义下也是原始递归的。

Abstract: This paper provides a new and more direct proof of the assertion that a
Turing computable function of the natural numbers is primitive recursive if and
only if the time complexity of the corresponding Turing machine is bounded by a
primitive recursive function of the function's arguments. In addition, it
provides detailed proofs of two consequences of this fact, which, although
well-known in some circles, do not seem to have ever been published. The first
is that the Satisfiability Problem, properly construed as a function of natural
numbers, is primitive recursive. The second is a generalization asserting that
all the problems in NP are similarly primitive recursive. The purpose here is
to present these theorems, fully detailed, in an archival journal, thereby
giving them a status of permanence and general availability.

</details>
