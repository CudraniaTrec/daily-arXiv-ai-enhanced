{"id": "2511.19565", "categories": ["cs.LO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19565", "abs": "https://arxiv.org/abs/2511.19565", "authors": ["Jorge Fandinno", "Vladimir Lifschitz"], "title": "Deductive Systems for Logic Programs with Counting", "comment": "Under consideration in Theory and Practice of Logic Programming (TPLP)", "summary": "In answer set programming, two groups of rules are considered strongly equivalent if they have the same meaning in any context. Strong equivalence of two programs can be sometimes established by deriving rules of each program from rules of the other in an appropriate deductive system. This paper shows how to extend this method of proving strong equivalence to programs containing the counting aggregate.", "AI": {"tldr": "\u672c\u8bba\u6587\u6269\u5c55\u4e86\u9488\u5bf9\u7b54\u6848\u96c6\u7f16\u7a0b\u4e2d\u5f3a\u7b49\u4ef7\u6027\u8bc1\u660e\u7684\u65b9\u6cd5\uff0c\u4f7f\u5176\u80fd\u591f\u5904\u7406\u5305\u542b\u8ba1\u6570\u805a\u5408\u7684\u89c4\u5219\u7ec4\uff0c\u4ece\u800c\u63d0\u5347\u4e86\u7406\u8bba\u7684\u9002\u7528\u8303\u56f4\u548c\u5b9e\u7528\u4ef7\u503c\u3002", "motivation": "\u5728\u7b54\u6848\u96c6\u7f16\u7a0b\u4e2d\uff0c\u9700\u8981\u5224\u65ad\u4e0d\u540c\u89c4\u5219\u7ec4\u5728\u5404\u79cd\u4e0a\u4e0b\u6587\u4e2d\u7684\u7b49\u4ef7\u6027\uff0c\u5373\u5f3a\u7b49\u4ef7\u6027\u3002\u968f\u7740\u7f16\u7a0b\u5f15\u5165\u8ba1\u6570\u805a\u5408\u64cd\u4f5c\uff0c\u73b0\u6709\u7684\u5f3a\u7b49\u4ef7\u8bc1\u660e\u65b9\u6cd5\u9762\u4e34\u65b0\u7684\u6311\u6218\uff0c\u56e0\u6b64\u9700\u8981\u6269\u5c55\u76f8\u5173\u7406\u8bba\u548c\u5de5\u5177\u3002", "method": "\u672c\u8bba\u6587\u901a\u8fc7\u6269\u5c55\u73b0\u6709\u7684\u63a8\u7406\u7cfb\u7edf\uff0c\u4f7f\u5176\u80fd\u591f\u5904\u7406\u5305\u542b\u8ba1\u6570\u805a\u5408\u7684\u7a0b\u5e8f\uff0c\u5b9e\u73b0\u4e24\u7ec4\u89c4\u5219\u5f3a\u7b49\u4ef7\u6027\u8bc1\u660e\u7684\u65b9\u6cd5\u5ef6\u4f38\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u9002\u7528\u4e8e\u5305\u542b\u8ba1\u6570\u805a\u5408\u7684\u7a0b\u5e8f\u7684\u5f3a\u7b49\u4ef7\u6027\u8bc1\u660e\u65b9\u6cd5\uff0c\u586b\u8865\u4e86\u73b0\u6709\u63a8\u7406\u7cfb\u7edf\u5728\u8be5\u9886\u57df\u7684\u4e0d\u8db3\u3002", "conclusion": "\u6269\u5c55\u7684\u63a8\u7406\u7cfb\u7edf\u548c\u8bc1\u660e\u65b9\u6cd5\u6210\u529f\u9002\u7528\u4e8e\u5305\u542b\u8ba1\u6570\u805a\u5408\u7684\u7b54\u6848\u96c6\u7a0b\u5e8f\uff0c\u4e3a\u66f4\u590d\u6742\u7684\u89c4\u5219\u7b49\u4ef7\u6027\u5224\u5b9a\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2511.19521", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.19521", "abs": "https://arxiv.org/abs/2511.19521", "authors": ["Tesla Zhang", "Asher Kornfeld", "Rui Li", "Sonya Simkin", "Yue Yao", "Stephanie Balzer"], "title": "Mechanizing a Proof-Relevant Logical Relation for Timed Message-Passing Protocols", "comment": "15 pages, 9 figures", "summary": "Semantic typing has become a powerful tool for program verification, applying the technique of logical relations as not only a proof method, but also a device for prescribing program behavior. In recent work, Yao et al. scaled semantic typing to the verification of timed message-passing protocols, which are prevalent in, e.g., IoT and real-time systems applications. The appeal of semantic typing in this context is precisely because of its ability to support typed and untyped program components alike -- including physical objects -- which caters to the heterogeneity of these applications. Another demand inherent to these applications is timing: constraining the time or time window within which a message exchange must happen. Yao et al. equipped their logical relation not only with temporal predicates, but also with computable trajectories, to supply the evidence that an inhabitant can step from one time point to another one. While Yao et al. provide the formalization for such a verification tool, it lacks a mechanization. Mechanizing the system would not only provide a machine proof for it, but also facilitate scalability for future extensions and applications.\n  This paper tackles the challenge of mechanizing the resulting proof-relevant logical relation in a proof assistant. allowing trajectories to be interleaved, partitioned, and concatenated, while the intended equality on trajectories is the equality of their graphs when seen as processes indexed by time. Unfortunately, proof assistants based on intensional type theory only have modest support for such equations, forcing a prolific use of transports. This paper reports on the process of mechanizing Yao et al.'s results, comprising the logical relation, the algebra of computable trajectories with supporting lemmas, and the fundamental theorem of the logical relation, in the Rocq theorem prover.", "AI": {"tldr": "\u672c\u6587\u5b9e\u73b0\u4e86\u9762\u5411\u65f6\u5e8f\u6d88\u606f\u534f\u8bae\u9a8c\u8bc1\u7684\u8bed\u4e49\u7c7b\u578b\u7cfb\u7edf\u7684\u673a\u68b0\u5316\u5de5\u5177\uff0c\u89e3\u51b3\u4e86\u7406\u8bba\u4e0e\u5b9e\u9645\u8131\u8282\u7684\u95ee\u9898\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u9a8c\u8bc1\u5de5\u5177\u7684\u63a8\u5e7f\u548c\u5e94\u7528\u6253\u4e0b\u4e86\u57fa\u7840\u3002", "motivation": "Yao\u7b49\u4eba\u7684\u8bed\u4e49\u7c7b\u578b\u65b9\u6cd5\u5728\u9a8c\u8bc1\u9762\u5411\u65f6\u95f4\u7684\u6d88\u606f\u4f20\u9012\u534f\u8bae\uff08\u5982\u7269\u8054\u7f51\u548c\u5b9e\u65f6\u7cfb\u7edf\uff09\u4e2d\u5c55\u73b0\u51fa\u4f18\u52bf\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u652f\u6301\u5f02\u6784\u7684\u7a0b\u5e8f\u7ec4\u4ef6\uff08\u5305\u62ec\u7269\u7406\u5bf9\u8c61\uff09\u3002\u4f46\u73b0\u6709\u7684\u5f62\u5f0f\u5316\u5de5\u5177\u7f3a\u4e4f\u673a\u68b0\u5316\uff0c\u5f71\u54cd\u4e86\u5176\u5b9e\u9645\u63a8\u5e7f\u548c\u6269\u5c55\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u672c\u6587\u91c7\u7528\u5728Rocq\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u673a\u68b0\u5316Yao\u7b49\u4eba\u7684\u4e0e\u65f6\u5e8f\u76f8\u5173\u7684\u903b\u8f91\u5173\u7cfb\uff0c\u5e76\u6784\u5efa\u4e86\u53ef\u8ba1\u7b97\u8f68\u8ff9\u7684\u4ee3\u6570\uff0c\u652f\u6301\u8f68\u8ff9\u7684\u4ea4\u9519\u3001\u5206\u5272\u548c\u62fc\u63a5\uff0c\u8bc1\u660e\u4e86\u76f8\u5173\u652f\u6301\u5f15\u7406\u548c\u903b\u8f91\u5173\u7cfb\u7684\u57fa\u672c\u5b9a\u7406\u3002\u8be5\u5de5\u4f5c\u514b\u670d\u4e86\u4f9d\u8d56\u4e8e\u5185\u6db5\u578b\u7c7b\u578b\u7406\u8bba\u8bc1\u660e\u52a9\u624b\u5728\u5904\u7406\u8f68\u8ff9\u7b49\u5f0f\u65b9\u9762\u7684\u5c40\u9650\u3002", "result": "\u6210\u529f\u5730\u5728 Rocq \u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u673a\u68b0\u5316\u4e86\u4ee5\u65f6\u5e8f\u4e3a\u4e2d\u5fc3\u7684\u903b\u8f91\u5173\u7cfb\u548c\u76f8\u5173\u7406\u8bba\uff0c\u5b8c\u5584\u4e86\u5bf9\u8f68\u8ff9\u7b49\u5f0f\u4e0e\u76f8\u5173\u64cd\u4f5c\u7684\u5f62\u5f0f\u652f\u6301\uff0c\u4f7f\u8fc7\u53bb\u7684\u7406\u8bba\u5de5\u5177\u5177\u5907\u4e86\u673a\u5668\u53ef\u9a8c\u8bc1\u3001\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002", "conclusion": "\u672c\u6587\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e0a\u4fc3\u8fdb\u4e86\u57fa\u4e8e\u8bed\u4e49\u7c7b\u578b\u7684\u3001\u9762\u5411\u65f6\u5e8f\u534f\u8bae\u7684\u7a0b\u5e8f\u9a8c\u8bc1\u5de5\u5177\u7684\u673a\u68b0\u5316\u5efa\u8bbe\uff0c\u65e2\u8bc1\u660e\u4e86\u53ef\u884c\u6027\uff0c\u4e5f\u4e3a\u65e5\u540e\u7cfb\u7edf\u6269\u5c55\u53ca\u5b9e\u9645\u5de5\u4e1a\u5e94\u7528\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2511.19747", "categories": ["cs.LO", "math.LO"], "pdf": "https://arxiv.org/pdf/2511.19747", "abs": "https://arxiv.org/abs/2511.19747", "authors": ["Tenyo Takahashi"], "title": "Chopping More Finely: Finite Countermodels in Modal Logic via the Subdivision Construction", "comment": "32 pages, 1 figure", "summary": "We present a new method, the Subdivision Construction, for proving the finite model property (the fmp) for broad classes of modal logics and modal rule systems. The construction builds on the framework of stable canonical rules, and produces a finite modal algebra (finite modal space) that will be a finite countermodel of such rules, yielding the fmp. We apply the Subdivision Construction for proving the fmp for logics and rule systems axiomatized by stable canonical formulas and rules of finite modal algebras of finite height. We also observe that these logics and rule systems are union-splittings in corresponding lattices. As a consequence, we identify a class of union-splittings in $\\mathsf{NExt}(\\mathsf{K4})$ with the degree of Kripke incompleteness 1.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Subdivision Construction\u65b9\u6cd5\uff0c\u6709\u6548\u8bc1\u660e\u4e86\u67d0\u7c7b\u6a21\u6001\u903b\u8f91\u7684\u6709\u9650\u6a21\u578b\u6027\u8d28\uff0c\u5e76\u5728K4\u6269\u5c55\u7cfb\u7edf\u4e2d\u53d1\u73b0\u4e86\u5177\u6709\u7279\u6b8aKripke\u4e0d\u5b8c\u5168\u5ea6\u7684\u7ed3\u6784\u3002", "motivation": "\u6709\u9650\u6a21\u578b\u6027\u8d28\uff08fmp\uff09\u5bf9\u4e8e\u6a21\u6001\u903b\u8f91\u7814\u7a76\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5bf9\u5e7f\u6cdb\u6a21\u6001\u903b\u8f91\u53ca\u5176\u89c4\u5219\u7cfb\u7edf\u8bc1\u660efmp\u7684\u65b9\u6cd5\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65b0\u7684\u65b9\u6cd5\u6765\u6269\u5c55\u9002\u7528\u8303\u56f4\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684Subdivision Construction\u7ec6\u5206\u6784\u9020\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4f9d\u6258\u7a33\u5b9a\u89c4\u8303\u89c4\u5219\uff0c\u6784\u5efa\u6709\u9650\u6a21\u6001\u4ee3\u6570\uff0c\u4ece\u800c\u751f\u6210\u6709\u9650\u7684\u53cd\u6a21\u578b\u4ee5\u8bc1\u660e\u6240\u6d89\u53ca\u903b\u8f91\u548c\u89c4\u5219\u7cfb\u7edf\u7684\u6709\u9650\u6a21\u578b\u6027\u8d28\u3002", "result": "\u8be5\u65b9\u6cd5\u6210\u529f\u8bc1\u660e\u4e86\u7531\u6709\u9650\u9ad8\u5ea6\u6709\u9650\u6a21\u6001\u4ee3\u6570\u7684\u7a33\u5b9a\u89c4\u8303\u516c\u5f0f\u548c\u89c4\u5219\u516c\u7406\u5316\u7684\u903b\u8f91\u548c\u89c4\u5219\u7cfb\u7edf\u7684\u6709\u9650\u6a21\u578b\u6027\u8d28\uff0c\u5e76\u53d1\u73b0\u8fd9\u4e9b\u903b\u8f91\u548c\u7cfb\u7edf\u5728\u5bf9\u5e94\u683c\u4e2d\u662funion-splittings\u3002\u6b64\u5916\uff0c\u53d1\u73b0\u4e86\u5728\u6269\u5c55K4\u6a21\u6001\u903b\u8f91\u7cfb\u7edf\uff08NExt(K4)\uff09\u4e2dKripke\u4e0d\u5b8c\u5168\u5ea6\u4e3a1\u7684\u4e00\u7c7bunion-splittings\u3002", "conclusion": "Subdivision Construction\u65b9\u6cd5\u6709\u6548\u6269\u5c55\u4e86\u80fd\u591f\u8bc1\u660e\u6709\u9650\u6a21\u578b\u6027\u8d28\u7684\u6a21\u6001\u903b\u8f91\u53ca\u89c4\u5219\u7cfb\u7edf\u7684\u7c7b\u522b\uff0c\u5e76\u5728\u6a21\u6001\u903b\u8f91\u7ed3\u6784\u4e0a\u7ed9\u51fa\u4e86\u65b0\u7684\u5206\u7c7b\u4e0e\u4e0d\u5b8c\u5168\u6027\u89c2\u5bdf\u3002"}}
{"id": "2511.19764", "categories": ["cs.PL", "cs.AR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.19764", "abs": "https://arxiv.org/abs/2511.19764", "authors": ["Ayaka Yorihiro", "Griffin Berlstein", "Pedro Pontes Garc\u00eda", "Kevin Laeufer", "Adrian Sampson"], "title": "Understanding Accelerator Compilers via Performance Profiling", "comment": null, "summary": "Accelerator design languages (ADLs), high-level languages that compile to hardware units, help domain experts quickly design efficient application-specific hardware. ADL compilers optimize datapaths and convert software-like control flow constructs into control paths. Such compilers are necessarily complex and often unpredictable: they must bridge the wide semantic gap between high-level semantics and cycle-level schedules, and they typically rely on advanced heuristics to optimize circuits. The resulting performance can be difficult to control, requiring guesswork to find and resolve performance problems in the generated hardware. We conjecture that ADL compilers will never be perfect: some performance unpredictability is endemic to the problem they solve.\n  In lieu of compiler perfection, we argue for compiler understanding tools that give ADL programmers insight into how the compiler's decisions affect performance. We introduce Petal, a cycle-level Petal for the Calyx intermediate language (IL). Petal instruments the Calyx code with probes and then analyzes the trace from a register-transfer-level simulation. It maps the events in the trace back to high-level control constructs in the Calyx code to track the clock cycles when each construct was active. Using case studies, we demonstrate that Petal's cycle-level profiles can identify performance problems in existing accelerator designs. We show that these insights can also guide developers toward optimizations that the compiler was unable to perform automatically, including a reduction by 46.9\\% of total cycles for one application.", "AI": {"tldr": "\u672c\u8bba\u6587\u9488\u5bf9\u52a0\u901f\u5668\u8bbe\u8ba1\u8bed\u8a00\u7f16\u8bd1\u5668\u6027\u80fd\u4e0d\u53ef\u9884\u6d4b\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u540d\u4e3aPetal\u7684\u5468\u671f\u7ea7\u5206\u6790\u5de5\u5177\uff0c\u80fd\u5e2e\u52a9\u5f00\u53d1\u8005\u5b9a\u4f4d\u5e76\u4f18\u5316\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u6027\u80fd\u74f6\u9888\u3002\u7ecf\u8fc7\u5b9e\u8bc1\uff0c\u5de5\u5177\u80fd\u663e\u8457\u63d0\u5347\u786c\u4ef6\u6027\u80fd\uff0c\u90e8\u5206\u5e94\u7528\u603b\u8fd0\u884c\u5468\u671f\u51cf\u5c11\u8fd1\u4e00\u534a\u3002", "motivation": "\u73b0\u6709\u7684\u52a0\u901f\u5668\u8bbe\u8ba1\u8bed\u8a00\uff08ADL\uff09\u7f16\u8bd1\u5668\u5728\u5c06\u9ad8\u5c42\u8bed\u4e49\u8f6c\u5316\u4e3a\u786c\u4ef6\u5468\u671f\u7ea7\u6267\u884c\u8ba1\u5212\u65f6\u5b58\u5728\u4e0d\u53ef\u9884\u6d4b\u6027\uff0c\u4e0d\u6613\u63a7\u5236\u6027\u80fd\u4e14\u96be\u4ee5\u5b9a\u4f4d\u95ee\u9898\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u7c7b\u7f16\u8bd1\u5668\u65e0\u6cd5\u505a\u5230\u5b8c\u5168\u7406\u60f3\uff0c\u6027\u80fd\u4e0d\u53ef\u9884\u6d4b\u6027\u662f\u5185\u5728\u96be\u9898\u3002", "method": "\u63d0\u51fa\u4e86Petal\u5de5\u5177\uff0c\u5bf9Calyx\u4e2d\u95f4\u8bed\u8a00\u8fdb\u884c\u5468\u671f\u7ea7\u6027\u80fd\u5206\u6790\uff0c\u901a\u8fc7\u5728\u4ee3\u7801\u63d2\u5165\u63a2\u9488\u5e76\u5206\u6790\u5bc4\u5b58\u5668\u4f20\u8f93\u7ea7\u6a21\u62df\u7684\u8f68\u8ff9\uff0c\u5c06\u4f4e\u5c42\u4e8b\u4ef6\u6620\u5c04\u56de\u4e0a\u5c42\u63a7\u5236\u7ed3\u6784\uff0c\u4ece\u800c\u8ffd\u8e2a\u6bcf\u4e2a\u6784\u9020\u5728\u65f6\u949f\u5468\u671f\u7684\u6d3b\u8dc3\u60c5\u51b5\u3002\u5e76\u4ee5\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u5176\u6548\u679c\u3002", "result": "\u5229\u7528Petal\u5206\u6790\u5de5\u5177\uff0c\u53ef\u4ee5\u8bc6\u522b\u5b9e\u9645\u52a0\u901f\u5668\u8bbe\u8ba1\u4e2d\u7684\u6027\u80fd\u74f6\u9888\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u53d1\u73b0\u7f16\u8bd1\u5668\u672a\u80fd\u81ea\u52a8\u4f18\u5316\u7684\u95ee\u9898\uff0c\u5e76\u6307\u5bfc\u4f18\u5316\u3002\u5b9e\u9645\u6848\u4f8b\u4e2d\u5bf9\u67d0\u5e94\u7528\u603b\u5468\u671f\u6570\u51cf\u5c11\u4e8646.9%\u3002", "conclusion": "ADL\u7f16\u8bd1\u5668\u7684\u6027\u80fd\u4e0d\u53ef\u9884\u6d4b\u6027\u96be\u4ee5\u6839\u672c\u89e3\u51b3\uff0c\u4f46\u901a\u8fc7\u7406\u89e3\u7f16\u8bd1\u5668\u51b3\u7b56\u5f71\u54cd\u6027\u80fd\u7684\u5206\u6790\u5de5\u5177\uff0c\u5982Petal\uff0c\u53ef\u4ee5\u5e2e\u52a9\u5f00\u53d1\u8005\u66f4\u597d\u5730\u4f18\u5316\u786c\u4ef6\u8bbe\u8ba1\u3002"}}
{"id": "2511.19897", "categories": ["cs.LO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2511.19897", "abs": "https://arxiv.org/abs/2511.19897", "authors": ["Parosh Aziz Abdulla", "Yu-Fang Chen", "Michal He\u010dko", "Luk\u00e1\u0161 Hol\u00edk", "Ond\u0159ej Leng\u00e1l", "Jyun-Ao Lin", "Ramanathan Srinivasan Thinniyam"], "title": "Parameterized Verification of Quantum Circuits (Technical Report)", "comment": "Accepted for POPL'26", "summary": "We present the first fully automatic framework for verifying relational properties of parameterized quantum programs, i.e., a program that, given an input size, generates a corresponding quantum circuit. We focus on verifying input-output correctness as well as equivalence. At the core of our approach is a new automata model, synchronized weighted tree automata (SWTAs), which compactly and precisely captures the infinite families of quantum states produced by parameterized programs. We introduce a class of transducers to model quantum gate semantics and develop composition algorithms for constructing transducers of parameterized circuits. Verification is reduced to functional inclusion or equivalence checking between SWTAs, for which we provide decision procedures. Our implementation demonstrates both the expressiveness and practical efficiency of the framework by verifying a diverse set of representative parameterized quantum programs with verification times ranging from milliseconds to seconds.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u7528\u4e8e\u53c2\u6570\u5316\u91cf\u5b50\u7a0b\u5e8f\u5173\u7cfb\u6027\u8d28\u5168\u81ea\u52a8\u9a8c\u8bc1\u7684\u6846\u67b6\uff0c\u57fa\u4e8e\u65b0\u9896\u7684\u540c\u6b65\u52a0\u6743\u6811\u81ea\u52a8\u673a\u548c\u53d8\u6362\u5668\uff0c\u7406\u8bba\u548c\u5b9e\u8df5\u5747\u8868\u660e\u8be5\u65b9\u6cd5\u9ad8\u6548\u4e14\u8868\u8fbe\u529b\u5f3a\uff0c\u663e\u8457\u63a8\u52a8\u4e86\u91cf\u5b50\u7a0b\u5e8f\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u53d1\u5c55\u3002", "motivation": "\u76ee\u524d\u8fd8\u7f3a\u4e4f\u5bf9\u53c2\u6570\u5316\u91cf\u5b50\u7a0b\u5e8f\u7684\u5173\u7cfb\u6027\u8d28\uff08\u5982\u8f93\u5165\u8f93\u51fa\u6b63\u786e\u6027\u3001\u7b49\u4ef7\u6027\uff09\u8fdb\u884c\u5168\u81ea\u52a8\u9a8c\u8bc1\u7684\u65b9\u6cd5\uff0c\u800c\u8fd9\u4e9b\u9a8c\u8bc1\u5bf9\u4e8e\u91cf\u5b50\u7b97\u6cd5\u7684\u53ef\u9760\u6027\u548c\u6b63\u786e\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u52a8\u673a\u6a21\u578b\uff1a\u540c\u6b65\u52a0\u6743\u6811\u81ea\u52a8\u673a\uff08SWTA\uff09\uff0c\u80fd\u7cbe\u786e\u5e76\u7d27\u51d1\u5730\u6355\u6349\u53c2\u6570\u5316\u91cf\u5b50\u7a0b\u5e8f\u751f\u6210\u7684\u65e0\u9650\u91cf\u5b50\u6001\u65cf\u3002\u540c\u65f6\uff0c\u5f15\u5165\u53d8\u6362\u5668\u523b\u753b\u91cf\u5b50\u95e8\u8bed\u4e49\uff0c\u5f00\u53d1\u4e86\u7ec4\u5408\u7b97\u6cd5\u6765\u4e3a\u53c2\u6570\u5316\u7535\u8def\u6784\u9020\u53d8\u6362\u5668\u3002\u5c06\u9a8c\u8bc1\u95ee\u9898\u5f52\u7ea6\u4e3aSWTA\u4e4b\u95f4\u7684\u51fd\u6570\u5305\u542b\u6027\u6216\u7b49\u4ef7\u6027\u6821\u9a8c\uff0c\u5e76\u7ed9\u51fa\u4e86\u5224\u5b9a\u8fc7\u7a0b\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u6beb\u79d2\u5230\u79d2\u7ea7\u65f6\u95f4\u5185\uff0c\u9ad8\u6548\u4e14\u51c6\u786e\u5730\u9a8c\u8bc1\u591a\u79cd\u4ee3\u8868\u6027\u53c2\u6570\u5316\u91cf\u5b50\u7a0b\u5e8f\uff0c\u5c55\u73b0\u4e86\u65b9\u6cd5\u7684\u8868\u8fbe\u80fd\u529b\u548c\u5b9e\u7528\u6548\u7387\u3002", "conclusion": "\u9996\u6b21\u5b9e\u73b0\u4e86\u5bf9\u53c2\u6570\u5316\u91cf\u5b50\u7a0b\u5e8f\u7684\u5173\u7cfb\u6027\u8d28\u8fdb\u884c\u5168\u81ea\u52a8\u9a8c\u8bc1\u7684\u65b0\u6846\u67b6\uff0c\u7406\u8bba\u4e0a\u548c\u5b9e\u8df5\u4e0a\u90fd\u5f97\u5230\u4e86\u6709\u6548\u9a8c\u8bc1\uff0c\u5bf9\u91cf\u5b50\u7a0b\u5e8f\u9a8c\u8bc1\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.20369", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.20369", "abs": "https://arxiv.org/abs/2511.20369", "authors": ["Frank Sch\u00fcssele", "Matthias Zumkeller", "Miriam Lagunes-Rochin", "Dominik Klumpp"], "title": "The Ghosts of Empires: Extracting Modularity from Interleaving-Based Proofs (Extended Version)", "comment": "39 pages, 10 figures, 1 table. Extended version with proofs of the paper published at POPL'2026 (https://doi.org/10.1145/3776684)", "summary": "Implementation bugs threaten the soundness of algorithmic software verifiers. Generating correctness certificates for correct programs allows for efficient independent validation of verification results, and thus helps to reveal such bugs. Automatic generation of small, compact correctness proofs for concurrent programs is challenging, as the correctness arguments may depend on the particular interleaving, which can lead to exponential explosion. We present an approach that converts an interleaving-based correctness proof, as generated by many algorithmic verifiers, into a thread-modular correctness proof in the style of Owicki and Gries. We automatically synthesize ghost variables that capture the relevant interleaving information, and abstract away irrelevant details. Our evaluation shows that the approach is efficient in practice and generates compact proofs, compared to a baseline.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5c06\u5e76\u53d1\u7a0b\u5e8f\u7684\u4ea4\u9519\u5f0f\u6b63\u786e\u6027\u8bc1\u660e\u8f6c\u5316\u4e3a\u53ef\u72ec\u7acb\u9a8c\u8bc1\u4e14\u7d27\u51d1\u7684Owicki-Gries\u7ebf\u7a0b\u6a21\u5757\u5316\u8bc1\u660e\u7684\u65b9\u6cd5\uff0c\u81ea\u52a8\u751f\u6210\u6240\u9700\u7684ghost\u53d8\u91cf\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u9ad8\u6548\u4e14\u751f\u6210\u8bc1\u660e\u6587\u4ef6\u66f4\u5c0f\u3002", "motivation": "\u5f53\u524d\u7b97\u6cd5\u5316\u8f6f\u4ef6\u9a8c\u8bc1\u5668\u5b58\u5728\u5b9e\u73b0\u4e0a\u7684\u6f0f\u6d1e\uff0c\u5f71\u54cd\u5176\u5728\u9a8c\u8bc1\u8fc7\u7a0b\u4e2d\u7684\u53ef\u9760\u6027\u3002\u4e3a\u4e86\u72ec\u7acb\u6709\u6548\u5730\u9a8c\u8bc1\u8fd9\u4e9b\u5de5\u5177\u7684\u7ed3\u679c\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u4e3a\u6b63\u786e\u7a0b\u5e8f\u81ea\u52a8\u751f\u6210\u7d27\u51d1\u3001\u6613\u68c0\u67e5\u7684\u6b63\u786e\u6027\u8bc1\u660e\u3002\u7279\u522b\u662f\u5728\u5e76\u53d1\u7a0b\u5e8f\u9886\u57df\uff0c\u7531\u4e8e\u6267\u884c\u987a\u5e8f\u7684\u590d\u6742\uff0c\u6b63\u786e\u6027\u8bc1\u660e\u96be\u4ee5\u538b\u7f29\u548c\u81ea\u52a8\u5316\u3002", "method": "\u6587\u4e2d\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u5c06\u57fa\u4e8e\u4ea4\u9519(interleaving)\u7684\u6b63\u786e\u6027\u8bc1\u660e\uff08\u76ee\u524d\u8bb8\u591a\u8f6f\u4ef6\u9a8c\u8bc1\u5668\u751f\u6210\u8fd9\u7c7b\u8bc1\u660e\uff09\uff0c\u81ea\u52a8\u8f6c\u5316\u4e3aOwicki-Gries\u98ce\u683c\u7684\u7ebf\u7a0b\u6a21\u5757\u5316(thread-modular)\u6b63\u786e\u6027\u8bc1\u660e\u3002\u8be5\u65b9\u6cd5\u4f1a\u81ea\u52a8\u5408\u6210ghost\u53d8\u91cf\u7528\u4e8e\u8bb0\u5f55\u76f8\u5173\u7684\u4ea4\u9519\u4fe1\u606f\uff0c\u5e76\u62bd\u8c61\u5316\u65e0\u5173\u7ec6\u8282\u3002", "result": "\u65b9\u6cd5\u5f97\u5230\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\uff1a\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u672c\u65b9\u6cd5\u751f\u6210\u7684\u6b63\u786e\u6027\u8bc1\u660e\u66f4\u52a0\u7d27\u51d1\uff0c\u540c\u65f6\u5b9e\u9645\u6548\u7387\u4e5f\u8f83\u9ad8\u3002", "conclusion": "\u6587\u4e2d\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u9ad8\u6548\u81ea\u52a8\u5730\u4e3a\u5e76\u53d1\u7a0b\u5e8f\u751f\u6210\u7d27\u51d1\u7684\u6b63\u786e\u6027\u8bc1\u660e\uff0c\u6709\u52a9\u4e8e\u72ec\u7acb\u9a8c\u8bc1\u8f6f\u4ef6\u9a8c\u8bc1\u5668\u7684\u6b63\u786e\u6027\uff0c\u4ece\u800c\u4fdd\u969c\u7b97\u6cd5\u5316\u8f6f\u4ef6\u9a8c\u8bc1\u5de5\u5177\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.20249", "categories": ["cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2511.20249", "abs": "https://arxiv.org/abs/2511.20249", "authors": ["S\u00e9bastien Bonte", "Gauvain Devillez", "Valentin Dusollier", "Alain Hertz", "Hadrien M\u00e9lot", "David Schindl"], "title": "ChemicHull: an online tool for determining extremal chemical graphs of maximum degree at most 3 for any degree-based topological indices", "comment": "23 pages, 8 figures", "summary": "Topological indices are graph-theoretic descriptors that play a crucial role in mathematical chemistry, capturing the structural characteristics of molecules and enabling the prediction of their physicochemical properties. A widely studied category of topological indices, known as degree-based topological indices, are calculated as the sum of the weights of a graph's edges, where each edge weight is determined by a formula that depends solely on the degrees of its endpoints.\n  This work focuses exclusively on chemical graphs in which no vertex has a degree greater than 3, a model for conjugated systems. Within a polyhedral framework, each chemical graph is mapped to a point in a three-dimensional space, enabling extremal values of any degree-based topological index to be determined through linear optimization over the corresponding polyhedron. Analysis within this framework reveals that extremality is limited to a small subset of chemical graph families, implying that certain chemical graphs can never attain extremality for any degree-based topological index.\n  The main objective of this paper is to present ChemicHull, an online tool we have developed to determine and display extremal chemical graphs for arbitrary degree-based topological indices. To illustrate the power of this tool, we easily recover established results, emphasizing its effectiveness for chemically significant graph classes such as chemical trees and unicyclic chemical graphs. This tool also enabled the identification of a counterexample to a previously published extremal result concerning the Randi\u0107 index.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u901a\u8fc7\u591a\u9762\u4f53\u4f18\u5316\u7406\u8bba\u53ca\u5728\u7ebf\u5de5\u5177ChemicHull\uff0c\u9ad8\u6548\u5bfb\u627e\u5404\u7c7b\u5ea6\u57fa\u62d3\u6251\u6307\u6570\u7684\u6781\u503c\u5316\u5b66\u56fe\uff0c\u63ed\u793a\u53ea\u6709\u90e8\u5206\u56fe\u80fd\u5b9e\u73b0\u6781\u503c\uff0c\u5e76\u7528\u65b0\u5de5\u5177\u7ea0\u6b63\u4e86\u65e2\u6709\u7406\u8bba\u9519\u8bef\u3002", "motivation": "\u62d3\u6251\u6307\u6570\u5728\u6570\u5b66\u5316\u5b66\u9886\u57df\u7528\u4e8e\u63cf\u8ff0\u5206\u5b50\u7ed3\u6784\u7279\u5f81\uff0c\u5e76\u80fd\u9884\u6d4b\u5176\u7269\u7406\u5316\u5b66\u6027\u8d28\u3002\u5ea6\u57fa\u62d3\u6251\u6307\u6570\u662f\u4e00\u7c7b\u5e38\u7528\u7684\u6307\u6807\uff0c\u4ec5\u4f9d\u8d56\u4e8e\u56fe\u4e2d\u9876\u70b9\u7684\u5ea6\u6570\u3002\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u7cfb\u7edf\u6027\u5730\u627e\u51fa\u8fd9\u4e9b\u6307\u6570\u7684\u6781\u503c\u5316\u5b66\u56fe\u3002\u4e3a\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u9ad8\u6548\u5de5\u5177\u4e0e\u7406\u8bba\u65b9\u6cd5\u3002", "method": "\u5c06\u6bcf\u4e2a\u5316\u5b66\u56fe\uff08\u9876\u70b9\u5ea6\u6700\u5927\u4e3a3\uff09\u6620\u5c04\u5230\u4e09\u7ef4\u7a7a\u95f4\u7684\u591a\u9762\u4f53\uff0c\u7136\u540e\u901a\u8fc7\u7ebf\u6027\u4f18\u5316\u65b9\u6cd5\u786e\u5b9a\u6240\u6709\u53ef\u80fd\u7684\u5ea6\u57fa\u62d3\u6251\u6307\u6570\u5728\u8be5\u591a\u9762\u4f53\u4e0a\u7684\u6781\u503c\u3002\u5f00\u53d1\u4e86\u540d\u4e3aChemicHull\u7684\u5728\u7ebf\u5de5\u5177\uff0c\u53ef\u81ea\u52a8\u8ba1\u7b97\u3001\u5c55\u73b0\u4efb\u610f\u5ea6\u57fa\u62d3\u6251\u6307\u6570\u7684\u6781\u503c\u5316\u5b66\u56fe\u3002", "result": "\u5206\u6790\u663e\u793a\uff0c\u4ec5\u6709\u5c11\u6570\u5316\u5b66\u56fe\u65cf\u80fd\u591f\u83b7\u5f97\u5ea6\u57fa\u62d3\u6251\u6307\u6570\u7684\u6781\u503c\uff0c\u90e8\u5206\u5316\u5b66\u56fe\u6c38\u8fdc\u65e0\u6cd5\u6210\u4e3a\u6781\u503c\u56fe\u3002ChemicHull\u5de5\u5177\u53ef\u4ee5\u6709\u6548\u3001\u4fbf\u6377\u5730\u6062\u590d\u5df2\u77e5\u7ed3\u679c\uff0c\u8fd8\u9002\u7528\u4e8e\u5206\u6790\u5316\u5b66\u6811\u548c\u5355\u73af\u5316\u5b66\u56fe\u3002\u8be5\u5de5\u5177\u8fd8\u53d1\u73b0\u4e86\u5173\u4e8eRandi\u0107\u6307\u6570\u7684\u4e00\u4e2a\u53cd\u4f8b\uff0c\u4fee\u6b63\u4e86\u5148\u524d\u7684\u7ed3\u8bba\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u591a\u9762\u4f53\u7406\u8bba\u7684\u7cfb\u7edf\u65b9\u6cd5\u4e0e\u5728\u7ebf\u5de5\u5177ChemicHull\uff0c\u5b9e\u73b0\u4e86\u6781\u503c\u5316\u5b66\u56fe\u7684\u81ea\u52a8\u5316\u63a2\u7d22\u4e0e\u53ef\u89c6\u5316\u3002\u65b0\u53d1\u73b0\u4fee\u6b63\u4e86\u5173\u4e8e\u67d0\u4e9b\u5ea6\u57fa\u62d3\u6251\u6307\u6570\u6781\u503c\u7684\u5df2\u77e5\u7ed3\u8bba\uff0c\u6781\u9ad8\u6548\u5730\u670d\u52a1\u4e8e\u5316\u5b66\u56fe\u5206\u6790\u3002"}}
{"id": "2511.20193", "categories": ["cs.LO", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.20193", "abs": "https://arxiv.org/abs/2511.20193", "authors": ["Neta Elad", "Adithya Murali", "Sharon Shoham"], "title": "Separating the Wheat from the Chaff: Understanding (In-)Completeness of Proof Mechanisms for Separation Logic with Inductive Definitions", "comment": null, "summary": "For over two decades Separation Logic has been arguably the most popular framework for reasoning about heap-manipulating programs, as well as reasoning about shared resources and permissions. Separation Logic is often extended to include inductively-defined predicates, interpreted as least fixpoints, forming Separation Logic with Inductive Definitions (SLID). Many theoretical and practical advances have been made in developing automated proof mechanisms for SLID, but these mechanisms are imperfect, and a deeper understanding of their failures is desired. As expressive as Separation Logic is, it is not surprising that it is incomplete, and in fact, it contains several sources of incompleteness that defy automated reasoning.\n  In this paper we study these sources of incompleteness and how they relate to failures of proof mechanisms. We place SLID within a larger logic, that we call Weak Separation Logic (WSL). We prove that unlike SLID, WSL is complete for a non-trivial fragment of quantified entailments with background theories and inductive definitions, via a reduction to first-order logic (FOL). Moreover, we show that the ubiquitous fold/unfold proof mechanism is sound and complete for theory-free, quantifier-free WSL entailments with inductive definitions. Through this, we understand proof failures as stemming from nonstandard models present in WSL, but not allowed in SLID. These rogue models are typically infinite, and we use the formalism of symbolic structures to represent and automatically find them.\n  We present a prototype tool that implements the FOL encoding of WSL and test it on an existing benchmark, which contains over 700 quantified entailment problems with inductive definitions. Our tool is able to find counter-models to many of the examples, and we provide a partial taxonomy of the rogue models, shedding some light on real-world proof failures.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5206\u79bb\u903b\u8f91\u4e2d\u81ea\u52a8\u8bc1\u660e\u5931\u8d25\u7684\u6839\u6e90\uff0c\u901a\u8fc7\u5c06SLID\u6269\u5c55\u5230WSL\uff0c\u7406\u8bba\u4e0a\u8bc1\u660eWSL\u5728\u7279\u5b9a\u7247\u6bb5\u662f\u5b8c\u5907\u7684\uff0c\u5e76\u901a\u8fc7\u539f\u578b\u5de5\u5177\u6210\u529f\u8bc6\u522b\u548c\u5206\u7c7b\u4e86\u5bfc\u81f4\u5931\u8d25\u7684\u201c\u6d41\u6c13\u6a21\u578b\u201d\u3002", "motivation": "\u5206\u79bb\u903b\u8f91\uff08Separation Logic\uff09\u5728\u63a8\u7406\u5806\u64cd\u4f5c\u7a0b\u5e8f\u548c\u5171\u4eab\u8d44\u6e90\u65b9\u9762\u975e\u5e38\u6d41\u884c\uff0c\u4f46\u5176\u6269\u5c55SLID\u5728\u81ea\u52a8\u5316\u8bc1\u660e\u8fc7\u7a0b\u4e2d\u5b58\u5728\u4e0d\u5b8c\u6574\u6027\u548c\u5931\u8d25\u73b0\u8c61\uff0c\u4f5c\u8005\u5e0c\u671b\u6df1\u5165\u7406\u89e3\u5bfc\u81f4\u8fd9\u4e9b\u5931\u8d25\u7684\u6839\u672c\u539f\u56e0\u3002", "method": "\u4f5c\u8005\u5c06SLID\u7f6e\u4e8e\u66f4\u5927\u7684\u903b\u8f91WSL\uff08\u5f31\u5206\u79bb\u903b\u8f91\uff09\u6846\u67b6\u4e2d\uff0c\u901a\u8fc7\u4e0e\u4e00\u9636\u903b\u8f91\uff08FOL\uff09\u7684\u5f52\u7ea6\uff0c\u7406\u8bba\u5206\u6790WSL\u4e0eSLID\u7684\u533a\u522b\uff0c\u5e76\u5229\u7528\u539f\u578b\u5de5\u5177\u5b9e\u73b0\u4e86WSL\u7684FOL\u7f16\u7801\uff0c\u5bf9\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u96c6\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u4f5c\u8005\u8bc1\u660eWSL\u5728\u91cf\u5316\u8574\u6db5\u7684\u975e\u5e73\u51e1\u7247\u6bb5\u4e0a\u662f\u5b8c\u5907\u7684\uff0c\u5e76\u4e14WSL\u7684fold/unfold\u8bc1\u660e\u673a\u5236\u5bf9\u4e8e\u65e0\u7406\u8bba\u3001\u65e0\u91cf\u8bcd\u7684\u60c5\u51b5\u662f\u5b8c\u5907\u548c\u53ef\u9760\u7684\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5de5\u5177\u80fd\u591f\u627e\u5230\u8bb8\u591a\u53cd\u4f8b\u6a21\u578b\uff0c\u5e76\u5bf9\u201c\u6d41\u6c13\u6a21\u578b\u201d\u8fdb\u884c\u4e86\u5206\u7c7b\u5206\u6790\u3002", "conclusion": "\u901a\u8fc7\u7406\u8bba\u4e0e\u5b9e\u9a8c\u5206\u6790\uff0c\u4f5c\u8005\u63ed\u793a\u4e86SLID\u4e0d\u5b8c\u6574\u6027\u7684\u6839\u672c\u539f\u56e0\uff0c\u63d0\u51fa\u4e86WSL\u548c\u8c61\u5f81\u7ed3\u6784\u7528\u4e8e\u8fa8\u8bc6\u548c\u81ea\u52a8\u53d1\u73b0\u5bfc\u81f4\u8bc1\u660e\u5931\u8d25\u7684\u201c\u6d41\u6c13\u6a21\u578b\u201d\uff0c\u4ece\u800c\u4e3a\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u81ea\u52a8\u8bc1\u660e\u5931\u8d25\u73b0\u8c61\u63d0\u4f9b\u4e86\u7406\u8bba\u89e3\u91ca\u548c\u5b9e\u9645\u5de5\u5177\u3002"}}
{"id": "2511.20367", "categories": ["cs.DM", "cs.CC"], "pdf": "https://arxiv.org/pdf/2511.20367", "abs": "https://arxiv.org/abs/2511.20367", "authors": ["Kevin Mann"], "title": "Enumeration With Nice Roman Domination Properties", "comment": "An extended abstract of this paper will be published in the proceedings of SOFSEM 2026", "summary": "Although Extension Perfect Roman Domination is NP-complete, all minimal (with respect to the pointwise order) perfect Roman dominating functions can be enumerated with polynomial delay. This algorithm uses a bijection between minimal perfect Roman dominating functions and Roman dominating functions and the fact that all minimal Roman dominating functions can be enumerated with polynomial delay. This bijection considers the set of vertices with value 2 under the functions. In this paper, we will generalize this idea by defining so called nice Roman Domination properties for which we can employ this method. With this idea, we can show that all minimal maximal Roman Dominating functions can be enumerated with polynomial delay in O(1.9332^n) time. Furthermore, we prove that enumerating all minimal connected/total Roman dominating functions on cobipartite graphs can be achieved with polynomial delay. Additionally, we show the existence of a polynomial-delay algorithm for enumerating all minimal connected Roman dominating function on interval graphs. We show some downsides to this method as well.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u63a8\u5e7f\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u591a\u9879\u5f0f\u5ef6\u8fdf\u679a\u4e3e\u7b97\u6cd5\uff0c\u4f7f\u5f97\u591a\u79cd\u7f57\u9a6c\u652f\u914d\u53d8\u4f53\u6781\u5c0f\u652f\u914d\u51fd\u6570\u7684\u9ad8\u6548\u679a\u4e3e\u6210\u4e3a\u53ef\u80fd\uff0c\u8986\u76d6\u4e86\u5305\u62ec\u6781\u5927\u3001\u8fde\u901a\u3001\u5168\u4f53\u7b49\u591a\u79cd\u7c7b\u578b\uff0c\u4ee5\u53ca\u4e0d\u540c\u7279\u6b8a\u56fe\u7c7b\uff0c\u5e76\u5206\u6790\u4e86\u65b9\u6cd5\u7684\u4e0d\u8db3\u4e4b\u5904\u3002", "motivation": "\u7f57\u9a6c\u652f\u914d\u53ca\u5176\u53d8\u4f53\u5728\u56fe\u8bba\u548c\u6700\u4f18\u5316\u7b49\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u7136\u800c\uff0c\u76f8\u5173\u95ee\u9898\uff08\u5982\u6269\u5c55\u5b8c\u7f8e\u7f57\u9a6c\u652f\u914d\uff09\u5224\u5b9a\u95ee\u9898\u4e3aNP\u5b8c\u5168\uff0c\u4f46\u5bf9\u5176\u6781\u5c0f\u652f\u914d\u51fd\u6570\u7684\u679a\u4e3e\u6548\u7387\u4e0d\u9ad8\u3002\u4f5c\u8005\u5e0c\u671b\u53d1\u5c55\u4e00\u822c\u5316\u65b9\u6cd5\u63d0\u5347\u679a\u4e3e\u6548\u7387\uff0c\u540c\u65f6\u6269\u5c55\u9002\u7528\u8303\u56f4\u5230\u66f4\u591a\u652f\u914d\u51fd\u6570\u7c7b\u578b\u4e0e\u56fe\u7c7b\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6781\u5c0f\u5b8c\u7f8e\u7f57\u9a6c\u652f\u914d\u51fd\u6570\u4e0e\u7f57\u9a6c\u652f\u914d\u51fd\u6570\u4e4b\u95f4\u7684\u53cc\u5c04\uff0c\u4ee5\u53ca\u6781\u5c0f\u7f57\u9a6c\u652f\u914d\u51fd\u6570\u7684\u591a\u9879\u5f0f\u5ef6\u8fdf\u679a\u4e3e\u65b9\u6cd5\uff0c\u5e76\u5c06\u8be5\u601d\u8def\u63a8\u5e7f\u5230\u6240\u8c13\u7684\u201c\u826f\u6027\u7f57\u9a6c\u652f\u914d\u6027\u8d28\u201d\uff0c\u501f\u6b64\u8bbe\u8ba1\u591a\u9879\u5f0f\u5ef6\u8fdf\u679a\u4e3e\u7b97\u6cd5\u3002\u540c\u65f6\u9488\u5bf9\u4e0d\u540c\u7c7b\u522b\u7684\u652f\u914d\u51fd\u6570\u4e0e\u56fe\u7c7b\uff08\u5982cobipartite\u56fe\u3001\u533a\u95f4\u56fe\u7b49\uff09\u5206\u6790\u548c\u8ba8\u8bba\u5b9e\u73b0\u7ec6\u8282\u3002", "result": "\u8bc1\u660e\u5e76\u5b9e\u73b0\u4e86\u6240\u6709\u6781\u5c0f\u6781\u5927\u7f57\u9a6c\u652f\u914d\u51fd\u6570\u5728O(1.9332^n)\u65f6\u95f4\u5185\u53ef\u591a\u9879\u5f0f\u5ef6\u8fdf\u679a\u4e3e\uff1b\u5728cobipartite\u56fe\u4e0a\uff0c\u6781\u5c0f\u8fde\u901a/\u5168\u4f53\u7f57\u9a6c\u652f\u914d\u51fd\u6570\u53ef\u591a\u9879\u5f0f\u5ef6\u8fdf\u679a\u4e3e\uff1b\u5728\u533a\u95f4\u56fe\u4e0a\uff0c\u6781\u5c0f\u8fde\u901a\u7f57\u9a6c\u652f\u914d\u51fd\u6570\u4e5f\u53ef\u591a\u9879\u5f0f\u5ef6\u8fdf\u679a\u4e3e\u3002\u540c\u65f6\u5206\u6790\u4e86\u8be5\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "conclusion": "\u5c3d\u7ba1\u6269\u5c55\u5b8c\u7f8e\u7f57\u9a6c\u652f\u914d\u95ee\u9898\u5224\u5b9a\u5f88\u56f0\u96be\uff0c\u4f46\u901a\u8fc7\u63a8\u5e7f\u53cc\u5c04\u4e0e\u679a\u4e3e\u65b9\u6cd5\uff0c\u53ef\u5bf9\u82e5\u5e72\u91cd\u8981\u53d8\u4f53\u5b9e\u73b0\u9ad8\u6548\u6781\u5c0f\u652f\u914d\u51fd\u6570\u7684\u679a\u4e3e\u3002\u8fd9\u4e3a\u56fe\u8bba\u4e2d\u7684\u7f57\u9a6c\u652f\u914d\u76f8\u5173\u95ee\u9898\u7684\u7b97\u6cd5\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u4e5f\u63ed\u793a\u4e86\u65b9\u6cd5\u7684\u9002\u7528\u8fb9\u754c\u3002"}}
{"id": "2511.19477", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.19477", "abs": "https://arxiv.org/abs/2511.19477", "authors": ["Aram Vardanyan"], "title": "Building Browser Agents: Architecture, Security, and Practical Solutions", "comment": "30 pages, 22 figures. Production architecture and benchmark evaluation of browser agents", "summary": "Browser agents enable autonomous web interaction but face critical reliability and security challenges in production. This paper presents findings from building and operating a production browser agent. The analysis examines where current approaches fail and what prevents safe autonomous operation. The fundamental insight: model capability does not limit agent performance; architectural decisions determine success or failure. Security analysis of real-world incidents reveals prompt injection attacks make general-purpose autonomous operation fundamentally unsafe. The paper argues against developing general browsing intelligence in favor of specialized tools with programmatic constraints, where safety boundaries are enforced through code instead of large language model (LLM) reasoning. Through hybrid context management combining accessibility tree snapshots with selective vision, comprehensive browser tooling matching human interaction capabilities, and intelligent prompt engineering, the agent achieved approximately 85% success rate on the WebGames benchmark across 53 diverse challenges (compared to approximately 50% reported for prior browser agents and 95.7% human baseline).", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u5f53\u524d\u6d4f\u89c8\u5668\u4ee3\u7406\u6700\u5927\u77ed\u677f\u662f\u67b6\u6784\u548c\u5b89\u5168\u673a\u5236\uff0c\u800c\u975e\u6a21\u578b\u672c\u8eab\u3002\u901a\u8fc7\u67b6\u6784\u521b\u65b0\u548c\u5b89\u5168\u7ea6\u675f\uff0c\u4ee3\u7406\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f5c\u8005\u5efa\u8bae\u653e\u5f03\u8ffd\u6c42\u901a\u7528\u667a\u80fd\uff0c\u8f6c\u5411\u4e13\u4e1a\u53d7\u63a7\u4ee3\u7406\u4ee5\u63d0\u5347\u5b89\u5168\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u6d4f\u89c8\u5668\u4ee3\u7406\u867d\u7136\u80fd\u591f\u5b9e\u73b0\u81ea\u4e3b\u7f51\u9875\u4ea4\u4e92\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9762\u4e34\u4e25\u5cfb\u7684\u53ef\u9760\u6027\u4e0e\u5b89\u5168\u6027\u6311\u6218\u3002\u672c\u7814\u7a76\u65e8\u5728\u5206\u6790\u8fd9\u4e9b\u6311\u6218\u5e76\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\uff0c\u5f3a\u8c03\u5b89\u5168\u8fd0\u884c\u673a\u5236\u7684\u91cd\u8981\u6027\u3002", "method": "\u7814\u7a76\u56e2\u961f\u642d\u5efa\u5e76\u8fd0\u8425\u4e86\u4e00\u4e2a\u751f\u4ea7\u7ea7\u6d4f\u89c8\u5668\u4ee3\u7406\uff0c\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u5206\u6790\u4e86\u73b0\u6709\u65b9\u6cd5\u5931\u8d25\u7684\u539f\u56e0\u53ca\u5b89\u5168\u9690\u60a3\uff0c\u7279\u522b\u662f\u9488\u5bf9\u63d0\u793a\u6ce8\u5165\uff08prompt injection\uff09\u653b\u51fb\uff0c\u8fdb\u884c\u4e86\u5b89\u5168\u4e8b\u4ef6\u5206\u6790\u3002\u540c\u65f6\uff0c\u91c7\u7528\u4e86\u6df7\u5408\u5f0f\u4e0a\u4e0b\u6587\u7ba1\u7406\u3001\u5168\u9762\u7684\u6d4f\u89c8\u5668\u5de5\u5177\u94fe\u4ee5\u53ca\u667a\u80fd\u63d0\u793a\u5de5\u7a0b\u7b49\u6280\u672f\uff0c\u4f18\u5316\u4ee3\u7406\u67b6\u6784\u3002", "result": "\u6240\u63d0\u51fa\u7684\u4ee3\u7406\u901a\u8fc7\u6df7\u5408\u4e0a\u4e0b\u6587\u7ba1\u7406\u548c\u4e13\u7528\u5de5\u5177\uff0c\u6210\u529f\u7387\u8fbe\u5230WebGames\u57fa\u51c6\u6d4b\u8bd5\u7ea685%\uff0c\u76f8\u6bd4\u6b64\u524d50%\u7684\u666e\u901a\u4ee3\u7406\u6709\u5927\u5e45\u63d0\u5347\uff0c\u867d\u7565\u4f4e\u4e8e95.7%\u7684\u4eba\u7c7b\u8868\u73b0\u3002", "conclusion": "\u4ee3\u7406\u7684\u6027\u80fd\u74f6\u9888\u4e0d\u5728\u4e8e\u6a21\u578b\u80fd\u529b\uff0c\u800c\u5728\u4e8e\u67b6\u6784\u8bbe\u8ba1\u3002\u6cdb\u5316\u7684\u81ea\u4e3b\u6d4f\u89c8\u667a\u80fd\u5b58\u5728\u56fa\u6709\u5b89\u5168\u98ce\u9669\uff0c\u5efa\u8bae\u5f00\u53d1\u5177\u6709\u9650\u5236\u6027\u7684\u4e13\u7528\u5de5\u5177\uff0c\u901a\u8fc7\u4ee3\u7801\u5c42\u9762\u800c\u975e\u5927\u6a21\u578b\u63a8\u7406\u6765\u786e\u4fdd\u5b89\u5168\u8fb9\u754c\u3002"}}
{"id": "2511.19648", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19648", "abs": "https://arxiv.org/abs/2511.19648", "authors": ["Manil Shrestha", "Edward Kim"], "title": "Efficient Multi-Hop Question Answering over Knowledge Graphs via LLM Planning and Embedding-Guided Search", "comment": null, "summary": "Multi-hop question answering over knowledge graphs remains computationally challenging due to the combinatorial explosion of possible reasoning paths. Recent approaches rely on expensive Large Language Model (LLM) inference for both entity linking and path ranking, limiting their practical deployment. Additionally, LLM-generated answers often lack verifiable grounding in structured knowledge. We present two complementary hybrid algorithms that address both efficiency and verifiability: (1) LLM-Guided Planning that uses a single LLM call to predict relation sequences executed via breadth-first search, achieving near-perfect accuracy (micro-F1 > 0.90) while ensuring all answers are grounded in the knowledge graph, and (2) Embedding-Guided Neural Search that eliminates LLM calls entirely by fusing text and graph embeddings through a lightweight 6.7M-parameter edge scorer, achieving over 100 times speedup with competitive accuracy. Through knowledge distillation, we compress planning capability into a 4B-parameter model that matches large-model performance at zero API cost. Evaluation on MetaQA demonstrates that grounded reasoning consistently outperforms ungrounded generation, with structured planning proving more transferable than direct answer generation. Our results show that verifiable multi-hop reasoning does not require massive models at inference time, but rather the right architectural inductive biases combining symbolic structure with learned representations.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u7b26\u53f7\u7ed3\u6784\u65b9\u6cd5\u548c\u6df1\u5ea6\u5b66\u4e60\uff0c\u63d0\u51fa\u4e86\u9ad8\u6548\u4e14\u53ef\u9a8c\u8bc1\u7684\u591a\u8df3\u63a8\u7406\u7b97\u6cd5\uff0c\u5927\u5e45\u63d0\u5347\u901f\u5ea6\u5e76\u964d\u4f4e\u6210\u672c\uff0c\u5b9e\u9a8c\u8bc1\u5b9e\u5c0f\u6a21\u578b\u5373\u53ef\u5b9e\u73b0\u5927\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u591a\u8df3\u95ee\u9898\u89e3\u7b54\u5728\u77e5\u8bc6\u56fe\u8c31\u4e0a\u7684\u63a8\u7406\uff0c\u56e0\u53ef\u80fd\u8def\u5f84\u6570\u91cf\u6fc0\u589e\uff0c\u5bfc\u81f4\u8ba1\u7b97\u96be\u5ea6\u5927\u3002\u76ee\u524d\u4f9d\u8d56\u5927\u6a21\u578b\u8fdb\u884c\u5b9e\u4f53\u5bf9\u9f50\u548c\u8def\u5f84\u6392\u5e8f\uff0c\u4f46\u6210\u672c\u9ad8\u3001\u6548\u7387\u4f4e\uff0c\u4e14\u7b54\u6848\u7f3a\u4e4f\u7ed3\u6784\u5316\u77e5\u8bc6\u7684\u53ef\u9a8c\u8bc1\u6027\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u6df7\u5408\u7b97\u6cd5\uff1a(1) LLM\u5f15\u5bfc\u89c4\u5212\uff0c\u5355\u6b21LLM\u9884\u6d4b\u5173\u7cfb\u5e8f\u5217\u540e\u901a\u8fc7\u5bbd\u5ea6\u4f18\u5148\u641c\u7d22\u6267\u884c\uff0c\u6240\u6709\u7b54\u6848\u5747\u6709\u77e5\u8bc6\u56fe\u8c31\u652f\u6491\uff1b(2) \u57fa\u4e8e\u5d4c\u5165\u7684\u795e\u7ecf\u641c\u7d22\uff0c\u878d\u5408\u6587\u672c\u548c\u56fe\u5d4c\u5165\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8fb9\u8bc4\u5206\u5668\u5b9e\u73b0\uff0c\u6bd4LLM\u65b9\u6cd5\u5feb\u767e\u500d\u63a5\u8fd1\u7cbe\u5ea6\u3002\u5e76\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u5c06\u89c4\u5212\u80fd\u529b\u538b\u7f29\u52304B\u53c2\u6570\u6a21\u578b\uff0c\u5b9e\u73b0\u5927\u6a21\u578b\u6c34\u5e73\uff0c\u65e0API\u6210\u672c\u3002", "result": "\u5728MetaQA\u4e0a\u9a8c\u8bc1\uff0c\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u63a8\u7406\u5168\u9762\u4f18\u4e8e\u65e0\u652f\u6491\u7684\u751f\u6210\u7c7b\u65b9\u6cd5\uff0c\u7ed3\u6784\u5316\u89c4\u5212\u6bd4\u76f4\u63a5\u751f\u6210\u66f4\u5177\u8fc1\u79fb\u6027\u3002\u63d0\u51fa\u7b97\u6cd5\u65e0\u9700\u5de8\u578b\u6a21\u578b\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u53ef\u9760\u7684\u591a\u8df3\u63a8\u7406\u3002", "conclusion": "\u5229\u7528\u7ed3\u6784\u5316\u5f52\u7eb3\u504f\u5dee\u548c\u8868\u5f81\u5b66\u4e60\uff0c\u80fd\u4ee5\u5c0f\u6a21\u578b\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u3001\u9ad8\u6548\u7684\u591a\u8df3\u77e5\u8bc6\u63a8\u7406\uff0c\u7a81\u7834\u73b0\u6709\u5927\u6a21\u578b\u63a8\u7406\u7684\u9ad8\u6210\u672c\u548c\u4f4e\u53ef\u9a8c\u8bc1\u6027\u9650\u5236\u3002"}}
{"id": "2511.20038", "categories": ["cs.FL", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.20038", "abs": "https://arxiv.org/abs/2511.20038", "authors": ["Hongjian Jiang", "Michael Hahn", "Georg Zetzsche", "Anthony Widjaja Lin"], "title": "Softmax Transformers are Turing-Complete", "comment": null, "summary": "Hard attention Chain-of-Thought (CoT) transformers are known to be Turing-complete. However, it is an open problem whether softmax attention Chain-of-Thought (CoT) transformers are Turing-complete. In this paper, we prove a stronger result that length-generalizable softmax CoT transformers are Turing-complete. More precisely, our Turing-completeness proof goes via the CoT extension of the Counting RASP (C-RASP), which correspond to softmax CoT transformers that admit length generalization. We prove Turing-completeness for CoT C-RASP with causal masking over a unary alphabet (more generally, for letter-bounded languages). While we show this is not Turing-complete for arbitrary languages, we prove that its extension with relative positional encoding is Turing-complete for arbitrary languages. We empirically validate our theory by training transformers for languages requiring complex (non-linear) arithmetic reasoning.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u4e86\u8f6f\u6ce8\u610f\u529b\u94fe\u5f0f\u601d\u7ef4transformer\u662f\u5426\u56fe\u7075\u5b8c\u5907\u7684\u516c\u5f00\u95ee\u9898\uff0c\u8bc1\u660e\u5176\u5728\u4e00\u5b9a\u6269\u5c55\u4e0b\u53ef\u5bf9\u4efb\u610f\u8bed\u8a00\u5b9e\u73b0\u56fe\u7075\u5b8c\u5907\uff0c\u7406\u8bba\u4e0e\u5b9e\u9a8c\u5747\u5f97\u5230\u9a8c\u8bc1\u3002", "motivation": "\u76ee\u524d\u5df2\u77e5\u786c\u6ce8\u610f\u529b\u7684\u94fe\u5f0f\u601d\u7ef4(CoT) transformer\u662f\u56fe\u7075\u5b8c\u5907\u7684\uff0c\u4f46\u5bf9\u4e8e\u8f6f\u6ce8\u610f\u529b\u7684CoT transformer\u662f\u5426\u4e5f\u5177\u5907\u56fe\u7075\u5b8c\u5907\u6027\u4ecd\u662f\u4e00\u4e2a\u672a\u89e3\u95ee\u9898\u3002\u63a2\u7d22\u8fd9\u4e00\u5c5e\u6027\u6709\u52a9\u4e8e\u7406\u89e3transformer\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5c06Counting RASP (C-RASP)\u6269\u5c55\u5230\u94fe\u5f0f\u601d\u7ef4(CoT)\uff0c\u5e76\u5f15\u5165\u56e0\u679c\u63a9\u7801\u548c\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u5177\u5907\u957f\u5ea6\u6cdb\u5316\u7279\u6027\u7684\u8f6fmax CoT transformer\u7684\u56fe\u7075\u5b8c\u5907\u6027\u3002\u6b64\u5916\uff0c\u5f00\u5c55\u4e86\u9488\u5bf9\u9700\u8981\u590d\u6742\u975e\u7ebf\u6027\u7b97\u672f\u63a8\u7406\u7684\u8bed\u8a00\u7684\u5b9e\u8bc1\u8bad\u7ec3\uff0c\u4ee5\u9a8c\u8bc1\u7406\u8bba\u3002", "result": "\u8bc1\u660e\u4e86\u5e26\u56e0\u679c\u63a9\u7801\u3001\u9002\u7528\u4e8e\u4e00\u5143\u5b57\u6bcd\u8868\uff08\u4ee5\u53ca\u66f4\u4e00\u822c\u7684\u5b57\u6bcd\u754c\u5b9a\u8bed\u8a00\uff09\u7684\u8f6fmax CoT transformer\u5177\u6709\u56fe\u7075\u5b8c\u5907\u6027\u3002\u5bf9\u4e8e\u4efb\u610f\u8bed\u8a00\uff0c\u539f\u59cb\u6a21\u578b\u5e76\u4e0d\u5b8c\u5907\uff0c\u4f46\u6269\u5c55\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u540e\u5219\u6210\u4e3a\u56fe\u7075\u5b8c\u5907\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u590d\u6742\u7b97\u672f\u63a8\u7406\u4efb\u52a1\u4e0b\u8be5\u7406\u8bba\u7684\u6b63\u786e\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u8bc1\u660e\u4e86\u5177\u5907\u957f\u5ea6\u6cdb\u5316\u80fd\u529b\u7684\u8f6fmax\u6ce8\u610f\u529bCoT transformer\u5728\u5f15\u5165\u56e0\u679c\u63a9\u7801\u53ca\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\u540e\u5bf9\u4efb\u610f\u8bed\u8a00\u662f\u56fe\u7075\u5b8c\u5907\u7684\uff0c\u63a8\u8fdb\u4e86\u5bf9transformer\u8868\u8fbe\u80fd\u529b\u7684\u7406\u8bba\u8ba4\u77e5\uff0c\u5e76\u5f97\u5230\u5b9e\u8bc1\u652f\u6301\u3002"}}
{"id": "2511.20540", "categories": ["cs.LO", "cs.AI", "cs.GT", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.20540", "abs": "https://arxiv.org/abs/2511.20540", "authors": ["Adam Bjorndahl"], "title": "Proceedings Twentieth Conference on Theoretical Aspects of Rationality and Knowledge", "comment": null, "summary": "The TARK conference (Theoretical Aspects of Rationality and Knowledge) is a conference that aims to bring together researchers from a wide variety of fields, including computer science, artificial intelligence, game theory, decision theory, philosophy, logic, linguistics, and cognitive science. Its goal is to further our understanding of interdisciplinary issues involving reasoning about rationality and knowledge.\n  Previous conferences have been held biennially around the world since 1986, on the initiative of Joe Halpern (Cornell University). Topics of interest include, but are not limited to, semantic models for knowledge, belief, uncertainty, awareness, bounded rationality, common sense epistemic reasoning, epistemic logic, epistemic game theory, knowledge and action, applications of reasoning about knowledge and other mental states, belief revision, computational social choice, algorithmic game theory, and foundations of multi-agent systems.\n  Information about TARK is available at http://www.tark.org/.\n  These proceedings contain the papers that have been accepted for presentation at the Twentieth Conference on Theoretical Aspects of Rationality and Knowledge (TARK 2025), held July 14--16, 2025, at Heinrich-Heine-Universit\u00e4t, D\u00fcsseldorf, Germany. The conference website can be found at https://ccc.cs.uni-duesseldorf.de/tark-2025/.", "AI": {"tldr": "TARK\u662f\u4e00\u9879\u5173\u6ce8\u7406\u6027\u4e0e\u77e5\u8bc6\u7406\u8bba\u8de8\u5b66\u79d1\u7814\u7a76\u7684\u56fd\u9645\u4f1a\u8bae\uff0c\u5df2\u4e3e\u529e\u81f3\u7b2c20\u5c4a\uff0c\u6c47\u805a\u5168\u7403\u76f8\u5173\u9886\u57df\u5b66\u8005\uff0c\u4fc3\u8fdb\u5b66\u672f\u4ea4\u6d41\u4e0e\u7814\u7a76\u8fdb\u5c55\u3002", "motivation": "TARK\u4f1a\u8bae\u65e8\u5728\u6c47\u96c6\u6765\u81ea\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u4eba\u5de5\u667a\u80fd\u3001\u535a\u5f08\u8bba\u3001\u51b3\u7b56\u7406\u8bba\u3001\u54f2\u5b66\u3001\u903b\u8f91\u5b66\u3001\u8bed\u8a00\u5b66\u4e0e\u8ba4\u77e5\u79d1\u5b66\u7b49\u591a\u4e2a\u9886\u57df\u7684\u7814\u7a76\u8005\uff0c\u5171\u540c\u63a2\u8ba8\u7406\u6027\u4e0e\u77e5\u8bc6\u76f8\u5173\u7684\u8de8\u5b66\u79d1\u8bae\u9898\u3002", "method": "\u4f1a\u8bae\u901a\u8fc7\u5f81\u96c6\u5e76\u9074\u9009\u76f8\u5173\u9886\u57df\u8bba\u6587\u3001\u7ec4\u7ec7\u5b66\u672f\u62a5\u544a\u548c\u4ea4\u6d41\u8ba8\u8bba\uff0c\u5b9e\u73b0\u5b66\u79d1\u95f4\u7684\u6df1\u5165\u5408\u4f5c\u548c\u524d\u6cbf\u7814\u7a76\u5c55\u793a\u3002", "result": "\u672c\u5c4a\uff08\u7b2c20\u5c4a\uff09TARK\u4f1a\u8bae\u5df2\u6210\u529f\u5f81\u96c6\u5e76\u5f55\u7528\u4e86\u76f8\u5173\u4e3b\u9898\u7684\u8bba\u6587\uff0c\u5e76\u5c06\u4e8e2025\u5e747\u6708\u5728\u5fb7\u56fd\u675c\u585e\u5c14\u591a\u592b\u4e3e\u529e\u3002\u8bba\u6587\u96c6\u6536\u5f55\u4e86\u6240\u6709\u88ab\u63a5\u53d7\u7684\u7814\u7a76\u8bba\u6587\u3002", "conclusion": "TARK\u4f1a\u8bae\u5728\u63a8\u52a8\u5173\u4e8e\u7406\u6027\u4e0e\u77e5\u8bc6\u7406\u8bba\u65b9\u9762\u7684\u591a\u5b66\u79d1\u56fd\u9645\u4ea4\u6d41\u4e0e\u5408\u4f5c\u4e2d\u626e\u6f14\u7740\u91cd\u8981\u89d2\u8272\u3002"}}
{"id": "2511.20617", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.20617", "abs": "https://arxiv.org/abs/2511.20617", "authors": ["Saman Dehghan", "Tianran Sun", "Tianxiang Wu", "Zihan Li", "Reyhaneh Jabbarvand"], "title": "Translating Large-Scale C Repositories to Idiomatic Rust", "comment": "21 pages, 14 figures", "summary": "Existing C to Rust translation techniques fail to balance quality and scalability: transpilation-based approaches scale to large projects but produce code with poor safety, idiomaticity, and readability. In contrast, LLM-based techniques are prohibitively expensive due to their reliance on frontier models (without which they cannot reliably generate compilable translations), thus limiting scalability. This paper proposes Rustine, a fully automated pipeline for effective and efficient repository-level C to idiomatic safe Rust translation. Evaluating on a diverse set of 23 C programs, ranging from 27 to 13,200 lines of code, Rustine can generate fully compilable Rust code for all and achieve 87% functional equivalence (passing 1,063,099 assertions out of 1,221,192 in test suites with average function and line coverage of 74.7% and 72.2%). Compared to six prior repository-level C to Rust translation techniques, the translations by Rustine are overall safer (fewer raw pointers, pointer arithmetic, and unsafe constructs), more idiomatic (fewer Rust linter violations), and more readable. When the translations cannot pass all tests to fulfill functional equivalence, human developers were able to complete the task in 4.5 hours, on average, using Rustine as debugging support.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRustine\u7684\u65b0\u5de5\u5177\uff0c\u9ad8\u6548\u5b9e\u73b0\u4e86C\u5230\u5b89\u5168\u3001\u89c4\u8303\u7684Rust\u4ee3\u7801\u81ea\u52a8\u8fc1\u79fb\uff0c\u7efc\u5408\u5728\u4ee3\u7801\u5b89\u5168\u6027\u3001\u53ef\u8bfb\u6027\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684C\u8f6cRust\u7684\u7ffb\u8bd1\u6280\u672f\u5728\u4ee3\u7801\u8d28\u91cf\u548c\u53ef\u6269\u5c55\u6027\u4e4b\u95f4\u96be\u4ee5\u517c\u987e\u3002\u57fa\u4e8e\u8f6c\u8bd1\u7684\u529e\u6cd5\u9002\u7528\u4e8e\u5927\u578b\u9879\u76ee\uff0c\u4f46\u4ee3\u7801\u5b89\u5168\u6027\u3001\u7b26\u5408Rust\u4e60\u60ef\u548c\u53ef\u8bfb\u6027\u5dee\uff1b\u800c\u57fa\u4e8e\u5927\u6a21\u578b\uff08LLM\uff09\u7684\u65b9\u6cd5\u5219\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u5927\uff0c\u96be\u4ee5\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "\u63d0\u51faRustine\uff0c\u4e00\u4e2a\u5168\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u6709\u6548\u7684C\u5230\u7b26\u5408Rust\u4e60\u60ef\u4e14\u5b89\u5168\u7684Rust\u4ee3\u7801\u4ed3\u5e93\u7ea7\u7ffb\u8bd1\uff0c\u5e76\u572823\u4e2a\u4e0d\u540cC\u7a0b\u5e8f\u4e0a\u8fdb\u884c\u8bc4\u6d4b\u3002", "result": "Rustine\u5bf9\u6240\u6709\u6d4b\u8bd5\u9879\u76ee\u90fd\u80fd\u751f\u6210\u53ef\u7f16\u8bd1\u7684Rust\u4ee3\u7801\uff0c\u5e76\u57281,221,192\u4e2a\u65ad\u8a00\u6d4b\u8bd5\u4e2d\u901a\u8fc7\u4e861,063,099\u4e2a\uff0887%\u529f\u80fd\u7b49\u4ef7\uff09\uff0c\u5e73\u5747\u51fd\u6570\u548c\u884c\u8986\u76d6\u7387\u5206\u522b\u4e3a74.7%\u4e0e72.2%\u3002\u4e0e\u516d\u79cd\u5df2\u6709\u6280\u672f\u5bf9\u6bd4\uff0cRustine\u751f\u6210\u7684\u4ee3\u7801\u66f4\u5b89\u5168\u3001\u66f4\u7b26\u5408Rust\u89c4\u8303\u3001\u66f4\u6613\u8bfb\u3002\u5bf9\u4e8e\u672a\u901a\u8fc7\u6240\u6709\u6d4b\u8bd5\u7684\u60c5\u51b5\uff0c\u5f00\u53d1\u8005\u5e73\u5747\u4ec5\u97004.5\u5c0f\u65f6\u901a\u8fc7Rustine\u8f85\u52a9\u5c31\u80fd\u5b8c\u6210\u8c03\u8bd5\u3002", "conclusion": "Rustine\u5f25\u8865\u4e86\u73b0\u6709C\u5230Rust\u7ffb\u8bd1\u6280\u672f\u5728\u8d28\u91cf\u548c\u53ef\u6269\u5c55\u6027\u4e4b\u95f4\u7684\u4e0d\u8db3\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u3001\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u4ee3\u7801\u8fc1\u79fb\u3002"}}
{"id": "2511.20368", "categories": ["cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2511.20368", "abs": "https://arxiv.org/abs/2511.20368", "authors": ["Daniel Gon\u00e7alves"], "title": "3-colorable planar graphs have an intersection segment representation using 3 slopes", "comment": "23 pages, 17 figures", "summary": "In his PhD Thesis, E.R. Scheinerman conjectured that planar graphs are intersection graphs of line segments in the plane. This conjecture was proved with two different approaches by J. Chalopin and the author, and by the author, L. Isenmann, and C. Pennarun. In the case of 3-colorable planar graphs E.R. Scheinerman conjectured that it is possible to restrict the set of slopes used by the segments to only 3 slopes. Here we prove this conjecture by using an approach introduced by S. Felsner to deal with contact representations of planar graphs with homothetic triangles.", "AI": {"tldr": "\u4f5c\u8005\u901a\u8fc7\u501f\u7528\u4e0e\u540c\u80da\u4e09\u89d2\u5f62\u76f8\u5173\u7684\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u4efb\u610f3-\u53ef\u7740\u8272\u7684\u5e73\u9762\u56fe\u90fd\u53ef\u4ee5\u88ab\u8868\u793a\u4e3a\u53ea\u4f7f\u7528\u4e09\u79cd\u659c\u7387\u7ebf\u6bb5\u7684\u4ea4\u96c6\u56fe\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86Scheinerman\u7684\u731c\u60f3\u3002", "motivation": "\u6b64\u524d\u5df2\u7ecf\u8bc1\u660e\u4e86\u6240\u6709\u5e73\u9762\u56fe\u662f\u7ebf\u6bb5\u4ea4\u96c6\u56fe\uff1b\u8be5\u6587\u5173\u6ce8\u4e8e\u5c06\u8fd9\u79cd\u4ea4\u96c6\u9650\u5236\u5728\u4ec5\u4e09\u79cd\u659c\u7387\uff0c\u56de\u5e943-\u53ef\u7740\u8272\u5e73\u9762\u56fe\u76f8\u5173\u7684\u731c\u60f3\u3002", "method": "\u4f5c\u8005\u91c7\u7528\u4e86S. Felsner\u63d0\u51fa\u7684\u7528\u4e8e\u5904\u7406\u4e0e\u540c\u80da\u4e09\u89d2\u5f62\u63a5\u89e6\u8868\u793a\u76f8\u5173\u7684\u5e73\u9762\u56fe\u7684\u65b9\u6cd5\u3002", "result": "\u8bc1\u660e\u4e863-\u53ef\u7740\u8272\u5e73\u9762\u56fe\u662f\u4ec5\u7528\u4e09\u79cd\u659c\u7387\u7ebf\u6bb5\u7684\u4ea4\u96c6\u56fe\u3002", "conclusion": "\u4f5c\u8005\u8bc1\u660e\u4e863-\u53ef\u7740\u8272\u5e73\u9762\u56fe\u53ef\u4ee5\u53ea\u7528\u4e09\u79cd\u659c\u7387\u7684\u7ebf\u6bb5\u4f5c\u4e3a\u4ea4\u96c6\u56fe\uff0c\u4ece\u800c\u8bc1\u5b9e\u4e86E.R. Scheinerman\u7684\u731c\u60f3\u3002"}}
{"id": "2511.19483", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19483", "abs": "https://arxiv.org/abs/2511.19483", "authors": ["Qingsong He", "Jing Nan", "Jiayu Jiao", "Liangjie Tang", "Xiaodong Xu", "Mengmeng Sun", "Qingyao Wang", "Minghui Yan"], "title": "Z-Space: A Multi-Agent Tool Orchestration Framework for Enterprise-Grade LLM Automation", "comment": null, "summary": "Large Language Models can break through knowledge and timeliness limitations by invoking external tools within the Model Context Protocol framework to achieve automated execution of complex tasks. However, with the rapid growth of enterprise-scale MCP services, efficiently and accurately matching target functionalities among thousands of heterogeneous tools has become a core challenge restricting system practicality. Existing approaches generally rely on full-prompt injection or static semantic retrieval, facing issues including semantic disconnection between user queries and tool descriptions, context inflation in LLM input, and high inference latency. To address these challenges, this paper proposes Z-Space, a data-generation-oriented multi-agent collaborative tool invocation framework Z-Space. The Z-Space framework establishes a multi-agent collaborative architecture and tool filtering algorithm: (1) A structured semantic understanding of user queries is achieved through an intent parsing model; (2) A tool filtering module (FSWW) based on fused subspace weighted algorithm realizes fine-grained semantic alignment between intents and tools without parameter tuning; (3) An inference execution agent is constructed to support dynamic planning and fault-tolerant execution for multi-step tasks. This framework has been deployed in the Eleme platform's technical division, serving large-scale test data generation scenarios across multiple business units including Taotian, Gaode, and Hema. Production data demonstrates that the system reduces average token consumption in tool inference by 96.26\\% while achieving a 92\\% tool invocation accuracy rate, significantly enhancing the efficiency and reliability of intelligent test data generation systems.", "AI": {"tldr": "Z-Space\u6846\u67b6\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u7cbe\u7ec6\u8bed\u4e49\u5339\u914d\uff0c\u5b9e\u73b0\u4e86\u4f01\u4e1a\u7ea7\u590d\u6742\u4efb\u52a1\u7684\u9ad8\u6548\u81ea\u52a8\u5316\u5de5\u5177\u8c03\u7528\uff0c\u663e\u8457\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u5e76\u63d0\u5347\u51c6\u786e\u7387\uff0c\u5df2\u5728\u591a\u4e2a\u771f\u5b9e\u4e1a\u52a1\u573a\u666f\u5f97\u5230\u9a8c\u8bc1\u3002", "motivation": "\u968f\u7740\u4f01\u4e1a\u7ea7MCP\u670d\u52a1\u89c4\u6a21\u5feb\u901f\u6269\u5c55\uff0c\u5982\u4f55\u5728\u4f17\u591a\u5f02\u6784\u5de5\u5177\u4e2d\u9ad8\u6548\u3001\u51c6\u786e\u5730\u5339\u914d\u76ee\u6807\u529f\u80fd\u6210\u4e3a\u5236\u7ea6\u7cfb\u7edf\u5b9e\u9645\u5e94\u7528\u7684\u5173\u952e\u96be\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u8bed\u4e49\u8131\u8282\u3001\u4e0a\u4e0b\u6587\u8f93\u5165\u81a8\u80c0\u53ca\u63a8\u7406\u5ef6\u8fdf\u9ad8\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u6570\u636e\u751f\u6210\u5bfc\u5411\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5de5\u5177\u8c03\u7528\u6846\u67b6Z-Space\uff0c\u5305\u62ec\u610f\u56fe\u89e3\u6790\u6a21\u578b\u3001\u878d\u5408\u5b50\u7a7a\u95f4\u52a0\u6743\u7b97\u6cd5(FSWW)\u7684\u5de5\u5177\u8fc7\u6ee4\u6a21\u5757\uff0c\u4ee5\u53ca\u52a8\u6001\u89c4\u5212\u548c\u5bb9\u9519\u6267\u884c\u7684\u63a8\u7406\u4ee3\u7406\u3002\u7cfb\u7edf\u5df2\u5728\u997f\u4e86\u4e48\u5e73\u53f0\u6295\u5165\u4f7f\u7528\u3002", "result": "\u7cfb\u7edf\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u5c06\u5de5\u5177\u63a8\u7406\u7684\u5e73\u5747token\u6d88\u8017\u964d\u4f4e\u4e8696.26%\uff0c\u5de5\u5177\u8c03\u7528\u51c6\u786e\u7387\u8fbe\u523092%\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u667a\u80fd\u6d4b\u8bd5\u6570\u636e\u751f\u6210\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\u3002", "conclusion": "Z-Space\u6846\u67b6\u80fd\u591f\u9ad8\u6548\u3001\u53ef\u9760\u5730\u5b9e\u73b0\u5927\u89c4\u6a21\u5de5\u5177\u8c03\u7528\uff0c\u663e\u8457\u63d0\u5347\u667a\u80fd\u6d4b\u8bd5\u6570\u636e\u751f\u6210\u7cfb\u7edf\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2511.19719", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19719", "abs": "https://arxiv.org/abs/2511.19719", "authors": ["Mobina Mehrazar", "Mohammad Amin Yousefi", "Parisa Abolfath Beygi", "Behnam Bahrak"], "title": "Can LLMs Faithfully Explain Themselves in Low-Resource Languages? A Case Study on Emotion Detection in Persian", "comment": null, "summary": "Large language models (LLMs) are increasingly used to generate self-explanations alongside their predictions, a practice that raises concerns about the faithfulness of these explanations, especially in low-resource languages. This study evaluates the faithfulness of LLM-generated explanations in the context of emotion classification in Persian, a low-resource language, by comparing the influential words identified by the model against those identified by human annotators. We assess faithfulness using confidence scores derived from token-level log-probabilities. Two prompting strategies, differing in the order of explanation and prediction (Predict-then-Explain and Explain-then-Predict), are tested for their impact on explanation faithfulness. Our results reveal that while LLMs achieve strong classification performance, their generated explanations often diverge from faithful reasoning, showing greater agreement with each other than with human judgments. These results highlight the limitations of current explanation methods and metrics, emphasizing the need for more robust approaches to ensure LLM reliability in multilingual and low-resource contexts.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u6ce2\u65af\u8bed\u60c5\u611f\u5206\u7c7b\uff0c\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u81ea\u6211\u89e3\u91ca\u4e0e\u4eba\u7c7b\u6807\u6ce8\u7ed3\u679c\u7684\u5dee\u5f02\uff0c\u53d1\u73b0\u6a21\u578b\u89e3\u91ca\u4fe1\u5ea6\u8f83\u4f4e\uff0c\u65b9\u6cd5\u4e0e\u8bc4\u4ef7\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u9002\u5e94\u591a\u8bed\u8a00\u548c\u4f4e\u8d44\u6e90\u573a\u666f\u3002", "motivation": "\u9762\u5bf9LLM\u9010\u6b65\u5e94\u7528\u4e8e\u751f\u6210\u9884\u6d4b\u89e3\u91ca\u7684\u8d8b\u52bf\uff0c\u5c24\u5176\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u73af\u5883\u4e0b\uff0c\u5bf9\u8fd9\u4e9b\u89e3\u91ca\u7684\u53ef\u4fe1\u5ea6\u548c\u53ef\u9760\u6027\u63d0\u51fa\u6000\u7591\uff0c\u4e9f\u9700\u7cfb\u7edf\u6027\u8bc4\u4f30\u5176\u4e0e\u4eba\u7c7b\u4e00\u81f4\u6027\u3002", "method": "\u901a\u8fc7\u60c5\u611f\u5206\u7c7b\u4efb\u52a1\uff0c\u6bd4\u8f83LLM\u8bc6\u522b\u7684\u91cd\u8981\u5355\u8bcd\u4e0e\u4eba\u7c7b\u6807\u6ce8\u8005\u7684\u7ed3\u679c\uff0c\u91c7\u7528\u57fa\u4e8etoken\u7ea7\u522blog\u6982\u7387\u7684\u7f6e\u4fe1\u5ea6\u5206\u6570\u8861\u91cf\u89e3\u91ca\u7684\u53ef\u4fe1\u5ea6\uff0c\u5e76\u6d4b\u8bd5\u4e24\u79cd\u4e0d\u540c\u7684\u63d0\u793a\u987a\u5e8f\uff08\u5148\u9884\u6d4b\u540e\u89e3\u91ca\u4e0e\u5148\u89e3\u91ca\u540e\u9884\u6d4b\uff09\u5bf9\u4fe1\u5ea6\u7684\u5f71\u54cd\u3002", "result": "LLM\u5728\u60c5\u611f\u5206\u7c7b\u8868\u73b0\u5f3a\u52b2\uff0c\u4f46\u89e3\u91ca\u7684\u4fe1\u5ea6\u8f83\u4f4e\uff0c\u5176\u89e3\u91ca\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u9ad8\u4e8e\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u4e00\u81f4\u6027\uff0c\u6307\u5411\u89e3\u91ca\u65b9\u6cd5\u4e0e\u8bc4\u4f30\u6807\u51c6\u7684\u4e0d\u8db3\u3002", "conclusion": "\u5f53\u524dLLM\u751f\u6210\u7684\u89e3\u91ca\u5728\u4fe1\u5ea6\u4e0a\u5b58\u5728\u663e\u8457\u7f3a\u9677\uff0c\u5c24\u5176\u662f\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u73af\u5883\u4e2d\u96be\u4ee5\u4e0e\u4eba\u7c7b\u5224\u65ad\u4fdd\u6301\u9ad8\u5ea6\u4e00\u81f4\u3002\u73b0\u6709\u7684\u89e3\u91ca\u65b9\u6cd5\u548c\u8bc4\u4ef7\u6307\u6807\u6709\u5f85\u6539\u8fdb\uff0c\u4ee5\u63d0\u5347\u591a\u8bed\u8a00\u53ca\u4f4e\u8d44\u6e90\u8bed\u5883\u4e0b\u7684\u6a21\u578b\u53ef\u9760\u6027\u3002"}}
{"id": "2511.20550", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2511.20550", "abs": "https://arxiv.org/abs/2511.20550", "authors": ["Dustin Bryant", "Jonathan Julian Huerta y Munive", "Simon Foster"], "title": "Verifying Numerical Methods with Isabelle/HOL", "comment": "30 pages, 30 listings, for accompanying formalisation, see https://zenodo.org/records/17679526", "summary": "Modern machine learning pipelines are built on numerical algorithms. Reliable numerical methods are thus a prerequisite for trustworthy machine learning and cyber-physical systems. Therefore, we contribute a framework for verified numerical methods in Isabelle/HOL based on ITrees. Our user-friendly specification language enables the direct declaration of numerical programs that can be annotated with variants and invariants for reasoning about correctness specifications. The generated verification conditions can be discharged via automated proof methods and lemmas from the HOL-Analysis library. The ITrees foundation interacts with Isabelle's code generator to export source code. This provides an end-to-end path from formal specifications with machine-checked guarantees to executable sources. We illustrate the process of modelling numerical methods and demonstrate the effectiveness of the verification by focusing on two well-known methods, the bisection method and the fixed-point iteration method. We also contribute crucial extensions to the libraries of formalised mathematics required for this objective: higher-order derivatives and Taylor's theorem in Peano form. Finally, we qualitatively evaluate the use of the framework for verifying numerical methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5728Isabelle/HOL\u4e2d\u5b9e\u73b0\u7684\u6570\u503c\u65b9\u6cd5\u9a8c\u8bc1\u6846\u67b6\uff0c\u80fd\u591f\u4ece\u5f62\u5f0f\u89c4\u8303\u81ea\u52a8\u751f\u6210\u53ef\u9a8c\u8bc1\u7684\u4e14\u53ef\u6267\u884c\u7684\u6570\u503c\u7b97\u6cd5\u3002\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5e76\u6269\u5c55\u4e86\u76f8\u5173\u6570\u5b66\u5e93\u3002", "motivation": "\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u548c\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\u4f9d\u8d56\u4e8e\u6570\u503c\u7b97\u6cd5\uff0c\u56e0\u6b64\uff0c\u53ef\u9760\u7684\u6570\u503c\u65b9\u6cd5\u5bf9\u4e8e\u6784\u5efa\u53ef\u4fe1\u8d56\u7684\u7cfb\u7edf\u975e\u5e38\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u5957\u57fa\u4e8eITrees\u7684\u3001\u5728Isabelle/HOL\u4e2d\u5b9e\u73b0\u7684\u6570\u503c\u65b9\u6cd5\u9a8c\u8bc1\u6846\u67b6\u3002\u8be5\u6846\u67b6\u91c7\u7528\u53cb\u597d\u7684\u89c4\u8303\u8bed\u8a00\uff0c\u652f\u6301\u6570\u503c\u7a0b\u5e8f\u7684\u76f4\u63a5\u58f0\u660e\uff0c\u5e76\u53ef\u6dfb\u52a0\u53d8\u4f53\u548c\u4e0d\u53d8\u6027\u7528\u4e8e\u6b63\u786e\u6027\u8bc1\u660e\u3002\u81ea\u52a8\u5316\u8bc1\u660e\u5de5\u5177\u4e0eHOL-Analysis\u5e93\u8054\u52a8\uff0c\u5b9e\u73b0\u89c4\u8303\u5224\u636e\u7684\u81ea\u52a8\u9a8c\u8bc1\u3002\u540c\u65f6\u4e0eIsabelle\u7684\u4ee3\u7801\u751f\u6210\u5668\u96c6\u6210\uff0c\u5b9e\u73b0\u4ece\u5f62\u5f0f\u5316\u89c4\u8303\u5230\u53ef\u6267\u884c\u4ee3\u7801\u7684\u7aef\u5230\u7aef\u6d41\u7a0b\u3002", "result": "\u6210\u529f\u5c06\u9a8c\u8bc1\u6d41\u7a0b\u5e94\u7528\u4e8e\u4e24\u79cd\u8457\u540d\u6570\u503c\u65b9\u6cd5\uff1a\u4e8c\u5206\u6cd5\u548c\u4e0d\u52a8\u70b9\u8fed\u4ee3\u6cd5\uff0c\u5e76\u6269\u5c55\u4e86\u5f62\u5f0f\u5316\u6570\u5b66\u5e93\uff0c\u5305\u62ec\u9ad8\u9636\u5bfc\u6570\u548c\u76ae\u4e9a\u8bfa\u5f62\u5f0f\u7684\u6cf0\u52d2\u5b9a\u7406\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u6709\u6548\u5b9e\u73b0\u6570\u503c\u65b9\u6cd5\u7684\u673a\u5668\u68c0\u9a8c\u8bc1\u660e\u5230\u53ef\u6267\u884c\u4ee3\u7801\u7684\u8f6c\u6362\uff0c\u5bf9\u6570\u503c\u65b9\u6cd5\u7684\u9a8c\u8bc1\u5177\u6709\u8f83\u5f3a\u5b9e\u7528\u6027\u3002"}}
{"id": "2511.19484", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19484", "abs": "https://arxiv.org/abs/2511.19484", "authors": ["Randall Balestriero", "Hugues Van Assel", "Sami BuGhanem", "Lucas Maes"], "title": "stable-pretraining-v1: Foundation Model Research Made Simple", "comment": null, "summary": "Foundation models and self-supervised learning (SSL) have become central to modern AI, yet research in this area remains hindered by complex codebases, redundant re-implementations, and the heavy engineering burden of scaling experiments. We present stable-pretraining, a modular, extensible, and performance-optimized library built on top of PyTorch, Lightning, Hugging Face, and TorchMetrics. Unlike prior toolkits focused narrowly on reproducing state-of-the-art results, stable-pretraining is designed for flexibility and iteration speed: it unifies essential SSL utilities--including probes, collapse detection metrics, augmentation pipelines, and extensible evaluation routines--within a coherent and reliable framework. A central design principle is logging everything, enabling fine-grained visibility into training dynamics that makes debugging, monitoring, and reproducibility seamless. We validate the library by demonstrating its ability to generate new research insights with minimal overhead, including depthwise representation probing and the analysis of CLIP degradation under synthetic data finetuning. By lowering barriers to entry while remaining scalable to large experiments, stable-pretraining aims to accelerate discovery and expand the possibilities of foundation model research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86stable-pretraining\u5e93\uff0c\u5728\u4fdd\u6709\u9ad8\u6269\u5c55\u6027\u548c\u6027\u80fd\u4f18\u5316\u7684\u540c\u65f6\uff0c\u6574\u5408\u4e86\u81ea\u76d1\u7763\u5b66\u4e60\u76f8\u5173\u6838\u5fc3\u529f\u80fd\uff0c\u663e\u8457\u7b80\u5316\u4e86\u57fa\u7840\u6a21\u578b\u4e0eSSL\u7814\u7a76\u7684\u6280\u672f\u95e8\u69db\u548c\u5de5\u7a0b\u8d1f\u62c5\u3002", "motivation": "\u57fa\u91d1\u4f1a\u6a21\u578b\u548c\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u662f\u73b0\u4ee3\u4eba\u5de5\u667a\u80fd\u7684\u6838\u5fc3\uff0c\u4f46\u76f8\u5173\u7814\u7a76\u53d7\u9650\u4e8e\u7e41\u7410\u7684\u4ee3\u7801\u5e93\u3001\u91cd\u590d\u5b9e\u73b0\u548c\u5b9e\u9a8c\u6269\u5c55\u7684\u5de5\u7a0b\u8d1f\u62c5\u3002", "method": "\u63d0\u51fastable-pretraining\uff0c\u662f\u4e00\u4e2a\u517c\u5bb9PyTorch\u3001Lightning\u3001Hugging Face\u548cTorchMetrics\u7684\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u3001\u9ad8\u6027\u80fd\u7684\u5e93\u3002\u5b83\u6574\u5408\u4e86SSL\u5e38\u7528\u5de5\u5177\uff08\u5982\u63a2\u9488\u3001\u574d\u584c\u68c0\u6d4b\u3001\u6570\u636e\u589e\u5f3a\u548c\u53ef\u6269\u5c55\u8bc4\u6d4b\uff09\u4e8e\u7edf\u4e00\u6846\u67b6\uff0c\u5e76\u6ce8\u91cd\u8be6\u7ec6\u65e5\u5fd7\u8bb0\u5f55\u4ee5\u63d0\u5347\u53ef\u8c03\u8bd5\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002", "result": "stable-pretraining\u5e93\u53ef\u4ee5\u4ee5\u6781\u5c0f\u7684\u5de5\u7a0b\u5f00\u9500\uff0c\u652f\u6301\u65b0\u9896\u7684\u7814\u7a76\u63a2\u7d22\uff0c\u5982\u6df1\u5ea6\u8868\u5f81\u63a2\u6d4b\u548cCLIP\u5728\u5408\u6210\u6570\u636e\u5fae\u8c03\u65f6\u7684\u9000\u5316\u5206\u6790\uff0c\u4e14\u53ef\u6269\u5c55\u81f3\u5927\u89c4\u6a21\u5b9e\u9a8c\u3002", "conclusion": "stable-pretraining\u964d\u4f4e\u4e86\u57fa\u7840\u6a21\u578b\u548cSSL\u7814\u7a76\u7684\u95e8\u69db\uff0c\u63d0\u5347\u5b9e\u9a8c\u8fed\u4ee3\u901f\u5ea6\u548c\u53ef\u6269\u5c55\u6027\uff0c\u6709\u671b\u52a0\u5feb\u9886\u57df\u53d1\u5c55\u548c\u521b\u65b0\u3002"}}
{"id": "2511.19739", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19739", "abs": "https://arxiv.org/abs/2511.19739", "authors": ["Richard J. Young", "Alice M. Matthews"], "title": "Comparative Analysis of LoRA-Adapted Embedding Models for Clinical Cardiology Text Representation", "comment": "25 pages, 13 figures, 5 tables", "summary": "Domain-specific text embeddings are critical for clinical natural language processing, yet systematic comparisons across model architectures remain limited. This study evaluates ten transformer-based embedding models adapted for cardiology through Low-Rank Adaptation (LoRA) fine-tuning on 106,535 cardiology text pairs derived from authoritative medical textbooks. Results demonstrate that encoder-only architectures, particularly BioLinkBERT, achieve superior domain-specific performance (separation score: 0.510) compared to larger decoder-based models, while requiring significantly fewer computational resources. The findings challenge the assumption that larger language models necessarily produce better domain-specific embeddings and provide practical guidance for clinical NLP system development. All models, training code, and evaluation datasets are publicly available to support reproducible research in medical informatics.", "AI": {"tldr": "\u76f8\u8f83\u4e8e\u4f53\u79ef\u66f4\u5927\u7684\u89e3\u7801\u5668\u67b6\u6784\uff0c\u7f16\u7801\u5668\u578bTransformer\uff08\u5982BioLinkBERT\uff09\u901a\u8fc7LoRA\u5fae\u8c03\uff0c\u5728\u5fc3\u810f\u75c5\u6587\u672c\u5d4c\u5165\u4efb\u52a1\u4e0a\u6027\u80fd\u66f4\u4f73\u4e14\u8d44\u6e90\u6d88\u8017\u66f4\u4f4e\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u533b\u7597\u4fe1\u606f\u5b66\u9886\u57dfNLP\u7cfb\u7edf\u7684\u5f00\u53d1\u6548\u7387\u4e0e\u6548\u679c\u3002", "motivation": "\u5728\u4e34\u5e8a\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u9886\u57df\uff0c\u7279\u5b9a\u9886\u57df\u7684\u6587\u672c\u5d4c\u5165\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5bf9\u4e8e\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u7684\u7cfb\u7edf\u8bc4\u6d4b\u5c1a\u7f3a\u5931\u3002", "method": "\u5bf9\u5341\u79cd\u7ecfLoRA\u5fae\u8c03\u7684\u3001\u9002\u5e94\u5fc3\u810f\u75c5\u5b66\u9886\u57df\u7684Transformer\u6587\u672c\u5d4c\u5165\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u4f7f\u7528\u6765\u6e90\u4e8e\u6743\u5a01\u533b\u5b66\u6559\u79d1\u4e66\u7684106,535\u7ec4\u5fc3\u810f\u75c5\u5b66\u6587\u672c\u5bf9\u3002", "result": "\u7f16\u7801\u5668\u67b6\u6784\uff08\u5c24\u5176\u662fBioLinkBERT\uff09\u5728\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u8d8a\uff08\u5206\u79bb\u5206\u65700.510\uff09\uff0c\u4e14\u6240\u9700\u8ba1\u7b97\u8d44\u6e90\u8fdc\u4f4e\u4e8e\u66f4\u5927\u7684\u89e3\u7801\u5668\u6a21\u578b\u3002", "conclusion": "\u6311\u6218\u4e86\u201c\u5927\u6a21\u578b\u5fc5\u4f18\u201d\u7684\u666e\u904d\u5047\u8bbe\uff0c\u4e3a\u4e34\u5e8aNLP\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u4e86\u5b9e\u9645\u6307\u5bfc\uff0c\u76f8\u5173\u6a21\u578b\u548c\u6570\u636e\u5df2\u5f00\u6e90\u4fc3\u8fdb\u91cd\u590d\u6027\u7814\u7a76\u3002"}}
{"id": "2511.19489", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19489", "abs": "https://arxiv.org/abs/2511.19489", "authors": ["Zhe Zhao", "Yuheng Yang", "Haibin Wen", "Xiaojie Qiu", "Zaixi Zhang", "Qingfu Zhang"], "title": "Evolution without an Oracle: Driving Effective Evolution with LLM Judges", "comment": "14 pages, 5 figures", "summary": "The integration of Large Language Models (LLMs) with Evolutionary Computation (EC) has unlocked new frontiers in scientific discovery but remains shackled by a fundamental constraint: the reliance on an Oracle--an objective, machine-computable fitness function. This paper breaks this barrier by asking: Can evolution thrive in a purely subjective landscape governed solely by LLM judges? We introduce MADE (Multi-Agent Decomposed Evolution), a framework that tames the inherent noise of subjective evaluation through \"Problem Specification.\" By decomposing vague instructions into specific, verifiable sub-requirements, MADE transforms high-variance LLM feedback into stable, precise selection pressure. The results are transformative: across complex benchmarks like DevAI and InfoBench, MADE outperforms strong baselines by over 50% in software requirement satisfaction (39.9% to 61.9%) and achieves a 95% perfect pass rate on complex instruction following. This work validates a fundamental paradigm shift: moving from optimizing \"computable metrics\" to \"describable qualities,\" thereby unlocking evolutionary optimization for the vast open-ended domains where no ground truth exists.", "AI": {"tldr": "\u8bba\u6587\u7a81\u7834\u8fdb\u5316\u8ba1\u7b97\u5bf9\u5ba2\u89c2\u9002\u5e94\u5ea6\u7684\u4f9d\u8d56\uff0c\u5f15\u5165MADE\u6846\u67b6\uff0c\u5229\u7528LLM\u4e3b\u89c2\u8bc4\u5206+\u95ee\u9898\u5206\u89e3\uff0c\u5b9e\u73b0\u9ad8\u6548\u4f18\u5316\uff0c\u5e76\u5728\u591a\u9879\u590d\u6742\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u8fdb\u5316\u8ba1\u7b97\u4f9d\u8d56\u5ba2\u89c2\u7684\u53ef\u8ba1\u7b97\u9002\u5e94\u5ea6\u51fd\u6570\uff08Oracle\uff09\uff0c\u96be\u4ee5\u5728\u4e3b\u89c2\u3001\u65e0\u660e\u786e\u76ee\u6807\u7684\u5f00\u653e\u57df\u95ee\u9898\u4e2d\u5e94\u7528\uff0c\u963b\u788d\u4e86\u79d1\u5b66\u53d1\u73b0\u7684\u53ef\u80fd\u6027\u3002", "method": "\u63d0\u51fa\u4e86MADE\uff08\u591a\u667a\u80fd\u4f53\u5206\u89e3\u8fdb\u5316\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u201c\u95ee\u9898\u89c4\u683c\u5316\u201d\u628a\u6a21\u7cca\u6307\u4ee4\u5206\u89e3\u4e3a\u53ef\u9a8c\u8bc1\u7684\u5b50\u9700\u6c42\uff0c\u5c06\u9ad8\u65b9\u5dee\u7684LLM\u53cd\u9988\u8f6c\u5316\u4e3a\u7a33\u5b9a\u3001\u7cbe\u786e\u7684\u9009\u62e9\u538b\u529b\u3002", "result": "\u5728DevAI\u548cInfoBench\u7b49\u590d\u6742\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cMADE\u6846\u67b6\u5728\u8f6f\u4ef6\u9700\u6c42\u6ee1\u8db3\u7387\u4e0a\u8f83\u5f3a\u57fa\u7ebf\u63d0\u5347\u8d85\u8fc750%\uff0839.9%\u81f361.9%\uff09\uff0c\u5728\u590d\u6742\u6307\u4ee4\u8ddf\u968f\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e8695%\u7684\u5b8c\u7f8e\u901a\u8fc7\u7387\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u65b0\u8fdb\u5316\u4f18\u5316\u8303\u5f0f\uff0c\u53ef\u4ee5\u5728\u6ca1\u6709\u5ba2\u89c2\u53ef\u8ba1\u7b97\u9002\u5e94\u5ea6\u51fd\u6570\u7684\u573a\u666f\u4e0b\uff0c\u4ec5\u4f9d\u8d56\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4e3b\u89c2\u5224\u65ad\uff0c\u5b9e\u73b0\u9ad8\u6548\u8fdb\u5316\u4f18\u5316\u3002"}}
{"id": "2511.19757", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19757", "abs": "https://arxiv.org/abs/2511.19757", "authors": ["Colton Casto", "Anna Ivanova", "Evelina Fedorenko", "Nancy Kanwisher"], "title": "What does it mean to understand language?", "comment": null, "summary": "Language understanding entails not just extracting the surface-level meaning of the linguistic input, but constructing rich mental models of the situation it describes. Here we propose that because processing within the brain's core language system is fundamentally limited, deeply understanding language requires exporting information from the language system to other brain regions that compute perceptual and motor representations, construct mental models, and store our world knowledge and autobiographical memories. We review the existing evidence for this hypothesis, and argue that recent progress in cognitive neuroscience provides both the conceptual foundation and the methods to directly test it, thus opening up a new strategy to reveal what it means, cognitively and neurally, to understand language.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\uff0c\u6df1\u5165\u7684\u8bed\u8a00\u7406\u89e3\u4f9d\u8d56\u6838\u5fc3\u8bed\u8a00\u7cfb\u7edf\u4e0e\u5176\u4ed6\u8111\u533a\u7684\u4fe1\u606f\u4ea4\u4e92\uff0c\u652f\u6301\u611f\u77e5\u3001\u8fd0\u52a8\u3001\u77e5\u8bc6\u548c\u8bb0\u5fc6\u7b49\u529f\u80fd\u3002\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u7684\u6700\u65b0\u8fdb\u5c55\u4e3a\u9a8c\u8bc1\u8fd9\u4e00\u5047\u8bbe\u63d0\u4f9b\u4e86\u57fa\u7840\u548c\u65b9\u6cd5\uff0c\u5e76\u63a8\u52a8\u8bed\u8a00\u7406\u89e3\u673a\u5236\u7684\u7814\u7a76\u3002", "motivation": "\u63a2\u8ba8\u8bed\u8a00\u7406\u89e3\u4e0d\u4ec5\u5305\u62ec\u8bc6\u522b\u8868\u5c42\u610f\u4e49\uff0c\u8fd8\u9700\u8981\u6784\u5efa\u4e30\u5bcc\u7684\u60c5\u5883\u5fc3\u7406\u6a21\u578b\u3002", "method": "\u56de\u987e\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u9886\u57df\u7684\u76f8\u5173\u8bc1\u636e\uff0c\u63d0\u51fa\u7406\u8bba\u5047\u8bbe\uff0c\u5e76\u8ba8\u8bba\u53ef\u7528\u4e8e\u76f4\u63a5\u9a8c\u8bc1\u8be5\u5047\u8bbe\u7684\u7814\u7a76\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u6df1\u5ea6\u8bed\u8a00\u7406\u89e3\u9700\u8981\u5c06\u4fe1\u606f\u4ece\u6838\u5fc3\u8bed\u8a00\u7cfb\u7edf\u8fc1\u79fb\u81f3\u5176\u4ed6\u8111\u533a\uff0c\u4ee5\u5b9e\u73b0\u611f\u77e5\u3001\u8fd0\u52a8\u8868\u5f81\u3001\u5fc3\u7406\u6a21\u578b\u6784\u5efa\u4ee5\u53ca\u77e5\u8bc6\u548c\u8bb0\u5fc6\u7684\u5b58\u50a8\u3002\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u7684\u8fdb\u5c55\u4e3a\u7406\u8bba\u5960\u5b9a\u57fa\u7840\u5e76\u63d0\u4f9b\u65b0\u65b9\u6cd5\u3002", "conclusion": "\u7406\u89e3\u8bed\u8a00\u4e0d\u4ec5\u4f9d\u8d56\u6838\u5fc3\u8bed\u8a00\u7cfb\u7edf\uff0c\u66f4\u9700\u5168\u8111\u534f\u540c\uff0c\u5305\u62ec\u4e0e\u611f\u77e5\u3001\u52a8\u4f5c\u3001\u8bb0\u5fc6\u7b49\u76f8\u5173\u8111\u533a\u7684\u4fe1\u606f\u4ea4\u6d41\u3002\u8ba4\u77e5\u795e\u7ecf\u79d1\u5b66\u7684\u6700\u65b0\u8fdb\u5c55\u4e3a\u7814\u7a76\u8bed\u8a00\u7406\u89e3\u7684\u8ba4\u77e5\u548c\u795e\u7ecf\u673a\u5236\u5f00\u62d3\u65b0\u65b9\u5411\u3002"}}
{"id": "2511.19510", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.19510", "abs": "https://arxiv.org/abs/2511.19510", "authors": ["Asif Zaman", "Kallol Naha", "Khalid Belhajjame", "Hasan M. Jamil"], "title": "CodeR3: A GenAI-Powered Workflow Repair and Revival Ecosystem", "comment": "9 pages, 4 figures", "summary": "Scientific workflows encode valuable domain expertise and computational methodologies. Yet studies consistently show that a significant proportion of published workflows suffer from decay over time. This problem is particularly acute for legacy workflow systems like Taverna, where discontinued services, obsolete dependencies, and system retirement render previously functional workflows unusable. We present a novel legacy workflow migration system, called CodeR$^3$ (stands for Code Repair, Revival and Reuse), that leverages generative AI to analyze the characteristics of decayed workflows, reproduce them into modern workflow technologies like Snakemake and VisFlow. Our system additionally integrates stepwise workflow analysis visualization, automated service substitution, and human-in-the-loop validation. Through several case studies of Taverna workflow revival, we demonstrate the feasibility of this approach while identifying key challenges that require human oversight. Our findings reveal that automation significantly reduces manual effort in workflow parsing and service identification. However, critical tasks such as service substitution and data validation still require domain expertise. Our result will be a crowdsourcing platform that enables the community to collaboratively revive decayed workflows and validate the functionality and correctness of revived workflows. This work contributes a framework for workflow revival that balances automation efficiency with necessary human judgment.", "AI": {"tldr": "\u5229\u7528AI\u81ea\u52a8\u4fee\u590d\u548c\u8fc1\u79fb\u8001\u65e7\u79d1\u5b66\u5de5\u4f5c\u6d41\u5230\u73b0\u4ee3\u5e73\u53f0\uff0c\u5e76\u901a\u8fc7\u4f17\u5305\u534f\u4f5c\u5e73\u53f0\u5b9e\u73b0\u4eba\u673a\u7ed3\u5408\u7684\u9ad8\u6548\u590d\u7528\u3002\u81ea\u52a8\u5316\u663e\u8457\u51cf\u8f7b\u4e86\u4eba\u5de5\u8d1f\u62c5\uff0c\u4f46\u5173\u952e\u6b65\u9aa4\u8fd8\u9700\u4e13\u5bb6\u53c2\u4e0e\u3002", "motivation": "\u73b0\u6709\u5927\u91cf\u79d1\u5b66\u5de5\u4f5c\u6d41\u56e0\u4f9d\u8d56\u8fc7\u65f6\u670d\u52a1\u548c\u7cfb\u7edf\u9000\u4f11\u800c\u5931\u6548\uff0c\u5c24\u5176\u662f\u5728Taverna\u7b49\u9057\u7559\u7cfb\u7edf\u4e2d\uff0c\u5bfc\u81f4\u5df2\u53d1\u5e03\u7684\u5de5\u4f5c\u6d41\u65e0\u6cd5\u91cd\u590d\u5229\u7528\u3002\u8be5\u5de5\u4f5c\u65e8\u5728\u89e3\u51b3\u9057\u7559\u5de5\u4f5c\u6d41\u5931\u6548\u548c\u590d\u7528\u96be\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCodeR^3\uff08Code Repair, Revival and Reuse\uff09\u7684\u9057\u7559\u79d1\u5b66\u5de5\u4f5c\u6d41\u8fc1\u79fb\u7cfb\u7edf\uff0c\u91c7\u7528\u751f\u6210\u5f0fAI\u5bf9\u5931\u6548\u7684\u65e7\u5de5\u4f5c\u6d41\u8fdb\u884c\u5206\u6790\uff0c\u81ea\u52a8\u5c06\u5176\u8fc1\u79fb\u5230\u73b0\u4ee3\u7684\u5de5\u4f5c\u6d41\u5e73\u53f0\uff08\u5982Snakemake\u548cVisFlow\uff09\uff0c\u5e76\u7ed3\u5408\u4e86\u5de5\u4f5c\u6d41\u53ef\u89c6\u5316\u5206\u6790\u3001\u81ea\u52a8\u670d\u52a1\u66ff\u6362\u53ca\u4eba\u5de5\u53c2\u4e0e\u9a8c\u8bc1\u3002", "result": "\u5728\u591a\u4e2aTaverna\u7528\u4f8b\u4e2d\uff0c\u7cfb\u7edf\u80fd\u591f\u81ea\u52a8\u5206\u6790\u548c\u8f6c\u6362\u5de5\u4f5c\u6d41\uff0c\u5927\u5e45\u51cf\u5c11\u4e86\u4eba\u5de5\u89e3\u6790\u548c\u670d\u52a1\u8bc6\u522b\u7684\u5de5\u4f5c\u91cf\u3002\u4f46\u670d\u52a1\u66ff\u6362\u548c\u6570\u636e\u9a8c\u8bc1\u7b49\u73af\u8282\u4ecd\u9700\u9886\u57df\u4e13\u5bb6\u53c2\u4e0e\uff0c\u8868\u660e\u90e8\u5206\u5173\u952e\u6b65\u9aa4\u5c1a\u65e0\u6cd5\u5b8c\u5168\u81ea\u52a8\u5316\u3002\u6700\u7ec8\u5c06\u5f62\u6210\u4e00\u4e2a\u4f17\u5305\u5e73\u53f0\uff0c\u4e3a\u793e\u533a\u63d0\u4f9b\u534f\u540c\u4fee\u590d\u548c\u9a8c\u8bc1\u5de5\u4f5c\u6d41\u7684\u529f\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5e73\u8861\u81ea\u52a8\u5316\u4e0e\u4eba\u5de5\u5224\u65ad\u7684\u9057\u7559\u5de5\u4f5c\u6d41\u590d\u5174\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u6280\u672f\u53ef\u884c\u6027\u548c\u73b0\u5b9e\u6311\u6218\u3002\u81ea\u52a8\u5316\u5728\u5904\u7406\u6d41\u7a0b\u89e3\u6790\u548c\u8bc6\u522b\u4e0a\u8868\u73b0\u7a81\u51fa\uff0c\u90e8\u5206\u6d41\u7a0b\u4ecd\u9700\u4e13\u5bb6\u51b3\u7b56\u3002\u672a\u6765\uff0c\u8be5\u7cfb\u7edf\u5c06\u901a\u8fc7\u793e\u533a\u4f17\u5305\u8fdb\u4e00\u6b65\u63d0\u5347\u5de5\u4f5c\u6d41\u7684\u518d\u5229\u7528\u548c\u9a8c\u8bc1\u80fd\u529b\u3002"}}
{"id": "2511.19785", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.19785", "abs": "https://arxiv.org/abs/2511.19785", "authors": ["Maureen Herbert", "Katie Sun", "Angelica Lim", "Yasaman Etesam"], "title": "Gender Bias in Emotion Recognition by Large Language Models", "comment": "Accepted at AAAI 2026 Workshop (WS37)", "summary": "The rapid advancement of large language models (LLMs) and their growing integration into daily life underscore the importance of evaluating and ensuring their fairness. In this work, we examine fairness within the domain of emotional theory of mind, investigating whether LLMs exhibit gender biases when presented with a description of a person and their environment and asked, \"How does this person feel?\". Furthermore, we propose and evaluate several debiasing strategies, demonstrating that achieving meaningful reductions in bias requires training based interventions rather than relying solely on inference-time prompt-based approaches such as prompt engineering.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30LLM\u5728\u60c5\u7eea\u5fc3\u7406\u63a8\u7406\u4efb\u52a1\u4e2d\u662f\u5426\u6709\u6027\u522b\u504f\u89c1\uff0c\u7ed3\u679c\u8868\u660e\uff0c\u964d\u4f4e\u504f\u89c1\u9700\u4f9d\u8d56\u8bad\u7ec3\u9636\u6bb5\u7684\u5e72\u9884\uff0c\u800c\u4e0d\u662f\u4ec5\u9760\u63d0\u793a\u5de5\u7a0b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5e7f\u6cdb\u5e94\u7528\u4e8e\u65e5\u5e38\u751f\u6d3b\uff0c\u63d0\u9ad8\u5176\u516c\u5e73\u6027\u6781\u4e3a\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u60c5\u611f\u63a8\u7406\u548c\u6d89\u53ca\u6027\u522b\u7684\u573a\u666f\u4e2d\u3002", "method": "\u5206\u6790LLM\u5bf9\u63cf\u8ff0\u4eba\u7269\u53ca\u5176\u60c5\u5883\u540e\uff0c\u56de\u7b54\u201c\u8fd9\u4e2a\u4eba\u611f\u89c9\u5982\u4f55\uff1f\u201d\u65f6\u662f\u5426\u51fa\u73b0\u6027\u522b\u504f\u89c1\uff0c\u540c\u65f6\u63d0\u51fa\u5e76\u68c0\u9a8c\u591a\u79cd\u53bb\u504f\u7b56\u7565\uff0c\u5305\u62ec\u63d0\u793a\u5de5\u7a0b\u548c\u8bad\u7ec3\u5e72\u9884\u3002", "result": "\u4ec5\u7528\u63a8\u7406\u9636\u6bb5\u7684\u63d0\u793a\u5de5\u7a0b\u65e0\u6cd5\u6709\u6548\u964d\u4f4e\u6027\u522b\u504f\u89c1\uff0c\u8bad\u7ec3\u9636\u6bb5\u7684\u53bb\u504f\u65b9\u6cd5\u80fd\u66f4\u6709\u610f\u4e49\u5730\u51cf\u5c11\u504f\u89c1\u3002", "conclusion": "\u8981\u5b9e\u73b0\u8bed\u8a00\u6a21\u578b\u516c\u5e73\u6027\uff0c\u5c24\u5176\u5728\u60c5\u7eea\u5fc3\u7406\u9886\u57df\u51cf\u5c11\u6027\u522b\u504f\u89c1\uff0c\u5fc5\u987b\u91c7\u7528\u8bad\u7ec3\u9636\u6bb5\u7684\u5e72\u9884\u65b9\u6cd5\uff0c\u5e76\u975e\u4ec5\u9760\u63a8\u7406\u9636\u6bb5\u7684\u63d0\u793a\u5de5\u7a0b\u3002"}}
{"id": "2511.19635", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19635", "abs": "https://arxiv.org/abs/2511.19635", "authors": ["Abhi Chivukula", "Jay Somasundaram", "Vijay Somasundaram"], "title": "Agint: Agentic Graph Compilation for Software Engineering Agents", "comment": "18 pages, 5 figures, NeurIPS 2025: Deep Learning for Code in the Agentic Era", "summary": "LLM-based coding agents are increasingly common but still face challenges in context management, latency, reliability, reproducibility, and scalability. We present Agint, an agentic graph compiler, interpreter, and runtime that incrementally and hierarchically converts natural-language instructions into typed, effect-aware code DAGs. Agint introduces explicit type floors (text to data to spec to code) grounded in semantic graph transformations and a hybrid LLM and function-based JIT runtime. This enables dynamic graph refinement, reproducible and optimizable execution, speculative evaluation, and interoperability with existing developer tools. Agint's typed graph bindings improve reliability and allow concurrent composition of concurrent codebases by construction, supporting accelerated development with smaller and faster models, lower latency, efficient context utilization, and higher throughput. Hierarchical compilation allows scalable graph edits, while the graph structure supports reproducibility and efficient parallel generation. Agint provides a composable unix-style toolchain: dagify (DAG compiler), dagent (hybrid JIT runtime), schemagin (schema generator), and datagin (data transformer) for realtime, low-latency code and dataflow creation. Human developers and coding agents refine graphs through the Agint CLI, while non-technical users use Agint Flow GUI for visual editing, conversational refinement, and debugging to promote prototype agentic workflows to production code. This continuous co-creation model allows teams to prototype quickly, refine seamlessly, and deploy reliably, bridging natural language, compiler methods, and developer tooling to enable a new generation of composable, team-centric coding agents at scale.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Agint\uff0c\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u9ad8\u53ef\u9760\u6027\u3001\u652f\u6301\u81ea\u7136\u8bed\u8a00\u5230\u4ee3\u7801DAG\u8f6c\u6362\u7684\u4ee3\u7406\u7cfb\u7edf\uff0c\u4ee5\u9ad8\u6548\u56e2\u961f\u534f\u4f5c\u548c\u4f4e\u5ef6\u8fdf\u65b9\u6cd5\u63a8\u52a8LLM\u7f16\u7801\u4ee3\u7406\u5b9e\u73b0\u539f\u578b\u5230\u751f\u4ea7\u7684\u5168\u6d41\u7a0b\u4f18\u5316\u3002", "motivation": "\u5f53\u524d\u4ee5\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e3a\u57fa\u7840\u7684\u7f16\u7801\u4ee3\u7406\u5728\u4e0a\u4e0b\u6587\u7ba1\u7406\u3001\u5ef6\u8fdf\u3001\u53ef\u9760\u6027\u3001\u53ef\u590d\u73b0\u6027\u548c\u53ef\u6269\u5c55\u6027\u7b49\u65b9\u9762\u9762\u4e34\u6311\u6218\u3002", "method": "\u63d0\u51faAgint\u7cfb\u7edf\uff0c\u5305\u62ec\u7f16\u8bd1\u5668\u3001\u89e3\u91ca\u5668\u53ca\u8fd0\u884c\u65f6\uff0c\u901a\u8fc7\u5206\u5c42\u3001\u6709\u7c7b\u578b\u7684\u8bed\u4e49\u56fe\uff08DAG\uff09\u5c06\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u9010\u6b65\u8f6c\u6362\u4e3a\u5177\u5907\u6548\u679c\u611f\u77e5\u80fd\u529b\u7684\u4ee3\u7801\u3002\u7cfb\u7edf\u7ed3\u5408LLM\u548c\u51fd\u6570\u578bJIT\u8fd0\u884c\u65f6\uff0c\u5b9e\u73b0\u52a8\u6001\u56fe\u4f18\u5316\u548c\u9ad8\u53ef\u9760\u6027\u3002\u914d\u5957\u63d0\u4f9b\u5305\u62ecDAG\u7f16\u8bd1\u5668\u3001\u6df7\u5408JIT\u8fd0\u884c\u65f6\u3001\u6a21\u5f0f\u751f\u6210\u5668\u548c\u6570\u636e\u8f6c\u6362\u5de5\u5177\uff0c\u8fd8\u914d\u6709CLI\u548cGUI\u7528\u4e8e\u4eba\u7c7b\u5f00\u53d1\u8005\u53ca\u975e\u6280\u672f\u7528\u6237\u4ea4\u4e92\u3002", "result": "Agint\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u4e0a\u4e0b\u6587\u5229\u7528\u3001\u4f4e\u5ef6\u8fdf\u4e0e\u9ad8\u541e\u5410\uff0c\u652f\u6301\u5e76\u53d1\u4ee3\u7801\u590d\u5408\u4e0e\u53ef\u6269\u5c55\u7684\u56fe\u7f16\u8f91\uff0c\u5b9e\u73b0\u4ee3\u7801\u751f\u6210\u548c\u6570\u636e\u6d41\u7684\u5b9e\u65f6\u4f18\u5316\u4e0e\u590d\u73b0\uff0c\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\u548c\u4ee3\u7801\u53ef\u9760\u6027\u3002CLI\u548cGUI\u652f\u6301\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u7f16\u8f91\u4e0e\u8054\u5408\u4f5c\u4e1a\uff0c\u4fc3\u8fdb\u539f\u578b\u5230\u751f\u4ea7\u4ee3\u7801\u65e0\u7f1d\u8fc7\u6e21\u3002", "conclusion": "Agint\u67b6\u6784\u878d\u5408\u81ea\u7136\u8bed\u8a00\u3001\u7f16\u8bd1\u6280\u672f\u548c\u5f00\u53d1\u8005\u5de5\u5177\uff0c\u4e3a\u56e2\u961f\u7ea7\u7f16\u7801\u4ee3\u7406\u521b\u9020\u4e86\u9ad8\u6548\u3001\u53ef\u7ec4\u5408\u3001\u652f\u6301\u6301\u7eed\u5171\u521b\u7684\u65b0\u8303\u5f0f\uff0c\u63a8\u52a8LLM\u7f16\u7801\u4ee3\u7406\u5728\u53ef\u9760\u6027\u548c\u53ef\u6269\u5c55\u6027\u4e0a\u7684\u7a81\u7834\u3002"}}
{"id": "2511.19816", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19816", "abs": "https://arxiv.org/abs/2511.19816", "authors": ["Saif M. Mohammad"], "title": "Breaking Bad: Norms for Valence, Arousal, and Dominance for over 10k English Multiword Expressions", "comment": null, "summary": "Factor analysis studies have shown that the primary dimensions of word meaning are Valence (V), Arousal (A), and Dominance (D). Existing lexicons such as the NRC VAD Lexicon, published in 2018, include VAD association ratings for words. Here, we present a complement to it, which has human ratings of valence, arousal, and dominance for 10k English Multiword Expressions (MWEs) and their constituent words. We also increase the coverage of unigrams, especially words that have become more common since 2018. In all, the new NRC VAD Lexicon v2 now has entries for 10k MWEs and 25k words, in addition to the entries in v1. We show that the associations are highly reliable. We use the lexicon to examine emotional characteristics of MWEs, including: 1. The degree to which MWEs (idioms, noun compounds, and verb particle constructions) exhibit strong emotionality; 2. The degree of emotional compositionality in MWEs. The lexicon enables a wide variety of research in NLP, Psychology, Public Health, Digital Humanities, and Social Sciences. The NRC VAD Lexicon v2 is freely available through the project webpage: http://saifmohammad.com/WebPages/nrc-vad.html", "AI": {"tldr": "\u4f5c\u8005\u63a8\u51fa\u4e86\u8986\u76d6\u5ea6\u66f4\u5e7f\u3001\u5e26\u6709\u8be6\u7ec6\u4eba\u7c7b\u60c5\u611f\u8bc4\u5206\u7684NRC VAD\u60c5\u611f\u8bcd\u5178v2\uff0c\u9996\u6b21\u7cfb\u7edf\u8986\u76d6\u82f1\u8bed\u591a\u8bcd\u8868\u8fbe\uff08\u5982\u4e60\u8bed\u3001\u590d\u5408\u540d\u8bcd\u7b49\uff09\uff0c\u4e3a\u60c5\u611f\u8ba1\u7b97\u548c\u591a\u5b66\u79d1\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\u3002", "motivation": "\u73b0\u6709\u60c5\u611f\u8bcd\u5178\u4e3b\u8981\u6db5\u76d6\u5355\u8bcd\uff0c\u5bf9\u591a\u8bcd\u8868\u8fbe\u548c\u65b0\u8bcd\u8986\u76d6\u4e0d\u8db3\uff0c\u5f71\u54cd\u8bed\u8a00\u60c5\u611f\u5206\u6790\u7cbe\u5ea6\uff0c\u4e9f\u9700\u66f4\u5927\u8986\u76d6\u9762\u548c\u66f4\u8be6\u7ec6\u8bc4\u5206\u7684\u4eba\u7c7b\u8bcd\u5178\u4ee5\u63a8\u52a8NLP\u7b49\u591a\u9886\u57df\u7814\u7a76\u3002", "method": "\u6536\u96c6\u82f1\u8bed\u591a\u8bcd\u8868\u8fbe\uff08MWE\uff09\u53ca\u5176\u6210\u5206\u8bcd\u7684\u4eba\u7c7bVAD\uff08\u6109\u60a6\u3001\u5524\u9192\u3001\u652f\u914d\uff09\u8bc4\u5206\uff0c\u5927\u5e45\u6269\u5c55\u8bcd\u8868\u8bcd\u6761\uff0c\u5305\u62ec\u65b0\u5e38\u89c1\u8bcd\uff1b\u5bf9\u8bc4\u5206\u53ef\u9760\u6027\u8fdb\u884c\u68c0\u9a8c\uff0c\u5e76\u5206\u6790\u591a\u8bcd\u8868\u8fbe\u7684\u60c5\u611f\u7279\u5f81\u4e0e\u6210\u5206\u6784\u6210\u3002", "result": "\u65b0\u53d1\u5e03\u7684NRC VAD Lexicon v2\u5305\u62ec1\u4e07\u6761MWE\u548c2.5\u4e07\u6761\u5355\u8bcd\u7684VAD\u8bc4\u5206\uff0c\u8986\u76d6\u7387\u663e\u8457\u63d0\u5347\uff0c\u8bc4\u5206\u9ad8\u5ea6\u53ef\u9760\u3002\u5229\u7528\u65b0\u8bcd\u5178\u53d1\u73b0MWE\u663e\u8457\u8868\u73b0\u51fa\u60c5\u611f\u7279\u5f81\uff0c\u5e76\u5206\u6790\u4e86\u5176\u60c5\u611f\u53ef\u7ec4\u5408\u6027\u3002", "conclusion": "NRC VAD Lexicon v2\u662f\u60c5\u611f\u5206\u6790\u9886\u57df\u7684\u91cd\u8981\u5de5\u5177\uff0c\u80fd\u66f4\u5168\u9762\u51c6\u786e\u6355\u6349\u590d\u6742\u8bed\u8a00\u4e2d\u7684\u60c5\u611f\u4fe1\u606f\uff0c\u5c06\u4fc3\u8fdbNLP\u3001\u5fc3\u7406\u5b66\u3001\u6570\u5b57\u4eba\u6587\u7b49\u9886\u57df\u7684\u7814\u7a76\u548c\u5e94\u7528\u3002"}}
{"id": "2511.19875", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19875", "abs": "https://arxiv.org/abs/2511.19875", "authors": ["Qingyu Zhang", "Puzhuo Liu", "Peng Di", "Chenxiong Qian"], "title": "CodeFuse-CommitEval: Towards Benchmarking LLM's Power on Commit Message and Code Change Inconsistency Detection", "comment": null, "summary": "Version control relies on commit messages to convey the rationale for code changes, but these messages are often low quality and, more critically, inconsistent with their diffs-known as message-code inconsistency (MCI). MCIs mislead reviewers, hinder maintenance, contaminate research datasets, and may obscure security patches. Yet, no dedicated benchmark exists to evaluate models for MCI detection. We introduce CODEFUSE-COMMITEVAL, the first benchmark designed for MCI detection using large language models (LLMs). Built on the ApacheCM dataset for diversity and quality, we generate seven types of inconsistent messages through rule-guided mutations of originally consistent commits and apply two-fold validation to verify both positive and negative samples. Using this labeled dataset of message-diff pairs, we evaluate six state-of-the-art open-source LLMs under a vanilla setting and with three augmentation strategies: few-shot prompting, chain-of-thought, and extended context. Results show models detect inconsistent commits more reliably than consistent ones (average Recall 85.95%, Precision 80.28%, Specificity 63.8%); gpt-oss-20B performs best overall but uses over twice the tokens of others. Augmentation effects vary: adjacent context helps larger models but adds noise for smaller ones; few-shot improves accuracy and reduces token use, yet increases universally incorrect predictions; chain-of-thought boosts precision and specificity at the cost of recall and higher token consumption. Type-wise analysis reveals higher detectability for component, file-path, and operation inconsistencies, but lower accuracy and higher token cost for intent-level \"purpose\" inconsistencies. CODEFUSE-COMMITEVAL provides a rigorous foundation for measuring, comparing, and advancing MCI detection, highlighting the need for richer context and balanced data to capture high-level semantic gaps.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9996\u4e2a\u4e13\u7528\u4e8e\u4ee3\u7801\u63d0\u4ea4\u4fe1\u606f\u4e0e\u4ee3\u7801\u5dee\u5f02\u4e00\u81f4\u6027\u68c0\u6d4b\uff08MCI\uff09\u7684\u57fa\u51c6CODEFUSE-COMMITEVAL\uff0c\u7cfb\u7edf\u5206\u6790\u4e866\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u57287\u7c7b\u4e0d\u4e00\u81f4\u60c5\u666f\u4e0b\u7684\u8868\u73b0\uff0c\u603b\u7ed3\u4e86\u4e0d\u540c\u589e\u5f3a\u7b56\u7565\u7684\u5229\u5f0a\uff0c\u5e76\u9488\u5bf9\u9ad8\u5c42\u8bed\u4e49\u4e00\u81f4\u6027\u68c0\u6d4b\u96be\u9898\u63d0\u51fa\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u4ee3\u7801\u7248\u672c\u63a7\u5236\u7cfb\u7edf\u9ad8\u5ea6\u4f9d\u8d56\u63d0\u4ea4\u4fe1\u606f\u6765\u8bf4\u660e\u53d8\u66f4\u539f\u56e0\uff0c\u4f46\u8fd9\u4e9b\u4fe1\u606f\u5e38\u5e38\u4e0e\u4ee3\u7801\u5dee\u5f02\uff08diff\uff09\u4e0d\u4e00\u81f4\uff0c\u5bfc\u81f4\u8bef\u5bfc\u548c\u7ef4\u62a4\u56f0\u96be\u7b49\u95ee\u9898\u3002\u4e4b\u524d\u7f3a\u4e4f\u9488\u5bf9\u68c0\u6d4b\u63d0\u4ea4\u4fe1\u606f-\u4ee3\u7801\u4e0d\u4e00\u81f4\uff08MCI\uff09\u95ee\u9898\u7684\u4e13\u7528\u8bc4\u6d4b\u57fa\u51c6\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86CODEFUSE-COMMITEVAL\uff0c\u4e00\u4e2a\u4e13\u4e3aMCI\u68c0\u6d4b\u8bbe\u8ba1\u7684\u57fa\u51c6\uff0c\u57fa\u4e8e\u9ad8\u8d28\u91cf\u3001\u591a\u6837\u5316\u7684ApacheCM\u6570\u636e\u96c6\u3002\u901a\u8fc7\u89c4\u5219\u5f15\u5bfc\u7684\u53d8\u5f02\u751f\u62107\u7c7b\u4e0d\u4e00\u81f4\u4fe1\u606f\uff0c\u5e76\u8fdb\u884c\u53cc\u91cd\u9a8c\u8bc1\u6784\u9020\u6b63\u8d1f\u6837\u672c\u3002\u5229\u7528\u8be5\u6570\u636e\u96c6\u8bc4\u6d4b6\u4e2a\u4e3b\u6d41\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u8bbe\u7f6e\u539f\u59cb\u3001\u5c11\u6837\u672c\u63d0\u793a\u3001\u601d\u7ef4\u94fe\u6269\u5c55\u7b49\u589e\u5f3a\u65b9\u5f0f\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0c\u6a21\u578b\u68c0\u6d4b\u51fa\u4e0d\u4e00\u81f4\u63d0\u4ea4\u7684\u53ef\u9760\u6027\u9ad8\u4e8e\u4e00\u81f4\u63d0\u4ea4\uff08\u5e73\u5747\u53ec\u56de\u738785.95%\uff0c\u7cbe\u51c6\u738780.28%\uff0c\u7279\u5f02\u602763.8%\uff09\u3002gpt-oss-20B\u6027\u80fd\u6700\u4f73\u4f46\u8d44\u6e90\u6d88\u8017\u5927\u3002\u90bb\u8fd1\u4e0a\u4e0b\u6587\u589e\u5f3a\u6709\u5229\u4e8e\u5927\u6a21\u578b\uff0c\u5c0f\u6a21\u578b\u5219\u5f15\u5165\u566a\u58f0\uff1b\u5c11\u6837\u672c\u63d0\u793a\u63d0\u5347\u51c6\u786e\u5ea6\u4f46\u9519\u8bef\u9884\u6d4b\u589e\u52a0\uff1b\u601d\u7ef4\u94fe\u589e\u5f3a\u7cbe\u5ea6\u3001\u7279\u5f02\u6027\u4f46\u964d\u4f4e\u53ec\u56de\uff0c\u4e14\u8017\u8d39\u8d44\u6e90\u8f83\u591a\u3002\u5bf9\u4e0d\u540c\u4e0d\u4e00\u81f4\u7c7b\u578b\u7684\u5206\u6790\u663e\u793a\uff0c\u2018\u76ee\u7684\u2019\u7c7b\u9ad8\u5c42\u8bed\u4e49\u96be\u4ee5\u68c0\u6d4b\u4e14\u6d88\u8017\u9ad8\u3002", "conclusion": "CODEFUSE-COMMITEVAL\u4e3a\u68c0\u6d4b\u548c\u8bc4\u4f30MCI\u95ee\u9898\u63d0\u4f9b\u4e86\u6807\u51c6\uff0c\u63ed\u793a\u4e86\u8865\u5145\u66f4\u4e30\u5bcc\u4e0a\u4e0b\u6587\u548c\u6570\u636e\u5e73\u8861\u5bf9\u6355\u6349\u9ad8\u8bed\u4e49\u5dee\u5f02\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.19818", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19818", "abs": "https://arxiv.org/abs/2511.19818", "authors": ["Koena Ronny Mabokela", "Tim Schlippe", "Mpho Raborife", "Turgay Celik"], "title": "Language-Independent Sentiment Labelling with Distant Supervision: A Case Study for English, Sepedi and Setswana", "comment": "Published in the The Fourth Workshop on Processing Emotions, Decisions and Opinions (EDO 2023) at 10th Language & Technology Conference: Human Language Technologies as a Challenge for Computer Science and Linguistics (LTC 2023), Pozna\u0144, Poland, 21-23 April 2023. ISBN: 978-83-232-4176-8", "summary": "Sentiment analysis is a helpful task to automatically analyse opinions and emotions on various topics in areas such as AI for Social Good, AI in Education or marketing. While many of the sentiment analysis systems are developed for English, many African languages are classified as low-resource languages due to the lack of digital language resources like text labelled with corresponding sentiment classes. One reason for that is that manually labelling text data is time-consuming and expensive. Consequently, automatic and rapid processes are needed to reduce the manual effort as much as possible making the labelling process as efficient as possible. In this paper, we present and analyze an automatic language-independent sentiment labelling method that leverages information from sentiment-bearing emojis and words. Our experiments are conducted with tweets in the languages English, Sepedi and Setswana from SAfriSenti, a multilingual sentiment corpus for South African languages. We show that our sentiment labelling approach is able to label the English tweets with an accuracy of 66%, the Sepedi tweets with 69%, and the Setswana tweets with 63%, so that on average only 34% of the automatically generated labels remain to be corrected.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u57fa\u4e8e\u8868\u60c5\u7b26\u53f7\u548c\u5355\u8bcd\u7684\u81ea\u52a8\u60c5\u611f\u6807\u6ce8\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u63d0\u5347\u5bf9\u5357\u975e\u591a\u8bed\u79cd\u63a8\u6587\u7684\u6807\u6ce8\u6548\u7387\u3002\u8be5\u65b9\u6cd5\u51cf\u5c11\u4e86\u4eba\u5de5\u5de5\u4f5c\u91cf\uff0c\u6709\u52a9\u4e8e\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u60c5\u611f\u5206\u6790\u7814\u7a76\u3002", "motivation": "\u8bb8\u591a\u975e\u82f1\u8bed\u7684\u975e\u6d32\u8bed\u8a00\u7531\u4e8e\u7f3a\u4e4f\u5e26\u6709\u60c5\u611f\u6807\u7b7e\u7684\u6570\u5b57\u8d44\u6e90\uff0c\u88ab\u5f52\u7c7b\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u3002\u624b\u52a8\u6807\u6ce8\u8fd9\u4e9b\u6570\u636e\u65e2\u8017\u65f6\u53c8\u6602\u8d35\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u3001\u9ad8\u6548\u7684\u6807\u6ce8\u65b9\u6cd5\u6765\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u8a00\u65e0\u5173\u7684\u81ea\u52a8\u60c5\u611f\u6807\u6ce8\u65b9\u6cd5\uff0c\u5229\u7528\u542b\u6709\u60c5\u611f\u4fe1\u606f\u7684\u8868\u60c5\u7b26\u53f7\u548c\u8bcd\u8bed\uff0c\u5bf9\u63a8\u6587\u8fdb\u884c\u60c5\u611f\u81ea\u52a8\u6807\u6ce8\u3002\u5b9e\u9a8c\u57fa\u4e8eSAfriSenti\u6570\u636e\u96c6\u4e2d\u7684\u82f1\u8bed\u3001Sepedi\u8bed\u548cSetswana\u8bed\u63a8\u6587\u8fdb\u884c\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6807\u6ce8\u65b9\u6cd5\u5728\u82f1\u8bed\u63a8\u6587\u4e2d\u7684\u51c6\u786e\u7387\u4e3a66%\u3001Sepedi\u8bed\u63a8\u6587\u4e3a69%\u3001Setswana\u8bed\u63a8\u6587\u4e3a63%\u3002\u5e73\u5747\u6765\u770b\uff0c\u4ec5\u670934%\u7684\u81ea\u52a8\u751f\u6210\u6807\u7b7e\u9700\u8981\u4eba\u5de5\u7ea0\u6b63\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u624b\u52a8\u60c5\u611f\u6807\u6ce8\u7684\u5de5\u4f5c\u91cf\uff0c\u63d0\u9ad8\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00\u6570\u636e\u96c6\u7684\u6807\u6ce8\u6548\u7387\u3002"}}
{"id": "2511.20403", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20403", "abs": "https://arxiv.org/abs/2511.20403", "authors": ["Andrea Lops", "Fedelucio Narducci", "Azzurra Ragone", "Michelantonio Trizio", "Claudio Barto"], "title": "LLMs for Automated Unit Test Generation and Assessment in Java: The AgoneTest Framework", "comment": "Accepted at 40th IEEE/ACM International Conference on Automated Software Engineering", "summary": "Unit testing is an essential but resource-intensive step in software development, ensuring individual code units function correctly. This paper introduces AgoneTest, an automated evaluation framework for Large Language Model-generated (LLM) unit tests in Java. AgoneTest does not aim to propose a novel test generation algorithm; rather, it supports researchers and developers in comparing different LLMs and prompting strategies through a standardized end-to-end evaluation pipeline under realistic conditions. We introduce the Classes2Test dataset, which maps Java classes under test to their corresponding test classes, and a framework that integrates advanced evaluation metrics, such as mutation score and test smells, for a comprehensive assessment. Experimental results show that, for the subset of tests that compile, LLM-generated tests can match or exceed human-written tests in terms of coverage and defect detection. Our findings also demonstrate that enhanced prompting strategies contribute to test quality. AgoneTest clarifies the potential of LLMs in software testing and offers insights for future improvements in model design, prompt engineering, and testing practices.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86AgoneTest\u6846\u67b6\uff0c\u7528\u4e8e\u5ba2\u89c2\u8bc4\u4f30\u5927\u6a21\u578b\u751f\u6210\u7684Java\u5355\u5143\u6d4b\u8bd5\uff0c\u53d1\u73b0\u53ea\u8981\u7f16\u8bd1\u901a\u8fc7\uff0c\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u7684\u6548\u679c\u4e0d\u900a\u8272\u4e8e\u4eba\u5de5\u6d4b\u8bd5\uff0c\u5e76\u4e14\u66f4\u4f18\u63d0\u793a\u65b9\u5f0f\u80fd\u63d0\u5347\u8d28\u91cf\u3002", "motivation": "\u5355\u5143\u6d4b\u8bd5\u662f\u4fdd\u8bc1\u4ee3\u7801\u6b63\u786e\u6027\u7684\u91cd\u8981\u73af\u8282\uff0c\u4f46\u5176\u8fc7\u7a0b\u5341\u5206\u8017\u8d39\u8d44\u6e90\u3002\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u53d1\u5c55\uff0c\u81ea\u52a8\u5316\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u6210\u4e3a\u7814\u7a76\u70ed\u70b9\u3002\u8be5\u8bba\u6587\u5173\u6ce8\u4e8e\u8bc4\u4f30\u4e0d\u540cLLM\u751f\u6210\u7684\u5355\u5143\u6d4b\u8bd5\u7684\u6548\u679c\uff0c\u800c\u975e\u63d0\u51fa\u65b0\u7684\u751f\u6210\u7b97\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51faAgoneTest\uff0c\u4e00\u4e2a\u9762\u5411Java\u7684LLM\u81ea\u52a8\u5316\u5355\u5143\u6d4b\u8bd5\u8bc4\u4f30\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5efa\u7acb\u4e86Classes2Test\u6570\u636e\u96c6\uff0c\u5c06Java\u7c7b\u4e0e\u5176\u6d4b\u8bd5\u7c7b\u8fdb\u884c\u6620\u5c04\uff0c\u5e76\u96c6\u6210\u4e86\u5982\u53d8\u5f02\u5206\u6570\u548c\u6d4b\u8bd5\u5f02\u5473\u7b49\u591a\u79cd\u9ad8\u7ea7\u8bc4\u4f30\u6307\u6807\uff0c\u4ece\u800c\u7cfb\u7edf\u6027\u8bc4\u4f30\u751f\u6210\u6d4b\u8bd5\u7684\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u53ea\u8981\u751f\u6210\u7684\u6d4b\u8bd5\u80fd\u6210\u529f\u7f16\u8bd1\uff0cLLM\u751f\u6210\u7684\u6d4b\u8bd5\u5728\u8986\u76d6\u7387\u548c\u7f3a\u9677\u68c0\u6d4b\u4e0a\u80fd\u591f\u5ab2\u7f8e\u751a\u81f3\u8d85\u8d8a\u4eba\u5de5\u7f16\u5199\u7684\u6d4b\u8bd5\u3002\u6b64\u5916\uff0c\u6539\u8fdb\u7684\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u6d4b\u8bd5\u8d28\u91cf\u3002", "conclusion": "AgoneTest\u6846\u67b6\u660e\u786e\u5c55\u73b0\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u6d4b\u8bd5\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u4e3a\u6a21\u578b\u4f18\u5316\u3001\u63d0\u793a\u5de5\u7a0b\u53ca\u6d4b\u8bd5\u5b9e\u8df5\u7684\u672a\u6765\u6539\u8fdb\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2511.19852", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19852", "abs": "https://arxiv.org/abs/2511.19852", "authors": ["Shi-Wei Dai", "Yan-Wei Shie", "Tsung-Huan Yang", "Lun-Wei Ku", "Yung-Hui Li"], "title": "Profile-LLM: Dynamic Profile Optimization for Realistic Personality Expression in LLMs", "comment": null, "summary": "Personalized Large Language Models (LLMs) have been shown to be an effective way to create more engaging and enjoyable user-AI interactions. While previous studies have explored using prompts to elicit specific personality traits in LLMs, they have not optimized these prompts to maximize personality expression. To address this limitation, we propose PersonaPulse: Dynamic Profile Optimization for Realistic Personality Expression in LLMs, a framework that leverages LLMs' inherent knowledge of personality traits to iteratively enhance role-play prompts while integrating a situational response benchmark as a scoring tool, ensuring a more realistic and contextually grounded evaluation to guide the optimization process. Quantitative evaluations demonstrate that the prompts generated by PersonaPulse outperform those of prior work, which were designed based on personality descriptions from psychological studies. Additionally, we explore the relationship between model size and personality modeling through extensive experiments. Finally, we find that, for certain personality traits, the extent of personality evocation can be partially controlled by pausing the optimization process. These findings underscore the importance of prompt optimization in shaping personality expression within LLMs, offering valuable insights for future research on adaptive AI interactions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86PersonaPulse\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u4f18\u5316\u63d0\u793a\u8bcd\u663e\u8457\u63d0\u5347\u4e86LLMs\u7684\u4eba\u683c\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u8bc1\u660e\u63d0\u793a\u8bcd\u4f18\u5316\u5bf9\u4e2a\u6027\u5efa\u6a21\u4f5c\u7528\u91cd\u5927\u3002", "motivation": "\u4e2a\u6027\u5316\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u80fd\u591f\u63d0\u5347\u7528\u6237\u4e0eAI\u7684\u4ea4\u4e92\u4f53\u9a8c\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u901a\u8fc7\u63d0\u793a\u8bcd\u6fc0\u53d1\u6a21\u578b\u4eba\u683c\u7279\u8d28\u65b9\u9762\uff0c\u672a\u80fd\u4f18\u5316\u63d0\u793a\u8bcd\u4ee5\u6700\u5927\u5316\u4eba\u683c\u8868\u8fbe\u3002", "method": "\u63d0\u51faPersonaPulse\u6846\u67b6\uff0c\u52a8\u6001\u4f18\u5316\u89d2\u8272\u626e\u6f14\u63d0\u793a\u8bcd\uff0c\u5e76\u4f7f\u7528\u60c5\u5883\u53cd\u5e94\u57fa\u51c6\u4f5c\u4e3a\u8bc4\u5206\u5de5\u5177\uff0c\u5f15\u5bfc\u4f18\u5316\u6d41\u7a0b\u3002\u8be5\u65b9\u6cd5\u5229\u7528LLMs\u5bf9\u4eba\u683c\u7279\u8d28\u7684\u5185\u5728\u77e5\u8bc6\uff0c\u8fed\u4ee3\u63d0\u5347\u4eba\u683c\u8868\u8fbe\u7684\u771f\u5b9e\u611f\u4e0e\u60c5\u5883\u5951\u5408\u5ea6\u3002", "result": "PersonaPulse\u751f\u6210\u7684\u63d0\u793a\u8bcd\u5728\u5b9a\u91cf\u8bc4\u4f30\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u4e8e\u5fc3\u7406\u5b66\u63cf\u8ff0\u7684\u4f20\u7edf\u65b9\u6cd5\u3002\u5b9e\u9a8c\u8fd8\u63a2\u8ba8\u4e86\u6a21\u578b\u89c4\u6a21\u4e0e\u4eba\u683c\u5efa\u6a21\u7684\u5173\u7cfb\uff0c\u5e76\u53d1\u73b0\u67d0\u4e9b\u4eba\u683c\u7279\u8d28\u7684\u5c55\u73b0\u7a0b\u5ea6\u53ef\u901a\u8fc7\u6682\u505c\u4f18\u5316\u8fc7\u7a0b\u6765\u8c03\u63a7\u3002", "conclusion": "\u63d0\u793a\u8bcd\u4f18\u5316\u5bf9\u5851\u9020LLMs\u7684\u4eba\u683c\u8868\u8fbe\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u672a\u6765\u9002\u5e94\u6027AI\u4ea4\u4e92\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.19858", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19858", "abs": "https://arxiv.org/abs/2511.19858", "authors": ["Farzad Ahmed", "Joniel Augustine Jerome", "Meliha Yetisgen", "\u00d6zlem Uzuner"], "title": "A Systematic Analysis of Large Language Models with RAG-enabled Dynamic Prompting for Medical Error Detection and Correction", "comment": null, "summary": "Objective: Clinical documentation contains factual, diagnostic, and management errors that can compromise patient safety. Large language models (LLMs) may help detect and correct such errors, but their behavior under different prompting strategies remains unclear. We evaluate zero-shot prompting, static prompting with random exemplars (SPR), and retrieval-augmented dynamic prompting (RDP) for three subtasks of medical error processing: error flag detection, error sentence detection, and error correction.\n  Methods: Using the MEDEC dataset, we evaluated nine instruction-tuned LLMs (GPT, Claude, Gemini, and OpenAI o-series models). We measured performance using accuracy, recall, false-positive rate (FPR), and an aggregate score of ROUGE-1, BLEURT, and BERTScore for error correction. We also analyzed example outputs to identify failure modes and differences between LLM and clinician reasoning.\n  Results: Zero-shot prompting showed low recall in both detection tasks, often missing abbreviation-heavy or atypical errors. SPR improved recall but increased FPR. Across all nine LLMs, RDP reduced FPR by about 15 percent, improved recall by 5 to 10 percent in error sentence detection, and generated more contextually accurate corrections.\n  Conclusion: Across diverse LLMs, RDP outperforms zero-shot and SPR prompting. Using retrieved exemplars improves detection accuracy, reduces false positives, and enhances the reliability of medical error correction.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86\u4e09\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u7b56\u7565\u5728\u533b\u5b66\u6587\u6863\u9519\u8bef\u68c0\u6d4b\u548c\u7ea0\u6b63\u4e2d\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u68c0\u7d22\u589e\u5f3a\u52a8\u6001\u63d0\u793a\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u68c0\u6d4b\u53ec\u56de\u7387\u548c\u51c6\u786e\u7387\uff0c\u5e76\u6709\u6548\u51cf\u5c11\u8bef\u62a5\u3002", "motivation": "\u4e34\u5e8a\u6587\u6863\u5b58\u5728\u4e8b\u5b9e\u3001\u8bca\u65ad\u53ca\u7ba1\u7406\u9519\u8bef\uff0c\u8fd9\u4e9b\u9519\u8bef\u53ef\u80fd\u5f71\u54cd\u60a3\u8005\u5b89\u5168\u3002\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u88ab\u8ba4\u4e3a\u6709\u6f5c\u529b\u5e2e\u52a9\u53d1\u73b0\u548c\u7ea0\u6b63\u8fd9\u4e9b\u9519\u8bef\uff0c\u4f46\u9488\u5bf9\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u4e0bLLM\u8868\u73b0\u5c1a\u4e0d\u660e\u786e\uff0c\u56e0\u6b64\u9700\u7cfb\u7edf\u8bc4\u4f30\u8fd9\u4e9b\u65b9\u6cd5\u5728\u533b\u5b66\u9519\u8bef\u5904\u7406\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u91c7\u7528MEDEC\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u4e86\u4e5d\u79cd\u7ecf\u8fc7\u6307\u4ee4\u5fae\u8c03\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5305\u62ecGPT\u3001Claude\u3001Gemini\u53caOpenAI o-series\uff09\uff0c\u5206\u522b\u6d4b\u8bd5\u96f6\u6837\u672c\u63d0\u793a\u3001\u9759\u6001\u968f\u673a\u793a\u4f8b\u63d0\u793a\u4ee5\u53ca\u68c0\u7d22\u589e\u5f3a\u52a8\u6001\u63d0\u793a\u5728\u533b\u7597\u9519\u8bef\u68c0\u6d4b\u4e09\u5b50\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u901a\u8fc7\u51c6\u786e\u7387\u3001\u53ec\u56de\u7387\u3001\u8bef\u62a5\u7387\uff08FPR\uff09\u53caROUGE-1\u3001BLEURT\u548cBERTScore\u805a\u5408\u5206\u6570\u8bc4\u4f30\u7ea0\u9519\u6548\u679c\uff0c\u5e76\u5206\u6790\u6a21\u578b\u8f93\u51fa\u4e0e\u4e34\u5e8a\u533b\u751f\u63a8\u7406\u7684\u5dee\u5f02\u3002", "result": "\u96f6\u6837\u672c\u63d0\u793a\u5728\u68c0\u6d4b\u4efb\u52a1\u4e2d\u53ec\u56de\u7387\u8f83\u4f4e\uff0c\u5c24\u5176\u5bb9\u6613\u9057\u6f0f\u7f29\u5199\u6216\u975e\u5178\u578b\u9519\u8bef\u3002\u9759\u6001\u968f\u673a\u793a\u4f8b\u63d0\u793a\u63d0\u5347\u4e86\u53ec\u56de\u7387\u4f46\u589e\u52a0\u4e86\u8bef\u62a5\u3002\u68c0\u7d22\u589e\u5f3a\u52a8\u6001\u63d0\u793a\u5728\u6240\u6709\u6a21\u578b\u4e2d\u80fd\u663e\u8457\u964d\u4f4e\u8bef\u62a5\u7387\u7ea615%\u3001\u63d0\u5347\u53ec\u56de\u73875-10%\uff0c\u5e76\u751f\u6210\u66f4\u5177\u4e0a\u4e0b\u6587\u51c6\u786e\u6027\u7684\u9519\u8bef\u4fee\u6b63\u7ed3\u679c\u3002", "conclusion": "\u68c0\u7d22\u589e\u5f3a\u52a8\u6001\u63d0\u793a\u5728\u5404\u79cdLLM\u4e0a\u5747\u4f18\u4e8e\u96f6\u6837\u672c\u548c\u9759\u6001\u63d0\u793a\uff0c\u80fd\u591f\u63d0\u5347\u68c0\u6d4b\u51c6\u786e\u6027\u3001\u51cf\u5c11\u8bef\u62a5\uff0c\u5e76\u589e\u5f3a\u533b\u5b66\u9519\u8bef\u7ea0\u6b63\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.19957", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19957", "abs": "https://arxiv.org/abs/2511.19957", "authors": ["Tianyi Chen", "Michael Solodko", "Sen Wang", "Jongwoo Ko", "Junheng Hao", "Colby Banbury", "Sara Abdali", "Saeed Amizadeh", "Qing Xiao", "Yinheng Li", "Tianyu Ding", "Kamran Ghasedi Dizaji", "Suzhen Zheng", "Hao Fan", "Justin Wagle", "Pashmina Cameron", "Kazuhito Koishida"], "title": "AppSelectBench: Application-Level Tool Selection Benchmark", "comment": null, "summary": "Computer Using Agents (CUAs) are increasingly equipped with external tools, enabling them to perform complex and realistic tasks. For CUAs to operate effectively, application selection, which refers to deciding which application to use before invoking fine-grained tools such as APIs, is a fundamental capability. It determines whether the agent initializes the correct environment, avoids orchestration confusion, and efficiently focuses on relevant context. However, existing benchmarks primarily assess fine-grained API selection, offering limited insight into whether models can reason across and choose between different applications. To fill this gap, we introduce AppSelectBench, a comprehensive benchmark for evaluating application selection in CUAs. AppSelectBench contains a novel user task generation pipeline that produces realistic, diverse, and semantically grounded user intents at scale, together with unified evaluation protocols covering random, heuristic, zero-shot, few-shot, and retrieval-augmented-settings. AppSelectBench covers one hundred widely used desktop applications and includes more than one hundred thousand realistic, diverse, and semantically grounded user tasks. Extensive experiments across both closed-source and open-source large language models reveal systematic strengths and weaknesses in inter-application reasoning, showing that even the most capable models still struggle to make consistent application choices. Together, these results establish AppSelectBench as a foundation for studying and advancing application level reasoning, an essential yet underexplored capability of intelligent CUAs. The source is available at https://github.com/microsoft/appselectbench.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AppSelectBench\uff0c\u4e00\u5957\u7528\u4e8e\u8bc4\u6d4b\u667a\u80fd\u4f53\u5e94\u7528\u9009\u62e9\u80fd\u529b\u7684\u65b0\u57fa\u51c6\uff0c\u6db5\u76d6100\u4e2a\u5e94\u7528\u548c\u8d85\u8fc710\u4e07\u4e2a\u771f\u5b9e\u7528\u6237\u4efb\u52a1\u3002\u5b9e\u9a8c\u663e\u793a\u73b0\u6709\u5927\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u5c1a\u6709\u660e\u663e\u4e0d\u8db3\uff0cAppSelectBench\u4e3a\u63a8\u52a8\u667a\u80fd\u4f53\u5e94\u7528\u63a8\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u5e73\u53f0\u548c\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7684\u8bc4\u6d4b\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u4e8e\u7ec6\u7c92\u5ea6\u7684API\u9009\u62e9\uff0c\u96be\u4ee5\u53cd\u6620\u667a\u80fd\u4f53\u662f\u5426\u5177\u5907\u8de8\u5e94\u7528\u7a0b\u5e8f\u9009\u62e9\u4e0e\u63a8\u7406\u80fd\u529b\u3002\u800c\u5e94\u7528\u9009\u62e9\u5bf9\u4e8e\u667a\u80fd\u4f53\u521d\u59cb\u5316\u6b63\u786e\u73af\u5883\u3001\u907f\u514d\u64cd\u4f5c\u6df7\u4e71\u3001\u805a\u7126\u76f8\u5173\u4e0a\u4e0b\u6587\u5177\u6709\u57fa\u7840\u6027\u4f5c\u7528\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u66f4\u5168\u9762\u3001\u66f4\u5177\u4ee3\u8868\u6027\u7684\u8bc4\u6d4b\u6846\u67b6\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86AppSelectBench\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e13\u4e3a\u8bc4\u6d4b\u667a\u80fd\u4f53\u5e94\u7528\u9009\u62e9\u80fd\u529b\u800c\u8bbe\u8ba1\u7684\u57fa\u51c6\u3002\u5b83\u5305\u542b\u81ea\u52a8\u5316\u7684\u5927\u89c4\u6a21\u7528\u6237\u4efb\u52a1\u751f\u6210\u6d41\u7a0b\uff0c\u8986\u76d6100\u4e2a\u5e38\u7528\u5e94\u7528\u548c\u8d85\u8fc710\u4e07\u4e2a\u771f\u5b9e\u8bed\u4e49\u4efb\u52a1\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u8bc4\u6d4b\u534f\u8bae\uff08\u5982\u968f\u673a\u3001\u542f\u53d1\u5f0f\u3001\u96f6\u6837\u672c\u3001\u5c0f\u6837\u672c\u548c\u68c0\u7d22\u589e\u5f3a\u8bbe\u7f6e\uff09\u3002", "result": "\u901a\u8fc7\u5728\u95ed\u6e90\u548c\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\uff0c\u73b0\u6709\u6a21\u578b\u5728\u8de8\u5e94\u7528\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u7cfb\u7edf\u6027\u7684\u4f18\u7f3a\u70b9\uff0c\u751a\u81f3\u80fd\u529b\u6700\u5f3a\u7684\u6a21\u578b\u5728\u4e00\u81f4\u6027\u5e94\u7528\u9009\u62e9\u65b9\u9762\u4f9d\u7136\u5b58\u5728\u8f83\u5927\u6311\u6218\u3002", "conclusion": "AppSelectBench\u4e3a\u7814\u7a76\u548c\u63a8\u52a8\u667a\u80fd\u4f53\u5e94\u7528\u7ea7\u522b\u63a8\u7406\u80fd\u529b\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u53d1\u6398\u548c\u63d0\u5347CUA\u5c1a\u672a\u5145\u5206\u5f00\u53d1\u7684\u91cd\u8981\u80fd\u529b\u3002"}}
{"id": "2511.19987", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.19987", "abs": "https://arxiv.org/abs/2511.19987", "authors": ["Xinyu Wang", "Hanwei Wu", "Qingchen Hu", "Zhenghan Tai", "Jingrui Tian", "Lei Ding", "Jijun Chi", "Hailin He", "Tung Sum Thomas Kwok", "Yufei Cui", "Sicheng Lyu", "Muzhi Li", "Mingze Li", "Xinyue Yu", "Ling Zhou", "Peng Lu"], "title": "$\\text{R}^2\\text{R}$: A Route-to-Rerank Post-Training Framework for Multi-Domain Decoder-Only Rerankers", "comment": "13 pages, including 3 figures and 3 tables", "summary": "Decoder-only rerankers are central to Retrieval-Augmented Generation (RAG). However, generalist models miss domain-specific nuances in high-stakes fields like finance and law, and naive fine-tuning causes surface-form overfitting and catastrophic forgetting. To address this challenge, we introduce R2R, a domain-aware framework that combines dynamic expert routing with a two-stage training strategy, Entity Abstraction for Generalization (EAG). EAG introduces a counter-shortcut mechanism by masking the most predictive surface cues, forcing the reranker to learn domain-invariant relevance patterns rather than memorizing dataset-specific entities. To efficiently activate domain experts, R2R employs a lightweight Latent Semantic Router that probes internal representations from the frozen backbone decoder to select the optimal LoRA expert per query. Extensive experiments across different reranker backbones and diverse domains (legal, medical, and financial) demonstrate that R2R consistently surpasses generalist and single-domain fine-tuned baselines. Our results confirm that R2R is a model-agnostic and modular approach to domain specialization with strong cross-domain robustness.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa R2R \u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u4e13\u5bb6\u8def\u7531\u4e0e\u53cd\u6377\u5f84\u5b9e\u4f53\u62bd\u8c61\u8bad\u7ec3\uff0c\u6709\u6548\u89e3\u51b3\u9ad8\u4e13\u4e1a\u9886\u57df reranker \u6a21\u578b\u7684\u8868\u9762\u8fc7\u62df\u5408\u548c\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u3002\u5728\u6cd5\u5f8b\u3001\u91d1\u878d\u3001\u533b\u5b66\u7b49\u9886\u57df\u6d4b\u8bd5\u4f18\u4e8e\u901a\u7528\u548c\u5355\u9886\u57df\u5fae\u8c03\u6a21\u578b\uff0c\u8868\u73b0\u51fa\u5f88\u5f3a\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u4e0e\u9c81\u68d2\u6027\uff0c\u65b9\u6848\u901a\u7528\u53ef\u6a21\u5757\u5316\u96c6\u6210\u3002", "motivation": "\u89e3\u7801\u5668\u4ec5 reranker \u5728 Retrieval-Augmented Generation\uff08RAG\uff09\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\uff0c\u4f46\u901a\u7528\u6a21\u578b\u5728\u91d1\u878d\u3001\u6cd5\u5f8b\u7b49\u9ad8\u5ea6\u4e13\u4e1a\u5316\u9886\u57df\u96be\u4ee5\u6355\u6349\u9886\u57df\u7279\u6709\u7ec6\u8282\uff0c\u800c\u76f4\u63a5\u5fae\u8c03\u5bb9\u6613\u5bfc\u81f4\u8868\u9762\u7279\u5f81\u8fc7\u62df\u5408\u53ca\u707e\u96be\u9057\u5fd8\u3002", "method": "\u63d0\u51fa R2R \u6846\u67b6\uff0c\u7ed3\u5408\u52a8\u6001\u4e13\u5bb6\u8def\u7531\u4e0e\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u3002\u901a\u8fc7 Entity Abstraction for Generalization\uff08EAG\uff09\uff0c\u91c7\u7528\u53cd\u6377\u5f84\u673a\u5236\uff0c\u906e\u853d\u6700\u5177\u9884\u6d4b\u6027\u7684\u5b9e\u4f53\u8868\u9762\u7ebf\u7d22\uff0c\u4fc3\u8fdb\u6a21\u578b\u5b66\u4e60\u9886\u57df\u4e0d\u53d8\u7684\u76f8\u5173\u6027\u6a21\u5f0f\u3002\u540c\u65f6\uff0c\u5f15\u5165 Latent Semantic Router \u4ece\u51bb\u7ed3\u7684\u4e3b\u5e72\u89e3\u7801\u5668\u5185\u90e8\u8868\u5f81\u4e2d\u9009\u62e9\u6700\u4f18 LoRA \u4e13\u5bb6\uff0c\u4ee5\u9ad8\u6548\u6fc0\u6d3b\u9886\u57df\u4e13\u5bb6\u3002", "result": "\u5728\u4e0d\u540c reranker \u4e3b\u5e72\u548c\u591a\u4e2a\u9886\u57df\uff08\u6cd5\u5f8b\u3001\u533b\u5b66\u3001\u91d1\u878d\uff09\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cR2R \u7684\u8868\u73b0\u4f18\u4e8e\u901a\u7528\u6a21\u578b\u548c\u5355\u9886\u57df\u5fae\u8c03\u57fa\u7ebf\u3002", "conclusion": "R2R \u662f\u4e00\u79cd\u5bf9\u6a21\u578b\u7b97\u6cd5\u65e0\u5173\u4e14\u6a21\u5757\u5316\u7684\u9886\u57df\u4e13\u7528\u65b9\u6cd5\uff0c\u5177\u6709\u5f88\u5f3a\u7684\u8de8\u9886\u57df\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.19997", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19997", "abs": "https://arxiv.org/abs/2511.19997", "authors": ["Mihir Sahasrabudhe"], "title": "Directional Optimization Asymmetry in Transformers: A Synthetic Stress Test", "comment": "19 pages, 4 figures. Code available at https://github.com/mihirs-0/synass", "summary": "Transformers are theoretically reversal-invariant: their function class does not prefer left-to-right over right-to-left mappings. Yet empirical studies on natural language repeatedly report a \"reversal curse,\" and recent work on temporal asymmetry in LLMs suggests that real-world corpora carry their own arrow of time. This leaves an unresolved question: do directional failures stem from linguistic statistics, or from the architecture itself? We cut through this ambiguity with a fully synthetic, entropy-controlled benchmark designed as a clean-room stress test for directional learning. Using random string mappings with tunable branching factor K, we construct forward tasks with zero conditional entropy and inverse tasks with analytically determined entropy floors. Excess loss above these floors reveals that even scratch-trained GPT-2 models exhibit a strong, reproducible directional optimization gap (e.g., 1.16 nats at K=5), far larger than that of an MLP trained on the same data. Pre-trained initializations shift optimization behavior but do not eliminate this gap, while LoRA encounters a sharp capacity wall on high-entropy inverse mappings. Together, these results isolate a minimal, semantics-free signature of directional friction intrinsic to causal Transformer training-one that persists even when linguistic priors, token frequencies, and corpus-level temporal asymmetries are removed. Our benchmark provides a controlled instrument for dissecting directional biases in modern sequence models and motivates deeper mechanistic study of why inversion remains fundamentally harder for Transformers.", "AI": {"tldr": "\u5373\u4f7f\u6392\u9664\u8bed\u4e49\u548c\u8bed\u6599\u7279\u5f81\uff0c\u4ec5\u9760\u67b6\u6784\u672c\u8eab\uff0cTransformer\u4f9d\u7136\u5bf9\u9006\u5e8f\u5b66\u4e60\u8868\u73b0\u51fa\u56fa\u6709\u56f0\u96be\uff1b\u8bba\u6587\u63d0\u51fa\u65b0\u57fa\u51c6\u63ed\u793a\u8be5\u504f\u5dee\uff0c\u63a8\u52a8\u673a\u5236\u89e3\u91ca\u3002", "motivation": "Transformer\u6a21\u578b\u7406\u8bba\u4e0a\u5bf9\u5e8f\u5217\u65b9\u5411\u662f\u65e0\u504f\u7684\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u5374\u5e38\u51fa\u73b0\u201c\u65b9\u5411\u6027\u8bc5\u5492\u201d\uff0c\u5373\u5bf9\u9006\u5e8f\u9884\u6d4b\u6bd4\u6b63\u5e8f\u9884\u6d4b\u8868\u73b0\u5dee\u3002\u79d1\u5b66\u754c\u5c1a\u4e0d\u6e05\u695a\u8fd9\u79cd\u73b0\u8c61\u662f\u7531\u8bed\u8a00\u6570\u636e\u672c\u8eab\uff0c\u8fd8\u662f\u6a21\u578b\u7ed3\u6784\u5f15\u8d77\u3002\u672c\u6587\u65e8\u5728\u6d88\u9664\u6570\u636e\u7edf\u8ba1\u56e0\u7d20\u5f71\u54cd\uff0c\u7eaf\u7cb9\u8003\u5bdf\u67b6\u6784\u5bf9\u65b9\u5411\u6027\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u5168\u5408\u6210\u3001\u71b5\u53ef\u63a7\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5229\u7528\u53ef\u8c03\u5206\u652f\u56e0\u5b50K\u751f\u6210\u968f\u673a\u5b57\u7b26\u4e32\u6620\u5c04\uff0c\u5206\u8bbe\u96f6\u6761\u4ef6\u71b5\u7684\u6b63\u5411\u4efb\u52a1\uff0c\u4ee5\u53ca\u71b5\u4e0b\u9650\u5df2\u77e5\u7684\u9006\u5411\u4efb\u52a1\u3002\u901a\u8fc7\u5bf9GPT-2\u53caMLP\u6a21\u578b\u4ece\u96f6\u8bad\u7ec3\u4e0e\u9884\u8bad\u7ec3\u521d\u59cb\u6761\u4ef6\u7684\u6d4b\u8bd5\uff0c\u7cfb\u7edf\u5206\u6790\u5176\u65b9\u5411\u6027\u5b66\u4e60\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5373\u4fbf\u6d88\u9664\u4e86\u8bed\u4e49\u3001\u9891\u7387\u548c\u65f6\u95f4\u5148\u9a8c\uff0c\u4ec5\u5728\u5408\u6210\u73af\u5883\u4e2d\u8bad\u7ec3\uff0cGPT-2\u4f9d\u7136\u5b58\u5728\u660e\u663e\u7684\u65b9\u5411\u6027\u4f18\u5316\u5dee\u8ddd\uff08\u5982K=5\u65f6\uff0c\u9006\u5e8f\u591a1.16 nats\u635f\u5931\uff09\uff0c\u9ad8\u4e8eMLP\u3002\u9884\u8bad\u7ec3\u53ea\u80fd\u90e8\u5206\u7f13\u89e3\uff0cLoRA\u5728\u9ad8\u71b5\u9006\u4efb\u52a1\u4e0a\u5f88\u5feb\u9047\u5230\u5bb9\u91cf\u74f6\u9888\u3002\u8868\u660e\u65b9\u5411\u6027\u6469\u64e6\u662fTransformer\u8bad\u7ec3\u7684\u5185\u5728\u7279\u6027\u3002", "conclusion": "\u8bba\u6587\u9996\u6b21\u5728\u4e25\u683c\u53d7\u63a7\u5408\u6210\u4efb\u52a1\u4e0b\uff0c\u8bc1\u5b9e\u4e86Transformer\u6a21\u578b\u9006\u5e8f\u5b66\u4e60\u66f4\u96be\u7684\u65b9\u5411\u6027\u504f\u5dee\u5373\u4f7f\u4e0d\u4f9d\u8d56\u8bed\u4e49\u548c\u8bed\u6599\u7279\u70b9\u4e5f\u666e\u904d\u5b58\u5728\uff0c\u8fd9\u4e00\u73b0\u8c61\u4e0e\u6a21\u578b\u8bad\u7ec3\u673a\u5236\u76f8\u5173\u3002\u8be5\u57fa\u51c6\u4e3a\u5256\u6790\u5e8f\u5217\u6a21\u578b\u65b9\u5411\u6027\u504f\u5dee\u53ca\u5176\u673a\u5236\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u9a8c\u5de5\u5177\u548c\u52a8\u673a\u3002"}}
{"id": "2511.20001", "categories": ["cs.CL", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.20001", "abs": "https://arxiv.org/abs/2511.20001", "authors": ["Edward Ajayi", "Martha Kachweka", "Mawuli Deku", "Emily Aiken"], "title": "A Machine Learning Approach for Detection of Mental Health Conditions and Cyberbullying from Social Media", "comment": "Accepted for Oral Presentation at the AAAI-26 Bridge Program on AI for Medicine and Healthcare (AIMedHealth). To appear in Proceedings of Machine Learning Research (PMLR)", "summary": "Mental health challenges and cyberbullying are increasingly prevalent in digital spaces, necessitating scalable and interpretable detection systems. This paper introduces a unified multiclass classification framework for detecting ten distinct mental health and cyberbullying categories from social media data. We curate datasets from Twitter and Reddit, implementing a rigorous \"split-then-balance\" pipeline to train on balanced data while evaluating on a realistic, held-out imbalanced test set. We conducted a comprehensive evaluation comparing traditional lexical models, hybrid approaches, and several end-to-end fine-tuned transformers. Our results demonstrate that end-to-end fine-tuning is critical for performance, with the domain-adapted MentalBERT emerging as the top model, achieving an accuracy of 0.92 and a Macro F1 score of 0.76, surpassing both its generic counterpart and a zero-shot LLM baseline. Grounded in a comprehensive ethical analysis, we frame the system as a human-in-the-loop screening aid, not a diagnostic tool. To support this, we introduce a hybrid SHAPLLM explainability framework and present a prototype dashboard (\"Social Media Screener\") designed to integrate model predictions and their explanations into a practical workflow for moderators. Our work provides a robust baseline, highlighting future needs for multi-label, clinically-validated datasets at the critical intersection of online safety and computational mental health.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u591a\u5206\u7c7b\u68c0\u6d4b\u6846\u67b6\uff0c\u9488\u5bf9\u793e\u4ea4\u5a92\u4f53\u5fc3\u7406\u5065\u5eb7\u4e0e\u7f51\u7edc\u6b3a\u51cc\uff0cMentalBERT\u8868\u73b0\u6700\u4f73\u3002\u7cfb\u7edf\u5f3a\u8c03\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u4f5c\u4e3a\u4eba\u5de5\u8f85\u52a9\u5de5\u5177\uff0c\u63a8\u52a8\u672a\u6765\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u5efa\u8bbe\u3002", "motivation": "\u6570\u5b57\u7a7a\u95f4\u4e2d\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\u548c\u7f51\u7edc\u6b3a\u51cc\u73b0\u8c61\u65e5\u76ca\u4e25\u91cd\uff0c\u73b0\u6709\u68c0\u6d4b\u7cfb\u7edf\u53ef\u6269\u5c55\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\uff0c\u4e9f\u9700\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u591a\u7c7b\u522b\u8bc6\u522b\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u7edf\u4e00\u591a\u5206\u7c7b\u6846\u67b6\uff0c\u68c0\u6d4b\u793e\u4ea4\u5a92\u4f53\u4e2d\u7684\u5341\u7c7b\u5fc3\u7406\u5065\u5eb7\u548c\u7f51\u7edc\u6b3a\u51cc\u7c7b\u522b\u3002\u6570\u636e\u6765\u6e90\u4e3aTwitter\u548cReddit\uff0c\u91c7\u7528\u201csplit-then-balance\u201d\u6570\u636e\u5904\u7406\u6d41\u7a0b\uff0c\u5728\u5e73\u8861\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u5e76\u5728\u4e0d\u5e73\u8861\u771f\u5b9e\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\u3002\u6a21\u578b\u8bc4\u4f30\u5305\u542b\u4f20\u7edf\u8bcd\u6c47\u3001\u6df7\u5408\u65b9\u6cd5\u4ee5\u53ca\u7aef\u5230\u7aef\u5fae\u8c03\u7684Transformer\u6a21\u578b\u3002\u5f15\u5165\u4e86SHAPLLM\u53ef\u89e3\u91ca\u6027\u6846\u67b6\uff0c\u4ee5\u53ca\u96c6\u6210\u9884\u6d4b\u4e0e\u89e3\u91ca\u7684\u539f\u578b\u4eea\u8868\u76d8\u3002", "result": "\u7aef\u5230\u7aef\u5fae\u8c03Transformer\u6027\u80fd\u6700\u4f73\uff0cMentalBERT\u6a21\u578b\u51c6\u786e\u7387\u8fbe0.92\uff0cMacro F1\u4e3a0.76\uff0c\u4f18\u4e8e\u901a\u7528\u6a21\u578b\u548c\u96f6\u6837\u672c\u5927\u8bed\u8a00\u6a21\u578b\u3002\u7cfb\u7edf\u4f5c\u4e3a\u4eba\u5de5\u8f85\u52a9\u7b5b\u67e5\u5de5\u5177\u800c\u975e\u8bca\u65ad\u5de5\u5177\u3002", "conclusion": "\u6587\u4e2d\u65b9\u6cd5\u4e3a\u7f51\u7edc\u5b89\u5168\u4e0e\u8ba1\u7b97\u5fc3\u7406\u5065\u5eb7\u4ea4\u53c9\u9886\u57df\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7ebf\uff0c\u5e76\u5f3a\u8c03\u672a\u6765\u9700\u591a\u6807\u7b7e\u3001\u4e34\u5e8a\u9a8c\u8bc1\u7684\u6570\u636e\u96c6\u3002"}}
{"id": "2511.20056", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20056", "abs": "https://arxiv.org/abs/2511.20056", "authors": ["Huiyu Bai", "Runze Wang", "Zhuoyun Du", "Yiyang Zhao", "Fengji Zhang", "Haoyu Chen", "Xiaoyong Zhu", "Bo Zheng", "Xuejiao Zhao"], "title": "Online-PVLM: Advancing Personalized VLMs with Online Concept Learning", "comment": "Work in Progress", "summary": "Personalized Visual Language Models (VLMs) are gaining increasing attention for their formidable ability in user-specific concepts aligned interactions (e.g., identifying a user's bike). Existing methods typically require the learning of separate embeddings for each new concept, which fails to support real-time adaptation during testing. This limitation becomes particularly pronounced in large-scale scenarios, where efficient retrieval of concept embeddings is not achievable. To alleviate this gap, we propose Online-PVLM, a framework for online concept learning by leveraging hyperbolic representations. Our approach makes a train-free paradigm for concept embeddings generation at test time, making the use of personalized VLMs both scalable and efficient. In addition, we develop OP-Eval, a comprehensive and large-scale benchmark comprising 1,292 concepts and over 30K high-quality instances with diverse question types, designed to rigorously assess online concept learning in realistic scenarios. Extensive experiments demonstrate the state-of-the-art performance of our proposed framework. Our source code and dataset will be made available.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u65e0\u9700\u8bad\u7ec3\u3001\u5728\u7ebf\u751f\u6210\u4e2a\u6027\u5316\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6982\u5ff5\u5d4c\u5165\u7684\u65b0\u6846\u67b6Online-PVLM\uff0c\u5e76\u5f00\u53d1\u5927\u89c4\u6a21\u8bc4\u6d4b\u96c6OP-Eval\uff0c\u5728\u771f\u5b9e\u573a\u666f\u4e0b\u5b9e\u73b0\u9ad8\u6548\u548c\u9886\u5148\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u4e2a\u6027\u5316\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u7528\u6237\u4e13\u5c5e\u6982\u5ff5\u4ea4\u4e92\u6548\u7387\u4e0a\u53d7\u5230\u9650\u5236\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u573a\u666f\u4e2d\uff0c\u5b9e\u65f6\u751f\u6210\u548c\u68c0\u7d22\u6982\u5ff5\u5d4c\u5165\u8f83\u4e3a\u56f0\u96be\u3002", "method": "\u63d0\u51faOnline-PVLM\u6846\u67b6\uff0c\u91c7\u7528\u8d85\u7403\u9762\u8868\u793a\uff0c\u5b9e\u73b0\u6d4b\u8bd5\u9636\u6bb5\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u751f\u6210\u6982\u5ff5\u5d4c\u5165\uff0c\u4ece\u800c\u63d0\u5347VLM\u7684\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\u3002\u540c\u65f6\u5f00\u53d1\u4e86OP-Eval\u57fa\u51c6\uff0c\u5305\u62ec1292\u4e2a\u6982\u5ff5\u548c3\u4e07\u591a\u4e2a\u9ad8\u8d28\u91cf\u5b9e\u4f8b\uff0c\u7528\u4e8e\u771f\u5b9e\u573a\u666f\u5728\u7ebf\u6982\u5ff5\u5b66\u4e60\u7684\u8bc4\u4f30\u3002", "result": "\u5728\u7ebf\u548c\u5927\u89c4\u6a21\u6761\u4ef6\u4e0b\uff0cOnline-PVLM\u5c55\u73b0\u4e86\u9886\u5148\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Online-PVLM\u514b\u670d\u4e86\u73b0\u6709\u4e2a\u6027\u5316VLM\u5b9e\u73b0\u5b9e\u65f6\u81ea\u9002\u5e94\u7684\u74f6\u9888\uff0c\u901a\u8fc7\u65e0\u8bad\u7ec3\u751f\u6210\u3001\u9ad8\u6548\u6269\u5c55\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63a8\u52a8\u4e86\u4e2a\u6027\u5316\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u843d\u5730\u4e0e\u53d1\u5c55\u3002"}}
{"id": "2511.20072", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20072", "abs": "https://arxiv.org/abs/2511.20072", "authors": ["Xiaopeng Li", "Yuanjin Zheng", "Wanyu Wang", "wenlin zhang", "Pengyue Jia", "Yiqi Wang", "Maolin Wang", "Xuetao Wei", "Xiangyu Zhao"], "title": "MTA: A Merge-then-Adapt Framework for Personalized Large Language Model", "comment": null, "summary": "Personalized Large Language Models (PLLMs) aim to align model outputs with individual user preferences, a crucial capability for user-centric applications. However, the prevalent approach of fine-tuning a separate module for each user faces two major limitations: (1) storage costs scale linearly with the number of users, rendering the method unscalable; and (2) fine-tuning a static model from scratch often yields suboptimal performance for users with sparse data. To address these challenges, we propose MTA, a Merge-then-Adapt framework for PLLMs. MTA comprises three key stages. First, we construct a shared Meta-LoRA Bank by selecting anchor users and pre-training meta-personalization traits within meta-LoRA modules. Second, to ensure scalability and enable dynamic personalization combination beyond static models, we introduce an Adaptive LoRA Fusion stage. This stage retrieves and dynamically merges the most relevant anchor meta-LoRAs to synthesize a user-specific one, thereby eliminating the need for user-specific storage and supporting more flexible personalization. Third, we propose a LoRA Stacking for Few-Shot Personalization stage, which applies an additional ultra-low-rank, lightweight LoRA module on top of the merged LoRA. Fine-tuning this module enables effective personalization under few-shot settings. Extensive experiments on the LaMP benchmark demonstrate that our approach outperforms existing SOTA methods across multiple tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u65e0\u9700\u4e3a\u6bcf\u4f4d\u7528\u6237\u5206\u522b\u5fae\u8c03\u7684\u4e2a\u6027\u5316\u5927\u6a21\u578b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5171\u4eab\u4e0e\u52a8\u6001\u5408\u6210\u7684LoRA\u6a21\u5757\uff0c\u9ad8\u6548\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u4e14\u9488\u5bf9\u5c11\u6837\u672c\u66f4\u53cb\u597d\u7684\u4e2a\u6027\u5316\u5927\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u4e2a\u4eba\u5316\u5927\u6a21\u578b\u7684\u8bad\u7ec3\u65b9\u5f0f\u9700\u8981\u4e3a\u6bcf\u4e2a\u7528\u6237\u5206\u522b\u5fae\u8c03\u4e00\u4e2a\u6a21\u5757\uff0c\u5bfc\u81f4\u5b58\u50a8\u6210\u672c\u968f\u7528\u6237\u6570\u7ebf\u6027\u589e\u957f\uff0c\u4e14\u5bf9\u4e8e\u6570\u636e\u7a00\u758f\u7528\u6237\u6548\u679c\u4e0d\u4f73\uff0c\u96be\u4ee5\u6269\u5c55\u3002", "method": "\u63d0\u51faMTA\uff08Merge-then-Adapt\uff09\u6846\u67b6\u3002\u5305\u62ec\u4e09\u6b65\uff1a\uff081\uff09\u901a\u8fc7\u951a\u70b9\u7528\u6237\u9884\u8bad\u7ec3meta-LoRA\uff0c\u6784\u5efa\u5171\u4eab\u7684Meta-LoRA Bank\uff1b\uff082\uff09\u901a\u8fc7Adaptive LoRA Fusion\uff0c\u4eceBank\u4e2d\u68c0\u7d22\u548c\u52a8\u6001\u5408\u5e76\u76f8\u5173meta-LoRA\uff0c\u5b9e\u73b0\u65e0\u7528\u6237\u7279\u5b9a\u5b58\u50a8\u7684\u52a8\u6001\u4e2a\u6027\u5316\uff1b\uff083\uff09\u5c11\u6837\u672c\u6761\u4ef6\u4e0b\u518d\u53e0\u52a0\u4e00\u4e2a\u8d85\u4f4e\u79e9LoRA\u8fdb\u884c\u8f7b\u91cf\u5fae\u8c03\u3002", "result": "\u5728LaMP\u57fa\u51c6\u4efb\u52a1\u4e0a\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7Merge-then-Adapt\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4e2a\u6027\u5316\u5927\u6a21\u578b\u5728\u5b58\u50a8\u548c\u6570\u636e\u7a00\u758f\u573a\u666f\u4e0b\u7684\u6269\u5c55\u4e0e\u6548\u679c\u96be\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u4e2a\u6027\u5316\u6a21\u578b\u8f93\u51fa\u3002"}}
{"id": "2511.20086", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20086", "abs": "https://arxiv.org/abs/2511.20086", "authors": ["Duc Anh Vu", "Thong Nguyen", "Cong-Duy Nguyen", "Viet Anh Nguyen", "Anh Tuan Luu"], "title": "More Bias, Less Bias: BiasPrompting for Enhanced Multiple-Choice Question Answering", "comment": "Accepted at the 41st ACM/SIGAPP Symposium On Applied Computing (SAC 2026), Main Conference", "summary": "With the advancement of large language models (LLMs), their performance on multiple-choice question (MCQ) tasks has improved significantly. However, existing approaches face key limitations: answer choices are typically presented to LLMs without contextual grounding or explanation. This absence of context can lead to incomplete exploration of all possible answers, ultimately degrading the models' reasoning capabilities. To address these challenges, we introduce BiasPrompting, a novel inference framework that guides LLMs to generate and critically evaluate reasoning across all plausible answer options before reaching a final prediction. It consists of two components: first, a reasoning generation stage, where the model is prompted to produce supportive reasonings for each answer option, and then, a reasoning-guided agreement stage, where the generated reasonings are synthesized to select the most plausible answer. Through comprehensive evaluations, BiasPrompting demonstrates significant improvements in five widely used multiple-choice question answering benchmarks. Our experiments showcase that BiasPrompting enhances the reasoning capabilities of LLMs and provides a strong foundation for tackling complex and challenging questions, particularly in settings where existing methods underperform.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u751f\u6210\u5e76\u7efc\u5408\u6bcf\u4e2a\u9009\u9879\u7406\u7531\u7684\u65b0\u63a8\u7406\u6846\u67b6BiasPrompting\uff0c\u663e\u8457\u63d0\u5347\u5927\u6a21\u578b\u5728\u9009\u62e9\u9898\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u548c\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u5927\u6a21\u578b\u5728\u591a\u9879\u9009\u62e9\u9898\u4efb\u52a1\u4e2d\u867d\u7136\u8868\u73b0\u63d0\u5347\uff0c\u4f46\u56de\u7b54\u9009\u9879\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u548c\u7406\u7531\u8bf4\u660e\uff0c\u5bfc\u81f4\u63a8\u7406\u4e0d\u5145\u5206\u3001\u51c6\u786e\u7387\u53d7\u5f71\u54cd\u3002", "method": "\u63d0\u51faBiasPrompting\u63a8\u7406\u6846\u67b6\uff0c\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a\u9996\u5148\u751f\u6210\u6bcf\u4e2a\u9009\u9879\u7684\u652f\u6301\u6027\u7406\u7531\uff0c\u518d\u7efc\u5408\u6240\u6709\u7406\u7531\u6765\u9009\u62e9\u6700\u5408\u7406\u7b54\u6848\u3002", "result": "\u5728\u4e94\u4e2a\u4e3b\u6d41\u591a\u9879\u9009\u62e9\u9898\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u6a21\u578b\u8868\u73b0\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u95ee\u9898\u6216\u73b0\u6709\u65b9\u6cd5\u6548\u679c\u8f83\u5dee\u7684\u573a\u666f\u4e0b\u63d0\u5347\u5927\u6a21\u578b\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "BiasPrompting\u80fd\u591f\u6709\u6548\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u89e3\u51b3\u590d\u6742\u9009\u62e9\u9898\u548c\u63d0\u5347\u7b54\u6848\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2511.20102", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20102", "abs": "https://arxiv.org/abs/2511.20102", "authors": ["Zhenyi Shen", "Junru Lu", "Lin Gui", "Jiazheng Li", "Yulan He", "Di Yin", "Xing Sun"], "title": "SSA: Sparse Sparse Attention by Aligning Full and Sparse Attention Outputs in Feature Space", "comment": "28 pages", "summary": "The quadratic complexity of full attention limits efficient long-context processing in large language models (LLMs). Sparse attention mitigates this cost by restricting each query to attend to a subset of previous tokens; however, training-free approaches often lead to severe performance degradation. Native sparse-attention methods (e.g., NSA, MoBA) alleviate this issue, yet exhibit a critical paradox: they produce lower attention sparsity than full-attention models, despite aiming to approximate full attention, which may constrain their effectiveness. We attribute this paradox to gradient update deficiency: low-ranked key-value pairs excluded during sparse training receive neither forward contribution nor backward gradients, and thus never learn proper suppression. To overcome this limitation, we propose SSA (Sparse Sparse Attention), a unified training framework that considers both sparse and full attention and enforces bidirectional alignment at every layer. This design preserves gradient flow to all tokens while explicitly encouraging sparse-attention outputs to align with their full-attention counterparts, thereby promoting stronger sparsity. As a result, SSA achieves state-of-the-art performance under both sparse and full attention inference across multiple commonsense benchmarks. Furthermore, SSA enables models to adapt smoothly to varying sparsity budgets; performance improves consistently as more tokens are allowed to attend, supporting flexible compute-performance trade-offs at inference time. Finally, we show that native sparse-attention training surprisingly improves long-context extrapolation by mitigating the over-allocation of attention values in sink areas, with SSA demonstrating the strongest extrapolation capability.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u6ce8\u610f\u529b\u673a\u5236\u8ba1\u7b97\u74f6\u9888\uff0c\u63d0\u51fa\u4e86SSA\u6846\u67b6\uff0c\u7ed3\u5408\u7a00\u758f\u548c\u5168\u6ce8\u610f\u529b\u8bad\u7ec3\uff0c\u89e3\u51b3\u4e86\u68af\u5ea6\u4e0d\u8db3\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660eSSA\u663e\u8457\u63d0\u5347\u4e86\u7a00\u758f\u6ce8\u610f\u529b\u6027\u80fd\u548c\u957f\u6587\u672c\u5904\u7406\u80fd\u529b\uff0c\u5e76\u53ef\u7075\u6d3b\u8c03\u6574\u63a8\u7406\u8ba1\u7b97\u91cf\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u7531\u4e8e\u5927\u6a21\u578b\u7684\u5168\u6ce8\u610f\u529b\uff08full attention\uff09\u5177\u6709\u4e8c\u6b21\u590d\u6742\u5ea6\uff0c\u5bfc\u81f4\u5904\u7406\u957f\u6587\u672c\u53d8\u5f97\u4f4e\u6548\u3002\u867d\u7136\u7a00\u758f\u6ce8\u610f\u529b\uff08sparse attention\uff09\u80fd\u591f\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u4f46\u76ee\u524d\u65e0\u8bad\u7ec3\u7684\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\u6027\u80fd\u4e0b\u964d\u660e\u663e\uff0c\u800c\u539f\u751f\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\u53c8\u5b58\u5728\u6ce8\u610f\u529b\u7a00\u758f\u5ea6\u4e0d\u8db3\u7684\u6096\u8bba\u3002\u4f5c\u8005\u5206\u6790\u8fd9\u79cd\u6096\u8bba\u662f\u68af\u5ea6\u66f4\u65b0\u4e0d\u8db3\u5bfc\u81f4\u7684\uff0c\u5fc5\u987b\u89e3\u51b3\u6b64\u95ee\u9898\u4ee5\u63d0\u5347\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u6548\u7387\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u8bad\u7ec3\u6846\u67b6SSA\uff08Sparse Sparse Attention\uff09\uff0c\u7ed3\u5408\u4e86\u7a00\u758f\u4e0e\u5168\u6ce8\u610f\u529b\uff0c\u901a\u8fc7\u6bcf\u4e00\u5c42\u7684\u53cc\u5411\u5bf9\u9f50\uff0c\u4fdd\u6301\u6240\u6709\u4ee4\u724c\u7684\u68af\u5ea6\u6d41\u52a8\u3002\u8be5\u65b9\u6cd5\u8ba9\u7a00\u758f\u6ce8\u610f\u529b\u7684\u8f93\u51fa\u66f4\u63a5\u8fd1\u5168\u6ce8\u610f\u529b\uff0c\u540c\u65f6\u5b9e\u73b0\u66f4\u5f3a\u7a00\u758f\u6027\u3002", "result": "SSA\u6846\u67b6\u5728\u591a\u79cd\u5e38\u8bc6\u57fa\u51c6\u6d4b\u8bd5\u4e0b\uff0c\u7a00\u758f\u548c\u5168\u6ce8\u610f\u529b\u63a8\u7406\u90fd\u8fbe\u5230\u4e86\u6700\u65b0\u6c34\u5e73\u3002\u6a21\u578b\u80fd\u591f\u7075\u6d3b\u9002\u5e94\u4e0d\u540c\u7a00\u758f\u9884\u7b97\uff0c\u4ee4\u6027\u80fd\u4e0e\u63a8\u7406\u8ba1\u7b97\u91cf\u53ef\u5e73\u8861\u3002\u540c\u65f6\uff0c\u539f\u751f\u7a00\u758f\u8bad\u7ec3\u663e\u8457\u63d0\u5347\u4e86\u957f\u6587\u672c\u5916\u63a8\u80fd\u529b\uff0cSSA\u8868\u73b0\u6700\u4f18\u3002", "conclusion": "SSA\u8bad\u7ec3\u6846\u67b6\u4e0d\u4ec5\u63d0\u5347\u4e86\u7a00\u758f\u6ce8\u610f\u529b\u7684\u6027\u80fd\u548c\u7a00\u758f\u6027\uff0c\u8fd8\u80fd\u7075\u6d3b\u8c03\u8282\u63a8\u7406\u65f6\u7684\u8ba1\u7b97\u4e0e\u6027\u80fd\u6743\u8861\uff0c\u6781\u5927\u6539\u5584\u4e86\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u548c\u5916\u63a8\u80fd\u529b\u3002"}}
{"id": "2511.20106", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20106", "abs": "https://arxiv.org/abs/2511.20106", "authors": ["Xingfeng Li", "Xiaohan Shi", "Junjie Li", "Yongwei Li", "Masashi Unoki", "Tomoki Toda", "Masato Akagi"], "title": "EM2LDL: A Multilingual Speech Corpus for Mixed Emotion Recognition through Label Distribution Learning", "comment": "Submitted to IEEE Transactions on Affective computing", "summary": "This study introduces EM2LDL, a novel multilingual speech corpus designed to advance mixed emotion recognition through label distribution learning. Addressing the limitations of predominantly monolingual and single-label emotion corpora \\textcolor{black}{that restrict linguistic diversity, are unable to model mixed emotions, and lack ecological validity}, EM2LDL comprises expressive utterances in English, Mandarin, and Cantonese, capturing the intra-utterance code-switching prevalent in multilingual regions like Hong Kong and Macao. The corpus integrates spontaneous emotional expressions from online platforms, annotated with fine-grained emotion distributions across 32 categories. Experimental baselines using self-supervised learning models demonstrate robust performance in speaker-independent gender-, age-, and personality-based evaluations, with HuBERT-large-EN achieving optimal results. By incorporating linguistic diversity and ecological validity, EM2LDL enables the exploration of complex emotional dynamics in multilingual settings. This work provides a versatile testbed for developing adaptive, empathetic systems for applications in affective computing, including mental health monitoring and cross-cultural communication. The dataset, annotations, and baseline codes are publicly available at https://github.com/xingfengli/EM2LDL.", "AI": {"tldr": "EM2LDL\u662f\u4e00\u4e2a\u4e13\u4e3a\u591a\u8bed\u79cd\u6df7\u5408\u60c5\u611f\u8bc6\u522b\u8bbe\u8ba1\u7684\u65b0\u578b\u8bed\u97f3\u8bed\u6599\u5e93\uff0c\u5305\u542b\u82f1\u8bed\u3001\u666e\u901a\u8bdd\u548c\u7ca4\u8bed\u771f\u5b9e\u8868\u8fbe\uff0c\u652f\u6301\u5206\u5e03\u5f0f\u591a\u60c5\u611f\u6807\u6ce8\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u4e0d\u540c\u4e2a\u4f53\u5c5e\u6027\u4e0a\u7684\u9c81\u68d2\u6027\uff0c\u6709\u52a9\u4e8e\u53d1\u5c55\u9762\u5411\u60c5\u611f\u8ba1\u7b97\u548c\u5fc3\u7406\u5065\u5eb7\u7b49\u8de8\u6587\u5316\u5e94\u7528\u7684\u667a\u80fd\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u60c5\u611f\u8bed\u97f3\u8bed\u6599\u5e93\u591a\u4e3a\u5355\u8bed\u3001\u5355\u6807\u7b7e\uff0c\u65e0\u6cd5\u6709\u6548\u523b\u753b\u591a\u8bed\u79cd\u6df7\u5408\u60c5\u611f\u53ca\u73b0\u5b9e\u4e16\u754c\u771f\u5b9e\u8868\u8fbe\uff0c\u9650\u5236\u4e86\u8de8\u6587\u5316\u3001\u4e2a\u6027\u5316\u60c5\u611f\u8ba1\u7b97\u5e94\u7528\u7684\u53d1\u5c55\u3002", "method": "\u6784\u5efa\u5305\u542b\u82f1\u8bed\u3001\u666e\u901a\u8bdd\u548c\u7ca4\u8bed\u7684\u591a\u8bed\u79cd\u8bed\u97f3\u8bed\u6599\u5e93\uff0c\u6536\u96c6\u6765\u81ea\u7f51\u7edc\u5e73\u53f0\u7684\u771f\u5b9e\u60c5\u611f\u8868\u8fbe\uff0c\u5e76\u901a\u8fc732\u7c7b\u7ec6\u7c92\u5ea6\u60c5\u611f\u5206\u7c7b\u8fdb\u884c\u5206\u5e03\u5f0f\u6807\u6ce8\u3002\u91c7\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u6a21\u578b\uff08\u5982HuBERT-large-EN\uff09\u8fdb\u884c\u57fa\u7ebf\u8bc4\u4f30\uff0c\u5b9e\u73b0\u8bf4\u8bdd\u4eba\u6027\u522b\u3001\u5e74\u9f84\u548c\u4eba\u683c\u7684\u72ec\u7acb\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cEM2LDL\u5728\u591a\u7ef4\u5ea6\u57fa\u7ebf\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u5c24\u5176HuBERT-large-EN\u6a21\u578b\u5404\u9879\u6307\u6807\u6700\u4f73\u3002\u8bed\u6599\u5e93\u652f\u6301\u590d\u6742\u60c5\u611f\u52a8\u6001\u7814\u7a76\uff0c\u4e3a\u81ea\u9002\u5e94\u548c\u5177\u5907\u540c\u7406\u5fc3\u7684\u667a\u80fd\u7cfb\u7edf\u5f00\u53d1\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "EM2LDL\u8bed\u6599\u5e93\u5728\u63d0\u5347\u591a\u8bed\u79cd\u6df7\u5408\u60c5\u611f\u8bc6\u522b\u548c\u6807\u7b7e\u5206\u5e03\u5b66\u4e60\u65b9\u9762\u5c55\u73b0\u4e86\u5f3a\u5927\u6f5c\u529b\uff0c\u5c24\u5176\u5728\u751f\u6001\u6709\u6548\u6027\u548c\u8bed\u8a00\u591a\u6837\u6027\u4e0a\u7a81\u7834\u4e86\u4f20\u7edf\u8bed\u6599\u5e93\u7684\u9650\u5236\u3002"}}
{"id": "2511.20107", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2511.20107", "abs": "https://arxiv.org/abs/2511.20107", "authors": ["Huu Tuong Tu", "Ha Viet Khanh", "Tran Tien Dat", "Vu Huan", "Thien Van Luong", "Nguyen Tien Cuong", "Nguyen Thi Thu Trang"], "title": "Mispronunciation Detection and Diagnosis Without Model Training: A Retrieval-Based Approach", "comment": null, "summary": "Mispronunciation Detection and Diagnosis (MDD) is crucial for language learning and speech therapy. Unlike conventional methods that require scoring models or training phoneme-level models, we propose a novel training-free framework that leverages retrieval techniques with a pretrained Automatic Speech Recognition model. Our method avoids phoneme-specific modeling or additional task-specific training, while still achieving accurate detection and diagnosis of pronunciation errors. Experiments on the L2-ARCTIC dataset show that our method achieves a superior F1 score of 69.60% while avoiding the complexity of model training.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b0\u578b\u53d1\u97f3\u9519\u8bef\u68c0\u6d4b\u4e0e\u8bca\u65ad\u65b9\u6cd5\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\u548c\u68c0\u7d22\u6280\u672f\u5b9e\u73b0\u9ad8\u6548\u9ad8\u51c6\u786e\u5ea6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6027\u80fd\u4f18\u8d8a\u4e14\u7cfb\u7edf\u7b80\u5355\u3002", "motivation": "\u4f20\u7edf\u7684\u53d1\u97f3\u9519\u8bef\u68c0\u6d4b\u4e0e\u8bca\u65ad\uff08MDD\uff09\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5efa\u6a21\u3001\u8bad\u7ec3\u97f3\u7d20\u7ea7\u522b\u8bc4\u5206\u6a21\u578b\uff0c\u8fc7\u7a0b\u590d\u6742\uff0c\u5bf9\u7b97\u529b\u548c\u6570\u636e\u8981\u6c42\u9ad8\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u7b80\u4fbf\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u65b0\u7684\u3001\u65e0\u9700\u8bad\u7ec3\u7684MDD\u6846\u67b6\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u7684\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u6a21\u578b\u7ed3\u5408\u68c0\u7d22\u6280\u672f\u8fdb\u884c\u9519\u8bef\u68c0\u6d4b\u4e0e\u8bca\u65ad\uff0c\u65e0\u9700\u9488\u5bf9\u97f3\u7d20\u5efa\u6a21\u6216\u989d\u5916\u4efb\u52a1\u8bad\u7ec3\u3002", "result": "\u5728L2-ARCTIC\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u65b9\u6cd5\u5b9e\u73b0\u4e8669.60%\u7684F1\u5206\u6570\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u5927\u5927\u7b80\u5316\u4e86\u7cfb\u7edf\u7684\u590d\u6742\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u9884\u8bad\u7ec3ASR\u4e0e\u68c0\u7d22\u6280\u672f\uff0c\u4e0d\u4ec5\u907f\u514d\u4e86\u7e41\u7410\u7684\u8bad\u7ec3\u6d41\u7a0b\u548c\u6a21\u578b\u590d\u6742\u6027\uff0c\u8fd8\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u7684\u53d1\u97f3\u9519\u8bef\u68c0\u6d4b\uff0c\u4e3aMDD\u4efb\u52a1\u63d0\u4f9b\u4e86\u9ad8\u6548\u5b9e\u7528\u7684\u65b0\u601d\u8def\u3002"}}
{"id": "2511.20120", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20120", "abs": "https://arxiv.org/abs/2511.20120", "authors": ["Somsubhra De", "Harsh Kumar", "Arun Prakash A"], "title": "\"When Data is Scarce, Prompt Smarter\"... Approaches to Grammatical Error Correction in Low-Resource Settings", "comment": "10 pages, 5 figures, 5 tables; Accept-demonstration at BHASHA Workshop, IJCNLP-AACL 2025", "summary": "Grammatical error correction (GEC) is an important task in Natural Language Processing that aims to automatically detect and correct grammatical mistakes in text. While recent advances in transformer-based models and large annotated datasets have greatly improved GEC performance for high-resource languages such as English, the progress has not extended equally. For most Indic languages, GEC remains a challenging task due to limited resources, linguistic diversity and complex morphology. In this work, we explore prompting-based approaches using state-of-the-art large language models (LLMs), such as GPT-4.1, Gemini-2.5 and LLaMA-4, combined with few-shot strategy to adapt them to low-resource settings. We observe that even basic prompting strategies, such as zero-shot and few-shot approaches, enable these LLMs to substantially outperform fine-tuned Indic-language models like Sarvam-22B, thereby illustrating the exceptional multilingual generalization capabilities of contemporary LLMs for GEC. Our experiments show that carefully designed prompts and lightweight adaptation significantly enhance correction quality across multiple Indic languages. We achieved leading results in the shared task--ranking 1st in Tamil (GLEU: 91.57) and Hindi (GLEU: 85.69), 2nd in Telugu (GLEU: 85.22), 4th in Bangla (GLEU: 92.86), and 5th in Malayalam (GLEU: 92.97). These findings highlight the effectiveness of prompt-driven NLP techniques and underscore the potential of large-scale LLMs to bridge resource gaps in multilingual GEC.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7prompt+LLM\u65b9\u6cd5\u5728\u591a\u79cd\u5370\u5ea6\u8bed\u7684\u8bed\u6cd5\u7ea0\u9519\u4efb\u52a1\u4e2d\u5927\u5e45\u63d0\u5347\u6548\u679c\uff0c\u5b9e\u9a8c\u8bc1\u660e\u73b0\u6709\u5927\u578b\u6a21\u578b\u5373\u4f7f\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u4e5f\u6709\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\uff0c\u663e\u8457\u4f18\u4e8e\u672c\u5730\u5fae\u8c03\u6a21\u578b\uff0c\u5177\u6709\u5b9e\u9645\u63a8\u5e7f\u4ef7\u503c\u3002", "motivation": "\u5c3d\u7ba1\u82f1\u8bed\u7b49\u9ad8\u8d44\u6e90\u8bed\u8a00\u5728\u8bed\u6cd5\u7ea0\u9519\uff08GEC\uff09\u4efb\u52a1\u4e0a\u5df2\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5927\u591a\u6570\u5370\u5ea6\u8bed\u79cd\u56e0\u8d44\u6e90\u532e\u4e4f\u3001\u8bed\u8a00\u591a\u6837\u6027\u548c\u590d\u6742\u5f62\u6001\u53d8\u5316\uff0cGEC\u4efb\u52a1\u4ecd\u7136\u6781\u5177\u6311\u6218\u3002", "method": "\u91c7\u7528\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-4.1\u3001Gemini-2.5\u548cLLaMA-4\uff09\uff0c\u7ed3\u5408\u57fa\u7840\u81f3\u5c11\u91cf\u5b66\u4e60\u7684prompting\u65b9\u6cd5\uff08\u5305\u62eczero-shot\u548cfew-shot\u7b56\u7565\uff09\uff0c\u4ee5\u9002\u5e94\u4f4e\u8d44\u6e90\u8bed\u8a00\u73af\u5883\uff0c\u5e76\u4e0e\u5370\u5ea6\u8bed\u79cd\u7684\u5fae\u8c03\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5373\u4f7f\u662f\u57fa\u672cprompting\u7b56\u7565\uff0c\u4e5f\u80fd\u8ba9LLMs\u5728\u591a\u4e2a\u5370\u5ea6\u8bed\u79cdGEC\u4efb\u52a1\u4e2d\u5927\u5e45\u8d85\u8d8a\u5fae\u8c03\u5927\u578b\u672c\u5730\u6a21\u578b\uff0c\u5982Sarvam-22B\u3002\u7ecf\u8fc7\u8f7b\u91cf\u7ea7prompt\u8bbe\u8ba1\u4e0e\u9002\u914d\u540e\uff0c\u5728\u591a\u79cd\u5370\u5ea6\u8bed\u7684\u7ea0\u9519\u8d28\u91cf\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u5e76\u5728GEC\u76f8\u5173\u7ade\u8d5b\u4e2d\u6392\u540d\u7a81\u51fa\uff08\u4f8b\u5982\u6cf0\u7c73\u5c14\u8bed\u7b2c1\u3001\u5370\u5730\u8bed\u7b2c1\u7b49\uff09\u3002", "conclusion": "Prompting\u7ed3\u5408LLMs\u80fd\u6781\u5927\u63d0\u5347\u591a\u8bed\u79cd\u3001\u4f4e\u8d44\u6e90\u6761\u4ef6\u4e0b\u7684GEC\u6548\u679c\uff0c\u5c55\u793a\u4e86\u5f53\u524d\u5927\u578b\u6a21\u578b\u7684\u5353\u8d8a\u591a\u8bed\u79cd\u6cdb\u5316\u80fd\u529b\uff0c\u6709\u671b\u7f29\u5c0f\u591a\u8bed\u79cdGEC\u9886\u57df\u7684\u8d44\u6e90\u9e3f\u6c9f\u3002"}}
{"id": "2511.20143", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.20143", "abs": "https://arxiv.org/abs/2511.20143", "authors": ["Wen-Fang Su", "Hsiao-Wei Chou", "Wen-Yang Lin"], "title": "SEDA: A Self-Adapted Entity-Centric Data Augmentation for Boosting Gird-based Discontinuous NER Models", "comment": "9 pages, 5 figures", "summary": "Named Entity Recognition (NER) is a critical task in natural language processing, yet it remains particularly challenging for discontinuous entities. The primary difficulty lies in text segmentation, as traditional methods often missegment or entirely miss cross-sentence discontinuous entities, significantly affecting recognition accuracy. Therefore, we aim to address the segmentation and omission issues associated with such entities. Recent studies have shown that grid-tagging methods are effective for information extraction due to their flexible tagging schemes and robust architectures. Building on this, we integrate image data augmentation techniques, such as cropping, scaling, and padding, into grid-based models to enhance their ability to recognize discontinuous entities and handle segmentation challenges. Experimental results demonstrate that traditional segmentation methods often fail to capture cross-sentence discontinuous entities, leading to decreased performance. In contrast, our augmented grid models achieve notable improvements. Evaluations on the CADEC, ShARe13, and ShARe14 datasets show F1 score gains of 1-2.5% overall and 3.7-8.4% for discontinuous entities, confirming the effectiveness of our approach.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5728\u683c\u5b50\u6807\u6ce8\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6a21\u578b\u4e2d\u5e94\u7528\u56fe\u50cf\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4e0d\u8fde\u7eed\u5b9e\u4f53\u7684\u5206\u5272\u548c\u8bc6\u522b\u96be\u9898\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u8457\u63d0\u5347\u4e86\u8bc6\u522b\u6548\u679c\u3002", "motivation": "\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08NER\uff09\u5f88\u96be\u51c6\u786e\u8bc6\u522b\u8de8\u53e5\u5b50\u5206\u5e03\u7684\u4e0d\u8fde\u7eed\u5b9e\u4f53\uff0c\u4e3b\u8981\u6311\u6218\u5728\u4e8e\u6587\u672c\u5206\u6bb5\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u5206\u5272\u548c\u8bc6\u522b\u4e0d\u8fde\u7eed\u5b9e\u4f53\u65f6\u5bb9\u6613\u51fa\u9519\u6216\u9057\u6f0f\u3002", "method": "\u5728\u5df2\u6709\u7684\u683c\u5b50\u6807\u6ce8\uff08grid-tagging\uff09\u4fe1\u606f\u62bd\u53d6\u65b9\u6cd5\u57fa\u7840\u4e0a\uff0c\u7ed3\u5408\u56fe\u50cf\u6570\u636e\u589e\u5f3a\u6280\u672f\uff08\u5982\u88c1\u526a\u3001\u7f29\u653e\u3001\u586b\u5145\uff09\u5bf9\u683c\u5b50\u6807\u6ce8\u6a21\u578b\u8fdb\u884c\u6539\u8fdb\uff0c\u4ee5\u63d0\u5347\u8bc6\u522b\u4e0d\u8fde\u7eed\u5b9e\u4f53\u7684\u80fd\u529b\uff0c\u5c24\u5176\u9488\u5bf9\u5206\u6bb5\u95ee\u9898\u3002", "result": "\u5728CADEC\u3001ShARe13\u548cShARe14\u6570\u636e\u96c6\u4e0a\uff0c\u6539\u8fdb\u540e\u7684\u6a21\u578b\u6574\u4f53F1\u5206\u6570\u63d0\u53471-2.5%\uff0c\u5bf9\u4e0d\u8fde\u7eed\u5b9e\u4f53F1\u5206\u6570\u63d0\u53473.7-8.4%\u3002", "conclusion": "\u901a\u8fc7\u5c06\u56fe\u50cf\u589e\u5f3a\u6280\u672f\u878d\u5165\u683c\u5b50\u6a21\u578b\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u5bf9\u8de8\u53e5\u5b50\u4e0d\u8fde\u7eed\u5b9e\u4f53\u7684\u8bc6\u522b\u51c6\u786e\u7387\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u5206\u6bb5\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2511.20182", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20182", "abs": "https://arxiv.org/abs/2511.20182", "authors": ["Adilet Metinov", "Gulida M. Kudakeeva", "Gulnara D. Kabaeva"], "title": "KyrgyzBERT: A Compact, Efficient Language Model for Kyrgyz NLP", "comment": "3 pages, 1 figure, 2 tables. Preprint", "summary": "Kyrgyz remains a low-resource language with limited foundational NLP tools. To address this gap, we introduce KyrgyzBERT, the first publicly available monolingual BERT-based language model for Kyrgyz. The model has 35.9M parameters and uses a custom tokenizer designed for the language's morphological structure. To evaluate performance, we create kyrgyz-sst2, a sentiment analysis benchmark built by translating the Stanford Sentiment Treebank and manually annotating the full test set. KyrgyzBERT fine-tuned on this dataset achieves an F1-score of 0.8280, competitive with a fine-tuned mBERT model five times larger. All models, data, and code are released to support future research in Kyrgyz NLP.", "AI": {"tldr": "\u8be5\u8bba\u6587\u53d1\u5e03\u4e86\u9996\u4e2a\u5409\u5c14\u5409\u65af\u8bedBERT\u6a21\u578bKyrgyzBERT\uff0c\u5e76\u521b\u5efa\u4e86\u60c5\u611f\u5206\u6790\u57fa\u51c6\uff0c\u6a21\u578b\u8868\u73b0\u4f18\u5f02\u4e14\u8d44\u6e90\u5168\u90e8\u516c\u5f00\uff0c\u663e\u8457\u4fc3\u8fdb\u4e86\u5409\u5c14\u5409\u65af\u8bedNLP\u53d1\u5c55\u3002", "motivation": "\u5409\u5c14\u5409\u65af\u8bed\u4f5c\u4e3a\u4e00\u79cd\u8d44\u6e90\u7a00\u7f3a\u8bed\u8a00\uff0c\u7f3a\u4e4f\u57fa\u7840\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5de5\u5177\u3002\u5f53\u524d\u9488\u5bf9\u5409\u5c14\u5409\u65af\u8bed\u7684NLP\u7814\u7a76\u8f83\u5c11\uff0c\u63a8\u52a8\u76f8\u5173\u5de5\u5177\u548c\u8d44\u6e90\u7684\u5efa\u7acb\u5bf9\u8be5\u8bed\u8a00\u7684\u6570\u5b57\u5316\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u8bba\u6587\u63d0\u51faKyrgyzBERT\uff0c\u8fd9\u662f\u9996\u4e2a\u516c\u5f00\u7684\u5409\u5c14\u5409\u65af\u8bed\u5355\u8bedBERT\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u91c7\u7528\u9488\u5bf9\u5409\u5c14\u5409\u65af\u8bed\u5f62\u6001\u7ed3\u6784\u5b9a\u5236\u7684\u5206\u8bcd\u5668\u3002\u4e3a\u8bc4\u4f30\u6027\u80fd\uff0c\u4f5c\u8005\u6784\u5efa\u4e86kyrgyz-sst2\u60c5\u611f\u5206\u6790\u57fa\u51c6\uff0c\u901a\u8fc7\u7ffb\u8bd1Stanford Sentiment Treebank\u5e76\u624b\u52a8\u6ce8\u91ca\u5b8c\u6574\u6d4b\u8bd5\u96c6\u6765\u5b9e\u73b0\u3002", "result": "KyrgyzBERT\u5728kyrgyz-sst2\u6570\u636e\u96c6\u5fae\u8c03\u540e\u53d6\u5f97\u4e860.8280\u7684F1\u5206\u6570\uff0c\u4e0e\u53c2\u6570\u91cf\u5927\u4e94\u500d\u7684mBERT\u6a21\u578b\u6027\u80fd\u6301\u5e73\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u516c\u5f00\u4e86\u6240\u6709\u6a21\u578b\u3001\u6570\u636e\u548c\u4ee3\u7801\uff0c\u4fc3\u8fdb\u5409\u5c14\u5409\u65af\u8bedNLP\u53d1\u5c55\u3002", "conclusion": "KyrgyzBERT\u6269\u5927\u4e86\u5409\u5c14\u5409\u65af\u8bedNLP\u5de5\u5177\u548c\u8d44\u6e90\uff0c\u4e3a\u8be5\u8bed\u8a00\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u5176\u6027\u80fd\u663e\u793a\u4e13\u7528\u6a21\u578b\u5728\u8d44\u6e90\u7a00\u7f3a\u8bed\u8a00\u4efb\u52a1\u4e2d\u5177\u6709\u6548\u7387\u3002"}}
{"id": "2511.20233", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20233", "abs": "https://arxiv.org/abs/2511.20233", "authors": ["Chuyi Kong", "Gao Wei", "Jing Ma", "Hongzhan Lin", "Zhiyuan Fan"], "title": "REFLEX: Self-Refining Explainable Fact-Checking via Disentangling Truth into Style and Substance", "comment": null, "summary": "The prevalence of misinformation on social media threatens public trust, demanding automated fact-checking systems that provide accurate verdicts with interpretable explanations. However, existing large language model-based (LLM-based) approaches often rely heavily on external knowledge sources, introducing substantial latency and even hallucinations that undermine reliability, interpretability, and responsiveness, which is crucial for real-time use. To address these challenges, we propose REason-guided Fact-checking with Latent EXplanations REFLEX paradigm, a plug-and-play, self-refining paradigm that leverages the internal knowledge in backbone model to improve both verdict accuracy and explanation quality. REFLEX reformulates fact-checking as a role-play dialogue and jointly trains verdict prediction and explanation generation. It adaptively extracts contrastive activation pairs between the backbone model and its fine-tuned variant to construct steering vectors that disentangle truth into style and substance naturally. These activation-level signals guide inference and suppress noisy explanations, enabling more faithful and efficient reasoning. Experiments on real-world datasets show that REFLEX outperforms previous methods that steer toward a single truth direction and underscores the challenge traditional approaches face when handling the subtle, human-unknown truth in fact-checking tasks. Remarkably, with only 465 self-refined training samples, RELFEX achieves state-of-the-art performance. Furthermore, models trained with explanatory objectives can effectively guide those without them, yielding up to a 7.57% improvement, highlighting that internal explanation signals play a dual role in both interpreting and enhancing factual reasoning.", "AI": {"tldr": "REFLEX\u65e0\u9700\u91cd\u5ea6\u4f9d\u8d56\u5916\u90e8\u77e5\u8bc6\uff0c\u901a\u8fc7\u65b0\u9896\u5bf9\u8bdd\u5f0f\u8bad\u7ec3\u548c\u5185\u90e8\u6fc0\u6d3b\u63d0\u53d6\uff0c\u663e\u8457\u63d0\u5347\u4e8b\u5b9e\u6838\u67e5\u7684\u51c6\u786e\u6027\u548c\u89e3\u91ca\u80fd\u529b\uff0c\u5e76\u80fd\u6709\u6548\u8d4b\u80fd\u5176\u4ed6\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e8b\u5b9e\u6838\u67e5\u65b9\u6cd5\u5bf9\u5916\u90e8\u77e5\u8bc6\u4f9d\u8d56\u9ad8\uff0c\u5bfc\u81f4\u54cd\u5e94\u901f\u5ea6\u6162\u4e14\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u5f71\u54cd\u53ef\u9760\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u65f6\u6027\u3002\u8be5\u6587\u65e8\u5728\u6d88\u9664\u8fd9\u4e9b\u95ee\u9898\uff0c\u901a\u8fc7\u6316\u6398\u4e3b\u5e72\u6a21\u578b\u5185\u90e8\u77e5\u8bc6\u5b9e\u73b0\u9ad8\u8d28\u91cf\u89e3\u91ca\u548c\u5224\u51b3\u3002", "method": "\u63d0\u51fa\u4e86REFLEX\u8303\u5f0f\uff0c\u4e00\u79cd\u7528\u4e8e\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u89d2\u8272\u626e\u6f14\u5bf9\u8bdd\u7684\u5f62\u5f0f\u8054\u5408\u8bad\u7ec3\u5224\u51b3\u9884\u6d4b\u548c\u89e3\u91ca\u751f\u6210\uff0c\u5229\u7528\u4e3b\u5e72\u6a21\u578b\u5185\u90e8\u77e5\u8bc6\uff0c\u5e76\u91c7\u7528\u81ea\u9002\u5e94\u6fc0\u6d3b\u5bf9\u6bd4\u63d0\u53d6\u6784\u5efa\u6307\u5411\u771f\u7406\u7684\u5411\u91cf\uff0c\u6291\u5236\u566a\u58f0\u89e3\u91ca\uff0c\u63d0\u5347\u63a8\u7406\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "result": "REFLEX\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5927\u5e45\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4ec5\u7528465\u4e2a\u81ea\u6211\u4f18\u5316\u6837\u672c\u5373\u53d6\u5f97SOTA\u6027\u80fd\uff0c\u4e14\u89e3\u91ca\u76ee\u6807\u8bad\u7ec3\u4e0b\u7684\u6a21\u578b\u80fd\u63d0\u5347\u65e0\u89e3\u91ca\u76ee\u6807\u6a21\u578b\uff0c\u6700\u9ad8\u63d0\u53477.57%\u3002", "conclusion": "REFLEX\u5c55\u73b0\u51fa\u4e30\u5bcc\u7684\u5185\u90e8\u77e5\u8bc6\u6316\u6398\u4e0e\u5229\u7528\u6f5c\u529b\uff0c\u6781\u5927\u63d0\u5347\u4e86\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u7684\u6548\u7387\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u63a8\u52a8\u4e86\u4e8b\u5b9e\u6838\u67e5\u6280\u672f\u5411\u66f4\u5207\u5b9e\u53ef\u7528\u548c\u667a\u80fd\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.20340", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20340", "abs": "https://arxiv.org/abs/2511.20340", "authors": ["Luohe Shi", "Zuchao Li", "Lefei Zhang", "Baoyuan Qi", "Guoming Liu", "Hai Zhao"], "title": "Scaling LLM Speculative Decoding: Non-Autoregressive Forecasting in Large-Batch Scenarios", "comment": "accepted by AAAI-2026", "summary": "Speculative decoding accelerates LLM inference by utilizing otherwise idle computational resources during memory-to-chip data transfer. Current speculative decoding methods typically assume a considerable amount of available computing power, then generate a complex and massive draft tree using a small autoregressive language model to improve overall prediction accuracy. However, methods like batching have been widely applied in mainstream model inference systems as a superior alternative to speculative decoding, as they compress the available idle computing power. Therefore, performing speculative decoding with low verification resources and low scheduling costs has become an important research problem. We believe that more capable models that allow for parallel generation on draft sequences are what we truly need. Recognizing the fundamental nature of draft models to only generate sequences of limited length, we propose SpecFormer, a novel architecture that integrates unidirectional and bidirectional attention mechanisms. SpecFormer combines the autoregressive model's ability to extract information from the entire input sequence with the parallel generation benefits of non-autoregressive models. This design eliminates the reliance on large prefix trees and achieves consistent acceleration, even in large-batch scenarios. Through lossless speculative decoding experiments across models of various scales, we demonstrate that SpecFormer sets a new standard for scaling LLM inference with lower training demands and reduced computational costs.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86SpecFormer\u67b6\u6784\uff0c\u5b9e\u73b0\u4e86\u5728\u4f4e\u9a8c\u8bc1\u8d44\u6e90\u6761\u4ef6\u4e0b\u4f9d\u7136\u6709\u6548\u7684\u6295\u673a\u89e3\u7801\uff0c\u52a0\u901f\u4e86\u4e3b\u6d41\u5927\u6a21\u578b\u63a8\u7406\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u4e3b\u6d41\u7684\u5927\u6a21\u578b\u63a8\u7406\u7cfb\u7edf\u666e\u904d\u91c7\u7528\u6279\u91cf\u63a8\u7406\u65b9\u5f0f\uff0c\u5bfc\u81f4\u95f2\u7f6e\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\uff0c\u73b0\u6709\u6295\u673a\u89e3\u7801\u65b9\u6cd5\u96be\u4ee5\u9002\u7528\u3002\u5b9e\u73b0\u4f4e\u9a8c\u8bc1\u8d44\u6e90\u548c\u4f4e\u8c03\u5ea6\u6210\u672c\u4e0b\u7684\u6295\u673a\u89e3\u7801\u6210\u4e3a\u5173\u952e\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u67b6\u6784SpecFormer\uff0c\u5c06\u5355\u5411\u548c\u53cc\u5411\u6ce8\u610f\u529b\u673a\u5236\u7ed3\u5408\u5728\u4e00\u8d77\uff0c\u878d\u5408\u81ea\u56de\u5f52\u6a21\u578b\u4e0e\u975e\u81ea\u56de\u5f52\u6a21\u578b\u7684\u4f18\u70b9\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u5927\u578b\u524d\u7f00\u6811\u7684\u6295\u673a\u89e3\u7801\u65b9\u6cd5\u3002", "result": "SpecFormer\u53ef\u4ee5\u5728\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u4e0a\u8fdb\u884c\u65e0\u635f\u7684\u6295\u673a\u89e3\u7801\uff0c\u52a0\u901f\u5927\u6a21\u578b\u63a8\u7406\uff0c\u5e76\u964d\u4f4e\u8bad\u7ec3\u9700\u6c42\u548c\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "SpecFormer\u67b6\u6784\u89e3\u51b3\u4e86\u9ad8\u5e76\u53d1\u4e0e\u4f4e\u7a7a\u95f2\u8d44\u6e90\u4e0b\u6295\u673a\u89e3\u7801\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u4f7f\u5f97\u5927\u6279\u6b21\u60c5\u51b5\u4e0b\u4f9d\u7136\u80fd\u5b9e\u73b0\u7a33\u5b9a\u52a0\u901f\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6269\u5c55\u8bbe\u7acb\u4e86\u65b0\u6807\u51c6\u3002"}}
{"id": "2511.20344", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20344", "abs": "https://arxiv.org/abs/2511.20344", "authors": ["Taewhoo Lee", "Minju Song", "Chanwoong Yoon", "Jungwoo Park", "Jaewoo Kang"], "title": "The Curious Case of Analogies: Investigating Analogical Reasoning in Large Language Models", "comment": "AAAI 2026", "summary": "Analogical reasoning is at the core of human cognition, serving as an important foundation for a variety of intellectual activities. While prior work has shown that LLMs can represent task patterns and surface-level concepts, it remains unclear whether these models can encode high-level relational concepts and apply them to novel situations through structured comparisons. In this work, we explore this fundamental aspect using proportional and story analogies, and identify three key findings. First, LLMs effectively encode the underlying relationships between analogous entities; both attributive and relational information propagate through mid-upper layers in correct cases, whereas reasoning failures reflect missing relational information within these layers. Second, unlike humans, LLMs often struggle not only when relational information is missing, but also when attempting to apply it to new entities. In such cases, strategically patching hidden representations at critical token positions can facilitate information transfer to a certain extent. Lastly, successful analogical reasoning in LLMs is marked by strong structural alignment between analogous situations, whereas failures often reflect degraded or misplaced alignment. Overall, our findings reveal that LLMs exhibit emerging but limited capabilities in encoding and applying high-level relational concepts, highlighting both parallels and gaps with human cognition.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u63a2\u8ba8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7c7b\u6bd4\u63a8\u7406\u4e2d\u7684\u5173\u7cfb\u7f16\u7801\u4e0e\u5e94\u7528\u80fd\u529b\uff0c\u53d1\u73b0\u5176\u53ef\u4ee5\u521d\u6b65\u6355\u6349\u548c\u4f20\u64ad\u9ad8\u9636\u5173\u7cfb\uff0c\u4f46\u5728\u6cdb\u5316\u5230\u65b0\u60c5\u5883\u65f6\u4ecd\u6709\u9650\uff0c\u63ed\u793a\u4e86\u5176\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u7684\u76f8\u4f3c\u4e0e\u4e0d\u8db3\u4e4b\u5904\u3002", "motivation": "\u7c7b\u6bd4\u63a8\u7406\u662f\u4eba\u7c7b\u8ba4\u77e5\u7684\u6838\u5fc3\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u662f\u5426\u80fd\u50cf\u4eba\u7c7b\u4e00\u6837\u7f16\u7801\u9ad8\u9636\u5173\u7cfb\u6982\u5ff5\u5e76\u5728\u65b0\u60c5\u5883\u4e0b\u5e94\u7528\u8fd9\u4e9b\u77e5\u8bc6\u3002\u8be5\u7814\u7a76\u65e8\u5728\u586b\u8865\u673a\u5668\u4e0e\u4eba\u7c7b\u5728\u7c7b\u6bd4\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u5dee\u8ddd\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u4f7f\u7528\u6bd4\u4f8b\u7c7b\u6bd4\u548c\u6545\u4e8b\u7c7b\u6bd4\u4efb\u52a1\uff0c\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e2d\u9ad8\u5c42\u7f51\u7edc\u4e2d\u5bf9\u4e8e\u5f52\u56e0\u4fe1\u606f\u548c\u5173\u8054\u4fe1\u606f\u7684\u7f16\u7801\u65b9\u5f0f\uff0c\u4ee5\u53ca\u5728\u65b0\u5b9e\u4f53\u4e0a\u7684\u5e94\u7528\u80fd\u529b\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u5bf9\u9690\u85cf\u8868\u793a\u7684\u6709\u9488\u5bf9\u6027\u4fee\u8865\uff0c\u89c2\u5bdf\u4fe1\u606f\u8f6c\u79fb\u8fc7\u7a0b\uff0c\u5e76\u7cfb\u7edf\u8bc4\u4f30\u6210\u529f\u548c\u5931\u8d25\u7684\u7c7b\u6bd4\u63a8\u7406\u6848\u4f8b\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u4e00\u4e9b\u60c5\u5883\u4e0b\u6709\u6548\u7f16\u7801\u548c\u4f20\u64ad\u7c7b\u6bd4\u5bf9\u8c61\u95f4\u7684\u5173\u7cfb\u4fe1\u606f\uff0c\u4f46\u5728\u4fe1\u606f\u7f3a\u5931\u6216\u5c1d\u8bd5\u5bf9\u65b0\u5b9e\u4f53\u5e94\u7528\u65f6\u5bb9\u6613\u53d7\u963b\uff0c\u6709\u65f6\u901a\u8fc7\u4fee\u8865\u5173\u952e\u4f4d\u7f6e\u7684\u9690\u85cf\u8868\u793a\u53ef\u90e8\u5206\u7f13\u89e3\u3002\u6a21\u578b\u6210\u529f\u7684\u7c7b\u6bd4\u63a8\u7406\u8868\u73b0\u4e3a\u7ed3\u6784\u5bf9\u9f50\u826f\u597d\uff0c\u800c\u5931\u8d25\u5219\u901a\u5e38\u4e3a\u7ed3\u6784\u5bf9\u9f50\u5f31\u5316\u6216\u9519\u4f4d\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u9636\u5173\u7cfb\u6982\u5ff5\u7684\u7f16\u7801\u4e0e\u5e94\u7528\u65b9\u9762\u663e\u793a\u51fa\u521d\u6b65\u4f46\u6709\u9650\u7684\u80fd\u529b\u3002\u867d\u7136\u5176\u5728\u67d0\u4e9b\u65b9\u9762\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u5b58\u5728\u76f8\u4f3c\u6027\uff0c\u4f46\u4ecd\u6709\u660e\u663e\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u5bf9\u65b0\u60c5\u5883\u4e0b\u5173\u7cfb\u77e5\u8bc6\u8fc1\u79fb\u65b9\u9762\u3002"}}
{"id": "2511.20399", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20399", "abs": "https://arxiv.org/abs/2511.20399", "authors": ["Abdullah Al Sefat"], "title": "BengaliFig: A Low-Resource Challenge for Figurative and Culturally Grounded Reasoning in Bengali", "comment": null, "summary": "Large language models excel on broad multilingual benchmarks but remain to be evaluated extensively in figurative and culturally grounded reasoning, especially in low-resource contexts. We present BengaliFig, a compact yet richly annotated challenge set that targets this gap in Bengali, a widely spoken low-resourced language. The dataset contains 435 unique riddles drawn from Bengali oral and literary traditions. Each item is annotated along five orthogonal dimensions capturing reasoning type, trap type, cultural depth, answer category, and difficulty, and is automatically converted to multiple-choice format through a constraint-aware, AI-assisted pipeline. We evaluate eight frontier LLMs from major providers under zero-shot and few-shot chain-of-thought prompting, revealing consistent weaknesses in metaphorical and culturally specific reasoning. BengaliFig thus contributes both a diagnostic probe for evaluating LLM robustness in low-resource cultural contexts and a step toward inclusive and heritage-aware NLP evaluation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u5b5f\u52a0\u62c9\u8bed\u7684\u8c1c\u8bed\u6311\u6218\u6570\u636e\u96c6BengaliFig\uff0c\u7528\u4e8e\u6d4b\u8bd5\u4e3b\u6d41\u8bed\u8a00\u6a21\u578b\u5728\u5177\u8c61\u548c\u6587\u5316\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u7ed3\u679c\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u5728\u8fd9\u4e00\u9886\u57df\u7684\u663e\u8457\u4e0d\u8db3\uff0c\u4e3a\u4eca\u540e\u66f4\u5177\u6587\u5316\u5305\u5bb9\u6027\u7684NLP\u7814\u7a76\u548c\u8bc4\u6d4b\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u5728\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u79c0\uff0c\u4f46\u5728\u5904\u7406\u5177\u8c61\u548c\u4e0e\u6587\u5316\u76f8\u5173\u7684\u63a8\u7406\uff0c\u5c24\u5176\u662f\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u73af\u5883\u4e0b\uff0c\u5c1a\u7f3a\u4e4f\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002\u4e3a\u586b\u8865\u8fd9\u4e00\u9886\u57df\u7a7a\u767d\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u63a8\u52a8\u5bf9\u4f4e\u8d44\u6e90\u6587\u5316\u73af\u5883\u4e2dLLMs\u63a8\u7406\u80fd\u529b\u7684\u68c0\u6d4b\u548c\u63d0\u5347\u3002", "method": "\u63d0\u51faBengaliFig\u6570\u636e\u96c6\uff0c\u5305\u542b435\u4e2a\u72ec\u7279\u7684\u5b5f\u52a0\u62c9\u8bed\u8c1c\u8bed\uff0c\u6db5\u76d6\u53e3\u5934\u4e0e\u6587\u5b66\u4f20\u7edf\uff0c\u5e76\u6cbf\u4e94\u4e2a\u7ef4\u5ea6\u8be6\u7ec6\u6ce8\u91ca\uff08\u63a8\u7406\u7c7b\u578b\u3001\u9677\u9631\u7c7b\u578b\u3001\u6587\u5316\u6df1\u5ea6\u3001\u7b54\u6848\u7c7b\u522b\u548c\u96be\u5ea6\uff09\u3002\u5168\u90e8\u8c1c\u9898\u901a\u8fc7AI\u8f85\u52a9\u6d41\u7a0b\u81ea\u52a8\u8f6c\u5316\u4e3a\u591a\u9009\u9898\u3002\u8bc4\u4f30\u4e86\u516b\u4e2a\u4e3b\u6d41\u524d\u6cbfLLMs\uff0c\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u4e0b\uff0c\u5206\u6790\u5176\u5728\u9690\u55bb\u548c\u6587\u5316\u76f8\u5173\u63a8\u7406\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "\u516b\u79cd\u4e3b\u6d41LLMs\u5728\u9690\u55bb\u6027\u548c\u6587\u5316\u7279\u5f02\u6027\u63a8\u7406\u4efb\u52a1\u4e0a\u5747\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u4e0d\u8db3\uff0c\u5c55\u73b0\u4e86\u76ee\u524d\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u6587\u5316\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u663e\u8457\u5f31\u70b9\u3002", "conclusion": "BengaliFig\u4e0d\u4ec5\u662f\u8bc4\u4f30LLMs\u5728\u4f4e\u8d44\u6e90\u6587\u5316\u8bed\u5883\u4e0b\u9c81\u68d2\u6027\u7684\u6709\u6548\u5de5\u5177\uff0c\u4e5f\u4e3a\u66f4\u52a0\u5305\u5bb9\u548c\u6ce8\u91cd\u6587\u5316\u4f20\u627f\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u8bc4\u4ef7\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.20409", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20409", "abs": "https://arxiv.org/abs/2511.20409", "authors": ["Md Abdullah Al Kafi", "Raka Moni", "Sumit Kumar Banshal"], "title": "A Task-Oriented Evaluation Framework for Text Normalization in Modern NLP Pipelines", "comment": null, "summary": "Text normalization is an essential preprocessing step in many natural language processing (NLP) tasks, and stemming is one such normalization technique that reduces words to their base or root form. However, evaluating stemming methods is challenging because current evaluation approaches are limited and do not capture the potential harm caused by excessive stemming; therefore, it is essential to develop new approaches to evaluate stemming methods. To address this issue, this study propose a novel, task-oriented approach to evaluate stemming methods, which considers three aspects: (1) the utility of stemming using Stemming Effectiveness Score (SES), (2) the impact of stemming on downstream tasks using Model Performance Delta (MPD), and (3) the semantic similarity between stemmed and original words using Average Normalized Levenshtein Distance (ANLD), thus providing a comprehensive evaluation framework. We apply our evaluation framework to compare two stemmers for Bangla (BNLTK) and English (Snowball), and our results reveal a significant issue, prompting us to analyze their performance in detail. While the Bangla stemmer achieves the highest SES (1.67) due to effective word reduction (CR = 1.90), SES alone is insufficient because our proposed safety measure, ANLD, reveals that this high SES is due to harmful over-stemming (ANLD = 0.26), which correlates with the observed decrease in downstream performance.In contrast, the English stemmer achieves a moderate SES (1.31) with a safe meaning distance (ANLD = 0.14), allowing its word reduction to contribute positively to downstream performance; therefore, it is a more reliable stemmer. Our study provides a valuable tool for distinguishing between potential efficiency gains (high SES) and meaning preservation (low ANLD).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u65b0\u7684\u591a\u7ef4\u5ea6\u8bcd\u5e72\u5668\u8bc4\u4f30\u65b9\u6cd5\uff0c\u53d1\u73b0\u9ad8\u6548\u8bcd\u5e72\u672a\u5fc5\u6709\u76ca\u4e8e\u4e0b\u6e38\u4efb\u52a1\uff0c\u8bed\u4e49\u4fdd\u7559\u540c\u6837\u91cd\u8981\uff0c\u4e3a\u8bc4\u4f30\u4e0e\u9009\u578b\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\u3002", "motivation": "\u73b0\u6709\u7684\u8bcd\u5e72\u63d0\u53d6\uff08stemming\uff09\u8bc4\u4f30\u65b9\u6cd5\u6709\u9650\uff0c\u4e14\u672a\u80fd\u5145\u5206\u53cd\u6620\u201c\u8fc7\u5ea6\u8bcd\u5e72\u63d0\u53d6\u201d\u53ef\u80fd\u9020\u6210\u7684\u5371\u5bb3\uff0c\u4e9f\u9700\u66f4\u5168\u9762\u548c\u5b9e\u7528\u7684\u8bc4\u4f30\u65b9\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u3001\u4efb\u52a1\u5bfc\u5411\u7684\u8bcd\u5e72\u63d0\u53d6\u65b9\u6cd5\u8bc4\u4f30\u6846\u67b6\uff0c\u7efc\u5408\u8003\u8651\u4e86\u8bcd\u5e72\u6548\u679c\uff08SES\uff09\u3001\u5bf9\u4e0b\u6e38\u4efb\u52a1\u5f71\u54cd\uff08MPD\uff09\u548c\u8bcd\u4e49\u4fdd\u6301\uff08ANLD\uff09\u4e09\u4e2a\u65b9\u9762\u3002\u5e76\u4ee5Bengali\u548c\u82f1\u6587\u8bcd\u5e72\u5668\u4e3a\u4f8b\u5e94\u7528\u8be5\u8bc4\u4f30\u6846\u67b6\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\u3002", "result": "Bangla\u8bcd\u5e72\u5668\u5728\u8bcd\u5e72\u6548\u679c\u8bc4\u5206\uff08SES\uff09\u4e2d\u6700\u9ad8\uff0c\u4f46\u5728\u8bcd\u4e49\u4fdd\u6301\u65b9\u9762\uff08ANLD\u5206\u6570\uff09\u8868\u73b0\u4e0d\u4f73\uff0c\u5bfc\u81f4\u4e0b\u6e38\u6027\u80fd\u4e0b\u964d\uff1b\u800c\u82f1\u6587\u8bcd\u5e72\u5668\u5c3d\u7ba1SES\u8f83\u4f4e\uff0c\u4f46\u5728\u8bcd\u4e49\u4fdd\u6301\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5e76\u4fc3\u8fdb\u4e86\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u63d0\u5347\u3002", "conclusion": "SES\u6307\u6807\u4e0d\u80fd\u5355\u72ec\u53cd\u6620\u8bcd\u5e72\u5668\u597d\u574f\uff0c\u987b\u7ed3\u5408\u8bed\u4e49\u8ddd\u79bb\uff08ANLD\uff09\u7b49\u5b89\u5168\u6027\u6307\u6807\u7efc\u5408\u8bc4\u4ef7\uff0c\u624d\u80fd\u66f4\u6709\u6548\u5730\u533a\u5206\u6548\u7387\u63d0\u5347\u548c\u8bed\u4e49\u4fdd\u7559\u3002\u8be5\u6846\u67b6\u4e3a\u4eca\u540e\u7684\u8bcd\u5e72\u5668\u8bc4\u4f30\u4e0e\u9009\u62e9\u63d0\u4f9b\u4e86\u53ef\u9760\u5de5\u5177\u3002"}}
{"id": "2511.20459", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20459", "abs": "https://arxiv.org/abs/2511.20459", "authors": ["Mosab Rezaei", "Mina Rajaei Moghadam", "Abdul Rahman Shaikh", "Hamed Alhoori", "Reva Freedman"], "title": "Generation, Evaluation, and Explanation of Novelists' Styles with Single-Token Prompts", "comment": null, "summary": "Recent advances in large language models have created new opportunities for stylometry, the study of writing styles and authorship. Two challenges, however, remain central: training generative models when no paired data exist, and evaluating stylistic text without relying only on human judgment. In this work, we present a framework for both generating and evaluating sentences in the style of 19th-century novelists. Large language models are fine-tuned with minimal, single-token prompts to produce text in the voices of authors such as Dickens, Austen, Twain, Alcott, and Melville. To assess these generative models, we employ a transformer-based detector trained on authentic sentences, using it both as a classifier and as a tool for stylistic explanation. We complement this with syntactic comparisons and explainable AI methods, including attention-based and gradient-based analyses, to identify the linguistic cues that drive stylistic imitation. Our findings show that the generated text reflects the authors' distinctive patterns and that AI-based evaluation offers a reliable alternative to human assessment. All artifacts of this work are published online.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548cAI\u68c0\u6d4b\u5668\u81ea\u52a8\u751f\u6210\u53ca\u8bc4\u4ef719\u4e16\u7eaa\u77e5\u540d\u5c0f\u8bf4\u5bb6\u98ce\u683c\u6587\u672c\uff0c\u65e0\u9700\u4eba\u5de5\u914d\u5bf9\u8bc4\u4ef7\u3002\u65b9\u6cd5\u901a\u8fc7\u5fae\u8c03\u548c\u53ef\u89e3\u91caAI\u8bc6\u522b\u6587\u4f53\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u53ef\u9760\u7684\u81ea\u52a8\u5316\u6587\u4f53\u5b66\u7814\u7a76\uff0c\u6240\u6709\u7814\u7a76\u4ea7\u51fa\u5df2\u516c\u5f00\u3002", "motivation": "\u8fd1\u671f\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u5c55\u4e3a\u6587\u4f53\u5b66\uff08\u5199\u4f5c\u98ce\u683c\u4e0e\u4f5c\u8005\u7814\u7a76\uff09\u5e26\u6765\u4e86\u65b0\u673a\u9047\uff0c\u4f46\u9762\u5bf9\u4e24\u5927\u4e3b\u8981\u6311\u6218\uff1a1\uff09\u5728\u65e0\u914d\u5bf9\u6570\u636e\u60c5\u51b5\u4e0b\u5982\u4f55\u8bad\u7ec3\u751f\u6210\u6a21\u578b\uff1b2\uff09\u5982\u4f55\u5728\u4e0d\u5b8c\u5168\u4f9d\u8d56\u4eba\u5de5\u5224\u65ad\u7684\u524d\u63d0\u4e0b\u8bc4\u4ef7\u6587\u4f53\u6587\u672c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65e2\u53ef\u751f\u6210\u53c8\u53ef\u8bc4\u4ef719\u4e16\u7eaa\u5c0f\u8bf4\u5bb6\u6587\u4f53\u53e5\u5b50\u7684\u6846\u67b6\u3002\u901a\u8fc7\u6700\u5c0f\u5316\u3001\u5355\u8bcd\u63d0\u793a\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u751f\u6210\u72c4\u66f4\u65af\u3001\u5965\u65af\u6c40\u3001\u9a6c\u514b\u00b7\u5410\u6e29\u3001\u5965\u5c14\u79d1\u7279\u3001\u6885\u5c14\u7ef4\u5c14\u7b49\u4f5c\u5bb6\u7684\u6587\u672c\u3002\u8bc4\u4f30\u65b9\u6cd5\u4e3a\uff1a\u7528\u57fa\u4e8etransformer\u7684\u68c0\u6d4b\u5668\u5728\u771f\u5b9e\u53e5\u5b50\u4e0a\u8bad\u7ec3\uff0c\u5e76\u4f5c\u4e3a\u5206\u7c7b\u5668\u548c\u98ce\u683c\u89e3\u91ca\u5de5\u5177\uff1b\u7ed3\u5408\u53e5\u6cd5\u5bf9\u6bd4\u548c\u53ef\u89e3\u91caAI\uff08attention\u548c\u68af\u5ea6\u5206\u6790\uff09\u65b9\u6cd5\uff0c\u8bc6\u522b\u9a71\u52a8\u6587\u4f53\u6a21\u4eff\u7684\u8bed\u8a00\u7ebf\u7d22\u3002", "result": "\u751f\u6210\u6587\u672c\u80fd\u591f\u4f53\u73b0\u8fd9\u4e9b\u4f5c\u8005\u72ec\u7279\u7684\u98ce\u683c\u7279\u5f81\u3002AI\u81ea\u52a8\u8bc4\u4ef7\u5728\u53ef\u9760\u6027\u65b9\u9762\u662f\u4eba\u5de5\u8bc4\u4ef7\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u6240\u6709\u7684\u7814\u7a76\u4ea7\u51fa\u5747\u5df2\u516c\u5f00\u53d1\u5e03\u3002", "conclusion": "\u901a\u8fc7\u5fae\u8c03\u5927\u6a21\u578b\u548cAI\u68c0\u6d4b\u6280\u672f\uff0c\u751f\u6210\u5e76\u8bc4\u4ef719\u4e16\u7eaa\u5c0f\u8bf4\u5bb6\u98ce\u683c\u6587\u672c\u53d8\u5f97\u53ef\u884c\uff0cAI\u65b9\u6cd5\u5728\u6587\u4f53\u7814\u7a76\u4e2d\u5c55\u73b0\u51fa\u8f83\u597d\u8868\u73b0\u3002"}}
{"id": "2511.20494", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20494", "abs": "https://arxiv.org/abs/2511.20494", "authors": ["Jakub Hoscilowicz", "Artur Janicki"], "title": "Adversarial Confusion Attack: Disrupting Multimodal Large Language Models", "comment": null, "summary": "We introduce the Adversarial Confusion Attack, a new class of threats against multimodal large language models (MLLMs). Unlike jailbreaks or targeted misclassification, the goal is to induce systematic disruption that makes the model generate incoherent or confidently incorrect outputs. Applications include embedding adversarial images into websites to prevent MLLM-powered agents from operating reliably. The proposed attack maximizes next-token entropy using a small ensemble of open-source MLLMs. In the white-box setting, we show that a single adversarial image can disrupt all models in the ensemble, both in the full-image and adversarial CAPTCHA settings. Despite relying on a basic adversarial technique (PGD), the attack generates perturbations that transfer to both unseen open-source (e.g., Qwen3-VL) and proprietary (e.g., GPT-5.1) models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u7684\u65b0\u578b\u7cfb\u7edf\u6027\u5e72\u6270\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u6270\u4e71\u6a21\u578b\u8f93\u51fa\u4f7f\u5176\u4ea7\u751f\u4e0d\u8fde\u8d2f\u6216\u81ea\u4fe1\u4f46\u9519\u8bef\u7684\u56de\u7b54\u3002\u65b9\u6cd5\u7b80\u5355\u4f46\u8fc1\u79fb\u6027\u5f3a\uff0c\u9002\u7528\u4e8e\u591a\u7c7b\u6a21\u578b\uff0c\u63ed\u793a\u4e86MLLM\u5b89\u5168\u65b9\u9762\u7684\u65b0\u9690\u60a3\u3002", "motivation": "\u76ee\u524d\u9488\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u7684\u653b\u51fb\u4e3b\u8981\u96c6\u4e2d\u5728\u8d8a\u72f1\u6216\u5b9a\u5411\u8bef\u5224\u7b49\u6709\u9650\u76ee\u6807\uff0c\u4f46\u7f3a\u5c11\u5bf9\u7cfb\u7edf\u6027\u6270\u4e71\u6a21\u578b\u7a33\u5b9a\u6027\u7684\u7814\u7a76\u3002\u4f5c\u8005\u65e8\u5728\u63d0\u51fa\u65b0\u7684\u653b\u51fb\u65b9\u5f0f\uff0c\u63d0\u5347\u5b89\u5168\u9632\u62a4\u610f\u8bc6\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u653b\u51fb\u65b9\u5f0f\u2014\u2014Adversarial Confusion Attack\uff0c\u901a\u8fc7\u6700\u5927\u5316\u4e0b\u4e00\u4e2atoken\u7684\u71b5\uff0c\u5229\u7528\u5f00\u6e90MLLMs\u7684\u5c0f\u578b\u96c6\u6210\uff0c\u901a\u8fc7PGD\u8fdb\u884c\u767d\u76d2\u653b\u51fb\u3002\u91c7\u7528\u5d4c\u5165\u5f0f\u5bf9\u6297\u56fe\u50cf\u6765\u6270\u4e71\u6a21\u578b\u5728\u7f51\u7ad9\u7b49\u573a\u666f\u4e0b\u7684\u6b63\u5e38\u8fd0\u884c\u3002", "result": "\u5728\u767d\u76d2\u73af\u5883\u4e0b\uff0c\u4e00\u4e2a\u5bf9\u6297\u6027\u56fe\u50cf\u80fd\u540c\u65f6\u6270\u4e71\u96c6\u6210\u4e2d\u7684\u6240\u6709\u6a21\u578b\uff0c\u65e0\u8bba\u5b8c\u6574\u56fe\u7247\u8fd8\u662f\u5bf9\u6297\u578b\u9a8c\u8bc1\u7801\u573a\u666f\u5747\u6709\u6548\u3002\u751f\u6210\u7684\u6270\u52a8\u8fd8\u53ef\u8fc1\u79fb\u5230\u672a\u89c1\u8fc7\u7684\u5f00\u6e90\u6a21\u578b\uff08\u5982Qwen3-VL\uff09\u548c\u95ed\u6e90\u6a21\u578b\uff08\u5982GPT-5.1\uff09\u3002", "conclusion": "Adversarial Confusion Attack\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5bf9MLLM\u7684\u5e72\u6270\u6027\uff0c\u5e76\u5177\u5907\u5e7f\u6cdb\u7684\u8fc1\u79fb\u80fd\u529b\uff0c\u4f53\u73b0\u4e86\u5f53\u524d\u9632\u62a4\u4f53\u7cfb\u4e0b\u7684\u5b89\u5168\u9690\u60a3\u3002"}}
{"id": "2511.20507", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20507", "abs": "https://arxiv.org/abs/2511.20507", "authors": ["Nathan Roll", "Jill Kries", "Flora Jin", "Catherine Wang", "Ann Marie Finley", "Meghan Sumner", "Cory Shain", "Laura Gwilliams"], "title": "The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models", "comment": null, "summary": "Large language models (LLMs) have emerged as a candidate \"model organism\" for human language, offering an unprecedented opportunity to study the computational basis of linguistic disorders like aphasia. However, traditional clinical assessments are ill-suited for LLMs, as they presuppose human-like pragmatic pressures and probe cognitive processes not inherent to artificial architectures. We introduce the Text Aphasia Battery (TAB), a text-only benchmark adapted from the Quick Aphasia Battery (QAB) to assess aphasic-like deficits in LLMs. The TAB comprises four subtests: Connected Text, Word Comprehension, Sentence Comprehension, and Repetition. This paper details the TAB's design, subtests, and scoring criteria. To facilitate large-scale use, we validate an automated evaluation protocol using Gemini 2.5 Flash, which achieves reliability comparable to expert human raters (prevalence-weighted Cohen's kappa = 0.255 for model--consensus agreement vs. 0.286 for human--human agreement). We release TAB as a clinically-grounded, scalable framework for analyzing language deficits in artificial systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7c7b\u4f3c\u5931\u8bed\u75c7\u8bed\u8a00\u7f3a\u9677\u7684\u6807\u51c6\u5316\u6587\u672c\u6027\u6d4b\u8bd5\u5de5\u5177TAB\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u5316\u534f\u8bae\u9a8c\u8bc1\u5176\u53ef\u9760\u6027\uff0c\u4ee5\u652f\u6301\u5927\u89c4\u6a21LLM\u8bed\u8a00\u969c\u788d\u7814\u7a76\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u6a21\u62df\u548c\u7814\u7a76\u4eba\u7c7b\u8bed\u8a00\uff0c\u7279\u522b\u662f\u8bed\u8a00\u969c\u788d\uff08\u5982\u5931\u8bed\u75c7\uff09\u7684\u8ba1\u7b97\u57fa\u7840\u4e0a\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u4f20\u7edf\u7684\u4e34\u5e8a\u8bc4\u4f30\u65b9\u6cd5\u5e76\u4e0d\u9002\u5408\u76f4\u63a5\u5e94\u7528\u4e8eLLM\u3002\u672c\u6587\u65e8\u5728\u5f25\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u6587\u672c\u5931\u8bed\u75c7\u6d4b\u8bd5\uff08TAB\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u4ee5\u6587\u672c\u4e3a\u57fa\u7840\uff0c\u5bf9\u73b0\u6709Quick Aphasia Battery(QAB)\u5931\u8bed\u75c7\u5feb\u901f\u6d4b\u8bd5\u8fdb\u884c\u6539\u7f16\u7684\u57fa\u51c6\u5de5\u5177\uff0c\u5305\u542b\u56db\u9879\u5b50\u6d4b\u8bd5\uff08\u8fde\u8d2f\u6587\u672c\u3001\u8bcd\u6c47\u7406\u89e3\u3001\u53e5\u5b50\u7406\u89e3\u548c\u590d\u8ff0\uff09\uff0c\u5e76\u8be6\u7ec6\u9610\u8ff0\u4e86\u8bc4\u5206\u6807\u51c6\u3002\u4e3a\u5b9e\u73b0\u5927\u89c4\u6a21\u81ea\u52a8\u8bc4\u4f30\uff0c\u4f5c\u8005\u8fd8\u8bbe\u8ba1\u5e76\u9a8c\u8bc1\u4e86\u57fa\u4e8eGemini 2.5 Flash\u6a21\u578b\u7684\u81ea\u52a8\u5316\u8bc4\u5206\u534f\u8bae\u3002", "result": "\u81ea\u52a8\u5316\u534f\u8bae\u7684\u53ef\u9760\u6027\u4e0e\u4e13\u5bb6\u4eba\u5de5\u8bc4\u5206\u63a5\u8fd1\uff08\u6a21\u578b\u4e0e\u5171\u8bc6\u8bc4\u5206\u8005\u7684\u52a0\u6743Cohen's kappa\u4e3a0.255\uff0c\u4eba\u5de5\u8bc4\u5206\u8005\u95f4\u4e3a0.286\uff09\u3002TAB\u57fa\u51c6\u88ab\u53d1\u5e03\u4e3a\u4e34\u5e8a\u57fa\u7840\u7684\u3001\u53ef\u6269\u5c55\u5206\u6790\u4eba\u5de5\u7cfb\u7edf\u8bed\u8a00\u969c\u788d\u7684\u65b0\u6846\u67b6\u3002", "conclusion": "TAB\u4e3a\u7814\u7a76\u548c\u91cf\u5316LLM\u4e2d\u7684\u7c7b\u5931\u8bed\u75c7\u7f3a\u9677\u63d0\u4f9b\u4e86\u79d1\u5b66\u3001\u6807\u51c6\u5316\u548c\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u5de5\u5177\uff0c\u4fc3\u8fdb\u4e86AI\u5728\u795e\u7ecf\u8bed\u8a00\u79d1\u5b66\u548c\u8ba4\u77e5\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2511.20534", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20534", "abs": "https://arxiv.org/abs/2511.20534", "authors": ["Wesley Bian", "Xiaofeng Lin", "Guang Cheng"], "title": "Bridging the Language Gap: Synthetic Voice Diversity via Latent Mixup for Equitable Speech Recognition", "comment": "Accepted at ICML 2025 Workshop on Machine Learning for Audio", "summary": "Modern machine learning models for audio tasks often exhibit superior performance on English and other well-resourced languages, primarily due to the abundance of available training data. This disparity leads to an unfair performance gap for low-resource languages, where data collection is both challenging and costly. In this work, we introduce a novel data augmentation technique for speech corpora designed to mitigate this gap. Through comprehensive experiments, we demonstrate that our method significantly improves the performance of automatic speech recognition systems on low-resource languages. Furthermore, we show that our approach outperforms existing augmentation strategies, offering a practical solution for enhancing speech technology in underrepresented linguistic communities.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00\u8bed\u97f3\u8bc6\u522b\u6548\u679c\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63a8\u52a8\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00\u8bed\u97f3\u6280\u672f\u7684\u53d1\u5c55\u3002", "motivation": "\u5f53\u524d\u8bed\u97f3\u4efb\u52a1\u4e2d\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u82f1\u8bed\u7b49\u8d44\u6e90\u4e30\u5bcc\u7684\u8bed\u8a00\u4e0a\u6548\u679c\u4f18\u5f02\uff0c\u4e3b\u8981\u7531\u4e8e\u8bad\u7ec3\u6570\u636e\u5145\u8db3\uff0c\u800c\u4f4e\u8d44\u6e90\u8bed\u8a00\u56e0\u6570\u636e\u7a00\u7f3a\uff0c\u8868\u73b0\u5b58\u5728\u660e\u663e\u5dee\u8ddd\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8bed\u97f3\u8bed\u6599\u5e93\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u65e8\u5728\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u4e14\u4f18\u4e8e\u73b0\u6709\u7684\u589e\u5f3a\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u63d0\u5347\u6b20\u4ee3\u8868\u6027\u8bed\u8a00\u793e\u533a\u7684\u8bed\u97f3\u6280\u672f\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20547", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20547", "abs": "https://arxiv.org/abs/2511.20547", "authors": ["Farjana Sultana Mim", "Shuchin Aeron", "Eric Miller", "Kristen Wendell"], "title": "From Words to Wisdom: Discourse Annotation and Baseline Models for Student Dialogue Understanding", "comment": null, "summary": "Identifying discourse features in student conversations is quite important for educational researchers to recognize the curricular and pedagogical variables that cause students to engage in constructing knowledge rather than merely completing tasks. The manual analysis of student conversations to identify these discourse features is time-consuming and labor-intensive, which limits the scale and scope of studies. Leveraging natural language processing (NLP) techniques can facilitate the automatic detection of these discourse features, offering educational researchers scalable and data-driven insights. However, existing studies in NLP that focus on discourse in dialogue rarely address educational data. In this work, we address this gap by introducing an annotated educational dialogue dataset of student conversations featuring knowledge construction and task production discourse. We also establish baseline models for automatically predicting these discourse properties for each turn of talk within conversations, using pre-trained large language models GPT-3.5 and Llama-3.1. Experimental results indicate that these state-of-the-art models perform suboptimally on this task, indicating the potential for future research.", "AI": {"tldr": "\u4f5c\u8005\u5efa\u7acb\u4e86\u4e00\u4e2a\u6559\u80b2\u5bf9\u8bdd\u6ce8\u91ca\u6570\u636e\u96c6\uff0c\u5173\u6ce8\u5b66\u751f\u77e5\u8bc6\u5efa\u6784\u4e0e\u4efb\u52a1\u6267\u884c\u4e24\u79cd\u8bdd\u8bed\u3002\u5229\u7528GPT-3.5\u548cLlama-3.1\u8fdb\u884c\u81ea\u52a8\u68c0\u6d4b\u57fa\u51c6\u5b9e\u9a8c\uff0c\u7ed3\u679c\u4e00\u822c\uff0c\u8bf4\u660e\u73b0\u6709\u6a21\u578b\u5728\u8be5\u9886\u57df\u8868\u73b0\u4e0d\u8db3\uff0c\u6709\u5f85\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002", "motivation": "\u624b\u52a8\u5206\u6790\u5b66\u751f\u5bf9\u8bdd\u4e2d\u7684\u8bdd\u8bed\u7279\u5f81\u6548\u7387\u4f4e\u4e14\u8017\u65f6\uff0c\u9650\u5236\u4e86\u7814\u7a76\u7684\u89c4\u6a21\u3002\u5229\u7528NLP\u6280\u672f\u80fd\u591f\u5b9e\u73b0\u81ea\u52a8\u68c0\u6d4b\uff0c\u63d0\u9ad8\u5206\u6790\u7684\u53ef\u6269\u5c55\u6027\u548c\u6570\u636e\u9a71\u52a8\u80fd\u529b\uff0c\u4f46\u76ee\u524d\u9488\u5bf9\u6559\u80b2\u9886\u57df\u5bf9\u8bdd\u7684\u8bdd\u8bed\u68c0\u6d4b\u7814\u7a76\u8f83\u5c11\u3002", "method": "\u5efa\u7acb\u4e86\u5305\u542b\u77e5\u8bc6\u5efa\u6784\u4e0e\u4efb\u52a1\u751f\u4ea7\u8bdd\u8bed\u7684\u5b66\u751f\u5bf9\u8bdd\u6ce8\u91ca\u6570\u636e\u96c6\uff0c\u5e76\u57fa\u4e8e\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff08GPT-3.5\u548cLlama-3.1\uff09\u8fdb\u884c\u4e86\u57fa\u7ebf\u6a21\u578b\u5b9e\u9a8c\uff0c\u7528\u4e8e\u81ea\u52a8\u9884\u6d4b\u6bcf\u6b21\u53d1\u8a00\u7684\u8bdd\u8bed\u5c5e\u6027\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5f53\u524d\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\uff08GPT-3.5\u548cLlama-3.1\uff09\u5728\u8be5\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u6709\u5f85\u63d0\u5347\uff0c\u63ed\u793a\u4e86\u672a\u6765\u6539\u8fdb\u548c\u7814\u7a76\u7684\u6f5c\u529b\u3002", "conclusion": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\uff08GPT-3.5\u548cLlama-3.1\uff09\u5728\u81ea\u52a8\u68c0\u6d4b\u5b66\u751f\u5bf9\u8bdd\u4e2d\u7684\u8bdd\u8bed\u7279\u5f81\u4efb\u52a1\u4e0a\u8868\u73b0\u4e00\u822c\uff0c\u8bf4\u660e\u8fd8\u6709\u8fdb\u4e00\u6b65\u6539\u8fdb\u7684\u7a7a\u95f4\u3002"}}
{"id": "2511.20604", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20604", "abs": "https://arxiv.org/abs/2511.20604", "authors": ["Yixin Liu", "Pengfei Liu", "Arman Cohan"], "title": "On Evaluating LLM Alignment by Evaluating LLMs as Judges", "comment": "NeurIPS 2025 Camera Ready", "summary": "Alignment with human preferences is an important evaluation aspect of LLMs, requiring them to be helpful, honest, safe, and to precisely follow human instructions. Evaluating large language models' (LLMs) alignment typically involves directly assessing their open-ended responses, requiring human annotators or strong LLM judges. Conversely, LLMs themselves have also been extensively evaluated as judges for assessing alignment. In this work, we examine the relationship between LLMs' generation and evaluation capabilities in aligning with human preferences. To this end, we first conduct a comprehensive analysis of the generation-evaluation consistency (GE-consistency) among various LLMs, revealing a strong correlation between their generation and evaluation capabilities when evaluated by a strong LLM preference oracle. Utilizing this finding, we propose a benchmarking paradigm that measures LLM alignment with human preferences without directly evaluating their generated outputs, instead assessing LLMs in their role as evaluators. Our evaluation shows that our proposed benchmark, AlignEval, matches or surpasses widely used automatic LLM evaluation benchmarks, such as AlpacaEval and Arena-Hard, in capturing human preferences when ranking LLMs. Our study offers valuable insights into the connection between LLMs' generation and evaluation capabilities, and introduces a benchmark that assesses alignment without directly evaluating model outputs.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0LLM\u7684\u751f\u6210\u80fd\u529b\u548c\u8bc4\u4ef7\u80fd\u529b\u5f3a\u76f8\u5173\uff0c\u5e76\u63d0\u51fa\u5229\u7528\u8bc4\u4ef7\u80fd\u529b\u800c\u975e\u751f\u6210\u8f93\u51fa\u7684\u65b0\u5bf9\u9f50\u5ea6\u8bc4\u4ef7\u57fa\u51c6AlignEval\uff0c\u5176\u6548\u679c\u4f18\u8d8a\u3001\u6548\u7387\u66f4\u9ad8\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9700\u8981\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\uff0c\u5305\u62ec\u6709\u7528\u6027\u3001\u8bda\u5b9e\u6027\u3001\u5b89\u5168\u6027\u548c\u7cbe\u786e\u6267\u884c\u4eba\u7c7b\u6307\u4ee4\u3002\u73b0\u6709\u5bf9\u9f50\u8bc4\u4f30\u5f80\u5f80\u9700\u4eba\u5de5\u6ce8\u91ca\u6216\u501f\u52a9\u5f3a\u5927\u8bc4\u6d4b\u6a21\u578b\uff0c\u6210\u672c\u8f83\u9ad8\uff0c\u4e14\u6548\u7387\u6709\u9650\u3002\u56e0\u6b64\uff0c\u63a2\u7d22\u4e00\u79cd\u65e0\u9700\u5bf9\u751f\u6210\u7ed3\u679c\u76f4\u63a5\u8bc4\u4f30\u7684\u65b0\u5bf9\u9f50\u8bc4\u6d4b\u65b9\u5f0f\uff0c\u6709\u73b0\u5b9e\u9700\u6c42\u548c\u7814\u7a76\u4ef7\u503c\u3002", "method": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u591a\u79cdLLM\u7684\u751f\u6210-\u8bc4\u4ef7\u4e00\u81f4\u6027\uff08GE-consistency\uff09\uff0c\u5373\u5176\u751f\u6210\u80fd\u529b\u4e0e\u8bc4\u4ef7\u80fd\u529b\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002\u57fa\u4e8e\u5f3aLLM\u504f\u597d\u201c\u795e\u8c15\u8005\u201d\u8bc4\u6d4b\u8fd9\u4e00\u76f8\u5173\u6027\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u8bc4\u4ef7\u80fd\u529b\u800c\u975e\u76f4\u63a5\u8bc4\u4f30\u751f\u6210\u8f93\u51fa\u7684\u65b0\u578b\u5bf9\u9f50\u57fa\u51c6AlignEval\u3002", "result": "AlignEval\u8868\u73b0\u826f\u597d\uff0c\u5728\u5bf9\u9f50\u6027\u6392\u540d\u80fd\u529b\u4e0a\u8fbe\u5230\u6216\u8d85\u8fc7\u4e86\u73b0\u6709\u77e5\u540d\u81ea\u52a8\u8bc4\u4ef7\u57fa\u51c6\uff08\u5982AlpacaEval\u548cArena-Hard\uff09\uff0c\u5e76\u80fd\u66f4\u597d\u5730\u6355\u6349\u4eba\u7c7b\u504f\u597d\u3002", "conclusion": "LLM\u7684\u751f\u6210\u80fd\u529b\u548c\u8bc4\u4ef7\u80fd\u529b\u7d27\u5bc6\u76f8\u5173\u3002\u5229\u7528LLM\u81ea\u8eab\u8bc4\u4ef7\u80fd\u529b\uff0c\u53ef\u4ee5\u9ad8\u6548\u3001\u51c6\u786e\u8bc4\u4f30\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u65e0\u9700\u76f4\u63a5\u4eba\u5de5\u8bc4\u4f30\u8f93\u51fa\u3002AlignEval\u4e3aLLM\u5bf9\u9f50\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.20639", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20639", "abs": "https://arxiv.org/abs/2511.20639", "authors": ["Jiaru Zou", "Xiyuan Yang", "Ruizhong Qiu", "Gaotang Li", "Katherine Tieu", "Pan Lu", "Ke Shen", "Hanghang Tong", "Yejin Choi", "Jingrui He", "James Zou", "Mengdi Wang", "Ling Yang"], "title": "Latent Collaboration in Multi-Agent Systems", "comment": "Project: https://github.com/Gen-Verse/LatentMAS", "summary": "Multi-agent systems (MAS) extend large language models (LLMs) from independent single-model reasoning to coordinative system-level intelligence. While existing LLM agents depend on text-based mediation for reasoning and communication, we take a step forward by enabling models to collaborate directly within the continuous latent space. We introduce LatentMAS, an end-to-end training-free framework that enables pure latent collaboration among LLM agents. In LatentMAS, each agent first performs auto-regressive latent thoughts generation through last-layer hidden embeddings. A shared latent working memory then preserves and transfers each agent's internal representations, ensuring lossless information exchange. We provide theoretical analyses establishing that LatentMAS attains higher expressiveness and lossless information preservation with substantially lower complexity than vanilla text-based MAS. In addition, empirical evaluations across 9 comprehensive benchmarks spanning math and science reasoning, commonsense understanding, and code generation show that LatentMAS consistently outperforms strong single-model and text-based MAS baselines, achieving up to 14.6% higher accuracy, reducing output token usage by 70.8%-83.7%, and providing 4x-4.3x faster end-to-end inference. These results demonstrate that our new latent collaboration framework enhances system-level reasoning quality while offering substantial efficiency gains without any additional training. Code and data are fully open-sourced at https://github.com/Gen-Verse/LatentMAS.", "AI": {"tldr": "LatentMAS\u8ba9\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u5728\u9690\u7a7a\u95f4\u534f\u4f5c\uff0c\u76f8\u6bd4\u4f20\u7edf\u6587\u672c\u901a\u4fe1MAS\uff0c\u51c6\u786e\u7387\u63d0\u5347\u660e\u663e\uff0c\u6548\u7387\u5927\u5e45\u63d0\u9ad8\uff0c\u65e0\u9700\u518d\u8bad\u7ec3\uff0c\u6548\u679c\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u4e3b\u8981\u901a\u8fc7\u6587\u672c\u901a\u4fe1\u548c\u63a8\u7406\uff0c\u5b58\u5728\u4fe1\u606f\u635f\u5931\u548c\u6548\u7387\u4f4e\u4e0b\u7b49\u95ee\u9898\uff0c\u4e9f\u9700\u5bfb\u627e\u66f4\u9ad8\u6548\u7684\u4fe1\u606f\u4ea4\u6362\u65b9\u5f0f\uff0c\u4ee5\u63d0\u5347\u7cfb\u7edf\u7ea7\u667a\u80fd\u3002", "method": "\u63d0\u51faLatentMAS\u6846\u67b6\uff0c\u4f7f\u591a\u4e2aLLM\u667a\u80fd\u4f53\u76f4\u63a5\u5728\u8fde\u7eed\u9690\u7a7a\u95f4\u5185\u534f\u4f5c\uff0c\u5b9e\u73b0\u65e0\u635f\u7684\u4fe1\u606f\u8868\u8fbe\u548c\u4ea4\u6362\u3002\u8be5\u6846\u67b6\u91c7\u7528\u65e0\u8bad\u7ec3\u65b9\u5f0f\uff0c\u667a\u80fd\u4f53\u901a\u8fc7\u6700\u540e\u4e00\u5c42\u7684\u9690\u85cf\u5d4c\u5165\u8fdb\u884c\u81ea\u56de\u5f52\u6f5c\u5728\u601d\u7ef4\u751f\u6210\uff0c\u5e76\u5229\u7528\u5171\u4eab\u9690\u7a7a\u95f4\u8bb0\u5fc6\u5b9e\u73b0\u4fe1\u606f\u4fdd\u5b58\u4e0e\u8f6c\u79fb\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u5b9eLatentMAS\u6bd4\u4f20\u7edf\u6587\u672cMAS\u6709\u66f4\u9ad8\u7684\u8868\u8fbe\u80fd\u529b\u548c\u66f4\u4f4e\u7684\u590d\u6742\u5ea6\u3002\u5b9e\u8bc1\u6d4b\u8bd5\uff089\u4e2a\u57fa\u51c6\u4efb\u52a1\uff09\u663e\u793aLatentMAS\u5728\u51c6\u786e\u7387\u4e0a\u63d0\u5347\u6700\u9ad814.6%\uff0c\u8f93\u51fatoken\u51cf\u5c1170.8%-83.7%\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u53474-4.3\u500d\uff0c\u6027\u80fd\u5168\u9762\u4f18\u4e8e\u5355\u6a21\u578b\u548c\u6587\u672cMAS\u3002", "conclusion": "LatentMAS\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u901a\u8fc7\u6f5c\u5728\u7a7a\u95f4\u5408\u4f5c\u663e\u8457\u63d0\u5347\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u7684\u63a8\u7406\u80fd\u529b\u548c\u6548\u7387\uff0c\u4e3a\u7cfb\u7edf\u7ea7\u667a\u80fd\u5960\u5b9a\u4e86\u65b0\u57fa\u7840\u3002"}}
