<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 9]
- [cs.CL](#cs.CL) [Total: 51]
- [cs.DM](#cs.DM) [Total: 1]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [A Novel Compiler Transformation for Fast Sparse Matrix Multiplication in GPUs](https://arxiv.org/abs/2506.15174)
*Hossein Albakri,Kazem Cheshmi*

Main category: cs.PL

TL;DR: 本文提出一种新的编译器变换方法，显著提升了GPU上稀疏神经网络的SPMM速度，对比业界标准库提升最高超过2倍。


<details>
  <summary>Details</summary>
Motivation: 尽管稀疏数据结构能节省内存，但由于随机访问等不规则操作导致GPU上内存体系无法高效利用，进而影响计算和内存资源的效率，因此需要对稀疏结构上的操作进行加速。

Method: 通过编译器端的 enumerate-and-sparse-coarsen 变换，增加了寄存器和缓存的数据重用性，并对GPU的计算资源进行了更均衡的负载分配，从而优化SPMM操作，在神经网络（卷积和变换器模型）中实现具体测试。

Result: 在NVIDIA A100 GPU上，针对$A \times B = C$，对B矩阵宽度bCols从32到128的范围，新的方法相对于cuBLAS和cuSPARSE分别实现了1.84×和2.27×的几何平均加速比。

Conclusion: 提出了一种针对GPU设备的编译器变换方法 enumerate-and-sparse-coarsen，能够加速稀疏神经网络中的稀疏矩阵-矩阵乘法（SPMM），在A100 GPU上对比cuBLAS和cuSPARSE取得了1.84×到2.27×的加速效果。

Abstract: Sparse data structures are commonly used in neural networks to reduce the
memory footprint. These data structures are compact but cause irregularities
such as random memory accesses, which prevent efficient use of the memory
hierarchy. GPUs are a common platform for machine learning practitioners, but
running compact data structures on these devices often leads to slow-downs due
to inefficient use of computing and memory resources. This paper proposes a new
compiler transformation, enumerate-and-sparse-coarsen, that accelerates sparse
matrix-matrix multiplication (SPMM) on GPU devices. The transformation
increases data reuse in registers and caches while creating more balanced
workloads for GPU computing resources. The transformation is tested on sparse
neural networks in convolutional and transformer models. On an A100 GPU and
across a columns of matrix B (bCols) in $ A \times B = C$ from range of 32 to
128, the transformation yields a geometric mean speedup of 1.84$\times$ to
2.27$\times$ compared to cuBLAS and cuSPARSE baselines, respectively.

</details>


### [2] [PSM: Policy Synchronised Deterministic Memory](https://arxiv.org/abs/2506.15424)
*Michael Mendler,Marc Pouzet*

Main category: cs.PL

TL;DR: PSM是一种新型Haskell内存抽象，结合了并发、共享、可变状态和确定性，避免竞态，提升了并发编程的表达能力和安全性。


<details>
  <summary>Details</summary>
Motivation: 在需要共享资源的情况下，实现并发性和确定性通常会产生冲突。Haskell虽提供了一些并发和并行的编程抽象，例如IVar、LVar、MVar和TVar，但它们在支持可变状态、并发及确定性三个方面仍有不足。现有的解决方案要么缺少破坏性更新（destructive updates），要么无法保持确定性。因此，作者希望提出一种既能支持并发、共享、破坏性更新，又能保持确定性的抽象。

Method: 提出了一个新的类型上下文PSM（policy synchronised memory）用于Haskell。PSM允许像STM和IO那样访问和更新持久状态，同时支持并发线程和共享状态。通过策略协调的方式避免竞争条件，从而保证确定性。作者设计了类型系统保证了在PSM中实现的事务和数据结构具有并发、可变、可共享且行为确定性。

Result: PSM上下文支持具有可变状态、能被并发共享且行为确定的数据结构和编程模式。通过策略同步，避免了竞态条件，实现了破坏性更新和确定性的结合。有效提高了Haskell在编写既高效又可预测的并发程序方面的能力。

Conclusion: PSM为Haskell提供了一种新的存储抽象方式，使程序员能够编写既支持可变状态、并发、共享，又具备确定性保障的程序。通过静态类型系统和策略同步机制，PSM结合了STM/IO和Par/IO抽象的优点，填补了现有Haskell并发模型的空白。

Abstract: Concurrency and determinacy do not go well with each other when resources
must be shared. Haskell provides parallel programming abstractions such as IVar
and LVar in the Par monad and concurrent abstractions such as MVar and TVar in
the in IO and STM monads, respectively. The former are determinate but have no
destructive updates and the latter have destructive updates but do not
guarantee determinacy. Programming patterns that are both concurrent and
determinate, such as those provided by Kahn or Berry require memory
abstractions at a higher level than is currently available. In this paper we
describe a new type context PSM for policy synchronised memory in Haskell. Like
STM and IO, the computations in PSM can access persistent state and, as a
side-effect, update the memory in imperative style. Like the Par and IO monads,
PSM supports concurrent threads and shared state. However, in contrast to IO,
our PSM contexts are race-free since concurrent accesses are policy coordinated
which guarantees determinacy.Well-typed transactions in the PSM context can
accommodate abstract data structures that are imperative, concurrently
shareable and still behave deterministically, by construction.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [OS-Harm: A Benchmark for Measuring Safety of Computer Use Agents](https://arxiv.org/abs/2506.14866)
*Thomas Kuntz,Agatha Duzan,Hao Zhao,Francesco Croce,Zico Kolter,Nicolas Flammarion,Maksym Andriushchenko*

Main category: cs.SE

TL;DR: 本文提出了针对能操作图形界面的LLM代理的安全性测评基准OS-Harm。基准涵盖多种安全威胁，实验证明主流大模型存在安全漏洞。OS-Harm可用于未来该领域安全研究与提升。


<details>
  <summary>Details</summary>
Motivation: 随着基于大模型（LLM）的计算机使用代理能够直接操作图形界面，其安全性问题被大多忽视。然而，广泛应用前必须评估和理解这类系统可能带来的有害行为。

Method: 作者提出OS-Harm基准，用于衡量计算机使用代理的安全性。OS-Harm基于OSWorld环境，包含150个涵盖不同安全违规类型（如骚扰、版权侵犯等）与多种操作系统应用交互的任务，并实现自动评测系统以自动化对代理的准确性和安全性评估。

Result: 评测显示，所有前沿大模型（如o4-mini、Claude 3.7 Sonnet和Gemini 2.5 Pro）都容易直接响应恶意请求，对静态提示注入攻击较为脆弱，且偶尔会有不安全操作。自动评测方法与人工标注一致性较高。

Conclusion: 计算机使用代理在安全方面存在实际隐患，OS-Harm为进一步研究和改进相关系统安全性提供了重要工具和基准。

Abstract: Computer use agents are LLM-based agents that can directly interact with a
graphical user interface, by processing screenshots or accessibility trees.
While these systems are gaining popularity, their safety has been largely
overlooked, despite the fact that evaluating and understanding their potential
for harmful behavior is essential for widespread adoption. To address this gap,
we introduce OS-Harm, a new benchmark for measuring safety of computer use
agents. OS-Harm is built on top of the OSWorld environment and aims to test
models across three categories of harm: deliberate user misuse, prompt
injection attacks, and model misbehavior. To cover these cases, we create 150
tasks that span several types of safety violations (harassment, copyright
infringement, disinformation, data exfiltration, etc.) and require the agent to
interact with a variety of OS applications (email client, code editor, browser,
etc.). Moreover, we propose an automated judge to evaluate both accuracy and
safety of agents that achieves high agreement with human annotations (0.76 and
0.79 F1 score). We evaluate computer use agents based on a range of frontier
models - such as o4-mini, Claude 3.7 Sonnet, Gemini 2.5 Pro - and provide
insights into their safety. In particular, all models tend to directly comply
with many deliberate misuse queries, are relatively vulnerable to static prompt
injections, and occasionally perform unsafe actions. The OS-Harm benchmark is
available at https://github.com/tml-epfl/os-harm.

</details>


### [4] [An Empirical Study of Bugs in Data Visualization Libraries](https://arxiv.org/abs/2506.15084)
*Weiqi Lu,Yongqiang Tian,Xiaohan Zhong,Haoyang Ma,Zhenyang Xu,Shing-Chi Cheung,Chengnian Sun*

Main category: cs.SE

TL;DR: 本文系统分析了数据可视化库中的564个错误，发现错误普遍且以图形计算出错为主，提出专属分类和测试判据并探讨了VLM自动检测的效果，为后续自动化测试和错误检测技术的发展打下基础。


<details>
  <summary>Details</summary>
Motivation: 数据可视化库在数据表达、分析和应用开发中至关重要，其可视化准确性直接影响用户体验和决策。但此类库中的可视化错误（visual bugs）通常表现为图形误导而非崩溃，用户难以察觉，后果却可能十分严重。因此，系统研究数据可视化库中的错误特性，对开发者和研究者修复和检测相关错误具有重要意义。

Method: 该研究收集了来自五个广泛使用的数据可视化库的564个错误案例，对这些错误的表征和根本原因进行了系统分析，并提出了详细的分类体系。同时，识别了触发此类错误的关键步骤和适用于数据可视化库的测试判定标准。最后，尝试利用视觉语言模型（VLMs）自动检测可视化错误，并分析其检测效果。

Result: 研究发现不正确/不准确的可视化广泛存在于当前的数据可视化库，而图形计算的不正确是主要根本原因。文中提出了8个关键触发步骤及2类测试判定准则，为自动化测试方法带来了启示。使用VLM检测可视化错误的有效性依赖于提示的设计，有效率介于29%到57%，补充更多提示信息不一定提升效果。

Conclusion: 本研究首次对数据可视化库中的错误进行了系统性梳理和分析，阐明该领域亟需更高效的自动化测试方法，并对视觉语言模型在错误检测中的实际应用效果进行了探讨。所提出的分析框架和测试思路能够为后续的相关研究和工具开发提供借鉴。

Abstract: Data visualization (DataViz) libraries play a crucial role in presentation,
data analysis, and application development, underscoring the importance of
their accuracy in transforming data into visual representations. Incorrect
visualizations can adversely impact user experience, distort information
conveyance, and influence user perception and decision-making processes. Visual
bugs in these libraries can be particularly insidious as they may not cause
obvious errors like crashes, but instead mislead users of the underlying data
graphically, resulting in wrong decision making. Consequently, a good
understanding of the unique characteristics of bugs in DataViz libraries is
essential for researchers and developers to detect and fix bugs in DataViz
libraries.
  This study presents the first comprehensive analysis of bugs in DataViz
libraries, examining 564 bugs collected from five widely-used libraries. Our
study systematically analyzes their symptoms and root causes, and provides a
detailed taxonomy. We found that incorrect/inaccurate plots are pervasive in
DataViz libraries and incorrect graphic computation is the major root cause,
which necessitates further automated testing methods for DataViz libraries.
Moreover, we identified eight key steps to trigger such bugs and two test
oracles specific to DataViz libraries, which may inspire future research in
designing effective automated testing techniques. Furthermore, with the recent
advancements in Vision Language Models (VLMs), we explored the feasibility of
applying these models to detect incorrect/inaccurate plots. The results show
that the effectiveness of VLMs in bug detection varies from 29% to 57%,
depending on the prompts, and adding more information in prompts does not
necessarily increase the effectiveness. More findings can be found in our
manuscript.

</details>


### [5] [Program Feature-based Fuzzing Benchmarking](https://arxiv.org/abs/2506.15088)
*Miao Miao*

Main category: cs.SE

TL;DR: 论文提出可配置细粒度程序特征的新型模糊测试基准，评测发现程序特征显著影响不同模糊器的表现，建议在评估时必须纳入程序特征考量。


<details>
  <summary>Details</summary>
Motivation: 尽管模糊测试是一种强大的缺陷发现手段，目前主流的评估大多只关注整体性能，而很少有基准测试细致考虑程序特征如何影响测试效果。

Method: 作者提出了一种新的基准测试方法，可以根据可配置的、细粒度的程序特征自动生成测试程序，并提取了25篇最新相关文献中7种与控制流、数据流相关的重要程序特征。然后据此生成了包含153个，通过10个参数细粒度控制的程序集合，并用它对11个常用模糊器进行了评测。

Result: 结果显示，模糊器的性能会因程序特征和属性强度的不同而有较大变化，强调了在模糊测试评估中考虑程序特性的重要性。

Conclusion: 研究提出了更具针对性的模糊基准测试框架，可助力评估和提升模糊器在不同程序特征下的有效性。

Abstract: Fuzzing is a powerful software testing technique renowned for its
effectiveness in identifying software vulnerabilities. Traditional fuzzing
evaluations typically focus on overall fuzzer performance across a set of
target programs, yet few benchmarks consider how fine-grained program features
influence fuzzing effectiveness. To bridge this gap, we introduce a novel
benchmark designed to generate programs with configurable, fine-grained program
features to enhance fuzzing evaluations. We reviewed 25 recent grey-box fuzzing
studies, extracting 7 program features related to control-flow and data-flow
that can impact fuzzer performance. Using these features, we generated a
benchmark consisting of 153 programs controlled by 10 fine-grained configurable
parameters. We evaluated 11 popular fuzzers using this benchmark. The results
indicate that fuzzer performance varies significantly based on the program
features and their strengths, highlighting the importance of incorporating
program characteristics into fuzzing evaluations.

</details>


### [6] [Enhancement Report Approval Prediction: A Comparative Study of Large Language Models](https://arxiv.org/abs/2506.15098)
*Haosheng Zuo,Feifei Niu,Chuanyi Li*

Main category: cs.SE

TL;DR: 大模型（LLM）能显著提升软件增强报告自动审批的准确率与效率，尤其是微调后的Llama表现最佳，在不同方面优于传统方法，有助于实际软件开发流程。


<details>
  <summary>Details</summary>
Motivation: 增强报告（ERs）帮助用户与开发者沟通软件改进建议，但人工处理这些信息成本高、效率低。如何利用自动化方法提高处理效率并减少信息流失，是当前的研究难题。

Method: 本文系统性评估了18种大语言模型（LLM）变体（包括多种编码器/解码器模型），并与传统机器学习方法（如CNN/LSTM-BERT/GloVe）进行对比。在实验中还尝试引入创建者画像信息及基于LoRA微调的技术，以提升模型表现，并在真实的时间顺序数据上进行评估。

Result: 1）引入创建者画像可提升未微调的解码器模型准确率10.8%，但有引入偏差的风险；2）LoRA 微调的 Llama 3.1 8B Instruct 模型表现最佳，准确率79%，对于被批准报告召回率从64.1%提升到76.1%，在严格时间顺序评测中超越传统方法5%，有效应对类别不平衡问题。

Conclusion: 大语言模型优于传统方法，可大幅优化增强报告的自动审批预测，有助于提升软件维护效率和决策水平。同时，研究还分析了模型表现不佳的案例，为后续研究指明方向。

Abstract: Enhancement reports (ERs) serve as a critical communication channel between
users and developers, capturing valuable suggestions for software improvement.
However, manually processing these reports is resource-intensive, leading to
delays and potential loss of valuable insights. To address this challenge,
enhancement report approval prediction (ERAP) has emerged as a research focus,
leveraging machine learning techniques to automate decision-making. While
traditional approaches have employed feature-based classifiers and deep
learning models, recent advancements in large language models (LLM) present new
opportunities for enhancing prediction accuracy. This study systematically
evaluates 18 LLM variants (including BERT, RoBERTa, DeBERTa-v3, ELECTRA, and
XLNet for encoder models; GPT-3.5-turbo, GPT-4o-mini, Llama 3.1 8B, Llama 3.1
8B Instruct and DeepSeek-V3 for decoder models) against traditional methods
(CNN/LSTM-BERT/GloVe). Our experiments reveal two key insights: (1)
Incorporating creator profiles increases unfine-tuned decoder-only models'
overall accuracy by 10.8 percent though it may introduce bias; (2) LoRA
fine-tuned Llama 3.1 8B Instruct further improve performance, reaching 79
percent accuracy and significantly enhancing recall for approved reports (76.1
percent vs. LSTM-GLOVE's 64.1 percent), outperforming traditional methods by 5
percent under strict chronological evaluation and effectively addressing class
imbalance issues. These findings establish LLM as a superior solution for ERAP,
demonstrating their potential to streamline software maintenance workflows and
improve decision-making in real-world development environments. We also
investigated and summarized the ER cases where the large models underperformed,
providing valuable directions for future research.

</details>


### [7] [Towards Bug-Free Distributed Go Programs](https://arxiv.org/abs/2506.15135)
*Zhengqun Koo*

Main category: cs.SE

TL;DR: 本文提出了一个验证框架，可静态证明Go语言分布式程序中没有通信竞争，有助于保证分布式消息通信的正确性与安全。


<details>
  <summary>Details</summary>
Motivation: 分布式系统程序员需要推理并发性以避免竞争条件（race），但推理十分困难，容易出现意外的竞争作为bug。此前在共享内存系统中数据竞争检测已有大量研究。分布式系统中，通信竞争（communication race）同数据竞争类似，但涉及消息发送与接收，没有严格的happens-before关系则可能导致严重问题。

Method: 本文描述了一种验证框架，能够证明在使用Go语言某个子集实现的分布式程序中不存在通信竞争。该方法为静态分析，通过推理分布式程序的执行过程，结合基于发生先后（happens-before）顺序的分析，并对缓冲与非缓冲信道做了扩展。

Result: 该方法可以静态地确认使用消息传递为主的分布式Go程序中没有通信竞争，提高了程序可靠性的验证能力。

Conclusion: 通过发生先后顺序扩展和静态分析，本文的验证框架能够为Go分布式程序提供通信竞争的消除保障，提升了消息传递程序的正确性与可靠性。

Abstract: Programmers of distributed systems need to reason about concurrency to avoid
races. However, reasoning about concurrency is difficult, and unexpected races
show up as bugs. Data race detection in shared memory systems is well-studied
(dynamic data race detection [13], behavioral types [15], dynamic race
detection [31]). Similar to how a data race consists of reads and writes not
related by happens-before at a shared memory location, a communication race
consists of receives and sends not related by happens-before on a shared
channel. Communication races are problematic: a receiver expects a specific
message from a specific sender, but with a communication race, the receiver can
receive a message meant for another receiver, or not receive anything at all.
In this work, we describe a verification framework that can prove the absence
of communication races for distributed programs that use a subset of the Go
programming language, where synchronization is mainly achieved via message
passing. We statically reason about how a distributed program executes, using a
happens-before order, extended to buffered and unbuffered channels.

</details>


### [8] [Advanced approach for Agile/Scrum Process: RetroAI++](https://arxiv.org/abs/2506.15172)
*Maria Spichkova,Kevin Iwan,Madeleine Zwart,Hina Lee,Yuwon Yoon,Xiaohan Qin*

Main category: cs.SE

TL;DR: 本文提出了智能辅助的敏捷开发原型工具RetroAI++，可自动优化冲刺计划和回顾流程，对敏捷团队管理具备积极应用价值。


<details>
  <summary>Details</summary>
Motivation: 敏捷/Scrum软件开发中，迭代计划与回顾分析是项目管理的关键。为了帮助开发者更好地进行这些活动，引入智能技术以提升效率和效果具有重要意义。

Method: 提出并设计了一个基于人工智能的新型原型工具RetroAI++，用于自动化并优化Sprint计划与回顾流程，通过AI智能分析提供冲刺组织建议和总结反思洞见。

Result: RetroAI++能够在敏捷开发项目中自动化处理冲刺计划、开发与回顾等多个流程，提供更有价值的冲刺规划建议及回顾分析结果。

Conclusion: 基于AI的RetroAI++原型工具，有效地支持了敏捷/Scrum流程中的关键活动，可提升团队的冲刺组织和回顾反思质量。

Abstract: In Agile/Scrum software development, sprint planning and retrospective
analysis are the key elements of project management. The aim of our work is to
support software developers in these activities. In this paper, we present our
prototype tool RetroAI++, based on emerging intelligent technologies. In our
RetroAI++ prototype, we aim to automate and refine the practical application of
Agile/Scrum processes within Sprint Planning and Retrospectives. Leveraging AI
insights, our prototype aims to automate and refine the many processes involved
in the Sprint Planning, Development and Retrospective stages of Agile/Scrum
development projects, offering intelligent suggestions for sprint organisation
as well as meaningful insights for retrospective reflection.

</details>


### [9] [Large Language Models for Unit Testing: A Systematic Literature Review](https://arxiv.org/abs/2506.15227)
*Quanjun Zhang,Chunrong Fang,Siqi Gu,Ye Shang,Zhenyu Chen,Liang Xiao*

Main category: cs.SE

TL;DR: 本文首次系统梳理了LLMs在自动化单元测试的应用，总结现有任务、方法、挑战与前景，对研究者理解和推进该领域有重要参考价值。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的进步，越来越多的研究利用LLMs自动化单元测试任务，显著减轻了人工负担。但目前LLM在单元测试中的应用尚处于探索阶段，研究人员难以全面了解已有成果、未解问题与未来机遇，因此有必要对该领域进行系统梳理。

Method: 本文通过系统性文献综述，梳理截至2025年3月LLMs在单元测试任务中的应用研究。作者分析了多篇相关论文，从单元测试和LLMs两个维度进行归类，总结LLMs在测试生成、判定条件生成等任务中的应用，讨论模型使用、适应策略及混合方法等关键技术，并梳理面临的挑战与未来研究方向。

Result: 本文归纳了LLMs在单元测试领域的关键任务、方法创新、应用成效，并总结了未解决的核心挑战。同时，本文公开了相关综述资料，便于学界后续深入研究。

Conclusion: 本文是首个梳理LLM在单元测试应用领域的系统综述，帮助研究人员全面了解该领域现状、挑战与发展方向，对促进未来研究具有基础性指导作用。

Abstract: Unit testing is a fundamental practice in modern software engineering, with
the aim of ensuring the correctness, maintainability, and reliability of
individual software components. Very recently, with the advances in Large
Language Models (LLMs), a rapidly growing body of research has leveraged LLMs
to automate various unit testing tasks, demonstrating remarkable performance
and significantly reducing manual effort. However, due to ongoing explorations
in the LLM-based unit testing field, it is challenging for researchers to
understand existing achievements, open challenges, and future opportunities.
This paper presents the first systematic literature review on the application
of LLMs in unit testing until March 2025. We analyze \numpaper{} relevant
papers from the perspectives of both unit testing and LLMs. We first categorize
existing unit testing tasks that benefit from LLMs, e.g., test generation and
oracle generation. We then discuss several critical aspects of integrating LLMs
into unit testing research, including model usage, adaptation strategies, and
hybrid approaches. We further summarize key challenges that remain unresolved
and outline promising directions to guide future research in this area.
Overall, our paper provides a systematic overview of the research landscape to
the unit testing community, helping researchers gain a comprehensive
understanding of achievements and promote future research. Our artifacts are
publicly available at the GitHub repository:
https://github.com/iSEngLab/AwesomeLLM4UT.

</details>


### [10] [Uncovering Intention through LLM-Driven Code Snippet Description Generation](https://arxiv.org/abs/2506.15453)
*Yusuf Sulistyo Nugroho,Farah Danisha Salam,Brittany Reid,Raula Gaikovina Kula,Kazumasa Shimari,Kenichi Matsumoto*

Main category: cs.SE

TL;DR: 本研究分析了npm代码片段的文档描述类型，发现超半数为使用示例。Llama在自动分类和描述方面表现不错，但与原始描述仍有差距，未来可提升细节和意图表达能力。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的兴起，开发者及用户对代码片段的文档编写需求变得更为重要，尤其是第三方库的使用示例和接口文档。作者希望探究开发者常用的描述类型，以及LLM（以Llama为例）自动生成代码片段描述的效果。

Method: 作者利用包含185,412个npm包、1,024,579个代码片段的NPM Code Snippets数据集，从中随机抽取400个代码片段及对应描述进行手动分类分析；随后使用Llama模型对这些代码片段生成描述并与人工结果做对比分析，包括类别识别准确率与描述内容的相似度评分。

Result: （1）手动分类发现，55.5%的原始描述侧重使用示例，部分描述细节不足，难以有效传达使用意图；（2）Llama模型能够79.75%准确地识别“使用示例”类别，与人工分类结果吻合，表明模型有一定泛化能力；（3）自动生成描述与原始描述的平均相似度为0.7173，相关性尚可，但存在提升空间，部分生成结果与原意不完全一致。

Conclusion: 当前LLM（如Llama）在代码片段自动描述生成方面总体表现较好，特别是对常见类别如“使用示例”的识别和描述，但仍有改进空间，特别在细节和意图表达上。不同代码片段的描述需求可能因用途（如用法、安装、学习示例）而异，因此自动生成描述时应充分考虑其具体任务。

Abstract: Documenting code snippets is essential to pinpoint key areas where both
developers and users should pay attention. Examples include usage examples and
other Application Programming Interfaces (APIs), which are especially important
for third-party libraries. With the rise of Large Language Models (LLMs), the
key goal is to investigate the kinds of description developers commonly use and
evaluate how well an LLM, in this case Llama, can support description
generation. We use NPM Code Snippets, consisting of 185,412 packages with
1,024,579 code snippets. From there, we use 400 code snippets (and their
descriptions) as samples. First, our manual classification found that the
majority of original descriptions (55.5%) highlight example-based usage. This
finding emphasizes the importance of clear documentation, as some descriptions
lacked sufficient detail to convey intent. Second, the LLM correctly identified
the majority of original descriptions as "Example" (79.75%), which is identical
to our manual finding, showing a propensity for generalization. Third, compared
to the originals, the produced description had an average similarity score of
0.7173, suggesting relevance but room for improvement. Scores below 0.9
indicate some irrelevance. Our results show that depending on the task of the
code snippet, the intention of the document may differ from being instructions
for usage, installations, or descriptive learning examples for any user of a
library.

</details>


### [11] [cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree](https://arxiv.org/abs/2506.15655)
*Yilin Zhang,Xinran Zhao,Zora Zhiruo Wang,Chenyang Yang,Jiayi Wei,Tongshuang Wu*

Main category: cs.SE

TL;DR: 本论文提出基于抽象语法树（AST）的代码分块方法，有效提升了RAG代码生成系统的性能，强调了结构化分块对于代码检索与生成的关键作用。


<details>
  <summary>Details</summary>
Motivation: 在针对代码生成的检索增强生成（RAG）系统中，如何将代码文档合理分块（chunking）是一个被忽视但非常重要的问题。现有基于行的分块方法容易破坏语义结构，如分隔函数或将无关代码合并，影响生成质量。作者希望改进这一环节，提高生成效果。

Method: 作者提出了一种基于抽象语法树（AST）的结构感知分块方法：递归地将较大的AST节点拆分成更小的块，并在不超过大小限制的情况下合并兄弟节点，从而生成自包含、语义连贯的分块，适用于多种编程语言及任务。

Result: 该方法能在不同代码生成任务中提升性能：在RepoEval检索任务中Recall@5提升4.3个百分点，在SWE-bench生成任务中Pass@1提升2.67个百分点，具体表明结构感知分块方法的有效性。

Conclusion: 论文证明了结构感知的分块在RAG代码智能系统中至关重要，不仅能提升检索与生成性能，也为大规模代码智能的发展指明了方向。

Abstract: Retrieval-Augmented Generation (RAG) has become essential for large-scale
code generation, grounding predictions in external code corpora to improve
actuality. However, a critical yet underexplored aspect of RAG pipelines is
chunking -- the process of dividing documents into retrievable units. Existing
line-based chunking heuristics often break semantic structures, splitting
functions or merging unrelated code, which can degrade generation quality. We
propose chunking via Abstract Syntax Trees (\ourwork), a structure-aware method
that recursively breaks large AST nodes into smaller chunks and merges sibling
nodes while respecting size limits. This approach generates self-contained,
semantically coherent units across programming languages and tasks, improving
performance on diverse code generation tasks, e.g., boosting Recall@5 by 4.3
points on RepoEval retrieval and Pass@1 by 2.67 points on SWE-bench generation.
Our work highlights the importance of structure-aware chunking for scaling
retrieval-enhanced code intelligence.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [12] [Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings](https://arxiv.org/abs/2506.14900)
*Imane Guellil,Salomé Andres,Atul Anand,Bruce Guthrie,Huayu Zhang,Abul Hasan,Honghan Wu,Beatrice Alex*

Main category: cs.CL

TL;DR: 本研究构建了详尽标注的老年患者出院小结不良事件语料库，发现现有模型对一般事件抽取成绩高，但对细分和罕见病例及复杂语义支持不足，为后续方法评估提供了基准。


<details>
  <summary>Details</summary>
Motivation: 老年患者在临床自然语言处理（NLP）资源中常被忽视，尤其是在不良事件检测领域，且以往数据和方法很少覆盖复杂与交叠实体。

Method: 构建并人工标注老年患者出院小结中的不良事件语料库，包含多种事件和上下文属性，并支持跨界和重叠实体注释。采用FlairNLP平台训练多种模型，设定不同标注粒度（细粒度、粗粒度、带否定的粗粒度）下评测模型性能。

Result: BERT-cased等transformer模型在粗粒度文档层面F1=0.943，细粒度实体层面F1仅为0.675，特殊事件和复杂属性上更低。指出高层面表现掩盖了对稀有事件和复杂临床语义处理的不足。

Conclusion: 虽然BERT等transformer模型在粗粒度事件提取上表现良好，但在细粒度、复杂或罕见不良事件提取方面依然面临明显挑战。

Abstract: In this work, we present a manually annotated corpus for Adverse Event (AE)
extraction from discharge summaries of elderly patients, a population often
underrepresented in clinical NLP resources. The dataset includes 14 clinically
significant AEs-such as falls, delirium, and intracranial haemorrhage, along
with contextual attributes like negation, diagnosis type, and in-hospital
occurrence. Uniquely, the annotation schema supports both discontinuous and
overlapping entities, addressing challenges rarely tackled in prior work. We
evaluate multiple models using FlairNLP across three annotation granularities:
fine-grained, coarse-grained, and coarse-grained with negation. While
transformer-based models (e.g., BERT-cased) achieve strong performance on
document-level coarse-grained extraction (F1 = 0.943), performance drops
notably for fine-grained entity-level tasks (e.g., F1 = 0.675), particularly
for rare events and complex attributes. These results demonstrate that despite
high-level scores, significant challenges remain in detecting underrepresented
AEs and capturing nuanced clinical language. Developed within a Trusted
Research Environment (TRE), the dataset is available upon request via DataLoch
and serves as a robust benchmark for evaluating AE extraction methods and
supporting future cross-dataset generalisation.

</details>


### [13] [Combining Constrained and Unconstrained Decoding via Boosting: BoostCD and Its Application to Information Extraction](https://arxiv.org/abs/2506.14901)
*Marija Šakota,Robert West*

Main category: cs.CL

TL;DR: 通过将有约束与无约束解码结合，并用boosting方式融合两种预测，BoostCD 提升了结构化NLP任务的输出质量，在信息抽取等实际任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 结构化NLP任务常用自回归语言模型通过受限解码生成结构化输出，但训练阶段模型对约束不敏感，导致测试时受限解码输出质量下降，需要提升模型在严格结构约束下的输出质量。

Method: 提出 Boosted Constrained Decoding (BoostCD) 两阶段模型：第一阶段分别用有约束和无约束方案解码，获得两种弱预测结果；第二阶段采用自回归的boosting模型融合这两种预测，得到最终输出。

Result: BoostCD 在信息抽取任务上表现优异，其实现模型BoostIE在分布内外均优于以往方法，并能解决以往方法中的常见错误。

Conclusion: BoostCD 能有效结合有约束和无约束的解码预测，提升结构化NLP任务的性能，并减小测试时受限解码带来的输出质量问题。

Abstract: Many recent approaches to structured NLP tasks use an autoregressive language
model $M$ to map unstructured input text $x$ to output text $y$ representing
structured objects (such as tuples, lists, trees, code, etc.), where the
desired output structure is enforced via constrained decoding. During training,
these approaches do not require the model to be aware of the constraints, which
are merely implicit in the training outputs $y$. This is advantageous as it
allows for dynamic constraints without requiring retraining, but can lead to
low-quality output during constrained decoding at test time. We overcome this
problem with Boosted Constrained Decoding (BoostCD), which combines constrained
and unconstrained decoding in two phases: Phase 1 decodes from the base model
$M$ twice, in constrained and unconstrained mode, obtaining two weak
predictions. In phase 2, a learned autoregressive boosted model combines the
two weak predictions into one final prediction. The mistakes made by the base
model with vs. without constraints tend to be complementary, which the boosted
model learns to exploit for improved performance. We demonstrate the power of
BoostCD by applying it to closed information extraction. Our model, BoostIE,
outperforms prior approaches both in and out of distribution, addressing
several common errors identified in those approaches.

</details>


### [14] [CrEst: Credibility Estimation for Contexts in LLMs via Weak Supervision](https://arxiv.org/abs/2506.14912)
*Dyah Adila,Shuai Zhang,Boran Han,Bonan Min,Yuyang Wang*

Main category: cs.CL

TL;DR: 该论文提出了一种无须人工标注的新方法（CrEst）来自动评估语言模型使用的上下文文档可信度，并通过黑盒和白盒两种方式融入推理过程。在多个模型和数据集上的实验证明，该方法能显著提升准确率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在需要知识的任务中通过上下文信息提升了性能，但这些上下文文档的可信度往往不一，这可能导致模型采纳了不可靠的信息。过去的方法忽略了评估文档可信度这一关键问题。

Method: 提出了一种新的弱监督框架CrEst, 在不需要人工标注的情况下，评估LLM推理时所用上下文文档的可信度。其核心思想是，通过文档之间的语义一致性度量可信度，并分别设计了‘黑盒’（不访问模型内部参数）和‘白盒’（直接修改模型注意力机制）两种集成策略，将可信度融入到LLM推理过程中。

Result: 在三种模型架构和五个数据集上的实验结果显示，CrEst方法相较于强基线方法，最高提升了26.86%的准确率和3.49%的F1分数，并在高噪声条件下依然表现出鲁棒性。

Conclusion: CrEst实现了无需人工标注情况下对语境文档可信度的有效估计，并通过与不同类型LLM的集成显著提升了知识密集型任务的表现，尤其在噪声较大的应用场景下更具优势。

Abstract: The integration of contextual information has significantly enhanced the
performance of large language models (LLMs) on knowledge-intensive tasks.
However, existing methods often overlook a critical challenge: the credibility
of context documents can vary widely, potentially leading to the propagation of
unreliable information. In this paper, we introduce CrEst, a novel weakly
supervised framework for assessing the credibility of context documents during
LLM inference--without requiring manual annotations. Our approach is grounded
in the insight that credible documents tend to exhibit higher semantic
coherence with other credible documents, enabling automated credibility
estimation through inter-document agreement. To incorporate credibility into
LLM inference, we propose two integration strategies: a black-box approach for
models without access to internal weights or activations, and a white-box
method that directly modifies attention mechanisms. Extensive experiments
across three model architectures and five datasets demonstrate that CrEst
consistently outperforms strong baselines, achieving up to a 26.86% improvement
in accuracy and a 3.49% increase in F1 score. Further analysis shows that CrEst
maintains robust performance even under high-noise conditions.

</details>


### [15] [MDBench: A Synthetic Multi-Document Reasoning Benchmark Generated with Knowledge Guidance](https://arxiv.org/abs/2506.14927)
*Joseph J. Peper,Wenzhao Qiu,Ali Payani,Lu Wang*

Main category: cs.CL

TL;DR: 本文提出MDBench数据集，通过合成生成方式高效创建多文档推理评测任务，为大语言模型在MD推理方面的能力提供了系统性、可扩展的评测基准，实验证明当前主流模型在该任务上仍面临显著挑战。


<details>
  <summary>Details</summary>
Motivation: 自然语言处理评测的发展推动了大语言模型（LLM）的进步，但对LLM进行多文档（MD）推理能力的系统性评测基准却很少，主要因为标注长文档非常昂贵。此外，随着LLM对长文本的处理和推理能力增强，对MD推理评测需求日益增加。

Method: 提出了MDBench数据集，通过一种新的合成生成流程构建。方法基于结构化种子知识，由LLM辅助编辑生成具有多文档推理特点的QA样例，并转化为自然语言文本的文档集及其问答对。该方法高效、可控，并能聚焦于指定的推理挑战。

Result: 实验分析显示，MDBench对主流LLM以及不同提示技巧提出了很大挑战，即使文档较短，各方法的表现也远未解决MD推理问题。此外，该知识引导的生成方法支持对MD推理能力的专项分析，并能灵活适应新的研究挑战。

Conclusion: MDBench提供了一个高效、可控并具有挑战性的新型多文档推理评测数据集，为LLM在MD推理上的能力分析和未来模型改进提供了重要工具。

Abstract: Natural language processing evaluation has made significant progress, largely
driven by the proliferation of powerful large language mod-els (LLMs). New
evaluation benchmarks are of increasing priority as the reasoning capabilities
of LLMs are expanding at a rapid pace. In particular, while multi-document (MD)
reasoning is an area of extreme relevance given LLM capabilities in handling
longer-context inputs, few benchmarks exist to rigorously examine model
behavior in this setting. Moreover, the multi-document setting is historically
challenging for benchmark creation due to the expensive cost of annotating long
inputs. In this work, we introduce MDBench, a new dataset for evaluating LLMs
on the task of multi-document reasoning. Notably, MDBench is created through a
novel synthetic generation process, allowing us to controllably and efficiently
generate challenging document sets and the corresponding question-answer (QA)
examples. Our novel technique operates on condensed structured seed knowledge,
modifying it through LLM-assisted edits to induce MD-specific reasoning
challenges. We then convert this structured knowledge into a natural text
surface form, generating a document set and corresponding QA example. We
analyze the behavior of popular LLMs and prompting techniques, finding that
MDBENCH poses significant challenges for all methods, even with relatively
short document sets. We also see our knowledge-guided generation technique (1)
allows us to readily perform targeted analysis of MD-specific reasoning
capabilities and (2) can be adapted quickly to account for new challenges and
future modeling improvements.

</details>


### [16] [From Chat to Checkup: Can Large Language Models Assist in Diabetes Prediction?](https://arxiv.org/abs/2506.14949)
*Shadman Sakib,Oishy Fatema Akhand,Ajwad Abrar*

Main category: cs.CL

TL;DR: 本文首次系统评估LLM在糖尿病结构化数据预测上的表现，发现专有LLM在少样本场景下表现优越，部分开源模型甚至优于传统机器学习方法，但依然存在提示策略敏感等问题。LLM有望为未来医疗预测提供新思路，提升健康管理水平。


<details>
  <summary>Details</summary>
Motivation: 尽管传统机器学习和深度学习模型已广泛应用于糖尿病预测，但大语言模型（LLM）在结构化数值数据处理方面的能力尚未得到充分探索。

Method: 作者以Pima印第安人糖尿病数据库（PIDD）为研究对象，采用零样本、一样本和三样本提示，系统性评估六种大语言模型（4个开源和2个专有模型），并与三种传统机器学习方法进行对比。评价指标包括准确率、精确率、召回率和F1分数。

Result: 专有LLM（如GPT-4o和Gemma-2-27B）在少样本设定下表现优越，其中Gemma-2-27B在F1分数上超越传统机器学习模型。不过，不同提示策略下模型表现仍有波动，且需要领域特定的微调。

Conclusion: LLM在医学预测任务中具有一定潜力，尤其是在优化提示工程和结合混合方法后，有望进一步提升健康预测的效果。

Abstract: While Machine Learning (ML) and Deep Learning (DL) models have been widely
used for diabetes prediction, the use of Large Language Models (LLMs) for
structured numerical data is still not well explored. In this study, we test
the effectiveness of LLMs in predicting diabetes using zero-shot, one-shot, and
three-shot prompting methods. We conduct an empirical analysis using the Pima
Indian Diabetes Database (PIDD). We evaluate six LLMs, including four
open-source models: Gemma-2-27B, Mistral-7B, Llama-3.1-8B, and Llama-3.2-2B. We
also test two proprietary models: GPT-4o and Gemini Flash 2.0. In addition, we
compare their performance with three traditional machine learning models:
Random Forest, Logistic Regression, and Support Vector Machine (SVM). We use
accuracy, precision, recall, and F1-score as evaluation metrics. Our results
show that proprietary LLMs perform better than open-source ones, with GPT-4o
and Gemma-2-27B achieving the highest accuracy in few-shot settings. Notably,
Gemma-2-27B also outperforms the traditional ML models in terms of F1-score.
However, there are still issues such as performance variation across prompting
strategies and the need for domain-specific fine-tuning. This study shows that
LLMs can be useful for medical prediction tasks and encourages future work on
prompt engineering and hybrid approaches to improve healthcare predictions.

</details>


### [17] [Memory Tokens: Large Language Models Can Generate Reversible Sentence Embeddings](https://arxiv.org/abs/2506.15001)
*Ignacio Sastre,Aiala Rosá*

Main category: cs.CL

TL;DR: 通过引入特殊可训练token嵌入，大模型在不改变参数的情况下能精确还原原始文本，表现出强大的记忆能力，对信息检索、压缩等应用很有潜力。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型(LLM)是否能够通过特殊嵌入，实现原始文本的可逆性，即能否精确还原原句，为理解模型记忆机制和信息表达方式提供参考。

Method: 通过为模型引入一个经过训练优化的特殊记忆token嵌入，模型看到该嵌入时，可以精确重构训练时的原始文本，无需更改模型参数。实验在不同规模的模型（100M到8B参数）、英语和西班牙语数据集、最长240 token的序列上进行。

Result: 包括Llama 3.1 8B在内的各种模型在实验中均能实现对指定序列的精确重构，8B版本对所有测试序列的还原无误。

Conclusion: LLM具备学习将特定嵌入完全映射为特定文本序列的能力，揭示出模型在记忆和表达信息上的新潜力，可用于基于内存的检索、压缩以及可控文本生成等任务。

Abstract: In this work, we observe an interesting phenomenon: it is possible to
generate reversible sentence embeddings that allow an LLM to reconstruct the
original text exactly, without modifying the model's weights. This is achieved
by introducing a special memory token, whose embedding is optimized through
training on a fixed sequence. When prompted with this embedding, the model
reconstructs the fixed sequence exactly. We evaluate this phenomenon across
English and Spanish datasets, sequences of up to approximately 240 tokens, and
model scales ranging from 100M to 8B parameters. Notably, Llama 3.1 8B
successfully reconstructs all tested sequences. Our findings highlight an
interesting capability of LLMs and suggest potential applications in
memory-based retrieval, compression, and controlled text generation.

</details>


### [18] [Identifying social isolation themes in NVDRS text narratives using topic modeling and text-classification methods](https://arxiv.org/abs/2506.15030)
*Drew Walker,Swati Rajwal,Sudeshna Das,Snigdha Peddireddy,Abeed Sarker*

Main category: cs.CL

TL;DR: 本研究借助NLP，对超30万例自杀案例文本分析，开发出高效识别社交孤立的人工智能模型，发现男性、同性恋者、离婚者等更可能长期社交孤立，结果有助于自杀监测与预防创新。


<details>
  <summary>Details</summary>
Motivation: 社交孤立和孤独感近年上升，且被证实显著增加自杀率，但目前美国暴力死亡报告系统（NVDRS）并未对“社交孤立”和“孤独”这类结构化变量进行记录。该研究想借助自然语言处理（NLP）方法弥补该数据缺口，提升对自杀相关因素的监测和预防。

Method: 本文应用主题建模用于词表构建，并基于监督学习开发用于识别社交孤立和孤独的分类器，对执法记录和法医记录文本进行分析，评估分类器的准确性和泛化能力。

Result: 开发的分类器性能优良（平均F1: 0.86，准确率: 0.82），在分析2002至2020年间超过30万自杀案例后，识别出1,198份存在长期社交孤立描述的案例。统计分析显示，男性、同性恋者、以及离婚者等特定人群长期社交孤立发生概率更高。此外，近期或即将发生的离婚、子女监护权丧失、驱逐或搬家，以及分手等社会事件也是重要的关联因素。

Conclusion: 研究表明，NLP方法可有效在大规模死亡报告文本中识别社交孤立和孤独，为美国相关监测和自杀预防提供新工具，有助于有针对性地开展干预和支持。

Abstract: Social isolation and loneliness, which have been increasing in recent years
strongly contribute toward suicide rates. Although social isolation and
loneliness are not currently recorded within the US National Violent Death
Reporting System's (NVDRS) structured variables, natural language processing
(NLP) techniques can be used to identify these constructs in law enforcement
and coroner medical examiner narratives. Using topic modeling to generate
lexicon development and supervised learning classifiers, we developed
high-quality classifiers (average F1: .86, accuracy: .82). Evaluating over
300,000 suicides from 2002 to 2020, we identified 1,198 mentioning chronic
social isolation. Decedents had higher odds of chronic social isolation
classification if they were men (OR = 1.44; CI: 1.24, 1.69, p<.0001), gay (OR =
3.68; 1.97, 6.33, p<.0001), or were divorced (OR = 3.34; 2.68, 4.19, p<.0001).
We found significant predictors for other social isolation topics of recent or
impending divorce, child custody loss, eviction or recent move, and break-up.
Our methods can improve surveillance and prevention of social isolation and
loneliness in the United States.

</details>


### [19] [Semantically-Aware Rewards for Open-Ended R1 Training in Free-Form Generation](https://arxiv.org/abs/2506.15068)
*Zongxia Li,Yapei Chang,Yuhang Zhou,Xiyang Wu,Zichao Liang,Yoo Yeon Sung,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: 本文提出了PrefBERT评分模型，用于更贴合人类偏好地评估和引导开放式长文本生成。通过多项实验与人类评价验证，PrefBERT有效弥补了现有方法的不足，为长文本生成任务提供了更有价值的奖励反馈。


<details>
  <summary>Details</summary>
Motivation: 现有方法在评估开放式长文本生成时经常忽略关键要素，比如连贯性、风格或相关性，并且容易受预训练数据的偏见影响。因此，开放式长文本评估依然是一个未被充分探索的问题。

Method: 提出PrefBERT评分模型，对开放式长文本生成进行评估，并在GRPO的训练过程中为好输出和坏输出提供不同的奖励信号。PrefBERT在两个涵盖多样长文本风格且带有Likert评分的数据集上进行训练，并和传统指标（如ROUGE-L和BERTScore）进行了对比测试。评估方法包括LLM作为评判者、人类评分和定性分析。

Result: PrefBERT为GRPO训练提供了比ROUGE-L和BERTScore更优的语义奖励反馈。在多句子和段落级响应上的训练表现出色，能适应不同的长文本场景，并与GRPO所需的可验证奖励高度一致。人类评估结果显示，用PrefBERT做奖励信号训练的策略模型生成的回复比用传统指标训练的更符合人类偏好。

Conclusion: PrefBERT可以提升开放式长文本生成系统的评估与训练质量，更好地对齐生成内容与人类偏好。代码已开源。

Abstract: Evaluating open-ended long-form generation is challenging because it is hard
to define what clearly separates good from bad outputs. Existing methods often
miss key aspects like coherence, style, or relevance, or are biased by
pretraining data, making open-ended long-form evaluation an underexplored
problem. To address this gap, we propose PrefBERT, a scoring model for
evaluating open-ended long-form generation in GRPO and guiding its training
with distinct rewards for good and bad outputs. Trained on two response
evaluation datasets with diverse long-form styles and Likert-rated quality,
PrefBERT effectively supports GRPO by offering better semantic reward feedback
than traditional metrics ROUGE-L and BERTScore do. Through comprehensive
evaluations, including LLM-as-a-judge, human ratings, and qualitative analysis,
we show that PrefBERT, trained on multi-sentence and paragraph-length
responses, remains reliable across varied long passages and aligns well with
the verifiable rewards GRPO needs. Human evaluations confirm that using
PrefBERT as the reward signal to train policy models yields responses better
aligned with human preferences than those trained with traditional metrics. Our
code is available at https://github.com/zli12321/long_form_rl.

</details>


### [20] [Learning-Time Encoding Shapes Unlearning in LLMs](https://arxiv.org/abs/2506.15076)
*Ruihan Wu,Konstantin Garov,Kamalika Chaudhuri*

Main category: cs.CL

TL;DR: 大语言模型的知识编码方式将直接影响后续遗忘特定知识的能力，采用同义改写训练有助于提升遗忘效果，但细粒度删除单一知识仍存挑战。


<details>
  <summary>Details</summary>
Motivation: 在现实世界广泛部署大语言模型（LLMs）时，如何在事后移除或“遗忘”特定知识已变得极为重要，原因包括隐私法规、纠正过时或有害内容等。

Method: 通过实证实验，分析训练期间知识编码的不同选择对事后遗忘事实性知识效果的影响。

Result: 1）用同义改写的描述进行训练能提升遗忘的效果；2）从一大段文本中删除单独事实性知识比较困难。

Conclusion: 训练期间如何编码知识对于后续能否有效、安全地移除特定知识有重要影响。

Abstract: As large language models (LLMs) are increasingly deployed in the real world,
the ability to ``unlearn'', or remove specific pieces of knowledge post hoc,
has become essential for a variety of reasons ranging from privacy regulations
to correcting outdated or harmful content. Prior work has proposed unlearning
benchmarks and algorithms, and has typically assumed that the training process
and the target model are fixed. In this work, we empirically investigate how
learning-time choices in knowledge encoding impact the effectiveness of
unlearning factual knowledge. Our experiments reveal two key findings: (1)
learning with paraphrased descriptions improves unlearning performance and (2)
unlearning individual piece of knowledge from a chunk of text is challenging.
Our results suggest that learning-time knowledge encoding may play a central
role in enabling reliable post-hoc unlearning.

</details>


### [21] [Improving Dialogue Discourse Parsing through Discourse-aware Utterance Clarification](https://arxiv.org/abs/2506.15081)
*Yaxin Fan,Peifeng Li,Qiaoming Zhu*

Main category: cs.CL

TL;DR: 本文提出了面向话语消歧的新方法，通过创新推理模块和反馈机制，有效提升了对话话语关系解析在歧义、模糊情况下的表现，实验优于最先进基线。


<details>
  <summary>Details</summary>
Motivation: 对话中常见的语言特性如省略和习语容易造成语义模糊，导致对话话语间话语关系解析存在很大挑战。解析器在面对含糊表达时难以准确识别话语关系。

Method: 提出了一个面向话语的消歧模块（DCM），通过“消歧类型推理”和“话语目标推理”两个推理过程来解决对话中的模糊和歧义问题。同时，引入贡献感知偏好优化（CPO）机制对DCM模块的结果进行评估和反馈，从而降低错误扩散、提升解析器的适应性和性能。

Result: 在STAC和Molweni两个数据集上的实验表明，所提出方法能有效消除对话中的歧义，并在性能上显著优于当前最新基线方法。

Conclusion: 引入DCM和CPO方法后，对话话语解析准确性获得显著提升，系统能更好地应对语言省略、习语等引发的语义歧义问题，对话解析更鲁棒、更精确，对实际应用有重要价值。

Abstract: Dialogue discourse parsing aims to identify and analyze discourse relations
between the utterances within dialogues. However, linguistic features in
dialogues, such as omission and idiom, frequently introduce ambiguities that
obscure the intended discourse relations, posing significant challenges for
parsers. To address this issue, we propose a Discourse-aware Clarification
Module (DCM) to enhance the performance of the dialogue discourse parser. DCM
employs two distinct reasoning processes: clarification type reasoning and
discourse goal reasoning. The former analyzes linguistic features, while the
latter distinguishes the intended relation from the ambiguous one. Furthermore,
we introduce Contribution-aware Preference Optimization (CPO) to mitigate the
risk of erroneous clarifications, thereby reducing cascading errors. CPO
enables the parser to assess the contributions of the clarifications from DCM
and provide feedback to optimize the DCM, enhancing its adaptability and
alignment with the parser's requirements. Extensive experiments on the STAC and
Molweni datasets demonstrate that our approach effectively resolves ambiguities
and significantly outperforms the state-of-the-art (SOTA) baselines.

</details>


### [22] [CKD-EHR:Clinical Knowledge Distillation for Electronic Health Records](https://arxiv.org/abs/2506.15118)
*Junke Wang,Hongshun Ling,Li Zhang,Longqian Zhang,Fang Wang,Yuan Gao,Zhi Li*

Main category: cs.CL

TL;DR: 本文提出了CKD-EHR模型，结合多粒度知识蒸馏和大模型微调技术，在EHR疾病预测上实现了显著的准确率和效率提升，为临床部署提供了实际可行的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的EHR疾病预测模型对精准医疗和早期干预有重要价值，但当前大型语言模型存在医疗知识表达不足和临床部署效率低的问题。

Method: 本文提出了CKD-EHR框架，利用知识蒸馏方法。首先，将Qwen2.5-7B大语言模型在医学知识增强的数据集上微调，作为教师模型。然后，通过多粒度注意力蒸馏机制生成可解释的软标签。最终，将蒸馏知识转移到轻量级的BERT学生模型。

Result: 在MIMIC-III数据集上的实验结果表明，CKD-EHR相较于基线模型，准确率提升9%，F1-score提升27%，推理速度提升22.2倍。

Conclusion: CKD-EHR不仅大幅提升了资源利用效率，还显著提高了诊断的准确性和及时性，为临床场景下的资源优化提供了实用的技术方案。

Abstract: Electronic Health Records (EHR)-based disease prediction models have
demonstrated significant clinical value in promoting precision medicine and
enabling early intervention. However, existing large language models face two
major challenges: insufficient representation of medical knowledge and low
efficiency in clinical deployment. To address these challenges, this study
proposes the CKD-EHR (Clinical Knowledge Distillation for EHR) framework, which
achieves efficient and accurate disease risk prediction through knowledge
distillation techniques. Specifically, the large language model Qwen2.5-7B is
first fine-tuned on medical knowledge-enhanced data to serve as the teacher
model.It then generates interpretable soft labels through a multi-granularity
attention distillation mechanism. Finally, the distilled knowledge is
transferred to a lightweight BERT student model. Experimental results show that
on the MIMIC-III dataset, CKD-EHR significantly outperforms the baseline
model:diagnostic accuracy is increased by 9%, F1-score is improved by 27%, and
a 22.2 times inference speedup is achieved. This innovative solution not only
greatly improves resource utilization efficiency but also significantly
enhances the accuracy and timeliness of diagnosis, providing a practical
technical approach for resource optimization in clinical settings. The code and
data for this research are available athttps://github.com/209506702/CKD_EHR.

</details>


### [23] [Modeling the One-to-Many Property in Open-Domain Dialogue with LLMs](https://arxiv.org/abs/2506.15131)
*Jing Yang Lee,Kong-Aik Lee,Woon-Seng Gan*

Main category: cs.CL

TL;DR: 本文针对现代大模型对话系统未显式建模“一对多”特性的问题，提出多回复生成与基于偏好选择的两阶段方法，并引入o2mDial语料库。实验证明，该方法显著提升小模型回复的多样性与质量，接近大型模型水平。


<details>
  <summary>Details</summary>
Motivation: 开放域对话有“一对多”的特点，即同一个对话上下文可以有多个合适的回复。尽管以往的研究证明建模该性质可以提升回复多样性，但目前大多数大模型对话系统并不显式建模这一点。

Method: 将开放域对话的生成分解为两个阶段：多回复生成（MRG）和基于偏好的选择（PS）。具体方法为：先为每个对话上下文生成n个语义及词汇多样的高质量回复，然后基于人类偏好选择唯一回复。同时引入了新语料库o2mDial，开发了新颖的学习策略及评价指标。

Result: 实验证明，该两阶段框架可使小型大模型在开放域对话生成任务中提升回复多样性，同时保持上下文连贯性，回复质量最多提升90%，效果接近大型模型。

Conclusion: 通过显式建模开放域对话的一对多特性，可以极大提升回复的质量与多样性，尤其是在小型模型中成效显著。提出的框架有效缩小了小模型与大型模型的性能差距。

Abstract: Open-domain Dialogue (OD) exhibits a one-to-many (o2m) property, whereby
multiple appropriate responses exist for a single dialogue context. Despite
prior research showing that modeling this property boosts response diversity,
most modern LLM-based dialogue agents do not explicitly do so. In this work, we
model the o2m property of OD in LLMs by decomposing OD generation into two key
tasks: Multi-Response Generation (MRG) and Preference-based Selection (PS),
which entail generating a set of n semantically and lexically diverse
high-quality responses for a given dialogue context, followed by selecting a
single response based on human preference, respectively. To facilitate MRG and
PS, we introduce o2mDial, a dialogue corpus explicitly designed to capture the
o2m property by featuring multiple plausible responses for each context.
Leveraging o2mDial, we propose new in-context learning and instruction-tuning
strategies, as well as novel evaluation metrics for MRG, alongside a
model-based approach for PS. Empirical results demonstrate that applying the
proposed two-stage framework to smaller LLMs for OD generation enhances overall
response diversity while maintaining contextual coherence, improving response
quality by up to 90%, bringing them closer to the performance of larger models.

</details>


### [24] [Thunder-Tok: Minimizing Tokens per Word in Tokenizing Korean Texts for Generative Language Models](https://arxiv.org/abs/2506.15138)
*Gyeongje Cho,Yeonkyoun So,Chanwoo Park,Sangmin Lee,Sungmok Jung,Jaejin Lee*

Main category: cs.CL

TL;DR: 本论文提出韩语高效分词器Thunder-Tok，通过结合规则化分词和熵值算法，减少token数量约10%，模型速度提升且效果不降。


<details>
  <summary>Details</summary>
Motivation: 现有分词方法（如BPE）在韩语处理中token数量高（fertility高），影响模型效率，因此需要一种能兼顾效率和效果的新分词方法。

Method: 设计了与韩语语言结构对齐的规则化预分词方法，结合具备语言单元特征的种子词汇，用分支熵算法进行 token 选择，从而降低token数量。

Result: Thunder-Tok 将token数量（fertility）降低约10%，推理速度提升10%，且对下游任务性能无负面影响。

Conclusion: Thunder-Tok 能在不降低模型性能的情况下，有效降低韩语分词的 token 数量，提高推理速度。

Abstract: This paper introduces Thunder-Tok, a new Korean tokenizer designed to reduce
token fertility without compromising model performance. Our approach uses a
rule-based pre-tokenization method that aligns with the linguistic structure of
the Korean language. We also create a seed vocabulary containing tokens that
resemble linguistic units and employ a branching entropy-based selection
algorithm. These techniques increase the average token length, thus lowering
fertility while preserving linguistic information. Experimental results
indicate that Thunder-Tok reduces fertility by approximately 10% (i.e., reduces
the number of tokens by 10%, improving the inference speed by 10%) compared to
BPE without compromising performance across various downstream tasks. These
findings demonstrate that our linguistically informed approach is effective and
practical for designing efficient tokenizers for language models.

</details>


### [25] [Emergence of Primacy and Recency Effect in Mamba: A Mechanistic Point of View](https://arxiv.org/abs/2506.15156)
*Muhammad Cendekia Airlangga,Hilal AlQuabeh,Munachiso S Nwadike,Kentaro Inui*

Main category: cs.CL

TL;DR: 本研究系统揭示了Mamba语言模型深层次记忆机制，并指出其U型准确率分布源于独特的长期/短期记忆通道及语义动态调节。这些结论为理解和优化状态空间语言模型的记忆能力提供了理论和实验依据。


<details>
  <summary>Details</summary>
Motivation: 探究状态空间语言模型（特别是Mamba架构）记忆信息的方式，尤其关注模型如何保留和遗忘信息。利用心理学中的首因效应和近因效应，分析信息在模型处理序列中的留存和遗忘规律。

Method: 设计结构化回忆任务，对Mamba架构的语言模型（分别为1.4B和7B参数规模）进行实验分析。通过定位模型内部机制，并采用靶向消融和输入扰动的方法，系统性地分析不同记忆效应产生的原因。

Result: 发现准确率呈U型分布——序列首尾表现较好；长时记忆依赖于模型中稀疏选择性状态空间通道，短时记忆则由delta调制的递归机制主导且易受干扰，语义重复会动态调整记忆分配，加剧中间项的遗忘。所有发现均在两种规模模型上得到验证。

Conclusion: Mamba语言模型的记忆机制受内部结构影响，存在明显的首因和近因效应，其运作机制可分为长期、短期和语义相关三类，且各有独特的表现和局限。通过详细剖析和实验证明了这些机理的普遍性和对模型行为的影响。

Abstract: We study memory in state-space language models using primacy and recency
effects as behavioral tools to uncover how information is retained and
forgotten over time. Applying structured recall tasks to the Mamba
architecture, we observe a consistent U-shaped accuracy profile, indicating
strong performance at the beginning and end of input sequences. We identify
three mechanisms that give rise to this pattern. First, long-term memory is
supported by a sparse subset of channels within the model's selective state
space block, which persistently encode early input tokens and are causally
linked to primacy effects. Second, short-term memory is governed by
delta-modulated recurrence: recent inputs receive more weight due to
exponential decay, but this recency advantage collapses when distractor items
are introduced, revealing a clear limit to memory depth. Third, we find that
memory allocation is dynamically modulated by semantic regularity: repeated
relations in the input sequence shift the delta gating behavior, increasing the
tendency to forget intermediate items. We validate these findings via targeted
ablations and input perturbations on two large-scale Mamba-based language
models: one with 1.4B and another with 7B parameters.

</details>


### [26] [A Comparative Study of Task Adaptation Techniques of Large Language Models for Identifying Sustainable Development Goals](https://arxiv.org/abs/2506.15208)
*Andrea Cadeddu,Alessandro Chessa,Vincenzo De Leo,Gianni Fenu,Enrico Motta,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino,Luca Secchi*

Main category: cs.CL

TL;DR: 为实现联合国可持续发展目标的自动文本分类追踪，本研究分析了多种大型语言模型及多种任务适应技术，发现经优化的小型模型可实现与大型模型相近的分类性能。


<details>
  <summary>Details</summary>
Motivation: 联合国提出了17个可持续发展目标（SDGs），但由于相关数据规模和复杂度大，进展追踪变得困难。文本分类模型可自动处理和分析大量文本数据，因此成为实现SDGs追踪的重要工具。近期的大型语言模型（LLMs）在文本分类等任务中表现突出。

Method: 本研究对多种专有及开源的大型语言模型（LLMs）在SDGs相关单标签、多类别文本分类任务中的表现进行了分析。同时评估了零样本学习（Zero-Shot）、小样本学习（Few-Shot）和微调（Fine-Tuning）等任务适应技术的有效性，尤其关注上下文学习（in-context learning）的方法。

Result: 研究结果显示，通过提示工程优化后的小型语言模型，其性能能够与大型语言模型（如OpenAI的GPT）相媲美。

Conclusion: 通过提示工程等优化手段，小体量模型同样能够有效用于SDGs相关的文本分类任务，具备与主流大型模型竞争的能力，有望降低资源消耗。

Abstract: In 2012, the United Nations introduced 17 Sustainable Development Goals
(SDGs) aimed at creating a more sustainable and improved future by 2030.
However, tracking progress toward these goals is difficult because of the
extensive scale and complexity of the data involved. Text classification models
have become vital tools in this area, automating the analysis of vast amounts
of text from a variety of sources. Additionally, large language models (LLMs)
have recently proven indispensable for many natural language processing tasks,
including text classification, thanks to their ability to recognize complex
linguistic patterns and semantics. This study analyzes various proprietary and
open-source LLMs for a single-label, multi-class text classification task
focused on the SDGs. Then, it also evaluates the effectiveness of task
adaptation techniques (i.e., in-context learning approaches), namely Zero-Shot
and Few-Shot Learning, as well as Fine-Tuning within this domain. The results
reveal that smaller models, when optimized through prompt engineering, can
perform on par with larger models like OpenAI's GPT (Generative Pre-trained
Transformer).

</details>


### [27] [ProtoReasoning: Prototypes as the Foundation for Generalizable Reasoning in LLMs](https://arxiv.org/abs/2506.15211)
*Feng He,Zijun Chen,Xinnian Liang,Tingting Ma,Yunqi Qiu,Shuangzhi Wu,Junchi Yan*

Main category: cs.CL

TL;DR: 本文提出ProtoReasoning框架，用可扩展、可验证的原型表达增强大模型推理能力，实验证明其显著提升了各类推理与规划任务的泛化与准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型（LRMs）在长链式推理任务中表现出优秀的跨领域泛化能力，但其背后的迁移机制尚未被充分揭示。论文认为，将多领域问题抽象为共享的推理原型，是多领域泛化能力的根本原因。

Method: 提出ProtoReasoning框架，通过原型表示（如Prolog用于逻辑推理、PDDL用于规划）提升LLM的推理能力。该框架包括：（1）自动原型构建流程；（2）基于Prolog/PDDL的验证系统反馈；（3）能够在原型空间内大规模合成问题并确保正确性。

Result: 实验证明ProtoReasoning在多个任务上优于基线模型：逻辑推理提升4.7%、规划任务提升6.3%、通用推理提升4.0%、数学提升1.0%。消融实验表明，在原型空间中学习，比仅基于自然语言表示有更好的结构化泛化能力。

Conclusion: 原型推理（ProtoReasoning）能够增强大模型的推理与泛化能力，进一步验证了推理原型作为大模型跨领域推理基础的假设。

Abstract: Recent advances in Large Reasoning Models (LRMs) trained with Long
Chain-of-Thought (Long CoT) reasoning have demonstrated remarkable cross-domain
generalization capabilities. However, the underlying mechanisms supporting such
transfer remain poorly understood. We hypothesize that cross-domain
generalization arises from shared abstract reasoning prototypes -- fundamental
reasoning patterns that capture the essence of problems across domains. These
prototypes minimize the nuances of the representation, revealing that seemingly
diverse tasks are grounded in shared reasoning structures.Based on this
hypothesis, we propose ProtoReasoning, a framework that enhances the reasoning
ability of LLMs by leveraging scalable and verifiable prototypical
representations (Prolog for logical reasoning, PDDL for
planning).ProtoReasoning features: (1) an automated prototype construction
pipeline that transforms problems into corresponding prototype representations;
(2) a comprehensive verification system providing reliable feedback through
Prolog/PDDL interpreters; (3) the scalability to synthesize problems
arbitrarily within prototype space while ensuring correctness. Extensive
experiments show that ProtoReasoning achieves 4.7% improvement over baseline
models on logical reasoning (Enigmata-Eval), 6.3% improvement on planning
tasks, 4.0% improvement on general reasoning (MMLU) and 1.0% on mathematics
(AIME24). Significantly, our ablation studies confirm that learning in
prototype space also demonstrates enhanced generalization to structurally
similar problems compared to training solely on natural language
representations, validating our hypothesis that reasoning prototypes serve as
the foundation for generalizable reasoning in large language models.

</details>


### [28] [MinosEval: Distinguishing Factoid and Non-Factoid for Tailored Open-Ended QA Evaluation with LLMs](https://arxiv.org/abs/2506.15215)
*Yongqi Fan,Yating Wang,Guandong Wang,Jie Zhai,Jingping Liu,Qi Ye,Tong Ruan*

Main category: cs.CL

TL;DR: 该文提出了针对开放式问答系统的自动评测新方法MinosEval，分别针对事实型与非事实型问题采用不同策略，在评测准确性和可解释性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在开放式问答(Question Answering, QA)中，评估大语言模型能力面临多样性答案、复杂推理和多表达形式的问题。传统指标（如ROUGE、BERTScore）无法有效衡量语义相似性，现有LLM评测方法缺乏可解释性，并忽视了事实型和非事实型问题的差异。研究者亟需更细致且具可解释性的自动评测方法。

Method: 提出MinosEval新评测方法，首先区分事实型与非事实型开放式问题，然后采用不同策略评估候选答案：对事实型问题采用自适应关键点评分(key-point scoring)策略，对非事实型问题采用实例感知型列表排序(listwise ranking)策略。同时在多个开放式QA数据集（含自建、多样候选答案）上进行了实验。

Result: 实验结果表明MinosEval在多个开放式QA数据集上的评测结果更对齐人工标注，且结果更具可解释性，相比现有方法在可靠性和解释性方面显著提升。

Conclusion: MinosEval创新性地根据问题类型采用差异化评估策略，有效提升了开放式QA任务大语言模型答案的自动评测准确性和可解释性。此方法为后续LLM能力评估与QA任务评价提供了更科学的工具。

Abstract: Open-ended question answering (QA) is a key task for evaluating the
capabilities of large language models (LLMs). Compared to closed-ended QA, it
demands longer answer statements, more nuanced reasoning processes, and diverse
expressions, making refined and interpretable automatic evaluation both crucial
and challenging. Traditional metrics like ROUGE and BERTScore struggle to
capture semantic similarities due to different patterns between model responses
and reference answers. Current LLM-based evaluation approaches, such as
pairwise or listwise comparisons of candidate answers, lack intuitive
interpretability. While pointwise scoring of each response provides some
descriptions, it fails to adapt across different question contents. Most
notably, existing methods overlook the distinction between factoid and
non-factoid questions. To address these challenges, we propose
\textbf{MinosEval}, a novel evaluation method that first distinguishes
open-ended questions and then ranks candidate answers using different
evaluation strategies. For factoid questions, it applies an adaptive key-point
scoring strategy, while for non-factoid questions, it uses an instance-aware
listwise ranking strategy. Experiments on multiple open-ended QA datasets,
including self-built ones with more candidate responses to complement community
resources, show that MinosEval better aligns with human annotations and offers
more interpretable results.

</details>


### [29] [Lost in Variation? Evaluating NLI Performance in Basque and Spanish Geographical Variants](https://arxiv.org/abs/2506.15239)
*Jaione Bengoetxea,Itziar Gonzalez-Dios,Rodrigo Agerri*

Main category: cs.CL

TL;DR: 本文构建了巴斯克语和西班牙语及其方言的新型数据集，通过NLI任务评估当前主流大模型在处理这些语言变体时的能力，发现模型尤其难以理解边缘方言，显示出语言变体对模型性能的显著挑战。


<details>
  <summary>Details</summary>
Motivation: 近年来，大型语言模型在多种自然语言处理任务上取得了显著进展，但对于具有丰富方言变体的语言（如巴斯克语和西班牙语）的理解能力尚不明确。本文旨在评估当前语言技术对这些语言及其方言变体的处理能力，揭示现有方法的局限性。

Method: 作者以自然语言推断（NLI）作为研究任务，构建了一个新颖的、手工整理的巴斯克语与西班牙语及其方言变体的平行数据集。通过交叉语言学习与上下文学习实验，分别测试了编码器-only和解码器型大型语言模型的表现。论文还进行了错误分析与消融实验，深入分析不同模型对于各方言的处理难点。

Result: 实验表明，当模型处理语言变体时，性能明显下降，对巴斯克语表现尤为显著。错误分析显示性能下降并非由词汇重叠造成，而与语言变体本身有关。消融实验进一步表明，编码器-only模型对于西部巴斯克方言的处理尤为困难，这与语言学理论关于边缘方言距离标准语更远的观点一致。

Conclusion: 当前的大型语言模型在理解语言变体（特别是巴斯克语及其边缘方言）上存在明显瓶颈。提升对多样化语言变体的建模能力仍是未来语言技术发展的重要方向。

Abstract: In this paper, we evaluate the capacity of current language technologies to
understand Basque and Spanish language varieties. We use Natural Language
Inference (NLI) as a pivot task and introduce a novel, manually-curated
parallel dataset in Basque and Spanish, along with their respective variants.
Our empirical analysis of crosslingual and in-context learning experiments
using encoder-only and decoder-based Large Language Models (LLMs) shows a
performance drop when handling linguistic variation, especially in Basque.
Error analysis suggests that this decline is not due to lexical overlap, but
rather to the linguistic variation itself. Further ablation experiments
indicate that encoder-only models particularly struggle with Western Basque,
which aligns with linguistic theory that identifies peripheral dialects (e.g.,
Western) as more distant from the standard. All data and code are publicly
available.

</details>


### [30] [Research on Graph-Retrieval Augmented Generation Based on Historical Text Knowledge Graphs](https://arxiv.org/abs/2506.15241)
*Yang Fan,Zhang Qi,Xing Wenqian,Liu Chang,Liu Liu*

Main category: cs.CL

TL;DR: 作者提出GraphRAG框架，低标注成本下自动构建历史人物关系数据集，通过知识图谱与检索增强生成协作优化关系抽取任务，在中文历史文本及开放域测试集上均显著提升了准确率与可解释性，有助于数字人文与AIGC领域的发展。


<details>
  <summary>Details</summary>
Motivation: 当前的大语言模型在历史文本分析时存在领域知识不足的问题，影响了其在数字人文学科及AIGC技术下的应用效果。如何低成本地提升模型对历史文本的理解和知识提取能力，成为亟需解决的挑战。

Method: 提出Graph RAG框架，融合了链式思考提示、自动生成自监督指令与过程监督，利用极少量人工标注，构建了《前四史》人物关系数据集。在生成阶段，知识图谱与检索增强生成算法（GraphRAG）协同工作，以提升大模型的历史知识拟合度与抽取准确性。

Result: 以Xunzi-Qwen1.5-14B模型（中文输入+链式思考提示）实现了历史人物关系抽取F1=0.68。将GraphRAG集成到DeepSeek模型后，在C-CLUE开放域关系抽取任务上F1提升11%（0.08-0.19），超过Xunzi-Qwen1.5-14B（F1=0.12），显著降低了幻觉现象并提升了可解释性。

Conclusion: GraphRAG框架为经典文本知识抽取提供了一种低资源、高效率的新方法，提升了历史知识服务与数字人文研究能力。

Abstract: This article addresses domain knowledge gaps in general large language models
for historical text analysis in the context of computational humanities and
AIGC technology. We propose the Graph RAG framework, combining chain-of-thought
prompting, self-instruction generation, and process supervision to create a The
First Four Histories character relationship dataset with minimal manual
annotation. This dataset supports automated historical knowledge extraction,
reducing labor costs. In the graph-augmented generation phase, we introduce a
collaborative mechanism between knowledge graphs and retrieval-augmented
generation, improving the alignment of general models with historical
knowledge. Experiments show that the domain-specific model Xunzi-Qwen1.5-14B,
with Simplified Chinese input and chain-of-thought prompting, achieves optimal
performance in relation extraction (F1 = 0.68). The DeepSeek model integrated
with GraphRAG improves F1 by 11% (0.08-0.19) on the open-domain C-CLUE relation
extraction dataset, surpassing the F1 value of Xunzi-Qwen1.5-14B (0.12),
effectively alleviating hallucinations phenomenon, and improving
interpretability. This framework offers a low-resource solution for classical
text knowledge extraction, advancing historical knowledge services and
humanities research.

</details>


### [31] [TopClustRAG at SIGIR 2025 LiveRAG Challenge](https://arxiv.org/abs/2506.15246)
*Juli Bakagianni,John Pavlopoulos,Aristidis Likas*

Main category: cs.CL

TL;DR: TopClustRAG通过混合检索和聚类优化RAG系统，提升了问答的多样性和准确性，在大规模数据集评测中表现突出。


<details>
  <summary>Details</summary>
Motivation: 大规模网页语料库上端到端问答具有挑战性，尤其是在提高答案的多样性、相关性和准确性方面。本文旨在改进当前检索增强生成（RAG）系统在这些方面的表现。

Method: 系统结合稀疏和稠密索引的混合检索方式，在检索到文本后，通过K-Means聚类将语义相似的段落分组。每个聚类中选出代表性段落，构建针对集群的提示词给大模型生成中间答案，再经过过滤、重排序，最终综合生成单一答案。

Result: 在FineWeb Sample-10BT数据集上，TopClustRAG系统在官方排行榜上忠实度排名第2，正确性排名第7，表明聚类过滤和多阶段提示聚合在大规模RAG系统中效果显著。

Conclusion: 聚类和多阶段提示聚合能有效提升大规模RAG系统的答案多样性、相关性和忠实度，方法在排行榜中取得优异成绩。

Abstract: We present TopClustRAG, a retrieval-augmented generation (RAG) system
developed for the LiveRAG Challenge, which evaluates end-to-end question
answering over large-scale web corpora. Our system employs a hybrid retrieval
strategy combining sparse and dense indices, followed by K-Means clustering to
group semantically similar passages. Representative passages from each cluster
are used to construct cluster-specific prompts for a large language model
(LLM), generating intermediate answers that are filtered, reranked, and finally
synthesized into a single, comprehensive response. This multi-stage pipeline
enhances answer diversity, relevance, and faithfulness to retrieved evidence.
Evaluated on the FineWeb Sample-10BT dataset, TopClustRAG ranked 2nd in
faithfulness and 7th in correctness on the official leaderboard, demonstrating
the effectiveness of clustering-based context filtering and prompt aggregation
in large-scale RAG systems.

</details>


### [32] [Thunder-DeID: Accurate and Efficient De-identification Framework for Korean Court Judgments](https://arxiv.org/abs/2506.15266)
*Sungen Hahm,Heejin Kim,Gyuseong Lee,Hyunji Park,Jaejin Lee*

Main category: cs.CL

TL;DR: 本文针对韩国法院判决文书去标识化难题，提出并验证了一套包含数据集、PII分类及深度学习模型的综合解决方案，在保保护隐私和提升判决公开效率方面取得了优异成果。


<details>
  <summary>Details</summary>
Motivation: 韩国法律要求公开法院判决时必须去标识化个人信息，但现有流程无法高效、合规地处理大规模判决文书。此外，法律规定的个人标识信息定义模糊，难以直接应用于技术实现。

Method: 提出Thunder-DeID框架，具体包括：构建并发布首个带注释的韩文法律判决数据集及实体列表，提出系统化的个人可识别信息（PII）分类，并开发基于深度神经网络的端到端去标识化流程。

Result: 实验表明，所提出的模型在法院判决文书去标识化任务中达到了当前最优的效果。

Conclusion: Thunder-DeID框架可兼顾法律合规性与技术可行性，显著提升了法院判决文书去标识化的效率与准确性。

Abstract: To ensure a balance between open access to justice and personal data
protection, the South Korean judiciary mandates the de-identification of court
judgments before they can be publicly disclosed. However, the current
de-identification process is inadequate for handling court judgments at scale
while adhering to strict legal requirements. Additionally, the legal
definitions and categorizations of personal identifiers are vague and not
well-suited for technical solutions. To tackle these challenges, we propose a
de-identification framework called Thunder-DeID, which aligns with relevant
laws and practices. Specifically, we (i) construct and release the first Korean
legal dataset containing annotated judgments along with corresponding lists of
entity mentions, (ii) introduce a systematic categorization of Personally
Identifiable Information (PII), and (iii) develop an end-to-end deep neural
network (DNN)-based de-identification pipeline. Our experimental results
demonstrate that our model achieves state-of-the-art performance in the
de-identification of court judgments.

</details>


### [33] [Cohort Discovery: A Survey on LLM-Assisted Clinical Trial Recruitment](https://arxiv.org/abs/2506.15301)
*Shrestha Ghosh,Moritz Schneider,Carina Reinicke,Carsten Eickhoff*

Main category: cs.CL

TL;DR: 本文综述了大型语言模型在临床试验-患者匹配任务中的应用与挑战，指出现有方法多依赖闭源模型与薄弱评测，强调需完善公开模型与评价标准，未来发展空间巨大。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在通用NLP任务上表现优异，但在临床试验招募等关键领域的应用有限。传统方法难以泛化，LLM能够汇总知识和推理，有潜力为患者与试验的匹配构建更通用的解决方案。

Method: 本文通过调研当前的文献和方法，对试验-患者匹配任务进行首次系统性分析，评估和对比现有基于LLM的方法、基准和评价框架，并探讨其面临的挑战及未来发展方向。

Result: 文献评价显示，尽管LLM具备应用潜力，但当前多依赖闭源模型和不充分的评测基准，实际应用还存在诸多挑战。

Conclusion: LLM为临床试验招募中的试验-患者匹配带来新机遇，但在模型开放性、评测体系等方面需克服多重挑战，未来有广阔的研究空间。

Abstract: Recent advances in LLMs have greatly improved general-domain NLP tasks. Yet,
their adoption in critical domains, such as clinical trial recruitment, remains
limited. As trials are designed in natural language and patient data is
represented as both structured and unstructured text, the task of matching
trials and patients benefits from knowledge aggregation and reasoning abilities
of LLMs. Classical approaches are trial-specific and LLMs with their ability to
consolidate distributed knowledge hold the potential to build a more general
solution. Yet recent applications of LLM-assisted methods rely on proprietary
models and weak evaluation benchmarks. In this survey, we are the first to
analyze the task of trial-patient matching and contextualize emerging LLM-based
approaches in clinical trial recruitment. We critically examine existing
benchmarks, approaches and evaluation frameworks, the challenges to adopting
LLM technologies in clinical research and exciting future directions.

</details>


### [34] [ConLID: Supervised Contrastive Learning for Low-Resource Language Identification](https://arxiv.org/abs/2506.15304)
*Negar Foroutan,Jakhongir Saydaliev,Ye Eun Kim,Antoine Bosselut*

Main category: cs.CL

TL;DR: 本文提出用监督式对比学习提升低资源语言的语言识别性能，实验表明对跨领域任务有明显提升。


<details>
  <summary>Details</summary>
Motivation: 现有LID模型对于低资源语言表现较差，尤其是训练数据来源单一（如圣经），导致类别不平衡和偏倚问题。

Method: 本文提出了一种新颖的监督式对比学习（SCL）方法，旨在针对低资源语言学习领域无关的表征。

Result: 该方法将低资源语言的跨领域LID性能提升了3.2%。

Conclusion: 所提出的监督式对比学习（SCL）方法能够有效提升低资源语言的跨领域识别效果，从而改善语言识别模型的表现。

Abstract: Language identification (LID) is a critical step in curating multilingual LLM
pretraining corpora from web crawls. While many studies on LID model training
focus on collecting diverse training data to improve performance, low-resource
languages -- often limited to single-domain data, such as the Bible -- continue
to perform poorly. To resolve these class imbalance and bias issues, we propose
a novel supervised contrastive learning (SCL) approach to learn
domain-invariant representations for low-resource languages. Through an
extensive analysis, we show that our approach improves LID performance on
out-of-domain data for low-resource languages by 3.2%, demonstrating its
effectiveness in enhancing LID models.

</details>


### [35] [DeVisE: Behavioral Testing of Medical Large Language Models](https://arxiv.org/abs/2506.15339)
*Camila Zurdo Tagliabue,Heloisa Oss Boll,Aykut Erdem,Erkut Erdem,Iacer Calixto*

Main category: cs.CL

TL;DR: 作者提出DeVisE行为测试方法，通过带反事实的ICU出院数据评估五种大模型的临床推理，发现零样本模型推理更好，微调模型对临床变化不敏感，人口变量影响显著，强调了公平性和行为测试在医疗AI中的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有对临床辅助决策用大型语言模型（LLM）的评估方法，难以区分真正医学推理与表面模式识别。本研究希望通过新的行为测试框架，深入探查模型对临床细节的理解能力。

Method: 提出DeVisE测试框架，基于MIMIC-IV中的ICU出院记录，构建真实及合成（模板化、控制单变量反事实）数据集，主要变量为人口学特征（年龄、性别、族裔）与生命体征。对五个LLM（通用与医学微调版）进行零样本和微调评估，从输入敏感性和下游推理两方面分析。

Result: 结果发现，零样本模型在反事实推理上更连贯，微调模型更稳定但对临床变化反应不足。人口学变量对模型输出有持续细微影响，提醒需要公平性评估。

Conclusion: 提出的行为测试框架能揭示临床LLM的推理机制，对安全透明的医疗AI系统设计具有重要意义。

Abstract: Large language models (LLMs) are increasingly used in clinical decision
support, yet current evaluation methods often fail to distinguish genuine
medical reasoning from superficial patterns. We introduce DeVisE (Demographics
and Vital signs Evaluation), a behavioral testing framework for probing
fine-grained clinical understanding. We construct a dataset of ICU discharge
notes from MIMIC-IV, generating both raw (real-world) and template-based
(synthetic) versions with controlled single-variable counterfactuals targeting
demographic (age, gender, ethnicity) and vital sign attributes. We evaluate
five LLMs spanning general-purpose and medically fine-tuned variants, under
both zero-shot and fine-tuned settings. We assess model behavior via (1)
input-level sensitivity - how counterfactuals alter the likelihood of a note;
and (2) downstream reasoning - how they affect predicted hospital
length-of-stay. Our results show that zero-shot models exhibit more coherent
counterfactual reasoning patterns, while fine-tuned models tend to be more
stable yet less responsive to clinically meaningful changes. Notably,
demographic factors subtly but consistently influence outputs, emphasizing the
importance of fairness-aware evaluation. This work highlights the utility of
behavioral testing in exposing the reasoning strategies of clinical LLMs and
informing the design of safer, more transparent medical AI systems.

</details>


### [36] [SANSKRITI: A Comprehensive Benchmark for Evaluating Language Models' Knowledge of Indian Culture](https://arxiv.org/abs/2506.15355)
*Arijit Maji,Raghvendra Kumar,Akash Ghosh,Anushka,Sriparna Saha*

Main category: cs.CL

TL;DR: 提出了系统性的印度文化知识评测集SANSKRITI，用以检验主流语言模型在地域文化层面的理解能力，发现现有模型在本地化挑战上存在较大差距，为未来改进提供参考。


<details>
  <summary>Details</summary>
Motivation: 当前主流语言模型在应用于不同地区时存在理解当地社会文化语境的难题，迫切需要评价和提升模型在地区文化方面的能力。

Method: 作者构建了涵盖28个邦及8个联邦属地、共21,853个问答对的SANSKRITI数据集，覆盖印度文化16个关键属性，并在多个主流大语言模型（LLMs）、本地语言模型（ILMs）及小型语言模型（SLMs）上进行评测。

Result: 评测结果表明，多数模型在处理含有地域及文化细节的问题时表现不佳，尤其是在特定区域相关问题上的理解能力存在明显不足。

Conclusion: SANSKRITI数据集为评估语言模型在印度文化理解方面提供了全新标准，揭示现有模型在地域性文化语境下的显著短板。

Abstract: Language Models (LMs) are indispensable tools shaping modern workflows, but
their global effectiveness depends on understanding local socio-cultural
contexts. To address this, we introduce SANSKRITI, a benchmark designed to
evaluate language models' comprehension of India's rich cultural diversity.
Comprising 21,853 meticulously curated question-answer pairs spanning 28 states
and 8 union territories, SANSKRITI is the largest dataset for testing Indian
cultural knowledge. It covers sixteen key attributes of Indian culture: rituals
and ceremonies, history, tourism, cuisine, dance and music, costume, language,
art, festivals, religion, medicine, transport, sports, nightlife, and
personalities, providing a comprehensive representation of India's cultural
tapestry. We evaluate SANSKRITI on leading Large Language Models (LLMs), Indic
Language Models (ILMs), and Small Language Models (SLMs), revealing significant
disparities in their ability to handle culturally nuanced queries, with many
models struggling in region-specific contexts. By offering an extensive,
culturally rich, and diverse dataset, SANSKRITI sets a new standard for
assessing and improving the cultural understanding of LMs.

</details>


### [37] [COSMMIC: Comment-Sensitive Multimodal Multilingual Indian Corpus for Summarization and Headline Generation](https://arxiv.org/abs/2506.15372)
*Raghvendra Kumar,S. A. Mohammed Salman,Aryan Sahu,Tridib Nandi,Pragathi Y. P.,Sriparna Saha,Jose G. Moreno*

Main category: cs.CL

TL;DR: 本文提出了首个面向九种印度语言的多模态评论感知摘要数据集COSMMIC，并在多种配置下进行了系统评测，为印度语种NLP及多模态应用研究提供了宝贵资源。


<details>
  <summary>Details</summary>
Motivation: 尽管在英文和中文的评论感知多模态与多语言摘要取得了一定进展，印度语言相关研究却极为有限。因此，该研究试图填补这一空白。

Method: 提出了COSMMIC数据集，涵盖九种主要印度语言，含有4959篇文章-图片对和24484条用户评论，并为每种语言提供权威摘要。研究对四种组合（仅文本、加入评论、加入图片、文本+评论+图片）进行摘要和标题生成实验，引入LLama3和GPT-4进行评估。同时，通过IndicBERT评论分类器和多语言CLIP工具分别对评论和图片进行筛选和处理，以去除噪声并提取有价值信息。

Result: 全面评测各组件组合对自然语言生成（NLG）任务的有效性，发现结合文本、图片和用户评论的数据集更能反映多模态语境下的真实应用需求。COSMMIC为印度语言NLP研究提供了具有代表性且多样的新资源。

Conclusion: COSMMIC首次实现了多模态、多语言、评论感知的印度语言摘要任务数据集建设，显著助力印度语言NLP研究和多样化包容性发展。

Abstract: Despite progress in comment-aware multimodal and multilingual summarization
for English and Chinese, research in Indian languages remains limited. This
study addresses this gap by introducing COSMMIC, a pioneering comment-sensitive
multimodal, multilingual dataset featuring nine major Indian languages. COSMMIC
comprises 4,959 article-image pairs and 24,484 reader comments, with
ground-truth summaries available in all included languages. Our approach
enhances summaries by integrating reader insights and feedback. We explore
summarization and headline generation across four configurations: (1) using
article text alone, (2) incorporating user comments, (3) utilizing images, and
(4) combining text, comments, and images. To assess the dataset's
effectiveness, we employ state-of-the-art language models such as LLama3 and
GPT-4. We conduct a comprehensive study to evaluate different component
combinations, including identifying supportive comments, filtering out noise
using a dedicated comment classifier using IndicBERT, and extracting valuable
insights from images with a multilingual CLIP-based classifier. This helps
determine the most effective configurations for natural language generation
(NLG) tasks. Unlike many existing datasets that are either text-only or lack
user comments in multimodal settings, COSMMIC uniquely integrates text, images,
and user feedback. This holistic approach bridges gaps in Indian language
resources, advancing NLP research and fostering inclusivity.

</details>


### [38] [Targeted Lexical Injection: Unlocking Latent Cross-Lingual Alignment in Lugha-Llama via Early-Layer LoRA Fine-Tuning](https://arxiv.org/abs/2506.15415)
*Stanley Ngugi*

Main category: cs.CL

TL;DR: 本文提出‘目标词汇注入’（TLI）微调方法，通过锁定内部早期层、使用LoRA和对比学习，有效增强低资源语言跨语种词对齐能力，实验证明稳健提升，泛化性良好。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）在低资源语言（如斯瓦希里语）上的表现通常较差，主要原因是训练数据稀缺和预训练阶段代表性不足。其中，实现稳健的跨语言词汇对齐是诸如翻译与跨语言信息检索等任务的关键挑战。

Method: 本文提出了一种新颖且高效的微调方法——目标词汇注入（TLI），利用低秩适应（LoRA）和对比学习目标，对模型的早期内部层（经验表明该层词汇对齐能力最强）进行有针对性的微调。具体做法为，在斯瓦希里语-英语词对任务中，选定表现优异的早期层（第2层），对其嵌入进行补强。

Result: 实验显示，TLI大幅提升了模型输出层对齐能力，623组训练词对余弦相似度由0.3211提升至0.4113（+28.08%），在63组未见过的对照词对中也有相似提升，显示微调能有效泛化。

Conclusion: TLI方法能够高效利用大语言模型内部的早期跨语言特性，实现低资源语言词汇对齐的显著提升，是参数高效且有效的技术路径。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities, yet
their performance in low-resource languages (LRLs), such as Swahili, often lags
due to data scarcity and underrepresentation in pre-training. A key challenge
is achieving robust cross-lingual lexical alignment, crucial for tasks like
translation and cross-lingual information retrieval. This paper introduces
Targeted Lexical Injection (TLI), a novel and efficient fine-tuning approach.
We first demonstrate that Lugha-Llama-8B-wura, a Swahili-centric LLM, exhibits
strong, near-perfect lexical alignment for Swahili-English word pairs in its
early internal layers (specifically Layer 2, with ~0.99998 average cosine
similarity based on a pilot study), a capability not fully reflected in its
final output representations (baseline ~0.32 similarity on our evaluation set).
TLI leverages this insight by using Low-Rank Adaptation (LoRA) and a
contrastive learning objective to fine-tune the model, specifically targeting
embeddings from this empirically identified optimal early layer. Our
experiments show that TLI significantly improves the output-level lexical
alignment for 623 trained Swahili-English word pairs, increasing average cosine
similarity from 0.3211 to 0.4113 (+28.08%, p < 1.33 x 10^-240). More
importantly, these improvements generalize remarkably well to 63 unseen control
word pairs, with similarity increasing from 0.3143 to 0.4033 (+28.32%, p < 7.17
x 10^-27). These findings suggest TLI enhances the model's ability to preserve
and propagate its inherent early-layer cross-lingual knowledge, offering a
parameter-efficient and effective strategy for improving lexical alignment in
LRL-focused LLMs.

</details>


### [39] [Understanding GUI Agent Localization Biases through Logit Sharpness](https://arxiv.org/abs/2506.15425)
*Xingjian Tao,Yiwei Wang,Yujun Cai,Zhicheng Yang,Jing Tang*

Main category: cs.CL

TL;DR: 提出评估和提升GUI智能体可靠性的框架，包含新指标和输入优化方法，有效改进多模态大模型在GUI任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型用于GUI自动化任务时，常发生定位谬误（幻觉），且传统指标无法揭示其复杂失效模式，需要更准确/解释性更强的评估方法。

Method: 1. 将模型预测细分为四种类型，揭示更细致的失败模式；2. 引入PSS指标，用于衡量语义连续性和坐标预测logits分布的一致性；3. 提出训练无关的Context-Aware Cropping方法，自适应优化输入上下文。

Result: 实验表明所提出的框架和方法能够提升模型解释性，并增强GUI代理的表现及可靠性。

Conclusion: 提出了一种细粒度评估框架和新的评估指标（Peak Sharpness Score, PSS），并采用Context-Aware Cropping技术，有效提升了多模态大模型驱动的GUI智能体的可解释性和鲁棒性。

Abstract: Multimodal large language models (MLLMs) have enabled GUI agents to interact
with operating systems by grounding language into spatial actions. Despite
their promising performance, these models frequently exhibit
hallucinations-systematic localization errors that compromise reliability. We
propose a fine-grained evaluation framework that categorizes model predictions
into four distinct types, revealing nuanced failure modes beyond traditional
accuracy metrics. To better quantify model uncertainty, we introduce the Peak
Sharpness Score (PSS), a metric that evaluates the alignment between semantic
continuity and logits distribution in coordinate prediction. Building on this
insight, we further propose Context-Aware Cropping, a training-free technique
that improves model performance by adaptively refining input context. Extensive
experiments demonstrate that our framework and methods provide actionable
insights and enhance the interpretability and robustness of GUI agent behavior.

</details>


### [40] [AgentGroupChat-V2: Divide-and-Conquer Is What LLM-Based Multi-Agent System Need](https://arxiv.org/abs/2506.15451)
*Zhouhong Gu,Xiaoxuan Zhu,Yin Cai,Hao Shen,Xingzhou Chen,Qingyi Wang,Jialin Li,Xiaoran Shi,Haoran Guo,Wenxuan Huang,Hongwei Feng,Yanghua Xiao,Zheyu Ye,Yao Hu,Shaosheng Cao*

Main category: cs.CL

TL;DR: AgentGroupChat-V2通过并行架构、自适应协作和创新的组织策略，大幅提升多智能体系统在复杂任务中的性能，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型多智能体系统在社会模拟和复杂任务解决方面展现出潜力，但面临架构设计、跨领域泛化性和性能保证等关键挑战，特别是在任务复杂度和智能体数量上升时更为突出。

Method: 提出AgentGroupChat-V2框架，包括三项核心创新：（1）分而治之的全并行架构，将用户查询分解为层级任务森林，实现依赖和并发处理；（2）自适应协作引擎，根据任务特性动态选择异构LLM组合和交互模式；（3）结合分而治之的问题分解的智能体组织优化策略。

Result: 大量实验显示，AgentGroupChat-V2在多个领域优于现有方法：GSM8K准确率91.50%（高5.6个百分点），AIME准确率30.4%（几乎翻倍），HumanEval pass@1为79.20%。在高难度任务上优势更加明显，比如Level 5 MATH提升超过11个百分点。

Conclusion: AgentGroupChat-V2为高效、通用的大模型多智能体系统构建提供了解决方案，尤其在复杂推理场景下具有明显优势。

Abstract: Large language model based multi-agent systems have demonstrated significant
potential in social simulation and complex task resolution domains. However,
current frameworks face critical challenges in system architecture design,
cross-domain generalizability, and performance guarantees, particularly as task
complexity and number of agents increases. We introduces AgentGroupChat-V2, a
novel framework addressing these challenges through three core innovations: (1)
a divide-and-conquer fully parallel architecture that decomposes user queries
into hierarchical task forest structures enabling dependency management and
distributed concurrent processing. (2) an adaptive collaboration engine that
dynamically selects heterogeneous LLM combinations and interaction modes based
on task characteristics. (3) agent organization optimization strategies
combining divide-and-conquer approaches for efficient problem decomposition.
Extensive experiments demonstrate AgentGroupChat-V2's superior performance
across diverse domains, achieving 91.50% accuracy on GSM8K (exceeding the best
baseline by 5.6 percentage points), 30.4% accuracy on competition-level AIME
(nearly doubling other methods), and 79.20% pass@1 on HumanEval. Performance
advantages become increasingly pronounced with higher task difficulty,
particularly on Level 5 MATH problems where improvements exceed 11 percentage
points compared to state-of-the-art baselines. These results confirm that
AgentGroupChat-V2 provides a comprehensive solution for building efficient,
general-purpose LLM multi-agent systems with significant advantages in complex
reasoning scenarios. Code is available at
https://github.com/MikeGu721/AgentGroupChat-V2.

</details>


### [41] [RE-IMAGINE: Symbolic Benchmark Synthesis for Reasoning Evaluation](https://arxiv.org/abs/2506.15455)
*Xinnuo Xu,Rachel Lawrence,Kshitij Dubey,Atharva Pandey,Risa Ueno,Fabian Falck,Aditya V. Nori,Rahul Sharma,Amit Sharma,Javier Gonzalez*

Main category: cs.CL

TL;DR: 本文提出了RE-IMAGINE框架，通过生成记忆难以处理的问题，检验LLMs的真实推理能力，发现模型在新变体问题上的表现下降，说明它们在标准推理测试上相当依赖记忆而非真正推理。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLMs）在推理基准测试上表现出高准确率，但尚不清楚这些表现是否真的由推理能力驱动，还是仅仅依赖于数据记忆。该论文希望揭示LLMs推理能力的真实来源。

Method: 作者提出了RE-IMAGINE框架，通过引入因果推理的三级阶梯（关联、干预、反事实）来刻画LLMs推理能力的层级，并利用中间符号表述生成多样化的、单靠记忆无法解决的新问题。框架适用于多种推理领域，并构建了自动化pipeline生成各层级问题变体。

Result: 在四个广泛使用的推理基准上评估不同家族的LLMs，测试表明模型在变体问题上的表现有所下降，说明模型有一定程度依赖统计回忆，而非真正的推理能力。

Conclusion: LLMs在推理测试中的高分很大程度上依赖于统计回忆。RE-IMAGINE框架揭示了这一点，为进一步研究各推理层级的能力敞开了大门。

Abstract: Recent Large Language Models (LLMs) have reported high accuracy on reasoning
benchmarks. However, it is still unclear whether the observed results arise
from true reasoning or from statistical recall of the training set. Inspired by
the ladder of causation (Pearl, 2009) and its three levels (associations,
interventions and counterfactuals), this paper introduces RE-IMAGINE, a
framework to characterize a hierarchy of reasoning ability in LLMs, alongside
an automated pipeline to generate problem variations at different levels of the
hierarchy. By altering problems in an intermediate symbolic representation,
RE-IMAGINE generates arbitrarily many problems that are not solvable using
memorization alone. Moreover, the framework is general and can work across
reasoning domains, including math, code, and logic. We demonstrate our
framework on four widely-used benchmarks to evaluate several families of LLMs,
and observe reductions in performance when the models are queried with problem
variations. These assessments indicate a degree of reliance on statistical
recall for past performance, and open the door to further research targeting
skills across the reasoning hierarchy.

</details>


### [42] [Context-Informed Grounding Supervision](https://arxiv.org/abs/2506.15480)
*Hyunji Lee,Seunghyun Yoon,Yunjae Won,Hanseok Oh,Geewook Kim,Trung Bui,Franck Dernoncourt,Elias Stengel-Eskin,Mohit Bansal,Minjoon Seo*

Main category: cs.CL

TL;DR: 文中提出了CINGS，一种通过训练时采用只对答案部分loss的方式，增强大模型在文本和视觉-语言任务中对外部知识的依赖，有效减少幻觉并维持其它任务表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在需要外部知识补充或者减少幻觉（hallucination）时，通常会附加外部上下文信息，但仅在推理阶段简单拼接上下文未必能保证回答内容真正依赖于这些上下文。

Method: 提出了一种新的后训练机制Context-INformed Grounding Supervision（CINGS）：在训练时将相关上下文加到回答前面，但只对回答部分计算损失，将上下文部分mask掉，强化模型利用外部上下文进行信息生成。

Result: （1）文本领域：CINGS在11个信息检索类数据集上超越其他训练方法，并能与推理阶段的grounding技术互补使用；（2）视觉-语言领域：用CINGS训练的语言模型替代视觉-语言模型的LLM骨干，有效减少幻觉并保持答案的事实一致性；（3）整体性能没有下降。同时，CINGS导致模型依赖外部信息的行为变化。

Conclusion: CINGS能有效提升大模型的grounding能力，无论是在文本还是视觉-语言任务中均表现出色，并可减少幻觉而不损害其它下游任务表现。对模型行为分析还揭示了CINGS改变了模型的知识利用方式，更加依赖外部上下文。

Abstract: Large language models (LLMs) are often supplemented with external knowledge
to provide information not encoded in their parameters or to reduce
hallucination. In such cases, we expect the model to generate responses by
grounding its response in the provided external context. However, prior work
has shown that simply appending context at inference time does not ensure
grounded generation. To address this, we propose Context-INformed Grounding
Supervision (CINGS), a post-training supervision in which the model is trained
with relevant context prepended to the response, while computing the loss only
over the response tokens and masking out the context. Our experiments
demonstrate that models trained with CINGS exhibit stronger grounding in both
textual and visual domains compared to standard instruction-tuned models. In
the text domain, CINGS outperforms other training methods across 11
information-seeking datasets and is complementary to inference-time grounding
techniques. In the vision-language domain, replacing a vision-language model's
LLM backbone with a CINGS-trained model reduces hallucinations across four
benchmarks and maintains factual consistency throughout the generated response.
This improved grounding comes without degradation in general downstream
performance. Finally, we analyze the mechanism underlying the enhanced
grounding in CINGS and find that it induces a shift in the model's prior
knowledge and behavior, implicitly encouraging greater reliance on the external
context.

</details>


### [43] [SPARE: Single-Pass Annotation with Reference-Guided Evaluation for Automatic Process Supervision and Reward Modelling](https://arxiv.org/abs/2506.15498)
*Md Imbesat Hassan Rizvi,Xiaodan Zhu,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本文提出了SPARE方法，实现高效、高质量的自动化多步推理过程标注，显著提升了LLM推理能力，同时标注效率大幅高于传统树搜索方法。


<details>
  <summary>Details</summary>
Motivation: 复杂多步推理需要过程监督，但高质量、自动化过程标注效率不高。本工作旨在提升自动标注的效率与质量，促进LLM推理能力增强。

Method: 提出了SPARE（Single-Pass Annotation with Reference-Guided Evaluation）结构化框架，将参考解步骤与每一步解答对齐，同时结合显式推理进行评价，实现单次、逐步自动标注。对多领域四个数据集进行实验，将SPARE用于模型微调与训练奖励模型，并与其他基线方法比较。

Result: SPARE在跨领域四个数据集上提升了模型推理表现。与树搜索法相比，效率提升2.6倍，仅需38%运行时间，并取得了有竞争力的性能。

Conclusion: SPARE方法能够高效地进行高质量的自动化过程标注，相比树搜索类自动标注具有效率提升，并在提升LLM多步推理能力方面表现优异。

Abstract: Process or step-wise supervision has played a crucial role in advancing
complex multi-step reasoning capabilities of Large Language Models (LLMs).
However, efficient, high-quality automated process annotation remains a
significant challenge. To address this, we introduce Single-Pass Annotation
with Reference-Guided Evaluation (SPARE), a novel structured framework that
enables single-pass, per-step annotation by aligning each solution step to one
or multiple steps in a reference solution, accompanied by explicit reasoning
for evaluation. We show that reference-guided step-level evaluation effectively
facilitates process supervision on four datasets spanning three domains:
mathematical reasoning, multi-hop compositional question answering, and spatial
reasoning. We demonstrate that SPARE, when compared to baselines, improves
reasoning performance when used for: (1) fine-tuning models in an offline RL
setup for inference-time greedy-decoding, and (2) training reward models for
ranking/aggregating multiple LLM-generated outputs. Additionally, SPARE
achieves competitive performance on challenging mathematical datasets while
offering 2.6 times greater efficiency, requiring only 38% of the runtime,
compared to tree search-based automatic annotation. The codebase, along with a
trained SPARE-PRM model, is publicly released to facilitate further research
and reproducibility.

</details>


### [44] [Enhancing Hyperbole and Metaphor Detection with Their Bidirectional Dynamic Interaction and Emotion Knowledge](https://arxiv.org/abs/2506.15504)
*Li Zheng,Sihang Wang,Hao Fei,Zuquan Peng,Fei Li,Jianming Fu,Chong Teng,Donghong Ji*

Main category: cs.CL

TL;DR: 该文提出结合情感分析的EmoBi模型，有效提升了夸张与隐喻检测效果，在多个数据集上大幅超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 夸张和隐喻的自动检测对自然语言处理任务至关重要，但由于其语义隐晦和表达多样，检测难度大。目前方法大多只关注表层文本特征，忽略了夸张和隐喻之间的联系以及情感对辨识修辞手法的影响。

Method: 本文提出了基于双向动态交互的情感引导式夸张与隐喻检测框架（EmoBi）。首先利用情感分析模块深入挖掘修辞背后的情感内涵；然后通过基于情感的领域映射获得夸张和隐喻的更深层隐含意义；最后，双向动态交互模块促进夸张与隐喻检测的相互提升，同时设计了验证机制以确保检测准确性和可靠性。

Result: 在四个数据集上，EmoBi均优于所有基线方法。其中，在TroFi数据集上的夸张检测F1分数比当前最优提升28.1%，在HYPO-L数据集上的隐喻检测F1提升23.1%。

Conclusion: 引入情感和交互机制能够显著提升夸张和隐喻检测效果，EmoBi方法证明了情感和修辞手法之间的复杂关系对于高性能检测系统的重要性。

Abstract: Text-based hyperbole and metaphor detection are of great significance for
natural language processing (NLP) tasks. However, due to their semantic
obscurity and expressive diversity, it is rather challenging to identify them.
Existing methods mostly focus on superficial text features, ignoring the
associations of hyperbole and metaphor as well as the effect of implicit
emotion on perceiving these rhetorical devices. To implement these hypotheses,
we propose an emotion-guided hyperbole and metaphor detection framework based
on bidirectional dynamic interaction (EmoBi). Firstly, the emotion analysis
module deeply mines the emotion connotations behind hyperbole and metaphor.
Next, the emotion-based domain mapping module identifies the target and source
domains to gain a deeper understanding of the implicit meanings of hyperbole
and metaphor. Finally, the bidirectional dynamic interaction module enables the
mutual promotion between hyperbole and metaphor. Meanwhile, a verification
mechanism is designed to ensure detection accuracy and reliability. Experiments
show that EmoBi outperforms all baseline methods on four datasets.
Specifically, compared to the current SoTA, the F1 score increased by 28.1% for
hyperbole detection on the TroFi dataset and 23.1% for metaphor detection on
the HYPO-L dataset. These results, underpinned by in-depth analyses, underscore
the effectiveness and potential of our approach for advancing hyperbole and
metaphor detection.

</details>


### [45] [Lessons from Training Grounded LLMs with Verifiable Rewards](https://arxiv.org/abs/2506.15522)
*Shang Hong Sim,Tej Deep Pala,Vernon Toh,Hai Leong Chieu,Amir Zadeh,Chuan Li,Navonil Majumder,Soujanya Poria*

Main category: cs.CL

TL;DR: 此论文提出用强化学习与推理能力提升LLM生成答案的事实溯源，采用GRPO算法和两阶段训练，显著优于传统指令微调。结合GPT-4蒸馏进一步加强长文本问答能力，为训练更可靠和可验证的LLM提供了新路径。


<details>
  <summary>Details</summary>
Motivation: 虽然检索增强生成（RAG）结合了引用式溯源，有望改进大语言模型（LLM）的可靠性，但指令微调后的模型在现实应用中经常出现关键失误，如未能给出答案、引用出错、或者在有证据情况下拒答。亟需更有效的方法提升LLM生成答案的可证实性与可信度。

Method: 提出利用强化学习（RL）和内部推理提升LLM的事实溯源能力，采用GRPO（Group Relative Policy Optimization）算法，以针对答案正确性、引用充分性和拒答质量的可验证结果作为奖励信号，无需金标准推理轨迹或昂贵人工标注。并设计两阶段训练流程：先强化答案与引用行为，再针对拒答行为进行优化。同时结合GPT-4蒸馏式指令微调来提升长文本生成问答性能。

Result: 通过对ASQA、QAMPARI、ELI5、ExpertQA四个数据集的大量实验，验证了推理增强的模型相比单纯指令微调模型在不可答问题处理和高质量引用生成方面有显著提升。两阶段训练策略进一步稳定优化信号，提升事实溯源能力。结合GPT-4蒸馏与GRPO，能在长文本生成任务上取得更好表现。

Conclusion: 通过引入推理能力、分阶段优化和以结果为导向的强化学习方法，能显著提高LLM的问题答案准确性、溯源能力和整体可靠性。

Abstract: Generating grounded and trustworthy responses remains a key challenge for
large language models (LLMs). While retrieval-augmented generation (RAG) with
citation-based grounding holds promise, instruction-tuned models frequently
fail even in straightforward scenarios: missing explicitly stated answers,
citing incorrectly, or refusing when evidence is available. In this work, we
explore how reinforcement learning (RL) and internal reasoning can enhance
grounding in LLMs. We use the GRPO (Group Relative Policy Optimization) method
to train models using verifiable outcome-based rewards targeting answer
correctness, citation sufficiency, and refusal quality, without requiring gold
reasoning traces or expensive annotations. Through comprehensive experiments
across ASQA, QAMPARI, ELI5, and ExpertQA we show that reasoning-augmented
models significantly outperform instruction-only variants, especially in
handling unanswerable queries and generating well-cited responses. A two-stage
training setup, first optimizing answer and citation behavior and then refusal,
further improves grounding by stabilizing the learning signal. Additionally, we
revisit instruction tuning via GPT-4 distillation and find that combining it
with GRPO enhances performance on long-form, generative QA tasks. Overall, our
findings highlight the value of reasoning, stage-wise optimization, and
outcome-driven RL for building more verifiable and reliable LLMs.

</details>


### [46] [RATTENTION: Towards the Minimal Sliding Window Size in Local-Global Attention Models](https://arxiv.org/abs/2506.15545)
*Bailin Wang,Chang Lan,Chong Wang,Ruoming Pang*

Main category: cs.CL

TL;DR: RATTENTION结合局部和线性注意力技术，显著提升了模型效率并保持性能，即使窗口极小也能接近全注意力效果，解决了传统local attention窗口选择的效率-性能权衡难题。


<details>
  <summary>Details</summary>
Motivation: 解决local attention模型对窗口外内容完全不关注的问题，希望在缩小局部窗口时依然保持准确率，实现性能与效率的优化平衡。

Method: 提出RATTENTION，一种结合局部窗口注意力与特殊线性注意力机制（用于跨窗口信息捕获）的模型，并对其在3B和12B参数规模上进行预训练和性能测试。使用RULER基准评估长上下文能力，同时优化实现以保证训练效率。

Result: RATTENTION在窗口仅为512的情况下可与全注意力模型比肩，实验在多种设置下证实，无论性能还是效率均优于现有主流方案，尤其在长上下文表现和训练速度上表现优秀。

Conclusion: RATTENTION模型有效地提升了local-global attention模型在保持高效的同时，缩小窗口也能维持整体性能，特别是在长上下文任务上表现突出，并且训练速度不受影响。

Abstract: Local-global attention models have recently emerged as compelling
alternatives to standard Transformers, promising improvements in both training
and inference efficiency. However, the crucial choice of window size presents a
Pareto tradeoff: larger windows maintain performance akin to full attention but
offer minimal efficiency gains in short-context scenarios, while smaller
windows can lead to performance degradation. Current models, such as Gemma2 and
Mistral, adopt conservative window sizes (e.g., 4096 out of an 8192 pretraining
length) to preserve performance. This work investigates strategies to shift
this Pareto frontier, enabling local-global models to achieve efficiency gains
even in short-context regimes. Our core motivation is to address the intrinsic
limitation of local attention -- its complete disregard for tokens outside the
defined window. We explore RATTENTION, a variant of local attention integrated
with a specialized linear attention mechanism designed to capture information
from these out-of-window tokens. Pretraining experiments at the 3B and 12B
scales demonstrate that RATTENTION achieves a superior Pareto tradeoff between
performance and efficiency. As a sweet spot, RATTENTION with a window size of
just 512 consistently matches the performance of full-attention models across
diverse settings. Furthermore, the recurrent nature inherent in the linear
attention component of RATTENTION contributes to enhanced long-context
performance, as validated on the RULER benchmark. Crucially, these improvements
do not compromise training efficiency; thanks to a specialized kernel
implementation and the reduced window size, RATTENTION maintains training
speeds comparable to existing state-of-the-art approaches.

</details>


### [47] [Approximating Language Model Training Data from Weights](https://arxiv.org/abs/2506.15553)
*John X. Morris,Junjie Oscar Yin,Woojeong Kim,Vitaly Shmatikov,Alexander M. Rush*

Main category: cs.CL

TL;DR: 本文提出了一种利用模型权重近似还原训练数据的方法，并验证了在分类及微调任务上的有效性，对开放权重但闭源数据的语言模型提升透明性有重要启示。


<details>
  <summary>Details</summary>
Motivation: 尽管现代语言模型经常开源权重，但训练数据往往是封闭的，这带来了可追溯性和理解模型行为的困难。该研究旨在探索是否能仅利用已公开的模型权重去近似还原原训练数据。

Method: 作者形式化了从模型权重近似数据的问题，提出了多种基线方法和评估指标。主要方法是基于梯度的方法：通过比较原始与微调后模型权重，在大规模公开语料库中筛选出匹配度最高的数据子集。

Result: 实验表明，该方法在训练数据未知的情况下，能从公开的网络文档中恢复一小部分用于训练模型的数据子集，效果接近原始训练效果。在AG News文本分类任务上，性能从随机选择数据的65%提升到80%，接近专家基准的88%；在MSMARCO任务中，困惑度从3.3降至2.3，接近专家LLAMA模型的2.0。

Conclusion: 该研究证明了仅借助模型权重可有效还原部分原始训练数据，对模型可解释性及模型重现具有重要意义。基于梯度的搜索方法在数据恢复和模型复现上表现出良好效果。

Abstract: Modern language models often have open weights but closed training data. We
formalize the problem of data approximation from model weights and propose
several baselines and metrics. We develop a gradient-based approach that
selects the highest-matching data from a large public text corpus and show its
effectiveness at recovering useful data given only weights of the original and
finetuned models. Even when none of the true training data is known, our method
is able to locate a small subset of public Web documents can be used to train a
model to close to the original model performance given models trained for both
classification and supervised-finetuning. On the AG News classification task,
our method improves performance from 65% (using randomly selected data) to 80%,
approaching the expert benchmark of 88%. When applied to a model trained with
SFT on MSMARCO web documents, our method reduces perplexity from 3.3 to 2.3,
compared to an expert LLAMA model's perplexity of 2.0.

</details>


### [48] [PredGen: Accelerated Inference of Large Language Models through Input-Time Speculation for Real-Time Speech Interaction](https://arxiv.org/abs/2506.15556)
*Shufan Li,Aditya Grover*

Main category: cs.CL

TL;DR: 为了解决大模型语音助手响应慢的问题，本文提出PredGen预测式生成框架，可使语音输出延迟减半且几乎不增加计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在实时语音聊天应用中发挥着重要作用，但其体积庞大导致用户输入结束到音频输出开始之间存在明显延迟，影响用户体验。这个问题在硬件能力有限的消费设备上更为明显，尤其是作为单用户语音助手时。

Method: 提出了Predictive Generation（PredGen）框架，该框架在用户说话时便通过推测解码提前生成候选回复，从而在LLM输出首句后能立即进行文本转语音（TTS）处理，显著减少延迟。

Result: 在Lmsys和MT-Bench数据集上的模拟实验表明，PredGen方法在各类应用中能有效地将延迟降低约2倍，同时仅需极少的额外输入时运算成本。

Conclusion: PredGen框架有效缓解了LLM与TTS结合系统中的首句延迟问题，显著提升了语音助手等场景下的用户体验，而且成本低廉，适用于资源受限的终端设备。

Abstract: Large Language Models (LLMs) are widely used in real-time voice chat
applications, typically in combination with text-to-speech (TTS) systems to
generate audio responses. However, their large size often leads to noticeable
latency between the end of user input and the start of audio output, resulting
in suboptimal user experiences. This latency is particularly evident when LLMs
are deployed as single-user voice assistants on consumer-grade hardware with
limited computing capacity. We discovered that this latency is primarily
dominated by the time it takes for the LLMs to generate the first sentence,
which is required as input by the TTS systems that synthesize audio responses
on a sentence-by-sentence basis. To address this bottleneck, we propose
Predictive Generation (PredGen), a novel framework that mitigates-or even
eliminates-this delay through speculative decoding at input time. PredGen
generates candidate responses while the user is still speaking, enabling the
system to begin TTS processing with minimal delay. Simulated experiments on the
Lmsys and MT-Bench datasets show that the proposed method can effectively
reduce the latency by around 2x across a wide range of use cases, while
incurring only minimal additional computation cost at input time-computation
that would otherwise go unused.

</details>


### [49] [Gender Inclusivity Fairness Index (GIFI): A Multilevel Framework for Evaluating Gender Diversity in Large Language Models](https://arxiv.org/abs/2506.15568)
*Zhengyang Shan,Emily Ruth Diana,Jiawei Zhou*

Main category: cs.CL

TL;DR: 提出GIFI指标，全面评测22种大语言模型的性别包容性，发现模型在处理非二元性别方面存在显著差异与偏见，为性别公平研究和模型改进提供关键参考。


<details>
  <summary>Details</summary>
Motivation: 过往对大语言模型（LLMs）的性别公平性研究主要集中在二元性别（男/女）区分，忽略了非二元性别用户的包容性，因此有必要提出更全面的性别公平指标来促进模型的性别包容性。

Method: 提出并设计了一个新的性别包容公平性指标（GIFI），通过多维度评估，包括性别代词的反应、模型生成及认知行为在不同性别假设下的表现等，系统分析LLMs对多样化性别的包容程度。

Result: 对22个主流开源和专有LLM进行了大规模评测，发现各个模型在性别包容性上表现差异显著，存在对不同性别标识的偏见。

Conclusion: 本研究揭示了现有LLM在性别包容性上的不足，GIFI为后续提升生成型模型性别公平性提供了重要评价基准，有助于推动更具包容性的AI系统发展。

Abstract: We present a comprehensive evaluation of gender fairness in large language
models (LLMs), focusing on their ability to handle both binary and non-binary
genders. While previous studies primarily focus on binary gender distinctions,
we introduce the Gender Inclusivity Fairness Index (GIFI), a novel and
comprehensive metric that quantifies the diverse gender inclusivity of LLMs.
GIFI consists of a wide range of evaluations at different levels, from simply
probing the model with respect to provided gender pronouns to testing various
aspects of model generation and cognitive behaviors under different gender
assumptions, revealing biases associated with varying gender identifiers. We
conduct extensive evaluations with GIFI on 22 prominent open-source and
proprietary LLMs of varying sizes and capabilities, discovering significant
variations in LLMs' gender inclusivity. Our study highlights the importance of
improving LLMs' inclusivity, providing a critical benchmark for future
advancements in gender fairness in generative models.

</details>


### [50] [SciVer: Evaluating Foundation Models for Multimodal Scientific Claim Verification](https://arxiv.org/abs/2506.15569)
*Chengye Wang,Yifei Shen,Zexi Kuang,Arman Cohan,Yilun Zhao*

Main category: cs.CL

TL;DR: 本文介绍了多模态科学主张验证基准SciVer，通过3000例专家标注样本测试21个主流多模态基础模型，发现其性能远低于人类专家，并分析了当前模型的关键不足，为今后模型发展指明了方向。


<details>
  <summary>Details</summary>
Motivation: 目前并没有针对基础大模型在多模态科学内容中验证学术主张能力的专用基准，现有方法难以细致评估模型在科学文献中推理和理解的水平。

Method: 提出了SciVer，这是第一个专为评估基础大模型在多模态科学背景下验证主张能力而设计的基准。SciVer包含3000个人工标注的样本，涵盖1113篇科学论文，分为四类常见的推理类型，并为每个样本配有专家标注的支持性证据。评测了包括o4-mini、Gemini-2.5-Flash、Llama-3.2-Vision和Qwen2.5-VL等21种最新的多模态基础模型。

Result: 实验表明，这些多模态基础模型在SciVer基准上的表现与人类专家相比存在显著差距。

Conclusion: 提出了SciVer基准，并通过系统评测揭示了当前开源多模态模型在科学文献理解与推理任务上的局限性，为后续模型改进提供了关键参考。

Abstract: We introduce SciVer, the first benchmark specifically designed to evaluate
the ability of foundation models to verify claims within a multimodal
scientific context. SciVer consists of 3,000 expert-annotated examples over
1,113 scientific papers, covering four subsets, each representing a common
reasoning type in multimodal scientific claim verification. To enable
fine-grained evaluation, each example includes expert-annotated supporting
evidence. We assess the performance of 21 state-of-the-art multimodal
foundation models, including o4-mini, Gemini-2.5-Flash, Llama-3.2-Vision, and
Qwen2.5-VL. Our experiment reveals a substantial performance gap between these
models and human experts on SciVer. Through an in-depth analysis of
retrieval-augmented generation (RAG), and human-conducted error evaluations, we
identify critical limitations in current open-source models, offering key
insights to advance models' comprehension and reasoning in multimodal
scientific literature tasks.

</details>


### [51] [DiscoSG: Towards Discourse-Level Text Scene Graph Parsing through Iterative Graph Refinement](https://arxiv.org/abs/2506.15583)
*Shaoqing Lin,Chong Teng,Fei Li,Donghong Ji,Lizhen Qu,Zhuang Li*

Main category: cs.CL

TL;DR: 论文针对现有视觉-语言模型生成多句描述造成场景图解析困难的问题，提出了新的任务和数据集，并设计了高效的多模型协作方案，在大幅提升性能的同时降低计算和开源门槛，对相关应用具有推动意义。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型（VLMs）能够生成跨句、多句的视觉描述，但现有的文本场景图解析器主要针对单句解析，难以处理跨句指代等现象，导致下游任务效果下降。

Method: 提出了一个新的任务Discourse-level text Scene Graph parsing（DiscoSG），并构建了对应的大型标注数据集DiscoSG-DS。同时，提出DiscoSG-Refiner方法：先用小模型生成基础图，再用第二个小模型迭代地对场景图进行调整，以降低大模型推理成本。

Result: 在新数据集上，GPT-4微调后SPICE指标提升约48%，但推理和开源方面有限。DiscoSG-Refiner框架即使仅用两个Flan-T5-Base模型，也可以比最佳基线高30%，推理速度比GPT-4快86倍，并提升下游任务表现。

Conclusion: DiscoSG任务和数据集以及DiscoSG-Refiner方法在处理跨句场景图解析方面有效，能在保持较低计算成本的同时，显著提升场景图生成质量和多个下游VLM任务表现。

Abstract: Vision-Language Models (VLMs) now generate discourse-level, multi-sentence
visual descriptions, challenging text scene graph parsers originally designed
for single-sentence caption-to-graph mapping. Current approaches typically
merge sentence-level parsing outputs for discourse input, often missing
phenomena like cross-sentence coreference, resulting in fragmented graphs and
degraded downstream VLM task performance. To address this, we introduce a new
task, Discourse-level text Scene Graph parsing (DiscoSG), supported by our
dataset DiscoSG-DS, which comprises 400 expert-annotated and 8,430 synthesised
multi-sentence caption-graph pairs for images. Each caption averages 9
sentences, and each graph contains at least 3 times more triples than those in
existing datasets. While fine-tuning large PLMs (i.e., GPT-4) on DiscoSG-DS
improves SPICE by approximately 48% over the best sentence-merging baseline,
high inference cost and restrictive licensing hinder its open-source use, and
smaller fine-tuned PLMs struggle with complex graphs. We propose
DiscoSG-Refiner, which drafts a base graph using one small PLM, then employs a
second PLM to iteratively propose graph edits, reducing full-graph generation
overhead. Using two Flan-T5-Base models, DiscoSG-Refiner still improves SPICE
by approximately 30% over the best baseline while achieving 86 times faster
inference than GPT-4. It also consistently improves downstream VLM tasks like
discourse-level caption evaluation and hallucination detection. Code and data
are available at: https://github.com/ShaoqLin/DiscoSG

</details>


### [52] [WikiMixQA: A Multimodal Benchmark for Question Answering over Tables and Charts](https://arxiv.org/abs/2506.15594)
*Negar Foroutan,Angelika Romanou,Matin Ansaripour,Julian Martin Eisenschlos,Karl Aberer,Rémi Lebret*

Main category: cs.CL

TL;DR: 本文提出WikiMixQA基准集，专注于跨模态推理和长上下文文档理解，评测12个主流视觉-语言模型，发现模型在长文档检索场景下均表现不佳，仅GPT-4-o表现较好，表明该领域仍具挑战，基准集有助于推动相关研究。


<details>
  <summary>Details</summary>
Motivation: 文档常包含复杂的排版、表格和图表，这些特性对自动文档理解（DU）任务造成了挑战。近年来，视觉-语言大模型（VLLMs）在多任务中取得进步，但其在处理长文本视觉输入方面的有效性尚不明确。

Method: 本文提出了WikiMixQA基准集，包含1000道多项选择题（MCQs），用于评测模型在表格和图表上的跨模态推理能力。数据来源于4000个维基百科页面，涵盖7个主题。利用该基准集，评测了12个主流视觉-语言模型的能力，比较它们在有直接上下文和需要长文本检索两种场景下的表现。

Result: 私有模型在拥有直接上下文时能达到约70%的准确率，但在需要对长文档进行检索时，性能显著下降。只有GPT-4-o在需要检索的任务中准确率超过50%，开源模型最高仅为27%。

Conclusion: 长上下文和多模态推理仍然极具挑战性，现有模型在这一能力上表现有限。WikiMixQA为文档理解领域的研究提供了一个重要的、针对复杂跨模态推理能力的新基准。

Abstract: Documents are fundamental to preserving and disseminating information, often
incorporating complex layouts, tables, and charts that pose significant
challenges for automatic document understanding (DU). While vision-language
large models (VLLMs) have demonstrated improvements across various tasks, their
effectiveness in processing long-context vision inputs remains unclear. This
paper introduces WikiMixQA, a benchmark comprising 1,000 multiple-choice
questions (MCQs) designed to evaluate cross-modal reasoning over tables and
charts extracted from 4,000 Wikipedia pages spanning seven distinct topics.
Unlike existing benchmarks, WikiMixQA emphasizes complex reasoning by requiring
models to synthesize information from multiple modalities. We evaluate 12
state-of-the-art vision-language models, revealing that while proprietary
models achieve ~70% accuracy when provided with direct context, their
performance deteriorates significantly when retrieval from long documents is
required. Among these, GPT-4-o is the only model exceeding 50% accuracy in this
setting, whereas open-source models perform considerably worse, with a maximum
accuracy of 27%. These findings underscore the challenges of long-context,
multi-modal reasoning and establish WikiMixQA as a crucial benchmark for
advancing document understanding research.

</details>


### [53] [From Model to Classroom: Evaluating Generated MCQs for Portuguese with Narrative and Difficulty Concerns](https://arxiv.org/abs/2506.15598)
*Bernardo Leite,Henrique Lopes Cardoso,Pedro Pinto,Abel Ferreira,Luís Abreu,Isabel Rangel,Sandra Monteiro*

Main category: cs.CL

TL;DR: 本研究评估了生成式AI在葡萄牙语小学阅读理解MCQ自动生成上的表现，发现AI生成题目接近人工质量，但在干扰项和题目清晰度等环节存在改进空间。


<details>
  <summary>Details</summary>
Motivation: 手动编写多项选择题（MCQ）耗时且成本高，尤其要针对不同难度级别和阅读技能。随着生成式AI的发展，有望自动化MCQ的生成，但对生成质量和可靠性的评估、尤其是失败案例关注较少。此外，大部分研究集中于英语，其他语言如葡萄牙语尚未充分探索。

Method: 本研究利用当前生成式模型，针对葡萄牙语，生成适合小学课程、不同难度级别的阅读理解MCQ。通过专家评审和学生作答心理测量分析，评估这些AI生成MCQ的质量与适用性。

Result: 结果显示，当前生成模型可生成与人工编写质量相当的MCQ，但在语义清晰度和可答性方面存在问题，并且生成符合高质量选项标准的干扰项仍有挑战。

Conclusion: 生成式模型已经具备生成部分高质量葡萄牙语MCQ的能力，但仍需解决语义和干扰项设计相关的问题。

Abstract: While MCQs are valuable for learning and evaluation, manually creating them
with varying difficulty levels and targeted reading skills remains a
time-consuming and costly task. Recent advances in generative AI provide an
opportunity to automate MCQ generation efficiently. However, assessing the
actual quality and reliability of generated MCQs has received limited attention
-- particularly regarding cases where generation fails. This aspect becomes
particularly important when the generated MCQs are meant to be applied in
real-world settings. Additionally, most MCQ generation studies focus on
English, leaving other languages underexplored. This paper investigates the
capabilities of current generative models in producing MCQs for reading
comprehension in Portuguese, a morphologically rich language. Our study focuses
on generating MCQs that align with curriculum-relevant narrative elements and
span different difficulty levels. We evaluate these MCQs through expert review
and by analyzing the psychometric properties extracted from student responses
to assess their suitability for elementary school students. Our results show
that current models can generate MCQs of comparable quality to human-authored
ones. However, we identify issues related to semantic clarity and
answerability. Also, challenges remain in generating distractors that engage
students and meet established criteria for high-quality MCQ option design.

</details>


### [54] [The Compositional Architecture of Regret in Large Language Models](https://arxiv.org/abs/2506.15617)
*Xiangxiang Cui,Shu Yang,Tianjin Huang,Wanyu Lin,Lijie Hu,Di Wang*

Main category: cs.CL

TL;DR: 本文提出了大语言模型懊悔表达研究的系统框架，包括数据集、指标与机制分析，并揭示了模型内部的表征和信息处理规律，有助于提升模型可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在面对自身生成的错误信息被证据推翻时，其表现出的“懊悔”机制尚未被系统分析。理解这种懊悔机制对于提升模型可靠性以及揭示神经网络中的认知编码至关重要。

Method: 本文提出了三项创新方法：(1) 通过设计迷你场景化提示，构建捕捉模型懊悔表达的大型数据集；(2) 提出S-CDI指标，用于鉴别模型中的最优懊悔表达层；(3) 提出RDS指标定位懊悔神经元、GIC指标分析神经元激活模式。

Result: 实验结果利用S-CDI指标成功定位最优懊悔表达层，并且该层在探针分类任务上大幅提升性能。还发现模型层间存在“M型解耦”模式（信息处理在耦合和解耦阶段交替）。RDS指标将神经元分为三类：懊悔神经元、非懊悔神经元和二元神经元。

Conclusion: 本文为大语言模型中懊悔表达的识别与解释性分析提供了首个完整体系，实现了数据集构建、有效表征层/神经元判别和机制揭示，推动了模型可解释性和可靠性的研究。

Abstract: Regret in Large Language Models refers to their explicit regret expression
when presented with evidence contradicting their previously generated
misinformation. Studying the regret mechanism is crucial for enhancing model
reliability and helps in revealing how cognition is coded in neural networks.
To understand this mechanism, we need to first identify regret expressions in
model outputs, then analyze their internal representation. This analysis
requires examining the model's hidden states, where information processing
occurs at the neuron level. However, this faces three key challenges: (1) the
absence of specialized datasets capturing regret expressions, (2) the lack of
metrics to find the optimal regret representation layer, and (3) the lack of
metrics for identifying and analyzing regret neurons. Addressing these
limitations, we propose: (1) a workflow for constructing a comprehensive regret
dataset through strategically designed prompting scenarios, (2) the Supervised
Compression-Decoupling Index (S-CDI) metric to identify optimal regret
representation layers, and (3) the Regret Dominance Score (RDS) metric to
identify regret neurons and the Group Impact Coefficient (GIC) to analyze
activation patterns. Our experimental results successfully identified the
optimal regret representation layer using the S-CDI metric, which significantly
enhanced performance in probe classification experiments. Additionally, we
discovered an M-shaped decoupling pattern across model layers, revealing how
information processing alternates between coupling and decoupling phases.
Through the RDS metric, we categorized neurons into three distinct functional
groups: regret neurons, non-regret neurons, and dual neurons.

</details>


### [55] [Minding the Politeness Gap in Cross-cultural Communication](https://arxiv.org/abs/2506.15623)
*Yuka Machino,Matthias Hofer,Max Siegel,Joshua B. Tenenbaum,Robert D. Hawkins*

Main category: cs.CL

TL;DR: 英国与美式英语使用者对强化词的理解差异，既涉及词语本身的字面意义，也与对表达成本的考量不同，说明跨文化理解需要兼顾语义和语用两方面的复杂作用。


<details>
  <summary>Details</summary>
Motivation: 跨文化交际常因细微的解释差异引起误解，但这种差异究竟源于词语的字面含义，还是源于更一般的语用因素（如礼貌和简洁规范），尚不明确。

Method: 通过三个实验，考察英国英语和美式英语使用者对诸如“quite”和“very”等强化词的理解差异，并构建了一个递归推理的计算认知模型，考虑信息量、礼貌和表达成本的权衡。

Result: 模型比较结果显示，强化词解释上的跨文化差异既源于字面含义的不同，也源于对表达成本权重的不同。

Conclusion: 仅依靠语义变异或礼貌规范解释跨文化理解差异是不充分的，这些差异是两者间复杂相互作用的结果。

Abstract: Misunderstandings in cross-cultural communication often arise from subtle
differences in interpretation, but it is unclear whether these differences
arise from the literal meanings assigned to words or from more general
pragmatic factors such as norms around politeness and brevity. In this paper,
we report three experiments examining how speakers of British and American
English interpret intensifiers like "quite" and "very." To better understand
these cross-cultural differences, we developed a computational cognitive model
where listeners recursively reason about speakers who balance informativity,
politeness, and utterance cost. Our model comparisons suggested that
cross-cultural differences in intensifier interpretation stem from a
combination of (1) different literal meanings, (2) different weights on
utterance cost. These findings challenge accounts based purely on semantic
variation or politeness norms, demonstrating that cross-cultural differences in
interpretation emerge from an intricate interplay between the two.

</details>


### [56] [Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability](https://arxiv.org/abs/2506.15629)
*Yusuke Sakai,Hidetaka Kamigaito,Taro Watanabe*

Main category: cs.CL

TL;DR: 本文提出Ordered CommonGen基准，系统评估LLM在按顺序组合概念且遵循指令方面的能力，并发现当前模型在多样性和指令遵循上均有待提升。


<details>
  <summary>Details</summary>
Motivation: 生成式大语言模型（LLMs）在常识推理任务中，虽然能够涵盖所有给定概念，但在需要按照指定顺序生成内容时表现不足。因此，迫切需要一种方法来评估LLM在遵循指令和组合泛化方面的能力。

Method: 作者提出了Ordered CommonGen基准，用于评估LLM是否能按照指定顺序组合生成句子，并用该基准对36种LLM进行了系统分析，重点衡量了Ordered Coverage指标。

Result: 分析结果表明，尽管大多数LLM能够理解指令意图，但普遍存在对特定概念顺序的偏好，导致生成结果多样性不足或对不同顺序指令产生相同输出。最优秀的LLM在Ordered Coverage上也仅达到大约75%。

Conclusion: 无论是在指令遵循还是组合泛化能力上，当前LLM都存在明显不足，未来需要进一步改进。

Abstract: In generative commonsense reasoning tasks such as CommonGen, generative large
language models (LLMs) compose sentences that include all given concepts.
However, when focusing on instruction-following capabilities, if a prompt
specifies a concept order, LLMs must generate sentences that adhere to the
specified order. To address this, we propose Ordered CommonGen, a benchmark
designed to evaluate the compositional generalization and instruction-following
abilities of LLMs. This benchmark measures ordered coverage to assess whether
concepts are generated in the specified order, enabling a simultaneous
evaluation of both abilities. We conducted a comprehensive analysis using 36
LLMs and found that, while LLMs generally understand the intent of
instructions, biases toward specific concept order patterns often lead to
low-diversity outputs or identical results even when the concept order is
altered. Moreover, even the most instruction-compliant LLM achieved only about
75% ordered coverage, highlighting the need for improvements in both
instruction-following and compositional generalization capabilities.

</details>


### [57] [Oldies but Goldies: The Potential of Character N-grams for Romanian Texts](https://arxiv.org/abs/2506.15650)
*Dana Lupsa,Sanda-Maria Avram*

Main category: cs.CL

TL;DR: 本研究比较六种机器学习方法归属于罗马尼亚语文本作者，发现基于字符n-gram的ANN模型效果最优，结果支持简单模型和特征在低资源语言归属任务中的可行性和有效性。


<details>
  <summary>Details</summary>
Motivation: 罗马尼亚语文本作者归属问题在资源受限的语言环境中亟需有效解法，现有方法大多针对主流语种，缺少对罗马尼亚语的系统研究。

Method: 基于ROST数据集，系统比较SVM、逻辑回归、k近邻、决策树、随机森林和人工神经网络等6种机器学习方法，通过字符n-gram特征进行作者归属分类。

Result: 在六种方法中，5-gram特征下的人工神经网络（ANN）表现最佳，15次实验中有4次实现了完美分类。整体显示 ANN 明显优于其它方法。

Conclusion: 简单、可解释的字符n-gram特征结合轻量级模型，在罗马尼亚语文本作者归属任务上可达到与复杂模型媲美的准确率。该方法对资源有限或研究不足的语言同样具有很大应用潜力。

Abstract: This study addresses the problem of authorship attribution for Romanian texts
using the ROST corpus, a standard benchmark in the field. We systematically
evaluate six machine learning techniques: Support Vector Machine (SVM),
Logistic Regression (LR), k-Nearest Neighbors (k-NN), Decision Trees (DT),
Random Forests (RF), and Artificial Neural Networks (ANN), employing character
n-gram features for classification. Among these, the ANN model achieved the
highest performance, including perfect classification in four out of fifteen
runs when using 5-gram features. These results demonstrate that lightweight,
interpretable character n-gram approaches can deliver state-of-the-art accuracy
for Romanian authorship attribution, rivaling more complex methods. Our
findings highlight the potential of simple stylometric features in resource,
constrained or under-studied language settings.

</details>


### [58] [CC-LEARN: Cohort-based Consistency Learning](https://arxiv.org/abs/2506.15662)
*Xiao Ye,Shaswat Shrivastava,Zhaonan Li,Jacob Dineen,Shijie Lu,Avneet Ahuja,Ming Shen,Zhikun Xu,Ben Zhou*

Main category: cs.CL

TL;DR: 作者提出了一种基于队列一致性学习的强化学习方法，能够显著提升LLM在推理任务中的一致性和准确率。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型（LLM）在许多任务中表现优异，但在推理的一致性和鲁棒性方面仍有不足。该研究旨在提高LLM在推理任务中的可靠性。

Method: 提出了一种队列一致性学习（Cohort-based Consistency Learning, CC-Learn）强化学习框架，通过从共享程序抽象中派生出的类似问题队列来训练模型，并结合队列准确率、有效问题分解的检索奖励以及对无效检索的惩罚，以引导模型在队列内采用一致的推理模式。

Result: 在如ARC-Challenge和StrategyQA等具有挑战性的推理基准测试上，CC-Learn显著提升了模型的推理准确率及一致性，相较于预训练模型和有监督微调（SFT）基线有更好的表现。

Conclusion: 队列级强化学习能有效提升大型语言模型的推理一致性和稳定性。

Abstract: Large language models excel at many tasks but still struggle with consistent,
robust reasoning. We introduce Cohort-based Consistency Learning (CC-Learn), a
reinforcement learning framework that improves the reliability of LLM reasoning
by training on cohorts of similar questions derived from shared programmatic
abstractions. To enforce cohort-level consistency, we define a composite
objective combining cohort accuracy, a retrieval bonus for effective problem
decomposition, and a rejection penalty for trivial or invalid lookups that
reinforcement learning can directly optimize, unlike supervised fine-tuning.
Optimizing this reward guides the model to adopt uniform reasoning patterns
across all cohort members. Experiments on challenging reasoning benchmarks
(including ARC-Challenge and StrategyQA) show that CC-Learn boosts both
accuracy and reasoning stability over pretrained and SFT baselines. These
results demonstrate that cohort-level RL effectively enhances reasoning
consistency in LLMs.

</details>


### [59] [Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers](https://arxiv.org/abs/2506.15674)
*Tommaso Green,Martin Gubri,Haritz Puerto,Sangdoo Yun,Seong Joon Oh*

Main category: cs.CL

TL;DR: 该文揭示大模型推理轨迹易泄露用户隐私，推理增强虽能提升答案安全却导致内部思考泄露加剧，呼吁关注内部推理隐私问题。


<details>
  <summary>Details</summary>
Motivation: 现有关于大模型推理过程中隐私泄露的关注主要集中在最终输出，而推理轨迹常被视为安全并被忽视。作者希望验证推理轨迹是否也会泄露用户敏感数据。

Method: 采用探测（probing）与智能体评测（agentic evaluations），以及增加推理步数等算力预算的测试来评估大模型推理轨迹中的隐私泄露情况。

Result: 推理轨迹中经常包含敏感用户数据，可被prompt injection等方式获取，推理步数增加反而加剧泄露，同时尽管模型输出更谨慎，但内部思考过程泄露更多。

Conclusion: 推理能力提升增强模型效用的同时也增大了隐私攻击面，安全工作需覆盖模型内部思考过程而不仅是最终输出。

Abstract: We study privacy leakage in the reasoning traces of large reasoning models
used as personal agents. Unlike final outputs, reasoning traces are often
assumed to be internal and safe. We challenge this assumption by showing that
reasoning traces frequently contain sensitive user data, which can be extracted
via prompt injections or accidentally leak into outputs. Through probing and
agentic evaluations, we demonstrate that test-time compute approaches,
particularly increased reasoning steps, amplify such leakage. While increasing
the budget of those test-time compute approaches makes models more cautious in
their final answers, it also leads them to reason more verbosely and leak more
in their own thinking. This reveals a core tension: reasoning improves utility
but enlarges the privacy attack surface. We argue that safety efforts must
extend to the model's internal thinking, not just its outputs.

</details>


### [60] [Gender-Neutral Machine Translation Strategies in Practice](https://arxiv.org/abs/2506.15676)
*Hillary Dawkins,Isar Nejadgholi,Chi-kiu Lo*

Main category: cs.CL

TL;DR: 多数机器翻译系统无法很好地应对性别歧义，仅少数系统可根据目标语言采用性别中立策略，整体性别中立翻译仍待提升。


<details>
  <summary>Details</summary>
Motivation: 在机器翻译过程中，尤其是从如英语这样的无标记性别语言翻译到有语法性别区分的语言时，保持性别歧义（即性别中性）很有挑战性。该研究关注于如何避免性别误译和代表性伤害的问题。

Method: 本研究评估了21个机器翻译系统在面对性别歧义时，保持性别中立的灵敏度，并分析了三种难度不同的翻译方向。研究对实际使用的性别中立翻译策略进行了分类与讨论，并进一步考察了二元性别刻板印象对性别中立翻译使用的影响。

Result: 大多数机器翻译系统在面对性别歧义时未能产出性别中立的译文，只有极少数系统会根据目标语言使用特定策略切换到性别中立翻译。

Conclusion: 当前主流机器翻译系统在处理性别中立需求时表现不佳，但某些系统显示了采用性别中立翻译策略的潜力，表明这一方向有改进空间。

Abstract: Gender-inclusive machine translation (MT) should preserve gender ambiguity in
the source to avoid misgendering and representational harms. While gender
ambiguity often occurs naturally in notional gender languages such as English,
maintaining that gender neutrality in grammatical gender languages is a
challenge. Here we assess the sensitivity of 21 MT systems to the need for
gender neutrality in response to gender ambiguity in three translation
directions of varying difficulty. The specific gender-neutral strategies that
are observed in practice are categorized and discussed. Additionally, we
examine the effect of binary gender stereotypes on the use of gender-neutral
translation. In general, we report a disappointing absence of gender-neutral
translations in response to gender ambiguity. However, we observe a small
handful of MT systems that switch to gender neutral translation using specific
strategies, depending on the target language.

</details>


### [61] [GenRecal: Generation after Recalibration from Large to Small Vision-Language Models](https://arxiv.org/abs/2506.15681)
*Byung-Kwan Lee,Ryo Hachiuma,Yong Man Ro,Yu-Chiang Frank Wang,Yueh-Hua Wu*

Main category: cs.CL

TL;DR: GenRecal是一种通用的VLM知识蒸馏框架，不受模型类型限制，显著提升了小模型在多项任务上的表现，有望推动VLM在实际场景尤其是边缘设备上的部署。


<details>
  <summary>Details</summary>
Motivation: 现有VLM虽然强大，但难以部署于资源受限设备，因此需要将大模型的知识迁移到小模型。然而不同VLM间的架构、token类型差异大，现有蒸馏方法适用性有限。

Method: 提出并实现了GenRecal蒸馏框架，通过Recalibrator模块对异构VLM的特征进行对齐，实现知识高效迁移。

Result: 在多个有挑战性的基准测试上，GenRecal蒸馏后的小型VLM性能远超蒸馏前，甚至领先于某些大型开源和闭源VLM系统。

Conclusion: GenRecal能高效且显著提升小型VLM的性能，甚至超越部分大型开源和闭源VLM。

Abstract: Recent advancements in vision-language models (VLMs) have leveraged large
language models (LLMs) to achieve performance on par with closed-source systems
like GPT-4V. However, deploying these models in real-world scenarios,
particularly on resource-constrained devices, remains challenging due to their
substantial computational demands. This has spurred interest in distilling
knowledge from large VLMs into smaller, more efficient counterparts. A key
challenge arises here from the diversity of VLM architectures, which are built
on different LLMs and employ varying token types-differing in vocabulary size,
token splits, and token index ordering. To address this challenge of limitation
to a specific VLM type, we present Generation after Recalibration (GenRecal), a
novel, general-purpose distillation framework for VLMs. GenRecal incorporates a
Recalibrator that aligns and adapts feature representations between
heterogeneous VLMs, enabling effective knowledge transfer across different
types of VLMs. Through extensive experiments on multiple challenging
benchmarks, we demonstrate that GenRecal significantly improves baseline
performances, eventually outperforming large-scale open- and closed-source
VLMs.

</details>


### [62] [PhantomHunter: Detecting Unseen Privately-Tuned LLM-Generated Text via Family-Aware Learning](https://arxiv.org/abs/2506.15683)
*Yuhui Shi,Yehan Yang,Qiang Sheng,Hao Mi,Beizhe Hu,Chaoxi Xu,Juan Cao*

Main category: cs.CL

TL;DR: 本文提出了PhantomHunter，一种专门检测私有微调LLM生成文本的新方法，通过家族级特征学习显著提升了识别准确率，在多个开放及商业检测方案中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）的普及，由于其被滥用而导致的信息造假、学术不端等社会问题更加严重，因此对LLM生成文本的检测变得前所未有的重要。现有检测方法在实际中受限于私有微调LLM文本的挑战，这一问题尚未被充分探讨。

Method: 作者提出了PhantomHunter，这是一种专门用于检测来自未见过的、私有微调LLM文本的检测模型。其核心是“家族感知学习”框架，能够捕捉基础模型及其衍生模型之间共享的家族级特征，而不是仅仅记忆单个模型的特征。

Result: 在涉及LLaMA、Gemma和Mistral家族的数据实验中，PhantomHunter在F1分数上超过了7个已有基线方法和3个工业服务，达到了96%以上。

Conclusion: PhantomHunter有效解决了现有检测器在私有微调LLM文本检测中的性能下降问题，具备更广泛的适应性和优越的检测性能。

Abstract: With the popularity of large language models (LLMs), undesirable societal
problems like misinformation production and academic misconduct have been more
severe, making LLM-generated text detection now of unprecedented importance.
Although existing methods have made remarkable progress, a new challenge posed
by text from privately tuned LLMs remains underexplored. Users could easily
possess private LLMs by fine-tuning an open-source one with private corpora,
resulting in a significant performance drop of existing detectors in practice.
To address this issue, we propose PhantomHunter, an LLM-generated text detector
specialized for detecting text from unseen, privately-tuned LLMs. Its
family-aware learning framework captures family-level traits shared across the
base models and their derivatives, instead of memorizing individual
characteristics. Experiments on data from LLaMA, Gemma, and Mistral families
show its superiority over 7 baselines and 3 industrial services, with F1 scores
of over 96%.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [63] [A survey of Chernoff and Hoeffding bounds](https://arxiv.org/abs/2506.15612)
*Alexandros V. Gerbessiotis*

Main category: cs.DM

TL;DR: 本文综述并系统整理了Chernoff界、Hoeffding界及其派生概率界，汇总了证明，便于研究者查阅。


<details>
  <summary>Details</summary>
Motivation: 现有概率界（如Chernoff界和Hoeffding界）被广泛应用，但分布零散、形式多样。为方便研究者查阅，提高研究效率，有必要将这些界系统汇总，并补充证明。

Method: 通过文献综述的方式，系统归纳了Chernoff界、Hoeffding界及其各种衍生概率不等式，并根据需要提供了完整的证明。

Result: 文章整理了原始概率界及相关推导，提供了翔实的分类与完整的证明，成为概率不等式领域便于检索与引用的资料库。

Conclusion: 本文整理并归纳了Chernoff与Hoeffding等开创性论文中的原始概率界，并涵盖了各类派生形式的概率不等式，为相关领域研究者提供了详细的参考文献。

Abstract: This is a survey paper that discusses the original bounds of the seminal
papers by Chernoff and Hoeffding. Moreover, it includes a variety of derivative
bounds in a variety of forms. Complete proofs are provided as needed. The
intent is to provide a repository of reference bounds for the interested
researcher.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [64] [Controller Synthesis for Parametric Timed Games](https://arxiv.org/abs/2506.15532)
*Mikael Bisgaard Dahlsen-Jensen,Baptiste Fievet,Laure Petrucci,Jaco van de Pol*

Main category: cs.FL

TL;DR: 本文提出了一种能够直接计算参数化定时游戏致胜策略的算法，并将其转化为控制自动机，理论和实验证明该方法可行且有效。


<details>
  <summary>Details</summary>
Motivation: 之前的算法只能合成能够获胜的游戏参数的约束条件，无法直接生成相应的致胜策略。作者旨在填补这一空白，对参数化定时游戏直接构建对应的致胜策略。

Method: 提出一种（半）算法，能够为参数化定时游戏直接构造致胜策略，并对致胜策略提出新定义。同时，将这些策略转化为（参数化）定时自动机，以便后续用于控制器的构建。通过在生产单元案例上的实现和实验验证了方法的可行性。

Result: 方法能够成功计算出参数化定时游戏的致胜策略，并能转化为可用于控制的定时自动机，用实际案例验证了其实用性与可行性。

Conclusion: 本文提出了一种新颖的算法方法，实现了参数化定时游戏致胜策略的自动计算，对参数化自动机的控制合成提供了技术基础，并通过实践证明了其有效性。

Abstract: We present a (semi)-algorithm to compute winning strategies for parametric
timed games. Previous algorithms only synthesized constraints on the clock
parameters for which the game is winning. A new definition of (winning)
strategies is proposed, and ways to compute them. A transformation of these
strategies to (parametric) timed automata allows for building a controller
enforcing them. The feasibility of the method is demonstrated by an
implementation and experiments for the Production Cell case study.

</details>
