<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 9]
- [cs.LO](#cs.LO) [Total: 6]
- [cs.CL](#cs.CL) [Total: 13]
- [cs.DM](#cs.DM) [Total: 1]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Tuning Random Generators: Property-Based Testing as Probabilistic Programming](https://arxiv.org/abs/2508.14394)
*Ryan Tjoa,Poorva Garg,Harrison Goldstein,Todd Millstein,Benjamin Pierce,Guy Van den Broeck*

Main category: cs.PL

TL;DR: 本文提出了利用概率编程系统自动调优PBT测试输入生成器权重的方法，能大幅提升测试分布质量和bug发现效率。


<details>
  <summary>Details</summary>
Motivation: 在属性基础测试（PBT）中，为了生成具有良好分布的测试输入，用户需微调生成器权重，但手动调整权重困难且耗时，限制了实际可达的测试输入分布。

Method: 提出了一种自动、离线调整生成器权重的技术。通过让生成器权重符号化，并结合目标函数，系统自动学习最优权重。实现并应用于一个新颖的离散概率编程系统 Loaded Dice，支持微分和参数学习，用于生成测试输入。

Result: 系统能有效优化生成器的分布以满足目标函数要求。在PBT基准测试中，自动调优后的生成器在发现bug速度上提升了3.1-7.4倍。

Conclusion: 自动化调优生成器权重的方法能使属性基础测试在分布覆盖和效率上实现显著提升，降低了手动调整难度，有助于发现更多bug。

Abstract: Property-based testing validates software against an executable specification
by evaluating it on randomly generated inputs. The standard way that PBT users
generate test inputs is via generators that describe how to sample test inputs
through random choices. To achieve a good distribution over test inputs, users
must tune their generators, i.e., decide on the weights of these individual
random choices. Unfortunately, it is very difficult to understand how to choose
individual generator weights in order to achieve a desired distribution, so
today this process is tedious and limits the distributions that can be
practically achieved.
  In this paper, we develop techniques for the automatic and offline tuning of
generators. Given a generator with undetermined symbolic weights and an
objective function, our approach automatically learns values for these weights
that optimize for the objective. We describe useful objective functions that
allow users to (1) target desired distributions and (2) improve the diversity
and validity of their test cases. We have implemented our approach in a novel
discrete probabilistic programming system, Loaded Dice, that supports
differentiation and parameter learning, and use it as a language for
generators. We empirically demonstrate that our approach is effective at
optimizing generator distributions according to the specified objective
functions. We also perform a thorough evaluation on PBT benchmarks,
demonstrating that, when automatically tuned for diversity and validity, the
generators exhibit a 3.1-7.4x speedup in bug finding.

</details>


### [2] [Close is Good Enough: Component-Based Synthesis Modulo Logical Similarity](https://arxiv.org/abs/2508.14614)
*Ashish Mishra,Suresh Jagannathan*

Main category: cs.PL

TL;DR: 论文提出一种基于逻辑相似性和类型约束的CBS算法新方法，通过Qualified Tree Automata优化搜索过程，并实现了工具\name，成功解决了更复杂的CBS问题，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: CBS算法的有效性受到查询约束的影响，面对复杂且稀疏的可行方案空间时，现有方法难以应对，因此作者提出提升CBS搜索能力的需求。

Method: 作者通过增强CBS搜索，使其能够推理探索路径间的逻辑相似性。利用具备丰富逻辑限定符的精化类型规范的库方法，采用Qualified Tree Automata变体记录枚举项的信息，通过精化类型的子类型约束，避免搜索语义近似的路径。

Result: 作者实现了这一思路的工具（称为\name），并通过全面的评估展示了其能合成远超现有技术复杂CBS查询的方案。

Conclusion: 通过利用路径间逻辑相似性及类型间的约束，有效提升了CBS的合成能力和效率，扩展了其在复杂约束下的应用范围。

Abstract: Component-based synthesis (CBS) aims to generate loop-free programs from a
set of libraries whose methods are annotated with specifications and whose
output must satisfy a set of logical constraints, expressed as a query. The
effectiveness of a CBS algorithm critically depends on the severity of the
constraints imposed by the query. The more exact these constraints are, the
sparser the space of feasible solutions. This maxim also applies when we enrich
the expressiveness of the specifications affixed to library methods. In both
cases, the search must now contend with constraints that may only hold over a
small number of the possible execution paths that can be enumerated by a CBS
procedure.
  In this paper, we address this challenge by equipping CBS search with the
ability to reason about logical similarities among the paths it explores. Our
setting considers library methods equipped with refinement-type specifications
that enrich ordinary base types with a set of rich logical qualifiers to
constrain the set of values accepted by that type. We perform a search over a
tree automata variant called Qualified Tree Automata that intelligently records
information about enumerated terms, leveraging subtyping constraints over the
refinement types associated with these terms to enable reasoning about
similarity among candidate solutions as search proceeds, thereby avoiding
exploration of semantically similar paths.
  We present an implementation of this idea in a tool called \name, and provide
a comprehensive evaluation that demonstrates \name's ability to synthesize
solutions to complex CBS queries that go well-beyond the capabilities of the
existing state-of-the-art.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [You Don't Know Until You Click:Automated GUI Testing for Production-Ready Software Evaluation](https://arxiv.org/abs/2508.14104)
*Yutong Bian,Xianhao Lin,Yupeng Xie,Tianyang Liu,Mingchen Zhuge,Siyuan Lu,Haoming Tang,Jinlin Wang,Jiayi Zhang,Jiaqi Chen,Xiangru Tang,Yongxin Ni,Sirui Hong,Chenglin Wu*

Main category: cs.SE

TL;DR: 文章提出了RealDevWorld自动化评估框架，专为评估大模型生成的生产级软件设计，结合多样任务集和自动化交互代理，可全面、细粒度地评估软件质量，其性能与人工专家高度一致，大幅提高了评估效率与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法有效评估由大模型和代码代理生成的真实生产级软件，特别是缺乏对交互行为和运行时动态的考察，仅依赖静态或二元判定方式，无法反映实际可用性。

Method: 提出了RealDevWorld评估框架，包括：1）RealDevBench，194项开放式软件工程任务，涵盖多领域并带有多模态元素；2）AppEvalPilot，基于代理的自动评判系统，通过GUI用户模拟交互自动全面评估软件的功能正确性、视觉效果、运行行为。该框架可以自动生成细粒度、任务相关的诊断反馈。

Result: 实际测试显示，该框架自动评估结果与人工专家高度一致（准确率0.92，相关性0.85），显著减少了人工审核需求。

Conclusion: RealDevWorld框架能够自动、可扩展且与人工一致地评估大模型生成的生产级应用软件，推进了软件智能生成的评测方法。

Abstract: Large Language Models (LLMs) and code agents in software development are
rapidly evolving from generating isolated code snippets to producing
full-fledged software applications with graphical interfaces, interactive
logic, and dynamic behaviors. However, current benchmarks fall short in
evaluating such production-ready software, as they often rely on static checks
or binary pass/fail scripts, failing to capture the interactive behaviors and
runtime dynamics that define real-world usability - qualities that only emerge
when an application is actively used. This is the blind spot of current
evaluation: you don't know if an app works until you click through it, interact
with it, and observe how it responds. To bridge this gap, we introduce
RealDevWorld, a novel evaluation framework for automated end-to-end assessment
of LLMs' ability to generate production-ready repositories from scratch. It
features two key components: (1) RealDevBench, a diverse collection of 194
open-ended software engineering tasks across multiple domains, incorporating
multimodal elements to reflect real-world complexity; and (2) AppEvalPilot, a
new agent-as-a-judge evaluation system that simulates realistic, GUI-based user
interactions to automatically and holistically assess software functional
correctness, visual fidelity, and runtime behavior. The framework delivers
fine-grained, task-specific diagnostic feedback, supporting nuanced evaluation
beyond simple success/failure judgments. Empirical results show that
RealDevWorld delivers effective, automatic, and human-aligned evaluations,
achieving an accuracy of 0.92 and a correlation of 0.85 with expert human
assessments, while significantly reducing the reliance on manual review. This
enables scalable, human-aligned assessment of production-level software
generated by LLMs. Our code is available on GitHub.

</details>


### [4] [Ambiguity Resolution with Human Feedback for Code Writing Tasks](https://arxiv.org/abs/2508.14114)
*Aditey Nandan,Viraj Kumar*

Main category: cs.SE

TL;DR: 本文提出ARHF技术，通过自动检测歧义、获取人类反馈生成明确代码，提升程序员处理任务歧义的能力，对编程教育有积极影响。


<details>
  <summary>Details</summary>
Motivation: 代码编写任务的规范常用自然语言表达，容易产生歧义，程序员需要具备识别和消除任务歧义的能力。本文希望借助辅助系统提升这一能力。

Method: 提出了一种新的技术ARHF（人类反馈的歧义消解），让系统自动识别自然语言规范中的潜在歧义，针对具体输入寻求人类反馈，并利用反馈生成无歧义的代码。并通过原型系统进行实验评估。

Result: 原型系统可自动检测歧义输入、有效收集人类反馈，并据此生成消解歧义的代码。系统性能得到了实证评估。

Conclusion: ARHF技术和原型系统能辅助程序员识别和解决规范歧义，对于提高计算机科学教育质量具有重要意义。

Abstract: Specifications for code writing tasks are usually expressed in natural
language and may be ambiguous. Programmers must therefore develop the ability
to recognize ambiguities in task specifications and resolve them by asking
clarifying questions. We present and evaluate a prototype system, based on a
novel technique (ARHF: Ambiguity Resolution with Human Feedback), that (1)
suggests specific inputs on which a given task specification may be ambiguous,
(2) seeks limited human feedback about the code's desired behavior on those
inputs, and (3) uses this feedback to generate code that resolves these
ambiguities. We evaluate the efficacy of our prototype, and we discuss the
implications of such assistive systems on Computer Science education.

</details>


### [5] [Measuring LLM Code Generation Stability via Structural Entropy](https://arxiv.org/abs/2508.14288)
*Yewei Song,Tiezhu Sun,Xunzhu Tang,Prateek Rajput,Tegawende F. Bissyande,Jacques Klein*

Main category: cs.SE

TL;DR: 作者提出了一种基于AST子树分布的结构熵分析法，能够无参考、无执行判断、跨语言地评估LLM生成代码的稳定性，并用该方法揭示了主流模型在一致性和健壮性上的差异，是一种高效、实用的新评价工具。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在代码生成领域的应用逐渐广泛，但评估其生成代码的稳定性对实际开发的可靠性至关重要。现有指标如pass@k、BLEU等存在依赖参考答案、特定语言或执行依赖等局限，难以全面反映代码生成的一致性和结构稳健性。

Method: 该论文将结构熵（structural-entropy）扩展到程序领域，并结合抽象语法树（AST）分析。具体做法为：针对某一固定提示，从每个生成程序中收集AST的限定深度子树集合，并将其相对频率视为概率分布。随后，采用Jensen-Shannon散度和结构交叉熵比率两种方式评估代码生成的稳定性。这两种度量既有仅关注结构的形式，也有关注标识符等Token细节的变体，无需参考答案、执行或语言特定信息。

Result: 用该方法在主流代码生成LLM及标准任务集上进行评测，结果显示：基于AST的结构熵能够揭示模型在一致性和健壮性方面更细微的表现差异。此方法计算复杂度低（O(n,d)），无需外部测试，适合作为轻量级代码生成评测工具。

Conclusion: 论文提出的结构熵评估方法能更加全面且高效地衡量LLM代码生成稳定性，突破了现有指标的多项限制，为后续相关研究和实际开发应用提供支持。

Abstract: Assessing the stability of code generation from large language models (LLMs)
is essential for judging their reliability in real-world development. We extend
prior "structural-entropy concepts" to the program domain by pairing entropy
with abstract syntax tree (AST) analysis. For any fixed prompt, we collect the
multiset of depth-bounded subtrees of AST in each generated program and treat
their relative frequencies as a probability distribution. We then measure
stability in two complementary ways: (i) Jensen-Shannon divergence, a
symmetric, bounded indicator of structural overlap, and (ii) a Structural
Cross-Entropy ratio that highlights missing high-probability patterns. Both
metrics admit structural-only and token-aware variants, enabling separate views
on control-flow shape and identifier-level variability. Unlike pass@k, BLEU, or
CodeBLEU, our metrics are reference-free, language-agnostic, and
execution-independent. We benchmark several leading LLMs on standard code
generation tasks, demonstrating that AST-driven structural entropy reveals
nuances in model consistency and robustness. The method runs in O(n,d) time
with no external tests, providing a lightweight addition to the code-generation
evaluation toolkit.

</details>


### [6] [Static Analysis as a Feedback Loop: Enhancing LLM-Generated Code Beyond Correctness](https://arxiv.org/abs/2508.14419)
*Scott Blyth,Sherlock A. Licorish,Christoph Treude,Markus Wagner*

Main category: cs.SE

TL;DR: 本文提出用静态分析工具驱动提示迭代提升LLM生成代码的安全性、可读性和可靠性，在GPT-4o和PythonSecurityEval实验中取得显著效果，说明LLM通过静态反馈能生成更高质量代码。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLM）在代码生成任务上表现出色，但主流评测（如HumanEval和MBPP）仅关注功能正确性，忽略了代码安全性、可读性、可靠性等更广泛的质量维度。作者认为有必要综合评估和提升LLM生成代码的整体质量。

Method: 提出了一种基于迭代静态分析驱动的提示算法，结合Bandit和Pylint工具自动检测并修复代码中的安全性、可读性和可靠性等问题。在每一轮，静态分析发现问题后，LLM根据反馈再次生成改进后的代码，反复迭代。评测基于PythonSecurityEval基准和GPT-4o模型进行。

Result: 通过十轮迭代，安全问题从40%以上降至13%，可读性问题从80%以上降至11%，可靠性警告从50%以上降至11%。

Conclusion: 结合静态分析反馈可以显著提升LLM生成代码在多个质量维度上的表现，突破了仅关注功能正确性的局限性。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities in
code generation, achieving high scores on benchmarks such as HumanEval and
MBPP. However, these benchmarks primarily assess functional correctness and
neglect broader dimensions of code quality, including security, reliability,
readability, and maintainability. In this work, we systematically evaluate the
ability of LLMs to generate high-quality code across multiple dimensions using
the PythonSecurityEval benchmark. We introduce an iterative static
analysis-driven prompting algorithm that leverages Bandit and Pylint to
identify and resolve code quality issues. Our experiments with GPT-4o show
substantial improvements: security issues reduced from >40% to 13%, readability
violations from >80% to 11%, and reliability warnings from >50% to 11% within
ten iterations. These results demonstrate that LLMs, when guided by static
analysis feedback, can significantly enhance code quality beyond functional
correctness.

</details>


### [7] [Design and Evaluation of a Scalable Data Pipeline for AI-Driven Air Quality Monitoring in Low-Resource Settings](https://arxiv.org/abs/2508.14451)
*Richard Sserujongi,Daniel Ogenrwot,Nicholas Niwamanya,Noah Nsimbe,Martin Bbaale,Benjamin Ssempala,Noble Mutabazi,Raja Fidel Wabinyai,Deo Okure,Engineer Bainomugisha*

Main category: cs.SE

TL;DR: 本文提出并开源了AirQo云原生环境数据管道系统，在资源有限、网络不稳定的非洲城市大规模环境监测项目中，展现了高效、稳定、易用的数据处理能力，为低成本环境智能平台建设提供了可借鉴经验。


<details>
  <summary>Details</summary>
Motivation: 由于低成本环境传感器和AI应用的普及，尤其是在数据稀缺和资源有限的地区，亟需可扩展且具备弹性的环境数据基础设施。

Method: 设计、实现并评估了AirQo数据管道——一种模块化、云原生的ETL系统，能够支持城市区域大规模部署下的多样化实时与批处理空气质量数据集成。该系统结合开源技术（如Apache Airflow、Kafka和Google BigQuery），实现自动采集、校准、预报与分析功能。

Result: AirQo管道能够每月低延迟高吞吐地从400多个设备中稳定采集和分发数百万空气质量数据，即使在电力、连接受限场景下也保持数据可用。系统在资源利用、吞吐量、校准精度和可用性方面表现良好。

Conclusion: 文中开源且文档完善的平台和经验为低资源环境下的可持续环境数据基础设施建设提供了可复用蓝图，有助于推动环境智能的普及。

Abstract: The increasing adoption of low-cost environmental sensors and AI-enabled
applications has accelerated the demand for scalable and resilient data
infrastructures, particularly in data-scarce and resource-constrained regions.
This paper presents the design, implementation, and evaluation of the AirQo
data pipeline: a modular, cloud-native Extract-Transform-Load (ETL) system
engineered to support both real-time and batch processing of heterogeneous air
quality data across urban deployments in Africa. It is Built using open-source
technologies such as Apache Airflow, Apache Kafka, and Google BigQuery. The
pipeline integrates diverse data streams from low-cost sensors, third-party
weather APIs, and reference-grade monitors to enable automated calibration,
forecasting, and accessible analytics. We demonstrate the pipeline's ability to
ingest, transform, and distribute millions of air quality measurements monthly
from over 400 monitoring devices while achieving low latency, high throughput,
and robust data availability, even under constrained power and connectivity
conditions. The paper details key architectural features, including workflow
orchestration, decoupled ingestion layers, machine learning-driven sensor
calibration, and observability frameworks. Performance is evaluated across
operational metrics such as resource utilization, ingestion throughput,
calibration accuracy, and data availability, offering practical insights into
building sustainable environmental data platforms. By open-sourcing the
platform and documenting deployment experiences, this work contributes a
reusable blueprint for similar initiatives seeking to advance environmental
intelligence through data engineering in low-resource settings.

</details>


### [8] [What You See Is What It Does: A Structural Pattern for Legible Software](https://arxiv.org/abs/2508.14511)
*Eagon Meng,Daniel Jackson*

Main category: cs.SE

TL;DR: 现有软件结构不够清晰与模块化，不利于增量开发与可维护性。作者提出基于“概念-同步”以及事件规则的新结构模式，用专用语言提高表达和生成能力。实证表明，该方法有利于构建LLM友好的、高度模块化的软件系统。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代码生成器带来了机遇，同时也暴露出现有软件结构在可读性与模块化方面的不足：代码与行为关联不明晰、模块化程度低，影响了增量开发、完整性和透明度等关键要求。作者希望推动软件结构的重新设计。

Method: 提出一种新的结构化模式，由概念和同步元素构建：即完全独立的服务与基于事件的规则来协调它们，并设计了专用领域语言描述同步规则，从而实现行为特性的细粒度、声明式表达。然后用RealWorld基准进行案例研究以演示和评估这一方法。

Result: 新结构在可读性和模块化方面带来改进。利用特定领域语言实现行为描述的粒度和表达能力，提升了软件的增量开发性、完整性保障及透明度。案例分析支持了这种结构化方案的有效性。

Conclusion: 应重构现有软件的结构，采用概念+同步的模块化新模式，可以显著提升代码与行为的对应性和系统的可维护性，同时让LLM辅助开发变得更有效。专用同步语言极大地利于自动代码生成和管理复杂行为。

Abstract: The opportunities offered by LLM coders (and their current limitations)
demand a reevaluation of how software is structured. Software today is often
"illegible" - lacking a direct correspondence between code and observed
behavior - and insufficiently modular, leading to a failure of three key
requirements of robust coding: incrementality (the ability to deliver small
increments by making localized changes), integrity (avoiding breaking prior
increments) and transparency (making clear what has changed at build time, and
what actions have happened at runtime).
  A new structural pattern offers improved legibility and modularity. Its
elements are concepts and synchronizations: fully independent services and
event-based rules that mediate between them. A domain-specific language for
synchronizations allows behavioral features to be expressed in a granular and
declarative way (and thus readily generated by an LLM). A case study of the
RealWorld benchmark is used to illustrate and evaluate the approach.

</details>


### [9] [Preguss: It Analyzes, It Specifies, It Verifies](https://arxiv.org/abs/2508.14532)
*Zhongyi Wang,Tengjie Lin,Mingshuai Chen,Mingqi Yang,Haokun Li,Xiao Yi,Shengchao Qin,Jianwei Yin*

Main category: cs.SE

TL;DR: 本文提出Preguss框架，通过RTE引导静态分析与LLM辅助规范合成，提升了大型程序的自动化验证能力，解决了LLM在可扩展性和复杂规范推理上的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）在自动化形式化验证中展现了潜力，但受限于上下文长度和推理复杂跨过程规范的困难，导致可扩展性较差。需要新的方法来提高对于大规模系统的自动化验证能力。

Method: 提出了Preguss，一个模块化与细粒度框架。其通过静态分析与演绎验证结合，包含两大组件：(1)利用潜在运行时错误（RTE）引导构建和优先验证单元；(2)通过LLM辅助在单元级别合成跨过程规范。协同两者以提升自动生成与完善形式化规范的能力。

Result: 孕育出了一条促进大型程序自动化验证的可行道路，提升了规范生成与自动化验证的效率和可扩展性。

Conclusion: Preguss框架有效结合了静态分析与LLM的优势，提供了自动化、可扩展的形式化规范生成新范式，有望推动大规模程序的自动化形式化验证。

Abstract: Fully automated verification of large-scale software and hardware systems is
arguably the holy grail of formal methods. Large language models (LLMs) have
recently demonstrated their potential for enhancing the degree of automation in
formal verification by, e.g., generating formal specifications as essential to
deductive verification, yet exhibit poor scalability due to context-length
limitations and, more importantly, the difficulty of inferring complex,
interprocedural specifications. This paper outlines Preguss - a modular,
fine-grained framework for automating the generation and refinement of formal
specifications. Preguss synergizes between static analysis and deductive
verification by orchestrating two components: (i) potential runtime error
(RTE)-guided construction and prioritization of verification units, and (ii)
LLM-aided synthesis of interprocedural specifications at the unit level. We
envisage that Preguss paves a compelling path towards the automated
verification of large-scale programs.

</details>


### [10] [Post-hoc LLM-Supported Debugging of Distributed Processes](https://arxiv.org/abs/2508.14540)
*Dennis Schiese,Andreas Both*

Main category: cs.SE

TL;DR: 该论文提出用生成式AI和流程数据自动生成系统行为解释，辅助开发者调试，展示了一个Java系统演示器，方法具有语言无关性，可成为提升调试效率的通用方案。


<details>
  <summary>Details</summary>
Motivation: 如今手动调试依然耗时且效率低下，尤其在复杂、分布式的软件系统里尤为突出，因此需要新的方法来提升调试效率。

Method: 利用系统的流程数据，结合生成式AI，自动生成自然语言解释。这些解释结合了实际流程数据、接口信息和文档内容，从而辅助开发者理解系统过程及其子过程的行为和可能出错点。

Result: 开发了一个基于组件的Java系统演示器，展示该方法实际使用效果。该方法不依赖于具体编程语言，适用于任意系统。

Conclusion: 提出了一种通用的、可应用于不同系统层级的自动化调试辅助方法，通过自然语言生成解释提升开发者对系统及故障的理解，是调试效率提升的新方向。

Abstract: In this paper, we address the problem of manual debugging, which nowadays
remains resource-intensive and in some parts archaic. This problem is
especially evident in increasingly complex and distributed software systems.
Therefore, our objective of this work is to introduce an approach that can
possibly be applied to any system, at both the macro- and micro-level, to ease
this debugging process. This approach utilizes a system's process data, in
conjunction with generative AI, to generate natural-language explanations.
These explanations are generated from the actual process data, interface
information, and documentation to guide the developers more efficiently to
understand the behavior and possible errors of a process and its sub-processes.
Here, we present a demonstrator that employs this approach on a component-based
Java system. However, our approach is language-agnostic. Ideally, the generated
explanations will provide a good understanding of the process, even if
developers are not familiar with all the details of the considered system. Our
demonstrator is provided as an open-source web application that is freely
accessible to all users.

</details>


### [11] [Towards LLM-generated explanations for Component-based Knowledge Graph Question Answering Systems](https://arxiv.org/abs/2508.14553)
*Dennis Schiese,Aleksandr Perevalov,Andreas Both*

Main category: cs.SE

TL;DR: 本文提出利用输入输出数据流为问答组件的决策行为自动生成可解释结果，实验显示LLM生成的解释优于模板方法，增强了系统的可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着软件复杂度增加，系统的行为决策变得难以解释和理解，尤其是在基于组件的问答系统中，AI驱动的决策难以为开发者和用户所解释。

Method: 提出一种基于组件输入/输出数据流来解释系统行为的方法，并在问答框架中将数据流转化为SPARQL查询和RDF三元组，通过模板和大语言模型（LLM）生成解释。

Result: 实验表明，采用LLM自动生成解释的质量高于模板方法，大部分情况下获得用户更高评价。

Conclusion: 方法有效提升了基于RDF和SPARQL的问答组件的自动可解释性，为用户理解其行为和决策提供了帮助。

Abstract: Over time, software systems have reached a level of complexity that makes it
difficult for their developers and users to explain particular decisions made
by them. In this paper, we focus on the explainability of component-based
systems for Question Answering (QA). These components often conduct processes
driven by AI methods, in which behavior and decisions cannot be clearly
explained or justified, s.t., even for QA experts interpreting the executed
process and its results is hard. To address this challenge, we present an
approach that considers the components' input and output data flows as a source
for representing the behavior and provide explanations for the components,
enabling users to comprehend what happened. In the QA framework used here, the
data flows of the components are represented as SPARQL queries (inputs) and RDF
triples (outputs). Hence, we are also providing valuable insights on
verbalization regarding these data types. In our experiments, the approach
generates explanations while following template-based settings (baseline) or
via the use of Large Language Models (LLMs) with different configurations
(automatic generation). Our evaluation shows that the explanations generated
via LLMs achieve high quality and mostly outperform template-based approaches
according to the users' ratings. Therefore, it enables us to automatically
explain the behavior and decisions of QA components to humans while using RDF
and SPARQL as a context for explanations.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [12] [To Zip Through the Cost Analysis of Probabilistic Programs](https://arxiv.org/abs/2508.14249)
*Matthias Hetzenberger,Georg Moser,Florian Zuleger*

Main category: cs.LO

TL;DR: 提出了在Liquid Haskell中编码概率行为的概率monad，实现了概率算法期望运行时间的自动化推理，并在实际案例中验证了有效性，推动了概率程序分析自动化的发展。


<details>
  <summary>Details</summary>
Motivation: 概率编程和概率算法的形式化分析因广泛使用随机性提升性能而成为研究热点，但关于期望运行时间的自动化推理仍较为有限。该论文旨在解决自动推理概率算法期望运行时间的挑战。

Method: 该方法通过在Liquid Haskell中引入细化类型概率monad，将概率行为直接编码到类型中，从而自动化推理期望值和运行成本。最初仅支持有限离散分布，后通过公理化方法扩展到无限分布，并利用Liquid Haskell的SMT驱动类型检查提升自动化程度。

Result: 通过四个案例研究（可合并堆、集换券收集者、随机快速排序、zip树）进行了方法评估。前两个案例显示自动化推理几乎无需额外标注，后两个展示了monad与交互式证明的集成，尤其实现了zip树期望运行时间的首次形式化验证。

Conclusion: 提出了一种结合细化类型与概率monad的新框架，实现了概率算法期望值和运行时间的自动推理，在实际案例中展示了高效性与自动化，为形式化验证概率算法性能提供了新工具。

Abstract: Probabilistic programming and the formal analysis of probabilistic algorithms
are active areas of research, driven by the widespread use of randomness to
improve performance. While functional correctness has seen substantial
progress, automated reasoning about expected runtime remains comparatively
limited. In this work, we address this challenge by introducing a
refinement-typed probability monad in Liquid Haskell. Our monad enables
automated reasoning about expected values and costs by encoding probabilistic
behaviour directly in types. Initially defined for discrete distributions over
finite support, it is extended to support infinite distributions via an
axiomatic approach. By leveraging Liquid Haskell's SMT-based refinement type
checking, our framework provides a high degree of automation. We evaluate our
approach through four case studies: meldable heaps, coupon collector,
randomised quicksort, and zip trees. The first two demonstrate automation with
minimal annotation overhead. The latter two showcase how our monad integrates
with interactive proofs, including the first formal verification of the
expected runtime of zip trees.

</details>


### [13] [Quantum Petri Nets with Event Structures semantics](https://arxiv.org/abs/2508.14531)
*Julien Saan Joachim,Marc de Visme,Stefan Haar*

Main category: cs.LO

TL;DR: 本论文提出了量子Petri网（QPNs）及其展开和组合理论，弥补了量子并发建模的理论空白，为量子程序和并发分析工具提供了坚实的基础。


<details>
  <summary>Details</summary>
Motivation: 传统的Petri网在并发建模方面有着成熟的理论和工具，但在量子并发领域，目前缺乏类似的、严密的理论框架。现有的“量子Petri网”无法提供完善的量子语义与并发分析工具及理论基础。

Method: 作者提出了Quantum Petri Nets（QPNs），并结合了量子事件结构的语义进行建模。具体方法包括：（i）提出了兼容量子事件结构的局部量子发生网（LQONs）；（ii）构建了具有明确定义的展开语义的QPNs；（iii）建立了QPNs的组合式框架。

Result: 作者建立了一种语义上有坚实基础的量子并发模型，使Petri网理论能够延伸到量子编程领域，填补了量子Petri网在展开语义和组合式建模上的空白。

Conclusion: 该工作首次在量子并发领域构建了与传统Petri网理论同等严密的理论框架，为量子并发和量子程序分析工具的发展奠定了基础。

Abstract: Classical Petri nets provide a canonical model of concurrency, with unfolding
semantics linking nets, occurrence nets, and event structures. No comparable
framework exists for quantum concurrency: existing ''quantum Petri nets'' lack
rigorous concurrent and sound quantum semantics, analysis tools, and unfolding
theory. We introduce Quantum Petri Nets (QPNs), Petri nets equipped with a
quantum valuation compatible with the quantum event structure semantics of
Clairambault, De Visme, and Winskel (2019). Our contributions are: (i) a local
definition of Quantum Occurrence Nets (LQONs) compatible with quantum event
structures, (ii) a construction of QPNs with a well-defined unfolding
semantics, (iii) a compositional framework for QPNs. This establishes a
semantically well grounded model of quantum concurrency, bridging Petri net
theory and quantum programming.

</details>


### [14] [Correct Black-Box Monitors for Distributed Deadlock Detection: Formalisation and Implementation (Technical Report)](https://arxiv.org/abs/2508.14851)
*Radosław Jan Rowicki,Adrian Francalanza,Alceste Scalas*

Main category: cs.LO

TL;DR: 本文针对分布式微服务死锁难以诊断问题，提出并证明了首个分布式黑盒死锁监控算法，并通过工具DDMon在Erlang/OTP应用中验证了效果。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统中并发和分布式（微）服务的演化，其复杂度和规模不断增加，死锁的风险也随之升高。而死锁影响往往不仅限于发生死锁的服务，还会波及依赖其响应的其他服务，使得真正的死锁位置难以诊断和修复。解决这一挑战具有重要意义。

Method: 作者提出了一种分布式黑盒监控方法：为每个服务部署监控器，仅通过观察进出消息和与其它监控器交换探针实现死锁检测。建立了覆盖流行RPC应用模式（如Erlang/OTP的gen_servers）的形式化模型，提出并证明了分布式黑盒监控算法的正确性（无误报、漏报）。

Result: 算法已在工具DDMon中实现，并针对Erlang/OTP应用进行了性能评估。结果表明，该工具能够有效检测死锁。相关理论结果已在Coq中机械化证明。

Conclusion: 首次实现了针对RPC服务的分布式黑盒死锁监控器的形式化、正确性证明及实现，并展示了实际工具DDMon的有效性。

Abstract: Many software applications rely on concurrent and distributed (micro)services
that interact via message-passing and various forms of remote procedure calls
(RPC). As these systems organically evolve and grow in scale and complexity,
the risk of introducing deadlocks increases and their impact may worsen: even
if only a few services deadlock, many other services may block while awaiting
responses from the deadlocked ones. As a result, the "core" of the deadlock can
be obfuscated by its consequences on the rest of the system, and diagnosing and
fixing the problem can be challenging.
  In this work we tackle the challenge by proposing distributed black-box
monitors that are deployed alongside each service and detect deadlocks by only
observing the incoming and outgoing messages, and exchanging probes with other
monitors. We present a formal model that captures popular RPC-based application
styles (e.g., gen_servers in Erlang/OTP), and a distributed black-box
monitoring algorithm that we prove sound and complete (i.e., identifies
deadlocked services with neither false positives nor false negatives). We
implement our results in a tool called DDMon for the monitoring of Erlang/OTP
applications, and we evaluate its performance.
  This is the first work that formalises, proves the correctness, and
implements distributed black-box monitors for deadlock detection. Our results
are mechanised in Coq. DDMon is the companion artifact of this paper.

</details>


### [15] [A Complete and Natural Rule Set for Multi-Qutrit Clifford Circuits](https://arxiv.org/abs/2508.14670)
*Sarah Meng Li,Michele Mosca,Neil J. Ross,John van de Wetering,Yuming Zhao*

Main category: cs.LO

TL;DR: 作者提出了第一套适用于n-qutrit Clifford电路的完备重写规则，给出了该类电路正规形，并以简洁规则明晰描述了其群结构。


<details>
  <summary>Details</summary>
Motivation: 目前关于量子电路，尤其是奇素数维度下的理论还不完善。对于n-qutrit Clifford电路，尚无完备的重写规则集，限制了相关计算和理论分析。

Method: 作者首先将Selinger提出的n-qubit Clifford电路的正规形推广到qutrit场景，建立了新的重写系统，然后将规则精简为小而自然的一套规则，完整地用生成元和关系描述了qutrit Clifford幺正群。

Result: 提出了首个适用于n-qutrit Clifford电路（n为任意非负整数）的完备重写规则，并将该类电路的群结构以生成元与关系的形式清晰刻画。

Conclusion: 本文首次为任何奇素数维度中的量子电路片段（n-qutrit Clifford电路）给出完备性结果，并提供了一套简明、有效的生成元-关系描述方法。

Abstract: We present a complete set of rewrite rules for n-qutrit Clifford circuits
where n is any non-negative integer. This is the first completeness result for
any fragment of quantum circuits in odd prime dimensions. We first generalize
Selinger's normal form for n-qubit Clifford circuits to the qutrit setting.
Then, we present a rewrite system by which any Clifford circuit can be reduced
to this normal form. We then simplify the rewrite rules in this procedure to a
small natural set of rules, giving a clean presentation of the group of qutrit
Clifford unitaries in terms of generators and relations.

</details>


### [16] [Emerson-Lei and Manna-Pnueli Games for LTLf+ and PPLTL+ Synthesis](https://arxiv.org/abs/2508.14725)
*Daniel Hausmann,Shufang Zhu,Gianmarco Parretti,Christoph Weinhuber,Giuseppe De Giacomo,Nir Piterman*

Main category: cs.LO

TL;DR: 本论文提出两种适用于LTLfp/PPLTLp的反应式综合求解器，并实现、评估了它们。实验表明Manna-Pnueli游戏通常更高效，两类方法结合有望进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: LTLfp和PPLTLp允许在无限轨迹上利用有限轨迹LTLf/PPLTL技术，从而实现与完整LTL同等的表达能力，但缺少高效的反应式综合问题求解器。

Method: 提出并实现了基于图游戏的两种求解器：一种通过Emerson-Lei游戏先将简单目标归约为复杂目标，另一种直接在图中嵌入Manna-Pnueli目标，并级联求解DAG上的子游戏。实际在代表性公式上进行性能测试。

Result: 实验结果显示，Manna-Pnueli游戏在许多情况下性能优于基于Emerson-Lei游戏的方案，但也有例外。两种方法结合能进一步提升实际性能。

Conclusion: Manna-Pnueli games在求解反应式综合问题时通常比现有方法更高效，但不是所有场景都占优，实际应用中两种方法结合使用可能进一步优化性能。

Abstract: Recently, the Manna-Pnueli Hierarchy has been used to define the temporal
logics LTLfp and PPLTLp, which allow to use finite-trace LTLf/PPLTL techniques
in infinite-trace settings while achieving the expressiveness of full LTL. In
this paper, we present the first actual solvers for reactive synthesis in these
logics. These are based on games on graphs that leverage DFA-based techniques
from LTLf/PPLTL to construct the game arena. We start with a symbolic solver
based on Emerson-Lei games, which reduces lower-class properties (guarantee,
safety) to higher ones (recurrence, persistence) before solving the game. We
then introduce Manna-Pnueli games, which natively embed Manna-Pnueli objectives
into the arena. These games are solved by composing solutions to a DAG of
simpler Emerson-Lei games, resulting in a provably more efficient approach. We
implemented the solvers and practically evaluated their performance on a range
of representative formulas. The results show that Manna-Pnueli games often
offer significant advantages, though not universally, indicating that combining
both approaches could further enhance practical performance.

</details>


### [17] [Constraint satisfaction problems, compactness and non-measurable sets](https://arxiv.org/abs/2508.14838)
*Claude Tardif*

Main category: cs.LO

TL;DR: 本文分析了有限关系结构紧性的证明所需集合论公理：宽度为一的情形在ZF系统中可证明，否则则需接受更强的集合论结论，如三维空间的不可测集存在。


<details>
  <summary>Details</summary>
Motivation: 研究有限关系结构的紧性与集合论公理系统的关联，揭示其数学基础属性。

Method: 运用模型论和集合论工具，分析不同宽度的有限关系结构紧性的证明需求。

Result: 对于宽度为一的有限关系结构，其紧性可在Zermelo-Fraenkel(ZF)公理系统中证明；否则，若该结构紧性成立，则会蕴含三维空间中存在不可测集。

Conclusion: 宽度为一的有限关系结构的紧性较弱，易于在普通集合论中处理，而更高宽度的紧性则意味着对集合论基础有更强需求。

Abstract: A finite relational structure A is called compact if for any infinite
relational structure B of the same type, the existence of a homomorphism from B
to A is equivalent to the existence of homomorphisms from all finite
substructures of B to A. We show that if A has width one, then the compactness
of A can be proved in the axiom system of Zermelo and Fraenkel, but otherwise,
the compactness of A implies the existence of non-measurable sets in 3-space.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [18] [From Image Captioning to Visual Storytelling](https://arxiv.org/abs/2508.14045)
*Admitos Passadakis,Yingjin Song,Albert Gatt*

Main category: cs.CL

TL;DR: 本文提出以描述为中介的视觉故事生成新方法，提升了生成质量和效率，并引入新评价指标。


<details>
  <summary>Details</summary>
Motivation: 视觉故事生成需要既依赖图片序列，又保证故事的连贯性和叙事性，现有方法难以平衡两者。

Method: 将视觉故事生成视为图像描述的超集。首先用视觉-语言模型为输入图片生成描述，再用语言-语言方法将描述转为连贯故事。提出了新的统一框架，并引入了“理想性”新指标。

Result: 结合图像描述和故事生成的统一框架可以提升生成故事的质量。同时，该方法加速训练、框架可复用性和可复现性强。新指标“理想性”可用于评估生成结果与理想模型的距离。

Conclusion: 统一的描述-故事框架提升了视觉故事生成的质量和效率，“理想性”指标为评价提供了新方式。

Abstract: Visual Storytelling is a challenging multimodal task between Vision &
Language, where the purpose is to generate a story for a stream of images. Its
difficulty lies on the fact that the story should be both grounded to the image
sequence but also narrative and coherent. The aim of this work is to balance
between these aspects, by treating Visual Storytelling as a superset of Image
Captioning, an approach quite different compared to most of prior relevant
studies. This means that we firstly employ a vision-to-language model for
obtaining captions of the input images, and then, these captions are
transformed into coherent narratives using language-to-language methods. Our
multifarious evaluation shows that integrating captioning and storytelling
under a unified framework, has a positive impact on the quality of the produced
stories. In addition, compared to numerous previous studies, this approach
accelerates training time and makes our framework readily reusable and
reproducible by anyone interested. Lastly, we propose a new metric/tool, named
ideality, that can be used to simulate how far some results are from an oracle
model, and we apply it to emulate human-likeness in visual storytelling.

</details>


### [19] [Benchmarking Sociolinguistic Diversity in Swahili NLP: A Taxonomy-Guided Approach](https://arxiv.org/abs/2508.14051)
*Kezia Oketch,John P. Lalor,Ahmed Abbasi*

Main category: cs.CL

TL;DR: 本研究提出了针对斯瓦希里语的分类法引导评价方法，收集真实答复并分析模型在不同语言变异下的错误，推动了更具文化多样性的自然语言处理模型评价。


<details>
  <summary>Details</summary>
Motivation: 当前斯瓦希里语自然语言处理（NLP）领域在社会语言多样性方面存在不足，亟需构建更具文化和语言代表性的评价框架。

Method: 收集了2170份肯尼亚说话者的自由文本答复，涵盖部落影响、城市俚语、代码混合和外来词，并据此构建结构化分类法。利用该分类法分析不同预训练与指令微调语言模型的预测误差。

Result: 建立了能够捕捉社会语言多样性的评价框架，并展示了社会语言变异对模型性能具有显著影响。

Conclusion: 论文推进了以文化为基础的评价方法，强调了社会语言多样性在模型评估中的重要性，对斯瓦希里语NLP发展具有重要意义。

Abstract: We introduce the first taxonomy-guided evaluation of Swahili NLP, addressing
gaps in sociolinguistic diversity. Drawing on health-related psychometric
tasks, we collect a dataset of 2,170 free-text responses from Kenyan speakers.
The data exhibits tribal influences, urban vernacular, code-mixing, and
loanwords. We develop a structured taxonomy and use it as a lens for examining
model prediction errors across pre-trained and instruction-tuned language
models. Our findings advance culturally grounded evaluation frameworks and
highlight the role of sociolinguistic variation in shaping model performance.

</details>


### [20] [Contrastive Analysis of Constituent Order Preferences Within Adverbial Roles in English and Chinese News: A Large-Language-Model-Driven Approach](https://arxiv.org/abs/2508.14054)
*Yiran Rex Ma*

Main category: cs.CL

TL;DR: 本文利用LLM标注的大型英汉新闻语料，发现英文新闻偏后置修饰成分，中文偏前置，语序有不同的系统性偏好及灵活适应性，丰富了英汉对比信息结构研究。


<details>
  <summary>Details</summary>
Motivation: 目前英汉新闻文本中，成分顺序的差异对信息呈现有重要影响。以往对语序的对比研究多停留于理论层面，缺乏结合大规模真实语料的细致实证分析。本文结合LLM标注的大型英汉新闻语料，尝试从功能块（尤其修饰性成分）的角度，细致分析英汉新闻语序偏好及分布模式。

Method: 基于由大型语言模型（LLM）标注的可比英汉新闻语料库，统计和分析英汉新闻中承担状语等修饰性功能块的典型语序、分布及其偏好，结合SVO结构和功能块共现时的语序变化，探讨信息结构和语用驱动对语序的影响。

Result: （1）英文新闻偏好先呈现核心信息，功能块多后置；中文新闻则倾向先给背景信息，功能块常前置。（2）在SVO结构中，两语言对功能块分布都表现出差异，但中文的前置倾向更显著，英文后置倾向较为温和。（3）功能块共现时，英汉均显示高度灵活性，语序调整受信息和语用目的驱动。

Conclusion: 英汉新闻语序既有系统性偏好，也具备动态适应性，呈现出信息结构的对比特点。本文为英汉语对比信息结构研究提供了新的实证依据。

Abstract: Based on comparable English-Chinese news corpora annotated by Large Language
Model (LLM), this paper attempts to explore the differences in constituent
order of English-Chinese news from the perspective of functional chunks with
adverbial roles, and analyze their typical positional preferences and
distribution patterns. It is found that: (1) English news prefers linear
narrative of core information first, and functional chunks are mostly
post-positioned, while Chinese news prefers overall presentation mode of
background first, and functional chunks are often pre-positioned; (2) In SVO
structure, both English and Chinese news show differences in the distribution
of functional chunks, but the tendency of Chinese pre-positioning is more
significant, while that of English post-positioning is relatively mild; (3)
When function blocks are co-occurring, both English and Chinese news show high
flexibility, and the order adjustment is driven by information and pragmatic
purposes. The study reveals that word order has both systematic preference and
dynamic adaptability, providing new empirical support for contrastive study of
English-Chinese information structure.

</details>


### [21] [T-REX: Table -- Refute or Entail eXplainer](https://arxiv.org/abs/2508.14055)
*Tim Luka Horstmann,Baptiste Geisenberger,Mehwish Alam*

Main category: cs.CL

TL;DR: T-REX是一个基于大语言模型的实时表格事实验证工具，开放在线，帮助非专业用户高效完成主张核查。


<details>
  <summary>Details</summary>
Motivation: 验证文本主张与结构化表格数据之间的一致性是NLP中的一个重要且具有挑战性的任务，具有广泛的现实意义，但目前的解决方案对非专业人士不友好。

Method: 提出了T-REX，一个基于最先进的指令微调推理型大语言模型的实时交互式工具，支持多模态、多语言表格的主张验证。

Result: T-REX使非专家能够访问和使用先进的事实核查技术，并追求高准确性和高透明度，系统已开放在线使用。

Conclusion: T-REX实现了表格主张验证工具的民主化和易用性，特别适用于非专业用户场景。

Abstract: Verifying textual claims against structured tabular data is a critical yet
challenging task in Natural Language Processing with broad real-world impact.
While recent advances in Large Language Models (LLMs) have enabled significant
progress in table fact-checking, current solutions remain inaccessible to
non-experts. We introduce T-REX (T-REX: Table -- Refute or Entail eXplainer),
the first live, interactive tool for claim verification over multimodal,
multilingual tables using state-of-the-art instruction-tuned reasoning LLMs.
Designed for accuracy and transparency, T-REX empowers non-experts by providing
access to advanced fact-checking technology. The system is openly available
online.

</details>


### [22] [Confidence Estimation for Text-to-SQL in Large Language Models](https://arxiv.org/abs/2508.14056)
*Sepideh Entezari Maleki,Mohammadreza Pourreza,Davood Rafiei*

Main category: cs.CL

TL;DR: 本文研究了在大语言模型下文本到SQL的置信度估计，分别评估了黑盒一致性、白盒SQL语法增强以及执行信号的方法组合，实验结果表明结合多种方法能提升置信度评估可靠性。


<details>
  <summary>Details</summary>
Motivation: 文本到SQL的转换过程中，需评估模型生成的SQL查询的可靠性，而无需依赖标准答案。面对大语言模型（LLMs）在权重和梯度不可获取的约束下，这项工作变得更加重要。

Method: 研究了黑盒和白盒的置信度估计方法，黑盒方法着重于一致性基础，而白盒方法结合SQL语法信息利用LLMs的logits。此外，分析了基于SQL执行结果的增强信号对置信度估计的辅助作用。

Result: 一致性方法在黑盒置信度评估中表现最佳；而关注SQL语法并利用LLM logits的白盒方法则在解释性上更具优势。通过执行查询获得的实际信号能显著提高这两类方法的有效性。

Conclusion: 综合黑盒一致性和白盒语法增强方法后，结合执行结果可以更准确地估计文本到SQL的置信度，适用于大语言模型场景。

Abstract: Confidence estimation for text-to-SQL aims to assess the reliability of
model-generated SQL queries without having access to gold answers. We study
this problem in the context of large language models (LLMs), where access to
model weights and gradients is often constrained. We explore both black-box and
white-box confidence estimation strategies, evaluating their effectiveness on
cross-domain text-to-SQL benchmarks. Our evaluation highlights the superior
performance of consistency-based methods among black-box models and the
advantage of SQL-syntax-aware approaches for interpreting LLM logits in
white-box settings. Furthermore, we show that execution-based grounding of
queries provides a valuable supplementary signal, improving the effectiveness
of both approaches.

</details>


### [23] [Assessing and Mitigating Data Memorization Risks in Fine-Tuned Large Language Models](https://arxiv.org/abs/2508.14062)
*Badrinath Ramakrishnan,Akshaya Balaji*

Main category: cs.CL

TL;DR: 微调大语言模型会显著增加隐私数据泄漏风险，本文提出的多层隐私保护方法可有效防止数据泄漏，且模型性能几乎不受影响。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在各种自然语言处理任务中表现出色，但在微调过程中容易记忆训练数据，带来严重的隐私风险。本研究旨在详细分析LLMs微调时的数据记忆现象，并探索有效的隐私保护方法。

Method: 作者基于现有主流LLMs如GPT-2、Phi-3和Gemma-2，设计了包含重复敏感数据的对照实验，测试微调后数据泄漏的比例。同时，提出并评估了语义去重、生成时差分隐私、基于熵的过滤和基于模式的内容过滤四种隐私防护方法。

Result: 实验表明，微调时如包含重复敏感数据，隐私泄漏率从基线的0-5%显著上升到60-75%，平均上升64.2%。经过四种隐私保护技术处理后，数据泄漏率可降至0%，且模型效用可保留94.7%。

Conclusion: 微调LLMs带来显著隐私风险，但组合多层隐私保护技术能兼顾隐私与模型效用，基本消除数据泄漏隐患。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
diverse natural language processing tasks, but their tendency to memorize
training data poses significant privacy risks, particularly during fine-tuning
processes. This paper presents a comprehensive empirical analysis of data
memorization in fine-tuned LLMs and introduces a novel multi-layered privacy
protection framework. Through controlled experiments on modern LLM
architectures including GPT-2, Phi-3, and Gemma-2, we demonstrate that
fine-tuning with repeated sensitive data increases privacy leakage rates from
baseline levels of 0-5% to 60-75%, representing a 64.2% average increase across
tested models. We propose and rigorously evaluate four complementary privacy
protection methods: semantic data deduplication, differential privacy during
generation, entropy-based filtering, and pattern-based content filtering. Our
experimental results show that these techniques can reduce data leakage to 0%
while maintaining 94.7% of original model utility.

</details>


### [24] [Punctuation and Predicates in Language Models](https://arxiv.org/abs/2508.14067)
*Sonakshi Chauhan,Maheep Chaudhary,Koby Choy,Samuel Nellessen,Nandi Schoots*

Main category: cs.CL

TL;DR: 本文系统研究了大语言模型内部层级对标点及推理元素的处理机制，发现不同模型对这些元素的重要性及处理方式存在巨大差异，为模型可解释性带来新启示。


<details>
  <summary>Details</summary>
Motivation: 本文旨在揭示大语言模型（LLMs）内部信息是如何被收集和跨层传播的，特别关注标点符号和不同输入成分在模型处理过程中的作用机制。

Method: 采用干预式技术（intervention-based techniques）来分析GPT-2、DeepSeek和Gemma等模型中标点符号在各层的必要性和充分性，并通过互换干预和层交换实验，研究模型对推理规则的处理方式。

Result: 实验显示，GPT-2在多个层级上标点符号既必要又充分，而DeepSeek和Gemma则明显较弱。此外，模型对于条件语句（if, then）和全称量化（for all）的处理方式有显著差异。

Conclusion: 不同大语言模型在内部层级处理中对于标点和推理规则的利用方式有显著差异，这为理解和解释模型内部机制提供了新视角。

Abstract: In this paper we explore where information is collected and how it is
propagated throughout layers in large language models (LLMs). We begin by
examining the surprising computational importance of punctuation tokens which
previous work has identified as attention sinks and memory aids. Using
intervention-based techniques, we evaluate the necessity and sufficiency (for
preserving model performance) of punctuation tokens across layers in GPT-2,
DeepSeek, and Gemma. Our results show stark model-specific differences: for
GPT-2, punctuation is both necessary and sufficient in multiple layers, while
this holds far less in DeepSeek and not at all in Gemma. Extending beyond
punctuation, we ask whether LLMs process different components of input (e.g.,
subjects, adjectives, punctuation, full sentences) by forming early static
summaries reused across the network, or if the model remains sensitive to
changes in these components across layers. Extending beyond punctuation, we
investigate whether different reasoning rules are processed differently by
LLMs. In particular, through interchange intervention and layer-swapping
experiments, we find that conditional statements (if, then), and universal
quantification (for all) are processed very differently. Our findings offer new
insight into the internal mechanisms of punctuation usage and reasoning in LLMs
and have implications for interpretability.

</details>


### [25] [DLLMQuant: Quantizing Diffusion-based Large Language Models](https://arxiv.org/abs/2508.14090)
*Chen Xu,Dawei Yang*

Main category: cs.CL

TL;DR: DLLM的量化很难，主要由于其特殊的生成机制和分布特点。本文分析难点，提出专用量化方案DLLMQuant（涵盖采样、激活量化和权重误差补偿三技术），相比通用PTQ显著提升准确性和推理效率。


<details>
  <summary>Details</summary>
Motivation: 非自回归扩散式大语言模型（DLLMs）虽有潜力，但受限于模型体积大和计算成本高。现有主流的后训练量化（PTQ）压缩方法在DLLM上应用时会带来严重精度下降和泛化退化。作者希望解决DLLM量化的特殊挑战。

Method: 分析DLLM的核心机制与量化方法的冲突，归纳出三大问题：分步生成和动态mask导致token分布变化、量化误差随迭代累积放大、特征分布与现有量化兼容性不足。为此提出DLLMQuant框架，包括三项新技术：时间mask自适应采样（TMAS）、交互感知激活量化（IA-AQ）、确定性导向量化（CGQ）。

Result: DLLMQuant在多个实验中验证了其适用性，可明显提升DLLM的量化性能和计算效率。

Conclusion: 对DLLM的量化需专用方法，提出的DLLMQuant有效缓解了传统PTQ面临的三大问题，并实现了高性能和高效率。

Abstract: Diffusion-based large language models (DLLMs) have shown promise for
non-autoregressive text generation, but their deployment is constrained by
large model sizes and heavy computational costs. Post-training quantization
(PTQ), a widely used method for compressing and accelerating Large Language
Models (LLMs), suffers from severe accuracy degradation and reduced
generalization performance when directly applied to DLLMs (e.g., AWQ suffers a
16% accuracy drop on LLADA under W4A4). This paper explores how DLLMs' key
mechanisms - dynamic masking, iterative generation, bidirectional attention -
clash with quantization. We identify three core issues: 1) Iterative generation
and dynamic masking ratios lead to distinct token distributions across decoding
steps, which are not adequately captured by existing PTQ calibration methods;
2) Quantization errors are accumulated and amplified progressively during
iteration in DLLMs, causing quantized models to perform worse as decoding steps
progress; 3) Unmasked tokens stabilize while masked remain probabilistic,
making overall feature distribution incompatible with existing PTQ methods. To
address these issues, we propose DLLMQuant, a PTQ framework tailored for DLLMs,
which incorporates three novel techniques: 1) Temporal-Mask Adaptive Sampling
(TMAS), a calibration method that accounts for both time and mask factors, with
the capacity to capture distributions across timesteps. 2) Interaction-Aware
Activation Quantization (IA-AQ), which utilizes bidirectional attention's
interaction signals to dynamically allocate quantization resources. 3)
Certainty-Guided Quantization (CGQ), which integrates mask status and token
scores as key weighting criteria into error compensation, making weight
quantization more suitable for DLLMs. Experiments show that DLLMQuant achieves
significant performance gains while enhancing efficiency.

</details>


### [26] [MMReview: A Multidisciplinary and Multimodal Benchmark for LLM-Based Peer Review Automation](https://arxiv.org/abs/2508.14146)
*Xian Gao,Jiacheng Ruan,Zongyun Zhang,Jingsheng Gao,Ting Liu,Yuzhuo Fu*

Main category: cs.CL

TL;DR: 作者提出了涵盖多学科和多模态内容的评审基准MMReview，并通过大量模型实验验证其有效性，有望成为自动化学术评审标准的重要基础。


<details>
  <summary>Details</summary>
Motivation: 学术出版物数量快速增长使得同行评审变得至关重要但耗时，目前大语言模型（LLM）逐渐应用于评审意见生成，但缺乏统一基准以评估其在生成全面、准确且符合人类标准评审方面的能力，尤其在包含多模态内容（如图表）的场景下。

Method: 提出了MMReview，一个涵盖多学科、多模态的评测基准。MMReview收录了17个研究领域的240篇论文的多模态内容及专家评审意见，分为四大学科——人工智能、自然科学、工程科学和社会科学。包含13项任务、4大核心类别，系统性评估LLM和多模态LLM在评审生成、结果制定、人类偏好对齐及对抗输入鲁棒性等方面的表现。并对16个开源模型与5个闭源模型进行了广泛实验验证。

Result: MMReview通过广泛的模型评测验证了其全面性，能够评估模型在多模态学术评审任务中的表现。

Conclusion: MMReview为自动化同行评审系统的开发奠定了标准化的基础，是建立自动化评审标准的重要一步。

Abstract: With the rapid growth of academic publications, peer review has become an
essential yet time-consuming responsibility within the research community.
Large Language Models (LLMs) have increasingly been adopted to assist in the
generation of review comments; however, current LLM-based review tasks lack a
unified evaluation benchmark to rigorously assess the models' ability to
produce comprehensive, accurate, and human-aligned assessments, particularly in
scenarios involving multimodal content such as figures and tables. To address
this gap, we propose \textbf{MMReview}, a comprehensive benchmark that spans
multiple disciplines and modalities. MMReview includes multimodal content and
expert-written review comments for 240 papers across 17 research domains within
four major academic disciplines: Artificial Intelligence, Natural Sciences,
Engineering Sciences, and Social Sciences. We design a total of 13 tasks
grouped into four core categories, aimed at evaluating the performance of LLMs
and Multimodal LLMs (MLLMs) in step-wise review generation, outcome
formulation, alignment with human preferences, and robustness to adversarial
input manipulation. Extensive experiments conducted on 16 open-source models
and 5 advanced closed-source models demonstrate the thoroughness of the
benchmark. We envision MMReview as a critical step toward establishing a
standardized foundation for the development of automated peer review systems.

</details>


### [27] [DPad: Efficient Diffusion Language Models with Suffix Dropout](https://arxiv.org/abs/2508.14148)
*Xinhua Chen,Sitao Huang,Cong Guo,Chiyue Wei,Yintao He,Jianyi Zhang,Hai "Hellen" Li,Yiran Chen*

Main category: cs.CL

TL;DR: 本文提出DPad方法，通过滑动窗口和距离衰减dropout优化扩散式大语言模型生成过程，无需重新训练即可兼容现有代码，实现推理速度提升最高61.4倍且精度几乎不变，非常适合长序列推理场景。


<details>
  <summary>Details</summary>
Motivation: 扩散式大语言模型（dLLMs）在生成文本时虽然能够并行化操作，但由于每一步都会预测所有未来的后缀词元，导致计算开销极大且效率低下。该问题限制了其在长序列推理上的实际应用能力。

Method: 提出Diffusion Scratchpad（DPad）方法，无需重新训练，通过两种策略优化后缀词元的处理：（1）滑动窗口，仅关注固定长度的近端后缀；（2）距离衰减dropout，在注意力计算前去除远端后缀。这种设计不仅简单易用，还兼容现有优化手段，比如前缀缓存，可轻松集成到代码中。

Result: 在多个基准测试（如LLaDA-1.5和Dream模型）上，DPad方案相较于原始dLLMs实现了最高61.4倍的推理加速，同时在精度上基本无损。

Conclusion: DPad显著提高了扩散式大语言模型的推理效率和可扩展性，为长序列任务提供了可行的高效解决方案，其效果强大且易于集成。

Abstract: Diffusion-based Large Language Models (dLLMs) parallelize text generation by
framing decoding as a denoising process, but suffer from high computational
overhead since they predict all future suffix tokens at each step while
retaining only a small fraction. We propose Diffusion Scratchpad (DPad), a
training-free method that restricts attention to a small set of nearby suffix
tokens, preserving fidelity while eliminating redundancy. DPad integrates two
strategies: (i) a sliding window, which maintains a fixed-length suffix window,
and (ii) distance-decay dropout, which deterministically removes distant suffix
tokens before attention computation. This simple design is compatible with
existing optimizations such as prefix caching and can be implemented with only
a few lines of code. Comprehensive evaluations across multiple benchmarks on
LLaDA-1.5 and Dream models demonstrate that DPad delivers up to
$\mathbf{61.4\times}$ speedup over vanilla dLLMs while maintaining comparable
accuracy, highlighting its potential for efficient and scalable long-sequence
inference. Our code is available at https://github.com/Crys-Chen/DPad.

</details>


### [28] [Comparing energy consumption and accuracy in text classification inference](https://arxiv.org/abs/2508.14170)
*Johannes Zschache,Tilman Hartwig*

Main category: cs.CL

TL;DR: 论文系统评估了文本分类推理阶段不同模型和硬件下的准确率与能耗权衡，发现高准确率模型可兼具高能效，而大型模型能耗高反而表现一般。推理运行时间可作为能耗的简易代理，为可持续AI应用和决策提供参考。


<details>
  <summary>Details</summary>
Motivation: 在大模型持续部署到NLP任务的趋势下，过去关注更多的是训练阶段能耗，推理阶段能耗却被忽视。本研究旨在填补这一空白，探索模型推理时的能效与性能关系。

Method: 对不同模型架构和硬件配置的文本分类推理过程进行系统实证分析，衡量准确率与能耗的权衡。

Result: 最佳准确率模型亦可能能效较高；较大模型耗能明显增加且分类准确率较低。能耗与运行时间有强相关性，不同模型、硬件下能耗差异巨大。

Conclusion: 运行时间可以作为能耗的代理，同时准确率高的模型也可能兼具能效，但大型语言模型能耗较高且准确率反而较低。

Abstract: The increasing deployment of large language models (LLMs) in natural language
processing (NLP) tasks raises concerns about energy efficiency and
sustainability. While prior research has largely focused on energy consumption
during model training, the inference phase has received comparatively less
attention. This study systematically evaluates the trade-offs between model
accuracy and energy consumption in text classification inference across various
model architectures and hardware configurations. Our empirical analysis shows
that the best-performing model in terms of accuracy can also be
energy-efficient, while larger LLMs tend to consume significantly more energy
with lower classification accuracy. We observe substantial variability in
inference energy consumption ($<$mWh to $>$kWh), influenced by model type,
model size, and hardware specifications. Additionally, we find a strong
correlation between inference energy consumption and model runtime, indicating
that execution time can serve as a practical proxy for energy usage in settings
where direct measurement is not feasible. These findings have implications for
sustainable AI development, providing actionable insights for researchers,
industry practitioners, and policymakers seeking to balance performance and
resource efficiency in NLP applications.

</details>


### [29] [Let's Use ChatGPT To Write Our Paper! Benchmarking LLMs To Write the Introduction of a Research Paper](https://arxiv.org/abs/2508.14273)
*Krishna Garg,Firoz Shaikh,Sambaran Bandyopadhyay,Cornelia Caragea*

Main category: cs.CL

TL;DR: 研究评估了主流大语言模型自动生成科研论文引言的能力，提出了SciIG任务和数据集。结果显示，LLaMA-4 Maverick表现最佳，三次示例输入效果更优，相关资源将公开，为学术写作辅助提供参考。


<details>
  <summary>Details</summary>
Motivation: 研究人员越来越多地采用大语言模型（LLMs）作为写作助手，但如何生成高质量的论文引言仍具挑战性且十分重要。本论文旨在评估LLMs在基于标题、摘要和相关工作自动生成科学论文引言方面的能力。

Method: 作者提出了Scientific Introduction Generation（SciIG）任务，并新建了包含NAACL 2025和ICLR 2025论文的新数据集。比较了五个先进模型（包括开源与闭源），在词汇重合度、语义相似性、内容全面性、真实性、一致性、引用正确性和叙事质量等多个维度进行评测。采用了自动指标结合LLM判官评估的方法。

Result: LLaMA-4 Maverick在大部分指标，尤其是在语义相似性和真实性方面表现最佳。此外，三次示例提示（three-shot prompting）始终优于更少示例。相关代码和数据集将公开发布，促进重现性与后续研究。

Conclusion: 本文为构建高效研究写作助手提供了实践指导，并为LLM辅助学术写作的能力设定了现实预期，对未来研究具有推动作用。

Abstract: As researchers increasingly adopt LLMs as writing assistants, generating
high-quality research paper introductions remains both challenging and
essential. We introduce Scientific Introduction Generation (SciIG), a task that
evaluates LLMs' ability to produce coherent introductions from titles,
abstracts, and related works. Curating new datasets from NAACL 2025 and ICLR
2025 papers, we assess five state-of-the-art models, including both open-source
(DeepSeek-v3, Gemma-3-12B, LLaMA 4-Maverick, MistralAI Small 3.1) and
closed-source GPT-4o systems, across multiple dimensions: lexical overlap,
semantic similarity, content coverage, faithfulness, consistency, citation
correctness, and narrative quality. Our comprehensive framework combines
automated metrics with LLM-as-a-judge evaluations. Results demonstrate LLaMA-4
Maverick's superior performance on most metrics, particularly in semantic
similarity and faithfulness. Moreover, three-shot prompting consistently
outperforms fewer-shot approaches. These findings provide practical insights
into developing effective research writing assistants and set realistic
expectations for LLM-assisted academic writing. To foster reproducibility and
future research, we will publicly release all code and datasets.

</details>


### [30] [Disentangling concept semantics via multilingual averaging in Sparse Autoencoders](https://arxiv.org/abs/2508.14275)
*Cliff O'Reilly,Ernesto Jimenez-Ruiz,Tillman Weyde*

Main category: cs.CL

TL;DR: 本文提出了一种基于稀疏自动编码器的多语言平均概念激活方法，有效提升了LLM对本体概念语义的表示与内部机制解释能力，实验验证其优于单语言方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在语义推理方面存在不足，目前常用的文本表示方法如嵌入和稀疏自动编码器会混合语义和语法信息，影响对概念的准确表达。作者希望通过结合形式知识表达与推理，提升LLMs的语义表达能力。

Method: 作者提出了一种方法，通过利用稀疏自动编码器获取由OWL本体类生成的英文文本表示，并将英文翻译为法语和中文，再分别输入Gemma 2B LLM进行概念激活获取。将不同语言下获得的激活结果进行平均，得到概念平均值，并与本体类的真实映射进行相关性对比分析。

Result: 实验显示，跨语言概念平均激活能更准确地反映本体类之间的真实语义关系，相较于仅用单一语言的激活结果性能更优。

Conclusion: 多语言稀疏自动编码器激活平均值有助于隔离概念语义，并在机制层面提升对LLM内部状态的解读准确度，为概念表示和解释机制提供了新的方法思路。

Abstract: Connecting LLMs with formal knowledge representation and reasoning is a
promising approach to address their shortcomings. Embeddings and sparse
autoencoders are widely used to represent textual content, but the semantics
are entangled with syntactic and language-specific information. We propose a
method that isolates concept semantics in Large Langue Models by averaging
concept activations derived via Sparse Autoencoders. We create English text
representations from OWL ontology classes, translate the English into French
and Chinese and then pass these texts as prompts to the Gemma 2B LLM. Using the
open source Gemma Scope suite of Sparse Autoencoders, we obtain concept
activations for each class and language version. We average the different
language activations to derive a conceptual average. We then correlate the
conceptual averages with a ground truth mapping between ontology classes. Our
results give a strong indication that the conceptual average aligns to the true
relationship between classes when compared with a single language by itself.
The result hints at a new technique which enables mechanistic interpretation of
internal network states with higher accuracy.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [31] [A statistical test for network similarity](https://arxiv.org/abs/2508.14399)
*Pierre Miasnikof,Alexander Y. Shetopaloff*

Main category: cs.DM

TL;DR: 该研究扩展了早期关于图相似性的工作，通过大量实证检验，证明所提出的测试方法能准确衡量图之间的相似性和差异性，无论是在合成数据还是真实网络中。


<details>
  <summary>Details</summary>
Motivation: 作者希望改进图相似性测量方法，并测试其在不同网络上的表现。

Method: 进行大量实证测试，分析测试对网络变化的敏感性，并在合成和真实图数据上进行评估。

Result: 测试方法在不同类型的图（包括合成和真实世界的图）上表现良好，能够准确测量图的相似性和差异性。

Conclusion: 所提出的测试方法能有效、准确地衡量图之间的（不）相似性，且表现符合预期。

Abstract: In this article, we revisit and expand our prior work on graph similarity. In
this version of our work, we offer an extensive array of empirical tests. We
also examine the sensitivity of our test to network variations. Our test
performs exactly as expected, on synthetic and real-world graphs. It offers a
very accurate measure of graph (dis)similarity.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [32] [Efficient Learning of Weak Deterministic Büchi Automata](https://arxiv.org/abs/2508.14274)
*Mona Alluwayma,Yong Li,Sven Schewe,Qiyi Tang*

Main category: cs.FL

TL;DR: 该论文提出了一个高效的wDBA学习算法，将查询复杂度从五次方降至二次方，并在实验中取得显著优势。


<details>
  <summary>Details</summary>
Motivation: 相比于普通的确定性Büchi和co-Büchi自动机，wDBA存在可唯一确定的最小规范形式，且现有学习方法查询复杂度较高，因此有必要研究更高效的学习算法。

Method: 设计了一种新的学习算法，将目标语言的wDBA归约为其最小规范形式，分析和改进了查询复杂度，并与以往方法进行了对比实验。

Result: 理论上将查询复杂度从五次方降至二次方，并通过基准实验验证，显著减少了实际学习过程中所需的查询次数。

Conclusion: 提出了一种高效的基于Angluin风格的算法，能有效学习弱确定性Büchi自动机（wDBA）的最小规范形式，并在理论和实验上均提升了学习效率。

Abstract: We present an efficient Angluin-style learning algorithm for weak
deterministic B\"uchi automata (wDBAs). Different to ordinary deterministic
B\"uchi and co-B\"uchi automata, wDBAs have a minimal normal form, and we show
that we can learn this minimal normal form efficiently. We provide an improved
result on the number of queries required and show on benchmarks that this
theoretical advantage translates into significantly fewer queries: while
previous approaches require a quintic number of queries, we only require
quadratically many queries in the size of the canonic wDBA that recognises the
target language.

</details>
