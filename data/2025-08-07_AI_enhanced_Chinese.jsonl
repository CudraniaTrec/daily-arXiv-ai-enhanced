{"id": "2508.03947", "categories": ["cs.LO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.03947", "abs": "https://arxiv.org/abs/2508.03947", "authors": ["Vishnu Murali", "Mohammed Adib Oumer", "Majid Zamani"], "title": "Control Closure Certificates", "comment": "28 pages, 4 figures, 6 Tables. To appear in International Symposium\n  on Automated Technology for Verification and Analysis (ATVA), 2025", "summary": "This paper introduces the notion of control closure certificates to\nsynthesize controllers for discrete-time control systems against\n$\\omega$-regular specifications. Typical functional approaches to synthesize\ncontrollers against $\\omega$-regular specifications rely on combining inductive\ninvariants (for example, via barrier certificates) with proofs of\nwell-foundedness (for example, via ranking functions). Transition invariants,\nprovide an alternative where instead of standard well-foundedness arguments one\nmay instead search for disjunctive well-foundedness arguments that together\nensure a well-foundedness argument. Closure certificates, functional analogs of\ntransition invariants, provide an effective, automated approach to verify\ndiscrete-time dynamical systems against linear temporal logic and\n$\\omega$-regular specifications. We build on this notion to synthesize\ncontrollers to ensure the satisfaction of $\\omega$-regular specifications. To\ndo so, we first illustrate how one may construct control closure certificates\nto visit a region infinitely often (or only finitely often) via disjunctive\nwell-founded arguments. We then combine these arguments to provide an argument\nfor parity specifications. Thus, finding an appropriate control closure\ncertificate over the product of the system and a parity automaton specifying a\ndesired $\\omega$-regular specification ensures that there exists a controller\n$\\kappa$ to enforce the $\\omega$-regular specification. We propose a\nsum-of-squares optimization approach to synthesize such certificates and\ndemonstrate their efficacy in designing controllers over some case studies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u79f0\u4e3a\u63a7\u5236\u95ed\u5305\u8bc1\u4e66\u7684\u65b0\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u79bb\u6563\u65f6\u95f4\u7cfb\u7edf\u5bf9\u03c9-\u6b63\u5219\u89c4\u8303\u7684\u81ea\u52a8\u63a7\u5236\u5668\u5408\u6210\uff0c\u901a\u8fc7\u6c42\u548c\u5e73\u65b9(SOS)\u65b9\u6cd5\u81ea\u52a8\u641c\u7d22\u8bc1\u4e66\uff0c\u5e76\u5728\u591a\u4e2a\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6848\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u03c9-\u6b63\u5219\u89c4\u8303\u4e0b\u7684\u63a7\u5236\u5668\u5408\u6210\u4f9d\u8d56\u4e8e\u5f52\u7eb3\u4e0d\u53d8\u5f0f\u4e0e\u5e38\u89c4\u7684\u826f\u57fa\u6027\u8bc1\u660e\uff0c\u8fd9\u9650\u5236\u4e86\u81ea\u52a8\u5316\u4e0e\u7075\u6d3b\u6027\u3002\u901a\u8fc7\u5f15\u5165\u51fd\u6570\u5f0f\u7c7b\u4f3c\u7684\u4e0d\u53d8\u5f0f\u6982\u5ff5\u2014\u2014\u5373\u95ed\u5305\u8bc1\u4e66\uff0c\u6709\u671b\u63d0\u5347\u7cfb\u7edf\u5316\u3001\u81ea\u52a8\u5316\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u63a7\u5236\u95ed\u5305\u8bc1\u4e66\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u7528\u6c42\u548c\u5e73\u65b9\u4f18\u5316\u65b9\u6cd5\u6765\u81ea\u52a8\u5316\u641c\u7d22\u8bc1\u4e66\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u6ee1\u8db3 \u03c9-\u6b63\u5219\u89c4\u8303\u7684\u63a7\u5236\u5668\u5408\u6210\u3002\u5177\u4f53\u5305\u62ec\u5c06\u7cfb\u7edf\u4e0e\u8d4b\u4e88\u89c4\u8303\u7684\u5947\u5076\u81ea\u52a8\u673a\uff08parity automaton\uff09\u6784\u6210\u79ef\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e0d\u4ea4\u7684\u826f\u57fa\u6027\uff08disjunctive well-foundedness\uff09\u7ec4\u5408\u8bc1\u636e\uff0c\u6700\u7ec8\u4e3a\u5947\u5076\u89c4\u8303\uff08parity specification\uff09\u6784\u5efa\u8bc1\u4e66\u3002", "result": "\u63d0\u51fa\u7684\u63a7\u5236\u95ed\u5305\u8bc1\u4e66\u65b9\u6cd5\u80fd\u591f\u81ea\u52a8\u4e3a\u79bb\u6563\u65f6\u95f4\u7cfb\u7edf\u5408\u6210\u6ee1\u8db3 \u03c9-\u6b63\u5219\u89c4\u8303\u7684\u63a7\u5236\u5668\uff0c\u5e76\u5728\u6848\u4f8b\u4e2d\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u4e0e\u5b9e\u7528\u6027\u3002", "conclusion": "\u901a\u8fc7\u63d0\u51fa\u63a7\u5236\u95ed\u5305\u8bc1\u4e66\uff08control closure certificates\uff09\uff0c\u53ef\u4ee5\u6709\u6548\u81ea\u52a8\u5730\u4e3a\u79bb\u6563\u65f6\u95f4\u63a7\u5236\u7cfb\u7edf\u5408\u6210\u6ee1\u8db3 \u03c9-\u6b63\u5219\u89c4\u8303\u7684\u63a7\u5236\u5668\uff0c\u5e76\u4e14\u5229\u7528\u6c42\u548c\u5e73\u65b9\uff08sum-of-squares\uff09\u4f18\u5316\u65b9\u6cd5\u641c\u7d22\u6b64\u7c7b\u8bc1\u4e66\uff0c\u5b9e\u73b0\u4e86\u591a\u6848\u4f8b\u9a8c\u8bc1\u3002"}}
{"id": "2508.04438", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.04438", "abs": "https://arxiv.org/abs/2508.04438", "authors": ["Mark Chevallier", "Filip Smola", "Richard Schmoetten", "Jacques D. Fleuriot"], "title": "GradSTL: Comprehensive Signal Temporal Logic for Neurosymbolic Reasoning and Learning", "comment": "Accepted for presentation at TIME 2025", "summary": "We present GradSTL, the first fully comprehensive implementation of signal\ntemporal logic (STL) suitable for integration with neurosymbolic learning. In\nparticular, GradSTL can successfully evaluate any STL constraint over any\nsignal, regardless of how it is sampled. Our formally verified approach\nspecifies smooth STL semantics over tensors, with formal proofs of soundness\nand of correctness of its derivative function. Our implementation is generated\nautomatically from this formalisation, without manual coding, guaranteeing\ncorrectness by construction. We show via a case study that using our\nimplementation, a neurosymbolic process learns to satisfy a pre-specified STL\nconstraint. Our approach offers a highly rigorous foundation for integrating\nsignal temporal logic and learning by gradient descent.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u53ef\u65e0\u7f1d\u96c6\u6210\u8fdb\u795e\u7ecf\u7b26\u53f7\u5b66\u4e60\u7684\u9996\u4e2a\u5168\u9762\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08GradSTL\uff09\u5de5\u5177\u94fe\uff0c\u81ea\u52a8\u5316\u5b9e\u73b0\u4e14\u5177\u5907\u5f62\u5f0f\u5316\u6b63\u786e\u6027\u8bc1\u660e\uff0c\u5e76\u6709\u6548\u652f\u6301\u4efb\u610f\u91c7\u6837\u4fe1\u53f7\u7684\u53ef\u5fae\u7ea6\u675f\u9a8c\u8bc1\u3002", "motivation": "\u5f53\u524d\u795e\u7ecf\u7b26\u53f7\u5b66\u4e60\u5728\u4e0e\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08STL\uff09\u96c6\u6210\u65f6\u9762\u4e34\u5b9e\u73b0\u4e0d\u5168\u9762\u548c\u4e0d\u591f\u4e25\u8c28\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5bf9\u4efb\u610f\u91c7\u6837\u4fe1\u53f7\u548c\u7ea6\u675f\u8fdb\u884c\u53ef\u5fae\u5206\u9a8c\u8bc1\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGradSTL\u7684\u65b0\u5b9e\u73b0\u65b9\u5f0f\uff0c\u9996\u5148\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e86\u5728\u5f20\u91cf\u4e0a\u7684\u5e73\u6ed1STL\u8bed\u4e49\uff0c\u5e76\u5bf9\u5176\u5bfc\u6570\u51fd\u6570\u7684\u6b63\u786e\u6027\u548c\u5065\u58ee\u6027\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\u8bc1\u660e\u3002\u7136\u540e\uff0c\u5229\u7528\u8fd9\u4e00\u5f62\u5f0f\u5316\u5b9a\u4e49\u901a\u8fc7\u81ea\u52a8\u5316\u5de5\u5177\u751f\u6210\u4ee3\u7801\uff0c\u5b9e\u73b0\u65e0\u9700\u624b\u5199\u4ee3\u7801\u7684\u81ea\u52a8\u5316\u6784\u5efa\uff0c\u786e\u4fdd\u4e86\u6b63\u786e\u6027\u3002", "result": "GradSTL\u80fd\u591f\u5bf9\u4efb\u610f\u4fe1\u53f7\u548c\u4efb\u610fSTL\u7ea6\u675f\u8fdb\u884c\u5e73\u6ed1\u53ef\u5fae\u7684\u68c0\u67e5\uff0c\u5e76\u4e14\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230\u795e\u7ecf\u7b26\u53f7\u5b66\u4e60\u6846\u67b6\u4e2d\u3002\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u5229\u7528\u8be5\u65b9\u6cd5\u53ef\u4ee5\u4f7f\u795e\u7ecf\u7b26\u53f7\u8fc7\u7a0b\u6210\u529f\u5b66\u4e60\u5e76\u6ee1\u8db3\u9884\u8bbe\u7684STL\u7ea6\u675f\u3002", "conclusion": "GradSTL\u4e3a\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\u4e0e\u68af\u5ea6\u4e0b\u964d\u5b66\u4e60\u7684\u96c6\u6210\u63d0\u4f9b\u4e86\u6781\u4e3a\u4e25\u8c28\u4e14\u901a\u7528\u7684\u57fa\u7840\uff0c\u53ef\u663e\u8457\u63d0\u5347\u76f8\u5173\u7cfb\u7edf\u7684\u6b63\u786e\u6027\u4e0e\u7075\u6d3b\u6027\u3002"}}
{"id": "2508.03826", "categories": ["cs.FL", "F.1.1; F.4.2; F.4.3"], "pdf": "https://arxiv.org/pdf/2508.03826", "abs": "https://arxiv.org/abs/2508.03826", "authors": ["Smayan Agarwal", "Shobhit Singh", "Aalok Thakkar"], "title": "Identity Testing for Stochastic Languages", "comment": null, "summary": "Determining whether an unknown distribution matches a known reference is a\ncornerstone problem in distributional analysis. While classical results\nestablish a rigorous framework in the case of distributions over finite\ndomains, real-world applications in computational linguistics, bioinformatics,\nand program analysis demand testing over infinite combinatorial structures,\nparticularly strings. In this paper, we initiate the theoretical study of\nidentity testing for stochastic languages, bridging formal language theory with\nmodern distribution property testing.\n  We first propose a polynomial-time algorithm to verify if a finite state\nmachine represents a stochastic language, and then prove that rational\nstochastic languages can approximate an arbitrary probability distribution.\nBuilding on these representations, we develop a truncation-based identity\ntesting algorithm that distinguishes between a known and an unknown\ndistributions with sample complexity $\\widetilde{\\Theta}\\left(\n\\frac{\\sqrt{n}}{\\varepsilon^2} + \\frac{n}{\\log n} \\right)$ where $n$ is the\nsize of the truncated support. Our approach leverages the exponential decay\ninherent in rational stochastic languages to bound truncation error, then\napplies classical finite-domain testers to the restricted problem.\n  This work establishes the first identity testing framework for infinite\ndiscrete distributions, opening new directions in probabilistic formal methods\nand statistical analysis of structured data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9996\u4e2a\u65e0\u9650\u79bb\u6563\u5206\u5e03\uff08\u5c24\u5176\u662f\u968f\u673a\u8bed\u8a00\uff09\u7684\u6052\u7b49\u6027\u68c0\u9a8c\u7b97\u6cd5\u4e0e\u7406\u8bba\u6846\u67b6\uff0c\u501f\u52a9\u6709\u9650\u72b6\u6001\u673a\u548c\u6709\u7406\u968f\u673a\u8bed\u8a00\u7684\u8868\u793a\uff0c\u91c7\u7528\u622a\u65ad+\u6709\u9650\u57df\u68c0\u9a8c\u6c42\u89e3\u95ee\u9898\uff0c\u6837\u672c\u590d\u6742\u5ea6\u83b7\u5f97\u7406\u8bba\u4fdd\u8bc1\uff0c\u5e76\u62d3\u5c55\u4e86\u5206\u5e03\u68c0\u9a8c\u7684\u5e94\u7528\u573a\u666f\u3002", "motivation": "\u4f20\u7edf\u5206\u5e03\u68c0\u9a8c\u4e3b\u8981\u96c6\u4e2d\u5728\u6709\u9650\u57df\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u5982\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u751f\u7269\u4fe1\u606f\u5b66\u548c\u7a0b\u5e8f\u5206\u6790\u7b49\u9886\u57df\u9700\u8981\u5bf9\u65e0\u9650\u7ec4\u5408\u7ed3\u6784\uff08\u5982\u5b57\u7b26\u4e32\uff09\u4e0a\u7684\u5206\u5e03\u8fdb\u884c\u68c0\u9a8c\uff0c\u56e0\u6b64\u8feb\u5207\u9700\u8981\u7406\u8bba\u4e0e\u65b9\u6cd5\u8fdb\u5c55\u3002", "method": "\u9996\u5148\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u6765\u9a8c\u8bc1\u6709\u9650\u72b6\u6001\u673a\u662f\u5426\u8868\u793a\u4e86\u968f\u673a\u8bed\u8a00\uff1b\u63a5\u7740\u8bc1\u660e\u6709\u7406\u968f\u673a\u8bed\u8a00\u80fd\u591f\u903c\u8fd1\u4efb\u610f\u6982\u7387\u5206\u5e03\uff1b\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u53d1\u5c55\u4e86\u57fa\u4e8e\u622a\u65ad\u7684\u6052\u7b49\u6027\u68c0\u9a8c\u7b97\u6cd5\uff0c\u5e76\u501f\u52a9\u968f\u673a\u8bed\u8a00\u7684\u6307\u6570\u8870\u51cf\u6027\u8d28\u6765\u63a7\u5236\u622a\u65ad\u8bef\u5dee\uff0c\u6700\u7ec8\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u6709\u9650\u57df\u4e0a\u7ecf\u5178\u68c0\u9a8c\u65b9\u6cd5\u53ef\u89e3\u3002", "result": "\u63d0\u51fa\u7684\u68c0\u9a8c\u7b97\u6cd5\u53ef\u4ee5\u4ee5$\\widetilde{\\Theta}(\\frac{\\sqrt{n}}{\\varepsilon^2} + \\frac{n}{\\log n})$\u7684\u6837\u672c\u590d\u6742\u5ea6\u5728\u5df2\u77e5\u4e0e\u672a\u77e5\u5206\u5e03\u4e4b\u95f4\u8fdb\u884c\u533a\u5206\uff0c\u8fd9\u91cc$n$\u662f\u622a\u65ad\u540e\u7684\u652f\u6301\u96c6\u5927\u5c0f\uff0c\u5e76\u7ed9\u51fa\u9996\u4e2a\u9002\u7528\u4e8e\u65e0\u9650\u79bb\u6563\u5206\u5e03\u7684\u6052\u7b49\u6027\u68c0\u9a8c\u7406\u8bba\u6846\u67b6\u3002", "conclusion": "\u8bba\u6587\u9996\u6b21\u5efa\u7acb\u4e86\u65e0\u9650\u79bb\u6563\u5206\u5e03\u7684\u6052\u7b49\u6027\u68c0\u9a8c\u7406\u8bba\u4f53\u7cfb\uff0c\u4e3a\u6982\u7387\u5f62\u5f0f\u5316\u65b9\u6cd5\u548c\u7ed3\u6784\u5316\u6570\u636e\u7684\u7edf\u8ba1\u5206\u6790\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.03830", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.03830", "abs": "https://arxiv.org/abs/2508.03830", "authors": ["Hanwen Guo", "Ben Greenman"], "title": "If-T: A Benchmark for Type Narrowing", "comment": null, "summary": "**Context:** The design of static type systems that can validate\ndynamically-typed programs (**gradually**) is an ongoing challenge. A key\ndifficulty is that dynamic code rarely follows datatype-driven design. Programs\ninstead use runtime tests to narrow down the proper usage of incoming data.\nType systems for dynamic languages thus need a **type narrowing** mechanism\nthat refines the type environment along individual control paths based on\ndominating tests, a form of flow-sensitive typing. In order to express\nrefinements, the type system must have some notion of sets and subsets. Since\nset-theoretic types are computationally and ergonomically complex, the need for\ntype narrowing raises design questions about how to balance precision and\nperformance. **Inquiry:** To date, the design of type narrowing systems has\nbeen driven by intuition, past experience, and examples from users in various\nlanguage communities. There is no standard that captures desirable and\nundesirable behaviors. Prior formalizations of narrowing are also significantly\nmore complex than a standard type system, and it is unclear how the extra\ncomplexity pays off in terms of concrete examples. This paper addresses the\nproblems through If-T, a language-agnostic **design benchmark** for type\nnarrowing that characterizes the abilities of implementations using simple\nprograms that draw attention to fundamental questions. Unlike a traditional\nperformance-focused benchmark, If-T measures a narrowing system's ability to\nvalidate correct code and reject incorrect code. Unlike a test suite, systems\nare not required to fully conform to If-T. Deviations are acceptable provided\nthey are justified by well-reasoned design considerations, such as compile-time\nperformance. **Approach:** If-T is guided by the literature on type narrowing,\nthe documentation of gradual languages such as TypeScript, and experiments with\ntypechecker implementations. We have identified a set of core technical\ndimensions for type narrowing. For each dimension, the benchmark contains a set\nof topics and (at least) two characterizing programs per topic: one that should\ntypecheck and one that should not typecheck. **Knowledge:** If-T provides a\nbaseline to measure type narrowing systems. For researchers, it provides\ncriteria to categorize future designs via its collection of positive and\nnegative examples. For language designers, the benchmark demonstrates the\npayoff of typechecker complexity in terms of concrete examples. Designers can\nuse the examples to decide whether supporting a particular example is\nworthwhile. Both the benchmark and its implementations are freely available\nonline. **Grounding:** We have implemented the benchmark for five typecheckers:\nTypeScript, Flow, Typed Racket, mypy, and Pyright. The results highlight\nimportant differences, such as the ability to track logical implications among\nprogram variables and typechecking for user-defined narrowing predicates.\n**Importance:** Type narrowing is essential for gradual type systems, but the\ntradeoffs between systems with different complexity have been unclear. If-T\nclarifies these tradeoffs by illustrating the benefits and limitations of each\nlevel of complexity. With If-T as a way to assess implementations in a fair,\ncross-language manner, future type system designs can strive for a better\nbalance among precision, annotation burden, and performance.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51faIf-T\u8fd9\u4e00\u65b0\u57fa\u51c6\uff0c\u7528\u4e8e\u7cfb\u7edf\u6027\u8bc4\u4f30\u548c\u6bd4\u8f83\u4e0d\u540c\u8bed\u8a00\u7c7b\u578b\u7f29\u7a84\u673a\u5236\u7684\u4f18\u7f3a\u70b9\uff0c\u5df2\u5e94\u7528\u4e8e\u591a\u79cd\u4e3b\u6d41\u7c7b\u578b\u68c0\u67e5\u5668\uff0c\u63ed\u793a\u4e86\u5b9e\u73b0\u4e0a\u7684\u6838\u5fc3\u5dee\u5f02\uff0c\u4e3a\u7c7b\u578b\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002", "motivation": "\u52a8\u6001\u8bed\u8a00\u7684\u9759\u6001\u7c7b\u578b\u7cfb\u7edf\u8bbe\u8ba1\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4ee3\u7801\u5e38\u901a\u8fc7\u8fd0\u884c\u65f6\u6d4b\u8bd5\u8fdb\u884c\u7c7b\u578b\u7f29\u7a84\uff0c\u9700\u6709\u7cbe\u7ec6\u7684\u7c7b\u578b\u7f29\u7a84\u673a\u5236\u3002\u76ee\u524d\u7c7b\u578b\u7f29\u7a84\u8bbe\u8ba1\u7f3a\u4e4f\u6807\u51c6\u8bc4\u4f30\uff0c\u4e14\u73b0\u6709\u5f62\u5f0f\u5316\u65b9\u6cd5\u590d\u6742\uff0c\u5b9e\u7528\u6027\u4e0d\u660e\u3002\u8be5\u7814\u7a76\u5e0c\u671b\u4e3a\u7c7b\u578b\u7f29\u7a84\u8bbe\u8ba1\u63d0\u4f9b\u7cfb\u7edf\u5316\u8bc4\u6d4b\u57fa\u51c6\u3002", "method": "\u63d0\u51faIf-T\uff0c\u4e00\u79cd\u8bed\u8a00\u65e0\u5173\u7684\u7c7b\u578b\u7f29\u7a84\u8bbe\u8ba1\u57fa\u51c6\uff0c\u901a\u8fc7\u6db5\u76d6\u5173\u952e\u6280\u672f\u7ef4\u5ea6\u548c\u5177\u4f53\u7528\u4f8b\uff0c\u5224\u65ad\u7c7b\u578b\u7f29\u7a84\u7cfb\u7edf\u5bf9\u6b63\u786e\u4e0e\u9519\u8bef\u4ee3\u7801\u7684\u8bc6\u522b\u80fd\u529b\u3002\u5e76\u5728TypeScript\u3001Flow\u3001Typed Racket\u3001mypy\u3001Pyright\u4e94\u4e2a\u7c7b\u578b\u68c0\u67e5\u5668\u4e0a\u5b9e\u65bd\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "If-T\u57fa\u51c6\u63ed\u793a\u4e86\u4e0d\u540c\u7c7b\u578b\u7cfb\u7edf\u5728\u5904\u7406\u7c7b\u578b\u7f29\u7a84\u65b9\u9762\u7684\u91cd\u8981\u5dee\u5f02\uff0c\u5305\u62ec\u53d8\u91cf\u95f4\u903b\u8f91\u5173\u7cfb\u8ffd\u8e2a\u548c\u7528\u6237\u81ea\u5b9a\u4e49\u7f29\u7a84\u8c13\u8bcd\u7684\u80fd\u529b\u3002\u7814\u7a76\u4e3a\u8bbe\u8ba1\u4eba\u5458\u63d0\u4f9b\u4e86\u8bc4\u4f30\u7c7b\u578b\u7cfb\u7edf\u590d\u6742\u5ea6\u6536\u76ca\u7684\u5177\u4f53\u4f8b\u8bc1\u3002", "conclusion": "If-T\u57fa\u51c6\u4e3a\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u7c7b\u578b\u7f29\u7a84\u7cfb\u7edf\u63d0\u4f9b\u4e86\u516c\u5e73\u3001\u8de8\u8bed\u8a00\u7684\u8bc4\u4f30\u5de5\u5177\uff0c\u5e2e\u52a9\u672a\u6765\u7c7b\u578b\u7cfb\u7edf\u5728\u7cbe\u5ea6\u3001\u6ce8\u89e3\u8d1f\u62c5\u4e0e\u6027\u80fd\u95f4\u66f4\u597d\u6743\u8861\uff0c\u63a8\u52a8\u6e10\u8fdb\u5f0f\u7c7b\u578b\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2508.03846", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03846", "abs": "https://arxiv.org/abs/2508.03846", "authors": ["Hashini Gunatilake", "John Grundy", "Rashina Hoda", "Ingo Mueller"], "title": "Empathy Guidelines for Improving Practitioner Well-being & Software Engineering Practices", "comment": null, "summary": "Empathy is a powerful yet often overlooked element in software engineering\n(SE), supporting better teamwork, smoother communication, and effective\ndecision-making. In our previous study, we identified a range of practitioner\nstrategies for fostering empathy in SE contexts. Building on these insights,\nthis paper introduces 17 actionable empathy guidelines designed to support\npractitioners, teams, and organisations. We also explore how these guidelines\ncan be implemented in practice by examining real-world applications,\nchallenges, and strategies to overcome them shared by software practitioners.\nTo support adoption, we present a visual prioritisation framework that\ncategorises the guidelines based on perceived importance, ease of\nimplementation, and willingness to adopt. The findings offer practical and\nflexible suggestions for integrating empathy into everyday SE work, helping\nteams move from principles to sustainable action.", "AI": {"tldr": "\u63d0\u51fa\u4e8617\u6761\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u540c\u7406\u5fc3\u6307\u5357\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u548c\u4f18\u5148\u7ea7\u6846\u67b6\uff0c\u5e2e\u52a9\u56e2\u961f\u6709\u6548\u843d\u5b9e\u540c\u7406\u5fc3\u5b9e\u8df5\u3002", "motivation": "\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\uff0c\u540c\u7406\u5fc3\u867d\u7136\u5bf9\u4e8e\u63d0\u5347\u56e2\u961f\u5408\u4f5c\u3001\u4ea4\u6d41\u4e0e\u51b3\u7b56\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u5f80\u5f80\u88ab\u5ffd\u89c6\u3002\u7814\u7a76\u52a8\u673a\u662f\u63d0\u5347\u540c\u7406\u5fc3\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u57fa\u4e8e\u4ee5\u5f80\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u63d0\u51fa\u4e8617\u6761\u53ef\u64cd\u4f5c\u7684\u540c\u7406\u5fc3\u6307\u5357\u3002\u901a\u8fc7\u5bf9\u8f6f\u4ef6\u4ece\u4e1a\u8005\u7684\u5b9e\u9645\u6848\u4f8b\u3001\u5e94\u7528\u96be\u70b9\u4e0e\u5e94\u5bf9\u7b56\u7565\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u5f15\u5165\u4e00\u4e2a\u53ef\u89c6\u5316\u4f18\u5148\u7ea7\u6846\u67b6\uff0c\u4ee5\u652f\u6301\u6307\u5357\u7684\u91c7\u7eb3\u4e0e\u5b9e\u65bd\u3002", "result": "\u5f62\u6210\u4e8617\u6761\u540c\u7406\u5fc3\u6307\u5357\uff0c\u901a\u8fc7\u4f18\u5148\u7ea7\u6846\u67b6\u5e2e\u52a9\u8f6f\u4ef6\u56e2\u961f\u6839\u636e\u91cd\u8981\u6027\u3001\u5b9e\u65bd\u96be\u5ea6\u548c\u91c7\u7eb3\u610f\u613f\u8fdb\u884c\u5206\u7c7b\uff0c\u63d0\u51fa\u4e86\u6574\u5408\u540c\u7406\u5fc3\u8fdb\u65e5\u5e38\u5de5\u4f5c\u7684\u5b9e\u9645\u548c\u7075\u6d3b\u5efa\u8bae\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u540c\u7406\u5fc3\u57f9\u517b\u63d0\u4f9b\u4e86\u4e00\u5957\u5177\u4f53\u3001\u53ef\u884c\u7684\u5b9e\u8df5\u6307\u5357\uff0c\u5e76\u901a\u8fc7\u4f18\u5148\u7ea7\u6846\u67b6\u8f85\u52a9\u5176\u5b9e\u8df5\uff0c\u5e2e\u52a9\u56e2\u961f\u548c\u7ec4\u7ec7\u5c06\u540c\u7406\u5fc3\u7406\u5ff5\u4ed8\u8bf8\u4e8e\u65e5\u5e38\u548c\u6301\u7eed\u7684\u884c\u52a8\u3002"}}
{"id": "2508.03712", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.03712", "abs": "https://arxiv.org/abs/2508.03712", "authors": ["Agrima Seth", "Monojit Choudhary", "Sunayana Sitaram", "Kentaro Toyama", "Aditya Vashistha", "Kalika Bali"], "title": "How Deep Is Representational Bias in LLMs? The Cases of Caste and Religion", "comment": "Accepted to AIES 2025", "summary": "Representational bias in large language models (LLMs) has predominantly been\nmeasured through single-response interactions and has focused on Global\nNorth-centric identities like race and gender. We expand on that research by\nconducting a systematic audit of GPT-4 Turbo to reveal how deeply encoded\nrepresentational biases are and how they extend to less-explored dimensions of\nidentity. We prompt GPT-4 Turbo to generate over 7,200 stories about\nsignificant life events (such as weddings) in India, using prompts designed to\nencourage diversity to varying extents. Comparing the diversity of religious\nand caste representation in the outputs against the actual population\ndistribution in India as recorded in census data, we quantify the presence and\n\"stickiness\" of representational bias in the LLM for religion and caste. We\nfind that GPT-4 responses consistently overrepresent culturally dominant groups\nfar beyond their statistical representation, despite prompts intended to\nencourage representational diversity. Our findings also suggest that\nrepresentational bias in LLMs has a winner-take-all quality that is more biased\nthan the likely distribution bias in their training data, and repeated\nprompt-based nudges have limited and inconsistent efficacy in dislodging these\nbiases. These results suggest that diversifying training data alone may not be\nsufficient to correct LLM bias, highlighting the need for more fundamental\nchanges in model development. Dataset and Codebook:\nhttps://github.com/agrimaseth/How-Deep-Is-Representational-Bias-in-LLMs", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0GPT-4 Turbo\u5728\u6709\u5173\u5370\u5ea6\u6545\u4e8b\u751f\u6210\u4e2d\uff0c\u5bf9\u5b97\u6559\u548c\u79cd\u59d3\u5c55\u73b0\u51fa\u4e25\u91cd\u4ee3\u8868\u6027\u504f\u89c1\uff0c\u4e3b\u8981\u504f\u5411\u4e3b\u5bfc\u7fa4\u4f53\uff0c\u73b0\u6709\u5229\u7528\u63d0\u793a\u8bcd\u7684\u591a\u6837\u6027\u9f13\u52b1\u624b\u6bb5\u96be\u4ee5\u6d88\u9664\u6b64\u504f\u89c1\uff0c\u4ec5\u4f9d\u9760\u589e\u52a0\u591a\u6837\u5316\u8bad\u7ec3\u6570\u636e\u4e0d\u80fd\u5b8c\u5168\u89e3\u51b3LLM\u504f\u89c1\u95ee\u9898\u3002", "motivation": "\u4ee5\u5f80\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4ee3\u8868\u6027\u504f\u89c1\u7684\u7814\u7a76\u96c6\u4e2d\u5728\u5355\u4e00\u56de\u590d\u4e14\u5173\u6ce8\u4e8e\u5317\u534a\u7403\u5982\u79cd\u65cf\u548c\u6027\u522b\u7b49\u8eab\u4efd\u7279\u5f81\u3002\u672c\u7814\u7a76\u610f\u5728\u63a2\u7a76\u8fd9\u4e9b\u504f\u89c1\u5728LLMs\u4e2d\u7684\u6df1\u5ea6\uff0c\u4ee5\u53ca\u5982\u4f55\u5ef6\u4f38\u81f3\u88ab\u8f83\u5c11\u5173\u6ce8\u7684\u8eab\u4efd\u7ef4\u5ea6\uff08\u5982\u5370\u5ea6\u7684\u5b97\u6559\u548c\u79cd\u59d3\uff09\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u5ba1\u67e5\uff0c\u5411GPT-4 Turbo\u63d0\u51fa7200\u591a\u6761\u4e0e\u5370\u5ea6\u91cd\u8981\u751f\u6d3b\u4e8b\u4ef6\u76f8\u5173\u7684\u6545\u4e8b\u751f\u6210\u8bf7\u6c42\uff0c\u4f7f\u7528\u4e0d\u540c\u7a0b\u5ea6\u9f13\u52b1\u591a\u6837\u6027\u7684\u63d0\u793a\u8bcd\uff0c\u7136\u540e\u5c06\u5176\u8f93\u51fa\u4e2d\u7684\u5b97\u6559\u548c\u79cd\u59d3\u591a\u6837\u6027\u4e0e\u5370\u5ea6\u4eba\u53e3\u666e\u67e5\u6570\u636e\u5bf9\u6bd4\uff0c\u91cf\u5316\u4ee3\u8868\u6027\u504f\u89c1\u53ca\u5176\u201c\u9ecf\u6027\u201d\u3002", "result": "GPT-4 Turbo\u5728\u5b97\u6559\u548c\u79cd\u59d3\u7684\u751f\u6210\u5185\u5bb9\u4e2d\u663e\u8457\u8fc7\u5ea6\u4ee3\u8868\u4e86\u6587\u5316\u4e3b\u5bfc\u7fa4\u4f53\uff0c\u5373\u4f7f\u5728\u8f93\u5165\u63d0\u5021\u591a\u6837\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u7fa4\u4f53\u5206\u5e03\u8fdc\u8d85\u771f\u5b9e\u4eba\u53e3\u6bd4\u4f8b\u3002\u91cd\u590d\u6027\u63d0\u793a\u8c03\u6574\u5bf9\u504f\u89c1\u7684\u6d88\u51cf\u6548\u679c\u6709\u9650\u4e14\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u4ec5\u4ec5\u589e\u52a0\u591a\u6837\u5316\u8bad\u7ec3\u6570\u636e\u53ef\u80fd\u4e0d\u8db3\u4ee5\u7ea0\u6b63LLMs\u4ee3\u8868\u6027\u504f\u89c1\uff0c\u6a21\u578b\u5f00\u53d1\u9700\u8fdb\u884c\u66f4\u6839\u672c\u6027\u7684\u53d8\u9769\u3002"}}
{"id": "2508.04458", "categories": ["cs.FL"], "pdf": "https://arxiv.org/pdf/2508.04458", "abs": "https://arxiv.org/abs/2508.04458", "authors": ["Hiroya Fujinami", "Masaki Waga", "Jie An", "Kohei Suenaga", "Nayuta Yanagisawa", "Hiroki Iseri", "Ichiro Hasuo"], "title": "Componentwise Automata Learning for System Integration (Extended Version)", "comment": null, "summary": "Compositional automata learning is attracting attention as an analysis\ntechnique for complex black-box systems. It exploits a target system's internal\ncompositional structure to reduce complexity. In this paper, we identify system\nintegration -- the process of building a new system as a composite of\npotentially third-party and black-box components -- as a new application domain\nof compositional automata learning. Accordingly, we propose a new problem\nsetting, where the learner has direct access to black-box components. This is\nin contrast with the usual problem settings of compositional learning, where\nthe target is a legacy black-box system and queries can only be made to the\nwhole system (but not to components). We call our problem componentwise\nautomata learning for distinction. We identify a challenge there called\ncomponent redundancies: some parts of components may not contribute to\nsystem-level behaviors, and learning them incurs unnecessary effort. We\nintroduce a contextual componentwise learning algorithm that systematically\nremoves such redundancies. We experimentally evaluate our proposal and show its\npractical relevance.", "AI": {"tldr": "\u672c\u6587\u521b\u65b0\u6027\u5730\u63d0\u51fa\u4e86\u53ef\u76f4\u63a5\u8bbf\u95ee\u7ec4\u4ef6\u7684\u65b0\u578b\u81ea\u52a8\u673a\u5b66\u4e60\u95ee\u9898\u8bbe\u5b9a\uff0c\u5e76\u9488\u5bf9\u7ec4\u4ef6\u5197\u4f59\u95ee\u9898\u7ed9\u51fa\u4e86\u89e3\u51b3\u7b97\u6cd5\uff0c\u7ecf\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5177\u5907\u5b9e\u9645\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u7ec4\u5408\u5f0f\u81ea\u52a8\u673a\u5b66\u4e60\u901a\u5e38\u53ea\u5141\u8bb8\u5bf9\u6574\u4e2a\u9ed1\u76d2\u7cfb\u7edf\u8fdb\u884c\u67e5\u8be2\uff0c\u65e0\u6cd5\u76f4\u63a5\u8bbf\u95ee\u548c\u5229\u7528\u7cfb\u7edf\u5185\u90e8\u7684\u7ec4\u4ef6\u4fe1\u606f\u3002\u968f\u7740\u8d8a\u6765\u8d8a\u591a\u7cfb\u7edf\u7531\u7b2c\u4e09\u65b9\u548c\u9ed1\u76d2\u7ec4\u4ef6\u7ec4\u5408\u96c6\u6210\uff0c\u5982\u4f55\u5728\u7cfb\u7edf\u96c6\u6210\u573a\u666f\u4e2d\u9ad8\u6548\u5b66\u4e60\u7cfb\u7edf\u884c\u4e3a\u6210\u4e3a\u4e9f\u9700\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u95ee\u9898\u8bbe\u5b9a\u2014\u2014\u201c\u57fa\u4e8e\u7ec4\u4ef6\u7684\u81ea\u52a8\u673a\u5b66\u4e60\u201d\uff0c\u5373\u5b66\u4e60\u8005\u80fd\u591f\u76f4\u63a5\u8bbf\u95ee\u5404\u9ed1\u76d2\u7ec4\u4ef6\u3002\u5e76\u9488\u5bf9\u7ec4\u4ef6\u5197\u4f59\uff08\u5373\u6709\u4e9b\u7ec4\u4ef6\u90e8\u5206\u5bf9\u7cfb\u7edf\u884c\u4e3a\u65e0\u8d21\u732e\uff09\u96be\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u57fa\u4e8e\u7ec4\u4ef6\u7684\u5b66\u4e60\u7b97\u6cd5\u6765\u81ea\u52a8\u6d88\u9664\u8fd9\u7c7b\u5197\u4f59\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u7b97\u6cd5\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u8bc1\u660e\u5176\u5728\u53bb\u9664\u5197\u4f59\u548c\u63d0\u5347\u5b66\u4e60\u6548\u7387\u4e0a\u7684\u6709\u6548\u6027\u4e0e\u5b9e\u7528\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u7ec4\u4ef6\u7684\u81ea\u52a8\u673a\u5b66\u4e60\u548c\u5197\u4f59\u6d88\u9664\u65b0\u7b97\u6cd5\uff0c\u6709\u6548\u6269\u5c55\u4e86\u7ec4\u5408\u5f0f\u81ea\u52a8\u673a\u5b66\u4e60\u5728\u7cfb\u7edf\u96c6\u6210\u9886\u57df\u7684\u9002\u7528\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2508.03831", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.03831", "abs": "https://arxiv.org/abs/2508.03831", "authors": ["Chinmayi Prabhu Baramashetru", "Paola Giannini", "Silvia Lizeth Tapia Tarifa", "Olaf Owe"], "title": "A Type System for Data Privacy Compliance in Active Object Languages", "comment": null, "summary": "Data protection laws such as GDPR aim to give users unprecedented control\nover their personal data. Compliance with these regulations requires\nsystematically considering information flow and interactions among entities\nhandling sensitive data. Privacy-by-design principles advocate embedding data\nprotection into system architectures as a default. However, translating these\nabstract principles into concrete, explicit methods remains a significant\nchallenge. This paper addresses this gap by proposing a language-based approach\nto privacy integration, combining static and runtime techniques. By employing\ntype checking and type inference in an active object language, the framework\nenables the tracking of authorised data flows and the automatic generation of\nconstraints checked at runtime based on user consent. This ensures that\npersonal data is processed in compliance with GDPR constraints. The key\ncontribution of this work is a type system that gather the compliance checks\nand the changes to users consent and integrates data privacy compliance\nverification into system execution. The paper demonstrates the feasibility of\nthis approach through a soundness proof and several examples, illustrating how\nthe proposed language addresses common GDPR requirements, such as user consent,\npurpose limitation, and data subject rights. This work advances the state of\nthe art in privacy-aware system design by offering a systematic and automated\nmethod for integrating GDPR compliance into programming languages. This\ncapability has implications for building trustworthy systems in domains such as\nhealthcare or finance, where data privacy is crucial.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u9759\u6001\u4e0e\u8fd0\u884c\u65f6\u6280\u672f\u7684\u7f16\u7a0b\u8bed\u8a00\u7c7b\u578b\u7cfb\u7edf\uff0c\u81ea\u52a8\u8ffd\u8e2a\u548c\u68c0\u67e5\u7528\u6237\u6570\u636e\u6d41\uff0c\u786e\u4fddGDPR\u5408\u89c4\u3002\u901a\u8fc7\u5b9e\u4f8b\u548c\u7406\u8bba\u8bc1\u660e\u5c55\u793a\u5176\u5728\u7528\u6237\u540c\u610f\u3001\u7528\u9014\u9650\u5236\u7b49\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u6709\u52a9\u4e8e\u81ea\u52a8\u5316\u5f00\u53d1\u9690\u79c1\u5408\u89c4\u7cfb\u7edf\u3002", "motivation": "\u5c3d\u7ba1GDPR\u7b49\u6570\u636e\u4fdd\u62a4\u6cd5\u89c4\u9f13\u52b1\u5f00\u53d1\u8005\u5728\u7cfb\u7edf\u67b6\u6784\u4e2d\u9ed8\u8ba4\u878d\u5165\u9690\u79c1\u4fdd\u62a4\uff08\u5373\u9690\u79c1\u8bbe\u8ba1\u539f\u5219\uff09\uff0c\u4f46\u73b0\u6709\u4ece\u62bd\u8c61\u539f\u5219\u5230\u5177\u4f53\u3001\u53ef\u6267\u884c\u65b9\u6cd5\u7684\u8f6c\u5316\u4ecd\u9762\u4e34\u5de8\u5927\u6311\u6218\u3002\u672c\u6587\u65e8\u5728\u5f25\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5bfb\u6c42\u7cfb\u7edf\u6027\u3001\u81ea\u52a8\u5316\u7684\u5408\u89c4\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7f16\u7a0b\u8bed\u8a00\u7684\u9690\u79c1\u96c6\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408\u9759\u6001\u548c\u8fd0\u884c\u65f6\u6280\u672f\uff0c\u901a\u8fc7\u5728\u4e3b\u52a8\u5bf9\u8c61\u8bed\u8a00\u4e2d\u91c7\u7528\u7c7b\u578b\u68c0\u67e5\u548c\u7c7b\u578b\u63a8\u5bfc\uff0c\u5b9e\u73b0\u4e86\u5bf9\u6388\u6743\u6570\u636e\u6d41\u7684\u8ddf\u8e2a\uff0c\u5e76\u57fa\u4e8e\u7528\u6237\u540c\u610f\u81ea\u52a8\u751f\u6210\u8fd0\u884c\u65f6\u7ea6\u675f\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u7c7b\u578b\u7cfb\u7edf\u5c06\u5408\u89c4\u68c0\u67e5\u548c\u7528\u6237\u540c\u610f\u7684\u52a8\u6001\u53d8\u5316\u6574\u5408\u8fdb\u7cfb\u7edf\u7684\u5b9e\u9645\u8fd0\u884c\u4e2d\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u5957\u7c7b\u578b\u7cfb\u7edf\uff0c\u5c06\u9690\u79c1\u5408\u89c4\u6027\u68c0\u67e5\u878d\u5165\u7cfb\u7edf\u6267\u884c\u6d41\u7a0b\uff0c\u5b9e\u73b0\u4e86\u5bf9GDPR\u5177\u4f53\u8981\u6c42\uff08\u5982\u7528\u6237\u540c\u610f\u3001\u7528\u9014\u9650\u5236\u548c\u6570\u636e\u4e3b\u4f53\u6743\u5229\uff09\u7684\u652f\u6301\u3002\u901a\u8fc7\u5f62\u5f0f\u5316\u8bc1\u660e\u548c\u591a\u4e2a\u5b9e\u4f8b\uff0c\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u548c\u9002\u7528\u6027\u3002", "conclusion": "\u672c\u65b9\u6cd5\u4e3a\u9690\u79c1\u53cb\u597d\u578b\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u5316\u3001\u81ea\u52a8\u5316\u7684GDPR\u5408\u89c4\u96c6\u6210\u624b\u6bb5\uff0c\u63a8\u52a8\u4e86\u4fe1\u4efb\u7cfb\u7edf\u6784\u5efa\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5bf9\u6570\u636e\u9690\u79c1\u8981\u6c42\u9ad8\u7684\u9886\u57df\uff08\u5982\u533b\u7597\u3001\u91d1\u878d\uff09\u3002"}}
{"id": "2508.03856", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.03856", "abs": "https://arxiv.org/abs/2508.03856", "authors": ["Richard Hegewald", "Rebecca Beyer"], "title": "Evaluating Software Supply Chain Security in Research Software", "comment": "Accepted at conference GI SKILL 2025", "summary": "The security of research software is essential for ensuring the integrity and\nreproducibility of scientific results. However, research software security is\nstill largely unexplored. Due to its dependence on open source components and\ndistributed development practices, research software is particularly vulnerable\nto supply chain attacks. This study analyses 3,248 high-quality, largely\npeer-reviewed research software repositories using the OpenSSF Scorecard. We\nfind a generally weak security posture with an average score of 3.5/10.\nImportant practices, such as signed releases and branch protection, are rarely\nimplemented. Finally, we present actionable, low-effort recommendations that\ncan help research teams improve software security and mitigate potential\nthreats to scientific integrity.", "AI": {"tldr": "\u79d1\u7814\u8f6f\u4ef6\u5b89\u5168\u666e\u904d\u8584\u5f31\uff0c\u6613\u53d7\u4f9b\u5e94\u94fe\u653b\u51fb\uff0c\u5efa\u8bae\u91c7\u53d6\u7b80\u5355\u53ef\u884c\u7684\u6539\u8fdb\u63aa\u65bd\u4ee5\u63d0\u5347\u5b89\u5168\u6c34\u5e73\u3002", "motivation": "\u79d1\u7814\u8f6f\u4ef6\u7684\u5b89\u5168\u6027\u5bf9\u4e8e\u786e\u4fdd\u79d1\u5b66\u7ed3\u679c\u7684\u5b8c\u6574\u6027\u548c\u53ef\u590d\u73b0\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8be5\u9886\u57df\u7684\u5b89\u5168\u6027\u7814\u7a76\u4ecd\u7136\u4e0d\u8db3\u3002\u7279\u522b\u662f\u7531\u4e8e\u5176\u4f9d\u8d56\u5f00\u6e90\u7ec4\u4ef6\u548c\u5206\u5e03\u5f0f\u5f00\u53d1\u5b9e\u8df5\uff0c\u79d1\u7814\u8f6f\u4ef6\u5728\u4f9b\u5e94\u94fe\u653b\u51fb\u9762\u524d\u5c24\u4e3a\u8106\u5f31\u3002", "method": "\u672c\u7814\u7a76\u5229\u7528OpenSSF Scorecard\uff0c\u5bf93,248\u4e2a\u9ad8\u8d28\u91cf\u3001\u4e3b\u8981\u7ecf\u8fc7\u540c\u884c\u8bc4\u5ba1\u7684\u79d1\u7814\u8f6f\u4ef6\u4ee3\u7801\u5e93\u8fdb\u884c\u4e86\u5b89\u5168\u6027\u5206\u6790\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u8fd9\u4e9b\u4ee3\u7801\u5e93\u7684\u6574\u4f53\u5b89\u5168\u72b6\u51b5\u8f83\u5f31\uff0c\u5e73\u5747\u5f97\u5206\u4e3a3.5/10\u3002\u5176\u4e2d\uff0c\u8bf8\u5982\u7b7e\u540d\u53d1\u5e03\u548c\u5206\u652f\u4fdd\u62a4\u7b49\u91cd\u8981\u7684\u5b89\u5168\u5b9e\u8df5\u5f88\u5c11\u88ab\u5b9e\u65bd\u3002", "conclusion": "\u79d1\u7814\u8f6f\u4ef6\u5f53\u524d\u7684\u5b89\u5168\u63aa\u65bd\u4e0d\u8db3\uff0c\u5b58\u5728\u8f83\u5927\u98ce\u9669\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u53ef\u64cd\u4f5c\u3001\u4f4e\u6210\u672c\u7684\u5efa\u8bae\uff0c\u5e2e\u52a9\u79d1\u7814\u56e2\u961f\u63d0\u5347\u8f6f\u4ef6\u5b89\u5168\u6027\u5e76\u4fdd\u62a4\u79d1\u5b66\u8bda\u4fe1\u3002"}}
{"id": "2508.03716", "categories": ["cs.CL", "cs.LG", "hep-th"], "pdf": "https://arxiv.org/pdf/2508.03716", "abs": "https://arxiv.org/abs/2508.03716", "authors": ["Paul Richmond", "Prarit Agarwal", "Borun Chowdhury", "Vasilis Niarchos", "Constantinos Papageorgakis"], "title": "FeynTune: Large Language Models for High-Energy Theory", "comment": "16 pages", "summary": "We present specialized Large Language Models for theoretical High-Energy\nPhysics, obtained as 20 fine-tuned variants of the 8-billion parameter\nLlama-3.1 model. Each variant was trained on arXiv abstracts (through August\n2024) from different combinations of hep-th, hep-ph and gr-qc. For a\ncomparative study, we also trained models on datasets that contained abstracts\nfrom disparate fields such as the q-bio and cs categories. All models were\nfine-tuned using two distinct Low-Rank Adaptation fine-tuning approaches and\nvarying dataset sizes, and outperformed the base model on hep-th abstract\ncompletion tasks. We compare performance against leading commercial LLMs\n(ChatGPT, Claude, Gemini, DeepSeek) and derive insights for further developing\nspecialized language models for High-Energy Theoretical Physics.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u9ad8\u80fd\u7406\u8bba\u7269\u7406\u7814\u53d1\u4e8620\u79cdLlama-3.1\u6a21\u578b\u5fae\u8c03\u53d8\u4f53\uff0c\u5747\u5728\u9886\u57df\u4efb\u52a1\u4e0a\u8d85\u8d8a\u57fa\u7840\u6a21\u578b\uff0c\u5e76\u4e0e\u5e02\u9762\u4e3b\u6d41LLM\u8fdb\u884c\u4e86\u6027\u80fd\u5bf9\u6bd4\uff0c\u603b\u7ed3\u4e86\u9762\u5411\u5c0f\u4f17\u5b66\u672f\u9886\u57df\u5b9a\u5236\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7ecf\u9a8c\u3002", "motivation": "\u9ad8\u80fd\u7406\u8bba\u7269\u7406\u9886\u57df\u9700\u8981\u66f4\u4e13\u4e1a\u548c\u8868\u73b0\u4f18\u79c0\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u76ee\u524d\u901a\u7528\u5927\u6a21\u578b\u96be\u4ee5\u5e94\u5bf9\u8be5\u9886\u57df\u7684\u7279\u5b9a\u4efb\u52a1\u3002", "method": "\u5bf98B\u53c2\u6570\u7684Llama-3.1\u6a21\u578b\u8fdb\u884c\u4e86\u7ec6\u81f4\u5fae\u8c03\uff0c\u4ea7\u751f\u4e8620\u4e2a\u53d8\u4f53\uff0c\u5206\u522b\u5728\u9ad8\u80fd\u7269\u7406\u7684hep-th\u3001hep-ph\u3001gr-qc\u7b49\u4e0d\u540c\u5b50\u9886\u57dfarXiv\u6458\u8981\u6570\u636e\u4e0a\u8bad\u7ec3\u3002\u540c\u65f6\u5bf9\u6bd4\u4e86\u5305\u62ec\u751f\u7269\u3001\u8ba1\u7b97\u673a\u7b49\u4ea4\u53c9\u9886\u57df\u6458\u8981\u4e0a\u7684\u6548\u679c\uff1b\u91c7\u7528\u4e24\u79cd\u4e0d\u540c\u7684\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u5fae\u8c03\u65b9\u6cd5\u548c\u4e0d\u540c\u6570\u636e\u96c6\u89c4\u6a21\u3002", "result": "\u6240\u6709\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5728\u9ad8\u80fd\u7406\u8bba\u7269\u7406\uff08hep-th\uff09\u6458\u8981\u8865\u5168\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u57fa\u7840Llama-3.1\u6a21\u578b\u3002", "conclusion": "\u4e13\u95e8\u9762\u5411\u9ad8\u80fd\u7406\u8bba\u7269\u7406\u9886\u57df\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u5b9a\u5236\u5fae\u8c03\uff0c\u53ef\u663e\u8457\u63d0\u5347\u8be5\u9886\u57df\u7684\u5b66\u672f\u6587\u672c\u751f\u6210\u8868\u73b0\uff0c\u5e76\u4e3a\u540e\u7eed\u4e13\u7528\u6a21\u578b\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u5f00\u53d1\u601d\u8def\u3002"}}
{"id": "2508.03832", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.03832", "abs": "https://arxiv.org/abs/2508.03832", "authors": ["Andreas Pointner", "Josef Pichler", "Herbert Pr\u00e4hofer"], "title": "Generating Inputs for Grammar Mining using Dynamic Symbolic Execution", "comment": null, "summary": "A vast number of software systems include components that parse and process\nstructured input. In addition to programming languages, which are analyzed by\ncompilers or interpreters, there are numerous components that process\nstandardized or proprietary data formats of varying complexity. Even if such\ncomponents were initially developed and tested based on a specification, such\nas a grammar, numerous modifications and adaptations over the course of\nsoftware evolution can make it impossible to precisely determine which inputs\nthey actually accept. In this situation, grammar mining can be used to\nreconstruct the specification in the form of a grammar. Established approaches\nalready produce useful results, provided that sufficient input data is\navailable to fully cover the input language. However, achieving this\ncompleteness is a major challenge. In practice, only input data recorded during\nthe operation of the software systems is available. If this data is used for\ngrammar mining, the resulting grammar reflects only the actual processed inputs\nbut not the complete grammar of the input language accepted by the software\ncomponent. As a result, edge cases or previously supported features that no\nlonger appear in the available input data are missing from the generated\ngrammar. This work addresses this challenge by introducing a novel approach for\nthe automatic generation of inputs for grammar mining. Although input\ngenerators have already been used for fuzz testing, it remains unclear whether\nthey are also suitable for grammar miners. Building on the grammar miner Mimid,\nthis work presents a fully automated approach to input generation. The approach\nleverages Dynamic Symbolic Execution (DSE) and extends it with two mechanisms\nto overcome the limitations of DSE regarding structured input parsers. First,\nthe search for new inputs is guided by an iterative expansion that starts with\na single-character input and gradually extends it. Second, input generation is\nstructured into a novel three-phase approach, which separates the generation of\ninputs for parser functions. The proposed method was evaluated against a\ndiverse set of eleven benchmark applications from the existing literature.\nResults demonstrate that the approach achieves precision and recall for\nextracted grammars close to those derived from state-of-the-art grammar miners\nsuch as Mimid. Notably, it successfully uncovers subtle features and edge cases\nin parsers that are typically missed by such grammar miners. The effectiveness\nof the method is supported by empirical evidence, showing that it can achieve\nhigh performance in various domains without requiring prior input samples. This\ncontribution is significant for researchers and practitioners in software\nengineering, offering an automated, scalable, and precise solution for grammar\nmining. By eliminating the need for manual input generation, the approach not\nonly reduces workload but also enhances the robustness and comprehensiveness of\nthe extracted grammars. Following this approach, software engineers can\nreconstruct specification from existing (legacy) parsers.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u52a8\u6001\u7b26\u53f7\u6267\u884c\u548c\u591a\u9636\u6bb5\u8f93\u5165\u751f\u6210\u7684\u65b0\u6587\u6cd5\u6316\u6398\u65b9\u6cd5\uff0c\u80fd\u9ad8\u6548\u81ea\u52a8\u53d1\u73b0\u8f6f\u4ef6\u89e3\u6790\u5668\u7684\u5b8c\u6574\u8f93\u5165\u89c4\u8303\uff0c\u5728\u8986\u76d6\u8fb9\u7f18\u7279\u6027\u548c\u63d0\u5347\u81ea\u52a8\u5316\u7a0b\u5ea6\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f88\u591a\u8f6f\u4ef6\u9700\u8981\u89e3\u6790\u548c\u5904\u7406\u7ed3\u6784\u5316\u8f93\u5165\uff0c\u4f46\u7531\u4e8e\u957f\u671f\u6f14\u5316\u548c\u4fee\u6539\uff0c\u8f93\u5165\u7ec4\u4ef6\u5b9e\u9645\u63a5\u53d7\u7684\u8f93\u5165\u5f80\u5f80\u96be\u4ee5\u754c\u5b9a\u3002\u5df2\u6709\u7684\u6587\u6cd5\u6316\u6398\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5168\u9762\u7684\u8f93\u5165\u6837\u672c\uff0c\u800c\u5b9e\u9645\u5f55\u5236\u7684\u6570\u636e\u5f80\u5f80\u8986\u76d6\u6709\u9650\uff0c\u65e0\u6cd5\u5f97\u5230\u5b8c\u6574\u7684\u8f93\u5165\u6587\u6cd5\uff0c\u5bfc\u81f4\u8fb9\u7f18\u60c5\u51b5\u548c\u65e7\u7279\u6027\u88ab\u5ffd\u7565\u3002\u89e3\u51b3\u5982\u4f55\u81ea\u52a8\u8865\u9f50\u8f93\u5165\u6570\u636e\u3001\u63d0\u5347\u6587\u6cd5\u6316\u6398\u8986\u76d6\u7387\u662f\u672c\u7814\u7a76\u52a8\u673a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u8f93\u5165\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u6587\u6cd5\u6316\u6398\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8eDynamic Symbolic Execution (DSE)\uff0c\u5e76\u5f15\u5165\u4e24\u5927\u673a\u5236\uff1a\u4e00\u662f\u901a\u8fc7\u8fed\u4ee3\u5f0f\u6269\u5c55\u4ece\u5355\u5b57\u7b26\u5f00\u59cb\u9010\u6b65\u751f\u6210\u66f4\u590d\u6742\u7684\u8f93\u5165\uff1b\u4e8c\u662f\u91c7\u7528\u4e09\u9636\u6bb5\u521b\u65b0\u7ed3\u6784\u5c06\u89e3\u6790\u5668\u51fd\u6570\u7684\u8f93\u5165\u751f\u6210\u6b65\u9aa4\u5206\u79bb\u3002\u65b9\u6cd5\u5728Mimid\uff08\u73b0\u6709\u6587\u6cd5\u6316\u6398\u5de5\u5177\uff09\u4e4b\u4e0a\u8fdb\u884c\u4e86\u6269\u5c55\u3002", "result": "\u572811\u4e2a\u57fa\u51c6\u5e94\u7528\u4e0a\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u63d0\u53d6\u7684\u6587\u6cd5\u5728\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u65b9\u9762\u63a5\u8fd1\u751a\u81f3\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684Mimid\u3002\u5c24\u5176\u662f\u5728\u8bc6\u522b\u89e3\u6790\u5668\u4e2d\u7684\u7ec6\u5fae\u7279\u6027\u548c\u8fb9\u7f18\u60c5\u51b5\uff08\u5e38\u89c4\u65b9\u6cd5\u7ecf\u5e38\u9057\u6f0f\uff09\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002\u5b9e\u9a8c\u8fd8\u8868\u660e\u65b9\u6cd5\u65e0\u9700\u9884\u5148\u8f93\u5165\u6837\u672c\uff0c\u5177\u5907\u81ea\u52a8\u5316\u3001\u9ad8\u6548\u548c\u5e7f\u6cdb\u9002\u7528\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u7814\u7a76\u8005\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u4e00\u5957\u81ea\u52a8\u3001\u53ef\u6269\u5c55\u4e14\u7cbe\u786e\u7684\u6587\u6cd5\u6316\u6398\u89e3\u51b3\u65b9\u6848\u3002\u5b83\u6709\u6548\u51cf\u8f7b\u4e86\u4eba\u5de5\u751f\u6210\u8f93\u5165\u6837\u672c\u7684\u8d1f\u62c5\uff0c\u540c\u65f6\u63d0\u5347\u4e86\u63d0\u53d6\u7ed3\u679c\u7684\u5065\u58ee\u6027\u548c\u5b8c\u6574\u6027\uff0c\u4e3a\u73b0\u6709\u6216\u9057\u7559\u7cfb\u7edf\u7684\u8f93\u5165\u89c4\u8303\u91cd\u5efa\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2508.03881", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03881", "abs": "https://arxiv.org/abs/2508.03881", "authors": ["Martin Obaidi", "Kushtrim Qengaj", "Jakob Droste", "Hannah Deters", "Marc Herrmann", "Jil Kl\u00fcnder", "Elisa Schmid", "Kurt Schneider"], "title": "From App Features to Explanation Needs: Analyzing Correlations and Predictive Potential", "comment": "This paper has been accepted at the 33rd IEEE International\n  Requirements Engineering Workshop (REW 2025)", "summary": "In today's digitized world, software systems must support users in\nunderstanding both how to interact with a system and why certain behaviors\noccur. This study investigates whether explanation needs, classified from user\nreviews, can be predicted based on app properties, enabling early consideration\nduring development and large-scale requirements mining. We analyzed a gold\nstandard dataset of 4,495 app reviews enriched with metadata (e.g., app\nversion, ratings, age restriction, in-app purchases). Correlation analyses\nidentified mostly weak associations between app properties and explanation\nneeds, with moderate correlations only for specific features such as app\nversion, number of reviews, and star ratings. Linear regression models showed\nlimited predictive power, with no reliable forecasts across configurations.\nValidation on a manually labeled dataset of 495 reviews confirmed these\nfindings. Categories such as Security & Privacy and System Behavior showed\nslightly higher predictive potential, while Interaction and User Interface\nremained most difficult to predict. Overall, our results highlight that\nexplanation needs are highly context-dependent and cannot be precisely inferred\nfrom app metadata alone. Developers and requirements engineers should therefore\nsupplement metadata analysis with direct user feedback to effectively design\nexplainable and user-centered software systems.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\uff0c\u4ec5\u51ed\u5e94\u7528\u5143\u6570\u636e\u96be\u4ee5\u51c6\u786e\u9884\u6d4b\u7528\u6237\u7684\u89e3\u91ca\u9700\u6c42\uff0c\u5efa\u8bae\u5f00\u53d1\u8005\u7ed3\u5408\u5143\u6570\u636e\u4e0e\u7528\u6237\u53cd\u9988\u5171\u540c\u6307\u5bfc\u7cfb\u7edf\u8bbe\u8ba1\u3002", "motivation": "\u73b0\u4ee3\u6570\u5b57\u5316\u73af\u5883\u4e0b\uff0c\u8f6f\u4ef6\u7cfb\u7edf\u9700\u8981\u652f\u6301\u7528\u6237\u7406\u89e3\u7cfb\u7edf\u4ea4\u4e92\u65b9\u5f0f\u53ca\u5176\u884c\u4e3a\u80cc\u540e\u7684\u539f\u56e0\u3002\u4e3a\u63d0\u5347\u8f6f\u4ef6\u5f00\u53d1\u548c\u9700\u6c42\u5de5\u7a0b\u6548\u7387\uff0c\u7814\u7a76\u5982\u4f55\u57fa\u4e8e\u5e94\u7528\u5c5e\u6027\u9884\u6d4b\u7528\u6237\u7684\u89e3\u91ca\u9700\u6c42\uff0c\u4ece\u800c\u5728\u5f00\u53d1\u65e9\u671f\u6216\u5927\u89c4\u6a21\u9700\u6c42\u6316\u6398\u4e2d\u52a0\u4ee5\u8003\u8651\u3002", "method": "\u5206\u6790\u5305\u542b4,495\u6761\u5e94\u7528\u8bc4\u8bba\u53ca\u76f8\u5173\u5143\u6570\u636e\uff08\u91d1\u6807\u51c6\u6570\u636e\u96c6\uff09\uff0c\u901a\u8fc7\u76f8\u5173\u6027\u5206\u6790\u53ca\u7ebf\u6027\u56de\u5f52\u6a21\u578b\uff0c\u63a2\u7d22\u5e94\u7528\u5c5e\u6027\u4e0e\u7528\u6237\u89e3\u91ca\u9700\u6c42\u4e4b\u95f4\u7684\u5173\u7cfb\u53ca\u5176\u53ef\u9884\u6d4b\u6027\u3002\u5e76\u7528495\u6761\u4eba\u5de5\u6807\u6ce8\u7684\u6570\u636e\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5e94\u7528\u5c5e\u6027\u4e0e\u89e3\u91ca\u9700\u6c42\u5927\u591a\u4ec5\u5448\u5f31\u76f8\u5173\uff0c\u90e8\u5206\u7279\u6027\u5982\u7248\u672c\u3001\u8bc4\u8bba\u6570\u3001\u8bc4\u5206\u5b58\u5728\u4e2d\u7b49\u76f8\u5173\u6027\u3002\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u9884\u6d4b\u80fd\u529b\u6709\u9650\uff0c\u96be\u4ee5\u505a\u51fa\u53ef\u9760\u9884\u6d4b\u3002\u5728\u9a8c\u8bc1\u6570\u636e\u96c6\u4e0a\u4e5f\u5f97\u5230\u76f8\u540c\u7ed3\u679c\u3002\u5c11\u6570\u7c7b\u522b\uff08\u5982\u5b89\u5168\u4e0e\u9690\u79c1\u3001\u7cfb\u7edf\u884c\u4e3a\uff09\u53ef\u7a0d\u597d\u9884\u6d4b\uff0c\u7528\u6237\u4ea4\u4e92\u548c\u754c\u9762\u9700\u6c42\u6700\u96be\u9884\u6d4b\u3002", "conclusion": "\u89e3\u91ca\u9700\u6c42\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u5177\u4f53\u4e0a\u4e0b\u6587\uff0c\u65e0\u6cd5\u4ec5\u901a\u8fc7\u5e94\u7528\u5143\u6570\u636e\u7cbe\u786e\u63a8\u65ad\u3002\u5f00\u53d1\u8005\u548c\u9700\u6c42\u5de5\u7a0b\u5e08\u5e94\u7ed3\u5408\u76f4\u63a5\u7528\u6237\u53cd\u9988\uff0c\u624d\u80fd\u6709\u6548\u8bbe\u8ba1\u53ef\u89e3\u91ca\u3001\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u8f6f\u4ef6\u7cfb\u7edf\u3002"}}
{"id": "2508.03719", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03719", "abs": "https://arxiv.org/abs/2508.03719", "authors": ["Abhay Vijayvargia", "Ajay Nagpal", "Kundeshwar Pundalik", "Atharva Savarkar", "Smita Gautam", "Pankaj Singh", "Rohit Saluja", "Ganesh Ramakrishnan"], "title": "Intent Aware Context Retrieval for Multi-Turn Agricultural Question Answering", "comment": null, "summary": "Indian farmers often lack timely, accessible, and language-friendly\nagricultural advice, especially in rural areas with low literacy. To address\nthis gap in accessibility, this paper presents a novel AI-powered agricultural\nchatbot, Krishi Sathi, designed to support Indian farmers by providing\npersonalized, easy-to-understand answers to their queries through both text and\nspeech. The system's intelligence stems from an IFT model, subsequently refined\nthrough fine-tuning on Indian agricultural knowledge across three curated\ndatasets. Unlike traditional chatbots that respond to one-off questions, Krishi\nSathi follows a structured, multi-turn conversation flow to gradually collect\nthe necessary details from the farmer, ensuring the query is fully understood\nbefore generating a response. Once the intent and context are extracted, the\nsystem performs Retrieval-Augmented Generation (RAG) by first fetching\ninformation from a curated agricultural database and then generating a tailored\nresponse using the IFT model. The chatbot supports both English and Hindi\nlanguages, with speech input and output features (via ASR and TTS) to make it\naccessible for users with low literacy or limited digital skills. This work\ndemonstrates how combining intent-driven dialogue flows, instruction-tuned\nmodels, and retrieval-based generation can improve the quality and\naccessibility of digital agricultural support in India.\n  This approach yielded strong results, with the system achieving a query\nresponse accuracy of 97.53%, 91.35% contextual relevance and personalization,\nand a query completion rate of 97.53%. The average response time remained under\n6 seconds, ensuring timely support for users across both English and Hindi\ninteractions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u667a\u80fd\u519c\u4e1a\u52a9\u624bKrishi Sathi\uff0c\u901a\u8fc7\u591a\u8f6e\u5bf9\u8bdd\u3001\u6307\u4ee4\u5fae\u8c03\u548c\u68c0\u7d22\u589e\u5f3a\u6280\u672f\uff0c\u4e3a\u5370\u5ea6\u519c\u6c11\u63d0\u4f9b\u82f1\u5370\u53cc\u8bed\u3001\u6587\u672c\u4e0e\u8bed\u97f3\u517c\u5bb9\u7684\u9ad8\u8d28\u91cf\u4e2a\u6027\u5316\u519c\u4e1a\u54a8\u8be2\u652f\u6301\uff0c\u663e\u8457\u63d0\u5347\u670d\u52a1\u53ef\u53ca\u6027\u548c\u54cd\u5e94\u6548\u7387\uff0c\u6d4b\u8bd5\u5404\u9879\u6027\u80fd\u6307\u6807\u5747\u8868\u73b0\u4f18\u79c0\u3002", "motivation": "\u5370\u5ea6\u519c\u6c11\u3001\u5c24\u5176\u662f\u519c\u6751\u4e0e\u4f4e\u8bc6\u5b57\u7387\u7fa4\u4f53\uff0c\u96be\u4ee5\u53ca\u65f6\u83b7\u5f97\u4fbf\u6377\u4e14\u9002\u5408\u672c\u5730\u8bed\u5883\u7684\u519c\u4e1a\u54a8\u8be2\u670d\u52a1\uff0c\u9700\u8981\u4e00\u79cd\u4f4e\u95e8\u69db\u3001\u667a\u80fd\u5316\u3001\u4e2a\u6027\u5316\u7684\u6570\u5b57\u652f\u6301\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86Krishi Sathi AI\u519c\u4e1a\u804a\u5929\u673a\u5668\u4eba\uff0c\u91c7\u7528\u6307\u4ee4\u5fae\u8c03\uff08IFT\uff09\u6a21\u578b\uff0c\u7ed3\u5408\u4e09\u7ec4\u5370\u5ea6\u519c\u4e1a\u77e5\u8bc6\u6570\u636e\u96c6\u8fdb\u884c\u7ec6\u5316\uff1b\u5b9e\u73b0\u591a\u8f6e\u5bf9\u8bdd\u6d41\u7a0b\uff0c\u901a\u8fc7RAG(\u68c0\u7d22\u589e\u5f3a\u751f\u6210)\u4ece\u519c\u4e1a\u77e5\u8bc6\u5e93\u68c0\u7d22\u5e76\u751f\u6210\u4e2a\u6027\u5316\u54cd\u5e94\uff0c\u652f\u6301\u82f1\u5370\u53cc\u8bed\u53ca\u8bed\u97f3\u8f93\u5165\u8f93\u51fa\u7528\u4e8e\u4f4e\u8bc6\u5b57\u7387\u7528\u6237\u3002", "result": "\u7cfb\u7edf\u5728\u67e5\u8be2\u54cd\u5e94\u51c6\u786e\u7387\uff0897.53%\uff09\u3001\u60c5\u5883\u76f8\u5173\u4e0e\u4e2a\u6027\u5316\uff0891.35%\uff09\u3001\u67e5\u8be2\u5b8c\u6210\u7387\uff0897.53%\uff09\u7b49\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5e73\u5747\u54cd\u5e94\u65f6\u95f4\u4e0d\u8d85\u8fc76\u79d2\uff0c\u6ee1\u8db3\u7528\u6237\u5bf9\u53ca\u65f6\u6027\u7684\u9700\u6c42\u3002", "conclusion": "\u7ed3\u5408\u57fa\u4e8e\u610f\u56fe\u7684\u5bf9\u8bdd\u6d41\u3001\u6307\u4ee4\u8c03\u4f18\u7684\u6a21\u578b\u548c\u68c0\u7d22\u5f0f\u751f\u6210\u6280\u672f\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u5370\u5ea6\u519c\u4e1a\u6570\u5b57\u5316\u54a8\u8be2\u670d\u52a1\u7684\u8d28\u91cf\u4e0e\u53ef\u53ca\u6027\uff0c\u5c24\u5176\u662f\u5728\u4f4e\u8bc6\u5b57\u7387\u548c\u4e61\u6751\u5730\u533a\u3002"}}
{"id": "2508.04115", "categories": ["cs.PL", "A.1; C.1.2; D.3.1; F.3.1; F.3.2"], "pdf": "https://arxiv.org/pdf/2508.04115", "abs": "https://arxiv.org/abs/2508.04115", "authors": ["Roger C. Su", "Robert J. Colvin"], "title": "Weak Memory Model Formalisms: Introduction and Survey", "comment": null, "summary": "Memory consistency models define the order in which accesses to shared memory\nin a concurrent system may be observed to occur. Such models are a necessity\nsince program order is not a reliable indicator of execution order, due to\nmicroarchitectural features or compiler transformations. Concurrent\nprogramming, already a challenging task, is thus made even harder when weak\nmemory effects must be addressed. A rigorous specification of weak memory\nmodels is therefore essential to make this problem tractable for developers of\nsafety- and security-critical, low-level software.\n  In this paper we survey the field of formalisations of weak memory models,\nincluding their specification, their effects on execution, and tools and\ninference systems for reasoning about code. To assist the discussion we also\nprovide an introduction to two styles of formal representation found commonly\nin the literature (using a much simplified version of Intel's x86 as the\nexample): a step-by-step construction of traces of the system (operational\nsemantics); and with respect to relations between memory events (axiomatic\nsemantics). The survey covers some long-standing hardware features that lead to\nobservable weak behaviours, a description of historical developments in\npractice and in theory, an overview of computability and complexity results,\nand outlines current and future directions in the field.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u548c\u603b\u7ed3\u4e86\u5f31\u5185\u5b58\u6a21\u578b\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\u3001\u7406\u8bba\u53d1\u5c55\u3001\u5de5\u7a0b\u5b9e\u8df5\u4e0e\u63a8\u7406\u5de5\u5177\uff0c\u4e3a\u5e76\u53d1\u7a0b\u5e8f\u5f00\u53d1\u548c\u53ef\u9760\u6027\u4fdd\u969c\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u4e0e\u6700\u65b0\u8fdb\u5c55\u3002", "motivation": "\u5f31\u5185\u5b58\u6a21\u578b\u589e\u52a0\u4e86\u5e76\u53d1\u7a0b\u5e8f\u5f00\u53d1\u7684\u96be\u5ea6\uff0c\u5c24\u5176\u662f\u5728\u5b89\u5168\u53ca\u5173\u952e\u8f6f\u4ef6\u9886\u57df\u3002\u4e3a\u5e2e\u52a9\u5f00\u53d1\u8005\u6709\u6548\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u6025\u9700\u5bf9\u5f31\u5185\u5b58\u6a21\u578b\u8fdb\u884c\u7cbe\u51c6\u4e14\u53ef\u64cd\u4f5c\u7684\u7406\u8bba\u89c4\u8303\u548c\u5206\u6790\u3002", "method": "\u901a\u8fc7\u5bf9\u5f31\u5185\u5b58\u6a21\u578b\u7684\u5f62\u5f0f\u5316\u65b9\u6848\u8fdb\u884c\u5168\u9762\u68b3\u7406\uff0c\u5305\u62ec\u64cd\u4f5c\u8bed\u4e49\u548c\u516c\u7406\u8bed\u4e49\u4e24\u79cd\u8868\u793a\u65b9\u5f0f\uff0c\u5e76\u7ed3\u5408\u5177\u4f53\u5b9e\u4f8b\uff08\u5982\u7b80\u5316\u7248x86\uff09\uff0c\u7cfb\u7edf\u6027\u5730\u5206\u6790\u4e86\u5176\u89c4\u683c\u3001\u5b9e\u9645\u8868\u73b0\u3001\u63a8\u7406\u7cfb\u7edf\u7b49\u3002", "result": "\u68b3\u7406\u4e86\u5f31\u5185\u5b58\u786c\u4ef6\u7279\u6027\u3001\u5386\u53f2\u53d1\u5c55\u3001\u53ef\u8ba1\u7b97\u6027\u53ca\u590d\u6742\u6027\u6210\u679c\uff0c\u4ee5\u53ca\u8f85\u52a9\u5f00\u53d1\u548c\u63a8\u7406\u7684\u76f8\u5173\u5de5\u5177\u7cfb\u7edf\uff0c\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u5f53\u524d\u5f31\u5185\u5b58\u6a21\u578b\u7406\u8bba\u53ca\u5b9e\u8df5\u524d\u6cbf\u3002", "conclusion": "\u672c\u6587\u603b\u7ed3\u4e86\u5f31\u5185\u5b58\u6a21\u578b\u5f62\u5f0f\u5316\u7814\u7a76\u7684\u4e3b\u8981\u8fdb\u5c55\uff0c\u5e76\u6307\u51fa\u4e86\u5f53\u524d\u548c\u672a\u6765\u5728\u8be5\u9886\u57df\u7684\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2508.03922", "categories": ["cs.SE", "cs.HC", "D.2.1"], "pdf": "https://arxiv.org/pdf/2508.03922", "abs": "https://arxiv.org/abs/2508.03922", "authors": ["Soroush Heydari"], "title": "A Human Centric Requirements Engineering Framework for Assessing Github Copilot Output", "comment": "8 pages", "summary": "The rapid adoption of Artificial Intelligence(AI) programming assistants such\nas GitHub Copilot introduces new challenges in how these software tools address\nhuman needs. Many existing evaluation frameworks address technical aspects such\nas code correctness and efficiency, but often overlook crucial human factors\nthat affect the successful integration of AI assistants in software development\nworkflows. In this study, I analyzed GitHub Copilot's interaction with users\nthrough its chat interface, measured Copilot's ability to adapt explanations\nand code generation to user expertise levels, and assessed its effectiveness in\nfacilitating collaborative programming experiences. I established a\nhuman-centered requirements framework with clear metrics to evaluate these\nqualities in GitHub Copilot chat. I discussed the test results and their\nimplications for future analysis of human requirements in automated\nprogramming.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4ee5\u4eba\u4e3a\u672c\u7684GitHub Copilot\u8bc4\u4f30\u6846\u67b6\uff0c\u8865\u8db3\u4e86\u5355\u4e00\u6280\u672f\u6307\u6807\u7684\u4e0d\u8db3\uff0c\u91cd\u70b9\u5173\u6ce8\u4ea4\u4e92\u3001\u9002\u5e94\u6027\u548c\u534f\u4f5c\u652f\u6301\u7b49\u4eba\u56e0\u9700\u6c42\uff0c\u5b9e\u9a8c\u7ed3\u679c\u4e3a\u672a\u6765AI\u7f16\u7a0b\u52a9\u624b\u7684\u6539\u8fdb\u548c\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002", "motivation": "AI\u7f16\u7a0b\u52a9\u624b\u5982GitHub Copilot\u88ab\u5feb\u901f\u91c7\u7528\uff0c\u4f46\u73b0\u6709\u8bc4\u4f30\u6846\u67b6\u4e3b\u8981\u805a\u7126\u6280\u672f\u6307\u6807\uff0c\u5ffd\u89c6\u4e86\u4eba\u56e0\u56e0\u7d20\uff0c\u8fd9\u5f71\u54cd\u4e86AI\u52a9\u624b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u6709\u6548\u6574\u5408\u3002\u4f5c\u8005\u5e0c\u671b\u8865\u8db3\u8fd9\u4e00\u8bc4\u4f30\u77ed\u677f\u3002", "method": "\u4f5c\u8005\u5206\u6790\u4e86GitHub Copilot\u901a\u8fc7\u804a\u5929\u754c\u9762\u4e0e\u7528\u6237\u4e92\u52a8\u7684\u60c5\u51b5\uff0c\u6d4b\u91cf\u4e86Copilot\u6839\u636e\u7528\u6237\u4e13\u4e1a\u6c34\u5e73\u8c03\u6574\u89e3\u91ca\u4e0e\u4ee3\u7801\u751f\u6210\u7684\u80fd\u529b\uff0c\u5e76\u8bc4\u4f30\u4e86\u5176\u5728\u534f\u4f5c\u7f16\u7a0b\u4e2d\u7684\u6709\u6548\u6027\u3002\u6b64\u5916\uff0c\u6784\u5efa\u4e86\u4ee5\u4eba\u4e3a\u672c\u7684\u9700\u6c42\u8bc4\u4f30\u6846\u67b6\uff0c\u8bbe\u5b9a\u4e86\u5177\u4f53\u8861\u91cf\u6307\u6807\u3002", "result": "\u901a\u8fc7\u6d4b\u8bd5\u8868\u660e\uff0cGitHub Copilot\u5728\u9002\u5e94\u7528\u6237\u4e13\u4e1a\u6c34\u5e73\u3001\u4ee3\u7801\u751f\u6210\u548c\u534f\u4f5c\u652f\u6301\u65b9\u9762\u5b58\u5728\u4e00\u5b9a\u6548\u679c\uff0c\u6d4b\u8bd5\u7ed3\u679c\u4e3a\u672a\u6765\u4eba\u56e0\u9700\u6c42\u7684\u6df1\u5165\u7814\u7a76\u63d0\u4f9b\u4e86\u53c2\u8003\u3002", "conclusion": "\u4ee5\u4eba\u4e3a\u672c\u7684\u8bc4\u4f30\u5bf9AI\u7f16\u7a0b\u52a9\u624b\u7684\u6574\u5408\u4e0e\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u672c\u6587\u63d0\u51fa\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u6d4b\u8bd5\u7ed3\u679c\u6709\u52a9\u4e8e\u5b8c\u5584\u6b64\u7c7b\u5de5\u5177\uff0c\u66f4\u597d\u5730\u6ee1\u8db3\u7528\u6237\u9700\u6c42\uff0c\u5bf9\u4e8e\u540e\u7eed\u81ea\u52a8\u5316\u7f16\u7a0b\u7684\u4eba\u56e0\u5206\u6790\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2508.03726", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.03726", "abs": "https://arxiv.org/abs/2508.03726", "authors": ["Jaydip Sen", "Harshitha Puvvala", "Subhasis Dasgupta"], "title": "Hierarchical Verification of Speculative Beams for Accelerating LLM Inference", "comment": "This paper was accepted for oral presentation and publication in the\n  3rd International Conference on Data Science and Network Engineering (ICDSNE\n  2025), organized at NIT, Agartala, India, from July 25 to 26, 2025. The paper\n  is 12 pages long, and it contains 3 tables and 4 figures. This is NOT the\n  final paper, which will be published in the Springer-published proceedings", "summary": "Large language models (LLMs) have achieved remarkable success across diverse\nnatural language processing tasks but face persistent challenges in inference\nefficiency due to their autoregressive nature. While speculative decoding and\nbeam sampling offer notable improvements, traditional methods verify draft\nsequences sequentially without prioritization, leading to unnecessary\ncomputational overhead. This work proposes the Hierarchical Verification Tree\n(HVT), a novel framework that restructures speculative beam decoding by\nprioritizing high-likelihood drafts and enabling early pruning of suboptimal\ncandidates. Theoretical foundations and a formal verification-pruning algorithm\nare developed to ensure correctness and efficiency. Integration with standard\nLLM inference pipelines is achieved without requiring retraining or\narchitecture modification. Experimental evaluations across multiple datasets\nand models demonstrate that HVT consistently outperforms existing speculative\ndecoding schemes, achieving substantial reductions in inference time and energy\nconsumption while maintaining or enhancing output quality. The findings\nhighlight the potential of hierarchical verification strategies as a new\ndirection for accelerating large language model inference.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u9a8c\u8bc1\u6846\u67b6\uff08HVT\uff09\uff0c\u80fd\u663e\u8457\u52a0\u901f\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u751f\u6210\u8d28\u91cf\uff0c\u65e0\u987b\u989d\u5916\u8bad\u7ec3\u6216\u4fee\u6539\u6a21\u578b\u7ed3\u6784\uff0c\u5b9e\u9a8c\u7ed3\u679c\u4f18\u5f02\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7531\u4e8e\u81ea\u56de\u5f52\u751f\u6210\u65b9\u5f0f\uff0c\u63a8\u7406\u6548\u7387\u6709\u9650\u3002\u867d\u7136\u5df2\u6709\u6295\u673a\u89e3\u7801\u548c\u675f\u91c7\u6837\u7b49\u6539\u8fdb\u65b9\u6cd5\uff0c\u4f46\u4f20\u7edf\u65b9\u6848\u5728\u9a8c\u8bc1\u8349\u7a3f\u5e8f\u5217\u65f6\u6ca1\u6709\u4f18\u5316\u4f18\u5148\u7ea7\uff0c\u9020\u6210\u8ba1\u7b97\u5197\u4f59\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c42\u6b21\u5316\u9a8c\u8bc1\u6811\uff08HVT\uff09\u6846\u67b6\uff0c\u91cd\u6784\u4e86\u6295\u673a\u675f\u89e3\u7801\u6d41\u7a0b\uff0c\u901a\u8fc7\u4f18\u5148\u9a8c\u8bc1\u9ad8\u6982\u7387\u8349\u7a3f\u5e76\u53ca\u65e9\u526a\u679d\u4f4e\u8d28\u91cf\u5019\u9009\uff0c\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u3002\u8be5\u65b9\u6cd5\u5305\u62ec\u7406\u8bba\u57fa\u7840\u548c\u5f62\u5f0f\u5316\u7684\u9a8c\u8bc1-\u526a\u679d\u7b97\u6cd5\uff0c\u65e0\u9700\u6a21\u578b\u91cd\u65b0\u8bad\u7ec3\u6216\u7ed3\u6784\u4fee\u6539\uff0c\u53ef\u76f4\u63a5\u878d\u5165\u6807\u51c6\u63a8\u7406\u6d41\u7a0b\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cHVT\u65b9\u6cd5\u5728\u63a8\u7406\u901f\u5ea6\u548c\u80fd\u8017\u4e0a\u663e\u8457\u4f18\u4e8e\u4ee5\u5f80\u6295\u673a\u89e3\u7801\u65b9\u6cd5\uff0c\u5e76\u4e14\u4fdd\u8bc1\u6216\u63d0\u5347\u4e86\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "HVT\u5c55\u73b0\u4e86\u5c42\u6b21\u5316\u9a8c\u8bc1\u7b56\u7565\u5728\u52a0\u901f\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u9ad8\u6548\u63a8\u7406\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.03931", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03931", "abs": "https://arxiv.org/abs/2508.03931", "authors": ["Everton Guimaraes", "Nathalia Nascimento", "Chandan Shivalingaiah", "Asish Nelapati"], "title": "Analyzing Prominent LLMs: An Empirical Study of Performance and Complexity in Solving LeetCode Problems", "comment": "11 pages, 13 figures, 29th International Conference on Evaluation and\n  Assessment in Software Engineering (EASE)", "summary": "Large Language Models (LLMs) like ChatGPT, Copilot, Gemini, and DeepSeek are\ntransforming software engineering by automating key tasks, including code\ngeneration, testing, and debugging. As these models become integral to\ndevelopment workflows, a systematic comparison of their performance is\nessential for optimizing their use in real world applications. This study\nbenchmarks these four prominent LLMs on one hundred and fifty LeetCode problems\nacross easy, medium, and hard difficulties, generating solutions in Java and\nPython. We evaluate each model based on execution time, memory usage, and\nalgorithmic complexity, revealing significant performance differences. ChatGPT\ndemonstrates consistent efficiency in execution time and memory usage, while\nCopilot and DeepSeek show variability as task complexity increases. Gemini,\nalthough effective on simpler tasks, requires more attempts as problem\ndifficulty rises. Our findings provide actionable insights into each model's\nstrengths and limitations, offering guidance for developers selecting LLMs for\nspecific coding tasks and providing insights on the performance and complexity\nof GPT-like generated solutions.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5bf9\u6bd4\u4e86ChatGPT\u3001Copilot\u3001Gemini\u548cDeepSeek\u56db\u5927\u4e3b\u6d41LLM\u5728LeetCode\u81ea\u52a8\u89e3\u9898\u4e2d\u7684\u8868\u73b0\u3002\u7ed3\u679c\u663e\u793aChatGPT\u6548\u7387\u4e0e\u7a33\u5b9a\u6027\u6700\u4f73\uff1bCopilot\u548cDeepSeek\u5728\u96be\u9898\u4e0a\u6ce2\u52a8\u8f83\u5927\uff1bGemini\u96be\u9898\u8868\u73b0\u6b20\u4f73\u3002\u7814\u7a76\u4e3a\u5f00\u53d1\u8005\u6a21\u578b\u9009\u62e9\u548c\u7406\u89e3GPT\u7c7b\u4ee3\u7801\u751f\u6210\u80fd\u529b\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u53c2\u8003\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5982ChatGPT\u3001Copilot\u3001Gemini\u548cDeepSeek\u5df2\u6df1\u5ea6\u878d\u5165\u8f6f\u4ef6\u5de5\u7a0b\u6d41\u7a0b\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5b83\u4eec\u5728\u4ee3\u7801\u751f\u6210\u7b49\u5b9e\u9645\u5f00\u53d1\u4efb\u52a1\u4e2d\u7cfb\u7edf\u5316\u3001\u7ec6\u81f4\u7684\u6027\u80fd\u6bd4\u8f83\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u5b9e\u8bc1\u6570\u636e\u5e2e\u52a9\u5f00\u53d1\u8005\u5728\u5b9e\u9645\u9009\u578b\u65f6\u6709\u636e\u53ef\u4f9d\u3002", "method": "\u4f5c\u8005\u9009\u53d6\u4e86150\u9053LeetCode\u9898\u76ee\uff08\u6db5\u76d6\u7b80\u5355\u3001\u4e2d\u7b49\u3001\u56f0\u96be\uff09\uff0c\u5206\u522b\u7528Java\u548cPython\u4e24\u79cd\u8bed\u8a00\u751f\u6210\u4ee3\u7801\u89e3\u7b54\u3002\u5bf9\u6bd4\u5206\u6790\u4e86\u56db\u4e2a\u4e3b\u6d41LLM\u5728\u6267\u884c\u65f6\u95f4\u3001\u5185\u5b58\u4f7f\u7528\u4e0e\u7b97\u6cd5\u590d\u6742\u5ea6\u4e0a\u7684\u8868\u73b0\u3002", "result": "ChatGPT\u5728\u6267\u884c\u6548\u7387\u4e0e\u5185\u5b58\u6d88\u8017\u4e0a\u8868\u73b0\u59cb\u7ec8\u7a33\u5b9a\u4e14\u4f18\u79c0\u3002Copilot\u4e0eDeepSeek\u968f\u7740\u9898\u76ee\u53d8\u96be\uff0c\u6027\u80fd\u6ce2\u52a8\u52a0\u5927\u3002Gemini\u867d\u7136\u5728\u7b80\u5355\u95ee\u9898\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u96be\u9898\u4e0a\u5c1d\u8bd5\u6b21\u6570\u6fc0\u589e\u3002\u6574\u4f53\u4e0a\uff0c\u56db\u6b3e\u6a21\u578b\u5728\u4e0d\u540c\u96be\u5ea6\u548c\u4efb\u52a1\u4e0b\u5448\u73b0\u51fa\u663e\u8457\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "\u6bcf\u79cdLLM\u5728\u4ee3\u7801\u751f\u6210\u7b49\u4efb\u52a1\u4e0a\u6709\u5404\u81ea\u7684\u4f18\u7f3a\u70b9\u3002\u5b9e\u8bc1\u6bd4\u8f83\u80fd\u4e3a\u5f00\u53d1\u8005\u7684\u6a21\u578b\u9009\u578b\u63d0\u4f9b\u9488\u5bf9\u6027\u6307\u5bfc\uff0c\u4e5f\u63ed\u793a\u4e86GPT\u7c7b\u6a21\u578b\u5728\u6027\u80fd\u548c\u7b97\u6cd5\u590d\u6742\u5ea6\u65b9\u9762\u7684\u8868\u73b0\u548c\u5c40\u9650\u3002"}}
{"id": "2508.03728", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.03728", "abs": "https://arxiv.org/abs/2508.03728", "authors": ["Revanth Gangi Reddy", "Tanay Dixit", "Jiaxin Qin", "Cheng Qian", "Daniel Lee", "Jiawei Han", "Kevin Small", "Xing Fan", "Ruhi Sarikaya", "Heng Ji"], "title": "WINELL: Wikipedia Never-Ending Updating with LLM Agents", "comment": null, "summary": "Wikipedia, a vast and continuously consulted knowledge base, faces\nsignificant challenges in maintaining up-to-date content due to its reliance on\nmanual human editors. Inspired by the vision of continuous knowledge\nacquisition in NELL and fueled by advances in LLM-based agents, this paper\nintroduces WiNELL, an agentic framework for continuously updating Wikipedia\narticles. Our approach employs a multi-agent framework to aggregate online\ninformation, select new and important knowledge for a target entity in\nWikipedia, and then generate precise edit suggestions for human review. Our\nfine-grained editing models, trained on Wikipedia's extensive history of human\nedits, enable incorporating updates in a manner consistent with human editing\nbehavior. Our editor models outperform both open-source instruction-following\nbaselines and closed-source LLMs (e.g., GPT-4o) in key information coverage and\nediting efficiency. End-to-end evaluation on high-activity Wikipedia pages\ndemonstrates WiNELL's ability to identify and suggest timely factual updates.\nThis opens up a promising research direction in LLM agents for automatically\nupdating knowledge bases in a never-ending fashion.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faWiNELL\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u548c\u9ad8\u6548\u7f16\u8f91\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ef4\u57fa\u767e\u79d1\u81ea\u52a8\u5316\u3001\u6301\u7eed\u66f4\u65b0\u7684\u80fd\u529b\uff0c\u5728\u5173\u952e\u4fe1\u606f\u8986\u76d6\u548c\u6548\u7387\u65b9\u9762\u8d85\u8d8a\u591a\u79cd\u5148\u8fdb\u57fa\u7ebf\uff0c\u4e3a\u81ea\u52a8\u77e5\u8bc6\u5e93\u7ef4\u62a4\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002", "motivation": "\u7ef4\u57fa\u767e\u79d1\u662f\u5168\u7403\u6700\u5927\u7684\u77e5\u8bc6\u5e93\u4e4b\u4e00\uff0c\u4f46\u7531\u4e8e\u5176\u9ad8\u5ea6\u4f9d\u8d56\u4eba\u5de5\u7f16\u8f91\uff0c\u5185\u5bb9\u53ca\u65f6\u66f4\u65b0\u4e00\u76f4\u662f\u4e3b\u8981\u6311\u6218\u3002\u968f\u7740NELL\u7b49\u7cfb\u7edf\u5bf9\u6301\u7eed\u77e5\u8bc6\u83b7\u53d6\u7684\u63a2\u7d22\u4ee5\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u667a\u80fd\u4f53\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u81ea\u52a8\u5316\u77e5\u8bc6\u66f4\u65b0\u663e\u5f97\u5c24\u4e3a\u91cd\u8981\u3002", "method": "\u8bbe\u8ba1\u5e76\u63d0\u51fa\u4e86WiNELL\u2014\u2014\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u805a\u5408\u5728\u7ebf\u4fe1\u606f\uff0c\u7b5b\u9009\u65b0\u7684\u91cd\u8981\u77e5\u8bc6\uff0c\u4e3a\u7ef4\u57fa\u767e\u79d1\u76ee\u6807\u5b9e\u4f53\u751f\u6210\u7cbe\u786e\u7684\u7f16\u8f91\u5efa\u8bae\uff0c\u5e76\u7531\u4eba\u5de5\u6700\u7ec8\u5ba1\u6838\u3002\u5176\u7f16\u8f91\u6a21\u578b\u4ee5\u7ef4\u57fa\u767e\u79d1\u5386\u53f2\u4eba\u5de5\u7f16\u8f91\u6570\u636e\u4e3a\u8bad\u7ec3\u96c6\uff0c\u4ee5\u8d34\u8fd1\u771f\u5b9e\u7f16\u8f91\u98ce\u683c\u3002", "result": "\u7f16\u8f91\u5668\u6a21\u578b\u5728\u5173\u952e\u4fe1\u606f\u8986\u76d6\u548c\u7f16\u8f91\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u5f00\u6e90\u6307\u4ee4\u8ddf\u968f\u57fa\u7ebf\u6a21\u578b\u548c\u95ed\u6e90LLM\uff08\u5982GPT-4o\uff09\u3002\u5728\u9ad8\u6d3b\u8dc3\u5ea6\u7ef4\u57fa\u767e\u79d1\u9875\u9762\u7684\u7aef\u5230\u7aef\u8bc4\u6d4b\u4e2d\uff0cWiNELL\u80fd\u591f\u53ca\u65f6\u53d1\u73b0\u5e76\u5efa\u8bae\u7cbe\u51c6\u7684\u4e8b\u5b9e\u66f4\u65b0\u3002", "conclusion": "WiNELL\u80fd\u591f\u5b9e\u73b0\u9ad8\u6548\u3001\u6301\u7eed\u7684\u7ef4\u57fa\u767e\u79d1\u5185\u5bb9\u81ea\u52a8\u66f4\u65b0\uff0c\u63a8\u52a8\u4e86LLM\u667a\u80fd\u4f53\u81ea\u52a8\u7ef4\u62a4\u5927\u89c4\u6a21\u77e5\u8bc6\u5e93\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2508.03949", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03949", "abs": "https://arxiv.org/abs/2508.03949", "authors": ["Md. Abdul Awal", "Mrigank Rochan", "Chanchal K. Roy"], "title": "Model Compression vs. Adversarial Robustness: An Empirical Study on Language Models for Code", "comment": null, "summary": "Transformer-based language models for code have shown remarkable performance\nin various software analytics tasks, but their adoption is hindered by high\ncomputational costs, slow inference speeds, and substantial environmental\nimpact. Model compression techniques such as pruning, quantization, and\nknowledge distillation have gained traction in addressing these challenges.\nHowever, the impact of these strategies on the robustness of compressed\nlanguage models for code in adversarial scenarios remains poorly understood.\nUnderstanding how these compressed models behave under adversarial attacks is\nessential for their safe and effective deployment in real-world applications.\nTo bridge this knowledge gap, we conduct a comprehensive evaluation of how\ncommon compression strategies affect the adversarial robustness of compressed\nmodels. We assess the robustness of compressed versions of three widely used\nlanguage models for code across three software analytics tasks, using six\nevaluation metrics and four commonly used classical adversarial attacks. Our\nfindings indicate that compressed models generally maintain comparable\nperformance to their uncompressed counterparts. However, when subjected to\nadversarial attacks, compressed models exhibit significantly reduced\nrobustness. These results reveal a trade-off between model size reduction and\nadversarial robustness, underscoring the need for careful consideration when\ndeploying compressed models in security-critical software applications. Our\nstudy highlights the need for further research into compression strategies that\nstrike a balance between computational efficiency and adversarial robustness,\nwhich is essential for deploying reliable language models for code in\nreal-world software applications.", "AI": {"tldr": "\u538b\u7f29\u63d0\u5347\u4ee3\u7801\u6a21\u578b\u6548\u7387\uff0c\u4f46\u663e\u8457\u964d\u4f4e\u5176\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u5b89\u5168\u654f\u611f\u573a\u666f\u9700\u6743\u8861\u4f7f\u7528\uff0c\u547c\u5401\u7814\u7a76\u66f4\u5747\u8861\u7684\u538b\u7f29\u65b9\u6848\u3002", "motivation": "\u4ee3\u7801\u9886\u57df\u7684Transformer\u6a21\u578b\u867d\u7136\u6027\u80fd\u51fa\u8272\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u63a8\u7406\u6162\u4e14\u4ea7\u751f\u8f83\u5927\u73af\u5883\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8981\u901a\u8fc7\u6a21\u578b\u538b\u7f29\uff08\u526a\u679d\u3001\u91cf\u5316\u3001\u77e5\u8bc6\u84b8\u998f\u7b49\uff09\u6765\u63d0\u5347\u6548\u7387\u3002\u4f46\u6a21\u578b\u538b\u7f29\u540e\u5728\u9762\u5bf9\u5bf9\u6297\u653b\u51fb\u65f6\u9c81\u68d2\u6027\u7684\u53d8\u5316\u5c1a\u4e0d\u6e05\u695a\uff0c\u5f71\u54cd\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u6027\u3002", "method": "\u4f5c\u8005\u5bf9\u5e38\u89c1\u7684\u6a21\u578b\u538b\u7f29\u7b56\u7565\uff08\u526a\u679d\u3001\u91cf\u5316\u3001\u84b8\u998f\uff09\u8fdb\u884c\u4e86\u7cfb\u7edf\u8bc4\u4f30\u3002\u9009\u62e9\u4e09\u79cd\u5178\u578b\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u4e09\u7c7b\u8f6f\u4ef6\u5206\u6790\u4efb\u52a1\u4e0a\uff0c\u901a\u8fc7\u516d\u79cd\u8bc4\u4f30\u6307\u6807\u548c\u56db\u79cd\u5e38\u89c1\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\uff0c\u6d4b\u8bd5\u538b\u7f29\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u538b\u7f29\u540e\u7684\u6a21\u578b\u5728\u6b63\u5e38\u60c5\u51b5\u4e0b\u6027\u80fd\u4e0e\u539f\u6a21\u578b\u76f8\u5f53\u3002\u4f46\u4e00\u65e6\u53d7\u5230\u5bf9\u6297\u653b\u51fb\uff0c\u9c81\u68d2\u6027\u660e\u663e\u4e0b\u964d\u3002", "conclusion": "\u6a21\u578b\u538b\u7f29\u5728\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\uff0c\u4f1a\u524a\u5f31\u6a21\u578b\u9762\u5bf9\u5bf9\u6297\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u4e24\u8005\u4e4b\u95f4\u5b58\u5728\u660e\u663e\u6743\u8861\u5173\u7cfb\u3002\u5728\u5b89\u5168\u5173\u952e\u578b\u8f6f\u4ef6\u5e94\u7528\u4e2d\uff0c\u90e8\u7f72\u538b\u7f29\u6a21\u578b\u9700\u8c28\u614e\u3002\u672a\u6765\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u517c\u987e\u6548\u7387\u4e0e\u9c81\u68d2\u6027\u7684\u538b\u7f29\u7b56\u7565\u3002"}}
{"id": "2508.03737", "categories": ["cs.CL", "cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.03737", "abs": "https://arxiv.org/abs/2508.03737", "authors": ["Ashutosh Bandooni", "Brindha Subburaj"], "title": "GanitBench: A bi-lingual benchmark for evaluating mathematical reasoning in Vision Language Models", "comment": "6 pages, 3 figures. Accepted, Presented and Published as part of\n  Proceedings of the 6th International Conference on Recent Advantages in\n  Information Technology (RAIT) 2025", "summary": "Benchmarks for evaluating reasoning among Vision Language Models (VLMs) on\nseveral fields and domains are being curated more frequently over the last few\nyears. However these are often monolingual, mostly available in English.\nAdditionally there also is a lack of datasets available in Hindi on tasks apart\nfrom comprehension and translation. We introduce GanitBench, a tough benchmark\nconsisting of 1527 vision-only questions covering several topics in Mathematics\n- available in languages English and Hindi. Collected from two major\nexaminations from India, the JEE Advanced and the CBSE Boards examinations,\nthis benchmark includes questions in the form of images comprising of figures\nessential to a question as well as text. We evaluate two closed source models\nfor the same, in zero-shot Chain-of-Thought (CoT) and two-shot CoT settings.\nGPT-4o mini is found to be the more dominant model on the benchmark, with it's\nhighest average accuracy being 38.15%. We also evaluate models through a\n\"Double Lock\" constraint, which brings down the performance of the models by\nconsiderable margins. We observe that two-shot CoT appears to be a more\neffective setting under this environment. Performance of the two VLMs also\ndecreases when answering the same questions in the Hindi language. We hope to\nfacilitate the inclusion of languages like Hindi in research through our work.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6db5\u76d6\u82f1\u6587\u548c\u5370\u5730\u8bed\u6570\u5b66\u9898\u76ee\u7684\u89c6\u89c9\u63a8\u7406\u57fa\u51c6GanitBench\uff0c\u5e76\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5728\u6b64\u57fa\u51c6\u4e0a\u8868\u73b0\u6709\u9650\uff0c\u5c24\u5176\u5728\u5370\u5730\u8bed\u4e0a\u7684\u8868\u73b0\u66f4\u5f31\uff0c\u5bf9\u591a\u8bed\u8a00VLM\u7814\u7a76\u5177\u6709\u63a8\u52a8\u4f5c\u7528\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u63a8\u7406\u80fd\u529b\u7684\u8bc4\u6d4b\u57fa\u51c6\u589e\u591a\uff0c\u4f46\u8fd9\u4e9b\u57fa\u51c6\u5927\u591a\u662f\u82f1\u6587\uff0c\u6db5\u76d6\u5176\u4ed6\u8bed\u8a00\uff08\u5982\u5370\u5730\u8bed\uff09\u4ee5\u53ca\u9664\u7406\u89e3\u548c\u7ffb\u8bd1\u5916\u4efb\u52a1\u7684\u6570\u636e\u96c6\u7a00\u7f3a\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u8be5\u7814\u7a76\u4fc3\u8fdb\u5305\u62ec\u5370\u5730\u8bed\u5728\u5185\u7684\u591a\u8bed\u8a00VLM\u7814\u7a76\u53d1\u5c55\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86GanitBench\u57fa\u51c6\uff0c\u5305\u542b1527\u9053\u4e3b\u8981\u6765\u81ea\u5370\u5ea6JEE Advanced\u548cCBSE\u8003\u8bd5\uff0c\u6db5\u76d6\u591a\u7c7b\u6570\u5b66\u9898\u7684\u7eaf\u89c6\u89c9\u95ee\u9898\uff0c\u5e76\u4ee5\u56fe\u7247\uff08\u5305\u542b\u56fe\u5f62\u548c\u6587\u672c\uff09\u7684\u5f62\u5f0f\uff0c\u652f\u6301\u82f1\u6587\u548c\u5370\u5730\u8bed\u3002\u5e76\u5728\u96f6\u6837\u672c\u548c\u4e24\u6837\u672c\u94fe\u5f0f\u601d\u8003\uff08Chain-of-Thought, CoT\uff09\u8bbe\u7f6e\u4e0b\uff0c\u5bf9\u4e24\u4e2a\u95ed\u6e90VLM\u6a21\u578b\u8fdb\u884c\u4e86\u8bc4\u6d4b\u3002", "result": "GPT-4o mini\u5728\u8be5\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u5bf9\u6bd4\u6a21\u578b\uff0c\u6700\u9ad8\u5e73\u5747\u51c6\u786e\u7387\u4e3a38.15%\u3002\u5728\u201cDouble Lock\u201d\u7ea6\u675f\uff08\u66f4\u4e25\u683c\u7684\u8bbe\u5b9a\uff09\u4e0b\uff0c\u6a21\u578b\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u4e24\u6837\u672cCoT\u8bbe\u7f6e\u8f83\u4e3a\u6709\u6548\u3002\u6b64\u5916\uff0c\u6a21\u578b\u5728\u5370\u5730\u8bed\u95ee\u9898\u4e0b\u8868\u73b0\u8f83\u5dee\u3002", "conclusion": "GanitBench\u4f5c\u4e3a\u591a\u8bed\u8a00\u89c6\u89c9\u63a8\u7406\u57fa\u51c6\uff0c\u5c24\u5176\u8865\u8db3\u4e86\u5370\u5730\u8bed\u6570\u5b66\u4efb\u52a1\u7684\u7a7a\u767d\u3002\u53cc\u8bed\u8a00\u3001\u591a\u4efb\u52a1\u8bbe\u5b9a\u5c55\u73b0\u4e86\u5f53\u524dVLM\u7684\u5c40\u9650\uff0c\u4e5f\u4e3a\u672a\u6765\u591a\u8bed\u8a00VLM\u7814\u7a76\u63d0\u4f9b\u4e86\u53c2\u8003\u548c\u6570\u636e\u652f\u6301\u3002"}}
{"id": "2508.04125", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04125", "abs": "https://arxiv.org/abs/2508.04125", "authors": ["Sangwon Hyun", "Hyunjun Kim", "Jinhyuk Jang", "Hyojin Choi", "M. Ali Babar"], "title": "Experimental Analysis of Productive Interaction Strategy with ChatGPT: User Study on Function and Project-level Code Generation Tasks", "comment": "The benchmark repository has not been publicly released yet due to\n  the IP policy in our institutions. If you would like to use the benchmark or\n  collaborate on extension, please contact \"dr.sangwon.hyun@gmail.com\"", "summary": "The application of Large Language Models (LLMs) is growing in the productive\ncompletion of Software Engineering tasks. Yet, studies investigating the\nproductive prompting techniques often employed a limited problem space,\nprimarily focusing on well-known prompting patterns and mainly targeting\nfunction-level SE practices. We identify significant gaps in real-world\nworkflows that involve complexities beyond class-level (e.g., multi-class\ndependencies) and different features that can impact Human-LLM Interactions\n(HLIs) processes in code generation. To address these issues, we designed an\nexperiment that comprehensively analyzed the HLI features regarding the code\ngeneration productivity. Our study presents two project-level benchmark tasks,\nextending beyond function-level evaluations. We conducted a user study with 36\nparticipants from diverse backgrounds, asking them to solve the assigned tasks\nby interacting with the GPT assistant using specific prompting patterns. We\nalso examined the participants' experience and their behavioral features during\ninteractions by analyzing screen recordings and GPT chat logs. Our statistical\nand empirical investigation revealed (1) that three out of 15 HLI features\nsignificantly impacted the productivity in code generation; (2) five primary\nguidelines for enhancing productivity for HLI processes; and (3) a taxonomy of\n29 runtime and logic errors that can occur during HLI processes, along with\nsuggested mitigation plans.", "AI": {"tldr": "\u672c\u7814\u7a76\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5b9e\u8f6f\u4ef6\u5de5\u7a0b\u73af\u5883\u4e0b\u7684\u4ee3\u7801\u751f\u6210\u751f\u4ea7\u529b\uff0c\u9996\u6b21\u7cfb\u7edf\u5206\u6790\u4e86\u9879\u76ee\u7ea7\u522b\u4efb\u52a1\u4e2d\u5f71\u54cd\u6548\u7387\u7684\u4eba\u673a\u4ea4\u4e92\u7279\u5f81\uff0c\u603b\u7ed3\u6307\u5f15\u5e76\u63d0\u51fa\u9519\u8bef\u5bf9\u7b56\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u5b9e\u9645\u5f00\u53d1\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u8d8a\u6765\u8d8a\u5e7f\u6cdb\uff0c\u4f46\u73b0\u6709\u6709\u5173\u9ad8\u6548\u63d0\u95ee\uff08prompting\uff09\u6280\u672f\u7684\u7814\u7a76\u591a\u96c6\u4e2d\u4e8e\u51fd\u6570\u7ea7\u522b\u7684\u95ee\u9898\uff0c\u5ffd\u7565\u4e86\u771f\u5b9e\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u66f4\u590d\u6742\u7684\u3001\u591a\u7c7b\u4f9d\u8d56\uff08\u5982\u7c7b\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\uff09\u7b49\u60c5\u51b5\u3002", "method": "\u8bbe\u8ba1\u5e76\u6267\u884c\u4e86\u4e00\u4e2a\u7efc\u5408\u5b9e\u9a8c\uff0c\u5305\u62ec\u4e24\u4e2a\u9879\u76ee\u7ea7\u522b\u57fa\u51c6\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u4e0eGPT\u52a9\u624b\u4e92\u52a8\uff08\u91c7\u7528\u7279\u5b9a\u63d0\u95ee\u6a21\u5f0f\uff09\u9080\u8bf736\u540d\u4e0d\u540c\u80cc\u666f\u7684\u53c2\u4e0e\u8005\u5b8c\u6210\u4efb\u52a1\u3002\u540c\u65f6\u6536\u96c6\u5206\u6790\u5176\u5c4f\u5e55\u5f55\u5236\u548c\u5bf9\u8bdd\u65e5\u5fd7\uff0c\u4ece\u7ecf\u9a8c\u548c\u884c\u4e3a\u89d2\u5ea6\u8003\u5bdf\u5f71\u54cd\u4ee3\u7801\u751f\u6210\u6548\u7387\u7684\u4eba\u673a\u4ea4\u4e92\uff08HLI\uff09\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\uff1a(1) 15\u9879HLI\u7279\u5f81\u4e2d\u67093\u9879\u5bf9\u4ee3\u7801\u751f\u6210\u751f\u4ea7\u529b\u6709\u663e\u8457\u5f71\u54cd\uff1b(2) \u603b\u7ed3\u51fa\u63d0\u5347\u751f\u4ea7\u529b\u7684\u4e94\u6761\u4e3b\u8981\u6307\u5f15\uff1b(3) \u6784\u5efa\u51fa29\u79cdHLI\u8fc7\u7a0b\u4e2d\u8fd0\u884c\u671f\u548c\u903b\u8f91\u9519\u8bef\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u63d0\u51fa\u76f8\u5e94\u7684\u7f13\u89e3\u63aa\u65bd\u3002", "conclusion": "\u771f\u5b9e\u3001\u591a\u7c7b\u4f9d\u8d56\u7b49\u590d\u6742\u80cc\u666f\u4e0b\u7684\u4eba\u673a-\u5927\u8bed\u8a00\u6a21\u578b\u4ea4\u4e92\u4e2d\uff0c\u6709\u7279\u5b9a\u7279\u5f81\u4f1a\u663e\u8457\u5f71\u54cd\u4ee3\u7801\u751f\u6210\u6548\u7387\u3002\u901a\u8fc7\u7cfb\u7edf\u5b9e\u9a8c\u8bc1\u660e\uff0c\u91c7\u53d6\u5408\u7406\u6307\u5f15\u548c\u9519\u8bef\u7f13\u89e3\u63aa\u65bd\u80fd\u6709\u6548\u63d0\u5347\u8fd9\u7c7b\u4ea4\u4e92\u7684\u6548\u7387\u548c\u8d28\u91cf\u3002"}}
{"id": "2508.03793", "categories": ["cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.03793", "abs": "https://arxiv.org/abs/2508.03793", "authors": ["Yanting Wang", "Runpeng Geng", "Ying Chen", "Jinyuan Jia"], "title": "AttnTrace: Attention-based Context Traceback for Long-Context LLMs", "comment": "The code is available at https://github.com/Wang-Yanting/AttnTrace.\n  The demo is available at https://huggingface.co/spaces/SecureLLMSys/AttnTrace", "summary": "Long-context large language models (LLMs), such as Gemini-2.5-Pro and\nClaude-Sonnet-4, are increasingly used to empower advanced AI systems,\nincluding retrieval-augmented generation (RAG) pipelines and autonomous agents.\nIn these systems, an LLM receives an instruction along with a context--often\nconsisting of texts retrieved from a knowledge database or memory--and\ngenerates a response that is contextually grounded by following the\ninstruction. Recent studies have designed solutions to trace back to a subset\nof texts in the context that contributes most to the response generated by the\nLLM. These solutions have numerous real-world applications, including\nperforming post-attack forensic analysis and improving the interpretability and\ntrustworthiness of LLM outputs. While significant efforts have been made,\nstate-of-the-art solutions such as TracLLM often lead to a high computation\ncost, e.g., it takes TracLLM hundreds of seconds to perform traceback for a\nsingle response-context pair. In this work, we propose AttnTrace, a new context\ntraceback method based on the attention weights produced by an LLM for a\nprompt. To effectively utilize attention weights, we introduce two techniques\ndesigned to enhance the effectiveness of AttnTrace, and we provide theoretical\ninsights for our design choice. We also perform a systematic evaluation for\nAttnTrace. The results demonstrate that AttnTrace is more accurate and\nefficient than existing state-of-the-art context traceback methods. We also\nshow that AttnTrace can improve state-of-the-art methods in detecting prompt\ninjection under long contexts through the attribution-before-detection\nparadigm. As a real-world application, we demonstrate that AttnTrace can\neffectively pinpoint injected instructions in a paper designed to manipulate\nLLM-generated reviews. The code is at\nhttps://github.com/Wang-Yanting/AttnTrace.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u6ce8\u610f\u529b\u6743\u91cd\u7684\u9ad8\u6548\u4e0a\u4e0b\u6587\u8ffd\u8e2a\u65b9\u6cd5AttnTrace\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u4e0e\u6548\u7387\uff0c\u6709\u52a9\u4e8e\u5927\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u4e0e\u5b89\u5168\u5e94\u7528\uff0c\u5f00\u6e90\u4ee3\u7801\u5df2\u53d1\u5e03\u3002", "motivation": "\u73b0\u6709\u957f\u4e0a\u4e0b\u6587\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5982Gemini-2.5-Pro\u3001Claude-Sonnet-4\uff09\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u590d\u6742AI\u7cfb\u7edf\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u9700\u8981\u8ffd\u8e2a\u54ea\u4e9b\u4e0a\u4e0b\u6587\u5185\u5bb9\u5bf9\u6a21\u578b\u8f93\u51fa\u5f71\u54cd\u6700\u5927\u3002\u7136\u800c\uff0c\u4e3b\u6d41\u8ffd\u8e2a\u65b9\u6cd5\u5982TracLLM\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u6548\u7387\u4f4e\uff0c\u5236\u7ea6\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u6ce8\u610f\u529b\u6743\u91cd\u7684\u65b0\u4e0a\u4e0b\u6587\u8ffd\u8e2a\u65b9\u6cd5AttnTrace\uff1b\u4e3a\u6709\u6548\u5229\u7528\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u8bbe\u8ba1\u4e86\u4e24\u9879\u6539\u8fdb\u6280\u672f\u5e76\u7ed9\u51fa\u4e86\u7406\u8bba\u89e3\u91ca\uff1b\u7cfb\u7edf\u6027\u5730\u5bf9\u6bd4\u8bc4\u4f30\u4e86\u8be5\u65b9\u6cd5\u3002", "result": "AttnTrace\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u68c0\u6d4b\u957f\u4e0a\u4e0b\u6587\u4e0b\u7684\u63d0\u793a\u6ce8\u5165\u65b9\u9762\u66f4\u5177\u6548\u679c\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u5e94\u7528\u4e8e\u68c0\u6d4b\u6a21\u578b\u8f93\u51fa\u64cd\u63a7\u884c\u4e3a\u7684\u5b9e\u9645\u573a\u666f\u3002", "conclusion": "AttnTrace\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u8ffd\u8e2a\u5173\u952e\u4e0a\u4e0b\u6587\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u4fe1\u7684\u65b0\u65b9\u6848\uff0c\u5e76\u6709\u52a9\u4e8e\u63d0\u5347\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3001\u68c0\u6d4b\u5b89\u5168\u98ce\u9669\uff0c\u5177\u5907\u5e7f\u6cdb\u771f\u5b9e\u4e16\u754c\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2508.04295", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.04295", "abs": "https://arxiv.org/abs/2508.04295", "authors": ["Chaofan Wang", "Tingrui Yu", "Jie Wang", "Dong Chen", "Wenrui Zhang", "Yuling Shi", "Xiaodong Gu", "Beijun Shen"], "title": "EVOC2RUST: A Skeleton-guided Framework for Project-Level C-to-Rust Translation", "comment": null, "summary": "Rust's compile-time safety guarantees make it ideal for safety-critical\nsystems, creating demand for translating legacy C codebases to Rust. While\nvarious approaches have emerged for this task, they face inherent trade-offs:\nrule-based solutions face challenges in meeting code safety and idiomaticity\nrequirements, while LLM-based solutions often fail to generate semantically\nequivalent Rust code, due to the heavy dependencies of modules across the\nentire codebase. Recent studies have revealed that both solutions are limited\nto small-scale programs. In this paper, we propose EvoC2Rust, an automated\nframework for converting entire C projects to equivalent Rust ones. EvoC2Rust\nemploys a skeleton-guided translation strategy for project-level translation.\nThe pipeline consists of three evolutionary stages: 1) it first decomposes the\nC project into functional modules, employs a feature-mapping-enhanced LLM to\ntransform definitions and macros and generates type-checked function stubs,\nwhich form a compilable Rust skeleton; 2) it then incrementally translates the\nfunction, replacing the corresponding stub placeholder; 3) finally, it repairs\ncompilation errors by integrating LLM and static analysis. Through evolutionary\naugmentation, EvoC2Rust combines the advantages of both rule-based and\nLLM-based solutions. Our evaluation on open-source benchmarks and six\nindustrial projects demonstrates EvoC2Rust's superior performance in\nproject-level C-to-Rust translation. On average, it achieves 17.24% and 14.32%\nimprovements in syntax and semantic accuracy over the LLM-based approaches,\nalong with a 96.79% higher code safety rate than the rule-based tools. At the\nmodule level, EvoC2Rust reaches 92.25% compilation and 89.53% test pass rates\non industrial projects, even for complex codebases and long functions.", "AI": {"tldr": "EvoC2Rust\u6846\u67b6\u901a\u8fc7\u9010\u6b65\u9aa8\u67b6\u5f15\u5bfc\u4e0e\u81ea\u52a8\u4fee\u590d\uff0c\u5b9e\u73b0\u4e86\u5927\u578bC\u9879\u76ee\u5411Rust\u7684\u9ad8\u8d28\u91cf\u81ea\u52a8\u8fc1\u79fb\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u7387\u4e0e\u5b89\u5168\u6027\u3002", "motivation": "Rust\u5177\u6709\u7f16\u8bd1\u671f\u5b89\u5168\u4fdd\u969c\uff0c\u975e\u5e38\u9002\u5408\u5b89\u5168\u5173\u952e\u7cfb\u7edf\uff0c\u56e0\u6b64\u5b58\u5728\u5c06\u9057\u7559C\u4ee3\u7801\u8fc1\u79fb\u5230Rust\u7684\u9700\u6c42\u3002\u73b0\u6709\u65b9\u6cd5\uff08\u57fa\u4e8e\u89c4\u5219\u548cLLM\uff09\u5404\u6709\u5f0a\u7aef\uff0c\u96be\u4ee5\u540c\u65f6\u6ee1\u8db3\u4ee3\u7801\u5b89\u5168\u4e0e\u9c81\u68d2\u6027\uff0c\u5927\u578b\u9879\u76ee\u652f\u6301\u4e5f\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e86EvoC2Rust\uff0c\u8fd9\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u9aa8\u67b6\u5f15\u5bfc\u7684\u7ffb\u8bd1\u7b56\u7565\uff0c\u5206\u4e09\u4e2a\u9636\u6bb5\u5c06C\u9879\u76ee\u8f6c\u6362\u4e3a\u8bed\u4e49\u7b49\u4ef7\u7684Rust\u9879\u76ee\uff1a1\uff09\u9879\u76ee\u529f\u80fd\u6a21\u5757\u5316\u5e76\u7528\u589e\u5f3a\u578bLLM\u751f\u6210Rust\u9aa8\u67b6\uff1b2\uff09\u9010\u6b65\u66ff\u6362\u51fd\u6570\u5b9e\u73b0\uff1b3\uff09\u7ed3\u5408LLM\u4e0e\u9759\u6001\u5206\u6790\u81ea\u52a8\u4fee\u590d\u7f16\u8bd1\u9519\u8bef\u3002", "result": "\u5728\u5f00\u6e90\u57fa\u51c6\u548c6\u4e2a\u5de5\u4e1a\u9879\u76ee\u4e0a\u8bc4\u4f30\uff0cEvoC2Rust\u5728\u9879\u76ee\u7ea7C\u8f6cRust\u7ffb\u8bd1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u6bd4LLM\u65b9\u6cd5\u8bed\u6cd5\u548c\u8bed\u4e49\u51c6\u786e\u7387\u5206\u522b\u63d0\u534717.24%\u548c14.32%\uff0c\u6bd4\u57fa\u4e8e\u89c4\u5219\u7684\u5de5\u5177\u4ee3\u7801\u5b89\u5168\u7387\u9ad896.79%\u3002\u6a21\u5757\u7ea7\u4e0a\uff0c\u590d\u6742\u4ee3\u7801\u5e93\u7684\u7f16\u8bd1\u901a\u8fc7\u7387\u548c\u6d4b\u8bd5\u901a\u8fc7\u7387\u5206\u522b\u4e3a92.25%\u548c89.53%\u3002", "conclusion": "EvoC2Rust\u80fd\u9ad8\u6548\u63a8\u8fdb\u5927\u578bC\u9879\u76ee\u5411Rust\u7684\u8fc1\u79fb\uff0c\u517c\u987e\u4ee3\u7801\u5b89\u5168\u3001\u8bed\u4e49\u4e00\u81f4\u6027\u53ca\u7f16\u8bd1\u6210\u529f\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002"}}
{"id": "2508.03829", "categories": ["cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.03829", "abs": "https://arxiv.org/abs/2508.03829", "authors": ["Jiahao Xu", "Rui Hu", "Zikai Zhang"], "title": "Majority Bit-Aware Watermarking For Large Language Models", "comment": "Preprint", "summary": "The growing deployment of Large Language Models (LLMs) in real-world\napplications has raised concerns about their potential misuse in generating\nharmful or deceptive content. To address this issue, watermarking techniques\nhave emerged as a promising solution by embedding identifiable binary messages\ninto generated text for origin verification and misuse tracing. While recent\nefforts have explored multi-bit watermarking schemes capable of embedding rich\ninformation such as user identifiers, they typically suffer from the\nfundamental trade-off between text quality and decoding accuracy: to ensure\nreliable message decoding, they have to restrict the size of preferred token\nsets during encoding, yet such restrictions reduce the quality of the generated\ncontent. In this work, we propose MajorMark, a novel watermarking method that\nimproves this trade-off through majority bit-aware encoding. MajorMark selects\npreferred token sets based on the majority bit of the message, enabling a\nlarger and more flexible sampling of tokens. In contrast to prior methods that\nrely on token frequency analysis for decoding, MajorMark employs a\nclustering-based decoding strategy, which maintains high decoding accuracy even\nwhen the preferred token set is large, thus preserving both content quality and\ndecoding accuracy. We further introduce MajorMark$^+$, which partitions the\nmessage into multiple blocks to independently encode and deterministically\ndecode each block, thereby further enhancing the quality of watermarked text\nand improving decoding accuracy. Extensive experiments on state-of-the-art LLMs\ndemonstrate that our methods significantly enhance both decoding accuracy and\ntext generation quality, outperforming prior multi-bit watermarking baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u578b\u591a\u6bd4\u7279\u6c34\u5370\u65b9\u6cd5MajorMark\u53ca\u5176\u589e\u5f3a\u7248\u672c\uff0c\u901a\u8fc7\u591a\u6570\u6bd4\u7279\u611f\u77e5\u7684\u7f16\u7801\u7b56\u7565\u548c\u805a\u7c7b\u89e3\u7801\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6c34\u5370\u6587\u672c\u7684\u751f\u6210\u8d28\u91cf\u548c\u89e3\u7801\u51c6\u786e\u7387\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5e7f\u6cdb\u90e8\u7f72\uff0c\u5982\u4f55\u9632\u6b62\u5176\u751f\u6210\u6709\u5bb3\u6216\u8bef\u5bfc\u5185\u5bb9\u6210\u4e3a\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u3002\u6c34\u5370\u6280\u672f\u53ef\u901a\u8fc7\u5728\u751f\u6210\u6587\u672c\u4e2d\u5d4c\u5165\u53ef\u8bc6\u522b\u7684\u4e8c\u8fdb\u5236\u4fe1\u606f\uff0c\u5b9e\u73b0\u6765\u6e90\u9a8c\u8bc1\u548c\u6ee5\u7528\u8ffd\u8e2a\u3002\u7136\u800c\uff0c\u73b0\u6709\u591a\u6bd4\u7279\u6c34\u5370\u65b9\u6848\u901a\u5e38\u5728\u6587\u672c\u8d28\u91cf\u548c\u89e3\u7801\u51c6\u786e\u7387\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u96be\u4ee5\u517c\u987e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6c34\u5370\u65b9\u6cd5MajorMark\uff0c\u901a\u8fc7\u57fa\u4e8e\u591a\u6570\u6bd4\u7279\u7684\u7f16\u7801\u7b56\u7565\u9009\u62e9\u4f18\u5148token\u96c6\u5408\uff0c\u4f7f\u5f97\u80fd\u591f\u66f4\u7075\u6d3b\u3001\u6269\u5927\u751f\u6210token\u7684\u8303\u56f4\uff0c\u540c\u65f6\u5f15\u5165\u57fa\u4e8e\u805a\u7c7b\u7684\u65b0\u578b\u89e3\u7801\u65b9\u6cd5\uff0c\u5728\u4f18\u5148token\u96c6\u5408\u8f83\u5927\u65f6\u4e5f\u80fd\u4fdd\u6301\u9ad8\u89e3\u7801\u51c6\u786e\u7387\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86MajorMark+\uff0c\u901a\u8fc7\u5206\u5757\u7f16\u7801\u548c\u786e\u5b9a\u6027\u89e3\u7801\u8fdb\u4e00\u6b65\u4f18\u5316\u6587\u672c\u8d28\u91cf\u548c\u89e3\u7801\u6027\u80fd\u3002", "result": "\u5728\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u663e\u793a\uff0cMajorMark\u548cMajorMark+\u5728\u89e3\u7801\u51c6\u786e\u7387\u548c\u6587\u672c\u751f\u6210\u8d28\u91cf\u65b9\u9762\u5747\u663e\u8457\u4f18\u4e8e\u5df2\u6709\u591a\u6bd4\u7279\u6c34\u5370\u65b9\u6cd5\u3002", "conclusion": "MajorMark\u53ca\u5176\u589e\u5f3a\u7248\u672cMajorMark+\u6709\u6548\u6539\u5584\u4e86\u6c34\u5370\u6587\u672c\u5728\u4fdd\u8bc1\u5185\u5bb9\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u591a\u6bd4\u7279\u6d88\u606f\u5d4c\u5165\u4e0e\u89e3\u7801\uff0c\u4e3a\u5b9e\u9645LLM\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u6eaf\u6e90\u548c\u9632\u6ee5\u7528\u6280\u672f\u65b9\u6848\u3002"}}
{"id": "2508.04352", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.04352", "abs": "https://arxiv.org/abs/2508.04352", "authors": ["Dragana Sunaric", "Charlotte Verbruggen", "Dominik Bork"], "title": "Vanilla-Converter: A Tool for Converting Camunda 7 BPMN Models into Camunda 8 Models", "comment": null, "summary": "As organizations prepare for the end-of-life of Camunda 7, manual migration\nremains complex due to fundamental differences between the two platforms. We\npresent Vanilla-Converter, a command-line tool that facilitates the migration\nof BPMN models from Camunda 7 to Camunda 8. Vanilla-Converter automates the\ntransformation process, supports a wide range of BPMN elements, and produces a\ntransformed model and a detailed transformation log indicating automatic\nchanges and remaining manual conversion tasks. The tool's effectiveness is\ndemonstrated through three case studies with real industrially used Camunda 7\nmodels, confirming its ability to convert these models into valid and\nexecutable Camunda 8 models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u8df5\u4e86\u8fc1\u79fb\u5de5\u5177 Vanilla-Converter\uff0c\u80fd\u81ea\u52a8\u5c06 Camunda 7 \u7684\u4e1a\u52a1\u6d41\u7a0b\u6a21\u578b\u9ad8\u6548\u8fc1\u79fb\u81f3 Camunda 8\uff0c\u5e76\u5728\u5b9e\u9645\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u7531\u4e8e Camunda 7 \u5373\u5c06\u505c\u6b62\u652f\u6301\uff0c\u4f01\u4e1a\u6025\u9700\u4fbf\u6377\u3001\u9ad8\u6548\u7684\u65b9\u6cd5\u5c06\u73b0\u6709 BPMN \u6a21\u578b\u8fc1\u79fb\u81f3 Camunda 8\uff0c\u7136\u800c\u4e24\u5e73\u53f0\u67b6\u6784\u5dee\u5f02\u5927\uff0c\u4eba\u5de5\u8fc1\u79fb\u6781\u4e3a\u590d\u6742\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u547d\u4ee4\u884c\u5de5\u5177 Vanilla-Converter\uff0c\u5bf9 Camunda 7 \u7684 BPMN \u6a21\u578b\u8fdb\u884c\u81ea\u52a8\u8f6c\u6362\uff0c\u652f\u6301\u591a\u79cd BPMN \u5143\u7d20\uff0c\u5e76\u8bb0\u5f55\u8be6\u7ec6\u7684\u8f6c\u6362\u65e5\u5fd7\u3002\u901a\u8fc7\u4e09\u4e2a\u771f\u5b9e\u5de5\u4e1a\u6848\u4f8b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u5bf9\u4e09\u4e2a\u5b9e\u9645\u5de5\u4e1a\u7528\u4f8b\u7684\u8f6c\u5316\u5b9e\u9a8c\uff0cVanilla-Converter \u6210\u529f\u5c06\u539f\u6709\u6a21\u578b\u8f6c\u4e3a Camunda 8 \u53ef\u7528\u3001\u53ef\u6267\u884c\u7684\u6a21\u578b\uff0c\u5177\u5907\u5b9e\u7528\u6027\u3002", "conclusion": "Vanilla-Converter \u5de5\u5177\u80fd\u591f\u6709\u6548\u5c06 Camunda 7 \u7684 BPMN \u6a21\u578b\u8fc1\u79fb\u5230 Camunda 8\uff0c\u751f\u6210\u53ef\u6267\u884c\u7684\u6a21\u578b\uff0c\u5e76\u8be6\u7ec6\u6807\u6ce8\u8f6c\u6362\u8fc7\u7a0b\u4e2d\u7684\u81ea\u52a8\u4e0e\u624b\u52a8\u4fee\u6539\u73af\u8282\u3002"}}
{"id": "2508.03860", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.03860", "abs": "https://arxiv.org/abs/2508.03860", "authors": ["Subhey Sadi Rahman", "Md. Adnanul Islam", "Md. Mahbub Alam", "Musarrat Zeba", "Md. Abdur Rahman", "Sadia Sultana Chowa", "Mohaimenul Azam Khan Raiaan", "Sami Azam"], "title": "Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models", "comment": "30 pages, 11 figures, 6 tables. Submitted to Artificial Intelligence\n  Review for peer review", "summary": "Large Language Models (LLMs) are trained on vast and diverse internet corpora\nthat often include inaccurate or misleading content. Consequently, LLMs can\ngenerate misinformation, making robust fact-checking essential. This review\nsystematically analyzes how LLM-generated content is evaluated for factual\naccuracy by exploring key challenges such as hallucinations, dataset\nlimitations, and the reliability of evaluation metrics. The review emphasizes\nthe need for strong fact-checking frameworks that integrate advanced prompting\nstrategies, domain-specific fine-tuning, and retrieval-augmented generation\n(RAG) methods. It proposes five research questions that guide the analysis of\nthe recent literature from 2020 to 2025, focusing on evaluation methods and\nmitigation techniques. The review also discusses the role of instruction\ntuning, multi-agent reasoning, and external knowledge access via RAG\nframeworks. Key findings highlight the limitations of current metrics, the\nvalue of grounding outputs with validated external evidence, and the importance\nof domain-specific customization to improve factual consistency. Overall, the\nreview underlines the importance of building LLMs that are not only accurate\nand explainable but also tailored for domain-specific fact-checking. These\ninsights contribute to the advancement of research toward more trustworthy and\ncontext-aware language models.", "AI": {"tldr": "\u672c\u7efc\u8ff0\u68b3\u7406\u4e86LLM\u4e8b\u5b9e\u6838\u67e5\u7684\u6311\u6218\u548c\u6700\u65b0\u65b9\u6cd5\uff0c\u6307\u51fa\u9700\u7ed3\u5408RAG\u3001\u9886\u57df\u5fae\u8c03\u7b49\u63d0\u5347\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u672a\u6765\u7814\u7a76\u5e94\u91cd\u89c6\u8bc4\u6d4b\u6307\u6807\u6539\u8fdb\u548c\u9886\u57df\u5b9a\u5236\u3002", "motivation": "\u7531\u4e8eLLM\u7684\u8bad\u7ec3\u6570\u636e\u5305\u542b\u5927\u91cf\u4e0d\u51c6\u786e\u6216\u8bef\u5bfc\u6027\u4fe1\u606f\uff0c\u5bfc\u81f4\u5176\u751f\u6210\u5185\u5bb9\u5bb9\u6613\u51fa\u73b0\u865a\u5047\u4fe1\u606f\u3002\u56e0\u6b64\uff0c\u5bf9LLM\u8f93\u51fa\u5185\u5bb9\u7684\u4e8b\u5b9e\u6838\u67e5\u548c\u4e00\u81f4\u6027\u8bc4\u4f30\u53d8\u5f97\u5c24\u4e3a\u91cd\u8981\u3002", "method": "\u672c\u6587\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u7684\u65b9\u6cd5\uff0c\u68b3\u7406\u5e76\u5206\u6790\u4e862020\u20142025\u5e74\u95f4\u5173\u4e8eLLM\u4e8b\u5b9e\u6027\u8bc4\u6d4b\u548c\u6539\u8fdb\u63aa\u65bd\u7684\u6700\u65b0\u7814\u7a76\uff0c\u5e76\u56f4\u7ed5\u4e94\u4e2a\u5173\u952e\u7814\u7a76\u95ee\u9898\u8fdb\u884c\u5f52\u7eb3\u3002", "result": "\u73b0\u6709\u8bc4\u6d4b\u6307\u6807\u5b58\u5728\u5c40\u9650\uff0c\u6709\u6548\u4e8b\u5b9e\u68c0\u9a8c\u9700\u7ed3\u5408\u9ad8\u9636\u7684\u63d0\u793a\u8bbe\u8ba1\u3001\u9886\u57df\u5fae\u8c03\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7b49\u65b9\u6cd5\u3002\u7279\u522b\u5f3a\u8c03\u5229\u7528\u53ef\u9760\u5916\u90e8\u8bc1\u636e\u3001\u9886\u57df\u5b9a\u5236\u65b9\u6cd5\u4ee5\u53ca\u591a\u4e3b\u4f53\u63a8\u7406\u548c\u6307\u4ee4\u5fae\u8c03\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u8f93\u51fa\u7684\u4e8b\u5b9e\u4e00\u81f4\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "conclusion": "\u8bba\u6587\u5f3a\u8c03\u9700\u8981\u6784\u5efa\u5177\u5907\u9886\u57df\u9002\u5e94\u6027\u3001\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684LLM\uff0c\u4ee5\u589e\u5f3a\u5176\u4e8b\u5b9e\u4e00\u81f4\u6027\u548c\u53ef\u9760\u6027\uff0c\u4ece\u800c\u63d0\u9ad8\u5176\u5728\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e0b\u7684\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2508.04408", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.04408", "abs": "https://arxiv.org/abs/2508.04408", "authors": ["Carlos Andr\u00e9s Ram\u00edrez Cata\u00f1o", "Makoto Itoh"], "title": "Breaking New Ground in Software Defect Prediction: Introducing Practical and Actionable Metrics with Superior Predictive Power for Enhanced Decision-Making", "comment": "16 pages, 2 figures, 2 formulas, 12 tables", "summary": "Software defect prediction using code metrics has been extensively researched\nover the past five decades. However, prediction harnessing non-software metrics\nis under-researched. Considering that the root cause of software defects is\noften attributed to human error, human factors theory might offer key\nforecasting metrics for actionable insights. This paper explores automated\nsoftware defect prediction at the method level based on the developers' coding\nhabits. First, we propose a framework for deciding the metrics to conduct\npredictions. Next, we compare the performance of our metrics to that of the\ncode and commit history metrics shown by research to achieve the highest\nperformance to date. Finally, we analyze the prediction importance of each\nmetric. As a result of our analyses of twenty-one critical infrastructure\nlarge-scale open-source software projects, we have presented: (1) a human\nerror-based framework with metrics useful for defect prediction at method\nlevel; (2) models using our proposed metrics achieve better average prediction\nperformance than the state-of-the-art code metrics and history measures; (3)\nthe prediction importance of all metrics distributes differently with each of\nthe novel metrics having better average importance than code and history\nmetrics; (4) the novel metrics dramatically enhance the explainability,\npracticality, and actionability of software defect prediction models,\nsignificantly advancing the field. We present a systematic approach to\nforecasting defect-prone software methods via a human error framework. This\nwork empowers practitioners to act on predictions, empirically demonstrating\nhow developer coding habits contribute to defects in software systems.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4eba\u7c7b\u9519\u8bef\u7406\u8bba\u7684\u7f3a\u9677\u9884\u6d4b\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u5f00\u53d1\u8005\u7f16\u7801\u4e60\u60ef\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7f3a\u9677\u9884\u6d4b\u7684\u6548\u679c\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u5b9e\u9645\u8f6f\u4ef6\u5f00\u53d1\u63d0\u4f9b\u4e86\u66f4\u5177\u6307\u5bfc\u610f\u4e49\u7684\u53c2\u8003\u3002", "motivation": "\u4ee5\u5f80\u7684\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b\u5927\u591a\u57fa\u4e8e\u4ee3\u7801\u5ea6\u91cf\uff0c\u4f46\u5f88\u5c11\u5173\u6ce8\u975e\u8f6f\u4ef6\u5c42\u9762\u7684\u6307\u6807\u3002\u4eba\u7c7b\u56e0\u7d20\uff0c\u7279\u522b\u662f\u5f00\u53d1\u8005\u7684\u7f16\u7a0b\u4e60\u60ef\uff0c\u53ef\u80fd\u662f\u7f3a\u9677\u7684\u6839\u672c\u539f\u56e0\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u63a2\u7d22\u57fa\u4e8e\u8fd9\u4e9b\u56e0\u7d20\u7684\u65b0\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u9009\u62e9\u9884\u6d4b\u6307\u6807\u7684\u6846\u67b6\uff0c\u91cd\u70b9\u5229\u7528\u5f00\u53d1\u8005\u7f16\u7801\u4e60\u60ef\u76f8\u5173\u7684\u6570\u636e\uff0c\u5e76\u5c06\u8fd9\u4e9b\u65b0\u6307\u6807\u4e0e\u5386\u53f2\u4e0a\u6027\u80fd\u6700\u597d\u7684\u4ee3\u7801\u5c42\u9762\u53ca\u63d0\u4ea4\u5386\u53f2\u6307\u6807\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002\u6700\u540e\u8fd8\u5206\u6790\u4e86\u5404\u9879\u6307\u6807\u5728\u9884\u6d4b\u6a21\u578b\u4e2d\u7684\u91cd\u8981\u7a0b\u5ea6\u3002", "result": "1\uff09\u9996\u6b21\u63d0\u51fa\u57fa\u4e8e\u4eba\u7c7b\u9519\u8bef\u7406\u8bba\u6784\u5efa\u7f3a\u9677\u9884\u6d4b\u6307\u6807\u7684\u6846\u67b6\uff1b2\uff09\u572821\u4e2a\u5927\u578b\u5f00\u6e90\u9879\u76ee\u5b9e\u9a8c\u4e2d\uff0c\u57fa\u4e8e\u8be5\u6846\u67b6\u7684\u65b0\u6a21\u578b\u5e73\u5747\u9884\u6d4b\u8868\u73b0\u8d85\u8fc7\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\uff1b3\uff09\u65b0\u6307\u6807\u5728\u6a21\u578b\u4e2d\u7684\u91cd\u8981\u6027\u901a\u5e38\u9ad8\u4e8e\u4f20\u7edf\u4ee3\u7801\u548c\u5386\u53f2\u6307\u6807\uff1b4\uff09\u8be5\u65b9\u6cd5\u6781\u5927\u63d0\u5347\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3001\u5b9e\u7528\u6027\u548c\u53ef\u64cd\u4f5c\u6027\u3002", "conclusion": "\u5c06\u5f00\u53d1\u8005\u7f16\u7a0b\u4e60\u60ef\u7b49\u4eba\u7c7b\u56e0\u7d20\u7eb3\u5165\u7f3a\u9677\u9884\u6d4b\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u51c6\u786e\u7387\uff0c\u8fd8\u8ba9\u9884\u6d4b\u7ed3\u679c\u66f4\u5177\u89e3\u91ca\u6027\u548c\u6307\u5bfc\u4ef7\u503c\uff0c\u63a8\u52a8\u4e86\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2508.03865", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.03865", "abs": "https://arxiv.org/abs/2508.03865", "authors": ["Yajie Luo", "Yihong Wu", "Muzhi Li", "Fengran Mo", "Jia Ao Sun", "Xinyu Wang", "Liheng Ma", "Yingxue Zhang", "Jian-Yun Nie"], "title": "An Entity Linking Agent for Question Answering", "comment": "12 pages, 2 figures. Submitted to AAAI 2026 Conference", "summary": "Some Question Answering (QA) systems rely on knowledge bases (KBs) to provide\naccurate answers. Entity Linking (EL) plays a critical role in linking natural\nlanguage mentions to KB entries. However, most existing EL methods are designed\nfor long contexts and do not perform well on short, ambiguous user questions in\nQA tasks. We propose an entity linking agent for QA, based on a Large Language\nModel that simulates human cognitive workflows. The agent actively identifies\nentity mentions, retrieves candidate entities, and makes decision. To verify\nthe effectiveness of our agent, we conduct two experiments: tool-based entity\nlinking and QA task evaluation. The results confirm the robustness and\neffectiveness of our agent.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u4f53\u94fe\u63a5\u667a\u80fd\u4f53\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u77ed\u6587\u672c\u95ee\u7b54\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u5b9e\u4f53\u94fe\u63a5\uff08EL\uff09\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u957f\u6587\u672c\u8bbe\u8ba1\uff0c\u9762\u5bf9\u95ee\u7b54\u4efb\u52a1\u4e2d\u8f83\u77ed\u4e14\u6a21\u7cca\u7684\u7528\u6237\u95ee\u9898\u8868\u73b0\u4e0d\u4f73\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u80dc\u4efb\u77ed\u6587\u672c\u95ee\u7b54\u573a\u666f\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u4f53\u94fe\u63a5\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u6d41\u7a0b\uff0c\u4e3b\u52a8\u8bc6\u522b\u5b9e\u4f53\u63d0\u53ca\u3001\u68c0\u7d22\u5907\u9009\u5b9e\u4f53\uff0c\u5e76\u505a\u51fa\u5224\u65ad\u3002", "result": "\u901a\u8fc7\u5b9e\u4f53\u94fe\u63a5\u5de5\u5177\u548c\u95ee\u7b54\u4efb\u52a1\u8bc4\u6d4b\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\u6240\u63d0\u51fa\u7684\u667a\u80fd\u4f53\u5728\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\u4e0a\u5747\u6709\u4f18\u5f02\u8868\u73b0\u3002", "conclusion": "\u8be5\u667a\u80fd\u4f53\u65b9\u6cd5\u80fd\u591f\u63d0\u5347\u95ee\u7b54\u7cfb\u7edf\u5728\u5904\u7406\u77ed\u5c0f\u3001\u6a21\u7cca\u95ee\u9898\u65f6\u7684\u5b9e\u4f53\u94fe\u63a5\u6027\u80fd\uff0c\u4e3a\u77e5\u8bc6\u5e93\u95ee\u7b54\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u7b54\u6848\u3002"}}
{"id": "2508.04448", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.04448", "abs": "https://arxiv.org/abs/2508.04448", "authors": ["Damian Gnieciak", "Tomasz Szandala"], "title": "Large Language Models Versus Static Code Analysis Tools: A Systematic Benchmark for Vulnerability Detection", "comment": null, "summary": "Modern software relies on a multitude of automated testing and quality\nassurance tools to prevent errors, bugs and potential vulnerabilities. This\nstudy sets out to provide a head-to-head, quantitative and qualitative\nevaluation of six automated approaches: three industry-standard rule-based\nstatic code-analysis tools (SonarQube, CodeQL and Snyk Code) and three\nstate-of-the-art large language models hosted on the GitHub Models platform\n(GPT-4.1, Mistral Large and DeepSeek V3). Using a curated suite of ten\nreal-world C# projects that embed 63 vulnerabilities across common categories\nsuch as SQL injection, hard-coded secrets and outdated dependencies, we measure\nclassical detection accuracy (precision, recall, F-score), analysis latency,\nand the developer effort required to vet true positives. The language-based\nscanners achieve higher mean F-1 scores,0.797, 0.753 and 0.750, than their\nstatic counterparts, which score 0.260, 0.386 and 0.546, respectively. LLMs'\nadvantage originates from superior recall, confirming an ability to reason\nacross broader code contexts. However, this benefit comes with substantial\ntrade-offs: DeepSeek V3 exhibits the highest false-positive ratio, all language\nmodels mislocate issues at line-or-column granularity due to tokenisation\nartefacts. Overall, language models successfully rival traditional static\nanalysers in finding real vulnerabilities. Still, their noisier output and\nimprecise localisation limit their standalone use in safety-critical audits. We\ntherefore recommend a hybrid pipeline: employ language models early in\ndevelopment for broad, context-aware triage, while reserving deterministic\nrule-based scanners for high-assurance verification. The open benchmark and\nJSON-based result harness released with this paper lay a foundation for\nreproducible, practitioner-centric research into next-generation automated code\nsecurity.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u6bd4\u8f83\u4e86\u4e3b\u6d41\u9759\u6001\u5206\u6790\u5de5\u5177\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5b9eC#\u9879\u76ee\u4e2d\u7684\u6f0f\u6d1e\u68c0\u6d4b\u8868\u73b0\u3002\u8bed\u8a00\u6a21\u578b\u53ec\u56de\u7387\u9ad8\u3001\u68c0\u6d4b\u80fd\u529b\u5f3a\uff0c\u4f46\u8bef\u62a5\u4e0e\u7cbe\u5ea6\u52a3\u52bf\u660e\u663e\u3002\u5efa\u8bae\u5b9e\u9645\u5f00\u53d1\u4e2d\u91c7\u7528\u6df7\u5408\u6d41\u7a0b\uff0c\u5c06\u5927\u6a21\u578b\u4e0e\u4f20\u7edf\u89c4\u5219\u5f15\u64ce\u5404\u53d6\u6240\u957f\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u9ad8\u5ea6\u4f9d\u8d56\u81ea\u52a8\u5316\u6d4b\u8bd5\u548c\u8d28\u91cf\u4fdd\u8bc1\u5de5\u5177\u4ee5\u9632\u6b62\u9519\u8bef\u3001\u6f0f\u6d1e\u548c\u6f5c\u5728\u7684\u5b89\u5168\u9690\u60a3\u3002\u8be5\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u73b0\u6709\u4e3b\u6d41\u9759\u6001\u4ee3\u7801\u5206\u6790\u5de5\u5177\u4e0e\u6700\u65b0\u5927\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4b\u5b89\u5168\u6f0f\u6d1e\u65b9\u9762\u7684\u4f18\u7f3a\u70b9\u548c\u9002\u7528\u6027\u3002", "method": "\u6bd4\u8f83\u4e86\u4e09\u79cd\u4e3b\u6d41\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u9759\u6001\u4ee3\u7801\u5206\u6790\u5de5\u5177\uff08SonarQube\u3001CodeQL\u548cSnyk Code\uff09\u4e0e\u4e09\u79cd\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08GPT-4.1\u3001Mistral Large\u548cDeepSeek V3\uff09\u3002\u5229\u7528\u5305\u542b63\u4e2a\u6f0f\u6d1e\u768410\u4e2a\u771f\u5b9eC#\u9879\u76ee\uff0c\u91cf\u5316\u5206\u6790\u5de5\u5177\u7684\u68c0\u6d4b\u7cbe\u5ea6\uff08precision\u3001recall\u3001F-score\uff09\u3001\u5206\u6790\u5ef6\u8fdf\u4ee5\u53ca\u6838\u67e5\u771f\u9633\u6027\u6240\u9700\u7684\u5f00\u53d1\u8005\u5de5\u4f5c\u91cf\u3002", "result": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e73\u5747F1\u5206\u6570\uff080.797\u30010.753\u30010.750\uff09\u660e\u663e\u9ad8\u4e8e\u9759\u6001\u5de5\u5177\uff080.260\u30010.386\u30010.546\uff09\uff0c\u4e3b\u8981\u6765\u6e90\u4e8e\u66f4\u9ad8\u7684\u53ec\u56de\u7387\uff0c\u663e\u793a\u4e86\u5176\u8de8\u4ee3\u7801\u4e0a\u4e0b\u6587\u63a8\u7406\u7684\u80fd\u529b\u3002\u4f46\u7f3a\u70b9\u5305\u62ec\u8bef\u62a5\u8f83\u9ad8\u4e14\u5b9a\u4f4d\u6f0f\u6d1e\u7684\u7cbe\u5ea6\u8f83\u5dee\uff0c\u96be\u4ee5\u5728\u5173\u952e\u5b89\u5168\u5ba1\u8ba1\u4e2d\u5355\u72ec\u4f7f\u7528\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4e0a\u53ef\u4e0e\u4f20\u7edf\u9759\u6001\u5206\u6790\u5de5\u5177\u7ade\u4e89\uff0c\u4f46\u4ec5\u4f9d\u8d56\u5176\u8f93\u51fa\u4e0d\u9002\u5408\u9ad8\u5b89\u5168\u573a\u666f\u3002\u63a8\u8350\u7ed3\u5408\u4f7f\u7528\uff1a\u5f00\u53d1\u65e9\u671f\u7528\u5927\u6a21\u578b\u505a\u5e7f\u8986\u76d6\u521d\u7b5b\uff0c\u5173\u952e\u9636\u6bb5\u7528\u89c4\u5219\u5f15\u64ce\u505a\u7cbe\u786e\u9a8c\u8bc1\u3002\u540c\u65f6\uff0c\u8be5\u7814\u7a76\u516c\u5f00\u4e86\u57fa\u51c6\u6570\u636e\u96c6\u4e0e\u7ed3\u679c\u5904\u7406\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u540e\u7eed\u53ef\u590d\u73b0\u7814\u7a76\u3002"}}
{"id": "2508.03905", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.03905", "abs": "https://arxiv.org/abs/2508.03905", "authors": ["Haofei Yu", "Zhengyang Qi", "Yining Zhao", "Kolby Nottingham", "Keyang Xuan", "Bodhisattwa Prasad Majumder", "Hao Zhu", "Paul Pu Liang", "Jiaxuan You"], "title": "Sotopia-RL: Reward Design for Social Intelligence", "comment": "10 pages", "summary": "Social intelligence has become a critical capability for large language\nmodels (LLMs), enabling them to engage effectively in real-world social tasks\nsuch as accommodation, persuasion, collaboration, and negotiation.\nReinforcement learning (RL) is a natural fit for training socially intelligent\nagents because it allows models to learn sophisticated strategies directly\nthrough social interactions. However, social interactions have two key\ncharacteristics that set barriers for RL training: (1) partial observability,\nwhere utterances have indirect and delayed effects that complicate credit\nassignment, and (2) multi-dimensionality, where behaviors such as\nrapport-building or knowledge-seeking contribute indirectly to goal\nachievement. These characteristics make Markov decision process (MDP)-based RL\nwith single-dimensional episode-level rewards inefficient and unstable. To\naddress these challenges, we propose Sotopia-RL, a novel framework that refines\ncoarse episode-level feedback into utterance-level, multi-dimensional rewards.\nUtterance-level credit assignment mitigates partial observability by\nattributing outcomes to individual utterances, while multi-dimensional rewards\ncapture the full richness of social interactions and reduce reward hacking.\nExperiments in Sotopia, an open-ended social learning environment, demonstrate\nthat Sotopia-RL achieves state-of-the-art social goal completion scores (7.17\non Sotopia-hard and 8.31 on Sotopia-full), significantly outperforming existing\napproaches. Ablation studies confirm the necessity of both utterance-level\ncredit assignment and multi-dimensional reward design for RL training. Our\nimplementation is publicly available at:\nhttps://github.com/sotopia-lab/sotopia-rl.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSotopia-RL\uff0c\u901a\u8fc7\u8bdd\u8bed\u7ea7\u3001\u591a\u7ef4\u56de\u62a5\u4f18\u5316\u793e\u4ea4\u667a\u80fdRL\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u5927\u6a21\u578b\u793e\u4ea4\u4efb\u52a1\u8868\u73b0\uff0c\u5e76\u5728\u516c\u5f00\u73af\u5883\u4e2d\u5b9e\u73b0\u6700\u4f18\u6210\u7ee9\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u7684\u793e\u4ea4\u4efb\u52a1\u65f6\uff0c\u5bf9\u793e\u4ea4\u667a\u80fd\u7684\u9700\u6c42\u4e0d\u65ad\u4e0a\u5347\u3002\u7136\u800c\uff0c\u5229\u7528\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8bad\u7ec3\u5177\u5907\u793e\u4ea4\u667a\u80fd\u7684\u6a21\u578b\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u4e00\u662f\u4e92\u52a8\u7684\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u5bfc\u81f4\u56de\u62a5\u5f52\u56e0\u56f0\u96be\uff1b\u4e8c\u662f\u793e\u4ea4\u884c\u4e3a\u5177\u6709\u591a\u7ef4\u76ee\u6807\uff0c\u5355\u4e00\u7ef4\u5ea6\u7684\u56de\u62a5\u8bbe\u8ba1\u65e0\u6cd5\u8986\u76d6\u5176\u590d\u6742\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6Sotopia-RL\uff0c\u8be5\u65b9\u6cd5\u5c06\u539f\u672c\u7c97\u7c92\u5ea6\u7684\u56de\u62a5\uff08\u5982\u6bcf\u4e2aepisode\u7684\u56de\u62a5\uff09\u7ec6\u5206\u4e3a\u8bdd\u8bed\u7ea7\u522b\uff0c\u5e76\u5f15\u5165\u591a\u7ef4\u5ea6\u7684\u56de\u62a5\u673a\u5236\u3002\u8fd9\u6837\u80fd\u591f\u66f4\u597d\u5730\u8fdb\u884c\u4fe1\u7528\u5206\u914d\uff0c\u5e76\u5168\u9762\u6355\u83b7\u793e\u4ea4\u4e92\u52a8\u7684\u591a\u6837\u6027\u3002", "result": "Sotopia-RL\u5728\u5f00\u653e\u5f0f\u793e\u4ea4\u5b66\u4e60\u73af\u5883Sotopia\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u793e\u4ea4\u76ee\u6807\u5b8c\u6210\u7387\uff08\u5728Sotopia-hard\u4e0a\u4e3a7.17\uff0cSotopia-full\u4e0a\u4e3a8.31\uff09\uff0c\u663e\u8457\u4f18\u4e8e\u5df2\u6709\u65b9\u6cd5\u3002\u6d88\u878d\u5b9e\u9a8c\u663e\u793a\uff0c\u8bdd\u8bed\u7ea7\u4fe1\u7528\u5206\u914d\u548c\u591a\u7ef4\u56de\u62a5\u8bbe\u8ba1\u5bf9\u4e8e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u9488\u5bf9\u793e\u4ea4\u667a\u80fd\u8bad\u7ec3\u4e2d\u7684\u96be\u9898\uff0cSotopia-RL\u901a\u8fc7\u7ec6\u7c92\u5ea6\u548c\u591a\u7ef4\u5ea6\u7684\u5956\u52b1\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u6a21\u578b\u5728\u793e\u4ea4\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4e3a\u793e\u4ea4\u667a\u80fdRL\u8bad\u7ec3\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.04479", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.04479", "abs": "https://arxiv.org/abs/2508.04479", "authors": ["Hashini Gunatilake", "John Grundy", "Rashina Hoda", "Ingo Mueller"], "title": "Manifestations of Empathy in Software Engineering: How, Why, and When It Matters", "comment": null, "summary": "Empathy plays a crucial role in software engineering (SE), influencing\ncollaboration, communication, and decision-making. While prior research has\nhighlighted the importance of empathy in SE, there is limited understanding of\nhow empathy manifests in SE practice, what motivates SE practitioners to\ndemonstrate empathy, and the factors that influence empathy in SE work. Our\nstudy explores these aspects through 22 interviews and a large scale survey\nwith 116 software practitioners. Our findings provide insights into the\nexpression of empathy in SE, the drivers behind empathetic practices, SE\nactivities where empathy is perceived as useful or not, and the other factors\nthat influence empathy. In addition, we offer practical implications for SE\npractitioners and researchers, offering a deeper understanding of how to\neffectively integrate empathy into SE processes.", "AI": {"tldr": "\u901a\u8fc7\u6df1\u5ea6\u8bbf\u8c08\u548c\u95ee\u5377\u8c03\u67e5\uff0c\u672c\u7814\u7a76\u5168\u9762\u5206\u6790\u4e86\u540c\u7406\u5fc3\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u8868\u73b0\u3001\u52a8\u673a\u53ca\u5f71\u54cd\u56e0\u7d20\uff0c\u5e76\u63d0\u51fa\u76f8\u5173\u5b9e\u8df5\u5efa\u8bae\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u867d\u7136\u5f3a\u8c03\u540c\u7406\u5fc3\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u4f46\u5bf9\u4e8e\u5b9e\u9645\u5de5\u4f5c\u4e2d\u540c\u7406\u5fc3\u7684\u4f53\u73b0\u3001\u52a8\u56e0\u53ca\u5f71\u54cd\u56e0\u7d20\u7f3a\u4e4f\u7cfb\u7edf\u7406\u89e3\u3002", "method": "\u91c7\u7528\u4e8622\u4e2a\u6df1\u5ea6\u8bbf\u8c08\u548c116\u540d\u8f6f\u4ef6\u4ece\u4e1a\u8005\u7684\u5927\u89c4\u6a21\u95ee\u5377\u8c03\u67e5\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u7cfb\u7edf\u603b\u7ed3\u4e86\u540c\u7406\u5fc3\u5728SE\u6d3b\u52a8\u4e2d\u7684\u5916\u5728\u8868\u73b0\u3001\u9a71\u52a8\u56e0\u7d20\u3001\u5728\u54ea\u4e9b\u6d3b\u52a8\u4e2d\u88ab\u8ba4\u4e3a\u6709\u7528\u6216\u65e0\u7528\uff0c\u4ee5\u53ca\u5f71\u54cd\u540c\u7406\u5fc3\u7684\u5176\u4ed6\u56e0\u7d20\uff0c\u5e76\u9488\u5bf9\u4ece\u4e1a\u8005\u548c\u7814\u7a76\u8005\u7ed9\u51fa\u4e86\u5b9e\u8df5\u542f\u793a\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u540c\u7406\u5fc3\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u4e2d\u7684\u591a\u79cd\u8868\u73b0\u5f62\u5f0f\u3001\u52a8\u673a\u4ee5\u53ca\u5f71\u54cd\u56e0\u7d20\uff0c\u5e76\u63d0\u51fa\u4e86\u5c06\u540c\u7406\u5fc3\u6709\u6548\u878d\u5165\u8f6f\u4ef6\u5de5\u7a0b\u6d41\u7a0b\u7684\u5efa\u8bae\u3002"}}
{"id": "2508.03923", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.03923", "abs": "https://arxiv.org/abs/2508.03923", "authors": ["Linxin Song", "Yutong Dai", "Viraj Prabhu", "Jieyu Zhang", "Taiwei Shi", "Li Li", "Junnan Li", "Silvio Savarese", "Zeyuan Chen", "Jieyu Zhao", "Ran Xu", "Caiming Xiong"], "title": "CoAct-1: Computer-using Agents with Coding as Actions", "comment": null, "summary": "Autonomous agents that operate computers via Graphical User Interfaces (GUIs)\noften struggle with efficiency and reliability on complex, long-horizon tasks.\nWhile augmenting these agents with planners can improve task decomposition,\nthey remain constrained by the inherent limitations of performing all actions\nthrough GUI manipulation, leading to brittleness and inefficiency. In this\nwork, we introduce a more robust and flexible paradigm: enabling agents to use\ncoding as a enhanced action. We present CoAct-1, a novel multi-agent system\nthat synergistically combines GUI-based control with direct programmatic\nexecution. CoAct-1 features an Orchestrator that dynamically delegates subtasks\nto either a conventional GUI Operator or a specialized Programmer agent, which\ncan write and execute Python or Bash scripts. This hybrid approach allows the\nagent to bypass inefficient GUI action sequences for tasks like file management\nand data processing, while still leveraging visual interaction when necessary.\nWe evaluate our system on the challenging OSWorld benchmark, where CoAct-1\nachieves a new state-of-the-art success rate of 60.76%, significantly\noutperforming prior methods. Furthermore, our approach dramatically improves\nefficiency, reducing the average number of steps required to complete a task to\njust 10.15, compared to 15 for leading GUI agents. Our results demonstrate that\nintegrating coding as a core action provides a more powerful, efficient, and\nscalable path toward generalized computer automation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408GUI\u64cd\u4f5c\u548c\u4ee3\u7801\u6267\u884c\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edfCoAct-1\uff0c\u5728\u81ea\u52a8\u5316\u590d\u6742\u7535\u8111\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u548c\u6210\u529f\u7387\uff0c\u5f00\u8f9f\u4e86\u66f4\u901a\u7528\u9ad8\u6548\u7684\u8ba1\u7b97\u673a\u81ea\u4e3b\u4ee3\u7406\u65b0\u65b9\u5411\u3002", "motivation": "\u73b0\u6709\u901a\u8fc7\u56fe\u5f62\u754c\u9762\uff08GUI\uff09\u64cd\u4f5c\u8ba1\u7b97\u673a\u7684\u81ea\u4e3b\u4ee3\u7406\uff0c\u5728\u5904\u7406\u590d\u6742\u3001\u957f\u671f\u4efb\u52a1\u65f6\u6548\u7387\u4f4e\u4e14\u6613\u51fa\u9519\u3002\u867d\u7136\u5f15\u5165\u89c4\u5212\u5668\u53ef\u4ee5\u6539\u8fdb\u4efb\u52a1\u5206\u89e3\uff0c\u4f46\u5b8c\u5168\u4f9d\u8d56GUI\u64cd\u4f5c\u672c\u8eab\u5b58\u5728\u56fa\u6709\u9650\u5236\uff0c\u9020\u6210\u4f4e\u6548\u548c\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51faCoAct-1\u7cfb\u7edf\uff0c\u5c06\u4f20\u7edfGUI\u64cd\u4f5c\u548c\u76f4\u63a5\u7f16\u7a0b\u6267\u884c\u7ed3\u5408\u3002\u8be5\u7cfb\u7edf\u5305\u542b\u4e00\u4e2a\u8c03\u5ea6\u8005\uff0c\u80fd\u591f\u6839\u636e\u4efb\u52a1\u7279\u6027\u52a8\u6001\u5206\u914d\u5b50\u4efb\u52a1\u7ed9GUI\u64cd\u4f5c\u5458\u6216\u7a0b\u5e8f\u5458\u4ee3\u7406\uff08\u540e\u8005\u53ef\u7f16\u5199\u6267\u884cPython\u6216Bash\u811a\u672c\uff09\u3002", "result": "CoAct-1\u5728OSWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e8660.76%\u7684\u6700\u65b0\u6700\u4f18\u6210\u529f\u7387\uff0c\u663e\u8457\u8d85\u8fc7\u5148\u524d\u65b9\u6cd5\uff1b\u540c\u65f6\u5e73\u5747\u4efb\u52a1\u6b65\u9aa4\u51cf\u81f310.15\u6b65\uff0c\u4f18\u4e8e\u4ec5\u4f9d\u8d56GUI\u768415\u6b65\u3002", "conclusion": "\u5c06\u7f16\u7a0b\u4f5c\u4e3a\u6838\u5fc3\u64cd\u4f5c\uff0c\u7ed3\u5408GUI\u548c\u4ee3\u7801\u6267\u884c\u7684\u65b9\u6cd5\uff0c\u4f7f\u5f97\u81ea\u4e3b\u4ee3\u7406\u7cfb\u7edf\u5728\u901a\u7528\u81ea\u52a8\u5316\u4efb\u52a1\u4e0a\u66f4\u9ad8\u6548\u3001\u5f3a\u5927\u3001\u5177\u5907\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2508.03935", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.03935", "abs": "https://arxiv.org/abs/2508.03935", "authors": ["Raymond Wilson", "Cole Graham", "Chase Carter", "Zefeng Yang", "Ruiqi Gu"], "title": "CAP-LLM: Context-Augmented Personalized Large Language Models for News Headline Generation", "comment": null, "summary": "In the era of information overload, personalized news headline generation is\ncrucial for engaging users by tailoring content to their preferences while\naccurately conveying news facts. Existing methods struggle with effectively\ncapturing complex user interests and ensuring factual consistency, often\nleading to generic or misleading headlines. Leveraging the unprecedented\ncapabilities of Large Language Models (LLMs) in text generation, we propose\nContext-Augmented Personalized LLM (CAP-LLM), a novel framework that integrates\nuser preferences and factual consistency constraints into a powerful\npre-trained LLM backbone. CAP-LLM features a User Preference Encoder to capture\nlong-term user interests, a Context Injection Adapter to seamlessly integrate\nthese preferences and current article context into the LLM's generation\nprocess, and a Fact-Consistency Reinforcement Module employing a novel\ncontrastive loss to mitigate hallucination. Evaluated on the real-world PENS\ndataset, CAP-LLM achieves state-of-the-art performance across all metrics.\nNotably, it significantly improves factual consistency (FactCC of 87.50) over\nstrong baselines like BART (86.67), while simultaneously enhancing\npersonalization (Pc(avg) 2.73, Pc(max) 17.25) and content coverage (ROUGE-1\n26.55, ROUGE-2 9.95, ROUGE-L 23.01). Our ablation studies, human evaluations,\nand sensitivity analyses further validate the effectiveness of each component\nand the robustness of our approach, demonstrating CAP-LLM's ability to achieve\na superior balance between personalization and factual accuracy in news\nheadline generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684CAP-LLM\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u7528\u6237\u504f\u597d\u4e0e\u4e8b\u5b9e\u4e00\u81f4\u6027\u7ea6\u675f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65b0\u95fb\u5934\u6761\u7684\u4e2a\u6027\u5316\u548c\u51c6\u786e\u6027\uff0c\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u8d85\u8fc7\u73b0\u6709\u6700\u5f3a\u65b9\u6cd5\u3002", "motivation": "\u5728\u4fe1\u606f\u8fc7\u8f7d\u65f6\u4ee3\uff0c\u7528\u6237\u5bf9\u65b0\u95fb\u5934\u6761\u7684\u4e2a\u6027\u5316\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\u6709\u66f4\u9ad8\u9700\u6c42\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5145\u5206\u6355\u6349\u590d\u6742\u7528\u6237\u5174\u8da3\u4e14\u6613\u5f15\u5165\u4e8b\u5b9e\u9519\u8bef\uff0c\u5bfc\u81f4\u5934\u6761\u540c\u8d28\u5316\u6216\u8bef\u5bfc\u6027\u5f3a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCAP-LLM\u7684\u65b0\u578b\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u96c6\u6210\u7528\u6237\u504f\u597d\u548c\u4e8b\u5b9e\u4e00\u81f4\u6027\u7ea6\u675f\u3002\u5176\u7ed3\u6784\u5305\u62ec\uff1a\u7528\u6237\u504f\u597d\u7f16\u7801\u5668\u7528\u4e8e\u6355\u6349\u957f\u671f\u5174\u8da3\uff1b\u4e0a\u4e0b\u6587\u6ce8\u5165\u9002\u914d\u5668\u878d\u5408\u7528\u6237\u4e0e\u65b0\u95fb\u4e0a\u4e0b\u6587\u8fdb\u751f\u6210\u8fc7\u7a0b\uff1b\u4e8b\u5b9e\u4e00\u81f4\u6027\u589e\u5f3a\u6a21\u5757\u901a\u8fc7\u5bf9\u6bd4\u635f\u5931\u51cf\u5c11\u865a\u5047\u5185\u5bb9\u3002", "result": "\u5728\u771f\u5b9ePENS\u6570\u636e\u96c6\u4e0a\uff0c\u5404\u9879\u6307\u6807\u5747\u8fbe\u6700\u65b0\u6700\u4f18\u6c34\u5e73\u3002\u5982\u4e8b\u5b9e\u4e00\u81f4\u6027FactCC\u9ad8\u8fbe87.50\uff0c\u660e\u663e\u4f18\u4e8eBART\uff0886.67\uff09\uff1b\u4e2a\u6027\u5316\u548c\u4fe1\u606f\u8986\u76d6\u6307\u6807\u5747\u663e\u8457\u63d0\u5347\uff08\u5982ROUGE\u5404\u9879\u5206\u6570\u5747\u4e3a\u9886\u57df\u9886\u5148\uff09\u3002\u6d88\u878d\u3001\u4eba\u5de5\u548c\u654f\u611f\u6027\u5b9e\u9a8c\u5747\u9a8c\u8bc1\u4e86\u5404\u7ec4\u4ef6\u548c\u65b9\u6cd5\u7684\u6709\u6548\u6027\u4e0e\u7a33\u5065\u6027\u3002", "conclusion": "CAP-LLM\u80fd\u591f\u6709\u6548\u63d0\u5347\u65b0\u95fb\u5934\u6761\u751f\u6210\u4e2d\u7684\u4e2a\u6027\u5316\u548c\u4e8b\u5b9e\u4e00\u81f4\u6027\uff0c\u5b9e\u73b0\u4e86\u4e24\u8005\u7684\u4f18\u8d28\u5e73\u8861\u3002"}}
{"id": "2508.03970", "categories": ["cs.CL", "cs.AI", "68T01 (Primary), 68T50 (Secondary)", "I.2.0; I.2.7"], "pdf": "https://arxiv.org/pdf/2508.03970", "abs": "https://arxiv.org/abs/2508.03970", "authors": ["Alok Abhishek", "Lisa Erickson", "Tushar Bandopadhyay"], "title": "Data and AI governance: Promoting equity, ethics, and fairness in large language models", "comment": "Published in MIT Science Policy Review 6, 139-146 (2025)", "summary": "In this paper, we cover approaches to systematically govern, assess and\nquantify bias across the complete life cycle of machine learning models, from\ninitial development and validation to ongoing production monitoring and\nguardrail implementation. Building upon our foundational work on the Bias\nEvaluation and Assessment Test Suite (BEATS) for Large Language Models, the\nauthors share prevalent bias and fairness related gaps in Large Language Models\n(LLMs) and discuss data and AI governance framework to address Bias, Ethics,\nFairness, and Factuality within LLMs. The data and AI governance approach\ndiscussed in this paper is suitable for practical, real-world applications,\nenabling rigorous benchmarking of LLMs prior to production deployment,\nfacilitating continuous real-time evaluation, and proactively governing LLM\ngenerated responses. By implementing the data and AI governance across the life\ncycle of AI development, organizations can significantly enhance the safety and\nresponsibility of their GenAI systems, effectively mitigating risks of\ndiscrimination and protecting against potential reputational or brand-related\nharm. Ultimately, through this article, we aim to contribute to advancement of\nthe creation and deployment of socially responsible and ethically aligned\ngenerative artificial intelligence powered applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u5957\u8986\u76d6\u5f00\u53d1\u5230\u8fd0\u8425\u5168\u8fc7\u7a0b\u7684\u5927\u6a21\u578b\u504f\u89c1\u4e0e\u516c\u5e73\u6027\u6cbb\u7406\u4f53\u7cfb\uff0c\u6269\u5c55BEATS\u5de5\u5177\uff0c\u5b9e\u73b0\u5bf9\u6a21\u578b\u7684\u6301\u7eed\u8bc4\u4f30\u548c\u98ce\u9669\u9632\u63a7\uff0c\u4e3a\u751f\u6210\u5f0fAI\u5b89\u5168\u5e94\u7528\u63d0\u4f9b\u5b9e\u8df5\u65b9\u6848\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u53d1\u5c55\u548c\u5e94\u7528\u8fc7\u7a0b\u4e2d\uff0c\u5bb9\u6613\u51fa\u73b0\u504f\u89c1\u3001\u4e0d\u516c\u5e73\u548c\u4e8b\u5b9e\u9519\u8bef\u7b49\u4f26\u7406\u53ca\u5b89\u5168\u98ce\u9669\u3002\u5f53\u524d\u7684\u6cbb\u7406\u548c\u8bc4\u4f30\u65b9\u6cd5\u96be\u4ee5\u7cfb\u7edf\u8986\u76d6\u6574\u4e2a\u673a\u5668\u5b66\u4e60\u6a21\u578b\u751f\u547d\u5468\u671f\uff0c\u5b9e\u9645\u843d\u5730\u4e9f\u9700\u5b8c\u5584\u7684\u6846\u67b6\u4e0e\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u5e76\u63a8\u5e7f\u4e86\u4e00\u6574\u5957\u6570\u636e\u4e0eAI\u6cbb\u7406\u65b9\u6cd5\uff0c\u6db5\u76d6\u6a21\u578b\u5f00\u53d1\u3001\u9a8c\u8bc1\u3001\u751f\u4ea7\u4e0a\u7ebf\u53ca\u76d1\u63a7\u7b49\u5404\u9636\u6bb5\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u6269\u5c55\u4e86\u5df2\u6709\u7684\u504f\u89c1\u8bc4\u4f30\u5de5\u5177\uff08BEATS\uff09\uff0c\u7ed3\u5408\u6cbb\u7406\u6846\u67b6\uff0c\u7cfb\u7edf\u5bf9LLM\u7684\u504f\u89c1\u3001\u4f26\u7406\u3001\u516c\u5e73\u6027\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\u8fdb\u884c\u68c0\u6d4b\u4e0e\u7ba1\u7406\u3002", "result": "\u8fd9\u79cd\u65b9\u6cd5\u53ef\u5728\u751f\u4ea7\u90e8\u7f72\u524d\u4e3aLLM\u8fdb\u884c\u4e25\u683c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u652f\u6301\u6301\u7eed\u3001\u5b9e\u65f6\u8bc4\u4f30\u548c\u4e3b\u52a8\u89c4\u63a7\uff0c\u6709\u6548\u589e\u5f3a\u751f\u6210\u5f0fAI\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u8d23\u4efb\u611f\uff0c\u51cf\u5c11\u6b67\u89c6\u548c\u58f0\u8a89\u98ce\u9669\u3002", "conclusion": "\u901a\u8fc7\u5168\u751f\u547d\u5468\u671f\u7684\u6570\u636e\u548cAI\u6cbb\u7406\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u751f\u6210\u5f0fAI\u7684\u793e\u4f1a\u8d23\u4efb\u4e0e\u4f26\u7406\u5951\u5408\uff0c\u4e3a\u5b89\u5168\u3001\u53ef\u4fe1\u7684AI\u5e94\u7528\u843d\u5730\u63d0\u4f9b\u5207\u5b9e\u4fdd\u969c\u3002"}}
{"id": "2508.03979", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.03979", "abs": "https://arxiv.org/abs/2508.03979", "authors": ["Md Arafat Sultan", "Ram\u00f3n Fernandez Astudillo"], "title": "Confidence-Weighted Token Set Cover for Early Hypothesis Pruning in Self-Consistency", "comment": null, "summary": "Despite its simplicity and efficacy, the high token expenditure of\nself-consistency can limit its practical utility. Here we investigate if\nself-consistency can be made more token-efficient for long chain-of-thought\nreasoning tasks, while preserving its parallelism, through early hypothesis\npruning. Concretely, we generate all solutions in parallel, but periodically\nprune intermediate hypotheses that are deemed unnecessary based on two\nlightweight indicators: (a) the model's own confidence in individual\nhypotheses, and (b) lexical coverage of all current hypotheses by candidate\nsubsets that are under consideration for continued retention. We design a fast\nweighted set cover algorithm that utilizes the two indicators; our evaluation\nof five LLMs on three math benchmarks shows that this method can improve token\nefficiency for all models, by 10-35% in many cases.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u65e9\u671f\u5047\u8bbe\u526a\u679d\u63d0\u5347\u81ea\u4e00\u81f4\u6027token\u6548\u7387\u7684\u65b9\u6cd5\uff0c\u5e76\u5728\u591a\u4e2a\u6a21\u578b\u548c\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\uff0c\u8282\u770110-35%\u7684token\u6d88\u8017\u3002", "motivation": "\u81ea\u4e00\u81f4\u6027\u65b9\u6cd5\u867d\u7136\u7b80\u5355\u4e14\u6709\u6548\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7531\u4e8e\u9700\u8981\u6d88\u8017\u5927\u91cf\u7684token\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u957f\u94fe\u601d\u7ef4\u63a8\u7406\u4efb\u52a1\u65f6\uff0c\u4f7f\u7528\u53d7\u9650\u3002\u8bba\u6587\u5e0c\u671b\u5728\u4fdd\u6301\u5e76\u884c\u6027\u7684\u57fa\u7840\u4e0a\uff0c\u63d0\u9ad8token\u6548\u7387\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u901a\u8fc7\u65e9\u671f\u5047\u8bbe\u526a\u679d\u63d0\u5347\u81ea\u4e00\u81f4\u6027\u63a8\u7406\u7684token\u6548\u7387\u3002\u5177\u4f53\u505a\u6cd5\u662f\u5728\u5e76\u884c\u751f\u6210\u6240\u6709\u89e3\u7b54\u7684\u540c\u65f6\uff0c\u5468\u671f\u6027\u5730\u5229\u7528\u4e24\u79cd\u8f7b\u91cf\u7ea7\u6307\u6807\uff08\u6a21\u578b\u5bf9\u5355\u72ec\u5047\u8bbe\u7684\u7f6e\u4fe1\u5ea6\u4ee5\u53ca\u5047\u8bbe\u96c6\u5408\u7684\u8bcd\u6c47\u8986\u76d6\u7387\uff09\u526a\u9664\u4e0d\u5fc5\u8981\u7684\u4e2d\u95f4\u5047\u8bbe\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5feb\u901f\u52a0\u6743\u96c6\u5408\u8986\u76d6\u7b97\u6cd5\u6765\u5b9e\u73b0\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u5b66\u57fa\u51c6\u4efb\u52a1\u548c\u4e94\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u63d0\u5347\u6240\u6709\u6a21\u578b10-35%\u7684token\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u65e9\u671f\u5047\u8bbe\u526a\u679d\uff0c\u53ef\u5728\u4e0d\u635f\u5931\u5e76\u884c\u6027\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u4efb\u52a1\u4e2d\u7684token\u6548\u7387\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.03990", "categories": ["cs.CL", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.03990", "abs": "https://arxiv.org/abs/2508.03990", "authors": ["Bohan Jiang", "Dawei Li", "Zhen Tan", "Chengshuai Zhao", "Huan Liu"], "title": "Are Today's LLMs Ready to Explain Well-Being Concepts?", "comment": "9 pages, 4 figures, 3 tables", "summary": "Well-being encompasses mental, physical, and social dimensions essential to\npersonal growth and informed life decisions. As individuals increasingly\nconsult Large Language Models (LLMs) to understand well-being, a key challenge\nemerges: Can LLMs generate explanations that are not only accurate but also\ntailored to diverse audiences? High-quality explanations require both factual\ncorrectness and the ability to meet the expectations of users with varying\nexpertise. In this work, we construct a large-scale dataset comprising 43,880\nexplanations of 2,194 well-being concepts, generated by ten diverse LLMs. We\nintroduce a principle-guided LLM-as-a-judge evaluation framework, employing\ndual judges to assess explanation quality. Furthermore, we show that\nfine-tuning an open-source LLM using Supervised Fine-Tuning (SFT) and Direct\nPreference Optimization (DPO) can significantly enhance the quality of\ngenerated explanations. Our results reveal: (1) The proposed LLM judges align\nwell with human evaluations; (2) explanation quality varies significantly\nacross models, audiences, and categories; and (3) DPO- and SFT-finetuned models\noutperform their larger counterparts, demonstrating the effectiveness of\npreference-based learning for specialized explanation tasks.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6784\u5efa\u5927\u578b\u6570\u636e\u96c6\u548c\u4ee5LLM\u4e3a\u5224\u5b98\u7684\u8bc4\u4ef7\u4f53\u7cfb\uff0c\u8bc1\u660e\u4e86\u9488\u5bf9\u5e78\u798f\u611f\u76f8\u5173\u77e5\u8bc6\uff0cLLM\u7684\u89e3\u91ca\u8d28\u91cf\u53ef\u901a\u8fc7\u504f\u597d\u5fae\u8c03\u5927\u5e45\u63d0\u5347\uff0c\u4e14\u5fae\u8c03\u540e\u7684\u5c0f\u6a21\u578b\u53ef\u8d85\u8d8a\u66f4\u5927\u4f46\u672a\u7ecf\u4f18\u5316\u7684\u6a21\u578b\u3002", "motivation": "\u968f\u7740\u8d8a\u6765\u8d8a\u591a\u7684\u4eba\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u83b7\u53d6\u6709\u5173\u5e78\u798f\u611f\uff08well-being\uff09\u4fe1\u606f\uff0c\u5982\u4f55\u8ba9LLM\u751f\u6210\u65e2\u7cbe\u51c6\u53c8\u80fd\u9002\u5e94\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u9700\u6c42\u7684\u89e3\u91ca\uff0c\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002\u8be5\u95ee\u9898\u7684\u6838\u5fc3\u5728\u4e8e\uff0c\u89e3\u91ca\u4e0d\u4ec5\u8981\u4e8b\u5b9e\u6b63\u786e\uff0c\u8fd8\u9700\u80fd\u591f\u6ee1\u8db3\u4e0d\u540c\u4e13\u4e1a\u80cc\u666f\u7528\u6237\u7684\u671f\u671b\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5305\u542b\u6765\u81ea\u5341\u4e2a\u4e0d\u540cLLM\u768443,880\u6761\u5173\u4e8e2,194\u4e2a\u5e78\u798f\u611f\u6982\u5ff5\u7684\u89e3\u91ca\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u539f\u5219\u7684\u201c\u4ee5LLM\u4e3a\u5224\u5b98\u201d\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u91c7\u7528\u53ccLLM\u5224\u5b98\u6a21\u5f0f\u5bf9\u89e3\u91ca\u8d28\u91cf\u8fdb\u884c\u8bc4\u4ef7\u3002\u540c\u65f6\uff0c\u5229\u7528\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u4e24\u79cd\u7b56\u7565\u5bf9\u5f00\u6e90\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u4ee5\u63d0\u5347\u89e3\u91ca\u8d28\u91cf\u3002", "result": "\uff081\uff09\u4ee5LLM\u4e3a\u8bc4\u5224\u5458\u7684\u8bc4\u4ef7\u7ed3\u679c\u4e0e\u4eba\u5de5\u8bc4\u4f30\u9ad8\u5ea6\u4e00\u81f4\uff1b\uff082\uff09\u4e0d\u540c\u6a21\u578b\u3001\u7528\u6237\u7fa4\u4f53\u548c\u5e78\u798f\u611f\u7c7b\u522b\u7684\u89e3\u91ca\u8d28\u91cf\u5b58\u5728\u660e\u663e\u5dee\u5f02\uff1b\uff083\uff09\u901a\u8fc7DPO\u4e0eSFT\u5fae\u8c03\u540e\u7684\u6a21\u578b\uff0c\u5728\u4e13\u95e8\u5316\u89e3\u91ca\u4efb\u52a1\u4e0a\u8868\u73b0\u8d85\u8fc7\u89c4\u6a21\u66f4\u5927\u7684\u57fa\u7840\u6a21\u578b\uff0c\u8868\u660e\u504f\u597d\u5b66\u4e60\u5bf9\u4f18\u5316\u89e3\u91ca\u6709\u663e\u8457\u4f5c\u7528\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u660e\u4e86\u4ee5LLM\u4e3a\u8bc4\u5224\u5458\u7684\u8bc4\u4ef7\u4f53\u7cfb\u7684\u53ef\u884c\u6027\uff0c\u5e76\u4e14\u901a\u8fc7\u504f\u597d\u5fae\u8c03\u7b49\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u5347LLM\u751f\u6210\u5e78\u798f\u611f\u76f8\u5173\u89e3\u91ca\u7684\u8d28\u91cf\u3002\u7531\u6b64\uff0c\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\uff0c\u901a\u8fc7\u4f18\u5316\u548c\u5fae\u8c03\u53ef\u4ee5\u83b7\u5f97\u66f4\u9ad8\u8d28\u91cf\u3001\u4e2a\u6027\u5316\u7684\u89e3\u91ca\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u4e13\u4e1a\u548c\u77e5\u8bc6\u80cc\u666f\u7684\u7528\u6237\u7fa4\u3002"}}
{"id": "2508.03998", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.03998", "abs": "https://arxiv.org/abs/2508.03998", "authors": ["Xinyu Zhao", "Zhen Tan", "Maya Enisman", "Minjae Seo", "Marta R. Durantini", "Dolores Albarracin", "Tianlong Chen"], "title": "Transferring Expert Cognitive Models to Social Robots via Agentic Concept Bottleneck Models", "comment": "27 pages, 7 figures", "summary": "Successful group meetings, such as those implemented in group\nbehavioral-change programs, work meetings, and other social contexts, must\npromote individual goal setting and execution while strengthening the social\nrelationships within the group. Consequently, an ideal facilitator must be\nsensitive to the subtle dynamics of disengagement, difficulties with individual\ngoal setting and execution, and interpersonal difficulties that signal a need\nfor intervention. The challenges and cognitive load experienced by facilitators\ncreate a critical gap for an embodied technology that can interpret social\nexchanges while remaining aware of the needs of the individuals in the group\nand providing transparent recommendations that go beyond powerful but \"black\nbox\" foundation models (FMs) that identify social cues. We address this\nimportant demand with a social robot co-facilitator that analyzes multimodal\nmeeting data and provides discreet cues to the facilitator. The robot's\nreasoning is powered by an agentic concept bottleneck model (CBM), which makes\ndecisions based on human-interpretable concepts like participant engagement and\nsentiments, ensuring transparency and trustworthiness. Our core contribution is\na transfer learning framework that distills the broad social understanding of\nan FM into our specialized and transparent CBM. This concept-driven system\nsignificantly outperforms direct zero-shot FMs in predicting the need for\nintervention and enables real-time human correction of its reasoning.\nCritically, we demonstrate robust knowledge transfer: the model generalizes\nacross different groups and successfully transfers the expertise of senior\nhuman facilitators to improve the performance of novices. By transferring an\nexpert's cognitive model into an interpretable robotic partner, our work\nprovides a powerful blueprint for augmenting human capabilities in complex\nsocial domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u6570\u636e\u7684\u793e\u4f1a\u673a\u5668\u4eba\u5171\u540c\u4fc3\u8fdb\u8005\uff0c\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u6982\u5ff5\u74f6\u9888\u6a21\u578b\u8f85\u52a9\u7fa4\u4f53\u4f1a\u8bae\u4fc3\u8fdb\uff0c\u5e76\u80fd\u5c06\u4e13\u5bb6\u77e5\u8bc6\u8fc1\u79fb\u7ed9\u65b0\u624b\uff0c\u6548\u679c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u9ed1\u7bb1\u6a21\u578b\uff0c\u63d0\u5347\u4e86\u667a\u80fd\u52a9\u7406\u5728\u590d\u6742\u793e\u4ea4\u73af\u5883\u4e2d\u7684\u53ef\u7528\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u7fa4\u4f53\u4f1a\u8bae\u7684\u6210\u529f\u9700\u517c\u987e\u4e2a\u4eba\u76ee\u6807\u7684\u5b9e\u73b0\u4e0e\u7fa4\u4f53\u5173\u7cfb\u7684\u5f3a\u5316\uff0c\u4f46\u4fc3\u8fdb\u8005\u9700\u5e94\u5bf9\u6210\u5458\u8131\u79bb\u3001\u76ee\u6807\u6267\u884c\u56f0\u96be\u53ca\u4eba\u9645\u5173\u7cfb\u95ee\u9898\uff0c\u8d1f\u62c5\u6781\u5927\u3002\u73b0\u6709\u201c\u9ed1\u7bb1\u201d\u57fa\u7840\u6a21\u578b\u867d\u80fd\u8bc6\u522b\u793e\u4ea4\u7ebf\u7d22\uff0c\u5374\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u9488\u5bf9\u6027\uff0c\u56e0\u6b64\u9700\u8981\u80fd\u81ea\u52a8\u89e3\u91ca\u7fa4\u4f53\u4e92\u52a8\u548c\u4e2a\u4f53\u9700\u6c42\u7684\u667a\u80fd\u8f85\u52a9\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u793e\u4f1a\u673a\u5668\u4eba\u5171\u540c\u4fc3\u8fdb\u8005\uff0c\u4f7f\u7528\u591a\u6a21\u6001\u4f1a\u8bae\u6570\u636e\uff0c\u4e3a\u4fc3\u8fdb\u8005\u63d0\u4f9b\u5b9e\u65f6\u3001\u9690\u853d\u7684\u5efa\u8bae\u3002\u5176\u6838\u5fc3\u4e3a\u6982\u5ff5\u74f6\u9888\u6a21\u578b\uff08CBM\uff09\uff0c\u901a\u8fc7\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u6982\u5ff5\uff08\u5982\u53c2\u4e0e\u5ea6\u3001\u60c5\u611f\uff09\u505a\u51fa\u63a8\u65ad\uff0c\u652f\u6301\u77e5\u8bc6\u8fc1\u79fb\u548c\u4eba\u7c7b\u5b9e\u65f6\u7ea0\u9519\u3002\u4e3b\u8981\u65b9\u6cd5\u4e3a\u5c06\u57fa\u7840\u6a21\u578b\u7684\u5e7f\u6cdb\u793e\u4ea4\u7406\u89e3\u8fc1\u79fb\u81f3\u5177\u5907\u53ef\u89e3\u91ca\u6027\u7684CBM\u4e2d\u3002", "result": "\u63d0\u51fa\u7684\u6982\u5ff5\u9a71\u52a8\u7cfb\u7edf\u5728\u9884\u6d4b\u4f55\u65f6\u9700\u8981\u5e72\u9884\u4e0a\u663e\u8457\u4f18\u4e8e\u76f4\u63a5\u96f6\u6837\u672c\u57fa\u7840\u6a21\u578b\uff0c\u4e14\u652f\u6301\u6a21\u578b\u51b3\u7b56\u7684\u5b9e\u65f6\u4eba\u7c7b\u4fee\u6b63\u3002\u6a21\u578b\u80fd\u8de8\u7fa4\u4f53\u6cdb\u5316\uff0c\u5e76\u5c06\u9ad8\u7ea7\u4fc3\u8fdb\u8005\u7684\u4e13\u4e1a\u77e5\u8bc6\u8fc1\u79fb\u7ed9\u521d\u5b66\u8005\uff0c\u6709\u6548\u63d0\u5347\u65b0\u624b\u8868\u73b0\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u501f\u52a9\u53ef\u89e3\u91ca\u7684\u673a\u5668\u4eba\u4f19\u4f34\uff0c\u5c06\u8d44\u6df1\u4e13\u5bb6\u7684\u8ba4\u77e5\u6a21\u578b\u5bfc\u5165\u5b9e\u9645\u4fc3\u8fdb\uff0c\u4f1a\u663e\u8457\u589e\u5f3a\u7fa4\u4f53\u4f1a\u8bae\u7b49\u590d\u6742\u793e\u4f1a\u573a\u57df\u4e0b\u7684\u4eba\u7c7b\u80fd\u529b\u3002"}}
{"id": "2508.04010", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04010", "abs": "https://arxiv.org/abs/2508.04010", "authors": ["Yurun Chen", "Xavier Hu", "Yuhan Liu", "Keting Yin", "Juncheng Li", "Zhuosheng Zhang", "Shengyu Zhang"], "title": "HarmonyGuard: Toward Safety and Utility in Web Agents via Adaptive Policy Enhancement and Dual-Objective Optimization", "comment": null, "summary": "Large language models enable agents to autonomously perform tasks in open web\nenvironments. However, as hidden threats within the web evolve, web agents face\nthe challenge of balancing task performance with emerging risks during\nlong-sequence operations. Although this challenge is critical, current research\nremains limited to single-objective optimization or single-turn scenarios,\nlacking the capability for collaborative optimization of both safety and\nutility in web environments. To address this gap, we propose HarmonyGuard, a\nmulti-agent collaborative framework that leverages policy enhancement and\nobjective optimization to jointly improve both utility and safety. HarmonyGuard\nfeatures a multi-agent architecture characterized by two fundamental\ncapabilities: (1) Adaptive Policy Enhancement: We introduce the Policy Agent\nwithin HarmonyGuard, which automatically extracts and maintains structured\nsecurity policies from unstructured external documents, while continuously\nupdating policies in response to evolving threats. (2) Dual-Objective\nOptimization: Based on the dual objectives of safety and utility, the Utility\nAgent integrated within HarmonyGuard performs the Markovian real-time reasoning\nto evaluate the objectives and utilizes metacognitive capabilities for their\noptimization. Extensive evaluations on multiple benchmarks show that\nHarmonyGuard improves policy compliance by up to 38% and task completion by up\nto 20% over existing baselines, while achieving over 90% policy compliance\nacross all tasks. Our project is available here:\nhttps://github.com/YurunChen/HarmonyGuard.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6HarmonyGuard\uff0c\u80fd\u8054\u5408\u63d0\u5347\u6548\u7528\u548c\u5b89\u5168\u6027\u3002\u901a\u8fc7\u5b9e\u65f6\u7b56\u7565\u66f4\u65b0\u548c\u76ee\u6807\u4f18\u5316\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u667a\u80fd\u4f53\u7684\u7b56\u7565\u5408\u89c4\u7387\u548c\u4efb\u52a1\u5b8c\u6210\u7387\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u52a8\u4e86\u667a\u80fd\u4f53\u5728\u5f00\u653e\u7f51\u7edc\u4e2d\u7684\u81ea\u4e3b\u4efb\u52a1\u6267\u884c\uff0c\u4f46\u7531\u4e8e\u7f51\u7edc\u73af\u5883\u4e2d\u7684\u6f5c\u5728\u5a01\u80c1\u4e0d\u65ad\u6f14\u53d8\uff0c\u667a\u80fd\u4f53\u9700\u8981\u5728\u4efb\u52a1\u8868\u73b0\u548c\u5b89\u5168\u98ce\u9669\u4e4b\u95f4\u505a\u6743\u8861\u3002\u76ee\u524d\u76f8\u5173\u7814\u7a76\u5927\u591a\u53ea\u5173\u6ce8\u5355\u4e00\u76ee\u6807\u6216\u5355\u8f6e\u573a\u666f\uff0c\u7f3a\u4e4f\u5728\u7f51\u7edc\u73af\u5883\u4e0b\u540c\u65f6\u4f18\u5316\u6548\u7528\u548c\u5b89\u5168\u6027\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faHarmonyGuard\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff0c\u7ed3\u5408\u7b56\u7565\u589e\u5f3a\u548c\u76ee\u6807\u4f18\u5316\u4ee5\u8054\u5408\u63d0\u5347\u6548\u7528\u4e0e\u5b89\u5168\u3002\u5305\u62ec\uff1a(1) \u5f15\u5165Policy Agent\u81ea\u52a8\u63d0\u53d6\u4e0e\u7ef4\u62a4\u7ed3\u6784\u5316\u5b89\u5168\u7b56\u7565\uff0c\u5e76\u5e94\u5bf9\u5b89\u5168\u5a01\u80c1\u6301\u7eed\u66f4\u65b0\uff1b(2) \u5f15\u5165Utility Agent\u57fa\u4e8e\u5b89\u5168\u548c\u6548\u7528\u53cc\u91cd\u76ee\u6807\uff0c\u91c7\u7528\u9a6c\u5c14\u53ef\u592b\u5b9e\u65f6\u63a8\u7406\u548c\u5143\u8ba4\u77e5\u8fdb\u884c\u8bc4\u4f30\u4e0e\u4f18\u5316\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHarmonyGuard\u76f8\u8f83\u73b0\u6709\u65b9\u6cd5\uff0c\u7b56\u7565\u5408\u89c4\u6027\u6700\u591a\u63d0\u534738%\uff0c\u4efb\u52a1\u5b8c\u6210\u7387\u63d0\u534720%\uff0c\u5e76\u5728\u6240\u6709\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e8690%\u4ee5\u4e0a\u7684\u7b56\u7565\u5408\u89c4\u7387\u3002", "conclusion": "HarmonyGuard\u80fd\u591f\u5728\u7f51\u7edc\u73af\u5883\u4e0b\u517c\u987e\u4efb\u52a1\u6548\u7528\u4e0e\u5b89\u5168\u6027\uff0c\u4e3a\u667a\u80fd\u4f53\u7cfb\u7edf\u5e26\u6765\u66f4\u9ad8\u6548\u5b89\u5168\u7684\u4efb\u52a1\u6267\u884c\u80fd\u529b\uff0c\u5e76\u5927\u5e45\u63d0\u5347\u7b56\u7565\u5408\u89c4\u4e0e\u4efb\u52a1\u5b8c\u6210\u8868\u73b0\u3002"}}
{"id": "2508.04012", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04012", "abs": "https://arxiv.org/abs/2508.04012", "authors": ["Xiaopeng Li", "Shasha Li", "Xi Wang", "Shezheng Song", "Bin Ji", "Shangwen Wang", "Jun Ma", "Xiaodong Liu", "Mina Liu", "Jie Yu"], "title": "Step More: Going Beyond Single Backpropagation in Meta Learning Based Model Editing", "comment": null, "summary": "Large Language Models (LLMs) underpin many AI applications, but their static\nnature makes updating knowledge costly. Model editing offers an efficient\nalternative by injecting new information through targeted parameter\nmodifications. In particular, meta-learning-based model editing (MLBME) methods\nhave demonstrated notable advantages in both editing effectiveness and\nefficiency. Despite this, we find that MLBME exhibits suboptimal performance in\nlow-data scenarios, and its training efficiency is bottlenecked by the\ncomputation of KL divergence. To address these, we propose $\\textbf{S}$tep\n$\\textbf{M}$ore $\\textbf{Edit}$ ($\\textbf{SMEdit}$), a novel MLBME method that\nadopts $\\textbf{M}$ultiple $\\textbf{B}$ackpro$\\textbf{P}$agation\n$\\textbf{S}$teps ($\\textbf{MBPS}$) to improve editing performance under limited\nsupervision and a norm regularization on weight updates to improve training\nefficiency. Experimental results on two datasets and two LLMs demonstrate that\nSMEdit outperforms prior MLBME baselines and the MBPS strategy can be\nseamlessly integrated into existing methods to further boost their performance.\nOur code will be released soon.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u65b9\u6cd5SMEdit\uff0c\u901a\u8fc7\u591a\u6b65\u53cd\u5411\u4f20\u64ad\u548c\u6b63\u5219\u5316\u6280\u5de7\uff0c\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7f16\u8f91\u4e2d\u4f4e\u6570\u636e\u8868\u73b0\u548c\u8bad\u7ec3\u6548\u7387\u95ee\u9898\uff0c\u5b9e\u9a8c\u7ed3\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u66f4\u65b0\u77e5\u8bc6\u6210\u672c\u9ad8\uff0c\u800c\u6a21\u578b\u7f16\u8f91\u4f5c\u4e3a\u66ff\u4ee3\u624b\u6bb5\u5df2\u83b7\u5f97\u8fdb\u5c55\uff0c\u5c24\u5176\u662f\u5143\u5b66\u4e60\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u73b0\u6709MLBME\u65b9\u6cd5\u5728\u4f4e\u6570\u636e\u548c\u8bad\u7ec3\u6548\u7387\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u5143\u5b66\u4e60\u578b\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5SMEdit\uff0c\u6838\u5fc3\u4e3a\u591a\u6b21\u53cd\u5411\u4f20\u64ad\u6b65\u9aa4\uff08MBPS\uff09\u7528\u4e8e\u63d0\u5347\u4f4e\u76d1\u7763\u7f16\u8f91\u6548\u679c\uff0c\u5e76\u901a\u8fc7\u6743\u91cd\u66f4\u65b0\u7684\u8303\u6570\u6b63\u5219\u5316\u6539\u5584\u8bad\u7ec3\u6548\u7387\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u548c\u4e24\u4e2aLLM\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cSMEdit\u660e\u663e\u4f18\u4e8e\u4e4b\u524d\u7684MLBME\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14MBPS\u65b9\u6cd5\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u8fdb\u73b0\u6709\u7b97\u6cd5\u5e76\u63d0\u5347\u5176\u6548\u679c\u3002", "conclusion": "SMEdit\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u5728\u4f4e\u6570\u636e\u573a\u666f\u4e0b\u7684\u6a21\u578b\u7f16\u8f91\u6548\u679c\u548c\u8bad\u7ec3\u6548\u7387\uff0c\u5e76\u4f18\u4e8e\u73b0\u6709MLBME\u65b9\u6cd5\u3002MBPS\u7b56\u7565\u5177\u6709\u826f\u597d\u7684\u901a\u7528\u6027\uff0c\u53ef\u76f4\u63a5\u878d\u5408\u8fdb\u5176\u4ed6\u65b9\u6cd5\u5e76\u5e26\u6765\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2508.04038", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.04038", "abs": "https://arxiv.org/abs/2508.04038", "authors": ["Zechen Li", "Baiyu Chen", "Hao Xue", "Flora D. Salim"], "title": "ZARA: Zero-shot Motion Time-Series Analysis via Knowledge and Retrieval Driven LLM Agents", "comment": null, "summary": "Motion sensor time-series are central to human activity recognition (HAR),\nwith applications in health, sports, and smart devices. However, existing\nmethods are trained for fixed activity sets and require costly retraining when\nnew behaviours or sensor setups appear. Recent attempts to use large language\nmodels (LLMs) for HAR, typically by converting signals into text or images,\nsuffer from limited accuracy and lack verifiable interpretability. We propose\nZARA, the first agent-based framework for zero-shot, explainable HAR directly\nfrom raw motion time-series. ZARA integrates an automatically derived pair-wise\nfeature knowledge base that captures discriminative statistics for every\nactivity pair, a multi-sensor retrieval module that surfaces relevant evidence,\nand a hierarchical agent pipeline that guides the LLM to iteratively select\nfeatures, draw on this evidence, and produce both activity predictions and\nnatural-language explanations. ZARA enables flexible and interpretable HAR\nwithout any fine-tuning or task-specific classifiers. Extensive experiments on\n8 HAR benchmarks show that ZARA achieves SOTA zero-shot performance, delivering\nclear reasoning while exceeding the strongest baselines by 2.53x in macro F1.\nAblation studies further confirm the necessity of each module, marking ZARA as\na promising step toward trustworthy, plug-and-play motion time-series analysis.\nOur codes are available at https://github.com/zechenli03/ZARA.", "AI": {"tldr": "ZARA\u662f\u9996\u4e2a\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u53ef\u89e3\u91ca\u3001\u96f6\u6837\u672c\u8fd0\u52a8\u8bc6\u522b\u7684\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u6027\u80fd\u8fdc\u8d85\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u52a8\u4f5c\u4f20\u611f\u5668\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u65b9\u6cd5\u901a\u5e38\u53ea\u80fd\u5904\u7406\u56fa\u5b9a\u96c6\u5408\u7684\u6d3b\u52a8\uff0c\u5e76\u4e14\u5728\u51fa\u73b0\u65b0\u884c\u4e3a\u6216\u65b0\u4f20\u611f\u5668\u914d\u7f6e\u65f6\u9700\u8981\u6602\u8d35\u7684\u91cd\u65b0\u8bad\u7ec3\uff0c\u5bf9\u6cdb\u5316\u548c\u53ef\u89e3\u91ca\u6027\u6709\u8f83\u9ad8\u9700\u6c42\u3002\u6700\u8fd1\u5c1d\u8bd5\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5904\u7406\u8be5\u4efb\u52a1\uff0c\u4f46\u9762\u4e34\u51c6\u786e\u7387\u4e0e\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86ZARA\uff0c\u8fd9\u662f\u4e00\u4e2a\u9996\u521b\u7684\u57fa\u4e8e\u667a\u80fd\u4f53\u3001\u53ef\u96f6\u6837\u672c\u3001\u53ef\u89e3\u91ca\u7684\u52a8\u4f5c\u8bc6\u522b\u6846\u67b6\u3002ZARA\u7531\u4e09\u4e2a\u6838\u5fc3\u90e8\u5206\u7ec4\u6210\uff1a1\uff09\u81ea\u52a8\u83b7\u53d6\u7684\u4e24\u4e24\u884c\u4e3a\u7279\u5f81\u77e5\u8bc6\u5e93\uff0c2\uff09\u591a\u4f20\u611f\u5668\u8bc1\u636e\u68c0\u7d22\u6a21\u5757\uff0c3\uff09\u5c42\u6b21\u5316\u667a\u80fd\u4f53\u6d41\u6c34\u7ebf\uff0c\u5f15\u5bfcLLM\u9010\u6b65\u9009\u62e9\u7279\u5f81\u3001\u63d0\u53d6\u8bc1\u636e\uff0c\u5e76\u6700\u7ec8\u7ed9\u51fa\u9884\u6d4b\u53ca\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002ZARA\u65e0\u9700\u5fae\u8c03\u6216\u7279\u5b9a\u5206\u7c7b\u5668\u5373\u53ef\u7075\u6d3b\u6267\u884c\u4efb\u52a1\u3002", "result": "\u57288\u4e2a\u6743\u5a01\u52a8\u4f5c\u8bc6\u522b\u6570\u636e\u96c6\u4e0a\uff0cZARA\u8fbe\u5230\u4e86\u6700\u4f18\u7684\u96f6\u6837\u672c\u6027\u80fd\uff0c\u5728\u5b8fF1\u5206\u6570\u4e0a\u8d85\u8fc7\u6700\u5f3a\u57fa\u7ebf2.53\u500d\u3002\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6bcf\u4e2a\u6a21\u5757\u7684\u91cd\u8981\u6027\u3002", "conclusion": "ZARA\u5b9e\u73b0\u4e86\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u8bad\u7ec3\u3001\u53ef\u89e3\u91ca\u4e14\u7075\u6d3b\u7684\u52a8\u4f5c\u8bc6\u522b\uff0c\u4e3a\u53ef\u4fe1\u8d56\u3001\u5373\u63d2\u5373\u7528\u7684\u4eba\u7c7b\u52a8\u4f5c\u8bc6\u522b\u5206\u6790\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2508.04039", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.04039", "abs": "https://arxiv.org/abs/2508.04039", "authors": ["Thilo Hagendorff", "Erik Derner", "Nuria Oliver"], "title": "Large Reasoning Models Are Autonomous Jailbreak Agents", "comment": null, "summary": "Jailbreaking -- bypassing built-in safety mechanisms in AI models -- has\ntraditionally required complex technical procedures or specialized human\nexpertise. In this study, we show that the persuasive capabilities of large\nreasoning models (LRMs) simplify and scale jailbreaking, converting it into an\ninexpensive activity accessible to non-experts. We evaluated the capabilities\nof four LRMs (DeepSeek-R1, Gemini 2.5 Flash, Grok 3 Mini, Qwen3 235B) to act as\nautonomous adversaries conducting multi-turn conversations with nine widely\nused target models. LRMs received instructions via a system prompt, before\nproceeding to planning and executing jailbreaks with no further supervision. We\nperformed extensive experiments with a benchmark of harmful prompts composed of\n70 items covering seven sensitive domains. This setup yielded an overall attack\nsuccess rate across all model combinations of 97.14%. Our study reveals an\nalignment regression, in which LRMs can systematically erode the safety\nguardrails of other models, highlighting the urgent need to further align\nfrontier models not only to resist jailbreak attempts, but also to prevent them\nfrom being co-opted into acting as jailbreak agents.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5927\u578b\u63a8\u7406\u6a21\u578b\u6781\u5927\u964d\u4f4e\u4e86AI\u6a21\u578b\u8d8a\u72f1\u95e8\u69db\uff0c\u4e00\u822c\u7528\u6237\u4e5f\u80fd\u8f7b\u677e\u5b9e\u65bd\u8d8a\u72f1\u653b\u51fb\u3002\u6d4b\u8bd5\u4e2d\uff0c\u81ea\u52a8\u5316\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe97.14%\uff0c\u663e\u793a\u5f53\u524d\u4e3b\u6d41AI\u6a21\u578b\u9762\u4e34\u4e25\u91cd\u7684\u5b89\u5168\u98ce\u9669\uff0c\u4e9f\u9700\u52a0\u5f3a\u6a21\u578b\u7684\u6297\u8d8a\u72f1\u4e0e\u81ea\u4fdd\u80fd\u529b\u3002", "motivation": "AI\u6a21\u578b\u56fa\u6709\u7684\u5b89\u5168\u673a\u5236\u901a\u5e38\u9700\u8981\u590d\u6742\u6280\u672f\u6216\u4e13\u5bb6\u77e5\u8bc6\u624d\u80fd\u7ed5\u8fc7\uff0c\u7136\u800c\u968f\u7740\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u8bf4\u670d\u80fd\u529b\u7684\u63d0\u5347\uff0c\u8d8a\u72f1\u653b\u51fb\u53d8\u5f97\u7b80\u5355\u4e14\u5ec9\u4ef7\uff0c\u751a\u81f3\u666e\u901a\u7528\u6237\u4e5f\u80fd\u64cd\u4f5c\u3002\u56e0\u6b64\uff0c\u63a2\u7a76LRMs\u5728AI\u6a21\u578b\u8d8a\u72f1\u4e2d\u7684\u4f5c\u7528\u53ca\u5176\u5b89\u5168\u9690\u60a3\u53d8\u5f97\u8feb\u5207\u3002", "method": "\u4f5c\u8005\u6311\u9009\u4e86\u56db\u79cd\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08DeepSeek-R1\u3001Gemini 2.5 Flash\u3001Grok 3 Mini\u3001Qwen3 235B\uff09\u4f5c\u4e3a\u653b\u51fb\u8005\uff0c\u4e0e\u4e5d\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u76ee\u6807\u6a21\u578b\u8fdb\u884c\u591a\u8f6e\u81ea\u52a8\u5bf9\u8bdd\uff0c\u5e76\u901a\u8fc7\u7cfb\u7edf\u63d0\u793a\u7ed9\u4e88\u57fa\u672c\u6307\u4ee4\u3002\u5b9e\u9a8c\u8bbe\u8ba1\u8986\u76d6\u4e03\u5927\u654f\u611f\u9886\u57df\u517170\u6761\u6709\u5bb3\u63d0\u793a\uff0c\u7cfb\u7edf\u6027\u6d4b\u8bd5\u7ec4\u5408\u653b\u51fb\u6210\u529f\u7387\uff0c\u65e0\u9700\u540e\u7eed\u4eba\u5de5\u5e72\u9884\u3002", "result": "\u5728\u6240\u6709\u6a21\u578b\u7ec4\u5408\u4e2d\uff0c\u653b\u51fb\u5e73\u5747\u6210\u529f\u7387\u9ad8\u8fbe97.14%\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLRMs\u80fd\u591f\u9ad8\u6548\u5730\u524a\u5f31\u6216\u7ed5\u8fc7\u5176\u4ed6AI\u6a21\u578b\u7684\u5b89\u5168\u673a\u5236\u3002", "conclusion": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e0d\u4ec5\u6613\u4e8e\u88ab\u7528\u4f5c\u8d8a\u72f1\u5de5\u5177\uff0c\u8fd8\u80fd\u4f5c\u4e3a\u81ea\u52a8\u5316\u653b\u51fb\u8005\u9ad8\u6548\u7834\u574fAI\u6a21\u578b\u7684\u5b89\u5168\u63aa\u65bd\uff0c\u66b4\u9732\u4e86AI\u6a21\u578b\u5728\u5bf9\u6297\u6076\u610f\u5229\u7528\u53ca\u5b89\u5168\u5bf9\u9f50\u65b9\u9762\u7684\u91cd\u5927\u77ed\u677f\u3002"}}
{"id": "2508.04047", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04047", "abs": "https://arxiv.org/abs/2508.04047", "authors": ["Jiabing Yang", "Yixiang Chen", "Zichen Wen", "Chenhang Cui", "Peiyan Li", "Yuan Xu", "Bowen Fang", "Yan Huang", "Liang Wang"], "title": "DTPA: Dynamic Token-level Prefix Augmentation for Controllable Text Generation", "comment": null, "summary": "Controllable Text Generation (CTG) is a vital subfield in Natural Language\nProcessing (NLP), aiming to generate text that aligns with desired attributes.\nHowever, previous studies commonly focus on the quality of controllable text\ngeneration for short sequences, while the generation of long-form text remains\nlargely underexplored. In this paper, we observe that the controllability of\ntexts generated by the powerful prefix-based method Air-Decoding tends to\ndecline with increasing sequence length, which we hypothesize primarily arises\nfrom the observed decay in attention to the prefixes. Meanwhile, different\ntypes of prefixes including soft and hard prefixes are also key factors\ninfluencing performance. Building on these insights, we propose a lightweight\nand effective framework called Dynamic Token-level Prefix Augmentation (DTPA)\nbased on Air-Decoding for controllable text generation. Specifically, it first\nselects the optimal prefix type for a given task. Then we dynamically amplify\nthe attention to the prefix for the attribute distribution to enhance\ncontrollability, with a scaling factor growing exponentially as the sequence\nlength increases. Moreover, based on the task, we optionally apply a similar\naugmentation to the original prompt for the raw distribution to balance text\nquality. After attribute distribution reconstruction, the generated text\nsatisfies the attribute constraints well. Experiments on multiple CTG tasks\ndemonstrate that DTPA generally outperforms other methods in attribute control\nwhile maintaining competitive fluency, diversity, and topic relevance. Further\nanalysis highlights DTPA's superior effectiveness in long text generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u52a8\u6001Token\u7ea7\u524d\u7f00\u589e\u5f3a\uff08DTPA\uff09\u65b9\u6cd5\uff0c\u6709\u6548\u6539\u5584\u4e86\u957f\u6587\u672c\u53ef\u63a7\u751f\u6210\u4e2d\u7684\u5c5e\u6027\u63a7\u5236\u80fd\u529b\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u751f\u6210\u6587\u672c\u6d41\u7545\u4e14\u76f8\u5173\u6027\u5f3a\u3002", "motivation": "\u4ee5\u5f80\u7684\u53ef\u63a7\u6587\u672c\u751f\u6210\u65b9\u6cd5\u5728\u751f\u6210\u957f\u6587\u672c\u65f6\uff0c\u6587\u672c\u7684\u53ef\u63a7\u6027\u4e0b\u964d\uff0c\u5c24\u5176\u662f\u524d\u7f00\u6ce8\u610f\u529b\u8870\u51cf\u5bfc\u81f4\u751f\u6210\u7ed3\u679c\u4e0d\u7406\u60f3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAir-Decoding\u7684\u52a8\u6001Token\u7ea7\u524d\u7f00\u589e\u5f3a\uff08DTPA\uff09\u6846\u67b6\uff0c\u80fd\u591f\u6839\u636e\u4efb\u52a1\u52a8\u6001\u8c03\u6574\u524d\u7f00\u7c7b\u578b\uff0c\u5e76\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u6307\u6570\u589e\u5f3a\u524d\u7f00\u6ce8\u610f\u529b\uff0c\u4ece\u800c\u63d0\u5347\u957f\u6587\u672c\u751f\u6210\u7684\u53ef\u63a7\u6027\uff0c\u5e76\u53ef\u9009\u6027\u589e\u5f3a\u539f\u59cb\u63d0\u793a\uff0c\u517c\u987e\u6587\u672c\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cDTPA\u7b97\u6cd5\u5728\u4fdd\u8bc1\u6587\u672c\u6d41\u7545\u6027\u3001\u4e3b\u9898\u76f8\u5173\u6027\u548c\u591a\u6837\u6027\u7684\u540c\u65f6\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u957f\u6587\u672c\u4e2d\u7684\u5c5e\u6027\u63a7\u5236\u80fd\u529b\u3002\u5206\u6790\u8fd8\u8bc1\u660e\u5176\u5728\u957f\u6587\u672c\u751f\u6210\u65b9\u9762\u5c24\u5176\u6709\u6548\u3002", "conclusion": "DTPA\u80fd\u591f\u5f88\u597d\u5730\u63d0\u5347\u957f\u6587\u672c\u751f\u6210\u4e2d\u7684\u5c5e\u6027\u53ef\u63a7\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6d41\u7545\u5ea6\u3001\u591a\u6837\u6027\u548c\u4e3b\u9898\u76f8\u5173\u6027\uff0c\u5e76\u5728\u591a\u79cd\u53ef\u63a7\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2508.04057", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04057", "abs": "https://arxiv.org/abs/2508.04057", "authors": ["Wang Chen", "Guanqiang Qi", "Weikang Li", "Yang Li", "Deguo Xia", "Jizhou Huang"], "title": "PAIRS: Parametric-Verified Adaptive Information Retrieval and Selection for Efficient RAG", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has become a cornerstone technique for\nenhancing large language models (LLMs) with external knowledge. However,\ncurrent RAG systems face two critical limitations: (1) they inefficiently\nretrieve information for every query, including simple questions that could be\nresolved using the LLM's parametric knowledge alone, and (2) they risk\nretrieving irrelevant documents when queries contain sparse information\nsignals. To address these gaps, we introduce Parametric-verified Adaptive\nInformation Retrieval and Selection (PAIRS), a training-free framework that\nintegrates parametric and retrieved knowledge to adaptively determine whether\nto retrieve and how to select external information. Specifically, PAIRS employs\na dual-path generation mechanism: First, the LLM produces both a direct answer\nand a context-augmented answer using self-generated pseudo-context. When these\noutputs converge, PAIRS bypasses external retrieval entirely, dramatically\nimproving the RAG system's efficiency. For divergent cases, PAIRS activates a\ndual-path retrieval (DPR) process guided by both the original query and\nself-generated contextual signals, followed by an Adaptive Information\nSelection (AIS) module that filters documents through weighted similarity to\nboth sources. This simple yet effective approach can not only enhance\nefficiency by eliminating unnecessary retrievals but also improve accuracy\nthrough contextually guided retrieval and adaptive information selection.\nExperimental results on six question-answering (QA) benchmarks show that PAIRS\nreduces retrieval costs by around 25% (triggering for only 75% of queries)\nwhile still improving accuracy-achieving +1.1% EM and +1.0% F1 over prior\nbaselines on average.", "AI": {"tldr": "PAIRS\u6846\u67b6\u901a\u8fc7\u667a\u80fd\u5224\u65ad\u4f55\u65f6\u9700\u8981\u68c0\u7d22\u548c\u5982\u4f55\u9009\u62e9\u5916\u90e8\u4fe1\u606f\uff0c\u5728\u8282\u770125%\u68c0\u7d22\u6210\u672c\u7684\u540c\u65f6\u8fd8\u80fd\u63d0\u9ad8\u95ee\u7b54\u51c6\u786e\u7387\uff0c\u65e0\u987b\u53e6\u884c\u8bad\u7ec3\uff0c\u7b80\u5355\u6709\u6548\u3002", "motivation": "\u5f53\u524d\u7684RAG\u7cfb\u7edf\u5728\u7b80\u5355\u95ee\u9898\u4e0a\u4e0d\u5fc5\u8981\u5730\u8fdb\u884c\u68c0\u7d22\uff0c\u6d6a\u8d39\u8d44\u6e90\u4e14\u6548\u7387\u4f4e\uff1b\u5bf9\u4e8e\u4fe1\u606f\u7a00\u758f\u7684\u67e5\u8be2\uff0c\u5bb9\u6613\u68c0\u7d22\u5230\u65e0\u5173\u6587\u6863\uff0c\u5f71\u54cd\u56de\u7b54\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b0\u578b\u6846\u67b6PAIRS\uff0c\u901a\u8fc7\u53cc\u8def\u5f84\u751f\u6210\u673a\u5236\uff1a\u5148\u8ba9LLM\u72ec\u7acb\u751f\u6210\u76f4\u63a5\u56de\u7b54\u548c\u4f2a\u4e0a\u4e0b\u6587\u589e\u5f3a\u56de\u7b54\uff0c\u82e5\u4e24\u8005\u4e00\u81f4\u5219\u76f4\u63a5\u8f93\u51fa\u7ed3\u679c\uff0c\u65e0\u9700\u68c0\u7d22\uff1b\u82e5\u4e0d\u4e00\u81f4\uff0c\u518d\u6839\u636e\u539f\u59cb\u67e5\u8be2\u4e0e\u81ea\u751f\u6210\u4e0a\u4e0b\u6587\u4fe1\u53f7\u8054\u5408\u5f15\u5bfc\u68c0\u7d22\u3001\u5e76\u901a\u8fc7\u52a0\u6743\u76f8\u4f3c\u5ea6\u8fc7\u6ee4\u6587\u6863\uff0c\u6700\u7ec8\u8f93\u51fa\u7b54\u6848\u3002", "result": "\u5728\u516d\u4e2a\u95ee\u7b54\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cPAIRS\u80fd\u591f\u51cf\u5c11\u7ea625%\u7684\u68c0\u7d22\u64cd\u4f5c\uff08\u4ec5\u5bf975%\u7684\u67e5\u8be2\u9700\u8981\u68c0\u7d22\uff09\uff0c\u540c\u65f6\u51c6\u786e\u7387\u63d0\u5347\uff0c\u5e73\u5747EM\u63d0\u53471.1%\uff0cF1\u63d0\u53471.0%\u3002", "conclusion": "PAIRS\u65e0\u987b\u8bad\u7ec3\u5373\u53ef\u9ad8\u6548\u878d\u5408LLM\u5df2\u6709\u77e5\u8bc6\u4e0e\u68c0\u7d22\u77e5\u8bc6\uff0c\u81ea\u9002\u5e94\u51b3\u5b9a\u662f\u5426\u68c0\u7d22\u53ca\u5982\u4f55\u9009\u62e9\u5916\u90e8\u4fe1\u606f\uff0c\u63d0\u5347\u6548\u7387\u5e76\u63d0\u9ad8\u95ee\u7b54\u6548\u679c\u3002"}}
{"id": "2508.04073", "categories": ["cs.CL", "cs.LG", "I.2.7; I.2.6; I.5.1"], "pdf": "https://arxiv.org/pdf/2508.04073", "abs": "https://arxiv.org/abs/2508.04073", "authors": ["Juli\u00e1n Camilo Velandia Guti\u00e9rrez"], "title": "Efficient Strategy for Improving Large Language Model (LLM) Capabilities", "comment": "Based on master's thesis in Systems and Computer Engineering,\n  Universidad Nacional de Colombia (2025)", "summary": "Large Language Models (LLMs) have become a milestone in the field of\nartificial intelligence and natural language processing. However, their\nlarge-scale deployment remains constrained by the need for significant\ncomputational resources. This work proposes starting from a base model to\nexplore and combine data processing and careful data selection techniques,\ntraining strategies, and architectural adjustments to improve the efficiency of\nLLMs in resource-constrained environments and within a delimited knowledge\nbase. The methodological approach included defining criteria for building\nreliable datasets, conducting controlled experiments with different\nconfigurations, and systematically evaluating the resulting variants in terms\nof capability, versatility, response time, and safety. Finally, comparative\ntests were conducted to measure the performance of the developed variants and\nto validate the effectiveness of the proposed strategies. This work is based on\nthe master's thesis in Systems and Computer Engineering titled \"Efficient\nStrategy for Improving the Capabilities of Large Language Models (LLMs)\".", "AI": {"tldr": "\u672c\u6587\u805a\u7126\u4e8e\u8d44\u6e90\u53d7\u9650\u60c5\u5883\u4e0b\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6548\u7387\uff0c\u7efc\u5408\u6570\u636e\u3001\u8bad\u7ec3\u4e0e\u67b6\u6784\u4f18\u5316\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6548\u7387\u4e0e\u6027\u80fd\u7684\u6539\u8fdb\uff0c\u4e3aLLMs\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u7b56\u7565\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u5728\u4eba\u5de5\u667a\u80fd\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u53d6\u5f97\u4e86\u7a81\u7834\uff0c\u4f46\u5176\u5927\u89c4\u6a21\u90e8\u7f72\u53d7\u5230\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u9ad8\u7684\u9650\u5236\u3002\u63a8\u52a8\u66f4\u9ad8\u6548\u7684LLM\u4ee5\u9002\u5e94\u8d44\u6e90\u53d7\u9650\u73af\u5883\u662f\u5f53\u524d\u7684\u7814\u7a76\u96be\u9898\u3002", "method": "\u672c\u6587\u4ece\u57fa\u7840\u6a21\u578b\u51fa\u53d1\uff0c\u7ed3\u5408\u6570\u636e\u5904\u7406\u3001\u6570\u636e\u7b5b\u9009\u3001\u8bad\u7ec3\u7b56\u7565\u53ca\u67b6\u6784\u8c03\u6574\u7b49\u7efc\u5408\u65b9\u6cd5\u3002\u5177\u4f53\u5305\u62ec\u5efa\u7acb\u53ef\u9760\u6570\u636e\u96c6\u7684\u6807\u51c6\u3001\u8bbe\u8ba1\u53d7\u63a7\u5b9e\u9a8c\u548c\u7cfb\u7edf\u8bc4\u4f30\u6a21\u578b\u80fd\u529b\u3001\u901a\u7528\u6027\u3001\u54cd\u5e94\u65f6\u95f4\u4e0e\u5b89\u5168\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u5c55\u793a\u4e86\u4e0d\u540c\u6539\u8fdb\u7b56\u7565\u4e0b\u6a21\u578b\u6027\u80fd\u7684\u53d8\u5316\uff0c\u901a\u8fc7\u5bf9\u6bd4\u8bd5\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u5728\u63d0\u5347LLM\u6548\u7387\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b56\u7565\u80fd\u591f\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53d7\u9650\u8d44\u6e90\u548c\u7279\u5b9a\u77e5\u8bc6\u5e93\u5185\u7684\u6548\u7387\u548c\u80fd\u529b\uff0c\u5177\u6709\u73b0\u5b9e\u90e8\u7f72\u4ef7\u503c\u3002"}}
{"id": "2508.04086", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04086", "abs": "https://arxiv.org/abs/2508.04086", "authors": ["Zhongyi Zhou", "Kohei Uehara", "Haoyu Zhang", "Jingtao Zhou", "Lin Gu", "Ruofei Du", "Zheng Xu", "Tatsuya Harada"], "title": "ToolGrad: Efficient Tool-use Dataset Generation with Textual \"Gradients\"", "comment": null, "summary": "Prior work synthesizes tool-use LLM datasets by first generating a user\nquery, followed by complex tool-use annotations like DFS. This leads to\ninevitable annotation failures and low efficiency in data generation. We\nintroduce ToolGrad, an agentic framework that inverts this paradigm. ToolGrad\nfirst constructs valid tool-use chains through an iterative process guided by\ntextual \"gradients\", and then synthesizes corresponding user queries. This\n\"answer-first\" approach led to ToolGrad-5k, a dataset generated with more\ncomplex tool use, lower cost, and 100% pass rate. Experiments show that models\ntrained on ToolGrad-5k outperform those on expensive baseline datasets and\nproprietary LLMs, even on OOD benchmarks.", "AI": {"tldr": "ToolGrad\u6846\u67b6\u4ee5\u7b54\u6848\u5148\u884c\u751f\u6210\u9ad8\u8d28\u91cf\u5de5\u5177\u4f7f\u7528\u6570\u636e\u96c6\uff0c\u5b9e\u73b0\u66f4\u4f4e\u6210\u672c\u548c\u66f4\u9ad8\u590d\u6742\u5ea6\u6ce8\u91ca\uff0c\u5e76\u663e\u8457\u63d0\u5347\u6a21\u578b\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u4f7f\u7528\u7c7b\u5927\u6a21\u578b\uff08LLM\uff09\u6570\u636e\u96c6\u7684\u5408\u6210\u65b9\u6cd5\uff0c\u901a\u5e38\u662f\u5148\u751f\u6210\u7528\u6237\u67e5\u8be2\uff0c\u518d\u8fdb\u884c\u590d\u6742\u7684\u5de5\u5177\u4f7f\u7528\u6ce8\u91ca\uff0c\u4f46\u8fd9\u5bfc\u81f4\u6ce8\u91ca\u5931\u8d25\u548c\u6570\u636e\u751f\u6210\u6548\u7387\u4f4e\u3002", "method": "\u63d0\u51fa\u4e86ToolGrad\u6846\u67b6\uff0c\u53cd\u8f6c\u4f20\u7edf\u751f\u6210\u6d41\u7a0b\uff0c\u5373\u5148\u57fa\u4e8e\u6587\u672c\u201c\u68af\u5ea6\u201d\u8fed\u4ee3\u6784\u9020\u6709\u6548\u5de5\u5177\u4f7f\u7528\u94fe\uff0c\u7136\u540e\u518d\u5408\u6210\u76f8\u5e94\u7684\u7528\u6237\u67e5\u8be2\uff0c\u5b9e\u73b0\u201c\u5148\u7b54\u6848\u540e\u95ee\u9898\u201d\u7684\u6570\u636e\u751f\u6210\u6a21\u5f0f\u3002", "result": "\u751f\u6210\u4e86ToolGrad-5k\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u5de5\u5177\u4f7f\u7528\u66f4\u590d\u6742\u3001\u751f\u6210\u6210\u672c\u66f4\u4f4e\uff0c\u5e76\u4e14\u6ce8\u91ca\u901a\u8fc7\u7387\u8fbe\u5230100%\u3002", "conclusion": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728ToolGrad-5k\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u65e0\u8bba\u662f\u5728\u5e38\u89c4\u8fd8\u662f\u5206\u5e03\u5916\uff08OOD\uff09\u57fa\u51c6\u4e0a\uff0c\u90fd\u4f18\u4e8e\u7528\u6602\u8d35\u57fa\u7ebf\u6570\u636e\u96c6\u6216\u5546\u4e1a\u5927\u6a21\u578b\u8bad\u7ec3\u7684\u6a21\u578b\u3002"}}
{"id": "2508.04088", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04088", "abs": "https://arxiv.org/abs/2508.04088", "authors": ["Jianghangfan Zhang", "Yibo Yan", "Kening Zheng", "Xin Zou", "Song Dai", "Xuming Hu"], "title": "GM-PRM: A Generative Multimodal Process Reward Model for Multimodal Mathematical Reasoning", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) demonstrate remarkable capabilities\nbut often struggle with complex, multi-step mathematical reasoning, where minor\nerrors in visual perception or logical deduction can lead to complete failure.\nWhile Process Reward Models (PRMs) offer step-by-step supervision, existing\nmultimodal PRMs are limited to being binary verifiers that can identify but not\ncorrect errors, offering little explanatory power. To address these\ndeficiencies, we introduce the Generative Multimodal Process Reward Model\n(GM-PRM), a novel paradigm that transforms the PRM from a passive judge into an\nactive reasoning collaborator. Instead of a simple scalar score, GM-PRM\nprovides a fine-grained, interpretable analysis of each reasoning step,\nevaluating its step intent, visual alignment, and logical soundness. More\ncritically, GM-PRM is trained to generate a corrected version of the first\nerroneous step it identifies. This unique corrective capability enables our new\ntest-time inference strategy, Refined Best-of-N (Refined-BoN). This framework\nactively enhances solution quality by using the PRM's generated correction to\nguide the policy model toward a more promising reasoning trajectory, thereby\nimproving the diversity and correctness of the solution pool. We demonstrate\nthat GM-PRM achieves state-of-the-art results on multiple multimodal math\nbenchmarks, significantly boosting policy model performance with remarkable\ndata efficiency, requiring only a 20K-sample training dataset. Our code will be\nreleased upon acceptance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u81ea\u52a8\u7ea0\u9519\u7684\u751f\u6210\u5f0f\u591a\u6a21\u6001\u6d41\u7a0b\u5956\u52b1\u6a21\u578b\uff08GM-PRM\uff09\uff0c\u5927\u5e45\u63d0\u5347\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u590d\u6742\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u8868\u73b0\uff0c\u4e14\u4ec5\u9700\u5c11\u91cf\u8bad\u7ec3\u6570\u636e\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u5904\u7406\u590d\u6742\u7684\u3001\u591a\u6b65\u7684\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u56e0\u4e3a\u5fae\u5c0f\u7684\u89c6\u89c9\u611f\u77e5\u6216\u903b\u8f91\u63a8\u7406\u9519\u8bef\u4f1a\u5bfc\u81f4\u6574\u4e2a\u63a8\u7406\u5931\u8d25\u3002\u867d\u7136\u6d41\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRMs\uff09\u53ef\u4ee5\u63d0\u4f9b\u5206\u6b65\u76d1\u7763\uff0c\u4f46\u5f53\u524d\u591a\u6a21\u6001PRMs\u4ec5\u80fd\u8bc6\u522b\u9519\u8bef\uff0c\u65e0\u6cd5\u7ea0\u6b63\uff0c\u4e14\u89e3\u91ca\u80fd\u529b\u6709\u9650\u3002", "method": "\u63d0\u51fa\u751f\u6210\u5f0f\u591a\u6a21\u6001\u6d41\u7a0b\u5956\u52b1\u6a21\u578b\uff08GM-PRM\uff09\uff0c\u5b83\u4e0d\u4ec5\u80fd\u7ec6\u81f4\u5730\u5206\u6790\u6bcf\u4e00\u6b65\u7684\u63a8\u7406\u610f\u56fe\u3001\u89c6\u89c9\u5339\u914d\u548c\u903b\u8f91\u5408\u7406\u6027\uff0c\u8fd8\u80fd\u4e3b\u52a8\u751f\u6210\u9519\u8bef\u63a8\u7406\u6b65\u9aa4\u7684\u4fee\u6b63\u7248\u672c\u3002\u5229\u7528\u8fd9\u4e00\u7ea0\u9519\u80fd\u529b\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86Refined Best-of-N\uff08Refined-BoN\uff09\u7684\u6d4b\u8bd5\u63a8\u7406\u7b56\u7565\uff0c\u5f15\u5bfc\u6a21\u578b\u671d\u66f4\u4f18\u7684\u63a8\u7406\u8def\u5f84\u53d1\u5c55\u3002", "result": "GM-PRM\u5728\u591a\u4e2a\u591a\u6a21\u6001\u6570\u5b66\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u6700\u65b0\u6700\u4f18\uff08SOTA\uff09\u6210\u7ee9\uff0c\u6781\u5927\u63d0\u5347\u4e86\u7b56\u7565\u6a21\u578b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u53ea\u9700\u6781\u5c0f\u7684\u6570\u636e\u91cf\uff08\u4ec52\u4e07\u6837\u672c\uff09\u5373\u53ef\u8bad\u7ec3\u3002", "conclusion": "GM-PRM\u5927\u5e45\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u590d\u6742\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u89e3\u91ca\u6027\u3001\u7ea0\u9519\u80fd\u529b\u548c\u6574\u4f53\u6027\u80fd\uff0c\u5e76\u4ee5\u9ad8\u6570\u636e\u6548\u7387\u53d6\u5f97\u4e86\u9886\u5148\u6210\u7ee9\u3002"}}
{"id": "2508.04117", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04117", "abs": "https://arxiv.org/abs/2508.04117", "authors": ["Zhiwen Ruan", "Yun Chen", "Yutao Hou", "Peng Li", "Yang Liu", "Guanhua Chen"], "title": "Unveiling Over-Memorization in Finetuning LLMs for Reasoning Tasks", "comment": null, "summary": "The pretrained large language models (LLMs) are finetuned with labeled data\nfor better instruction following ability and alignment with human values. In\nthis paper, we study the learning dynamics of LLM finetuning on reasoning tasks\nand reveal the uncovered over-memorization phenomenon during a specific stage\nof LLM finetuning. At this stage, the LLMs have excessively memorized training\ndata and exhibit high test perplexity while maintaining good test accuracy. We\ninvestigate the conditions that lead to LLM over-memorization and find that\ntraining epochs and large learning rates contribute to this issue. Although\nmodels with over-memorization demonstrate comparable test accuracy to normal\nmodels, they suffer from reduced robustness, poor out-of-distribution\ngeneralization, and decreased generation diversity. Our experiments unveil the\nover-memorization to be broadly applicable across different tasks, models, and\nfinetuning methods. Our research highlights that overparameterized, extensively\nfinetuned LLMs exhibit unique learning dynamics distinct from traditional\nmachine learning models. Based on our observations of over-memorization, we\nprovide recommendations on checkpoint and learning rate selection during\nfinetuning.", "AI": {"tldr": "LLM\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u5bb9\u6613\u4ea7\u751f\u8fc7\u5ea6\u8bb0\u5fc6\uff0c\u867d\u51c6\u786e\u7387\u672a\u964d\u4f46\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u53d8\u5dee\u3002\u4f5c\u8005\u7cfb\u7edf\u5206\u6790\u8be5\u73b0\u8c61\u53ca\u6210\u56e0\uff0c\u5e76\u63d0\u51fa\u5fae\u8c03\u4f18\u5316\u5efa\u8bae\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\uff0c\u7279\u522b\u662f\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u5b58\u5728\u672a\u88ab\u5145\u5206\u8ba4\u8bc6\u7684\u95ee\u9898\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7d22LLM\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u5b58\u5728\u7684\u65b0\u578b\u8fc7\u5ea6\u8bb0\u5fc6\u73b0\u8c61\uff0c\u4ee5\u4fc3\u8fdb\u5bf9\u6a21\u578b\u5b66\u4e60\u673a\u5236\u7684\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u5c06LLM\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u5b9e\u9a8c\u5206\u6790\u6a21\u578b\u5728\u4e0d\u540c\u8bad\u7ec3\u8f6e\u6b21\u548c\u5b66\u4e60\u7387\u4e0b\u7684\u5b66\u4e60\u52a8\u6001\uff0c\u89c2\u5bdf\u6a21\u578b\u5728\u4fdd\u6301\u6d4b\u8bd5\u51c6\u786e\u7387\u60c5\u51b5\u4e0b\u51fa\u73b0\u7684\u9ad8\u6d4b\u8bd5\u56f0\u60d1\u5ea6\u3001\u9c81\u68d2\u6027\u4e0b\u964d\u3001\u6cdb\u5316\u80fd\u529b\u53d8\u5dee\u7b49\u73b0\u8c61\u3002\u8986\u76d6\u4e86\u591a\u4efb\u52a1\u3001\u591a\u6a21\u578b\u3001\u591a\u79cd\u5fae\u8c03\u65b9\u6cd5\u3002", "result": "\u5728\u6a21\u578b\u5fae\u8c03\u7684\u7279\u5b9a\u9636\u6bb5\uff0cLLM\u4f1a\u5bf9\u8bad\u7ec3\u6570\u636e\u4ea7\u751f\u8fc7\u5ea6\u8bb0\u5fc6\uff0c\u5bfc\u81f4\u6d4b\u8bd5\u56f0\u60d1\u5ea6\u9ad8\uff0c\u4f46\u6d4b\u8bd5\u51c6\u786e\u7387\u4f9d\u7136\u4e0d\u9519\u3002\u540c\u65f6\uff0c\u53d1\u73b0\u8fc7\u5ea6\u8bb0\u5fc6\u4f7f\u6a21\u578b\u9c81\u68d2\u6027\u3001\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\u548c\u751f\u6210\u591a\u6837\u6027\u964d\u4f4e\u3002\u8be5\u73b0\u8c61\u5728\u4e0d\u540c\u4efb\u52a1\u3001\u6a21\u578b\u548c\u5fae\u8c03\u65b9\u6cd5\u4e2d\u5747\u666e\u904d\u5b58\u5728\u3002", "conclusion": "\u8fc7\u5ea6\u53c2\u6570\u5316\u3001\u957f\u671f\u5fae\u8c03\u7684LLM\u5728\u5b66\u4e60\u52a8\u6001\u4e0a\u8868\u73b0\u51fa\u4e0e\u4f20\u7edf\u6a21\u578b\u663e\u8457\u4e0d\u540c\u7684\u7279\u70b9\u3002\u57fa\u4e8e\u8fc7\u5ea6\u8bb0\u5fc6\u73b0\u8c61\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u6a21\u578b\u5fae\u8c03\u65f6\u5173\u4e8e\u68c0\u67e5\u70b9\u9009\u62e9\u548c\u5b66\u4e60\u7387\u8c03\u6574\u7684\u4f18\u5316\u5efa\u8bae\u3002"}}
{"id": "2508.04149", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04149", "abs": "https://arxiv.org/abs/2508.04149", "authors": ["Xuan Qi", "Rongwu Xu", "Zhijing Jin"], "title": "Difficulty-Based Preference Data Selection by DPO Implicit Reward Gap", "comment": "Our code and data are available at\n  https://github.com/Difficulty-Based-Preference-Data-Select/Difficulty-Based-Preference-Data-Select", "summary": "Aligning large language models (LLMs) with human preferences is a critical\nchallenge in AI research. While methods like Reinforcement Learning from Human\nFeedback (RLHF) and Direct Preference Optimization (DPO) are widely used, they\noften rely on large, costly preference datasets. The current work lacks methods\nfor high-quality data selection specifically for preference data. In this work,\nwe introduce a novel difficulty-based data selection strategy for preference\ndatasets, grounded in the DPO implicit reward mechanism. By selecting\npreference data examples with smaller DPO implicit reward gaps, which are\nindicative of more challenging cases, we improve data efficiency and model\nalignment. Our approach consistently outperforms five strong baselines across\nmultiple datasets and alignment tasks, achieving superior performance with only\n10\\% of the original data. This principled, efficient selection method offers a\npromising solution for scaling LLM alignment with limited resources.", "AI": {"tldr": "\u901a\u8fc7\u57fa\u4e8e\u96be\u5ea6\u7684\u6570\u636e\u9009\u62e9\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u6548\u7387\u548c\u6548\u679c\uff0c\u4ec5\u7528\u5c11\u91cf\u4f18\u9009\u6570\u636e\u5373\u53ef\u8d85\u8d8a\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u76ee\u524d\u57fa\u4e8e\u4eba\u7c7b\u504f\u597d\u7684\u5bf9\u9f50\u65b9\u6cd5\u5982RLHF\u548cDPO\u901a\u5e38\u9700\u8981\u5927\u91cf\u4e14\u6602\u8d35\u7684\u504f\u597d\u6570\u636e\u96c6\uff0c\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9\u504f\u597d\u6570\u636e\u8fdb\u884c\u9ad8\u8d28\u91cf\u6570\u636e\u9009\u62e9\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eDPO\u9690\u5f0f\u5956\u52b1\u673a\u5236\u7684\u3001\u4ee5\u96be\u5ea6\u4e3a\u5bfc\u5411\u7684\u6570\u636e\u9009\u62e9\u7b56\u7565\uff0c\u9009\u62e9\u5177\u6709\u8f83\u5c0fDPO\u9690\u5f0f\u5956\u52b1\u5dee\u7684\u6570\u636e\u6837\u672c\u4f5c\u4e3a\u66f4\u5177\u6311\u6218\u6027\u7684\u8bad\u7ec3\u4f8b\u5b50\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u4e94\u4e2a\u5f3a\u529b\u7684\u57fa\u7ebf\uff0c\u4ec5\u7528\u539f\u6570\u636e\u768410%\u5373\u53ef\u53d6\u5f97\u66f4\u4f18\u7684\u6548\u679c\u3002", "conclusion": "\u8fd9\u79cd\u9ad8\u6548\u4e14\u6709\u539f\u5219\u6027\u7684\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u80fd\u5728\u8d44\u6e90\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u6269\u5c55\u5927\u6a21\u578b\u5bf9\u9f50\u8fc7\u7a0b\uff0c\u5bf9LLM\u5bf9\u9f50\u95ee\u9898\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2508.04179", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2508.04179", "abs": "https://arxiv.org/abs/2508.04179", "authors": ["Praveen Srinivasa Varadhan", "Sherry Thomas", "Sai Teja M. S.", "Suvrat Bhooshan", "Mitesh M. Khapra"], "title": "The State Of TTS: A Case Study with Human Fooling Rates", "comment": "Accepted at InterSpeech 2025", "summary": "While subjective evaluations in recent years indicate rapid progress in TTS,\ncan current TTS systems truly pass a human deception test in a Turing-like\nevaluation? We introduce Human Fooling Rate (HFR), a metric that directly\nmeasures how often machine-generated speech is mistaken for human. Our\nlarge-scale evaluation of open-source and commercial TTS models reveals\ncritical insights: (i) CMOS-based claims of human parity often fail under\ndeception testing, (ii) TTS progress should be benchmarked on datasets where\nhuman speech achieves high HFRs, as evaluating against monotonous or less\nexpressive reference samples sets a low bar, (iii) Commercial models approach\nhuman deception in zero-shot settings, while open-source systems still struggle\nwith natural conversational speech; (iv) Fine-tuning on high-quality data\nimproves realism but does not fully bridge the gap. Our findings underscore the\nneed for more realistic, human-centric evaluations alongside existing\nsubjective tests.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4ee5Human Fooling Rate\u8861\u91cfTTS\u6a21\u578b\u62df\u4eba\u5ea6\u5e76\u5f00\u5c55\u5927\u89c4\u6a21\u6d4b\u8bd5\u3002\u7ed3\u679c\u663e\u793a\u4e3b\u6d41TTS\u6a21\u578b\u5728\u8ff7\u60d1\u4eba\u7c7b\u65b9\u9762\u5c1a\u6709\u9650\uff0c\u5546\u7528\u7cfb\u7edf\u8868\u73b0\u4f18\u4e8e\u5f00\u6e90\uff0c\u5efa\u8bae\u672a\u6765\u8bc4\u6d4b\u5e94\u66f4\u8d34\u8fd1\u771f\u5b9e\u4eba\u7c7b\u611f\u77e5\u3002", "motivation": "\u8fd1\u5e74\u6765TTS\uff08\u6587\u672c\u5230\u8bed\u97f3\uff09\u6280\u672f\u4e3b\u89c2\u8bc4\u4ef7\u663e\u793a\u8fdb\u6b65\u660e\u663e\uff0c\u4f46\u73b0\u6709TTS\u7cfb\u7edf\u80fd\u5426\u5728\u7c7b\u4f3c\u56fe\u7075\u6d4b\u8bd5\u7684\u4eba\u7c7b\u6b3a\u9a97\u6d4b\u8bd5\u4e2d\u901a\u8fc7\uff0c\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8861\u91cf\u6307\u6807Human Fooling Rate (HFR)\uff0c\u5373\u673a\u5668\u751f\u6210\u8bed\u97f3\u88ab\u8bef\u8ba4\u4e3a\u4eba\u7c7b\u8bed\u97f3\u7684\u6bd4\u4f8b\uff0c\u5e76\u5bf9\u5f00\u6e90\u4e0e\u5546\u7528TTS\u6a21\u578b\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u8bc4\u4f30\u3002", "result": "\uff08i\uff09\u57fa\u4e8eCMOS\u7684\u201c\u5ab2\u7f8e\u4eba\u7c7b\u201d\u4e3b\u5f20\u5728\u6b3a\u9a97\u6d4b\u8bd5\u4e0b\u5e38\u5e38\u4e0d\u6210\u7acb\uff1b\uff08ii\uff09TTS\u8fdb\u6b65\u5e94\u5728\u9ad8HFR\u6570\u636e\u96c6\u4e0a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u907f\u514d\u8bbe\u7f6e\u8fc7\u4f4e\u7684\u8bc4\u4ef7\u6807\u51c6\uff1b\uff08iii\uff09\u5546\u7528\u6a21\u578b\u5728\u96f6\u6837\u672c\u60c5\u5883\u4e0b\u63a5\u8fd1\u4eba\u7c7b\u6b3a\u9a97\u80fd\u529b\uff0c\u800c\u5f00\u6e90\u7cfb\u7edf\u5728\u81ea\u7136\u5bf9\u8bdd\u7c7b\u8bed\u97f3\u4e0a\u8868\u73b0\u5c1a\u6709\u8ddd\u79bb\uff1b\uff08iv\uff09\u9ad8\u8d28\u91cf\u6570\u636e\u5fae\u8c03\u6709\u52a9\u63d0\u5347\u62df\u771f\u6027\u4f46\u8fd8\u4e0d\u80fd\u5b8c\u5168\u5f25\u8865\u5dee\u8ddd\u3002", "conclusion": "TTS\u7cfb\u7edf\u9700\u8981\u901a\u8fc7\u66f4\u771f\u5b9e\u3001\u66f4\u5173\u6ce8\u4eba\u7c7b\u4f53\u9a8c\u7684\u6d4b\u8bd5\u6765\u8bc4\u4ef7\uff0c\u800c\u4e0d\u4ec5\u4ec5\u4f9d\u8d56\u4f20\u7edf\u7684\u4e3b\u89c2\u8bc4\u4ef7\u624b\u6bb5\u3002"}}
{"id": "2508.04182", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04182", "abs": "https://arxiv.org/abs/2508.04182", "authors": ["Peizheng Guo", "Jingyao Wang", "Wenwen Qiang", "Huijie Guo", "Changwen Zheng", "Jiahuan Zhou", "Gang Hua"], "title": "Hacking Hallucinations of MLLMs with Causal Sufficiency and Necessity", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have demonstrated impressive\ncapabilities across vision-language tasks. However, they may suffer from\nhallucinations--generating outputs that are semantically inconsistent with the\ninput image or text. Through causal analyses, we find that: (i) hallucinations\nwith omission may arise from the failure to adequately capture essential causal\nfactors, and (ii) hallucinations with fabrication are likely caused by the\nmodel being misled by non-causal cues. To address these challenges, we propose\na novel reinforcement learning framework guided by causal completeness, which\njointly considers both causal sufficiency and causal necessity of tokens.\nSpecifically, we evaluate each token's standalone contribution and\ncounterfactual indispensability to define a token-level causal completeness\nreward. This reward is used to construct a causally informed advantage function\nwithin the GRPO optimization framework, encouraging the model to focus on\ntokens that are both causally sufficient and necessary for accurate generation.\nExperimental results across various benchmark datasets and tasks demonstrate\nthe effectiveness of our approach, which effectively mitigates hallucinations\nin MLLMs.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u95ee\u9898\uff0c\u901a\u8fc7\u56e0\u679c\u5206\u6790\u5256\u6790\u5176\u6839\u6e90\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u56e0\u679c\u5b8c\u5907\u6027\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u6709\u6548\u964d\u4f4e\u5e7b\u89c9\u73b0\u8c61\uff0c\u5b9e\u9a8c\u6548\u679c\u663e\u8457\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u89c6\u89c9-\u8bed\u8a00\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u5373\u6a21\u578b\u8f93\u51fa\u4e0e\u8f93\u5165\u7684\u56fe\u50cf\u6216\u6587\u672c\u5728\u8bed\u4e49\u4e0a\u4e0d\u4e00\u81f4\u3002\u8bba\u6587\u5e0c\u671b\u5206\u6790\u5e76\u89e3\u51b3\u8fd9\u4e00\u5e7b\u89c9\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u56e0\u679c\u5206\u6790\uff0c\u8bba\u6587\u53d1\u73b0\u5e7b\u89c9\u53ef\u5206\u4e3a\u9057\u6f0f\u548c\u634f\u9020\u4e24\u7c7b\uff0c\u5206\u522b\u7531\u672a\u6355\u6349\u56e0\u679c\u8981\u7d20\u548c\u88ab\u975e\u56e0\u679c\u7ebf\u7d22\u8bef\u5bfc\u5f15\u53d1\u3002\u9488\u5bf9\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u7531\u56e0\u679c\u5b8c\u5907\u6027\u5f15\u5bfc\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u540c\u65f6\u8003\u8651token\u7684\u56e0\u679c\u5145\u5206\u6027\u548c\u5fc5\u8981\u6027\u3002\u5177\u4f53\u505a\u6cd5\u662f\u8bc4\u4f30\u6bcf\u4e2atoken\u7684\u72ec\u7acb\u8d21\u732e\u548c\u53cd\u4e8b\u5b9e\u4e0d\u53ef\u6216\u7f3a\u6027\uff0c\u4ee5\u6b64\u5b9a\u4e49token\u7ea7\u7684\u56e0\u679c\u5b8c\u5907\u6027\u5956\u52b1\uff0c\u5e76\u7528\u5728GRPO\u4f18\u5316\u6846\u67b6\u4e2d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u5728\u591a\u79cd\u57fa\u51c6\u6570\u636e\u96c6\u548c\u4efb\u52a1\u4e0a\u5747\u53d6\u5f97\u4e86\u826f\u597d\u6548\u679c\u3002", "conclusion": "\u8bba\u6587\u4ee5\u56e0\u679c\u63a8\u65ad\u4e3a\u7406\u8bba\u57fa\u7840\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u56e0\u679c\u5b8c\u5907\u6027\u5f15\u5bfc\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u751f\u6210\u3002"}}
{"id": "2508.04183", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04183", "abs": "https://arxiv.org/abs/2508.04183", "authors": ["Abhinav Java", "Ashmit Khandelwal", "Sukruta Midigeshi", "Aaron Halfaker", "Amit Deshpande", "Navin Goyal", "Ankur Gupta", "Nagarajan Natarajan", "Amit Sharma"], "title": "Characterizing Deep Research: A Benchmark and Formal Definition", "comment": "First three authors contributed equally (ordered alphabetically)", "summary": "Information tasks such as writing surveys or analytical reports require\ncomplex search and reasoning, and have recently been grouped under the umbrella\nof \\textit{deep research} -- a term also adopted by recent models targeting\nthese capabilities. Despite growing interest, the scope of the deep research\ntask remains underdefined and its distinction from other reasoning-intensive\nproblems is poorly understood. In this paper, we propose a formal\ncharacterization of the deep research (DR) task and introduce a benchmark to\nevaluate the performance of DR systems. We argue that the core defining feature\nof deep research is not the production of lengthy report-style outputs, but\nrather the high fan-out over concepts required during the search process, i.e.,\nbroad and reasoning-intensive exploration. To enable objective evaluation, we\ndefine DR using an intermediate output representation that encodes key claims\nuncovered during search-separating the reasoning challenge from surface-level\nreport generation. Based on this formulation, we propose a diverse, challenging\nbenchmark LiveDRBench with 100 challenging tasks over scientific topics (e.g.,\ndatasets, materials discovery, prior art search) and public interest events\n(e.g., flight incidents, movie awards). Across state-of-the-art DR systems, F1\nscore ranges between 0.02 and 0.72 for any sub-category. OpenAI's model\nperforms the best with an overall F1 score of 0.55. Analysis of reasoning\ntraces reveals the distribution over the number of referenced sources,\nbranching, and backtracking events executed by current DR systems, motivating\nfuture directions for improving their search mechanisms and grounding\ncapabilities. The benchmark is available at\nhttps://github.com/microsoft/LiveDRBench.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5b9a\u4e49\u4e86\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\uff0c\u5e76\u63d0\u51fa\u4e86LiveDRBench\u57fa\u51c6\uff0c\u6d4b\u8bd5\u5f53\u4ee3\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u76ee\u524d\u7cfb\u7edf\u5728\u5927\u8303\u56f4\u63a8\u7406\u63a2\u7d22\u4e0a\u5b58\u5728\u663e\u8457\u63d0\u5347\u7a7a\u95f4\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u5bf9\u6df1\u5ea6\u7814\u7a76\uff08deep research\uff09\u4efb\u52a1\u7684\u5173\u6ce8\u4e0d\u65ad\u589e\u52a0\uff0c\u4f46\u5176\u5b9a\u4e49\u6a21\u7cca\uff0c\u4e0e\u5176\u4ed6\u9ad8\u63a8\u7406\u4efb\u52a1\u7684\u533a\u5206\u4e0d\u660e\u786e\u3002\u4f5c\u8005\u5e0c\u671b\u66f4\u7cfb\u7edf\u5730\u5b9a\u4e49\u2018\u6df1\u5ea6\u7814\u7a76\u2019\u4efb\u52a1\uff0c\u5e76\u5efa\u7acb\u8bc4\u6d4b\u57fa\u51c6\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u5bf9\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u7684\u6b63\u5f0f\u754c\u5b9a\uff0c\u8ba4\u4e3a\u5176\u6838\u5fc3\u7279\u5f81\u662f\u641c\u7d22\u8fc7\u7a0b\u4e2d\u5bf9\u6982\u5ff5\u7684\u5927\u8303\u56f4\u3001\u9ad8\u63a8\u7406\u6027\u63a2\u7d22\uff0c\u5e76\u63d0\u51fa\u7528\u4e2d\u95f4\u8f93\u51fa\u8868\u5f81\u5206\u79bb\u63a8\u7406\u4e0e\u62a5\u544a\u751f\u6210\u3002\u4ed6\u4eec\u636e\u6b64\u6784\u5efa\u4e86\u540d\u4e3aLiveDRBench\u7684\u57fa\u51c6\u96c6\uff0c\u6db5\u76d6100\u4e2a\u5173\u4e8e\u79d1\u5b66\u4e0e\u516c\u5171\u4e8b\u4ef6\u7684\u6311\u6218\u6027\u4efb\u52a1\u3002", "result": "\u5728\u8be5\u57fa\u51c6\u96c6\u4e0a\uff0c\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u7684\u5b50\u4efb\u52a1F1\u5206\u6570\u57280.02\u81f30.72\u4e4b\u95f4\uff0cOpenAI\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u603b\u4f53F1\u4e3a0.55\u3002\u4f5c\u8005\u8fd8\u5206\u6790\u4e86\u63a8\u7406\u8f68\u8ff9\uff0c\u8986\u76d6\u4e86\u5f15\u7528\u6765\u6e90\u6570\u91cf\u3001\u5206\u652f\u4e0e\u56de\u6eaf\u7b49\u6307\u6807\u3002", "conclusion": "\u672c\u6587\u660e\u786e\u4e86\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u7684\u6838\u5fc3\u7279\u5f81\u3001\u7ed9\u51fa\u4e86\u8bc4\u6d4b\u57fa\u51c6\uff0c\u5e76\u63ed\u793a\u4e86\u5f53\u524d\u7cfb\u7edf\u5728\u63a8\u7406\u548c\u641c\u7d22\u673a\u5236\u4e0a\u7684\u4e0d\u8db3\uff0c\u4e3a\u672a\u6765\u6539\u8fdb\u65b9\u5411\u63d0\u4f9b\u4e86\u4f9d\u636e\u3002"}}
{"id": "2508.04196", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.04196", "abs": "https://arxiv.org/abs/2508.04196", "authors": ["Siddhant Panpatil", "Hiskias Dingeto", "Haon Park"], "title": "Eliciting and Analyzing Emergent Misalignment in State-of-the-Art Large Language Models", "comment": null, "summary": "Despite significant advances in alignment techniques, we demonstrate that\nstate-of-the-art language models remain vulnerable to carefully crafted\nconversational scenarios that can induce various forms of misalignment without\nexplicit jailbreaking. Through systematic manual red-teaming with\nClaude-4-Opus, we discovered 10 successful attack scenarios, revealing\nfundamental vulnerabilities in how current alignment methods handle narrative\nimmersion, emotional pressure, and strategic framing. These scenarios\nsuccessfully elicited a range of misaligned behaviors, including deception,\nvalue drift, self-preservation, and manipulative reasoning, each exploiting\ndifferent psychological and contextual vulnerabilities. To validate\ngeneralizability, we distilled our successful manual attacks into\nMISALIGNMENTBENCH, an automated evaluation framework that enables reproducible\ntesting across multiple models. Cross-model evaluation of our 10 scenarios\nagainst five frontier LLMs revealed an overall 76% vulnerability rate, with\nsignificant variations: GPT-4.1 showed the highest susceptibility (90%), while\nClaude-4-Sonnet demonstrated greater resistance (40%). Our findings demonstrate\nthat sophisticated reasoning capabilities often become attack vectors rather\nthan protective mechanisms, as models can be manipulated into complex\njustifications for misaligned behavior. This work provides (i) a detailed\ntaxonomy of conversational manipulation patterns and (ii) a reusable evaluation\nframework. Together, these findings expose critical gaps in current alignment\nstrategies and highlight the need for robustness against subtle, scenario-based\nmanipulation in future AI systems.", "AI": {"tldr": "\u672c\u8bba\u6587\u63ed\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u5bf9\u8bdd\u4e0b\u6613\u88ab\u8bf1\u5bfc\u51fa\u73b0\u8bef\u5bf9\u9f50\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u81ea\u52a8\u8bc4\u6d4b\u5de5\u5177\u548c\u5206\u7c7b\u4f53\u7cfb\uff0c\u8de8\u6a21\u578b\u5b9e\u9a8c\u8bc1\u660e\u8bef\u5bf9\u9f50\u73b0\u8c61\u666e\u904d\u4e14\u4e25\u91cd\uff0c\u6307\u660e\u672a\u6765AI\u9700\u63d0\u5347\u9488\u5bf9\u9690\u853d\u64cd\u63a7\u573a\u666f\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5728\u5927\u6a21\u578b\u5bf9\u9f50\u6280\u672f\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u6a21\u578b\u4ecd\u5b58\u5728\u5728\u67d0\u4e9b\u590d\u6742\u5bf9\u8bdd\u573a\u666f\u4e0b\u5931\u6548\u7684\u9690\u5fe7\u3002\u4e3a\u8bc4\u4f30\u548c\u63ed\u793a\u8fd9\u4e9b\u6f5c\u5728\u7684\u5b89\u5168\u9690\u60a3\uff0c\u4f5c\u8005\u5e0c\u671b\u7cfb\u7edf\u6027\u5730\u6316\u6398\u73b0\u6709\u5bf9\u9f50\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "method": "\u4f5c\u8005\u91c7\u7528\u7cfb\u7edf\u6027\u7684\u4eba\u5de5\u5bf9\u6297\uff08red-teaming\uff09\u6d4b\u8bd5\uff0c\u9488\u5bf9Claude-4-Opus\u53d1\u73b0\u5e76\u603b\u7ed3\u4e8610\u79cd\u80fd\u591f\u8bf1\u53d1\u6a21\u578b\u5931\u6548\uff08\u8bef\u5bf9\u9f50\uff09\u884c\u4e3a\u7684\u573a\u666f\uff0c\u5e76\u5c06\u8fd9\u4e9b\u653b\u51fb\u65b9\u6cd5\u8f6c\u5316\u4e3a\u4e00\u4e2a\u81ea\u52a8\u5316\u8bc4\u6d4b\u6846\u67b6MISALIGNMENTBENCH\uff0c\u4ee5\u4fbf\u5728\u591a\u4e2a\u4e3b\u6d41\u5927\u6a21\u578b\u4e0a\u8fdb\u884c\u53ef\u91cd\u590d\u6027\u6d4b\u8bd5\u548c\u6a2a\u5411\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c10\u79cd\u653b\u51fb\u573a\u666f\u57285\u4e2a\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5e73\u5747\u6210\u529f\u7387\u9ad8\u8fbe76%\uff0c\u5176\u4e2dGPT-4.1\u6700\u6613\u53d7\u653b\u51fb\uff0890%\uff09\uff0c\u800cClaude-4-Sonnet\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u62b5\u6297\u529b\uff0840%\uff09\u3002\u8fd9\u4e9b\u573a\u666f\u80fd\u5f15\u53d1\u6a21\u578b\u6b3a\u9a97\u3001\u4ef7\u503c\u6f02\u79fb\u3001\u81ea\u6211\u4fdd\u62a4\u3001\u64cd\u63a7\u6027\u63a8\u7406\u7b49\u591a\u79cd\u5931\u6548\u884c\u4e3a\u3002", "conclusion": "\u5f53\u524d\u5148\u8fdb\u7684\u5bf9\u9f50\u7b56\u7565\u4ecd\u6709\u663e\u8457\u7f3a\u9677\uff0c\u6a21\u578b\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\u53cd\u800c\u5e38\u88ab\u653b\u51fb\u8005\u4f5c\u4e3a\u7a81\u7834\u53e3\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u8be6\u5c3d\u7684\u5bf9\u8bdd\u64cd\u63a7\u573a\u666f\u5206\u7c7b\u4f53\u7cfb\u53ca\u81ea\u52a8\u5316\u8bc4\u6d4b\u5de5\u5177\uff0c\u4e3aAI\u5bf9\u9f50\u6280\u672f\u7684\u672a\u6765\u53d1\u5c55\u4e0e\u5b89\u5168\u6027\u63d0\u51fa\u66f4\u9ad8\u8981\u6c42\u3002"}}
{"id": "2508.04199", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04199", "abs": "https://arxiv.org/abs/2508.04199", "authors": ["Millicent Ochieng", "Anja Thieme", "Ignatius Ezeani", "Risa Ueno", "Samuel Maina", "Keshet Ronen", "Javier Gonzalez", "Jacki O'Neill"], "title": "Reasoning Beyond Labels: Measuring LLM Sentiment in Low-Resource, Culturally Nuanced Contexts", "comment": null, "summary": "Sentiment analysis in low-resource, culturally nuanced contexts challenges\nconventional NLP approaches that assume fixed labels and universal affective\nexpressions. We present a diagnostic framework that treats sentiment as a\ncontext-dependent, culturally embedded construct, and evaluate how large\nlanguage models (LLMs) reason about sentiment in informal, code-mixed WhatsApp\nmessages from Nairobi youth health groups. Using a combination of\nhuman-annotated data, sentiment-flipped counterfactuals, and rubric-based\nexplanation evaluation, we probe LLM interpretability, robustness, and\nalignment with human reasoning. Framing our evaluation through a social-science\nmeasurement lens, we operationalize and interrogate LLMs outputs as an\ninstrument for measuring the abstract concept of sentiment. Our findings reveal\nsignificant variation in model reasoning quality, with top-tier LLMs\ndemonstrating interpretive stability, while open models often falter under\nambiguity or sentiment shifts. This work highlights the need for culturally\nsensitive, reasoning-aware AI evaluation in complex, real-world communication.", "AI": {"tldr": "\u672c\u7814\u7a76\u9488\u5bf9\u591a\u8bed\u6df7\u7528\u3001\u6587\u5316\u4e30\u5bcc\u4f46\u8d44\u6e90\u532e\u4e4f\u8bed\u5883\u4e0b\u7684\u60c5\u611f\u5206\u6790\uff0c\u63d0\u51fa\u8bca\u65ad\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u9876\u5c16LLM\u5728\u590d\u6742\u573a\u666f\u4e0b\u7684\u4f18\u52bf\u548c\u73b0\u6709\u5f00\u6e90\u6a21\u578b\u7684\u4e0d\u8db3\uff0c\u5f3a\u8c03\u6587\u5316\u654f\u611f\u8bc4\u4f30\u65b9\u6cd5\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406(NLP)\u65b9\u6cd5\u5728\u60c5\u611f\u5206\u6790\u4e2d\u901a\u5e38\u5047\u8bbe\u6807\u7b7e\u56fa\u5b9a\u4e14\u60c5\u611f\u8868\u8fbe\u5177\u6709\u666e\u904d\u6027\uff0c\u4f46\u5728\u8d44\u6e90\u532e\u4e4f\u4e14\u6587\u5316\u8bed\u5883\u590d\u6742\u7684\u73af\u5883\u4e0b\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u9762\u4e34\u5de8\u5927\u6311\u6218\u3002\u4f5c\u8005\u5e0c\u671b\u89e3\u51b3\u4e3b\u6d41\u60c5\u611f\u5206\u6790\u65b9\u6cd5\u5728\u6587\u5316\u654f\u611f\u3001\u591a\u8bed\u4ee3\u7801\u6df7\u7528\u8bed\u5883\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c06\u60c5\u611f\u89c6\u4e3a\u4f9d\u8d56\u60c5\u5883\u3001\u6587\u5316\u5d4c\u5165\u6027\u6784\u5ff5\u7684\u8bca\u65ad\u6027\u6846\u67b6\uff0c\u901a\u8fc7\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u3001\u60c5\u611f\u7ffb\u8f6c\u7684\u5bf9\u7167\u6837\u672c\u4ee5\u53ca\u57fa\u4e8e\u91cf\u8868\u7684\u89e3\u91ca\u6027\u8bc4\u4ef7\uff0c\u5206\u6790\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5185\u7f57\u6bd5\u9752\u5e74\u5065\u5eb7\u5c0f\u7ec4\u4e2dWhatsApp\u6d88\u606f\u7684\u60c5\u611f\u63a8\u7406\u8fc7\u7a0b\uff0c\u91cd\u70b9\u8003\u5bdf\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3001\u9c81\u68d2\u6027\u53ca\u4e0e\u4eba\u7c7b\u63a8\u7406\u7684\u4e00\u81f4\u6027\u3002", "result": "\u53d1\u73b0\u4e0d\u540cLLM\u63a8\u7406\u8d28\u91cf\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1a\u9876\u5c16LLM\u8868\u73b0\u51fa\u89e3\u91ca\u7684\u7a33\u5b9a\u6027\uff0c\u800c\u5f00\u6e90\u6a21\u578b\u5728\u9762\u5bf9\u6a21\u7cca\u6216\u60c5\u611f\u53d8\u5316\u65f6\u5e38\u5e38\u8868\u73b0\u4e0d\u4f73\u3002\u6a21\u578b\u5728\u60c5\u611f\u8bc6\u522b\u4e0a\u7684\u8868\u73b0\u53d7\u6587\u5316\u8bed\u5883\u5f71\u54cd\u663e\u8457\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u793e\u4f1a\u79d1\u5b66\u6d4b\u91cf\u601d\u8def\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5728\u590d\u6742\u3001\u771f\u5b9e\u8bed\u5883\u4e0b\u5bf9LLM\u60c5\u611f\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u8bca\u65ad\u548c\u6bd4\u8f83\u3002\u7814\u7a76\u663e\u793a\uff0c\u590d\u6742\u8de8\u6587\u5316\u4ea4\u6d41\u573a\u666f\u9700\u8003\u8651\u6587\u5316\u654f\u611f\u6027\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5bf9AI\u8bc4\u4ef7\u6807\u51c6\u63d0\u51fa\u65b0\u8981\u6c42\u3002"}}
{"id": "2508.04204", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04204", "abs": "https://arxiv.org/abs/2508.04204", "authors": ["Yuquan Wang", "Mi Zhang", "Yining Wang", "Geng Hong", "Xiaoyu You", "Min Yang"], "title": "ReasoningGuard: Safeguarding Large Reasoning Models with Inference-time Safety Aha Moments", "comment": null, "summary": "Large Reasoning Models (LRMs) have demonstrated impressive performance in\nreasoning-intensive tasks, but they remain vulnerable to harmful content\ngeneration, particularly in the mid-to-late steps of their reasoning processes.\nExisting defense mechanisms, however, rely on costly fine-tuning and additional\nexpert knowledge, which restricts their scalability. In this work, we propose\nReasoningGuard, an inference-time safeguard for LRMs, which injects timely\nsafety aha moments to steer harmless while helpful reasoning processes.\nLeveraging the model's internal attention behavior, our approach accurately\nidentifies critical points in the reasoning path, and triggers spontaneous,\nsafety-oriented reflection. To safeguard both the subsequent reasoning steps\nand the final answers, we further implement a scaling sampling strategy during\nthe decoding phase, selecting the optimal reasoning path. Inducing minimal\nextra inference cost, ReasoningGuard effectively mitigates three types of\njailbreak attacks, including the latest ones targeting the reasoning process of\nLRMs. Our approach outperforms seven existing safeguards, achieving\nstate-of-the-art safety defenses while effectively avoiding the common\nexaggerated safety issues.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faReasoningGuard\uff0c\u901a\u8fc7\u5206\u6790\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u65f6\u8fdb\u884c\u5b89\u5168\u81ea\u7701\u548c\u8def\u5f84\u91c7\u6837\uff0c\u4f4e\u6210\u672c\u63d0\u9ad8\u5927\u6a21\u578b\u5185\u5bb9\u5b89\u5168\u6027\uff0c\u8d85\u8fc7\u5f53\u524d\u4e03\u79cd\u4e3b\u6d41\u9632\u62a4\u624b\u6bb5\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5c3d\u7ba1\u5728\u9700\u8981\u63a8\u7406\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u63a8\u7406\u8fc7\u7a0b\u7684\u4e2d\u540e\u671f\u4ecd\u7136\u5bb9\u6613\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u3002\u73b0\u6709\u7684\u9632\u62a4\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u6602\u8d35\u7684\u5fae\u8c03\u548c\u4e13\u5bb6\u77e5\u8bc6\uff0c\u96be\u4ee5\u5927\u89c4\u6a21\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86ReasoningGuard\uff0c\u8fd9\u662f\u4e00\u79cd\u5728\u63a8\u7406\u6a21\u578b\u63a8\u7406\u65f6\u8fdb\u884c\u4fdd\u62a4\u7684\u65b9\u6cd5\u3002\u5b83\u901a\u8fc7\u5206\u6790\u6a21\u578b\u5185\u90e8\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u51c6\u786e\u8bc6\u522b\u63a8\u7406\u8def\u5f84\u7684\u5173\u952e\u8282\u70b9\uff0c\u53ca\u65f6\u89e6\u53d1\u9762\u5411\u5b89\u5168\u7684\u81ea\u7701\u6b65\u9aa4\uff0c\u5e76\u5728\u89e3\u7801\u9636\u6bb5\u5f15\u5165\u91c7\u6837\u7b56\u7565\uff0c\u4ee5\u9009\u62e9\u6700\u4f18\u7684\u63a8\u7406\u8def\u5f84\uff0c\u4ece\u800c\u51cf\u5c11\u6709\u5bb3\u5185\u5bb9\u751f\u6210\u3002\u8be5\u65b9\u6cd5\u53ea\u9700\u8f83\u5c0f\u7684\u989d\u5916\u63a8\u7406\u5f00\u9500\uff0c\u65e0\u9700\u5fae\u8c03\u6216\u989d\u5916\u77e5\u8bc6\u3002", "result": "ReasoningGuard\u6210\u529f\u9632\u5fa1\u4e86\u5305\u62ec\u9488\u5bf9\u63a8\u7406\u8fc7\u7a0b\u7684\u6700\u65b0\u8d8a\u72f1\u653b\u51fb\u5728\u5185\u7684\u4e09\u7c7b\u5b89\u5168\u653b\u51fb\uff0c\u5bf9\u6bd4\u4e03\u79cd\u5df2\u6709\u4fdd\u62a4\u673a\u5236\u8868\u73b0\u66f4\u4f73\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6c34\u5e73\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u6709\u6548\u907f\u514d\u4e86\u8fc7\u5ea6\u5b89\u5168\u9020\u6210\u7684\u95ee\u9898\u3002", "conclusion": "ReasoningGuard\u4f5c\u4e3a\u65e0\u9700\u5fae\u8c03\u3001\u9ad8\u6548\u7684\u63a8\u7406\u65f6\u4fdd\u62a4\u65b9\u6848\uff0c\u5728\u4fdd\u969c\u5927\u578b\u63a8\u7406\u6a21\u578b\u751f\u6210\u5185\u5bb9\u5b89\u5168\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u826f\u597d\u7684\u5b9e\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2508.04219", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04219", "abs": "https://arxiv.org/abs/2508.04219", "authors": ["Kosuke Yoshimura", "Hisashi Kashima"], "title": "Hierarchical Text Classification Using Black Box Large Language Models", "comment": "16 pages, 6 figures", "summary": "Hierarchical Text Classification (HTC) aims to assign texts to structured\nlabel hierarchies; however, it faces challenges due to data scarcity and model\ncomplexity. This study explores the feasibility of using black box Large\nLanguage Models (LLMs) accessed via APIs for HTC, as an alternative to\ntraditional machine learning methods that require extensive labeled data and\ncomputational resources. We evaluate three prompting strategies -- Direct Leaf\nLabel Prediction (DL), Direct Hierarchical Label Prediction (DH), and Top-down\nMulti-step Hierarchical Label Prediction (TMH) -- in both zero-shot and\nfew-shot settings, comparing the accuracy and cost-effectiveness of these\nstrategies. Experiments on two datasets show that a few-shot setting\nconsistently improves classification accuracy compared to a zero-shot setting.\nWhile a traditional machine learning model achieves high accuracy on a dataset\nwith a shallow hierarchy, LLMs, especially DH strategy, tend to outperform the\nmachine learning model on a dataset with a deeper hierarchy. API costs increase\nsignificantly due to the higher input tokens required for deeper label\nhierarchies on DH strategy. These results emphasize the trade-off between\naccuracy improvement and the computational cost of prompt strategy. These\nfindings highlight the potential of black box LLMs for HTC while underscoring\nthe need to carefully select a prompt strategy to balance performance and cost.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u901a\u8fc7API\u8c03\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u5206\u5c42\u6587\u672c\u5206\u7c7b\u7684\u6548\u679c\uff0c\u53d1\u73b0\u9002\u5f53\u7684\u63d0\u793a\u7b56\u7565\u80fd\u591f\u5728\u6df1\u5c42\u6b21\u7ed3\u6784\u4e0a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u4e5f\u4f1a\u5e26\u6765\u66f4\u9ad8\u8ba1\u7b97\u6210\u672c\uff0c\u63d0\u793a\u51c6\u786e\u6027\u4e0e\u8d44\u6e90\u6d88\u8017\u9700\u6743\u8861\u3002", "motivation": "\u5206\u5c42\u6587\u672c\u5206\u7c7b\uff08HTC\uff09\u7531\u4e8e\u6570\u636e\u7a00\u7f3a\u548c\u6a21\u578b\u590d\u6742\u6027\u800c\u9762\u4e34\u6311\u6218\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u901a\u8fc7API\u8bbf\u95ee\u7684\u9ed1\u76d2\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728HTC\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u4f5c\u4e3a\u4f20\u7edf\u9700\u5927\u91cf\u6807\u6ce8\u6570\u636e\u548c\u7b97\u529b\u652f\u6301\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u8bc4\u4f30\u4e86\u4e09\u79cd\u63d0\u793a\u7b56\u7565\uff1a\u76f4\u63a5\u53f6\u5b50\u6807\u7b7e\u9884\u6d4b\uff08DL\uff09\u3001\u76f4\u63a5\u5c42\u7ea7\u6807\u7b7e\u9884\u6d4b\uff08DH\uff09\u548c\u81ea\u9876\u5411\u4e0b\u591a\u6b65\u5c42\u7ea7\u6807\u7b7e\u9884\u6d4b\uff08TMH\uff09\uff0c\u5e76\u5728\u96f6\u6837\u672c\u548c\u5c0f\u6837\u672c\u4e0b\u6d4b\u8bd5\u8fd9\u4e9b\u7b56\u7565\u7684\u51c6\u786e\u6027\u4e0e\u6210\u672c\u6548\u76ca\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u5c0f\u6837\u672c\u4e0b\u7684\u5206\u7c7b\u51c6\u786e\u7387\u666e\u904d\u9ad8\u4e8e\u96f6\u6837\u672c\u3002\u5bf9\u6d45\u5c42\u6b21\u7ed3\u6784\u6570\u636e\uff0c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u5728\u6df1\u5c42\u6b21\u7ed3\u6784\u6570\u636e\u4e0a\uff0cLLM\uff08\u7279\u522b\u662fDH\u7b56\u7565\uff09\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\u3002\u5bf9\u4e8e\u5c42\u6b21\u8d8a\u6df1\u7684\u6807\u7b7e\u7ed3\u6784\uff0cDH\u7b56\u7565\u7684API\u6210\u672c\u663e\u8457\u4e0a\u5347\u3002", "conclusion": "\u9ed1\u76d2\u5927\u8bed\u8a00\u6a21\u578b\u5728HTC\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u5c24\u5176\u9002\u5408\u6df1\u5c42\u6b21\u6807\u7b7e\u7ed3\u6784\u3002\u4f46\u9700\u6743\u8861\u63d0\u793a\u7b56\u7565\u7684\u6027\u80fd\u63d0\u5347\u4e0e\u8ba1\u7b97\u6210\u672c\uff0c\u5408\u7406\u7b56\u7565\u9009\u62e9\u5c24\u4e3a\u91cd\u8981\u3002"}}
{"id": "2508.04239", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04239", "abs": "https://arxiv.org/abs/2508.04239", "authors": ["Chanjuan Liu", "Shengzhi Wang", "Enqiang Zhu"], "title": "DP-GPT4MTS: Dual-Prompt Large Language Model for Textual-Numerical Time Series Forecasting", "comment": null, "summary": "Time series forecasting is crucial in strategic planning and decision-making\nacross various industries. Traditional forecasting models mainly concentrate on\nnumerical time series data, often overlooking important textual information\nsuch as events and news, which can significantly affect forecasting accuracy.\nWhile large language models offer a promise for integrating multimodal data,\nexisting single-prompt frameworks struggle to effectively capture the semantics\nof timestamped text, introducing redundant information that can hinder model\nperformance. To address this limitation, we introduce DP-GPT4MTS (Dual-Prompt\nGPT2-base for Multimodal Time Series), a novel dual-prompt large language model\nframework that combines two complementary prompts: an explicit prompt for clear\ntask instructions and a textual prompt for context-aware embeddings from\ntime-stamped data. The tokenizer generates the explicit prompt while the\nembeddings from the textual prompt are refined through self-attention and\nfeed-forward networks. Comprehensive experiments conducted on diverse\ntextural-numerical time series datasets demonstrate that this approach\noutperforms state-of-the-art algorithms in time series forecasting. This\nhighlights the significance of incorporating textual context via a dual-prompt\nmechanism to achieve more accurate time series predictions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDP-GPT4MTS\u53cc\u63d0\u793a\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5c06\u663e\u5f0f\u4e0e\u6587\u672c\u63d0\u793a\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8d85\u8d8a\u73b0\u6709\u7b97\u6cd5\uff0c\u51f8\u663e\u6587\u672c\u4e0a\u4e0b\u6587\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5728\u5404\u884c\u4e1a\u7684\u6218\u7565\u89c4\u5212\u548c\u51b3\u7b56\u5236\u5b9a\u4e2d\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u4f20\u7edf\u6a21\u578b\u901a\u5e38\u53ea\u5173\u6ce8\u6570\u503c\u578b\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u5ffd\u7565\u4e86\u5982\u4e8b\u4ef6\u3001\u65b0\u95fb\u7b49\u91cd\u8981\u6587\u672c\u4fe1\u606f\uff0c\u5f71\u54cd\u4e86\u9884\u6d4b\u7cbe\u5ea6\u3002\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5177\u5907\u6574\u5408\u591a\u6a21\u6001\u6570\u636e\u7684\u6f5c\u529b\uff0c\u4f46\u5355\u4e00\u63d0\u793a\u8bcd\u673a\u5236\u5728\u5904\u7406\u5e26\u65f6\u95f4\u6233\u7684\u6587\u672c\u8bed\u4e49\u65f6\u8868\u73b0\u6709\u9650\uff0c\u6613\u5f15\u5165\u5197\u4f59\u4fe1\u606f\uff0c\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u53cc\u63d0\u793a\u8bed\u5927\u8bed\u8a00\u6a21\u578b\u6846\u67b6DP-GPT4MTS\uff08Dual-Prompt GPT2-base for Multimodal Time Series\uff09\uff0c\u7ed3\u5408\u663e\u5f0f\u63d0\u793a\uff08\u660e\u786e\u4efb\u52a1\u6307\u4ee4\uff09\u548c\u9690\u5f0f\u6587\u672c\u63d0\u793a\uff08\u4ece\u5e26\u65f6\u95f4\u6233\u7684\u6570\u636e\u4e2d\u63d0\u53d6\u4e0a\u4e0b\u6587\u8bed\u4e49\u5d4c\u5165\uff09\u3002\u663e\u5f0f\u63d0\u793a\u7531\u5206\u8bcd\u5668\u751f\u6210\uff0c\u6587\u672c\u63d0\u793a\u7ecf\u8fc7\u81ea\u6ce8\u610f\u529b\u548c\u524d\u9988\u7f51\u7edc\u4f18\u5316\u5d4c\u5165\u8868\u8fbe\uff0c\u65e8\u5728\u5145\u5206\u5229\u7528\u6587\u672c\u548c\u6570\u503c\u6570\u636e\u3002", "result": "\u5728\u5305\u542b\u6587\u672c\u548c\u6570\u503c\u4fe1\u606f\u7684\u591a\u79cd\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\uff0cDP-GPT4MTS\u6a21\u578b\u7684\u9884\u6d4b\u8868\u73b0\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u7b97\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u53cc\u63d0\u793a\u673a\u5236\u5e76\u6709\u6548\u6574\u5408\u6587\u672c\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u80fd\u663e\u8457\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002\u6a21\u578b\u8bbe\u8ba1\u4e3a\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5bf9\u5b9e\u9645\u5e94\u7528\u5177\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2508.04248", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04248", "abs": "https://arxiv.org/abs/2508.04248", "authors": ["Xi Wang", "Anxo Perez", "Javier Parapar", "Fabio Crestani"], "title": "TalkDep: Clinically Grounded LLM Personas for Conversation-Centric Depression Screening", "comment": "Paper accepted at CIKM 2025", "summary": "The increasing demand for mental health services has outpaced the\navailability of real training data to develop clinical professionals, leading\nto limited support for the diagnosis of depression. This shortage has motivated\nthe development of simulated or virtual patients to assist in training and\nevaluation, but existing approaches often fail to generate clinically valid,\nnatural, and diverse symptom presentations. In this work, we embrace the recent\nadvanced language models as the backbone and propose a novel\nclinician-in-the-loop patient simulation pipeline, TalkDep, with access to\ndiversified patient profiles to develop simulated patients. By conditioning the\nmodel on psychiatric diagnostic criteria, symptom severity scales, and\ncontextual factors, our goal is to create authentic patient responses that can\nbetter support diagnostic model training and evaluation. We verify the\nreliability of these simulated patients with thorough assessments conducted by\nclinical professionals. The availability of validated simulated patients offers\na scalable and adaptable resource for improving the robustness and\ngeneralisability of automatic depression diagnosis systems.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4e34\u5e8a\u4e13\u5bb6\u53cd\u9988\u7684\u865a\u62df\u60a3\u8005\u751f\u6210\u65b9\u6cd5TalkDep\uff0c\u751f\u6210\u7ecf\u8fc7\u4e13\u4e1a\u4eba\u58eb\u9a8c\u8bc1\u7684\u591a\u6837\u5316\u3001\u771f\u5b9e\u7684\u6291\u90c1\u75c7\u60a3\u8005\u6a21\u62df\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u81ea\u52a8\u8bca\u65ad\u7cfb\u7edf\u6548\u679c\u3002", "motivation": "\u7531\u4e8e\u5fc3\u7406\u5065\u5eb7\u670d\u52a1\u9700\u6c42\u6fc0\u589e\uff0c\u800c\u7528\u4e8e\u57f9\u517b\u4e34\u5e8a\u4e13\u4e1a\u4eba\u5458\u7684\u771f\u5b9e\u8bad\u7ec3\u6570\u636e\u77ed\u7f3a\uff0c\u9650\u5236\u4e86\u6291\u90c1\u75c7\u8bca\u65ad\u7684\u652f\u6301\u80fd\u529b\u3002\u73b0\u6709\u865a\u62df\u60a3\u8005\u65b9\u6848\u96be\u4ee5\u751f\u6210\u7b26\u5408\u4e34\u5e8a\u3001\u81ea\u7136\u4e14\u591a\u6837\u7684\u75c7\u72b6\u8868\u73b0\uff0c\u56e0\u6b64\u4e9f\u9700\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5148\u8fdb\u8bed\u8a00\u6a21\u578b\u5e76\u878d\u5408\u4e34\u5e8a\u4e13\u5bb6\u53cd\u9988\u7684\u865a\u62df\u60a3\u8005\u6a21\u62df\u6d41\u7a0bTalkDep\uff0c\u901a\u8fc7\u4f7f\u7528\u7cbe\u795e\u79d1\u8bca\u65ad\u6807\u51c6\u3001\u75c7\u72b6\u4e25\u91cd\u7a0b\u5ea6\u91cf\u8868\u548c\u4e0a\u4e0b\u6587\u56e0\u7d20\u6765\u6307\u5bfc\u6a21\u578b\u751f\u6210\u591a\u6837\u5316\u4e14\u771f\u5b9e\u7684\u60a3\u8005\u56de\u5e94\u3002", "result": "\u901a\u8fc7\u4e34\u5e8a\u4e13\u4e1a\u4eba\u58eb\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u4e86\u8be5\u6a21\u62df\u60a3\u8005\u65b9\u6cd5\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u53ef\u9002\u5e94\u7684\u865a\u62df\u60a3\u8005\u8d44\u6e90\uff0c\u53ef\u6539\u5584\u81ea\u52a8\u5316\u6291\u90c1\u75c7\u8bca\u65ad\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u4e0e\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2508.04257", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04257", "abs": "https://arxiv.org/abs/2508.04257", "authors": ["Zunhai Su", "Kehong Yuan"], "title": "KVSink: Understanding and Enhancing the Preservation of Attention Sinks in KV Cache Quantization for LLMs", "comment": "Published as a conference paper at COLM 2025", "summary": "Key-Value (KV) cache quantization has become a widely adopted optimization\ntechnique for efficient large language models (LLMs) inference by reducing KV\ncache memory usage and mitigating memory-bound constraints. Recent studies have\nemphasized the importance of preserving the original precision of KVs for the\nfirst few tokens to ensure the protection of attention sinks. While this\napproach has proven effective in mitigating performance degradation, its\nunderlying principles remain insufficiently understood. Moreover, it fails to\naddress the recent discovery that attention sinks can emerge beyond the initial\ntoken positions. In this work, we elucidate the underlying mechanisms of\nattention sinks during inference by examining their role in the cross-layer\nevolution of extreme activation outliers. Additionally, we provide a\ncomprehensive analysis of the interplay between attention sinks and KV cache\nquantization. Based on our enhanced understanding, we introduce\n\\textit{\\textbf{KVSink}}, a plug-and-play method that effectively predicts sink\ntokens with negligible overhead, enabling more thorough preservation. Extensive\nexperiments demonstrate that KVSink outperforms the existing Preserve-First-N\n(PFN) strategy, offering more effective preservation of attention sinks during\nKV cache quantization. Moreover, when applied to the well-established KVQuant\nmethod, KVSink further improves perplexity (PPL) and reduces reliance on 16-bit\nnumerical outliers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faKVSink\u65b9\u6cd5\uff0c\u57fa\u4e8e\u6df1\u5165\u5206\u6790\u6ce8\u610f\u529bsink\u673a\u5236\uff0c\u80fd\u7cbe\u51c6\u9ad8\u6548\u5730\u4fdd\u62a4LLMs\u63a8\u7406\u4e2d\u5173\u952etoken\uff0c\u8f83\u4f20\u7edf\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\uff0c\u6709\u6548\u63d0\u5347KV\u7f13\u5b58\u91cf\u5316\u4e0b\u7684\u6a21\u578b\u6027\u80fd\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63a8\u7406\u4e2d\u7684KV\u7f13\u5b58\u8fdb\u884c\u91cf\u5316\uff0c\u662f\u63d0\u5347\u63a8\u7406\u6548\u7387\u3001\u964d\u4f4e\u5185\u5b58\u538b\u529b\u7684\u91cd\u8981\u624b\u6bb5\u3002\u4f46\u90e8\u5206\u7814\u7a76\u6307\u51fa\uff0c\u4e3a\u4fdd\u62a4\u6ce8\u610f\u529bsink\u70b9\uff0c\u9700\u5bf9\u524d\u51e0\u4e2atoken\u4fdd\u6301\u9ad8\u7cbe\u5ea6\uff0c\u8fd9\u4e00\u7ecf\u9a8c\u80cc\u540e\u7684\u539f\u7406\u4ee5\u53ca\u5176\u5c40\u9650\u6027\u5c1a\u672a\u88ab\u6df1\u5165\u7406\u89e3\u3002\u5c24\u5176\u662f\u65b0\u53d1\u73b0\uff1a\u6ce8\u610f\u529bsink\u70b9\u4e0d\u53ea\u5b58\u5728\u4e8e\u521d\u59cbtokens\uff0c\u4ecd\u7f3a\u4e4f\u7cfb\u7edf\u6027\u5e94\u5bf9\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5206\u6790\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6ce8\u610f\u529bsink\u7684\u4ea7\u751f\u673a\u5236\u548c\u6781\u7aef\u6fc0\u6d3b\u5f02\u5e38\u503c\u5728\u8de8\u5c42\u4f20\u64ad\u4e2d\u7684\u4f5c\u7528\uff0c\u63ed\u793aKV\u7f13\u5b58\u91cf\u5316\u4e0esink\u4fdd\u62a4\u7684\u5173\u7cfb\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u63d0\u51fa\u4e86KVSink\u65b9\u6cd5\uff1a\u4e00\u79cd\u57fa\u4e8e\u6709\u6548\u9884\u6d4bsink token\u7684\u901a\u7528\u673a\u5236\uff0c\u80fd\u9ad8\u6548\u8bc6\u522b\u5e76\u4fdd\u62a4sink token\uff0c\u51e0\u4e4e\u65e0\u989d\u5916\u5f00\u9500\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\uff0cKVSink\u5728KV\u7f13\u5b58\u91cf\u5316\u8fc7\u7a0b\u4e2d\uff0c\u6bd4\u73b0\u6709\u7684Preserve-First-N (PFN)\u7b56\u7565\u66f4\u6709\u6548\u5730\u4fdd\u62a4\u4e86\u6ce8\u610f\u529bsink\u3002\u540c\u65f6\uff0c\u7ed3\u5408\u73b0\u6709KVQuant\u65b9\u6cd5\uff0cKVSink\u80fd\u8fdb\u4e00\u6b65\u4f18\u5316PPL\uff08\u56f0\u60d1\u5ea6\uff09\uff0c\u964d\u4f4e\u5bf916\u4f4d\u6570\u503c\u5f02\u5e38\u503c\u7684\u4f9d\u8d56\u3002", "conclusion": "KVSink\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86KV\u7f13\u5b58\u91cf\u5316\u4e0bLLMs\u63a8\u7406\u7684\u7a33\u5b9a\u6027\u548c\u7cbe\u5ea6\uff0c\u5b9e\u73b0\u4e86\u66f4\u667a\u80fd\u7684\u6ce8\u610f\u529bsink\u4fdd\u62a4\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u524dN token\u4fdd\u62a4\u7b56\u7565\u3002"}}
{"id": "2508.04266", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04266", "abs": "https://arxiv.org/abs/2508.04266", "authors": ["Jiangyuan Wang", "Kejun Xiao", "Qi Sun", "Huaipeng Zhao", "Tao Luo", "Jiandong Zhang", "Xiaoyi Zeng"], "title": "ShoppingBench: A Real-World Intent-Grounded Shopping Benchmark for LLM-based Agents", "comment": "submit to AAAI2026", "summary": "Existing benchmarks in e-commerce primarily focus on basic user intents, such\nas finding or purchasing products. However, real-world users often pursue more\ncomplex goals, such as applying vouchers, managing budgets, and finding\nmulti-products seller. To bridge this gap, we propose ShoppingBench, a novel\nend-to-end shopping benchmark designed to encompass increasingly challenging\nlevels of grounded intent. Specifically, we propose a scalable framework to\nsimulate user instructions based on various intents derived from sampled\nreal-world products. To facilitate consistent and reliable evaluations, we\nprovide a large-scale shopping sandbox that serves as an interactive simulated\nenvironment, incorporating over 2.5 million real-world products. Experimental\nresults demonstrate that even state-of-the-art language agents (such as\nGPT-4.1) achieve absolute success rates under 50% on our benchmark tasks,\nhighlighting the significant challenges posed by our ShoppingBench. In\naddition, we propose a trajectory distillation strategy and leverage supervised\nfine-tuning, along with reinforcement learning on synthetic trajectories, to\ndistill the capabilities of a large language agent into a smaller one. As a\nresult, our trained agent achieves competitive performance compared to GPT-4.1.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7535\u5546\u590d\u6742\u7528\u6237\u610f\u56fe\u57fa\u51c6ShoppingBench\uff0c\u4efb\u52a1\u96be\u5ea6\u663e\u8457\u63d0\u5347\uff0c\u9876\u5c16\u5927\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff1b\u540c\u65f6\u63d0\u51fa\u80fd\u529b\u84b8\u998f\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u5c0f\u6a21\u578b\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7535\u5546\u57fa\u51c6\u53ea\u5173\u6ce8\u7b80\u5355\u7528\u6237\u76ee\u6807\uff0c\u65e0\u6cd5\u6ee1\u8db3\u73b0\u5b9e\u590d\u6742\u60c5\u5883\uff08\u5982\u52a0\u5238\u3001\u63a7\u9884\u7b97\u3001\u6bd4\u8f83\u591a\u5546\u54c1\u7b49\uff09\uff0c\u9ad8\u7ef4\u5ea6\u590d\u6742\u610f\u56fe\u8bc4\u6d4b\u5de5\u5177\u53ca\u9ad8\u8d28\u91cf\u73af\u5883\u6025\u7f3a\u3002", "method": "1. \u6784\u5efa\u4e86\u6db5\u76d6\u591a\u5c42\u6b21/\u66f4\u590d\u6742\u610f\u56fe\u7684ShoppingBench\u57fa\u51c6\u548c2.5M+\u771f\u5b9e\u5546\u54c1\u7684\u6c99\u76d2\u73af\u5883\r\n2. \u7528\u72b6\u6001\u6700\u5148\u8fdblarge language agents (\u5982GPT-4.1)\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\r\n3. \u63d0\u51fa\u8f68\u8ff9\u84b8\u998f\u7b56\u7565\u548c\u5f3a\u5316\u5b66\u4e60+\u76d1\u7763\u5fae\u8c03\uff0c\u4ece\u5927\u6a21\u578b\u8fc1\u79fb\u80fd\u529b\u5230\u5c0f\u6a21\u578b\uff0c\u5e76\u68c0\u9a8c\u5176\u6709\u6548\u6027", "result": "\u5728ShoppingBench\u57fa\u51c6\u4e0a\uff0cGPT-4.1\u7b49\u5148\u8fdb\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff08<50%\u6210\u529f\u7387\uff09\uff0c\u53cd\u6620\u51fa\u6b64\u4efb\u52a1\u96be\u5ea6\u6781\u5927\u3002\u540c\u65f6\uff0c\u65b0\u63d0\u51fa\u7684\u8f68\u8ff9\u84b8\u998f\u4e0e\u7ed3\u5408\u589e\u5f3a\u5b66\u4e60/\u5fae\u8c03\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5c0f\u6a21\u578b\u6027\u80fd\uff0c\u4f7f\u4e4b\u63a5\u8fd1\u5927\u6a21\u578b\u3002", "conclusion": "\u6587\u7ae0\u63d0\u51fa\u7684ShoppingBench\u663e\u8457\u63d0\u5347\u4e86\u7535\u5546\u573a\u666f\u4e2d\u5bf9\u590d\u6742\u7528\u6237\u76ee\u6807\u7684\u5efa\u6a21\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u8fc1\u79fb\u548c\u84b8\u998f\u6280\u672f\u6210\u529f\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u6709\u6548\u538b\u7f29\u8fdb\u5c0f\u6a21\u578b\u4e2d\uff0c\u53d6\u5f97\u4e86\u548cGPT-4.1\u76f8\u5f53\u7684\u8868\u73b0\u3002"}}
{"id": "2508.04276", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04276", "abs": "https://arxiv.org/abs/2508.04276", "authors": ["Jiayi Wen", "Tianxin Chen", "Zhirun Zheng", "Cheng Huang"], "title": "A Few Words Can Distort Graphs: Knowledge Poisoning Attacks on Graph-based Retrieval-Augmented Generation of Large Language Models", "comment": null, "summary": "Graph-based Retrieval-Augmented Generation (GraphRAG) has recently emerged as\na promising paradigm for enhancing large language models (LLMs) by converting\nraw text into structured knowledge graphs, improving both accuracy and\nexplainability. However, GraphRAG relies on LLMs to extract knowledge from raw\ntext during graph construction, and this process can be maliciously manipulated\nto implant misleading information. Targeting this attack surface, we propose\ntwo knowledge poisoning attacks (KPAs) and demonstrate that modifying only a\nfew words in the source text can significantly change the constructed graph,\npoison the GraphRAG, and severely mislead downstream reasoning. The first\nattack, named Targeted KPA (TKPA), utilizes graph-theoretic analysis to locate\nvulnerable nodes in the generated graphs and rewrites the corresponding\nnarratives with LLMs, achieving precise control over specific\nquestion-answering (QA) outcomes with a success rate of 93.1\\%, while keeping\nthe poisoned text fluent and natural. The second attack, named Universal KPA\n(UKPA), exploits linguistic cues such as pronouns and dependency relations to\ndisrupt the structural integrity of the generated graph by altering globally\ninfluential words. With fewer than 0.05\\% of full text modified, the QA\naccuracy collapses from 95\\% to 50\\%. Furthermore, experiments show that\nstate-of-the-art defense methods fail to detect these attacks, highlighting\nthat securing GraphRAG pipelines against knowledge poisoning remains largely\nunexplored.", "AI": {"tldr": "\u4f5c\u8005\u53d1\u73b0\u5e76\u5b9e\u9a8c\u8bc1\u660e\uff0c\u653b\u51fb\u8005\u901a\u8fc7\u6781\u5c0f\u7684\u6587\u672c\u4fee\u6539\u5373\u53ef\u5bf9GraphRAG\u77e5\u8bc6\u56fe\u6295\u6bd2\uff0c\u4ece\u800c\u4e25\u91cd\u8bef\u5bfc\u540e\u7eed\u63a8\u7406\u3002\u540c\u65f6\uff0c\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u96be\u4ee5\u9632\u8303\u6b64\u7c7b\u653b\u51fb\uff0c\u51f8\u663e\u8be5\u9886\u57df\u7684\u5de8\u5927\u5b89\u5168\u9690\u60a3\u3002", "motivation": "\u5f53\u524d\u6d41\u884c\u7684Graph-based Retrieval-Augmented Generation (GraphRAG)\u65b9\u6cd5\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4f46\u5176\u4f9d\u8d56\u4e8eLLMs\u4ece\u539f\u59cb\u6587\u672c\u4e2d\u63d0\u53d6\u77e5\u8bc6\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u5b58\u5728\u88ab\u6076\u610f\u653b\u51fb\u8005\u64cd\u7eb5\u7684\u98ce\u9669\u3002\u8bba\u6587\u5173\u6ce8\u8fd9\u4e00\u6f5c\u5728\u7684\u5b89\u5168\u9690\u60a3\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u77e5\u8bc6\u6295\u6bd2\u653b\u51fb\uff08KPA\uff09\uff1a\u4e00\u662fTargeted KPA\uff08TKPA\uff09\uff0c\u901a\u8fc7\u56fe\u8bba\u5206\u6790\u5b9a\u4f4d\u751f\u6210\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u8106\u5f31\u8282\u70b9\uff0c\u5e76\u501f\u52a9LLM\u6539\u5199\u76f8\u5173\u53d9\u8ff0\uff0c\u4ee5\u7cbe\u51c6\u64cd\u63a7\u7279\u5b9a\u95ee\u7b54\u4efb\u52a1\u7684\u7ed3\u679c\uff1b\u4e8c\u662fUniversal KPA\uff08UKPA\uff09\uff0c\u5229\u7528\u6307\u4ee3\u3001\u4f9d\u5b58\u5173\u7cfb\u7b49\u8bed\u8a00\u7279\u5f81\uff0c\u901a\u8fc7\u5c11\u91cf\u4fee\u6539\u5168\u5c40\u5f71\u54cd\u529b\u8bcd\u6c47\uff0c\u7834\u574f\u77e5\u8bc6\u56fe\u8c31\u7684\u7ed3\u6784\u5b8c\u6574\u6027\u3002", "result": "TKPA\u80fd\u4ee593.1%\u7684\u9ad8\u6210\u529f\u7387\u7cbe\u51c6\u5f71\u54cd\u95ee\u7b54\u7ed3\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u6587\u672c\u6d41\u7545\u81ea\u7136\u3002UKPA\u4ec5\u9700\u4fee\u65390.05%\u7684\u6587\u672c\uff0c\u5c31\u80fd\u4f7f\u95ee\u7b54\u51c6\u786e\u7387\u4ece95%\u9aa4\u964d\u81f350%\u3002\u5b9e\u9a8c\u8fd8\u663e\u793a\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u96be\u4ee5\u68c0\u6d4b\u4e0a\u8ff0\u653b\u51fb\u3002", "conclusion": "GraphRAG\u5728\u77e5\u8bc6\u62bd\u53d6\u9636\u6bb5\u5b58\u5728\u663e\u8457\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u5f53\u524d\u9632\u5fa1\u673a\u5236\u65e0\u6cd5\u6709\u6548\u8bc6\u522b\u548c\u9632\u5fa1\u77e5\u8bc6\u6295\u6bd2\u653b\u51fb\u3002\u56e0\u6b64\uff0c\u4fdd\u969cGraphRAG\u5b89\u5168\u6027\u4e9f\u9700\u66f4\u591a\u7814\u7a76\u3002"}}
{"id": "2508.04325", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.04325", "abs": "https://arxiv.org/abs/2508.04325", "authors": ["Zizhan Ma", "Wenxuan Wang", "Guo Yu", "Yiu-Fai Cheung", "Meidan Ding", "Jie Liu", "Wenting Chen", "Linlin Shen"], "title": "Beyond the Leaderboard: Rethinking Medical Benchmarks for Large Language Models", "comment": null, "summary": "Large language models (LLMs) show significant potential in healthcare,\nprompting numerous benchmarks to evaluate their capabilities. However, concerns\npersist regarding the reliability of these benchmarks, which often lack\nclinical fidelity, robust data management, and safety-oriented evaluation\nmetrics. To address these shortcomings, we introduce MedCheck, the first\nlifecycle-oriented assessment framework specifically designed for medical\nbenchmarks. Our framework deconstructs a benchmark's development into five\ncontinuous stages, from design to governance, and provides a comprehensive\nchecklist of 46 medically-tailored criteria. Using MedCheck, we conducted an\nin-depth empirical evaluation of 53 medical LLM benchmarks. Our analysis\nuncovers widespread, systemic issues, including a profound disconnect from\nclinical practice, a crisis of data integrity due to unmitigated contamination\nrisks, and a systematic neglect of safety-critical evaluation dimensions like\nmodel robustness and uncertainty awareness. Based on these findings, MedCheck\nserves as both a diagnostic tool for existing benchmarks and an actionable\nguideline to foster a more standardized, reliable, and transparent approach to\nevaluating AI in healthcare.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u8df5\u4e86MedCheck\u8bc4\u4f30\u6846\u67b6\uff0c\u7cfb\u7edf\u63ed\u793a\u4e86\u5f53\u524d\u533b\u7597LLM\u57fa\u51c6\u5efa\u8bbe\u7684\u8bf8\u591a\u5f0a\u75c5\uff0c\u5e76\u4e3a\u540e\u7eed\u6539\u8fdb\u63d0\u4f9b\u4e86\u5207\u5b9e\u53ef\u884c\u7684\u8def\u5f84\u3002", "motivation": "\u5f53\u524d\u5728\u533b\u7597\u9886\u57df\u5e94\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u65f6\uff0c\u8bc4\u4ef7\u5176\u8868\u73b0\u7684\u57fa\u51c6\u5b58\u5728\u53ef\u9760\u6027\u62c5\u5fe7\uff0c\u5177\u4f53\u5305\u62ec\u4e34\u5e8a\u76f8\u5173\u6027\u4e0d\u8db3\u3001\u6570\u636e\u7ba1\u7406\u4e0d\u5065\u5168\u53ca\u5b89\u5168\u6027\u8bc4\u4f30\u6307\u6807\u7f3a\u5931\u3002\u4f5c\u8005\u5e0c\u671b\u89e3\u51b3\u8fd9\u4e9b\u957f\u671f\u5b58\u5728\u7684\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u5e76\u63d0\u51fa\u4e86MedCheck\u2014\u2014\u9996\u4e2a\u9488\u5bf9\u533b\u7597\u57fa\u51c6\u7684\u5168\u751f\u547d\u5468\u671f\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u57fa\u51c6\u7684\u5efa\u8bbe\u5206\u4e3a\u4e94\u4e2a\u8fde\u7eed\u9636\u6bb5\uff0c\u5e76\u63d0\u51fa\u4e8646\u9879\u533b\u7597\u573a\u666f\u4e0b\u4e13\u95e8\u5b9a\u5236\u7684\u8bc4\u5224\u6807\u51c6\u3002\u501f\u52a9\u8be5\u6846\u67b6\uff0c\u5bf953\u4e2a\u533b\u7597\u7c7bLLM\u57fa\u51c6\u8fdb\u884c\u4e86\u5b9e\u8bc1\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u5206\u6790\u53d1\u73b0\u533b\u7597\u57fa\u51c6\u5b58\u5728\u666e\u904d\u7684\u7cfb\u7edf\u6027\u95ee\u9898\uff0c\u5982\u4e0e\u4e34\u5e8a\u5b9e\u8df5\u8131\u8282\u3001\u6570\u636e\u5b8c\u6574\u6027\u5371\u673a\uff08\u6c61\u67d3\u98ce\u9669\u65e0\u6cd5\u63a7\u5236\uff09\u3001\u5bf9\u6a21\u578b\u5b89\u5168\u4e0e\u4e0d\u786e\u5b9a\u6027\u8bc4\u4ef7\u7b49\u5173\u952e\u7ef4\u5ea6\u7684\u5ffd\u89c6\u3002", "conclusion": "MedCheck\u4e0d\u4ec5\u80fd\u591f\u5e2e\u52a9\u8bca\u65ad\u73b0\u6709\u533b\u7597LLM\u57fa\u51c6\u5b58\u5728\u7684\u95ee\u9898\uff0c\u8fd8\u53ef\u4ee5\u4f5c\u4e3a\u884c\u52a8\u6307\u5357\uff0c\u63a8\u52a8\u533b\u7597AI\u8bc4\u4ef7\u66f4\u6807\u51c6\u5316\u3001\u53ef\u9760\u4e0e\u900f\u660e\u3002"}}
{"id": "2508.04337", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.04337", "abs": "https://arxiv.org/abs/2508.04337", "authors": ["Francisco Bola\u00f1os", "Angelo Salatino", "Francesco Osborne", "Enrico Motta"], "title": "Modelling and Classifying the Components of a Literature Review", "comment": null, "summary": "Previous work has demonstrated that AI methods for analysing scientific\nliterature benefit significantly from annotating sentences in papers according\nto their rhetorical roles, such as research gaps, results, limitations,\nextensions of existing methodologies, and others. Such representations also\nhave the potential to support the development of a new generation of systems\ncapable of producing high-quality literature reviews. However, achieving this\ngoal requires the definition of a relevant annotation schema and effective\nstrategies for large-scale annotation of the literature. This paper addresses\nthese challenges by 1) introducing a novel annotation schema specifically\ndesigned to support literature review generation and 2) conducting a\ncomprehensive evaluation of a wide range of state-of-the-art large language\nmodels (LLMs) in classifying rhetorical roles according to this schema. To this\nend, we also present Sci-Sentence, a novel multidisciplinary benchmark\ncomprising 700 sentences manually annotated by domain experts and 2,240\nsentences automatically labelled using LLMs. We evaluate 37 LLMs on this\nbenchmark, spanning diverse model families and sizes, using both zero-shot\nlearning and fine-tuning approaches. The experiments yield several novel\ninsights that advance the state of the art in this challenging domain. First,\nthe current generation of LLMs performs remarkably well on this task when\nfine-tuned on high-quality data, achieving performance levels above 96\\% F1.\nSecond, while large proprietary models like GPT-4o achieve the best results,\nsome lightweight open-source alternatives also demonstrate excellent\nperformance. Finally, enriching the training data with semi-synthetic examples\ngenerated by LLMs proves beneficial, enabling small encoders to achieve robust\nresults and significantly enhancing the performance of several open decoder\nmodels.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u7528\u4e8e\u751f\u6210\u6587\u732e\u7efc\u8ff0\u7684\u65b0\u53e5\u5b50\u4fee\u8f9e\u6ce8\u91ca\u4f53\u7cfb\u53ca\u57fa\u51c6\uff0c\u7cfb\u7edf\u8bc4\u6d4b\u4e8637\u79cd\u5927\u6a21\u578b\uff0c\u53d1\u73b0\u5fae\u8c03\u548c\u534a\u5408\u6210\u6570\u636e\u80fd\u663e\u8457\u63d0\u5347\u5206\u7c7b\u6548\u679c\uff0c\u63a8\u52a8\u5c0f\u6a21\u578b\u4e0e\u5f00\u6e90\u6a21\u578b\u8fdb\u6b65\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u663e\u793a\uff0c\u901a\u8fc7\u5bf9\u8bba\u6587\u4e2d\u53e5\u5b50\u7684\u4fee\u8f9e\u89d2\u8272\uff08\u5982\u7814\u7a76\u7a7a\u767d\u3001\u7ed3\u679c\u3001\u5c40\u9650\u6027\u3001\u65b9\u6cd5\u6269\u5c55\u7b49\uff09\u8fdb\u884c\u6ce8\u91ca\uff0c\u6709\u52a9\u4e8e\u63d0\u5347AI\u5206\u6790\u79d1\u5b66\u6587\u732e\u7684\u80fd\u529b\uff0c\u5c24\u5176\u5bf9\u9ad8\u8d28\u91cf\u7efc\u8ff0\u7cfb\u7edf\u7684\u5f00\u53d1\u6f5c\u529b\u5de8\u5927\u3002\u7136\u800c\uff0c\u8981\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\uff0c\u9700\u8981\u5b9a\u4e49\u5408\u9002\u7684\u6ce8\u91ca\u4f53\u7cfb\uff0c\u5e76\u627e\u5230\u6709\u6548\u7684\u5927\u89c4\u6a21\u6807\u6ce8\u7b56\u7565\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6ce8\u91ca\u4f53\u7cfb\uff0c\u4e13\u4e3a\u652f\u6301\u6587\u732e\u7efc\u8ff0\u751f\u6210\u8bbe\u8ba1\uff0c\u5e76\u5bf9\u591a\u79cd\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8be5\u4f53\u7cfb\u4e0b\u8fdb\u884c\u4fee\u8f9e\u89d2\u8272\u5206\u7c7b\u7684\u80fd\u529b\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a\u6784\u5efa\u8de8\u5b66\u79d1\u57fa\u51c6\u6570\u636e\u96c6Sci-Sentence\uff08\u5305\u542b700\u6761\u4e13\u5bb6\u4eba\u5de5\u6807\u6ce8\u53e5\u5b50\u548c2240\u6761LLMs\u81ea\u52a8\u6807\u6ce8\u53e5\u5b50\uff09\uff0c\u5e76\u4f7f\u7528\u96f6\u6837\u672c\u5b66\u4e60\u4e0e\u5fae\u8c03\u65b9\u5f0f\uff0c\u5bf937\u79cd\u4e0d\u540c\u89c4\u6a21\u548c\u7c7b\u578b\u7684LLMs\u8fdb\u884c\u5206\u7c7b\u6027\u80fd\u8bc4\u6d4b\u3002", "result": "\u5fae\u8c03\u540e\u7684\u5f53\u524d\u4e3b\u6d41LLMs\u5728\u8be5\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0cF1\u5206\u6570\u53ef\u8fbe96%\u4ee5\u4e0a\uff1bGPT-4o\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\uff0c\u4f46\u90e8\u5206\u8f7b\u91cf\u7ea7\u5f00\u6e90\u6a21\u578b\u540c\u6837\u8868\u73b0\u4f18\u79c0\uff1b\u7528LLMs\u751f\u6210\u7684\u534a\u5408\u6210\u6807\u6ce8\u6269\u5145\u8bad\u7ec3\u6570\u636e\uff0c\u53ef\u4ee5\u8ba9\u5c0f\u6a21\u578b\u548c\u90e8\u5206\u5f00\u6e90\u6a21\u578b\u5927\u5e45\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u65b0\u6ce8\u91ca\u4f53\u7cfb\u548c\u57fa\u51c6\u63a8\u52a8\u4e86\u8bba\u6587\u53e5\u5b50\u4fee\u8f9e\u89d2\u8272\u5206\u7c7b\u9886\u57df\u7684\u53d1\u5c55\uff0c\u9a8c\u8bc1\u4e86\u591a\u79cdLLMs\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e3a\u5c0f\u6a21\u578b\u548c\u5f00\u6e90\u6a21\u578b\u63d0\u4f9b\u4e86\u63d0\u5347\u9014\u5f84\u3002"}}
{"id": "2508.04349", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04349", "abs": "https://arxiv.org/abs/2508.04349", "authors": ["Hongze Tan", "Jianfei Pan"], "title": "GTPO and GRPO-S: Token and Sequence-Level Reward Shaping with Policy Entropy", "comment": null, "summary": "Reinforcement learning (RL) with algorithms like Group Relative Policy\nOptimization (GRPO) improves Large Language Model (LLM) reasoning, but is\nlimited by a coarse-grained credit assignment that applies a uniform reward to\nall tokens in a sequence. This is a major flaw in long-chain reasoning tasks.\nThis paper solves this with \\textbf{Dynamic Entropy Weighting}. Our core idea\nis that high-entropy tokens in correct responses can guide the policy toward a\nhigher performance ceiling. This allows us to create more fine-grained reward\nsignals for precise policy updates via two ways: 1) \\textbf{Group Token Policy\nOptimization} (\\textbf{GTPO}), we assigns a entropy-weighted reward to each\ntoken for fine-grained credit assignment. 2) \\textbf{Sequence-Level Group\nRelative Policy Optimization} (\\textbf{GRPO-S}), we assigns a entropy-weighted\nreward to each sequence based on its average token entropy. Experiments show\nour methods significantly outperform the strong DAPO baseline. The results\nconfirm that our entropy-weighting mechanism is the key driver of this\nperformance boost, offering a better path to enhance deep reasoning in models.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5f53\u524dLLM\u63a8\u7406\u4e2d\u5956\u52b1\u5206\u914d\u7c97\u7cd9\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8etoken\u71b5\u7684\u52a8\u6001\u52a0\u6743\u673a\u5236\uff08GTPO\u548cGRPO-S\uff09\uff0c\u5b9e\u73b0\u66f4\u7ec6\u7c92\u5ea6\u7684\u5956\u52b1\u5206\u914d\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u9a8c\u8bc1\u5b9e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u76ee\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\u901a\u5e38\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08\u5982GRPO\uff09\u589e\u5f3a\uff0c\u4f46\u7531\u4e8e\u5bf9\u5e8f\u5217\u4e2d\u6240\u6709token\u5206\u914d\u76f8\u540c\u5956\u52b1\uff0c\u65e0\u6cd5\u7ec6\u7c92\u5ea6\u5730\u5224\u522b\u957f\u94fe\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8d21\u732e\u3002\u73b0\u6709\u673a\u5236\u5728\u957f\u94fe\u63a8\u7406\u4efb\u52a1\u4e2d\u5bfc\u81f4\u5956\u52b1\u5206\u914d\u7c97\u7cd9\uff0c\u964d\u4f4e\u4e86\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u52a8\u6001\u71b5\u52a0\u6743\uff08Dynamic Entropy Weighting\uff09\u673a\u5236\uff0c\u7528token\u7684\u71b5\u503c\u6307\u5bfc\u5956\u52b1\u5206\u914d\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u4fe1\u7528\u5206\u914d\u3002\u5177\u4f53\u5305\u62ec\u4e24\u79cd\u65b9\u6cd5\uff1a\uff081\uff09GTPO\uff0c\u5bf9\u6bcf\u4e2atoken\u6839\u636e\u71b5\u503c\u52a0\u6743\u5956\u52b1\uff0c\u5b9e\u73b0\u7cbe\u7ec6\u7c92\u5ea6\u7684\u4fe1\u7528\u5f52\u56e0\uff1b\uff082\uff09GRPO-S\uff0c\u5bf9\u6574\u4e2a\u5e8f\u5217\u6309token\u5e73\u5747\u71b5\u5206\u914d\u52a0\u6743\u5956\u52b1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u5f3a\u5316\u957f\u94fe\u63a8\u7406\u80fd\u529b\u4e0a\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebfDAPO\uff0c\u63d0\u5347\u6548\u679c\u4e3b\u8981\u5f52\u56e0\u4e8e\u6240\u7528\u7684\u71b5\u52a0\u6743\u673a\u5236\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u71b5\u7684\u5956\u52b1\u6743\u91cd\uff0c\u53ef\u4ee5\u66f4\u9ad8\u6548\u5730\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u6df1\u5ea6\u63a8\u7406\u80fd\u529b\uff0c\u71b5\u6743\u91cd\u673a\u5236\u662f\u6027\u80fd\u589e\u5f3a\u7684\u5173\u952e\u3002"}}
{"id": "2508.04350", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.04350", "abs": "https://arxiv.org/abs/2508.04350", "authors": ["Nima Iji", "Kia Dashtipour"], "title": "Chain of Questions: Guiding Multimodal Curiosity in Language Models", "comment": null, "summary": "Reasoning capabilities in large language models (LLMs) have substantially\nadvanced through methods such as chain-of-thought and explicit step-by-step\nexplanations. However, these improvements have not yet fully transitioned to\nmultimodal contexts, where models must proactively decide which sensory\nmodalities such as vision, audio, or spatial perception to engage when\ninteracting with complex real-world environments. In this paper, we introduce\nthe Chain of Questions (CoQ) framework, a curiosity-driven reasoning approach\nthat encourages multimodal language models to dynamically generate targeted\nquestions regarding their surroundings. These generated questions guide the\nmodel to selectively activate relevant modalities, thereby gathering critical\ninformation necessary for accurate reasoning and response generation. We\nevaluate our framework on a novel multimodal benchmark dataset, assembled by\nintegrating WebGPT, ScienceQA, AVSD, and ScanQA datasets. Experimental results\ndemonstrate that our CoQ method improves a foundation model's ability to\neffectively identify and integrate pertinent sensory information. This leads to\nimproved accuracy, interpretability, and alignment of the reasoning process\nwith diverse multimodal tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4ee5\u751f\u6210\u95ee\u9898\u4e3a\u6838\u5fc3\u7684\u591a\u6a21\u6001\u63a8\u7406\u65b0\u65b9\u6cd5\uff08CoQ\uff09\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u4e0e\u54cd\u5e94\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u63a8\u7406\u80fd\u529b\u901a\u8fc7\u94fe\u5f0f\u601d\u7ef4\u548c\u9010\u6b65\u89e3\u91ca\u7b49\u6280\u672f\u53d6\u5f97\u4e86\u5f88\u5927\u8fdb\u5c55\uff0c\u4f46\u5728\u591a\u6a21\u6001\u73af\u5883\uff08\u5982\u89c6\u89c9\u3001\u97f3\u9891\u6216\u7a7a\u95f4\u611f\u77e5\uff09\u4e0b\u7684\u5e94\u7528\u4ecd\u7136\u9762\u4e34\u6311\u6218\u3002\u5b83\u4eec\u5c1a\u4e0d\u80fd\u4e3b\u52a8\u51b3\u5b9a\u4f55\u65f6\u4f7f\u7528\u54ea\u4e00\u79cd\u611f\u5b98\u6a21\u6001\u4ee5\u5e94\u5bf9\u590d\u6742\u771f\u5b9e\u73af\u5883\u3002", "method": "\u63d0\u51fa\u4e86\u201cChain of Questions\uff08CoQ\uff09\u201d\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u79cd\u4ee5\u597d\u5947\u5fc3\u9a71\u52a8\u7684\u63a8\u7406\u65b9\u6cd5\uff0c\u4fc3\u4f7f\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u52a8\u6001\u751f\u6210\u5173\u4e8e\u5468\u56f4\u73af\u5883\u7684\u6709\u9488\u5bf9\u6027\u95ee\u9898\u3002\u6a21\u578b\u901a\u8fc7\u751f\u6210\u8fd9\u4e9b\u95ee\u9898\uff0c\u4e3b\u52a8\u9009\u62e9\u548c\u6fc0\u6d3b\u76f8\u5e94\u7684\u611f\u77e5\u6a21\u6001\uff0c\u4ece\u800c\u6536\u96c6\u6709\u6548\u4fe1\u606f\uff0c\u7528\u4e8e\u63a8\u7406\u4e0e\u751f\u6210\u66f4\u51c6\u786e\u7684\u56de\u7b54\u3002\u65b9\u6cd5\u5728\u96c6\u6210\u4e86WebGPT\u3001ScienceQA\u3001AVSD\u548cScanQA\u7684\u65b0\u591a\u6a21\u6001\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cCoQ\u65b9\u6cd5\u63d0\u5347\u4e86\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u6709\u6548\u8bc6\u522b\u548c\u6574\u5408\u5173\u952e\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u63d0\u9ad8\u4e86\u63a8\u7406\u8fc7\u7a0b\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u7387\u3001\u53ef\u89e3\u91ca\u6027\u4e0e\u63a8\u7406\u4e00\u81f4\u6027\u3002", "conclusion": "CoQ\u6846\u67b6\u80fd\u591f\u4fc3\u8fdb\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u66f4\u4e3b\u52a8\u3001\u66f4\u9ad8\u6548\u5730\u6574\u5408\u591a\u79cd\u611f\u5b98\u4fe1\u606f\uff0c\u4f18\u5316\u63a8\u7406\u6548\u679c\u4e0e\u4efb\u52a1\u8868\u73b0\u3002"}}
{"id": "2508.04390", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04390", "abs": "https://arxiv.org/abs/2508.04390", "authors": ["Herbert Ullrich", "Jan Drchal"], "title": "AIC CTU@FEVER 8: On-premise fact checking through long context RAG", "comment": null, "summary": "In this paper, we present our fact-checking pipeline which has scored first\nin FEVER 8 shared task. Our fact-checking system is a simple two-step RAG\npipeline based on our last year's submission. We show how the pipeline can be\nredeployed on-premise, achieving state-of-the-art fact-checking performance (in\nsense of Ev2R test-score), even under the constraint of a single NVidia A10\nGPU, 23GB of graphical memory and 60s running time per claim.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eRAG\u7684\u4e24\u6b65\u4e8b\u5b9e\u6838\u67e5\u6d41\u7a0b\uff0c\u5728FEVER 8\u7ade\u8d5b\u4e2d\u6392\u540d\u7b2c\u4e00\uff0c\u5e76\u4e14\u5728\u6709\u9650\u786c\u4ef6\u6761\u4ef6\u4e0b\u4f9d\u7136\u8868\u73b0\u51fa\u8272\uff0c\u6613\u4e8e\u672c\u5730\u90e8\u7f72\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4fe1\u606f\u8fc7\u8f7d\u65f6\u4ee3\u4e8b\u5b9e\u6838\u67e5\u7684\u96be\u9898\uff0c\u5e76\u5728\u6709\u9650\u786c\u4ef6\u8d44\u6e90\u4e0b\u5b9e\u73b0\u9ad8\u6548\u3001\u7cbe\u51c6\u7684\u4e8b\u5b9e\u6838\u67e5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u6d01\u7684\u4e24\u6b65RAG\uff08Retrieval-Augmented Generation\uff09\u6d41\u7a0b\uff0c\u5bf9\u53bb\u5e74\u7684\u65b9\u6cd5\u8fdb\u884c\u4e86\u6539\u8fdb\uff0c\u652f\u6301\u672c\u5730\u5316\u90e8\u7f72\u3002", "result": "\u8be5\u7cfb\u7edf\u5728FEVER 8\u7ade\u8d5b\u4e2d\u83b7\u5f97\u7b2c\u4e00\u540d\uff0c\u5e76\u4e14\u5728\u4ec5\u6709\u5355\u5f20NVidia A10 GPU\u300123GB\u663e\u5b58\u548c\u6bcf\u6761claim 60\u79d2\u8fd0\u884c\u65f6\u95f4\u7684\u6761\u4ef6\u4e0b\uff0c\u4ecd\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684Ev2R\u6307\u6807\u7ec6\u5206\u4e0b\u7684\u4e8b\u5b9e\u6838\u67e5\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4e24\u6b65RAG\u6d41\u7a0b\u4e0d\u4ec5\u80fd\u83b7\u5f97\u9ad8\u7cbe\u5ea6\u7684\u4e8b\u5b9e\u6838\u67e5\u7ed3\u679c\uff0c\u4e5f\u6613\u4e8e\u90e8\u7f72\u4e8e\u672c\u5730\u53d7\u9650\u786c\u4ef6\u73af\u5883\u4e2d\uff0c\u517c\u987e\u51c6\u786e\u7387\u548c\u5b9e\u9645\u5e94\u7528\u80fd\u529b\u3002"}}
{"id": "2508.04399", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04399", "abs": "https://arxiv.org/abs/2508.04399", "authors": ["Xu Zhang", "Mei Chen"], "title": "Improving Crash Data Quality with Large Language Models: Evidence from Secondary Crash Narratives in Kentucky", "comment": "19 pages, 2 figures", "summary": "This study evaluates advanced natural language processing (NLP) techniques to\nenhance crash data quality by mining crash narratives, using secondary crash\nidentification in Kentucky as a case study. Drawing from 16,656 manually\nreviewed narratives from 2015-2022, with 3,803 confirmed secondary crashes, we\ncompare three model classes: zero-shot open-source large language models (LLMs)\n(LLaMA3:70B, DeepSeek-R1:70B, Qwen3:32B, Gemma3:27B); fine-tuned transformers\n(BERT, DistilBERT, RoBERTa, XLNet, Longformer); and traditional logistic\nregression as baseline. Models were calibrated on 2015-2021 data and tested on\n1,771 narratives from 2022. Fine-tuned transformers achieved superior\nperformance, with RoBERTa yielding the highest F1-score (0.90) and accuracy\n(95%). Zero-shot LLaMA3:70B reached a comparable F1 of 0.86 but required 139\nminutes of inference; the logistic baseline lagged well behind (F1:0.66). LLMs\nexcelled in recall for some variants (e.g., GEMMA3:27B at 0.94) but incurred\nhigh computational costs (up to 723 minutes for DeepSeek-R1:70B), while\nfine-tuned models processed the test set in seconds after brief training.\nFurther analysis indicated that mid-sized LLMs (e.g., DeepSeek-R1:32B) can\nrival larger counterparts in performance while reducing runtime, suggesting\nopportunities for optimized deployments. Results highlight trade-offs between\naccuracy, efficiency, and data requirements, with fine-tuned transformer models\nbalancing precision and recall effectively on Kentucky data. Practical\ndeployment considerations emphasize privacy-preserving local deployment,\nensemble approaches for improved accuracy, and incremental processing for\nscalability, providing a replicable scheme for enhancing crash-data quality\nwith advanced NLP.", "AI": {"tldr": "\u901a\u8fc7\u5bf9\u80af\u5854\u57fa\u5dde16,656\u4efd\u4e8b\u6545\u53d9\u8ff0\u6d4b\u8bd5\uff0c\u5fae\u8c03\u7248Transformer\u6a21\u578b\u5982RoBERTa\u80fd\u9ad8\u6548\u51c6\u786e\u5730\u81ea\u52a8\u8bc6\u522b\u4ea4\u901a\u4e8c\u6b21\u4e8b\u6545\uff0c\u4f18\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u548c\u4f20\u7edf\u65b9\u6cd5\uff0c\u9002\u5408\u672c\u5730\u9690\u79c1\u53cb\u597d\u90e8\u7f72\u3002\u5927\u6a21\u578b\u53ec\u56de\u7a81\u51fa\u4f46\u63a8\u7406\u5f00\u9500\u5927\uff0c\u4e2d\u7b49\u89c4\u6a21\u6a21\u578b\u5728\u51c6\u786e\u548c\u6548\u7387\u95f4\u8868\u73b0\u826f\u597d\uff0c\u4e3a\u4ea4\u901a\u6570\u636e\u667a\u80fd\u5316\u5904\u7406\u63d0\u4f9b\u53ef\u884c\u4f18\u5316\u65b9\u6848\u3002", "motivation": "\u63d0\u5347\u9053\u8def\u4ea4\u901a\u4e8b\u6545\u6570\u636e\u8d28\u91cf\u5bf9\u4e8e\u4ea4\u901a\u5b89\u5168\u4e0e\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u800c\u73b0\u6709\u7684\u4e8c\u6b21\u4e8b\u6545\u8bc6\u522b\u4e3b\u8981\u4f9d\u8d56\u7ed3\u6784\u5316\u6570\u636e\uff0c\u672a\u5145\u5206\u5229\u7528\u4e8b\u6545\u53d9\u8ff0\u6587\u672c\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5148\u8fdb\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406(NLP)\u6280\u672f\uff0c\u6316\u6398\u4e8b\u6545\u53d9\u8ff0\uff0c\u63d0\u9ad8\u4e8b\u6545\u6570\u636e\u7684\u5b8c\u6574\u6027\u548c\u51c6\u786e\u6027\uff0c\u52a9\u529b\u66f4\u6709\u6548\u7684\u4e8c\u6b21\u4e8b\u6545\u8bc6\u522b\u3002", "method": "\u4ee5\u80af\u5854\u57fa\u5dde2015-2022\u5e74\u517116,656\u4efd\u4eba\u5de5\u5ba1\u6838\u7684\u4ea4\u901a\u4e8b\u6545\u53d9\u8ff0\u4e3a\u6570\u636e\u96c6\uff0c\u5176\u4e2d\u5305\u542b3,803\u4f8b\u786e\u8ba4\u7684\u4e8c\u6b21\u4e8b\u6545\u3002\u5bf9\u6bd4\u8bc4\u4f30\u4e86\u4e09\u7c7b\u6a21\u578b\uff1a1) \u96f6\u6837\u672c\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff08LLaMA3:70B, DeepSeek-R1:70B, Qwen3:32B, Gemma3:27B\uff09\uff1b2) \u7ecf\u8fc7\u5fae\u8c03\u7684transformers\u6a21\u578b\uff08BERT, DistilBERT, RoBERTa, XLNet, Longformer\uff09\uff1b3) \u4f20\u7edf\u7684\u903b\u8f91\u56de\u5f52\u4f5c\u4e3a\u57fa\u7ebf\u3002\u4ee52015-2021\u5e74\u6570\u636e\u8bad\u7ec3\uff0c2022\u5e741,771\u6761\u6570\u636e\u4e3a\u6d4b\u8bd5\u96c6\u3002", "result": "\u5fae\u8c03\u7684transformer\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0cRoBERTa\u53d6\u5f97F1\u503c0.90\u548c\u51c6\u786e\u738795%\uff1b\u96f6\u6837\u672cLLaMA3:70B\u83b7\u5f97\u53ef\u6bd4\u7684F1\uff080.86\uff09\uff0c\u4f46\u63a8\u7406\u8017\u65f6139\u5206\u949f\uff0c\u903b\u8f91\u56de\u5f52\u663e\u8457\u843d\u540e\uff08F1:0.66\uff09\u3002\u90e8\u5206LLMs\u5982GEMMA3:27B\u53ec\u56de\u7387\u8fbe0.94\u4f46\u8fd0\u7b97\u8017\u65f6\u9ad8\uff1b\u800c\u4e2d\u7b49\u89c4\u6a21LLMs\uff08\u5982DeepSeek-R1:32B\uff09\u53ef\u5339\u654c\u5927\u6a21\u578b\u5374\u5927\u5e45\u51cf\u5c11\u8fd0\u884c\u65f6\u95f4\u3002", "conclusion": "\u5fae\u8c03Transformer\u6a21\u578b\uff08\u5c24\u5176\u662fRoBERTa\uff09\u53ef\u5728\u4ea4\u901a\u4e8b\u6545\u6587\u672c\u6316\u6398\u4e2d\u5b9e\u73b0\u9ad8\u51c6\u786e\u7387\u548c\u9ad8\u6548\u7387\uff0c\u9002\u5408\u672c\u5730\u5316\u3001\u9690\u79c1\u53cb\u597d\u90e8\u7f72\u3002\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53ec\u56de\u7387\u4e0a\u5177\u6709\u6f5c\u529b\u4f46\u63a8\u7406\u4ee3\u4ef7\u5927\u3002\u4e2d\u7b49\u89c4\u6a21\u6a21\u578b\u5b9e\u73b0\u4e86\u6027\u80fd\u4e0e\u6548\u7387\u7684\u5e73\u8861\u3002\u7efc\u5408\u6765\u770b\uff0c\u7ec6\u81f4\u6743\u8861\u7cbe\u5ea6\u3001\u6548\u7387\u4e0e\u6570\u636e\u9700\u6c42\u540e\uff0c\u5fae\u8c03Transformer\u65b9\u6848\u53ef\u4e3a\u4ea4\u901a\u4e8b\u6545\u6570\u636e\u63d0\u5347\u8d28\u91cf\u63d0\u4f9b\u53ef\u590d\u5236\u8def\u5f84\u3002"}}
{"id": "2508.04401", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04401", "abs": "https://arxiv.org/abs/2508.04401", "authors": ["Vladim\u00edr Havl\u00edk"], "title": "Why are LLMs' abilities emergent?", "comment": "20 pages", "summary": "The remarkable success of Large Language Models (LLMs) in generative tasks\nhas raised fundamental questions about the nature of their acquired\ncapabilities, which often appear to emerge unexpectedly without explicit\ntraining. This paper examines the emergent properties of Deep Neural Networks\n(DNNs) through both theoretical analysis and empirical observation, addressing\nthe epistemological challenge of \"creation without understanding\" that\ncharacterises contemporary AI development. We explore how the neural approach's\nreliance on nonlinear, stochastic processes fundamentally differs from symbolic\ncomputational paradigms, creating systems whose macro-level behaviours cannot\nbe analytically derived from micro-level neuron activities. Through analysis of\nscaling laws, grokking phenomena, and phase transitions in model capabilities,\nI demonstrate that emergent abilities arise from the complex dynamics of highly\nsensitive nonlinear systems rather than simply from parameter scaling alone. My\ninvestigation reveals that current debates over metrics, pre-training loss\nthresholds, and in-context learning miss the fundamental ontological nature of\nemergence in DNNs. I argue that these systems exhibit genuine emergent\nproperties analogous to those found in other complex natural phenomena, where\nsystemic capabilities emerge from cooperative interactions among simple\ncomponents without being reducible to their individual behaviours. The paper\nconcludes that understanding LLM capabilities requires recognising DNNs as a\nnew domain of complex dynamical systems governed by universal principles of\nemergence, similar to those operating in physics, chemistry, and biology. This\nperspective shifts the focus from purely phenomenological definitions of\nemergence to understanding the internal dynamic transformations that enable\nthese systems to acquire capabilities that transcend their individual\ncomponents.", "AI": {"tldr": "\u672c\u6587\u5256\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u6d8c\u73b0\u7684\u672c\u8d28\uff0c\u8ba4\u4e3a\u5176\u6e90\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u590d\u6742\u975e\u7ebf\u6027\u52a8\u6001\u8fc7\u7a0b\uff0c\u547c\u5401\u7528\u590d\u6742\u7cfb\u7edf\u7406\u8bba\u53bb\u7406\u89e3\u548c\u5b9a\u4e49LLMs\u7684\u80fd\u529b\u8fb9\u754c\u548c\u539f\u7406\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u975e\u51e1\u8868\u73b0\u5f15\u53d1\u4e86\u5173\u4e8e\u5176\u80fd\u529b\u672c\u8d28\u7684\u8ba8\u8bba\uff0c\u5c24\u5176\u662f\u8fd9\u4e9b\u80fd\u529b\u5f80\u5f80\u662f\u201c\u6d8c\u73b0\u201d\u7684\u3001\u975e\u76f4\u63a5\u8bad\u7ec3\u6240\u81f4\u3002\u672c\u8bba\u6587\u5173\u6ce8\u4e8e\u7406\u89e3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNNs\uff09\u80fd\u529b\u6d8c\u73b0\u7684\u6839\u672c\u539f\u56e0\uff0c\u53ca\u5176\u4e0e\u4f20\u7edf\u7b26\u53f7\u4e3b\u4e49\u8ba1\u7b97\u8303\u5f0f\u7684\u672c\u8d28\u5dee\u5f02\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u7406\u8bba\u5206\u6790\u4e0e\u5b9e\u8bc1\u7814\u7a76\uff0c\u63a2\u8ba8\u4e86\u795e\u7ecf\u7f51\u7edc\u7684\u975e\u7ebf\u6027\u3001\u968f\u673a\u6027\u5982\u4f55\u5bfc\u81f4\u7cfb\u7edf\u5b8f\u89c2\u884c\u4e3a\u65e0\u6cd5\u76f4\u63a5\u4ece\u5fae\u89c2\u795e\u7ecf\u5143\u6d3b\u52a8\u63a8\u5bfc\u51fa\u6765\u3002\u7740\u91cd\u5206\u6790\u4e86\u6269\u5c55\u5b9a\u5f8b\uff08scaling laws\uff09\u3001grokking\u73b0\u8c61\u548c\u6a21\u578b\u80fd\u529b\u7684\u76f8\u53d8\uff0c\u5e76\u8003\u5bdf\u4e86\u5e38\u89c1\u6307\u6807\u3001\u9884\u8bad\u7ec3\u635f\u5931\u9608\u503c\u53ca\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u4e89\u8bae\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cDNN\u7684\u80fd\u529b\u6d8c\u73b0\u4e0d\u662f\u7b80\u5355\u7531\u53c2\u6570\u6269\u5c55\u5f15\u8d77\uff0c\u800c\u662f\u6e90\u4e8e\u9ad8\u5ea6\u654f\u611f\u7684\u975e\u7ebf\u6027\u7cfb\u7edf\u7684\u590d\u6742\u52a8\u6001\u3002\u80fd\u529b\u6d8c\u73b0\u7c7b\u4f3c\u4e8e\u81ea\u7136\u754c\u7269\u7406\u3001\u5316\u5b66\u3001\u751f\u7269\u4e2d\u7684\u590d\u6742\u7cfb\u7edf\uff0c\u5176\u534f\u540c\u4e0e\u76f8\u4e92\u4f5c\u7528\u4ea7\u751f\u8d85\u8d8a\u4e2a\u4f53\u7684\u7cfb\u7edf\u6027\u80fd\u529b\u3002\u5355\u9760\u73b0\u6709\u6307\u6807\u96be\u4ee5\u6355\u6349\u672c\u8d28\u3002", "conclusion": "\u771f\u6b63\u7406\u89e3LLMs\u80fd\u529b\u9700\u8981\u628aDNN\u89c6\u4e3a\u4e00\u79cd\u5168\u65b0\u590d\u6742\u52a8\u529b\u7cfb\u7edf\uff0c\u5176\u53d7\u63a7\u4e8e\u666e\u9002\u7684\u6d8c\u73b0\u539f\u7406\u3002\u672a\u6765\u7814\u7a76\u5e94\u8be5\u8f6c\u5411\u5206\u6790\u7cfb\u7edf\u5185\u90e8\u7684\u52a8\u529b\u5b66\u53d8\u6362\u548c\u7ec4\u5206\u95f4\u534f\u4f5c\u673a\u5236\uff0c\u800c\u4e0d\u53ea\u662f\u89c2\u5bdf\u8868\u9762\u73b0\u8c61\u3002"}}
{"id": "2508.04402", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04402", "abs": "https://arxiv.org/abs/2508.04402", "authors": ["Kiyotada Mori", "Seiya Kawano", "Chaoran Liu", "Carlos Toshinori Ishi", "Angel Fernando Garcia Contreras", "Koichiro Yoshino"], "title": "What Do Humans Hear When Interacting? Experiments on Selective Listening for Evaluating ASR of Spoken Dialogue Systems", "comment": null, "summary": "Spoken dialogue systems (SDSs) utilize automatic speech recognition (ASR) at\nthe front end of their pipeline. The role of ASR in SDSs is to recognize\ninformation in user speech related to response generation appropriately.\nExamining selective listening of humans, which refers to the ability to focus\non and listen to important parts of a conversation during the speech, will\nenable us to identify the ASR capabilities required for SDSs and evaluate them.\nIn this study, we experimentally confirmed selective listening when humans\ngenerate dialogue responses by comparing human transcriptions for generating\ndialogue responses and reference transcriptions. Based on our experimental\nresults, we discuss the possibility of a new ASR evaluation method that\nleverages human selective listening, which can identify the gap between\ntranscription ability between ASR systems and humans.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u4eba\u7c7b\u5728\u5bf9\u8bdd\u751f\u6210\u65f6\u4f1a\u9009\u62e9\u6027\u5173\u6ce8\u6709\u7528\u4fe1\u606f\uff0c\u63d0\u51fa\u4ee5\u6b64\u4e3a\u57fa\u7840\u7684ASR\u8bc4\u4f30\u65b0\u601d\u8def\uff0c\u6709\u671b\u63d0\u5347\u5f53\u524d\u53e3\u8bed\u5bf9\u8bdd\u7cfb\u7edf\u7684\u8bc4\u6d4b\u8d34\u8fd1\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u662f\u53e3\u8bed\u5bf9\u8bdd\u7cfb\u7edf\uff08SDS\uff09\u524d\u7aef\u7684\u5173\u952e\u73af\u8282\uff0c\u5f53\u524d\u7f3a\u4e4f\u7406\u89e3\u548c\u8bc4\u4f30ASR\u5728\u5bf9\u8bdd\u751f\u6210\u4e2d\u5e94\u5177\u5907\u7684\u80fd\u529b\u3002\u53d7\u4eba\u7c7b\u201c\u9009\u62e9\u6027\u542c\u53d6\u201d\u80fd\u529b\u7684\u542f\u53d1\uff0c\u4f5c\u8005\u5e0c\u671b\u627e\u5230\u66f4\u8d34\u5408\u5b9e\u9645\u5bf9\u8bdd\u573a\u666f\u7684ASR\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u5bf9\u6bd4\u4eba\u7c7b\u5728\u751f\u6210\u5bf9\u8bdd\u56de\u590d\u65f6\u7684\u8f6c\u5f55\u5185\u5bb9\u4e0e\u6807\u51c6\u53c2\u8003\u8f6c\u5f55\uff0c\u5206\u6790\u4eba\u7c7b\u5728\u5bf9\u8bdd\u751f\u6210\u4e2d\u7684\u9009\u62e9\u6027\u542c\u53d6\u73b0\u8c61\u3002", "result": "\u5b9e\u9a8c\u786e\u8ba4\u4e86\u4eba\u5728\u751f\u6210\u5bf9\u8bdd\u56de\u590d\u65f6\u5b58\u5728\u660e\u663e\u7684\u9009\u62e9\u6027\u542c\u53d6\uff0c\u5173\u6ce8\u7684\u662f\u5bf9\u751f\u6210\u56de\u590d\u6709\u4ef7\u503c\u7684\u8bed\u97f3\u90e8\u5206\uff0c\u4e0e\u53c2\u8003\u8f6c\u5f55\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u57fa\u4e8e\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4f5c\u8005\u8ba4\u4e3a\u53ef\u4ee5\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4eba\u7c7b\u9009\u62e9\u6027\u542c\u53d6\u7684\u65b0\u578bASR\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7528\u4e8e\u8861\u91cfASR\u4e0e\u4eba\u7c7b\u5728\u771f\u5b9e\u5bf9\u8bdd\u4e2d\u8f6c\u5f55\u80fd\u529b\u7684\u5dee\u8ddd\u3002"}}
{"id": "2508.04403", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04403", "abs": "https://arxiv.org/abs/2508.04403", "authors": ["Kiyotada Mori", "Seiya Kawano", "Angel Fernando Garcia Contreras", "Koichiro Yoshino"], "title": "Dialogue Response Prefetching Based on Semantic Similarity and Prediction Confidence of Language Model", "comment": null, "summary": "Prefetching of dialogue responses has been investigated to reduce\nuser-perceived latency (UPL), which refers to the user's waiting time before\nreceiving the system's response, in spoken dialogue systems. To reduce the UPL,\nit is necessary to predict complete user utterances before the end of the\nuser's speech, typically by language models, to prepare prefetched dialogue\nresponses. In this study, we proposed a prediction confidence model (PCM) that\ndetermines whether prefetching is possible or not by estimating the semantic\nsimilarity between the predicted complete user utterance and the complete user\nutterance. We evaluated our PCM based on the differences between the predicted\ncomplete user utterance and the complete user utterance.", "AI": {"tldr": "\u901a\u8fc7\u63d0\u51fa\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u6a21\u578b\uff0c\u7cbe\u51c6\u5224\u65ad\u5bf9\u8bdd\u9884\u6d4b\u662f\u5426\u53ef\u7528\uff0c\u4ece\u800c\u51cf\u5c11\u7528\u6237\u7b49\u5f85\u65f6\u95f4\u3002", "motivation": "\u5728\u8bed\u97f3\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\uff0c\u7528\u6237\u7b49\u5f85\u7cfb\u7edf\u54cd\u5e94\u7684\u65f6\u95f4\uff08\u7528\u6237\u611f\u77e5\u5ef6\u8fdf\uff0cUPL\uff09\u8f83\u957f\uff0c\u5f71\u54cd\u7528\u6237\u4f53\u9a8c\u3002\u4e3a\u51cf\u5c11UPL\uff0c\u9700\u5728\u7528\u6237\u8bf4\u8bdd\u7ed3\u675f\u524d\u9884\u6d4b\u5b8c\u6574\u53d1\u8a00\uff0c\u63d0\u524d\u51c6\u5907\u7cfb\u7edf\u54cd\u5e94\u3002", "method": "\u63d0\u51fa\u4e86\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u6a21\u578b\uff08PCM\uff09\uff0c\u901a\u8fc7\u4f30\u7b97\u9884\u6d4b\u7684\u5b8c\u6574\u7528\u6237\u53d1\u8a00\u4e0e\u771f\u5b9e\u7528\u6237\u53d1\u8a00\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6\uff0c\u5224\u65ad\u662f\u5426\u53ef\u4ee5\u8fdb\u884c\u9884\u53d6\u54cd\u5e94\u3002", "result": "\u5229\u7528PCM\u6839\u636e\u9884\u6d4b\u548c\u771f\u5b9e\u7528\u6237\u53d1\u8a00\u7684\u5dee\u5f02\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u4e86PCM\u5bf9\u53ef\u5426\u9884\u53d6\u54cd\u5e94\u7684\u5224\u65ad\u80fd\u529b\u3002", "conclusion": "\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u6a21\u578b\uff08PCM\uff09\u53ef\u4ee5\u6709\u6548\u8bc4\u4f30\u662f\u5426\u53ef\u4ee5\u8fdb\u884c\u5bf9\u8bdd\u54cd\u5e94\u9884\u53d6\uff0c\u4ece\u800c\u6709\u52a9\u4e8e\u51cf\u5c11\u8bed\u97f3\u5bf9\u8bdd\u7cfb\u7edf\u7684\u7528\u6237\u611f\u77e5\u5ef6\u8fdf\u3002"}}
{"id": "2508.04423", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04423", "abs": "https://arxiv.org/abs/2508.04423", "authors": ["Jie Zhu", "Huaixia Dou", "Junhui Li", "Lifan Guo", "Feng Chen", "Chi Zhang", "Fang Kong"], "title": "Evaluating, Synthesizing, and Enhancing for Customer Support Conversation", "comment": "under review", "summary": "Effective customer support requires not only accurate problem solving but\nalso structured and empathetic communication aligned with professional\nstandards. However, existing dialogue datasets often lack strategic guidance,\nand real-world service data is difficult to access and annotate. To address\nthis, we introduce the task of Customer Support Conversation (CSC), aimed at\ntraining customer service agents to respond using well-defined support\nstrategies. We propose a structured CSC framework grounded in COPC guidelines,\ndefining five conversational stages and twelve strategies to guide high-quality\ninteractions. Based on this, we construct CSConv, an evaluation dataset of\n1,855 real-world customer-agent conversations rewritten using LLMs to reflect\ndeliberate strategy use, and annotated accordingly. Additionally, we develop a\nrole-playing approach that simulates strategy-rich conversations using\nLLM-powered roles aligned with the CSC framework, resulting in the training\ndataset RoleCS. Experiments show that fine-tuning strong LLMs on RoleCS\nsignificantly improves their ability to generate high-quality, strategy-aligned\nresponses on CSConv. Human evaluations further confirm gains in problem\nresolution. All code and data will be made publicly available at\nhttps://github.com/aliyun/qwen-dianjin.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u7ed3\u6784\u5316\u5ba2\u670d\u5bf9\u8bdd\u65b0\u4efb\u52a1\u4e0e\u6846\u67b6\uff0c\u5229\u7528LLM\u751f\u6210\u5e76\u91cd\u5199\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u6a21\u578b\u5728\u5ba2\u670d\u9886\u57df\u7684\u5e94\u7b54\u8d28\u91cf\u548c\u7b56\u7565\u6267\u884c\u80fd\u529b\u3002", "motivation": "\u5ba2\u6237\u652f\u6301\u4e0d\u4ec5\u9700\u8981\u51c6\u786e\u89e3\u51b3\u95ee\u9898\uff0c\u8fd8\u9700\u8981\u7ed3\u6784\u5316\u548c\u5177\u5907\u540c\u7406\u5fc3\u7684\u4e13\u4e1a\u6c9f\u901a\uff0c\u4f46\u73b0\u6709\u6570\u636e\u96c6\u7f3a\u4e4f\u7b56\u7565\u6307\u5bfc\u4e14\u771f\u5b9e\u5ba2\u670d\u6570\u636e\u96be\u4ee5\u83b7\u53d6\u548c\u6807\u6ce8\u3002", "method": "\u63d0\u51fa\u4e86Customer Support Conversation (CSC)\u65b0\u4efb\u52a1\u3002\u57fa\u4e8eCOPC\u6807\u51c6\uff0c\u5b9a\u4e49\u4e86\u4e94\u4e2a\u4f1a\u8bdd\u9636\u6bb5\u548c\u5341\u4e8c\u79cd\u652f\u6301\u7b56\u7565\uff0c\u642d\u5efa\u4e86\u7ed3\u6784\u5316\u7684CSC\u6846\u67b6\u3002\u901a\u8fc7LLM\u91cd\u5199\u5e76\u6807\u6ce8\u4e861,855\u6761\u771f\u5b9e\u5ba2\u670d\u5bf9\u8bdd\uff0c\u5f62\u6210\u4e86CSConv\u8bc4\u6d4b\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eLLM\u89d2\u8272\u626e\u6f14\u7684\u5bf9\u8bdd\u751f\u6210\u65b9\u6cd5\uff0c\u521b\u9020\u4e86RoleCS\u8bad\u7ec3\u96c6\u3002", "result": "\u5728RoleCS\u4e0a\u5fae\u8c03\u7684\u5927\u6a21\u578b\u5728CSConv\u6570\u636e\u96c6\u4e0a\u7684\u7b56\u7565\u4e00\u81f4\u6027\u548c\u9ad8\u8d28\u91cf\u5e94\u7b54\u80fd\u529b\u663e\u8457\u63d0\u5347\uff0c\u7ecf\u4eba\u5de5\u8bc4\u4f30\u4e5f\u663e\u793a\u5728\u95ee\u9898\u89e3\u51b3\u6548\u679c\u4e0a\u6709\u660e\u663e\u63d0\u5347\u3002", "conclusion": "\u7ed3\u6784\u5316\u7684\u5bf9\u8bdd\u7b56\u7565\u6846\u67b6\u7ed3\u5408LLM\u89d2\u8272\u626e\u6f14\u751f\u6210\u7684\u6570\u636e\u80fd\u591f\u6709\u6548\u63d0\u5347\u5927\u6a21\u578b\u5728\u5ba2\u670d\u573a\u666f\u4e0b\u7684\u5e94\u7b54\u8d28\u91cf\u4e0e\u7b56\u7565\u5bf9\u9f50\u80fd\u529b\u3002"}}
{"id": "2508.04440", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04440", "abs": "https://arxiv.org/abs/2508.04440", "authors": ["Yutong Wu", "Di Huang", "Ruosi Wan", "Yue Peng", "Shijie Shang", "Chenrui Cao", "Lei Qi", "Rui Zhang", "Zidong Du", "Jie Yan", "Xing Hu"], "title": "StepFun-Formalizer: Unlocking the Autoformalization Potential of LLMs through Knowledge-Reasoning Fusion", "comment": "24 pages, 17 figures, under review", "summary": "Autoformalization aims to translate natural-language mathematical statements\ninto a formal language. While LLMs have accelerated progress in this area,\nexisting methods still suffer from low accuracy. We identify two key abilities\nfor effective autoformalization: comprehensive mastery of formal-language\ndomain knowledge, and reasoning capability of natural language problem\nunderstanding and informal-formal alignment. Without the former, a model cannot\nidentify the correct formal objects; without the latter, it struggles to\ninterpret real-world contexts and map them precisely into formal expressions.\nTo address these gaps, we introduce ThinkingF, a data synthesis and training\npipeline that improves both abilities. First, we construct two datasets: one by\ndistilling and selecting large-scale examples rich in formal knowledge, and\nanother by generating informal-to-formal reasoning trajectories guided by\nexpert-designed templates. We then apply SFT and RLVR with these datasets to\nfurther fuse and refine the two abilities. The resulting 7B and 32B models\nexhibit both comprehensive formal knowledge and strong informal-to-formal\nreasoning. Notably, StepFun-Formalizer-32B achieves SOTA BEq@1 scores of 40.5%\non FormalMATH-Lite and 26.7% on ProverBench, surpassing all prior\ngeneral-purpose and specialized models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6570\u636e\u53ca\u8bad\u7ec3\u6d41\u7a0b\uff0c\u6709\u6548\u63d0\u5347\u5927\u6a21\u578b\u81ea\u52a8\u5c06\u6570\u5b66\u81ea\u7136\u8bed\u8a00\u8f6c\u5316\u4e3a\u5f62\u5f0f\u5316\u8bed\u8a00\u7684\u80fd\u529b\uff0c\u5e76\u5927\u5e45\u5237\u65b0\u4e86\u76f8\u5173\u4efb\u52a1\u7684\u51c6\u786e\u7387\u7eaa\u5f55\u3002", "motivation": "\u73b0\u6709\u5927\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u5230\u6570\u5b66\u5f62\u5f0f\u5316\uff08autoformalization\uff09\u4efb\u52a1\u4e0a\u51c6\u786e\u7387\u4ecd\u4f4e\uff0c\u4e3b\u8981\u7531\u4e8e\u7f3a\u4e4f\u5b8c\u5584\u7684\u5f62\u5f0f\u5316\u77e5\u8bc6\u5b66\u4e60\u4e0e\u81ea\u7136\u8bed\u8a00\u5bf9\u9f50\u63a8\u7406\u80fd\u529b\u3002", "method": "\u6784\u5efa\u4e24\u4e2a\u65b0\u6570\u636e\u96c6\uff08\u6db5\u76d6\u5927\u91cf\u5f62\u5f0f\u5316\u77e5\u8bc6\u4f8b\u5b50\u7684distilled dataset\u548c\u7531\u4e13\u5bb6\u6a21\u677f\u5f15\u5bfc\u7684\u975e\u6b63\u5f0f\u5230\u6b63\u5f0f\u63a8\u7406\u8bb0\u5f55\uff09\uff0c\u5e76\u7528SFT\u548cRLVR\u5bf9\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "7B\u548c32B\u53c2\u6570\u89c4\u6a21\u6a21\u578b\u5747\u8fbe\u5230\u4e86\u4f18\u79c0\u7684\u7efc\u5408\u8868\u73b0\uff0c32B\u6a21\u578b\u5728FormalMATH-Lite\uff08BEq@1 40.5%\uff09\u548cProverBench\uff0826.7%\uff09\u4e0a\u83b7\u5f97SOTA\u3002", "conclusion": "\u63d0\u51fa\u7684ThinkingF\u6d41\u7a0b\u80fd\u6709\u6548\u63d0\u5347\u5927\u6a21\u578b\u5728\u6570\u5b66\u81ea\u52a8\u5f62\u5f0f\u5316\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u8fbe\u5230\u65b0\u7684SOTA\u6c34\u5e73\u3002"}}
{"id": "2508.04442", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04442", "abs": "https://arxiv.org/abs/2508.04442", "authors": ["Rohaizah Abdul Wahid", "Muhamad Said Nizamuddin Nadim", "Suliana Sulaiman", "Syahmi Akmal Shaharudin", "Muhammad Danial Jupikil", "Iqqwan Jasman Su Azlan Su"], "title": "Automated Generation of Curriculum-Aligned Multiple-Choice Questions for Malaysian Secondary Mathematics Using Generative AI", "comment": null, "summary": "This paper addresses the critical need for scalable and high-quality\neducational assessment tools within the Malaysian education system. It\nhighlights the potential of Generative AI (GenAI) while acknowledging the\nsignificant challenges of ensuring factual accuracy and curriculum alignment,\nespecially for low-resource languages like Bahasa Melayu. This research\nintroduces and compares four incremental pipelines for generating Form 1\nMathematics multiple-choice questions (MCQs) in Bahasa Melayu using OpenAI's\nGPT-4o. The methods range from non-grounded prompting (structured and basic) to\nRetrieval-Augmented Generation (RAG) approaches (one using the LangChain\nframework, one implemented manually). The system is grounded in official\ncurriculum documents, including teacher-prepared notes and the yearly teaching\nplan (RPT). A dual-pronged automated evaluation framework is employed to assess\nthe generated questions. Curriculum alignment is measured using Semantic\nTextual Similarity (STS) against the RPT, while contextual validity is verified\nthrough a novel RAG-based Question-Answering (RAG-QA) method. The results\ndemonstrate that RAG-based pipelines significantly outperform non-grounded\nprompting methods, producing questions with higher curriculum alignment and\nfactual validity. The study further analyzes the trade-offs between the ease of\nimplementation of framework-based RAG and the fine-grained control offered by a\nmanual pipeline. This work presents a validated methodology for generating\ncurriculum-specific educational content in a low-resource language, introduces\na symbiotic RAG-QA evaluation technique, and provides actionable insights for\nthe development and deployment of practical EdTech solutions in Malaysia and\nsimilar regions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u591a\u79cd\u751f\u6210\u9a6c\u6765\u8bed\u6570\u5b66\u9898\u76ee\u7684\u81ea\u52a8\u5316\u6d41\u7a0b\uff0c\u57fa\u4e8eRAG\u65b9\u6cd5\u5e76\u7ed3\u5408\u5b98\u65b9\u8bfe\u7a0b\u5185\u5bb9\u3002\u5b9e\u9a8c\u7ed3\u679c\u6df1\u663eRAG\u65b9\u6cd5\u5728\u8bfe\u7a0b\u5bf9\u9f50\u548c\u4e8b\u5b9e\u6709\u6548\u6027\u4e0a\u4f18\u52bf\u660e\u663e\uff0c\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6027\u7684EdTech\u751f\u6210\u4e0e\u8bc4\u6d4b\u53c2\u8003\u3002", "motivation": "\u8be5\u8bba\u6587\u5173\u6ce8\u9a6c\u6765\u897f\u4e9a\u6559\u80b2\u4f53\u7cfb\u4e2d\u5bf9\u53ef\u6269\u5c55\u4e14\u9ad8\u8d28\u91cf\u6559\u80b2\u8bc4\u4f30\u5de5\u5177\u7684\u8feb\u5207\u9700\u6c42\uff0c\u5c24\u5176\u662f\u5728\u8d44\u6e90\u6709\u9650\u7684\u8bed\u8a00\u73af\u5883\uff08\u5982\u9a6c\u6765\u8bed\uff09\u4e0b\uff0c\u4e9f\u9700\u786e\u4fdd\u81ea\u52a8\u5316\u751f\u6210\u5185\u5bb9\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\u4e0e\u8bfe\u7a0b\u5bf9\u9f50\u3002", "method": "\u63d0\u51fa\u5e76\u6bd4\u8f83\u4e86\u56db\u79cd\u9012\u8fdb\u5f0f\u6d41\u7a0b\uff0c\u5229\u7528OpenAI GPT-4o\u5728\u9a6c\u6765\u8bed\u73af\u5883\u4e0b\u751f\u6210\u521d\u4e2d\u4e00\u5e74\u7ea7\u6570\u5b66\u9009\u62e9\u9898\u3002\u8fd9\u4e9b\u65b9\u6cd5\u6db5\u76d6\uff1a\u975e\u57fa\u7840\u7684\u76f4\u63a5\u63d0\u793a\uff08\u7ed3\u6784\u5316\u548c\u57fa\u7840\u578b\uff09\u3001\u4ee5\u53ca\u4e24\u79cd\u4fe1\u606f\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\uff08\u4e00\u4e2a\u57fa\u4e8eLangChain\u6846\u67b6\uff0c\u4e00\u4e2a\u624b\u52a8\u5b9e\u73b0\uff09\u3002\u7cfb\u7edf\u5f15\u7528\u4e86\u5b98\u65b9\u8bfe\u7a0b\u6587\u6863\u548c\u6559\u5e08\u5907\u8bfe\u8d44\u6599\u3002\u8bc4\u4f30\u65b9\u9762\uff0c\u91c7\u7528\u4e86\u53cc\u7ba1\u9f50\u4e0b\u7684\u81ea\u52a8\u5316\u8bc4\u6d4b\u6846\u67b6\uff0c\u5229\u7528\u8bed\u4e49\u6587\u672c\u76f8\u4f3c\u5ea6\uff08STS\uff09\u8bc4\u4ef7\u9898\u76ee\u4e0e\u8bfe\u7a0b\u8ba1\u5212\uff08RPT\uff09\u7684\u5bf9\u9f50\u5ea6\uff0c\u5e76\u7528\u65b0\u9896\u7684RAG-QA\u65b9\u6cd5\u9a8c\u8bc1\u9898\u76ee\u7684\u4e0a\u4e0b\u6587\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u57fa\u4e8eRAG\u7684\u6d41\u7a0b\u5728\u751f\u6210\u8bfe\u7a0b\u5bf9\u9f50\u3001\u9ad8\u4e8b\u5b9e\u6709\u6548\u6027\u7684\u9898\u76ee\u65b9\u9762\u660e\u663e\u4f18\u4e8e\u975e\u57fa\u7840\u63d0\u793a\u65b9\u6cd5\u3002\u540c\u65f6\uff0c\u8bba\u6587\u5bf9RAG\u6846\u67b6\u5b9e\u73b0\u7684\u6613\u7528\u6027\u548c\u624b\u52a8\u5b9e\u73b0\u7684\u7ec6\u7c92\u5ea6\u63a7\u5236\u8fdb\u884c\u4e86\u6743\u8861\u5206\u6790\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u5957\u53ef\u5728\u8d44\u6e90\u6709\u9650\u8bed\u8a00\u4e2d\u5e94\u7528\u3001\u5bf9\u8bfe\u7a0b\u7279\u5b9a\u5185\u5bb9\u81ea\u52a8\u751f\u6210\u7684\u7ecf\u9a8c\u8bc1\u65b9\u6cd5\uff1b\u521b\u65b0\u6027\u5f15\u5165\u4e86RAG-QA\u8054\u5408\u8bc4\u6d4b\u6280\u672f\uff0c\u5e76\u4e3a\u9a6c\u6765\u897f\u4e9a\u53ca\u76f8\u4f3c\u5730\u533a\u6559\u80b2\u79d1\u6280\u5de5\u5177\u7684\u5b9e\u9645\u90e8\u7f72\u548c\u5f00\u53d1\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6027\u6307\u5bfc\u3002"}}
{"id": "2508.04494", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04494", "abs": "https://arxiv.org/abs/2508.04494", "authors": ["Bastien Li\u00e9tard", "Gabriel Loiseau"], "title": "CALE : Concept-Aligned Embeddings for Both Within-Lemma and Inter-Lemma Sense Differentiation", "comment": "Under review in ARR July 2025", "summary": "Lexical semantics is concerned with both the multiple senses a word can adopt\nin different contexts, and the semantic relations that exist between meanings\nof different words. To investigate them, Contextualized Language Models are a\nvaluable tool that provides context-sensitive representations that can be used\nto investigate lexical meaning. Recent works like XL-LEXEME have leveraged the\ntask of Word-in-Context to fine-tune them to get more semantically accurate\nrepresentations, but Word-in-Context only compares occurrences of the same\nlemma, limiting the range of captured information. In this paper, we propose an\nextension, Concept Differentiation, to include inter-words scenarios. We\nprovide a dataset for this task, derived from SemCor data. Then we fine-tune\nseveral representation models on this dataset. We call these models\nConcept-Aligned Embeddings (CALE). By challenging our models and other models\non various lexical semantic tasks, we demonstrate that the proposed models\nprovide efficient multi-purpose representations of lexical meaning that reach\nbest performances in our experiments. We also show that CALE's fine-tuning\nbrings valuable changes to the spatial organization of embeddings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u8de8\u8bcd\u8bed\u8bed\u4e49\u5efa\u6a21\u7684\u65b0\u65b9\u6cd5\u548c\u8bed\u6599\uff0c\u8bad\u7ec3\u51fa\u80fd\u591f\u9ad8\u6548\u8868\u8fbe\u591a\u79cd\u8bcd\u4e49\u8bed\u5883\u7684\u6a21\u578bCALE\uff0c\u5e76\u5728\u591a\u9879\u8bed\u4e49\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u8bcd\u6c47\u8bed\u4e49\u5b66\u5173\u6ce8\u5355\u8bcd\u5728\u4e0d\u540c\u8bed\u5883\u4e0b\u7684\u591a\u91cd\u8bcd\u4e49\uff0c\u4ee5\u53ca\u4e0d\u540c\u8bcd\u8bed\u4e49\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u5c3d\u7ba1\u4e0a\u4e0b\u6587\u5316\u8bed\u8a00\u6a21\u578b\u5982XL-LEXEME\u901a\u8fc7\u201c\u8bed\u5883\u4e2d\u8bcd\u8bed\u201d\u4efb\u52a1\u63d0\u5347\u8bcd\u4e49\u8868\u793a\uff0c\u4f46\u5176\u4ec5\u9650\u4e8e\u6bd4\u8f83\u540c\u4e00\u4e2a\u8bcd\u5f62\u7684\u4e0d\u540c\u7528\u6cd5\uff0c\u96be\u4ee5\u6355\u6349\u8bcd\u95f4\u7684\u8bed\u4e49\u4fe1\u606f\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u591f\u6269\u5c55\u81f3\u8bcd\u95f4\u8bed\u4e49\u5173\u7cfb\u7684\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6269\u5c55\u4efb\u52a1\u2014\u2014\u6982\u5ff5\u533a\u5206\uff08Concept Differentiation\uff09\uff0c\u4e0d\u518d\u5c40\u9650\u4e8e\u540c\u4e00\u8bcd\u5f62\uff08lemma\uff09\uff0c\u800c\u662f\u5173\u6ce8\u4e0d\u540c\u8bcd\u4e4b\u95f4\u7684\u5173\u8054\uff0c\u5e76\u57fa\u4e8eSemCor\u6784\u5efa\u4e86\u76f8\u5173\u6570\u636e\u96c6\u3002\u968f\u540e\uff0c\u4f5c\u8005\u5c06\u591a\u4e2a\u4e0a\u4e0b\u6587\u5316\u8868\u793a\u6a21\u578b\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\uff0c\u83b7\u5f97\u4e86\u540d\u4e3aConcept-Aligned Embeddings\uff08CALE\uff09\u7684\u65b0\u6a21\u578b\u3002", "result": "CALE\u6a21\u578b\u5728\u591a\u9879\u8bcd\u6c47\u8bed\u4e49\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u73b0\u4f18\u5f02\uff0c\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\u3002\u6b64\u5916\uff0cCALE\u7684\u5fae\u8c03\u663e\u8457\u6539\u5584\u4e86\u8bcd\u5411\u91cf\uff08embedding\uff09\u7684\u7a7a\u95f4\u5206\u5e03\uff0c\u63d0\u5347\u4e86\u8bed\u4e49\u6cdb\u5316\u80fd\u529b\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "\u6269\u5c55\u540e\u7684\u4efb\u52a1\u548c\u6570\u636e\u96c6\u6709\u52a9\u4e8e\u83b7\u5f97\u66f4\u5e7f\u6cdb\u4e14\u51c6\u786e\u7684\u8bcd\u4e49\u8868\u793a\u3002\u672c\u6587\u63d0\u51fa\u7684CALE\u6a21\u578b\u5728\u5b9e\u9645\u8bc4\u6d4b\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u548c\u5229\u7528\u8bcd\u6c47\u4e4b\u95f4\u4e30\u5bcc\u7684\u8bed\u4e49\u4fe1\u606f\u3002"}}
{"id": "2508.04530", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04530", "abs": "https://arxiv.org/abs/2508.04530", "authors": ["Chenglei Shen", "Zhongxiang Sun", "Teng Shi", "Xiao Zhang", "Jun Xu"], "title": "StyliTruth : Unlocking Stylized yet Truthful LLM Generation via Disentangled Steering", "comment": null, "summary": "Generating stylized large language model (LLM) responses via representation\nediting is a promising way for fine-grained output control. However, there\nexists an inherent trade-off: imposing a distinctive style often degrades\ntruthfulness. Existing representation editing methods, by naively injecting\nstyle signals, overlook this collateral impact and frequently contaminate the\nmodel's core truthfulness representations, resulting in reduced answer\ncorrectness. We term this phenomenon stylization-induced truthfulness collapse.\nWe attribute this issue to latent coupling between style and truth directions\nin certain key attention heads, and propose StyliTruth, a mechanism that\npreserves stylization while keeping truthfulness intact. StyliTruth separates\nthe style-relevant and truth-relevant subspaces in the model's representation\nspace via an orthogonal deflation process. This decomposition enables\nindependent control of style and truth in their own subspaces, minimizing\ninterference. By designing adaptive, token-level steering vectors within each\nsubspace, we dynamically and precisely control the generation process to\nmaintain both stylistic fidelity and truthfulness. We validate our method on\nmultiple styles and languages. Extensive experiments and analyses show that\nStyliTruth significantly reduces stylization-induced truthfulness collapse and\noutperforms existing inference-time intervention methods in balancing style\nadherence with truthfulness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faStyliTruth\u673a\u5236\uff0c\u901a\u8fc7\u5206\u79bb\u548c\u72ec\u7acb\u63a7\u5236\u8bed\u8a00\u6a21\u578b\u8868\u5f81\u7a7a\u95f4\u7684\u98ce\u683c\u4e0e\u771f\u5b9e\u6027\u5b50\u7a7a\u95f4\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u98ce\u683c\u591a\u6837\u6027\u540c\u65f6\u51cf\u5c11\u4e86\u5bf9\u7b54\u6848\u771f\u5b9e\u6027\u7684\u635f\u5bb3\uff0c\u5b9e\u9a8c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5728\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u5177\u6709\u7279\u5b9a\u98ce\u683c\u7684\u56de\u590d\u65f6\uff0c\u73b0\u6709\u7684\u8868\u793a\u7f16\u8f91\u65b9\u6cd5\u5e38\u5e38\u5bfc\u81f4\u98ce\u683c\u548c\u771f\u5b9e\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u5373\u98ce\u683c\u8d8a\u5f3a\u70c8\uff0c\u56de\u7b54\u7684\u6b63\u786e\u6027\uff08\u771f\u5b9e\u6027\uff09\u5c31\u8d8a\u5bb9\u6613\u53d7\u635f\u3002\u8be5\u95ee\u9898\u88ab\u79f0\u4e3a\u201c\u98ce\u683c\u5316\u5f15\u53d1\u7684\u771f\u5b9e\u6027\u5d29\u6e83\u201d\u3002\u4f5c\u8005\u53d1\u73b0\u8fd9\u662f\u7531\u4e8e\u98ce\u683c\u548c\u771f\u5b9e\u76f8\u5173\u8868\u5f81\u5728\u90e8\u5206\u5173\u952e\u6ce8\u610f\u529b\u5934\u4e0a\u6f5c\u5728\u8026\u5408\u9020\u6210\u7684\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aStyliTruth\u7684\u65b0\u673a\u5236\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6b63\u4ea4\u6d88\u5143\uff08orthogonal deflation\uff09\u8fc7\u7a0b\uff0c\u5c06\u6a21\u578b\u8868\u5f81\u7a7a\u95f4\u4e2d\u7684\u98ce\u683c\u76f8\u5173\u548c\u771f\u5b9e\u6027\u76f8\u5173\u5b50\u7a7a\u95f4\u5206\u79bb\uff0c\u5b9e\u73b0\u4e24\u8005\u7684\u72ec\u7acb\u63a7\u5236\u3002\u540c\u65f6\uff0c\u5728\u6bcf\u4e2a\u5b50\u7a7a\u95f4\u5185\u8bbe\u8ba1\u4e86\u81ea\u9002\u5e94\u3001\u9488\u5bf9Token\u7ea7\u522b\u7684\u5f15\u5bfc\u5411\u91cf\uff0c\u4ece\u800c\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u52a8\u6001\u7cbe\u51c6\u5730\u63a7\u5236\u98ce\u683c\u548c\u771f\u5b9e\u6027\uff0c\u6700\u5927\u9650\u5ea6\u51cf\u5c11\u76f8\u4e92\u5e72\u6270\u3002", "result": "\u5728\u591a\u79cd\u98ce\u683c\u548c\u8bed\u8a00\u4e0b\u8fdb\u884c\u7684\u5b9e\u9a8c\u548c\u5206\u6790\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u98ce\u683c\u5316\u5f15\u53d1\u7684\u771f\u5b9e\u6027\u5d29\u6e83\uff08\u5373\u63d0\u5347\u7b54\u6848\u7684\u771f\u5b9e\u6027\uff09\uff0c\u5e76\u5728\u98ce\u683c\u4fdd\u6301\u548c\u771f\u5b9e\u6027\u5e73\u8861\u65b9\u9762\u6574\u4f53\u4f18\u4e8e\u73b0\u6709\u7684\u63a8\u7406\u671f\u5e72\u9884\u65b9\u6cd5\u3002", "conclusion": "StyliTruth\u673a\u5236\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u98ce\u683c\u4e0e\u771f\u5b9e\u6027\u7684\u534f\u540c\u63a7\u5236\uff0c\u663e\u8457\u51cf\u5f31\u4e86\u98ce\u683c\u5316\u5e26\u6765\u7684\u771f\u5b9e\u6027\u635f\u5931\uff0c\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7684\u53ef\u63a7\u6027\u548c\u53ef\u9760\u6027\u63d0\u5347\u6709\u8f83\u5927\u610f\u4e49\u3002"}}
{"id": "2508.04531", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04531", "abs": "https://arxiv.org/abs/2508.04531", "authors": ["Zhuang Chen", "Guanqun Bi", "Wen Zhang", "Jiawei Hu", "Aoyun Wang", "Xiyao Xiao", "Kun Feng", "Minlie Huang"], "title": "Unveiling the Landscape of Clinical Depression Assessment: From Behavioral Signatures to Psychiatric Reasoning", "comment": null, "summary": "Depression is a widespread mental disorder that affects millions worldwide.\nWhile automated depression assessment shows promise, most studies rely on\nlimited or non-clinically validated data, and often prioritize complex model\ndesign over real-world effectiveness. In this paper, we aim to unveil the\nlandscape of clinical depression assessment. We introduce C-MIND, a clinical\nneuropsychiatric multimodal diagnosis dataset collected over two years from\nreal hospital visits. Each participant completes three structured psychiatric\ntasks and receives a final diagnosis from expert clinicians, with informative\naudio, video, transcript, and functional near-infrared spectroscopy (fNIRS)\nsignals recorded. Using C-MIND, we first analyze behavioral signatures relevant\nto diagnosis. We train a range of classical models to quantify how different\ntasks and modalities contribute to diagnostic performance, and dissect the\neffectiveness of their combinations. We then explore whether LLMs can perform\npsychiatric reasoning like clinicians and identify their clear limitations in\nrealistic clinical settings. In response, we propose to guide the reasoning\nprocess with clinical expertise and consistently improves LLM diagnostic\nperformance by up to 10% in Macro-F1 score. We aim to build an infrastructure\nfor clinical depression assessment from both data and algorithmic perspectives,\nenabling C-MIND to facilitate grounded and reliable research for mental\nhealthcare.", "AI": {"tldr": "\u4f5c\u8005\u53d1\u5e03\u4e86\u4e3a\u671f\u4e24\u5e74\u7684\u771f\u5b9e\u4e34\u5e8a\u591a\u6a21\u6001\u6570\u636e\u96c6C-MIND\uff0c\u5206\u6790\u4e0d\u540c\u6a21\u6001\u5bf9\u6291\u90c1\u75c7\u8bca\u65ad\u7684\u8d21\u732e\uff0c\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5355\u72ec\u6548\u679c\u6709\u9650\uff0c\u5f15\u5165\u4e34\u5e8a\u77e5\u8bc6\u540e\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002\u8be5\u5de5\u4f5c\u63a8\u52a8\u4e86\u771f\u5b9e\u4e16\u754c\u7684\u667a\u80fd\u6291\u90c1\u75c7\u8bc4\u4f30\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u5316\u6291\u90c1\u75c7\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u4e8e\u6709\u9650\u4e14\u975e\u4e34\u5e8a\u9a8c\u8bc1\u6570\u636e\uff0c\u6a21\u578b\u590d\u6742\u6027\u88ab\u4f18\u5148\u8003\u8651\u5374\u5ffd\u7565\u4e86\u771f\u5b9e\u4e16\u754c\u6548\u7528\uff0c\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u4e34\u5e8a\u6570\u636e\u548c\u6709\u6548\u7b97\u6cd5\u652f\u6491\u5b9e\u9645\u8bca\u65ad\u3002", "method": "\u63d0\u51fa\u5e76\u53d1\u5e03C-MIND\u6570\u636e\u96c6\u2014\u2014\u4e3a\u671f\u4e24\u5e74\u3001\u57fa\u4e8e\u771f\u5b9e\u533b\u9662\u8bbf\u95ee\u7684\u4e34\u5e8a\u795e\u7ecf\u7cbe\u795e\u75be\u75c5\u591a\u6a21\u6001\u8bca\u65ad\u6570\u636e\u96c6\uff0c\u5305\u62ec\u97f3\u9891\u3001\u89c6\u9891\u3001\u8f6c\u5f55\u548c\u8fd1\u7ea2\u5916\u5149\u8c31\u4fe1\u53f7\u3002\u901a\u8fc7\u6570\u636e\u96c6\uff0c\u5206\u6790\u8bca\u65ad\u76f8\u5173\u884c\u4e3a\u7279\u5f81\uff0c\u8bad\u7ec3\u591a\u79cd\u4f20\u7edf\u6a21\u578b\u8bc4\u4f30\u4e0d\u540c\u4efb\u52a1\u548c\u6a21\u6001\u5bf9\u8bca\u65ad\u6548\u679c\u7684\u8d21\u732e\uff0c\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u662f\u5426\u80fd\u5177\u5907\u7c7b\u4f3c\u4e34\u5e8a\u533b\u751f\u7684\u7cbe\u795e\u79d1\u5224\u65ad\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u5f15\u5165\u4e34\u5e8a\u77e5\u8bc6\u5f15\u5bfc\u63d0\u95ee\u4ee5\u63d0\u5347LLM\u5728\u8bca\u65ad\u4e2d\u7684\u8868\u73b0\u3002", "result": "C-MIND\u6570\u636e\u96c6\u4e3a\u6291\u90c1\u75c7\u8bc4\u4f30\u63d0\u4f9b\u4e86\u771f\u5b9e\u53ef\u9760\u7684\u4e34\u5e8a\u57fa\u7840\u3002\u5b9e\u9a8c\u4e2d\u53d1\u73b0\uff0c\u5355\u4e00\u6216\u7ec4\u5408\u6a21\u6001\u5bf9\u8bca\u65ad\u6548\u679c\u5b58\u5728\u4e0d\u540c\u5f71\u54cd\uff0c\u5355\u9760LLM\u5b58\u5728\u660e\u663e\u5c40\u9650\uff1b\u901a\u8fc7\u5f15\u5165\u4e34\u5e8a\u4e13\u5bb6\u77e5\u8bc6\u53ef\u5c06LLM\u8bca\u65ad\u7684Macro-F1\u5206\u6570\u63d0\u5347\u6700\u9ad810%\u3002", "conclusion": "C-MIND\u6570\u636e\u96c6\u548c\u914d\u5957\u65b9\u6cd5\u4e3a\u6291\u90c1\u75c7\u81ea\u52a8\u8bca\u65ad\u9886\u57df\u63d0\u4f9b\u4e86\u5173\u952e\u57fa\u7840\u5efa\u8bbe\uff0c\u4e3a\u4eca\u540e\u4ee5\u4e34\u5e8a\u4e3a\u672c\u7684\u9ad8\u53ef\u4fe1\u5ea6\u667a\u80fd\u8bca\u65ad\u65b9\u6cd5\u63a2\u7d22\u63d0\u4f9b\u4e86\u6570\u636e\u4e0e\u7b97\u6cd5\u652f\u6301\u3002"}}
{"id": "2508.04575", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.04575", "abs": "https://arxiv.org/abs/2508.04575", "authors": ["Nuo Chen", "Yicheng Tong", "Jiaying Wu", "Minh Duc Duong", "Qian Wang", "Qingyun Zou", "Bryan Hooi", "Bingsheng He"], "title": "Beyond Brainstorming: What Drives High-Quality Scientific Ideas? Lessons from Multi-Agent Collaboration", "comment": "Preprint", "summary": "While AI agents show potential in scientific ideation, most existing\nframeworks rely on single-agent refinement, limiting creativity due to bounded\nknowledge and perspective. Inspired by real-world research dynamics, this paper\ninvestigates whether structured multi-agent discussions can surpass solitary\nideation. We propose a cooperative multi-agent framework for generating\nresearch proposals and systematically compare configurations including group\nsize, leaderled versus leaderless structures, and team compositions varying in\ninterdisciplinarity and seniority. To assess idea quality, we employ a\ncomprehensive protocol with agent-based scoring and human review across\ndimensions such as novelty, strategic vision, and integration depth. Our\nresults show that multi-agent discussions substantially outperform solitary\nbaselines. A designated leader acts as a catalyst, transforming discussion into\nmore integrated and visionary proposals. Notably, we find that cognitive\ndiversity is a primary driver of quality, yet expertise is a non-negotiable\nprerequisite, as teams lacking a foundation of senior knowledge fail to surpass\neven a single competent agent. These findings offer actionable insights for\ndesigning collaborative AI ideation systems and shed light on how team\nstructure influences creative outcomes.", "AI": {"tldr": "\u591a\u667a\u80fd\u4f53\u5408\u4f5c\u6bd4\u5355\u667a\u80fd\u4f53\u66f4\u80fd\u6fc0\u53d1\u79d1\u7814\u521b\u610f\uff0c\u524d\u63d0\u662f\u56e2\u961f\u8981\u6709\u8db3\u591f\u7684\u77e5\u8bc6\u6df1\u5ea6\u548c\u591a\u6837\u6027\uff0c\u5e26\u6709\u9886\u5bfc\u7684\u7ed3\u6784\u6700\u4f18\u3002\u8fd9\u5bf9AI\u534f\u540c\u521b\u65b0\u7cfb\u7edf\u8bbe\u8ba1\u6709\u542f\u793a\u610f\u4e49\u3002", "motivation": "\u73b0\u6709AI\u79d1\u7814\u8f85\u52a9\u7cfb\u7edf\u591a\u4ee5\u5355\u667a\u80fd\u4f53\u4e3a\u4e3b\uff0c\u77e5\u8bc6\u548c\u89c6\u89d2\u6709\u9650\uff0c\u5bfc\u81f4\u521b\u65b0\u6027\u4e0d\u8db3\u3002\u73b0\u5b9e\u79d1\u7814\u5f80\u5f80\u901a\u8fc7\u591a\u4e3b\u4f53\u5408\u4f5c\u6fc0\u53d1\u66f4\u591a\u60f3\u6cd5\uff0c\u56e0\u6b64\u4f5c\u8005\u5e0c\u671b\u63a2\u7d22\u591a\u667a\u80fd\u4f53\u7ed3\u6784\u662f\u5426\u80fd\u63d0\u5347\u79d1\u7814\u65b9\u6848\u7684\u521b\u610f\u548c\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5408\u4f5c\u578b\u591a\u667a\u80fd\u4f53\u79d1\u7814\u63d0\u6848\u751f\u6210\u6846\u67b6\uff0c\u7cfb\u7edf\u6027\u5bf9\u6bd4\u4e0d\u540c\u56e2\u961f\u914d\u7f6e\uff08\u7ec4\u5458\u6570\u91cf\u3001\u6709\u65e0\u9886\u5bfc\u3001\u56e2\u961f\u8de8\u5b66\u79d1\u7a0b\u5ea6\u4e0e\u8d44\u5386\uff09\u3002\u91c7\u7528\u667a\u80fd\u4f53\u8bc4\u5206\u548c\u4eba\u5de5\u590d\u6838\u7b49\u7efc\u5408\u534f\u8bae\uff0c\u8bc4\u4f30\u65b9\u6848\u7684\u65b0\u9896\u6027\u3001\u6218\u7565\u89c6\u91ce\u548c\u6574\u5408\u6df1\u5ea6\u3002", "result": "\u591a\u667a\u80fd\u4f53\u8ba8\u8bba\u663e\u8457\u4f18\u4e8e\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\u3002\u8bbe\u5b9a\u56e2\u961f\u9886\u5bfc\u80fd\u5c06\u8ba8\u8bba\u9ad8\u6548\u8f6c\u6362\u6210\u66f4\u5177\u6574\u5408\u6027\u548c\u524d\u77bb\u6027\u7684\u63d0\u6848\u3002\u8ba4\u77e5\u591a\u6837\u6027\u662f\u8d28\u91cf\u63d0\u5347\u7684\u5173\u952e\uff0c\u4f46\u662f\u56e2\u961f\u5fc5\u987b\u5305\u542b\u6709\u7ecf\u9a8c\u7684\u6210\u5458\uff0c\u5426\u5219\u6574\u4f53\u6c34\u5e73\u4e0d\u80fd\u8d85\u8fc7\u4e00\u4e2a\u5355\u4e00\u7684\u8d44\u6df1\u667a\u80fd\u4f53\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u5408\u4f5c\u80fd\u63d0\u9ad8\u79d1\u7814\u65b9\u6848\u521b\u65b0\u6027\uff0c\u4f46\u9700\u6ce8\u91cd\u56e2\u961f\u6210\u5458\u7684\u4e13\u4e1a\u6df1\u5ea6\u548c\u8ba4\u77e5\u591a\u6837\u6027\u3002\u9886\u5bfc\u4f5c\u7528\u548c\u56e2\u961f\u7ed3\u6784\u5bf9\u521b\u9020\u529b\u7ed3\u679c\u6709\u91cd\u8981\u5f71\u54cd\u3002\u8be5\u7814\u7a76\u4e3aAI\u534f\u540c\u521b\u65b0\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u4f9d\u636e\u3002"}}
{"id": "2508.04581", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04581", "abs": "https://arxiv.org/abs/2508.04581", "authors": ["Magauiya Zhussip", "Dmitriy Shopkhoev", "Ammar Ali", "Stamatios Lefkimmiatis"], "title": "Share Your Attention: Transformer Weight Sharing via Matrix-based Dictionary Learning", "comment": null, "summary": "Large language models (LLMs) have revolutionized AI applications, yet their\nhigh computational and memory demands hinder their widespread deployment.\nExisting compression techniques focus on intra-block optimizations (e.g.\nlow-rank approximation, attention head pruning), while the repetitive layered\nstructure of transformers implies significant inter-block redundancy - a\ndimension largely unexplored beyond key-value (KV) caching. Inspired by\ndictionary learning in CNNs, we propose a framework for structured weight\nsharing across transformer layers. Our approach decomposes attention projection\nmatrices into shared dictionary atoms, reducing the attention module's\nparameters by 66.7% while achieving on-par performance. Unlike complex methods\nrequiring distillation or architectural changes, MASA (Matrix Atom Sharing in\nAttention) operates as a drop-in replacement - trained with standard optimizers\n- and represents each layer's weights as linear combinations of shared matrix\natoms. Experiments across scales (100M-700M parameters) show that MASA achieves\nbetter benchmark accuracy and perplexity than grouped-query attention (GQA),\nlow-rank baselines and recently proposed Repeat-all-over/Sequential sharing at\ncomparable parameter budgets. Ablation studies confirm robustness to the\ndictionary size and the efficacy of shared representations in capturing\ncross-layer statistical regularities. Extending to Vision Transformers (ViT),\nMASA matches performance metrics on image classification and detection tasks\nwith 66.7% fewer attention parameters. By combining dictionary learning\nstrategies with transformer efficiency, MASA offers a scalable blueprint for\nparameter-efficient models without sacrificing performance. Finally, we\ninvestigate the possibility of employing MASA on pretrained LLMs to reduce\ntheir number of parameters without experiencing any significant drop in their\nperformance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMASA\u65b9\u6cd5\uff0c\u901a\u8fc7\u8de8transformer\u5c42\u5171\u4eabattention\u6a21\u5757\u6743\u91cd\uff0c\u5b9e\u73b066.7%\u53c2\u6570\u538b\u7f29\uff0c\u6027\u80fd\u57fa\u672c\u65e0\u635f\uff0c\u9002\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u53ca\u89c6\u89c9\u4efb\u52a1\u3002\u652f\u6301\u76f4\u63a5\u66ff\u6362\u73b0\u6709\u7ed3\u6784\u3001\u6613\u4e8e\u8bad\u7ec3\uff0c\u662f\u9ad8\u6548\u53c2\u6570\u5171\u4eab\u7684\u6709\u529b\u65b9\u6848\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u9ad8\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u90e8\u7f72\u3002\u76ee\u524d\u591a\u6570\u7684\u6a21\u578b\u538b\u7f29\u65b9\u6cd5\u53ea\u5173\u6ce8transformer\u5185\u90e8\u7684\u5355\u5c42\u4f18\u5316\uff0c\u4f46transformer\u5c42\u4e4b\u95f4\u5b58\u5728\u660e\u663e\u7684\u5197\u4f59\uff0c\u8fd9\u4e00\u65b9\u5411\u76ee\u524d\u63a2\u7d22\u8f83\u5c11\u3002\u672c\u6587\u4f5c\u8005\u53d7\u5230CNN\u4e2d\u5b57\u5178\u5b66\u4e60\u601d\u60f3\u7684\u542f\u53d1\uff0c\u8bd5\u56fe\u901a\u8fc7\u8de8\u5c42\u6743\u91cd\u5171\u4eab\u8fdb\u4e00\u6b65\u63d0\u5347\u538b\u7f29\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u7684\u8de8\u5c42\u6743\u91cd\u5171\u4eab\u65b9\u6cd5\uff0c\u79f0\u4e3aMASA\uff08Matrix Atom Sharing in Attention\uff09\u3002\u8be5\u65b9\u6cd5\u5c06attention\u6295\u5f71\u77e9\u9635\u5206\u89e3\u4e3a\u5171\u4eab\u7684\u201c\u5b57\u5178\u57fa\u5143\u201d\uff0c\u6bcf\u5c42\u7684\u6743\u91cd\u7531\u8fd9\u4e9b\u5171\u4eab\u57fa\u5143\u7ebf\u6027\u7ec4\u5408\u800c\u6210\uff0c\u65e0\u9700\u590d\u6742\u84b8\u998f\u6216\u6a21\u578b\u7ed3\u6784\u66f4\u6539\uff0c\u53ef\u76f4\u63a5\u4f5c\u4e3a\u73b0\u6709attention\u6a21\u5757\u7684\u66ff\u4ee3\uff0c\u5e76\u53ef\u7528\u6807\u51c6\u4f18\u5316\u5668\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "MASA\u5728\u591a\u4e2a\u6a21\u578b\u89c4\u6a21\uff081\u4ebf~7\u4ebf\u53c2\u6570\uff09\u4e0a\u6d4b\u8bd5\uff0c\u4e0e\u4e3b\u6d41\u65b9\u6cd5\uff08grouped-query attention\u3001\u4f4e\u79e9\u5206\u89e3\u7b49\uff09\u76f8\u6bd4\uff0c\u5728\u76f8\u4f3c\u53c2\u6570\u89c4\u6a21\u4e0b\u83b7\u5f97\u66f4\u4f18\u7684\u51c6\u786e\u6027\u548c\u56f0\u60d1\u5ea6\u3002\u6b64\u5916\uff0c\u5728\u89c6\u89c9Transformer\uff08ViT\uff09\u4e0a\uff0cMASA\u5728\u51cf\u5c1166.7%\u6ce8\u610f\u529b\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u7ef4\u6301\u5206\u7c7b\u4e0e\u68c0\u6d4b\u4efb\u52a1\u7684\u6027\u80fd\u3002\u6d88\u878d\u5b9e\u9a8c\u663e\u793aMASA\u5bf9\u5b57\u5178\u5927\u5c0f\u7684\u9c81\u68d2\u6027\uff0c\u4ee5\u53ca\u5176\u5728\u6355\u6349\u8de8\u5c42\u7edf\u8ba1\u89c4\u5f8b\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "MASA\u4e3atransformer\u53c2\u6570\u9ad8\u6548\u538b\u7f29\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u9700\u727a\u7272\u6a21\u578b\u6027\u80fd\u3002\u5e76\u4e14\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5728\u9884\u8bad\u7ec3\u7684LLMs\u4e0a\u5e94\u7528\uff0c\u5b9e\u73b0\u53c2\u6570\u51cf\u5c11\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u4e0d\u964d\u3002"}}
{"id": "2508.04604", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.04604", "abs": "https://arxiv.org/abs/2508.04604", "authors": ["Zhejun Zhao", "Yuehu Dong", "Alley Liu", "Lixue Zheng", "Pingsheng Liu", "Dongdong Shen", "Long Xia", "Jiashu Zhao", "Dawei Yin"], "title": "TURA: Tool-Augmented Unified Retrieval Agent for AI Search", "comment": null, "summary": "The advent of Large Language Models (LLMs) is transforming search engines\ninto conversational AI search products, primarily using Retrieval-Augmented\nGeneration (RAG) on web corpora. However, this paradigm has significant\nindustrial limitations. Traditional RAG approaches struggle with real-time\nneeds and structured queries that require accessing dynamically generated\ncontent like ticket availability or inventory. Limited to indexing static\npages, search engines cannot perform the interactive queries needed for such\ntime-sensitive data. Academic research has focused on optimizing RAG for static\ncontent, overlooking complex intents and the need for dynamic sources like\ndatabases and real-time APIs. To bridge this gap, we introduce TURA\n(Tool-Augmented Unified Retrieval Agent for AI Search), a novel three-stage\nframework that combines RAG with agentic tool-use to access both static content\nand dynamic, real-time information. TURA has three key components: an\nIntent-Aware Retrieval module to decompose queries and retrieve information\nsources encapsulated as Model Context Protocol (MCP) Servers, a DAG-based Task\nPlanner that models task dependencies as a Directed Acyclic Graph (DAG) for\noptimal parallel execution, and a lightweight Distilled Agent Executor for\nefficient tool calling. TURA is the first architecture to systematically bridge\nthe gap between static RAG and dynamic information sources for a world-class AI\nsearch product. Serving tens of millions of users, it leverages an agentic\nframework to deliver robust, real-time answers while meeting the low-latency\ndemands of a large-scale industrial system.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86TURA\u6846\u67b6\uff0c\u521b\u65b0\u6027\u5730\u5c06RAG\u4e0e\u5de5\u5177\u8c03\u7528\u673a\u5236\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u9759\u6001\u4e0e\u52a8\u6001\u4fe1\u606f\u6e90\u7684\u7edf\u4e00\u68c0\u7d22\u548c\u5904\u7406\uff0c\u4ece\u800c\u5927\u5e45\u63d0\u5347AI\u641c\u7d22\u5f15\u64ce\u7684\u5b9e\u65f6\u6027\u3001\u590d\u6742\u67e5\u8be2\u5904\u7406\u548c\u5de5\u4e1a\u53ef\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eRAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09\u7684LLM\u641c\u7d22\u5f15\u64ce\u5728\u5904\u7406\u52a8\u6001\u3001\u5b9e\u65f6\u548c\u7ed3\u6784\u5316\u590d\u6742\u67e5\u8be2\u65f6\u5b58\u5728\u5f88\u5927\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5de5\u4e1a\u754c\u5bf9\u4e8e\u5b9e\u65f6\u6570\u636e\uff08\u5982\u5e93\u5b58\u3001\u7968\u52a1\u7b49\uff09\u7684\u9700\u6c42\u3002\u5b66\u672f\u754c\u4e5f\u5927\u591a\u805a\u7126\u4e8e\u9759\u6001\u5185\u5bb9\u7684\u4f18\u5316\uff0c\u5ffd\u89c6\u4e86\u52a8\u6001\u6570\u636e\u548c\u590d\u6742\u610f\u56fe\u7684\u5904\u7406\u9700\u6c42\u3002", "method": "\u63d0\u51faTURA\uff08Tool-Augmented Unified Retrieval Agent\uff09\uff0c\u4e00\u4e2a\u96c6\u6210\u4e09\u5927\u7ec4\u4ef6\u7684\u65b0\u578b\u4e09\u9636\u6bb5\u6846\u67b6\uff1a(1) \u610f\u56fe\u611f\u77e5\u68c0\u7d22\u6a21\u5757\uff0c\u80fd\u591f\u628a\u590d\u6742\u67e5\u8be2\u62c6\u5206\u5e76\u5c06\u4fe1\u606f\u6e90\u5c01\u88c5\u4e3aMCP\u670d\u52a1\u5668\uff1b(2) \u57fa\u4e8e\u6709\u5411\u65e0\u73af\u56fe\u7684\u4efb\u52a1\u89c4\u5212\u5668\uff0c\u5b9e\u73b0\u4efb\u52a1\u4f9d\u8d56\u7684\u6700\u4f18\u5e76\u884c\u5904\u7406\uff1b(3) \u8f7b\u91cf\u7ea7\u7684\u84b8\u998f\u4ee3\u7406\u6267\u884c\u5668\uff0c\u5b9e\u73b0\u9ad8\u6548\u5de5\u5177\u8c03\u7528\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u4f20\u7edfRAG\u4e0eagentic\u5de5\u5177\u8c03\u7528\uff0c\u5bf9\u9759\u6001\u4e0e\u52a8\u6001\u4fe1\u606f\u6e90\u5747\u80fd\u68c0\u7d22\u548c\u8c03\u7528\u3002", "result": "TURA\u662f\u9996\u4e2a\u7cfb\u7edf\u6027\u6253\u901a\u9759\u6001RAG\u4e0e\u52a8\u6001\u4fe1\u606f\u6e90\u67b6\u6784\u7684\u5de5\u4e1a\u7ea7AI\u641c\u7d22\u65b9\u6848\uff0c\u5df2\u670d\u52a1\u5343\u4e07\u7ea7\u7528\u6237\uff0c\u5728\u6ee1\u8db3\u5927\u89c4\u6a21\u7cfb\u7edf\u4f4e\u5ef6\u8fdf\u9700\u6c42\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b9e\u65f6\u548c\u590d\u6742\u67e5\u8be2\u7684\u5904\u7406\u80fd\u529b\u3002", "conclusion": "TURA\u4e3a\u5927\u89c4\u6a21AI\u641c\u7d22\u4ea7\u54c1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u901a\u7528\u3001\u53ef\u6269\u5c55\u7684\u68c0\u7d22\u589e\u5f3a\u65b9\u6848\uff0c\u5f25\u8865\u4e86\u4f20\u7edfRAG\u5728\u5b9e\u65f6\u548c\u52a8\u6001\u6570\u636e\u5904\u7406\u4e0a\u7684\u4e0d\u8db3\uff0c\u63a8\u52a8\u641c\u7d22\u5f15\u64ce\u5411\u667a\u80fd\u95ee\u7b54\u548c\u52a8\u6001\u54cd\u5e94\u80fd\u529b\u7684\u8fdb\u5316\u3002"}}
{"id": "2508.04623", "categories": ["cs.CL", "cs.IR", "68T50 % Natural language processing (in Computer Science)", "I.2.7; H.2.3"], "pdf": "https://arxiv.org/pdf/2508.04623", "abs": "https://arxiv.org/abs/2508.04623", "authors": ["Chirag Seth", "Utkarsh Singh"], "title": "Lightweight Transformers for Zero-Shot and Fine-Tuned Text-to-SQL Generation Using Spider", "comment": null, "summary": "Text-to-SQL translation enables non-expert users to query relational\ndatabases using natural language, with applications in education and business\nintelligence. This study evaluates three lightweight transformer models -\nT5-Small, BART-Small, and GPT-2 - on the Spider dataset, focusing on\nlow-resource settings. We developed a reusable, model-agnostic pipeline that\ntailors schema formatting to each model's architecture, training them across\n1000 to 5000 iterations and evaluating on 1000 test samples using Logical Form\nAccuracy (LFAcc), BLEU, and Exact Match (EM) metrics. Fine-tuned T5-Small\nachieves the highest LFAcc (27.8%), outperforming BART-Small (23.98%) and GPT-2\n(20.1%), highlighting encoder-decoder models' superiority in schema-aware SQL\ngeneration. Despite resource constraints limiting performance, our pipeline's\nmodularity supports future enhancements, such as advanced schema linking or\nalternative base models. This work underscores the potential of compact\ntransformers for accessible text-to-SQL solutions in resource-scarce\nenvironments.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u4f4e\u8d44\u6e90\u73af\u5883\uff0c\u8bc4\u6d4b\u4e86\u4e09\u79cd\u8f7b\u91cf\u7ea7Transformer\u6a21\u578b\u5728Text-to-SQL\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0cT5-Small\u6548\u679c\u6700\u4f73\uff0c\u663e\u793a\u7d27\u51d1Transformer\u5728\u8d44\u6e90\u6709\u9650\u573a\u666f\u4e0b\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u53ef\u590d\u7528\u7684\u5904\u7406\u6d41\u7a0b\u4e3a\u540e\u7eed\u4f18\u5316\u63d0\u4f9b\u652f\u6301\u3002", "motivation": "\u8ba9\u975e\u4e13\u5bb6\u7528\u6237\u80fd\u591f\u7528\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u5173\u7cfb\u578b\u6570\u636e\u5e93\uff0c\u63d0\u5347\u6559\u80b2\u548c\u5546\u4e1a\u667a\u80fd\u9886\u57df\u7684\u6570\u636e\u8bbf\u95ee\u4fbf\u6377\u6027\u3002\u7279\u522b\u5173\u6ce8\u5728\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\uff0c\u5982\u4f55\u5229\u7528\u8f7b\u91cf\u7ea7Transformer\u6a21\u578b\u5b9e\u73b0Text-to-SQL\u3002", "method": "\u8bc4\u4f30\u4e86\u4e09\u79cd\u8f7b\u91cf\u7ea7Transformer\u6a21\u578b\uff08T5-Small\u3001BART-Small\u3001GPT-2\uff09\u5728Spider\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u5f00\u53d1\u4e86\u53ef\u590d\u7528\u3001\u6a21\u578b\u65e0\u5173\u7684\u5904\u7406\u6d41\u7a0b\uff0c\u9488\u5bf9\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u5b9a\u5236schema\u683c\u5f0f\u3002\u8bad\u7ec3\u8fed\u4ee3\u6b21\u6570\u4e3a1000\u52305000\u6b21\uff0c\u4f7f\u7528LFAcc\u3001BLEU\u548cExact Match\u6307\u6807\uff0c\u57281000\u4e2a\u6d4b\u8bd5\u6837\u672c\u4e0a\u8bc4\u4f30\u7ed3\u679c\u3002", "result": "T5-Small\u6a21\u578b\u5fae\u8c03\u540e\u5728LFAcc\u4e0a\u53d6\u5f97\u6700\u9ad8\u5206\uff0827.8%\uff09\uff0c\u4f18\u4e8eBART-Small\uff0823.98%\uff09\u548cGPT-2\uff0820.1%\uff09\uff0c\u8bf4\u660e\u7f16\u7801\u5668-\u89e3\u7801\u5668\u7ed3\u6784\u5728\u6a21\u5f0f\u611f\u77e5SQL\u751f\u6210\u4e2d\u6709\u4f18\u52bf\u3002\u867d\u7136\u8d44\u6e90\u53d7\u9650\u5f71\u54cd\u4e86\u603b\u4f53\u6027\u80fd\uff0c\u4f46\u63d0\u51fa\u7684pipeline\u5177\u5907\u826f\u597d\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u7d27\u51d1\u578bTransformer\u5728\u8d44\u6e90\u7a00\u7f3a\u73af\u5883\u4e0b\uff0c\u4e3a\u81ea\u7136\u8bed\u8a00\u5230SQL\u7684\u8f6c\u6362\u63d0\u4f9b\u4e86\u6709\u6548\u548c\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e3a\u672a\u6765\u5f15\u5165\u66f4\u590d\u6742schema\u8054\u52a8\u6216\u4e0d\u540c\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2508.04626", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04626", "abs": "https://arxiv.org/abs/2508.04626", "authors": ["Feifan Song", "Bofei Gao", "Yifan Song", "Yi Liu", "Weimin Xiong", "Yuyang Song", "Tianyu Liu", "Guoyin Wang", "Houfeng Wang"], "title": "P-Aligner: Enabling Pre-Alignment of Language Models via Principled Instruction Synthesis", "comment": null, "summary": "Large Language Models (LLMs) are expected to produce safe, helpful, and\nhonest content during interaction with human users, but they frequently fail to\nalign with such values when given flawed instructions, e.g., missing context,\nambiguous directives, or inappropriate tone, leaving substantial room for\nimprovement along multiple dimensions. A cost-effective yet high-impact way is\nto pre-align instructions before the model begins decoding. Existing approaches\neither rely on prohibitive test-time search costs or end-to-end model rewrite,\nwhich is powered by a customized training corpus with unclear objectives. In\nthis work, we demonstrate that the goal of efficient and effective preference\nalignment can be achieved by P-Aligner, a lightweight module generating\ninstructions that preserve the original intents while being expressed in a more\nhuman-preferred form. P-Aligner is trained on UltraPrompt, a new dataset\nsynthesized via a proposed principle-guided pipeline using Monte-Carlo Tree\nSearch, which systematically explores the space of candidate instructions that\nare closely tied to human preference. Experiments across different methods show\nthat P-Aligner generally outperforms strong baselines across various models and\nbenchmarks, including average win-rate gains of 28.35% and 8.69% on GPT-4-turbo\nand Gemma-2-SimPO, respectively. Further analyses validate its effectiveness\nand efficiency through multiple perspectives, including data quality, search\nstrategies, iterative deployment, and time overhead.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faP-Aligner\u6a21\u5757\uff0c\u901a\u8fc7\u9ad8\u8d28\u91cf\u7684\u5408\u6210\u6570\u636e\u96c6UltraPrompt\u8f7b\u91cf\u9884\u5bf9\u9f50\u6307\u4ee4\uff0c\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u591a\u7ef4\u8868\u73b0\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u7b97\u6cd5\u5e76\u517c\u5177\u6548\u7387\u4e0e\u5b9e\u7528\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7ecf\u5e38\u56e0\u63a5\u53d7\u4e0d\u5b8c\u5584\u6307\u4ee4\uff08\u5982\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u3001\u6b67\u4e49\u3001\u4e0d\u9002\u5f53\u8bed\u6c14\uff09\u800c\u884c\u4e3a\u4e0d\u7406\u60f3\uff0c\u73b0\u6709\u4f18\u5316\u624b\u6bb5\u8981\u4e48\u63a8\u7406\u6210\u672c\u9ad8\uff0c\u8981\u4e48\u8bad\u7ec3\u76ee\u6807\u4e0d\u660e\u786e\uff0c\u6025\u9700\u66f4\u9ad8\u6548\u3001\u6210\u672c\u53cb\u597d\u7684\u6307\u4ee4\u5bf9\u9f50\u65b9\u6cd5\u3002", "method": "\u63d0\u51faP-Aligner\u6a21\u5757\uff0c\u8bad\u7ec3\u4e8e\u901a\u8fc7\u8499\u7279\u5361\u7f57\u6811\u641c\u7d22\uff08MCTS\uff09\u91c7\u96c6\u7684UltraPrompt\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u591a\u6a21\u578b\u4e0e\u591a\u57fa\u51c6\u7684\u5b9e\u9a8c\u8fdb\u884c\u8bc4\u4f30\uff0c\u5305\u62ec\u5bf9\u6bd4\u57fa\u7ebf\u3001\u6570\u636e\u8d28\u91cf\u3001\u641c\u7d22\u7b56\u7565\u4ee5\u53ca\u90e8\u7f72\u6548\u7387\u7b49\u5206\u6790\u3002", "result": "P-Aligner\u5728GPT-4-turbo\u548cGemma-2-SimPO\u6a21\u578b\u4e0a\u5206\u522b\u83b7\u5f9728.35%\u548c8.69%\u7684\u5e73\u5747\u80dc\u7387\u63d0\u5347\u3002\u591a\u9879\u5206\u6790\u8bc1\u660e\u5176\u5728\u6570\u636e\u3001\u7b56\u7565\u3001\u6548\u7387\u7b49\u65b9\u9762\u5747\u6709\u6548\u3002", "conclusion": "P-Aligner\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u8f7b\u91cf\u7684\u6a21\u5757\uff0c\u80fd\u591f\u5728LLM\u89e3\u7801\u524d\u5bf9\u6307\u4ee4\u8fdb\u884c\u9884\u5bf9\u9f50\uff0c\u5728\u63d0\u5347\u6a21\u578b\u5b89\u5168\u3001\u5e2e\u52a9\u6027\u4e0e\u8bda\u5b9e\u6027\u7b49\u591a\u7ef4\u8868\u73b0\u65b9\u9762\u6548\u679c\u663e\u8457\uff0c\u5e76\u4f18\u4e8e\u591a\u4e2a\u5f3a\u57fa\u7ebf\u3002"}}
{"id": "2508.04632", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04632", "abs": "https://arxiv.org/abs/2508.04632", "authors": ["Xu Guo", "Tianyi Liang", "Tong Jian", "Xiaogui Yang", "Ling-I Wu", "Chenhui Li", "Zhihui Lu", "Qipeng Guo", "Kai Chen"], "title": "IFDECORATOR: Wrapping Instruction Following Reinforcement Learning with Verifiable Rewards", "comment": "7 pages, 4 figures", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) improves instruction\nfollowing capabilities of large language models (LLMs), but suffers from\ntraining inefficiency due to inadequate difficulty assessment. Moreover, RLVR\nis prone to over-optimization, where LLMs exploit verification shortcuts\nwithout aligning to the actual intent of user instructions. We introduce\nInstruction Following Decorator (IFDecorator}, a framework that wraps RLVR\ntraining into a robust and sample-efficient pipeline. It consists of three\ncomponents: (1) a cooperative-adversarial data flywheel that co-evolves\ninstructions and hybrid verifications, generating progressively more\nchallenging instruction-verification pairs; (2) IntentCheck, a bypass module\nenforcing intent alignment; and (3) trip wires, a diagnostic mechanism that\ndetects reward hacking via trap instructions, which trigger and capture\nshortcut exploitation behaviors. Our Qwen2.5-32B-Instruct-IFDecorator achieves\n87.43% accuracy on IFEval, outperforming larger proprietary models such as\nGPT-4o. Additionally, we demonstrate substantial improvements on FollowBench\nwhile preserving general capabilities. Our trip wires show significant\nreductions in reward hacking rates. We will release models, code, and data for\nfuture research.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6307\u4ee4\u8ddf\u968f\u8bad\u7ec3\u6846\u67b6\u2014\u2014IFDecorator\uff0c\u6709\u6548\u89e3\u51b3\u4e86RLVR\u65b9\u6cd5\u4e2d\u7684\u6548\u7387\u4f4e\u548c\u5956\u52b1\u4f5c\u5f0a\u95ee\u9898\uff0c\u4f7f\u5927\u6a21\u578b\u66f4\u51c6\u786e\u7406\u89e3\u548c\u6267\u884c\u6307\u4ee4\uff0c\u6027\u80fd\u4f18\u4e8e\u540c\u7c7b\u6a21\u578b\u5e76\u51cf\u5c11\u4e86\u6295\u673a\u53d6\u5de7\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff08RLVR\uff09\u867d\u7136\u80fd\u63d0\u5347\u5927\u6a21\u578b\u7684\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\uff0c\u4f46\u5728\u8bad\u7ec3\u4e2d\u5b58\u5728\u6548\u7387\u4f4e\u548c\u5bb9\u6613\u5956\u52b1\u4f5c\u5f0a\uff08\u6a21\u578b\u5b66\u4f1a\u6295\u673a\u53d6\u5de7\u800c\u975e\u771f\u6b63\u7406\u89e3\u6307\u4ee4\u610f\u56fe\uff09\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Instruction Following Decorator\uff08IFDecorator\uff09\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u4e3b\u8981\u5305\u542b\uff1a1\uff09\u534f\u4f5c-\u5bf9\u6297\u6570\u636e\u751f\u6210\u673a\u5236\uff0c\u9010\u6b65\u751f\u6210\u66f4\u6709\u6311\u6218\u6027\u7684\u6307\u4ee4\u548c\u9a8c\u8bc1\u5bf9\uff1b2\uff09IntentCheck\u5b50\u6a21\u5757\uff0c\u5f3a\u5236\u6a21\u578b\u4e0e\u610f\u56fe\u5bf9\u9f50\uff0c\u9632\u6b62\u6a21\u578b\u504f\u79bb\u7528\u6237\u771f\u5b9e\u610f\u56fe\uff1b3\uff09trip wires\u673a\u5236\uff0c\u901a\u8fc7\u201c\u9677\u9631\u6307\u4ee4\u201d\u53ca\u65f6\u8bca\u65ad\u548c\u6355\u83b7\u6a21\u578b\u5956\u52b1\u6295\u673a\u884c\u4e3a\u3002", "result": "\u7ecf\u8fc7IFDecorator\u8bad\u7ec3\u7684Qwen2.5-32B-Instruct-IFDecorator\u6a21\u578b\uff0c\u5728IFEval\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u53d6\u5f9787.43%\u51c6\u786e\u7387\uff0c\u8d85\u8fc7\u4e86\u5305\u62ecGPT-4o\u7b49\u66f4\u5927\u578b\u7684\u4e13\u6709\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u5728FollowBench\u7b49\u4efb\u52a1\u4e0a\u4e5f\u6709\u660e\u663e\u63d0\u5347\uff0c\u5e76\u4e14\u6709\u6548\u964d\u4f4e\u4e86\u5956\u52b1\u6295\u673a/\u4f5c\u5f0a\u7387\u3002", "conclusion": "IFDecorator\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u6307\u4ee4\u8ddf\u968f\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u540c\u65f6\u663e\u8457\u6291\u5236\u4e86\u5956\u52b1\u4f5c\u5f0a\u884c\u4e3a\uff0c\u63d0\u9ad8\u4e86\u8bad\u7ec3\u7684\u6548\u7387\u4e0e\u6a21\u578b\u5b9e\u9645\u5bf9\u9f50\u80fd\u529b\u3002\u76f8\u5173\u6a21\u578b\u3001\u4ee3\u7801\u548c\u6570\u636e\u4e5f\u4f1a\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2508.04638", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04638", "abs": "https://arxiv.org/abs/2508.04638", "authors": ["Tanvi Dinkar", "Aiqi Jiang", "Simona Frenda", "Poppy Gerrard-Abbott", "Nancie Gunson", "Gavin Abercrombie", "Ioannis Konstas"], "title": "Can NLP Tackle Hate Speech in the Real World? Stakeholder-Informed Feedback and Survey on Counterspeech", "comment": null, "summary": "Counterspeech, i.e. the practice of responding to online hate speech, has\ngained traction in NLP as a promising intervention. While early work emphasised\ncollaboration with non-governmental organisation stakeholders, recent research\ntrends have shifted toward automated pipelines that reuse a small set of legacy\ndatasets, often without input from affected communities. This paper presents a\nsystematic review of 74 NLP studies on counterspeech, analysing the extent to\nwhich stakeholder participation influences dataset creation, model development,\nand evaluation. To complement this analysis, we conducted a participatory case\nstudy with five NGOs specialising in online Gender-Based Violence (oGBV),\nidentifying stakeholder-informed practices for counterspeech generation. Our\nfindings reveal a growing disconnect between current NLP research and the needs\nof communities most impacted by toxic online content. We conclude with concrete\nrecommendations for re-centring stakeholder expertise in counterspeech\nresearch.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6027\u5206\u6790\u4e8674\u7bc7\u53cd\u51fb\u4ec7\u6068\u8a00\u8bba\u7684NLP\u7814\u7a76\uff0c\u53d1\u73b0\u8fd1\u5e74\u6765\u7814\u7a76\u548c\u53d7\u5bb3\u793e\u7fa4\u9700\u6c42\u95f4\u65e5\u76ca\u8131\u8282\u3002\u901a\u8fc7\u4e0e5\u5bb6NGO\u7684\u5408\u4f5c\uff0c\u63d0\u51fa\u4e86\u91cd\u65b0\u805a\u7126\u5229\u76ca\u76f8\u5173\u65b9\u7684\u5efa\u8bae\uff0c\u5f3a\u8c03\u8ba9\u53d7\u5f71\u54cd\u793e\u7fa4\u53c2\u4e0e\u5bf9\u63d0\u9ad8\u7814\u7a76\u5b9e\u9645\u6548\u679c\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u53cd\u51fb\u4ec7\u6068\u8a00\u8bba\uff08Counterspeech\uff09\u5728NLP\u9886\u57df\u88ab\u89c6\u4e3a\u5e94\u5bf9\u7f51\u7edc\u4ec7\u6068\u7684\u91cd\u8981\u7b56\u7565\uff0c\u65e9\u671f\u591a\u548c\u975e\u653f\u5e9c\u7ec4\u7ec7\u5408\u4f5c\uff0c\u4f46\u8fd1\u671f\u7814\u7a76\u66f4\u504f\u5411\u81ea\u52a8\u5316\u6d41\u7a0b\u4e14\u7f3a\u4e4f\u53d7\u5f71\u54cd\u793e\u533a\u7684\u53c2\u4e0e\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76\u5229\u76ca\u76f8\u5173\u65b9\u53c2\u4e0e\u5bf9\u53cd\u51fb\u4ec7\u6068\u8a00\u8bba\u6570\u636e\u96c6\u548c\u6a21\u578b\u6784\u5efa\u7684\u5f71\u54cd\u3002", "method": "\u5bf974\u7bc7\u53cd\u51fb\u4ec7\u6068\u8a00\u8bba\u76f8\u5173\u7684NLP\u7814\u7a76\u8fdb\u884c\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u5e76\u4e0e5\u5bb6\u4e13\u6ce8\u4e8e\u7ebf\u4e0a\u6027\u522b\u66b4\u529b\u7684NGO\u5408\u4f5c\uff0c\u5f00\u5c55\u53c2\u4e0e\u5f0f\u6848\u4f8b\u7814\u7a76\uff0c\u5206\u6790\u5229\u76ca\u76f8\u5173\u65b9\u53c2\u4e0e\u7684\u6700\u4f73\u5b9e\u8df5\u3002", "result": "\u53d1\u73b0\u5f53\u524dNLP\u7814\u7a76\u4e0e\u53d7\u6709\u5bb3\u5185\u5bb9\u5f71\u54cd\u6700\u6df1\u793e\u533a\u4e4b\u95f4\u7684\u8131\u8282\u65e5\u76ca\u4e25\u91cd\uff0c\u4e14\u7f3a\u4e4f\u5229\u76ca\u76f8\u5173\u65b9\u7684\u6df1\u5ea6\u53c2\u4e0e\u3002\u901a\u8fc7\u4e0eNGO\u5408\u4f5c\uff0c\u603b\u7ed3\u51fa\u5bf9\u5229\u76ca\u76f8\u5173\u65b9\u6709\u76ca\u7684\u5b9e\u8df5\u5efa\u8bae\u3002", "conclusion": "NLP\u53cd\u51fb\u4ec7\u6068\u8a00\u8bba\u7814\u7a76\u4e9f\u9700\u91cd\u89c6\u548c\u6574\u5408\u53d7\u5f71\u54cd\u793e\u7fa4\u548c\u5229\u76ca\u76f8\u5173\u65b9\u7684\u4e13\u4e1a\u7ecf\u9a8c\u4e0e\u9700\u6c42\uff0c\u4ece\u800c\u63d0\u5347\u5e72\u9884\u7684\u6709\u6548\u6027\u548c\u793e\u4f1a\u4ef7\u503c\u3002"}}
{"id": "2508.04660", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04660", "abs": "https://arxiv.org/abs/2508.04660", "authors": ["Noah Ziems", "Dilara Soylu", "Lakshya A Agrawal", "Isaac Miller", "Liheng Lai", "Chen Qian", "Kaiqiang Song", "Meng Jiang", "Dan Klein", "Matei Zaharia", "Karel D'Oosterlinck", "Christopher Potts", "Omar Khattab"], "title": "Multi-module GRPO: Composing Policy Gradients and Prompt Optimization for Language Model Programs", "comment": null, "summary": "Group Relative Policy Optimization (GRPO) has proven to be an effective tool\nfor post-training language models (LMs). However, AI systems are increasingly\nexpressed as modular programs that mix together multiple LM calls with distinct\nprompt templates and other tools, and it is not clear how best to leverage GRPO\nto improve these systems. We begin to address this challenge by defining\nmmGRPO, a simple multi-module generalization of GRPO that groups LM calls by\nmodule across rollouts and handles variable-length and interrupted\ntrajectories. We find that mmGRPO, composed with automatic prompt optimization,\nimproves accuracy by 11% on average across classification, many-hop search, and\nprivacy-preserving delegation tasks against the post-trained LM, and by 5%\nagainst prompt optimization on its own. We open-source mmGRPO in DSPy as the\ndspy.GRPO optimizer.", "AI": {"tldr": "\u63d0\u51fammGRPO\u65b9\u6cd5\uff0c\u5c06GRPO\u63a8\u5e7f\u5230\u591a\u6a21\u5757AI\u7cfb\u7edf\uff0c\u5bf9\u591a\u79cdNLP\u4efb\u52a1\u63d0\u5347\u51c6\u786e\u7387\uff0c\u5e76\u5df2\u5f00\u6e90\u5b9e\u73b0\u3002", "motivation": "\u6a21\u5757\u5316AI\u7cfb\u7edf\u8d8a\u6765\u8d8a\u666e\u904d\uff0c\u4f46\u5355\u4e00\u7684GRPO\u4f18\u5316\u65e0\u6cd5\u9002\u5e94\u4e0d\u540c\u6a21\u5757\u548c\u591a\u6837\u5316\u8f68\u8ff9\u7684\u9700\u6c42\u3002\u4f5c\u8005\u5e0c\u671b\u5b9e\u73b0\u4e00\u4e2a\u80fd\u9002\u7528\u590d\u6742\u3001\u591a\u6a21\u5757\u7cfb\u7edf\u7684GRPO\u4f18\u5316\u65b9\u5f0f\u3002", "method": "\u5c06\u4f20\u7edf\u7684GRPO\u65b9\u6cd5\u6cdb\u5316\u4e3a\u80fd\u591f\u9488\u5bf9AI\u7cfb\u7edf\u4e2d\u4e0d\u540c\u6a21\u5757\u3001\u53d8\u957f\u548c\u53ef\u80fd\u4e2d\u65ad\u7684\u8f68\u8ff9\u8fdb\u884c\u56e2\u7ec4\u4f18\u5316\uff0c\u5e76\u7ed3\u5408\u81ea\u52a8\u5316\u7684prompt\u4f18\u5316\u3002", "result": "mmGRPO\u5728\u5206\u7c7b\u3001\u591a\u8df3\u641c\u7d22\u3001\u9690\u79c1\u4fdd\u62a4\u59d4\u6258\u7b49\u4efb\u52a1\u4e0a\u76f8\u8f83\u540e\u8bad\u7ec3\u7684LM\u5e73\u5747\u63d0\u5347\u4e8611%\u7684\u51c6\u786e\u7387\uff0c\u76f8\u8f83\u5355\u7eaf\u7684prompt\u4f18\u5316\u63d0\u53475%\u3002\u5df2\u5728DSPy\u5e93\u4e2d\u5f00\u6e90\u8be5\u4f18\u5316\u5668\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u5757GRPO\u65b9\u6cd5\uff08mmGRPO\uff09\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u6a21\u5757\u5316AI\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u5e76\u5df2\u5728DSPy\u5de5\u5177\u4e2d\u5f00\u6e90\u3002"}}
{"id": "2508.04664", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04664", "abs": "https://arxiv.org/abs/2508.04664", "authors": ["Mo Li", "L. H. Xu", "Qitai Tan", "Ting Cao", "Yunxin Liu"], "title": "Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management", "comment": "Preprint. Work in progress", "summary": "Large Language Models (LLMs) suffer from significant performance degradation\nwhen processing long contexts due to proactive interference, where irrelevant\ninformation in earlier parts of the context disrupts reasoning and memory\nrecall. While most research focuses on external memory systems to augment LLMs'\ncapabilities, we propose a complementary approach: empowering LLMs with Active\nContext Management (ACM) tools to actively sculpt their internal working\nmemory. We introduce Sculptor, a framework that equips LLMs with three\ncategories of tools: (1) context fragmentation, (2) summary, hide, and restore,\nand (3) intelligent search. Our approach enables LLMs to proactively manage\ntheir attention and working memory, analogous to how humans selectively focus\non relevant information while filtering out distractions. Experimental\nevaluation on information-sparse benchmarks-PI-LLM (proactive interference) and\nNeedleBench Multi-Needle Reasoning-demonstrates that Sculptor significantly\nimproves performance even without specific training, leveraging LLMs' inherent\ntool calling generalization capabilities. By enabling Active Context\nManagement, Sculptor not only mitigates proactive interference but also\nprovides a cognitive foundation for more reliable reasoning across diverse\nlong-context tasks-highlighting that explicit context-control strategies,\nrather than merely larger token windows, are key to robustness at scale.", "AI": {"tldr": "\u957f\u6587\u672c\u65f6\uff0cLLM\u5e38\u88ab\u65e0\u5173\u4fe1\u606f\u5e72\u6270\uff0c\u63a8\u7406\u80fd\u529b\u4e0b\u964d\u3002\u4f5c\u8005\u63d0\u51faSculptor\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e3b\u52a8\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u5de5\u5177\uff0c\u660e\u663e\u7f13\u89e3\u4e86\u8fd9\u4e00\u95ee\u9898\u5e76\u63d0\u5347\u4e86\u63a8\u7406\u9c81\u68d2\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5904\u7406\u957f\u6587\u672c\u65f6\uff0c\u7531\u4e8e\u4e3b\u52a8\u5e72\u6270\uff0c\u8868\u73b0\u4f1a\u5927\u5e45\u4e0b\u964d\uff1a\u4e0a\u4e0b\u6587\u4e2d\u65e0\u5173\u7684\u4fe1\u606f\u4f1a\u5e72\u6270\u6a21\u578b\u7684\u63a8\u7406\u4e0e\u8bb0\u5fc6\u56de\u8c03\u3002\u73b0\u6709\u591a\u6570\u5de5\u4f5c\u4e3b\u8981\u4e13\u6ce8\u4e8e\u901a\u8fc7\u5916\u90e8\u8bb0\u5fc6\u7cfb\u7edf\u6269\u5c55LLM\u7684\u80fd\u529b\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e92\u8865\u601d\u8def\uff0c\u5e0c\u671b\u63d0\u5347LLM\u7684\u5185\u90e8\u5de5\u4f5c\u8bb0\u5fc6\u7ba1\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faActive Context Management (ACM\uff0c\u4e3b\u52a8\u4e0a\u4e0b\u6587\u7ba1\u7406)\u5de5\u5177\uff0c\u8d4b\u4e88LLM\u4e3b\u52a8\u201c\u96d5\u523b\u201d\u5176\u5185\u90e8\u8bb0\u5fc6\u7684\u80fd\u529b\u3002\u5177\u4f53\u5b9e\u73b0\u540d\u4e3aSculptor\u6846\u67b6\uff0c\u5305\u62ec\u4e09\u7c7b\u5de5\u5177\uff1a1. \u4e0a\u4e0b\u6587\u5206\u7247\uff08fragmentation\uff09\uff0c2. \u603b\u7ed3\u3001\u9690\u85cf\u4e0e\u6062\u590d\uff08summary, hide and restore\uff09\uff0c3. \u667a\u80fd\u641c\u7d22\uff08intelligent search\uff09\u3002\u4e0a\u8ff0\u5de5\u5177\u8ba9LLM\u50cf\u4eba\u7c7b\u4e00\u6837\uff0c\u9009\u62e9\u6027\u5730\u5173\u6ce8\u6709\u7528\u4fe1\u606f\u3001\u8fc7\u6ee4\u5e72\u6270\u3002", "result": "\u5728\u4fe1\u606f\u7a00\u758f\u57fa\u51c6\uff08PI-LLM, NeedleBench Multi-Needle Reasoning\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSculptor\u6846\u67b6\u53ef\u663e\u8457\u63d0\u5347LLM\u5728\u957f\u6587\u672c\u4efb\u52a1\u4e0b\u7684\u8868\u73b0\uff0c\u5373\u4f7f\u6ca1\u6709\u4e3a\u6b64\u4e13\u95e8\u8bad\u7ec3\uff0c\u4e5f\u80fd\u53d1\u6325LLMs\u7684\u5de5\u5177\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u4e3b\u52a8\u4e0a\u4e0b\u6587\u7ba1\u7406\uff0cSculptor\u4e0d\u4ec5\u6709\u6548\u7f13\u89e3\u4e86\u4e3b\u52a8\u5e72\u6270\u95ee\u9898\uff0c\u8fd8\u4e3a\u591a\u79cd\u957f\u6587\u672c\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u8ba4\u77e5\u57fa\u7840\u3002\u8bba\u6587\u5f3a\u8c03\uff0c\u76f8\u8f83\u4e8e\u7b80\u5355\u6269\u5927\u4e0a\u4e0b\u6587\u7a97\u53e3\uff0c\u5f15\u5165\u663e\u5f0f\u7684\u4e0a\u4e0b\u6587\u63a7\u5236\u7b56\u7565\u5bf9\u5927\u89c4\u6a21LLMs\u7684\u7a33\u5065\u6027\u66f4\u52a0\u5173\u952e\u3002"}}
{"id": "2508.04676", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.04676", "abs": "https://arxiv.org/abs/2508.04676", "authors": ["Yunan Zhang", "Shuoran Jiang", "Mengchen Zhao", "Yuefeng Li", "Yang Fan", "Xiangping Wu", "Qingcai Chen"], "title": "GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via General Samples Replay", "comment": null, "summary": "The continual learning capability of large language models (LLMs) is crucial\nfor advancing artificial general intelligence. However, continual fine-tuning\nLLMs across various domains often suffers from catastrophic forgetting,\ncharacterized by: 1) significant forgetting of their general capabilities, and\n2) sharp performance declines in previously learned tasks. To simultaneously\naddress both issues in a simple yet stable manner, we propose General Sample\nReplay (GeRe), a framework that use usual pretraining texts for efficient\nanti-forgetting. Beyond revisiting the most prevalent replay-based practices\nunder GeRe, we further leverage neural states to introduce a enhanced\nactivation states constrained optimization method using threshold-based margin\n(TM) loss, which maintains activation state consistency during replay learning.\nWe are the first to validate that a small, fixed set of pre-collected general\nreplay samples is sufficient to resolve both concerns--retaining general\ncapabilities while promoting overall performance across sequential tasks.\nIndeed, the former can inherently facilitate the latter. Through controlled\nexperiments, we systematically compare TM with different replay strategies\nunder the GeRe framework, including vanilla label fitting, logit imitation via\nKL divergence and feature imitation via L1/L2 losses. Results demonstrate that\nTM consistently improves performance and exhibits better robustness. Our work\npaves the way for efficient replay of LLMs for the future. Our code and data\nare available at https://github.com/Qznan/GeRe.", "AI": {"tldr": "\u63d0\u51fa\u901a\u7528\u6837\u672c\u56de\u653eGeRe\u6846\u67b6\u53caTM\u635f\u5931\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3LLM\u707e\u96be\u6027\u9057\u5fd8\u548c\u8fde\u7eed\u4efb\u52a1\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u56de\u653e\u7b56\u7565\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6301\u7eed\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u5e38\u5e38\u9762\u4e34\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u8868\u73b0\u4e3a\u5bf9\u901a\u7528\u80fd\u529b\u4e0e\u5df2\u5b66\u4efb\u52a1\u8868\u73b0\u7684\u663e\u8457\u4e0b\u964d\uff0c\u963b\u788d\u4e86\u4eba\u5de5\u901a\u7528\u667a\u80fd\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u4e86General Sample Replay\uff08GeRe\uff09\u6846\u67b6\uff0c\u4f7f\u7528\u5e38\u89c4\u9884\u8bad\u7ec3\u6587\u672c\u8fdb\u884c\u9ad8\u6548\u6297\u9057\u5fd8\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6fc0\u6d3b\u72b6\u6001\u7ea6\u675f\u4e0e\u9608\u503c\u8fb9\u9645\uff08TM\uff09\u635f\u5931\u7684\u589e\u5f3a\u4f18\u5316\u65b9\u6cd5\uff0c\u5728\u56de\u653e\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u795e\u7ecf\u6fc0\u6d3b\u72b6\u6001\u7684\u4e00\u81f4\u6027\u3002\u5c06TM\u4e0e\u6807\u7b7e\u62df\u5408\u3001KL\u6563\u5ea6\u7684logit\u6a21\u4eff\u3001L1/L2\u7279\u5f81\u6a21\u4eff\u7b49\u56de\u653e\u7b56\u7565\u8fdb\u884c\u4e86\u7cfb\u7edf\u5bf9\u6bd4\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u91c7\u7528\u5c0f\u89c4\u6a21\u3001\u56fa\u5b9a\u9884\u6536\u96c6\u7684\u901a\u7528\u6837\u672c\u56de\u653e\uff0c\u53ef\u4ee5\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u901a\u7528\u80fd\u529b\u548c\u5728\u5404\u8fde\u7eed\u4efb\u52a1\u4e0a\u7684\u6574\u4f53\u6027\u80fd\u63d0\u5347\u3002TM\u635f\u5931\u6cd5\u5728\u4e0d\u540c\u7b56\u7565\u4e0b\u5747\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6027\u80fd\u4e0e\u9c81\u68d2\u6027\u3002", "conclusion": "GeRe\u6846\u67b6\u53caTM\u635f\u5931\u4e3a\u9ad8\u6548\u9632\u9057\u5fd8\u548c\u9ad8\u6027\u80fd\u7684LLM\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\uff0c\u63a8\u52a8\u672a\u6765LLM\u6709\u6548\u56de\u653e\u53d1\u5c55\u3002\u4ee3\u7801\u548c\u6570\u636e\u5df2\u7ecf\u5f00\u6e90\u3002"}}
{"id": "2508.04698", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.04698", "abs": "https://arxiv.org/abs/2508.04698", "authors": ["Thibaut Thonet", "Germ\u00e1n Kruszewski", "Jos Rozen", "Pierre Erbacher", "Marc Dymetman"], "title": "FaST: Feature-aware Sampling and Tuning for Personalized Preference Alignment with Limited Data", "comment": null, "summary": "LLM-powered conversational assistants are often deployed in a\none-size-fits-all manner, which fails to accommodate individual user\npreferences. Recently, LLM personalization -- tailoring models to align with\nspecific user preferences -- has gained increasing attention as a way to bridge\nthis gap. In this work, we specifically focus on a practical yet challenging\nsetting where only a small set of preference annotations can be collected per\nuser -- a problem we define as Personalized Preference Alignment with Limited\nData (PPALLI). To support research in this area, we introduce two datasets --\nDnD and ELIP -- and benchmark a variety of alignment techniques on them. We\nfurther propose FaST, a highly parameter-efficient approach that leverages\nhigh-level features automatically discovered from the data, achieving the best\noverall performance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e13\u6ce8\u4e8e\u5728\u7528\u6237\u504f\u597d\u6807\u6ce8\u6587\u6863\u6709\u9650\u7684\u573a\u666f\u4e0b\u5b9e\u73b0LLM\u4e2a\u6027\u5316\uff0c\u901a\u8fc7\u65b0\u6570\u636e\u96c6\u548c\u521b\u65b0\u65b9\u6cd5FaST\uff0c\u5728\u73b0\u6709\u6280\u672f\u4e0a\u53d6\u5f97\u4e86\u6700\u4f18\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u5bf9\u8bdd\u52a9\u624b\u901a\u5e38\u91c7\u53d6\u7edf\u4e00\u9002\u7528\u7684\u6a21\u5f0f\uff0c\u96be\u4ee5\u6ee1\u8db3\u4e2a\u4f53\u7528\u6237\u7684\u504f\u597d\u3002\u4e2a\u4eba\u5316\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u63a8\u52a8\u4e86\u6a21\u578b\u4e2a\u6027\u5316\u7814\u7a76\u7684\u5174\u8d77\uff0c\u4f46\u6bcf\u4f4d\u7528\u6237\u4ec5\u6709\u5c11\u91cf\u504f\u597d\u6807\u6ce8\u6570\u636e\u60c5\u5883\u4e0b\u7684\u4e2a\u6027\u5316\u5bf9\u9f50\u95ee\u9898\u5c1a\u672a\u88ab\u5145\u5206\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u4e86\u4e2a\u6027\u5316\u504f\u597d\u5bf9\u9f50\u95ee\u9898\uff08PPALLI\uff09\uff0c\u5e76\u6784\u5efa\u4e86\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\uff08DnD\u548cELIP\uff09\uff1b\u5bf9\u591a\u79cd\u5bf9\u9f50\u6280\u672f\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u3001\u81ea\u52a8\u53d1\u73b0\u9ad8\u5c42\u7279\u5f81\u7684\u6a21\u578b\u5bf9\u9f50\u65b9\u6cd5FaST\u3002", "result": "FaST\u65b9\u6cd5\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u4f73\u7684\u6574\u4f53\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u9ad8\u5c42\u7279\u5f81\u81ea\u52a8\u53d1\u73b0\u4e0e\u53c2\u6570\u9ad8\u6548\u7ed3\u5408\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u4e2a\u6027\u5316\u504f\u597d\u5bf9\u9f50\u95ee\u9898\u5728\u6570\u636e\u6709\u9650\u8bbe\u7f6e\u4e0b\u5177\u6709\u6311\u6218\u6027\uff0c\u63d0\u51fa\u7684\u516c\u5f00\u6570\u636e\u96c6\u53ca\u57fa\u51c6\u63a8\u52a8\u4e86\u8be5\u65b9\u5411\u7814\u7a76\uff0cFaST\u65b9\u6cd5\u5728\u5b9e\u9645\u573a\u666f\u4e0b\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2508.04699", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.04699", "abs": "https://arxiv.org/abs/2508.04699", "authors": ["Anushka Yadav", "Isha Nalawade", "Srujana Pillarichety", "Yashwanth Babu", "Reshmi Ghosh", "Samyadeep Basu", "Wenlong Zhao", "Ali Nasaeh", "Sriram Balasubramanian", "Soundararajan Srinivasan"], "title": "Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during Multi-Hop Analysis", "comment": null, "summary": "The emergence of reasoning models and their integration into practical AI\nchat bots has led to breakthroughs in solving advanced math, deep search, and\nextractive question answering problems that requires a complex and multi-step\nthought process. Yet, a complete understanding of why these models hallucinate\nmore than general purpose language models is missing. In this investigative\nstudy, we systematicallyexplore reasoning failures of contemporary language\nmodels on multi-hop question answering tasks. We introduce a novel, nuanced\nerror categorization framework that examines failures across three critical\ndimensions: the diversity and uniqueness of source documents involved (\"hops\"),\ncompleteness in capturing relevant information (\"coverage\"), and cognitive\ninefficiency (\"overthinking\"). Through rigorous hu-man annotation, supported by\ncomplementary automated metrics, our exploration uncovers intricate error\npatterns often hidden by accuracy-centric evaluations. This investigative\napproach provides deeper insights into the cognitive limitations of current\nmodels and offers actionable guidance toward enhancing reasoning fidelity,\ntransparency, and robustness in future language modeling efforts.", "AI": {"tldr": "\u8bba\u6587\u7cfb\u7edf\u5256\u6790\u4e86\u63a8\u7406\u5927\u6a21\u578b\u591a\u8df3\u95ee\u7b54\u65f6\u7684\u9519\u8bef\uff0c\u63d0\u51fa\u4e09\u7ef4\u5ea6\u65b0\u5206\u7c7b\u4f53\u7cfb\uff0c\u53d1\u73b0\u591a\u4e2a\u88ab\u51c6\u786e\u7387\u6307\u6807\u63a9\u76d6\u7684\u8ba4\u77e5\u5c40\u9650\uff0c\u5e76\u4e3a\u6a21\u578b\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002", "motivation": "\u867d\u7136\u63a8\u7406\u578b\u5927\u6a21\u578b\u5728\u591a\u6b65\u590d\u6742\u4efb\u52a1\u4e2d\u5c55\u73b0\u7a81\u7834\u6027\u8fdb\u5c55\uff0c\u4f46\u5176\u4e3a\u4f55\u6bd4\u901a\u7528\u8bed\u8a00\u6a21\u578b\u66f4\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\u73b0\u8c61\u4ecd\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7406\u89e3\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u6df1\u5165\u5256\u6790\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u95ee\u7b54\u4e2d\u7684\u9519\u8bef\u673a\u5236\uff0c\u5e76\u4e3a\u6a21\u578b\u6539\u8fdb\u63d0\u4f9b\u7406\u8bba\u4e0e\u5b9e\u8df5\u4f9d\u636e\u3002", "method": "\u7cfb\u7edf\u5206\u6790\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u5931\u8d25\uff0c\u63d0\u51fa\u5e76\u5e94\u7528\u4e86\u4e00\u4e2a\u4ece'\u8df3\u6570'\u591a\u6837\u6027\u3001\u4fe1\u606f\u8986\u76d6\u5b8c\u6574\u6027\u548c\u8ba4\u77e5\u6548\u7387\uff08\u4e09\u7ef4\uff09\u5c55\u5f00\u7684\u7cbe\u7ec6\u5316\u9519\u8bef\u5206\u7c7b\u4f53\u7cfb\u3002\u901a\u8fc7\u4eba\u5de5\u6807\u6ce8\u4e0e\u81ea\u52a8\u5316\u6307\u6807\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6df1\u5c42\u9519\u8bef\u7279\u70b9\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0c\u73b0\u6709\u63a8\u7406\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8df3\u95ee\u7b54\u4e2d\u666e\u904d\u5b58\u5728\u4e0e\u76f8\u5173\u6587\u732e\u591a\u6837\u6027\u3001\u4fe1\u606f\u8986\u76d6\u548c\u601d\u8003\u8fc7\u7a0b\u975e\u6548\u7387\u76f8\u5173\u7684\u590d\u6742\u9519\u8bef\u3002\u8fd9\u4e9b\u7ec6\u81f4\u9519\u8bef\u901a\u8fc7\u65b0\u5206\u7c7b\u6846\u67b6\u5f97\u4ee5\u7ec6\u81f4\u63ed\u793a\uff0c\u4e3a\u672a\u6765\u6a21\u578b\u4f18\u5316\u6307\u660e\u4e86\u65b9\u5411\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u73b0\u6709\u63a8\u7406\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u590d\u6742\u9519\u8bef\u6a21\u5f0f\uff0c\u8fd9\u4e9b\u9519\u8bef\u5e38\u5e38\u88ab\u4f20\u7edf\u7684\u51c6\u786e\u7387\u8bc4\u4ef7\u65b9\u5f0f\u5ffd\u89c6\u3002\u63d0\u51fa\u7684\u65b0\u578b\u9519\u8bef\u5206\u7c7b\u4f53\u7cfb\u6709\u52a9\u4e8e\u6df1\u5165\u7406\u89e3\u6a21\u578b\u7684\u8ba4\u77e5\u5c40\u9650\uff0c\u5e76\u4e3a\u672a\u6765\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u63d0\u5347\u63d0\u4f9b\u4e86\u5177\u4f53\u53ef\u884c\u7684\u6307\u5bfc\u3002"}}
