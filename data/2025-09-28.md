<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 18]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.CL](#cs.CL) [Total: 66]
- [cs.DM](#cs.DM) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Dual-Language General-Purpose Self-Hosted Visual Language and new Textual Programming Language for Applications](https://arxiv.org/abs/2509.20426)
*Mahmoud Samir Fayed*

Main category: cs.PL

TL;DR: 本文提出并实现了PWCT2，一种支持中英文通用、自举的视觉化编程语言，并通过自带Ring文本语言实现自我开发，显著提升了代码生成效率和存储空间，获得了用户广泛认可。


<details>
  <summary>Details</summary>
Motivation: 大多数视觉化编程语言（VPL）仅限于特定领域，通用VPL很少且通常需用文本语言开发和改进，亟需打破此限制。

Method: 设计并实现PWCT2，一个支持中英文通用、可自举的视觉化编程语言。先设计文本语言Ring，为PWCT2开发提供基础。Ring支持动态类型、语法自定义、领域特定语言扩展等。通过PWCT视觉编程实现Ring编译器和虚拟机，并通过自举生成PWCT2。

Result: PWCT2实现了代码生成速度提升约36倍，视觉源文件存储减少约20倍；支持Ring代码与视觉代码互转，实现了自举开发。PWCT2包含约9.2万行Ring代码、394个视觉组件，并成功通过Steam平台分发，得到用户积极反馈。

Conclusion: PWCT2突破了传统视觉化编程语言依赖文本编程开发的模式，实现了自举、通用化，显著提升了效率与用户体验，对视觉化编程语言的研究和推广有重要意义。

Abstract: Most visual programming languages (VPLs) are domain-specific, with few
general-purpose VPLs like Programming Without Coding Technology (PWCT). These
general-purpose VPLs are developed using textual programming languages and
improving them requires textual programming. In this thesis, we designed and
developed PWCT2, a dual-language (Arabic/English), general-purpose,
self-hosting visual programming language. Before doing so, we specifically
designed a textual programming language called Ring for its development. Ring
is a dynamically typed language with a lightweight implementation, offering
syntax customization features. It permits the creation of domain-specific
languages through new features that extend object-oriented programming,
allowing for specialized languages resembling Cascading Style Sheets (CSS) or
Supernova language. The Ring Compiler and Virtual Machine are designed using
the PWCT visual programming language where the visual implementation is
composed of 18,945 components that generate 24,743 lines of C code, which
increases the abstraction level and hides unnecessary details. Using PWCT to
develop Ring allowed us to realize several issues in PWCT, which led to the
development of the PWCT2 visual programming language using the Ring textual
programming language. PWCT2 provides approximately 36 times faster code
generation and requires 20 times less storage for visual source files. It also
allows for the conversion of Ring code into visual code, enabling the creation
of a self-hosting VPL that can be developed using itself. PWCT2 consists of
approximately 92,000 lines of Ring code and comes with 394 visual components.
PWCT2 is distributed to many users through the Steam platform and has received
positive feedback, On Steam, 1772 users have launched the software, and the
total recorded usage time exceeds 17,000 hours, encouraging further research
and development.

</details>


### [2] [Efficient Symbolic Computation vis Hash Consing](https://arxiv.org/abs/2509.20534)
*Bowen Zhu,Aayush Sabharwal,Songchen Tan,Yingbo Ma,Alan Edelman,Christopher Rackauckas*

Main category: cs.PL

TL;DR: 提出并实现哈希一致化以消除Julia符号计算表达式冗余，大幅提升速度与内存效率，为AI数学工具扩展打下基础。


<details>
  <summary>Details</summary>
Motivation: 在符号计算中，表达式冗余存储导致内存低效和性能下降，特别是在电脑代数和AI数学推理工具中尤为突出。解决表达式膨胀问题是提升符号计算系统效率的关键。

Method: 将哈希一致化（hash consing）首次集成到Julia高性能符号计算工具JuliaSymbolics中，通过全局弱引用哈希表对表达式进行标准化并消除重复，同时无缝兼容Julia的元编程和即时编译架构。

Result: 在多个计算领域的基准测试显示，该方法最高可将符号计算加速3.2倍，内存使用减少2倍，代码生成快5倍，函数编译快10倍，大模型数值求值快100倍。部分变量较少的初始阶段计算负载增益有限，甚至略有开销，但后续处理阶段均显著受益。

Conclusion: 哈希一致化的引入极大地提升了符号计算系统的可扩展性与性能，并为未来与等价类图（e-graphs）结合以增强AI管道的等价表达式共享能力奠定了基础。

Abstract: Symbolic computation systems suffer from memory inefficiencies due to
redundant storage of structurally identical subexpressions, commonly known as
expression swell, which degrades performance in both classical computer algebra
and emerging AI-driven mathematical reasoning tools. In this paper, we present
the first integration of hash consing into JuliaSymbolics, a high-performance
symbolic toolkit in Julia, by employing a global weak-reference hash table that
canonicalizes expressions and eliminates duplication. This approach reduces
memory consumption and accelerates key operations such as differentiation,
simplification, and code generation, while seamlessly integrating with Julia's
metaprogramming and just-in-time compilation infrastructure. Benchmark
evaluations across different computational domains reveal substantial
improvements: symbolic computations are accelerated by up to 3.2 times, memory
usage is reduced by up to 2 times, code generation is up to 5 times faster,
function compilation up to 10 times faster, and numerical evaluation up to 100
times faster for larger models. While certain workloads with fewer duplicate
unknown-variable expressions show more modest gains or even slight overhead in
initial computation stages, downstream processing consistently benefits
significantly. These findings underscore the importance of hash consing in
scaling symbolic computation and pave the way for future work integrating hash
consing with e-graphs for enhanced equivalence-aware expression sharing in
AI-driven pipelines.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [ACCeLLiuM: Supervised Fine-Tuning for Automated OpenACC Pragma Generation](https://arxiv.org/abs/2509.20380)
*Samyak Jhaveri,Vanessa Klotzmann,Crista Lopes*

Main category: cs.SE

TL;DR: 本研究提出了针对OpenACC指令生成的专用大语言模型ACCeLLiuM，并通过大规模真实数据微调，有效提升了自动并行化能力。模型及数据集均已开源，为自动GPU加速和相关研究提供了坚实基准。


<details>
  <summary>Details</summary>
Motivation: 随着GPU的普及，其硬件和并行编程框架变得愈发复杂。现有指令式并行编程如OpenACC虽降低了一定编程门槛，但仍需专业技能。研究旨在进一步简化GPU编程，自动生成高质量OpenACC指令，帮助开发者高效实现数据并行。

Method: 提出了ACCeLLiuM，这是两个专门针对生成OpenACC指令（用于数据并行循环）的开源大语言模型，并使用来自公开GitHub C/C++仓库的4033条OpenACC pragma-loop对进行监督微调训练（3223训练，810测试）。

Result: 微调后的ACCeLLiuM模型在生成正确OpenACC指令方面大幅优于基础模型：在测试集中，87%的数据并行循环能生成有效的指令类型，50%能生成完全准确的指令（包括指令、子句、顺序和变量）。即使不是完全匹配，也常能生成包含关键子句的有效指令，为实际并行化和自动GPU加速带来额外价值。

Conclusion: ACCeLLiuM显著提升了LLM自动生成OpenACC指令的能力，降低了GPU并行化的门槛。公开的代码、模型和数据集为相关研究提供可复现的基准，加速了传统串行程序的自动并行化进程。

Abstract: The increasing ubiquity of GPUs is accompanied by the increasing complexity
of their hardware and parallel programming frameworks. Directive-based parallel
programming standards like OpenACC simplify GPU programming to some extent by
abstracting away low-level complexities, but a fair amount of expertise is
still required in order to use those directives effectively.
  We introduce ACCeLLiuM, two open weights Large Language Models specifically
fine-tuned for generating expert OpenACC directives for data-parallel loops,
along with the supervised fine-tuning dataset that was used to train them. The
ACCeLLiuM SFT dataset contains 4,033 OpenACC pragma-loop pairs mined from
public GitHub C/C++ repositories, with 3,223 pairs for training and 810 for
testing. Experimental evaluations show a pronounced performance gap in
generating correct OpenACC pragmas between base LLMs and our fine-tuned
versions. On the held-out test set, base LLMs fail to consistently generate
valid pragmas, whereas LLMs fine-tuned on the ACCeLLiuM dataset generate valid
pragmas with the correct directive type for $87\%$ of the data-parallel loops,
and exact pragmas--including directives, clauses, clause order, and clause
variables--for $50\%$ of the cases. Even when not exact, generated pragmas
frequently incorporate the correct clauses in a different order than the
ground-truth label, or include additional clauses that enable finer control
over parallel execution, data movement, and concurrency, offering practical
value beyond strict string-matching. By publicly releasing the code, models,
and dataset as ACCeLLiuM we hope to establish a reproducible benchmark for
LLM-powered OpenACC pragma generation, and lower the barrier to automated GPU
offloading of serially written programs.

</details>


### [4] [State-of-the-Art in Software Security Visualization: A Systematic Review](https://arxiv.org/abs/2509.20385)
*Ishara Devendra,Chaman Wijesiriwardana,Prasad Wimalaratne*

Main category: cs.SE

TL;DR: 本文系统梳理软件安全可视化领域，归纳四类主流技术，分析关键进展及挑战，强调创新可视化方法对安全威胁识别和响应的重要性，并为未来研究提供参考。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统复杂性增加及安全威胁不断演变，传统基于文本和数值的方法已难以有效分析软件安全问题。因此，亟需创新的可视化技术来辅助安全数据解读与决策。本文旨在系统性梳理和归纳该领域的主要可视化技术。

Method: 系统性综述方法，筛选并分析了60余篇近期软件安全可视化的关键论文，创建了技术分类体系。将现有技术分为：基于图、符号、矩阵和隐喻四种可视化类型，并对其关键问题及未来方向进行总结。

Result: 系统梳理了当前软件安全可视化技术及其分类，识别出两大核心应用领域：软件开发可视化（侧重架构建模）与操作安全/网络安全可视化。发现创新型可视化技术有助于提升威胁检测、改善安全响应，并为未来研究指明方向。

Conclusion: 软件安全可视化是应对复杂安全问题的有效手段，需持续发展适应不断变化威胁的创新技术。可视化方法对增强安全检测、响应与研究具有重要实际价值。

Abstract: Software security visualization is an interdisciplinary field that combines
the technical complexity of cybersecurity, including threat intelligence and
compliance monitoring, with visual analytics, transforming complex security
data into easily digestible visual formats. As software systems get more
complex and the threat landscape evolves, traditional text-based and numerical
methods for analyzing and interpreting security concerns become increasingly
ineffective. The purpose of this paper is to systematically review existing
research and create a comprehensive taxonomy of software security visualization
techniques through literature, categorizing these techniques into four types:
graph-based, notation-based, matrix-based, and metaphor-based visualization.
This systematic review explores over 60 recent key research papers in software
security visualization, highlighting its key issues, recent advancements, and
prospective future research directions. From the comprehensive analysis, the
two main areas were distinctly highlighted as extensive software development
visualization, focusing on advanced methods for depicting software
architecture: operational security visualization and cybersecurity
visualization. The findings highlight the necessity for innovative
visualization techniques that adapt to the evolving security landscape, with
practical implications for enhancing threat detection, improving security
response strategies, and guiding future research.

</details>


### [5] [Dynamic ReAct: Scalable Tool Selection for Large-Scale MCP Environments](https://arxiv.org/abs/2509.20386)
*Nishant Gaurav,Adit Akarsh,Ankit Ranjan,Manoj Bajaj*

Main category: cs.SE

TL;DR: 本文提出Dynamic ReAct用于解决AI Agent在海量工具集下的智能选择问题，通过优化工具加载机制显著减少资源消耗且不影响性能。


<details>
  <summary>Details</summary>
Motivation: 随着可用工具数量激增，现有ReAct智能体难以在内存受限的条件下高效加载和选择数百到数千个工具，因此急需解决大规模工具管理问题。

Method: 提出并评估了五种逐步优化的工具选择架构，最终采用了智能的搜索与加载机制以实现动态工具管理。

Result: 实验结果显示，通过动态工具选择机制，工具加载量最多可降低50%，且任务完成率未受影响。

Conclusion: Dynamic ReAct方法在大规模工具集环境下实现了高效、智能的工具选择，有效减少了计算资源消耗同时保持任务完成的准确性。

Abstract: We present Dynamic ReAct, a novel approach for enabling ReAct agents to ef-
ficiently operate with extensive Model Control Protocol (MCP) tool sets that
exceed the contextual memory limitations of large language models. Our approach
addresses the fundamental challenge of tool selection in environments
containing hundreds or thousands of available tools, where loading all tools
simultaneously is computationally infeasible. We propose and evaluate five
distinct architectures that progressively refine the tool selection process,
culminating in a search-and-load mechanism that achieves intelligent tool
selection with minimal computational overhead. Our experimental results
demonstrate that the proposed approach reduces tool loading by up to 50% while
maintaining task completion accuracy, advancing the path towards truly
general-purpose AI agents capable of dynamically adapting to diverse task
environments.

</details>


### [6] [Towards Systematic Specification and Verification of Fairness Requirements: A Position Paper](https://arxiv.org/abs/2509.20387)
*Qusai Ramadan,Jukka Ruohonen,Abhishek Tiwari,Adam Alami,Zeyd Boukhers*

Main category: cs.SE

TL;DR: 软件系统中的歧视常源于公平性需求定义不清，作者提出利用知识图谱形式化专家知识，辅助公平性需求的表达和验证，并规划了研究路线。


<details>
  <summary>Details</summary>
Motivation: 现有研究多归因于算法与数据偏差，然而忽略了公平性规范本身的制定难题，且目前尚缺乏形式化、公正的需求定义与验证机制。

Method: 提出使用知识图谱来帮助梳理和形式化专家对公平的隐性知识，从而辅助公平性需求的制定与验证。

Result: 本文提出一种基于知识图谱的公平性框架，并讨论了相关挑战、研究问题及未来研究路径。

Conclusion: 论文认为，当前软件系统中的歧视性决策，与缺乏明确且可验证的公平性需求有关。

Abstract: Decisions suggested by improperly designed software systems might be prone to
discriminate against people based on protected characteristics, such as gender
and ethnicity. Previous studies attribute such undesired behavior to flaws in
algorithmic design or biased data. However, these studies ignore that
discrimination is often the result of a lack of well-specified fairness
requirements and their verification. The fact that experts' knowledge about
fairness is often implicit makes the task of specifying precise and verifiable
fairness requirements difficult. In related domains, such as security
engineering, knowledge graphs have been proven to be effective in formalizing
knowledge to assist requirements specification and verification. To address the
lack of formal mechanisms for specifying and verifying fairness requirements,
we propose the development of a knowledge graph-based framework for fairness.
In this paper, we discuss the challenges, research questions, and a road map
towards addressing the research questions.

</details>


### [7] [Online-Optimized RAG for Tool Use and Function Calling](https://arxiv.org/abs/2509.20415)
*Yu Pan,Xiaocheng Li,Hanzhao Wang*

Main category: cs.SE

TL;DR: 论文提出了一种在线优化的RAG框架，通过部署期间根据实时反馈不断优化嵌入，显著提升了工具选择和任务成功率，适用于各类RAG与工具调用场景，且无需更改LLM本身，兼具理论分析和实证改进。


<details>
  <summary>Details</summary>
Motivation: 许多应用中，利用RAG（检索增强生成）通过嵌入用户查询和工具/函数描述来驱动工具使用和函数调用，但在实际应用中，由于嵌入模型不完善或描述噪声，嵌入错位常导致检索错误和任务失败。

Method: 文中提出了“在线优化RAG”框架，它在部署时根据真实交互和最小反馈（如任务成功与否）持续适应检索嵌入，通过轻量级的在线梯度更新来优化嵌入参数，对每次查询几乎无延迟、且无需更改LLM本身。方法支持单/多跳工具调用、动态工具库及K次检索并重排序，是即插即用的。文中还给出了理论分析，量化了初始化嵌入质量及相关因素对性能的影响。

Result: 在多种工具调用和文档检索场景下，在线优化RAG方法持续提升了工具选择准确率和最终任务成功率，表现出一致性的改进效果。

Conclusion: 在线优化RAG为构建健壮、可自我提升的RAG系统提供了简单实用的途径，显著提高了实际工具使用场景的检索和任务表现。

Abstract: In many applications, retrieval-augmented generation (RAG) drives tool use
and function calling by embedding the (user) queries and matching them to
pre-specified tool/function descriptions. In this paper, we address an
embedding misalignment issue that often arises in practical applications due to
imperfect embedding models or noisy descriptions; such misalignment may lead to
incorrect retrieval and task failure. We introduce Online-Optimized RAG, a
deployment-time framework that continually adapts retrieval embeddings from
live interactions using minimal feedback (e.g., task success). Online-Optimized
RAG applies lightweight online gradient updates with negligible per-query
latency and requires no changes to the underlying LLM. The method is
plug-and-play: it supports both single- and multi-hop tool use, dynamic tool
inventories, and $K$-retrieval with re-ranking. We provide a problem-dependent
theoretical analysis that quantifies how the method's performance depends on
the initialization quality of the embeddings and other related quantities.
Across diverse tool-use and document-retrieval scenarios, our Online-Optimized
RAG consistently improves tool selection accuracy and end-task success, thus
providing a simple, practical path to robust, self-improving RAG systems.

</details>


### [8] [Formal Verification of Legal Contracts: A Translation-based Approach](https://arxiv.org/abs/2509.20421)
*Reiner Hähnle,Cosimo Laneve,Adele Veschetti*

Main category: cs.SE

TL;DR: 通过自动把Stipula合约翻译为Java+JML并用KeY工具验证，本文实现了法律合约的自动化正确性证明，展示了通用工具的强大适用性。


<details>
  <summary>Details</summary>
Motivation: Stipula是一种用于建模法律合同（如资产转移和义务履行）的领域专用编程语言。合同的正确性至关重要，因此需要一种形式化且自动化的验证方法，以避免法律和资金风险。

Method: 将Stipula合约自动翻译为带有JML（Java建模语言）注释的Java代码，再利用KeY工具进行归纳验证。该方法对具有不相交循环的大部分合约支持完全自动化验证，包括部分和全部正确性。

Result: 对包含不相交循环的大部分Stipula合同，所提出的自动化翻译和验证方法成功地实现了部分和完全正确性的自动验证。

Conclusion: 通用的归纳验证工具可以通过自动化翻译方法成功用于验证Stipula智能合约的正确性。

Abstract: Stipula is a domain-specific programming language designed to model legal
contracts with enforceable properties, especially those involving asset
transfers and obligations. This paper presents a methodology to formally verify
the correctness of Stipula contracts through translation into Java code
annotated with Java Modeling Language specifications. As a verification
backend, the deductive verification tool KeY is used. Both, the translation and
the verification of partial and total correctness for a large subset of Stipula
contracts, those with disjoint cycles, is fully automatic. Our work
demonstrates that a general-purpose deductive verification tool can be used
successfully in a translation approach.

</details>


### [9] [AI-Specific Code Smells: From Specification to Detection](https://arxiv.org/abs/2509.20491)
*Brahim Mahmoudi,Naouel Moha,Quentin Stievenert,Florent Avellaneda*

Main category: cs.SE

TL;DR: 论文针对AI系统开发中的独特代码异味问题，提出了结合DSL和静态分析的SpecDetect4AI工具，能高效、精准地检测AI特有的代码隐患，在大规模数据实证中性能优异，具备良好的扩展性和实际意义。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能（AI）技术的兴起，AI系统开发过程中的软件问题日益突出，且现有检测工具常常无法发现与AI相关的特殊代码异味，影响系统可复现性、稳健性与泛化能力。作者旨在处理这些AI特有的代码质量隐患。

Method: 提出SpecDetect4AI工具结合高层次声明式领域专用语言（DSL）进行规则制定，以及可扩展静态分析工具进行规则解释和代码异味检测。作者设计了22种AI特有代码异味检测规则，并在大规模AI系统上进行了实证评估。

Result: SpecDetect4AI在826个AI系统（共计2000万行代码）上评测，检测精度达到88.66%，召回率88.89%，性能优于现有检测工具，并且具有较强的效率和扩展性（SUS可用性评分81.7/100）。

Conclusion: SpecDetect4AI能够有效、灵活地指定并检测AI系统中存在的特有代码异味，能对大型AI系统进行高效分析，并优于同类工具。工具支持新规则扩展，其方法具备实际应用价值。

Abstract: The rise of Artificial Intelligence (AI) is reshaping how software systems
are developed and maintained. However, AI-based systems give rise to new
software issues that existing detection tools often miss. Among these, we focus
on AI-specific code smells, recurring patterns in the code that may indicate
deeper problems such as unreproducibility, silent failures, or poor model
generalization. We introduce SpecDetect4AI, a tool-based approach for the
specification and detection of these code smells at scale. This approach
combines a high-level declarative Domain-Specific Language (DSL) for rule
specification with an extensible static analysis tool that interprets and
detects these rules for AI-based systems. We specified 22 AI-specific code
smells and evaluated SpecDetect4AI on 826 AI-based systems (20M lines of code),
achieving a precision of 88.66% and a recall of 88.89%, outperforming other
existing detection tools. Our results show that SpecDetect4AI supports the
specification and detection of AI-specific code smells through dedicated rules
and can effectively analyze large AI-based systems, demonstrating both
efficiency and extensibility (SUS 81.7/100).

</details>


### [10] [Enhancing Python Programming Education with an AI-Powered Code Helper: Design, Implementation, and Impact](https://arxiv.org/abs/2509.20518)
*Sayed Mahbub Hasan Amiri,Md Mainul Islam*

Main category: cs.SE

TL;DR: 本研究开发了一款结合代码分析、动态追踪及大语言模型的教学型AI聊天机器人，显著提升学生调试效率和编程能力（成功率85%），超越传统工具和单一AI助手，获得积极用户反馈，证明AI能在编程教育中增强学习效果和理解深度。


<details>
  <summary>Details</summary>
Motivation: 目前编程学习工具如IDE和静态分析器无法主动帮助学生，AI代码助手如Copilot更注重任务完成，缺乏针对学习过程的支持；因此需要一种兼顾技术创新和教育同理性的工具，改善编程教育体验和学习效果。

Method: 设计了一个AI-Python聊天机器人，融合静态代码分析、动态执行追踪及大语言模型（CodeLlama嵌入，GPT-4对话），配合Docker沙箱实现安全的代码运行。通过混合方法评估，分析1500名学生提交的数据，涵盖定量和定性反馈。

Result: 机器人实现了85%的错误解决率，优于pylint（62%）和GPT-4（73%）；用户调试时间减少了59.3%；学生编程能力提升34%，主要在递归和异常处理方面。120名学生反馈认为机器人指导清晰，易于使用，并提升了信心，但也指出偶尔延迟和代码审查过于严格。

Conclusion: 本文提出的AI聊天机器人能有效帮助学生编程学习，通过技术和教育的结合，促进理解和能力提升，强调教育公平与技能保留，为AI辅助教学提供了实用范例和参考蓝图。

Abstract: This is the study that presents an AI-Python-based chatbot that helps
students to learn programming by demonstrating solutions to such problems as
debugging errors, solving syntax problems or converting abstract theoretical
concepts to practical implementations. Traditional coding tools like Integrated
Development Environments (IDEs) and static analyzers do not give robotic help
while AI-driven code assistants such as GitHub Copilot focus on getting things
done. To close this gap, our chatbot combines static code analysis, dynamic
execution tracing, and large language models (LLMs) to provide the students
with relevant and practical advice, hence promoting the learning process. The
chatbots hybrid architecture employs CodeLlama for code embedding, GPT-4 for
natural language interactions, and Docker-based sandboxing for secure
execution. Evaluated through a mixed-methods approach involving 1,500 student
submissions, the system demonstrated an 85% error resolution success rate,
outperforming standalone tools like pylint (62%) and GPT-4 (73%). Quantitative
results revealed a 59.3% reduction in debugging time among users, with pre- and
post-test assessments showing a 34% improvement in coding proficiency,
particularly in recursion and exception handling. Qualitative feedback from 120
students highlighted the chatbots clarity, accessibility, and
confidence-building impact, though critiques included occasional latency and
restrictive code sanitization. By balancing technical innovation with
pedagogical empathy, this research provides a blueprint for AI tools that
prioritize educational equity and long-term skill retention over mere code
completion. The chatbot exemplifies how AI can augment human instruction,
fostering deeper conceptual understanding in programming education.

</details>


### [11] [PromptDebt: A Comprehensive Study of Technical Debt Across LLM Projects](https://arxiv.org/abs/2509.20497)
*Ahmed Aljohani,Hyunsook Do*

Main category: cs.SE

TL;DR: 首次系统实证分析LLM技术债务来源及类型。OpenAI与LangChain集成最常见，Prompt设计问题高发，指令清晰度和范例质量至关重要。发布数据集和实践建议有助于社区管理和减轻技术债务。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）通过API嵌入软件，带来了强大的AI功能，但也引入了独特的技术债务（SATD）。目前缺乏关于LLM相关技术债务的系统研究。

Method: 作者对93,142个Python文件采用大规模实证分析，聚焦主流LLM API（如OpenAI和LangChain），并分析SATD的来源、流行程度及应对策略。

Result: OpenAI集成产生了54.49%的技术债务，LangChain产生了12.35%。其中，Prompt设计是技术债务的主要来源（6.61%与Prompt配置和优化相关），其次是超参数调整和LLM框架集成。说明基于指令的Prompt（38.60%）、少样本Prompt（18.13%）最容易引入债务。作者还发布了SATD数据集以支持可重复性和实践指导。

Conclusion: LLM在软件集成中的技术债务普遍且具体，Prompt设计尤其应重视。面向开发者，需关注Prompt配置、范例质量及指令明确性，合理规划可降低技术债务。数据集发布促进社区理解和解决相关问题。

Abstract: Large Language Models (LLMs) are increasingly embedded in software via APIs
like OpenAI, offering powerful AI features without heavy infrastructure. Yet
these integrations bring their own form of self-admitted technical debt (SATD).
In this paper, we present the first large-scale empirical study of LLM-specific
SATD: its origins, prevalence, and mitigation strategies. By analyzing 93,142
Python files across major LLM APIs, we found that 54.49% of SATD instances stem
from OpenAI integrations and 12.35% from LangChain use. Prompt design emerged
as the primary source of LLM-specific SATD, with 6.61% of debt related to
prompt configuration and optimization issues, followed by hyperparameter tuning
and LLM-framework integration. We further explored which prompt techniques
attract the most debt, revealing that instruction-based prompts (38.60%) and
few-shot prompts (18.13%) are particularly vulnerable due to their dependence
on instruction clarity and example quality. Finally, we release a comprehensive
SATD dataset to support reproducibility and offer practical guidance for
managing technical debt in LLM-powered systems.

</details>


### [12] [Enhancing LLM-based Fault Localization with a Functionality-Aware Retrieval-Augmented Generation Framework](https://arxiv.org/abs/2509.20552)
*Xinyu Shi,Zhenhao Li,An Ran Chen*

Main category: cs.SE

TL;DR: 作者提出FaR-Loc，结合LLM和检索增强技术，实现更高效的方法级故障定位。在Defects4J数据集上，准确率显著优于主流方法，并且通过代码结构嵌入能进一步提升性能，为软件调试提供了强有力的技术支持。


<details>
  <summary>Details</summary>
Motivation: 故障定位是软件调试中关键但耗时的任务。尽管大型语言模型（LLM）在这一方向取得了进展，但面对复杂系统时，由于缺乏项目信息和难以在大型项目中导航，故障定位效果有限。作者希望解决LLM在项目特定知识获取、复杂项目故障定位上的局限。

Method: 提出FaR-Loc框架，通过结合LLM和检索增强生成（RAG）提升方法级故障定位。框架包括LLM功能提取、语义密集检索和LLM重排序三大核心步骤。首先，LLM提取失败测试及堆栈跟踪的行为描述；然后，使用预训练代码理解编码器将描述和方法嵌入同一语义空间，检索功能相似的方法；最后，由LLM对检索结果进行上下文相关性排序。

Result: FaR-Loc在Defects4J数据集上，Top-1准确率分别超越SoapFL和AutoFL 14.6%和9.1%，Top-5准确率超越19.2%和22.1%。在所有Top-N评价指标上，均优于现有学习型和光谱型方法，无需再次训练。此外，如UniXcoder等包含代码结构的嵌入模型，可将Top-1准确率提升49.0%。通过案例研究验证了FaR-Loc的有效性。

Conclusion: FaR-Loc显著提升了LLM在复杂项目中的故障定位性能，无需重新训练，且代码结构嵌入能进一步增强效果，对实际软件调试具有应用价值。

Abstract: Fault localization (FL) is a critical but time-consuming task in software
debugging, aiming to identify faulty code elements. While recent advances in
large language models (LLMs) have shown promise for FL, they often struggle
with complex systems due to the lack of project-specific knowledge and the
difficulty of navigating large projects. To address these limitations, we
propose FaR-Loc, a novel framework that enhances method-level FL by integrating
LLMs with retrieval-augmented generation (RAG). FaR-Loc consists of three key
components: LLM Functionality Extraction, Semantic Dense Retrieval, and LLM
Re-ranking. First, given a failed test and its associated stack trace, the LLM
Functionality Extraction module generates a concise natural language
description that captures the failing behavior. Next, the Semantic Dense
Retrieval component leverages a pre-trained code-understanding encoder to embed
both the functionality description (natural language) and the covered methods
(code) into a shared semantic space, enabling the retrieval of methods with
similar functional behavior. Finally, the LLM Re-ranking module reorders the
retrieved methods based on their contextual relevance. Our experiments on the
widely used Defects4J benchmark show that FaR-Loc outperforms state-of-the-art
LLM-based baselines SoapFL and AutoFL, by 14.6% and 9.1% in Top-1 accuracy, by
19.2% and 22.1% in Top-5 accuracy, respectively. It also surpasses all
learning-based and spectrum-based baselines across all Top-N metrics without
requiring re-training. Furthermore, we find that pre-trained code embedding
models that incorporate code structure, such as UniXcoder, can significantly
improve fault localization performance by up to 49.0% in Top-1 accuracy.
Finally, we conduct a case study to illustrate the effectiveness of FaR-Loc and
to provide insights for its practical application.

</details>


### [13] [Design, Implementation and Evaluation of a Novel Programming Language Topic Classification Workflow](https://arxiv.org/abs/2509.20631)
*Michael Zhang,Yuan Tian,Mariam Guizani*

Main category: cs.SE

TL;DR: 提出了一种结合多标签SVM及滑动窗口投票策略的源码语言主题细粒度分析方法，实验效果优异，为代码分析提供了一条高效可靠的技术路线。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统规模和复杂性的增长，准确理解源码中编程语言主题的分布对于技术决策、员工培训及工具开发变得越来越重要。

Method: 文中设计并实现了一种新颖的编程语言主题分类流程，结合多标签支持向量机（SVM）、滑动窗口和投票策略，实现对源码中核心语言概念的细粒度定位。

Result: 在IBM Project CodeNet数据集上训练后，模型在主题分类的平均F1分数为0.90，在代码-主题高亮的F1分数为0.75。

Conclusion: 该研究为代码分析与数据驱动软件工程提供了有价值的实证见解和可复用的流程工具，对相关领域的研究人员和从业者具有实际意义。

Abstract: As software systems grow in scale and complexity, understanding the
distribution of programming language topics within source code becomes
increasingly important for guiding technical decisions, improving onboarding,
and informing tooling and education. This paper presents the design,
implementation, and evaluation of a novel programming language topic
classification workflow. Our approach combines a multi-label Support Vector
Machine (SVM) with a sliding window and voting strategy to enable fine-grained
localization of core language concepts such as operator overloading, virtual
functions, inheritance, and templates. Trained on the IBM Project CodeNet
dataset, our model achieves an average F1 score of 0.90 across topics and 0.75
in code-topic highlight. Our findings contribute empirical insights and a
reusable pipeline for researchers and practitioners interested in code analysis
and data-driven software engineering.

</details>


### [14] [Exploring Engagement in Hybrid Meetings](https://arxiv.org/abs/2509.20780)
*Daniela Grassi,Fabio Calefato,Darja Smite,Nicole Novielli,Filippo Lanubile*

Main category: cs.SE

TL;DR: 通过客观测量发现：远程成员长会议参与度较低，积极发言和小型早间会议更能提升参与度，结果为优化混合团队协作和会议管理提供科学依据。


<details>
  <summary>Details</summary>
Motivation: 疫情后，混合办公成为软件开发的新常态，但远程团队成员可能由于远程参与会议而产生孤立感和低参与度。现有认知对混合会议中参与度的客观测量有限，尤其关注远程与现场之间的差异。

Method: 研究跟踪了三家软件公司的专业人员，采用多模态方法，包括自我报告问卷和生理生物测量（使用生物特征设备）来客观测量混合会议中的参与度。

Result: 回归分析显示，现场与远程参与者的总体参与度相当，但远程参与者在长时间会议中无论模式均表现出较低参与度。主动角色与更高参与度正相关，大型会议和下午举行的会议则与低参与度相关。

Conclusion: 本研究揭示了混合会议中影响参与度的因素，为会议改进和团队协作提出了建议，对软件领域及其他知识密集型行业的混合协作均有参考价值。

Abstract: Background. The widespread adoption of hybrid work following the COVID-19
pandemic has fundamentally transformed software development practices,
introducing new challenges in communication and collaboration as organizations
transition from traditional office-based structures to flexible working
arrangements. This shift has established a new organizational norm where even
traditionally office-first companies now embrace hybrid team structures. While
remote participation in meetings has become commonplace in this new
environment, it may lead to isolation, alienation, and decreased engagement
among remote team members. Aims. This study aims to identify and characterize
engagement patterns in hybrid meetings through objective measurements, focusing
on the differences between co-located and remote participants. Method. We
studied professionals from three software companies over several weeks,
employing a multimodal approach to measure engagement. Data were collected
through self-reported questionnaires and physiological measurements using
biometric devices during hybrid meetings to understand engagement dynamics.
Results. The regression analyses revealed comparable engagement levels between
onsite and remote participants, though remote participants show lower
engagement in long meetings regardless of participation mode. Active roles
positively correlate with higher engagement, while larger meetings and
afternoon sessions are associated with lower engagement. Conclusions. Our
results offer insights into factors associated with engagement and
disengagement in hybrid meetings, as well as potential meeting improvement
recommendations. These insights are potentially relevant not only for software
teams but also for knowledge-intensive organizations across various sectors
facing similar hybrid collaboration challenges.

</details>


### [15] [Verification Limits Code LLM Training](https://arxiv.org/abs/2509.20837)
*Srishti Gureja,Elena Tommasone,Jingyi He,Sara Hooker,Matthias Gallé,Marzieh Fadaee*

Main category: cs.SE

TL;DR: 论文指出当前用于代码生成大语言模型训练的合成数据中，验证策略过于严格导致训练数据多样性受限，从而影响模型性能。通过提升测试多样性、放宽通过标准、采用软验证和保留多样正确方案，可以显著提升模型表现。作者建议重新调整验证流程，突破验证上限以打造更强大的代码生成模型。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在代码生成领域的广泛应用，模型日益依赖合成数据（包括自动生成的问题解决方案和验证测试），但合成验证能力限制了数据质量和多样性，形成所谓的“验证上限”。该工作旨在系统研究验证设计与策略如何影响代码大模型性能。

Method: 通过系统性实验，作者研究了：（1）测试用例复杂性和数量对模型训练的影响；（2）不同的代码通过标准（如放宽100%通过门槛，采用软验证方式）对训练数据回收和模型表现的作用；（3）对正式正确和错误解决方案的对比，以及人类评估结果，以分析保留多样正确答案对模型泛化性能的意义。

Result: 研究发现：（1）丰富的测试用例集提升代码生成能力，但仅增加数量效果递减；（2）放宽验证门槛或加入软验证能有效回收优质训练数据，性能提升2-4pp（pass@1指标）；（3）保留每个问题多样的正确解决方案能持续提升模型泛化性能。过于严格的验证流程过滤了有价值的多样性，但验证仍不可或缺，需精准调校。

Conclusion: 严格的合成验证限制了模型训练数据的质量和多样性，成为大语言模型代码生成能力提升的瓶颈。合理调整验证策略并保留多样、挑战性强的样本，是突破“验证上限”、提升模型能力的关键路径。

Abstract: Large language models for code generation increasingly rely on synthetic
data, where both problem solutions and verification tests are generated by
models. While this enables scalable data creation, it introduces a previously
unexplored bottleneck: the verification ceiling, in which the quality and
diversity of training data are fundamentally constrained by the capabilities of
synthetic verifiers. In this work, we systematically study how verification
design and strategies influence model performance. We investigate (i) what we
verify by analyzing the impact of test complexity and quantity: richer test
suites improve code generation capabilities (on average +3 pass@1), while
quantity alone yields diminishing returns, (ii) how we verify by exploring
relaxed pass thresholds: rigid 100% pass criteria can be overly restrictive. By
allowing for relaxed thresholds or incorporating LLM-based soft verification,
we can recover valuable training data, leading to a 2-4 point improvement in
pass@1 performance. However, this benefit is contingent upon the strength and
diversity of the test cases used, and (iii) why verification remains necessary
through controlled comparisons of formally correct versus incorrect solutions
and human evaluation: retaining diverse correct solutions per problem yields
consistent generalization gains. Our results show that Verification as
currently practiced is too rigid, filtering out valuable diversity. But it
cannot be discarded, only recalibrated. By combining calibrated verification
with diverse, challenging problem-solution pairs, we outline a path to break
the verification ceiling and unlock stronger code generation models.

</details>


### [16] [PseudoBridge: Pseudo Code as the Bridge for Better Semantic and Logic Alignment in Code Retrieval](https://arxiv.org/abs/2509.20881)
*Yixuan Li,Xinyi Liu,Weidong Yang,Ben Fei,Shuhao Li,Mingjie Zhou,Lipeng Ma*

Main category: cs.SE

TL;DR: 本文提出PseudoBridge将伪代码作为自然语言和代码之间的桥梁，通过显式逻辑对齐和多风格代码增强，显著提升代码检索准确率和泛化能力，优于现有方法，适用于多编程语言和零样本迁移场景。


<details>
  <summary>Details</summary>
Motivation: 代码检索任务面临着自然语言与编程语言之间的语义鸿沟，以及对多样代码风格的鲁棒性不足的问题。

Method: 提出了PseudoBridge框架，采用伪代码作为自然语言与代码之间的中间表示，通过LLM生成伪代码和多样化代码风格的实现，增强语义对齐和模型鲁棒性。分两阶段：第一阶段生成伪代码以对齐查询和伪代码，第二阶段通过逻辑不变的代码风格增强并与伪代码对齐。

Result: 在10种PLMs和6种主流编程语言上进行了评估。实验结果显示PseudoBridge在检索准确率和泛化能力上均优于基线，尤其是在零样本域迁移如Solidity和XLCoST数据集上效果显著。

Conclusion: 通过伪代码实现的显式逻辑对齐，有效提升了代码检索的准确率和泛化能力，PseudoBridge展现了其作为健壮且可泛化代码检索方案的潜力。

Abstract: Code search aims to precisely find relevant code snippets that match natural
language queries within massive codebases, playing a vital role in software
development. Recent advances leverage pre-trained language models (PLMs) to
bridge the semantic gap between unstructured natural language (NL) and
structured programming languages (PL), yielding significant improvements over
traditional information retrieval and early deep learning approaches. However,
existing PLM-based methods still encounter key challenges, including a
fundamental semantic gap between human intent and machine execution logic, as
well as limited robustness to diverse code styles. To address these issues, we
propose PseudoBridge, a novel code retrieval framework that introduces
pseudo-code as an intermediate, semi-structured modality to better align NL
semantics with PL logic. Specifically, PseudoBridge consists of two stages.
First, we employ an advanced large language model (LLM) to synthesize
pseudo-code, enabling explicit alignment between NL queries and pseudo-code.
Second, we introduce a logic-invariant code style augmentation strategy and
employ the LLM to generate stylistically diverse yet logically equivalent code
implementations with pseudo-code, then align the code snippets of different
styles with pseudo-code, enhancing model robustness to code style variation. We
build PseudoBridge across 10 different PLMs and evaluate it on 6 mainstream
programming languages. Extensive experiments demonstrate that PseudoBridge
consistently outperforms baselines, achieving significant gains in retrieval
accuracy and generalization, particularly under zero-shot domain transfer
scenarios such as Solidity and XLCoST datasets. These results demonstrate the
effectiveness of explicit logical alignment via pseudo-code and highlight
PseudoBridge's potential as a robust, generalizable solution for code
retrieval.

</details>


### [17] [Designing for Novice Debuggers: A Pilot Study on an AI-Assisted Debugging Tool](https://arxiv.org/abs/2509.21067)
*Oka Kurniawan,Erick Chandra,Christopher M. Poskitt,Yannic Noller,Kenny Tsu Wei Choo,Cyrille Jegourel*

Main category: cs.SE

TL;DR: 本文提出了一种结合传统方法与AI的调试工具CodeHinter，增强了新手程序员的主动调试能力，经学生测试后证明有效且易用，强调工具应个性化设计以提升用户体验。


<details>
  <summary>Details</summary>
Motivation: 新手程序员在调试代码时需要掌握基本的调试技能，但现有许多自动修正工具可能导致他们过度依赖AI，缺乏主动参与调试过程。

Method: 设计并优化了结合传统调试工具与大型语言模型（LLM）辅助的调试助手CodeHinter，通过第二次设计迭代，与本科生进行用户测试，分析其在修正语义错误方面的有效性及易用性。

Result: 学生认为该工具在修复语义错误时非常有效，较第一版更易用，并且错误定位功能仍然是最有价值的部分。

Conclusion: AI辅助调试工具应根据用户特征进行个性化，以优化师生的交互体验。

Abstract: Debugging is a fundamental skill that novice programmers must develop.
Numerous tools have been created to assist novice programmers in this process.
Recently, large language models (LLMs) have been integrated with automated
program repair techniques to generate fixes for students' buggy code. However,
many of these tools foster an over-reliance on AI and do not actively engage
students in the debugging process. In this work, we aim to design an intuitive
debugging assistant, CodeHinter, that combines traditional debugging tools with
LLM-based techniques to help novice debuggers fix semantic errors while
promoting active engagement in the debugging process. We present findings from
our second design iteration, which we tested with a group of undergraduate
students. Our results indicate that the students found the tool highly
effective in resolving semantic errors and significantly easier to use than the
first version. Consistent with our previous study, error localization was the
most valuable feature. Finally, we conclude that any AI-assisted debugging tool
should be personalized based on user profiles to optimize their interactions
with students.

</details>


### [18] [An Improved Quantum Software Challenges Classification Approach using Transfer Learning and Explainable AI](https://arxiv.org/abs/2509.21068)
*Nek Dil Khan,Javed Ali Khan,Mobashir Husain,Muhammad Sohail Khan,Arif Ali Khan,Muhammad Azeem Akbar,Shahid Hussain*

Main category: cs.SE

TL;DR: 本研究归类并分析了量子软件工程领域开发者在Q&A平台上的常见挑战，建立了标注数据集。以微调的BERT等Transformer模型自动分类，准确率达到95%，大幅优于传统深度学习方法。采用SHAP增强模型解释性，有助于改进论坛讨论组织，但需更多实证研究验证。


<details>
  <summary>Details</summary>
Motivation: 量子软件工程（QSE）是一个新兴领域，量子开发者在优化量子计算与QSE相关概念时面临众多挑战。他们在Stack Overflow等平台上讨论问题，但现有标签往往更偏向技术细节，缺乏对开发者实际困难的细致归类。研究旨在通过对讨论内容按量子概念分类，帮助识别常见QSE挑战，提升论坛组织和可读性。

Method: 研究从多个Q&A平台收集了2829条带有量子相关标签的问题，通过内容分析和新颖的扎根理论，针对“工具、理论、学习、概念、错误、API使用”等挑战进行分类，并建立了一个标注好的数据集。使用ChatGPT辅助人类标注员进行标注和分歧解决。接着，利用微调的Transformer算法（如BERT、DistilBERT、RoBERTa）对问题进行自动分类，并与传统深度学习模型（FNN、CNN、LSTM）进行比较。同时，采用SHAP工具揭示模型的语言特征解释。

Result: Transformer类模型（BERT和DistilBERT）在分类挑战问题上取得了平均95%的准确率，显著高于FNN（89%）、CNN（86%）和LSTM（84%），无需数据增强便提升6%的准确率。SHAP分析增强了模型解释性，揭示语言特征如何影响预测。

Conclusion: 基于Transformer的自动分类方法能有效提升量子软件工程问题的识别准确率和透明性，可帮助厂商和论坛更好地组织和呈现讨论内容。不过，仍需结合真实开发者和厂商开展实证评估研究。

Abstract: Quantum Software Engineering (QSE) is a research area practiced by tech
firms. Quantum developers face challenges in optimizing quantum computing and
QSE concepts. They use Stack Overflow (SO) to discuss challenges and label
posts with specialized quantum tags, which often refer to technical aspects
rather than developer posts. Categorizing questions based on quantum concepts
can help identify frequent QSE challenges. We conducted studies to classify
questions into various challenges. We extracted 2829 questions from Q&A
platforms using quantum-related tags. Posts were analyzed to identify frequent
challenges and develop a novel grounded theory. Challenges include Tooling,
Theoretical, Learning, Conceptual, Errors, and API Usage. Through content
analysis and grounded theory, discussions were annotated with common challenges
to develop a ground truth dataset. ChatGPT validated human annotations and
resolved disagreements. Fine-tuned transformer algorithms, including BERT,
DistilBERT, and RoBERTa, classified discussions into common challenges. We
achieved an average accuracy of 95% with BERT DistilBERT, compared to
fine-tuned Deep and Machine Learning (D&ML) classifiers, including Feedforward
Neural Networks (FNN), Convolutional Neural Networks (CNN), and Long Short-Term
Memory networks (LSTM), which achieved accuracies of 89%, 86%, and 84%,
respectively. The Transformer-based approach outperforms the D&ML-based
approach with a 6\% increase in accuracy by processing actual discussions,
i.e., without data augmentation. We applied SHAP (SHapley Additive
exPlanations) for model interpretability, revealing how linguistic features
drive predictions and enhancing transparency in classification. These findings
can help quantum vendors and forums better organize discussions for improved
access and readability. However,empirical evaluation studies with actual
developers and vendors are needed.

</details>


### [19] [Fine-Tuning LLMs to Analyze Multiple Dimensions of Code Review: A Maximum Entropy Regulated Long Chain-of-Thought Approach](https://arxiv.org/abs/2509.21170)
*Yongda Yu,Guohao Shi,Xianwei Wu,Haochuan He,XueMing Gu,Qianqian Zhao,Kui Liu,Qiushi Wang,Zhao Tian,Haifeng Shen,Guoping Rong*

Main category: cs.SE

TL;DR: 本文提出的MelcotCR通过链式思考微调和最大熵模型原理，有效增强了低参数量模型在代码审查的准确性和推理能力，达到与超大模型媲美的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在自动化代码审查方面展现出巨大潜力，但其能力受训练数据限制，难以达到人类认知水平。现有方法多利用有限或模糊信息进行微调，未能充分发挥模型多维度代码分析潜力。

Method: 提出了MelcotCR，一种基于链式思考（Chain-of-Thought, COT）的微调方法，通过利用长链式思考技术提供丰富结构化信息，并结合最大熵（Maximum Entropy, ME）模型原理和预定义推理路径，解决模型在处理长COT提示时的上下文和逻辑损失问题。

Result: 在自建MelcotCR数据集和公开CodeReviewer数据集上进行实证评估，发现用MelcotCR微调后的低参数量模型（如14B Qwen2.5）在检测和描述代码问题的准确性方面，优于现有最先进方法，并且表现与超大模型（671B DeepSeek-R1）接近。

Conclusion: MelcotCR显著增强了模型多维度代码审查与推理能力，使小模型能在代码问题检测和描述方面达到甚至超越大模型的效果。

Abstract: Large Language Models (LLMs) have shown great potential in supporting
automated code review due to their impressive capabilities in context
understanding and reasoning. However, these capabilities are still limited
compared to human-level cognition because they are heavily influenced by the
training data. Recent research has demonstrated significantly improved
performance through fine-tuning LLMs with code review data. However, compared
to human reviewers who often simultaneously analyze multiple dimensions of code
review to better identify issues, the full potential of these methods is
hampered by the limited or vague information used to fine-tune the models. This
paper contributes MelcotCR, a chain-of-thought (COT) fine-tuning approach that
trains LLMs with an impressive reasoning ability to analyze multiple dimensions
of code review by harnessing long COT techniques to provide rich structured
information. To address context loss and reasoning logic loss issues that
frequently occur when LLMs process long COT prompts, we propose a solution that
combines the Maximum Entropy (ME) modeling principle with pre-defined reasoning
pathways in MelcotCR to enable more effective utilization of in-context
knowledge within long COT prompts while strengthening the logical tightness of
the reasoning process. Empirical evaluations on our curated MelcotCR dataset
and the public CodeReviewer dataset reveal that a low-parameter base model,
such as 14B Qwen2.5, fine-tuned with MelcotCR can surpass state-of-the-art
methods in terms of the accuracy of detecting and describing code issues, with
its performance remarkably on par with that of the 671B DeepSeek-R1 model.

</details>


### [20] [Semantic Clustering of Civic Proposals: A Case Study on Brazil's National Participation Platform](https://arxiv.org/abs/2509.21292)
*Ronivaldo Ferreira,Guilherme da Silva,Carla Rocha,Gustavo Pinto*

Main category: cs.SE

TL;DR: 作者提出了一种基于BERTopic、种子词和大语言模型的方法，实现了对数字平台公众意见的高效自动化归类，有助于政府高效利用公民参与数据。


<details>
  <summary>Details</summary>
Motivation: 数字平台如Brasil Participativo上的公众参与日益重要，但参与量巨大导致相关建议常被忽略，因为组织和归类这些建议面临若干挑战：手工分类无法扩展、需要专家参与、还需与官方分类体系一致。

Method: 提出了一种结合BERTopic、种子词以及由大型语言模型自动验证的方法，实现自动化且高效的话题归类。

Result: 初步结果显示，所生成的话题具有连贯性，并且能够与官方分类体系保持一致，同时极大地减少了人工工作量。

Conclusion: 该方法可以帮助政府将大量的公众意见转化为可用于公共政策制定的可操作数据，有效提升数字平台上的公民参与价值。

Abstract: Promoting participation on digital platforms such as Brasil Participativo has
emerged as a top priority for governments worldwide. However, due to the sheer
volume of contributions, much of this engagement goes underutilized, as
organizing it presents significant challenges: (1) manual classification is
unfeasible at scale; (2) expert involvement is required; and (3) alignment with
official taxonomies is necessary. In this paper, we introduce an approach that
combines BERTopic with seed words and automatic validation by large language
models. Initial results indicate that the generated topics are coherent and
institutionally aligned, with minimal human effort. This methodology enables
governments to transform large volumes of citizen input into actionable data
for public policy.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [21] [A Unified Formal Theory on the Logical Limits of Symbol Grounding](https://arxiv.org/abs/2509.20409)
*Zhangchi Liu*

Main category: cs.LO

TL;DR: 该论文通过形式证明，系统论证了符号系统内部无法自洽赋予意义，符号与意义的连接必须依赖外部、开放、非算法化过程，任何企图自动化该过程只会导致新的不完备性。这揭示了自洽智能系统在意义获取上的根本限制。


<details>
  <summary>Details</summary>
Motivation: 符号基础问题探讨的是形式系统如何赋予符号以实际意义，该问题在人工智能和认知科学中至关重要。过去的理论和技术尝试多集中于算法内部解决符号与意义的连接，该论文试图通过形式证明的方式，系统厘定了符号基础问题的逻辑界限。

Method: 作者通过一系列形式证明，分四个阶段逐步论证，包含对纯符号系统、本体意义设定、符号外部连接及自动化判断的严密分析。每一步都基于逻辑和集合论原理，旨在证明符号系统内部无法自洽建立意义，必须依赖外部非算法性过程。

Result: 证明了纯符号系统由于自指悖论无法自洽确立意义；扩展证明有限静态意义设定的系统必然不完备；符号到外部意义的连接不能依赖系统逻辑推断，而需元层级的公理性更新；任何试图用固定外部算法自动化该更新过程最终只能构建规模更大但同样不完备的符号系统。

Conclusion: 意义的获取本质上需开放性、非算法性的外部过程，任何封闭、自洽的智能系统在意义基础上都存在类似哥德尔不完备性限制，符号基础问题逻辑极限得以形式化确立。

Abstract: This paper synthesizes a series of formal proofs to construct a unified
theory on the logical limits of the Symbol Grounding Problem. We demonstrate
through a four-stage argument that meaning within a formal system must arise
from a process that is external, dynamic, and non-algorithmic. First, we prove
that any purely symbolic system, devoid of external connections, cannot
internally establish a consistent foundation for meaning due to
self-referential paradoxes. Second, we extend this limitation to systems with
any finite, static set of pre-established meanings, proving they are inherently
incomplete. Third, we demonstrate that the very "act" of connecting an internal
symbol to an external meaning cannot be a product of logical inference within
the system but must be an axiomatic, meta-level update. Finally, we prove that
any attempt to automate this update process using a fixed, external "judgment"
algorithm will inevitably construct a larger, yet equally incomplete, symbolic
system. Together, these conclusions formally establish that the grounding of
meaning is a necessarily open-ended, non-algorithmic process, revealing a
fundamental, G\"odel-style limitation for any self-contained intelligent
system.

</details>


### [22] [Reverse Faà di Bruno's Formula for Cartesian Reverse Differential Categories](https://arxiv.org/abs/2509.20931)
*Aaron Biggin,Jean-Simon Pacaud Lemay*

Main category: cs.LO

TL;DR: 本文推广了Faà di Bruno公式到范畴论的反向微分情境，构建了高阶反向链式法则，对高阶自动微分理论发展具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 反向微分是自动微分中的关键操作，但其高阶版本在范畴论框架下的理论尚不完善。当前范畴中的高阶反向链式法则缺失，限制了后续研究和应用。

Method: 作者将Faà di Bruno公式进行反向微分推广，在Cartesian逆微分范畴中定义了偏反向微分和高阶反向微分，并严格表述和证明了高阶反向链式法则。

Result: 提出了Faà di Bruno反向微分公式，建立了高阶反向链式法则的范畴论版本，并系统定义了相关数学对象。为自动微分在理论和实际应用中处理高阶微分提供了坚实基础。

Conclusion: 论文为范畴论中的反向微分理论补充了重要高阶法则，为相关领域的后续研究和深度学习等应用提供了更强有力的理论工具。

Abstract: Reverse differentiation is an essential operation for automatic
differentiation. Cartesian reverse differential categories axiomatize reverse
differentiation in a categorical framework, where one of the primary axioms is
the reverse chain rule, which is the formula that expresses the reverse
derivative of a composition. Here, we present the reverse differential analogue
of Faa di Bruno's Formula, which gives a higher-order reverse chain rule in a
Cartesian reverse differential category. To properly do so, we also define
partial reverse derivatives and higher-order reverse derivatives in a Cartesian
reverse differential category.

</details>


### [23] [A Coalgebraic Model of Quantum Bisimulation](https://arxiv.org/abs/2509.20933)
*Lorenzo Ceragioli,Elena Di Lavore,Giuseppe Lomurno,Gabriele Tedeschi*

Main category: cs.LO

TL;DR: 本文提出了一种统一描述量子系统概率行为的余代数理论，通过分级幺半范畴和 kernel 互模拟刻画量子系统在不同输入状态下的等价性，并发展了适用于量子输入参数化的行为理论操作符，为量子过程演算的语义提供理论基础。


<details>
  <summary>Details</summary>
Motivation: 在量子系统中定义与观测性质匹配的行为等价性非常困难，尤其是在并发、非确定性和受量子效应影响的情境下。因此，作者希望提出统一刻画此类系统概率性行为的理论框架，并明确刻画量子输入状态对系统行为的影响。

Method: 作者通过研究加权取自一般效应代数（能够涵盖概率和量子效应）的分布余代数结构，提出基于部分交换幺半群分级的幺半范畴，确保遵守量子理论中的 no-cloning 原理。并对比了 Aczel-Mendler 和 kernel 式互模拟，进一步为量子效应带标签的转移系统定义操作符。

Result: 作者揭示了量子系统及其对应具体量子输入实例化后的概率系统之间的关系，强调 kernel 互模拟能刻画所有输入状态下概率行为相同的量子系统，并提出了适用于参数化量子输入的行为理论运算符。

Conclusion: 文中为量子输入参数化过程演算奠定了量子行为等价性的理论基础，拓展了量子系统行为建模的工具箱，并强调 kernel 互模拟在区分量子系统概率行为中的优势。

Abstract: Recent works have shown that defining a behavioural equivalence that matches
the observational properties of a quantum-capable, concurrent,
non-deterministic system is a surprisingly difficult task. We explore
coalgebras over distributions taking weights from a generic effect algebra,
which subsumes probabilities and quantum effects, a physical formalism that
represents the probabilistic behaviour of an open quantum system. To abide by
the properties of quantum theory, we introduce monads graded on a partial
commutative monoid, intuitively allowing composition of two processes only if
they use different quantum resources, as prescribed by the no-cloning theorem.
We investigate the relation between an open quantum system and its
probabilistic counterparts obtained when instantiating the input with a
specific quantum state. We consider Aczel-Mendler and kernel bisimilarities,
advocating for the latter as it characterizes quantum systems that exhibit the
same probabilistic behaviour for all input states. Finally, we propose
operators on quantum effect labelled transition systems, paving the way for a
process calculi semantics that is parametric over the quantum input.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [24] [Interpreting Public Sentiment in Diplomacy Events: A Counterfactual Analysis Framework Using Large Language Models](https://arxiv.org/abs/2509.20367)
*Leyi Ouyang*

Main category: cs.CL

TL;DR: 该论文提出了一种用大模型与专家知识指导，只需改写外交事件描述即可有效提升公众的正面情绪，实验证明成功率高达70%，为外交文本塑造和政策传播提供了实用工具。


<details>
  <summary>Details</summary>
Motivation: 传统舆情分析方法效率低，耗时长且难以前瞻性地引导舆论，亟需一种智能高效、可实际应用的方法来指导外交文本的正向舆情塑造。

Method: 构建了外交事件及其公众讨论的数据集，并训练了语言模型预测公众反应。基于传播理论和专家指导，预设需修改的文本特征，然后利用大型语言模型生成系统性改写文本，检验叙述调整对公众情绪的影响。

Result: 该框架能以70%的成功率将公众情感从负面转为中性或正面，验证了方法的有效性。

Conclusion: 提出的方法能够帮助外交官及相关决策者有效调整外交事件的叙述方式，从而促进公众对外交事件的正面情感反应。

Abstract: Diplomatic events consistently prompt widespread public discussion and
debate. Public sentiment plays a critical role in diplomacy, as a good
sentiment provides vital support for policy implementation, helps resolve
international issues, and shapes a nation's international image. Traditional
methods for gauging public sentiment, such as large-scale surveys or manual
content analysis of media, are typically time-consuming, labor-intensive, and
lack the capacity for forward-looking analysis. We propose a novel framework
that identifies specific modifications for diplomatic event narratives to shift
public sentiment from negative to neutral or positive. First, we train a
language model to predict public reaction towards diplomatic events. To this
end, we construct a dataset comprising descriptions of diplomatic events and
their associated public discussions. Second, guided by communication theories
and in collaboration with domain experts, we predetermined several textual
features for modification, ensuring that any alterations changed the event's
narrative framing while preserving its core facts.We develop a counterfactual
generation algorithm that employs a large language model to systematically
produce modified versions of an original text. The results show that this
framework successfully shifted public sentiment to a more favorable state with
a 70\% success rate. This framework can therefore serve as a practical tool for
diplomats, policymakers, and communication specialists, offering data-driven
insights on how to frame diplomatic initiatives or report on events to foster a
more desirable public sentiment.

</details>


### [25] [Speaker Style-Aware Phoneme Anchoring for Improved Cross-Lingual Speech Emotion Recognition](https://arxiv.org/abs/2509.20373)
*Shreya G. Upadhyay,Carlos Busso,Chi-Chun Lee*

Main category: cs.CL

TL;DR: 提出了说话人风格感知音素锚定方法，通过聚类构建说话人社区，并在双空间实现情感对齐，在跨语言语音情感识别任务中取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 跨语言语音情感识别面临声学和说话人表达风格差异带来的挑战，导致情感难以一致捕捉。本文旨在提出一种新方法以更好地跨说话人和语言对齐情感表达。

Method: 提出了一种说话人风格感知的音素锚定框架。首先通过基于图的聚类方法建立情感特定的说话人社区以捕捉共享说话人特性，再在说话人和音素空间进行双空间锚定，实现跨语言情感转移。

Result: 在MSP-Podcast（英语）和BIIC-Podcast（台语普通话）数据集上进行评估，结果优于现有强基线方法，显示出更好的泛化能力，并揭示了跨语言情感表达的共性特点。

Conclusion: 所提出的框架能更有效地对齐不同语言和说话人的情感表达，提升了跨语言语音情感识别的准确性和泛化性。

Abstract: Cross-lingual speech emotion recognition (SER) remains a challenging task due
to differences in phonetic variability and speaker-specific expressive styles
across languages. Effectively capturing emotion under such diverse conditions
requires a framework that can align the externalization of emotions across
different speakers and languages. To address this problem, we propose a
speaker-style aware phoneme anchoring framework that aligns emotional
expression at the phonetic and speaker levels. Our method builds
emotion-specific speaker communities via graph-based clustering to capture
shared speaker traits. Using these groups, we apply dual-space anchoring in
speaker and phonetic spaces to enable better emotion transfer across languages.
Evaluations on the MSP-Podcast (English) and BIIC-Podcast (Taiwanese Mandarin)
corpora demonstrate improved generalization over competitive baselines and
provide valuable insights into the commonalities in cross-lingual emotion
representation.

</details>


### [26] [CFD-LLMBench: A Benchmark Suite for Evaluating Large Language Models in Computational Fluid Dynamics](https://arxiv.org/abs/2509.20374)
*Nithin Somasekharan,Ling Yue,Yadi Cao,Weichao Li,Patrick Emami,Pochinapeddi Sai Bhargav,Anurag Acharya,Xingyu Xie,Shaowu Pan*

Main category: cs.CL

TL;DR: 本文提出了CFDLLMBench基准，从知识理解、物理推理和代码实现三个维度系统评估大型语言模型在计算流体力学自动化实验中的能力，并提供可用于后续研究的开源工具、代码与数据。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在通用NLP任务中表现优秀，但尚未深入探索其在自动化复杂物理系统数值实验方面的应用，而这类实验一直是计算科学中至关重要且劳动密集的工作。计算流体力学（CFD）作为主要的研究范例，为考察LLMs的科学能力提供了理想测试场。

Method: 本文提出CFDLLMBench，包含CFDQuery、CFDCodeBench和FoamBench三大组件，分别针对CFD的知识理解、数值与物理推理以及情境相关的CFD工作流实现，对LLMs进行全面评估。该基准结合任务分类和严格的评估框架，可复现并量化LLMs在代码可执行性、解答准确性和数值收敛性等方面的性能。

Result: CFDLLMBench能够系统地评估LLMs在CFD领域自动化数值实验的能力，并在实际CFD工作流程中验证了其科学推理与实现的潜力。相关代码与数据已开源发布。

Conclusion: CFDLLMBench为LLMs在复杂物理系统自动化实验的开发与评估奠定了基础，有望推动LLMs在科学实验自动化领域的应用。

Abstract: Large Language Models (LLMs) have demonstrated strong performance across
general NLP tasks, but their utility in automating numerical experiments of
complex physical system -- a critical and labor-intensive component -- remains
underexplored. As the major workhorse of computational science over the past
decades, Computational Fluid Dynamics (CFD) offers a uniquely challenging
testbed for evaluating the scientific capabilities of LLMs. We introduce
CFDLLMBench, a benchmark suite comprising three complementary components --
CFDQuery, CFDCodeBench, and FoamBench -- designed to holistically evaluate LLM
performance across three key competencies: graduate-level CFD knowledge,
numerical and physical reasoning of CFD, and context-dependent implementation
of CFD workflows. Grounded in real-world CFD practices, our benchmark combines
a detailed task taxonomy with a rigorous evaluation framework to deliver
reproducible results and quantify LLM performance across code executability,
solution accuracy, and numerical convergence behavior. CFDLLMBench establishes
a solid foundation for the development and evaluation of LLM-driven automation
of numerical experiments for complex physical systems. Code and data are
available at https://github.com/NREL-Theseus/cfdllmbench/.

</details>


### [27] [Assessing Classical Machine Learning and Transformer-based Approaches for Detecting AI-Generated Research Text](https://arxiv.org/abs/2509.20375)
*Sharanya Parimanoharan,Ruwan D. Nawarathna*

Main category: cs.CL

TL;DR: 研究比较了多种机器学习与Transformer-based模型对ChatGPT-3.5生成摘要检测能力，发现DistilBERT表现最好，集成模型未优于单一强Transformer，意义在于为更强AI文本检测工具打基础。


<details>
  <summary>Details</summary>
Motivation: 随着ChatGPT等大型语言模型的快速普及，AI生成文本与人类文本的界限变得模糊，给学术诚信、知识产权和信息误导带来挑战。因此，急需可靠的AI文本检测方法以维护公平、公正和信任。

Method: 作者构建了包含250对不同研究主题的ChatGPT-3.5生成与人类撰写摘要的数据集，采用并比较了经典机器学习（Logistic Regression配合Bag-of-Words、POS和TF-IDF特征）与多种Transformer方法（Augmented BERT N-gram、DistilBERT、BERT-Custom、LSTM N-gram模型），评估各自的检测性能，并测试模型集成（max voting ensemble）效果。

Result: DistilBERT在文本检测任务上表现最佳，Logistic Regression和BERT-Custom则较为均衡，LSTM和BERT-N-gram方法表现较差。三种最佳模型的集成未能超越DistilBERT本身，说明单一Transformer模型的优势强于多模型集成。

Conclusion: 现有方法中单一高性能Transformer架构优于模型多样性集成，本文为未来构建更大规模、多样化数据支持的强健Transformer检测框架奠定了基础，以应对生成式AI的持续进化。

Abstract: The rapid adoption of large language models (LLMs) such as ChatGPT has
blurred the line between human and AI-generated texts, raising urgent questions
about academic integrity, intellectual property, and the spread of
misinformation. Thus, reliable AI-text detection is needed for fair assessment
to safeguard human authenticity and cultivate trust in digital communication.
In this study, we investigate how well current machine learning (ML) approaches
can distinguish ChatGPT-3.5-generated texts from human-written texts employing
a labeled data set of 250 pairs of abstracts from a wide range of research
topics. We test and compare both classical (Logistic Regression armed with
classical Bag-of-Words, POS, and TF-IDF features) and transformer-based (BERT
augmented with N-grams, DistilBERT, BERT with a lightweight custom classifier,
and LSTM-based N-gram models) ML detection techniques. As we aim to assess each
model's performance in detecting AI-generated research texts, we also aim to
test whether an ensemble of these models can outperform any single detector.
Results show DistilBERT achieves the overall best performance, while Logistic
Regression and BERT-Custom offer solid, balanced alternatives; LSTM- and
BERT-N-gram approaches lag. The max voting ensemble of the three best models
fails to surpass DistilBERT itself, highlighting the primacy of a single
transformer-based representation over mere model diversity. By comprehensively
assessing the strengths and weaknesses of these AI-text detection approaches,
this work lays a foundation for more robust transformer frameworks with larger,
richer datasets to keep pace with ever-improving generative AI models.

</details>


### [28] [ConceptViz: A Visual Analytics Approach for Exploring Concepts in Large Language Models](https://arxiv.org/abs/2509.20376)
*Haoxuan Li,Zhen Wen,Qiqi Jiang,Chenxiao Li,Yuwei Wu,Yuchen Yang,Yiyao Wang,Xiuqi Huang,Minfeng Zhu,Wei Chen*

Main category: cs.CL

TL;DR: 本文提出了一套可视化工具ConceptViz，方便用户将LLM自动编码器特征与具体概念进行探索和验证。该系统显著提升了AI模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 虽然SAE能揭示LLM内部特征，但这些特征难以直接与人类可理解的概念对应，解释工作费力且繁琐，因此需要一种方法将自动提取的特征与人类概念有效对齐。

Method: 提出了一套视觉分析系统ConceptViz，包含身份识别-解释-验证流程，允许用户通过查询、交互探索和验证模型表现来检查SAE特征与人类概念的一致性。

Result: 通过两个使用场景和用户研究，验证了ConceptViz提升特征解释效率和准确性。用户能够更便捷地发现和验证LLM中的概念表达。

Conclusion: ConceptViz可以有助于发现并验证LLM中的有意义概念特征，从而推动模型可解释性领域的发展。

Abstract: Large language models (LLMs) have achieved remarkable performance across a
wide range of natural language tasks. Understanding how LLMs internally
represent knowledge remains a significant challenge. Despite Sparse
Autoencoders (SAEs) have emerged as a promising technique for extracting
interpretable features from LLMs, SAE features do not inherently align with
human-understandable concepts, making their interpretation cumbersome and
labor-intensive. To bridge the gap between SAE features and human concepts, we
present ConceptViz, a visual analytics system designed for exploring concepts
in LLMs. ConceptViz implements a novel dentification => Interpretation =>
Validation pipeline, enabling users to query SAEs using concepts of interest,
interactively explore concept-to-feature alignments, and validate the
correspondences through model behavior verification. We demonstrate the
effectiveness of ConceptViz through two usage scenarios and a user study. Our
results show that ConceptViz enhances interpretability research by streamlining
the discovery and validation of meaningful concept representations in LLMs,
ultimately aiding researchers in building more accurate mental models of LLM
features. Our code and user guide are publicly available at
https://github.com/Happy-Hippo209/ConceptViz.

</details>


### [29] [SKILL-RAG: Self-Knowledge Induced Learning and Filtering for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.20377)
*Tomoaki Isoda*

Main category: cs.CL

TL;DR: SKILL-RAG利用模型自我知识提升RAG任务表现，通过强化学习训练和细粒度过滤方法优化内容选择，兼具生成质量提升和减少无关输入。


<details>
  <summary>Details</summary>
Motivation: 由于检索系统可能返回无关内容，纳入这些信息会导致生成模型产生幻觉，为此需要有效识别和筛除无用信息，提高RAG性能。

Method: 提出SKILL-RAG方法，通过强化学习框架显式引导模型自我知识，并在句子级别过滤掉无关内容，保留有用知识。

Result: 在多个问答基准数据集上的实验表明，SKILL-RAG提升了生成质量，并显著减少了输入文档数。

Conclusion: SKILL-RAG能显著提升RAG系统的生成质量，并有效减少输入文档数量，突出自我知识在检索内容筛选中的重要性。

Abstract: Retrieval-Augmented Generation (RAG) has significantly improved the
performance of large language models (LLMs) on knowledge-intensive tasks in
recent years. However, since retrieval systems may return irrelevant content,
incorporating such information into the model often leads to hallucinations.
Thus, identifying and filtering out unhelpful retrieved content is a key
challenge for improving RAG performance.To better integrate the internal
knowledge of the model with external knowledge from retrieval, it is essential
to understand what the model "knows" and "does not know" (which is also called
"self-knowledge"). Based on this insight, we propose SKILL-RAG (Self-Knowledge
Induced Learning and Filtering for RAG), a novel method that leverages the
model's self-knowledge to determine which retrieved documents are beneficial
for answering a given query. We design a reinforcement learning-based training
framework to explicitly elicit self-knowledge from the model and employs
sentence-level granularity to filter out irrelevant content while preserving
useful knowledge.We evaluate SKILL-RAG using Llama2-7B and Qwen3-8B on several
question answering benchmarks. Experimental results demonstrate that SKILL-RAG
not only improves generation quality but also significantly reduces the number
of input documents, validating the importance of self-knowledge in guiding the
selection of high-quality retrievals.

</details>


### [30] [Beyond Global Emotion: Fine-Grained Emotional Speech Synthesis with Dynamic Word-Level Modulation](https://arxiv.org/abs/2509.20378)
*Sirui Wang,Andong Chen,Tiejun Zhao*

Main category: cs.CL

TL;DR: 该论文提出Emo-FiLM，填补了现有语音情感合成在句内词级动态表达上的空白，通过FiLM实现词级情感控制，实验效果显著，推动E-TTS向更自然细腻发展。


<details>
  <summary>Details</summary>
Motivation: 现有的情感语音合成（E-TTS）方法多基于句级情感控制，难以捕捉句内细腻的情感变化。作者希望实现更加细粒度、动态和自然的语音情感表达。

Method: 提出了Emo-FiLM，一个用于大模型驱动语音合成的细粒度情感建模框架。该方法通过align emotion2vec的帧级特征到词，实现词级情感标注，并利用Feature-wise Linear Modulation（FiLM）层对文本嵌入进行情感调制，从而实现每个词的情感控制。还构建了细粒度情感动态数据集（FEDD）用于效果评测。

Result: Emo-FiLM在整体和细粒度情感合成任务上均超越了现有方法，有效提升了语音合成的情感表达能力和泛化性。

Conclusion: Emo-FiLM框架能实现句内词级的细粒度情感控制，推动语音合成由全局表达向动态细致转变，有助于更自然的人机交互体验。

Abstract: Emotional text-to-speech (E-TTS) is central to creating natural and
trustworthy human-computer interaction. Existing systems typically rely on
sentence-level control through predefined labels, reference audio, or natural
language prompts. While effective for global emotion expression, these
approaches fail to capture dynamic shifts within a sentence. To address this
limitation, we introduce Emo-FiLM, a fine-grained emotion modeling framework
for LLM-based TTS. Emo-FiLM aligns frame-level features from emotion2vec to
words to obtain word-level emotion annotations, and maps them through a
Feature-wise Linear Modulation (FiLM) layer, enabling word-level emotion
control by directly modulating text embeddings. To support evaluation, we
construct the Fine-grained Emotion Dynamics Dataset (FEDD) with detailed
annotations of emotional transitions. Experiments show that Emo-FiLM
outperforms existing approaches on both global and fine-grained tasks,
demonstrating its effectiveness and generality for expressive speech synthesis.

</details>


### [31] [USB-Rec: An Effective Framework for Improving Conversational Recommendation Capability of Large Language Model](https://arxiv.org/abs/2509.20381)
*Jianyu Wen,Jingyun Wang,Cilin Yan,Jiayin Cai,Xiaolong Jiang,Ying Zhang*

Main category: cs.CL

TL;DR: 本文针对LLM在对话推荐系统中的训练问题，提出了训练-推理一体化框架USB-Rec，包括RL优化和推理自增强，大幅提升了模型性能，并在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在对话推荐系统中的应用主要依赖模型的总结和分析能力，忽视了训练方法对其推荐表现的提升。因此，作者希望通过改进训练与推理流程，提升LLM在该任务中的整体表现。

Method: 首先提出基于LLM的兴趣优化数据集构建策略，用于强化学习（RL）训练，帮助模型理解对话推荐的策略和方法。其次，在推理阶段提出自增强策略（SES），进一步挖掘强化学习训练获得的对话推荐潜力。

Result: 在多个公开数据集上的实验结果表明，USB-Rec方法在对话推荐系统任务中能够持续超过以往的最先进方法。

Conclusion: 本文提出的USB-Rec框架在对话推荐系统中提升了大语言模型（LLM）的性能，尤其是在模型训练层面，并且在多个数据集上实现了优于以往最新方法的效果。

Abstract: Recently, Large Language Models (LLMs) have been widely employed in
Conversational Recommender Systems (CRSs). Unlike traditional language model
approaches that focus on training, all existing LLMs-based approaches are
mainly centered around how to leverage the summarization and analysis
capabilities of LLMs while ignoring the issue of training. Therefore, in this
work, we propose an integrated training-inference framework,
User-Simulator-Based framework (USB-Rec), for improving the performance of LLMs
in conversational recommendation at the model level. Firstly, we design a
LLM-based Preference Optimization (PO) dataset construction strategy for RL
training, which helps the LLMs understand the strategies and methods in
conversational recommendation. Secondly, we propose a Self-Enhancement Strategy
(SES) at the inference stage to further exploit the conversational
recommendation potential obtained from RL training. Extensive experiments on
various datasets demonstrate that our method consistently outperforms previous
state-of-the-art methods.

</details>


### [32] [Document Summarization with Conformal Importance Guarantees](https://arxiv.org/abs/2509.20461)
*Bruce Kuwahara,Chen-Yuan Lin,Xiao Shi Huang,Kin Kwan Leung,Jullian Arta Yapeter,Ilya Stanevich,Felipe Perez,Jesse C. Cresswell*

Main category: cs.CL

TL;DR: 该论文提出CIS方法，通过合规预测确保自动摘要对关键内容的覆盖率，方法模型无关且融合方便，在医疗、法律、金融等高风险领域具广泛安全应用前景。


<details>
  <summary>Details</summary>
Motivation: 当前自动摘要系统虽然取得了显著进展，但在医疗、法律、金融等高风险领域仍难以保证关键内容的覆盖，因此需要一种可控且有理论保障的方法来提升关键内容的覆盖率。

Method: 作者提出了Conformal Importance Summarization（CIS）框架，通过对句子重要性评分设定阈值，结合合规预测（conformal prediction）技术，实现了提取式摘要对关键内容覆盖率的分布无关理论保障。该方法无需特定模型，仅需少量校准数据，并可与现有黑盒大模型直接结合。

Result: 在主流摘要基准测试中，CIS方法实现了理论保证的信息覆盖率，并允许用户指定对关键内容的召回率。

Conclusion: CIS框架可与现有摘要技术结合，为关键领域的AI自动摘要提供具理论保障、可控的信息覆盖能力，有助于AI摘要工具在高风险场景下更安全应用。

Abstract: Automatic summarization systems have advanced rapidly with large language
models (LLMs), yet they still lack reliable guarantees on inclusion of critical
content in high-stakes domains like healthcare, law, and finance. In this work,
we introduce Conformal Importance Summarization, the first framework for
importance-preserving summary generation which uses conformal prediction to
provide rigorous, distribution-free coverage guarantees. By calibrating
thresholds on sentence-level importance scores, we enable extractive document
summarization with user-specified coverage and recall rates over critical
content. Our method is model-agnostic, requires only a small calibration set,
and seamlessly integrates with existing black-box LLMs. Experiments on
established summarization benchmarks demonstrate that Conformal Importance
Summarization achieves the theoretically assured information coverage rate. Our
work suggests that Conformal Importance Summarization can be combined with
existing techniques to achieve reliable, controllable automatic summarization,
paving the way for safer deployment of AI summarization tools in critical
applications. Code is available at
https://github.com/layer6ai-labs/conformal-importance-summarization.

</details>


### [33] [ShortCheck: Checkworthiness Detection of Multilingual Short-Form Videos](https://arxiv.org/abs/2509.20467)
*Henrik Vatndal,Vinay Setty*

Main category: cs.CL

TL;DR: 本文提出了用于短视频虚假信息检测的多模态自动化管道ShortCheck，融合多种技术模块，在真实数据集上检测性能突出，能有效辅助人工核查。


<details>
  <summary>Details</summary>
Motivation: 当前短视频平台（如TikTok）内容复杂且多样，信息噪音大，给虚假信息检测带来极大挑战，亟需有效的自动化辅助工具帮助人工核查。

Method: 设计了一个包含语音转录、OCR、物体与深度伪造检测、视频文本摘要和主张验证的多模块自动化管道，并采用推理后处理方式，界面友好。

Result: 在两个TikTok多语言人工标注数据集上评估，该管道获得F1加权得分超过70%。

Conclusion: ShortCheck能够有效辅助人为事实核查短视频内容，表现出较高的检测准确率。

Abstract: Short-form video platforms like TikTok present unique challenges for
misinformation detection due to their multimodal, dynamic, and noisy content.
We present ShortCheck, a modular, inference-only pipeline with a user-friendly
interface that automatically identifies checkworthy short-form videos to help
human fact-checkers. The system integrates speech transcription, OCR, object
and deepfake detection, video-to-text summarization, and claim verification.
ShortCheck is validated by evaluating it on two manually annotated datasets
with TikTok videos in a multilingual setting. The pipeline achieves promising
results with F1-weighted score over 70\%.

</details>


### [34] [MARS: toward more efficient multi-agent collaboration for LLM reasoning](https://arxiv.org/abs/2509.20502)
*Xiao Wang,Jia Wang,Yijie Wang,Pengtao Dang,Sha Cao,Chi Zhang*

Main category: cs.CL

TL;DR: MARS是一种模拟学术评审流程的多智能体协作框架，帮助语言模型高效推理，在保持准确率的前提下节约了一半计算资源。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体推理方法（如MAD）虽提升了语言模型的推理能力，但带来极高的计算负担及资源消耗。作者希望设计一种在保证推理效果基础上，优化计算效率的协作机制。

Method: 本研究提出了一种新的多智能体协作框架MARS，借鉴学术评审流程，通过作者、评审员和元评审员角色分工，实现初稿生成、独立评审与意见整合，从而提升推理质量且减少无需的多智能体沟通。

Result: MARS在多项基准测试和不同LLM上进行实验，准确率与MAD相当，同时令token消耗和推理时间降低约50%。

Conclusion: MARS系统能有效提升大型语言模型的推理能力，与MAD方法相比，推理准确率持平，但极大降低了计算资源消耗。

Abstract: Large language models (LLMs) have achieved impressive results in natural
language understanding, yet their reasoning capabilities remain limited when
operating as single agents. Multi-Agent Debate (MAD) has been proposed to
address this limitation by enabling collaborative reasoning among multiple
models in a round-table debate manner. While effective, MAD introduces
substantial computational overhead due to the number of agents involved and the
frequent communication required. In this paper, we propose MARS (Multi-Agent
Review System), a role-based collaboration framework inspired by the review
process. In MARS, an author agent generates an initial solution, reviewer
agents provide decisions and comments independently, and a meta-reviewer
integrates the feedback to make the final decision and guide further revision.
This design enhances reasoning quality while avoiding costly
reviewer-to-reviewer interactions, thereby controlling token consumption and
inference time. We compared MARS with both MAD and other state-of-the-art
reasoning strategies across multiple benchmarks. Extensive experiments with
different LLMs show that MARS matches the accuracy of MAD while reducing both
token usage and inference time by approximately 50\%. Code is available at
https://github.com/xwang97/MARS.

</details>


### [35] [SiniticMTError: A Machine Translation Dataset with Error Annotations for Sinitic Languages](https://arxiv.org/abs/2509.20557)
*Hannah Liu,Junghyun Min,Ethan Yue Heng Cheung,Shou-Yi Hung,Syed Mekael Wasti,Runtong Liang,Shiyao Qian,Shizhao Zheng,Elsie Chan,Ka Ieng Charlotte Lo,Wing Yu Yip,Richard Tzong-Han Tsai,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 作者提出了SiniticMTError数据集，详细标注了英文到数种汉语（包括低资源的粤语和吴语）的机器翻译错误信息，可用于提升低资源语言机器翻译的质量评估和模型改进。


<details>
  <summary>Details</summary>
Motivation: 尽管近年来机器翻译取得了重大进展，但对于缺乏大规模训练数据和语言资源的低资源语言（如粤语和吴语），进展依然有限。作者希望改善这些语言的机器翻译质量支持。

Method: 提出了SiniticMTError数据集，扩展现有的平行语料库，并为英文到普通话、粤语、吴语的机器翻译样本提供了错误区间、错误类型和错误严重程度注释。注释过程由母语者严格把关，并对注释者一致性、反馈迭代和错误类型及严重性进行了分析。

Result: 构建了包含丰富错误标注信息的数据集，支持低资源语言的翻译质量评估、错误检测模型微调和错误敏感生成等研究方向。

Conclusion: SiniticMTError数据集为机器翻译社区提供了宝贵资源，在推动针对低资源语言的翻译质量提升和模型优化方面具有重要意义。

Abstract: Despite major advances in machine translation (MT) in recent years, progress
remains limited for many low-resource languages that lack large-scale training
data and linguistic resources. Cantonese and Wu Chinese are two Sinitic
examples, although each enjoys more than 80 million speakers around the world.
In this paper, we introduce SiniticMTError, a novel dataset that builds on
existing parallel corpora to provide error span, error type, and error severity
annotations in machine-translated examples from English to Mandarin, Cantonese,
and Wu Chinese. Our dataset serves as a resource for the MT community to
utilize in fine-tuning models with error detection capabilities, supporting
research on translation quality estimation, error-aware generation, and
low-resource language evaluation. We report our rigorous annotation process by
native speakers, with analyses on inter-annotator agreement, iterative
feedback, and patterns in error type and severity.

</details>


### [36] [SwasthLLM: a Unified Cross-Lingual, Multi-Task, and Meta-Learning Zero-Shot Framework for Medical Diagnosis Using Contrastive Representations](https://arxiv.org/abs/2509.20567)
*Ayan Sar,Pranav Singh Puri,Sumit Aich,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: 该文提出了一种多语种零样本医学诊断框架SwasthLLM，无需特定语言微调，在英语、印地语和孟加拉语下表现优异，特别在低资源场景下泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 在多语言医疗环境中，低资源语言标注数据稀缺及语言差异导致自动疾病诊断困难。

Method: 提出了SwasthLLM框架，结合多语种XLM-RoBERTa编码器、语言感知注意力机制、疾病分类头、Siamese对比学习模块、翻译一致性模块与MAML元学习，实现零样本、多任务跨语言医学诊断。训练流程包括多任务联合优化与逐步任务微调。

Result: SwasthLLM在监督环境下取得97.22%的测试准确率和97.17%的F1分数；在零样本环境下，Hindi文本准确率达92.78%，Bengali文本达73.33%。

Conclusion: SwasthLLM可无须针对具体语言微调，显著提升了低资源语言下临床文本的自动疾病诊断性能，并具备出色的通用性和快速适应新任务/语言的能力。

Abstract: In multilingual healthcare environments, automatic disease diagnosis from
clinical text remains a challenging task due to the scarcity of annotated
medical data in low-resource languages and the linguistic variability across
populations. This paper proposes SwasthLLM, a unified, zero-shot,
cross-lingual, and multi-task learning framework for medical diagnosis that
operates effectively across English, Hindi, and Bengali without requiring
language-specific fine-tuning. At its core, SwasthLLM leverages the
multilingual XLM-RoBERTa encoder augmented with a language-aware attention
mechanism and a disease classification head, enabling the model to extract
medically relevant information regardless of the language structure. To align
semantic representations across languages, a Siamese contrastive learning
module is introduced, ensuring that equivalent medical texts in different
languages produce similar embeddings. Further, a translation consistency module
and a contrastive projection head reinforce language-invariant representation
learning. SwasthLLM is trained using a multi-task learning strategy, jointly
optimizing disease classification, translation alignment, and contrastive
learning objectives. Additionally, we employ Model-Agnostic Meta-Learning
(MAML) to equip the model with rapid adaptation capabilities for unseen
languages or tasks with minimal data. Our phased training pipeline emphasizes
robust representation alignment before task-specific fine-tuning. Extensive
evaluation shows that SwasthLLM achieves high diagnostic performance, with a
test accuracy of 97.22% and an F1-score of 97.17% in supervised settings.
Crucially, in zero-shot scenarios, it attains 92.78% accuracy on Hindi and
73.33% accuracy on Bengali medical text, demonstrating strong generalization in
low-resource contexts.

</details>


### [37] [Dynamic Reasoning Chains through Depth-Specialized Mixture-of-Experts in Transformer Architectures](https://arxiv.org/abs/2509.20577)
*Sampurna Roy,Ayan Sar,Anurag Kaushish,Kanav Gupta,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: 本文提出了DS-MoE架构，通过深度定制专家模块实现按需推理，不仅提升了推理效率和准确率，还增强了模型的可解释性，在大规模领域数据上取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 当前的Transformer结构对所有输入应用相同深度的处理，导致资源浪费，并限制了模型的推理能力，无法有效区分简单与复杂任务的需求。作者希望提升模型处理效率和推理质量。

Method: 提出了一种基于深度专用专家混合（DS-MoE）的动态推理链架构，将Mixture of Experts从宽度扩展到深度维度，通过动态路由网络按复杂度激活不同深度的专家模块，实现定制化推理流程。

Result: 在The Pile大规模数据集上训练与评估，DS-MoE相比传统Transformer，推理速度提升35%，计算资源节省16%，在复杂多步推理基准上的准确率提高2.8%。路由决策还带来可解释的推理链。

Conclusion: DS-MoE作为一种深度专用模块化处理范式显著提升了大型语言模型的效率、推理质量与可解释性，为自适应神经网络架构发展提供了新思路。

Abstract: Contemporary transformer architectures apply identical processing depth to
all inputs, creating inefficiencies and limiting reasoning quality. Simple
factual queries are subjected to the same multilayered computation as complex
logical problems, wasting resources while constraining deep inference. To
overcome this, we came up with a concept of Dynamic Reasoning Chains through
Depth Specialised Mixture of Experts (DS-MoE), a modular framework that extends
the Mixture of Experts paradigm from width-based to depth specialised
computation. DS-MoE introduces expert modules optimised for distinct reasoning
depths, shallow pattern recognition, compositional reasoning, logical
inference, memory integration, and meta-cognitive supervision. A learned
routing network dynamically assembles custom reasoning chains, activating only
the necessary experts to match input complexity. The dataset on which we
trained and evaluated DS-MoE is on The Pile, an 800GB corpus covering diverse
domains such as scientific papers, legal texts, programming code, and web
content, enabling systematic assessment across reasoning depths. Experimental
results demonstrate that DS-MoE achieves up to 16 per cent computational
savings and 35 per cent faster inference compared to uniform-depth
transformers, while delivering 2.8 per cent higher accuracy on complex
multi-step reasoning benchmarks. Furthermore, routing decisions yield
interpretable reasoning chains, enhancing transparency and scalability. These
findings establish DS-MoE as a significant advancement in adaptive neural
architectures, demonstrating that depth-specialised modular processing can
simultaneously improve efficiency, reasoning quality, and interpretability in
large-scale language models.

</details>


### [38] [Hierarchical Resolution Transformers: A Wavelet-Inspired Architecture for Multi-Scale Language Understanding](https://arxiv.org/abs/2509.20581)
*Ayan Sar,Sampurna Roy,Kanav Gupta,Anurag Kaushish,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: HRT通过多层次联合建模和高效注意力机制，大幅提升主流NLP任务表现和推理效率，兼顾准确性与资源消耗，是Transformer架构的重要创新。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer虽然在自然语言任务取得了SOTA表现，但它将文本处理为扁平的token序列，忽略了人类语言的层次结构，导致计算成本高、泛化能力弱及篇章级建模不足。

Method: 提出了Hierarchical Resolution Transformer（HRT）架构，借鉴小波理论，同时在字符到篇章多个分辨率上处理文本，通过分辨率递减和多层级注意力，实现O(nlogn)复杂度。

Result: 在GLUE、SuperGLUE、Long Range Arena和WikiText-103等多项基准测试上，HRT相较于BERT和GPT等同参数规模模型，分别平均提高+3.8%、+4.5%、+6.1%准确率，内存使用降低42%，推理延迟降低37%。消融实验也证实跨分辨率注意力和尺度特化模块对效率和准确性有独立贡献。

Conclusion: HRT首次实现了与人类语言层次结构相符的计算架构，多尺度、小波启发的处理不仅带来理论上的效率提升，也在实际语言理解任务中获得了显著改进。

Abstract: Transformer architectures have achieved state-of-the-art performance across
natural language tasks, yet they fundamentally misrepresent the hierarchical
nature of human language by processing text as flat token sequences. This
results in quadratic computational cost, weak computational cost, weak
compositional generalization, and inadequate discourse-level modeling. We
propose Hierarchical Resolution Transformer (HRT), a novel wavelet-inspired
neural architecture that processes language simultaneously across multiple
resolutions, from characters to discourse-level units. HRT constructs a
multi-resolution attention, enabling bottom-up composition and top-down
contextualization. By employing exponential sequence reduction across scales,
HRT achieves O(nlogn) complexity, offering significant efficiency improvements
over standard transformers. We evaluated HRT on a diverse suite of benchmarks,
including GLUE, SuperGLUE, Long Range Arena, and WikiText-103, and results
demonstrated that HRT outperforms standard transformer baselines by an average
of +3.8% on GLUE, +4.5% on SuperGLUE, and +6.1% on Long Range Arena, while
reducing memory usage by 42% and inference latency by 37% compared to BERT and
GPT style models of similar parameter count. Ablation studies confirm the
effectiveness of cross-resolution attention and scale-specialized modules,
showing that each contributes independently to both efficiency and accuracy.
Our findings establish HRT as the first architecture to align computational
structure with the hierarchical organization of human language, demonstrating
that multi-scale, wavelet-inspired processing yields both theoretical
efficiency gains and practical improvements in language understanding.

</details>


### [39] [FS-DFM: Fast and Accurate Long Text Generation with Few-Step Diffusion Language Models](https://arxiv.org/abs/2509.20624)
*Amin Karimi Monsefi,Nikhil Bhendawade,Manuel Rafael Ciosici,Dominic Culver,Yizhe Zhang,Irina Belousova*

Main category: cs.CL

TL;DR: FS-DFM能用极少采样步高效并行地生成高质量文本，相比常规扩散模型采样速度提升数十倍，适合需要低延迟高吞吐量的语言生成场景。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型（ARMs）生成质量高，但由于一次只能生成一个token，导致在处理长序列时吞吐量低、延迟高。扩散语言模型（DLMs）虽然能并行处理多个位置，但需要大量模型迭代才能达到高质量，计算开销大。因此，需要一种能在保证生成质量的前提下降低计算量、提升速度的新方法。

Method: 提出FS-DFM（Few-Step Discrete Flow-Matching），将采样步数显式作为参数，训练模型在不同步数预算下保持一致性。配合法则可靠的概率更新规则，防止跳步过大，并结合老师模型的强指导，使少步采样过程稳定、准确，同时易于控制。

Result: 在语言建模基准测试中，FS-DFM采用8步采样，在生成1024个tokens时，困惑度与采用1024步采样的离散流模型持平，同时采样速度提升最多达128倍，显著改善了延迟和吞吐量。

Conclusion: FS-DFM突破了扩散语言模型在生成速度与质量上的常见权衡，以极少采样步数实现高效且高质量的并行生成，为大规模、高吞吐量语言任务提供了具有实践意义的新方案。

Abstract: Autoregressive language models (ARMs) deliver strong likelihoods, but are
inherently serial: they generate one token per forward pass, which limits
throughput and inflates latency for long sequences. Diffusion Language Models
(DLMs) parallelize across positions and thus appear promising for language
generation, yet standard discrete diffusion typically needs hundreds to
thousands of model evaluations to reach high quality, trading serial depth for
iterative breadth. We introduce FS-DFM, Few-Step Discrete Flow-Matching. A
discrete flow-matching model designed for speed without sacrificing quality.
The core idea is simple: make the number of sampling steps an explicit
parameter and train the model to be consistent across step budgets, so one big
move lands where many small moves would. We pair this with a reliable update
rule that moves probability in the right direction without overshooting, and
with strong teacher guidance distilled from long-run trajectories. Together,
these choices make few-step sampling stable, accurate, and easy to control. On
language modeling benchmarks, FS-DFM with 8 sampling steps achieves perplexity
parity with a 1,024-step discrete-flow baseline for generating 1,024 tokens
using a similar-size model, delivering up to 128 times faster sampling and
corresponding latency/throughput gains.

</details>


### [40] [Look Before you Leap: Estimating LLM Benchmark Scores from Descriptions](https://arxiv.org/abs/2509.20645)
*Jungsoo Park,Ethan Mendes,Gabriel Stanovsky,Alan Ritter*

Main category: cs.CL

TL;DR: 本论文提出仅凭任务描述预测大模型表现的方法，构建了相应数据集和基准，实验验证了可行性，也指出现有模型的不足，对实验优先排序和难度预估具有意义。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的发展受制于评测瓶颈——需要为每个实验构建基准、评测结果、再进行迭代。作者提出：能否在不实际运行实验的情况下预测模型表现？

Method: 作者提出text-only performance forecasting：仅凭任务描述和配置信息（不接触数据细节）预测模型分数，并建立PRECOG语料库，包含多样化任务中的描述-表现配对。同时，实验比较了带检索模块的模型在预测准确度和不确定性校准方面的表现。还测试了“零泄漏”情境（如仅用新发布的数据集，在对应论文未被收录前预测性能）。

Result: 结果表明，该预测任务具有挑战性但可行。带检索模块的模型在高置信度阈值下，Accuracy子集的平均绝对误差最低可达8.7。分析发现更强的推理模型会进行多样、迭代的信息查询，而开源模型则查询不足且证据多样性较弱。即便在零泄漏条件下，GPT-5结合网页搜索，仍能达到相当水平的预测准确度。

Conclusion: 作者构建了多任务、多领域的评测数据集，并验证了在无实验数据前提下预测模型表现的可行性，为更高效的实验优先级排序和难度估计提供了方法基础。

Abstract: Progress in large language models is constrained by an evaluation bottleneck:
build a benchmark, evaluate models and settings, then iterate. We therefore ask
a simple question: can we forecast outcomes before running any experiments? We
study text-only performance forecasting: estimating a model's score from a
redacted task description and intended configuration, with no access to dataset
instances. To support systematic study, we curate PRECOG, a corpus of redacted
description-performance pairs spanning diverse tasks, domains, and metrics.
Experiments show the task is challenging but feasible: models equipped with a
retrieval module that excludes source papers achieve moderate prediction
performance with well-calibrated uncertainty, reaching mean absolute error as
low as 8.7 on the Accuracy subset at high-confidence thresholds. Our analysis
indicates that stronger reasoning models engage in diverse, iterative querying,
whereas current open-source models lag and often skip retrieval or gather
evidence with limited diversity. We further test a zero-leakage setting,
forecasting on newly released datasets or experiments before their papers are
indexed, where GPT-5 with built-in web search still attains nontrivial
prediction accuracy. Overall, our corpus and analyses offer an initial step
toward open-ended anticipatory evaluation, supporting difficulty estimation and
smarter experiment prioritization.

</details>


### [41] [Building Tailored Speech Recognizers for Japanese Speaking Assessment](https://arxiv.org/abs/2509.20655)
*Yotaro Kubo,Richard Sproat,Chihiro Taguchi,Llion Jones*

Main category: cs.CL

TL;DR: 本文针对日语口语评估，提出多任务学习和模型融合技术，有效解决重音标记音素转录数据稀缺问题，使语音识别误差率大幅下降，优于现有通用模型。


<details>
  <summary>Details</summary>
Motivation: 尽管日语语音资源丰富，带有重音标记的精确音素转录训练数据稀缺，因此需要新方法缓解数据稀疏性，以提升识别器性能，服务于日语口语评估任务。

Method: 主要包括多任务训练方案（利用辅助损失函数估计输入信号的正字标签和音调模式，充分利用只有正字标注的数据）以及模型融合方案（将基于音素字母和文本序列的两个估算器，通过有限状态转换器算法进行融合）。

Result: 提出的方法使CSJ核心评测集的mora标签误差率从12.3%降低至7.1%。多任务学习和模型融合均显著提升了标注准确率。

Conclusion: 提出的多任务学习与模型融合方法有效提升日语语音识别中带有重音标记的音素转录准确性，显著优于通用多语言识别器。

Abstract: This paper presents methods for building speech recognizers tailored for
Japanese speaking assessment tasks. Specifically, we build a speech recognizer
that outputs phonemic labels with accent markers. Although Japanese is
resource-rich, there is only a small amount of data for training models to
produce accurate phonemic transcriptions that include accent marks. We propose
two methods to mitigate data sparsity. First, a multitask training scheme
introduces auxiliary loss functions to estimate orthographic text labels and
pitch patterns of the input signal, so that utterances with only orthographic
annotations can be leveraged in training. The second fuses two estimators, one
over phonetic alphabet strings, and the other over text token sequences. To
combine these estimates we develop an algorithm based on the finite-state
transducer framework. Our results indicate that the use of multitask learning
and fusion is effective for building an accurate phonemic recognizer. We show
that this approach is advantageous compared to the use of generic multilingual
recognizers. The relative advantages of the proposed methods were also
compared. Our proposed methods reduced the average of mora-label error rates
from 12.3% to 7.1% over the CSJ core evaluation sets.

</details>


### [42] [Enhancing Molecular Property Prediction with Knowledge from Large Language Models](https://arxiv.org/abs/2509.20664)
*Peng Zhou,Lai Hou Tim,Zhixiang Cheng,Kun Xie,Chaoyi Li,Wei Liu,Xiangxiang Zeng*

Main category: cs.CL

TL;DR: 本文通过融合LLM抽取的知识与预训练分子模型的结构特征，提升了分子属性预测的准确性。实验表明，该方法优于以往方案。


<details>
  <summary>Details</summary>
Motivation: 分子属性预测在药物研发中非常关键，虽然深度学习（尤其是图神经网络GNN）提升了性能，但人工知识的整合仍不可或缺。现有方法利用大语言模型（LLM）抽取知识，但其在某些分子属性上仍存在知识缺口与幻觉等问题。作者旨在融合结构化特征与LLM知识，弥补各自不足。

Method: 作者提出了一个新框架，将LLM抽取的知识与预训练分子模型的结构特征相结合，用于提升分子属性预测（MPP）。具体做法是推动LLM生成领域相关知识及可执行分子向量化代码，形成知识型特征，并与结构化表征融合。实验中用GPT-4o、GPT-4.1和DeepSeek-R1三种先进LLM进行知识提取。

Result: 综合实验结果显示，该融合方法优于现有方法。整合LLM知识和结构信息可为分子属性预测提供更加鲁棒和高效的解决方案。

Conclusion: 本文首次提出融合LLM知识与分子结构特征的新框架，有效提升了分子属性预测性能，验证了两者结合的必要性和优势。

Abstract: Predicting molecular properties is a critical component of drug discovery.
Recent advances in deep learning, particularly Graph Neural Networks (GNNs),
have enabled end-to-end learning from molecular structures, reducing reliance
on manual feature engineering. However, while GNNs and self-supervised learning
approaches have advanced molecular property prediction (MPP), the integration
of human prior knowledge remains indispensable, as evidenced by recent methods
that leverage large language models (LLMs) for knowledge extraction. Despite
their strengths, LLMs are constrained by knowledge gaps and hallucinations,
particularly for less-studied molecular properties. In this work, we propose a
novel framework that, for the first time, integrates knowledge extracted from
LLMs with structural features derived from pre-trained molecular models to
enhance MPP. Our approach prompts LLMs to generate both domain-relevant
knowledge and executable code for molecular vectorization, producing
knowledge-based features that are subsequently fused with structural
representations. We employ three state-of-the-art LLMs, GPT-4o, GPT-4.1, and
DeepSeek-R1, for knowledge extraction. Extensive experiments demonstrate that
our integrated method outperforms existing approaches, confirming that the
combination of LLM-derived knowledge and structural information provides a
robust and effective solution for MPP.

</details>


### [43] [RedHerring Attack: Testing the Reliability of Attack Detection](https://arxiv.org/abs/2509.20691)
*Jonathan Rusert*

Main category: cs.CL

TL;DR: 本文提出了RedHerring攻击，使文本攻击检测模型变得不可靠，但分类器却正常工作。大规模实验显示，检测准确率大幅下降，但简单置信度检查可作为有效防御。该工作揭示检测模型新的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 尽管攻击检测模型在识别恶意文本方面表现良好，但其可靠性缺乏深入分析。本文希望揭示其潜在弱点及新型威胁方式，推动检测模型的改进。

Method: 提出RedHerring攻击方法，通过修改文本让检测模型误判为攻击，但分类器仍做出正确预测。实验在4组数据集、3个检测器和4个分类器上进行，并设定初步防御机制——置信度检查。

Result: RedHerring攻击导致检测准确率下降20至71个百分点，分类器准确率仍保持甚至上升。作者提出的置信度检查无需重新训练模型，即可显著提升检测表现。

Conclusion: RedHerring攻击能显著降低检测模型的准确率，而分类器的准确率依然保持或提升。针对这种威胁，作者提出了一种简单的置信度检查防御方法，可以显著提升检测准确率。

Abstract: In response to adversarial text attacks, attack detection models have been
proposed and shown to successfully identify text modified by adversaries.
Attack detection models can be leveraged to provide an additional check for NLP
models and give signals for human input. However, the reliability of these
models has not yet been thoroughly explored. Thus, we propose and test a novel
attack setting and attack, RedHerring. RedHerring aims to make attack detection
models unreliable by modifying a text to cause the detection model to predict
an attack, while keeping the classifier correct. This creates a tension between
the classifier and detector. If a human sees that the detector is giving an
``incorrect'' prediction, but the classifier a correct one, then the human will
see the detector as unreliable. We test this novel threat model on 4 datasets
against 3 detectors defending 4 classifiers. We find that RedHerring is able to
drop detection accuracy between 20 - 71 points, while maintaining (or
improving) classifier accuracy. As an initial defense, we propose a simple
confidence check which requires no retraining of the classifier or detector and
increases detection accuracy greatly. This novel threat model offers new
insights into how adversaries may target detection models.

</details>


### [44] [Overcoming Black-box Attack Inefficiency with Hybrid and Dynamic Select Algorithms](https://arxiv.org/abs/2509.20699)
*Abhinay Shankar Belde,Rohit Ramkumar,Jonathan Rusert*

Main category: cs.CL

TL;DR: 本研究针对文本对抗攻击在计算资源消耗上的问题，提出了Hybrid Select和Dynamic Select两种高效攻击选择策略，能在保持攻击有效性的同时，显著减少每次攻击所需查询次数（平均下降25.82%），更适用于资源有限的研究环境。


<details>
  <summary>Details</summary>
Motivation: 随着transformer架构复杂性的提升，现有对抗样本文本攻击测试变得计算资源消耗高，尤其对资源有限（例如GPU不足）的研究者不友好。当前流行的黑盒攻击方式需大量查询，效率低下，限制了实际应用。

Method: 提出了两种新的攻击选择策略：Hybrid Select和Dynamic Select。Hybrid Select将BinarySelect和GreedySelect结合，通过设置长度阈值决定选用哪种算法；Dynamic Select通过学习文本长度，动态决定采用哪种选择方法以优化查询次数。方法在句子级别应用。

Result: 在4个数据集和6个目标模型上，句子级Hybrid Select方法平均减少了25.82%的每次攻击所需查询次数，同时攻击效果无明显损失，无论针对编码器模型还是大语言模型（LLM）。

Conclusion: 新提出的选择策略显著提升了对抗攻击测试的效率，减小了资源消耗，同时保持了攻击有效性，解决了当前主流方法查询次数过多的问题。

Abstract: Adversarial text attack research plays a crucial role in evaluating the
robustness of NLP models. However, the increasing complexity of
transformer-based architectures has dramatically raised the computational cost
of attack testing, especially for researchers with limited resources (e.g.,
GPUs). Existing popular black-box attack methods often require a large number
of queries, which can make them inefficient and impractical for researchers. To
address these challenges, we propose two new attack selection strategies called
Hybrid and Dynamic Select, which better combine the strengths of previous
selection algorithms. Hybrid Select merges generalized BinarySelect techniques
with GreedySelect by introducing a size threshold to decide which selection
algorithm to use. Dynamic Select provides an alternative approach of combining
the generalized Binary and GreedySelect by learning which lengths of texts each
selection method should be applied to. This greatly reduces the number of
queries needed while maintaining attack effectiveness (a limitation of
BinarySelect). Across 4 datasets and 6 target models, our best
method(sentence-level Hybrid Select) is able to reduce the number of required
queries per attack up 25.82\% on average against both encoder models and LLMs,
without losing the effectiveness of the attack.

</details>


### [45] [MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model](https://arxiv.org/abs/2509.20706)
*Hsiao-Ying Huang,Yi-Cheng Lin,Hung-yi Lee*

Main category: cs.CL

TL;DR: 论文针对无法获得源域数据且只能API访问大型音频-语言模型的实际情感语音识别自适应问题，提出了MI-Fuse框架。方法结合LALM和源域教师模型多次预测，通过互信息加权融合和去噪，实现了目标域性能超越LALM和传统方法，在多个数据集和转移场景中取得了显著提升，对实际部署极具价值。


<details>
  <summary>Details</summary>
Motivation: 当前大型音频-语言模型（LALMs）在语音任务上展现了强大的零样本能力，但实际环境下面临域不匹配，且只能通过API访问LALMs，源数据无法获取，因此如何适应目标域成为挑战。

Method: 提出了MI-Fuse框架：以真实无标签目标域音频为训练对象，将API访问的LALM和一个源域训练好的SER分类器作为双教师，通过多次随机预测融合标签，并用基于互信息的不确定性加权模型分布。同时，训练过程用指数移动平均教师稳定学习。

Result: 在三大公开情感数据集和六个跨域转移实验中，学生模型持续优于LALM，超过最强基线3.9%，实现了更高的目标域自适应 SER 性能。

Conclusion: MI-Fuse框架无须源域数据即可显著提升目标域语音情感识别效果，有效促进实际通用情感语音系统的发展。

Abstract: Large audio-language models (LALMs) show strong zero-shot ability on speech
tasks, suggesting promise for speech emotion recognition (SER). However, SER in
real-world deployments often fails under domain mismatch, where source data are
unavailable and powerful LALMs are accessible only through an API. We ask:
given only unlabeled target-domain audio and an API-only LALM, can a student
model be adapted to outperform the LALM in the target domain? To this end, we
propose MI-Fuse, a denoised label fusion framework that supplements the LALM
with a source-domain trained SER classifier as an auxiliary teacher. The
framework draws multiple stochastic predictions from both teachers, weights
their mean distributions by mutual-information-based uncertainty, and
stabilizes training with an exponential moving average teacher. Experiments
across three public emotion datasets and six cross-domain transfers show
consistent gains, with the student surpassing the LALM and outperforming the
strongest baseline by 3.9%. This approach strengthens emotion-aware speech
systems without sharing source data, enabling realistic adaptation.

</details>


### [46] [Probability Distribution Collapse: A Critical Bottleneck to Compact Unsupervised Neural Grammar Induction](https://arxiv.org/abs/2509.20734)
*Jinwook Park,Kangil Kim*

Main category: cs.CL

TL;DR: 本文发现当前无监督神经语法归纳方法存在概率分布坍塌问题，导致语法大且效果差。通过提出新的神经参数化方法，显著提升了性能并获得更紧凑的语法，经多语言实证验证。


<details>
  <summary>Details</summary>
Motivation: 无监督的神经语法归纳旨在从语言数据中学习可解释的层次结构。然而，当前模型表现受限，容易生成过于庞大且效果不佳的语法。作者发现其核心问题在于概率分布的坍塌。

Method: 作者分析概率分布坍塌在神经参数化中的出现，并提出了专门的解决方案——坍塌缓解神经参数化。

Result: 提出的方法能够显著提升解析性能，并在多种语言下实现更紧凑的语法结构。作者通过大量实证分析验证了该方法的有效性。

Conclusion: 针对神经语法归纳模型的表达能力瓶颈，本文发现并解析了概率分布坍塌的机理，并提出坍塌缓解神经参数化算法，有效提升性能与语法紧凑度。

Abstract: Unsupervised neural grammar induction aims to learn interpretable
hierarchical structures from language data. However, existing models face an
expressiveness bottleneck, often resulting in unnecessarily large yet
underperforming grammars. We identify a core issue, $\textit{probability
distribution collapse}$, as the underlying cause of this limitation. We analyze
when and how the collapse emerges across key components of neural
parameterization and introduce a targeted solution, $\textit{collapse-relaxing
neural parameterization}$, to mitigate it. Our approach substantially improves
parsing performance while enabling the use of significantly more compact
grammars across a wide range of languages, as demonstrated through extensive
empirical analysis.

</details>


### [47] [Confidence-guided Refinement Reasoning for Zero-shot Question Answering](https://arxiv.org/abs/2509.20750)
*Youwon Jang,Woo Suk Choi,Minjoon Jung,Minsu Lee,Byoung-Tak Zhang*

Main category: cs.CL

TL;DR: 提出C2R框架，通过置信度优化子问答推理，无需训练即可提升文本、图像、视频QA模型表现，并剖析子问答对模型行为的影响。


<details>
  <summary>Details</summary>
Motivation: 当前QA任务在不同领域都受限于推理路径单一、模型信心无法充分利用的问题，因此需要一种通用、可无缝整合的新方法提升推理鲁棒性和准确率。

Method: 提出了一种训练无关的置信度引导细化推理（C2R）框架，通过生成并优化子问答及其置信度分数，选取最有信心的最终答案。该方法适配于多种QA模型，无需重新训练。

Result: C2R框架在多种QA模型和数据集上都带来了稳定的性能提升，并深入分析了子问答数量和质量对推理有效性的影响，为领域研究提供了新见解。

Conclusion: C2R方法通过引入子问答，并依据模型自身置信度进行答案筛选，有效提升了多种现有QA模型在文本、图像、视频不同领域的表现。

Abstract: We propose Confidence-guided Refinement Reasoning (C2R), a novel
training-free framework applicable to question-answering (QA) tasks across
text, image, and video domains. C2R strategically constructs and refines
sub-questions and their answers (sub-QAs), deriving a better confidence score
for the target answer. C2R first curates a subset of sub-QAs to explore diverse
reasoning paths, then compares the confidence scores of the resulting answer
candidates to select the most reliable final answer. Since C2R relies solely on
confidence scores derived from the model itself, it can be seamlessly
integrated with various existing QA models, demonstrating consistent
performance improvements across diverse models and benchmarks. Furthermore, we
provide essential yet underexplored insights into how leveraging sub-QAs
affects model behavior, specifically analyzing the impact of both the quantity
and quality of sub-QAs on achieving robust and reliable reasoning.

</details>


### [48] [SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs](https://arxiv.org/abs/2509.20758)
*Jiacheng Lin,Zhongruo Wang,Kun Qian,Tian Wang,Arvind Srinivasan,Hansi Zeng,Ruochen Jiao,Xie Zhou,Jiri Gesi,Dakuo Wang,Yufan Guo,Kai Zhong,Weiqi Zhang,Sujay Sanghavi,Changyou Chen,Hyokun Yun,Lihong Li*

Main category: cs.CL

TL;DR: 本文系统分析了SFT带来的领域与泛化性能权衡，提出TALR新方法在两者间实现最佳平衡，并给出领域微调实用建议。


<details>
  <summary>Details</summary>
Motivation: SFT常用于让LLM适应特定任务，但业界普遍认为它会降低模型的泛化能力，因此本文旨在重新探讨SFT的这种权衡，寻找能同时提升领域和泛化能力的方法。

Method: 首先通过实证分析不同学习率对SFT泛化能力的影响；其次开展理论分析解释现象并提出Token-Adaptive Loss Reweighting (TALR)方法；最后与现有方法（L2正则、LoRA、模型平均、FLOW等）做对比实验。

Result: 小学习率能减轻SFT对模型泛化能力的损伤但不能完全消除；TALR方法在领域性能和泛化能力之间实现最佳权衡，超越其他主流策略。

Conclusion: SFT并非一定损伤泛化能力，适当控制学习率可取得良好平衡；强需求下推荐结合TALR方法。

Abstract: Supervised Fine-Tuning (SFT) on domain-specific datasets is a common approach
to adapt Large Language Models (LLMs) to specialized tasks but is often
believed to degrade their general capabilities. In this work, we revisit this
trade-off and present both empirical and theoretical insights. First, we show
that SFT does not always hurt: using a smaller learning rate can substantially
mitigate general performance degradation while preserving comparable
target-domain performance. We then provide a theoretical analysis that explains
these phenomena and further motivates a new method, Token-Adaptive Loss
Reweighting (TALR). Building on this, and recognizing that smaller learning
rates alone do not fully eliminate general-performance degradation in all
cases, we evaluate a range of strategies for reducing general capability loss,
including L2 regularization, LoRA, model averaging, FLOW, and our proposed
TALR. Experimental results demonstrate that while no method completely
eliminates the trade-off, TALR consistently outperforms these baselines in
balancing domain-specific gains and general capabilities. Finally, we distill
our findings into practical guidelines for adapting LLMs to new domains: (i)
using a small learning rate to achieve a favorable trade-off, and (ii) when a
stronger balance is further desired, adopt TALR as an effective strategy.

</details>


### [49] [Towards Atoms of Large Language Models](https://arxiv.org/abs/2509.20784)
*Chenhui Hu,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: 本文提出并验证了用于拆解大语言模型内部表征的Atoms Theory，定义了表征原子并给出了相关理论和实验支撑。Atoms相比神经元/特征更稳定、可唯一恢复，有助于提升LLM可解释性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）的内部表示单元尚未明确定义，现有的神经元或特征方案都存在多义性、不稳定等不足，这限制了对模型机理的深入理解。

Method: 提出了Atoms Theory（原子理论），把LLM的基本单元定义为Atoms。提出了atomic inner product（AIP）用于纠正表征漂移，形式化定义了Atoms，并证明了Atoms符合受限等距性质（RIP），确保了稀疏表征的稳定性，并与压缩感知理论建立联系。在更严格的条件下，证明了稀疏表征的唯一性和精确$[1;31m\ell_1$可恢复性；同时给出单层稀疏自动编码器（SAE）在阈值激活下可以可靠识别Atoms的理论保证。实验采用SAE训练在不同规模的LLM模型上验证理论方法。

Result: SAE在Gemma2-2B、Gemma2-9B和Llama3.1-8B上实现了99.9%的稀疏重建准确率，超过99.8%的Atoms满足唯一性条件，相较于神经元（0.5%）和特征（68.2%），显示Atoms更能有效捕捉LLM内部本质表征。扩展实验进一步揭示了SAE的规模与恢复能力的联系。

Conclusion: 系统性提出并验证了LLM的Atoms Theory，为理解其内部表征和解释其机制提供了完整理论框架与实验验证。Atoms优于现有神经元或特征方案，用以描述LLM内部表征的本质单元。

Abstract: The fundamental units of internal representations in large language models
(LLMs) remain undefined, limiting further understanding of their mechanisms.
Neurons or features are often regarded as such units, yet neurons suffer from
polysemy, while features face concerns of unreliable reconstruction and
instability. To address this issue, we propose the Atoms Theory, which defines
such units as atoms. We introduce the atomic inner product (AIP) to correct
representation shifting, formally define atoms, and prove the conditions that
atoms satisfy the Restricted Isometry Property (RIP), ensuring stable sparse
representations over atom set and linking to compressed sensing. Under stronger
conditions, we further establish the uniqueness and exact $\ell_1$
recoverability of the sparse representations, and provide guarantees that
single-layer sparse autoencoders (SAEs) with threshold activations can reliably
identify the atoms. To validate the Atoms Theory, we train threshold-activated
SAEs on Gemma2-2B, Gemma2-9B, and Llama3.1-8B, achieving 99.9% sparse
reconstruction across layers on average, and more than 99.8% of atoms satisfy
the uniqueness condition, compared to 0.5% for neurons and 68.2% for features,
showing that atoms more faithfully capture intrinsic representations of LLMs.
Scaling experiments further reveal the link between SAEs size and recovery
capacity. Overall, this work systematically introduces and validates Atoms
Theory of LLMs, providing a theoretical framework for understanding internal
representations and a foundation for mechanistic interpretability. Code
available at https://github.com/ChenhuiHu/towards_atoms.

</details>


### [50] [Few-Shot and Training-Free Review Generation via Conversational Prompting](https://arxiv.org/abs/2509.20805)
*Genki Kusano*

Main category: cs.CL

TL;DR: 本论文创新性地提出对话式提示（SCP/CCP），在少样本和免训练场景下能高效生成贴合用户风格的评论，相较传统方法显著提升了个性化表现。


<details>
  <summary>Details</summary>
Motivation: 目前个性化评论生成大多依赖于用户大量历史评论或需要对模型进一步训练，但现实中常常只有少量用户评论且难以进行微调。

Method: 提出Conversational Prompting，通过把用户评论转为多轮对话形式来优化生成：SCP仅用用户评论，CCP引入其他用户或大模型的评论作为反例，要求模型纠正并仿写目标用户风格。

Result: 在八个商品领域、五种大模型上实验证明，传统prompt生成的评论更多地类似于随机用户产出，而SCP和CCP能更贴近目标用户风格，只需用户两条评论即可；CCP在有高质量反例时提升更明显，无充足反例时SCP也有竞争力。

Conclusion: 对话式提示能在极少量样本和无需训练的情况下，有效提升个性化评论生成的用户定制能力。

Abstract: Personalized review generation helps businesses understand user preferences,
yet most existing approaches assume extensive review histories of the target
user or require additional model training. Real-world applications often face
few-shot and training-free situations, where only a few user reviews are
available and fine-tuning is infeasible. It is well known that large language
models (LLMs) can address such low-resource settings, but their effectiveness
depends on prompt engineering. In this paper, we propose Conversational
Prompting, a lightweight method that reformulates user reviews as multi-turn
conversations. Its simple variant, Simple Conversational Prompting (SCP),
relies solely on the user's own reviews, while the contrastive variant,
Contrastive Conversational Prompting (CCP), inserts reviews from other users or
LLMs as incorrect replies and then asks the model to correct them, encouraging
the model to produce text in the user's style. Experiments on eight product
domains and five LLMs showed that the conventional non-conversational prompt
often produced reviews similar to those written by random users, based on
text-based metrics such as ROUGE-L and BERTScore, and application-oriented
tasks like user identity matching and sentiment analysis. In contrast, both SCP
and CCP produced reviews much closer to those of the target user, even when
each user had only two reviews. CCP brings further improvements when
high-quality negative examples are available, whereas SCP remains competitive
when such data cannot be collected. These results suggest that conversational
prompting offers a practical solution for review generation under few-shot and
training-free constraints.

</details>


### [51] [Enrich-on-Graph: Query-Graph Alignment for Complex Reasoning with LLM Enriching](https://arxiv.org/abs/2509.20810)
*Songze Li,Zhiqiang Liu,Zhengke Gui,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: 论文针对知识图谱问答中的语义鸿沟问题，提出了融合大模型知识的图谱增强方法EoG，显著改善了答案质量并具备低资源消耗和高可扩展性，取得了最新的实验成绩。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLMs）在复杂任务中具备强推理能力，但在知识密集型的知识图谱问答（KGQA）场景中依然存在虚构和事实错误。这一问题部分源于结构化知识图谱和非结构化查询之间的语义鸿沟。现有方法常用高资源消耗且难以扩展的流程，且忽视了这一语义差距。

Method: 提出了一个灵活的框架——Enrich-on-Graph（EoG），利用LLM的先验知识丰富知识图谱，从而弥合结构化图谱和查询间的语义差距。EoG支持高效证据提取，实现精确且稳健的推理，同时保证低计算成本和良好的可扩展性。此外，提出三项图谱质量评估指标，用于分析查询与图谱之间的对齐情况，并理论验证了优化目标。

Result: 在两个KGQA基准数据集上的广泛实验表明，EoG能够有效生成高质量的知识图谱，并实现当前最优性能。

Conclusion: Enrich-on-Graph框架不仅提升了知识图谱的质量，还有效提高了知识图谱问答任务的准确性和健壮性，同时具备较强的可扩展性和适应性。

Abstract: Large Language Models (LLMs) exhibit strong reasoning capabilities in complex
tasks. However, they still struggle with hallucinations and factual errors in
knowledge-intensive scenarios like knowledge graph question answering (KGQA).
We attribute this to the semantic gap between structured knowledge graphs (KGs)
and unstructured queries, caused by inherent differences in their focuses and
structures. Existing methods usually employ resource-intensive, non-scalable
workflows reasoning on vanilla KGs, but overlook this gap. To address this
challenge, we propose a flexible framework, Enrich-on-Graph (EoG), which
leverages LLMs' prior knowledge to enrich KGs, bridge the semantic gap between
graphs and queries. EoG enables efficient evidence extraction from KGs for
precise and robust reasoning, while ensuring low computational costs,
scalability, and adaptability across different methods. Furthermore, we propose
three graph quality evaluation metrics to analyze query-graph alignment in KGQA
task, supported by theoretical validation of our optimization objectives.
Extensive experiments on two KGQA benchmark datasets indicate that EoG can
effectively generate high-quality KGs and achieve the state-of-the-art
performance. Our code and data are available at
https://github.com/zjukg/Enrich-on-Graph.

</details>


### [52] [Leveraging What's Overfixed: Post-Correction via LLM Grammatical Error Overcorrection](https://arxiv.org/abs/2509.20811)
*Taehee Park,Heejin Do,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: PoCO结合大模型的高召回与小模型的高精度，先过度纠错再精修，实现更优语法纠错效果。


<details>
  <summary>Details</summary>
Motivation: 当前小型语言模型（sLMs）精度高但召回率低，倾向于保守修正；而大型语言模型（LLMs）纠错较激进，导致精度降低、召回升高。如何平衡召回与精度成为语法纠错（GEC）中的关键难题。

Method: 提出Post-Correction via Overcorrection（PoCO）方法，第一步利用LLM故意“过度纠错”以提高召回率，第二步用精调的小模型进一步对输出进行甄别和精修，从而提升结果的整体质量。

Result: 大量实验表明，PoCO方法有效提升了GEC任务中的召回的同时，精度不降反升，整体纠错表现优于传统方法，在精度和召回之间取得了更好平衡。

Conclusion: PoCO通过融合LLM和sLM的优势，兼顾召回与精度，提高了语法错误纠正的整体表现。

Abstract: Robust supervised fine-tuned small Language Models (sLMs) often show high
reliability but tend to undercorrect. They achieve high precision at the cost
of low recall. Conversely, Large Language Models (LLMs) often show the opposite
tendency, making excessive overcorrection, leading to low precision. To
effectively harness the strengths of LLMs to address the recall challenges in
sLMs, we propose Post-Correction via Overcorrection (PoCO), a novel approach
that strategically balances recall and precision. PoCO first intentionally
triggers overcorrection via LLM to maximize recall by allowing comprehensive
revisions, then applies a targeted post-correction step via fine-tuning smaller
models to identify and refine erroneous outputs. We aim to harmonize both
aspects by leveraging the generative power of LLMs while preserving the
reliability of smaller supervised models. Our extensive experiments demonstrate
that PoCO effectively balances GEC performance by increasing recall with
competitive precision, ultimately improving the overall quality of grammatical
error correction.

</details>


### [53] [Distilling Many-Shot In-Context Learning into a Cheat Sheet](https://arxiv.org/abs/2509.20820)
*Ukyo Honda,Soichiro Murakami,Peinan Zhang*

Main category: cs.CL

TL;DR: cheat-sheet ICL把多例上下文学习浓缩为简明摘要，在推理时用更少的令牌取得与传统方法相当甚至更好的效果，大幅降低计算需求，是一种实用的替代方案。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型（LLMs）在使用多例（many-shot）上下文学习时，虽然表现优异，但需要处理大量输入令牌，计算开销很大。

Method: 提出了cheat-sheet ICL方法，通过将多例上下文学习的信息提炼成简明的文本摘要（cheat sheet），在推理阶段作为上下文使用。

Result: 在具有挑战性的推理任务中，cheat-sheet ICL使用更少的令牌，表现与多例上下文学习相当或更优，并且不需检索，在性能上也可匹敌基于检索的方法。

Conclusion: cheat-sheet ICL是一种实用、计算高效的方案，可用于提升下游任务中大语言模型的表现。

Abstract: Recent advances in large language models (LLMs) enable effective in-context
learning (ICL) with many-shot examples, but at the cost of high computational
demand due to longer input tokens. To address this, we propose cheat-sheet ICL,
which distills the information from many-shot ICL into a concise textual
summary (cheat sheet) used as the context at inference time. Experiments on
challenging reasoning tasks show that cheat-sheet ICL achieves comparable or
better performance than many-shot ICL with far fewer tokens, and matches
retrieval-based ICL without requiring test-time retrieval. These findings
demonstrate that cheat-sheet ICL is a practical alternative for leveraging LLMs
in downstream tasks.

</details>


### [54] [Zero-Shot Privacy-Aware Text Rewriting via Iterative Tree Search](https://arxiv.org/abs/2509.20838)
*Shuo Huang,Xingliang Yuan,Gholamreza Haffari,Lizhen Qu*

Main category: cs.CL

TL;DR: 针对LLM用户输入的隐私泄露问题，提出了零样本树搜索句子改写新算法，能更好地隐藏敏感信息并保持文本质量，在实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在云服务中的广泛应用，用户输入可能会泄露敏感信息，因而引发了隐私担忧。现有的文本匿名化和去标识化技术（如基于规则的编辑和清理）难以兼顾隐私保护与文本自然度与实用性。

Method: 提出了一种零样本、基于树搜索的迭代句子改写算法，系统性地混淆或删除私密信息，同时保留文本的连贯性、相关性和自然性。该方法通过由奖励模型引导的结构化搜索，递增式地改写隐私敏感段落，动态探索改写空间。

Result: 在隐私敏感数据集上的实验显示，该方法在隐私保护与文本实用性之间取得了显著优于已有技术的平衡。

Conclusion: 所提出的算法能有效提升隐私保护水平，同时保持文本自然和有用，优于现有基线方法。

Abstract: The increasing adoption of large language models (LLMs) in cloud-based
services has raised significant privacy concerns, as user inputs may
inadvertently expose sensitive information. Existing text anonymization and
de-identification techniques, such as rule-based redaction and scrubbing, often
struggle to balance privacy preservation with text naturalness and utility. In
this work, we propose a zero-shot, tree-search-based iterative sentence
rewriting algorithm that systematically obfuscates or deletes private
information while preserving coherence, relevance, and naturalness. Our method
incrementally rewrites privacy-sensitive segments through a structured search
guided by a reward model, enabling dynamic exploration of the rewriting space.
Experiments on privacy-sensitive datasets show that our approach significantly
outperforms existing baselines, achieving a superior balance between privacy
protection and utility preservation.

</details>


### [55] [Concise and Sufficient Sub-Sentence Citations for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.20859)
*Guo Chen,Qiuyuan Li,Qiuxian Li,Hongliang Dai,Xiang Chen,Piji Li*

Main category: cs.CL

TL;DR: 本文提出了一种子句级别文献引用框架，提升了RAG系统中引用的相关性与可读性，让用户更易验证生成答案的准确性。


<details>
  <summary>Details</summary>
Motivation: 在RAG问答系统中，现有的引用生成方式通常在句子或段落级别进行，这会导致引用包含大量无关内容，且可能遗漏关键信息，增加用户验证负担。

Method: 提出了一套注释标准并构建了数据集；提出了一种新的归因框架，包括利用大语言模型自动生成微调数据，结合信用模型过滤低质量样本，以实现高质量子句级别引用生成。

Result: 实验证明，所提方法可以生成更加优质且可读性更高的引用，有效提升了用户验证的便捷性。

Conclusion: 子句级别的引用可更好地保障生成答案的可验证性和易用性，并且新的归因框架确实能优化引用质量。

Abstract: In retrieval-augmented generation (RAG) question answering systems,
generating citations for large language model (LLM) outputs enhances
verifiability and helps users identify potential hallucinations. However, we
observe two problems in the citations produced by existing attribution methods.
First, the citations are typically provided at the sentence or even paragraph
level. Long sentences or paragraphs may include a substantial amount of
irrelevant content. Second, sentence-level citations may omit information that
is essential for verifying the output, forcing users to read the surrounding
context. In this paper, we propose generating sub-sentence citations that are
both concise and sufficient, thereby reducing the effort required by users to
confirm the correctness of the generated output. To this end, we first develop
annotation guidelines for such citations and construct a corresponding dataset.
Then, we propose an attribution framework for generating citations that adhere
to our standards. This framework leverages LLMs to automatically generate
fine-tuning data for our task and employs a credit model to filter out
low-quality examples. Our experiments on the constructed dataset demonstrate
that the propose approach can generate high-quality and more readable
citations.

</details>


### [56] [WeFT: Weighted Entropy-driven Fine-Tuning for dLLMs](https://arxiv.org/abs/2509.20863)
*Guowei Xu,Wenxin Xu,Jiawang Zhao,Kaisheng Ma*

Main category: cs.CL

TL;DR: 扩散语言模型虽有强表现，但微调难以实现可控性。作者提出基于熵加权的微调方法WeFT，大幅提升了四个推理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在语言建模方面显示出很强的潜力，且生成速度快于传统自回归方法。但将监督微调（SFT）应用于扩散模型存在挑战，主要因其在每个去噪步骤上缺乏准确的概率估计。这导致生成过程不可预测且结果不一致，尤为需要对关键标记进行有效控制，以引导生成方向。

Method: 提出了一种基于扩散理论的加权监督微调方法——WeFT，通过为不同标记分配基于信息熵的权重，增强对生成结果的控制。

Result: 在open-r1数据集上的s1K、s1K-1.1和3k样本进行训练，在四个推理基准（Sudoku，Countdown，GSM8K和MATH-500）上，相较标准SFT方法取得了分别为39%、64%、83%的性能提升。

Conclusion: WeFT有效解决了扩散语言模型监督微调中的可控性问题，显著提高了模型在推理任务中的表现。

Abstract: Diffusion models have recently shown strong potential in language modeling,
offering faster generation compared to traditional autoregressive approaches.
However, applying supervised fine-tuning (SFT) to diffusion models remains
challenging, as they lack precise probability estimates at each denoising step.
While the diffusion mechanism enables the model to reason over entire
sequences, it also makes the generation process less predictable and often
inconsistent. This highlights the importance of controlling key tokens that
guide the direction of generation. To address this issue, we propose WeFT, a
weighted SFT method for diffusion language models, where tokens are assigned
different weights based on their entropy. Derived from diffusion theory, WeFT
delivers substantial gains: training on s1K, s1K-1.1, and 3k samples from
open-r1, it achieves relative improvements of 39%, 64%, and 83% over standard
SFT on four widely used reasoning benchmarks (Sudoku, Countdown, GSM8K, and
MATH-500). The code and models will be made publicly available.

</details>


### [57] [Single Answer is Not Enough: On Generating Ranked Lists with Medical Reasoning Models](https://arxiv.org/abs/2509.20866)
*Pittawat Taveekitworachai,Natpatchara Pongjirapat,Krittaphas Chaisutyakorn,Piyalitt Ittichaiwong,Tossaporn Saengja,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 本研究首次提出并系统分析医学推理模型输出答案排名列表的新方法，发现使用奖励微调（RFT）可显著提升模型在多种答案格式上的稳健性，有望推动临床实际所需的多元答案生成。


<details>
  <summary>Details</summary>
Motivation: 临床决策通常不只依赖单一答案，而是考虑多个选项，以减少风险。然而现有医学推理模型（MRMs）往往被训练为只输出一个答案，即使在开放式问题情景下也是如此。因此，作者希望探索MRMs产生排名列表答案的新格式，以更好反映实际医疗决策过程。

Method: 作者提出将MRMs的输出格式改为答案排名列表，并系统性研究了两种方法：提示式（prompting）和微调（包括监督微调SFT和奖励微调RFT）。借助新设的奖励函数针对排名列表格式进行RFT，并通过消融实验分析其效果。研究比较了不同训练方式在多种答案格式（选择题、简短文本、列表答案）上的泛化能力。

Result: 结果显示，部分SFT模型能够泛化到某些答案格式，但采用RFT训练的模型在多种答案格式下表现更为稳健。此外，通过在改进后的MedQA多答案数据集上的案例研究发现，虽然MRM未必选择基准的理想答案，但能够识别其它合理有效的答案。

Conclusion: 首次系统性探索了使MRMs输出排名列表答案的方法，证明了RFT训练的MRMs在处理多格式开放式答案时更为鲁棒，为医学领域多元化答案格式的发展提供了新思路。

Abstract: This paper presents a systematic study on enabling medical reasoning models
(MRMs) to generate ranked lists of answers for open-ended questions. Clinical
decision-making rarely relies on a single answer but instead considers multiple
options, reducing the risks of narrow perspectives. Yet current MRMs are
typically trained to produce only one answer, even in open-ended settings. We
propose an alternative format: ranked lists and investigate two approaches:
prompting and fine-tuning. While prompting is a cost-effective way to steer an
MRM's response, not all MRMs generalize well across different answer formats:
choice, short text, and list answers. Based on our prompting findings, we train
and evaluate MRMs using supervised fine-tuning (SFT) and reinforcement
fine-tuning (RFT). SFT teaches a model to imitate annotated responses, and RFT
incentivizes exploration through the responses that maximize a reward. We
propose new reward functions targeted at ranked-list answer formats, and
conduct ablation studies for RFT. Our results show that while some SFT models
generalize to certain answer formats, models trained with RFT are more robust
across multiple formats. We also present a case study on a modified MedQA with
multiple valid answers, finding that although MRMs might fail to select the
benchmark's preferred ground truth, they can recognize valid answers. To the
best of our knowledge, this is the first systematic investigation of approaches
for enabling MRMs to generate answers as ranked lists. We hope this work
provides a first step toward developing alternative answer formats that are
beneficial beyond single answers in medical domains.

</details>


### [58] [Learning to Summarize by Learning to Quiz: Adversarial Agentic Collaboration for Long Document Summarization](https://arxiv.org/abs/2509.20900)
*Weixuan Wang,Minghao Wu,Barry Haddow,Alexandra Birch*

Main category: cs.CL

TL;DR: 该论文提出了结合摘要与测验的对抗协作智能体框架SummQ，有效改善了长文档摘要质量，并在多项指标和评估中超过了当前最优方法。


<details>
  <summary>Details</summary>
Motivation: 长文档摘要对于目前的大型语言模型（LLM）仍然极具挑战性，常见方法容易出现信息丢失、事实不一致和连贯性差等问题。因此，作者希望寻求新的解决方案提升长文本摘要的质量。

Method: 提出了SummQ，一种新颖的多智能体对抗协作框架，通过专门的摘要和测验智能体的协同工作来改进摘要过程。摘要生成和评论智能体协作生成和评估摘要，测验生成和评论智能体则持续通过问答评估摘要质量，引入考生智能体用于判断摘要是否含有解答测验所需的信息，实现多维度反馈和迭代优化。

Result: 在三个主流长文档摘要基准测试上，SummQ在ROUGE、BERTScore等自动指标，以及LLM-as-a-Judge和人工评估上均显著优于现有方法。分析还揭示了多智能体协作、智能体配置和测验机制对摘要质量的积极影响。

Conclusion: SummQ利用多智能体的对抗协作机制，有效提升了长文档摘要的质量，为长文本处理领域提供了全新的路径。

Abstract: Long document summarization remains a significant challenge for current large
language models (LLMs), as existing approaches commonly struggle with
information loss, factual inconsistencies, and coherence issues when processing
excessively long documents. We propose SummQ, a novel adversarial multi-agent
framework that addresses these limitations through collaborative intelligence
between specialized agents operating in two complementary domains:
summarization and quizzing. Our approach employs summary generators and
reviewers that work collaboratively to create and evaluate comprehensive
summaries, while quiz generators and reviewers create comprehension questions
that serve as continuous quality checks for the summarization process. This
adversarial dynamic, enhanced by an examinee agent that validates whether the
generated summary contains the information needed to answer the quiz questions,
enables iterative refinement through multifaceted feedback mechanisms. We
evaluate SummQ on three widely used long document summarization benchmarks.
Experimental results demonstrate that our framework significantly outperforms
existing state-of-the-art methods across ROUGE and BERTScore metrics, as well
as in LLM-as-a-Judge and human evaluations. Our comprehensive analyses reveal
the effectiveness of the multi-agent collaboration dynamics, the influence of
different agent configurations, and the impact of the quizzing mechanism. This
work establishes a new approach for long document summarization that uses
adversarial agentic collaboration to improve summarization quality.

</details>


### [59] [MemLens: Uncovering Memorization in LLMs with Activation Trajectories](https://arxiv.org/abs/2509.20909)
*Zirui He,Haiyan Zhao,Ali Payani,Mengnan du*

Main category: cs.CL

TL;DR: 提出了基于概率轨迹的新方法MemLens，有效检测LLM在基准测试中是否记忆化污染数据，实验证明其对记忆化信号的判别能力强，优于传统检测手段。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）评测方法面临基准数据易被污染和模型记忆化的问题，现有检测方法泛化能力差，尤其难以检测隐性记忆化。

Method: 提出了MemLens，通过分析模型生成过程中数值token的概率轨迹，来检测记忆化。方法揭示模型在污染数据和干净数据上的推理路径差异，用LoRA微调人工注入污染样本，进一步检验方法有效性。

Result: 污染样本在模型浅层就会对答案锁定高置信度，而干净样本则是在整个模型深度中逐步累积证据。污染与干净样本具有明显区分的推理轨迹。通过人工注入污染数据，MemLens表现出与自然污染一致的检测效果，证明方法能捕捉真实记忆化信号。

Conclusion: MemLens能够有效检测出LLM在各类污染数据中的记忆化行为，且优于仅基于表层特征的传统方法，能够为模型评测带来更准确的信号。

Abstract: Large language models (LLMs) are commonly evaluated on challenging benchmarks
such as AIME and Math500, which are susceptible to contamination and risk of
being memorized. Existing detection methods, which primarily rely on
surface-level lexical overlap and perplexity, demonstrate low generalization
and degrade significantly when encountering implicitly contaminated data. In
this paper, we propose MemLens (An Activation Lens for Memorization Detection)
to detect memorization by analyzing the probability trajectories of numeric
tokens during generation. Our method reveals that contaminated samples exhibit
``shortcut'' behaviors, locking onto an answer with high confidence in the
model's early layers, whereas clean samples show more gradual evidence
accumulation across the model's full depth. We observe that contaminated and
clean samples exhibit distinct and well-separated reasoning trajectories. To
further validate this, we inject carefully designed samples into the model
through LoRA fine-tuning and observe the same trajectory patterns as in
naturally contaminated data. These results provide strong evidence that MemLens
captures genuine signals of memorization rather than spurious correlations.

</details>


### [60] [Cross-Linguistic Analysis of Memory Load in Sentence Comprehension: Linear Distance and Structural Density](https://arxiv.org/abs/2509.20916)
*Krishna Aggarwal*

Main category: cs.CL

TL;DR: 本文采用多语言依存句法树库与混合效应模型，细致分析句子长度、依存距离及插入复杂度对句级记忆负担的影响。结果显示结构复杂度（插入中心数）比线性距离更能解释记忆负担，既融合了线性和结构观点，也为记忆负担理论评估提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在探究在句子理解过程中，句级记忆负担与句法相关词语之间的线性距离，还是与这些词之间插入部分的结构密度关系更大。研究关注于记忆负担的预测因素，并试图通过更精细的结构化指标来完善现有的线性距离模型。

Method: 研究采用了一致化依存句法树库以及横跨多种语言的混合效应模型框架，同时对句子长度、依存距离和插入复杂度（即依存中心之间的插入中心数目）进行联合分析，评估其对句级记忆负担的预测力。对于心理语言学上的特征干扰和错误绑定对记忆负担的贡献，作者采用其线性总和作为操作性定义。

Result: 发现三大因素（句子长度、依存距离、插入复杂度）都与记忆负担呈正相关关系。句子长度影响最广泛，而插入复杂度在解释力上优于单纯的线性距离，能更好地反映结构整合和记忆维持需求。

Conclusion: 研究结果将线性和结构化视角融合，为记忆负担理论提供了新的解释：线性距离是重要表征，但结构中插入的中心节点更直接反映认知处理负担。通过跨语言、结构化的图指标和高效建模，本研究为判别竞争性理论提供了方法学路径和实证支持。

Abstract: This study examines whether sentence-level memory load in comprehension is
better explained by linear proximity between syntactically related words or by
the structural density of the intervening material. Building on locality-based
accounts and cross-linguistic evidence for dependency length minimization, the
work advances Intervener Complexity-the number of intervening heads between a
head and its dependent-as a structurally grounded lens that refines linear
distance measures. Using harmonized dependency treebanks and a mixed-effects
framework across multiple languages, the analysis jointly evaluates sentence
length, dependency length, and Intervener Complexity as predictors of the
Memory-load measure. Studies in Psycholinguistics have reported the
contributions of feature interference and misbinding to memory load during
processing. For this study, I operationalized sentence-level memory load as the
linear sum of feature misbinding and feature interference for tractability;
current evidence does not establish that their cognitive contributions combine
additively. All three factors are positively associated with memory load, with
sentence length exerting the broadest influence and Intervener Complexity
offering explanatory power beyond linear distance. Conceptually, the findings
reconcile linear and hierarchical perspectives on locality by treating
dependency length as an important surface signature while identifying
intervening heads as a more proximate indicator of integration and maintenance
demands. Methodologically, the study illustrates how UD-based graph measures
and cross-linguistic mixed-effects modelling can disentangle linear and
structural contributions to processing efficiency, providing a principled path
for evaluating competing theories of memory load in sentence comprehension.

</details>


### [61] [Tool Calling for Arabic LLMs: Data Strategies and Instruction Tuning](https://arxiv.org/abs/2509.20957)
*Asim Ersoy,Enes Altinisik,Husrev Taha Sencar,Kareem Darwish*

Main category: cs.CL

TL;DR: 本文针对阿拉伯语工具调用的研究空白，通过数据集适配和实验，探索了三种提升工具调用性能的策略，总结出开发阿拉伯语工具增强LLM的关键经验和建议。


<details>
  <summary>Details</summary>
Motivation: 目前对于大型语言模型（LLM）的工具调用几乎都集中在英文领域，缺乏对阿拉伯语等其他语言的相关研究和数据资源。本文旨在解决这一资源和研究空白。

Method: 本文通过将两份开源英文工具调用数据集翻译并适配为阿拉伯语版本，构建了相关实验资源。随后，以阿拉伯语开源LLM的基础模型及其不同后训练变体为对象，分别开展了在本地工具调用数据和跨语言迁移、通用指令微调以及对特定重点工具微调的工具调用性能对比实验。

Result: 实验揭示了以下关键点：（1）在本地语言（阿拉伯语）工具调用数据与跨语言迁移之间的权衡与作用；（2）通用指令微调对工具调用性能的影响；（3）对高优先级工具进行专门微调的价值。

Conclusion: 本研究提出并验证了构建及优化阿拉伯语工具增强智能体的有效策略，推动了非英语工具调用领域的数据资源建设和方法研究。

Abstract: Tool calling is a critical capability that allows Large Language Models
(LLMs) to interact with external systems, significantly expanding their
utility. However, research and resources for tool calling are predominantly
English-centric, leaving a gap in our understanding of how to enable this
functionality for other languages, such as Arabic. This paper investigates
three key research questions: (1) the necessity of in-language (Arabic)
tool-calling data versus relying on cross-lingual transfer, (2) the effect of
general-purpose instruction tuning on tool-calling performance, and (3) the
value of fine-tuning on specific, high-priority tools. To address these
questions, we conduct extensive experiments using base and post-trained
variants of an open-weight Arabic LLM. To enable this study, we bridge the
resource gap by translating and adapting two open-source tool-calling datasets
into Arabic. Our findings provide crucial insights into the optimal strategies
for developing robust tool-augmented agents for Arabic.

</details>


### [62] [Analysis of instruction-based LLMs' capabilities to score and judge text-input problems in an academic setting](https://arxiv.org/abs/2509.20982)
*Valeria Ramirez-Garcia,David de-Fitero-Dominguez,Antonio Garcia-Cabot,Eva Garcia-Lopez*

Main category: cs.CL

TL;DR: 本文探索了多种基于大语言模型的文本题自动化评分方法，发现参考答案辅助的评估系统在与真人评分的接近度和评价质量上最佳，验证了AI在教育自动评估中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在教育领域常被用作辅助教学工具，但其作为评估者的能力尚未深入探索，尤其是在自动化评估学生文本输入题目方面。该研究旨在填补LLM作为自动化学术评估工具的应用空白。

Method: 研究提出并测试了五种基于LLM的自动评估系统，分别为JudgeLM评估、参考辅助评估、无参考评估、增量评估和自适应评估。所有方法都在一个含有110道高等教育学生计算机科学答案的数据集上，使用JudgeLM、Llama-3.1-8B和DeepSeek-R1-Distill-Llama-8B三种模型进行比较，并与人类评估结果对比。

Result: 参考辅助评估法在与人类评估对比中表现最优，获得最低的中位绝对偏差（0.945）和均方根偏差（1.214），能同时提供公平、有洞察力及全面的评估。增量与自适应评估在简短答案场景下效果不理想，无参考评估因缺乏关键信息无法准确评分，JudgeLM因模型局限性表现较差。

Conclusion: 人工智能驱动的自动学术评估系统，通过合理方法辅助，可以成为学术资源的有益补充工具。

Abstract: Large language models (LLMs) can act as evaluators, a role studied by methods
like LLM-as-a-Judge and fine-tuned judging LLMs. In the field of education,
LLMs have been studied as assistant tools for students and teachers. Our
research investigates LLM-driven automatic evaluation systems for academic
Text-Input Problems using rubrics. We propose five evaluation systems that have
been tested on a custom dataset of 110 answers about computer science from
higher education students with three models: JudgeLM, Llama-3.1-8B and
DeepSeek-R1-Distill-Llama-8B. The evaluation systems include: The JudgeLM
evaluation, which uses the model's single answer prompt to obtain a score;
Reference Aided Evaluation, which uses a correct answer as a guide aside from
the original context of the question; No Reference Evaluation, which ommits the
reference answer; Additive Evaluation, which uses atomic criteria; and Adaptive
Evaluation, which is an evaluation done with generated criteria fitted to each
question. All evaluation methods have been compared with the results of a human
evaluator. Results show that the best method to automatically evaluate and
score Text-Input Problems using LLMs is Reference Aided Evaluation. With the
lowest median absolute deviation (0.945) and the lowest root mean square
deviation (1.214) when compared to human evaluation, Reference Aided Evaluation
offers fair scoring as well as insightful and complete evaluations. Other
methods such as Additive and Adaptive Evaluation fail to provide good results
in concise answers, No Reference Evaluation lacks information needed to
correctly assess questions and JudgeLM Evaluations have not provided good
results due to the model's limitations. As a result, we conclude that
Artificial Intelligence-driven automatic evaluation systems, aided with proper
methodologies, show potential to work as complementary tools to other academic
resources.

</details>


### [63] [Generative AI for FFRDCs](https://arxiv.org/abs/2509.21040)
*Arun S. Maiya*

Main category: cs.CL

TL;DR: 通过开源本地部署的OnPrem.LLM框架，FFRDCs可安全高效地利用大语言模型对政策和科学文献进行自动处理，显著提升监督与分析能力，保证数据可控。


<details>
  <summary>Details</summary>
Motivation: FFRDCs需要高效处理大量政策及科研相关的文本数据，手动分析耗时且低效，亟需自动化、智能化工具以提高工作效率且保证数据安全。

Method: 结合大型语言模型，通过少量输入输出样例，实现了文本的自动摘要、分类、抽取与分析，并采用OnPrem.LLM框架进行部署，确保数据本地化与安全。

Result: 在国防政策文件和科研项目数据（如NDAA和NSF Awards）上的案例分析显示，该方法不仅提升了文本处理速度和质量，还增强了对战略层面的监督和分析能力，同时保持了数据主权和可审计性。

Conclusion: 应用开源工具OnPrem.LLM，可以在确保数据安全和可审计性的前提下，将生成式AI有效应用于敏感政府环境中，显著提升FFRDCs处理文本密集型任务的效率。

Abstract: Federally funded research and development centers (FFRDCs) face text-heavy
workloads, from policy documents to scientific and engineering papers, that are
slow to analyze manually. We show how large language models can accelerate
summarization, classification, extraction, and sense-making with only a few
input-output examples. To enable use in sensitive government contexts, we apply
OnPrem$.$LLM, an open-source framework for secure and flexible application of
generative AI. Case studies on defense policy documents and scientific corpora,
including the National Defense Authorization Act (NDAA) and National Science
Foundation (NSF) Awards, demonstrate how this approach enhances oversight and
strategic analysis while maintaining auditability and data sovereignty.

</details>


### [64] [Behind RoPE: How Does Causal Mask Encode Positional Information?](https://arxiv.org/abs/2509.21042)
*Junu Kim,Xiao Liu,Zhenghao Lin,Lei Ji,Yeyun Gong,Edward Choi*

Main category: cs.CL

TL;DR: 因果掩码不仅提供隐式的位置信息，还会扭曲显式位置编码RoPE的效果，建议今后必须将因果掩码作为位置信息的重要来源之一进行考量。


<details>
  <summary>Details</summary>
Motivation: 当前Transformer主要依赖显式位置编码（如RoPE）来注入位置信息，但作者怀疑因果掩码本身就是一个隐式的位置信息来源，因此需要分析它的实际影响。

Method: 理论分析和实验验证，证明了Transformer解码器中的因果掩码（causal mask）本身可以引入位置信息，并分析了因果掩码与显式位置编码（如RoPE）的交互效应。

Result: 理论分析显示，即使没有参数或输入的因果关系，因果掩码也会导致注意力分数中出现基于位置的模式，并且倾向于增强相邻query-key对。实验证明该模式在经过训练的模型中同样存在；此外，因果掩码与RoPE的相互作用会导致RoPE的相对注意力分数模式失真。该效应在主流大语言模型中普遍观察到。

Conclusion: Transformer解码器中的因果掩码会诱发位置相关模式，其与显式位置编码的交互会影响最终的注意力表现，因此未来模型设计和分析时需重点关注这一点。

Abstract: While explicit positional encodings such as RoPE are a primary source of
positional information in Transformer decoders, the causal mask also provides
positional information. In this work, we prove that the causal mask can induce
position-dependent patterns in attention scores, even without parameters or
causal dependency in the input. Our theoretical analysis indicates that the
induced attention pattern tends to favor nearby query-key pairs, mirroring the
behavior of common positional encodings. Empirical analysis confirms that
trained models exhibit the same behavior, with learned parameters further
amplifying these patterns. Notably, we found that the interaction of causal
mask and RoPE distorts RoPE's relative attention score patterns into
non-relative ones. We consistently observed this effect in modern large
language models, suggesting the importance of considering the causal mask as a
source of positional information alongside explicit positional encodings.

</details>


### [65] [When Instructions Multiply: Measuring and Estimating LLM Capabilities of Multiple Instructions Following](https://arxiv.org/abs/2509.21051)
*Keno Harada,Yudai Yamazaki,Masachika Taniguchi,Edison Marrese-Taylor,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CL

TL;DR: 本文提出了针对文本和代码生成下的多指令遵循基准，发现LLM性能随指令数增加而下降，并用逻辑回归较准预测多指令情境下的表现，验证了用少量样本就能高效评估LLM多指令能力。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）在实际应用中会遇到需要同时遵循多条指令的场景，因此了解其遵循多指令的能力变得尤为重要。

Method: 作者提出了两个专门的基准测试：ManyIFEval（用于文本生成，最多十条指令）和StyleMBPP（用于代码生成，最多六条指令），并对十个主流LLM进行了系统实验评估。此外，开发了三种回归模型用于预测多指令组合下的性能，包括对未见过指令组合的预测。

Result: 结果显示，随着指令数量增加，模型性能会持续下降。通过以指令数量为解释变量的逻辑回归模型，可以以大约10%的误差预测未知指令组合的性能，且只需适中规模的样本量（ManyIFEval为500，StyleMBPP为300），即可高效估算LLM在不同组合指令下的表现。

Conclusion: LLM在多指令遵循方面存在性能下降现象，但可通过有效采样和简单回归模型进行高效性能估算，从而实现在实际应用中对多指令情境的快速评估。

Abstract: As large language models (LLMs) are increasingly applied to real-world
scenarios, it becomes crucial to understand their ability to follow multiple
instructions simultaneously. To systematically evaluate these capabilities, we
introduce two specialized benchmarks for fundamental domains where multiple
instructions following is important: Many Instruction-Following Eval
(ManyIFEval) for text generation with up to ten instructions, and Style-aware
Mostly Basic Programming Problems (StyleMBPP) for code generation with up to
six instructions. Our experiments with the created benchmarks across ten LLMs
reveal that performance consistently degrades as the number of instructions
increases. Furthermore, given the fact that evaluating all the possible
combinations of multiple instructions is computationally impractical in actual
use cases, we developed three types of regression models that can estimate
performance on both unseen instruction combinations and different numbers of
instructions which are not used during training. We demonstrate that a logistic
regression model using instruction count as an explanatory variable can predict
performance of following multiple instructions with approximately 10% error,
even for unseen instruction combinations. We show that relatively modest sample
sizes (500 for ManyIFEval and 300 for StyleMBPP) are sufficient for performance
estimation, enabling efficient evaluation of LLMs under various instruction
combinations.

</details>


### [66] [SoM-1K: A Thousand-Problem Benchmark Dataset for Strength of Materials](https://arxiv.org/abs/2509.21079)
*Qixin Wan,Zilong Wang,Jingwen Zhou,Wanting Wang,Ziheng Geng,Jiachen Liu,Ran Cao,Minghui Cheng,Lu Cheng*

Main category: cs.CL

TL;DR: 本论文发布SoM-1K多模态工程问题数据集，并提出图像文本描述提示，有效提升基础模型理解复杂工程问题的能力，但现有模型整体表现不佳，亟需更强多模态推理模型。


<details>
  <summary>Details</summary>
Motivation: 当前基础模型在多个领域表现优异，但在复杂、多模态的工程问题，尤其是材料强度领域的应用表现尚未充分探索。论文旨在填补该领域评估基准的空白，并探究模型在实际工程任务中的能力。

Method: 设计并推出SoM-1K数据集，涵盖1065个含文本和示意图的材料强度真实工程问题；提出新型提示策略“Descriptions of Images（DoI）”，由专家撰写图示的严谨文本描述作为上下文；评估了8种主流基础模型，包括大语言模型（LLM）和视觉语言模型（VLM）。

Result: 所有基础模型在此类工程问题上表现有限，最佳模型准确率仅56.6%；当LLM搭配DoI时通常优于VLM直接输入图像；DoI能够有效减少视觉误解错误，文本描述在当前模型下比图像输入更具帮助。

Conclusion: 建立了面向工程与科学AI的严格基准，揭示了基础模型在多模态推理能力上的重大不足，强调需针对工程领域开发更强大的多模态模型。

Abstract: Foundation models have shown remarkable capabilities in various domains, but
their performance on complex, multimodal engineering problems remains largely
unexplored. We introduce SoM-1K, the first large-scale multimodal benchmark
dataset dedicated to evaluating foundation models on problems in the strength
of materials (SoM). The dataset, which contains 1,065 annotated SoM problems,
mirrors real-world engineering tasks by including both textual problem
statements and schematic diagrams. Due to the limited capabilities of current
foundation models in understanding complicated visual information, we propose a
novel prompting strategy called Descriptions of Images (DoI), which provides
rigorous expert-generated text descriptions of the visual diagrams as the
context. We evaluate eight representative foundation models, including both
large language models (LLMs) and vision language models (VLMs). Our results
show that current foundation models struggle significantly with these
engineering problems, with the best-performing model achieving only 56.6%
accuracy. Interestingly, we found that LLMs, when provided with DoI, often
outperform VLMs provided with visual diagrams. A detailed error analysis
reveals that DoI plays a crucial role in mitigating visual misinterpretation
errors, suggesting that accurate text-based descriptions can be more effective
than direct image input for current foundation models. This work establishes a
rigorous benchmark for engineering AI and highlights a critical need for
developing more robust multimodal reasoning capabilities in foundation models,
particularly in scientific and engineering contexts.

</details>


### [67] [Which Cultural Lens Do Models Adopt? On Cultural Positioning Bias and Agentic Mitigation in LLMs](https://arxiv.org/abs/2509.21080)
*Yixin Wan,Xingrun Chen,Kai-Wei Chang*

Main category: cs.CL

TL;DR: LLM输出存在主流文化偏见，提出CultureLens评测和多代理公正干预方法，有效缓解生成内容的文化偏见。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型（LLM）在多种生成任务中表现优异，但存在潜在的文化公正性问题，尤其是其输出往往以美国主流文化为中心，对其他文化则表现出外部性。研究的动机在于发现并系统性分析这种新颖的文化定位偏见。

Method: 提出了CultureLens基准，包括4000条生成提示和3项评估指标，通过模拟LLM作为当地采访记者，生成涵盖10种不同文化的采访脚本，并对5个主流LLM进行偏见实证分析。同时，提出两种推理阶段消除偏见的方法：基线的公平干预支柱（FIP）提示法，以及结构化的多代理公平干预（MFA），包括单代理自反-重写机制（MFA-SA）和多代理分工协作流程（MFA-MA）。

Result: 实证评估显示，主流LLM在美国语境下生成的脚本88%以上采用“内部人”视角，而在其他不占主导地位的文化中则明显采用“外部人”视角。论文提出的基于代理的方法能有效降低文化定位偏见，提升脚本的公正性和中立性。

Conclusion: 文化定位偏见是真实存在的问题。CultureLens基准和代理方法为量化和缓解LLM的文化偏见提供了有效工具，使生成任务更具公正性和多样性。

Abstract: Large language models (LLMs) have unlocked a wide range of downstream
generative applications. However, we found that they also risk perpetuating
subtle fairness issues tied to culture, positioning their generations from the
perspectives of the mainstream US culture while demonstrating salient
externality towards non-mainstream ones. In this work, we identify and
systematically investigate this novel culture positioning bias, in which an
LLM's default generative stance aligns with a mainstream view and treats other
cultures as outsiders. We propose the CultureLens benchmark with 4000
generation prompts and 3 evaluation metrics for quantifying this bias through
the lens of a culturally situated interview script generation task, in which an
LLM is positioned as an onsite reporter interviewing local people across 10
diverse cultures. Empirical evaluation on 5 state-of-the-art LLMs reveals a
stark pattern: while models adopt insider tones in over 88 percent of
US-contexted scripts on average, they disproportionately adopt mainly outsider
stances for less dominant cultures. To resolve these biases, we propose 2
inference-time mitigation methods: a baseline prompt-based Fairness
Intervention Pillars (FIP) method, and a structured Mitigation via Fairness
Agents (MFA) framework consisting of 2 pipelines: (1) MFA-SA (Single-Agent)
introduces a self-reflection and rewriting loop based on fairness guidelines.
(2) MFA-MA (Multi-Agent) structures the process into a hierarchy of specialized
agents: a Planner Agent(initial script generation), a Critique Agent (evaluates
initial script against fairness pillars), and a Refinement Agent (incorporates
feedback to produce a polished, unbiased script). Empirical results showcase
the effectiveness of agent-based methods as a promising direction for
mitigating biases in generative LLMs.

</details>


### [68] [PerHalluEval: Persian Hallucination Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2509.21104)
*Mohammad Hosseini,Kimia Hosseini,Shayan Bali,Zahra Zanjani,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 本文提出了波斯语幻觉评测基准PerHalluEval，结合自动和人工方法系统性检测LLM幻觉问题。结果显示，现有LLM在波斯语幻觉检测上表现不佳，提供原始文档可略有改善，同时波斯语专向训练的LLM也未明显优于其他模型。


<details>
  <summary>Details</summary>
Motivation: 大多数大型语言模型在低资源语言（如波斯语）中更易产生幻觉（错误或虚假的生成内容），而相关的系统性评估工具缺乏，影响模型在这些语言环境下的实际应用。

Method: 提出了PerHalluEval，这是首个专门针对波斯语幻觉评估的动态基准，结合三阶段LLM主导流程与人工验证，涵盖了问答与摘要两项任务，并利用LLM生成的token概率甄选可信的幻觉实例。同时，引入人工标注强调波斯语特定文化背景，并测试了不同LLM的表现。

Result: 对12个LLM在PerHalluEval上的评测显示，各模型普遍难以检测波斯语中的幻觉文本。通过提供外部知识（原始文档），能部分缓解幻觉问题。此外，专为波斯语训练的LLM与通用LLM在幻觉表现上无显著差异。

Conclusion: 波斯语等低资源语言下，LLM普遍幻觉严重，现有模型检测能力有限，基于专家知识可稍有改善，而特定语种模型未显示出明显优势。PerHalluEval为相关模型评估和改进提供了新的工具。

Abstract: Hallucination is a persistent issue affecting all large language Models
(LLMs), particularly within low-resource languages such as Persian.
PerHalluEval (Persian Hallucination Evaluation) is the first dynamic
hallucination evaluation benchmark tailored for the Persian language. Our
benchmark leverages a three-stage LLM-driven pipeline, augmented with human
validation, to generate plausible answers and summaries regarding QA and
summarization tasks, focusing on detecting extrinsic and intrinsic
hallucinations. Moreover, we used the log probabilities of generated tokens to
select the most believable hallucinated instances. In addition, we engaged
human annotators to highlight Persian-specific contexts in the QA dataset in
order to evaluate LLMs' performance on content specifically related to Persian
culture. Our evaluation of 12 LLMs, including open- and closed-source models
using PerHalluEval, revealed that the models generally struggle in detecting
hallucinated Persian text. We showed that providing external knowledge, i.e.,
the original document for the summarization task, could mitigate hallucination
partially. Furthermore, there was no significant difference in terms of
hallucination when comparing LLMs specifically trained for Persian with others.

</details>


### [69] [BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback](https://arxiv.org/abs/2509.21106)
*Hyunseo Kim,Sangam Lee,Kwangwook Seo,Dongha Lee*

Main category: cs.CL

TL;DR: 本文针对缺乏个性化评估的问题，提出了BESPOKE真实数据基准，通过人类真实历史和详细反馈，推动检索增强型LLM的个性化能力与评估发展。


<details>
  <summary>Details</summary>
Motivation: 当前基于检索的大型语言模型（LLM）虽然提升了信息检索任务的效果，减轻了用户的认知负担，但对于用户多样化的需求，尤其是同一查询在不同用户间体现不同意图、信息以用户偏好形式展现，仍不充分。个性化评估体系也尚未建立。

Method: 作者提出了BESPOKE基准，通过收集真实用户的聊天和搜索历史，结合细粒度的偏好打分与反馈，长期深入的人类标注来实现个性化信息需求和响应评价。

Result: 利用BESPOKE基准，系统性分析了高效个性化信息检索所需的关键条件，为个性化检索型LLM的细粒度评估奠定了基础。

Conclusion: BESPOKE为评估检索增强型LLM的个性化提供了真实且诊断性的数据集，推动了个性化信息检索系统发展。

Abstract: Search-augmented large language models (LLMs) have advanced
information-seeking tasks by integrating retrieval into generation, reducing
users' cognitive burden compared to traditional search systems. Yet they remain
insufficient for fully addressing diverse user needs, which requires
recognizing how the same query can reflect different intents across users and
delivering information in preferred forms. While recent systems such as ChatGPT
and Gemini attempt personalization by leveraging user histories, systematic
evaluation of such personalization is under-explored. To address this gap, we
propose BESPOKE, the realistic benchmark for evaluating personalization in
search-augmented LLMs. BESPOKE is designed to be both realistic, by collecting
authentic chat and search histories directly from humans, and diagnostic, by
pairing responses with fine-grained preference scores and feedback. The
benchmark is constructed through long-term, deeply engaged human annotation,
where human annotators contributed their own histories, authored queries with
detailed information needs, and evaluated responses with scores and diagnostic
feedback. Leveraging BESPOKE, we conduct systematic analyses that reveal key
requirements for effective personalization in information-seeking tasks,
providing a foundation for fine-grained evaluation of personalized
search-augmented LLMs. Our code and data are available at
https://augustinlib.github.io/BESPOKE/.

</details>


### [70] [VoiceBBQ: Investigating Effect of Content and Acoustics in Social Bias of Spoken Language Model](https://arxiv.org/abs/2509.21108)
*Junhyuk Choi,Ro-hoon Oh,Jihwan Seol,Bugeun Kim*

Main category: cs.CL

TL;DR: VoiceBBQ首次实现对口语模型的系统性偏见检测，既能测内容偏见，也能测语音偏见。有助于优化和选择更公平的口语AI模型。


<details>
  <summary>Details</summary>
Motivation: 口语语言模型（SLMs）可能存在内容和语音两个层面的社会偏见，目前缺乏可以有效检测这两类偏见的基准测试工具。

Method: 提出了VoiceBBQ，一个BBQ（文本偏见基准）在语音领域的扩展。它将原始文本测试集转换为有控制的语音数据，并能分别评估SLM的内容偏见和语音（音色、性别、口音等）偏见。

Result: 用VoiceBBQ对LLaMA-Omni与Qwen2-Audio两个SLM进行了评估。LLaMA-Omni对语音偏见较为抵抗，但会加强性别与口音偏见；Qwen2-Audio则明显减弱这些偏见，同时能较好保持内容准确性。

Conclusion: VoiceBBQ是一个紧凑而易用的工具，能同时诊断SLM在内容和语音方面的社会偏见，为后续相关模型评估与改进提供了良好基础。

Abstract: We introduce VoiceBBQ, a spoken extension of the BBQ (Bias Benchmark for
Question Answering) - a dataset that measures social bias by presenting
ambiguous or disambiguated contexts followed by questions that may elicit
stereotypical responses. Due to the nature of speech, social bias in Spoken
Language Models (SLMs) can emerge from two distinct sources: 1) content aspect
and 2) acoustic aspect. The dataset converts every BBQ context into controlled
voice conditions, enabling per-axis accuracy, bias, and consistency scores that
remain comparable to the original text benchmark. Using VoiceBBQ, we evaluate
two SLMs - LLaMA-Omni and Qwen2-Audio - and observe architectural contrasts:
LLaMA-Omni resists acoustic bias while amplifying gender and accent bias,
whereas Qwen2-Audio substantially dampens these cues while preserving content
fidelity. VoiceBBQ thus provides a compact, drop-in testbed for jointly
diagnosing content and acoustic bias across spoken language models.

</details>


### [71] [Acoustic-based Gender Differentiation in Speech-aware Language Models](https://arxiv.org/abs/2509.21125)
*Junhyuk Choi,Jihwan Seol,Nayeon Kim,Chanhee Cho,EunBin Cho,Bugeun Kim*

Main category: cs.CL

TL;DR: 本文系统分析了语音感知语言模型中的性别偏见问题，提出新数据集并发现：虽然模型在不同性别下表现出表面一致，但实际存在偏向男性的悖论性响应，根源于语音编码器。强调需研发更有效的技术以实现语音交互的性别公平。


<details>
  <summary>Details</summary>
Motivation: 目前的语音感知语言模型（SpeechLMs）存在因说话人性别导致的响应差异，即使面对相同问题，不同性别的说话者可能得到不同的系统回答。如何系统性分析和缓解这些模型中的性别偏见，是提升人机语音交互公平性的重要问题。

Method: 本文提出了一个新的数据集，涵盖9,208个语音样本，分为三类：性别独立、性别刻板印象和性别相关问题。利用该数据集，作者系统评估了LLaMA-Omni系列语音语言模型，并与其底层LLMs做对比分析，同时探究了模型中性化处理以及语音编码器（Whisper）的影响。

Result: 实验发现：在性别刻板印象问题上，SpeechLMs普遍给予偏向男性的回答；而在语境要求区分性别的问题上，模型反而显示与性别无关的答复。排除了中性选项和语音感知性别等因素后，发现这一悖论主要源自Whisper语音编码器生成了偏向男性的声学标记。中性处理无法有效消除这一现象。

Conclusion: 当前SpeechLMs虽然试图实现普遍公平原则，但在涉及性别相关语境时未能适当利用性别信息，未能真正消除性别偏见。未来需要更精细的方法来合理处理语音交互中的性别信息，实现技术层面上的语境公平性。

Abstract: Speech-aware Language Models (SpeechLMs) have fundamentally transformed
human-AI interaction by enabling voice-based communication, yet they may
exhibit acoustic-based gender differentiation where identical questions lead to
different responses based on the speaker's gender. This paper propose a new
dataset that enables systematic analysis of this phenomenon, containing 9,208
speech samples across three categories: Gender-Independent,
Gender-Stereotypical, and Gender-Dependent. We further evaluated LLaMA-Omni
series and discovered a paradoxical pattern; while overall responses seems
identical regardless of gender, the pattern is far from unbiased responses.
Specifically, in Gender-Stereotypical questions, all models consistently
exhibited male-oriented responses; meanwhile, in Gender-Dependent questions
where gender differentiation would be contextually appropriate, models
exhibited responses independent to gender instead. We also confirm that this
pattern does not result from neutral options nor perceived gender of a voice.
When we allow neutral response, models tends to respond neutrally also in
Gender-Dependent questions. The paradoxical pattern yet retains when we applied
gender neutralization methods on speech. Through comparison between SpeechLMs
with corresponding backbone LLMs, we confirmed that these paradoxical patterns
primarily stem from Whisper speech encoders, which generates male-oriented
acoustic tokens. These findings reveal that current SpeechLMs may not
successfully remove gender biases though they prioritized general fairness
principles over contextual appropriateness, highlighting the need for more
sophisticated techniques to utilize gender information properly in speech
technology.

</details>


### [72] [AutoIntent: AutoML for Text Classification](https://arxiv.org/abs/2509.21138)
*Ilya Alekseev,Roman Solomatin,Darina Rustamova,Denis Kuznetsov*

Main category: cs.CL

TL;DR: AutoIntent是一款面向文本分类的全流程自动化工具，比现有AutoML工具更易用且效果更优，支持多标签、异常检测等高级功能，适合希望提高模型性能且降低开发难度的用户。


<details>
  <summary>Details</summary>
Motivation: 当前自动化机器学习（AutoML）工具对于文本分类任务存在缺陷，如支持的功能有限或接口不够友好。本文提出AutoIntent，旨在解决这些问题，实现全流程自动化、易用和高性能。

Method: AutoIntent是一个自动化文本分类工具，集成了嵌入模型选择、分类器优化和决策阈值调整。具备模块化和sklearn风格接口，支持多标签和超出范围检测。

Result: AutoIntent在多个标准意图分类数据集上优于现有AutoML工具，用户可在效果和资源消耗之间灵活权衡。

Conclusion: AutoIntent不仅提升了意图分类的性能，而且通过自动化和高扩展性降低了使用门槛和资源成本。

Abstract: AutoIntent is an automated machine learning tool for text classification
tasks. Unlike existing solutions, AutoIntent offers end-to-end automation with
embedding model selection, classifier optimization, and decision threshold
tuning, all within a modular, sklearn-like interface. The framework is designed
to support multi-label classification and out-of-scope detection. AutoIntent
demonstrates superior performance compared to existing AutoML tools on standard
intent classification datasets and enables users to balance effectiveness and
resource consumption.

</details>


### [73] [Retrieval over Classification: Integrating Relation Semantics for Multimodal Relation Extraction](https://arxiv.org/abs/2509.21151)
*Lei Hei,Tingjing Liao,Yingxin Pei,Yiyang Qi,Jiaqi Wang,Ruiting Li,Feiliang Ren*

Main category: cs.CL

TL;DR: 本文提出ROC框架，将关系抽取任务由分类转为语义检索，通过多模态编码和对比学习，显著提升了性能、鲁棒性和解释能力。


<details>
  <summary>Details</summary>
Motivation: 传统的多模态关系抽取（RE）方法大多采用分类任务处理，将关系作为离散标签，导致无法充分利用结构约束（如实体类型、位置信息），且语义表达能力有限，无法实现细粒度关系理解。

Method: 提出一种名为ROC（Retrieval Over Classification）的新框架，把多模态RE问题重新表述为由关系语义驱动的检索任务。ROC方法包括：通过多模态编码器整合实体类型和位置信息；用大语言模型将关系标签扩展为自然语言描述；用基于语义相似度的对比学习对齐实体-关系对。

Result: 在MNRE和MORE这两个基准数据集上，ROC方法取得了最新最优的性能，同时表现出更强的鲁棒性和可解释性。

Conclusion: ROC框架有效突破了传统多模态RE的局限，实现了对结构约束和语义表达的综合建模，大幅提升了模型性能和实用性。

Abstract: Relation extraction (RE) aims to identify semantic relations between entities
in unstructured text. Although recent work extends traditional RE to multimodal
scenarios, most approaches still adopt classification-based paradigms with
fused multimodal features, representing relations as discrete labels. This
paradigm has two significant limitations: (1) it overlooks structural
constraints like entity types and positional cues, and (2) it lacks semantic
expressiveness for fine-grained relation understanding. We propose
\underline{R}etrieval \underline{O}ver \underline{C}lassification (ROC), a
novel framework that reformulates multimodal RE as a retrieval task driven by
relation semantics. ROC integrates entity type and positional information
through a multimodal encoder, expands relation labels into natural language
descriptions using a large language model, and aligns entity-relation pairs via
semantic similarity-based contrastive learning. Experiments show that our
method achieves state-of-the-art performance on the benchmark datasets MNRE and
MORE and exhibits stronger robustness and interpretability.

</details>


### [74] [Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models](https://arxiv.org/abs/2509.21155)
*Chantal Shaib,Vinith M. Suriyakumar,Levent Sagun,Byron C. Wallace,Marzyeh Ghassemi*

Main category: cs.CL

TL;DR: LLM不仅需理解指令语义和领域，还受到句法模板影响。模型训练过程中，句法与领域的虚假相关会导致理解偏差和安全漏洞。作者开发方法检测此现象，建议提升训练数据句法多样性以降低风险。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在理解任务指令时，需兼顾语义和领域信息，但近期研究发现，句法构式（如高频词性标签序列）也能隐含重要信息。作者关注模型在训练时是否会将句法和领域错误相关联，从而影响指令理解。

Method: 研究通过分析任务指令对中的句法模板、领域和语义关系，利用合成训练数据评估句法-领域错误相关，开发检测评价框架，并在开放及闭源模型（如OLMo-2、Llama-4、GPT-4o）以及真实数据集上进行实证测试，补充安全微调绕过分析。

Result: 作者发现句法和领域关联的虚假相关在训练后显著降低模型在部分实体知识任务上的表现。此外实验证明主流模型与真实数据中确实存在这一问题，且可被用来绕过模型安全机制。作者提出应显式检测此类相关，并在训练数据中提升领域句法多样性。

Conclusion: 虚假的句法-领域相关会影响LLM对于任务指令的理解和安全性。应在模型训练和评测环节加强对这些相关性的检测，并优化数据构造策略，以避免性能和安全隐患。

Abstract: For an LLM to correctly respond to an instruction it must understand both the
semantics and the domain (i.e., subject area) of a given task-instruction pair.
However, syntax can also convey implicit information Recent work shows that
syntactic templates--frequent sequences of Part-of-Speech (PoS) tags--are
prevalent in training data and often appear in model outputs. In this work we
characterize syntactic templates, domain, and semantics in task-instruction
pairs. We identify cases of spurious correlations between syntax and domain,
where models learn to associate a domain with syntax during training; this can
sometimes override prompt semantics. Using a synthetic training dataset, we
find that the syntactic-domain correlation can lower performance (mean 0.51 +/-
0.06) on entity knowledge tasks in OLMo-2 models (1B-13B). We introduce an
evaluation framework to detect this phenomenon in trained models, and show that
it occurs on a subset of the FlanV2 dataset in open (OLMo-2-7B;
Llama-4-Maverick), and closed (GPT-4o) models. Finally, we present a case study
on the implications for safety finetuning, showing that unintended
syntactic-domain correlations can be used to bypass refusals in OLMo-2-7B
Instruct and GPT-4o. Our findings highlight two needs: (1) to explicitly test
for syntactic-domain correlations, and (2) to ensure syntactic diversity in
training data, specifically within domains, to prevent such spurious
correlations.

</details>


### [75] [Who's Laughing Now? An Overview of Computational Humour Generation and Explanation](https://arxiv.org/abs/2509.21175)
*Tyler Loakman,William Thorne,Chenghua Lin*

Main category: cs.CL

TL;DR: 本文综述了生成和解释幽默的计算方法，指出现有模型在幽默处理上远不及人类，强调该领域的重要性及未来值得关注的方向。


<details>
  <summary>Details</summary>
Motivation: 幽默的创造与理解是人类的基本特质，对其进行计算机化建模是自然语言处理(NLP)最具挑战性的任务之一。

Method: 对计算机幽默领域进行了综述，尤其关注生成幽默和解释幽默的任务，同时分析了相关领域的研究现状。

Result: 除了双关语，幽默的生成和解释研究尚不充分，主流模型距离人类水平仍有明显差距。

Conclusion: 计算机幽默处理是NLP的重要子领域，未来研究需关注幽默的主观性和伦理模糊性，并推动更具常识推理能力的模型发展。

Abstract: The creation and perception of humour is a fundamental human trait,
positioning its computational understanding as one of the most challenging
tasks in natural language processing (NLP). As an abstract, creative, and
frequently context-dependent construct, humour requires extensive reasoning to
understand and create, making it a pertinent task for assessing the
common-sense knowledge and reasoning abilities of modern large language models
(LLMs). In this work, we survey the landscape of computational humour as it
pertains to the generative tasks of creation and explanation. We observe that,
despite the task of understanding humour bearing all the hallmarks of a
foundational NLP task, work on generating and explaining humour beyond puns
remains sparse, while state-of-the-art models continue to fall short of human
capabilities. We bookend our literature survey by motivating the importance of
computational humour processing as a subdiscipline of NLP and presenting an
extensive discussion of future directions for research in the area that takes
into account the subjective and ethically ambiguous nature of humour.

</details>


### [76] [GEP: A GCG-Based method for extracting personally identifiable information from chatbots built on small language models](https://arxiv.org/abs/2509.21192)
*Jieli Zhu,Vi Ngoc-Nha Tran*

Main category: cs.CL

TL;DR: 本文发现小语言模型(SLM)在医疗聊天应用中也会泄露PII信息，传统检测方法能力有限，作者提出的GEP方法能大幅提升检测PII泄漏效率。结果警示，在SLM实际部署中需要加强隐私防护。


<details>
  <summary>Details</summary>
Motivation: SLMs虽然在某些领域与LLMs表现相当，且节省资源，但其在下游任务中的个人可识别信息(PII)泄露问题未被充分探索。作者希望揭示SLMs在医疗类聊天任务中潜在的隐私风险。

Method: 作者使用BioGPT为基础，结合Alpaca和HealthCareMagic医疗数据集finetune新的聊天机器人ChatBioGPT，评估其性能后，分析PII泄漏情况。他们首先验证现有模板式PII攻击方法在SLM下效果不佳，继而提出基于贪婪坐标梯度(GCG)的PII提取新方法GEP，并在更复杂场景下测试PII泄漏能力。

Result: GEP方法在PII泄漏检测上比传统模板方法能力显著提升，泄漏量最高提升60倍。即使在自由风格插入、表达更复杂的PII场景下，GEP仍能检测出高达4.53%的泄漏率。

Conclusion: SLM在医疗聊天应用中存在显著PII泄漏风险，传统方法难以发现这些隐私隐患，GEP则能有效提高检测率，说明需要更严格的隐私保护措施。

Abstract: Small language models (SLMs) become unprecedentedly appealing due to their
approximately equivalent performance compared to large language models (LLMs)
in certain fields with less energy and time consumption during training and
inference. However, the personally identifiable information (PII) leakage of
SLMs for downstream tasks has yet to be explored. In this study, we investigate
the PII leakage of the chatbot based on SLM. We first finetune a new chatbot,
i.e., ChatBioGPT based on the backbone of BioGPT using medical datasets Alpaca
and HealthCareMagic. It shows a matchable performance in BERTscore compared
with previous studies of ChatDoctor and ChatGPT. Based on this model, we prove
that the previous template-based PII attacking methods cannot effectively
extract the PII in the dataset for leakage detection under the SLM condition.
We then propose GEP, which is a greedy coordinate gradient-based (GCG) method
specifically designed for PII extraction. We conduct experimental studies of
GEP and the results show an increment of up to 60$\times$ more leakage compared
with the previous template-based methods. We further expand the capability of
GEP in the case of a more complicated and realistic situation by conducting
free-style insertion where the inserted PII in the dataset is in the form of
various syntactic expressions instead of fixed templates, and GEP is still able
to reveal a PII leakage rate of up to 4.53%.

</details>


### [77] [Eigen-1: Adaptive Multi-Agent Refinement with Monitor-Based RAG for Scientific Reasoning](https://arxiv.org/abs/2509.21193)
*Xiangru Tang,Wanghan Xu,Yujie Wang,Zijie Guo,Daniel Shao,Jiapeng Chen,Cixuan Zhang,Ziyi Wang,Lixin Zhang,Guancheng Wan,Wenlong Zhang,Lei Bai,Zhenfei Yin,Philip Torr,Hanrui Wang,Di Jin*

Main category: cs.CL

TL;DR: 提出结合隐式检索和结构化协作的新框架，有效提升科学推理准确率和效率，在多个基准上超越现有大模型和多agent方法。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在科学推理上的进展虽快，但仍面临两个主要瓶颈：一是显式检索打断推理过程并增加“工具税”，二是多agent流程中强解法被稀释，影响效果。作者希望提升科学推理的效率与准确性。

Method: 提出了一套统一框架，将隐式检索与结构化协作结合。主要包括：1）Monitor-based检索模块，在token级别无缝整合外部知识，减少对推理的干扰；2）分层解决方案修正（HSR），由同伴修补每个候选解；3）质量感知迭代推理（QAIR），根据方案质量自适应修正。

Result: 在HLE Bio/Chem Gold数据集上，框架达到48.3%的准确率，比最强agent基线高出13.4个百分点，比前沿LLM高出最多18.1个百分点，并减少53.5%的token用量和43.7%的agent步数。对SuperGPQA和TRQA也有强鲁棒性。

Conclusion: 隐式外部知识整合和结构化解法修正能有效克服传统工具使用和平均化带来的效率与准确性问题，在多种领域都表现出优越性。

Abstract: Large language models (LLMs) have recently shown strong progress on
scientific reasoning, yet two major bottlenecks remain. First, explicit
retrieval fragments reasoning, imposing a hidden "tool tax" of extra tokens and
steps. Second, multi-agent pipelines often dilute strong solutions by averaging
across all candidates. We address these challenges with a unified framework
that combines implicit retrieval and structured collaboration. At its
foundation, a Monitor-based retrieval module operates at the token level,
integrating external knowledge with minimal disruption to reasoning. On top of
this substrate, Hierarchical Solution Refinement (HSR) iteratively designates
each candidate as an anchor to be repaired by its peers, while Quality-Aware
Iterative Reasoning (QAIR) adapts refinement to solution quality. On Humanity's
Last Exam (HLE) Bio/Chem Gold, our framework achieves 48.3\% accuracy -- the
highest reported to date, surpassing the strongest agent baseline by 13.4
points and leading frontier LLMs by up to 18.1 points, while simultaneously
reducing token usage by 53.5\% and agent steps by 43.7\%. Results on SuperGPQA
and TRQA confirm robustness across domains. Error analysis shows that reasoning
failures and knowledge gaps co-occur in over 85\% of cases, while diversity
analysis reveals a clear dichotomy: retrieval tasks benefit from solution
variety, whereas reasoning tasks favor consensus. Together, these findings
demonstrate how implicit augmentation and structured refinement overcome the
inefficiencies of explicit tool use and uniform aggregation. Code is available
at: https://github.com/tangxiangru/Eigen-1.

</details>


### [78] [CLaw: Benchmarking Chinese Legal Knowledge in Large Language Models - A Fine-grained Corpus and Reasoning Analysis](https://arxiv.org/abs/2509.21208)
*Xinzhe Xu,Liang Zhao,Hongshen Xu,Chen Chen*

Main category: cs.CL

TL;DR: 本文提出了中国法律领域专用LLM评测基准CLaw，覆盖完整法典和真实案例推理，实证表明当前LLM在法律条文检索与引用方面存在严重不足，亟需结合准确检索与推理优化以提升其法律推理可靠性。


<details>
  <summary>Details</summary>
Motivation: 目前的大型语言模型（LLMs）在分析法律文本和引用相关法规时，受限于通用预训练，未能深入专注于法律领域，导致其法律知识的准确性和深度不足。针对缺乏专门评测中国法律知识及其实用推理能力的基准，本文旨在弥补这一研究空白。

Method: 本文提出了CLaw基准，包括两个主要部分：一是覆盖所有306部中国国家法典、细分到条款级别并精确记录历史修订时间的大规模法律语料库（共64,849条）；二是包含254个源于最高法院真实材料的案例推理题，用以评估模型法律知识的实际应用能力。

Result: 实证评测结果显示，大多数现有LLMs在准确复现法律条文方面表现不佳，无法可靠地查找和引用法律内容，这严重影响其法律推理的可信度。

Conclusion: 本文认为，要实现可信赖的法律推理，LLMs需具备高效知识检索能力（如通过监督微调或检索增强生成）与强大的逻辑推理能力，两者缺一不可。CLaw基准为提升行业内特定领域LLM推理能力，尤其是法律领域，提供了重要参考和基础。

Abstract: Large Language Models (LLMs) are increasingly tasked with analyzing legal
texts and citing relevant statutes, yet their reliability is often compromised
by general pre-training that ingests legal texts without specialized focus,
obscuring the true depth of their legal knowledge. This paper introduces CLaw,
a novel benchmark specifically engineered to meticulously evaluate LLMs on
Chinese legal knowledge and its application in reasoning. CLaw comprises two
key components: (1) a comprehensive, fine-grained corpus of all 306 Chinese
national statutes, segmented to the subparagraph level and incorporating
precise historical revision timesteps for rigorous recall evaluation (64,849
entries), and (2) a challenging set of 254 case-based reasoning instances
derived from China Supreme Court curated materials to assess the practical
application of legal knowledge. Our empirical evaluation reveals that most
contemporary LLMs significantly struggle to faithfully reproduce legal
provisions. As accurate retrieval and citation of legal provisions form the
basis of legal reasoning, this deficiency critically undermines the reliability
of their responses. We contend that achieving trustworthy legal reasoning in
LLMs requires a robust synergy of accurate knowledge retrieval--potentially
enhanced through supervised fine-tuning (SFT) or retrieval-augmented generation
(RAG)--and strong general reasoning capabilities. This work provides an
essential benchmark and critical insights for advancing domain-specific LLM
reasoning, particularly within the complex legal sphere.

</details>


### [79] [SGMem: Sentence Graph Memory for Long-Term Conversational Agents](https://arxiv.org/abs/2509.21212)
*Yaxiong Wu,Yongyue Zhang,Sheng Liang,Yong Liu*

Main category: cs.CL

TL;DR: 为了解决长期对话超过上下文窗口的问题，作者提出SGMem，用句子级图结构和多粒度记忆高效管理对话历史，在多个测试集效果优异，显著提升长期对话问答的准确性。


<details>
  <summary>Details</summary>
Motivation: 针对长时对话智能体需要有效管理对话历史（超出大语言模型上下文窗口），现有方法只做事实提取或摘要，信息组织与检索存在局限性。

Method: 提出SGMem（句子图记忆），将对话内容以句子级别图结构进行表示，并按块分单元，捕捉转折、轮次和会话级多粒度上下文的关联，结合原始对话、生成记忆（摘要、事实、洞见）共同为LLM提供上下文。

Result: 在LongMemEval和LoCoMo数据集上，SGMem在长期对话问答任务中，准确率稳定提升，明显优于强基线方法。

Conclusion: SGMem能更好地管理和检索长时对话中的多粒度信息，提升LLM对长期对话的应答能力和准确率。

Abstract: Long-term conversational agents require effective memory management to handle
dialogue histories that exceed the context window of large language models
(LLMs). Existing methods based on fact extraction or summarization reduce
redundancy but struggle to organize and retrieve relevant information across
different granularities of dialogue and generated memory. We introduce SGMem
(Sentence Graph Memory), which represents dialogue as sentence-level graphs
within chunked units, capturing associations across turn-, round-, and
session-level contexts. By combining retrieved raw dialogue with generated
memory such as summaries, facts and insights, SGMem supplies LLMs with coherent
and relevant context for response generation. Experiments on LongMemEval and
LoCoMo show that SGMem consistently improves accuracy and outperforms strong
baselines in long-term conversational question answering.

</details>


### [80] [Query-Centric Graph Retrieval Augmented Generation](https://arxiv.org/abs/2509.21237)
*Yaxiong Wu,Jianyuan Bo,Yongyue Zhang,Sheng Liang,Yong Liu*

Main category: cs.CL

TL;DR: 本文提出QCG-RAG框架，采用查询中心图和多跳检索，有效提升了多跳问答中的准确率和推理能力，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的图结构RAG方法在粒度上存在困境：实体级图导致高token消耗且丢失上下文，文档级图又无法捕捉到细致的关系。如何权衡粒度、提升推理效果成为难题。

Method: 提出QCG-RAG，即以查询为中心的图检索增强生成框架。通过Doc2Query系列技术构建可控粒度的查询中心图，实现更优的关系表示和解释性。定制化多跳检索机制用于通过生成的查询选择相关文本块，加强推理能力。

Result: 在LiHuaWorld和MultiHop-RAG数据集上，QCG-RAG在问答准确率上持续优于以往的块级和图结构RAG方法。

Conclusion: QCG-RAG解决了图粒度困境，在多跳推理RAG领域建立了新范式，提升了准确率和解释性。

Abstract: Graph-based retrieval-augmented generation (RAG) enriches large language
models (LLMs) with external knowledge for long-context understanding and
multi-hop reasoning, but existing methods face a granularity dilemma:
fine-grained entity-level graphs incur high token costs and lose context, while
coarse document-level graphs fail to capture nuanced relations. We introduce
QCG-RAG, a query-centric graph RAG framework that enables query-granular
indexing and multi-hop chunk retrieval. Our query-centric approach leverages
Doc2Query and Doc2Query{-}{-} to construct query-centric graphs with
controllable granularity, improving graph quality and interpretability. A
tailored multi-hop retrieval mechanism then selects relevant chunks via the
generated queries. Experiments on LiHuaWorld and MultiHop-RAG show that QCG-RAG
consistently outperforms prior chunk-based and graph-based RAG methods in
question answering accuracy, establishing a new paradigm for multi-hop
reasoning.

</details>


### [81] [Un-Doubling Diffusion: LLM-guided Disambiguation of Homonym Duplication](https://arxiv.org/abs/2509.21262)
*Evgeny Kaskov,Elizaveta Petrova,Petr Surovtsev,Anna Kostikova,Ilya Mistiurin,Alexander Kapitanov,Alexander Nagaev*

Main category: cs.CL

TL;DR: 论文揭示了同形异义词给扩散模型带来的生成重复问题，提出了度量和干预方法，验证了prompt扩展技术的有效性，并公布了评测工具。


<details>
  <summary>Details</summary>
Motivation: 同形异义词（Homonyms）在文本生成中容易引起模型生成多重含义，尤其在扩散模型中表现为同形异义词重复。且英文中心化（Anglocentric bias）导致在翻译过程中产生新的同形异义词，使原文失去准确含义，因此需要系统性评估和干预。

Method: 提出一种度量同形异义词重复率的方法，并对不同扩散模型在此问题上的表现进行了评估。评估方式包括利用视觉-语言模型（VLM）的自动化评估和人工评估。同时，探索通过扩充prompt（prompt expansion）来减少同形异义词重复的方法。相关自动评估代码已公开。

Result: 通过自动化和人工评估，系统性衡量了扩散模型中的同形异义词重复问题。实验表明，prompt expansion不仅能有效缓解同形异义词重复，还能改善由英文本位偏差导致的相关问题。

Conclusion: 本研究首次系统评估了文本到图像扩散模型中的同形异义词重复现象，并提出了有效的缓解方法（prompt expansion），为解决扩散模型的多义词理解和英文本位偏差提供了新的思路和工具。

Abstract: Homonyms are words with identical spelling but distinct meanings, which pose
challenges for many generative models. When a homonym appears in a prompt,
diffusion models may generate multiple senses of the word simultaneously, which
is known as homonym duplication. This issue is further complicated by an
Anglocentric bias, which includes an additional translation step before the
text-to-image model pipeline. As a result, even words that are not homonymous
in the original language may become homonyms and lose their meaning after
translation into English. In this paper, we introduce a method for measuring
duplication rates and conduct evaluations of different diffusion models using
both automatic evaluation utilizing Vision-Language Models (VLM) and human
evaluation. Additionally, we investigate methods to mitigate the homonym
duplication problem through prompt expansion, demonstrating that this approach
also effectively reduces duplication related to Anglocentric bias. The code for
the automatic evaluation pipeline is publicly available.

</details>


### [82] [LLM Output Homogenization is Task Dependent](https://arxiv.org/abs/2509.21267)
*Shomik Jain,Jack Lanchantin,Maximilian Nickel,Karen Ullrich,Ashia Wilson,Jamelle Watson-Daniels*

Main category: cs.CL

TL;DR: 本文针对大语言模型同质化问题，提出基于任务类型的同质化概念划分、新的多样性评估指标及采样算法，实验证明该方法能按需提升输出多样性且不损失质量，有效提高模型实用性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在生成回复时可能会出现输出同质化现象，这会影响模型的实用性。此前研究往往没有根据任务类型对多样性进行具体区分。该论文旨在填补这一空白。

Method: 1）提出八种各自包含不同输出同质化概念的任务类型分类法；2）引入基于任务的功能性多样性指标，用于更好地评估输出同质化；3）提出基于任务的采样技术，用于在需要多样性的情况下提升功能性多样性，同时在期望同质化场景下保留同质性；4）探讨并挑战多样性与质量之间的权衡。

Result: 实验表明，所提方案能够在提升功能性多样性的同时保证回复质量，实现对输出同质化现象更符合任务需求的评估与调控。

Conclusion: 该研究展示了基于任务的思路在输出同质化评估和缓解中的优势，有助于根据不同任务类型实现更优的语言模型输出多样性与质量平衡。

Abstract: A large language model can be less helpful if it exhibits output response
homogenization. But whether two responses are considered homogeneous, and
whether such homogenization is problematic, both depend on the task category.
For instance, in objective math tasks, we often expect no variation in the
final answer but anticipate variation in the problem-solving strategy. Whereas,
for creative writing tasks, we may expect variation in key narrative components
(e.g. plot, genre, setting, etc), beyond the vocabulary or embedding diversity
produced by temperature-sampling. Previous work addressing output
homogenization often fails to conceptualize diversity in a task-dependent way.
We address this gap in the literature directly by making the following
contributions. (1) We present a task taxonomy comprised of eight task
categories that each have distinct conceptualizations of output homogenization.
(2) We introduce task-anchored functional diversity to better evaluate output
homogenization. (3) We propose a task-anchored sampling technique that
increases functional diversity for task categories where homogenization is
undesired, while preserving homogenization where it is desired. (4) We
challenge the perceived existence of a diversity-quality trade-off by
increasing functional diversity while maintaining response quality. Overall, we
demonstrate how task dependence improves the evaluation and mitigation of
output homogenization.

</details>


### [83] [LLMTrace: A Corpus for Classification and Fine-Grained Localization of AI-Written Text](https://arxiv.org/abs/2509.21269)
*Irina Tolstykh,Aleksandra Tsybina,Sergey Yakubson,Maksim Kuprashevich*

Main category: cs.CL

TL;DR: 本文提出LLMTrace双语AI检测数据集，包含多模型、多场景以及字符级标注，提升混合作者文本的AI片段检测能力，为后续研究和模型训练提供关键资源。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLM）生成的人类文本趋于普遍，亟需更为强健的AI文本检测系统。然而，现有的数据集普遍过时，主要为英语且未能适配人类与AI混合创作的场景，同时缺乏精确定位AI生成段落所需的字符级标注数据。

Method: 该论文提出了LLMTrace，一套大规模、双语（英语和俄语）AI生成文本检测数据集。数据集涵盖了多种现代的专有及开源LLM生成数据，并配有人类与AI混合创作文本的字符级标注，支持整段分类（人类vs AI）及AI生成片段定位两个任务。

Result: LLMTrace数据集能够提升AI文本检测的精度和范围，支持更复杂的检测任务，尤其是对混合作者文本中AI生成段落的定位。该资源有助于未来更精准和实用的AI检测模型的研发与评估。

Conclusion: LLMTrace弥补了现有数据集的缺陷，尤其在双语、混合作者场景及字符级标注方面，推动了AI文本检测领域的进步，将成为下一代检测系统的重要基础。

Abstract: The widespread use of human-like text from Large Language Models (LLMs)
necessitates the development of robust detection systems. However, progress is
limited by a critical lack of suitable training data; existing datasets are
often generated with outdated models, are predominantly in English, and fail to
address the increasingly common scenario of mixed human-AI authorship.
Crucially, while some datasets address mixed authorship, none provide the
character-level annotations required for the precise localization of
AI-generated segments within a text. To address these gaps, we introduce
LLMTrace, a new large-scale, bilingual (English and Russian) corpus for
AI-generated text detection. Constructed using a diverse range of modern
proprietary and open-source LLMs, our dataset is designed to support two key
tasks: traditional full-text binary classification (human vs. AI) and the novel
task of AI-generated interval detection, facilitated by character-level
annotations. We believe LLMTrace will serve as a vital resource for training
and evaluating the next generation of more nuanced and practical AI detection
models. The project page is available at
\href{https://sweetdream779.github.io/LLMTrace-info/}{iitolstykh/LLMTrace}.

</details>


### [84] [Bounds of Chain-of-Thought Robustness: Reasoning Steps, Embed Norms, and Beyond](https://arxiv.org/abs/2509.21284)
*Dingzirui Wang,Xuanliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 本文对CoT推理过程中的输入扰动影响进行了理论和实证分析，证明扰动随推理步数增加而加大且无法完全消除，并揭示在简化Transformer（LSA）架构下扰动上界与嵌入范数负相关。实验结果支持了理论发现，为Prompt优化和模型稳健性提供重要理论依据。


<details>
  <summary>Details</summary>
Motivation: 当前的CoT输出易受到输入扰动影响，现有方法多通过优化Prompt进行缓解，但尚缺乏理论层面的解释，限制了更深入的理解与优化。

Method: 对输入扰动对CoT输出波动的影响进行理论分析，推导输入扰动的上界，证明其与推理步数正相关，同时分析LSA模型中输入扰动上界与输入嵌入和隐状态范数的负相关关系，并进行实证实验验证。

Result: 证明扰动上界与推理步数正相关，且无限推理步无法消除扰动影响；在LSA模型中，扰动上界与输入嵌入和隐状态范数负相关。通过三类数据集和四种主流模型实验验证理论分析。

Conclusion: 理论分析揭示了输入扰动在CoT输出中的传播机制，证实了扰动对输出的持续影响，为后续优化Prompt和模型鲁棒性提供了理论基础。

Abstract: Existing research indicates that the output of Chain-of-Thought (CoT) is
significantly affected by input perturbations. Although many methods aim to
mitigate such impact by optimizing prompts, a theoretical explanation of how
these perturbations influence CoT outputs remains an open area of research.
This gap limits our in-depth understanding of how input perturbations propagate
during the reasoning process and hinders further improvements in prompt
optimization methods. Therefore, in this paper, we theoretically analyze the
effect of input perturbations on the fluctuation of CoT outputs. We first
derive an upper bound for input perturbations under the condition that the
output fluctuation is within an acceptable range, based on which we prove that:
(i) This upper bound is positively correlated with the number of reasoning
steps in the CoT; (ii) Even an infinitely long reasoning process cannot
eliminate the impact of input perturbations. We then apply these conclusions to
the Linear Self-Attention (LSA) model, which can be viewed as a simplified
version of the Transformer. For the LSA model, we prove that the upper bound
for input perturbation is negatively correlated with the norms of the input
embedding and hidden state vectors. To validate this theoretical analysis, we
conduct experiments on three mainstream datasets and four mainstream models.
The experimental results align with our theoretical analysis, empirically
demonstrating the correctness of our findings.

</details>


### [85] [DisCoCLIP: A Distributional Compositional Tensor Network Encoder for Vision-Language Understanding](https://arxiv.org/abs/2509.21287)
*Kin Ian Lo,Hala Hawashin,Mina Abbaszadeh,Tilen Limback-Stokin,Hadi Wazni,Mehrnoosh Sadrzadeh*

Main category: cs.CL

TL;DR: 论文提出DisCoCLIP，将显式语法结构引入视觉-语言模型，经端到端训练后，在多项组合性推理任务大幅超越现有模型，同时保持较低参数规模。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型虽擅长大规模图文对齐，但往往忽视了语言的组合结构，导致在依赖词序和谓-宾结构的任务上表现不佳。

Method: 提出DisCoCLIP模型，将冻结的CLIP视觉Transformer与新颖的张量网络文本编码器相结合。文本输入经过CCG（Combinatory Categorial Grammar）句法解析，生成分布式词张量，张量收缩操作与句法推导一致。高阶张量通过分解方式减少参数量。整个模型通过自监督对比损失端到端训练。

Result: DisCoCLIP模型在动词语义和词序敏感性方面显著优于标准CLIP：SVO-Probes动词准确率由77.6%提升至82.4%，ARO归因和关系得分提升9%和4%以上，并在新引入的SVO-Swap基准上取得93.7%的高分。

Conclusion: 将显式的句法结构通过张量网络引入视觉-语言编码器，能够大幅提升组合性推理能力，在参数效率更高的情况下取得更好的性能。

Abstract: Recent vision-language models excel at large-scale image-text alignment but
often neglect the compositional structure of language, leading to failures on
tasks that hinge on word order and predicate-argument structure. We introduce
DisCoCLIP, a multimodal encoder that combines a frozen CLIP vision transformer
with a novel tensor network text encoder that explicitly encodes syntactic
structure. Sentences are parsed with a Combinatory Categorial Grammar parser to
yield distributional word tensors whose contractions mirror the sentence's
grammatical derivation. To keep the model efficient, high-order tensors are
factorized with tensor decompositions, reducing parameter count from tens of
millions to under one million. Trained end-to-end with a self-supervised
contrastive loss, DisCoCLIP markedly improves sensitivity to verb semantics and
word order: it raises CLIP's SVO-Probes verb accuracy from 77.6% to 82.4%,
boosts ARO attribution and relation scores by over 9% and 4%, and achieves
93.7% on a newly introduced SVO-Swap benchmark. These results demonstrate that
embedding explicit linguistic structure via tensor networks yields
interpretable, parameter-efficient representations that substantially improve
compositional reasoning in vision-language tasks.

</details>


### [86] [The role of synthetic data in Multilingual, Multi-cultural AI systems: Lessons from Indic Languages](https://arxiv.org/abs/2509.21294)
*Pranjal A. Chitale,Varun Gumma,Sanchit Ahuja,Prashant Kodali,Manan Uppadhyay,Deepthi Sudharsan,Sunayana Sitaram*

Main category: cs.CL

TL;DR: 本文提出了一种结合本地化Wikipedia内容的合成数据生成策略，构建了面向印度13种语言的多文化指令数据集Updesh。微调后模型在多项多语种任务上取得了显著进步，特别提升了低资源语言的表现，验证了文化语境扎根的数据生成对多语言AI系统至关重要。


<details>
  <summary>Details</summary>
Motivation: 多语言AI系统在低资源语种和文化扎根性方面长期存在挑战。现有合成数据方法在多语言、多文化语境中的效果尚未充分探索。

Method: 采用自下而上的生成策略，利用大型开放源LLM（参数量≥235B），以语言特定的Wikipedia内容为基础生成数据，与传统自上而下的翻译形式形成互补。

Result: 创建了Updesh大规模合成指令数据集，涵盖13种印度语言，包含950万条数据。经过自动评估和人工评注，数据质量高但有改进空间。微调模型并在多语种下游任务上评估，表明该数据集能显著提升生成式任务性能，尤其是在低中资源语言中减小与高资源语言的差距。

Conclusion: 通过结合文化和语言背景的合成数据，可以显著提升多语言AI模型，特别是在低资源语种上的表现。多元化、具文化根基的数据生成方法是实现有效多语言AI的关键。

Abstract: Developing AI systems that operate effectively across languages while
remaining culturally grounded is a long-standing challenge, particularly in
low-resource settings. Synthetic data provides a promising avenue, yet its
effectiveness in multilingual and multicultural contexts remains underexplored.
We investigate the creation and impact of synthetic, culturally contextualized
datasets for Indian languages through a bottom-up generation strategy that
prompts large open-source LLMs (>= 235B parameters) to ground data generation
in language-specific Wikipedia content. This approach complements the dominant
top-down paradigm of translating synthetic datasets from high-resource
languages such as English. We introduce Updesh, a high-quality large-scale
synthetic instruction-following dataset comprising 9.5M data points across 13
Indian languages, encompassing diverse reasoning and generative tasks with an
emphasis on long-context, multi-turn capabilities, and alignment with Indian
cultural contexts. A comprehensive evaluation incorporating both automated
metrics and human annotation across 10k assessments indicates that generated
data is high quality; though, human evaluation highlights areas for further
improvement. Additionally, we perform downstream evaluations by fine-tuning
models on our dataset and assessing the performance across 15 diverse
multilingual datasets. Models trained on Updesh consistently achieve
significant gains on generative tasks and remain competitive on multiple-choice
style NLU tasks. Notably, relative improvements are most pronounced in low and
medium-resource languages, narrowing their gap with high-resource languages.
These findings provide empirical evidence that effective multilingual AI
requires multi-faceted data curation and generation strategies that incorporate
context-aware, culturally grounded methodologies.

</details>


### [87] [Sycophancy Is Not One Thing: Causal Separation of Sycophantic Behaviors in LLMs](https://arxiv.org/abs/2509.21305)
*Daniel Vennemeyer,Phan Anh Duong,Tiffany Zhan,Tianyu Jiang*

Main category: cs.CL

TL;DR: 该论文表明，LLM中的谄媚行为（如同意和赞美用户）具备独立的可操控表征，其结构在不同模型中高度一致。研究采用多种方法证明了每种谄媚行为都是潜空间中的独立特征，可单独调节。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM经常表现出谄媚性行为，但尚不清楚这些行为是由单一机制产生还是由多个不同过程构成，因此希望揭示谄媚行为的根源及其表征方式。

Method: 分析LLM在潜空间中的线性方向，使用差异均值方向、激活叠加和子空间几何等方法，横跨多种模型和数据集进行研究。

Result: （1）谄媚性同意、谄媚性赞美和真实同意均在潜空间中表现为不同的线性方向；（2）可以独立增强或抑制这三种行为而互不影响；（3）这些表征结构在不同模型家族和规模中保持一致性。

Conclusion: 谄媚性行为在大型语言模型（LLM）中对应于独立且可操控的表征。

Abstract: Large language models (LLMs) often exhibit sycophantic behaviors -- such as
excessive agreement with or flattery of the user -- but it is unclear whether
these behaviors arise from a single mechanism or multiple distinct processes.
We decompose sycophancy into sycophantic agreement and sycophantic praise,
contrasting both with genuine agreement. Using difference-in-means directions,
activation additions, and subspace geometry across multiple models and
datasets, we show that: (1) the three behaviors are encoded along distinct
linear directions in latent space; (2) each behavior can be independently
amplified or suppressed without affecting the others; and (3) their
representational structure is consistent across model families and scales.
These results suggest that sycophantic behaviors correspond to distinct,
independently steerable representations.

</details>


### [88] [RLBFF: Binary Flexible Feedback to bridge between Human Feedback & Verifiable Rewards](https://arxiv.org/abs/2509.21319)
*Zhilin Wang,Jiaqi Zeng,Olivier Delalleau,Ellie Evans,Daniel Egert,Hoo-Chang Shin,Felipe Soares,Yi Dong,Oleksii Kuchaiev*

Main category: cs.CL

TL;DR: 提出RLBFF方法，通过可二元判断原则，兼顾人类偏好与规则验证优势，奖励模型性能全面优于现有方法，实现高性价比大模型对齐与开源复现。


<details>
  <summary>Details</summary>
Motivation: 目前主流的LLM微调强化学习方法RLHF和RLVR都有各自的局限性：RLHF有可解释性和奖励欺骗问题，因为其依赖于缺乏明确标准的人类判断；RLVR只局限于可验证的正确性，无法涵盖更复杂的偏好类评价。

Method: 提出了RLBFF（Reinforcement Learning with Binary Flexible Feedback），该方法结合了人类评判的灵活性与规则验证的精确性。从自然语言反馈中提取可用二元形式（是/否）回答的原则，用于奖励模型训练，将其转化为蕴含判定任务。用户可在推理时指定关注原则，自定义奖励模型。

Result: 基于RLBFF训练的奖励模型在数据匹配条件下优于Bradley-Terry模型，并在RM-Bench和JudgeBench等基准上取得领先成绩（86.2%、81.4%）。Qwen3-32B结合RLBFF及新奖励模型，在MT-Bench、WildBench、Arena Hard v2等通用对齐基准上达到或超过o3-mini和DeepSeek R1的表现，同时推理成本低于5%。

Conclusion: RLBFF兼具灵活性与精确性，提升了奖励模型的效果和定制能力。完全开源流程助力大模型高效对齐。

Abstract: Reinforcement Learning with Human Feedback (RLHF) and Reinforcement Learning
with Verifiable Rewards (RLVR) are the main RL paradigms used in LLM
post-training, each offering distinct advantages. However, RLHF struggles with
interpretability and reward hacking because it relies on human judgments that
usually lack explicit criteria, whereas RLVR is limited in scope by its focus
on correctness-based verifiers. We propose Reinforcement Learning with Binary
Flexible Feedback (RLBFF), which combines the versatility of human-driven
preferences with the precision of rule-based verification, enabling reward
models to capture nuanced aspects of response quality beyond mere correctness.
RLBFF extracts principles that can be answered in a binary fashion (e.g.
accuracy of information: yes, or code readability: no) from natural language
feedback. Such principles can then be used to ground Reward Model training as
an entailment task (response satisfies or does not satisfy an arbitrary
principle). We show that Reward Models trained in this manner can outperform
Bradley-Terry models when matched for data and achieve top performance on
RM-Bench (86.2%) and JudgeBench (81.4%, #1 on leaderboard as of September 24,
2025). Additionally, users can specify principles of interest at inference time
to customize the focus of our reward models, in contrast to Bradley-Terry
models. Finally, we present a fully open source recipe (including data) to
align Qwen3-32B using RLBFF and our Reward Model, to match or exceed the
performance of o3-mini and DeepSeek R1 on general alignment benchmarks of
MT-Bench, WildBench, and Arena Hard v2 (at <5% of the inference cost).

</details>


### [89] [SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines](https://arxiv.org/abs/2509.21320)
*Yizhou Wang,Chen Tang,Han Deng,Jiabei Xiao,Jiaqi Liu,Jianyu Wu,Jun Yao,Pengze Li,Encheng Su,Lintao Wang,Guohang Zhuang,Yuchen Ren,Ben Fei,Ming Hu,Xin Chen,Dongzhan Zhou,Junjun He,Xiangyu Yue,Zhenfei Yin,Jiamin Wu,Qihao Zheng,Yuhao Zhou,Huihui Xu,Chenglong Ma,Yan Lu,Wenlong Zhang,Chunfeng Song,Philip Torr,Shixiang Tang,Xinzhu Ma,Wanli Ouyang,Lei Bai*

Main category: cs.CL

TL;DR: 本文提出一种面向科学推理的对齐大模型，在大规模异构科学数据上训练，并结合多阶段优化，显著提升跨领域泛化和科学任务推理能力。模型核心资源已开源，便于后续研究者验证与应用。


<details>
  <summary>Details</summary>
Motivation: 当前科学推理任务中，如何让自然语言与各种科学表示形式有效对齐，并实现跨领域泛化能力，是人工智能研究的一大难题。针对专用系统存在的指令覆盖面窄、跨领域泛化能力弱等问题，作者提出构建一个具有广泛对齐能力的推理基础模型。

Method: 采用多阶段预训练机制：先在2060亿token的科学文本和各类科学表示（文本、纯序列、序列文本对）上进行预训练，再通过4000万条指令进行监督微调(SFT)；冷启动自举与长链推理训练促进复杂思维能力，并结合强化学习，针对任务设定奖励以增强科学推理的可靠性。

Result: 该模型支持四大能力家族、覆盖103个科学任务，包括文本与科学格式的双向转换、信息/知识抽取、属性预测、属性分类以及多种序列生成；实验证明其指令覆盖更广、跨领域能力更强、结果精准度和可靠性优于专用系统。

Conclusion: 所提出的模型显著拓展了科学领域推理模型的能力边界，实现了跨学科领域的泛化提升，并在多项关键任务上取得领先结果。相关模型、指令微调数据集及评测代码已实现开源，有望推动科学推理研究的进一步发展。

Abstract: We present a scientific reasoning foundation model that aligns natural
language with heterogeneous scientific representations. The model is pretrained
on a 206B-token corpus spanning scientific text, pure sequences, and
sequence-text pairs, then aligned via SFT on 40M instructions, annealed
cold-start bootstrapping to elicit long-form chain-of-thought, and
reinforcement learning with task-specific reward shaping, which instills
deliberate scientific reasoning. It supports four capability families, covering
up to 103 tasks across workflows: (i) faithful translation between text and
scientific formats, (ii) text/knowledge extraction, (iii) property prediction,
(iv) property classification, (v) unconditional and conditional sequence
generation and design. Compared with specialist systems, our approach broadens
instruction coverage, improves cross-domain generalization, and enhances
fidelity. We detail data curation and training and show that cross-discipline
learning strengthens transfer and downstream reliability. The model, instruct
tuning datasets and the evaluation code are open-sourced at
https://huggingface.co/SciReason and
https://github.com/open-sciencelab/SciReason.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [90] [An orderly algorithm for generation of Condorcet Domains](https://arxiv.org/abs/2509.20865)
*Bei Zhou,Klas Markström*

Main category: cs.DM

TL;DR: 本文提出了一个高效算法，用于生成所有非同构的最大 Condorcet 域，并公开了相关实现和数据，对多数投票理论的动力学研究具有重要价值。


<details>
  <summary>Details</summary>
Motivation: Condorcet 域在多数投票理论中非常重要，是对所有备选项进行线性排序时能够保证多数排名仍为线性顺序的集合。此前对这些域的系统化生成和分类仍具有挑战性。

Method: 提出了一种高效的顺序算法，可以生成所有非同构的最大 Condorcet 域。该算法还可以适配于生成各种重要子类的 Condorcet 域。

Result: 通过实例实现，扩展了现有针对这些子类域的枚举，且数据和实现公开可用。

Conclusion: 本文为 Condorcet 域及其子类的全面系统化生成提供了实用方法和数据资源，促进了投票理论相关研究的发展。

Abstract: Condorcet domains are fundamental objects in the theory of majority voting;
they are sets of linear orders with the property that if every voter picks a
linear order from this set, assuming that the number of voters is odd, and
alternatives are ranked according to the pairwise majority ranking, then the
result is a linear order on the set of all alternatives. In this paper we
present an efficient orderly algorithm for the generation of all non-isomorphic
maximal Condorcet domains on $n$ alternatives. The algorithm can be adapted to
generate domains from various important subclasses of Condorcet domains. We use
an example implementation to extend existing enumerations of domains from
several such subclasses and make both data and the implementation publicly
available.

</details>
