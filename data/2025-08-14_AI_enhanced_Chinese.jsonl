{"id": "2508.09856", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.09856", "abs": "https://arxiv.org/abs/2508.09856", "authors": ["Mathieu Boespflug", "Arnaud Spiwack"], "title": "Invertible Syntax without the Tuples (Functional Pearl)", "comment": null, "summary": "In the seminal paper Functional unparsing, Olivier Danvy used continuation\npassing to reanalyse printf-like format strings as combinators. In the\nintervening decades, the conversation shifted towards a concurrent line of work\n-- applicative, monadic or arrow-based combinator libraries -- in an effort to\nfind combinators for invertible syntax descriptions that simultaneously\ndetermine a parser as well as a printer, and with more expressive power, able\nto handle inductive structures such as lists and trees. Along the way,\ncontinuation passing got lost. This paper argues that Danvy's insight remains\nas relevant to the general setting as it was to the restricted setting of his\noriginal paper. Like him, we present three solutions that exploit\ncontinuation-passing style as an alternative to both dependent types and\nmonoidal aggregation via nested pairs, in our case to parse and print\nstructured data with increasing expressive power.", "AI": {"tldr": "\u8be5\u6587\u6307\u51fa continuation-passing style \u5728\u89e3\u6790\u4e0e\u6253\u5370\u590d\u6742\u7ed3\u6784\u6570\u636e\u65f6\u4f9d\u65e7\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u63d0\u51fa\u4e09\u79cd\u57fa\u4e8e\u8be5\u601d\u60f3\u7684\u65b9\u6848\uff0c\u8bc1\u660e\u5176\u4e0e\u73b0\u4ee3\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5177\u6709\u826f\u597d\u8868\u8fbe\u6027\u548c\u901a\u7528\u6027\u3002", "motivation": "\u76ee\u524d\u7684\u7ec4\u5408\u5b50\u5e93\u591a\u4f9d\u8d56 applicative\u3001monadic \u6216 arrow \u98ce\u683c\u6765\u8bbe\u8ba1\u89e3\u6790\u4e0e\u53cd\u5e8f\u5217\u5316\uff08\u6253\u5370\uff09\u5de5\u5177\uff0c\u65e8\u5728\u901a\u8fc7\u540c\u6837\u7684\u8bed\u6cd5\u63cf\u8ff0\u5b9e\u73b0\u65e2\u80fd\u89e3\u6790\u53c8\u80fd\u8f93\u51fa\u7ed3\u6784\u5316\u6570\u636e\uff0c\u5c24\u5176\u5173\u6ce8\u53ef\u5904\u7406\u5217\u8868\u3001\u6811\u7b49\u9012\u5f52\u7ed3\u6784\u7684\u9ad8\u8868\u8fbe\u6027\u3002\u800c Danvy \u7684 continuation-passing \u601d\u60f3\u5728\u8fd9\u4e9b\u63a2\u8ba8\u4e2d\u88ab\u5ffd\u89c6\uff0c\u4f5c\u8005\u5e0c\u671b\u91cd\u65b0\u8bc4\u4f30\u5e76\u63a8\u5e7f\u8fd9\u79cd\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u501f\u9274 Danvy \u7684\u7ee7\u7eed\u4f20\u9012\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e09\u79cd\u57fa\u4e8e continuation-passing \u7684\u65b9\u6848\uff0c\u7528\u4e8e\u5904\u7406\u5177\u6709\u9012\u5f52\u548c\u7ed3\u6784\u6027\u7684\u6570\u636e\u89e3\u6790\u4e0e\u6253\u5370\u95ee\u9898\u3002", "result": "\u4f5c\u8005\u5c55\u793a\u4e86\u4e09\u79cd\u57fa\u4e8e continuation-passing \u7684\u89e3\u6790\u4e0e\u6253\u5370\u65b9\u6848\uff0c\u8868\u8fbe\u80fd\u529b\u80fd\u591f\u8986\u76d6\u9012\u5f52\u548c\u7ed3\u6784\u5316\u6570\u636e\uff0c\u663e\u793a\u8be5\u65b9\u6cd5\u76f8\u8f83\u4e8e\u4f9d\u8d56\u578b\u7cfb\u7edf\u6216\u5e7a\u534a\u805a\u5408\u5177\u5907\u7ade\u4e89\u529b\u3002", "conclusion": "\u91c7\u7528 continuation-passing style \uff08CPS\uff09\u7684\u65b9\u6cd5\u5728\u66f4\u5e7f\u6cdb\u3001\u590d\u6742\u7684\u7ed3\u6784\u89e3\u6790\u4e0e\u6253\u5370\u4efb\u52a1\u4e2d\u4ecd\u7136\u975e\u5e38\u6709\u6548\uff0c\u53ef\u4ee5\u66ff\u4ee3\u4f9d\u8d56\u7c7b\u578b\u6216\u57fa\u4e8e\u5d4c\u5957\u5bf9\u7684\u5e7a\u534a\u96c6\u5408\u805a\u5408\u3002"}}
{"id": "2508.09332", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.09332", "abs": "https://arxiv.org/abs/2508.09332", "authors": ["Anshul Khairnar", "Aarya Rajoju", "Edward F. Gehringer"], "title": "Teaching Code Refactoring Using LLMs", "comment": "Accepted for presentation at the Frontiers in Education Conference,\n  Nashville, Tennessee, USA, 2-5 November 2025", "summary": "This Innovative Practice full paper explores how Large Language Models (LLMs)\ncan enhance the teaching of code refactoring in software engineering courses\nthrough real-time, context-aware feedback. Refactoring improves code quality\nbut is difficult to teach, especially with complex, real-world codebases.\nTraditional methods like code reviews and static analysis tools offer limited,\ninconsistent feedback. Our approach integrates LLM-assisted refactoring into a\ncourse project using structured prompts to help students identify and address\ncode smells such as long methods and low cohesion. Implemented in Spring 2025\nin a long-lived OSS project, the intervention is evaluated through student\nfeedback and planned analysis of code quality improvements. Findings suggest\nthat LLMs can bridge theoretical and practical learning, supporting a deeper\nunderstanding of maintainability and refactoring principles.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u8bfe\u7a0b\u4ee3\u7801\u91cd\u6784\u6559\u5b66\uff0c\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u3001\u5b9e\u65f6\u7684\u53cd\u9988\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b66\u751f\u5bf9\u91cd\u6784\u548c\u53ef\u7ef4\u62a4\u6027\u7684\u7406\u89e3\u4e0e\u5b9e\u8df5\u80fd\u529b\u3002", "motivation": "\u76ee\u524d\u4ee3\u7801\u91cd\u6784\u6559\u5b66\u9762\u4e34\u53cd\u9988\u6709\u9650\u4e14\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u7684\u771f\u5b9e\u4ee3\u7801\u5e93\u4e2d\u3002\u501f\u52a9LLM\u5e0c\u671b\u63d0\u5347\u4ee3\u7801\u91cd\u6784\u6559\u5b66\u7684\u6709\u6548\u6027\u3002", "method": "\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u7684\u91cd\u6784\u6d3b\u52a8\u878d\u5165\u8f6f\u4ef6\u5de5\u7a0b\u8bfe\u7a0b\u9879\u76ee\uff0c\u4f7f\u7528\u7ed3\u6784\u5316\u63d0\u793a\u5e2e\u52a9\u5b66\u751f\u8bc6\u522b\u5e76\u89e3\u51b3\u4ee3\u7801\u5f02\u5473\uff0c\u901a\u8fc7\u5b66\u751f\u53cd\u9988\u548c\u4ee3\u7801\u8d28\u91cf\u63d0\u5347\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u663e\u793aLLM\u80fd\u5e2e\u52a9\u5b66\u751f\u66f4\u597d\u5730\u7406\u89e3\u7406\u8bba\u4e0e\u5b9e\u9645\u64cd\u4f5c\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u63d0\u5347\u7ef4\u62a4\u6027\u548c\u91cd\u6784\u76f8\u5173\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u5b9e\u9645\u6559\u5b66\u4e2d\u4e3a\u5b66\u751f\u63d0\u4f9b\u5b9e\u65f6\u3001\u60c5\u5883\u611f\u77e5\u7684\u4ee3\u7801\u91cd\u6784\u53cd\u9988\uff0c\u6709\u52a9\u4e8e\u5b66\u751f\u66f4\u6df1\u5165\u7406\u89e3\u53ef\u7ef4\u62a4\u6027\u548c\u91cd\u6784\u539f\u5219\u3002"}}
{"id": "2508.09318", "categories": ["cs.LO", "cs.AI", "68T27", "I.2.3; I.2.4; F.4.1"], "pdf": "https://arxiv.org/pdf/2508.09318", "abs": "https://arxiv.org/abs/2508.09318", "authors": ["Alexander Steen", "Geoff Sutcliffe"], "title": "TPTP World Infrastructure for Non-classical Logics", "comment": "35 pages", "summary": "The TPTP World is the well established infrastructure that supports research,\ndevelopment, and deployment of Automated Theorem Proving (ATP) systems. The\nTPTP World supports a range of classical logics, and since release v9.0.0 has\nsupported non-classical logics. This paper provides a self-contained\ncomprehensive overview of the TPTP World infrastructure for ATP in\nnon-classical logics: the non-classical language extension, problems and\nsolutions, and tool support. A detailed description of use of the\ninfrastructure for quantified normal multi-modal logic is given.", "AI": {"tldr": "\u672c\u8bba\u6587\u4ecb\u7ecd\u4e86TPTP World\u57fa\u7840\u8bbe\u65bd\u6269\u5c55\u652f\u6301\u4e86\u975e\u7ecf\u5178\u903b\u8f91\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\uff0c\u6db5\u76d6\u8bed\u8a00\u3001\u5de5\u5177\u548c\u5b9e\u4f8b\u5e94\u7528\uff0c\u7279\u522b\u5f3a\u8c03\u4e86\u591a\u6a21\u6001\u903b\u8f91\u65b9\u9762\u7684\u5177\u4f53\u5b9e\u73b0\u3002", "motivation": "\u4f20\u7edf\u7684TPTP World\u4e3b\u8981\u652f\u6301\u7ecf\u5178\u903b\u8f91\uff0c\u968f\u7740\u5bf9\u975e\u7ecf\u5178\u903b\u8f91ATP\u9700\u6c42\u7684\u589e\u957f\uff0c\u4e9f\u9700\u6269\u5c55\u5176\u57fa\u7840\u8bbe\u65bd\u4ee5\u652f\u6301\u66f4\u5e7f\u6cdb\u7684\u903b\u8f91\u7cfb\u7edf\u3002", "method": "\u901a\u8fc7\u68b3\u7406TPTP World\u73b0\u6709\u529f\u80fd\uff0c\u91cd\u70b9\u4ecb\u7ecd\u5176\u9488\u5bf9\u91cf\u5316\u6b63\u5e38\u591a\u6a21\u6001\u903b\u8f91\u7684\u5e94\u7528\u7ec6\u8282\u3002", "result": "TPTP World\u5df2\u4ecev9.0.0\u5f00\u59cb\u652f\u6301\u975e\u7ecf\u5178\u903b\u8f91\uff0c\u73b0\u6709\u914d\u5957\u5de5\u5177\u548c\u95ee\u9898\u5e93\u53ef\u9002\u7528\u4e8e\u591a\u79cd\u975e\u7ecf\u5178\u903b\u8f91\uff0c\u5e76\u8be6\u8ff0\u4e86\u5bf9\u591a\u6a21\u6001\u903b\u8f91\u7684\u652f\u6301\u3002", "conclusion": "\u6587\u7ae0\u603b\u7ed3\u4e86TPTP World\u5728\u652f\u6301\u975e\u7ecf\u5178\u903b\u8f91\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u65b9\u9762\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u5305\u62ec\u8bed\u8a00\u6269\u5c55\u3001\u95ee\u9898\u4e0e\u89e3\u51b3\u65b9\u6848\u4ee5\u53ca\u76f8\u5173\u5de5\u5177\u3002"}}
{"id": "2508.09366", "categories": ["cs.SE", "D.2.5"], "pdf": "https://arxiv.org/pdf/2508.09366", "abs": "https://arxiv.org/abs/2508.09366", "authors": ["Qiaolin Qin", "Xingfang Wu", "Heng Li", "Ettore Merlo"], "title": "Plug it and Play on Logs: A Configuration-Free Statistic-Based Log Parser", "comment": null, "summary": "Log parsing is an essential task in log analysis, and many tools have been\ndesigned to accomplish it. Existing log parsers can be categorized into\nstatistic-based and semantic-based approaches. In comparison to semantic-based\nparsers, existing statistic-based parsers tend to be more efficient, require\nlower computational costs, and be more privacy-preserving thanks to on-premise\ndeployment, but often fall short in their accuracy (e.g., grouping or parsing\naccuracy) and generalizability. Therefore, it became a common belief that\nstatistic-based parsers cannot be as effective as semantic-based parsers since\nthe latter could take advantage of external knowledge supported by pretrained\nlanguage models. Our work, however, challenges this belief with a novel\nstatistic-based parser, PIPLUP. PIPLUP eliminates the pre-assumption of the\nposition of constant tokens for log grouping and relies on data-insensitive\nparameters to overcome the generalizability challenge, allowing \"plug and play\"\non given log files. According to our experiments on an open-sourced large log\ndataset, PIPLUP shows promising accuracy and generalizability with the\ndata-insensitive default parameter set. PIPLUP not only outperforms the\nstate-of-the-art statistic-based log parsers, Drain and its variants, but also\nobtains a competitive performance compared to the best unsupervised\nsemantic-based log parser (i.e., LUNAR). Further, PIPLUP exhibits low time\nconsumption without GPU acceleration and external API usage; our simple,\nefficient, and effective approach makes it more practical in real-world\nadoptions, especially when costs and privacy are of major concerns.", "AI": {"tldr": "PIPLUP\u662f\u4e00\u79cd\u65b0\u578b\u9ad8\u6548\u7684\u7edf\u8ba1\u5f0f\u65e5\u5fd7\u89e3\u6790\u5668\uff0c\u4e0d\u9700GPU\u548c\u5916\u90e8\u77e5\u8bc6\u3001\u6613\u90e8\u7f72\uff0c\u51c6\u786e\u7387\u548c\u6cdb\u5316\u6027\u5ab2\u7f8e\u6216\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u5408\u5bf9\u6210\u672c\u548c\u9690\u79c1\u6709\u9ad8\u8981\u6c42\u7684\u5b9e\u9645\u573a\u666f\u3002", "motivation": "\u5f53\u524d\u65e5\u5fd7\u89e3\u6790\u5de5\u5177\u5206\u4e3a\u7edf\u8ba1\u578b\u548c\u8bed\u4e49\u578b\u4e24\u6d3e\u3002\u7edf\u8ba1\u578b\u65b9\u6cd5\u867d\u7136\u6548\u7387\u9ad8\u3001\u6210\u672c\u4f4e\u3001\u6613\u4e8e\u672c\u5730\u5316\u3001\u4fdd\u62a4\u9690\u79c1\uff0c\u4f46\u51c6\u786e\u7387\u548c\u6cdb\u5316\u6027\u8f83\u5dee\uff0c\u88ab\u8ba4\u4e3a\u4e0d\u5982\u53ef\u4ee5\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7b49\u5916\u90e8\u77e5\u8bc6\u7684\u8bed\u4e49\u578b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u65b0\u7684\u7edf\u8ba1\u578b\u65e5\u5fd7\u89e3\u6790\u5668PIPLUP\u3002PIPLUP\u53bb\u9664\u4e86\u5e38\u91cftoken\u4f4d\u7f6e\u7684\u5148\u9a8c\u5047\u8bbe\uff0c\u91c7\u7528\u4e0e\u6570\u636e\u65e0\u5173\u7684\u53c2\u6570\u8bbe\u7f6e\u6765\u63d0\u5347\u6cdb\u5316\u80fd\u529b\uff0c\u5b9e\u73b0\u201c\u5373\u63d2\u5373\u7528\u201d\u3002", "result": "\u5728\u5f00\u6e90\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\uff0cPIPLUP\u7528\u9ed8\u8ba4\u53c2\u6570\u5373\u53ef\u8fbe\u5230\u51fa\u8272\u7684\u51c6\u786e\u7387\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4f18\u4e8e\u6700\u5148\u8fdb\u7684Drain\u53ca\u5176\u53d8\u79cd\uff0c\u5e76\u4e0e\u6700\u4f73\u65e0\u76d1\u7763\u8bed\u4e49\u578b\u89e3\u6790\u5668LUNAR\u6027\u80fd\u63a5\u8fd1\u3002\u6b64\u5916\uff0c\u65e0\u9700GPU\u548c\u5916\u90e8API\u5373\u53ef\u9ad8\u6548\u8fd0\u884c\uff0c\u63d0\u5347\u4e86\u5b9e\u7528\u6027\u3002", "conclusion": "PIPLUP\u7a81\u7834\u4e86\u7edf\u8ba1\u578b\u65e5\u5fd7\u89e3\u6790\u65b9\u6cd5\u5728\u51c6\u786e\u7387\u548c\u6cdb\u5316\u6027\u65b9\u9762\u7684\u74f6\u9888\uff0c\u5728\u6548\u7387\u3001\u9690\u79c1\u3001\u6210\u672c\u7b49\u65b9\u9762\u5177\u6709\u66f4\u5f3a\u7684\u73b0\u5b9e\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.09553", "categories": ["cs.LO", "cs.CC"], "pdf": "https://arxiv.org/pdf/2508.09553", "abs": "https://arxiv.org/abs/2508.09553", "authors": ["Anne-Marie George", "Ana Ozaki"], "title": "On Middle Grounds for Preference Statements", "comment": "Longer Version of IJCAI'25 publication under the same name", "summary": "In group decisions or deliberations, stakeholders are often confronted with\nconflicting opinions. We investigate a logic-based way of expressing such\nopinions and a formal general notion of a middle ground between stakeholders.\nInspired by the literature on preferences with hierarchical and lexicographic\nmodels, we instantiate our general framework to the case where stakeholders\nexpress their opinions using preference statements of the form I prefer 'a' to\n'b', where 'a' and 'b' are alternatives expressed over some attributes, e.g.,\nin a trolley problem, one can express I prefer to save 1 adult and 1 child to 2\nadults (and 0 children). We prove theoretical results on the existence and\nuniqueness of middle grounds. In particular, we show that, for preference\nstatements, middle grounds may not exist and may not be unique. We also provide\nalgorithms for deciding the existence and finding middle grounds.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u903b\u8f91\u5316\u7684\u610f\u89c1\u8868\u8fbe\u65b9\u6cd5\uff0c\u5206\u6790\u5e76\u8bc1\u660e\u504f\u597d\u8868\u8fbe\u4e0b\u4e2d\u95f4\u7acb\u573a\u53ef\u80fd\u4e0d\u5b58\u5728\u6216\u4e0d\u552f\u4e00\uff0c\u540c\u65f6\u7ed9\u51fa\u5224\u5b9a\u548c\u5bfb\u627e\u4e2d\u95f4\u7acb\u573a\u7684\u7b97\u6cd5\u3002", "motivation": "\u5728\u7fa4\u4f53\u51b3\u7b56\u6216\u8ba8\u8bba\u4e2d\uff0c\u5229\u76ca\u76f8\u5173\u8005\u5e38\u6709\u51b2\u7a81\u610f\u89c1\uff0c\u9700\u8981\u4e00\u79cd\u903b\u8f91\u5316\u7684\u8868\u8fbe\u53ca\u5bfb\u627e\u4e2d\u95f4\u7acb\u573a\u7684\u7406\u8bba\u65b9\u6cd5\u6765\u534f\u8c03\u5206\u6b67\u3002", "method": "\u901a\u8fc7\u903b\u8f91\u8868\u8fbe\u7684\u65b9\u5f0f\u5efa\u6a21\u5229\u76ca\u76f8\u5173\u8005\u7684\u610f\u89c1\uff0c\u57fa\u4e8e\u504f\u597d\u5c42\u6b21\u548c\u5b57\u5178\u5e8f\u6a21\u578b\uff0c\u7406\u8bba\u5206\u6790\u4e2d\u95f4\u7acb\u573a\u7684\u5b58\u5728\u6027\u548c\u552f\u4e00\u6027\uff0c\u5e76\u8bbe\u8ba1\u76f8\u5173\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86\u4e2d\u95f4\u7acb\u573a\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4e0d\u5b58\u5728\u6216\u4e0d\u552f\u4e00\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5173\u5224\u5b9a\u548c\u641c\u7d22\u7b97\u6cd5\u3002", "conclusion": "\u5bf9\u4e8e\u504f\u597d\u9648\u8ff0\uff0c\u4e2d\u95f4\u7acb\u573a\u53ef\u80fd\u4e0d\u5b58\u5728\uff0c\u4e5f\u53ef\u80fd\u4e0d\u552f\u4e00\uff0c\u5e76\u63d0\u51fa\u4e86\u5224\u65ad\u5b58\u5728\u6027\u548c\u5bfb\u627e\u4e2d\u95f4\u7acb\u573a\u7684\u7b97\u6cd5\u3002"}}
{"id": "2508.09537", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09537", "abs": "https://arxiv.org/abs/2508.09537", "authors": ["Yanzhou Li", "Tianlin Li", "Yiran Zhang", "Shangqing Liu", "Aishan Liu", "Yang Liu"], "title": "Your Coding Intent is Secretly in the Context and You Should Deliberately Infer It Before Completion", "comment": null, "summary": "Large Language Models (LLMs) are increasingly used for function completion in\nrepository-scale codebases. Prior studies demonstrate that when explicit\ninstructions--such as docstrings--are provided, these models can generate\nhighly accurate implementations. However, in real-world repositories, such\nannotations are frequently absent, and performance drops substantially without\nthem. To address this gap, we frame the task as a three-stage process. The\nfirst stage focuses on intent inference, where the model analyzes the code\npreceding the target function to uncover cues about the desired functionality.\nSuch preceding context often encodes subtle but critical information, and we\ndesign a reasoning-based prompting framework to guide the LLM through\nstep-by-step extraction and synthesis of these signals before any code is\ngenerated. The second stage introduces an optional interactive refinement\nmechanism to handle cases where preceding context alone is insufficient for\nintent recovery. In this stage, the model proposes a small set of candidate\nintentions, enabling the developer to select or edit them so that the inferred\nintent closely matches the actual requirement. Finally, in the third stage, the\nLLM generates the target function conditioned on the finalized intent. To\nsupport this pipeline, we curate a dataset of 40,000 examples annotated with\nintermediate reasoning traces and corresponding docstrings. Extensive\nexperiments on DevEval and ComplexCodeEval show that our approach consistently\nboosts multiple LLMs, achieving over 20\\% relative gains in both\nreference-based and execution-based metrics, with the interactive refinement\nstage delivering additional improvements beyond these gains.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u4e09\u9636\u6bb5\u6d41\u7a0b\uff0c\u901a\u8fc7\u5206\u6790\u51fd\u6570\u524d\u7f6e\u4ee3\u7801\u3001\u4ea4\u4e92\u610f\u56fe\u4fee\u6b63\u548c\u610f\u56fe\u9a71\u52a8\u751f\u6210\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u6a21\u578b\u5728\u5b9e\u9645\u4ee3\u7801\u8865\u5168\u4e2d\u7684\u8868\u73b0\uff0c\u5c24\u5176\u5728\u7f3a\u4e4f\u6ce8\u91ca\u65f6\u6548\u679c\u660e\u663e\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4ee5\u5f80\u5927\u6a21\u578b\u5728\u4ee3\u7801\u81ea\u52a8\u8865\u5168\u4efb\u52a1\u4e2d\uff0c\u4f9d\u8d56\u4e8e\u660e\u786e\u8bf4\u660e\uff08\u5982\u51fd\u6570\u6ce8\u91ca\uff09\uff0c\u800c\u73b0\u5b9e\u4ee3\u7801\u4ed3\u5e93\u4e2d\u5f80\u5f80\u7f3a\u4e4f\u8fd9\u4e9b\u6ce8\u91ca\uff0c\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a(1) \u610f\u56fe\u63a8\u65ad\uff1a\u5206\u6790\u76ee\u6807\u51fd\u6570\u4e4b\u524d\u7684\u4ee3\u7801\uff0c\u5229\u7528\u57fa\u4e8e\u63a8\u7406\u7684\u63d0\u793a\u6846\u67b6\u9010\u6b65\u62bd\u53d6\u548c\u5408\u6210\u529f\u80fd\u7ebf\u7d22\uff1b(2) \u4ea4\u4e92\u5f0f\u610f\u56fe\u4fee\u6b63\uff1a\u5f53\u4e0a\u4e0b\u6587\u4e0d\u8db3\u65f6\uff0c\u6a21\u578b\u751f\u6210\u82e5\u5e72\u610f\u56fe\u5019\u9009\uff0c\u8ba9\u5f00\u53d1\u8005\u9009\u62e9\u6216\u7f16\u8f91\u4ee5\u786e\u4fdd\u7b26\u5408\u9700\u6c42\uff1b(3) \u6839\u636e\u6700\u7ec8\u786e\u5b9a\u610f\u56fe\u751f\u6210\u76ee\u6807\u51fd\u6570\u3002\u6b64\u5916\uff0c\u6784\u5efa\u4e86\u5305\u542b4\u4e07\u4e2a\u5e26\u6709\u63a8\u7406\u8fc7\u7a0b\u548c\u6ce8\u91ca\u7684\u6570\u636e\u96c6\u3002", "result": "\u5728DevEval\u548cComplexCodeEval\u8d44\u6e90\u4e0a\u7684\u5927\u89c4\u6a21\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u5927\u6a21\u578b\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u53c2\u8003\u4e0e\u6267\u884c\u7c7b\u6307\u6807\u76f8\u8f83\u4e8e\u539f\u59cb\u6a21\u578b\u63d0\u5347\u8d85\u8fc720%\uff0c\u4ea4\u4e92\u4fee\u6b63\u9636\u6bb5\u8fd8\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u6548\u679c\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u63a8\u7406\u548c\u4ea4\u4e92\u673a\u5236\uff0c\u6709\u6548\u5f25\u8865\u4e86\u7f3a\u4e4f\u6ce8\u91ca\u65f6\u5927\u6a21\u578b\u4ee3\u7801\u8865\u5168\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u7684\u51c6\u786e\u7387\u3002"}}
{"id": "2508.09851", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.09851", "abs": "https://arxiv.org/abs/2508.09851", "authors": ["Adrian Rebola-Pardo"], "title": "Short proofs without interference", "comment": null, "summary": "Interference is a phenomenon on proof systems for SAT solving that is both\ncounter-intuitive and bothersome when developing proof-logging techniques.\nHowever, all existing proof systems that can produce short proofs for all\ninprocessing techniques deployed by SAT present this feature. Based on insights\nfrom propositional dynamic logic, we propose a framework that eliminates\ninterference while preserving the same expressive power of interference-based\nproofs. Furthermore, we propose a first building blocks towards RUP-like\ndecision procedures for our dynamic logic-based frameworks, which are essential\nto developing effective proof checking methods.", "AI": {"tldr": "\u672c\u8bba\u6587\u901a\u8fc7\u547d\u9898\u52a8\u6001\u903b\u8f91\uff0c\u8bbe\u8ba1\u51fa\u80fd\u6d88\u9664\u5e72\u6270\u4e14\u8868\u8fbe\u529b\u4e0d\u51cf\u7684SAT\u8bc1\u660e\u6846\u67b6\uff0c\u5e76\u4e3a\u540e\u7eed\u9ad8\u6548\u8bc1\u660e\u68c0\u67e5\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "SAT\u8bc1\u660e\u7cfb\u7edf\u4e2d\u8bc1\u660e-\u8bb0\u5f55\u6280\u672f\u5e38\u53d7\u201c\u5e72\u6270\u201d\u5f71\u54cd\uff0c\u9650\u5236\u4e86\u6709\u6548\u6027\u3002\u5f53\u524d\u77ed\u8bc1\u660e\u65b9\u6cd5\u5747\u5b58\u5728\u6b64\u95ee\u9898\uff0c\u4f5c\u8005\u6b32\u5bfb\u6c42\u65e0\u5e72\u6270\u4e14\u540c\u6837\u6709\u529b\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u4f5c\u8005\u5229\u7528\u547d\u9898\u52a8\u6001\u903b\u8f91\u7684\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u4e86\u65b0\u7684\u8bc1\u660e\u6846\u67b6\uff0c\u5e76\u9610\u8ff0\u4e86\u6784\u5efaRUP\u98ce\u683c\u51b3\u7b56\u89c4\u7a0b\u7684\u521d\u6b65\u65b9\u5411\u3002", "result": "\u63d0\u51fa\u4e86\u9996\u4e2a\u80fd\u6d88\u9664\u5e72\u6270\u73b0\u8c61\u7684\u65b0\u6846\u67b6\uff0c\u5e76\u4e3a\u672a\u6765\u5f00\u53d1\u9ad8\u6548\u8bc1\u660e\u68c0\u67e5\u6280\u672f\u5efa\u7acb\u4e86\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u901a\u8fc7\u63d0\u51fa\u57fa\u4e8e\u547d\u9898\u52a8\u6001\u903b\u8f91\u7684\u6846\u67b6\uff0c\u4f5c\u8005\u6210\u529f\u6d88\u9664\u4e86SAT\u6c42\u89e3\u4e2d\u8bc1\u660e\u7cfb\u7edf\u7684\u5e72\u6270\u73b0\u8c61\uff0c\u5e76\u4fdd\u6301\u4e86\u539f\u6709\u8bc1\u660e\u7cfb\u7edf\u7684\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2508.09648", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.09648", "abs": "https://arxiv.org/abs/2508.09648", "authors": ["Taohong Zhu", "Lucas C. Cordeiro", "Youcheng Sun"], "title": "ReqInOne: A Large Language Model-Based Agent for Software Requirements Specification Generation", "comment": null, "summary": "Software Requirements Specification (SRS) is one of the most important\ndocuments in software projects, but writing it manually is time-consuming and\noften leads to ambiguity. Existing automated methods rely heavily on manual\nanalysis, while recent Large Language Model (LLM)-based approaches suffer from\nhallucinations and limited controllability. In this paper, we propose ReqInOne,\nan LLM-based agent that follows the common steps taken by human requirements\nengineers when writing an SRS to convert natural language into a structured\nSRS. ReqInOne adopts a modular architecture by decomposing SRS generation into\nthree tasks: summary, requirement extraction, and requirement classification,\neach supported by tailored prompt templates to improve the quality and\nconsistency of LLM outputs.\n  We evaluate ReqInOne using GPT-4o, LLaMA 3, and DeepSeek-R1, and compare the\ngenerated SRSs against those produced by the holistic GPT-4-based method from\nprior work as well as by entry-level requirements engineers. Expert evaluations\nshow that ReqInOne produces more accurate and well-structured SRS documents.\nThe performance advantage of ReqInOne benefits from its modular design, and\nexperimental results further demonstrate that its requirement classification\ncomponent achieves comparable or even better results than the state-of-the-art\nrequirement classification model.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5206\u6b65\u3001\u6a21\u5757\u5316\u7684\u5927\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5ReqInOne\uff0c\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u7ed3\u6784\u5316SRS\u3002\u5b9e\u9a8c\u663e\u793a\u5176\u51c6\u786e\u7387\u548c\u7ed3\u6784\u6e05\u6670\u5ea6\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u53ca\u5165\u95e8\u5de5\u7a0b\u5e08\uff0c\u90e8\u5206\u6a21\u5757\u8fbe\u5230\u751a\u81f3\u8d85\u8fc7\u884c\u4e1a\u6700\u4f73\u6c34\u5e73\u3002", "motivation": "\u624b\u5de5\u7f16\u5199\u8f6f\u4ef6\u9700\u6c42\u89c4\u683c\u8bf4\u660e\u4e66\uff08SRS\uff09\u8d39\u65f6\u4e14\u6613\u4ea7\u751f\u6b67\u4e49\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u65b9\u6cd5\u5b58\u5728\u5e7b\u89c9\u548c\u53ef\u63a7\u6027\u5dee\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51faReqInOne\uff0c\u4e00\u4e2a\u6a21\u62df\u4eba\u7c7b\u9700\u6c42\u5de5\u7a0b\u5e08\u5199SRS\u6d41\u7a0b\u7684\u6a21\u5757\u5316LLM\u4ee3\u7406\uff0c\u5c06SRS\u751f\u6210\u62c6\u89e3\u4e3a\u6458\u8981\u3001\u9700\u6c42\u63d0\u53d6\u548c\u9700\u6c42\u5206\u7c7b\u4e09\u4e2a\u4efb\u52a1\uff0c\u6bcf\u6b65\u91c7\u7528\u5b9a\u5236\u5316\u63d0\u793a\u6a21\u677f\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\uff0c\u57fa\u4e8eGPT-4o\u3001LLaMA 3\u548cDeepSeek-R1\u7684ReqInOne\u76f8\u8f83\u4e8e\u4ee5\u5f80\u6574\u4f53\u5f0fGPT-4\u65b9\u6cd5\u4e0e\u5165\u95e8\u7ea7\u9700\u6c42\u5de5\u7a0b\u5e08\uff0c\u751f\u6210\u7684SRS\u66f4\u51c6\u786e\u3001\u7ed3\u6784\u66f4\u4f18\u3002\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u5206\u7c7b\u7ec4\u4ef6\u5e26\u6765\u4e86\u6027\u80fd\u4f18\u52bf\uff0c\u5bf9\u6bd4\u5206\u7c7bSOTA\u6a21\u578b\u4e5f\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "ReqInOne\u80fd\u6709\u6548\u63d0\u5347LLM\u751f\u6210SRS\u7684\u51c6\u786e\u6027\u548c\u7ed3\u6784\u6027\uff0c\u6a21\u5757\u5316\u5206\u6b65\u8bbe\u8ba1\u4f18\u4e8e\u6574\u4f53\u5f0f\u65b9\u6cd5\uff0c\u90e8\u5206\u73af\u8282\u6027\u80fd\u53ef\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u6a21\u578b\u3002"}}
{"id": "2508.09934", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.09934", "abs": "https://arxiv.org/abs/2508.09934", "authors": ["Arijit Shaw", "Uddalok Sarkar", "Kuldeep S. Meel"], "title": "Efficient Volume Computation for SMT Formulas", "comment": "Full version of conference paper accepted to KR 2023", "summary": "Satisfiability Modulo Theory (SMT) has recently emerged as a powerful tool\nfor solving various automated reasoning problems across diverse domains. Unlike\ntraditional satisfiability methods confined to Boolean variables, SMT can\nreason on real-life variables like bitvectors, integers, and reals. A natural\nextension in this context is to ask quantitative questions. One such query in\nthe SMT theory of Linear Real Arithmetic (LRA) is computing the volume of the\nentire satisfiable region defined by SMT formulas. This problem is important in\nsolving different quantitative verification queries in software verification,\ncyber-physical systems, and neural networks, to mention a few.\n  We introduce ttc, an efficient algorithm that extends the capabilities of SMT\nsolvers to volume computation. Our method decomposes the solution space of SMT\nLinear Real Arithmetic formulas into a union of overlapping convex polytopes,\nthen computes their volumes and calculates their union. Our algorithm builds on\nrecent developments in streaming-mode set unions, volume computation\nalgorithms, and AllSAT techniques. Experimental evaluations demonstrate\nsignificant performance improvements over existing state-of-the-art approaches.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6269\u5c55SMT\u5b9a\u91cf\u5206\u6790\u80fd\u529b\u7684\u65b0\u7b97\u6cd5ttc\uff0c\u80fd\u9ad8\u6548\u8ba1\u7b97SMT\u7ebf\u6027\u5b9e\u6570\u7b97\u672f\u516c\u5f0f\u7684\u53ef\u6ee1\u8db3\u533a\u57df\u4f53\u79ef\u3002\u65b9\u6cd5\u5305\u62ec\u591a\u9762\u4f53\u5206\u89e3\u3001\u4f53\u79ef\u8ba1\u7b97\u53ca\u96c6\u5408\u5e76\u3002\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u4f18\u8d8a\uff0c\u5bf9\u5b9a\u91cf\u9a8c\u8bc1\u7b49\u9886\u57df\u6709\u91cd\u8981\u4ef7\u503c\u3002", "motivation": "SMT\uff08\u53ef\u6ee1\u8db3\u6027\u6a21\u7406\u8bba\uff09\u73b0\u5df2\u5e7f\u6cdb\u7528\u4e8e\u81ea\u52a8\u5316\u63a8\u7406\u95ee\u9898\uff0c\u80fd\u591f\u5904\u7406\u66f4\u4e30\u5bcc\u7684\u53d8\u91cf\u7c7b\u578b\u3002\u73b0\u6709\u7814\u7a76\u66f4\u591a\u5173\u6ce8\u4e8e\u5224\u5b9a\u53ef\u6ee1\u8db3\u95ee\u9898\uff0c\u800c\u5b9e\u9645\u5e94\u7528\uff08\u5982\u8f6f\u4ef6\u9a8c\u8bc1\u7b49\uff09\u7684\u5b9a\u91cf\u5206\u6790\u9700\u6c42\u589e\u52a0\uff0c\u5982\u6c42SMT\u516c\u5f0f\u5b9a\u4e49\u533a\u57df\u7684\u4f53\u79ef\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u63a8\u52a8SMT\u4ece\u903b\u8f91\u5224\u5b9a\u5230\u5b9a\u91cf\u5206\u6790\u7684\u80fd\u529b\u6269\u5c55\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9ad8\u6548\u7b97\u6cd5ttc\uff0c\u5b83\u5c06SMT\u7684\u7ebf\u6027\u5b9e\u6570\u7b97\u672f\uff08LRA\uff09\u516c\u5f0f\u7684\u89e3\u7a7a\u95f4\u5206\u89e3\u4e3a\u591a\u4e2a\u91cd\u53e0\u7684\u51f8\u591a\u9762\u4f53\uff0c\u901a\u8fc7\u4f53\u79ef\u8ba1\u7b97\u4e0e\u96c6\u5408\u5e76\u6280\u672f\uff0c\u6700\u7ec8\u5f97\u5230\u603b\u7684\u53ef\u6ee1\u8db3\u533a\u57df\u4f53\u79ef\uff0c\u5e76\u7ed3\u5408\u6d41\u5f0f\u96c6\u5408\u5e76\u3001\u4f53\u79ef\u8ba1\u7b97\u3001AllSAT\u7b49\u6700\u65b0\u6280\u672f\u8fdb\u884c\u5b9e\u73b0\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660ettc\u7b97\u6cd5\u5728\u4f53\u79ef\u8ba1\u7b97\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u9886\u57df\u7684\u76f8\u5173\u5e94\u7528\u4e2d\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "ttc\u663e\u8457\u63d0\u5347\u4e86SMT\u5728\u7ebf\u6027\u5b9e\u6570\u7b97\u672f\u4f53\u79ef\u8ba1\u7b97\u4e0a\u7684\u80fd\u529b\uff0c\u4e3a\u8f6f\u4ef6\u9a8c\u8bc1\u3001\u7f51\u7edc\u5b89\u5168\u7b49\u6d89\u53ca\u5b9a\u91cf\u9a8c\u8bc1\u7684\u9886\u57df\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u6280\u672f\u652f\u6491\u3002\u5176\u65b9\u6cd5\u53ef\u4f5c\u4e3a\u73b0\u6709SMT\u5de5\u5177\u7684\u91cd\u8981\u8865\u5145\u3002"}}
{"id": "2508.09303", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.09303", "abs": "https://arxiv.org/abs/2508.09303", "authors": ["Shu Zhao", "Tan Yu", "Anbang Xu", "Japinder Singh", "Aaditya Shukla", "Rama Akkiraju"], "title": "ParallelSearch: Train your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning", "comment": null, "summary": "Reasoning-augmented search agents such as Search-R1, trained via\nreinforcement learning with verifiable rewards (RLVR), demonstrate remarkable\ncapabilities in multi-step information retrieval from external knowledge\nsources. These agents address the limitations of their parametric memory by\ndynamically gathering relevant facts to address complex reasoning tasks.\nHowever, existing approaches suffer from a fundamental architectural\nlimitation: they process search queries strictly sequentially, even when\nhandling inherently parallelizable and logically independent comparisons. This\nsequential bottleneck significantly constrains computational efficiency,\nparticularly for queries that require multiple entity comparisons. To address\nthis critical limitation, we propose ParallelSearch, a novel reinforcement\nlearning framework that empowers large language models (LLMs) to recognize\nparallelizable query structures and execute multiple search operations\nconcurrently. Our approach introduces dedicated reward functions that\nincentivize the identification of independent query components while preserving\nanswer accuracy through jointly considering correctness, query decomposition\nquality, and parallel execution benefits. Comprehensive experiments demonstrate\nthat ParallelSearch outperforms state-of-the-art baselines by an average\nperformance gain of 2.9% across seven question-answering benchmarks. Notably,\non parallelizable questions, our method achieves a 12.7% performance\nimprovement while requiring only 69.6% of the LLM calls compared to sequential\napproaches.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86ParallelSearch\u6846\u67b6\uff0c\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u65f6\u53ef\u4ee5\u5e76\u884c\u6267\u884c\u72ec\u7acb\u7684\u67e5\u8be2\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u6548\u7387\u548c\u6027\u80fd\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5bf9\u53ef\u5e76\u884c\u7684\u590d\u6742\u95ee\u9898\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u63a8\u7406\u589e\u5f3a\u641c\u7d22\u4ee3\u7406\u5728\u591a\u6b65\u4fe1\u606f\u68c0\u7d22\u4e0a\u5f88\u5f3a\uff0c\u4f46\u7531\u4e8e\u67b6\u6784\u9650\u5236\uff0c\u5b83\u4eec\u5bf9\u4e8e\u53ef\u4ee5\u5e76\u884c\u5904\u7406\u7684\u72ec\u7acb\u67e5\u8be2\u4ecd\u7136\u91c7\u7528\u4e25\u683c\u7684\u987a\u5e8f\u5904\u7406\u65b9\u5f0f\uff0c\u5bfc\u81f4\u6548\u7387\u74f6\u9888\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u6bd4\u5bf9\u591a\u4e2a\u5b9e\u4f53\u65f6\u3002", "method": "\u63d0\u51faParallelSearch\uff0c\u4e00\u4e2a\u65b0\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u8bc6\u522b\u53ef\u5e76\u884c\u5316\u7684\u67e5\u8be2\u7ed3\u6784\uff0c\u5e76\u53d1\u6267\u884c\u591a\u4e2a\u641c\u7d22\u64cd\u4f5c\u3002\u901a\u8fc7\u8bbe\u7f6e\u4e13\u95e8\u7684\u5956\u52b1\u51fd\u6570\uff0c\u6fc0\u52b1\u6a21\u578b\u8bc6\u522b\u72ec\u7acb\u7684\u67e5\u8be2\u7ec4\u4ef6\uff0c\u7efc\u5408\u8003\u8651\u6b63\u786e\u6027\u3001\u67e5\u8be2\u5206\u89e3\u8d28\u91cf\u4e0e\u5e76\u884c\u6267\u884c\u7684\u6536\u76ca\u3002", "result": "\u5728\u4e03\u4e2a\u95ee\u7b54\u57fa\u51c6\u4efb\u52a1\u4e0a\uff0cParallelSearch\u5e73\u5747\u6027\u80fd\u63d0\u53472.9%\u3002\u9488\u5bf9\u53ef\u5e76\u884c\u5316\u95ee\u9898\uff0c\u6027\u80fd\u63d0\u5347\u8fbe12.7%\uff0c\u4e14\u4ec5\u4f7f\u7528\u539f\u987a\u5e8f\u65b9\u6cd569.6%\u7684\u6a21\u578b\u8c03\u7528\u6b21\u6570\u3002", "conclusion": "ParallelSearch\u6709\u6548\u7a81\u7834\u4e86\u987a\u5e8f\u5904\u7406\u7684\u67b6\u6784\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u578b\u641c\u7d22\u4ee3\u7406\u5728\u5e76\u884c\u5316\u67e5\u8be2\u573a\u666f\u4e0b\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2508.09676", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.09676", "abs": "https://arxiv.org/abs/2508.09676", "authors": ["Vishal Khare", "Vijay Saini", "Deepak Sharma", "Anand Kumar", "Ankit Rana", "Anshul Yadav"], "title": "DeputyDev -- AI Powered Developer Assistant: Breaking the Code Review Logjam through Contextual AI to Boost Developer Productivity", "comment": "12 pages, 5 figures, 6 pages of supplementary materials", "summary": "This study investigates the implementation and efficacy of DeputyDev, an\nAI-powered code review assistant developed to address inefficiencies in the\nsoftware development process. The process of code review is highly inefficient\nfor several reasons, such as it being a time-consuming process, inconsistent\nfeedback, and review quality not being at par most of the time. Using our\ntelemetry data, we observed that at TATA 1mg, pull request (PR) processing\nexhibits significant inefficiencies, with average pick-up and review times of\n73 and 82 hours, respectively, resulting in a 6.2 day closure cycle. The review\ncycle was marked by prolonged iterative communication between the reviewing and\nsubmitting parties. Research from the University of California, Irvine\nindicates that interruptions can lead to an average of 23 minutes of lost\nfocus, critically affecting code quality and timely delivery. To address these\nchallenges, we developed DeputyDev's PR review capabilities by providing\nautomated, contextual code reviews. We conducted a rigorous double-controlled\nA/B experiment involving over 200 engineers to evaluate DeputyDev's impact on\nreview times. The results demonstrated a statistically significant reduction in\nboth average per PR (23.09%) and average per-line-of-code (40.13%) review\ndurations. After implementing safeguards to exclude outliers, DeputyDev has\nbeen effectively rolled out across the entire organisation. Additionally, it\nhas been made available to external companies as a Software-as-a-Service (SaaS)\nsolution, currently supporting the daily work of numerous engineering\nprofessionals. This study explores the implementation and effectiveness of\nAI-assisted code reviews in improving development workflow timelines and code.", "AI": {"tldr": "DeputyDev\u662f\u4e00\u6b3e\u57fa\u4e8eAI\u7684\u4ee3\u7801\u5ba1\u67e5\u52a9\u624b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5ba1\u67e5\u6548\u7387\uff0c\u7f29\u77ed\u4e86\u8bc4\u5ba1\u65f6\u95f4\uff0c\u5728\u5b9e\u9645\u5de5\u7a0b\u573a\u666f\u4e2d\u6548\u679c\u7a81\u51fa\uff0c\u5e76\u5df2\u6269\u5c55\u4e3aSaaS\u670d\u52a1\u3002", "motivation": "\u4ee3\u7801\u5ba1\u67e5\u8fc7\u7a0b\u666e\u904d\u5b58\u5728\u4f4e\u6548\u95ee\u9898\uff0c\u4f8b\u5982\u8017\u65f6\u957f\u3001\u53cd\u9988\u4e0d\u4e00\u81f4\u3001\u5ba1\u67e5\u8d28\u91cf\u4e0d\u8fbe\u6807\u7b49\uff0cTATA 1mg \u7684\u5b9e\u9645\u6570\u636e\u4e5f\u663e\u793a\u62c9\u53d6\u8bf7\u6c42\u7684\u5904\u7406\u548c\u5ba1\u67e5\u5468\u671f\u8fc7\u957f\uff0c\u4e25\u91cd\u5f71\u54cd\u8f6f\u4ef6\u4ea4\u4ed8\u6548\u7387\u548c\u8d28\u91cf\u3002", "method": "\u8bbe\u8ba1\u5e76\u5f00\u53d1\u4e86AI\u9a71\u52a8\u7684\u4ee3\u7801\u5ba1\u67e5\u52a9\u624bDeputyDev\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u4ee3\u7801\u5ba1\u67e5\u63d0\u5347\u6548\u7387\u3002\u91c7\u7528\u53cc\u76f2A/B\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u7ec4\u7ec7200\u591a\u540d\u5de5\u7a0b\u5e08\u53c2\u4e0e\u6d4b\u8bd5DeputyDev\u5bf9\u4ee3\u7801\u5ba1\u67e5\u65f6\u957f\u7684\u5f71\u54cd\u3002\u540c\u65f6\u901a\u8fc7\u6570\u636e\u6e05\u7406\u6392\u9664\u4e86\u6781\u7aef\u5f02\u5e38\u503c\uff0c\u786e\u4fdd\u7ed3\u679c\u7684\u53ef\u9760\u6027\u3002", "result": "DeputyDev\u663e\u8457\u7f29\u77ed\u4e86\u4ee3\u7801\u5ba1\u67e5\u5e73\u5747\u65f6\u957f\uff0c\u6bcf\u4e2aPR\u51cf\u5c11\u4e8623.09%\uff0c\u6bcf\u884c\u4ee3\u7801\u51cf\u5c11\u4e8640.13%\u3002\u6700\u7ec8\u8be5\u5de5\u5177\u5728\u516c\u53f8\u5185\u5168\u9762\u63a8\u5e7f\uff0c\u5e76\u4ee5SaaS\u5f62\u5f0f\u5bf9\u5916\u63d0\u4f9b\uff0c\u5176\u6709\u6548\u6027\u5f97\u5230\u4e86\u5b9e\u9645\u5e94\u7528\u7684\u9a8c\u8bc1\u3002", "conclusion": "AI\u8f85\u52a9\u7684\u4ee3\u7801\u5ba1\u67e5\u52a9\u624bDeputyDev\u80fd\u6709\u6548\u63d0\u5347\u4ee3\u7801\u5ba1\u67e5\u6d41\u7a0b\u6548\u7387\u5e76\u6539\u5584\u5f00\u53d1\u5468\u671f\u3002\u968f\u7740\u5e94\u7528\u666e\u53ca\uff0c\u5176\u5bf9\u63d0\u5347\u8f6f\u4ef6\u5f00\u53d1\u8d28\u91cf\u548c\u6548\u7387\u5177\u6709\u79ef\u6781\u610f\u4e49\u3002"}}
{"id": "2508.09323", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09323", "abs": "https://arxiv.org/abs/2508.09323", "authors": ["Nan Miles Xi", "Yu Deng", "Lin Wang"], "title": "Leveraging Large Language Models for Rare Disease Named Entity Recognition", "comment": null, "summary": "Named Entity Recognition (NER) in the rare disease domain poses unique\nchallenges due to limited labeled data, semantic ambiguity between entity\ntypes, and long-tail distributions. In this study, we evaluate the capabilities\nof GPT-4o for rare disease NER under low-resource settings, using a range of\nprompt-based strategies including zero-shot prompting, few-shot in-context\nlearning, retrieval-augmented generation (RAG), and task-level fine-tuning. We\ndesign a structured prompting framework that encodes domain-specific knowledge\nand disambiguation rules for four entity types. We further introduce two\nsemantically guided few-shot example selection methods to improve in-context\nperformance while reducing labeling effort. Experiments on the RareDis Corpus\nshow that GPT-4o achieves competitive or superior performance compared to\nBioClinicalBERT, with task-level fine-tuning yielding new state-of-the-art\n(SOTA) results. Cost-performance analysis reveals that few-shot prompting\ndelivers high returns at low token budgets, while RAG offers marginal\nadditional benefit. An error taxonomy highlights common failure modes such as\nboundary drift and type confusion, suggesting opportunities for post-processing\nand hybrid refinement. Our results demonstrate that prompt-optimized LLMs can\nserve as effective, scalable alternatives to traditional supervised models in\nbiomedical NER, particularly in rare disease applications where annotated data\nis scarce.", "AI": {"tldr": "\u672c\u6587\u7ed3\u5408\u591a\u79cd\u63d0\u793a\u65b9\u6cd5\u5206\u6790GPT-4o\u5728\u7f55\u89c1\u75c5\u9886\u57dfNER\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u6a21\u578b\u5bf9\u5927\u89c4\u6a21\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u8fbe\u5230\u751a\u81f3\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u5f00\u542f\u4e86\u5927\u6a21\u578b\u5728\u7a00\u6709\u9886\u57df\u6570\u636e\u5904\u7406\u7684\u5168\u65b0\u53ef\u80fd\u3002", "motivation": "\u7f55\u89c1\u75c5\u9886\u57df\u7684\u547d\u540d\u5b9e\u4f53\u8bc6\u522b(NER)\u9762\u4e34\u6807\u7b7e\u6570\u636e\u7a00\u7f3a\u3001\u5b9e\u4f53\u7c7b\u578b\u8bed\u4e49\u6a21\u7cca\u3001\u957f\u5c3e\u5206\u5e03\u7b49\u72ec\u7279\u6311\u6218\u3002", "method": "\u8bc4\u4f30GPT-4o\u5728\u4f4e\u8d44\u6e90\u6761\u4ef6\u4e0b\u8fdb\u884c\u7f55\u89c1\u75c5NER\u7684\u80fd\u529b\uff0c\u91c7\u7528\u96f6\u6837\u672c\u63d0\u793a\u3001\u5c11\u6837\u672c\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u3001\u4efb\u52a1\u7ea7\u5fae\u8c03\u7b49\u63d0\u793a\u65b9\u6cd5\u3002\u6784\u5efa\u4e86\u7ed3\u6784\u5316\u63d0\u793a\u6846\u67b6\uff0c\u5e76\u5f15\u5165\u4e86\u4e24\u79cd\u8bed\u4e49\u5f15\u5bfc\u7684\u5c11\u6837\u672c\u793a\u4f8b\u9009\u62e9\u65b9\u6cd5\u6765\u63d0\u5347\u5b9e\u9645\u6548\u679c\u5e76\u964d\u4f4e\u6807\u6ce8\u6210\u672c\u3002", "result": "\u5728RareDis\u8bed\u6599\u5e93\u4e0a\u7684\u5b9e\u9a8c\u4e2d\uff0cGPT-4o\u4e0eBioClinicalBERT\u76f8\u6bd4\u8868\u73b0\u51fa\u7ade\u4e89\u6216\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u4efb\u52a1\u7ea7\u5fae\u8c03\u8fbe\u5230\u4e86\u65b0\u7684SOTA\u3002\u6210\u672c\u6548\u76ca\u5206\u6790\u8868\u660e\uff0c\u5c11\u6837\u672c\u63d0\u793a\u5728\u4f4etoken\u6d88\u8017\u4e0b\u6548\u679c\u663e\u8457\uff0cRAG\u589e\u76ca\u6709\u9650\u3002\u9519\u8bef\u5206\u7c7b\u63ed\u793a\u8fb9\u754c\u6f02\u79fb\u3001\u7c7b\u578b\u6df7\u6dc6\u7b49\u5e38\u89c1\u5931\u8d25\u6a21\u5f0f\uff0c\u63d0\u793a\u53ef\u901a\u8fc7\u540e\u5904\u7406\u53ca\u6df7\u5408\u4f18\u5316\u8fdb\u4e00\u6b65\u5b8c\u5584\u3002", "conclusion": "\u7ecf\u8fc7\u63d0\u793a\u4f18\u5316\u7684LLM\uff08\u5982GPT-4o\uff09\u5728\u7a00\u7f3a\u6807\u6ce8\u6570\u636e\u7684\u7f55\u89c1\u75c5\u751f\u7269\u533b\u5b66NER\u4efb\u52a1\u4e2d\uff0c\u53ef\u6210\u4e3a\u4f20\u7edf\u6709\u76d1\u7763\u6a21\u578b\u7684\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2508.09680", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.09680", "abs": "https://arxiv.org/abs/2508.09680", "authors": ["Orvila Sarker", "Mona Jamshaid", "M. Ali Babar"], "title": "Inclusive Employment Pathways: Career Success Factors for Autistic Individuals in Software Engineering", "comment": null, "summary": "Research has highlighted the valuable contributions of autistic individuals\nin the Information and Communication Technology (ICT) sector, particularly in\nareas such as software development, testing, and cybersecurity. Their strengths\nin information processing, attention to detail, innovative thinking, and\ncommitment to high-quality outcomes in the ICT domain are well-documented.\nHowever, despite their potential, autistic individuals often face barriers in\nSoftware Engineering (SE) roles due to a lack of personalised tools, complex\nwork environments, non-inclusive recruitment practices, limited co-worker\nsupport, challenging social dynamics and so on. Motivated by the ethical\nframework of the neurodiversity movement and the success of pioneering\ninitiatives like the Dandelion program, corporate Diversity, Equity, and\nInclusion (DEI) in the ICT sector has increasingly focused on autistic talent.\nThis movement fundamentally reframes challenges not as individual deficits but\nas failures of environments designed for a neurotypical majority. Despite this\nprogress, there is no synthesis of knowledge reporting the full pathway from\nsoftware engineering education through to sustainable workplace inclusion. To\naddress this, we conducted a Systematic Review of 30 studies and identified 18\nsuccess factors grouped into four thematic categories: (1) Software Engineering\nEducation, (2) Career and Employment Training, (3) Work Environment, and (4)\nTools and Assistive Technologies. Our findings offer evidence-based\nrecommendations for educational institutions, employers, organisations, and\ntool developers to enhance the inclusion of autistic individuals in SE. These\ninclude strategies for inclusive meeting and collaboration practices,\naccessible and structured work environments, clear role and responsibility\ndefinitions, and the provision of tailored workplace accommodations.", "AI": {"tldr": "\u672c\u8bba\u6587\u7cfb\u7edf\u56de\u987e\u4e86\u81ea\u95ed\u75c7\u4e2a\u4f53\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u6559\u80b2\u5230\u5c31\u4e1a\u6d41\u7a0b\uff0c\u5f52\u7eb3\u5e76\u63d0\u51fa18\u4e2a\u6709\u52a9\u4e8e\u5176\u6301\u7eed\u5305\u5bb9\u548c\u53d1\u5c55\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5e76\u9488\u5bf9\u6559\u80b2\u3001\u4f01\u4e1a\u7ba1\u7406\u548c\u5de5\u5177\u5f00\u53d1\u63d0\u51fa\u4e86\u5177\u4f53\u5b9e\u8bc1\u5efa\u8bae\uff0c\u4ee5\u6d88\u9664\u73b0\u6709\u969c\u788d\u5b9e\u73b0\u66f4\u5e7f\u6cdb\u7684\u795e\u7ecf\u591a\u6837\u6027\u5305\u5bb9\u3002", "motivation": "\u81ea\u95ed\u75c7\u4e2a\u4f53\u5728ICT\u9886\u57df\u8868\u73b0\u51fa\u72ec\u7279\u4f18\u52bf\uff0c\u4f46\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5c97\u4f4d\u4e0a\u4f9d\u7136\u9762\u4e34\u8bf8\u591a\u969c\u788d\uff0c\u5305\u62ec\u5de5\u5177\u7f3a\u4e4f\u3001\u590d\u6742\u7684\u5de5\u4f5c\u73af\u5883\u548c\u4e0d\u5305\u5bb9\u7684\u62db\u8058\u6d41\u7a0b\u7b49\uff0c\u4fc3\u4f7f\u7814\u7a76\u63a2\u7d22\u7cfb\u7edf\u6027\u7684\u652f\u6301\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u7efc\u8ff0\uff08Systematic Review\uff09\u5206\u6790\u4e8630\u9879\u76f8\u5173\u7814\u7a76\uff0c\u603b\u7ed3\u5f52\u7eb3\u51fa18\u4e2a\u6210\u529f\u56e0\u7d20\uff0c\u5e76\u6309\u6559\u80b2\u3001\u804c\u4e1a\u57f9\u8bad\u3001\u5de5\u4f5c\u73af\u5883\u3001\u8f85\u52a9\u5de5\u5177\u7b49\u56db\u5927\u4e3b\u9898\u5206\u7c7b\u3002", "result": "\u7814\u7a76\u660e\u786e\u4e86\u652f\u6301\u81ea\u95ed\u75c7\u4e2a\u4f53\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u6301\u7eed\u878d\u5165\u7684\u591a\u9879\u5173\u952e\u6210\u529f\u56e0\u7d20\uff0c\u5e76\u636e\u6b64\u4e3a\u76f8\u5173\u6559\u80b2\u673a\u6784\u3001\u96c7\u4e3b\u548c\u5de5\u5177\u5f00\u53d1\u8005\u63d0\u51fa\u4e86\u5b9e\u8bc1\u5316\u7684\u6539\u5584\u5efa\u8bae\uff0c\u5982\u5305\u5bb9\u6027\u534f\u4f5c\u65b9\u5f0f\u3001\u53ef\u53ca\u4e14\u7ed3\u6784\u5316\u7684\u5de5\u4f5c\u73af\u5883\u3001\u660e\u786e\u804c\u8d23\u5206\u5de5\u3001\u9488\u5bf9\u6027\u5de5\u4f5c\u652f\u6301\u7b49\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u73b0\u6709\u7814\u7a76\u7cfb\u7edf\u6027\u6574\u7406\uff0c\u8bba\u6587\u4e3a\u4fc3\u8fdb\u81ea\u95ed\u75c7\u4e2a\u4f53\u5728\u8f6f\u4ef6\u5de5\u7a0b\u884c\u4e1a\u957f\u671f\u5305\u5bb9\u4e0e\u53d1\u5c55\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u548c\u5177\u6709\u53ef\u64cd\u4f5c\u6027\u7684\u653f\u7b56\u5efa\u8bae\u3002"}}
{"id": "2508.09324", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09324", "abs": "https://arxiv.org/abs/2508.09324", "authors": ["Nikita Mehrotra", "Aayush Kumar", "Sumit Gulwani", "Arjun Radhakrishna", "Ashish Tiwari"], "title": "TEN: Table Explicitization, Neurosymbolically", "comment": null, "summary": "We present a neurosymbolic approach, TEN, for extracting tabular data from\nsemistructured input text. This task is particularly challenging for text input\nthat does not use special delimiters consistently to separate columns and rows.\nPurely neural approaches perform poorly due to hallucinations and their\ninability to enforce hard constraints. TEN uses Structural Decomposition\nprompting - a specialized chain-of-thought prompting approach - on a large\nlanguage model (LLM) to generate an initial table, and thereafter uses a\nsymbolic checker to evaluate not only the well-formedness of that table, but\nalso detect cases of hallucinations or forgetting. The output of the symbolic\nchecker is processed by a critique-LLM to generate guidance for fixing the\ntable, which is presented to the original LLM in a self-debug loop. Our\nextensive experiments demonstrate that TEN significantly outperforms purely\nneural baselines across multiple datasets and metrics, achieving significantly\nhigher exact match accuracy and substantially reduced hallucination rates. A\n21-participant user study further confirms that TEN's tables are rated\nsignificantly more accurate (mean score: 5.0 vs 4.3; p = 0.021), and are\nconsistently preferred for ease of verification and correction, with\nparticipants favoring our method in over 60% of the cases.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u795e\u7ecf\u7b26\u53f7\u6df7\u5408\u65b9\u6cd5TEN\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u94fe\u5f0f\u63d0\u793a\u3001\u5927\u6a21\u578b\u751f\u6210\u548c\u7b26\u53f7\u68c0\u67e5\u53cd\u9988\u5faa\u73af\uff0c\u5b9e\u73b0\u4ece\u534a\u7ed3\u6784\u5316\u6587\u672c\u9ad8\u6548\u63d0\u53d6\u8868\u683c\u6570\u636e\uff0c\u6548\u679c\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u660e\u663e\u4f18\u4e8e\u7eaf\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u3002", "motivation": "\u4ece\u534a\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u63d0\u53d6\u8868\u683c\u6570\u636e\u975e\u5e38\u5177\u6709\u6311\u6218\u6027\uff0c\u5c24\u5176\u662f\u5f53\u6587\u672c\u6ca1\u6709\u4e00\u81f4\u7684\u5206\u9694\u7b26\u65f6\u3002\u7eaf\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u5bb9\u6613\u51fa\u73b0\u5e7b\u89c9\u4e14\u65e0\u6cd5\u65bd\u52a0\u5f3a\u7ea6\u675f\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u63d0\u5347\u8868\u683c\u63d0\u53d6\u7684\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u6df7\u5408\u65b9\u6cd5TEN\u3002\u9996\u5148\u901a\u8fc7\u5927\u6a21\u578b\u8fdb\u884c\u7ed3\u6784\u5206\u89e3\u63d0\u793a\uff08chain-of-thought\u65b9\u5f0f\uff09\u751f\u6210\u521d\u6b65\u8868\u683c\uff0c\u7136\u540e\u7528\u7b26\u53f7\u68c0\u67e5\u5668\u8bc4\u4f30\u8868\u683c\u7684\u7ed3\u6784\u5408\u7406\u6027\u5e76\u68c0\u6d4b\u5e7b\u89c9\u6216\u9057\u6f0f\u3002\u68c0\u67e5\u5668\u7ed3\u679c\u7531\u201c\u6279\u5224\u578b\u5927\u6a21\u578b\u201d\u751f\u6210\u4fee\u6b63\u5efa\u8bae\uff0c\u5f62\u6210\u81ea\u6211\u8c03\u8bd5\u95ed\u73af\u3002", "result": "TEN\u5728\u591a\u6570\u636e\u96c6\u548c\u591a\u4e2a\u8bc4\u6d4b\u6307\u6807\u4e0a\u90fd\u5927\u5e45\u4f18\u4e8e\u7eaf\u795e\u7ecf\u7f51\u7edc\u57fa\u7ebf\uff0c\u5305\u62ec\u66f4\u9ad8\u7684\u7cbe\u786e\u5339\u914d\u51c6\u786e\u7387\u548c\u663e\u8457\u964d\u4f4e\u7684\u5e7b\u89c9\u7387\u3002\u7528\u6237\u7814\u7a76\u4e5f\u8868\u660eTEN\u751f\u6210\u7684\u8868\u683c\u66f4\u51c6\u786e\u3001\u66f4\u6613\u9a8c\u8bc1\u548c\u4fee\u6b63\uff0c\u53c2\u4e0e\u8005\u5728\u8d85\u8fc760%\u7684\u6848\u4f8b\u4e2d\u504f\u597dTEN\u65b9\u6cd5\u3002", "conclusion": "\u795e\u7ecf\u7b26\u53f7\u6df7\u5408\u7684TEN\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u4ece\u534a\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u63d0\u53d6\u8868\u683c\u6570\u636e\u7684\u51c6\u786e\u6027\u53ca\u53ef\u9760\u6027\uff0c\u4e14\u53d7\u5230\u7528\u6237\u9752\u7750\u3002"}}
{"id": "2508.09791", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09791", "abs": "https://arxiv.org/abs/2508.09791", "authors": ["Junxiao Han", "Yarong Wang", "Xiaodong Gu", "Cuiyun Gao", "Yao Wan", "Song Han", "David Lo", "Shuiguang Deng"], "title": "LibRec: Benchmarking Retrieval-Augmented LLMs for Library Migration Recommendations", "comment": null, "summary": "In this paper, we propose LibRec, a novel framework that integrates the\ncapabilities of LLMs with retrieval-augmented generation(RAG) techniques to\nautomate the recommendation of alternative libraries. The framework further\nemploys in-context learning to extract migration intents from commit messages\nto enhance the accuracy of its recommendations. To evaluate the effectiveness\nof LibRec, we introduce LibEval, a benchmark designed to assess the performance\nin the library migration recommendation task. LibEval comprises 2,888 migration\nrecords associated with 2,368 libraries extracted from 2,324 Python\nrepositories. Each migration record captures source-target library pairs, along\nwith their corresponding migration intents and intent types. Based on LibEval,\nwe evaluated the effectiveness of ten popular LLMs within our framework,\nconducted an ablation study to examine the contributions of key components\nwithin our framework, explored the impact of various prompt strategies on the\nframework's performance, assessed its effectiveness across various intent\ntypes, and performed detailed failure case analyses.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLibRec\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5927\u6a21\u578b\u548c\u68c0\u7d22\u589e\u5f3a\u6280\u672f\u81ea\u52a8\u63a8\u8350Python\u5e93\u66ff\u4ee3\u65b9\u6848\uff0c\u5e76\u5229\u7528commit\u6d88\u606f\u6316\u6398\u8fc1\u79fb\u610f\u56fe\uff0c\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u6db5\u76d6\u591a\u6a21\u578b\u548c\u591a\u7b56\u7565\u8bc4\u4f30\uff0c\u6548\u679c\u663e\u8457\uff0c\u540c\u65f6\u53d1\u5e03LibEval\u65b0\u57fa\u51c6\u52a9\u529b\u540e\u7eed\u7814\u7a76\u3002", "motivation": "\u76ee\u524d\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\uff0c\u5e93\u8fc1\u79fb\u7ecf\u5e38\u51fa\u73b0\uff0c\u5f00\u53d1\u8005\u9700\u8981\u5728\u8fc1\u79fb\u8fc7\u7a0b\u4e2d\u83b7\u5f97\u5408\u9002\u7684\u66ff\u4ee3\u5e93\u63a8\u8350\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u81ea\u52a8\u8bc6\u522b\u548c\u63a8\u8350\u65b9\u9762\u51c6\u786e\u6027\u4e0d\u9ad8\u3002", "method": "\u63d0\u51faLibRec\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\uff0c\u81ea\u52a8\u63a8\u8350\u66ff\u4ee3\u5e93\uff0c\u5e76\u501f\u52a9\u4e0a\u4e0b\u6587\u5b66\u4e60\u4ececommit\u6d88\u606f\u4e2d\u62bd\u53d6\u8fc1\u79fb\u610f\u56fe\uff0c\u63d0\u9ad8\u63a8\u8350\u51c6\u786e\u6027\u3002\u5f15\u5165LibEval\u57fa\u51c6\uff0c\u5305\u542b2888\u6761\u8fc1\u79fb\u8bb0\u5f55\u7528\u4e8e\u8bc4\u4f30\u3002", "result": "\u5728LibEval\u6570\u636e\u96c6\u4e0a\uff0c\u8bc4\u4f30\u4e8610\u79cd\u6d41\u884cLLM\u5728\u6846\u67b6\u4e2d\u7684\u8868\u73b0\uff0c\u8fdb\u884c\u4e86\u6d88\u878d\u5b9e\u9a8c\uff0c\u5206\u6790\u4e86\u5173\u952e\u7ec4\u4ef6\u8d21\u732e\uff0c\u63a2\u8ba8\u4e86\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u9488\u5bf9\u4e0d\u540c\u610f\u56fe\u7c7b\u578b\u8bc4\u4f30\u4e86\u6548\u679c\uff0c\u5e76\u8be6\u7ec6\u5206\u6790\u4e86\u5931\u8d25\u6848\u4f8b\u3002", "conclusion": "LibRec\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u81ea\u52a8\u5e93\u63a8\u8350\u7684\u51c6\u786e\u6027\u3002\u5229\u7528\u5927\u6a21\u578b\u4e0eRAG\u6280\u672f\u7ed3\u5408\uff0c\u4ee5\u53ca\u5bf9\u8fc1\u79fb\u610f\u56fe\u7684\u6df1\u5165\u6316\u6398\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u8fc1\u79fb\u63a8\u8350\u4efb\u52a1\u7684\u6027\u80fd\u3002\u63d0\u51fa\u7684LibEval\u4e5f\u4e3a\u540e\u7eed\u8bc4\u6d4b\u63d0\u4f9b\u4e86\u65b0\u57fa\u51c6\u3002"}}
{"id": "2508.09337", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09337", "abs": "https://arxiv.org/abs/2508.09337", "authors": ["Gideon Vos", "Maryam Ebrahimpour", "Liza van Eijk", "Zoltan Sarnyai", "Mostafa Rahimi Azghadi"], "title": "Decoding Neural Emotion Patterns through Natural Language Processing Embeddings", "comment": "26 pages, 9 figures", "summary": "Understanding how emotional expression in language relates to brain function\nis a challenge in computational neuroscience and affective computing.\nTraditional neuroimaging is costly and lab-bound, but abundant digital text\noffers new avenues for emotion-brain mapping. Prior work has largely examined\nneuroimaging-based emotion localization or computational text analysis\nseparately, with little integration. We propose a computational framework that\nmaps textual emotional content to anatomically defined brain regions without\nrequiring neuroimaging. Using OpenAI's text-embedding-ada-002, we generate\nhigh-dimensional semantic representations, apply dimensionality reduction and\nclustering to identify emotional groups, and map them to 18 brain regions\nlinked to emotional processing. Three experiments were conducted: i) analyzing\nconversational data from healthy vs. depressed subjects (DIAC-WOZ dataset) to\ncompare mapping patterns, ii) applying the method to the GoEmotions dataset and\niii) comparing human-written text with large language model (LLM) responses to\nassess differences in inferred brain activation. Emotional intensity was scored\nvia lexical analysis. Results showed neuroanatomically plausible mappings with\nhigh spatial specificity. Depressed subjects exhibited greater limbic\nengagement tied to negative affect. Discrete emotions were successfully\ndifferentiated. LLM-generated text matched humans in basic emotion distribution\nbut lacked nuanced activation in empathy and self-referential regions (medial\nprefrontal and posterior cingulate cortex). This cost-effective, scalable\napproach enables large-scale analysis of naturalistic language, distinguishes\nbetween clinical populations, and offers a brain-based benchmark for evaluating\nAI emotional expression.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6587\u672c\u5206\u6790\u4e0e\u8111\u533a\u6620\u5c04\u7684\u65b0\u65b9\u6cd5\uff0c\u65e0\u9700\u795e\u7ecf\u5f71\u50cf\uff0c\u80fd\u4ece\u6587\u672c\u63a8\u65ad\u5927\u8111\u60c5\u611f\u6fc0\u6d3b\u6a21\u5f0f\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u79d1\u5b66\u6709\u6548\uff0c\u53ef\u533a\u5206\u5065\u5eb7\u4e0e\u6291\u90c1\u7fa4\u4f53\u3001\u5927\u6a21\u578b\u4e0e\u4eba\u7c7b\u5728\u60c5\u611f\u8868\u8fbe\u4e0a\u7684\u5dee\u5f02\u3002\u8be5\u6846\u67b6\u4e3a\u5927\u89c4\u6a21\u3001\u591a\u60c5\u611f\u7ef4\u5ea6\u7684\u8111\u529f\u80fd\u5206\u6790\u53caAI\u60c5\u611f\u8868\u8fbe\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002", "motivation": "\u5728\u8ba1\u7b97\u795e\u7ecf\u79d1\u5b66\u548c\u60c5\u611f\u8ba1\u7b97\u9886\u57df\uff0c\u7406\u89e3\u8bed\u8a00\u4e2d\u7684\u60c5\u611f\u8868\u8fbe\u5982\u4f55\u4e0e\u5927\u8111\u529f\u80fd\u76f8\u5173\u662f\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684\u795e\u7ecf\u5f71\u50cf\u6280\u672f\u6602\u8d35\u4e14\u53d7\u9650\u4e8e\u5b9e\u9a8c\u5ba4\u73af\u5883\uff0c\u800c\u4e30\u5bcc\u7684\u6570\u5b57\u6587\u672c\u4e3a\u60c5\u611f-\u5927\u8111\u5173\u8054\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u6e20\u9053\u3002\u6b64\u524d\u7684\u7814\u7a76\u5e38\u5c06\u8111\u5f71\u50cf\u60c5\u611f\u5b9a\u4f4d\u4e0e\u6587\u672c\u5206\u6790\u5206\u5f00\u5904\u7406\uff0c\u7f3a\u4e4f\u4e24\u8005\u7684\u6574\u5408\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba1\u7b97\u6846\u67b6\uff0c\u65e0\u9700\u795e\u7ecf\u5f71\u50cf\uff0c\u76f4\u63a5\u5c06\u6587\u672c\u4e2d\u7684\u60c5\u611f\u5185\u5bb9\u6620\u5c04\u5230\u89e3\u5256\u5b66\u5b9a\u4e49\u7684\u5927\u8111\u533a\u57df\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a\u4f7f\u7528OpenAI\u7684text-embedding-ada-002\u8fdb\u884c\u6587\u672c\u5d4c\u5165\u751f\u6210\u9ad8\u7ef4\u8bed\u4e49\u8868\u793a\uff0c\u901a\u8fc7\u964d\u7ef4\u4e0e\u805a\u7c7b\u8bc6\u522b\u60c5\u611f\u7c7b\u522b\uff0c\u5e76\u6620\u5c04\u523018\u4e2a\u4e0e\u60c5\u611f\u52a0\u5de5\u76f8\u5173\u7684\u5927\u8111\u533a\u57df\u3002\u5b9e\u9a8c\u5305\u62ec\uff1a\u5206\u6790\u5065\u5eb7\u4e0e\u6291\u90c1\u88ab\u8bd5\u7684\u5bf9\u8bdd\u6570\u636e\u4ee5\u6bd4\u8f83\u6620\u5c04\u6a21\u5f0f\u3001\u5728GoEmotions\u6570\u636e\u96c6\u4e0a\u5e94\u7528\u8be5\u65b9\u6cd5\uff0c\u4ee5\u53ca\u6bd4\u8f83\u4eba\u7c7b\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u672c\u63a8\u65ad\u7684\u5927\u8111\u6fc0\u6d3b\u5dee\u5f02\u3002\u60c5\u611f\u5f3a\u5ea6\u901a\u8fc7\u8bcd\u6c47\u5206\u6790\u8bc4\u5206\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u795e\u7ecf\u89e3\u5256\u5b66\u4e0a\u5408\u7406\u4e14\u7a7a\u95f4\u7279\u5f02\u6027\u9ad8\u7684\u6620\u5c04\u3002\u6291\u90c1\u88ab\u8bd5\u8868\u73b0\u51fa\u4e0e\u8d1f\u9762\u60c5\u611f\u76f8\u5173\u7684\u8fb9\u7f18\u7cfb\u7edf\u66f4\u9ad8\u6fc0\u6d3b\u3002\u79bb\u6563\u60c5\u611f\u80fd\u88ab\u6210\u529f\u533a\u5206\u3002\u5927\u6a21\u578b\u751f\u6210\u6587\u672c\u5728\u57fa\u7840\u60c5\u611f\u5206\u5e03\u4e0a\u4e0e\u4eba\u7c7b\u7c7b\u4f3c\uff0c\u4f46\u5728\u540c\u7406\u5fc3\u548c\u81ea\u6211\u76f8\u5173\u533a\u57df\uff08\u5185\u4fa7\u524d\u989d\u53f6\u53ca\u540e\u6263\u5e26\u76ae\u5c42\uff09\u7684\u6fc0\u6d3b\u65b9\u9762\u4e0d\u53ca\u4eba\u7c7b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u4f4e\u6210\u672c\u548c\u53ef\u6269\u5c55\u6027\u7684\u4f18\u70b9\uff0c\u80fd\u591f\u5bf9\u81ea\u7136\u8bed\u8a00\u8fdb\u884c\u5927\u89c4\u6a21\u8111\u533a\u5206\u6790\u3001\u8fa8\u522b\u4e34\u5e8a\u4eba\u7fa4\u5dee\u5f02\uff0c\u5e76\u4e3a\u8bc4\u4f30\u4eba\u5de5\u667a\u80fd\u7684\u60c5\u611f\u8868\u8fbe\u529b\u63d0\u4f9b\u8111\u533a\u57fa\u51c6\u3002"}}
{"id": "2508.09828", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.09828", "abs": "https://arxiv.org/abs/2508.09828", "authors": ["Sebastiano Antonio Piccolo"], "title": "Fast and Accurate Heuristics for Bus-Factor Estimation", "comment": null, "summary": "The bus-factor is a critical risk indicator that quantifies how many key\ncontributors a project can afford to lose before core knowledge or\nfunctionality is compromised. Despite its practical importance, accurately\ncomputing the bus-factor is NP-Hard under established formalizations, making\nscalable analysis infeasible for large software systems.\n  In this paper, we model software projects as bipartite graphs of developers\nand tasks and propose two novel approximation heuristics, Minimum Coverage and\nMaximum Coverage, based on iterative graph peeling, for two influential\nbus-factor formalizations. Our methods significantly outperform the widely\nadopted degree-based heuristic, which we show can yield severely inflated\nestimates.\n  We conduct a comprehensive empirical evaluation on over $1\\,000$ synthetic\npower-law graphs and demonstrate that our heuristics provide tighter estimates\nwhile scaling to graphs with millions of nodes and edges in minutes. Our\nresults reveal that the proposed heuristics are not only more accurate but also\nrobust to structural variations in developer-task assignment graph. We release\nour implementation as open-source software to support future research and\npractical adoption.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u9879\u76ee\u5173\u952e\u6210\u5458\u6d41\u5931\u98ce\u9669\u7684 bus-factor \u8bc4\u4f30\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u65b0\u578b\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u5728\u5927\u89c4\u6a21\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u8d8a\uff0c\u5e76\u5df2\u5f00\u6e90\u3002", "motivation": "bus-factor \u662f\u8861\u91cf\u9879\u76ee\u5173\u952e\u6210\u5458\u6d41\u5931\u98ce\u9669\u7684\u91cd\u8981\u6307\u6807\uff0c\u4f46\u76ee\u524d\u5bf9\u4e8e\u5176\u8ba1\u7b97\u95ee\u9898\u5c5e\u4e8e NP-Hard\uff0c\u96be\u4ee5\u9ad8\u6548\u5206\u6790\u5927\u89c4\u6a21\u9879\u76ee\u3002", "method": "\u5c06\u8f6f\u4ef6\u9879\u76ee\u62bd\u8c61\u4e3a\u5f00\u53d1\u8005\u4e0e\u4efb\u52a1\u7684\u4e8c\u5206\u56fe\uff0c\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u8fed\u4ee3\u56fe\u5265\u79bb\u7684\u65b0\u8fd1\u4f3c\u542f\u53d1\u6cd5\uff1a\u6700\u5c0f\u8986\u76d6\uff08Minimum Coverage\uff09\u548c\u6700\u5927\u8986\u76d6\uff08Maximum Coverage\uff09\uff0c\u7528\u4e8e\u4e3b\u6d41 bus-factor \u5f62\u5f0f\u5316\u5b9a\u4e49\u3002", "result": "\u5728\u8d85\u8fc7 1000 \u4e2a\u5408\u6210\u5e42\u5f8b\u56fe\u4e0a\u7684\u5b9e\u8bc1\u5206\u6790\u8868\u660e\uff0c\u4e24\u79cd\u65b0\u542f\u53d1\u6cd5\u4f18\u4e8e\u5e38\u7528\u7684\u57fa\u4e8e\u8282\u70b9\u5ea6\u6570\u7684\u65b9\u6cd5\uff0c\u4f30\u7b97\u66f4\u51c6\u786e\u4e14\u53ef\u6269\u5c55\u81f3\u767e\u4e07\u7ea7\u8282\u70b9\u4e0e\u8fb9\u7684\u56fe\uff0c\u5728\u6570\u5206\u949f\u5185\u5b8c\u6210\u8ba1\u7b97\u3002\u540c\u65f6\uff0c\u8fd9\u4e9b\u542f\u53d1\u6cd5\u5bf9\u5f00\u53d1\u8005\u4e0e\u4efb\u52a1\u5206\u914d\u7ed3\u6784\u53d8\u52a8\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u8fd1\u4f3c\u542f\u53d1\u6cd5\u80fd\u9ad8\u6548\u3001\u51c6\u786e\u5730\u4f30\u7b97\u5927\u578b\u8f6f\u4ef6\u7cfb\u7edf\u7684 bus-factor\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5df2\u5f00\u6e90\uff0c\u4fbf\u4e8e\u540e\u7eed\u7814\u7a76\u4e0e\u5b9e\u9645\u91c7\u7528\u3002"}}
{"id": "2508.09349", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09349", "abs": "https://arxiv.org/abs/2508.09349", "authors": ["Cathy Speed", "Ahmed A. Metwally"], "title": "The Human-AI Hybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in Complex Domains", "comment": null, "summary": "Expert consensus plays a critical role in domains where evidence is complex,\nconflicting, or insufficient for direct prescription. Traditional methods, such\nas Delphi studies, consensus conferences, and systematic guideline synthesis,\noffer structure but face limitations including high panel burden, interpretive\noversimplification, and suppression of conditional nuance. These challenges are\nnow exacerbated by information overload, fragmentation of the evidence base,\nand increasing reliance on publicly available sources that lack expert\nfiltering. This study introduces and evaluates a Human-AI Hybrid Delphi\n(HAH-Delphi) framework designed to augment expert consensus development by\nintegrating a generative AI model (Gemini 2.5 Pro), small panels of senior\nhuman experts, and structured facilitation. The HAH-Delphi was tested in three\nphases: retrospective replication, prospective comparison, and applied\ndeployment in two applied domains (endurance training and resistance and mixed\ncardio/strength training). The AI replicated 95% of published expert consensus\nconclusions in Phase I and showed 95% directional agreement with senior human\nexperts in Phase II, though it lacked experiential and pragmatic nuance. In\nPhase III, compact panels of six senior experts achieved >90% consensus\ncoverage and reached thematic saturation before the final participant. The AI\nprovided consistent, literature-grounded scaffolding that supported divergence\nresolution and accelerated saturation. The HAH-Delphi framework offers a\nflexible, scalable approach for generating high-quality, context-sensitive\nconsensus. Its successful application across health, coaching, and performance\nscience confirms its methodological robustness and supports its use as a\nfoundation for generating conditional, personalised guidance and published\nconsensus frameworks at scale.", "AI": {"tldr": "\u63d0\u51fa\u4e86HAH-Delphi\u4eba\u673a\u6df7\u5408\u5171\u8bc6\u65b9\u6cd5\uff0c\u7ed3\u5408AI\u548c\u5c0f\u578b\u4e13\u5bb6\u7ec4\uff0c\u80fd\u9ad8\u6548\u51c6\u786e\u8fbe\u6210\u9ad8\u8d28\u91cf\u5171\u8bc6\uff0c\u5e94\u7528\u4e8e\u5065\u5eb7\u548c\u8fd0\u52a8\u7b49\u9886\u57df\u8868\u73b0\u51fa\u826f\u597d\u53ef\u6269\u5c55\u6027\uff0c\u53ef\u4e3a\u672a\u6765\u4e2a\u6027\u5316\u548c\u6761\u4ef6\u5316\u6307\u5bfc\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002", "motivation": "\u5728\u8bc1\u636e\u590d\u6742\u3001\u51b2\u7a81\u6216\u4e0d\u8db3\u4ee5\u5f97\u51fa\u660e\u786e\u7ed3\u8bba\u7684\u9886\u57df\uff0c\u4f20\u7edf\u4e13\u5bb6\u5171\u8bc6\u65b9\u6cd5\u5b58\u5728\u9ad8\u8d1f\u62c5\u3001\u8fc7\u5ea6\u7b80\u5316\u548c\u96be\u4ee5\u5904\u7406\u6761\u4ef6\u7ec6\u8282\u7b49\u95ee\u9898\uff0c\u4e14\u53d7\u5230\u4fe1\u606f\u8fc7\u8f7d\u548c\u8bc1\u636e\u788e\u7247\u5316\u7684\u6311\u6218\uff0c\u56e0\u6b64\u4e9f\u9700\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u53ef\u9760\u4e14\u7ec6\u81f4\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u4e13\u5bb6\u5171\u8bc6\u5efa\u7acb\u7684\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u4e00\u79cd\u201c\u4eba\u673a\u6df7\u5408\u5fb7\u5c14\u83f2\u6cd5\uff08HAH-Delphi\uff09\u201d\uff0c\u7ed3\u5408\u4e86\u751f\u6210\u5f0fAI\u6a21\u578b\uff08Gemini 2.5 Pro\uff09\u3001\u5c11\u91cf\u8d44\u6df1\u4eba\u7c7b\u4e13\u5bb6\u548c\u7ed3\u6784\u5316\u5f15\u5bfc\uff0c\u5206\u4e09\u4e2a\u9636\u6bb5\u8fdb\u884c\u6d4b\u8bd5\uff1a1\uff09\u56de\u987e\u6027\u590d\u73b0\u5df2\u53d1\u5e03\u5171\u8bc6\uff1b2\uff09\u524d\u77bb\u6027\u4e0e\u4e13\u5bb6\u6bd4\u8f83\uff1b3\uff09\u5728\u4e24\u5927\u9886\u57df\u7684\u5b9e\u9645\u90e8\u7f72\u548c\u5e94\u7528\u3002", "result": "AI\u5728\u7b2c\u4e00\u9636\u6bb5\u590d\u73b0\u4e8695%\u7684\u5df2\u53d1\u8868\u4e13\u5bb6\u5171\u8bc6\u7ed3\u8bba\uff0c\u5728\u7b2c\u4e8c\u9636\u6bb5\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u7684\u89c2\u70b9\u4e00\u81f4\u7387\u8fbe95%\uff0c\u4f46\u672a\u80fd\u8986\u76d6\u4e13\u5bb6\u7684\u7ecf\u9a8c\u6027\u548c\u5b9e\u9645\u64cd\u4f5c\u7ec6\u8282\u3002\u5728\u7b2c\u4e09\u9636\u6bb5\uff0c\u5c0f\u578b\u4e13\u5bb6\u7ec4\u5feb\u901f\u5b9e\u73b0\u4e8690%\u4ee5\u4e0a\u7684\u5171\u8bc6\u8986\u76d6\u548c\u4e3b\u9898\u9971\u548c\u3002AI\u4e3a\u5171\u8bc6\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u7a33\u5b9a\u3001\u57fa\u4e8e\u6587\u732e\u7684\u6846\u67b6\uff0c\u52a0\u901f\u5171\u8bc6\u8fbe\u6210\u548c\u5206\u6b67\u89e3\u51b3\u3002", "conclusion": "HAH-Delphi\u6846\u67b6\u53ef\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u5730\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u5177\u60c5\u5883\u5173\u8054\u6027\u7684\u5171\u8bc6\u6210\u679c\uff0c\u5176\u65b9\u6cd5\u5b66\u4e0a\u7684\u7a33\u5065\u6027\u5df2\u5728\u5065\u5eb7\u3001\u6559\u7ec3\u548c\u8fd0\u52a8\u79d1\u5b66\u7b49\u9886\u57df\u5f97\u5230\u9a8c\u8bc1\uff0c\u6709\u671b\u6210\u4e3a\u5927\u89c4\u6a21\u751f\u6210\u4e2a\u6027\u5316\u3001\u6761\u4ef6\u5316\u6307\u5bfc\u610f\u89c1\u548c\u5171\u8bc6\u6807\u51c6\u7684\u57fa\u7840\u3002"}}
{"id": "2508.09832", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09832", "abs": "https://arxiv.org/abs/2508.09832", "authors": ["Linh Nguyen", "Chunhua Liu", "Hong Yi Lin", "Patanamon Thongtanunam"], "title": "Exploring the Potential of Large Language Models in Fine-Grained Review Comment Classification", "comment": "Accepted at 2025 IEEE International Conference on Source Code\n  Analysis & Manipulation (SCAM)", "summary": "Code review is a crucial practice in software development. As code review\nnowadays is lightweight, various issues can be identified, and sometimes, they\ncan be trivial. Research has investigated automated approaches to classify\nreview comments to gauge the effectiveness of code reviews. However, previous\nstudies have primarily relied on supervised machine learning, which requires\nextensive manual annotation to train the models effectively. To address this\nlimitation, we explore the potential of using Large Language Models (LLMs) to\nclassify code review comments. We assess the performance of LLMs to classify 17\ncategories of code review comments. Our results show that LLMs can classify\ncode review comments, outperforming the state-of-the-art approach using a\ntrained deep learning model. In particular, LLMs achieve better accuracy in\nclassifying the five most useful categories, which the state-of-the-art\napproach struggles with due to low training examples. Rather than relying\nsolely on a specific small training data distribution, our results show that\nLLMs provide balanced performance across high- and low-frequency categories.\nThese results suggest that the LLMs could offer a scalable solution for code\nreview analytics to improve the effectiveness of the code review process.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5206\u7c7b\u4ee3\u7801\u8bc4\u5ba1\u8bc4\u8bba\uff0c\u8f83\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u8868\u73b0\u66f4\u4f73\uff0c\u5c24\u5176\u5728\u9ad8\u4f4e\u9891\u7c7b\u522b\u4e0a\u5747\u6709\u7a33\u5b9a\u51c6\u786e\u6027\uff0c\u6709\u671b\u63d0\u5347\u4ee3\u7801\u8bc4\u5ba1\u7684\u81ea\u52a8\u5316\u548c\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u4ee3\u7801\u8bc4\u5ba1\u8bc4\u8bba\u5206\u7c7b\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e8e\u76d1\u7763\u5f0f\u673a\u5668\u5b66\u4e60\uff0c\u8bad\u7ec3\u6a21\u578b\u9700\u8981\u5927\u91cf\u4eba\u5de5\u6807\u6ce8\uff0c\u6210\u672c\u9ad8\u4e14\u4f9d\u8d56\u6807\u6ce8\u6570\u636e\u5206\u5e03\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5bf9\u4ee3\u7801\u8bc4\u5ba1\u8bc4\u8bba\u8fdb\u884c\u81ea\u52a8\u5206\u7c7b\uff0c\u5e76\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u6027\u80fd\u5bf9\u6bd4\uff0c\u6d89\u53ca\u8bc4\u8bba\u768417\u4e2a\u7c7b\u522b\u3002", "result": "LLM\u5728\u4ee3\u7801\u8bc4\u5ba1\u8bc4\u8bba\u5206\u7c7b\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u8d8a\uff0c\u5c24\u5176\u5728\u8bad\u7ec3\u6837\u672c\u8f83\u5c11\u7684\u6709\u7528\u7c7b\u522b\u4e0a\u51c6\u786e\u7387\u66f4\u9ad8\uff0c\u8868\u73b0\u8f83\u4e3a\u5747\u8861\uff0c\u65e0\u9700\u4f9d\u8d56\u7279\u5b9a\u5c0f\u6837\u672c\u5206\u5e03\u3002", "conclusion": "LLM\u53ef\u4e3a\u4ee3\u7801\u8bc4\u5ba1\u5206\u6790\u63d0\u4f9b\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u4ee3\u7801\u8bc4\u5ba1\u6d41\u7a0b\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2508.09350", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09350", "abs": "https://arxiv.org/abs/2508.09350", "authors": ["Ju-Chieh Chou", "Jiawei Zhou", "Karen Livescu"], "title": "Flow-SLM: Joint Learning of Linguistic and Acoustic Information for Spoken Language Modeling", "comment": "Accepted to ASRU 2025", "summary": "Textless spoken language models (SLMs) are generative models of speech that\ndo not rely on text supervision. Most textless SLMs learn to predict the next\nsemantic token, a discrete representation of linguistic content, and rely on a\nseparate vocoder to add acoustic information to the generated speech. Such\nmodels have no access to acoustic context and no built-in control over acoustic\ndetails. In this work, we propose to jointly model linguistic and acoustic\ninformation by generating semantic tokens and a continuous real-valued\nrepresentation of the acoustic frame. We use a flow-matching objective to\npredict the continuous vector conditioned on the semantic tokens. We study the\ndesign space of this approach and find that predicting multiple future semantic\ntokens helps preserve linguistic information. Our approach achieves comparable\nperformance to existing models in terms of linguistic likelihood benchmarks,\nwhile providing better acoustic detail in prompted generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u540c\u65f6\u751f\u6210\u8bed\u4e49\u4e0e\u58f0\u5b66\u4fe1\u606f\u7684\u65e0\u6587\u672c\u8bed\u97f3\u6a21\u578b\uff0c\u901a\u8fc7flow-matching\u65b9\u6cd5\u9884\u6d4b\u8fde\u7eed\u58f0\u5b66\u5411\u91cf\uff0c\u5728\u4fdd\u7559\u8bed\u8a00\u5185\u5bb9\u7684\u540c\u65f6\u63d0\u5347\u4e86\u8bed\u97f3\u751f\u6210\u7684\u58f0\u5b66\u7ec6\u8282\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\u5728\u58f0\u5b66\u8d28\u91cf\u4e0a\u5177\u6709\u4f18\u52bf\u3002", "motivation": "\u76ee\u524d\u7684\u65e0\u6587\u672c\u8bed\u97f3\u6a21\u578b\uff08SLMs\uff09\u4f9d\u8d56\u4e8e\u9884\u6d4b\u79bb\u6563\u8bed\u4e49\u6807\u8bb0\uff0c\u5e76\u501f\u52a9\u72ec\u7acb\u7684vocoder\u6dfb\u52a0\u8bed\u97f3\u58f0\u5b66\u4fe1\u606f\uff0c\u56e0\u6b64\u7f3a\u4e4f\u5bf9\u58f0\u5b66\u7ec6\u8282\u7684\u63a7\u5236\u4e0e\u4e0a\u4e0b\u6587\u4fe1\u606f\u5229\u7528\u3002\u672c\u5de5\u4f5c\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u5c40\u9650\u3002", "method": "\u63d0\u51fa\u8054\u5408\u5efa\u6a21\u8bed\u4e49\u4e0e\u58f0\u5b66\u4fe1\u606f\u7684\u65b9\u6cd5\uff1a\u540c\u65f6\u751f\u6210\u8bed\u4e49\u6807\u8bb0\u548c\u8fde\u7eed\u5b9e\u503c\u7684\u58f0\u5b66\u5e27\u8868\u793a\uff0c\u5e76\u91c7\u7528flow-matching\u76ee\u6807\u51fd\u6570\uff0c\u5728\u8bed\u4e49\u6807\u8bb0\u6761\u4ef6\u4e0b\u9884\u6d4b\u8fde\u7eed\u58f0\u5b66\u5411\u91cf\u3002\u8fd8\u7814\u7a76\u4e86\u591a\u4e2a\u672a\u6765\u8bed\u4e49\u6807\u8bb0\u9884\u6d4b\u5bf9\u6a21\u578b\u6548\u679c\u7684\u5f71\u54cd\u3002", "result": "\u8054\u5408\u5efa\u6a21\u65b9\u6cd5\u5728\u8bed\u8a00\u57fa\u51c6\u8868\u73b0\u53ef\u4e0e\u73b0\u6709\u6a21\u578b\u5ab2\u7f8e\uff0c\u540c\u65f6\u5728\u751f\u6210\u8bed\u97f3\u65f6\u80fd\u591f\u66f4\u597d\u5730\u8fd8\u539f\u58f0\u5b66\u7ec6\u8282\u3002", "conclusion": "\u8054\u5408\u9884\u6d4b\u8bed\u4e49\u4e0e\u58f0\u5b66\u4fe1\u606f\u7684\u65b0\u65b9\u6cd5\u65e2\u4fdd\u6301\u4e86\u539f\u6709\u8bed\u8a00\u8868\u73b0\u80fd\u529b\uff0c\u53c8\u660e\u663e\u63d0\u5347\u4e86\u58f0\u5b66\u751f\u6210\u8d28\u91cf\uff0c\u6269\u5c55\u4e86\u6587\u672c\u65e0\u5173\u8bed\u97f3\u6a21\u578b\u7684\u80fd\u529b\u3002"}}
{"id": "2508.09875", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.09875", "abs": "https://arxiv.org/abs/2508.09875", "authors": ["Jinbao Chen", "Boyao Ding", "Yu Zhang", "Qingwei Li", "Fugen Tang"], "title": "An Empirical Study of CGO Usage in Go Projects -- Distribution, Purposes, Patterns and Critical Issues", "comment": "Accepted for publication in The Journal of Systems and Software", "summary": "Multilingual software development integrates multiple languages into a single\napplication, with the Foreign Function Interface (FFI) enabling seamless\ninteraction. While FFI boosts efficiency and extensibility, it also introduces\nrisks. Existing studies focus on FFIs in languages like Python and Java,\nneglecting CGO, the emerging FFI in Go, which poses unique risks.\n  To address these concerns, we conduct an empirical study of CGO usage across\n920 open-source Go projects. Our study aims to reveal the distribution,\npatterns, purposes, and critical issues associated with CGO, offering insights\nfor developers and the Go team. We develop CGOAnalyzer, a tool to efficiently\nidentify and quantify CGO-related features. Our findings reveal that: (1) 11.3%\nof analyzed Go projects utilize CGO, with usage concentrated in a subset of\nprojects; (2) CGO serves 4 primary purposes, including system-level\ninteractions and performance optimizations, with 15 distinct usage patterns\nobserved; (3) 19 types of CGO-related issues exist, including one critical\nissue involving unnecessary pointer checks that pose risks of runtime crashes\ndue to limitations in the current Go compilation toolchain; (4) a temporary\nsolution reduces unnecessary pointer checks, mitigating crash risks, and (5) we\nsubmitted a proposal to improve the Go toolchain for a permanent fix, which has\nbeen grouped within an accepted proposal for future resolution. Our findings\nprovide valuable insights for developers and the Go team, enhancing development\nefficiency and reliability while improving the robustness of the Go toolchain.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5927\u89c4\u6a21\u5206\u6790\u4e86Go\u8bed\u8a00\u7684CGO\u7528\u6cd5\u53ca\u5176\u98ce\u9669\uff0c\u53d1\u73b0\u4e86\u96c6\u4e2d\u4f7f\u7528\u573a\u666f\u53ca\u591a\u79cd\u95ee\u9898\uff0c\u63d0\u51fa\u4e34\u65f6\u548c\u6c38\u4e45\u6539\u8fdb\u65b9\u6848\uff0c\u6709\u6548\u63d0\u5347\u5f00\u53d1\u5b89\u5168\u6027\u548c\u5de5\u5177\u94fe\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u5173\u4e8e\u591a\u8bed\u8a00\u5f00\u53d1\u7684FFI\u7814\u7a76\u591a\u96c6\u4e2d\u4e8ePython\u548cJava\uff0c\u5bf9Go\u8bed\u8a00\u4e2d\u7684CGO\u5173\u6ce8\u751a\u5c11\uff0c\u800cCGO\u4f5c\u4e3a\u65b0\u5174\u7684FFI\uff0c\u5b58\u5728\u72ec\u7279\u7684\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u5bf9920\u4e2a\u5f00\u6e90Go\u9879\u76ee\u4e2d\u7684CGO\u4f7f\u7528\u60c5\u51b5\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u5f00\u53d1\u4e86CGOAnalyzer\u5de5\u5177\u5bf9CGO\u76f8\u5173\u7279\u5f81\u8fdb\u884c\u9ad8\u6548\u8bc6\u522b\u548c\u91cf\u5316\u5206\u6790\u3002", "result": "1\uff09\u670911.3%\u7684Go\u9879\u76ee\u4f7f\u7528CGO\uff0c\u4e14\u4e3b\u8981\u96c6\u4e2d\u5728\u90e8\u5206\u9879\u76ee\u4e2d\uff1b2\uff09CGO\u4e3b\u8981\u6709\u56db\u7c7b\u7528\u9014\uff0c\u89c2\u5bdf\u523015\u79cd\u4f7f\u7528\u6a21\u5f0f\uff1b3\uff09\u53d1\u73b0\u4e8619\u7c7bCGO\u76f8\u5173\u95ee\u9898\uff0c\u5305\u62ec\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u5373\u4e0d\u5fc5\u8981\u7684\u6307\u9488\u68c0\u67e5\u4f1a\u56e0Go\u7f16\u8bd1\u5de5\u5177\u94fe\u9650\u5236\u9020\u6210\u8fd0\u884c\u65f6\u5d29\u6e83\u98ce\u9669\uff1b4\uff09\u63d0\u4f9b\u4e86\u4e34\u65f6\u89e3\u51b3\u65b9\u6848\u4ee5\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u6307\u9488\u68c0\u67e5\uff0c\u964d\u4f4e\u5d29\u6e83\u98ce\u9669\uff1b5\uff09\u63d0\u4ea4\u4e86\u9488\u5bf9Go\u5de5\u5177\u94fe\u7684\u6c38\u4e45\u6027\u4fee\u590d\u63d0\u6848\u5e76\u83b7\u63a5\u6536\u3002", "conclusion": "\u7cfb\u7edf\u6027\u5730\u63ed\u793a\u4e86CGO\u4f7f\u7528\u7684\u5206\u5e03\u3001\u6a21\u5f0f\u3001\u7528\u9014\u548c\u5173\u8054\u95ee\u9898\uff0c\u5bf9\u63d0\u5347Go\u8bed\u8a00\u7684\u5f00\u53d1\u6548\u7387\u548c\u5de5\u5177\u94fe\u5065\u58ee\u6027\u5177\u6709\u663e\u8457\u610f\u4e49\u3002"}}
{"id": "2508.09378", "categories": ["cs.CL", "cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.09378", "abs": "https://arxiv.org/abs/2508.09378", "authors": ["Artem Chernodub", "Aman Saini", "Yejin Huh", "Vivek Kulkarni", "Vipul Raheja"], "title": "APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification", "comment": "Accepted for publication at Recent Advances in Natural Language\n  Processing conference (RANLP 2025)", "summary": "Recent advancements in large language models (LLMs) have enabled a wide range\nof natural language processing (NLP) tasks to be performed through simple\nprompt-based interactions. Consequently, several approaches have been proposed\nto engineer prompts that most effectively enable LLMs to perform a given task\n(e.g., chain-of-thought prompting). In settings with a well-defined metric to\noptimize model performance, automatic prompt optimization (APO) methods have\nbeen developed to refine a seed prompt. Advancing this line of research, we\npropose APIO, a simple but effective prompt induction and optimization approach\nfor the tasks of Grammatical Error Correction (GEC) and Text Simplification,\nwithout relying on manually specified seed prompts. APIO achieves a new\nstate-of-the-art performance for purely LLM-based prompting methods on these\ntasks. We make our data, code, prompts, and outputs publicly available.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u52a8\u63d0\u793a\u5f52\u7eb3\u4e0e\u4f18\u5316\u65b9\u6cd5\uff08APIO\uff09\uff0c\u65e0\u9700\u4eba\u5de5\u79cd\u5b50\u63d0\u793a\uff0c\u5728\u8bed\u6cd5\u7ea0\u9519\u548c\u6587\u672c\u7b80\u5316\u7b49\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u4f73\u6027\u80fd\uff0c\u63a8\u8fdb\u4e86LLM\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u65b9\u5411\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u53d1\u5c55\uff0c\u901a\u8fc7\u63d0\u793a\uff08prompt\uff09\u5b9e\u73b0\u5404\u79cd\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u53d8\u5f97\u8d8a\u6765\u8d8a\u666e\u904d\u3002\u73b0\u6709\u65b9\u6cd5\u591a\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u7684\u63d0\u793a\uff0c\u6216\u8005\u9700\u9884\u5148\u7ed9\u5b9a\u79cd\u5b50\u63d0\u793a\uff0c\u5b58\u5728\u4e00\u5b9a\u7684\u5c40\u9650\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86APIO\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u6307\u5b9a\u79cd\u5b50\u63d0\u793a\u7684\u81ea\u52a8\u63d0\u793a\u5f52\u7eb3\u4e0e\u4f18\u5316\u65b9\u6cd5\uff0c\u4e3b\u8981\u7528\u4e8e\u8bed\u6cd5\u9519\u8bef\u7ea0\u6b63\uff08GEC\uff09\u548c\u6587\u672c\u7b80\u5316\u4efb\u52a1\u3002", "result": "\u57fa\u4e8eAPIO\u7684\u65b9\u6cd5\u5728GEC\u548c\u6587\u672c\u7b80\u5316\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u540c\u7c7b\u7eafLLM\u63d0\u793a\u65b9\u6cd5\u4e2d\u7684\u6700\u65b0\u6700\u4f73\u6548\u679c\u3002", "conclusion": "APIO\u80fd\u6709\u6548\u63d0\u5347LLM\u5728\u76f8\u5173NLP\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u7b80\u5316\u4e86\u63d0\u793a\u5de5\u7a0b\u6d41\u7a0b\u3002\u6587\u7ae0\u8fd8\u516c\u5f00\u4e86\u76f8\u5173\u6570\u636e\u3001\u4ee3\u7801\u3001\u63d0\u793a\u548c\u8f93\u51fa\u3002"}}
{"id": "2508.09403", "categories": ["cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2508.09403", "abs": "https://arxiv.org/abs/2508.09403", "authors": ["Ting Cai", "Stephen Sheen", "AnHai Doan"], "title": "Columbo: Expanding Abbreviated Column Names for Tabular Data Using Large Language Models", "comment": null, "summary": "Expanding the abbreviated column names of tables, such as ``esal'' to\n``employee salary'', is critical for numerous downstream data tasks. This\nproblem arises in enterprises, domain sciences, government agencies, and more.\nIn this paper we make three contributions that significantly advances the state\nof the art. First, we show that synthetic public data used by prior work has\nmajor limitations, and we introduce 4 new datasets in enterprise/science\ndomains, with real-world abbreviations. Second, we show that accuracy measures\nused by prior work seriously undercount correct expansions, and we propose new\nsynonym-aware measures that capture accuracy much more accurately. Finally, we\ndevelop Columbo, a powerful LLM-based solution that exploits context, rules,\nchain-of-thought reasoning, and token-level analysis. Extensive experiments\nshow that Columbo significantly outperforms NameGuess, the current most\nadvanced solution, by 4-29\\%, over 5 datasets. Columbo has been used in\nproduction on EDI, a major data portal for environmental sciences.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u8868\u683c\u7f29\u5199\u5217\u540d\u6269\u5c55\u95ee\u9898\uff0c\u6784\u5efa\u4e86\u771f\u5b9e\u6570\u636e\u96c6\u3001\u6539\u8fdb\u4e86\u51c6\u786e\u6027\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u5927\u6a21\u578b\u7684Columbo\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u6280\u672f\uff0c\u5df2\u5e94\u7528\u4e8e\u5b9e\u9645\u6570\u636e\u95e8\u6237\u3002", "motivation": "\u8868\u683c\u4e2d\u7f29\u5199\u5217\u540d\u6269\u5c55\u4e3a\u5168\u79f0\uff08\u5982\u201cesal\u201d\u6269\u5c55\u4e3a\u201cemployee salary\u201d\uff09\u5bf9\u4e8e\u6570\u636e\u5904\u7406\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u76ee\u524d\u5b9e\u9645\u5e94\u7528\u4e2d\u5b58\u5728\u51c6\u786e\u6027\u548c\u6570\u636e\u9002\u7528\u6027\u7684\u95ee\u9898\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e09\u9879\u4e3b\u8981\u8d21\u732e\uff1a1\uff09\u53d1\u73b0\u5e76\u6307\u51fa\u73b0\u6709\u516c\u5f00\u5408\u6210\u6570\u636e\u5b58\u5728\u5c40\u9650\uff0c\u5e76\u65b0\u5efa\u4e864\u4e2a\u771f\u5b9e\u9886\u57df\u6570\u636e\u96c6\uff1b2\uff09\u6279\u8bc4\u73b0\u6709\u51c6\u786e\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u66f4\u5408\u7406\u7684\u540c\u4e49\u8bcd\u611f\u77e5\u8bc4\u4f30\u6307\u6807\uff1b3\uff09\u5f00\u53d1\u4e86Columbo\uff0c\u4e00\u79cd\u7ed3\u5408\u4e0a\u4e0b\u6587\u3001\u89c4\u5219\u3001\u94fe\u5f0f\u63a8\u7406\u548c\u5206\u8bcd\u5206\u6790\u7684LLM\u65b9\u6cd5\u3002", "result": "Columbo\u5728\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u51c6\u786e\u7387\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u7684\u65b9\u6848\uff08NameGuess\uff09\u63d0\u5347\u4e864-29%\u3002Columbo\u5df2\u5728\u5b9e\u9645\u73af\u5883\u79d1\u5b66\u6570\u636e\u95e8\u6237\uff08EDI\uff09\u4e2d\u90e8\u7f72\u3002", "conclusion": "\u8bba\u6587\u7cfb\u7edf\u6027\u63d0\u5347\u4e86\u8868\u683c\u7f29\u5199\u5217\u540d\u6269\u5c55\u4efb\u52a1\u7684\u5e94\u7528\u57fa\u7840\u548c\u8bc4\u4f30\u6807\u51c6\uff0c\u5e76\u63d0\u51fa\u4e86\u6548\u679c\u663e\u8457\u7684\u65b0\u65b9\u6cd5Columbo\uff0c\u63a8\u52a8\u4e86\u6280\u672f\u8fdb\u6b65\u4e0e\u5b9e\u9645\u5e94\u7528\u843d\u5730\u3002"}}
{"id": "2508.09430", "categories": ["cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2508.09430", "abs": "https://arxiv.org/abs/2508.09430", "authors": ["Lavanya Shankar", "Leibny Paola Garcia Perera"], "title": "Leveraging Zipformer Model for Effective Language Identification in Code-Switched Child-Directed Speech", "comment": null, "summary": "Code-switching and language identification in child-directed scenarios\npresent significant challenges, particularly in bilingual environments. This\npaper addresses this challenge by using Zipformer to handle the nuances of\nspeech, which contains two imbalanced languages, Mandarin and English, in an\nutterance. This work demonstrates that the internal layers of the Zipformer\neffectively encode the language characteristics, which can be leveraged in\nlanguage identification. We present the selection methodology of the inner\nlayers to extract the embeddings and make a comparison with different\nback-ends. Our analysis shows that Zipformer is robust across these backends.\nOur approach effectively handles imbalanced data, achieving a Balanced Accuracy\n(BAC) of 81.89%, a 15.47% improvement over the language identification\nbaseline. These findings highlight the potential of the transformer encoder\narchitecture model in real scenarios.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u9a8c\u8bc1Zipformer\u5bf9\u4e2d\u82f1\u53cc\u8bed\u4e0d\u5747\u8861\u7ae5\u8bed\u573a\u666f\u7684\u8bed\u8a00\u8bc6\u522b\u80fd\u529b\uff0c\u76f8\u8f83\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u663e\u8457\uff08BAC\u63d0\u534715.47%\uff09\uff0c\u4e14\u5728\u4e0d\u540c\u540e\u7aef\u5747\u8868\u73b0\u7a33\u5065\uff0c\u8868\u660etransformer\u67b6\u6784\u6709\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u5728\u53cc\u8bed\u73af\u5883\u4e0b\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u513f\u7ae5\u4ea4\u6d41\uff0c\u4ee3\u7801\u8f6c\u6362\u548c\u8bed\u8a00\u8bc6\u522b\u9762\u4e34\u8bf8\u591a\u6311\u6218\u3002", "method": "\u91c7\u7528Zipformer\u6a21\u578b\u5904\u7406\u5305\u542b\u4e0d\u5e73\u8861\u7684\u666e\u901a\u8bdd\u548c\u82f1\u8bed\u8bed\u97f3\u6570\u636e\uff0c\u901a\u8fc7\u9009\u62e9\u5176\u5185\u90e8\u5c42\u6765\u63d0\u53d6\u5d4c\u5165\u7279\u5f81\uff0c\u5e76\u4e0e\u4e0d\u540c\u540e\u7aef\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\u3002", "result": "Zipformer\u5728\u4e0d\u540c\u540e\u7aef\u4e0b\u8868\u73b0\u7a33\u5065\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u4e0d\u5e73\u8861\u6570\u636e\uff0c\u5176\u5e73\u8861\u51c6\u786e\u7387\uff08BAC\uff09\u8fbe\u523081.89%\uff0c\u8f83\u4f20\u7edf\u8bed\u8a00\u8bc6\u522b\u57fa\u7ebf\u63d0\u534715.47%\u3002", "conclusion": "Zipformer\u7684\u5185\u90e8\u5c42\u53ef\u6709\u6548\u7f16\u7801\u8bed\u8a00\u7279\u5f81\uff0c\u63d0\u5347\u8bed\u8a00\u8bc6\u522b\u80fd\u529b\uff0c\u663e\u793a\u51fatransformer\u7f16\u7801\u5668\u67b6\u6784\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2508.09450", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09450", "abs": "https://arxiv.org/abs/2508.09450", "authors": ["Ridwan Mahbub", "Mohammed Saidul Islam", "Mir Tafseer Nayeem", "Md Tahmid Rahman Laskar", "Mizanur Rahman", "Shafiq Joty", "Enamul Hoque"], "title": "From Charts to Fair Narratives: Uncovering and Mitigating Geo-Economic Biases in Chart-to-Text", "comment": null, "summary": "Charts are very common for exploring data and communicating insights, but\nextracting key takeaways from charts and articulating them in natural language\ncan be challenging. The chart-to-text task aims to automate this process by\ngenerating textual summaries of charts. While with the rapid advancement of\nlarge Vision-Language Models (VLMs), we have witnessed great progress in this\ndomain, little to no attention has been given to potential biases in their\noutputs. This paper investigates how VLMs can amplify geo-economic biases when\ngenerating chart summaries, potentially causing societal harm. Specifically, we\nconduct a large-scale evaluation of geo-economic biases in VLM-generated chart\nsummaries across 6,000 chart-country pairs from six widely used proprietary and\nopen-source models to understand how a country's economic status influences the\nsentiment of generated summaries. Our analysis reveals that existing VLMs tend\nto produce more positive descriptions for high-income countries compared to\nmiddle- or low-income countries, even when country attribution is the only\nvariable changed. We also find that models such as GPT-4o-mini,\nGemini-1.5-Flash, and Phi-3.5 exhibit varying degrees of bias. We further\nexplore inference-time prompt-based debiasing techniques using positive\ndistractors but find them only partially effective, underscoring the complexity\nof the issue and the need for more robust debiasing strategies. Our code and\ndataset are publicly available here.", "AI": {"tldr": "\u8bba\u6587\u7cfb\u7edf\u63ed\u793a\u4e86\u73b0\u6709\u89c6\u89c9-\u8bed\u8a00\u5927\u6a21\u578b\u5728\u56fe\u8868\u81ea\u52a8\u6587\u672c\u751f\u6210\u65f6\uff0c\u56e0\u56fd\u5bb6\u7ecf\u6d4e\u6c34\u5e73\u4e0d\u540c\u800c\u4ea7\u751f\u63cf\u8ff0\u60c5\u611f\u504f\u89c1\u7684\u95ee\u9898\uff0c\u5e76\u8bc4\u6d4b\u5f53\u524d\u53bb\u504f\u65b9\u6cd5\u7684\u6548\u679c\u6709\u9650\uff0c\u547c\u5401\u8fdb\u4e00\u6b65\u7814\u7a76\u66f4\u6709\u6548\u7684\u53bb\u504f\u6280\u672f\u3002\u6570\u636e\u4e0e\u4ee3\u7801\u5df2\u516c\u5f00\u3002", "motivation": "\u672c\u8bba\u6587\u5173\u6ce8\u4e8e\u5229\u7528\u56fe\u8868\u81ea\u52a8\u751f\u6210\u6587\u672c\u6458\u8981\u7684\u4efb\u52a1\uff08chart-to-text\uff09\uff0c\u7279\u522b\u662f\u5728\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u88ab\u8fc5\u901f\u5e94\u7528\u4e8e\u8be5\u9886\u57df\u65f6\uff0c\u9c9c\u6709\u4eba\u5173\u6ce8\u5176\u751f\u6210\u7ed3\u679c\u6f5c\u5728\u7684\u5730\u7f18\u7ecf\u6d4e\u504f\u89c1\u95ee\u9898\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u4e9b\u504f\u89c1\u53ef\u80fd\u5e26\u6765\u793e\u4f1a\u4f24\u5bb3\uff0c\u56e0\u6b64\u8fdb\u884c\u6df1\u5165\u7814\u7a76\u3002", "method": "\u4f5c\u8005\u5bf96\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u4e13\u6709\u548c\u5f00\u6e90VLM\u6a21\u578b\uff0c\u8bbe\u8ba1\u4e86\u5927\u89c4\u6a21\u8bc4\u6d4b\u5b9e\u9a8c\uff0c\u6db5\u76d66,000\u4efd\u56fe\u8868-\u56fd\u5bb6\u914d\u5bf9\uff0c\u5206\u6790\u8fd9\u4e9b\u6a21\u578b\u5728\u751f\u6210\u56fe\u8868\u6458\u8981\u65f6\u5bf9\u4e0d\u540c\u56fd\u5bb6\u7ecf\u6d4e\u5730\u4f4d\uff08\u9ad8\u3001\u4e2d\u3001\u4f4e\u6536\u5165\uff09\u5e26\u6765\u7684\u60c5\u611f\u503e\u5411\uff0c\u5e76\u6d4b\u8bd5\u4e86\u5229\u7528\u79ef\u6781\u6697\u793a\u7684\u63a8\u65ad\u65f6\u53bb\u504f\u6280\u5de7\u3002", "result": "\u7814\u7a76\u663e\u793a\uff0c\u73b0\u6709VLM\u5728\u9762\u5bf9\u9ad8\u6536\u5165\u56fd\u5bb6\u65f6\uff0c\u751f\u6210\u66f4\u79ef\u6781\u7684\u6587\u672c\u63cf\u8ff0\uff0c\u800c\u5bf9\u4e2d\u4f4e\u6536\u5165\u56fd\u5bb6\u5219\u504f\u5411\u6d88\u6781\uff0c\u5373\u4f7f\u4ec5\u6539\u53d8\u56fd\u5bb6\u5f52\u5c5e\u53d8\u91cf\u4e5f\u5b58\u5728\u6b64\u73b0\u8c61\u3002\u4e0d\u540c\u6a21\u578b\u7684\u504f\u89c1\u7a0b\u5ea6\u4e0d\u4e00\uff0c\u5982GPT-4o-mini\u3001Gemini-1.5-Flash\u4e0ePhi-3.5\u7b49\u3002\u91c7\u7528\u63a8\u65ad\u65f6\u57fa\u4e8e\u6b63\u9762\u5e72\u6270\u7269\u7684\u53bb\u504f\u65b9\u6cd5\u4ec5\u90e8\u5206\u6709\u6548\uff0c\u504f\u89c1\u95ee\u9898\u4f9d\u7136\u590d\u6742\u3002", "conclusion": "\u672c\u8bba\u6587\u53d1\u73b0\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u8868\u751f\u6210\u6587\u672c\u4efb\u52a1\u4e2d\uff0c\u4f1a\u5f3a\u5316\u5730\u7f18\u7ecf\u6d4e\u504f\u89c1\uff0c\u4e14\u76ee\u524d\u5e94\u7528\u7684\u53bb\u504f\u65b9\u6cd5\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u66f4\u5f3a\u5927\u548c\u7cfb\u7edf\u6027\u7684\u53bb\u504f\u89e3\u51b3\u65b9\u6848\u3002\u7814\u7a76\u5f00\u653e\u4e86\u76f8\u5173\u6570\u636e\u96c6\u4e0e\u4ee3\u7801\u4f9b\u5b66\u754c\u53c2\u8003\u3002"}}
{"id": "2508.09463", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09463", "abs": "https://arxiv.org/abs/2508.09463", "authors": ["Qi Jia", "Xiujie Song", "Zicheng Zhang", "Yijin Guo", "Kaiwei Zhang", "Zijian Chen", "Guangtao Zhai"], "title": "User-centric Subjective Leaderboard by Customizable Reward Modeling", "comment": null, "summary": "Existing benchmarks for large language models (LLMs) predominantely focus on\nassessing their capabilities through verifiable tasks. Such objective and\nstatic benchmarks offer limited utility for practical LLM selection, making it\ndifficult for users to find suitable models for their individual needs. To\nbridge this gap, we present the first User-Centric Subjective Leaderboard\n(USL), which provides a preference-driven, dynamic ranking of LLMs across\ndiverse real-world scenarios. Our work is built upon a thorough investigation\nof real human preference data, involving more than 10K subjective queries. Our\ninvestigation reveals significant diversity and contradictions in human\npreferences, which limit the effectiveness of state-of-the-art reward models.\nTo address this, we introduce Customizable Reward Models (CRMs). With only 4B\nparameters, our CRM surpasses the performance of leading models such as GPT-4.1\nand Gemini-2.5-pro, showing exceptional generalization capabilities across new\ntopics and criteria. The USL, powered by CRMs, exhibits strong negative\ncorrelations to contradictory preferences.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u6237\u4e2d\u5fc3\u7684\u4e3b\u89c2\u6027\u6392\u884c\u699c\uff08USL\uff09\u548c\u53ef\u81ea\u5b9a\u4e49\u5956\u52b1\u6a21\u578b\uff08CRM\uff09\uff0c\u57fa\u4e8e\u5927\u91cf\u771f\u5b9e\u7528\u6237\u504f\u597d\u591a\u6837\u6027\u6570\u636e\u6784\u5efa\u3002CRM\u4e0d\u4ec5\u53c2\u6570\u5c0f\u4e8e\u4e3b\u6d41\u5927\u6a21\u578b\uff0c\u5374\u5b9e\u73b0\u66f4\u5f3a\u6cdb\u5316\u548c\u5339\u914d\u80fd\u529b\uff0c\u80fd\u591f\u52a8\u6001\u5730\u6839\u636e\u7528\u6237\u504f\u597d\u4e3aLLM\u6392\u540d\uff0c\u586b\u8865\u4e86\u73b0\u6709\u8bc4\u6d4b\u4e0e\u7528\u6237\u73b0\u5b9e\u9700\u6c42\u4e4b\u95f4\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8bc4\u6d4b\u4e3b\u8981\u96c6\u4e2d\u5728\u53ef\u9a8c\u8bc1\u4efb\u52a1\u4e0a\uff0c\u8fd9\u4e9b\u5ba2\u89c2\u4e14\u9759\u6001\u7684\u57fa\u51c6\u96be\u4ee5\u6ee1\u8db3\u5b9e\u9645\u7528\u6237\u9009\u578b\u9700\u6c42\u3002\u56e0\u6b64\uff0c\u5b9e\u9645\u5e94\u7528\u4e2d\u7528\u6237\u96be\u4ee5\u4f9d\u636e\u4e2a\u4eba\u9700\u6c42\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u3002\u672c\u6587\u8bd5\u56fe\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u7814\u7a76\u6536\u96c6\u4e86\u8d85\u8fc71\u4e07\u4efd\u771f\u5b9e\u7684\u4e3b\u89c2\u7528\u6237\u504f\u597d\u6570\u636e\uff0c\u63ed\u793a\u4e86\u4eba\u7c7b\u504f\u597d\u7684\u591a\u6837\u6027\u548c\u77db\u76fe\u6027\u3002\u57fa\u4e8e\u8fd9\u4e9b\u6570\u636e\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u7528\u6237\u4e2d\u5fc3\u7684\u4e3b\u89c2\u6027\u6392\u884c\u699c\uff08USL\uff09\uff0c\u5e76\u8bbe\u8ba1\u4e86\u53ef\u81ea\u5b9a\u4e49\u5956\u52b1\u6a21\u578b\uff08CRM\uff09\uff0c\u53ef\u6839\u636e\u4e0d\u540c\u7528\u6237\u548c\u573a\u666f\u8c03\u6574\u6a21\u578b\u8bc4\u6d4b\u3002", "result": "\u4f5c\u8005\u6784\u5efa\u7684CRM\u4ec5\u670940\u4ebf\u53c2\u6570\uff0c\u4f46\u5728\u6cdb\u5316\u80fd\u529b\u548c\u504f\u597d\u5339\u914d\u4e0a\u8d85\u8d8a\u4e86GPT-4.1\u548cGemini-2.5-pro\u7b49\u4e3b\u6d41\u5927\u6a21\u578b\uff0c\u5bf9\u65b0\u4e3b\u9898\u548c\u51c6\u5219\u4e5f\u6709\u5f88\u597d\u7684\u9002\u5e94\u6027\u3002USL\u6392\u540d\u4e0e\u76f8\u4e92\u77db\u76fe\u7684\u504f\u597d\u5448\u73b0\u5f3a\u8d1f\u76f8\u5173\u6027\uff0c\u80fd\u591f\u66f4\u5408\u7406\u5730\u53cd\u6620\u4e0d\u540c\u7528\u6237\u7684\u771f\u5b9e\u9700\u6c42\u3002", "conclusion": "\u4e3b\u89c2\u6027\u6392\u884c\u699c\uff08USL\uff09\u53caCRM\u80fd\u591f\u66f4\u51c6\u786e\u5730\u53cd\u6620\u4e0d\u540c\u7528\u6237\u7684\u9700\u6c42\u548c\u504f\u597d\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u66f4\u6709\u6548\u3001\u4e2a\u6027\u5316\u7684\u53c2\u8003\u6807\u51c6\u3002"}}
{"id": "2508.09494", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09494", "abs": "https://arxiv.org/abs/2508.09494", "authors": ["Jessy Lin", "Vincent-Pierre Berges", "Xilun Chen", "Wen-Tau Yih", "Gargi Ghosh", "Barlas O\u011fuz"], "title": "Learning Facts at Scale with Active Reading", "comment": null, "summary": "LLMs are known to store vast amounts of knowledge in their parametric memory.\nHowever, learning and recalling facts from this memory is known to be\nunreliable, depending largely on the prevalence of particular facts in the\ntraining data and other factors which are poorly understood. Practitioners are\nlacking tools which will allow them to ensure that the models learn a given\nbody of knowledge reliably and consistently. To this end, we propose Active\nReading: a framework where we train models to study a given set of material\nwith self-generated learning strategies. First, we demonstrate models trained\nwith Active Reading on expert domains absorb significantly more knowledge than\nvanilla finetuning and other data augmentations. We train expert 8B models that\nachieve 66% on a Wikipedia-grounded subset of SimpleQA (+313% relative over\nvanilla finetuning) and 26% on FinanceBench (+160% relative over vanilla\nfinetuning) by applying Active Reading to the source documents for each\nbenchmark. Finally, we show that Active Reading can be utilized at pre-training\nscale to build more factual models. As a demonstration of this, we release Meta\nWikiExpert-8B, a Wikipedia-expert model trained on 1 trillion generated tokens,\nwhich outcompetes models with hundreds of billions of parameters on factual QA.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86Active Reading\u4e3b\u52a8\u5b66\u4e60\u6846\u67b6\uff0c\u8ba9\u5927\u6a21\u578b\u66f4\u6709\u6548\u5438\u6536\u6307\u5b9a\u9886\u57df\u77e5\u8bc6\uff0c\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\uff0c\u5e76\u53d1\u5e03\u4e86\u65b0\u4e00\u4ee3Wikipedia\u4e13\u5bb6\u6a21\u578b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u53c2\u6570\u4e2d\u5b58\u50a8\u4e86\u5927\u91cf\u77e5\u8bc6\uff0c\u4f46\u5176\u8bb0\u5fc6\u548c\u56de\u5fc6\u4e8b\u5b9e\u7684\u80fd\u529b\u5e76\u4e0d\u53ef\u9760\uff0c\u4e14\u53d7\u5230\u8bad\u7ec3\u6570\u636e\u4e2d\u4e8b\u5b9e\u51fa\u73b0\u9891\u7387\u7b49\u591a\u56e0\u7d20\u5f71\u54cd\uff0c\u76f8\u5173\u673a\u5236\u5c1a\u4e0d\u660e\u786e\u3002\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u7f3a\u4e4f\u786e\u4fdd\u6a21\u578b\u80fd\u53ef\u9760\u5b66\u4e60\u7279\u5b9a\u77e5\u8bc6\u7684\u65b9\u6cd5\u548c\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u4e86Active Reading\u6846\u67b6\uff0c\u8ba9\u6a21\u578b\u901a\u8fc7\u81ea\u53d1\u751f\u6210\u7684\u5b66\u4e60\u7b56\u7565\uff0c\u4e3b\u52a8\u5b66\u4e60\u7279\u5b9a\u6750\u6599\u3002\u4f5c\u8005\u5728\u4e13\u5bb6\u9886\u57df\uff0c\u901a\u8fc7Active Reading\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u4e0e\u666e\u901a\u5fae\u8c03\u53ca\u5176\u4ed6\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u505a\u5bf9\u6bd4\u8bd5\u9a8c\u3002\u6b64\u5916\uff0c\u8fd8\u5c1d\u8bd5\u5c06Active Reading\u6269\u5c55\u5230\u9884\u8bad\u7ec3\u89c4\u6a21\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u91c7\u7528Active Reading\u6846\u67b6\u7684\u4e13\u5bb6\u6a21\u578b\u77e5\u8bc6\u5438\u6536\u6548\u679c\u663e\u8457\u4f18\u4e8e\u666e\u901a\u5fae\u8c03\u3002\u5177\u4f53\u6307\u6807\uff1a\u5728Wikipedia-grounded SimpleQA\u5b50\u96c6\u4e0a\u8fbe\u523066%\uff08\u6bd4\u666e\u901a\u5fae\u8c03\u63d0\u5347313%\uff09\uff1b\u5728FinanceBench\u4efb\u52a1\u4e0a\u8fbe\u523026%\uff08\u63d0\u5347160%\uff09\u3002Meta WikiExpert-8B\u6a21\u578b\u5728\u4e8b\u5b9e\u6027\u95ee\u7b54\u4e0a\u6027\u80fd\u8d85\u8fc7\u8bb8\u591a\u66f4\u5927\u53c2\u6570\u91cf\u6a21\u578b\u3002", "conclusion": "Active Reading\u80fd\u663e\u8457\u63d0\u5347LLMs\u5728\u7279\u5b9a\u9886\u57df\u7684\u77e5\u8bc6\u5438\u6536\u548c\u56de\u5fc6\u80fd\u529b\u3002\u8be5\u6846\u67b6\u4e0d\u4ec5\u9002\u7528\u4e8e\u5fae\u8c03\u9636\u6bb5\uff0c\u4e5f\u53ef\u7528\u4e8e\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u51c6\u786e\u7684\u4e8b\u5b9e\u6027\u6a21\u578b\u3002"}}
{"id": "2508.09497", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09497", "abs": "https://arxiv.org/abs/2508.09497", "authors": ["Siyuan Meng", "Junming Liu", "Yirong Chen", "Song Mao", "Pinlong Cai", "Guohang Yan", "Botian Shi", "Ding Wang"], "title": "From Ranking to Selection: A Simple but Efficient Dynamic Passage Selector for Retrieval Augmented Generation", "comment": "9 pages, 4 tables", "summary": "Retrieval-augmented generation (RAG) systems are often bottlenecked by their\nreranking modules, which typically score passages independently and select a\nfixed Top-K size. This approach struggles with complex multi-hop queries that\nrequire synthesizing evidence across multiple documents, creating a trade-off\nwhere small K values omit crucial information and large K values introduce\nnoise. To address this, we introduce the Dynamic Passage Selector (DPS), a\nnovel reranking framework that treats passage selection as a supervised\nlearning problem. Unlike traditional point-wise or list-wise methods, DPS is\nfine-tuned to capture inter-passage dependencies and dynamically select the\nmost relevant set of passages for generation. As a seamless plug-and-play\nmodule, DPS requires no modifications to the standard RAG pipeline.\nComprehensive evaluations on five benchmarks show that DPS consistently\noutperforms state-of-the-art rerankers and fine-tuning methods. Notably, on the\nchallenging MuSiQue dataset, DPS improves the F1-score by 30.06% and 15.4% over\nstrong baselines like Qwen3-reranker and RankingGPT, respectively. Our results\ndemonstrate that by enabling adaptive evidence selection, DPS substantially\nenhances reasoning capabilities in complex RAG scenarios.", "AI": {"tldr": "DPS\u52a8\u6001\u9009\u62e9\u76f8\u5173\u6587\u6bb5\uff0c\u6709\u6548\u63d0\u5347RAG\u7cfb\u7edf\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u4e0e\u751f\u6210\u8868\u73b0\uff0c\u5c24\u5176\u5728\u591a\u8df3\u548c\u8de8\u6587\u6863\u573a\u666f\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709RAG\u7684\u91cd\u6392\u5e8f\u65b9\u6cd5\u901a\u5e38\u72ec\u7acb\u8bc4\u5206\u5e76\u56fa\u5b9aTop-K\u6570\u91cf\uff0c\u96be\u4ee5\u5728\u591a\u8df3\u67e5\u8be2\u4e2d\u5904\u7406\u8de8\u6587\u6863\u7efc\u5408\u8bc1\u636e\uff0c\u9020\u6210\u4fe1\u606f\u9057\u6f0f\u6216\u566a\u58f0\u589e\u52a0\u3002\u4e3a\u6b64\uff0c\u63d0\u51fa\u52a8\u6001\u4e14\u66f4\u667a\u80fd\u7684\u6587\u6bb5\u9009\u62e9\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86Dynamic Passage Selector (DPS)\uff0c\u5c06\u6587\u6bb5\u9009\u62e9\u89c6\u4e3a\u76d1\u7763\u5b66\u4e60\u95ee\u9898\uff0c\u80fd\u591f\u6355\u6349\u8de8\u6587\u6bb5\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u52a8\u6001\u9009\u62e9\u6700\u76f8\u5173\u6587\u6bb5\u7528\u4e8e\u751f\u6210\uff0c\u65e0\u9700\u66f4\u6539\u73b0\u6709RAG\u6d41\u7a0b\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDPS\u8868\u73b0\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u91cd\u6392\u5e8f\u548c\u5fae\u8c03\u65b9\u6cd5\u3002\u5728MuSiQue\u6570\u636e\u96c6\u4e0a\uff0cF1\u5206\u6570\u76f8\u6bd4Qwen3-reranker\u548cRankingGPT\u5206\u522b\u63d0\u5347\u4e8630.06%\u548c15.4%\u3002", "conclusion": "DPS\u80fd\u591f\u663e\u8457\u63d0\u5347\u590d\u6742RAG\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u548c\u751f\u6210\u80fd\u529b\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u9009\u62e9\u8bc1\u636e\uff0c\u6709\u6548\u514b\u670d\u4f20\u7edfTop-K\u9009\u62e9\u7684\u4e0d\u8db3\u3002"}}
{"id": "2508.09515", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09515", "abs": "https://arxiv.org/abs/2508.09515", "authors": ["Jakub \u0160m\u00edd", "Pavel P\u0159ib\u00e1\u0148", "Pavel Kr\u00e1l"], "title": "LACA: Improving Cross-lingual Aspect-Based Sentiment Analysis with LLM Data Augmentation", "comment": "Published in Proceedings of the 63rd Annual Meeting of the\n  Association for Computational Linguistics; Volume 1: Long Papers (ACL 2025).\n  Official version: https://aclanthology.org/2025.acl-long.41/", "summary": "Cross-lingual aspect-based sentiment analysis (ABSA) involves detailed\nsentiment analysis in a target language by transferring knowledge from a source\nlanguage with available annotated data. Most existing methods depend heavily on\noften unreliable translation tools to bridge the language gap. In this paper,\nwe propose a new approach that leverages a large language model (LLM) to\ngenerate high-quality pseudo-labelled data in the target language without the\nneed for translation tools. First, the framework trains an ABSA model to obtain\npredictions for unlabelled target language data. Next, LLM is prompted to\ngenerate natural sentences that better represent these noisy predictions than\nthe original text. The ABSA model is then further fine-tuned on the resulting\npseudo-labelled dataset. We demonstrate the effectiveness of this method across\nsix languages and five backbone models, surpassing previous state-of-the-art\ntranslation-based approaches. The proposed framework also supports generative\nmodels, and we show that fine-tuned LLMs outperform smaller multilingual\nmodels.", "AI": {"tldr": "\u7528LLM\u66ff\u4ee3\u7ffb\u8bd1\u5de5\u5177\u6765\u751f\u6210\u76ee\u6807\u8bed\u8a00\u7684\u9ad8\u8d28\u91cf\u4f2a\u6807\u6ce8\u6570\u636e\uff0c\u65e0\u9700\u7ffb\u8bd1\u4e5f\u80fd\u663e\u8457\u63d0\u5347\u8de8\u8bed\u8a00\u60c5\u611f\u5206\u6790\u8868\u73b0\uff0c\u6548\u679c\u8d85\u8fc7\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u8de8\u8bed\u8a00\u7ec6\u7c92\u5ea6\u60c5\u611f\u5206\u6790\uff08ABSA\uff09\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u7ffb\u8bd1\u5de5\u5177\u6765\u89e3\u51b3\u8bed\u8a00\u969c\u788d\uff0c\u4f46\u8fd9\u4e9b\u5de5\u5177\u7684\u53ef\u9760\u6027\u8f83\u4f4e\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u6846\u67b6\uff1a\u5148\u8bad\u7ec3ABSA\u6a21\u578b\u5bf9\u76ee\u6807\u8bed\u8a00\u7684\u65e0\u6807\u6ce8\u6570\u636e\u8fdb\u884c\u9884\u6d4b\uff0c\u518d\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u66f4\u81ea\u7136\u3001\u8868\u8fbe\u66f4\u51c6\u786e\u7684\u4f2a\u6807\u6ce8\u6587\u672c\uff0c\u6700\u540e\u7528\u8fd9\u4e9b\u4f2a\u6807\u6ce8\u6570\u636e\u518d\u6b21\u5fae\u8c03ABSA\u6a21\u578b\u3002\u65e0\u9700\u4f20\u7edf\u7ffb\u8bd1\u5de5\u5177\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u516d\u79cd\u8bed\u8a00\u548c\u4e94\u4e2a\u4e3b\u6d41\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u7ed3\u679c\u4f18\u4e8e\u7ffb\u8bd1\u57fa\u7840\u7684\u65b9\u6cd5\u3002\u5fae\u8c03\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u4e5f\u8d85\u8d8a\u4e86\u8f83\u5c0f\u7684\u591a\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "\u5229\u7528LLM\u751f\u6210\u9ad8\u8d28\u91cf\u4f2a\u6807\u6ce8\u6570\u636e\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8\u8de8\u8bed\u8a00ABSA\u7684\u6027\u80fd\uff0c\u6446\u8131\u4e86\u4f9d\u8d56\u4f20\u7edf\u7ffb\u8bd1\u5de5\u5177\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u65b9\u6cd5\u7684\u9769\u65b0\u3002"}}
{"id": "2508.09516", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09516", "abs": "https://arxiv.org/abs/2508.09516", "authors": ["Jakub \u0160m\u00edd", "Pavel Kr\u00e1l"], "title": "Cross-lingual Aspect-Based Sentiment Analysis: A Survey on Tasks, Approaches, and Challenges", "comment": "Submitted version prior to peer review. Updated version accepted in\n  Information Fusion. Official version:\n  https://www.sciencedirect.com/science/article/pii/S1566253525001460", "summary": "Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis\ntask that focuses on understanding opinions at the aspect level, including\nsentiment towards specific aspect terms, categories, and opinions. While ABSA\nresearch has seen significant progress, much of the focus has been on\nmonolingual settings. Cross-lingual ABSA, which aims to transfer knowledge from\nresource-rich languages (such as English) to low-resource languages, remains an\nunder-explored area, with no systematic review of the field. This paper aims to\nfill that gap by providing a comprehensive survey of cross-lingual ABSA. We\nsummarize key ABSA tasks, including aspect term extraction, aspect sentiment\nclassification, and compound tasks involving multiple sentiment elements.\nAdditionally, we review the datasets, modelling paradigms, and cross-lingual\ntransfer methods used to solve these tasks. We also examine how existing work\nin monolingual and multilingual ABSA, as well as ABSA with LLMs, contributes to\nthe development of cross-lingual ABSA. Finally, we highlight the main\nchallenges and suggest directions for future research to advance cross-lingual\nABSA systems.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u68b3\u7406\u4e86\u8de8\u8bed\u8a00\u65b9\u9762\u7ea7\u60c5\u611f\u5206\u6790\uff08ABSA\uff09\uff0c\u603b\u7ed3\u4e86\u4efb\u52a1\u3001\u6570\u636e\u96c6\u548c\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u73b0\u6709\u6311\u6218\u5e76\u6307\u660e\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7cfb\u7edf\u7efc\u8ff0\u7684\u7a7a\u7f3a\u3002", "motivation": "\u5c3d\u7ba1ABSA\u9886\u57df\u83b7\u5f97\u4e86\u957f\u8db3\u8fdb\u5c55\uff0c\u4f46\u7edd\u5927\u591a\u6570\u7814\u7a76\u805a\u7126\u4e8e\u5355\u8bed\u73af\u5883\uff0c\u8de8\u8bed\u8a00ABSA\u7814\u7a76\u4e0d\u8db3\u4e14\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7efc\u8ff0\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u9886\u57df\u7684\u6587\u732e\u7efc\u8ff0\u7a7a\u767d\u3002", "method": "\u672c\u6587\u8fdb\u884c\u4e86\u6587\u732e\u56de\u987e\u4e0e\u5f52\u7eb3\uff0c\u7cfb\u7edf\u6027\u68b3\u7406\u4e86\u8de8\u8bed\u8a00ABSA\u7684\u4e3b\u8981\u4efb\u52a1\u3001\u6570\u636e\u96c6\u548c\u65b9\u6cd5\uff0c\u5e76\u5206\u6790\u73b0\u6709\u6280\u672f\u53ca\u5176\u5728\u8de8\u8bed\u8a00\u573a\u666f\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u8be5\u7efc\u8ff0\u5f52\u7eb3\u4e86\u8de8\u8bed\u8a00ABSA\u7684\u6838\u5fc3\u4efb\u52a1\uff08\u5982\u65b9\u9762\u9879\u62bd\u53d6\u3001\u60c5\u611f\u5206\u7c7b\u7b49\uff09\u3001\u516c\u5f00\u6570\u636e\u96c6\u3001\u901a\u7528\u5efa\u6a21\u4e0e\u8fc1\u79fb\u8303\u5f0f\uff0c\u5e76\u7ed3\u5408\u5355\u8bed\u3001\u591a\u8bed\u548c\u5927\u6a21\u578b\uff08LLM\uff09\u7b49\u76f8\u5173\u7814\u7a76\uff0c\u5206\u6790\u5176\u5bf9\u8de8\u8bed\u8a00ABSA\u7684\u63a8\u52a8\u4f5c\u7528\uff0c\u6700\u540e\u603b\u7ed3\u4e86\u9762\u4e34\u7684\u6838\u5fc3\u6311\u6218\u5e76\u4e3a\u672a\u6765\u7ed9\u51fa\u5efa\u8bae\u3002", "conclusion": "\u672c\u8bba\u6587\u7efc\u8ff0\u4e86\u8de8\u8bed\u8a00\u7ec6\u7c92\u5ea6\u60c5\u611f\u5206\u6790\uff08ABSA\uff09\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u603b\u7ed3\u5173\u952e\u4efb\u52a1\u3001\u6570\u636e\u96c6\u3001\u5efa\u6a21\u8303\u5f0f\u548c\u8de8\u8bed\u8a00\u8fc1\u79fb\u65b9\u6cd5\uff0c\u6307\u51fa\u5f53\u524d\u7684\u6311\u6218\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2508.09517", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09517", "abs": "https://arxiv.org/abs/2508.09517", "authors": ["Ladislav Lenc", "Daniel C\u00edfka", "Ji\u0159\u00ed Mart\u00ednek", "Jakub \u0160m\u00edd", "Pavel Kr\u00e1l"], "title": "UWBa at SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval", "comment": "Published in Proceedings of the 19th International Workshop on\n  Semantic Evaluation (SemEval-2025). Official version:\n  https://aclanthology.org/2025.semeval-1.31/", "summary": "This paper presents a zero-shot system for fact-checked claim retrieval. We\nemployed several state-of-the-art large language models to obtain text\nembeddings. The models were then combined to obtain the best possible result.\nOur approach achieved 7th place in monolingual and 9th in cross-lingual\nsubtasks. We used only English translations as an input to the text embedding\nmodels since multilingual models did not achieve satisfactory results. We\nidentified the most relevant claims for each post by leveraging the embeddings\nand measuring cosine similarity. Overall, the best results were obtained by the\nNVIDIA NV-Embed-v2 model. For some languages, we benefited from model\ncombinations (NV-Embed & GPT or Mistral).", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u7ed3\u5408\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u7684\u96f6\u6837\u672c\u4e8b\u5b9e\u67e5\u8bc1\u68c0\u7d22\u7cfb\u7edf\uff0c\u5355\u8bed\u548c\u8de8\u8bed\u79cd\u6392\u540d\u8f83\u9ad8\uff0c\u5c24\u5176NV-Embed-v2\u6a21\u578b\u8868\u73b0\u7a81\u51fa\uff0c\u6a21\u578b\u878d\u5408\u5bf9\u90e8\u5206\u8bed\u79cd\u6709\u52a9\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u591a\u8bed\u79cd\u5d4c\u5165\u6a21\u578b\u6548\u679c\u4e0d\u4f73\uff0c\u4e9f\u9700\u4e00\u79cd\u65e0\u9700\u8bed\u8a00\u6807\u7b7e\u548c\u8bad\u7ec3\u3001\u901a\u7528\u4e14\u9ad8\u6548\u7684\u4e8b\u5b9e\u6838\u67e5\u68c0\u7d22\u7cfb\u7edf\uff0c\u5bf9\u8de8\u8bed\u8a00\u4e0e\u5355\u8bed\u8a00\u4efb\u52a1\u5747\u9002\u7528\u3002", "method": "\u4f7f\u7528\u591a\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982NV-Embed\u3001GPT\u3001Mistral\uff09\u751f\u6210\u6587\u672c\u5d4c\u5165\uff0c\u4e3b\u8981\u91c7\u7528\u82f1\u6587\u7ffb\u8bd1\u4f5c\u4e3a\u8f93\u5165\uff0c\u57fa\u4e8e\u4f59\u5f26\u76f8\u4f3c\u5ea6\u68c0\u7d22\u6700\u76f8\u5173\u7684\u4e8b\u5b9e\u4e3b\u5f20\u3002\u9488\u5bf9\u90e8\u5206\u8bed\u79cd\u95ee\u9898\uff0c\u5c1d\u8bd5\u4e86\u6a21\u578b\u878d\u5408\u65b9\u5f0f\u3002", "result": "\u8be5\u7cfb\u7edf\u5728\u76f8\u5173\u56fd\u9645\u8bc4\u6d4b\u4e2d\uff0c\u5355\u8bed\u68c0\u7d22\u6392\u540d\u7b2c7\uff0c\u8de8\u8bed\u79cd\u68c0\u7d22\u6392\u540d\u7b2c9\u3002NVIDIA NV-Embed-v2\u6548\u679c\u6700\u597d\uff0c\u4e00\u4e9b\u8bed\u79cd\u901a\u8fc7\u6a21\u578b\u7ec4\u5408\u6709\u6240\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u83b7\u53d6\u6587\u672c\u5d4c\u5165\u5e76\u6d4b\u91cf\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff0c\u7cfb\u7edf\u5728\u5355\u8bed\u548c\u8de8\u8bed\u79cd\u4efb\u52a1\u4e2d\u5206\u522b\u53d6\u5f97\u7b2c7\u548c\u7b2c9\u540d\u7684\u7ed3\u679c\uff0c\u663e\u793a\u5176\u96f6\u6837\u672c\u4e8b\u5b9e\u67e5\u8bc1\u68c0\u7d22\u7684\u6709\u6548\u6027\u3002\u7279\u522b\u5730\uff0cNVIDIA NV-Embed-v2\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u90e8\u5206\u8bed\u8a00\u4f7f\u7528\u6a21\u578b\u7ec4\u5408\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6548\u679c\u3002"}}
{"id": "2508.09521", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09521", "abs": "https://arxiv.org/abs/2508.09521", "authors": ["Yunxiao Wang", "Meng Liu", "Wenqi Liu", "Kaiyu Jiang", "Bin Wen", "Fan Yang", "Tingting Gao", "Guorui Zhou", "Liqiang Nie"], "title": "COMPEER: Controllable Empathetic Reinforcement Reasoning for Emotional Support Conversation", "comment": null, "summary": "Emotional support conversations are crucial for promoting emotional\nwell-being, yet current models often lack deep empathetic reasoning grounded in\npsychological principles. To address this, we propose controllable empathetic\nreasoning, which combines natural language reasoning with structured\npsychological steps. We construct a fine-grained dataset annotated with\nreasoning correctness and response preferences to enable this capability. To\nfurther enhance training, we employ reinforcement learning with a unified\nprocess-outcome reward model that delivers precise feedback. To mitigate\nresponse repetitiveness from entropy collapse, we introduce personality-based\ndialogue rewriting and a redundancy-aware reward reweighting strategy. Our\napproach significantly improves model's emotional support ability, advancing\nthe development of empathetic, human-like support systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u5fc3\u7406\u5b66\u548c\u8bed\u8a00\u63a8\u7406\u7684\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u6570\u636e\u96c6\u548c\u591a\u91cd\u521b\u65b0\u63aa\u65bd\u63d0\u5347\u4e86\u6a21\u578b\u7684\u5171\u60c5\u80fd\u529b\uff0c\u5b9e\u73b0\u66f4\u4f18\u7684\u4eba\u6027\u5316\u652f\u6301\u3002", "motivation": "\u73b0\u6709\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u6a21\u578b\u7f3a\u4e4f\u57fa\u4e8e\u5fc3\u7406\u5b66\u539f\u7406\u7684\u6df1\u5c42\u5171\u60c5\u63a8\u7406\uff0c\u4e0d\u80fd\u5f88\u597d\u5730\u63d0\u4f9b\u60c5\u611f\u652f\u6301\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u53ef\u63a7\u7684\u5171\u60c5\u63a8\u7406\u65b9\u6cd5\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4e0e\u7ed3\u6784\u5316\u5fc3\u7406\u6b65\u9aa4\u7ed3\u5408\u3002\u6784\u5efa\u4e86\u7ec6\u7c92\u5ea6\u7684\u6570\u636e\u96c6\uff0c\u5e76\u91c7\u7528\u4e86\u5e26\u6709\u7edf\u4e00\u8fc7\u7a0b-\u7ed3\u679c\u5956\u52b1\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86\u57fa\u4e8e\u4eba\u683c\u7684\u5bf9\u8bdd\u91cd\u5199\u548c\u5197\u4f59\u611f\u77e5\u5956\u52b1\u91cd\u52a0\u6743\u7b56\u7565\uff0c\u7f13\u89e3\u4e86\u56de\u590d\u91cd\u590d\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u60c5\u611f\u652f\u6301\u80fd\u529b\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\uff0c\u6a21\u578b\u5171\u60c5\u548c\u652f\u6301\u80fd\u529b\u66f4\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u3002", "conclusion": "\u8be5\u8bba\u6587\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u6a21\u578b\u7684\u6027\u80fd\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u7c7b\u4f3c\u4eba\u7c7b\u7684\u5171\u60c5\u652f\u6301\u7cfb\u7edf\u53d1\u5c55\u3002"}}
{"id": "2508.09603", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09603", "abs": "https://arxiv.org/abs/2508.09603", "authors": ["Skyler Hallinan", "Jaehun Jung", "Melanie Sclar", "Ximing Lu", "Abhilasha Ravichander", "Sahana Ramnath", "Yejin Choi", "Sai Praneeth Karimireddy", "Niloofar Mireshghallah", "Xiang Ren"], "title": "The Surprising Effectiveness of Membership Inference with Simple N-Gram Coverage", "comment": "CoLM 2025", "summary": "Membership inference attacks serves as useful tool for fair use of language\nmodels, such as detecting potential copyright infringement and auditing data\nleakage. However, many current state-of-the-art attacks require access to\nmodels' hidden states or probability distribution, which prevents investigation\ninto more widely-used, API-access only models like GPT-4. In this work, we\nintroduce N-Gram Coverage Attack, a membership inference attack that relies\nsolely on text outputs from the target model, enabling attacks on completely\nblack-box models. We leverage the observation that models are more likely to\nmemorize and subsequently generate text patterns that were commonly observed in\ntheir training data. Specifically, to make a prediction on a candidate member,\nN-Gram Coverage Attack first obtains multiple model generations conditioned on\na prefix of the candidate. It then uses n-gram overlap metrics to compute and\naggregate the similarities of these outputs with the ground truth suffix; high\nsimilarities indicate likely membership. We first demonstrate on a diverse set\nof existing benchmarks that N-Gram Coverage Attack outperforms other black-box\nmethods while also impressively achieving comparable or even better performance\nto state-of-the-art white-box attacks - despite having access to only text\noutputs. Interestingly, we find that the success rate of our method scales with\nthe attack compute budget - as we increase the number of sequences generated\nfrom the target model conditioned on the prefix, attack performance tends to\nimprove. Having verified the accuracy of our method, we use it to investigate\npreviously unstudied closed OpenAI models on multiple domains. We find that\nmore recent models, such as GPT-4o, exhibit increased robustness to membership\ninference, suggesting an evolving trend toward improved privacy protections.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u4ec5\u4f9d\u8d56\u6587\u672c\u8f93\u51fa\u7684N-Gram Coverage\u6210\u5458\u63a8\u65ad\u653b\u51fb\uff0c\u5bf9\u9ed1\u76d2API\u6a21\u578b\u5982GPT-4\u6709\u6548\uff0c\u6027\u80fd\u8d85\u8fc7\u751a\u81f3\u8ffd\u5e73\u767d\u76d2\u65b9\u6cd5\uff0c\u5e76\u63ed\u793a\u5927\u6a21\u578b\u9010\u6b65\u589e\u5f3a\u7684\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u73b0\u6709\u7684\u6210\u5458\u63a8\u65ad\u653b\u51fb\u9700\u8981\u8bbf\u95ee\u6a21\u578b\u7684\u9690\u85cf\u72b6\u6001\u6216\u6982\u7387\u5206\u5e03\uff0c\u4e0d\u80fd\u9002\u7528\u4e8eAPI\u9650\u5236\u7684\u95ed\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-4\uff09\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u4e2d\u68c0\u6d4b\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u6cc4\u9732\u3001\u7248\u6743\u98ce\u9669\u7b49\u9700\u6c42\u5e7f\u6cdb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ec5\u4f7f\u7528\u76ee\u6807\u6a21\u578b\u6587\u672c\u8f93\u51fa\u7684\u6210\u5458\u63a8\u65ad\u653b\u51fb\u65b9\u6cd5\uff1aN-Gram Coverage Attack\u3002\u5177\u4f53\u505a\u6cd5\u662f\u4ee5\u5019\u9009\u6587\u672c\u7684\u524d\u7f00\u4e3a\u6761\u4ef6\u751f\u6210\u591a\u4e2a\u6a21\u578b\u8f93\u51fa\uff0c\u518d\u901a\u8fc7n-gram\u91cd\u53e0\u5ea6\u6307\u6807\uff0c\u7edf\u8ba1\u751f\u6210\u6587\u672c\u4e0e\u771f\u5b9e\u540e\u7f00\u7684\u76f8\u4f3c\u6027\uff0c\u8fdb\u800c\u5224\u65ad\u6587\u672c\u662f\u5426\u5c5e\u4e8e\u8bad\u7ec3\u96c6\u6210\u5458\u3002", "result": "\u5728\u591a\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cN-Gram Coverage Attack\u8d85\u8d8a\u4e86\u5176\u4ed6\u9ed1\u76d2\u65b9\u6cd5\uff0c\u5e76\u80fd\u8fbe\u5230\u751a\u81f3\u8d85\u8fc7\u4e3b\u6d41\u767d\u76d2\u653b\u51fb\u6548\u679c\uff0c\u65e0\u9700\u6a21\u578b\u5185\u90e8\u4fe1\u606f\u3002\u53d1\u73b0\u653b\u51fb\u6027\u80fd\u968f\u751f\u6210\u5e8f\u5217\u6570\u91cf\uff08\u7b97\u529b\u9884\u7b97\uff09\u589e\u52a0\u800c\u63d0\u5347\u3002\u8fdb\u4e00\u6b65\u7528\u8be5\u65b9\u6cd5\u7814\u7a76OpenAI\u95ed\u6e90\u6a21\u578b\uff0c\u53d1\u73b0\u65b0\u6a21\u578b\u5982GPT-4o\u5728\u6210\u5458\u63a8\u65ad\u4e0a\u7684\u9c81\u68d2\u6027\u589e\u5f3a\uff0c\u8bf4\u660e\u9690\u79c1\u4fdd\u62a4\u6709\u8fdb\u6b65\u8d8b\u52bf\u3002", "conclusion": "\u63d0\u51fa\u4e86\u9488\u5bf9\u9ed1\u76d2API\u6a21\u578b\u7684\u65b0\u653b\u51fb\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u6210\u5458\u63a8\u65ad\uff0c\u5bf9\u73b0\u6709\u95ed\u6e90\u5927\u6a21\u578b\u7684\u9690\u79c1\u98ce\u9669\u505a\u4e86\u91cf\u5316\u5206\u6790\uff0c\u5e76\u63ed\u793a\u4e86\u6a21\u578b\u9010\u6e10\u52a0\u5f3a\u9690\u79c1\u4fdd\u62a4\u7684\u8d8b\u52bf\u3002"}}
{"id": "2508.09622", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09622", "abs": "https://arxiv.org/abs/2508.09622", "authors": ["Tatiana Batura", "Elena Bruches", "Milana Shvenk", "Valentin Malykh"], "title": "AINL-Eval 2025 Shared Task: Detection of AI-Generated Scientific Abstracts in Russian", "comment": "AINL 2025 Conference", "summary": "The rapid advancement of large language models (LLMs) has revolutionized text\ngeneration, making it increasingly difficult to distinguish between human- and\nAI-generated content. This poses a significant challenge to academic integrity,\nparticularly in scientific publishing and multilingual contexts where detection\nresources are often limited. To address this critical gap, we introduce the\nAINL-Eval 2025 Shared Task, specifically focused on the detection of\nAI-generated scientific abstracts in Russian. We present a novel, large-scale\ndataset comprising 52,305 samples, including human-written abstracts across 12\ndiverse scientific domains and AI-generated counterparts from five\nstate-of-the-art LLMs (GPT-4-Turbo, Gemma2-27B, Llama3.3-70B, Deepseek-V3, and\nGigaChat-Lite). A core objective of the task is to challenge participants to\ndevelop robust solutions capable of generalizing to both (i) previously unseen\nscientific domains and (ii) models not included in the training data. The task\nwas organized in two phases, attracting 10 teams and 159 submissions, with top\nsystems demonstrating strong performance in identifying AI-generated content.\nWe also establish a continuous shared task platform to foster ongoing research\nand long-term progress in this important area. The dataset and platform are\npublicly available at https://github.com/iis-research-team/AINL-Eval-2025.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u9488\u5bf9\u4fc4\u8bed\u79d1\u5b66\u6458\u8981AI\u751f\u6210\u68c0\u6d4b\u7684\u5927\u89c4\u6a21\u5171\u4eab\u4efb\u52a1\u4e0e\u6570\u636e\u96c6\uff0c\u63a8\u52a8\u4e86\u591a\u9886\u57df\u6cdb\u5316\u68c0\u6d4b\u7814\u7a76\uff0c\u5e76\u5efa\u7acb\u4e86\u6301\u7eed\u7814\u7a76\u7684\u5e73\u53f0\u3002", "motivation": "\u7531\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u6587\u672c\u751f\u6210\u6280\u672f\u53d6\u5f97\u4e86\u5de8\u5927\u8fdb\u6b65\uff0c\u5bfc\u81f4\u4eba\u7c7b\u4e0eAI\u751f\u6210\u5185\u5bb9\u4e4b\u95f4\u96be\u4ee5\u533a\u5206\uff0c\u5c24\u5176\u662f\u5728\u79d1\u5b66\u51fa\u7248\u548c\u591a\u8bed\u79cd\u73af\u5883\u4e0b\u3002\u73b0\u6709\u68c0\u6d4b\u5de5\u5177\u8d44\u6e90\u6709\u9650\uff0c\u5a01\u80c1\u5b66\u672f\u8bda\u4fe1\uff0c\u4e9f\u9700\u6709\u6548\u68c0\u6d4bAI\u751f\u6210\u79d1\u5b66\u6458\u8981\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b52,305\u6761\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u6db5\u76d612\u4e2a\u79d1\u5b66\u9886\u57df\u7684\u771f\u4eba\u6458\u8981\u4e0e5\u79cd\u4e3b\u6d41LLM\u751f\u6210\u7684\u6458\u8981\uff08GPT-4-Turbo\u3001Gemma2-27B\u3001Llama3.3-70B\u3001Deepseek-V3\u3001GigaChat-Lite\uff09\uff0c\u5e76\u4ee5\u6b64\u4e3e\u529e\u4e86AINL-Eval 2025\u5171\u4eab\u4efb\u52a1\u3002\u4efb\u52a1\u8981\u6c42\u5f00\u53d1\u80fd\u6cdb\u5316\u5230\u672a\u77e5\u9886\u57df\u4e0e\u672a\u89c1\u6a21\u578b\u7684\u9c81\u68d2\u89e3\u51b3\u65b9\u6848\u3002\u7ec4\u7ec7\u5206\u4e3a\u4e24\u9636\u6bb5\uff0c\u5438\u5f1510\u652f\u961f\u4f0d\u3001159\u4efd\u6295\u7a3f\u3002", "result": "\u53c2\u8d5b\u7cfb\u7edf\u5728\u8bc6\u522bAI\u751f\u6210\u5185\u5bb9\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002\u6210\u529f\u5efa\u7acb\u4e86\u6301\u7eed\u7684\u5171\u4eab\u4efb\u52a1\u5e73\u53f0\uff0c\u652f\u6301\u8be5\u9886\u57df\u7684\u6301\u7eed\u7814\u7a76\u4e0e\u8fdb\u6b65\u3002\u6570\u636e\u96c6\u53ca\u5e73\u53f0\u5df2\u516c\u5f00\u53d1\u5e03\u3002", "conclusion": "AINL-Eval 2025\u4efb\u52a1\u4e0d\u4ec5\u63a8\u52a8\u4e86AI\u751f\u6210\u79d1\u5b66\u6458\u8981\u68c0\u6d4b\u65b9\u6cd5\u7684\u8fdb\u6b65\uff0c\u8fd8\u4e3a\u8be5\u9886\u57df\u7684\u957f\u671f\u53d1\u5c55\u548c\u7814\u7a76\u63d0\u4f9b\u4e86\u516c\u5f00\u8d44\u6e90\u548c\u5e73\u53f0\u3002"}}
{"id": "2508.09654", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.09654", "abs": "https://arxiv.org/abs/2508.09654", "authors": ["Alexandre Verine", "Florian Le Bronnec", "Kunhao Zheng", "Alexandre Allauzen", "Yann Chevaleyre", "Benjamin Negrevergne"], "title": "Improving Diversity in Language Models: When Temperature Fails, Change the Loss", "comment": "Forty-Second International Conference on Machine Learning, ICML2025", "summary": "Increasing diversity in language models is a challenging yet essential\nobjective. A common approach is to raise the decoding temperature. In this\nwork, we investigate this approach through a simplistic yet common case to\nprovide insights into why decreasing temperature can improve quality\n(Precision), while increasing it often fails to boost coverage (Recall). Our\nanalysis reveals that for a model to be effectively tunable through temperature\nadjustments, it must be trained toward coverage. To address this, we propose\nrethinking loss functions in language models by leveraging the Precision-Recall\nframework. Our results demonstrate that this approach achieves a substantially\nbetter trade-off between Precision and Recall than merely combining negative\nlog-likelihood training with temperature scaling. These findings offer a\npathway toward more versatile and robust language modeling techniques.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u89e3\u7801\u6e29\u5ea6\u5bf9\u8bed\u8a00\u6a21\u578b\u591a\u6837\u6027\u548c\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u8ba4\u4e3a\u63d0\u5347\u6e29\u5ea6\u5e76\u4e0d\u80fd\u6709\u6548\u63d0\u5347\u8f93\u51fa\u8986\u76d6\u5ea6\u3002\u63d0\u51fa\u5229\u7528Precision-Recall\u6846\u67b6\u4f18\u5316\u635f\u5931\u51fd\u6570\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u6bd4\u4f20\u7edf\u6e29\u5ea6\u8c03\u6574\u5b9e\u73b0\u66f4\u4f18\u7684\u591a\u6837\u6027\u4e0e\u51c6\u786e\u6027\u5e73\u8861\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6837\u6027\u4e00\u76f4\u662f\u91cd\u8981\u4f46\u56f0\u96be\u7684\u76ee\u6807\u3002\u76ee\u524d\u5e38\u89c1\u7684\u65b9\u6cd5\u662f\u63d0\u5347\u89e3\u7801\u6e29\u5ea6\uff0c\u4f46\u8fd9\u79cd\u505a\u6cd5\u5728\u5b9e\u9645\u6548\u679c\u4e0a\u5b58\u5728\u5c40\u9650\u3002\u4f5c\u8005\u5e0c\u671b\u6df1\u5165\u5206\u6790\u6e29\u5ea6\u8c03\u6574\u5bf9\u8f93\u51fa\u8d28\u91cf\u548c\u591a\u6837\u6027\u7684\u5f71\u54cd\u673a\u5236\u3002", "method": "\u901a\u8fc7\u5206\u6790\u7b80\u5355\u4e14\u5e38\u89c1\u7684\u6848\u4f8b\uff0c\u6df1\u5165\u63a2\u8ba8\u4e0d\u540c\u6e29\u5ea6\u5bf9\u6a21\u578bPrecision\u548cRecall\u7684\u5f71\u54cd\uff0c\u5e76\u5f15\u5165Precision-Recall\u6846\u67b6\uff0c\u91cd\u65b0\u601d\u8003\u8bed\u8a00\u6a21\u578b\u635f\u5931\u51fd\u6570\u7684\u8bbe\u8ba1\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u5728\u591a\u6837\u6027\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u5e73\u8861\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u91c7\u7528Precision-Recall\u6846\u67b6\u4f18\u5316\u635f\u5931\u51fd\u6570\uff0c\u6bd4\u4ec5\u4ec5\u7ed3\u5408\u8d1f\u5bf9\u6570\u4f3c\u7136\u8bad\u7ec3\u548c\u6e29\u5ea6\u8c03\u6574\u53d6\u5f97\u4e86\u66f4\u4f18\u7684Precision-Recall\u6743\u8861\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u65b0\u65b9\u6cd5\u5728\u63d0\u5347\u591a\u6837\u6027\u7684\u540c\u65f6\u66f4\u597d\u5730\u4fdd\u6301\u4e86\u6587\u672c\u751f\u6210\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u6e29\u5ea6\u8c03\u8282\u4e0d\u662f\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u591a\u6837\u6027\u7684\u4e07\u80fd\u65b9\u6cd5\uff0c\u53ea\u6709\u8bad\u7ec3\u65f6\u6709\u9488\u5bf9\u6027\u5730\u63d0\u5347\u8986\u76d6\u5ea6\uff0c\u624d\u53ef\u4ee5\u5229\u7528\u6e29\u5ea6\u8fdb\u884c\u6709\u6548\u8c03\u8282\u3002Precision-Recall\u6846\u67b6\u4e3a\u8bed\u8a00\u6a21\u578b\u7684\u635f\u5931\u51fd\u6570\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u66f4\u79d1\u5b66\u7684\u601d\u8def\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u66f4\u52a0\u591a\u6837\u800c\u51c6\u786e\u7684\u751f\u6210\u3002"}}
{"id": "2508.09662", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09662", "abs": "https://arxiv.org/abs/2508.09662", "authors": ["Yaoning Wang", "Jiahao Ying", "Yixin Cao", "Yubo Ma", "Yugang Jiang"], "title": "EffiEval: Efficient and Generalizable Model Evaluation via Capability Coverage Maximization", "comment": null, "summary": "The rapid advancement of large language models (LLMs) and the development of\nincreasingly large and diverse evaluation benchmarks have introduced\nsubstantial computational challenges for model assessment. In this paper, we\npresent EffiEval, a training-free approach for efficient benchmarking that\neffectively addresses data redundancy while maintaining high evaluation\nreliability. Our method is specifically designed to meet three key criteria for\nhigh-quality evaluation: representativeness, by ensuring comprehensive coverage\nof model capabilities; fairness, by remaining independent of model performance\nduring sample selection to avoid bias; and generalizability, by enabling\nflexible transfer across datasets and model families without reliance on\nlarge-scale evaluation data. Unlike traditional methods that rely on absolute\nperformance or require extensive evaluation data, our approach adaptively\nselects high-quality representative subsets based on the Model Utility Index\n(MUI). Extensive experiments on multiple public benchmarks and diverse LLMs\ndemonstrate that EffiEval achieves strong ranking consistency with full-dataset\nevaluation using only a small fraction of the original data. Furthermore, our\nmethod is flexible and scalable in size, allowing users to balance evaluation\nefficiency and representativeness according to specific needs. Overall,\nEffiEval provides a practical and generalizable solution for reliable, fair,\nand efficient evaluation in the era of LLMs.", "AI": {"tldr": "EffiEval\u662f\u4e00\u79cd\u5229\u7528\u5c11\u91cf\u4ee3\u8868\u6027\u6570\u636e\u9ad8\u6548\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u5de5\u5177\uff0c\u65e0\u9700\u8bad\u7ec3\u548c\u5927\u89c4\u6a21\u6570\u636e\uff0c\u540c\u65f6\u786e\u4fdd\u8bc4\u6d4b\u516c\u5e73\u6027\u548c\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u80fd\u663e\u8457\u51cf\u5c11\u8bc4\u6d4b\u8ba1\u7b97\u5f00\u9500\u4e14\u7ed3\u679c\u53ef\u9760\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5feb\u901f\u53d1\u5c55\u548c\u5927\u89c4\u6a21\u8bc4\u6d4b\u57fa\u51c6\u7684\u4e0d\u65ad\u4e30\u5bcc\u5bfc\u81f4\u4e86\u6a21\u578b\u8bc4\u4f30\u9762\u4e34\u5de8\u5927\u7684\u8ba1\u7b97\u6311\u6218\u3002\u4f20\u7edf\u7684\u8bc4\u6d4b\u65b9\u6cd5\u5f80\u5f80\u4f9d\u8d56\u5927\u91cf\u5b8c\u6574\u6570\u636e\uff0c\u6d88\u8017\u8d44\u6e90\u548c\u65f6\u95f4\uff0c\u4e9f\u9700\u66f4\u9ad8\u6548\u3001\u53ef\u9760\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51faEffiEval\uff0c\u8fd9\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b0\u578b\u9ad8\u6548\u8bc4\u6d4b\u65b9\u6cd5\u3002\u901a\u8fc7Model Utility Index\uff08MUI\uff09\u81ea\u9002\u5e94\u9009\u62e9\u5177\u6709\u4ee3\u8868\u6027\u7684\u6570\u636e\u5b50\u96c6\uff0c\u540c\u65f6\u6ee1\u8db3\u8bc4\u6d4b\u4ee3\u8868\u6027\u3001\u516c\u5e73\u6027\u548c\u6cdb\u5316\u80fd\u529b\u8fd9\u4e09\u5927\u6807\u51c6\u3002EffiEval\u4e0d\u4f9d\u8d56\u6a21\u578b\u6027\u80fd\u6216\u5927\u89c4\u6a21\u8bc4\u6d4b\u6570\u636e\uff0c\u80fd\u591f\u7075\u6d3b\u9002\u7528\u4e8e\u4e0d\u540c\u6570\u636e\u96c6\u548c\u6a21\u578b\u3002", "result": "\u5728\u591a\u4e2a\u516c\u5f00\u57fa\u51c6\u548c\u591a\u79cdLLM\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cEffiEval\u7528\u6781\u5c0f\u7684\u6570\u636e\u5b50\u96c6\u5373\u53ef\u83b7\u5f97\u4e0e\u5b8c\u6574\u8bc4\u6d4b\u9ad8\u5ea6\u4e00\u81f4\u7684\u6392\u540d\u7ed3\u679c\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u5f88\u9ad8\u7684\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u53ef\u6839\u636e\u5b9e\u9645\u9700\u6c42\u8c03\u6574\u8bc4\u6d4b\u89c4\u6a21\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e0e\u4ee3\u8868\u6027\u7684\u5e73\u8861\u3002", "conclusion": "EffiEval\u4e3aLLM\u65f6\u4ee3\u4e0b\u53ef\u9760\u3001\u516c\u5e73\u3001\u9ad8\u6548\u7684\u6a21\u578b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u5177\u5907\u5e7f\u6cdb\u9002\u5e94\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09666", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09666", "abs": "https://arxiv.org/abs/2508.09666", "authors": ["Ziyang Ma", "Qingyue Yuan", "Linhai Zhang", "Deyu Zhou"], "title": "Slow Tuning and Low-Entropy Masking for Safe Chain-of-Thought Distillation", "comment": "Preprint", "summary": "Previous chain-of-thought (CoT) distillation methods primarily focused on\nenhancing the reasoning capabilities of Small Language Models (SLMs) by\nutilizing high-quality rationales generated by powerful Large Language Models\n(LLMs, e.g., GPT-4). However, few works have noted the negative effects on SLM\nsafety brought by the training, which are revealed in this study. Although\nthere are works on safety alignment that fine-tune language models or\nmanipulate model weights to defend against harmful inputs, they require extra\ncomputation or annotated data, and probably impact the reasoning ability of\nSLMs. In this paper, we investigate how to maintain the safety of SLMs during\nthe CoT distillation process. Specifically, we propose a safe distillation\nmethod, Slow Tuning and Low-Entropy Masking Distillation (SLowED), containing\ntwo modules: Slow Tuning and Low-Entropy Masking. Slow Tuning scales down the\nmagnitude of model weight changes to optimize the model weights in the\nneighboring space near the initial weight distribution. Low-Entropy Masking\nmasks low-entropy tokens, which are regarded as unnecessary learning targets,\nto exclude them from fine-tuning. Experiments on three SLMs (Qwen2.5-1.5B,\nLlama-3.2-1B, BLOOM-1.1B) across reasoning benchmarks (BBH, BB-Sub, ARC,\nAGIEval) and safety evaluation (AdvBench) show that SLowED retains the safety\nof SLMs and comparably improves their reasoning capability compared to existing\ndistillation methods. Furthermore, our ablation study presents the\neffectiveness of Slow Tuning and Low-Entropy Masking, with the former\nmaintaining the model's safety in the early stage and the latter prolonging the\nsafe training epochs.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86CoT\u84b8\u998f\u5bf9SLM\u5b89\u5168\u6027\u7684\u9690\u60a3\uff0c\u63d0\u51faSLowED\u65b9\u6cd5\uff08\u6162\u8c03\u4f18+\u4f4e\u71b5\u5c4f\u853d\uff09\u80fd\u5728\u63d0\u5347\u63a8\u7406\u80fd\u529b\u7684\u540c\u65f6\u7ef4\u6301\u6a21\u578b\u5b89\u5168\u3002\u5b9e\u9a8c\u8bc1\u5b9e\u6709\u6548\u6027\uff0c\u65b9\u6cd5\u7b80\u5355\u9ad8\u6548\uff0c\u9002\u7528\u4e8e\u5404\u7c7bSLM\u5b89\u5168\u84b8\u998f\u573a\u666f\u3002", "motivation": "\u6b64\u524d\u7684CoT\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u65e8\u5728\u63d0\u5347\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5ffd\u89c6\u4e86\u84b8\u998f\u8fc7\u7a0b\u4e2d\u5bf9\u6a21\u578b\u5b89\u5168\u6027\u7684\u8d1f\u9762\u5f71\u54cd\u3002\u5df2\u6709\u7684\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u5219\u666e\u904d\u6210\u672c\u9ad8\u3001\u4f9d\u8d56\u989d\u5916\u6807\u6ce8\u6570\u636e\uff0c\u5e76\u53ef\u80fd\u5f71\u54cdSLM\u63a8\u7406\u80fd\u529b\u3002\u4f5c\u8005\u4e3a\u89e3\u51b3\u84b8\u998f\u8fc7\u7a0b\u4e2d\u7684\u5b89\u5168\u4fdd\u6301\u95ee\u9898\uff0c\u63d0\u51fa\u65b0\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b89\u5168\u84b8\u998f\u65b9\u6cd5SLowED\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u6a21\u5757\uff1a\u6162\u8c03\u4f18\uff08Slow Tuning\uff09\u548c\u4f4e\u71b5\u5c4f\u853d\uff08Low-Entropy Masking\uff09\u3002\u6162\u8c03\u4f18\u901a\u8fc7\u51cf\u7f13\u6a21\u578b\u6743\u91cd\u53d8\u5316\u5e45\u5ea6\uff0c\u4fdd\u8bc1\u6a21\u578b\u4f18\u5316\u8fc7\u7a0b\u4e2d\u6743\u91cd\u5206\u5e03\u4e0d\u504f\u79bb\u521d\u59cb\u90bb\u57df\uff1b\u4f4e\u71b5\u5c4f\u853d\u5219\u5c4f\u853d\u88ab\u89c6\u4e3a\u4e0d\u5fc5\u8981\u5b66\u4e60\u76ee\u6807\u7684\u4f4e\u71b5token\uff0c\u9632\u6b62\u5b83\u4eec\u53c2\u4e0e\u5fae\u8c03\u3002", "result": "\u5728\u4e09\u4e2aSLM\uff08Qwen2.5-1.5B\u3001Llama-3.2-1B\u3001BLOOM-1.1B\uff09\u4e0a\uff0c\u901a\u8fc7\u63a8\u7406\u57fa\u51c6\u548c\u5b89\u5168\u8bc4\u4f30\u5b9e\u9a8c\uff0cSLowED\u5728\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u540c\u65f6\uff0c\u63a8\u7406\u80fd\u529b\u4e0e\u4f20\u7edf\u84b8\u998f\u65b9\u6cd5\u6301\u5e73\u3002\u6d88\u878d\u5b9e\u9a8c\u663e\u793a\uff0c\u6162\u8c03\u4f18\u4e3b\u8981\u5728\u8bad\u7ec3\u521d\u671f\u7ef4\u6301\u5b89\u5168\u6027\uff0c\u4f4e\u71b5\u5c4f\u853d\u5219\u53ef\u663e\u8457\u5ef6\u957f\u5b89\u5168\u8bad\u7ec3\u5468\u671f\u3002", "conclusion": "SLowED\u65b9\u6cd5\u53ef\u5728CoT\u84b8\u998f\u8fc7\u7a0b\u4e2d\u540c\u65f6\u63d0\u5347SLM\u63a8\u7406\u80fd\u529b\u548c\u4fdd\u7559\u5b89\u5168\u6027\uff0c\u4e3a\u4f4e\u6210\u672c\u5b89\u5168\u84b8\u998f\u63d0\u4f9b\u6709\u6548\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2508.09713", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09713", "abs": "https://arxiv.org/abs/2508.09713", "authors": ["Rahul Hemrajani"], "title": "Evaluating the Role of Large Language Models in Legal Practice in India", "comment": null, "summary": "The integration of Artificial Intelligence(AI) into the legal profession\nraises significant questions about the capacity of Large Language Models(LLM)\nto perform key legal tasks. In this paper, I empirically evaluate how well\nLLMs, such as GPT, Claude, and Llama, perform key legal tasks in the Indian\ncontext, including issue spotting, legal drafting, advice, research, and\nreasoning. Through a survey experiment, I compare outputs from LLMs with those\nof a junior lawyer, with advanced law students rating the work on helpfulness,\naccuracy, and comprehensiveness. LLMs excel in drafting and issue spotting,\noften matching or surpassing human work. However, they struggle with\nspecialised legal research, frequently generating hallucinations, factually\nincorrect or fabricated outputs. I conclude that while LLMs can augment certain\nlegal tasks, human expertise remains essential for nuanced reasoning and the\nprecise application of law.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5370\u5ea6\u6cd5\u5f8b\u573a\u666f\u4e0b\u7684\u5b9e\u8bc1\u5bf9\u6bd4\u7814\u7a76\uff0c\u53d1\u73b0LLM\u5728\u6587\u4e66\u8d77\u8349\u548c\u95ee\u9898\u8bc6\u522b\u65b9\u9762\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u5728\u590d\u6742\u6cd5\u5f8b\u7814\u7a76\u4efb\u52a1\u4e0a\u6613\u51fa\u9519\uff0c\u6700\u7ec8\u8ba4\u4e3aLLM\u80fd\u63d0\u5347\u90e8\u5206\u6cd5\u5f8b\u5de5\u4f5c\u7684\u6548\u7387\uff0c\u4f46\u96be\u4ee5\u5b8c\u5168\u66ff\u4ee3\u4eba\u7c7b\u5f8b\u5e08\u7684\u4e13\u4e1a\u5224\u65ad\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u5728\u6cd5\u5f8b\u884c\u4e1a\u7684\u9010\u6b65\u5e94\u7528\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u662f\u5426\u5177\u5907\u6267\u884c\u6838\u5fc3\u6cd5\u5f8b\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u6210\u4e3a\u503c\u5f97\u63a2\u8ba8\u7684\u91cd\u8981\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u8bc4\u4f30LLM\u5728\u5370\u5ea6\u6cd5\u5f8b\u8bed\u5883\u4e0b\u5b8c\u6210\u5173\u952e\u6cd5\u5f8b\u4efb\u52a1\u7684\u8868\u73b0\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5b9e\u9a8c\u6027\u8c03\u67e5\uff0c\u5c06GPT\u3001Claude\u548cLlama\u7b49LLM\u5728\u6cd5\u5f8b\u95ee\u9898\u8bc6\u522b\u3001\u6cd5\u5f8b\u6587\u4e66\u8d77\u8349\u3001\u6cd5\u5f8b\u54a8\u8be2\u3001\u6cd5\u5f8b\u7814\u7a76\u4e0e\u63a8\u7406\u7b49\u4efb\u52a1\u4e2d\u7684\u8f93\u51fa\uff0c\u4e0e\u4e00\u4f4d\u521d\u7ea7\u5f8b\u5e08\u7684\u6210\u679c\u8fdb\u884c\u5bf9\u6bd4\uff0c\u7531\u9ad8\u7ea7\u6cd5\u5b66\u5b66\u751f\u6839\u636e\u8f93\u51fa\u7684\u6709\u7528\u6027\u3001\u51c6\u786e\u6027\u548c\u5168\u9762\u6027\u8fdb\u884c\u8bc4\u5206\u3002", "result": "LLM\u5728\u6cd5\u5f8b\u6587\u4e66\u8d77\u8349\u548c\u95ee\u9898\u8bc6\u522b\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u90e8\u5206\u60c5\u51b5\u4e0b\u751a\u81f3\u80fd\u591f\u8d76\u8d85\u6216\u8d85\u8fc7\u4eba\u7c7b\u3002\u5728\u4e13\u4e1a\u6027\u5f3a\u7684\u6cd5\u5f8b\u7814\u7a76\u4efb\u52a1\u4e0a\uff0cLLM\u5219\u5bb9\u6613\u51fa\u73b0\u201c\u5e7b\u89c9\u201d\uff0c\u5373\u8f93\u51fa\u4e0d\u51c6\u786e\u6216\u634f\u9020\u7684\u5185\u5bb9\u3002", "conclusion": "LLM\u53ef\u5728\u90e8\u5206\u6cd5\u5f8b\u4efb\u52a1\u4e2d\u53d1\u6325\u8f85\u52a9\u4f5c\u7528\uff0c\u4f46\u5bf9\u4e8e\u9700\u8981\u7ec6\u81f4\u63a8\u7406\u548c\u6cd5\u5f8b\u7cbe\u51c6\u5e94\u7528\u7684\u5de5\u4f5c\uff0c\u4eba\u7c7b\u4e13\u4e1a\u80fd\u529b\u4ecd\u4e0d\u53ef\u6216\u7f3a\u3002"}}
{"id": "2508.09716", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09716", "abs": "https://arxiv.org/abs/2508.09716", "authors": ["Ridwan Mahbub", "Mohammed Saidul Islam", "Md Tahmid Rahman Laskar", "Mizanur Rahman", "Mir Tafseer Nayeem", "Enamul Hoque"], "title": "The Perils of Chart Deception: How Misleading Visualizations Affect Vision-Language Models", "comment": "Accepted to IEEE VIS 2025", "summary": "Information visualizations are powerful tools that help users quickly\nidentify patterns, trends, and outliers, facilitating informed decision-making.\nHowever, when visualizations incorporate deceptive design elements-such as\ntruncated or inverted axes, unjustified 3D effects, or violations of best\npractices-they can mislead viewers and distort understanding, spreading\nmisinformation. While some deceptive tactics are obvious, others subtly\nmanipulate perception while maintaining a facade of legitimacy. As\nVision-Language Models (VLMs) are increasingly used to interpret\nvisualizations, especially by non-expert users, it is critical to understand\nhow susceptible these models are to deceptive visual designs. In this study, we\nconduct an in-depth evaluation of VLMs' ability to interpret misleading\nvisualizations. By analyzing over 16,000 responses from ten different models\nacross eight distinct types of misleading chart designs, we demonstrate that\nmost VLMs are deceived by them. This leads to altered interpretations of\ncharts, despite the underlying data remaining the same. Our findings highlight\nthe need for robust safeguards in VLMs against visual misinformation.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u591a\u6570\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u9762\u5bf9\u5177\u6709\u8bef\u5bfc\u6027\u8bbe\u8ba1\u7684\u53ef\u89c6\u5316\u56fe\u8868\u65f6\u4f1a\u4ea7\u751f\u9519\u8bef\u7406\u89e3\uff0c\u5efa\u8bae\u52a0\u5f3a\u5bf9\u6297\u89c6\u89c9\u8bef\u4fe1\u606f\u7684\u6280\u672f\u3002", "motivation": "\u5c3d\u7ba1\u4fe1\u606f\u53ef\u89c6\u5316\u80fd\u591f\u5e2e\u52a9\u7528\u6237\u8bc6\u522b\u6570\u636e\u6a21\u5f0f\u548c\u8d8b\u52bf\uff0c\u4f46\u4e00\u4e9b\u5177\u6709\u8bef\u5bfc\u6027\u7684\u8bbe\u8ba1\u5143\u7d20\u53ef\u80fd\u8ba9\u7528\u6237\u4ea7\u751f\u9519\u8bef\u7406\u89e3\u5e76\u4f20\u64ad\u9519\u8bef\u4fe1\u606f\u3002\u968f\u7740\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u88ab\u5e7f\u6cdb\u7528\u4e8e\u89e3\u8bfb\u53ef\u89c6\u5316\uff0c\u5c24\u5176\u662f\u975e\u4e13\u4e1a\u7528\u6237\uff0c\u4e5f\u9700\u8981\u4e86\u89e3\u8fd9\u4e9b\u6a21\u578b\u5bf9\u4e8e\u8bef\u5bfc\u6027\u53ef\u89c6\u5316\u7684\u654f\u611f\u6027\u3002", "method": "\u4f5c\u8005\u5bf9\u5341\u79cd\u4e0d\u540c\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u516b\u79cd\u8bef\u5bfc\u6027\u56fe\u8868\u8bbe\u8ba1\u4e0a\u7684\u89e3\u8bfb\u80fd\u529b\u8fdb\u884c\u6df1\u5165\u8bc4\u4f30\uff0c\u901a\u8fc7\u5206\u6790\u8d85\u8fc716000\u4e2a\u6a21\u578b\u8f93\u51fa\u7ed3\u679c\u3002", "result": "\u5927\u591a\u6570\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4f1a\u88ab\u5177\u8bef\u5bfc\u6027\u7684\u56fe\u8868\u8bbe\u8ba1\u6b3a\u9a97\uff0c\u5bf9\u76f8\u540c\u6570\u636e\u7ed9\u51fa\u9519\u8bef\u6216\u504f\u5dee\u7684\u89e3\u91ca\u3002", "conclusion": "\u5982\u679c\u4e0d\u52a0\u4ee5\u9632\u8303\uff0c\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5f88\u5bb9\u6613\u88ab\u8bef\u5bfc\u6027\u8bbe\u8ba1\u8bef\u5bfc\uff0c\u4ece\u800c\u5f71\u54cd\u6570\u636e\u53ef\u89c6\u5316\u4e0b\u7684\u89e3\u8bfb\uff0c\u5f3a\u8c03\u4e86\u5728VLMs\u4e2d\u5efa\u7acb\u9632\u8303\u89c6\u89c9\u8bef\u4fe1\u606f\u673a\u5236\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2508.09726", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.09726", "abs": "https://arxiv.org/abs/2508.09726", "authors": ["Vaishnavi Shrivastava", "Ahmed Awadallah", "Vidhisha Balachandran", "Shivam Garg", "Harkirat Behl", "Dimitris Papailiopoulos"], "title": "Sample More to Think Less: Group Filtered Policy Optimization for Concise Reasoning", "comment": null, "summary": "Large language models trained with reinforcement learning with verifiable\nrewards tend to trade accuracy for length--inflating response lengths to\nachieve gains in accuracy. While longer answers may be warranted for harder\nproblems, many tokens are merely \"filler\": repetitive, verbose text that makes\nno real progress. We introduce GFPO (Group Filtered Policy Optimization), which\ncurbs this length explosion by sampling larger groups per problem during\ntraining and filtering responses to train on based on two key metrics: (1)\nresponse length and (2) token efficiency: reward per token ratio. By sampling\nmore at training time, we teach models to think less at inference time. On the\nPhi-4-reasoning model, GFPO cuts GRPO's length inflation by 46-71% across\nchallenging STEM and coding benchmarks (AIME 24/25, GPQA, Omni-MATH,\nLiveCodeBench) while maintaining accuracy. Optimizing for reward per token\nfurther increases reductions in length inflation to 71-85%. We also propose\nAdaptive Difficulty GFPO, which dynamically allocates more training resources\nto harder problems based on real-time difficulty estimates, improving the\nbalance between computational efficiency and accuracy especially on difficult\nquestions. GFPO demonstrates that increased training-time compute directly\ntranslates to reduced test-time compute--a simple yet effective trade-off for\nefficient reasoning.", "AI": {"tldr": "GFPO\u901a\u8fc7\u4f18\u5316\u8bad\u7ec3\u6837\u672c\u7b5b\u9009\u548c\u6301\u7eed\u91c7\u6837\uff0c\u663e\u8457\u51cf\u5c11\u5927\u6a21\u578b\u54cd\u5e94\u957f\u5ea6\u81a8\u80c0\uff0c\u63d0\u5347\u63a8\u7406\u6548\u7387\u4e14\u51c6\u786e\u7387\u4e0d\u53d7\u5f71\u54cd\uff0c\u5728\u591a\u9879\u96be\u9898\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6548\u679c\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u81ea\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u9a71\u52a8\u4e0b\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u63d0\u9ad8\u51c6\u786e\u7387\u800c\u751f\u6210\u8fc7\u957f\u3001\u5197\u4f59\u54cd\u5e94\u7684\u95ee\u9898\uff0c\u63d0\u5347\u63a8\u7406\u6548\u7387\u548c\u8ba1\u7b97\u8d44\u6e90\u5229\u7528\u7387\u3002", "method": "\u63d0\u51fa\u4e86GFPO\uff08Group Filtered Policy Optimization\uff09\u8bad\u7ec3\u7b56\u7565\uff0c\u5728\u8bad\u7ec3\u671f\u95f4\u5bf9\u6bcf\u4e2a\u95ee\u9898\u8fdb\u884c\u5927\u6837\u672c\u91c7\u6837\uff0c\u901a\u8fc7\u54cd\u5e94\u957f\u5ea6\u548c\u5956\u52b1/\u6807\u8bb0\u6548\u7387\u8fc7\u6ee4\u8bad\u7ec3\u6837\u672c\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u96be\u5ea6\u5206\u914d\u673a\u5236\uff0c\u6839\u636e\u95ee\u9898\u96be\u5ea6\u52a8\u6001\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\u3002", "result": "\u5728Phi-4-reasoning\u5927\u6a21\u578b\u4e0a\uff0cGFPO\u5c06\u54cd\u5e94\u957f\u5ea6\u81a8\u80c0\u95ee\u9898\u51cf\u5c11\u4e8646-71%\uff0c\u5f53\u4f18\u5316\u5956\u52b1/\u6807\u8bb0\u6bd4\u540e\uff0c\u8fdb\u4e00\u6b65\u964d\u81f371-85%\uff0c\u5728\u591a\u4e2a\u9ad8\u96be\u57fa\u51c6\uff08\u5982AIME 24/25\u3001GPQA\u3001Omni-MATH\u3001LiveCodeBench\uff09\u4e0a\u4fdd\u6301\u51c6\u786e\u7387\u3002\u81ea\u9002\u5e94\u96be\u5ea6\u5206\u914d\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6a21\u578b\u5728\u96be\u9898\u4e0a\u7684\u6548\u7387\u548c\u8868\u73b0\u3002", "conclusion": "GFPO\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7531\u4e8e\u5956\u52b1\u53ef\u9a8c\u8bc1\u6027\u5bfc\u81f4\u7684\u957f\u5ea6\u81a8\u80c0\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63a8\u7406\u51c6\u786e\u7387\uff0c\u4f18\u5316\u4e86\u63a8\u7406\u6548\u7387\u3002"}}
{"id": "2508.09755", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09755", "abs": "https://arxiv.org/abs/2508.09755", "authors": ["Seokgi Lee"], "title": "Transforming Questions and Documents for Semantically Aligned Retrieval-Augmented Generation", "comment": null, "summary": "We introduce a novel retrieval-augmented generation (RAG) framework tailored\nfor multihop question answering. First, our system uses large language model\n(LLM) to decompose complex multihop questions into a sequence of single-hop\nsubquestions that guide document retrieval. This decomposition mitigates the\nambiguity inherent in multi-hop queries by clearly targeting distinct knowledge\nfacets. Second, instead of embedding raw or chunked documents directly, we\ngenerate answerable questions from each document chunk using Qwen3-8B, embed\nthese generated questions, and retrieve relevant chunks via question-question\nembedding similarity. During inference, the retrieved chunks are then fed along\nwith the original question into the RAG pipeline. We evaluate on three multihop\nquestion datasets (MuSiQue, 2WikiMultiHopQa, HotpotQA) from LongBench. Our\nmethod improves RAG performacne compared to baseline systems. Our contributions\nhighlight the benefits of using answerable-question embeddings for RAG, and the\neffectiveness of LLM-based query decomposition for multihop scenarios.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u591a\u8df3\u95ee\u7b54\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7LLM\u5206\u89e3\u95ee\u9898\u548c\u751f\u6210\u53ef\u56de\u7b54\u95ee\u9898\u5d4c\u5165\u8fdb\u884c\u68c0\u7d22\u4f18\u5316\uff0c\u5728\u591a\u4e2a\u591a\u8df3\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u591a\u8df3\u95ee\u9898\u7531\u4e8e\u95ee\u9898\u672c\u8eab\u7684\u590d\u6742\u6027\u548c\u591a\u4e49\u6027\uff0c\u5e38\u5bfc\u81f4\u4f20\u7edf\u68c0\u7d22\u548c\u751f\u6210\u65b9\u6cd5\u6027\u80fd\u53d7\u9650\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u6709\u6548\u7684\u5206\u89e3\u548c\u68c0\u7d22\u65b9\u5f0f\u63d0\u5347\u7cfb\u7edf\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5c06\u590d\u6742\u591a\u8df3\u95ee\u9898\u5206\u89e3\u4e3a\u5355\u8df3\u5b50\u95ee\u9898\u6307\u5bfc\u6587\u6863\u68c0\u7d22\uff1b\u4ece\u6587\u6863\u7247\u6bb5\u751f\u6210\u53ef\u56de\u7b54\u95ee\u9898\u5e76\u7528\u95ee\u9898-\u95ee\u9898\u5d4c\u5165\u6765\u68c0\u7d22\u76f8\u5173\u7247\u6bb5\uff0c\u518d\u4e0e\u539f\u59cb\u95ee\u9898\u4e00\u8d77\u8f93\u5165RAG\u7ba1\u9053\u8fdb\u884c\u63a8\u7406\u3002", "result": "\u5728MuSiQue\u30012WikiMultiHopQa\u3001HotpotQA\u4e09\u5927\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u7cfb\u7edf\uff0c\u9a8c\u8bc1\u4e86\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\uff0c\u5728\u591a\u8df3\u95ee\u7b54\u4e2d\u91c7\u7528\u7531LLM\u5206\u89e3\u67e5\u8be2\u548c\u53ef\u56de\u7b54\u95ee\u9898\u5d4c\u5165\uff0c\u80fd\u663e\u8457\u63d0\u5347\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2508.09759", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09759", "abs": "https://arxiv.org/abs/2508.09759", "authors": ["Avneet Kaur"], "title": "Echoes of Agreement: Argument Driven Opinion Shifts in Large Language Models", "comment": null, "summary": "There have been numerous studies evaluating bias of LLMs towards political\ntopics. However, how positions towards these topics in model outputs are highly\nsensitive to the prompt. What happens when the prompt itself is suggestive of\ncertain arguments towards those positions remains underexplored. This is\ncrucial for understanding how robust these bias evaluations are and for\nunderstanding model behaviour, as these models frequently interact with\nopinionated text. To that end, we conduct experiments for political bias\nevaluation in presence of supporting and refuting arguments. Our experiments\nshow that such arguments substantially alter model responses towards the\ndirection of the provided argument in both single-turn and multi-turn settings.\nMoreover, we find that the strength of these arguments influences the\ndirectional agreement rate of model responses. These effects point to a\nsycophantic tendency in LLMs adapting their stance to align with the presented\narguments which has downstream implications for measuring political bias and\ndeveloping effective mitigation strategies.", "AI": {"tldr": "LLM\u5728\u5904\u7406\u5e26\u6709\u660e\u663e\u7acb\u573a\u8bba\u636e\u7684\u63d0\u793a\u8bcd\u65f6\uff0c\u5bb9\u6613\u8868\u73b0\u51fa\u8fce\u5408\u6027\uff0c\u65e0\u8bba\u5355\u8f6e\u8fd8\u662f\u591a\u8f6e\u5bf9\u8bdd\uff0c\u6a21\u578b\u4f1a\u968f\u8bba\u636e\u65b9\u5411\u8c03\u6574\u81ea\u5df1\u7684\u653f\u6cbb\u504f\u89c1\u5224\u65ad\u3002\u8fd9\u8868\u660e\u73b0\u6709\u504f\u89c1\u8bc4\u4f30\u65b9\u6cd5\u53ef\u80fd\u4f4e\u4f30\u4e86\u6a21\u578b\u7684\u654f\u611f\u6027\uff0c\u4e5f\u4e3a\u540e\u7eed\u504f\u89c1\u7f13\u89e3\u5e26\u6765\u6311\u6218\u3002", "motivation": "\u6b64\u524d\u867d\u7136\u5bf9\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u653f\u6cbb\u8bdd\u9898\u4e0a\u7684\u504f\u89c1\u8fdb\u884c\u4e86\u5927\u91cf\u8bc4\u4f30\uff0c\u4f46\u672a\u6df1\u5165\u63a2\u8ba8\u6a21\u578b\u8f93\u51fa\u5bf9\u4e8e\u5e26\u6709\u503e\u5411\u6027\u8bba\u636e\u7684\u63d0\u793a\u8bcd\u7684\u654f\u611f\u6027\u3002\u8fdb\u4e00\u6b65\u4e86\u89e3\u8fd9\u7c7b\u504f\u89c1\u8bc4\u4f30\u7684\u9c81\u68d2\u6027\u53ca\u6a21\u578b\u884c\u4e3a\u975e\u5e38\u91cd\u8981\uff0c\u56e0\u4e3a\u6a21\u578b\u5e38\u4e0e\u89c2\u70b9\u6027\u6587\u672c\u4ea4\u4e92\u3002", "method": "\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6d4b\u8bd5\u5728\u63d0\u4f9b\u652f\u6301\u6216\u53cd\u9a73\uff08\u503e\u5411\u6027\uff09\u8bba\u636e\u60c5\u51b5\u4e0b\uff0cLLM\u5bf9\u653f\u6cbb\u504f\u89c1\u7684\u54cd\u5e94\uff0c\u5e76\u5206\u6790\u5355\u8f6e\u4e0e\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0c\u6a21\u578b\u54cd\u5e94\u4f1a\u660e\u663e\u53d7\u63d0\u793a\u8bcd\u8bba\u636e\u65b9\u5411\u5f71\u54cd\uff0c\u503e\u5411\u4e0e\u63d0\u793a\u8bcd\u8bba\u636e\u4e00\u81f4\u3002\u4e14\u8bba\u636e\u5f3a\u5ea6\u8d8a\u5927\uff0c\u6a21\u578b\u54cd\u5e94\u4e0e\u8bba\u636e\u65b9\u5411\u7684\u4e00\u81f4\u7387\u8d8a\u9ad8\u3002", "conclusion": "LLM\u5448\u73b0\u201c\u8fce\u5408\u6027\u201d\u503e\u5411\uff0c\u4f1a\u968f\u7740\u8bba\u636e\u65b9\u5411\u8c03\u6574\u81ea\u8eab\u7acb\u573a\uff0c\u8fd9\u5bf9\u672a\u6765\u653f\u6cbb\u504f\u89c1\u6d4b\u91cf\u548c\u7f13\u89e3\u7b56\u7565\u8bbe\u8ba1\u4ea7\u751f\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2508.09767", "categories": ["cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2508.09767", "abs": "https://arxiv.org/abs/2508.09767", "authors": ["Shuhei Kato"], "title": "UtterTune: LoRA-Based Target-Language Pronunciation Edit and Control in Multilingual Text-to-Speech", "comment": null, "summary": "We propose UtterTune, a lightweight adaptation method that fine-tunes a\nmultilingual text-to-speech (TTS) system based on a large language model (LLM)\narchitecture, designed to enhance the controllability of pronunciation in a\ntarget language while preserving performance in others. While LLM architectures\nhave enabled TTS models to achieve remarkable naturalness, accurately modeling\ngrapheme-to-phoneme (G2P) mapping and prosody remains challenging, especially\nwhen the model omits an explicit G2P module and directly processes minimally\nencoded text (e.g., byte-pair encoding). UtterTune leverages low-rank\nadaptation to enable the control of segmental pronunciation and pitch accent at\nthe phoneme level for Japanese speech, the target language in this paper, while\nmaintaining naturalness and speaker similarity in a zero-shot setting.\nObjective and subjective evaluations confirm its effectiveness.", "AI": {"tldr": "UtterTune\u662f\u4e00\u79cd\u9762\u5411\u591a\u8bed\u79cdTTS\u7684\u8f7b\u91cf\u9002\u914d\u65b9\u6cd5\uff0c\u53ef\u7ec6\u81f4\u63a7\u5236\u76ee\u6807\u8bed\u8a00\uff08\u5982\u65e5\u8bed\uff09\u7684\u53d1\u97f3\u548c\u8bed\u8c03\uff0c\u540c\u65f6\u4e0d\u5f71\u54cd\u5176\u5b83\u8bed\u8a00\u7684\u8868\u73b0\uff0c\u7ecf\u591a\u9879\u8bc4\u6d4b\u8bc1\u5b9e\u5176\u5b9e\u7528\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u67b6\u6784\u63d0\u5347\u4e86TTS\u7684\u81ea\u7136\u5ea6\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u663e\u5f0f\u7684\u5b57\u6bcd\u5230\u97f3\u7d20\uff08G2P\uff09\u6a21\u5757\uff0c\u76f4\u63a5\u5bf9\u6700\u7b80\u7f16\u7801\u6587\u672c\u8fdb\u884c\u5904\u7406\u65f6\u96be\u4ee5\u7cbe\u51c6\u5efa\u6a21G2P\u6620\u5c04\u548c\u8bed\u8c03\uff0c\u5c24\u5176\u5f71\u54cd\u7279\u5b9a\u8bed\u8a00\u7684\u53d1\u97f3\u53ef\u63a7\u6027\u3002\u4e9f\u9700\u65b9\u6cd5\u63d0\u5347\u76ee\u6807\u8bed\u8a00\u53ef\u63a7\u6027\u540c\u65f6\u517c\u987e\u591a\u8bed\u8a00\u6027\u80fd\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u67b6\u6784\u7684\u591a\u8bed\u79cdTTS\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f4e\u79e9\u9002\u914d\uff08low-rank adaptation\uff09\u65b9\u6cd5\u8c03\u6574\u6a21\u578b\u53c2\u6570\uff0c\u5b9e\u73b0\u5bf9\u53d1\u97f3\u548c\u8bed\u8c03\u7684\u7ec6\u81f4\u63a7\u5236\uff0c\u5c24\u5176\u9488\u5bf9\u65e5\u8bed\u8bed\u97f3\u7684\u97f3\u7d20\u7ea7\u522b\u53d1\u97f3\u548c\u97f3\u9ad8\u91cd\u97f3\u3002", "result": "UtterTune \u5b9e\u73b0\u4e86\u5bf9\u65e5\u8bed\u8bed\u97f3\u53d1\u97f3\u548c\u97f3\u9ad8\u7684\u7cbe\u7ec6\u63a7\u5236\uff0c\u63d0\u5347\u4e86\u76ee\u6807\u8bed\u8a00\u53d1\u97f3\u53ef\u63a7\u6027\uff0c\u5728\u591a\u8bed\u8a00\u573a\u666f\u4e0b\u4e0d\u635f\u5931\u5176\u4ed6\u8bed\u8a00\u7684\u81ea\u7136\u5ea6\u548c\u8bf4\u8bdd\u4eba\u4e00\u81f4\u6027\uff0c\u7ecf\u5ba2\u89c2\u548c\u4e3b\u89c2\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u3002", "conclusion": "UtterTune \u80fd\u591f\u6709\u9009\u62e9\u6027\u5730\u63d0\u5347\u76ee\u6807\u8bed\u8a00\uff08\u5982\u65e5\u8bed\uff09\u7684\u53d1\u97f3\u53ef\u63a7\u6027\uff0c\u540c\u65f6\u5728\u5176\u4ed6\u8bed\u8a00\u4fdd\u6301\u8868\u73b0\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u5b9a\u4e0b\u4ecd\u80fd\u7ef4\u6301\u8bed\u97f3\u7684\u81ea\u7136\u6027\u548c\u8bf4\u8bdd\u4eba\u76f8\u4f3c\u5ea6\u3002\u5ba2\u89c2\u548c\u4e3b\u89c2\u8bc4\u6d4b\u5747\u8bc1\u5b9e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2508.09776", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09776", "abs": "https://arxiv.org/abs/2508.09776", "authors": ["Mahdi Dhaini", "Juraj Vladika", "Ege Erdogan", "Zineb Attaoui", "Gjergji Kasneci"], "title": "Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study", "comment": "Accepted to the 34th International Conference on Artificial Neural\n  Networks (ICANN 2025)", "summary": "In the rapidly evolving field of Explainable Natural Language Processing\n(NLP), textual explanations, i.e., human-like rationales, are pivotal for\nexplaining model predictions and enriching datasets with interpretable labels.\nTraditional approaches rely on human annotation, which is costly,\nlabor-intensive, and impedes scalability. In this work, we present an automated\nframework that leverages multiple state-of-the-art large language models (LLMs)\nto generate high-quality textual explanations. We rigorously assess the quality\nof these LLM-generated explanations using a comprehensive suite of Natural\nLanguage Generation (NLG) metrics. Furthermore, we investigate the downstream\nimpact of these explanations on the performance of pre-trained language models\n(PLMs) and LLMs across natural language inference tasks on two diverse\nbenchmark datasets. Our experiments demonstrate that automated explanations\nexhibit highly competitive effectiveness compared to human-annotated\nexplanations in improving model performance. Our findings underscore a\npromising avenue for scalable, automated LLM-based textual explanation\ngeneration for extending NLP datasets and enhancing model performance.", "AI": {"tldr": "\u63d0\u51fa\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210NLP\u6a21\u578b\u7684\u6587\u672c\u89e3\u91ca\uff0c\u8bc1\u660e\u5176\u9ad8\u6548\u4e14\u53ef\u66ff\u4ee3\u4eba\u5de5\u6807\u6ce8\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u6a21\u578b\u8868\u73b0\uff0c\u4e3a\u6570\u636e\u6269\u5145\u548c\u6a21\u578b\u4f18\u5316\u63d0\u4f9b\u65b0\u9014\u5f84\u3002", "motivation": "\u5728\u53ef\u89e3\u91ca\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u9886\u57df\uff0c\u6a21\u578b\u9884\u6d4b\u7684\u6587\u672c\u89e3\u91ca\uff08\u7c7b\u4f3c\u4eba\u7c7b\u7684\u63a8\u7406\uff09\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u6269\u5c55\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u6587\u672c\u89e3\u91ca\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u5229\u7528\u591a\u4e2a\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6765\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u6587\u672c\u89e3\u91ca\uff0c\u5e76\u7528\u591a\u79cd\u81ea\u7136\u8bed\u8a00\u751f\u6210\uff08NLG\uff09\u6307\u6807\u4e25\u683c\u8bc4\u4f30\u89e3\u91ca\u8d28\u91cf\u3002\u8fdb\u4e00\u6b65\u63a2\u7d22\u8fd9\u4e9b\u81ea\u52a8\u751f\u6210\u7684\u89e3\u91ca\u5bf9\u4e0d\u540cNLP\u4efb\u52a1\u4e2d\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u548cLLM\u6027\u80fd\u7684\u5f71\u54cd\u3002\u5b9e\u9a8c\u6db5\u76d6\u4e24\u4e2a\u591a\u6837\u5316\u7684\u57fa\u51c6\u6570\u636e\u96c6\u3002", "result": "\u81ea\u52a8\u5316\u751f\u6210\u7684\u6587\u672c\u89e3\u91ca\u5728\u63d0\u5347\u6a21\u578b\u6027\u80fd\u65b9\u9762\u4e0e\u4eba\u5de5\u6807\u6ce8\u89e3\u91ca\u8868\u73b0\u51fa\u9ad8\u5ea6\u7ade\u4e89\u529b\u3002", "conclusion": "\u901a\u8fc7LLM\u81ea\u52a8\u751f\u6210\u89e3\u91ca\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u4e30\u5bccNLP\u6570\u636e\u96c6\u5e76\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2508.09786", "categories": ["cs.CL", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.09786", "abs": "https://arxiv.org/abs/2508.09786", "authors": ["Mahdi Dhaini", "Tobias M\u00fcller", "Roksoliana Rabets", "Gjergji Kasneci"], "title": "Adoption of Explainable Natural Language Processing: Perspectives from Industry and Academia on Practices and Challenges", "comment": "Accepted to AAAI/ACM Conference on AI, Ethics, and Society (AIES\n  2025)", "summary": "The field of explainable natural language processing (NLP) has grown rapidly\nin recent years. The growing opacity of complex models calls for transparency\nand explanations of their decisions, which is crucial to understand their\nreasoning and facilitate deployment, especially in high-stakes environments.\nDespite increasing attention given to explainable NLP, practitioners'\nperspectives regarding its practical adoption and effectiveness remain\nunderexplored. This paper addresses this research gap by investigating\npractitioners' experiences with explainability methods, specifically focusing\non their motivations for adopting such methods, the techniques employed,\nsatisfaction levels, and the practical challenges encountered in real-world NLP\napplications. Through a qualitative interview-based study with industry\npractitioners and complementary interviews with academic researchers, we\nsystematically analyze and compare their perspectives. Our findings reveal\nconceptual gaps, low satisfaction with current explainability methods, and\nhighlight evaluation challenges. Our findings emphasize the need for clear\ndefinitions and user-centric frameworks for better adoption of explainable NLP\nin practice.", "AI": {"tldr": "\u53ef\u89e3\u91ca\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u4ece\u4e1a\u8005\u5bf9\u73b0\u6709\u65b9\u6cd5\u6ee1\u610f\u5ea6\u4f4e\uff0c\u5b58\u5728\u8bc4\u4f30\u6311\u6218\u3002\u8bba\u6587\u901a\u8fc7\u8bbf\u8c08\u63ed\u793a\u4e86\u6982\u5ff5\u548c\u8ba4\u77e5\u7684\u5dee\u8ddd\uff0c\u547c\u5401\u5efa\u7acb\u66f4\u5b8c\u5584\u7684\u7528\u6237\u5bfc\u5411\u6846\u67b6\u3002", "motivation": "\u76ee\u524d\u590d\u6742\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6a21\u578b\u7684\u4e0d\u53ef\u89e3\u91ca\u6027\u8d8a\u6765\u8d8a\u9ad8\uff0c\u5c24\u5176\u5728\u5173\u952e\u5e94\u7528\u9886\u57df\u9700\u8981\u66f4\u9ad8\u7684\u900f\u660e\u5ea6\u548c\u89e3\u91ca\u6027\uff0c\u4f46\u5b9e\u9645\u4ece\u4e1a\u8005\u5bf9\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u7684\u91c7\u7528\u548c\u6709\u6548\u6027\u8ba4\u77e5\u4e0d\u8db3\u3002\u8be5\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u8bba\u6587\u91c7\u7528\u5b9a\u6027\u8bbf\u8c08\u7814\u7a76\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u4e1a\u754c\u4ece\u4e1a\u8005\u4ee5\u53ca\u5b66\u672f\u7814\u7a76\u8005\u7684\u7cfb\u7edf\u8bbf\u8c08\uff0c\u5206\u6790\u4ed6\u4eec\u5bf9\u4e8e\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u7684\u52a8\u673a\u3001\u5b9e\u9645\u4f7f\u7528\u6280\u672f\u3001\u6ee1\u610f\u5ea6\u4ee5\u53ca\u9762\u4e34\u7684\u6311\u6218\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u4e1a\u754c\u548c\u5b66\u672f\u754c\u5728\u53ef\u89e3\u91caNLP\u4e0a\u7684\u6982\u5ff5\u5dee\u8ddd\uff0c\u4ece\u4e1a\u8005\u5bf9\u76ee\u524d\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u7684\u6ee1\u610f\u5ea6\u8f83\u4f4e\uff0c\u5e76\u4e14\u5b58\u5728\u8bc4\u4f30\u4e0a\u7684\u96be\u70b9\u3002", "conclusion": "\u8bba\u6587\u5f3a\u8c03\u9700\u8981\u6784\u5efa\u66f4\u6e05\u6670\u7684\u5b9a\u4e49\u548c\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u6846\u67b6\uff0c\u4ee5\u63a8\u52a8\u53ef\u89e3\u91caNLP\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2508.09804", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09804", "abs": "https://arxiv.org/abs/2508.09804", "authors": ["Ahmed Masry", "Abhay Puri", "Masoud Hashemi", "Juan A. Rodriguez", "Megh Thakkar", "Khyati Mahajan", "Vikas Yadav", "Sathwik Tejaswi Madhusudhan", "Alexandre Pich\u00e9", "Dzmitry Bahdanau", "Christopher Pal", "David Vazquez", "Enamul Hoque", "Perouz Taslakian", "Sai Rajeswar", "Spandana Gella"], "title": "BigCharts-R1: Enhanced Chart Reasoning with Visual Reinforcement Finetuning", "comment": null, "summary": "Charts are essential to data analysis, transforming raw data into clear\nvisual representations that support human decision-making. Although current\nvision-language models (VLMs) have made significant progress, they continue to\nstruggle with chart comprehension due to training on datasets that lack\ndiversity and real-world authenticity, or on automatically extracted underlying\ndata tables of charts, which can contain numerous estimation errors.\nFurthermore, existing models only rely on supervised fine-tuning using these\nlow-quality datasets, severely limiting their effectiveness. To address these\nissues, we first propose BigCharts, a dataset creation pipeline that generates\nvisually diverse chart images by conditioning the rendering process on\nreal-world charts sourced from multiple online platforms. Unlike purely\nsynthetic datasets, BigCharts incorporates real-world data, ensuring\nauthenticity and visual diversity, while still retaining accurate underlying\ndata due to our proposed replotting process. Additionally, we introduce a\ncomprehensive training framework that integrates supervised fine-tuning with\nGroup Relative Policy Optimization (GRPO)-based reinforcement learning. By\nintroducing novel reward signals specifically designed for chart reasoning, our\napproach enhances model robustness and generalization across diverse chart\nstyles and domains, resulting in a state-of-the-art chart reasoning model,\nBigCharts-R1. Extensive experiments demonstrate that our models surpass\nexisting methods on multiple chart question-answering benchmarks compared to\neven larger open-source and closed-source models.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u8868\u7406\u89e3\u4e0a\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86\u5305\u542b\u771f\u5b9e\u6570\u636e\u548c\u591a\u6837\u89c6\u89c9\u98ce\u683c\u7684BigCharts\u6570\u636e\u96c6\u4e0e\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fe\u8868\u95ee\u7b54\u4efb\u52a1\u7684\u51c6\u786e\u7387\uff0c\u6240\u63d0\u51fa\u7684BigCharts-R1\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u5747\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u56fe\u8868\u7406\u89e3\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u539f\u56e0\u5728\u4e8e\u8bad\u7ec3\u6570\u636e\u96c6\u7f3a\u4e4f\u591a\u6837\u6027\u4e0e\u771f\u5b9e\u6027\uff0c\u4ee5\u53ca\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u4f4e\u8d28\u91cf\u6570\u636e\u96c6\u8fdb\u884c\u6709\u76d1\u7763\u5fae\u8c03\uff0c\u5bfc\u81f4\u6027\u80fd\u53d7\u9650\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86BigCharts\uff0c\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u96c6\u6784\u5efa\u6d41\u7a0b\uff0c\u901a\u8fc7\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u591a\u5e73\u53f0\u6536\u96c6\u7684\u56fe\u8868\u5bf9\u6e32\u67d3\u8fc7\u7a0b\u8fdb\u884c\u6761\u4ef6\u63a7\u5236\uff0c\u751f\u6210\u5177\u6709\u89c6\u89c9\u591a\u6837\u6027\u548c\u771f\u5b9e\u6027\u7684\u56fe\u8868\uff0c\u5e76\u91c7\u7528\u91cd\u65b0\u7ed8\u5236\uff08replotting\uff09\u65b9\u5f0f\u786e\u4fdd\u6570\u636e\u51c6\u786e\u3002\u540c\u65f6\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u7efc\u5408\u6027\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u5c06\u6709\u76d1\u7763\u5fae\u8c03\u4e0e\u57fa\u4e8eGroup Relative Policy Optimization (GRPO)\u7684\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\uff0c\u5e76\u5f15\u5165\u4e13\u95e8\u9488\u5bf9\u56fe\u8868\u63a8\u7406\u7684\u65b0\u5956\u52b1\u4fe1\u53f7\u3002", "result": "\u4f5c\u8005\u63d0\u51fa\u7684BigCharts-R1\u6a21\u578b\u5728\u591a\u4e2a\u56fe\u8868\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u8d85\u8d8a\u4e86\u73b0\u6709\u4e3b\u6d41\u751a\u81f3\u66f4\u5927\u578b\u7684\u5f00\u6e90\u53ca\u95ed\u6e90\u6a21\u578b\uff0c\u663e\u793a\u51fa\u66f4\u5f3a\u7684\u7a33\u5065\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "BigCharts\u6570\u636e\u96c6\u548c\u8bad\u7ec3\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u56fe\u8868\u63a8\u7406\u76f8\u5173\u6a21\u578b\u7684\u6027\u80fd\u4e0e\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u7684\u56fe\u8868\u7406\u89e3\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09809", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09809", "abs": "https://arxiv.org/abs/2508.09809", "authors": ["Aishik Mandal", "Prottay Kumar Adhikary", "Hiba Arnaout", "Iryna Gurevych", "Tanmoy Chakraborty"], "title": "A Comprehensive Survey of Datasets for Clinical Mental Health AI Systems", "comment": "14 pages, 3 figures", "summary": "Mental health disorders are rising worldwide. However, the availability of\ntrained clinicians has not scaled proportionally, leaving many people without\nadequate or timely support. To bridge this gap, recent studies have shown the\npromise of Artificial Intelligence (AI) to assist mental health diagnosis,\nmonitoring, and intervention. However, the development of efficient, reliable,\nand ethical AI to assist clinicians is heavily dependent on high-quality\nclinical training datasets. Despite growing interest in data curation for\ntraining clinical AI assistants, existing datasets largely remain scattered,\nunder-documented, and often inaccessible, hindering the reproducibility,\ncomparability, and generalizability of AI models developed for clinical mental\nhealth care. In this paper, we present the first comprehensive survey of\nclinical mental health datasets relevant to the training and development of\nAI-powered clinical assistants. We categorize these datasets by mental\ndisorders (e.g., depression, schizophrenia), data modalities (e.g., text,\nspeech, physiological signals), task types (e.g., diagnosis prediction, symptom\nseverity estimation, intervention generation), accessibility (public,\nrestricted or private), and sociocultural context (e.g., language and cultural\nbackground). Along with these, we also investigate synthetic clinical mental\nhealth datasets. Our survey identifies critical gaps such as a lack of\nlongitudinal data, limited cultural and linguistic representation, inconsistent\ncollection and annotation standards, and a lack of modalities in synthetic\ndata. We conclude by outlining key challenges in curating and standardizing\nfuture datasets and provide actionable recommendations to facilitate the\ndevelopment of more robust, generalizable, and equitable mental health AI\nsystems.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u68b3\u7406\u4e86\u4e34\u5e8a\u5fc3\u7406\u5065\u5eb7AI\u8bad\u7ec3\u7528\u7684\u6570\u636e\u96c6\uff0c\u6307\u51fa\u6570\u636e\u7eb5\u6df1\u3001\u6587\u5316\u8986\u76d6\u548c\u6807\u51c6\u5316\u7b49\u4e0d\u8db3\uff0c\u5e76\u7ed9\u51fa\u63a8\u52a8AI\u7cfb\u7edf\u66f4\u5065\u58ee\u53d1\u5c55\u7684\u5efa\u8bae\u3002", "motivation": "\u5168\u7403\u5fc3\u7406\u5065\u5eb7\u969c\u788d\u4eba\u6570\u4e0a\u5347\uff0c\u4f46\u4e13\u4e1a\u4e34\u5e8a\u533b\u5e08\u6570\u91cf\u672a\u80fd\u540c\u6b65\u589e\u957f\uff0c\u5bfc\u81f4\u8bb8\u591a\u4eba\u65e0\u6cd5\u83b7\u5f97\u8db3\u591f\u6216\u53ca\u65f6\u7684\u652f\u6301\u3002\u4eba\u5de5\u667a\u80fd\u6709\u671b\u534f\u52a9\u5fc3\u7406\u5065\u5eb7\u7684\u8bca\u65ad\u4e0e\u5e72\u9884\uff0c\u4f46\u9ad8\u8d28\u91cf\u4e34\u5e8a\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u7f3a\u4e4f\u4e25\u91cd\u963b\u788d\u4e86AI\u7cfb\u7edf\u7684\u53d1\u5c55\u3002", "method": "\u672c\u6587\u9996\u6b21\u5bf9\u7528\u4e8e\u8bad\u7ec3\u548c\u5f00\u53d1AI\u4e34\u5e8a\u52a9\u624b\u7684\u4e34\u5e8a\u5fc3\u7406\u5065\u5eb7\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u5168\u9762\u68b3\u7406\u548c\u8c03\u67e5\u3002\u6309\u5fc3\u7406\u969c\u788d\u7c7b\u522b\u3001\u6570\u636e\u6a21\u6001\u3001\u4efb\u52a1\u7c7b\u578b\u3001\u53ef\u83b7\u53d6\u6027\u53ca\u793e\u4f1a\u6587\u5316\u80cc\u666f\u7b49\u7ef4\u5ea6\u5f52\u7c7b\uff0c\u5e76\u6d89\u53ca\u5408\u6210\u6570\u636e\u96c6\uff0c\u8bc6\u522b\u6570\u636e\u5c42\u9762\u7684\u5173\u952e\u95ee\u9898\u3002", "result": "\u8c03\u67e5\u63ed\u793a\u5b58\u5728\u6570\u636e\u7eb5\u5411\u6027\u4e0d\u8db3\u3001\u6587\u5316\u4e0e\u8bed\u8a00\u8986\u76d6\u6709\u9650\u3001\u91c7\u96c6\u4e0e\u6807\u6ce8\u6807\u51c6\u4e0d\u4e00\u81f4\uff0c\u5408\u6210\u6570\u636e\u6a21\u6001\u7f3a\u5931\u7b49\u5173\u952e\u6f0f\u6d1e\u3002", "conclusion": "\u901a\u8fc7\u7efc\u8ff0\u73b0\u6709\u6570\u636e\u96c6\u548c\u5173\u952e\u6311\u6218\uff0c\u63d0\u51fa\u672a\u6765\u6570\u636e\u96c6\u8bbe\u8ba1\u53ca\u6807\u51c6\u5316\u7684\u5efa\u8bae\uff0c\u4ee5\u4fc3\u8fdb\u66f4\u5f3a\u5065\u3001\u53ef\u63a8\u5e7f\u548c\u516c\u5e73\u7684\u5fc3\u7406\u5065\u5eb7AI\u7cfb\u7edf\u53d1\u5c55\u3002"}}
{"id": "2508.09834", "categories": ["cs.CL", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.09834", "abs": "https://arxiv.org/abs/2508.09834", "authors": ["Weigao Sun", "Jiaxi Hu", "Yucheng Zhou", "Jusen Du", "Disen Lan", "Kexin Wang", "Tong Zhu", "Xiaoye Qu", "Yu Zhang", "Xiaoyu Mo", "Daizong Liu", "Yuxuan Liang", "Wenliang Chen", "Guoqi Li", "Yu Cheng"], "title": "Speed Always Wins: A Survey on Efficient Architectures for Large Language Models", "comment": "Survey, 82 pages, GitHub:\n  https://github.com/weigao266/Awesome-Efficient-Arch", "summary": "Large Language Models (LLMs) have delivered impressive results in language\nunderstanding, generation, reasoning, and pushes the ability boundary of\nmultimodal models. Transformer models, as the foundation of modern LLMs, offer\na strong baseline with excellent scaling properties. However, the traditional\ntransformer architecture requires substantial computations and poses\nsignificant obstacles for large-scale training and practical deployment. In\nthis survey, we offer a systematic examination of innovative LLM architectures\nthat address the inherent limitations of transformers and boost the efficiency.\nStarting from language modeling, this survey covers the background and\ntechnical details of linear and sparse sequence modeling methods, efficient\nfull attention variants, sparse mixture-of-experts, hybrid model architectures\nincorporating the above techniques, and emerging diffusion LLMs. Additionally,\nwe discuss applications of these techniques to other modalities and consider\ntheir wider implications for developing scalable, resource-aware foundation\nmodels. By grouping recent studies into the above category, this survey\npresents a blueprint of modern efficient LLM architectures, and we hope this\ncould help motivate future research toward more efficient, versatile AI\nsystems.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u4e3a\u89e3\u51b3Transformer\u8ba1\u7b97\u74f6\u9888\u800c\u53d1\u5c55\u7684\u9ad8\u6548LLM\u67b6\u6784\uff0c\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u5404\u7c7b\u65b0\u65b9\u6cd5\u53ca\u5176\u5728\u591a\u6a21\u6001\u7b49\u9886\u57df\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u9ad8\u6548AI\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5e95\u5c42\u7684Transformer\u67b6\u6784\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u5f71\u54cd\u5927\u89c4\u6a21\u8bad\u7ec3\u4e0e\u5b9e\u9645\u90e8\u7f72\u3002\u8feb\u5207\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b0\u578b\u67b6\u6784\u63d0\u5347\u5b9e\u7528\u6027\u3002", "method": "\u672c\u6587\u4e3a\u7efc\u8ff0\u6027\u8bba\u6587\uff0c\u7cfb\u7edf\u68b3\u7406LLM\u67b6\u6784\u7684\u521b\u65b0\u6539\u8fdb\uff0c\u6db5\u76d6\u7ebf\u6027\u4e0e\u7a00\u758f\u5e8f\u5217\u6a21\u578b\u3001\u9ad8\u6548\u5168\u6ce8\u610f\u529b\u53d8\u4f53\u3001\u7a00\u758f\u4e13\u5bb6\u6df7\u5408\u67b6\u6784\u3001\u6df7\u5408\u578b\u6a21\u578b\u4ee5\u53ca\u65b0\u5174\u6269\u6563\u6a21\u578b\uff0c\u5e76\u63a2\u8ba8\u8fd9\u4e9b\u6280\u672f\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u8be5\u8bba\u6587\u5c06\u8fd1\u5e74\u9ad8\u6548LLM\u67b6\u6784\u7814\u7a76\u5206\u95e8\u522b\u7c7b\uff0c\u8be6\u7ec6\u4ecb\u7ecd\u6bcf\u7c7b\u65b9\u6cd5\u7684\u539f\u7406\u4e0e\u5e94\u7528\u73b0\u72b6\uff0c\u5256\u6790\u5176\u5728\u6784\u5efa\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u57fa\u7840\u6a21\u578b\u4e2d\u7684\u4f5c\u7528\u548c\u6f5c\u529b\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u68b3\u7406\u5f53\u524d\u9ad8\u6548LLM\u67b6\u6784\u53d1\u5c55\u56fe\u8c31\uff0c\u672c\u6587\u4e3a\u540e\u7eed\u7814\u7a76\u9ad8\u6548\u3001\u901a\u7528AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u4e0e\u601d\u8def\u6307\u5f15\u3002"}}
{"id": "2508.09848", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09848", "abs": "https://arxiv.org/abs/2508.09848", "authors": ["Mo Yu", "Tsz Ting Chung", "Chulun Zhou", "Tong Li", "Rui Lu", "Jiangnan Li", "Liyan Xu", "Haoshu Lu", "Ning Zhang", "Jing Li", "Jie Zhou"], "title": "PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts", "comment": "First 7 authors contributed equally. Project page:\n  https://gorov.github.io/prelude", "summary": "We introduce PRELUDE, a benchmark for evaluating long-context understanding\nthrough the task of determining whether a character's prequel story is\nconsistent with the canonical narrative of the original book. Our task poses a\nstronger demand for global comprehension and deep reasoning than existing\nbenchmarks -- as the prequels are not part of the original story, assessing\ntheir plausibility typically requires searching and integrating information\nthat is only indirectly related. Empirically, 88% of instances require evidence\nfrom multiple parts of the narrative. Experimental results highlight the\nchallenge of our task: in-context learning, RAG and in-domain training with\nstate-of-the-art LLMs, and commercial DeepResearch services, lag behind humans\nby >15%. A further human study reveals that models often produce correct\nanswers with flawed reasoning, leading to an over 30% gap in reasoning accuracy\ncompared to humans. These findings underscore the substantial room for\nimprovement in long-context understanding and reasoning.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51faPRELUDE\u57fa\u51c6\uff0c\u7528\u4e8e\u6d4b\u8bd5\u957f\u7bc7\u6587\u672c\u7406\u89e3\u548c\u63a8\u7406\uff0c\u53d1\u73b0\u4e3b\u6d41\u6a21\u578b\u8fdc\u900a\u4e8e\u4eba\u7c7b\uff0c\u5c24\u5176\u662f\u5728\u63a8\u7406\u80fd\u529b\u4e0a\uff0c\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u4ecd\u5177\u6709\u5f88\u5927\u8fdb\u6b65\u7a7a\u95f4\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u80fd\u6709\u6548\u8bc4\u4ef7\u6a21\u578b\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u4e0e\u6df1\u5ea6\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\u4efb\u52a1\u3002\u4e3a\u63a8\u52a8\u8be5\u9886\u57df\u53d1\u5c55\uff0c\u9700\u8981\u8bbe\u8ba1\u66f4\u5177\u6311\u6218\u6027\u7684\u57fa\u51c6\uff0c\u5bf9\u6a21\u578b\u63d0\u51fa\u66f4\u9ad8\u8981\u6c42\u3002", "method": "\u63d0\u51faPRELUDE\u57fa\u51c6\uff0c\u901a\u8fc7\u5224\u65ad\u4e00\u4e2a\u89d2\u8272\u7684\u524d\u4f20\u6545\u4e8b\u4e0e\u539f\u8457\u6b63\u5178\u53d9\u4e8b\u662f\u5426\u4e00\u81f4\u7684\u65b9\u6cd5\uff0c\u6765\u8bc4\u4f30\u6a21\u578b\u7684\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u3002\u5bf9\u6bd4\u4e86\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001RAG\u3001\u9886\u57df\u5185\u8bad\u7ec3\u7b49\u591a\u79cd\u65b9\u5f0f\u4e0b\uff0c\u4e0e\u4eba\u7c7b\u7684\u5dee\u8ddd\u3002\u540c\u65f6\u8fdb\u884c\u4e86\u4eba\u7c7b\u7814\u7a76\u4ee5\u5206\u6790\u6a21\u578b\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0c\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u6a21\u578b\u548c\u6df1\u5ea6\u7814\u7a76\u670d\u52a1\uff0c\u5176\u51c6\u786e\u7387\u4ecd\u6bd4\u4eba\u7c7b\u4f4e15%\u4ee5\u4e0a\u3002\u540c\u65f6\uff0c\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u6b63\u786e\u6027\u4e0e\u4eba\u7c7b\u76f8\u6bd4\u5dee\u8ddd\u66f4\u5927\uff0c\u8868\u73b0\u4e3a\u63a8\u7406\u51c6\u786e\u7387\u843d\u540e30%\u4ee5\u4e0a\u3002\u5927\u90e8\u5206\u4efb\u52a1\u9700\u8981\u6574\u5408\u591a\u6bb5\u4fe1\u606f\u624d\u80fd\u505a\u51fa\u5224\u65ad\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5f53\u524d\u4e3b\u6d41\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u6df1\u5ea6\u7814\u7a76\u670d\u52a1\u5728\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u4e0e\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u660e\u663e\u843d\u540e\u4e8e\u4eba\u7c7b\uff0c\u63a8\u7406\u51c6\u786e\u7387\u4e5f\u5b58\u5728\u8f83\u5927\u5dee\u8ddd\uff0c\u663e\u793a\u8fd9\u4e00\u9886\u57df\u4ecd\u6709\u5f88\u5927\u63d0\u5347\u7a7a\u95f4\u3002"}}
{"id": "2508.09865", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09865", "abs": "https://arxiv.org/abs/2508.09865", "authors": ["Abdul Rehman Antall", "Naveed Akhtar"], "title": "Assessing the Feasibility of Lightweight Whisper Models for Low-Resource Urdu Transcription", "comment": "8 pages, 3 figures, 1 table, including references and appendix", "summary": "This study evaluates the feasibility of lightweight Whisper models (Tiny,\nBase, Small) for Urdu speech recognition in low-resource settings. Despite Urdu\nbeing the 10th most spoken language globally with over 230 million speakers,\nits representation in automatic speech recognition (ASR) systems remains\nlimited due to dialectal diversity, code-switching, and sparse training data.\nWe benchmark these models on a curated Urdu dataset using word error rate\n(WER), without fine-tuning. Results show Whisper-Small achieves the lowest\nerror rates (33.68\\% WER), outperforming Tiny (67.08\\% WER) and Base (53.67\\%\nWER). Qualitative analysis reveals persistent challenges in phonetic accuracy\nand lexical coherence, particularly for complex utterances. While Whisper-Small\ndemonstrates promise for deployable Urdu ASR, significant gaps remain. Our\nfindings emphasize lay the groundwork for future research into effective,\nlow-resource ASR systems.", "AI": {"tldr": "Whisper-Small\u6a21\u578b\u5728\u65e0\u5fae\u8c03\u60c5\u51b5\u4e0b\u5bf9\u4e4c\u5c14\u90fd\u8bed\u8bc6\u522b\u6709\u8f83\u597d\u8868\u73b0\uff0c\u4f46\u6574\u4f53\u4f9d\u7136\u9762\u4e34\u51c6\u786e\u7387\u53ca\u590d\u6742\u8bed\u53e5\u5904\u7406\u7b49\u6311\u6218\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u79cdASR\u7814\u7a76\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u5c3d\u7ba1\u4e4c\u5c14\u90fd\u8bed\u662f\u5168\u7403\u7b2c\u5341\u591a\u4f7f\u7528\u7684\u8bed\u8a00\uff082.3\u4ebf\u4f7f\u7528\u8005\uff09\uff0c\u4f46\u56e0\u65b9\u8a00\u591a\u6837\u3001\u4ee3\u7801\u6df7\u5408\u548c\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\uff0c\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u7cfb\u7edf\u5bf9\u4e4c\u5c14\u90fd\u8bed\u7684\u652f\u6301\u4ecd\u6709\u9650\u3002", "method": "\u5728\u672a\u8fdb\u884c\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528Whisper\u5bb6\u65cf\u4e2d\u7684\u4e09\u79cd\u8f7b\u91cf\u7ea7\u6a21\u578b\uff08Tiny\u3001Base\u3001Small\uff09\u5728\u6574\u7406\u7684\u4e4c\u5c14\u90fd\u8bed\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u91c7\u7528\u8bcd\u9519\u8bef\u7387\uff08WER\uff09\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807; \u5e76\u7ed3\u5408\u5b9a\u6027\u5206\u6790\uff0c\u6df1\u5165\u63a2\u8ba8\u8bc6\u522b\u4e2d\u51fa\u73b0\u7684\u95ee\u9898\u3002", "result": "Whisper-Small\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0cWER\u4e3a33.68%\uff0c\u4f18\u4e8eBase\uff0853.67%\uff09\u548cTiny\uff0867.08%\uff09\u3002\u7136\u800c\uff0c\u6a21\u578b\u5728\u8bed\u97f3\u548c\u8bcd\u6c47\u4e00\u81f4\u6027\u4e0a\u4ecd\u6709\u660e\u663e\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u8bed\u53e5\u4e0a\u3002", "conclusion": "Whisper-Small\u6a21\u578b\u4e3a\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u4e4c\u5c14\u90fd\u8bedASR\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u6848\uff0c\u4f46\u5f53\u524d\u6a21\u578b\u4ecd\u5b58\u5728\u663e\u8457\u6539\u8fdb\u7a7a\u95f4\uff0c\u540e\u7eed\u7814\u7a76\u6709\u671b\u8fdb\u4e00\u6b65\u63d0\u5347\u7cfb\u7edf\u8868\u73b0\u3002"}}
{"id": "2508.09874", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.09874", "abs": "https://arxiv.org/abs/2508.09874", "authors": ["Jiaqi Cao", "Jiarui Wang", "Rubin Wei", "Qipeng Guo", "Kai Chen", "Bowen Zhou", "Zhouhan Lin"], "title": "Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) have shown strong abilities in general language\ntasks, yet adapting them to specific domains remains a challenge. Current\nmethod like Domain Adaptive Pretraining (DAPT) requires costly full-parameter\ntraining and suffers from catastrophic forgetting. Meanwhile,\nRetrieval-Augmented Generation (RAG) introduces substantial inference latency\ndue to expensive nearest-neighbor searches and longer context. This paper\nintroduces Memory Decoder, a plug-and-play pretrained memory that enables\nefficient domain adaptation without changing the original model's parameters.\nMemory Decoder employs a small transformer decoder that learns to imitate the\nbehavior of an external non-parametric retriever. Once trained, Memory Decoder\ncan be seamlessly integrated with any pretrained language model that shares the\nsame tokenizer, requiring no model-specific modifications. Experimental results\ndemonstrate that Memory Decoder enables effective adaptation of various Qwen\nand Llama models to three distinct specialized domains: biomedicine, finance,\nand law, reducing perplexity by an average of 6.17 points. Overall, Memory\nDecoder introduces a novel paradigm centered on a specially pretrained memory\ncomponent designed for domain-specific adaptation. This memory architecture can\nbe integrated in a plug-and-play manner, consistently enhancing performance\nacross multiple models within the target domain.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMemory Decoder\uff0c\u901a\u8fc7\u53ef\u63d2\u62d4\u7684\u9884\u8bad\u7ec3\u8bb0\u5fc6\u6a21\u5757\u5b9e\u73b0\u9ad8\u6548\u3001\u65e0\u53c2\u6570\u4fee\u6539\u7684\u9886\u57df\u9002\u5e94\u65b9\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u5927\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u901a\u7528\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5c06\u5176\u9ad8\u6548\u9002\u5e94\u5230\u7279\u5b9a\u9886\u57df\u4f9d\u7136\u9762\u4e34\u6311\u6218\u3002\u5f53\u524d\u7684\u4e3b\u6d41\u65b9\u6cd5\u5982DAPT\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u4e14\u5b58\u5728\u9057\u5fd8\u95ee\u9898\uff0cRAG\u5219\u63a8\u9ad8\u4e86\u63a8\u7406\u5ef6\u8fdf\u3002", "method": "\u63d0\u51faMemory Decoder\u2014\u2014\u4e00\u79cd\u9884\u8bad\u7ec3\u8bb0\u5fc6\u6a21\u5757\u3002\u8be5\u6a21\u5757\u901a\u8fc7\u4e00\u4e2a\u5c0f\u578btransformer decoder\u6a21\u62df\u975e\u53c2\u6570\u68c0\u7d22\u5668\u884c\u4e3a\uff0c\u4e0e\u539f\u59cb\u6a21\u578b\u65e0\u7f1d\u96c6\u6210\u4e14\u65e0\u9700\u4fee\u6539\u5176\u53c2\u6570\uff0c\u53ea\u8981tokenizer\u517c\u5bb9\u5373\u53ef\u3002", "result": "Memory Decoder\u88ab\u5e94\u7528\u5728\u591a\u79cdQwen\u548cLlama\u6a21\u578b\uff0c\u5e76\u5728\u751f\u7269\u533b\u5b66\u3001\u91d1\u878d\u548c\u6cd5\u5f8b\u4e09\u5927\u4e13\u95e8\u9886\u57df\u4e0a\u6d4b\u8bd5\uff0c\u6709\u6548\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u9002\u5e94\u6027\uff0c\u5e73\u5747\u56f0\u60d1\u5ea6\u964d\u4f4e6.17\u5206\u3002", "conclusion": "Memory Decoder\u4e3a\u9886\u57df\u9002\u5e94\u63d0\u51fa\u4e86\u65b0\u7684\u8303\u5f0f\uff0c\u901a\u8fc7\u53ef\u63d2\u62d4\u7684\u9884\u8bad\u7ec3\u8bb0\u5fc6\u67b6\u6784\uff0c\u6781\u5927\u7b80\u5316\u4e86\u9886\u57df\u9002\u5e94\u8fc7\u7a0b\uff0c\u5e76\u80fd\u5728\u591a\u4e2a\u4e3b\u6d41\u6a21\u578b\u548c\u9886\u57df\u4e0a\u5747\u5e26\u6765\u4e00\u81f4\u6027\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2508.09878", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09878", "abs": "https://arxiv.org/abs/2508.09878", "authors": ["Archie Sage", "Jeroen Keppens", "Helen Yannakoudakis"], "title": "A Survey of Cognitive Distortion Detection and Classification in NLP", "comment": "Under review via ACL Rolling Review and committed to EMNLP 2025.\n  Camera-ready updates to follow", "summary": "As interest grows in the application of natural language processing (NLP)\ntechniques to mental health, a growing body of work explores the automatic\ndetection and classification of cognitive distortions (CDs). CDs are habitual\npatterns of negatively biased or flawed thinking that distort how people\nperceive events, judge themselves, and react to the world around them.\nIdentifying and addressing them is an important part of therapy. Despite its\nmomentum, the field remains fragmented, with inconsistencies in CD taxonomies,\ntask formulations, and evaluation practices. This survey reviews 38 studies\nspanning two decades, providing a structured overview of datasets, modelling\napproaches, and evaluation strategies. We provide a consolidated CD taxonomy\nreference, summarise common task setups, and highlight open challenges to\nsupport more coherent and reproducible research in this emerging area.", "AI": {"tldr": "\u968f\u7740NLP\u5728\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u8ba4\u77e5\u504f\u5dee\u81ea\u52a8\u68c0\u6d4b\u6210\u4e3a\u70ed\u70b9\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u96f6\u6563\u4e0d\u7edf\u4e00\u3002\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u8fc7\u53bb20\u5e74\u7684\u76f8\u5173\u5de5\u4f5c\uff0c\u63d0\u70bc\u5206\u7c7b\u4f53\u7cfb\u3001\u4efb\u52a1\u8bbe\u5b9a\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u6307\u51fa\u7814\u7a76\u6311\u6218\uff0c\u63a8\u52a8\u9886\u57df\u89c4\u8303\u5316\u53d1\u5c55\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u8d8a\u6765\u8d8a\u591a\u7814\u7a76\u5173\u6ce8\u5c06\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u6280\u672f\u5e94\u7528\u4e8e\u5fc3\u7406\u5065\u5eb7\u9886\u57df\uff0c\u7279\u522b\u662f\u81ea\u52a8\u68c0\u6d4b\u548c\u5206\u7c7b\u8ba4\u77e5\u504f\u5dee\uff08CDs\uff09\u3002\u8ba4\u77e5\u504f\u5dee\u4f1a\u5f71\u54cd\u4eba\u4eec\u5bf9\u4e8b\u4ef6\u3001\u5bf9\u81ea\u6211\u7684\u5224\u65ad\u548c\u5bf9\u5916\u754c\u7684\u53cd\u5e94\uff0c\u662f\u5fc3\u7406\u6cbb\u7597\u4e2d\u4e9f\u9700\u8bc6\u522b\u548c\u5904\u7406\u7684\u91cd\u8981\u90e8\u5206\uff0c\u4f46\u76ee\u524d\u76f8\u5173\u7814\u7a76\u5728\u5206\u7c7b\u4f53\u7cfb\u3001\u4efb\u52a1\u8bbe\u5b9a\u548c\u8bc4\u4f30\u5b9e\u8df5\u4e0a\u8fd8\u5f88\u5206\u6563\u548c\u4e0d\u7edf\u4e00\u3002", "method": "\u672c\u8bba\u6587\u5bf9\u8fc7\u53bb\u4e8c\u5341\u5e74\u5185\u768438\u9879\u76f8\u5173\u7814\u7a76\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u7ed3\u6784\u5316\u5730\u5f52\u7eb3\u4e86\u8fd9\u4e9b\u7814\u7a76\u4f7f\u7528\u7684\u6570\u636e\u96c6\u3001\u5efa\u6a21\u65b9\u6cd5\u548c\u8bc4\u4f30\u7b56\u7565\uff0c\u5e76\u6574\u7406\u878d\u5408\u4e86\u8ba4\u77e5\u504f\u5dee\u7684\u5206\u7c7b\u4f53\u7cfb\u3002", "result": "\u8bba\u6587\u603b\u7ed3\u4e86\u8ba4\u77e5\u504f\u5dee\u5e38\u7528\u7684\u4efb\u52a1\u8bbe\u5b9a\uff0c\u7ed9\u51fa\u7edf\u4e00\u7684CD\u5206\u7c7b\u4f53\u7cfb\u53c2\u8003\uff0c\u5398\u6e05\u9886\u57df\u5185\u7684\u5f00\u653e\u96be\u9898\uff0c\u4e3a\u540e\u7eed\u66f4\u7cfb\u7edf\u3001\u53ef\u590d\u73b0\u6027\u66f4\u5f3a\u7684\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002", "conclusion": "\u901a\u8fc7\u7efc\u8ff0\u548c\u6574\u5408\u73b0\u6709\u6587\u732e\u3001\u63d0\u51fa\u5408\u5e76\u540e\u7684\u6807\u51c6\u5316\u5206\u7c7b\u4f53\u7cfb\u548c\u68b3\u7406\u6311\u6218\uff0c\u672c\u6587\u4e3a\u8ba4\u77e5\u504f\u5deeNLP\u81ea\u52a8\u68c0\u6d4b\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u8d44\u6e90\u548c\u65b9\u5411\u5efa\u8bae\uff0c\u6709\u52a9\u4e8e\u9886\u57df\u7814\u7a76\u66f4\u6807\u51c6\u5316\u3001\u534f\u4f5c\u548c\u6df1\u5165\u3002"}}
{"id": "2508.09935", "categories": ["cs.CL", "q-fin.CP", "q-fin.GN"], "pdf": "https://arxiv.org/pdf/2508.09935", "abs": "https://arxiv.org/abs/2508.09935", "authors": ["Sayem Hossen", "Monalisa Moon Joti", "Md. Golam Rashed"], "title": "Language of Persuasion and Misrepresentation in Business Communication: A Textual Detection Approach", "comment": "21", "summary": "Business communication digitisation has reorganised the process of persuasive\ndiscourse, which\n  allows not only greater transparency but also advanced deception. This\ninquiry synthesises classical\n  rhetoric and communication psychology with linguistic theory and empirical\nstudies in the financial\n  reporting, sustainability discourse, and digital marketing to explain how\ndeceptive language can be\n  systematically detected using persuasive lexicon. In controlled settings,\ndetection accuracies of greater\n  than 99% were achieved by using computational textual analysis as well as\npersonalised transformer\n  models. However, reproducing this performance in multilingual settings is\nalso problematic and,\n  to a large extent, this is because it is not easy to find sufficient data,\nand because few multilingual\n  text-processing infrastructures are in place. This evidence shows that there\nhas been an increasing\n  gap between the theoretical representations of communication and those\nempirically approximated,\n  and therefore, there is a need to have strong automatic text-identification\nsystems where AI-based\n  discourse is becoming more realistic in communicating with humans.", "AI": {"tldr": "\u672c\u7814\u7a76\u878d\u5408\u591a\u5b66\u79d1\u7406\u8bba\uff0c\u63d0\u51fa\u7528\u8bf4\u670d\u6027\u8bcd\u6c47\u68c0\u6d4b\u6b3a\u9a97\u6027\u8bed\u8a00\uff0c\u53d7\u63a7\u73af\u5883\u4e0b\u8bc6\u522b\u51c6\u786e\u7387\u6781\u9ad8\uff0c\u4f46\u591a\u8bed\u8a00\u573a\u666f\u9762\u4e34\u6570\u636e\u4e0e\u5de5\u5177\u74f6\u9888\uff0c\u547c\u5401\u63a8\u52a8\u5f3a\u81ea\u52a8\u8bc6\u522b\u7cfb\u7edf\u4ee5\u5e94\u5bf9AI\u4ea4\u6d41\u6311\u6218\u3002", "motivation": "\u968f\u7740\u5546\u4e1a\u6c9f\u901a\u6570\u5b57\u5316\u53d1\u5c55\uff0c\u4f20\u7edf\u7684\u8bf4\u670d\u6027\u8bdd\u8bed\u7ed3\u6784\u53d1\u751f\u4e86\u6539\u53d8\uff0c\u867d\u7136\u63d0\u5347\u4e86\u900f\u660e\u5ea6\uff0c\u4f46\u4e5f\u8ba9\u9ad8\u7ea7\u6b3a\u9a97\u53d8\u5f97\u5bb9\u6613\u3002\u8fd9\u9700\u8981\u7406\u89e3\u548c\u68c0\u6d4b\u4f7f\u7528\u8bf4\u670d\u6027\u8bcd\u6c47\u8fdb\u884c\u6b3a\u9a97\u7684\u8bed\u8a00\u624b\u6cd5\u3002", "method": "\u5c06\u53e4\u5178\u4fee\u8f9e\u3001\u4f20\u64ad\u5fc3\u7406\u5b66\u4e0e\u8bed\u8a00\u5b66\u7406\u8bba\u76f8\u7ed3\u5408\uff0c\u5229\u7528\u91d1\u878d\u62a5\u544a\u3001\u53ef\u6301\u7eed\u53d1\u5c55\u8bdd\u8bed\u548c\u6570\u5b57\u8425\u9500\u7b49\u9886\u57df\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u91c7\u7528\u8ba1\u7b97\u6587\u672c\u5206\u6790\u548c\u4e2a\u6027\u5316Transformer\u6a21\u578b\u68c0\u6d4b\u6b3a\u9a97\u6027\u8bed\u8a00\u3002", "result": "\u5728\u53d7\u63a7\u73af\u5883\u4e0b\uff0c\u4f7f\u7528\u8ba1\u7b97\u6587\u672c\u5206\u6790\u53ca\u5b9a\u5236\u5316Transformer\u6a21\u578b\uff0c\u6b3a\u9a97\u6027\u8bed\u8a00\u68c0\u6d4b\u51c6\u786e\u7387\u8d85\u8fc799%\u3002\u4f46\u8be5\u65b9\u6cd5\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u6548\u679c\u53d7\u9650\uff0c\u4e3b\u8981\u56e0\u6570\u636e\u4e0d\u8db3\u53ca\u591a\u8bed\u8a00\u6587\u672c\u5904\u7406\u57fa\u7840\u8bbe\u65bd\u532e\u4e4f\u3002", "conclusion": "\u7406\u8bba\u4e0e\u5b9e\u9645\u4e4b\u95f4\u51fa\u73b0\u4e86\u8d8a\u6765\u8d8a\u5927\u7684\u6c9f\u901a\u8868\u793a\u9e3f\u6c9f\uff0c\u968f\u7740AI\u8bdd\u8bed\u7684\u771f\u5b9e\u6027\u63d0\u5347\uff0c\u4e9f\u9700\u5f3a\u5927\u81ea\u52a8\u6587\u672c\u8bc6\u522b\u7cfb\u7edf\u4ee5\u4fdd\u969c\u4eba\u4e0eAI\u6c9f\u901a\u7684\u771f\u5b9e\u6027\u3002"}}
{"id": "2508.09937", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.09937", "abs": "https://arxiv.org/abs/2508.09937", "authors": ["Muneeza Azmat", "Momin Abbas", "Maysa Malfiza Garcia de Macedo", "Marcelo Carpinette Grave", "Luan Soares de Souza", "Tiago Machado", "Rogerio A de Paula", "Raya Horesh", "Yixin Chen", "Heloisa Caroline de Souza Pereira Candello", "Rebecka Nordenlow", "Aminat Adebiyi"], "title": "A Comprehensive Evaluation framework of Alignment Techniques for LLMs", "comment": "In submission", "summary": "As Large Language Models (LLMs) become increasingly integrated into\nreal-world applications, ensuring their outputs align with human values and\nsafety standards has become critical. The field has developed diverse alignment\napproaches including traditional fine-tuning methods (RLHF, instruction\ntuning), post-hoc correction systems, and inference-time interventions, each\nwith distinct advantages and limitations. However, the lack of unified\nevaluation frameworks makes it difficult to systematically compare these\nparadigms and guide deployment decisions. This paper introduces a\nmulti-dimensional evaluation of alignment techniques for LLMs, a comprehensive\nevaluation framework that provides a systematic comparison across all major\nalignment paradigms. Our framework assesses methods along four key dimensions:\nalignment detection, alignment quality, computational efficiency, and\nrobustness. Through experiments across diverse base models and alignment\nstrategies, we demonstrate the utility of our framework in identifying\nstrengths and limitations of current state-of-the-art models, providing\nvaluable insights for future research directions.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u9f50\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u7cfb\u7edf\u6027\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u6a2a\u5411\u6bd4\u8f83\u4e3b\u6d41\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u53ef\u6df1\u5165\u63ed\u793a\u5404\u65b9\u6cd5\u4f18\u52a3\uff0c\u6709\u52a9\u4e8e\u5b89\u5168\u53ef\u9760\u5730\u90e8\u7f72LLMs\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8d8a\u6765\u8d8a\u666e\u53ca\uff0c\u5176\u8f93\u51fa\u9700\u7b26\u5408\u4eba\u7c7b\u4ef7\u503c\u89c2\u548c\u5b89\u5168\u6807\u51c6\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u73b0\u6709\u5404\u79cd\u5bf9\u9f50\u65b9\u6cd5\uff08\u5982RLHF\u3001\u6307\u4ee4\u5fae\u8c03\u3001\u540e\u5904\u7406\u4fee\u6b63\u3001\u63a8\u7406\u65f6\u5e72\u9884\u7b49\uff09\u867d\u5404\u6709\u4f18\u52a3\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5bfc\u81f4\u96be\u4ee5\u7cfb\u7edf\u6027\u6bd4\u8f83\u548c\u90e8\u7f72\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u4e86\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u4ece\u5bf9\u9f50\u68c0\u6d4b\u3001\u5bf9\u9f50\u8d28\u91cf\u3001\u8ba1\u7b97\u6548\u7387\u3001\u9c81\u68d2\u6027\u56db\u4e2a\u5173\u952e\u7ef4\u5ea6\u51fa\u53d1\uff0c\u5bf9\u4e3b\u6d41LLM\u5bf9\u9f50\u65b9\u6cd5\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\uff0c\u901a\u8fc7\u591a\u79cd\u57fa\u7840\u6a21\u578b\u548c\u5bf9\u9f50\u7b56\u7565\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u5c55\u793a\u8be5\u6846\u67b6\u53ef\u6709\u6548\u8bc6\u522b\u5f53\u524d\u4e3b\u6d41\u6a21\u578b\u5728\u5404\u5bf9\u9f50\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\uff0c\u4e3a\u76f8\u5173\u6a21\u578b\u90e8\u7f72\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002", "conclusion": "\u591a\u7ef4\u5ea6\u7edf\u4e00\u8bc4\u4f30\u6846\u67b6\u4f7fLLM\u5bf9\u9f50\u65b9\u6cd5\u80fd\u591f\u88ab\u7cfb\u7edf\u3001\u5168\u9762\u5730\u6bd4\u8f83\u548c\u8bc4\u4f30\uff0c\u6709\u52a9\u4e8e\u9009\u578b\u548c\u63a8\u52a8\u7814\u7a76\u8fdb\u5c55\u3002"}}
{"id": "2508.09945", "categories": ["cs.CL", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.09945", "abs": "https://arxiv.org/abs/2508.09945", "authors": ["Lingjie Jiang", "Shaohan Huang", "Xun Wu", "Yixia Li", "Dongdong Zhang", "Furu Wei"], "title": "VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models", "comment": null, "summary": "Multimodal large language models (MLLMs) have significantly advanced the\nintegration of visual and textual understanding. However, their ability to\ngenerate code from multimodal inputs remains limited. In this work, we\nintroduce VisCodex, a unified framework that seamlessly merges vision and\ncoding language models to empower MLLMs with strong multimodal code generation\nabilities. Leveraging a task vector-based model merging technique, we integrate\na state-of-the-art coding LLM into a strong vision-language backbone, while\npreserving both visual comprehension and advanced coding skills. To support\ntraining and evaluation, we introduce the Multimodal Coding Dataset (MCD), a\nlarge-scale and diverse collection of 598k samples, including high-quality HTML\ncode, chart image-code pairs, image-augmented StackOverflow QA, and algorithmic\nproblems. Furthermore, we propose InfiBench-V, a novel and challenging\nbenchmark specifically designed to assess models on visually-rich, real-world\nprogramming questions that demand a nuanced understanding of both textual and\nvisual contexts. Extensive experiments show that VisCodex achieves\nstate-of-the-art performance among open-source MLLMs and approaches proprietary\nmodels like GPT-4o, highlighting the effectiveness of our model merging\nstrategy and new datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVisCodex\uff0c\u5c06\u89c6\u89c9\u3001\u8bed\u8a00\u548c\u4ee3\u7801\u751f\u6210\u80fd\u529b\u9ad8\u6548\u878d\u5408\uff0c\u5229\u7528\u65b0\u6570\u636e\u96c6\u548c\u8bc4\u6d4b\u57fa\u51c6\uff0c\u663e\u8457\u63d0\u5347\u591a\u6a21\u6001\u4ee3\u7801\u751f\u6210\u8868\u73b0\uff0c\u8fbe\u5230\u751a\u81f3\u903c\u8fd1GPT-4o\u6c34\u5e73\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u89c6\u89c9\u548c\u6587\u672c\u7406\u89e3\u878d\u5408\u65b9\u9762\u53d6\u5f97\u4e86\u91cd\u8981\u8fdb\u5c55\uff0c\u4f46\u5176\u57fa\u4e8e\u591a\u6a21\u6001\u8f93\u5165\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\u4f9d\u7136\u6709\u9650\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3MLLM\u5728\u591a\u6a21\u6001\u4ee3\u7801\u751f\u6210\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51faVisCodex\uff0c\u4e00\u79cd\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u4efb\u52a1\u5411\u91cf\u7684\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\uff0c\u5c06\u5148\u8fdb\u7684\u4ee3\u7801\u751f\u6210LLM\u4e0e\u5f3a\u5927\u7684\u89c6\u89c9-\u8bed\u8a00\u4e3b\u5e72\u7f51\u7edc\u7ed3\u5408\uff0c\u65e2\u4fdd\u7559\u89c6\u89c9\u7406\u89e3\u80fd\u529b\uff0c\u4e5f\u5177\u5907\u9ad8\u7ea7\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002\u540c\u65f6\uff0c\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u591a\u6a21\u6001\u7f16\u7801\u6570\u636e\u96c6\uff08MCD\uff09\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u6d4b\u8bd5\u57fa\u51c6InfiBench-V\u3002", "result": "VisCodex\u5728\u5f00\u6e90MLLMs\u4e2d\u5b9e\u73b0\u4e86\u6700\u4f18\u6027\u80fd\uff0c\u5e76\u63a5\u8fd1GPT-4o\u7b49\u95ed\u6e90\u6a21\u578b\u7684\u6c34\u5e73\u3002\u5b9e\u9a8c\u8bc1\u660e\u6a21\u578b\u878d\u5408\u7b56\u7565\u548c\u65b0\u6570\u636e\u96c6\u6709\u6548\u63d0\u5347\u4e86\u591a\u6a21\u6001\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002", "conclusion": "VisCodex\u6709\u529b\u63a8\u52a8\u4e86\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u9886\u57df\u7684\u53d1\u5c55\uff0c\u901a\u8fc7\u521b\u65b0\u6a21\u578b\u7ed3\u6784\u3001\u4e30\u5bcc\u6570\u636e\u96c6\u53ca\u9488\u5bf9\u6027\u7684\u8bc4\u6d4b\u57fa\u51c6\uff0c\u4e3a\u89c6\u89c9\u4e0e\u4ee3\u7801\u6df1\u5ea6\u878d\u5408\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.09952", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.09952", "abs": "https://arxiv.org/abs/2508.09952", "authors": ["Hermione Warr", "Wentian Xu", "Harry Anthony", "Yasin Ibrahim", "Daniel McGowan", "Konstantinos Kamnitsas"], "title": "Specialised or Generic? Tokenization Choices for Radiology Language Models", "comment": "Accepted to ELAMI@MICCAI2025", "summary": "The vocabulary used by language models (LM) - defined by the tokenizer -\nplays a key role in text generation quality. However, its impact remains\nunder-explored in radiology. In this work, we address this gap by\nsystematically comparing general, medical, and domain-specific tokenizers on\nthe task of radiology report summarisation across three imaging modalities. We\nalso investigate scenarios with and without LM pre-training on PubMed\nabstracts. Our findings demonstrate that medical and domain-specific\nvocabularies outperformed widely used natural language alternatives when models\nare trained from scratch. Pre-training partially mitigates performance\ndifferences between tokenizers, whilst the domain-specific tokenizers achieve\nthe most favourable results. Domain-specific tokenizers also reduce memory\nrequirements due to smaller vocabularies and shorter sequences. These results\ndemonstrate that adapting the vocabulary of LMs to the clinical domain provides\npractical benefits, including improved performance and reduced computational\ndemands, making such models more accessible and effective for both research and\nreal-world healthcare settings.", "AI": {"tldr": "\u533b\u5b66\u548c\u9886\u57df\u4e13\u7528\u5206\u8bcd\u5668\u5728\u653e\u5c04\u5b66\u62a5\u544a\u751f\u6210\u4e2d\u6bd4\u901a\u7528\u5206\u8bcd\u5668\u6548\u679c\u66f4\u597d\uff0c\u5c24\u5176\u5728\u6a21\u578b\u4ece\u96f6\u8bad\u7ec3\u65f6\u8868\u73b0\u7a81\u51fa\uff0c\u4e14\u6709\u52a9\u4e8e\u964d\u4f4e\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\uff0c\u9884\u8bad\u7ec3\u53ef\u51cf\u7f13\u5206\u8bcd\u5668\u5dee\u5f02\u4f46\u9886\u57df\u8bcd\u8868\u4f9d\u65e7\u6700\u4f18\uff0c\u5efa\u8bae\u4e34\u5e8a\u533b\u5b66\u9886\u57df\u4f18\u5148\u4f7f\u7528\u4e13\u4e1a\u5316\u5206\u8bcd\u5668\u3002", "motivation": "\u76ee\u524d\u8bed\u8a00\u6a21\u578b\u4e2d\u4f7f\u7528\u7684\u8bcd\u6c47\u8868\uff08tokenizer\uff09\u5df2\u7ecf\u88ab\u8bc1\u660e\u5bf9\u6587\u672c\u751f\u6210\u8d28\u91cf\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4f46\u5728\u533b\u5b66\u5f71\u50cf\u9886\u57df\uff08\u5982\u653e\u5c04\u5b66\uff09\u4e2d\u7684\u5177\u4f53\u4f5c\u7528\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63a2\u8ba8\u4e0d\u540c\u7c7b\u578b\u7684\u5206\u8bcd\u5668\u5bf9\u533b\u5b66\u5f71\u50cf\u62a5\u544a\u751f\u6210\u4efb\u52a1\u7684\u5f71\u54cd\u3002", "method": "\u7cfb\u7edf\u6bd4\u8f83\u4e86\u901a\u7528\u3001\u533b\u5b66\u548c\u9886\u57df\u4e13\u7528\u4e09\u7c7b\u5206\u8bcd\u5668\u5728\u4e09\u79cd\u5f71\u50cf\u6a21\u5f0f\u7684\u653e\u5c04\u5b66\u62a5\u544a\u6458\u8981\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u8003\u5bdf\u4e86\u6a21\u578b\u662f\u5426\u5728PubMed\u6458\u8981\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "result": "\uff081\uff09\u533b\u5b66\u548c\u9886\u57df\u4e13\u7528\u8bcd\u8868\u5728\u4ece\u5934\u8bad\u7ec3\u6a21\u578b\u65f6\u8868\u73b0\u660e\u663e\u4f18\u4e8e\u666e\u901a\u81ea\u7136\u8bed\u8a00\u8bcd\u8868\uff1b\uff082\uff09\u7ecf\u8fc7\u533b\u5b66\u6587\u732e\u9884\u8bad\u7ec3\u53ef\u4ee5\u90e8\u5206\u51cf\u5c0f\u4e0d\u540c\u5206\u8bcd\u5668\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u4f46\u9886\u57df\u4e13\u7528\u8bcd\u8868\u4f9d\u7136\u6548\u679c\u6700\u4f73\uff1b\uff083\uff09\u9886\u57df\u4e13\u7528\u5206\u8bcd\u5668\u8fd8\u663e\u8457\u964d\u4f4e\u4e86\u6a21\u578b\u7684\u663e\u5b58\u5360\u7528\u548c\u5e8f\u5217\u957f\u5ea6\u3002", "conclusion": "\u5c06\u8bed\u8a00\u6a21\u578b\u7684\u8bcd\u6c47\u8868\u9002\u5e94\u4e8e\u4e34\u5e8a\u533b\u5b66\u9886\u57df\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u751f\u6210\u6027\u80fd\uff0c\u8fd8\u964d\u4f4e\u4e86\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\uff0c\u4f7f\u5f97\u533b\u5b66\u9886\u57df\u7684\u6587\u672c\u751f\u6210\u6a21\u578b\u66f4\u5177\u5b9e\u7528\u6027\u548c\u53ef\u63a8\u5e7f\u6027\u3002"}}
{"id": "2508.09954", "categories": ["cs.CL", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.09954", "abs": "https://arxiv.org/abs/2508.09954", "authors": ["Johannes Sch\u00e4fer", "Roman Klinger"], "title": "Shaping Event Backstories to Estimate Potential Emotion Contexts", "comment": "May 2025 version", "summary": "Emotion analysis is an inherently ambiguous task. Previous work studied\nannotator properties to explain disagreement, but this overlooks the\npossibility that ambiguity may stem from missing information about the context\nof events. In this paper, we propose a novel approach that adds reasonable\ncontexts to event descriptions, which may better explain a particular\nsituation. Our goal is to understand whether these enriched contexts enable\nhuman annotators to annotate emotions more reliably. We disambiguate a target\nevent description by automatically generating multiple event chains conditioned\non differing emotions. By combining techniques from short story generation in\nvarious settings, we achieve coherent narratives that result in a specialized\ndataset for the first comprehensive and systematic examination of\ncontextualized emotion analysis. Through automatic and human evaluation, we\nfind that contextual narratives enhance the interpretation of specific emotions\nand support annotators in producing more consistent annotations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u81ea\u52a8\u751f\u6210\u7684\u60c5\u5883\u6545\u4e8b\u4e3a\u4e8b\u4ef6\u8865\u5145\u4e0a\u4e0b\u6587\uff0c\u4ee5\u589e\u5f3a\u60c5\u611f\u5206\u6790\u6807\u6ce8\u7684\u53ef\u9760\u6027\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u6807\u6ce8\u4e00\u81f4\u6027\uff0c\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u7406\u89e3\u60c5\u7eea\u3002", "motivation": "\u60c5\u611f\u5206\u6790\u4efb\u52a1\u672c\u8d28\u5b58\u5728\u6b67\u4e49\uff0c\u5148\u524d\u7684\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6807\u6ce8\u8005\u81ea\u8eab\u7684\u7279\u5f81\uff0c\u5374\u5ffd\u7565\u4e86\u6b67\u4e49\u53ef\u80fd\u6765\u6e90\u4e8e\u4e8b\u4ef6\u80cc\u666f\u4fe1\u606f\u4e0d\u8db3\u3002\u8be5\u8bba\u6587\u5e0c\u671b\u63a2\u7d22\u901a\u8fc7\u8865\u5145\u5408\u7406\u4e0a\u4e0b\u6587\u662f\u5426\u80fd\u51cf\u5c11\u6b67\u4e49\u3002", "method": "\u81ea\u52a8\u751f\u6210\u591a\u6761\u57fa\u4e8e\u4e0d\u540c\u60c5\u7eea\u6761\u4ef6\u7684\u4e8b\u4ef6\u94fe\uff0c\u4e3a\u76ee\u6807\u4e8b\u4ef6\u63cf\u8ff0\u8865\u5145\u4e0d\u540c\u7684\u4e0a\u4e0b\u6587\u73af\u5883\u3002\u901a\u8fc7\u6574\u5408\u77ed\u7bc7\u6545\u4e8b\u751f\u6210\u7b49\u6280\u672f\uff0c\u5f97\u5230\u8fde\u8d2f\u7684\u53d9\u4e8b\u6587\u672c\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8e\u7cfb\u7edf\u6027\u7814\u7a76\u5e26\u4e0a\u4e0b\u6587\u60c5\u7eea\u5206\u6790\u7684\u6570\u636e\u96c6\u3002\u91c7\u7528\u81ea\u52a8\u548c\u4eba\u5de5\u8bc4\u4f30\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u8865\u5145\u4e0a\u4e0b\u6587\u7684\u53d9\u4e8b\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u7279\u5b9a\u60c5\u7eea\u7684\u7406\u89e3\u80fd\u529b\uff0c\u4f7f\u5f97\u4eba\u5de5\u6807\u6ce8\u8005\u5728\u60c5\u611f\u5224\u65ad\u4e0a\u66f4\u4e3a\u4e00\u81f4\u3002", "conclusion": "\u4e3a\u60c5\u611f\u5206\u6790\u4efb\u52a1\u8865\u5145\u5408\u7406\u4e0a\u4e0b\u6587\u80fd\u5e2e\u52a9\u51cf\u5c11\u6b67\u4e49\u5e76\u63d0\u9ad8\u6807\u6ce8\u4e00\u81f4\u6027\uff0c\u4e3a\u4eca\u540e\u60c5\u611f\u5206\u6790\u6570\u636e\u6807\u6ce8\u548c\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2508.09956", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09956", "abs": "https://arxiv.org/abs/2508.09956", "authors": ["Fares Antaki", "David Mikhail", "Daniel Milad", "Danny A Mammo", "Sumit Sharma", "Sunil K Srivastava", "Bing Yu Chen", "Samir Touma", "Mertcan Sevgi", "Jonathan El-Khoury", "Pearse A Keane", "Qingyu Chen", "Yih Chung Tham", "Renaud Duval"], "title": "Performance of GPT-5 Frontier Models in Ophthalmology Question Answering", "comment": null, "summary": "Large language models (LLMs) such as GPT-5 integrate advanced reasoning\ncapabilities that may improve performance on complex medical question-answering\ntasks. For this latest generation of reasoning models, the configurations that\nmaximize both accuracy and cost-efficiency have yet to be established. We\nevaluated 12 configurations of OpenAI's GPT-5 series (three model tiers across\nfour reasoning effort settings) alongside o1-high, o3-high, and GPT-4o, using\n260 closed-access multiple-choice questions from the American Academy of\nOphthalmology Basic Clinical Science Course (BCSC) dataset. The primary outcome\nwas multiple-choice accuracy; secondary outcomes included head-to-head ranking\nvia a Bradley-Terry model, rationale quality assessment using a\nreference-anchored, pairwise LLM-as-a-judge framework, and analysis of\naccuracy-cost trade-offs using token-based cost estimates. GPT-5-high achieved\nthe highest accuracy (0.965; 95% CI, 0.942-0.985), outperforming all GPT-5-nano\nvariants (P < .001), o1-high (P = .04), and GPT-4o (P < .001), but not o3-high\n(0.958; 95% CI, 0.931-0.981). GPT-5-high ranked first in both accuracy (1.66x\nstronger than o3-high) and rationale quality (1.11x stronger than o3-high).\nCost-accuracy analysis identified several GPT-5 configurations on the Pareto\nfrontier, with GPT-5-mini-low offering the most favorable low-cost,\nhigh-performance balance. These results benchmark GPT-5 on a high-quality\nophthalmology dataset, demonstrate the influence of reasoning effort on\naccuracy, and introduce an autograder framework for scalable evaluation of\nLLM-generated answers against reference standards in ophthalmology.", "AI": {"tldr": "GPT-5\u5728\u533b\u5b66\u773c\u79d1\u95ee\u7b54\u4e2d\u51c6\u786e\u7387\u4f18\u4e8e\u524d\u4ee3\u4e0e\u90e8\u5206\u7ade\u54c1\uff0c\u63a8\u7406\u5f3a\u5ea6\u4e0e\u6210\u672c\u914d\u7f6e\u5f71\u54cd\u6548\u679c\uff0cGPT-5-mini-low\u517c\u5177\u6027\u4ef7\u6bd4\u3002\u63d0\u51fa\u4e86\u81ea\u52a8\u8bc4\u5206\u65b0\u6846\u67b6\uff0c\u63a8\u52a8\u4e13\u4e1a\u533b\u7597AI\u9ad8\u6548\u8bc4\u6d4b\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5982GPT-5\u5728\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u63d0\u5347\uff0c\u5176\u5728\u590d\u6742\u533b\u5b66\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u4e9f\u9700\u8bc4\u4f30\u3002\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u54ea\u79cd\u914d\u7f6e\u80fd\u5728\u4fdd\u8bc1\u51c6\u786e\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u6210\u672c\u6548\u76ca\u6700\u5927\u5316\uff0c\u7279\u522b\u662f\u5728\u4e13\u4e1a\u533b\u5b66\u9886\u57df\uff0c\u5982\u773c\u79d1\u5b66\u3002", "method": "\u4f5c\u8005\u5bf9OpenAI\u7684GPT-5\u7cfb\u521712\u79cd\u914d\u7f6e\uff08\u5206\u4e3a\u4e09\u4e2a\u6a21\u578b\u5c42\u7ea7\u4e0e\u56db\u79cd\u63a8\u7406\u5f3a\u5ea6\uff09\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5e76\u4e0eo1-high\u3001o3-high\u548cGPT-4o\u8fdb\u884c\u5bf9\u6bd4\u3002\u6d4b\u8bc4\u6570\u636e\u4f7f\u7528\u4e86\u7f8e\u56fd\u773c\u79d1\u5b66\u4f1a\u7684\u9ad8\u8d28\u91cfBCSC\u4e34\u5e8a\u79d1\u5b66\u9009\u62e9\u9898\u96c6\uff08\u5171260\u9898\uff09\u3002\u4e3b\u8981\u8bc4\u4f30\u591a\u9879\u9009\u62e9\u9898\u7684\u51c6\u786e\u7387\uff1b\u6b21\u8981\u6307\u6807\u5305\u62ec\u5229\u7528Bradley-Terry\u6a21\u578b\u7684\u5934\u5bf9\u5934\u6392\u540d\u3001\u57fa\u4e8e\u53c2\u8003\u548cLLM\u5224\u65ad\u7684\u63a8\u7406\u8d28\u91cf\u3001\u4ee5\u53ca\u57fa\u4e8eToken\u7684\u6210\u672c-\u51c6\u786e\u7387\u6743\u8861\u5206\u6790\u3002", "result": "GPT-5-high\u5728\u51c6\u786e\u7387\u4e0a\u8fbe\u52300.965\uff0c\u663e\u8457\u4f18\u4e8e\u6240\u6709GPT-5-nano\u53d8\u4f53\uff08P<.001\uff09\u3001o1-high\uff08P=0.04\uff09\u548cGPT-4o\uff08P<.001\uff09\uff0c\u4f46\u4e0eo3-high\u5dee\u5f02\u4e0d\u663e\u8457\u3002\u6b64\u5916\uff0cGPT-5-high\u5728\u51c6\u786e\u7387\u548c\u63a8\u7406\u8d28\u91cf\u4e0a\u5747\u6392\u540d\u7b2c\u4e00\uff08\u51c6\u786e\u7387\u662fo3-high\u76841.66\u500d\uff0c\u63a8\u7406\u8d28\u91cf\u662f1.11\u500d\uff09\u3002\u6210\u672c-\u51c6\u786e\u7387\u5206\u6790\u53d1\u73b0\u591a\u4e2aGPT-5\u914d\u7f6e\u5728\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u5176\u4e2dGPT-5-mini-low\u5728\u4f4e\u6210\u672c\u9ad8\u6027\u80fd\u95f4\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u672c\u7814\u7a76\u57fa\u51c6\u6027\u5730\u8bc4\u4f30\u4e86GPT-5\u5728\u9ad8\u8d28\u91cf\u773c\u79d1\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u9a8c\u8bc1\u4e86\u63a8\u7406\u5f3a\u5ea6\u5bf9\u6a21\u578b\u51c6\u786e\u7387\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684LLM\u7b54\u9898\u81ea\u52a8\u8bc4\u5206\u6846\u67b6\uff0c\u4e3a\u5408\u7406\u914d\u7f6e\u5927\u6a21\u578b\u5728\u4e13\u4e1a\u573a\u666f\u843d\u5730\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2508.09957", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.09957", "abs": "https://arxiv.org/abs/2508.09957", "authors": ["Renas Adnan", "Hossein Hassani"], "title": "Which one Performs Better? Wav2Vec or Whisper? Applying both in Badini Kurdish Speech to Text (BKSTT)", "comment": "21 pages, 20 figures, 7 tables", "summary": "Speech-to-text (STT) systems have a wide range of applications. They are\navailable in many languages, albeit at different quality levels. Although\nKurdish is considered a less-resourced language from a processing perspective,\nSST is available for some of the Kurdish dialects, for instance, Sorani\n(Central Kurdish). However, that is not applied to other Kurdish dialects,\nBadini and Hawrami, for example. This research is an attempt to address this\ngap. Bandin, approximately, has two million speakers, and STT systems can help\ntheir community use mobile and computer-based technologies while giving their\ndialect more global visibility. We aim to create a language model based on\nBadini's speech and evaluate its performance. To cover a conversational aspect,\nhave a proper confidence level of grammatical accuracy, and ready\ntranscriptions, we chose Badini kids' stories, eight books including 78\nstories, as the textual input. Six narrators narrated the books, which resulted\nin approximately 17 hours of recording. We cleaned, segmented, and tokenized\nthe input. The preprocessing produced nearly 15 hours of speech, including\n19193 segments and 25221 words. We used Wav2Vec2-Large-XLSR-53 and\nWhisper-small to develop the language models. The experiments indicate that the\ntranscriptions process based on the Wav2Vec2-Large-XLSR-53 model provides a\nsignificantly more accurate and readable output than the Whisper-small model,\nwith 90.38% and 65.45% readability, and 82.67% and 53.17% accuracy,\nrespectively.", "AI": {"tldr": "\u4f5c\u8005\u6784\u5efa\u4e86\u9996\u4e2a\u9762\u5411Badini\u5e93\u5c14\u5fb7\u8bed\u65b9\u8a00\u7684\u8bed\u97f3\u8f6c\u6587\u672c\u6a21\u578b\u3002\u4e0eWhisper-small\u6a21\u578b\u5bf9\u6bd4\uff0cWav2Vec2-Large-XLSR-53\u6a21\u578b\u5728\u53ef\u8bfb\u6027\u548c\u51c6\u786e\u7387\u4e0a\u5747\u6709\u660e\u663e\u4f18\u52bf\uff0c\u4e3a\u4f4e\u8d44\u6e90\u65b9\u8a00\u7684\u6570\u5b57\u5316\u5e94\u7528\u4f5c\u51fa\u4e86\u8d21\u732e\u3002", "motivation": "\u867d\u7136\u5e93\u5c14\u5fb7\u8bed\u662f\u4e00\u79cd\u8d44\u6e90\u8f83\u5c11\u7684\u8bed\u8a00\uff0c\u4f46\u5176\u90e8\u5206\u65b9\u8a00\uff08\u5982Sorani\uff09\u5df2\u6709\u8bed\u97f3\u8f6c\u6587\u672c\uff08STT\uff09\u7cfb\u7edf\uff0c\u7136\u800cBadini\u3001Hawrami\u7b49\u5176\u4ed6\u5e93\u5c14\u5fb7\u8bed\u65b9\u8a00\u5c1a\u672a\u6709\u76f8\u5173\u7cfb\u7edf\u3002Badini\u6709\u7ea6200\u4e07\u4f7f\u7528\u8005\uff0cSTT\u5bf9\u8fd9\u90e8\u5206\u7fa4\u4f53\u7684\u6570\u5b57\u5316\u975e\u5e38\u91cd\u8981\u3002", "method": "\u9009\u53d6\u4e86Badini\u65b9\u8a00\u7684\u513f\u7ae5\u6545\u4e8b\u6587\u672c\uff088\u672c\uff0c\u517178\u4e2a\u6545\u4e8b\uff09\u4f5c\u4e3a\u8bed\u6599\uff0c\u75316\u4f4d\u8bb2\u8ff0\u8005\u6717\u8bfb\u5f55\u5236\uff0c\u603b\u65f6\u957f\u7ea617\u5c0f\u65f6\u3002\u5bf9\u5f55\u97f3\u8fdb\u884c\u4e86\u6e05\u6d17\u3001\u5206\u6bb5\u548c\u5206\u8bcd\u9884\u5904\u7406\uff0c\u6700\u7ec8\u5f97\u5230\u7ea615\u5c0f\u65f6\u7684\u8bed\u97f3\u6570\u636e\u3002\u91c7\u7528Wav2Vec2-Large-XLSR-53\u548cWhisper-small\u4e24\u79cd\u6a21\u578b\u5206\u522b\u8bad\u7ec3\u548c\u8bc4\u4f30STT\u7cfb\u7edf\u3002", "result": "Wav2Vec2-Large-XLSR-53\u6a21\u578b\u5728\u8f6c\u5f55Badini\u8bed\u97f3\u65f6\u8868\u73b0\u660e\u663e\u4f18\u4e8eWhisper-small\u6a21\u578b\uff0c\u53ef\u8bfb\u6027\u5206\u522b\u4e3a90.38%\u4e0e65.45%\uff0c\u51c6\u786e\u7387\u5206\u522b\u4e3a82.67%\u4e0e53.17%\u3002", "conclusion": "Wav2Vec2-Large-XLSR-53\u662f\u4e00\u79cd\u66f4\u9002\u7528\u4e8eBadini\u5e93\u5c14\u5fb7\u8bed\u65b9\u8a00STT\u4efb\u52a1\u7684\u6a21\u578b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6587\u5b57\u8f6c\u5199\u7684\u53ef\u8bfb\u6027\u548c\u51c6\u786e\u7387\u3002"}}
{"id": "2508.09958", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.09958", "abs": "https://arxiv.org/abs/2508.09958", "authors": ["Baran Atalar", "Eddie Zhang", "Carlee Joe-Wong"], "title": "Neural Bandit Based Optimal LLM Selection for a Pipeline of Tasks", "comment": "Submitted to AAAI 2026", "summary": "With the increasing popularity of large language models (LLMs) for a variety\nof tasks, there has been a growing interest in strategies that can predict\nwhich out of a set of LLMs will yield a successful answer at low cost. This\nproblem promises to become more and more relevant as providers like Microsoft\nallow users to easily create custom LLM \"assistants\" specialized to particular\ntypes of queries. However, some tasks (i.e., queries) may be too specialized\nand difficult for a single LLM to handle alone. These applications often\nbenefit from breaking down the task into smaller subtasks, each of which can\nthen be executed by a LLM expected to perform well on that specific subtask.\nFor example, in extracting a diagnosis from medical records, one can first\nselect an LLM to summarize the record, select another to validate the summary,\nand then select another, possibly different, LLM to extract the diagnosis from\nthe summarized record. Unlike existing LLM selection or routing algorithms,\nthis setting requires that we select a sequence of LLMs, with the output of\neach LLM feeding into the next and potentially influencing its success. Thus,\nunlike single LLM selection, the quality of each subtask's output directly\naffects the inputs, and hence the cost and success rate, of downstream LLMs,\ncreating complex performance dependencies that must be learned and accounted\nfor during selection. We propose a neural contextual bandit-based algorithm\nthat trains neural networks that model LLM success on each subtask in an online\nmanner, thus learning to guide the LLM selections for the different subtasks,\neven in the absence of historical LLM performance data. Experiments on\ntelecommunications question answering and medical diagnosis prediction datasets\nillustrate the effectiveness of our proposed approach compared to other LLM\nselection algorithms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u7684LLM\u5e8f\u5217\u9009\u62e9\u7b97\u6cd5\uff0c\u5728\u591a\u5b50\u4efb\u52a1\u548c\u65e0\u5386\u53f2\u6570\u636e\u4e0b\u80fd\u66f4\u9ad8\u6548\u5730\u5206\u914d\u548c\u9009\u62e9LLM\uff0c\u9002\u7528\u4e8e\u590d\u6742\u4e14\u9700\u591a\u6a21\u578b\u534f\u4f5c\u7684\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5404\u7c7b\u4efb\u52a1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5982\u4f55\u4ee5\u4f4e\u6210\u672c\u9884\u6d4b\u548c\u9009\u62e9\u6700\u9002\u5408\u7279\u5b9a\u4efb\u52a1\u7684LLM\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u4efb\u52a1\u9ad8\u5ea6\u4e13\u4e1a\u5316\u548c\u590d\u6742\u65f6\uff0c\u5355\u4e00LLM\u96be\u4ee5\u5b8c\u5168\u80dc\u4efb\u3002\u672a\u6765\u7528\u6237\u53ef\u6839\u636e\u9700\u6c42\u5b9a\u5236\u4e13\u5c5eLLM\u52a9\u624b\uff0c\u63d0\u5347\u4efb\u52a1\u5904\u7406\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u7b97\u6cd5\uff08neural contextual bandit\uff09\u7684LLM\u5e8f\u5217\u9009\u62e9\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u5728\u7ebf\u5efa\u6a21\u6bcf\u4e2a\u5b50\u4efb\u52a1\u4e2dLLM\u7684\u6210\u529f\u7387\uff0c\u5728\u6ca1\u6709\u5386\u53f2\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u9010\u6b65\u5b66\u4e60\u5982\u4f55\u4e3a\u4e0d\u540c\u5b50\u4efb\u52a1\u6311\u9009\u6700\u5408\u9002\u7684LLM\u3002", "result": "\u5728\u7535\u4fe1\u95ee\u7b54\u548c\u533b\u7597\u8bca\u65ad\u9884\u6d4b\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u5b50\u4efb\u52a1\u5206\u914d\u4e0eLLM\u9009\u62e9\u4e0a\u6bd4\u4f20\u7edf\u5355\u4e00\u6a21\u578b\u9009\u62e9\u7b97\u6cd5\u66f4\u6709\u6548\uff0c\u63d0\u5347\u4e86\u6574\u4f53\u4efb\u52a1\u5b8c\u6210\u7387\u548c\u6548\u7387\u3002", "conclusion": "\u9488\u5bf9\u590d\u6742\u4efb\u52a1\u9700\u8981\u591a\u8f6eLLM\u534f\u4f5c\u7684\u60c5\u5883\uff0c\u6587\u4e2d\u63d0\u51fa\u7684\u5e8f\u5217\u9009\u62e9\u4e0e\u5728\u7ebf\u5b66\u4e60\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u6027\u80fd\u4f9d\u8d56\u548c\u6210\u672c\u63a7\u5236\u7684\u95ee\u9898\uff0c\u4e3a\u591aLLM\u534f\u4f5c\u4efb\u52a1\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u548c\u6280\u672f\u53c2\u8003\u3002"}}
