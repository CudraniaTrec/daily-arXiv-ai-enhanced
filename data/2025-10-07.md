<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]
- [cs.SE](#cs.SE) [Total: 10]
- [cs.LO](#cs.LO) [Total: 9]
- [cs.CL](#cs.CL) [Total: 10]
- [cs.DM](#cs.DM) [Total: 4]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [PLSEMANTICSBENCH: Large Language Models As Programming Language Interpreters](https://arxiv.org/abs/2510.03415)
*Aditya Thimmaiah,Jiyang Zhang,Jayanth Srinivasa,Junyi Jessy Li,Milos Gligoric*

Main category: cs.PL

TL;DR: 本文研究了LLM能否基于形式语义解释程序，发现LLM有潜力用于语言解释，但对语义规则的理解尚不牢靠，尤其在非常规情况下性能下降，且形式语义对复杂任务可能有反效果。提供了公开基准与代码。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）在代码推理方面表现优异，作者提出一个自然问题：能否让LLM仅依据编程语言的形式语义来执行程序，即充当解释器？这将有助于快速原型开发新编程语言和语言特性。

Method: 作者以命令式语言IMP（C语言的子集）为研究对象，通过小步操作语义（SOS）和基于重写的操作语义（K-semantics）进行形式化。设计了三组评测集（人工编写、LLM翻译、Fuzzer生成），通过代码复杂度进行难度控制。评测包括三类任务：最终状态预测、语义规则预测、执行轨迹预测。为区分预训练记忆和语义能力，作者还定义了两种非常规语义规则。

Result: 发现强代码推理的LLM在非常规语义下性能显著下降，且不同模型失败有规律。大多数模型能在复杂程序的粗粒度任务上表现优异，如五层以上嵌套循环，但提供形式语义只对简单程序有帮助，对复杂程序反而有负面影响。

Conclusion: LLM有望充当编程语言的解释器，但在语义理解上仍不健壮，需要进一步提升。作者已公开基准及代码。

Abstract: As large language models (LLMs) excel at code reasoning, a natural question
arises: can an LLM execute programs (i.e., act as an interpreter) purely based
on a programming language's formal semantics? If so, it will enable rapid
prototyping of new programming languages and language features. We study this
question using the imperative language IMP (a subset of C), formalized via
small-step operational semantics (SOS) and rewriting-based operational
semantics (K-semantics). We introduce three evaluation sets-Human-Written,
LLM-Translated, and Fuzzer- Generated-whose difficulty is controlled by
code-complexity metrics spanning the size, control-flow, and data-flow axes.
Given a program and its semantics formalized with SOS/K-semantics, models are
evaluated on three tasks ranging from coarse to fine: (1) final-state
prediction, (2) semantic rule prediction, and (3) execution trace prediction.
To distinguish pretraining memorization from semantic competence, we define two
nonstandard semantics obtained through systematic mutations of the standard
rules. Across strong code/reasoning LLMs, performance drops under nonstandard
semantics despite high performance under the standard one. We further find that
(i) there are patterns to different model failures, (ii) most reasoning models
perform exceptionally well on coarse grained tasks involving reasoning about
highly complex programs often containing nested loop depths beyond five, and
surprisingly, (iii) providing formal semantics helps on simple programs but
often hurts on more complex ones. Overall, the results show a promise that LLMs
could serve as programming language interpreters, but points to the lack of
their robust semantics understanding. We release the benchmark and the
supporting code at https://github.com/EngineeringSoftware/PLSemanticsBench.

</details>


### [2] [Encoding Numeric Computations and Infusing Heuristic Knowledge Using Integrity Constraints in stableKanren](https://arxiv.org/abs/2510.04049)
*Xiangyu Guo,Ajay Bansal*

Main category: cs.PL

TL;DR: 本文分析了stableKanren在数值计算与问题求解中的优势，证明其在符号与数值计算平衡、约束表达简化及启发式优化方面具有显著提升，尤其是在组合搜索类问题（如SEND+MORE=MONEY）中其性能大幅增强。


<details>
  <summary>Details</summary>
Motivation: 当前关系型编程语言在数值计算的表达和性能方面存在不足，有必要优化数值计算的表达方式和提升问题求解效率。

Method: 提出并分析 stableKanren在数值计算问题上的应用，并通过具体例子（如SEND+MORE=MONEY谜题）探讨多种注入启发式知识与实现求解时间优化的方法。比较 stableKanren 与传统数值关系型表达的不同方式，分析其约束存储机制和语法简化。

Result: stableKanren提供了简洁直观的数值表达方式，合理平衡了符号和数值计算，避免了全部数值符号化，并具备比约束存储传统方法更简单的语法。通过启发式知识不断注入，SEND+MORE=MONEY问题的求解效率得以提升。外部函数的使用进一步实现混合式求解，增强了灵活性。

Conclusion: stableKanren在关系型编程范式下，通过约束存储和重新设计数值表达，有效提升了组合搜索与数值计算的效率与灵活性，在 declarative generate and test 问题求解场景中表现出更好性能和更易用语法，证明了启发式知识与外部函数混合机制的有效性。

Abstract: This paper presents examples of using integrity constraints in stableKanren
to encode numeric computations for problem solving. Then, we use one of the
examples to introduce multiple ways to infuse heuristic knowledge and reduce
solving time. stableKanren is an extension of miniKanren that supports normal
logic programs under stable model semantics. stableKanren further supports
numeric computation by constructing a constraint store for integrity
constraints. There are three ways to extend a relational programming language
with numeric computations: relational number representation, grounding numbers
to symbols, and constraint store construction. We demonstrate that the numeric
computations in stableKanren have a straightforward numerical representation
compared to relational number representations. More importantly, stableKanren
balances symbolic and numeric computation in relational programming by avoiding
the grounding of all numbers to symbols. Lastly, it also has simpler syntax
compared to other constraint store construction approaches. stableKanren
supports combinatorial search problem solving under a declarative generate and
test paradigm. Such a paradigm generates all possible combinations of solutions
to the problem, then applies a set of constraints to prune out the unwanted
solutions. We demonstrate that different approaches to writing programs or
queries affect the solver's performance in the SEND+MORE=MONEY puzzle. The
performance gradually improves as more heuristic knowledge is infused through
the programs or queries. Additionally, we show how to use an external function
to achieve a hybrid solution.

</details>


### [3] [Retrofitting Control Flow Graphs in LLVM IR for Auto Vectorization](https://arxiv.org/abs/2510.04890)
*Shihan Fang,Wenxin Zheng*

Main category: cs.PL

TL;DR: 本文提出一种基于结构和依赖信息扩展的创新向量化流水线，实现比主流编译器更大范围和效率的自动向量化，性能最高提升达58%。


<details>
  <summary>Details</summary>
Motivation: 现代处理器高度依赖SIMD指令（如AVX、RVV）提升并行及计算性能，但主流编译器（如LLVM和GCC）由于向量化流程分散和可扩展性不足，无法充分挖掘所有向量化机会。现有方法在启发式规则和中间表示（IR）设计上虽有提升，但控制流分析简化和精确识别向量化机会依旧困难。

Method: 提出了一个新颖的向量化流水线，包含两种专用IR扩展：SIR（编码高层次结构信息）和VIR（通过数据依赖性分析明确指令依赖）。借助VIR的依赖信息，开发出了灵活可扩展的新型向量化框架。

Result: 所提出的向量化流水线比LLVM和GCC在自动向量化的范围和效率上有明显提升。

Conclusion: 基于SIR和VIR的创新向量化框架能极大增强自动向量化分析能力和性能，实验证明与LLVM、GCC相比，分别带来53%和58%的显著加速。

Abstract: Modern processors increasingly rely on SIMD instruction sets, such as AVX and
RVV, to significantly enhance parallelism and computational performance.
However, production-ready compilers like LLVM and GCC often fail to fully
exploit available vectorization opportunities due to disjoint vectorization
passes and limited extensibility. Although recent attempts in heuristics and
intermediate representation (IR) designs have attempted to address these
problems, efficiently simplifying control flow analysis and accurately
identifying vectorization opportunities remain challenging tasks.
  To address these issues, we introduce a novel vectorization pipeline
featuring two specialized IR extensions: SIR, which encodes high-level
structural information, and VIR, which explicitly represents instruction
dependencies through data dependency analysis. Leveraging the detailed
dependency information provided by VIR, we develop a flexible and extensible
vectorization framework. This approach substantially improves interoperability
across vectorization passes and expands the search space for identifying
isomorphic instructions, ultimately enhancing both the scope and efficiency of
automatic vectorization. Experimental evaluations demonstrate that our proposed
vectorization pipeline achieves significant performance improvements,
delivering speedups of up to 53% and 58% compared to LLVM and GCC,
respectively.

</details>


### [4] [concurrentKanren: miniKanren for parallel execution](https://arxiv.org/abs/2510.04994)
*Sjoerd Dost*

Main category: cs.PL

TL;DR: 本文首次在 Go 语言中实现了并行 miniKanren，证明了其可行性并提升了性能，为后续并发逻辑编程语言研究提供了经验和思路。


<details>
  <summary>Details</summary>
Motivation: miniKanren 作为逻辑编程语言在并发实现上尚未被充分探索。

Method: 在 Go 语言中实现了 miniKanren 的并行版本，利用隐式并行性提高性能。

Result: 实验展示了并行 miniKanren 的可行性及其对性能的提升，评估了并行带来的实际效果。

Conclusion: 本文为基于语言无关模型的未来并发逻辑编程实现奠定了基础。

Abstract: Concurrent logic programming predates miniKanren, but concurrent
implementations of miniKanren have remained largely unexplored. In this work we
present a parallel implementation of miniKanren in Go, demonstrating its
feasibility and potential for performance improvements. Our approach leverages
implicit parallelism allowing legacy programs to benefit from parallel
execution. We discuss implementation strategies and evaluate the impact of
parallelism, laying groundwork for future language-agnostic models.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [5] [Repairing Leaks in Resource Wrappers](https://arxiv.org/abs/2510.03461)
*Sanjay Malakar,Michael D. Ernst,Martin Kellogg,Manu Sridharan*

Main category: cs.SE

TL;DR: 本文通过规范推断、代码变换和新的分析修复方法，显著提升了复杂资源包装情境下的自动资源泄漏修复能力，修复率由41%提升到68%。


<details>
  <summary>Details</summary>
Motivation: 资源泄漏（如套接字、文件描述符或数据库连接未释放）常常引发软件缺陷。以往自动修复方法只覆盖少量硬编码库资源类型，无法处理实际代码中各种资源封装器，从而限制了修复范围。解决实际开发中广泛使用的资源包装器带来的复杂性，是本工作的动机。

Method: （1）将资源管理规范推断过程集成至修复流水线中，使现有修复方法可处理资源封装器；（2）通过代码变换减少分析难度，使推断、检测和修复工具能更有效地定位泄漏根因，问题报告更靠近实际调用者；（3）引入字段包容分析，实现基于字段存储资源时的生命周期推断，从而修复更多泄漏；（4）提出新的修复模式和精确机制，尤其针对资源储存在非final字段的场景。

Result: 新方案对NJR基准集中的资源泄漏警告修复率从以往的41%提升到68%。

Conclusion: 整体改进对自动修复资源泄漏能力有显著提升，能更广泛覆盖复杂的资源封装器，提升实用性和检测修复效果。

Abstract: A resource leak occurs when a program fails to release a finite resource like
a socket, file descriptor or database connection. While sound static analysis
tools can detect all leaks, automatically repairing them remains challenging.
Prior work took the output of a detection tool and attempted to repair only
leaks from a hard-coded list of library resource types. That approach limits
the scope of repairable leaks: real-world code uses resource wrappers that
store a resource in a field and must themselves be closed. This paper makes
four key contributions to improve resource leak repair in the presence of
wrappers. (1) It integrates inference of resource management specifications
into the repair pipeline, enabling extant fixing approaches to reason about
wrappers. (2) It transforms programs into variants that are easier to analyze,
making inference, detection, and fixing tools more effective; for instance, it
makes detection tools report problems closer to the root cause, often in a
client of a resource wrapper rather than within the wrapper class itself. (3) A
novel field containment analysis reasons about resource lifetimes, enabling
repair of more leaks involving resources stored in fields. (4) It introduces a
new repair pattern and more precise reasoning to better handle resources stored
in non-final fields. Prior work fixed 41% of resource leak warnings in the NJR
benchmark suite; our implementation Arodnap fixes 68%.

</details>


### [6] [ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering Framework](https://arxiv.org/abs/2510.03463)
*Vali Tawosi,Keshav Ramani,Salwa Alamir,Xiaomo Liu*

Main category: cs.SE

TL;DR: 本文提出ALMAS框架，将LLM智能体应用于软件开发全生命周期，与敏捷流程和人类开发者无缝协作，已通过案例验证其端到端自动化开发能力，未来具备广泛应用前景。


<details>
  <summary>Details</summary>
Motivation: 多智能体LLM系统已在多个领域推动应用研究，尤其是在软件开发领域自动化各类任务。鉴于软件开发不仅仅是编码，还涉及整个软件生命周期，当前方法存在局限。

Method: 提出ALMAS框架：一个基于大型语言模型的多智能体软件工程系统，将智能体与敏捷开发角色对齐，采用模块化设计，可与人类开发者及环境无缝集成，支持SDLC多个阶段。

Result: 通过已有发表成果和使用案例证明，ALMAS框架能够端到端生成应用、添加新功能，实现智能体协助软件开发流程。

Conclusion: ALMAS展示了基于LLM多智能体的自动化软件工程落地能力，能有效提升敏捷开发团队的效率和协作，具备实际应用潜力。

Abstract: Multi-agent Large Language Model (LLM) systems have been leading the way in
applied LLM research across a number of fields. One notable area is software
development, where researchers have advanced the automation of code
implementation, code testing, code maintenance, inter alia, using LLM agents.
However, software development is a multifaceted environment that extends beyond
just code. As such, a successful LLM system must factor in multiple stages of
the software development life-cycle (SDLC). In this paper, we propose a vision
for ALMAS, an Autonomous LLM-based Multi-Agent Software Engineering framework,
which follows the above SDLC philosophy such that it may work within an agile
software development team to perform several tasks end-to-end. ALMAS aligns its
agents with agile roles, and can be used in a modular fashion to seamlessly
integrate with human developers and their development environment. We showcase
the progress towards ALMAS through our published works and a use case
demonstrating the framework, where ALMAS is able to seamlessly generate an
application and add a new feature.

</details>


### [7] [Relative Code Comprehensibility Prediction](https://arxiv.org/abs/2510.03474)
*Nadeeshan De Silva,Martin Kellogg,Oscar Chaparro*

Main category: cs.SE

TL;DR: 针对代码可理解性预测任务，本文提出用相对预测（判断哪段代码更容易理解）替代绝对预测，并在大规模人类标注数据上实验证明，前者模型效果显著优于后者，能更好应用于实际软件工程场景。


<details>
  <summary>Details</summary>
Motivation: 在软件工程领域，理解代码段的难易程度对开发者进行重构决策等任务具有重要意义。传统方法基于代码可理解性指标，但这些指标与真实的人工测量相关性较低，现有机器学习方法直接预测代码可理解性但准确率有限。作者认为问题关键在于人工数据本身存在噪声，影响了模型对“绝对”可理解性的预测效果。

Method: 作者提出采用“相对可理解性预测”模型，即训练模型判断两段代码中哪一段更容易被人理解，避免直接预测每段代码的绝对可理解性。通过用真实的可理解性测量数据（共150个Java代码片段和12500个人类测量记录），比较绝对预测和相对预测模型，并以朴素基线作为对照。

Result: 实验结果显示，绝对可理解性模型相比基线最多提高33.4%，且常常表现不佳；而相对可理解性模型在片段层面和开发者层面分别提升了137.8%和74.7%。这说明相对模型能更有效地从数据中学习，并更具实际应用价值。

Conclusion: 相对可理解性预测方法由于更好地应对了人工数据中的噪声，对下游软件工程任务（如评估重构是否改善代码可理解性）更具实用意义。

Abstract: Automatically predicting how difficult it is for humans to understand a code
snippet can assist developers in tasks like deciding when and where to
refactor. Despite many proposed code comprehensibility metrics, studies have
shown they often correlate poorly with actual measurements of human
comprehensibility. This has motivated the use of machine learning models to
predict human comprehensibility directly from code, but these models have also
shown limited accuracy.
  We argue that model inaccuracy stems from inherent noise in human
comprehensibility data, which confuses models trained to predict it directly.
To address this, we propose training models to predict the relative
comprehensibility of two code snippets - that is, predicting which snippet a
human would find easier to understand without predicting each snippet's
comprehensibility in isolation. This mitigates noise in predicting 'absolute'
comprehensibility measurements, but is still useful for downstream
software-engineering tasks like assessing whether refactoring improves or
hinders comprehensibility.
  We conducted a study to assess and compare the effectiveness of absolute and
relative code comprehensibility prediction via machine learning. We used a
dataset of 150 Java code snippets and 12.5k human comprehensibility
measurements from prior user studies, comparing the models' performance with
naive baselines (eg 'always predict the majority class'). Our findings indicate
that absolute comprehensibility models improve over the baselines by at most
33.4% and frequently underperform. In contrast, relative comprehensibility
models are substantially better, with average improvements of 137.8% and 74.7%
for snippet-wise and developer-wise prediction, respectively. These results
suggest that relative comprehensibility models learn more effectively from the
data, supporting their practical applicability for downstream SE tasks.

</details>


### [8] [LLM Agents for Automated Dependency Upgrades](https://arxiv.org/abs/2510.03480)
*Vali Tawosi,Salwa Alamir,Xiaomo Liu,Manuela Veloso*

Main category: cs.SE

TL;DR: 本文提出了一种自动化升级Java库依赖的LLM代理系统，在精度和资源消耗方面优于主流方案，可有效减轻开发者维护负担。


<details>
  <summary>Details</summary>
Motivation: 随着代码库的扩展，其依赖的库可能会过时，需要更新以保证创新和安全性。然而库的更新可能带来代码的不兼容，给开发者维护带来大量工作量。

Method: 提出了一套结合迁移文档使用的LLM代理框架，能够自动定位Java代码库中的需要升级的库用法，并自动推荐和实现代码修复。系统架构包括Summary Agent、Control Agent和Code Agent多个关键组件。

Result: 在多个合成代码库与主流方法对比测试中，该方法实现了更少的token使用和71.4%的升级精度，展现出高效和有效性。

Conclusion: 该LLM代理框架能够自动化处理库升级过程，降低开发者维护成本，在精度和资源消耗方面优于现有方法。

Abstract: As a codebase expands over time, its library dependencies can become outdated
and require updates to maintain innovation and security. However, updating a
library can introduce breaking changes in the code, necessitating significant
developer time for maintenance. To address this, we introduce a framework of
LLM agents to be used in combination with migration documentation to
automatically recommend and apply code updates and ensure compatibility with
new versions. Our solution can automatically localize updated library usages in
live Java codebases and implement recommended fixes in a user-friendly manner.
The system architecture consists of multiple key components: a Summary Agent,
Control Agent, and Code Agent. To validate our approach, we apply the framework
on an industrial use case by which we create three synthetic code repositories
with major Upgrade changes and benchmark our approach against state-of-the-art
methods. Results show that our approach not only performs upgrades using fewer
tokens across all cases but also achieves a precision of 71.4%, highlighting
its efficiency and effectiveness compared to state-of-the-art methods.

</details>


### [9] [AgentHub: A Research Agenda for Agent Sharing Infrastructure](https://arxiv.org/abs/2510.03495)
*Erik Pautsch,Tanmay Singla,Wenxin Jiang,Huiyun Peng,Behnaz Hassanshahi,Konstantin Läufer,George K. Thiruvathukal,James C. Davis*

Main category: cs.SE

TL;DR: 智能体应用迅速发展，但其基础设施滞后。本文提出AgentHub，倡导解决能力、透明性、兼容性、安全等六大挑战，推动智能体像软件包一样高效共享与组合。


<details>
  <summary>Details</summary>
Motivation: 当前基于大型语言模型（LLM）的智能体（Agent）应用迅速增长，但其相关的发现、评价和治理基础设施还非常分散，远不如软件包注册库或模型共享平台完善。这种基础设施的薄弱限制了Agent的分发与复用能力。

Method: 本文提出了一个名为AgentHub的研究议程，系统性地框定了构建Agent共享基础设施所需面对的关键挑战，包括能力澄清、生命周期透明性、互操作性、治理、安全和工作流集成等。

Result: AgentHub 提出了围绕六大核心挑战展开的社区合作蓝图，旨在实现一个可靠、可扩展的智能体生态系统。这个系统可以让智能体像软件库一样被高效共享、信任和组合。

Conclusion: 通过AgentHub研究议程，为智能体生态系统的基础设施建设指明了方向，有望推动智能体的开放共享、标准化和可信任发展。

Abstract: LLM-based agents are rapidly proliferating, yet the infrastructure for
discovering, evaluating, and governing them remains fragmented compared to
mature ecosystems like software package registries (e.g., npm) and model hubs
(e.g., Hugging Face). Recent research and engineering works have begun to
consider the requisite infrastructure, but so far they focus narrowly -- on
distribution, naming, or protocol negotiation. However, considering broader
software engineering requirements would improve open-source distribution and
ease reuse. We therefore propose AgentHub, a research agenda for agent sharing.
By framing the key challenges of capability clarity, lifecycle transparency,
interoperability, governance, security, and workflow integration, AgentHub
charts a community-wide agenda for building reliable and scalable agent
ecosystems. Our vision is a future where agents can be shared, trusted, and
composed as seamlessly as today's software libraries.

</details>


### [10] [REFINE: Enhancing Program Repair Agents through Context-Aware Patch Refinement](https://arxiv.org/abs/2510.03588)
*Anvith Pabba,Simin Chen,Alex Mathai,Anindya Chakraborty,Baishakhi Ray*

Main category: cs.SE

TL;DR: 本文提出了针对LLM驱动自动程序修复的补丁细化框架Refine, 有效解决了因语境理解和测试不全导致的部分修复问题。Refine通过内容澄清、多样候选扩展和智能代码评审，大幅提高了修复正确率，在多个基准和系统上取得显著提升，并已实现开源。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的自动程序修复（APR）技术，尽管有潜力，但在生成正确补丁时存在困境。主要原因是对代码语境理解不足，以及过度依赖不完整的测试用例，这导致生成的补丁常常是“草稿补丁”，只能部分解决问题或者过拟合于测试。

Method: 提出了一个新颖的补丁细化框架Refine，系统性地将草稿补丁转化为正确补丁。从三方面着手：1）澄清模糊的问题与代码上下文；2）通过测试阶段扩展多样化补丁候选；3）借助LLM驱动的代码评审过程聚合部分修复。该模块可以集成到开放式或工作流式APR系统中。

Result: Refine在SWE-Bench Lite基准上达到了工作流类方法的最新水平，整体表现接近所有APR类别的最佳结果。具体表现为让AutoCodeRover性能提升了14.67%，得分达到51.67%，超越所有对比基线；在SWE-Bench Verified上修复率提升12.2%；集成到多种APR系统平均提升达14%，展现了广泛有效性和泛化能力。相关代码已开源。

Conclusion: 补丁细化作为APR流程中缺失的关键环节，可以有效提升现有LLM驱动修复系统的性能，推动从“近正确”补丁走向真正正确。Refine框架通过智能协作和多元语境处理方式，为自动程序修复领域闭合了重要技术缺口。

Abstract: Large Language Models (LLMs) have recently shown strong potential in
automatic program repair (APR), especially in repository-level settings where
the goal is to generate patches based on natural language issue descriptions,
large codebases, and regression tests. However, despite their promise, current
LLM-based APR techniques often struggle to produce correct fixes due to limited
understanding of code context and over-reliance on incomplete test suites. As a
result, they frequently generate Draft Patches-partially correct patches that
either incompletely address the bug or overfit to the test cases. In this work,
we propose a novel patch refinement framework, Refine, that systematically
transforms Draft Patches into correct ones. Refine addresses three key
challenges: disambiguating vague issue and code context, diversifying patch
candidates through test-time scaling, and aggregating partial fixes via an
LLM-powered code review process. We implement Refine as a general refinement
module that can be integrated into both open-agent-based and workflow-based APR
systems. Our evaluation on the SWE-Bench Lite benchmark shows that Refine
achieves state-of-the-art results among workflow-based approaches and
approaches the best-known performance across all APR categories. Specifically,
Refine boosts AutoCodeRover's performance by 14.67%, achieving a score of
51.67% and surpassing all prior baselines. On SWE-Bench Verified, Refine
improves the resolution rate by 12.2%, and when integrated across multiple APR
systems, it yields an average improvement of 14%-demonstrating its broad
effectiveness and generalizability. These results highlight the effectiveness
of refinement as a missing component in current APR pipelines and the potential
of agentic collaboration in closing the gap between near-correct and correct
patches. We also open source our code.

</details>


### [11] [Generating High-Level Test Cases from Requirements using LLM: An Industry Study](https://arxiv.org/abs/2510.03641)
*Satoshi Masuda,Satoshi Kouzawa,Kyousuke Sezai,Hidetoshi Suhara,Yasuaki Hiruta,Kunihiro Kudou*

Main category: cs.SE

TL;DR: 该论文提出了一种不依赖RAG，仅使用LLM和prompt自动生成需求文档高层测试用例的方法，在实际数据集上获得良好效果，具备较强行业推广价值。


<details>
  <summary>Details</summary>
Motivation: 目前业界对自动从需求文档生成高层次测试用例有强烈需求，传统方法依赖手工，或需构建特定知识体系的RAG，过程繁琐且难以通用。亟需一种无需RAG且能广泛适用需求文档的通用方法。

Method: 提出一种仅用Prompt（提示词），不依赖RAG，通过LLMs自动从需求文档中生成高层测试用例。具体方法为：首先将需求文档输入LLM以生成相应测试设计技术；随后针对每个设计技术生成高层测试用例，并采用语义相似度进行效果评估。

Result: 在Bluetooth和Mozilla数据集上验证，分别获得宏召回率0.81和0.37。表明此方法无需RAG即可有效生成高层次测试用例，具备实际应用可行性。

Conclusion: 本文提出的基于prompt的自动测试用例生成方法可行，降低了构建测试用例的人工和知识库依赖，适用于广泛需求文档场景，且实验结果支持其实用性。

Abstract: Currently, generating high-level test cases described in natural language
from requirement documents is performed manually. In the industry, including
companies specializing in software testing, there is a significant demand for
the automatic generation of high-level test cases from requirement documents
using Large Language Models (LLMs). Efforts to utilize LLMs for requirement
analysis are underway. In some cases, retrieval-augmented generation (RAG) is
employed for generating high-level test cases using LLMs. However, in practical
applications, it is necessary to create a RAG tailored to the knowledge system
of each specific application, which is labor-intensive. Moreover, when applying
high-level test case generation as a prompt, there is no established method for
instructing the generation of high-level test cases at a level applicable to
other specifications without using RAG. It is required to establish a method
for the automatic generation of high-level test cases that can be generalized
across a wider range of requirement documents. In this paper, we propose a
method for generating high-level (GHL) test cases from requirement documents
using only prompts, without creating RAGs. In the proposed method, first, the
requirement document is input into the LLM to generate test design techniques
corresponding to the requirement document. Then, high-level test cases are
generated for each of the generated test design techniques. Furthermore, we
verify an evaluation method based on semantic similarity of the generated
high-level test cases. In the experiments, we confirmed the method using
datasets from Bluetooth and Mozilla, where requirement documents and high-level
test cases are available, achieving macro-recall measurement of 0.81 and 0.37,
respectively. We believe that the method is feasible for practical application
in generating high-level test cases without using RAG.

</details>


### [12] [Detecting and Preventing Latent Risk Accumulation in High-Performance Software Systems](https://arxiv.org/abs/2510.03712)
*Jahidul Arafat,Kh. M. Moniruzzaman,Shamim Hossain,Fariha Tasmin,Kamrujjaman,Ahsan Habib Tareq*

Main category: cs.SE

TL;DR: 本文提出了面向分布式系统优化导致隐患的系统性风险检测与规避框架，涵盖建模、扰动测试及风险优化三大环节，并在大规模实际与测试环境中实现了高准确率、极强收益和可复现性，为可靠性工程转型提供了路径。


<details>
  <summary>Details</summary>
Motivation: 现有分布式系统依赖激进的性能优化使得隐性脆弱点被掩盖，可靠性工程大多为事后响应而非事前主动识别，亟需系统性的方法来预警、规避优化诱导的潜在风险。

Method: 整合数学建模、智能扰动测试和风险感知性能优化三种方法，开发出LRI指标，以及HYDRA、RAVEN和APEX三个系统，实现风险预测、监控与优化。

Result: 该框架通过HYDRA获得89.7%的风险发现率，RAVEN实现92.9%的精度与93.8%的召回率，APEX在保持96.6%性能基线下减少59.2%潜在风险。24周生产环境部署实现69.1%恢复时间下降、78.6%事故严重性降低、81起事故避免，平均年化收益达144万美元，投资回报3.2个月。

Conclusion: 提出了一套针对现代分布式系统中优化所带来的潜在风险进行检测、防范和优化的综合性框架，并通过理论与实证方法验证了该框架在准确发现和减少系统隐患方面的有效性。

Abstract: Modern distributed systems employ aggressive optimization strategies that
create latent risks - hidden vulnerabilities where exceptional performance
masks catastrophic fragility when optimizations fail. Cache layers achieving
99% hit rates can obscure database bottlenecks until cache failures trigger
100x load amplification and cascading collapse. Current reliability engineering
focuses on reactive incident response rather than proactive detection of
optimization-induced vulnerabilities. This paper presents the first
comprehensive framework for systematic latent risk detection, prevention, and
optimization through integrated mathematical modeling, intelligent perturbation
testing, and risk-aware performance optimization. We introduce the Latent Risk
Index (LRI) that correlates strongly with incident severity (r=0.863, p<0.001),
enabling predictive risk assessment. Our framework integrates three systems:
HYDRA employing six optimization-aware perturbation strategies achieving 89.7%
risk discovery rates, RAVEN providing continuous production monitoring with
92.9% precision and 93.8% recall across 1,748 scenarios, and APEX enabling
risk-aware optimization maintaining 96.6% baseline performance while reducing
latent risks by 59.2%. Evaluation across three testbed environments
demonstrates strong statistical validation with large effect sizes (Cohen
d>2.0) and exceptional reproducibility (r>0.92). Production deployment over 24
weeks shows 69.1% mean time to recovery reduction, 78.6% incident severity
reduction, and 81 prevented incidents generating 1.44M USD average annual
benefits with 3.2-month ROI. Our approach transforms reliability engineering
from reactive incident management to proactive risk-aware optimization.

</details>


### [13] [APIDA-Chat: Structured Synthesis of API Search Dialogues to Bootstrap Conversational Agents](https://arxiv.org/abs/2510.03743)
*Zachary Eberhart,Collin McMillan*

Main category: cs.SE

TL;DR: APIDA-Chat是一条自动生成API对话数据的开源流程，显著提升小模型对小众API的理解与解释能力，无须依赖昂贵算力或外部服务。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型善于解释主流API，但面对冷门或专有库时，由于缺乏丰富的多轮对话微调数据，效果较差。该工作旨在解决针对低资源API领域的对话训练数据稀缺问题。

Method: 提出APIDA-Chat流程。第一阶段，利用传统对话规划器与高性能LLM（o4-mini）协同生成高质量对话，再用小模型（Llama 3.2 3B）微调得到学生模型。第二阶段，使用经过微调的学生模型与原规划器快速生成新对话，无需暴露源代码或调用外部服务。

Result: 微调后模型BLEU由0.38提升到0.50，BERTScore由0.88提升到0.91；全部流程可在消费级GPU上运行，系统开源并支持灵活扩展。

Conclusion: APIDA-Chat实现了一种高效且低成本的方法，能够自动生成高质量、领域相关的API对话数据，显著改善小模型在解释小众或私有API时的能力。

Abstract: Large-language-model assistants are suitable for explaining popular APIs, yet
they falter on niche or proprietary libraries because the multi-turn dialogue
data needed for fine-tuning are scarce. We present APIDA-Chat, an open-source
pipeline that converts symbolic dialogue-act "scripts" into realistic,
domain-grounded API Search conversations using a lightweight model for
inexpensive training data generation. Phase I pairs a legacy dialogue planner
with a high-capability teacher LLM (o4-mini) to synthesize a "gold set" of
realized dialogues; then, a smaller Llama 3.2 3B student model is fine-tuned on
this corpus. Phase II drops the teacher and reuses the same planner with the
fine-tuned model, allowing rapid, low-cost synthesis of new dialogues without
exposing source code to external services. The fine-tuned student improves BLEU
from 0.38 to 0.50 and BERTScore from 0.88 to 0.91 versus the base model while
running entirely on a single consumer GPU. All components are modular and
publicly released to serve as a conservative baseline for future work.
APIDA-Chat is open-sourced at https://github.com/Zeberhart/apida-chat and a
video demo is available at https://youtu.be/YqmZBHyGbPs .

</details>


### [14] [Code4MeV2: a Research-oriented Code-completion Platform](https://arxiv.org/abs/2510.03755)
*Roham Koohestani,Parham Bateni,Aydin Ebrahimi,Behdad Etezadi,Kiarash Karimi,Maliheh Izadi*

Main category: cs.SE

TL;DR: 本研究提出了开源插件 Code4MeV2，为学术界提供了业界水平的代码补全和数据采集能力，弥补了现有专有工具带来的数据壁垒，预期将促进人机协作相关研究。


<details>
  <summary>Details</summary>
Motivation: 当前主流 AI 代码补全工具的数据仍被大公司垄断，学术界难以获得交互数据，阻碍了研究的可复现性和大规模数据分析。

Method: 文章介绍了 Code4MeV2 的架构设计（客户端-服务器）、主要功能（内联代码补全和上下文感知聊天助手），并通过专家评估和八位参与者的用户研究对工具进行了测试。

Result: Code4MeV2 能实现约 200 毫秒的代码补全延迟，功能实用，收集反馈显示工具的信息量和有用性较高。

Conclusion: Code4MeV2 是一个开源、面向研究的代码补全插件，能支持 JetBrains IDE，具有与业界水平相当的性能，并且提供了细粒度、透明的数据收集框架，得到了专家和用户的积极反馈。

Abstract: The adoption of AI-powered code completion tools in software development has
increased substantially, yet the user interaction data produced by these
systems remain proprietary within large corporations. This creates a barrier
for the academic community, as researchers must often develop dedicated
platforms to conduct studies on human--AI interaction, making reproducible
research and large-scale data analysis impractical. In this work, we introduce
Code4MeV2, a research-oriented, open-source code completion plugin for
JetBrains IDEs, as a solution to this limitation. Code4MeV2 is designed using a
client--server architecture and features inline code completion and a
context-aware chat assistant. Its core contribution is a modular and
transparent data collection framework that gives researchers fine-grained
control over telemetry and context gathering. Code4MeV2 achieves
industry-comparable performance in terms of code completion, with an average
latency of 200~ms. We assess our tool through a combination of an expert
evaluation and a user study with eight participants. Feedback from both
researchers and daily users highlights its informativeness and usefulness. We
invite the community to adopt and contribute to this tool. More information
about the tool can be found at https://app.code4me.me.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [15] [An Empirical Study of Rational Tree Unification for miniKanren](https://arxiv.org/abs/2510.03789)
*Eridan Domoratskiy,Dmitrii Kosarev,Dmitry Boulytchev*

Main category: cs.LO

TL;DR: 本文针对miniKanren，定义并优化了理性树的统一算法，证明了其性质，并通过基准测试展示其有效性，讨论了与传统统一算法的关系及共存方案。


<details>
  <summary>Details</summary>
Motivation: miniKanren等关系型编程对理性树统一的需求，推动高效且可证明正确性的统一算法研究。

Method: 定义理性树，指定统一算法，证明算法性质，引入启发式优化，并通过相关基准测试进行评估。

Result: 提出了理性树的统一算法及其优化方法，并给出评测结果，分析了与传统统一算法的关系及共存场景。

Conclusion: 理性树的统一算法可以有效应用于miniKanren，并且与传统统一算法可在关系型编程中共存。

Abstract: We present a study of unification for rational trees in the context of
miniKanren. We give the definition of rational trees, specify the unification
algorithm and prove some of its properties. We also introduce a number of
heuristic optimizations and evaluate them for a number of relevant benchmarks.
Finally we discuss the relations between rational and conventional unification
algorithms and possible scenarios of their coexistence in the context of
relational programming.

</details>


### [16] [Unreliability in Practical Subclasses of Communicating Systems](https://arxiv.org/abs/2510.03941)
*Amrita Suresh,Nobuko Yoshida*

Main category: cs.LO

TL;DR: 论文针对通讯自动机的两种故障场景（干扰、崩溃）提出了放宽和扩展，使两类重要可判定性属性（RSC、k-MC）在故障下仍具韧性与可用性，并通过工具验证代表协议，证明其实用价值。


<details>
  <summary>Details</summary>
Motivation: 现有通讯自动机系统对于点对点消息传递具有强大建模能力，但一般情况下大部分验证属性都不可判定。虽然提出了可判定的RSC与k-MC两个子类并开发了相应工具，但这两者在遇到现实中的干扰和崩溃等故障时并不具备韧性。

Method: 该论文研究了RSC和k-MC在两种故障情景下（干扰与崩溃停止）下的韧性。对于干扰，作者放宽了RSC和k-MC的条件，并证明在干扰情况下其判定性仍成立且复杂度未变。针对崩溃，提出了新的崩溃处理通讯系统，比现有MPST模型涵盖更广行为，并研究了将带崩溃的MPST转译到该系统与RSC、k-MC属性结合的可判定性。

Result: （1）放宽干扰下的RSC与k-MC可判定性和复杂度得到保持；（2）提出新的系统对崩溃停止更具表现力，且相关可判定性结果成立；（3）通过用扩展工具验证代表性协议，展示了这些系统在故障情况下的韧性。

Conclusion: 通过方法创新，本文使RSC和k-MC模型在多种故障下具备更好的韧性，并且相关性质保持可判定性，为协议验证提供了更可靠的理论和工具支持。

Abstract: Systems of communicating automata are prominent models for peer-to-peer
message-passing over unbounded channels, but in the general scenario, most
verification properties are undecidable. To address this issue, two decidable
subclasses, Realisable with Synchronous Communication (RSC) and k-Multiparty
Compatibility} (k-MC), were proposed in the literature, with corresponding
verification tools developed and applied in practice. Unfortunately, both RSC
and k-MC are not resilient under failures: (1) their decidability relies on the
assumption of perfect channels and (2) most standard protocols do not satisfy
RSC or k-MC under failures. To address these limitations, this paper studies
the resilience of RSC and k-MC under two distinct failure models: interference
and crash-stop failures. For interference, we relax the conditions of RSC and
k-MC and prove that the inclusions of these relaxed properties remain decidable
under interference, preserving their known complexity bounds. We then propose a
novel crash-handling communicating system that captures wider behaviours than
existing multiparty session types (MPST) with crash-stop failures. We study a
translation of MPST with crash-stop failures into this system integrating RSC
and k-MC properties, and establish their decidability results. Finally, by
verifying representative protocols from the literature using RSC and k-MC tools
extended to interferences, we evaluate the relaxed systems and demonstrate
their resilience.

</details>


### [17] [Interpolation in First-Order Logic](https://arxiv.org/abs/2510.03822)
*Balder ten Cate,Jesse Comer*

Main category: cs.LO

TL;DR: 该文综述了一阶逻辑及其片段中的Craig插值定理及应用，帮助读者快速了解其理论发展、实际应用和计算方法。


<details>
  <summary>Details</summary>
Motivation: Craig插值定理及其扩展在逻辑学与计算机科学中有重要应用，但相关理论和技术分布在众多文献中，需要一个易于入门的总结和导航。

Method: 通过文献回顾，系统梳理了Craig插值定理的各种精细化结果、主要应用和对于一阶逻辑各语法片段的相关插值性研究，以及插值子的计算问题。

Result: 论文总结了已有的Craig插值定理相关理论、应用实例、在一阶逻辑及其各重要片段中的结果，以及计算插值子面临的难题和已有方法。

Conclusion: 本文为一阶逻辑及其片段中的Craig插值定理及其应用提供了综述和文献入门。

Abstract: In this chapter we give a basic overview of known results regarding Craig
interpolation for first-order logic as well as for fragments of first-order
logic. Our aim is to provide an entry point into the literature on
interpolation theorems for first-order logic and fragments of first-order
logic, and their applications. In particular, we cover a range of known
refinements of the Craig interpolation theorem, we discuss several important
applications of interpolation in logic and computer science, we review known
results about interpolation for important syntactic fragments of first-order
logic, and we discuss the problem of computing interpolants.

</details>


### [18] [On Hyperproperty Verification, Quantifier Alternations, and Games under Partial Information](https://arxiv.org/abs/2510.03942)
*Raven Beutner,Bernd Finkbeiner*

Main category: cs.LO

TL;DR: 本文针对现有hyperproperties自动化验证难以处理量词交替的瓶颈，提出利用多方部分信息游戏的方法，显著扩展了可验证的HyperLTL性质范围，且在分层信息条件下保证判定性与效率，对安全分析等领域具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 传统的trace性质只能针对单次执行进行推理，无法表达涉及多个执行轨迹之间关系的hyperproperties，而许多实际系统的关键安全属性（如信息流等）属于hyperproperties。现有基于HyperLTL等时序逻辑的自动化验证方法对涉及量词交替的复杂hyperproperties难以处理，完整的验证需系统互补化，每次交替都增加巨大计算负担，使得在实践中不可行，因此亟需更高效的验证方法。

Method: 提出将hyperproperties验证问题建模为多方部分信息游戏，打破了现有方法对$orall^*
exists^*$结构的限制。通过分析这些多方游戏在分层信息（hierarchical information）下属于可判定问题，并结合预言变量（prophecy variables）技术分析部分信息环境下的逻辑性质和方法完备性。

Result: 证明了在分层信息条件下，多方部分信息游戏是可判定的，可以支持具有任意量词交替的hyperproperties自动化验证。对游戏方法的完备性与实践的局限进行论证，并就预言变量在该框架下的应用进行了研究与讨论。

Conclusion: 通过游戏化建模，在自动化验证方面扩展了可处理的hyperproperties类别，让具有更复杂量词结构的需求能够高效验证，推进了相关理论与实际应用边界。

Abstract: Hyperproperties generalize traditional trace properties by relating multiple
execution traces rather than reasoning about individual runs in isolation. They
provide a unified way to express important requirements such as information
flow and robustness properties. Temporal logics like HyperLTL capture these
properties by explicitly quantifying over executions of a system. However, many
practically relevant hyperproperties involve quantifier alternations, a feature
that poses substantial challenges for automated verification. Complete
verification methods require a system complementation for each quantifier
alternation, making it infeasible in practice. A cheaper (but incomplete)
method interprets the verification of a HyperLTL formula as a two-player game
between universal and existential quantifiers. The game-based approach is
significantly cheaper, facilitates interactive proofs, and allows for
easy-to-check certificates of satisfaction. It is, however, limited to
$\forall^*\exists^*$ properties, leaving important properties out of reach. In
this paper, we show that we can use games to verify hyperproperties with
arbitrary quantifier alternations by utilizing multiplayer games under partial
information. While games under partial information are, in general,
undecidable, we show that our game is played under hierarchical information and
thus falls in a decidable class of games. We discuss the completeness of the
game and study prophecy variables in the setting of partial information.

</details>


### [19] [Strategy Logic, Imperfect Information, and Hyperproperties](https://arxiv.org/abs/2510.03952)
*Raven Beutner,Bernd Finkbeiner*

Main category: cs.LO

TL;DR: 本文讨论战略逻辑（SL）、不完全信息下的战略逻辑（SL_ii）与超战略逻辑（HyperSL）之间的关系，证明在限定条件下SL_ii与HyperSL在表达能力上可以互相编码，是等价的。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统（MAS）中，代理经常无法观察系统的全局状态，这导致了对不完全信息下战略逻辑（SL）扩展的研究。同时，研究者也对战略行为与超属性（Hyperproperties）的结合进行了研究，超属性通常用于表达涉及多个系统执行之间关系的安全策略。本论文旨在探究两种逻辑（SL_ii与HyperSL）之间的关系。

Method: 将SL_ii与HyperSL进行对比研究，并限定在没有状态公式嵌套于路径公式的情况。首先，通过已知的不完全信息是超属性的结论，将SL_ii实例编码到HyperSL，反方向则通过自我组合多智能体系统来实现用不完全信息模拟超属性。

Result: 限定条件下，SL_ii和HyperSL是等价的，可以将SL_ii实例编码到HyperSL实例，反之亦然。

Conclusion: 结论是，只要公式不嵌套状态公式，战略逻辑不完全信息（SL_ii）与超战略逻辑（HyperSL）在表达能力上等价。

Abstract: Strategy logic (SL) is a powerful temporal logic that enables first-class
reasoning over strategic behavior in multi-agent systems (MAS). In many MASs,
the agents (and their strategies) cannot observe the global state of the
system, leading to many extensions of SL centered around imperfect information,
such as strategy logic with imperfect information (SL$_\mathit{ii}$). Along
orthogonal lines, researchers have studied the combination of strategic
behavior and hyperproperties. Hyperproperties are system properties that relate
multiple executions in a system and commonly arise when specifying security
policies. Hyper Strategy Logic (HyperSL) is a temporal logic that combines
quantification over strategies with the ability to express hyperproperties on
the executions of different strategy profiles. In this paper, we study the
relation between SL$_\mathit{ii}$ and HyperSL. Our main result is that both
logics (restricted to formulas where no state formulas are nested within path
formulas) are equivalent in the sense that we can encode SL$_\mathit{ii}$
instances into HyperSL instances and vice versa. For the former direction, we
build on the well-known observation that imperfect information is a
hyperproperty. For the latter direction, we construct a self-composition of
MASs and show how we can simulate hyperproperties using imperfect information.

</details>


### [20] [A Complete Diagrammatic Calculus for Conditional Gaussian Mixtures](https://arxiv.org/abs/2510.04649)
*Mateo Torres-Ruiz,Robin Piedeleu,Alexandra Silva,Fabio Zanasi*

Main category: cs.LO

TL;DR: 本文扩展了概率模型的合成理论，引入了可组合的图示演算方法以处理离散与高斯连续变量混合情形，尤其适用于高斯混合模型，并提供了判别模型等价性的完备理论。


<details>
  <summary>Details</summary>
Motivation: 现有合成概率理论主要针对离散和高斯（连续）情形，缺乏描述混合模型（如高斯混合模型）的方法。本文旨在填补这方面理论及工具的空白，以满足实际建模需求。

Method: 采用弦图（string diagram）语法来表达和组合混合概率模型，并为其赋予了组合语义，通过构建完备且可靠的等价理论确保模型之间可比较。

Result: 提出了用于混合概率模型的图示演算体系，能够系统地构建和分析模型，还建立了完整的判别两个模型等价的理论标准。

Conclusion: 本文提出了一种用于混合概率模型（离散与连续变量结合）的图示演算方法，并建立了判定何时两个模型代表相同分布的理论基础。

Abstract: We extend the synthetic theories of discrete and Gaussian categorical
probability by introducing a diagrammatic calculus for reasoning about hybrid
probabilistic models in which continuous random variables, conditioned on
discrete ones, follow a multivariate Gaussian distribution. This setting
includes important classes of models such as Gaussian mixture models, where
each Gaussian component is selected according to a discrete variable. We
develop a string diagrammatic syntax for expressing and combining these models,
give it a compositional semantics, and equip it with a sound and complete
equational theory that characterises when two models represent the same
distribution.

</details>


### [21] [Continuation Semantics for Fixpoint Modal Logic and Computation Tree Logics](https://arxiv.org/abs/2510.04653)
*Ryota Kojima,Corina Cirstea*

Main category: cs.LO

TL;DR: 本文提出了一种基于延续Monad的统一语义框架，使FML和CTL*在所有分支类型下都能与煤代数语义等价，同时重构了CTL*的模型，使其支持更灵活的执行图。这项工作为相关逻辑的表述和编码方式提供了理论基础和新的可能性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在为定点模态逻辑（FML）和计算树逻辑*（CTL*）提出一种新的形式语义——延续语义。当前相关逻辑在处理分支类型与量化谓词提升时存在一定局限，作者希望能统一和推广现有的语义框架。

Method: 作者基于延续Monad上的上煤代数（coalgebra），定义了延续语义，并将公式的真值域设为答案类型。通过将谓词与延续进行识别，该煤代数实现了模态性由延续求值来解释。随后，作者将CTL*的煤代数语义进行重构，引入非最大点的执行图（execution map），并证明了通过Monad态射可以转移执行图，达到了延续语义与煤代数语义的等价。

Result: 作者证明了FML和CTL*的延续语义在所有分支类型下与煤代数语义等价。同时，提出了CTL*煤代数模型允许非最大点执行图的新框架，并针对Monad态射给出执行图的转移结果。此外还找到了一个充分条件，可将CTL编码到FML的延续语义下。

Conclusion: 延续语义为FML和CTL*提供了新的统一语义框架，并在广义分支结构下与传统煤代数语义保持等价。提出的新型CTL*模型更灵活，有助于理论推广与应用，且为CTL向FML的语义编码提供了理论支持。

Abstract: We introduce continuation semantics for both fixpoint modal logic (FML) and
Computation Tree Logic* (CTL*), parameterised by a choice of branching type and
quantitative predicate lifting. Our main contribution is proving that they are
equivalent to coalgebraic semantics, for all branching types. Our continuation
semantics is defined over coalgebras of the continuation monad whose answer
type coincides with the domain of truth values of the formulas. By identifying
predicates and continuations, such a coalgebra has a canonical interpretation
of the modality by evaluation of continuations. We show that this continuation
semantics is equivalent to the coalgebraic semantics for fixpoint modal logic.
We then reformulate the current construction for coalgebraic models of CTL*.
These models are usually required to have an infinitary trace/maximal execution
map, characterized as the greatest fixpoint of a special operator. Instead, we
allow coalgebraic models of CTL* to employ non-maximal fixpoints, which we call
execution maps. Under this reformulation, we establish a general result on
transferring execution maps via monad morphisms. From this result, we obtain
that continuation semantics is equivalent to the coalgebraic semantics for
CTL*. We also identify a sufficient condition under which CTL can be encoded
into fixpoint modal logic under continuation semantics.

</details>


### [22] [Curved Boolean Logic: A Contextual Generalization of Propositional Logic with Algorithmic Consequences](https://arxiv.org/abs/2510.04716)
*Maximilian R. P. von Liechtenstein*

Main category: cs.LO

TL;DR: 该论文提出了一种推广的曲率布尔逻辑（CBL），允许局部真值无法扩展为全局一致性，给出了相关理论、复杂性分析、剪枝算法与代码实现，并探讨了与经典与现代人工智能模型之间的联系及应用潜力。


<details>
  <summary>Details</summary>
Motivation: 传统的命题逻辑要求所有真值赋值必须能扩展为一个全局一致的赋值，但在许多实际情况或复杂系统中，这种全局一致性往往不能保证。该论文旨在推广这种逻辑框架，引入类似于几何曲率的思想，允许局部的真值分配无法延伸为整体一致的解，从而扩展逻辑系统的表达与建模能力。

Method: 作者提出了Curved Boolean Logic（CBL），并给出了等价的层析（sheaf）语义与排斥图（exclusivity-graph）语义。同时，设计了一种上下文感知的证明演算，该演算在局部一致退化为传统逻辑。正式定义了CBL的可满足性问题（CBL-SAT），对其复杂性进行了分析（总体为NP-完全）。提出了两种运算符（CBL-AC和CBL-CONS），能更早在经典硬件上剪枝矛盾。此外，引入了噪声建模（独立同分布、AR(1)相关、对抗性有界扰动），采用基于排列检验的方法和Benjamini-Hochberg假发现率控制进行统计显著性分析，并提供了可复现代码和辅助材料。

Result: CBL框架在理论上推广了命题逻辑，能更有效地表述局部一致但全局不一致的情景。方法在经典硬件上提升了剪枝效率。此外，作者展示了该模型与KCBS、CSW、层析框架、可满足性/约束满足问题（SAT/CSP）以及大型语言模型中鲁棒性和适配器稳定性的关系和应用前景。

Conclusion: 该论文为推广和应用命题逻辑提供了新视角，使其可描述更广泛的复杂系统局部与全局不一致性，为SAT/CSP求解优化、大模型鲁棒性分析等方向提供了理论与工具基础。CBL在理论与实际计算中具有重要前景。

Abstract: Curved Boolean Logic (CBL) generalizes propositional logic by allowing local
truth assignments that do not extend to a single global valuation, analogous to
curvature in geometry. We give equivalent sheaf and exclusivity-graph semantics
and a context-aware proof calculus that is conservative in the flat limit. We
formalize CBL-SAT and basic complexity (NP-complete in general) and present
operational operators (CBL-AC and CBL-CONS) that prune contradictions earlier
on classical hardware. We model noise with iid, AR(1)-correlated, and
adversarial bounded perturbations and provide permutation-based significance
with Benjamini-Hochberg FDR control. A Colab-ready notebook (ancillary files)
regenerates all figures and statistics. We position CBL relative to KCBS, CSW,
and sheaf frameworks and outline links to SAT/CSP and robustness/adapter
stability in large language models.

</details>


### [23] [One rig to control them all](https://arxiv.org/abs/2510.05032)
*Chris Heunen,Robin Kaarsgaard,Louis Lemonnier*

Main category: cs.LO

TL;DR: 本文提出了一种由七个方程组成的计算控制理论，能够统一描述受控电路，并证明其与已知范畴结构等价，推动了量子电路等领域的理论发展。


<details>
  <summary>Details</summary>
Motivation: 受控电路在可逆计算和量子计算中具有重要作用，现有理论尚缺乏统一、可解释的代数结构来描述受控电路的构造。本文旨在通过一套方程为计算控制提供通用的理论基础。

Method: 提出了七个可解释的方程来构建计算控制理论，这些方程可以加入到基本电路的框架（prop）中，以构建受控电路。作者通过反向布尔电路和量子电路的例子展现了该方法。最后，证明了该构造在语义上等价于在基本框架上取自由rig范畴。

Result: 作者构建了一套由七个方程组成的理论体系，并用其成功描述了受控布尔电路和量子电路。所提出的构造与自由rig范畴在语义上是等价的。

Conclusion: 本文为受控电路的计算控制问题提供了可解释的代数结构，并证明了该结构与自由rig范畴的语义对应，为后续理论和实际应用提供了基础。

Abstract: We introduce a theory for computational control, consisting of seven
naturally interpretable equations. Adding these to a prop of base circuits
constructs controlled circuits, borne out in examples of reversible Boolean
circuits and quantum circuits. We prove that this syntactic construction
semantically corresponds to taking the free rig category on the base prop.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [24] [Decomposing Attention To Find Context-Sensitive Neurons](https://arxiv.org/abs/2510.03315)
*Alex Gibson*

Main category: cs.CL

TL;DR: 作者提出了一种利用注意力头softmax分母稳定性，从权重和校准文本中发现、解释第一层神经元语境响应能力的方法，有助于深入理解GPT2结构。


<details>
  <summary>Details</summary>
Motivation: 研究变压器语言模型时，关注那些注意力分布较为分散、且成绩对内容依赖较弱的注意力头，这有助于理解模型内部机制。

Method: 分析GPT2-Small第一层的attention head，通过采样softmax分母的方式，结合“校准文本”稳定这些头的输出，并用线性方法近似地总结文本上下文。

Result: 可以仅凭模型权重和一段校准文本，揭示出大量对高级语境属性敏感的一层神经元，包括校准文本中未激活的神经元。

Conclusion: 本文方法为挖掘和解释transformer模型隐层中负责上下文语义的神经元提供了新途径。

Abstract: We study transformer language models, analyzing attention heads whose
attention patterns are spread out, and whose attention scores depend weakly on
content. We argue that the softmax denominators of these heads are stable when
the underlying token distribution is fixed. By sampling softmax denominators
from a "calibration text", we can combine together the outputs of multiple such
stable heads in the first layer of GPT2-Small, approximating their combined
output by a linear summary of the surrounding text. This approximation enables
a procedure where from the weights alone - and a single calibration text - we
can uncover hundreds of first layer neurons that respond to high-level
contextual properties of the surrounding text, including neurons that didn't
activate on the calibration text.

</details>


### [25] [Graph-S3: Enhancing Agentic textual Graph Retrieval with Synthetic Stepwise Supervision](https://arxiv.org/abs/2510.03323)
*Ge Chang,Jinbo Su,Jiacheng Liu,Pengfei Yang,Yuhao Shang,Huiwen Zheng,Hongli Ma,Yan Liang,Yuanchun Li,Yunxin Liu*

Main category: cs.CL

TL;DR: 本文提出了一种结合LLM和合成监督的文本图问答检索框架Graph-$S^3$，通过创新的数据合成和分阶段训练实现了对复杂图问答的高效和高质量检索，实验显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在基于文本图的问答中，难以高效检索信息，现有方法要么依赖劣质的嵌入相似度，要么需要大量数据标注和训练资源，性能受限。

Method: 设计了一个LLM驱动的智能检索器，结合数据合成管道用于生成高质量的奖励子图，以及分阶段训练机制用于优化图探索策略。每一步奖励来自离线提取的黄金子图而非最终答案。

Result: 在三个主流数据集与七个先进方法对比，Graph-$S^3$平均提升准确率8.1%，F$_1$分数提升9.7%。多跳复杂推理中优势更显著。代码将开源。

Conclusion: 提出了一种新的基于LLM的文本图检索和推理框架Graph-$S^3$，通过合成的步骤级监督方式显著提升了复杂图问题的问答能力。

Abstract: A significant portion of real-world data is inherently represented as textual
graphs, and integrating these graphs into large language models (LLMs) is
promising to enable complex graph-based question answering. However, a key
challenge in LLM-based textual graph QA systems lies in graph retrieval, i.e.,
how to retrieve relevant content from large graphs that is sufficiently
informative while remaining compact for the LLM context. Existing retrievers
suffer from poor performance since they either rely on shallow embedding
similarity or employ interactive retrieving policies that demand excessive data
labeling and training cost. To address these issues, we present Graph-$S^3$, an
agentic textual graph reasoning framework that employs an LLM-based retriever
trained with synthetic stepwise supervision. Instead of rewarding the agent
based on the final answers, which may lead to sparse and unstable training
signals, we propose to closely evaluate each step of the retriever based on
offline-extracted golden subgraphs. Our main techniques include a data
synthesis pipeline to extract the golden subgraphs for reward generation and a
two-stage training scheme to learn the interactive graph exploration policy
based on the synthesized rewards. Based on extensive experiments on three
common datasets in comparison with seven strong baselines, our approach
achieves an average improvement of 8.1\% in accuracy and 9.7\% in F$_1$ score.
The advantage is even higher in more complicated multi-hop reasoning tasks. Our
code will be open-sourced.

</details>


### [26] [Implicit Values Embedded in How Humans and LLMs Complete Subjective Everyday Tasks](https://arxiv.org/abs/2510.03384)
*Arjun Arunasalam,Madison Pickering,Z. Berkay Celik,Blase Ur*

Main category: cs.CL

TL;DR: 本研究对六款 LLMs 及普通人类在 30 项日常任务的隐性价值观表现进行了比较，结果发现 LLMs 在价值表达方面与人类及彼此之间均有较大差异，提示现有 AI 助手在主观任务上有待进一步完善。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）正在成为 AI 助手的核心，能够帮助用户完成日常任务，但我们对这些助手在主观性任务中体现的隐性价值观了解甚少，如环境保护、慈善和多样性等。探究 LLMs 在执行日常任务时是否体现这些价值，以及与人类相比表现如何，是本研究的核心动机。

Method: 作者对六个主流 LLMs 在完成 30 项日常任务过程中的表现进行了审查，并将它们的结果与 100 名美国众包工人（人类）进行了对比。分析内容聚焦于隐性价值观的体现与差异。

Result: 研究发现，LLMs 在体现隐性价值观方面，往往既不与人类一致，也不与其他 LLMs 保持一致，说明现有 LLMs 在主观性任务中的价值观表达存在显著差异。

Conclusion: 目前流行的大语言模型在主观性日常任务中表现出的隐性价值观未能很好地与人类或其他模型保持一致，对 AI 助手进一步优化和规范提出了挑战。

Abstract: Large language models (LLMs) can underpin AI assistants that help users with
everyday tasks, such as by making recommendations or performing basic
computation. Despite AI assistants' promise, little is known about the implicit
values these assistants display while completing subjective everyday tasks.
Humans may consider values like environmentalism, charity, and diversity. To
what extent do LLMs exhibit these values in completing everyday tasks? How do
they compare with humans? We answer these questions by auditing how six popular
LLMs complete 30 everyday tasks, comparing LLMs to each other and to 100 human
crowdworkers from the US. We find LLMs often do not align with humans, nor with
other LLMs, in the implicit values exhibited.

</details>


### [27] [Morpheme Induction for Emergent Language](https://arxiv.org/abs/2510.03439)
*Brendon Boldt,David Mortensen*

Main category: cs.CL

TL;DR: 提出CSAR贪心算法，从形式-意义对应的新兴语言中自动归纳词素，效果优于基线方法，并能量化语言学特征。


<details>
  <summary>Details</summary>
Motivation: 在新兴语言或人工生成语言中，自动归纳出语素的能力对理解语言结构和构词过程至关重要，但现有方法在这种场景下效果有限。

Method: 提出了一种贪心算法CSAR（Count, Select, Ablate, Repeat），基于词形与意义之间的互信息对词素加权，不断选取最高加权对、移除并重复该过程；并通过合成数据集和真实语言数据集进行验证和比较。

Result: CSAR在程序生成的数据集以及人类语言数据集上验证有效，表现优于相关基线，并能用来量化新兴语言的同义性、以及多义性等语言学特征。

Conclusion: CSAR算法能有效从新兴语言语料中归纳词素，并在合成和人类语言数据集上表现出合理的预测能力，也能量化诸如同义性和多义性等语言特征。

Abstract: We introduce CSAR, an algorithm for inducing morphemes from emergent language
corpora of parallel utterances and meanings. It is a greedy algorithm that (1)
weights morphemes based on mutual information between forms and meanings, (2)
selects the highest-weighted pair, (3) removes it from the corpus, and (4)
repeats the process to induce further morphemes (i.e., Count, Select, Ablate,
Repeat). The effectiveness of CSAR is first validated on procedurally generated
datasets and compared against baselines for related tasks. Second, we validate
CSAR's performance on human language data to show that the algorithm makes
reasonable predictions in adjacent domains. Finally, we analyze a handful of
emergent languages, quantifying linguistic characteristics like degree of
synonymy and polysemy.

</details>


### [28] [Omni-Embed-Nemotron: A Unified Multimodal Retrieval Model for Text, Image, Audio, and Video](https://arxiv.org/abs/2510.03458)
*Mengyao Xu,Wenfei Zhou,Yauhen Babakhin,Gabriel Moreira,Ronay Ak,Radek Osmulski,Bo Liu,Even Oldridge,Benedikt Schifferer*

Main category: cs.CL

TL;DR: 该论文提出了一个统一的多模态检索模型Omni-Embed-Nemotron，支持文本、图像、音频和视频的高效跨模态检索，相比现有基于文本的检索和部分多模态方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 真实世界的信息需求日益复杂，常规的基于文本的检索方法难以应对PDF、幻灯片、视频等多模态、语义丰富的内容。当前如ColPali等研究表明，保留文档布局的图像式表示可提升检索质量，但现有模型多局限于文本和图片。

Method: 提出了Omni-Embed-Nemotron，这是一个支持文本、图像、音频、视频多模态统一检索的embedding模型。模型架构允许跨模态（如文本-视频）、联合模态（如文本-视频+音频）检索，详细介绍了体系结构、训练过程及评测方式。

Result: 实验表明，Omni-Embed-Nemotron在文本、图像、视频等检索任务中效果突出，能够提升跨多模态内容的检索能力。

Conclusion: Omni-Embed-Nemotron模型有效解决了真实世界多模态检索的痛点，实现了单一模型下对文本、图片、音频、视频的联合高质量检索，推进了多模态检索的发展。

Abstract: We present Omni-Embed-Nemotron, a unified multimodal retrieval embedding
model developed to handle the increasing complexity of real-world information
needs. While Retrieval-Augmented Generation (RAG) has significantly advanced
language models by incorporating external knowledge, existing text-based
retrievers rely on clean, structured input and struggle with the visually and
semantically rich content found in real-world documents such as PDFs, slides,
or videos. Recent work such as ColPali has shown that preserving document
layout using image-based representations can improve retrieval quality.
Building on this, and inspired by the capabilities of recent multimodal models
such as Qwen2.5-Omni, we extend retrieval beyond text and images to also
support audio and video modalities. Omni-Embed-Nemotron enables both
cross-modal (e.g., text - video) and joint-modal (e.g., text - video+audio)
retrieval using a single model. We describe the architecture, training setup,
and evaluation results of Omni-Embed-Nemotron, and demonstrate its
effectiveness in text, image, and video retrieval.

</details>


### [29] [Searching for the Most Human-like Emergent Language](https://arxiv.org/abs/2510.03467)
*Brendon Boldt,David Mortensen*

Main category: cs.CL

TL;DR: 本文提出信号博弈结合超参数优化的新型涌现通信框架，使用XferBench衡量语言与人类语言的相似度，发现熵可预测迁移表现，并总结了生成更拟人化语言的超参数选择。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能系统中的涌现语言往往与人类语言相差较大，提升涌现语言与人类语言的相似性对于提升其在人类语言任务中的迁移能力至关重要。如何设计更拟人化的涌现语言，以及有效衡量涌现语言与人类语言的相似度，是该领域的关键问题。

Method: 本文基于信号博弈（signalling game）框架，构建涌现通信环境，并通过超参数优化，以XferBench为目标函数。XferBench用来量化涌现语言与人类语言的统计相似度，具体方式为评估其在深度迁移学习任务中的表现。同时探讨熵指标对涌现语言迁移能力的预测作用，以及关于熵最小化性质的相关实验。

Result: 实验发现，通过合理选择超参数，可生成与人类语言更为相似、迁移能力更强的涌现语言。此外，文中证实了涌现通信系统呈现熵最小化特性，并发现熵对迁移性能具有一定预测力。

Conclusion: 基于信号博弈和超参数优化的涌现通信环境能够有效生成拟人化涌现语言，同时提出XferBench量化指标对促进涌现与人类语言的融合具有重要意义。对熵指标的分析为理解涌现语言系统的生成机制和性能预测提供了新视角。

Abstract: In this paper, we design a signalling game-based emergent communication
environment to generate state-of-the-art emergent languages in terms of
similarity to human language. This is done with hyperparameter optimization,
using XferBench as the objective function. XferBench quantifies the statistical
similarity of emergent language to human language by measuring its suitability
for deep transfer learning to human language. Additionally, we demonstrate the
predictive power of entropy on the transfer learning performance of emergent
language as well as corroborate previous results on the entropy-minimization
properties of emergent communication systems. Finally, we report
generalizations regarding what hyperparameters produce more realistic emergent
languages, that is, ones which transfer better to human language.

</details>


### [30] [Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model Reasoning](https://arxiv.org/abs/2510.04081)
*Honglin Lin,Qizhi Pei,Xin Gao,Zhuoshi Pan,Yu Li,Juntao Li,Conghui He,Lijun Wu*

Main category: cs.CL

TL;DR: 提出了一种代码辅助自动生成多样化、高质量推理数据的闭环系统，有效提升了大模型在数学推理任务的性能和泛化能力，开辟了无需人工参与的可信推理系统新路径。


<details>
  <summary>Details</summary>
Motivation: 大模型在解决复杂任务时推理能力至关重要，但现有链式思维（CoT）方法存在生成控制不足、质量不高和推理路径多样性有限等问题，且基于代码的方法通常受限于特定数学问题，缺乏通用性和可扩展性。

Method: 提出Caco（Code-Assisted Chain-of-ThOught）框架，通过代码驱动的增强自动合成高质量、可验证、多样化的推理数据。方法包括：统一代码格式训练CoT生成器、通过代码生成多样推理轨迹、利用代码执行与规则过滤自动验证逻辑正确性与结构多样性，再反向转换为自然语言指令和语言CoT，闭环自动化生成推理数据。

Result: Caco框架生成的Caco-1.3M数据集训练的模型在数学推理基准任务上表现优异，超过现有强基线。分析表明，Caco的代码验证和指令多样性提升了对新任务的泛化能力。

Conclusion: Caco为无需人工干预构建自循环、可靠的推理系统建立了新范式，实现了高质量、可扩展的自动推理数据生成。

Abstract: Reasoning capability is pivotal for Large Language Models (LLMs) to solve
complex tasks, yet achieving reliable and scalable reasoning remains
challenging. While Chain-of-Thought (CoT) prompting has become a mainstream
approach, existing methods often suffer from uncontrolled generation,
insufficient quality, and limited diversity in reasoning paths. Recent efforts
leverage code to enhance CoT by grounding reasoning in executable steps, but
such methods are typically constrained to predefined mathematical problems,
hindering scalability and generalizability. In this work, we propose Caco
(Code-Assisted Chain-of-ThOught), a novel framework that automates the
synthesis of high-quality, verifiable, and diverse instruction-CoT reasoning
data through code-driven augmentation. Unlike prior work, Caco first fine-tunes
a code-based CoT generator on existing math and programming solutions in a
unified code format, then scales the data generation to a large amount of
diverse reasoning traces. Crucially, we introduce automated validation via code
execution and rule-based filtering to ensure logical correctness and structural
diversity, followed by reverse-engineering filtered outputs into natural
language instructions and language CoTs to enrich task adaptability. This
closed-loop process enables fully automated, scalable synthesis of reasoning
data with guaranteed executability. Experiments on our created Caco-1.3M
dataset demonstrate that Caco-trained models achieve strong competitive
performance on mathematical reasoning benchmarks, outperforming existing strong
baselines. Further analysis reveals that Caco's code-anchored verification and
instruction diversity contribute to superior generalization across unseen
tasks. Our work establishes a paradigm for building self-sustaining,
trustworthy reasoning systems without human intervention.

</details>


### [31] [SEER: The Span-based Emotion Evidence Retrieval Benchmark](https://arxiv.org/abs/2510.03490)
*Aneesha Sampath,Oya Aran,Emily Mower Provost*

Main category: cs.CL

TL;DR: 论文提出SEER基准用于评测LLM定位情感表达片段的能力，数据集包含句内和跨句任务，并对14个模型进行效果评估。结果显示模型在短句任务接近人类，但五句段落表现明显退步，分析指出模型主要依赖关键词，容易误判。


<details>
  <summary>Details</summary>
Motivation: 目前大多数情感识别任务只对整个句子赋予情感标签，却很少关注文本中具体哪一部分表达了情感。因此，需要推动情感证据检测这一细粒度任务的发展，特别是对于需要理解情感表达方式的实际应用，如共情对话与临床支持。

Method: 提出了SEER基准数据集，专门评测大语言模型（LLM）发掘并定位文本中具体表达情感的片段（span）的能力。SEER基准设立两个任务：句内情感证据识别和跨五句段落的情感证据识别，并为1200条真实语句打上情感及证据标注。

Result: 评测了14个开源LLM，结果显示：在单句情感证据识别任务上部分模型接近人类平均水平，但在较长文本段落上表现显著下降。错误分析显示，模型常依赖情感关键词，且在中性文本中误报情感。

Conclusion: SEER推动了情感证据检测领域发展，揭示了现有LLMs在情感表达定位上的局限，尤其在更复杂文本中易出错，对系统性改进模型提出了需求。

Abstract: We introduce the SEER (Span-based Emotion Evidence Retrieval) Benchmark to
test Large Language Models' (LLMs) ability to identify the specific spans of
text that express emotion. Unlike traditional emotion recognition tasks that
assign a single label to an entire sentence, SEER targets the underexplored
task of emotion evidence detection: pinpointing which exact phrases convey
emotion. This span-level approach is crucial for applications like empathetic
dialogue and clinical support, which need to know how emotion is expressed, not
just what the emotion is. SEER includes two tasks: identifying emotion evidence
within a single sentence, and identifying evidence across a short passage of
five consecutive sentences. It contains new annotations for both emotion and
emotion evidence on 1200 real-world sentences. We evaluate 14 open-source LLMs
and find that, while some models approach average human performance on
single-sentence inputs, their accuracy degrades in longer passages. Our error
analysis reveals key failure modes, including overreliance on emotion keywords
and false positives in neutral text.

</details>


### [32] [ALHD: A Large-Scale and Multigenre Benchmark Dataset for Arabic LLM-Generated Text Detection](https://arxiv.org/abs/2510.03502)
*Ali Khairallah,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: 提出首个大规模阿拉伯语人类与LLM文本区分数据集ALHD，基于多模型基线实验，发现BERT效果较好但跨领域性能仍有限，尤其在新闻领域，未来需提升泛化能力以应对实际应用挑战。


<details>
  <summary>Details</summary>
Motivation: 当前阿拉伯语领域缺乏用于区分人类与大语言模型（LLM）生成文本的高质量大规模数据集，限制了相关检测研究和实际应用的进展。

Method: 构建并发布了ALHD数据集，涵盖新闻、社交媒体、评论三大文本类型，包含标准阿拉伯语与方言版本，总计40万均衡样本（由领先LLM生成和多源真实人类文本），并提供详细预处理、标注与标准分割。使用传统分类器、BERT模型和LLM进行基准测试。

Result: 微调后的BERT模型在检测任务中表现优越，超过了直接用LLM进行零样本和少样本推断的效果；但跨领域（如不同文本类型）泛化能力有限，尤其在新闻文本测试中，LLM生成文风与人类极为相似，模型分辨困难。

Conclusion: ALHD数据集为阿拉伯语LLM文本检测提供了坚实基础，对应的基线实验揭示了目前方法的局限，并为未来提升跨领域泛化能力、打击虚假信息和防范学术不端及网络威胁指明了研究方向。

Abstract: We introduce ALHD, the first large-scale comprehensive Arabic dataset
explicitly designed to distinguish between human- and LLM-generated texts. ALHD
spans three genres (news, social media, reviews), covering both MSA and
dialectal Arabic, and contains over 400K balanced samples generated by three
leading LLMs and originated from multiple human sources, which enables studying
generalizability in Arabic LLM-genearted text detection. We provide rigorous
preprocessing, rich annotations, and standardized balanced splits to support
reproducibility. In addition, we present, analyze and discuss benchmark
experiments using our new dataset, in turn identifying gaps and proposing
future research directions. Benchmarking across traditional classifiers,
BERT-based models, and LLMs (zero-shot and few-shot) demonstrates that
fine-tuned BERT models achieve competitive performance, outperforming LLM-based
models. Results are however not always consistent, as we observe challenges
when generalizing across genres; indeed, models struggle to generalize when
they need to deal with unseen patterns in cross-genre settings, and these
challenges are particularly prominent when dealing with news articles, where
LLM-generated texts resemble human texts in style, which opens up avenues for
future research. ALHD establishes a foundation for research related to Arabic
LLM-detection and mitigating risks of misinformation, academic dishonesty, and
cyber threats.

</details>


### [33] [TS-Reasoner: Aligning Time Series Foundation Models with LLM Reasoning](https://arxiv.org/abs/2510.03519)
*Fangxu Yu,Hongyu Zhao,Tianyi Zhou*

Main category: cs.CL

TL;DR: 本论文提出了TS-Reasoner，一种结合冻结的时间序列基础模型与大语言模型的新架构，通过合成多模态对齐和分阶段训练，在多项时间序列理解与推理任务中取得了优异且高效的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列基础模型（TSFMs）虽然擅长捕捉动态模式，实现高精度预测，但对于更高层次的分析和推理还依赖于丰富背景知识和复杂推理能力——这些是TSFMs缺乏且LLMs擅长的部分。然而，LLMs在没有额外昂贵训练的情况下，对时间序列数据的数值理解较弱。因此，如何有效融合两者能力并训练对齐其多模态特征成为一项挑战。

Method: 提出了TS-Reasoner，通过生成多样化的合成时间序列和文本描述对，进行对齐训练。该方法包括两阶段训练流程——首先进行对齐预训练，然后进行指令微调。不同于以往直接让LLM处理时间序列输入的做法，这里利用预训练好的TSFM并在训练中冻结其参数，只优化生成的对齐映射。

Result: 在多个基准测试上，TS-Reasoner不仅超越了现有的主流LLMs、视觉语言模型（VLMs）以及时间序列LLMs，而且在数据利用率上表现更佳，能用不到一半的训练数据达到更好效果。

Conclusion: TS-Reasoner有效地将TSFM与LLM结合，通过创新的对齐训练和指令微调策略，在时间序列理解与推理任务中取得了领先的效果，并且大幅提升了训练数据利用效率。

Abstract: Time series reasoning is crucial to decision-making in diverse domains,
including finance, energy usage, traffic, weather, and scientific discovery.
While existing time series foundation models (TSFMs) can capture low-level
dynamic patterns and provide accurate forecasting, further analysis usually
requires additional background knowledge and sophisticated reasoning, which are
lacking in most TSFMs but can be achieved through large language models (LLMs).
On the other hand, without expensive post-training, LLMs often struggle with
the numerical understanding of time series data. Although it is intuitive to
integrate the two types of models, developing effective training recipes that
align the two modalities for reasoning tasks is still an open challenge. To
this end, we propose TS-Reasoner that aligns the latent representations of
TSFMs with the textual inputs of LLMs for downstream understanding/reasoning
tasks. Specifically, we propose a simple yet effective method to curate
diverse, synthetic pairs of time series and textual captions for alignment
training. We then develop a two-stage training recipe that applies instruction
finetuning after the alignment pretraining. Unlike existing works that train an
LLM to take time series as inputs, we leverage a pretrained TSFM and freeze it
during training. Extensive experiments on several benchmarks demonstrate that
TS-Reasoner not only outperforms a wide range of prevailing LLMs, Vision
Language Models (VLMs), and Time Series LLMs, but also achieves this with
remarkable data efficiency, e.g., using less than half the training data.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [34] [Space-time reversible graph rewriting](https://arxiv.org/abs/2510.03296)
*Pablo Arrighi,Marin Costes,Luidnel Maignan*

Main category: cs.DM

TL;DR: 该论文提出了适用于图重写系统的新型时空可逆性理论，形式化了相关条件并给出可实现的例子。


<details>
  <summary>Details</summary>
Motivation: 传统数学要求动力系统的可逆性必须是双射，但图重写操作因其非确定性难以满足此要求。作者受物理中时空可逆的灵感，试图构建一种更灵活、更实际的可逆性定义和分析。

Method: 采用了空间-时间确定性图重写的理论框架，形式化定义了时空可逆性条件，并通过具体示例进行了论证。

Result: 证明了一组足够的局部判据可保证图重写满足时空可逆性，并通过考虑类似广义相对论中的时间膨胀情形给出了应用实例。

Conclusion: 研究提出了图重写的时空可逆性新框架，并证明了某些局部规则可以实现这一可逆性。

Abstract: In the mathematical tradition, reversibility requires that the evolution of a
dynamical system be a bijective function. In the context of graph rewriting,
however, the evolution is not even a function, because it is not even
deterministic -- as the rewrite rules get applied at non-deterministically
chosen locations. Physics, by contrast, suggests a more flexible understanding
of reversibility in space-time, whereby any two closeby snapshots (aka
`space-like cuts'), must mutually determine each other. We build upon the
recently developed framework of space-time deterministic graph rewriting, in
order to formalise this notion of space-time reversibility, and henceforth
study reversible graph rewriting. We establish sufficient, local conditions on
the rewrite rules so that they be space-time reversible. We provide an example
featuring time dilation, in the spirit of general relativity.

</details>


### [35] [Vector Trifference](https://arxiv.org/abs/2510.04079)
*Siddharth Bhandari,Abhishek Khetan*

Main category: cs.DM

TL;DR: 本文将trifferent码概念推广到向量场景并提出新上界，通过新方法在离散情形下也取得了对经典上界的改进，并进一步推广至更广泛的组合码理论。


<details>
  <summary>Details</summary>
Motivation: 尝试打破长期未改进的trifferent码最大规模上界（Elias提出的 |C| ≤ 2*(3/2)^n），并希望通过向量化方法获得新的理论突破，同时类比于其他组合问题的向量推广。

Method: 构造向量trifferent码（将码字视为单位球面上的向量），并使用新的技术对其最大码字数做上界分析；该方法还可逆向应用于离散型trifferent码，从而改进Elias的上界。

Result: 证明了向量trifferent码的最大规模上界为 (sqrt(2)+o(1))*(3/2)^n；在离散场景下利用新方法将经典上界改进为 |C| ≲ n^{-1/4}*(3/2)^n。并推广到更丰富字母表以及给出Fredman-Komlos定理的向量化版本。

Conclusion: 本文提出了一种向量型trifferent码，并对其最大码字数给出了新的上界，同时方法也在离散场景下改进了经典上界。

Abstract: We investigate a geometric generalization of trifference, a concept
introduced by Elias in 1988 in the study of zero-error channel capacity. In the
discrete setting, a code C \subseteq {0,1,2}^n is trifferent if for any three
distinct codewords x, y, z in C, there exists a coordinate i in [n] where x_i,
y_i, z_i are all distinct. Determining the maximum size of such codes remains a
central open problem; the classical upper bound |C| \leq 2 * (3/2)^n, proved
via a simple pruning argument, has resisted significant improvement.
  Motivated by the search for new techniques, and in line with vectorial
extensions of other classical combinatorial notions, we introduce the concept
of vector trifferent codes. Consider C \subseteq (S^2)^n, where the alphabet is
the unit sphere S^2 = { v in R^3 : ||v|| = 1 }. We say C is vector trifferent
if for any three distinct x, y, z in C, there is an index i where the vectors
x_i, y_i, z_i are mutually orthogonal. A direct reduction of the vectorial
problem to the discrete setting appears infeasible, making it difficult to
replicate Elias's pruning argument. Nevertheless, we develop a new method to
establish the upper bound |C| \leq (sqrt(2) + o(1)) * (3/2)^n.
  Interestingly, our approach, when adapted back to the discrete setting,
yields a polynomial improvement to Elias's bound: |C| \lesssim n^(-1/4) *
(3/2)^n. This improvement arises from a technique that parallels, but is not
identical to, a recent method of the authors, though it still falls short of
the sharper n^(-2/5) factor obtained there. We also generalize the concept of
vector trifferent codes to richer alphabets and prove a vectorial version of
the Fredman-Komlos theorem (1984) for general k-separating codes.

</details>


### [36] [Maximum Biclique for Star 1,2,3 -free and Bounded Bimodularwidth Twin-free Bipartite Graphs $\star$](https://arxiv.org/abs/2510.04621)
*Fabien de Montgolfier,Renaud Torfs*

Main category: cs.DM

TL;DR: 对于常见的三种最大二分团问题，虽然普遍情况下求解困难，但若限定在某些特殊二分图结构（如Star123-free twin-free和有界bimodularwidth twin-free图），则可以借助图的分解技术实现多项式时间高效求解。


<details>
  <summary>Details</summary>
Motivation: 在二分图中，最大二分团（biclique）的定义通常有三种：最大化顶点数、最大化边数，以及寻找最大平衡二分团。除了最大顶点数的求解有多项式时间算法外，其他两种都是NP完全问题。本文旨在研究特定类型的二分图（如Star123-free twin-free图和有界二模宽的twin-free图）下，这三种最大二分团问题能否被高效求解。

Method: 作者利用二分图的分解方法（如bimodular decomposition），针对Star123-free twin-free图与有界bimodularwidth twin-free图，通过对给定的分解结构进行分析，提出了O(n^2)时间复杂度的高效算法。而所需分解的预处理分别可在O(n+m)和O(mn^3)时间内完成。

Result: 在Star123-free twin-free图和有界bimodularwidth twin-free图两类二分图上，三种最大二分团相关的NP-困难问题都可通过利用图分解技术在多项式时间（O(n^2)）内有效求解。

Conclusion: 通过引入和利用bimodular decomposition等结构特性，部分通常NP-困难的最大二分团问题在特定二分图类别下变得高效可解，显著扩展了相关问题的可处理范围。

Abstract: There are three usual definitions of a maximum bipartite clique (biclique) in
a bipartite graph\,: either maximizing the number of vertices, or of edges, or
finding a maximum balanced biclique. The first problem can be solved in
polynomial time, the last ones are NP-complete. Here we show how these three
problems may be efficiently solved for two classes of bipartite graphs:
Star123-free twin-free graphs, and bounded bimodularwidth twin-free graphs, a
class that may be defined using bimodular decomposition. Our computation
requires O(n^2) time and requires a decomposition is provided, which takes
respectively O(n + m) and O(mn^3) time.

</details>


### [37] [Discrete scalar curvature as a weighted sum of Ollivier-Ricci curvatures](https://arxiv.org/abs/2510.04936)
*Abigail Hickok,Andrew J. Blumberg*

Main category: cs.DM

TL;DR: 本文提出了适用于点云和图的一种新的离散标量曲率定义，并证明其在最近邻图采样情况下能收敛至经典流形的标量曲率；同时改进了Ollivier-Ricci曲率的收敛性理论。


<details>
  <summary>Details</summary>
Motivation: 探索离散曲率（用于点云和图）的定义及其与经典流形曲率的关系，推动流形理论与数据分析领域的结合。

Method: 采用Ollivier-Ricci曲率作为离散Ricci曲率的替代，并提出一种新的Ollivier-Ricci标量曲率定义。通过分析最近邻图（由流形采样获得）验证其收敛性，并理论证明Ollivier-Ricci曲率向Ricci曲率的收敛性。

Result: 提出并证明了一种离散标量曲率定义，该定义在由流形采样得到的最近邻图上收敛到连续情形下的标量曲率。同时，改进和扩展了Ollivier-Ricci曲率收敛到经典Ricci曲率的理论结果。

Conclusion: 离散曲率（Ollivier-Ricci及其标量版本）在合适离散结构中能够很好地逼近经典流形上的曲率，有助于数据驱动下流形性质的分析。

Abstract: We study the relationship between discrete analogues of Ricci and scalar
curvature that are defined for point clouds and graphs. In the discrete
setting, Ricci curvature is replaced by Ollivier-Ricci curvature. Scalar
curvature can be computed as the trace of Ricci curvature for a Riemannian
manifold; this motivates a new definition of a scalar version of Ollivier-Ricci
curvature. We show that our definition converges to scalar curvature for
nearest neighbor graphs obtained by sampling from a manifold. We also prove
some new results about the convergence of Ollivier-Ricci curvature to Ricci
curvature.

</details>
