<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 9]
- [cs.CL](#cs.CL) [Total: 9]
- [cs.DM](#cs.DM) [Total: 1]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [A Novel Compiler Transformation for Fast Sparse Matrix Multiplication in GPUs](https://arxiv.org/abs/2506.15174)
*Hossein Albakri,Kazem Cheshmi*

Main category: cs.PL

TL;DR: 本文提出了一种新编译器变换方法（enumerate-and-sparse-coarsen），显著提升了GPU上稀疏矩阵乘法的效率，在神经网络场景中相较主流工具提升了约2倍性能。


<details>
  <summary>Details</summary>
Motivation: 在神经网络中，为减少内存使用，经常采用稀疏数据结构，但这会导致内存访问不规则，限制了GPU等硬件平台的效率。因此，如何高效利用GPU执行稀疏数据结构操作是一个亟需解决的问题。

Method: 提出了一种新的编译器变换方法——enumerate-and-sparse-coarsen，用于加速GPU上的稀疏矩阵-矩阵乘法（SPMM）。该方法增加数据在寄存器和缓存中的复用，并为GPU计算资源创建更均衡的工作负载。

Result: 在A100 GPU上，对稀疏神经网络中的卷积和Transformer模型测试，矩阵B列数范围32到128时，该方法比cuBLAS和cuSPARSE基线分别取得了1.84倍和2.27倍的几何平均加速比。

Conclusion: 提出的编译器转换方法有效提升了GPU上稀疏矩阵运算的速度，显著超越了主流基线方法，为稀疏神经网络高效执行提供了新的硬件支持思路。

Abstract: Sparse data structures are commonly used in neural networks to reduce the
memory footprint. These data structures are compact but cause irregularities
such as random memory accesses, which prevent efficient use of the memory
hierarchy. GPUs are a common platform for machine learning practitioners, but
running compact data structures on these devices often leads to slow-downs due
to inefficient use of computing and memory resources. This paper proposes a new
compiler transformation, enumerate-and-sparse-coarsen, that accelerates sparse
matrix-matrix multiplication (SPMM) on GPU devices. The transformation
increases data reuse in registers and caches while creating more balanced
workloads for GPU computing resources. The transformation is tested on sparse
neural networks in convolutional and transformer models. On an A100 GPU and
across a columns of matrix B (bCols) in $ A \times B = C$ from range of 32 to
128, the transformation yields a geometric mean speedup of 1.84$\times$ to
2.27$\times$ compared to cuBLAS and cuSPARSE baselines, respectively.

</details>


### [2] [PSM: Policy Synchronised Deterministic Memory](https://arxiv.org/abs/2506.15424)
*Michael Mendler,Marc Pouzet*

Main category: cs.PL

TL;DR: 本文提出了PSM类型上下文，为Haskell带来一种新的并发编程机制，能够同时保证并发性、命令式共享与结果的确定性，解决了以往工具之间难以兼顾的难题。


<details>
  <summary>Details</summary>
Motivation: 在具有共享资源的并发编程中，实现确定性（determinacy）是一大难题。Haskell 现有的并发编程抽象（如IVar、LVar、MVar、TVar）在确定性和可破坏更新之间难以兼顾。现有模式无法同时实现并发性和确定性，且缺乏更高层次的内存抽象来满足需求。

Method: 本文提出了一种新的类型上下文PSM（policy synchronised memory）用于Haskell。PSM结合了STM和IO的持久状态访问，以及Par和IO的并发线程及共享状态，使用政策协调的方式来同步并发访问，保证事务的无竞争（race-free）和确定性。

Result: PSM能让抽象数据结构即具备命令式、并发共享的能力，又能够保证其操作结果的确定性。类型正确的事务能够自动避免竞态条件（race condition），且易于构建同时满足并发性和确定性的程序。

Conclusion: PSM类型上下文为Haskell提供了一种在并发共享内存环境下，实现既确定又命令式抽象数据结构的支撑方法，弥补了现有并发工具无法兼得并发性与确定性的缺陷。

Abstract: Concurrency and determinacy do not go well with each other when resources
must be shared. Haskell provides parallel programming abstractions such as IVar
and LVar in the Par monad and concurrent abstractions such as MVar and TVar in
the in IO and STM monads, respectively. The former are determinate but have no
destructive updates and the latter have destructive updates but do not
guarantee determinacy. Programming patterns that are both concurrent and
determinate, such as those provided by Kahn or Berry require memory
abstractions at a higher level than is currently available. In this paper we
describe a new type context PSM for policy synchronised memory in Haskell. Like
STM and IO, the computations in PSM can access persistent state and, as a
side-effect, update the memory in imperative style. Like the Par and IO monads,
PSM supports concurrent threads and shared state. However, in contrast to IO,
our PSM contexts are race-free since concurrent accesses are policy coordinated
which guarantees determinacy.Well-typed transactions in the PSM context can
accommodate abstract data structures that are imperative, concurrently
shareable and still behave deterministically, by construction.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [Towards Bug-Free Distributed Go Programs](https://arxiv.org/abs/2506.15135)
*Zhengqun Koo*

Main category: cs.SE

TL;DR: 本文提出了一种能够静态检测Go分布式程序通信竞态的新型验证框架，通过扩展happens-before顺序对消息传递路径进行分析，实现了通信竞态的静态证明。


<details>
  <summary>Details</summary>
Motivation: 分布式系统的程序员需要处理并发性以避免竞态条件，但并发推理本身十分困难，竞态引发的错误很常见。虽然在共享内存系统中的数据竞争检测已有成熟研究，但在分布式环境下，消息传递中的通信竞态问题同样严重且难以检测，需要有效的静态验证框架。

Method: 本文提出了一种验证框架，能够证明使用Go语言子集（以消息传递为主同步手段）的分布式程序不存在通信竞态问题。该方法采用静态分析手段，基于happens-before顺序扩展到带缓冲与不带缓冲的通道，推演消息传递过程中的事件顺序。

Result: 用所提出的框架可以对特定类型的Go分布式程序静态证明其不存在通信竞态，从而提升程序正确性，降低因未预料同步行为导致的错误风险。

Conclusion: 本文的静态验证框架能够有效检测Go消息传递程序中的通信竞态，为分布式并发程序的可靠性提供了理论支持和工具基础。

Abstract: Programmers of distributed systems need to reason about concurrency to avoid
races. However, reasoning about concurrency is difficult, and unexpected races
show up as bugs. Data race detection in shared memory systems is well-studied
(dynamic data race detection [13], behavioral types [15], dynamic race
detection [31]). Similar to how a data race consists of reads and writes not
related by happens-before at a shared memory location, a communication race
consists of receives and sends not related by happens-before on a shared
channel. Communication races are problematic: a receiver expects a specific
message from a specific sender, but with a communication race, the receiver can
receive a message meant for another receiver, or not receive anything at all.
In this work, we describe a verification framework that can prove the absence
of communication races for distributed programs that use a subset of the Go
programming language, where synchronization is mainly achieved via message
passing. We statically reason about how a distributed program executes, using a
happens-before order, extended to buffered and unbuffered channels.

</details>


### [4] [OS-Harm: A Benchmark for Measuring Safety of Computer Use Agents](https://arxiv.org/abs/2506.14866)
*Thomas Kuntz,Agatha Duzan,Hao Zhao,Francesco Croce,Zico Kolter,Nicolas Flammarion,Maksym Andriushchenko*

Main category: cs.SE

TL;DR: 该论文提出OS-Harm基准，首次系统测试电脑使用代理的安全性，涵盖用户误用、攻击和模型失误。评测结果警示现有系统安全隐患严重。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM驱动的“computer use agents”在自动与图形界面交互方面越来越流行，但关于其安全性尤其是其潜在危害的评估却被忽视了。为了实现广泛应用，确保这些系统在面对用户误用、攻击等情况下的安全至关重要。

Method: 作者提出新基准OS-Harm，基于OSWorld环境设计，旨在测试电脑使用代理在恶意用户操作、提示注入攻击和模型自身不良行为三个方面的安全性。基准共包含150个涵盖多种安全违规（如骚扰、版权侵犯等）的任务，涉及不同操作系统应用。还设计了自动评判机制，在精度和安全判别上与人工标注高度一致。

Result: 通过OS-Harm基准对多种前沿模型的代理（如o4-mini、Claude 3.7 Sonnet、Gemini 2.5 Pro）进行安全能力评测。实验表明：所有模型在面对用户恶意请求时普遍顺从，容易遭受提示注入攻击，且偶发不安全行为。

Conclusion: OS-Harm为计算机使用代理的安全研究提供了系统化评估平台。实验表明，现有主流代理安全性仍存在较大隐患。

Abstract: Computer use agents are LLM-based agents that can directly interact with a
graphical user interface, by processing screenshots or accessibility trees.
While these systems are gaining popularity, their safety has been largely
overlooked, despite the fact that evaluating and understanding their potential
for harmful behavior is essential for widespread adoption. To address this gap,
we introduce OS-Harm, a new benchmark for measuring safety of computer use
agents. OS-Harm is built on top of the OSWorld environment and aims to test
models across three categories of harm: deliberate user misuse, prompt
injection attacks, and model misbehavior. To cover these cases, we create 150
tasks that span several types of safety violations (harassment, copyright
infringement, disinformation, data exfiltration, etc.) and require the agent to
interact with a variety of OS applications (email client, code editor, browser,
etc.). Moreover, we propose an automated judge to evaluate both accuracy and
safety of agents that achieves high agreement with human annotations (0.76 and
0.79 F1 score). We evaluate computer use agents based on a range of frontier
models - such as o4-mini, Claude 3.7 Sonnet, Gemini 2.5 Pro - and provide
insights into their safety. In particular, all models tend to directly comply
with many deliberate misuse queries, are relatively vulnerable to static prompt
injections, and occasionally perform unsafe actions. The OS-Harm benchmark is
available at https://github.com/tml-epfl/os-harm.

</details>


### [5] [An Empirical Study of Bugs in Data Visualization Libraries](https://arxiv.org/abs/2506.15084)
*Weiqi Lu,Yongqiang Tian,Xiaohan Zhong,Haoyang Ma,Zhenyang Xu,Shing-Chi Cheung,Chengnian Sun*

Main category: cs.SE

TL;DR: 本文系统收集并分析了主流数据可视化库中的564个缺陷，发现不精确绘图广泛存在，主要由图形计算错误引发。提出了完整的缺陷分类、触发流程和检测判据，并初步试验了视觉语言模型在缺陷检测中的应用，发现其效果有待加强。研究为未来自动化测试和缺陷检测技术提供了方向。


<details>
  <summary>Details</summary>
Motivation: 数据可视化库在数据展示与分析中极其重要，不准确的可视化可能会误导用户、带来错误决策，但其可视化缺陷通常隐蔽，不会像程序崩溃等明显暴露。这对相关研究和开发者提出了检测与修复此类缺陷的迫切需求。

Method: 收集并系统分析了五个主流数据可视化库中的564个缺陷，从缺陷症状和根因出发，建立了详尽的缺陷分类体系。同时，探索出触发此类缺陷的关键流程与适用的检验判据，并初步评估了视觉语言模型在相关缺陷检测上的表现。

Result: 研究发现，不正确/不精确的图形在数据可视化库中普遍存在，且图形计算错误是主要根因。文中明确指出需开发更高效的自动化测试方法。研究还总结了触发此类漏洞的八大关键步骤与两个专用的检验判据。另外，视觉语言模型在检测时表现效果差异较大（准确率29%至57%），且仅靠丰富提示词未必能提升效果。

Conclusion: 这是首个系统分析数据可视化库缺陷的研究，揭示了其独特的缺陷特征与根因，并为自动化检测、判据设计和未来研究指明方向。此外，当前视觉语言模型在缺陷检测应用中仍有提升空间。

Abstract: Data visualization (DataViz) libraries play a crucial role in presentation,
data analysis, and application development, underscoring the importance of
their accuracy in transforming data into visual representations. Incorrect
visualizations can adversely impact user experience, distort information
conveyance, and influence user perception and decision-making processes. Visual
bugs in these libraries can be particularly insidious as they may not cause
obvious errors like crashes, but instead mislead users of the underlying data
graphically, resulting in wrong decision making. Consequently, a good
understanding of the unique characteristics of bugs in DataViz libraries is
essential for researchers and developers to detect and fix bugs in DataViz
libraries.
  This study presents the first comprehensive analysis of bugs in DataViz
libraries, examining 564 bugs collected from five widely-used libraries. Our
study systematically analyzes their symptoms and root causes, and provides a
detailed taxonomy. We found that incorrect/inaccurate plots are pervasive in
DataViz libraries and incorrect graphic computation is the major root cause,
which necessitates further automated testing methods for DataViz libraries.
Moreover, we identified eight key steps to trigger such bugs and two test
oracles specific to DataViz libraries, which may inspire future research in
designing effective automated testing techniques. Furthermore, with the recent
advancements in Vision Language Models (VLMs), we explored the feasibility of
applying these models to detect incorrect/inaccurate plots. The results show
that the effectiveness of VLMs in bug detection varies from 29% to 57%,
depending on the prompts, and adding more information in prompts does not
necessarily increase the effectiveness. More findings can be found in our
manuscript.

</details>


### [6] [Program Feature-based Fuzzing Benchmarking](https://arxiv.org/abs/2506.15088)
*Miao Miao*

Main category: cs.SE

TL;DR: 本文提出了具备可配置、细粒度特征的基准程序集，用以评估11个主流模糊器，结果发现程序特性对模糊器表现影响显著，强调在模糊测试评估中纳入程序特征的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的模糊测试评估通常侧重于模糊器在一组目标程序上的整体性能，但很少关注具体的程序细粒度特征如何影响模糊测试效果。缺乏这样的基准阻碍了对模糊器细致比较与提升。

Method: 作者提出了一种新的基准，用于生成具有可配置、细粒度程序特征的程序，帮助更系统、更深入地评估模糊测试器。通过调研25篇与灰盒模糊测试相关的近期研究，提取了7种与控制流、数据流相关、会影响模糊器性能的程序特征。基于这些特征，作者生成了由10个细粒度可配置参数控制的153个程序，并利用这些程序评估了11款流行模糊器。

Result: 实验显示，模糊器的性能会随着程序特征及其强度的变化而显著波动，表明在模糊测试评估中引入程序特性非常重要。

Conclusion: 引入具备可控、细粒度特征的基准程序能够更全面、精确地评估模糊测试工具，有助于发现其性能瓶颈并进行有针对性的优化。

Abstract: Fuzzing is a powerful software testing technique renowned for its
effectiveness in identifying software vulnerabilities. Traditional fuzzing
evaluations typically focus on overall fuzzer performance across a set of
target programs, yet few benchmarks consider how fine-grained program features
influence fuzzing effectiveness. To bridge this gap, we introduce a novel
benchmark designed to generate programs with configurable, fine-grained program
features to enhance fuzzing evaluations. We reviewed 25 recent grey-box fuzzing
studies, extracting 7 program features related to control-flow and data-flow
that can impact fuzzer performance. Using these features, we generated a
benchmark consisting of 153 programs controlled by 10 fine-grained configurable
parameters. We evaluated 11 popular fuzzers using this benchmark. The results
indicate that fuzzer performance varies significantly based on the program
features and their strengths, highlighting the importance of incorporating
program characteristics into fuzzing evaluations.

</details>


### [7] [Enhancement Report Approval Prediction: A Comparative Study of Large Language Models](https://arxiv.org/abs/2506.15098)
*Haosheng Zuo,Feifei Niu,Chuanyi Li*

Main category: cs.SE

TL;DR: 该研究系统评估了多种LLM及其在增强报告审批预测上的表现，结果显示LLM（特别是微调后的模型）显著优于传统方法，有望提升软件开发流程效率，并针对模型不足提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 手工处理软件增强报告（ER）耗费资源且存在延迟和信息损失问题，需要自动化手段提升效率。

Method: 系统性评估了18种大型语言模型（LLM）变体（包括多种编码器和解码器模型），并与传统方法（如CNN/LSTM-BERT/GloVe）进行对比。研究还探索了加入创造者信息和LoRA微调的影响。

Result: （1）引入创造者档案使未微调的纯解码器模型准确率提升10.8%，但可能带来偏见；（2）通过LoRA微调的Llama 3.1 8B Instruct模型取得了79%的准确率，获批报告召回率显著提升（76.1%对比LSTM-GLOVE的64.1%），在严格时序评测下比传统方法高5%，并有效克服类别不平衡问题。

Conclusion: LLM在增强报告审批预测任务上优于传统方法，可提升软件维护和决策流程。研究也分析了LLM表现不佳的案例，为后续研究指明了方向。

Abstract: Enhancement reports (ERs) serve as a critical communication channel between
users and developers, capturing valuable suggestions for software improvement.
However, manually processing these reports is resource-intensive, leading to
delays and potential loss of valuable insights. To address this challenge,
enhancement report approval prediction (ERAP) has emerged as a research focus,
leveraging machine learning techniques to automate decision-making. While
traditional approaches have employed feature-based classifiers and deep
learning models, recent advancements in large language models (LLM) present new
opportunities for enhancing prediction accuracy. This study systematically
evaluates 18 LLM variants (including BERT, RoBERTa, DeBERTa-v3, ELECTRA, and
XLNet for encoder models; GPT-3.5-turbo, GPT-4o-mini, Llama 3.1 8B, Llama 3.1
8B Instruct and DeepSeek-V3 for decoder models) against traditional methods
(CNN/LSTM-BERT/GloVe). Our experiments reveal two key insights: (1)
Incorporating creator profiles increases unfine-tuned decoder-only models'
overall accuracy by 10.8 percent though it may introduce bias; (2) LoRA
fine-tuned Llama 3.1 8B Instruct further improve performance, reaching 79
percent accuracy and significantly enhancing recall for approved reports (76.1
percent vs. LSTM-GLOVE's 64.1 percent), outperforming traditional methods by 5
percent under strict chronological evaluation and effectively addressing class
imbalance issues. These findings establish LLM as a superior solution for ERAP,
demonstrating their potential to streamline software maintenance workflows and
improve decision-making in real-world development environments. We also
investigated and summarized the ER cases where the large models underperformed,
providing valuable directions for future research.

</details>


### [8] [Advanced approach for Agile/Scrum Process: RetroAI++](https://arxiv.org/abs/2506.15172)
*Maria Spichkova,Kevin Iwan,Madeleine Zwart,Hina Lee,Yuwon Yoon,Xiaohan Qin*

Main category: cs.SE

TL;DR: 论文提出并实现了基于AI的原型工具RetroAI++，用于自动化和优化敏捷/Scrum中的冲刺规划与回顾流程，显著提升流程效率与智能化水平。


<details>
  <summary>Details</summary>
Motivation: 敏捷/Scrum软件开发中，冲刺规划和回顾分析是项目管理的关键环节。当前这些环节中，手动操作较多，效率和智能化水平有待提升。论文旨在通过智能技术支持开发者、提升这些活动的效率与效果。

Method: 提出并开发了一个名为RetroAI++的原型工具。该工具基于新兴的智能技术，自动化敏捷/Scrum流程中的冲刺规划与回顾环节，同时在开发阶段提供智能化建议和洞察。

Result: RetroAI++原型能够在冲刺规划、开发和回顾阶段提供智能建议与洞察，帮助团队优化敏捷/Scrum流程，提升组织和回顾的质量与效率。

Conclusion: 通过RetroAI++工具的应用，敏捷/Scrum开发团队能够实现流程的自动化与优化，更高效地进行冲刺规划，以及获得有针对性的回顾洞察，从而改进项目管理和团队协作。

Abstract: In Agile/Scrum software development, sprint planning and retrospective
analysis are the key elements of project management. The aim of our work is to
support software developers in these activities. In this paper, we present our
prototype tool RetroAI++, based on emerging intelligent technologies. In our
RetroAI++ prototype, we aim to automate and refine the practical application of
Agile/Scrum processes within Sprint Planning and Retrospectives. Leveraging AI
insights, our prototype aims to automate and refine the many processes involved
in the Sprint Planning, Development and Retrospective stages of Agile/Scrum
development projects, offering intelligent suggestions for sprint organisation
as well as meaningful insights for retrospective reflection.

</details>


### [9] [Large Language Models for Unit Testing: A Systematic Literature Review](https://arxiv.org/abs/2506.15227)
*Quanjun Zhang,Chunrong Fang,Siqi Gu,Ye Shang,Zhenyu Chen,Liang Xiao*

Main category: cs.SE

TL;DR: 本论文对截至2025年3月LLMs在单元测试领域的应用进行了首次系统性综述，梳理了现有成果、主要挑战与未来机遇，并开源了调研成果。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在自动化单元测试任务中的显著表现，相关研究数量快速增长，但该领域尚缺乏系统性文献综述，导致研究人员难以全面理解现有成果、挑战和未来机遇。

Method: 本论文进行了一项系统性文献综述，旨在梳理截至2025年3月LLMs在单元测试中的应用。作者从单元测试与LLMs两大视角出发，对相关论文进行分类、对现有测试任务（如测试生成、判定生成等）进行归纳，总结LLMs集成到单元测试中的关键方面（模型使用、适配策略、混合方法），并分析未解决的主要挑战及未来发展方向。

Result: 本文系统梳理了LLMs在单元测试领域的应用，分类总结了受益于LLMs的单元测试任务，归纳了模型应用、适配和组合策略，并明确指出当前尚存的一些关键挑战及未来研究方向，为业界和学界提供了全面的现状认知与研究指引。相关整理数据在GitHub公开。

Conclusion: 本论文为LLMs在单元测试领域的研究现状提供了系统化综述，帮助研究者全面把握相关进展、挑战和方向，并以开源的方式贡献了整理成果，推动该领域进一步发展。

Abstract: Unit testing is a fundamental practice in modern software engineering, with
the aim of ensuring the correctness, maintainability, and reliability of
individual software components. Very recently, with the advances in Large
Language Models (LLMs), a rapidly growing body of research has leveraged LLMs
to automate various unit testing tasks, demonstrating remarkable performance
and significantly reducing manual effort. However, due to ongoing explorations
in the LLM-based unit testing field, it is challenging for researchers to
understand existing achievements, open challenges, and future opportunities.
This paper presents the first systematic literature review on the application
of LLMs in unit testing until March 2025. We analyze \numpaper{} relevant
papers from the perspectives of both unit testing and LLMs. We first categorize
existing unit testing tasks that benefit from LLMs, e.g., test generation and
oracle generation. We then discuss several critical aspects of integrating LLMs
into unit testing research, including model usage, adaptation strategies, and
hybrid approaches. We further summarize key challenges that remain unresolved
and outline promising directions to guide future research in this area.
Overall, our paper provides a systematic overview of the research landscape to
the unit testing community, helping researchers gain a comprehensive
understanding of achievements and promote future research. Our artifacts are
publicly available at the GitHub repository:
https://github.com/iSEngLab/AwesomeLLM4UT.

</details>


### [10] [Uncovering Intention through LLM-Driven Code Snippet Description Generation](https://arxiv.org/abs/2506.15453)
*Yusuf Sulistyo Nugroho,Farah Danisha Salam,Brittany Reid,Raula Gaikovina Kula,Kazumasa Shimari,Kenichi Matsumoto*

Main category: cs.SE

TL;DR: 代码片段文档多以用法示例为主，LLM（如Llama）在归类上表现优异，但自动生成的代码描述与原始描述相关度尚有提升空间，文档意图需结合具体任务。


<details>
  <summary>Details</summary>
Motivation: 代码片段文档化有助于开发者和用户快速了解关注重点，尤其是第三方库示例和API说明。当前大模型（LLM）崛起，亟需了解开发者常用描述方式，以及LLM在生成代码描述方面的能力。

Method: 作者从NPM收集了大规模代码片段数据集，随机抽取400条作为样本，通过手动分类分析原始描述内容，并评估Llama模型对这些代码片段生成描述的表现，包括分类准确性和文本相似度。

Result: 手动标注发现，原始描述有55.5%强调用法示例，强调文档需要清晰。Llama模型自动分类结果与人工一致度高（79.75%为“示例”），但生成文档的平均相似度为0.7173，说明相关但还有改进空间。得分低于0.9的情形显示在部分内容上的不相关性。

Conclusion: LLM（如Llama）在将代码片段描述归类为“示例”方面表现良好，但自动生成描述还存在与原始描述部分不一致的问题，尤其在表意清晰和细节描述上尚有提升空间。不同任务对文档意图需求也不尽相同，如用法指引、安装教程或学习示例等。

Abstract: Documenting code snippets is essential to pinpoint key areas where both
developers and users should pay attention. Examples include usage examples and
other Application Programming Interfaces (APIs), which are especially important
for third-party libraries. With the rise of Large Language Models (LLMs), the
key goal is to investigate the kinds of description developers commonly use and
evaluate how well an LLM, in this case Llama, can support description
generation. We use NPM Code Snippets, consisting of 185,412 packages with
1,024,579 code snippets. From there, we use 400 code snippets (and their
descriptions) as samples. First, our manual classification found that the
majority of original descriptions (55.5%) highlight example-based usage. This
finding emphasizes the importance of clear documentation, as some descriptions
lacked sufficient detail to convey intent. Second, the LLM correctly identified
the majority of original descriptions as "Example" (79.75%), which is identical
to our manual finding, showing a propensity for generalization. Third, compared
to the originals, the produced description had an average similarity score of
0.7173, suggesting relevance but room for improvement. Scores below 0.9
indicate some irrelevance. Our results show that depending on the task of the
code snippet, the intention of the document may differ from being instructions
for usage, installations, or descriptive learning examples for any user of a
library.

</details>


### [11] [cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree](https://arxiv.org/abs/2506.15655)
*Yilin Zhang,Xinran Zhao,Zora Zhiruo Wang,Chenyang Yang,Jiayi Wei,Tongshuang Wu*

Main category: cs.SE

TL;DR: 本文提出结构感知的AST分块方法，显著提升了代码检索和生成任务中的性能，强调了结构化分块在RAG代码智能中的重要性。


<details>
  <summary>Details</summary>
Motivation: 传统基于行的代码分块方式往往破坏语义结构，导致函数被拆分或无关代码合并，影响生成质量。因此需要更精细且结构化的分块策略，提升RAG效果。

Method: 提出了基于抽象语法树（AST）的分块方法，通过递归地将大的AST节点拆分为更小块，并在限定大小的前提下合并兄弟节点，生成自包含、语义一致的检索单元。

Result: 提出的方法在不同代码生成任务上提升明显：在RepoEval检索任务Recall@5提升4.3%，在SWE-bench生成任务Pass@1提升2.67%。

Conclusion: 结构感知的分块（chunking）在检索增强代码生成（RAG）中显著提升了检索和生成表现，有效提升了代码智能系统的性能。

Abstract: Retrieval-Augmented Generation (RAG) has become essential for large-scale
code generation, grounding predictions in external code corpora to improve
actuality. However, a critical yet underexplored aspect of RAG pipelines is
chunking -- the process of dividing documents into retrievable units. Existing
line-based chunking heuristics often break semantic structures, splitting
functions or merging unrelated code, which can degrade generation quality. We
propose chunking via Abstract Syntax Trees (\ourwork), a structure-aware method
that recursively breaks large AST nodes into smaller chunks and merges sibling
nodes while respecting size limits. This approach generates self-contained,
semantically coherent units across programming languages and tasks, improving
performance on diverse code generation tasks, e.g., boosting Recall@5 by 4.3
points on RepoEval retrieval and Pass@1 by 2.67 points on SWE-bench generation.
Our work highlights the importance of structure-aware chunking for scaling
retrieval-enhanced code intelligence.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [12] [Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings](https://arxiv.org/abs/2506.14900)
*Imane Guellil,Salomé Andres,Atul Anand,Bruce Guthrie,Huayu Zhang,Abul Hasan,Honghan Wu,Beatrice Alex*

Main category: cs.CL

TL;DR: 该文构建了一个关注老年患者不良事件抽取的高质量注释数据集，表明当前NLP模型在处理细粒度和罕见事件时仍有明显不足，为相关研究提供了新基准。


<details>
  <summary>Details</summary>
Motivation: 老年患者在临床NLP资源中常常被低估，且对于不良事件（AE）的抽取存在挑战，尤其是涉及罕见事件和复杂属性。

Method: 构建了一个手工注释的数据集，专注于从老年患者的出院小结中提取14种临床显著的AE，并包括否定、诊断类型、住院时发生等上下文属性。采用可处理不连续和重叠实体的注释体系。用FlairNLP测试了多种模型，在三种不同粒度（细粒度、粗粒度、带否定的粗粒度）上评估模型表现。

Result: BERT等transformer模型在文档级粗粒度AE抽取上表现强劲（F1=0.943），但在细粒度实体级任务上表现显著下降（如F1=0.675），特别是罕见事件和复杂属性上效果不佳。

Conclusion: 尽管在高层次抽取上模型表现良好，但在处理低频AE和复杂临床语言方面仍面临挑战。数据集可作为标准测试集用于方法评估和跨数据集泛化研究。

Abstract: In this work, we present a manually annotated corpus for Adverse Event (AE)
extraction from discharge summaries of elderly patients, a population often
underrepresented in clinical NLP resources. The dataset includes 14 clinically
significant AEs-such as falls, delirium, and intracranial haemorrhage, along
with contextual attributes like negation, diagnosis type, and in-hospital
occurrence. Uniquely, the annotation schema supports both discontinuous and
overlapping entities, addressing challenges rarely tackled in prior work. We
evaluate multiple models using FlairNLP across three annotation granularities:
fine-grained, coarse-grained, and coarse-grained with negation. While
transformer-based models (e.g., BERT-cased) achieve strong performance on
document-level coarse-grained extraction (F1 = 0.943), performance drops
notably for fine-grained entity-level tasks (e.g., F1 = 0.675), particularly
for rare events and complex attributes. These results demonstrate that despite
high-level scores, significant challenges remain in detecting underrepresented
AEs and capturing nuanced clinical language. Developed within a Trusted
Research Environment (TRE), the dataset is available upon request via DataLoch
and serves as a robust benchmark for evaluating AE extraction methods and
supporting future cross-dataset generalisation.

</details>


### [13] [Combining Constrained and Unconstrained Decoding via Boosting: BoostCD and Its Application to Information Extraction](https://arxiv.org/abs/2506.14901)
*Marija Šakota,Robert West*

Main category: cs.CL

TL;DR: 该论文提出通过先后用基模型做约束与非约束预测，再训练一个提升模型结合两者结果，有效提升结构化NLP任务的表现，尤其在信息抽取方面优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 许多结构化NLP任务采用自回归语言模型，从非结构化输入生成结构化输出。虽然在训练时不强制模型遵守结构约束使得系统灵活，但在测试时基于约束的解码往往产生低质量输出。作者动机是解决约束解码时输出质量不高的问题。

Method: 提出Boosted Constrained Decoding（BoostCD）方法：第一阶段分别用约束和非约束模式从基模型进行两次解码；第二阶段，训练一个自回归提升模型，结合这两种预测，利用它们在错误上的互补性生成更好最终输出。

Result: 应用BoostCD于闭合式信息抽取任务，并提出BoostIE模型，结果显示在分布内外均优于现有方法，有效解决了以往系统中的常见错误。

Conclusion: BoostCD方法能有效提升结构化任务中的解码输出质量，在信息抽取任务中取得了领先表现，显示了这一范式的优越性。

Abstract: Many recent approaches to structured NLP tasks use an autoregressive language
model $M$ to map unstructured input text $x$ to output text $y$ representing
structured objects (such as tuples, lists, trees, code, etc.), where the
desired output structure is enforced via constrained decoding. During training,
these approaches do not require the model to be aware of the constraints, which
are merely implicit in the training outputs $y$. This is advantageous as it
allows for dynamic constraints without requiring retraining, but can lead to
low-quality output during constrained decoding at test time. We overcome this
problem with Boosted Constrained Decoding (BoostCD), which combines constrained
and unconstrained decoding in two phases: Phase 1 decodes from the base model
$M$ twice, in constrained and unconstrained mode, obtaining two weak
predictions. In phase 2, a learned autoregressive boosted model combines the
two weak predictions into one final prediction. The mistakes made by the base
model with vs. without constraints tend to be complementary, which the boosted
model learns to exploit for improved performance. We demonstrate the power of
BoostCD by applying it to closed information extraction. Our model, BoostIE,
outperforms prior approaches both in and out of distribution, addressing
several common errors identified in those approaches.

</details>


### [14] [CrEst: Credibility Estimation for Contexts in LLMs via Weak Supervision](https://arxiv.org/abs/2506.14912)
*Dyah Adila,Shuai Zhang,Boran Han,Bonan Min,Yuyang Wang*

Main category: cs.CL

TL;DR: 本文提出CrEst，无需人工标注即可自动评估上下文文档可信度，并通过白盒和黑盒两种方式提升LLM表现，实验结果显著优于现有方法，在高噪声下依然稳定。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型（LLM）中集成上下文信息已显著提升知识密集型任务的表现。然而，现有方法忽视了上下文文档可信度参差不齐的问题，导致可能传播不可靠信息。因此，需要有方法有效评估上下文文档的可信度。

Method: 提出了一种名为CrEst的弱监督框架，在不依赖人工标注的情况下，评估LLM推理过程中的上下文文档可信度。CrEst基于一个理论洞见：可信文档之间在语义上通常更为一致，因此可以通过文档间的一致性自动评估可信度。同时，分别提出黑盒和白盒两种模型集成策略，前者适用于不可访问模型权重的情况下，后者则直接修改注意力机制。

Result: 在三种模型架构和五个数据集上的大量实验表明，CrEst在各项指标上均优于现有强基线方法，准确率最高提升26.86%，F1分数提升3.49%。此外，即使在高噪声条件下，CrEst依然表现稳健。

Conclusion: CrEst能有效评估并整合上下文文档可信度，显著提升LLM在知识密集型任务中的准确性和鲁棒性。

Abstract: The integration of contextual information has significantly enhanced the
performance of large language models (LLMs) on knowledge-intensive tasks.
However, existing methods often overlook a critical challenge: the credibility
of context documents can vary widely, potentially leading to the propagation of
unreliable information. In this paper, we introduce CrEst, a novel weakly
supervised framework for assessing the credibility of context documents during
LLM inference--without requiring manual annotations. Our approach is grounded
in the insight that credible documents tend to exhibit higher semantic
coherence with other credible documents, enabling automated credibility
estimation through inter-document agreement. To incorporate credibility into
LLM inference, we propose two integration strategies: a black-box approach for
models without access to internal weights or activations, and a white-box
method that directly modifies attention mechanisms. Extensive experiments
across three model architectures and five datasets demonstrate that CrEst
consistently outperforms strong baselines, achieving up to a 26.86% improvement
in accuracy and a 3.49% increase in F1 score. Further analysis shows that CrEst
maintains robust performance even under high-noise conditions.

</details>


### [15] [MDBench: A Synthetic Multi-Document Reasoning Benchmark Generated with Knowledge Guidance](https://arxiv.org/abs/2506.14927)
*Joseph J. Peper,Wenzhao Qiu,Ali Payani,Lu Wang*

Main category: cs.CL

TL;DR: 本文提出了用于大语言模型多文档推理评测的新数据集MDBench，通过合成的方法高效生成具有针对性的难题，发现主流模型在该数据集上仍有诸多挑战，并展示了方法的灵活性与适应性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）推理能力的飞速提升，对于多文档（MD）推理的评测需求逐渐增加。然而，目前缺乏针对多文档推理的系统性评价基准，并且因人工标注长文本的高昂成本，MD评测集的构建尤为困难。

Method: 作者提出MDBench，这是一个通过合成生成流程创建的新型数据集。具体做法是：先用结构化知识作为种子，通过LLM辅助的编辑操作，引入多文档推理挑战，再将结构化知识转换为自然文本，实现多文档集和相应问答对的高效生成。

Result: MDBench能够有效产生具有挑战性的多文档及对应的问答样本。实验分析表明，无论是主流模型还是各种提示工程方法，对MDBench的应对都极具挑战，即使文档数目不多。此外，该生成技术可以灵活地针对特定推理能力进行分析，也有良好适应性，可应对未来新挑战。

Conclusion: MDBench为LLM的多文档推理评估提供了高效且可控的数据集构建方法，有望推动更多相关研究与模型改进。

Abstract: Natural language processing evaluation has made significant progress, largely
driven by the proliferation of powerful large language mod-els (LLMs). New
evaluation benchmarks are of increasing priority as the reasoning capabilities
of LLMs are expanding at a rapid pace. In particular, while multi-document (MD)
reasoning is an area of extreme relevance given LLM capabilities in handling
longer-context inputs, few benchmarks exist to rigorously examine model
behavior in this setting. Moreover, the multi-document setting is historically
challenging for benchmark creation due to the expensive cost of annotating long
inputs. In this work, we introduce MDBench, a new dataset for evaluating LLMs
on the task of multi-document reasoning. Notably, MDBench is created through a
novel synthetic generation process, allowing us to controllably and efficiently
generate challenging document sets and the corresponding question-answer (QA)
examples. Our novel technique operates on condensed structured seed knowledge,
modifying it through LLM-assisted edits to induce MD-specific reasoning
challenges. We then convert this structured knowledge into a natural text
surface form, generating a document set and corresponding QA example. We
analyze the behavior of popular LLMs and prompting techniques, finding that
MDBENCH poses significant challenges for all methods, even with relatively
short document sets. We also see our knowledge-guided generation technique (1)
allows us to readily perform targeted analysis of MD-specific reasoning
capabilities and (2) can be adapted quickly to account for new challenges and
future modeling improvements.

</details>


### [16] [From Chat to Checkup: Can Large Language Models Assist in Diabetes Prediction?](https://arxiv.org/abs/2506.14949)
*Shadman Sakib,Oishy Fatema Akhand,Ajwad Abrar*

Main category: cs.CL

TL;DR: 本文系统评估了六种大型语言模型在糖尿病预测上的表现，发现专有LLM优于开源LLM，部分模型可超越传统机器学习方法，提示工程和领域微调仍是今后提升性能的重点。


<details>
  <summary>Details</summary>
Motivation: 大模型（LLM）在处理结构化数值医疗数据（如糖尿病预测）上的研究还较少，而现有工作主要集中于传统机器学习和深度学习方法。本文旨在探索和对比LLM在此类任务中的能力，以填补相关研究空白。

Method: 本文采用零样本、单样本和三样本提示法，基于Pima Indian Diabetes Database，对六个大语言模型（包括四个开源模型和两个专有模型）在糖尿病预测任务上的表现进行对比，并以传统机器学习模型（随机森林、逻辑回归、支持向量机）作参照，评价指标包括准确率、精确率、召回率和F1分数。

Result: 实验结果显示，专有LLM（如GPT-4o）整体优于开源LLM，且在少样本提示下，GPT-4o和Gemma-2-27B取得了最高准确率。Gemma-2-27B的F1分数甚至超过了传统机器学习模型。不同提示策略下LLM表现波动明显，且仍存在领域微调需求。

Conclusion: LLM在医学预测任务上具有可行性和潜力，尤其在某些指标上可超越传统模型。未来工作应关注提示工程和混合方法，以进一步提升医疗预测能力。

Abstract: While Machine Learning (ML) and Deep Learning (DL) models have been widely
used for diabetes prediction, the use of Large Language Models (LLMs) for
structured numerical data is still not well explored. In this study, we test
the effectiveness of LLMs in predicting diabetes using zero-shot, one-shot, and
three-shot prompting methods. We conduct an empirical analysis using the Pima
Indian Diabetes Database (PIDD). We evaluate six LLMs, including four
open-source models: Gemma-2-27B, Mistral-7B, Llama-3.1-8B, and Llama-3.2-2B. We
also test two proprietary models: GPT-4o and Gemini Flash 2.0. In addition, we
compare their performance with three traditional machine learning models:
Random Forest, Logistic Regression, and Support Vector Machine (SVM). We use
accuracy, precision, recall, and F1-score as evaluation metrics. Our results
show that proprietary LLMs perform better than open-source ones, with GPT-4o
and Gemma-2-27B achieving the highest accuracy in few-shot settings. Notably,
Gemma-2-27B also outperforms the traditional ML models in terms of F1-score.
However, there are still issues such as performance variation across prompting
strategies and the need for domain-specific fine-tuning. This study shows that
LLMs can be useful for medical prediction tasks and encourages future work on
prompt engineering and hybrid approaches to improve healthcare predictions.

</details>


### [17] [Memory Tokens: Large Language Models Can Generate Reversible Sentence Embeddings](https://arxiv.org/abs/2506.15001)
*Ignacio Sastre,Aiala Rosá*

Main category: cs.CL

TL;DR: 通过优化特殊token的嵌入，大模型可精确“记忆”并重建原始文本，无需调整模型参数。这一能力有望拓展高效信息检索、压缩、可控生成等应用场景。


<details>
  <summary>Details</summary>
Motivation: 探索LLM（大语言模型）是否能够生成可逆的句子向量，并实现原文的精确重构，即一种“记忆”能力，而无需修改模型参数。

Method: 引入一个特殊的memory token（记忆令牌），并通过在固定文本序列上优化其向量表示。随后将优化后的嵌入输入到LLM，测试模型是否能精确还原原始文本。

Result: 在英语和西班牙语数据集、最长约240 token的文本序列、模型参数100M至8B的不同规模下测试，Llama 3.1 8B模型可成功重建所有测试文本。

Conclusion: LLM具备通过特殊嵌入实现文本记忆与精确重建的新能力，或将促进基于记忆的检索、压缩及可控文本生成等应用。

Abstract: In this work, we observe an interesting phenomenon: it is possible to
generate reversible sentence embeddings that allow an LLM to reconstruct the
original text exactly, without modifying the model's weights. This is achieved
by introducing a special memory token, whose embedding is optimized through
training on a fixed sequence. When prompted with this embedding, the model
reconstructs the fixed sequence exactly. We evaluate this phenomenon across
English and Spanish datasets, sequences of up to approximately 240 tokens, and
model scales ranging from 100M to 8B parameters. Notably, Llama 3.1 8B
successfully reconstructs all tested sequences. Our findings highlight an
interesting capability of LLMs and suggest potential applications in
memory-based retrieval, compression, and controlled text generation.

</details>


### [18] [Identifying social isolation themes in NVDRS text narratives using topic modeling and text-classification methods](https://arxiv.org/abs/2506.15030)
*Drew Walker,Swati Rajwal,Sudeshna Das,Snigdha Peddireddy,Abeed Sarker*

Main category: cs.CL

TL;DR: 本文通过NLP与机器学习，自动识别30万余自杀案例中的社会孤立与孤独情形，揭示了关键风险因素；方法有效提升了相关群体的监测与预防能力。


<details>
  <summary>Details</summary>
Motivation: 社会孤立和孤独感近年来日益加剧，强烈影响自杀率，但现有的美国国家暴力死亡报告系统（NVDRS）中并未正式记录相关变量，因此急需开发方法识别这些风险因素。

Method: 研究采用自然语言处理（NLP）技术，对执法和验尸官报告中的叙述内容进行主题建模和词汇本体构建，并用监督学习方法训练分类器，筛选出涉及社会孤立与孤独的自杀案例。

Result: 开发的分类器表现出较高的准确性（F1值为0.86，准确率0.82）。在分析超过30万例自杀案例后，识别出1198例明确提及慢性社会孤立，男性、同性恋者及离婚者罹患慢性社会孤立的风险显著更高。同时也发现近期或即将离婚、子女抚养权丧失、被驱逐或近期搬家、情感分手等事件是新发社会孤立的重要预测因素。

Conclusion: 利用自然语言处理与机器学习方法，可高效识别出自杀相关的社会孤立与孤独现象。这为美国社会孤立和孤独的监测及预防工作提供了有效工具。

Abstract: Social isolation and loneliness, which have been increasing in recent years
strongly contribute toward suicide rates. Although social isolation and
loneliness are not currently recorded within the US National Violent Death
Reporting System's (NVDRS) structured variables, natural language processing
(NLP) techniques can be used to identify these constructs in law enforcement
and coroner medical examiner narratives. Using topic modeling to generate
lexicon development and supervised learning classifiers, we developed
high-quality classifiers (average F1: .86, accuracy: .82). Evaluating over
300,000 suicides from 2002 to 2020, we identified 1,198 mentioning chronic
social isolation. Decedents had higher odds of chronic social isolation
classification if they were men (OR = 1.44; CI: 1.24, 1.69, p<.0001), gay (OR =
3.68; 1.97, 6.33, p<.0001), or were divorced (OR = 3.34; 2.68, 4.19, p<.0001).
We found significant predictors for other social isolation topics of recent or
impending divorce, child custody loss, eviction or recent move, and break-up.
Our methods can improve surveillance and prevention of social isolation and
loneliness in the United States.

</details>


### [19] [Semantically-Aware Rewards for Open-Ended R1 Training in Free-Form Generation](https://arxiv.org/abs/2506.15068)
*Zongxia Li,Yapei Chang,Yuhang Zhou,Xiyang Wu,Zichao Liang,Yoo Yeon Sung,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: 本文提出了PrefBERT模型用于长文本生成评价，相较传统指标更能反映丰富语义信息，用作奖励信号能提升模型输出与人类偏好的对齐度。


<details>
  <summary>Details</summary>
Motivation: 长文本生成的自动评价非常困难，现有方法容易忽略连贯性、风格和相关性等重要方面，并且容易受到预训练数据偏差的影响，因此长文本开放式生成的评价方法依然不足。

Method: 作者提出了PrefBERT评分模型，用于评价长文本生成，并在GRPO中引导训练。PrefBERT在两个带有不同风格和Likert量表质量评分的对话回复数据集上训练，通过为优劣输出分别设计奖励信号，从而提升奖励的语义反馈质量。模型效果通过大语言模型判官、人类评分和定性分析等多种方法综合评估。

Result: PrefBERT相比ROUGE-L和BERTScore等传统指标，在长文本的评分上具有更好的语义反馈能力。人类评测结果显示，以PrefBERT作为训练奖励信号的策略模型，其输出与人类偏好对齐度高于以传统指标为奖励的模型。

Conclusion: PrefBERT在长文本生成奖励和评价方面有效可用，用其做奖励信号能提升长文本生成对人类偏好的契合度，为开放式长文本生成评价提供了新工具和思路。

Abstract: Evaluating open-ended long-form generation is challenging because it is hard
to define what clearly separates good from bad outputs. Existing methods often
miss key aspects like coherence, style, or relevance, or are biased by
pretraining data, making open-ended long-form evaluation an underexplored
problem. To address this gap, we propose PrefBERT, a scoring model for
evaluating open-ended long-form generation in GRPO and guiding its training
with distinct rewards for good and bad outputs. Trained on two response
evaluation datasets with diverse long-form styles and Likert-rated quality,
PrefBERT effectively supports GRPO by offering better semantic reward feedback
than traditional metrics ROUGE-L and BERTScore do. Through comprehensive
evaluations, including LLM-as-a-judge, human ratings, and qualitative analysis,
we show that PrefBERT, trained on multi-sentence and paragraph-length
responses, remains reliable across varied long passages and aligns well with
the verifiable rewards GRPO needs. Human evaluations confirm that using
PrefBERT as the reward signal to train policy models yields responses better
aligned with human preferences than those trained with traditional metrics. Our
code is available at https://github.com/zli12321/long_form_rl.

</details>


### [20] [Learning-Time Encoding Shapes Unlearning in LLMs](https://arxiv.org/abs/2506.15076)
*Ruihan Wu,Konstantin Garov,Kamalika Chaudhuri*

Main category: cs.CL

TL;DR: 训练时采用不同的知识编码策略，比如用多样化的释义，有助于提升大语言模型后续“遗忘”某些知识时的有效性，但要从文本块中删除单独知识点仍然很难。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在现实中的广泛应用，“遗忘”特定知识的能力变得非常重要，例如满足隐私法规或修正过时/有害内容。此前的工作大多假设训练过程和目标模型是固定的，未深入探讨训练阶段的选择对后续遗忘效果的影响。

Method: 通过实证实验，分析在知识编码阶段的不同训练方式（如使用释义描述）对事实知识遗忘效果的影响，并测试针对文本块中单独知识点的遗忘难度。

Result: （1）采用释义描述进行学习，可以提升遗忘特定知识的有效性；（2）从一段文本中单独遗忘某一知识点仍具有挑战性。

Conclusion: 知识编码的方式会显著影响模型后续“遗忘”能力，优化学习阶段的编码对实现可靠的后验遗忘非常关键。

Abstract: As large language models (LLMs) are increasingly deployed in the real world,
the ability to ``unlearn'', or remove specific pieces of knowledge post hoc,
has become essential for a variety of reasons ranging from privacy regulations
to correcting outdated or harmful content. Prior work has proposed unlearning
benchmarks and algorithms, and has typically assumed that the training process
and the target model are fixed. In this work, we empirically investigate how
learning-time choices in knowledge encoding impact the effectiveness of
unlearning factual knowledge. Our experiments reveal two key findings: (1)
learning with paraphrased descriptions improves unlearning performance and (2)
unlearning individual piece of knowledge from a chunk of text is challenging.
Our results suggest that learning-time knowledge encoding may play a central
role in enabling reliable post-hoc unlearning.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [21] [A survey of Chernoff and Hoeffding bounds](https://arxiv.org/abs/2506.15612)
*Alexandros V. Gerbessiotis*

Main category: cs.DM

TL;DR: 本文综述了Chernoff和Hoeffding界限及变形，并汇集了完整证明，成为研究者的重要参考资料库。


<details>
  <summary>Details</summary>
Motivation: 为研究者提供Chernoff和Hoeffding重要定理原始界限及其各种衍生界限的全面参考，以便查阅和应用。

Method: 整理并综述Chernoff和Hoeffding定理的原始界限，同时收集和汇总各种不同形式的衍生界限，并在需要时提供完整的证明。

Result: 论文收集并整理了Chernoff和Hoeffding等定理的原始界限及其衍生变体，形成了一个全面的参考资料库，并为部分结果提供了完整证明。

Conclusion: 本文作为综述性文献，系统性地为研究者提供了Chernoff及Hoeffding界限及各种衍变形态的详细汇编和证明，是相关领域参考和研究的有用资源。

Abstract: This is a survey paper that discusses the original bounds of the seminal
papers by Chernoff and Hoeffding. Moreover, it includes a variety of derivative
bounds in a variety of forms. Complete proofs are provided as needed. The
intent is to provide a repository of reference bounds for the interested
researcher.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [22] [Controller Synthesis for Parametric Timed Games](https://arxiv.org/abs/2506.15532)
*Mikael Bisgaard Dahlsen-Jensen,Baptiste Fievet,Laure Petrucci,Jaco van de Pol*

Main category: cs.FL

TL;DR: 本文提出一种可自动合成参数时序博弈获胜策略的算法，并能转化为实际控制器，弥补了以往只能合成获胜参数的不足。通过实验证明该方法可行。


<details>
  <summary>Details</summary>
Motivation: 以往的时序博弈参数合成算法只能求出对于获胜的参数，但不能直接合成策略。本文出于自动化控制系统需要，不仅要知道什么参数可以获胜，还要可实现获胜的控制策略。

Method: 提出一种（半）算法，能够计算参数时序博弈的获胜策略。引入新的获胜策略定义，并提出求解方法。同时，策略可转换为参数时序自动机，从而能用于实际控制器设计。通过实际实例（Production Cell案例）进行实验验证。

Result: 基于本文方法，能够自动化合成参数博弈的具体获胜策略，并且可以转化为控制器实施。实验展示了该方法的可行性。

Conclusion: 本文解决了参数时序博弈中仅能合成参数不能合成策略的难题，实现了自动化获胜策略的合成和控制器设计，并通过实验验证了其实用性。

Abstract: We present a (semi)-algorithm to compute winning strategies for parametric
timed games. Previous algorithms only synthesized constraints on the clock
parameters for which the game is winning. A new definition of (winning)
strategies is proposed, and ways to compute them. A transformation of these
strategies to (parametric) timed automata allows for building a controller
enforcing them. The feasibility of the method is demonstrated by an
implementation and experiments for the Production Cell case study.

</details>
