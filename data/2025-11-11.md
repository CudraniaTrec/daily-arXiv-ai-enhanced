<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 30]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.CL](#cs.CL) [Total: 31]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [A Data-driven Analysis of Code Optimizations](https://arxiv.org/abs/2511.06117)
*Yacine Hakimi,Riyadh Baghdadi*

Main category: cs.PL

TL;DR: 本文通过大规模数据实验，分析了自动代码优化中优化顺序的影响，提出固定顺序可兼顾效率和性能，为编译器优化策略提供新思路。


<details>
  <summary>Details</summary>
Motivation: 随着计算需求的增长，自动化编译器优化变得愈发重要。如何自动选择和应用优化变换以提升性能，且无需人工干预，是当前面临的核心挑战。理解不同变换之间的作用和相互影响，有助于设计更有效的优化策略。同时，如何权衡搜索空间与优化潜力，是编译器开发中难以回避的问题。

Method: 采用数据驱动方法：生成大量随机程序，随机进行优化变换顺序，并记录每个程序的执行时间。之后进行统计分析，探讨不同优化顺序对搜索空间和优化效果的影响。

Result: 通过数据分析，揭示了优化变换顺序的设计对自动化编译优化算法效率和潜力的影响，为更高效自动优化算法的设计提供数据支持。

Conclusion: 预定义、固定的优化顺序在提升搜索速度方面具有实际价值，且不会严重损害优化潜力。相关发现为自动代码优化算法设计提出了可行性建议。

Abstract: As the demand for computational power grows, optimizing code through compilers becomes increasingly crucial. In this context, we focus on fully automatic code optimization techniques that automate the process of selecting and applying code transformations for better performance without manual intervention. Understanding how these transformations behave and interact is key to designing more effective optimization strategies. Compiler developers must make numerous design choices when constructing these heuristics. For instance, they may decide whether to allow transformations to be explored in any arbitrary order or to enforce a fixed sequence. While the former may theoretically offer the best performance gains, it significantly increases the search space. This raises an important question: Can a predefined, fixed order of applying transformations speed up the search without severely compromising optimization potential? In this paper, we address this and other related questions that arise in the design of automatic code optimization algorithms. Using a data-driven approach, we generate a large dataset of random programs, apply random optimization sequences, and record their execution times. Through statistical analysis, we provide insights that guide the development of more efficient automatic code optimization algorithms.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [LLMs as Packagers of HPC Software](https://arxiv.org/abs/2511.05626)
*Caetano Melone,Daniel Nichols,Konstantinos Parasyris,Todd Gamblin,Harshitha Menon*

Main category: cs.SE

TL;DR: 本文提出了SpackIt框架，通过分析、检索和反馈机制，显著提高了LLM自动生成Spack包配方的可靠性和成功率，为HPC生态系统的依赖管理自动化提供了有效解决方案。


<details>
  <summary>Details</summary>
Motivation: 高性能计算（HPC）软件生态系统复杂，维护和创建Spack依赖包配方（recipe）十分繁琐，现有自动化工具依赖手工编写，面临可扩展性挑战。研究动机是寻求自动化、可维护的依赖管理方法。

Method: 提出SpackIt框架，整合代码仓库分析、相关示例检索和基于诊断反馈的迭代精炼，系统性探索大语言模型（LLM）及上下文增强方法生成Spack配方的能力，并在308个开源HPC软件包上测试。

Result: SpackIt框架将Spack包安装成功率从零样本（zero-shot）的20%提升到最优配置下的80%以上，有效利用信息检索与结构化反馈，提高包构建的自动化和可靠性。

Conclusion: 结合大语言模型、示例检索和诊断反馈能明显提高自动生成Spack包配方的准确率和可维护性，是自动化通用包管理的重要技术途径。

Abstract: High performance computing (HPC) software ecosystems are inherently heterogeneous, comprising scientific applications that depend on hundreds of external packages, each with distinct build systems, options, and dependency constraints. Tools such as Spack automate dependency resolution and environment management, but their effectiveness relies on manually written build recipes. As these ecosystems grow, maintaining existing specifications and creating new ones becomes increasingly labor-intensive. While large language models (LLMs) have shown promise in code generation, automatically producing correct and maintainable Spack recipes remains a significant challenge. We present a systematic analysis of how LLMs and context-augmentation methods can assist in the generation of Spack recipes. To this end, we introduce SpackIt, an end-to-end framework that combines repository analysis, retrieval of relevant examples, and iterative refinement through diagnostic feedback. We apply SpackIt to a representative subset of 308 open-source HPC packages to assess its effectiveness and limitations. Our results show that SpackIt increases installation success from 20% in a zero-shot setting to over 80% in its best configuration, demonstrating the value of retrieval and structured feedback for reliable package synthesis.

</details>


### [3] [Accelerating Control Systems with GitOps: A Path to Automation and Reliability](https://arxiv.org/abs/2511.05663)
*M. Gonzalez,M. Acosta*

Main category: cs.SE

TL;DR: 该论文展示了通过GitOps等现代技术手段，科学实验设施如何实现基础设施和应用的自动化、智能化与现代化升级。


<details>
  <summary>Details</summary>
Motivation: 科学设施（如CERN、Diamond Light Source等）正逐步迈向现代软件与基础设施模式，但实际转型面临挑战。本项目旨在加快设施管理与数据采集的自动化和智能化进程。

Method: 通过在像Fermilab这样的科学加速器设施引入GitOps、容器化、基础设施即代码、现代数据管道，以及AI/ML技术，实践并探索这些方法的应用效果。

Result: ACORN项目已将GitOps及相关技术应用于控制系统现代化，包括实现自动化部署与管理，提升数据处理能力，并开始融合AI/ML优化设施运营。

Conclusion: GitOps等现代工程实践有助于实现自动化、可审计和版本控制的基础设施管理，推动科学设施的软件与硬件现代化。

Abstract: GitOps is a foundational approach for modernizing infrastructure by leveraging Git as the single source of truth for declarative configurations. The poster explores how GitOps transforms traditional control system infrastructure, services and applications by enabling fully automated, auditable, and version-controlled infrastructure management. Cloud-native and containerized environments are shifting the ecosystem not only in the IT industry but also within the computational science field, as is the case of CERN [1] and Diamond Light Source [2] among other Accelerator/Science facilities which are slowly shifting towards modern software and infrastructure paradigms. The ACORN project, which aims to modernize Fermilab's control system infrastructure and software is implementing proven best-practices and cutting-edge technology standards including GitOps, containerization, infrastructure as code and modern data pipelines for control system data acquisition and the inclusion of AI/ML in our accelerator complex.

</details>


### [4] [An Empirical Study of Java Code Improvements Based on Stack Overflow Answer Edits](https://arxiv.org/abs/2511.05813)
*In-on Wiratsin,Chaiyong Ragkhitwetsagul,Matheus Paixao,Denis De Sousa,Pongpop Lapvikai,Peter Haddawy*

Main category: cs.SE

TL;DR: 研究将Stack Overflow Java答案的编辑用于开源项目代码优化，通过代码克隆与手动分析，发现约半数编辑可直接用在实际项目，部分建议已被项目采纳，显示SO社区协作知识有助于提升软件质量。


<details>
  <summary>Details</summary>
Motivation: 鉴于开发者常因多种原因编写次优代码，维护成本和技术债务随之增加，因此探索利用SO代码片段改进开源项目代码的可能性。

Method: 通过改进的代码克隆搜索工具，分析带有历史版本的SO Java代码片段，并对开源项目进行对比，手动分类编辑类型并创建PR（拉取请求）应用代码改进。

Result: 6.91%的SO Java答案有多次修订，49.24%的编辑代码段可实际用于开源项目，建议的36个Bug修复中有11个被正式项目接受。

Conclusion: SO上的答案编辑能为开源项目代码优化和错误修复提供实际帮助，社区协作知识库对提升代码质量发挥了积极作用。

Abstract: Suboptimal code is prevalent in software systems. Developers often write low-quality code due to factors like technical knowledge gaps, insufficient experience, time pressure, management decisions, or personal factors. Once integrated, the accumulation of this suboptimal code leads to significant maintenance costs and technical debt.
  Developers frequently consult external knowledge bases, such as API documentation and Q&A websites like Stack Overflow (SO), to aid their programming tasks. SO's crowdsourced, collaborative nature has created a vast repository of programming knowledge. Its community-curated content is constantly evolving, with new answers posted or existing ones edited.
  In this paper, we present an empirical study of SO Java answer edits and their application to improving code in open-source projects. We use a modified code clone search tool to analyze SO code snippets with version history and apply it to open-source Java projects. This identifies outdated or unoptimized code and suggests improved alternatives. Analyzing 140,840 Java accepted answers from SOTorrent and 10,668 GitHub Java projects, we manually categorized SO answer edits and created pull requests to open-source projects with the suggested code improvements. Our results show that 6.91% of SO Java accepted answers have more than one revision (average of 2.82). Moreover, 49.24% of the code snippets in the answer edits are applicable to open-source projects, and 11 out of 36 proposed bug fixes based on these edits were accepted by the GitHub project maintainers.

</details>


### [5] [High-Performance Generation of Constrained Input](https://arxiv.org/abs/2511.05987)
*Addison Crump,Alexi Turcotte,José Antonio Zamudio Amaya,Andreas Zeller*

Main category: cs.SE

TL;DR: 作者提出了一种基于Rust和优化进化算法的新型语言测试生成方法，极大加速了测试用例生成和约束求解，显著优于现有工具，适配更复杂测试需求。


<details>
  <summary>Details</summary>
Motivation: 现有基于语言的测试方法，通过将上下文无关文法与语义约束结合，生成测试用例。但在复杂约束场景下，现有方法（如SMT求解器和进化算法）效率低或难以应对高复杂度约束，影响编译器等领域的测试需求。

Method: 作者提出了一种新颖的进化式基于语言的测试方案：一方面将文法转化为Rust类型与trait，以充分利用编译器优化；另一方面引入更优的进化算法，以增强约束求解能力。

Result: 新原型FANDANGO-RS相比既有方法性能提升3-4个数量级，能在数秒内完成以往需数小时的生成与求解任务。案例研究中，FANDANGO-RS每分钟可为C子集编译器产生401个多样、复杂且有效的测试用例。

Conclusion: 通过将文法高效映射为Rust类型并优化进化算法，该方法显著提升了基于语言的测试在处理复杂约束时的性能，并可扩展至更复杂的实际测试场景。

Abstract: Language-based testing combines context-free grammar definitions with semantic constraints over grammar elements to generate test inputs. By pairing context-free grammars with constraints, users have the expressiveness of unrestricted grammars while retaining simple structure. However, producing inputs in the presence of such constraints can be challenging. In past approaches, SMT solvers have been found to be very slow at finding string solutions; evolutionary algorithms are faster and more general, but current implementations still struggle with complex constraints that would be required for domains such as compiler testing. In this paper, we present a novel approach for evolutionary language-based testing that improves performance by 3-4 orders of magnitude over the current state of the art, reducing hours of generation and constraint solving time to seconds. We accomplish this by (1) carefully transforming grammar definitions into Rust types and trait implementations, ensuring that the compiler may near-maximally optimize arbitrary operations on arbitrary grammars; and (2) using better evolutionary algorithms that improve the ability of language-based testing to solve complex constraint systems. These performance and algorithmic improvements allow our prototype, FANDANGO-RS, to solve constraints that previous strategies simply cannot handle. We demonstrate this by a case study for a C subset, in which FANDANGO-RS is able to generate 401 diverse, complex, and valid test inputs for a C compiler per minute.

</details>


### [6] [WAR-Re: Web API Recommendation with Semantic Reasoning](https://arxiv.org/abs/2511.05820)
*Zishuo Xu,Dezhong Yao,Yao Wan*

Main category: cs.SE

TL;DR: 本文提出了一种结合大语言模型和语义推理的新Web API推荐方法WAR-Re，不仅提升了推荐准确率，还能自动生成推荐理由，有效补足了现有方法的主要不足。


<details>
  <summary>Details</summary>
Motivation: 云计算的发展使Web API数量急剧增加，推动了高效API推荐的需求。但现有方法存在两大挑战：一是推荐数量固定，无法适应不同需求；二是只给排序列表，没有解释原因，用户理解困难。

Method: 提出WAR-Re模型，基于大语言模型，利用特殊的起止标记解决API推荐数量可变的问题，并采用两阶段训练方法：有监督微调和基于GRPO的强化学习，以提升推荐效果和解释能力。

Result: 在ProgrammableWeb数据集上，WAR-Re模型的推荐准确率比最先进的基线模型提升了最多21.59%，且能持续输出高质量的推荐理由。

Conclusion: WAR-Re显著提升了Web API推荐的灵活性和可解释性，成为API推荐领域的有效新方案。

Abstract: With the development of cloud computing, the number of Web APIs has increased dramatically, further intensifying the demand for efficient Web API recommendation. Despite the demonstrated success of previous Web API recommendation solutions, two critical challenges persist: 1) a fixed top-N recommendation that cannot accommodate the varying API cardinality requirements of different mashups, and 2) these methods output only ranked API lists without accompanying reasons, depriving users of understanding the recommendation. To address these challenges, we propose WAR-Re, an LLM-based model for Web API recommendation with semantic reasoning for justification. WAR-Re leverages special start and stop tokens to handle the first challenge and uses two-stage training: supervised fine-tuning and reinforcement learning via Group Relative Policy Optimization (GRPO) to enhance the model's ability in both tasks. Comprehensive experimental evaluations on the ProgrammableWeb dataset demonstrate that WAR-Re achieves a gain of up to 21.59\% over the state-of-the-art baseline model in recommendation accuracy, while consistently producing high-quality semantic reasons for recommendations.

</details>


### [7] [PyGress: Tool for Analyzing the Progression of Code Proficiency in Python OSS Projects](https://arxiv.org/abs/2511.05821)
*Rujiphart Charatvaraphan,Bunradar Chatchaiyadech,Thitirat Sukijprasert,Chaiyong Ragkhitwetsagul,Morakot Choetkiertikul,Raula Gaikovina Kula,Thanwadee Sunetnanta,Kenichi Matsumoto*

Main category: cs.SE

TL;DR: 本文提出一个自动评估和可视化开源项目开发者Python代码水平的工具PyGress，实现基于源码和提交历史的能力分布与进展追踪，支持更深入的项目管理和团队能力分析。


<details>
  <summary>Details</summary>
Motivation: 开源项目的发展依赖于开发者的能力评估，尤其在理解团队成员的编程水平以及项目整体技能动态方面至关重要。但目前用于自动评估和可视化开发者编程能力的工具较少，单靠手动评估效率低，易受主观影响。

Method: 提出并实现了PyGress，一个基于网页的工具。用户只需提交GitHub仓库链接，系统利用pycefr（Python代码能力分析器）自动提取代码提交记录，按照CEFR等级（A1到C2）分析源码，并生成个人和项目整体能力的可视化结果。工具可追踪各贡献者的能力分布及项目能力随时间的演变。

Result: PyGress实现了Python开源项目贡献者能力自动评估与动态可视化，支持项目和个人角度的能力追踪，工具开源，且有操作演示视频。

Conclusion: PyGress为探索和评估开源项目贡献者编程水平提供了新的自动化可视化方式，有助于项目管理决策和开发团队能力提升。

Abstract: Assessing developer proficiency in open-source software (OSS) projects is essential for understanding project dynamics, especially for expertise. This paper presents PyGress, a web-based tool designed to automatically evaluate and visualize Python code proficiency using pycefr, a Python code proficiency analyzer. By submitting a GitHub repository link, the system extracts commit histories, analyzes source code proficiency across CEFR-aligned levels (A1 to C2), and generates visual summaries of individual and project-wide proficiency. The PyGress tool visualizes per-contributor proficiency distribution and tracks project code proficiency progression over time. PyGress offers an interactive way to explore contributor coding levels in Python OSS repositories. The video demonstration of the PyGress tool can be found at https://youtu.be/hxoeK-ggcWk, and the source code of the tool is publicly available at https://github.com/MUICT-SERU/PyGress.

</details>


### [8] [The Impact of COVID-19 and Remote Work on Software Development in Thailand](https://arxiv.org/abs/2511.05824)
*Chaiyong Ragkhitwetsagul,Morakot Choetkiertikul,Srisupa Palakvangsa-Na-Ayudhya,Thanwadee Sunetnanta,Nattanee Satchanawakul*

Main category: cs.SE

TL;DR: 本研究调查了泰国软件开发者疫情期间远程工作的影响，发现生产力和幸福感无显著变化，既有挑战也有收获，结果可为类似国家提供借鉴。


<details>
  <summary>Details</summary>
Motivation: 疫情改变了软件开发的工作模式，尤其是远程办公。虽然有许多关于疫情期间软件开发远程工作的研究，但尚无专门针对泰国这一亚洲增长型市场的研究。

Method: 通过问卷调查194名泰国软件开发人员，分析他们在疫情期间远程工作面临的挑战与收获。

Result: 泰国软件开发者在疫情前后生产力和幸福感上没有统计学显著变化。远程工作既带来了机遇也带来了挑战，结果与其他研究类似，但也有泰国独特的差异。

Conclusion: 泰国软件开发员在疫情期间远程工作经验可为亚洲其他国家及全球低中收入国家提供参考。

Abstract: The COVID-19 pandemic impacted the way of working, including software development. During the pandemic, software companies were forced to work remotely, and many companies have been using such work arrangements. There are prior studies showing the benefits and drawbacks of remote work in software development during COVID-19. However, there is no study that targets Thailand, one of the growing software markets in Asia, specifically. This paper performs an empirical study of the effects of COVID-19 on software development in Thailand. We surveyed 194 Thai software developers regarding the challenges and benefits they faced while working remotely during the COVID-19 period. The results show no statistically significant changes in the productivity and well-being of Thai software developers before and after working remotely due to the pandemic. The results show that software developers in Thailand both received benefits and faced challenges from remote work during COVID-19, similar to results reported by other studies, but with some unique differences. This study can be beneficial to similar Asian countries or other low- and middle-income countries around the world.

</details>


### [9] [Design and Implementation of Data Acquisition and Analysis System for Programming Debugging Process Based On VS Code Plug-In](https://arxiv.org/abs/2511.05825)
*Boyang Liu*

Main category: cs.SE

TL;DR: 本文提出并实现了一个基于VS Code插件的编程调试数据采集与分析系统，通过多种技术自动化识别学生调试行为，支持更精细的教学评估，系统在教学实际测试中表现有效和稳定。


<details>
  <summary>Details</summary>
Motivation: 现有的传统评估方式难以全面评估学生的编程调试能力，故需一种新的系统来满足学生调试能力训练和评估的需求。

Method: 基于VS Code插件，设计并实现了一个支持多种编程语言的数据采集与分析系统，实时捕捉学生调试行为，并通过平台数据库进行全程监控和反馈；采用基于抽象语法树的调试行为分析模型，结合节点注释、序列识别和聚类分析等技术，自动跟踪调试过程上下文并识别关键特征。

Result: 系统能够实时监控学生调试行为，智能化识别调试方向与行为模式，实现精细化调试数据分析。通过引入多文件多任务复杂场景，提升了数据多维捕捉能力。经过多次教学测试，证明了系统的可行性和稳定性，可有效支持调试教学中的程序化评估。

Conclusion: 该系统不仅优化和提升了学生调试行为分析的精度，还为调试行为分析的研究提供了新方向，能够改善教师的教学效果，辅助更加科学精准的调试能力评估。

Abstract: In order to meet the needs of students' programming debugging ability training, this paper designs and implements a data acquisition and analysis system for programming debugging process based on VS Code plug-in, which aims to solve the limitation of traditional assessment methods that are difficult to fully evaluate students' debugging ability. The system supports a variety of programming languages, integrates debugging tasks and data acquisition functions, captures students' debugging behavior in the local editor in real time, and uploads the data to the platform database to realize the whole process monitoring and feedback, provides accurate debugging guidance for teachers, and improves the teaching effect. In terms of data analysis, the system proposed a debugging behavior analysis model based on abstract syntax tree, combined with node annotation, sequence recognition and cluster analysis and other technologies, to automatically track the context of students' debugging process and accurately identify key features in the debugging path. Through this tool, the system realizes the intelligent identification and labeling of the debugging direction and behavior pattern, and improves the refinement level of debugging data analysis. In this research system, a complex debugging scenario of multi-file and multi-task is introduced into the debugging problem design, which optimizes the multi-dimensional capturing ability of debugging data and lays a foundation for accurate debugging behavior analysis. Through several practical teaching tests, the feasibility and stability of the system are verified, which proves that it can effectively support procedural evaluation in programming debugging teaching, and provides a new direction for debugging behavior analysis research.

</details>


### [10] [ZeroLog: Zero-Label Generalizable Cross-System Log-based Anomaly Detection](https://arxiv.org/abs/2511.05862)
*Xinlong Zhao,Tong Jia,Minghua He,Ying Li,Gang Huang*

Main category: cs.SE

TL;DR: 本文提出ZeroLog方法实现零标签跨系统日志异常检测，通过对抗训练和元学习获得系统无关特征，无需目标系统标签可达先进性能，大幅降低应用门槛。


<details>
  <summary>Details</summary>
Motivation: 日志异常检测对于软件系统的稳定性和可靠性至关重要，但实际中常常缺乏有标签的日志数据。当前方法多依赖迁移学习，借助成熟系统的大量标注日志，但仍需目标系统的部分标签。作者关注的是一个更极端但实际常见的场景：目标系统完全缺乏标签，即“零标签跨系统”日志异常检测。

Method: 提出ZeroLog方法，采用系统无关的表示元学习。具体做法包括：利用无监督领域自适应技术，在源系统与目标系统间进行对抗训练，获得系统无关的通用特征表征；通过元学习方式进一步提升特征的泛化能力，实现无需目标标签的异常检测。

Result: 在三个不同系统的公开日志数据集上，ZeroLog在无标签情况下F1分数超过80%，不仅与依赖带标签日志的最新方法效果相当，而且在零标签条件下显著优于已有方法。

Conclusion: ZeroLog首次实现了真正的零标签跨系统日志异常检测，仅需源系统标注数据即可取得卓越效果，大幅降低了异常检测的实际数据标注成本。

Abstract: Log-based anomaly detection is an important task in ensuring the stability and reliability of software systems. One of the key problems in this task is the lack of labeled logs. Existing works usually leverage large-scale labeled logs from mature systems to train an anomaly detection model of a target system based on the idea of transfer learning. However, these works still require a certain number of labeled logs from the target system. In this paper, we take a step forward and study a valuable yet underexplored setting: zero-label cross-system log-based anomaly detection, that is, no labeled logs are available in the target system. Specifically, we propose ZeroLog, a system-agnostic representation meta-learning method that enables cross-system log-based anomaly detection under zero-label conditions. To achieve this, we leverage unsupervised domain adaptation to perform adversarial training between the source and target domains, aiming to learn system-agnostic general feature representations. By employing meta-learning, the learned representations are further generalized to the target system without any target labels. Experimental results on three public log datasets from different systems show that ZeroLog reaches over 80% F1-score without labels, comparable to state-of-the-art cross-system methods trained with labeled logs, and outperforms existing methods under zero-label conditions.

</details>


### [11] [Generality Is Not Enough: Zero-Label Cross-System Log-Based Anomaly Detection via Knowledge-Level Collaboration](https://arxiv.org/abs/2511.05882)
*Xinlong Zhao,Tong Jia,Minghua He,Ying Li*

Main category: cs.SE

TL;DR: 本文提出GeneralLog方法，通过动态知识分工实现零标签跨系统日志异常检测，无需目标系统标注，性能（F1>90%）显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于日志的异常检测方法在跨系统应用时面临难以获得目标系统带标签日志的问题，导致部署受限。虽然最新方法在少量标注下表现不错，但依赖样本复杂度且知识迁移不足或推理成本高，难以满足零标签场景需求。

Method: 提出GeneralLog方法，创新性地结合LLM和小模型，在零标签跨系统场景下根据日志类型动态分配处理任务：LLM负责目标系统的专有日志，小模型负责通用日志，实现知识分工协作，无需目标系统的标注。

Result: 在三个公开日志数据集上的实验结果显示，GeneralLog在完全无标签的设置下能取得90%以上的F1分数，明显优于现有方法。

Conclusion: GeneralLog改变了跨系统日志异常检测方法的知识分配策略，不仅实现了零标签下高性能检测，还突破了以往模型在知识迁移与推理效率上的限制。

Abstract: Log-based anomaly detection is crucial for ensuring software system stability. However, the scarcity of labeled logs limits rapid deployment to new systems. Cross-system transfer has become an important research direction. State-of-the-art approaches perform well with a few labeled target logs, but limitations remain: small-model methods transfer general knowledge but overlook mismatches with the target system's proprietary knowledge; LLM-based methods can capture proprietary patterns but rely on a few positive examples and incur high inference cost. Existing LLM-small model collaborations route 'simple logs' to the small model and 'complex logs' to the LLM based on output uncertainty. In zero-label cross-system settings, supervised sample complexity is unavailable, and such routing does not consider knowledge separation. To address this, we propose GeneralLog, a novel LLM-small model collaborative method for zero-label cross-system log anomaly detection. GeneralLog dynamically routes unlabeled logs, letting the LLM handle 'proprietary logs' and the small model 'general logs,' enabling cross-system generalization without labeled target logs. Experiments on three public log datasets show that GeneralLog achieves over 90% F1-score under a fully zero-label setting, significantly outperforming existing methods.

</details>


### [12] [SWE-fficiency: Can Language Models Optimize Real-World Repositories on Real Workloads?](https://arxiv.org/abs/2511.06090)
*Jeffrey Jian Ma,Milad Hashemi,Amir Yazdanbakhsh,Kevin Swersky,Ofir Press,Enhui Li,Vijay Janapa Reddi,Parthasarathy Ranganathan*

Main category: cs.SE

TL;DR: 本文提出SWE-fficiency基准，自动从真实开源仓库采集性能优化任务，针对完整代码库及慢速工作负载，系统评估智能体的定位、修复和测试能力。结果显示现有智能体远落后专家，公开的数据和基准将推动自动化性能工程与软件推理领域研究。


<details>
  <summary>Details</summary>
Motivation: 现有的性能优化基准主要关注于代码需要修复的地方，即“修什么”，而忽略了具体的优化方法，即“怎么修”。亟需一个能够综合评估大型软件仓库性能优化能力、尤其关注优化路径和方法之基准。

Method: 本研究构建了SWE-fficiency基准，并通过自动化流程：从GitHub拉取性能优化相关的Pull Request，结合关键词筛选、静态分析、覆盖率工具和执行验证，得到性能提升的代码修正和相关测试。该基准覆盖9个主流的数据科学、机器学习和高性能计算仓库，共计498个具体任务。评估中，要求智能体定位性能瓶颈和相关测试、并提交能达到甚至超过专家加速效果且通过所有单元测试的补丁。

Result: 现有先进智能体平均仅能达到专家加速效果的0.15倍，主要在于智能体在定位优化机会、跨函数执行推理以及保证代码正确性方面存在较大不足。

Conclusion: SWE-fficiency基准为软件性能自动化工程与复杂代码优化方法研究提供了重要平台和数据，当前智能体在此任务下仍面临较大挑战。研究者可以据此改进自动化软工智能体，提高其实际性能优化能力。

Abstract: Optimizing the performance of large-scale software repositories demands expertise in code reasoning and software engineering (SWE) to reduce runtime while preserving program correctness. However, most benchmarks emphasize what to fix rather than how to fix code. We introduce \textsc{SWE-fficiency}, a benchmark for evaluating repository-level performance optimization on real workloads. Our suite contains 498 tasks across nine widely used data-science, machine-learning, and HPC repositories (e.g., numpy, pandas, scipy): given a complete codebase and a slow workload, an agent must investigate code semantics, localize bottlenecks and relevant tests, and produce a patch that matches or exceeds expert speedup while passing the same unit tests. To enable this how-to-fix evaluation, our automated pipeline scrapes GitHub pull requests for performance-improving edits, combining keyword filtering, static analysis, coverage tooling, and execution validation to both confirm expert speedup baselines and identify relevant repository unit tests. Empirical evaluation of state-of-the-art agents reveals significant underperformance. On average, agents achieve less than 0.15x the expert speedup: agents struggle in localizing optimization opportunities, reasoning about execution across functions, and maintaining correctness in proposed edits. We release the benchmark and accompanying data pipeline to facilitate research on automated performance engineering and long-horizon software reasoning.

</details>


### [13] [Quality in model-driven engineering: a tertiary study](https://arxiv.org/abs/2511.06103)
*Miguel Goulão,Vasco Amaral,Marjan Mernik*

Main category: cs.SE

TL;DR: 本文通过三级综述系统整合了MDE对软件质量的影响研究，发现可维护性为关注重点，但更多实证与使用质量相关研究亟待加强。


<details>
  <summary>Details</summary>
Motivation: 模型驱动工程（MDE）对软件质量的影响广受关注，但相关证据分散在大量不同文献中，研究人员和从业者难以系统获取。本文旨在整合MDE对软件质量影响的研究成果，为科研与实践人员提供便捷参考，并揭示尚需关注的研究空白。

Method: 作者进行了关于MDE与软件质量的三级研究综述，系统收集和分析了文献中的突出发现和挑战。在筛选文献后，确定了22项系统性文献综述与映射研究，并提取了其中所涉及的主要质量属性。

Result: 发现MDE最常被研究和报告的质量属性是可维护性。被选定的二级研究中的大多数研究问题倾向于梳理现有研究，而非对具体方法进行直接对比。已收集的研究对软件产品质量有广泛覆盖，但多数呼吁进行更多实证研究以验证现有观点。MDE对产品使用质量的影响关注较少。

Conclusion: MDE对软件质量的影响已有较多综述性研究积累，尤其是可维护性领域，然而相关实证数据和对使用质量的关注还显不足。研究者需补足更具体、对比性及实证性的研究，尤其在产品使用质量方面。

Abstract: Model-driven engineering (MDE) is believed to have a significant impact in software quality. However, researchers and practitioners may have a hard time locating consolidated evidence on this impact, as the available information is scattered in several different publications. Our goal is to aggregate consolidated findings on quality in MDE, facilitating the work of researchers and practitioners in learning about the coverage and main findings of existing work as well as identifying relatively unexplored niches of research that need further attention. We performed a tertiary study on quality in MDE, in order to gain a better understanding of its most prominent findings and existing challenges, as reported in the literature. We identified 22 systematic literature reviews and mapping studies and the most relevant quality attributes addressed by each of those studies, in the context of MDE. Maintainability is clearly the most often studied and reported quality attribute impacted by MDE. Eighty out of 83 research questions in the selected secondary studies have a structure that is more often associated with mapping existing research than with answering more concrete research questions (e.g., comparing two alternative MDE approaches with respect to their impact on a specific quality attribute). We briefly outline the main contributions of each of the selected literature reviews. In the collected studies, we observed a broad coverage of software product quality, although frequently accompanied by notes on how much more empirical research is needed to further validate existing claims. Relatively, little attention seems to be devoted to the impact of MDE on the quality in use of products developed using MDE.

</details>


### [14] [On the impact of semantic transparency on understanding and reviewing social goal models](https://arxiv.org/abs/2511.06110)
*Mafalda Santos,Catarina Gralha,Miguel Goulão,João Araújo,Ana Moreira*

Main category: cs.SE

TL;DR: 增强语义透明的i*语法在准确率、速度和易用性无显著提升，但能显著减少视觉工作量，模型上下文和语言说明能帮助理解符号。


<details>
  <summary>Details</summary>
Motivation: i*语言虽然在需求工程领域很有影响力，但因其复杂性和行业采用率低，导致研究者关注提升其具体语法及用户对模型的理解能力。

Method: 采用准实验的方法，将标准i*语法与增强语义透明性的替代语法进行对比，邀请57名新手参与模型理解与审查任务，通过任务成功率、时间、工作量（结合眼动仪和反馈）来测量表现。

Result: 未发现替代语法在准确度或速度上优于标准语法。两者在易用性认知上也相近，但用替代语法时，参与者在模型和语言说明上的视觉耗费显著较少。

Conclusion: 模型和语言说明的上下文可减弱i*符号识别的障碍。虽然准确度和速度无提升，但替代语法明显减少了视觉努力。

Abstract: Context: i* is one of the most influential languages in the Requirements Engineering research community. Perhaps due to its complexity and low adoption in industry, it became a natural candidate for studies aiming at improving its concrete syntax and the stakeholders' ability to correctly interpret i* models.
  Objectives: We evaluate the impact of semantic transparency on understanding and reviewing i* models, in the presence of a language key. Methods: We performed a quasi-experiment comparing the standard i* concrete syntax with an alternative that has an increased semantic transparency. We asked 57 novice participants to perform understanding and reviewing tasks on i* models, and measured their accuracy, speed and ease, using metrics of task success, time and effort, collected with eye-tracking and participants' feedback.
  Results: We found no evidence of improved accuracy or speed attributable to the alternative concrete syntax. Although participants' perceived ease was similar, they devoted significantly less visual effort to the model and the provided language key, when using the alternative concrete syntax.
  Conclusions: The context provided by the model and language key may mitigate the i* symbol recognition deficit reported in previous works. However, the alternative concrete syntax required a significantly lower visual effort.

</details>


### [15] [The Lifecycle Workbench - A Configurable Framework for Digitized Product Maintenance Services](https://arxiv.org/abs/2511.06149)
*Dominique Briechle,Mohammed Fahad Ali,Marit Briechle-Mathiszig,Tobias Geger,Robert Werner,Andreas Rausch*

Main category: cs.SE

TL;DR: 本文针对循环经济服务因定价与产品状况评估不确定导致的用户与服务商风险，提出LCW数字生态系统，显著提升服务可靠性与经济效益，有助于促进循环经济转型。


<details>
  <summary>Details</summary>
Motivation: 全球电子产品生产造成环境健康影响和资源枯竭，当前工业流程需转型以应对气候变化。循环经济（CE）作为一种社会经济系统，能在全球范围上重新配置资源和产品使用，尤其在延长产品生命周期方面具有优势。然而，尽管相关可持续服务被普遍认知，其使用率不高，主要原因之一是服务定价的不确定性，影响用户和服务提供商的意愿和利益。

Method: 提出Lifecycle Workbench (LCW)生态系统，采用数字化手段实现服务定价可靠性和产品状态评估。具体方法是通过数字化表示物品、部件等，以支持循环经济领域的服务流程。

Result: LCW生态系统能够提升产品状态评估的准确性及服务定价的可靠性，从而降低用户和服务商的经济风险，促进循环经济相关服务的使用。

Conclusion: 通过LCW生态系统，可为循环经济相关服务提供更高的可靠性和经济可行性，缓解当前因定价和物品状态不确定导致的服务采纳困难与风险。

Abstract: The global production of electric goods is at an all-time high, causing negative environmental and health impacts as well as a continuing depletion of natural resources. Considering the worsening global climate change, a transition of current industrial processes is necessary to tackle the above-mentioned factors. To address this urgent issue, socio-economic systems like the Circular Economy (CE) provide options to reallocate the use of resources and products on a global scale. Especially in terms of product lifecycle-prolonging, this system provides suitable approaches to alter the current modes of product handling by society and industry alike, based on the condition of the products. Although the importance and benefits of sustainable services enabling these options are widely known, users tend to shy away from using them. One of the reasons is the missing reliability in terms of the knowledge of the costs associated with a particular service. This uncertainty in expected pricing can, therefore, lower the willingness of potential clients. However, not only clients struggle with the boundary conditions of such services. On the part of the potential providers of services, the monetary risk is often caused by the incapability to detect the condition of a product in advance. This can result on the provider side in a severe economic loss if this possibility is not covered by the service price or through the mass of items, which could allow equalization of serval service operations. To address these weak points in current service execution, the authors propose the \textit{Lifecycle Workbench (LCW)}-ecosystem, which features digital representations to enhance the reliability of service pricing as well as the assessment of the condition of items, assemblies, and parts in the Circular Economy domain.

</details>


### [16] [Diagnosing and Resolving Android Applications Building Issues: An Empirical Study](https://arxiv.org/abs/2511.06186)
*Lakshmi Priya Bodepudi,Yutong Zhao,Ming Quan Fu,Yuanyuan Wu,Sen He,Yu Zhao*

Main category: cs.SE

TL;DR: 针对Android构建高失败问题，实证分析发现修复策略有效提升成功率，AI（如GPT-5）能辅助修复，提出改进建议与对影响因素的分析。


<details>
  <summary>Details</summary>
Motivation: Android应用构建过程因依赖复杂、配置多样及生态变化快而面临高失败率，亟需有效诊断和修复方案。

Method: 对200个开源Android项目（Java和Kotlin）进行实证分析，包括数据收集、构建执行、故障分类、修复策略设计，以及大语言模型辅助评估共五个阶段。

Result: 初次构建失败的135个项目中，通过诊断和修复策略成功解决了102个（占75.56%）。使用大模型辅助修复实现53.3%的成功建议率。

Conclusion: 提出的诊断与修复策略有效提升了Android项目构建的成功率，AI辅助具有实际应用前景。同时发现编程语言、项目年龄、应用规模影响构建成功。

Abstract: Building Android applications reliably remains a persistent challenge due to complex dependencies, diverse configurations, and the rapid evolution of the Android ecosystem. This study conducts an empirical analysis of 200 open-source Android projects written in Java and Kotlin to diagnose and resolve build failures. Through a five-phase process encompassing data collection, build execution, failure classification, repair strategy design, and LLM-assisted evaluation, we identified four primary types of build errors: environment issues, dependency and Gradle task errors, configuration problems, and syntax/API incompatibilities. Among the 135 projects that initially failed to build, our diagnostic and repair strategy enabled developers to resolve 102 cases (75.56%), significantly reducing troubleshooting effort. We further examined the potential of Large Language Models, such as GPT-5, to assist in error diagnosis, achieving a 53.3% success rate in suggesting viable fixes. An analysis of project attributes revealed that build success is influenced by programming language, project age, and app size. These findings provide practical insights into improving Android build reliability and advancing AI-assisted software maintenance.

</details>


### [17] [Assertion-Aware Test Code Summarization with Large Language Models](https://arxiv.org/abs/2511.06227)
*Anamul Haque Mollah,Ahmed Aljohani,Hyunsook Do*

Main category: cs.SE

TL;DR: 本文通过构建测试代码摘要基准，系统研究了不同提示信息对大语言模型生成测试摘要的影响，发现强调断言语义能最佳提升摘要质量，并在多种模型和评价方法下验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 单元测试代码常常缺乏表达测试意图的简洁摘要，特别是在自动生成或缺乏文档的代码库中。现有的大语言模型（LLMs）虽然有望解决这一问题，但其生成摘要的效果受提示方式影响较大。与通用代码摘要不同，测试代码摘要有其独特挑战，因为测试方法侧重于验证预期行为而不是实现功能。

Method: 本文构建了一个包含91个真实Java测试用例及开发者撰写摘要的新基准数据集，并设计受控消融实验，探究与测试代码相关的组件（如被测方法、断言信息、断言语义）对LLM生成测试摘要性能的影响。研究评估了四个代码LLM（Codex、Codestral、DeepSeek、Qwen-Coder），通过七种提示配置，使用n-gram指标（BLEU、ROUGE-L、METEOR）、语义相似度（BERTScore）和基于LLM的主观评估进行对比分析。

Result: 实验结果表明，使用断言语义作为提示可使摘要质量平均提升0.10分（2.3%），且所需输入token更少。Codex和Qwen-Coder生成的摘要与人类编写的摘要最为一致；DeepSeek尽管词汇重合度高，却表现较差。

Conclusion: 针对测试代码设计更有效的提示能够明显提升LLM生成摘要的质量，尤其是断言语义对提升效果最为显著。

Abstract: Unit tests often lack concise summaries that convey test intent, especially in auto-generated or poorly documented codebases. Large Language Models (LLMs) offer a promising solution, but their effectiveness depends heavily on how they are prompted. Unlike generic code summarization, test-code summarization poses distinct challenges because test methods validate expected behavior through assertions rather than im- plementing functionality. This paper presents a new benchmark of 91 real-world Java test cases paired with developer-written summaries and conducts a controlled ablation study to investigate how test code-related components-such as the method under test (MUT), assertion messages, and assertion semantics-affect the performance of LLM-generated test summaries. We evaluate four code LLMs (Codex, Codestral, DeepSeek, and Qwen-Coder) across seven prompt configurations using n-gram metrics (BLEU, ROUGE-L, METEOR), semantic similarity (BERTScore), and LLM-based evaluation. Results show that prompting with as- sertion semantics improves summary quality by an average of 0.10 points (2.3%) over full MUT context (4.45 vs. 4.35) while requiring fewer input tokens. Codex and Qwen-Coder achieve the highest alignment with human-written summaries, while DeepSeek underperforms despite high lexical overlap. The replication package is publicly available at https://doi.org/10. 5281/zenodo.17067550

</details>


### [18] [WebVIA: A Web-based Vision-Language Agentic Framework for Interactive and Verifiable UI-to-Code Generation](https://arxiv.org/abs/2511.06251)
*Mingde Xu,Zhen Yang,Wenyi Hong,Lihang Pan,Xinyue Fan,Yan Wang,Xiaotao Gu,Bin Xu,Jie Tang*

Main category: cs.SE

TL;DR: WebVIA提出了一套创新的UI-to-Code自动生成框架，显著提升了网页交互代码的生成和自动验证能力，超越现有方法，助力高效UI开发。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLMs）虽可辅助设计稿到代码的自动转化，但仅能生成静态UI代码，缺乏页面交互性，且UI开发仍然重复且耗时。亟需能自动生成且验证交互式UI代码的高效方案。

Method: 提出WebVIA框架，包括三部分：1）利用探索agent自动捕捉多状态的UI截图；2）UI2Code模型可生成可执行的交互式代码；3）验证模块自动检测生成代码的交互性。通过端到端的集成提升UI-to-Code自动化及交互验证。

Result: 实验证明WebVIA-Agent在UI探索的稳定性与准确性明显优于通用型agent（如Gemini-2.5-Pro）。WebVIA-UI2Code模型在交互和静态代码生成基准上均显著优于基础模型，可生成高质量、可交互的网页代码。

Conclusion: WebVIA首次实现了端到端的交互式UI-to-Code生成和自动验证，推动UI开发自动化水平，并提供了公开可用的代码和模型资源。

Abstract: User interface (UI) development requires translating design mockups into functional code, a process that remains repetitive and labor-intensive. While recent Vision-Language Models (VLMs) automate UI-to-Code generation, they generate only static HTML/CSS/JavaScript layouts lacking interactivity. To address this, we propose WebVIA, the first agentic framework for interactive UI-to-Code generation and validation. The framework comprises three components: 1) an exploration agent to capture multi-state UI screenshots; 2) a UI2Code model that generates executable interactive code; 3) a validation module that verifies the interactivity. Experiments demonstrate that WebVIA-Agent achieves more stable and accurate UI exploration than general-purpose agents (e.g., Gemini-2.5-Pro). In addition, our fine-tuned WebVIA-UI2Code models exhibit substantial improvements in generating executable and interactive HTML/CSS/JavaScript code, outperforming their base counterparts across both interactive and static UI2Code benchmarks. Our code and models are available at \href{https://zheny2751-dotcom.github.io/webvia.github.io/}{\texttt{https://webvia.github.io}}.

</details>


### [19] [State of the Art on Self-adaptive Systems: An Essay](https://arxiv.org/abs/2511.06352)
*Sara Mahdavi Hezavehi,Danny Weyns,Paris Avgeriou*

Main category: cs.SE

TL;DR: 本文为博士研究奠定了不确定性与风险感知适应的理论基础，并梳理相关前沿研究。


<details>
  <summary>Details</summary>
Motivation: 为推动博士研究，有必要梳理并整合不确定性与风险感知领域的核心理论和现有成果。

Method: 首先介绍相关基础概念，然后综述相关领域的研究进展。

Result: 文中厘清了该领域的关键概念，系统梳理了相关研究，为后续科研提供理论支撑。

Conclusion: 本文总结了不确定性与风险感知适应的基础理论，为后续博士研究做好理论铺垫。

Abstract: In this essay, we introduce the basic concepts necessary to lay out the foundation for our PhD research on uncertainty and risk-aware adaptation, and discuss relevant related research.

</details>


### [20] [Understanding Student Interaction with AI-Powered Next-Step Hints: Strategies and Challenges](https://arxiv.org/abs/2511.06362)
*Anastasiia Birillo,Aleksei Rostovskii,Yaroslav Golubev,Hieke Keuning*

Main category: cs.SE

TL;DR: 研究分析了学生在IDE中与AI提示系统的交互，发现了多种处理提示的方法，并总结行为模式与改进建议，为未来编程教育中自动化提示系统的优化提供了参考。


<details>
  <summary>Details</summary>
Motivation: 在计算机科学教育中，自动化反馈（尤其是下一步提示）对个性化学习至关重要。当前尚需系统了解学生如何与AI驱动的提示系统互动及面对无效提示时的应对方式，以推动提示系统的优化。

Method: 收集34名学生在IDE环境下解决Kotlin任务的数据，分析详细的提示交互日志，并应用流程挖掘技术识别16种常见的互动场景。此外，对6名学生进行了半结构化访谈以深入理解其行为策略。

Result: 通过流程挖掘，识别出16种交互场景；访谈揭示学生面对此类系统常用的策略。研究数据集公开，为后续研究提供支持，同时为提升提示设计与学习支持提供了新见解。

Conclusion: 本研究总结了学生与AI驱动的下一步提示系统的互动行为，揭示了学生为应对无效提示所采用的策略，如调整部分提示或修改代码以获取不同版本的提示。这些发现有助于改进自动化提示系统的设计，增强编程学习的个性化与有效性。

Abstract: Automated feedback generation plays a crucial role in enhancing personalized learning experiences in computer science education. Among different types of feedback, next-step hint feedback is particularly important, as it provides students with actionable steps to progress towards solving programming tasks. This study investigates how students interact with an AI-driven next-step hint system in an in-IDE learning environment. We gathered and analyzed a dataset from 34 students solving Kotlin tasks, containing detailed hint interaction logs. We applied process mining techniques and identified 16 common interaction scenarios. Semi-structured interviews with 6 students revealed strategies for managing unhelpful hints, such as adapting partial hints or modifying code to generate variations of the same hint. These findings, combined with our publicly available dataset, offer valuable opportunities for future research and provide key insights into student behavior, helping improve hint design for enhanced learning support.

</details>


### [21] [Methodological Considerations for Self-adaptive Systems: An Essay](https://arxiv.org/abs/2511.06367)
*Sara Mahdavi Hezavehi,Danny Weyns,Paris Avgeriou*

Main category: cs.SE

TL;DR: 本文综述了进行不确定性和风险适应性研究所需的方法论要点，为博士课题搭建理论基础。


<details>
  <summary>Details</summary>
Motivation: 新兴领域需要系统性的理论框架来指导对不确定性及风险感知适应性的研究。

Method: 综述相关方法论，探讨如何科学研究不确定性和风险感知的适应性。

Result: 概述了进行不确定性和风险适应研究应关注的关键方法论问题，为后续研究提供参考。

Conclusion: 本文主要为日后博士研究奠定基础，聚焦于不确定性和风险感知的适应性研究方法。

Abstract: In this essay, we provide an overview of methodological considerations necessary to lay out the foundation for our PhD research on uncertainty and risk-aware adaptation.

</details>


### [22] [Walking the Tightrope of LLMs for Software Development: A Practitioners' Perspective](https://arxiv.org/abs/2511.06428)
*Samuel Ferino,Rashina Hoda,John Grundy,Christoph Treude*

Main category: cs.SE

TL;DR: 此论文通过访谈与理论分析揭示了大型语言模型对软件开发的多层次利弊和管理建议，尤其强调了需要综合权衡和最佳实践，对团队和组织领导有现实指导价值。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的出现，对软件开发影响巨大，如流程自动化、劳动力转型等。虽已有初步讨论，但缺乏对LLM应用于软件开发前后影响平衡的实证研究。作者希望系统地理解LLM对开发的多层次影响及管理方法。

Method: 研究团队在2024年10月至2025年9月期间，分三轮对22位软件从业者进行访谈，采用社会技术扎根理论（STGT）分析参与者的访谈内容，以获得对LLM影响的深入理解。

Result: 研究发现LLM带来诸多益处，包括保持开发流程流畅、提升开发者心智模型、促进企业创新，同时也存在负面影响，如对开发者个性的负面作用及损害开发者声誉。影响体现于个人、团队、组织和社会四个层面，且总结了LLM应用中的最佳实践。

Conclusion: 该研究深入剖析了在实际软件开发过程中使用LLM所需面对的权衡，并对团队领导和IT管理者评估在其实际场景中应用LLM的可行性，提供了实证参考。

Abstract: Background: Large Language Models emerged with the potential of provoking a revolution in software development (e.g., automating processes, workforce transformation). Although studies have started to investigate the perceived impact of LLMs for software development, there is a need for empirical studies to comprehend how to balance forward and backward effects of using LLMs. Objective: We investigated how LLMs impact software development and how to manage the impact from a software developer's perspective. Method: We conducted 22 interviews with software practitioners across 3 rounds of data collection and analysis, between October (2024) and September (2025). We employed socio-technical grounded theory (STGT) for data analysis to rigorously analyse interview participants' responses. Results: We identified the benefits (e.g., maintain software development flow, improve developers' mental model, and foster entrepreneurship) and disadvantages (e.g., negative impact on developers' personality and damage to developers' reputation) of using LLMs at individual, team, organisation, and society levels; as well as best practices on how to adopt LLMs. Conclusion: Critically, we present the trade-offs that software practitioners, teams, and organisations face in working with LLMs. Our findings are particularly useful for software team leaders and IT managers to assess the viability of LLMs within their specific context.

</details>


### [23] [Automatically Identifying Solution-Related Content in Issue Report Discussions with Language Models](https://arxiv.org/abs/2511.06501)
*Antu Saha,Mehedi Sun,Oscar Chaparro*

Main category: cs.SE

TL;DR: 本文提出用语言模型自动识别问题报告讨论中的解决方案，通过实验比较不同模型和技术，微调LLM和集成模型效果最佳，可提升软件维护和理解效率，且具良好迁移能力。


<details>
  <summary>Details</summary>
Motivation: 软件开发者在解决问题时，需在漫长讨论中识别方案相关内容，手工过程难且费时。自动识别此内容，将有助于处理问题重开、回归、方案复用及理解代码变更原因。

Method: 本文提出用语言模型作为监督分类器自动识别问题讨论中的解决方案内容。分别探索嵌入、提示、微调三种方案，并在传统机器学习模型、预训练语言模型、大型语言模型三类分类器上进行对比实验。使用356个Mozilla Firefox问题报告构建数据集，训练并评价六种MLM、四种PLM和两种LLM共68种配置。

Result: 结果显示：采用LLM嵌入的MLM优于TF-IDF特征；提示方法效果较差；微调LLM取得最佳性能，LLAMAft F1值达0.716。最佳模型集成提升至0.737 F1。误判主要因线索误导或语境缺失，需语境感知分类器。模型可迁移到其他项目，少量项目特定数据可进一步提升效果。

Conclusion: 自动方案识别支持软件维护、问题理解与方案复用。提出的分类方法在多个模型和场景下表现优异，尤其是微调LLM和集成模型，且具较好领域迁移能力。

Abstract: During issue resolution, software developers rely on issue reports to discuss solutions for defects, feature requests, and other changes. These discussions contain proposed solutions-from design changes to code implementations-as well as their evaluations. Locating solution-related content is essential for investigating reopened issues, addressing regressions, reusing solutions, and understanding code change rationale. Manually understanding long discussions to identify such content can be difficult and time-consuming.
  This paper automates solution identification using language models as supervised classifiers. We investigate three applications-embeddings, prompting, and fine-tuning-across three classifier types: traditional ML models (MLMs), pre-trained language models (PLMs), and large language models (LLMs). Using 356 Mozilla Firefox issues, we created a dataset to train and evaluate six MLMs, four PLMs, and two LLMs across 68 configurations.
  Results show that MLMs with LLM embeddings outperform TF-IDF features, prompting underperforms, and fine-tuned LLMs achieve the highest performance, with LLAMAft reaching 0.716 F1 score. Ensembles of the best models further improve results (0.737 F1). Misclassifications often arise from misleading clues or missing context, highlighting the need for context-aware classifiers. Models trained on Mozilla transfer to other projects, with a small amount of project-specific data, further enhancing results. This work supports software maintenance, issue understanding, and solution reuse.

</details>


### [24] [LLM For Loop Invariant Generation and Fixing: How Far Are We?](https://arxiv.org/abs/2511.06552)
*Mostafijur Rahman Akhond,Saikat Chakraborty,Gias Uddin*

Main category: cs.SE

TL;DR: 本文评估了大语言模型在程序循环不变式推断与修复上的应用能力，发现其虽有一定潜力，但在没有辅助信息时效果有限，尤其在修复不变式方面，成功率较低。


<details>
  <summary>Details</summary>
Motivation: 循环不变式识别是自动化程序安全性评估的关键步骤，目前大语言模型（LLMs）在软件工程及形式化验证领域展现了潜力，但尚未有系统研究其在推断循环不变式方面的能力。本文旨在填补这一空白。

Method: 作者对多种开源及闭源、规模各异的大语言模型进行了实证研究，评估其推断程序归纳式循环不变式与修正错误不变式的能力。同时考察在辅助信息（如领域知识、例子）的补充下性能变化。

Result: 在推断和修复循环不变式方面，LLMs有一定实用性。补充辅助信息后，表现明显提升。推断循环不变式的最大成功率为78%，修复错误不变式的成功率仅为16%。

Conclusion: LLMs在推断循环不变式领域展示了一定价值，但若仅依赖其自身能力，表现仍有限。结合领域知识和示例等辅助信息可提升效果，且修复错误不变式的能力目前仍较弱。

Abstract: A loop invariant is a property of a loop that remains true before and after each execution of the loop. The identification of loop invariants is a critical step to support automated program safety assessment. Recent advancements in Large Language Models (LLMs) have demonstrated potential in diverse software engineering (SE) and formal verification tasks. However, we are not aware of the performance of LLMs to infer loop invariants. We report an empirical study of both open-source and closed-source LLMs of varying sizes to assess their proficiency in inferring inductive loop invariants for programs and in fixing incorrect invariants. Our findings reveal that while LLMs exhibit some utility in inferring and repairing loop invariants, their performance is substantially enhanced when supplemented with auxiliary information such as domain knowledge and illustrative examples. LLMs achieve a maximum success rate of 78\% in generating, but are limited to 16\% in repairing the invariant.

</details>


### [25] [PhaseSeed: Precise Call Graph Construction for Split-Phase Applications using Dynamic Seeding](https://arxiv.org/abs/2511.06661)
*Tapti Palit,Seyedhamed Ghavamnia,Michalis Polychronakis*

Main category: cs.SE

TL;DR: PhaseSeed通过先动态分析初始化阶段、再静态分析处理阶段，有效提升了分阶段应用的指针分析和调用图构建精度，在多个安全机制场景（如CFI、软件瘦身、系统调用过滤）中都有显著效果。


<details>
  <summary>Details</summary>
Motivation: 传统的静态指针分析技术在应用程序调用图构建中存在精度不足的问题，特别是它们忽略了应用分阶段（如初始化和处理阶段）的特点。研究者希望提升针对分阶段应用的指针分析精度，以更好地服务于软件安全机制。

Method: 本文提出了PhaseSeed技术：在应用初始化阶段通过动态分析收集运行时建立的points-to关系，然后将这些关系作为种子，输入到静态分析阶段，专注分析处理阶段的所有代码，从而提升指针分析的精度。

Result: PhaseSeed被应用于三种安全机制：控制流完整性（CFI）、软件瘦身和系统调用过滤。在CFI场景下，PhaseSeed较传统静态调用图构建技术将精度提升高达92.6%；在Seccomp配置文件生成中，能够过滤多9个关键系统调用。

Conclusion: 通过结合动态分析和静态分析，利用初始化阶段的实际points-to关系，PhaseSeed显著提升了针对分阶段应用的指针分析精度，为多类安全机制带来实质性改进。

Abstract: Precise and sound call graph construction is crucial for many software security mechanisms. Unfortunately, traditional static pointer analysis techniques used to generate application call graphs suffer from imprecision. These techniques are agnostic to the application's architecture and are designed for broad applicability. To mitigate this precision problem, we propose PhaseSeed, a novel technique that improves the accuracy of pointer analysis for split-phase applications, which have distinct initialization and processing phases. PhaseSeed analyzes the initialization phase dynamically, collecting the points-to relationships established at runtime. At the end of the initialization phase, it then seeds this information to a static analysis stage that performs pointer analysis for all code that stays in scope during the processing phase, improving precision. Our observations show that, given the same runtime configuration options, the points-to relationships established during the initialization phase remain constant across multiple runs. Therefore, PhaseSeed is sound with respect to a given initial configuration. We apply PhaseSeed to three security mechanisms: control flow integrity (CFI), software debloating, and system call filtering. PhaseSeed provides up to 92.6% precision improvement for CFI compared to static call graph construction techniques, and filters nine additional security-critical system calls when used to generate Seccomp profiles.

</details>


### [26] [Structural Enforcement of Statistical Rigor in AI-Driven Discovery: A Functional Architecture](https://arxiv.org/abs/2511.06701)
*Karen Sargsyan*

Main category: cs.SE

TL;DR: 本文提出利用Haskell函数式架构和声明性框架，结构性保障AI科学系统在顺序统计协议下的严谨性，实验证明该方法能防止自动研究中的统计错误，是提升自动科学诚信的重要防线。


<details>
  <summary>Details</summary>
Motivation: 在自动化研究系统（如AI科学家）中，顺序统计协议需要精确的状态管理和错误处理，现有系统很容易因动态假设检验而出现虚假发现。作者认为当前使用大型语言模型（LLM）辅助科学发现时，统计严谨性和结果可信性亟需结构性保障。

Method: 提出了一种基于函数式编程的“Research monad”（研究单子）架构，这是一种Haskell上的嵌入式领域特定语言（eDSL），利用monad变换器栈强制遵循顺序统计协议（如在线FDR控制）。此外，使用“声明性脚手架”方法，生成结构性严格的程序框架，来约束由LLM自动生成的命令式代码，防止如数据泄露等方法学错误。

Result: 通过大规模仿真实验（N=2000个假设）和端到端案例分析，验证了该方法可以有效防范自动化科学发现中的统计不严谨问题，提升系统整体的科学诚信。

Conclusion: 结合函数式架构和声明性脚手架能够为AI科学家的自动研究系统提供结构性防护，有效避免虚假发现和统计误用，强化自动科学发现的严谨性和可靠性。

Abstract: Sequential statistical protocols require meticulous state management and robust error handling -- challenges naturally suited to functional programming. We present a functional architecture for structural enforcement of statistical rigor in automated research systems (AI-Scientists). These LLM-driven systems risk generating spurious discoveries through dynamic hypothesis testing. We introduce the Research monad, a Haskell eDSL that enforces sequential statistical protocols (e.g., Online FDR (false discovery rate) control) using a monad transformer stack. To address risks in hybrid architectures where LLMs generate imperative code, we employ Declarative Scaffolding -- generating rigid harnesses that structurally constrain execution and prevent methodological errors like data leakage. We validate this approach through large-scale simulation (N=2000 hypotheses) and an end-to-end case study, demonstrating essential defense-in-depth for automated science integrity.

</details>


### [27] [Minimizing Breaking Changes and Redundancy in Mitigating Technical Lag for Java Projects](https://arxiv.org/abs/2511.06762)
*Rui Lu,Lyuye Zhang,Kaixuan Li,Min Zhang,Yixiang Chen*

Main category: cs.SE

TL;DR: 本文提出了DepUpdater工具，能高效自动化地升级开源软件依赖，减少技术滞后，同时保证项目兼容和控制冗余依赖，效果优于现有工具并带来兼容性提升的新发现。


<details>
  <summary>Details</summary>
Motivation: 解决开源软件依赖升级难题，避免技术滞后、兼容性问题和冗余依赖堆积，且现有工具未能有效平衡这些需求。希望实现自动化且高效的依赖升级流程。

Method: 提出DepUpdater工具，并通过实验与现有依赖管理工具进行了对比测试，同时进行了消融实验分析不同因素对升级结果的影响。最后利用该工具分析了传递依赖升级对兼容性的影响。

Result: DepUpdater比传统依赖管理工具更有效地减少了技术滞后并兼顾兼容性与依赖冗余，消融实验证明了冗余依赖考虑在升级流程中的重要性，并探索了传递依赖升级对兼容性的实际影响。

Conclusion: DepUpdater能够有效平衡依赖升级的多重考虑，实现最小化技术滞后、兼容性保障以及冗余依赖的裁剪。通过与现有工具对比，其效果更优。

Abstract: Re-using open-source software (OSS) can avoid reinventing the wheel, but failing to keep it up-to-date can lead to missing new features and persistent bugs or vulnerabilities that have already been resolved. The use of outdated OSS libraries introduces technical lag, necessitating timely upgrades. However, maintaining up-to-date libraries is challenging, as it may introduce incompatibility issues that break the project or redundant dependencies that unnecessarily increase the size of the project. These issues discourage developers from upgrading libraries, highlighting the need for a fully automated solution that balances version upgrades, reduces technical lag, ensures compatibility, and avoids redundant dependencies.
  To this end, we propose DepUpdater, which ensures that upgrades minimize technical lag as much as possible while avoiding incompatibility issues and redundant dependencies. The comparison with existing dependency management tools demonstrates that DepUpdater more effectively reduces technical lag while ensuring compatibility and pruning redundant dependencies. Additionally, an ablation study highlights the potential benefits of considering pruning requirements during upgrades to mitigate incompatibility issues. Finally, leveraging DepUpdater, we investigate the impact of transitive dependency upgrades on client compatibility, providing insights for future research.

</details>


### [28] [MetricSynth: Framework for Aggregating DORA and KPI Metrics Across Multi-Platform Engineering](https://arxiv.org/abs/2511.06864)
*Pallav Jain,Yuvraj Agrawal,Ashutosh Nigam,Pushpak Patil*

Main category: cs.SE

TL;DR: 该论文设计并实现了一个集中式数据框架，集成各类内部工具数据，实现开发体验和KPI的实时可视化分析，显著提升了效率并节省人力，为软件工程智能平台建设提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 大型软件开发中，工程领导者难以全面且数据驱动地了解团队绩效与系统健康，因数据分散于不同工具且手动报告耗时且易出错。

Method: 提出并实现了一个集中式框架，通过定时任务的数据采集层、双模式存储、指标预计算引擎、主动告警系统，并采用开源BI工具Metabase进行可视化，基于角色访问控制实现安全。

Result: 成功大幅减少了手动报告的工作量，每周节省约20人小时，并加快了数据驱动的瓶颈识别速度。系统具备良好的可扩展性，并对其权衡进行了讨论。

Conclusion: 提出的工程智能平台显著提升了报告效率和团队洞察力，是对DevEx和KPI监控的有价值补充。

Abstract: In modern, large-scale software development, engineering leaders face the significant challenge of gaining a holistic and data-driven view of team performance and system health. Data is often siloed across numerous disparate tools, making manual report generation time-consuming and prone to inconsistencies. This paper presents the architecture and implementation of a centralized framework designed to provide near-real-time visibility into developer experience (DevEx) and Key Performance Indicator (KPI) metrics for a software ecosystem. By aggregating data from various internal tools and platforms, the system computes and visualizes metrics across key areas such as Developer Productivity, Quality, and Operational Efficiency. The architecture features a cron-based data ingestion layer, a dual-schema data storage approach, a processing engine for metric pre-computation, a proactive alerting system, and utilizes the open-source BI tool Metabase for visualization, all secured with role-based access control (RBAC). The implementation resulted in a significant reduction in manual reporting efforts, saving an estimated 20 person-hours per week, and enabled faster, data-driven bottleneck identification. Finally, we evaluate the system's scalability and discuss its trade-offs, positioning it as a valuable contribution to engineering intelligence platforms.

</details>


### [29] [A Collaborative Model for Improving Information Sharing among Cancer Care Groups using Software Engineering Principles](https://arxiv.org/abs/2511.06885)
*Davis Byamugisha,Francis Kamuganga,Adones Rukundo,John Businge*

Main category: cs.SE

TL;DR: 本文提出将GitHub版本控制等软件工程原则用于癌症护理信息共享和协作，模拟实验表明可有效减少信息延误，加强团队协调，提高诊断和治疗效果。


<details>
  <summary>Details</summary>
Motivation: 癌症治疗的有效性需要早期诊断，但现实中由于医疗人力有限和信息管理系统设计缺陷，导致各护理团队之间存在信息鸿沟，进而造成诊断延误和沟通不畅。现有方法在决策支持和数据共享方面有欠缺，且忽略了某些关键利益相关者，未能有效解决这些问题。

Method: 通过分析癌症治疗与软件工程信息管理的相似性，采用软件工程GitHub版本控制系统中的缺陷修复原则设计信息共享模型，并利用Any-Logic仿真软件模拟模型在虚拟环境下的实际效果。

Result: 模型展示了软件工程和GitHub版本控制的缺陷修复原则可以有效协调癌症护理团队之间的信息共享和协作，涉及所有相关利益方，从而提高护理治疗效果、确保早期诊断并提升患者的生存率。

Conclusion: 将软件工程中的协作和版本管理原则应用到癌症护理的信息共享，有助于减少延误、改善协调和沟通，最终提升患者获益和治疗效果。

Abstract: Effective treatment of cancer requires early diagnosis which involves the patient's awareness of the early signs and symptoms, leading to a consultation with a health provider, who would then promptly refer the patient for confirmation of the diagnosis and thereafter treatment. However, this is not always the case because of delays arising from limited skilled manpower and health information management systems that are neither integrated nor organized in their design hence leading to information gap among care groups. Existing methods focus on using accumulated data to support decision making, enhancing the sharing of secondary data while others exclude some critical stakeholders like patient caretakers and administrators thus, leaving an information gap that creates delays and miscommunication during case management. We however notice some similarities between cancer treatment and software engineering information management especially when progress history needs to be maintained (versioning).
  We analyze the similarities and propose a model for information sharing among cancer care groups using the software engineering principles approach. We model for reducing delays and improving coordination among care groups in cancer case management. Model design was guided by software engineering principles adopted in GitHub version control system for bug fixing in open-source code projects. Any-Logic simulation software was used to mimic the model realism in a virtual environment. Results show that bug resolution principles from software engineering and GitHub version control system can be adopted to coordinate collaboration and information sharing among care groups in a cancer case management environment while involving all stakeholders to improve care treatment outcomes, ensure early diagnosis and increase patient's survival chances.

</details>


### [30] [Benchmarking LLMs for Fine-Grained Code Review with Enriched Context in Practice](https://arxiv.org/abs/2511.07017)
*Ruida Hu,Xinchen Wang,Xin-Cheng Wen,Zhao Zhang,Bo Jiang,Pengfei Gao,Chao Peng,Cuiyun Gao*

Main category: cs.SE

TL;DR: 本文提出了上下文丰富的代码评审基准ContextCRBench，弥补了现有评测集缺乏语义、样本质量低和粒度粗等问题，显著提升了LLM代码评审表现，并在工业场景中取得了实际应用和大幅性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有用于大语言模型代码评审的基准存在三个主要问题：缺乏语义上下文（如缺少问题描述）、数据质量不高（样本存在噪声）、粒度过粗（忽略细粒度的行级推理）。这些问题影响了代码评审自动化的有效性和评估的可靠性。

Method: 提出高质量、上下文丰富的代码评审基准ContextCRBench，通过三步构建流程：数据抓取（收集问题和拉取请求）、全面上下文提取（关联文本和代码上下文）、多阶段数据过滤（联合规则和LLM验证），最终获得近七万条优质多上下文评审样本。并设计三类评估场景：hunk级质量评估、行级缺陷定位、行级评审评论生成。

Result: 文本上下文能比代码上下文单独带来更大性能提升，现有主流LLM在代码评审任务上距离人类水平还有较大差距。ContextCRBench已在字节跳动落地应用，推动自进化代码评审系统，性能提升达61.98%，展现了实际工业价值和鲁棒性。

Conclusion: ContextCRBench凭借丰富的上下文和高质量样本，有效解决了现有基准的痛点，不仅提升了LLM评审性能，还在实际工业场景中实现了显著的效果和应用价值。

Abstract: Code review is a cornerstone of software quality assurance, and recent advances in Large Language Models (LLMs) have shown promise in automating this process. However, existing benchmarks for LLM-based code review face three major limitations. (1) Lack of semantic context: most benchmarks provide only code diffs without textual information such as issue descriptions, which are crucial for understanding developer intent. (2) Data quality issues: without rigorous validation, many samples are noisy-e.g., reviews on outdated or irrelevant code-reducing evaluation reliability. (3) Coarse granularity: most benchmarks operate at the file or commit level, overlooking the fine-grained, line-level reasoning essential for precise review.
  We introduce ContextCRBench, a high-quality, context-rich benchmark for fine-grained LLM evaluation in code review. Our construction pipeline comprises: (1) Raw Data Crawling, collecting 153.7K issues and pull requests from top-tier repositories; (2) Comprehensive Context Extraction, linking issue-PR pairs for textual context and extracting the full surrounding function or class for code context; and (3) Multi-stage Data Filtering, combining rule-based and LLM-based validation to remove outdated, malformed, or low-value samples, resulting in 67,910 context-enriched entries.
  ContextCRBench supports three evaluation scenarios aligned with the review workflow: (1) hunk-level quality assessment, (2) line-level defect localization, and (3) line-level comment generation. Evaluating eight leading LLMs (four closed-source and four open-source) reveals that textual context yields greater performance gains than code context alone, while current LLMs remain far from human-level review ability. Deployed at ByteDance, ContextCRBench drives a self-evolving code review system, improving performance by 61.98% and demonstrating its robustness and industrial utility.

</details>


### [31] [Bridging the Prototype-Production Gap: A Multi-Agent System for Notebooks Transformation](https://arxiv.org/abs/2511.07257)
*Hanya Elhashemy,Youssef Lotfy,Yongjian Tang*

Main category: cs.SE

TL;DR: Codelevate通过多智能体系统自动把Jupyter笔记本转为高质量Python代码库，显著提升工程规范和可维护性，实现原型到生产的无缝衔接。


<details>
  <summary>Details</summary>
Motivation: Jupyter笔记本在数据科学和机器学习中广泛应用，但笔记本代码通常缺乏软件工程规范，难以直接迁移到生产环境，因此亟需一种自动化工具提升代码结构和工程质量。

Method: 提出一个多智能体系统（包括Architect, Developer, Structure三位代理），利用共享依赖树协同将Jupyter笔记本自动转化为高质量、结构清晰的Python仓库。

Result: 实验结果表明，Codelevate能够显著提升代码质量指标并保持计算语义一致性，实现原型代码到生产代码的顺利转化。

Conclusion: Codelevate能够有效地将Jupyter笔记本原型代码自动转换为结构化、易维护的Python代码库，提高代码质量，顺利实现从原型到生产的过渡。

Abstract: The increasing adoption of Jupyter notebooks in data science and machine learning workflows has created a gap between exploratory code development and production-ready software systems. While notebooks excel at iterative development and visualization, they often lack proper software engineering principles, making their transition to production environments challenging. This paper presents Codelevate, a novel multi-agent system that automatically transforms Jupyter notebooks into well-structured, maintainable Python code repositories. Our system employs three specialized agents - Architect, Developer, and Structure - working in concert through a shared dependency tree to ensure architectural coherence and code quality. Our experimental results validate Codelevate's capability to bridge the prototype-to-production gap through autonomous code transformation, yielding quantifiable improvements in code quality metrics while preserving computational semantics.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [32] [Generalized Security-Preserving Refinement for Concurrent Systems](https://arxiv.org/abs/2511.06862)
*Huan Sun,David Sanán,Jingyi Wang,Yongwang Zhao,Jun Sun,Wenhai Wang*

Main category: cs.LO

TL;DR: 本文提出了一种通用的基于精化的信息流安全验证方法，适用于复杂安全策略下的并发系统。理论创新点在于抽象和实现之间的逐步映射，方法已在Isabelle/HOL下进行机械化验证，并成功发现及修正了多核航空标准的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 信息流安全(IFC)对并发系统，尤其是大规模代码基础（如多核OS内核）来说极具挑战性。现有基于精化的安全验证技术要么仅适用顺序系统，要么难以表达并发系统中的复杂安全策略。

Method: 提出并形式化了一种基于精化的组合式安全验证方法，通过在实现和抽象之间建立逐步映射关系，证明推广化的信息流安全属性（如非传递非干涉性）在实现与抽象之间得到保持。所有证明都在Isabelle/HOL中机械化完成。

Result: 所提新方法（1）在理论上推广了精化技术支持复杂策略下并发系统的IFC；（2）通过两个非平凡案例的全面机械化验证，发现并修正了ARINC 653多核标准中的隐蔽通道问题，证明了方法的有效性。

Conclusion: 本文提出的方法能有效地对并发系统中的信息流安全性(IFC)进行形式化验证，并能发现并修正复杂安全策略下的安全漏洞。

Abstract: Ensuring compliance with Information Flow Security (IFS) is known to be challenging, especially for concurrent systems with large codebases such as multicore operating system (OS) kernels. Refinement, which verifies that an implementation preserves certain properties of a more abstract specification, is promising for tackling such challenges. However, in terms of refinement-based verification of security properties, existing techniques are still restricted to sequential systems or lack the expressiveness needed to capture complex security policies for concurrent systems.
  In this work, we present a generalized security-preserving refinement technique, particularly for verifying the IFS of concurrent systems governed by potentially complex security policies. We formalize the IFS properties for concurrent systems and present a refinement-based compositional approach to prove that the generalized security properties (e.g., intransitive noninterference) are preserved between implementation and abstraction. The key intuition enabling such reasoning, compared to previous refinement work, is to establish a step-mapping relation between the implementation and the abstraction, which is sufficient to ensure that every paired step (in the abstraction and the implementation, respectively) is either permitted or prohibited by the security policy. We apply our approach to verify two non-trivial case studies against a collection of security policies. Our proofs are fully mechanized in Isabelle/HOL, during which we identified that two covert channels previously reported in the ARINC 653 single-core standard also exist in the ARINC 653 multicore standard. We subsequently proved the correctness of the revised mechanism, showcasing the effectiveness of our approach.

</details>


### [33] [Verifying rich robustness properties for neural networks](https://arxiv.org/abs/2511.07293)
*Mohammad Afzal,S. Akshay,Ashutosh Gupta*

Main category: cs.LO

TL;DR: 这项工作提出了通用且灵活的神经网络鲁棒性验证框架，能统一处理多种鲁棒性变体和置信度需求，不依赖繁琐编码，实验效果优于传统方法，显著提升AI安全验证能力。


<details>
  <summary>Details</summary>
Motivation: 神经网络在安全关键系统中广泛应用，对其鲁棒性（在输入扰动下决策不变性）验证尤为重要。现有方法局限于特定编码且常忽视网络输出的置信度，缺乏通用验证框架。

Method: 提出一种简单语法规范的通用框架，可以灵活描述和验证大多数已知及新的鲁棒性变体（包括输出置信度因素）。核心方法是通过在神经网络中增加几层，实现对所有鲁棒性变体的统一验证，并能直接配合任何现有验证工具，无需修改底层编码，同时保证误差有界。

Result: 在8870个基准（最大网络参数量达1.38亿）上大规模实验，成功捕捉广泛的鲁棒性变体，验证框架在效率和表现上优于传统直接编码方法，并具备广泛适用性。

Conclusion: 论文构建了灵活且通用的神经网络鲁棒性验证框架，将多个鲁棒性变体及置信度因素统一纳入验证流程，大幅提升验证效率和范围。该框架对安全关键应用的AI系统可信度提升具有重要意义。

Abstract: Robustness is a important problem in AI alignment and safety, with models such as neural networks being increasingly used in safety-critical systems. In the last decade, a large body of work has emerged on local robustness, i.e., checking if the decision of a neural network remains unchanged when the input is slightly perturbed. However, many of these approaches require specialized encoding and often ignore the confidence of a neural network on its output. In this paper, our goal is to build a generalized framework to specify and verify variants of robustness in neural network verification. We propose a specification framework using a simple grammar, which is flexible enough to capture most existing variants. This allows us to introduce new variants of robustness that take into account the confidence of the neural network in its outputs. Next, we develop a novel and powerful unified technique to verify all such variants in a homogeneous way, viz., by adding a few additional layers to the neural network. This enables us to use any state-of-the-art neural network verification tool, without having to tinker with the encoding within, while incurring an approximation error that we show is bounded. We perform an extensive experimental evaluation over a large suite of 8870 benchmarks having 138M parameters in a largest network, and show that we are able to capture a wide set of robustness variants and outperform direct encoding approaches by a significant margin.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [34] [Ming-UniAudio: Speech LLM for Joint Understanding, Generation and Editing with Unified Representation](https://arxiv.org/abs/2511.05516)
*Canxiang Yan,Chunxiang Jin,Dawei Huang,Haibing Yu,Han Peng,Hui Zhan,Jie Gao,Jing Peng,Jingdong Chen,Jun Zhou,Kaimeng Ren,Ming Yang,Mingxue Yang,Qiang Xu,Qin Zhao,Ruijie Xiong,Shaoxiong Lin,Xuezhi Wang,Yi Yuan,Yifei Wu,Yongjie Lyu,Zhengyu He,Zhihao Qiu,Zhiqiang Fang,Ziyuan Huang*

Main category: cs.CL

TL;DR: 本文提出了可统一理解、生成及编辑的语音语言模型与框架，通过创新连续分词器与统一模型，实现了领先的语音理解与生成性能，首次支持基于自由指令的语音编辑，并开源了所有方法与评测基准。


<details>
  <summary>Details</summary>
Motivation: 现有的语音模型在理解与生成任务对 token 表示的需求上存在冲突。这种表示上的不一致使得语音语言模型难以进行基于指令的自由编辑。为解决这一挑战，本文提出了一种统一语音理解、生成与编辑的框架。

Method: 本文核心方法是提出了统一的连续语音分词器 MingTok-Audio，能有效整合语义与声学特征，并据此开发了统一语音语言模型 Ming-UniAudio，实现理解与生成能力的平衡。此外，进一步训练了专用语音编辑模型 Ming-UniAudio-Edit，实现纯基于自然语言指令的语音自由编辑，无需时间戳条件，并推出了综合性基准 Ming-Freeform-Audio-Edit。

Result: Ming-UniAudio 在 ContextASR 基准上的 12 项指标中刷新 8 项 SOTA 纪录，并在中文语音克隆任务中获得 Seed-TTS-WER 0.95 的竞争性成绩。Ming-UniAudio-Edit 可实现语义与声学的指令性自由编辑，Ming-Freeform-Audio-Edit 作为首个相关基准，为未来研究提供评测基础。

Conclusion: 本文开源了连续音频分词器、统一基础模型及编辑模型，推动了统一音频理解、生成与编辑的发展，为指令为导向的语音处理任务奠定了技术与评测基础。

Abstract: Existing speech models suffer from competing requirements on token representations by understanding and generation tasks. This discrepancy in representation prevents speech language models from performing instruction-based free-form editing. To solve this challenge, we introduce a novel framework that unifies speech understanding, generation, and editing. The core of our unified model is a unified continuous speech tokenizer MingTok-Audio, the first continuous tokenizer to effectively integrate semantic and acoustic features, which makes it suitable for both understanding and generation tasks. Based on this unified continuous audio tokenizer, we developed the speech language model Ming-UniAudio, which achieved a balance between generation and understanding capabilities. Ming-UniAudio sets new state-of-the-art (SOTA) records on 8 out of 12 metrics on the ContextASR benchmark. Notably, for Chinese voice cloning, it achieves a highly competitive Seed-TTS-WER of 0.95. Leveraging this foundational model, we further trained a dedicated speech editing model Ming-UniAudio-Edit, the first speech language model that enables universal, free-form speech editing guided solely by natural language instructions, handling both semantic and acoustic modifications without timestamp condition. To rigorously assess the editing capability and establish a foundation for future research, we introduce Ming-Freeform-Audio-Edit, the first comprehensive benchmark tailored for instruction-based free-form speech editing, featuring diverse scenarios and evaluation dimensions spanning semantic correctness, acoustic quality, and instruction alignment. We open-sourced the continuous audio tokenizer, the unified foundational model, and the free-form instruction-based editing model to facilitate the development of unified audio understanding, generation, and manipulation.

</details>


### [35] [Retracing the Past: LLMs Emit Training Data When They Get Lost](https://arxiv.org/abs/2511.05518)
*Myeongseob Ko,Nikhil Reddy Billa,Adam Nguyen,Charles Fleming,Ming Jin,Ruoxi Jia*

Main category: cs.CL

TL;DR: 本文基于模型预测不确定性高点，提出CIA框架，可高效提取LLMs的训练数据，揭示主流LLMs普遍存在记忆泄漏风险，对敏感数据应用带来警示。


<details>
  <summary>Details</summary>
Motivation: 当前大模型对训练数据的记忆带来隐私和版权风险，而现有数据提取方法效果有限，且未能深入揭示记忆泄漏的关键机制。因此亟需更系统且有效的攻击与评估框架。

Method: 提出Confusion-Inducing Attacks（CIA）框架，通过优化输入序列使模型产生连续高熵状态，从而导致模型泄漏记忆内容。同时针对对齐后的LLMs，提出Mismatched Supervised Fine-tuning（SFT）方法以削弱模型对齐，提升攻击效果。

Result: 实验显示，CIA攻击在多种（对齐与非对齐）LLMs上能够更高效地提取原文或近似原文的训练数据，且无需预知训练集，性能优于现有方法。

Conclusion: 研究表明，各类LLMs都存在持续的记忆泄漏风险，通过作者提出的CIA方法可系统性地评估和挖掘这些风险，现有防护措施存在不足。

Abstract: The memorization of training data in large language models (LLMs) poses significant privacy and copyright concerns. Existing data extraction methods, particularly heuristic-based divergence attacks, often exhibit limited success and offer limited insight into the fundamental drivers of memorization leakage. This paper introduces Confusion-Inducing Attacks (CIA), a principled framework for extracting memorized data by systematically maximizing model uncertainty. We empirically demonstrate that the emission of memorized text during divergence is preceded by a sustained spike in token-level prediction entropy. CIA leverages this insight by optimizing input snippets to deliberately induce this consecutive high-entropy state. For aligned LLMs, we further propose Mismatched Supervised Fine-tuning (SFT) to simultaneously weaken their alignment and induce targeted confusion, thereby increasing susceptibility to our attacks. Experiments on various unaligned and aligned LLMs demonstrate that our proposed attacks outperform existing baselines in extracting verbatim and near-verbatim training data without requiring prior knowledge of the training data. Our findings highlight persistent memorization risks across various LLMs and offer a more systematic method for assessing these vulnerabilities.

</details>


### [36] [Beyond One-Size-Fits-All: Personalized Harmful Content Detection with In-Context Learning](https://arxiv.org/abs/2511.05532)
*Rufan Zhang,Lin Zhang,Xianghang Mi*

Main category: cs.CL

TL;DR: 该论文提出基于ICL和大模型的内容审核新框架，实现毒性、垃圾信息、负面情绪多任务统一检测。无需再训练，具备极强个性化和泛化能力，实验表现出色，已开源代码和数据。


<details>
  <summary>Details</summary>
Motivation: 当前有害内容（如毒性言论、垃圾信息、负面情绪）在网络中泛滥，传统的内容审核系统高度中心化且针对单一任务，不透明且难以适应用户多样化需求，尤其在隐私敏感或去中心化环境中问题突出。

Method: 提出了一个创新性框架，利用大模型的in-context learning（ICL）能力，将有害内容检测任务（毒性、垃圾信息、负面情绪）统一于二分类、多分类和多标签场景下。该方法通过简单的提示词配置实现轻量化个性化，无需模型再训练即可实现内容审核类别的快速添加、解除或语义扩展，只需提供少量用户样例或定义即可进行个性化设置。

Result: 在TextDetox、UCI SMS、SST2等公开数据集及新标注的Mastodon数据集上测试，结果显示：1）基础模型有很强的跨任务泛化能力，性能与或优于任务专用微调模型；2）用户个性化仅需单个用户样例或定义即可有效实现；3）提示词中补充标签定义或理由可显著提升模型对真实场景中噪声数据的鲁棒性。

Conclusion: 本工作展现了内容审核从“一刀切”向用户个性化、高适应性和隐私保护方向的转变，证明了ICL在下一代用户中心内容安全系统中的实际可行性，并已开源代码与数据集以促进后续研究。

Abstract: The proliferation of harmful online content--e.g., toxicity, spam, and negative sentiment--demands robust and adaptable moderation systems. However, prevailing moderation systems are centralized and task-specific, offering limited transparency and neglecting diverse user preferences--an approach ill-suited for privacy-sensitive or decentralized environments. We propose a novel framework that leverages in-context learning (ICL) with foundation models to unify the detection of toxicity, spam, and negative sentiment across binary, multi-class, and multi-label settings. Crucially, our approach enables lightweight personalization, allowing users to easily block new categories, unblock existing ones, or extend detection to semantic variations through simple prompt-based interventions--all without model retraining. Extensive experiments on public benchmarks (TextDetox, UCI SMS, SST2) and a new, annotated Mastodon dataset reveal that: (i) foundation models achieve strong cross-task generalization, often matching or surpassing task-specific fine-tuned models; (ii) effective personalization is achievable with as few as one user-provided example or definition; and (iii) augmenting prompts with label definitions or rationales significantly enhances robustness to noisy, real-world data. Our work demonstrates a definitive shift beyond one-size-fits-all moderation, establishing ICL as a practical, privacy-preserving, and highly adaptable pathway for the next generation of user-centric content safety systems. To foster reproducibility and facilitate future research, we publicly release our code on GitHub and the annotated Mastodon dataset on Hugging Face.

</details>


### [37] [MCP4IFC: IFC-Based Building Design Using Large Language Models](https://arxiv.org/abs/2511.05533)
*Bharathi Kannan Nithyanantham,Tobias Sesterhenn,Ashwin Nedungadi,Sergio Peral Garijo,Janis Zenkner,Christian Bartelt,Stefan Lüdtke*

Main category: cs.CL

TL;DR: 该论文提出MCP4IFC开源框架，使大语言模型可用自然语言操作BIM的IFC数据，通过查询工具、构件预设函数和RAG技术，LLM可高效完成建模与编辑任务，显著推动AI在建筑行业的实际应用与研究。


<details>
  <summary>Details</summary>
Motivation: 生成式AI已在多个领域取得进展，但架构、工程和建造（AEC）行业仍缺乏能将自然语言指令直接转换为对标准化数据模型的操作系统。该论文旨在填补这方面的技术空白，实现AI在BIM工作流中的实际应用。

Method: 提出了一个名为MCP4IFC的开源框架，允许大规模语言模型（LLMs）通过Model Context Protocol（MCP）直接操控行业基础类（IFC）数据。该框架集成了BIM工具，包括场景查询工具、用于建筑元素创建与修改的预定义函数，以及结合上下文学习和检索增强生成（RAG）的动态代码生成系统。

Result: 实验表明，使用该框架的LLM能够成功完成从建造简单房屋到查询和编辑现有IFC数据等复杂任务。作者还将框架开源，鼓励相关领域的研究与创新。

Conclusion: MCP4IFC框架为LLM在BIM设计中直接操作IFC数据提供了可行路径，推动了AI驱动的建模工作流发展。其开源性质有助于促进AEC领域AI应用研究。

Abstract: Bringing generative AI into the architecture, engineering and construction (AEC) field requires systems that can translate natural language instructions into actions on standardized data models. We present MCP4IFC, a comprehensive open-source framework that enables Large Language Models (LLMs) to directly manipulate Industry Foundation Classes (IFC) data through the Model Context Protocol (MCP). The framework provides a set of BIM tools, including scene querying tools for information retrieval, predefined functions for creating and modifying common building elements, and a dynamic code-generation system that combines in-context learning with retrieval-augmented generation (RAG) to handle tasks beyond the predefined toolset. Experiments demonstrate that an LLM using our framework can successfully perform complex tasks, from building a simple house to querying and editing existing IFC data. Our framework is released as open-source to encourage research in LLM-driven BIM design and provide a foundation for AI-assisted modeling workflows. Our code is available at https://show2instruct.github.io/mcp4ifc/.

</details>


### [38] [FlowMM: Cross-Modal Information Flow Guided KV Cache Merging for Efficient Multimodal Context Inference](https://arxiv.org/abs/2511.05534)
*Kunxi Li,Yufan Xiong,Zhonghua Jiang,Yiyun Zhou,Zhaode Wang,Chengfei Lv,Shengyu Zhang*

Main category: cs.CL

TL;DR: 提出跨模态信息流引导的KV缓存合并框架FlowMM，实现高效的KV缓存管理，大幅降低内存和延迟，同时确保多模态模型任务性能。


<details>
  <summary>Details</summary>
Motivation: 传统的基于注意力分数进行KV缓存剔除，在多模态场景下易造成上下文丢失或幻觉，新兴KV合并方法受限于模态分布偏差和交互偏差，亟需更智能的跨模态KV缓存管理策略。

Method: 提出FlowMM框架，通过跨模态信息流自适应地指导KV缓存合并，结合层级差异化策略及敏感度自适应的token匹配机制。

Result: FlowMM可使KV缓存减少80%-95%，解码延迟降低1.3-1.8倍，并在多种主流多模态大模型任务中表现出与原始方法相当的性能。

Conclusion: FlowMM在降低KV缓存内存消耗和解码延迟的同时，能够保持主流多模态大模型的任务性能。

Abstract: Traditional KV cache eviction strategies, which discard less critical KV-pairs based on attention scores, often degrade generation quality, causing context loss or hallucinations. Recent efforts shift toward KV merging, merging eviction tokens with retention tokens based on similarity. However, in multimodal scenarios, distributional biases across modality tokens and attentional biases in cross-modal interactions limit its effectiveness. This work introduces FlowMM, an adaptive framework for cross-modal information flow-guided multimodal KV cache merging. FlowMM leverages cross-modal information flow to dynamically apply layer-specific merging strategies, capturing modality-specific patterns while preserving contextual integrity. Furthermore, we introduce a sensitivity-adaptive token matching mechanism that jointly evaluates token similarity and task-critical sensitivity, merging low-risk tokens while safeguarding high-sensitivity ones. Extensive experiments across diverse leading MLLMs show that FlowMM reduces KV cache memory by 80% to 95% and decoding latency by 1.3-1.8x, while maintaining competitive task performance.

</details>


### [39] [Future of AI Models: A Computational perspective on Model collapse](https://arxiv.org/abs/2511.05535)
*Trivikram Satharasi,S Sitharama Iyengar*

Main category: cs.CL

TL;DR: 大量AI合成内容的递归训练正在导致互联网语义多样性快速收敛。根据英文维基百科的分析，语义相似度指数上升已经发生，即将威胁数据多样性和模型能力。


<details>
  <summary>Details</summary>
Motivation: 本论文关注当前AI技术，尤其是大型语言模型（LLMs）与图生成扩散模型在各行业的广泛应用，以及由此导致的大量合成内容对互联网数据结构和多样性造成的潜在影响。作者希望揭示这种高度合成内容递归训练会导致语义和语言多样性丧失，最终引发“模型坍缩”。

Method: 作者使用了Transformer模型嵌入及余弦相似度来衡量英文维基百科（抽取自Common Crawl）在2013至2025年间的语义相似度年变化。通过折年分析，量化并预测了语义收敛和“模型坍缩”风险的时点。

Result: 结果显示，在公众广泛采用LLM前，内容语义相似度稳步上升（受早期RNN/LSTM驱动），但规模较小。LLM大规模采用后，语义相似度呈指数增长。波动反映不可消除的语言多样性、年份样本量差异及有限采样误差。

Conclusion: 合成内容递归训练已开始大幅提升语义相似度，如果这种趋势继续，将显著威胁互联网数据的多样性与模型泛化能力。这项研究为AI内容污染显著影响数据丰富性的时间节点提出了数据驱动的预估。

Abstract: Artificial Intelligence, especially Large Language Models (LLMs), has transformed domains such as software engineering, journalism, creative writing, academia, and media (Naveed et al. 2025; arXiv:2307.06435). Diffusion models like Stable Diffusion generate high-quality images and videos from text. Evidence shows rapid expansion: 74.2% of newly published webpages now contain AI-generated material (Ryan Law 2025), 30-40% of the active web corpus is synthetic (Spennemann 2025; arXiv:2504.08755), 52% of U.S. adults use LLMs for writing, coding, or research (Staff 2025), and audits find AI involvement in 18% of financial complaints and 24% of press releases (Liang et al. 2025). The underlying neural architectures, including Transformers (Vaswani et al. 2023; arXiv:1706.03762), RNNs, LSTMs, GANs, and diffusion networks, depend on large, diverse, human-authored datasets (Shi & Iyengar 2019). As synthetic content dominates, recursive training risks eroding linguistic and semantic diversity, producing Model Collapse (Shumailov et al. 2024; arXiv:2307.15043; Dohmatob et al. 2024; arXiv:2402.07712). This study quantifies and forecasts collapse onset by examining year-wise semantic similarity in English-language Wikipedia (filtered Common Crawl) from 2013 to 2025 using Transformer embeddings and cosine similarity metrics. Results reveal a steady rise in similarity before public LLM adoption, likely driven by early RNN/LSTM translation and text-normalization pipelines, though modest due to a smaller scale. Observed fluctuations reflect irreducible linguistic diversity, variable corpus size across years, finite sampling error, and an exponential rise in similarity after the public adoption of LLM models. These findings provide a data-driven estimate of when recursive AI contamination may significantly threaten data richness and model generalization.

</details>


### [40] [Temporal Sparse Autoencoders: Leveraging the Sequential Nature of Language for Interpretability](https://arxiv.org/abs/2511.05541)
*Usha Bhalla,Alex Oesterling,Claudio Mayrink Verdun,Himabindu Lakkaraju,Flavio P. Calmon*

Main category: cs.CL

TL;DR: T-SAEs在无监督情境下通过时间一致性约束改进了特征学习，可以让语言模型自动分离和发现语义结构，显著提升解释性，方法简单有效。


<details>
  <summary>Details</summary>
Motivation: 当前SAE等字典学习方法虽然能发现可解释特征，但往往只捕捉到浅层、噪声或局部语言特征，未能有效揭示语言模型内部的语义结构，原因在于训练方式忽略了语言的丰富结构知识。

Method: 提出Temporal Sparse Autoencoders (T-SAEs)，在传统SAE基础上加入新型对比损失，鼓励高层特征在相邻token间保持一致激活，从而自动区分语言中的语义和句法。

Result: 在多个数据集和模型上，T-SAE能恢复更平滑、连贯的语义概念，没有牺牲重构质量，实现了语义结构的自监督分离。

Conclusion: T-SAEs无需显式语义信号即可分离语义和句法特征，为语言模型无监督可解释性开辟新路径。

Abstract: Translating the internal representations and computations of models into concepts that humans can understand is a key goal of interpretability. While recent dictionary learning methods such as Sparse Autoencoders (SAEs) provide a promising route to discover human-interpretable features, they suffer from a variety of problems, including a systematic failure to capture the rich conceptual information that drives linguistic understanding. Instead, they exhibit a bias towards shallow, token-specific, or noisy features, such as "the phrase 'The' at the start of sentences". In this work, we propose that this is due to a fundamental issue with how dictionary learning methods for LLMs are trained. Language itself has a rich, well-studied structure spanning syntax, semantics, and pragmatics; however, current unsupervised methods largely ignore this linguistic knowledge, leading to poor feature discovery that favors superficial patterns over meaningful concepts. We focus on a simple but important aspect of language: semantic content has long-range dependencies and tends to be smooth over a sequence, whereas syntactic information is much more local. Building on this insight, we introduce Temporal Sparse Autoencoders (T-SAEs), which incorporate a novel contrastive loss encouraging consistent activations of high-level features over adjacent tokens. This simple yet powerful modification enables SAEs to disentangle semantic from syntactic features in a self-supervised manner. Across multiple datasets and models, T-SAEs recover smoother, more coherent semantic concepts without sacrificing reconstruction quality. Strikingly, they exhibit clear semantic structure despite being trained without explicit semantic signal, offering a new pathway for unsupervised interpretability in language models.

</details>


### [41] [Sample-Efficient Language Modeling with Linear Attention and Lightweight Enhancements](https://arxiv.org/abs/2511.05560)
*Patrick Haller,Jonas Golde,Alan Akbik*

Main category: cs.CL

TL;DR: 本文提出了采用mLSTM和多种轻量化改进的BLaLM模型，并在BabyLM 2025任务设定下验证了有效性。主要创新包括线性注意力与滑动窗注意力，及新型Muon优化器，均显著提升了模型在低资源场景下的表现，表明小规模但高效的语言模型具有实际可行性。


<details>
  <summary>Details</summary>
Motivation: 在BabyLM 2025挑战限制下，需要开发在资源有限情况下仍能高效进行语言建模的方法和架构。现有模型依赖于大规模训练，资源消耗大，因此寻找更高效的替代方案非常重要。

Method: 提出了BLaLM模型，用mLSTM替换自注意力机制，并结合短卷积、滑动窗注意力（可动态调制）、Hedgehog特征映射等轻量化改进；同时，整理了一套高质量、强调可读性和教学结构的数据集以适应低资源设定。优化器方面，尝试了Muon以提升收敛稳定性和减少困惑度。

Result: 在STRICT和STRICT-SMALL两个评测赛道上，线性注意力与滑动窗注意力结合能稳定提升零样本任务表现；Muon优化器对于模型训练的稳定性和困惑度均优于常用的AdamW。

Conclusion: 无需大规模模型，通过轻量化架构、有效优化策略和高质量数据，可以实现高效、样本节约的语言建模。

Abstract: We study architectural and optimization techniques for sample-efficient language modeling under the constraints of the BabyLM 2025 shared task. Our model, BLaLM, replaces self-attention with a linear-time mLSTM token mixer and explores lightweight enhancements, including short convolutions, sliding window attention with dynamic modulation, and Hedgehog feature maps. To support training in low-resource settings, we curate a high-quality corpus emphasizing readability and pedagogical structure. Experiments across both STRICT and STRICT-SMALL tracks show that (1) linear attention combined with sliding window attention consistently improves zero-shot performance, and (2) the Muon optimizer stabilizes convergence and reduces perplexity over AdamW. These results highlight effective strategies for efficient language modeling without relying on scale.

</details>


### [42] [UTF-8 Plumbing: Byte-level Tokenizers Unavoidably Enable LLMs to Generate Ill-formed UTF-8](https://arxiv.org/abs/2511.05578)
*Preston Firestone,Shubham Ugare,Gagandeep Singh,Sasa Misailovic*

Main category: cs.CL

TL;DR: 本文系统性分析了基于字节子词分词器存在生成非法UTF-8序列的问题，提出理论证明并通过现实案例展示影响，警示分词器设计及模型应用需高度关注词元合法性，否则可能造成系统性Bug和兼容性隐患。


<details>
  <summary>Details</summary>
Motivation: 当前的子词分词技术使用统一词表将输入文本拆分后送入语言模型，但基于字节的分词方式可能造成分词结果不是有效的UTF-8，这会导致下游应用出错。

Method: 作者将分词过程形式化为幺半群理论，并对分词器词表中存在非合法UTF-8分词的情形进行数学证明，揭示编码转换增量处理和整体处理结果差异，同时对主流基础模型和推理服务的缓解措施及案例进行评估。

Result: 证明了只要词表包含非法UTF-8分词，就必然可以生成非法UTF-8序列；实验及案例分析验证了理论分析的实际影响，并评估了现有缓解手段。

Conclusion: 分词器设计若存在非合法UTF-8词元会实质性引入后续处理风险，系统需明确考量词元合法性及相关兼容性问题。

Abstract: Subword tokenization segments input text according to a pre-defined vocabulary to feed it into a language model; the language model, in turn, generates a sequence made from this same vocabulary. The members of the vocabulary can be built of code points or bytes. Using code points means that all members of the vocabulary are valid UTF-8 characters. However, it also requires thousands of initial members to achieve acceptable coverage of inputs. Beginning with bytes, on the contrary, avoids out-of-vocabulary errors with only 256 initial members of the vocabulary, but the members of the vocabulary and sequences of them are not guaranteed to be valid UTF-8. Sequences that are not valid UTF-8 break code that assumes its input to be valid UTF-8. Applications of language models must account for the breakage thereby introduced. In this paper, we formalize tokenization using monoid theory and prove that tokenizers whose vocabularies contain tokens that are ill-formed UTF-8 can always produce sequences that are ill-formed UTF-8. We demonstrate formally that attempting to incrementally convert tokens back to a string and interpret the results as UTF-8 gives different results than converting the whole sequence of tokens at once. This formal result predicts real-world bugs: we evaluate mitigations for the problem identified and provide case studies of major foundation models, serving engines, and constrained generation systems.

</details>


### [43] [Optimizing Diversity and Quality through Base-Aligned Model Collaboration](https://arxiv.org/abs/2511.05650)
*Yichen Wang,Chenghao Yang,Tenghao Huang,Muhao Chen,Jonathan May,Mina Lee*

Main category: cs.CL

TL;DR: BACo是一种推理阶段动态结合基础与对齐大模型的新方法，无需重训练或多次采样即可同步提升输出的多样性和质量，并实现强可控性，在多项任务和度量上显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有对齐技术虽然提升了大模型输出的质量，却导致生成结果高度相似，牺牲了多样性，亟需一种方法在不损失质量的情况下提升多样性。

Method: 提出了Base-Aligned Model Collaboration（BACo）推理阶段的token级模型协作框架，通过动态整合基础模型和对齐后的模型，基于下一个token预测的不确定性和语义角色，路由决定由哪个模型生成该token，从而优化结果的多样性与质量。

Result: 在三类开放式生成任务和13种度量标准下，BACo在多样性和质量上均超越现有最优推理方法，最佳路由器实现了21.3%的多样性与质量联合提升，且人类评价同样证明了改进。

Conclusion: 在推理阶段基础模型与对齐模型合作，可实现兼顾高多样性和高质量的生成效果，并大幅提升对生成内容的可控性。

Abstract: Alignment has greatly improved large language models (LLMs)' output quality at the cost of diversity, yielding highly similar outputs across generations. We propose Base-Aligned Model Collaboration (BACo), an inference-time token-level model collaboration framework that dynamically combines a base LLM with its aligned counterpart to optimize diversity and quality. Inspired by prior work (Fei et al., 2025), BACo employs routing strategies that determine, at each token, from which model to decode based on next-token prediction uncertainty and predicted contents' semantic role. Prior diversity-promoting methods, such as retraining, prompt engineering, and multi-sampling methods, improve diversity but often degrade quality or require costly decoding or post-training. In contrast, BACo achieves both high diversity and quality post hoc within a single pass, while offering strong controllability. We explore a family of routing strategies, across three open-ended generation tasks and 13 metrics covering diversity and quality, BACo consistently surpasses state-of-the-art inference-time baselines. With our best router, BACo achieves a 21.3% joint improvement in diversity and quality. Human evaluations also mirror these improvements. The results suggest that collaboration between base and aligned models can optimize and control diversity and quality.

</details>


### [44] [OckBench: Measuring the Efficiency of LLM Reasoning](https://arxiv.org/abs/2511.05722)
*Zheng Du,Hao Kang,Song Han,Tushar Krishna,Ligeng Zhu*

Main category: cs.CL

TL;DR: OckBench提出并验证了大模型评估不仅要看准确率，还应关注token生成效率。研究表明，模型在token消耗上的差异显著，忽视效率不利于模型实际应用。OckBench为业界和学术界提供了一个准确率与效率并重的新基准测试平台。


<details>
  <summary>Details</summary>
Motivation: 当前大模型评测主要关注准确率和输出质量，忽略了实际应用中token生成数量对延迟、成本及能耗的显著影响。作者希望建立一个可同时衡量准确率和token效率的统一标准，从而推动模型高效性的发展。

Method: 提出了OckBench，这是一个与模型和硬件无关的基准测试，能评估模型在推理和代码任务中的准确率及token消耗。通过对多种开源和闭源大模型进行实验比较，分析了准确率与token效率的关系。

Result: 实验发现：许多准确率接近的模型在token消耗上差异很大，token效率成为忽视但重要的能力。作者展示了准确率-效率的帕累托前沿，证明了效率考量的必要性。OckBench成为评估和引导高效推理模型研究的新平台。

Conclusion: OckBench揭示了在推理和代码生成任务中，模型的准确率和生成token效率同样重要。很多模型准确率相近，但token消耗却存在巨大差异，因此应重视token效率作为模型评价的关键维度。作者提出不应再把token当作“免费资源”看待，倡导新的评估范式。

Abstract: Large language models such as GPT-4, Claude 3, and the Gemini series have improved automated reasoning and code generation. However, existing benchmarks mainly focus on accuracy and output quality, and they ignore an important factor: decoding token efficiency. In real systems, generating 10,000 tokens versus 100,000 tokens leads to large differences in latency, cost, and energy. In this work, we introduce OckBench, a model-agnostic and hardware-agnostic benchmark that evaluates both accuracy and token count for reasoning and coding tasks. Through experiments comparing multiple open- and closed-source models, we uncover that many models with comparable accuracy differ wildly in token consumption, revealing that efficiency variance is a neglected but significant axis of differentiation. We further demonstrate Pareto frontiers over the accuracy-efficiency plane and argue for an evaluation paradigm shift: we should no longer treat tokens as "free" to multiply. OckBench provides a unified platform for measuring, comparing, and guiding research in token-efficient reasoning. Our benchmarks are available at https://ockbench.github.io/ .

</details>


### [45] [In-Context Learning Without Copying](https://arxiv.org/abs/2511.05743)
*Kerem Sahin,Sheridan Feucht,Adam Belfki,Jannik Brinkmann,Aaron Mueller,David Bau,Chris Wendler*

Main category: cs.CL

TL;DR: 归纳头不是抽象上下文学习的必要前提，即便大幅减少归纳复制，模型在各种ICL任务上的表现依然优异甚至更好。


<details>
  <summary>Details</summary>
Motivation: 过去研究认为，在Transformer模型中归纳复制（inductive copying）由归纳头（induction heads）实现，是更复杂的上下文学习（ICL）能力的前提。本文质疑这种归纳复制是否真的是必要的。

Method: 提出“Hapax”方法：在训练中，对于可以由归纳头正确预测的token，其损失不计入训练目标，显著减少归纳复制现象。然后对比Hapax训练模型和常规模型在各种抽象ICL任务上的表现，并分析归纳头发展情况。

Result: 尽管归纳复制能力显著下降，Hapax模型在13/21个抽象ICL任务上的表现与标准模型相当甚至更优，而且在无法被归纳头复制的位置上有更低的损失。同时，Hapax模型具有更少且更弱的归纳头，但仍保留上下文学习能力。

Conclusion: 归纳复制（inductive copying）不是学习抽象上下文学习（ICL）机制的必要条件。即使抑制归纳复制，Transformer模型仍能发展复杂的抽象ICL能力。

Abstract: Induction heads are attention heads that perform inductive copying by matching patterns from earlier context and copying their continuations verbatim. As models develop induction heads, they often experience a sharp drop in training loss, a phenomenon cited as evidence that induction heads may serve as a prerequisite for more complex in-context learning (ICL) capabilities. In this work, we ask whether transformers can still acquire ICL capabilities when inductive copying is suppressed. We propose Hapax, a setting where we omit the loss contribution of any token that can be correctly predicted by induction heads. Despite a significant reduction in inductive copying, performance on abstractive ICL tasks (i.e., tasks where the answer is not contained in the input context) remains comparable and surpasses the vanilla model on 13 of 21 tasks, even though 31.7\% of tokens are omitted from the loss. Furthermore, our model achieves lower loss values on token positions that cannot be predicted correctly by induction heads. Mechanistic analysis further shows that models trained with Hapax develop fewer and weaker induction heads but still preserve ICL capabilities. Taken together, our findings indicate that inductive copying is not essential for learning abstractive ICL mechanisms.

</details>


### [46] [Multi-Scale Feature Fusion and Graph Neural Network Integration for Text Classification with Large Language Models](https://arxiv.org/abs/2511.05752)
*Xiangchen Song,Yulin Huang,Jinxu Guo,Yuchen Liu,Yaxuan Luan*

Main category: cs.CL

TL;DR: 结合大语言模型、特征金字塔和图神经网络的新型文本分类方法，在多个主流评价指标上超越现有模型，实现了更强的复杂语义建模能力和分类性能。


<details>
  <summary>Details</summary>
Motivation: 文本分类任务中，复杂语义环境下如何有效获取和融合全局与局部特征，并捕捉结构化语义关系，以提升分类性能，是当前研究的挑战。

Method: 本文提出了一种混合方法，将大语言模型用于深层特征提取，通过特征金字塔实现多尺度特征融合，再利用图神经网络建模结构化语义关系，最后通过分类模块输出文本类别。

Result: 所提出方法在鲁棒性一致性实验中，在准确率、F1分数、AUC、精确率等指标上均优于现有模型，展示了其有效性和稳定性。

Conclusion: 该方法构建了一个兼顾全局与局部、语义与结构的信息整合框架，为多尺度特征融合及结构化语义建模提供了新视角，有望推动文本分类任务的发展。

Abstract: This study investigates a hybrid method for text classification that integrates deep feature extraction from large language models, multi-scale fusion through feature pyramids, and structured modeling with graph neural networks to enhance performance in complex semantic contexts. First, the large language model captures contextual dependencies and deep semantic representations of the input text, providing a rich feature foundation for subsequent modeling. Then, based on multi-level feature representations, the feature pyramid mechanism effectively integrates semantic features of different scales, balancing global information and local details to construct hierarchical semantic expressions. Furthermore, the fused features are transformed into graph representations, and graph neural networks are employed to capture latent semantic relations and logical dependencies in the text, enabling comprehensive modeling of complex interactions among semantic units. On this basis, the readout and classification modules generate the final category predictions. The proposed method demonstrates significant advantages in robustness alignment experiments, outperforming existing models on ACC, F1-Score, AUC, and Precision, which verifies the effectiveness and stability of the framework. This study not only constructs an integrated framework that balances global and local information as well as semantics and structure, but also provides a new perspective for multi-scale feature fusion and structured semantic modeling in text classification tasks.

</details>


### [47] [Language Generation: Complexity Barriers and Implications for Learning](https://arxiv.org/abs/2511.05759)
*Marcelo Arenas,Pablo Barceló,Luis Cofré,Alexander Kozachinskiy*

Main category: cs.CL

TL;DR: 虽然理论证明语言生成可行，但成功生成需要的例子数量在实际中可能极大，实践中现代语言模型高效性的解释需更细致地考虑自然语言的结构特性。


<details>
  <summary>Details</summary>
Motivation: 前人证明了只要有足够多正例，学习者可以无限接近目标语言，但该理论未讨论实际可行性。本文旨在分析在实际已知语言家族中生成目标语言所需例子的实际需求，评估理论与实践间的鸿沟。

Method: 分析正则语言和上下文无关语言等简单语言家族，通过理论推导，评估实际成功生成所需示例数量的下界。

Result: 发现即使对于已经被充分研究的语言家族，所需的例子数目可能极大，甚至不可通过任何可计算函数进行界定。这显示了理论可生成性与实际高效学习之间的巨大分歧。

Conclusion: 理论上，语言生成总是可能的，但要成功生成所需的正例数量在实际中可能极大，甚至无法通过任一可计算函数界定。理论的可能性与高效的可学习性之间存在巨大差距。

Abstract: Kleinberg and Mullainathan showed that, in principle, language generation is always possible: with sufficiently many positive examples, a learner can eventually produce sentences indistinguishable from those of a target language. However, the existence of such a guarantee does not speak to its practical feasibility. In this work, we show that even for simple and well-studied language families -- such as regular and context-free languages -- the number of examples required for successful generation can be extraordinarily large, and in some cases not bounded by any computable function. These results reveal a substantial gap between theoretical possibility and efficient learnability. They suggest that explaining the empirical success of modern language models requires a refined perspective -- one that takes into account structural properties of natural language that make effective generation possible in practice.

</details>


### [48] [DRAGON: Guard LLM Unlearning in Context via Negative Detection and Reasoning](https://arxiv.org/abs/2511.05784)
*Yaxuan Wang,Chris Yuhao Liu,Quan Liu,Jinglong Pang,Wei Wei,Yujia Bao,Yang Liu*

Main category: cs.CL

TL;DR: 本文提出了DRAGON方法，无需保留数据即可高效实现LLM的遗忘功能，通过检测与链式推理干预提升模型安全性，并设计了新的评估指标，实验验证了其实用价值。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）遗忘方法大多依赖微调，需同时获取保留（retain）和遗忘（forget）数据，而实际场景下保留数据经常缺失，传统方法难以有效应对数据受限的现实需求。

Method: 提出了Detect-Reasoning Augmented GeneratiON（DRAGON）框架，通过上下文中的链式推理指令（CoT instructions）来保护LLM免遭不良知识触发。该方法不需修改现有模型，利用LLM的指令跟随能力，并增设检测模块来识别需要遗忘的提示（prompts），对于这些提示，通过专门的CoT guard模型进行干预，无需保留数据。

Result: DRAGON框架在三个代表性遗忘任务上进行了大量实验，结果显示该方法在无需保留数据的前提下，有效提升了LLM遗忘能力、可扩展性及实际应用适应性。同时，论文提出了用于持续性遗忘的新评估指标，增强了评测的全面性和实用性。

Conclusion: DRAGON是一种无需保留数据的、高效可推广的大语言模型遗忘框架，它强化了模型在实际数据有限情况下的敏感知识遗忘能力，对LLM安全和隐私保护有重要意义。

Abstract: Unlearning in Large Language Models (LLMs) is crucial for protecting private data and removing harmful knowledge. Most existing approaches rely on fine-tuning to balance unlearning efficiency with general language capabilities. However, these methods typically require training or access to retain data, which is often unavailable in real world scenarios. Although these methods can perform well when both forget and retain data are available, few works have demonstrated equivalent capability in more practical, data-limited scenarios. To overcome these limitations, we propose Detect-Reasoning Augmented GeneratiON (DRAGON), a systematic, reasoning-based framework that utilizes in-context chain-of-thought (CoT) instructions to guard deployed LLMs before inference. Instead of modifying the base model, DRAGON leverages the inherent instruction-following ability of LLMs and introduces a lightweight detection module to identify forget-worthy prompts without any retain data. These are then routed through a dedicated CoT guard model to enforce safe and accurate in-context intervention. To robustly evaluate unlearning performance, we introduce novel metrics for unlearning performance and the continual unlearning setting. Extensive experiments across three representative unlearning tasks validate the effectiveness of DRAGON, demonstrating its strong unlearning capability, scalability, and applicability in practical scenarios.

</details>


### [49] [Quantifying Edits Decay in Fine-tuned LLMs](https://arxiv.org/abs/2511.05852)
*Yinjie Cheng,Paul Youssef,Christin Seifert,Jörg Schlötterer,Zhixue Zhao*

Main category: cs.CL

TL;DR: 知识编辑后的模型再进行微调，编辑内容通常会受影响而衰减，具体程度因方法和微调方式而异。针对编辑安全性和有效性，作者提出了可操作方案，并建议评估模型编辑时要结合实际应用全流程。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在应用中常常需要纠正或注入特定知识，知识编辑（KE）作为一种轻量方法被广泛研究，但与微调（fine-tuning）通常各自独立进行。一个关键问题是：在知识编辑后再微调，编辑内容能否被保留？此问题关乎实际应用中移除恶意编辑和保留有益编辑的可行性与安全性。

Method: 该研究系统地量化了知识编辑在微调后的衰减情况，评估了两种主流知识编辑方法（MEMIT、AlphaEdit）与三种微调方法（全参数、LoRA、DoRA），分别在五个大语言模型与三个数据集上做了232种实验配置。并提出选择性层微调方法，只微调被编辑的层或非编辑层。

Result: 结果发现，知识编辑一般在微调后会发生衰减，不同方法生存率不同，如AlphaEdit的衰减比MEMIT更明显。选择性层微调可有效移除编辑，且只微调非编辑层时比全参数微调衰减更大，但会略微影响下游任务性能。

Conclusion: 研究建立了知识编辑与微调结合的实证基线与实施策略，强调在评估大语言模型编辑效果时需考虑完整的应用流程。

Abstract: Knowledge editing has emerged as a lightweight alternative to retraining for correcting or injecting specific facts in large language models (LLMs). Meanwhile, fine-tuning remains the default operation for adapting LLMs to new domains and tasks. Despite their widespread adoption, these two post-training interventions have been studied in isolation, leaving open a crucial question: if we fine-tune an edited model, do the edits survive? This question is motivated by two practical scenarios: removing covert or malicious edits, and preserving beneficial edits. If fine-tuning impairs edits as shown in Figure 1, current KE methods become less useful, as every fine-tuned model would require re-editing, which significantly increases the cost; if edits persist, fine-tuned models risk propagating hidden malicious edits, raising serious safety concerns. To this end, we systematically quantify edits decay after fine-tuning, investigating how fine-tuning affects knowledge editing. We evaluate two state-of-the-art editing methods (MEMIT, AlphaEdit) and three fine-tuning approaches (full-parameter, LoRA, DoRA) across five LLMs and three datasets, yielding 232 experimental configurations. Our results show that edits decay after fine-tuning, with survival varying across configurations, e.g., AlphaEdit edits decay more than MEMIT edits. Further, we propose selective-layer fine-tuning and find that fine-tuning edited layers only can effectively remove edits, though at a slight cost to downstream performance. Surprisingly, fine-tuning non-edited layers impairs more edits than full fine-tuning. Overall, our study establishes empirical baselines and actionable strategies for integrating knowledge editing with fine-tuning, and underscores that evaluating model editing requires considering the full LLM application pipeline.

</details>


### [50] [Retrieval-Augmented Generation in Medicine: A Scoping Review of Technical Implementations, Clinical Applications, and Ethical Considerations](https://arxiv.org/abs/2511.05901)
*Rui Yang,Matthew Yu Heng Wong,Huitao Li,Xin Li,Wentao Zhu,Jingchi Liao,Kunyu Yu,Jonathan Chong Kai Liew,Weihao Xuan,Yingjian Chen,Yuhe Ke,Jasmine Chiat Ling Ong,Douglas Teodoro,Chuan Hong,Daniel Shi Wei Ting,Nan Liu*

Main category: cs.CL

TL;DR: 本文综述了RAG技术在医学领域的应用，发现大多依赖公开数据且评估注意力偏重传统指标，实际临床应用和医学专属技术尚不足，未来亟需实现临床有效性、语言多样性及低资源环境适配。


<details>
  <summary>Details</summary>
Motivation: 医学知识的快速增长和临床实践的复杂性提出了新的挑战，需要更有效的信息处理方法。大语言模型在医学领域展现了价值，但仍存在局限，RAG技术有望提升其临床应用性。

Method: 本文对医学领域中RAG技术的相关应用进行了综述研究，分析了数据来源、检索和生成方法、评价指标以及应用场景。

Result: 现有研究主要依赖公开数据，医疗专属私有数据的应用有限。英文向量模型为主流，医学专用LLM利用较少。自动指标用于评估生成质量及任务表现，人工评估关注准确性、完整性、相关性和流畅性，但对偏见和安全性关注不足。RAG应用集中于医学问答、报告生成、文本摘要及信息抽取。

Conclusion: 医学领域RAG技术仍处于早期，需要推进临床验证、跨语言适配及低资源场景支持，以实现全球范围内可信且负责任的应用。

Abstract: The rapid growth of medical knowledge and increasing complexity of clinical practice pose challenges. In this context, large language models (LLMs) have demonstrated value; however, inherent limitations remain. Retrieval-augmented generation (RAG) technologies show potential to enhance their clinical applicability. This study reviewed RAG applications in medicine. We found that research primarily relied on publicly available data, with limited application in private data. For retrieval, approaches commonly relied on English-centric embedding models, while LLMs were mostly generic, with limited use of medical-specific LLMs. For evaluation, automated metrics evaluated generation quality and task performance, whereas human evaluation focused on accuracy, completeness, relevance, and fluency, with insufficient attention to bias and safety. RAG applications were concentrated on question answering, report generation, text summarization, and information extraction. Overall, medical RAG remains at an early stage, requiring advances in clinical validation, cross-linguistic adaptation, and support for low-resource settings to enable trustworthy and responsible global use.

</details>


### [51] [NILC: Discovering New Intents with LLM-assisted Clustering](https://arxiv.org/abs/2511.05913)
*Hongtao Wang,Renchi Yang,Wenqing Lin*

Main category: cs.CL

TL;DR: 本文提出的NILC框架结合大语言模型对聚类中心和难样本优化，在多领域数据集上超越主流NID方法。


<details>
  <summary>Details</summary>
Motivation: NID（新意图发现）在实际对话系统中非常重要，现有方法采用级联架构，存在各阶段无法互相优化、聚类仅依赖嵌入导致语义捕捉能力弱等问题，因此性能不佳。

Method: 提出了NILC聚类框架，采用迭代流程，通过大语言模型（LLM）辅助，精细化聚类中心及难判文本嵌入。具体包括：利用LLM生成语义聚类中心，丰富原有嵌入语境；针对难判语句，通过LLM改写增强样本；在半监督场景下，通过种子和软约束连接注入监督信号。

Result: 在六个不同领域的基准数据集上，NILC在无监督和半监督两种设置下均显著优于近期主流方法。

Conclusion: NILC有效提升了新意图发现任务中的聚类表现，解决了嵌入聚类语义不够丰富、难样本处理不到位等问题，通过LLM与新聚类技术配合取得了显著性能提升。

Abstract: New intent discovery (NID) seeks to recognize both new and known intents from unlabeled user utterances, which finds prevalent use in practical dialogue systems. Existing works towards NID mainly adopt a cascaded architecture, wherein the first stage focuses on encoding the utterances into informative text embeddings beforehand, while the latter is to group similar embeddings into clusters (i.e., intents), typically by K-Means. However, such a cascaded pipeline fails to leverage the feedback from both steps for mutual refinement, and, meanwhile, the embedding-only clustering overlooks nuanced textual semantics, leading to suboptimal performance. To bridge this gap, this paper proposes NILC, a novel clustering framework specially catered for effective NID. Particularly, NILC follows an iterative workflow, in which clustering assignments are judiciously updated by carefully refining cluster centroids and text embeddings of uncertain utterances with the aid of large language models (LLMs). Specifically, NILC first taps into LLMs to create additional semantic centroids for clusters, thereby enriching the contextual semantics of the Euclidean centroids of embeddings. Moreover, LLMs are then harnessed to augment hard samples (ambiguous or terse utterances) identified from clusters via rewriting for subsequent cluster correction. Further, we inject supervision signals through non-trivial techniques seeding and soft must links for more accurate NID in the semi-supervised setting. Extensive experiments comparing NILC against multiple recent baselines under both unsupervised and semi-supervised settings showcase that NILC can achieve significant performance improvements over six benchmark datasets of diverse domains consistently.

</details>


### [52] [IDALC: A Semi-Supervised Framework for Intent Detection and Active Learning based Correction](https://arxiv.org/abs/2511.05921)
*Ankan Mullick,Sukannya Purkayastha,Saransh Sharma,Pawan Goyal,Niloy Ganguly*

Main category: cs.CL

TL;DR: 本文提出的IDALC框架大幅降低了对人工标注的依赖，同时提升了语音对话系统对用户意图的检测和修正能力，实验效果显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 语音对话系统虽然广受欢迎，但在面对系统低置信度或新意图时，常常需要大量人工标注和再训练，长期来看难以承受高昂的标注成本。如何有效减少人工标注，却又能及时提升和扩展系统意图识别能力，是当前亟需解决的问题。

Method: 本文提出了一种名为IDALC（基于意图检测与主动学习的修正）半监督框架。其核心思路是在尽量少依赖人工标注的前提下，结合主动学习策略和意图检测技术自动识别并修正系统拒绝的语句。

Result: 在多组基准数据集上的实验证明，IDALC系统的准确率比基线方法提升了5-10%，宏平均F1提升4-8%，同时整体标注成本仅占未标注数据的6-10%。

Conclusion: IDALC显著减少了人工标注量的同时，可以更高效地提升语音对话系统对新意图和低置信度语句的识别、修正能力，具有很好的实际应用前景。

Abstract: Voice-controlled dialog systems have become immensely popular due to their ability to perform a wide range of actions in response to diverse user queries. These agents possess a predefined set of skills or intents to fulfill specific user tasks. But every system has its own limitations. There are instances where, even for known intents, if any model exhibits low confidence, it results in rejection of utterances that necessitate manual annotation. Additionally, as time progresses, there may be a need to retrain these agents with new intents from the system-rejected queries to carry out additional tasks. Labeling all these emerging intents and rejected utterances over time is impractical, thus calling for an efficient mechanism to reduce annotation costs. In this paper, we introduce IDALC (Intent Detection and Active Learning based Correction), a semi-supervised framework designed to detect user intents and rectify system-rejected utterances while minimizing the need for human annotation. Empirical findings on various benchmark datasets demonstrate that our system surpasses baseline methods, achieving a 5-10% higher accuracy and a 4-8% improvement in macro-F1. Remarkably, we maintain the overall annotation cost at just 6-10% of the unlabelled data available to the system. The overall framework of IDALC is shown in Fig. 1

</details>


### [53] [Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs](https://arxiv.org/abs/2511.05933)
*Renfei Zhang,Manasa Kaniselvan,Niloofar Mireshghallah*

Main category: cs.CL

TL;DR: 本文发现强化学习提升了语言模型对结构化知识的检索与程序性导航能力，而非削弱记忆性知识。通过分析模型输出和内部激活，作者指出RL专注于优化模型知识检索方式，而不是改变知识本身的表征。结构化提示能让SFT模型部分追赶RL模型，但RL仍在深层检索和路径还原方面更胜一筹。


<details>
  <summary>Details</summary>
Motivation: 以往研究认为，通过强化学习（RL）提升语言模型的推理和泛化能力会损害模型的记忆性知识。但本文质疑该观点，关注RL对模型知识检索能力的实际影响，特别是在结构化、分层知识领域。

Method: 对比RL增强模型与基础模型及有监督微调（SFT）模型在纯知识检索任务上的表现（如医疗编码），并通过结构化提示让SFT模型显式进行分层检索。分析模型层次激活，比较知识表述与查询表述的向量类似性。

Result: RL增强模型在结构化知识检索任务上优于基础和SFT模型。结构化提示能显著缩小SFT与RL模型的性能差距，但RL模型在深层检索任务中对检索路径的回忆能力更强。内部激活分析显示，RL模型在如何检索知识（而非知识本身的表征）方面发生主要变化。

Conclusion: RL并未损害模型记忆的知识，而是增强了模型对现有知识架构的检索和程序性探索能力。这种能力提升不是因为获得了新知识，而是改进了已有知识的使用方式。

Abstract: Reinforcement learning (RL) is often credited with improving language model reasoning and generalization at the expense of degrading memorized knowledge. We challenge this narrative by observing that RL-enhanced models consistently outperform their base and supervised fine-tuned (SFT) counterparts on pure knowledge recall tasks, particularly those requiring traversal of hierarchical, structured knowledge (e.g., medical codes). We hypothesize these gains stem not from newly acquired data, but from improved procedural skills in navigating and searching existing knowledge hierarchies within the model parameters. To support this hypothesis, we show that structured prompting, which explicitly guides SFTed models through hierarchical traversal, recovers most of the performance gap (reducing 24pp to 7pp on MedConceptsQA for DeepSeek-V3/R1). We further find that while prompting improves final-answer accuracy, RL-enhanced models retain superior ability to recall correct procedural paths on deep-retrieval tasks. Finally our layer-wise internal activation analysis reveals that while factual representations (e.g., activations for the statement "code 57.95 refers to urinary infection") maintain high cosine similarity between SFT and RL models, query representations (e.g., "what is code 57.95") diverge noticeably, indicating that RL primarily transforms how models traverse knowledge rather than the knowledge representation itself.

</details>


### [54] [Interpretable Recognition of Cognitive Distortions in Natural Language Texts](https://arxiv.org/abs/2511.05969)
*Anton Kolonin,Anna Arinicheva*

Main category: cs.CL

TL;DR: 提出了一种基于加权结构化N-gram的新多因素文本分类方法，有效识别心理认知偏差，性能优于现有方法，已公开代码和模型。


<details>
  <summary>Details</summary>
Motivation: 自动化检测心理认知偏差有重要社会意义，现有方法在准确性和可解释性方面存在不足，亟需新的高效方法。

Method: 采用加权结构化N-gram方法，结合异层级关系，并设计了新的识别和学习算法，在两个公开数据集上进行实验。

Result: 该论文提出了一种新的自然语言文本多因素分类方法，基于加权结构化模式（如N-gram），并考虑了其间的异层级关系。此方法应用于自动检测心理护理中的特定认知偏差，依赖于可解释、健壮且透明的人工智能模型。作者设计了新的识别和学习算法，并在两个公开数据集上进行测试，与现有文献相比，F1分数显著提升，同时公开了代码和模型以供社区未来使用。

Conclusion: 实验结果显示，提出的方法在心理认知偏差自动检测任务上优于当前最佳方法，且模型具有较高的可解释性和透明度。

Abstract: We propose a new approach to multi-factor classification of natural language texts based on weighted structured patterns such as N-grams, taking into account the heterarchical relationships between them, applied to solve such a socially impactful problem as the automation of detection of specific cognitive distortions in psychological care, relying on an interpretable, robust and transparent artificial intelligence model. The proposed recognition and learning algorithms improve the current state of the art in this field. The improvement is tested on two publicly available datasets, with significant improvements over literature-known F1 scores for the task, with optimal hyper-parameters determined, having code and models available for future use by the community.

</details>


### [55] [Revisiting Entropy in Reinforcement Learning for Large Reasoning Models](https://arxiv.org/abs/2511.05993)
*Renren Jin,Pengzhi Gao,Yuqi Ren,Zhuowen Han,Tongxuan Zhang,Wuwei Huang,Wei Liu,Jian Luan,Deyi Xiong*

Main category: cs.CL

TL;DR: 该论文分析了RLVR训练下大语言模型的熵动态，发现off-policy更新、训练数据多样性及损失剪切阈值显著影响熵，正优势token是导致熵崩塌的关键。通过调整损失权重可有效调控熵，为提升大模型性能和多样性提供新思路。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）在使用基于可验证奖励的强化学习（RLVR）进行训练时，模型的熵往往迅速下降，导致模型早早收敛到欠佳的局部最优状态，进一步提升模型性能变得困难。尽管已有一些方法试图缓解熵崩塌的问题，但对于RLVR过程中熵变化的系统性研究仍然缺乏。该论文的动机即是填补这一研究空白。

Method: 作者设计了大量实验，系统分析了使用RLVR训练的大语言模型在不同条件下模型熵的动态变化，并研究熵与响应多样性、校准及性能之间的相关性。此外，理论分析和实证对比了不同训练参数如off-policy更新次数、训练数据多样性、目标函数中剪切阈值等因素对模型熵的具体影响，并进一步关注正优势token在熵崩塌中的作用，通过调整正负优势token的损失权重来调控模型熵。

Result: 研究发现：off-policy更新次数、训练数据多样性、损失函数中的剪切阈值是影响RLVR训练后模型熵的关键因素。理论和实验结果均表明，拥有正优势的token是导致熵崩塌的主要贡献者，且通过调整这些token和负优势token在损失函数中的权重，可以有效实现对模型熵的调节。

Conclusion: 论文系统揭示了RLVR大模型训练中熵动态变化的过程及其影响因素，并提出了一种通过调整正负优势token损失权重优化熵、提升模型泛化能力和响应多样性的有效方法。为后续RLVR领域的优化和应用提供了理论指导和实践参考。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has emerged as a predominant approach for enhancing the reasoning capabilities of large language models (LLMs). However, the entropy of LLMs usually collapses during RLVR training, causing premature convergence to suboptimal local minima and hinder further performance improvement. Although various approaches have been proposed to mitigate entropy collapse, a comprehensive study of entropy in RLVR remains lacking. To address this gap, we conduct extensive experiments to investigate the entropy dynamics of LLMs trained with RLVR and analyze how model entropy correlates with response diversity, calibration, and performance across various benchmarks. Our findings reveal that the number of off-policy updates, the diversity of training data, and the clipping thresholds in the optimization objective are critical factors influencing the entropy of LLMs trained with RLVR. Moreover, we theoretically and empirically demonstrate that tokens with positive advantages are the primary contributors to entropy collapse, and that model entropy can be effectively regulated by adjusting the relative loss weights of tokens with positive and negative advantages during training.

</details>


### [56] [LLMs Do Not See Age: Assessing Demographic Bias in Automated Systematic Review Synthesis](https://arxiv.org/abs/2511.06000)
*Favour Yahdii Aghaebe,Tanefa Apekey,Elizabeth Williams,Nafise Sadat Moosavi*

Main category: cs.CL

TL;DR: 本研究发现，主流语言模型在生成生物医学研究年龄相关摘要方面存在人口统计信息丢失和偏差问题，尤其是在成人组表现最差，对弱势或代表性不足人群更易产生幻觉。这一现象提示亟需针对公平性的评估和优化方案。


<details>
  <summary>Details</summary>
Motivation: 临床干预通常依赖于年龄因素，不同年龄段的患者面临药物和治疗方法的安全性挑战。随着语言模型在生物医学证据综合工作流程中的应用，尚不清楚这些系统是否能够保留关键的人口统计学区分（如年龄信息）。本文旨在评估最新语言模型在生成生物医学研究摘要时对年龄相关信息的保持能力。

Method: 作者构建了一个新颖的年龄分层系统综述原始研究数据集DemogSummary，覆盖儿童、成人和老年人群。针对Qwen、Longformer和GPT-4.1 Nano三个主流有摘要能力的大模型，采用标准评价指标及新提出的人口统计显著性评分（Demographic Salience Score, DSS），量化模型对年龄实体的保留和幻觉。

Result: 研究结果显示，三个模型在不同年龄群体下呈现出系统性差异：基于成人的摘要在人口统计保真度方面最低，且在信息贫乏的年龄群体（如老年人和儿童）更易产生信息幻觉。

Conclusion: 当前大语言模型在准确、无偏见地生成生物医学摘要时在保留关键人口统计信息方面存在明显局限性，亟需开发更加关注公平性的评价框架和总结流程。

Abstract: Clinical interventions often hinge on age: medications and procedures safe for adults may be harmful to children or ineffective for older adults. However, as language models are increasingly integrated into biomedical evidence synthesis workflows, it remains uncertain whether these systems preserve such crucial demographic distinctions. To address this gap, we evaluate how well state-of-the-art language models retain age-related information when generating abstractive summaries of biomedical studies. We construct DemogSummary, a novel age-stratified dataset of systematic review primary studies, covering child, adult, and older adult populations. We evaluate three prominent summarisation-capable LLMs, Qwen (open-source), Longformer (open-source) and GPT-4.1 Nano (proprietary), using both standard metrics and a newly proposed Demographic Salience Score (DSS), which quantifies age-related entity retention and hallucination. Our results reveal systematic disparities across models and age groups: demographic fidelity is lowest for adult-focused summaries, and under-represented populations are more prone to hallucinations. These findings highlight the limitations of current LLMs in faithful and bias-free summarisation and point to the need for fairness-aware evaluation frameworks and summarisation pipelines in biomedical NLP.

</details>


### [57] [Multi-Reward GRPO Fine-Tuning for De-biasing Large Language Models: A Study Based on Chinese-Context Discrimination Data](https://arxiv.org/abs/2511.06023)
*Deng Yixuan,Ji Xiaoqiang*

Main category: cs.CL

TL;DR: 本文提出GRPO多奖励优化框架，结合多维公平性奖励信号，有效减少LLM文化语境下多维歧视偏见，保障模型流畅性与信息性，对LLM伦理对齐问题提供新思路。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）虽然通过最新的对齐技术（如RLHF和DPO）缓解了部分偏见问题，但在处理具有文化特殊性、多维度的歧视方面仍有局限性。

Method: 提出了一种多奖励组相对策略优化（GRPO）框架：首先构建以中文语境歧视类别为基础的英文数据集，包括地域、族群及职业偏见；用中性与带偏见的回应对每个实例进行配对，训练以DeBERTa-v3为基础的奖励模型，该模型同时考虑公平性、中立性和语言质量等多维度奖励信号，指导GRPO进行模型微调。

Result: 实验显示，通过多维度奖励信号指导微调，不影响流畅性和信息丰富性前提下，有效降低了模型偏见强度，提升了其与非歧视标准的符合度。

Conclusion: GRPO多奖励优化机制在LLM去偏见方面效果显著，为模型实现文化和语境相关的伦理对齐提供了可复现的新方法。

Abstract: Large Language Models (LLMs) often exhibit implicit biases and discriminatory tendencies that reflect underlying social stereotypes. While recent alignment techniques such as RLHF and DPO have mitigated some of these issues, they remain limited in addressing culturally specific and multi-dimensional forms of discrimination. This paper proposes a Multi-Reward Group Relative Policy Optimization (GRPO) framework to fine-tune LLMs toward ethical and bias-free behavior. Our approach constructs a synthetic English-language dataset derived from Chinese-context discrimination categories, including regional, ethnic, and occupational biases. Each instance is paired with both neutral and biased responses to train a reward model based on DeBERTa-v3, which provides multi-dimensional reward signals capturing fairness, neutrality, and linguistic quality. The trained reward model then guides GRPO fine-tuning to optimize model outputs along these ethical dimensions. Experimental results demonstrate significant reductions in bias intensity and improved alignment with non-discriminatory standards without compromising fluency or informativeness. This study highlights the effectiveness of GRPO-based multi-reward optimization for de-biasing LLMs and offers a replicable framework for cultural-contextual ethical alignment.

</details>


### [58] [Visual Exploration of Feature Relationships in Sparse Autoencoders with Curated Concepts](https://arxiv.org/abs/2511.06048)
*Xinyuan Yan,Shusen Liu,Kowshik Thopalli,Bei Wang*

Main category: cs.CL

TL;DR: 本文提出专注概念的混合可视化系统，改善SAE特征的探索与分析，提升可解释性与效率。


<details>
  <summary>Details</summary>
Motivation: 针对稀疏自动编码器在大语言模型中学习到的特征数量众多，传统降维或嵌入工具存在压缩伪影、邻域失真等问题，难以高效和准确地探索全部特征，需开发更聚焦和可解释的分析体系。

Method: 作者开发了一个混合可视化框架，结合拓扑学方法和传统降维技术，面向特定概念和特征集进行针对性展示分析，而不是对所有特征整体冗余地可视化。

Result: 系统能有效支持用户从局部和全局角度分析选定特征间的关系，提高对SAE特征、概念表示的理解深度与分析效率。

Conclusion: 本文提出了一种互动可视化系统，将拓扑可视化编码与降维方法结合，用于分析稀疏自动编码器（SAE）在大语言模型中的特征表现。该系统优先展示经过策划的概念和相关SAE特征，可更好地揭示局部和全局特征关系。

Abstract: Sparse autoencoders (SAEs) have emerged as a powerful tool for uncovering interpretable features in large language models (LLMs) through the sparse directions they learn. However, the sheer number of extracted directions makes comprehensive exploration intractable. While conventional embedding techniques such as UMAP can reveal global structure, they suffer from limitations including high-dimensional compression artifacts, overplotting, and misleading neighborhood distortions. In this work, we propose a focused exploration framework that prioritizes curated concepts and their corresponding SAE features over attempts to visualize all available features simultaneously. We present an interactive visualization system that combines topology-based visual encoding with dimensionality reduction to faithfully represent both local and global relationships among selected features. This hybrid approach enables users to investigate SAE behavior through targeted, interpretable subsets, facilitating deeper and more nuanced analysis of concept representation in latent space.

</details>


### [59] [Efficient Hate Speech Detection: A Three-Layer LoRA-Tuned BERTweet Framework](https://arxiv.org/abs/2511.06051)
*Mahmoud El-Bahnasawi*

Main category: cs.CL

TL;DR: 该文提出三层高效仇恨言论检测系统，以极低参数和训练时间实现接近大模型的性能，兼顾易用性、实时性和准确率，适合实际应用。


<details>
  <summary>Details</summary>
Motivation: 开发能够实时部署、在算力有限环境下依然表现优异的仇恨言论检测系统，以应对大模型算力消耗大、不适合实际应用的挑战。

Method: 提出三层架构：首先利用基于规则的预筛查；然后引入低参数量、通过LoRA微调的BERTweet模型；同时支持持续学习能力。通过数据集整合与优化微调提升整体性能。

Result: 系统在使用远小于主流大模型参数量（134M对比14B）的情况下，实现了0.85的macro F1分数，达到SafePhi（一种Phi-4大模型）94%的性能，并且较同参数级别的BERT基线方法表现更优。训练仅需1.87M可训练参数、2小时（T4），适合低资源环境。

Conclusion: 提出的方法在极大降低计算资源需求的前提下，保持了与大规模模型相近的检测准确率，适合实际部署，可推广至资源受限环境中。

Abstract: This paper addresses the critical challenge of developing computationally efficient hate speech detection systems that maintain competitive performance while being practical for real-time deployment. We propose a novel three-layer framework that combines rule-based pre-filtering with a parameter-efficient LoRA-tuned BERTweet model and continuous learning capabilities. Our approach achieves 0.85 macro F1 score - representing 94% of the performance of state-of-the-art large language models like SafePhi (Phi-4 based) while using a base model that is 100x smaller (134M vs 14B parameters). Compared to traditional BERT-based approaches with similar computational requirements, our method demonstrates superior performance through strategic dataset unification and optimized fine-tuning. The system requires only 1.87M trainable parameters (1.37% of full fine-tuning) and trains in approximately 2 hours on a single T4 GPU, making robust hate speech detection accessible in resource-constrained environments while maintaining competitive accuracy for real-world deployment.

</details>


### [60] [ReMoD: Rethinking Modality Contribution in Multimodal Stance Detection via Dual Reasoning](https://arxiv.org/abs/2511.06057)
*Bingbing Wang,Zhengda Jin,Bin Liang,Jing Li,Ruifeng Xu*

Main category: cs.CL

TL;DR: ReMoD通过模拟人类认知的双过程机制，动态权衡多模态立场信息，取得了优异实验效果，提升了多模态立场检测的准确率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态立场检测仅粗糙融合各模态，忽略不同模态表达立场的差异性，可能引入误判噪声。该工作旨在更加细致地利用不同模态信息，提升立场识别的准确性。

Method: 参考人类认知的双过程理论，ReMoD采用经验驱动的直觉推理和审慎的反思性推理两阶段，分别利用Modality Experience Pool和Semantic Experience Pool动态调整各模态对立场表达的贡献。

Result: ReMoD在MMSD公开基准数据集实验中，明显超过大多数主流方法，并展现良好的泛化能力。

Conclusion: 提出的ReMoD框架能更有效地处理多模态立场检测任务，并在公开基准上显著优于现有方法，展现了较强的泛化能力。

Abstract: Multimodal Stance Detection (MSD) is a crucial task for understanding public opinion on social media. Existing work simply fuses information from various modalities to learn stance representations, overlooking the varying contributions of stance expression from different modalities. Therefore, stance misunderstanding noises may be drawn into the stance learning process due to the risk of learning errors by rough modality combination. To address this, we get inspiration from the dual-process theory of human cognition and propose **ReMoD**, a framework that **Re**thinks **Mo**dality contribution of stance expression through a **D**ual-reasoning paradigm. ReMoD integrates *experience-driven intuitive reasoning* to capture initial stance cues with *deliberate reflective reasoning* to adjust for modality biases, refine stance judgments, and thereby dynamically weight modality contributions based on their actual expressive power for the target stance. Specifically, the intuitive stage queries the Modality Experience Pool (MEP) and Semantic Experience Pool (SEP) to form an initial stance hypothesis, prioritizing historically impactful modalities. This hypothesis is then refined in the reflective stage via two reasoning chains: Modality-CoT updates MEP with adaptive fusion strategies to amplify relevant modalities, while Semantic-CoT refines SEP with deeper contextual insights of stance semantics. These dual experience structures are continuously refined during training and recalled at inference to guide robust and context-aware stance decisions. Extensive experiments on the public MMSD benchmark demonstrate that our ReMoD significantly outperforms most baseline models and exhibits strong generalization capabilities.

</details>


### [61] [Automating Hardware Design and Verification from Architectural Papers via a Neural-Symbolic Graph Framework](https://arxiv.org/abs/2511.06067)
*Haoyue Yang,Xuanle Zhao,Yujie Liu,Zhuojun Zou,Kailin Lyu,Changchun Zhou,Yao Zhu,Jie Hao*

Main category: cs.CL

TL;DR: 该论文提出了ArchCraft框架，能将学术论文中的硬件架构描述自动转换为可验证的Verilog项目，并提出了ArchSynthBench基准用于评估。实验表明该方法在理解论文和生成代码方面优于现有方法，生成的RTL代码可符合性能和时序要求。


<details>
  <summary>Details</summary>
Motivation: 当前学术论文中的硬件架构复现面临极大挑战，主要由于缺少公开源码以及硬件描述语言的复杂性，严重影响了学术成果复现与对比。

Method: 提出ArchCraft框架，通过将不结构化的学术论文架构描述转换为形式化的架构蓝图（使用图结构描述）和功能规范（符号定义），并自动生成Verilog代码与测试平台，实现RTL级验证。框架能自动报告电路的功耗、面积和性能。还提出了首个综合硬件架构描述的基准集ArchSynthBench，包含全面评估指标和大量电路。

Result: ArchCraft在ArchSynthBench上系统评估，实验结果显示在论文理解和代码生成方面优于直接生成方法及VerilogCoder框架。自动生成的RTL代码符合时序约束，性能指标与原论文报告一致。

Conclusion: ArchCraft显著提升了学术论文中硬件架构的可复现性与自动化实现能力，推动了硬件设计研究的工程化进程。

Abstract: The reproduction of hardware architectures from academic papers remains a significant challenge due to the lack of publicly available source code and the complexity of hardware description languages (HDLs). To this end, we propose \textbf{ArchCraft}, a Framework that converts abstract architectural descriptions from academic papers into synthesizable Verilog projects with register-transfer level (RTL) verification. ArchCraft introduces a structured workflow, which uses formal graphs to capture the Architectural Blueprint and symbols to define the Functional Specification, translating unstructured academic papers into verifiable, hardware-aware designs. The framework then generates RTL and testbench (TB) code decoupled via these symbols to facilitate verification and debugging, ultimately reporting the circuit's Power, Area, and Performance (PPA). Moreover, we propose the first benchmark, \textbf{ArchSynthBench}, for synthesizing hardware from architectural descriptions, with a complete set of evaluation indicators, 50 project-level circuits, and around 600 circuit blocks. We systematically assess ArchCraft on ArchSynthBench, where the experiment results demonstrate the superiority of our proposed method, surpassing direct generation methods and the VerilogCoder framework in both paper understanding and code completion. Furthermore, evaluation and physical implementation of the generated executable RTL code show that these implementations meet all timing constraints without violations, and their performance metrics are consistent with those reported in the original papers.

</details>


### [62] [Stemming Hallucination in Language Models Using a Licensing Oracle](https://arxiv.org/abs/2511.06073)
*Simeon Emanuilov,Richard Ackermann*

Main category: cs.CL

TL;DR: 本文提出将结构化知识验证嵌入语言模型生成流程，有效消除事实幻觉，比现有统计方法更具可靠性和确定性。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型（LM）在自然语言生成方面表现出色，但容易出现幻觉，生成事实错误的信息。论文旨在解决语言模型幻觉的问题。

Method: 提出了一种新架构——Licensing Oracle，通过对生成内容与结构化知识图谱进行形式验证，嵌入确定性验证环节，强制生成内容满足事实约束。并与现有方法（基础模型、事实召回微调、弃答微调、检索增强生成RAG）进行对比实验。

Result: Licensing Oracle能够实现完美的弃答精度（AP=1.0）和零错误答案（FAR-NE=0.0），仅生成有效主张，并且在事实响应准确率上达到89.1%。相较于现有统计方法，能彻底消除幻觉。

Conclusion: 结构创新（如Licensing Oracle）在基于结构化知识的领域针对幻觉问题提供了充分且必要的解决方案，保证了语言模型输出的可靠性，为未来受真理约束的生成模型奠定了基础。

Abstract: Language models exhibit remarkable natural language generation capabilities but remain prone to hallucinations, generating factually incorrect information despite producing syntactically coherent responses. This study introduces the Licensing Oracle, an architectural solution designed to stem hallucinations in LMs by enforcing truth constraints through formal validation against structured knowledge graphs. Unlike statistical approaches that rely on data scaling or fine-tuning, the Licensing Oracle embeds a deterministic validation step into the model's generative process, ensuring that only factually accurate claims are made. We evaluated the effectiveness of the Licensing Oracle through experiments comparing it with several state-of-the-art methods, including baseline language model generation, fine-tuning for factual recall, fine-tuning for abstention behavior, and retrieval-augmented generation (RAG). Our results demonstrate that although RAG and fine-tuning improve performance, they fail to eliminate hallucinations. In contrast, the Licensing Oracle achieved perfect abstention precision (AP = 1.0) and zero false answers (FAR-NE = 0.0), ensuring that only valid claims were generated with 89.1% accuracy in factual responses. This work shows that architectural innovations, such as the Licensing Oracle, offer a necessary and sufficient solution for hallucinations in domains with structured knowledge representations, offering guarantees that statistical methods cannot match. Although the Licensing Oracle is specifically designed to address hallucinations in fact-based domains, its framework lays the groundwork for truth-constrained generation in future AI systems, providing a new path toward reliable, epistemically grounded models.

</details>


### [63] [MuonAll: Muon Variant for Efficient Finetuning of Large Language Models](https://arxiv.org/abs/2511.06086)
*Saurabh Page,Advait Joshi,S. S. Sonawane*

Main category: cs.CL

TL;DR: 作者提出了MuonAll优化器，将所有参数纳入，广泛测试发现其与现有主流优化器AdamW表现持平，是一个有效的替代方案，并开源了相关实现。


<details>
  <summary>Details</summary>
Motivation: Muon优化器在语言模型预训练中表现优异，但其在现有公开预训练模型微调中的表现还未被充分研究。过去Muon常与AdamW共同使用，尚有改进潜力（即将所有参数均纳入Muon优化器）。

Method: 作者提出了一种新方法MuonAll，通过将参数变为2D矩阵，将所有参数纳入Muon优化器内。在多种公开语言模型（最大参数量达五亿）的微调任务上进行广泛实验。

Result: Muon和MuonAll在主流基准测试上的表现与AdamW相当，证明了其作为替代优化器的有效性。

Conclusion: MuonAll方法能有效整合所有参数，且Muon家族优化器可作为AdamW的有效替代品，表现稳健。两种分布式实现也对外开源。

Abstract: Muon optimizer has demonstrated robust results in pretraining of language models but its performance in finetuning of existing public pretrained models is not yet explored. Currently, Muon is used along with AdamW introducing a scope of improvement for adopting all parameters inside Muon. We introduce MuonAll, which incorporates all the parameters inside Muon by transforming into 2D matrices. We conduct extensive finetuning experiments across publicly available language models with model sizes upto half billion parameters. Muon and MuonAll perform at par with AdamW across major benchmarks, highlighting their effectiveness as alternative optimizers. We open-source the distributed implementations of Muon and MuonAll, available at https://github.com/Saurabh750/optimizer

</details>


### [64] [Evaluation of retrieval-based QA on QUEST-LOFT](https://arxiv.org/abs/2511.06125)
*Nathan Scales,Nathanael Schärli,Olivier Bousquet*

Main category: cs.CL

TL;DR: 论文分析了RAG和长上下文模型在复杂问答场景的局限，通过人类评测和结构化推理优化证明RAG可显著提升性能，优于长上下文方法。


<details>
  <summary>Details</summary>
Motivation: RAG在学术界和工业界非常流行用于基于事实的问答，但面对信息分布于多文档或需要复杂推理的问题时，现有RAG表现不佳。近期LOFT研究也发现基于长上下文语言模型的方案同样存在此极限，尤其在QUEST基准上的差距较大。

Method: 本文详细分析导致在QUEST-LOFT表现不佳的原因，通过人类评估提供了更准确的性能数据，并探索如何结合结构化输出和推理证据（可选的答案重新验证）来优化RAG，使其显著优于长上下文模型。

Result: 根据更新的人类评估数据和实验，优化后的RAG（结合结构化输出和推理证据）在复杂问答场景下显著优于长上下文模型。

Conclusion: RAG方法通过合理优化和结构化推理输出，可明显提升多文档和复杂推理问题上的问答准确性，超过长上下文模型方式。

Abstract: Despite the popularity of retrieval-augmented generation (RAG) as a solution for grounded QA in both academia and industry, current RAG methods struggle with questions where the necessary information is distributed across many documents or where retrieval needs to be combined with complex reasoning. Recently, the LOFT study has shown that this limitation also applies to approaches based on long-context language models, with the QUEST benchmark exhibiting particularly large headroom. In this paper, we provide an in-depth analysis of the factors contributing to the poor performance on QUEST-LOFT, publish updated numbers based on a thorough human evaluation, and demonstrate that RAG can be optimized to significantly outperform long-context approaches when combined with a structured output format containing reasoning and evidence, optionally followed by answer re-verification.

</details>
