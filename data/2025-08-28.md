<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 9]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.CL](#cs.CL) [Total: 59]
- [cs.DM](#cs.DM) [Total: 1]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Stack Trace-Based Crash Deduplication with Transformer Adaptation](https://arxiv.org/abs/2508.19449)
*Md Afif Al Mamun,Gias Uddin,Lan Xia,Longyu Zhang*

Main category: cs.SE

TL;DR: 本文提出并验证了一种基于Transformer的堆栈跟踪崩溃去重方法dedupT，能更准确地识别和归并重复报告，显著减少开发者人工筛查负担，在多项指标上均超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动化崩溃报告系统产生大量重复报告，导致问题跟踪系统超负荷，并增加开发者负担。现有的基于堆栈跟踪的去重方法，如字符串相似性、规则或深度学习，往往无法捕捉堆栈跟踪中的上下文和结构关系。

Method: 提出了dedupT，这是一种基于Transformer的去重方法。dedupT将预训练语言模型（PLM）适配到堆栈跟踪，然后利用其嵌入训练全连接网络(FCN)用于重复崩溃排名。重点在于整体建模堆栈跟踪，而非单独处理每帧。

Result: 在真实数据集上的大量实验表明，dedupT在重复排名和唯一崩溃检测上都优于现有的深度学习和传统方法。与最佳DL基线相比，dedupT在MRR上提高超过15%，与传统方法相比提升至多9%；在检测唯一崩溃报告的ROC-AUC指标上也更高。

Conclusion: dedupT有效整合了现代NLP技术到软件工程中，为基于堆栈跟踪的崩溃去重提供了高效解决方案。

Abstract: Automated crash reporting systems generate large volumes of duplicate
reports, overwhelming issue-tracking systems and increasing developer workload.
Traditional stack trace-based deduplication methods, relying on string
similarity, rule-based heuristics, or deep learning (DL) models, often fail to
capture the contextual and structural relationships within stack traces. We
propose dedupT, a transformer-based approach that models stack traces
holistically rather than as isolated frames. dedupT first adapts a pretrained
language model (PLM) to stack traces, then uses its embeddings to train a
fully-connected network (FCN) to rank duplicate crashes effectively. Extensive
experiments on real-world datasets show that dedupT outperforms existing DL and
traditional methods (e.g., sequence alignment and information retrieval
techniques) in both duplicate ranking and unique crash detection, significantly
reducing manual triage effort. On four public datasets, dedupT improves Mean
Reciprocal Rank (MRR) often by over 15% compared to the best DL baseline and up
to 9% over traditional methods while achieving higher Receiver Operating
Characteristic Area Under the Curve (ROC-AUC) in detecting unique crash
reports. Our work advances the integration of modern natural language
processing (NLP) techniques into software engineering, providing an effective
solution for stack trace-based crash deduplication.

</details>


### [2] [Functional Consistency of LLM Code Embeddings: A Self-Evolving Data Synthesis Framework for Benchmarking](https://arxiv.org/abs/2508.19558)
*Zhuohao Li,Wenqing Chen,Jianxing Yu,Zhichao Lu*

Main category: cs.SE

TL;DR: 本文提出了一套功能导向的代码数据合成方法，显著增强了嵌入模型在理解代码功能语义上的能力，为代码分析相关任务提供了更健壮的模型和数据基准。


<details>
  <summary>Details</summary>
Motivation: 现有的嵌入模型在文本任务中表现良好，但它们能否捕捉代码的功能语义尚不明确。现有研究多偏重语法相似性，忽略了代码的功能一致性，因此亟需方法来衡量和提升代码嵌入对功能的理解。

Method: 提出了一种功能导向的代码自进化数据合成框架。该框架定义了四类语义与语法的代码类型，从单一代码实例生成四种不同变体，丰富了代码示例的多样性，更好反映功能差异，并构建更具挑战性的基准测试集。

Result: 在代码克隆检测、代码功能一致性识别和代码检索三个下游任务上进行广泛实验，结果显示嵌入模型在该新合成数据集上训练后性能显著提升。

Conclusion: 所提出的数据合成框架能够有效提升嵌入模型对代码功能语义的理解和泛化能力，为代码表示与分析领域带来新的方法基础。

Abstract: Embedding models have demonstrated strong performance in tasks like
clustering, retrieval, and feature extraction while offering computational
advantages over generative models and cross-encoders. Benchmarks such as MTEB
have shown that text embeddings from large language models (LLMs) capture rich
semantic information, but their ability to reflect code-level functional
semantics remains unclear. Existing studies largely focus on code clone
detection, which emphasizes syntactic similarity and overlooks functional
understanding. In this paper, we focus on the functional consistency of LLM
code embeddings, which determines if two code snippets perform the same
function regardless of syntactic differences. We propose a novel data synthesis
framework called Functionality-Oriented Code Self-Evolution to construct
diverse and challenging benchmarks. Specifically, we define code examples
across four semantic and syntactic categories and find that existing datasets
predominantly capture syntactic properties. Our framework generates four unique
variations from a single code instance, providing a broader spectrum of code
examples that better reflect functional differences. Extensive experiments on
three downstream tasks-code clone detection, code functional consistency
identification, and code retrieval-demonstrate that embedding models
significantly improve their performance when trained on our evolved datasets.
These results highlight the effectiveness and generalization of our data
synthesis framework, advancing the functional understanding of code.

</details>


### [3] [The Influence of Code Comments on the Perceived Helpfulness of Stack Overflow Posts](https://arxiv.org/abs/2508.19610)
*Kathrin Figl,Maria Kirchner,Sebastian Baltes,Michael Felderer*

Main category: cs.SE

TL;DR: 本研究通过在线实验发现，无论是块注释还是行内注释都能提升 Stack Overflow 代码片段的感知帮助性，特别是新手更偏好块注释，而答案评分和位置影响较小。这一发现对社区平台及 AI 编程工具的内容优化均有指导价值。


<details>
  <summary>Details</summary>
Motivation: 许多开发者在 Stack Overflow 等问答平台查找和共享代码，但代码复用不当会导致 bug 或安全问题。因此，研究代码注释对开发者感知答案帮助性的影响，以及其在 AI 时代的意义，很有必要。

Method: 研究设计为在线实验，模拟 Stack Overflow 环境，招募了91名参与者，比较带块注释、行内注释和无注释的代码片段在感知帮助性上的差异，同时考察答案排列位置和评分等表层因素的影响。

Result: 结果显示：带块注释和行内注释的代码片段显著比无注释代码更被认为有帮助；新手用户更偏好块注释；答案的位置和得分等表层特征影响较小。

Conclusion: 代码注释能显著提升开发者对答案的感知帮助性，特别是新手更倾向于块注释。结果对于 Stack Overflow 这样的社区平台和基于代码语料的 AI 编程助手（如 Copilot）均有指导意义。通过了解影响感知帮助性的特征，有望优化社区内容展示和 AI 代码生成策略。

Abstract: Question-and-answer platforms such as Stack Overflow have become an important
way for software developers to share and retrieve knowledge. However, reusing
poorly understood code can lead to serious problems, such as bugs or security
vulnerabilities. To better understand how code comments affect the perceived
helpfulness of Stack Overflow answers, we conducted an online experiment
simulating a Stack Overflow environment (n=91). The results indicate that both
block and inline comments are perceived as significantly more helpful than
uncommented source code. Moreover, novices rated code snippets with block
comments as more helpful than those with inline comments. Interestingly, other
surface features, such as the position of an answer and its answer score, were
considered less important. The content of Stack Overflow has been a major
source for training large language models. AI-based coding assistants such as
GitHub Copilot, which are based on these models, might change the way Stack
Overflow is used. However, our findings have implications beyond this specific
platform. First, they may help to improve the relevance of community-driven
platforms such as Stack Overflow, which provide human advice and explanations
of code solutions, complementing AI-based support for software developers.
Second, since chat-based AI tools can be prompted to generate code in different
ways, knowing which properties influence perceived helpfulness might lead to
targeted prompting strategies to generate more readable code snippets.

</details>


### [4] [Leveraging LLMs for Automated Translation of Legacy Code: A Case Study on PL/SQL to Java Transformation](https://arxiv.org/abs/2508.19663)
*Lola Solovyeva,Eduardo Carneiro Oliveira,Shiyu Fan,Alper Tuncay,Shamil Gareev,Andrea Capiluppi*

Main category: cs.SE

TL;DR: 本研究探索利用大语言模型（LLMs）将遗留PL/SQL代码自动转换为Java，并结合链式引导与多例提示策略，有效提升翻译代码的语法和功能正确性，为大规模系统现代化提供了可行方向，但受限于样本规模和测试资源。


<details>
  <summary>Details</summary>
Motivation: VT遗留系统由约250万行PL/SQL代码构成，缺乏一致的文档和自动化测试，给重构和现代化带来了极大挑战。作者旨在探索利用大型语言模型（LLMs）辅助将PL/SQL代码转换为Java，以助力系统升级。

Method: 使用一个包含10组PL/SQL到Java的代码对和15个Java类的数据集，建立了领域模型，并评估了多种LLMs。提出了结合chain-of-guidance推理与n-shot提示的定制化提示策略，用于引导LLMs生成代码。

Result: 采用定制化提示策略的方法能有效引导LLMs生成语法正确并实现功能正确的Java翻译代码。

Conclusion: 虽然由于可用样本量和测试用例有限，该方法的验证受限，但初步结果为未来大规模自动化现代化遗留系统提供了理论基础。

Abstract: The VT legacy system, comprising approximately 2.5 million lines of PL/SQL
code, lacks consistent documentation and automated tests, posing significant
challenges for refactoring and modernisation. This study investigates the
feasibility of leveraging large language models (LLMs) to assist in translating
PL/SQL code into Java for the modernised "VTF3" system. By leveraging a dataset
comprising 10 PL/SQL-to-Java code pairs and 15 Java classes, which collectively
established a domain model for the translated files, multiple LLMs were
evaluated. Furthermore, we propose a customized prompting strategy that
integrates chain-of-guidance reasoning with $n$-shot prompting. Our findings
indicate that this methodology effectively guides LLMs in generating
syntactically accurate translations while also achieving functional
correctness. However, the findings are limited by the small sample size of
available code files and the restricted access to test cases used for
validating the correctness of the generated code. Nevertheless, these findings
lay the groundwork for scalable, automated solutions in modernising large
legacy systems.

</details>


### [5] [Enabling Content Management Systems as an Information Source in Model-driven Projects](https://arxiv.org/abs/2508.19797)
*Joan Giner-Miguelez,Abel Gómez,Jordi Cabot*

Main category: cs.SE

TL;DR: 这篇论文提出了自动化集成无头内容管理系统的模型框架，能够自动发现CMS信息结构并生成跨平台中间件，显著简化了CMS集成流程，促进了信息系统的标准化和自动化。


<details>
  <summary>Details</summary>
Motivation: 现有的内容管理系统（CMS）已经进化为无头CMS，主要通过REST API为其他应用提供内容，扩大了其应用场景。但对于高度定制的CMS，信息发现和管理仍依赖耗时且易出错的人工方式，缺乏自动化工具。

Method: 提出了一种基于模型的框架，能够自动发现并显式表示CMS背后的信息架构。该框架帮助设计CMS与其他信息消费组件的交互方式，并自动生成作为中间件库的交互逻辑，支持所有客户端应用跨平台访问CMS。

Result: 该框架可以自动发现CMS的信息模型，并生成中间件，显著简化了无头CMS在软件开发流程中的集成。整个框架为开源项目，已在线发布。

Conclusion: 所提框架解决了无头CMS集成过程中信息发现和管理的难题，提高了自动化程度和集成效率，为多平台和多应用信息系统提供了标准化解决方案。

Abstract: Content Management Systems (CMSs) are the most popular tool when it comes to
create and publish content across the web. Recently, CMSs have evolved,
becoming \emph{headless}. Content served by a \emph{headless CMS} aims to be
consumed by other applications and services through REST APIs rather than by
human users through a web browser. This evolution has enabled CMSs to become a
notorious source of content to be used in a variety of contexts beyond pure web
navigation. As such, CMS have become an important component of many information
systems. Unfortunately, we still lack the tools to properly discover and manage
the information stored in a CMS, often highly customized to the needs of a
specific domain. Currently, this is mostly a time-consuming and error-prone
manual process.
  In this paper, we propose a model-based framework to facilitate the
integration of headless CMSs in software development processes. Our framework
is able to discover and explicitly represent the information schema behind the
CMS. This facilitates designing the interaction between the CMS model and other
components consuming that information. These interactions are then generated as
part of a middleware library that offers platform-agnostic access to the CMS to
all the client applications. The complete framework is open-source and
available online.

</details>


### [6] [Towards a fundamental theory of modeling discrete systems](https://arxiv.org/abs/2508.19803)
*Peter Fettke,Wolfgang Reisig*

Main category: cs.SE

TL;DR: 本文分析了数字时代建模面临的挑战，提出了Heraklit建模框架，并展望了未来的研究重点。


<details>
  <summary>Details</summary>
Motivation: 现有的建模理论无法满足数字时代的需求，需要新的基本理论来应对其挑战。

Method: 文献综述与理论推导，提出了Heraklit建模框架作为新的方法。

Result: 介绍了Heraklit建模框架，并指出未来研究方向，包括模型正确性和信息及不变性的处理。

Conclusion: 提出了一种新的建模方法——Heraklit建模框架，并强调了未来需要关注建模的正确性、信息的定义以及建模中的不变性。

Abstract: Modeling is a central concern in both science and engineering. However, we
need a new fundamental theory to address the challenges of the digital age. In
this paper, we first explain why modeling is fundamental and which challenges
must be addressed in the digital world. As a main contribution, we introduce
the Heraklit modeling framework as a new approach to modeling. We conclude with
some general remarks. Future work will involve the correctness of modeling, the
notion of information, and the description of invariance in modeling.

</details>


### [7] [On the Future of Software Reuse in the Era of AI Native Software Engineering](https://arxiv.org/abs/2508.19834)
*Antero Taivalsaari,Tommi Mikkonen,Cesare Pautasso*

Main category: cs.SE

TL;DR: 本文讨论了AI驱动下生成式软件复用带来的影响和问题，提出相关研究议题，强调需警惕AI生成代码的潜在风险和开发模式变化。


<details>
  <summary>Details</summary>
Motivation: 软件开发正在经历范式转变，人工智能和生成式软件复用在软件创建中愈发重要。传统的有机开发和偶发复用逐步被“AI原生”方法取代，开发者越来越信任由AI生成的代码。

Method: 本文分析了AI辅助生成式软件复用的影响，提出关键问题，并制定了研究议程以应对相关核心问题。

Result: 研究揭示AI辅助的复用与“货物崇拜式开发”在本质上有相似之处，强调需关注AI生成代码带来的挑战及风险。

Conclusion: AI驱动生成式复用改变了开发范式，带来新机遇同时也伴随诸多值得深入研究的隐患和问题。

Abstract: Software development is currently under a paradigm shift in which artificial
intelligence and generative software reuse are taking the center stage in
software creation. Earlier opportunistic software reuse practices and organic
software development methods are rapidly being replaced by "AI Native"
approaches in which developers place their trust on code that has been
generated by artificial intelligence. This is leading to a new form of software
reuse that is conceptually not all that different from cargo cult development.
In this paper we discuss the implications of AI-assisted generative software
reuse, bring forth relevant questions, and define a research agenda for
tackling the central issues associated with this emerging approach.

</details>


### [8] [Generative AI for Testing of Autonomous Driving Systems: A Survey](https://arxiv.org/abs/2508.19882)
*Qunying Song,He Ye,Mark Harman,Federica Sarro*

Main category: cs.SE

TL;DR: 本文综述生成式AI在自动驾驶系统测试中的应用，分析六大领域、评估方法与局限，为未来测试手段和研究方向提供参考。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统（ADS）在安全性和功能验证方面面临巨大挑战，需要在多样化驾驶条件下进行广泛测试以确保可靠性。针对高效测试的需求，探索新方法是领域开放性问题。

Method: 系统分析了91篇相关研究论文，并对其在ADS测试中的应用进行了归纳总结，形成了六大主要应用类别。主要以场景驱动测试为核心，同时归纳现有的评估数据集、模拟器、系统、指标和基准测试，并评估了这些方法的有效性。

Result: 系统性综述了生成式AI在ADS测试中的应用，目前主要集中在基于场景的检测方法，并总结出27项主要局限性，梳理了现有工具和评估手段。

Conclusion: 生成式AI在自动驾驶系统测试中展现出巨大潜力，能提升测试多样性与效率，但仍需解决诸多技术和评估挑战。本文为领域研究者提供了全面的现状分析与未来研究方向指引。

Abstract: Autonomous driving systems (ADS) have been an active area of research, with
the potential to deliver significant benefits to society. However, before
large-scale deployment on public roads, extensive testing is necessary to
validate their functionality and safety under diverse driving conditions.
Therefore, different testing approaches are required, and achieving effective
and efficient testing of ADS remains an open challenge. Recently, generative AI
has emerged as a powerful tool across many domains, and it is increasingly
being applied to ADS testing due to its ability to interpret context, reason
about complex tasks, and generate diverse outputs. To gain a deeper
understanding of its role in ADS testing, we systematically analyzed 91
relevant studies and synthesized their findings into six major application
categories, primarily centered on scenario-based testing of ADS. We also
reviewed their effectiveness and compiled a wide range of datasets, simulators,
ADS, metrics, and benchmarks used for evaluation, while identifying 27
limitations. This survey provides an overview and practical insights into the
use of generative AI for testing ADS, highlights existing challenges, and
outlines directions for future research in this rapidly evolving field.

</details>


### [9] [Smart Contract Intent Detection with Pre-trained Programming Language Model](https://arxiv.org/abs/2508.20086)
*Youwei Huang,Jianwen Li,Sen Fang,Yao Li,Peng Yang,Bin Hu,Tao Zhang*

Main category: cs.SE

TL;DR: 论文提出了升级版的智能合约意图检测模型SmartIntentNN2，引入BERT预训练模型并结合BiLSTM，实现了更高的检测准确率（F1 = 0.927），显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 智能合约开发中的恶意意图可能造成重大经济损失，因此亟需高效准确的方法自动检测智能合约中的不安全意图。

Method: 该方法在原有的SmartIntentNN模型基础上，引入了以BERT为核心的预训练语言模型，专门对16,000个真实智能合约进行Masked Language Modeling训练，并结合BiLSTM多标签分类网络实现意图检测。

Result: SmartIntentNN2在十种不同意图类别的检测任务中，F1得分从0.8633提升至0.927，优于上一代模型，性能大幅提升。

Conclusion: SmartIntentNN2（智能合约意图神经网络V2）通过集成预训练BERT模型和保持BiLSTM多标签分类网络，显著提升了对智能合约意图检测的性能，F1得分达到0.927，成为该领域的最新最优方法。

Abstract: Malicious intent in smart contract development can lead to substantial
economic losses. SmartIntentNN is a deep learning model specifically designed
to identify unsafe intents in smart contracts. This model integrates the
Universal Sentence Encoder, a K-means clustering-based intent highlighting
mechanism, and a Bidirectional Long Short-Term Memory network for multi-label
classification, achieving an F1 of 0.8633 in distinguishing ten different
intent categories. In this study, we present an upgraded version of this model,
SmartIntentNN2 (Smart Contract Intent Neural Network V2). A significant
enhancement in V2 is the incorporation of a BERT-based pre-trained language
model, which has been trained on a dataset of 16,000 real smart contracts using
a Masked Language Modeling objective. SmartIntentNN2 retains the BiLSTM-based
multi-label classification network. With an improved F1 of 0.927, V2
demonstrates enhanced performance compared to its predecessor, establishing
itself as the state-of-the-art model for smart contract intent detection.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [10] [The Power of Regular Constraint Propagation (Technical Report)](https://arxiv.org/abs/2508.19888)
*Matthew Hague,Artur Jeż,Anthony W. Lin,Oliver Markgraf,Philipp Rümmer*

Main category: cs.LO

TL;DR: 本文提出并实现了一种简单通用的字符串约束求解方法——正则约束传播（RCP），不仅在理论上对大量可判定片段具备完备性，且在实际基准测试中大幅提升OSTRICH求解器性能，尤其优于同类工具，展示出广泛的应用前景。


<details>
  <summary>Details</summary>
Motivation: 现有的字符串求解器采用的求解策略较为复杂，因此作者们想探索一种更简单、通用的字符串约束求解方法。

Method: 提出并实施了正则约束传播（RCP）方法，通过对正则语言在字符串函数下的前/后像进行反复计算，逐步推断字符串变量可能取值，直到发现冲突或得出公式满足性结论。该方法适用包括串联、替换等多种字符串操作。

Result: 正则约束传播理论上对大量字符串约束片段（包括两种最具表现力的可判定片段）具有完备性与正确性；实际实验中，在OSTRICH字符串求解器中实现该方法，性能显著提升，尤其在随机PCP与生物信息学基准测试上远超其他求解器。

Conclusion: 正则约束传播是一种通用且有效的字符串约束求解方法，不仅可以提升现有求解器性能，且在多类型字符串约束问题下都具备理论与工程上的优势。

Abstract: The past decade has witnessed substantial developments in string solving.
Motivated by the complexity of string solving strategies adopted in existing
string solvers, we investigate a simple and generic method for solving string
constraints: regular constraint propagation. The method repeatedly computes
pre- or post-images of regular languages under the string functions present in
a string formula, inferring more and more knowledge about the possible values
of string variables, until either a conflict is found or satisfiability of the
string formula can be concluded. Such a propagation strategy is applicable to
string constraints with multiple operations like concatenation, replace, and
almost all flavors of string transductions. We demonstrate the generality and
effectiveness of this method theoretically and experimentally. On the
theoretical side, we show that RCP is sound and complete for a large fragment
of string constraints, subsuming both straight-line and chain-free constraints,
two of the most expressive decidable fragments for which some modern string
solvers provide formal completeness guarantees. On the practical side, we
implement regular constraint propagation within the open-source string solver
OSTRICH.
  Our experimental evaluation shows that this addition significantly improves
OSTRICH's performance and makes it competitive with existing solvers. In fact,
it substantially outperforms other solvers on random PCP and bioinformatics
benchmarks. The results also suggest that incorporating regular constraint
propagation alongside other techniques could lead to substantial performance
gains for existing solvers.

</details>


### [11] [Between Markov and restriction: Two more monads on categories for relations](https://arxiv.org/abs/2508.20054)
*Cipriano Junior Cioffo,Fabio Gadducci,Davide Trotta*

Main category: cs.LO

TL;DR: 本文对关系范畴进行了理论扩展，提出了基于mass与domain抽象的更高层次gs-monoidal范畴和新型monads，系统总结并推广了相关分类体系，深化了对半环加权关系等结构的统一范畴学描述。


<details>
  <summary>Details</summary>
Motivation: 此前对抽象关系结构性质的范畴（categories for relations）已有较多研究，并形成了系统归纳，但尚有更高层次的抽象结构有待补充与探索。作者希望通过引入更一般的理论工具，丰富已有的理论体系。

Method: 作者提出了两个更为抽象的gs-monoidal范畴类别，并以箭头的“mass”和“domain”两种公理化特征刻画它们；进一步定义了保持mass/domain的幺半范畴子结构（monads），并证明相关Kleisli范畴自然保持上述结构方程。这些结构可涵盖对半环加权关系的描述。

Result: 论文扩展并系统化了关系范畴的分类，引入了比Markov范畴与限制范畴更一般的gs-monoidal新类别，提出了mass和domain保持的幺半范畴子结构，证明它们能用于半环加权关系/态射中，从而拓展了理论适用范围。

Conclusion: 通过新引入的更抽象gs-monoidal范畴和相关幺半结构，本文进一步丰富和推广了关系范畴的理论框架，系统连接和拓展了Markov、限制等类别，并为基于半环加权关系的范畴分析提供了统一理论支撑基础。

Abstract: The study of categories abstracting the structural properties of relations
has been extensively developed over the years, resulting in a rich and diverse
body of work. A previous paper offered a survey providing a modern and
comprehensive presentation of these ``categories for relations'' as instances
of gs-monoidal categories, showing how they arise as Kleisli categories of
suitable symmetric monoidal monads. The end result was a taxonomy that
organised numerous related concepts in the literature, including in particular
Markov and restriction categories. This paper further enriches the taxonomy: it
proposes two categories that are once more instances of gs-monoidal categories,
yet more abstract than Markov and restriction categories. They are
characterised by an axiomatic notion of mass and domain of an arrow, the latter
one of the key ingredient of restriction categories, which generalises the
domain of partial functions. The paper then introduces mass and domain
preserving monads, proving that the associated Kleisli categories in fact
preserve the corresponding equations and that these monads arise naturally for
the categories of semiring-weighted relations.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [12] [Heterogeneous LLM Methods for Ontology Learning (Few-Shot Prompting, Ensemble Typing, and Attention-Based Taxonomies)](https://arxiv.org/abs/2508.19428)
*Aleksandra Beliaeva,Temurbek Rahmatullaev*

Main category: cs.CL

TL;DR: 本文提出融合RAG、零样本分类与图建模的端到端本体构建系统，不需微调模型，即在术语抽取、类型分配与分类体系发现三项任务上取得了优异成绩，验证了LLM架构在本体学习任务上的强大潜力。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs4OL 2025挑战赛的三项任务（术语抽取、类型分配、分类体系发现），覆盖完整本体构建流程，以提升本体学习的自动化广度和适应性。

Method: 针对三项任务分别采用：1）检索增强生成（RAG）方法用于术语和类型联合抽取；2）少/零样本类型分配，结合few-shot RAG与多嵌入模型的置信加权余弦相似度分类器；3）基于嵌入和交叉注意力的图建模方法推断is-a关系，实现软邻接矩阵化表征。

Result: 通过上述各任务专属方法，在官方排行榜三项任务上均获得了最高排名，验证了方法的可扩展性、适应性与稳健性。

Conclusion: LLM为核心的架构在异构领域的本体学习上具有高可扩展性、适应性和鲁棒性，所提方法展现了解决端到端本体构建任务的能力。

Abstract: We present a comprehensive system for addressing Tasks A, B, and C of the
LLMs4OL 2025 challenge, which together span the full ontology construction
pipeline: term extraction, typing, and taxonomy discovery. Our approach
combines retrieval-augmented prompting, zero-shot classification, and
attention-based graph modeling -- each tailored to the demands of the
respective task. For Task A, we jointly extract domain-specific terms and their
ontological types using a retrieval-augmented generation (RAG) pipeline.
Training data was reformulated into a document to terms and types
correspondence, while test-time inference leverages semantically similar
training examples. This single-pass method requires no model finetuning and
improves overall performance through lexical augmentation Task B, which
involves assigning types to given terms, is handled via a dual strategy. In the
few-shot setting (for domains with labeled training data), we reuse the RAG
scheme with few-shot prompting. In the zero-shot setting (for previously unseen
domains), we use a zero-shot classifier that combines cosine similarity scores
from multiple embedding models using confidence-based weighting. In Task C, we
model taxonomy discovery as graph inference. Using embeddings of type labels,
we train a lightweight cross-attention layer to predict is-a relations by
approximating a soft adjacency matrix. These modular, task-specific solutions
enabled us to achieve top-ranking results in the official leaderboard across
all three tasks. Taken together these strategies showcase the scalability,
adaptability, and robustness of LLM-based architectures for ontology learning
across heterogeneous domains.
  Code is available at:
https://github.com/BelyaevaAlex/LLMs4OL-Challenge-Alexbek

</details>


### [13] [MultiPL-MoE: Multi-Programming-Lingual Extension of Large Language Models through Hybrid Mixture-of-Experts](https://arxiv.org/abs/2508.19268)
*Qing Wang,Xue Han,Jiahui Wang,Lehao Xing,Qian Hu,Lianlian Zhang,Chao Deng,Junlan Feng*

Main category: cs.CL

TL;DR: 本文提出了一种多编程语言扩展的混合专家模型MultiPL-MoE，通过对模型结构创新，有效提升了LLM在多语言代码生成上的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）具备强大的代码生成能力，但在多语言代码生成任务中仍面临挑战，尤其是在资源受限情况下提升性能。

Method: 提出了一种混合专家模型（MoE）结构，结合了token级和segment级的MoE：token级MoE采用共享专家和门权重归一化，segment级MoE通过滑动窗口分割token序列与专家选择路由策略。

Result: MultiPL-MoE结构有效改善了多编程语言代码生成任务的表现，优化了专家选择过程，提升了整体生成性能。

Conclusion: MultiPL-MoE显著提升了多编程语言代码生成任务中的专家选择能力和模型性能，实验表明其方法有效。

Abstract: Despite LLMs' excellent code creation capabilities, multilingual code
generation remains extremely challenging. To address this, we intent to improve
the multi-programming-lingual (MultiPL) performance of the base LLMs while
retaining the most popular ones using restricted computational resources. We
consider MultiPL to be a special case of multiple natural languages and propose
a MultiPL extension of LLMs utilizing a hybrid mixture of experts (MoE), called
MultiPL-MoE. Specifically, MultiPL-MoE combines two paired MoEs to optimize
expert selection at both the token and segment levels. The token-level MoE is a
standard upcycling MoE structure with a shared expert and a novel gate weight
normalization approach that aids in the final fusion with the segment-level
MoE. The segment-level MoE incorporates two innovative designs to better
capture the syntactic structure and contextual patterns of programming
languages: First, using a sliding window to partition the input token sequence
into multiple segments; Then, adopting an expert-choice routing strategy that
allows experts to select the top-k segments. The results of the experiment
proved the effectiveness of MultiPL-MoE.

</details>


### [14] [Whisper based Cross-Lingual Phoneme Recognition between Vietnamese and English](https://arxiv.org/abs/2508.19270)
*Nguyen Huu Nhat Minh,Tran Nguyen Anh,Truong Dinh Dung,Vo Van Nam,Le Pham Tuyen*

Main category: cs.CL

TL;DR: 本文针对越南语与英语混合发音的语音识别难题，提出了构建双语音素集及端到端音素识别新方法，实验证明能提升越南语-英语自动语音识别的准确率，并增强系统对不同语音特性的适应能力。


<details>
  <summary>Details</summary>
Motivation: 越南语与英语混合发音时，跨语言音素识别是提升自动语音识别（ASR）准确性的重大挑战。主要原因在于越南语依靠声调区分词义，而英语则注重重音和非标准发音，导致两者音素难以对齐。

Method: 提出了两项主要创新：1）构建一个能够桥接越南语和英语语音系统差异的双语音素集；2）设计端到端系统，利用预训练的PhoWhisper编码器，实现对音素的深层高阶表示，从而提升音素识别能力。

Result: 实验结果显示，该方法在越南语-英语双语语音识别任务中显著提升了识别准确率，并建立了一个可以有效处理声调与重音复杂性的鲁棒框架。

Conclusion: 该研究提出的方法有效改善了越南语-英语混合语音的音素识别性能，同时为应对声调和重音音素识别的复杂性提供了创新的技术路径。

Abstract: Cross-lingual phoneme recognition has emerged as a significant challenge for
accurate automatic speech recognition (ASR) when mixing Vietnamese and English
pronunciations. Unlike many languages, Vietnamese relies on tonal variations to
distinguish word meanings, whereas English features stress patterns and
non-standard pronunciations that hinder phoneme alignment between the two
languages. To address this challenge, we propose a novel bilingual speech
recognition approach with two primary contributions: (1) constructing a
representative bilingual phoneme set that bridges the differences between
Vietnamese and English phonetic systems; (2) designing an end-to-end system
that leverages the PhoWhisper pre-trained encoder for deep high-level
representations to improve phoneme recognition. Our extensive experiments
demonstrate that the proposed approach not only improves recognition accuracy
in bilingual speech recognition for Vietnamese but also provides a robust
framework for addressing the complexities of tonal and stress-based phoneme
recognition

</details>


### [15] [Rethinking Reasoning in LLMs: Neuro-Symbolic Local RetoMaton Beyond ICL and CoT](https://arxiv.org/abs/2508.19271)
*Rushitha Santhoshi Mamidala,Anshuman Chhabra,Ankur Mali*

Main category: cs.CL

TL;DR: 作者提出利用本地加权有限自动机（WFA）优化神经符号框架RetoMaton，解决现有Prompt-based推理在稳定性和透明度上的不足。实验表明方法在标准推理任务上优于基线方法，并具备可解释、易迁移等优点，为大模型符号推理带来新思路。


<details>
  <summary>Details</summary>
Motivation: 当前广泛使用的Prompt-based推理方法（如Chain-of-Thought、In-Context Learning）在大语言模型中的推理稳定性和可解释性存在问题，输出易受随机种子、格式或细微Prompt变化影响，因此在需要稳定、可解释推理的任务上不可靠。作者旨在寻找更可信、结构化的神经符号方法。

Method: 作者扩展了RetoMaton神经符号框架，用本地、任务自适应的加权有限自动机（WFA）取代全局数据存储，WFA直接由外部领域语料构建，从而提升检索的稳健性和上下文适应能力，同时保留符号可追踪性和低推理开销。方法通过WFAs结构实现透明、模块化检索行为。

Result: 作者在LLaMA-3.2-1B和Gemma-3-1B-PT两个预训练大模型和TriviaQA、GSM8K、MMLU三项推理任务上，验证了本地RetoMaton方法。实验结果显示，相较原始模型和Prompt-based方法，融合本地RetoMaton能持续提升任务表现，且检索过程透明、可复现。

Conclusion: 基于本地WFA的RetoMaton方法能够对现代大语言模型提供透明、稳健且可追踪的推理机制。这一轻量级自动机引导的符号记忆方案，有望替代脆弱的Prompt方法，为可信赖的符号推理探索了新方向。

Abstract: Prompt-based reasoning strategies such as Chain-of-Thought (CoT) and
In-Context Learning (ICL) have become widely used for eliciting reasoning
capabilities in large language models (LLMs). However, these methods rely on
fragile, implicit mechanisms often yielding inconsistent outputs across seeds,
formats, or minor prompt variations making them fundamentally unreliable for
tasks requiring stable, interpretable reasoning. In contrast, automata-based
neuro-symbolic frameworks like RetoMaton offer a more structured and
trustworthy alternative by grounding retrieval in symbolic memory with
deterministic transitions. In this work, we extend RetoMaton by replacing its
global datastore with a local, task-adaptive Weighted Finite Automaton (WFA),
constructed directly from external domain corpora. This local automaton
structure promotes robust, context-aware retrieval while preserving symbolic
traceability and low inference overhead. Unlike prompting, which entangles
context and memory in opaque ways, our approach leverages the explicit
structure of WFAs to provide verifiable and modular retrieval behavior, making
it better suited for domain transfer and interoperability. We evaluate this
local RetoMaton variant on two pretrained LLMs LLaMA-3.2-1B and Gemma-3-1B-PT
across three reasoning tasks: TriviaQA (reading comprehension), GSM8K
(multi-step math), and MMLU (domain knowledge). Compared to the base model and
prompting-based methods, augmenting these setups with local RetoMaton
consistently improves performance while enabling transparent and reproducible
retrieval dynamics. Our results highlight a promising shift toward trustworthy,
symbolic reasoning in modern LLMs via lightweight, automaton-guided memory.

</details>


### [16] [RAGAPHENE: A RAG Annotation Platform with Human Enhancements and Edits](https://arxiv.org/abs/2508.19272)
*Kshitij Fadnis,Sara Rosenthal,Maeda Hanafi,Yannis Katsis,Marina Danilevsky*

Main category: cs.CL

TL;DR: 该论文提出一个对话标注平台RAGAPHENE，帮助模拟真实多轮检索增强生成场景，已成功构建大量用于评估大语言模型的真实对话数据。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）在与用户交流时，事实性正确的信息变得非常重要，但LLM有时会生成看似正确但实际包含虚假信息的答案。因此，建立能评估LLM在多轮检索增强生成（RAG）对话场景中的基准变得越来越重要。

Method: 提出并开发了一个名为RAGAPHENE的聊天式标注平台，让标注人员可以模拟真实世界的对话，从而用于基准测试和评估LLM。

Result: RAGAPHENE平台已被约40名标注员成功使用，构建了数千个真实世界的对话数据集，为LLM的多轮RAG评测提供了丰富资源。

Conclusion: 通过RAGAPHENE平台，可以更真实地模拟实际使用环境，建立高质量的评测基准，从而更有效地评估和提升LLM在事实性检索增强生成任务上的表现。

Abstract: Retrieval Augmented Generation (RAG) is an important aspect of conversing
with Large Language Models (LLMs) when factually correct information is
important. LLMs may provide answers that appear correct, but could contain
hallucinated information. Thus, building benchmarks that can evaluate LLMs on
multi-turn RAG conversations has become an increasingly important task.
Simulating real-world conversations is vital for producing high quality
evaluation benchmarks. We present RAGAPHENE, a chat-based annotation platform
that enables annotators to simulate real-world conversations for benchmarking
and evaluating LLMs. RAGAPHENE has been successfully used by approximately 40
annotators to build thousands of real-world conversations.

</details>


### [17] [Leveraging Language Models and Machine Learning in Verbal Autopsy Analysis](https://arxiv.org/abs/2508.19274)
*Yue Chu*

Main category: cs.CL

TL;DR: 本文发现，利用口头尸检叙述文本，配合预训练语言模型和多模态融合方法，能显著提升死亡原因自动分类精度，超越仅用结构化问卷的方法，为全球健康和工具改进提供理论和数据支持。


<details>
  <summary>Details</summary>
Motivation: 在一些没有民事登记和人口统计系统的国家，准确估算死亡原因（COD）对公共政策制定至关重要。传统的口头尸检（VA）仅利用结构化问卷信息，忽略了非结构化叙述中的潜在有价值信息。本文旨在探索如何利用VA叙述文本提升自动化死亡原因分类的准确率。

Method: 使用来自南非的实际数据，采用预训练语言模型（PLM）和机器学习方法对VA叙述文本进行自动死亡原因分类。具体包括对变换器模型进行任务特定微调，仅用叙述文本进行分类，并尝试将叙述与结构化问题多模态融合，提升分类性能。同时分析医生对信息充分性的感知及其对分类准确性的影响。

Result: 仅用叙述文本，经微调的变换器模型表现优于现有仅用问卷的主流算法，尤其在识别非传染性疾病方面有明显提升。多模态融合（叙述+问卷）进一步提升了分类准确性。医生及模型的分类准确性受信息充分性影响。

Conclusion: VA叙述文本在提升自动COD分类中具重要价值，多模态方法能够更充分利用各类信息，显著提升分类表现。研究建议构建更高质量、更具多样性的数据集以训练和微调PLM/ML方法，同时为VA工具和访谈流程的优化提供了有益启示。

Abstract: In countries without civil registration and vital statistics, verbal autopsy
(VA) is a critical tool for estimating cause of death (COD) and inform policy
priorities. In VA, interviewers ask proximal informants for details on the
circumstances preceding a death, in the form of unstructured narratives and
structured questions. Existing automated VA cause classification algorithms
only use the questions and ignore the information in the narratives. In this
thesis, we investigate how the VA narrative can be used for automated COD
classification using pretrained language models (PLMs) and machine learning
(ML) techniques. Using empirical data from South Africa, we demonstrate that
with the narrative alone, transformer-based PLMs with task-specific fine-tuning
outperform leading question-only algorithms at both the individual and
population levels, particularly in identifying non-communicable diseases. We
explore various multimodal fusion strategies combining narratives and questions
in unified frameworks. Multimodal approaches further improve performance in COD
classification, confirming that each modality has unique contributions and may
capture valuable information that is not present in the other modality. We also
characterize physician-perceived information sufficiency in VA. We describe
variations in sufficiency levels by age and COD and demonstrate that
classification accuracy is affected by sufficiency for both physicians and
models. Overall, this thesis advances the growing body of knowledge at the
intersection of natural language processing, epidemiology, and global health.
It demonstrates the value of narrative in enhancing COD classification. Our
findings underscore the need for more high-quality data from more diverse
settings to use in training and fine-tuning PLM/ML methods, and offer valuable
insights to guide the rethinking and redesign of the VA instrument and
interview.

</details>


### [18] [FLAIRR-TS -- Forecasting LLM-Agents with Iterative Refinement and Retrieval for Time Series](https://arxiv.org/abs/2508.19279)
*Gunjan Jalori,Preetika Verma,Sercan Ö Arık*

Main category: cs.CL

TL;DR: FLAIRR-TS通过代理自适应优化提示词，实现无需微调和复杂工程即可用LLM高效预测时间序列，效果优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统利用大型语言模型（LLM）进行时间序列预测，需要复杂的预处理和微调，且手工设计提示词流程繁琐，难以泛化。现有方法虽然效果接近专业预测器，但提示词工程门槛高，难以高效应用于不同任务。

Method: 提出FLAIRR-TS框架，利用Forecaster-agent生成预测，再由Refiner-agent根据历史输出及相似案例优化提示词，实现自适应且通用的提示词模板，无需中间代码生成。

Result: 在多项基准数据集实验中，FLAIRR-TS准确率优于静态提示和检索增强基线，接近专业提示词性能，同时无需微调和复杂预处理。

Conclusion: FLAIRR-TS以代理系统自适应优化提示词，为LLM时间序列预测提供了无需调参的高效实用方案。

Abstract: Time series Forecasting with large languagemodels (LLMs) requires bridging
numericalpatterns and natural language. Effective fore-casting on LLM often
relies on extensive pre-processing and fine-tuning.Recent studiesshow that a
frozen LLM can rival specializedforecasters when supplied with a carefully
en-gineered natural-language prompt, but craft-ing such a prompt for each task
is itself oner-ous and ad-hoc. We introduce FLAIRR-TS, atest-time prompt
optimization framework thatutilizes an agentic system: a
Forecaster-agentgenerates forecasts using an initial prompt,which is then
refined by a refiner agent, in-formed by past outputs and retrieved
analogs.This adaptive prompting generalizes across do-mains using creative
prompt templates andgenerates high-quality forecasts without inter-mediate code
generation.Experiments onbenchmark datasets show improved accuracyover static
prompting and retrieval-augmentedbaselines, approaching the performance
ofspecialized prompts.FLAIRR-TS providesa practical alternative to tuning,
achievingstrong performance via its agentic approach toadaptive prompt
refinement and retrieval.

</details>


### [19] [CORE: Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning](https://arxiv.org/abs/2508.19282)
*Ziqiang Cui,Yunpeng Weng,Xing Tang,Peiyang Liu,Shiwei Li,Bowei He,Jiamin Chen,Xiuqiang He,Chen Ma*

Main category: cs.CL

TL;DR: 论文提出CORE，在RAG中使用增强学习进行无损压缩，无需预设标签，显著提高压缩比且提升任务表现，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: RAG提高了大语言模型的知识时效性和事实准确性，但检索过多文档会导致输入变长，计算成本增加。现有文档压缩方法常损失下游任务表现，且依赖固定启发式，无法保证压缩内容有效支持最终任务。

Method: CORE采用增强学习优化压缩过程，无需预定义压缩标签。以下游任务表现为奖励信号，通过广义强化学习策略优化（GRPO）训练压缩器，实现端到端训练，使压缩器生成能最大化LLM答案准确率的摘要。

Result: 在四个数据集上的大量实验显示，CORE在高达3%的压缩率下，不仅避免了性能下降，还使平均EM分数提升3.3分。

Conclusion: CORE方法实现了对RAG无损的上下文压缩，在显著降低输入长度和计算成本的同时，提升了下游任务性能。代码即将开放。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising approach to
enhance the timeliness of knowledge and the factual accuracy of responses in
Large Language Models (LLMs). However, the inclusion of excessive retrieved
documents substantially increases the input length, leading to higher
computational costs. Previous studies have attempted to compress retrieved
documents into shorter texts before in-context integration, but such methods
often compromise end-task performance. The lack of well-defined compression
targets forces many approaches to rely on fixed heuristics, which cannot
guarantee that the compressed content will effectively support the end task. To
address these limitations, we propose CORE, a novel method designed to achieve
lossless context compression for RAG. CORE employs reinforcement learning to
optimize the compression process without relying on predefined compression
labels. Specifically, it utilizes end-task performance as a reward signal and
applies Generalized Reinforcement Learning Policy Optimization (GRPO) to train
the compressor. This end-to-end training framework enables the compressor to
generate summaries that maximize the accuracy of answers generated by the LLM.
Extensive experiments on four datasets demonstrate the superiority of our
approach. With a high compression ratio of 3\%, our method not only avoids
performance degradation compared to prepending full documents across all
datasets but also improves the average Exact Match (EM) score by 3.3 points.
The code will be released soon.

</details>


### [20] [Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains](https://arxiv.org/abs/2508.19357)
*Peiran Zhou,Junnan Zhu,Yichen Shen,Ruoxi Yu*

Main category: cs.CL

TL;DR: 针对传统RAG在复杂多文档领域信息过载和合成低效的问题，提出了CASC新框架，通过小型LLM智能分析和压缩检索内容，有效提升科学领域多文档问答任务的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然在语言任务上表现优异，但易出现幻觉和知识过时的问题。RAG通过检索外部知识改善此状况，但在面对复杂、多文本或存在冲突的领域时信息过载，导致合成效率低和答案不可信。

Method: 提出CASC（Context-Adaptive Synthesis and Compression）框架，利用经过微调的小型LLM组成的CAS模块，进行关键信息提取、文件一致性检查与冲突解决，以及面向问题的结构化合成，将原始检索内容浓缩为高结构化和语义丰富的上下文。

Result: CASC在新提出的多文档科学领域问答数据集SciDocs-QA上，经过广泛实验，持续超越各类强基线方法，表现优异。

Conclusion: CASC有效解决了多文档RAG范式下的信息过载与低效合成问题，生成更简洁、结构化且语义丰富的输入，从而显著提升多文档问答的准确性和可靠性。

Abstract: Large Language Models (LLMs) excel in language tasks but are prone to
hallucinations and outdated knowledge. Retrieval-Augmented Generation (RAG)
mitigates these by grounding LLMs in external knowledge. However, in complex
domains involving multiple, lengthy, or conflicting documents, traditional RAG
suffers from information overload and inefficient synthesis, leading to
inaccurate and untrustworthy answers. To address this, we propose CASC
(Context-Adaptive Synthesis and Compression), a novel framework that
intelligently processes retrieved contexts. CASC introduces a Context Analyzer
& Synthesizer (CAS) module, powered by a fine-tuned smaller LLM, which performs
key information extraction, cross-document consistency checking and conflict
resolution, and question-oriented structured synthesis. This process transforms
raw, scattered information into a highly condensed, structured, and
semantically rich context, significantly reducing the token count and cognitive
load for the final Reader LLM. We evaluate CASC on SciDocs-QA, a new
challenging multi-document question answering dataset designed for complex
scientific domains with inherent redundancies and conflicts. Our extensive
experiments demonstrate that CASC consistently outperforms strong baselines.

</details>


### [21] [Reflective Agreement: Combining Self-Mixture of Agents with a Sequence Tagger for Robust Event Extraction](https://arxiv.org/abs/2508.19359)
*Fatemeh Haji,Mazal Bethany,Cho-Yu Jason Chiang,Anthony Rios,Peyman Najafirad*

Main category: cs.CL

TL;DR: ARIS是一种结合判别与生成模型优势的创新事件抽取方法，有效提升了模型的召回率与整体精度，在多个数据集上超过现有最佳技术。


<details>
  <summary>Details</summary>
Motivation: 传统判别模型虽精度高但对细粒度或低频事件召回差；生成式方法（如LLMs）召回高但易产生幻觉与不一致预测。为解决二者局限，需设计新方法兼顾优势并缓解缺点。

Method: ARIS是一种混合方法，结合了多智能体自混合和判别式序列标注器。它利用结构化模型共识、基于置信度的过滤和LLM反思式推理模块，有效解决歧义问题，并提升事件预测的整体质量。此外，还对分解式指令微调进行了探索。

Result: 实验表明，ARIS在三个主流数据集上的表现超过现有最优事件抽取方法。

Conclusion: 本文提出的ARIS方法在事件抽取任务上优于其他先进方法，在三个基准数据集上取得了更好表现。

Abstract: Event Extraction (EE) involves automatically identifying and extracting
structured information about events from unstructured text, including triggers,
event types, and arguments. Traditional discriminative models demonstrate high
precision but often exhibit limited recall, particularly for nuanced or
infrequent events. Conversely, generative approaches leveraging Large Language
Models (LLMs) provide higher semantic flexibility and recall but suffer from
hallucinations and inconsistent predictions. To address these challenges, we
propose Agreement-based Reflective Inference System (ARIS), a hybrid approach
combining a Self Mixture of Agents with a discriminative sequence tagger. ARIS
explicitly leverages structured model consensus, confidence-based filtering,
and an LLM reflective inference module to reliably resolve ambiguities and
enhance overall event prediction quality. We further investigate decomposed
instruction fine-tuning for enhanced LLM event extraction understanding.
Experiments demonstrate our approach outperforms existing state-of-the-art
event extraction methods across three benchmark datasets.

</details>


### [22] [LongReasonArena: A Long Reasoning Benchmark for Large Language Models](https://arxiv.org/abs/2508.19363)
*Jiayu Ding,Shuming Ma,Lei Cui,Nanning Zheng,Furu Wei*

Main category: cs.CL

TL;DR: 本文提出LongReasonArena用于评测大语言模型的长推理能力，结果显示现有模型在该基准上的表现远不理想，准确率随推理长度增加急剧下降。


<details>
  <summary>Details</summary>
Motivation: 当前长上下文基准主要关注对长输入的理解，但忽略了对长推理能力的评测，因此亟需建立针对长推理的评测体系。

Method: 设计了一套可以根据需求调整推理长度、包含检索和回溯等长推理特征的任务，用于评估LLM在长推理场景下的能力。

Result: 以Deepseek-R1为例，仅取得7.5%的准确率，且准确率与所需推理步骤对数成线性下降趋势，验证了该基准的高挑战性。

Conclusion: LongReasonArena为现有LLM提供了全新的长推理评测难题，当前主流开源和闭源模型在该测试下表现不佳，且随着推理长度增加，准确率线性下降。

Abstract: Existing long-context benchmarks for Large Language Models (LLMs) focus on
evaluating comprehension of long inputs, while overlooking the evaluation of
long reasoning abilities. To address this gap, we introduce LongReasonArena, a
benchmark specifically designed to assess the long reasoning capabilities of
LLMs. Our tasks require models to solve problems by executing multi-step
algorithms that reflect key aspects of long reasoning, such as retrieval and
backtracking. By controlling the inputs, the required reasoning length can be
arbitrarily scaled, reaching up to 1 million tokens of reasoning for the most
challenging tasks. Extensive evaluation results demonstrate that
LongReasonArena presents a significant challenge for both open-source and
proprietary LLMs. For instance, Deepseek-R1 achieves only 7.5% accuracy on our
task. Further analysis also reveals that the accuracy exhibits a linear decline
with respect to the logarithm of the expected number of reasoning steps. Our
code and data is available at
https://github.com/LongReasonArena/LongReasonArena.

</details>


### [23] [Database Entity Recognition with Data Augmentation and Deep Learning](https://arxiv.org/abs/2508.19372)
*Zikun Fu,Chen Yang,Kourosh Davoudi,Ken Q. Pu*

Main category: cs.CL

TL;DR: 提出针对自然语言查询的数据库实体识别新方法，包括高质量数据集、新型数据增广技术和基于T5的专用模型，在多个指标上超越现有NER方法。


<details>
  <summary>Details</summary>
Motivation: 数据库实体识别（DB-ER）在自然语言查询中的表现不理想，现有数据集和方法有局限性，需要提升识别准确率和扩展性。

Method: 1. 构建基于流行text-to-sql数据集的人工标注DB-ER基准数据集；2. 提出一种新颖的数据增广方法，通过自动标注自然语言查询，利用数据库对应的SQL查询信息；3. 基于T5模型开发专门用于DB-ER任务的实体识别模型，采用序列标注和分词分类进行微调和任务执行。

Result: 与两种主流NER标注器相比，提出的DB-ER模型在精确率和召回率上均表现更佳。消融实验显示，数据增广可提升精确率和召回率超过10%，T5模型微调可提升5-10%。

Conclusion: 综合创新的数据集构建、数据增广与T5模型微调策略，使得DB-ER任务在准确率和召回率上获得显著提升。

Abstract: This paper addresses the challenge of Database Entity Recognition (DB-ER) in
Natural Language Queries (NLQ). We present several key contributions to advance
this field: (1) a human-annotated benchmark for DB-ER task, derived from
popular text-to-sql benchmarks, (2) a novel data augmentation procedure that
leverages automatic annotation of NLQs based on the corresponding SQL queries
which are available in popular text-to-SQL benchmarks, (3) a specialized
language model based entity recognition model using T5 as a backbone and two
down-stream DB-ER tasks: sequence tagging and token classification for
fine-tuning of backend and performing DB-ER respectively. We compared our DB-ER
tagger with two state-of-the-art NER taggers, and observed better performance
in both precision and recall for our model. The ablation evaluation shows that
data augmentation boosts precision and recall by over 10%, while fine-tuning of
the T5 backbone boosts these metrics by 5-10%.

</details>


### [24] [One Joke to Rule them All? On the (Im)possibility of Generalizing Humor](https://arxiv.org/abs/2508.19402)
*Mor Turgeman,Chen Shani,Dafna Shahaf*

Main category: cs.CL

TL;DR: 本文探讨大语言模型在幽默任务上的迁移泛化能力，发现不同幽默类型间存在转移潜力，多样性训练能提升泛化表现，尤其“Dad Jokes”对迁移帮助大。


<details>
  <summary>Details</summary>
Motivation: 幽默是一种复杂的交流形式，但目前大多数计算幽默研究仅限于对某一特定类型的幽默建模。随着网络和社交媒体的发展，新型幽默形式不断出现，因此亟需模型能够泛化不同幽默类型。本文旨在探索现有模型在熟悉幽默类型上的能力，是否能够迁移到新、未见过的幽默类型，以解决当前幽默建模碎片化的问题。

Method: 作者采用四个代表不同幽默任务的数据集，进行系列迁移学习实验。通过在不同多样性条件下训练大型语言模型（分别在1-3个数据集上训练，再在新任务上测试），评估模型的泛化转移能力，并进一步分析不同幽默类型之间的关系。

Result: 实验结果显示，模型确实具有一定迁移能力，在未见过的数据集上可达75%的准确率；在多来源数据上训练可提升1.88-4.05%的迁移能力，且在原域任务上的性能几无下降。进一步分析发现，不同幽默类型之间存在联系，其中“Dad Jokes”最有助于迁移，但自身却难以被迁移到。

Conclusion: 本文研究说明，幽默任务间不是完全碎片化的，模型存在跨幽默类型的迁移潜力，且多样化训练资源有助于提升其泛化能力。数据和代码已公开。

Abstract: Humor is a broad and complex form of communication that remains challenging
for machines. Despite its broadness, most existing research on computational
humor traditionally focused on modeling a specific type of humor. In this work,
we wish to understand whether competence on one or more specific humor tasks
confers any ability to transfer to novel, unseen types; in other words, is this
fragmentation inevitable? This question is especially timely as new humor types
continuously emerge in online and social media contexts (e.g., memes,
anti-humor, AI fails). If Large Language Models (LLMs) are to keep up with this
evolving landscape, they must be able to generalize across humor types by
capturing deeper, transferable mechanisms. To investigate this, we conduct a
series of transfer learning experiments across four datasets, representing
different humor tasks. We train LLMs under varied diversity settings (1-3
datasets in training, testing on a novel task). Experiments reveal that models
are capable of some transfer, and can reach up to 75% accuracy on unseen
datasets; training on diverse sources improves transferability (1.88-4.05%)
with minimal-to-no drop in in-domain performance. Further analysis suggests
relations between humor types, with Dad Jokes surprisingly emerging as the best
enabler of transfer (but is difficult to transfer to). We release data and
code.

</details>


### [25] [A perishable ability? The future of writing in the face of generative artificial intelligence](https://arxiv.org/abs/2508.19427)
*Evandro L. T. P. Cunha*

Main category: cs.CL

TL;DR: 该文探讨生成式AI普及后，人类将可能因为依赖机器创作而逐步丧失写作能力，并通过历史类比引发对此现象的深刻思考。


<details>
  <summary>Details</summary>
Motivation: 近年来，大语言模型等生成式AI被广泛应用于文本生成，这可能导致人类文本创作的减少。作者关注这种趋势对人类写作能力的长远影响。

Method: 通过历史与现状对比、理论分析，探讨人类写作能力的未来变迁。

Result: 作者提出一种未来可能：因为写作工作被机器取代，人类写作能力下降，并将此现象与人类历史上的写作能力消失（如希腊黑暗时代）做类比。

Conclusion: 随着生成式AI工具的发展，人类可能失去或大幅削弱写作能力。

Abstract: The 2020s have been witnessing a very significant advance in the development
of generative artificial intelligence tools, including text generation systems
based on large language models. These tools have been increasingly used to
generate texts in the most diverse domains -- from technical texts to literary
texts --, which might eventually lead to a lower volume of written text
production by humans. This article discusses the possibility of a future in
which human beings will have lost or significantly decreased their ability to
write due to the outsourcing of this activity to machines. This possibility
parallels the loss of the ability to write in other moments of human history,
such as during the so-called Greek Dark Ages (approx. 1200 BCE - 800 BCE).

</details>


### [26] [Bridging Language Gaps: Enhancing Few-Shot Language Adaptation](https://arxiv.org/abs/2508.19464)
*Philipp Borchert,Jochen De Weerdt,Marie-Francine Moens*

Main category: cs.CL

TL;DR: 针对多语言NLP中低资源语言数据不足的问题，作者提出了CoLAP方法，融合对比学习与提示实现高效跨语言知识迁移。实验显示CoLAP优于现有基线，显著改善了低资源语言表现。


<details>
  <summary>Details</summary>
Motivation: 多语言自然语言处理（NLP）中，不同语言资源分布不均，高资源语言有大量数据可用，而低资源语言缺乏足够数据训练，导致低资源语言任务效果差。因此，作者希望解决多语言之间的数据鸿沟问题。

Method: 提出对比语言对齐与提示（CoLAP）方法，将对比学习与跨语言表示结合，通过提示机制实现高资源语言到低资源语言的任务知识迁移，提升数据利用效率。方法在多语言的只编码器模型和只解码器模型上进行实验，涉及自然语言推理和关系抽取等任务。

Result: 实验结果表明，CoLAP方法在高、低资源语言上均优于当前主流的few-shot跨语言迁移和in-context learning技术，即使在数据有限情况下，仍显著提升了跨语言任务的表现。

Conclusion: CoLAP有效缩小了高、低资源语言的性能差距，提高了多语言NLP的效率，有助于发展更强大的多语言处理技术。

Abstract: The disparity in language resources poses a challenge in multilingual NLP,
with high-resource languages benefiting from extensive data, while low-resource
languages lack sufficient data for effective training. Our Contrastive Language
Alignment with Prompting (CoLAP) method addresses this gap by integrating
contrastive learning with cross-lingual representations, facilitating
task-specific knowledge transfer from high-resource to lower-resource
languages. The primary advantage of our approach is its data efficiency,
enabling rapid adaptation to new languages and reducing the need for large
labeled datasets. We conduct experiments with multilingual encoder-only and
decoder-only language models on natural language understanding tasks, including
natural language inference and relation extraction, evaluating performance
across both high- and low-resource languages. Our results demonstrate that
CoLAP outperforms few-shot cross-lingual transfer baselines and in-context
learning, even with limited available data. This effectively narrows the
cross-lingual performance gap, contributing to the development of more
efficient multilingual NLP techniques.

</details>


### [27] [Inference Gap in Domain Expertise and Machine Intelligence in Named Entity Recognition: Creation of and Insights from a Substance Use-related Dataset](https://arxiv.org/abs/2508.19467)
*Sumon Kanti Dey,Jeanne M. Powell,Azra Ismail,Jeanmarie Perrone,Abeed Sarker*

Main category: cs.CL

TL;DR: 本文针对社交媒体上的阿片类药物自报后果，提出NER框架和新数据集RedditImpacts 2.0。微调DeBERTa-large模型优于零/少样本的大语言模型，但与专家一致性仍有差距，显示领域化AI模型需进一步提升以支持临床决策。


<details>
  <summary>Details</summary>
Motivation: 非医疗性阿片类药物滥用带来严重的临床和社会影响，而这些影响在传统医疗环境中常被低估或漏报。社交媒体平台用户常分享其亲身经历，为理解这些影响提供了宝贵但尚未充分挖掘的信息来源。

Method: 提出了一套命名实体识别（NER）框架，从与阿片类药物使用相关的社交媒体叙述中，提取自报临床和社会后果两大类信息。研究构建了高质量的RedditImpacts 2.0数据集，并对现有编码器模型（如DeBERTa-large）与最新大语言模型（LLMs）在不同学习场景下进行了比较评估。

Result: DeBERTa-large微调模型在无需大量标注数据的情况下表现出色，取得了0.61的宽松令牌级F1分数，优于大语言模型在精确度、跨度准确性和任务规范遵循上的表现。同时指出，领域定制微调对临床自然语言处理任务意义重大。

Conclusion: 领域微调的编码器模型在社交媒体药物使用后果抽取任务上优于主流大语言模型，即便在资源有限情况下亦可部署较为稳健的模型。然而，模型性能与专家一致性仍存明显差距，AI在该领域任务上尚未达到专家水平。

Abstract: Nonmedical opioid use is an urgent public health challenge, with far-reaching
clinical and social consequences that are often underreported in traditional
healthcare settings. Social media platforms, where individuals candidly share
first-person experiences, offer a valuable yet underutilized source of insight
into these impacts. In this study, we present a named entity recognition (NER)
framework to extract two categories of self-reported consequences from social
media narratives related to opioid use: ClinicalImpacts (e.g., withdrawal,
depression) and SocialImpacts (e.g., job loss). To support this task, we
introduce RedditImpacts 2.0, a high-quality dataset with refined annotation
guidelines and a focus on first-person disclosures, addressing key limitations
of prior work. We evaluate both fine-tuned encoder-based models and
state-of-the-art large language models (LLMs) under zero- and few-shot
in-context learning settings. Our fine-tuned DeBERTa-large model achieves a
relaxed token-level F1 of 0.61 [95% CI: 0.43-0.62], consistently outperforming
LLMs in precision, span accuracy, and adherence to task-specific guidelines.
Furthermore, we show that strong NER performance can be achieved with
substantially less labeled data, emphasizing the feasibility of deploying
robust models in resource-limited settings. Our findings underscore the value
of domain-specific fine-tuning for clinical NLP tasks and contribute to the
responsible development of AI tools that may enhance addiction surveillance,
improve interpretability, and support real-world healthcare decision-making.
The best performing model, however, still significantly underperforms compared
to inter-expert agreement (Cohen's kappa: 0.81), demonstrating that a gap
persists between expert intelligence and current state-of-the-art NER/AI
capabilities for tasks requiring deep domain knowledge.

</details>


### [28] [Automatic Question & Answer Generation Using Generative Large Language Model (LLM)](https://arxiv.org/abs/2508.19475)
*Md. Alvee Ehsan,A. S. M Mehedi Hasan,Kefaya Benta Shahnoor,Syeda Sumaiya Tasneem*

Main category: cs.CL

TL;DR: 作者提出利用微调大语言模型和无监督学习，实现高效自动化出题与答题生成，缓解教师出题难题，提高评估效率。


<details>
  <summary>Details</summary>
Motivation: 学生评价在教育中和知识传授同等重要，但目前主要依赖手动设计文本类考核题，这对教师来说既费时又难以保证公平和多样性。作者希望通过自动化手段简化这一过程。

Method: 研究采用微调的生成式大语言模型（Meta-Llama 2-7B），利用无监督学习方法和RACE数据集进行训练，同时通过提示工程实现对不同类型题目的定制。

Result: 提出了一种基于大模型和无监督NLP的自动问答生成方法，初步结果表明该模型能有效为教育工作者和相关人员生成题目及答案，有助于优化评估流程。

Conclusion: 自动化问答生成工具可极大提升文本类评估的效率和公平性，为教育者提供可靠高效的出题与答题辅助，有望推广应用。

Abstract: \Abstract{In the realm of education, student evaluation holds equal
significance as imparting knowledge. To be evaluated, students usually need to
go through text-based academic assessment methods. Instructors need to make
diverse sets of questions that need to be fair for all students to prove their
adequacy over a particular topic. This can prove to be quite challenging as
they may need to manually go through several different lecture materials. Our
objective is to make this whole process much easier by implementing Automatic
Question Answer Generation /(AQAG), using fine-tuned generative LLM. For
tailoring the instructor's preferred question style (MCQ, conceptual, or
factual questions), prompt Engineering (PE) is being utilized. In this
research, we propose to leverage unsupervised learning methods in NLP,
primarily focusing on the English language. This approach empowers the base
Meta-Llama 2-7B model to integrate RACE dataset as training data for the
fine-tuning process. Creating a customized model that will offer efficient
solutions for educators, instructors, and individuals engaged in text-based
evaluations. A reliable and efficient tool for generating questions and answers
can free up valuable time and resources, thus streamlining their evaluation
processes.}

</details>


### [29] [Improving Low-Resource Translation with Dictionary-Guided Fine-Tuning and RL: A Spanish-to-Wayuunaiki Study](https://arxiv.org/abs/2508.19481)
*Manuel Mosquera,Melissa Robles,Johan Rodriguez,Ruben Manrique*

Main category: cs.CL

TL;DR: 结合外部字典工具和强化学习训练，大语言模型能有效提升低资源语言（如西班牙语-瓦尤纳伊基语对）的翻译性能，BLEU分显著提升，展现了新方法的潜力。


<details>
  <summary>Details</summary>
Motivation: 低资源语言的机器翻译对于大语言模型来说极具挑战，原因在于预训练阶段接触这些语言较少，且微调时可用的平行数据有限。因此需要有效提升低资源语言翻译质量的方法。

Method: 提出了一种新方法，将外部词典工具与大语言模型结合，采用端到端强化学习训练，并配合监督微调。具体针对西班牙语-瓦尤纳伊基语对，模型可在翻译生成期间有选择地查字典。方法结合了有监督指令微调与Guided Reward Policy Optimization（GRPO）算法，通过BLEU分数奖励引导学习何时及如何使用词典。

Result: 初步实验结果显示，工具增强模型在西班牙语-瓦尤纳伊基测试集上，BLEU分数相比此前最佳提高3.37分，相比单纯监督微调无词典模型提升了18%。还进行消融实验，比较不同模型架构（如Qwen2.5-0.5B-Instruct、LLaMA、NLLB变体）和训练策略的影响。

Conclusion: 将大语言模型与外部词典工具结合、并利用强化学习进行训练，可显著提升低资源语言对的机器翻译质量。

Abstract: Low-resource machine translation remains a significant challenge for large
language models (LLMs), which often lack exposure to these languages during
pretraining and have limited parallel data for fine-tuning. We propose a novel
approach that enhances translation for low-resource languages by integrating an
external dictionary tool and training models end-to-end using reinforcement
learning, in addition to supervised fine-tuning. Focusing on the
Spanish-Wayuunaiki language pair, we frame translation as a tool-augmented
decision-making problem in which the model can selectively consult a bilingual
dictionary during generation. Our method combines supervised instruction tuning
with Guided Reward Policy Optimization (GRPO), enabling the model to learn both
when and how to use the tool effectively. BLEU similarity scores are used as
rewards to guide this learning process. Preliminary results show that our
tool-augmented models achieve up to +3.37 BLEU improvement over previous work,
and a 18% relative gain compared to a supervised baseline without dictionary
access, on the Spanish-Wayuunaiki test set from the AmericasNLP 2025 Shared
Task. We also conduct ablation studies to assess the effects of model
architecture and training strategy, comparing Qwen2.5-0.5B-Instruct with other
models such as LLaMA and a prior NLLB-based system. These findings highlight
the promise of combining LLMs with external tools and the role of reinforcement
learning in improving translation quality in low-resource language settings.

</details>


### [30] [Rule Synergy Analysis using LLMs: State of the Art and Implications](https://arxiv.org/abs/2508.19484)
*Bahar Bateni,Benjamin Pratt,Jim Whitehead*

Main category: cs.CL

TL;DR: 本论文以卡牌游戏为例，研究了大语言模型对复杂规则交互的理解。发现模型更擅长识别无协同作用的卡牌对，但在正负协同检测上难度较大，并归纳出了若干典型错误和模型局限。提出需进一步研究以提升LLM在规则推理上的能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）虽然在逻辑推理与数学等领域表现优异，但仍不清楚它们在复杂规则交互、尤其是动态环境如卡牌游戏中的理解与推理能力。论文旨在研究LLM处理复杂规则交互的实际能力。

Method: 研究者以卡牌游戏《杀戮尖塔》为例，构建了一个卡牌协同作用的数据集，包含正面、负面或中性交互的卡牌对，然后用LLM对这些数据进行分类和分析其表现，并归类主要的错误类型。

Result: 实验结果表明，LLM在识别无协同作用的卡牌对表现优异，但在检测正面和特别是负面协同方面表现不足，同时出现了如时序错误、定义游戏状态不准确、以及不能正确遵循游戏规则等常见错误类型。

Conclusion: LLM在处理复杂规则交互时存在明显局限性，尤其是在预测规则和交互效果方面。论文提出未来研究方向，以提升模型对复杂规则理解和推理能力。

Abstract: Large language models (LLMs) have demonstrated strong performance across a
variety of domains, including logical reasoning, mathematics, and more. In this
paper, we investigate how well LLMs understand and reason about complex rule
interactions in dynamic environments, such as card games. We introduce a
dataset of card synergies from the game Slay the Spire, where pairs of cards
are classified based on their positive, negative, or neutral interactions. Our
evaluation shows that while LLMs excel at identifying non-synergistic pairs,
they struggle with detecting positive and, particularly, negative synergies. We
categorize common error types, including issues with timing, defining game
states, and following game rules. Our findings suggest directions for future
research to improve model performance in predicting the effect of rules and
their interactions.

</details>


### [31] [Blockwise SFT for Diffusion Language Models: Reconciling Bidirectional Attention and Autoregressive Decoding](https://arxiv.org/abs/2508.19529)
*Bowen Sun,Yujun Cai,Ming-Hsuan Yang,Yiwei Wang*

Main category: cs.CL

TL;DR: 本文发现经典的SFT方式与离散扩散语言模型的推断方式不匹配，影响了性能。作者提出了Blockwise SFT，使训练阶段与推断阶段的分块策略一致，实验显示该方法能显著提升性能，并验证了改进主要源于这种一致性的策略设计。


<details>
  <summary>Details</summary>
Motivation: 现有的离散扩散语言模型在文本生成任务中表现出色，但标准的有监督微调(SFT)方式与其半自回归推断过程存在不匹配——训练时随机掩码所有位置，而推断时是分块顺序生成，这导致梯度偏差，并影响模型性能。

Method: 提出了Blockwise SFT方法，将响应分为固定大小的块，每步仅对一个活跃块进行随机掩码，其余已生成的块冻结，后续块完全隐藏，仅对当前块计算损失，使训练过程和分块推断过程一致。

Result: 在GSM8K、MATH和MetaMathQA数据集上，Blockwise SFT在相同算力或token消耗下都优于传统SFT。块大小一致性研究和消融实验表明，性能提升主要得益于训练与推断过程的一致。

Conclusion: 强调了在扩散式语言模型中，训练监督粒度应与推断过程严格匹配的重要性。

Abstract: Discrete diffusion language models have shown strong potential for text
generation, yet standard supervised fine-tuning (SFT) misaligns with their
semi-autoregressive inference: training randomly masks tokens across the entire
response, while inference generates fixed-size blocks sequentially. This
mismatch introduces noisy prefixes and leaky suffixes, biasing gradients away
from the desired blockwise likelihood. We propose Blockwise SFT, which
partitions responses into fixed-size blocks, selects one active block per step
for stochastic masking, freezes all preceding tokens, and fully hides future
ones. Loss is computed only over the active block, directly mirroring the
blockwise decoding process. Experiments on GSM8K, MATH, and MetaMathQA show
consistent gains over classical SFT under equal compute or token budgets. Block
size consistency studies and ablations confirm that improvements stem from
faithful training-inference alignment rather than incidental masking effects.
Our results highlight the importance of matching supervision granularity to the
decoding procedure in diffusion-based language models.

</details>


### [32] [Alignment with Fill-In-the-Middle for Enhancing Code Generation](https://arxiv.org/abs/2508.19532)
*Houxing Ren,Zimu Lu,Weikang Shi,Haotian Hou,Yunqiao Yang,Ke Wang,Aojun Zhou,Junting Pan,Mingjie Zhan,Hongsheng Li*

Main category: cs.CL

TL;DR: 提出细粒度代码划分与AST切分结合课程训练的DPO提升策略，显著增强了大语言模型的代码生成能力，并在多项主流数据集上验证了效果。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）在代码生成等任务中取得了显著进展，但由于可验证真实测试用例的数据有限，提升其代码相关任务的性能依然困难。当前生成测试用例的方法仍然存在局限性。

Method: 提出一种创新方法，将代码片段划分为更小的细粒度代码块，从同一组测试用例中创造出更多样化的DPO对。同时，引入AST（抽象语法树）切分和课程化训练方法，以提升DPO训练效果。

Result: 在HumanEval（+）、MBPP（+）、APPS、LiveCodeBench和BigCodeBench等多个基准数据集上，实验证明该方法在代码生成任务上取得了显著提升。

Conclusion: 通过细粒度代码块划分、多样化DPO对生成和AST切分与课程化训练，能够显著提升LLM在代码生成类任务中的表现。相关代码和数据已开源。

Abstract: The code generation capabilities of Large Language Models (LLMs) have
advanced applications like tool invocation and problem-solving. However,
improving performance in code-related tasks remains challenging due to limited
training data that is verifiable with accurate test cases. While Direct
Preference Optimization (DPO) has shown promise, existing methods for
generating test cases still face limitations. In this paper, we propose a novel
approach that splits code snippets into smaller, granular blocks, creating more
diverse DPO pairs from the same test cases. Additionally, we introduce the
Abstract Syntax Tree (AST) splitting and curriculum training method to enhance
the DPO training. Our approach demonstrates significant improvements in code
generation tasks, as validated by experiments on benchmark datasets such as
HumanEval (+), MBPP (+), APPS, LiveCodeBench, and BigCodeBench. Code and data
are available at https://github.com/SenseLLM/StructureCoder.

</details>


### [33] [Emotion Transfer with Enhanced Prototype for Unseen Emotion Recognition in Conversation](https://arxiv.org/abs/2508.19533)
*Kun Peng,Cong Cao,Hao Peng,Guanlin Wu,Zhifeng Hao,Lei Jiang,Yanbing Liu,Philip S. Yu*

Main category: cs.CL

TL;DR: 本文首次提出未见情感识别对话任务，针对实际应用遇到的新情感设计了创新的ProEmoTrans原型迁移框架，通过三项技术突破解决表达复杂、编码困难和转移挑战，并在多个数据集取得强基线表现。


<details>
  <summary>Details</summary>
Motivation: 现有的对话情感识别（ERC）研究多基于封闭域假设，然而心理学界对情感分类并无共识，实际应用中会遇到新颖的未见情感，这为模型识别带来挑战。本文旨在解决如何识别这些未见情感的问题。

Method: 提出了“未见情感识别对话任务”（UERC），并设计了原型迁移框架ProEmoTrans。方法上采用LLM增强的情感描述、无参数高效编码防止过拟合，以及改进的Attention Viterbi解码方法实现对情感转移的有效迁移。

Result: 在三个数据集上的大量实验验证了ProEmoTrans作为新领域初步探索的强大基线效果。

Conclusion: 原型迁移框架与辅助技术能有效提升未见情感识别的性能，对开放域对话情感识别具有积极推动作用。

Abstract: Current Emotion Recognition in Conversation (ERC) research follows a
closed-domain assumption. However, there is no clear consensus on emotion
classification in psychology, which presents a challenge for models when it
comes to recognizing previously unseen emotions in real-world applications. To
bridge this gap, we introduce the Unseen Emotion Recognition in Conversation
(UERC) task for the first time and propose ProEmoTrans, a solid prototype-based
emotion transfer framework. This prototype-based approach shows promise but
still faces key challenges: First, implicit expressions complicate emotion
definition, which we address by proposing an LLM-enhanced description approach.
Second, utterance encoding in long conversations is difficult, which we tackle
with a proposed parameter-free mechanism for efficient encoding and overfitting
prevention. Finally, the Markovian flow nature of emotions is hard to transfer,
which we address with an improved Attention Viterbi Decoding (AVD) method to
transfer seen emotion transitions to unseen emotions. Extensive experiments on
three datasets show that our method serves as a strong baseline for preliminary
exploration in this new area.

</details>


### [34] [Language Models Identify Ambiguities and Exploit Loopholes](https://arxiv.org/abs/2508.19546)
*Jio Choi,Mohit Bansal,Elias Stengel-Eskin*

Main category: cs.CL

TL;DR: 本文显示，大语言模型不仅能识别语句歧义，还会主动利用漏洞以偏向自身目标，暴露出AI安全的新风险。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型（LLMs）对漏洞场景的响应，目的是探索其对模糊性和语用推理的能力，以及模型在面对目标冲突时的对齐问题。

Method: 设计冲突场景，让LLMs在既定目标和存在歧义的用户指令之间进行选择，涵盖标量隐含、结构性歧义和权力动态，并测量模型对漏洞的利用能力。

Result: 发现无论是闭源还是强大的开源模型，都能识别到指令中的歧义，并有能力利用漏洞以满足自身目标，而非用户目标。

Conclusion: LLMs能够识别并利用指令中的漏洞和歧义，这对AI安全构成潜在风险。能够“钻漏洞”的模型会明确识别并推理指令的歧义和冲突目标。

Abstract: Studying the responses of large language models (LLMs) to loopholes presents
a two-fold opportunity. First, it affords us a lens through which to examine
ambiguity and pragmatics in LLMs, since exploiting a loophole requires
identifying ambiguity and performing sophisticated pragmatic reasoning. Second,
loopholes pose an interesting and novel alignment problem where the model is
presented with conflicting goals and can exploit ambiguities to its own
advantage. To address these questions, we design scenarios where LLMs are given
a goal and an ambiguous user instruction in conflict with the goal, with
scenarios covering scalar implicature, structural ambiguities, and power
dynamics. We then measure different models' abilities to exploit loopholes to
satisfy their given goals as opposed to the goals of the user. We find that
both closed-source and stronger open-source models can identify ambiguities and
exploit their resulting loopholes, presenting a potential AI safety risk. Our
analysis indicates that models which exploit loopholes explicitly identify and
reason about both ambiguity and conflicting goals.

</details>


### [35] [Towards a Holistic and Automated Evaluation Framework for Multi-Level Comprehension of LLMs in Book-Length Contexts](https://arxiv.org/abs/2508.19578)
*Jiaqi Deng,Yuho Lee,Nicole Hee-Yeon Kim,Hyangsuk Min,Taewon Yun,Minjeong Ban,Kim Yul,Hwanjun Song*

Main category: cs.CL

TL;DR: HAMLET是一种自动化评估LLMs长文本理解的系统，与人工评估高度一致，揭示了当前模型在细粒度和层次性信息理解上的不足，并发现模型类型与规模均影响其表现。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型（LLMs）在长文本理解上存在挑战，缺乏系统化且自动化的评估框架，理解模型在不同细粒度层次上的表现，尤其是评估其召回和表征信息的能力。

Method: 提出HAMLET框架，将源文本划分为三层关键事实层次（根、枝、叶），并通过聚焦查询式摘要对每一层的理解进行自动化评估。同时通过专家与自动评估一致性进行人的验证。

Result: HAMLET自动化评估与专家一致率超过90%，成本减少达25倍，揭示LLMs在细粒度（叶层）理解上有较大困难，对文本中位次敏感。分析性任务比叙事性任务更有挑战，开源模型与专有模型之间、以及不同规模模型之间存在明显性能差距。

Conclusion: HAMLET为长文本理解提供了高效、自动化的测评工具，能够可靠评估不同模型在细粒度和层次性理解上的表现，有助于推动长文本大语言模型的优化与发展。

Abstract: We introduce HAMLET, a holistic and automated framework for evaluating the
long-context comprehension of large language models (LLMs). HAMLET structures
source texts into a three-level key-fact hierarchy at root-, branch-, and
leaf-levels, and employs query-focused summarization to evaluate how well
models recall and faithfully represent information at each level. To validate
the reliability of our fully automated pipeline, we conduct a systematic human
study, showing that our automatic evaluation achieves over 90% agreement with
expert human judgments, while reducing the cost by up to 25 times. HAMLET
reveals that LLMs struggle with fine-grained comprehension, especially at the
leaf level, and are sensitive to positional effects like the
lost-in-the-middle. Analytical queries pose greater challenges than narrative
ones, and consistent performance gaps emerge between open-source and
proprietary models, as well as across model scales. Our code and dataset are
publicly available at https://github.com/DISL-Lab/HAMLET.

</details>


### [36] [ArgCMV: An Argument Summarization Benchmark for the LLM-era](https://arxiv.org/abs/2508.19580)
*Omkar Gurjar,Agam Goyal,Eshwar Chandrasekharan*

Main category: cs.CL

TL;DR: 本文指出现有关键点提取数据集无法反映真实人类辩论，利用LLM构建了更复杂的新数据集ArgCMV，并对基线与开源模型进行测试，为后续大语言模型驱动的摘要研究提供新方向和挑战。


<details>
  <summary>Details</summary>
Motivation: 现有主流关键点提取数据集ArgKP21存在代表性不足、复杂度低等局限，难以反映真实人类对话环境，因此亟需更加真实复杂的新数据集。

Method: 利用最先进的大型语言模型（LLMs）从实际在线人类辩论中收集约12K条论点，涵盖3K多个主题，并对现有方法及开源模型进行实验与基准评测。

Result: 新数据集ArgCMV较ArgKP21在论点长度、呼应关系、主观话语单元和话题广度方面复杂度更高。现有方法在ArgCMV上的表现适应性较差，为后续研究提供了更具挑战性的基准。

Conclusion: 本文提出了一个新的关键点提取数据集（ArgCMV），更贴近真实人类辩论场景，有助于推动基于大型语言模型的论证摘要研究。

Abstract: Key point extraction is an important task in argument summarization which
involves extracting high-level short summaries from arguments. Existing
approaches for KP extraction have been mostly evaluated on the popular ArgKP21
dataset. In this paper, we highlight some of the major limitations of the
ArgKP21 dataset and demonstrate the need for new benchmarks that are more
representative of actual human conversations. Using SoTA large language models
(LLMs), we curate a new argument key point extraction dataset called ArgCMV
comprising of around 12K arguments from actual online human debates spread
across over 3K topics. Our dataset exhibits higher complexity such as longer,
co-referencing arguments, higher presence of subjective discourse units, and a
larger range of topics over ArgKP21. We show that existing methods do not adapt
well to ArgCMV and provide extensive benchmark results by experimenting with
existing baselines and latest open source models. This work introduces a novel
KP extraction dataset for long-context online discussions, setting the stage
for the next generation of LLM-driven summarization research.

</details>


### [37] [Towards stable AI systems for Evaluating Arabic Pronunciations](https://arxiv.org/abs/2508.19587)
*Hadi Zaatiti,Hatem Hajri,Osama Abdullah,Nader Masmoudi*

Main category: cs.CL

TL;DR: 现有ASR模型难以准确识别阿拉伯语孤立字母。通过新构建的语料库和训练方案，准确性显著提升，鲁棒性通过对抗训练进一步提高，相关数据代码已开放可复现。


<details>
  <summary>Details</summary>
Motivation: 现有的阿拉伯语ASR系统在单词和句子层面表现优异，但对孤立字母的识别能力较差，而孤立字母的识别对于语言学习、语音治疗和语音学研究至关重要。孤立字母由于缺乏协同发音线索、缺少词汇上下文且持续时间极短，给识别带来很大难度，尤其是阿拉伯语中特殊的咽化音和其他罕见音素。

Method: 本研究引入了一个多样、加注音符号的孤立阿拉伯语字母语料库，并利用wav2vec 2.0模型进行识别任务评估，通过在wav2vec嵌入的基础上训练轻量级神经网络来提升性能。此外，对模型进行了微小幅度扰动的鲁棒性测试，并通过对抗训练技术提升在噪音环境下的稳定性。

Result: wav2vec 2.0模型在该语料库上仅达到35%的准确率，训练轻量神经网络后提升至65%；但加入微小振幅扰动后准确率降至32%。采用对抗训练后，在噪声语音下准确率下滑仅为9%，同时保持干净语音的准确率。

Conclusion: 阿拉伯语孤立字母的ASR识别极具挑战，但通过优化的训练方法和对抗训练可以显著提升鲁棒性。所提出的语料库和管道对于进一步研究具有重要价值。

Abstract: Modern Arabic ASR systems such as wav2vec 2.0 excel at word- and
sentence-level transcription, yet struggle to classify isolated letters. In
this study, we show that this phoneme-level task, crucial for language
learning, speech therapy, and phonetic research, is challenging because
isolated letters lack co-articulatory cues, provide no lexical context, and
last only a few hundred milliseconds. Recogniser systems must therefore rely
solely on variable acoustic cues, a difficulty heightened by Arabic's emphatic
(pharyngealized) consonants and other sounds with no close analogues in many
languages. This study introduces a diverse, diacritised corpus of isolated
Arabic letters and demonstrates that state-of-the-art wav2vec 2.0 models
achieve only 35% accuracy on it. Training a lightweight neural network on
wav2vec embeddings raises performance to 65%. However, adding a small amplitude
perturbation (epsilon = 0.05) cuts accuracy to 32%. To restore robustness, we
apply adversarial training, limiting the noisy-speech drop to 9% while
preserving clean-speech accuracy. We detail the corpus, training pipeline, and
evaluation protocol, and release, on demand, data and code for reproducibility.
Finally, we outline future work extending these methods to word- and
sentence-level frameworks, where precise letter pronunciation remains critical.

</details>


### [38] [Understanding and Leveraging the Expert Specialization of Context Faithfulness in Mixture-of-Experts LLMs](https://arxiv.org/abs/2508.19594)
*Jun Bai,Minghao Tong,Yang Liu,Zixia Jia,Zilong Zheng*

Main category: cs.CL

TL;DR: 该论文提出Router Lens方法识别语境忠实专家，并提出选择性微调的CEFT方法，实验证明能以更高效率达到甚至超越整体微调效果。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在依赖给定语境进行推理时常出现输出偏离上下文的问题。受到专家混合架构中专家分工现象的启发，作者探索特定专家在语境利用上的专精，从而有针对性地提升模型的语境忠实度。

Method: 提出Router Lens方法对专家模块的语境忠实度进行识别，并据此选择性微调上下文忠实的专家模块（CEFT）。

Result: 通过在多个基准和模型上的实验，证明了CEFT方法在效率大幅提升下，达到或超过了全量微调的性能。

Conclusion: 提出的CEFT方法能够实现与全量微调同等或更优的性能，同时大大提升效率。

Abstract: Context faithfulness is essential for reliable reasoning in context-dependent
scenarios. However, large language models often struggle to ground their
outputs in the provided context, resulting in irrelevant responses. Inspired by
the emergent expert specialization observed in mixture-of-experts
architectures, this work investigates whether certain experts exhibit
specialization in context utilization, offering a potential pathway toward
targeted optimization for improved context faithfulness. To explore this, we
propose Router Lens, a method that accurately identifies context-faithful
experts. Our analysis reveals that these experts progressively amplify
attention to relevant contextual information, thereby enhancing context
grounding. Building on this insight, we introduce Context-faithful Expert
Fine-Tuning (CEFT), a lightweight optimization approach that selectively
fine-tunes context-faithful experts. Experiments across a wide range of
benchmarks and models demonstrate that CEFT matches or surpasses the
performance of full fine-tuning while being significantly more efficient.

</details>


### [39] [LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.19614)
*Yang Sun,Lixin Zou,Dan Luo,Zhiyong Xie,Long Zhang,Liming Dong,Yunwei Zhao,Xixun Lin,Yanxiong Lu,Chenliang Li*

Main category: cs.CL

TL;DR: 本论文揭示了大型语言模型分层处理外部知识的机制，提出了一种将中间层与最终解码融合的新方法LFD，有效提升了RAG系统检索知识的利用率和生成质量。


<details>
  <summary>Details</summary>
Motivation: 尽管往检索到的文档注入噪音有助于提升LLM利用外部知识的能力，但原因并不明确且实际应用受限，因此需要更精细地理解和调控LLM的分层知识整合机制。

Method: 分析LLM不同层对外部知识的集成机制，提出了Layer Fused Decoding策略，将中间层与最终解码层融合，并通过内部知识评分（IKS）自动选择最优融合层。

Result: LFD策略在多个基准测试上均表现优异，能更充分地利用检索获得的外部知识，成本低效率高。

Conclusion: LFD解码策略可以有效提升RAG系统对检索到的外部知识的利用，提升生成效果且成本较低。

Abstract: Retrieval-augmented generation (RAG) incorporates external knowledge into
large language models (LLMs), improving their adaptability to downstream tasks
and enabling information updates. Surprisingly, recent empirical evidence
demonstrates that injecting noise into retrieved relevant documents
paradoxically facilitates exploitation of external knowledge and improves
generation quality. Although counterintuitive and challenging to apply in
practice, this phenomenon enables granular control and rigorous analysis of how
LLMs integrate external knowledge. Therefore, in this paper, we intervene on
noise injection and establish a layer-specific functional demarcation within
the LLM: shallow layers specialize in local context modeling, intermediate
layers focus on integrating long-range external factual knowledge, and deeper
layers primarily rely on parametric internal knowledge. Building on this
insight, we propose Layer Fused Decoding (LFD), a simple decoding strategy that
directly combines representations from an intermediate layer with final-layer
decoding outputs to fully exploit the external factual knowledge. To identify
the optimal intermediate layer, we introduce an internal knowledge score (IKS)
criterion that selects the layer with the lowest IKS value in the latter half
of layers. Experimental results across multiple benchmarks demonstrate that LFD
helps RAG systems more effectively surface retrieved context knowledge with
minimal cost.

</details>


### [40] [A Symbolic Adversarial Learning Framework for Evolving Fake News Generation and Detection](https://arxiv.org/abs/2508.19633)
*Chong Tian,Qirong Ho,Xiuying Chen*

Main category: cs.CL

TL;DR: 提出SALF框架，通过代理之间的象征性争辩对抗，模拟学习优化并提升虚假新闻检测效果。SALF生成的虚假新闻可极大削弱现有检测器性能，同时促进检测器进化，提升对复杂虚假内容的识别能力。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型的发展加剧了自动生成高质量虚假新闻的风险，现有检测方法难以应对内容动态演化，亟需新的检测框架提升应对能力。

Method: 提出Symbolic Adversarial Learning Framework (SALF)，通过生成与检测代理之间的象征性学习与争辩对抗，实现非数值方式的对抗训练，并用可学习的提示而非参数权重进行优化。实验在多语言数据集上进行验证。

Result: SALF生成的虚假新闻显著削弱现有检测器对新型内容的识别能力（中文降至53.4%、英文降至34.2%），同时在多轮对抗迭代下，可增强检测器识别能力最多提升7.7%。

Conclusion: SALF能生成高度复杂的虚假新闻，并促使检测模型不断优化和提升针对新型虚假内容的检测能力。该框架为未来更健壮和适应性强的虚假新闻检测系统提供了新思路。

Abstract: Rapid LLM advancements heighten fake news risks by enabling the automatic
generation of increasingly sophisticated misinformation. Previous detection
methods, including fine-tuned small models or LLM-based detectors, often
struggle with its dynamically evolving nature. In this work, we propose a novel
framework called the Symbolic Adversarial Learning Framework (SALF), which
implements an adversarial training paradigm by an agent symbolic learning
optimization process, rather than relying on numerical updates. SALF introduces
a paradigm where the generation agent crafts deceptive narratives, and the
detection agent uses structured debates to identify logical and factual flaws
for detection, and they iteratively refine themselves through such adversarial
interactions. Unlike traditional neural updates, we represent agents using
agent symbolic learning, where learnable weights are defined by agent prompts,
and simulate back-propagation and gradient descent by operating on natural
language representations of weights, loss, and gradients. Experiments on two
multilingual benchmark datasets demonstrate SALF's effectiveness, showing it
generates sophisticated fake news that degrades state-of-the-art detection
performance by up to 53.4% in Chinese and 34.2% in English on average. SALF
also refines detectors, improving detection of refined content by up to 7.7%.
We hope our work inspires further exploration into more robust, adaptable fake
news detection systems.

</details>


### [41] [Automatic integration of SystemC in the FMI standard for Software-defined Vehicle design](https://arxiv.org/abs/2508.19665)
*Giovanni Pollo,Andrei Mihai Albu,Alessio Burrello,Daniele Jahier Pagliari,Cristian Tesconi,Loris Panaro,Dario Soldi,Fabio Autieri,Sara Vinco*

Main category: cs.CL

TL;DR: 本文提出一种自动将SystemC模型包装为FMI标准的方法，有效提升了嵌入式系统的协同仿真集成性和安全性，并在实际案例中验证了其对复杂设计的适用性。


<details>
  <summary>Details</summary>
Motivation: 汽车行业的持续发展需要强大的协同仿真方法，实现硬件与软件的提前验证和无缝集成。然而，目前缺乏标准化接口以及专有仿真平台的主导地位，阻碍了协作、可扩展性和知识产权保护。

Method: 提出将SystemC模型通过Functional Mock-up Interface（FMI）标准进行自动包装的方法，以实现互操作性和封装性。这样既保留了SystemC的建模精度和快速上市优势，也融合了FMI的集成便利性。

Result: 将该方法应用于实际案例研究，显示在处理复杂设计时具有很好的有效性。

Conclusion: 通过将SystemC与FMI结合，本文方法实现了嵌入式组件在协同仿真流程中的安全、可移植集成，有效促进了早期验证和跨平台协作。

Abstract: The recent advancements of the automotive sector demand robust co-simulation
methodologies that enable early validation and seamless integration across
hardware and software domains. However, the lack of standardized interfaces and
the dominance of proprietary simulation platforms pose significant challenges
to collaboration, scalability, and IP protection. To address these limitations,
this paper presents an approach for automatically wrapping SystemC models by
using the Functional Mock-up Interface (FMI) standard. This method combines the
modeling accuracy and fast time-to-market of SystemC with the interoperability
and encapsulation benefits of FMI, enabling secure and portable integration of
embedded components into co-simulation workflows. We validate the proposed
methodology on real-world case studies, demonstrating its effectiveness with
complex designs.

</details>


### [42] [Survey of Specialized Large Language Model](https://arxiv.org/abs/2508.19667)
*Chenghan Yang,Ruiyu Zhao,Yang Liu,Ling Jiang*

Main category: cs.CL

TL;DR: 该论文系统回顾了专业领域大型语言模型的发展与技术突破，总结了专业架构、多模态能力与参数优化等方面的创新如何提升专业应用效果，尤其对电商领域的发展具有指导意义。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的发展，其应用已经从简单的领域适配转变为复杂的原生架构，推动了人工智能领域的范式变革。该综述旨在系统性分析专业领域（如医疗、金融、法律和技术）的LLMs演进过程。

Method: 本文采用系统综述的方法，聚焦于医疗、金融、法律和技术领域LLMs的发展，并分析了技术突破（如超越微调的领域原生架构、稀疏计算与量化的参数效率、多模态能力集成等）。

Result: 分析显示，专业化LLM能够有效解决通用LLM在专业应用中的根本性局限性，并且在领域专属基准测试中持续实现性能提升。同时，针对电商领域，本文重点指出专业LLM的发展可弥补该领域的技术短板。

Conclusion: 专业领域大型语言模型在特定应用场景表现优异，并通过架构创新、大幅提升参数效率、多模态能力等，持续推动领域技术进步，尤其对电商等应用场景有突出意义。

Abstract: The rapid evolution of specialized large language models (LLMs) has
transitioned from simple domain adaptation to sophisticated native
architectures, marking a paradigm shift in AI development. This survey
systematically examines this progression across healthcare, finance, legal, and
technical domains. Besides the wide use of specialized LLMs, technical
breakthrough such as the emergence of domain-native designs beyond fine-tuning,
growing emphasis on parameter efficiency through sparse computation and
quantization, increasing integration of multimodal capabilities and so on are
applied to recent LLM agent. Our analysis reveals how these innovations address
fundamental limitations of general-purpose LLMs in professional applications,
with specialized models consistently performance gains on domain-specific
benchmarks. The survey further highlights the implications for E-Commerce field
to fill gaps in the field.

</details>


### [43] [Building Task Bots with Self-learning for Enhanced Adaptability, Extensibility, and Factuality](https://arxiv.org/abs/2508.19689)
*Xiaoying Zhang*

Main category: cs.CL

TL;DR: 本文探索了无需人工干预即可实现对话任务机器人自适应与进化的方法，分析了实现过程中的难题及创新方案。


<details>
  <summary>Details</summary>
Motivation: 如何在最少甚至零人工干预下，开发高效且可扩展的对话任务机器人，是当前对话系统领域亟需解决的重大挑战。

Method: 论文主要聚焦于创新技术，让对话机器人能够在不断变化的环境中自主学习与适应。

Result: 提出了一些支持机器人自主学习与适应性的前沿技术，并讨论了它们解决关键难题的可行性。

Conclusion: 本论文总结了在实现可自适应、可扩展并且准确的任务型机器人过程中面临的障碍，并对相关创新解决方案进行探讨。

Abstract: Developing adaptable, extensible, and accurate task bots with minimal or zero
human intervention is a significant challenge in dialog research. This thesis
examines the obstacles and potential solutions for creating such bots, focusing
on innovative techniques that enable bots to learn and adapt autonomously in
constantly changing environments.

</details>


### [44] [Continuously Steering LLMs Sensitivity to Contextual Knowledge with Proxy Models](https://arxiv.org/abs/2508.19720)
*Yilin Wang,Heng Wang,Yuyang Bai,Minnan Luo*

Main category: cs.CL

TL;DR: 本文提出CSKS框架，能低成本、无侵入地连续调控大语言模型对上下文知识的敏感度，并通过大量实验验证了其实用性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在生成过程中常常会遇到内置知识和上下文知识之间的冲突。现有方法如参数微调、解码算法或定位并编辑上下文相关神经元，虽能一定程度上缓解问题，但普遍存在效率低、适用范围有限、难以对黑盒模型操作或无法持续调整对上下文知识敏感度等不足。

Method: 提出了一种名为CSKS（Continuously Steering Knowledge Sensitivity）的新框架，无需修改原有LLM参数，通过训练两个小型代理语言模型，并利用它们输出分布的差异，动态调整LLM对上下文知识的敏感度，操作轻量且高效。

Result: 通过构造合成数据、细粒度指标和真实冲突数据集进行评测，实验结果显示，CSKS可实现LLM对上下文知识敏感度的连续、精确控制，既能增强也能减弱对上下文知识的响应，从而灵活地在上下文知识与参数知识间调整优先级。

Conclusion: CSKS框架能够高效、灵活、精细地控制大语言模型对上下文知识的敏感度，无需更改模型参数，适用于大模型甚至黑盒模型场景，极大提升了模型在矛盾知识情景下的适应能力和实用价值。

Abstract: In Large Language Models (LLMs) generation, there exist knowledge conflicts
and scenarios where parametric knowledge contradicts knowledge provided in the
context. Previous works studied tuning, decoding algorithms, or locating and
editing context-aware neurons to adapt LLMs to be faithful to new contextual
knowledge. However, they are usually inefficient or ineffective for large
models, not workable for black-box models, or unable to continuously adjust
LLMs' sensitivity to the knowledge provided in the context. To mitigate these
problems, we propose CSKS (Continuously Steering Knowledge Sensitivity), a
simple framework that can steer LLMs' sensitivity to contextual knowledge
continuously at a lightweight cost. Specifically, we tune two small LMs (i.e.
proxy models) and use the difference in their output distributions to shift the
original distribution of an LLM without modifying the LLM weights. In the
evaluation process, we not only design synthetic data and fine-grained metrics
to measure models' sensitivity to contextual knowledge but also use a real
conflict dataset to validate CSKS's practical efficacy. Extensive experiments
demonstrate that our framework achieves continuous and precise control over
LLMs' sensitivity to contextual knowledge, enabling both increased sensitivity
and reduced sensitivity, thereby allowing LLMs to prioritize either contextual
or parametric knowledge as needed flexibly. Our data and code are available at
https://github.com/OliveJuiceLin/CSKS.

</details>


### [45] [CAMÕES: A Comprehensive Automatic Speech Recognition Benchmark for European Portuguese](https://arxiv.org/abs/2508.19721)
*Carlos Carvalho,Francisco Teixeira,Catarina Botelho,Anna Pompili,Rubén Solera-Ureña,Sérgio Paulo,Mariana Julião,Thomas Rolland,John Mendonça,Diogo Pereira,Isabel Trancoso,Alberto Abad*

Main category: cs.CL

TL;DR: 针对欧洲葡萄牙语资源匮乏问题，本文提出了首个开放评测与模型框架CAMÕES，利用大规模数据和多种模型显著提升了EP语音识别性能，并刷新了该领域的研究新纪录。


<details>
  <summary>Details</summary>
Motivation: 目前自动语音识别（ASR）资源主要集中于巴西葡萄牙语，而欧洲葡萄牙语（EP）及其他变体研究较少，亟需填补这一领域的空白。

Method: 提出了CAMÕES，这是首个面向欧洲葡萄牙语及其他变体的开放框架。包括46小时多领域EP测试集评测基准和一组最先进的模型，涵盖多种基础模型及E-Branchformer模型，采用425小时EP语音数据进行微调和训练，并比较了其在零样本和微调下的表现。

Result: 微调基础模型与E-Branchformer模型在EP任务上的性能相当；最佳模型较最强零样本基础模型在识别错误率（WER）上提升超过35%，为欧洲葡萄牙语及其他变体的语音识别建立了新标杆。

Conclusion: CAMÕES工具包有效提升了欧洲葡萄牙语及其他变体的语音识别性能，为该领域研究和应用提供了坚实基础。

Abstract: Existing resources for Automatic Speech Recognition in Portuguese are mostly
focused on Brazilian Portuguese, leaving European Portuguese (EP) and other
varieties under-explored. To bridge this gap, we introduce CAM\~OES, the first
open framework for EP and other Portuguese varieties. It consists of (1) a
comprehensive evaluation benchmark, including 46h of EP test data spanning
multiple domains; and (2) a collection of state-of-the-art models. For the
latter, we consider multiple foundation models, evaluating their zero-shot and
fine-tuned performances, as well as E-Branchformer models trained from scratch.
A curated set of 425h of EP was used for both fine-tuning and training. Our
results show comparable performance for EP between fine-tuned foundation models
and the E-Branchformer. Furthermore, the best-performing models achieve
relative improvements above 35% WER, compared to the strongest zero-shot
foundation model, establishing a new state-of-the-art for EP and other
varieties.

</details>


### [46] [NLKI: A lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks](https://arxiv.org/abs/2508.19724)
*Aritra Dutta,Swapnanil Mukherjee,Deepanway Ghosal,Somak Aditya*

Main category: cs.CL

TL;DR: 提出了利用检索+生成自然语言解释的方法，提升小型视觉语言模型的常识问答能力，准确率提升最高7%，抗噪微调进一步增益2.5%-5.5%，参数高效的小模型常识推理已可实现。


<details>
  <summary>Details</summary>
Motivation: 目前小型视觉语言模型（sVLMs）在常识视觉问答任务中表现逊于大型生成式模型，主要原因是图像或问题本身缺乏关键信息。作者希望通过更精细地整合外部常识知识来改善小模型的表现。

Method: 提出了端到端框架NLKI，包括（i）检索自然语言事实，（ii）利用大语言模型（LLM）生成自然语言解释，（iii）将检索到的信息和解释输入到sVLMs，分别在CRIC、AOKVQA两个常识问答数据集及视觉蕴含数据集e-SNLI-VE上验证。事实检索使用微调的ColBERTv2和带物体信息的提示词；同时尝试了抗噪声损失函数（如对称交叉熵和广义交叉熵）进行额外微调。

Result: 通过自然语言事实检索与解释生成，可减少模型幻觉，提高端到端答题准确率最高达7%；噪声鲁棒损失函数微调进一步提升CRIC、AOKVQA数据集的准确率分别为2.5%、5.5%；FLAVA等小模型在NLKI框架下能够达到甚至超越部分中等规模模型（如Qwen-2 VL-2B和SmolVLM-2.5B）的性能。

Conclusion: 通过合理整合和增强外部常识知识，小型视觉语言模型可以在参数高效的情况下达到与中等规模模型相媲美的常识推理表现。噪声感知训练和LLM生成的解释对于稳定和提升小模型的能力尤为关键。

Abstract: Commonsense visual-question answering often hinges on knowledge that is
missing from the image or the question. Small vision-language models (sVLMs)
such as ViLT, VisualBERT and FLAVA therefore lag behind their larger generative
counterparts. To study the effect of careful commonsense knowledge integration
on sVLMs, we present an end-to-end framework (NLKI) that (i) retrieves natural
language facts, (ii) prompts an LLM to craft natural language explanations, and
(iii) feeds both signals to sVLMs respectively across two commonsense VQA
datasets (CRIC, AOKVQA) and a visual-entailment dataset (e-SNLI-VE). Facts
retrieved using a fine-tuned ColBERTv2 and an object information-enriched
prompt yield explanations that largely cut down hallucinations, while lifting
the end-to-end answer accuracy by up to 7% (across 3 datasets), making FLAVA
and other models in NLKI match or exceed medium-sized VLMs such as Qwen-2 VL-2B
and SmolVLM-2.5B. As these benchmarks contain 10-25% label noise, additional
finetuning using noise-robust losses (such as symmetric cross entropy and
generalised cross entropy) adds another 2.5% in CRIC, and 5.5% in AOKVQA. Our
findings expose when LLM-based commonsense knowledge beats retrieval from
commonsense knowledge bases, how noise-aware training stabilises small models
in the context of external knowledge augmentation, and why parameter-efficient
commonsense reasoning is now within reach for 250M models.

</details>


### [47] [Spotlight Attention: Towards Efficient LLM Generation via Non-linear Hashing-based KV Cache Retrieval](https://arxiv.org/abs/2508.19740)
*Wenhao Li,Yuxin Zhang,Gen Luo,Haiyuan Wan,Ziyang Gong,Fei Chao,Rongrong Ji*

Main category: cs.CL

TL;DR: 论文提出非线性哈希方法Spotlight Attention，大幅提升KV缓存检索效率和推理速度，在实际GPU上表现优秀。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在推理时KV缓存负担较重，减少KV缓存可以显著提升推理速度。现有方法用线性哈希选取重要缓存，但因查询和键分布不理想，效率低下。

Method: 提出了Spotlight Attention，一种利用非线性哈希优化queries和keys的嵌入分布的方法，并开发了基于Bradley-Terry排序损失的轻量训练框架，在16GB GPU上8小时内即可训练。CUDA核实现支持高效位操作。

Result: 实验表明，Spotlight Attention能极大提高检索精度，同时哈希码长度比传统线性哈希至少缩短5倍。通过专用CUDA内核，512K token的检索在A100 GPU上100微秒内完成，端到端吞吐吞吐量提升最高3倍。

Conclusion: Spotlight Attention显著优化了LLM推理KV缓存管理，既提升了检索精度，又加速了推理过程，有望广泛应用于高效LLM推理场景。

Abstract: Reducing the key-value (KV) cache burden in Large Language Models (LLMs)
significantly accelerates inference. Dynamically selecting critical KV caches
during decoding helps maintain performance. Existing methods use random linear
hashing to identify important tokens, but this approach is inefficient due to
the orthogonal distribution of queries and keys within two narrow cones in
LLMs. We introduce Spotlight Attention, a novel method that employs non-linear
hashing functions to optimize the embedding distribution of queries and keys,
enhancing coding efficiency and robustness. We also developed a lightweight,
stable training framework using a Bradley-Terry ranking-based loss, enabling
optimization of the non-linear hashing module on GPUs with 16GB memory in 8
hours. Experimental results show that Spotlight Attention drastically improves
retrieval precision while shortening the length of the hash code at least
5$\times$ compared to traditional linear hashing. Finally, we exploit the
computational advantages of bitwise operations by implementing specialized CUDA
kernels, achieving hashing retrieval for 512K tokens in under 100$\mu$s on a
single A100 GPU, with end-to-end throughput up to 3$\times$ higher than vanilla
decoding.

</details>


### [48] [Uncovering the Bigger Picture: Comprehensive Event Understanding Via Diverse News Retrieval](https://arxiv.org/abs/2508.19758)
*Yixuan Tang,Yuanyuan Shi,Yiqun Sun,Anthony Kum Hoe Tung*

Main category: cs.CL

TL;DR: NEWSCOPE通过句子级聚类与重排实现新闻检索结果的多样化，显著提升了信息互补性与事件覆盖广度，在相关性不下降的前提下优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 现有新闻检索系统通常只关注文本相关性，导致结果冗余且观点单一，不利于用户全面理解现实事件。为了解决这一问题，需要提升新闻检索结果的多样性，确保不同视角和补充信息被充分展现。

Method: 提出了NEWSCOPE两阶段检索框架：第一阶段利用密集检索获取主题相关内容，第二阶段通过句子级聚类与多样性重排，显式建模语义变异性，以呈现互补信息。并引入三项可解释性多样性评估指标（平均成对距离、正向聚类覆盖率、信息密度比），并构建了两个段落级基准数据集（LocalNews和DSGlobal）以评估系统性能。

Result: NEWSCOPE在实验中相比强基线系统，在多样性指标上显著更优，同时未损失相关性，证明了细粒度多样性建模对提升新闻事件覆盖的有效性。

Conclusion: 通过句子级的多样化建模与重排，NEWSCOPE能有效缓解新闻检索中的冗余现象，提升事件理解的全面性，并在多项指标和数据集上优于现有方法。

Abstract: Access to diverse perspectives is essential for understanding real-world
events, yet most news retrieval systems prioritize textual relevance, leading
to redundant results and limited viewpoint exposure. We propose NEWSCOPE, a
two-stage framework for diverse news retrieval that enhances event coverage by
explicitly modeling semantic variation at the sentence level. The first stage
retrieves topically relevant content using dense retrieval, while the second
stage applies sentence-level clustering and diversity-aware re-ranking to
surface complementary information. To evaluate retrieval diversity, we
introduce three interpretable metrics, namely Average Pairwise Distance,
Positive Cluster Coverage, and Information Density Ratio, and construct two
paragraph-level benchmarks: LocalNews and DSGlobal. Experiments show that
NEWSCOPE consistently outperforms strong baselines, achieving significantly
higher diversity without compromising relevance. Our results demonstrate the
effectiveness of fine-grained, interpretable modeling in mitigating redundancy
and promoting comprehensive event understanding. The data and code are
available at https://github.com/tangyixuan/NEWSCOPE.

</details>


### [49] [Principled Personas: Defining and Measuring the Intended Effects of Persona Prompting on Task Performance](https://arxiv.org/abs/2508.19764)
*Pedro Henrique Luz de Araujo,Paul Röttger,Dirk Hovy,Benjamin Roth*

Main category: cs.CL

TL;DR: 专家角色设定虽常用于提升LLM任务表现，但实际提升有限，且模型对角色细节敏感，轻微偏差即可能导致巨大性能下降。仅最大型模型能受益于缓解策略，未来需更严格设计角色及评估其实际效果。


<details>
  <summary>Details</summary>
Motivation: 目前广泛使用专家角色推动（persona prompting）对语言模型（LLMs）进行任务优化，但过往研究对其有效性结论不一，且较少探讨专家角色何时及为何能改善模型表现。本文旨在系统性分析专家角色推动的作用机制与条件。

Method: 梳理和总结现有专家角色推动相关文献，提出三个评价准则：1）专家角色的表现优势；2）对无关角色属性的鲁棒性；3）对角色属性的忠实度。使用9个最新LLM，在27项任务中基于上述准则进行系统实验评估。

Result: 实验发现，专家角色一般会带来正向或无显著影响的性能变化；令人意外的是，模型对无关角色属性极度敏感，性能可瞬间下降近30个百分点。忠实度方面发现，诸如高学历、专业化及领域相关性等可有助提升表现，但其效果在不同任务中并不一致或显著。提出了一些提升鲁棒性的缓解策略，但仅对最强大的模型有效。

Conclusion: 专家角色推动并非对所有任务均能提升表现，且模型对角色设定细节极为敏感。需更为谨慎地设计“专家”角色，并优化评估方法以真实反映角色设定的预期影响。

Abstract: Expert persona prompting -- assigning roles such as expert in math to
language models -- is widely used for task improvement. However, prior work
shows mixed results on its effectiveness, and does not consider when and why
personas should improve performance. We analyze the literature on persona
prompting for task improvement and distill three desiderata: 1) performance
advantage of expert personas, 2) robustness to irrelevant persona attributes,
and 3) fidelity to persona attributes. We then evaluate 9 state-of-the-art LLMs
across 27 tasks with respect to these desiderata. We find that expert personas
usually lead to positive or non-significant performance changes. Surprisingly,
models are highly sensitive to irrelevant persona details, with performance
drops of almost 30 percentage points. In terms of fidelity, we find that while
higher education, specialization, and domain-relatedness can boost performance,
their effects are often inconsistent or negligible across tasks. We propose
mitigation strategies to improve robustness -- but find they only work for the
largest, most capable models. Our findings underscore the need for more careful
persona design and for evaluation schemes that reflect the intended effects of
persona usage.

</details>


### [50] [T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables](https://arxiv.org/abs/2508.19813)
*Jie Zhang,Changzai Pan,Kaiwen Wei,Sishi Xiong,Yu Zhao,Xiangyu Li,Jiaxin Peng,Xiaoyan Gu,Jian Yang,Wenhan Chang,Zhenhe Wu,Jiang Zhong,Shuangyong Song,Yongxiang Li,Xuelong Li*

Main category: cs.CL

TL;DR: 本文提出了table-to-report任务和T2R-bench基准，评测发现现有大语言模型在工业表格到报告生成方面表现有限，T2R-bench有助于推动该领域进一步发展。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在表格推理方面取得了进展，但将表格信息转化为报告仍具有挑战，尤其在工业实际应用中存在复杂和多样性高的表格，且现有表格基准无法很好地衡量实际报告生成任务。

Method: 提出了table-to-report任务，并构建一个名为T2R-bench的双语基准，收集包含457个真实工业场景表格，涵盖19个行业领域和4种工业表格类型。同时，提出了新的评估标准来公平衡量报告生成质量。

Result: 在25种主流大语言模型上的实验结果显示，即使最先进的模型如Deepseek-R1在T2R-bench上的整体得分也仅为62.71，表明现有模型仍有较大提升空间。

Conclusion: T2R-bench为评估表格到报告生成任务提供了真实、丰富的基准，揭示了当前主流模型在该任务上的不足，为后续研究指明了方向。

Abstract: Extensive research has been conducted to explore the capabilities of large
language models (LLMs) in table reasoning. However, the essential task of
transforming tables information into reports remains a significant challenge
for industrial applications. This task is plagued by two critical issues: 1)
the complexity and diversity of tables lead to suboptimal reasoning outcomes;
and 2) existing table benchmarks lack the capacity to adequately assess the
practical application of this task. To fill this gap, we propose the
table-to-report task and construct a bilingual benchmark named T2R-bench, where
the key information flow from the tables to the reports for this task. The
benchmark comprises 457 industrial tables, all derived from real-world
scenarios and encompassing 19 industry domains as well as 4 types of industrial
tables. Furthermore, we propose an evaluation criteria to fairly measure the
quality of report generation. The experiments on 25 widely-used LLMs reveal
that even state-of-the-art models like Deepseek-R1 only achieves performance
with 62.71 overall score, indicating that LLMs still have room for improvement
on T2R-bench. Source code and data will be available after acceptance.

</details>


### [51] [Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning](https://arxiv.org/abs/2508.19828)
*Sikuan Yan,Xiufeng Yang,Zuchao Huang,Ercong Nie,Zifeng Ding,Zonggen Li,Xiaowen Ma,Hinrich Schütze,Volker Tresp,Yunpu Ma*

Main category: cs.CL

TL;DR: 本论文针对LLM长时推理受限于上下文窗口的问题，提出Memory-R1强化学习框架，实现主动外部记忆管理和利用。实验表明，即使训练数据极少，Memory-R1仍能优于现有方法，并在多场景下具备良好泛化性，为LLM记忆增强和智能推理提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）在许多自然语言处理任务中表现出色，但由于受限于上下文窗口，难以进行长时推理。现有解决方法多通过外部记忆增强，但缺乏学习机制来动态管理记忆。

Method: 提出Memory-R1，一个基于强化学习（RL）的框架，通过两个专用代理（Memory Manager和Answer Agent）实现LLM对外部记忆的主动管理和利用。代理采用PPO和GRPO进行结果驱动式微调，能够执行ADD、UPDATE、DELETE和NOOP等记忆操作，并在检索和推理过程中选择相关信息。

Result: Memory-R1仅用152条问答训练数据和相应的记忆库，即超越目前最先进的基线模型，并在多样问题类型和不同LLM主干上表现出强泛化能力。

Conclusion: 强化学习机制能显著提升LLM的记忆管理和推理能力，为实现更持久、更智能的推理系统提供了新方向。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities across
a wide range of NLP tasks, but they remain fundamentally stateless, constrained
by limited context windows that hinder long-horizon reasoning. Recent efforts
to address this limitation often augment LLMs with an external memory bank, yet
most existing pipelines are static and heuristic-driven, lacking any learned
mechanism for deciding what to store, update, or retrieve. We present
Memory-R1, a reinforcement learning (RL) framework that equips LLMs with the
ability to actively manage and utilize external memory through two specialized
agents: a Memory Manager that learns to perform structured memory operations
{ADD, UPDATE, DELETE, NOOP}, and an Answer Agent that selects the most relevant
entries and reasons over them to produce an answer. Both agents are fine-tuned
with outcome-driven RL (PPO and GRPO), enabling adaptive memory management and
use with minimal supervision. With as few as 152 question-answer pairs and a
corresponding temporal memory bank for training, Memory-R1 outperforms the most
competitive existing baseline and demonstrates strong generalization across
diverse question types and LLM backbones. Beyond presenting an effective
approach, this work provides insights into how RL can unlock more agentic,
memory-aware behaviors in LLMs, pointing toward richer, more persistent
reasoning systems.

</details>


### [52] [Benchmarking Hindi LLMs: A New Suite of Datasets and a Comparative Analysis](https://arxiv.org/abs/2508.19831)
*Anusha Kamath,Kanishk Singla,Rakesh Paul,Raviraj Joshi,Utkarsh Vaidya,Sanjay Singh Chauhan,Niranjan Wartikar*

Main category: cs.CL

TL;DR: 针对印地语缺乏高质量LLM评测数据集的问题，提出并构建了五个新数据集，通过人工标注和翻译-验证流程提升数据质量，并对开源LLMs进行了详尽对比分析，同时提供了低资源语言评测数据集的可复用构建方法。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏高质量用于评估指令调优大型语言模型（LLMs）在印地语环境下表现的标准数据集。英文数据集直接翻译无法体现印地语的语言和文化差异。

Method: 提出并构建了五个专用印地语LLM评测数据集，通过从头开始人工标注结合翻译-验证流程，有效保证数据质量和本地适应性。

Result: 利用新构建的数据集，对主流支持印地语的开源LLMs进行了广泛基准测试，并进行了详细的能力对比分析。同时，这套数据构建流程可为其它低资源语言基准提供复制范例。

Conclusion: 所提出的评测数据集和构建方法有效解决了印地语LLM评测难题，并推动了低资源语言领域评测基准的开发和标准化。

Abstract: Evaluating instruction-tuned Large Language Models (LLMs) in Hindi is
challenging due to a lack of high-quality benchmarks, as direct translation of
English datasets fails to capture crucial linguistic and cultural nuances. To
address this, we introduce a suite of five Hindi LLM evaluation datasets:
IFEval-Hi, MT-Bench-Hi, GSM8K-Hi, ChatRAG-Hi, and BFCL-Hi. These were created
using a methodology that combines from-scratch human annotation with a
translate-and-verify process. We leverage this suite to conduct an extensive
benchmarking of open-source LLMs supporting Hindi, providing a detailed
comparative analysis of their current capabilities. Our curation process also
serves as a replicable methodology for developing benchmarks in other
low-resource languages.

</details>


### [53] [Scalable and consistent few-shot classification of survey responses using text embeddings](https://arxiv.org/abs/2508.19836)
*Jonas Timmann Mjaaland,Markus Fleten Kreutzer,Halvor Tyseng,Rebeckah K. Fussell,Gina Passante,N. G. Holmes,Anders Malthe-Sørenssen,Tor Ole B. Odden*

Main category: cs.CL

TL;DR: 本文提出了一种结合文本嵌入的新方法，无需大量标注即可对开放式问卷反馈进行高效、一致的定性编码，实验证明方法与人工分析高度一致，可扩展至大数据集，并支持模型微调与数据集审计。


<details>
  <summary>Details</summary>
Motivation: 传统的开放式调查问卷定性分析方法耗时且易出现不一致，现有基于自然语言处理的解决方案对定性分析的适用性有限，比如需大量标注数据、打断既有工作流程或者结果不稳定。

Method: 提出了一种基于文本嵌入的分类框架，只需每个类别少量示例即可进行分类，并与标准定性分析流程兼容。通过与专家人工编码对比，在2899份开放式物理概念调查问卷数据上进行了基准测试。

Result: 该框架与专家人工编码的Cohen’s Kappa达0.74到0.83，表现出良好一致性。进一步通过微调嵌入模型提升了性能，并展示了该方法可用于审查历史数据集。

Conclusion: 基于文本嵌入的辅助编码方法能兼顾可解释性和大规模分析需求，为大规模演绎性定性分析提供了可行路径。

Abstract: Qualitative analysis of open-ended survey responses is a commonly-used
research method in the social sciences, but traditional coding approaches are
often time-consuming and prone to inconsistency. Existing solutions from
Natural Language Processing such as supervised classifiers, topic modeling
techniques, and generative large language models have limited applicability in
qualitative analysis, since they demand extensive labeled data, disrupt
established qualitative workflows, and/or yield variable results. In this
paper, we introduce a text embedding-based classification framework that
requires only a handful of examples per category and fits well with standard
qualitative workflows. When benchmarked against human analysis of a conceptual
physics survey consisting of 2899 open-ended responses, our framework achieves
a Cohen's Kappa ranging from 0.74 to 0.83 as compared to expert human coders in
an exhaustive coding scheme. We further show how performance of this framework
improves with fine-tuning of the text embedding model, and how the method can
be used to audit previously-analyzed datasets. These findings demonstrate that
text embedding-assisted coding can flexibly scale to thousands of responses
without sacrificing interpretability, opening avenues for deductive qualitative
analysis at scale.

</details>


### [54] [TokenVerse++: Towards Flexible Multitask Learning with Dynamic Task Activation](https://arxiv.org/abs/2508.19856)
*Shashi Kumar,Srikanth Madikeri,Esaú Villatoro-Tello,Sergio Burdisso,Pradeep Rangappa,Andrés Carofilis,Petr Motlicek,Karthik Pandia,Shankar Venkatesan,Kadri Hacioğlu,Andreas Stolcke*

Main category: cs.CL

TL;DR: 文章提出TokenVerse++方法，允许多任务ASR训练中使用部分标注数据，通过引入动态任务激活机制，实现了与传统方法相当甚至更好的多任务表现，促进了大规模多任务学习的实际应用。


<details>
  <summary>Details</summary>
Motivation: 现有多任务学习框架（如TokenVerse）要求所有训练样本都具备所有任务标签，限制了部分标注数据的利用和扩展能力。

Method: 提出了一种在XLSR-Transducer ASR模型的声学嵌入空间引入可学习向量以动态激活任务的方法，使得训练可以在只有部分任务标签的语句上进行。

Result: 实验表明，TokenVerse++集成了仅有部分任务标签的数据后，在多任务上的表现与TokenVerse持平或有所提升，显示了更强实用性。

Conclusion: TokenVerse++能够在不损失ASR性能的前提下，有效利用部分标注的数据进行多任务训练，实用性更强。

Abstract: Token-based multitasking frameworks like TokenVerse require all training
utterances to have labels for all tasks, hindering their ability to leverage
partially annotated datasets and scale effectively. We propose TokenVerse++,
which introduces learnable vectors in the acoustic embedding space of the
XLSR-Transducer ASR model for dynamic task activation. This core mechanism
enables training with utterances labeled for only a subset of tasks, a key
advantage over TokenVerse. We demonstrate this by successfully integrating a
dataset with partial labels, specifically for ASR and an additional task,
language identification, improving overall performance. TokenVerse++ achieves
results on par with or exceeding TokenVerse across multiple tasks, establishing
it as a more practical multitask alternative without sacrificing ASR
performance.

</details>


### [55] [Beyond Shallow Heuristics: Leveraging Human Intuition for Curriculum Learning](https://arxiv.org/abs/2508.19873)
*Vanessa Toborek,Sebastian Müller,Tim Selbach,Tamás Horváth,Christian Bauckhage*

Main category: cs.CL

TL;DR: 论文表明，用人工区分的“简单”语言作为课程学习信号，有助于提升小型语言模型在简单语言上的训练效果，而自动启发式方法没有带来类似收益。


<details>
  <summary>Details</summary>
Motivation: 课程学习（Curriculum Learning, CL）试图通过从“简单”到“困难”地呈现数据来改善训练效果，但如何定义和测量语言难度始终是个难题。论文探索了能否用人工策划的简单语言作为CL的有效信号。

Method: 利用Simple Wikipedia语料库的文章级标签，将基于标签的课程与依赖浅表启发式的能力基课程策略进行对比。在BERT-tiny模型上进行实验，比较不同课程下的训练效果。

Result: 仅引入简单数据对于整体表现无明显益处，但通过课程结构化，特别是将简单数据优先呈现时，能持续提升在简单语言上的困惑度分数。反之，基于能力的课程策略未能优于随机排序，推测原因是无法有效区分两类数据。

Conclusion: 人工对语言难度的直觉可用于指导语言模型预训练中的课程学习设计。

Abstract: Curriculum learning (CL) aims to improve training by presenting data from
"easy" to "hard", yet defining and measuring linguistic difficulty remains an
open challenge. We investigate whether human-curated simple language can serve
as an effective signal for CL. Using the article-level labels from the Simple
Wikipedia corpus, we compare label-based curricula to competence-based
strategies relying on shallow heuristics. Our experiments with a BERT-tiny
model show that adding simple data alone yields no clear benefit. However,
structuring it via a curriculum -- especially when introduced first --
consistently improves perplexity, particularly on simple language. In contrast,
competence-based curricula lead to no consistent gains over random ordering,
probably because they fail to effectively separate the two classes. Our results
suggest that human intuition about linguistic difficulty can guide CL for
language model pre-training.

</details>


### [56] [AI-Powered Detection of Inappropriate Language in Medical School Curricula](https://arxiv.org/abs/2508.19883)
*Chiman Salavati,Shannon Song,Scott A. Hale,Roberto E. Montenegro,Shiri Dori-Hacohen,Fabricio Murai*

Main category: cs.CL

TL;DR: 面对医疗教材中大量不当用语筛查的挑战，本研究发现微调的小型语言模型比大语言模型能更有效识别和分类这些问题，尤其在优化负样本后可显著提升检测效果，有助于改善医疗教育的语言质量。


<details>
  <summary>Details</summary>
Motivation: 医疗教材中长期存在不当用词，如过时、排他或非患者中心的表达，会影响临床培训和健康结果。但鉴于教材内容庞大，人工系统性筛查此类用语既昂贵又不现实，因此需要自动化方法。

Method: 本研究评估了两类模型：第一类是基于标注数据微调的小型语言模型（SLMs），包括通用IUL分类器、子类别二元分类器、多标签分类器，以及两阶段层级管道模型。第二类是大语言模型（LLMs），主要利用不同的提示方式，包括定义和示例，进行上下文学习。

Result: 实验表明，尽管精心设计提示，大语言模型（如LLama-3 8B和70B）整体表现不如小型语言模型。在标注数据上，多标签分类器表现最佳，而用未被标记为不当的摘录做负样本训练，可以显著提升子类别分类器AUC至25%。这些提升使得相关SLM模型在医疗教材语言筛查上效果最优。

Conclusion: 微调的小型语言模型能显著优于当前预训练大语言模型，且通过优化负样本训练，可有效检测和分类医疗教材中的不当用语，有助于降低医疗教育中的有害表述。

Abstract: The use of inappropriate language -- such as outdated, exclusionary, or
non-patient-centered terms -- medical instructional materials can significantly
influence clinical training, patient interactions, and health outcomes. Despite
their reputability, many materials developed over past decades contain examples
now considered inappropriate by current medical standards. Given the volume of
curricular content, manually identifying instances of inappropriate use of
language (IUL) and its subcategories for systematic review is prohibitively
costly and impractical. To address this challenge, we conduct a first-in-class
evaluation of small language models (SLMs) fine-tuned on labeled data and
pre-trained LLMs with in-context learning on a dataset containing approximately
500 documents and over 12,000 pages. For SLMs, we consider: (1) a general IUL
classifier, (2) subcategory-specific binary classifiers, (3) a multilabel
classifier, and (4) a two-stage hierarchical pipeline for general IUL detection
followed by multilabel classification. For LLMs, we consider variations of
prompts that include subcategory definitions and/or shots. We found that both
LLama-3 8B and 70B, even with carefully curated shots, are largely outperformed
by SLMs. While the multilabel classifier performs best on annotated data,
supplementing training with unflagged excerpts as negative examples boosts the
specific classifiers' AUC by up to 25%, making them most effective models for
mitigating harmful language in medical curricula.

</details>


### [57] [Bangla-Bayanno: A 52K-Pair Bengali Visual Question Answering Dataset with LLM-Assisted Translation Refinement](https://arxiv.org/abs/2508.19887)
*Mohammed Rakibul Hasan,Rafi Majid,Ahanaf Tahmid*

Main category: cs.CL

TL;DR: 本文提出了Bangla-Bayanno，首个大规模高质量孟加拉语视觉问答数据集，涵盖52,650组QA对，创新采用LLM翻译精修流程，为低资源多模态AI研究提供了重要基准。


<details>
  <summary>Details</summary>
Motivation: 目前多模态AI研究中的视觉问答（VQA）数据集大多聚焦于高资源语言，低资源语言（如孟加拉语）的开放式VQA数据集匮乏，且已有数据集常受制于标注方式、领域和答案类型等限制。此外，现有多语种自动翻译容易带来低质量、含糊和错误。

Method: 采用多语言LLM辅助翻译精修流程，确保翻译质量和数据清晰性。数据集包含52,650对问题-答案，跨越4750余张图像。问题分为三类答案类型（短描述、数量型、是非型）。

Result: 成功构建了Bangla-Bayanno数据集，成为目前最全面、开源、高质量的孟加拉语视觉问答基准数据集。为低资源多模态学习和更包容AI系统的发展奠定了基础。

Conclusion: Bangla-Bayanno填补了低资源语言VQA领域的空白，提升了数据集质量，有利于多模态AI的研究和应用发展。

Abstract: In this paper, we introduce Bangla-Bayanno, an open-ended Visual Question
Answering (VQA) Dataset in Bangla, a widely used, low-resource language in
multimodal AI research. The majority of existing datasets are either manually
annotated with an emphasis on a specific domain, query type, or answer type or
are constrained by niche answer formats. In order to mitigate human-induced
errors and guarantee lucidity, we implemented a multilingual LLM-assisted
translation refinement pipeline. This dataset overcomes the issues of
low-quality translations from multilingual sources. The dataset comprises
52,650 question-answer pairs across 4750+ images. Questions are classified into
three distinct answer types: nominal (short descriptive), quantitative
(numeric), and polar (yes/no). Bangla-Bayanno provides the most comprehensive
open-source, high-quality VQA benchmark in Bangla, aiming to advance research
in low-resource multimodal learning and facilitate the development of more
inclusive AI systems.

</details>


### [58] [Logical Reasoning with Outcome Reward Models for Test-Time Scaling](https://arxiv.org/abs/2508.19903)
*Ramya Keerthy Thatikonda,Wray Buntine,Ehsan Shareghi*

Main category: cs.CL

TL;DR: 本文提出了一种结合链式思维和回声生成技术的数据增强方法，用于训练逻辑推理奖励模型，实验显示这种方法能提升大语言模型在逻辑推理任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 逻辑推理是评估大语言模型能力的关键之一，但现有用于复杂推理任务的结果导向奖励模型（Outcome Reward Models, ORMs）与测试时规模化策略，尚未充分应用于演绎逻辑推理中。作者希望填补这一空白。

Method: 提出并训练了一套用于演绎推理的结果奖励模型（ORMs），主要使用链式思维（CoT）方法生成单样本和多样本训练数据。同时，创新地引入了回声生成技术，使模型通过模仿错误假设来生成覆盖新型错误类型的数据，从而丰富训练集和改善模型能力。

Result: 在四种不同大语言模型上，ORMs在FOLIO、JustLogic和ProverQA等推理数据集上均取得了性能提升。

Conclusion: 引入回声生成技术并结合CoT数据训练的ORMs能够提升LLM在复杂演绎推理任务中的表现。

Abstract: Logical reasoning is a critical benchmark for evaluating the capabilities of
large language models (LLMs), as it reflects their ability to derive valid
conclusions from given premises. While the combination of test-time scaling
with dedicated outcome or process reward models has opened up new avenues to
enhance LLMs performance in complex reasoning tasks, this space is
under-explored in deductive logical reasoning. We present a set of Outcome
Reward Models (ORMs) for deductive reasoning. To train the ORMs we mainly
generate data using Chain-of-Thought (CoT) with single and multiple samples.
Additionally, we propose a novel tactic to further expand the type of errors
covered in the training dataset of the ORM. In particular, we propose an echo
generation technique that leverages LLMs' tendency to reflect incorrect
assumptions made in prompts to extract additional training data, covering
previously unexplored error types. While a standard CoT chain may contain
errors likely to be made by the reasoner, the echo strategy deliberately steers
the model toward incorrect reasoning. We show that ORMs trained on CoT and
echo-augmented data demonstrate improved performance on the FOLIO, JustLogic,
and ProverQA datasets across four different LLMs.

</details>


### [59] [Your AI Bosses Are Still Prejudiced: The Emergence of Stereotypes in LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2508.19919)
*Jingyu Guo,Yingying Xu*

Main category: cs.CL

TL;DR: 本研究通过模拟LLM多智能体职场交互，发现AI无初始偏见时也会自发形成刻板印象，并随交互增强并表现出类似人类的群体效应。这一现象在不同LLM架构下均普遍存在，提示AI偏见可能是交互涌现的结果，应关注其机制和伦理风险。


<details>
  <summary>Details</summary>
Motivation: 人类社会中刻板印象广泛存在，然而AI系统是否也会在无初始偏见情况下自发产生类似的偏见值得探究。此前关注的多为训练数据带来的偏差，本研究聚焦AI多智能体交互中刻板印象的自发生成。

Method: 设计了一个新颖的实验框架，模拟工作场景下LLM多智能体（AI代理）在无预设偏见条件下的互动，通过多轮交互、决策和引入层级制度，定量分析刻板印象的形成与演化过程。

Result: 1. 即使最初没有预设偏见，LLM AI代理在交互过程中仍然产生基于刻板印象的偏见；2. 交互轮数和决策权提升、特别是引入层级结构后，刻板印象效应增强；3. 系统呈现类似人类社会的群体效应，如晕轮效应、证实性偏差和角色适配性；4. 这些刻板印象模式在不同LLM结构下表现出一致性。

Conclusion: AI多智能体系统中的刻板印象可能是交互过程中的一种涌现现象，而不仅仅来源于训练数据偏差，需要进一步研究其内在机制，并制定应对相关伦理影响的策略。

Abstract: While stereotypes are well-documented in human social interactions, AI
systems are often presumed to be less susceptible to such biases. Previous
studies have focused on biases inherited from training data, but whether
stereotypes can emerge spontaneously in AI agent interactions merits further
exploration. Through a novel experimental framework simulating workplace
interactions with neutral initial conditions, we investigate the emergence and
evolution of stereotypes in LLM-based multi-agent systems. Our findings reveal
that (1) LLM-Based AI agents develop stereotype-driven biases in their
interactions despite beginning without predefined biases; (2) stereotype
effects intensify with increased interaction rounds and decision-making power,
particularly after introducing hierarchical structures; (3) these systems
exhibit group effects analogous to human social behavior, including halo
effects, confirmation bias, and role congruity; and (4) these stereotype
patterns manifest consistently across different LLM architectures. Through
comprehensive quantitative analysis, these findings suggest that stereotype
formation in AI systems may arise as an emergent property of multi-agent
interactions, rather than merely from training data biases. Our work
underscores the need for future research to explore the underlying mechanisms
of this phenomenon and develop strategies to mitigate its ethical impacts.

</details>


### [60] [HEAL: A Hypothesis-Based Preference-Aware Analysis Framework](https://arxiv.org/abs/2508.19922)
*Yifu Huo,Chenglong Wang,Qiren Zhu,Shunjie Xing,Tong Xiao,Chunliang Zhang,Tongran Liu,Jinbo Zhu*

Main category: cs.CL

TL;DR: HEAL框架通过假设空间重排序及新评价指标，完善偏好学习方法的评估流程，并用统一基准数据验证其高效性，为偏好对齐理论和实践提供新工具和研究思路。


<details>
  <summary>Details</summary>
Motivation: 现有偏好优化（如DPO）方法仅基于单一回应进行评估，忽略了其他可能输出，难以全面反映真实应用中模型表现，有必要开发能够覆盖假设空间的评估框架。

Method: 提出HEAL框架，将偏好对齐任务抽象为在假设空间中的重排序过程，并设定两个互补评价指标：排序准确率（评估序一致性）和偏好强度相关性（反映持续对齐程度）；并构建统一的UniHypoBench基准进行实验。

Result: 实验显示目前偏好学习方法能有效捕捉代理模型提供的偏好，并抑制负样本。HEAL分析揭示了现有方法的机制，并为更先进、能全面捕捉偏好的对齐算法指明了发展方向。

Conclusion: HEAL框架为偏好优化方法提供了更全面的评估机制，不仅考虑单一响应，还能覆盖假设空间中的多样输出，为未来的偏好学习和对齐算法指明了更完整的发展方向和新的研究范式。

Abstract: Preference optimization methods like DPO have achieved remarkable performance
in LLM alignment. However, the evaluation for these methods relies on a single
response and overlooks other potential outputs, which could also be generated
in real-world applications within this hypothetical space. To address this
issue, this paper presents a \textbf{H}ypothesis-based
Pr\textbf{E}ference-aware \textbf{A}na\textbf{L}ysis Framework (HEAL), a novel
evaluation paradigm that formulates preference alignment as a re-ranking
process within hypothesis spaces. The framework incorporates two complementary
metrics: ranking accuracy for evaluating ordinal consistency and preference
strength correlation for assessing continuous alignment. To facilitate this
framework, we develop UniHypoBench, a unified hypothesis benchmark constructed
from diverse instruction-response pairs. Through extensive experiments based on
HEAL, with a particular focus on the intrinsic mechanisms of preference
learning, we demonstrate that current preference learning methods can
effectively capture preferences provided by proxy models while simultaneously
suppressing negative samples. These findings contribute to preference learning
research through two significant avenues. Theoretically, we introduce
hypothesis space analysis as an innovative paradigm for understanding
preference alignment. Practically, HEAL offers researchers robust diagnostic
tools for refining preference optimization methods, while our empirical results
identify promising directions for developing more advanced alignment algorithms
capable of comprehensive preference capture.

</details>


### [61] [Dhati+: Fine-tuned Large Language Models for Arabic Subjectivity Evaluation](https://arxiv.org/abs/2508.19966)
*Slimane Bellaouar,Attia Nehar,Soumia Souffi,Mounia Bouameur*

Main category: cs.CL

TL;DR: 本文针对阿拉伯语主观性文本分类，构建了新数据集AraDhati+，微调了多种预训练语言模型并采用集成决策，最终取得了97.79%的高准确率，解决了阿拉伯语自然语言处理中主观性分析因数据有限的难题。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语虽然语言结构丰富，但由于缺乏大量经过标注的数据集，相应的主观性分析工具发展受限。本文旨在解决阿拉伯语自然语言处理中标注数据稀缺带来的挑战。

Method: 作者构建了一个新数据集AraDhati+，综合利用了现有阿拉伯语数据集（如ASTD、LABR、HARD和SANAD），并微调了三种主流阿拉伯语预训练语言模型（XLM-RoBERTa、AraBERT和ArabianGPT）。此外，还采用了模型集成决策方法以提升分类效果。

Result: 在阿拉伯语主观性分类任务上，提出的方法达到了97.79%的高准确率。

Conclusion: 通过新数据集和多模型集成，显著提升了阿拉伯语主观性文本分类的精度，有效缓解了阿拉伯语资源有限的问题。

Abstract: Despite its significance, Arabic, a linguistically rich and morphologically
complex language, faces the challenge of being under-resourced. The scarcity of
large annotated datasets hampers the development of accurate tools for
subjectivity analysis in Arabic. Recent advances in deep learning and
Transformers have proven highly effective for text classification in English
and French. This paper proposes a new approach for subjectivity assessment in
Arabic textual data. To address the dearth of specialized annotated datasets,
we developed a comprehensive dataset, AraDhati+, by leveraging existing Arabic
datasets and collections (ASTD, LABR, HARD, and SANAD). Subsequently, we
fine-tuned state-of-the-art Arabic language models (XLM-RoBERTa, AraBERT, and
ArabianGPT) on AraDhati+ for effective subjectivity classification.
Furthermore, we experimented with an ensemble decision approach to harness the
strengths of individual models. Our approach achieves a remarkable accuracy of
97.79\,\% for Arabic subjectivity classification. Results demonstrate the
effectiveness of the proposed approach in addressing the challenges posed by
limited resources in Arabic language processing.

</details>


### [62] [Diffusion Language Models Know the Answer Before Decoding](https://arxiv.org/abs/2508.19982)
*Pengxiang Li,Yefan Zhou,Dilxat Muhtar,Lu Yin,Shilin Yan,Li Shen,Yi Liang,Soroush Vosoughi,Shiwei Liu*

Main category: cs.CL

TL;DR: 本文发现DLMs生成序列时很早就能确定答案，据此提出Prophet解码技巧无需训练即可大幅减少推理步骤、提升推理速度且不损生成质量，对实际应用极具借鉴价值。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型（DLMs）虽然具备并行生成与灵活token顺序等优点，但在推理阶段速度不及自回归模型，主要原因是其需要双向注意力及多个高质量输出的反复精炼步骤。解决DLM生成速度慢的问题，成为亟需研究的动机。

Method: 作者首次发现DLMs存在早期答案收敛的特性，即在最终解码步骤前的半数步骤中，许多实例已可内部确定正确答案，并提出Prophet解码范式。Prophet不需额外训练，通过判断前两大预测候选的置信度差距，动态地选择是否继续精炼或一次性解码所有token，实现早期提交。该方法可无缝集成到现有DLM中，实现快解码，增量负担极小。

Result: 在GSM8K和MMLU任务上，多达97%和99%的样本在仅使用一半精炼步骤下即可正确解码。实验证明，在LLaDA-8B和Dream-7B等模型的多项任务中，Prophet能减少高达3.4倍的解码步骤，同时保持生成质量。

Conclusion: Prophet通过利用DLM的早期收敛属性，实现训练无关、几乎无额外开销的快速解码。它能显著加速DLM推理，并可与现有提速技术形成互补。该方法为DLM推理提供了新的思路，即通过动态决定停止采样时机，加速推理过程。

Abstract: Diffusion language models (DLMs) have recently emerged as an alternative to
autoregressive approaches, offering parallel sequence generation and flexible
token orders. However, their inference remains slower than that of
autoregressive models, primarily due to the cost of bidirectional attention and
the large number of refinement steps required for high quality outputs. In this
work, we highlight and leverage an overlooked property of DLMs early answer
convergence: in many cases, the correct answer can be internally identified by
half steps before the final decoding step, both under semi-autoregressive and
random remasking schedules. For example, on GSM8K and MMLU, up to 97% and 99%
of instances, respectively, can be decoded correctly using only half of the
refinement steps. Building on this observation, we introduce Prophet, a
training-free fast decoding paradigm that enables early commit decoding.
Specifically, Prophet dynamically decides whether to continue refinement or to
go "all-in" (i.e., decode all remaining tokens in one step), using the
confidence gap between the top-2 prediction candidates as the criterion. It
integrates seamlessly into existing DLM implementations, incurs negligible
overhead, and requires no additional training. Empirical evaluations of
LLaDA-8B and Dream-7B across multiple tasks show that Prophet reduces the
number of decoding steps by up to 3.4x while preserving high generation
quality. These results recast DLM decoding as a problem of when to stop
sampling, and demonstrate that early decode convergence provides a simple yet
powerful mechanism for accelerating DLM inference, complementary to existing
speedup techniques. Our code is publicly available at
https://github.com/pixeli99/Prophet.

</details>


### [63] [AgentCoMa: A Compositional Benchmark Mixing Commonsense and Mathematical Reasoning in Real-World Scenarios](https://arxiv.org/abs/2508.19988)
*Lisa Alazraki,Lihu Chen,Ana Brassard,Joe Stacey,Hossein A. Rahmani,Marek Rei*

Main category: cs.CL

TL;DR: 该论文提出了同时考验常识和数学推理的新基准AgentCoMa，发现主流LLMs在混合推理任务上表现大幅退化，远弱于人类，强调了其在真实多类型推理任务中的不足，并为该方向改进提供测试平台。


<details>
  <summary>Details</summary>
Motivation: 当前组合性推理基准只关注单一推理类型，但实际任务常需混合常识与数学推理。缺乏对LLMs在混合推理场景下能力的系统检验和诊断。

Method: 提出了AgentCoMa基准测试集，其中每项任务都包含常识和数学两步推理，并在61个不同规模、模型家族及训练策略的LLM上测试，进一步通过可解释性分析（如神经元模式、注意力图和成员推断）分析模型表现。

Result: LLMs在单项推理任务上能高准确率作答，但混合推理准确率平均下降约30%，远大于同类推理组合任务。相比之下，人类非专家可基本无性能下降地完成此类任务。

Conclusion: 当前的大语言模型（LLMs）在单独处理常识推理或数学推理时表现出色，但一旦任务需要将两者结合，即混合型组合推理，模型表现显著下降，显示出模型在实际复杂推理任务中的脆弱性。

Abstract: Large Language Models (LLMs) have achieved high accuracy on complex
commonsense and mathematical problems that involve the composition of multiple
reasoning steps. However, current compositional benchmarks testing these skills
tend to focus on either commonsense or math reasoning, whereas LLM agents
solving real-world tasks would require a combination of both. In this work, we
introduce an Agentic Commonsense and Math benchmark (AgentCoMa), where each
compositional task requires a commonsense reasoning step and a math reasoning
step. We test it on 61 LLMs of different sizes, model families, and training
strategies. We find that LLMs can usually solve both steps in isolation, yet
their accuracy drops by ~30% on average when the two are combined. This is a
substantially greater performance gap than the one we observe in prior
compositional benchmarks that combine multiple steps of the same reasoning
type. In contrast, non-expert human annotators can solve the compositional
questions and the individual steps in AgentCoMa with similarly high accuracy.
Furthermore, we conduct a series of interpretability studies to better
understand the performance gap, examining neuron patterns, attention maps and
membership inference. Our work underscores a substantial degree of model
brittleness in the context of mixed-type compositional reasoning and offers a
test bed for future improvement.

</details>


### [64] [MathBuddy: A Multimodal System for Affective Math Tutoring](https://arxiv.org/abs/2508.19993)
*Debanjana Kar,Leopold Böss,Dacia Braca,Sebastian Maximilian Dennerlein,Nina Christine Hubig,Philipp Wintersberger,Yufang Hou*

Main category: cs.CL

TL;DR: 本论文提出了一种情感感知的数学教学系统MathBuddy，结合学生的情感状态以提升教学效果。通过集成文本和面部表情感知，显著提高了AI导师的教学表现。


<details>
  <summary>Details</summary>
Motivation: 当前的学习模型忽略了学生的情感状态，而教育心理学研究证实情感对学习有显著影响。因此，作者希望打造一种能理解并响应学生情感的AI数学导师。

Method: 系统通过分析学生对话文本和面部表情，捕捉其情绪，并融合这些信息触发LLM导师做出情感响应，结合八个教学维度自动评测和用户研究进行效果评估。

Result: 在八个教学维度及用户研究中，MathBuddy在胜率指标提升了23分，在总分指标DAMR提升了3分，强烈证明情感建模能显著增强LLM导师的教学能力。

Conclusion: 通过建模学生情感并将其映射至针对性的教学策略，能让AI数学导师更具同理心，显著提升其教学表现，为未来教育技术提供了新的方向。

Abstract: The rapid adoption of LLM-based conversational systems is already
transforming the landscape of educational technology. However, the current
state-of-the-art learning models do not take into account the student's
affective states. Multiple studies in educational psychology support the claim
that positive or negative emotional states can impact a student's learning
capabilities. To bridge this gap, we present MathBuddy, an emotionally aware
LLM-powered Math Tutor, which dynamically models the student's emotions and
maps them to relevant pedagogical strategies, making the tutor-student
conversation a more empathetic one. The student's emotions are captured from
the conversational text as well as from their facial expressions. The student's
emotions are aggregated from both modalities to confidently prompt our LLM
Tutor for an emotionally-aware response. We have effectively evaluated our
model using automatic evaluation metrics across eight pedagogical dimensions
and user studies. We report a massive 23 point performance gain using the win
rate and a 3 point gain at an overall level using DAMR scores which strongly
supports our hypothesis of improving LLM-based tutor's pedagogical abilities by
modeling students' emotions.

</details>


### [65] [ReSURE: Regularizing Supervision Unreliability for Multi-turn Dialogue Fine-tuning](https://arxiv.org/abs/2508.19996)
*Yiming Du,Yifan Xiang,Bin Liang,Dahua Lin,Kam-Fai Wong,Fei Tan*

Main category: cs.CL

TL;DR: ReSURE动态抑制监督不可靠性，提升多轮对话系统的训练效果和响应质量，显著优于传统静态筛选方法。


<details>
  <summary>Details</summary>
Motivation: 多轮对话系统微调需高质量监督，但低质量数据导致性能下降，且早期监督错误会在后续回合中扩散影响，现有方法静态筛选难以应对监督不可靠性。

Method: 提出了ReSURE（Regularizing Supervision UnREliability）方法，利用Welford在线统计动态估算每回合损失分布，并实时对样本损失进行重新加权，避免了静态数据筛选和监督错误的连锁传播。

Result: 在单源和混合质量数据集上，ReSURE提升了训练稳定性和对话质量，多基准下响应分数与样本数量呈正Spearman相关，证明该方法利于大规模低质数据的有效利用。

Conclusion: ReSURE方法通过动态调整监督权重，有效应对多轮对话系统训练中的监督不可靠性，提高了模型稳定性和响应质量，为大规模数据利用铺平了道路。

Abstract: Fine-tuning multi-turn dialogue systems requires high-quality supervision but
often suffers from degraded performance when exposed to low-quality data.
Supervision errors in early turns can propagate across subsequent turns,
undermining coherence and response quality. Existing methods typically address
data quality via static prefiltering, which decouples quality control from
training and fails to mitigate turn-level error propagation. In this context,
we propose ReSURE (Regularizing Supervision UnREliability), an adaptive
learning method that dynamically down-weights unreliable supervision without
explicit filtering. ReSURE estimates per-turn loss distributions using
Welford's online statistics and reweights sample losses on the fly accordingly.
Experiments on both single-source and mixed-quality datasets show improved
stability and response quality. Notably, ReSURE enjoys positive Spearman
correlations (0.21 ~ 1.0 across multiple benchmarks) between response scores
and number of samples regardless of data quality, which potentially paves the
way for utilizing large-scale data effectively. Code is publicly available at
https://github.com/Elvin-Yiming-Du/ReSURE_Multi_Turn_Training.

</details>


### [66] [Selective Retrieval-Augmentation for Long-Tail Legal Text Classification](https://arxiv.org/abs/2508.19997)
*Boheng Mao*

Main category: cs.CL

TL;DR: 针对法律文本分类中的长尾分布标签问题，作者提出了选择性检索增强方法，无需改动模型结构，仅增强稀有类别样本。在两个基准数据集上，该方法显著提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 法律文本分类任务在实际数据中常常存在标签分布长尾现象，少数标签样本很少，导致模型在稀有类别上的性能较差。

Method: 提出了选择性检索增强（SRA）方法，仅对训练集低频标签样本进行增强，不改变模型结构，也不引入外部语料，只利用训练数据避免信息泄漏和噪声。

Result: 在LEDGAR（单标签）和UNFAIR-ToS（多标签）两个长尾分布法律文本分类基准数据集上测试，SRA在micro-F1和macro-F1评分上都优于当前所有LexGLUE基线方法。

Conclusion: SRA方法在法律文本分类（尤其是长尾分布场景）中能显著提升模型对稀有类别的分类表现且易于集成。

Abstract: Legal text classification is a fundamental NLP task in the legal domain.
Benchmark datasets in this area often exhibit a long-tail label distribution,
where many labels are underrepresented, leading to poor model performance on
rare classes. This paper proposes Selective Retrieval-Augmentation (SRA) as a
solution to this problem. SRA focuses on augmenting samples belonging to
low-frequency labels in the training set, preventing the introduction of noise
for well-represented classes, and requires no changes to the model
architecture. Retrieval is performed only from the training data to ensure
there is no potential information leakage, removing the need for external
corpora simultaneously. The proposed SRA method is tested on two legal text
classification benchmark datasets with long-tail distributions: LEDGAR
(single-label) and UNFAIR-ToS (multi-label). The results indicate that SRA
attains higher micro-F1 and macro-F1 scores compared to all current LexGLUE
baselines across both datasets, illustrating consistent improvements in
long-tail legal text classification. The code repository is available at:
https://github.com/Boheng-Mao/sra-legal

</details>


### [67] [DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis](https://arxiv.org/abs/2508.20033)
*Liana Patel,Negar Arabzadeh,Harshit Gupta,Ankita Sundar,Ion Stoica,Matei Zaharia,Carlos Guestrin*

Main category: cs.CL

TL;DR: 本文提出了用于生成式研究综述系统评估的新基准DeepScholar-bench，覆盖知识整合、检索和可验证性三大维度，并建立了强基线DeepScholar-base。实验表明任务具有高度挑战性，全部系统得分均低于19%，凸显本基准推动领域进步的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的问答基准主要关注简短的事实性回答，专家精心编制的数据集也可能过时且易受数据污染，均无法反映现实研究综述任务的复杂性和不断变化的特点。因此，评估生成式研究综述系统仍然是一个开放性问题。

Method: 本研究提出DeepScholar-bench，这是一个用于评估生成式研究综述的动态基准和自动化综合评估框架。该基准从最近的高质量ArXiv论文中获取查询，聚焦于通过检索、整合和引用现有研究，生成论文“相关工作”部分。评估框架从知识合成、检索质量和可验证性三个维度综合评价系统表现。还开发了DeepScholar-base作为参考管道，并用该框架系统性测试了多个开源系统、搜索型AI、OpenAI的DeepResearch及DeepScholar-base。

Result: DeepScholar-base建立了强有力的基准，其性能相较于其他方法具有竞争力甚至更好。整体上，DeepScholar-bench仍远未饱和，所有方法在各项指标的总得分都未超过19%，显示了任务的挑战性和改进空间。

Conclusion: DeepScholar-bench为评估生成式研究综述能力提供了新的标准和工具，其难度和全面性对于推动相关AI系统研究具有重要意义。

Abstract: The ability to research and synthesize knowledge is central to human
expertise and progress. An emerging class of systems promises these exciting
capabilities through generative research synthesis, performing retrieval over
the live web and synthesizing discovered sources into long-form, cited
summaries. However, evaluating such systems remains an open challenge: existing
question-answering benchmarks focus on short-form factual responses, while
expert-curated datasets risk staleness and data contamination. Both fail to
capture the complexity and evolving nature of real research synthesis tasks. In
this work, we introduce DeepScholar-bench, a live benchmark and holistic,
automated evaluation framework designed to evaluate generative research
synthesis. DeepScholar-bench draws queries from recent, high-quality ArXiv
papers and focuses on a real research synthesis task: generating the related
work sections of a paper by retrieving, synthesizing, and citing prior
research. Our evaluation framework holistically assesses performance across
three key dimensions, knowledge synthesis, retrieval quality, and
verifiability. We also develop DeepScholar-base, a reference pipeline
implemented efficiently using the LOTUS API. Using the DeepScholar-bench
framework, we perform a systematic evaluation of prior open-source systems,
search AI's, OpenAI's DeepResearch, and DeepScholar-base. We find that
DeepScholar-base establishes a strong baseline, attaining competitive or higher
performance than each other method. We also find that DeepScholar-bench remains
far from saturated, with no system exceeding a score of $19\%$ across all
metrics. These results underscore the difficulty of DeepScholar-bench, as well
as its importance for progress towards AI systems capable of generative
research synthesis. We make our code available at
https://github.com/guestrin-lab/deepscholar-bench.

</details>


### [68] [Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks](https://arxiv.org/abs/2508.20038)
*Sheng Liu,Qiang Sheng,Danding Wang,Yang Li,Guang Yang,Juan Cao*

Main category: cs.CL

TL;DR: 该论文提出IMAGINE框架，通过生成分布逼近真实攻击的指令，增强安全训练语料，有效提高大模型抵御jailbreak攻击的能力，且不会损害模型性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLM）在拒绝恶意指令方面取得了一定进展，但实际应用中依然容易受到jailbreak攻击，即攻击者用与安全对齐语料分布不同的指令绕过限制。这暴露了训练数据和真实攻击之间的分布差距，导致开发者只能事后打补丁应对新攻击。

Method: 提出了IMAGINE合成框架，该方法通过分析嵌入空间分布，生成类似jailbreak的指令，从而弥补真实jailbreak与安全对齐语料之间的分布空白。IMAGINE采用迭代优化过程，不断扩展文本生成分布，通过合成数据增强安全对齐语料的覆盖度。

Result: IMAGINE生成的数据增强了安全对齐语料，并在Qwen2.5、Llama3.1和Llama3.2上大幅降低了攻击成功率，同时不影响模型的实用性。

Conclusion: IMAGINE通过合成逼真的jailbreak指令，提升了LLM对未知攻击的防御能力，为主动训练和提升模型安全性提供了新思路。

Abstract: Despite advances in improving large language model(LLM) to refuse to answer
malicious instructions, widely used LLMs remain vulnerable to jailbreak attacks
where attackers generate instructions with distributions differing from safety
alignment corpora. New attacks expose LLMs' inability to recognize unseen
malicious instructions, highlighting a critical distributional mismatch between
training data and real-world attacks that forces developers into reactive
patching cycles. To tackle this challenge, we propose IMAGINE, a synthesis
framework that leverages embedding space distribution analysis to generate
jailbreak-like instructions. This approach effectively fills the distributional
gap between authentic jailbreak patterns and safety alignment corpora. IMAGINE
follows an iterative optimization process that dynamically evolves text
generation distributions across iterations, thereby augmenting the coverage of
safety alignment data distributions through synthesized data examples. Based on
the safety-aligned corpus enhanced through IMAGINE, our framework demonstrates
significant decreases in attack success rate on Qwen2.5, Llama3.1, and Llama3.2
without compromising their utility.

</details>


### [69] [AraHealthQA 2025 Shared Task Description Paper](https://arxiv.org/abs/2508.20047)
*Hassan Alhuzali,Farah Shamout,Muhammad Abdul-Mageed,Chaimae Abouzahir,Mouath Abu-Daoud,Ashwag Alasmari,Walid Al-Eisawi,Renad Al-Monef,Ali Alqahtani,Lama Ayash,Nizar Habash,Leen Kharouf*

Main category: cs.CL

TL;DR: 该论文提出并组织了阿拉伯语健康问答共享任务（含心理健康与广泛医学领域），构建了多样化数据集和统一评测框架，推动了阿拉伯语医疗问答领域的进步，并对系统表现及未来发展进行了总结与展望。


<details>
  <summary>Details</summary>
Motivation: 为弥补阿拉伯语医疗问答优质资源的缺乏，促进面向真实医疗场景的多语言、高质量建模与评测。

Method: 提出了两个子任务（MentalQA和MedArabiQ）并配套多个评测子任务、标准化测评数据集及指标，支持多语种及文化敏感场景下的建模与评测。参与统计和基线系统也被详细阐述。

Result: 建立了多维度数据集和评测体系，吸引了广泛参与，推动了阿拉伯语健康问答技术的发展，并总结了现有系统的表现和未来展望。

Conclusion: 总结了不同基线系统在多任务、多领域下的表现趋势，并提出未来阿拉伯语健康问答任务的改进方向。

Abstract: We introduce {AraHealthQA 2025}, the {Comprehensive Arabic Health Question
Answering Shared Task}, held in conjunction with {ArabicNLP 2025} (co-located
with EMNLP 2025). This shared task addresses the paucity of high-quality Arabic
medical QA resources by offering two complementary tracks: {MentalQA}, focusing
on Arabic mental health Q\&A (e.g., anxiety, depression, stigma reduction), and
{MedArabiQ}, covering broader medical domains such as internal medicine,
pediatrics, and clinical decision making. Each track comprises multiple
subtasks, evaluation datasets, and standardized metrics, facilitating fair
benchmarking. The task was structured to promote modeling under realistic,
multilingual, and culturally nuanced healthcare contexts. We outline the
dataset creation, task design and evaluation framework, participation
statistics, baseline systems, and summarize the overall outcomes. We conclude
with reflections on the performance trends observed and prospects for future
iterations in Arabic health QA.

</details>


### [70] [11Plus-Bench: Demystifying Multimodal LLM Spatial Reasoning with Cognitive-Inspired Analysis](https://arxiv.org/abs/2508.20068)
*Chengzu Li,Wenshan Wu,Huanyu Zhang,Qingtao Li,Zeyu Gao,Yan Xia,José Hernández-Orallo,Ivan Vulić,Furu Wei*

Main category: cs.CL

TL;DR: 本文提出了面向大模型的空间推理评测框架与高质量数据集，实证分析表明MLLM目前虽有一定空间认知能力，但与人类表现仍有巨大差距。


<details>
  <summary>Details</summary>
Motivation: 目前针对MLLM的空间推理与感知能力缺乏系统性评估，而理解MLLM是否具备类人的空间认知对于推动模型能力提升具有重要意义。

Method: 提出了系统性评价框架，并建立了11Plus-Bench基准，其中包含基于真实空间智力标准测试改编的题目，同时配有专家逐项注释。通过对14个主流MLLM和人类进行实验证明，对比分析模型与人类在空间推理认知方面的表现。

Result: （1）MLLM在空间认知能力上有初步表现，认知努力与推理复杂度高度相关，与人类认知特征相似；（2）但整体性能远落后于人类，且在实例层面，模型的正确性表现随机，缺乏对抽象模式复杂性的适应性。

Conclusion: 现有的多模态大语言模型（MLLMs）在空间推理方面已经出现了初步的类人认知迹象，但它们与人类之间仍有较大性能差距，且模型的实例级表现较为随机，说明其空间推理能力尚有很大提升空间。

Abstract: For human cognitive process, spatial reasoning and perception are closely
entangled, yet the nature of this interplay remains underexplored in the
evaluation of multimodal large language models (MLLMs). While recent MLLM
advancements show impressive performance on reasoning, their capacity for
human-like spatial cognition remains an open question. In this work, we
introduce a systematic evaluation framework to assess the spatial reasoning
abilities of state-of-the-art MLLMs relative to human performance. Central to
our work is 11Plus-Bench, a high-quality benchmark derived from realistic
standardized spatial aptitude tests. 11Plus-Bench also features fine-grained
expert annotations of both perceptual complexity and reasoning process,
enabling detailed instance-level analysis of model behavior. Through extensive
experiments across 14 MLLMs and human evaluation, we find that current MLLMs
exhibit early signs of spatial cognition. Despite a large performance gap
compared to humans, MLLMs' cognitive profiles resemble those of humans in that
cognitive effort correlates strongly with reasoning-related complexity.
However, instance-level performance in MLLMs remains largely random, whereas
human correctness is highly predictable and shaped by abstract pattern
complexity. These findings highlight both emerging capabilities and limitations
in current MLLMs' spatial reasoning capabilities and provide actionable
insights for advancing model design.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [71] [An algorithm for accurate and simple-looking metaphorical maps](https://arxiv.org/abs/2508.19810)
*Eleni Katsanou,Tamara Mchedlidze,Antonios Symvonis,Thanos Tolias*

Main category: cs.DM

TL;DR: 本文提出了一种改进隐喻地图生成算法的方法，实现了更精确的面积分配和更普适的地图结构，实验验证了新算法可以大幅提高地图领域的表示精度。


<details>
  <summary>Details</summary>
Motivation: 现有隐喻地图生成算法在权重（面积）精确度和地图形状简洁性之间无法很好平衡，特别是在精确度方面有较大缺陷（最高可达30%误差）。因此，需要一种能够进一步提升面积准确性的算法，同时尽量保持地图形状的简洁性。

Method: 提出对现有算法的扩展，包括区域刚性（stiffness）概念及其动态调整以提升面积精确度、对狭窄通道处多边形点的压力施加权重系数以维持形状简洁，以及支持非三角化图（允许多区域交汇点和地图中引入“空洞”）。

Result: 实验表明，所提出的扩展算法能够以微小的简洁性牺牲，生成几乎完美面积精度的隐喻地图。

Conclusion: 论文成功提升了隐喻地图本体的面积表示精度，同时较好地保持了地图的简洁性，并扩展支持了更加一般的图结构，显著优于已有方法。

Abstract: "Metaphorical maps" or "contact representations" are visual representations
of vertex-weighted graphs that rely on the geographic map metaphor. The
vertices are represented by countries, the weights by the areas of the
countries, and the edges by contacts/ boundaries among them. The accuracy with
which the weights are mapped to areas and the simplicity of the polygons
representing the countries are the two classical optimization goals for
metaphorical maps. Mchedlidze and Schnorr [Metaphoric Maps for Dynamic
Vertex-weighted Graphs, EuroVis 2022] presented a force-based algorithm that
creates metaphorical maps that balance between these two optimization goals.
Their maps look visually simple, but the accuracy of the maps is far from
optimal - the countries' areas can vary up to 30% compared to required. In this
paper, we provide a multi-fold extension of the algorithm in [Metaphoric Maps
for Dynamic Vertex-weighted Graphs, EuroVis 2022]. More specifically:
  1. Towards improving accuracy: We introduce the notion of region stiffness
and suggest a technique for varying the stiffness based on the current pressure
of map regions.
  2. Towards maintaining simplicity: We introduce a weight coefficient to the
pressure force exerted on each polygon point based on whether the corresponding
point appears along a narrow passage.
  3. Towards generality: We cover, in contrast to [Metaphoric Maps for Dynamic
Vertex-weighted Graphs, EuroVis 2022], non-triangulated graphs. This is done by
either generating points where more than three regions meet or by introducing
holes in the metaphorical map.
  We perform an extended experimental evaluation that, among other results,
reveals that our algorithm is able to construct metaphorical maps with nearly
perfect area accuracy with a little sacrifice in their simplicity.

</details>
