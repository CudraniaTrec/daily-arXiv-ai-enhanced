{"id": "2506.19284", "categories": ["cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2506.19284", "abs": "https://arxiv.org/abs/2506.19284", "authors": ["Mohammad Hadi Shekarriz", "Dhananjay Thiruvady", "Asef Nazari", "Wilfried Imrich"], "title": "Local Search Improvements for Soft Happy Colouring", "comment": "33 pages, 17 figures, 2 tables", "summary": "For $0\\leq \\rho\\leq 1$ and a coloured graph $G$, a vertex $v$ is $\\rho$-happy\nif at least $\\rho \\deg(v)$ of its neighbours have the same colour as $v$. Soft\nhappy colouring of a partially coloured graph $G$ is the problem of finding a\nvertex colouring $\\sigma$ that preserves the precolouring and has the maximum\nnumber of $\\rho$-happy vertices. It is already known that this problem is\nNP-hard and directly relates to the community structure of the graphs; under a\ncertain condition on the proportion of happiness $\\rho$ and for graphs with\ncommunity structures, the induced colouring by communities can make all the\nvertices $\\rho$-happy. We show that when $0\\leq \\rho_1<\\rho_2\\leq 1$, a\ncomplete $\\rho_2$-happy colouring has a higher accuracy of community detection\nthan a complete $\\rho_1$-happy colouring. Moreover, when $\\rho$ is greater than\na threshold, it is unlikely for an algorithm to find a complete $\\rho$-happy\ncolouring with colour classes of almost equal sizes. Three local search\nalgorithms for soft happy colouring are proposed, and their performances are\ncompared with one another and other known algorithms. Among them, the\nlinear-time local search is shown to be not only very fast, but also a reliable\nalgorithm that can dramatically improve the number of $\\rho$-happy vertices.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86soft happy colouring\u95ee\u9898\uff0c\u63d0\u51fa\u4e09\u79cd\u5c40\u90e8\u641c\u7d22\u7b97\u6cd5\uff0c\u5e76\u5bf9\u6bd4\u5b83\u4eec\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u8f83\u5927\u03c1\u503c\u66f4\u6709\u5229\u4e8e\u793e\u533a\u68c0\u6d4b\u4f46\u66f4\u96be\u6c42\u89e3\u3002\u63d0\u51fa\u7684\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\u5341\u5206\u9ad8\u6548\u4e14\u6613\u53d6\u5f97\u4f18\u826f\u7ed3\u679c\u3002", "motivation": "\u5f53\u524d\u5173\u4e8ehappy colouring\u95ee\u9898\u5df2\u7ecf\u88ab\u8bc1\u660e\u4e3aNP-hard\uff0c\u5e76\u4e14\u8be5\u95ee\u9898\u548c\u56fe\u7684\u793e\u533a\u7ed3\u6784\u6709\u76f4\u63a5\u5173\u8054\uff0c\u7279\u522b\u662f\u5728\u7279\u5b9a\u7684happiness\u9608\u503c\u548c\u793e\u533a\u7ed3\u6784\u4e0b\uff0c\u793e\u533a\u7684\u67d3\u8272\u80fd\u591f\u4f7f\u6240\u6709\u9876\u70b9\u90fd\u6210\u4e3a\u03c1-happy\u3002\u7136\u800c\uff0c\u4e0d\u540c\u53c2\u6570\u3001\u7b97\u6cd5\u548c\u7ed3\u6784\u4e0b\u76f8\u5173\u7ed3\u8bba\u53ca\u6700\u4f18\u7b56\u7565\u5c1a\u4e0d\u5b8c\u5168\u6e05\u695a\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "method": "\u6587\u4e2d\u63d0\u51fa\u5e76\u5206\u6790\u4e86\u4e09\u79cd\u9488\u5bf9soft happy colouring\u7684\u5c40\u90e8\u641c\u7d22\u7b97\u6cd5\u3002\u540c\u65f6\uff0c\u5c06\u5b83\u4eec\u4e0e\u73b0\u6709\u7684\u7b97\u6cd5\u8fdb\u884c\u4e86\u6027\u80fd\u5bf9\u6bd4\u3002\u8fd8\u7406\u8bba\u4e0a\u63a2\u8ba8\u4e86\u8f83\u5927\u03c1\u503c\u4e0b\u5b8c\u5168\u03c1-happy\u67d3\u8272\u7684\u4e0d\u53ef\u80fd\u6027\uff0c\u4ee5\u53ca\u4e0d\u540c\u03c1\u503c\u5bf9\u793e\u533a\u68c0\u6d4b\u51c6\u786e\u7387\u7684\u5f71\u54cd\u3002", "result": "\u4e3b\u8981\u7ed3\u679c\u6709\uff1a1. \u8bc1\u660e\u4e86\u5f530\u2264\u03c11<\u03c12\u22641\u65f6\uff0c\u5b8c\u5168\u03c12-happy\u67d3\u8272\u80fd\u6bd4\u5b8c\u5168\u03c11-happy\u67d3\u8272\u5728\u793e\u533a\u68c0\u6d4b\u4e2d\u66f4\u51c6\u786e\uff1b2. \u5f53\u03c1\u8d85\u8fc7\u67d0\u4e00\u9608\u503c\u540e\uff0c\u51e0\u4e4e\u4e0d\u53ef\u80fd\u6784\u9020\u51fa\u8272\u7c7b\u89c4\u6a21\u63a5\u8fd1\u7684\u5b8c\u5168\u03c1-happy\u67d3\u8272\uff1b3. \u63d0\u51fa\u7684\u7ebf\u6027\u65f6\u95f4\u5c40\u90e8\u641c\u7d22\u7b97\u6cd5\u4e0d\u4ec5\u901f\u5ea6\u975e\u5e38\u5feb\uff0c\u8fd8\u80fd\u591f\u663e\u8457\u63d0\u5347\u03c1-happy\u9876\u70b9\u6570\u91cf\uff0c\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u901a\u8fc7\u4e0d\u540c\u53c2\u6570\u4e0b\u7684\u7406\u8bba\u5206\u6790\u548c\u7b97\u6cd5\u6bd4\u8f83\uff0c\u9a8c\u8bc1\u4e86\u63d0\u51fa\u7684\u7ebf\u6027\u65f6\u95f4\u5c40\u90e8\u641c\u7d22\u7b97\u6cd5\u5728soft happy colouring\u95ee\u9898\u4e2d\u7684\u9ad8\u6548\u6027\u4e0e\u53ef\u9760\u6027\u3002\u540c\u65f6\uff0c\u9610\u660e\u4e86\u4e0d\u540chappiness\u53c2\u6570\u5bf9\u793e\u533a\u68c0\u6d4b\u53ca\u53ef\u89e3\u6027\u7684\u5f71\u54cd\u3002"}}
{"id": "2506.19529", "categories": ["cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2506.19529", "abs": "https://arxiv.org/abs/2506.19529", "authors": ["Hande Tuncel Golpek", "Zeliha Kartal Yildiz", "Aysun Aytac"], "title": "Paired Disjunctive Domination Number of Middle Graphs", "comment": "12 pages, 0 figures", "summary": "The concept of domination in graphs plays a central role in understanding\nstructural properties and applications in network theory. In this study, we\nfocus on the paired disjunctive domination number in the context of middle\ngraphs, a transformation that captures both adjacency and incidence relations\nof the original graph. We begin by investigating this parameter for middle\ngraphs of several special graph classes, including path graphs, cycle graphs,\nwheel graphs, complete graphs, complete bipartite graphs, star graphs,\nfriendship graphs, and double star graphs. We then present general results by\nestablishing lower and upper bounds for the paired disjunctive domination\nnumber in middle graphs of arbitrary graphs, with particular emphasis on trees.\nAdditionally, we determine the exact value of the parameter for middle graphs\nobtained through the join operation. These findings contribute to the broader\nunderstanding of domination-type parameters in transformed graph structures and\noffer new insights into their combinatorial behavior.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u591a\u7c7b\u4e2d\u95f4\u56fe\u7684\u914d\u5bf9\u6790\u53d6\u652f\u914d\u6570\uff0c\u7ed9\u51fa\u5177\u4f53\u8ba1\u7b97\u3001\u4e00\u822c\u6027\u4e0a\u4e0b\u754c\u53ca\u67d0\u4e9b\u8fd0\u7b97\u4e0b\u7684\u7cbe\u786e\u8868\u8fbe\uff0c\u63a8\u8fdb\u4e86\u5bf9\u56fe\u652f\u914d\u53c2\u6570\u7684\u7406\u8bba\u7406\u89e3\u3002", "motivation": "\u56fe\u7684\u652f\u914d\uff08domination\uff09\u6982\u5ff5\u5728\u7406\u89e3\u7ed3\u6784\u6027\u8d28\u548c\u7f51\u7edc\u7406\u8bba\u5e94\u7528\u4e2d\u5177\u6709\u6838\u5fc3\u4f5c\u7528\u3002\u8be5\u6587\u732e\u5173\u6ce8\u4e2d\u95f4\u56fe\uff08middle graphs\uff09\u4e2d\u7684\u914d\u5bf9\u6790\u53d6\u652f\u914d\u6570\uff08paired disjunctive domination number\uff09\uff0c\u4ee5\u63ed\u793a\u5176\u5728\u56fe\u7ed3\u6784\u53d8\u6362\u540e\u7684\u7ec4\u5408\u6027\u8d28\u3002", "method": "\u9996\u5148\uff0c\u5206\u6790\u8def\u5f84\u56fe\u3001\u5708\u56fe\u3001\u8f6e\u56fe\u3001\u5b8c\u5168\u56fe\u3001\u5b8c\u5168\u4e8c\u5206\u56fe\u3001\u661f\u56fe\u3001\u53cb\u8c0a\u56fe\u548c\u53cc\u661f\u56fe\u7684\u4e2d\u95f4\u56fe\u7684\u914d\u5bf9\u6790\u53d6\u652f\u914d\u6570\uff0c\u7136\u540e\u5efa\u7acb\u4e00\u822c\u4efb\u610f\u56fe\uff08\u5c24\u5176\u662f\u6811\uff09\u4e2d\u95f4\u56fe\u6b64\u53c2\u6570\u7684\u4e0a\u4e0b\u754c\uff0c\u5e76\u7814\u7a76\u4e86\u4e2d\u95f4\u56fe\u7684 join \u8fd0\u7b97\u4e0b\u8be5\u53c2\u6570\u7684\u786e\u5207\u503c\u3002", "result": "\u7ed9\u51fa\u4e86\u591a\u7c7b\u7279\u6b8a\u56fe\u7684\u4e2d\u95f4\u56fe\u7684\u914d\u5bf9\u6790\u53d6\u652f\u914d\u6570\uff0c\u83b7\u5f97\u4e86\u4efb\u610f\u56fe\u7684\u4e2d\u95f4\u56fe\u6b64\u53c2\u6570\u7684\u4e0a\u7ebf\u754c\uff0c\u7279\u522b\u5bf9\u6811\u7c7b\u56fe\u7ed9\u51fa\u5f3a\u8c03\uff0c\u4e14\u7cbe\u786e\u786e\u5b9a\u4e86 join \u8fd0\u7b97\u4e0b\u7684\u914d\u5bf9\u6790\u53d6\u652f\u914d\u6570\u3002", "conclusion": "\u672c\u6587\u7684\u7ed3\u679c\u4e30\u5bcc\u4e86\u5bf9\u56fe\u7ed3\u6784\u53d8\u6362\u4e0b\u652f\u914d\u7c7b\u53c2\u6570\u7684\u7406\u89e3\uff0c\u4e3a\u5176\u7ec4\u5408\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u62d3\u5c55\u76f8\u5173\u56fe\u8bba\u9886\u57df\u7684\u7406\u8bba\u548c\u5e94\u7528\u3002"}}
{"id": "2506.18919", "categories": ["cs.CL", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2506.18919", "abs": "https://arxiv.org/abs/2506.18919", "authors": ["Hexiang Gu", "Qifan Yu", "Saihui Hou", "Zhiqin Fang", "Huijia Wu", "Zhaofeng He"], "title": "MemeMind: A Large-Scale Multimodal Dataset with Chain-of-Thought Reasoning for Harmful Meme Detection", "comment": null, "summary": "The rapid development of social media has intensified the spread of harmful\ncontent. Harmful memes, which integrate both images and text, pose significant\nchallenges for automated detection due to their implicit semantics and complex\nmultimodal interactions. Although existing research has made progress in\ndetection accuracy and interpretability, the lack of a systematic, large-scale,\ndiverse, and highly explainable dataset continues to hinder further advancement\nin this field. To address this gap, we introduce MemeMind, a novel dataset\nfeaturing scientifically rigorous standards, large scale, diversity, bilingual\nsupport (Chinese and English), and detailed Chain-of-Thought (CoT) annotations.\nMemeMind fills critical gaps in current datasets by offering comprehensive\nlabeling and explicit reasoning traces, thereby providing a solid foundation\nfor enhancing harmful meme detection. In addition, we propose an innovative\ndetection framework, MemeGuard, which effectively integrates multimodal\ninformation with reasoning process modeling, significantly improving models'\nability to understand and identify harmful memes. Extensive experiments\nconducted on the MemeMind dataset demonstrate that MemeGuard consistently\noutperforms existing state-of-the-art methods in harmful meme detection tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u7684 MemeMind \u6570\u636e\u96c6\u548c\u521b\u65b0\u68c0\u6d4b\u6846\u67b6 MemeGuard\uff0c\u63a8\u8fdb\u591a\u6a21\u6001\u6709\u5bb3\u8ff7\u56e0\u68c0\u6d4b\u9886\u57df\u53d1\u5c55\u3002", "motivation": "\u5f53\u524d\u6709\u5bb3\u8ff7\u56e0\u8bc6\u522b\u53d7\u9650\u4e8e\u6570\u636e\u96c6\u89c4\u6a21\u3001\u5c0f\u6837\u672c\u548c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u5f71\u54cd\u6a21\u578b\u8fdb\u4e00\u6b65\u63d0\u5347\uff0c\u56e0\u6b64\u4e9f\u9700\u7cfb\u7edf\u6027\u3001\u5177\u591a\u6837\u6027\u548c\u9ad8\u89e3\u91ca\u6027\u7684\u6570\u636e\u652f\u6301\u53ca\u66f4\u5f3a\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b\u4e2d\u82f1\u6587\u3001\u94fe\u5f0f\u63a8\u7406\u6807\u6ce8\u7684\u5927\u89c4\u6a21\u591a\u6837\u5316 MemeMind \u6570\u636e\u96c6\uff0c\u5e76\u8bbe\u8ba1\u96c6\u6210\u591a\u6a21\u6001\u4fe1\u606f\u4e0e\u63a8\u7406\u8fc7\u7a0b\u5efa\u6a21\u7684\u65b0\u65b9\u6cd5 MemeGuard\uff0c\u7ed3\u5408\u5728\u65b0\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u3002", "result": "MemeMind \u6570\u636e\u96c6\u5177\u5907\u89c4\u6a21\u5927\u3001\u79d1\u5b66\u6807\u51c6\u9ad8\u3001\u591a\u6837\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u5f3a\uff08\u542b\u63a8\u7406\u94fe\u6807\u6ce8\uff09\uff1b\u65b0\u65b9\u6cd5 MemeGuard \u5728\u76f8\u5173\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u65b0\u7684\u6570\u636e\u96c6 MemeMind \u548c\u68c0\u6d4b\u6846\u67b6 MemeGuard\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6709\u5bb3\u7f51\u7edc\u8ff7\u56e0\u8bc6\u522b\u7684\u6548\u679c\u3002"}}
{"id": "2506.18998", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.18998", "abs": "https://arxiv.org/abs/2506.18998", "authors": ["Sahil Kale", "Vijaykant Nadadur"], "title": "Mirage of Mastery: Memorization Tricks LLMs into Artificially Inflated Self-Knowledge", "comment": "Accepted to the Pre-ACL Workshop 2025, Copenhagen", "summary": "When artificial intelligence mistakes memorization for intelligence, it\ncreates a dangerous mirage of reasoning. Existing studies treat memorization\nand self-knowledge deficits in LLMs as separate issues and do not recognize an\nintertwining link that degrades the trustworthiness of LLM responses. In our\nstudy, we utilize a novel framework to ascertain if LLMs genuinely learn\nreasoning patterns from training data or merely memorize them to assume\ncompetence across problems of similar complexity focused on STEM domains. Our\nanalysis shows a noteworthy problem in generalization: LLMs draw confidence\nfrom memorized solutions to infer a higher self-knowledge about their reasoning\nability, which manifests as an over 45% inconsistency in feasibility\nassessments when faced with self-validated, logically coherent task\nperturbations. This effect is most pronounced in science and medicine domains,\nwhich tend to have maximal standardized jargon and problems, further confirming\nour approach. Significant wavering within the self-knowledge of LLMs also shows\nflaws in current architectures and training patterns, highlighting the need for\ntechniques that ensure a balanced, consistent stance on models' perceptions of\ntheir own knowledge for maximum AI explainability and trustworthiness. Our code\nand results are available publicly at\nhttps://github.com/knowledge-verse-ai/LLM-Memorization_SK_Eval-.", "AI": {"tldr": "\u5927\u6a21\u578b\u5728STEM\u9886\u57df\u5f80\u5f80\u6df7\u6dc6\u8bb0\u5fc6\u4e0e\u63a8\u7406\u771f\u5b9e\u80fd\u529b\uff0c\u5bf9\u81ea\u77e5\u80fd\u529b\u8bc4\u4f30\u4e0d\u4e00\u81f4\uff0c\u5c24\u5176\u79d1\u5b66\u533b\u5b66\u7c7b\u6700\u4e25\u91cd\uff0c\u9700\u6539\u8fdb\u8bad\u7ec3\u65b9\u6cd5\u4ee5\u63d0\u5347AI\u53ef\u4fe1\u4efb\u5ea6\u3002", "motivation": "\u5f53\u524d\u5927\u6a21\u578b\uff08LLMs\uff09\u5e38\u88ab\u8bdf\u75c5\uff1a\u4e00\u65b9\u9762\u5176\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u80fd\u529b\uff0c\u53e6\u4e00\u65b9\u9762\u53c8\u5bb9\u6613\u843d\u5165\u7b80\u5355\u8bb0\u5fc6\u800c\u975e\u771f\u6b63\u7406\u89e3\u3001\u63a8\u7406\u7684\u95ee\u9898\u3002\u4ee5\u5f80\u7814\u7a76\u5f80\u5f80\u5c06\u8bb0\u5fc6\u5316\u548c\u81ea\u77e5\u4e4b\u660e\u7684\u7f3a\u9677\u89c6\u4e3a\u4e24\u4e2a\u72ec\u7acb\u95ee\u9898\uff0c\u5ffd\u89c6\u4e86\u5b83\u4eec\u4e4b\u95f4\u7684\u5185\u5728\u8054\u7cfb\u3002\u672c\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63ed\u793a\u4e24\u8005\u4ea4\u7ec7\u540e\u5bf9\u6a21\u578b\u53ef\u4fe1\u6027\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u7279\u5b9a\u5b9e\u9a8c\u533a\u5206\u5927\u6a21\u578b\u5728STEM\u9886\u57df\uff08\u79d1\u5b66\u3001\u6280\u672f\u3001\u5de5\u7a0b\u3001\u6570\u5b66\uff09\u7684\u8868\u73b0\uff0c\u662f\u6765\u6e90\u4e8e\u771f\u5b9e\u63a8\u7406\u8fd8\u662f\u4ec5\u51ed\u8bb0\u5fc6\u3002\u4ed6\u4eec\u4e3b\u8981\u5173\u6ce8\u6a21\u578b\u5728\u9762\u5bf9\u81ea\u9a8c\u8bc1\u3001\u7b26\u5408\u903b\u8f91\u6270\u52a8\u4efb\u52a1\u65f6\u7684\u8868\u73b0\uff0c\u5e76\u8bc4\u4f30\u5176\u81ea\u77e5\u80fd\u529b\uff08self-knowledge\uff09\u53ca\u5176\u6ce2\u52a8\u6027\u3002", "result": "\u5206\u6790\u63ed\u793a\uff0cLLMs\u5728\u9047\u5230\u4e0e\u8bad\u7ec3\u96c6\u4e2d\u7c7b\u4f3c\u7684\u95ee\u9898\u65f6\uff0c\u5f80\u5f80\u56e0\u5bf9\u8bb0\u5fc6\u5316\u5185\u5bb9\u7684\u9ad8\u4fe1\u5fc3\u8bef\u5224\u81ea\u8eab\u63a8\u7406\u80fd\u529b\u3002\u5bf9\u81ea\u9a8c\u8bc1\u3001\u903b\u8f91\u4e00\u81f4\u4f46\u6709\u6270\u52a8\u7684\u4efb\u52a1\uff0c\u6a21\u578b\u5728\u53ef\u884c\u6027\u8bc4\u4f30\uff08\u5373\u662f\u5426\u80fd\u89e3\u51b3\u95ee\u9898\u7684\u81ea\u6211\u8bc4\u4f30\uff09\u4e0a\u6709\u8d85\u8fc745%\u7684\u8868\u73b0\u4e0d\u4e00\u81f4\uff0c\u5c24\u5176\u5728\u79d1\u5b66\u53ca\u533b\u5b66\u9886\u57df\u66f4\u660e\u663e\u3002", "conclusion": "\u5de5\u4f5c\u663e\u793aLLMs\u5728\u81ea\u77e5\u80fd\u529b\u4e0a\u660e\u663e\u6ce2\u52a8\uff0c\u66b4\u9732\u4e86\u73b0\u6709\u6a21\u578b\u7ed3\u6784\u548c\u8bad\u7ec3\u65b9\u6cd5\u7684\u4e0d\u5b8c\u5584\u3002\u4e3a\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u672a\u6765\u9700\u7814\u53d1\u80fd\u5e73\u8861\u6a21\u578b\u77e5\u8bc6\u611f\u77e5\u3001\u63d0\u5347\u81ea\u77e5\u4e00\u81f4\u6027\u7684\u6280\u672f\u3002"}}
{"id": "2506.19421", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2506.19421", "abs": "https://arxiv.org/abs/2506.19421", "authors": ["Markus Lohrey", "Sebastian Maneth", "Markus L. Schmid"], "title": "FO-Query Enumeration over SLP-Compressed Structures of Bounded Degree", "comment": null, "summary": "Enumerating the result set of a first-order query over a relational structure\nof bounded degree can be done with linear preprocessing and constant delay. In\nthis work, we extend this result towards the compressed perspective where the\nstructure is given in a potentially highly compressed form by a straight-line\nprogram (SLP). Our main result is an algorithm that enumerates the result set\nof a first-order query over a structure of bounded degree that is represented\nby an SLP satisfying the so-called apex condition. For a fixed formula, the\nenumeration algorithm has constant delay and needs a preprocessing time that is\nlinear in the size of the SLP.", "AI": {"tldr": "\u672c\u6587\u5c06\u6709\u754c\u5ea6\u7ed3\u6784\u7b2c\u4e00\u9636\u67e5\u8be2\u7ed3\u679c\u7684\u9ad8\u6548\u679a\u4e3e\u6269\u5c55\u5230SLP\u538b\u7f29\u8868\u793a\uff0c\u63d0\u51fa\u7b97\u6cd5\u5728\u5e38\u6570\u5ef6\u8fdf\u3001SLP\u7ebf\u6027\u9884\u5904\u7406\u4e0b\u5b8c\u6210\u7ed3\u679c\u96c6\u679a\u4e3e\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u5df2\u77e5\uff0c\u5bf9\u4e8e\u6709\u754c\u5ea6\u7684\u5173\u7cfb\u7ed3\u6784\uff0c\u7b2c\u4e00\u9636\u67e5\u8be2\u53ef\u4ee5\u5728\u7ebf\u6027\u9884\u5904\u7406\u53ca\u5e38\u6570\u5ef6\u8fdf\u4e0b\u679a\u4e3e\u7ed3\u679c\u3002\u7136\u800c\uff0c\u5b9e\u9645\u6570\u636e\u5f80\u5f80\u7ecf\u8fc7\u9ad8\u5ea6\u538b\u7f29\uff0c\u672c\u5de5\u4f5c\u65e8\u5728\u6269\u5c55\u8be5\u7406\u8bba\uff0c\u7814\u7a76\u7ed3\u6784\u4ee5SLP\u5f62\u5f0f\u538b\u7f29\u5b58\u50a8\u65f6\u7684\u9ad8\u6548\u679a\u4e3e\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u5e76\u5206\u6790\u4e86\u4e00\u79cd\u65b0\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u57fa\u4e8e\u5bf9SLP\uff08straight-line program\uff09\u9ad8\u6548\u5c55\u5f00\u4e0e\u904d\u5386\uff0c\u5e76\u7ed3\u5408\u7b2c\u4e00\u9636\u903b\u8f91\u67e5\u8be2\u7684\u7279\u6b8a\u7ed3\u6784\uff0c\u4fdd\u8bc1\u4e86\u5728\u7ed3\u6784\u538b\u7f29\u5b58\u50a8\u65f6\u7684\u9ad8\u6548\u679a\u4e3e\u6027\u80fd\u3002", "result": "\u63d0\u51fa\u4e86\u9488\u5bf9\u6ee1\u8db3apex\u6761\u4ef6\u7684SLP\u7f16\u7801\u6709\u754c\u5ea6\u7ed3\u6784\u7684\u7b2c\u4e00\u9636\u67e5\u8be2\u7ed3\u679c\u5e38\u6570\u5ef6\u8fdf\u679a\u4e3e\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u5176\u9884\u5904\u7406\u65f6\u95f4\u4e3aSLP\u5927\u5c0f\u7684\u7ebf\u6027\u7ea7\u522b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b97\u6cd5\uff0c\u80fd\u591f\u5728\u7ed3\u6784\u7531\u6ee1\u8db3apex\u6761\u4ef6\u7684SLP\u7f16\u7801\u65f6\uff0c\u5bf9\u6709\u754c\u5ea6\u5173\u7cfb\u7ed3\u6784\u7684\u7b2c\u4e00\u9636\u67e5\u8be2\u7ed3\u679c\u96c6\u8fdb\u884c\u5e38\u6570\u5ef6\u8fdf\u679a\u4e3e\uff0c\u5e76\u4e14\u9884\u5904\u7406\u65f6\u95f4\u4e0eSLP\u5927\u5c0f\u7ebf\u6027\u76f8\u5173\u3002"}}
{"id": "2506.19379", "categories": ["cs.FL", "cs.AR"], "pdf": "https://arxiv.org/pdf/2506.19379", "abs": "https://arxiv.org/abs/2506.19379", "authors": ["Subrata Paul", "Sukanta Das", "Biplab K Sikdar"], "title": "In-Memory Sorting-Searching with Cayley Tree", "comment": null, "summary": "This work proposes a computing model to reduce the workload of CPU. It relies\non the data intensive computation in memory, where the data reside, and\neffectively realizes an in-memory computing (IMC) platform. Each memory word,\nwith additional logic, acts as a tiny processing element which forms the node\nof a Cayley tree. The Cayley tree in turn defines the framework for solving the\ndata intensive computational problems. It finds the solutions for in-memory\nsearching, computing the max (min) in-memory and in-memory sorting while\nreducing the involvement of CPU. The worst case time complexities of the IMC\nbased solutions for in-memory searching and computing max (min) in-memory are\n$\\mathcal{O}\\log{n}$. Such solutions are independent of the order of elements\nin the list. The worst case time complexity of in-memory sorting, on the other\nhand, is $\\mathcal{O}(n\\log{n})$. Two types of hardware implementations of the\nIMC platform are proposed. One is based on the existing/conventional memory\narchitecture, and the other one is on a newly defined memory architecture. The\nsolutions are further implemented in FPGA platform to prove the effectiveness\nof the IMC architecture while comparing with the state-of-the art designs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCayley\u6811\u7684\u5185\u5b58\u5185\u8ba1\u7b97\u67b6\u6784\uff0c\u901a\u8fc7\u8f6f/\u786c\u4ef6\u7ed3\u5408\u663e\u8457\u964d\u4f4eCPU\u8d1f\u62c5\u548c\u63d0\u5347\u641c\u7d22\u3001\u6700\u5927\u503c\u3001\u6392\u5e8f\u7b49\u64cd\u4f5c\u7684\u6548\u7387\uff0cFPGA\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6848\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7684CPU\u5728\u5904\u7406\u6570\u636e\u5bc6\u96c6\u578b\u8ba1\u7b97\u65f6\u5de5\u4f5c\u8d1f\u8f7d\u8f83\u9ad8\uff0c\u5b58\u5728\u6570\u636e\u8981\u9891\u7e41\u79fb\u52a8\u5230CPU\u5904\u7406\u7684\u6548\u7387\u74f6\u9888\u3002\u4e3a\u4e86\u89e3\u51b3CPU\u74f6\u9888\uff0c\u63d0\u5347\u6570\u636e\u5bc6\u96c6\u578b\u4efb\u52a1\u7684\u5904\u7406\u6548\u7387\uff0c\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u201c\u5185\u5b58\u5185\u8ba1\u7b97\u201d\uff08IMC\uff09\u5e73\u53f0\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eCayley\u6811\u7ed3\u6784\u7684\u5185\u5b58\u5185\u8ba1\u7b97\u6a21\u578b\uff0c\u6bcf\u4e2a\u5e26\u6709\u9644\u52a0\u903b\u8f91\u7684\u5185\u5b58\u5355\u5143\u89c6\u4e3a\u5fae\u5c0f\u5904\u7406\u5355\u5143\uff0c\u5f62\u6210\u6811\u7684\u8282\u70b9\u3002\u901a\u8fc7\u8be5\u7ed3\u6784\u5b9e\u73b0\u5185\u5b58\u5185\u7684\u6570\u636e\u641c\u7d22\u3001\u6700\u5927\uff08\u6700\u5c0f\uff09\u503c\u8ba1\u7b97\u548c\u6392\u5e8f\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e24\u79cd\u786c\u4ef6\u5b9e\u73b0\u65b9\u5f0f\uff1a\u4e00\u79cd\u57fa\u4e8e\u4f20\u7edf\u5185\u5b58\u67b6\u6784\uff0c\u53e6\u4e00\u79cd\u57fa\u4e8e\u65b0\u5b9a\u4e49\u7684\u5185\u5b58\u67b6\u6784\u3002\u540c\u65f6\u5728FPGA\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "result": "\u57fa\u4e8eIMC\u7684\u5185\u5b58\u5185\u641c\u7d22\u548c\u6700\u5927\uff08\u6700\u5c0f\uff09\u503c\u8ba1\u7b97\u7684\u6700\u574f\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(log n)\uff0c\u4e0e\u5217\u8868\u4e2d\u5143\u7d20\u987a\u5e8f\u65e0\u5173\uff1b\u5185\u5b58\u5185\u6392\u5e8f\u7684\u6700\u574f\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(n log n)\u3002\u8bba\u6587\u63d0\u51fa\u7684\u4e24\u7c7b\u786c\u4ef6\u5e73\u53f0\u5728FPGA\u4e0a\u7684\u5b9e\u73b0\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u8bbe\u8ba1\u3002", "conclusion": "IMC\u6a21\u578b\u6709\u6548\u51cf\u5c11\u4e86CPU\u7684\u53c2\u4e0e\uff0c\u901a\u8fc7\u5728\u5185\u5b58\u7aef\u8fdb\u884c\u5e76\u884c\u5904\u7406\uff0c\u63d0\u5347\u6570\u636e\u5bc6\u96c6\u578b\u4efb\u52a1\u7684\u6027\u80fd\u3002\u5176\u7075\u6d3b\u7684\u786c\u4ef6\u5b9e\u73b0\u4fdd\u8bc1\u4e86\u67b6\u6784\u7684\u5b9e\u9645\u53ef\u7528\u6027\uff0c\u5e76\u4f18\u4e8e\u5f53\u4e0b\u4e3b\u6d41\u65b9\u6848\u3002"}}
{"id": "2506.18923", "categories": ["cs.PL", "cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2506.18923", "abs": "https://arxiv.org/abs/2506.18923", "authors": ["Yifan Zong", "Yuntian Deng", "Pengyu Nie"], "title": "Mix-of-Language-Experts Architecture for Multilingual Programming", "comment": "Accepted at LLM4Code @ ICSE 2025", "summary": "Large language models (LLMs) have demonstrated impressive capabilities in\naiding developers with tasks like code comprehension, generation, and\ntranslation. Supporting multilingual programming -- i.e., coding tasks across\nmultiple programming languages -- typically requires either (1) finetuning a\nsingle LLM across all programming languages, which is cost-efficient but\nsacrifices language-specific specialization and performance, or (2) finetuning\nseparate LLMs for each programming language, which allows for specialization\nbut is computationally expensive and storage-intensive due to the duplication\nof parameters. This paper introduces MoLE (Mix-of-Language-Experts), a novel\narchitecture that balances efficiency and specialization for multilingual\nprogramming. MoLE is composed of a base model, a shared LoRA (low-rank\nadaptation) module, and a collection of language-specific LoRA modules. These\nmodules are jointly optimized during the finetuning process, enabling effective\nknowledge sharing and specialization across programming languages. During\ninference, MoLE automatically routes to the language-specific LoRA module\ncorresponding to the programming language of the code token being generated.\nOur experiments demonstrate that MoLE achieves greater parameter efficiency\ncompared to training separate language-specific LoRAs, while outperforming a\nsingle shared LLM finetuned for all programming languages in terms of accuracy.", "AI": {"tldr": "MoLE\u901a\u8fc7\u6df7\u5408\u4e13\u5bb6\u673a\u5236\uff0c\u4ee5\u8f83\u4f4e\u6210\u672c\u517c\u987e\u591a\u8bed\u8a00\u4ee3\u7801\u751f\u6210\u6548\u7387\u4e0e\u4e13\u95e8\u5316\uff0c\u4f18\u4e8e\u4f20\u7edf\u5355/\u591a\u6a21\u578b\u5fae\u8c03\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u591a\u7f16\u7a0b\u8bed\u8a00\u4efb\u52a1\u4e0a\uff0c\u5355\u6a21\u578b\u5fae\u8c03\u6548\u7387\u9ad8\u4f46\u727a\u7272\u4e86\u8bed\u8a00\u4e13\u95e8\u5316\uff0c\u591a\u6a21\u578b\u5fae\u8c03\u4e13\u95e8\u5316\u5f3a\u4f46\u6210\u672c\u9ad8\u3001\u53c2\u6570\u5197\u4f59\u3002\u5982\u4f55\u517c\u987e\u6548\u7387\u4e0e\u4e13\u95e8\u5316\u6210\u4e3a\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86MoLE\uff08Mix-of-Language-Experts\uff09\u65b0\u67b6\u6784\uff0c\u7531\u57fa\u7840\u6a21\u578b\u3001\u5171\u4eabLoRA\u6a21\u5757\u53ca\u591a\u4e2a\u8bed\u8a00\u4e13\u5c5eLoRA\u6a21\u5757\u7ec4\u6210\uff0c\u91c7\u7528\u8054\u5408\u4f18\u5316\u5fae\u8c03\u65b9\u5f0f\uff0c\u63a8\u7406\u65f6\u6839\u636e\u76ee\u6807\u7f16\u7a0b\u8bed\u8a00\u81ea\u52a8\u9009\u62e9\u5bf9\u5e94\u7684\u4e13\u5c5e\u6a21\u5757\u3002", "result": "MoLE\u6bd4\u4e3a\u6bcf\u7c7b\u8bed\u8a00\u5206\u522b\u8bad\u7ec3LoRA\u66f4\u8282\u7701\u53c2\u6570\uff0c\u540c\u65f6\u5728\u591a\u8bed\u8a00\u4ee3\u7801\u4efb\u52a1\u4e0a\u7cbe\u5ea6\u4f18\u4e8e\u4ec5\u6709\u5355\u4e00\u5fae\u8c03LLM\u3002", "conclusion": "MoLE\u5b9e\u73b0\u4e86\u6548\u7387\u4e0e\u4e13\u95e8\u5316\u4e4b\u95f4\u7684\u5e73\u8861\uff0c\u5728\u591a\u7f16\u7a0b\u8bed\u8a00\u573a\u666f\u4e0b\u5177\u5907\u66f4\u597d\u7684\u53c2\u6570\u6548\u7387\u548c\u8868\u73b0\u3002"}}
{"id": "2506.19045", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.19045", "abs": "https://arxiv.org/abs/2506.19045", "authors": ["Ahmadreza Saboor Yaraghi", "Golnaz Gharachorlu", "Sakina Fatima", "Lionel C. Briand", "Ruiyuan Wan", "Ruifeng Gao"], "title": "Black-Box Test Code Fault Localization Driven by Large Language Models and Execution Estimation", "comment": null, "summary": "Fault localization (FL) is a critical step in debugging which typically\nrelies on repeated executions to pinpoint faulty code regions. However,\nrepeated executions can be impractical in the presence of non-deterministic\nfailures or high execution costs. While recent efforts have leveraged Large\nLanguage Models (LLMs) to aid execution-free FL, these have primarily focused\non identifying faults in the system under test (SUT) rather than in the often\ncomplex system test code. However, the latter is also important as, in\npractice, many failures are triggered by faulty test code. To overcome these\nchallenges, we introduce a fully static, LLM-driven approach for system test\ncode fault localization (TCFL) that does not require executing the test case.\nOur method uses a single failure execution log to estimate the test's execution\ntrace through three novel algorithms that identify only code statements likely\ninvolved in the failure. This pruned trace, combined with the error message, is\nused to prompt the LLM to rank potential faulty locations. Our black-box,\nsystem-level approach requires no access to the SUT source code and is\napplicable to large test scripts that assess full system behavior. We evaluate\nour technique at function, block, and line levels using an industrial dataset\nof faulty test cases not previously used in pre-training LLMs. Results show\nthat our best estimated trace closely match actual traces, with an F1 score of\naround 90%. Additionally, pruning the complex system test code reduces the\nLLM's inference time by up to 34% without any loss in FL performance. Our\nresults further suggest that block-level TCFL offers a practical balance,\nnarrowing the search space while preserving useful context, achieving an 81%\nhit rate at top-3 (Hit@3).", "AI": {"tldr": "\u63d0\u51fa\u65e0\u6267\u884c\u7684LLM\u9a71\u52a8\u7cfb\u7edf\u6d4b\u8bd5\u4ee3\u7801\u6545\u969c\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u7528\u4e00\u6b21\u5931\u8d25\u65e5\u5fd7\u63a8\u65ad\u76f8\u5173\u4ee3\u7801\u5e76\u4f18\u5148\u6392\u5e8f\uff0c\u65e0\u9700SUT\u6e90\u7801\uff0c\u5177\u9ad8\u51c6\u786e\u7387\u548c\u6548\u7387\uff0c\u5bf9\u5de5\u4e1a\u7ea7\u5927\u89c4\u6a21\u590d\u6742\u6d4b\u8bd5\u7528\u4f8b\u9002\u7528\u3002", "motivation": "\u4f20\u7edf\u7684\u6545\u969c\u5b9a\u4f4d\u65b9\u6cd5\u9700\u8981\u591a\u6b21\u6267\u884c\u7a0b\u5e8f\uff0c\u8fd9\u5728\u9762\u4e34\u975e\u786e\u5b9a\u6027\u5931\u8d25\u6216\u9ad8\u6267\u884c\u6210\u672c\u65f6\u4e0d\u5207\u5b9e\u9645\u3002\u540c\u65f6\uff0c\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65e0\u6267\u884c\u6545\u969c\u5b9a\u4f4d\u591a\u4e13\u6ce8\u4e8e\u88ab\u6d4b\u7cfb\u7edf\uff08SUT\uff09\uff0c\u800c\u5ffd\u89c6\u6d4b\u8bd5\u4ee3\u7801\u672c\u8eab\u7684\u6545\u969c\uff0c\u4f46\u5b9e\u9645\u4e0a\u5f88\u591a\u6545\u969c\u7531\u6d4b\u8bd5\u4ee3\u7801\u5f15\u53d1\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u79cd\u4e0d\u4f9d\u8d56\u6267\u884c\u3001\u80fd\u5b9a\u4f4d\u6d4b\u8bd5\u4ee3\u7801\u6545\u969c\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u9759\u6001\u3001\u7531\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u7cfb\u7edf\u6d4b\u8bd5\u4ee3\u7801\u6545\u969c\u5b9a\u4f4d\uff08TCFL\uff09\u65b9\u6cd5\uff0c\u65e0\u9700\u6267\u884c\u6d4b\u8bd5\u7528\u4f8b\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u4e00\u6b21\u5931\u8d25\u6267\u884c\u65e5\u5fd7\uff0c\u7ed3\u5408\u4e09\u79cd\u7b97\u6cd5\uff0c\u4f30\u7b97\u6d4b\u8bd5\u7684\u9759\u6001\u6267\u884c\u8f68\u8ff9\uff0c\u7b5b\u9009\u4e0e\u5931\u8d25\u76f8\u5173\u7684\u4ee3\u7801\u8bed\u53e5\u3002\u5c06\u7cbe\u7b80\u8f68\u8ff9\u548c\u9519\u8bef\u4fe1\u606f\u4e00\u540c\u8f93\u5165LLM\uff0c\u8fdb\u884c\u6545\u969c\u4f4d\u7f6e\u6392\u5e8f\u3002\u6b64\u65b9\u6cd5\u4e0d\u9700SUT\u6e90\u7801\uff0c\u9002\u7528\u5927\u578b\u6d4b\u8bd5\u811a\u672c\u3002", "result": "\u5728\u4e00\u4e2a\u672a\u88abLLM\u9884\u8bad\u7ec3\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u6700\u4f18\u4f30\u7b97\u8f68\u8ff9\u4e0e\u771f\u5b9e\u8f68\u8ff9F1\u5f97\u5206\u7ea690%\uff1b\u7cbe\u7b80\u5927\u89c4\u6a21\u6d4b\u8bd5\u4ee3\u7801\u8ba9LLM\u63a8\u7406\u65f6\u95f4\u51cf\u5c1134%\uff0c\u65e0\u7cbe\u5ea6\u635f\u5931\u3002\u5757\u7ea7TCFL\u53d6\u5f97\u6700\u4f73\u5e73\u8861\uff0ctop-3\u547d\u4e2d\u7387\u8fbe81%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u7cfb\u7edf\u6d4b\u8bd5\u4ee3\u7801\u9759\u6001\u6545\u969c\u5b9a\u4f4d\uff0c\u4e0d\u9700\u8981\u6267\u884c\u6d4b\u8bd5\u6216\u8bbf\u95eeSUT\u6e90\u7801\uff0c\u63d0\u5347\u4e86\u5927\u578b\u590d\u6742\u7cfb\u7edf\u4e0b\u7684\u8c03\u8bd5\u6548\u7387\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.19004", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.19004", "abs": "https://arxiv.org/abs/2506.19004", "authors": ["Brian Siyuan Zheng", "Alisa Liu", "Orevaoghene Ahia", "Jonathan Hayase", "Yejin Choi", "Noah A. Smith"], "title": "Broken Tokens? Your Language Model can Secretly Handle Non-Canonical Tokenizations", "comment": "preprint", "summary": "Modern tokenizers employ deterministic algorithms to map text into a single\n\"canonical\" token sequence, yet the same string can be encoded as many\nnon-canonical tokenizations using the tokenizer vocabulary. In this work, we\ninvestigate the robustness of LMs to text encoded with non-canonical\ntokenizations entirely unseen during training. Surprisingly, when evaluated\nacross 20 benchmarks, we find that instruction-tuned models retain up to 93.4%\nof their original performance when given a randomly sampled tokenization, and\n90.8% with character-level tokenization. We see that overall stronger models\ntend to be more robust, and robustness diminishes as the tokenization departs\nfarther from the canonical form. Motivated by these results, we then identify\nsettings where non-canonical tokenization schemes can *improve* performance,\nfinding that character-level segmentation improves string manipulation and code\nunderstanding tasks by up to +14%, and right-aligned digit grouping enhances\nlarge-number arithmetic by +33%. Finally, we investigate the source of this\nrobustness, finding that it arises in the instruction-tuning phase. We show\nthat while both base and post-trained models grasp the semantics of\nnon-canonical tokenizations (perceiving them as containing misspellings), base\nmodels try to mimic the imagined mistakes and degenerate into nonsensical\noutput, while post-trained models are committed to fluent responses. Overall,\nour findings suggest that models are less tied to their tokenizer than\npreviously believed, and demonstrate the promise of intervening on tokenization\nat inference time to boost performance.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u4ece\u672a\u89c1\u8fc7\u7684\u5206\u8bcd\u65b9\u6cd5\u6709\u6781\u5f3a\u9c81\u68d2\u6027\uff0c\u4e00\u4e9b\u7279\u522b\u5206\u8bcd\u65b9\u5f0f\u8fd8\u80fd\u63d0\u5347\u7279\u5b9a\u4efb\u52a1\u8868\u73b0\uff0c\u4e14\u63d0\u5347\u4e3b\u8981\u5f97\u76ca\u4e8einstruction-tuning\u9636\u6bb5\uff0c\u8bf4\u660e\u6a21\u578b\u5bf9\u5206\u8bcd\u5668\u4f9d\u8d56\u6027\u4f4e\u4e8e\u8fc7\u5f80\u8ba4\u77e5\u3002", "motivation": "\u73b0\u6709\u5206\u8bcd\u5668\u91c7\u7528\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u4f46\u540c\u4e00\u5b57\u7b26\u4e32\u5728\u8bcd\u8868\u4e0b\u5b58\u5728\u5927\u91cf\u53ef\u80fd\u7684\u975e\u89c4\u8303\u5206\u8bcd\u7f16\u7801\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u5927\u6a21\u578b\u9762\u5bf9\u8bad\u7ec3\u672a\u89c1\u7684\u975e\u89c4\u8303\u5206\u8bcd\u65f6\u7684\u9c81\u68d2\u6027\u4e0e\u673a\u5236\u3002", "method": "\u572820\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u96c6\u4e0a\uff0c\u5c06\u8bed\u8a00\u6a21\u578b\u66b4\u9732\u4e8e\u5b8c\u5168\u968f\u673a\u548c\u5b57\u7b26\u7ea7\u7684\u975e\u89c4\u8303\u5206\u8bcd\u7f16\u7801\uff0c\u5e76\u5bf9\u6bd4\u539f\u59cb\u4e0e\u975e\u89c4\u8303\u5206\u8bcd\u4e0b\u7684\u6a21\u578b\u8868\u73b0\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u5728\u7279\u5b9a\u4efb\u52a1\u4e2d\u4e0d\u540c\u5206\u8bcd\u65b9\u6848\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u5e76\u8ffd\u6eaf\u9c81\u68d2\u6027\u6765\u6e90\u3002", "result": "instruction-tuned\u6a21\u578b\u5728\u975e\u89c4\u8303\u5206\u8bcd\u4e0b\u6700\u9ad8\u53ef\u4fdd\u755993.4%\u539f\u59cb\u8868\u73b0\uff0c\u5b57\u7b26\u7ea7\u5206\u8bcd\u4e0b\u4e3a90.8%\uff1b\u66f4\u5f3a\u6a21\u578b\u901a\u5e38\u66f4\u9c81\u68d2\uff0c\u4e14\u975e\u89c4\u8303\u5206\u8bcd\u5728\u90e8\u5206\u573a\u666f\u660e\u663e\u63d0\u5347\u4efb\u52a1\u6548\u679c\uff08\u5982\u4ee3\u7801\u7406\u89e3\u63d0\u534714%\uff0c\u5927\u6570\u8fd0\u7b97\u63d0\u534733%\uff09\u3002\u9c81\u68d2\u6027\u4e3b\u8981\u6765\u6e90\u4e8einstruction-tuning\u9636\u6bb5\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\uff0c\u73b0\u4ee3\u5927\u6a21\u578b\u5bf9\u8bad\u7ec3\u65f6\u4ece\u672a\u89c1\u8fc7\u7684\u975e\u89c4\u8303\u5206\u8bcd\u4ecd\u5177\u8f83\u9ad8\u7684\u9c81\u68d2\u6027\uff0c\u4e14\u8fd9\u79cd\u9c81\u68d2\u6027\u4e3b\u8981\u6765\u6e90\u4e8einstruction-tuning\u9636\u6bb5\u3002\u6b64\u5916\uff0c\u5728\u67d0\u4e9b\u4efb\u52a1\u4e0a\uff0c\u91c7\u7528\u7279\u522b\u7684\u975e\u89c4\u8303\u5206\u8bcd\u65b9\u5f0f\u53ef\u663e\u8457\u63d0\u5347\u8868\u73b0\u3002"}}
{"id": "2506.19568", "categories": ["cs.LO", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2506.19568", "abs": "https://arxiv.org/abs/2506.19568", "authors": ["Gabriel Dengler", "Carlos E. Budde", "Laura Carnevali", "Arnd Hartmanns"], "title": "Time-Sensitive Importance Splitting", "comment": "Accepted at QEST+FORMATS 2025", "summary": "State-of-the-art methods for rare event simulation of non-Markovian models\nface practical or theoretical limits if observing the event of interest\nrequires prior knowledge or information on the timed behavior of the system. In\nthis paper, we attack both limits by extending importance splitting with a\ntime-sensitive importance function. To this end, we perform backwards\nreachability search from the target states, considering information about the\nlower and upper bounds of the active timers in order to steer the generation of\npaths towards the rare event. We have developed a prototype implementation of\nthe approach for input/output stochastic automata within the Modest Toolset.\nPreliminary experiments show the potential of the approach in estimating rare\nevent probabilities for an example from reliability engineering.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u65f6\u95f4\u654f\u611f\u7684\u8bc4\u4ef7\u51fd\u6570\uff0c\u63d0\u5347\u4e86\u975e\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u4e2d\u7a00\u6709\u4e8b\u4ef6\u4eff\u771f\u7684\u6548\u7387\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u53ef\u9760\u6027\u5de5\u7a0b\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u5f53\u524d\u7a00\u6709\u4e8b\u4ef6\u4eff\u771f\u7684\u975e\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u65b9\u6cd5\uff0c\u5728\u9700\u8981\u63d0\u524d\u4e86\u89e3\u7cfb\u7edf\u5b9a\u65f6\u884c\u4e3a\u65f6\u53d7\u5230\u5b9e\u9645\u6216\u7406\u8bba\u4e0a\u7684\u9650\u5236\u3002\u4f5c\u8005\u5e0c\u671b\u7a81\u7834\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u5c06\u91cd\u8981\u6027\u5206\u88c2\u6280\u672f\u4e0e\u5bf9\u65f6\u95f4\u654f\u611f\u7684\u8bc4\u4ef7\u51fd\u6570\u76f8\u7ed3\u5408\u3002\u5177\u4f53\u505a\u6cd5\u662f\u4ece\u76ee\u6807\u72b6\u6001\u8fdb\u884c\u53cd\u5411\u53ef\u8fbe\u6027\u641c\u7d22\uff0c\u5229\u7528\u6d3b\u52a8\u8ba1\u65f6\u5668\u7684\u4e0a\u4e0b\u754c\u4fe1\u606f\u6765\u5f15\u5bfc\u8def\u5f84\u751f\u6210\uff0c\u76ee\u6807\u662f\u66f4\u9ad8\u6548\u5730\u4eff\u771f\u7a00\u6709\u4e8b\u4ef6\u7684\u53d1\u751f\u3002\u65b9\u6cd5\u5728Modest Toolset\u4e2d\u9488\u5bf9\u8f93\u5165/\u8f93\u51fa\u968f\u673a\u81ea\u52a8\u673a\u5b9e\u73b0\u4e86\u539f\u578b\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u53ef\u9760\u6027\u5de5\u7a0b\u6837\u4f8b\u4e2d\uff0c\u5bf9\u7a00\u6709\u4e8b\u4ef6\u6982\u7387\u7684\u4f30\u7b97\u663e\u793a\u51fa\u6f5c\u529b\u3002", "conclusion": "\u5229\u7528\u65f6\u95f4\u654f\u611f\u7684\u8bc4\u4ef7\u51fd\u6570\u6269\u5c55\u91cd\u8981\u6027\u5206\u88c2\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u975e\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u7a00\u6709\u4e8b\u4ef6\u4eff\u771f\u7684\u6709\u6548\u6027\u3002\u65b9\u6cd5\u5177\u6709\u5b9e\u9645\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2506.19457", "categories": ["cs.PL", "cs.DC", "D.3.1; F.3.1; F.3.2"], "pdf": "https://arxiv.org/pdf/2506.19457", "abs": "https://arxiv.org/abs/2506.19457", "authors": ["Tom T. P. Franken", "Thomas Neele", "Jan Friso Groote"], "title": "The Autonomous Data Language -- Concepts, Design and Formal Verification", "comment": "48 pages, preprint submitted to Elsevier", "summary": "Nowadays, the main advances in computational power are due to parallelism.\nHowever, most parallel languages have been designed with a focus on processors\nand threads. This makes dealing with data and memory in programs hard, which\ndistances the implementation from its original algorithm. We propose a new\nparadigm for parallel programming, the data-autonomous paradigm, where\ncomputation is performed by autonomous data elements. Programs in this paradigm\nare focused on making the data collaborate in a highly parallel fashion. We\nfurthermore present AuDaLa, the first data autonomous programming language, and\nprovide a full formalisation that includes a type system and operational\nsemantics. Programming in AuDaLa is very natural, as illustrated by examples,\nalbeit in a style very different from sequential and contemporary parallel\nprogramming. Additionally, it lends itself for the formal verification of\nparallel programs, which we demonstrate.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ee5\u81ea\u6cbb\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u5168\u65b0\u5e76\u884c\u7f16\u7a0b\u8303\u5f0f\uff0c\u5e76\u5b9e\u73b0\u4e86\u9996\u4e2a\u76f8\u5173\u8bed\u8a00AuDaLa\uff0c\u517c\u5177\u81ea\u7136\u6613\u7528\u548c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u80fd\u529b\uff0c\u4e3a\u5e76\u884c\u7f16\u7a0b\u5e26\u6765\u4e86\u521b\u65b0\u9014\u5f84\u3002", "motivation": "\u76ee\u524d\u7684\u5e76\u884c\u8bed\u8a00\u4e3b\u8981\u5173\u6ce8\u5904\u7406\u5668\u548c\u7ebf\u7a0b\uff0c\u5bfc\u81f4\u6570\u636e\u548c\u5185\u5b58\u5904\u7406\u56f0\u96be\uff0c\u4f7f\u5b9e\u73b0\u4e0e\u539f\u59cb\u7b97\u6cd5\u8131\u8282\u3002\u4f5c\u8005\u63d0\u51fa\u65b0\u7684\u5e76\u884c\u7f16\u7a0b\u8303\u5f0f\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86data-autonomous\uff08\u6570\u636e\u81ea\u6cbb\u578b\uff09\u5e76\u884c\u7f16\u7a0b\u8303\u5f0f\uff0c\u7528\u81ea\u6cbb\u6570\u636e\u5143\u7d20\u9a71\u52a8\u8ba1\u7b97\uff0c\u5e76\u9996\u6b21\u63a8\u51faAuDaLa\u8bed\u8a00\uff0c\u8fd8\u7ed9\u51fa\u4e86\u5305\u62ec\u7c7b\u578b\u7cfb\u7edf\u548c\u64cd\u4f5c\u8bed\u4e49\u7684\u5b8c\u6574\u5f62\u5f0f\u5316\u63cf\u8ff0\u3002\u901a\u8fc7\u793a\u4f8b\u8bf4\u660eAuDaLa\u7684\u7f16\u7a0b\u65b9\u5f0f\u548c\u5e76\u5229\u7528\u5176\u5f62\u5f0f\u5316\u7279\u6027\u5b9e\u73b0\u4e86\u5e76\u884c\u7a0b\u5e8f\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002", "result": "\u8bc1\u5b9e\u4e86AuDaLa\u8bed\u8a00\u81ea\u7136\u6613\u7528\uff0c\u5e76\u9002\u5408\u8fdb\u884c\u5e76\u884c\u7a0b\u5e8f\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u4e0e\u4f20\u7edf\u987a\u5e8f\u53ca\u5e76\u884c\u7f16\u7a0b\u622a\u7136\u4e0d\u540c\u7684\u7f16\u7a0b\u98ce\u683c\u3002", "conclusion": "\u6570\u636e\u81ea\u6cbb\u578b\u7f16\u7a0b\u8303\u5f0f\u53ca\u5176\u5b9e\u73b0\u7684AuDaLa\u8bed\u8a00\uff0c\u80fd\u4f7f\u5e76\u884c\u7a0b\u5e8f\u8bbe\u8ba1\u66f4\u63a5\u8fd1\u7b97\u6cd5\u672c\u610f\uff0c\u540c\u65f6\u4fbf\u4e8e\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u63d0\u5347\u4e86\u5e76\u884c\u7f16\u7a0b\u7684\u8868\u8fbe\u529b\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2506.19153", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.19153", "abs": "https://arxiv.org/abs/2506.19153", "authors": ["Krzysztof Fonal"], "title": "Dataset of Yul Contracts to Support Solidity Compiler Research", "comment": "4 pages", "summary": "The YulCode dataset presents a comprehensive collection of 348,840 Yul-based\nsmart contract instances, comprising approximately 135,013 unique contracts.\nThese contracts were generated through the compilation of Solidity source files\nthat have been deployed on the Ethereum mainnet, making the dataset directly\nrepresentative of real-world decentralized applications. YulCode provides a\nrich foundation for a variety of research and development tasks, including but\nnot limited to machine learning applications, formal verification, optimization\nanalysis, and software engineering tool evaluation in the context of low-level\nsmart contract code. To the best of our knowledge at the time of writing,\nYulCode is the first and only publicly available dataset that focuses\nspecifically on Yul, an intermediate language designed for the Ethereum Virtual\nMachine (EVM). As such, it fills a critical gap in the current ecosystem of\nsmart contract datasets and opens new avenues for research and tooling aimed at\nlow-level contract analysis and generation.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u53d1\u5e03\u4e86\u9996\u4e2a\u6db5\u76d6348,840\u4e2a\u771f\u5b9e\u4ee5\u592a\u574a\u4e3b\u7f51Yul\u667a\u80fd\u5408\u7ea6\u5b9e\u4f8b\u7684\u6570\u636e\u96c6YulCode\uff0c\u4e3a\u5e95\u5c42\u5408\u7ea6\u7814\u7a76\u548c\u5206\u6790\u63d0\u4f9b\u4e86\u5f00\u653e\u6807\u51c6\u548c\u6570\u636e\u57fa\u7840\u3002", "motivation": "\u5f53\u524d\u4ee5\u592a\u574a\u667a\u80fd\u5408\u7ea6\u7814\u7a76\u5927\u91cf\u4f9d\u8d56Solidity\u6e90\u7801\uff0c\u800c\u9762\u5411\u5e95\u5c42EVM\u7684\u5f00\u6e90Yul\u8bed\u8a00\u5408\u7ea6\u6570\u636e\u96c6\u6781\u4e3a\u7a00\u7f3a\uff0c\u9650\u5236\u4e86\u5e95\u5c42\u4ee3\u7801\u5206\u6790\u3001\u9a8c\u8bc1\u548c\u4f18\u5316\u7b49\u65b9\u5411\u7684\u6df1\u5165\u7814\u7a76\u3002\u672c\u6587\u63d0\u51fa\u6570\u636e\u96c6\u4ee5\u586b\u8865\u8be5\u9886\u57df\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u6536\u96c6\u5e76\u7f16\u8bd1\u5df2\u5728\u4ee5\u592a\u574a\u4e3b\u7f51\u90e8\u7f72\u7684Solidity\u6e90\u7801\uff0c\u751f\u6210\u5e76\u6574\u7406\u5bf9\u5e94\u7684Yul\u4f4e\u7ea7\u4ee3\u7801\u5b9e\u4f8b\uff0c\u7b5b\u9009\u540e\u5f62\u6210\u4e86\u5305\u542b348,840\u4e2aYul\u5b9e\u4f8b\u3001135,013\u4e2a\u72ec\u7279\u5408\u7ea6\u7684\u6570\u636e\u96c6\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u5177\u4ee3\u8868\u6027\u4e14\u516c\u5f00\u53ef\u7528\u7684Yul\u667a\u80fd\u5408\u7ea6\u6570\u636e\u96c6\u2014\u2014YulCode\uff0c\u6db5\u76d6\u4e86\u4e3b\u7f51\u771f\u5b9e\u667a\u80fd\u5408\u7ea6\u7684\u4f4e\u7ea7\u5b9e\u73b0\u3002", "conclusion": "YulCode\u662f\u9996\u4e2a\u805a\u7126Yul\u4e2d\u95f4\u8bed\u8a00\u7684\u516c\u5f00\u6570\u636e\u96c6\uff0c\u4e3a\u4f4e\u7ea7\u667a\u80fd\u5408\u7ea6\u5206\u6790\u3001\u673a\u5668\u5b66\u4e60\u3001\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3001\u4f18\u5316\u7b49\u591a\u4e2a\u7814\u7a76\u548c\u5f00\u53d1\u9886\u57df\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6491\u3002\u8be5\u6570\u636e\u96c6\u5f25\u8865\u4e86\u667a\u80fd\u5408\u7ea6\u7814\u7a76\u9886\u57df\u7684\u5173\u952e\u77ed\u677f\uff0c\u5e76\u5c06\u63a8\u52a8\u4f4e\u7ea7\u53ef\u7f16\u7a0b\u6027\u4e0e\u5b89\u5168\u6027\u5de5\u5177\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.19028", "categories": ["cs.CL", "cs.AI", "cs.CY", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2506.19028", "abs": "https://arxiv.org/abs/2506.19028", "authors": ["Weijie Xu", "Yiwen Wang", "Chi Xue", "Xiangkun Hu", "Xi Fang", "Guimin Dong", "Chandan K. Reddy"], "title": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective", "comment": "29 pages, 9 figures, 15 tables", "summary": "Large Language Models (LLMs) often generate responses with inherent biases,\nundermining their reliability in real-world applications. Existing evaluation\nmethods often overlook biases in long-form responses and the intrinsic\nvariability of LLM outputs. To address these challenges, we propose\nFiSCo(Fine-grained Semantic Computation), a novel statistical framework to\nevaluate group-level fairness in LLMs by detecting subtle semantic differences\nin long-form responses across demographic groups. Unlike prior work focusing on\nsentiment or token-level comparisons, FiSCo goes beyond surface-level analysis\nby operating at the claim level, leveraging entailment checks to assess the\nconsistency of meaning across responses. We decompose model outputs into\nsemantically distinct claims and apply statistical hypothesis testing to\ncompare inter- and intra-group similarities, enabling robust detection of\nsubtle biases. We formalize a new group counterfactual fairness definition and\nvalidate FiSCo on both synthetic and human-annotated datasets spanning gender,\nrace, and age. Experiments show that FiSco more reliably identifies nuanced\nbiases while reducing the impact of stochastic LLM variability, outperforming\nvarious evaluation metrics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86FiSCo\u6846\u67b6\uff0c\u53ef\u5728claim\u7ea7\u522b\u68c0\u6d4bLLM\u8f93\u51fa\u957f\u6587\u672c\u4e2d\u7684\u7ec6\u5fae\u504f\u89c1\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u7fa4\u4f53\u516c\u5e73\u6027\u68c0\u6d4b\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u7684\u56de\u7b54\u5e38\u5e26\u6709\u56fa\u6709\u504f\u89c1\uff0c\u5f71\u54cd\u5176\u5728\u73b0\u5b9e\u4e16\u754c\u573a\u666f\u4e2d\u7684\u53ef\u9760\u6027\u3002\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5f80\u5f80\u5ffd\u89c6\u4e86\u957f\u6587\u672c\u56de\u7b54\u4e2d\u7684\u504f\u89c1\u4ee5\u53caLLMs\u8f93\u51fa\u7684\u5185\u5728\u53d8\u5f02\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u540d\u4e3aFiSCo\uff08Fine-grained Semantic Computation\uff09\u7684\u65b0\u578b\u7edf\u8ba1\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u5c06\u6a21\u578b\u8f93\u51fa\u5206\u89e3\u4e3a\u8bed\u4e49\u4e0a\u533a\u5206\u660e\u786e\u7684claim\uff0c\u57fa\u4e8e\u8574\u542b\u68c0\u9a8c\u8fdb\u884cclaim\u7ea7\u522b\u7684\u610f\u4e49\u4e00\u81f4\u6027\u8bc4\u4f30\uff0c\u5e76\u901a\u8fc7\u7edf\u8ba1\u5047\u8bbe\u68c0\u9a8c\u6bd4\u8f83\u7fa4\u4f53\u5185\u548c\u7fa4\u4f53\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u4ee5\u68c0\u6d4b\u5fae\u5999\u7684\u504f\u89c1\u3002\u65b9\u6cd5\u8fd8\u5f62\u5f0f\u5316\u4e86\u5206\u7ec4\u53cd\u4e8b\u5b9e\u516c\u5e73\u6027\u7684\u65b0\u5b9a\u4e49\u3002", "result": "FiSCo\u88ab\u5e94\u7528\u4e8e\u5408\u6210\u548c\u4eba\u5de5\u6ce8\u91ca\u7684\u591a\u4e2a\u6570\u636e\u96c6\uff08\u6db5\u76d6\u6027\u522b\u3001\u79cd\u65cf\u548c\u5e74\u9f84\uff09\uff0c\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u591a\u79cd\u8bc4\u4ef7\u6307\u6807\uff0cFiSCo\u80fd\u66f4\u53ef\u9760\u5730\u68c0\u6d4b\u7ec6\u5fae\u504f\u89c1\uff0c\u540c\u65f6\u51cf\u5c11LLM\u751f\u6210\u968f\u673a\u6027\u7684\u5f71\u54cd\u3002", "conclusion": "FiSCo\u80fd\u591f\u5728\u957f\u6587\u672c\u8f93\u51fa\u548c\u4e0d\u540c\u4eba\u7fa4\u95f4\uff0c\u7ec6\u81f4\u3001\u7a33\u5065\u5730\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u56de\u7b54\u4e2d\u7684\u6df1\u5c42\u504f\u89c1\uff0c\u4e3aLLMs\u516c\u5e73\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2506.19746", "categories": ["cs.LO", "03C13", "F.4.1; G.2.2"], "pdf": "https://arxiv.org/pdf/2506.19746", "abs": "https://arxiv.org/abs/2506.19746", "authors": ["Georg Schindling"], "title": "Homomorphism Indistinguishability and Game Comonads for Restricted Conjunction and Requantification", "comment": "Full version of a conference paper accepted for publication at MFCS\n  2025", "summary": "The notion of homomorphism indistinguishability offers a combinatorial\nframework for characterizing equivalence relations of graphs, in particular\nequivalences in counting logics within finite model theory. That is, for\ncertain graph classes, two structures agree on all homomorphism counts from the\nclass if and only if they satisfy the same sentences in a corresponding logic.\nThis perspective often reveals connections between the combinatorial properties\nof graph classes and the syntactic structure of logical fragments. In this\nwork, we extend this perspective to logics with restricted requantification,\nrefining the stratification of logical resources in finite-variable counting\nlogics. Specifically, we generalize Lov\\'asz-type theorems for these logics\nwith either restricted conjunction or bounded quantifier-rank and present new\ncombinatorial proofs of existing results. To this end, we introduce novel path\nand tree decompositions that incorporate the concept of reusability and develop\ncharacterizations based on pursuit-evasion games. Leveraging this framework, we\nestablish that classes of bounded pathwidth and treewidth with reusability\nconstraints are homomorphism distinguishing closed. Finally, we develop a\ncomonadic perspective on requantification by constructing new comonads that\nencapsulate restricted-reusability pebble games. We show a tight correspondence\nbetween their coalgebras and path/tree decompositions, yielding categorical\ncharacterizations of reusability in graph decompositions. This unifies logical,\ncombinatorial, and categorical perspectives on the notion of reusability.", "AI": {"tldr": "\u672c\u6587\u5728\u56fe\u7684\u540c\u6001\u4e0d\u53ef\u533a\u5206\u6027\u7406\u8bba\u4e2d\uff0c\u5c06\u6709\u9650\u53d8\u91cf\u8ba1\u6570\u903b\u8f91\u548c\u53d7\u9650\u9012\u91cf\u5316\u903b\u8f91\u6846\u67b6\u4e0b\u7684\u7b49\u4ef7\u5173\u7cfb\u4e0e\u53ef\u590d\u7528\u6027\u5206\u89e3\u3001\u535a\u5f08\u3001\u8303\u7574\u7406\u8bba\u4e09\u8005\u7edf\u4e00\u8fde\u63a5\uff0c\u5bf9Lov\u00e1sz\u578b\u5b9a\u7406\u8fdb\u884c\u63a8\u5e7f\uff0c\u5e76\u901a\u8fc7\u65b0\u9896\u7684\u8def\u5f84/\u6811\u5206\u89e3\u5de5\u5177\u548c\u8303\u7574\u7b49\u4ef7\uff0c\u63ed\u793a\u903b\u8f91\u4e0e\u7ec4\u5408\u7ed3\u6784\u7684\u6df1\u5c42\u8054\u7cfb\u3002", "motivation": "\u5f53\u524d\u56fe\u540c\u6001\u4e0d\u53ef\u533a\u5206\u6027\u4e3a\u7814\u7a76\u56fe\u7ed3\u6784\u7684\u7b49\u4ef7\u5173\u7cfb\u63d0\u4f9b\u4e86\u7ec4\u5408\u6846\u67b6\uff0c\u5c24\u5176\u5728\u6709\u9650\u6a21\u578b\u7406\u8bba\u4e2d\u7684\u8ba1\u6570\u903b\u8f91\u5177\u6709\u7279\u6b8a\u610f\u4e49\u3002\u63a2\u7d22\u5982\u4f55\u5c06\u8fd9\u4e00\u89c6\u89d2\u6269\u5c55\u5230\u66f4\u53d7\u9650\u7684\u903b\u8f91\uff0c\u5982\u53d7\u9650\u9012\u91cf\u5316\u7684\u903b\u8f91\uff0c\u9700\u8fdb\u4e00\u6b65\u63ed\u793a\u903b\u8f91\u8d44\u6e90\u5206\u5c42\u4e0e\u56fe\u7ed3\u6784\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u5bf9\u5df2\u6709\u7406\u8bba\u8fdb\u884c\u63a8\u5e7f\u3002", "method": "\u4f5c\u8005\u5c06Lov\u00e1sz\u578b\u5b9a\u7406\u63a8\u5e7f\u5230\u53d7\u9650\u5408\u53d6\u6216\u6709\u754c\u91cf\u8bcd\u6df1\u5ea6\u7684\u903b\u8f91\uff0c\u901a\u8fc7\u5f15\u5165\u53ef\u590d\u7528\u6027\u7684\u8def\u5f84\u4e0e\u6811\u5206\u89e3\u3001\u53d1\u5c55\u57fa\u4e8e\u8ffd\u9003\u535a\u5f08\u7684\u523b\u753b\u65b9\u6cd5\uff0c\u4ee5\u53ca\u6784\u9020\u5305\u6db5\u53d7\u9650\u53ef\u590d\u7528\u6027\u6c9f\u5b50\u6e38\u620f\u7684\u65b0\u4f34\u968f\u51fd\u5b50\u4f53\u7cfb\uff0c\u5b9e\u73b0\u903b\u8f91\u3001\u7ec4\u5408\u53ca\u8303\u7574\u4e09\u91cd\u89c6\u89d2\u7684\u7edf\u4e00\u3002", "result": "\u8bc1\u660e\u4e86\u5e26\u53ef\u590d\u7528\u6027\u7ea6\u675f\u7684\u6709\u754c\u8def\u5f84\u5bbd\u5ea6\u4e0e\u6811\u5bbd\u5ea6\u56fe\u7c7b\u5728\u540c\u6001\u4e0d\u53ef\u533a\u5206\u6027\u4e0b\u6784\u6210\u5c01\u95ed\u7c7b\uff0c\u5e76\u5efa\u7acb\u4e86\u8be5\u7c7b\u56fe\u5206\u89e3\u7684\u5177\u4f53\u903b\u8f91\u3001\u7ec4\u5408\u53ca\u8303\u7574\u523b\u753b\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u65b0\u6784\u9020\u7684\u4f34\u968f\u51fd\u5b50\uff0c\u5b9e\u73b0\u4e86\u903b\u8f91\u6e38\u620f\u4e0e\u5206\u89e3\u7684\u8303\u7574\u7b49\u4ef7\u6027\u3002", "conclusion": "\u672c\u6587\u62d3\u5c55\u4e86\u56fe\u540c\u6001\u4e0d\u53ef\u533a\u5206\u6027\u7684\u7406\u8bba\u6846\u67b6\uff0c\u7edf\u4e00\u4e86\u903b\u8f91\u3001\u7ec4\u5408\u4e0e\u8303\u7574\u89c6\u89d2\uff0c\u63a8\u52a8\u4e86\u6709\u754c\u903b\u8f91\u8d44\u6e90\u4e0e\u56fe\u7ed3\u6784\u4e4b\u95f4\u6df1\u5c42\u5173\u7cfb\u7684\u7406\u89e3\u3002\u5bf9\u53d7\u9650\u9012\u91cf\u5316\u903b\u8f91\u4ee5\u53ca\u53ef\u590d\u7528\u6027\u5206\u89e3\u7684\u7814\u7a76\u6709\u91cd\u8981\u63a8\u52a8\u4f5c\u7528\uff0c\u5bf9\u6709\u9650\u6a21\u578b\u7406\u8bba\u548c\u56fe\u7ed3\u6784\u7406\u8bba\u5747\u5177\u53c2\u8003\u4ef7\u503c\u3002"}}
{"id": "2506.19287", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.19287", "abs": "https://arxiv.org/abs/2506.19287", "authors": ["Yaoxuan Wu", "Xiaojie Zhou", "Ahmad Humayun", "Muhammad Ali Gulzar", "Miryung Kim"], "title": "Generating and Understanding Tests via Path-Aware Symbolic Execution with LLMs", "comment": null, "summary": "Symbolic execution is a widely used technique for test generation, offering\nsystematic exploration of program paths through constraint solving. However, it\nis fundamentally constrained by the capability to model the target code\nincluding library functions in terms of symbolic constraint and the capability\nof underlying constraint solvers. As a result, many paths involving complex\nfeatures remain unanalyzed or insufficiently modeled. Recent advances in large\nlanguage models (LLMs) have shown promise in generating diverse and valid test\ninputs. Yet, LLMs lack mechanisms for systematically enumerating program paths\nand often fail to cover subtle corner cases. We observe that directly prompting\nan LLM with the full program leads to missed coverage of interesting paths. In\nthis paper, we present PALM, a test generation system that combines symbolic\npath enumeration with LLM-assisted test generation. PALM statically enumerates\npossible paths through AST-level analysis and transforms each into an\nexecutable variant with embedded assertions that specify the target path. This\navoids the need to translate path constraints into SMT formulae, by instead\nconstructing program variants that LLM can interpret. Importantly, PALM is the\nfirst to provide an interactive frontend that visualizes path coverage\nalongside generated tests, assembling tests based on the specific paths they\nexercise. A user study with 12 participants demonstrates that PALM's frontend\nhelps users better understand path coverage and identify which paths are\nactually exercised by PALM-generated tests, through verification and\nvisualization of their path profiles.", "AI": {"tldr": "PALM\u7cfb\u7edf\u4ee5\u5168\u65b0\u65b9\u5f0f\u7ed3\u5408\u7b26\u53f7\u6267\u884c\u4e0eLLM\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff0c\u901a\u8fc7\u9759\u6001\u8def\u5f84\u679a\u4e3e+\u4ee3\u7801\u53d8\u4f53+\u65ad\u8a00+\u53ef\u89c6\u5316\u524d\u7aef\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u63d0\u9ad8\u4e86\u8def\u5f84\u8986\u76d6\u4e0e\u6d4b\u8bd5\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u7b26\u53f7\u6267\u884c\u65b9\u6cd5\u5728\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u53d7\u9650\u4e8e\u5bf9\u76ee\u6807\u4ee3\u7801\u53ca\u5e93\u51fd\u6570\u7684\u5efa\u6a21\u80fd\u529b\u548c\u5e95\u5c42\u7ea6\u675f\u6c42\u89e3\u5668\u7684\u80fd\u529b\uff0c\u5bfc\u81f4\u67d0\u4e9b\u590d\u6742\u8def\u5f84\u65e0\u6cd5\u5206\u6790\u3002\u6b64\u5916\uff0c\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u53ef\u4ee5\u751f\u6210\u591a\u6837\u7684\u6d4b\u8bd5\u8f93\u5165\uff0c\u4f46\u4e0d\u80fd\u7cfb\u7edf\u6027\u5730\u679a\u4e3e\u7a0b\u5e8f\u8def\u5f84\uff0c\u4e5f\u96be\u4ee5\u8986\u76d6\u8fb9\u89d2\u8def\u5f84\u3002\u672c\u6587\u6b63\u662f\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e24\u4e2a\u65b9\u6cd5\u7684\u4e0d\u8db3\u800c\u63d0\u51fa\u65b0\u65b9\u6848\u3002", "method": "PALM \u7cfb\u7edf\u7ed3\u5408\u7b26\u53f7\u8def\u5f84\u679a\u4e3e\u4e0eLLM\u6d4b\u8bd5\u751f\u6210\u3002\u5177\u4f53\u6765\u8bf4\uff0cPALM\u9759\u6001\u5730\u901a\u8fc7AST\u7ea7\u5206\u6790\u679a\u4e3e\u7a0b\u5e8f\u7684\u53ef\u80fd\u8def\u5f84\uff0c\u5c06\u6bcf\u4e00\u6761\u8def\u5f84\u8f6c\u6362\u4e3a\u5e26\u65ad\u8a00\u7684\u53ef\u6267\u884c\u7a0b\u5e8f\u53d8\u4f53\uff0c\u7528\u4e8e\u6307\u5b9a\u76ee\u6807\u8def\u5f84\uff0c\u800c\u4e0d\u662f\u4f20\u7edf\u5730\u8f6c\u5316\u4e3aSMT\u7ea6\u675f\u3002\u8fd9\u4e9b\u53d8\u4f53\u4fbf\u4e8eLLM\u7406\u89e3\u548c\u751f\u6210\u76f8\u5e94\u6d4b\u8bd5\u3002\u6b64\u5916\uff0cPALM\u8fd8\u63d0\u4f9b\u4e86\u4ea4\u4e92\u5f0f\u524d\u7aef\uff0c\u76f4\u89c2\u53ef\u89c6\u5316\u8def\u5f84\u8986\u76d6\u60c5\u51b5\u4ee5\u53ca\u5bf9\u5e94\u7684\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u7528\u6237\u7814\u7a76\u663e\u793a\uff0cPALM\u7684\u524d\u7aef\u80fd\u591f\u663e\u8457\u5e2e\u52a9\u7528\u6237\u7406\u89e3\u8def\u5f84\u8986\u76d6\uff0c\u5e76\u7cbe\u786e\u8bc6\u522b\u54ea\u4e9b\u8def\u5f84\u88ab\u751f\u6210\u7684\u6d4b\u8bd5\u7528\u4f8b\u8986\u76d6\u3002\u7528\u6237\u80fd\u901a\u8fc7\u8def\u5f84\u5206\u6790\u548c\u53ef\u89c6\u5316\u66f4\u597d\u5730\u9a8c\u8bc1\u548c\u7406\u89e3\u6d4b\u8bd5\u7528\u4f8b\u884c\u4e3a\u3002", "conclusion": "PALM\u7cfb\u7edf\u901a\u8fc7\u521b\u65b0\u6027\u5730\u7ed3\u5408\u9759\u6001\u8def\u5f84\u679a\u4e3e\u4e0eLLM\u8f85\u52a9\u6d4b\u8bd5\u751f\u6210\uff0c\u5728\u65e0\u9700\u590d\u6742SMT\u8f6c\u6362\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u4e86\u6709\u6548\u8def\u5f84\u8986\u76d6\u548c\u6d4b\u8bd5\u751f\u6210\uff0c\u5e76\u501f\u52a9\u53ef\u89c6\u5316\u4ea4\u4e92\u754c\u9762\u63d0\u5347\u4e86\u7528\u6237\u5bf9\u8986\u76d6\u6027\u7684\u7406\u89e3\u548c\u6d4b\u8bd5\u5b9a\u4f4d\u80fd\u529b\u3002"}}
{"id": "2506.19037", "categories": ["cs.CL", "cs.AI", "cs.IT", "cs.LG", "cs.NE", "math.IT"], "pdf": "https://arxiv.org/pdf/2506.19037", "abs": "https://arxiv.org/abs/2506.19037", "authors": ["Omer Luxembourg", "Haim Permuter", "Eliya Nachmani"], "title": "Plan for Speed -- Dilated Scheduling for Masked Diffusion Language Models", "comment": null, "summary": "Masked diffusion language models (MDLM) have shown strong promise for\nnon-autoregressive text generation, yet existing samplers act as implicit\nplanners, selecting tokens to unmask via denoiser confidence or entropy scores.\nSuch heuristics falter under parallel unmasking - they ignore pairwise\ninteractions between tokens and cannot account for dependencies when unmasking\nmultiple positions at once, limiting their inference time to traditional\nauto-regressive (AR) models. We introduce the Dilated-scheduled Unmasking\nStrategy (DUS), an inference-only, planner-model-free method that requires no\nadditional training. DUS leverages a first-order Markov assumption to partition\nsequence positions into dilation-based groups of non-adjacent tokens, enabling\nindependent, parallel unmasking steps that respect local context that minimizes\nthe joint entropy of each iteration step. Unlike semi-AR block approaches\n(e.g., LLADA and Dream) that still invoke the denoiser per block, DUS reduces\nthe number of denoiser calls to O(log B) per generation block - yielding\nsubstantial speedup over the O(B) run time of state-of-the-art diffusion\nmodels, where B is the block size in the semi-AR inference process. In\nexperiments on math (GSM8K) and code completion (Humaneval, MBPP) benchmarks -\ndomains suited to non-ordinal generation - DUS improves scores over parallel\nconfidence-based planner, without modifying the underlying denoiser. DUS offers\na lightweight, budget-aware approach to efficient, high-quality text\ngeneration, paving the way to unlock the true capabilities of MDLMs.", "AI": {"tldr": "DUS\u901a\u8fc7\u6269\u5f20\u5206\u7ec4\u548c\u5e76\u884c\u53bb\u63a9\u7801\u673a\u5236\uff0c\u4f7f\u975e\u81ea\u56de\u5f52\u6269\u6563\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u5927\u5e45\u52a0\u901f\u4e14\u63d0\u5347\u8d28\u91cf\uff0c\u65e0\u987b\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u63a9\u7801\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff08MDLM\uff09\u5728\u975e\u81ea\u56de\u5f52\u6587\u672c\u751f\u6210\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u4e3b\u6d41\u91c7\u6837\u5668\u91c7\u7528\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff08\u5982\u7f6e\u4fe1\u5ea6\u6216\u71b5\u5206\u6570\uff09\u5728\u5e76\u884c\u53bb\u63a9\u7801\u65f6\u65e0\u6cd5\u5f88\u597d\u5730\u5904\u7406\u591a\u4e2atoken\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5bfc\u81f4\u63a8\u7406\u901f\u5ea6\u96be\u4ee5\u8d85\u8fc7\u4f20\u7edf\u81ea\u56de\u5f52\u6a21\u578b\u3002\u63d0\u5347\u6548\u7387\u4e14\u4e0d\u635f\u5931\u751f\u6210\u8d28\u91cf\u6210\u4e3a\u8feb\u5207\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ec5\u5728\u63a8\u7406\u9636\u6bb5\u4f7f\u7528\u3001\u65e0\u987b\u989d\u5916\u8bad\u7ec3\u7684 Dilated-scheduled Unmasking Strategy\uff08DUS\uff09\u3002\u8be5\u65b9\u6cd5\u4f9d\u6258\u4e00\u9636\u9a6c\u5c14\u53ef\u592b\u5047\u8bbe\uff0c\u5c06\u5e8f\u5217\u4f4d\u7f6e\u6309\u7167\u6269\u5f20\uff08dilation\uff09\u65b9\u5f0f\u5206\u7ec4\uff0c\u6bcf\u7ec4\u4e3a\u975e\u76f8\u90bbtoken\uff0c\u5b9e\u73b0\u53ef\u4ee5\u5e76\u884c\u3001\u72ec\u7acb\u5730\u53bb\u63a9\u7801\u3002DUS\u6bcf\u8f6e\u6700\u5c0f\u5316\u8054\u5408\u71b5\uff0c\u76f8\u6bd4\u534a\u81ea\u56de\u5f52\uff08semi-AR\uff09block\u6cd5\uff0c\u6781\u5927\u51cf\u5c11\u4e86\u53bb\u566a\u5668\u8c03\u7528\u6b21\u6570\uff08O(log B) vs. O(B)\uff09\u3002", "result": "\u5728math\uff08GSM8K\uff09\u548c\u4ee3\u7801\u8865\u5168\uff08Humaneval, MBPP\uff09\u7b49\u91cd\u975e\u5e8f\u751f\u6210\u4efb\u52a1\u4e2d\uff0cDUS\u76f8\u6bd4\u5e76\u884c\u7f6e\u4fe1\u5ea6\u89c4\u5212\u65b9\u6cd5\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u5206\u6570\uff0c\u4e14\u65e0\u9700\u66f4\u6539\u5e95\u5c42\u53bb\u566a\u6a21\u5757\u3002\u6548\u7387\u548c\u751f\u6210\u8d28\u91cf\u53cc\u63d0\u5347\u3002", "conclusion": "DUS\u662f\u4e00\u79cd\u8f7b\u91cf\u3001\u9ad8\u6548\u3001\u65e0\u9700\u6a21\u578b\u6539\u52a8\u7684\u63a8\u7406\u589e\u5f3a\u65b9\u6848\uff0c\u4e3aMDLMs\u5e26\u6765\u9ad8\u8d28\u91cf\u4e0e\u63a8\u7406\u6548\u7387\u7684\u517c\u5f97\uff0c\u63d0\u5347\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.19425", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.19425", "abs": "https://arxiv.org/abs/2506.19425", "authors": ["Ang Jia", "He Jiang", "Zhilei Ren", "Xiaochen Li", "Ming Fan", "Ting Liu"], "title": "What Makes the Best Decomposition? Investigating Binary Decomposition Under FCG Variance", "comment": null, "summary": "Binary decomposition, which decomposes binary files into modules, plays a\ncritical role in binary reuse detection. Existing binary decomposition works\neither apply anchor-based methods by extending anchor functions to generate\nmodules, or apply clustering-based methods by using clustering algorithms to\ngroup binary functions, which all rely on that reused code shares similar\nfunction call relationships. However, we find that function call graphs (FCGs)\nvary a lot when using different compilation settings, especially with diverse\nfunction inlining decisions.\n  In this work, we conduct the first systematic empirical study on the variance\nof FCGs compiled by various compilation settings and explore its effect on\nbinary decomposition methods. We first construct a dataset compiled by 17\ncompilers, using 6 optimizations to 4 architectures and analyze the changes and\nmappings of the FCGs. We find that the size of FCGs changes dramatically, while\nthe FCGs are still linked by three different kinds of mappings. Then we\nevaluate the existing works under the FCG variance, and results show that\nexisting works are facing great challenges when conducting cross-compiler\nevaluation with diverse optimization settings. Finally, we propose a method to\nidentify the optimal decomposition and compare the existing decomposition works\nwith the optimal decomposition. Existing works either suffer from low coverage\nor cannot generate stable community similarities.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u6027\u5206\u6790\u4e0d\u540c\u7f16\u8bd1\u8bbe\u7f6e\u4e0b\u4e8c\u8fdb\u5236\u51fd\u6570\u8c03\u7528\u56fe\u53d8\u5316\u53ca\u5176\u5bf9\u5206\u89e3\u65b9\u6cd5\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u9002\u5e94\u8de8\u7f16\u8bd1\u5668\u548c\u4f18\u5316\u591a\u6837\u6027\uff0c\u63d0\u51fa\u7684\u6700\u4f18\u5206\u89e3\u6cd5\u4e3a\u6a21\u5757\u5212\u5206\u548c\u8bc4\u6d4b\u63d0\u4f9b\u65b0\u57fa\u51c6\u3002", "motivation": "\u4e8c\u8fdb\u5236\u91cd\u7528\u68c0\u6d4b\u8fc7\u7a0b\u4e2d\uff0c\u4e8c\u8fdb\u5236\u5206\u89e3\uff08\u5c06\u4e8c\u8fdb\u5236\u6587\u4ef6\u5206\u4e3a\u6a21\u5757\uff09\u662f\u5173\u952e\u73af\u8282\u3002\u73b0\u6709\u65b9\u6cd5\u666e\u904d\u5047\u8bbe\u5df2\u91cd\u7528\u4ee3\u7801\u4f1a\u4fdd\u6301\u76f8\u4f3c\u7684\u51fd\u6570\u8c03\u7528\u5173\u7cfb\uff0c\u4f9d\u8d56\u51fd\u6570\u8c03\u7528\u56fe\uff08FCG\uff09\uff0c\u4f46\u4f5c\u8005\u53d1\u73b0\u4f7f\u7528\u4e0d\u540c\u7f16\u8bd1\u8bbe\u7f6e\uff08\u5c24\u5176\u662f\u5404\u79cd\u51fd\u6570\u5185\u8054\u51b3\u7b56\uff09\u4f1a\u5bfc\u81f4FCG\u5dee\u5f02\u5f88\u5927\uff0c\u8fd9\u5bf9\u73b0\u6709\u65b9\u6cd5\u6548\u679c\u6709\u91cd\u5927\u5f71\u54cd\u3002", "method": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u5b9e\u8bc1\u5206\u6790\u4e86\u4e0d\u540c\u7f16\u8bd1\u8bbe\u7f6e\u4e0bFCG\u7684\u53d8\u5f02\uff0c\u5e76\u7814\u7a76\u8fd9\u4e9b\u53d8\u5316\u5bf9\u4e8c\u8fdb\u5236\u5206\u89e3\u65b9\u6cd5\u7684\u5f71\u54cd\u3002\u4f5c\u8005\u6784\u5efa\u6db5\u76d617\u79cd\u7f16\u8bd1\u5668\u30016\u79cd\u4f18\u5316\u9009\u9879\u548c4\u79cd\u67b6\u6784\u7684\u591a\u6837\u5316\u6570\u636e\u96c6\uff0c\u5206\u6790FCG\u7684\u53d8\u5316\u53ca\u5176\u4e09\u79cd\u4e0d\u540c\u7684\u6620\u5c04\u65b9\u5f0f\u3002\u968f\u540e\u5bf9\u73b0\u6709\u5206\u89e3\u65b9\u6cd5\u5728FCG\u53d8\u5316\u80cc\u666f\u4e0b\u8fdb\u884c\u8bc4\u6d4b\uff0c\u6700\u540e\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u8bc6\u522b\u6700\u4f18\u5206\u89e3\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u7528\u5176\u4e0e\u73b0\u6709\u6240\u6709\u5206\u89e3\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cFCG\u7684\u89c4\u6a21\u968f\u7f16\u8bd1\u9009\u9879\u53d8\u5316\u5267\u70c8\uff0c\u4f46\u8fd8\u53ef\u4ee5\u901a\u8fc7\u4e09\u79cd\u6620\u5c04\u65b9\u5f0f\u5efa\u7acb\u8054\u7cfb\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u9762\u5bf9\u8fd9\u79cd\u8de8\u7f16\u8bd1\u5668\u53ca\u4f18\u5316\u591a\u6837\u6027\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u5f88\u5927\u6311\u6218\uff0c\u5b58\u5728\u8986\u76d6\u7387\u4f4e\u6216\u751f\u6210\u7684\u793e\u533a\u76f8\u4f3c\u6027\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\u3002\u672c\u5de5\u4f5c\u63d0\u51fa\u7684\u6700\u4f18\u5206\u89e3\u65b9\u6cd5\u4e3a\u8bc4\u6d4b\u73b0\u6709\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b0\u57fa\u51c6\u3002", "conclusion": "\u4e0d\u540c\u7f16\u8bd1\u8bbe\u7f6e\u663e\u8457\u6539\u53d8\u4e86\u4e8c\u8fdb\u5236\u7684\u51fd\u6570\u8c03\u7528\u56fe\u7ed3\u6784\uff0c\u73b0\u6709\u6a21\u5757\u5206\u89e3\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u8de8\u7f16\u8bd1\u5668\u548c\u591a\u4f18\u5316\u8bbe\u7f6e\u7684\u573a\u666f\u3002\u63d0\u51fa\u7684\u6700\u4f18\u5206\u89e3\u65b9\u6cd5\u63d0\u5347\u4e86\u5206\u89e3\u8bc4\u6d4b\u7684\u79d1\u5b66\u6027\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u4eca\u540e\u7684\u4e8c\u8fdb\u5236\u91cd\u7528\u68c0\u6d4b\u548c\u5206\u89e3\u7b97\u6cd5\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.19058", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.19058", "abs": "https://arxiv.org/abs/2506.19058", "authors": ["Mike Zhang", "Rob van der Goot"], "title": "NLPnorth @ TalentCLEF 2025: Comparing Discriminative, Contrastive, and Prompt-Based Methods for Job Title and Skill Matching", "comment": "TalentCLEF 2025", "summary": "Matching job titles is a highly relevant task in the computational job market\ndomain, as it improves e.g., automatic candidate matching, career path\nprediction, and job market analysis. Furthermore, aligning job titles to job\nskills can be considered an extension to this task, with similar relevance for\nthe same downstream tasks. In this report, we outline NLPnorth's submission to\nTalentCLEF 2025, which includes both of these tasks: Multilingual Job Title\nMatching, and Job Title-Based Skill Prediction. For both tasks we compare\n(fine-tuned) classification-based, (fine-tuned) contrastive-based, and\nprompting methods. We observe that for Task A, our prompting approach performs\nbest with an average of 0.492 mean average precision (MAP) on test data,\naveraged over English, Spanish, and German. For Task B, we obtain an MAP of\n0.290 on test data with our fine-tuned classification-based approach.\nAdditionally, we made use of extra data by pulling all the language-specific\ntitles and corresponding \\emph{descriptions} from ESCO for each job and skill.\nOverall, we find that the largest multilingual language models perform best for\nboth tasks. Per the provisional results and only counting the unique teams, the\nranking on Task A is 5$^{\\text{th}}$/20 and for Task B 3$^{\\text{rd}}$/14.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u6bd4\u8f83\u591a\u79cdNLP\u65b9\u6cd5\u7528\u4e8e\u591a\u8bed\u8a00\u5c97\u4f4d\u5339\u914d\u548c\u57fa\u4e8e\u804c\u4f4d\u540d\u7684\u6280\u80fd\u9884\u6d4b\uff0c\u53d1\u73b0\u5927\u89c4\u6a21\u591a\u8bed\u8a00\u6a21\u578b\u548cprompt\u65b9\u6cd5\u5728\u5c97\u4f4d\u5339\u914d\u4e0a\u6548\u679c\u6700\u597d\uff0c\u5206\u7c7b\u6a21\u578b\u5728\u6280\u80fd\u9884\u6d4b\u4e0a\u66f4\u4f18\uff0c\u6700\u7ec8\u5728\u56fd\u9645\u4efb\u52a1\u4e2d\u53d6\u5f97\u8f83\u597d\u6392\u540d\u3002", "motivation": "\u5de5\u4f5c\u5c97\u4f4d\u540d\u79f0\u5339\u914d\u548c\u5c97\u4f4d\u6280\u80fd\u5bf9\u9f50\u5728\u5c31\u4e1a\u5e02\u573a\u4e2d\u5bf9\u81ea\u52a8\u5019\u9009\u4eba\u5339\u914d\u3001\u804c\u4e1a\u8def\u5f84\u9884\u6d4b\u548c\u5c31\u4e1a\u5e02\u573a\u5206\u6790\u7b49\u4e0b\u6e38\u5e94\u7528\u975e\u5e38\u91cd\u8981\u3002\u8fd9\u4e2a\u7814\u7a76\u7684\u52a8\u673a\u662f\u63d0\u5347\u8fd9\u4e9b\u4efb\u52a1\u7684\u6548\u679c\uff0c\u5c24\u5176\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u7684\u804c\u4f4d\u540d\u5339\u914d\u4e0e\u804c\u4f4d\u76f8\u5173\u6280\u80fd\u9884\u6d4b\u3002", "method": "\u6bd4\u8f83\u4e86\u4e09\u79cd\u65b9\u6cd5\uff1a\u5fae\u8c03\u7684\u5206\u7c7b\u6a21\u578b\u3001\u5fae\u8c03\u7684\u5bf9\u6bd4\u5b66\u4e60\u6a21\u578b\u4ee5\u53ca\u57fa\u4e8eprompt\u7684\u6a21\u578b\u3002\u6b64\u5916\uff0c\u8fd8\u5229\u7528\u4e86\u989d\u5916\u7684\u591a\u8bed\u8a00\u804c\u4f4d\u540d\u79f0\u548c\u63cf\u8ff0\u6570\u636e\u4f5c\u4e3a\u589e\u5f3a\u3002", "result": "\u5728\u591a\u8bed\u8a00\u5c97\u4f4d\u540d\u79f0\u5339\u914d\uff08Task A\uff09\u4e0a\uff0c\u57fa\u4e8eprompt\u7684\u65b9\u6cd5\u8868\u73b0\u6700\u4f73\uff0c\u6d4b\u8bd5\u96c6\u5e73\u5747MAP\u4e3a0.492\u3002\u5728\u57fa\u4e8e\u804c\u4f4d\u540d\u79f0\u7684\u6280\u80fd\u9884\u6d4b\uff08Task B\uff09\u4e0a\uff0c\u5fae\u8c03\u5206\u7c7b\u6a21\u578b\u8868\u73b0\u6700\u597d\uff0cMAP\u4e3a0.290\u3002\u4f7f\u7528\u4e86\u6765\u81eaESCO\u7684\u591a\u8bed\u8a00\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u3002\u5927\u89c4\u6a21\u591a\u8bed\u8a00\u6a21\u578b\u5728\u4e24\u9879\u4efb\u52a1\u4e0a\u5747\u8868\u73b0\u4f18\u5f02\u3002\u6392\u540d\u65b9\u9762\uff0cTask A\u572820\u652f\u961f\u4f0d\u4e2d\u6392\u7b2c5\uff0cTask B\u572814\u652f\u961f\u4f0d\u4e2d\u6392\u7b2c3\u3002", "conclusion": "\u591a\u8bed\u8a00\u5927\u6a21\u578b\u548c\u5408\u9002\u7684\u65b9\u6cd5\u53ef\u6709\u6548\u63d0\u5347\u804c\u4f4d\u540d\u5339\u914d\u548c\u6280\u80fd\u9884\u6d4b\u7684\u6548\u679c\u3002\u901a\u8fc7\u65b9\u6cd5\u6bd4\u8f83\u786e\u5b9a\u4e86\u5728\u4e0d\u540c\u4efb\u52a1\u4e0b\u8868\u73b0\u6700\u4f73\u7684\u6280\u672f\uff0c\u7efc\u5408\u8868\u73b0\u4f18\u5f02\uff0c\u5728\u56fd\u9645\u6bd4\u8d5b\u4e2d\u53d6\u5f97\u524d\u5217\u6210\u7ee9\u3002"}}
{"id": "2506.19481", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.19481", "abs": "https://arxiv.org/abs/2506.19481", "authors": ["Shahbaz Siddeeq", "Muhammad Waseem", "Zeeshan Rasheed", "Md Mahade Hasan", "Jussi Rasku", "Mika Saari", "Henri Terho", "Kalle Makela", "Kai-Kristian Kemell", "Pekka Abrahamsson"], "title": "LLM-based Multi-Agent System for Intelligent Refactoring of Haskell Code", "comment": "arXiv admin note: text overlap with arXiv:2502.07928", "summary": "Refactoring is a constant activity in software development and maintenance.\nScale and maintain software systems are based on code refactoring. However,\nthis process is still labor intensive, as it requires programmers to analyze\nthe codebases in detail to avoid introducing new defects. In this research, we\nput forward a large language model (LLM)-based multi-agent system to automate\nthe refactoring process on Haskell code. The objective of this research is to\nevaluate the effect of LLM-based agents in performing structured and\nsemantically accurate refactoring on Haskell code. Our proposed multi-agent\nsystem based on specialized agents with distinct roles, including code\nanalysis, refactoring execution, verification, and debugging. To test the\neffectiveness and practical applicability of the multi-agent system, we\nconducted evaluations using different open-source Haskell codebases. The\nresults of the experiments carried out showed that the proposed LLM-based\nmulti-agent system could average 11.03% decreased complexity in code, an\nimprovement of 22.46% in overall code quality, and increase performance\nefficiency by an average of 13.27%. Furthermore, memory allocation was\noptimized by up to 14.57%. These results highlight the ability of LLM-based\nmulti-agent in managing refactoring tasks targeted toward functional\nprogramming paradigms. Our findings hint that LLM-based multi-agent systems\nintegration into the refactoring of functional programming languages can\nenhance maintainability and support automated development workflows.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u81ea\u52a8\u91cd\u6784\u7cfb\u7edf\uff0c\u53ef\u6709\u6548\u63d0\u5347Haskell\u7b49\u51fd\u6570\u5f0f\u4ee3\u7801\u7684\u8d28\u91cf\u3001\u6027\u80fd\u548c\u53ef\u7ef4\u62a4\u6027\uff0c\u4e3a\u81ea\u52a8\u5316\u91cd\u6784\u63d0\u4f9b\u4e86\u65b0\u8def\u5f84\u3002", "motivation": "\u4ee3\u7801\u91cd\u6784\u662f\u8f6f\u4ef6\u5f00\u53d1\u548c\u7ef4\u62a4\u4e2d\u7684\u5e38\u89c4\u6d3b\u52a8\uff0c\u4f46\u8fd9\u4e00\u8fc7\u7a0b\u4ecd\u7136\u9ad8\u5ea6\u4f9d\u8d56\u4eba\u5de5\u5206\u6790\u4e0e\u64cd\u4f5c\uff0c\u5bb9\u6613\u51fa\u9519\u4e14\u8017\u65f6\uff1b\u5982\u4f55\u81ea\u52a8\u5316\u3001\u667a\u80fd\u5316\u5730\u8fdb\u884c\u91cd\u6784\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u51fd\u6570\u5f0f\u8bed\u8a00\uff08\u5982Haskell\uff09\uff0c\u610f\u4e49\u91cd\u5927\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u627f\u62c5\u4e0d\u540c\u804c\u8d23\uff08\u5982\u4ee3\u7801\u5206\u6790\u3001\u91cd\u6784\u6267\u884c\u3001\u9a8c\u8bc1\u548c\u8c03\u8bd5\uff09\uff0c\u5b9e\u73b0Haskell\u4ee3\u7801\u81ea\u52a8\u91cd\u6784\uff0c\u5e76\u5728\u591a\u4e2a\u5f00\u6e90Haskell\u4ee3\u7801\u5e93\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5e73\u5747\u964d\u4f4e\u4e86\u4ee3\u7801\u590d\u6742\u5ea611.03%\uff0c\u6574\u4f53\u4ee3\u7801\u8d28\u91cf\u63d0\u534722.46%\uff0c\u6027\u80fd\u6548\u7387\u63d0\u9ad813.27%\uff0c\u5185\u5b58\u5206\u914d\u4f18\u5316\u6700\u9ad8\u53ef\u8fbe14.57%\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u7ba1\u7406\u9488\u5bf9\u51fd\u6570\u5f0f\u7f16\u7a0b\u8303\u5f0f\u7684\u91cd\u6784\u4efb\u52a1\uff0c\u63d0\u5347\u4ee3\u7801\u53ef\u7ef4\u62a4\u6027\u3001\u81ea\u52a8\u5316\u5f00\u53d1\u6d41\u7a0b\uff0c\u6709\u671b\u6210\u4e3a\u51fd\u6570\u5f0f\u7f16\u7a0b\u8bed\u8a00\u81ea\u52a8\u91cd\u6784\u7684\u6709\u6548\u5de5\u5177\u3002"}}
