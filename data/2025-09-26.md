<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 18]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.CL](#cs.CL) [Total: 59]
- [cs.DM](#cs.DM) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Dual-Language General-Purpose Self-Hosted Visual Language and new Textual Programming Language for Applications](https://arxiv.org/abs/2509.20426)
*Mahmoud Samir Fayed*

Main category: cs.PL

TL;DR: 论文提出并实现了一种全新的通用自托管可视化编程语言PWCT2，基于自主开发的动态语言Ring支持跨语言和领域专用扩展，显著提升了开发效率和资源利用率，并已在Steam平台获得广泛实际应用和正面用户反馈。


<details>
  <summary>Details</summary>
Motivation: 大部分可视化编程语言（VPL）都是针对特定领域开发的，通用型VPL较少，且现有通用VPL多需依赖文本编程进行完善，限制了其进一步发展和易用性。

Method: 作者设计并开发了PWCT2——一种支持阿拉伯语和英语的、通用的、自托管的可视化编程语言。在开发PWCT2前，专门设计了一种名为Ring的动态类型文本编程语言，其具有自定义语法和扩展面向对象编程新特性，可以便捷创建领域专用语言。编译器和虚拟机通过PWCT语言的可视化方式实现，大大提升了抽象层次并隐藏了实现细节。PWCT2可实现自托管，由自身进行开发和扩展。

Result: PWCT2在代码生成速度上提升36倍，视觉源文件存储需求减少20倍，并支持将Ring代码转为视觉代码，实现自托管。PWCT2由约92,000行Ring代码和394个视觉组件组成，已通过Steam平台分发，拥有1772名用户，累计使用时长逾17,000小时，用户反馈积极。

Conclusion: PWCT2不仅显著提升了通用可视化编程语言的性能与可扩展性，并且实现了自托管、跨语言（阿拉伯语/英语）、高效代码生成等创新功能，获得了实际用户的验证与认可，对可视化编程工具的发展具有推动作用。

Abstract: Most visual programming languages (VPLs) are domain-specific, with few
general-purpose VPLs like Programming Without Coding Technology (PWCT). These
general-purpose VPLs are developed using textual programming languages and
improving them requires textual programming. In this thesis, we designed and
developed PWCT2, a dual-language (Arabic/English), general-purpose,
self-hosting visual programming language. Before doing so, we specifically
designed a textual programming language called Ring for its development. Ring
is a dynamically typed language with a lightweight implementation, offering
syntax customization features. It permits the creation of domain-specific
languages through new features that extend object-oriented programming,
allowing for specialized languages resembling Cascading Style Sheets (CSS) or
Supernova language. The Ring Compiler and Virtual Machine are designed using
the PWCT visual programming language where the visual implementation is
composed of 18,945 components that generate 24,743 lines of C code, which
increases the abstraction level and hides unnecessary details. Using PWCT to
develop Ring allowed us to realize several issues in PWCT, which led to the
development of the PWCT2 visual programming language using the Ring textual
programming language. PWCT2 provides approximately 36 times faster code
generation and requires 20 times less storage for visual source files. It also
allows for the conversion of Ring code into visual code, enabling the creation
of a self-hosting VPL that can be developed using itself. PWCT2 consists of
approximately 92,000 lines of Ring code and comes with 394 visual components.
PWCT2 is distributed to many users through the Steam platform and has received
positive feedback, On Steam, 1772 users have launched the software, and the
total recorded usage time exceeds 17,000 hours, encouraging further research
and development.

</details>


### [2] [Efficient Symbolic Computation vis Hash Consing](https://arxiv.org/abs/2509.20534)
*Bowen Zhu,Aayush Sabharwal,Songchen Tan,Yingbo Ma,Alan Edelman,Christopher Rackauckas*

Main category: cs.PL

TL;DR: 本研究在JuliaSymbolics中集成了hash consing，大幅提升了符号计算系统的效率与性能，尤其在大型表达式和下游处理时表现突出。


<details>
  <summary>Details</summary>
Motivation: 传统符号计算系统存在表达式膨胀问题，导致内存低效，影响计算性能，尤其是在AI驱动的数学推理工具中尤为关键。

Method: 在JuliaSymbolics中首次集成了hash consing机制，使用全局弱引用哈希表实现表达式的规范化和去重。

Result: 与以往方法比，符号计算速度提升高达3.2倍，内存使用减少2倍，代码生成提升5倍，函数编译提升10倍，大型模型的数值评估速度提升最多达100倍。

Conclusion: 引入hash consing能显著提升JuliaSymbolics在内存和性能方面的表现，并为未来与e-graphs等技术的融合奠定基础。

Abstract: Symbolic computation systems suffer from memory inefficiencies due to
redundant storage of structurally identical subexpressions, commonly known as
expression swell, which degrades performance in both classical computer algebra
and emerging AI-driven mathematical reasoning tools. In this paper, we present
the first integration of hash consing into JuliaSymbolics, a high-performance
symbolic toolkit in Julia, by employing a global weak-reference hash table that
canonicalizes expressions and eliminates duplication. This approach reduces
memory consumption and accelerates key operations such as differentiation,
simplification, and code generation, while seamlessly integrating with Julia's
metaprogramming and just-in-time compilation infrastructure. Benchmark
evaluations across different computational domains reveal substantial
improvements: symbolic computations are accelerated by up to 3.2 times, memory
usage is reduced by up to 2 times, code generation is up to 5 times faster,
function compilation up to 10 times faster, and numerical evaluation up to 100
times faster for larger models. While certain workloads with fewer duplicate
unknown-variable expressions show more modest gains or even slight overhead in
initial computation stages, downstream processing consistently benefits
significantly. These findings underscore the importance of hash consing in
scaling symbolic computation and pave the way for future work integrating hash
consing with e-graphs for enhanced equivalence-aware expression sharing in
AI-driven pipelines.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [ACCeLLiuM: Supervised Fine-Tuning for Automated OpenACC Pragma Generation](https://arxiv.org/abs/2509.20380)
*Samyak Jhaveri,Vanessa Klotzmann,Crista Lopes*

Main category: cs.SE

TL;DR: 本文提出并开源了用于OpenACC指令自动生成的LLM模型ACCeLLiuM及其训练数据集，其生成准确率远超基础LLM，有望大幅简化GPU离线加速流程。


<details>
  <summary>Details</summary>
Motivation: 针对GPU复杂性和OpenACC编程门槛较高，开发能够自动且高效生成专业OpenACC指令的LLM模型，降低普通用户进行GPU离线加速的技术壁垒。

Method: 通过从GitHub公开C/C++项目挖掘4033个OpenACC pragma-loop对，建立并监督微调基于大语言模型（LLM）的新模型ACCeLLiuM，并对其生成能力与基础LLM进行对比测试。

Result: 在测试集上，微调后的LLM模型能正确生成87%数据并行循环的有效OpenACC指令，并完全精确匹配指令内容的比例为50%。生成结果即使不完全一致，也常包含合理有效的扩展参数。

Conclusion: ACCeLLiuM显著提升了LLM自动生成OpenACC指令的准确率，为自动化GPU加速和OpenACC指令生成提供了新的基线。

Abstract: The increasing ubiquity of GPUs is accompanied by the increasing complexity
of their hardware and parallel programming frameworks. Directive-based parallel
programming standards like OpenACC simplify GPU programming to some extent by
abstracting away low-level complexities, but a fair amount of expertise is
still required in order to use those directives effectively.
  We introduce ACCeLLiuM, two open weights Large Language Models specifically
fine-tuned for generating expert OpenACC directives for data-parallel loops,
along with the supervised fine-tuning dataset that was used to train them. The
ACCeLLiuM SFT dataset contains 4,033 OpenACC pragma-loop pairs mined from
public GitHub C/C++ repositories, with 3,223 pairs for training and 810 for
testing. Experimental evaluations show a pronounced performance gap in
generating correct OpenACC pragmas between base LLMs and our fine-tuned
versions. On the held-out test set, base LLMs fail to consistently generate
valid pragmas, whereas LLMs fine-tuned on the ACCeLLiuM dataset generate valid
pragmas with the correct directive type for $87\%$ of the data-parallel loops,
and exact pragmas--including directives, clauses, clause order, and clause
variables--for $50\%$ of the cases. Even when not exact, generated pragmas
frequently incorporate the correct clauses in a different order than the
ground-truth label, or include additional clauses that enable finer control
over parallel execution, data movement, and concurrency, offering practical
value beyond strict string-matching. By publicly releasing the code, models,
and dataset as ACCeLLiuM we hope to establish a reproducible benchmark for
LLM-powered OpenACC pragma generation, and lower the barrier to automated GPU
offloading of serially written programs.

</details>


### [4] [State-of-the-Art in Software Security Visualization: A Systematic Review](https://arxiv.org/abs/2509.20385)
*Ishara Devendra,Chaman Wijesiriwardana,Prasad Wimalaratne*

Main category: cs.SE

TL;DR: 该论文系统综述了软件安全可视化领域，建立了分类体系，总结了当前技术及未来方向，强调了创新型可视化方法对安全防护的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统复杂性增加以及威胁环境演变，传统的基于文本和数字的安全分析方法变得越来越低效，需要新的方法更高效地理解和应对安全威胁。

Method: 系统性回顾现有文献，通过梳理60余篇关键论文，将软件安全可视化技术归类为四种类型：基于图、符号、矩阵和隐喻的可视化方法，构建全面的分类体系。

Result: 系统性分析展现了软件安全可视化领域的主要问题、最新进展和未来研究方向。两个主要关注点包括：用于软件架构可视化的方法，以及面向操作安全和网络安全的可视化技术。

Conclusion: 需要创新的可视化技术以适应不断变化的安全环境，这对于提升威胁检测能力、改进安全响应策略、并指导未来研究具有重要实践意义。

Abstract: Software security visualization is an interdisciplinary field that combines
the technical complexity of cybersecurity, including threat intelligence and
compliance monitoring, with visual analytics, transforming complex security
data into easily digestible visual formats. As software systems get more
complex and the threat landscape evolves, traditional text-based and numerical
methods for analyzing and interpreting security concerns become increasingly
ineffective. The purpose of this paper is to systematically review existing
research and create a comprehensive taxonomy of software security visualization
techniques through literature, categorizing these techniques into four types:
graph-based, notation-based, matrix-based, and metaphor-based visualization.
This systematic review explores over 60 recent key research papers in software
security visualization, highlighting its key issues, recent advancements, and
prospective future research directions. From the comprehensive analysis, the
two main areas were distinctly highlighted as extensive software development
visualization, focusing on advanced methods for depicting software
architecture: operational security visualization and cybersecurity
visualization. The findings highlight the necessity for innovative
visualization techniques that adapt to the evolving security landscape, with
practical implications for enhancing threat detection, improving security
response strategies, and guiding future research.

</details>


### [5] [Dynamic ReAct: Scalable Tool Selection for Large-Scale MCP Environments](https://arxiv.org/abs/2509.20386)
*Nishant Gaurav,Adit Akarsh,Ankit Ranjan,Manoj Bajaj*

Main category: cs.SE

TL;DR: 论文提出了一种高效筛选和加载海量工具的新方法Dynamic ReAct，能大幅减少计算资源消耗，同时保持完成任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前ReAct智能体在面对成百上千个工具的复杂环境时，会受到大语言模型上下文长度和计算资源的显著限制，因此如何高效选择和加载所需工具成为一大挑战。

Method: 提出了Dynamic ReAct方法，并设计和评估了五种递进式架构，优化工具筛选流程，最终采用了“搜索-加载”机制实现高效智能工具选择。

Result: 实验结果表明，该方法可在保持任务准确率的前提下，减少最多50%的工具加载量。

Conclusion: Dynamic ReAct方法有效降低了智能体的计算负担，提高了适应复杂多变环境下的通用性，为通用型AI在动态任务中高效运作铺平道路。

Abstract: We present Dynamic ReAct, a novel approach for enabling ReAct agents to ef-
ficiently operate with extensive Model Control Protocol (MCP) tool sets that
exceed the contextual memory limitations of large language models. Our approach
addresses the fundamental challenge of tool selection in environments
containing hundreds or thousands of available tools, where loading all tools
simultaneously is computationally infeasible. We propose and evaluate five
distinct architectures that progressively refine the tool selection process,
culminating in a search-and-load mechanism that achieves intelligent tool
selection with minimal computational overhead. Our experimental results
demonstrate that the proposed approach reduces tool loading by up to 50% while
maintaining task completion accuracy, advancing the path towards truly
general-purpose AI agents capable of dynamically adapting to diverse task
environments.

</details>


### [6] [Enhancing Python Programming Education with an AI-Powered Code Helper: Design, Implementation, and Impact](https://arxiv.org/abs/2509.20518)
*Sayed Mahbub Hasan Amiri,Md Mainul Islam*

Main category: cs.SE

TL;DR: 本论文提出了一种结合代码分析、动态追踪和LLM的新型AI聊天机器人，在编程教学场景下显著优于传统工具，提升学生技能和信心，为教育型AI设计提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 传统编程工具，如IDE和静态分析器，无法为编程学习者提供类人辅导式帮助，而现有AI代码助手(如GitHub Copilot)更偏重于代码完成，并未完全满足学生学习编程过程中的需求，因此研究旨在弥补这一差距。

Method: 提出基于AI和Python的聊天机器人，融合静态代码分析、动态执行追踪和大语言模型（LLM）。架构采用CodeLlama做代码嵌入，GPT-4负责自然语言交互，用Docker容器保障安全执行，评价方法为混合方法（包括1500份学生提交的定量分析及120名学生的定性反馈）。

Result: 系统比独立工具提升更高的错误解决率（Chatbot 85%，pylint 62%，GPT-4单独 73%），用户调试时间减少59.3%，学生编程能力提升34%，在递归与异常处理方面尤为突出。学生反馈机器人的表达清晰、易用，能增强信心，但也指出有延迟和代码限制等缺点。

Conclusion: 本研究展示了AI辅助编程教育的范例，不仅提升学习效果，还促进长期技能保留，是关注教育公平和师生互动的工具设计的新蓝图。

Abstract: This is the study that presents an AI-Python-based chatbot that helps
students to learn programming by demonstrating solutions to such problems as
debugging errors, solving syntax problems or converting abstract theoretical
concepts to practical implementations. Traditional coding tools like Integrated
Development Environments (IDEs) and static analyzers do not give robotic help
while AI-driven code assistants such as GitHub Copilot focus on getting things
done. To close this gap, our chatbot combines static code analysis, dynamic
execution tracing, and large language models (LLMs) to provide the students
with relevant and practical advice, hence promoting the learning process. The
chatbots hybrid architecture employs CodeLlama for code embedding, GPT-4 for
natural language interactions, and Docker-based sandboxing for secure
execution. Evaluated through a mixed-methods approach involving 1,500 student
submissions, the system demonstrated an 85% error resolution success rate,
outperforming standalone tools like pylint (62%) and GPT-4 (73%). Quantitative
results revealed a 59.3% reduction in debugging time among users, with pre- and
post-test assessments showing a 34% improvement in coding proficiency,
particularly in recursion and exception handling. Qualitative feedback from 120
students highlighted the chatbots clarity, accessibility, and
confidence-building impact, though critiques included occasional latency and
restrictive code sanitization. By balancing technical innovation with
pedagogical empathy, this research provides a blueprint for AI tools that
prioritize educational equity and long-term skill retention over mere code
completion. The chatbot exemplifies how AI can augment human instruction,
fostering deeper conceptual understanding in programming education.

</details>


### [7] [Towards Systematic Specification and Verification of Fairness Requirements: A Position Paper](https://arxiv.org/abs/2509.20387)
*Qusai Ramadan,Jukka Ruohonen,Abhishek Tiwari,Adam Alami,Zeyd Boukhers*

Main category: cs.SE

TL;DR: 当前算法公平性问题关注点不足，作者提出基于知识图谱的公平框架设想，并绘制了未来研究路线图。


<details>
  <summary>Details</summary>
Motivation: 当前软件系统在设计不当时，可能会对性别、种族等受保护特征产生歧视。以往研究主要归因于算法设计缺陷或数据偏见，但忽略了公平需求规范和验证的不足。专家关于公平的知识通常是隐性的，这导致公平需求难以精准且可验证地规范。

Method: 借鉴安全工程领域知识图谱用于知识形式化和需求规范的做法，论文提出开发一个基于知识图谱的公平性框架，以支持公平需求的规范与验证。文章探讨了相关挑战、研究问题及解决路径。

Result: 目前尚未实现具体框架，主要提出了研究路线图和讨论相关挑战与问题。

Conclusion: 文章指出解决公平需求规范与验证缺失问题的紧迫性，倡议基于知识图谱的方法来辅助公平需求管理，并提出未来的研究方向。

Abstract: Decisions suggested by improperly designed software systems might be prone to
discriminate against people based on protected characteristics, such as gender
and ethnicity. Previous studies attribute such undesired behavior to flaws in
algorithmic design or biased data. However, these studies ignore that
discrimination is often the result of a lack of well-specified fairness
requirements and their verification. The fact that experts' knowledge about
fairness is often implicit makes the task of specifying precise and verifiable
fairness requirements difficult. In related domains, such as security
engineering, knowledge graphs have been proven to be effective in formalizing
knowledge to assist requirements specification and verification. To address the
lack of formal mechanisms for specifying and verifying fairness requirements,
we propose the development of a knowledge graph-based framework for fairness.
In this paper, we discuss the challenges, research questions, and a road map
towards addressing the research questions.

</details>


### [8] [Online-Optimized RAG for Tool Use and Function Calling](https://arxiv.org/abs/2509.20415)
*Yu Pan,Xiaocheng Li,Hanzhao Wang*

Main category: cs.SE

TL;DR: 本文针对RAG系统检索嵌入不对齐问题，提出了一个在线优化嵌入的新方法，能在多种任务下显著提升工具选择准确率和工作成功率，简单易用，适合实际部署。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG系统在工具或函数调用时，会将用户查询与工具描述进行嵌入匹配。但由于嵌入模型不完美或描述文本噪声，导致嵌入不对齐，检索结果可能错误，影响任务完成。本文希望解决实际应用中嵌入错位导致的检索问题。

Method: 提出了Online-Optimized RAG框架，该方法在系统部署时在线优化检索嵌入，通过最小化反馈（如任务成功与否），使用在线梯度更新来适应嵌入，无需修改底层LLM，且对每次查询延迟极低。可直接用于单跳、多跳工具使用、动态工具库和K-检索重排序，是一种即插即用方案。

Result: 在不同的工具使用和文档检索场景下，Online-Optimized RAG框架能持续提升工具选择的准确性和任务成功率。理论分析说明了该方法性能与嵌入初始化质量等因素的关系。

Conclusion: 提出了一种轻量、实用且自我改进的RAG优化方案，可增强系统鲁棒性和实际效果。

Abstract: In many applications, retrieval-augmented generation (RAG) drives tool use
and function calling by embedding the (user) queries and matching them to
pre-specified tool/function descriptions. In this paper, we address an
embedding misalignment issue that often arises in practical applications due to
imperfect embedding models or noisy descriptions; such misalignment may lead to
incorrect retrieval and task failure. We introduce Online-Optimized RAG, a
deployment-time framework that continually adapts retrieval embeddings from
live interactions using minimal feedback (e.g., task success). Online-Optimized
RAG applies lightweight online gradient updates with negligible per-query
latency and requires no changes to the underlying LLM. The method is
plug-and-play: it supports both single- and multi-hop tool use, dynamic tool
inventories, and $K$-retrieval with re-ranking. We provide a problem-dependent
theoretical analysis that quantifies how the method's performance depends on
the initialization quality of the embeddings and other related quantities.
Across diverse tool-use and document-retrieval scenarios, our Online-Optimized
RAG consistently improves tool selection accuracy and end-task success, thus
providing a simple, practical path to robust, self-improving RAG systems.

</details>


### [9] [Formal Verification of Legal Contracts: A Translation-based Approach](https://arxiv.org/abs/2509.20421)
*Reiner Hähnle,Cosimo Laneve,Adele Veschetti*

Main category: cs.SE

TL;DR: 本文提出将 Stipula 合约自动转换为带 JML 注释的 Java 代码，利用 KeY 工具进行自动化的正确性验证，尤其适用于无交集循环的合约类型，有效提升了法律合约代码的可验证性。


<details>
  <summary>Details</summary>
Motivation: Stipula 专门用于建模涉及资产转移和义务的法律合约，其正确性至关重要。现有工具无法直接验证此类合约，因此需要一种有效的自动化验证方法。

Method: 将 Stipula 域特定语言的合约自动翻译为带有 Java Modeling Language 注释的 Java 代码，然后用 KeY 工具进行推理验证。

Result: 对于包含无交集循环的大子集 Stipula 合约，可以实现自动化的部分和完全正确性验证。验证过程无需人工干预。

Conclusion: 通用的推理验证工具（KeY）可通过自动的翻译流程有效验证 Stipula 合约的正确性。

Abstract: Stipula is a domain-specific programming language designed to model legal
contracts with enforceable properties, especially those involving asset
transfers and obligations. This paper presents a methodology to formally verify
the correctness of Stipula contracts through translation into Java code
annotated with Java Modeling Language specifications. As a verification
backend, the deductive verification tool KeY is used. Both, the translation and
the verification of partial and total correctness for a large subset of Stipula
contracts, those with disjoint cycles, is fully automatic. Our work
demonstrates that a general-purpose deductive verification tool can be used
successfully in a translation approach.

</details>


### [10] [AI-Specific Code Smells: From Specification to Detection](https://arxiv.org/abs/2509.20491)
*Brahim Mahmoudi,Naouel Moha,Quentin Stievenert,Florent Avellaneda*

Main category: cs.SE

TL;DR: 针对传统工具无法检测的AI领域代码异味，作者提出了SpecDetect4AI，通过DSL规则和静态分析实现高效检测，在多项指标上表现优异，适合大规模AI系统使用。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统的兴起，现有的软件检测工具无法有效识别AI特有的问题，如不可复现、隐性失败或模型泛化能力差。因此，需要专门针对AI系统的代码“异味”进行检测。

Method: 提出了SpecDetect4AI工具，采用高层次声明式领域特定语言（DSL）进行规则制定，并结合可扩展的静态分析工具进行代码异味检测。

Result: 在826个AI系统（2千万行代码）中检测22种AI特有代码异味，取得了88.66%的精度和88.89%的召回率，优于现有检测工具。用户满意度得分为81.7（满分100）。

Conclusion: SpecDetect4AI能够高效且可扩展地支持AI系统中特有代码异味的规则制定与检测，适合大规模AI系统分析，效果优越。

Abstract: The rise of Artificial Intelligence (AI) is reshaping how software systems
are developed and maintained. However, AI-based systems give rise to new
software issues that existing detection tools often miss. Among these, we focus
on AI-specific code smells, recurring patterns in the code that may indicate
deeper problems such as unreproducibility, silent failures, or poor model
generalization. We introduce SpecDetect4AI, a tool-based approach for the
specification and detection of these code smells at scale. This approach
combines a high-level declarative Domain-Specific Language (DSL) for rule
specification with an extensible static analysis tool that interprets and
detects these rules for AI-based systems. We specified 22 AI-specific code
smells and evaluated SpecDetect4AI on 826 AI-based systems (20M lines of code),
achieving a precision of 88.66% and a recall of 88.89%, outperforming other
existing detection tools. Our results show that SpecDetect4AI supports the
specification and detection of AI-specific code smells through dedicated rules
and can effectively analyze large AI-based systems, demonstrating both
efficiency and extensibility (SUS 81.7/100).

</details>


### [11] [PromptDebt: A Comprehensive Study of Technical Debt Across LLM Projects](https://arxiv.org/abs/2509.20497)
*Ahmed Aljohani,Hyunsook Do*

Main category: cs.SE

TL;DR: 本文系统分析了LLM集成的软件技术债务，发现问题主要集中在提示设计和配置，OpenAI集成风险最大，并发布相关债务数据集，为后续研究和工程实践提供了参考。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）通过API嵌入软件系统已成为趋势，尽管带来强大能力，但也引入了新的技术债务问题，特别是针对LLM集成的自我承认技术债务（SATD）。目前对这一领域缺乏大规模、系统性的实证分析。

Method: 作者对93,142个主要LLM API相关的Python文件进行了大规模数据分析，统计SATD的来源、分布及缓解策略，并对不同提示设计和技术债务的风险进行了分类。同时，发布了SATD数据集用于研究复现。

Result: 超过一半（54.49%）的SATD来自OpenAI集成，12.35%来自LangChain。提示设计成为LLM相关技术债务的最大来源，6.61%债务与提示配置和优化相关。说明基于指令和few-shot的提示更易引发债务（分别达38.60%和18.13%），与指令清晰度和示例质量相关。

Conclusion: LLM集成带来的技术债务主要集中于提示设计和配置，尤其OpenAI和LangChain集成。指令型和few-shot提示风险高。论文为业界提供了数据支持和实用建议以管理这类新型技术债务。

Abstract: Large Language Models (LLMs) are increasingly embedded in software via APIs
like OpenAI, offering powerful AI features without heavy infrastructure. Yet
these integrations bring their own form of self-admitted technical debt (SATD).
In this paper, we present the first large-scale empirical study of LLM-specific
SATD: its origins, prevalence, and mitigation strategies. By analyzing 93,142
Python files across major LLM APIs, we found that 54.49% of SATD instances stem
from OpenAI integrations and 12.35% from LangChain use. Prompt design emerged
as the primary source of LLM-specific SATD, with 6.61% of debt related to
prompt configuration and optimization issues, followed by hyperparameter tuning
and LLM-framework integration. We further explored which prompt techniques
attract the most debt, revealing that instruction-based prompts (38.60%) and
few-shot prompts (18.13%) are particularly vulnerable due to their dependence
on instruction clarity and example quality. Finally, we release a comprehensive
SATD dataset to support reproducibility and offer practical guidance for
managing technical debt in LLM-powered systems.

</details>


### [12] [Enhancing LLM-based Fault Localization with a Functionality-Aware Retrieval-Augmented Generation Framework](https://arxiv.org/abs/2509.20552)
*Xinyu Shi,Zhenhao Li,An Ran Chen*

Main category: cs.SE

TL;DR: 本文提出了结合检索增强和LLM的新方法（FaR-Loc），在主流基准上显著优于现有方法，尤其适合复杂和大型项目的故障定位。


<details>
  <summary>Details</summary>
Motivation: 传统基于大模型的故障定位，因缺乏项目特定知识和面对大型项目时难以导航，效果受限。

Method: 提出FaR-Loc方法，将LLM与检索增强生成（RAG）相结合。其流程包含三个模块：LLM功能提取（对故障行为进行自然语言描述）、语义密集检索（代码与描述共嵌入至语义空间以检索相关方法）、LLM重排序（根据上下文相关性重新排序）。

Result: 在Defects4J基准上，FaR-Loc方法分别较SoapFL和AutoFL提升Top-1准确率14.6%和9.1%，Top-5提升19.2%和22.1%；在所有Top-N指标上都优于传统学习和谱基线，并且无需重新训练。融合代码结构的UniXcoder嵌入模型最高能提升49%的Top-1准确率。

Conclusion: 融合RAG的LLM方法能显著提升故障定位精准度，对实际大型项目有更强适应性，且不需额外训练。

Abstract: Fault localization (FL) is a critical but time-consuming task in software
debugging, aiming to identify faulty code elements. While recent advances in
large language models (LLMs) have shown promise for FL, they often struggle
with complex systems due to the lack of project-specific knowledge and the
difficulty of navigating large projects. To address these limitations, we
propose FaR-Loc, a novel framework that enhances method-level FL by integrating
LLMs with retrieval-augmented generation (RAG). FaR-Loc consists of three key
components: LLM Functionality Extraction, Semantic Dense Retrieval, and LLM
Re-ranking. First, given a failed test and its associated stack trace, the LLM
Functionality Extraction module generates a concise natural language
description that captures the failing behavior. Next, the Semantic Dense
Retrieval component leverages a pre-trained code-understanding encoder to embed
both the functionality description (natural language) and the covered methods
(code) into a shared semantic space, enabling the retrieval of methods with
similar functional behavior. Finally, the LLM Re-ranking module reorders the
retrieved methods based on their contextual relevance. Our experiments on the
widely used Defects4J benchmark show that FaR-Loc outperforms state-of-the-art
LLM-based baselines SoapFL and AutoFL, by 14.6% and 9.1% in Top-1 accuracy, by
19.2% and 22.1% in Top-5 accuracy, respectively. It also surpasses all
learning-based and spectrum-based baselines across all Top-N metrics without
requiring re-training. Furthermore, we find that pre-trained code embedding
models that incorporate code structure, such as UniXcoder, can significantly
improve fault localization performance by up to 49.0% in Top-1 accuracy.
Finally, we conduct a case study to illustrate the effectiveness of FaR-Loc and
to provide insights for its practical application.

</details>


### [13] [Design, Implementation and Evaluation of a Novel Programming Language Topic Classification Workflow](https://arxiv.org/abs/2509.20631)
*Michael Zhang,Yuan Tian,Mariam Guizani*

Main category: cs.SE

TL;DR: 本文提出了一种结合多标签SVM、滑动窗口与投票策略的代码细粒度主题分类方法，在CodeNet数据集上表现优异，并为代码分析领域提供了可复用的流程和实证结论。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统规模和复杂性的增加，了解源代码内编程语言主题的分布对于技术决策、人才培养、工具开发和教育有重要意义。

Method: 方法结合了多标签支持向量机（SVM）、滑动窗口和投票策略，用于实现对源代码中各类编程语言主题的细粒度分类和定位。

Result: 模型在IBM Project CodeNet数据集上训练，在各主题的平均F1得分为0.90，在代码-主题高亮方面为0.75。

Conclusion: 论文提出了一种创新的编程语言主题分类流程，在精细定位源代码中的核心语言概念方面有效，并为代码分析领域提供了实用工具和经验数据。

Abstract: As software systems grow in scale and complexity, understanding the
distribution of programming language topics within source code becomes
increasingly important for guiding technical decisions, improving onboarding,
and informing tooling and education. This paper presents the design,
implementation, and evaluation of a novel programming language topic
classification workflow. Our approach combines a multi-label Support Vector
Machine (SVM) with a sliding window and voting strategy to enable fine-grained
localization of core language concepts such as operator overloading, virtual
functions, inheritance, and templates. Trained on the IBM Project CodeNet
dataset, our model achieves an average F1 score of 0.90 across topics and 0.75
in code-topic highlight. Our findings contribute empirical insights and a
reusable pipeline for researchers and practitioners interested in code analysis
and data-driven software engineering.

</details>


### [14] [Exploring Engagement in Hybrid Meetings](https://arxiv.org/abs/2509.20780)
*Daniela Grassi,Fabio Calefato,Darja Smite,Nicole Novielli,Filippo Lanubile*

Main category: cs.SE

TL;DR: 混合办公下，远程参与者在长会议中的参与度偏低，积极角色能提升参与度，大型与下午会议不利于参与，高参与度建议对会议时间和角色进行优化。


<details>
  <summary>Details</summary>
Motivation: 新冠疫情后，混合办公模式普及，改变了软件开发的协作和沟通方式，但远程参与可能导致团队成员孤立、疏离和参与度下降。

Method: 对三家软件公司的专业人员进行为期数周的研究，采用多模态方法，通过自我报告问卷和生理测量（生物识别设备）评估在混合会议中的参与度。

Result: 回归分析显示，现场与远程参与者的参与度总体相当，但长会议中远程参与者的参与度较低。积极角色与较高参与度正相关，大型会议和下午会议与较低参与度相关。

Conclusion: 结果揭示影响混合会议参与度的因素，为提升会议体验和效果提出建议，这些发现适用于软件团队及其他依赖知识密集型协作的组织。

Abstract: Background. The widespread adoption of hybrid work following the COVID-19
pandemic has fundamentally transformed software development practices,
introducing new challenges in communication and collaboration as organizations
transition from traditional office-based structures to flexible working
arrangements. This shift has established a new organizational norm where even
traditionally office-first companies now embrace hybrid team structures. While
remote participation in meetings has become commonplace in this new
environment, it may lead to isolation, alienation, and decreased engagement
among remote team members. Aims. This study aims to identify and characterize
engagement patterns in hybrid meetings through objective measurements, focusing
on the differences between co-located and remote participants. Method. We
studied professionals from three software companies over several weeks,
employing a multimodal approach to measure engagement. Data were collected
through self-reported questionnaires and physiological measurements using
biometric devices during hybrid meetings to understand engagement dynamics.
Results. The regression analyses revealed comparable engagement levels between
onsite and remote participants, though remote participants show lower
engagement in long meetings regardless of participation mode. Active roles
positively correlate with higher engagement, while larger meetings and
afternoon sessions are associated with lower engagement. Conclusions. Our
results offer insights into factors associated with engagement and
disengagement in hybrid meetings, as well as potential meeting improvement
recommendations. These insights are potentially relevant not only for software
teams but also for knowledge-intensive organizations across various sectors
facing similar hybrid collaboration challenges.

</details>


### [15] [Verification Limits Code LLM Training](https://arxiv.org/abs/2509.20837)
*Srishti Gureja,Elena Tommasone,Jingyi He,Sara Hooker,Matthias Gallé,Marzieh Fadaee*

Main category: cs.SE

TL;DR: 针对代码生成模型依赖合成数据训练，本文发现验证设计过于刚性，限制了模型表现。通过优化验证策略（如软性标准、多样化测试）和资源多元化，可以提升模型泛化能力和实际性能。


<details>
  <summary>Details</summary>
Motivation: 现今代码生成的大型语言模型大量依赖合成数据，其中问题的解决方案与验证测试都由模型生成。这种方法提升了数据生成的可扩展性，但也带来了一个新的瓶颈——验证上限，即训练数据的质量与多样性受到合成验证器能力的根本限制。

Method: 系统性地研究验证设计和策略如何影响代码生成模型性能。包括分析测试复杂度与数量对模型的影响、探索放宽测试通过门槛（如非严格100%通过或用LLM软性验证），以及对比形式正确与错误解及多样化正确解对泛化性能的影响。

Result: (i) 丰富的测试集增强了模型的代码生成能力，平均提升pass@1约3个百分点，仅增加数量则收益递减；(ii) 放宽通过门槛或采用LLM软验证可回收有价值的训练数据，进而带来2-4点的pass@1提升，但依赖测试的强度和多样性；(iii) 保留多样的正确解决方案有助于泛化性能。当前验证实践过于刚性，会过滤掉有价值的多样数据，但验证机制不可完全废弃，只能校准与优化。

Conclusion: 合成验证机制存在上限，需要通过验证策略优化和多样化问题-解决方案对的结合来突破，进而提升代码生成模型的能力。

Abstract: Large language models for code generation increasingly rely on synthetic
data, where both problem solutions and verification tests are generated by
models. While this enables scalable data creation, it introduces a previously
unexplored bottleneck: the verification ceiling, in which the quality and
diversity of training data are fundamentally constrained by the capabilities of
synthetic verifiers. In this work, we systematically study how verification
design and strategies influence model performance. We investigate (i) what we
verify by analyzing the impact of test complexity and quantity: richer test
suites improve code generation capabilities (on average +3 pass@1), while
quantity alone yields diminishing returns, (ii) how we verify by exploring
relaxed pass thresholds: rigid 100% pass criteria can be overly restrictive. By
allowing for relaxed thresholds or incorporating LLM-based soft verification,
we can recover valuable training data, leading to a 2-4 point improvement in
pass@1 performance. However, this benefit is contingent upon the strength and
diversity of the test cases used, and (iii) why verification remains necessary
through controlled comparisons of formally correct versus incorrect solutions
and human evaluation: retaining diverse correct solutions per problem yields
consistent generalization gains. Our results show that Verification as
currently practiced is too rigid, filtering out valuable diversity. But it
cannot be discarded, only recalibrated. By combining calibrated verification
with diverse, challenging problem-solution pairs, we outline a path to break
the verification ceiling and unlock stronger code generation models.

</details>


### [16] [PseudoBridge: Pseudo Code as the Bridge for Better Semantic and Logic Alignment in Code Retrieval](https://arxiv.org/abs/2509.20881)
*Yixuan Li,Xinyi Liu,Weidong Yang,Ben Fei,Shuhao Li,Mingjie Zhou,Lipeng Ma*

Main category: cs.SE

TL;DR: 现有代码检索方法仍受制于语义对齐和代码风格泛化难题。本文提出PseudoBridge，通过大型语言模型生成伪代码，并多样化代码风格实现逻辑对齐，在多模型多语言中均取得了显著效果，尤其在零样本领域泛化表现优异，是更强健和通用的代码检索方案。


<details>
  <summary>Details</summary>
Motivation: 尽管通过预训练语言模型（PLMs）提升了代码检索的性能，但在自然语言与编程语言的语义对齐、以及对多样化代码风格的鲁棒性方面仍存在挑战。主要困难包括：人类意图与机器执行逻辑间的语义鸿沟，以及模型对不同代码风格的适应能力有限。

Method: 提出了PseudoBridge框架，将伪代码作为中间的、半结构化的桥梁，分两阶段进行：首先利用大型语言模型（LLM）生成伪代码，实现自然语言查询与伪代码对齐；其次通过逻辑不变的代码风格扩充策略，用LLM生成多风格但逻辑等价的代码，并加强伪代码与不同风格代码的对齐，以增强模型对代码风格变异的鲁棒性。

Result: 在10个不同PLM和6种主流编程语言上进行评估，PseudoBridge在检索准确性和泛化能力上均显著优于现有方法，尤其在跨领域（如Solidity和XLCoST数据集）零样本场景下表现突出。结果证实了伪代码的显式逻辑对齐和框架的泛化鲁棒性。

Conclusion: 通过伪代码作为中介，PseudoBridge有效实现了自然语言与代码的逻辑对齐，显著提升了代码检索的准确性、鲁棒性和泛化能力，展示出作为通用代码检索解决方案的潜力。

Abstract: Code search aims to precisely find relevant code snippets that match natural
language queries within massive codebases, playing a vital role in software
development. Recent advances leverage pre-trained language models (PLMs) to
bridge the semantic gap between unstructured natural language (NL) and
structured programming languages (PL), yielding significant improvements over
traditional information retrieval and early deep learning approaches. However,
existing PLM-based methods still encounter key challenges, including a
fundamental semantic gap between human intent and machine execution logic, as
well as limited robustness to diverse code styles. To address these issues, we
propose PseudoBridge, a novel code retrieval framework that introduces
pseudo-code as an intermediate, semi-structured modality to better align NL
semantics with PL logic. Specifically, PseudoBridge consists of two stages.
First, we employ an advanced large language model (LLM) to synthesize
pseudo-code, enabling explicit alignment between NL queries and pseudo-code.
Second, we introduce a logic-invariant code style augmentation strategy and
employ the LLM to generate stylistically diverse yet logically equivalent code
implementations with pseudo-code, then align the code snippets of different
styles with pseudo-code, enhancing model robustness to code style variation. We
build PseudoBridge across 10 different PLMs and evaluate it on 6 mainstream
programming languages. Extensive experiments demonstrate that PseudoBridge
consistently outperforms baselines, achieving significant gains in retrieval
accuracy and generalization, particularly under zero-shot domain transfer
scenarios such as Solidity and XLCoST datasets. These results demonstrate the
effectiveness of explicit logical alignment via pseudo-code and highlight
PseudoBridge's potential as a robust, generalizable solution for code
retrieval.

</details>


### [17] [Designing for Novice Debuggers: A Pilot Study on an AI-Assisted Debugging Tool](https://arxiv.org/abs/2509.21067)
*Oka Kurniawan,Erick Chandra,Christopher M. Poskitt,Yannic Noller,Kenny Tsu Wei Choo,Cyrille Jegourel*

Main category: cs.SE

TL;DR: 本文提出并测试了CodeHinter调试助手，结合传统调试与AI模型，能够高效帮助学生修复语义错误，并促进主动参与调试。工具易用性提升明显，具备个性化设计潜力。


<details>
  <summary>Details</summary>
Motivation: 当前许多调试工具虽能修复学生代码中的错误，但容易让学生过度依赖AI，缺乏主动参与调试，因此需要开发可促进学生积极参与且更直观的调试工具。

Method: 设计了一款结合传统调试工具与大型语言模型（LLM）技术的调试助手CodeHinter，并在本科生群体中进行了第二轮设计迭代测试。

Result: CodeHinter在修复语义错误上表现高效，学生认为该工具比第一版更容易使用，其中错误定位功能尤为有价值。

Conclusion: AI辅助调试工具应根据用户画像进行个性化设计，以优化与学生的互动。

Abstract: Debugging is a fundamental skill that novice programmers must develop.
Numerous tools have been created to assist novice programmers in this process.
Recently, large language models (LLMs) have been integrated with automated
program repair techniques to generate fixes for students' buggy code. However,
many of these tools foster an over-reliance on AI and do not actively engage
students in the debugging process. In this work, we aim to design an intuitive
debugging assistant, CodeHinter, that combines traditional debugging tools with
LLM-based techniques to help novice debuggers fix semantic errors while
promoting active engagement in the debugging process. We present findings from
our second design iteration, which we tested with a group of undergraduate
students. Our results indicate that the students found the tool highly
effective in resolving semantic errors and significantly easier to use than the
first version. Consistent with our previous study, error localization was the
most valuable feature. Finally, we conclude that any AI-assisted debugging tool
should be personalized based on user profiles to optimize their interactions
with students.

</details>


### [18] [An Improved Quantum Software Challenges Classification Approach using Transfer Learning and Explainable AI](https://arxiv.org/abs/2509.21068)
*Nek Dil Khan,Javed Ali Khan,Mobashir Husain,Muhammad Sohail Khan,Arif Ali Khan,Muhammad Azeem Akbar,Shahid Hussain*

Main category: cs.SE

TL;DR: 本研究通过内容分析和扎根理论整理量子开发领域的Q&A数据，发现主流困难，并用BERT等模型实现高准确率分类。结果显示变换器优于传统方法，且采用SHAP增强模型可解释性，对行业有组织讨论和提升帮助，但需进一步实际验证。


<details>
  <summary>Details</summary>
Motivation: 量子软件工程（QSE）是技术公司关注的研究领域，但量子开发者在优化量子计算及QSE概念时遇到诸多挑战，他们常在问答平台如Stack Overflow讨论并标注与量子相关的问题标签。当前标签多偏技术层面，缺乏对实际开发者问题的明确分类。通过对问题进行分类，可以揭示QSE领域内常见难题，有助于行业发展。

Method: 作者收集了2829条带有量子标签的问题，从Q&A平台提取并分析内容，归纳出了最常见的挑战类型（如工具、理论、学习、概念、错误、API使用），结合内容分析与扎根理论建立了标注数据集。人类标注数据之后利用ChatGPT进行验证和纠正分歧，随后用BERT、DistilBERT、RoBERTa等变换器模型进行分类，与传统深度/机器学习模型（FNN、CNN、LSTM）进行准确率对比，并使用SHAP解释模型预测。

Result: 变换器模型（如BERT DistilBERT）的平均准确率达95%，优于深度/机器学习模型（FNN、CNN、LSTM）的89%、86%、84%。SHAP分析提升了模型解释性，揭示了语言特征对预测结果的影响。

Conclusion: 基于变换器的分类方法能更准确识别和组织量子软件工程领域的开发者实际挑战，为论坛和供应商改善访问与可读性提供支持，但仍需结合实际开发者与供应商进行实证研究。

Abstract: Quantum Software Engineering (QSE) is a research area practiced by tech
firms. Quantum developers face challenges in optimizing quantum computing and
QSE concepts. They use Stack Overflow (SO) to discuss challenges and label
posts with specialized quantum tags, which often refer to technical aspects
rather than developer posts. Categorizing questions based on quantum concepts
can help identify frequent QSE challenges. We conducted studies to classify
questions into various challenges. We extracted 2829 questions from Q&A
platforms using quantum-related tags. Posts were analyzed to identify frequent
challenges and develop a novel grounded theory. Challenges include Tooling,
Theoretical, Learning, Conceptual, Errors, and API Usage. Through content
analysis and grounded theory, discussions were annotated with common challenges
to develop a ground truth dataset. ChatGPT validated human annotations and
resolved disagreements. Fine-tuned transformer algorithms, including BERT,
DistilBERT, and RoBERTa, classified discussions into common challenges. We
achieved an average accuracy of 95% with BERT DistilBERT, compared to
fine-tuned Deep and Machine Learning (D&ML) classifiers, including Feedforward
Neural Networks (FNN), Convolutional Neural Networks (CNN), and Long Short-Term
Memory networks (LSTM), which achieved accuracies of 89%, 86%, and 84%,
respectively. The Transformer-based approach outperforms the D&ML-based
approach with a 6\% increase in accuracy by processing actual discussions,
i.e., without data augmentation. We applied SHAP (SHapley Additive
exPlanations) for model interpretability, revealing how linguistic features
drive predictions and enhancing transparency in classification. These findings
can help quantum vendors and forums better organize discussions for improved
access and readability. However,empirical evaluation studies with actual
developers and vendors are needed.

</details>


### [19] [Fine-Tuning LLMs to Analyze Multiple Dimensions of Code Review: A Maximum Entropy Regulated Long Chain-of-Thought Approach](https://arxiv.org/abs/2509.21170)
*Yongda Yu,Guohao Shi,Xianwei Wu,Haochuan He,XueMing Gu,Qianqian Zhao,Kui Liu,Qiushi Wang,Zhao Tian,Haifeng Shen,Guoping Rong*

Main category: cs.SE

TL;DR: 本文提出MelcotCR链式思维微调方法，通过最大熵建模和预定义推理路径，有效提升低参数LLM在代码审查多维推理上的性能，超越当前先进方法，并接近超大模型效果。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）用于自动化代码审查虽具潜力，但由于训练数据限制，与人类认知相比仍有不足，尤其在分析代码问题的多个维度方面。人类评审往往从多角度同时分析代码，而模型微调信息有限，影响了其性能。

Method: 本文提出MelcotCR链式思维(COT)微调方法，通过长链式思维技术为模型提供丰富结构化信息，使其能分析代码审查中的多个维度。同时，为了解决LLM在长COT提示下的语境丢失和逻辑推理能力弱化问题，提出融合最大熵（ME）建模原理与预定义推理路径的策略，加强模型的推理逻辑紧密性和信息利用效率。

Result: 在MelcotCR自建数据集和公开CodeReviewer数据集上的实证评估显示，基于MelcotCR微调的低参数模型（如14B Qwen2.5）在代码问题检测和描述准确率上超越了现有最先进方法，在性能上与更高参数的671B DeepSeek-R1模型表现接近。

Conclusion: 提出用于代码审查多维度推理的MelcotCR链式思维微调框架，在提升低参数LLM模型表现的同时，显著增强其推理能力和逻辑严密性，优于当前SOTA方法并接近超大模型水平。

Abstract: Large Language Models (LLMs) have shown great potential in supporting
automated code review due to their impressive capabilities in context
understanding and reasoning. However, these capabilities are still limited
compared to human-level cognition because they are heavily influenced by the
training data. Recent research has demonstrated significantly improved
performance through fine-tuning LLMs with code review data. However, compared
to human reviewers who often simultaneously analyze multiple dimensions of code
review to better identify issues, the full potential of these methods is
hampered by the limited or vague information used to fine-tune the models. This
paper contributes MelcotCR, a chain-of-thought (COT) fine-tuning approach that
trains LLMs with an impressive reasoning ability to analyze multiple dimensions
of code review by harnessing long COT techniques to provide rich structured
information. To address context loss and reasoning logic loss issues that
frequently occur when LLMs process long COT prompts, we propose a solution that
combines the Maximum Entropy (ME) modeling principle with pre-defined reasoning
pathways in MelcotCR to enable more effective utilization of in-context
knowledge within long COT prompts while strengthening the logical tightness of
the reasoning process. Empirical evaluations on our curated MelcotCR dataset
and the public CodeReviewer dataset reveal that a low-parameter base model,
such as 14B Qwen2.5, fine-tuned with MelcotCR can surpass state-of-the-art
methods in terms of the accuracy of detecting and describing code issues, with
its performance remarkably on par with that of the 671B DeepSeek-R1 model.

</details>


### [20] [Semantic Clustering of Civic Proposals: A Case Study on Brazil's National Participation Platform](https://arxiv.org/abs/2509.21292)
*Ronivaldo Ferreira,Guilherme da Silva,Carla Rocha,Gustavo Pinto*

Main category: cs.SE

TL;DR: 结合BERTopic和大语言模型的新方法，使政府能够自动、高效、低人力成本地整理和利用数字平台上大量的公民参与内容，有助于政策制定。


<details>
  <summary>Details</summary>
Motivation: 促进公民在数字平台上的参与已成为各国政府的优先事项。然而，由于贡献量过大，缺乏高效整理方法，导致大量公民意见难以被有效利用。主要挑战包括：人工分类不可行、需专家参与、且需与官方分类体系对齐。

Method: 本研究提出了一种结合BERTopic、种子词以及大语言模型自动验证的方法，用于自动分类和整理大量公民数字参与内容。

Result: 初步结果显示，该方法生成的主题具备连贯性，并且很好地与官方分类体系对齐，同时极大减少了人工参与。

Conclusion: 该方法能够帮助政府高效地将大量公民意见转化为可用于公共政策的数据，提升数字平台参与的实际政策价值。

Abstract: Promoting participation on digital platforms such as Brasil Participativo has
emerged as a top priority for governments worldwide. However, due to the sheer
volume of contributions, much of this engagement goes underutilized, as
organizing it presents significant challenges: (1) manual classification is
unfeasible at scale; (2) expert involvement is required; and (3) alignment with
official taxonomies is necessary. In this paper, we introduce an approach that
combines BERTopic with seed words and automatic validation by large language
models. Initial results indicate that the generated topics are coherent and
institutionally aligned, with minimal human effort. This methodology enables
governments to transform large volumes of citizen input into actionable data
for public policy.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [21] [A Unified Formal Theory on the Logical Limits of Symbol Grounding](https://arxiv.org/abs/2509.20409)
*Zhangchi Liu*

Main category: cs.LO

TL;DR: 该文通过形式化证明展示符号基础意义问题的理论极限，证明任何纯粹自包含的智能系统无法完全自洽地解决符号指涉，意义的获得必须依赖外部且非算法化的动态过程。


<details>
  <summary>Details</summary>
Motivation: 符号指涉问题是人工智能和认知科学中的核心难题，现有理论多无法形式化展示其逻辑极限，该文旨在系统性、形式化地揭示其原理性障碍。

Method: 采用一系列形式化证明，分四个阶段阐明：1）纯符号系统因自指悖论无法自洽建立意义；2）有限静态含义集无法补全系统；3）将符号与外部意义的连接只能是元层面的公理化更新，逻辑推导无法实现；4）即使采用固定外部算法“判断”也只是扩展系统规模，本质不变。

Result: 给出了一套严密的形式证明，阐明任何封闭的智能系统在符号基础意义上的内在不完备性，即符号的真正意义必须外源性和非算法性地获得。

Conclusion: 符号系统中的意义基础必须通过外部、动态且非算法性的过程获得，自包含系统无法完全自洽地实现符号指涉的意义基础，存在哥德尔式的根本极限。

Abstract: This paper synthesizes a series of formal proofs to construct a unified
theory on the logical limits of the Symbol Grounding Problem. We demonstrate
through a four-stage argument that meaning within a formal system must arise
from a process that is external, dynamic, and non-algorithmic. First, we prove
that any purely symbolic system, devoid of external connections, cannot
internally establish a consistent foundation for meaning due to
self-referential paradoxes. Second, we extend this limitation to systems with
any finite, static set of pre-established meanings, proving they are inherently
incomplete. Third, we demonstrate that the very "act" of connecting an internal
symbol to an external meaning cannot be a product of logical inference within
the system but must be an axiomatic, meta-level update. Finally, we prove that
any attempt to automate this update process using a fixed, external "judgment"
algorithm will inevitably construct a larger, yet equally incomplete, symbolic
system. Together, these conclusions formally establish that the grounding of
meaning is a necessarily open-ended, non-algorithmic process, revealing a
fundamental, G\"odel-style limitation for any self-contained intelligent
system.

</details>


### [22] [Reverse Faà di Bruno's Formula for Cartesian Reverse Differential Categories](https://arxiv.org/abs/2509.20931)
*Aaron Biggin,Jean-Simon Pacaud Lemay*

Main category: cs.LO

TL;DR: 本文在Cartesian反向微分范畴中首次提出并证明了高阶反向链式法则（Faa di Bruno公式的反向类比），并系统补充了相关的偏反向与高阶反向导数定义，对自动微分的理论与应用具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 反向微分在自动微分中至关重要，而现有范畴理论中反向微分链式法则的高阶推广尚不完备，因此需要发展高阶反向链式法则的范畴公理理论。

Method: 本文通过范畴论框架，正式定义了Cartesian反向微分范畴中的偏反向导数和高阶反向导数，并提出了Faa di Bruno公式的反向微分类比，用于描述高阶反向链式法则。

Result: 文中建立了具有普适性的高阶反向链式法则公式，并完善了Cartesian反向微分范畴中的相关概念。

Conclusion: 该研究丰富了自动微分的理论基础，为后续自动微分软件工具中的高阶反向微分算法提供了坚实的范畴论理论支撑。

Abstract: Reverse differentiation is an essential operation for automatic
differentiation. Cartesian reverse differential categories axiomatize reverse
differentiation in a categorical framework, where one of the primary axioms is
the reverse chain rule, which is the formula that expresses the reverse
derivative of a composition. Here, we present the reverse differential analogue
of Faa di Bruno's Formula, which gives a higher-order reverse chain rule in a
Cartesian reverse differential category. To properly do so, we also define
partial reverse derivatives and higher-order reverse derivatives in a Cartesian
reverse differential category.

</details>


### [23] [A Coalgebraic Model of Quantum Bisimulation](https://arxiv.org/abs/2509.20933)
*Lorenzo Ceragioli,Elena Di Lavore,Giuseppe Lomurno,Gabriele Tedeschi*

Main category: cs.LO

TL;DR: 该文提出了一种基于effect代数分布余代数和分级monad的量子系统行为等价理论，更好地符合量子物理理论，强调kernel双模拟的优势，并为量子过程演算提供了理论工具和语义表达能力。


<details>
  <summary>Details</summary>
Motivation: 量子系统天生具有并发性和不确定性，为这些系统定义一种符合观测性质的行为等价关系是一项极具挑战性的任务。现有的等价性定义难以全面刻画量子系统的概率行为，因此本文试图提出更为通用和精确的行为等价分析方法。

Method: 本文采用基于泛化effect代数的分布的余代数(coalgebra)方法，建立了统一描述概率和量子效应的理论框架。引入在部分交换幺半群上分级的monad，以适应量子理论中资源不可克隆的要求。同时，比较了Aczel-Mendler和kernel双模拟关系，强调后者在刻画所有输入状态下等概率行为系统中的优势。

Result: 本文表明kernel双模拟关系能够刻画所有输入状态下表现出相同行为的量子系统。提出的理论为量子effect标记转移系统提供了新算子，支持面向量子输入的过程演算语义。

Conclusion: 通过基于effect代数的分布余代数与分级monad，本文不仅统一了对概率和量子效应的建模，也为量子系统行为等价定义及其验证提供了新视角，并为量子过程演算语义奠定了基础。

Abstract: Recent works have shown that defining a behavioural equivalence that matches
the observational properties of a quantum-capable, concurrent,
non-deterministic system is a surprisingly difficult task. We explore
coalgebras over distributions taking weights from a generic effect algebra,
which subsumes probabilities and quantum effects, a physical formalism that
represents the probabilistic behaviour of an open quantum system. To abide by
the properties of quantum theory, we introduce monads graded on a partial
commutative monoid, intuitively allowing composition of two processes only if
they use different quantum resources, as prescribed by the no-cloning theorem.
We investigate the relation between an open quantum system and its
probabilistic counterparts obtained when instantiating the input with a
specific quantum state. We consider Aczel-Mendler and kernel bisimilarities,
advocating for the latter as it characterizes quantum systems that exhibit the
same probabilistic behaviour for all input states. Finally, we propose
operators on quantum effect labelled transition systems, paving the way for a
process calculi semantics that is parametric over the quantum input.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [24] [Interpreting Public Sentiment in Diplomacy Events: A Counterfactual Analysis Framework Using Large Language Models](https://arxiv.org/abs/2509.20367)
*Leyi Ouyang*

Main category: cs.CL

TL;DR: 本文提出基于大语言模型的外交事件舆情转向框架，自动改写事件叙述以提升公众情绪，成功率达70%，对外交传播具有实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 外交事件常引发公众广泛讨论，公众情绪对外交决策和国际形象有重要影响。但传统的舆情分析方法如问卷调查或人工文本分析效率低、难以前瞻。需要一种更高效、可操作性强，并能指导情绪转向的新方法。

Method: 提出了一个新颖的框架：先通过语言模型预测外交事件引发的公众情绪。构建了包含外交事件描述及相关讨论的数据集。结合传播理论和领域专家确定可修改的文本特征，在保持核心事实的前提下，利用大语言模型生成反事实文本（即对原始事件描述的系统性改写）。

Result: 该方法能将公众情绪从负面有效转向中性或正面，转化成功率达70%。

Conclusion: 此框架为外交人员、政策制定者和传播专家提供了一个基于数据分析的实用工具，可在外交活动或报道时优化叙述方式，促进更积极的公众情绪形成。

Abstract: Diplomatic events consistently prompt widespread public discussion and
debate. Public sentiment plays a critical role in diplomacy, as a good
sentiment provides vital support for policy implementation, helps resolve
international issues, and shapes a nation's international image. Traditional
methods for gauging public sentiment, such as large-scale surveys or manual
content analysis of media, are typically time-consuming, labor-intensive, and
lack the capacity for forward-looking analysis. We propose a novel framework
that identifies specific modifications for diplomatic event narratives to shift
public sentiment from negative to neutral or positive. First, we train a
language model to predict public reaction towards diplomatic events. To this
end, we construct a dataset comprising descriptions of diplomatic events and
their associated public discussions. Second, guided by communication theories
and in collaboration with domain experts, we predetermined several textual
features for modification, ensuring that any alterations changed the event's
narrative framing while preserving its core facts.We develop a counterfactual
generation algorithm that employs a large language model to systematically
produce modified versions of an original text. The results show that this
framework successfully shifted public sentiment to a more favorable state with
a 70\% success rate. This framework can therefore serve as a practical tool for
diplomats, policymakers, and communication specialists, offering data-driven
insights on how to frame diplomatic initiatives or report on events to foster a
more desirable public sentiment.

</details>


### [25] [Speaker Style-Aware Phoneme Anchoring for Improved Cross-Lingual Speech Emotion Recognition](https://arxiv.org/abs/2509.20373)
*Shreya G. Upadhyay,Carlos Busso,Chi-Chun Lee*

Main category: cs.CL

TL;DR: 作者针对跨语言语音情感识别的难题，提出基于说话人风格和音素锚定的框架，并通过实验验证其优越性，有助于提升情感在不同语言间的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 跨语言语音情感识别（SER）具有挑战性，因为不同语言在语音变异和说话人表达风格上存在差异。有效抓取跨语言、跨说话人情感表达需要能够对齐不同情感外显方式的框架。

Method: 作者提出一种说话人风格感知的音素锚定框架。该方法首先利用基于图的聚类方法构建情感特定的说话人社区，以捕捉共享的说话人特征。基于这些说话人群体，方法在说话人空间和音素空间中进行双重锚定，促进情感信息跨语言迁移。

Result: 在MSP-Podcast（英语）和BIIC-Podcast（台湾普通话）语料库上的实验表明，该方法在泛化能力上优于当前有竞争力的基线方法，并揭示了跨语言情感表达的共性。

Conclusion: 该框架有效提升了跨语言情感识别的效果，推动了跨文化情感计算的发展。

Abstract: Cross-lingual speech emotion recognition (SER) remains a challenging task due
to differences in phonetic variability and speaker-specific expressive styles
across languages. Effectively capturing emotion under such diverse conditions
requires a framework that can align the externalization of emotions across
different speakers and languages. To address this problem, we propose a
speaker-style aware phoneme anchoring framework that aligns emotional
expression at the phonetic and speaker levels. Our method builds
emotion-specific speaker communities via graph-based clustering to capture
shared speaker traits. Using these groups, we apply dual-space anchoring in
speaker and phonetic spaces to enable better emotion transfer across languages.
Evaluations on the MSP-Podcast (English) and BIIC-Podcast (Taiwanese Mandarin)
corpora demonstrate improved generalization over competitive baselines and
provide valuable insights into the commonalities in cross-lingual emotion
representation.

</details>


### [26] [CFD-LLMBench: A Benchmark Suite for Evaluating Large Language Models in Computational Fluid Dynamics](https://arxiv.org/abs/2509.20374)
*Nithin Somasekharan,Ling Yue,Yadi Cao,Weichao Li,Patrick Emami,Pochinapeddi Sai Bhargav,Anurag Acharya,Xingyu Xie,Shaowu Pan*

Main category: cs.CL

TL;DR: 本文提出了用于评估大型语言模型在计算流体力学（CFD）领域自动化能力的CFDLLMBench基准套件，涵盖CFD知识、数值推理与实际工作流三大核心能力，推动了LLM在科学计算中的发展与应用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在通用自然语言处理任务上表现优异，但其在复杂物理系统数值实验自动化中的应用潜力尚未被充分探索。计算流体力学（CFD）作为计算科学中的核心领域，是评估LLMs科学能力的绝佳试验场。

Method: 作者提出了CFDLLMBench，一个包含CFDQuery、CFDCodeBench和FoamBench三大组件的基准测试套件，从CFD专业知识、数值与物理推理、以及面向实际工作的工作流实现三方面全面评测LLMs。该基准测试依据实际CFD实践，设计细致的任务分类和严格的评估框架，量化LLM在代码可执行性、解的准确性和数值收敛性等方面的表现。

Result: CFDLLMBench提供了可复现的基准测试和详细的数据与代码，成为推动LLM在复杂物理系统数值实验自动化应用开发和评估的重要基础。该平台可用于定量评价不同LLM在CFD任务中的执行力和科学推理能力。

Conclusion: CFDLLMBench奠定了LLM用于复杂物理系统数值实验自动化的基础，为科学领域LLM能力的评测和发展提供了标准化平台和工具。

Abstract: Large Language Models (LLMs) have demonstrated strong performance across
general NLP tasks, but their utility in automating numerical experiments of
complex physical system -- a critical and labor-intensive component -- remains
underexplored. As the major workhorse of computational science over the past
decades, Computational Fluid Dynamics (CFD) offers a uniquely challenging
testbed for evaluating the scientific capabilities of LLMs. We introduce
CFDLLMBench, a benchmark suite comprising three complementary components --
CFDQuery, CFDCodeBench, and FoamBench -- designed to holistically evaluate LLM
performance across three key competencies: graduate-level CFD knowledge,
numerical and physical reasoning of CFD, and context-dependent implementation
of CFD workflows. Grounded in real-world CFD practices, our benchmark combines
a detailed task taxonomy with a rigorous evaluation framework to deliver
reproducible results and quantify LLM performance across code executability,
solution accuracy, and numerical convergence behavior. CFDLLMBench establishes
a solid foundation for the development and evaluation of LLM-driven automation
of numerical experiments for complex physical systems. Code and data are
available at https://github.com/NREL-Theseus/cfdllmbench/.

</details>


### [27] [Assessing Classical Machine Learning and Transformer-based Approaches for Detecting AI-Generated Research Text](https://arxiv.org/abs/2509.20375)
*Sharanya Parimanoharan,Ruwan D. Nawarathna*

Main category: cs.CL

TL;DR: 本研究比较了多种机器学习方法区分ChatGPT-3.5生成与人类撰写的研究摘要。DistilBERT表现最佳，集成多模型未超越单一Transformer。结果揭示了基于Transformer方法在AI文本检测中的优势，为未来相关研究提供方向。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）如ChatGPT的广泛应用，人工与AI生成文本的界限变得模糊，引发了关于学术诚信、知识产权和错误信息传播的担忧。因此，迫切需要可靠的AI文本检测方法，以保障人与内容的真实性，维护数字交流的信任。

Method: 使用涵盖广泛主题的250组研究摘要（ChatGPT-3.5生成与人类撰写），对比测试多种机器学习检测方法，包括经典方法（逻辑回归配合Bag-of-Words、词性、TF-IDF特征）和基于Transformer的方法（BERT结合N-gram、DistilBERT、定制BERT分类器、基于LSTM的N-gram模型），同时评估将最佳模型集成的性能表现。

Result: DistilBERT模型表现最佳，逻辑回归与定制BERT分类器也有均衡表现，LSTM和BERT-N-gram方法效果较差。集成前三优模型的投票法未能超越DistilBERT单一模型，在此任务中，Transformer模型表现优于模型多样化方案。

Conclusion: DistilBERT是当前检测AI生成文本的最优方案，集成策略并未带来性能提升。分析各检测方法强弱后，研究为未来基于更大、更丰富数据集的鲁棒Transformer框架奠定基础。

Abstract: The rapid adoption of large language models (LLMs) such as ChatGPT has
blurred the line between human and AI-generated texts, raising urgent questions
about academic integrity, intellectual property, and the spread of
misinformation. Thus, reliable AI-text detection is needed for fair assessment
to safeguard human authenticity and cultivate trust in digital communication.
In this study, we investigate how well current machine learning (ML) approaches
can distinguish ChatGPT-3.5-generated texts from human-written texts employing
a labeled data set of 250 pairs of abstracts from a wide range of research
topics. We test and compare both classical (Logistic Regression armed with
classical Bag-of-Words, POS, and TF-IDF features) and transformer-based (BERT
augmented with N-grams, DistilBERT, BERT with a lightweight custom classifier,
and LSTM-based N-gram models) ML detection techniques. As we aim to assess each
model's performance in detecting AI-generated research texts, we also aim to
test whether an ensemble of these models can outperform any single detector.
Results show DistilBERT achieves the overall best performance, while Logistic
Regression and BERT-Custom offer solid, balanced alternatives; LSTM- and
BERT-N-gram approaches lag. The max voting ensemble of the three best models
fails to surpass DistilBERT itself, highlighting the primacy of a single
transformer-based representation over mere model diversity. By comprehensively
assessing the strengths and weaknesses of these AI-text detection approaches,
this work lays a foundation for more robust transformer frameworks with larger,
richer datasets to keep pace with ever-improving generative AI models.

</details>


### [28] [ConceptViz: A Visual Analytics Approach for Exploring Concepts in Large Language Models](https://arxiv.org/abs/2509.20376)
*Haoxuan Li,Zhen Wen,Qiqi Jiang,Chenxiao Li,Yuwei Wu,Yuchen Yang,Yiyao Wang,Xiuqi Huang,Minfeng Zhu,Wei Chen*

Main category: cs.CL

TL;DR: 本文提出ConceptViz系统，实现SAE特征与人类概念的交互式对齐与可视化，有效提升了LLM特征的解释性和研究效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言处理任务上表现优异，但其内部知识表征仍难以理解。虽然稀疏自编码器（SAE）可以提取模型中的可解释特征，但这些特征难以与人类可理解的概念对齐，解释过程繁琐、费力。为此，需要一种能将SAE特征与人类概念关联的方法。

Method: 提出了ConceptViz，一个可视化分析系统，通过“识别-解释-验证”三步流程：用户可用感兴趣的概念查询SAE，交互式探索概念与特征的对应关系，并通过模型行为验证进行验证。系统还通过应用场景和用户研究展示其有效性。

Result: 实验和用户研究表明，ConceptViz提升了LLM特征解释性的研究效率，简化了有意义概念表征的发现与验证过程，帮助研究者更准确地理解LLM特征。

Conclusion: ConceptViz能够有效促进LLM中概念与SAE特征的对齐，提高特征可解释性，为研究者理解和分析大型语言模型内部机制提供了新工具。

Abstract: Large language models (LLMs) have achieved remarkable performance across a
wide range of natural language tasks. Understanding how LLMs internally
represent knowledge remains a significant challenge. Despite Sparse
Autoencoders (SAEs) have emerged as a promising technique for extracting
interpretable features from LLMs, SAE features do not inherently align with
human-understandable concepts, making their interpretation cumbersome and
labor-intensive. To bridge the gap between SAE features and human concepts, we
present ConceptViz, a visual analytics system designed for exploring concepts
in LLMs. ConceptViz implements a novel dentification => Interpretation =>
Validation pipeline, enabling users to query SAEs using concepts of interest,
interactively explore concept-to-feature alignments, and validate the
correspondences through model behavior verification. We demonstrate the
effectiveness of ConceptViz through two usage scenarios and a user study. Our
results show that ConceptViz enhances interpretability research by streamlining
the discovery and validation of meaningful concept representations in LLMs,
ultimately aiding researchers in building more accurate mental models of LLM
features. Our code and user guide are publicly available at
https://github.com/Happy-Hippo209/ConceptViz.

</details>


### [29] [SKILL-RAG: Self-Knowledge Induced Learning and Filtering for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.20377)
*Tomoaki Isoda*

Main category: cs.CL

TL;DR: 本文提出SKILL-RAG方法，利用模型自知来筛选检索内容，采用强化学习训练和句子级过滤，在提升生成质量的同时大幅减少无用输入，验证了自知机制在RAG系统中的价值。


<details>
  <summary>Details</summary>
Motivation: 当前RAG框架在处理知识密集型任务时，检索系统可能返回无关内容，进而导致大模型出现幻觉，如何有效过滤无用检索结果成为提升RAG表现的关键。

Method: 提出SKILL-RAG方法，通过引入模型自知(Self-Knowledge)机制，利用强化学习框架训练模型显式提取自知内容，并在句子级别过滤无关信息，仅保留有用知识。

Result: 在Llama2-7B和Qwen3-8B等模型及多项问答基准上实验，SKILL-RAG不仅提升了生成质量，还显著减少了输入文档数量，证实了模型自知在高质量检索内容选择中的重要性。

Conclusion: SKILL-RAG通过模型自知机制改善了RAG检索结果的筛选，显著提升了大模型在知识密集型任务上的问答质量与效率。

Abstract: Retrieval-Augmented Generation (RAG) has significantly improved the
performance of large language models (LLMs) on knowledge-intensive tasks in
recent years. However, since retrieval systems may return irrelevant content,
incorporating such information into the model often leads to hallucinations.
Thus, identifying and filtering out unhelpful retrieved content is a key
challenge for improving RAG performance.To better integrate the internal
knowledge of the model with external knowledge from retrieval, it is essential
to understand what the model "knows" and "does not know" (which is also called
"self-knowledge"). Based on this insight, we propose SKILL-RAG (Self-Knowledge
Induced Learning and Filtering for RAG), a novel method that leverages the
model's self-knowledge to determine which retrieved documents are beneficial
for answering a given query. We design a reinforcement learning-based training
framework to explicitly elicit self-knowledge from the model and employs
sentence-level granularity to filter out irrelevant content while preserving
useful knowledge.We evaluate SKILL-RAG using Llama2-7B and Qwen3-8B on several
question answering benchmarks. Experimental results demonstrate that SKILL-RAG
not only improves generation quality but also significantly reduces the number
of input documents, validating the importance of self-knowledge in guiding the
selection of high-quality retrievals.

</details>


### [30] [Beyond Global Emotion: Fine-Grained Emotional Speech Synthesis with Dynamic Word-Level Modulation](https://arxiv.org/abs/2509.20378)
*Sirui Wang,Andong Chen,Tiejun Zhao*

Main category: cs.CL

TL;DR: 本文提出Emo-FiLM，实现语音合成中的单词级情感控制，显著优于传统方法，提升表达性和自然性，并支持细粒度情感评测。


<details>
  <summary>Details</summary>
Motivation: 现有的情感文本到语音（E-TTS）系统多通过预设标签、参考音频或自然语言提示进行句子级别的情感控制，虽然能表达整体情感，但难以捕捉句内的动态情感变化。为解决这一不足，提出了新的方法。

Method: 提出Emo-FiLM，一种基于大语言模型（LLM）的细粒度情感建模框架。该方法将emotion2vec的帧级特征对齐到单词，实现单词级情感标注，并通过Feature-wise Linear Modulation（FiLM）层将这些标注映射到文本嵌入，实现对单词级别情感的直接调节。同时，构建了Fine-grained Emotion Dynamics Dataset（FEDD）以评估细粒度情感变化。

Result: 实验表明，Emo-FiLM在整体和细粒度任务上均优于现有方法，展现了其在表达性语音合成中的有效性和广泛适用性。

Conclusion: Emo-FiLM能够实现对语音合成中单词级别的情感精细控制，有效提升了人机交互中的表达自然性和可信度，并在多个任务上超越了现有技术。

Abstract: Emotional text-to-speech (E-TTS) is central to creating natural and
trustworthy human-computer interaction. Existing systems typically rely on
sentence-level control through predefined labels, reference audio, or natural
language prompts. While effective for global emotion expression, these
approaches fail to capture dynamic shifts within a sentence. To address this
limitation, we introduce Emo-FiLM, a fine-grained emotion modeling framework
for LLM-based TTS. Emo-FiLM aligns frame-level features from emotion2vec to
words to obtain word-level emotion annotations, and maps them through a
Feature-wise Linear Modulation (FiLM) layer, enabling word-level emotion
control by directly modulating text embeddings. To support evaluation, we
construct the Fine-grained Emotion Dynamics Dataset (FEDD) with detailed
annotations of emotional transitions. Experiments show that Emo-FiLM
outperforms existing approaches on both global and fine-grained tasks,
demonstrating its effectiveness and generality for expressive speech synthesis.

</details>


### [31] [USB-Rec: An Effective Framework for Improving Conversational Recommendation Capability of Large Language Model](https://arxiv.org/abs/2509.20381)
*Jianyu Wen,Jingyun Wang,Cilin Yan,Jiayin Cai,Xiaolong Jiang,Ying Zhang*

Main category: cs.CL

TL;DR: 本文提出了结合训练和推理的USB-Rec框架，通过强化学习和自增强策略提升LLM在对话推荐中的表现，并在实验中取得了优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的对话推荐系统主要依赖其总结和分析能力，忽视了模型训练问题，因此需要探索如何通过训练提升LLM在对话推荐任务的表现。

Method: 提出了一个集成训练-推理的USB-Rec框架，包括基于LLM的偏好优化数据集构建用于强化学习训练，以及在推理阶段的自增强策略，以充分挖掘LLM在对话推荐中的潜力。

Result: 在多个数据集上的大量实验表明，该方法在对话推荐任务中性能优于此前的最先进方法。

Conclusion: 通过USB-Rec框架有效提升了LLM在对话推荐系统中的效果，证明了训练过程和推理策略的结合对于任务性能的积极作用。

Abstract: Recently, Large Language Models (LLMs) have been widely employed in
Conversational Recommender Systems (CRSs). Unlike traditional language model
approaches that focus on training, all existing LLMs-based approaches are
mainly centered around how to leverage the summarization and analysis
capabilities of LLMs while ignoring the issue of training. Therefore, in this
work, we propose an integrated training-inference framework,
User-Simulator-Based framework (USB-Rec), for improving the performance of LLMs
in conversational recommendation at the model level. Firstly, we design a
LLM-based Preference Optimization (PO) dataset construction strategy for RL
training, which helps the LLMs understand the strategies and methods in
conversational recommendation. Secondly, we propose a Self-Enhancement Strategy
(SES) at the inference stage to further exploit the conversational
recommendation potential obtained from RL training. Extensive experiments on
various datasets demonstrate that our method consistently outperforms previous
state-of-the-art methods.

</details>


### [32] [Document Summarization with Conformal Importance Guarantees](https://arxiv.org/abs/2509.20461)
*Bruce Kuwahara,Chen-Yuan Lin,Xiao Shi Huang,Kin Kwan Leung,Jullian Arta Yapeter,Ilya Stanevich,Felipe Perez,Jesse C. Cresswell*

Main category: cs.CL

TL;DR: 本文提出了Conformal Importance Summarization方法，为摘要系统提供关键内容覆盖的分布无关理论保证，实验验证其有效性，有助于AI摘要在高风险领域的可靠应用。


<details>
  <summary>Details</summary>
Motivation: 目前的大型语言模型自动摘要系统在医疗、法律和金融等高风险领域，仍无法保证所有关键信息的完整覆盖，存在遗漏重要内容的风险。因此，需要开发能对关键信息覆盖率提供明确保证的摘要方法。

Method: 提出了基于保形预测（conformal prediction）的Conformal Importance Summarization方法。该方法通过对句子级重要性分数设置阈值，实现可控的关键内容覆盖率和召回率，实现了模型无关、仅需少量校准数据，并可无缝集成现有LLM的可提取式文档摘要生成。

Result: 在主流摘要数据集上的实验显示，该方法能够达到理论保证的信息覆盖率。

Conclusion: Conformal Importance Summarization为高风险领域自动摘要带来了可靠、可控的信息覆盖保证，为AI摘要工具在医疗、法律等关键应用的安全部署奠定了基础，同时可和现有方法结合，进一步提升性能。

Abstract: Automatic summarization systems have advanced rapidly with large language
models (LLMs), yet they still lack reliable guarantees on inclusion of critical
content in high-stakes domains like healthcare, law, and finance. In this work,
we introduce Conformal Importance Summarization, the first framework for
importance-preserving summary generation which uses conformal prediction to
provide rigorous, distribution-free coverage guarantees. By calibrating
thresholds on sentence-level importance scores, we enable extractive document
summarization with user-specified coverage and recall rates over critical
content. Our method is model-agnostic, requires only a small calibration set,
and seamlessly integrates with existing black-box LLMs. Experiments on
established summarization benchmarks demonstrate that Conformal Importance
Summarization achieves the theoretically assured information coverage rate. Our
work suggests that Conformal Importance Summarization can be combined with
existing techniques to achieve reliable, controllable automatic summarization,
paving the way for safer deployment of AI summarization tools in critical
applications. Code is available at
https://github.com/layer6ai-labs/conformal-importance-summarization.

</details>


### [33] [ShortCheck: Checkworthiness Detection of Multilingual Short-Form Videos](https://arxiv.org/abs/2509.20467)
*Henrik Vatndal,Vinay Setty*

Main category: cs.CL

TL;DR: 针对短视频虚假信息检测难题，论文提出了集成多项技术的自动化短视频查核工具ShortCheck，并在多语言真实数据集上实现优异表现，显著提升了事实查核效率。


<details>
  <summary>Details</summary>
Motivation: 短视频平台如TikTok因其多模态、动态性和内容噪声，给虚假信息检测带来挑战。亟需辅助工具帮助人工事实查核。

Method: 提出了ShortCheck，一个模块化、仅推理、带有用户友好界面的自动识别可查核短视频管道。集成语音转录、光学字符识别（OCR）、物体与深度伪造检测、视频到文本摘要和主张验证等技术，用于辅助事实查核员。

Result: 该系统在两个带有多语言TikTok视频的人工标注数据集上进行验证，取得F1加权分数超过70%。

Conclusion: ShortCheck能自动帮助识别需要查核的短视频，为事实查核人员提供有力支持，在多语言环境下取得了良好效果。

Abstract: Short-form video platforms like TikTok present unique challenges for
misinformation detection due to their multimodal, dynamic, and noisy content.
We present ShortCheck, a modular, inference-only pipeline with a user-friendly
interface that automatically identifies checkworthy short-form videos to help
human fact-checkers. The system integrates speech transcription, OCR, object
and deepfake detection, video-to-text summarization, and claim verification.
ShortCheck is validated by evaluating it on two manually annotated datasets
with TikTok videos in a multilingual setting. The pipeline achieves promising
results with F1-weighted score over 70\%.

</details>


### [34] [MARS: toward more efficient multi-agent collaboration for LLM reasoning](https://arxiv.org/abs/2509.20502)
*Xiao Wang,Jia Wang,Yijie Wang,Pengtao Dang,Sha Cao,Chi Zhang*

Main category: cs.CL

TL;DR: 本文提出了MARS系统，通过角色划分优化多代理推理，大幅减少计算开销且准确率不逊于传统MAD方案。


<details>
  <summary>Details</summary>
Motivation: 单个大语言模型（LLM）在自然语言理解上表现优秀，但其推理能力有限。多代理辩论（MAD）虽能提升推理能力，但带来大量计算开销。本文致力于在提升推理能力的同时降低计算成本。

Method: 提出了一种新的多代理协作框架MARS（Multi-Agent Review System）。MARS借鉴学术评审流程，分为作者、评审员和元评审员三个角色：作者代理生成初始答案，评审员独立给出意见，元评审员整合反馈做最终决策，避免了评审员之间频繁交互。

Result: 在多个基准测试中，与MAD及其他推理策略比较，MARS在保持与MAD相当的准确率的同时，减少了约50%的token消耗和推理时间。

Conclusion: MARS有效提升了多代理协同推理的效率，在保证准确性的前提下大大降低计算资源消耗。

Abstract: Large language models (LLMs) have achieved impressive results in natural
language understanding, yet their reasoning capabilities remain limited when
operating as single agents. Multi-Agent Debate (MAD) has been proposed to
address this limitation by enabling collaborative reasoning among multiple
models in a round-table debate manner. While effective, MAD introduces
substantial computational overhead due to the number of agents involved and the
frequent communication required. In this paper, we propose MARS (Multi-Agent
Review System), a role-based collaboration framework inspired by the review
process. In MARS, an author agent generates an initial solution, reviewer
agents provide decisions and comments independently, and a meta-reviewer
integrates the feedback to make the final decision and guide further revision.
This design enhances reasoning quality while avoiding costly
reviewer-to-reviewer interactions, thereby controlling token consumption and
inference time. We compared MARS with both MAD and other state-of-the-art
reasoning strategies across multiple benchmarks. Extensive experiments with
different LLMs show that MARS matches the accuracy of MAD while reducing both
token usage and inference time by approximately 50\%. Code is available at
https://github.com/xwang97/MARS.

</details>


### [35] [SiniticMTError: A Machine Translation Dataset with Error Annotations for Sinitic Languages](https://arxiv.org/abs/2509.20557)
*Hannah Liu,Junghyun Min,Ethan Yue Heng Cheung,Shou-Yi Hung,Syed Mekael Wasti,Runtong Liang,Shiyao Qian,Shizhao Zheng,Elsie Chan,Ka Ieng Charlotte Lo,Wing Yu Yip,Richard Tzong-Han Tsai,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 本文提出了SiniticMTError数据集，涵盖英语到普通话、粤语和吴语的机器翻译错误标注，为低资源语言MT研究和模型优化提供重要支持。


<details>
  <summary>Details</summary>
Motivation: 尽管近年来机器翻译取得了重大进展，但许多低资源语言由于缺乏大规模训练数据和语言资源，进展仍然有限。粤语和吴语虽然有超过八千万使用者，但相关机器翻译资源极少。

Method: 提出了一个新颖的数据集SiniticMTError，基于现有平行语料，对从英语到普通话、粤语和吴语的机器翻译结果进行错误范围、错误类型和错误严重程度的人工标注。标注过程由母语者严谨完成，并分析了标注者之间的一致性、反馈迭代以及错误类型和严重程度的模式。

Result: 构建了可用于模型微调、翻译质量评估、错误检测等研究的新数据资源，并通过分析证明标注过程的可靠性以及错误类型和严重程度的分布。

Conclusion: SiniticMTError为机器翻译社区提供了针对低资源汉语方言的高质量错误标注数据，有助于提升相关机器翻译系统的性能和研究深度。

Abstract: Despite major advances in machine translation (MT) in recent years, progress
remains limited for many low-resource languages that lack large-scale training
data and linguistic resources. Cantonese and Wu Chinese are two Sinitic
examples, although each enjoys more than 80 million speakers around the world.
In this paper, we introduce SiniticMTError, a novel dataset that builds on
existing parallel corpora to provide error span, error type, and error severity
annotations in machine-translated examples from English to Mandarin, Cantonese,
and Wu Chinese. Our dataset serves as a resource for the MT community to
utilize in fine-tuning models with error detection capabilities, supporting
research on translation quality estimation, error-aware generation, and
low-resource language evaluation. We report our rigorous annotation process by
native speakers, with analyses on inter-annotator agreement, iterative
feedback, and patterns in error type and severity.

</details>


### [36] [SwasthLLM: a Unified Cross-Lingual, Multi-Task, and Meta-Learning Zero-Shot Framework for Medical Diagnosis Using Contrastive Representations](https://arxiv.org/abs/2509.20567)
*Ayan Sar,Pranav Singh Puri,Sumit Aich,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: 该论文提出了多语种医疗诊断模型SwasthLLM，在无须专门微调的情况下，实现了跨英语、印地语和孟加拉语的高效疾病自动诊断，尤其在低资源语言环境下表现优异。


<details>
  <summary>Details</summary>
Motivation: 在多语种医疗环境下，由于低资源语言标注的医疗数据稀缺，以及跨人群语言差异，自动疾病诊断一直是一个挑战。

Method: 提出了SwasthLLM，一个统一的零样本、跨语言、多任务学习框架。该框架基于多语种XLM-RoBERTa编码器，结合语言感知注意力机制和疾病分类头，使用Siamese对比学习模块对齐跨语言语义表示，并有翻译一致性模块与对比投影头强化语言无关表征。训练过程中采用多任务学习并集成MAML元学习，以实现对新语言和任务的快速适应。分阶段训练流程注重表征对齐后再进行任务微调。

Result: 在监督条件下测试准确率达97.22%，F1分数97.17%。在零样本场景下，Hindi文本准确率92.78%，Bengali文本准确率73.33%，展现了在低资源环境下的优秀泛化能力。

Conclusion: SwasthLLM在多语种医学诊断领域实现了无需语言特定微调即可高效诊断，特别是在低资源语言下表现突出。其多任务联合优化和元学习能力支持了对新语言及任务的快速适应，在实际医疗应用中有良好推广价值。

Abstract: In multilingual healthcare environments, automatic disease diagnosis from
clinical text remains a challenging task due to the scarcity of annotated
medical data in low-resource languages and the linguistic variability across
populations. This paper proposes SwasthLLM, a unified, zero-shot,
cross-lingual, and multi-task learning framework for medical diagnosis that
operates effectively across English, Hindi, and Bengali without requiring
language-specific fine-tuning. At its core, SwasthLLM leverages the
multilingual XLM-RoBERTa encoder augmented with a language-aware attention
mechanism and a disease classification head, enabling the model to extract
medically relevant information regardless of the language structure. To align
semantic representations across languages, a Siamese contrastive learning
module is introduced, ensuring that equivalent medical texts in different
languages produce similar embeddings. Further, a translation consistency module
and a contrastive projection head reinforce language-invariant representation
learning. SwasthLLM is trained using a multi-task learning strategy, jointly
optimizing disease classification, translation alignment, and contrastive
learning objectives. Additionally, we employ Model-Agnostic Meta-Learning
(MAML) to equip the model with rapid adaptation capabilities for unseen
languages or tasks with minimal data. Our phased training pipeline emphasizes
robust representation alignment before task-specific fine-tuning. Extensive
evaluation shows that SwasthLLM achieves high diagnostic performance, with a
test accuracy of 97.22% and an F1-score of 97.17% in supervised settings.
Crucially, in zero-shot scenarios, it attains 92.78% accuracy on Hindi and
73.33% accuracy on Bengali medical text, demonstrating strong generalization in
low-resource contexts.

</details>


### [37] [Dynamic Reasoning Chains through Depth-Specialized Mixture-of-Experts in Transformer Architectures](https://arxiv.org/abs/2509.20577)
*Sampurna Roy,Ayan Sar,Anurag Kaushish,Kanav Gupta,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: 本文提出DS-MoE模块化框架，通过深度专注专家，动态组装推理链，有效提升大模型推理效率和质量，同时增强可解释性。实验显示显著节约计算资源、提升推理速度和准确率，对大语言模型结构创新具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 当前的transformer架构对所有输入都采用相同的处理深度，导致简单问题与复杂问题计算资源浪费，并限制了模型的深度推理能力。

Method: 提出了一种DS-MoE（Depth Specialised Mixture of Experts，深度专注型专家混合）模块化框架，将专家混合范式从传统的宽度扩展到深度，针对不同推理复杂度（如模式识别、逻辑推理、记忆整合等）设置对应专家模块，通过可学习的路由网络，根据输入复杂度动态选择并激活必要的专家，动态组装推理链。

Result: 在包含科学论文、法律文本、代码和网页内容的多领域数据集The Pile上训练和评估，DS-MoE相比于传统transformer，在推理效率上提升显著：节省多达16%的计算资源，推理速度提升35%；并在复杂多步推理基准上，准确率提高2.8%。路由决策可解释性也增强，推理链条透明，有利于扩展。

Conclusion: DS-MoE实现了深度专注的模块化推理，不仅显著提高了效率、推理质量和可解释性，也为大规模语言模型的自适应结构提供了新方向。

Abstract: Contemporary transformer architectures apply identical processing depth to
all inputs, creating inefficiencies and limiting reasoning quality. Simple
factual queries are subjected to the same multilayered computation as complex
logical problems, wasting resources while constraining deep inference. To
overcome this, we came up with a concept of Dynamic Reasoning Chains through
Depth Specialised Mixture of Experts (DS-MoE), a modular framework that extends
the Mixture of Experts paradigm from width-based to depth specialised
computation. DS-MoE introduces expert modules optimised for distinct reasoning
depths, shallow pattern recognition, compositional reasoning, logical
inference, memory integration, and meta-cognitive supervision. A learned
routing network dynamically assembles custom reasoning chains, activating only
the necessary experts to match input complexity. The dataset on which we
trained and evaluated DS-MoE is on The Pile, an 800GB corpus covering diverse
domains such as scientific papers, legal texts, programming code, and web
content, enabling systematic assessment across reasoning depths. Experimental
results demonstrate that DS-MoE achieves up to 16 per cent computational
savings and 35 per cent faster inference compared to uniform-depth
transformers, while delivering 2.8 per cent higher accuracy on complex
multi-step reasoning benchmarks. Furthermore, routing decisions yield
interpretable reasoning chains, enhancing transparency and scalability. These
findings establish DS-MoE as a significant advancement in adaptive neural
architectures, demonstrating that depth-specialised modular processing can
simultaneously improve efficiency, reasoning quality, and interpretability in
large-scale language models.

</details>


### [38] [Hierarchical Resolution Transformers: A Wavelet-Inspired Architecture for Multi-Scale Language Understanding](https://arxiv.org/abs/2509.20581)
*Ayan Sar,Sampurna Roy,Kanav Gupta,Anurag Kaushish,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: HRT是一种新颖的多层次语言处理模型，比传统Transformer在准确率和计算效率上都有显著提升，实现了更接近人类语言组织的处理方式。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer架构在自然语言任务中性能优异，但它们将文本视为扁平的序列处理，忽略了语言的层次结构，导致计算成本高、泛化能力弱、对话建模能力不足。

Method: 提出了一种新的Hierarchical Resolution Transformer (HRT)架构，受小波思想启发，通过多层次分辨率（从字符到语篇单元）同时处理语言。HRT利用多分辨率注意力机制，支持自下而上的组合和自上而下的上下文交互，并通过跨尺度的指数级序列缩减，将复杂度降低到O(nlogn)。

Result: 在GLUE、SuperGLUE、Long Range Arena 和 WikiText-103等数据集上，HRT平均比标准Transformer基线分别提升了3.8%、4.5%、6.1%。同时，与参数量相近的BERT/GPT模型相比，内存消耗降低42%，推理延迟减少37%。消融实验表明跨分辨率注意力和尺度特化模块都独立提升了效率和效果。

Conclusion: HRT首次将计算结构和语言层次组织相结合，多尺度、小波式处理带来理论效率和实际性能双重提升。

Abstract: Transformer architectures have achieved state-of-the-art performance across
natural language tasks, yet they fundamentally misrepresent the hierarchical
nature of human language by processing text as flat token sequences. This
results in quadratic computational cost, weak computational cost, weak
compositional generalization, and inadequate discourse-level modeling. We
propose Hierarchical Resolution Transformer (HRT), a novel wavelet-inspired
neural architecture that processes language simultaneously across multiple
resolutions, from characters to discourse-level units. HRT constructs a
multi-resolution attention, enabling bottom-up composition and top-down
contextualization. By employing exponential sequence reduction across scales,
HRT achieves O(nlogn) complexity, offering significant efficiency improvements
over standard transformers. We evaluated HRT on a diverse suite of benchmarks,
including GLUE, SuperGLUE, Long Range Arena, and WikiText-103, and results
demonstrated that HRT outperforms standard transformer baselines by an average
of +3.8% on GLUE, +4.5% on SuperGLUE, and +6.1% on Long Range Arena, while
reducing memory usage by 42% and inference latency by 37% compared to BERT and
GPT style models of similar parameter count. Ablation studies confirm the
effectiveness of cross-resolution attention and scale-specialized modules,
showing that each contributes independently to both efficiency and accuracy.
Our findings establish HRT as the first architecture to align computational
structure with the hierarchical organization of human language, demonstrating
that multi-scale, wavelet-inspired processing yields both theoretical
efficiency gains and practical improvements in language understanding.

</details>


### [39] [FS-DFM: Fast and Accurate Long Text Generation with Few-Step Diffusion Language Models](https://arxiv.org/abs/2509.20624)
*Amin Karimi Monsefi,Nikhil Bhendawade,Manuel Rafael Ciosici,Dominic Culver,Yizhe Zhang,Irina Belousova*

Main category: cs.CL

TL;DR: FS-DFM通过将采样步数显式化与多项技术创新，实现了极少步数下的高质量、高速文本生成，显著提升语言模型吞吐量与效率。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型在生成能力上表现优异，但由于每次只能生成一个token，导致序列较长时吞吐量低、延迟高。扩散语言模型虽然可以并行，但高质量生成通常需要大量迭代步数，效率低下。因此，论文旨在解决语言生成模型的效率与质量平衡问题。

Method: 提出了一种Few-Step Discrete Flow-Matching (FS-DFM)模型，将采样步数作为明确参数，通过训练模型在不同步数预算下保持一致性，实现少步采样仍能获得高质量输出。配合可靠的概率更新规则与教师指导，使少步采样过程稳定、准确且易控。

Result: FS-DFM模型在语言生成基准测试中，使用8步采样即可达到和传统1,024步离散流基线模型相当的困惑度（perplexity），实现采样速度提升至最多128倍，同时大幅优化延迟和吞吐量。

Conclusion: FS-DFM有效地解决了传统语言生成模型在生成效率与质量之间的权衡，实现了极少采样步数下的高效高质量文本生成。

Abstract: Autoregressive language models (ARMs) deliver strong likelihoods, but are
inherently serial: they generate one token per forward pass, which limits
throughput and inflates latency for long sequences. Diffusion Language Models
(DLMs) parallelize across positions and thus appear promising for language
generation, yet standard discrete diffusion typically needs hundreds to
thousands of model evaluations to reach high quality, trading serial depth for
iterative breadth. We introduce FS-DFM, Few-Step Discrete Flow-Matching. A
discrete flow-matching model designed for speed without sacrificing quality.
The core idea is simple: make the number of sampling steps an explicit
parameter and train the model to be consistent across step budgets, so one big
move lands where many small moves would. We pair this with a reliable update
rule that moves probability in the right direction without overshooting, and
with strong teacher guidance distilled from long-run trajectories. Together,
these choices make few-step sampling stable, accurate, and easy to control. On
language modeling benchmarks, FS-DFM with 8 sampling steps achieves perplexity
parity with a 1,024-step discrete-flow baseline for generating 1,024 tokens
using a similar-size model, delivering up to 128 times faster sampling and
corresponding latency/throughput gains.

</details>


### [40] [Look Before you Leap: Estimating LLM Benchmark Scores from Descriptions](https://arxiv.org/abs/2509.20645)
*Jungsoo Park,Ethan Mendes,Gabriel Stanovsky,Alan Ritter*

Main category: cs.CL

TL;DR: 本文提出用纯文本信息（而非具体数据）预测模型性能，并建立了PRECOG新基准，首次验证了该任务可行性，也揭示了强模型与弱模型间的行为差异。成果为实验优先级排序和难度预估打开新思路。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的发展受限于评测瓶颈：需要人工构建基准、评测和多次迭代。作者提出，能否在不做实验前预测模型结果，实现评估自动化？

Method: 提出text-only performance forecasting任务，即根据经过遮蔽处理的任务描述与模型设定，完全不访问具体数据，预测模型的得分。为此，作者建立了PRECOG语料库，含多样的任务、领域和指标的redacted description-performance对。同时实验对比了带检索模块与不开源模型的表现。

Result: 带检索模块的模型在排除来源论文后，依然能获得较好的预测表现，如在Accuracy子集上的平均绝对误差低至8.7。分析发现较强的推理模型具备多样化和迭代的检索能力，而现有开源模型表现较弱。作者还在“零泄露”设置下（即预测新发布数据集或者未被索引的实验）测试，GPT-5携带web搜索功能也有一定准确性。

Conclusion: 构建了PRECOG数据集，并证明了在不访问原始数据条件下，对实验性能进行预测是可行且有价值的，为后续自动化评估和实验管理提供了基础。

Abstract: Progress in large language models is constrained by an evaluation bottleneck:
build a benchmark, evaluate models and settings, then iterate. We therefore ask
a simple question: can we forecast outcomes before running any experiments? We
study text-only performance forecasting: estimating a model's score from a
redacted task description and intended configuration, with no access to dataset
instances. To support systematic study, we curate PRECOG, a corpus of redacted
description-performance pairs spanning diverse tasks, domains, and metrics.
Experiments show the task is challenging but feasible: models equipped with a
retrieval module that excludes source papers achieve moderate prediction
performance with well-calibrated uncertainty, reaching mean absolute error as
low as 8.7 on the Accuracy subset at high-confidence thresholds. Our analysis
indicates that stronger reasoning models engage in diverse, iterative querying,
whereas current open-source models lag and often skip retrieval or gather
evidence with limited diversity. We further test a zero-leakage setting,
forecasting on newly released datasets or experiments before their papers are
indexed, where GPT-5 with built-in web search still attains nontrivial
prediction accuracy. Overall, our corpus and analyses offer an initial step
toward open-ended anticipatory evaluation, supporting difficulty estimation and
smarter experiment prioritization.

</details>


### [41] [Building Tailored Speech Recognizers for Japanese Speaking Assessment](https://arxiv.org/abs/2509.20655)
*Yotaro Kubo,Richard Sproat,Chihiro Taguchi,Llion Jones*

Main category: cs.CL

TL;DR: 针对日语发音评估任务，作者提出了结合多任务训练和结果融合的语音识别方法，显著提升了包含重音标注的音素识别准确率。


<details>
  <summary>Details</summary>
Motivation: 日语虽为资源丰富语言，但包含重音标注的高质量音素转录训练数据极为稀缺，需要提升相关识别器效果。

Method: 利用多任务训练（结合正字法和音高辅助任务）及基于有限状态转导器的估算融合算法。

Result: 新方法将CSJ核心评测集的音节标签错误率从12.3%降至7.1%。

Conclusion: 提出的多任务训练和融合方法有效提升了日语语音识别在发音及重音标注方面的精度，优于通用多语种识别器。

Abstract: This paper presents methods for building speech recognizers tailored for
Japanese speaking assessment tasks. Specifically, we build a speech recognizer
that outputs phonemic labels with accent markers. Although Japanese is
resource-rich, there is only a small amount of data for training models to
produce accurate phonemic transcriptions that include accent marks. We propose
two methods to mitigate data sparsity. First, a multitask training scheme
introduces auxiliary loss functions to estimate orthographic text labels and
pitch patterns of the input signal, so that utterances with only orthographic
annotations can be leveraged in training. The second fuses two estimators, one
over phonetic alphabet strings, and the other over text token sequences. To
combine these estimates we develop an algorithm based on the finite-state
transducer framework. Our results indicate that the use of multitask learning
and fusion is effective for building an accurate phonemic recognizer. We show
that this approach is advantageous compared to the use of generic multilingual
recognizers. The relative advantages of the proposed methods were also
compared. Our proposed methods reduced the average of mora-label error rates
from 12.3% to 7.1% over the CSJ core evaluation sets.

</details>


### [42] [Enhancing Molecular Property Prediction with Knowledge from Large Language Models](https://arxiv.org/abs/2509.20664)
*Peng Zhou,Lai Hou Tim,Zhixiang Cheng,Kun Xie,Chaoyi Li,Wei Liu,Xiangxiang Zeng*

Main category: cs.CL

TL;DR: 本文首次提出将大语言模型自动生成的领域知识与分子结构特征深度融合，用于分子属性预测。实验表明，该方法在精度和鲁棒性上均优于传统与单一模型。


<details>
  <summary>Details</summary>
Motivation: 分子属性预测对新药研发至关重要。现有的深度学习方法（如GNN）虽能自动从分子结构中学习，但仍需依赖人工特征或外部知识，而LLM虽然可提取人类知识，却受限于对某些分子属性的知识空白与幻觉。本文动机是在分子属性预测中深度融合结构信息与语言模型人类知识，进一步提升预测表现。

Method: 提出一种创新框架，将从LLM（如GPT-4o、GPT-4.1、DeepSeek-R1）自动提取的领域知识和可执行代码生成的分子向量特征，与分子模型自带的结构特征进行融合。通过prompt引导LLMs生成有用知识和代码后，将知识特征与结构特征合并，进行分子属性预测。

Result: 通过大量实验验证，该融合方法优于现有基准方法，融合LLM知识与分子结构显著提升了分子属性预测的鲁棒性和精度。

Conclusion: 融合大语言模型知识与分子结构特征，是提升分子属性预测的有效路径。创新型知识-结构整合模型在多个指标上刷新性能。

Abstract: Predicting molecular properties is a critical component of drug discovery.
Recent advances in deep learning, particularly Graph Neural Networks (GNNs),
have enabled end-to-end learning from molecular structures, reducing reliance
on manual feature engineering. However, while GNNs and self-supervised learning
approaches have advanced molecular property prediction (MPP), the integration
of human prior knowledge remains indispensable, as evidenced by recent methods
that leverage large language models (LLMs) for knowledge extraction. Despite
their strengths, LLMs are constrained by knowledge gaps and hallucinations,
particularly for less-studied molecular properties. In this work, we propose a
novel framework that, for the first time, integrates knowledge extracted from
LLMs with structural features derived from pre-trained molecular models to
enhance MPP. Our approach prompts LLMs to generate both domain-relevant
knowledge and executable code for molecular vectorization, producing
knowledge-based features that are subsequently fused with structural
representations. We employ three state-of-the-art LLMs, GPT-4o, GPT-4.1, and
DeepSeek-R1, for knowledge extraction. Extensive experiments demonstrate that
our integrated method outperforms existing approaches, confirming that the
combination of LLM-derived knowledge and structural information provides a
robust and effective solution for MPP.

</details>


### [43] [RedHerring Attack: Testing the Reliability of Attack Detection](https://arxiv.org/abs/2509.20691)
*Jonathan Rusert*

Main category: cs.CL

TL;DR: 本文提出并验证了RedHerring攻击，对文本攻击检测模型造成显著误导但无损分类器性能，并通过置信度检测初步缓解攻击影响，为攻击检测系统安全性提供新视角。


<details>
  <summary>Details</summary>
Motivation: 现有文本攻击检测模型虽能识别文本攻击，但对其可靠性研究有限。通过引入使检测模型失效的新型攻击，可以揭示此类系统的潜在威胁和改进空间。

Method: 作者提出并测试了一种新颖的攻击方式RedHerring，使检测模型产生错误判断，但分类器仍给出正确结果。此外，提出置信度检测作为防御措施，并在4个数据集、4个分类器和3个检测器上进行实验。

Result: RedHerring攻击能使检测准确率下降20-71个百分点，而分类器准确率保持甚至提升。简单置信度检测机制在无需重新训练的情况下可显著提升检测效果。

Conclusion: RedHerring攻击方法能显著降低现有文本攻击检测模型的检测准确率，同时不影响甚至提升分类模型的准确率。同时，作者提出了一种简单的置信度检测机制作为初步防御，有效提升了检测准确率。

Abstract: In response to adversarial text attacks, attack detection models have been
proposed and shown to successfully identify text modified by adversaries.
Attack detection models can be leveraged to provide an additional check for NLP
models and give signals for human input. However, the reliability of these
models has not yet been thoroughly explored. Thus, we propose and test a novel
attack setting and attack, RedHerring. RedHerring aims to make attack detection
models unreliable by modifying a text to cause the detection model to predict
an attack, while keeping the classifier correct. This creates a tension between
the classifier and detector. If a human sees that the detector is giving an
``incorrect'' prediction, but the classifier a correct one, then the human will
see the detector as unreliable. We test this novel threat model on 4 datasets
against 3 detectors defending 4 classifiers. We find that RedHerring is able to
drop detection accuracy between 20 - 71 points, while maintaining (or
improving) classifier accuracy. As an initial defense, we propose a simple
confidence check which requires no retraining of the classifier or detector and
increases detection accuracy greatly. This novel threat model offers new
insights into how adversaries may target detection models.

</details>


### [44] [Overcoming Black-box Attack Inefficiency with Hybrid and Dynamic Select Algorithms](https://arxiv.org/abs/2509.20699)
*Abhinay Shankar Belde,Rohit Ramkumar,Jonathan Rusert*

Main category: cs.CL

TL;DR: 针对黑盒文本对抗攻击中所需大量查询的问题，提出Hybrid和Dynamic Select两种新策略，显著降低查询成本而不影响攻击效果，对资源有限的研究者更为友好。


<details>
  <summary>Details</summary>
Motivation: 当前变换器架构复杂度提升，导致NLP模型对抗攻击消耗大量计算资源，尤其对于资源有限的研究者（如GPU不足）尤为不便。现有黑盒攻击方法查询次数多，效率低，实际应用受限。

Method: 提出了两种新的攻击选择策略：Hybrid Select和Dynamic Select。Hybrid Select通过引入大小阈值将广义BinarySelect与GreedySelect结合；Dynamic Select则通过学习文本长度，动态决定使用Binary或Greedy方法，从而提升查询效率同时保持攻击有效性。

Result: 在4个数据集和6个目标模型上，最佳方法（句子级Hybrid Select）平均可将每次攻击的查询次数减少25.82%，并且不会降低攻击的有效性。

Conclusion: 提出的新选择策略显著降低了对抗攻击的查询次数，提升了测试效率，同时保持了攻击有效性，对于资源有限的研究者极具实用价值。

Abstract: Adversarial text attack research plays a crucial role in evaluating the
robustness of NLP models. However, the increasing complexity of
transformer-based architectures has dramatically raised the computational cost
of attack testing, especially for researchers with limited resources (e.g.,
GPUs). Existing popular black-box attack methods often require a large number
of queries, which can make them inefficient and impractical for researchers. To
address these challenges, we propose two new attack selection strategies called
Hybrid and Dynamic Select, which better combine the strengths of previous
selection algorithms. Hybrid Select merges generalized BinarySelect techniques
with GreedySelect by introducing a size threshold to decide which selection
algorithm to use. Dynamic Select provides an alternative approach of combining
the generalized Binary and GreedySelect by learning which lengths of texts each
selection method should be applied to. This greatly reduces the number of
queries needed while maintaining attack effectiveness (a limitation of
BinarySelect). Across 4 datasets and 6 target models, our best
method(sentence-level Hybrid Select) is able to reduce the number of required
queries per attack up 25.82\% on average against both encoder models and LLMs,
without losing the effectiveness of the attack.

</details>


### [45] [MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model](https://arxiv.org/abs/2509.20706)
*Hsiao-Ying Huang,Yi-Cheng Lin,Hung-yi Lee*

Main category: cs.CL

TL;DR: 提出基于互信息融合的方法，结合源域分类器和API型LALM，在跨域语音情感识别任务中显著提升学生模型表现，无需访问源数据，适合真实部署。


<details>
  <summary>Details</summary>
Motivation: 大规模音频-语言模型（LALMs）虽然在语音任务上具有强大的零样本能力，但在真实世界中的情感识别存在域不匹配问题，特别是在源数据不可用且只能通过API访问LALM的场景下，现有方法适应性较差，因此需要新方法来提升目标域中的表现。

Method: 提出了MI-Fuse框架，该方法利用源域训练的情感识别分类器作为辅助教师，将LALM与辅助教师的多个随机预测结果进行融合，通过互信息衡量不确定性对分布加权，并采用指数移动平均教师稳定训练过程，从而提升学生模型的目标域性能。

Result: 在三个公开情感数据集和六个跨域迁移任务中，实验结果显示学生模型表现优于LALM本身，并比最强对比基线高出3.9%。

Conclusion: MI-Fuse方法在源数据无法共享，且只通过API访问强大LALM的实际场景下，显著提升了学生模型的表现，为情感语音系统的现实自适应提供了有效解决方案。

Abstract: Large audio-language models (LALMs) show strong zero-shot ability on speech
tasks, suggesting promise for speech emotion recognition (SER). However, SER in
real-world deployments often fails under domain mismatch, where source data are
unavailable and powerful LALMs are accessible only through an API. We ask:
given only unlabeled target-domain audio and an API-only LALM, can a student
model be adapted to outperform the LALM in the target domain? To this end, we
propose MI-Fuse, a denoised label fusion framework that supplements the LALM
with a source-domain trained SER classifier as an auxiliary teacher. The
framework draws multiple stochastic predictions from both teachers, weights
their mean distributions by mutual-information-based uncertainty, and
stabilizes training with an exponential moving average teacher. Experiments
across three public emotion datasets and six cross-domain transfers show
consistent gains, with the student surpassing the LALM and outperforming the
strongest baseline by 3.9%. This approach strengthens emotion-aware speech
systems without sharing source data, enabling realistic adaptation.

</details>


### [46] [Probability Distribution Collapse: A Critical Bottleneck to Compact Unsupervised Neural Grammar Induction](https://arxiv.org/abs/2509.20734)
*Jinwook Park,Kangil Kim*

Main category: cs.CL

TL;DR: 该论文针对无监督神经语法归纳中的表达瓶颈问题，识别出核心障碍为概率分布坍塌，并提出专门的神经参数化方法，有效改善解析性能并压缩语法规模。


<details>
  <summary>Details</summary>
Motivation: 无监督神经语法归纳希望从语言数据中学习可解释的层次结构，但现有模型面临表达能力瓶颈，导致语法复杂且表现较差。

Method: 作者分析了神经参数化过程中的概率分布坍塌问题，并提出了一种针对性解决方案——collapse-relaxing神经参数化，以缓解这一问题。

Result: 通过广泛实证分析，新方法在多种语言上显著提升了解析性能，同时使得可用语法更加紧凑。

Conclusion: 提出的collapse-relaxing神经参数化方法有效解决了神经语法归纳模型的表达瓶颈问题，在解析效果和语法紧凑性方面均取得了优异成绩。

Abstract: Unsupervised neural grammar induction aims to learn interpretable
hierarchical structures from language data. However, existing models face an
expressiveness bottleneck, often resulting in unnecessarily large yet
underperforming grammars. We identify a core issue, $\textit{probability
distribution collapse}$, as the underlying cause of this limitation. We analyze
when and how the collapse emerges across key components of neural
parameterization and introduce a targeted solution, $\textit{collapse-relaxing
neural parameterization}$, to mitigate it. Our approach substantially improves
parsing performance while enabling the use of significantly more compact
grammars across a wide range of languages, as demonstrated through extensive
empirical analysis.

</details>


### [47] [Confidence-guided Refinement Reasoning for Zero-shot Question Answering](https://arxiv.org/abs/2509.20750)
*Youwon Jang,Woo Suk Choi,Minjoon Jung,Minsu Lee,Byoung-Tak Zhang*

Main category: cs.CL

TL;DR: 提出了一个无训练、基于置信度引导的QA推理框架C2R，通过构建和整合子问题及答案提升模型表现，并深入分析了子问题机制对推理结果的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的QA系统在推理过程中难以保证答案的可靠性，且如何系统性利用子问题进行推理是一个亟待解决的问题。

Method: 通过构造和细化子问题与答案，利用模型自身的置信度分数，选择最可靠的最终答案。无需额外训练，可无缝集成到现有QA模型中。

Result: C2R在多种QA模型和基准测试中均带来了性能提升，并分析了子问题数量和质量对推理稳健性的影响。

Conclusion: C2R方法可以有效提升各类QA模型在不同领域中的表现，且对模型行为的机制进行了深入分析。

Abstract: We propose Confidence-guided Refinement Reasoning (C2R), a novel
training-free framework applicable to question-answering (QA) tasks across
text, image, and video domains. C2R strategically constructs and refines
sub-questions and their answers (sub-QAs), deriving a better confidence score
for the target answer. C2R first curates a subset of sub-QAs to explore diverse
reasoning paths, then compares the confidence scores of the resulting answer
candidates to select the most reliable final answer. Since C2R relies solely on
confidence scores derived from the model itself, it can be seamlessly
integrated with various existing QA models, demonstrating consistent
performance improvements across diverse models and benchmarks. Furthermore, we
provide essential yet underexplored insights into how leveraging sub-QAs
affects model behavior, specifically analyzing the impact of both the quantity
and quality of sub-QAs on achieving robust and reliable reasoning.

</details>


### [48] [SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs](https://arxiv.org/abs/2509.20758)
*Jiacheng Lin,Zhongruo Wang,Kun Qian,Tian Wang,Arvind Srinivasan,Hansi Zeng,Ruochen Jiao,Xie Zhou,Jiri Gesi,Dakuo Wang,Yufan Guo,Kai Zhong,Weiqi Zhang,Sujay Sanghavi,Changyou Chen,Hyokun Yun,Lihong Li*

Main category: cs.CL

TL;DR: 论文系统分析了LLM微调的领域与通用能力权衡，发现小学习率能缓解通用性能下降，提出TALR方法实现更优平衡，但没有现有方法能彻底消除这一权衡。最终给出具体适配建议。


<details>
  <summary>Details</summary>
Motivation: 针对大语言模型（LLMs）在领域数据上进行有监督微调（SFT）时，常见观点认为会导致模型通用能力下降。为此，作者希望重新评估这一权衡，并提出新的解决方案。

Method: 作者采用了实证和理论分析，首先对不同学习率下的SFT进行了实验，并提出了Token-Adaptive Loss Reweighting（TALR）方法。同时，论文还评估了包括L2正则化、LoRA、模型平均、FLOW以及TALR等多种减少通用能力损失的策略。

Result: 实验结果显示，采用较小学习率能有效减少通用能力下降，并且TALR方案在兼顾领域性能和通用能力方面优于其它方法，但没有一种方法能完全消除这一权衡。

Conclusion: 建议在适配LLM到新领域时：（i）采用较小学习率以实现较优权衡；（ii）如果需要更好平衡，可选TALR方案。

Abstract: Supervised Fine-Tuning (SFT) on domain-specific datasets is a common approach
to adapt Large Language Models (LLMs) to specialized tasks but is often
believed to degrade their general capabilities. In this work, we revisit this
trade-off and present both empirical and theoretical insights. First, we show
that SFT does not always hurt: using a smaller learning rate can substantially
mitigate general performance degradation while preserving comparable
target-domain performance. We then provide a theoretical analysis that explains
these phenomena and further motivates a new method, Token-Adaptive Loss
Reweighting (TALR). Building on this, and recognizing that smaller learning
rates alone do not fully eliminate general-performance degradation in all
cases, we evaluate a range of strategies for reducing general capability loss,
including L2 regularization, LoRA, model averaging, FLOW, and our proposed
TALR. Experimental results demonstrate that while no method completely
eliminates the trade-off, TALR consistently outperforms these baselines in
balancing domain-specific gains and general capabilities. Finally, we distill
our findings into practical guidelines for adapting LLMs to new domains: (i)
using a small learning rate to achieve a favorable trade-off, and (ii) when a
stronger balance is further desired, adopt TALR as an effective strategy.

</details>


### [49] [Towards Atoms of Large Language Models](https://arxiv.org/abs/2509.20784)
*Chenhui Hu,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: 本文提出一种新的表征单元“原子”，理论上定义其稀疏性、唯一性与稳定性，用新型稀疏自编码器在主流LLM中实验验证，被证实明显优于传统神经元和特征，有力推动LLM机制解释。


<details>
  <summary>Details</summary>
Motivation: 当前大量语言模型（LLMs）内部表征的基本单元未被明确界定，常用的神经元或特征都存在多义性、重建不可靠与不稳定等问题。这限制了对模型机制更深入的理解。

Method: 提出原子理论（Atoms Theory），首次系统定义LLM中“原子”表征单元，引入原子内积（AIP）校正表征偏移，并从理论上证明原子的稀疏性与稳定性条件（RIP），与压缩感知相关联。在更强的条件下，证明原子表征的唯一性与$\\ell_1$可恢复性，并保证用单层稀疏自编码器（SAE）带阈值激活可可靠识别原子。实验方面，在Gemma2-2B、Gemma2-9B、Llama3.1-8B多层上训练SAE，检验理论。

Result: 原子表征相比传统的神经元（0.5%唯一性）与特征（68.2%唯一性），在三个主流LLM模型上达到平均99.9%稀疏重建率，超99.8%原子满足唯一性条件，显示原子更忠实捕捉LLM内在表征。规模实验揭示SAE容量与恢复能力的联系。

Conclusion: 原子理论为LLMs内部表征单元提供了严密的理论定义与验证，为机制化解释性打开新方向。原子单元在构建稳定、唯一、可恢复的稀疏表征方面表现优异，为研究LLM机制提供了理论基础与工具。

Abstract: The fundamental units of internal representations in large language models
(LLMs) remain undefined, limiting further understanding of their mechanisms.
Neurons or features are often regarded as such units, yet neurons suffer from
polysemy, while features face concerns of unreliable reconstruction and
instability. To address this issue, we propose the Atoms Theory, which defines
such units as atoms. We introduce the atomic inner product (AIP) to correct
representation shifting, formally define atoms, and prove the conditions that
atoms satisfy the Restricted Isometry Property (RIP), ensuring stable sparse
representations over atom set and linking to compressed sensing. Under stronger
conditions, we further establish the uniqueness and exact $\ell_1$
recoverability of the sparse representations, and provide guarantees that
single-layer sparse autoencoders (SAEs) with threshold activations can reliably
identify the atoms. To validate the Atoms Theory, we train threshold-activated
SAEs on Gemma2-2B, Gemma2-9B, and Llama3.1-8B, achieving 99.9% sparse
reconstruction across layers on average, and more than 99.8% of atoms satisfy
the uniqueness condition, compared to 0.5% for neurons and 68.2% for features,
showing that atoms more faithfully capture intrinsic representations of LLMs.
Scaling experiments further reveal the link between SAEs size and recovery
capacity. Overall, this work systematically introduces and validates Atoms
Theory of LLMs, providing a theoretical framework for understanding internal
representations and a foundation for mechanistic interpretability. Code
available at https://github.com/ChenhuiHu/towards_atoms.

</details>


### [50] [Few-Shot and Training-Free Review Generation via Conversational Prompting](https://arxiv.org/abs/2509.20805)
*Genki Kusano*

Main category: cs.CL

TL;DR: 提出对话式提示生成个性化评论，无需训练且只需极少用户评论样本即可显著提升评论个性化，适用于真实低资源场景。


<details>
  <summary>Details</summary>
Motivation: 现有个性化评论生成方法需要丰富的用户评论历史或额外模型训练，而实际应用中常常面临评论样本极少和无法微调的问题。因此，寻求一种低资源、无需训练的评论生成方式十分关键。

Method: 提出了对话式提示方法（Conversational Prompting），将用户评论重构为多轮对话。其简单变体SCP仅使用用户自身评论，对比变体CCP则引入其他用户或LLM的评论作为“错误回复”，再让模型纠正，强化用户风格。

Result: 在八个商品领域和五种LLM上的实验表明，传统非对话式提示生成的评论更接近随机用户；而SCP和CCP生成的评论显著更贴合目标用户，仅需两个评论样本即可。CCP在有高质量负例时效果更好，SCP适用于负例无法收集时。

Conclusion: 对话式提示，尤其是SCP和CCP，可在极少样本且无需训练的情况下生成高度个性化的评论，为实际个性化评论生成带来实用解决方案。

Abstract: Personalized review generation helps businesses understand user preferences,
yet most existing approaches assume extensive review histories of the target
user or require additional model training. Real-world applications often face
few-shot and training-free situations, where only a few user reviews are
available and fine-tuning is infeasible. It is well known that large language
models (LLMs) can address such low-resource settings, but their effectiveness
depends on prompt engineering. In this paper, we propose Conversational
Prompting, a lightweight method that reformulates user reviews as multi-turn
conversations. Its simple variant, Simple Conversational Prompting (SCP),
relies solely on the user's own reviews, while the contrastive variant,
Contrastive Conversational Prompting (CCP), inserts reviews from other users or
LLMs as incorrect replies and then asks the model to correct them, encouraging
the model to produce text in the user's style. Experiments on eight product
domains and five LLMs showed that the conventional non-conversational prompt
often produced reviews similar to those written by random users, based on
text-based metrics such as ROUGE-L and BERTScore, and application-oriented
tasks like user identity matching and sentiment analysis. In contrast, both SCP
and CCP produced reviews much closer to those of the target user, even when
each user had only two reviews. CCP brings further improvements when
high-quality negative examples are available, whereas SCP remains competitive
when such data cannot be collected. These results suggest that conversational
prompting offers a practical solution for review generation under few-shot and
training-free constraints.

</details>


### [51] [Enrich-on-Graph: Query-Graph Alignment for Complex Reasoning with LLM Enriching](https://arxiv.org/abs/2509.20810)
*Songze Li,Zhiqiang Liu,Zhengke Gui,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: 针对大语言模型在知识图谱问答中存在的准确性和推理难题，本文提出EoG框架，通过丰富知识图谱实现更好的语义对齐和推理性能，达到了最优实验结果。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）在知识密集型场景（如知识图谱问答KGQA）中存在幻觉和事实错误，核心原因在于结构化知识图谱和非结构化查询之间存在语义鸿沟。现有方法忽视了这种鸿沟，导致推理流程高资源消耗且可扩展性差。

Method: 提出了一个灵活的框架Enrich-on-Graph（EoG），利用LLMs的先验知识对知识图谱进行丰富，以弥合图谱与查询之间的语义差距。EoG支持高效的证据抽取、低计算成本、可扩展性和方法适应性。同时提出三种图谱质量评估指标，并进行了理论验证。

Result: EoG可以生成高质量的知识图谱，并且在两项KGQA基准数据集上达到了最新最优效果。

Conclusion: EoG框架有效缓解了知识图谱与查询之间的语义鸿沟，提升了KGQA任务的推理准确性和鲁棒性，并具备良好的计算效率和可扩展性。

Abstract: Large Language Models (LLMs) exhibit strong reasoning capabilities in complex
tasks. However, they still struggle with hallucinations and factual errors in
knowledge-intensive scenarios like knowledge graph question answering (KGQA).
We attribute this to the semantic gap between structured knowledge graphs (KGs)
and unstructured queries, caused by inherent differences in their focuses and
structures. Existing methods usually employ resource-intensive, non-scalable
workflows reasoning on vanilla KGs, but overlook this gap. To address this
challenge, we propose a flexible framework, Enrich-on-Graph (EoG), which
leverages LLMs' prior knowledge to enrich KGs, bridge the semantic gap between
graphs and queries. EoG enables efficient evidence extraction from KGs for
precise and robust reasoning, while ensuring low computational costs,
scalability, and adaptability across different methods. Furthermore, we propose
three graph quality evaluation metrics to analyze query-graph alignment in KGQA
task, supported by theoretical validation of our optimization objectives.
Extensive experiments on two KGQA benchmark datasets indicate that EoG can
effectively generate high-quality KGs and achieve the state-of-the-art
performance. Our code and data are available at
https://github.com/zjukg/Enrich-on-Graph.

</details>


### [52] [Leveraging What's Overfixed: Post-Correction via LLM Grammatical Error Overcorrection](https://arxiv.org/abs/2509.20811)
*Taehee Park,Heejin Do,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: 小模型纠错精度高但召回低，大模型召回高但过度纠正。PoCO方法结合两者，先用大模型过度纠正提高召回，再用小模型修正错误，实验显示有效提升语法纠错性能。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型在精度上表现优异但召回率低，而大型语言模型则召回率高但易过度纠正、精度低。如何结合两者优势以提升语法纠错任务性能是重要挑战。

Method: 提出PoCO方法，先用大模型进行故意过度纠正以最大化召回，再用微调小模型对输出进行有针对性的修正，以平衡精度和召回。

Result: 实验结果表明PoCO能有效平衡召回率和精度，提升语法纠错整体表现。

Conclusion: PoCO方法结合大模型的生成能力和小模型的可靠性，有效提升了语法纠错系统的召回和精度。

Abstract: Robust supervised fine-tuned small Language Models (sLMs) often show high
reliability but tend to undercorrect. They achieve high precision at the cost
of low recall. Conversely, Large Language Models (LLMs) often show the opposite
tendency, making excessive overcorrection, leading to low precision. To
effectively harness the strengths of LLMs to address the recall challenges in
sLMs, we propose Post-Correction via Overcorrection (PoCO), a novel approach
that strategically balances recall and precision. PoCO first intentionally
triggers overcorrection via LLM to maximize recall by allowing comprehensive
revisions, then applies a targeted post-correction step via fine-tuning smaller
models to identify and refine erroneous outputs. We aim to harmonize both
aspects by leveraging the generative power of LLMs while preserving the
reliability of smaller supervised models. Our extensive experiments demonstrate
that PoCO effectively balances GEC performance by increasing recall with
competitive precision, ultimately improving the overall quality of grammatical
error correction.

</details>


### [53] [Distilling Many-Shot In-Context Learning into a Cheat Sheet](https://arxiv.org/abs/2509.20820)
*Ukyo Honda,Soichiro Murakami,Peinan Zhang*

Main category: cs.CL

TL;DR: 提出了一种将多示例ICL信息压缩为简洁“cheat sheet”的方法，能大幅降低输入长度，并保持乃至提升性能，是高效实用的ICL新方式。


<details>
  <summary>Details</summary>
Motivation: 传统多示例ICL虽然表现优良，但需要较长输入，导致计算成本高。因此希望通过压缩和摘要的方式，减少token用量并维持性能。

Method: 提出了一种cheat-sheet ICL方法，通过将多示例ICL的信息压缩为简洁的文本摘要（cheat sheet），并在推理阶段将其作为上下文进行使用。通过在复杂推理任务上的实验证明其有效性。

Result: cheat-sheet ICL使用更少的token，效果与多示例ICL和检索式ICL持平或更好，且无需推理时检索。

Conclusion: cheat-sheet ICL 可以在显著减少输入token数量的同时，实现与多示例ICL相当甚至更优的性能，是一种高效且实用的ICL替代方案。

Abstract: Recent advances in large language models (LLMs) enable effective in-context
learning (ICL) with many-shot examples, but at the cost of high computational
demand due to longer input tokens. To address this, we propose cheat-sheet ICL,
which distills the information from many-shot ICL into a concise textual
summary (cheat sheet) used as the context at inference time. Experiments on
challenging reasoning tasks show that cheat-sheet ICL achieves comparable or
better performance than many-shot ICL with far fewer tokens, and matches
retrieval-based ICL without requiring test-time retrieval. These findings
demonstrate that cheat-sheet ICL is a practical alternative for leveraging LLMs
in downstream tasks.

</details>


### [54] [Zero-Shot Privacy-Aware Text Rewriting via Iterative Tree Search](https://arxiv.org/abs/2509.20838)
*Shuo Huang,Xingliang Yuan,Gholamreza Haffari,Lizhen Qu*

Main category: cs.CL

TL;DR: 本文提出一种新颖的自动句子重写算法，有效提升云服务大模型下的文本隐私保护，同时兼顾文本质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在云服务中的普及引发了用户输入隐私泄露的担忧，而现有文本匿名化和去标识技术往往无法兼顾隐私保护与文本自然性和可用性。

Method: 提出了一种零样本、基于树搜索的迭代句子重写算法，通过结构化搜索和奖励模型动态探索重写空间，逐步对敏感部分进行模糊化或删除，同时保留文本的连贯性和相关性。

Result: 在隐私敏感数据集上的实验结果显示，该方法相比现有基线方法，在保护隐私和保留文本效用两方面都取得了更好的平衡。

Conclusion: 所提出的算法能有效提升隐私保护能力，同时保持文本的自然流畅和实用性，优于已有处理方法。

Abstract: The increasing adoption of large language models (LLMs) in cloud-based
services has raised significant privacy concerns, as user inputs may
inadvertently expose sensitive information. Existing text anonymization and
de-identification techniques, such as rule-based redaction and scrubbing, often
struggle to balance privacy preservation with text naturalness and utility. In
this work, we propose a zero-shot, tree-search-based iterative sentence
rewriting algorithm that systematically obfuscates or deletes private
information while preserving coherence, relevance, and naturalness. Our method
incrementally rewrites privacy-sensitive segments through a structured search
guided by a reward model, enabling dynamic exploration of the rewriting space.
Experiments on privacy-sensitive datasets show that our approach significantly
outperforms existing baselines, achieving a superior balance between privacy
protection and utility preservation.

</details>


### [55] [Concise and Sufficient Sub-Sentence Citations for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.20859)
*Guo Chen,Qiuyuan Li,Qiuxian Li,Hongliang Dai,Xiang Chen,Piji Li*

Main category: cs.CL

TL;DR: 提出了针对RAG系统的子句级引用机制，并通过自动化数据生成与质量筛选，大幅提升了引用内容的相关性和准确性，减轻了用户验证负担。


<details>
  <summary>Details</summary>
Motivation: 现有RAG问答系统中的引用方式存在两个问题：1)引用通常是句子或段落级别，而长句/段落可能包含大量无关内容；2)句子级引用可能遗漏验证输出所需的关键信息，用户需要额外阅读上下文。为提升引用的准确性和用户验证效率，提出更细粒度的引用方法。

Method: 制定了新的细粒度子句（sub-sentence）级引用注释规范，并构建了相应数据集。提出了依照这些标准生成引用的归因框架：利用大模型自动生成微调数据，并通过信用模型过滤低质量示例。

Result: 实验表明，该方法能生成高质量且可读性更强的引用，提升了验证效率和引用的准确性。

Conclusion: 通过细粒度子句级引用及配套框架，有效提升了RAG问答系统中引用的可读性与准确性，帮助用户更便捷地验证LLM生成内容。

Abstract: In retrieval-augmented generation (RAG) question answering systems,
generating citations for large language model (LLM) outputs enhances
verifiability and helps users identify potential hallucinations. However, we
observe two problems in the citations produced by existing attribution methods.
First, the citations are typically provided at the sentence or even paragraph
level. Long sentences or paragraphs may include a substantial amount of
irrelevant content. Second, sentence-level citations may omit information that
is essential for verifying the output, forcing users to read the surrounding
context. In this paper, we propose generating sub-sentence citations that are
both concise and sufficient, thereby reducing the effort required by users to
confirm the correctness of the generated output. To this end, we first develop
annotation guidelines for such citations and construct a corresponding dataset.
Then, we propose an attribution framework for generating citations that adhere
to our standards. This framework leverages LLMs to automatically generate
fine-tuning data for our task and employs a credit model to filter out
low-quality examples. Our experiments on the constructed dataset demonstrate
that the propose approach can generate high-quality and more readable
citations.

</details>


### [56] [WeFT: Weighted Entropy-driven Fine-Tuning for dLLMs](https://arxiv.org/abs/2509.20863)
*Guowei Xu,Wenxin Xu,Jiawang Zhao,Kaisheng Ma*

Main category: cs.CL

TL;DR: 本文提出了WeFT，一种针对语言扩散模型的熵加权微调方法，有效提升了模型在多项推理任务上的表现和一致性，相较常规微调获得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在语言建模方面展现出潜力，具有比传统自回归方法更快的生成速度。但在应用监督微调（SFT）时遇到难题，扩散模型在每步去噪时缺少精确的概率估计，生成过程不可预测且一致性较低，尤其是在需要控制关键token引导生成方向时。

Method: 提出WeFT，即一种针对扩散语言模型的加权SFT方法。该方法根据token的熵为不同token分配不同权重，权重设计受扩散理论启发。

Result: 在open-r1数据集上的s1K、s1K-1.1和3k样本进行训练，WeFT方法在四个广泛使用的推理基准测试（Sudoku, Countdown, GSM8K, MATH-500）上相比标准SFT获得了39%、64%、83%的相对提升。代码和模型将公开。

Conclusion: 加权SFT（WeFT）能显著提升扩散语言模型在推理任务中的表现，通过合理分配token权重解决了扩散模型生成一致性和可控性的问题。

Abstract: Diffusion models have recently shown strong potential in language modeling,
offering faster generation compared to traditional autoregressive approaches.
However, applying supervised fine-tuning (SFT) to diffusion models remains
challenging, as they lack precise probability estimates at each denoising step.
While the diffusion mechanism enables the model to reason over entire
sequences, it also makes the generation process less predictable and often
inconsistent. This highlights the importance of controlling key tokens that
guide the direction of generation. To address this issue, we propose WeFT, a
weighted SFT method for diffusion language models, where tokens are assigned
different weights based on their entropy. Derived from diffusion theory, WeFT
delivers substantial gains: training on s1K, s1K-1.1, and 3k samples from
open-r1, it achieves relative improvements of 39%, 64%, and 83% over standard
SFT on four widely used reasoning benchmarks (Sudoku, Countdown, GSM8K, and
MATH-500). The code and models will be made publicly available.

</details>


### [57] [Single Answer is Not Enough: On Generating Ranked Lists with Medical Reasoning Models](https://arxiv.org/abs/2509.20866)
*Pittawat Taveekitworachai,Natpatchara Pongjirapat,Krittaphas Chaisutyakorn,Piyalitt Ittichaiwong,Tossaporn Saengja,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 本研究提出医学推理模型在开放式问题中生成排名列表答案的新方法，通过提示和微调有效提升模型对多答案格式的适应性，强化微调法尤其表现出更强泛化能力，为医疗决策提供多元解决方案。


<details>
  <summary>Details</summary>
Motivation: 医学领域的临床决策通常需要考虑多个答案选项，从而减少因单一视角带来的风险，但当前医学推理模型（MRMs）在开放式问题中一般只给出单一答案，无法满足实际需求。

Method: 论文提出让模型生成排名列表格式答案，并分别采用提示（prompting）和微调（SFT和RFT）两种方法。提示法试图通过不同提示来引导模型生成所需格式答案，微调法包括模拟标注答案的有监督微调（SFT）和基于奖励函数的强化微调（RFT），针对排名列表答案设计了新奖励函数，并对RFT进行了消融实验。

Result: 部分SFT模型能泛化到有限的答案格式，而RFT训练的模型在多种答案格式上更具鲁棒性。在修改后的MedQA案例研究中，即使模型未能选出基准答案，也能识别其他有效答案。

Conclusion: 首次系统性研究医学推理模型在开放式问题上生成排名列表答案的方法，提出的新方法和奖励函数提升了模型在多答案场景下的表现，为医学领域中更丰富的答案格式奠定了基础。

Abstract: This paper presents a systematic study on enabling medical reasoning models
(MRMs) to generate ranked lists of answers for open-ended questions. Clinical
decision-making rarely relies on a single answer but instead considers multiple
options, reducing the risks of narrow perspectives. Yet current MRMs are
typically trained to produce only one answer, even in open-ended settings. We
propose an alternative format: ranked lists and investigate two approaches:
prompting and fine-tuning. While prompting is a cost-effective way to steer an
MRM's response, not all MRMs generalize well across different answer formats:
choice, short text, and list answers. Based on our prompting findings, we train
and evaluate MRMs using supervised fine-tuning (SFT) and reinforcement
fine-tuning (RFT). SFT teaches a model to imitate annotated responses, and RFT
incentivizes exploration through the responses that maximize a reward. We
propose new reward functions targeted at ranked-list answer formats, and
conduct ablation studies for RFT. Our results show that while some SFT models
generalize to certain answer formats, models trained with RFT are more robust
across multiple formats. We also present a case study on a modified MedQA with
multiple valid answers, finding that although MRMs might fail to select the
benchmark's preferred ground truth, they can recognize valid answers. To the
best of our knowledge, this is the first systematic investigation of approaches
for enabling MRMs to generate answers as ranked lists. We hope this work
provides a first step toward developing alternative answer formats that are
beneficial beyond single answers in medical domains.

</details>


### [58] [Learning to Summarize by Learning to Quiz: Adversarial Agentic Collaboration for Long Document Summarization](https://arxiv.org/abs/2509.20900)
*Weixuan Wang,Minghao Wu,Barry Haddow,Alexandra Birch*

Main category: cs.CL

TL;DR: 针对长文档摘要的准确性和连贯性难题，本文提出融合摘要与测验的多智能体对抗框架SummQ，通过协同、反馈和动态优化，全面提升了摘要质量，在多项评价中明显超越当前主流方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在长文档摘要任务中普遍存在信息丢失、事实不一致和摘要连贯性差等问题。此领域亟需新的方法来提升摘要的质量与可信度。

Method: 提出了一种名为SummQ的新型对抗性多智能体框架。该方法通过摘要生成者和摘要评审者合作生成和评估摘要，同时有测验生成者和测验评审者负责生成理解性问题，对摘要过程进行质量检查。答题智能体检验摘要是否包含回答测验所需的信息，通过多维度反馈不断完善生成结果。

Result: 在三个主流长文档摘要基准上测试，SummQ框架在ROUGE和BERTScore等自动评价指标上，以及LLM-as-a-Judge与人工评估实验中显著优于现有最新方法。分析证实了多智能体协作、不同智能体配置与测验机制对摘要质量的提升作用。

Conclusion: 多智能体对抗协作和测验机制可以有效提升长文档摘要的质量，提供了一种全新的自动长文档摘要解决方案。

Abstract: Long document summarization remains a significant challenge for current large
language models (LLMs), as existing approaches commonly struggle with
information loss, factual inconsistencies, and coherence issues when processing
excessively long documents. We propose SummQ, a novel adversarial multi-agent
framework that addresses these limitations through collaborative intelligence
between specialized agents operating in two complementary domains:
summarization and quizzing. Our approach employs summary generators and
reviewers that work collaboratively to create and evaluate comprehensive
summaries, while quiz generators and reviewers create comprehension questions
that serve as continuous quality checks for the summarization process. This
adversarial dynamic, enhanced by an examinee agent that validates whether the
generated summary contains the information needed to answer the quiz questions,
enables iterative refinement through multifaceted feedback mechanisms. We
evaluate SummQ on three widely used long document summarization benchmarks.
Experimental results demonstrate that our framework significantly outperforms
existing state-of-the-art methods across ROUGE and BERTScore metrics, as well
as in LLM-as-a-Judge and human evaluations. Our comprehensive analyses reveal
the effectiveness of the multi-agent collaboration dynamics, the influence of
different agent configurations, and the impact of the quizzing mechanism. This
work establishes a new approach for long document summarization that uses
adversarial agentic collaboration to improve summarization quality.

</details>


### [59] [MemLens: Uncovering Memorization in LLMs with Activation Trajectories](https://arxiv.org/abs/2509.20909)
*Zirui He,Haiyan Zhao,Ali Payani,Mengnan du*

Main category: cs.CL

TL;DR: 提出了一种分析概率轨迹的新方法MemLens，可以准确检测大模型记忆污染，显著优于传统依赖词汇重叠与困惑度的方法，并验证了该方法可抓住真实的模型记忆信号。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型检测记忆污染主要依赖表面词汇重叠或困惑度，但泛化能力低，对隐性污染数据表现差。因此有必要开发更有效的记忆污染检测方法。

Method: 提出MemLens方法，通过分析模型生成过程中数值token的概率轨迹，判断是否发生记忆污染。对比污染样本和干净样本在模型不同层的“锁定答案”行为与证据累积过程。并通过LoRA微调注入人工设计样本与自然污染样本对比，验证有效性。

Result: MemLens发现污染样本会在模型早期层就高度自信锁定答案，而干净样本则在模型深度中渐进积累证据。污染样本与干净样本在推理轨迹上高度可分。人工注入污染样本后也能复现相同轨迹模式。

Conclusion: MemLens不仅能够区分污染与干净样本，还能捕捉真实的记忆信号，摆脱过往方法依赖的虚假相关，提高污染检测的准确性和鲁棒性。

Abstract: Large language models (LLMs) are commonly evaluated on challenging benchmarks
such as AIME and Math500, which are susceptible to contamination and risk of
being memorized. Existing detection methods, which primarily rely on
surface-level lexical overlap and perplexity, demonstrate low generalization
and degrade significantly when encountering implicitly contaminated data. In
this paper, we propose MemLens (An Activation Lens for Memorization Detection)
to detect memorization by analyzing the probability trajectories of numeric
tokens during generation. Our method reveals that contaminated samples exhibit
``shortcut'' behaviors, locking onto an answer with high confidence in the
model's early layers, whereas clean samples show more gradual evidence
accumulation across the model's full depth. We observe that contaminated and
clean samples exhibit distinct and well-separated reasoning trajectories. To
further validate this, we inject carefully designed samples into the model
through LoRA fine-tuning and observe the same trajectory patterns as in
naturally contaminated data. These results provide strong evidence that MemLens
captures genuine signals of memorization rather than spurious correlations.

</details>


### [60] [Cross-Linguistic Analysis of Memory Load in Sentence Comprehension: Linear Distance and Structural Density](https://arxiv.org/abs/2509.20916)
*Krishna Aggarwal*

Main category: cs.CL

TL;DR: 本研究通过多语言树库和混合效应模型考察句子处理中记忆负荷的决定因素，发现介入头数量这一结构指标优于线性距离，可更好解释语句理解中的认知负担。


<details>
  <summary>Details</summary>
Motivation: 传统语法处理研究通常关注句子结构中依存关系的线性距离，但实际认知负担可能还受到介入结构复杂性的影响。该研究旨在探究到底是线性距离还是结构密度更好地解释语句理解中的记忆负荷。

Method: 利用多语言依存句法树库和混合效应模型，考察句长、依存距离及介入者复杂度（即依存关系中介入头的数量）对句子记忆负荷的预测作用，并将句子层面的记忆负荷操作化为特征误绑定与特征干扰之线性和。

Result: 句长、依存距离、介入者复杂度均与记忆负荷呈正相关，其中句长影响最大，但介入者复杂度在解释记忆负荷上优于纯线性距离。

Conclusion: 研究发现结构密度（介入头数量）这一指标比线性依存距离更充分解释理解过程中的记忆负担。结果调和了线性与分层观念，并提出跨语言基于UD树库的分析路径，有助于区分不同理论的解释力。

Abstract: This study examines whether sentence-level memory load in comprehension is
better explained by linear proximity between syntactically related words or by
the structural density of the intervening material. Building on locality-based
accounts and cross-linguistic evidence for dependency length minimization, the
work advances Intervener Complexity-the number of intervening heads between a
head and its dependent-as a structurally grounded lens that refines linear
distance measures. Using harmonized dependency treebanks and a mixed-effects
framework across multiple languages, the analysis jointly evaluates sentence
length, dependency length, and Intervener Complexity as predictors of the
Memory-load measure. Studies in Psycholinguistics have reported the
contributions of feature interference and misbinding to memory load during
processing. For this study, I operationalized sentence-level memory load as the
linear sum of feature misbinding and feature interference for tractability;
current evidence does not establish that their cognitive contributions combine
additively. All three factors are positively associated with memory load, with
sentence length exerting the broadest influence and Intervener Complexity
offering explanatory power beyond linear distance. Conceptually, the findings
reconcile linear and hierarchical perspectives on locality by treating
dependency length as an important surface signature while identifying
intervening heads as a more proximate indicator of integration and maintenance
demands. Methodologically, the study illustrates how UD-based graph measures
and cross-linguistic mixed-effects modelling can disentangle linear and
structural contributions to processing efficiency, providing a principled path
for evaluating competing theories of memory load in sentence comprehension.

</details>


### [61] [Tool Calling for Arabic LLMs: Data Strategies and Instruction Tuning](https://arxiv.org/abs/2509.20957)
*Asim Ersoy,Enes Altinisik,Husrev Taha Sencar,Kareem Darwish*

Main category: cs.CL

TL;DR: 本文针对阿拉伯语大语言模型工具调用能力展开实验，涵盖数据本地化、通用微调和专用微调三大维度，提出优化策略，推动该领域发展。


<details>
  <summary>Details</summary>
Motivation: 目前大多数工具调用相关资源和研究都以英语为主，缺乏对其他语言（如阿拉伯语）工具调用能力的理解和探索。研究人员希望填补这一空白。

Method: 通过翻译和适配两个开源工具调用数据集到阿拉伯语，并使用开放权重的阿拉伯语大型语言模型（基础和后训练版本）进行广泛实验，探讨三大问题：1）是否需要阿拉伯语专属工具调用数据，2）通用指令微调对性能影响，3）针对特定高优先级工具的微调价值。

Result: 研究发现，为阿拉伯语开发强健工具增强智能体的最佳策略，给出了专属数据、通用微调和特定工具微调三者在性能上的关键洞察。

Conclusion: 阿拉伯语工具调用领域需要专属的本语言数据和合理的微调方法，不同方法在提升工具调用性能上具有重要作用，为构建更适合阿拉伯语的工具增强型智能体提供了指导。

Abstract: Tool calling is a critical capability that allows Large Language Models
(LLMs) to interact with external systems, significantly expanding their
utility. However, research and resources for tool calling are predominantly
English-centric, leaving a gap in our understanding of how to enable this
functionality for other languages, such as Arabic. This paper investigates
three key research questions: (1) the necessity of in-language (Arabic)
tool-calling data versus relying on cross-lingual transfer, (2) the effect of
general-purpose instruction tuning on tool-calling performance, and (3) the
value of fine-tuning on specific, high-priority tools. To address these
questions, we conduct extensive experiments using base and post-trained
variants of an open-weight Arabic LLM. To enable this study, we bridge the
resource gap by translating and adapting two open-source tool-calling datasets
into Arabic. Our findings provide crucial insights into the optimal strategies
for developing robust tool-augmented agents for Arabic.

</details>


### [62] [Analysis of instruction-based LLMs' capabilities to score and judge text-input problems in an academic setting](https://arxiv.org/abs/2509.20982)
*Valeria Ramirez-Garcia,David de-Fitero-Dominguez,Antonio Garcia-Cabot,Eva Garcia-Lopez*

Main category: cs.CL

TL;DR: 本研究提出并对比了五种基于大语言模型的学术文本自动评估方法，在真实学生答案上实测发现，以正确参考答案为辅助的评估方法最为精准，能有效减小与人工评分的差距。此类AI自动评分系统有望作为学术评价的可靠辅助。


<details>
  <summary>Details</summary>
Motivation: 当前教育领域中，大语言模型（LLM）常被用作学生和教师的辅助工具，但其作为学术文本输入类问题自动评估工具的能力尚未深入研究。研究动机在于探索LLM如何通过不同的方法与评分标准，自动评判学生回答，提升反馈的效率与公平性。

Method: 作者提出了五种自动评估系统，并在定制的110份高等教育计算机科学学生答案数据集上，用三个模型（JudgeLM、Llama-3.1-8B、DeepSeek-R1-Distill-Llama-8B）进行了测试。这五种评估方法包括：JudgeLM评估、参考答案辅助评估（Reference Aided Evaluation）、无参考答案评估（No Reference Evaluation）、加法评估（Additive Evaluation）、自适应评估（Adaptive Evaluation）。所有方法均与人工评估结果进行了对比分析。

Result: 结果显示，参考答案辅助评估（Reference Aided Evaluation）在与人工评估的偏差指标上表现最佳，具有最低的中位绝对偏差（0.945）和最低的均方根偏差（1.214），能实现公平且信息丰富的自动评分。加法与自适应评估在处理简短答案时效果不佳，无参考评估因缺乏信息导致准确性不足，而JudgeLM评估整体表现有限，受模型自身能力制约。

Conclusion: 基于AI的大语言模型自动评估系统，通过结合适当的方法（如参考答案辅助评估），有潜力成为高等教育中学术评价的重要补充工具。建议未来进一步完善方法以应对不同类型的问题和答案格式。

Abstract: Large language models (LLMs) can act as evaluators, a role studied by methods
like LLM-as-a-Judge and fine-tuned judging LLMs. In the field of education,
LLMs have been studied as assistant tools for students and teachers. Our
research investigates LLM-driven automatic evaluation systems for academic
Text-Input Problems using rubrics. We propose five evaluation systems that have
been tested on a custom dataset of 110 answers about computer science from
higher education students with three models: JudgeLM, Llama-3.1-8B and
DeepSeek-R1-Distill-Llama-8B. The evaluation systems include: The JudgeLM
evaluation, which uses the model's single answer prompt to obtain a score;
Reference Aided Evaluation, which uses a correct answer as a guide aside from
the original context of the question; No Reference Evaluation, which ommits the
reference answer; Additive Evaluation, which uses atomic criteria; and Adaptive
Evaluation, which is an evaluation done with generated criteria fitted to each
question. All evaluation methods have been compared with the results of a human
evaluator. Results show that the best method to automatically evaluate and
score Text-Input Problems using LLMs is Reference Aided Evaluation. With the
lowest median absolute deviation (0.945) and the lowest root mean square
deviation (1.214) when compared to human evaluation, Reference Aided Evaluation
offers fair scoring as well as insightful and complete evaluations. Other
methods such as Additive and Adaptive Evaluation fail to provide good results
in concise answers, No Reference Evaluation lacks information needed to
correctly assess questions and JudgeLM Evaluations have not provided good
results due to the model's limitations. As a result, we conclude that
Artificial Intelligence-driven automatic evaluation systems, aided with proper
methodologies, show potential to work as complementary tools to other academic
resources.

</details>


### [63] [Generative AI for FFRDCs](https://arxiv.org/abs/2509.21040)
*Arun S. Maiya*

Main category: cs.CL

TL;DR: 本研究提出用安全开源框架结合大语言模型，实现对国防及科研文本的高效分析处理，提升战略分析与监督能力，解决效率与安全难题。


<details>
  <summary>Details</summary>
Motivation: FFRDCs需要处理大量文本类工作（如政策文件、科研论文），人工分析速度慢且低效，因此需要新的智能方式提升分析效率。

Method: 利用大语言模型仅需少量输入输出示例实现摘要、分类、信息抽取和理解。同时采用OnPrem.LLM开源框架确保生成式AI在安全和敏感政府环境下应用。

Result: 在国防政策文件和科学数据库（如NDAA和NSF奖项）上的案例研究显示，这种方法提升了监督和战略分析能力，并保证审计与数据主权性。

Conclusion: 结合大语言模型和安全的开源框架可以有效加速和优化FFRDCs对文本工作负载的分析，适用于敏感政府场景。

Abstract: Federally funded research and development centers (FFRDCs) face text-heavy
workloads, from policy documents to scientific and engineering papers, that are
slow to analyze manually. We show how large language models can accelerate
summarization, classification, extraction, and sense-making with only a few
input-output examples. To enable use in sensitive government contexts, we apply
OnPrem$.$LLM, an open-source framework for secure and flexible application of
generative AI. Case studies on defense policy documents and scientific corpora,
including the National Defense Authorization Act (NDAA) and National Science
Foundation (NSF) Awards, demonstrate how this approach enhances oversight and
strategic analysis while maintaining auditability and data sovereignty.

</details>


### [64] [Behind RoPE: How Does Causal Mask Encode Positional Information?](https://arxiv.org/abs/2509.21042)
*Junu Kim,Xiao Liu,Zhenghao Lin,Lei Ji,Yeyun Gong,Edward Choi*

Main category: cs.CL

TL;DR: 论文指出：Transformer的因果掩码本身就能产生类似位置编码的信息和模式，尤其影响注意力分布，甚至能干扰RoPE等显式位置编码的效果，因此设计和分析大语言模型时必须充分考虑因果掩码带来的隐含位置信息。


<details>
  <summary>Details</summary>
Motivation: 虽然主流方法关注显式位置编码（如RoPE），但因果掩码也能带来位置信息，作者希望系统性分析因果掩码对模型位置敏感性的贡献和影响，并与显式位置编码进行比较。

Method: 理论分析与实证分析结合，分别从无参数情况下推导因果掩码的注意力模式，并通过训练模型验证其影响及与RoPE的相互作用。

Result: 证明了因果掩码本身能诱导注意力对近邻位置偏好，这一点随着参数训练会被进一步放大。此外，因果掩码与RoPE交互时，会扭曲RoPE的相对注意力得分，使其变为非相对模式。该现象被多种主流大语言模型验证。

Conclusion: 在Transformer解码器中，因果掩码同样能作为位置编码信息来源，对注意力分数模式产生影响，与显式位置编码（如RoPE）相似甚至可能会干扰其作用。

Abstract: While explicit positional encodings such as RoPE are a primary source of
positional information in Transformer decoders, the causal mask also provides
positional information. In this work, we prove that the causal mask can induce
position-dependent patterns in attention scores, even without parameters or
causal dependency in the input. Our theoretical analysis indicates that the
induced attention pattern tends to favor nearby query-key pairs, mirroring the
behavior of common positional encodings. Empirical analysis confirms that
trained models exhibit the same behavior, with learned parameters further
amplifying these patterns. Notably, we found that the interaction of causal
mask and RoPE distorts RoPE's relative attention score patterns into
non-relative ones. We consistently observed this effect in modern large
language models, suggesting the importance of considering the causal mask as a
source of positional information alongside explicit positional encodings.

</details>


### [65] [When Instructions Multiply: Measuring and Estimating LLM Capabilities of Multiple Instructions Following](https://arxiv.org/abs/2509.21051)
*Keno Harada,Yudai Yamazaki,Masachika Taniguchi,Edison Marrese-Taylor,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CL

TL;DR: 本文提出Two Benchmark体系和小样本回归方法，系统评估LLM在多指令场景下的表现，发现其性能随指令数增加而下降，并可高效预测未见组合表现。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）在真实场景中的应用越来越广泛，理解其同时遵循多条指令的能力变得十分关键。现有评测主要关注单一指令，因此缺乏对多指令场景系统性评估方法。

Method: 作者提出了两个专门的评测基准：ManyIFEval用于文本生成，包含最多10条指令；StyleMBPP用于代码生成，包含最多6条指令。此外，设计了三种回归模型来预估未见过的指令组合及不同指令数量下的表现，尤其是以指令数为解释变量的逻辑回归。

Result: 实验发现，无论文本还是代码任务，当指令数量增加时，LLM的完成质量稳定下降。逻辑回归模型可以在约10%误差范围内预测多指令组合的完成表现，且仅需相对较小的样本量即可实现有效预估（ManyIFEval用500个样本，StyleMBPP用300个样本）。

Conclusion: 作者提供了系统性的多指令跟随能力评估方法，并证明可以用有限样本量和简单模型，有效预测LLM在未见多指令组合下的表现，对实际检测和优化LLM有重要参考意义。

Abstract: As large language models (LLMs) are increasingly applied to real-world
scenarios, it becomes crucial to understand their ability to follow multiple
instructions simultaneously. To systematically evaluate these capabilities, we
introduce two specialized benchmarks for fundamental domains where multiple
instructions following is important: Many Instruction-Following Eval
(ManyIFEval) for text generation with up to ten instructions, and Style-aware
Mostly Basic Programming Problems (StyleMBPP) for code generation with up to
six instructions. Our experiments with the created benchmarks across ten LLMs
reveal that performance consistently degrades as the number of instructions
increases. Furthermore, given the fact that evaluating all the possible
combinations of multiple instructions is computationally impractical in actual
use cases, we developed three types of regression models that can estimate
performance on both unseen instruction combinations and different numbers of
instructions which are not used during training. We demonstrate that a logistic
regression model using instruction count as an explanatory variable can predict
performance of following multiple instructions with approximately 10% error,
even for unseen instruction combinations. We show that relatively modest sample
sizes (500 for ManyIFEval and 300 for StyleMBPP) are sufficient for performance
estimation, enabling efficient evaluation of LLMs under various instruction
combinations.

</details>


### [66] [SoM-1K: A Thousand-Problem Benchmark Dataset for Strength of Materials](https://arxiv.org/abs/2509.21079)
*Qixin Wan,Zilong Wang,Jingwen Zhou,Wanting Wang,Ziheng Geng,Jiachen Liu,Ran Cao,Minghui Cheng,Lu Cheng*

Main category: cs.CL

TL;DR: 提出了材料力学多模态数据集SoM-1K，并创新性地利用专家生成的图像描述提升大模型对工程问题的理解，结果显示现有模型表现有限，文本描述优于直接图像输入，指出多模态推理仍是大模型发展的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 目前大模型（Foundation Models）在诸多领域表现优异，但对于复杂多模态的工程类问题（如材料力学问题）依然鲜有系统性探索，因此亟需相关基准评测以推动模型在工程等科学领域的能力进步。

Method: 提出SoM-1K大规模多模态基准数据集，涵盖1065个带有文本与示意图的材料力学问题，并创新性地提出了图像描述（DoI）提示策略。通过将专业生成的精确图像描述作为上下文输入，评估了8种主流大模型（包括LLM和VLM）在这一任务上的表现，并进行了详细的误差分析。

Result: 当前主流大模型在SoM-1K基准上表现不佳，最佳模型准确率仅为56.6%。使用DoI文本描述时，LLM总体优于直接接收示意图输入的VLM，DoI显著减少了因图像误解导致的错误。

Conclusion: 本工作首次为工程领域建立了严谨的大模型多模态基准，发现准确的文本描述对于当前大模型尤为关键，现有多模态推理能力仍显不足。推动了面向科学工程场景的AI模型能力提升需求。

Abstract: Foundation models have shown remarkable capabilities in various domains, but
their performance on complex, multimodal engineering problems remains largely
unexplored. We introduce SoM-1K, the first large-scale multimodal benchmark
dataset dedicated to evaluating foundation models on problems in the strength
of materials (SoM). The dataset, which contains 1,065 annotated SoM problems,
mirrors real-world engineering tasks by including both textual problem
statements and schematic diagrams. Due to the limited capabilities of current
foundation models in understanding complicated visual information, we propose a
novel prompting strategy called Descriptions of Images (DoI), which provides
rigorous expert-generated text descriptions of the visual diagrams as the
context. We evaluate eight representative foundation models, including both
large language models (LLMs) and vision language models (VLMs). Our results
show that current foundation models struggle significantly with these
engineering problems, with the best-performing model achieving only 56.6%
accuracy. Interestingly, we found that LLMs, when provided with DoI, often
outperform VLMs provided with visual diagrams. A detailed error analysis
reveals that DoI plays a crucial role in mitigating visual misinterpretation
errors, suggesting that accurate text-based descriptions can be more effective
than direct image input for current foundation models. This work establishes a
rigorous benchmark for engineering AI and highlights a critical need for
developing more robust multimodal reasoning capabilities in foundation models,
particularly in scientific and engineering contexts.

</details>


### [67] [Which Cultural Lens Do Models Adopt? On Cultural Positioning Bias and Agentic Mitigation in LLMs](https://arxiv.org/abs/2509.21080)
*Yixin Wan,Xingrun Chen,Kai-Wei Chang*

Main category: cs.CL

TL;DR: 论文发现大模型生成内容存在突出美国文化中心倾向，对其他文化采取外群体视角。作者构建了CultureLens基准，并提出多代理公平性干预方法，有效缓解了生成中的文化偏见。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）有着广泛的生成应用，但研究者发现这些模型在生成内容上存在文化偏见，尤以美国主流文化为中心，忽视或将其他文化边缘化。这种潜在的不公平现象，可能影响模型在多元文化场景的适用性和公正性，因此需要系统研究和解决。

Method: 作者提出了CultureLens基准，包括4000个生成提示和3个评估指标，通过生成面向10种多元文化的采访脚本，系统性量化并分析LLM的文化定位偏见。同时，提出了两种推理时偏见缓解方法：一是基于提示的公平性干预（FIP），二是结构化的多代理公平性干预架构（MFA），分为单代理自我反思与改写和多代理分层批评与修正两种管线。

Result: 在5种最先进的LLM上实证测试，发现脚本中美国文化背景占88%以上为内群体语调，而在其他非主流文化背景下模型更倾向于采用外群体视角。采用多代理公平性干预方法后，脚本生成的文化偏见显著缓解，表现出更公正和多元的生成效果。

Conclusion: 主流LLMs存在明显的文化定位偏见，尤其在多元文化内容生成中易将非主流文化边缘化。提出的新基准和公平性干预方法有效缓解此偏见，提升模型多元文化适应力，为AI生成内容的公平与包容性提供了新的解决思路。

Abstract: Large language models (LLMs) have unlocked a wide range of downstream
generative applications. However, we found that they also risk perpetuating
subtle fairness issues tied to culture, positioning their generations from the
perspectives of the mainstream US culture while demonstrating salient
externality towards non-mainstream ones. In this work, we identify and
systematically investigate this novel culture positioning bias, in which an
LLM's default generative stance aligns with a mainstream view and treats other
cultures as outsiders. We propose the CultureLens benchmark with 4000
generation prompts and 3 evaluation metrics for quantifying this bias through
the lens of a culturally situated interview script generation task, in which an
LLM is positioned as an onsite reporter interviewing local people across 10
diverse cultures. Empirical evaluation on 5 state-of-the-art LLMs reveals a
stark pattern: while models adopt insider tones in over 88 percent of
US-contexted scripts on average, they disproportionately adopt mainly outsider
stances for less dominant cultures. To resolve these biases, we propose 2
inference-time mitigation methods: a baseline prompt-based Fairness
Intervention Pillars (FIP) method, and a structured Mitigation via Fairness
Agents (MFA) framework consisting of 2 pipelines: (1) MFA-SA (Single-Agent)
introduces a self-reflection and rewriting loop based on fairness guidelines.
(2) MFA-MA (Multi-Agent) structures the process into a hierarchy of specialized
agents: a Planner Agent(initial script generation), a Critique Agent (evaluates
initial script against fairness pillars), and a Refinement Agent (incorporates
feedback to produce a polished, unbiased script). Empirical results showcase
the effectiveness of agent-based methods as a promising direction for
mitigating biases in generative LLMs.

</details>


### [68] [PerHalluEval: Persian Hallucination Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2509.21104)
*Mohammad Hosseini,Kimia Hosseini,Shayan Bali,Zahra Zanjani,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 本文提出了波斯语幻觉评测基准PerHalluEval，评估了12种LLM，发现它们在波斯语幻觉检测上表现不佳，外部知识能部分减少幻觉，但专为波斯语训练的模型与其它模型差异不显著。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在低资源语言（如波斯语）中出现幻觉问题，缺乏针对波斯语的系统性评价基准。

Method: 提出了PerHalluEval，首个针对波斯语的动态幻觉评测基准。采用三阶段LLM驱动流程并结合人工校验，针对问答和摘要任务中的外在与内在幻觉进行检测，并利用生成token的对数概率筛选最可信的幻觉实例。引入人工标注以突出与波斯文化相关的问答内容，全面评估模型性能。

Result: 使用PerHalluEval对12个LLM（包括开源和闭源）进行评估，发现模型在检测波斯语幻觉方面表现较差。提供外部知识（如原文档）能部分缓解幻觉问题。专为波斯语训练的LLM与其他LLM在幻觉问题上无显著差异。

Conclusion: LLM在波斯语幻觉检测能力有限，外部知识有助于减少幻觉。专门训练的波斯语模型并未优于通用模型。

Abstract: Hallucination is a persistent issue affecting all large language Models
(LLMs), particularly within low-resource languages such as Persian.
PerHalluEval (Persian Hallucination Evaluation) is the first dynamic
hallucination evaluation benchmark tailored for the Persian language. Our
benchmark leverages a three-stage LLM-driven pipeline, augmented with human
validation, to generate plausible answers and summaries regarding QA and
summarization tasks, focusing on detecting extrinsic and intrinsic
hallucinations. Moreover, we used the log probabilities of generated tokens to
select the most believable hallucinated instances. In addition, we engaged
human annotators to highlight Persian-specific contexts in the QA dataset in
order to evaluate LLMs' performance on content specifically related to Persian
culture. Our evaluation of 12 LLMs, including open- and closed-source models
using PerHalluEval, revealed that the models generally struggle in detecting
hallucinated Persian text. We showed that providing external knowledge, i.e.,
the original document for the summarization task, could mitigate hallucination
partially. Furthermore, there was no significant difference in terms of
hallucination when comparing LLMs specifically trained for Persian with others.

</details>


### [69] [BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback](https://arxiv.org/abs/2509.21106)
*Hyunseo Kim,Sangam Lee,Kwangwook Seo,Dongha Lee*

Main category: cs.CL

TL;DR: 本文提出了针对搜索增强大模型个性化效果的评测基准BESPOKE，通过收集真实用户历史与细致偏好反馈，系统分析了实现个性化所需的关键要求，推动了信息检索中个性化服务的细致评估与发展。


<details>
  <summary>Details</summary>
Motivation: 当前的搜索增强大模型（LLMs）通过将检索与生成结合，在信息获取任务上取得明显进步，减轻了用户的认知负担。但它们仍无法充分满足用户多样化的需求，特别是在同一个查询可能反映不同用户意图，及信息呈现方式个性化方面。尽管如ChatGPT和Gemini的系统尝试利用用户历史实现个性化，但对个性化效果的系统性评估仍不足。

Method: 提出了BESPOKE，一个用于评估搜索增强大模型个性化效果的现实基准。BESPOKE通过收集真实人类聊天和搜索历史，实现现实性，并通过细致的偏好评分和反馈，实现诊断性。该基准由深度参与的人类标注者长期贡献自己的历史、编写有详细信息需求的查询、并用分数和反馈评价模型响应。

Result: 利用BESPOKE，作者进行了系统性分析，揭示了实现信息获取任务个性化的关键需求，并为个性化搜索增强大模型的细致评估奠定了基础。

Conclusion: BESPOKE基准能够真实反映用户历史和信息需求，实现针对搜索增强大模型个性化效果的细致评测，为后续个性化检索模型的研究与评估提供了科学基础。

Abstract: Search-augmented large language models (LLMs) have advanced
information-seeking tasks by integrating retrieval into generation, reducing
users' cognitive burden compared to traditional search systems. Yet they remain
insufficient for fully addressing diverse user needs, which requires
recognizing how the same query can reflect different intents across users and
delivering information in preferred forms. While recent systems such as ChatGPT
and Gemini attempt personalization by leveraging user histories, systematic
evaluation of such personalization is under-explored. To address this gap, we
propose BESPOKE, the realistic benchmark for evaluating personalization in
search-augmented LLMs. BESPOKE is designed to be both realistic, by collecting
authentic chat and search histories directly from humans, and diagnostic, by
pairing responses with fine-grained preference scores and feedback. The
benchmark is constructed through long-term, deeply engaged human annotation,
where human annotators contributed their own histories, authored queries with
detailed information needs, and evaluated responses with scores and diagnostic
feedback. Leveraging BESPOKE, we conduct systematic analyses that reveal key
requirements for effective personalization in information-seeking tasks,
providing a foundation for fine-grained evaluation of personalized
search-augmented LLMs. Our code and data are available at
https://augustinlib.github.io/BESPOKE/.

</details>


### [70] [VoiceBBQ: Investigating Effect of Content and Acoustics in Social Bias of Spoken Language Model](https://arxiv.org/abs/2509.21108)
*Junhyuk Choi,Ro-hoon Oh,Jihwan Seol,Bugeun Kim*

Main category: cs.CL

TL;DR: 作者提出了专为语音语言模型设计的偏见评测工具VoiceBBQ，并比较了主流模型在不同偏见类别下的表现，方便后续相关研究进行针对性评估。


<details>
  <summary>Details</summary>
Motivation: 当前的偏见检测数据集主要集中在文本，缺乏评估语音语言模型（SLM）社会偏见的工具。语音中除了内容偏见外，还有声学层面的偏见，因此需要新的评测方法。

Method: 作者将BBQ（用于检测问答模型中社会偏见的数据集）扩展为语音版本——VoiceBBQ，将每个语境转换为受控音频条件，并可分别评估内容和声学方面的准确率、偏见和一致性。利用该数据集，作者对两种SLM（LLaMA-Omni 和 Qwen2-Audio）进行比较分析。

Result: 实验显示：LLaMA-Omni能抵抗声学偏见，但增强了性别和口音偏见；而Qwen2-Audio明显减弱这些声学线索，同时保持内容准确性。

Conclusion: VoiceBBQ成为一个紧凑、易用的基准，能联合诊断语音语言模型中的内容和声学偏见。

Abstract: We introduce VoiceBBQ, a spoken extension of the BBQ (Bias Benchmark for
Question Answering) - a dataset that measures social bias by presenting
ambiguous or disambiguated contexts followed by questions that may elicit
stereotypical responses. Due to the nature of speech, social bias in Spoken
Language Models (SLMs) can emerge from two distinct sources: 1) content aspect
and 2) acoustic aspect. The dataset converts every BBQ context into controlled
voice conditions, enabling per-axis accuracy, bias, and consistency scores that
remain comparable to the original text benchmark. Using VoiceBBQ, we evaluate
two SLMs - LLaMA-Omni and Qwen2-Audio - and observe architectural contrasts:
LLaMA-Omni resists acoustic bias while amplifying gender and accent bias,
whereas Qwen2-Audio substantially dampens these cues while preserving content
fidelity. VoiceBBQ thus provides a compact, drop-in testbed for jointly
diagnosing content and acoustic bias across spoken language models.

</details>


### [71] [Acoustic-based Gender Differentiation in Speech-aware Language Models](https://arxiv.org/abs/2509.21125)
*Junhyuk Choi,Jihwan Seol,Nayeon Kim,Chanhee Cho,EunBin Cho,Bugeun Kim*

Main category: cs.CL

TL;DR: 本研究提出了定量分析语音语言模型性别偏见的新数据集，并发现现有模型在部分场景下有男性倾向且未能正确利用语音性别信息，这主要根源于语音编码器。论文呼吁发展更好的性别感知和处理技术，实现语音技术中公平与语境合理性的平衡。


<details>
  <summary>Details</summary>
Motivation: 语音感知语言模型（SpeechLMs）在实现人机语音交互方面有显著突破，但在不同性别发音下存在语音性别偏见，即同样的问题，根据说话者性别可能得到不同的答案。该研究旨在系统分析和揭示这种现象，为后续改进奠定基础。

Method: 作者构建了一个包含9208条语音样本的新数据集，包括性别无关、性别刻板印象和性别相关三种类别。利用该数据集对LLaMA-Omni系列模型进行系统评估，同时对比SpeechLM模型与其对应的基础LLM（大语言模型），并探索语音编码器（如Whisper）的影响。此外，尝试了性别中和处理和允许中立选项，分析模型行为变化。

Result: 发现所有模型在性别刻板印象问题上表现出明显的男性倾向回答，而在需要因性别差异做出差异化回答的性别相关问题上，模型却表现为性别无关。此外，该模式并非因为声音中立选项或性别感知导致，即使性别中和处理后这一矛盾模式依然存在。比对分析揭示，这种现象主要源自于Whisper语音编码器生成以男性为导向的声学标记。

Conclusion: 当前SpeechLMs模型并未成功消除性别偏见，更多是在追求公平的通用原则而牺牲了与语境相符的性别合理性。未来需提出更复杂的技术，能够在保障公平公正的同时更恰当地利用语音中的性别信息。

Abstract: Speech-aware Language Models (SpeechLMs) have fundamentally transformed
human-AI interaction by enabling voice-based communication, yet they may
exhibit acoustic-based gender differentiation where identical questions lead to
different responses based on the speaker's gender. This paper propose a new
dataset that enables systematic analysis of this phenomenon, containing 9,208
speech samples across three categories: Gender-Independent,
Gender-Stereotypical, and Gender-Dependent. We further evaluated LLaMA-Omni
series and discovered a paradoxical pattern; while overall responses seems
identical regardless of gender, the pattern is far from unbiased responses.
Specifically, in Gender-Stereotypical questions, all models consistently
exhibited male-oriented responses; meanwhile, in Gender-Dependent questions
where gender differentiation would be contextually appropriate, models
exhibited responses independent to gender instead. We also confirm that this
pattern does not result from neutral options nor perceived gender of a voice.
When we allow neutral response, models tends to respond neutrally also in
Gender-Dependent questions. The paradoxical pattern yet retains when we applied
gender neutralization methods on speech. Through comparison between SpeechLMs
with corresponding backbone LLMs, we confirmed that these paradoxical patterns
primarily stem from Whisper speech encoders, which generates male-oriented
acoustic tokens. These findings reveal that current SpeechLMs may not
successfully remove gender biases though they prioritized general fairness
principles over contextual appropriateness, highlighting the need for more
sophisticated techniques to utilize gender information properly in speech
technology.

</details>


### [72] [AutoIntent: AutoML for Text Classification](https://arxiv.org/abs/2509.21138)
*Ilya Alekseev,Roman Solomatin,Darina Rustamova,Denis Kuznetsov*

Main category: cs.CL

TL;DR: AutoIntent是一款高效的自动化文本分类工具，集成了模型选择、优化及阈值调整功能，性能优越且易于部署。


<details>
  <summary>Details</summary>
Motivation: 当前自动机器学习工具存在功能局限，比如无法实现从嵌入模型选择到分类器优化与阈值调整的全流程自动化。作者希望构建一个更高效、易用的文本分类自动化工具。

Method: AutoIntent是一个模块化、类似sklearn接口的自动机器学习工具，支持嵌入模型选择、分类器优化与决策阈值调整，同时支持多标签分类和超范围检测。

Result: 在标准意图分类数据集上，AutoIntent的表现优于现有AutoML工具，并帮助用户在效果与资源消耗之间进行平衡。

Conclusion: AutoIntent提供了端到端自动化的文本分类解决方案，在性能和资源利用上优于传统方法。

Abstract: AutoIntent is an automated machine learning tool for text classification
tasks. Unlike existing solutions, AutoIntent offers end-to-end automation with
embedding model selection, classifier optimization, and decision threshold
tuning, all within a modular, sklearn-like interface. The framework is designed
to support multi-label classification and out-of-scope detection. AutoIntent
demonstrates superior performance compared to existing AutoML tools on standard
intent classification datasets and enables users to balance effectiveness and
resource consumption.

</details>


### [73] [Retrieval over Classification: Integrating Relation Semantics for Multimodal Relation Extraction](https://arxiv.org/abs/2509.21151)
*Lei Hei,Tingjing Liao,Yingxin Pei,Yiyang Qi,Jiaqi Wang,Ruiting Li,Feiliang Ren*

Main category: cs.CL

TL;DR: 作者提出ROC框架，将多模态关系抽取由分类任务改为语义检索任务，增强了结构信息和语义表达力，实验结果优于现有方法并提升了鲁棒性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态关系抽取任务常用分类方式，将关系表示为离散标签，这种方法忽略了结构约束（如实体类型和位置信息），且难以进行细粒度语义理解。

Method: 提出ROC（Retrieval Over Classification）框架，将多模态关系抽取转为由关系语义驱动的检索任务。ROC通过多模态编码器整合实体类型和位置信息，用大语言模型将关系标签扩展为自然语言描述，并采用基于语义相似度的对比学习对齐实体-关系对。

Result: 方法在MNRE与MORE两个基准数据集上取得了最新最优的性能，并具备更强的鲁棒性和可解释性。

Conclusion: ROC框架通过提升语义表达力和结构利用，有效改善了多模态关系抽取的表现，突破了传统分类方法的局限。

Abstract: Relation extraction (RE) aims to identify semantic relations between entities
in unstructured text. Although recent work extends traditional RE to multimodal
scenarios, most approaches still adopt classification-based paradigms with
fused multimodal features, representing relations as discrete labels. This
paradigm has two significant limitations: (1) it overlooks structural
constraints like entity types and positional cues, and (2) it lacks semantic
expressiveness for fine-grained relation understanding. We propose
\underline{R}etrieval \underline{O}ver \underline{C}lassification (ROC), a
novel framework that reformulates multimodal RE as a retrieval task driven by
relation semantics. ROC integrates entity type and positional information
through a multimodal encoder, expands relation labels into natural language
descriptions using a large language model, and aligns entity-relation pairs via
semantic similarity-based contrastive learning. Experiments show that our
method achieves state-of-the-art performance on the benchmark datasets MNRE and
MORE and exhibits stronger robustness and interpretability.

</details>


### [74] [Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models](https://arxiv.org/abs/2509.21155)
*Chantal Shaib,Vinith M. Suriyakumar,Levent Sagun,Byron C. Wallace,Marzyeh Ghassemi*

Main category: cs.CL

TL;DR: 本文发现LLM训练数据中语法-领域相关性会导致模型性能下降和规避安全机制的风险，需加强此类相关性检测，并提升训练语料的语法多样性。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLM）在根据指令作答时，需理解任务的语义与领域（主题），但语法结构也可能蕴含隐含信息。已有研究发现训练数据中存在大量的语法模板（如常见的词性标注序列），并且模型输出中也常出现这些模板。作者旨在系统分析语法模板、领域和语义三者关系，尤其关注模型是否学习到了“语法-领域”的伪相关性，进而影响模型对语义的理解和匹配。

Method: 作者构建了合成训练数据来量化和分析语法与领域之间的相关性对模型表现的影响，重点分析OLMo-2系列模型（1B-13B）。同时，提出了一套评测体系，用于检测训练后模型中的语法-领域相关性，并在FlanV2数据集及开放、闭源大模型（如Llama-4、GPT-4o）上进行实证分析。最后，还通过安全微调案例，阐述此类伪相关性如何影响模型拒绝不当指令的能力。

Result: 实验发现当训练数据中语法模板与领域高度相关时，模型在部分实体知识任务上的表现显著降低（平均性能0.51+/-0.06），并可在多个开源与闭源模型中检测到这种现象。此外，案例研究显示，通过语法-领域伪相关性能够绕过某些安全机制，如强制拒绝不合规指令。

Conclusion: 该工作揭示了训练语料中语法-领域相关性带来的隐患：模型会倾向于依赖语法特征而非语义进行领域判断，造成模型性能下降与安全风险。作者建议，在训练和评测中需有意识地检测此类伪相关，并确保领域内语法多样性，从而避免此类问题。

Abstract: For an LLM to correctly respond to an instruction it must understand both the
semantics and the domain (i.e., subject area) of a given task-instruction pair.
However, syntax can also convey implicit information Recent work shows that
syntactic templates--frequent sequences of Part-of-Speech (PoS) tags--are
prevalent in training data and often appear in model outputs. In this work we
characterize syntactic templates, domain, and semantics in task-instruction
pairs. We identify cases of spurious correlations between syntax and domain,
where models learn to associate a domain with syntax during training; this can
sometimes override prompt semantics. Using a synthetic training dataset, we
find that the syntactic-domain correlation can lower performance (mean 0.51 +/-
0.06) on entity knowledge tasks in OLMo-2 models (1B-13B). We introduce an
evaluation framework to detect this phenomenon in trained models, and show that
it occurs on a subset of the FlanV2 dataset in open (OLMo-2-7B;
Llama-4-Maverick), and closed (GPT-4o) models. Finally, we present a case study
on the implications for safety finetuning, showing that unintended
syntactic-domain correlations can be used to bypass refusals in OLMo-2-7B
Instruct and GPT-4o. Our findings highlight two needs: (1) to explicitly test
for syntactic-domain correlations, and (2) to ensure syntactic diversity in
training data, specifically within domains, to prevent such spurious
correlations.

</details>


### [75] [Who's Laughing Now? An Overview of Computational Humour Generation and Explanation](https://arxiv.org/abs/2509.21175)
*Tyler Loakman,William Thorne,Chenghua Lin*

Main category: cs.CL

TL;DR: 本文综述了计算幽默领域当前的发展，指出超越文字游戏的幽默生成和解释研究依然稀缺，现有大模型在幽默处理上距离人类水平仍有较大差距，并提出未来研究需要重视幽默的主观性与伦理性。


<details>
  <summary>Details</summary>
Motivation: 幽默的创造与感知是人类的基本特质，因此计算机对幽默的理解是自然语言处理领域极具挑战性的任务。幽默涉及抽象、创造性和高度依赖上下文，需要复杂推理，成为评估大型语言模型常识知识与推理能力的重要任务。

Method: 论文对计算幽默领域进行综述，重点关注幽默的生成和解释任务，并审视现有文献，分析生成和解释幽默（尤其是超越文字游戏的复杂幽默）领域的研究现状。

Result: 发现虽然理解幽默具备自然语言处理基础任务的所有特征，但除文字游戏之外，幽默生成与解释上的相关研究很少，且先进模型在此任务上仍然明显逊于人类。

Conclusion: 作者强调了计算幽默作为NLP子学科的重要性，同时讨论了未来研究方向，关注幽默的主观性和伦理性问题。

Abstract: The creation and perception of humour is a fundamental human trait,
positioning its computational understanding as one of the most challenging
tasks in natural language processing (NLP). As an abstract, creative, and
frequently context-dependent construct, humour requires extensive reasoning to
understand and create, making it a pertinent task for assessing the
common-sense knowledge and reasoning abilities of modern large language models
(LLMs). In this work, we survey the landscape of computational humour as it
pertains to the generative tasks of creation and explanation. We observe that,
despite the task of understanding humour bearing all the hallmarks of a
foundational NLP task, work on generating and explaining humour beyond puns
remains sparse, while state-of-the-art models continue to fall short of human
capabilities. We bookend our literature survey by motivating the importance of
computational humour processing as a subdiscipline of NLP and presenting an
extensive discussion of future directions for research in the area that takes
into account the subjective and ethically ambiguous nature of humour.

</details>


### [76] [GEP: A GCG-Based method for extracting personally identifiable information from chatbots built on small language models](https://arxiv.org/abs/2509.21192)
*Jieli Zhu,Vi Ngoc-Nha Tran*

Main category: cs.CL

TL;DR: 本研究发现SLM在PII泄露检测方面，传统模板攻击方法不适用，提出的GEP方法能显著提升泄露检测效率，并能应对多样表达形式的隐私信息插入；展现高性能与更强隐私检测能力，对提升SLM应用安全性有积极推动作用。


<details>
  <summary>Details</summary>
Motivation: 虽然小型语言模型（SLMs）在特定领域表现接近大型语言模型（LLMs）且训练、推理能耗更低，但SLMs在下游任务中的个人可识别信息（PII）泄露问题尚未被充分研究。作者希望了解SLM在处理个人敏感信息时的风险与现有泄露检测方法的有效性。

Method: 作者以BioGPT为基础，微调出新的医疗聊天机器人 ChatBioGPT，用 Alpaca 和 HealthCareMagic 医疗数据集训练，并通过 BERTscore 评测性能。实验对比了模板式PII攻击方法与提出的一种贪婪坐标梯度（GCG）方法（GEP），评估不同PII提取手段在SLM上的泄露检测效果。最后实验扩展到对自由表达形式的PII插入，检验GEP在复杂现实场景下的检测能力。

Result: 在BioGPT为基础的SLM下，传统模板式PII攻击方法无法有效提取PII。作者提出的GEP方法在PII泄露检测方面比模板方法高出约60倍。当数据集中的PII以多种自由表达方式插入时，GEP仍能检测出最高4.53%的泄露率。ChatBioGPT性能与ChatDoctor、ChatGPT评测结果可媲美。

Conclusion: 本文证明了基于SLM的聊天机器人在PII泄露检测中，传统方法失效，贪婪坐标梯度方法（GEP）能大幅提升检测效率且适用于复杂表达情境，对后续SLM隐私保护研究具有重要意义。

Abstract: Small language models (SLMs) become unprecedentedly appealing due to their
approximately equivalent performance compared to large language models (LLMs)
in certain fields with less energy and time consumption during training and
inference. However, the personally identifiable information (PII) leakage of
SLMs for downstream tasks has yet to be explored. In this study, we investigate
the PII leakage of the chatbot based on SLM. We first finetune a new chatbot,
i.e., ChatBioGPT based on the backbone of BioGPT using medical datasets Alpaca
and HealthCareMagic. It shows a matchable performance in BERTscore compared
with previous studies of ChatDoctor and ChatGPT. Based on this model, we prove
that the previous template-based PII attacking methods cannot effectively
extract the PII in the dataset for leakage detection under the SLM condition.
We then propose GEP, which is a greedy coordinate gradient-based (GCG) method
specifically designed for PII extraction. We conduct experimental studies of
GEP and the results show an increment of up to 60$\times$ more leakage compared
with the previous template-based methods. We further expand the capability of
GEP in the case of a more complicated and realistic situation by conducting
free-style insertion where the inserted PII in the dataset is in the form of
various syntactic expressions instead of fixed templates, and GEP is still able
to reveal a PII leakage rate of up to 4.53%.

</details>


### [77] [Eigen-1: Adaptive Multi-Agent Refinement with Monitor-Based RAG for Scientific Reasoning](https://arxiv.org/abs/2509.21193)
*Xiangru Tang,Wanghan Xu,Yujie Wang,Zijie Guo,Daniel Shao,Jiapeng Chen,Cixuan Zhang,Ziyi Wang,Lixin Zhang,Guancheng Wan,Wenlong Zhang,Lei Bai,Zhenfei Yin,Philip Torr,Hanrui Wang,Di Jin*

Main category: cs.CL

TL;DR: 本文提出结合隐式检索和迭代协作的新框架，在科学推理任务上取得显著领先，同时减少资源消耗。框架能根据任务类型灵活优化答案质量。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在科学推理任务上取得进展，但面临两个主要瓶颈：一是显式检索会打断推理过程，带来额外的“工具税”，二是多智能体系统在结果融合时常导致优秀解被平均处理，影响整体效果。

Method: 提出一个统一框架，结合隐式检索与结构化协作。底层采用Monitor-based retrieval在token级集成外部知识，尽量减少推理过程干扰。上层通过分层方案修正（HSR）和质量感知迭代推理（QAIR），让解决方案在多智能体间细致、动态优化。

Result: 在HLE Bio/Chem Gold数据集取得48.3%的准确率，比最强智能体基线高13.4个百分点，比顶级LLM高最多18.1个百分点，同时显著减少token占用和agent步骤。SuperGPQA和TRQA数据也验证了模型的跨领域鲁棒性。错误分析发现85%以上失误同时涉及推理和知识缺口，多样性分析证明不同类型任务应采用相应策略（检索偏多样性，推理重共识）。

Conclusion: 隐式增强与结构化细化有效解决了显式工具使用和均匀聚合带来的效率问题，提升了科学推理类任务的性能和资源利用效率。

Abstract: Large language models (LLMs) have recently shown strong progress on
scientific reasoning, yet two major bottlenecks remain. First, explicit
retrieval fragments reasoning, imposing a hidden "tool tax" of extra tokens and
steps. Second, multi-agent pipelines often dilute strong solutions by averaging
across all candidates. We address these challenges with a unified framework
that combines implicit retrieval and structured collaboration. At its
foundation, a Monitor-based retrieval module operates at the token level,
integrating external knowledge with minimal disruption to reasoning. On top of
this substrate, Hierarchical Solution Refinement (HSR) iteratively designates
each candidate as an anchor to be repaired by its peers, while Quality-Aware
Iterative Reasoning (QAIR) adapts refinement to solution quality. On Humanity's
Last Exam (HLE) Bio/Chem Gold, our framework achieves 48.3\% accuracy -- the
highest reported to date, surpassing the strongest agent baseline by 13.4
points and leading frontier LLMs by up to 18.1 points, while simultaneously
reducing token usage by 53.5\% and agent steps by 43.7\%. Results on SuperGPQA
and TRQA confirm robustness across domains. Error analysis shows that reasoning
failures and knowledge gaps co-occur in over 85\% of cases, while diversity
analysis reveals a clear dichotomy: retrieval tasks benefit from solution
variety, whereas reasoning tasks favor consensus. Together, these findings
demonstrate how implicit augmentation and structured refinement overcome the
inefficiencies of explicit tool use and uniform aggregation. Code is available
at: https://github.com/tangxiangru/Eigen-1.

</details>


### [78] [CLaw: Benchmarking Chinese Legal Knowledge in Large Language Models - A Fine-grained Corpus and Reasoning Analysis](https://arxiv.org/abs/2509.21208)
*Xinzhe Xu,Liang Zhao,Hongshen Xu,Chen Chen*

Main category: cs.CL

TL;DR: 本文提出了针对中国法律知识及推理的CLaw评测集。实验发现主流LLM在法律条款复现和应用上表现不佳，可靠法律推理需结合知识检索与推理能力。CLaw将推动法律领域专用LLM的研发。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）在分析法律文本和引用相关法条时可靠性不高，主要原因是其训练时未针对法律知识进行专门化，导致法律知识掌握不够深入。

Method: 提出了CLaw基准，包括两部分：一是涵盖306部中国国家法律的细粒度语料库，按条、款、项细分并含有历史修订时间节点；二是基于最高人民法院材料的254个案例推理实例，用以测试模型的法律知识应用能力。

Result: 实验显示，大多数当前主流LLM难以准确复现法律条款，导致其法律推理回应的可靠性受限。

Conclusion: 提升LLM在法律领域的可信推理，需结合更精确的知识检索能力（如SFT或RAG）与强大的通用推理能力。CLaw为法律领域专用LLM推理研究提供了重要的评测基准和关键洞察。

Abstract: Large Language Models (LLMs) are increasingly tasked with analyzing legal
texts and citing relevant statutes, yet their reliability is often compromised
by general pre-training that ingests legal texts without specialized focus,
obscuring the true depth of their legal knowledge. This paper introduces CLaw,
a novel benchmark specifically engineered to meticulously evaluate LLMs on
Chinese legal knowledge and its application in reasoning. CLaw comprises two
key components: (1) a comprehensive, fine-grained corpus of all 306 Chinese
national statutes, segmented to the subparagraph level and incorporating
precise historical revision timesteps for rigorous recall evaluation (64,849
entries), and (2) a challenging set of 254 case-based reasoning instances
derived from China Supreme Court curated materials to assess the practical
application of legal knowledge. Our empirical evaluation reveals that most
contemporary LLMs significantly struggle to faithfully reproduce legal
provisions. As accurate retrieval and citation of legal provisions form the
basis of legal reasoning, this deficiency critically undermines the reliability
of their responses. We contend that achieving trustworthy legal reasoning in
LLMs requires a robust synergy of accurate knowledge retrieval--potentially
enhanced through supervised fine-tuning (SFT) or retrieval-augmented generation
(RAG)--and strong general reasoning capabilities. This work provides an
essential benchmark and critical insights for advancing domain-specific LLM
reasoning, particularly within the complex legal sphere.

</details>


### [79] [SGMem: Sentence Graph Memory for Long-Term Conversational Agents](https://arxiv.org/abs/2509.21212)
*Yaxiong Wu,Yongyue Zhang,Sheng Liang,Yong Liu*

Main category: cs.CL

TL;DR: 提出句子图记忆（SGMem）算法，通过图结构和分块组织长期对话历史，结合原始信息和生成记忆，实验表明在长期对话问答任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的对话代理在处理大规模历史时，常采用事实抽取或摘要，但很难在不同粒度间有效组织和检索相关信息，限制了长期对话的性能。

Method: 提出SGMem（Sentence Graph Memory），将对话表示为句子级别的图并分块，以此捕捉并关联回合、轮次、会话等多个层级的上下文。方法结合原始对话和生成的记忆（如摘要、事实、洞察）为LLM提供一致且相关的上下文。

Result: 在LongMemEval与LoCoMo数据集实验中，SGMem在长期对话问答任务下准确率稳步提高，并优于同类强基线方法。

Conclusion: SGMem能更有效地管理与组织长期对话历史，增强大型语言模型在对话问答场景中的表现。

Abstract: Long-term conversational agents require effective memory management to handle
dialogue histories that exceed the context window of large language models
(LLMs). Existing methods based on fact extraction or summarization reduce
redundancy but struggle to organize and retrieve relevant information across
different granularities of dialogue and generated memory. We introduce SGMem
(Sentence Graph Memory), which represents dialogue as sentence-level graphs
within chunked units, capturing associations across turn-, round-, and
session-level contexts. By combining retrieved raw dialogue with generated
memory such as summaries, facts and insights, SGMem supplies LLMs with coherent
and relevant context for response generation. Experiments on LongMemEval and
LoCoMo show that SGMem consistently improves accuracy and outperforms strong
baselines in long-term conversational question answering.

</details>


### [80] [Query-Centric Graph Retrieval Augmented Generation](https://arxiv.org/abs/2509.21237)
*Yaxiong Wu,Jianyuan Bo,Yongyue Zhang,Sheng Liang,Yong Liu*

Main category: cs.CL

TL;DR: QCG-RAG以查询为中心，灵活控制知识粒度，通过改进的多跳检索机制显著提升了长上下文和多跳推理任务的表现。


<details>
  <summary>Details</summary>
Motivation: 当前基于图的RAG方法，在语言模型增强外部知识时，存在粒度困境：实体级图粒度过细导致高token消耗和上下文丢失，而文档级图又无法捕获细粒度的语义关系。

Method: 提出了QCG-RAG，基于查询中心的图RAG框架。利用Doc2Query等技术，以查询为核心构建具可控粒度的图，并通过自定义的多跳检索机制，实现基于生成查询的相关文本片段检索。

Result: 在LiHuaWorld和MultiHop-RAG数据集上，QCG-RAG在问答准确率上优于以往的RAG方法。

Conclusion: QCG-RAG有效解决了RAG中的粒度困境，实现了对多跳推理和长上下文的更好支持，为此类任务提供了新范式。

Abstract: Graph-based retrieval-augmented generation (RAG) enriches large language
models (LLMs) with external knowledge for long-context understanding and
multi-hop reasoning, but existing methods face a granularity dilemma:
fine-grained entity-level graphs incur high token costs and lose context, while
coarse document-level graphs fail to capture nuanced relations. We introduce
QCG-RAG, a query-centric graph RAG framework that enables query-granular
indexing and multi-hop chunk retrieval. Our query-centric approach leverages
Doc2Query and Doc2Query{-}{-} to construct query-centric graphs with
controllable granularity, improving graph quality and interpretability. A
tailored multi-hop retrieval mechanism then selects relevant chunks via the
generated queries. Experiments on LiHuaWorld and MultiHop-RAG show that QCG-RAG
consistently outperforms prior chunk-based and graph-based RAG methods in
question answering accuracy, establishing a new paradigm for multi-hop
reasoning.

</details>


### [81] [Un-Doubling Diffusion: LLM-guided Disambiguation of Homonym Duplication](https://arxiv.org/abs/2509.21262)
*Evgeny Kaskov,Elizaveta Petrova,Petr Surovtsev,Anna Kostikova,Ilya Mistiurin,Alexander Kapitanov,Alexander Nagaev*

Main category: cs.CL

TL;DR: 本文分析了同形异义词在文本到图像扩散模型中的重复生成问题，并提出了一种自动测量重复率的新方法及prompt扩展缓解方案。实验表明该方法在减少重复现象和提升模型健壮性（含英中心偏见场景）上效果显著。


<details>
  <summary>Details</summary>
Motivation: 同形异义词在自然语言中很常见，但在生成式模型（如文本到图像的扩散模型）处理时，易导致模型将一个词的多重含义同时生成，产生“同形异义重复”现象。受英中心翻译偏见影响，原语中的非同形异义词在英译后也可能变为同形异义词，模型表现进一步恶化，因此亟需有效缓解方法。

Method: 提出了一种测量同形异义重复率的方法，并利用视觉-语言模型（VLM）和人工评测对不同扩散模型进行了测试。此外，提出了通过对prompt扩展来缓解该问题的具体手段。

Result: 通过自动化与人工评测发现：所提出的prompt扩展方法不但有效减少了同形异义重复现象，也能减轻因英中心偏见带来的语义混淆，并在多个主流扩散模型上验证了方法的泛用性和有效性。同时，自动评测代码也公开。

Conclusion: 通过引入一种新的评估方法和对prompt展开的方法，能够有效缓解扩散模型在生成含有同形异义词时产生多重意义（同形异义重复）的问题，尤其是在英中心偏见背景下也有良好效果。

Abstract: Homonyms are words with identical spelling but distinct meanings, which pose
challenges for many generative models. When a homonym appears in a prompt,
diffusion models may generate multiple senses of the word simultaneously, which
is known as homonym duplication. This issue is further complicated by an
Anglocentric bias, which includes an additional translation step before the
text-to-image model pipeline. As a result, even words that are not homonymous
in the original language may become homonyms and lose their meaning after
translation into English. In this paper, we introduce a method for measuring
duplication rates and conduct evaluations of different diffusion models using
both automatic evaluation utilizing Vision-Language Models (VLM) and human
evaluation. Additionally, we investigate methods to mitigate the homonym
duplication problem through prompt expansion, demonstrating that this approach
also effectively reduces duplication related to Anglocentric bias. The code for
the automatic evaluation pipeline is publicly available.

</details>


### [82] [LLM Output Homogenization is Task Dependent](https://arxiv.org/abs/2509.21267)
*Shomik Jain,Jack Lanchantin,Maximilian Nickel,Karen Ullrich,Ashia Wilson,Jamelle Watson-Daniels*

Main category: cs.CL

TL;DR: 本文提出基于任务分类的输出同质化概念，利用任务锚定多样性指标和采样方法，在提升多样性的同时保持高质量输出，改进了大语言模型输出多样化的评估和缓解策略。


<details>
  <summary>Details</summary>
Motivation: 以往研究在讨论大语言模型输出同质化问题时，未能根据任务类别具体定义多样性，导致评估和改进都有局限性。本文试图填补这一研究空白。

Method: 提出八类任务的分类法，明确每类任务对输出同质化的概念；引入任务锚定的功能多样性指标来评估输出同质化；提出任务锚定的采样方法，在需要多样性的任务中增强输出多样性，在需要同质化的任务中保持一致性。

Result: 该方法增加了功能多样性的同时，维持了输出质量，有效改善了同质化评估与缓解过程，不同任务类别下更加合理地处理输出多样化与同质化问题。

Conclusion: 任务依赖性对于评估和优化大语言模型输出同质化至关重要。通过任务分类和任务锚定方法，可以改进输出同质化问题的理解与解决，且无需以牺牲响应质量为代价。

Abstract: A large language model can be less helpful if it exhibits output response
homogenization. But whether two responses are considered homogeneous, and
whether such homogenization is problematic, both depend on the task category.
For instance, in objective math tasks, we often expect no variation in the
final answer but anticipate variation in the problem-solving strategy. Whereas,
for creative writing tasks, we may expect variation in key narrative components
(e.g. plot, genre, setting, etc), beyond the vocabulary or embedding diversity
produced by temperature-sampling. Previous work addressing output
homogenization often fails to conceptualize diversity in a task-dependent way.
We address this gap in the literature directly by making the following
contributions. (1) We present a task taxonomy comprised of eight task
categories that each have distinct conceptualizations of output homogenization.
(2) We introduce task-anchored functional diversity to better evaluate output
homogenization. (3) We propose a task-anchored sampling technique that
increases functional diversity for task categories where homogenization is
undesired, while preserving homogenization where it is desired. (4) We
challenge the perceived existence of a diversity-quality trade-off by
increasing functional diversity while maintaining response quality. Overall, we
demonstrate how task dependence improves the evaluation and mitigation of
output homogenization.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [83] [An orderly algorithm for generation of Condorcet Domains](https://arxiv.org/abs/2509.20865)
*Bei Zhou,Klas Markström*

Main category: cs.DM

TL;DR: 提出了高效生成最大Condorcet域及其重要子类的算法，扩展了已知域的枚举，并公开了相关数据和实现，促进多数投票理论研究。


<details>
  <summary>Details</summary>
Motivation: Condorcet域是多数投票理论中的核心对象，但生成所有非同构的最大Condorcet域在理论与实际应用中都很复杂，亟需高效的方法解决此问题。

Method: 本文提出了一种高效且有序的算法，用于生成所有非同构的最大Condorcet域，并且该算法可以适配于Condorcet域的重要子类。

Result: 通过实例实现，扩展了已有相关子类Condorcet域的枚举范围，并将数据与算法公开，便于研究和应用。

Conclusion: 本研究不仅提出了生成最大Condorcet域的高效算法，还丰富了相关数据资源，为多数投票理论的进一步研究提供了方法和基础。

Abstract: Condorcet domains are fundamental objects in the theory of majority voting;
they are sets of linear orders with the property that if every voter picks a
linear order from this set, assuming that the number of voters is odd, and
alternatives are ranked according to the pairwise majority ranking, then the
result is a linear order on the set of all alternatives. In this paper we
present an efficient orderly algorithm for the generation of all non-isomorphic
maximal Condorcet domains on $n$ alternatives. The algorithm can be adapted to
generate domains from various important subclasses of Condorcet domains. We use
an example implementation to extend existing enumerations of domains from
several such subclasses and make both data and the implementation publicly
available.

</details>
