{"id": "2510.20292", "categories": ["cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2510.20292", "abs": "https://arxiv.org/abs/2510.20292", "authors": ["Vincent Moulton", "Andreas Spillner"], "title": "Labeling and folding multi-labeled trees", "comment": null, "summary": "In 1989 Erd\\H{o}s and Sz\\'ekely showed that there is a bijection between (i)\nthe set of rooted trees with $n+1$ vertices whose leaves are bijectively\nlabeled with the elements of $[\\ell]=\\{1,2,\\dots,\\ell\\}$ for some $\\ell \\leq\nn$, and (ii) the set of partitions of $[n]=\\{1,2,\\dots,n\\}$. They established\nthis via a labeling algorithm based on the anti-lexicographic ordering of\nnon-empty subsets of $[n]$ which extends the labeling of the leaves of a given\ntree to a labeling of all of the vertices of that tree. In this paper, we\ngeneralize their approach by developing a labeling algorithm for multi-labeled\ntrees, that is, rooted trees whose leaves are labeled by positive integers but\nin which distinct leaves may have the same label. In particular, we show that\ncertain orderings of the set of all finite, non-empty multisets of positive\nintegers can be used to characterize partitions of a multiset that arise from\nlabelings of multi-labeled trees. As an application, we show that the recently\nintroduced class of labelable phylogenetic networks is precisely the class of\nphylogenetic networks that are stable relative to the so-called folding process\non multi-labeled trees. We also give a bijection between the labelable\nphylogenetic networks with leaf-set $[n]$ and certain partitions of multisets.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5c06\u6811\u4e0e\u96c6\u5408\u5212\u5206\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb\u4ece\u5355\u4e00\u6807\u7b7e\u62d3\u5c55\u5230\u591a\u6807\u7b7e\u60c5\u51b5\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u7cfb\u7edf\u53d1\u751f\u7f51\u7edc\u7684\u7406\u8bba\uff0c\u63d0\u4f9b\u4e86\u65b0\u7b97\u6cd5\u548c\u7ed3\u6784\u5f52\u7c7b\u65b9\u6cd5\uff0c\u4e30\u5bcc\u4e86\u751f\u7269\u4fe1\u606f\u5b66\u4e2d\u7684\u7f51\u7edc\u5efa\u6a21\u7406\u8bba\u3002", "motivation": "Erd\u0151s\u548cSz\u00e9kely\u63d0\u51fa\u4e86\u6811\u7ed3\u6784\u4e0e\u96c6\u5408\u5212\u5206\u4e4b\u95f4\u7684\u53cc\u5c04\u5173\u7cfb\uff0c\u4f46\u539f\u6709\u7b97\u6cd5\u4ec5\u9488\u5bf9\u5355\u6807\u7b7e\u6811\u3002\u56e0\u6b64\uff0c\u52a8\u673a\u662f\u63a8\u5e7f\u8fd9\u4e00\u65b9\u6cd5\uff0c\u5904\u7406\u6811\u7684\u53f6\u5b50\u6807\u7b7e\u4e0d\u552f\u4e00\uff08\u5373\u591a\u6807\u7b7e\u6811\uff09\u7684\u66f4\u4e00\u822c\u60c5\u5f62\uff0c\u6765\u9002\u5e94\u66f4\u590d\u6742\u7684\u751f\u7269\u4fe1\u606f\u5b66\u7ed3\u6784\uff08\u5982\u7cfb\u7edf\u53d1\u751f\u7f51\u7edc\uff09\u3002", "method": "\u8be5\u6587\u53d1\u5c55\u4e86\u4e00\u79cd\u9488\u5bf9\u591a\u6807\u7b7e\u6811\u7684\u6807\u7b7e\u7b97\u6cd5\uff0c\u901a\u8fc7\u5bf9\u6240\u6709\u6709\u9650\u975e\u7a7a\u6b63\u6574\u6570\u591a\u91cd\u96c6\u8fdb\u884c\u7279\u5b9a\u6709\u5e8f\u6392\u5217\uff0c\u6765\u523b\u753b\u591a\u6807\u7b7e\u6811\u6240\u8574\u6db5\u7684\u591a\u91cd\u96c6\u7684\u5212\u5206\u3002\u540c\u65f6\uff0c\u5229\u7528\u6b64\u65b9\u6cd5\u5728\u7cfb\u7edf\u53d1\u751f\u7f51\u7edc\u7684\u7406\u8bba\u6a21\u578b\u4e2d\u5b9e\u73b0\u4e86\u7ed3\u6784\u7a33\u5b9a\u6027\u7684\u5224\u5b9a\u4e0e\u5f52\u7c7b\u3002", "result": "\u4f5c\u8005\u8bc1\u660e\u4e86\u67d0\u4e9b\u5173\u4e8e\u6b63\u6574\u6570\u591a\u91cd\u96c6\u7684\u6392\u5e8f\u53ef\u4ee5\u7528\u4e8e\u523b\u753b\u7531\u591a\u6807\u7b7e\u6811\u6240\u4ea7\u751f\u7684\u591a\u91cd\u96c6\u5212\u5206\uff0c\u8fd8\u5efa\u7acb\u4e86\u53ef\u6807\u8bb0\u7cfb\u7edf\u53d1\u751f\u7f51\u7edc\u4e0e\u591a\u91cd\u96c6\u5212\u5206\u4e4b\u95f4\u7684\u53cc\u5c04\u3002\u540c\u65f6\u8bf4\u660e\u53ef\u6807\u8bb0\u7cfb\u7edf\u53d1\u751f\u7f51\u7edc\u6b63\u662f\u591a\u6807\u7b7e\u6811\u6298\u53e0\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u7a33\u5b9a\u7684\u7f51\u7edc\u3002", "conclusion": "\u672c\u6587\u63a8\u5e7f\u4e86\u6811\u548c\u96c6\u5408\u5212\u5206\u4e4b\u95f4\u7684\u6838\u5fc3\u601d\u60f3\uff0c\u4ece\u539f\u672c\u7684\u5355\u6807\u7b7e\u6811\u62d3\u5c55\u5230\u591a\u6807\u7b7e\u6811\uff0c\u4e3a\u7cfb\u7edf\u53d1\u751f\u7f51\u7edc\u7684\u7ed3\u6784\u8ba8\u8bba\u548c\u5206\u7c7b\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u5de5\u5177\u3002"}}
{"id": "2510.20301", "categories": ["cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2510.20301", "abs": "https://arxiv.org/abs/2510.20301", "authors": ["Daniel Dadush", "Friedrich Eisenbrand", "Rom Pinchasi", "Thomas Rothvoss", "Neta Singer"], "title": "Excluding a Line Minor via Design Matrices and Column Number Bounds for the Circuit Imbalance Measure", "comment": null, "summary": "For a real matrix $A \\in \\mathbb{R}^{d \\times n}$ with non-collinear columns,\nwe show that $n \\leq O(d^4 \\kappa_A)$ where $\\kappa_A$ is the \\emph{circuit\nimbalance measure} of $A$. The circuit imbalance measure $\\kappa$ is a real\nanalogue of $\\Delta$-modularity for integer matrices, satisfying $\\kappa_A \\leq\n\\Delta_A$ for integer $A$. The circuit imbalance measure has numerous\napplications in the context of linear programming (see Ekbatani, Natura and\nV{\\'e}gh (2022) for a survey). Our result generalizes the $O(d^4 \\Delta_A)$\nbound of Averkov and Schymura (2023) for integer matrices and provides the\nfirst polynomial bound holding for all parameter ranges on real matrices.\n  To derive our result, similar to the strategy of Geelen, Nelson and Walsh\n(2021) for $\\Delta$-modular matrices, we show that real representable matroids\ninduced by $\\kappa$-bounded matrices are minor closed and exclude a rank $2$\nuniform matroid on $O(\\kappa)$ elements as a minor (also known as a line of\nlength $O(\\kappa)$).\n  As our main technical contribution, we show that any simple rank $d$ complex\nrepresentable matroid which excludes a line of length $l$ has at most $O(d^4\nl)$ elements. This complements the tight bound of $(l-3)\\binom{d}{2} + d$ for\n$l \\geq 4$, of Geelen, Nelson and Walsh which holds when the rank $d$ is\nsufficiently large compared to $l$ (at least doubly exponential in $l$).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5206\u6790\u4e86\u5b9e\u77e9\u9635\u7684\u56de\u8def\u5931\u8861\u5ea6\u6307\u6807\uff0c\u9996\u6b21\u8bc1\u660e\u6240\u6709\u53c2\u6570\u4e0b\u5176\u5217\u6570\u591a\u9879\u5f0f\u53d7\u63a7\uff0c\u4e3a\u7ed3\u6784\u6027\u62df\u9635\u7406\u8bba\u548c\u5b9e\u9645\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u5e26\u6765\u7406\u8bba\u7a81\u7834\u3002", "motivation": "\u6b64\u524d\u5bf9\u4e8e\u6574\u6570\u77e9\u9635\u7ed9\u51fa\u4e86\u5173\u4e8e\u5176n\u4e0e\u6a21\u6570\uff08\u5982\u0394-\u6a21\u6027\uff09\u4e4b\u95f4\u7684\u591a\u9879\u5f0f\u754c\uff0c\u4f46\u5bf9\u5b9e\u77e9\u9635\u7f3a\u4e4f\u7c7b\u4f3c\u7684\u666e\u9002\u6027\u7ed3\u679c\u3002\u4e3a\u4e86\u63a8\u5e7f\u5df2\u77e5\u7684\u6574\u6570\u77e9\u9635\u7ed3\u8bba\uff0c\u5e76\u586b\u8865\u5b9e\u77e9\u9635\u53c2\u6570\u8303\u56f4\u5185\u7684\u7406\u8bba\u7a7a\u767d\uff0c\u6b64\u6587\u63d0\u51fa\u4e86\u2018\u56de\u8def\u5931\u8861\u5ea6\u2019\u8fd9\u4e00\u5ea6\u91cf\uff0c\u5e76\u7814\u7a76\u5176\u4e0a\u7ebf\u6027\u89c4\u5212\u7b49\u9886\u57df\u7684\u5e94\u7528\u3002", "method": "\u501f\u9274Geelen\u7b49\u4eba\u5bf9\u0394-\u6a21\u6027\u77e9\u9635\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u672c\u6587\u5bf9\u56de\u8def\u5931\u8861\u5ea6\u6709\u754c\u7684\u5b9e\u53ef\u8868\u793a\u62df\u9635\u8fdb\u884c\u4e86\u62df\u9635\u6b21\u5c0f\u95ed\u5408\u6027\u548c\u6b21\u5c0f\u6392\u9664\u6027\u7684\u77e9\u9635\u7406\u8bba\u63a8\u5bfc\uff0c\u4ee5\u53ca\u7ed3\u6784\u6027\u5206\u6790\u3002\u8fdb\u4e00\u6b65\uff0c\u6280\u672f\u4e0a\u8bc1\u660e\u4e86\u5bf9\u590d\u53ef\u8868\u793a\u62df\u9635\uff0c\u5728\u6392\u9664\u4e86\u957f\u5ea6\u4e3al\u7684line\u540e\uff0c\u5143\u7d20\u6570\u6709O(d^4 l)\u7684\u591a\u9879\u5f0f\u4e0a\u754c\u3002", "result": "\u5f97\u5230\u5b9e\u77e9\u9635A\u7684\u5217\u6570n\u53d7\u9650\u4e8eO(d^4 \u03ba_A)\uff0c\u5176\u4e2d\u03ba_A\u4e3aA\u7684\u56de\u8def\u5931\u8861\u5ea6\u3002\u8fd9\u4e00\u7ed3\u8bba\u5c06\u6574\u6570\u77e9\u9635\u573a\u666f\u4e0bn\u53d7O(d^4 \u0394_A)\u63a7\u5236\u7684\u5b9a\u7406\u63a8\u5e7f\u5230\u4e86\u5b9e\u6570\u57df\uff0c\u9996\u6b21\u4e3a\u6240\u6709\u53c2\u6570\u8303\u56f4\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u591a\u9879\u5f0f\u4e0a\u754c\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u4e3a\u6240\u6709\u53c2\u6570\u8303\u56f4\u7684\u5b9e\u77e9\u9635A\u7ed9\u51fa\u4e86\u57fa\u4e8e\u56de\u8def\u5931\u8861\u5ea6\u03ba_A\u7684\u591a\u9879\u5f0f\u5217\u6570\u4e0a\u9650\uff0c\u63a8\u5e7f\u4e86\u6574\u6570\u77e9\u9635\u4e0b\u7684\u76f8\u5173\u7ed3\u679c\u3002\u6b64\u754c\u6df1\u5165\u89e3\u91ca\u4e86\u5b9e\u77e9\u9635\u7ed3\u6784\u4e0e\u5176\u5e94\u7528\uff08\u5982\u7ebf\u6027\u89c4\u5212\uff09\u4e2d\u7684\u9650\u5236\u6761\u4ef6\uff0c\u5bf9\u7406\u8bba\u548c\u5b9e\u8df5\u5747\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2510.20431", "categories": ["cs.DM", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20431", "abs": "https://arxiv.org/abs/2510.20431", "authors": ["David Stein", "Bjoern Andres", "Silvia Di Gregorio"], "title": "Partial Optimality in Cubic Correlation Clustering for General Graphs", "comment": "35 pages", "summary": "The higher-order correlation clustering problem for a graph $G$ and costs\nassociated with cliques of $G$ consists in finding a clustering of $G$ so as to\nminimize the sum of the costs of those cliques whose nodes all belong to the\nsame cluster. To tackle this NP-hard problem in practice, local search\nheuristics have been proposed and studied in the context of applications. Here,\nwe establish partial optimality conditions for cubic correlation clustering,\ni.e., for the special case of at most 3-cliques. We define and implement\nalgorithms for deciding these conditions and examine their effectiveness\nnumerically, on two data sets.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u6700\u591a\u4e09\u8282\u70b9\u56e2\u7684\u9ad8\u9636\u76f8\u5173\u805a\u7c7b\u95ee\u9898\uff0c\u63d0\u51fa\u5224\u65ad\u90e8\u5206\u6700\u4f18\u6027\u6761\u4ef6\u7684\u7b97\u6cd5\uff0c\u7406\u8bba\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u4e3a\u5b9e\u9645\u805a\u7c7b\u4f18\u5316\u63d0\u4f9b\u65b0\u5de5\u5177\u3002", "motivation": "\u9ad8\u9636\u76f8\u5173\u805a\u7c7b\u95ee\u9898\u662f\u4e00\u4e2a\u5728\u56fe\u7684\u57fa\u7840\u4e0a\uff0c\u5bf9\u5305\u542b\u5728\u540c\u4e00\u805a\u7c7b\u4e2d\u7684\u56e2\uff08cliques\uff09\u6700\u5c0f\u5316\u603b\u6210\u672c\u7684NP\u96be\u95ee\u9898\uff0c\u5e7f\u6cdb\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u4f46\u6c42\u89e3\u56f0\u96be\u3002", "method": "\u9488\u5bf9\u81f3\u591a3\u8282\u70b9\u7684\u56e2\uff083-cliques\uff09\u7684\u76f8\u5173\u805a\u7c7b\uff08\u5373\u7acb\u65b9\u76f8\u5173\u805a\u7c7b\uff09\uff0c\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u51b3\u5b9a\u90e8\u5206\u6700\u4f18\u6027\u6761\u4ef6\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u5c40\u90e8\u641c\u7d22\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5e76\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6570\u503c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u6240\u63d0\u51fa\u7684\u90e8\u5206\u6700\u4f18\u6027\u5224\u65ad\u7b97\u6cd5\u53ef\u4ee5\u5728\u5b9e\u9645\u6570\u636e\u4e2d\u6709\u6548\u5730\u8bc6\u522b\u90e8\u5206\u6700\u4f18\u7684\u805a\u7c7b\u5206\u5e03\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u5728\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u90e8\u5206\u6700\u4f18\u6027\u6761\u4ef6\u4e3a\u9ad8\u9636\u76f8\u5173\u805a\u7c7b\uff08\u7279\u522b\u662f\u7acb\u65b9\u76f8\u5173\u805a\u7c7b\uff09\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u969c\uff0c\u5e76\u901a\u8fc7\u7b97\u6cd5\u5b9e\u73b0\u53ca\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u805a\u7c7b\u8d28\u91cf\u548c\u6c42\u89e3\u6548\u7387\u3002"}}
{"id": "2510.20802", "categories": ["cs.DM", "cs.CC", "cs.LO", "math.CO"], "pdf": "https://arxiv.org/pdf/2510.20802", "abs": "https://arxiv.org/abs/2510.20802", "authors": ["Sandra Kiefer", "T. Devini de Mel"], "title": "A Classification of Long-Refinement Graphs for Colour Refinement", "comment": "Full version of a paper accepted for publication at SODA 2026. 44\n  pages, 16 figures, 6 tables", "summary": "The Colour Refinement algorithm is a classical procedure to detect symmetries\nin graphs, whose most prominent application is in graph-isomorphism tests. The\nalgorithm and its generalisation, the Weisfeiler-Leman algorithm, evaluate\nlocal information to compute a colouring for the vertices in an iterative\nfashion. Different final colours of two vertices certify that no isomorphism\ncan map one onto the other. The number of iterations that the algorithm takes\nto terminate is its central complexity parameter. For a long time, it was open\nwhether graphs that take the maximum theoretically possible number of Colour\nRefinement iterations actually exist. Starting from an exhaustive search on\ngraphs of low degrees, Kiefer and McKay proved the existence of infinite\nfamilies of such long-refinement graphs with degrees 2 and 3, thereby showing\nthat the trivial upper bound on the iteration number of Colour Refinement is\ntight. In this work, we provide a complete characterisation of the\nlong-refinement graphs with low (or, equivalently, high) degrees. We show that,\nwith one exception, the aforementioned families are the only long-refinement\ngraphs with maximum degree at most 3, and we fully classify the long-refinement\ngraphs with maximum degree 4. To this end, via a reverse-engineering approach,\nwe show that all low-degree long-refinement graphs can be represented as\ncompact strings, and we derive multiple structural insights from this\nsurprising fact. Since long-refinement graphs are closed under taking edge\ncomplements, this also yields a classification of long-refinement graphs with\nhigh degrees. Kiefer and McKay initiated a search for long-refinement graphs\nthat are only distinguished in the last iteration of Colour Refinement before\ntermination. We conclude it in this submission by showing that such graphs\ncannot exist.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u5206\u7c7b\u4e86\u8ba9\u989c\u8272\u7ec6\u5316\u7b97\u6cd5\u8fed\u4ee3\u6b21\u6570\u8fbe\u5230\u6700\u5927\u503c\u7684\u56fe\uff08\u957f\u7ec6\u5316\u56fe\uff09\uff0c\u5c24\u5176\u662f\u5ea6\u6570\u4e0d\u9ad8\u548c\u5f88\u9ad8\u7684\u60c5\u51b5\uff0c\u53d1\u73b0\u8fd9\u4e9b\u56fe\u6709\u7279\u5b9a\u5bb6\u65cf\u4e14\u7ed3\u6784\u5f88\u7d27\u51d1\uff0c\u89e3\u51b3\u4e86\u6700\u540e\u4e00\u6b21\u533a\u5206\u56fe\u662f\u5426\u5b58\u5728\u7684\u7591\u95ee\uff0c\u5bf9\u56fe\u7b97\u6cd5\u7406\u8bba\u6709\u8865\u5145\u548c\u5b8c\u5584\u610f\u4e49\u3002", "motivation": "\u989c\u8272\u7ec6\u5316\uff08Colour Refinement\uff09\u7b97\u6cd5\u662f\u68c0\u6d4b\u56fe\u5bf9\u79f0\u6027\u7684\u91cd\u8981\u5de5\u5177\uff0c\u5c24\u5176\u7528\u4e8e\u56fe\u540c\u6784\u6d4b\u8bd5\u3002\u957f\u671f\u4ee5\u6765\uff0c\u662f\u5426\u5b58\u5728\u4f7f\u989c\u8272\u7ec6\u5316\u8fbe\u5230\u7406\u8bba\u6700\u5927\u8fed\u4ee3\u6b21\u6570\u7684\u56fe\uff0c\u4e00\u76f4\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002\u4f5c\u8005\u7684\u5de5\u4f5c\u52a8\u673a\u662f\u7406\u89e3\u548c\u5206\u7c7b\u8fd9\u4e9b\u201c\u957f\u7ec6\u5316\u201d\u56fe\u7684\u7ed3\u6784\u3002", "method": "\u4f5c\u8005\u91c7\u7528\u9006\u5411\u5de5\u7a0b\uff08reverse-engineering\uff09\u65b9\u6cd5\uff0c\u7cfb\u7edf\u6027\u5730\u5206\u6790\u6700\u5927\u5ea6\u6570\u4e0d\u8d85\u8fc73\u548c4\u7684\u56fe\u7ed3\u6784\uff0c\u5e76\u4f7f\u7528\u7d27\u51d1\u5b57\u7b26\u4e32\u8868\u793a\u8fd9\u4e9b\u56fe\uff0c\u4ece\u800c\u83b7\u5f97\u7ed3\u6784\u6027\u6d1e\u5bdf\u3002\u540c\u65f6\u7ed3\u5408\u4ee5\u5f80\u7684\u7a77\u4e3e\u548c\u7406\u8bba\u5206\u6790\uff0c\u5b8c\u6210\u5168\u90e8\u5c0f\u5ea6\u957f\u7ec6\u5316\u56fe\u53ca\u5176\u9ad8\u5ea6\u6570\u8865\u56fe\u7684\u5206\u7c7b\u3002", "result": "\uff081\uff09\u8bc1\u660e\u9664\u4e86\u4e00\u4e2a\u4f8b\u5916\uff0c\u53ea\u6709\u5df2\u77e5\u7684\u5bb6\u65cf\u662f\u6700\u5927\u5ea6\u4e0d\u8d85\u8fc73\u7684\u201c\u957f\u7ec6\u5316\u201d\u56fe\uff1b\uff082\uff09\u5bf9\u6700\u5927\u5ea6\u4e3a4\u7684\u201c\u957f\u7ec6\u5316\u201d\u56fe\u8fdb\u884c\u4e86\u5b8c\u5168\u5206\u7c7b\uff1b\uff083\uff09\u53d1\u73b0\u8fd9\u4e9b\u56fe\u53ef\u7528\u7d27\u51d1\u5b57\u7b26\u4e32\u8868\u793a\uff0c\u4e14\u5176\u7ed3\u6784\u95ed\u5408\u4e8e\u8fb9\u8865\u8fd0\u7b97\uff1b\uff084\uff09\u8bc1\u660e\u4e0d\u5b58\u5728\u4ec5\u5728\u989c\u8272\u7ec6\u5316\u7ec8\u6b62\u524d\u6700\u540e\u4e00\u6b21\u533a\u5206\u7684\u56fe\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u6b64\u524d\u7684\u60ac\u6848\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5b8c\u6210\u4e86\u6700\u5927\u5ea6\u6570\u4e0d\u8d85\u8fc73\u548c4\u7684\u957f\u7ec6\u5316\u56fe\u7684\u5206\u7c7b\uff0c\u8fdb\u4e00\u6b65\u63ed\u793a\u4e86\u8fd9\u4e9b\u56fe\u7684\u7ed3\u6784\u7279\u5f81\uff0c\u5e76\u6f84\u6e05\u4e86\u5173\u4e8e\u6700\u540e\u4e00\u6b21\u533a\u5206\u7684\u7279\u6b8a\u56fe\u7684\u5b58\u5728\u6027\u95ee\u9898\uff0c\u4e3a\u76f8\u5173\u7b97\u6cd5\u548c\u7406\u8bba\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.19858", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.19858", "abs": "https://arxiv.org/abs/2510.19858", "authors": ["Jindi Wang", "Yidi Zhang", "Zhaoxing Li"], "title": "DeBERTa-KC: A Transformer-Based Classifier for Knowledge Construction in Online Learning Discourse", "comment": null, "summary": "This study presents DeBERTa-KC, a transformer-based model for automatic\nclassification of knowledge construction (KC) levels in online science learning\ndiscourse. Using comments collected from four popular YouTube science channels\n(2022--2024), a balanced corpus of 20,000 manually annotated samples was\ncreated across four KC categories: \\textit{nonKC}, \\textit{Share},\n\\textit{Explore}, and \\textit{Negotiate}. The proposed model extends DeBERTa-v3\nwith Focal Loss, Label Smoothing, and R-Drop regularization to address class\nimbalance and enhance generalization. A reproducible end-to-end pipeline was\nimplemented, encompassing data extraction, annotation, preprocessing, training,\nand evaluation. Across 10-fold stratified cross-validation, DeBERTa-KC achieved\na macro-F1 of $0.836 \\pm 0.008$, significantly out-performing both classical\nand transformer baselines ($p<0.01$). Per-category results indicate strong\nsensitivity to higher-order epistemic engagement, particularly in\n\\textit{Explore} and \\textit{Negotiate} discourse. These findings demonstrate\nthat large language models can effectively capture nuanced indicators of\nknowledge construction in informal digital learning environments, offering\nscalable, theory-informed approaches to discourse analysis and the development\nof automated tools for assessing epistemic engagement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDeBERTa-KC\u6a21\u578b\uff0c\u81ea\u52a8\u8bc6\u522bYouTube\u79d1\u5b66\u9891\u9053\u8bc4\u8bba\u7684\u77e5\u8bc6\u5efa\u6784\u7b49\u7ea7\uff0c\u5728\u591a\u9879\u6539\u8fdb\u4e0b\u53d6\u5f97\u4f18\u5f02\u8868\u73b0\uff0c\u6709\u6548\u63a8\u52a8\u7ebf\u4e0a\u5b66\u4e60\u8bdd\u8bed\u81ea\u52a8\u5206\u6790\u3002", "motivation": "\u81ea\u52a8\u5206\u6790\u5728\u7ebf\u79d1\u5b66\u5b66\u4e60\u8ba8\u8bba\u4e2d\u7684\u77e5\u8bc6\u5efa\u6784\u6c34\u5e73\u662f\u4e00\u9879\u6311\u6218\uff0c\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\uff0c\u4e14\u9700\u5904\u7406\u7c7b\u522b\u4e0d\u5747\u8861\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u7cbe\u786e\u4e14\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5206\u7c7b\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8etransformer\u7684DeBERTa-KC\u6a21\u578b\uff0c\u5bf9YouTube\u79d1\u5b66\u9891\u9053\u8bc4\u8bba\u8fdb\u884c\u56db\u7c7b\u77e5\u8bc6\u5efa\u6784\u81ea\u52a8\u5206\u7c7b\u3002\u5229\u7528\u5e26Focal Loss\u3001\u6807\u7b7e\u5e73\u6ed1\u548cR-Drop\u6b63\u5219\u5316\u7684DeBERTa-v3\uff0c\u5efa\u7acb\u53ef\u590d\u73b0\u7684\u7aef\u5230\u7aef\u6d41\u7a0b\uff0c\u5305\u62ec\u6570\u636e\u91c7\u96c6\u3001\u6807\u6ce8\u3001\u9884\u5904\u7406\u3001\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u3002", "result": "DeBERTa-KC\u6a21\u578b\u572810\u6298\u4ea4\u53c9\u9a8c\u8bc1\u4e2d\u53d6\u5f97\u4e860.836\u00b10.008\u7684macro-F1\u5206\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u548c\u5176\u4ed6transformer\u57fa\u7ebf\uff0c\u5c24\u5176\u5728\u9ad8\u9636\u77e5\u8bc6\u5efa\u6784\u7c7b\u522b\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u6709\u6548\u89e3\u6790\u6570\u5b57\u5316\u5b66\u4e60\u73af\u5883\u4e0b\u77e5\u8bc6\u5efa\u6784\u7684\u7ec6\u81f4\u7279\u5f81\uff0c\u4e3a\u81ea\u52a8\u5316\u8bdd\u8bed\u5206\u6790\u548c\u8bc4\u4f30\u8ba4\u77e5\u53c2\u4e0e\u5ea6\u63d0\u4f9b\u4e86\u7406\u8bba\u5f15\u5bfc\u548c\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20452", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2510.20452", "abs": "https://arxiv.org/abs/2510.20452", "authors": ["Kostia Chardonnet", "Emmanuel Hainry", "Romain P\u00e9choux", "Thomas Vinet"], "title": "Resource-Aware Hybrid Quantum Programming with General Recursion and Quantum Control", "comment": null, "summary": "This paper introduces the hybrid quantum language with general recursion\n$\\mathtt{Hyrql}$, driven towards resource-analysis. By design, $\\mathtt{Hyrql}$\ndoes not require the specification of an initial set of quantum gates and,\nhence, is well amenable towards a generic cost analysis. Indeed, languages\nusing different sets of quantum gates lead to representations of quantum\ncircuits whose complexity varies. Towards resource-analysis, a\nsemantics-preserving compilation algorithm to simply-typed term rewrite systems\nis described; allowing a generic reuse of all known techniques for analyzing\nthe complexity of term rewrite systems. We prove the versatility of this\napproach through many examples.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u6307\u5b9a\u521d\u59cb\u91cf\u5b50\u95e8\u96c6\u5408\u7684\u6df7\u5408\u91cf\u5b50\u8bed\u8a00Hyrql\uff0c\u5e76\u7ed9\u51fa\u4e86\u8bed\u4e49\u4fdd\u6301\u7684\u7f16\u8bd1\u65b9\u6cd5\uff0c\u4f7f\u5176\u53ef\u5229\u7528\u9879\u91cd\u5199\u7cfb\u7edf\u7684\u590d\u6742\u5ea6\u5206\u6790\u6280\u672f\u4ee5\u5b9e\u73b0\u7edf\u4e00\u7684\u91cf\u5b50\u7a0b\u5e8f\u8d44\u6e90\u8bc4\u4f30\uff0c\u4e14\u5728\u591a\u4e2a\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u91cf\u5b50\u8bed\u8a00\u901a\u5e38\u4f9d\u8d56\u4e8e\u7279\u5b9a\u7684\u91cf\u5b50\u95e8\u96c6\u5408\uff0c\u5bfc\u81f4\u5728\u8d44\u6e90\u548c\u590d\u6742\u5ea6\u5206\u6790\u65b9\u9762\u9762\u4e34\u9650\u5236\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u9884\u8bbe\u91cf\u5b50\u95e8\u96c6\u5408\u3001\u66f4\u9002\u7528\u4e8e\u6cdb\u5316\u8d44\u6e90\u5206\u6790\u7684\u65b0\u578b\u91cf\u5b50\u7f16\u7a0b\u8bed\u8a00\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u578b\u6df7\u5408\u91cf\u5b50\u8bed\u8a00\uff08Hyrql\uff09\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u4fdd\u6301\u8bed\u4e49\u7684\u7f16\u8bd1\u7b97\u6cd5\uff0c\u5c06\u8be5\u8bed\u8a00\u7f16\u8bd1\u4e3a\u7b80\u5355\u7c7b\u578b\u9879\u91cd\u5199\u7cfb\u7edf\u3002\u8fd9\u6837\u53ef\u4ee5\u5229\u7528\u73b0\u6709\u6240\u6709\u9879\u91cd\u5199\u7cfb\u7edf\u590d\u6742\u5ea6\u5206\u6790\u6280\u672f\u6765\u5206\u6790\u91cf\u5b50\u7a0b\u5e8f\u3002", "result": "\u901a\u8fc7\u591a\u4e2a\u793a\u4f8b\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u666e\u9002\u6027\u548c\u6709\u6548\u6027\uff0c\u65e0\u8bba\u91c7\u7528\u4e0d\u540c\u91cf\u5b50\u95e8\u96c6\u5408\uff0c\u5747\u53ef\u7edf\u4e00\u8fdb\u884c\u8d44\u6e90\u6210\u672c\u5206\u6790\u3002", "conclusion": "Hyrql\u4e3a\u91cf\u5b50\u7a0b\u5e8f\u7684\u8d44\u6e90\u5206\u6790\u63d0\u4f9b\u4e86\u7edf\u4e00\u3001\u7075\u6d3b\u7684\u5de5\u5177\uff0c\u80fd\u591f\u517c\u5bb9\u4e0d\u540c\u91cf\u5b50\u95e8\u96c6\u5408\uff0c\u6210\u529f\u8fde\u63a5\u4e86\u91cf\u5b50\u7f16\u7a0b\u4e0e\u9879\u91cd\u5199\u7cfb\u7edf\u7684\u590d\u6742\u5ea6\u5206\u6790\u9886\u57df\u3002"}}
{"id": "2510.20692", "categories": ["cs.SE", "cs.AI", "cs.FL", "D.4.6; D.2.4; I.2.2; I.2.7; F.3.1; F.4.3"], "pdf": "https://arxiv.org/pdf/2510.20692", "abs": "https://arxiv.org/abs/2510.20692", "authors": ["Adarsh Vatsa", "Bethel Hall", "William Eiers"], "title": "Exploring Large Language Models for Access Control Policy Synthesis and Summarization", "comment": "20 pages, 7 figures", "summary": "Cloud computing is ubiquitous, with a growing number of services being hosted\non the cloud every day. Typical cloud compute systems allow administrators to\nwrite policies implementing access control rules which specify how access to\nprivate data is governed. These policies must be manually written, and due to\ntheir complexity can often be error prone. Moreover, existing policies often\nimplement complex access control specifications and thus can be difficult to\nprecisely analyze in determining their behavior works exactly as intended.\nRecently, Large Language Models (LLMs) have shown great success in automated\ncode synthesis and summarization. Given this success, they could potentially be\nused for automatically generating access control policies or aid in\nunderstanding existing policies. In this paper, we explore the effectiveness of\nLLMs for access control policy synthesis and summarization. Specifically, we\nfirst investigate diverse LLMs for access control policy synthesis, finding\nthat: although LLMs can effectively generate syntactically correct policies,\nthey have permissiveness issues, generating policies equivalent to the given\nspecification 45.8% of the time for non-reasoning LLMs, and 93.7% of the time\nfor reasoning LLMs. We then investigate how LLMs can be used to analyze\npolicies by introducing a novel semantic-based request summarization approach\nwhich leverages LLMs to generate a precise characterization of the requests\nallowed by a policy. Our results show that while there are significant hurdles\nin leveraging LLMs for automated policy generation, LLMs show promising results\nwhen combined with symbolic approaches in analyzing existing policies.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76LLMs\u5e94\u7528\u4e8e\u4e91\u8ba1\u7b97\u8bbf\u95ee\u63a7\u5236\u7b56\u7565\u7684\u751f\u6210\u4e0e\u5206\u6790\u3002\u53d1\u73b0\u81ea\u52a8\u751f\u6210\u7b56\u7565\u51c6\u786e\u7387\u6709\u9650\uff0c\u4f46\u5728\u5206\u6790\u73b0\u6709\u7b56\u7565\u4e0a\u8868\u73b0\u7a81\u51fa\uff0c\u5c24\u5176\u4e0e\u4f20\u7edf\u7b26\u53f7\u65b9\u6cd5\u7ed3\u5408\u4e0b\u6548\u679c\u6700\u4f73\u3002", "motivation": "\u4e91\u8ba1\u7b97\u670d\u52a1\u666e\u53ca\uff0c\u8bbf\u95ee\u63a7\u5236\u7b56\u7565\u7ba1\u7406\u53d8\u5f97\u590d\u6742\u4e14\u6613\u51fa\u9519\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u5de5\u5177\u63d0\u5347\u7b56\u7565\u7f16\u5199\u4e0e\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "method": "\u8c03\u7814\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8bbf\u95ee\u63a7\u5236\u7b56\u7565\u5408\u6210\u548c\u6458\u8981\u751f\u6210\u4e2d\u7684\u8868\u73b0\uff0c\u5c24\u5176\u6bd4\u8f83\u63a8\u7406\u578b\u4e0e\u975e\u63a8\u7406\u578b\u6a21\u578b\u3002\u540c\u65f6\uff0c\u5f15\u5165\u57fa\u4e8e\u8bed\u4e49\u7684\u8bf7\u6c42\u6458\u8981\u65b9\u6cd5\uff0c\u901a\u8fc7LLMs\u5206\u6790\u73b0\u6709\u7b56\u7565\u3002", "result": "\u975e\u63a8\u7406LLMs\u4ec545.8%\u80fd\u751f\u6210\u7b49\u4ef7\u7b56\u7565\uff0c\u63a8\u7406LLMs\u63d0\u5347\u81f393.7%\uff0c\u4f46\u81ea\u52a8\u751f\u6210\u7b56\u7565\u4ecd\u6709\u95ee\u9898\u3002\u7ec4\u5408\u7b26\u53f7\u65b9\u6cd5\u540e\uff0cLLMs\u5728\u5206\u6790\u73b0\u6709\u7b56\u7565\u65f6\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "LLMs\u5728\u81ea\u52a8\u751f\u6210\u8bbf\u95ee\u63a7\u5236\u7b56\u7565\u65b9\u9762\u5b58\u5728\u663e\u8457\u969c\u788d\uff0c\u4f46\u5728\u5206\u6790\u548c\u7406\u89e3\u590d\u6742\u653f\u7b56\u65f6\uff0c\u4e0e\u7b26\u53f7\u65b9\u6cd5\u7ed3\u5408\u80fd\u663e\u8457\u63d0\u5347\u6548\u679c\u3002"}}
{"id": "2510.19850", "categories": ["cs.PL", "cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.19850", "abs": "https://arxiv.org/abs/2510.19850", "authors": ["Mostapha Kalami Heris"], "title": "Prompt Decorators: A Declarative and Composable Syntax for Reasoning, Formatting, and Control in LLMs", "comment": null, "summary": "Large Language Models (LLMs) are central to reasoning, writing, and\ndecision-support workflows, yet users lack consistent control over how they\nreason and express outputs. Conventional prompt engineering relies on verbose\nnatural-language instructions, limiting reproducibility, modularity, and\ninterpretability. This paper introduces Prompt Decorators, a declarative,\ncomposable syntax that governs LLM behavior through compact control tokens such\nas +++Reasoning, +++Tone(style=formal), and +++Import(topic=\"Systems\nThinking\"). Each decorator modifies a behavioral dimension, such as reasoning\nstyle, structure, or tone, without changing task content. The framework\nformalizes twenty core decorators organized into two functional families\n(Cognitive & Generative and Expressive & Systemic), each further decomposed\ninto subcategories that govern reasoning, interaction, expression, and\nsession-control. It defines a unified syntax, scoping model, and deterministic\nprocessing pipeline enabling predictable and auditable behavior composition. By\ndecoupling task intent from execution behavior, Prompt Decorators create a\nreusable and interpretable interface for prompt design. Illustrative use cases\ndemonstrate improved reasoning transparency, reduced prompt complexity, and\nstandardized model behavior across domains. The paper concludes with\nimplications for interoperability, behavioral consistency, and the development\nof declarative interfaces for scalable AI systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Prompt Decorators\uff0c\u4e00\u79cd\u7528\u7d27\u51d1\u63a7\u5236\u6807\u8bb0\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u53ef\u63a7\u6027\u7684\u58f0\u660e\u5f0f\u8bed\u6cd5\u6846\u67b6\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u63d0\u793a\u8bbe\u8ba1\u7684\u7075\u6d3b\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u5bf9AI\u7cfb\u7edf\u7684\u6807\u51c6\u5316\u548c\u6269\u5c55\u6027\u6709\u79ef\u6781\u610f\u4e49\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u63a8\u7406\u3001\u5199\u4f5c\u548c\u51b3\u7b56\u652f\u6301\u4e2d\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u7528\u6237\u96be\u4ee5\u7a33\u5b9a\u3001\u7cfb\u7edf\u5730\u63a7\u5236\u5b83\u4eec\u7684\u63a8\u7406\u4e0e\u8868\u8fbe\u65b9\u5f0f\uff0c\u4e14\u73b0\u6709\u7684\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u5de5\u7a0b\u5197\u957f\u3001\u4e0d\u6613\u590d\u7528\u3001\u89e3\u91ca\u6027\u5dee\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u58f0\u660e\u5f0f\u3001\u53ef\u7ec4\u5408\u7684\u65b0\u578b\u8bed\u6cd5\u2014\u2014Prompt Decorators\uff0c\u4f7f\u7528\u7d27\u51d1\u7684\u63a7\u5236\u6807\u8bb0\uff08\u5982+++Reasoning, +++Tone(style=formal)\u7b49\uff09\u5bf9LLM\u7684\u884c\u4e3a\u8fdb\u884c\u8c03\u63a7\u3002\u8be5\u6846\u67b6\u7cfb\u7edf\u5316\u4e8620\u79cd\u6838\u5fc3\u88c5\u9970\u5668\uff0c\u5206\u4e3a\u4e24\u5927\u529f\u80fd\u5bb6\u65cf\uff0c\u652f\u6301\u884c\u4e3a\u7ef4\u5ea6\u7684\u7ec6\u81f4\u63a7\u5236\uff0c\u5e76\u5b9a\u4e49\u4e86\u7edf\u4e00\u7684\u8bed\u6cd5\u3001\u4f5c\u7528\u57df\u6a21\u578b\u548c\u786e\u5b9a\u6027\u5904\u7406\u6d41\u7a0b\u3002", "result": "Prompt Decorators\u80fd\u5c06\u4efb\u52a1\u610f\u56fe\u4e0e\u6267\u884c\u884c\u4e3a\u5206\u79bb\uff0c\u6781\u5927\u63d0\u5347\u63d0\u793a\u8bbe\u8ba1\u7684\u53ef\u590d\u7528\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u3002\u5b9e\u9645\u5e94\u7528\u4e2d\u6848\u4f8b\u5c55\u793a\u4e86\u63a8\u7406\u66f4\u900f\u660e\u3001\u63d0\u793a\u66f4\u7cbe\u7b80\u3001\u6a21\u578b\u884c\u4e3a\u66f4\u52a0\u6807\u51c6\u5316\u7b49\u4f18\u52bf\u3002", "conclusion": "Prompt Decorators\u4e3aLLM\u63d0\u793a\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u58f0\u660e\u5f0f\u63a5\u53e3\uff0c\u6709\u52a9\u4e8e\u63d0\u5347AI\u7cfb\u7edf\u7684\u884c\u4e3a\u4e00\u81f4\u6027\u3001\u53ef\u4e92\u64cd\u4f5c\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2510.19860", "categories": ["cs.SE", "D.2.5"], "pdf": "https://arxiv.org/pdf/2510.19860", "abs": "https://arxiv.org/abs/2510.19860", "authors": ["Ketai Qiu", "Luca Di Grazia", "Leonardo Mariani", "Mauro Pezz\u00e8"], "title": "E-Test: E'er-Improving Test Suites", "comment": "Accepted at the 48th IEEE/ACM International Conference on Software\n  Engineering (ICSE 2026)", "summary": "Test suites are inherently imperfect, and testers can always enrich a suite\nwith new test cases that improve its quality and, consequently, the reliability\nof the target software system. However, finding test cases that explore\nexecution scenarios beyond the scope of an existing suite can be extremely\nchallenging and labor-intensive, particularly when managing large test suites\nover extended periods.\n  In this paper, we propose E-Test, an approach that reduces the gap between\nthe execution space explored with a test suite and the executions experienced\nafter testing by augmenting the test suite with test cases that explore\nexecution scenarios that emerge in production. E-Test (i) identifies executions\nthat have not yet been tested from large sets of scenarios, such as those\nmonitored during intensive production usage, and (ii) generates new test cases\nthat enhance the test suite. E-Test leverages Large Language Models (LLMs) to\npinpoint scenarios that the current test suite does not adequately cover, and\naugments the suite with test cases that execute these scenarios.\n  Our evaluation on a dataset of 1,975 scenarios, collected from highly-starred\nopen-source Java projects already in production and Defects4J, demonstrates\nthat E-Test retrieves not-yet-tested execution scenarios significantly better\nthan state-of-the-art approaches. While existing regression testing and field\ntesting approaches for this task achieve a maximum F1-score of 0.34, and\nvanilla LLMs achieve a maximum F1-score of 0.39, E-Test reaches 0.55. These\nresults highlight the impact of E-Test in enhancing test suites by effectively\ntargeting not-yet-tested execution scenarios and reducing manual effort\nrequired for maintaining test suites.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faE-Test\uff0c\u901a\u8fc7LLM\u81ea\u52a8\u8bc6\u522b\u5e76\u8865\u5145\u672a\u8986\u76d6\u7684\u751f\u4ea7\u6d4b\u8bd5\u573a\u666f\uff0c\u663e\u8457\u63d0\u5347\u6d4b\u8bd5\u5957\u4ef6\u8986\u76d6\u7387\u4e0e\u8d28\u91cf\uff0c\u51cf\u5c11\u4eba\u5de5\u7ef4\u62a4\u5de5\u4f5c\uff0c\u5b9e\u9a8c\u4e2d\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u5957\u4ef6\u96be\u4ee5\u8986\u76d6\u6240\u6709\u5b9e\u9645\u6267\u884c\u573a\u666f\uff0c\u7279\u522b\u662f\u751f\u4ea7\u73af\u5883\u4e2d\u51fa\u73b0\u7684\u65b0\u573a\u666f\uff0c\u8865\u5145\u8fd9\u4e9b\u7f3a\u53e3\u8d39\u65f6\u8d39\u529b\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u65b9\u6cd5\u63d0\u5347\u6d4b\u8bd5\u6709\u6548\u6027\u3002", "method": "E-Test\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u4ece\u5927\u91cf\u751f\u4ea7\u573a\u666f\u6536\u96c6\u6570\u636e\uff0c\u8bc6\u522b\u672a\u88ab\u73b0\u6709\u6d4b\u8bd5\u8986\u76d6\u7684\u6267\u884c\u573a\u666f\uff0c\u5e76\u81ea\u52a8\u751f\u6210\u65b0\u6d4b\u8bd5\u7528\u4f8b\u6765\u6269\u5c55\u6d4b\u8bd5\u5957\u4ef6\u3002", "result": "\u5728\u5305\u542b1975\u4e2a\u751f\u4ea7\u73af\u5883\u573a\u666f\u7684\u6570\u636e\u96c6\u4e0a\uff0cE-Test\u7684F1\u5206\u6570\u8fbe0.55\uff0c\u660e\u663e\u4f18\u4e8e\u5176\u5b83\u6700\u65b0\u65b9\u6cd5\uff08\u6700\u9ad8F1\u4e3a0.34\uff09\uff0c\u4ee5\u53ca\u539f\u751fLLM\u65b9\u6cd5\uff08\u6700\u9ad8F1\u4e3a0.39\uff09\uff0c\u8868\u660e\u5176\u80fd\u66f4\u597d\u8bc6\u522b\u548c\u8986\u76d6\u672a\u6d4b\u8bd5\u573a\u666f\u3002", "conclusion": "E-Test\u80fd\u6709\u6548\u63d0\u5347\u6d4b\u8bd5\u5957\u4ef6\u8d28\u91cf\uff0c\u901a\u8fc7\u589e\u52a0\u8986\u76d6\u751f\u4ea7\u73af\u5883\u65b0\u573a\u666f\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u663e\u8457\u63d0\u9ad8\u6d4b\u8bd5\u5168\u9762\u6027\uff0c\u5e76\u51cf\u5c11\u624b\u52a8\u7ef4\u62a4\u5de5\u4f5c\u91cf\u3002"}}
{"id": "2510.19866", "categories": ["cs.CL", "cs.AI", "G.1.10; G.4; I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2510.19866", "abs": "https://arxiv.org/abs/2510.19866", "authors": ["Xincheng Liu"], "title": "An Evaluation of the Pedagogical Soundness and Usability of AI-Generated Lesson Plans Across Different Models and Prompt Frameworks in High-School Physics", "comment": "20 pages, 6 tables", "summary": "This study evaluates the pedagogical soundness and usability of AI-generated\nlesson plans across five leading large language models: ChatGPT (GPT-5), Claude\nSonnet 4.5, Gemini 2.5 Flash, DeepSeek V3.2, and Grok 4. Beyond model choice,\nthree structured prompt frameworks were tested: TAG (Task, Audience, Goal),\nRACE (Role, Audience, Context, Execution), and COSTAR (Context, Objective,\nStyle, Tone, Audience, Response Format).\n  Fifteen lesson plans were generated for a single high-school physics topic,\nThe Electromagnetic Spectrum. The lesson plans were analyzed through four\nautomated computational metrics: (1) readability and linguistic complexity, (2)\nfactual accuracy and hallucination detection, (3) standards and curriculum\nalignment, and (4) cognitive demand of learning objectives.\n  Results indicate that model selection exerted the strongest influence on\nlinguistic accessibility, with DeepSeek producing the most readable teaching\nplan (FKGL = 8.64) and Claude generating the densest language (FKGL = 19.89).\n  The prompt framework structure most strongly affected the factual accuracy\nand pedagogical completeness, with the RACE framework yielding the lowest\nhallucination index and the highest incidental alignment with NGSS curriculum\nstandards. Across all models, the learning objectives in the fifteen lesson\nplans clustered at the Remember and Understand tiers of Bloom's taxonomy. There\nwere limited higher-order verbs in the learning objectives extracted.\n  Overall, the findings suggest that readability is significantly governed by\nmodel design, while instructional reliability and curricular alignment depend\nmore on the prompt framework. The most effective configuration for lesson plans\nidentified in the results was to combine a readability-optimized model with the\nRACE framework and an explicit checklist of physics concepts, curriculum\nstandards, and higher-order objectives.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4e94\u5927AI\u6a21\u578b\u548c\u4e09\u79cd\u63d0\u793a\u7ed3\u6784\u5728\u751f\u6210\u9ad8\u4e2d\u7269\u7406\u6559\u5b66\u8ba1\u5212\u4e0a\u7684\u8868\u73b0\u3002\u53d1\u73b0\u6a21\u578b\u51b3\u5b9a\u53ef\u8bfb\u6027\uff0cRACE\u63d0\u793a\u7ed3\u6784\u63d0\u5347\u51c6\u786e\u6027\u548c\u8bfe\u7a0b\u9002\u914d\u6027\uff0c\u9ad8\u9636\u5b66\u4e60\u76ee\u6807\u8f83\u5c11\u3002\u4f18\u5316\u65b9\u6848\u4e3a\u53ef\u8bfb\u6027\u5f3a\u7684\u6a21\u578b\u914d\u5408RACE\u6846\u67b6\u548c\u5b8c\u6574\u76ee\u6807\u6e05\u5355\u3002", "motivation": "AI\u751f\u6210\u6559\u5b66\u8ba1\u5212\u5728\u6559\u80b2\u9886\u57df\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u5176\u6559\u5b66\u5408\u7406\u6027\u548c\u53ef\u7528\u6027\u5c1a\u672a\u5145\u5206\u8bc4\u4f30\uff0c\u5c24\u5176\u5728\u4e0d\u540c\u5927\u6a21\u578b\u548c\u63d0\u793a\u6846\u67b6\u4e0b\u8868\u73b0\u7684\u5dee\u5f02\uff0c\u4e9f\u9700\u7cfb\u7edf\u5206\u6790\u3002", "method": "\u7814\u7a76\u5bf9\u6bd4\u4e86\u4e94\u79cd\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\uff08ChatGPT GPT-5\u3001Claude Sonnet 4.5\u3001Gemini 2.5 Flash\u3001DeepSeek V3.2\u3001Grok 4\uff09\uff0c\u5e76\u4f7f\u7528\u4e09\u79cd\u7ed3\u6784\u5316\u63d0\u793a\u6846\u67b6\uff08TAG\u3001RACE\u3001COSTAR\uff09\uff0c\u9488\u5bf9\u4e00\u4e2a\u9ad8\u4e2d\u7269\u7406\u4e3b\u9898\u201c\u7535\u78c1\u8c31\u201d\u5404\u751f\u621015\u4efd\u6559\u5b66\u8ba1\u5212\u3002\u901a\u8fc7\u53ef\u8bfb\u6027/\u8bed\u8a00\u590d\u6742\u5ea6\u3001\u4e8b\u5b9e\u51c6\u786e\u6027/\u5e7b\u89c9\u6307\u6807\u3001\u4e0e\u8bfe\u7a0b\u6807\u51c6\u4e00\u81f4\u6027\u3001\u5b66\u4e60\u76ee\u6807\u8ba4\u77e5\u8981\u6c42\u56db\u9879\u81ea\u52a8\u5316\u6307\u6807\u8fdb\u884c\u5206\u6790\u8bc4\u4f30\u3002", "result": "\u6a21\u578b\u9009\u62e9\u663e\u8457\u5f71\u54cd\u6559\u5b66\u8ba1\u5212\u7684\u8bed\u8a00\u53ef\u8bfb\u6027\uff0cDeepSeek\u6700\u6613\u8bfb\uff08FKGL=8.64\uff09\uff0cClaude\u8bed\u8a00\u6700\u590d\u6742\uff08FKGL=19.89\uff09\uff1b\u63d0\u793a\u6846\u67b6\u5bf9\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u6559\u5b66\u5b8c\u6574\u6027\u5f71\u54cd\u6700\u5927\uff0cRACE\u6846\u67b6\u5e7b\u89c9\u6307\u6570\u6700\u4f4e\uff0c\u4e14\u4e0eNGSS\u8bfe\u7a0b\u6807\u51c6\u4e00\u81f4\u6027\u6700\u9ad8\u3002\u6240\u6709\u6a21\u578b\u751f\u6210\u7684\u5b66\u4e60\u76ee\u6807\u591a\u96c6\u4e2d\u4e8e\u5e03\u9c81\u59c6\u8ba4\u77e5\u5206\u7c7b\u7684\u8bb0\u5fc6\u548c\u7406\u89e3\u5c42\u7ea7\uff0c\u9ad8\u9636\u52a8\u8bcd\u8f83\u5c11\u3002", "conclusion": "\u6a21\u578b\u7684\u8bbe\u8ba1\u51b3\u5b9a\u4e86\u6559\u5b66\u6587\u672c\u7684\u53ef\u8bfb\u6027\uff0c\u6559\u5b66\u7684\u53ef\u9760\u6027\u548c\u8bfe\u7a0b\u9002\u914d\u6027\u66f4\u591a\u4f9d\u8d56\u63d0\u793a\u6846\u67b6\u3002\u6700\u4f73\u65b9\u6848\u662f\u7ed3\u5408\u9ad8\u53ef\u8bfb\u6027\u7684\u6a21\u578b\u3001RACE\u63d0\u793a\u7ed3\u6784\u4ee5\u53ca\u660e\u786e\u6db5\u76d6\u7269\u7406\u6982\u5ff5\u3001\u8bfe\u7a0b\u6807\u51c6\u548c\u9ad8\u9636\u76ee\u6807\u7684\u6e05\u5355\u3002"}}
{"id": "2510.19853", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.19853", "abs": "https://arxiv.org/abs/2510.19853", "authors": ["Assaf Marron", "David Harel"], "title": "A Specification's Realm: Characterizing the Knowledge Required for Executing a Given Algorithm Specification", "comment": null, "summary": "An algorithm specification in natural language or pseudocode is expected to\nbe clear and explicit enough to enable mechanical execution. In this position\npaper we contribute an initial characterization of the knowledge that an\nexecuting agent, human or machine, should possess in order to be able to carry\nout the instructions of a given algorithm specification as a stand-alone\nentity, independent of any system implementation. We argue that, for that\nalgorithm specification, such prerequisite knowledge, whether unique or shared\nwith other specifications, can be summarized in a document of practical size.\nWe term this document the realm of the algorithm specification. The generation\nof such a realm is itself a systematic analytical process, significant parts of\nwhich can be automated with the help of large language models and the reuse of\nexisting documents. The algorithm-specification's realm would consist of\nspecification language syntax and semantics, domain knowledge restricted to the\nreferenced entities, inter-entity relationships, relevant underlying\ncause-and-effect rules, and detailed instructions and means for carrying out\ncertain operations. Such characterization of the realm can contribute to\nmethodological implementation of the algorithm specification in diverse systems\nand to its formalization for mechanical verification. The paper also touches\nupon the question of assessing execution faithfulness, which is distinct from\ncorrectness: in the absence of a reference interpretation of natural language\nor pseudocode specification with a given vocabulary, how can we determine if an\nobserved agent's execution indeed complies with the input specification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u201c\u7b97\u6cd5\u89c4\u8303\u9886\u57df\u201d\u6587\u6863\uff0c\u7528\u4e8e\u5f52\u7eb3\u6267\u884c\u7b97\u6cd5\u89c4\u8303\u6240\u9700\u77e5\u8bc6\u3002\u8be5\u9886\u57df\u6709\u671b\u901a\u8fc7\u81ea\u52a8\u5316\u548c\u6587\u6863\u590d\u7528\u5b9e\u73b0\uff0c\u8fdb\u800c\u63d0\u5347\u7b97\u6cd5\u89c4\u8303\u7684\u72ec\u7acb\u6027\u548c\u673a\u68b0\u5b9e\u73b0\u6709\u6548\u6027\uff0c\u4e5f\u4e3a\u8bc4\u4f30\u7b97\u6cd5\u6267\u884c\u7684\u5fe0\u5b9e\u5ea6\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002", "motivation": "\u76ee\u524d\u7b97\u6cd5\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u6216\u4f2a\u4ee3\u7801\u8fdb\u884c\u63cf\u8ff0\uff0c\u4f46\u8fd9\u4e9b\u63cf\u8ff0\u5f80\u5f80\u5bf9\u6267\u884c\u8005\u9700\u8981\u5177\u5907\u7684\u77e5\u8bc6\u5e76\u4e0d\u660e\u786e\u3002\u672c\u6587\u65e8\u5728\u660e\u786e\u5212\u5b9a\u201c\u6267\u884c\u7b97\u6cd5\u89c4\u8303\u201d\u6240\u9700\u7684\u76f8\u5173\u77e5\u8bc6\uff0c\u4fc3\u8fdb\u7b97\u6cd5\u89c4\u8303\u7684\u72ec\u7acb\u4e0e\u673a\u68b0\u5316\u6267\u884c\u3002", "method": "\u672c\u6587\u63d0\u51fa\u5b9a\u4e49\u5e76\u5f52\u7eb3\u201c\u7b97\u6cd5\u89c4\u8303\u9886\u57df\u201d\u6587\u6863\uff0c\u7cfb\u7edf\u6027\u5730\u5206\u6790\u8be5\u9886\u57df\u6240\u9700\u7684\u5404\u7c7b\u77e5\u8bc6\u3002\u5e76\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u5df2\u6709\u6587\u6863\u590d\u7528\u5728\u81ea\u52a8\u751f\u6210\u6b64\u9886\u57df\u7684\u53ef\u884c\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u7b97\u6cd5\u89c4\u8303\u9886\u57df\u7684\u521d\u6b65\u6982\u5ff5\uff0c\u5305\u62ec\uff1a\u89c4\u8303\u8bed\u8a00\u7684\u8bed\u6cd5\u548c\u8bed\u4e49\u3001\u7279\u5b9a\u9886\u57df\u77e5\u8bc6\u3001\u5b9e\u4f53\u95f4\u5173\u7cfb\u3001\u56e0\u679c\u89c4\u5219\u4e0e\u64cd\u4f5c\u6267\u884c\u8bf4\u660e\u7b49\u3002\u5f3a\u8c03\u9886\u57df\u6587\u6863\u7684\u5c0f\u578b\u5316\u548c\u53ef\u603b\u7ed3\u6027\uff0c\u4ee5\u53ca\u81ea\u52a8\u5316\u751f\u6210\u7684\u6f5c\u529b\u3002", "conclusion": "\u7cfb\u7edf\u6027\u6574\u7406\u7b97\u6cd5\u6267\u884c\u6240\u9700\u77e5\u8bc6\uff0c\u53ef\u4ee5\u63d0\u5347\u7b97\u6cd5\u89c4\u8303\u5728\u591a\u7cfb\u7edf\u5b9e\u73b0\u548c\u673a\u68b0\u9a8c\u8bc1\u4e2d\u7684\u53ef\u79fb\u690d\u6027\u3001\u6e05\u6670\u6027\u4e0e\u6267\u884c\u7684\u5fe0\u5b9e\u5ea6\u3002\u63d0\u51fa\u4e86\u9886\u57df\u6587\u6863\u65b9\u6cd5\uff0c\u5e76\u7b80\u8981\u8ba8\u8bba\u4e86\u6267\u884c\u5fe0\u5b9e\u5ea6\u7684\u8bc4\u4f30\u95ee\u9898\u3002"}}
{"id": "2510.19864", "categories": ["cs.SE", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19864", "abs": "https://arxiv.org/abs/2510.19864", "authors": ["Amila Indika", "Igor Molybog"], "title": "SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations", "comment": "14 pages, 5 figures, 4 tables", "summary": "Numerous knowledge workers utilize spreadsheets in business, accounting, and\nfinance. However, a lack of systematic documentation methods for spreadsheets\nhinders automation, collaboration, and knowledge transfer, which risks the loss\nof crucial institutional knowledge. This paper introduces Spreadsheet\nOperations Documentation (SOD), an AI task that involves generating\nhuman-readable explanations from spreadsheet operations. Many previous studies\nhave utilized Large Language Models (LLMs) for generating spreadsheet\nmanipulation code; however, translating that code into natural language for SOD\nis a less-explored area. To address this, we present a benchmark of 111\nspreadsheet manipulation code snippets, each paired with a corresponding\nnatural language summary. We evaluate five LLMs, GPT-4o, GPT-4o-mini,\nLLaMA-3.3-70B, Mixtral-8x7B, and Gemma2-9B, using BLEU, GLEU, ROUGE-L, and\nMETEOR metrics. Our findings suggest that LLMs can generate accurate\nspreadsheet documentation, making SOD a feasible prerequisite step toward\nenhancing reproducibility, maintainability, and collaborative workflows in\nspreadsheets, although there are challenges that need to be addressed.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cdAI\u65b9\u6cd5\u5c06\u7535\u5b50\u8868\u683c\u64cd\u4f5c\u4ee3\u7801\u81ea\u52a8\u8f6c\u5316\u4e3a\u81ea\u7136\u8bed\u8a00\u6587\u6863\uff0c\u5e76\u6784\u5efa\u4e86\u5bf9\u6bd4\u57fa\u51c6\u548c\u4e3b\u6d41\u6a21\u578b\u8bc4\u6d4b\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u5e94\u7528\u524d\u666f\u548c\u53ef\u884c\u6027\u3002", "motivation": "\u5de5\u4f5c\u8868\u5728\u5546\u4e1a\u3001\u4f1a\u8ba1\u548c\u91d1\u878d\u7b49\u9886\u57df\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u7684\u6587\u6863\u5316\u65b9\u6cd5\uff0c\u5bfc\u81f4\u81ea\u52a8\u5316\u3001\u534f\u4f5c\u548c\u77e5\u8bc6\u4f20\u9012\u6548\u7387\u4f4e\u4e0b\uff0c\u5b58\u5728\u5173\u952e\u77e5\u8bc6\u6d41\u5931\u7684\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86Spreadsheet Operations Documentation (SOD)\u8fd9\u4e00AI\u4efb\u52a1\uff0c\u5373\u5c06\u5de5\u4f5c\u8868\u64cd\u4f5c\u4ee3\u7801\u81ea\u52a8\u751f\u6210\u53ef\u8bfb\u6027\u5f3a\u7684\u6587\u5b57\u89e3\u91ca\u3002\u6784\u5efa\u4e86\u5305\u542b111\u4e2a\u4ee3\u7801\u53ca\u5176\u5bf9\u5e94\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u7528\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-4o\u3001LLaMA\u7b49\uff09\uff0c\u501f\u52a9BLEU\u3001GLEU\u3001ROUGE-L\u548cMETEOR\u7b49\u81ea\u52a8\u8bc4\u6d4b\u6307\u6807\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u591a\u79cd\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u8f83\u597d\uff0c\u80fd\u751f\u6210\u51c6\u786e\u7684\u7535\u5b50\u8868\u683c\u64cd\u4f5c\u6587\u6863\uff0c\u8bc1\u660eSOD\u4efb\u52a1\u7684\u53ef\u884c\u6027\u3002\u4f46\u6a21\u578b\u5728\u90e8\u5206\u7ec6\u8282\u548c\u51c6\u786e\u6027\u65b9\u9762\u4ecd\u7136\u5b58\u5728\u6311\u6218\u3002", "conclusion": "SOD\u53ef\u4f5c\u4e3a\u63d0\u5347\u7535\u5b50\u8868\u683c\u53ef\u590d\u73b0\u6027\u3001\u53ef\u7ef4\u62a4\u6027\u548c\u534f\u4f5c\u6027\u7684\u524d\u7f6e\u6b65\u9aa4\uff0c\u6709\u52a9\u4e8e\u9632\u6b62\u77e5\u8bc6\u6d41\u5931\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u5e94\u5bf9\u73b0\u6709\u6311\u6218\u3002"}}
{"id": "2510.19871", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.19871", "abs": "https://arxiv.org/abs/2510.19871", "authors": ["Yatai Ji", "Teng Wang", "Yuying Ge", "Zhiheng Liu", "Sidi Yang", "Ying Shan", "Ping Luo"], "title": "From Denoising to Refining: A Corrective Framework for Vision-Language Diffusion Model", "comment": null, "summary": "Discrete diffusion models have emerged as a promising direction for\nvision-language tasks, offering bidirectional context modeling and theoretical\nparallelization. However, their practical application is severely hindered by a\ntrain-inference discrepancy, which leads to catastrophic error cascades:\ninitial token errors during parallel decoding pollute the generation context,\ntriggering a chain reaction of compounding errors and leading to syntactic\nerrors and semantic hallucinations. To address this fundamental challenge, we\nreframe the generation process from passive denoising to active refining. We\nintroduce ReDiff, a refining-enhanced diffusion framework that teaches the\nmodel to identify and correct its own errors. Our approach features a two-stage\ntraining process: first, we instill a foundational revision capability by\ntraining the model to revise synthetic errors; second, we implement a novel\nonline self-correction loop where the model is explicitly trained to revise its\nown flawed drafts by learning from an expert's corrections. This mistake-driven\nlearning endows the model with the crucial ability to revisit and refine its\nalready generated output, effectively breaking the error cascade. Extensive\nexperiments demonstrate that ReDiff significantly improves the coherence and\nfactual accuracy of generated content, enabling stable and efficient parallel\ngeneration far superior to traditional denoising methods. Our codes and models\nare available at https://rediff-hku.github.io/.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faReDiff\uff0c\u901a\u8fc7\u5f3a\u5316\u6a21\u578b\u4e3b\u52a8\u4fee\u6b63\u80fd\u529b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u79bb\u6563\u6269\u6563\u6a21\u578b\u5728\u5e76\u884c\u751f\u6210\u4e2d\u7684\u9519\u8bef\u7ea7\u8054\u95ee\u9898\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5176\u751f\u6210\u7684\u5185\u5bb9\u5728\u8fde\u8d2f\u6027\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u79bb\u6563\u6269\u6563\u6a21\u578b\u5728\u89c6\u89c9-\u8bed\u8a00\u4efb\u52a1\u4e2d\u867d\u7136\u6709\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u8bad\u7ec3\u548c\u63a8\u7406\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u521d\u59cb\u751f\u6210\u7684\u9519\u8bef\u4f1a\u5f15\u53d1\u8fde\u9501\u7684\u9519\u8bef\u7ea7\u8054\uff0c\u5f71\u54cd\u751f\u6210\u5185\u5bb9\u7684\u8bed\u6cd5\u548c\u8bed\u4e49\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u4e86ReDiff\u6846\u67b6\uff0c\u5c06\u751f\u6210\u8fc7\u7a0b\u7531\u88ab\u52a8\u53bb\u566a\u8f6c\u53d8\u4e3a\u4e3b\u52a8\u4fee\u6b63\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u5408\u6210\u9519\u8bef\u8bad\u7ec3\u6a21\u578b\u57fa\u672c\u7684\u4fee\u6b63\u80fd\u529b\uff0c\u7b2c\u4e8c\u9636\u6bb5\u5f15\u5165\u81ea\u6211\u4fee\u6b63\u73af\uff0c\u5229\u7528\u4e13\u5bb6\u7ea0\u6b63\u6570\u636e\u8bad\u7ec3\u6a21\u578b\u4e0d\u65ad\u81ea\u6211\u4fee\u6b63\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cReDiff\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u5185\u5bb9\u7684\u8fde\u8d2f\u6027\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u4f7f\u5e73\u884c\u751f\u6210\u8fc7\u7a0b\u66f4\u52a0\u7a33\u5b9a\u9ad8\u6548\uff0c\u4f18\u4e8e\u4f20\u7edf\u53bb\u566a\u65b9\u6cd5\u3002", "conclusion": "ReDiff\u901a\u8fc7\u4e3b\u52a8\u4fee\u6b63\u751f\u6210\u9519\u8bef\uff0c\u6709\u6548\u6253\u7834\u9519\u8bef\u7ea7\u8054\uff0c\u663e\u8457\u6539\u5584\u4e86\u79bb\u6563\u6269\u6563\u6a21\u578b\u5728\u89c6\u89c9-\u8bed\u8a00\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2510.20018", "categories": ["cs.PL", "68N18 (Primary), 03B70 (Secondary)", "F.3.3; D.3.1"], "pdf": "https://arxiv.org/pdf/2510.20018", "abs": "https://arxiv.org/abs/2510.20018", "authors": ["Ryan Kavanagh", "Chuta Sano", "Brigitte Pientka"], "title": "Deconstructed Proto-Quipper: A Rational Reconstruction", "comment": "Submitted to the 35th European Symposium on Programming (ESOP 2026)", "summary": "The Proto-Quipper family of programming languages aims to provide a formal\nfoundation for the Quipper quantum programming language. Unfortunately,\nProto-Quipper languages have complex operational semantics: they are inherently\neffectful, and they rely on set-theoretic operations and fresh name generation\nto manipulate quantum circuits. This makes them difficult to reason about using\nstandard programming language techniques and, ultimately, to mechanize. We\nintroduce Proto-Quipper-A, a rational reconstruction of Proto-Quipper languages\nfor static circuit generation. It uses a linear $\\lambda$-calculus to describe\nquantum circuits with normal forms that closely correspond to box-and-wire\ncircuit diagrams. Adjoint-logical foundations integrate this circuit language\nwith a linear/non-linear functional language and let us reconstruct\nProto-Quipper's circuit programming abstractions using more primitive\nadjoint-logical operations. Proto-Quipper-A enjoys a simple call-by-value\nreduction semantics, and to illustrate its tractability as a foundation for\nProto-Quipper languages, we show that it is normalizing. We show how to use\nstandard logical relations to prove normalization of linear and substructural\nsystems, thereby avoiding the inherent complexity of existing linear logical\nrelations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faProto-Quipper-A\u8bed\u8a00\uff0c\u4ee5\u7ebf\u6027\u03bb-\u6f14\u7b97\u4e3a\u57fa\u7840\u7b80\u5316\u5e76\u89c4\u8303\u5316\u91cf\u5b50\u7535\u8def\u751f\u6210\uff0c\u89e3\u51b3\u4e86Proto-Quipper\u539f\u6709\u8bed\u4e49\u590d\u6742\u6027\u95ee\u9898\uff0c\u5e76\u8bc1\u660e\u8be5\u8bed\u8a00\u662f\u53ef\u5f52\u4e00\u5316\u7684\u3002", "motivation": "Proto-Quipper\u8bed\u8a00\u7684\u64cd\u4f5c\u8bed\u4e49\u590d\u6742\u4e14\u96be\u4ee5\u673a\u68b0\u5316\uff0c\u57fa\u4e8e\u7535\u8def\u7684\u6784\u9020\u6d89\u53ca\u65b0\u540d\u5b57\u751f\u6210\u548c\u96c6\u5408\u8bba\u64cd\u4f5c\uff0c\u96be\u4ee5\u7528\u4f20\u7edf\u6280\u672f\u5f62\u5f0f\u5316\u548c\u63a8\u7406\u3002\u8be5\u7814\u7a76\u65e8\u5728\u63d0\u4f9b\u66f4\u7b80\u6d01\u3001\u4fbf\u4e8e\u63a8\u7406\u548c\u673a\u68b0\u5316\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u63d0\u51faProto-Quipper-A\uff0c\u4e00\u79cd\u57fa\u4e8e\u7ebf\u6027\u03bb-\u6f14\u7b97\u7684\u7535\u8def\u751f\u6210\u8bed\u8a00\uff0c\u5e76\u901a\u8fc7\u6807\u51c6\u903b\u8f91\u5173\u7cfb\u65b9\u6cd5\u8bc1\u660e\u5176\u5f52\u4e00\u5316\uff0c\u907f\u514d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u590d\u6742\u6027\u3002", "result": "Proto-Quipper-A\u62e5\u6709\u7b80\u5355\u7684\u5f52\u7ea6\u8bed\u4e49\u4e14\u53ef\u4ee5\u5f52\u4e00\u5316\uff0c\u5e76\u4e14\u80fd\u7528\u6807\u51c6\u903b\u8f91\u5173\u7cfb\u65b9\u6cd5\u5904\u7406\u7ebf\u6027\u548c\u5b50\u7ed3\u6784\u7cfb\u7edf\u7684\u5f52\u4e00\u5316\u8bc1\u660e\u3002", "conclusion": "Proto-Quipper-A\u8bed\u8a00\u901a\u8fc7\u7ebf\u6027\u03bb-\u6f14\u7b97\u548c\u4f34\u968f\u903b\u8f91\u57fa\u7840\uff0c\u6210\u529f\u89c4\u8303\u5316\u4e86Proto-Quipper\u8bed\u8a00\u7684\u9759\u6001\u7535\u8def\u751f\u6210\uff0c\u5e76\u8bc1\u660e\u5176\u5f52\u4e00\u5316\u6027\u8d28\u3002"}}
{"id": "2510.19868", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.19868", "abs": "https://arxiv.org/abs/2510.19868", "authors": ["Qian Xiong", "Bo Yang", "Weisong Sun", "Yiran Zhang", "Tianlin Li", "Yang Liu", "Zhi Jin"], "title": "Knowledge-Guided Multi-Agent Framework for Application-Level Software Code Generation", "comment": null, "summary": "Automated code generation driven by Large Lan- guage Models (LLMs) has\nenhanced development efficiency, yet generating complex application-level\nsoftware code remains challenging. Multi-agent frameworks show potential, but\nexisting methods perform inadequately in large-scale application-level software\ncode generation, failing to ensure reasonable orga- nizational structures of\nproject code and making it difficult to maintain the code generation process.\nTo address this, this paper envisions a Knowledge-Guided Application-Level Code\nGeneration framework named KGACG, which aims to trans- form software\nrequirements specification and architectural design document into executable\ncode through a collaborative closed- loop of the Code Organization & Planning\nAgent (COPA), Coding Agent (CA), and Testing Agent (TA), combined with a\nfeedback mechanism. We demonstrate the collaborative process of the agents in\nKGACG in a Java Tank Battle game case study while facing challenges. KGACG is\ndedicated to advancing the automation of application-level software\ndevelopment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u77e5\u8bc6\u5f15\u5bfc\u7684\u591a\u667a\u80fd\u4f53\u4ee3\u7801\u751f\u6210\u6846\u67b6KGACG\uff0c\u901a\u8fc7\u5206\u5de5\u534f\u4f5c\u548c\u53cd\u9988\u673a\u5236\u5c06\u9700\u6c42\u4e0e\u8bbe\u8ba1\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u5e76\u4ee5\u5766\u514b\u5927\u6218\u6848\u4f8b\u8fdb\u884c\u9a8c\u8bc1\uff0c\u663e\u793a\u51fa\u63d0\u5347\u5e94\u7528\u7ea7\u4ee3\u7801\u751f\u6210\u81ea\u52a8\u5316\u7684\u6f5c\u529b\u3002", "motivation": "\u5f53\u524d\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u81ea\u52a8\u5316\u4ee3\u7801\u751f\u6210\uff0c\u5c3d\u7ba1\u63d0\u9ad8\u4e86\u5f00\u53d1\u6548\u7387\uff0c\u4f46\u5728\u751f\u6210\u590d\u6742\u7684\u3001\u5e94\u7528\u7ea7\u522b\u7684\u8f6f\u4ef6\u4ee3\u7801\u65f6\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u9879\u76ee\u4ee3\u7801\u7ec4\u7ec7\u7ed3\u6784\u5408\u7406\u6027\u548c\u4ee3\u7801\u751f\u6210\u8fc7\u7a0b\u53ef\u7ef4\u62a4\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002\u591a\u667a\u80fd\u4f53\u6846\u67b6\u6709\u6240\u52a9\u76ca\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u5e94\u7528\u7ea7\u4ee3\u7801\u751f\u6210\u4e0a\u8868\u73b0\u4ecd\u4e0d\u7406\u60f3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u77e5\u8bc6\u5f15\u5bfc\u7684\u5e94\u7528\u7ea7\u4ee3\u7801\u751f\u6210\u6846\u67b6\uff08KGACG\uff09\uff0c\u901a\u8fc7Code Organization & Planning Agent\uff08COPA\uff09\u3001Coding Agent\uff08CA\uff09\u548cTesting Agent\uff08TA\uff09\u4e09\u7c7b\u667a\u80fd\u4f53\u7684\u534f\u4f5c\u5faa\u73af\uff0c\u5e76\u7ed3\u5408\u53cd\u9988\u673a\u5236\uff0c\u5c06\u9700\u6c42\u89c4\u8303\u548c\u67b6\u6784\u8bbe\u8ba1\u6587\u6863\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\u3002", "result": "\u5728Java\u5766\u514b\u5927\u6218\u6e38\u620f\u6848\u4f8b\u4e2d\u5c55\u793a\u4e86KGACG\u5404\u667a\u80fd\u4f53\u7684\u534f\u540c\u8fc7\u7a0b\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u53ef\u884c\u6027\u548c\u5728\u81ea\u52a8\u5316\u5e94\u7528\u7ea7\u8f6f\u4ef6\u5f00\u53d1\u4e0a\u7684\u6f5c\u529b\uff0c\u5c3d\u7ba1\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u4ecd\u9762\u4e34\u4e00\u5b9a\u6311\u6218\u3002", "conclusion": "KGACG\u6846\u67b6\u53ef\u63d0\u9ad8\u5e94\u7528\u7ea7\u8f6f\u4ef6\u4ee3\u7801\u81ea\u52a8\u5316\u751f\u6210\u7684\u8d28\u91cf\u548c\u6548\u7387\uff0c\u5c24\u5176\u6539\u5584\u4ee3\u7801\u7ec4\u7ec7\u7ed3\u6784\u548c\u7ef4\u62a4\u8fc7\u7a0b\uff0c\u4e3a\u8f6f\u4ef6\u5f00\u53d1\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2510.19875", "categories": ["cs.CL", "cs.AI", "68T40", "I.2.11"], "pdf": "https://arxiv.org/pdf/2510.19875", "abs": "https://arxiv.org/abs/2510.19875", "authors": ["J Rosser", "Jos\u00e9 Luis Redondo Garc\u00eda", "Gustavo Penha", "Konstantina Palla", "Hugues Bouchard"], "title": "Stream: Scaling up Mechanistic Interpretability to Long Context in LLMs via Sparse Attention", "comment": null, "summary": "As Large Language Models (LLMs) scale to million-token contexts, traditional\nMechanistic Interpretability techniques for analyzing attention scale\nquadratically with context length, demanding terabytes of memory beyond 100,000\ntokens. We introduce Sparse Tracing, a novel technique that leverages dynamic\nsparse attention to efficiently analyze long context attention patterns. We\npresent Stream, a compilable hierarchical pruning algorithm that estimates\nper-head sparse attention masks in near-linear time $O(T \\log T)$ and linear\nspace $O(T)$, enabling one-pass interpretability at scale. Stream performs a\nbinary-search-style refinement to retain only the top-$k$ key blocks per query\nwhile preserving the model's next-token behavior. We apply Stream to long\nchain-of-thought reasoning traces and identify thought anchors while pruning\n97-99\\% of token interactions. On the RULER benchmark, Stream preserves\ncritical retrieval paths while discarding 90-96\\% of interactions and exposes\nlayer-wise routes from the needle to output. Our method offers a practical\ndrop-in tool for analyzing attention patterns and tracing information flow\nwithout terabytes of caches. By making long context interpretability feasible\non consumer GPUs, Sparse Tracing helps democratize chain-of-thought monitoring.\nCode is available at https://anonymous.4open.science/r/stream-03B8/.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa Sparse Tracing \u548c Stream \u7b97\u6cd5\uff0c\u5b9e\u73b0\u5bf9\u767e\u4e07 Token \u957f\u4e0a\u4e0b\u6587\u7684\u9ad8\u6548 attention \u89e3\u6790\uff0c\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u4e0e\u5185\u5b58\u9700\u6c42\uff0c\u4fdd\u7559\u63a8\u7406\u5173\u952e\u8def\u5f84\uff0c\u4f7f\u957f\u8f93\u5165\u4e0b\u7684\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u63a8\u7406\u8ffd\u8e2a\u66f4\u4e3a\u53ef\u884c\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u663e\u8457\u63d0\u5347\uff0c\u73b0\u6709\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5728\u957f\u4e0a\u4e0b\u6587\u4e0b\u8ba1\u7b97\u548c\u5185\u5b58\u6d88\u8017\u8fc5\u901f\u589e\u957f\uff0c\u96be\u4ee5\u5b9e\u9645\u5e94\u7528\uff0c\u4e9f\u9700\u9ad8\u6548\u7684 attention \u89e3\u6790\u6280\u672f\u4ee5\u63a8\u52a8\u94fe\u5f0f\u63a8\u7406\u7b49\u4efb\u52a1\u7684\u53ef\u89e3\u91ca\u6027\u4e0e\u76d1\u63a7\u3002", "method": "\u63d0\u51fa Sparse Tracing \u6280\u672f\uff0c\u901a\u8fc7\u52a8\u6001\u7a00\u758f attention\uff0c\u6709\u6548\u5206\u6790\u957f\u4e0a\u4e0b\u6587\uff1b\u5e76\u5b9e\u73b0\u4e86 Stream\uff08\u4e00\u79cd\u53ef\u7f16\u8bd1\u7684\u5206\u5c42\u526a\u679d\u7b97\u6cd5\uff09\uff0c\u91c7\u7528\u7c7b\u4f3c\u4e8c\u5206\u67e5\u627e\u7684\u65b9\u6cd5\u4f30\u7b97\u6bcf\u4e2a attention head \u7684\u7a00\u758f Mask\uff0c\u4ec5\u4fdd\u7559\u6bcf\u4e2a\u67e5\u8be2\u7684 top-k \u5173\u952e\u5757\uff0c\u7a7a\u95f4\u548c\u65f6\u95f4\u590d\u6742\u5ea6\u5206\u522b\u4e3a O(T) \u548c O(T log T)\u3002", "result": "\u5728\u94fe\u5f0f\u601d\u8003\u8ffd\u8e2a\u548c RULER \u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSparse Tracing \u53ef\u6709\u6548\u8bc6\u522b\u5173\u952e\u601d\u8003\u951a\u70b9\uff0c\u526a\u9664 97-99% \u7684 Token \u4ea4\u4e92\uff0c\u4e14\u80fd\u591f\u4fdd\u7559\u5173\u952e\u68c0\u7d22\u8def\u5f84\u4e0e\u6a21\u578b\u884c\u4e3a\u7279\u5f81\uff0c\u5b9e\u73b0\u5927\u5e45\u964d\u8017\u5e76\u6269\u5c55\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "Sparse Tracing \u6280\u672f\u901a\u8fc7\u9ad8\u6548\u7a00\u758f attention \u5206\u6790\uff0c\u4f7f\u5f97\u767e\u4e07\u7ea7 Token \u7684\u957f\u4e0a\u4e0b\u6587\u53ef\u89e3\u91ca\u6027\u6210\u4e3a\u53ef\u80fd\uff0c\u5bf9\u94fe\u5f0f\u63a8\u7406\u8f68\u8ff9\u8fdb\u884c\u7ec6\u7c92\u5ea6\u8ffd\u8e2a\u4e0e\u5206\u6790\uff0c\u540c\u65f6\u6781\u5927\u51cf\u5c11\u4e86\u5185\u5b58\u548c\u8ba1\u7b97\u6d88\u8017\u3002"}}
{"id": "2510.20532", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.20532", "abs": "https://arxiv.org/abs/2510.20532", "authors": ["Patrycja Balik", "Szymon J\u0119dras", "Piotr Polesiuk"], "title": "Deciding not to Decide: Sound and Complete Effect Inference in the Presence of Higher-Rank Polymorphism", "comment": null, "summary": "Type-and-effect systems help the programmer to organize data and\ncomputational effects in a program. While for traditional type systems\nexpressive variants with sophisticated inference algorithms have been developed\nand widely used in programming languages, type-and-effect systems did not yet\ngain widespread adoption. One reason for this is that type-and-effect systems\nare more complex and the existing inference algorithms make compromises between\nexpressiveness, intuitiveness, and decidability. In this work, we present an\neffect inference algorithm for a type-and-effect system with subtyping,\nexpressive higher-rank polymorphism, and intuitive set-like semantics of\neffects. In order to deal with scoping issues of higher-rank polymorphism, we\ndelay solving of effect constraints by transforming them into formulae of\npropositional logic. We prove soundness and completeness of our algorithm with\nrespect to a declarative type-and-effect system. All the presented results have\nbeen formalized in the Rocq proof assistant, and the algorithm has been\nsuccessfully implemented in a realistic programming language.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u547d\u9898\u903b\u8f91\u516c\u5f0f\u5904\u7406\u6548\u5e94\u7ea6\u675f\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5177\u6709\u9ad8\u9636\u591a\u6001\u548c\u5b50\u7c7b\u578b\u652f\u6301\u7684\u7c7b\u578b\u4e0e\u6548\u5e94\u63a8\u65ad\u7b97\u6cd5\uff0c\u5e76\u7ecf\u8fc7\u7406\u8bba\u9a8c\u8bc1\u548c\u5b9e\u9645\u5b9e\u73b0\uff0c\u63a8\u52a8\u7c7b\u578b\u4e0e\u6548\u5e94\u7cfb\u7edf\u66f4\u6613\u4e8e\u5e94\u7528\u3002", "motivation": "\u7c7b\u578b\u4e0e\u6548\u5e94\u7cfb\u7edf\u80fd\u5e2e\u52a9\u7a0b\u5e8f\u5458\u7ec4\u7ec7\u7a0b\u5e8f\u4e2d\u7684\u6570\u636e\u548c\u8ba1\u7b97\u6548\u5e94\uff0c\u4f46\u76f8\u5173\u7cfb\u7edf\u7531\u4e8e\u590d\u6742\u6027\u9ad8\u3001\u63a8\u65ad\u7b97\u6cd5\u5728\u8868\u8fbe\u529b\u3001\u6613\u7528\u6027\u548c\u53ef\u5224\u5b9a\u6027\u95f4\u7684\u6743\u8861\uff0c\u5bfc\u81f4\u5e76\u672a\u5e7f\u6cdb\u5e94\u7528\u3002\u4e3a\u6b64\uff0c\u9700\u8981\u63a8\u52a8\u66f4\u5b9e\u7528\u4e14\u9ad8\u6548\u7684\u7c7b\u578b\u4e0e\u6548\u5e94\u63a8\u65ad\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u5177\u6709\u5b50\u7c7b\u578b\u3001\u9ad8\u9636\u591a\u6001\u4ee5\u53ca\u96c6\u5408\u8bed\u4e49\u6548\u5e94\u7684\u7c7b\u578b\u4e0e\u6548\u5e94\u7cfb\u7edf\u7684\u6548\u5e94\u63a8\u65ad\u7b97\u6cd5\u3002\u4e3a\u89e3\u51b3\u9ad8\u9636\u591a\u6001\u7684\u4f5c\u7528\u57df\u95ee\u9898\uff0c\u5c06\u6548\u5e94\u7ea6\u675f\u5ef6\u8fdf\u6c42\u89e3\uff0c\u5e76\u8f6c\u6362\u4e3a\u547d\u9898\u903b\u8f91\u516c\u5f0f\u3002\u7b97\u6cd5\u7684\u6b63\u786e\u6027\u5728Rocq\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u5f62\u5f0f\u5316\u8bc1\u660e\uff0c\u5e76\u5b9e\u73b0\u4e8e\u771f\u5b9e\u7f16\u7a0b\u8bed\u8a00\u4e2d\u3002", "result": "\u8bc1\u660e\u4e86\u7b97\u6cd5\u5728\u58f0\u79f0\u7684\u7c7b\u578b\u4e0e\u6548\u5e94\u7cfb\u7edf\u4e0b\u7684\u6b63\u786e\u6027\u4e0e\u5b8c\u5907\u6027\u3002\u7b97\u6cd5\u5df2\u88ab\u5b9e\u9645\u5b9e\u73b0\u5e76\u5e94\u7528\u4e8e\u73b0\u5b9e\u7f16\u7a0b\u8bed\u8a00\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u9ad8\u8868\u8fbe\u529b\u3001\u5f62\u5f0f\u5316\u4fdd\u8bc1\u7684\u7c7b\u578b\u4e0e\u6548\u5e94\u63a8\u65ad\u7b97\u6cd5\uff0c\u80fd\u591f\u4e3a\u5177\u6709\u5b50\u7c7b\u578b\u548c\u9ad8\u9636\u591a\u6001\u7684\u8bed\u8a00\u63d0\u4f9b\u5b9e\u7528\u4e14\u53ef\u9760\u7684\u7c7b\u578b\u4e0e\u6548\u5e94\u5206\u6790\u3002\u5176\u7406\u8bba\u548c\u5b9e\u73b0\u90fd\u8fbe\u6210\u4e86\u9884\u8bbe\u76ee\u6807\uff0c\u5e76\u4e3a\u7c7b\u578b\u4e0e\u6548\u5e94\u7cfb\u7edf\u66f4\u5e7f\u6cdb\u5e94\u7528\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.19898", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.19898", "abs": "https://arxiv.org/abs/2510.19898", "authors": ["Atharv Sonwane", "Isadora White", "Hyunji Lee", "Matheus Pereira", "Lucas Caccia", "Minseon Kim", "Zhengyan Shi", "Chinmay Singh", "Alessandro Sordoni", "Marc-Alexandre C\u00f4t\u00e9", "Xingdi Yuan"], "title": "BugPilot: Complex Bug Generation for Efficient Learning of SWE Skills", "comment": null, "summary": "High quality bugs are key to training the next generation of language model\nbased software engineering (SWE) agents. We introduce a novel method for\nsynthetic generation of difficult and diverse bugs. Our method instructs SWE\nAgents to introduce a feature into the codebase whereby they may\nunintentionally break tests, resulting in bugs. Prior approaches often induce\nan out-of-distribution effect by generating bugs intentionally (e.g. by\nintroducing local perturbation to existing code), which does not reflect\nrealistic development processes. We perform qualitative analysis to demonstrate\nthat our approach for generating bugs more closely reflects the patterns found\nin human-authored edits. Through extensive experiments, we demonstrate that our\nbugs provide more efficient training data for supervised fine-tuning,\noutperforming other bug datasets by 2% with half the training data (1.2k vs. 3k\nbugs). We train on our newly generated bugs in addition to existing bug\ndatasets to get FrogBoss a state-of-the-art 32B parameter model on SWE-bench\nVerified with a pass@1 of 54.6% and FrogMini a state-of-the-art 14B model on\nSWE-bench Verified with a pass@1 of 45.3% on SWE-bench Verified averaged over\nthree seeds.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u80fd\u4ea7\u751f\u66f4\u771f\u5b9e\u3001\u591a\u6837\u7684\u9ad8\u8d28\u91cfbug\u7684\u65b0\u65b9\u6cd5\uff0c\u5927\u5e45\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u7684\u8bad\u7ec3\u6709\u6548\u6027\u3002\u65b0bug\u96c6\u7528\u66f4\u5c11\u6570\u636e\u8ba9\u6a21\u578b\u8fbe\u5230\u66f4\u4f18\u6027\u80fd\uff0c\u5237\u65b0\u591a\u4e2aSWE-bench\u57fa\u51c6\u6210\u7ee9\u3002", "motivation": "\u73b0\u6709\u7684bug\u751f\u6210\u65b9\u6cd5\u591a\u91c7\u7528\u4eba\u4e3a\u6270\u52a8\u4ee3\u7801\uff0c\u901a\u5e38\u4f1a\u9020\u6210\u5206\u5e03\u5916\u6548\u5e94\uff0c\u4e0d\u7b26\u5408\u771f\u5b9e\u5f00\u53d1\u573a\u666f\u3002\u9ad8\u8d28\u91cf\u3001\u771f\u5b9e\u7684bug\u6570\u636e\u5bf9\u8bad\u7ec3\u66f4\u5f3a\u5927\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u6307\u5bfcSWE\u4ee3\u7406\u5728\u5f15\u5165\u65b0\u7279\u6027\u8fc7\u7a0b\u4e2d\u65e0\u610f\u4e2d\u5bfc\u81f4\u6d4b\u8bd5\u635f\u574f\uff0c\u4ece\u800c\u5728\u4ee3\u7801\u5e93\u4e2d\u751f\u6210\u8d34\u8fd1\u771f\u5b9e\u5f00\u53d1\u6d41\u7a0b\u7684\u591a\u6837\u5316\u590d\u6742bug\u3002", "result": "\u6240\u63d0\u51fa\u65b9\u6cd5\u751f\u6210\u7684bug\u6570\u636e\u5728\u7528\u66f4\u5c11\u8bad\u7ec3\u6837\u672c(1.2k\u5bf9\u6bd43k)\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u8868\u73b0\u8d85\u8d8a\u5176\u4ed6bug\u6570\u636e\u96c62%\u3002\u57fa\u4e8e\u65b0\u6570\u636e\u8bad\u7ec3\uff0cFrogBoss\u6a21\u578b\u5728SWE-bench\u4e0a\u8fbe\u5230pass@1 54.6%\uff0cFrogMini\u6a21\u578b\u8fbe\u523045.3%\uff0c\u5747\u4e3a\u540c\u53c2\u6570\u89c4\u6a21\u4e0b\u7684\u65b0SOTA\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u66f4\u771f\u5b9e\u4e14\u591a\u6837\u7684\u9ad8\u8d28\u91cfbug\uff0c\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u63d0\u5347\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u7684\u8bad\u7ec3\u6548\u679c\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u751f\u6210\u7684bug\u6bd4\u4ee5\u5f80\u7684\u6570\u636e\u96c6\u6027\u80fd\u66f4\u4f18\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728SWE-bench\u7684\u8868\u73b0\u3002"}}
{"id": "2510.19879", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.19879", "abs": "https://arxiv.org/abs/2510.19879", "authors": ["Lang Zhou", "Amrish Jhingoer", "Yinghao Luo", "Klaske Vliegenthart--Jongbloed", "Carlijn Jordans", "Ben Werkhoven", "Tom Seinen", "Erik van Mulligen", "Casper Rokx", "Yunlei Li"], "title": "Automated HIV Screening on Dutch EHR with Large Language Models", "comment": "28 pages, 6 figures", "summary": "Efficient screening and early diagnosis of HIV are critical for reducing\nonward transmission. Although large scale laboratory testing is not feasible,\nthe widespread adoption of Electronic Health Records (EHRs) offers new\nopportunities to address this challenge. Existing research primarily focuses on\napplying machine learning methods to structured data, such as patient\ndemographics, for improving HIV diagnosis. However, these approaches often\noverlook unstructured text data such as clinical notes, which potentially\ncontain valuable information relevant to HIV risk. In this study, we propose a\nnovel pipeline that leverages a Large Language Model (LLM) to analyze\nunstructured EHR text and determine a patient's eligibility for further HIV\ntesting. Experimental results on clinical data from Erasmus University Medical\nCenter Rotterdam demonstrate that our pipeline achieved high accuracy while\nmaintaining a low false negative rate.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5206\u6790\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u7684\u4e34\u5e8a\u6587\u672c\uff0c\u4ee5\u63d0\u5347HIV\u9ad8\u5371\u60a3\u8005\u7b5b\u67e5\u51c6\u786e\u7387\uff0c\u5e76\u5728\u5b9e\u9645\u6570\u636e\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u8868\u73b0\u3002", "motivation": "\u9ad8\u6548\u7b5b\u67e5\u548c\u65e9\u671f\u8bca\u65adHIV\u5bf9\u4e8e\u964d\u4f4e\u4f20\u64ad\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5927\u89c4\u6a21\u5b9e\u9a8c\u5ba4\u68c0\u6d4b\u4e0d\u53ef\u884c\u3002\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u7684\u666e\u53ca\u4e3a\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\u63d0\u4f9b\u4e86\u65b0\u673a\u9047\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u591a\u96c6\u4e2d\u4e8e\u7ed3\u6784\u5316\u6570\u636e\uff0c\u5ffd\u7565\u4e86\u53ef\u80fd\u5305\u542b\u5173\u952e\u4fe1\u606f\u7684\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u6587\u672c\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6d41\u7a0b\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5206\u6790\u975e\u7ed3\u6784\u5316EHR\u6587\u672c\uff0c\u4ee5\u786e\u5b9a\u60a3\u8005\u662f\u5426\u6709\u5fc5\u8981\u8fdb\u884c\u8fdb\u4e00\u6b65\u7684HIV\u68c0\u6d4b\u3002", "result": "\u5728\u9e7f\u7279\u4e39\u4f0a\u62c9\u65af\u8c1f\u5927\u5b66\u533b\u5b66\u4e2d\u5fc3\u7684\u4e34\u5e8a\u6570\u636e\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u4f4e\u5047\u9634\u6027\u7387\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u8f83\u9ad8\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u5229\u7528LLM\u5206\u6790\u975e\u7ed3\u6784\u5316EHR\u6570\u636e\u53ef\u6709\u6548\u63d0\u9ad8HIV\u7b5b\u67e5\u7684\u51c6\u786e\u6027\uff0c\u5e76\u6709\u52a9\u4e8e\u65e9\u671f\u53d1\u73b0\u9ad8\u5371\u60a3\u8005\u3002"}}
{"id": "2510.20547", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2510.20547", "abs": "https://arxiv.org/abs/2510.20547", "authors": ["Nikolaus Huber", "Susanne Graf", "Philipp R\u00fcmmer", "Wang Yi"], "title": "Compiling the Mimosa programming language to RTOS tasks", "comment": null, "summary": "This paper introduces a compilation scheme for programs written in the Mimosa\nprogramming language, which builds upon the MIMOS model of computation. Mimosa\ndescribes embedded systems software as a collection of time-triggered processes\nwhich communicate through FIFO queues. We formally describe an adaptation of\nthe Lustre compilation scheme to the semantics of Mimosa and show how the\ncoordination layer can be mapped to real-time operating system primitives.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684Mimosa\u7f16\u7a0b\u8bed\u8a00\uff0c\u63d0\u51fa\u5e76\u5f62\u5f0f\u5316\u4e86\u4e00\u5957\u7f16\u8bd1\u65b9\u6848\uff0c\u4f7f\u5176\u53ef\u901a\u8fc7\u5b9e\u65f6\u64cd\u4f5c\u7cfb\u7edf\u539f\u8bed\u8fdb\u884c\u5b9e\u73b0\uff0c\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u8f6f\u4ef6\u5f00\u53d1\u4e0e\u8fd0\u884c\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u5d4c\u5165\u5f0f\u7cfb\u7edf\u8f6f\u4ef6\u5bf9\u65f6\u95f4\u89e6\u53d1\u5f0f\u8fdb\u7a0b\u53caFIFO\u961f\u5217\u901a\u4fe1\u7684\u652f\u6301\u6709\u9650\uff0cMimosa\u8bed\u8a00\u65e8\u5728\u66f4\u597d\u5730\u63cf\u8ff0\u548c\u5b9e\u73b0\u8fd9\u79cd\u6a21\u578b\u3002", "method": "\u5c06Lustre\u7f16\u8bd1\u65b9\u6848\u9002\u914d\u81f3Mimosa\u8bed\u8a00\u7684\u8bed\u4e49\uff0c\u5e76\u8be6\u7ec6\u8bf4\u660e\u5982\u4f55\u5c06\u534f\u8c03\u5c42\u6620\u5c04\u5230\u5b9e\u65f6\u64cd\u4f5c\u7cfb\u7edf\u539f\u8bed\u3002", "result": "\u6210\u529f\u63d0\u51fa\u4e86Mimosa\u8bed\u8a00\u7684\u7f16\u8bd1\u6d41\u7a0b\uff0c\u5e76\u5b9e\u73b0\u4e86\u4e0e\u64cd\u4f5c\u7cfb\u7edf\u539f\u8bed\u7684\u6709\u6548\u5bf9\u5e94\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9Mimosa\u7f16\u7a0b\u8bed\u8a00\u7684\u7f16\u8bd1\u65b9\u6848\uff0c\u5c06\u5176\u5e94\u7528\u4e8e\u5b9e\u65f6\u64cd\u4f5c\u7cfb\u7edf\u3002"}}
{"id": "2510.19984", "categories": ["cs.SE", "D.2.5"], "pdf": "https://arxiv.org/pdf/2510.19984", "abs": "https://arxiv.org/abs/2510.19984", "authors": ["Konstantinos Kitsios", "Marcel B\u00f6hme", "Alberto Bacchelli"], "title": "On Interaction Effects in Greybox Fuzzing", "comment": "12 pages, 2 figures, Accepted for presentation at the 48th\n  International Conference on Software Engineering (ICSE '26)", "summary": "A greybox fuzzer is an automated software testing tool that generates new\ntest inputs by applying randomly chosen mutators (e.g., flipping a bit or\ndeleting a block of bytes) to a seed input in random order and adds all\ncoverage-increasing inputs to the corpus of seeds. We hypothesize that the\norder in which mutators are applied to a seed input has an impact on the\neffectiveness of greybox fuzzers. In our experiments, we fit a linear model to\na dataset that contains the effectiveness of all possible mutator pairs and\nindeed observe the conjectured interaction effect. This points us to more\nefficient fuzzing by choosing the most promising mutator sequence with a higher\nlikelihood. We propose MuoFuzz, a greybox fuzzer that learns and chooses the\nmost promising mutator sequences. MuoFuzz learns the conditional probability\nthat the next mutator will yield an interesting input, given the previously\nselected mutator. Then, it samples from the learned probability using a random\nwalk to generate mutator sequences. We compare the performance of MuoFuzz to\nAFL++, which uses a fixed selection probability, and MOPT, which optimizes the\nselection probability of each mutator in isolation. Experimental results on the\nFuzzBench and MAGMA benchmarks show that MuoFuzz achieves the highest code\ncoverage and finds four bugs missed by AFL++ and one missed by both AFL++ and\nMOPT.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u53d8\u5f02\u5668\u5e94\u7528\u987a\u5e8f\u5f71\u54cd\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u6548\u679c\uff0c\u63d0\u51fa\u5b66\u4e60\u53d8\u5f02\u5668\u5e8f\u5217\u66f4\u6709\u6548\u7684 MuoFuzz\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u4f18\u4e8e\u4e3b\u6d41\u5de5\u5177\u5e76\u53d1\u73b0\u989d\u5916\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u6709\u7684\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u968f\u673a\u6216\u72ec\u7acb\u9009\u62e9\u53d8\u5f02\u5668\uff0c\u672a\u5145\u5206\u5229\u7528\u53d8\u5f02\u5668\u4e4b\u95f4\u987a\u5e8f\u5bf9\u6d4b\u8bd5\u6709\u6548\u6027\u7684\u6f5c\u5728\u5f71\u54cd\u3002\u5e0c\u671b\u901a\u8fc7\u4f18\u5316\u53d8\u5f02\u5668\u5e94\u7528\u987a\u5e8f\uff0c\u63d0\u9ad8\u6d4b\u8bd5\u6548\u7387\u548c\u6f0f\u6d1e\u53d1\u73b0\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u7cca\u6d4b\u8bd5\u5668 MuoFuzz\uff0c\u901a\u8fc7\u62df\u5408\u7ebf\u6027\u6a21\u578b\u5206\u6790\u53d8\u5f02\u5668\u5e94\u7528\u987a\u5e8f\u7684\u6709\u6548\u6027\uff0c\u5b66\u4e60\u53d8\u5f02\u5668\u95f4\u7684\u6761\u4ef6\u6982\u7387\uff0c\u5e76\u57fa\u4e8e\u6982\u7387\u8fdb\u884c\u53d8\u5f02\u5668\u9009\u62e9\u3002\u4e0e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u5728 FuzzBench \u548c MAGMA \u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMuoFuzz \u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u4ee3\u7801\u8986\u76d6\u7387\uff0c\u5e76\u53d1\u73b0\u4e86 AFL++ \u672a\u80fd\u68c0\u6d4b\u5230\u7684 4 \u4e2a\u6f0f\u6d1e\uff0c\u4ee5\u53ca AFL++ \u548c MOPT \u90fd\u672a\u53d1\u73b0\u7684 1 \u4e2a\u6f0f\u6d1e\u3002", "conclusion": "MuoFuzz \u80fd\u591f\u901a\u8fc7\u5b66\u4e60\u5e76\u5229\u7528\u53d8\u5f02\u5668\u5e8f\u5217\u95f4\u7684\u5173\u7cfb\uff0c\u63d0\u5347\u8986\u76d6\u7387\uff0c\u5e76\u53d1\u73b0\u5176\u4ed6\u4e3b\u6d41\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u672a\u80fd\u53d1\u73b0\u7684\u6f0f\u6d1e\u3002"}}
{"id": "2510.19886", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.19886", "abs": "https://arxiv.org/abs/2510.19886", "authors": ["Artur Donaldson", "Bharathan Balaji", "Cajetan Oriekezie", "Manish Kumar", "Laure Patouillard"], "title": "An Expert-grounded benchmark of General Purpose LLMs in LCA", "comment": null, "summary": "Purpose: Artificial intelligence (AI), and in particular large language\nmodels (LLMs), are increasingly being explored as tools to support life cycle\nassessment (LCA). While demonstrations exist across environmental and social\ndomains, systematic evidence on their reliability, robustness, and usability\nremains limited. This study provides the first expert-grounded benchmark of\nLLMs in LCA, addressing the absence of standardized evaluation frameworks in a\nfield where no clear ground truth or consensus protocols exist.\n  Methods: We evaluated eleven general-purpose LLMs, spanning both commercial\nand open-source families, across 22 LCA-related tasks. Seventeen experienced\npractitioners reviewed model outputs against criteria directly relevant to LCA\npractice, including scientific accuracy, explanation quality, robustness,\nverifiability, and adherence to instructions. We collected 168 expert reviews.\n  Results: Experts judged 37% of responses to contain inaccurate or misleading\ninformation. Ratings of accuracy and quality of explanation were generally\nrated average or good on many models even smaller models, and format adherence\nwas generally rated favourably. Hallucination rates varied significantly, with\nsome models producing hallucinated citations at rates of up to 40%. There was\nno clear-cut distinction between ratings on open-weight versus closed-weight\nLLMs, with open-weight models outperforming or competing on par with\nclosed-weight models on criteria such as accuracy and quality of explanation.\n  Conclusion: These findings highlight the risks of applying LLMs na\\\"ively in\nLCA, such as when LLMs are treated as free-form oracles, while also showing\nbenefits especially around quality of explanation and alleviating labour\nintensiveness of simple tasks. The use of general-purpose LLMs without\ngrounding mechanisms presents ...", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5546\u7528\u548c\u5f00\u6e90LLM\u5728LCA\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u8f93\u51fa\u5e38\u5b58\u5728\u4e0d\u51c6\u786e\u548c\u865a\u5047\u4fe1\u606f\uff0c\u89e3\u91ca\u8d28\u91cf\u548c\u4efb\u52a1\u7b80\u5316\u6709\u76ca\uff0c\u4f46\u8131\u79bb\u4e13\u4e1a\u673a\u5236\u6613\u5e26\u6765\u98ce\u9669\u3002", "motivation": "AI\u7279\u522b\u662fLLMs\u5728LCA\u9886\u57df\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u7f3a\u4e4f\u5173\u4e8e\u5176\u53ef\u9760\u6027\u3001\u7a33\u5065\u6027\u53ca\u53ef\u7528\u6027\u7684\u7cfb\u7edf\u6027\u5b9e\u8bc1\uff0c\u4e14\u65e0\u7edf\u4e00\u7684\u8bc4\u4f30\u6807\u51c6\u6216\u534f\u8bae\uff0c\u56e0\u6b64\u4e9f\u9700\u5efa\u7acb\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u8bc4\u4f30\u4e8611\u79cd\u901a\u7528\u578bLLM\uff08\u5305\u62ec\u5546\u7528\u4e0e\u5f00\u6e90\uff09\uff0c\u9488\u5bf922\u4e2aLCA\u76f8\u5173\u4efb\u52a1\uff0c\u753117\u4f4d\u4e13\u5bb6\u57fa\u4e8e\u79d1\u5b66\u51c6\u786e\u6027\u3001\u89e3\u91ca\u8d28\u91cf\u3001\u5065\u58ee\u6027\u3001\u53ef\u9a8c\u8bc1\u6027\u548c\u6307\u4ee4\u9075\u5faa\u6027\u7b49\u6807\u51c6\u5ba1\u9605\u6a21\u578b\u8f93\u51fa\uff0c\u6536\u96c6\u4e86168\u4efd\u4e13\u5bb6\u8bc4\u4ef7\u3002", "result": "37%\u7684\u6a21\u578b\u8f93\u51fa\u88ab\u4e13\u5bb6\u5224\u5b9a\u4e3a\u4e0d\u51c6\u786e\u6216\u8bef\u5bfc\uff0c\u5176\u4e2d\u6709\u7684\u6a21\u578b\u80e1\u7f16\u4e71\u9020\u5f15\u7528\u7684\u6bd4\u4f8b\u9ad8\u8fbe40%\u3002\u5f00\u6e90\u4e0e\u95ed\u6e90\u6a21\u578b\u5728\u51c6\u786e\u6027\u548c\u89e3\u91ca\u8d28\u91cf\u4e0a\u5747\u6709\u7ade\u4e89\u529b\uff0c\u672a\u73b0\u660e\u663e\u4f18\u52a3\u5dee\u5f02\u3002\u683c\u5f0f\u9075\u5faa\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5e7b\u89c9\u7387\uff08\u4fe1\u606f\u4f2a\u9020\uff09\u5dee\u5f02\u8f83\u5927\u3002", "conclusion": "\u5e94\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e8e\u751f\u547d\u5468\u671f\u8bc4\u4f30\uff08LCA\uff09\u5b58\u5728\u98ce\u9669\uff0c\u5c24\u5176\u662f\u672a\u7ecf\u4e13\u4e1a\u8fde\u63a5\u548c\u6821\u9a8c\u65f6\uff0c\u4f46\u5728\u89e3\u91ca\u8d28\u91cf\u548c\u7b80\u5316\u7e41\u91cd\u4efb\u52a1\u65b9\u9762\u6709\u660e\u663e\u4f18\u52bf\u3002\u7f3a\u4e4f\u53ef\u9760\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\u9650\u5236\u4e86\u5176\u5e94\u7528\u3002"}}
{"id": "2510.20688", "categories": ["cs.PL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.20688", "abs": "https://arxiv.org/abs/2510.20688", "authors": ["Oliver Braunsdorf", "Tim Lange", "Konrad Hohentanner", "Julian Horsch", "Johannes Kinder"], "title": "SafeFFI: Efficient Sanitization at the Boundary Between Safe and Unsafe Code in Rust and Mixed-Language Applications", "comment": null, "summary": "Unsafe Rust code is necessary for interoperability with C/C++ libraries and\nimplementing low-level data structures, but it can cause memory safety\nviolations in otherwise memory-safe Rust programs. Sanitizers can catch such\nmemory errors at runtime, but introduce many unnecessary checks even for memory\naccesses guaranteed safe by the Rust type system. We introduce SafeFFI, a\nsystem for optimizing memory safety instrumentation in Rust binaries such that\nchecks occur at the boundary between unsafe and safe code, handing over the\nenforcement of memory safety from the sanitizer to the Rust type system. Unlike\nprevious approaches, our design avoids expensive whole-program analysis and\nadds much less compile-time overhead (2.64x compared to over 8.83x). On a\ncollection of popular Rust crates and known vulnerable Rust code, SafeFFI\nachieves superior performance compared to state-of-the-art systems, reducing\nsanitizer checks by up to 98%, while maintaining correctness and flagging all\nspatial and temporal memory safety violations.", "AI": {"tldr": "SafeFFI\u7cfb\u7edf\u901a\u8fc7\u4f18\u5316\u5185\u5b58\u5b89\u5168\u68c0\u67e5\u8fb9\u754c\uff0c\u663e\u8457\u51cf\u5c11Rust\u7a0b\u5e8f\u4e2d\u7684Sanitizer\u68c0\u6d4b\u6b21\u6570\uff0c\u6709\u6548\u63d0\u5347\u6027\u80fd\u4e14\u4fdd\u8bc1\u5b89\u5168\uff0c\u9002\u7528\u4e8e\u4e0eC/C++\u4e92\u64cd\u4f5c\u53ca\u4f7f\u7528unsafe\u4ee3\u7801\u573a\u666f\u3002", "motivation": "Rust\u8bed\u8a00\u867d\u7136\u4ee5\u9ad8\u5185\u5b58\u5b89\u5168\u6027\u8457\u79f0\uff0c\u4f46\u5728\u4e0eC/C++\u5e93\u4e92\u64cd\u4f5c\u548c\u5b9e\u73b0\u5e95\u5c42\u6570\u636e\u7ed3\u6784\u65f6\uff0c\u4e0d\u53ef\u907f\u514d\u5730\u9700\u8981\u4f7f\u7528unsafe\u4ee3\u7801\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u5185\u5b58\u5b89\u5168\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56Sanitizer\u52a8\u6001\u68c0\u6d4b\uff0c\u4f46\u4f1a\u8fdb\u884c\u5927\u91cf\u4e0d\u5fc5\u8981\u7684\u5185\u5b58\u5b89\u5168\u68c0\u67e5\uff0c\u589e\u52a0\u8fd0\u884c\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u4e86SafeFFI\u7cfb\u7edf\uff0c\u5c06\u5185\u5b58\u5b89\u5168\u68c0\u67e5\u4f18\u5316\uff0c\u4e3b\u8981\u5728\u5b89\u5168\u4e0e\u975e\u5b89\u5168\u4ee3\u7801\u8fb9\u754c\u8fdb\u884c\u68c0\u67e5\u3002\u8be5\u65b9\u6cd5\u5c06\u5185\u5b58\u5b89\u5168\u7684\u4fdd\u969c\u4eceSanitizer\u8f6c\u4ea4\u81f3Rust\u7c7b\u578b\u7cfb\u7edf\uff0c\u4e0d\u91c7\u7528\u6602\u8d35\u7684\u5168\u7a0b\u5e8f\u5206\u6790\u65b9\u6848\uff0c\u51cf\u5c11\u7f16\u8bd1\u65f6\u5f00\u9500\u3002", "result": "\u5728\u5927\u91cf\u6d41\u884cRust crate\u548c\u5df2\u77e5\u6709\u6f0f\u6d1e\u7684\u4ee3\u7801\u4e2d\uff0cSafeFFI\u7cfb\u7edf\u76f8\u8f83\u5f53\u524d\u65b9\u6848\u6027\u80fd\u66f4\u597d\uff0c\u6700\u591a\u80fd\u51cf\u5c1198%\u7684Sanitizer\u68c0\u67e5\uff0c\u540c\u65f6\u4fdd\u6301\u6b63\u786e\u6027\uff0c\u5e76\u80fd\u68c0\u6d4b\u6240\u6709\u7a7a\u95f4\u548c\u65f6\u95f4\u4e0a\u7684\u5185\u5b58\u5b89\u5168\u8fdd\u89c4\u3002", "conclusion": "SafeFFI\u6709\u6548\u5728\u4fdd\u8bc1\u5b89\u5168\u7684\u524d\u63d0\u4e0b\u6781\u5927\u4f18\u5316\u4e86Rust\u7a0b\u5e8f\u4e2d\u7684\u5185\u5b58\u5b89\u5168\u68c0\u6d4b\u6548\u7387\uff0c\u5c55\u73b0\u51fa\u5728\u6027\u80fd\u548c\u5b89\u5168\u6027\u4e4b\u95f4\u7684\u4f18\u8d8a\u6743\u8861\u3002"}}
{"id": "2510.19997", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19997", "abs": "https://arxiv.org/abs/2510.19997", "authors": ["Abraham Itzhak Weinberg"], "title": "A Framework for the Adoption and Integration of Generative AI in Midsize Organizations and Enterprises (FAIGMOE)", "comment": null, "summary": "Generative Artificial Intelligence (GenAI) presents transformative\nopportunities for organizations, yet both midsize organizations and larger\nenterprises face distinctive adoption challenges. Midsize organizations\nencounter resource constraints and limited AI expertise, while enterprises\nstruggle with organizational complexity and coordination challenges. Existing\ntechnology adoption frameworks, including TAM (Technology Acceptance Model),\nTOE (Technology Organization Environment), and DOI (Diffusion of Innovations)\ntheory, lack the specificity required for GenAI implementation across these\ndiverse contexts, creating a critical gap in adoption literature. This paper\nintroduces FAIGMOE (Framework for the Adoption and Integration of Generative AI\nin Midsize Organizations and Enterprises), a conceptual framework addressing\nthe unique needs of both organizational types. FAIGMOE synthesizes technology\nadoption theory, organizational change management, and innovation diffusion\nperspectives into four interconnected phases: Strategic Assessment, Planning\nand Use Case Development, Implementation and Integration, and\nOperationalization and Optimization. Each phase provides scalable guidance on\nreadiness assessment, strategic alignment, risk governance, technical\narchitecture, and change management adaptable to organizational scale and\ncomplexity. The framework incorporates GenAI specific considerations including\nprompt engineering, model orchestration, and hallucination management that\ndistinguish it from generic technology adoption frameworks. As a perspective\ncontribution, FAIGMOE provides the first comprehensive conceptual framework\nexplicitly addressing GenAI adoption across midsize and enterprise\norganizations, offering actionable implementation protocols, assessment\ninstruments, and governance templates requiring empirical validation through\nfuture research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86FAIGMOE\u6846\u67b6\uff0c\u5f25\u8865\u4e86GenAI\u5728\u7ec4\u7ec7\u5e94\u7528\u8fc7\u7a0b\u4e2d\u7f3a\u4e4f\u9488\u5bf9\u6027\u6307\u5bfc\u7684\u7a7a\u767d\uff0c\u4e3a\u4e0d\u540c\u89c4\u6a21\u7ec4\u7ec7\u843d\u5730GenAI\u63d0\u4f9b\u4e86\u5177\u4f53\u3001\u53ef\u64cd\u4f5c\u7684\u65b9\u6cd5\u548c\u5de5\u5177\u3002", "motivation": "\u672c\u6587\u5173\u6ce8\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u5728\u4e0d\u540c\u89c4\u6a21\u7ec4\u7ec7\uff08\u4e2d\u578b\u4f01\u4e1a\u548c\u5927\u578b\u4f01\u4e1a\uff09\u4e2d\u7684\u5e94\u7528\u3002\u7531\u4e8e\u73b0\u6709\u6280\u672f\u91c7\u7eb3\u7406\u8bba\uff08\u5982TAM\u3001TOE\u3001DOI\uff09\u7f3a\u4e4f\u9488\u5bf9GenAI\u7684\u5177\u4f53\u6307\u5bfc\uff0c\u7ec4\u7ec7\u5728\u91c7\u7eb3\u8fc7\u7a0b\u4e2d\u9047\u5230\u8bf8\u591a\u969c\u788d\uff0c\u4fc3\u4f7f\u4f5c\u8005\u63d0\u51fa\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aFAIGMOE\u7684\u6982\u5ff5\u6027\u6846\u67b6\uff0c\u7efc\u5408\u4e86\u6280\u672f\u91c7\u7eb3\u7406\u8bba\u3001\u7ec4\u7ec7\u53d8\u9769\u7ba1\u7406\u548c\u521b\u65b0\u6269\u6563\u89c6\u89d2\uff0c\u5c06\u91c7\u7eb3\u8fc7\u7a0b\u5212\u5206\u4e3a\u6218\u7565\u8bc4\u4f30\u3001\u89c4\u5212\u4e0e\u7528\u4f8b\u5f00\u53d1\u3001\u5b9e\u65bd\u4e0e\u96c6\u6210\u3001\u8fd0\u8425\u4e0e\u4f18\u5316\u56db\u4e2a\u9636\u6bb5\uff0c\u5e76\u9488\u5bf9GenAI\u7684\u7279\u70b9\u7ed9\u51fa\u53ef\u6269\u5c55\u7684\u64cd\u4f5c\u5efa\u8bae\u3002", "result": "FAIGMOE\u6846\u67b6\u4e3a\u4e2d\u578b\u548c\u5927\u578b\u4f01\u4e1a\u63d0\u4f9b\u4e86\u9488\u5bf9GenAI\u91c7\u7eb3\u7684\u8be6\u7ec6\u5b9e\u65bd\u534f\u8bae\u3001\u8bc4\u4f30\u5de5\u5177\u548c\u6cbb\u7406\u6a21\u677f\uff0c\u5e76\u6db5\u76d6\u4e86\u5982\u63d0\u793a\u5de5\u7a0b\u3001\u6a21\u578b\u7f16\u6392\u548c\u5e7b\u89c9\u7ba1\u7406\u7b49GenAI\u7279\u6709\u95ee\u9898\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e13\u95e8\u9762\u5411\u4e2d\u578b\u548c\u5927\u578b\u7ec4\u7ec7\u7684GenAI\u91c7\u7eb3\u4e0e\u96c6\u6210\u7efc\u5408\u6846\u67b6\uff0c\u4e3a\u672a\u6765\u7684\u5b9e\u9645\u5e94\u7528\u548c\u540e\u7eed\u5b9e\u8bc1\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.19892", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19892", "abs": "https://arxiv.org/abs/2510.19892", "authors": ["Nishant Balepur", "Dang Nguyen", "Dayeon Ki"], "title": "Can They Dixit? Yes they Can! Dixit as a Playground for Multimodal Language Model Capabilities", "comment": "Accepted as a Spotlight paper at the EMNLP 2025 Wordplay Workshop", "summary": "Multi-modal large language models (MLMs) are often assessed on static,\nindividual benchmarks -- which cannot jointly assess MLM capabilities in a\nsingle task -- or rely on human or model pairwise comparisons -- which is\nhighly subjective, expensive, and allows models to exploit superficial\nshortcuts (e.g., verbosity) to inflate their win-rates. To overcome these\nissues, we propose game-based evaluations to holistically assess MLM\ncapabilities. Games require multiple abilities for players to win, are\ninherently competitive, and are governed by fix, objective rules, and makes\nevaluation more engaging, providing a robust framework to address the\naforementioned challenges. We manifest this evaluation specifically through\nDixit, a fantasy card game where players must generate captions for a card that\ntrick some, but not all players, into selecting the played card. Our\nquantitative experiments with five MLMs show Dixit win-rate rankings are\nperfectly correlated with those on popular MLM benchmarks, while games between\nhuman and MLM players in Dixit reveal several differences between agent\nstrategies and areas of improvement for MLM reasoning.", "AI": {"tldr": "\u901a\u8fc7Dixit\u6e38\u620f\u6765\u8bc4\u4ef7\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u52a0\u5168\u9762\u5ba2\u89c2\uff0c\u53ef\u4ee5\u53d1\u73b0\u6a21\u578b\u4e0e\u4eba\u7684\u7b56\u7565\u53ca\u63a8\u7406\u80fd\u529b\u5dee\u5f02\uff0c\u662f\u4e00\u79cd\u66f4\u5177\u6311\u6218\u6027\u7684\u8bc4\u6d4b\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u7684\u8bc4\u4f30\u65b9\u6cd5\u8981\u4e48\u662f\u9759\u6001\u72ec\u7acb\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u65e0\u6cd5\u7efc\u5408\u5730\u8bc4\u4ef7MLM\u7684\u591a\u9879\u80fd\u529b\uff1b\u8981\u4e48\u4f9d\u8d56\u4e3b\u89c2\u7684\u4eba\u6216\u6a21\u578b\u5bf9\u6bd4\uff0c\u5bb9\u6613\u4ea7\u751f\u504f\u89c1\u5e76\u88ab\u6a21\u578b\u7684\u8868\u9762\u7279\u5f81\uff08\u5982\u5570\u55e6\uff09\u8bef\u5bfc\u7ed3\u679c\u3002\u9700\u8981\u4e00\u4e2a\u5ba2\u89c2\u3001\u7efc\u5408\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u8bc4\u4f30\u65b9\u5f0f\u3002", "method": "\u901a\u8fc7\u5c06MLM\u53c2\u4e0eDixit\u6e38\u620f\uff0c\u6bd4\u8f83\u5176\u80dc\u7387\uff0c\u5e76\u4e0e\u73b0\u6709\u4e3b\u6d41MLM\u57fa\u51c6\u6d4b\u8bd5\u6210\u7ee9\u8fdb\u884c\u76f8\u5173\u5206\u6790\uff0c\u540c\u65f6\u4e3e\u884c\u4eba\u673a\u5bf9\u6218\u4ee5\u89c2\u5bdf\u7b56\u7565\u4e0e\u63a8\u7406\u5dee\u5f02\u3002", "result": "\u4e94\u6b3eMLM\u5728Dixit\u6e38\u620f\u4e2d\u7684\u80dc\u7387\u6392\u540d\u4e0e\u4e3b\u6d41\u57fa\u51c6\u6d4b\u8bd5\u5b8c\u5168\u4e00\u81f4\uff0c\u4f46\u4eba\u673a\u5bf9\u6218\u63ed\u793a\u4e86\u6a21\u578b\u5728\u7b56\u7565\u548c\u63a8\u7406\u65b9\u9762\u4e0e\u4eba\u7c7b\u73a9\u5bb6\u7684\u660e\u663e\u5dee\u5f02\uff0c\u4ee5\u53ca\u672a\u6765\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "\u91c7\u7528\u6e38\u620f\u5316\u7684\u8bc4\u4f30\u65b9\u5f0f\uff08\u4ee5Dixit\u4e3a\u5b9e\u4f8b\uff09\u80fd\u591f\u66f4\u5168\u9762\u5ba2\u89c2\u5730\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLM\uff09\u7684\u80fd\u529b\uff0c\u5e76\u80fd\u53d1\u73b0\u6a21\u578b\u4e0e\u4eba\u7684\u7b56\u7565\u5dee\u5f02\u53ca\u5176\u6539\u8fdb\u7a7a\u95f4\u3002"}}
{"id": "2510.20041", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20041", "abs": "https://arxiv.org/abs/2510.20041", "authors": ["Gareema Ranjan", "Mahmoud Alfadel", "Gengyi Sun", "Shane McIntosh"], "title": "The Cost of Downgrading Build Systems: A Case Study of Kubernetes", "comment": null, "summary": "Since developers invoke the build system frequently, its performance can\nimpact productivity. Modern artifact-based build tools accelerate builds, yet\nprior work shows that teams may abandon them for alternatives that are easier\nto maintain. While prior work shows why downgrades are performed, the\nimplications of downgrades remain largely unexplored. In this paper, we\ndescribe a case study of the Kubernetes project, focusing on its downgrade from\nan artifact-based build tool (Bazel) to a language-specific solution (Go\nBuild). We reproduce and analyze the full and incremental builds of change sets\nduring the downgrade period. On the one hand, we find that Bazel builds are\nfaster than Go Build, completing full builds in 23.06-38.66 up to 75.19 impose\na larger memory footprint than Go Build of 81.42-351.07 respectively. Bazel\nbuilds also impose a greater CPU load at parallelism settings above eight for\nfull builds and above one for incremental builds. We estimate that downgrading\nfrom Bazel can increase CI resource costs by up to 76 explore whether our\nobservations generalize by replicating our Kubernetes study on four other\nprojects that also downgraded from Bazel to older build tools. We observe that\nwhile build time penalties decrease, Bazel consistently consumes more memory.\nWe conclude that abandoning artifact-based build tools, despite perceived\nmaintainability benefits, tends to incur considerable performance costs for\nlarge projects. Our observations may help stakeholders to balance trade-offs in\nbuild tool adoption", "AI": {"tldr": "\u672c\u6587\u4ee5Kubernetes\u53ca\u5176\u4ed6\u56db\u4e2a\u9879\u76ee\u4e3a\u4f8b\uff0c\u5206\u6790\u4eceBazel\u964d\u7ea7\u5230Go Build\u7684\u8fc7\u7a0b\uff0c\u53d1\u73b0\u964d\u7ea7\u867d\u63d0\u5347\u4e86\u53ef\u7ef4\u62a4\u6027\uff0c\u5374\u9020\u6210\u6784\u5efa\u901f\u5ea6\u4e0b\u964d\u3001\u8d44\u6e90\u6d88\u8017\u589e\u52a0\uff0c\u5efa\u8bae\u5728\u9009\u62e9\u6784\u5efa\u5de5\u5177\u65f6\u9700\u614e\u91cd\u6743\u8861\u6027\u80fd\u4e0e\u53ef\u7ef4\u62a4\u6027\u3002", "motivation": "\u6784\u5efa\u7cfb\u7edf\u7684\u6027\u80fd\u5f71\u54cd\u5f00\u53d1\u8005\u751f\u4ea7\u529b\u3002\u5c3d\u7ba1\u73b0\u4ee3\u57fa\u4e8e\u5de5\u4ef6\u7684\u6784\u5efa\u5de5\u5177\uff08\u5982Bazel\uff09\u53ef\u4ee5\u52a0\u901f\u6784\u5efa\uff0c\u4f46\u7531\u4e8e\u7ef4\u62a4\u96be\u5ea6\uff0c\u56e2\u961f\u53ef\u80fd\u4f1a\u5f03\u7528\u5b83\u4eec\u9009\u62e9\u6613\u4e8e\u7ef4\u62a4\u7684\u66ff\u4ee3\u54c1\u3002\u6b64\u524d\u5de5\u4f5c\u867d\u89e3\u91ca\u4e86\u5f03\u7528\u539f\u56e0\uff0c\u5f03\u7528\u7684\u5177\u4f53\u5f71\u54cd\u5c1a\u672a\u6df1\u5165\u63a2\u8ba8\u3002", "method": "\u4ee5Kubernetes\u9879\u76ee\u4e3a\u4f8b\uff0c\u5206\u6790\u4ece\u57fa\u4e8e\u5de5\u4ef6\u7684\u6784\u5efa\u5de5\u5177\uff08Bazel\uff09\u964d\u7ea7\u5230\u8bed\u8a00\u4e13\u7528\u6784\u5efa\u5de5\u5177\uff08Go Build\uff09\u7684\u8fc7\u7a0b\uff0c\u91cd\u65b0\u6784\u5efa\u5e76\u5206\u6790\u964d\u7ea7\u671f\u95f4\u7684\u5b8c\u6574\u548c\u589e\u91cf\u6784\u5efa\u6570\u636e\u3002\u6b64\u5916\uff0c\u5728\u53e6\u5916\u56db\u4e2a\u540c\u6837\u4eceBazel\u964d\u7ea7\u7684\u9879\u76ee\u4e0a\u590d\u73b0\u5e76\u5bf9\u6bd4\u7814\u7a76\u89c2\u5bdf\u3002", "result": "Bazel\u6784\u5efa\u901f\u5ea6\u6574\u4f53\u5feb\u4e8eGo Build\uff08\u5168\u91cf\u6784\u5efa\u4e3a23.06-38.66\u5206\u949f\uff09\uff0c\u4f46\u5185\u5b58\u5360\u7528\u66f4\u9ad8\uff08\u8fbe\u523081.42-351.07MB\uff09\uff0c\u5e76\u4e14\u5728\u66f4\u9ad8\u5e76\u884c\u5ea6\u4e0bCPU\u8d1f\u8f7d\u8f83\u5927\u3002\u964d\u7ea7\u540e\u6301\u7eed\u96c6\u6210\u8d44\u6e90\u6210\u672c\u6700\u591a\u53ef\u589e76%\u3002\u5728\u5176\u4ed6\u9879\u76ee\u4e0a\u91cd\u590d\u5b9e\u9a8c\u540e\u53d1\u73b0\uff0c\u867d\u7136\u6784\u5efa\u65f6\u95f4\u5dee\u5f02\u51cf\u5c0f\uff0c\u4f46Bazel\u4ecd\u6d88\u8017\u66f4\u591a\u5185\u5b58\u3002", "conclusion": "\u653e\u5f03\u57fa\u4e8e\u5de5\u4ef6\u7684\u6784\u5efa\u5de5\u5177\u4ee5\u6539\u5584\u53ef\u7ef4\u62a4\u6027\uff0c\u901a\u5e38\u4f1a\u4e3a\u5927\u578b\u9879\u76ee\u5e26\u6765\u663e\u8457\u6027\u80fd\u635f\u5931\u3002\u7814\u7a76\u7ed3\u679c\u6709\u52a9\u4e8e\u76f8\u5173\u5229\u76ca\u65b9\u5728\u6784\u5efa\u5de5\u5177\u5e94\u7528\u4e2d\u6743\u8861\u6027\u80fd\u548c\u7ef4\u62a4\u6027\u3002"}}
{"id": "2510.19895", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19895", "abs": "https://arxiv.org/abs/2510.19895", "authors": ["Guoyun Zhang"], "title": "Large Language Model enabled Mathematical Modeling", "comment": null, "summary": "The integration of Large Language Models (LLMs) with optimization modeling\noffers a promising avenue for advancing decision-making in operations research\n(OR). Traditional optimization methods,such as linear programming, mixed\ninteger programming, and simulation depend heavily on domain expertise to\ntranslate real-world problems into solvable mathematical models. While solvers\nlike Gurobi and COPT are powerful, expert input remains essential for defining\nobjectives, constraints, and variables. This research investigates the\npotential of LLMs, specifically the DeepSeek-R1 model, to bridge this\nformulation gap using natural language understanding and code generation.\nAlthough prior models like GPT-4, Claude, and Bard have shown strong\nperformance in NLP and reasoning tasks, their high token costs and tendency\ntoward hallucinations limit real-world applicability in supply chain contexts.\nIn contrast, DeepSeek-R1, a cost-efficient and high-performing model trained\nwith reinforcement learning, presents a viable alternative. Despite its success\nin benchmarks such as LiveCodeBench and Math-500, its effectiveness in applied\nOR scenarios remains under explored. This study systematically evaluates\nDeepSeek-R1 across four key OR benchmarks: NL4OPT, IndustryOR, EasyLP, and\nComplexOR. Our methodology includes baseline assessments, the development of a\nhallucination taxonomy, and the application of mitigation strategies like\nLLM-as-a-Judge, Few-shot Learning (FSL), Tool Calling, and a Multi-agent\nFramework. These techniques aim to reduce hallucinations, enhance formulation\naccuracy, and better align model outputs with user intent.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86DeepSeek-R1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fd0\u7b79\u5b66\u4f18\u5316\u5efa\u6a21\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002\u76f8\u8f83\u4f20\u7edf\u548c\u73b0\u6709\u4e3b\u6d41\u6a21\u578b\uff0cDeepSeek-R1\u5728\u6210\u672c\u4e0e\u6027\u80fd\u4e0a\u8868\u73b0\u7a81\u51fa\uff0c\u901a\u8fc7\u591a\u7b56\u7565\u6709\u6548\u964d\u4f4e\u5e7b\u89c9\u7387\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u81ea\u52a8\u5316\u5efa\u6a21\u7684\u51c6\u786e\u6027\u548c\u5b9e\u9645\u53ef\u7528\u6027\u3002", "motivation": "\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u5728\u8fd0\u7b79\u5b66\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5efa\u6a21\u8fc7\u7a0b\u9ad8\u5ea6\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\uff0c\u5bf9\u5b9e\u9645\u95ee\u9898\u7684\u6570\u5b66\u5efa\u6a21\u5b58\u5728\u95e8\u69db\u3002\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5177\u5907\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u6709\u671b\u901a\u8fc7\u964d\u4f4e\u5efa\u6a21\u95e8\u69db\uff0c\u4fc3\u8fdb\u4f18\u5316\u65b9\u6cd5\u5728\u5b9e\u9645\u51b3\u7b56\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002\u73b0\u6709\u4e3b\u6d41\u6a21\u578b\uff08\u5982GPT-4\u7b49\uff09\u5b58\u5728\u6210\u672c\u9ad8\u548c\u5e7b\u89c9\u9891\u53d1\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u4f9b\u5e94\u94fe\u51b3\u7b56\u4e2d\u7684\u73b0\u5b9e\u5e94\u7528\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u65b0\u6a21\u578bDeepSeek-R1\u5728\u6b64\u9886\u57df\u7684\u6f5c\u529b\u3002", "method": "\u672c\u6587\u9009\u62e9DeepSeek-R1\u6a21\u578b\uff0c\u9488\u5bf9\u8fd0\u7b79\u5b66\u9886\u57df\u7684\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff08NL4OPT\u3001IndustryOR\u3001EasyLP\u3001ComplexOR\uff09\u8fdb\u884c\u7cfb\u7edf\u6027\u8bc4\u4f30\uff0c\u5305\u62ec\u57fa\u7ebf\u80fd\u529b\u6d4b\u8bc4\u3001\u5e7b\u89c9\u5206\u7c7b\u4f53\u7cfb\u6784\u5efa\u3001\u4ee5\u53ca\u591a\u79cd\u7f13\u89e3\u5e7b\u89c9\u7b56\u7565\uff08LLM-as-a-Judge\u3001Few-shot Learning\u3001\u5de5\u5177\u8c03\u7528\u3001\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff09\u7684\u5e94\u7528\u3002\u8fd9\u4e9b\u65b9\u6cd5\u7528\u4e8e\u63d0\u5347\u6a21\u578b\u5728\u4f18\u5316\u5efa\u6a21\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u3001\u51cf\u5c11\u5e7b\u89c9\u504f\u5dee\uff0c\u5e76\u63d0\u5347\u7ed3\u679c\u4e0e\u7528\u6237\u9700\u6c42\u7684\u5951\u5408\u5ea6\u3002", "result": "DeepSeek-R1\u5728\u51b3\u7b56\u4f18\u5316\u5efa\u6a21\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u9ad8\u6027\u4ef7\u6bd4\u548c\u826f\u597d\u6027\u80fd\uff0c\u521d\u6b65\u9a8c\u8bc1\u4e86\u5176\u5728\u8fd0\u7b79\u5b66\u5b9e\u9645\u573a\u666f\u4e0b\u7684\u53ef\u7528\u6027\u3002\u5404\u7c7b\u7f13\u89e3\u7b56\u7565\u6709\u6548\u51cf\u5c11\u4e86\u5e7b\u89c9\u73b0\u8c61\uff0c\u63d0\u5347\u4e86\u4e0e\u7528\u6237\u610f\u56fe\u7684\u5bf9\u9f50\u548c\u6a21\u578b\u7684\u5efa\u6a21\u51c6\u786e\u7387\u3002", "conclusion": "DeepSeek-R1\u4f5c\u4e3a\u4e00\u79cd\u9ad8\u6548\u4f4e\u6210\u672c\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u53ef\u4ee5\u5728\u8fd0\u7b79\u5b66\u4f18\u5316\u5efa\u6a21\u9886\u57df\u4e2d\u6709\u6548\u7f13\u89e3\u4f20\u7edf\u65b9\u6cd5\u5bf9\u4e13\u5bb6\u77e5\u8bc6\u7684\u4f9d\u8d56\uff0c\u901a\u8fc7\u591a\u79cd\u6280\u672f\u624b\u6bb5\u663e\u8457\u964d\u4f4e\u5e7b\u89c9\u53d1\u751f\uff0c\u63a8\u52a8\u81ea\u7136\u8bed\u8a00\u5230\u4f18\u5316\u6a21\u578b\u7684\u81ea\u52a8\u5316\u8f6c\u5316\u3002"}}
{"id": "2510.20121", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.20121", "abs": "https://arxiv.org/abs/2510.20121", "authors": ["Carlos J. Fernandez-Candel", "Jesus Garcia-Molina", "Francisco Javier Bermudez Ruiz", "Jose Ramon Hoyos Barcelo", "Diego Sevilla Ruiz", "Benito Jose Cuesta Viera"], "title": "Developing a Model-Driven Reengineering Approach for Migrating PL/SQL Triggers to Java: A Practical Experience", "comment": "31 pages, 22 figures", "summary": "Model-driven software engineering (MDE) techniques are not only useful in\nforward engineering scenarios, but can also be successfully applied to evolve\nexisting systems. RAD (Rapid Application Development) platforms emerged in the\nnineties, but the success of modern software technologies motivated that a\nlarge number of enterprises tackled the migration of their RAD applications,\nsuch as Oracle Forms. Our research group has collaborated with a software\ncompany in developing a solution to migrate PL/SQL monolithic code on Forms\ntriggers and program units to Java code separated in several tiers.\n  Our research focused on the model-driven reengineering process applied to\ndevelop the migration tool for the conversion of PL/SQL code to Java. Legacy\ncode is represented in form of KDM (Knowledge-Discovery Metamodel) models. In\nthis paper, we propose a software process to implement a model-driven\nre-engineering. This process integrates a TDD-like approach to incrementally\ndevelop model transformations with three kinds of validations for the generated\ncode. The implementation and validation of the re-engineering approach are\nexplained in detail, as well as the evaluation of some issues related with the\napplication of MDE.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u5957\u57fa\u4e8eKDM\u548c\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\u7684\u9057\u7559PL/SQL\u4ee3\u7801\u81ea\u52a8\u8fc1\u79fb\u5230Java\u5206\u5c42\u67b6\u6784\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6d41\u7a0b\u96c6\u6210\u4e86\u589e\u91cf\u5f00\u53d1\u548c\u591a\u7ef4\u5ea6\u9a8c\u8bc1\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u65e7\u7cfb\u7edf\u7684\u8fc1\u79fb\u6548\u7387\u548c\u8d28\u91cf\u3002", "motivation": "\u968f\u7740\u73b0\u4ee3\u8f6f\u4ef6\u6280\u672f\u7684\u53d1\u5c55\uff0c\u8d8a\u6765\u8d8a\u591a\u4f01\u4e1a\u5e0c\u671b\u5c06\u4e5d\u5341\u5e74\u4ee3\u6d41\u884c\u7684RAD\uff08\u5feb\u901f\u5e94\u7528\u5f00\u53d1\uff09\u5e73\u53f0\u4e0a\u7684\u65e7\u5e94\u7528\u8fc1\u79fb\u81f3\u65b0\u5e73\u53f0\uff0c\u5982Oracle Forms\u5e94\u7528\u8fc1\u79fb\u3002\u6b64\u8fc1\u79fb\u8fc7\u7a0b\u9762\u5bf9PL/SQL\u5355\u4f53\u4ee3\u7801\u5411\u73b0\u4ee3\u5206\u5c42Java\u4ee3\u7801\u8f6c\u5316\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u6a21\u578b\u9a71\u52a8\u7684\u518d\u5de5\u7a0b\u8fc7\u7a0b\uff0c\u5c06PL/SQL\u9057\u7559\u4ee3\u7801\u8f6c\u6362\u4e3aJava\u4ee3\u7801\uff0c\u5e76\u5c06\u9057\u7559\u4ee3\u7801\u4ee5KDM\uff08\u77e5\u8bc6\u53d1\u73b0\u5143\u6a21\u578b\uff09\u6a21\u578b\u8fdb\u884c\u8868\u793a\u3002\u63d0\u51fa\u4e86\u4e00\u4e2a\u6a21\u578b\u9a71\u52a8\u7684\u518d\u5de5\u7a0b\u8f6f\u4ef6\u6d41\u7a0b\uff0c\u96c6\u6210\u7c7b\u4f3cTDD\u7684\u65b9\u5f0f\uff0c\u9488\u5bf9\u751f\u6210\u4ee3\u7801\u8fdb\u884c\u4e09\u7c7b\u9a8c\u8bc1\uff0c\u7ec6\u81f4\u63cf\u8ff0\u4e86\u8fd9\u4e00\u8fc1\u79fb\u5de5\u5177\u7684\u5f00\u53d1\u4e0e\u9a8c\u8bc1\u6d41\u7a0b\u3002", "result": "\u5f00\u53d1\u51fa\u4e86\u7528\u4e8ePL/SQL\u5230\u5206\u5c42Java\u4ee3\u7801\u8fc1\u79fb\u7684\u6a21\u578b\u9a71\u52a8\u5de5\u5177\uff0c\u5b8c\u6210\u4e86\u5bf9\u518d\u5de5\u7a0b\u6d41\u7a0b\u7684\u5b9e\u73b0\u4e0e\u9a8c\u8bc1\uff0c\u5e76\u5bf9\u8fc1\u79fb\u8fc7\u7a0b\u4e2d\u7684\u4e00\u4e9bMDE\u5e94\u7528\u76f8\u5173\u95ee\u9898\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "conclusion": "\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\u4e0d\u4ec5\u9002\u7528\u4e8e\u65b0\u7cfb\u7edf\u5f00\u53d1\uff0c\u540c\u6837\u80fd\u9ad8\u6548\u5e94\u7528\u4e8e\u65e7\u7cfb\u7edf\u8fc1\u79fb\u3002\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u6a21\u578b\u9a71\u52a8\u518d\u5de5\u7a0b\u6d41\u7a0b\u53ca\u7efc\u5408\u9a8c\u8bc1\u63aa\u65bd\uff0c\u80fd\u591f\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7684\u9057\u7559\u4ee3\u7801\u5411\u73b0\u4ee3\u67b6\u6784\u8fc1\u79fb\u3002"}}
{"id": "2510.19897", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19897", "abs": "https://arxiv.org/abs/2510.19897", "authors": ["Jackson Hassell", "Dan Zhang", "Hannah Kim", "Tom Mitchell", "Estevam Hruschka"], "title": "Learning from Supervision with Semantic and Episodic Memory: A Reflective Approach to Agent Adaptation", "comment": "11 pages", "summary": "We investigate how agents built on pretrained large language models can learn\ntarget classification functions from labeled examples without parameter\nupdates. While conventional approaches like fine-tuning are often costly,\ninflexible, and opaque, we propose a memory-augmented framework that leverages\nboth labeled data and LLM-generated critiques. Our framework uses episodic\nmemory to store instance-level critiques-capturing specific past\nexperiences-and semantic memory to distill these into reusable, task-level\nguidance. Across a diverse set of tasks, incorporating critiques yields up to a\n24.8 percent accuracy improvement over retrieval-based (RAG-style) baselines\nthat rely only on labels. Through extensive empirical evaluation, we uncover\ndistinct behavioral differences between OpenAI and opensource models,\nparticularly in how they handle fact-oriented versus preference-based data. To\ninterpret how models respond to different representations of supervision\nencoded in memory, we introduce a novel metric, suggestibility. This helps\nexplain observed behaviors and illuminates how model characteristics and memory\nstrategies jointly shape learning dynamics. Our findings highlight the promise\nof memory-driven, reflective learning for building more adaptive and\ninterpretable LLM agents.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u7ed3\u5408\u6807\u6ce8\u6570\u636e\u548cLLM\u751f\u6210\u6279\u5224\u53cd\u9988\u7684\u8bb0\u5fc6\u589e\u5f3a\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u65e0\u9700\u5fae\u8c03\u53c2\u6570\u4e0b\u63d0\u5347\u591a\u4efb\u52a1\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u5e76\u901a\u8fc7\u521b\u65b0\u6027\u6307\u6807\u89e3\u91ca\u4e0d\u540cLLM\u8868\u73b0\uff0c\u663e\u793a\u51fa\u66f4\u5f3a\u7684\u81ea\u9002\u5e94\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5206\u7c7b\u4efb\u52a1\u5b66\u4e60\u4e3b\u8981\u4f9d\u8d56\u53c2\u6570\u5fae\u8c03\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u901a\u5e38\u6210\u672c\u9ad8\u3001\u7075\u6d3b\u6027\u5dee\u4e14\u96be\u4ee5\u89e3\u91ca\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f5c\u8005\u65e8\u5728\u63a2\u7d22\u65e0\u9700\u53c2\u6570\u66f4\u65b0\uff0c\u901a\u8fc7\u589e\u5f3a\u8bb0\u5fc6\u7ed3\u6784\u63d0\u5347\u5b66\u4e60\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5b9e\u4f8b\u7ea7\u6279\u5224\uff08episodic memory\uff09\u548c\u4efb\u52a1\u7ea7\u6279\u5224\uff08semantic memory\uff09\u7684\u8bb0\u5fc6\u589e\u5f3a\u6846\u67b6\uff0c\u5c06\u6807\u6ce8\u6570\u636e\u4e0eLLM\u751f\u6210\u7684\u6279\u5224\u6027\u53cd\u9988\u7ed3\u5408\uff0c\u7528\u4e8e\u6307\u5bfc\u6a21\u578b\u5b66\u4e60\u3002\u5e76\u63d0\u51fa\u4e86\"suggestibility\"\u8fd9\u4e00\u65b0\u9896\u6307\u6807\u6765\u89e3\u91ca\u548c\u8861\u91cf\u6a21\u578b\u5bf9\u4e0d\u540c\u76d1\u7763\u4fe1\u606f\u7684\u54cd\u5e94\u3002", "result": "\u5728\u591a\u4e2a\u591a\u6837\u5316\u4efb\u52a1\u4e0a\uff0c\u5229\u7528LLM\u751f\u6210\u7684\u6279\u5224\u53cd\u9988\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5bf9\u6bd4\u5355\u7eaf\u6807\u6ce8\u68c0\u7d22\u57fa\u7ebf\u6700\u591a\u53ef\u63d0\u534724.8%\u7684\u51c6\u786e\u7387\u3002\u540c\u65f6\uff0c\u5b9e\u9a8c\u63ed\u793a\u4e86OpenAI\u4e0e\u5f00\u6e90\u5927\u6a21\u578b\u5728\u5904\u7406\u4e8b\u5b9e\u578b\u4e0e\u504f\u597d\u578b\u6570\u636e\u4e0a\u7684\u660e\u663e\u5dee\u5f02\u3002", "conclusion": "\u8bb0\u5fc6\u9a71\u52a8\u3001\u53cd\u601d\u5f0f\u5b66\u4e60\u80fd\u591f\u8ba9LLM\u667a\u80fd\u4f53\u66f4\u52a0\u81ea\u9002\u5e94\u4e14\u53ef\u89e3\u91ca\uff0c\u5c55\u73b0\u51fa\u6bd4\u4f20\u7edf\u68c0\u7d22\u6a21\u578b\u66f4\u5927\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.20211", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20211", "abs": "https://arxiv.org/abs/2510.20211", "authors": ["Zhenning Yang", "Hui Guan", "Victor Nicolet", "Brandon Paulsen", "Joey Dodds", "Daniel Kroening", "Ang Chen"], "title": "Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents", "comment": null, "summary": "Cloud infrastructure is managed through a mix of interfaces -- traditionally,\ncloud consoles, command-line interfaces (CLI), and SDKs are the tools of\nchoice. Recently, Infrastructure-as-Code/IaC frameworks (e.g., Terraform) have\nquickly gained popularity. Unlike conventional tools, IaC~frameworks encode the\ninfrastructure in a \"source-of-truth\" configuration. They are capable of\nautomatically carrying out modifications to the cloud -- deploying, updating,\nor destroying resources -- to bring the actual infrastructure into alignment\nwith the IaC configuration. However, when IaC is used alongside consoles, CLIs,\nor SDKs, it loses visibility into external changes, causing infrastructure\ndrift, where the configuration becomes outdated, and later IaC operations may\nundo valid updates or trigger errors.\n  We present NSync, an automated system for IaC reconciliation that propagates\nout-of-band changes back into the IaC program. Our key insight is that\ninfrastructure changes eventually all occur via cloud API invocations -- the\nlowest layer for cloud management operations. NSync gleans insights from API\ntraces to detect drift (i.e., non-IaC changes) and reconcile it (i.e., update\nthe IaC configuration to capture the changes). It employs an agentic\narchitecture that leverages LLMs to infer high-level intents from noisy API\nsequences, synthesize targeted IaC updates using specialized tools, and\ncontinually improve through a self-evolving knowledge base of past\nreconciliations. We further introduce a novel evaluation pipeline for injecting\nrealistic drifts into cloud infrastructure and assessing reconciliation\nperformance. Experiments across five real-world Terraform projects and 372\ndrift scenarios show that NSync outperforms the baseline both in terms of\naccuracy (from 0.71 to 0.97 pass@3) and token efficiency (1.47$\\times$\nimprovement).", "AI": {"tldr": "NSync\u7cfb\u7edf\u901a\u8fc7\u8ffd\u8e2a\u4e91API\u8c03\u7528\u5e76\u7ed3\u5408LLM\u81ea\u52a8\u5316\u8bc6\u522b\u4e0e\u4fee\u6b63\u57fa\u7840\u8bbe\u65bd\u6f02\u79fb\uff0c\u5927\u5e45\u63d0\u5347\u4e86IaC\u914d\u7f6e\u4e0e\u5b9e\u9645\u72b6\u6001\u7684\u4e00\u81f4\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u51c6\u786e\u7387\u548c\u6548\u7387\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u4e91\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\u5de5\u5177\uff08\u5982\u63a7\u5236\u53f0\u3001CLI\u3001SDK\uff09\u4e0e\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801\uff08IaC\uff09\u5de5\u5177\u5e76\u5b58\u65f6\uff0cIaC\u5931\u53bb\u4e86\u5bf9\u5916\u90e8\u53d8\u66f4\u7684\u611f\u77e5\u80fd\u529b\uff0c\u5bfc\u81f4\u57fa\u7840\u8bbe\u65bd\u6f02\u79fb\uff0c\u9020\u6210\u914d\u7f6e\u5931\u6548\u3001\u8fd0\u7ef4\u9519\u8bef\u7b49\u95ee\u9898\u3002\u8be5\u95ee\u9898\u5728IaC\u5f97\u5230\u5e7f\u6cdb\u5e94\u7528\u7684\u73b0\u72b6\u4e0b\u5c24\u4e3a\u7a81\u51fa\u3002", "method": "\u63d0\u51fa\u4e86NSync\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u6790\u4e91API\u8c03\u7528\u75d5\u8ff9\u68c0\u6d4b\u975eIaC\u7684\u53d8\u66f4\uff08\u6f02\u79fb\uff09\uff0c\u91c7\u7528LLM\u63a8\u7406API\u8c03\u7528\u80cc\u540e\u7684\u610f\u56fe\uff0c\u5e76\u81ea\u52a8\u5316\u751f\u6210IaC\u66f4\u65b0\u4ee5\u4fdd\u6301\u914d\u7f6e\u540c\u6b65\u3002\u540c\u65f6NSync\u62e5\u6709\u81ea\u8fdb\u5316\u77e5\u8bc6\u5e93\uff0c\u80fd\u6301\u7eed\u4ece\u4ee5\u5f80\u7684\u5bf9\u9f50\u7ecf\u9a8c\u4e2d\u63d0\u5347\u6548\u679c\uff0c\u5e76\u8bbe\u8ba1\u4e86\u6ce8\u5165\u771f\u5b9e\u6f02\u79fb\u7684\u8bc4\u6d4b\u6d41\u7a0b\u3002", "result": "\u57285\u4e2a\u771f\u5b9eTerraform\u9879\u76ee\u548c372\u4e2a\u6f02\u79fb\u573a\u666f\u4e2d\uff0cNSync\u5728\u51c6\u786e\u7387\u4e0a\u663e\u8457\u8d85\u8fc7\u57fa\u7ebf\u65b9\u6cd5\uff08pass@3\u4ece0.71\u63d0\u5347\u52300.97\uff09\uff0c\u4e14token\u6548\u7387\u63d0\u5347\u4e861.47\u500d\u3002", "conclusion": "NSync\u6709\u6548\u89e3\u51b3\u4e86IaC\u4e0e\u4f20\u7edf\u4e91\u7ba1\u7406\u5de5\u5177\u5171\u5b58\u9020\u6210\u7684\u57fa\u7840\u8bbe\u65bd\u6f02\u79fb\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u51c6\u786e\u7684\u81ea\u52a8\u5316\u5bf9\u9f50\u3002"}}
