<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 11]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.CL](#cs.CL) [Total: 37]
- [cs.DM](#cs.DM) [Total: 2]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Domain Knowledge in Requirements Engineering: A Systematic Mapping Study](https://arxiv.org/abs/2506.20754)
*Marina Araújo,Júlia Araújo,Romeu Oliveira,Lucas Romao,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 本论文系统性地梳理了领域知识在需求工程中的应用现状，分析了文献中的主流方法、关注点及挑战，总结了现有进展与未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 领域知识是需求工程（RE）成功的关键要素，有助于理解系统背景、满足利益相关方需求并减少需求规格描述的歧义。然而，现有文献缺乏系统梳理如何在RE中有效运用和操作领域知识。

Method: 采用系统化映射研究（systematic mapping study），结合数据库检索与正反向滚雪球法，调查领域知识在需求工程中的应用文献。

Result: 共纳入75篇论文，分析了被关注的主要需求类型、常见的质量属性，以及领域知识规范化、获取和长期维护中的挑战。研究总结了现有方法和未解决问题，并提出未来应发展可扩展、自动化与可持续将领域知识集成于RE过程的方案。

Conclusion: 本研究通过综合性梳理，为知识驱动的需求工程构建了概念和方法基础，有助于推动相关研究和实践。

Abstract: [Context] Domain knowledge is recognized as a key component for the success
of Requirements Engineering (RE), as it provides the conceptual support needed
to understand the system context, ensure alignment with stakeholder needs, and
reduce ambiguity in requirements specification. Despite its relevance, the
scientific literature still lacks a systematic consolidation of how domain
knowledge can be effectively used and operationalized in RE. [Goal] This paper
addresses this gap by offering a comprehensive overview of existing
contributions, including methods, techniques, and tools to incorporate domain
knowledge into RE practices. [Method] We conducted a systematic mapping study
using a hybrid search strategy that combines database searches with iterative
backward and forward snowballing. [Results] In total, we found 75 papers that
met our inclusion criteria. The analysis highlights the main types of
requirements addressed, the most frequently considered quality attributes, and
recurring challenges in the formalization, acquisition, and long-term
maintenance of domain knowledge. The results provide support for researchers
and practitioners in identifying established approaches and unresolved issues.
The study also outlines promising directions for future research, emphasizing
the development of scalable, automated, and sustainable solutions to integrate
domain knowledge into RE processes. [Conclusion] The study contributes by
providing a comprehensive overview that helps to build a conceptual and
methodological foundation for knowledge-driven requirements engineering.

</details>


### [2] [Agile Management for Machine Learning: A Systematic Mapping Study](https://arxiv.org/abs/2506.20759)
*Lucas Romao,Hugo Villamizar,Romeu Oliveira,Silvio Alonso,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 本文系统梳理了机器学习系统敏捷管理领域的研究，归纳出关键框架和主题，并指出工作量估算等主要挑战，呼吁进一步的实证研究。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习系统正在快速发展，但其高度动态性和实验性使得传统项目管理方法难以适用。敏捷方法表面上契合这些特点，但具体如何在ML系统中有效应用还不清楚，因此有必要系统梳理现有研究和最佳实践。

Method: 采用系统化映射研究法，结合数据库检索与前后向滚雪球搜索，全面查阅与敏捷管理ML系统相关的文献。

Result: 共筛选出27篇自2008年至2024年发表的相关论文，从中总结出8个框架，并将建议和实践归类为8个关键主题，如迭代灵活性、创新的ML专用工件以及最小可行模型等。主要挑战在于对ML任务进行准确的工作量估算。

Conclusion: 本研究全面梳理了ML系统敏捷管理的研究现状，指出了该领域的开放性问题。虽然已有一定研究基础，但仍需更有说服力的实证验证来支撑现有贡献。

Abstract: [Context] Machine learning (ML)-enabled systems are present in our society,
driving significant digital transformations. The dynamic nature of ML
development, characterized by experimental cycles and rapid changes in data,
poses challenges to traditional project management. Agile methods, with their
flexibility and incremental delivery, seem well-suited to address this
dynamism. However, it is unclear how to effectively apply these methods in the
context of ML-enabled systems, where challenges require tailored approaches.
[Goal] Our goal is to outline the state of the art in agile management for
ML-enabled systems. [Method] We conducted a systematic mapping study using a
hybrid search strategy that combines database searches with backward and
forward snowballing iterations. [Results] Our study identified 27 papers
published between 2008 and 2024. From these, we identified eight frameworks and
categorized recommendations and practices into eight key themes, such as
Iteration Flexibility, Innovative ML-specific Artifacts, and the Minimal Viable
Model. The main challenge identified across studies was accurate effort
estimation for ML-related tasks. [Conclusion] This study contributes by mapping
the state of the art and identifying open gaps in the field. While relevant
work exists, more robust empirical evaluation is still needed to validate these
contributions.

</details>


### [3] [Generating Reliable Adverse event Profiles for Health through Automated Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach](https://arxiv.org/abs/2506.20851)
*Srikar Reddy Gadusu,Larry Callahan,Samir Lababidi,Arunasri Nishtala,Sophia Healey,Hande McGinty*

Main category: cs.SE

TL;DR: 本文提出用Python和rdflib库实现Neo4j数据库向OWL本体的自动转换，简化了数据集成流程，降低了技术门槛，为药物不良事件大数据的知识图谱构建和公共健康决策提供支持。


<details>
  <summary>Details</summary>
Motivation: 随着数据量和知识的急剧增长，系统化的本体（ontology）生成方法日益重要。而大数据量和内容变更频繁导致对数据库存储与检索、以及知识图谱创建的需求迅速加大。此前提出的方法学在实际操作中面临Neo4j数据库与Web Ontology Language（OWL）结合难度较大，并且现有方法普遍要求用户掌握描述逻辑（DL）语法，这对普通用户不够友好。

Method: 本论文提出了一种用户友好的方法，利用Python及其rdflib库来支持本体开发。通过将来自FDA不良事件报告系统（FAERS）数据库的数据存入Neo4j，再利用Python脚本自动生成所需类及其公理，实现了从Neo4j到OWL的便捷集成。

Result: 该方法通过实际案例展示如何自动生成本体类和公理，有效提升Neo4j数据与OWL的集成流程，尤其适用于庞大且不断增长的不良药物事件数据集。本方法为药物安全监测与公共卫生决策提供了更高效的技术手段。

Conclusion: 提出了一种简单易用、自动化程度高的Neo4j与OWL本体集成方法，不需要深厚的描述逻辑知识，降低用户门槛，提升数据驱动知识图谱和本体构建的效率，对药品安全领域等大数据环境下的本体化应用具有实际价值。

Abstract: As data and knowledge expand rapidly, adopting systematic methodologies for
ontology generation has become crucial. With the daily increases in data
volumes and frequent content changes, the demand for databases to store and
retrieve information for the creation of knowledge graphs has become
increasingly urgent. The previously established Knowledge Acquisition and
Representation Methodology (KNARM) outlines a systematic approach to address
these challenges and create knowledge graphs. However, following this
methodology highlights the existing challenge of seamlessly integrating Neo4j
databases with the Web Ontology Language (OWL). Previous attempts to integrate
data from Neo4j into an ontology have been discussed, but these approaches
often require an understanding of description logics (DL) syntax, which may not
be familiar to many users. Thus, a more accessible method is necessary to
bridge this gap. This paper presents a user-friendly approach that utilizes
Python and its rdflib library to support ontology development. We showcase our
novel approach through a Neo4j database we created by integrating data from the
Food and Drug Administration (FDA) Adverse Event Reporting System (FAERS)
database. Using this dataset, we developed a Python script that automatically
generates the required classes and their axioms, facilitating a smoother
integration process. This approach offers a practical solution to the
challenges of ontology generation in the context of rapidly growing adverse
drug event datasets, supporting improved drug safety monitoring and public
health decision-making.

</details>


### [4] [Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation](https://arxiv.org/abs/2506.20869)
*Md Toufique Hasan,Muhammad Waseem,Kai-Kristian Kemell,Ayman Asad Khan,Mika Saari,Pekka Abrahamsson*

Main category: cs.SE

TL;DR: 本文在五大领域开发并评估了RAG系统，通过用户参与提炼出12条关键经验，针对RAG实际应用过程中的技术与伦理挑战，提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 现有RAG（Retrieval-Augmented Generation，检索增强生成）系统在提升大模型事实准确性和背景相关性方面表现突出，但缺乏实际案例、用户参与和系统性经验分享的实证研究。

Method: 开发了五个面向治理、网络安全、农业、工业研究、医疗诊断领域的RAG应用系统，融合多语种OCR、语义向量检索和领域自适应大模型，通过本地或云端服务部署。邀请100名用户参与网络评估，从六个维度对系统进行评价。

Result: 用户从易用性、相关性、透明度、响应速度、准确性和推荐意愿六个方面对系统进行评价，总结出12条关键经验，涵盖了技术、运营与伦理挑战。

Conclusion: 实际RAG系统落地面临多维度挑战，用户反馈与开发经验为提高RAG系统可靠性和可用性提供了有价值的指导。

Abstract: Retrieval-Augmented Generation (RAG) systems are emerging as a key approach
for grounding Large Language Models (LLMs) in external knowledge, addressing
limitations in factual accuracy and contextual relevance. However, there is a
lack of empirical studies that report on the development of RAG-based
implementations grounded in real-world use cases, evaluated through general
user involvement, and accompanied by systematic documentation of lessons
learned. This paper presents five domain-specific RAG applications developed
for real-world scenarios across governance, cybersecurity, agriculture,
industrial research, and medical diagnostics. Each system incorporates
multilingual OCR, semantic retrieval via vector embeddings, and domain-adapted
LLMs, deployed through local servers or cloud APIs to meet distinct user needs.
A web-based evaluation involving a total of 100 participants assessed the
systems across six dimensions: (i) Ease of Use, (ii) Relevance, (iii)
Transparency, (iv) Responsiveness, (v) Accuracy, and (vi) Likelihood of
Recommendation. Based on user feedback and our development experience, we
documented twelve key lessons learned, highlighting technical, operational, and
ethical challenges affecting the reliability and usability of RAG systems in
practice.

</details>


### [5] [Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance](https://arxiv.org/abs/2506.20883)
*Kyanna Dagenais,Istvan David*

Main category: cs.SE

TL;DR: 该论文提出用强化学习结合不确定的人类建议，以高效开发复杂模型转换序列，实验证明人类参与能显著提升RL在复杂场景下的表现，推进了人机协同工程范式。


<details>
  <summary>Details</summary>
Motivation: 模型驱动工程中的复杂模型转换（MTs），如模型同步、自动化模型修复和设计空间探索，需要长链的转换序列，手动开发这些复杂序列容易出错甚至不可行。

Method: 提出了一个技术框架，将用户定义的模型转换映射为强化学习（RL）原语，并作为RL程序执行来寻找最优的模型转换序列，同时允许不确定的人类建议指导RL过程。

Result: 实验表明，即使人类建议存在不确定性，也能显著提升强化学习的性能，使复杂模型转换的开发更加高效。

Conclusion: 通过在RL过程中引入人类建议（即便不确定），本方法显著改进了复杂模型转换问题的求解效率，为人机协同的强化学习工程方法迈出了重要一步。

Abstract: Model-driven engineering problems often require complex model transformations
(MTs), i.e., MTs that are chained in extensive sequences. Pertinent examples of
such problems include model synchronization, automated model repair, and design
space exploration. Manually developing complex MTs is an error-prone and often
infeasible process. Reinforcement learning (RL) is an apt way to alleviate
these issues. In RL, an autonomous agent explores the state space through trial
and error to identify beneficial sequences of actions, such as MTs. However, RL
methods exhibit performance issues in complex problems. In these situations,
human guidance can be of high utility. In this paper, we present an approach
and technical framework for developing complex MT sequences through RL, guided
by potentially uncertain human advice. Our framework allows user-defined MTs to
be mapped onto RL primitives, and executes them as RL programs to find optimal
MT sequences. Our evaluation shows that human guidance, even if uncertain,
substantially improves RL performance, and results in more efficient
development of complex MTs. Through a trade-off between the certainty and
timeliness of human advice, our method takes a step towards RL-driven
human-in-the-loop engineering methods.

</details>


### [6] [Boosting Vulnerability Detection with Inter-function Multilateral Association Insights](https://arxiv.org/abs/2506.21014)
*Shaojian Qiu,Mengyang Huang,Jiahao Cheng*

Main category: cs.SE

TL;DR: 该论文提出了一个结合代码行为超图和超边卷积的多函数关联漏洞检测框架IFMA-VD，能提升多种数据集下的检测性能，并增强代码特征表征。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数基于深度学习的漏洞检测方法主要关注单独的函数，忽视了函数之间复杂的多边关联，容易漏检存在于这些关系中的漏洞。

Method: 提出了一个名为IFMA-VD（Inter-Function Multilateral Association analysis framework for Vulnerability Detection）的框架，核心是构建代码行为超图，并利用超边卷积提取多边关联特征。具体包括将函数解析为代码属性图生成函数内部特征，构建代码行为超图并对行为特征进行编码，最后利用超图网络捕获多边关联知识以增强漏洞检测。

Result: 在三个广泛使用的漏洞数据集上评估了IFMA-VD，并在F-measure和Recall等指标上相比基线方法均有提升，同时在真实数据集上也验证了其有效性。多边关联特征可以增强代码特征表征能力。

Conclusion: IFMA-VD能够有效挖掘跨函数的多边关联特征，显著提升了漏洞检测的性能。

Abstract: Vulnerability detection is a crucial yet challenging technique for ensuring
the security of software systems. Currently, most deep learning-based
vulnerability detection methods focus on stand-alone functions, neglecting the
complex inter-function interrelations, particularly the multilateral
associations. This oversight can fail to detect vulnerabilities in these
interrelations. To address this gap, we present an Inter-Function Multilateral
Association analysis framework for Vulnerability Detection (IFMA-VD). The
cornerstone of the IFMA-VD lies in constructing a code behavior hypergraph and
utilizing hyperedge convolution to extract multilateral association features.
Specifically, we first parse functions into a code property graph to generate
intra-function features. Following this, we construct a code behavior
hypergraph by segmenting the program dependency graph to isolate and encode
behavioral features into hyperedges. Finally, we utilize a hypergraph network
to capture the multilateral association knowledge for augmenting vulnerability
detection. We evaluate IFMA-VD on three widely used vulnerability datasets and
demonstrate improvements in F-measure and Recall compared to baseline methods.
Additionally, we illustrate that multilateral association features can boost
code feature representation and validate the effectiveness of IFMA-VD on
real-world datasets.

</details>


### [7] [How Good Are Synthetic Requirements ? Evaluating LLM-Generated Datasets for AI4RE](https://arxiv.org/abs/2506.21138)
*Abdelkarim El-Hajjami,Camille Salinesi*

Main category: cs.SE

TL;DR: 提出的Synthline v1能通过多样采样和提示优化生成高质量合成需求数据，并在安全与缺陷分类等任务上超过人工数据。方法可有效解决AI4RE领域公共数据集短缺问题，为数据集合成提供了实践路径。


<details>
  <summary>Details</summary>
Motivation: 在人工智能用于需求工程（AI4RE）领域，缺乏公开且带标签的需求数据集限制了研究进展。虽然大语言模型擅长生成合成数据，但对于如何系统性地优化和提升其生成的数据质量，现有研究尚不足。

Method: 作者提出了Synthline v1，这是一种增强型产品线生成合成需求数据的方法。该方法在旧版基础上，增加了高级生成策略和筛选技术。实验设计包括四个分类任务：缺陷检测、功能/非功能、质量/非质量、安全/非安全，并探讨了不同提示策略、多样化采样、自动化提示优化（如PACE）和相似度筛选对数据质量的影响。

Result: 多样采样生成相比单一样本，能显著提升数据的实际效用和多样性，F1分数最大提升达44分。PACE可自动优化提示，对功能分类提升显著（+32.5分），但对其他任务有时反而降低效果。基于相似度的筛选能提升多样性，但常损害分类表现，说明一定冗余对模型有效。最重要的是，对于特定任务，比如安全与缺陷分类，合成数据已优于人工数据，提升分别为7.8和15.4分。

Conclusion: 合成需求数据通过系统性生成策略，能达到甚至超越人工数据的效果。该研究为AI4RE领域解决数据匮乏、提升数据品质提供了有效、可行的途径，也为将合成数据广泛应用于实际做出指导。

Abstract: The shortage of publicly available, labeled requirements datasets remains a
major barrier to advancing Artificial Intelligence for Requirements Engineering
(AI4RE). While Large Language Models offer promising capabilities for synthetic
data generation, systematic approaches to control and optimize the quality of
generated requirements remain underexplored. This paper presents Synthline v1,
an enhanced Product Line approach for generating synthetic requirements data
that extends our earlier v0 version with advanced generation strategies and
curation techniques. We investigate four research questions assessing how
prompting strategies, automated prompt optimization, and post-generation
curation affect data quality across four classification tasks: defect
detection, functional vs. non-functional, quality vs. non-quality, and security
vs. non-security. Our evaluation shows that multi-sample prompting
significantly boosts both utility and diversity over single-sample generation,
with F1-score gains from 6 to 44 points. The use of PACE (Prompt Actor-Critic
Editing) for automated prompt optimization yields task-dependent results,
greatly improving functional classification (+32.5 points) but reducing
performance on others. Interestingly, similarity-based curation improves
diversity but often harms classification performance, indicating that some
redundancy may help ML models. Most importantly, our results show that
synthetic requirements can match or outperform human-authored ones for specific
tasks, with synthetic data surpassing human data for security (+7.8 points) and
defect classification (+15.4 points). These findings offer practical insights
for AI4RE and chart a viable path to mitigating dataset scarcity through
systematic synthetic generation.

</details>


### [8] [$T^3$: Multi-level Tree-based Automatic Program Repair with Large Language Models](https://arxiv.org/abs/2506.21211)
*Quanming Liu,Xupeng Bu,Zhichao Yan,Ru Li*

Main category: cs.SE

TL;DR: 本文创新性地将大语言模型推理与树搜索结合提出T^3框架，系统提升了自动程序修复的准确性和效率，对自动化调试领域具重要推动作用。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型和CoT技巧极大提升了模型推理能力，但由于自动程序修复任务需要复杂、多步推理，目前CoT在APR领域的应用尚且不足，亟需有效的结合方案。

Method: 系统评估了多种常见Chain-of-Thought（CoT）技术在自动程序修复（APR）中的表现，并创新性地将LLM和树搜索结合，以提高修复候选生成的精度及指导样本选择与修复策略优化。

Result: 所提T^3框架提升了修复候选方案生成的准确性，并为样本选择和修复策略优化带来指导，显著提升了自动程序修复的效率和效果。

Conclusion: 论文提出了创新性框架T^3，将大语言模型（LLM）的推理能力与树搜索方法结合，有效提升了自动程序修复（APR）任务中生成候选修复方案的精准度，为自动化调试提供了高效且可靠的框架。

Abstract: Automatic Program Repair (APR) is a core technology in software development
and maintenance, with aims to enable automated defect repair with minimal human
intervention. In recent years, the substantial advancements in Large Language
Models (LLMs) and the Chain-of-Thought (CoT) techniques have significantly
enhanced the reasoning capabilities of these models. However, due to the
complex logic and multi-step reasoning ability needed, the application of CoT
techniques in the APR domain remains insufficient. This study systematically
evaluates the performance of several common CoT techniques in APR tasks and
proposes an innovative framework $T^3$, which integrates the powerful reasoning
capabilities of LLMs with tree search, effectively improving the precision of
generating candidate repair solutions. Furthermore, $T^3$ provides valuable
guidance for optimizing sample selection and repair strategies in APR tasks,
establishing a robust framework for achieving efficient automated debugging.

</details>


### [9] [KOALA: a Configurable Tool for Collecting IDE Data When Solving Programming Tasks](https://arxiv.org/abs/2506.21266)
*Daniil Karol,Elizaveta Artser,Ilya Vlasov,Yaroslav Golubev,Hieke Keuning,Anastasiia Birillo*

Main category: cs.SE

TL;DR: 作者提出了KOALA插件，实现了对学生在JetBrains IDE中编程任务时多粒度数据的灵活收集，解决了现有工具在数据详尽程度和配置便利性上的缺陷，并通过教学实例证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的数据收集工具在学生编程任务中的使用有限，如无法控制数据收集的粒度、无法收集编程环境中的具体操作事件，以及配置困难等问题。因此亟需一个更加灵活且易于配置的工具。

Method: 作者提出并实现了KOALA插件，该工具可以集成到JetBrains IDE中，实现对学生编程过程中的代码快照、IDE特性使用情况的高粒度收集。插件支持个性化配置任务、启用/禁用IDE功能、进行问卷调查，并可监控如运行、调试、快捷键使用、在文件间切换等具体行为。收集的数据可以通过配套服务器储存，并转换为标准格式（ProgSnap2），方便后续分析。

Result: KOALA在两个课程的任务实践中被28名学生使用，成功收集到了丰富的编程行为数据，包括以往工具未能获取的如热键和文件切换等操作数据。并展示了部分数据分析结果，证明了插件的效力和灵活性。

Conclusion: KOALA插件克服了现有工具的主要局限，能够高效且细致地收集学生编程过程中的多维数据，为后续编程教育研究和数据分析工作提供了重要基础。

Abstract: Collecting data of students solving programming tasks is incredibly valuable
for researchers and educators. It allows verifying that the students correctly
apply the features and concepts they are taught, or finding students'
misconceptions. However, existing data collection tools have limitations, e.g.,
no control over the granularity of the collected code, not collecting the
specific events of the programming environment used, and overall being hard to
configure.
  To overcome these limitations, we propose KOALA, a convenient and highly
configurable tool for collecting code snapshots and feature usage from students
solving programming tasks in JetBrains IDEs. The plugin can be installed in
IDEs and configured to provide the students with the necessary tasks, enable or
disable certain IDE features like code completion, and run surveys. During
problem solving, the plugin collects code snapshots at the configured
granularity, all IDE actions like running and debugging, as well as some data
not collected in prior works, like employed hotkeys and switching focus between
files. The collected data is sent to the server that comes with the tool, where
it is stored and can be converted to the standardized ProgSnap2 format. To
showcase the tool, we collected data from 28 students solving tasks in two
courses within the IDE, highlighting some insights from this data.

</details>


### [10] [Exploring Micro Frontends: A Case Study Application in E-Commerce](https://arxiv.org/abs/2506.21297)
*Ricardo Hideki Hangai Kojo,Luiz Fernando Corte Real,Renato Cordeiro Ferreira,Thatiane de Oliveira Rosa,Alfredo Goldman*

Main category: cs.SE

TL;DR: 本文通过文献调研与实用案例，分析了微前端架构在实际企业中的应用与成效。尽管微前端带来便利和部分优势，但其采用需结合企业现状和目标进行权衡，不是所有情境下的最佳选择。


<details>
  <summary>Details</summary>
Motivation: 微前端架构旨在提升前端系统的可扩展性、弹性和团队独立性，但带来更高复杂性和基础设施需求。本文旨在探讨在企业环境下，何时值得采用微前端架构。

Method: （1）通过分析学术界和行业灰色文献，研究微前端的最新进展；（2）在已采用微服务的手工艺品市场平台上实施微前端架构；（3）通过半开放问卷对开发者进行评估。

Result: 案例公司采用微前端（结合API Gateway与Backend for Frontend模式，以及Svelte和Fastify技术）成功改善了与后端耦合、技术老化和开发体验问题，但分析显示并非唯一或必要选择，单体前端也能实现类似目标。最终，因公司已有微服务基础设施，微前端的实施便利与团队知识共享成为关键优势。

Conclusion: 微前端架构在存在既有微服务和分阶段解耦需求的企业中更具优势，但在某些场景下，单体前端或许同样有效，需根据具体环境权衡选择。

Abstract: In the micro frontends architectural style, the frontend is divided into
smaller components, which can range from a simple button to an entire page. The
goal is to improve scalability, resilience, and team independence, albeit at
the cost of increased complexity and infrastructure demands. This paper seeks
to understand when it is worth adopting micro frontends, particularly in the
context of industry. To achieve this, we conducted an investigation into the
state of the art of micro frontends, based on both academic and gray
literature. We then implemented this architectural style in a marketplace for
handcrafted products, which already used microservices. Finally, we evaluated
the implementation through a semi-open questionnaire with the developers. At
the studied marketplace company, the need for architectural change arose due to
the tight coupling between their main system (a Java monolith) and a dedicated
frontend system. Additionally, there were deprecated technologies and poor
developer experience. To address these issues, the micro frontends architecture
was adopted, along with the API Gateway and Backend for Frontend patterns, and
technologies such as Svelte and Fastify. Although the adoption of Micro
Frontends was successful, it was not strictly necessary to meet the company's
needs. According to the analysis of the mixed questionnaire responses, other
alternatives, such as a monolithic frontend, could have achieved comparable
results. What made adopting micro frontends the most convenient choice in the
company's context was the monolith strangulation and microservices adoption,
which facilitated implementation through infrastructure reuse and knowledge
sharing between teams.

</details>


### [11] [An object-centric core metamodel for IoT-enhanced event logs](https://arxiv.org/abs/2506.21300)
*Yannis Bertrand,Christian Imenkamp,Lukas Malburg,Matthias Ehrendorfer,Marco Franceschetti,Joscha Grüger,Francesco Leotta,Jürgen Mangler,Ronny Seiger,Agnes Koschmider,Stefanie Rinderle-Ma,Barbara Weber,Estefania Serral*

Main category: cs.SE

TL;DR: 物联网数据与传统流程数据的融合为流程挖掘带来新机遇，但现有数据模型碎片化。本文提出通用核心模型，提高数据共享与协作，并通过原型系统和多用例验证其实用性。


<details>
  <summary>Details</summary>
Motivation: 随着物联网（IoT）技术的发展，越来越多组织将IoT设备集成到业务流程中，从而产生大量IoT数据，这些数据为业务流程挖掘（PM）提供了丰富的资源。但IoT数据和传统流程数据在粒度等多方面特性存在显著差异，数据融合极具挑战。现有多种数据模型各自为政，导致数据交换和协作变得困难。

Method: 本文提出了一个综合现有数据模型重要特性的核心数据模型，并依据通用需求进行设计，以方便数据共享与协作。同时，开发了基于Python的原型实现，通过多个用例对模型进行了评估。

Result: 该核心模型在满足通用需求的基础上，提高了数据在流程挖掘领域的共享与协作能力，并通过原型和用例验证了其实用性和有效性。

Conclusion: 通过提出并验证一个基于共性需求的核心数据模型，有效解决了IoT与业务流程数据集成的碎片化问题，促进了流程挖掘领域的数据共享与研究合作。

Abstract: Advances in Internet-of-Things (IoT) technologies have prompted the
integration of IoT devices with business processes (BPs) in many organizations
across various sectors, such as manufacturing, healthcare and smart spaces. The
proliferation of IoT devices leads to the generation of large amounts of IoT
data providing a window on the physical context of BPs, which facilitates the
discovery of new insights about BPs using process mining (PM) techniques.
However, to achieve these benefits, IoT data need to be combined with
traditional process (event) data, which is challenging due to the very
different characteristics of IoT and process data, for instance in terms of
granularity levels. Recently, several data models were proposed to integrate
IoT data with process data, each focusing on different aspects of data
integration based on different assumptions and requirements. This fragmentation
hampers data exchange and collaboration in the field of PM, e.g., making it
tedious for researchers to share data. In this paper, we present a core model
synthesizing the most important features of existing data models. As the core
model is based on common requirements, it greatly facilitates data sharing and
collaboration in the field. A prototypical Python implementation is used to
evaluate the model against various use cases and demonstrate that it satisfies
these common requirements.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [12] [Pebble Games and Algebraic Proof Systems](https://arxiv.org/abs/2506.21149)
*Lisa-Marie Jaser,Jacobo Toran*

Main category: cs.LO

TL;DR: 本文建立了卵石游戏与代数证明系统之间的紧密联系，揭示了Peb$(G)$复杂度各项指标在系统中的严格对应，并用此导出度量分离和折中关系，对理论计算复杂性和证明复杂性研究具有指导意义。


<details>
  <summary>Details</summary>
Motivation: 探讨代数证明系统（NS, MC, PC）与图论中卵石游戏之间的复杂性联系，以及如何通过图结构获得证明系统的复杂性界限和分离。

Method: 通过分析Peb$(G)$公式在Monomial Calculus等代数证明系统中的反驳，以及黑色卵石法在DAG图上的策略，构建了它们之间的严格映射和复杂度关系，并用图论已知界限推出变量空间分离。

Result: 证明了Monomial Calculus反驳的度和规模与黑卵石策略在空间和时间复杂度上的等价，推广了原有NS案例的结果，展示了度-空间、度-规模之间的严格折中关系。同时获得变量空间度量上的分离，并澄清了三类卵石游戏与证明系统之间的完美对应。

Conclusion: 论文揭示了Peb$(G)$反驳在不同类型卵石游戏与三种代数证明系统（Nullstellensatz、Monomial Calculus、Polynomial Calculus）之间存在强烈的对应关系，空间复杂度精确匹配，并由此得出复杂性分离结果。

Abstract: Analyzing refutations of the well known 0pebbling formulas Peb$(G)$ we prove
some new strong connections between pebble games and algebraic proof system,
showing that there is a parallelism between the reversible, black and
black-white pebbling games on one side, and the three algebraic proof systems
Nullstellensatz, Monomial Calculus and Polynomial Calculus on the other side.
In particular we prove that for any DAG $G$ with a single sink, if there is a
Monomial Calculus refutation for Peb$(G)$ having simultaneously degree $s$ and
size $t$ then there is a black pebbling strategy on $G$ with space $s$ and time
$t+s$. Also if there is a black pebbling strategy for $G$ with space $s$ and
time $t$ it is possible to extract from it a MC refutation for Peb$(G)$ having
simultaneously degree $s$ and size $ts$. These results are analogous to those
proven in {deRezende et al.21} for the case of reversible pebbling and
Nullstellensatz. Using them we prove degree separations between NS, MC and PC,
as well as strong degree-size tradeoffs for MC.
  We also notice that for any directed acyclic graph $G$ the space needed in a
pebbling strategy on $G$, for the three versions of the game, reversible, black
and black-white, exactly matches the variable space complexity of a refutation
of the corresponding pebbling formula Peb$(G)$ in each of the algebraic proof
systems NS, MC and PC. Using known pebbling bounds on graphs, this connection
implies separations between the corresponding variable space measures.

</details>


### [13] [Deciding Robust Instances of an Escape Problem for Dynamical Systems in Euclidean Space](https://arxiv.org/abs/2506.21481)
*Eike Neumann*

Main category: cs.LO

TL;DR: 该论文提出了一种在实数计算bit模型下针对连续映射点逃逸判定的部分完备方法，该方法对所有鲁棒问题实例均可终止，广泛适用于不同函数，部分解答了Mandelbrot集可判定性的长期问题。


<details>
  <summary>Details</summary>
Motivation: 在实数计算的bit模型下，研究连续映射下点是否能逃离闭集合的问题，特别关注问题在扰动下的鲁棒性及其可判定性。该问题与动力系统的可计算性及著名的 Mandelbrot 集相关，并回应了 Penrose 提出的问题。

Method: 提出了一种可靠的部分决策方法来判定点逃逸问题。通过对鲁棒性实例进行分析，证明所设计的方法在所有健壮实例上都可终止，并与所有其他可靠部分决策方法的停机集合对齐。算法适用于一般连续函数，并特别分析了仿射线性系统和二次复多项式等刚性函数族。

Result: 算法在所有对函数扰动鲁棒的问题实例上都可终止，其停机集合在所有问题实例集合中是稠密的。在仿射线性系统和二次复多项式（假设超越性密度猜想成立）中，该算法也是完备的。为 Mandelbrot 集的可判定性提供了另一种证明方式。

Conclusion: 提出的方法为点逃逸判定问题提供了最强的部分决策手段，并在特定函数族（如二次复多项式）上达到完备性（条件成立时），深化了动力系统可计算性理论，并回应了 Penrose 等著名问题。

Abstract: We study the problem of deciding whether a point escapes a closed subset of
$\mathbb{R}^d$ under the iteration of a continuous map $f \colon \mathbb{R}^d
\to \mathbb{R}^d$ in the bit-model of real computation. We give a sound partial
decision method for this problem which is complete in the sense that its
halting set contains the halting set of all sound partial decision methods for
the problem. Equivalently, our decision method terminates on all problem
instances whose answer is robust under all sufficiently small perturbations of
the function. We further show that the halting set of our algorithm is dense in
the set of all problem instances. While our algorithm applies to general
continuous functions, we demonstrate that it also yields complete decision
methods for much more rigid function families: affine linear systems and
quadratic complex polynomials. In the latter case, completeness is subject to
the density of hyperbolicity conjecture in complex dynamics. This in particular
yields an alternative proof of Hertling's (2004) conditional answer to a
question raised by Penrose (1989) regarding the computability of the Mandelbrot
set.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [14] [Towards Probabilistic Question Answering Over Tabular Data](https://arxiv.org/abs/2506.20747)
*Chen Shen,Sajjadur Rahman,Estevam Hruschka*

Main category: cs.CL

TL;DR: 提出了利用贝叶斯网络与大语言模型结合的新表格概率问答框架，实验优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的表格问答系统（如NL2SQL）能很好地处理事实型问题，但在需要不确定性推理的概率型问题上表现不佳。因此，提升表格数据下概率性问答的能力成为新挑战。

Method: 提出了一个新的基准LUCARIO和一个针对大规模表格数据概率性问答的框架。该方法从表格中诱导生成贝叶斯网络，将自然语言问题转化为概率性查询，并利用大语言模型（LLMs）生成最终答案。

Result: 实验结果表明，该方法在概率表格问答任务上较基线有显著提升，验证了符号与神经网络混合推理的优势。

Conclusion: 混合符号-神经推理方法能够有效提升对表格数据下概率性问题的问答能力，补足了现有NL2SQL等方法的不足。

Abstract: Current approaches for question answering (QA) over tabular data, such as
NL2SQL systems, perform well for factual questions where answers are directly
retrieved from tables. However, they fall short on probabilistic questions
requiring reasoning under uncertainty. In this paper, we introduce a new
benchmark LUCARIO and a framework for probabilistic QA over large tabular data.
Our method induces Bayesian Networks from tables, translates natural language
queries into probabilistic queries, and uses large language models (LLMs) to
generate final answers. Empirical results demonstrate significant improvements
over baselines, highlighting the benefits of hybrid symbolic-neural reasoning.

</details>


### [15] [Multi-lingual Functional Evaluation for Large Language Models](https://arxiv.org/abs/2506.20793)
*Victor Ojewale,Inioluwa Deborah Raji,Suresh Venkatasubramanian*

Main category: cs.CL

TL;DR: 本文提出两种多语言功能性基准CL-GSM Symbolic与CL-IFEval，发现主流多语言大模型在这些基准上的表现普遍低于静态评测，模型在不同语言间的鲁棒性存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 目前通用Benchmarks如Belebele、M-MMLU和M-GSM等多为静态数据，无法充分评估大语言模型在多语言环境中的实用性能和鲁棒性，因此需引入更具实际应用价值的多语种功能性基准。

Method: 将现有英文功能性测试模板翻译成法语、西班牙语、印地语、阿拉伯语和约鲁巴语五种不同语言，开发出CL-GSM Symbolic和CL-IFEval两个多语种功能性基准，并分析主流多语言大模型在这些基准与已有静态数据集上的表现。

Result: 相比现有静态基准，不同模型在功能性基准（CL-GSM Symbolic与CL-IFEval）上的表现平均有15%-24%的下降。各模型在多语种上的鲁棒性也并不均衡，阿拉伯语和英语的表现较为突出，其他语种的表现和一致性波动较大。

Conclusion: 静态多语言评测数据集不能充分揭示大模型在多语言实际场景下的表现和鲁棒性，新创建的功能性基准更贴合实际应用能力。不同的静态评测基准与功能性基准的性能差距显著，并且在不同语种和模型上的鲁棒性存在较大差异。

Abstract: Multi-lingual competence in large language models is often evaluated via
static data benchmarks such as Belebele, M-MMLU and M-GSM. However, these
evaluations often fail to provide an adequate understanding of the practical
performance and robustness of models across multi-lingual settings. In
response, we create multi-lingual functional benchmarks -- Cross-Lingual Grade
School Math Symbolic (CL-GSM Symbolic) and Cross-Lingual Instruction-Following
Eval (CL-IFEval)-- by translating existing functional benchmark templates from
English to five additional languages that span the range of resources available
for NLP: French, Spanish, Hindi, Arabic and Yoruba. Our results reveal that
some static multi-lingual benchmarks capture functional performance much more
closely than others (i.e. across models, there is a 24%, 17% and 18% decrease
in performance between M-GSM and CL-GSM Symbolic in English, French and Spanish
respectively; similarly there's a 15 - 24% performance drop across languages
between Belebele and CL-IFEval, and only a 0.5% to 3% performance drop between
M-MMLU and CL-IFEval). Similarly, we find that model robustness across
languages varies significantly, with certain languages (eg. Arabic, English)
being the most consistently well performing across evaluation iterations.

</details>


### [16] [The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas](https://arxiv.org/abs/2506.20803)
*Chenglei Si,Tatsunori Hashimoto,Diyi Yang*

Main category: cs.CL

TL;DR: LLM虽能生成新颖研究创意，但这些创意被实际执行后效果不如人类专家，证明当前LLM在科研想法生成上有较大局限，仅凭创意阶段评价无法准确反映实际价值。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型（LLM）已显示出在科研领域中辅助生成新颖研究创意的潜力，甚至在某些场景下比专家更具新颖性。但新颖性仅是一个维度，真正有价值的研究创意还应在实施后带来更好的科研成果，现有工作鲜有探索AI生成想法实际执行后的效果。

Method: 作者招募43名专家研究员，分别执行由人类专家和LLM生成的研究想法，每位专家投入100小时完成实验并撰写4页短论文。最终邀请NLP专家对所有已实施的项目进行盲评，并比较创意在实施前后的评分变化。

Result: 与专家手写想法相比，LLM想法在执行后所有评价指标（新颖性、激动性、有效性和总分）上分值下降显著（p < 0.05），原先在创意阶段LLM的优势被消弭，甚至许多指标上人工想法得分高于LLM。同时出现了排名翻转现象，表明执行后的效果与仅凭想法打分存在较大差距。

Conclusion: 当前LLM在生成具备实际科研价值的有效想法方面存在显著局限，仅以表观新颖性或创意阶段评价不能反映想法最终对科研的促进作用。有效研究想法需结合执行效果做全面评估。

Abstract: Large Language Models (LLMs) have shown promise in accelerating the
scientific research pipeline. A key capability for this process is the ability
to generate novel research ideas, and prior studies have found settings in
which LLM-generated research ideas were judged as more novel than human-expert
ideas. However, a good idea should not simply appear to be novel, it should
also result in better research after being executed. To test whether
AI-generated ideas lead to better research outcomes, we conduct an execution
study by recruiting 43 expert researchers to execute randomly-assigned ideas,
either written by experts or generated by an LLM. Each expert spent over 100
hours implementing the idea and wrote a 4-page short paper to document the
experiments. All the executed projects are then reviewed blindly by expert NLP
researchers. Comparing the review scores of the same ideas before and after
execution, the scores of the LLM-generated ideas decrease significantly more
than expert-written ideas on all evaluation metrics (novelty, excitement,
effectiveness, and overall; p < 0.05), closing the gap between LLM and human
ideas observed at the ideation stage. When comparing the aggregated review
scores from the execution study, we even observe that for many metrics there is
a flip in rankings where human ideas score higher than LLM ideas. This
ideation-execution gap highlights the limitations of current LLMs in generating
truly effective research ideas and the challenge of evaluating research ideas
in the absence of execution outcomes.

</details>


### [17] [MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering](https://arxiv.org/abs/2506.20821)
*Chinmay Gondhalekar,Urjitkumar Patel,Fang-Chun Yeh*

Main category: cs.CL

TL;DR: MultiFinRAG通过高效的多模态抽取和灵活召回策略，显著提升了复杂金融文件问答的多模态推理能力，并大幅超越主流免费大模型。


<details>
  <summary>Details</summary>
Motivation: 金融文件如10-K、10-Q等包含大量文本、表格和图像，内容复杂，传统大模型和RAG方法在处理跨模态推理、上下文整合和token限制等方面存在挑战。

Method: 提出MultiFinRAG框架，先对表格和图像分批输入轻量开源多模态LLM，输出结构化JSON和文本摘要。所有模态内容与叙述文本嵌入后，用模态感知的相似度索引检索，并采用分级回退策略灵活引入更多模态，实现高效跨模态推理。

Result: 在用文本、表格、图像和多模态综合推理的复杂金融问答任务上，MultiFinRAG比ChatGPT-4o（免费版）高出19个百分点的准确率，且能在普通硬件上运行。

Conclusion: MultiFinRAG有效提升了大规模金融文件跨模态问答的准确性和效率，突破了传统大模型在token限制和跨模态整合上的瓶颈。

Abstract: Financial documents--such as 10-Ks, 10-Qs, and investor presentations--span
hundreds of pages and combine diverse modalities, including dense narrative
text, structured tables, and complex figures. Answering questions over such
content often requires joint reasoning across modalities, which strains
traditional large language models (LLMs) and retrieval-augmented generation
(RAG) pipelines due to token limitations, layout loss, and fragmented
cross-modal context. We introduce MultiFinRAG, a retrieval-augmented generation
framework purpose-built for financial QA. MultiFinRAG first performs multimodal
extraction by grouping table and figure images into batches and sending them to
a lightweight, quantized open-source multimodal LLM, which produces both
structured JSON outputs and concise textual summaries. These outputs, along
with narrative text, are embedded and indexed with modality-aware similarity
thresholds for precise retrieval. A tiered fallback strategy then dynamically
escalates from text-only to text+table+image contexts when necessary, enabling
cross-modal reasoning while reducing irrelevant context. Despite running on
commodity hardware, MultiFinRAG achieves 19 percentage points higher accuracy
than ChatGPT-4o (free-tier) on complex financial QA tasks involving text,
tables, images, and combined multimodal reasoning.

</details>


### [18] [Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral Vignettes](https://arxiv.org/abs/2506.20822)
*Quintin Myers,Yanjun Gao*

Main category: cs.CL

TL;DR: 本研究首次用社会科学工具系统评估大型语言模型应对暴力情境的能力，发现其在文本和内在倾向上常常自相矛盾，并在不同人口设定下可能产生与主流研究相悖的偏见，需谨慎应用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）被广泛用于检测和响应网络暴力内容，但其对于现实中具有道德模糊性的情境推理能力缺乏系统研究。

Method: 首次使用经过社会科学验证的衡量人类对日常冲突反应的工具——暴力行为情景问卷（VBVQ），评估6个来自不同地缘政治和机构背景的LLM，并引入以美国不同种族、年龄和地理身份为变量的角色设定提示，全部在零样本环境下统一评测。

Result: 研究发现：（1）LLM生成的表层文本与其内部对暴力反应的偏好常常不一致；（2）模型的暴力倾向会随着人口统计学设定而变化，且这些变化常与犯罪学、社会科学和心理学的既有研究结果相矛盾。

Conclusion: 目前LLMs在面对复杂的道德和社会冲突情景时，推理能力和偏好容易产生偏离或偏见，提示在实际应用中需警惕其潜在风险。

Abstract: Large language models (LLMs) are increasingly proposed for detecting and
responding to violent content online, yet their ability to reason about morally
ambiguous, real-world scenarios remains underexamined. We present the first
study to evaluate LLMs using a validated social science instrument designed to
measure human response to everyday conflict, namely the Violent Behavior
Vignette Questionnaire (VBVQ). To assess potential bias, we introduce
persona-based prompting that varies race, age, and geographic identity within
the United States. Six LLMs developed across different geopolitical and
organizational contexts are evaluated under a unified zero-shot setting. Our
study reveals two key findings: (1) LLMs surface-level text generation often
diverges from their internal preference for violent responses; (2) their
violent tendencies vary across demographics, frequently contradicting
established findings in criminology, social science, and psychology.

</details>


### [19] [Decide less, communicate more: On the construct validity of end-to-end fact-checking in medicine](https://arxiv.org/abs/2506.20876)
*Sebastian Joseph,Lily Chen,Barry Wei,Michael Mackert,Iain J. Marshall,Paul Pu Liang,Ramez Kouzy,Byron C. Wallace,Junyi Jessy Li*

Main category: cs.CL

TL;DR: 本文分析了医学领域自动事实核查的挑战，提出由于医学主张特殊性，端到端系统难以适用，应将其作为交互式沟通问题对待。


<details>
  <summary>Details</summary>
Motivation: 自动事实核查技术取得重大进展，尤其在公共健康和医疗领域受到关注，因为医学决策影响巨大，但用户医学素养普遍不足，亟需能有效核查医学主张的系统。

Method: 本文为首个研究，分析临床专家如何通过整合医学证据核查社交媒体中的真实医学主张，探索事实核查在医学领域的上限。

Result: 发现医学领域的端到端事实核查面临根本性挑战：难以将野生主张与临床试验证据对接、主张描述模糊、意图不匹配以及真假标签本质上带有主观性。

Conclusion: 作者认为，医学事实核查应被视为交互式沟通问题，而非单纯的端到端过程，需要新的评估和方法。

Abstract: Technological progress has led to concrete advancements in tasks that were
regarded as challenging, such as automatic fact-checking. Interest in adopting
these systems for public health and medicine has grown due to the high-stakes
nature of medical decisions and challenges in critically appraising a vast and
diverse medical literature. Evidence-based medicine connects to every
individual, and yet the nature of it is highly technical, rendering the medical
literacy of majority users inadequate to sufficiently navigate the domain. Such
problems with medical communication ripens the ground for end-to-end
fact-checking agents: check a claim against current medical literature and
return with an evidence-backed verdict. And yet, such systems remain largely
unused. To understand this, we present the first study examining how clinical
experts verify real claims from social media by synthesizing medical evidence.
In searching for this upper-bound, we reveal fundamental challenges in
end-to-end fact-checking when applied to medicine: Difficulties connecting
claims in the wild to scientific evidence in the form of clinical trials;
ambiguities in underspecified claims mixed with mismatched intentions; and
inherently subjective veracity labels. We argue that fact-checking should be
approached and evaluated as an interactive communication problem, rather than
an end-to-end process.

</details>


### [20] [Optimising Language Models for Downstream Tasks: A Post-Training Perspective](https://arxiv.org/abs/2506.20917)
*Zhengyan Shi*

Main category: cs.CL

TL;DR: 本文提出多种提升大规模语言模型适应下游任务的方法，包括高效利用无标签数据的新预训练技术、降低资源消耗的微调策略和改进的监督微调方案，并配合新型评测标准，大幅提升了模型的适用性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前大规模语言模型在自然语言处理领域表现优异，但对于具体任务的适应存在效率低、过拟合、小样本难题以及高计算成本的问题，尤其是在面对真实世界多样化任务需求时，这些限制严重影响了模型的应用。

Method: （1）提出基于无标签数据挖掘任务相关知识的方法，并引入一种新的持续预训练技术；（2）提出参数高效的微调方法，显著降低内存和计算成本；（3）改进有监督微调方法，使模型在标注数据稀缺时能更好地理解和执行指令；（4）设计新的评测方法和多跳空间推理等基准任务，更全面地评价语言模型的能力与适应性。

Result: 经过大量实证研究，所提方法在提高语言模型的健壮性、适应性以及泛化能力等方面取得显著效果，可支持更广泛的自然语言处理应用。

Conclusion: 该系列方法使得语言模型在效率、健壮性、泛化性等层面都得到提升，推动了通用人工智能目标的实现。

Abstract: Language models (LMs) have demonstrated remarkable capabilities in NLP, yet
adapting them efficiently and robustly to specific tasks remains challenging.
As their scale and complexity grow, fine-tuning LMs on labelled data often
underutilizes available unlabelled data, leads to overfitting on small
task-specific sets, and imposes significant computational costs. These
limitations hamper their application to the open-ended landscape of real-world
language tasks.
  This thesis proposes a series of methods to better adapt LMs to downstream
applications. First, we explore strategies for extracting task-relevant
knowledge from unlabelled data, introducing a novel continued pre-training
technique that outperforms state-of-the-art semi-supervised approaches. Next,
we present a parameter-efficient fine-tuning method that substantially reduces
memory and compute costs while maintaining competitive performance. We also
introduce improved supervised fine-tuning methods that enable LMs to better
follow instructions, especially when labelled data is scarce, enhancing their
performance across a range of NLP tasks, including open-ended generation.
Finally, we develop new evaluation methods and benchmarks, such as multi-hop
spatial reasoning tasks, to assess LM capabilities and adaptation more
comprehensively.
  Through extensive empirical studies across diverse NLP tasks, our results
demonstrate that these approaches substantially improve LM robustness,
efficiency, and generalization, making them more adaptable to a broad range of
applications. These advances mark a significant step towards more robust and
efficient LMs, bringing us closer to the goal of artificial general
intelligence.

</details>


### [21] [FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data Processing to Every Language](https://arxiv.org/abs/2506.20920)
*Guilherme Penedo,Hynek Kydlíček,Vinko Sabolčec,Bettina Messmer,Negar Foroutan,Amir Hossein Kargaran,Colin Raffel,Martin Jaggi,Leandro Von Werra,Thomas Wolf*

Main category: cs.CL

TL;DR: 作者提出自动化、多语言适配的数据处理管道，提升了非英语模型训练数据质量，并公开了支持1000多语言的FineWeb2大数据集及相关工具。


<details>
  <summary>Details</summary>
Motivation: 目前多语言大模型训练所需的大规模、高质量语料库依然稀缺，难以自动高效地进行过滤和去重，成为性能瓶颈。

Method: 提出一种基于FineWeb的数据预处理与过滤管道，该管道可自动适配多种语言，并通过一系列新的、可度量的任务进行评估与调优。此外，还引入了基于重复度和质量的语料再平衡方法。

Result: 该流程在九种不同语言上的实验表明，能显著提升生成的非英文语料性能。最终成功扩展到1000多种语言，并用几乎100个Common Crawl快照生成了FineWeb2多语言数据集（20TB/50亿文档）。相关代码和数据均已发布。

Conclusion: 提出的新管道能够高效地为多语言大模型生成更优质的训练数据，有效提升模型跨语言表现，为多语言大模型的发展打下基础。

Abstract: Pre-training state-of-the-art large language models (LLMs) requires vast
amounts of clean and diverse text data. While the open development of large
high-quality English pre-training datasets has seen substantial recent
progress, training performant multilingual LLMs remains a challenge, in large
part due to the inherent difficulty of tailoring filtering and deduplication
pipelines to a large number of languages. In this work, we introduce a new
pre-training dataset curation pipeline based on FineWeb that can be
automatically adapted to support any language. We extensively ablate our
pipeline design choices on a set of nine diverse languages, guided by a set of
meaningful and informative evaluation tasks that were chosen through a novel
selection process based on measurable criteria. Ultimately, we show that our
pipeline can be used to create non-English corpora that produce more performant
models than prior datasets. We additionally introduce a straightforward and
principled approach to rebalance datasets that takes into consideration both
duplication count and quality, providing an additional performance uplift.
Finally, we scale our pipeline to over 1000 languages using almost 100 Common
Crawl snapshots to produce FineWeb2, a new 20 terabyte (5 billion document)
multilingual dataset which we release along with our pipeline, training, and
evaluation codebases.

</details>


### [22] [KaLM-Embedding-V2: Superior Training Techniques and Data Inspire A Versatile Embedding Model](https://arxiv.org/abs/2506.20923)
*Xinping Zhao,Xinshuo Hu,Zifei Shan,Shouzheng Huang,Yao Zhou,Zetian Sun,Zhenyu Liu,Dongfang Li,Xinyuan Wei,Qian Chen,Youcheng Pan,Yang Xiang,Meishan Zhang,Haofen Wang,Jun Yu,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: KaLM-Embedding-V2是一款小于10亿参数的双语文本嵌入模型，在结构、训练和数据采集方面均有创新，实现了小模型高性能，显著超越同类及更大规模模型。


<details>
  <summary>Details</summary>
Motivation: 现有的文本嵌入模型往往在通用性、紧凑性和高性能之间难以兼得，本文旨在开发一款兼具小体量和高性能的通用文本嵌入模型，满足不同实际应用场景需求。

Method: 1. 去除因果掩码，采用全双向Transformer，结合均值池化实现定长嵌入；2. 分阶段训练流程，包括大规模弱监督语料预训练、高质量数据微调、模型参数平均以增强泛化能力；3. 引入焦点式重加权机制，更关注难样本，并采用在线难负样本混合策略，无需离线数据挖掘；4. 收集多类别数据进行训练和微调。

Result: 在MTEB大规模嵌入基准测试中，KaLM-Embedding-V2在中英文任务上显著优于同级别模型，并能与参数分别为3倍、14倍、18倍、26倍的更大模型竞争。

Conclusion: KaLM-Embedding-V2模型以不到10亿参数的规模，在中英文通用文本嵌入任务中表现优异，超越同规模模型，并与远超其参数量的模型媲美，成为新一代兼备通用性与紧凑性的嵌入模型标准。

Abstract: In this paper, we propose KaLM-Embedding-V2, a versatile and compact
embedding model, which achieves impressive performance in general-purpose text
embedding tasks by leveraging superior training techniques and data. Our key
innovations include: (1) To better align the architecture with representation
learning, we remove the causal attention mask and adopt a fully bidirectional
transformer with simple yet effective mean-pooling to produce fixed-length
embeddings; (2) We employ a multi-stage training pipeline: (i) pre-training on
large-scale weakly supervised open-source corpora; (ii) fine-tuning on
high-quality retrieval and non-retrieval datasets; and (iii) model-soup
parameter averaging for robust generalization. Besides, we introduce a
focal-style reweighting mechanism that concentrates learning on difficult
samples and an online hard-negative mixing strategy to continuously enrich hard
negatives without expensive offline mining; (3) We collect over 20 categories
of data for pre-training and 100 categories of data for fine-tuning, to boost
both the performance and generalization of the embedding model. Extensive
evaluations on the Massive Text Embedding Benchmark (MTEB) Chinese and English
show that our model significantly outperforms others of comparable size, and
competes with 3x, 14x, 18x, and 26x larger embedding models, setting a new
standard for a versatile and compact embedding model with less than 1B
parameters.

</details>


### [23] [Can Gradient Descent Simulate Prompting?](https://arxiv.org/abs/2506.20989)
*Eric Zhang,Leshem Choshen,Jacob Andreas*

Main category: cs.CL

TL;DR: 本文提出让微调模拟prompt效果的元学习方法，通过无标签方式训练语言模型，使其一次梯度更新后就能接近prompt模型的表现，对提升模型泛化和长文本推理有重要启示。


<details>
  <summary>Details</summary>
Motivation: 当前将新信息融入语言模型主要有两种方式：改变prompt（提示）或改变模型参数（如微调）。Prompt方式在少样本泛化和逻辑推理方面表现优异，但长期存储不方便；而微调则相反。研究动机在于：是否可以让微调模拟prompt的效果，兼具两者优点？

Method: 提出一种基于元学习的训练方法，让模型通过梯度更新来模拟prompt对模型的影响。具体做法是利用语言模型自身的prompt预测作为监督目标，无需真实标签，利用梯度下降训练。

Result: 经过这种方式训练后，通过少量梯度更新，模型能够部分甚至全部恢复prompt模型的性能，包括提升“reversal curse”任务表现、单次更新后能根据短文回答问题，展现出很强的泛化能力。

Conclusion: 只要初始化得当，梯度下降的表达能力更强，可以模拟prompt效果。这为长文本建模和基于梯度学习的泛化能力提供了新思路。

Abstract: There are two primary ways of incorporating new information into a language
model (LM): changing its prompt or changing its parameters, e.g. via
fine-tuning. Parameter updates incur no long-term storage cost for model
changes. However, for many model updates, prompting is significantly more
effective: prompted models can generalize robustly from single examples and
draw logical inferences that do not occur under standard fine-tuning. Can
models be modified so that fine-tuning does emulate prompting? This paper
describes a method for meta-training LMs such that gradient updates emulate the
effects of conditioning on new information. Our approach uses tools from
gradient-based meta-learning but uses an LM's own prompted predictions as
targets, eliminating the need for ground-truth labels. Subsequent gradient
descent training recovers some (and occasionally all) of prompted model
performance -- showing improvement on the ``reversal curse'' tasks, and
answering questions about text passages after a single gradient update. These
results suggest that, with appropriate initialization, gradient descent can be
surprisingly expressive. Our results suggest new avenues for long-context
modeling and offer insight into the generalization capabilities of
gradient-based learning.

</details>


### [24] [SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control](https://arxiv.org/abs/2506.20993)
*Adithya Chittem,Aishna Shrivastava,Sai Tarun Pendela,Jagat Sesh Challa,Dhruv Kumar*

Main category: cs.CL

TL;DR: 作者提出基于16PF模型和SAC框架，实现了大语言模型多维度、可控强度的个性化建模，比传统方法更灵活真实，为人机交互打开新可能。


<details>
  <summary>Details</summary>
Motivation: 目前大多数大语言模型的个性建模仅基于Big Five（OCEAN）五大人格维度，刻画粗糙且无法灵活调控特质强度，难以满足人们对类人个性化交互的需求。尤其缺乏细粒度和可控性的人格表达机制。

Method: 作者将Machine Personality Inventory（MPI）从基于Big Five模型扩展到16种人格因子的16PF模型，实现对更多特质的精细表达。提出Specific Attribute Control（SAC）框架，结合形容词语义锚定和五种强度因素（频率、深度、阈值、努力、意愿）的行为问题，动态评估和诱导特质强度，实现多维度和强度连续可控的人格表达。

Result: 实验表明，将特质强度看作连续谱系进行建模，比以往二元开关式方法能获得更一致、可控的人格表达。同时，目标特质强度的变化会系统性地影响相关特质，显示出LLM对多维人格结构的内在建模能力，而不是孤立处理某一特质。

Conclusion: 该方法拓展了LLM在人格表达的颗粒度与可控性，在医疗、教育、面试等需要细致人机交互场景中具有实际应用潜力，推动了更具人性化的社会型机器研究前进。

Abstract: Large language models (LLMs) have gained significant traction across a wide
range of fields in recent years. There is also a growing expectation for them
to display human-like personalities during interactions. To meet this
expectation, numerous studies have proposed methods for modelling LLM
personalities through psychometric evaluations. However, most existing models
face two major limitations: they rely on the Big Five (OCEAN) framework, which
only provides coarse personality dimensions, and they lack mechanisms for
controlling trait intensity. In this paper, we address this gap by extending
the Machine Personality Inventory (MPI), which originally used the Big Five
model, to incorporate the 16 Personality Factor (16PF) model, allowing
expressive control over sixteen distinct traits. We also developed a structured
framework known as Specific Attribute Control (SAC) for evaluating and
dynamically inducing trait intensity in LLMs. Our method introduces
adjective-based semantic anchoring to guide trait intensity expression and
leverages behavioural questions across five intensity factors:
\textit{Frequency}, \textit{Depth}, \textit{Threshold}, \textit{Effort}, and
\textit{Willingness}. Through experimentation, we find that modelling intensity
as a continuous spectrum yields substantially more consistent and controllable
personality expression compared to binary trait toggling. Moreover, we observe
that changes in target trait intensity systematically influence closely related
traits in psychologically coherent directions, suggesting that LLMs internalize
multi-dimensional personality structures rather than treating traits in
isolation. Our work opens new pathways for controlled and nuanced human-machine
interactions in domains such as healthcare, education, and interviewing
processes, bringing us one step closer to truly human-like social machines.

</details>


### [25] [Large Language Models Acing Chartered Accountancy](https://arxiv.org/abs/2506.21031)
*Jatin Gupta,Akhil Sharma,Saransh Singhania,Mohammad Adnan,Sakshi Deo,Ali Imam Abidi,Keshav Gupta*

Main category: cs.CL

TL;DR: 本文提出专为印度金融与会计领域设计的CA-Ben基准，测试六种主流大语言模型在金融、法律和定量推理方面的能力。结果显示，Claude 3.5 Sonnet和GPT-4o表现最佳，但所有模型在数值计算与法律解释过程中仍面临挑战，提示需结合新方法以提升LLM实际应用表现。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLM）不断进步，广泛应用于金融领域，但其对金融专业知识的理解和应用能力尚不明确，尤其是在印度等特定金融环境下缺乏针对性评测。

Method: 提出了CA-Ben评测基准，通过收集和整理印度特许会计师协会（ICAI）各阶段考试的问答数据集，系统评估六个主流LLM（GPT 4o, LLAMA 3.3 70B, LLAMA 3.1 405B, MISTRAL Large, Claude 3.5 Sonnet, Microsoft Phi 4）的金融、法律和定量推理能力。

Result: 不同模型表现存在差异，其中Claude 3.5 Sonnet和GPT-4o在概念和法律推理方面表现最好。但在数值计算和法律解释方面多数模型仍有明显困难。

Conclusion: 当前主流LLM在金融领域具备一定潜力，尤其是对复杂概念和法律推理，但在数值运算和法律细节把握上仍有提升空间。未来可通过混合推理和检索增强生成方法，强化其定量分析与准确认知法律条文的能力。

Abstract: Advanced intelligent systems, particularly Large Language Models (LLMs), are
significantly reshaping financial practices through advancements in Natural
Language Processing (NLP). However, the extent to which these models
effectively capture and apply domain-specific financial knowledge remains
uncertain. Addressing a critical gap in the expansive Indian financial context,
this paper introduces CA-Ben, a Chartered Accountancy benchmark specifically
designed to evaluate the financial, legal, and quantitative reasoning
capabilities of LLMs. CA-Ben comprises structured question-answer datasets
derived from the rigorous examinations conducted by the Institute of Chartered
Accountants of India (ICAI), spanning foundational, intermediate, and advanced
CA curriculum stages. Six prominent LLMs i.e. GPT 4o, LLAMA 3.3 70B, LLAMA 3.1
405B, MISTRAL Large, Claude 3.5 Sonnet, and Microsoft Phi 4 were evaluated
using standardized protocols. Results indicate variations in performance, with
Claude 3.5 Sonnet and GPT-4o outperforming others, especially in conceptual and
legal reasoning. Notable challenges emerged in numerical computations and legal
interpretations. The findings emphasize the strengths and limitations of
current LLMs, suggesting future improvements through hybrid reasoning and
retrieval-augmented generation methods, particularly for quantitative analysis
and accurate legal interpretation.

</details>


### [26] [A Semi-supervised Scalable Unified Framework for E-commerce Query Classification](https://arxiv.org/abs/2506.21049)
*Chunyuan Yuan,Chong Zhang,Zheng Fang,Ming Pang,Xue Jiang,Changping Peng,Zhangang Lin,Ching Law*

Main category: cs.CL

TL;DR: 针对电商查询分类信息不足和子任务割裂的问题，作者提出了半监督可扩展统一框架（SSUF），能灵活增强特征表达，并大幅超过现有方法。


<details>
  <summary>Details</summary>
Motivation: 电商查询分类任务中，因查询短且缺少上下文，标签信息间无法充分利用，导致建模缺乏先验信息。目前方法多依赖用户点击结果标签来构建训练样本，形成马太效应循环，同时不同子任务缺少统一方法框架，难以高效优化。

Method: 提出了一个新颖的半监督可扩展统一框架（SSUF），包含知识增强模块、标签增强模块和结构增强模块，分别用于增强查询表达、减少对后验标签依赖、建模复杂标签关系。各模块可插拔，输入特征可灵活调整，适应不同子任务。

Result: 通过大量离线实验和线上A/B测试，证明SSUF在多项任务中显著优于现有最先进方法。

Conclusion: SSUF通过模块化增强，有效提升了电商查询分类的精度和效率，为多子任务统一建模提供了新方案。

Abstract: Query classification, including multiple subtasks such as intent and category
prediction, is vital to e-commerce applications. E-commerce queries are usually
short and lack context, and the information between labels cannot be used,
resulting in insufficient prior information for modeling. Most existing
industrial query classification methods rely on users' posterior click behavior
to construct training samples, resulting in a Matthew vicious cycle.
Furthermore, the subtasks of query classification lack a unified framework,
leading to low efficiency for algorithm optimization.
  In this paper, we propose a novel Semi-supervised Scalable Unified Framework
(SSUF), containing multiple enhanced modules to unify the query classification
tasks. The knowledge-enhanced module uses world knowledge to enhance query
representations and solve the problem of insufficient query information. The
label-enhanced module uses label semantics and semi-supervised signals to
reduce the dependence on posterior labels. The structure-enhanced module
enhances the label representation based on the complex label relations. Each
module is highly pluggable, and input features can be added or removed as
needed according to each subtask. We conduct extensive offline and online A/B
experiments, and the results show that SSUF significantly outperforms the
state-of-the-art models.

</details>


### [27] [MT2-CSD: A New Dataset and Multi-Semantic Knowledge Fusion Method for Conversational Stance Detection](https://arxiv.org/abs/2506.21053)
*Fuqiang Niu,Genan Dai,Yisha Lu,Jiayu Liao,Xiang Li,Hu Huang,Bowen Zhang*

Main category: cs.CL

TL;DR: 本文提出了一个新的大型多方多轮立场检测数据集 MT2-CSD，并基于大型语言模型提出了新的检测方法 LLM-CRAN，经实验证明新方法效果最佳，促进多方对话立场检测领域进步。


<details>
  <summary>Details</summary>
Motivation: 现有立场检测多聚焦于单条实例，未能很好建模真实社交媒体场景下的多方、多轮对话。这主要由于缺乏高质量、真实的多方对话数据集，限制了领域进展。

Method: 提出了 LLM-CRAN（结合大型语言模型的对话关系注意力网络），利用 LLM 的推理能力提升多方对话中立场检测表现，并基于新构建的 MT2-CSD 数据集进行实验评估。

Result: 构建了目前最大且包含深层对话的多目标、多轮对话立场检测数据集 MT2-CSD（含 24,457 标注实例），并通过实验表明新方法在该任务上效果显著优于现有方法。

Conclusion: LLM-CRAN 模型在多目标、多轮对话中的立场检测任务上显著优于其它强基线模型，验证了方法的有效性。

Abstract: In the realm of contemporary social media, automatic stance detection is
pivotal for opinion mining, as it synthesizes and examines user perspectives on
contentious topics to uncover prevailing trends and sentiments. Traditional
stance detection research often targets individual instances, thereby limiting
its capacity to model multi-party discussions typical in real social media
scenarios. This shortcoming largely stems from the scarcity of datasets that
authentically capture the dynamics of social media interactions, hindering
advancements in conversational stance detection. In this paper, we introduce
MT2-CSD, a comprehensive dataset for multi-target, multi-turn conversational
stance detection. To the best of our knowledge, MT2-CSD is the largest dataset
available for this purpose, comprising 24,457 annotated instances and
exhibiting the greatest conversational depth, thereby presenting new challenges
for stance detection. To address these challenges, we propose the Large
Language model enhanced Conversational Relational Attention Network (LLM-CRAN),
which exploits the reasoning capabilities of LLMs to improve conversational
understanding. We conduct extensive experiments to evaluate the efficacy of
LLM-CRAN on the MT2-CSD dataset. The experimental results indicate that
LLM-CRAN significantly outperforms strong baseline models in the task of
conversational stance detection.

</details>


### [28] [DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning](https://arxiv.org/abs/2506.21096)
*Kang He,Yuzhe Ding. Haining Wang,Fei Li,Chong Teng,Donghong Ji*

Main category: cs.CL

TL;DR: 本文提出DALR方法，通过双层对齐机制提升多模态句子表示学习的效果，在相关评测中显著优于已有方法。


<details>
  <summary>Details</summary>
Motivation: 以往的多模态句子表示学习方法虽然表现优秀，但大多只在粗粒度层面对齐图像与文本，导致出现跨模态对齐偏差和模态内语义分歧，严重影响了句子表示的质量。

Method: 提出了DALR（Dual-level Alignment Learning for Multimodal Sentence Representation）方法。该方法包括：（1）跨模态对齐方面，设计了一种一致性学习模块，通过软化负样本并利用辅助任务的语义相似度，实现更细粒度的对齐；（2）将句子关系从传统的二元正负标签推广为更复杂的排序结构，并结合排序蒸馏与全局模态内对齐学习。

Result: 在语义文本相似性（STS）和迁移（TR）等任务上的实验表明，该方法在各项指标上均优于最先进的基线方法。

Conclusion: DALR方法有效解决了多模态句子表示中的跨模态对齐偏差和模态内语义分歧问题，提升了句子表示质量，在相关任务中达到了更优性能。

Abstract: Previous multimodal sentence representation learning methods have achieved
impressive performance. However, most approaches focus on aligning images and
text at a coarse level, facing two critical challenges:cross-modal misalignment
bias and intra-modal semantic divergence, which significantly degrade sentence
representation quality. To address these challenges, we propose DALR
(Dual-level Alignment Learning for Multimodal Sentence Representation). For
cross-modal alignment, we propose a consistency learning module that softens
negative samples and utilizes semantic similarity from an auxiliary task to
achieve fine-grained cross-modal alignment. Additionally, we contend that
sentence relationships go beyond binary positive-negative labels, exhibiting a
more intricate ranking structure. To better capture these relationships and
enhance representation quality, we integrate ranking distillation with global
intra-modal alignment learning. Comprehensive experiments on semantic textual
similarity (STS) and transfer (TR) tasks validate the effectiveness of our
approach, consistently demonstrating its superiority over state-of-the-art
baselines.

</details>


### [29] [Maintaining MTEB: Towards Long Term Usability and Reproducibility of Embedding Benchmarks](https://arxiv.org/abs/2506.21182)
*Isaac Chung,Imene Kerboua,Marton Kardos,Roman Solomatin,Kenneth Enevoldsen*

Main category: cs.CL

TL;DR: 本文聚焦MTEB评测平台的工程实践，介绍了保证可复现性和可扩展性的流水线与设计，促进了平台的大规模发展和持续质量。


<details>
  <summary>Details</summary>
Motivation: MTEB 已成为文本嵌入模型的标准评测平台，但持续可复现性和可扩展性工程经常被忽视。本文旨在弥补工程实践在保证评测平台可持续性的不足。

Method: 提出健壮的持续集成流水线，包括数据集完整性校验、自动测试执行和结果泛化性评估；阐述了可复现性与可用性提升的设计选择；详细讨论了对社区贡献的处理策略和新任务/数据集的扩展机制。

Result: 通过上述工程实践，MTEB 能够大规模扩展，涵盖更多任务，同时保证评测质量和持续相关性。并为其他机器学习评测框架提供可借鉴的工程经验。

Conclusion: 工程实践对于保证评测平台的持续、可靠和可扩展至关重要。MTEB 的经验有助于社区完善其它机器学习评测框架。

Abstract: The Massive Text Embedding Benchmark (MTEB) has become a standard evaluation
platform for text embedding models. While previous work has established the
core benchmark methodology, this paper focuses on the engineering aspects that
ensure MTEB's continued reproducibility and extensibility. We present our
approach to maintaining robust continuous integration pipelines that validate
dataset integrity, automate test execution, and assess benchmark results'
generalizability. We detail the design choices that collectively enhance
reproducibility and usability. Furthermore, we discuss our strategies for
handling community contributions and extending the benchmark with new tasks and
datasets. These engineering practices have been instrumental in scaling MTEB to
become more comprehensive while maintaining quality and, ultimately, relevance
to the field. Our experiences offer valuable insights for benchmark maintainers
facing similar challenges in ensuring reproducibility and usability in machine
learning evaluation frameworks. The MTEB repository is available at:
https://github.com/embeddings-benchmark/mteb

</details>


### [30] [ComRAG: Retrieval-Augmented Generation with Dynamic Vector Stores for Real-time Community Question Answering in Industry](https://arxiv.org/abs/2506.21098)
*Qinwen Chen,Wenbiao Tao,Zhiwei Zhu,Mingfan Xi,Liangzhong Guo,Yuan Wang,Wei Wang,Yunshi Lan*

Main category: cs.CL

TL;DR: 本文提出的ComRAG框架在工业社区问答场景中，通过新颖的记忆机制整合静态和动态知识，显著提升了检索生成效果、效率和存储扩展性，实验数据优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 社区问答（CQA）平台是社区知识的重要来源，但如何在实时场景下高效利用历史交互和领域知识仍然存在挑战。现有方法往往难以充分利用外部知识，无法很好地结合动态的历史问答上下文，且缺乏适用于工业部署的记忆机制。

Method: 提出了一种名为ComRAG的检索增强生成框架，适用于实时工业CQA。ComRAG通过一种基于质心的记忆机制，将静态知识与动态历史QA对进行整合，实现高效的检索、生成和存储。

Result: 在三个工业CQA数据集上，ComRAG在所有基线上均取得了显著提升：向量相似度提高最多25.9%，延迟降低8.7%-23.3%，并且区块增长率从20.23%降到2.06%。

Conclusion: ComRAG有效结合静态与动态知识，通过创新的记忆机制极大提升了工业CQA系统在性能、效率和扩展性上的表现。

Abstract: Community Question Answering (CQA) platforms can be deemed as important
knowledge bases in community, but effectively leveraging historical
interactions and domain knowledge in real-time remains a challenge. Existing
methods often underutilize external knowledge, fail to incorporate dynamic
historical QA context, or lack memory mechanisms suited for industrial
deployment. We propose ComRAG, a retrieval-augmented generation framework for
real-time industrial CQA that integrates static knowledge with dynamic
historical QA pairs via a centroid-based memory mechanism designed for
retrieval, generation, and efficient storage. Evaluated on three industrial CQA
datasets, ComRAG consistently outperforms all baselines--achieving up to 25.9%
improvement in vector similarity, reducing latency by 8.7% to 23.3%, and
lowering chunk growth from 20.23% to 2.06% over iterations.

</details>


### [31] [Progtuning: Progressive Fine-tuning Framework for Transformer-based Language Models](https://arxiv.org/abs/2506.21119)
*Xiaoshuang Ji,Zhendong Zhao,Xiaojun Chen,Xin Zhao,Zeyao Liu*

Main category: cs.CL

TL;DR: Progtuning按贡献动态分配资源，减少25%参数更新，节省成本且效果不降，适配多场景，是高效微调Transformer模型的创新方法。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer模型规模的不断增长，全部参数的微调（fine-tuning）变得计算和存储成本巨大。现有的高效参数微调方法虽然能够减少部分计算量，但大多仍按固定比例更新各层参数，未考虑各层对最终任务的不同贡献，导致计算资源分配低效。

Method: 提出了一种名为Progtuning的新型微调框架，将渐进式学习思想用于Transformer模型微调。具体做法是基于每个Transformer block的贡献，逐步减少被更新的block数量，从而优化参数更新和资源分配。Progtuning还可以与已有的高效参数微调方法结合使用。

Result: 采用Progtuning后，更新参数数量减少了约25%，但模型性能依然具备竞争力。此外，该方法能良好适配现有高效微调技巧，在多种任务中表现优异。

Conclusion: Progtuning有效提升了Transformer微调资源分配的效率，降低计算负担同时基本不损失精度，对现有微调范式具备广泛适配能力。

Abstract: Fine-tuning is a promising technique for leveraging Transformer-based
language models in downstream tasks. As model sizes continue to grow, updating
all model parameters becomes increasingly costly. Parameter-efficient
fine-tuning methods effectively address this issue by selectively updating a
small subset of parameters. However, fine-tuning and most existing
parameter-efficient fine-tuning methods require updating the same number of
parameters as the initial size, ignoring the unequal contribution across
Transformer blocks and leading to extremely inefficient allocation of computing
resources. In this paper, we propose Progtuning, the novel fine-tuning
framework combined with progressive learning for Transformer-based language
models. Specifically, Progtuning progressively reduces the number of updated
transformer blocks based on the contribution. Remarkably, Progtuning optimizes
resource allocation and reduces the number of updated parameters by
approximately 25\%, while still maintaining competitive performance. And it
also exhibits high adaptability with parameter-efficient fine-tuning methods,
demonstrating excellent performance across various adaptation scenarios.

</details>


### [32] [Compressed and Smooth Latent Space for Text Diffusion Modeling](https://arxiv.org/abs/2506.21170)
*Viacheslav Meshchaninov,Egor Chimbulatov,Alexander Shabalin,Aleksandr Abramov,Dmitry Vetrov*

Main category: cs.CL

TL;DR: 该论文提出Cosmos，在自定义潜空间中用扩散模型高效生成文本，实现比主流方法更快的推理速度和相当/更佳的生成质量，对多项任务表现突出。


<details>
  <summary>Details</summary>
Motivation: 现代文本生成模型多以自回归语言模型为主，但这些模型的序列生成方式带来了推理速度慢和难以保持全局连贯性的限制。扩散模型具备并行生成和灵活可控的优点，却因为文本高维度的token级表示，难以直接应用于文本生成。本文旨在克服这两大类方法的关键缺陷。

Method: 提出Cosmos，一种基于扩散模型、全程在压缩且平滑的定制潜空间中工作的新型文本生成方法。该潜空间通过联合训练的自动编码器获得，既对token级信息进行重建，也与预训练语言编码器的激活对齐，从而获得强鲁棒性和良好的语义基础，并支持基于扰动的增强。

Result: 实验表明，Cosmos可将文本表示压缩8倍，仍能保持与token级扩散模型相当的生成质量。增加潜空间序列长度后，Cosmos生成效果超过现有扩散与自回归基线。Cosmos在故事生成、问题生成、摘要、文本去毒等多任务和多范式下评测，均取得了相当或更佳的生成质量，同时推理速度提升了2倍以上。

Conclusion: Cosmos实现了扩散模型并行生成优势与语义压缩表示结合，在多项生成任务中优于或媲美主流方法，且显著加快推理速度，展示出应用潜力与创新价值。

Abstract: Autoregressive language models dominate modern text generation, yet their
sequential nature introduces fundamental limitations: decoding is slow, and
maintaining global coherence remains challenging. Diffusion models offer a
promising alternative by enabling parallel generation and flexible control;
however, their application to text generation is hindered by the high
dimensionality of token-level representations. We introduce Cosmos, a novel
approach to text generation that operates entirely in a compressed, smooth
latent space tailored specifically for diffusion. This space is learned using
an autoencoder trained simultaneously for token-level reconstruction and
alignment with frozen activations from a pretrained language encoder, providing
robust semantic grounding and enabling effective perturbation-based
augmentations. Empirically, we demonstrate that text representations can be
compressed by $8\times$ while maintaining generation quality comparable to
token-level diffusion models. Furthermore, increasing the latent sequence
length allows Cosmos to surpass both diffusion-based and autoregressive
baselines. We evaluate Cosmos on four diverse generative tasks including story
generation, question generation, summarization, and detoxification and compare
it with various generative paradigms. Cosmos achieves comparable or superior
generation quality while offering more than $2\times$ faster inference.

</details>


### [33] [Prompt-Guided Turn-Taking Prediction](https://arxiv.org/abs/2506.21191)
*Koji Inoue,Mikey Elmers,Yahui Fu,Zi Haur Pang,Divesh Lala,Keiko Ochi,Tatsuya Kawahara*

Main category: cs.CL

TL;DR: 该文提出了一个结合文本指令的轮次预测模型，能依据提示动态调整交流节奏，经实验验证提升了轮次预测准确率，并实现了基于指令的行为调控。


<details>
  <summary>Details</summary>
Motivation: 现有交互系统需要更加灵活、自然地预测对话轮次，当前方法很难根据不同对话需求动态调整预测行为。

Method: 基于transformer的VAP模型，结合文本提示嵌入（prompt embeddings），将这些嵌入添加到通道内与跨通道transformer中，并通过大语言模型(LLM)生成合成文本提示进行训练和测试。

Result: 模型在950小时人类对话数据上得到了验证，通过文本提示可以灵活有效地调整轮次预测行为，同时准确率也有所提升。

Conclusion: 提出的方法不仅提升了轮次预测的准确性，还能根据文本指令灵活适应不同对话节奏和需求，为对话系统带来更自然的人机交互体验。

Abstract: Turn-taking prediction models are essential components in spoken dialogue
systems and conversational robots. Recent approaches leverage transformer-based
architectures to predict speech activity continuously and in real-time. In this
study, we propose a novel model that enables turn-taking prediction to be
dynamically controlled via textual prompts. This approach allows intuitive and
explicit control through instructions such as "faster" or "calmer" adapting
dynamically to conversational partners and contexts. The proposed model builds
upon a transformer-based voice activity projection (VAP) model, incorporating
textual prompt embeddings into both channel-wise transformers and a
cross-channel transformer. We evaluated the feasibility of our approach using
over 950 hours of human-human spoken dialogue data. Since textual prompt data
for the proposed approach was not available in existing datasets, we utilized a
large language model (LLM) to generate synthetic prompt sentences. Experimental
results demonstrated that the proposed model improved prediction accuracy and
effectively varied turn-taking timing behaviors according to the textual
prompts.

</details>


### [34] [Enhancing Automatic Term Extraction with Large Language Models via Syntactic Retrieval](https://arxiv.org/abs/2506.21222)
*Yongchan Chun,Minhyuk Kim,Dongjun Kim,Chanjun Park,Heuiseok Lim*

Main category: cs.CL

TL;DR: 本文提出了一种利用句法相似性进行示例选择的检索式提示方法，实验证明该法可以提升大型语言模型在专业术语抽取任务中的表现，显示了句法信息在此类任务中的重要性。


<details>
  <summary>Details</summary>
Motivation: 自动术语抽取（ATE）对于如机器翻译和信息检索等下游任务至关重要，但大型语言模型（LLMs）在ATE任务中的潜力尚未被充分研究。

Method: 提出了一种基于检索的提示策略，在少样本环境下，采用“句法”相似性而非语义相似性来选择示例（demonstrations），该方法不依赖于领域知识，有助于更准确地识别术语边界。

Result: 在三个专业ATE基准上进行实验，结果表明句法检索方法能够提升F1分数。还分析了查询句子与其检索到的示例之间的词汇重叠对性能的影响。

Conclusion: 句法线索对于将大型语言模型应用于术语抽取任务具有重要作用，句法检索为这些任务提供了更可靠的指导。

Abstract: Automatic Term Extraction (ATE) identifies domain-specific expressions that
are crucial for downstream tasks such as machine translation and information
retrieval. Although large language models (LLMs) have significantly advanced
various NLP tasks, their potential for ATE has scarcely been examined. We
propose a retrieval-based prompting strategy that, in the few-shot setting,
selects demonstrations according to \emph{syntactic} rather than semantic
similarity. This syntactic retrieval method is domain-agnostic and provides
more reliable guidance for capturing term boundaries. We evaluate the approach
in both in-domain and cross-domain settings, analyzing how lexical overlap
between the query sentence and its retrieved examples affects performance.
Experiments on three specialized ATE benchmarks show that syntactic retrieval
improves F1-score. These findings highlight the importance of syntactic cues
when adapting LLMs to terminology-extraction tasks.

</details>


### [35] [Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents](https://arxiv.org/abs/2506.21252)
*Tianyi Men,Zhuoran Jin,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: 本文提出了Agent-RewardBench基准，专为多模态大模型智能体奖励建模评测设计。其涵盖多个场景、细粒度评测、多样性数据与难度控制。实验成果显示，当前前沿多模态模型在奖励建模上仍存在显著不足，凸显针对性训练与评测的必要性。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大模型（MLLMs）的进步，多模态智能体在真实世界任务中展现出应用潜力，如网页导航、具身智能等。然而受限于缺乏外部反馈，这些智能体自我纠错和泛化能力较弱。当前利用奖励模型作为外部反馈是一个有前景的方法，但如何为智能体选择合适的奖励模型尚无明确方案，因此亟需面向智能体的奖励评测基准。

Method: 作者提出了Agent-RewardBench基准，专为评估MLLMs奖励建模能力设计。该基准具有三大特点：（1）多维真实世界智能体场景评测，涵盖感知、规划和安全等7种场景；（2）步级奖励评测，可细粒度评估智能体在任务分步骤过程中的能力；（3）保证了合适的难度和数据质量，从10个多样性模型中采样，并控制难度及人工校验数据。

Result: 实验显示，即便是最新的大型多模态模型，在该基准上的表现也有限，反映出在智能体奖励建模方面尚需专门的训练。相关代码已在github开源。

Conclusion: Agent-RewardBench能够系统性评估和揭示当前MLLMs在智能体奖励建模上的不足，为后续模型训练和评测提供了参考工具，促进基于奖励反馈的多模态智能体能力提升。

Abstract: As Multimodal Large Language Models (MLLMs) advance, multimodal agents show
promise in real-world tasks like web navigation and embodied intelligence.
However, due to limitations in a lack of external feedback, these agents
struggle with self-correction and generalization. A promising approach is to
use reward models as external feedback, but there is no clear on how to select
reward models for agents. Thus, there is an urgent need to build a reward bench
targeted at agents. To address these challenges, we propose Agent-RewardBench,
a benchmark designed to evaluate reward modeling ability in MLLMs. The
benchmark is characterized by three key features: (1) Multiple dimensions and
real-world agent scenarios evaluation. It covers perception, planning, and
safety with 7 scenarios; (2) Step-level reward evaluation. It allows for the
assessment of agent capabilities at the individual steps of a task, providing a
more granular view of performance during the planning process; and (3)
Appropriately difficulty and high-quality. We carefully sample from 10 diverse
models, difficulty control to maintain task challenges, and manual verification
to ensure the integrity of the data. Experiments demonstrate that even
state-of-the-art multimodal models show limited performance, highlighting the
need for specialized training in agent reward modeling. Code is available at
github.

</details>


### [36] [Cat and Mouse -- Can Fake Text Generation Outpace Detector Systems?](https://arxiv.org/abs/2506.21274)
*Andrea McGlinchey,Peter J Barclay*

Main category: cs.CL

TL;DR: 即使大模型变强，假文本检测依然有希望；但新架构模型需警惕其更强的欺骗性能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型能生成在学术写作、产品评论、政治新闻等领域中具有迷惑性的“假文本”，检测这些人工生成文本的方法很重要，也需要了解检测与生成模型之间的“军备竞赛”。

Method: 通过分析统计分类器识别“假文本”的能力，特别是在经典侦探小说文体下，对不同版本（如Gemini和GPT）的生成能力进行对比评估。

Result: 在模型版本提升0.5的情况下，Gemini在生成具有欺骗性的文本方面表现有所提升，而GPT则无明显提升。统计分类器依然能以较好的准确率检测假文本。

Conclusion: 即使大语言模型规模不断提升，简单的检测方法仍可实现较好检测效果。但新模型结构（如Gemini）可能增强其迷惑性，使检测变得更具挑战性。

Abstract: Large language models can produce convincing "fake text" in domains such as
academic writing, product reviews, and political news. Many approaches have
been investigated for the detection of artificially generated text. While this
may seem to presage an endless "arms race", we note that newer LLMs use ever
more parameters, training data, and energy, while relatively simple classifiers
demonstrate a good level of detection accuracy with modest resources. To
approach the question of whether the models' ability to beat the detectors may
therefore reach a plateau, we examine the ability of statistical classifiers to
identify "fake text" in the style of classical detective fiction. Over a 0.5
version increase, we found that Gemini showed an increased ability to generate
deceptive text, while GPT did not. This suggests that reliable detection of
fake text may remain feasible even for ever-larger models, though new model
architectures may improve their deceptiveness

</details>


### [37] [Double-Checker: Enhancing Reasoning of Slow-Thinking LLMs via Self-Critical Fine-Tuning](https://arxiv.org/abs/2506.21285)
*Xin Xu,Tianhao Chen,Fan Zhang,Wanlong Liu,Pengxiang Li,Ajay Kumar Jaiswal,Yuchen Yan,Jishan Hu,Yang Wang,Hao Chen,Shiwei Liu,Shizhe Diao,Can Yang,Lu Yin*

Main category: cs.CL

TL;DR: 该论文提出Double-Checker框架，通过让大语言模型在推理中不断自我批评和修正，显著提升了模型在复杂推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 虽然慢思考的大模型展现了反思能力，但生成有信息量的批判和修正先前解答的能力有限。为提升其可信度和推理能力，亟需更有效的自我批判和迭代修正机制。

Method: 提出Double-Checker框架，使大模型在推理过程中进行显式自我批判和反复修正，并使用1,730个自我批判实例进行微调，在推理过程中反复自省和迭代，直到模型在自有评价中判定答案正确。

Result: 实验结果表明，Double-Checker方法在一系列推理基准任务中提升显著，AIME基准上pass@1从4.4%提升至18.2%。这说明通过迭代自我批判可以显著增强大模型的推理能力。

Conclusion: Double-Checker显著提升了长链思维（long-CoT）大模型在推理任务中的表现，尤其是在AIME等具有挑战性的基准测试中，表现得到大幅提升。

Abstract: While slow-thinking large language models (LLMs) exhibit reflection-like
reasoning, commonly referred to as the "aha moment:, their ability to generate
informative critiques and refine prior solutions remains limited. In this
paper, we introduce Double-Checker, a principled framework designed to enhance
the reasoning capabilities of slow-thinking LLMs by fostering explicit
self-critique and iterative refinement of their previous solutions. By
fine-tuning on our curated 1,730 self-critical instances, Double-Checker
empowers long-CoT LLMs to iteratively critique and refine their outputs during
inference until they evaluate their solutions as correct under self-generated
critiques. We validate the efficacy of Double-Checker across a comprehensive
suite of reasoning benchmarks, demonstrating that iterative self-critique
significantly enhances the reasoning capabilities of long-CoT LLMs. Notably,
our Double-Checker increases the pass@1 performance on challenging AIME
benchmarks from 4.4% to 18.2% compared to the original long-CoT LLMs. These
results highlight a promising direction for developing more trustworthy and
effective LLMs capable of structured self-critique.

</details>


### [38] [Small Encoders Can Rival Large Decoders in Detecting Groundedness](https://arxiv.org/abs/2506.21288)
*Istabrak Abbes,Gabriele Prato,Quentin Fournier,Fernando Rodriguez,Alaa Boukhary,Adam Elwood,Sarath Chandar*

Main category: cs.CL

TL;DR: 用微调后的RoBERTa和NomicBERT等轻量级模型，在不损失准确率的情况下，实现了对LLM生成前查询相关性的高效检测，大幅提升推理速度并降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言处理任务中性能提升明显，但当外部上下文信息缺失时，容易产生脱离事实的回答。因此，确保回答与上下文强相关（groundedness）变得尤为重要。现有方法大多聚焦于答案生成阶段，缺乏高效的前置检测机制。

Method: 本文提出在LLM生成答案之前，先用轻量级、任务特定的编码器模型（如RoBERTa和NomicBERT），对问题是否被文档支持进行检测。这些模型通过在特定数据集上微调达到目标。

Result: 实验结果表明，这些轻量级模型在“groundedness”检测任务上，能取得与SOTA LLMs（如Llama3 8B和GPT4o）相当的准确率，同时大幅降低推理延迟。

Conclusion: 通过检测机制提前筛查，无需调用大型生成模型即可高效过滤掉未被支持的问题，实现更高效、资源节省的NLP流程。相关代码已开源。

Abstract: Augmenting large language models (LLMs) with external context significantly
improves their performance in natural language processing (NLP) tasks. However,
LLMs struggle to answer queries reliably when the provided context lacks
information, often resorting to ungrounded speculation or internal knowledge.
Groundedness - generating responses strictly supported by the context - is
essential for ensuring factual consistency and trustworthiness. This study
focuses on detecting whether a given query is grounded in a document provided
in context before the costly answer generation by LLMs. Such a detection
mechanism can significantly reduce both inference time and resource
consumption. We show that lightweight, task specific encoder models such as
RoBERTa and NomicBERT, fine-tuned on curated datasets, can achieve accuracy
comparable to state-of-the-art LLMs, such as Llama3 8B and GPT4o, in
groundedness detection while reducing inference latency by orders of magnitude.
The code is available at : https://github.com/chandarlab/Hallucinate-less

</details>


### [39] [Detecting Referring Expressions in Visually Grounded Dialogue with Autoregressive Language Models](https://arxiv.org/abs/2506.21294)
*Bram Willemsen,Gabriel Skantze*

Main category: cs.CL

TL;DR: 本文提出用大语言模型，仅依赖文本信息，来检测对话中的指称表达，实验发现该方法效果不错，但强调任务本质需要多模态信息，纯文本法总有局限。


<details>
  <summary>Details</summary>
Motivation: 研究如何仅利用文本和语言模型，从需要视觉理解的对话中提取指称表达，而无需直接处理图像信息。

Method: 利用预训练大语言模型，通过自回归语言建模方式，对对话文本中的指称表达（mention）进行粗粒度注释，主要采用下一个词预测的方法标注mention的边界。通过对中等规模模型、小数据集以及参数高效微调的实验，评估其效果。

Result: 结果显示，即使只用文本信息，采用合适的语言模型和微调后，仍能有效地从对话中检测指称表达，说明语言上下文对这类任务有较大贡献。

Conclusion: 虽然纯文本方法表现良好，但该任务本质上是多模态任务，仅依赖文本始终存在局限性，因此纯文本方法难以替代视觉－语言联合的方法。

Abstract: In this paper, we explore the use of a text-only, autoregressive language
modeling approach for the extraction of referring expressions from visually
grounded dialogue. More specifically, the aim is to investigate the extent to
which the linguistic context alone can inform the detection of mentions that
have a (visually perceivable) referent in the visual context of the
conversation. To this end, we adapt a pretrained large language model (LLM) to
perform a relatively course-grained annotation of mention spans in unfolding
conversations by demarcating mention span boundaries in text via next-token
prediction. Our findings indicate that even when using a moderately sized LLM,
relatively small datasets, and parameter-efficient fine-tuning, a text-only
approach can be effective, highlighting the relative importance of the
linguistic context for this task. Nevertheless, we argue that the task
represents an inherently multimodal problem and discuss limitations fundamental
to unimodal approaches.

</details>


### [40] [Structuralist Approach to AI Literary Criticism: Leveraging Greimas Semiotic Square for Large Language Models](https://arxiv.org/abs/2506.21360)
*Fangzhou Dong,Yifan Zeng,Yingpeng Sang,Hong Shen*

Main category: cs.CL

TL;DR: GLASS是基于符号学方格的结构化分析框架，显著提升了大模型在深入文学评论中的表现，并为文学研究带来了高质量数据和运行工具。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在理解和生成文本方面表现优异，但在对思想深刻、叙事复杂的文学作品进行专业批评时仍有不足。

Method: 提出了一种基于格雷马斯符号学方格（GSS）的结构化分析框架GLASS，并构建了首个基于GSS的文学批评数据集，设计了相应的量化评测指标，并采用LLM-as-a-judge范式进行评价。

Result: 该框架在与专家批评和多种LLM模型的对比实验中表现出高水平；应用于39部经典文学作品，生成了高质量、原创性的分析，填补了相关研究空白。

Conclusion: 研究提出的GLASS框架大幅提升了LLM在文学分析方面的能力，为文学研究和教育领域提供了有效的AI辅助工具，并为理解文学认知机制提供了新视角。

Abstract: Large Language Models (LLMs) excel in understanding and generating text but
struggle with providing professional literary criticism for works with profound
thoughts and complex narratives. This paper proposes GLASS (Greimas Literary
Analysis via Semiotic Square), a structured analytical framework based on
Greimas Semiotic Square (GSS), to enhance LLMs' ability to conduct in-depth
literary analysis. GLASS facilitates the rapid dissection of narrative
structures and deep meanings in narrative works. We propose the first dataset
for GSS-based literary criticism, featuring detailed analyses of 48 works. Then
we propose quantitative metrics for GSS-based literary criticism using the
LLM-as-a-judge paradigm. Our framework's results, compared with expert
criticism across multiple works and LLMs, show high performance. Finally, we
applied GLASS to 39 classic works, producing original and high-quality analyses
that address existing research gaps. This research provides an AI-based tool
for literary research and education, offering insights into the cognitive
mechanisms underlying literary engagement.

</details>


### [41] [Leveraging LLM-Assisted Query Understanding for Live Retrieval-Augmented Generation](https://arxiv.org/abs/2506.21384)
*Guanting Dong,Xiaoxi Li,Yuyao Zhang,Mengjie Deng*

Main category: cs.CL

TL;DR: Omni-RAG提出了一种三模块结合、基于大模型的检索增强生成新框架，大幅提升了系统在真实复杂用户查询下的表现，为RAG在实际落地提供了更强的适应性和效果提升。


<details>
  <summary>Details</summary>
Motivation: 现有实际应用中的检索增强生成（RAG）系统在处理用户输入时，经常遇到查询噪音大、语义模糊或包含多个意图等复杂问题，而主流RAG系统通常是基于较为干净的数据训练或评估的，难以应对高复杂度场景。

Method: Omni-RAG框架引入了三大模块：1）基于LLM的深度查询理解和分解，利用定制化提示词对查询降噪（如纠错）并将多意图查询分解为结构化子查询；2）意图感知知识检索，对每个子查询检索文档库（如FineWeb-OpenSearch），并聚合结果；3）重排序与生成，利用重排模型（如BGE）优化文档选择，最终由LLM（如Falcon-10B）结合思维链提示生成回答。

Result: Omni-RAG显著提升了RAG系统在真实、开放领域及高复杂度查询下的鲁棒性和有效性，能够更好地处理来自真实用户的复杂、嘈杂输入。

Conclusion: Omni-RAG架构有效地弥补了传统RAG系统在实际应用中面对复杂与噪声查询处理时的不足，为满足如SIGIR 2025 LiveRAG Challenge等真实场景下的实际需求提供了有力支持。

Abstract: Real-world live retrieval-augmented generation (RAG) systems face significant
challenges when processing user queries that are often noisy, ambiguous, and
contain multiple intents. While RAG enhances large language models (LLMs) with
external knowledge, current systems typically struggle with such complex
inputs, as they are often trained or evaluated on cleaner data. This paper
introduces Omni-RAG, a novel framework designed to improve the robustness and
effectiveness of RAG systems in live, open-domain settings. Omni-RAG employs
LLM-assisted query understanding to preprocess user inputs through three key
modules: (1) Deep Query Understanding and Decomposition, which utilizes LLMs
with tailored prompts to denoise queries (e.g., correcting spelling errors) and
decompose multi-intent queries into structured sub-queries; (2) Intent-Aware
Knowledge Retrieval, which performs retrieval for each sub-query from a corpus
(i.e., FineWeb using OpenSearch) and aggregates the results; and (3) Reranking
and Generation, where a reranker (i.e., BGE) refines document selection before
a final response is generated by an LLM (i.e., Falcon-10B) using a
chain-of-thought prompt. Omni-RAG aims to bridge the gap between current RAG
capabilities and the demands of real-world applications, such as those
highlighted by the SIGIR 2025 LiveRAG Challenge, by robustly handling complex
and noisy queries.

</details>


### [42] [Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection](https://arxiv.org/abs/2506.21443)
*Ali Şenol,Garima Agrawal,Huan Liu*

Main category: cs.CL

TL;DR: 本研究提出一种结合领域知识与大语言模型的框架，有效提升了欺诈对话和语义漂移检测的准确性，LLaMA实现达到98%准确率，并在可解释性与鲁棒性方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 随着交流平台语言模式不断演变和语义漂移现象的出现，欺诈性对话检测变得越来越困难。现有的大型语言模型在自然语言任务中表现不错，但在涉及上下文歧义和高风险场景下存在误判和幻觉问题。因此，亟需提升对欺诈及语义漂移的检测能力。

Method: 提出了一种结合领域知识（Domain Knowledge, DK）和大型语言模型（LLMs）的框架。该架构包含三个核心模块：（1）DK-LLM用于识别虚假或欺诈性对话；（2）漂移检测单元（OCDD）用于判别语义漂移是否发生；（3）第二个DK-LLM模块对检测到的漂移进行良性或欺诈性质分类。实验首先验证领域知识对检测的有效提升，随后将完整系统应用于多轮对话数据集SEConvo，涵盖多类欺诈和垃圾信息。

Result: 本系统在虚假对话检测和语义漂移分类上均取得了很高的准确率。基于结构化提示的LLaMA实现达到了98%的分类准确率。与零样本基线方法比较，结合领域知识和漂移检测的系统在性能、可解释性和鲁棒性上均有显著提升。

Conclusion: 通过结合领域知识与LLM，以及引入漂移检测机制，有效解决了动态场景下欺诈/虚假对话与语义漂移的检测难题，在实际高风险NLP中表现出优越的性能。

Abstract: Detecting deceptive conversations on dynamic platforms is increasingly
difficult due to evolving language patterns and Concept Drift (CD)-i.e.,
semantic or topical shifts that alter the context or intent of interactions
over time. These shifts can obscure malicious intent or mimic normal dialogue,
making accurate classification challenging. While Large Language Models (LLMs)
show strong performance in natural language tasks, they often struggle with
contextual ambiguity and hallucinations in risk-sensitive scenarios. To address
these challenges, we present a Domain Knowledge (DK)-Enhanced LLM framework
that integrates pretrained LLMs with structured, task-specific insights to
perform fraud and concept drift detection. The proposed architecture consists
of three main components: (1) a DK-LLM module to detect fake or deceptive
conversations; (2) a drift detection unit (OCDD) to determine whether a
semantic shift has occurred; and (3) a second DK-LLM module to classify the
drift as either benign or fraudulent. We first validate the value of domain
knowledge using a fake review dataset and then apply our full framework to
SEConvo, a multiturn dialogue dataset that includes various types of fraud and
spam attacks. Results show that our system detects fake conversations with high
accuracy and effectively classifies the nature of drift. Guided by structured
prompts, the LLaMA-based implementation achieves 98% classification accuracy.
Comparative studies against zero-shot baselines demonstrate that incorporating
domain knowledge and drift awareness significantly improves performance,
interpretability, and robustness in high-stakes NLP applications.

</details>


### [43] [Text2Cypher Across Languages: Evaluating Foundational Models Beyond English](https://arxiv.org/abs/2506.21445)
*Makbule Gulcin Ozsoy,William Tai*

Main category: cs.CL

TL;DR: 本文探讨大语言模型在多语言场景下将自然语言转换为Cypher查询的表现，发现英文效果最佳，prompt翻译影响较小，强调了多语种适配与公平性的重要性。


<details>
  <summary>Details</summary>
Motivation: 目前利用大语言模型实现自然语言数据库查询接口已较为普及，但相关研究多集中在英文，对于其他语言的评估和适配有限。本文针对该不足，希望探究大语言模型在多语言环境下的表现。

Method: 作者构建了一个多语言测试集，通过将英文问题翻译成西班牙语和土耳其语，同时保持原始Cypher查询不变，以保证跨语言可比性。同时，选用了多个基础大语言模型，使用标准化的提示词（prompt）和评测指标进行评估。还分别考察了任务prompt翻译成其它语言对模型表现的影响。

Result: 实验显示，无论模型类型为何，在英文下表现最佳，其次是西班牙语，最低的是土耳其语。作者认为主要原因是训练数据的可获得性差异以及语言本身的特性差异。同时，prompt翻译成目标语言后指标变化不大，表明prompt翻译影响有限。

Conclusion: 本文展示了大语言模型在Text2Cypher任务中存在显著的多语言性能差距，并发现prompt翻译对结果影响不大。作者呼吁未来研究需更重视多语言与本地化需求，例如数据模式(schema)本地化和多语种微调。

Abstract: Recent advances in large language models have enabled natural language
interfaces that translate user questions into database queries, such as
Text2SQL, Text2SPARQL, and Text2Cypher. While these interfaces enhance database
accessibility, most research today focuses solely on English, with limited
evaluation in other languages. This paper investigates the performance of
foundational LLMs on the Text2Cypher task across multiple languages. We create
and release a multilingual test set by translating English questions into
Spanish and Turkish while preserving the original Cypher queries, enabling fair
cross-lingual comparison. We evaluate multiple foundational models using
standardized prompts and metrics. Our results show a consistent performance
pattern: highest on English, then Spanish, and lowest on Turkish. We attribute
this to differences in training data availability and linguistic
characteristics. Additionally, we explore the impact of translating task
prompts into Spanish and Turkish. Results show little to no change in
evaluation metrics, suggesting prompt translation has minor impact. Our
findings highlight the need for more inclusive evaluation and development in
multilingual query generation. Future work includes schema localization and
fine-tuning across diverse languages.

</details>


### [44] [Aligning Spoken Dialogue Models from User Interactions](https://arxiv.org/abs/2506.21463)
*Anne Wu,Laurent Mazaré,Neil Zeghidour,Alexandre Défossez*

Main category: cs.CL

TL;DR: 该论文提出了一种针对实时语音对话系统的偏好对齐方法，通过大规模标注数据集和模型微调，有效提升了语音对话模型在真实性、安全性和语境一致性方面的表现，为更自然的语音对话系统提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 当前偏好学习方法主要针对文本语言模型，而对实时语音交互中更丰富、更复杂的动态并不适用，如无明显说话轮次分界、打断等。语音对话系统需要新的偏好对齐技术以提升交互自然性和语境适应能力。

Method: 作者提出一种新颖的偏好对齐框架，构建了包含超过15万对多轮语音对话偏好样本的大规模数据集，并利用AI反馈标注，覆盖语言内容和时间语境变化。通过离线对齐方法微调全双工自回归语音到语音模型，在泛化任务下进行实验证明其有效性，并部署模型进行多轮人工评价。

Result: 实验结果表明，该方法能显著提升语音对话模型的事实准确性、安全性和语境一致性。人工评价也验证了其在多轮对话中带来的整体改进。

Conclusion: 研究强调了平衡各种交互动态对于构建自然且实时语音对话系统的重要性，并展示了通过偏好对齐大幅提升对话模型实际效果的可行性。

Abstract: We propose a novel preference alignment framework for improving spoken
dialogue models on real-time conversations from user interactions. Current
preference learning methods primarily focus on text-based language models, and
are not directly suited to the complexities of real-time speech interactions,
with richer dynamics (e.g. interruption, interjection) and no explicit
segmentation between speaker turns.We create a large-scale dataset of more than
150,000 preference pairs from raw multi-turn speech conversations, annotated
with AI feedback, to cover preferences over both linguistic content and
temporal context variations. We leverage offline alignment methods to finetune
a full-duplex autoregressive speech-to-speech model. Extensive experiments
demonstrate that feedback on generic conversations can be consistently
effective in improving spoken dialogue models to produce more factual, safer
and more contextually aligned interactions. We deploy the finetuned model and
conduct holistic human evaluations to assess the impact beyond single-turn
conversations. Our findings shed light on the importance of a well-calibrated
balance among various dynamics, crucial for natural real-time speech dialogue
systems.

</details>


### [45] [TopK Language Models](https://arxiv.org/abs/2506.21468)
*Ryosuke Takahashi,Tatsuro Inaba,Kentaro Inui,Benjamin Heinzerling*

Main category: cs.CL

TL;DR: 该论文提出在Transformer中内嵌TopK激活，以替代后验SAE，提高稀疏特征的稳定性和解释性，保持模型性能的同时，大幅提升可控性与分析能力。


<details>
  <summary>Details</summary>
Motivation: 当前稀疏自编码器（SAEs）在分析和解释Transformer语言模型（LMs）激活空间中有广泛应用，但存在鲁棒性和解释性不足、特征稳定性差的问题，限制了其有效性。因此，论文希望解决SAEs后验训练、特征不稳定及其与模型隐层表征关系不确切等瓶颈。

Method: 论文提出对Transformer结构做出改进，在选定层引入TopK激活函数，使模型的隐状态等价于TopK SAE的潜在特征，从而直接在模型内部实现稀疏可解释特征，无需SAE事后训练。

Result: TopK LMs在保持原有能力的同时，获得与SAEs相当的可解释性和更高的特征稳定性，提升了模型大小、运算效率和可解释性的综合权衡。实验证明TopK LMs的稀疏表征支持针对神经元的干预和跨检查点、层的神经元分析，显著提升了解释和可控能力。

Conclusion: TopK LMs通过结构性创新替代了传统SAE在语言模型解释和分析中的作用，提升了可解释性和可控性，推动了模型可解释性和可控性的研究进展。

Abstract: Sparse autoencoders (SAEs) have become an important tool for analyzing and
interpreting the activation space of transformer-based language models (LMs).
However, SAEs suffer several shortcomings that diminish their utility and
internal validity. Since SAEs are trained post-hoc, it is unclear if the
failure to discover a particular concept is a failure on the SAE's side or due
to the underlying LM not representing this concept. This problem is exacerbated
by training conditions and architecture choices affecting which features an SAE
learns. When tracing how LMs learn concepts during training, the lack of
feature stability also makes it difficult to compare SAEs features across
different checkpoints. To address these limitations, we introduce a
modification to the transformer architecture that incorporates a TopK
activation function at chosen layers, making the model's hidden states
equivalent to the latent features of a TopK SAE. This approach eliminates the
need for post-hoc training while providing interpretability comparable to SAEs.
The resulting TopK LMs offer a favorable trade-off between model size,
computational efficiency, and interpretability. Despite this simple
architectural change, TopK LMs maintain their original capabilities while
providing robust interpretability benefits. Our experiments demonstrate that
the sparse representations learned by TopK LMs enable successful steering
through targeted neuron interventions and facilitate detailed analysis of
neuron formation processes across checkpoints and layers. These features make
TopK LMs stable and reliable tools for understanding how language models learn
and represent concepts, which we believe will significantly advance future
research on model interpretability and controllability.

</details>


### [46] [Bridging Offline and Online Reinforcement Learning for LLMs](https://arxiv.org/abs/2506.21495)
*Jack Lanchantin,Angelica Chen,Janice Lan,Xian Li,Swarnadeep Saha,Tianlu Wang,Jing Xu,Ping Yu,Weizhe Yuan,Jason E Weston,Sainbayar Sukhbaatar,Ilia Kulikov*

Main category: cs.CL

TL;DR: 本研究系统比较不同强化学习微调方法在离线、半在线和全在线场景下对大语言模型的效果，发现在线与半在线方法明显优于离线方法，且效果相近。联合可验证与不可验证任务的多任务训练能进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在微调阶段多采用离线强化学习方法，但面对不同的实际场景（如离线、半在线到全在线学习），这些方法的有效性和适用性尚未充分探究。本文希望比较和分析不同在线学习范式和优化目标下RL微调方法的表现。

Method: 本文分别在可验证的数学任务和不可验证的指令任务上，采用Direct Preference Optimization（DPO）和Group Reward Policy Optimization（GRPO）等多种RL优化目标，在离线、半在线和全在线三种训练模式下进行对比实验，并对训练动态和超参数选择进行详细分析。此外，研究还考察了多任务（融合可验证与不可验证奖励）对整体性能的影响。

Result: 无论是全在线还是半在线DPO与GRPO，这些方法在各类任务下性能和收敛速度都相似，且明显优于经典的离线方法。多任务联合训练同时提升了可验证与不可验证任务的表现。

Conclusion: 在线及半在线的DPO和GRPO等RL微调方法比离线方法更优，且各自间性能差异不大。多任务训练带来进一步增益。建议采用这些RL微调方法，并关注多任务设计以提升大语言模型效能。

Abstract: We investigate the effectiveness of reinforcement learning methods for
finetuning large language models when transitioning from offline to semi-online
to fully online regimes for both verifiable and non-verifiable tasks. Our
experiments cover training on verifiable math as well as non-verifiable
instruction following with a set of benchmark evaluations for both. Across
these settings, we extensively compare online and semi-online Direct Preference
Optimization and Group Reward Policy Optimization objectives, and surprisingly
find similar performance and convergence between these variants, which all
strongly outperform offline methods. We provide a detailed analysis of the
training dynamics and hyperparameter selection strategies to achieve optimal
results. Finally, we show that multi-tasking with verifiable and non-verifiable
rewards jointly yields improved performance across both task types.

</details>


### [47] [Enhancing User Engagement in Socially-Driven Dialogue through Interactive LLM Alignments](https://arxiv.org/abs/2506.21497)
*Jiashuo Wang,Kaitao Song,Chunpu Xu,Changhe Song,Yang Xiao,Dongsheng Li,Lili Qiu,Wenjie Li*

Main category: cs.CL

TL;DR: 本文创新性地通过用户模拟和互动型蒙特卡洛树搜索标记高低质量对话体验，并以此优化LLM，使其在社会性对话场景下表现出更高用户参与度，经验证有效。


<details>
  <summary>Details</summary>
Motivation: 在社交对话中提高用户参与度对于对话质量至关重要，但以往方法主要关注知识推理或对话计划，而这些并不能直接保证用户参与度，因此需要新的优化方向。

Method: 提出通过未来对话发展信号来学习用户参与度。采用用户对于对话意图的反应作为反馈，通过开发用户模拟器，并利用Monte Carlo Tree Search（i×MCTS）探索用户与LLM的互动，收集高低质量体验对比数据，再通过直接偏好优化（DPO）进行LLM模型对齐。

Result: 在两个社交场景（情感支持对话和劝善对话）下实验证明，该方法显著提升了LLM互动中的用户参与度。

Conclusion: 基于用户未来反应作为信号进行LLM模型优化能够有效增强社交对话场景中的用户参与度。

Abstract: Enhancing user engagement through interactions plays an essential role in
socially-driven dialogues. While prior works have optimized models to reason
over relevant knowledge or plan a dialogue act flow, the relationship between
user engagement and knowledge or dialogue acts is subtle and does not guarantee
user engagement in socially-driven dialogues. To this end, we enable
interactive LLMs to learn user engagement by leveraging signals from the future
development of conversations. Specifically, we adopt a more direct and relevant
indicator of user engagement, i.e., the user's reaction related to dialogue
intention after the interaction, as a reward to align interactive LLMs. To
achieve this, we develop a user simulator to interact with target interactive
LLMs and explore interactions between the user and the interactive LLM system
via \textit{i$\times$MCTS} (\textit{M}onte \textit{C}arlo \textit{T}ree
\textit{S}earch for \textit{i}nteraction). In this way, we collect a dataset
containing pairs of higher and lower-quality experiences using
\textit{i$\times$MCTS}, and align interactive LLMs for high-level user
engagement by direct preference optimization (DPO) accordingly. Experiments
conducted on two socially-driven dialogue scenarios (emotional support
conversations and persuasion for good) demonstrate that our method effectively
enhances user engagement in interactive LLMs.

</details>


### [48] [skLEP: A Slovak General Language Understanding Benchmark](https://arxiv.org/abs/2506.21508)
*Marek Šuppa,Andrej Ridzik,Daniel Hládek,Tomáš Javůrek,Viktória Ondrejová,Kristína Sásiková,Martin Tamajka,Marián Šimko*

Main category: cs.CL

TL;DR: 本文提出并开放了skLEP，第一个专为斯洛伐克语NLU评测设计的综合性基准，包含九种多样任务，并系统评估了多类模型，为斯洛伐克NLU研究提供了重要资源和工具。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏专门针对斯洛伐克语的自然语言理解基准，阻碍了该领域的进一步研究与模型发展，因此需要建立系统化的、适用于多个任务的基准测试。

Method: 作者汇总并构建了包含九类不同任务的skLEP基准，涵盖了token-level、sentence-pair和document-level三个层次。任务数据部分为新建斯洛伐克数据集，部分为英文NLU资源的精确翻译。然后对多种模型进行了系统测试和评估。

Result: skLEP成为首个系统评测斯洛伐克NLU模型的基准。此外，相关数据、工具包和榜单均已公开，为该领域研究提供了重要资源。

Conclusion: 本文提出了skLEP，这是第一个专为斯洛伐克自然语言理解（NLU）模型评测而设计的综合基准。通过skLEP，首次系统且广泛地评估了多种斯洛伐克专用、多语种及英语预训练语言模型，并公开了完整基准数据及开源工具包。

Abstract: In this work, we introduce skLEP, the first comprehensive benchmark
specifically designed for evaluating Slovak natural language understanding
(NLU) models. We have compiled skLEP to encompass nine diverse tasks that span
token-level, sentence-pair, and document-level challenges, thereby offering a
thorough assessment of model capabilities. To create this benchmark, we curated
new, original datasets tailored for Slovak and meticulously translated
established English NLU resources. Within this paper, we also present the first
systematic and extensive evaluation of a wide array of Slovak-specific,
multilingual, and English pre-trained language models using the skLEP tasks.
Finally, we also release the complete benchmark data, an open-source toolkit
facilitating both fine-tuning and evaluation of models, and a public
leaderboard at https://github.com/slovak-nlp/sklep in the hopes of fostering
reproducibility and drive future research in Slovak NLU.

</details>


### [49] [Potemkin Understanding in Large Language Models](https://arxiv.org/abs/2506.21521)
*Marina Mancoridis,Bec Weeks,Keyon Vafa,Sendhil Mullainathan*

Main category: cs.CL

TL;DR: 本文批判了当前使用传统基准测试评估LLM能力的做法，提出所谓“Potemkin理解”可能导致对模型能力的高估。结果显示，这种表面理解广泛存在。因此，评估LLM应更加重视模型与人类理解方式的一致性。


<details>
  <summary>Details</summary>
Motivation: 目前，大型语言模型(LLM)的能力经常通过基准数据集来评估，但仅根据模型在精心设计的问题上的表现来推断其真实能力是否合理存疑。作者希望探讨这种评估方法的合理性，并提出新的分析视角。

Method: 作者提出了一个形式化框架，从理论上分析用基准测试评估LLM能力的合理性。引入两种量化“Potemkin理解”现象的程序：一种是设计专门的基准测试，在三个不同领域进行测量，另一种是提供Potemkin现象发生率的下界的通用方法。

Result: 研究发现，Potemkin现象（即表面理解但本质上与人类理解相去甚远的假象）在多个模型、任务和领域中普遍存在。这种假象不仅仅是答错了问题，更反映出模型内部对概念表示存在更深的内在不一致性。

Conclusion: 仅仅依赖现有基准测试可能会导致对LLM能力的错误判断，因为这些测试未必能反映模型是否真正以人类方式理解概念。未来评测模型应关注理解的过程与一致性，而非单一结果。

Abstract: Large language models (LLMs) are regularly evaluated using benchmark
datasets. But what justifies making inferences about an LLM's capabilities
based on its answers to a curated set of questions? This paper first introduces
a formal framework to address this question. The key is to note that the
benchmarks used to test LLMs -- such as AP exams -- are also those used to test
people. However, this raises an implication: these benchmarks are only valid
tests if LLMs misunderstand concepts in ways that mirror human
misunderstandings. Otherwise, success on benchmarks only demonstrates potemkin
understanding: the illusion of understanding driven by answers irreconcilable
with how any human would interpret a concept. We present two procedures for
quantifying the existence of potemkins: one using a specially designed
benchmark in three domains, the other using a general procedure that provides a
lower-bound on their prevalence. We find that potemkins are ubiquitous across
models, tasks, and domains. We also find that these failures reflect not just
incorrect understanding, but deeper internal incoherence in concept
representations.

</details>


### [50] ["What's Up, Doc?": Analyzing How Users Seek Health Information in Large-Scale Conversational AI Datasets](https://arxiv.org/abs/2506.21532)
*Akshay Paruchuri,Maryam Aziz,Rohit Vartak,Ayman Ali,Best Uchehara,Xin Liu,Ishan Chatterjee,Monica Agrawal*

Main category: cs.CL

TL;DR: 通过构建并分析HealthChat-11K医疗对话数据集，系统揭示了用户与大语言模型健康对话的行为特征及风险，强调改进AI医疗支持能力的必要性。


<details>
  <summary>Details</summary>
Motivation: 越来越多的人通过大型语言模型（LLMs）与聊天机器人互动以获取医疗健康信息，但此类对话的本质与潜在风险仍未被充分研究。

Method: 作者从大规模对话式AI数据集中筛选并构建了HealthChat-11K数据集，包含1.1万个现实世界医疗对话和2.5万个用户消息。利用该数据集和临床医生主导的用户互动分类法，对21个医疗专科领域的用户与LLM互动方式进行了系统分析。

Result: 分析揭示了用户获取健康信息的行为模式，包括常见互动、不完整上下文、情感化行为以及容易引发LLM“迎合”的问题提问方式，并指出当前对话式AI在医疗支持能力上存在改进需求。

Conclusion: 当前部署的大语言模型健康对话AI在用户信息互动中存在风险和不足，需要针对真实用户行为予以改进。

Abstract: People are increasingly seeking healthcare information from large language
models (LLMs) via interactive chatbots, yet the nature and inherent risks of
these conversations remain largely unexplored. In this paper, we filter
large-scale conversational AI datasets to achieve HealthChat-11K, a curated
dataset of 11K real-world conversations composed of 25K user messages. We use
HealthChat-11K and a clinician-driven taxonomy for how users interact with LLMs
when seeking healthcare information in order to systematically study user
interactions across 21 distinct health specialties. Our analysis reveals
insights into the nature of how and why users seek health information, such as
common interactions, instances of incomplete context, affective behaviors, and
interactions (e.g., leading questions) that can induce sycophancy, underscoring
the need for improvements in the healthcare support capabilities of LLMs
deployed as conversational AI. Code and artifacts to retrieve our analyses and
combine them into a curated dataset can be found here:
https://github.com/yahskapar/HealthChat

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [51] [Making Graphs Irregular through Irregularising Walks](https://arxiv.org/abs/2506.21254)
*Julien Bensmail,Romain Bourneuf,Paul Colinot,Samuel Humeau,Timothée Martinod*

Main category: cs.DM

TL;DR: 本文在1-2-3猜想被解决的基础上，研究了只允许添加形成walk的边把普通图变为局部不规则多重图的问题，分析了新约束下的结构、算法和特定结果。


<details>
  <summary>Details</summary>
Motivation: 1-2-3猜想最近被解决，说明对于任意连通图（除$K_2$外）可以通过最多三重边使之变为局部不规则多重图。本文进一步研究实际应用中可能遇到的更强约束条件——只允许添加的边形成原图的walk，从而探讨该问题的新的理论与算法难点。

Method: 主要方法涉及对一般图和特定类别图进行结构性分析、组合性分析，以及针对walk约束提出新的算法研究最短不规则化walk的长度。

Result: 作者展示了引入walk约束后该问题的结构性和算法性变化，给出了最短不规则化walk长度的多种相关结果，并针对一般图和特定图类分别提出了结论。

Conclusion: 论文研究了在额外约束条件下将图转化为局部不规则多重图的问题。具体来说，要求添加到图中的边必须形成原图上的一条“walk”。作者分析了该约束带来的影响并给出了相关结构性、组合性、算法性的结果，尤其是在最短不规则化walk长度方面。

Abstract: The 1-2-3 Conjecture, introduced by Karo\'nski, {\L}uczak, and Thomason in
2004, was recently solved by Keusch. This implies that, for any connected graph
$G$ different from $K_2$, we can turn $G$ into a locally irregular multigraph
$M(G)$, i.e., in which no two adjacent vertices have the same degree, by
replacing some of its edges with at most three parallel edges. In this work, we
introduce and study a restriction of this problem under the additional
constraint that edges added to $G$ to reach $M(G)$ must form a walk (i.e., a
path with possibly repeated edges and vertices) of $G$. We investigate the
general consequences of having this additional constraint, and provide several
results of different natures (structural, combinatorial, algorithmic) on the
length of the shortest irregularising walks, for general graphs and more
restricted classes.

</details>


### [52] [Playing Snake on a Graph](https://arxiv.org/abs/2506.21281)
*Denise Graafsma,Bodo Manthey,Alexander Skopalik*

Main category: cs.DM

TL;DR: 文章推广了贪吃蛇游戏到一般图，定义snake-winnable图并研究其判定的复杂性，证明该问题在网格图上NP-难，并对一些特殊图（如奇数阶二分图、连通度1的图）给出完全描述，对哈密尔顿性与snake-winnable的关系也进行了深入分析。


<details>
  <summary>Details</summary>
Motivation: 将经典贪吃蛇游戏推广到任意无向图上，研究蛇如何在图中移动并“吃掉”所有顶点。

Method: 定义snake-winnable图，在图论框架下分析贪吃蛇游戏的决策难度，对不同的图结构（如奇数阶二分图、顶点连通度为1的图等）做完全刻画，并通过复杂性证明，分析判定snake-winnable的难度。

Result: 证明了判定一个图是否为snake-winnable在网格图中也是NP-难的；完全刻画了奇数阶二分图和顶点连通度为1的snake-winnable图；证明了所有哈密尔顿图都是snake-winnable；且非哈密尔顿snake-winnable图的girth最大为6，且该界取到。

Conclusion: 一般情形下判别snake-winnable图是计算困难问题，但特定结构可以完全解析，相关结论丰富了图论与经典游戏交叉领域的理论。

Abstract: Snake is a classic computer game, which has been around for decades. Based on
this game, we study the game of Snake on arbitrary undirected graphs. A snake
forms a simple path that has to move to an apple while avoiding colliding with
itself. When the snake reaches the apple, it grows longer, and a new apple
appears. A graph on which the snake has a strategy to keep eating apples until
it covers all the vertices of the graph is called snake-winnable. We prove that
determining whether a graph is snake-winnable is NP-hard, even when restricted
to grid graphs. We fully characterize snake-winnable graphs for odd-sized
bipartite graphs and graphs with vertex-connectivity 1. While Hamiltonian
graphs are always snake-winnable, we show that non-Hamiltonian snake-winnable
graphs have a girth of at most 6 and that this bound is tight.

</details>
