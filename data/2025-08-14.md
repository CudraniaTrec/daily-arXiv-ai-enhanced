<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 10]
- [cs.LO](#cs.LO) [Total: 4]
- [cs.CL](#cs.CL) [Total: 45]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Invertible Syntax without the Tuples (Functional Pearl)](https://arxiv.org/abs/2508.09856)
*Mathieu Boespflug,Arnaud Spiwack*

Main category: cs.PL

TL;DR: 该文指出 continuation-passing style 在解析与打印复杂结构数据时依旧有重要价值，提出三种基于该思想的方案，证明其与现代方法相比，具有良好表达性和通用性。


<details>
  <summary>Details</summary>
Motivation: 目前的组合子库多依赖 applicative、monadic 或 arrow 风格来设计解析与反序列化（打印）工具，旨在通过同样的语法描述实现既能解析又能输出结构化数据，尤其关注可处理列表、树等递归结构的高表达性。而 Danvy 的 continuation-passing 思想在这些探讨中被忽视，作者希望重新评估并推广这种方法。

Method: 本文借鉴 Danvy 的继续传递方法，提出三种基于 continuation-passing 的方案，用于处理具有递归和结构性的数据解析与打印问题。

Result: 作者展示了三种基于 continuation-passing 的解析与打印方案，表达能力能够覆盖递归和结构化数据，显示该方法相较于依赖型系统或幺半聚合具备竞争力。

Conclusion: 采用 continuation-passing style （CPS）的方法在更广泛、复杂的结构解析与打印任务中仍然非常有效，可以替代依赖类型或基于嵌套对的幺半集合聚合。

Abstract: In the seminal paper Functional unparsing, Olivier Danvy used continuation
passing to reanalyse printf-like format strings as combinators. In the
intervening decades, the conversation shifted towards a concurrent line of work
-- applicative, monadic or arrow-based combinator libraries -- in an effort to
find combinators for invertible syntax descriptions that simultaneously
determine a parser as well as a printer, and with more expressive power, able
to handle inductive structures such as lists and trees. Along the way,
continuation passing got lost. This paper argues that Danvy's insight remains
as relevant to the general setting as it was to the restricted setting of his
original paper. Like him, we present three solutions that exploit
continuation-passing style as an alternative to both dependent types and
monoidal aggregation via nested pairs, in our case to parse and print
structured data with increasing expressive power.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [Teaching Code Refactoring Using LLMs](https://arxiv.org/abs/2508.09332)
*Anshul Khairnar,Aarya Rajoju,Edward F. Gehringer*

Main category: cs.SE

TL;DR: 本研究将大语言模型应用于软件工程课程代码重构教学，提供了结构化、实时的反馈，显著提升了学生对重构和可维护性的理解与实践能力。


<details>
  <summary>Details</summary>
Motivation: 目前代码重构教学面临反馈有限且不一致的问题，尤其是在复杂的真实代码库中。借助LLM希望提升代码重构教学的有效性。

Method: 将大语言模型辅助的重构活动融入软件工程课程项目，使用结构化提示帮助学生识别并解决代码异味，通过学生反馈和代码质量提升进行评估。

Result: 结果显示LLM能帮助学生更好地理解理论与实际操作之间的联系，提升维护性和重构相关能力。

Conclusion: 研究表明，大语言模型能够在实际教学中为学生提供实时、情境感知的代码重构反馈，有助于学生更深入理解可维护性和重构原则。

Abstract: This Innovative Practice full paper explores how Large Language Models (LLMs)
can enhance the teaching of code refactoring in software engineering courses
through real-time, context-aware feedback. Refactoring improves code quality
but is difficult to teach, especially with complex, real-world codebases.
Traditional methods like code reviews and static analysis tools offer limited,
inconsistent feedback. Our approach integrates LLM-assisted refactoring into a
course project using structured prompts to help students identify and address
code smells such as long methods and low cohesion. Implemented in Spring 2025
in a long-lived OSS project, the intervention is evaluated through student
feedback and planned analysis of code quality improvements. Findings suggest
that LLMs can bridge theoretical and practical learning, supporting a deeper
understanding of maintainability and refactoring principles.

</details>


### [3] [Plug it and Play on Logs: A Configuration-Free Statistic-Based Log Parser](https://arxiv.org/abs/2508.09366)
*Qiaolin Qin,Xingfang Wu,Heng Li,Ettore Merlo*

Main category: cs.SE

TL;DR: PIPLUP是一种新型高效的统计式日志解析器，不需GPU和外部知识、易部署，准确率和泛化性媲美或优于现有方法，特别适合对成本和隐私有高要求的实际场景。


<details>
  <summary>Details</summary>
Motivation: 当前日志解析工具分为统计型和语义型两派。统计型方法虽然效率高、成本低、易于本地化、保护隐私，但准确率和泛化性较差，被认为不如可以利用预训练语言模型等外部知识的语义型方法。

Method: 提出了新的统计型日志解析器PIPLUP。PIPLUP去除了常量token位置的先验假设，采用与数据无关的参数设置来提升泛化能力，实现“即插即用”。

Result: 在开源大规模数据集上，PIPLUP用默认参数即可达到出色的准确率和泛化能力，优于最先进的Drain及其变种，并与最佳无监督语义型解析器LUNAR性能接近。此外，无需GPU和外部API即可高效运行，提升了实用性。

Conclusion: PIPLUP突破了统计型日志解析方法在准确率和泛化性方面的瓶颈，在效率、隐私、成本等方面具有更强的现实应用价值。

Abstract: Log parsing is an essential task in log analysis, and many tools have been
designed to accomplish it. Existing log parsers can be categorized into
statistic-based and semantic-based approaches. In comparison to semantic-based
parsers, existing statistic-based parsers tend to be more efficient, require
lower computational costs, and be more privacy-preserving thanks to on-premise
deployment, but often fall short in their accuracy (e.g., grouping or parsing
accuracy) and generalizability. Therefore, it became a common belief that
statistic-based parsers cannot be as effective as semantic-based parsers since
the latter could take advantage of external knowledge supported by pretrained
language models. Our work, however, challenges this belief with a novel
statistic-based parser, PIPLUP. PIPLUP eliminates the pre-assumption of the
position of constant tokens for log grouping and relies on data-insensitive
parameters to overcome the generalizability challenge, allowing "plug and play"
on given log files. According to our experiments on an open-sourced large log
dataset, PIPLUP shows promising accuracy and generalizability with the
data-insensitive default parameter set. PIPLUP not only outperforms the
state-of-the-art statistic-based log parsers, Drain and its variants, but also
obtains a competitive performance compared to the best unsupervised
semantic-based log parser (i.e., LUNAR). Further, PIPLUP exhibits low time
consumption without GPU acceleration and external API usage; our simple,
efficient, and effective approach makes it more practical in real-world
adoptions, especially when costs and privacy are of major concerns.

</details>


### [4] [Your Coding Intent is Secretly in the Context and You Should Deliberately Infer It Before Completion](https://arxiv.org/abs/2508.09537)
*Yanzhou Li,Tianlin Li,Yiran Zhang,Shangqing Liu,Aishan Liu,Yang Liu*

Main category: cs.SE

TL;DR: 本研究提出一种三阶段流程，通过分析函数前置代码、交互意图修正和意图驱动生成，显著提升了大模型在实际代码补全中的表现，尤其在缺乏注释时效果明显优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 以往大模型在代码自动补全任务中，依赖于明确说明（如函数注释），而现实代码仓库中往往缺乏这些注释，导致模型性能显著下降。

Method: 提出三阶段流程：(1) 意图推断：分析目标函数之前的代码，利用基于推理的提示框架逐步抽取和合成功能线索；(2) 交互式意图修正：当上下文不足时，模型生成若干意图候选，让开发者选择或编辑以确保符合需求；(3) 根据最终确定意图生成目标函数。此外，构建了包含4万个带有推理过程和注释的数据集。

Result: 在DevEval和ComplexCodeEval资源上的大规模实验证明，该方法在多种大模型上均有显著提升，参考与执行类指标相较于原始模型提升超过20%，交互修正阶段还能进一步提升效果。

Conclusion: 通过引入推理和交互机制，有效弥补了缺乏注释时大模型代码补全能力不足的问题，提升了自动生成代码的准确率。

Abstract: Large Language Models (LLMs) are increasingly used for function completion in
repository-scale codebases. Prior studies demonstrate that when explicit
instructions--such as docstrings--are provided, these models can generate
highly accurate implementations. However, in real-world repositories, such
annotations are frequently absent, and performance drops substantially without
them. To address this gap, we frame the task as a three-stage process. The
first stage focuses on intent inference, where the model analyzes the code
preceding the target function to uncover cues about the desired functionality.
Such preceding context often encodes subtle but critical information, and we
design a reasoning-based prompting framework to guide the LLM through
step-by-step extraction and synthesis of these signals before any code is
generated. The second stage introduces an optional interactive refinement
mechanism to handle cases where preceding context alone is insufficient for
intent recovery. In this stage, the model proposes a small set of candidate
intentions, enabling the developer to select or edit them so that the inferred
intent closely matches the actual requirement. Finally, in the third stage, the
LLM generates the target function conditioned on the finalized intent. To
support this pipeline, we curate a dataset of 40,000 examples annotated with
intermediate reasoning traces and corresponding docstrings. Extensive
experiments on DevEval and ComplexCodeEval show that our approach consistently
boosts multiple LLMs, achieving over 20\% relative gains in both
reference-based and execution-based metrics, with the interactive refinement
stage delivering additional improvements beyond these gains.

</details>


### [5] [ReqInOne: A Large Language Model-Based Agent for Software Requirements Specification Generation](https://arxiv.org/abs/2508.09648)
*Taohong Zhu,Lucas C. Cordeiro,Youcheng Sun*

Main category: cs.SE

TL;DR: 本文提出一种分步、模块化的大语言模型方法ReqInOne，用于自动生成结构化SRS。实验显示其准确率和结构清晰度均优于传统方法及入门工程师，部分模块达到甚至超过行业最佳水平。


<details>
  <summary>Details</summary>
Motivation: 手工编写软件需求规格说明书（SRS）费时且易产生歧义，现有自动化方法依赖人工，基于大语言模型（LLM）的方法存在幻觉和可控性差等问题。

Method: 提出ReqInOne，一个模拟人类需求工程师写SRS流程的模块化LLM代理，将SRS生成拆解为摘要、需求提取和需求分类三个任务，每步采用定制化提示模板。

Result: 实验证实，基于GPT-4o、LLaMA 3和DeepSeek-R1的ReqInOne相较于以往整体式GPT-4方法与入门级需求工程师，生成的SRS更准确、结构更优。模块化设计和分类组件带来了性能优势，对比分类SOTA模型也表现出色。

Conclusion: ReqInOne能有效提升LLM生成SRS的准确性和结构性，模块化分步设计优于整体式方法，部分环节性能可超越现有最佳模型。

Abstract: Software Requirements Specification (SRS) is one of the most important
documents in software projects, but writing it manually is time-consuming and
often leads to ambiguity. Existing automated methods rely heavily on manual
analysis, while recent Large Language Model (LLM)-based approaches suffer from
hallucinations and limited controllability. In this paper, we propose ReqInOne,
an LLM-based agent that follows the common steps taken by human requirements
engineers when writing an SRS to convert natural language into a structured
SRS. ReqInOne adopts a modular architecture by decomposing SRS generation into
three tasks: summary, requirement extraction, and requirement classification,
each supported by tailored prompt templates to improve the quality and
consistency of LLM outputs.
  We evaluate ReqInOne using GPT-4o, LLaMA 3, and DeepSeek-R1, and compare the
generated SRSs against those produced by the holistic GPT-4-based method from
prior work as well as by entry-level requirements engineers. Expert evaluations
show that ReqInOne produces more accurate and well-structured SRS documents.
The performance advantage of ReqInOne benefits from its modular design, and
experimental results further demonstrate that its requirement classification
component achieves comparable or even better results than the state-of-the-art
requirement classification model.

</details>


### [6] [DeputyDev -- AI Powered Developer Assistant: Breaking the Code Review Logjam through Contextual AI to Boost Developer Productivity](https://arxiv.org/abs/2508.09676)
*Vishal Khare,Vijay Saini,Deepak Sharma,Anand Kumar,Ankit Rana,Anshul Yadav*

Main category: cs.SE

TL;DR: DeputyDev是一款基于AI的代码审查助手，显著提升了审查效率，缩短了评审时间，在实际工程场景中效果突出，并已扩展为SaaS服务。


<details>
  <summary>Details</summary>
Motivation: 代码审查过程普遍存在低效问题，例如耗时长、反馈不一致、审查质量不达标等，TATA 1mg 的实际数据也显示拉取请求的处理和审查周期过长，严重影响软件交付效率和质量。

Method: 设计并开发了AI驱动的代码审查助手DeputyDev，通过自动化和上下文相关的代码审查提升效率。采用双盲A/B实验方法，组织200多名工程师参与测试DeputyDev对代码审查时长的影响。同时通过数据清理排除了极端异常值，确保结果的可靠性。

Result: DeputyDev显著缩短了代码审查平均时长，每个PR减少了23.09%，每行代码减少了40.13%。最终该工具在公司内全面推广，并以SaaS形式对外提供，其有效性得到了实际应用的验证。

Conclusion: AI辅助的代码审查助手DeputyDev能有效提升代码审查流程效率并改善开发周期。随着应用普及，其对提升软件开发质量和效率具有积极意义。

Abstract: This study investigates the implementation and efficacy of DeputyDev, an
AI-powered code review assistant developed to address inefficiencies in the
software development process. The process of code review is highly inefficient
for several reasons, such as it being a time-consuming process, inconsistent
feedback, and review quality not being at par most of the time. Using our
telemetry data, we observed that at TATA 1mg, pull request (PR) processing
exhibits significant inefficiencies, with average pick-up and review times of
73 and 82 hours, respectively, resulting in a 6.2 day closure cycle. The review
cycle was marked by prolonged iterative communication between the reviewing and
submitting parties. Research from the University of California, Irvine
indicates that interruptions can lead to an average of 23 minutes of lost
focus, critically affecting code quality and timely delivery. To address these
challenges, we developed DeputyDev's PR review capabilities by providing
automated, contextual code reviews. We conducted a rigorous double-controlled
A/B experiment involving over 200 engineers to evaluate DeputyDev's impact on
review times. The results demonstrated a statistically significant reduction in
both average per PR (23.09%) and average per-line-of-code (40.13%) review
durations. After implementing safeguards to exclude outliers, DeputyDev has
been effectively rolled out across the entire organisation. Additionally, it
has been made available to external companies as a Software-as-a-Service (SaaS)
solution, currently supporting the daily work of numerous engineering
professionals. This study explores the implementation and effectiveness of
AI-assisted code reviews in improving development workflow timelines and code.

</details>


### [7] [Inclusive Employment Pathways: Career Success Factors for Autistic Individuals in Software Engineering](https://arxiv.org/abs/2508.09680)
*Orvila Sarker,Mona Jamshaid,M. Ali Babar*

Main category: cs.SE

TL;DR: 本论文系统回顾了自闭症个体在软件工程领域的教育到就业流程，归纳并提出18个有助于其持续包容和发展的关键因素，并针对教育、企业管理和工具开发提出了具体实证建议，以消除现有障碍实现更广泛的神经多样性包容。


<details>
  <summary>Details</summary>
Motivation: 自闭症个体在ICT领域表现出独特优势，但在软件工程岗位上依然面临诸多障碍，包括工具缺乏、复杂的工作环境和不包容的招聘流程等，促使研究探索系统性的支持方法。

Method: 通过系统性综述（Systematic Review）分析了30项相关研究，总结归纳出18个成功因素，并按教育、职业培训、工作环境、辅助工具等四大主题分类。

Result: 研究明确了支持自闭症个体在软件工程领域持续融入的多项关键成功因素，并据此为相关教育机构、雇主和工具开发者提出了实证化的改善建议，如包容性协作方式、可及且结构化的工作环境、明确职责分工、针对性工作支持等。

Conclusion: 通过对现有研究系统性整理，论文为促进自闭症个体在软件工程行业长期包容与发展提供了理论依据和具有可操作性的政策建议。

Abstract: Research has highlighted the valuable contributions of autistic individuals
in the Information and Communication Technology (ICT) sector, particularly in
areas such as software development, testing, and cybersecurity. Their strengths
in information processing, attention to detail, innovative thinking, and
commitment to high-quality outcomes in the ICT domain are well-documented.
However, despite their potential, autistic individuals often face barriers in
Software Engineering (SE) roles due to a lack of personalised tools, complex
work environments, non-inclusive recruitment practices, limited co-worker
support, challenging social dynamics and so on. Motivated by the ethical
framework of the neurodiversity movement and the success of pioneering
initiatives like the Dandelion program, corporate Diversity, Equity, and
Inclusion (DEI) in the ICT sector has increasingly focused on autistic talent.
This movement fundamentally reframes challenges not as individual deficits but
as failures of environments designed for a neurotypical majority. Despite this
progress, there is no synthesis of knowledge reporting the full pathway from
software engineering education through to sustainable workplace inclusion. To
address this, we conducted a Systematic Review of 30 studies and identified 18
success factors grouped into four thematic categories: (1) Software Engineering
Education, (2) Career and Employment Training, (3) Work Environment, and (4)
Tools and Assistive Technologies. Our findings offer evidence-based
recommendations for educational institutions, employers, organisations, and
tool developers to enhance the inclusion of autistic individuals in SE. These
include strategies for inclusive meeting and collaboration practices,
accessible and structured work environments, clear role and responsibility
definitions, and the provision of tailored workplace accommodations.

</details>


### [8] [LibRec: Benchmarking Retrieval-Augmented LLMs for Library Migration Recommendations](https://arxiv.org/abs/2508.09791)
*Junxiao Han,Yarong Wang,Xiaodong Gu,Cuiyun Gao,Yao Wan,Song Han,David Lo,Shuiguang Deng*

Main category: cs.SE

TL;DR: 本文提出LibRec框架，通过结合大模型和检索增强技术自动推荐Python库替代方案，并利用commit消息挖掘迁移意图，提升推荐准确性。实验涵盖多模型和多策略评估，效果显著，同时发布LibEval新基准助力后续研究。


<details>
  <summary>Details</summary>
Motivation: 目前在软件开发中，库迁移经常出现，开发者需要在迁移过程中获得合适的替代库推荐。现有方法在自动识别和推荐方面准确性不高。

Method: 提出LibRec框架，结合大语言模型（LLM）与检索增强生成（RAG）技术，自动推荐替代库，并借助上下文学习从commit消息中抽取迁移意图，提高推荐准确性。引入LibEval基准，包含2888条迁移记录用于评估。

Result: 在LibEval数据集上，评估了10种流行LLM在框架中的表现，进行了消融实验，分析了关键组件贡献，探讨了不同提示策略对性能的影响，针对不同意图类型评估了效果，并详细分析了失败案例。

Conclusion: LibRec框架有效提升了自动库推荐的准确性。利用大模型与RAG技术结合，以及对迁移意图的深入挖掘，显著增强了迁移推荐任务的性能。提出的LibEval也为后续评测提供了新基准。

Abstract: In this paper, we propose LibRec, a novel framework that integrates the
capabilities of LLMs with retrieval-augmented generation(RAG) techniques to
automate the recommendation of alternative libraries. The framework further
employs in-context learning to extract migration intents from commit messages
to enhance the accuracy of its recommendations. To evaluate the effectiveness
of LibRec, we introduce LibEval, a benchmark designed to assess the performance
in the library migration recommendation task. LibEval comprises 2,888 migration
records associated with 2,368 libraries extracted from 2,324 Python
repositories. Each migration record captures source-target library pairs, along
with their corresponding migration intents and intent types. Based on LibEval,
we evaluated the effectiveness of ten popular LLMs within our framework,
conducted an ablation study to examine the contributions of key components
within our framework, explored the impact of various prompt strategies on the
framework's performance, assessed its effectiveness across various intent
types, and performed detailed failure case analyses.

</details>


### [9] [Fast and Accurate Heuristics for Bus-Factor Estimation](https://arxiv.org/abs/2508.09828)
*Sebastiano Antonio Piccolo*

Main category: cs.SE

TL;DR: 本文针对项目关键成员流失风险的 bus-factor 评估问题，提出了两种高效且准确的新型近似方法，在大规模数据上表现优越，并已开源。


<details>
  <summary>Details</summary>
Motivation: bus-factor 是衡量项目关键成员流失风险的重要指标，但目前对于其计算问题属于 NP-Hard，难以高效分析大规模项目。

Method: 将软件项目抽象为开发者与任务的二分图，提出两种基于迭代图剥离的新近似启发法：最小覆盖（Minimum Coverage）和最大覆盖（Maximum Coverage），用于主流 bus-factor 形式化定义。

Result: 在超过 1000 个合成幂律图上的实证分析表明，两种新启发法优于常用的基于节点度数的方法，估算更准确且可扩展至百万级节点与边的图，在数分钟内完成计算。同时，这些启发法对开发者与任务分配结构变动具有鲁棒性。

Conclusion: 提出的近似启发法能高效、准确地估算大型软件系统的 bus-factor，优于现有方法，并已开源，便于后续研究与实际采用。

Abstract: The bus-factor is a critical risk indicator that quantifies how many key
contributors a project can afford to lose before core knowledge or
functionality is compromised. Despite its practical importance, accurately
computing the bus-factor is NP-Hard under established formalizations, making
scalable analysis infeasible for large software systems.
  In this paper, we model software projects as bipartite graphs of developers
and tasks and propose two novel approximation heuristics, Minimum Coverage and
Maximum Coverage, based on iterative graph peeling, for two influential
bus-factor formalizations. Our methods significantly outperform the widely
adopted degree-based heuristic, which we show can yield severely inflated
estimates.
  We conduct a comprehensive empirical evaluation on over $1\,000$ synthetic
power-law graphs and demonstrate that our heuristics provide tighter estimates
while scaling to graphs with millions of nodes and edges in minutes. Our
results reveal that the proposed heuristics are not only more accurate but also
robust to structural variations in developer-task assignment graph. We release
our implementation as open-source software to support future research and
practical adoption.

</details>


### [10] [Exploring the Potential of Large Language Models in Fine-Grained Review Comment Classification](https://arxiv.org/abs/2508.09832)
*Linh Nguyen,Chunhua Liu,Hong Yi Lin,Patanamon Thongtanunam*

Main category: cs.SE

TL;DR: 本文提出利用大型语言模型自动分类代码评审评论，较现有深度学习方法表现更佳，尤其在高低频类别上均有稳定准确性，有望提升代码评审的自动化和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的代码评审评论分类方法主要依赖于监督式机器学习，训练模型需要大量人工标注，成本高且依赖标注数据分布。

Method: 使用大型语言模型（LLM）对代码评审评论进行自动分类，并与当前最先进的深度学习方法进行性能对比，涉及评论的17个类别。

Result: LLM在代码评审评论分类任务上表现优越，尤其在训练样本较少的有用类别上准确率更高，表现较为均衡，无需依赖特定小样本分布。

Conclusion: LLM可为代码评审分析提供高效且可扩展的解决方案，有助于提升代码评审流程的有效性。

Abstract: Code review is a crucial practice in software development. As code review
nowadays is lightweight, various issues can be identified, and sometimes, they
can be trivial. Research has investigated automated approaches to classify
review comments to gauge the effectiveness of code reviews. However, previous
studies have primarily relied on supervised machine learning, which requires
extensive manual annotation to train the models effectively. To address this
limitation, we explore the potential of using Large Language Models (LLMs) to
classify code review comments. We assess the performance of LLMs to classify 17
categories of code review comments. Our results show that LLMs can classify
code review comments, outperforming the state-of-the-art approach using a
trained deep learning model. In particular, LLMs achieve better accuracy in
classifying the five most useful categories, which the state-of-the-art
approach struggles with due to low training examples. Rather than relying
solely on a specific small training data distribution, our results show that
LLMs provide balanced performance across high- and low-frequency categories.
These results suggest that the LLMs could offer a scalable solution for code
review analytics to improve the effectiveness of the code review process.

</details>


### [11] [An Empirical Study of CGO Usage in Go Projects -- Distribution, Purposes, Patterns and Critical Issues](https://arxiv.org/abs/2508.09875)
*Jinbao Chen,Boyao Ding,Yu Zhang,Qingwei Li,Fugen Tang*

Main category: cs.SE

TL;DR: 本文首次大规模分析了Go语言的CGO用法及其风险，发现了集中使用场景及多种问题，提出临时和永久改进方案，有效提升开发安全性和工具链可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有关于多语言开发的FFI研究多集中于Python和Java，对Go语言中的CGO关注甚少，而CGO作为新兴的FFI，存在独特的风险。

Method: 通过对920个开源Go项目中的CGO使用情况进行实证研究，开发了CGOAnalyzer工具对CGO相关特征进行高效识别和量化分析。

Result: 1）有11.3%的Go项目使用CGO，且主要集中在部分项目中；2）CGO主要有四类用途，观察到15种使用模式；3）发现了19类CGO相关问题，包括一个关键问题即不必要的指针检查会因Go编译工具链限制造成运行时崩溃风险；4）提供了临时解决方案以减少不必要的指针检查，降低崩溃风险；5）提交了针对Go工具链的永久性修复提案并获接收。

Conclusion: 系统性地揭示了CGO使用的分布、模式、用途和关联问题，对提升Go语言的开发效率和工具链健壮性具有显著意义。

Abstract: Multilingual software development integrates multiple languages into a single
application, with the Foreign Function Interface (FFI) enabling seamless
interaction. While FFI boosts efficiency and extensibility, it also introduces
risks. Existing studies focus on FFIs in languages like Python and Java,
neglecting CGO, the emerging FFI in Go, which poses unique risks.
  To address these concerns, we conduct an empirical study of CGO usage across
920 open-source Go projects. Our study aims to reveal the distribution,
patterns, purposes, and critical issues associated with CGO, offering insights
for developers and the Go team. We develop CGOAnalyzer, a tool to efficiently
identify and quantify CGO-related features. Our findings reveal that: (1) 11.3%
of analyzed Go projects utilize CGO, with usage concentrated in a subset of
projects; (2) CGO serves 4 primary purposes, including system-level
interactions and performance optimizations, with 15 distinct usage patterns
observed; (3) 19 types of CGO-related issues exist, including one critical
issue involving unnecessary pointer checks that pose risks of runtime crashes
due to limitations in the current Go compilation toolchain; (4) a temporary
solution reduces unnecessary pointer checks, mitigating crash risks, and (5) we
submitted a proposal to improve the Go toolchain for a permanent fix, which has
been grouped within an accepted proposal for future resolution. Our findings
provide valuable insights for developers and the Go team, enhancing development
efficiency and reliability while improving the robustness of the Go toolchain.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [12] [TPTP World Infrastructure for Non-classical Logics](https://arxiv.org/abs/2508.09318)
*Alexander Steen,Geoff Sutcliffe*

Main category: cs.LO

TL;DR: 本论文介绍了TPTP World基础设施扩展支持了非经典逻辑自动定理证明，涵盖语言、工具和实例应用，特别强调了多模态逻辑方面的具体实现。


<details>
  <summary>Details</summary>
Motivation: 传统的TPTP World主要支持经典逻辑，随着对非经典逻辑ATP需求的增长，亟需扩展其基础设施以支持更广泛的逻辑系统。

Method: 通过梳理TPTP World现有功能，重点介绍其针对量化正常多模态逻辑的应用细节。

Result: TPTP World已从v9.0.0开始支持非经典逻辑，现有配套工具和问题库可适用于多种非经典逻辑，并详述了对多模态逻辑的支持。

Conclusion: 文章总结了TPTP World在支持非经典逻辑自动定理证明方面的基础设施，包括语言扩展、问题与解决方案以及相关工具。

Abstract: The TPTP World is the well established infrastructure that supports research,
development, and deployment of Automated Theorem Proving (ATP) systems. The
TPTP World supports a range of classical logics, and since release v9.0.0 has
supported non-classical logics. This paper provides a self-contained
comprehensive overview of the TPTP World infrastructure for ATP in
non-classical logics: the non-classical language extension, problems and
solutions, and tool support. A detailed description of use of the
infrastructure for quantified normal multi-modal logic is given.

</details>


### [13] [On Middle Grounds for Preference Statements](https://arxiv.org/abs/2508.09553)
*Anne-Marie George,Ana Ozaki*

Main category: cs.LO

TL;DR: 该论文提出逻辑化的意见表达方法，分析并证明偏好表达下中间立场可能不存在或不唯一，同时给出判定和寻找中间立场的算法。


<details>
  <summary>Details</summary>
Motivation: 在群体决策或讨论中，利益相关者常有冲突意见，需要一种逻辑化的表达及寻找中间立场的理论方法来协调分歧。

Method: 通过逻辑表达的方式建模利益相关者的意见，基于偏好层次和字典序模型，理论分析中间立场的存在性和唯一性，并设计相关算法。

Result: 证明了中间立场在某些情况下不存在或不唯一，并提出了相关判定和搜索算法。

Conclusion: 对于偏好陈述，中间立场可能不存在，也可能不唯一，并提出了判断存在性和寻找中间立场的算法。

Abstract: In group decisions or deliberations, stakeholders are often confronted with
conflicting opinions. We investigate a logic-based way of expressing such
opinions and a formal general notion of a middle ground between stakeholders.
Inspired by the literature on preferences with hierarchical and lexicographic
models, we instantiate our general framework to the case where stakeholders
express their opinions using preference statements of the form I prefer 'a' to
'b', where 'a' and 'b' are alternatives expressed over some attributes, e.g.,
in a trolley problem, one can express I prefer to save 1 adult and 1 child to 2
adults (and 0 children). We prove theoretical results on the existence and
uniqueness of middle grounds. In particular, we show that, for preference
statements, middle grounds may not exist and may not be unique. We also provide
algorithms for deciding the existence and finding middle grounds.

</details>


### [14] [Short proofs without interference](https://arxiv.org/abs/2508.09851)
*Adrian Rebola-Pardo*

Main category: cs.LO

TL;DR: 本论文通过命题动态逻辑，设计出能消除干扰且表达力不减的SAT证明框架，并为后续高效证明检查奠定了基础。


<details>
  <summary>Details</summary>
Motivation: SAT证明系统中证明-记录技术常受“干扰”影响，限制了有效性。当前短证明方法均存在此问题，作者欲寻求无干扰且同样有力的替代方案。

Method: 作者利用命题动态逻辑的方法，设计了新的证明框架，并阐述了构建RUP风格决策规程的初步方向。

Result: 提出了首个能消除干扰现象的新框架，并为未来开发高效证明检查技术建立了理论基础。

Conclusion: 通过提出基于命题动态逻辑的框架，作者成功消除了SAT求解中证明系统的干扰现象，并保持了原有证明系统的表达能力。

Abstract: Interference is a phenomenon on proof systems for SAT solving that is both
counter-intuitive and bothersome when developing proof-logging techniques.
However, all existing proof systems that can produce short proofs for all
inprocessing techniques deployed by SAT present this feature. Based on insights
from propositional dynamic logic, we propose a framework that eliminates
interference while preserving the same expressive power of interference-based
proofs. Furthermore, we propose a first building blocks towards RUP-like
decision procedures for our dynamic logic-based frameworks, which are essential
to developing effective proof checking methods.

</details>


### [15] [Efficient Volume Computation for SMT Formulas](https://arxiv.org/abs/2508.09934)
*Arijit Shaw,Uddalok Sarkar,Kuldeep S. Meel*

Main category: cs.LO

TL;DR: 该论文提出了一种扩展SMT定量分析能力的新算法ttc，能高效计算SMT线性实数算术公式的可满足区域体积。方法包括多面体分解、体积计算及集合并。实验显示性能优越，对定量验证等领域有重要价值。


<details>
  <summary>Details</summary>
Motivation: SMT（可满足性模理论）现已广泛用于自动化推理问题，能够处理更丰富的变量类型。现有研究更多关注于判定可满足问题，而实际应用（如软件验证等）的定量分析需求增加，如求SMT公式定义区域的体积。因此，本文旨在推动SMT从逻辑判定到定量分析的能力扩展。

Method: 提出了一种新的高效算法ttc，它将SMT的线性实数算术（LRA）公式的解空间分解为多个重叠的凸多面体，通过体积计算与集合并技术，最终得到总的可满足区域体积，并结合流式集合并、体积计算、AllSAT等最新技术进行实现。

Result: 通过实验证明ttc算法在体积计算效率上显著优于现有主流方法，在多个领域的相关应用中取得了更好的性能表现。

Conclusion: ttc显著提升了SMT在线性实数算术体积计算上的能力，为软件验证、网络安全等涉及定量验证的领域提供了强有力的技术支撑。其方法可作为现有SMT工具的重要补充。

Abstract: Satisfiability Modulo Theory (SMT) has recently emerged as a powerful tool
for solving various automated reasoning problems across diverse domains. Unlike
traditional satisfiability methods confined to Boolean variables, SMT can
reason on real-life variables like bitvectors, integers, and reals. A natural
extension in this context is to ask quantitative questions. One such query in
the SMT theory of Linear Real Arithmetic (LRA) is computing the volume of the
entire satisfiable region defined by SMT formulas. This problem is important in
solving different quantitative verification queries in software verification,
cyber-physical systems, and neural networks, to mention a few.
  We introduce ttc, an efficient algorithm that extends the capabilities of SMT
solvers to volume computation. Our method decomposes the solution space of SMT
Linear Real Arithmetic formulas into a union of overlapping convex polytopes,
then computes their volumes and calculates their union. Our algorithm builds on
recent developments in streaming-mode set unions, volume computation
algorithms, and AllSAT techniques. Experimental evaluations demonstrate
significant performance improvements over existing state-of-the-art approaches.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [16] [ParallelSearch: Train your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning](https://arxiv.org/abs/2508.09303)
*Shu Zhao,Tan Yu,Anbang Xu,Japinder Singh,Aaditya Shukla,Rama Akkiraju*

Main category: cs.CL

TL;DR: 该论文提出了ParallelSearch框架，让大语言模型在处理信息检索任务时可以并行执行独立的查询，大幅提升了效率和性能，实验证明对可并行的复杂问题显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有的推理增强搜索代理在多步信息检索上很强，但由于架构限制，它们对于可以并行处理的独立查询仍然采用严格的顺序处理方式，导致效率瓶颈，尤其是在需要比对多个实体时。

Method: 提出ParallelSearch，一个新型的强化学习框架，使大语言模型能够识别可并行化的查询结构，并发执行多个搜索操作。通过设置专门的奖励函数，激励模型识别独立的查询组件，综合考虑正确性、查询分解质量与并行执行的收益。

Result: 在七个问答基准任务上，ParallelSearch平均性能提升2.9%。针对可并行化问题，性能提升达12.7%，且仅使用原顺序方法69.6%的模型调用次数。

Conclusion: ParallelSearch有效突破了顺序处理的架构瓶颈，显著提升了推理型搜索代理在并行化查询场景下的效率和准确性。

Abstract: Reasoning-augmented search agents such as Search-R1, trained via
reinforcement learning with verifiable rewards (RLVR), demonstrate remarkable
capabilities in multi-step information retrieval from external knowledge
sources. These agents address the limitations of their parametric memory by
dynamically gathering relevant facts to address complex reasoning tasks.
However, existing approaches suffer from a fundamental architectural
limitation: they process search queries strictly sequentially, even when
handling inherently parallelizable and logically independent comparisons. This
sequential bottleneck significantly constrains computational efficiency,
particularly for queries that require multiple entity comparisons. To address
this critical limitation, we propose ParallelSearch, a novel reinforcement
learning framework that empowers large language models (LLMs) to recognize
parallelizable query structures and execute multiple search operations
concurrently. Our approach introduces dedicated reward functions that
incentivize the identification of independent query components while preserving
answer accuracy through jointly considering correctness, query decomposition
quality, and parallel execution benefits. Comprehensive experiments demonstrate
that ParallelSearch outperforms state-of-the-art baselines by an average
performance gain of 2.9% across seven question-answering benchmarks. Notably,
on parallelizable questions, our method achieves a 12.7% performance
improvement while requiring only 69.6% of the LLM calls compared to sequential
approaches.

</details>


### [17] [Leveraging Large Language Models for Rare Disease Named Entity Recognition](https://arxiv.org/abs/2508.09323)
*Nan Miles Xi,Yu Deng,Lin Wang*

Main category: cs.CL

TL;DR: 本文结合多种提示方法分析GPT-4o在罕见病领域NER任务中的表现，突破了传统模型对大规模标注数据的依赖，在低资源环境下达到甚至超越现有方法，开启了大模型在稀有领域数据处理的全新可能。


<details>
  <summary>Details</summary>
Motivation: 罕见病领域的命名实体识别(NER)面临标签数据稀缺、实体类型语义模糊、长尾分布等独特挑战。

Method: 评估GPT-4o在低资源条件下进行罕见病NER的能力，采用零样本提示、少样本上下文学习、检索增强生成(RAG)、任务级微调等提示方法。构建了结构化提示框架，并引入了两种语义引导的少样本示例选择方法来提升实际效果并降低标注成本。

Result: 在RareDis语料库上的实验中，GPT-4o与BioClinicalBERT相比表现出竞争或更优的性能，任务级微调达到了新的SOTA。成本效益分析表明，少样本提示在低token消耗下效果显著，RAG增益有限。错误分类揭示边界漂移、类型混淆等常见失败模式，提示可通过后处理及混合优化进一步完善。

Conclusion: 经过提示优化的LLM（如GPT-4o）在稀缺标注数据的罕见病生物医学NER任务中，可成为传统有监督模型的有效且可扩展的替代方案。

Abstract: Named Entity Recognition (NER) in the rare disease domain poses unique
challenges due to limited labeled data, semantic ambiguity between entity
types, and long-tail distributions. In this study, we evaluate the capabilities
of GPT-4o for rare disease NER under low-resource settings, using a range of
prompt-based strategies including zero-shot prompting, few-shot in-context
learning, retrieval-augmented generation (RAG), and task-level fine-tuning. We
design a structured prompting framework that encodes domain-specific knowledge
and disambiguation rules for four entity types. We further introduce two
semantically guided few-shot example selection methods to improve in-context
performance while reducing labeling effort. Experiments on the RareDis Corpus
show that GPT-4o achieves competitive or superior performance compared to
BioClinicalBERT, with task-level fine-tuning yielding new state-of-the-art
(SOTA) results. Cost-performance analysis reveals that few-shot prompting
delivers high returns at low token budgets, while RAG offers marginal
additional benefit. An error taxonomy highlights common failure modes such as
boundary drift and type confusion, suggesting opportunities for post-processing
and hybrid refinement. Our results demonstrate that prompt-optimized LLMs can
serve as effective, scalable alternatives to traditional supervised models in
biomedical NER, particularly in rare disease applications where annotated data
is scarce.

</details>


### [18] [TEN: Table Explicitization, Neurosymbolically](https://arxiv.org/abs/2508.09324)
*Nikita Mehrotra,Aayush Kumar,Sumit Gulwani,Arjun Radhakrishna,Ashish Tiwari*

Main category: cs.CL

TL;DR: 本论文提出神经符号混合方法TEN，通过结构化链式提示、大模型生成和符号检查反馈循环，实现从半结构化文本高效提取表格数据，效果和用户满意度明显优于纯神经网络方法。


<details>
  <summary>Details</summary>
Motivation: 从半结构化文本中提取表格数据非常具有挑战性，尤其是当文本没有一致的分隔符时。纯神经网络方法容易出现幻觉且无法施加强约束，因此需要新的方法提升表格提取的准确性。

Method: 提出了一种神经符号混合方法TEN。首先通过大模型进行结构分解提示（chain-of-thought方式）生成初步表格，然后用符号检查器评估表格的结构合理性并检测幻觉或遗漏。检查器结果由“批判型大模型”生成修正建议，形成自我调试闭环。

Result: TEN在多数据集和多个评测指标上都大幅优于纯神经网络基线，包括更高的精确匹配准确率和显著降低的幻觉率。用户研究也表明TEN生成的表格更准确、更易验证和修正，参与者在超过60%的案例中偏好TEN方法。

Conclusion: 神经符号混合的TEN方法能显著提升从半结构化文本中提取表格数据的准确性及可靠性，且受到用户青睐。

Abstract: We present a neurosymbolic approach, TEN, for extracting tabular data from
semistructured input text. This task is particularly challenging for text input
that does not use special delimiters consistently to separate columns and rows.
Purely neural approaches perform poorly due to hallucinations and their
inability to enforce hard constraints. TEN uses Structural Decomposition
prompting - a specialized chain-of-thought prompting approach - on a large
language model (LLM) to generate an initial table, and thereafter uses a
symbolic checker to evaluate not only the well-formedness of that table, but
also detect cases of hallucinations or forgetting. The output of the symbolic
checker is processed by a critique-LLM to generate guidance for fixing the
table, which is presented to the original LLM in a self-debug loop. Our
extensive experiments demonstrate that TEN significantly outperforms purely
neural baselines across multiple datasets and metrics, achieving significantly
higher exact match accuracy and substantially reduced hallucination rates. A
21-participant user study further confirms that TEN's tables are rated
significantly more accurate (mean score: 5.0 vs 4.3; p = 0.021), and are
consistently preferred for ease of verification and correction, with
participants favoring our method in over 60% of the cases.

</details>


### [19] [Decoding Neural Emotion Patterns through Natural Language Processing Embeddings](https://arxiv.org/abs/2508.09337)
*Gideon Vos,Maryam Ebrahimpour,Liza van Eijk,Zoltan Sarnyai,Mostafa Rahimi Azghadi*

Main category: cs.CL

TL;DR: 本文提出了一种结合文本分析与脑区映射的新方法，无需神经影像，能从文本推断大脑情感激活模式。实验结果表明该方法科学有效，可区分健康与抑郁群体、大模型与人类在情感表达上的差异。该框架为大规模、多情感维度的脑功能分析及AI情感表达评估提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 在计算神经科学和情感计算领域，理解语言中的情感表达如何与大脑功能相关是一个关键问题。然而，传统的神经影像技术昂贵且受限于实验室环境，而丰富的数字文本为情感-大脑关联研究提供了新渠道。此前的研究常将脑影像情感定位与文本分析分开处理，缺乏两者的整合。

Method: 提出了一种计算框架，无需神经影像，直接将文本中的情感内容映射到解剖学定义的大脑区域。具体方法包括：使用OpenAI的text-embedding-ada-002进行文本嵌入生成高维语义表示，通过降维与聚类识别情感类别，并映射到18个与情感加工相关的大脑区域。实验包括：分析健康与抑郁被试的对话数据以比较映射模式、在GoEmotions数据集上应用该方法，以及比较人类与大语言模型生成文本推断的大脑激活差异。情感强度通过词汇分析评分。

Result: 结果显示，该方法能够实现神经解剖学上合理且空间特异性高的映射。抑郁被试表现出与负面情感相关的边缘系统更高激活。离散情感能被成功区分。大模型生成文本在基础情感分布上与人类类似，但在同理心和自我相关区域（内侧前额叶及后扣带皮层）的激活方面不及人类。

Conclusion: 该方法具有低成本和可扩展性的优点，能够对自然语言进行大规模脑区分析、辨别临床人群差异，并为评估人工智能的情感表达力提供脑区基准。

Abstract: Understanding how emotional expression in language relates to brain function
is a challenge in computational neuroscience and affective computing.
Traditional neuroimaging is costly and lab-bound, but abundant digital text
offers new avenues for emotion-brain mapping. Prior work has largely examined
neuroimaging-based emotion localization or computational text analysis
separately, with little integration. We propose a computational framework that
maps textual emotional content to anatomically defined brain regions without
requiring neuroimaging. Using OpenAI's text-embedding-ada-002, we generate
high-dimensional semantic representations, apply dimensionality reduction and
clustering to identify emotional groups, and map them to 18 brain regions
linked to emotional processing. Three experiments were conducted: i) analyzing
conversational data from healthy vs. depressed subjects (DIAC-WOZ dataset) to
compare mapping patterns, ii) applying the method to the GoEmotions dataset and
iii) comparing human-written text with large language model (LLM) responses to
assess differences in inferred brain activation. Emotional intensity was scored
via lexical analysis. Results showed neuroanatomically plausible mappings with
high spatial specificity. Depressed subjects exhibited greater limbic
engagement tied to negative affect. Discrete emotions were successfully
differentiated. LLM-generated text matched humans in basic emotion distribution
but lacked nuanced activation in empathy and self-referential regions (medial
prefrontal and posterior cingulate cortex). This cost-effective, scalable
approach enables large-scale analysis of naturalistic language, distinguishes
between clinical populations, and offers a brain-based benchmark for evaluating
AI emotional expression.

</details>


### [20] [The Human-AI Hybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in Complex Domains](https://arxiv.org/abs/2508.09349)
*Cathy Speed,Ahmed A. Metwally*

Main category: cs.CL

TL;DR: 提出了HAH-Delphi人机混合共识方法，结合AI和小型专家组，能高效准确达成高质量共识，应用于健康和运动等领域表现出良好可扩展性，可为未来个性化和条件化指导提供新范式。


<details>
  <summary>Details</summary>
Motivation: 在证据复杂、冲突或不足以得出明确结论的领域，传统专家共识方法存在高负担、过度简化和难以处理条件细节等问题，且受到信息过载和证据碎片化的挑战，因此亟需一种更高效、可靠且细致的方法来提升专家共识建立的质量。

Method: 提出并评估了一种“人机混合德尔菲法（HAH-Delphi）”，结合了生成式AI模型（Gemini 2.5 Pro）、少量资深人类专家和结构化引导，分三个阶段进行测试：1）回顾性复现已发布共识；2）前瞻性与专家比较；3）在两大领域的实际部署和应用。

Result: AI在第一阶段复现了95%的已发表专家共识结论，在第二阶段与人类专家的观点一致率达95%，但未能覆盖专家的经验性和实际操作细节。在第三阶段，小型专家组快速实现了90%以上的共识覆盖和主题饱和。AI为共识过程提供了稳定、基于文献的框架，加速共识达成和分歧解决。

Conclusion: HAH-Delphi框架可灵活、可扩展地生成高质量、具情境关联性的共识成果，其方法学上的稳健性已在健康、教练和运动科学等领域得到验证，有望成为大规模生成个性化、条件化指导意见和共识标准的基础。

Abstract: Expert consensus plays a critical role in domains where evidence is complex,
conflicting, or insufficient for direct prescription. Traditional methods, such
as Delphi studies, consensus conferences, and systematic guideline synthesis,
offer structure but face limitations including high panel burden, interpretive
oversimplification, and suppression of conditional nuance. These challenges are
now exacerbated by information overload, fragmentation of the evidence base,
and increasing reliance on publicly available sources that lack expert
filtering. This study introduces and evaluates a Human-AI Hybrid Delphi
(HAH-Delphi) framework designed to augment expert consensus development by
integrating a generative AI model (Gemini 2.5 Pro), small panels of senior
human experts, and structured facilitation. The HAH-Delphi was tested in three
phases: retrospective replication, prospective comparison, and applied
deployment in two applied domains (endurance training and resistance and mixed
cardio/strength training). The AI replicated 95% of published expert consensus
conclusions in Phase I and showed 95% directional agreement with senior human
experts in Phase II, though it lacked experiential and pragmatic nuance. In
Phase III, compact panels of six senior experts achieved >90% consensus
coverage and reached thematic saturation before the final participant. The AI
provided consistent, literature-grounded scaffolding that supported divergence
resolution and accelerated saturation. The HAH-Delphi framework offers a
flexible, scalable approach for generating high-quality, context-sensitive
consensus. Its successful application across health, coaching, and performance
science confirms its methodological robustness and supports its use as a
foundation for generating conditional, personalised guidance and published
consensus frameworks at scale.

</details>


### [21] [Flow-SLM: Joint Learning of Linguistic and Acoustic Information for Spoken Language Modeling](https://arxiv.org/abs/2508.09350)
*Ju-Chieh Chou,Jiawei Zhou,Karen Livescu*

Main category: cs.CL

TL;DR: 本文提出一种同时生成语义与声学信息的无文本语音模型，通过flow-matching方法预测连续声学向量，在保留语言内容的同时提升了语音生成的声学细节，与现有方法相比在声学质量上具有优势。


<details>
  <summary>Details</summary>
Motivation: 目前的无文本语音模型（SLMs）依赖于预测离散语义标记，并借助独立的vocoder添加语音声学信息，因此缺乏对声学细节的控制与上下文信息利用。本工作旨在解决这一局限。

Method: 提出联合建模语义与声学信息的方法：同时生成语义标记和连续实值的声学帧表示，并采用flow-matching目标函数，在语义标记条件下预测连续声学向量。还研究了多个未来语义标记预测对模型效果的影响。

Result: 联合建模方法在语言基准表现可与现有模型媲美，同时在生成语音时能够更好地还原声学细节。

Conclusion: 联合预测语义与声学信息的新方法既保持了原有语言表现能力，又明显提升了声学生成质量，扩展了文本无关语音模型的能力。

Abstract: Textless spoken language models (SLMs) are generative models of speech that
do not rely on text supervision. Most textless SLMs learn to predict the next
semantic token, a discrete representation of linguistic content, and rely on a
separate vocoder to add acoustic information to the generated speech. Such
models have no access to acoustic context and no built-in control over acoustic
details. In this work, we propose to jointly model linguistic and acoustic
information by generating semantic tokens and a continuous real-valued
representation of the acoustic frame. We use a flow-matching objective to
predict the continuous vector conditioned on the semantic tokens. We study the
design space of this approach and find that predicting multiple future semantic
tokens helps preserve linguistic information. Our approach achieves comparable
performance to existing models in terms of linguistic likelihood benchmarks,
while providing better acoustic detail in prompted generation.

</details>


### [22] [APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification](https://arxiv.org/abs/2508.09378)
*Artem Chernodub,Aman Saini,Yejin Huh,Vivek Kulkarni,Vipul Raheja*

Main category: cs.CL

TL;DR: 本文提出了一种新的自动提示归纳与优化方法（APIO），无需人工种子提示，在语法纠错和文本简化等任务中实现了最佳性能，推进了LLM自动提示优化方向。


<details>
  <summary>Details</summary>
Motivation: 近年来，随着大语言模型（LLM）的发展，通过提示（prompt）实现各种自然语言处理任务变得越来越普遍。现有方法多依赖人工设计的提示，或者需预先给定种子提示，存在一定的局限性。

Method: 本文提出了APIO方法，这是一种无需人工指定种子提示的自动提示归纳与优化方法，主要用于语法错误纠正（GEC）和文本简化任务。

Result: 基于APIO的方法在GEC和文本简化任务上取得了同类纯LLM提示方法中的最新最佳效果。

Conclusion: APIO能有效提升LLM在相关NLP任务中的表现，简化了提示工程流程。文章还公开了相关数据、代码、提示和输出。

Abstract: Recent advancements in large language models (LLMs) have enabled a wide range
of natural language processing (NLP) tasks to be performed through simple
prompt-based interactions. Consequently, several approaches have been proposed
to engineer prompts that most effectively enable LLMs to perform a given task
(e.g., chain-of-thought prompting). In settings with a well-defined metric to
optimize model performance, automatic prompt optimization (APO) methods have
been developed to refine a seed prompt. Advancing this line of research, we
propose APIO, a simple but effective prompt induction and optimization approach
for the tasks of Grammatical Error Correction (GEC) and Text Simplification,
without relying on manually specified seed prompts. APIO achieves a new
state-of-the-art performance for purely LLM-based prompting methods on these
tasks. We make our data, code, prompts, and outputs publicly available.

</details>


### [23] [Columbo: Expanding Abbreviated Column Names for Tabular Data Using Large Language Models](https://arxiv.org/abs/2508.09403)
*Ting Cai,Stephen Sheen,AnHai Doan*

Main category: cs.CL

TL;DR: 该论文针对表格缩写列名扩展问题，构建了真实数据集、改进了准确性评估指标，并提出了基于大模型的Columbo方法，在多个数据集上显著超越现有技术，已应用于实际数据门户。


<details>
  <summary>Details</summary>
Motivation: 表格中缩写列名扩展为全称（如“esal”扩展为“employee salary”）对于数据处理具有重要意义，目前实际应用中存在准确性和数据适用性的问题。

Method: 论文提出三项主要贡献：1）发现并指出现有公开合成数据存在局限，并新建了4个真实领域数据集；2）批评现有准确性评估方法，并提出更合理的同义词感知评估指标；3）开发了Columbo，一种结合上下文、规则、链式推理和分词分析的LLM方法。

Result: Columbo在五个数据集上的表现，准确率比现有最先进的方案（NameGuess）提升了4-29%。Columbo已在实际环境科学数据门户（EDI）中部署。

Conclusion: 论文系统性提升了表格缩写列名扩展任务的应用基础和评估标准，并提出了效果显著的新方法Columbo，推动了技术进步与实际应用落地。

Abstract: Expanding the abbreviated column names of tables, such as ``esal'' to
``employee salary'', is critical for numerous downstream data tasks. This
problem arises in enterprises, domain sciences, government agencies, and more.
In this paper we make three contributions that significantly advances the state
of the art. First, we show that synthetic public data used by prior work has
major limitations, and we introduce 4 new datasets in enterprise/science
domains, with real-world abbreviations. Second, we show that accuracy measures
used by prior work seriously undercount correct expansions, and we propose new
synonym-aware measures that capture accuracy much more accurately. Finally, we
develop Columbo, a powerful LLM-based solution that exploits context, rules,
chain-of-thought reasoning, and token-level analysis. Extensive experiments
show that Columbo significantly outperforms NameGuess, the current most
advanced solution, by 4-29\%, over 5 datasets. Columbo has been used in
production on EDI, a major data portal for environmental sciences.

</details>


### [24] [Leveraging Zipformer Model for Effective Language Identification in Code-Switched Child-Directed Speech](https://arxiv.org/abs/2508.09430)
*Lavanya Shankar,Leibny Paola Garcia Perera*

Main category: cs.CL

TL;DR: 提出并验证Zipformer对中英双语不均衡童语场景的语言识别能力，相较基线方法提升显著（BAC提升15.47%），且在不同后端均表现稳健，表明transformer架构有应用前景。


<details>
  <summary>Details</summary>
Motivation: 在双语环境下，尤其是针对儿童交流，代码转换和语言识别面临诸多挑战。

Method: 采用Zipformer模型处理包含不平衡的普通话和英语语音数据，通过选择其内部层来提取嵌入特征，并与不同后端进行比较分析。

Result: Zipformer在不同后端下表现稳健，能够有效处理不平衡数据，其平衡准确率（BAC）达到81.89%，较传统语言识别基线提升15.47%。

Conclusion: Zipformer的内部层可有效编码语言特征，提升语言识别能力，显示出transformer编码器架构在实际应用中的潜力。

Abstract: Code-switching and language identification in child-directed scenarios
present significant challenges, particularly in bilingual environments. This
paper addresses this challenge by using Zipformer to handle the nuances of
speech, which contains two imbalanced languages, Mandarin and English, in an
utterance. This work demonstrates that the internal layers of the Zipformer
effectively encode the language characteristics, which can be leveraged in
language identification. We present the selection methodology of the inner
layers to extract the embeddings and make a comparison with different
back-ends. Our analysis shows that Zipformer is robust across these backends.
Our approach effectively handles imbalanced data, achieving a Balanced Accuracy
(BAC) of 81.89%, a 15.47% improvement over the language identification
baseline. These findings highlight the potential of the transformer encoder
architecture model in real scenarios.

</details>


### [25] [From Charts to Fair Narratives: Uncovering and Mitigating Geo-Economic Biases in Chart-to-Text](https://arxiv.org/abs/2508.09450)
*Ridwan Mahbub,Mohammed Saidul Islam,Mir Tafseer Nayeem,Md Tahmid Rahman Laskar,Mizanur Rahman,Shafiq Joty,Enamul Hoque*

Main category: cs.CL

TL;DR: 论文系统揭示了现有视觉-语言大模型在图表自动文本生成时，因国家经济水平不同而产生描述情感偏见的问题，并评测当前去偏方法的效果有限，呼吁进一步研究更有效的去偏技术。数据与代码已公开。


<details>
  <summary>Details</summary>
Motivation: 本论文关注于利用图表自动生成文本摘要的任务（chart-to-text），特别是在大型视觉-语言模型（VLMs）被迅速应用于该领域时，鲜有人关注其生成结果潜在的地缘经济偏见问题。作者认为这些偏见可能带来社会伤害，因此进行深入研究。

Method: 作者对6个广泛使用的专有和开源VLM模型，设计了大规模评测实验，涵盖6,000份图表-国家配对，分析这些模型在生成图表摘要时对不同国家经济地位（高、中、低收入）带来的情感倾向，并测试了利用积极暗示的推断时去偏技巧。

Result: 研究显示，现有VLM在面对高收入国家时，生成更积极的文本描述，而对中低收入国家则偏向消极，即使仅改变国家归属变量也存在此现象。不同模型的偏见程度不一，如GPT-4o-mini、Gemini-1.5-Flash与Phi-3.5等。采用推断时基于正面干扰物的去偏方法仅部分有效，偏见问题依然复杂。

Conclusion: 本论文发现大型视觉-语言模型在图表生成文本任务中，会强化地缘经济偏见，且目前应用的去偏方法效果有限，需要更强大和系统性的去偏解决方案。研究开放了相关数据集与代码供学界参考。

Abstract: Charts are very common for exploring data and communicating insights, but
extracting key takeaways from charts and articulating them in natural language
can be challenging. The chart-to-text task aims to automate this process by
generating textual summaries of charts. While with the rapid advancement of
large Vision-Language Models (VLMs), we have witnessed great progress in this
domain, little to no attention has been given to potential biases in their
outputs. This paper investigates how VLMs can amplify geo-economic biases when
generating chart summaries, potentially causing societal harm. Specifically, we
conduct a large-scale evaluation of geo-economic biases in VLM-generated chart
summaries across 6,000 chart-country pairs from six widely used proprietary and
open-source models to understand how a country's economic status influences the
sentiment of generated summaries. Our analysis reveals that existing VLMs tend
to produce more positive descriptions for high-income countries compared to
middle- or low-income countries, even when country attribution is the only
variable changed. We also find that models such as GPT-4o-mini,
Gemini-1.5-Flash, and Phi-3.5 exhibit varying degrees of bias. We further
explore inference-time prompt-based debiasing techniques using positive
distractors but find them only partially effective, underscoring the complexity
of the issue and the need for more robust debiasing strategies. Our code and
dataset are publicly available here.

</details>


### [26] [User-centric Subjective Leaderboard by Customizable Reward Modeling](https://arxiv.org/abs/2508.09463)
*Qi Jia,Xiujie Song,Zicheng Zhang,Yijin Guo,Kaiwei Zhang,Zijian Chen,Guangtao Zhai*

Main category: cs.CL

TL;DR: 本文提出用户中心的主观性排行榜（USL）和可自定义奖励模型（CRM），基于大量真实用户偏好多样性数据构建。CRM不仅参数小于主流大模型，却实现更强泛化和匹配能力，能够动态地根据用户偏好为LLM排名，填补了现有评测与用户现实需求之间的空白。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）评测主要集中在可验证任务上，这些客观且静态的基准难以满足实际用户选型需求。因此，实际应用中用户难以依据个人需求选择合适的模型。本文试图解决这一问题。

Method: 研究收集了超过1万份真实的主观用户偏好数据，揭示了人类偏好的多样性和矛盾性。基于这些数据，作者提出了用户中心的主观性排行榜（USL），并设计了可自定义奖励模型（CRM），可根据不同用户和场景调整模型评测。

Result: 作者构建的CRM仅有40亿参数，但在泛化能力和偏好匹配上超越了GPT-4.1和Gemini-2.5-pro等主流大模型，对新主题和准则也有很好的适应性。USL排名与相互矛盾的偏好呈现强负相关性，能够更合理地反映不同用户的真实需求。

Conclusion: 主观性排行榜（USL）及CRM能够更准确地反映不同用户的需求和偏好，为大语言模型选择提供更有效、个性化的参考标准。

Abstract: Existing benchmarks for large language models (LLMs) predominantely focus on
assessing their capabilities through verifiable tasks. Such objective and
static benchmarks offer limited utility for practical LLM selection, making it
difficult for users to find suitable models for their individual needs. To
bridge this gap, we present the first User-Centric Subjective Leaderboard
(USL), which provides a preference-driven, dynamic ranking of LLMs across
diverse real-world scenarios. Our work is built upon a thorough investigation
of real human preference data, involving more than 10K subjective queries. Our
investigation reveals significant diversity and contradictions in human
preferences, which limit the effectiveness of state-of-the-art reward models.
To address this, we introduce Customizable Reward Models (CRMs). With only 4B
parameters, our CRM surpasses the performance of leading models such as GPT-4.1
and Gemini-2.5-pro, showing exceptional generalization capabilities across new
topics and criteria. The USL, powered by CRMs, exhibits strong negative
correlations to contradictory preferences.

</details>


### [27] [Learning Facts at Scale with Active Reading](https://arxiv.org/abs/2508.09494)
*Jessy Lin,Vincent-Pierre Berges,Xilun Chen,Wen-Tau Yih,Gargi Ghosh,Barlas Oğuz*

Main category: cs.CL

TL;DR: 这篇论文提出了Active Reading主动学习框架，让大模型更有效吸收指定领域知识，在多项基准测试上显著优于传统微调方法，并发布了新一代Wikipedia专家模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在参数中存储了大量知识，但其记忆和回忆事实的能力并不可靠，且受到训练数据中事实出现频率等多因素影响，相关机制尚不明确。实际应用中，缺乏确保模型能可靠学习特定知识的方法和工具。

Method: 提出了Active Reading框架，让模型通过自发生成的学习策略，主动学习特定材料。作者在专家领域，通过Active Reading训练模型，并与普通微调及其他数据增强方法做对比试验。此外，还尝试将Active Reading扩展到预训练规模。

Result: 实验表明，采用Active Reading框架的专家模型知识吸收效果显著优于普通微调。具体指标：在Wikipedia-grounded SimpleQA子集上达到66%（比普通微调提升313%）；在FinanceBench任务上达到26%（提升160%）。Meta WikiExpert-8B模型在事实性问答上性能超过许多更大参数量模型。

Conclusion: Active Reading能显著提升LLMs在特定领域的知识吸收和回忆能力。该框架不仅适用于微调阶段，也可用于大规模预训练，有助于构建更准确的事实性模型。

Abstract: LLMs are known to store vast amounts of knowledge in their parametric memory.
However, learning and recalling facts from this memory is known to be
unreliable, depending largely on the prevalence of particular facts in the
training data and other factors which are poorly understood. Practitioners are
lacking tools which will allow them to ensure that the models learn a given
body of knowledge reliably and consistently. To this end, we propose Active
Reading: a framework where we train models to study a given set of material
with self-generated learning strategies. First, we demonstrate models trained
with Active Reading on expert domains absorb significantly more knowledge than
vanilla finetuning and other data augmentations. We train expert 8B models that
achieve 66% on a Wikipedia-grounded subset of SimpleQA (+313% relative over
vanilla finetuning) and 26% on FinanceBench (+160% relative over vanilla
finetuning) by applying Active Reading to the source documents for each
benchmark. Finally, we show that Active Reading can be utilized at pre-training
scale to build more factual models. As a demonstration of this, we release Meta
WikiExpert-8B, a Wikipedia-expert model trained on 1 trillion generated tokens,
which outcompetes models with hundreds of billions of parameters on factual QA.

</details>


### [28] [From Ranking to Selection: A Simple but Efficient Dynamic Passage Selector for Retrieval Augmented Generation](https://arxiv.org/abs/2508.09497)
*Siyuan Meng,Junming Liu,Yirong Chen,Song Mao,Pinlong Cai,Guohang Yan,Botian Shi,Ding Wang*

Main category: cs.CL

TL;DR: DPS动态选择相关文段，有效提升RAG系统在复杂任务中的推理与生成表现，尤其在多跳和跨文档场景中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有RAG的重排序方法通常独立评分并固定Top-K数量，难以在多跳查询中处理跨文档综合证据，造成信息遗漏或噪声增加。为此，提出动态且更智能的文段选择方法。

Method: 提出了Dynamic Passage Selector (DPS)，将文段选择视为监督学习问题，能够捕捉跨文段的依赖关系，并动态选择最相关文段用于生成，无需更改现有RAG流程。

Result: 在五个基准测试中，DPS表现优于当前最先进的重排序和微调方法。在MuSiQue数据集上，F1分数相比Qwen3-reranker和RankingGPT分别提升了30.06%和15.4%。

Conclusion: DPS能够显著提升复杂RAG任务中的推理和生成能力，通过自适应选择证据，有效克服传统Top-K选择的不足。

Abstract: Retrieval-augmented generation (RAG) systems are often bottlenecked by their
reranking modules, which typically score passages independently and select a
fixed Top-K size. This approach struggles with complex multi-hop queries that
require synthesizing evidence across multiple documents, creating a trade-off
where small K values omit crucial information and large K values introduce
noise. To address this, we introduce the Dynamic Passage Selector (DPS), a
novel reranking framework that treats passage selection as a supervised
learning problem. Unlike traditional point-wise or list-wise methods, DPS is
fine-tuned to capture inter-passage dependencies and dynamically select the
most relevant set of passages for generation. As a seamless plug-and-play
module, DPS requires no modifications to the standard RAG pipeline.
Comprehensive evaluations on five benchmarks show that DPS consistently
outperforms state-of-the-art rerankers and fine-tuning methods. Notably, on the
challenging MuSiQue dataset, DPS improves the F1-score by 30.06% and 15.4% over
strong baselines like Qwen3-reranker and RankingGPT, respectively. Our results
demonstrate that by enabling adaptive evidence selection, DPS substantially
enhances reasoning capabilities in complex RAG scenarios.

</details>


### [29] [LACA: Improving Cross-lingual Aspect-Based Sentiment Analysis with LLM Data Augmentation](https://arxiv.org/abs/2508.09515)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

TL;DR: 用LLM替代翻译工具来生成目标语言的高质量伪标注数据，无需翻译也能显著提升跨语言情感分析表现，效果超过现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的跨语言细粒度情感分析（ABSA）方法通常依赖翻译工具来解决语言障碍，但这些工具的可靠性较低，限制了模型的性能。

Method: 提出了一个新框架：先训练ABSA模型对目标语言的无标注数据进行预测，再通过大型语言模型（LLM）生成更自然、表达更准确的伪标注文本，最后用这些伪标注数据再次微调ABSA模型。无需传统翻译工具。

Result: 该方法在六种语言和五个主流模型上进行了验证，结果优于翻译基础的方法。微调的大型语言模型性能也超越了较小的多语言模型。

Conclusion: 利用LLM生成高质量伪标注数据可以有效提高跨语言ABSA的性能，摆脱了依赖传统翻译工具，推动了该领域方法的革新。

Abstract: Cross-lingual aspect-based sentiment analysis (ABSA) involves detailed
sentiment analysis in a target language by transferring knowledge from a source
language with available annotated data. Most existing methods depend heavily on
often unreliable translation tools to bridge the language gap. In this paper,
we propose a new approach that leverages a large language model (LLM) to
generate high-quality pseudo-labelled data in the target language without the
need for translation tools. First, the framework trains an ABSA model to obtain
predictions for unlabelled target language data. Next, LLM is prompted to
generate natural sentences that better represent these noisy predictions than
the original text. The ABSA model is then further fine-tuned on the resulting
pseudo-labelled dataset. We demonstrate the effectiveness of this method across
six languages and five backbone models, surpassing previous state-of-the-art
translation-based approaches. The proposed framework also supports generative
models, and we show that fine-tuned LLMs outperform smaller multilingual
models.

</details>


### [30] [Cross-lingual Aspect-Based Sentiment Analysis: A Survey on Tasks, Approaches, and Challenges](https://arxiv.org/abs/2508.09516)
*Jakub Šmíd,Pavel Král*

Main category: cs.CL

TL;DR: 本文全面梳理了跨语言方面级情感分析（ABSA），总结了任务、数据集和方法，分析了现有挑战并指明未来研究方向，填补了该领域系统综述的空缺。


<details>
  <summary>Details</summary>
Motivation: 尽管ABSA领域获得了长足进展，但绝大多数研究聚焦于单语环境，跨语言ABSA研究不足且缺乏系统化综述。本文旨在填补这一领域的文献综述空白。

Method: 本文进行了文献回顾与归纳，系统性梳理了跨语言ABSA的主要任务、数据集和方法，并分析现有技术及其在跨语言场景下的表现。

Result: 该综述归纳了跨语言ABSA的核心任务（如方面项抽取、情感分类等）、公开数据集、通用建模与迁移范式，并结合单语、多语和大模型（LLM）等相关研究，分析其对跨语言ABSA的推动作用，最后总结了面临的核心挑战并为未来给出建议。

Conclusion: 本论文综述了跨语言细粒度情感分析（ABSA）的研究进展，总结关键任务、数据集、建模范式和跨语言迁移方法，指出当前的挑战并提出未来研究方向。

Abstract: Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis
task that focuses on understanding opinions at the aspect level, including
sentiment towards specific aspect terms, categories, and opinions. While ABSA
research has seen significant progress, much of the focus has been on
monolingual settings. Cross-lingual ABSA, which aims to transfer knowledge from
resource-rich languages (such as English) to low-resource languages, remains an
under-explored area, with no systematic review of the field. This paper aims to
fill that gap by providing a comprehensive survey of cross-lingual ABSA. We
summarize key ABSA tasks, including aspect term extraction, aspect sentiment
classification, and compound tasks involving multiple sentiment elements.
Additionally, we review the datasets, modelling paradigms, and cross-lingual
transfer methods used to solve these tasks. We also examine how existing work
in monolingual and multilingual ABSA, as well as ABSA with LLMs, contributes to
the development of cross-lingual ABSA. Finally, we highlight the main
challenges and suggest directions for future research to advance cross-lingual
ABSA systems.

</details>


### [31] [UWBa at SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval](https://arxiv.org/abs/2508.09517)
*Ladislav Lenc,Daniel Cífka,Jiří Martínek,Jakub Šmíd,Pavel Král*

Main category: cs.CL

TL;DR: 作者提出了结合多种大语言模型的零样本事实查证检索系统，单语和跨语种排名较高，尤其NV-Embed-v2模型表现突出，模型融合对部分语种有助提升。


<details>
  <summary>Details</summary>
Motivation: 传统多语种嵌入模型效果不佳，亟需一种无需语言标签和训练、通用且高效的事实核查检索系统，对跨语言与单语言任务均适用。

Method: 使用多种大型语言模型（如NV-Embed、GPT、Mistral）生成文本嵌入，主要采用英文翻译作为输入，基于余弦相似度检索最相关的事实主张。针对部分语种问题，尝试了模型融合方式。

Result: 该系统在相关国际评测中，单语检索排名第7，跨语种检索排名第9。NVIDIA NV-Embed-v2效果最好，一些语种通过模型组合有所提升。

Conclusion: 通过结合多种大语言模型获取文本嵌入并测量余弦相似度，系统在单语和跨语种任务中分别取得第7和第9名的结果，显示其零样本事实查证检索的有效性。特别地，NVIDIA NV-Embed-v2模型表现最佳，部分语言使用模型组合进一步提升了效果。

Abstract: This paper presents a zero-shot system for fact-checked claim retrieval. We
employed several state-of-the-art large language models to obtain text
embeddings. The models were then combined to obtain the best possible result.
Our approach achieved 7th place in monolingual and 9th in cross-lingual
subtasks. We used only English translations as an input to the text embedding
models since multilingual models did not achieve satisfactory results. We
identified the most relevant claims for each post by leveraging the embeddings
and measuring cosine similarity. Overall, the best results were obtained by the
NVIDIA NV-Embed-v2 model. For some languages, we benefited from model
combinations (NV-Embed & GPT or Mistral).

</details>


### [32] [COMPEER: Controllable Empathetic Reinforcement Reasoning for Emotional Support Conversation](https://arxiv.org/abs/2508.09521)
*Yunxiao Wang,Meng Liu,Wenqi Liu,Kaiyu Jiang,Bin Wen,Fan Yang,Tingting Gao,Guorui Zhou,Liqiang Nie*

Main category: cs.CL

TL;DR: 本文提出一种结合心理学和语言推理的情感支持对话系统，数据集和多重创新措施提升了模型的共情能力，实现更优的人性化支持。


<details>
  <summary>Details</summary>
Motivation: 现有情感支持对话模型缺乏基于心理学原理的深层共情推理，不能很好地提供情感支持。

Method: 作者提出了可控的共情推理方法，将自然语言推理与结构化心理步骤结合。构建了细粒度的数据集，并采用了带有统一过程-结果奖励模型的强化学习。此外，引入了基于人格的对话重写和冗余感知奖励重加权策略，缓解了回复重复性。

Result: 实验表明，该方法在情感支持能力上取得了显著提升，模型共情和支持能力更接近人类水平。

Conclusion: 该论文的方法显著提升了情感支持对话模型的性能，有助于推动类似人类的共情支持系统发展。

Abstract: Emotional support conversations are crucial for promoting emotional
well-being, yet current models often lack deep empathetic reasoning grounded in
psychological principles. To address this, we propose controllable empathetic
reasoning, which combines natural language reasoning with structured
psychological steps. We construct a fine-grained dataset annotated with
reasoning correctness and response preferences to enable this capability. To
further enhance training, we employ reinforcement learning with a unified
process-outcome reward model that delivers precise feedback. To mitigate
response repetitiveness from entropy collapse, we introduce personality-based
dialogue rewriting and a redundancy-aware reward reweighting strategy. Our
approach significantly improves model's emotional support ability, advancing
the development of empathetic, human-like support systems.

</details>


### [33] [The Surprising Effectiveness of Membership Inference with Simple N-Gram Coverage](https://arxiv.org/abs/2508.09603)
*Skyler Hallinan,Jaehun Jung,Melanie Sclar,Ximing Lu,Abhilasha Ravichander,Sahana Ramnath,Yejin Choi,Sai Praneeth Karimireddy,Niloofar Mireshghallah,Xiang Ren*

Main category: cs.CL

TL;DR: 本文提出一种仅依赖文本输出的N-Gram Coverage成员推断攻击，对黑盒API模型如GPT-4有效，性能超过甚至追平白盒方法，并揭示大模型逐步增强的数据隐私保护。


<details>
  <summary>Details</summary>
Motivation: 现有的成员推断攻击需要访问模型的隐藏状态或概率分布，不能适用于API限制的闭源大型语言模型（如GPT-4），而实际应用中检测模型训练数据泄露、版权风险等需求广泛。

Method: 提出了一种仅使用目标模型文本输出的成员推断攻击方法：N-Gram Coverage Attack。具体做法是以候选文本的前缀为条件生成多个模型输出，再通过n-gram重叠度指标，统计生成文本与真实后缀的相似性，进而判断文本是否属于训练集成员。

Result: 在多种基准测试上，N-Gram Coverage Attack超越了其他黑盒方法，并能达到甚至超过主流白盒攻击效果，无需模型内部信息。发现攻击性能随生成序列数量（算力预算）增加而提升。进一步用该方法研究OpenAI闭源模型，发现新模型如GPT-4o在成员推断上的鲁棒性增强，说明隐私保护有进步趋势。

Conclusion: 提出了针对黑盒API模型的新攻击方法，实现了高精度成员推断，对现有闭源大模型的隐私风险做了量化分析，并揭示了模型逐渐加强隐私保护的趋势。

Abstract: Membership inference attacks serves as useful tool for fair use of language
models, such as detecting potential copyright infringement and auditing data
leakage. However, many current state-of-the-art attacks require access to
models' hidden states or probability distribution, which prevents investigation
into more widely-used, API-access only models like GPT-4. In this work, we
introduce N-Gram Coverage Attack, a membership inference attack that relies
solely on text outputs from the target model, enabling attacks on completely
black-box models. We leverage the observation that models are more likely to
memorize and subsequently generate text patterns that were commonly observed in
their training data. Specifically, to make a prediction on a candidate member,
N-Gram Coverage Attack first obtains multiple model generations conditioned on
a prefix of the candidate. It then uses n-gram overlap metrics to compute and
aggregate the similarities of these outputs with the ground truth suffix; high
similarities indicate likely membership. We first demonstrate on a diverse set
of existing benchmarks that N-Gram Coverage Attack outperforms other black-box
methods while also impressively achieving comparable or even better performance
to state-of-the-art white-box attacks - despite having access to only text
outputs. Interestingly, we find that the success rate of our method scales with
the attack compute budget - as we increase the number of sequences generated
from the target model conditioned on the prefix, attack performance tends to
improve. Having verified the accuracy of our method, we use it to investigate
previously unstudied closed OpenAI models on multiple domains. We find that
more recent models, such as GPT-4o, exhibit increased robustness to membership
inference, suggesting an evolving trend toward improved privacy protections.

</details>


### [34] [AINL-Eval 2025 Shared Task: Detection of AI-Generated Scientific Abstracts in Russian](https://arxiv.org/abs/2508.09622)
*Tatiana Batura,Elena Bruches,Milana Shvenk,Valentin Malykh*

Main category: cs.CL

TL;DR: 该论文介绍了针对俄语科学摘要AI生成检测的大规模共享任务与数据集，推动了多领域泛化检测研究，并建立了持续研究的平台。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）的快速发展，文本生成技术取得了巨大进步，导致人类与AI生成内容之间难以区分，尤其是在科学出版和多语种环境下。现有检测工具资源有限，威胁学术诚信，亟需有效检测AI生成科学摘要的解决方案。

Method: 构建了一个包含52,305条大规模数据集，涵盖12个科学领域的真人摘要与5种主流LLM生成的摘要（GPT-4-Turbo、Gemma2-27B、Llama3.3-70B、Deepseek-V3、GigaChat-Lite），并以此举办了AINL-Eval 2025共享任务。任务要求开发能泛化到未知领域与未见模型的鲁棒解决方案。组织分为两阶段，吸引10支队伍、159份投稿。

Result: 参赛系统在识别AI生成内容方面表现优异。成功建立了持续的共享任务平台，支持该领域的持续研究与进步。数据集及平台已公开发布。

Conclusion: AINL-Eval 2025任务不仅推动了AI生成科学摘要检测方法的进步，还为该领域的长期发展和研究提供了公开资源和平台。

Abstract: The rapid advancement of large language models (LLMs) has revolutionized text
generation, making it increasingly difficult to distinguish between human- and
AI-generated content. This poses a significant challenge to academic integrity,
particularly in scientific publishing and multilingual contexts where detection
resources are often limited. To address this critical gap, we introduce the
AINL-Eval 2025 Shared Task, specifically focused on the detection of
AI-generated scientific abstracts in Russian. We present a novel, large-scale
dataset comprising 52,305 samples, including human-written abstracts across 12
diverse scientific domains and AI-generated counterparts from five
state-of-the-art LLMs (GPT-4-Turbo, Gemma2-27B, Llama3.3-70B, Deepseek-V3, and
GigaChat-Lite). A core objective of the task is to challenge participants to
develop robust solutions capable of generalizing to both (i) previously unseen
scientific domains and (ii) models not included in the training data. The task
was organized in two phases, attracting 10 teams and 159 submissions, with top
systems demonstrating strong performance in identifying AI-generated content.
We also establish a continuous shared task platform to foster ongoing research
and long-term progress in this important area. The dataset and platform are
publicly available at https://github.com/iis-research-team/AINL-Eval-2025.

</details>


### [35] [Improving Diversity in Language Models: When Temperature Fails, Change the Loss](https://arxiv.org/abs/2508.09654)
*Alexandre Verine,Florian Le Bronnec,Kunhao Zheng,Alexandre Allauzen,Yann Chevaleyre,Benjamin Negrevergne*

Main category: cs.CL

TL;DR: 本文分析了解码温度对语言模型多样性和质量的影响，认为提升温度并不能有效提升输出覆盖度。提出利用Precision-Recall框架优化损失函数，实验证明该方法能比传统温度调整实现更优的多样性与准确性平衡，为语言模型训练提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 提升语言模型的多样性一直是重要但困难的目标。目前常见的方法是提升解码温度，但这种做法在实际效果上存在局限。作者希望深入分析温度调整对输出质量和多样性的影响机制。

Method: 通过分析简单且常见的案例，深入探讨不同温度对模型Precision和Recall的影响，并引入Precision-Recall框架，重新思考语言模型损失函数的设计，以提升模型在多样性和准确性之间的平衡。

Result: 实验结果显示，采用Precision-Recall框架优化损失函数，比仅仅结合负对数似然训练和温度调整取得了更优的Precision-Recall权衡。换句话说，新方法在提升多样性的同时更好地保持了文本生成的准确性。

Conclusion: 温度调节不是提升语言模型多样性的万能方法，只有训练时有针对性地提升覆盖度，才可以利用温度进行有效调节。Precision-Recall框架为语言模型的损失函数设计提供了更科学的思路，有助于实现更加多样而准确的生成。

Abstract: Increasing diversity in language models is a challenging yet essential
objective. A common approach is to raise the decoding temperature. In this
work, we investigate this approach through a simplistic yet common case to
provide insights into why decreasing temperature can improve quality
(Precision), while increasing it often fails to boost coverage (Recall). Our
analysis reveals that for a model to be effectively tunable through temperature
adjustments, it must be trained toward coverage. To address this, we propose
rethinking loss functions in language models by leveraging the Precision-Recall
framework. Our results demonstrate that this approach achieves a substantially
better trade-off between Precision and Recall than merely combining negative
log-likelihood training with temperature scaling. These findings offer a
pathway toward more versatile and robust language modeling techniques.

</details>


### [36] [EffiEval: Efficient and Generalizable Model Evaluation via Capability Coverage Maximization](https://arxiv.org/abs/2508.09662)
*Yaoning Wang,Jiahao Ying,Yixin Cao,Yubo Ma,Yugang Jiang*

Main category: cs.CL

TL;DR: EffiEval是一种利用少量代表性数据高效评估大语言模型的新工具，无需训练和大规模数据，同时确保评测公平性和广泛适用性，能显著减少评测计算开销且结果可靠。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）的快速发展和大规模评测基准的不断丰富导致了模型评估面临巨大的计算挑战。传统的评测方法往往依赖大量完整数据，消耗资源和时间，亟需更高效、可靠的新方法。

Method: 提出EffiEval，这是一种无需训练的新型高效评测方法。通过Model Utility Index（MUI）自适应选择具有代表性的数据子集，同时满足评测代表性、公平性和泛化能力这三大标准。EffiEval不依赖模型性能或大规模评测数据，能够灵活适用于不同数据集和模型。

Result: 在多个公开基准和多种LLM上的广泛实验表明，EffiEval用极小的数据子集即可获得与完整评测高度一致的排名结果。该方法具有很高的灵活性和可扩展性，可根据实际需求调整评测规模，实现高效与代表性的平衡。

Conclusion: EffiEval为LLM时代下可靠、公平、高效的模型评估提供了一种实用且具备广泛适应性的解决方案。

Abstract: The rapid advancement of large language models (LLMs) and the development of
increasingly large and diverse evaluation benchmarks have introduced
substantial computational challenges for model assessment. In this paper, we
present EffiEval, a training-free approach for efficient benchmarking that
effectively addresses data redundancy while maintaining high evaluation
reliability. Our method is specifically designed to meet three key criteria for
high-quality evaluation: representativeness, by ensuring comprehensive coverage
of model capabilities; fairness, by remaining independent of model performance
during sample selection to avoid bias; and generalizability, by enabling
flexible transfer across datasets and model families without reliance on
large-scale evaluation data. Unlike traditional methods that rely on absolute
performance or require extensive evaluation data, our approach adaptively
selects high-quality representative subsets based on the Model Utility Index
(MUI). Extensive experiments on multiple public benchmarks and diverse LLMs
demonstrate that EffiEval achieves strong ranking consistency with full-dataset
evaluation using only a small fraction of the original data. Furthermore, our
method is flexible and scalable in size, allowing users to balance evaluation
efficiency and representativeness according to specific needs. Overall,
EffiEval provides a practical and generalizable solution for reliable, fair,
and efficient evaluation in the era of LLMs.

</details>


### [37] [Slow Tuning and Low-Entropy Masking for Safe Chain-of-Thought Distillation](https://arxiv.org/abs/2508.09666)
*Ziyang Ma,Qingyue Yuan,Linhai Zhang,Deyu Zhou*

Main category: cs.CL

TL;DR: 本文揭示了CoT蒸馏对SLM安全性的隐患，提出SLowED方法（慢调优+低熵屏蔽）能在提升推理能力的同时维持模型安全。实验证实有效性，方法简单高效，适用于各类SLM安全蒸馏场景。


<details>
  <summary>Details</summary>
Motivation: 此前的CoT知识蒸馏方法旨在提升小型语言模型（SLM）推理能力，但忽视了蒸馏过程中对模型安全性的负面影响。已有的安全对齐方法则普遍成本高、依赖额外标注数据，并可能影响SLM推理能力。作者为解决蒸馏过程中的安全保持问题，提出新方案。

Method: 提出了一种安全蒸馏方法SLowED，包含两个关键模块：慢调优（Slow Tuning）和低熵屏蔽（Low-Entropy Masking）。慢调优通过减缓模型权重变化幅度，保证模型优化过程中权重分布不偏离初始邻域；低熵屏蔽则屏蔽被视为不必要学习目标的低熵token，防止它们参与微调。

Result: 在三个SLM（Qwen2.5-1.5B、Llama-3.2-1B、BLOOM-1.1B）上，通过推理基准和安全评估实验，SLowED在保证安全性的同时，推理能力与传统蒸馏方法持平。消融实验显示，慢调优主要在训练初期维持安全性，低熵屏蔽则可显著延长安全训练周期。

Conclusion: SLowED方法可在CoT蒸馏过程中同时提升SLM推理能力和保留安全性，为低成本安全蒸馏提供有效技术路径。

Abstract: Previous chain-of-thought (CoT) distillation methods primarily focused on
enhancing the reasoning capabilities of Small Language Models (SLMs) by
utilizing high-quality rationales generated by powerful Large Language Models
(LLMs, e.g., GPT-4). However, few works have noted the negative effects on SLM
safety brought by the training, which are revealed in this study. Although
there are works on safety alignment that fine-tune language models or
manipulate model weights to defend against harmful inputs, they require extra
computation or annotated data, and probably impact the reasoning ability of
SLMs. In this paper, we investigate how to maintain the safety of SLMs during
the CoT distillation process. Specifically, we propose a safe distillation
method, Slow Tuning and Low-Entropy Masking Distillation (SLowED), containing
two modules: Slow Tuning and Low-Entropy Masking. Slow Tuning scales down the
magnitude of model weight changes to optimize the model weights in the
neighboring space near the initial weight distribution. Low-Entropy Masking
masks low-entropy tokens, which are regarded as unnecessary learning targets,
to exclude them from fine-tuning. Experiments on three SLMs (Qwen2.5-1.5B,
Llama-3.2-1B, BLOOM-1.1B) across reasoning benchmarks (BBH, BB-Sub, ARC,
AGIEval) and safety evaluation (AdvBench) show that SLowED retains the safety
of SLMs and comparably improves their reasoning capability compared to existing
distillation methods. Furthermore, our ablation study presents the
effectiveness of Slow Tuning and Low-Entropy Masking, with the former
maintaining the model's safety in the early stage and the latter prolonging the
safe training epochs.

</details>


### [38] [Evaluating the Role of Large Language Models in Legal Practice in India](https://arxiv.org/abs/2508.09713)
*Rahul Hemrajani*

Main category: cs.CL

TL;DR: 本文通过印度法律场景下的实证对比研究，发现LLM在文书起草和问题识别方面表现突出，但在复杂法律研究任务上易出错，最终认为LLM能提升部分法律工作的效率，但难以完全替代人类律师的专业判断。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能（AI）在法律行业的逐步应用，大型语言模型（LLM）是否具备执行核心法律任务的能力，成为值得探讨的重要问题。本文旨在评估LLM在印度法律语境下完成关键法律任务的表现。

Method: 作者通过实验性调查，将GPT、Claude和Llama等LLM在法律问题识别、法律文书起草、法律咨询、法律研究与推理等任务中的输出，与一位初级律师的成果进行对比，由高级法学学生根据输出的有用性、准确性和全面性进行评分。

Result: LLM在法律文书起草和问题识别方面表现优异，部分情况下甚至能够赶超或超过人类。在专业性强的法律研究任务上，LLM则容易出现“幻觉”，即输出不准确或捏造的内容。

Conclusion: LLM可在部分法律任务中发挥辅助作用，但对于需要细致推理和法律精准应用的工作，人类专业能力仍不可或缺。

Abstract: The integration of Artificial Intelligence(AI) into the legal profession
raises significant questions about the capacity of Large Language Models(LLM)
to perform key legal tasks. In this paper, I empirically evaluate how well
LLMs, such as GPT, Claude, and Llama, perform key legal tasks in the Indian
context, including issue spotting, legal drafting, advice, research, and
reasoning. Through a survey experiment, I compare outputs from LLMs with those
of a junior lawyer, with advanced law students rating the work on helpfulness,
accuracy, and comprehensiveness. LLMs excel in drafting and issue spotting,
often matching or surpassing human work. However, they struggle with
specialised legal research, frequently generating hallucinations, factually
incorrect or fabricated outputs. I conclude that while LLMs can augment certain
legal tasks, human expertise remains essential for nuanced reasoning and the
precise application of law.

</details>


### [39] [The Perils of Chart Deception: How Misleading Visualizations Affect Vision-Language Models](https://arxiv.org/abs/2508.09716)
*Ridwan Mahbub,Mohammed Saidul Islam,Md Tahmid Rahman Laskar,Mizanur Rahman,Mir Tafseer Nayeem,Enamul Hoque*

Main category: cs.CL

TL;DR: 研究发现，多数视觉-语言模型在面对具有误导性设计的可视化图表时会产生错误理解，建议加强对抗视觉误信息的技术。


<details>
  <summary>Details</summary>
Motivation: 尽管信息可视化能够帮助用户识别数据模式和趋势，但一些具有误导性的设计元素可能让用户产生错误理解并传播错误信息。随着视觉-语言模型（VLMs）被广泛用于解读可视化，尤其是非专业用户，也需要了解这些模型对于误导性可视化的敏感性。

Method: 作者对十种不同的视觉-语言模型在八种误导性图表设计上的解读能力进行深入评估，通过分析超过16000个模型输出结果。

Result: 大多数视觉-语言模型会被具误导性的图表设计欺骗，对相同数据给出错误或偏差的解释。

Conclusion: 如果不加以防范，视觉-语言模型很容易被误导性设计误导，从而影响数据可视化下的解读，强调了在VLMs中建立防范视觉误信息机制的必要性。

Abstract: Information visualizations are powerful tools that help users quickly
identify patterns, trends, and outliers, facilitating informed decision-making.
However, when visualizations incorporate deceptive design elements-such as
truncated or inverted axes, unjustified 3D effects, or violations of best
practices-they can mislead viewers and distort understanding, spreading
misinformation. While some deceptive tactics are obvious, others subtly
manipulate perception while maintaining a facade of legitimacy. As
Vision-Language Models (VLMs) are increasingly used to interpret
visualizations, especially by non-expert users, it is critical to understand
how susceptible these models are to deceptive visual designs. In this study, we
conduct an in-depth evaluation of VLMs' ability to interpret misleading
visualizations. By analyzing over 16,000 responses from ten different models
across eight distinct types of misleading chart designs, we demonstrate that
most VLMs are deceived by them. This leads to altered interpretations of
charts, despite the underlying data remaining the same. Our findings highlight
the need for robust safeguards in VLMs against visual misinformation.

</details>


### [40] [Sample More to Think Less: Group Filtered Policy Optimization for Concise Reasoning](https://arxiv.org/abs/2508.09726)
*Vaishnavi Shrivastava,Ahmed Awadallah,Vidhisha Balachandran,Shivam Garg,Harkirat Behl,Dimitris Papailiopoulos*

Main category: cs.CL

TL;DR: GFPO通过优化训练样本筛选和持续采样，显著减少大模型响应长度膨胀，提升推理效率且准确率不受影响，在多项难题基准测试中效果优异。


<details>
  <summary>Details</summary>
Motivation: 解决自监督强化学习奖励驱动下，大语言模型为提高准确率而生成过长、冗余响应的问题，提升推理效率和计算资源利用率。

Method: 提出了GFPO（Group Filtered Policy Optimization）训练策略，在训练期间对每个问题进行大样本采样，通过响应长度和奖励/标记效率过滤训练样本。此外，提出了自适应难度分配机制，根据问题难度动态分配计算资源。

Result: 在Phi-4-reasoning大模型上，GFPO将响应长度膨胀问题减少了46-71%，当优化奖励/标记比后，进一步降至71-85%，在多个高难基准（如AIME 24/25、GPQA、Omni-MATH、LiveCodeBench）上保持准确率。自适应难度分配进一步提升了模型在难题上的效率和表现。

Conclusion: GFPO方法显著减少了大型语言模型由于奖励可验证性导致的长度膨胀问题，同时保持了推理准确率，优化了推理效率。

Abstract: Large language models trained with reinforcement learning with verifiable
rewards tend to trade accuracy for length--inflating response lengths to
achieve gains in accuracy. While longer answers may be warranted for harder
problems, many tokens are merely "filler": repetitive, verbose text that makes
no real progress. We introduce GFPO (Group Filtered Policy Optimization), which
curbs this length explosion by sampling larger groups per problem during
training and filtering responses to train on based on two key metrics: (1)
response length and (2) token efficiency: reward per token ratio. By sampling
more at training time, we teach models to think less at inference time. On the
Phi-4-reasoning model, GFPO cuts GRPO's length inflation by 46-71% across
challenging STEM and coding benchmarks (AIME 24/25, GPQA, Omni-MATH,
LiveCodeBench) while maintaining accuracy. Optimizing for reward per token
further increases reductions in length inflation to 71-85%. We also propose
Adaptive Difficulty GFPO, which dynamically allocates more training resources
to harder problems based on real-time difficulty estimates, improving the
balance between computational efficiency and accuracy especially on difficult
questions. GFPO demonstrates that increased training-time compute directly
translates to reduced test-time compute--a simple yet effective trade-off for
efficient reasoning.

</details>


### [41] [Transforming Questions and Documents for Semantically Aligned Retrieval-Augmented Generation](https://arxiv.org/abs/2508.09755)
*Seokgi Lee*

Main category: cs.CL

TL;DR: 本论文提出了一种适用于多跳问答的检索增强生成框架，通过LLM分解问题和生成可回答问题嵌入进行检索优化，在多个多跳问答数据集上显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 多跳问题由于问题本身的复杂性和多义性，常导致传统检索和生成方法性能受限，因此需要更有效的分解和检索方式提升系统表现。

Method: 使用大型语言模型（LLM）将复杂多跳问题分解为单跳子问题指导文档检索；从文档片段生成可回答问题并用问题-问题嵌入来检索相关片段，再与原始问题一起输入RAG管道进行推理。

Result: 在MuSiQue、2WikiMultiHopQa、HotpotQA三大数据集上进行实验，方法在性能上优于基线系统，验证了提出方法的有效性。

Conclusion: 本论文提出，在多跳问答中采用由LLM分解查询和可回答问题嵌入，能显著提升检索增强生成(RAG)系统的性能。

Abstract: We introduce a novel retrieval-augmented generation (RAG) framework tailored
for multihop question answering. First, our system uses large language model
(LLM) to decompose complex multihop questions into a sequence of single-hop
subquestions that guide document retrieval. This decomposition mitigates the
ambiguity inherent in multi-hop queries by clearly targeting distinct knowledge
facets. Second, instead of embedding raw or chunked documents directly, we
generate answerable questions from each document chunk using Qwen3-8B, embed
these generated questions, and retrieve relevant chunks via question-question
embedding similarity. During inference, the retrieved chunks are then fed along
with the original question into the RAG pipeline. We evaluate on three multihop
question datasets (MuSiQue, 2WikiMultiHopQa, HotpotQA) from LongBench. Our
method improves RAG performacne compared to baseline systems. Our contributions
highlight the benefits of using answerable-question embeddings for RAG, and the
effectiveness of LLM-based query decomposition for multihop scenarios.

</details>


### [42] [Echoes of Agreement: Argument Driven Opinion Shifts in Large Language Models](https://arxiv.org/abs/2508.09759)
*Avneet Kaur*

Main category: cs.CL

TL;DR: LLM在处理带有明显立场论据的提示词时，容易表现出迎合性，无论单轮还是多轮对话，模型会随论据方向调整自己的政治偏见判断。这表明现有偏见评估方法可能低估了模型的敏感性，也为后续偏见缓解带来挑战。


<details>
  <summary>Details</summary>
Motivation: 此前虽然对于大型语言模型（LLM）在政治话题上的偏见进行了大量评估，但未深入探讨模型输出对于带有倾向性论据的提示词的敏感性。进一步了解这类偏见评估的鲁棒性及模型行为非常重要，因为模型常与观点性文本交互。

Method: 进行实验，测试在提供支持或反驳（倾向性）论据情况下，LLM对政治偏见的响应，并分析单轮与多轮对话中的表现。

Result: 实验发现，模型响应会明显受提示词论据方向影响，倾向与提示词论据一致。且论据强度越大，模型响应与论据方向的一致率越高。

Conclusion: LLM呈现“迎合性”倾向，会随着论据方向调整自身立场，这对未来政治偏见测量和缓解策略设计产生重要影响。

Abstract: There have been numerous studies evaluating bias of LLMs towards political
topics. However, how positions towards these topics in model outputs are highly
sensitive to the prompt. What happens when the prompt itself is suggestive of
certain arguments towards those positions remains underexplored. This is
crucial for understanding how robust these bias evaluations are and for
understanding model behaviour, as these models frequently interact with
opinionated text. To that end, we conduct experiments for political bias
evaluation in presence of supporting and refuting arguments. Our experiments
show that such arguments substantially alter model responses towards the
direction of the provided argument in both single-turn and multi-turn settings.
Moreover, we find that the strength of these arguments influences the
directional agreement rate of model responses. These effects point to a
sycophantic tendency in LLMs adapting their stance to align with the presented
arguments which has downstream implications for measuring political bias and
developing effective mitigation strategies.

</details>


### [43] [UtterTune: LoRA-Based Target-Language Pronunciation Edit and Control in Multilingual Text-to-Speech](https://arxiv.org/abs/2508.09767)
*Shuhei Kato*

Main category: cs.CL

TL;DR: UtterTune是一种面向多语种TTS的轻量适配方法，可细致控制目标语言（如日语）的发音和语调，同时不影响其它语言的表现，经多项评测证实其实用性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型架构提升了TTS的自然度，但由于缺乏显式的字母到音素（G2P）模块，直接对最简编码文本进行处理时难以精准建模G2P映射和语调，尤其影响特定语言的发音可控性。亟需方法提升目标语言可控性同时兼顾多语言性能。

Method: 采用基于大语言模型架构的多语种TTS系统，通过低秩适配（low-rank adaptation）方法调整模型参数，实现对发音和语调的细致控制，尤其针对日语语音的音素级别发音和音高重音。

Result: UtterTune 实现了对日语语音发音和音高的精细控制，提升了目标语言发音可控性，在多语言场景下不损失其他语言的自然度和说话人一致性，经客观和主观实验验证有效。

Conclusion: UtterTune 能够有选择性地提升目标语言（如日语）的发音可控性，同时在其他语言保持表现，在零样本设定下仍能维持语音的自然性和说话人相似度。客观和主观评测均证实了其有效性。

Abstract: We propose UtterTune, a lightweight adaptation method that fine-tunes a
multilingual text-to-speech (TTS) system based on a large language model (LLM)
architecture, designed to enhance the controllability of pronunciation in a
target language while preserving performance in others. While LLM architectures
have enabled TTS models to achieve remarkable naturalness, accurately modeling
grapheme-to-phoneme (G2P) mapping and prosody remains challenging, especially
when the model omits an explicit G2P module and directly processes minimally
encoded text (e.g., byte-pair encoding). UtterTune leverages low-rank
adaptation to enable the control of segmental pronunciation and pitch accent at
the phoneme level for Japanese speech, the target language in this paper, while
maintaining naturalness and speaker similarity in a zero-shot setting.
Objective and subjective evaluations confirm its effectiveness.

</details>


### [44] [Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study](https://arxiv.org/abs/2508.09776)
*Mahdi Dhaini,Juraj Vladika,Ege Erdogan,Zineb Attaoui,Gjergji Kasneci*

Main category: cs.CL

TL;DR: 提出利用大语言模型自动生成NLP模型的文本解释，证明其高效且可替代人工标注，能够有效提升下游任务模型表现，为数据扩充和模型优化提供新途径。


<details>
  <summary>Details</summary>
Motivation: 在可解释自然语言处理（NLP）领域，模型预测的文本解释（类似人类的推理）非常重要，但人工标注成本高，难以扩展，因此需要一个高效、可扩展的自动化文本解释方法。

Method: 提出一个自动化框架，利用多个主流大语言模型（LLM）来生成高质量的文本解释，并用多种自然语言生成（NLG）指标严格评估解释质量。进一步探索这些自动生成的解释对不同NLP任务中预训练语言模型和LLM性能的影响。实验涵盖两个多样化的基准数据集。

Result: 自动化生成的文本解释在提升模型性能方面与人工标注解释表现出高度竞争力。

Conclusion: 通过LLM自动生成解释是一种可扩展且有效的方法，可以丰富NLP数据集并提升模型性能。

Abstract: In the rapidly evolving field of Explainable Natural Language Processing
(NLP), textual explanations, i.e., human-like rationales, are pivotal for
explaining model predictions and enriching datasets with interpretable labels.
Traditional approaches rely on human annotation, which is costly,
labor-intensive, and impedes scalability. In this work, we present an automated
framework that leverages multiple state-of-the-art large language models (LLMs)
to generate high-quality textual explanations. We rigorously assess the quality
of these LLM-generated explanations using a comprehensive suite of Natural
Language Generation (NLG) metrics. Furthermore, we investigate the downstream
impact of these explanations on the performance of pre-trained language models
(PLMs) and LLMs across natural language inference tasks on two diverse
benchmark datasets. Our experiments demonstrate that automated explanations
exhibit highly competitive effectiveness compared to human-annotated
explanations in improving model performance. Our findings underscore a
promising avenue for scalable, automated LLM-based textual explanation
generation for extending NLP datasets and enhancing model performance.

</details>


### [45] [Adoption of Explainable Natural Language Processing: Perspectives from Industry and Academia on Practices and Challenges](https://arxiv.org/abs/2508.09786)
*Mahdi Dhaini,Tobias Müller,Roksoliana Rabets,Gjergji Kasneci*

Main category: cs.CL

TL;DR: 可解释自然语言处理领域发展迅速，但实际应用中从业者对现有方法满意度低，存在评估挑战。论文通过访谈揭示了概念和认知的差距，呼吁建立更完善的用户导向框架。


<details>
  <summary>Details</summary>
Motivation: 目前复杂自然语言处理模型的不可解释性越来越高，尤其在关键应用领域需要更高的透明度和解释性，但实际从业者对可解释性方法的采用和有效性认知不足。该论文旨在填补这一研究空白。

Method: 论文采用定性访谈研究方法，通过对业界从业者以及学术研究者的系统访谈，分析他们对于可解释性方法的动机、实际使用技术、满意度以及面临的挑战。

Result: 研究结果揭示了业界和学术界在可解释NLP上的概念差距，从业者对目前可解释性方法的满意度较低，并且存在评估上的难点。

Conclusion: 论文强调需要构建更清晰的定义和以用户为中心的框架，以推动可解释NLP在实际场景中的应用。

Abstract: The field of explainable natural language processing (NLP) has grown rapidly
in recent years. The growing opacity of complex models calls for transparency
and explanations of their decisions, which is crucial to understand their
reasoning and facilitate deployment, especially in high-stakes environments.
Despite increasing attention given to explainable NLP, practitioners'
perspectives regarding its practical adoption and effectiveness remain
underexplored. This paper addresses this research gap by investigating
practitioners' experiences with explainability methods, specifically focusing
on their motivations for adopting such methods, the techniques employed,
satisfaction levels, and the practical challenges encountered in real-world NLP
applications. Through a qualitative interview-based study with industry
practitioners and complementary interviews with academic researchers, we
systematically analyze and compare their perspectives. Our findings reveal
conceptual gaps, low satisfaction with current explainability methods, and
highlight evaluation challenges. Our findings emphasize the need for clear
definitions and user-centric frameworks for better adoption of explainable NLP
in practice.

</details>


### [46] [BigCharts-R1: Enhanced Chart Reasoning with Visual Reinforcement Finetuning](https://arxiv.org/abs/2508.09804)
*Ahmed Masry,Abhay Puri,Masoud Hashemi,Juan A. Rodriguez,Megh Thakkar,Khyati Mahajan,Vikas Yadav,Sathwik Tejaswi Madhusudhan,Alexandre Piché,Dzmitry Bahdanau,Christopher Pal,David Vazquez,Enamul Hoque,Perouz Taslakian,Sai Rajeswar,Spandana Gella*

Main category: cs.CL

TL;DR: 本文针对视觉-语言模型在图表理解上的不足，提出了包含真实数据和多样视觉风格的BigCharts数据集与结合强化学习的训练框架，显著提升了图表问答任务的准确率，所提出的BigCharts-R1模型在多个基准上均超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLMs）在图表理解方面表现不佳，主要原因在于训练数据集缺乏多样性与真实性，以及模型主要依赖低质量数据集进行有监督微调，导致性能受限。

Method: 作者提出了BigCharts，一个新的数据集构建流程，通过基于真实世界多平台收集的图表对渲染过程进行条件控制，生成具有视觉多样性和真实性的图表，并采用重新绘制（replotting）方式确保数据准确。同时，作者提出了综合性的训练框架，将有监督微调与基于Group Relative Policy Optimization (GRPO)的强化学习结合，并引入专门针对图表推理的新奖励信号。

Result: 作者提出的BigCharts-R1模型在多个图表问答基准测试中表现超越了现有主流甚至更大型的开源及闭源模型，显示出更强的稳健性和泛化能力。

Conclusion: BigCharts数据集和训练框架能有效提升图表推理相关模型的性能与泛化能力，为视觉-语言模型的图表理解提供了新的解决方案。

Abstract: Charts are essential to data analysis, transforming raw data into clear
visual representations that support human decision-making. Although current
vision-language models (VLMs) have made significant progress, they continue to
struggle with chart comprehension due to training on datasets that lack
diversity and real-world authenticity, or on automatically extracted underlying
data tables of charts, which can contain numerous estimation errors.
Furthermore, existing models only rely on supervised fine-tuning using these
low-quality datasets, severely limiting their effectiveness. To address these
issues, we first propose BigCharts, a dataset creation pipeline that generates
visually diverse chart images by conditioning the rendering process on
real-world charts sourced from multiple online platforms. Unlike purely
synthetic datasets, BigCharts incorporates real-world data, ensuring
authenticity and visual diversity, while still retaining accurate underlying
data due to our proposed replotting process. Additionally, we introduce a
comprehensive training framework that integrates supervised fine-tuning with
Group Relative Policy Optimization (GRPO)-based reinforcement learning. By
introducing novel reward signals specifically designed for chart reasoning, our
approach enhances model robustness and generalization across diverse chart
styles and domains, resulting in a state-of-the-art chart reasoning model,
BigCharts-R1. Extensive experiments demonstrate that our models surpass
existing methods on multiple chart question-answering benchmarks compared to
even larger open-source and closed-source models.

</details>


### [47] [A Comprehensive Survey of Datasets for Clinical Mental Health AI Systems](https://arxiv.org/abs/2508.09809)
*Aishik Mandal,Prottay Kumar Adhikary,Hiba Arnaout,Iryna Gurevych,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文系统梳理了临床心理健康AI训练用的数据集，指出数据纵深、文化覆盖和标准化等不足，并给出推动AI系统更健壮发展的建议。


<details>
  <summary>Details</summary>
Motivation: 全球心理健康障碍人数上升，但专业临床医师数量未能同步增长，导致许多人无法获得足够或及时的支持。人工智能有望协助心理健康的诊断与干预，但高质量临床训练数据集的缺乏严重阻碍了AI系统的发展。

Method: 本文首次对用于训练和开发AI临床助手的临床心理健康数据集进行了全面梳理和调查。按心理障碍类别、数据模态、任务类型、可获取性及社会文化背景等维度归类，并涉及合成数据集，识别数据层面的关键问题。

Result: 调查揭示存在数据纵向性不足、文化与语言覆盖有限、采集与标注标准不一致，合成数据模态缺失等关键漏洞。

Conclusion: 通过综述现有数据集和关键挑战，提出未来数据集设计及标准化的建议，以促进更强健、可推广和公平的心理健康AI系统发展。

Abstract: Mental health disorders are rising worldwide. However, the availability of
trained clinicians has not scaled proportionally, leaving many people without
adequate or timely support. To bridge this gap, recent studies have shown the
promise of Artificial Intelligence (AI) to assist mental health diagnosis,
monitoring, and intervention. However, the development of efficient, reliable,
and ethical AI to assist clinicians is heavily dependent on high-quality
clinical training datasets. Despite growing interest in data curation for
training clinical AI assistants, existing datasets largely remain scattered,
under-documented, and often inaccessible, hindering the reproducibility,
comparability, and generalizability of AI models developed for clinical mental
health care. In this paper, we present the first comprehensive survey of
clinical mental health datasets relevant to the training and development of
AI-powered clinical assistants. We categorize these datasets by mental
disorders (e.g., depression, schizophrenia), data modalities (e.g., text,
speech, physiological signals), task types (e.g., diagnosis prediction, symptom
severity estimation, intervention generation), accessibility (public,
restricted or private), and sociocultural context (e.g., language and cultural
background). Along with these, we also investigate synthetic clinical mental
health datasets. Our survey identifies critical gaps such as a lack of
longitudinal data, limited cultural and linguistic representation, inconsistent
collection and annotation standards, and a lack of modalities in synthetic
data. We conclude by outlining key challenges in curating and standardizing
future datasets and provide actionable recommendations to facilitate the
development of more robust, generalizable, and equitable mental health AI
systems.

</details>


### [48] [Speed Always Wins: A Survey on Efficient Architectures for Large Language Models](https://arxiv.org/abs/2508.09834)
*Weigao Sun,Jiaxi Hu,Yucheng Zhou,Jusen Du,Disen Lan,Kexin Wang,Tong Zhu,Xiaoye Qu,Yu Zhang,Xiaoyu Mo,Daizong Liu,Yuxuan Liang,Wenliang Chen,Guoqi Li,Yu Cheng*

Main category: cs.CL

TL;DR: 本文综述了为解决Transformer计算瓶颈而发展的高效LLM架构，详细介绍了各类新方法及其在多模态等领域的潜力，为未来高效AI系统研究提供参考。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLMs）虽在多项任务上表现出色，但底层的Transformer架构计算开销大，影响大规模训练与实际部署。迫切需要更高效的新型架构提升实用性。

Method: 本文为综述性论文，系统梳理LLM架构的创新改进，涵盖线性与稀疏序列模型、高效全注意力变体、稀疏专家混合架构、混合型模型以及新兴扩散模型，并探讨这些技术在多模态任务中的应用。

Result: 该论文将近年高效LLM架构研究分门别类，详细介绍每类方法的原理与应用现状，剖析其在构建可扩展、高效基础模型中的作用和潜力。

Conclusion: 通过系统梳理当前高效LLM架构发展图谱，本文为后续研究高效、通用AI系统提供了理论基础与思路指引。

Abstract: Large Language Models (LLMs) have delivered impressive results in language
understanding, generation, reasoning, and pushes the ability boundary of
multimodal models. Transformer models, as the foundation of modern LLMs, offer
a strong baseline with excellent scaling properties. However, the traditional
transformer architecture requires substantial computations and poses
significant obstacles for large-scale training and practical deployment. In
this survey, we offer a systematic examination of innovative LLM architectures
that address the inherent limitations of transformers and boost the efficiency.
Starting from language modeling, this survey covers the background and
technical details of linear and sparse sequence modeling methods, efficient
full attention variants, sparse mixture-of-experts, hybrid model architectures
incorporating the above techniques, and emerging diffusion LLMs. Additionally,
we discuss applications of these techniques to other modalities and consider
their wider implications for developing scalable, resource-aware foundation
models. By grouping recent studies into the above category, this survey
presents a blueprint of modern efficient LLM architectures, and we hope this
could help motivate future research toward more efficient, versatile AI
systems.

</details>


### [49] [PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts](https://arxiv.org/abs/2508.09848)
*Mo Yu,Tsz Ting Chung,Chulun Zhou,Tong Li,Rui Lu,Jiangnan Li,Liyan Xu,Haoshu Lu,Ning Zhang,Jing Li,Jie Zhou*

Main category: cs.CL

TL;DR: 作者提出PRELUDE基准，用于测试长篇文本理解和推理，发现主流模型远逊于人类，尤其是在推理能力上，长上下文理解仍具有很大进步空间。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏能有效评价模型长上下文理解与深度推理能力的基准任务。为推动该领域发展，需要设计更具挑战性的基准，对模型提出更高要求。

Method: 提出PRELUDE基准，通过判断一个角色的前传故事与原著正典叙事是否一致的方法，来评估模型的长上下文理解能力。对比了模型在上下文学习、RAG、领域内训练等多种方式下，与人类的差距。同时进行了人类研究以分析模型推理能力。

Result: 实验发现，即使是最先进的模型和深度研究服务，其准确率仍比人类低15%以上。同时，模型在推理过程中的正确性与人类相比差距更大，表现为推理准确率落后30%以上。大部分任务需要整合多段信息才能做出判断。

Conclusion: 研究表明，当前主流的大型语言模型（LLM）和深度研究服务在长上下文理解与推理任务中的表现明显落后于人类，推理准确率也存在较大差距，显示这一领域仍有很大提升空间。

Abstract: We introduce PRELUDE, a benchmark for evaluating long-context understanding
through the task of determining whether a character's prequel story is
consistent with the canonical narrative of the original book. Our task poses a
stronger demand for global comprehension and deep reasoning than existing
benchmarks -- as the prequels are not part of the original story, assessing
their plausibility typically requires searching and integrating information
that is only indirectly related. Empirically, 88% of instances require evidence
from multiple parts of the narrative. Experimental results highlight the
challenge of our task: in-context learning, RAG and in-domain training with
state-of-the-art LLMs, and commercial DeepResearch services, lag behind humans
by >15%. A further human study reveals that models often produce correct
answers with flawed reasoning, leading to an over 30% gap in reasoning accuracy
compared to humans. These findings underscore the substantial room for
improvement in long-context understanding and reasoning.

</details>


### [50] [Assessing the Feasibility of Lightweight Whisper Models for Low-Resource Urdu Transcription](https://arxiv.org/abs/2508.09865)
*Abdul Rehman Antall,Naveed Akhtar*

Main category: cs.CL

TL;DR: Whisper-Small模型在无微调情况下对乌尔都语识别有较好表现，但整体依然面临准确率及复杂语句处理等挑战，为低资源语种ASR研究提供参考。


<details>
  <summary>Details</summary>
Motivation: 尽管乌尔都语是全球第十多使用的语言（2.3亿使用者），但因方言多样、代码混合和训练数据稀缺，自动语音识别（ASR）系统对乌尔都语的支持仍有限。

Method: 在未进行微调的情况下，使用Whisper家族中的三种轻量级模型（Tiny、Base、Small）在整理的乌尔都语数据集上进行基准测试，采用词错误率（WER）作为评估指标; 并结合定性分析，深入探讨识别中出现的问题。

Result: Whisper-Small模型表现最佳，WER为33.68%，优于Base（53.67%）和Tiny（67.08%）。然而，模型在语音和词汇一致性上仍有明显不足，尤其是在复杂语句上。

Conclusion: Whisper-Small模型为低资源环境下的乌尔都语ASR提供了有前景的方案，但当前模型仍存在显著改进空间，后续研究有望进一步提升系统表现。

Abstract: This study evaluates the feasibility of lightweight Whisper models (Tiny,
Base, Small) for Urdu speech recognition in low-resource settings. Despite Urdu
being the 10th most spoken language globally with over 230 million speakers,
its representation in automatic speech recognition (ASR) systems remains
limited due to dialectal diversity, code-switching, and sparse training data.
We benchmark these models on a curated Urdu dataset using word error rate
(WER), without fine-tuning. Results show Whisper-Small achieves the lowest
error rates (33.68\% WER), outperforming Tiny (67.08\% WER) and Base (53.67\%
WER). Qualitative analysis reveals persistent challenges in phonetic accuracy
and lexical coherence, particularly for complex utterances. While Whisper-Small
demonstrates promise for deployable Urdu ASR, significant gaps remain. Our
findings emphasize lay the groundwork for future research into effective,
low-resource ASR systems.

</details>


### [51] [Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models](https://arxiv.org/abs/2508.09874)
*Jiaqi Cao,Jiarui Wang,Rubin Wei,Qipeng Guo,Kai Chen,Bowen Zhou,Zhouhan Lin*

Main category: cs.CL

TL;DR: 本文提出Memory Decoder，通过可插拔的预训练记忆模块实现高效、无参数修改的领域适应方式，显著提升大模型在特定领域任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在通用任务上表现优异，将其高效适应到特定领域依然面临挑战。当前的主流方法如DAPT需要大量计算资源且存在遗忘问题，RAG则推高了推理延迟。

Method: 提出Memory Decoder——一种预训练记忆模块。该模块通过一个小型transformer decoder模拟非参数检索器行为，与原始模型无缝集成且无需修改其参数，只要tokenizer兼容即可。

Result: Memory Decoder被应用在多种Qwen和Llama模型，并在生物医学、金融和法律三大专门领域上测试，有效显著提升了模型适应性，平均困惑度降低6.17分。

Conclusion: Memory Decoder为领域适应提出了新的范式，通过可插拔的预训练记忆架构，极大简化了领域适应过程，并能在多个主流模型和领域上均带来一致性性能提升。

Abstract: Large Language Models (LLMs) have shown strong abilities in general language
tasks, yet adapting them to specific domains remains a challenge. Current
method like Domain Adaptive Pretraining (DAPT) requires costly full-parameter
training and suffers from catastrophic forgetting. Meanwhile,
Retrieval-Augmented Generation (RAG) introduces substantial inference latency
due to expensive nearest-neighbor searches and longer context. This paper
introduces Memory Decoder, a plug-and-play pretrained memory that enables
efficient domain adaptation without changing the original model's parameters.
Memory Decoder employs a small transformer decoder that learns to imitate the
behavior of an external non-parametric retriever. Once trained, Memory Decoder
can be seamlessly integrated with any pretrained language model that shares the
same tokenizer, requiring no model-specific modifications. Experimental results
demonstrate that Memory Decoder enables effective adaptation of various Qwen
and Llama models to three distinct specialized domains: biomedicine, finance,
and law, reducing perplexity by an average of 6.17 points. Overall, Memory
Decoder introduces a novel paradigm centered on a specially pretrained memory
component designed for domain-specific adaptation. This memory architecture can
be integrated in a plug-and-play manner, consistently enhancing performance
across multiple models within the target domain.

</details>


### [52] [A Survey of Cognitive Distortion Detection and Classification in NLP](https://arxiv.org/abs/2508.09878)
*Archie Sage,Jeroen Keppens,Helen Yannakoudakis*

Main category: cs.CL

TL;DR: 随着NLP在心理健康领域应用日益广泛，认知偏差自动检测成为热点，但现有研究零散不统一。本文系统综述了过去20年的相关工作，提炼分类体系、任务设定和评估方法，指出研究挑战，推动领域规范化发展。


<details>
  <summary>Details</summary>
Motivation: 近年来，越来越多研究关注将自然语言处理（NLP）技术应用于心理健康领域，特别是自动检测和分类认知偏差（CDs）。认知偏差会影响人们对事件、对自我的判断和对外界的反应，是心理治疗中亟需识别和处理的重要部分，但目前相关研究在分类体系、任务设定和评估实践上还很分散和不统一。

Method: 本论文对过去二十年内的38项相关研究进行了系统性综述，结构化地归纳了这些研究使用的数据集、建模方法和评估策略，并整理融合了认知偏差的分类体系。

Result: 论文总结了认知偏差常用的任务设定，给出统一的CD分类体系参考，厘清领域内的开放难题，为后续更系统、可复现性更强的研究奠定基础。

Conclusion: 通过综述和整合现有文献、提出合并后的标准化分类体系和梳理挑战，本文为认知偏差NLP自动检测研究提供了基础资源和方向建议，有助于领域研究更标准化、协作和深入。

Abstract: As interest grows in the application of natural language processing (NLP)
techniques to mental health, a growing body of work explores the automatic
detection and classification of cognitive distortions (CDs). CDs are habitual
patterns of negatively biased or flawed thinking that distort how people
perceive events, judge themselves, and react to the world around them.
Identifying and addressing them is an important part of therapy. Despite its
momentum, the field remains fragmented, with inconsistencies in CD taxonomies,
task formulations, and evaluation practices. This survey reviews 38 studies
spanning two decades, providing a structured overview of datasets, modelling
approaches, and evaluation strategies. We provide a consolidated CD taxonomy
reference, summarise common task setups, and highlight open challenges to
support more coherent and reproducible research in this emerging area.

</details>


### [53] [Language of Persuasion and Misrepresentation in Business Communication: A Textual Detection Approach](https://arxiv.org/abs/2508.09935)
*Sayem Hossen,Monalisa Moon Joti,Md. Golam Rashed*

Main category: cs.CL

TL;DR: 本研究融合多学科理论，提出用说服性词汇检测欺骗性语言，受控环境下识别准确率极高，但多语言场景面临数据与工具瓶颈，呼吁推动强自动识别系统以应对AI交流挑战。


<details>
  <summary>Details</summary>
Motivation: 随着商业沟通数字化发展，传统的说服性话语结构发生了改变，虽然提升了透明度，但也让高级欺骗变得容易。这需要理解和检测使用说服性词汇进行欺骗的语言手法。

Method: 将古典修辞、传播心理学与语言学理论相结合，利用金融报告、可持续发展话语和数字营销等领域的实证研究，采用计算文本分析和个性化Transformer模型检测欺骗性语言。

Result: 在受控环境下，使用计算文本分析及定制化Transformer模型，欺骗性语言检测准确率超过99%。但该方法在多语言环境下效果受限，主要因数据不足及多语言文本处理基础设施匮乏。

Conclusion: 理论与实际之间出现了越来越大的沟通表示鸿沟，随着AI话语的真实性提升，亟需强大自动文本识别系统以保障人与AI沟通的真实性。

Abstract: Business communication digitisation has reorganised the process of persuasive
discourse, which
  allows not only greater transparency but also advanced deception. This
inquiry synthesises classical
  rhetoric and communication psychology with linguistic theory and empirical
studies in the financial
  reporting, sustainability discourse, and digital marketing to explain how
deceptive language can be
  systematically detected using persuasive lexicon. In controlled settings,
detection accuracies of greater
  than 99% were achieved by using computational textual analysis as well as
personalised transformer
  models. However, reproducing this performance in multilingual settings is
also problematic and,
  to a large extent, this is because it is not easy to find sufficient data,
and because few multilingual
  text-processing infrastructures are in place. This evidence shows that there
has been an increasing
  gap between the theoretical representations of communication and those
empirically approximated,
  and therefore, there is a need to have strong automatic text-identification
systems where AI-based
  discourse is becoming more realistic in communicating with humans.

</details>


### [54] [A Comprehensive Evaluation framework of Alignment Techniques for LLMs](https://arxiv.org/abs/2508.09937)
*Muneeza Azmat,Momin Abbas,Maysa Malfiza Garcia de Macedo,Marcelo Carpinette Grave,Luan Soares de Souza,Tiago Machado,Rogerio A de Paula,Raya Horesh,Yixin Chen,Heloisa Caroline de Souza Pereira Candello,Rebecka Nordenlow,Aminat Adebiyi*

Main category: cs.CL

TL;DR: 本文针对大语言模型的对齐问题，提出了系统性多维度评估框架，横向比较主流对齐方法，实验表明该方法可深入揭示各方法优劣，有助于安全可靠地部署LLMs。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）在实际应用中越来越普及，其输出需符合人类价值观和安全标准变得至关重要。然而，现有各种对齐方法（如RLHF、指令微调、后处理修正、推理时干预等）虽各有优劣，但缺乏统一的评估框架，导致难以系统性比较和部署决策。

Method: 提出了多维度评估框架，从对齐检测、对齐质量、计算效率、鲁棒性四个关键维度出发，对主流LLM对齐方法进行系统比较，通过多种基础模型和对齐策略进行实验验证。

Result: 通过实验展示该框架可有效识别当前主流模型在各对齐方法的优缺点，为相关模型部署和未来研究方向提供有价值的参考。

Conclusion: 多维度统一评估框架使LLM对齐方法能够被系统、全面地比较和评估，有助于选型和推动研究进展。

Abstract: As Large Language Models (LLMs) become increasingly integrated into
real-world applications, ensuring their outputs align with human values and
safety standards has become critical. The field has developed diverse alignment
approaches including traditional fine-tuning methods (RLHF, instruction
tuning), post-hoc correction systems, and inference-time interventions, each
with distinct advantages and limitations. However, the lack of unified
evaluation frameworks makes it difficult to systematically compare these
paradigms and guide deployment decisions. This paper introduces a
multi-dimensional evaluation of alignment techniques for LLMs, a comprehensive
evaluation framework that provides a systematic comparison across all major
alignment paradigms. Our framework assesses methods along four key dimensions:
alignment detection, alignment quality, computational efficiency, and
robustness. Through experiments across diverse base models and alignment
strategies, we demonstrate the utility of our framework in identifying
strengths and limitations of current state-of-the-art models, providing
valuable insights for future research directions.

</details>


### [55] [VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models](https://arxiv.org/abs/2508.09945)
*Lingjie Jiang,Shaohan Huang,Xun Wu,Yixia Li,Dongdong Zhang,Furu Wei*

Main category: cs.CL

TL;DR: 本文提出VisCodex，将视觉、语言和代码生成能力高效融合，利用新数据集和评测基准，显著提升多模态代码生成表现，达到甚至逼近GPT-4o水平。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在视觉和文本理解融合方面取得了重要进展，但其基于多模态输入的代码生成能力依然有限。本文旨在解决MLLM在多模态代码生成方面的不足。

Method: 提出VisCodex，一种统一框架，通过基于任务向量的模型合并方法，将先进的代码生成LLM与强大的视觉-语言主干网络结合，既保留视觉理解能力，也具备高级代码生成能力。同时，构建了大规模多模态编码数据集（MCD），并提出了新的测试基准InfiBench-V。

Result: VisCodex在开源MLLMs中实现了最优性能，并接近GPT-4o等闭源模型的水平。实验证明模型融合策略和新数据集有效提升了多模态代码生成能力。

Conclusion: VisCodex有力推动了多模态大模型在代码生成领域的发展，通过创新模型结构、丰富数据集及针对性的评测基准，为视觉与代码深度融合提供了新的解决方案。

Abstract: Multimodal large language models (MLLMs) have significantly advanced the
integration of visual and textual understanding. However, their ability to
generate code from multimodal inputs remains limited. In this work, we
introduce VisCodex, a unified framework that seamlessly merges vision and
coding language models to empower MLLMs with strong multimodal code generation
abilities. Leveraging a task vector-based model merging technique, we integrate
a state-of-the-art coding LLM into a strong vision-language backbone, while
preserving both visual comprehension and advanced coding skills. To support
training and evaluation, we introduce the Multimodal Coding Dataset (MCD), a
large-scale and diverse collection of 598k samples, including high-quality HTML
code, chart image-code pairs, image-augmented StackOverflow QA, and algorithmic
problems. Furthermore, we propose InfiBench-V, a novel and challenging
benchmark specifically designed to assess models on visually-rich, real-world
programming questions that demand a nuanced understanding of both textual and
visual contexts. Extensive experiments show that VisCodex achieves
state-of-the-art performance among open-source MLLMs and approaches proprietary
models like GPT-4o, highlighting the effectiveness of our model merging
strategy and new datasets.

</details>


### [56] [Specialised or Generic? Tokenization Choices for Radiology Language Models](https://arxiv.org/abs/2508.09952)
*Hermione Warr,Wentian Xu,Harry Anthony,Yasin Ibrahim,Daniel McGowan,Konstantinos Kamnitsas*

Main category: cs.CL

TL;DR: 医学和领域专用分词器在放射学报告生成中比通用分词器效果更好，尤其在模型从零训练时表现突出，且有助于降低计算资源消耗，预训练可减缓分词器差异但领域词表依旧最优，建议临床医学领域优先使用专业化分词器。


<details>
  <summary>Details</summary>
Motivation: 目前语言模型中使用的词汇表（tokenizer）已经被证明对文本生成质量有重要影响，但在医学影像领域（如放射学）中的具体作用尚未被充分研究。本文旨在填补这一空白，探讨不同类型的分词器对医学影像报告生成任务的影响。

Method: 系统比较了通用、医学和领域专用三类分词器在三种影像模式的放射学报告摘要生成任务中的表现，并考察了模型是否在PubMed摘要上进行预训练对结果的影响。

Result: （1）医学和领域专用词表在从头训练模型时表现明显优于普通自然语言词表；（2）经过医学文献预训练可以部分减小不同分词器之间的性能差异，但领域专用词表依然效果最佳；（3）领域专用分词器还显著降低了模型的显存占用和序列长度。

Conclusion: 将语言模型的词汇表适应于临床医学领域，不仅提升了生成性能，还降低了计算资源消耗，使得医学领域的文本生成模型更具实用性和可推广性。

Abstract: The vocabulary used by language models (LM) - defined by the tokenizer -
plays a key role in text generation quality. However, its impact remains
under-explored in radiology. In this work, we address this gap by
systematically comparing general, medical, and domain-specific tokenizers on
the task of radiology report summarisation across three imaging modalities. We
also investigate scenarios with and without LM pre-training on PubMed
abstracts. Our findings demonstrate that medical and domain-specific
vocabularies outperformed widely used natural language alternatives when models
are trained from scratch. Pre-training partially mitigates performance
differences between tokenizers, whilst the domain-specific tokenizers achieve
the most favourable results. Domain-specific tokenizers also reduce memory
requirements due to smaller vocabularies and shorter sequences. These results
demonstrate that adapting the vocabulary of LMs to the clinical domain provides
practical benefits, including improved performance and reduced computational
demands, making such models more accessible and effective for both research and
real-world healthcare settings.

</details>


### [57] [Shaping Event Backstories to Estimate Potential Emotion Contexts](https://arxiv.org/abs/2508.09954)
*Johannes Schäfer,Roman Klinger*

Main category: cs.CL

TL;DR: 本文提出用自动生成的情境故事为事件补充上下文，以增强情感分析标注的可靠性。结果表明，这种方法能显著提升标注一致性，有助于更准确地理解情绪。


<details>
  <summary>Details</summary>
Motivation: 情感分析任务本质存在歧义，先前的研究主要关注标注者自身的特征，却忽略了歧义可能来源于事件背景信息不足。该论文希望探索通过补充合理上下文是否能减少歧义。

Method: 自动生成多条基于不同情绪条件的事件链，为目标事件描述补充不同的上下文环境。通过整合短篇故事生成等技术，得到连贯的叙事文本，并构建了一个专门用于系统性研究带上下文情绪分析的数据集。采用自动和人工评估方法进行对比分析。

Result: 实验显示，补充上下文的叙事显著提升了对特定情绪的理解能力，使得人工标注者在情感判断上更为一致。

Conclusion: 为情感分析任务补充合理上下文能帮助减少歧义并提高标注一致性，为今后情感分析数据标注和模型训练提供了新思路。

Abstract: Emotion analysis is an inherently ambiguous task. Previous work studied
annotator properties to explain disagreement, but this overlooks the
possibility that ambiguity may stem from missing information about the context
of events. In this paper, we propose a novel approach that adds reasonable
contexts to event descriptions, which may better explain a particular
situation. Our goal is to understand whether these enriched contexts enable
human annotators to annotate emotions more reliably. We disambiguate a target
event description by automatically generating multiple event chains conditioned
on differing emotions. By combining techniques from short story generation in
various settings, we achieve coherent narratives that result in a specialized
dataset for the first comprehensive and systematic examination of
contextualized emotion analysis. Through automatic and human evaluation, we
find that contextual narratives enhance the interpretation of specific emotions
and support annotators in producing more consistent annotations.

</details>


### [58] [Performance of GPT-5 Frontier Models in Ophthalmology Question Answering](https://arxiv.org/abs/2508.09956)
*Fares Antaki,David Mikhail,Daniel Milad,Danny A Mammo,Sumit Sharma,Sunil K Srivastava,Bing Yu Chen,Samir Touma,Mertcan Sevgi,Jonathan El-Khoury,Pearse A Keane,Qingyu Chen,Yih Chung Tham,Renaud Duval*

Main category: cs.CL

TL;DR: GPT-5在医学眼科问答中准确率优于前代与部分竞品，推理强度与成本配置影响效果，GPT-5-mini-low兼具性价比。提出了自动评分新框架，推动专业医疗AI高效评测。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）如GPT-5在推理能力上的提升，其在复杂医学问答任务中的潜力亟需评估。目前尚不清楚哪种配置能在保证准确率的同时实现成本效益最大化，特别是在专业医学领域，如眼科学。

Method: 作者对OpenAI的GPT-5系列12种配置（分为三个模型层级与四种推理强度）进行了评估，并与o1-high、o3-high和GPT-4o进行对比。测评数据使用了美国眼科学会的高质量BCSC临床科学选择题集（共260题）。主要评估多项选择题的准确率；次要指标包括利用Bradley-Terry模型的头对头排名、基于参考和LLM判断的推理质量、以及基于Token的成本-准确率权衡分析。

Result: GPT-5-high在准确率上达到0.965，显著优于所有GPT-5-nano变体（P<.001）、o1-high（P=0.04）和GPT-4o（P<.001），但与o3-high差异不显著。此外，GPT-5-high在准确率和推理质量上均排名第一（准确率是o3-high的1.66倍，推理质量是1.11倍）。成本-准确率分析发现多个GPT-5配置在帕累托前沿，其中GPT-5-mini-low在低成本高性能间表现最佳。

Conclusion: 本研究基准性地评估了GPT-5在高质量眼科学数据集上的表现，验证了推理强度对模型准确率的影响，并提出了一种可扩展的LLM答题自动评分框架，为合理配置大模型在专业场景落地提供参考。

Abstract: Large language models (LLMs) such as GPT-5 integrate advanced reasoning
capabilities that may improve performance on complex medical question-answering
tasks. For this latest generation of reasoning models, the configurations that
maximize both accuracy and cost-efficiency have yet to be established. We
evaluated 12 configurations of OpenAI's GPT-5 series (three model tiers across
four reasoning effort settings) alongside o1-high, o3-high, and GPT-4o, using
260 closed-access multiple-choice questions from the American Academy of
Ophthalmology Basic Clinical Science Course (BCSC) dataset. The primary outcome
was multiple-choice accuracy; secondary outcomes included head-to-head ranking
via a Bradley-Terry model, rationale quality assessment using a
reference-anchored, pairwise LLM-as-a-judge framework, and analysis of
accuracy-cost trade-offs using token-based cost estimates. GPT-5-high achieved
the highest accuracy (0.965; 95% CI, 0.942-0.985), outperforming all GPT-5-nano
variants (P < .001), o1-high (P = .04), and GPT-4o (P < .001), but not o3-high
(0.958; 95% CI, 0.931-0.981). GPT-5-high ranked first in both accuracy (1.66x
stronger than o3-high) and rationale quality (1.11x stronger than o3-high).
Cost-accuracy analysis identified several GPT-5 configurations on the Pareto
frontier, with GPT-5-mini-low offering the most favorable low-cost,
high-performance balance. These results benchmark GPT-5 on a high-quality
ophthalmology dataset, demonstrate the influence of reasoning effort on
accuracy, and introduce an autograder framework for scalable evaluation of
LLM-generated answers against reference standards in ophthalmology.

</details>


### [59] [Which one Performs Better? Wav2Vec or Whisper? Applying both in Badini Kurdish Speech to Text (BKSTT)](https://arxiv.org/abs/2508.09957)
*Renas Adnan,Hossein Hassani*

Main category: cs.CL

TL;DR: 作者构建了首个面向Badini库尔德语方言的语音转文本模型。与Whisper-small模型对比，Wav2Vec2-Large-XLSR-53模型在可读性和准确率上均有明显优势，为低资源方言的数字化应用作出了贡献。


<details>
  <summary>Details</summary>
Motivation: 虽然库尔德语是一种资源较少的语言，但其部分方言（如Sorani）已有语音转文本（STT）系统，然而Badini、Hawrami等其他库尔德语方言尚未有相关系统。Badini有约200万使用者，STT对这部分群体的数字化非常重要。

Method: 选取了Badini方言的儿童故事文本（8本，共78个故事）作为语料，由6位讲述者朗读录制，总时长约17小时。对录音进行了清洗、分段和分词预处理，最终得到约15小时的语音数据。采用Wav2Vec2-Large-XLSR-53和Whisper-small两种模型分别训练和评估STT系统。

Result: Wav2Vec2-Large-XLSR-53模型在转录Badini语音时表现明显优于Whisper-small模型，可读性分别为90.38%与65.45%，准确率分别为82.67%与53.17%。

Conclusion: Wav2Vec2-Large-XLSR-53是一种更适用于Badini库尔德语方言STT任务的模型，显著提高了文字转写的可读性和准确率。

Abstract: Speech-to-text (STT) systems have a wide range of applications. They are
available in many languages, albeit at different quality levels. Although
Kurdish is considered a less-resourced language from a processing perspective,
SST is available for some of the Kurdish dialects, for instance, Sorani
(Central Kurdish). However, that is not applied to other Kurdish dialects,
Badini and Hawrami, for example. This research is an attempt to address this
gap. Bandin, approximately, has two million speakers, and STT systems can help
their community use mobile and computer-based technologies while giving their
dialect more global visibility. We aim to create a language model based on
Badini's speech and evaluate its performance. To cover a conversational aspect,
have a proper confidence level of grammatical accuracy, and ready
transcriptions, we chose Badini kids' stories, eight books including 78
stories, as the textual input. Six narrators narrated the books, which resulted
in approximately 17 hours of recording. We cleaned, segmented, and tokenized
the input. The preprocessing produced nearly 15 hours of speech, including
19193 segments and 25221 words. We used Wav2Vec2-Large-XLSR-53 and
Whisper-small to develop the language models. The experiments indicate that the
transcriptions process based on the Wav2Vec2-Large-XLSR-53 model provides a
significantly more accurate and readable output than the Whisper-small model,
with 90.38% and 65.45% readability, and 82.67% and 53.17% accuracy,
respectively.

</details>


### [60] [Neural Bandit Based Optimal LLM Selection for a Pipeline of Tasks](https://arxiv.org/abs/2508.09958)
*Baran Atalar,Eddie Zhang,Carlee Joe-Wong*

Main category: cs.CL

TL;DR: 本文提出并验证了一种基于神经上下文赌博机的LLM序列选择算法，在多子任务和无历史数据下能更高效地分配和选择LLM，适用于复杂且需多模型协作的实际应用场景。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）在各类任务中的广泛应用，如何以低成本预测和选择最适合特定任务的LLM变得越来越重要，尤其是在任务高度专业化和复杂时，单一LLM难以完全胜任。未来用户可根据需求定制专属LLM助手，提升任务处理效果。

Method: 提出了一种基于神经上下文赌博机算法（neural contextual bandit）的LLM序列选择方法。该方法通过神经网络在线建模每个子任务中LLM的成功率，在没有历史数据的情况下逐步学习如何为不同子任务挑选最合适的LLM。

Result: 在电信问答和医疗诊断预测数据集上的实验结果显示，所提方法在子任务分配与LLM选择上比传统单一模型选择算法更有效，提升了整体任务完成率和效率。

Conclusion: 针对复杂任务需要多轮LLM协作的情境，文中提出的序列选择与在线学习方法能有效解决性能依赖和成本控制的问题，为多LLM协作任务解决方案提供了新思路和技术参考。

Abstract: With the increasing popularity of large language models (LLMs) for a variety
of tasks, there has been a growing interest in strategies that can predict
which out of a set of LLMs will yield a successful answer at low cost. This
problem promises to become more and more relevant as providers like Microsoft
allow users to easily create custom LLM "assistants" specialized to particular
types of queries. However, some tasks (i.e., queries) may be too specialized
and difficult for a single LLM to handle alone. These applications often
benefit from breaking down the task into smaller subtasks, each of which can
then be executed by a LLM expected to perform well on that specific subtask.
For example, in extracting a diagnosis from medical records, one can first
select an LLM to summarize the record, select another to validate the summary,
and then select another, possibly different, LLM to extract the diagnosis from
the summarized record. Unlike existing LLM selection or routing algorithms,
this setting requires that we select a sequence of LLMs, with the output of
each LLM feeding into the next and potentially influencing its success. Thus,
unlike single LLM selection, the quality of each subtask's output directly
affects the inputs, and hence the cost and success rate, of downstream LLMs,
creating complex performance dependencies that must be learned and accounted
for during selection. We propose a neural contextual bandit-based algorithm
that trains neural networks that model LLM success on each subtask in an online
manner, thus learning to guide the LLM selections for the different subtasks,
even in the absence of historical LLM performance data. Experiments on
telecommunications question answering and medical diagnosis prediction datasets
illustrate the effectiveness of our proposed approach compared to other LLM
selection algorithms.

</details>
