{"id": "2506.22561", "categories": ["cs.LO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2506.22561", "abs": "https://arxiv.org/abs/2506.22561", "authors": ["Clotilde Bizi\u00e8re", "Thibault Hilaire", "J\u00e9r\u00f4me Leroux", "Gr\u00e9goire Sutre"], "title": "On the Reachability Problem for Two-Dimensional Branching VASS", "comment": "Full version of the paper with the same title and authors to appear\n  in the proceedings of MFCS 2025", "summary": "Vectors addition systems with states (VASS), or equivalently Petri nets, are\narguably one of the most studied formalisms for the modeling and analysis of\nconcurrent systems. A central decision problem for VASS is reachability:\nwhether there exists a run from an initial configuration to a final one. This\nproblem has been known to be decidable for over forty years, and its complexity\nhas recently been precisely characterized. Our work concerns the reachability\nproblem for BVASS, a branching generalization of VASS. In dimension one, the\nexact complexity of this problem is known. In this paper, we prove that the\nreachability problem for 2-dimensional BVASS is decidable. In fact, we even\nshow that the reachability set admits a computable semilinear presentation. The\ndecidability status of the reachability problem for BVASS remains open in\nhigher dimensions.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u4e86\u4e8c\u7ef4BVASS\uff08\u5206\u652f\u72b6\u6001\u5411\u91cf\u52a0\u6cd5\u7cfb\u7edf\uff09\u7684\u53ef\u8fbe\u6027\u95ee\u9898\uff0c\u8bc1\u660e\u5176\u662f\u53ef\u5224\u5b9a\u7684\uff0c\u5e76\u4e14\u53ef\u8fbe\u96c6\u53ef\u7528\u53ef\u8ba1\u7b97\u7684\u534a\u7ebf\u6027\u5f62\u5f0f\u8868\u793a\u3002\u4f46\u9ad8\u7ef4BVASS\u7684\u60c5\u51b5\u4ecd\u672a\u89e3\u51b3\u3002", "motivation": "\u81ea\u52a8\u673a\u7406\u8bba\u548c\u5e76\u53d1\u7cfb\u7edf\u5efa\u6a21\u4e2d\uff0cVASS\uff08\u72b6\u6001\u5411\u91cf\u52a0\u6cd5\u7cfb\u7edf\uff09\u53ca\u5176\u5206\u652f\u6269\u5c55BVASS\u662f\u6838\u5fc3\u6a21\u578b\u4e4b\u4e00\u3002\u7814\u7a76\u5176\u53ef\u8fbe\u6027\u95ee\u9898\uff08\u662f\u5426\u80fd\u4ece\u521d\u59cb\u72b6\u6001\u5230\u8fbe\u76ee\u6807\u72b6\u6001\uff09\u5bf9\u4e8e\u5206\u6790\u7cfb\u7edf\u884c\u4e3a\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136VASS\u7684\u53ef\u8fbe\u6027\u95ee\u9898\u5df2\u88ab\u89e3\u51b3\uff0c\u4f46BVASS\u5728\u9ad8\u7ef4\u5ea6\u4e0b\u4f9d\u7136\u672a\u89e3\u3002\u8be5\u6587\u805a\u7126\u4e8e2\u7ef4BVASS\u7684\u6b64\u7c7b\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u9488\u5bf9\u4e8c\u7ef4BVASS\uff0c\u4f7f\u7528\u4e86\u7406\u8bba\u8ba1\u7b97\u65b9\u6cd5\u5bf9\u5176\u53ef\u8fbe\u6027\u95ee\u9898\u8fdb\u884c\u7814\u7a76\u3002\u8fdb\u4e00\u6b65\uff0c\u4f5c\u8005\u901a\u8fc7\u6570\u5b66\u5de5\u5177\uff0c\u8bc1\u660e\u4e86\u5176\u53ef\u8fbe\u96c6\u53ef\u7528\u53ef\u8ba1\u7b97\u7684\u534a\u7ebf\u6027\u8868\u8fbe\u5f0f\u8868\u8ff0\u3002", "result": "\u4f5c\u8005\u8bc1\u660e\u4e86\u4e8c\u7ef4BVASS\u7684\u53ef\u8fbe\u6027\u95ee\u9898\u662f\u53ef\u5224\u5b9a\u7684\uff0c\u5e76\u4e14\u5176\u53ef\u8fbe\u96c6\u5177\u6709\u53ef\u8ba1\u7b97\u7684\u534a\u7ebf\u6027\u7ed3\u6784\u3002\u5bf9\u4e8e\u66f4\u9ad8\u7ef4\u5ea6\u7684BVASS\uff0c\u53ef\u8fbe\u6027\u95ee\u9898\u662f\u5426\u53ef\u5224\u5b9a\u4f9d\u7136\u662f\u5f00\u653e\u95ee\u9898\u3002", "conclusion": "\u4e8c\u7ef4BVASS\u7684\u53ef\u8fbe\u6027\u95ee\u9898\u662f\u53ef\u5224\u5b9a\u7684\uff0c\u5e76\u6709\u7ed3\u6784\u6027\u7684\u53ef\u8ba1\u7b97\u8868\u8fbe\uff0c\u800c\u9ad8\u7ef4\u60c5\u5f62\u5c1a\u672a\u89e3\u51b3\u3002"}}
{"id": "2506.22584", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2506.22584", "abs": "https://arxiv.org/abs/2506.22584", "authors": ["Marek Dan\u010do", "Petra Hozzov\u00e1", "Mikol\u00e1\u0161 Janota"], "title": "From MBQI to Enumerative Instantiation and Back", "comment": "SMT 2025 early presubmission", "summary": "This work investigates the relation between model-based quantifier\ninstantiation (MBQI) and enumerative instantiation (EI) in Satisfiability\nModulo Theories (SMT). MBQI operates at the semantic level and guarantees to\nfind a counterexample to a given a non-model. However, it may lead to weak\ninstantiations. In contrast, EI strives for completeness by systematically\nenumerating terms at the syntactic level. However, such terms may not be\ncounter-examples. Here we investigate the relation between the two techniques\nand report on our initial experiments of the proposed algorithm that combines\nthe two.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u4e24\u79cd\u4e3b\u6d41SMT\u91cf\u8bcd\u5b9e\u4f8b\u5316\u65b9\u6cd5\uff08MBQI\u548cEI\uff09\uff0c\u63d0\u51fa\u5e76\u5b9e\u9a8c\u4e86\u7ed3\u5408\u4e8c\u8005\u7684\u65b0\u7b97\u6cd5\uff0c\u5e76\u62a5\u544a\u4e86\u521d\u6b65\u6548\u679c\u3002", "motivation": "MBQI\u867d\u7136\u80fd\u4fdd\u8bc1\u627e\u5230\u53cd\u4f8b\uff0c\u4f46\u5b9e\u4f8b\u5316\u8f83\u5f31\uff1b\u800cEI\u867d\u7cfb\u7edf\u679a\u4e3e\u4fdd\u8bc1\u5b8c\u5907\u6027\uff0c\u4f46\u679a\u4e3e\u5230\u7684\u9879\u672a\u5fc5\u662f\u771f\u6b63\u53cd\u4f8b\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u9a8c\u4e86\u4e00\u79cd\u7ed3\u5408MBQI\u4e0eEI\u7684\u65b9\u6cd5\uff0c\u5c06\u8bed\u4e49\u4e0a\u7684MBQI\u548c\u53e5\u6cd5\u4e0a\u7684EI\u76f8\u7ed3\u5408\uff0c\u5e76\u901a\u8fc7\u7b97\u6cd5\u5b9e\u9a8c\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u7ed3\u679c\u62a5\u544a\u4e86\u7ed3\u5408\u65b9\u6cd5\u7684\u8868\u73b0\uff0c\u5e76\u4e3a\u4e24\u79cd\u5b9e\u4f8b\u5316\u65b9\u6cd5\u7684\u5173\u7cfb\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u6570\u636e\u3002", "conclusion": "\u672c\u6587\u521d\u6b65\u5b9e\u9a8c\u4e86\u7ed3\u5408\u6a21\u578b\u9a71\u52a8\u91cf\u8bcd\u5b9e\u4f8b\u5316\uff08MBQI\uff09\u548c\u679a\u4e3e\u5b9e\u4f8b\u5316\uff08EI\uff09\u7684\u7b97\u6cd5\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e24\u8005\u4e4b\u95f4\u7684\u5173\u7cfb\u3002"}}
{"id": "2506.22687", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2506.22687", "abs": "https://arxiv.org/abs/2506.22687", "authors": ["Damian Arellanes"], "title": "Compositional Control-Driven Boolean Circuits", "comment": null, "summary": "Boolean circuits abstract away from physical details to focus on the logical\nstructure and computational behaviour of digital components. Despite they have\nbeen studied for many decades, compositionality has been widely ignored or\nexamined in an informal manner, which is a property for combining circuits\nwithout delving into their internal structure, while supporting modularity and\nformal reasoning. In this paper, we address this longstanding theoretical gap\nby proposing colimit-based operators for compositional circuit construction. We\ndefine separate operators for forming sequential, parallel, branchial and\niterative circuits. As composites encapsulate explicit control flow, a new\nmodel of computation emerges which we refer to as (families of) control-driven\nBoolean circuits. We show how this model is at least as powerful as its\nclassical counterpart. In other words, it is able to non-uniformly compute any\nBoolean function on inputs of arbitrary length.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f59\u6781\u9650\u7684\u5e03\u5c14\u7535\u8def\u7ec4\u5408\u65b9\u5f0f\uff0c\u9996\u6b21\u7cfb\u7edf\u5730\u89e3\u51b3\u4e86\u5e03\u5c14\u7535\u8def\u7ec4\u5408\u6027\u7684\u7406\u8bba\u96be\u9898\uff0c\u5b9a\u4e49\u4e86\u591a\u79cd\u7535\u8def\u7ec4\u5408\u64cd\u4f5c\u7b26\uff0c\u5e76\u5f15\u5165\u63a7\u5236\u9a71\u52a8\u5e03\u5c14\u7535\u8def\u7684\u65b0\u8ba1\u7b97\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u5176\u5f3a\u5927\u7684\u8ba1\u7b97\u80fd\u529b\u4ee5\u53ca\u5bf9\u6a21\u5757\u5316\u548c\u5f62\u5f0f\u5316\u63a8\u7406\u7684\u652f\u6301\u3002", "motivation": "\u5e03\u5c14\u7535\u8def\u957f\u671f\u4f5c\u4e3a\u7814\u7a76\u6570\u5b57\u7ec4\u4ef6\u903b\u8f91\u7ed3\u6784\u53ca\u8ba1\u7b97\u884c\u4e3a\u7684\u62bd\u8c61\u6a21\u578b\uff0c\u4f46\u5176\u7ec4\u5408\u6027\uff08\u5373\u5728\u4e0d\u5173\u6ce8\u5185\u90e8\u7ed3\u6784\u7684\u60c5\u51b5\u4e0b\u7ec4\u5408\u7535\u8def\u4ee5\u652f\u6301\u6a21\u5757\u5316\u548c\u5f62\u5f0f\u5316\u63a8\u7406\uff09\u4e00\u76f4\u88ab\u5ffd\u89c6\u6216\u8f83\u4e3a\u975e\u6b63\u5f0f\u5730\u5bf9\u5f85\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e2a\u7406\u8bba\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u4f59\u6781\u9650\uff08colimit\uff09\u7684\u7535\u8def\u7ec4\u5408\u64cd\u4f5c\u7b26\uff0c\u5206\u522b\u5b9a\u4e49\u7528\u4e8e\u6784\u5efa\u4e32\u884c\u3001\u5e76\u884c\u3001\u5206\u652f\u548c\u8fed\u4ee3\u7535\u8def\u7684\u64cd\u4f5c\u7b26\uff0c\u5e76\u4ee5\u6b64\u63cf\u8ff0\u5177\u5907\u663e\u5f0f\u63a7\u5236\u6d41\u7684\u7535\u8def\u590d\u5408\u5f62\u5f0f\uff0c\u5f62\u6210\u4e00\u79cd\u65b0\u7684\u63a7\u5236\u9a71\u52a8\u578b\u5e03\u5c14\u7535\u8def\u8ba1\u7b97\u6a21\u578b\u3002", "result": "\u8be5\u6a21\u578b\u81f3\u5c11\u4e0e\u4f20\u7edf\u5e03\u5c14\u7535\u8def\u6a21\u578b\u7b49\u4ef7\uff0c\u5373\u80fd\u591f\u975e\u5747\u5300\u5730\u8ba1\u7b97\u4efb\u610f\u957f\u5ea6\u8f93\u5165\u7684\u4efb\u610f\u5e03\u5c14\u51fd\u6570\u3002", "conclusion": "\u901a\u8fc7\u5f62\u5f0f\u5316\u7684colimit\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5e03\u5c14\u7535\u8def\u7684\u53ef\u7ec4\u5408\u6027\u6784\u9020\uff0c\u63a8\u52a8\u4e86\u6a21\u5757\u5316\u548c\u5f62\u5f0f\u5316\u63a8\u7406\u5728\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002\u63a7\u5236\u9a71\u52a8\u5e03\u5c14\u7535\u8def\u6a21\u578b\u5728\u7406\u8bba\u4e0a\u662f\u5b8c\u5907\u7684\uff0c\u5177\u6709\u548c\u7ecf\u5178\u6a21\u578b\u76f8\u540c\u7684\u8ba1\u7b97\u80fd\u529b\u3002"}}
{"id": "2506.22735", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2506.22735", "abs": "https://arxiv.org/abs/2506.22735", "authors": ["Willem Conradie", "Krishna Manoorkar", "Alessandra Palmigiano", "Apostolos Tzimoulis", "Nachoem Wijnberg"], "title": "Questions as cognitive filters", "comment": null, "summary": "In this paper, we develop a logico-algebraic framework for modeling\ndecision-making through deliberation in multi-agent settings. The central\nconcept in this framework is that of interrogative agendas, which represent the\ncognitive stances of agents regarding which features should be considered\nrelevant in the final decision. We formalize an agent's interrogative agenda as\nan equivalence relation that identifies outcomes differing only in aspects the\nagent deems irrelevant. Moreover, we characterize the sublattices of the\nresulting lattice that correspond to relevant interrogative agendas for\ndeliberation scenarios governed by different ``winning rules.\" We then\nintroduce a two-sorted logico-algebraic structure-comprising the lattice of\nrelevant interrogative agendas and the Boolean algebras of agent coalitions-to\nmodel the interaction between agents and agendas during deliberation. Finally,\nwe discuss which interaction conditions can and cannot be defined within this\nframework.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u903b\u8f91-\u4ee3\u6570\u6846\u67b6\uff0c\u5f62\u5f0f\u5316\u63cf\u8ff0\u591a\u667a\u80fd\u4f53\u534f\u8c03\u51b3\u7b56\u65f6\u5bf9\u201c\u76f8\u5173\u6027\u201d\u7279\u5f81\u7684\u8ba4\u77e5\u4e0e\u4ea4\u4e92\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u89c4\u5219\u4e0b\u7684\u7406\u8bba\u6027\u8d28\uff0c\u5e76\u660e\u786e\u6846\u67b6\u8868\u8fbe\u529b\u7684\u8fb9\u754c\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u51b3\u7b56\u8fc7\u7a0b\u901a\u5e38\u9700\u8981\u5728\u4e0d\u540c\u7279\u5f81\u6216\u4fe1\u606f\u76f8\u5173\u6027\u4e0a\u8fbe\u6210\u5171\u8bc6\uff0c\u4f46\u7f3a\u4e4f\u5f62\u5f0f\u5316\u5de5\u5177\u6765\u523b\u753b\u5404\u667a\u80fd\u4f53\u5bf9\u54ea\u4e9b\u7279\u5f81\u5e94\u88ab\u7eb3\u5165\u51b3\u7b56\u7684\u8ba4\u77e5\u7acb\u573a\u3002\u672c\u6587\u65e8\u5728\u5efa\u7acb\u4e00\u79cd\u5f62\u5f0f\u5316\u6846\u67b6\u6765\u63cf\u8ff0\u548c\u5206\u6790\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u4e86\u4ee5\u201c\u8be2\u95ee\u6027\u8bae\u7a0b\u201d\uff08interrogative agendas\uff09\u4e3a\u6838\u5fc3\u7684\u903b\u8f91-\u4ee3\u6570\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u4f53\u7684\u76f8\u5173\u6027\u5224\u65ad\u5f62\u5f0f\u5316\u4e3a\u7b49\u4ef7\u5173\u7cfb\uff0c\u5e76\u5206\u6790\u4e86\u4e0d\u540c\u2018\u80dc\u51fa\u89c4\u5219\u2019\u4e0b\uff0c\u76f8\u5173\u8bae\u7a0b\u5b50\u683c\u7684\u7ed3\u6784\u3002\u5f15\u5165\u4e24\u7c7b\u7ed3\u6784\uff1a\u76f8\u5173\u8bae\u7a0b\u683c\u4ee5\u53ca\u667a\u80fd\u4f53\u8054\u76df\u7684\u5e03\u5c14\u4ee3\u6570\uff0c\u901a\u8fc7\u5b83\u4eec\u5171\u540c\u5efa\u6a21\u591a\u667a\u80fd\u4f53\u8ba8\u8bba\u8fc7\u7a0b\u3002\u6700\u540e\u63a2\u8ba8\u4e86\u8be5\u6846\u67b6\u4e0b\u53ef\u523b\u753b\u548c\u4e0d\u53ef\u523b\u753b\u7684\u667a\u80fd\u4f53-\u8bae\u7a0b\u4ea4\u4e92\u6761\u4ef6\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u8986\u76d6\u591a\u79cd\u51b3\u7b56\u573a\u666f\u7684\u7406\u8bba\u6a21\u578b\uff0c\u80fd\u591f\u5f62\u5f0f\u5316\u5e76\u533a\u5206\u4e0d\u540c\u80dc\u51fa\u89c4\u5219\u4e0b\u7684\u8bae\u7a0b\u5173\u7cfb\uff1b\u660e\u786e\u6307\u51fa\u54ea\u4e9b\u4ea4\u4e92\u6761\u4ef6\u53ef\u901a\u8fc7\u8be5\u6846\u67b6\u8868\u8fbe\uff0c\u54ea\u4e9b\u4e0d\u53ef\u3002", "conclusion": "\u672c\u6587\u4e3a\u591a\u667a\u80fd\u4f53\u8ba8\u8bba-\u51b3\u7b56\u4e2d\u7684\u76f8\u5173\u6027\u8ba4\u77e5\u548c\u4ea4\u4e92\u63d0\u4f9b\u4e86\u7edf\u4e00\u4e14\u53ef\u6269\u5c55\u7684\u5f62\u5f0f\u5316\u5de5\u5177\uff0c\u5bf9\u5206\u6790\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u5171\u8bc6\u673a\u5236\u5177\u6709\u7406\u8bba\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2506.23384", "categories": ["cs.FL", "92-10", "F.4.3; J.3; F.1.3"], "pdf": "https://arxiv.org/pdf/2506.23384", "abs": "https://arxiv.org/abs/2506.23384", "authors": ["Da-Jung Cho", "Szil\u00e1rd Zsolt Fazekas", "Shinnosuke Seki", "Max Wiedenh\u00f6ft"], "title": "Programmable Co-Transcriptional Splicing: Realizing Regular Languages via Hairpin Deletion", "comment": "28 pages, 8 Figures, Accepted at the 31st International Conference on\n  DNA Computing and Molecular Programming (2025)", "summary": "RNA co-transcriptionality, where RNA is spliced or folded during\ntranscription from DNA templates, offers promising potential for molecular\nprogramming. It enables programmable folding of nano-scale RNA structures and\nhas recently been shown to be Turing universal. While post-transcriptional\nsplicing is well studied, co-transcriptional splicing is gaining attention for\nits efficiency, though its unpredictability still remains a challenge. In this\npaper, we focus on engineering co-transcriptional splicing, not only as a\nnatural phenomenon but as a programmable mechanism for generating specific RNA\ntarget sequences from DNA templates. The problem we address is whether we can\nencode a set of RNA sequences for a given system onto a DNA template word,\nensuring that all the sequences are generated through co-transcriptional\nsplicing. Given that finding the optimal encoding has been shown to be\nNP-complete under the various energy models considered, we propose a practical\nalternative approach under the logarithmic energy model. More specifically, we\nprovide a construction that encodes an arbitrary nondeterministic finite\nautomaton (NFA) into a circular DNA template from which co-transcriptional\nsplicing produces all sequences accepted by the NFA. As all finite languages\ncan be efficiently encoded as NFA, this framework solves the problem of finding\nsmall DNA templates for arbitrary target sets of RNA sequences. The quest to\nobtain the smallest possible such templates naturally leads us to consider the\nproblem of minimizing NFA and certain practically motivated variants of it, but\nas we show, those minimization problems are computationally intractable.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u80fd\u5c06\u4efb\u610f\u6709\u9650\u76ee\u6807RNA\u5e8f\u5217\u96c6\u9ad8\u6548\u7f16\u7801\u8fdbDNA\u73af\u72b6\u6a21\u677f\u7684\u65b9\u6cd5\uff0c\u4f9d\u8d56\u4e8eNFA\u8868\u8fbe\u80fd\u529b\uff0c\u901a\u8fc7\u5171\u8f6c\u5f55\u6027\u526a\u63a5\u751f\u6210\u76ee\u6807\u5e8f\u5217\u3002\u65b9\u6cd5\u5728\u5206\u5b50\u7f16\u7a0b\u4e0eRNA\u7ed3\u6784\u8bbe\u8ba1\u65b9\u9762\u5177\u5f00\u521b\u610f\u4e49\uff0c\u4f46\u6a21\u677f\u6700\u5c0f\u5316\u95ee\u9898\u8ba1\u7b97\u4e0a\u5177\u6311\u6218\u3002", "motivation": "RNA\u7684\u5171\u8f6c\u5f55\u6027\uff08\u5728DNA\u8f6c\u5f55\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u526a\u63a5\u6216\u6298\u53e0\uff09\u5728\u5206\u5b50\u7f16\u7a0b\u548cRNA\u7eb3\u7c73\u7ed3\u6784\u53ef\u7f16\u7a0b\u6298\u53e0\u65b9\u9762\u6709\u5de8\u5927\u6f5c\u529b\u3002\u7136\u800c\uff0c\u5171\u8f6c\u5f55\u6027\u526a\u63a5\u5b58\u5728\u6548\u7387\u9ad8\u4f46\u8fc7\u7a0b\u8f83\u96be\u9884\u6d4b\u7684\u95ee\u9898\u3002\u672c\u6587\u5e0c\u671b\u80fd\u5c06\u5176\u4f5c\u4e3a\u4e00\u79cd\u53ef\u7f16\u7a0b\u673a\u5236\uff0c\u4eceDNA\u6a21\u677f\u4ea7\u751f\u7279\u5b9aRNA\u5e8f\u5217\uff0c\u63d0\u5347\u7f16\u7a0b\u4e0e\u8bbe\u8ba1\u7684\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u6570\u80fd\u91cf\u6a21\u578b\u7684\u7f16\u7801\u65b9\u6cd5\uff0c\u5c06\u4efb\u610f\u975e\u786e\u5b9a\u6027\u6709\u9650\u81ea\u52a8\u673a\uff08NFA\uff09\u7f16\u7801\u8fdb\u73af\u72b6DNA\u6a21\u677f\uff0c\u4f7f\u5171\u8f6c\u5f55\u6027\u526a\u63a5\u53ef\u4ee5\u751f\u6210\u6240\u6709NFA\u63a5\u53d7\u7684RNA\u5e8f\u5217\u3002\u5229\u7528NFA\u7684\u9ad8\u6548\u8868\u8fbe\u80fd\u529b\u89e3\u51b3\u4e86\u4eceDNA\u6a21\u677f\u751f\u6210\u4e00\u7ec4\u7ed9\u5b9aRNA\u5e8f\u5217\u7684\u95ee\u9898\uff1b\u5e76\u63a2\u8ba8\u4e86\u4f18\u5316\u6700\u5c0f\u5316DNA\u6a21\u677f\u7684\u76f8\u5173\u81ea\u52a8\u673a\u6700\u5c0f\u5316\u95ee\u9898\u3002", "result": "\u4f5c\u8005\u6784\u5efa\u7684\u65b9\u6cd5\u53ef\u5c06\u4efb\u610f\u76ee\u6807RNA\u5e8f\u5217\u96c6\uff08\u53ef\u8868\u793a\u4e3a\u6709\u9650\u8bed\u8a00\uff09\u901a\u8fc7NFA\u9ad8\u6548\u7f16\u7801\u8fdbDNA\u6a21\u677f\uff0c\u5e76\u53ef\u7528\u5171\u8f6c\u5f55\u6027\u526a\u63a5\u751f\u6210\u5168\u90e8\u76ee\u6807\u5e8f\u5217\u3002\u4f46\u8fdb\u4e00\u6b65\u6700\u5c0f\u5316NFA\u7ed3\u6784\u53ca\u5176\u5b9e\u7528\u53d8\u4f53\u7684\u95ee\u9898\u88ab\u8bc1\u660e\u5728\u8ba1\u7b97\u4e0a\u662f\u4e0d\u53ef\u884c\u7684\uff08\u96be\u4ee5\u8fd1\u4f3c\u8ba1\u7b97\uff09\u3002", "conclusion": "\u6587\u7ae0\u4e3a\u5171\u8f6c\u5f55\u6027\u526a\u63a5\u7684\u53ef\u7f16\u7a0b\u5206\u5b50\u751f\u6210\u63d0\u51fa\u4e86\u4e00\u6574\u5957\u7406\u8bba\u4e0e\u5b9e\u8df5\u65b9\u6848\uff0c\u63d0\u4f9b\u4e86\u57fa\u4e8eNFA\u4e0eDNA\u6a21\u677f\u7684\u6709\u6548\u7f16\u7801\u65b9\u6cd5\u3002\u8be5\u5de5\u4f5c\u7a81\u7834\u6027\u5730\u4f7f\u5f97\u4efb\u610f\u6709\u9650\u96c6\u5408\u7684RNA\u5e8f\u5217\u90fd\u80fd\u4ee5\u8f83\u5c0f\u6a21\u677f\u5b9e\u73b0\u81ea\u52a8\u5408\u6210\uff0c\u867d\u5728\u8fdb\u4e00\u6b65\u4f18\u5316\u65f6\u5b58\u5728\u8ba1\u7b97\u590d\u6742\u6027\u9650\u5236\u3002"}}
{"id": "2506.23790", "categories": ["cs.DM", "cs.CC", "cs.DS", "math.CO"], "pdf": "https://arxiv.org/pdf/2506.23790", "abs": "https://arxiv.org/abs/2506.23790", "authors": ["Jesse Beisegel", "Katharina Klost", "Kristin Knorr", "Fabienne Ratajczak", "Robert Scheffler"], "title": "A Graph Width Perspective on Partially Ordered Hamiltonian Paths and Cycles I: Treewidth, Pathwidth, and Grid Graphs", "comment": "\"A Graph Width Perspective on Partially Ordered Hamiltonian Paths\"\n  arXiv:2503.03553 was an extended abstract of a host of results. We have\n  decided to split that paper into two separate full papers. This first paper\n  given here covers the first half of the results along with several new\n  results, in particular about Hamiltonian cycles", "summary": "We consider the problem of finding a Hamiltonian path or a Hamiltonian cycle\nwith precedence constraints in the form of a partial order on the vertex set.\nWe show that the path problem is $\\mathsf{NP}$-complete for graphs of pathwidth\n4 while the cycle problem is $\\mathsf{NP}$-complete on graphs of pathwidth 5.\nWe complement these results by giving polynomial-time algorithms for graphs of\npathwidth 3 and treewidth 2 for Hamiltonian paths as well as pathwidth 4 and\ntreewidth 3 for Hamiltonian cycles. Furthermore, we study the complexity of the\npath and cycle problems on rectangular grid graphs of bounded height. For\nthese, we show that the path and cycle problems are $\\mathsf{NP}$-complete when\nthe height of the grid is greater or equal to 7 and 9, respectively. In the\nvariant where we look for minimum edge-weighted Hamiltonian paths and cycles,\nthe problems are $\\mathsf{NP}$-hard for heights 5 and 6, respectively.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u5177\u6709\u4f18\u5148\u987a\u5e8f\u7ea6\u675f\u7684\u56fe\u7ed3\u6784\u4e2d\u6c42\u54c8\u5bc6\u987f\u8def\u5f84\u548c\u73af\u7684\u590d\u6742\u6027\u3002\u7ed3\u679c\u5c55\u793a\u4e86\u591a\u9879\u7ed3\u6784\u53c2\u6570\u4e0b\u7684\u590d\u6742\u5ea6\u754c\u9650\u4e0e\u591a\u9879\u5f0f\u53ef\u89e3\u60c5\u5f62\uff0c\u5bf9\u7406\u8bba\u4e0e\u5b9e\u9645\u5e94\u7528\u5747\u6709\u6307\u5bfc\u4ef7\u503c\u3002", "motivation": "\u5728\u56fe\u8bba\u4e2d\uff0c\u54c8\u5bc6\u987f\u8def\u5f84\u548c\u73af\u662f\u7ecf\u5178\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u3002\u6dfb\u52a0\u9876\u70b9\u95f4\u7684\u5148\u884c\u7ea6\u675f\uff08\u504f\u5e8f\u5173\u7cfb\uff09\u540e\uff0c\u95ee\u9898\u66f4\u5177\u6311\u6218\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5728\u6709\u9650\u8def\u5f84\u5bbd\u5ea6\u6216\u6811\u5bbd\u7684\u56fe\uff08\u5305\u62ec\u7f51\u683c\u56fe\uff09\u4e0a\uff0c\u52a0\u4e0a\u8fd9\u4e9b\u7ea6\u675f\u540e\u54c8\u5bc6\u987f\u8def\u5f84\uff08\u73af\uff09\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u590d\u6742\u5ea6\u8fd8\u539f\uff0c\u8bc1\u660e\u5e26\u504f\u5e8f\u7ea6\u675f\u7684\u54c8\u5bc6\u987f\u8def\u5f84\u548c\u73af\u95ee\u9898\u5206\u522b\u5728\u7279\u5b9a\u8def\u5f84\u5bbd\u5ea6\u7684\u56fe\u4e0a\u662f$\text{NP}$-\u5b8c\u5168\u7684\u3002\u540c\u65f6\uff0c\u8bbe\u8ba1\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u89e3\u51b3\u5728\u66f4\u5c0f\u8def\u5f84\u5bbd\u5ea6\u6216\u6811\u5bbd\u6761\u4ef6\u4e0b\u7684\u76f8\u5173\u95ee\u9898\u3002\u5bf9\u5e26\u6743\u56fe\u53d8\u4f53\u4e0e\u7f51\u683c\u56fe\u4e5f\u8fdb\u884c\u4e86\u590d\u6742\u5ea6\u7814\u7a76\u3002", "result": "\u5f53\u56fe\u7684\u8def\u5f84\u5bbd\u5ea6\u4e3a4\u65f6\uff0c\u5e26\u4f18\u5148\u7ea6\u675f\u7684\u54c8\u5bc6\u987f\u8def\u5f84\u95ee\u9898\u662f$\text{NP}$-\u5b8c\u5168\u7684\uff0c\u8def\u5f84\u5bbd\u5ea6\u4e3a5\u65f6\uff0c\u54c8\u5bc6\u987f\u73af\u95ee\u9898\u662f$\text{NP}$-\u5b8c\u5168\u7684\uff1b\u800c\u8def\u5f84\u5bbd\u5ea63\u6216\u6811\u5bbd2\u7684\u56fe\u7684\u8def\u5f84\u95ee\u9898\uff0c\u4ee5\u53ca\u8def\u5f84\u5bbd\u5ea64\u6216\u6811\u5bbd3\u7684\u73af\u95ee\u9898\uff0c\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u89e3\u51b3\u3002\u5bf9\u4e8e\u9ad8\u4e3a7\u62169\u4ee5\u4e0a\u7684\u7f51\u683c\u56fe\uff0c\u5176\u8def\u5f84/\u73af\u95ee\u9898\u4e3a$\text{NP}$-\u5b8c\u5168\uff08\u5e26\u6743\u65f65\u30016\u4e3a\u754c\uff09\u3002", "conclusion": "\u5e26\u6709\u5148\u884c\u7ea6\u675f\u7684\u54c8\u5bc6\u987f\u8def\u5f84\u548c\u73af\u95ee\u9898\u5728\u5177\u6709\u8f83\u5c0f\u8def\u5f84\u5bbd\u5ea6\u6216\u6811\u5bbd\u7684\u56fe\u548c\u7f51\u683c\u4e2d\u6709\u660e\u786e\u7684\u590d\u6742\u5ea6\u5206\u754c\uff0c\u5728\u4e00\u5b9a\u8303\u56f4\u5185\u53ef\u5b9e\u73b0\u9ad8\u6548\u7b97\u6cd5\uff0c\u4f46\u8d85\u8fc7\u8fd9\u4e2a\u8303\u56f4\u5219\u5448\u73b0$\text{NP}$-\u56f0\u96be\u3002"}}
{"id": "2506.22656", "categories": ["cs.SE", "cs.AI", "68-04", "D.2.3; I.2.7"], "pdf": "https://arxiv.org/pdf/2506.22656", "abs": "https://arxiv.org/abs/2506.22656", "authors": ["Jiangping Huang", "Dongming Jin", "Weisong Sun", "Yang Liu", "Zhi Jin"], "title": "Knowledge-Guided Multi-Agent Framework for Automated Requirements Development: A Vision", "comment": null, "summary": "This paper envisions a knowledge-guided multi-agent framework named KGMAF for\nautomated requirements development. KGMAF aims to address gaps in current\nautomation systems for SE, which prioritize code development and overlook the\ncomplexities of requirements tasks. KGMAF is composed of six specialized agents\nand an artifact pool to improve efficiency and accuracy. Specifically, KGMAF\noutlines the functionality, actions, and knowledge of each agent and provides\nthe conceptual design of the artifact pool. Our case study highlights the\npotential of KGMAF in real-world scenarios. Finally, we outline several\nresearch opportunities for implementing and enhancing automated requirements\ndevelopment using multi-agent systems. We believe that KGMAF will play a\npivotal role in shaping the future of automated requirements development in the\nera of LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86KGMAF\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u89e3\u51b3\u81ea\u52a8\u5316\u9700\u6c42\u5f00\u53d1\u4e2d\u7684\u75db\u70b9\uff0c\u7ecf\u6848\u4f8b\u9a8c\u8bc1\u5177\u5907\u5b9e\u9645\u5e94\u7528\u548c\u7814\u7a76\u4ef7\u503c\u3002", "motivation": "\u5f53\u524d\u8f6f\u4ef6\u5de5\u7a0b\u81ea\u52a8\u5316\u7cfb\u7edf\u8fc7\u4e8e\u5173\u6ce8\u4ee3\u7801\u5f00\u53d1\uff0c\u5ffd\u89c6\u4e86\u9700\u6c42\u5f00\u53d1\u7684\u590d\u6742\u6027\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u63d0\u5347\u9700\u6c42\u5f00\u53d1\u7684\u81ea\u52a8\u5316\u6c34\u5e73\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u8bbe\u8ba1\u516d\u4e2a\u4e13\u95e8\u7684agent\u53ca\u4e00\u4e2aartifact pool\uff0c\u5e76\u8be6\u7ec6\u63cf\u8ff0\u5404agent\u7684\u529f\u80fd\u3001\u884c\u52a8\u53ca\u77e5\u8bc6\uff0c\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u3002", "result": "KGMAF\u6709\u6548\u63d0\u5347\u4e86\u81ea\u52a8\u5316\u9700\u6c42\u5f00\u53d1\u7684\u6548\u7387\u4e0e\u51c6\u786e\u6027\uff0c\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5176\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "KGMAF\u6846\u67b6\u6709\u6f5c\u529b\u63a8\u52a8\u81ea\u52a8\u5316\u9700\u6c42\u5f00\u53d1\uff0c\u5e76\u5c06\u6210\u4e3aLLM\u65f6\u4ee3\u7684\u91cd\u8981\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.23058", "categories": ["cs.PL", "cs.DC"], "pdf": "https://arxiv.org/pdf/2506.23058", "abs": "https://arxiv.org/abs/2506.23058", "authors": ["Nikolaj Hey Hinnerskov", "Robert Schenck", "Cosmin E. Oancea"], "title": "Verifying Properties of Index Arrays in a Purely-Functional Data-Parallel Language", "comment": null, "summary": "This paper presents a novel approach to automatically verify properties of\npure data-parallel programs with non-linear indexing -- expressed as pre- and\npost-conditions on functions. Programs consist of nests of second-order array\ncombinators (e.g., map, scan, and scatter) and loops. The key idea is to\nrepresent arrays as index functions: programs are index function\ntransformations over which properties are propagated and inferred. Our\nframework proves properties on index functions by distilling them into\nalgebraic (in)equalities and discharging them to a Fourier-Motzkin-based\nsolver. The framework is practical and accessible: properties are not\nrestricted to a decidable logic, but instead are carefully selected to express\npractically useful guarantees that can be automatically reasoned about and\ninferred. These guarantees extend beyond program correctness and can be\nexploited by the entire compiler pipeline for optimization. We implement our\nsystem in the pure data-parallel language Futhark and demonstrate its\npracticality on seven applications, reporting an average verification time of 1\nsecond. Two case studies show how eliminating dynamic verification in GPU\nprograms results in significant speedups.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7d22\u5f15\u51fd\u6570\u548cFourier-Motzkin\u6c42\u89e3\u5668\u7684\u81ea\u52a8\u5c5e\u6027\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u80fd\u8bc1\u660e\u7eaf\u6570\u636e\u5e76\u884c\u7a0b\u5e8f\u7684\u6b63\u786e\u6027\uff0c\u8fd8\u80fd\u4f18\u5316\u7f16\u8bd1\u7ba1\u7ebf\uff0c\u9a8c\u8bc1\u6548\u7387\u9ad8\u4e14\u5b9e\u9645\u6709\u6548\u3002", "motivation": "\u5f53\u524d\u7eaf\u6570\u636e\u5e76\u884c\u7a0b\u5e8f\u4e2d\u5e26\u975e\u7ebf\u6027\u7d22\u5f15\u7684\u5c5e\u6027\u81ea\u52a8\u9a8c\u8bc1\u8f83\u4e3a\u56f0\u96be\uff0c\u73b0\u6709\u65b9\u6cd5\u5bf9\u4e8e\u8868\u8fbe\u80fd\u529b\u548c\u53ef\u81ea\u52a8\u5316\u63a8\u7406\u5b58\u5728\u5c40\u9650\u3002\u4f5c\u8005\u5e0c\u671b\u8bbe\u8ba1\u4e00\u79cd\u65e2\u80fd\u81ea\u52a8\u9a8c\u8bc1\u53c8\u80fd\u8868\u8fbe\u5b9e\u9645\u6709\u7528\u5c5e\u6027\u7684\u65b0\u65b9\u6cd5\uff0c\u540c\u65f6\u4e3a\u540e\u7eed\u7f16\u8bd1\u4f18\u5316\u63d0\u4f9b\u66f4\u591a\u4fdd\u969c\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5c06\u6570\u7ec4\u8868\u8fbe\u4e3a\u7d22\u5f15\u51fd\u6570\uff0c\u5e76\u5c06\u5c5e\u6027\u4f20\u64ad\u548c\u63a8\u65ad\u8f6c\u5316\u4e3a\u5bf9\u7d22\u5f15\u51fd\u6570\u7684\u53d8\u6362\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u5c5e\u6027\u7cbe\u70bc\u4e3a\u4ee3\u6570\uff08\u4e0d\uff09\u7b49\u5f0f\uff0c\u6700\u7ec8\u5229\u7528\u57fa\u4e8eFourier-Motzkin\u6d88\u53bb\u6cd5\u7684\u6c42\u89e3\u5668\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u6846\u67b6\u65e0\u9700\u9650\u5236\u4e8e\u53ef\u5224\u5b9a\u7684\u903b\u8f91\u4e0b\uff0c\u4f9d\u7136\u80fd\u81ea\u52a8\u9a8c\u8bc1\u5b9e\u9645\u4e2d\u6709\u7528\u7684\u7a0b\u5e8f\u5c5e\u6027\uff0c\u5e76\u5c06\u8fd9\u4e9b\u5c5e\u6027\u7528\u4e8e\u7f16\u8bd1\u5668\u4f18\u5316\u3002\u5b9e\u73b0\u5728Futhark\u8bed\u8a00\u5e76\u7528\u4e8e7\u4e2a\u5e94\u7528\uff0c\u5e73\u5747\u6bcf\u6b21\u9a8c\u8bc1\u4ec5\u8017\u65f61\u79d2\u3002\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u9a8c\u8bc1\u6d88\u9664GPU\u7a0b\u5e8f\u52a8\u6001\u9a8c\u8bc1\u540e\u901f\u5ea6\u6709\u660e\u663e\u63d0\u5347\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u81ea\u52a8\u9a8c\u8bc1\u5177\u6709\u975e\u7ebf\u6027\u7d22\u5f15\u7684\u6570\u636e\u5e76\u884c\u7a0b\u5e8f\u7684\u5c5e\u6027\u3002\u8be5\u65b9\u6cd5\u5b9e\u8df5\u6709\u6548\uff0c\u5e76\u5df2\u5728Futhark\u8bed\u8a00\u53ca\u4e03\u4e2a\u5e94\u7528\u4e0a\u6210\u529f\u9a8c\u8bc1\uff0c\u5e73\u5747\u8017\u65f6\u4ec51\u79d2\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u6d88\u9664GPU\u7a0b\u5e8f\u7684\u52a8\u6001\u9a8c\u8bc1\uff0c\u53ef\u5e26\u6765\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2506.22439", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22439", "abs": "https://arxiv.org/abs/2506.22439", "authors": ["Javier Conde", "Miguel Gonz\u00e1lez", "Mar\u00eda Grandury", "Gonzalo Mart\u00ednez", "Pedro Reviriego", "Mar Brysbaert"], "title": "Psycholinguistic Word Features: a New Approach for the Evaluation of LLMs Alignment with Humans", "comment": "Accepted for the GEM2 workshop at ACL 2025", "summary": "The evaluation of LLMs has so far focused primarily on how well they can\nperform different tasks such as reasoning, question-answering, paraphrasing, or\ntranslating. For most of these tasks, performance can be measured with\nobjective metrics, such as the number of correct answers. However, other\nlanguage features are not easily quantified. For example, arousal,\nconcreteness, or gender associated with a given word, as well as the extent to\nwhich we experience words with senses and relate them to a specific sense.\nThose features have been studied for many years by psycholinguistics,\nconducting large-scale experiments with humans to produce ratings for thousands\nof words. This opens an opportunity to evaluate how well LLMs align with human\nratings on these word features, taking advantage of existing studies that cover\nmany different language features in a large number of words. In this paper, we\nevaluate the alignment of a representative group of LLMs with human ratings on\ntwo psycholinguistic datasets: the Glasgow and Lancaster norms. These datasets\ncover thirteen features over thousands of words. The results show that\nalignment is \\textcolor{black}{generally} better in the Glasgow norms evaluated\n(arousal, valence, dominance, concreteness, imageability, familiarity, and\ngender) than on the Lancaster norms evaluated (introceptive, gustatory,\nolfactory, haptic, auditory, and visual). This suggests a potential limitation\nof current LLMs in aligning with human sensory associations for words, which\nmay be due to their lack of embodied cognition present in humans and\nillustrates the usefulness of evaluating LLMs with psycholinguistic datasets.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5fc3\u7406\u8bed\u8a00\u5b66\u7279\u5f81\u6570\u636e\u96c6\u8bc4\u4f30\u4e86\u591a\u7c7bLLMs\u4e0e\u4eba\u7c7b\u8bc4\u5206\u7684\u4e00\u81f4\u6027\u3002\u7ed3\u679c\u8868\u660e\uff0cLLMs\u5728\u975e\u611f\u5b98\u7684\u8bed\u8a00\u5fc3\u7406\u7279\u6027\u4e0a\u8f83\u597d\u5bf9\u9f50\u4eba\u7c7b\u8868\u73b0\uff0c\u800c\u5728\u611f\u5b98\u76f8\u5173\u7279\u6027\uff08\u5982\u55c5\u89c9\u7b49\uff09\u4e0a\u7684\u5bf9\u9f50\u8f83\u5f31\uff0c\u7a81\u663e\u4e86\u5f53\u524d\u6a21\u578b\u5728\u2018\u5177\u8eab\u2019\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8bc4\u4f30\u4e2d\uff0c\u4f20\u7edf\u4e0a\u4e3b\u8981\u5173\u6ce8\u6a21\u578b\u5728\u63a8\u7406\u3001\u95ee\u7b54\u3001\u91ca\u4e49\u548c\u7ffb\u8bd1\u7b49\u5177\u4f53\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u91c7\u7528\u5ba2\u89c2\u6307\u6807\u6765\u8861\u91cf\u3002\u4f46\u8bed\u8a00\u8fd8\u6709\u8bb8\u591a\u96be\u4ee5\u91cf\u5316\u7684\u7279\u5f81\uff0c\u5982\u6fc0\u52b1\u6027\u3001\u5177\u4f53\u6027\u3001\u6027\u522b\u8054\u60f3\u7b49\uff0c\u8fd9\u4e9b\u7279\u5f81\u5bf9\u4eba\u7c7b\u7684\u8bed\u8a00\u611f\u77e5\u548c\u4f53\u9a8c\u81f3\u5173\u91cd\u8981\u3002\u76ee\u524d\u5fc3\u7406\u8bed\u8a00\u5b66\u901a\u8fc7\u5927\u89c4\u6a21\u4eba\u7c7b\u5b9e\u9a8c\u83b7\u5f97\u4e86\u5927\u91cf\u8bcd\u6c47\u5728\u4eba\u7c7b\u611f\u77e5\u4e0b\u7684\u8bc4\u5206\u6570\u636e\uff0c\u8fd9\u4e3a\u5229\u7528\u8fd9\u4e9b\u6570\u636e\u8bc4\u4f30LLMs\u4e0e\u4eba\u7c7b\u611f\u77e5\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u63d0\u4f9b\u4e86\u5951\u673a\u3002", "method": "\u672c\u6587\u9009\u53d6\u4ee3\u8868\u6027\u7684\u591a\u79cdLLM\u6a21\u578b\uff0c\u5229\u7528\u5fc3\u7406\u8bed\u8a00\u5b66\u4e2d\u7684Glasgow\u548cLancaster\u8bcd\u6c47\u89c4\u8303\u6570\u636e\u5e93\uff0c\u5bf9\u6a21\u578b\u5728\u5341\u4e09\u9879\u8bed\u8a00\u7279\u5f81\u4e0a\u4e0e\u4eba\u7c7b\u8bc4\u5206\u7684\u4e00\u81f4\u6027\u8fdb\u884c\u8bc4\u4f30\u3002\u901a\u8fc7\u4e0e\u4e0d\u540c\u7c7b\u578b\u3001\u4e0d\u540c\u611f\u5b98\u7279\u5f81\u8bcd\u6c47\u7684\u4eba\u7c7b\u8bc4\u5206\u6570\u636e\u6bd4\u5bf9\uff0c\u7cfb\u7edf\u5206\u6790LLMs\u5bf9\u8fd9\u4e9b\u7279\u6027\u7684\u5bf9\u9f50\u80fd\u529b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cLLMs\u5728Glasgow\u89c4\u8303\u6570\u636e\u5e93\uff08\u5982\u6fc0\u52b1\u6027\u3001\u6548\u4ef7\u3001\u4e3b\u5bfc\u6027\u3001\u5177\u4f53\u6027\u3001\u53ef\u60f3\u8c61\u6027\u3001\u719f\u6089\u5ea6\u548c\u6027\u522b\uff09\u4e0a\u7684\u5bf9\u9f50\u8868\u73b0\u666e\u904d\u4f18\u4e8eLancaster\u89c4\u8303\u6570\u636e\u5e93\uff08\u5982\u5185\u611f\u53d7\u3001\u5473\u89c9\u3001\u55c5\u89c9\u3001\u89e6\u89c9\u3001\u542c\u89c9\u548c\u89c6\u89c9\uff09\u7684\u5bf9\u9f50\u3002\u8fd9\u663e\u793a\u5f53\u524dLLMs\u5728\u4e0e\u4eba\u7c7b\u8fdb\u884c\u57fa\u4e8e\u611f\u5b98\u7684\u8bed\u8a00\u7279\u6027\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u6f5c\u5728\u5c40\u9650\uff0c\u5c24\u5176\u662f\u5728\u7f3a\u5c11\u4f53\u73b0\u2018\u5177\u8eab\u8ba4\u77e5\u2019\u7684\u60c5\u51b5\u4e0b\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u67d0\u4e9b\u8bed\u8a00\u5fc3\u7406\u7279\u6027\u4e0a\u4e0e\u4eba\u7c7b\u611f\u77e5\u4e00\u81f4\u6027\u8f83\u9ad8\uff0c\u4f46\u5728\u6d89\u53ca\u4eba\u7c7b\u611f\u5b98\u5173\u8054\u7684\u8bed\u8a00\u7279\u6027\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\u3002\u8fd9\u4e00\u70b9\u53ef\u80fd\u6e90\u4e8e\u73b0\u6709\u6a21\u578b\u7f3a\u4e4f\u5177\u8eab\u8ba4\u77e5\u80fd\u529b\u3002\u5fc3\u7406\u8bed\u8a00\u5b66\u6570\u636e\u96c6\u5728LLMs\u8bc4\u4f30\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u80fd\u591f\u63ed\u793a\u6a21\u578b\u7684\u6df1\u5c42\u5c40\u9650\u6027\u3002"}}
{"id": "2506.22828", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2506.22828", "abs": "https://arxiv.org/abs/2506.22828", "authors": ["Go Hashimoto", "Daniel G\u0103in\u0103"], "title": "Model-theoretic Forcing in Transition Algebra", "comment": null, "summary": "We study L\\\"owenheim-Skolem and Omitting Types theorems in Transition\nAlgebra, a logical system obtained by enhancing many sorted first-order logic\nwith features from dynamic logic. The sentences we consider include\ncompositions, unions, and transitive closures of transition relations, which\nare treated similarly to actions in dynamic logics to define necessity and\npossibility operators. We show that Upward L\\\"owenheim-Skolem theorem, any form\nof compactness, and joint Robinson consistency property fail due to the\nexpressivity of transitive closures of transitions. In this non-compact\nmany-sorted logical system, we develop a forcing technique method by\ngeneralizing the classical method of forcing used by Keisler to prove Omitting\nTypes theorem. Instead of working within a single signature, we work with a\ndirected diagram of signatures, which allows us to establish Downward\nL\\\"owenheim-Skolem and Omitting Types theorems despite the fact that models\ninterpret sorts as sets, possibly empty. Building on a complete system of proof\nrules for Transition Algebra, we extend it with additional proof rules to\nreason about constructor-based and/or finite transition algebras. We then\nestablish the completeness of this extended system for a fragment of Transition\nAlgebra obtained by restricting models to constructor-based and/or finite\ntransition algebras.", "AI": {"tldr": "\u5bf9Transition Algebra\uff08\u52a8\u6001\u903b\u8f91+\u591a\u7c7b\u578b\u4e00\u9636\u903b\u8f91\uff09\u7814\u7a76\u53d1\u73b0\uff1a\u56e0\u4f20\u9012\u95ed\u5305\u7684\u5f3a\u8868\u8fbe\u6027\uff0c\u90e8\u5206\u7ecf\u5178\u6a21\u578b\u8bba\u5b9a\u7406\uff08\u5982\u5411\u4e0aLowenheim-Skolem\u3001\u7d27\u81f4\u6027\u7b49\uff09\u4e0d\u518d\u6210\u7acb\u3002\u4f5c\u8005\u901a\u8fc7\u63a8\u5e7fforcing\u6280\u672f\u5f15\u5165\u65b0\u65b9\u6cd5\uff0c\u5e76\u53d1\u5c55\u51fa\u9002\u7528\u4e8e\u6709\u9650\u6216\u6784\u9020\u578b\u8f6c\u79fb\u4ee3\u6570\u7684\u5b8c\u5168\u6027\u8bc1\u660e\uff0c\u4e3a\u76f8\u5173\u903b\u8f91\u7cfb\u7edf\u5206\u6790\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u65b0\u65b9\u6cd5\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u7814\u7a76Transition Algebra\uff08\u4e00\u79cd\u7ed3\u5408\u591a\u7c7b\u578b\u4e00\u9636\u903b\u8f91\u4e0e\u52a8\u6001\u903b\u8f91\u7279\u6027\u7684\u65b0\u903b\u8f91\u7cfb\u7edf\uff09\u4e2d\u7684Lowenheim-Skolem\u5b9a\u7406\u548c\u7565\u7c7b\u578b\u5b9a\u7406\uff0c\u63a2\u7d22\u5176\u5728\u5f15\u5165\u8f6c\u79fb\u5173\u7cfb\uff08\u5305\u62ec\u5e76\u3001\u590d\u5408\u3001\u4f20\u9012\u95ed\u5305\u7b49\u52a8\u6001\u903b\u8f91\u64cd\u4f5c\u7b26\uff09\u4e0b\u7684\u8868\u73b0\u548c\u6781\u9650\u3002", "method": "\u4f5c\u8005\u5206\u6790\u4e86Transition Algebra\u4e2d\u6a21\u578b\u8bba\u7279\u6027\u7684\u5931\u6548\uff08\u5982\u5411\u4e0aLowenheim-Skolem\u5b9a\u7406\u3001\u7d27\u81f4\u6027\u3001\u8054\u5408Robinson\u4e00\u81f4\u6027\uff09\uff0c\u5e76\u53d1\u5c55\u4e86\u4e00\u79cd\u63a8\u5e7f\u81eaKeisler forcing\u6280\u672f\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u5e26\u6709\u5b9a\u5411\u56fe\u7684\u7b7e\u540d\u4f53\u7cfb\uff0c\u4ee5\u9002\u5e94\u591a\u7c7b\u578b\u548c\u4f20\u9012\u95ed\u5305\u60c5\u5f62\uff1b\u6b64\u5916\uff0c\u6269\u5c55\u5e76\u5b8c\u5584\u4e86Transition Algebra\u7684\u8bc1\u660e\u7cfb\u7edf\uff0c\u4ee5\u652f\u6301\u6784\u9020\u578b\u4e0e\u6709\u9650\u8f6c\u79fb\u4ee3\u6570\u7247\u6bb5\u7684\u5b8c\u5168\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u5728Transition Algebra\u4e2d\u4f20\u7edf\u7684\u5411\u4e0aLowenheim-Skolem\u5b9a\u7406\u3001\u4efb\u610f\u7d27\u81f4\u6027\u4e0e\u8054\u5408\u4e00\u81f4\u6027\u6027\u8d28\u4f1a\u56e0\u4f20\u9012\u95ed\u5305\u7684\u8868\u8fbe\u6027\u800c\u5931\u6548\uff1b\u540c\u65f6\uff0c\u501f\u52a9\u65b0\u7684generalized forcing\u6280\u672f\uff0c\u5f97\u4ee5\u8bc1\u660e\u4e0b\u884cLowenheim-Skolem\u548c\u7565\u7c7b\u578b\u5b9a\u7406\u5728\u8be5\u7cfb\u7edf\u4ecd\u6210\u7acb\uff0c\u4e14\u4e3a\u6784\u9020\u578b/\u6709\u9650\u8f6c\u79fb\u4ee3\u6570\u7247\u6bb5\u5efa\u7acb\u4e86\u5b8c\u5168\u6027\u7ed3\u679c\u3002", "conclusion": "Transition Algebra\u5728\u52a8\u6001\u903b\u8f91\u64cd\u4f5c\u7684\u80cc\u666f\u4e0b\uff0c\u5448\u73b0\u51fa\u4e0e\u4f20\u7edf\u4e00\u9636\u903b\u8f91\u660e\u663e\u4e0d\u540c\u7684\u6a21\u578b\u8bba\u884c\u4e3a\uff0c\u90e8\u5206\u6838\u5fc3\u5b9a\u7406\u5931\u6548\uff0c\u4f46\u53ef\u51ed\u501f\u65b0\u7684\u6280\u672f\u6062\u590d\u90e8\u5206\u91cd\u8981\u5143\u6027\u8d28\uff0c\u4e3a\u591a\u7c7b\u578b\u53ca\u52a8\u6001\u7cfb\u7edf\u7684\u903b\u8f91\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2506.23578", "categories": ["cs.FL", "cs.CL"], "pdf": "https://arxiv.org/pdf/2506.23578", "abs": "https://arxiv.org/abs/2506.23578", "authors": ["\u0141ukasz Kami\u0144ski", "S\u0142awomir Lasota"], "title": "Reachability in symmetric VASS", "comment": null, "summary": "We investigate the reachability problem in symmetric vector addition systems\nwith states (VASS), where transitions are invariant under a group of\npermutations of coordinates. One extremal case, the trivial groups, yields\ngeneral VASS. In another extremal case, the symmetric groups, we show that the\nreachability problem can be solved in PSPACE, regardless of the dimension of\ninput VASS (to be contrasted with Ackermannian complexity in general VASS). We\nalso consider other groups, in particular alternating and cyclic ones.\nFurthermore, motivated by the open status of the reachability problem in data\nVASS, we estimate the gain in complexity when the group arises as a combination\nof the trivial and symmetric groups.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5728\u4e0d\u540c\u7fa4\u4f5c\u7528\u4e0b\u7684VASS\u53ef\u8fbe\u6027\u590d\u6742\u5ea6\uff0c\u7279\u522b\u53d1\u73b0\u5bf9\u79f0\u7fa4\u4e0b\u8be5\u95ee\u9898\u53ef\u5728PSPACE\u5185\u89e3\u51b3\uff0c\u663e\u8457\u4f18\u4e8e\u4e00\u822cVASS\uff0c\u5e76\u7814\u7a76\u4e86\u5e73\u51e1\u7fa4\u548c\u5bf9\u79f0\u7fa4\u7ec4\u5408\u65f6\u7684\u590d\u6742\u5ea6\u63d0\u5347\u3002", "motivation": "VASS\u7684\u53ef\u8fbe\u6027\u662f\u8ba1\u7b97\u7406\u8bba\u4e2d\u7684\u4e00\u4e2a\u6838\u5fc3\u4e14\u56f0\u96be\u95ee\u9898\u3002\u5bf9\u79f0\u7ed3\u6784\u4e0b\u80fd\u5426\u7b80\u5316\u590d\u6742\u5ea6\uff0c\u4ee5\u53ca\u5f53\u524d\u6570\u636eVASS\u76f8\u5173\u53ef\u8fbe\u6027\u95ee\u9898\u4ecd\u672a\u89e3\u51b3\uff0c\u4fc3\u4f7f\u4f5c\u8005\u63a2\u7d22\u4e0d\u540c\u7fa4\u4f5c\u7528\u4e0b\u7684\u590d\u6742\u5ea6\u53d8\u5316\u3002", "method": "\u5206\u6790VASS\u7cfb\u7edf\u5728\u4e0d\u540c\u7fa4\uff08\u7279\u522b\u662f\u5bf9\u79f0\u7fa4\u3001\u4ea4\u9519\u7fa4\u3001\u5faa\u73af\u7fa4\uff09\u4f5c\u7528\u4e0b\u7684\u53ef\u8fbe\u6027\uff0c\u5bf9\u6bd4\u590d\u6742\u5ea6\u3002\u5e76\u4f30\u7b97\u5f53\u7fa4\u662f\u5e73\u51e1\u7fa4\u4e0e\u5bf9\u79f0\u7fa4\u7ec4\u5408\u65f6\uff0c\u590d\u6742\u5ea6\u7684\u63d0\u9ad8\u3002", "result": "\u786e\u7acb\u4e86\u5bf9\u79f0\u7fa4\u4e0bVASS\u53ef\u8fbe\u6027\u5728PSPACE\u4e2d\u53ef\u89e3\uff0c\u5e76\u5bf9\u5176\u5b83\u7fa4\u8fdb\u884c\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u590d\u6742\u5ea6\u4f30\u7b97\uff0c\u5728\u7279\u5b9a\u7ec4\u5408\u60c5\u5f62\u4e0b\u83b7\u5f97\u590d\u6742\u5ea6\u63d0\u5347\u7684\u89c1\u89e3\u3002", "conclusion": "\u672c\u8bba\u6587\u53d1\u73b0\uff0c\u5728\u5bf9\u79f0\u7fa4\u4e0d\u53d8\u7684VASS\u4e2d\uff0c\u53ef\u8fbe\u6027\u95ee\u9898\u53ef\u5728PSPACE\u4e2d\u6c42\u89e3\uff0c\u65e0\u8bba\u7ef4\u5ea6\u5982\u4f55\uff0c\u800c\u4e00\u822cVASS\u7684\u590d\u6742\u5ea6\u8fdc\u9ad8\u4e8e\u6b64\u3002\u6b64\u5916\uff0c\u7814\u7a76\u4e86\u5176\u4ed6\u7fa4\u4f5c\u7528\u4e0b\u7684\u590d\u6742\u5ea6\u3002"}}
{"id": "2506.23943", "categories": ["cs.DM", "cs.CG"], "pdf": "https://arxiv.org/pdf/2506.23943", "abs": "https://arxiv.org/abs/2506.23943", "authors": ["Emilio Di Giacomo", "Walter Didimo", "Henry F\u00f6rster", "Torsten Ueckerdt", "Johannes Zink"], "title": "Linear Layouts of Graphs with Priority Queues", "comment": "Appears in Proc. 19th Algorithms and Data Structures Symposium (WADS\n  2025)", "summary": "A linear layout of a graph consists of a linear ordering of its vertices and\na partition of its edges into pages such that the edges assigned to the same\npage obey some constraint. The two most prominent and widely studied types of\nlinear layouts are stack and queue layouts, in which any two edges assigned to\nthe same page are forbidden to cross and nest, respectively. The names of these\ntwo layouts derive from the fact that, when parsing the graph according to the\nlinear vertex ordering, the edges in a single page can be stored using a single\nstack or queue, respectively. Recently, the concepts of stack and queue layouts\nhave been extended by using a double-ended queue or a restricted-input queue\nfor storing the edges of a page. We extend this line of study to edge-weighted\ngraphs by introducing priority queue layouts, that is, the edges on each page\nare stored in a priority queue whose keys are the edge weights. First, we show\nthat there are edge-weighted graphs that require a linear number of priority\nqueues. Second, we characterize the graphs that admit a priority queue layout\nwith a single queue, regardless of the edge-weight function, and we provide an\nefficient recognition algorithm. Third, we show that the number of priority\nqueues required independently of the edge-weight function is bounded by the\npathwidth of the graph, but can be arbitrarily large already for graphs of\ntreewidth two. Finally, we prove that determining the minimum number of\npriority queues is NP-complete if the linear ordering of the vertices is fixed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5e26\u6743\u56fe\u7684\u4f18\u5148\u7ea7\u961f\u5217\u5e03\u5c40\u65b0\u6a21\u578b\uff0c\u5206\u6790\u4e86\u76f8\u5173\u7406\u8bba\u754c\u9650\u3001\u5224\u522b\u7b97\u6cd5\u548c\u590d\u6742\u6027\uff0c\u4e3a\u56fe\u7ebf\u6027\u5e03\u5c40\u9886\u57df\u5e26\u6765\u65b0\u89c1\u89e3\u3002", "motivation": "\u4e3a\u4e86\u66f4\u597d\u5730\u5904\u7406\u5e26\u6743\u56fe\u7684\u7ebf\u6027\u5e03\u5c40\u95ee\u9898\uff0c\u4f5c\u8005\u5c06\u4f20\u7edf\u7684\u6808\uff08stack\uff09\u548c\u961f\u5217\uff08queue\uff09\u5e03\u5c40\u6269\u5c55\u5230\u6709\u4f18\u5148\u7ea7\u7684\u961f\u5217\uff08priority queue\uff09\u5e03\u5c40\uff0c\u76ee\u7684\u662f\u7814\u7a76\u5e26\u6743\u8fb9\u5728\u56fe\u7684\u7ebf\u6027\u6392\u5217\u4e0b\u80fd\u9ad8\u6548\u5b58\u50a8\u548c\u7ba1\u7406\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u5f15\u5165\u4e86\u4f18\u5148\u7ea7\u961f\u5217\u5e03\u5c40\u7684\u6982\u5ff5\uff0c\u5e76\u5728\u7406\u8bba\u4e0a\u5206\u6790\u4e86\u4e0d\u540c\u7c7b\u578b\u56fe\u5bf9\u4e8e\u4f18\u5148\u7ea7\u961f\u5217\u6570\u76ee\u7684\u9700\u6c42\uff0c\u63d0\u51fa\u4e86\u7528\u4e8e\u8bc6\u522b\u54ea\u4e9b\u56fe\u53ef\u4ee5\u7528\u5355\u4e2a\u4f18\u5148\u7ea7\u961f\u5217\u5e03\u5c40\u7684\u9ad8\u6548\u7b97\u6cd5\uff0c\u4ee5\u53ca\u9488\u5bf9\u5b9a\u5e8f\u9876\u70b9\u65f6\u5224\u5b9a\u4f18\u5148\u7ea7\u961f\u5217\u6570\u76ee\u7684\u590d\u6742\u6027\u3002", "result": "1. \u6709\u4e9b\u5e26\u6743\u56fe\u9700\u8981\u7ebf\u6027\u6570\u91cf\u7684\u4f18\u5148\u7ea7\u961f\u5217\u30022. \u7ed9\u51fa\u4e86\u80fd\u7528\u5355\u4e2a\u4f18\u5148\u7ea7\u961f\u5217\u5e03\u5c40\u7684\u56fe\u7684\u523b\u753b\uff0c\u5e76\u63d0\u4f9b\u4e86\u9ad8\u6548\u5224\u522b\u7b97\u6cd5\u30023. \u72ec\u7acb\u4e8e\u8fb9\u6743\u65f6\uff0c\u6240\u9700\u4f18\u5148\u7ea7\u961f\u5217\u7684\u6570\u91cf\u7531\u56fe\u7684\u8def\u5f84\u5bbd\u5ea6\u4e0a\u754c\uff0c\u4f46\u5bf9\u6811\u5bbd\u4e3a2\u7684\u56fe\u4e5f\u53ef\u80fd\u975e\u5e38\u5927\u30024. \u5f53\u9876\u70b9\u987a\u5e8f\u56fa\u5b9a\u65f6\uff0c\u5224\u5b9a\u6700\u5c0f\u6240\u9700\u4f18\u5148\u7ea7\u961f\u5217\u6570\u662fNP\u5b8c\u5168\u7684\u3002", "conclusion": "\u672c\u6587\u6269\u5c55\u4e86\u56fe\u5e03\u5c40\u7406\u8bba\uff0c\u9996\u6b21\u5c06\u4f18\u5148\u7ea7\u961f\u5217\u5f15\u5165\u5e26\u6743\u56fe\u7684\u7ebf\u6027\u5e03\u5c40\uff0c\u63ed\u793a\u4e86\u5176\u7ed3\u6784\u590d\u6742\u6027\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u8bc6\u522b\u7b97\u6cd5\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u76f8\u5173\u4f18\u5316\u51b3\u7b56\u95ee\u9898\u7684\u8ba1\u7b97\u96be\u5ea6\u3002"}}
{"id": "2506.22688", "categories": ["cs.SE", "D.2.11; D.2.2"], "pdf": "https://arxiv.org/pdf/2506.22688", "abs": "https://arxiv.org/abs/2506.22688", "authors": ["Humberto Cervantes", "Rick Kazman", "Yuanfang Cai"], "title": "An LLM-assisted approach to designing software architectures using ADD", "comment": "30 pages, 12 figures, 7 tables", "summary": "Designing effective software architectures is a complex, iterative process\nthat traditionally relies on expert judgment. This paper proposes an approach\nfor Large Language Model (LLM)-assisted software architecture design using the\nAttribute-Driven Design (ADD) method. By providing an LLM with an explicit\ndescription of ADD, an architect persona, and a structured iteration plan, our\nmethod guides the LLM to collaboratively produce architecture artifacts with a\nhuman architect. We validate the approach through case studies, comparing\ngenerated designs against proven solutions and evaluating them with\nprofessional architects. Results show that our LLM-assisted ADD process can\ngenerate architectures closely aligned with established solutions and partially\nsatisfying architectural drivers, highlighting both the promise and current\nlimitations of using LLMs in architecture design. Our findings emphasize the\nimportance of human oversight and iterative refinement when leveraging LLMs in\nthis domain.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7ed3\u5408ADD\u65b9\u6cd5\u8f85\u52a9\u8f6f\u4ef6\u67b6\u6784\u8bbe\u8ba1\uff0c\u7ecf\u6848\u4f8b\u9a8c\u8bc1\u6548\u679c\u8f83\u4f73\uff0c\u4f46\u9700\u4eba\u7c7b\u67b6\u6784\u5e08\u76d1\u7763\u4e0e\u8fed\u4ee3\u4f18\u5316\u3002", "motivation": "\u8f6f\u4ef6\u67b6\u6784\u8bbe\u8ba1\u901a\u5e38\u4f9d\u9760\u4e13\u5bb6\u7ecf\u9a8c\uff0c\u8fc7\u7a0b\u590d\u6742\u4e14\u9700\u8981\u591a\u6b21\u8fed\u4ee3\uff0c\u5982\u4f55\u7528LLM\u8f85\u52a9\u63d0\u9ad8\u8bbe\u8ba1\u6548\u7387\u4e0e\u8d28\u91cf\u6210\u4e3a\u503c\u5f97\u63a2\u8ba8\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408Attribute-Driven Design (ADD) \u65b9\u6cd5\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8f85\u52a9\u8f6f\u4ef6\u67b6\u6784\u8bbe\u8ba1\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5411LLM\u660e\u786e\u63cf\u8ff0ADD\u6d41\u7a0b\u3001\u8bbe\u5b9a\u67b6\u6784\u5e08\u89d2\u8272\u548c\u6709\u7ed3\u6784\u7684\u8fed\u4ee3\u8ba1\u5212\uff0c\u4f7fLLM\u4e0e\u4eba\u7c7b\u67b6\u6784\u5e08\u534f\u4f5c\u4ea7\u51fa\u67b6\u6784\u6210\u679c\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\uff0c\u6bd4\u8f83LLM\u8f85\u52a9\u8bbe\u8ba1\u4e0e\u6210\u719f\u65b9\u6848\uff0c\u5e76\u7531\u4e13\u4e1a\u67b6\u6784\u5e08\u8bc4\u4f30\u3002\u7ed3\u679c\u663e\u793aLLM-\u8f85\u52a9\u65b9\u6cd5\u751f\u6210\u7684\u67b6\u6784\u4e0e\u73b0\u6709\u6210\u719f\u65b9\u6848\u9ad8\u5ea6\u4e00\u81f4\uff0c\u80fd\u591f\u90e8\u5206\u6ee1\u8db3\u67b6\u6784\u9a71\u52a8\u76ee\u6807\u3002", "conclusion": "LLM\u8f85\u52a9\u8f6f\u4ef6\u67b6\u6784\u8bbe\u8ba1\u5177\u6709\u524d\u666f\uff0c\u4f46\u5f53\u524d\u4f9d\u7136\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4e14\u5f3a\u8c03\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u4eba\u7c7b\u76d1\u7763\u4e0e\u53cd\u590d\u4f18\u5316\u3002"}}
{"id": "2506.23320", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2506.23320", "abs": "https://arxiv.org/abs/2506.23320", "authors": ["Nicola Assolini", "Alessandra Di Pierro"], "title": "A Denotational Semantics for Quantum Loops", "comment": "17 pages", "summary": "Programming a quantum computer, i.e., implementing quantum algorithms on a\nquantum processor-based copmputer architecture, is a task that can be addressed\n(just as for classical computers) at different levels of abstraction. This\npaper proposes a denotational semantics for high-level quantum programming\nconstructs, focusing on the conceptual meaning of quantum-controlled branching\nand iteration. We introduce a denotational domain where a mathematical meaning\nof a quantum control flow with loops can be defined, which reflects the\ncoherent evolution of the quantum system implementing the program.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u91cf\u5b50\u7a0b\u5e8f\u9ad8\u5c42\u7ed3\u6784\u5982\u5206\u652f\u4e0e\u5faa\u73af\u7684\u6307\u79f0\u8bed\u4e49\u6a21\u578b\uff0c\u586b\u8865\u4e86\u5f53\u524d\u9ad8\u5c42\u91cf\u5b50\u7f16\u7a0b\u8bed\u4e49\u7684\u7a7a\u767d\uff0c\u4e3a\u91cf\u5b50\u8f6f\u4ef6\u9886\u57df\u7684\u7814\u7a76\u548c\u5f00\u53d1\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "\u5f53\u524d\u91cf\u5b50\u8ba1\u7b97\u673a\u7684\u7f16\u7a0b\u4e0e\u7ecf\u5178\u8ba1\u7b97\u673a\u4e0d\u540c\uff0c\u7f3a\u4e4f\u9ad8\u5c42\u6b21\u62bd\u8c61\u8bed\u4e49\uff0c\u5c24\u5176\u5728\u91cf\u5b50\u53d7\u63a7\u5206\u652f\u548c\u8fed\u4ee3\u7ed3\u6784\u4e0a\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u5c42\u6b21\u91cf\u5b50\u7f16\u7a0b\u6784\u9020\u7684\u6307\u79f0\u8bed\u4e49\uff0c\u5e76\u9488\u5bf9\u91cf\u5b50\u53d7\u63a7\u5206\u652f\u4e0e\u8fed\u4ee3\u8fdb\u884c\u4e86\u8be6\u7ec6\u5206\u6790\uff0c\u8bbe\u8ba1\u4e86\u65b0\u7684\u6570\u5b66\u6307\u79f0\u57df\u6765\u523b\u753b\u91cf\u5b50\u7a0b\u5e8f\u4e2d\u63a7\u5236\u6d41\u7684\u672c\u8d28\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u53ef\u53cd\u6620\u91cf\u5b50\u7cfb\u7edf\u76f8\u5e72\u6f14\u5316\u7684\u91cf\u5b50\u63a7\u5236\u6d41\u7a0b\uff08\u5305\u62ec\u5faa\u73af\uff09\u7684\u6307\u79f0\u8bed\u4e49\u6846\u67b6\uff0c\u4e3a\u9ad8\u5c42\u91cf\u5b50\u7a0b\u5e8f\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u91cf\u5b50\u7f16\u7a0b\u7684\u9ad8\u5c42\u63a7\u5236\u7ed3\u6784\uff08\u5982\u5206\u652f\u4e0e\u5faa\u73af\uff09\u63d0\u4f9b\u4e86\u4e25\u8c28\u7684\u8bed\u4e49\u652f\u6491\uff0c\u6709\u52a9\u4e8e\u540e\u7eed\u91cf\u5b50\u8f6f\u4ef6\u5f00\u53d1\u548c\u7406\u8bba\u5206\u6790\u3002"}}
{"id": "2506.22485", "categories": ["cs.CL", "cs.AI", "68T07, 68T50", "I.2.1; I.2.3; I.2.7; H.3.3"], "pdf": "https://arxiv.org/pdf/2506.22485", "abs": "https://arxiv.org/abs/2506.22485", "authors": ["Sudip Dasgupta", "Himanshu Shankar"], "title": "AI Agents-as-Judge: Automated Assessment of Accuracy, Consistency, Completeness and Clarity for Enterprise Documents", "comment": "17 pages, 2 system diagrams, 1 table, no prior conference publication", "summary": "This study presents a modular, multi-agent system for the automated review of\nhighly structured enterprise business documents using AI agents. Unlike prior\nsolutions focused on unstructured texts or limited compliance checks, this\nframework leverages modern orchestration tools such as LangChain, CrewAI,\nTruLens, and Guidance to enable section-by-section evaluation of documents for\naccuracy, consistency, completeness, and clarity. Specialized agents, each\nresponsible for discrete review criteria such as template compliance or factual\ncorrectness, operate in parallel or sequence as required. Evaluation outputs\nare enforced to a standardized, machine-readable schema, supporting downstream\nanalytics and auditability. Continuous monitoring and a feedback loop with\nhuman reviewers allow for iterative system improvement and bias mitigation.\n  Quantitative evaluation demonstrates that the AI Agent-as-Judge system\napproaches or exceeds human performance in key areas: achieving 99% information\nconsistency (vs. 92% for humans), halving error and bias rates, and reducing\naverage review time from 30 to 2.5 minutes per document, with a 95% agreement\nrate between AI and expert human judgment. While promising for a wide range of\nindustries, the study also discusses current limitations, including the need\nfor human oversight in highly specialized domains and the operational cost of\nlarge-scale LLM usage. The proposed system serves as a flexible, auditable, and\nscalable foundation for AI-driven document quality assurance in the enterprise\ncontext.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u7528\u4e8e\u4f01\u4e1a\u7ed3\u6784\u5316\u6587\u6863\u5ba1\u6838\uff0c\u663e\u8457\u63d0\u5347\u4e00\u81f4\u6027\u3001\u6548\u7387\u5e76\u964d\u4f4e\u504f\u5dee\uff0c\u5177\u5907\u5e7f\u6cdb\u884c\u4e1a\u5e94\u7528\u6f5c\u529b\uff0c\u4f46\u5728\u4e13\u4e1a\u7ec6\u5206\u9886\u57df\u4e0e\u6210\u672c\u65b9\u9762\u4ecd\u6709\u6311\u6218\u3002", "motivation": "\u5f53\u524d\u4f01\u4e1a\u4e2d\u5bf9\u4e8e\u9ad8\u5ea6\u7ed3\u6784\u5316\u5546\u4e1a\u6587\u6863\u7684\u81ea\u52a8\u5316\u5ba1\u6838\u4e3b\u8981\u96c6\u4e2d\u5728\u975e\u7ed3\u6784\u5316\u6587\u672c\u6216\u6709\u9650\u7684\u5408\u89c4\u6821\u9a8c\uff0c\u7f3a\u4e4f\u9488\u5bf9\u7ec6\u81f4\u5ba1\u6838\u6807\u51c6\u7684\u7cfb\u7edf\u5316\u3001\u667a\u80fd\u5316\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u57fa\u4e8e\u73b0\u4ee3AI\u7f16\u6392\u5de5\u5177\uff08\u5982LangChain\u3001CrewAI\u3001TruLens\u3001Guidance\uff09\uff0c\u7531\u591a\u4e2a\u4e13\u95e8\u7684AI\u4ee3\u7406\u5206\u522b\u8d1f\u8d23\u4e0d\u540c\u5ba1\u6838\u6807\u51c6\uff08\u5982\u6a21\u677f\u5408\u89c4\u3001\u4e8b\u5b9e\u51c6\u786e\u6027\u7b49\uff09\uff0c\u53ef\u5e76\u884c\u6216\u987a\u5e8f\u6267\u884c\uff0c\u5e76\u5c06\u8f93\u51fa\u6807\u51c6\u5316\u4e3a\u53ef\u673a\u8bfb\u7684\u7ed3\u6784\u5316\u7ed3\u679c\uff1b\u7cfb\u7edf\u542b\u6709\u4e0e\u4eba\u5de5\u7684\u53cd\u9988\u5faa\u73af\uff0c\u5b9e\u73b0\u6301\u7eed\u4f18\u5316\u4e0e\u504f\u5dee\u63a7\u5236\u3002", "result": "\u7cfb\u7edf\u5728\u4fe1\u606f\u4e00\u81f4\u6027\u4e0a\u8fbe\u523099%\uff08\u4eba\u5de5\u4e3a92%\uff09\uff0c\u9519\u8bef\u4e0e\u504f\u5dee\u7387\u51cf\u534a\uff0c\u5355\u6587\u6863\u5e73\u5747\u5ba1\u6838\u65f6\u95f4\u753130\u5206\u949f\u964d\u81f32.5\u5206\u949f\uff0cAI\u4e0e\u4e13\u5bb6\u7684\u5224\u5b9a\u4e00\u81f4\u7387\u8fbe95%\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u4f01\u4e1a\u7ea7\u6587\u6863\u8d28\u91cf\u4fdd\u8bc1\u63d0\u4f9b\u4e86\u7075\u6d3b\u3001\u53ef\u8ffd\u6eaf\u3001\u5177\u6269\u5c55\u6027\u7684AI\u57fa\u7840\uff0c\u4f46\u5728\u9ad8\u5ea6\u4e13\u4e1a\u9886\u57df\u4ecd\u9700\u4eba\u5de5\u76d1\u7763\uff0c\u4e14\u5927\u89c4\u6a21\u90e8\u7f72\u5b58\u5728\u7b97\u529b\u6210\u672c\u3002"}}
{"id": "2506.23730", "categories": ["cs.LO", "cs.SC"], "pdf": "https://arxiv.org/pdf/2506.23730", "abs": "https://arxiv.org/abs/2506.23730", "authors": ["Alessio Mansutti", "Mikhail R. Starchak"], "title": "One-Parametric Presburger Arithmetic has Quantifier Elimination", "comment": "Extended version of a MFCS 2025 paper", "summary": "We give a quantifier elimination procedure for one-parametric Presburger\narithmetic, the extension of Presburger arithmetic with the function $x \\mapsto\nt \\cdot x$, where $t$ is a fixed free variable ranging over the integers. This\nresolves an open problem proposed in [Bogart et al., Discrete Analysis, 2017].\nAs conjectured in [Goodrick, Arch. Math. Logic, 2018], quantifier elimination\nis obtained for the extended structure featuring all integer division functions\n$x \\mapsto \\lfloor{\\frac{x}{f(t)}}\\rfloor$, one for each integer polynomial\n$f$.\n  Our algorithm works by iteratively eliminating blocks of existential\nquantifiers. The elimination of a block builds on two sub-procedures, both\nrunning in non-deterministic polynomial time. The first one is an adaptation of\na recently developed and efficient quantifier elimination procedure for\nPresburger arithmetic, modified to handle formulae with coefficients over the\nring $\\mathbb{Z}[t]$ of univariate polynomials. The second is reminiscent of\nthe so-called \"base $t$ division method\" used by Bogart et al. As a result, we\ndeduce that the satisfiability problem for the existential fragment of\none-parametric Presburger arithmetic (which encompasses a broad class of\nnon-linear integer programs) is in NP, and that the smallest solution to a\nsatisfiable formula in this fragment is of polynomial bit size.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u5bf9\u4e00\u53c2\u53c2\u6570 Presburger \u7b97\u672f\uff08\u5e26\u4e58\u6cd5\u548c\u5206\u90e8\u51fd\u6570\u6269\u5c55\uff09\u8fdb\u884c\u91cf\u8bcd\u6d88\u53bb\u7684\u6709\u6548\u7b97\u6cd5\uff0c\u8bc1\u660e\u53c2\u4e0e\u7247\u6bb5\u7684\u5224\u5b9a\u95ee\u9898\u5728 NP \u4e14\u6709\u591a\u9879\u5f0f\u89c4\u6a21\u7684\u89e3\u3002\u8be5\u5de5\u4f5c\u89e3\u51b3\u4e86\u76f8\u5173\u5f00\u653e\u95ee\u9898\uff0c\u5e76\u6269\u5c55\u4e86\u6574\u6570\u89c4\u5212\u548c\u6570\u7406\u903b\u8f91\u9886\u57df\u7684\u5173\u952e\u5de5\u5177\u3002", "motivation": "Presburger \u7b97\u672f\u53ca\u5176\u6269\u5c55\u5f62\u5f0f\u5728\u6570\u7406\u903b\u8f91\u548c\u6574\u6570\u89c4\u5212\u7b49\u9886\u57df\u5177\u6709\u91cd\u8981\u7406\u8bba\u4ef7\u503c\u548c\u5e94\u7528\u524d\u666f\uff0c\u4f46\u542b\u6709\u53c2\u6570\u7684 Presburger \u7b97\u672f\u662f\u5426\u53ef\u4ee5\u5b9e\u73b0\u91cf\u8bcd\u6d88\u53bb\u4e00\u76f4\u662f\u5f00\u653e\u95ee\u9898\uff0c\u7279\u522b\u662f\u6d89\u53ca\u4e00\u4e2a\u56fa\u5b9a\u81ea\u7531\u53c2\u6570\uff08\u5982\u6574\u6570\u53d8\u91cf t\uff09\u65f6\u3002\u6b64\u524d\u6709\u7814\u7a76\u63d0\u51fa\u6b64\u4f5c\u4e3a\u5f85\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u9996\u6b21\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u4e00\u53c2\u53c2\u6570 Presburger \u7b97\u672f\u8fdb\u884c\u91cf\u8bcd\u6d88\u53bb\u7684\u7b97\u6cd5\uff0c\u80fd\u591f\u5904\u7406\u6240\u6709\u5e26\u6709\u6574\u6570\u591a\u9879\u5f0f\u5206\u90e8\u51fd\u6570\u7684\u6269\u5c55\u7ed3\u6784\u3002\u8be5\u7b97\u6cd5\u8fed\u4ee3\u5730\u6d88\u53bb\u5b58\u5728\u91cf\u8bcd\u5757\uff0c\u5206\u4e3a\u4e24\u4e2a\u4e3b\u8981\u6b65\u9aa4\uff1a\u4e00\u662f\u5bf9\u73b0\u6709\u9ad8\u6548\u91cf\u8bcd\u6d88\u53bb\u65b9\u6cd5\u8fdb\u884c\u6539\u9020\u4ee5\u9002\u5e94 \u007f\u2124[t] \u7cfb\u6570\u516c\u5f0f\uff0c\u4e8c\u662f\u5f15\u5165\u7c7b\u4f3c Bogart \u7b49\u4eba\u201c\u57fa\u4e8e t \u7684\u9664\u6cd5\u6cd5\u201d\uff0c\u6bcf\u4e00\u6b65\u5747\u53ef\u5728\u975e\u786e\u5b9a\u6027\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u5b8c\u6210\u3002", "result": "\u5b9e\u73b0\u4e86\u5bf9\u5e26\u6709\u5206\u90e8\u51fd\u6570\u7684\u9ad8\u7ea7\u4e00\u53c2\u53c2\u6570 Presburger \u7b97\u672f\u516c\u5f0f\u7684\u91cf\u8bcd\u6d88\u53bb\uff0c\u8bc1\u660e\u4e86\u5176\u5b58\u5728\u6ee1\u8db3\u516c\u5f0f\u7684\u89e3\u7684\u5224\u5b9a\u95ee\u9898\u5c5e\u4e8e NP \u4e14\u6700\u5c0f\u89e3\u7684\u6bd4\u7279\u957f\u5ea6\u4e3a\u591a\u9879\u5f0f\u7ea7\u522b\u3002", "conclusion": "\u672c\u6587\u89e3\u51b3\u4e86\u539f\u672c\u5f00\u653e\u7684\u4e00\u53c2\u53c2\u6570 Presburger \u7b97\u672f\u7684\u91cf\u8bcd\u6d88\u53bb\u95ee\u9898\uff0c\u800c\u4e14\u4e3a\u66f4\u5e7f\u6cdb\u7684\u975e\u7ebf\u6027\u6574\u6570\u89c4\u5212\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5c06\u5b58\u5728\u7247\u6bb5\u7684\u53ef\u6ee1\u8db3\u6027\u5f52\u5165 NP \u7c7b\u522b\uff0c\u6269\u5c55\u4e86\u76f8\u5173\u6570\u5b66\u903b\u8f91\u5de5\u5177\u7684\u9002\u7528\u8303\u56f4\u3002"}}
{"id": "2506.22703", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22703", "abs": "https://arxiv.org/abs/2506.22703", "authors": ["Wali Mohammad Abdullah", "Azmain Kabir"], "title": "P4OMP: Retrieval-Augmented Prompting for OpenMP Parallelism in Serial Code", "comment": null, "summary": "We present P4OMP, a retrieval-augmented framework for transforming serial\nC/C++ code into OpenMP-annotated parallel code using large language models\n(LLMs). To our knowledge, this is the first system to apply retrieval-based\nprompting for OpenMP pragma correctness without model fine-tuning or compiler\ninstrumentation. P4OMP leverages Retrieval-Augmented Generation (RAG) with\nstructured instructional knowledge from OpenMP tutorials to improve the\nreliability of prompt-driven code generation. By grounding generation in the\nretrieved context, P4OMP improves syntactic correctness compared to baseline\nprompting with GPT-3.5-Turbo. We evaluate P4OMP against a baseline,\nGPT-3.5-Turbo without retrieval, on a comprehensive benchmark of 108 real-world\nC++ programs drawn from Stack Overflow, PolyBench, and NAS benchmark suites.\nP4OMP achieves 100% compilation success on all parallelizable cases, while the\nbaseline fails to compile in 20 out of 108 cases. Six cases that rely on\nnon-random-access iterators or thread-unsafe constructs are excluded due to\nfundamental OpenMP limitations. A detailed analysis demonstrates how P4OMP\nconsistently avoids scoping errors, syntactic misuse, and invalid directive\ncombinations that commonly affect baseline-generated code. We further\ndemonstrate strong runtime scaling across seven compute-intensive benchmarks on\nan HPC cluster. P4OMP offers a robust, modular pipeline that significantly\nimproves the reliability and applicability of LLM-generated OpenMP code.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faP4OMP\u6846\u67b6\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u9ad8\u53ef\u9760\u6027\u7684C/C++\u5230OpenMP\u5e76\u884c\u4ee3\u7801\u81ea\u52a8\u8f6c\u6362\u3002\u76f8\u8f83\u4e8e\u4f20\u7edfLLM\u65b9\u6848\uff0cP4OMP\u663e\u8457\u63d0\u5347\u4e86\u7f16\u8bd1\u6210\u529f\u7387\uff0c\u51cf\u5c11\u4e86\u5e38\u89c1\u7684\u5e76\u884c\u7f16\u7a0b\u9519\u8bef\uff0c\u5728\u591a\u9879\u771f\u5b9e\u548c\u9ad8\u6027\u80fd\u8ba1\u7b97\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u8bb8\u591a\u5f00\u53d1\u8005\u5e0c\u671b\u5c06\u4e32\u884cC/C++\u4ee3\u7801\u81ea\u52a8\u8f6c\u6362\u4e3a\u5e76\u884c\u7684OpenMP\u4ee3\u7801\uff0c\u4f46\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u53ef\u7f16\u8bd1\u6027\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u5bb9\u6613\u5f15\u5165\u8bed\u6cd5\u548c\u4f5c\u7528\u57df\u9519\u8bef\uff0c\u56e0\u6b64\u8feb\u5207\u9700\u8981\u4e00\u79cd\u66f4\u53ef\u9760\u7684\u65b9\u6cd5\u63d0\u5347\u81ea\u52a8\u5316\u5e76\u884c\u4ee3\u7801\u751f\u6210\u7684\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u4e86P4OMP\u6846\u67b6\uff0c\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\uff0c\u4eceOpenMP\u6559\u5b66\u8d44\u6e90\u4e2d\u68c0\u7d22\u7ed3\u6784\u5316\u77e5\u8bc6\uff0c\u8f85\u52a9LLM\uff08\u5982GPT-3.5-Turbo\uff09\u5bf9\u4e32\u884c\u4ee3\u7801\u8fdb\u884c\u8f6c\u6362\u751f\u6210\uff0c\u5e76\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u901a\u8fc7\u68c0\u7d22\u5230\u7684\u4e0a\u4e0b\u6587\u63d0\u5347OpenMP\u6307\u4ee4\u751f\u6210\u7684\u6b63\u786e\u6027\uff0c\u65e0\u9700\u6a21\u578b\u5fae\u8c03\u4ea6\u65e0\u9700\u7f16\u8bd1\u5668\u63d2\u6869\u3002", "result": "\u5728108\u4e2a\u771f\u5b9eC++\u7a0b\u5e8f\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cP4OMP\u9488\u5bf9\u6240\u6709\u53ef\u5e76\u884c\u5316\u7684\u6848\u4f8b\u5747\u8fbe\u5230100%\u7f16\u8bd1\u6210\u529f\u7387\uff0c\u800c\u57fa\u7ebf\uff08\u672a\u7528\u68c0\u7d22\u7684GPT-3.5-Turbo\uff09\u670920\u4f8b\u7f16\u8bd1\u5931\u8d25\u3002\u6b64\u5916\uff0cP4OMP\u5728\u907f\u514dOpenMP\u4f5c\u7528\u57df\u9519\u8bef\u3001\u8bed\u6cd5\u8bef\u7528\u548c\u6307\u4ee4\u65e0\u6548\u7ec4\u5408\u7b49\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u5728\u9ad8\u6027\u80fd\u8ba1\u7b97\u96c6\u7fa4\u4e0a\u7684\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u826f\u597d\u7684\u8fd0\u884c\u65f6\u6269\u5c55\u6027\u3002", "conclusion": "P4OMP\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u751f\u6210OpenMP\u5e76\u884c\u4ee3\u7801\u65f6\u7684\u53ef\u9760\u6027\u4e0e\u9002\u7528\u6027\uff0c\u4e3a\u81ea\u52a8\u5316\u5e76\u884c\u5316C/C++\u4ee3\u7801\u63d0\u4f9b\u4e86\u4e00\u79cd\u9c81\u68d2\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.23407", "categories": ["cs.PL", "quant-ph"], "pdf": "https://arxiv.org/pdf/2506.23407", "abs": "https://arxiv.org/abs/2506.23407", "authors": ["Marcus Edwards"], "title": "Compiling a Q# Subset to QASM 3.0 in TypeScript via a JSON Based IR", "comment": null, "summary": "We implement a compile toolchain from Q# to QASM 3.0 including a\nfull-featured lexer and parser implementation, as well as a compiler that\nsupports a subset of Q# features. The lexer, parser and compiler are shown to\nwork with various input Q# programs and the implementation is compared against\nexisting Q# compile tools. Unlike the Microsoft implementation of the official\nQ# compile toolchain, our implementation is written in TypeScript in order to\nport functionality to web environments.", "AI": {"tldr": "\u672c\u6587\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8eTypeScript\u7684Q#\u5230QASM 3.0\u7f16\u8bd1\u5de5\u5177\u94fe\uff0c\u652f\u6301\u5728Web\u73af\u5883\u4e0b\u5bf9Q#\u7a0b\u5e8f\u8fdb\u884c\u7f16\u8bd1\uff0c\u4e3a\u91cf\u5b50\u7f16\u7a0b\u7684\u8de8\u5e73\u53f0\u5e94\u7528\u63d0\u4f9b\u4e86\u4fbf\u5229\u3002", "motivation": "\u73b0\u6709\u7684Q#\u7f16\u8bd1\u5de5\u5177\u94fe\u4ec5\u9650\u4e8e\u5b98\u65b9Microsoft\u5b9e\u73b0\uff0c\u7f3a\u4e4f\u5411Web\u73af\u5883\u79fb\u690d\u7684\u80fd\u529b\u3002\u968f\u7740\u91cf\u5b50\u7f16\u7a0b\u5e94\u7528\u7684\u6269\u5c55\uff0c\u5c06Q#\u7f16\u8bd1\u529f\u80fd\u5e26\u5230Web\u5e73\u53f0\u53d8\u5f97\u6709\u73b0\u5b9e\u9700\u6c42\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4eceQ#\u5230QASM 3.0\u7684\u7f16\u8bd1\u5de5\u5177\u94fe\uff0c\u5305\u62ec\u8bcd\u6cd5\u5206\u6790\u5668\uff08lexer\uff09\u3001\u8bed\u6cd5\u5206\u6790\u5668\uff08parser\uff09\u4ee5\u53ca\u7f16\u8bd1\u5668\u672c\u4f53\uff0c\u652f\u6301Q#\u90e8\u5206\u7279\u6027\uff0c\u5e76\u4f7f\u7528TypeScript\u8bed\u8a00\u7f16\u5199\u4ee5\u4fbf\u4e8eWeb\u73af\u5883\u79fb\u690d\u3002", "result": "\u5b9e\u73b0\u4e86\u4e00\u5957\u5b8c\u6574\u7684Q#\u5230QASM 3.0\u5de5\u5177\u94fe\uff0c\u5e76\u5728\u591a\u4e2aQ#\u7a0b\u5e8f\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u8868\u660e\u5176\u5de5\u4f5c\u6b63\u5e38\u3002\u540c\u65f6\uff0c\u4e0e\u5df2\u6709Q#\u7f16\u8bd1\u5de5\u5177\u8fdb\u884c\u4e86\u5bf9\u6bd4\u9a8c\u8bc1\u3002", "conclusion": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u57fa\u4e8eTypeScript\u7684Q#\u5230QASM 3.0\u7f16\u8bd1\u6d41\u7a0b\uff0c\u4e3aWeb\u73af\u5883\u4e0b\u7684Q#\u7f16\u8bd1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.22486", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22486", "abs": "https://arxiv.org/abs/2506.22486", "authors": ["Ming Cheung"], "title": "Hallucination Detection with Small Language Models", "comment": null, "summary": "Since the introduction of ChatGPT, large language models (LLMs) have\ndemonstrated significant utility in various tasks, such as answering questions\nthrough retrieval-augmented generation. Context can be retrieved using a\nvectorized database, serving as a foundation for LLMs to generate responses.\nHowever, hallucinations in responses can undermine the reliability of LLMs in\npractical applications, and they are not easily detectable in the absence of\nground truth, particularly in question-and-answer scenarios. This paper\nproposes a framework that integrates multiple small language models to verify\nresponses generated by LLMs using the retrieved context from a vectorized\ndatabase. By breaking down the responses into individual sentences and\nutilizing the probability of generating \"Yes\" tokens from the outputs of\nmultiple models for a given set of questions, responses, and relevant context,\nhallucinations can be detected. The proposed framework is validated through\nexperiments with real datasets comprising over 100 sets of questions, answers,\nand contexts, including responses with fully and partially correct sentences.\nThe results demonstrate a 10\\% improvement in F1 scores for detecting correct\nresponses compared to hallucinations, indicating that multiple small language\nmodels can be effectively employed for answer verification, providing a\nscalable and efficient solution for both academic and practical applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u878d\u5408\u591a\u4e2a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u9a8c\u8bc1\u5927\u6a21\u578b\u7b54\u6848\u7684\u6846\u67b6\uff0c\u5728\u56de\u7b54\u62c6\u5206\u548c\u5411\u91cf\u68c0\u7d22\u57fa\u7840\u4e0a\u901a\u8fc7\u201cYes\u201d\u6982\u7387\u6295\u7968\u68c0\u6d4b\u5e7b\u89c9\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u53ef\u5927\u5e45\u63d0\u5347\u7b54\u6848\u771f\u5b9e\u6027\u68c0\u6d4b\u6548\u7387\u548c\u7cbe\u5ea6\u3002", "motivation": "LLM\u5728\u95ee\u7b54\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u5e38\u51fa\u73b0\u5185\u5bb9\u5e7b\u89c9\uff0c\u4e14\u65e0\u771f\u5b9e\u7b54\u6848\u65f6\u96be\u4ee5\u68c0\u6d4b\u3002\u63d0\u5347LLM\u5b9e\u9645\u5e94\u7528\u53ef\u9760\u6027\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u8054\u5408\u9a8c\u8bc1LLM\u751f\u6210\u7b54\u6848\u7684\u65b0\u6846\u67b6\u3002\u65b9\u6cd5\u5305\u62ec\uff1a\u5c06LLM\u7ed9\u51fa\u7684\u7b54\u6848\u62c6\u5206\u6210\u5355\u53e5\uff1b\u5229\u7528\u5411\u91cf\u5316\u6570\u636e\u5e93\u68c0\u7d22\u76f8\u5173\u4e0a\u4e0b\u6587\uff1b\u8ba9\u591a\u4e2a\u5c0f\u8bed\u8a00\u6a21\u578b\u57fa\u4e8e\u95ee\u9898\u3001\u7b54\u6848\u548c\u4e0a\u4e0b\u6587\u5bf9\u6bcf\u53e5\u8bdd\u751f\u6210\u201cYes\u201d\u6982\u7387\u8fdb\u884c\u5224\u65ad\uff0c\u4ece\u800c\u68c0\u6d4b\u7b54\u6848\u4e2d\u7684\u5e7b\u89c9\u5185\u5bb9\uff1b\u5e76\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u3002", "result": "\u5728\u5305\u542b100\u4f59\u7ec4\u95ee\u9898\u3001\u7b54\u6848\u548c\u4e0a\u4e0b\u6587\u7684\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u6846\u67b6\u6bd4\u57fa\u7ebf\u63d0\u5347\u4e8610%\u7684F1\u5206\u6570\uff0c\u53ef\u6709\u6548\u533a\u5206\u771f\u5b9e\u56de\u7b54\u4e0e\u5e7b\u89c9\uff0c\u5177\u6709\u8f83\u5f3a\u7684\u6269\u5c55\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u591a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u6574\u5408\u53ef\u6709\u6548\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u56de\u7b54\u7684\u771f\u5b9e\u6027\u9a8c\u8bc1\uff0c\u63d0\u9ad8\u4e86\u5e7b\u89c9\u68c0\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u9a8c\u8bc1\u65b9\u6cd5\u53ef\u5e94\u7528\u4e8e\u5b66\u672f\u4e0e\u5b9e\u9645\u573a\u666f\u3002"}}
{"id": "2506.23789", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2506.23789", "abs": "https://arxiv.org/abs/2506.23789", "authors": ["Reza Soltani", "Stefano M. Nicoletti", "Milan Lopuha\u00e4-Zwakenberg", "Mari\u00eblle Stoelinga"], "title": "Querying Attack-Fault-Defense Trees: Property Specification in Smart Grid and Aerospace Case Studies", "comment": null, "summary": "This paper introduces AFDL, a logic-based framework for reasoning about\nsafety, security, and defense interactions in Attack-Fault-Defense Trees, which\nis a model that captures all safety, security, and defense domains in a single\nframework. We showcase both AFDL and propose a structured domain specific query\nlanguage, LangAFDL, which enables domain experts to express complex analysis\ngoals through intuitive templates. LangAFDL supports both Boolean and\nquantified queries as well as minimal cut set analysis, capturing the interplay\nbetween safety, security, and defensive measures. We illustrate the\nexpressiveness and utility of the approach through representative queries over\ntwo different real-world case studies: Gridshield and Ground Segment as a\nService. The formalization lays the automated safety-security groundwork for\nanalyses in mission-critical systems and paves the way for future tool\ndevelopment and integration into design workflows.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7edf\u4e00\u5206\u6790\u5b89\u5168\u3001\u4fdd\u5b89\u4e0e\u9632\u5fa1\u4ea4\u4e92\u7684\u65b0\u6846\u67b6\uff08AFDL\uff09\u53ca\u5176\u67e5\u8be2\u8bed\u8a00\uff08LangAFDL\uff09\uff0c\u901a\u8fc7\u6848\u4f8b\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u6027\uff0c\u5e76\u63a8\u52a8\u4e86\u4efb\u52a1\u5173\u952e\u7cfb\u7edf\u5b89\u5168\u81ea\u52a8\u5316\u5206\u6790\u7684\u53d1\u5c55\u3002", "motivation": "\u76ee\u524d\u5728\u5b89\u5168\u3001\u4fdd\u5b89\u4e0e\u9632\u5fa1\u9886\u57df\u9700\u8981\u7edf\u4e00\u7684\u5206\u6790\u6846\u67b6\u6765\u63cf\u8ff0\u548c\u5206\u6790\u8fd9\u4e9b\u9886\u57df\u7684\u4ea4\u4e92\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5168\u9762\u8986\u76d6\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u591a\u91cd\u5b89\u5168\u56e0\u7d20\u3002", "method": "\u63d0\u51fa\u4e86AFDL\u8fd9\u4e00\u57fa\u4e8e\u903b\u8f91\u7684\u63a8\u7406\u6846\u67b6\uff0c\u7528\u4e8eAttack-Fault-Defense Trees\uff08\u653b\u51fb-\u6545\u969c-\u9632\u5fa1\u6811\uff09\u6a21\u578b\uff0c\u5e76\u4e14\u8bbe\u8ba1\u4e86\u7ed3\u6784\u5316\u7684\u9886\u57df\u7279\u5b9a\u67e5\u8be2\u8bed\u8a00LangAFDL\uff0c\u4f7f\u4e13\u5bb6\u80fd\u591f\u5229\u7528\u6a21\u677f\u76f4\u89c2\u8868\u8fbe\u590d\u6742\u5206\u6790\u76ee\u6807\uff0c\u652f\u6301\u5e03\u5c14\u548c\u91cf\u5316\u67e5\u8be2\u53ca\u6700\u5c0f\u5272\u96c6\u5206\u6790\u3002", "result": "\u901a\u8fc7\u5bf9\u4e24\u4e2a\u771f\u5b9e\u6848\u4f8b\uff08Gridshield\u548cGround Segment as a Service\uff09\u7684\u67e5\u8be2\u793a\u4f8b\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u8868\u8fbe\u80fd\u529b\u548c\u5b9e\u7528\u6027\uff0c\u4e3a\u4efb\u52a1\u5173\u952e\u578b\u7cfb\u7edf\u7684\u81ea\u52a8\u5b89\u5168-\u5b89\u4fdd\u5206\u6790\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u52a9\u4e8e\u5b9e\u73b0\u81ea\u52a8\u5316\u7684\u5b89\u5168\u4e0e\u5b89\u4fdd\u5206\u6790\uff0c\u5e76\u4e3a\u672a\u6765\u5de5\u5177\u5f00\u53d1\u53ca\u5176\u8bbe\u8ba1\u6d41\u7a0b\u96c6\u6210\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2506.22742", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22742", "abs": "https://arxiv.org/abs/2506.22742", "authors": ["Wali Mohammad Abdullah", "Md. Morshedul Islam", "Devraj Parmar", "Happy Hasmukhbhai Patel", "Sindhuja Prabhakaran", "Baidya Saha"], "title": "RAILS: Retrieval-Augmented Intelligence for Learning Software Development", "comment": null, "summary": "Large Language Models (LLMs) like GPT-3.5-Turbo are increasingly used to\nassist software development, yet they often produce incomplete code or\nincorrect imports, especially when lacking access to external or\nproject-specific documentation. We introduce RAILS (Retrieval-Augmented\nIntelligence for Learning Software Development), a framework that augments LLM\nprompts with semantically retrieved context from curated Java resources using\nFAISS and OpenAI embeddings. RAILS incorporates an iterative validation loop\nguided by compiler feedback to refine suggestions. We evaluated RAILS on 78\nreal-world Java import error cases spanning standard libraries, GUI APIs,\nexternal tools, and custom utilities. Despite using the same LLM, RAILS\noutperforms baseline prompting by preserving intent, avoiding hallucinations,\nand surfacing correct imports even when libraries are unavailable locally.\nFuture work will integrate symbolic filtering via PostgreSQL and extend support\nto other languages and IDEs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRAILS\uff0c\u901a\u8fc7\u8bed\u4e49\u68c0\u7d22\u548c\u7f16\u8bd1\u5668\u53cd\u9988\u589e\u5f3a\u5927\u6a21\u578b\u8f85\u52a9Java\u5f00\u53d1\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u89e3\u51b3import\u9519\u8bef\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5927\u6a21\u578b\u7528\u6cd5\uff0c\u672a\u6765\u5c06\u6269\u5c55\u5230\u66f4\u591a\u8bed\u8a00\u548cIDE\u3002", "motivation": "\u5f53\u524d\u5927\u6a21\u578b\u5728\u8f6f\u4ef6\u5f00\u53d1\u8f85\u52a9\u4e2d\u5e38\u51fa\u73b0\u4ee3\u7801\u4e0d\u5b8c\u6574\u6216import\u9519\u8bef\u3001\u7f3a\u4e4f\u9488\u5bf9\u6027\u4e0a\u4e0b\u6587\uff0c\u5c24\u5176\u5728\u65e0\u5916\u90e8\u6216\u9879\u76ee\u6587\u6863\u65f6\u95ee\u9898\u7a81\u51fa\uff0c\u56e0\u6b64\u4e9f\u9700\u63d0\u5347\u5176\u4ee3\u7801\u51c6\u786e\u6027\u4e0e\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51faRAILS\u6846\u67b6\uff0c\u5229\u7528FAISS\u548cOpenAI embedding\u5bf9Java\u8d44\u6e90\u8fdb\u884c\u8bed\u4e49\u68c0\u7d22\uff0c\u5c06\u76f8\u5173\u4e0a\u4e0b\u6587\u52a0\u5165LLM\u63d0\u793a\u8bcd\u4e2d\uff0c\u5e76\u5f15\u5165\u7f16\u8bd1\u5668\u53cd\u9988\u7684\u8fed\u4ee3\u9a8c\u8bc1\u673a\u5236\u4ee5\u7cbe refine\u4ee3\u7801\u5efa\u8bae\u3002", "result": "\u572878\u4e2a\u5b9e\u9645Java import\u9519\u8bef\u6848\u4f8b\u4e0a\uff0cRAILS\u5728\u4fdd\u6301\u4ee3\u7801\u610f\u56fe\u3001\u907f\u514d\u5e7b\u60f3\u548c\u63d0\u4f9b\u6b63\u786eimport\u5efa\u8bae\u65b9\u9762\u5747\u5927\u5e45\u4f18\u4e8e\u666e\u901aLLM\u63d0\u793a\u8bcd\u3002\u5373\u4fbf\u672c\u5730\u672a\u6709\u76f8\u5173\u5e93\uff0c\u6548\u679c\u4f9d\u7136\u7a81\u51fa\u3002", "conclusion": "RAILS\u663e\u8457\u63d0\u5347\u4e86LLM\u5728Java\u4ee3\u7801\u5f00\u53d1\u4e2d\u5904\u7406import\u9519\u8bef\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u548c\u7f16\u8bd1\u5668\u53cd\u9988\u5faa\u73af\u6709\u6548\u907f\u514d\u4e86\u5e7b\u89c9\u3001\u4fdd\u6301\u4e86\u4ee3\u7801\u610f\u56fe\uff0c\u5e76\u80fd\u591f\u5728\u672c\u5730\u7f3a\u5931\u5e93\u65f6\u4ecd\u7ed9\u51fa\u6b63\u786e\u5efa\u8bae\u3002"}}
{"id": "2506.22776", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2506.22776", "abs": "https://arxiv.org/abs/2506.22776", "authors": ["Sen Fang", "Weiyuan Ding", "Antonio Mastropaolo", "Bowen Xu"], "title": "Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation", "comment": "13 pages, 6 figures", "summary": "Quantization has emerged as a mainstream method for compressing Large\nLanguage Models (LLMs), reducing memory requirements and accelerating inference\nwithout architectural modifications. While existing research primarily focuses\non evaluating the effectiveness of quantized LLMs compared to their original\ncounterparts, the impact on robustness remains largely unexplored.In this\npaper, we present the first systematic investigation of how quantization\naffects the robustness of LLMs in code generation tasks. Through extensive\nexperiments across four prominent LLM families (LLaMA, DeepSeek, CodeGen, and\nStarCoder) with parameter scales ranging from 350M to 33B, we evaluate\nrobustness from dual perspectives: adversarial attacks on input prompts and\nnoise perturbations on model architecture. Our findings challenge conventional\nwisdom by demonstrating that quantized LLMs often exhibit superior robustness\ncompared to their full-precision counterparts, with 51.59% versus 42.86% of our\nadversarial experiments showing better resilience in quantized LLMs. Similarly,\nour noise perturbation experiments also confirm that LLMs after quantitation\ngenerally withstand higher levels of weight disturbances. These results suggest\nthat quantization not only reduces computational requirements but can actually\nenhance LLMs' reliability in code generation tasks, providing valuable insights\nfor developing more robust and efficient LLM deployment strategies.", "AI": {"tldr": "\u9996\u6b21\u7cfb\u7edf\u6027\u7814\u7a76\u8868\u660e\uff0c\u91cf\u5316\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u6bd4\u5168\u7cbe\u5ea6\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u9c81\u68d2\u6027\uff0c\u65e2\u8282\u7701\u8ba1\u7b97\u8d44\u6e90\u53c8\u63d0\u5347\u53ef\u9760\u6027\u3002", "motivation": "\u76ee\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u91cf\u5316\u4e3b\u8981\u7528\u4e8e\u6a21\u578b\u538b\u7f29\u548c\u63a8\u7406\u52a0\u901f\uff0c\u4f46\u5173\u4e8e\u91cf\u5316\u5bf9\u6a21\u578b\u9c81\u68d2\u6027\u7684\u5f71\u54cd\u5c1a\u672a\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u9488\u5bf9\u4ee3\u7801\u751f\u6210\u4efb\u52a1\uff0c\u7cfb\u7edf\u6027\u8bc4\u4f30\u91cf\u5316\u5bf9\u56db\u5927\u5bb6\u65cf\uff08LLaMA\u3001DeepSeek\u3001CodeGen\u3001StarCoder\uff09\uff0c\u53c2\u6570\u89c4\u6a21\u4ece350M\u523033B\u7684\u6a21\u578b\u9c81\u68d2\u6027\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u4e24\u65b9\u9762\uff1a\u8f93\u5165\u63d0\u793a\u7684\u5bf9\u6297\u653b\u51fb\u548c\u6a21\u578b\u6743\u91cd\u6270\u52a8\u5b9e\u9a8c\u5206\u522b\u5f00\u5c55\u3002", "result": "\u91cf\u5316\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9c81\u68d2\u6027\u65b9\u9762\u5f80\u5f80\u4f18\u4e8e\u5168\u7cbe\u5ea6\u6a21\u578b\u3002\u5728\u5bf9\u6297\u653b\u51fb\u5b9e\u9a8c\u4e2d\u670951.59%\u7684\u91cf\u5316\u6a21\u578b\u66f4\u9c81\u68d2\uff0c\u800c\u5168\u7cbe\u5ea6\u6a21\u578b\u4ec5\u4e3a42.86%\u3002\u5728\u6743\u91cd\u6270\u52a8\u5b9e\u9a8c\u4e2d\uff0c\u91cf\u5316\u540e\u7684LLM\u80fd\u66f4\u597d\u5730\u62b5\u6297\u6270\u52a8\u5f71\u54cd\u3002", "conclusion": "\u91cf\u5316\u4e0d\u4ec5\u6709\u52a9\u4e8e\u538b\u7f29\u6a21\u578b\u548c\u52a0\u901f\u63a8\u7406\uff0c\u8fd8\u80fd\u589e\u5f3aLLM\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u4eca\u540e\u66f4\u7a33\u5065\u3001\u9ad8\u6548\u5730\u90e8\u7f72LLM\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.22491", "categories": ["cs.CL", "cs.AI", "cs.CY", "I.2.7; J.4; K.4.2"], "pdf": "https://arxiv.org/pdf/2506.22491", "abs": "https://arxiv.org/abs/2506.22491", "authors": ["Oliver Warke", "Joemon M. Jose", "Faegheh Hasibi", "Jan Breitsohl"], "title": "PromptAug: Fine-grained Conflict Classification Using Data Augmentation", "comment": null, "summary": "Given the rise of conflicts on social media, effective classification models\nto detect harmful behaviours are essential. Following the\ngarbage-in-garbage-out maxim, machine learning performance depends heavily on\ntraining data quality. However, high-quality labelled data, especially for\nnuanced tasks like identifying conflict behaviours, is limited, expensive, and\ndifficult to obtain. Additionally, as social media platforms increasingly\nrestrict access to research data, text data augmentation is gaining attention\nas an alternative to generate training data. Augmenting conflict-related data\nposes unique challenges due to Large Language Model (LLM) guardrails that\nprevent generation of offensive content. This paper introduces PromptAug, an\ninnovative LLM-based data augmentation method. PromptAug achieves statistically\nsignificant improvements of 2% in both accuracy and F1-score on conflict and\nemotion datasets. To thoroughly evaluate PromptAug against other data\naugmentation methods we conduct a robust evaluation using extreme data scarcity\nscenarios, quantitative diversity analysis and a qualitative thematic analysis.\nThe thematic analysis identifies four problematic patterns in augmented text:\nLinguistic Fluidity, Humour Ambiguity, Augmented Content Ambiguity, and\nAugmented Content Misinterpretation.\n  Overall, this work presents PromptAug as an effective method for augmenting\ndata in sensitive tasks like conflict detection, offering a unique,\ninterdisciplinary evaluation grounded in both natural language processing and\nsocial science methodology.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faPromptAug\uff0c\u5229\u7528LLM\u8fdb\u884c\u6570\u636e\u589e\u5f3a\uff0c\u5728\u793e\u4ea4\u5a92\u4f53\u51b2\u7a81\u68c0\u6d4b\u4efb\u52a1\u4e2d\u63d0\u5347\u4e86\u5206\u7c7b\u6548\u679c\uff0c\u5e76\u901a\u8fc7\u4e25\u8c28\u591a\u7ef4\u5206\u6790\u5c55\u793a\u5176\u4f18\u52bf\u548c\u5b58\u5728\u7684\u95ee\u9898\uff0c\u8bc1\u660e\u5176\u5728\u654f\u611f\u4efb\u52a1\u4e0a\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u51b2\u7a81\u884c\u4e3a\u65e5\u76ca\u589e\u591a\uff0c\u800c\u5bf9\u6709\u5bb3\u884c\u4e3a\u7684\u6709\u6548\u68c0\u6d4b\u6a21\u578b\u4f9d\u8d56\u4e8e\u9ad8\u8d28\u91cf\u7684\u8bad\u7ec3\u6570\u636e\u3002\u4f46\u9ad8\u8d28\u91cf\u3001\u6709\u6807\u7b7e\u7684\u6570\u636e\u96be\u4ee5\u83b7\u5f97\uff0c\u4e14\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u5bf9\u7814\u7a76\u6570\u636e\u7684\u8bbf\u95ee\u6b63\u53d8\u5f97\u66f4\u52a0\u53d7\u9650\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u6570\u636e\u6269\u5145\u65b9\u6cd5\u3002", "method": "\u63d0\u51faPromptAug\uff0c\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u8bad\u7ec3\u6570\u636e\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u521b\u65b0\u7684prompt\u8bbe\u8ba1\uff0c\u8ba9LLM\u5728\u4e0d\u8fdd\u53cd\u5b89\u5168\u89c4\u5219\uff08\u5982\u4e0d\u751f\u6210\u653b\u51fb\u6027\u5185\u5bb9\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u751f\u6210\u4e0e\u51b2\u7a81\u76f8\u5173\u7684\u6587\u672c\u3002\u540c\u65f6\u901a\u8fc7\u6781\u7aef\u6570\u636e\u7a00\u7f3a\u573a\u666f\u3001\u91cf\u5316\u591a\u6837\u6027\u5206\u6790\u53ca\u5b9a\u6027\u4e3b\u9898\u5206\u6790\u4ece\u591a\u89d2\u5ea6\u8bc4\u4f30\u8be5\u65b9\u6cd5\u3002", "result": "PromptAug\u5728\u51b2\u7a81\u4e0e\u60c5\u7eea\u6570\u636e\u96c6\u4e0a\uff0c\u5c06\u51c6\u786e\u7387\u548cF1\u5206\u6570\u63d0\u5347\u4e862%\uff0c\u6548\u679c\u5177\u6709\u7edf\u8ba1\u5b66\u610f\u4e49\u3002\u4e3b\u9898\u5206\u6790\u53d1\u73b0\uff0c\u589e\u5f3a\u6587\u672c\u4e2d\u5b58\u5728\u8bed\u8a00\u6d41\u52a8\u6027\u3001\u5e7d\u9ed8\u6b67\u4e49\u3001\u589e\u5f3a\u5185\u5bb9\u6b67\u4e49\u548c\u589e\u5f3a\u5185\u5bb9\u8bef\u89e3\u56db\u79cd\u95ee\u9898\u6a21\u5f0f\u3002", "conclusion": "PromptAug\u662f\u4e00\u79cd\u5728\u51b2\u7a81\u68c0\u6d4b\u7b49\u654f\u611f\u4efb\u52a1\u4e2d\u6709\u6548\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u793e\u4f1a\u79d1\u5b66\u65b9\u6cd5\u8bba\u7684\u4ea4\u53c9\u89c6\u89d2\u4e0b\uff0c\u63d0\u4f9b\u4e86\u72ec\u7279\u4e14\u5b9e\u7528\u7684\u8bc4\u4f30\u3002"}}
{"id": "2506.24072", "categories": ["cs.LO", "cs.CR"], "pdf": "https://arxiv.org/pdf/2506.24072", "abs": "https://arxiv.org/abs/2506.24072", "authors": ["R Ramanujam", "Vaishnavi Sundararajan", "S P Suresh"], "title": "Protocol insecurity with finitely many sessions and XOR", "comment": null, "summary": "We present a different proof of the insecurity problem for XOR, solved in by\nChevalier, Kuesters, Rusinowitch and Turuani (2005). Our proof uses the notion\nof typed terms and well-typed proofs, and removes a restriction on the class of\nprotocols to which the [CKRT05] proof applies, by introducing a slightly\ndifferent (but very natural) notion of protocols, where honest agent sends are\nderivable from previous receives in the same session.", "AI": {"tldr": "\u672c\u6587\u4e3aXOR\u5b89\u5168\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u5e7f\u9002\u7528\u6027\u7684\u8bc1\u660e\u65b9\u6cd5\uff0c\u7406\u8bba\u57fa\u7840\u66f4\u81ea\u7136\u3001\u76f4\u89c2\uff0c\u5bf9\u76f8\u5173\u534f\u8bae\u5b89\u5168\u6027\u5206\u6790\u6709\u8f83\u5927\u610f\u4e49\u3002", "motivation": "\u65e9\u671f\u6587\u732e\u4e2d\u7684\u5b89\u5168\u6027\u8bc1\u660e\u5bf9\u534f\u8bae\u7c7b\u578b\u6709\u4e00\u5b9a\u9650\u5236\uff0c\u672c\u6587\u5e0c\u671b\u5728\u4e00\u4e2a\u66f4\u81ea\u7136\u3001\u5408\u7406\u7684\u534f\u8bae\u6a21\u578b\u4e0b\uff0c\u89e3\u51b3\u540c\u6837\u7684XOR\u5b89\u5168\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528typed terms\u548cwell-typed proofs\u7684\u6280\u5de7\uff0c\u7ed3\u5408\u5bf9\u534f\u8bae\u5b9a\u4e49\u7684\u9002\u5f53\u4fee\u6539\uff0c\u7ed9\u51fa\u4e86\u4e0d\u540c\u4e8e\u4ee5\u5f80\u6587\u732e\u7684\u5b89\u5168\u6027\u8bc1\u660e\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u66f4\u4e00\u822c\u6027\u7684XOR\u4e0d\u5b89\u5168\u6027\u8bc1\u660e\uff0c\u540c\u65f6\u6240\u4f7f\u7528\u7684\u534f\u8bae\u5b9a\u4e49\u66f4\u8d34\u8fd1\u5b9e\u9645\u534f\u8bae\u7684\u884c\u4e3a\uff0c\u4e14\u7406\u8bba\u6846\u67b6\u66f4\u52a0\u901a\u7528\u3002", "conclusion": "\u672c\u6587\u4ee5\u65b0\u7684\u65b9\u5f0f\u8bc1\u660e\u4e86XOR\u5728\u67d0\u7c7b\u534f\u8bae\u4e0b\u5b58\u5728\u5b89\u5168\u6027\u95ee\u9898\uff0c\u5e76\u653e\u5bbd\u4e86\u65e9\u671f\u8bc1\u660e\u4e2d\u7684\u534f\u8bae\u9002\u7528\u8303\u56f4\u3002"}}
{"id": "2506.22752", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.22752", "abs": "https://arxiv.org/abs/2506.22752", "authors": ["Havvanur Dervi\u015fo\u011flu", "Ru\u015fen Halepmollas\u0131", "Elif Eyvaz"], "title": "Privacy-Preserving Methods for Bug Severity Prediction", "comment": null, "summary": "Bug severity prediction is a critical task in software engineering as it\nenables more efficient resource allocation and prioritization in software\nmaintenance. While AI-based analyses and models significantly require access to\nextensive datasets, industrial applications face challenges due to data-sharing\nconstraints and the limited availability of labeled data. In this study, we\ninvestigate method-level bug severity prediction using source code metrics and\nLarge Language Models (LLMs) with two widely used datasets. We compare the\nperformance of models trained using centralized learning, federated learning,\nand synthetic data generation. Our experimental results, obtained using two\nwidely recognized software defect datasets, indicate that models trained with\nfederated learning and synthetic data achieve comparable results to centrally\ntrained models without data sharing. Our finding highlights the potential of\nprivacy-preserving approaches such as federated learning and synthetic data\ngeneration to enable effective bug severity prediction in industrial context\nwhere data sharing is a major challenge.\n  The source code and dataset are available at our GitHub repository:\nhttps://github.com/drvshavva/EASE2025-Privacy-Preserving-Methods-for-Bug-Severity-Prediction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u8054\u90a6\u5b66\u4e60\u548c\u5408\u6210\u6570\u636e\u7b49\u9690\u79c1\u4fdd\u62a4\u624b\u6bb5\uff0c\u5728\u6570\u636e\u4e0d\u53ef\u5171\u4eab\u7684\u60c5\u51b5\u4e0b\uff0c\u540c\u6837\u80fd\u5b9e\u73b0\u6548\u679c\u4f18\u79c0\u7684bug\u4e25\u91cd\u6027\u9884\u6d4b\uff0c\u5bf9\u5de5\u4e1a\u5e94\u7528\u5177\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\uff0c\u9519\u8bef\u4e25\u91cd\u6027\u9884\u6d4b\u5bf9\u4e8e\u63d0\u5347\u8d44\u6e90\u5206\u914d\u548c\u7ef4\u62a4\u4f18\u5148\u7ea7\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u73b0\u5b9e\u4e2d\uff0c\u56e0\u6570\u636e\u5171\u4eab\u53d7\u9650\u53ca\u6709\u6807\u7b7e\u6570\u636e\u532e\u4e4f\uff0c\u5de5\u4e1a\u754c\u96be\u4ee5\u5e94\u7528AI\u5206\u6790\u4e0e\u6a21\u578b\u3002", "method": "\u57fa\u4e8e\u6e90\u4ee3\u7801\u5ea6\u91cf\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u4f7f\u7528\u4e24\u4e2a\u5e38\u7528\u7684\u6570\u636e\u96c6\uff0c\u5206\u522b\u5bf9\u96c6\u4e2d\u5f0f\u5b66\u4e60\u3001\u8054\u90a6\u5b66\u4e60\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u4e09\u79cd\u8bad\u7ec3\u65b9\u5f0f\u8fdb\u884c\u9519\u8bef\u4e25\u91cd\u6027\u9884\u6d4b\u6027\u80fd\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u91c7\u7528\u8054\u90a6\u5b66\u4e60\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u5728\u65e0\u9700\u6570\u636e\u5171\u4eab\u524d\u63d0\u4e0b\uff0c\u80fd\u591f\u8fbe\u5230\u4e0e\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u6a21\u578b\u76f8\u5f53\u7684\u6548\u679c\u3002", "conclusion": "\u8054\u90a6\u5b66\u4e60\u4e0e\u5408\u6210\u6570\u636e\u751f\u6210\u7b49\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\uff0c\u53ef\u6709\u6548\u5728\u6570\u636e\u5171\u4eab\u53d7\u9650\u7684\u5de5\u4e1a\u80cc\u666f\u4e0b\u5b9e\u73b0\u9ad8\u6548\u7684\u9519\u8bef\u4e25\u91cd\u6027\u9884\u6d4b\u3002"}}
{"id": "2506.23281", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2506.23281", "abs": "https://arxiv.org/abs/2506.23281", "authors": ["Xintong Zhou", "Zhenyang Xu", "Chengnian Sun"], "title": "On the Feasibility of Deduplicating Compiler Bugs with Bisection", "comment": null, "summary": "Random testing has proven to be an effective technique for compiler\nvalidation. However, the debugging of bugs identified through random testing\npresents a significant challenge due to the frequent occurrence of duplicate\ntest programs that expose identical compiler bugs. The process to identify\nduplicates is a practical research problem known as bug deduplication. Prior\nmethodologies for compiler bug deduplication primarily rely on program analysis\nto extract bug-related features for duplicate identification, which can result\nin substantial computational overhead and limited generalizability. This paper\ninvestigates the feasibility of employing bisection, a standard debugging\nprocedure largely overlooked in prior research on compiler bug deduplication,\nfor this purpose. Our study demonstrates that the utilization of bisection to\nlocate failure-inducing commits provides a valuable criterion for\ndeduplication, albeit one that requires supplementary techniques for more\naccurate identification. Building on these results, we introduce BugLens, a\nnovel deduplication method that primarily uses bisection, enhanced by the\nidentification of bug-triggering optimizations to minimize false negatives.\nEmpirical evaluations conducted on four real-world datasets demonstrate that\nBugLens significantly outperforms the state-of-the-art analysis-based\nmethodologies Tamer and D3 by saving an average of 26.98% and 9.64% human\neffort to identify the same number of distinct bugs. Given the inherent\nsimplicity and generalizability of bisection, it presents a highly practical\nsolution for compiler bug deduplication in real-world applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4e8c\u5206\u6cd5\u7ed3\u5408\u4f18\u5316\u4fe1\u606f\u7684\u65b0\u65b9\u6cd5BugLens\u8fdb\u884c\u7f16\u8bd1\u5668bug\u53bb\u91cd\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u7701\u4eba\u5de5\u4e14\u6548\u7387\u9ad8\uff0c\u5b9e\u7528\u6027\u5f3a\u3002", "motivation": "\u968f\u673a\u6d4b\u8bd5\u867d\u7136\u80fd\u6709\u6548\u53d1\u73b0\u7f16\u8bd1\u5668bug\uff0c\u4f46\u7531\u4e8e\u4ea7\u751f\u5927\u91cf\u91cd\u590d\u6027\u6d4b\u8bd5\u7a0b\u5e8f\uff0c\u9020\u6210bug\u53bb\u91cd\uff08deduplication\uff09\u6781\u5177\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u7a0b\u5e8f\u5206\u6790\uff0c\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u4e9f\u9700\u65b0\u7684\u9ad8\u6548\u53bb\u91cd\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u7cfb\u7edf\u6027\u7814\u7a76\u4e86\u201c\u4e8c\u5206\u6cd5\u201d\uff08bisection\uff09\u7528\u4e8e\u7f16\u8bd1\u5668bug\u53bb\u91cd\u7684\u53ef\u884c\u6027\uff0c\u5e76\u63d0\u51faBugLens\u65b9\u6cd5\uff0c\u4ee5\u4e8c\u5206\u6cd5\u8f85\u52a9\u4f18\u5316\u53bb\u91cd\u6d41\u7a0b\uff0c\u540c\u65f6\u7ed3\u5408\u5bf9\u89e6\u53d1bug\u7684\u4f18\u5316\u8fc7\u7a0b\u5206\u6790\uff0c\u51cf\u5c11\u6f0f\u5224\u3002\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u4f20\u7edf\u7279\u5f81\u5206\u6790\uff0c\u4e3b\u6253\u901a\u7528\u6027\u548c\u9ad8\u6548\u6027\u3002", "result": "\u57284\u4e2a\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cBugLens\u6bd4\u73b0\u6709\u9886\u5148\u65b9\u6cd5Tamer\u548cD3\u66f4\u9ad8\u6548\uff0c\u5206\u522b\u8282\u7701\u4e8626.98%\u548c9.64%\u7684\u4eba\u529b\u6210\u672c\uff0c\u4e14\u80fd\u8bc6\u522b\u76f8\u540c\u6570\u91cf\u7684\u72ec\u7279bug\u3002", "conclusion": "\u4e8c\u5206\u6cd5\u7b80\u5355\u3001\u9ad8\u6cdb\u5316\u80fd\u529b\uff0c\u7ed3\u5408\u4f18\u5316\u4fe1\u606f\u80fd\u663e\u8457\u63d0\u5347bug\u53bb\u91cd\u6548\u7387\uff0c\u4e3a\u7f16\u8bd1\u5668\u9519\u8bef\u53bb\u91cd\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u73b0\u5b9e\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.22508", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22508", "abs": "https://arxiv.org/abs/2506.22508", "authors": ["Chenyang Shao", "Tianxing Li", "Chenhao Pu", "Fengli Xu", "Yong Li"], "title": "AgentStealth: Reinforcing Large Language Model for Anonymizing User-generated Text", "comment": "This work has been submitted to NeurIPS 2025. Under review", "summary": "In today's digital world, casual user-generated content often contains subtle\ncues that may inadvertently expose sensitive personal attributes. Such risks\nunderscore the growing importance of effective text anonymization to safeguard\nindividual privacy. However, existing methods either rely on rigid replacements\nthat damage utility or cloud-based LLMs that are costly and pose privacy risks.\nTo address these issues, we explore the use of locally deployed smaller-scale\nlanguage models (SLMs) for anonymization. Yet training effective SLMs remains\nchallenging due to limited high-quality supervision. To address the challenge,\nwe propose AgentStealth, a self-reinforcing LLM anonymization framework.First,\nwe introduce an adversarial anonymization workflow enhanced by In-context\nContrastive Learning and Adaptive Utility-Aware Control. Second, we perform\nsupervised adaptation of SLMs using high-quality data collected from the\nworkflow, which includes both anonymization and attack signals. Finally, we\napply online reinforcement learning where the model leverages its internal\nadversarial feedback to iteratively improve anonymization performance.\nExperiments on two datasets show that our method outperforms baselines in both\nanonymization effectiveness (+12.3%) and utility (+6.8%). Our lightweight\ndesign supports direct deployment on edge devices, avoiding cloud reliance and\ncommunication-based privacy risks. Our code is open-source at\nhttps://github.com/tsinghua-fib-lab/AgentStealth.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u9002\u7528\u4e8e\u672c\u5730\u8f7b\u91cf\u5316\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u589e\u5f3a\u6587\u672c\u533f\u540d\u5316\u6846\u67b6AgentStealth\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u8bad\u7ec3\u6d41\u7a0b\u548c\u6548\u679c\u63d0\u5347\u5b9e\u9a8c\uff0c\u6709\u6548\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u4e14\u6613\u4e8e\u672c\u5730\u90e8\u7f72\uff0c\u76f8\u5173\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u533f\u540d\u5316\u65b9\u6cd5\u8981\u4e48\u5f71\u54cd\u6587\u672c\u6548\u7528\uff0c\u8981\u4e48\u4f9d\u8d56\u4e91\u7aef\u5927\u578b\u6a21\u578b\u4e14\u5b58\u5728\u9ad8\u6210\u672c\u548c\u9690\u79c1\u98ce\u9669\u3002\u672c\u7814\u7a76\u5e0c\u671b\u5728\u7aef\u4fa7\u8bbe\u5907\u4e0a\u5b9e\u73b0\u9ad8\u6548\u3001\u4f4e\u98ce\u9669\u7684\u6587\u672c\u533f\u540d\u5316\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u589e\u5f3a\u7684LLM\u533f\u540d\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u5bf9\u6bd4\u5b66\u4e60\u3001\u6548\u7528\u81ea\u9002\u5e94\u63a7\u5236\u3001\u6570\u636e\u9ad8\u8d28\u91cf\u6536\u96c6\u53ca\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u3002\u5728\u672c\u5730\u5316\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u6709\u76d1\u7763\u9002\u914d\u4e0e\u81ea\u53cd\u9988\u8fed\u4ee3\u4f18\u5316\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u4e86\u533f\u540d\u5316\u6548\u679c\u548c\u6587\u672c\u6548\u7528\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0cAgentStealth\u6846\u67b6\u5728\u533f\u540d\u5316\u6709\u6548\u6027\u4e0a\u63d0\u5347\u4e8612.3%\uff0c\u6587\u672c\u6548\u7528\u63d0\u5347\u4e866.8%\u3002\u8be5\u6846\u67b6\u8f7b\u91cf\u5316\u8bbe\u8ba1\uff0c\u53ef\u76f4\u63a5\u90e8\u7f72\u4e8e\u672c\u5730\u8bbe\u5907\uff0c\u907f\u514d\u4e86\u4e91\u7aef\u9690\u79c1\u98ce\u9669\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684AgentStealth\u6846\u67b6\u80fd\u591f\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u6709\u6548\u5730\u5b9e\u73b0\u6587\u672c\u533f\u540d\u5316\uff0c\u5e76\u4e14\u5177\u6709\u8f83\u9ad8\u7684\u5b9e\u9645\u9002\u7528\u6027\u3002"}}
{"id": "2506.23696", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2506.23696", "abs": "https://arxiv.org/abs/2506.23696", "authors": ["Francisco Oliveira", "Alexandra Mendes", "Carolina Carreira"], "title": "What Challenges Do Developers Face When Using Verification-Aware Programming Languages?", "comment": null, "summary": "Software reliability is critical in ensuring that the digital systems we\ndepend on function correctly. In software development, increasing software\nreliability often involves testing. However, for complex and critical systems,\ndevelopers can use Design by Contract (DbC) methods to define precise\nspecifications that software components must satisfy. Verification-Aware (VA)\nprogramming languages support DbC and formal verification at compile-time or\nrun-time, offering stronger correctness guarantees than traditional testing.\nHowever, despite the strong guarantees provided by VA languages, their adoption\nremains limited. In this study, we investigate the barriers to adopting VA\nlanguages by analyzing developer discussions on public forums using topic\nmodeling techniques. We complement this analysis with a developer survey to\nbetter understand the practical challenges associated with VA languages. Our\nfindings reveal key obstacles to adoption, including steep learning curves and\nusability issues. Based on these insights, we identify actionable\nrecommendations to improve the usability and accessibility of VA languages. Our\nfindings suggest that simplifying tool interfaces, providing better educational\nmaterials, and improving integration with everyday development environments\ncould improve the usability and adoption of these languages. Our work provides\nactionable insights for improving the usability of VA languages and making\nverification tools more accessible.", "AI": {"tldr": "\u4f5c\u8005\u901a\u8fc7\u8bba\u575b\u5185\u5bb9\u5206\u6790\u548c\u95ee\u5377\u8c03\u67e5\uff0c\u53d1\u73b0\u5b66\u4e60\u96be\u5ea6\u548c\u53ef\u7528\u6027\u95ee\u9898\u5bfc\u81f4\u9a8c\u8bc1\u611f\u77e5\u8bed\u8a00\u91c7\u7eb3\u7387\u4f4e\uff0c\u5efa\u8bae\u4f18\u5316\u5de5\u5177\u754c\u9762\u3001\u6559\u80b2\u6750\u6599\u548c\u96c6\u6210\uff0c\u4fc3\u4f7f\u5176\u66f4\u6613\u7528\u4e5f\u66f4\u6613\u666e\u53ca\u3002", "motivation": "\u867d\u7136\u9a8c\u8bc1\u611f\u77e5\uff08Verification-Aware, VA\uff09\u7f16\u7a0b\u8bed\u8a00\u5728\u63d0\u5347\u8f6f\u4ef6\u53ef\u9760\u6027\u65b9\u9762\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4f46\u5b9e\u9645\u4e2d\u91c7\u7528\u7387\u5f88\u4f4e\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u5206\u6790\u5f00\u53d1\u8005\u8ba8\u8bba\uff0c\u627e\u51fa\u5f71\u54cdVA\u8bed\u8a00\u91c7\u7528\u7684\u969c\u788d\u3002", "method": "\u672c\u6587\u91c7\u7528\u8bba\u575b\u8bdd\u9898\u5efa\u6a21\u5206\u6790\u4e0e\u5f00\u53d1\u8005\u95ee\u5377\u8c03\u67e5\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u5bf9\u5f00\u53d1\u8005\u91c7\u7528VA\u8bed\u8a00\u7684\u963b\u788d\u56e0\u7d20\u8fdb\u884c\u63a2\u7a76\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cVA\u8bed\u8a00\u5b58\u5728\u5b66\u4e60\u66f2\u7ebf\u9661\u5ced\u548c\u53ef\u7528\u6027\u4e0d\u8db3\u7b49\u4e3b\u8981\u95ee\u9898\u3002\u6b64\u5916\uff0c\u8fd8\u5f52\u7eb3\u51fa\u63d0\u5347\u53ef\u7528\u6027\u548c\u91c7\u7528\u5ea6\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u7b80\u5316\u5de5\u5177\u754c\u9762\u3001\u63d0\u4f9b\u66f4\u597d\u7684\u6559\u80b2\u8d44\u6e90\u3001\u4ee5\u53ca\u6539\u5584\u4e0e\u5f00\u53d1\u73af\u5883\u7684\u96c6\u6210\u3002", "conclusion": "\u6539\u8fdbVA\u8bed\u8a00\u7684\u5de5\u5177\u754c\u9762\u3001\u6559\u80b2\u8d44\u6e90\u548c\u73af\u5883\u96c6\u6210\u80fd\u6709\u6548\u63d0\u5347\u5176\u53ef\u7528\u6027\u548c\u88ab\u91c7\u7eb3\u7a0b\u5ea6\uff0c\u4e3a\u63a8\u5e7f\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5de5\u5177\u548c\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2506.22510", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22510", "abs": "https://arxiv.org/abs/2506.22510", "authors": ["Zihao Zhao", "Xinlong Zhai", "Jinyu Yang", "Chuan Shi"], "title": "Towards Text-free Graph Foundation Models: Rethinking Multi-Domain Graph Contrastive Learning", "comment": "16 pages, 5 figures", "summary": "Foundation models have achieved great success in natural language processing\n(NLP) and computer vision (CV). Their success largely stems from the ability to\nintegrate multi-domain knowledge in pre-training and transfer it to target\ndomains. Considering graph data, especially graphs without textual features, is\nubiquitous in real-world applications such as social networks and\nrecommendation systems, some researchers have attempted to extend this paradigm\nto the graph field, aiming to construct graph foundation models. However,\nunlike CV and NLP, there are huge gaps among the semantics and properties of\ngraphs in different domains, while current works still adopt traditional\ncontrastive pre-training strategies designed in the single-domain scenario,\nwhich regard contrastive samples from different domains as equivalent. From\nexperimental investigations, we discovered that inherent domain-specific\ndifferences prevent these strategies from effectively absorbing knowledge from\ndifferent domains to generate informative representations. In this paper, we\npropose a novel multi-domain pre-training and cross-domain transfer framework,\nnamely MDGCL.In the pre-training stage, we design a contrastive learning\nstrategy to substantially recognize and capture domain differences, and\nintroduce domain tokens to encode domain-level global information. In the\ndownstream stage, we introduce a domain attention mechanism to enable\nfine-grained domain knowledge transfer. Extensive experiments on five benchmark\ndatasets have demonstrated that our method outperforms state-of-the-art\nsignificantly, with the maximum improvement of 19.33\\% on accuracy and 19.13\\%\non Macro-F1 score.", "AI": {"tldr": "\u9488\u5bf9\u56fe\u6570\u636e\u8de8\u57df\u9884\u8bad\u7ec3\u9762\u4e34\u7684\u9886\u57df\u5dee\u5f02\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u9886\u57df\u611f\u77e5\u7684\u5bf9\u6bd4\u5b66\u4e60\u548c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u57df\u56fe\u4efb\u52a1\u7684\u8868\u73b0\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u53d6\u5f97\u4e86\u5de8\u5927\u6210\u529f\uff0c\u4e3b\u8981\u5f97\u76ca\u4e8e\u5176\u8de8\u9886\u57df\u77e5\u8bc6\u7684\u9884\u8bad\u7ec3\u80fd\u529b\u3002\u7136\u800c\uff0c\u56fe\u6570\u636e\u7531\u4e8e\u5404\u9886\u57df\u4e4b\u95f4\u8bed\u4e49\u548c\u5c5e\u6027\u7684\u5de8\u5927\u5dee\u5f02\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u8de8\u57df\u77e5\u8bc6\u8fc1\u79fb\u3002\u4f5c\u8005\u53d1\u73b0\uff0c\u5f53\u524d\u56fe\u9884\u8bad\u7ec3\u5f80\u5f80\u76f4\u63a5\u501f\u7528\u5355\u57df\u5bf9\u6bd4\u5b66\u4e60\u7b56\u7565\uff0c\u4e0d\u80fd\u6709\u6548\u6574\u5408\u591a\u57df\u77e5\u8bc6\uff0c\u8fd9\u9650\u5236\u4e86\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u57df\u9884\u8bad\u7ec3\u53ca\u8de8\u57df\u8fc1\u79fb\u6846\u67b6MDGCL\u3002\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\uff0c\u8bbe\u8ba1\u4e86\u80fd\u591f\u8bc6\u522b\u548c\u6355\u6349\u9886\u57df\u5dee\u5f02\u7684\u5bf9\u6bd4\u5b66\u4e60\u7b56\u7565\uff0c\u5e76\u5f15\u5165\u4e86\u9886\u57dftoken\u7528\u4e8e\u7f16\u7801\u9886\u57df\u7ea7\u7684\u5168\u5c40\u4fe1\u606f\uff1b\u5728\u4e0b\u6e38\u4efb\u52a1\u9636\u6bb5\uff0c\u5f15\u5165\u9886\u57df\u6ce8\u610f\u529b\u673a\u5236\u4ee5\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u7684\u9886\u57df\u77e5\u8bc6\u8fc1\u79fb\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u6700\u65b0\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u534719.33%\uff0cMacro-F1\u6700\u9ad8\u63d0\u534719.13%\u3002", "conclusion": "MDGCL \u80fd\u6709\u6548\u8bc6\u522b\u5e76\u5229\u7528\u8de8\u57df\u56fe\u6570\u636e\u4e2d\u7684\u9886\u57df\u5dee\u5f02\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u9886\u57df\u77e5\u8bc6\u8fc1\u79fb\u663e\u8457\u63d0\u5347\u4e86\u56fe\u8868\u793a\u5b66\u4e60\u7684\u6548\u679c\uff0c\u63a8\u52a8\u4e86\u56fe\u57fa\u7840\u6a21\u578b\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.23014", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23014", "abs": "https://arxiv.org/abs/2506.23014", "authors": ["Wilder Baldwin", "Shashank Chintakuntla", "Shreyah Parajuli", "Ali Pourghasemi", "Ryan Shanz", "Sepideh Ghanavati"], "title": "Generating Privacy Stories From Software Documentation", "comment": "Accepted to RENext!'25 at the 33rd IEEE International Requirements\n  Engineering 2025 conference", "summary": "Research shows that analysts and developers consider privacy as a security\nconcept or as an afterthought, which may lead to non-compliance and violation\nof users' privacy. Most current approaches, however, focus on extracting legal\nrequirements from the regulations and evaluating the compliance of software and\nprocesses with them. In this paper, we develop a novel approach based on\nchain-of-thought prompting (CoT), in-context-learning (ICL), and Large Language\nModels (LLMs) to extract privacy behaviors from various software documents\nprior to and during software development, and then generate privacy\nrequirements in the format of user stories. Our results show that most commonly\nused LLMs, such as GPT-4o and Llama 3, can identify privacy behaviors and\ngenerate privacy user stories with F1 scores exceeding 0.8. We also show that\nthe performance of these models could be improved through parameter-tuning. Our\nfindings provide insight into using and optimizing LLMs for generating privacy\nrequirements given software documents created prior to or throughout the\nsoftware development lifecycle.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u7528LLMs\u65b0\u65b9\u6cd5\uff0c\u4ece\u5f00\u53d1\u6587\u6863\u4e2d\u81ea\u52a8\u751f\u6210\u5408\u89c4\u7684\u9690\u79c1\u9700\u6c42\uff0c\u4e3b\u6d41\u5927\u6a21\u578b\u6548\u679c\u51fa\u8272\uff08F1\u5927\u4e8e0.8\uff09\uff0c\u7ecf\u8c03\u4f18\u540e\u8868\u73b0\u66f4\u4f18\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u8fc7\u7a0b\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u8fc7\u5f80\u5206\u6790\u4eba\u5458\u548c\u5f00\u53d1\u4eba\u5458\u5e38\u5e38\u5c06\u9690\u79c1\u89c6\u4e3a\u5b89\u5168\u7684\u9644\u5c5e\u54c1\uff0c\u5bfc\u81f4\u8f6f\u4ef6\u4e0d\u5408\u89c4\u548c\u7528\u6237\u9690\u79c1\u88ab\u4fb5\u72af\u3002\u5f53\u524d\u65b9\u6cd5\u591a\u805a\u7126\u4e8e\u5408\u89c4\u68c0\u67e5\uff0c\u7f3a\u4e4f\u81ea\u52a8\u5316\u4ece\u5f00\u53d1\u6587\u6863\u4e2d\u63d0\u53d6\u9690\u79c1\u9700\u6c42\u7684\u673a\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8echain-of-thought prompting\uff08CoT\uff09\u3001in-context-learning\uff08ICL\uff09\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u4ece\u8f6f\u4ef6\u5f00\u53d1\u524d\u53ca\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u7684\u5404\u79cd\u6587\u6863\u4e2d\u63d0\u53d6\u9690\u79c1\u884c\u4e3a\uff0c\u5e76\u636e\u6b64\u751f\u6210\u7528\u6237\u6545\u4e8b\u683c\u5f0f\u7684\u9690\u79c1\u9700\u6c42\u3002", "result": "\u4e3b\u6d41LLM\uff08\u5982GPT-4o\u548cLlama 3\uff09\u80fd\u4ee5F1\u5206\u6570\u8d85\u8fc70.8\u7684\u51c6\u786e\u7387\u8bc6\u522b\u9690\u79c1\u884c\u4e3a\u5e76\u751f\u6210\u9690\u79c1\u7528\u6237\u6545\u4e8b\uff0c\u8c03\u6574\u6a21\u578b\u53c2\u6570\u540e\u8868\u73b0\u8fd8\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86LLMs\u5728\u751f\u6210\u8f6f\u4ef6\u5f00\u53d1\u76f8\u5173\u9690\u79c1\u9700\u6c42\u65b9\u9762\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u5e76\u4e3a\u5982\u4f55\u4f18\u5316LLMs\u4ee5\u9002\u5e94\u5f00\u53d1\u6587\u6863\u63d0\u51fa\u89c1\u89e3\u3002"}}
{"id": "2506.22516", "categories": ["cs.CL", "cs.AI", "cs.NE", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2506.22516", "abs": "https://arxiv.org/abs/2506.22516", "authors": ["Jingkai Li"], "title": "Can \"consciousness\" be observed from large language model (LLM) internal states? Dissecting LLM representations obtained from Theory of Mind test with Integrated Information Theory and Span Representation analysis", "comment": "Published as a journal paper at:\n  https://doi.org/10.1016/j.nlp.2025.100163", "summary": "Integrated Information Theory (IIT) provides a quantitative framework for\nexplaining consciousness phenomenon, positing that conscious systems comprise\nelements integrated through causal properties. We apply IIT 3.0 and 4.0 -- the\nlatest iterations of this framework -- to sequences of Large Language Model\n(LLM) representations, analyzing data derived from existing Theory of Mind\n(ToM) test results. Our study systematically investigates whether the\ndifferences of ToM test performances, when presented in the LLM\nrepresentations, can be revealed by IIT estimates, i.e., $\\Phi^{\\max}$ (IIT\n3.0), $\\Phi$ (IIT 4.0), Conceptual Information (IIT 3.0), and $\\Phi$-structure\n(IIT 4.0). Furthermore, we compare these metrics with the Span Representations\nindependent of any estimate for consciousness. This additional effort aims to\ndifferentiate between potential \"consciousness\" phenomena and inherent\nseparations within LLM representational space. We conduct comprehensive\nexperiments examining variations across LLM transformer layers and linguistic\nspans from stimuli. Our results suggest that sequences of contemporary\nTransformer-based LLM representations lack statistically significant indicators\nof observed \"consciousness\" phenomena but exhibit intriguing patterns under\n$\\textit{spatio}$-permutational analyses. The Appendix and code are available\nas Supplementary Materials at: https://doi.org/10.1016/j.nlp.2025.100163.", "AI": {"tldr": "\u4f5c\u8005\u5229\u7528IIT\u7406\u8bba\u5206\u6790LLM\u5728\u5fc3\u667a\u7406\u8bba\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u8868\u5f81\u5c1a\u65e0\u201c\u610f\u8bc6\u201d\u8ff9\u8c61\uff0c\u4f46\u8868\u73b0\u51fa\u6709\u8da3\u7684\u7ed3\u6784\u6027\u7279\u5f81\u3002", "motivation": "\u5f53\u524d\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u662f\u5426\u5177\u5907\u201c\u610f\u8bc6\u201d\u73b0\u8c61\u7684\u4e89\u8bba\u6301\u7eed\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u91cf\u5316\u8fd9\u4e00\u80fd\u529b\u7684\u5de5\u5177\u3002\u7efc\u5408\u4fe1\u606f\u7406\u8bba\uff08IIT\uff09\u662f\u89e3\u91ca\u610f\u8bc6\u73b0\u8c61\u7684\u5b9a\u91cf\u7406\u8bba\uff0c\u4f5c\u8005\u5e0c\u671b\u5229\u7528\u8be5\u7406\u8bba\u5bf9LLM\u7684\u8868\u73b0\u8fdb\u884c\u63a2\u7d22\uff0c\u68c0\u9a8c\u5176\u662f\u5426\u8868\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u610f\u8bc6\u7684\u5c5e\u6027\u3002", "method": "\u4f5c\u8005\u5e94\u7528IIT 3.0\u548c4.0\u7248\u672c\u4e2d\u7684\u76f8\u5173\u5ea6\u91cf\uff08\u5982\u03a6^max\u3001\u03a6\u3001\u6982\u5ff5\u4fe1\u606f\u3001\u548c\u03a6\u7ed3\u6784\uff09\u5bf9LLM\u5728\u7406\u8bba\u5fc3\u667a\uff08ToM\uff09\u6d4b\u8bd5\u4e2d\u7684\u8868\u5f81\u5e8f\u5217\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u4e0eLLM\u5185\u90e8\u8868\u5f81\u7a7a\u95f4\u7684Span Representations\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002\u6b64\u5916\uff0c\u5b9e\u9a8c\u8003\u5bdf\u4e86Transformer\u6a21\u578b\u4e0d\u540c\u5c42\u53ca\u8bed\u8a00\u533a\u95f4\u7684\u8868\u5f81\u53d8\u5316\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u73b0\u4ee3Transformer\u578bLLM\u7684\u8868\u5f81\u5e8f\u5217\u672a\u8868\u73b0\u51fa\u7edf\u8ba1\u5b66\u610f\u4e49\u4e0a\u7684\u201c\u610f\u8bc6\u201d\u6307\u6807\uff0c\u4f46\u5728\u7a7a\u95f4\u7f6e\u6362\u5206\u6790\u4e0b\uff0c\u6a21\u578b\u8868\u5f81\u51fa\u73b0\u4e86\u4e00\u4e9b\u6709\u8da3\u7684\u6a21\u5f0f\u3002", "conclusion": "\u76ee\u524dLLM\u7684\u8868\u5f81\u672a\u80fd\u901a\u8fc7IIT\u91cf\u5316\u51fa\u660e\u663e\u201c\u610f\u8bc6\u201d\u7279\u5f81\uff0c\u4f46\u7814\u7a76\u63ed\u793a\u4e86\u5176\u8868\u5f81\u7a7a\u95f4\u7684\u4e00\u4e9b\u6709\u8da3\u5206\u9694\u548c\u7ed3\u6784\uff0c\u5bf9\u7406\u89e3LLM\u5185\u90e8\u673a\u5236\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2506.23034", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23034", "abs": "https://arxiv.org/abs/2506.23034", "authors": ["Hao Yan", "Swapneel Suhas Vaidya", "Xiaokuan Zhang", "Ziyu Yao"], "title": "Guiding AI to Fix Its Own Flaws: An Empirical Study on LLM-Driven Secure Code Generation", "comment": null, "summary": "Large Language Models (LLMs) have become powerful tools for automated code\ngeneration. However, these models often overlook critical security practices,\nwhich can result in the generation of insecure code that contains\nvulnerabilities-weaknesses or flaws in the code that attackers can exploit to\ncompromise a system. However, there has been limited exploration of strategies\nto guide LLMs in generating secure code and a lack of in-depth analysis of the\neffectiveness of LLMs in repairing code containing vulnerabilities. In this\npaper, we present a comprehensive evaluation of state-of-the-art LLMs by\nexamining their inherent tendencies to produce insecure code, their capability\nto generate secure code when guided by self-generated vulnerability hints, and\ntheir effectiveness in repairing vulnerabilities when provided with different\nlevels of feedback. Our study covers both proprietary and open-weight models\nacross various scales and leverages established benchmarks to assess a wide\nrange of vulnerability types. Through quantitative and qualitative analyses, we\nreveal that although LLMs are prone to generating insecure code, advanced\nmodels can benefit from vulnerability hints and fine-grained feedback to avoid\nor fix vulnerabilities. We also provide actionable suggestions to developers to\nreduce vulnerabilities when using LLMs for code generation.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u5f53\u524dLLM\u751f\u6210\u4e0e\u4fee\u590d\u4ee3\u7801\u5b89\u5168\u6f0f\u6d1e\u80fd\u529b\uff0c\u53d1\u73b0\u7ec6\u81f4\u63d0\u793a\u548c\u53cd\u9988\u6709\u52a9\u4e8e\u63d0\u5347\u6a21\u578b\u5b89\u5168\u6027\uff0c\u5e76\u5411\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u5efa\u8bae\u3002", "motivation": "\u5f53\u524dLLM\u867d\u80fd\u5f3a\u5927\u5730\u81ea\u52a8\u751f\u6210\u4ee3\u7801\uff0c\u4f46\u5e38\u5ffd\u7565\u5b89\u5168\u95ee\u9898\uff0c\u6613\u751f\u6210\u542b\u53ef\u88ab\u653b\u51fb\u8005\u5229\u7528\u7684\u5b89\u5168\u6f0f\u6d1e\u4ee3\u7801\u3002\u6307\u5bfcLLM\u751f\u6210\u5b89\u5168\u4ee3\u7801\u548c\u4fee\u590d\u6f0f\u6d1e\u7684\u6709\u6548\u7b56\u7565\u7814\u7a76\u4e0d\u8db3\uff0c\u5b9e\u9645\u4fee\u590d\u6548\u679c\u7f3a\u4e4f\u7cfb\u7edf\u5206\u6790\u3002", "method": "\u8bc4\u4f30\u591a\u79cd\u4e3b\u6d41LLM\uff0c\u5305\u62ec\u5f00\u6e90\u548c\u4e13\u6709\u6a21\u578b\uff0c\u91c7\u7528\u57fa\u51c6\u6f0f\u6d1e\u6570\u636e\u96c6\uff0c\u6bd4\u8f83\u5176\u751f\u6210\u548c\u4fee\u590d\u5b89\u5168\u6f0f\u6d1e\u7684\u80fd\u529b\uff0c\u7ed3\u5408\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\u3002", "result": "\u5148\u8fdb\u7684LLM\u5982\u679c\u6709\u6f0f\u6d1e\u63d0\u793a\u548c\u8be6\u7ec6\u53cd\u9988\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u907f\u514d\u548c\u4fee\u590d\u5b89\u5168\u6f0f\u6d1e\uff1b\u540c\u65f6\u6307\u51fa\u76ee\u524dLLM\u81ea\u52a8\u4ee3\u7801\u751f\u6210\u4ecd\u5177\u5b89\u5168\u6311\u6218\u3002\u7ed9\u51fa\u5b9e\u9645\u51cf\u7f13\u4ee3\u7801\u6f0f\u6d1e\u7684\u65b9\u6cd5\u5efa\u8bae\u3002", "conclusion": "LLMs\u5728\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u65f6\u5bb9\u6613\u5bfc\u81f4\u4e0d\u5b89\u5168\u4ee3\u7801\uff0c\u4f46\u901a\u8fc7\u63d0\u793a\u548c\u7ec6\u81f4\u53cd\u9988\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5176\u5b89\u5168\u6027\u3002\u6587\u7ae0\u8fd8\u63d0\u51fa\u4e86\u5b9e\u9645\u5efa\u8bae\u5e2e\u5f00\u53d1\u8005\u51cf\u5c11\u6f0f\u6d1e\u3002"}}
{"id": "2506.22518", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22518", "abs": "https://arxiv.org/abs/2506.22518", "authors": ["Deyu Zou", "Yongqiang Chen", "Mufei Li", "Siqi Miao", "Chenxi Liu", "Bo Han", "James Cheng", "Pan Li"], "title": "Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation", "comment": null, "summary": "Graph-based retrieval-augmented generation (RAG) enables large language\nmodels (LLMs) to ground responses with structured external knowledge from\nup-to-date knowledge graphs (KGs) and reduce hallucinations. However, LLMs\noften rely on a weak retriever in graph-based RAG: I) Due to the lack of ground\ntruth, the retriever is often trained on weak supervision, which often\nintroduces spurious signals to the LLMs. II) Due to the abstraction of graph\ndata, the retrieved knowledge is often presented in unorganized forms. To\nmitigate the issue, we present Refined Graph-based RAG (ReG) to align weak\nretrievers to LLMs for graph-based RAG. Specifically, ReG incorporates LLM\nfeedback to get rid of spurious signals and improve the quality of the\nsupervision. Meanwhile, ReG introduces a structure-aware reorganization module\nto refactor the retrieval results into logically coherent evidence chains.\nExperiments on prominent benchmarks demonstrate that ReG significantly and\nconsistently brings improvements across different LLM backbones by up to 10%.\nThe improved supervision quality enables ReG to match the state-of-the-art\nperformance with 5% training data and to transfer to out-of-distribution KGs.\nNotably, when adopted to reasoning-based LLMs, ReG reduces the reasoning token\ncost by up to 30% and improves the performance by up to 4%.", "AI": {"tldr": "ReG\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165LLM\u53cd\u9988\u548c\u77e5\u8bc6\u7ed3\u6784\u91cd\u7ec4\uff0c\u6709\u6548\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31\u8f85\u52a9\u7684RAG\u68c0\u7d22\u3001\u751f\u6210\u8d28\u91cf\uff0c\u5728\u6570\u636e\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u5747\u8868\u73b0\u7a81\u51fa\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u56fe\u7684RAG\u7cfb\u7edf\u5728\u68c0\u7d22\u5668\u90e8\u5206\u8868\u73b0\u8f83\u5f31\uff1a\u4e00\u65b9\u9762\uff0c\u68c0\u7d22\u5668\u56e0\u7f3a\u4e4f\u771f\u5b9e\u6807\u7b7e\u5e38\u4f9d\u8d56\u5f31\u76d1\u7763\uff0c\u6613\u5f15\u5165\u566a\u58f0\u4fe1\u53f7\uff1b\u53e6\u4e00\u65b9\u9762\uff0c\u56fe\u6570\u636e\u62bd\u8c61\u5bfc\u81f4\u77e5\u8bc6\u68c0\u7d22\u7ed3\u679c\u5448\u73b0\u5f62\u5f0f\u6742\u4e71\u3002\u4f5c\u8005\u65e8\u5728\u89e3\u51b3\u8fd9\u4e24\u65b9\u9762\u7684\u95ee\u9898\uff0c\u63d0\u9ad8LLM\u5bf9\u7ed3\u6784\u5316\u77e5\u8bc6\u7684\u5229\u7528\u80fd\u529b\u3002", "method": "\u63d0\u51faReG\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165LLM\u53cd\u9988\u4ee5\u53bb\u9664\u865a\u5047\u4fe1\u53f7\u5e76\u63d0\u5347\u76d1\u7763\u8d28\u91cf\uff0c\u540c\u65f6\u52a0\u5165\u7ed3\u6784\u611f\u77e5\u91cd\u7ec4\u6a21\u5757\uff0c\u5c06\u68c0\u7d22\u5230\u7684\u77e5\u8bc6\u7ed3\u6784\u5316\u4e3a\u903b\u8f91\u8fde\u8d2f\u7684\u8bc1\u636e\u94fe\u3002", "result": "ReG\u5728\u591a\u4e2a\u4e3b\u6d41\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e26\u6765\u6700\u9ad810%\u7684\u6027\u80fd\u63d0\u5347\uff1b\u5373\u4f7f\u4ec5\u75285%\u7684\u8bad\u7ec3\u6570\u636e\u4e5f\u80fd\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u5e76\u53ef\u8fc1\u79fb\u81f3\u5206\u5e03\u5916\u77e5\u8bc6\u56fe\u8c31\u3002\u5bf9\u4e8e\u9700\u8981\u63a8\u7406\u7684LLM\uff0cReG\u53ef\u964d\u4f4e\u6700\u591a30%\u7684\u63a8\u7406Token\u6d88\u8017\uff0c\u6027\u80fd\u63d0\u5347\u8fbe4%\u3002", "conclusion": "ReG\uff08Refined Graph-based RAG\uff09\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684RAG\u7cfb\u7edf\u6027\u80fd\uff0c\u5bf9\u4e0d\u540c\u7684LLM\u9aa8\u5e72\u5747\u6709\u663e\u8457\u6548\u679c\u6539\u8fdb\uff0c\u5e76\u5728\u53ea\u7528\u6781\u5c11\u8bad\u7ec3\u6570\u636e\u548c\u9762\u5bf9\u5206\u5e03\u5916\u77e5\u8bc6\u56fe\u8c31\u65f6\u4e5f\u80fd\u4fdd\u6301\u4f18\u5f02\u8868\u73b0\u3002"}}
{"id": "2506.23063", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23063", "abs": "https://arxiv.org/abs/2506.23063", "authors": ["Guangfa Lyu", "Zhenzhong Cao", "Xiaofei Ren", "Fengyu Wang"], "title": "HF-DGF: Hybrid Feedback Guided Directed Grey-box Fuzzing", "comment": null, "summary": "Directed Grey-box Fuzzing (DGF) has emerged as a widely adopted technique for\ncrash reproduction and patch testing, leveraging its capability to precisely\nnavigate toward target locations and exploit vulnerabilities. However, current\nDGF tools are constrained by insufficient runtime feedback, limiting their\nefficiency in reaching targets and exploring state spaces. This study presents\nHF-DGF, a novel directed grey-box fuzzing framework. Its seed scheduling is\nguided by a hybrid feedback mechanism integrating control-flow distance,\nvalue-flow influence score, and slice coverage. To enable precise control-flow\ndistance feedback, we propose a backward-stepping algorithm to calculate basic\nblock-level seed distances on a virtual inter-procedural control-flow graph\n(ICFG). For effective state space exploration, we introduce value-flow\ninfluence and a corresponding metric, the value-flow influence score.\nAdditionally, to mitigate runtime overhead from hybrid feedback, we adopt a\nnovel selective instrumentation strategy. Evaluations on 41 real-world\nvulnerabilities show HF-DGF outperforms existing tools: it achieves crash\nreproduction 5.05 times faster than AFL, 5.79 times faster than AFLGo, 73.75\ntimes faster than WindRanger, 2.56 times faster than DAFL, and 8.45 times\nfaster than Beacon on average. Notably, when all fuzzers triggered crashes,\nHF-DGF exhibited the lowest code coverage, demonstrating superior\ndirectionality and efficiency. It also surpasses AFLGo, WindRanger, DAFL, and\nBeacon in static analysis efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6df7\u5408\u53cd\u9988\u5b9a\u5411\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6HF-DGF\uff0c\u901a\u8fc7\u66f4\u7cbe\u51c6\u548c\u591a\u6837\u5316\u7684\u53cd\u9988\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u5d29\u6e83\u590d\u73b0\u901f\u5ea6\u548c\u5bfc\u5411\u6027\uff0c\u5176\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5728\u540c\u7c7b\u5de5\u5177\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41\u7684\u5b9a\u5411\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\uff08DGF\uff09\u5de5\u5177\u7531\u4e8e\u8fd0\u884c\u65f6\u53cd\u9988\u4e0d\u8db3\uff0c\u96be\u4ee5\u9ad8\u6548\u5730\u5230\u8fbe\u76ee\u6807\u4f4d\u7f6e\u6216\u5168\u9762\u63a2\u7d22\u72b6\u6001\u7a7a\u95f4\uff0c\u9650\u5236\u4e86\u5176\u6f0f\u6d1e\u6316\u6398\u80fd\u529b\u3002\u63d0\u5347\u53cd\u9988\u7c92\u5ea6\u548c\u591a\u6837\u6027\u662f\u4e9f\u9700\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u5b9a\u5411\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6HF-DGF\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u6df7\u5408\u53cd\u9988\u673a\u5236\uff08\u7ed3\u5408\u63a7\u5236\u6d41\u8ddd\u79bb\u3001\u503c\u6d41\u5f71\u54cd\u5206\u6570\u548c\u5207\u7247\u8986\u76d6\uff09\u6307\u5bfc\u79cd\u5b50\u8c03\u5ea6\u3002\u4e3a\u5b9e\u73b0\u66f4\u7cbe\u51c6\u63a7\u5236\u6d41\u8ddd\u79bb\u53cd\u9988\uff0c\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u865a\u62df\u8de8\u8fc7\u7a0b\u63a7\u5236\u6d41\u56fe\u7684\u53cd\u5411\u6b65\u8fdb\u7b97\u6cd5\uff1b\u4e3a\u63d0\u5347\u72b6\u6001\u7a7a\u95f4\u63a2\u7d22\u6548\u7387\uff0c\u5f15\u5165\u503c\u6d41\u5f71\u54cd\u53ca\u5176\u5ea6\u91cf\u65b9\u6cd5\uff1b\u9488\u5bf9\u8fd0\u884c\u65f6\u5f00\u9500\uff0c\u91c7\u7528\u4e86\u9009\u62e9\u6027\u63d2\u6869\u7b56\u7565\u4f18\u5316\u6027\u80fd\u3002", "result": "\u572841\u4e2a\u771f\u5b9e\u6f0f\u6d1e\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cHF-DGF\u5728\u5d29\u6e83\u590d\u73b0\u901f\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\uff0c\u6bd4\u5982\u5206\u522b\u6bd4AFL\u3001AFLGo\u3001WindRanger\u3001DAFL\u3001Beacon\u5e73\u5747\u5feb5.05\u30015.79\u300173.75\u30012.56\u548c8.45\u500d\u3002\u5728\u5168\u90e8fuzzer\u5747\u80fd\u5f15\u53d1\u5d29\u6e83\u7684\u573a\u666f\u4e0b\uff0cHF-DGF\u5177\u5907\u6700\u4f4e\u7684\u4ee3\u7801\u8986\u76d6\u7387\uff0c\u8bc1\u660e\u5176\u5bfc\u5411\u6027\u548c\u6548\u7387\u66f4\u9ad8\u3002\u540c\u65f6\uff0c\u5176\u9759\u6001\u5206\u6790\u6548\u7387\u4e5f\u4f18\u4e8eAFLGo\u3001WindRanger\u3001DAFL\u548cBeacon\u3002", "conclusion": "HF-DGF\u901a\u8fc7\u878d\u5408\u591a\u7ef4\u5ea6\u53cd\u9988\u5e76\u4f18\u5316\u8c03\u5ea6\u548c\u63d2\u6869\uff0c\u5728\u6f0f\u6d1e\u9a8c\u8bc1\u4e0e\u590d\u73b0\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u4f18\u8d8a\u6027\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u6548\u548c\u5b9a\u5411\u6027\u65b9\u9762\uff0c\u5bf9\u63d0\u9ad8\u5b9a\u5411\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u7684\u5b9e\u9645\u6548\u80fd\u5177\u6709\u79ef\u6781\u610f\u4e49\u3002"}}
{"id": "2506.22529", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.22529", "abs": "https://arxiv.org/abs/2506.22529", "authors": ["Lu Kalkbrenner", "Veronika Solopova", "Steffen Zeiler", "Robert Nickel", "Dorothea Kolossa"], "title": "MisinfoTeleGraph: Network-driven Misinformation Detection for German Telegram Messages", "comment": null, "summary": "Connectivity and message propagation are central, yet often underutilized,\nsources of information in misinformation detection -- especially on poorly\nmoderated platforms such as Telegram, which has become a critical channel for\nmisinformation dissemination, namely in the German electoral context. In this\npaper, we introduce Misinfo-TeleGraph, the first German-language Telegram-based\ngraph dataset for misinformation detection. It includes over 5 million messages\nfrom public channels, enriched with metadata, channel relationships, and both\nweak and strong labels. These labels are derived via semantic similarity to\nfact-checks and news articles using M3-embeddings, as well as manual\nannotation. To establish reproducible baselines, we evaluate both text-only\nmodels and graph neural networks (GNNs) that incorporate message forwarding as\na network structure. Our results show that GraphSAGE with LSTM aggregation\nsignificantly outperforms text-only baselines in terms of Matthews Correlation\nCoefficient (MCC) and F1-score. We further evaluate the impact of subscribers,\nview counts, and automatically versus human-created labels on performance, and\nhighlight both the potential and challenges of weak supervision in this domain.\nThis work provides a reproducible benchmark and open dataset for future\nresearch on misinformation detection in German-language Telegram networks and\nother low-moderation social platforms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5fb7\u8bedTelegram\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u9996\u4e2a\u5927\u89c4\u6a21\u56fe\u6570\u636e\u96c6Misinfo-TeleGraph\uff0c\u5e76\u8bc1\u660e\u7ed3\u5408\u6d88\u606f\u4f20\u64ad\u7ed3\u6784\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u68c0\u6d4b\u6548\u679c\u4e0a\u4f18\u4e8e\u7eaf\u6587\u672c\u65b9\u6cd5\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\u548c\u6570\u636e\u652f\u6301\u3002", "motivation": "\u5728\u4f4e\u7ba1\u7406\uff08\u5982Telegram\uff09\u5e73\u53f0\u4e0a\u4f20\u64ad\u7684\u865a\u5047\u4fe1\u606f\u65e5\u76ca\u4e25\u91cd\uff0c\u800c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5bf9\u6d88\u606f\u4f20\u64ad\u7ed3\u6784\u4e0e\u793e\u4ea4\u8fde\u7ed3\u7684\u5229\u7528\u6709\u9650\uff0c\u7279\u522b\u662f\u7f3a\u4e4f\u9002\u7528\u4e8e\u5fb7\u8bed\u8bed\u5883\u7684\u6570\u636e\u96c6\u548c\u57fa\u51c6\u3002", "method": "1. \u6784\u5efa\u5305\u542b500\u591a\u4e07\u6761\u5fb7\u8bedTelegram\u516c\u5f00\u9891\u9053\u6d88\u606f\u7684\u56fe\u6570\u636e\u96c6\uff0c\u9644\u6709\u5143\u6570\u636e\u3001\u9891\u9053\u5173\u7cfb\u4e0e\u6807\u7b7e\u30022. \u6807\u7b7e\u6765\u6e90\u5305\u62ec\u57fa\u4e8eM3-embeddings\u5bf9\u6d88\u606f\u4e0e\u4e8b\u5b9e\u6838\u67e5/\u65b0\u95fb\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6\u8ba1\u7b97\uff08\u5f31\u6807\u7b7e\uff09\u53ca\u4eba\u5de5\u6807\u6ce8\uff08\u5f3a\u6807\u7b7e\uff09\u30023. \u5bf9\u6bd4\u7eaf\u6587\u672c\u6a21\u578b\u4e0e\u5f15\u5165\u6d88\u606f\u8f6c\u53d1\u56fe\u7ed3\u6784\u7684GNN\uff08GraphSAGE+LSTM\uff09\u8868\u73b0\uff0c\u5206\u6790\u8ba2\u9605\u6570\u3001\u6d4f\u89c8\u91cf\u53ca\u6807\u7b7e\u65b9\u5f0f\u5bf9\u68c0\u6d4b\u6548\u679c\u7684\u5f71\u54cd\u3002", "result": "\u4ee5MCC\u548cF1\u4e3a\u6307\u6807\uff0c\u7ed3\u5408\u56fe\u7ed3\u6784\u7684GraphSAGE+LSTM\u663e\u8457\u4f18\u4e8e\u6587\u672c\u57fa\u7ebf\uff1b\u9644\u52a0\u7279\u5f81\u5982\u8ba2\u9605\u6570\u3001\u6d4f\u89c8\u91cf\u3001\u5f31/\u5f3a\u6807\u7b7e\u5bf9\u68c0\u6d4b\u6027\u80fd\u4ea7\u751f\u4e0d\u540c\u5f71\u54cd\u3002\u8be5\u6570\u636e\u96c6\u548c\u57fa\u51c6\u63d0\u5347\u4e86\u5bf9\u6b64\u7c7b\u5e73\u53f0\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u65b0\u7684\u5fb7\u8bedTelegram\u56fe\u6570\u636e\u96c6Misinfo-TeleGraph\uff0c\u7528\u4e8e\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u57fa\u7840\u9a8c\u8bc1\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff08\u5c24\u5176\u662f\u7ed3\u5408\u6d88\u606f\u8f6c\u53d1\u7ed3\u6784\u7684GraphSAGE+LSTM\uff09\u76f8\u6bd4\u7eaf\u6587\u672c\u6a21\u578b\u5728\u68c0\u6d4b\u6548\u679c\u4e0a\u7684\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2506.23100", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23100", "abs": "https://arxiv.org/abs/2506.23100", "authors": ["Jiayi Zhang", "Kai Huang", "Jian Zhang", "Yang Liu", "Chunyang Chen"], "title": "Repair Ingredients Are All You Need: Improving Large Language Model-Based Program Repair via Repair Ingredients Search", "comment": "Accepted by ICSE 2026. Jiayi Zhang and Kai Huang contributed equally\n  to this work", "summary": "Automated Program Repair (APR) techniques aim to automatically fix buggy\nprograms. Among these, Large Language Model-based (LLM-based) approaches have\nshown great promise. Recent advances demonstrate that directly leveraging LLMs\ncan achieve leading results. However, these techniques remain suboptimal in\ngenerating contextually relevant and accurate patches, as they often overlook\nrepair ingredients crucial for practical program repair. In this paper, we\npropose ReinFix, a novel framework that enables LLMs to autonomously search for\nrepair ingredients throughout both the reasoning and solution phases of bug\nfixing. In the reasoning phase, ReinFix integrates static analysis tools to\nretrieve internal ingredients, such as variable definitions, to assist the LLM\nin root cause analysis when it encounters difficulty understanding the context.\nDuring the solution phase, when the LLM lacks experience in fixing specific\nbugs, ReinFix searches for external ingredients from historical bug fixes with\nsimilar bug patterns, leveraging both the buggy code and its root cause to\nguide the LLM in identifying appropriate repair actions, thereby increasing the\nlikelihood of generating correct patches. Evaluations on two popular benchmarks\n(Defects4J V1.2 and V2.0) demonstrate the effectiveness of our approach over\nSOTA baselines. Notably, ReinFix fixes 146 bugs, which is 32 more than the\nbaselines on Defects4J V1.2. On Defects4J V2.0, ReinFix fixes 38 more bugs than\nthe SOTA. Importantly, when evaluating on the recent benchmarks that are free\nof data leakage risk, ReinFix also maintains the best performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684ReinFix\u6846\u67b6\u901a\u8fc7\u96c6\u6210\u9759\u6001\u5206\u6790\u4e0e\u5386\u53f2\u4fee\u590d\u7ecf\u9a8c\uff0c\u8ba9LLM\u66f4\u6709\u6548\u751f\u6210\u6b63\u786e\u8865\u4e01\uff0c\u5927\u5e45\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u65b9\u6cd5\u5728\u8865\u4e01\u751f\u6210\u7684\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u548c\u51c6\u786e\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4e3b\u8981\u95ee\u9898\u5728\u4e8e\u5ffd\u7565\u4e86\u5b9e\u9645\u4fee\u590d\u4e2d\u5173\u952e\u7684\u201c\u4fee\u590d\u6210\u5206\u201d\u3002", "method": "\u63d0\u51fa\u4e86ReinFix\u6846\u67b6\uff0c\u8ba9LLM\u5728\u5206\u6790\u548c\u4fee\u590d\u65f6\u4e3b\u52a8\u641c\u7d22\u4e0e\u95ee\u9898\u76f8\u5173\u7684\u4fee\u590d\u6210\u5206\u3002\u63a8\u7406\u9636\u6bb5\u5229\u7528\u9759\u6001\u5206\u6790\u5de5\u5177\u68c0\u7d22\u5982\u53d8\u91cf\u5b9a\u4e49\u7b49\u5185\u90e8\u6210\u5206\uff0c\u8f85\u52a9LLM\u5b9a\u4f4d\u6839\u56e0\uff1b\u89e3\u51b3\u9636\u6bb5\u5219\u7ed3\u5408\u5386\u53f2\u4fee\u590d\u8bb0\u5f55\u4e2d\u540c\u7c7b\u578bbug\u7684\u4fee\u590d\u7ecf\u9a8c\uff0c\u8f85\u52a9\u6a21\u578b\u5236\u5b9a\u6b63\u786e\u4fee\u590d\u65b9\u6848\u3002", "result": "\u5728Defects4J V1.2\u4e0a\uff0cReinFix\u6bd4\u5f53\u524d\u6700\u4f18\u57fa\u7ebf\u65b9\u6cd5\u591a\u4fee\u590d\u4e8632\u4e2abug\uff0c\u603b\u8ba1\u4fee\u590d146\u4e2a\uff1b\u5728Defects4J V2.0\u4e0a\u591a\u4fee\u590d38\u4e2abug\u3002\u6b64\u5916\uff0c\u5728\u6ca1\u6709\u6570\u636e\u6cc4\u9732\u98ce\u9669\u7684\u65b0\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4e5f\u4fdd\u6301\u6700\u4f73\u8868\u73b0\u3002", "conclusion": "ReinFix\u80fd\u591f\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u7684\u6548\u679c\u548c\u8986\u76d6\u8303\u56f4\uff0c\u8d85\u8d8a\u73b0\u6709SOTA\u57fa\u7ebf\uff0c\u5728\u4e3b\u6d41\u6570\u636e\u96c6\u548c\u65e0\u6570\u636e\u6cc4\u6f0f\u57fa\u51c6\u6d4b\u8bd5\u4e0b\u5747\u53d6\u5f97\u4e86\u6700\u4f73\u7ed3\u679c\u3002"}}
{"id": "2506.22598", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.22598", "abs": "https://arxiv.org/abs/2506.22598", "authors": ["Nicholas Edwards", "Yukyung Lee", "Yujun", "Mao", "Yulu Qin", "Sebastian Schuster", "Najoung Kim"], "title": "RExBench: Can coding agents autonomously implement AI research extensions?", "comment": null, "summary": "Agents based on Large Language Models (LLMs) have shown promise for\nperforming sophisticated software engineering tasks autonomously. In addition,\nthere has been progress towards developing agents that can perform parts of the\nresearch pipeline in machine learning and the natural sciences. We argue that\nresearch extension and its implementation is a critical capability for such\nsystems, and introduce RExBench to support the evaluation of this capability.\nRExBench is a benchmark consisting of 12 realistic research experiment\nimplementation tasks that aim to investigate research hypotheses that have not\npreviously been implemented. Each task is set up as an extension to an existing\nresearch paper and codebase, accompanied by domain expert-written instructions.\nRExBench is robust to data contamination, and supports an automatic evaluation\ninfrastructure that executes agent outputs to determine whether the success\ncriteria are met. We use this benchmark to evaluate nine LLM agents implemented\nusing three different frameworks: aider, Claude Code, and OpenHands. We find\nthat all agents evaluated fail to autonomously implement the majority of the\nextensions. Although the success rate improves with additional human-written\nhints, the best performance under this setting remains below 40%. This\nindicates that current agents are still short of being able to handle realistic\nresearch extension tasks without substantial human guidance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRExBench\u57fa\u6e96\uff0c\u7528\u65bc\u8a55\u6e2cLLM\u667a\u80fd\u9ad4\u7684\u7814\u7a76\u64f4\u5c55\u8207\u5be6\u4f5c\u80fd\u529b\u3002\u4e5d\u7a2e\u4e3b\u6d41LLM\u667a\u80fd\u9ad4\u5747\u7121\u6cd5\u5728\u7121\u4eba\u5de5\u5927\u91cf\u8f14\u52a9\u4e0b\uff0c\u81ea\u4e3b\u5b8c\u6210\u591a\u6578\u7814\u7a76\u64f4\u5c55\u4efb\u52d9\uff0c\u8aaa\u660e\u7576\u524d\u6280\u8853\u4ecd\u96e2\u81ea\u4e3b\u79d1\u7814\u61c9\u7528\u6709\u660e\u986f\u5dee\u8ddd\u3002", "motivation": "\u8fd1\u5e74\u4f86\u57fa\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b(LLMs)\u7684\u667a\u80fd\u9ad4\u5df2\u80fd\u81ea\u52d5\u57f7\u884c\u8907\u96dc\u7684\u8edf\u9ad4\u5de5\u7a0b\u4efb\u52d9\uff0c\u4e14\u5728\u6a5f\u5668\u5b78\u7fd2\u548c\u81ea\u7136\u79d1\u5b78\u7684\u7814\u7a76\u6d41\u7a0b\u81ea\u52d5\u5316\u65b9\u9762\u4e5f\u6709\u9032\u5c55\u3002\u7136\u800c\uff0c\u8b93\u9019\u985e\u7cfb\u7d71\u80fd\u81ea\u52d5\u64f4\u5c55\u73fe\u6709\u7814\u7a76\u4e26\u5be6\u4f5c\u5176\u60f3\u6cd5\uff0c\u662f\u5176\u9032\u4e00\u6b65\u767c\u5c55\u7684\u95dc\u9375\u80fd\u529b\u3002\u73fe\u6709\u81ea\u52d5\u5316\u5de5\u5177\u5728\u7814\u7a76\u64f4\u5c55\u4efb\u52d9\u7684\u80fd\u529b\u5c1a\u672a\u6709\u7cfb\u7d71\u6027\u8a55\u4f30\u6a19\u6e96\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u91dd\u5c0d\u9019\u4e00\u554f\u984c\u63d0\u51fa\u65b0\u57fa\u6e96\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u540d\u70baRExBench\u7684\u65b0\u57fa\u6e96\u96c6\u3002\u8a72\u57fa\u6e96\u96c6\u5305\u542b12\u500b\u771f\u5be6\u4e16\u754c\u7684\u7814\u7a76\u5be6\u9a57\u64f4\u5c55\u4efb\u52d9\uff0c\u6bcf\u500b\u4efb\u52d9\u90fd\u662f\u5c0d\u73fe\u6709\u8ad6\u6587\u548c\u4ee3\u78bc\u5eab\u7684\u5ef6\u4f38\uff0c\u4e26\u7531\u9818\u57df\u5c08\u5bb6\u64b0\u5beb\u660e\u78ba\u7684\u64cd\u4f5c\u8aaa\u660e\u3002\u9019\u4e00\u57fa\u6e96\u96c6\u5c0d\u6578\u64da\u6c61\u67d3\u5177\u6709\u9b6f\u68d2\u6027\uff0c\u4e26\u4e14\u914d\u5099\u81ea\u52d5\u8a55\u4f30\u6a5f\u5236\uff0c\u80fd\u81ea\u52d5\u57f7\u884c\u667a\u80fd\u9ad4\u8f38\u51fa\u7684\u7d50\u679c\u4ee5\u5224\u65b7\u5176\u662f\u5426\u9054\u5230\u6210\u529f\u6a19\u6e96\u3002\u7528\u8a72\u57fa\u6e96\u96c6\u4f86\u6e2c\u8a55\u4e86\u4e09\u7a2e\u6846\u67b6\u4e0b\uff08aider\u3001Claude Code\u3001OpenHands\uff09\u5171\u4e5d\u500bLLM\u667a\u80fd\u9ad4\u3002", "result": "\u5be6\u9a57\u767c\u73fe\uff0c\u6240\u6709\u53d7\u6e2c\u7684\u667a\u80fd\u9ad4\u5728\u7d55\u5927\u591a\u6578\u4efb\u52d9\u4e0a\u90fd\u7121\u6cd5\u81ea\u4e3b\u5b8c\u6210\u7814\u7a76\u64f4\u5c55\u5be6\u4f5c\u3002\u5373\u4fbf\u5728\u589e\u5f37\u4eba\u70ba\u63d0\u793a\u7684\u8f14\u52a9\u4e0b\uff0c\u6700\u4f73\u8868\u73fe\u4ecd\u4f4e\u65bc40%\u7684\u6210\u529f\u7387\u3002\u9019\u8aaa\u660e\u73fe\u6709LLM\u667a\u80fd\u9ad4\u8ddd\u96e2\u7121\u9700\u5927\u5e45\u4eba\u529b\u5e72\u9810\uff0c\u7368\u7acb\u8655\u7406\u73fe\u5be6\u7814\u7a76\u64f4\u5c55\u4efb\u52d9\u9084\u6709\u660e\u986f\u5dee\u8ddd\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u91dd\u5c0d\u7814\u7a76\u64f4\u5c55\u80fd\u529b\u7684\u6a19\u6e96\u5316\u8a55\u6e2c\u57fa\u6e96RExBench\uff0c\u4e26\u5be6\u8b49\u7576\u524dLLM\u667a\u80fd\u9ad4\u5c1a\u7121\u6cd5\u81ea\u4e3b\u61c9\u5c0d\u771f\u5be6\u4e14\u8907\u96dc\u7684\u7814\u7a76\u64f4\u5c55\u9700\u6c42\uff0c\u5c55\u793a\u4e86\u8a72\u9818\u57df\u4ecd\u6709\u5f88\u5927\u63d0\u5347\u7a7a\u9593\u3002\u8a72\u57fa\u6e96\u53ef\u4fc3\u9032\u672a\u4f86\u76f8\u95dc\u6280\u8853\u7684\u767c\u5c55\u8207\u8a55\u4f30\u3002"}}
{"id": "2506.23234", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23234", "abs": "https://arxiv.org/abs/2506.23234", "authors": ["Peerachai Banyongrakkul", "Mansooreh Zahedi", "Patanamon Thongtanunam", "Christoph Treude", "Haoyu Gao"], "title": "From Release to Adoption: Challenges in Reusing Pre-trained AI Models for Downstream Developers", "comment": "Recently accepted at ICSME 2025", "summary": "Pre-trained models (PTMs) have gained widespread popularity and achieved\nremarkable success across various fields, driven by their groundbreaking\nperformance and easy accessibility through hosting providers. However, the\nchallenges faced by downstream developers in reusing PTMs in software systems\nare less explored. To bridge this knowledge gap, we qualitatively created and\nanalyzed a dataset of 840 PTM-related issue reports from 31 OSS GitHub\nprojects. We systematically developed a comprehensive taxonomy of PTM-related\nchallenges that developers face in downstream projects. Our study identifies\nseven key categories of challenges that downstream developers face in reusing\nPTMs, such as model usage, model performance, and output quality. We also\ncompared our findings with existing taxonomies. Additionally, we conducted a\nresolution time analysis and, based on statistical tests, found that\nPTM-related issues take significantly longer to be resolved than issues\nunrelated to PTMs, with significant variation across challenge categories. We\ndiscuss the implications of our findings for practitioners and possibilities\nfor future research.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u5f00\u6e90\u9879\u76ee\u4e2d\u4e0e\u9884\u8bad\u7ec3\u6a21\u578b\u76f8\u5173\u7684\u95ee\u9898\u62a5\u544a\uff0c\u603b\u7ed3\u4e86\u5f00\u53d1\u8005\u5e38\u89c1\u7684\u4e03\u5927\u6311\u6218\u7c7b\u522b\uff0c\u5e76\u53d1\u73b0\u6b64\u7c7b\u95ee\u9898\u7684\u89e3\u51b3\u65f6\u95f4\u666e\u904d\u8f83\u957f\uff0c\u5bf9\u540e\u7eedPTM\u590d\u7528\u53ca\u6539\u8fdb\u5b9e\u8df5\u5177\u6709\u6307\u5bfc\u610f\u4e49\u3002", "motivation": "\u5c3d\u7ba1\u9884\u8bad\u7ec3\u6a21\u578b\u56e0\u5176\u51fa\u8272\u6027\u80fd\u548c\u6613\u83b7\u5f97\u6027\u88ab\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u5173\u4e8e\u4e0b\u6e38\u5f00\u53d1\u8005\u5728\u5b9e\u9645\u8f6f\u4ef6\u7cfb\u7edf\u590d\u7528PTMs\u65f6\u9047\u5230\u7684\u5177\u4f53\u6311\u6218\u548c\u5b9e\u9645\u969c\u788d\u5374\u8f83\u5c11\u88ab\u7cfb\u7edf\u6027\u63a2\u8ba8\u3002\u586b\u8865\u77e5\u8bc6\u7a7a\u767d\uff0c\u5bf9\u5b9e\u8df5\u4e0e\u7814\u7a76\u5747\u6709\u610f\u4e49\u3002", "method": "\u5b9a\u6027\u5730\u521b\u5efa\u5e76\u5206\u6790\u4e86\u6765\u81ea31\u4e2a\u5f00\u6e90GitHub\u9879\u76ee\u7684840\u4efd\u4e0ePTM\u76f8\u5173\u7684\u95ee\u9898\u62a5\u544a\uff0c\u5e76\u7cfb\u7edf\u6027\u5730\u5f00\u53d1\u4e86PTM\u76f8\u5173\u6311\u6218\u7684\u5206\u7c7b\u6cd5\uff0c\u540c\u65f6\u5bf9\u6bd4\u4e86\u5df2\u6709\u7684\u76f8\u5173\u5206\u7c7b\u6cd5\u3002\u91c7\u7528\u7edf\u8ba1\u65b9\u6cd5\u5206\u6790\u4e86\u4e0d\u540c\u7c7b\u578b\u95ee\u9898\u7684\u89e3\u51b3\u65f6\u957f\u3002", "result": "\u8bc6\u522b\u5e76\u603b\u7ed3\u4e86\u4e0b\u6e38\u5f00\u53d1\u8005\u5728\u590d\u7528PTMs\u65f6\u9762\u4e34\u7684\u4e03\u5927\u4e3b\u8981\u6311\u6218\u7c7b\u522b\uff08\u5982\u6a21\u578b\u4f7f\u7528\u3001\u6a21\u578b\u6027\u80fd\u3001\u8f93\u51fa\u8d28\u91cf\u7b49\uff09\uff0c\u5e76\u53d1\u73b0PTM\u76f8\u5173\u95ee\u9898\u7684\u89e3\u51b3\u65f6\u95f4\u663e\u8457\u957f\u4e8e\u975ePTM\u95ee\u9898\uff0c\u4e0d\u540c\u6311\u6218\u7c7b\u522b\u7684\u65f6\u957f\u6709\u660e\u663e\u5dee\u5f02\u3002", "conclusion": "\u4e0b\u6e38\u5f00\u53d1\u8005\u5728\u590d\u7528\u9884\u8bad\u7ec3\u6a21\u578b\uff08PTMs\uff09\u65f6\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u5e76\u4e14\u76f8\u5173\u95ee\u9898\u7684\u89e3\u51b3\u5468\u671f\u666e\u904d\u8f83\u957f\uff0c\u5404\u95ee\u9898\u7c7b\u522b\u95f4\u7684\u89e3\u51b3\u65f6\u957f\u4e5f\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002"}}
{"id": "2506.22623", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22623", "abs": "https://arxiv.org/abs/2506.22623", "authors": ["Badr Youbi Idrissi", "Monica Millunzi", "Amelia Sorrenti", "Lorenzo Baraldi", "Daryna Dementieva"], "title": "Temperature Matters: Enhancing Watermark Robustness Against Paraphrasing Attacks", "comment": null, "summary": "In the present-day scenario, Large Language Models (LLMs) are establishing\ntheir presence as powerful instruments permeating various sectors of society.\nWhile their utility offers valuable support to individuals, there are multiple\nconcerns over potential misuse. Consequently, some academic endeavors have\nsought to introduce watermarking techniques, characterized by the inclusion of\nmarkers within machine-generated text, to facilitate algorithmic\nidentification. This research project is focused on the development of a novel\nmethodology for the detection of synthetic text, with the overarching goal of\nensuring the ethical application of LLMs in AI-driven text generation. The\ninvestigation commences with replicating findings from a previous baseline\nstudy, thereby underscoring its susceptibility to variations in the underlying\ngeneration model. Subsequently, we propose an innovative watermarking approach\nand subject it to rigorous evaluation, employing paraphrased generated text to\nasses its robustness. Experimental results highlight the robustness of our\nproposal compared to the~\\cite{aarson} watermarking method.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u5728\u6ee5\u7528\u95ee\u9898\uff0c\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u66f4\u9c81\u68d2\u7684\u6c34\u5370\u68c0\u6d4b\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u63d0\u5347AI\u751f\u6210\u6587\u672c\u7684\u53ef\u8ffd\u6eaf\u6027\u548c\u4f26\u7406\u5e94\u7528\u4fdd\u969c\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u793e\u4f1a\u5404\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5bf9\u5176\u6f5c\u5728\u6ee5\u7528\u7684\u62c5\u5fe7\u9010\u6e10\u589e\u591a\u3002\u4eba\u5de5\u751f\u6210\u4e0e\u673a\u5668\u751f\u6210\u6587\u672c\u96be\u4ee5\u533a\u5206\uff0c\u5bb9\u6613\u5e26\u6765\u4f26\u7406\u548c\u5b89\u5168\u98ce\u9669\u3002\u672c\u6587\u52a8\u673a\u5728\u4e8e\u5f00\u53d1\u80fd\u591f\u68c0\u6d4b\u5408\u6210\u6587\u672c\u7684\u65b0\u65b9\u6cd5\uff0c\u4ee5\u4fdd\u969cLLM\u9a71\u52a8\u6587\u672c\u751f\u6210\u8fc7\u7a0b\u7684\u4f26\u7406\u6027\u3002", "method": "\u7814\u7a76\u9996\u5148\u590d\u73b0\u4e86\u5df2\u6709\u57fa\u7ebf\u7814\u7a76\u7684\u53d1\u73b0\uff0c\u9a8c\u8bc1\u5f53\u524d\u65b9\u6cd5\u5bf9\u5e95\u5c42\u751f\u6210\u6a21\u578b\u53d8\u5316\u7684\u654f\u611f\u6027\u3002\u968f\u540e\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u521b\u65b0\u6027\u7684\u6c34\u5370\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5bf9\u751f\u6210\u6587\u672c\u8fdb\u884c\u590d\u8ff0\u7b49\u65b9\u5f0f\uff0c\u4e25\u683c\u8bc4\u4f30\u5176\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f5c\u8005\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u9c81\u68d2\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684~\\cite{aarson}\u6c34\u5370\u65b9\u6cd5\uff0c\u80fd\u591f\u66f4\u6709\u6548\u68c0\u6d4b\u5408\u6210\u6587\u672c\uff0c\u5373\u4f7f\u5728\u9762\u5bf9\u88ab\u590d\u8ff0\u4fee\u6539\u7684\u60c5\u51b5\u4e0b\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6587\u672c\u6c34\u5370\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u8bc6\u522bAI\u751f\u6210\u6587\u672c\u65b9\u9762\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u9c81\u68d2\uff0c\u4e3aLLM\u6587\u672c\u68c0\u6d4b\u4e0e\u4f26\u7406\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u529b\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2506.22644", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2506.22644", "abs": "https://arxiv.org/abs/2506.22644", "authors": ["Chase Fensore", "Kaustubh Dhole", "Joyce C Ho", "Eugene Agichtein"], "title": "Evaluating Hybrid Retrieval Augmented Generation using Dynamic Test Sets: LiveRAG Challenge", "comment": "4 pages, 3 tables, 2 figures. Accepted at the SIGIR LiveRAG Workshop\n  2025 (Submission 2664)", "summary": "We present our submission to the LiveRAG Challenge 2025, which evaluates\nretrieval-augmented generation (RAG) systems on dynamic test sets using the\nFineWeb-10BT corpus. Our final hybrid approach combines sparse (BM25) and dense\n(E5) retrieval methods and then aims to generate relevant and faithful answers\nwith Falcon3-10B-Instruct. Through systematic evaluation on 200 synthetic\nquestions generated with DataMorgana across 64 unique question-user\ncombinations, we demonstrate that neural re-ranking with RankLLaMA improves MAP\nfrom 0.523 to 0.797 (52% relative improvement) but introduces prohibitive\ncomputational costs (84s vs 1.74s per question). While DSPy-optimized prompting\nstrategies achieved higher semantic similarity (0.771 vs 0.668), their 0%\nrefusal rates raised concerns about over-confidence and generalizability. Our\nsubmitted hybrid system without re-ranking achieved 4th place in faithfulness\nand 11th place in correctness among 25 teams. Analysis across question\ncategories reveals that vocabulary alignment between questions and documents\nwas the strongest predictor of performance on our development set, with\ndocument-similar phrasing improving cosine similarity from 0.562 to 0.762.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u7ed3\u5408\u7a00\u758f\u4e0e\u7a20\u5bc6\u68c0\u7d22\u7684\u751f\u6210\u7cfb\u7edf\uff0c\u5728\u5927\u578b\u52a8\u6001\u6d4b\u8bd5\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u795e\u7ecf\u91cd\u6392\u5e8f\u548c\u63d0\u793a\u5de5\u7a0b\u5e26\u6765\u63d0\u5347\u4f46\u5728\u6548\u7387\u53ca\u6cdb\u5316\u6027\u95f4\u9700\u6743\u8861\uff0c\u8bcd\u6c47-\u6587\u672c\u5bf9\u9f50\u6027\u4e3a\u5173\u952e\u5f71\u54cd\u56e0\u7d20\u3002", "motivation": "\u5728\u4e0d\u65ad\u53d8\u5316\u7684\u68c0\u7d22-\u751f\u6210\u73af\u5883\u4e2d\uff0c\u63d0\u5347RAG\u7cfb\u7edf\u5728\u5927\u89c4\u6a21\u8bed\u6599\u4e0b\u7684\u76f8\u5173\u6027\u4e0e\u5fe0\u5b9e\u5ea6\uff0c\u540c\u65f6\u63a2\u7d22\u4e0d\u540c\u6280\u672f\u8def\u5f84\u5bf9\u68c0\u7d22\u4e0e\u751f\u6210\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "method": "\u7ed3\u5408\u7a00\u758f\uff08BM25\uff09\u548c\u7a20\u5bc6\uff08E5\uff09\u68c0\u7d22\uff0c\u57fa\u4e8eFalcon3-10B-Instruct\u751f\u6210\u7b54\u6848\uff0c\u5e76\u7efc\u5408\u91c7\u7528\u795e\u7ecf\u91cd\u6392\u5e8f\uff08RankLLaMA\uff09\u548cDSPy\u4f18\u5316\u63d0\u793a\uff0c\u8fdb\u884c\u7cfb\u7edf\u6027\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u795e\u7ecf\u91cd\u6392\u5e8f\u663e\u8457\u63d0\u5347MAP\u4f46\u8ba1\u7b97\u6d88\u8017\u5927\uff0c\u63d0\u793a\u4f18\u5316\u63d0\u5347\u8bed\u4e49\u5f97\u5206\u4f46\u62d2\u7b54\u7387\u4e3a\u96f6\u5e26\u6765\u6cdb\u5316\u6027\u7591\u8651\uff1b\u6700\u7ec8\u6df7\u5408\u7cfb\u7edf\u5728faithfulness\u6392\u540d\u7b2c4\u3001correctness\u7b2c11\uff1b\u8bcd\u6c47\u5bf9\u9f50\u5bf9\u6027\u80fd\u5f71\u54cd\u6700\u5927\u3002", "conclusion": "\u6df7\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u5728\u52a8\u6001\u68c0\u7d22\u573a\u666f\u4e0b\u6027\u80fd\u8868\u73b0\u7a33\u5b9a\uff0c\u8bed\u4e49\u4e0e\u5b57\u9762\u5bf9\u9f50\u5ea6\u662f\u5f71\u54cd\u6548\u679c\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4f46\u90e8\u5206\u4f18\u5316\u65b9\u6cd5\u5b58\u5728\u5b9e\u9645\u5e94\u7528\u95e8\u69db\u3002"}}
{"id": "2506.23534", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23534", "abs": "https://arxiv.org/abs/2506.23534", "authors": ["Siyu Chen", "Jiongyi Yang", "Xiang Chen", "Menglin Zheng", "Minnan Wei", "Xiaolin Ju"], "title": "Improving vulnerability type prediction and line-level detection via adversarial training-based data augmentation and multi-task learning", "comment": null, "summary": "Context: Software vulnerabilities pose a significant threat to modern\nsoftware systems, as evidenced by the growing number of reported\nvulnerabilities and cyberattacks. These escalating trends underscore the urgent\nneed for effective approaches that can automatically detect and understand\nsoftware vulnerabilities. Objective: However, the scarcity of labeled samples\nand the class imbalance issue in vulnerability datasets present significant\nchallenges for both Vulnerability Type Prediction (VTP) and Line-level\nVulnerability Detection (LVD), especially for rare yet critical vulnerability\ntypes. Moreover, most existing studies treat VTP and LVD as independent tasks,\noverlooking their inherent correlation, which limits the potential to leverage\nshared semantic patterns across tasks. Methods: To address these limitations,\nwe propose a unified approach that integrates Embedding-Layer Driven\nAdversarial Training (EDAT) with Multi-task Learning (MTL). Specifically, EDAT\nenhances model robustness by introducing adversarial perturbations to\nidentifier embeddings, guided by semantic importance. Meanwhile, MTL improves\noverall performance by leveraging shared representations and inter-task\ncorrelations between VTP and LVD. Results: Extensive experiments demonstrate\nthat our proposed approach outperforms state-of-the-art baselines on both VTP\nand LVD tasks. For VTP, it yields notable improvements in accuracy, precision,\nrecall, and F1-score, particularly in identifying rare vulnerability types.\nSimilarly, for LVD, our approach enhances line-level detection accuracy while\nsignificantly reducing false positives. Conclusion: Our study demonstrates that\ncombining EDAT with MTL provides a unified solution that improves performance\non both tasks and warrants further investigation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEDAT+MTL\u8054\u5408\u65b9\u6cd5\uff0c\u5728\u6837\u672c\u7a00\u7f3a\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u60c5\u5f62\u4e0b\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6f0f\u6d1e\u7c7b\u578b\u9884\u6d4b\u53ca\u884c\u7ea7\u68c0\u6d4b\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5bf9\u7a00\u6709\u6f0f\u6d1e\u3002\u65b9\u6cd5\u7b80\u5355\u6709\u6548\uff0c\u5b9e\u9a8c\u7ed3\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u8f6f\u4ef6\u7cfb\u7edf\u9762\u4e34\u8d8a\u6765\u8d8a\u591a\u7684\u5b89\u5168\u6f0f\u6d1e\u5a01\u80c1\uff0c\u5c24\u5176\u662f\u5728\u6837\u672c\u532e\u4e4f\u3001\u7c7b\u522b\u6781\u5ea6\u4e0d\u5e73\u8861\u7684\u6570\u636e\u4e0b\uff0c\u5e38\u89c1\u7684\u6f0f\u6d1e\u7c7b\u578b\u9884\u6d4b\uff08VTP\uff09\u548c\u4ee3\u7801\u884c\u7ea7\u522b\u6f0f\u6d1e\u68c0\u6d4b\uff08LVD\uff09\u6548\u679c\u4e00\u822c\u3002\u6b64\u5916\uff0c\u76f8\u5173\u7814\u7a76\u5f80\u5f80\u5c06\u4e24\u7c7b\u4efb\u52a1\u5272\u88c2\uff0c\u5ffd\u7565\u4e86\u4e8c\u8005\u4e4b\u95f4\u7684\u5185\u5728\u8054\u7cfb\uff0c\u9650\u5236\u4e86\u6a21\u578b\u6027\u80fd\u63d0\u5347\u3002", "method": "\u672c\u6587\u63d0\u51fa\u5c06Embedding-Layer Driven Adversarial Training\uff08EDAT\uff09\u4e0e\u591a\u4efb\u52a1\u5b66\u4e60\uff08MTL\uff09\u7ed3\u5408\u7684\u7edf\u4e00\u65b9\u6cd5\u3002EDAT\u901a\u8fc7\u5bf9\u6807\u8bc6\u7b26\u5d4c\u5165\u5f15\u5165\u57fa\u4e8e\u8bed\u4e49\u91cd\u8981\u6027\u7684\u5bf9\u6297\u6270\u52a8\uff0c\u63d0\u9ad8\u6a21\u578b\u9c81\u68d2\u6027\uff1bMTL\u901a\u8fc7\u5171\u4eab\u8868\u793a\u53ca\u4efb\u52a1\u5173\u7cfb\uff0c\u63d0\u5347VTP\u548cLVD\u7efc\u5408\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u65b9\u6cd5\u5728VTP\u548cLVD\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002VTP\u65b9\u9762\uff0c\u5404\u9879\u6307\u6807\uff08\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\uff09\u663e\u8457\u63d0\u5347\uff0c\u5c24\u5176\u662f\u7a00\u6709\u6f0f\u6d1e\u7c7b\u578b\u68c0\u6d4b\u3002LVD\u65b9\u9762\uff0c\u63d0\u5347\u4e86\u884c\u7ea7\u68c0\u6d4b\u51c6\u786e\u7387\u5e76\u663e\u8457\u51cf\u5c11\u8bef\u62a5\u3002", "conclusion": "\u5c06EDAT\u4e0eMTL\u7ed3\u5408\uff0c\u4e3a\u6f0f\u6d1e\u7c7b\u578b\u9884\u6d4b\u548c\u884c\u7ea7\u6f0f\u6d1e\u68c0\u6d4b\u4efb\u52a1\u63d0\u4f9b\u4e86\u7edf\u4e00\u3001\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u9a8c\u6548\u679c\u7a81\u51fa\uff0c\u503c\u5f97\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2506.22679", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.22679", "abs": "https://arxiv.org/abs/2506.22679", "authors": ["Ankush Raut", "Projna Paromita", "Sydney Begerowski", "Suzanne Bell", "Theodora Chaspari"], "title": "Assessing the feasibility of Large Language Models for detecting micro-behaviors in team interactions during space missions", "comment": "5 pages, 4 figures. Accepted to Interspeech 2025", "summary": "We explore the feasibility of large language models (LLMs) in detecting\nsubtle expressions of micro-behaviors in team conversations using transcripts\ncollected during simulated space missions. Specifically, we examine zero-shot\nclassification, fine-tuning, and paraphrase-augmented fine-tuning with\nencoder-only sequence classification LLMs, as well as few-shot text generation\nwith decoder-only causal language modeling LLMs, to predict the micro-behavior\nassociated with each conversational turn (i.e., dialogue). Our findings\nindicate that encoder-only LLMs, such as RoBERTa and DistilBERT, struggled to\ndetect underrepresented micro-behaviors, particularly discouraging speech, even\nwith weighted fine-tuning. In contrast, the instruction fine-tuned version of\nLlama-3.1, a decoder-only LLM, demonstrated superior performance, with the best\nmodels achieving macro F1-scores of 44% for 3-way classification and 68% for\nbinary classification. These results have implications for the development of\nspeech technologies aimed at analyzing team communication dynamics and\nenhancing training interventions in high-stakes environments such as space\nmissions, particularly in scenarios where text is the only accessible data.", "AI": {"tldr": "RoBERTa\u7b49\u7f16\u7801\u5668\u6a21\u578b\u5bf9\u56e2\u961f\u5fae\u884c\u4e3a\u68c0\u6d4b\u6548\u679c\u6709\u9650\uff0c\u6307\u4ee4\u5fae\u8c03Llama-3.1\u7b49\u89e3\u7801\u5668\u5927\u6a21\u578b\u8868\u73b0\u66f4\u4f73\uff0c\u5bf9\u592a\u7a7a\u4efb\u52a1\u7b49\u9700\u6587\u672c\u5206\u6790\u573a\u666f\u5177\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u56e2\u961f\u6c9f\u901a\u4e2d\u7684\u5fae\u884c\u4e3a\uff08\u5982\u9f13\u52b1\u3001\u529d\u963b\u7b49\uff09\u5bf9\u4e8e\u9ad8\u98ce\u9669\u73af\u5883\uff08\u5982\u592a\u7a7a\u4efb\u52a1\uff09\u4e2d\u7684\u56e2\u961f\u52a8\u6001\u5206\u6790\u53ca\u8bad\u7ec3\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8fd9\u4e9b\u5fae\u884c\u4e3a\u5f80\u5f80\u8868\u73b0\u5728\u5bf9\u8bdd\u7ec6\u8282\u4e2d\u4e14\u96be\u4ee5\u4eba\u5de5\u8bc6\u522b\uff0c\u56e0\u6b64\u5e0c\u671b\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u68c0\u6d4b\u5bf9\u8bdd\u4e2d\u7684\u5fae\u884c\u4e3a\u3002", "method": "\u6536\u96c6\u6a21\u62df\u592a\u7a7a\u4efb\u52a1\u7684\u5bf9\u8bdd\u8f6c\u5f55\u672c\uff0c\u8bc4\u4f30\u7f16\u7801\u5668\u578b\uff08\u5982RoBERTa\u3001DistilBERT\uff09\u548c\u89e3\u7801\u5668\u578b\uff08\u5982Llama-3.1\uff09\u5927\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u5206\u7c7b\u3001\u5fae\u8c03\u3001\u589e\u5e7f\u5fae\u8c03\u548c\u5c11\u6837\u672c\u751f\u6210\u7b49\u65b9\u5f0f\u4e0b\u5bf9\u6bcf\u4e2a\u5bf9\u8bdd\u8bdd\u8f6e\u4e2d\u5fae\u884c\u4e3a\u7c7b\u522b\u7684\u81ea\u52a8\u9884\u6d4b\u80fd\u529b\u3002", "result": "RoBERTa\u548cDistilBERT\u7b49\u7f16\u7801\u5668\u578b\u6a21\u578b\u5373\u4fbf\u7ecf\u52a0\u6743\u5fae\u8c03\u540e\uff0c\u4ecd\u7136\u96be\u4ee5\u8bc6\u522b\u6837\u672c\u6570\u8f83\u5c11\u7684\u5fae\u884c\u4e3a\uff08\u5c24\u5176\u662f\u529d\u963b\u6027\u53d1\u8a00\uff09\uff1b\u800c\u7ecf\u8fc7\u6307\u4ee4\u5fae\u8c03\u7684\u89e3\u7801\u5668\u578b\u6a21\u578bLlama-3.1\u53d6\u5f97\u4e86\u66f4\u4f18\u6210\u7ee9\uff0c\u4e09\u5206\u7c7b\u4efb\u52a1\u5b8f\u5e73\u5747F1\u4e3a44%\uff0c\u4e8c\u5206\u7c7b\u4efb\u52a1\u4e3a68%\u3002", "conclusion": "\u89e3\u7801\u5668\u578b\u6a21\u578b\u5728\u5fae\u884c\u4e3a\u81ea\u52a8\u68c0\u6d4b\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u7f16\u7801\u5668\u578b\u6a21\u578b\uff0c\u5bf9\u5f00\u53d1\u56e2\u961f\u6c9f\u901a\u5206\u6790\u548c\u8bad\u7ec3\u5e72\u9884\u5de5\u5177\u5177\u6709\u73b0\u5b9e\u610f\u4e49\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u53ea\u80fd\u8bbf\u95ee\u6587\u672c\u6570\u636e\u7684\u9ad8\u98ce\u9669\u573a\u666f\u3002"}}
{"id": "2506.23535", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23535", "abs": "https://arxiv.org/abs/2506.23535", "authors": ["Malik Muhammad Umer"], "title": "Comparative Analysis of the Code Generated by Popular Large Language Models (LLMs) for MISRA C++ Compliance", "comment": null, "summary": "Safety-critical systems are engineered systems whose failure or malfunction\ncould result in catastrophic consequences. The software development for\nsafety-critical systems necessitates rigorous engineering practices and\nadherence to certification standards like DO-178C for avionics. DO-178C is a\nguidance document which requires compliance to well-defined software coding\nstandards like MISRA C++ to enforce coding guidelines that prevent the use of\nambiguous, unsafe, or undefined constructs. Large Language Models (LLMs) have\ndemonstrated significant capabilities in automatic code generation across a\nwide range of programming languages, including C++. Despite their impressive\nperformance, code generated by LLMs in safety-critical domains must be\ncarefully analyzed for conformance to MISRA C++ coding standards. In this\npaper, I have conducted a comparative analysis of the C++ code generated by\npopular LLMs including: OpenAI ChatGPT, Google Gemini, DeepSeek, Meta AI, and\nMicrosoft Copilot for compliance with MISRA C++.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u6bd4\u8f83\u4e86\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210C++\u4ee3\u7801\u5bf9MISRA C++\u5b89\u5168\u6807\u51c6\u7684\u9075\u5faa\uff0c\u7ed3\u8bba\u662f\u8fd9\u4e9b\u6a21\u578b\u751f\u6210\u7684\u81ea\u52a8\u4ee3\u7801\u5c1a\u9700\u4e25\u683c\u4eba\u5de5\u68c0\u67e5\u4ee5\u786e\u4fdd\u5b89\u5168\u6027\u3002", "motivation": "\u7531\u4e8e\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u6545\u969c\u4f1a\u9020\u6210\u707e\u96be\u6027\u540e\u679c\uff0c\u56e0\u6b64\u8be5\u9886\u57df\u5bf9\u8f6f\u4ef6\u7f16\u5199\u6807\u51c6\u6781\u4e3a\u4e25\u683c\u3002\u968f\u7740LLM\u5728\u81ea\u52a8\u4ee3\u7801\u751f\u6210\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u8bc4\u4f30\u5176\u5728\u9075\u5faa\u5b89\u5168\u7f16\u7801\u89c4\u8303\u65b9\u9762\u7684\u80fd\u529b\u6210\u4e3a\u5fc5\u8981\u3002", "method": "\u4f5c\u8005\u5bf9OpenAI ChatGPT\u3001Google Gemini\u3001DeepSeek\u3001Meta AI\u548cMicrosoft Copilot\u7b49\u4e3b\u6d41LLM\u751f\u6210\u7684C++\u4ee3\u7801\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790\uff0c\u91cd\u70b9\u8003\u67e5\u8fd9\u4e9b\u4ee3\u7801\u662f\u5426\u7b26\u5408MISRA C++\u6807\u51c6\u3002", "result": "\u8bba\u6587\u53d1\u73b0\uff0c\u4e0d\u540cLLM\u751f\u6210\u7684\u4ee3\u7801\u5728\u5bf9MISRA C++\u6807\u51c6\u7684\u7b26\u5408\u7a0b\u5ea6\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u81ea\u52a8\u4ee3\u7801\u4ecd\u9700\u4eba\u5de5\u4e25\u683c\u5ba1\u6838\uff0c\u4e0d\u80fd\u76f4\u63a5\u7528\u4e8e\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u3002", "conclusion": "\u8be5\u6587\u901a\u8fc7\u6bd4\u8f83\u5206\u6790\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u7684C++\u4ee3\u7801\u5bf9MISRA C++\u89c4\u8303\u7684\u9075\u5faa\u60c5\u51b5\uff0c\u6307\u51fa\u8fd9\u4e9b\u81ea\u52a8\u751f\u6210\u7684\u4ee3\u7801\u5728\u5e94\u7528\u4e8e\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u524d\u9700\u8981\u4e25\u683c\u5ba1\u67e5\u3002"}}
{"id": "2506.22694", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.22694", "abs": "https://arxiv.org/abs/2506.22694", "authors": ["Raghavv Goel", "Sudhanshu Agrawal", "Mukul Gagrani", "Junyoung Park", "Yifan Zao", "He Zhang", "Tian Liu", "Yiping Yang", "Xin Yuan", "Jiuyan Lu", "Chris Lott", "Mingu Lee"], "title": "VOCABTRIM: Vocabulary Pruning for Efficient Speculative Decoding in LLMs", "comment": "7 pages, 4 figures, 5 tables, accepted at ICML 2025 workshop on\n  Efficient Systems for Foundational Models", "summary": "In this paper, we introduce a simple training-free technique to improve the\nperformance of drafter-based speculative decoding (SpD) methods that\nincorporates language modeling head (LM head) during drafting process. A\ndrafter-based speculative decoding leverages one or more smaller language\nmodels, a.k.a. drafters or draft models, to sample a draft sequence or tree\nconsisting of multiple tokens, followed by verification by a base LLM, a target\nmodel, accepting a subset as its valid generation. As it is usually considered\nthat the speculative decoding requires one-to-one mapping between vocabularies\nof the target model and the draft model, it has been natural to share the\nvocabulary between them, or even share the LM head as in EAGLE or Medusa. We\nfirst identify that this draft token sampling scheme inherently contains an\nunnecessary inference overhead in drafting, especially for some target LLMs\nwith very large vocabularies. Then, we propose a simple technique, VocabTrim,\nto mitigate the drafting overhead to improve the generation speed in\nmemory-bound environment. VocabTrim reconstructs the drafter LM head to contain\nonly a limited set of tokens, selected by the most frequently sampled from the\nvocabulary of the target model. While limiting the vocabulary in drafting\nslightly degrades the acceptance rate, it significantly reduces the drafting\nlatency in memory-bound process which is often the case on edge devices,\nresulting in higher memory-bound speed up (MBSU). We show that our method can\nboost the memory-bound speed-up for Llama-3 models on Spec-Bench, specifically\nby 16% for Llama-3.2-3B-Instruct.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51faVocabTrim\u65b9\u6cd5\uff0c\u901a\u8fc7\u9650\u5236drafter\u7684\u8bcd\u8868\u89c4\u6a21\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u63a8\u7406\u5ef6\u8fdf\uff0c\u5728\u5185\u5b58\u53d7\u9650\u73af\u5883\u4e0b\u5927\u5e45\u63d0\u5347\u4e86LLM\u7684\u751f\u6210\u901f\u5ea6\uff0c\u5e76\u5728Llama-3\u6a21\u578b\u4e0a\u53d6\u5f97\u4e86\u6700\u9ad816%\u7684\u52a0\u901f\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8edrafter\uff08\u8d77\u8349\u8005\uff09\u7684speculative decoding\uff08\u63a8\u6d4b\u89e3\u7801\uff09\u65b9\u6cd5\u5728\u8349\u7a3f\u91c7\u6837\u9636\u6bb5\u5b58\u5728\u7531\u4e8e\u5927\u8bcd\u8868\u5bfc\u81f4\u7684\u63a8\u7406\u5f00\u9500\uff0c\u7279\u522b\u662f\u5728\u76ee\u6807LLM\u8bcd\u8868\u5f88\u5927\u65f6\uff0c\u8be5\u9636\u6bb5\u7684\u5ef6\u8fdf\u660e\u663e\uff0c\u5f71\u54cd\u4e86\u5728\u5185\u5b58\u53d7\u9650\u73af\u5883\uff08\u5982\u8fb9\u7f18\u8bbe\u5907\uff09\u4e0a\u7684\u751f\u6210\u901f\u5ea6\u3002\u4f5c\u8005\u5e0c\u671b\u51cf\u5c11\u8fd9\u79cd\u4e0d\u5fc5\u8981\u7684\u63a8\u7406\u5f00\u9500\uff0c\u63d0\u9ad8\u751f\u6210\u901f\u5ea6\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u65e0\u5173\u7684\u65b0\u6280\u672fVocabTrim\uff1a\u6839\u636e\u76ee\u6807\u6a21\u578b\u5b9e\u9645\u5e38\u7528\u7684\u8bcd\uff0c\u4ece\u5176\u8bcd\u8868\u7b5b\u9009\u51fa\u51fa\u73b0\u9891\u7387\u8f83\u9ad8\u7684\u4e00\u5c0f\u90e8\u5206\u5b50\u96c6\uff0c\u91cd\u6784drafter\u7684\u8bed\u8a00\u5efa\u6a21\u5934\uff08LM head\uff09\uff0c\u4f7fdrafter\u53ea\u8d1f\u8d23\u8fd9\u90e8\u5206\u9ad8\u9891\u8bcd\u7684\u9884\u6d4b\u3002\u8fd9\u6837\u53ef\u4ee5\u5728\u4fdd\u6709\u9002\u7528\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u6781\u5927\u51cf\u5c11drafter\u9636\u6bb5\u7684\u63a8\u7406\u91cf\u548c\u5ef6\u8fdf\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u76ee\u6807\u6a21\u578bLlama-3\u7684Spec-Bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u660e\u663e\u52a0\u901f\uff1a\u5bf9\u4e8eLlama-3.2-3B-Instruct\u6a21\u578b\uff0c\u5728\u5185\u5b58\u53d7\u9650\u6761\u4ef6\u4e0b\u7684\u63a8\u7406\u901f\u5ea6\u63d0\u5347\uff08MBSU\uff09\u8fbe\u5230\u4e8616%\u3002\u5c3d\u7ba1\u91c7\u6837\u63a5\u53d7\u7387\u7565\u6709\u4e0b\u964d\uff0c\u4f46\u6574\u4f53\u5e26\u6765\u4e86\u663e\u8457\u7684\u7f16\u89e3\u7801\u5ef6\u8fdf\u964d\u4f4e\u3002", "conclusion": "\u901a\u8fc7VocabTrim\u9650\u5236drafter\u7684\u8bcd\u8868\u89c4\u6a21\uff0c\u53ef\u4ee5\u5927\u5e45\u964d\u4f4e\u57fa\u4e8edrafter\u7684\u63a8\u6d4b\u89e3\u7801\u8fc7\u7a0b\u4e2d\u7684\u63a8\u7406\u5ef6\u8fdf\uff0c\u7279\u522b\u662f\u5728\u5185\u5b58\u53d7\u9650\u7684\u573a\u666f\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u901f\u5ea6\uff0c\u5bf9\u5b9e\u9645\u90e8\u7f72\u5728\u8fb9\u7f18\u8bbe\u5907\u7684LLM\u63a8\u7406\u6709\u5f88\u5927\u4fc3\u8fdb\u4f5c\u7528\u3002"}}
{"id": "2506.23644", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2506.23644", "abs": "https://arxiv.org/abs/2506.23644", "authors": ["Junze Hu", "Xiangyu Jin", "Yizhe Zeng", "Yuling Liu", "Yunpeng Li", "Dan Du", "Kaiyu Xie", "Hongsong Zhu"], "title": "QLPro: Automated Code Vulnerability Discovery via LLM and Static Code Analysis Integration", "comment": null, "summary": "We introduce QLPro, a vulnerability detection framework that systematically\nintegrates LLMs and static analysis tools to enable comprehensive vulnerability\ndetection across entire open-source projects.We constructed a new dataset,\nJavaTest, comprising 10 open-source projects from GitHub with 62 confirmed\nvulnerabilities. CodeQL, a state-of-the-art static analysis tool, detected only\n24 of these vulnerabilities while QLPro detected 41. Furthermore, QLPro\ndiscovered 6 previously unknown vulnerabilities, 2 of which have been confirmed\nas 0-days.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u80fd\u66f4\u6709\u6548\u68c0\u6d4b\u5f00\u6e90\u9879\u76ee\u6f0f\u6d1e\u7684QLPro\u7cfb\u7edf\uff0c\u7ed3\u5408LLM\u4e0e\u9759\u6001\u5206\u6790\u5de5\u5177\uff0c\u68c0\u6d4b\u80fd\u529b\u8fdc\u8d85\u4e3b\u6d41\u5de5\u5177\uff0c\u5e76\u80fd\u53d1\u73b0\u5b89\u5168\u793e\u533a\u672a\u77e5\u7684\u65b0\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u6709\u9759\u6001\u5206\u6790\u5de5\u5177\u5728\u68c0\u6d4b\u5f00\u6e90\u9879\u76ee\u4e2d\u7684\u6f0f\u6d1e\u65f6\u5b58\u5728\u6f0f\u68c0\u95ee\u9898\uff0c\u68c0\u6d4b\u6548\u679c\u4e0d\u7406\u60f3\u3002\u9700\u8981\u4e00\u79cd\u66f4\u5168\u9762\u4e14\u51c6\u786e\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86QLPro\u6846\u67b6\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0e\u9759\u6001\u5206\u6790\u5de5\u5177\u7cfb\u7edf\u6027\u7ed3\u5408\uff0c\u63d0\u9ad8\u5bf9\u5f00\u6e90\u9879\u76ee\u4e2d\u6f0f\u6d1e\u7684\u68c0\u6d4b\u80fd\u529b\u3002\u540c\u65f6\u6784\u5efa\u4e86JavaTest\u6570\u636e\u96c6\u7528\u4e8e\u8bc4\u4f30\u3002", "result": "QLPro\u5728JavaTest\u6570\u636e\u96c6\u4e0a\u68c0\u6d4b\u523041\u4e2a\u6f0f\u6d1e\uff0c\u4f18\u4e8eCodeQL\u768424\u4e2a\u3002QLPro\u8fd8\u53d1\u73b0\u4e866\u4e2a\u6b64\u524d\u672a\u77e5\u7684\u65b0\u6f0f\u6d1e\uff0c\u5176\u4e2d2\u4e2a\u5df2\u88ab\u8bc1\u5b9e\u4e3a0-day\u6f0f\u6d1e\u3002", "conclusion": "QLPro\u7cfb\u7edf\u6027\u6574\u5408\u4e86LLM\u4e0e\u9759\u6001\u5206\u6790\u5de5\u5177\uff0c\u80fd\u66f4\u5168\u9762\u68c0\u6d4b\u5f00\u6e90\u9879\u76ee\u4e2d\u7684\u6f0f\u6d1e\uff0c\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u5de5\u5177\uff0c\u5e76\u80fd\u53d1\u73b0\u65b0\u578b\u548c\u9ad8\u5371\u6f0f\u6d1e\u3002"}}
{"id": "2506.22698", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22698", "abs": "https://arxiv.org/abs/2506.22698", "authors": ["Emily Dux Speltz"], "title": "Text Production and Comprehension by Human and Artificial Intelligence: Interdisciplinary Workshop Report", "comment": null, "summary": "This report synthesizes the outcomes of a recent interdisciplinary workshop\nthat brought together leading experts in cognitive psychology, language\nlearning, and artificial intelligence (AI)-based natural language processing\n(NLP). The workshop, funded by the National Science Foundation, aimed to\naddress a critical knowledge gap in our understanding of the relationship\nbetween AI language models and human cognitive processes in text comprehension\nand composition. Through collaborative dialogue across cognitive, linguistic,\nand technological perspectives, workshop participants examined the underlying\nprocesses involved when humans produce and comprehend text, and how AI can both\ninform our understanding of these processes and augment human capabilities. The\nworkshop revealed emerging patterns in the relationship between large language\nmodels (LLMs) and human cognition, with highlights on both the capabilities of\nLLMs and their limitations in fully replicating human-like language\nunderstanding and generation. Key findings include the potential of LLMs to\noffer insights into human language processing, the increasing alignment between\nLLM behavior and human language processing when models are fine-tuned with\nhuman feedback, and the opportunities and challenges presented by human-AI\ncollaboration in language tasks. By synthesizing these findings, this report\naims to guide future research, development, and implementation of LLMs in\ncognitive psychology, linguistics, and education. It emphasizes the importance\nof ethical considerations and responsible use of AI technologies while striving\nto enhance human capabilities in text comprehension and production through\neffective human-AI collaboration.", "AI": {"tldr": "\u672c\u6587\u603b\u7ed3\u4e86\u4e00\u6b21\u8de8\u5b66\u79d1\u7814\u8ba8\u4f1a\uff0c\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u5728\u6587\u672c\u5904\u7406\u65b9\u9762\u7684\u5173\u7cfb\uff0c\u6307\u51fa\u4e86LLMs\u7684\u4f18\u52bf\u548c\u5c40\u9650\uff0c\u5e76\u5f3a\u8c03\u4e86\u4f26\u7406\u4e0e\u4eba\u673a\u534f\u4f5c\u7684\u95ee\u9898\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u672a\u6765\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u8bed\u8a00\u6a21\u578b\uff08\u5982\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0cLLMs\uff09\u4e0e\u4eba\u7c7b\u5728\u6587\u672c\u7406\u89e3\u548c\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u5173\u7cfb\u5c1a\u5b58\u5728\u5173\u952e\u77e5\u8bc6\u7a7a\u767d\u3002\u8bba\u6587\u5e0c\u671b\u901a\u8fc7\u6574\u5408\u8ba4\u77e5\u5fc3\u7406\u5b66\u3001\u8bed\u8a00\u5b66\u4e60\u548c\u57fa\u4e8eAI\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u591a\u4e2a\u9886\u57df\u7684\u4e13\u5bb6\u89c2\u70b9\uff0c\u63a2\u7d22AI\u5982\u4f55\u5e2e\u52a9\u7406\u89e3\u6216\u589e\u5f3a\u4eba\u7c7b\u7684\u8bed\u8a00\u80fd\u529b\u3002", "method": "\u4e3e\u529e\u8de8\u5b66\u79d1\u7814\u8ba8\u4f1a\uff0c\u5c06\u8ba4\u77e5\u5fc3\u7406\u5b66\u3001\u8bed\u8a00\u5b66\u4e60\u548cAI\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u7684\u4e13\u5bb6\u805a\u96c6\u5728\u4e00\u8d77\uff0c\u901a\u8fc7\u534f\u4f5c\u5bf9\u8bdd\u548c\u89c2\u70b9\u4ea4\u6d41\uff0c\u5206\u6790\u4eba\u7c7b\u6587\u672c\u7406\u89e3\u548c\u751f\u6210\u7684\u5e95\u5c42\u8fc7\u7a0b\uff0c\u4ee5\u53caAI\u5982\u4f55\u8f85\u52a9\u8fd9\u4e9b\u8fc7\u7a0b\u3002", "result": "\u7814\u8ba8\u4f1a\u63ed\u793a\u4e86AI\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u4e4b\u95f4\u7684\u65b0\u5173\u7cfb\u6a21\u5f0f\uff0c\u53d1\u73b0LLMs\u80fd\u4e3a\u4eba\u7c7b\u8bed\u8a00\u5904\u7406\u673a\u5236\u7814\u7a76\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002\u5728\u7528\u4eba\u7c7b\u53cd\u9988\u5fae\u8c03\u540e\uff0cLLMs\u4e0e\u4eba\u7c7b\u8bed\u8a00\u5904\u7406\u7684\u884c\u4e3a\u8d8a\u6765\u8d8a\u4e00\u81f4\u3002\u540c\u65f6\uff0c\u8bba\u6587\u6307\u51fa\u4e86LLMs\u5728\u5b8c\u5168\u590d\u5236\u4eba\u7c7b\u8bed\u8a00\u7406\u89e3\u4e0e\u751f\u6210\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u8ba8\u8bba\u4e86\u4eba\u673a\u534f\u4f5c\u4e2d\u5b58\u5728\u7684\u673a\u9047\u4e0e\u6311\u6218\u3002", "conclusion": "LLMs\u5177\u5907\u4e3a\u8ba4\u77e5\u5fc3\u7406\u5b66\u3001\u8bed\u8a00\u5b66\u53ca\u6559\u80b2\u9886\u57df\u63d0\u4f9b\u652f\u6301\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u9700\u9ad8\u5ea6\u5173\u6ce8\u4f26\u7406\u548cAI\u6280\u672f\u7684\u8d1f\u8d23\u4efb\u4f7f\u7528\u3002\u62a5\u544a\u4e3a\u672a\u6765\u76f8\u5173\u7814\u7a76\u3001\u5f00\u53d1\u53ca\u5b9e\u8df5\u6307\u660e\u4e86\u65b9\u5411\uff0c\u5e76\u5f3a\u8c03\u4eba\u673a\u534f\u4f5c\u5c06\u4e3a\u6587\u672c\u7406\u89e3\u4e0e\u751f\u6210\u5e26\u6765\u65b0\u7684\u53ef\u80fd\u3002"}}
{"id": "2506.22724", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.22724", "abs": "https://arxiv.org/abs/2506.22724", "authors": ["Niyati Bafna", "Tianjian Li", "Kenton Murray", "David R. Mortensen", "David Yarowsky", "Hale Sirin", "Daniel Khashabi"], "title": "The Translation Barrier Hypothesis: Multilingual Generation with Large Language Models Suffers from Implicit Translation Failure", "comment": "23 pages incl. appendix", "summary": "Multilingual generation with large language models (LLMs) is often of poor\nquality for mid- to low-resource languages. Building on insights from\ninterpretability, we demonstrate the existence of an implicit\ntask-solving-->translation pipeline for generation, whereby the model first\nsolves the required task in a largely target-language-agnostic manner, and\nsubsequently translates answer concepts into the intended target language. We\nhypothesize that the failure of the translation stage is an important culprit\nfor the observed low quality of final outputs, and formalize this as the\ntranslation barrier hypothesis. We test this hypothesis for a word translation\ntask across 108 language pairs, using logit lens to observe model processing in\nintermediate layers. We find that a significant portion of overall failures\nindeed stems from translation failure, or the model's inability to translate\ncorrectly solved intermediate concepts into the target language. This is\nespecially true for low-resource target languages. Our results highlight an\nimportant hurdle for end-to-end multilingual generation, and lend guiding\ninsights for future work seeking to improve multilinguality in LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLLM\u591a\u8bed\u751f\u6210\u4e2d\u7684\u7ffb\u8bd1\u969c\u788d\u5047\u8bf4\uff0c\u901a\u8fc7\u5bf9108\u79cd\u8bed\u8a00\u5bf9\u7684\u5206\u6790\u53d1\u73b0\uff0c\u6a21\u578b\u4e3b\u8981\u5728\u5c06\u5df2\u89e3\u51b3\u4efb\u52a1\u7684\u4e2d\u95f4\u6982\u5ff5\u7ffb\u8bd1\u4e3a\u76ee\u6807\u8bed\u8a00\u65f6\u5931\u8d25\uff0c\u5c24\u5176\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u7a81\u51fa\u3002\u8fd9\u4e00\u53d1\u73b0\u4e3a\u6539\u8fdb\u591a\u8bed\u79cd\u751f\u6210\u63d0\u4f9b\u4e86\u91cd\u8981\u65b9\u5411\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e2d\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u7684\u751f\u6210\u8d28\u91cf\u8f83\u5dee\uff0c\u539f\u56e0\u5c1a\u4e0d\u5b8c\u5168\u6e05\u695a\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u89e3\u91ca\u6027\u5206\u6790\u53d1\u73b0\u5e76\u89e3\u91ca\u8fd9\u4e9b\u6a21\u578b\u591a\u8bed\u79cd\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u6838\u5fc3\u74f6\u9888\u3002", "method": "\u5229\u7528\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u89c2\u5bdfLLM\u5728\u591a\u8bed\u4efb\u52a1\u4e2d\u7684\u4e2d\u95f4\u5904\u7406\u8fc7\u7a0b\u3002\u63d0\u51fa\u5e76\u9a8c\u8bc1\"\u7ffb\u8bd1\u969c\u788d\u5047\u8bf4\"\uff1a\u5373\u6a21\u578b\u5728\u5b8c\u6210\u8bed\u8a00\u65e0\u5173\u4efb\u52a1\u540e\uff0c\u65e0\u6cd5\u5c06\u6b63\u786e\u6982\u5ff5\u7ffb\u8bd1\u6210\u76ee\u6807\u8bed\u8a00\u3002\u4f5c\u8005\u901a\u8fc7logit lens\u5de5\u5177\uff0c\u5728108\u79cd\u8bed\u8a00\u5bf9\u7684\u8bcd\u6c47\u7ffb\u8bd1\u4efb\u52a1\u4e2d\uff0c\u5206\u6790\u4e2d\u95f4\u5c42\u5904\u7406\u7ed3\u679c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cLLM\u591a\u8bed\u751f\u6210\u8d28\u91cf\u4f4e\uff0c\u4e3b\u8981\u539f\u56e0\u4e4b\u4e00\u662f\u7ffb\u8bd1\u9636\u6bb5\u5931\u8d25\uff0c\u5c24\u5176\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u66f4\u4e3a\u7a81\u51fa\u3002\u6a21\u578b\u5e38\u5e38\u5df2\u7ecf\u6b63\u786e\u5b8c\u6210\u4efb\u52a1\uff0c\u4f46\u672a\u80fd\u5c06\u4e2d\u95f4\u6982\u5ff5\u6b63\u786e\u8868\u8fbe\u4e3a\u76ee\u6807\u8bed\u8a00\u3002", "conclusion": "\u591a\u8bed\u79cd\u751f\u6210\u7684\u5173\u952e\u74f6\u9888\u5728\u4e8e\u6a21\u578b\u5c06\u4e2d\u95f4\u6982\u5ff5\u7ffb\u8bd1\u4e3a\u76ee\u6807\u8bed\u8a00\u7684\u80fd\u529b\u3002\u6307\u51fa\u8fd9\u4e00\u95ee\u9898\u5bf9\u672a\u6765\u63d0\u5347LLM\u591a\u8bed\u79cd\u80fd\u529b\u6709\u91cd\u8981\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2506.23715", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23715", "abs": "https://arxiv.org/abs/2506.23715", "authors": ["Benoit Combemale"], "title": "Towards a Science of Developer eXperience (DevX)", "comment": null, "summary": "As software continues to permeate nearly every facet of modern life, the\ncomplexity and ubiquity of digital services underscore the need for\nsustainable, effective, and inclusive software development practices. Although\nsoftware engineering has made significant progress in technical challenges\nsince its inception, the human experience of those involved in software\ncreation, broadly defined as developers, remains underexplored. This column\nadvocates for the formal recognition of Developer eXperience (DevX) as a\ndistinct research field. We argue that DevX profoundly influences critical\ndevelopment activities and overall productivity, especially as development\nbecomes increasingly collaborative and diverse in terms of application domains.\nBuilding on existing efforts to measure and enhance DevX, we identify key\nrationales, scientific enablers, and interdisciplinary intersections that\nsupport this emerging discipline. We also outline the core scientific\nchallenges ahead, aiming to call for actions from the research community and to\npromote more human-centered approaches to software engineering.", "AI": {"tldr": "\u5c06\u5f00\u53d1\u8005\u4f53\u9a8c\uff08DevX\uff09\u63d0\u5347\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u72ec\u7acb\u7814\u7a76\u8bfe\u9898\uff0c\u68b3\u7406\u5176\u610f\u4e49\u3001\u5f71\u54cd\u4e0e\u6311\u6218\uff0c\u547c\u5401\u793e\u533a\u91cd\u89c6\u5e76\u63a8\u8fdb\u4ee5\u4eba\u4e3a\u672c\u7684\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u3002", "motivation": "\u73b0\u4ee3\u793e\u4f1a\u8f6f\u4ef6\u65e0\u5904\u4e0d\u5728\uff0c\u8f6f\u4ef6\u670d\u52a1\u590d\u6742\u4e14\u5e7f\u6cdb\uff0c\u5f53\u524d\u8f6f\u4ef6\u5de5\u7a0b\u591a\u4e13\u6ce8\u6280\u672f\u6311\u6218\uff0c\u800c\u5f00\u53d1\u8005\u4f53\u9a8c\uff08DevX\uff09\u8fd9\u4e2a\u5173\u4e4e\u4eba\u7c7b\u56e0\u7d20\u7684\u91cd\u8981\u8bae\u9898\u88ab\u5ffd\u89c6\u3002\u63a8\u52a8DevX\u7814\u7a76\u6709\u52a9\u4e8e\u5b9e\u73b0\u6301\u7eed\u3001\u9ad8\u6548\u548c\u5305\u5bb9\u6027\u7684\u8f6f\u4ef6\u5f00\u53d1\u65b9\u6cd5\u3002", "method": "\u7acb\u8db3\u4e8e\u73b0\u6709\u5bf9DevX\u6d4b\u91cf\u4e0e\u63d0\u5347\u7684\u7814\u7a76\uff0c\u603b\u7ed3\u5173\u952e\u52a8\u56e0\u3001\u79d1\u5b66\u4fc3\u8fdb\u56e0\u7d20\u53ca\u6d89\u53ca\u5b66\u79d1\u4ea4\u53c9\uff0c\u5206\u6790DevX\u5bf9\u5f00\u53d1\u6d3b\u52a8\u4e0e\u751f\u4ea7\u529b\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u79d1\u5b66\u6311\u6218\uff0c\u53f7\u53ec\u793e\u533a\u884c\u52a8\u3002", "result": "\u63d0\u51faDevX\u5e94\u88ab\u89c6\u4e3a\u72ec\u7acb\u7814\u7a76\u65b9\u5411\uff0c\u6307\u660eDevX\u5728\u534f\u4f5c\u6027\u66f4\u5f3a\u3001\u5e94\u7528\u591a\u5143\u5316\u73af\u5883\u4e0b\u5bf9\u6838\u5fc3\u5f00\u53d1\u6d3b\u52a8\u548c\u751f\u4ea7\u529b\u6709\u6df1\u523b\u5f71\u54cd\uff0c\u5e76\u7f57\u5217\u8be5\u9886\u57df\u7684\u79d1\u5b66\u6311\u6218\u4e0e\u7814\u7a76\u542f\u793a\u3002", "conclusion": "\u547c\u5401\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u6b63\u5f0f\u91cd\u89c6\u5f00\u53d1\u8005\u4f53\u9a8c\uff08DevX\uff09\uff0c\u52a0\u5f3a\u4ee5\u4eba\u4e3a\u672c\u7684\u7814\u7a76\uff0c\u63a8\u52a8\u5f62\u6210\u65b0\u7684\u7814\u7a76\u8303\u5f0f\u548c\u793e\u533a\u5173\u6ce8\u3002"}}
{"id": "2506.22760", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.22760", "abs": "https://arxiv.org/abs/2506.22760", "authors": ["Alan Dao", "Dinh Bach Vu"], "title": "Jan-nano Technical Report", "comment": null, "summary": "Most language models face a fundamental tradeoff where powerful capabilities\nrequire substantial computational resources. We shatter this constraint with\nJan-nano, a 4B parameter language model that redefines efficiency through\nradical specialization: instead of trying to know everything, it masters the\nart of finding anything instantly. Fine-tuned from Qwen3-4B using our novel\nmulti-stage RLVR system that completely eliminates reliance on next token\nprediction training (SFT), Jan-nano achieves 83.2% on SimpleQA benchmark with\nMCP integration while running on consumer hardware. With 128K context length,\nJan-nano proves that intelligence isn't about scale, it's about strategy.", "AI": {"tldr": "Jan-nano\u901a\u8fc7\u65b0\u9896\u8bad\u7ec3\u65b9\u6cd5\u548c\u7b56\u7565\u4e13\u6ce8\uff0c\u517c\u5907\u9ad8\u6548\u4e0e\u9ad8\u6027\u80fd\uff0c\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u7a81\u7834\u4e86\u5927\u6a21\u578b\u8d44\u6e90\u58c1\u5792\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u5728\u80fd\u529b\u548c\u8ba1\u7b97\u8d44\u6e90\u4e4b\u95f4\u5b58\u5728\u6839\u672c\u6027\u6743\u8861\uff0c\u4f5c\u8005\u5e0c\u671b\u7a81\u7834\u8fd9\u4e00\u9650\u5236\uff0c\u63a2\u7d22\u4e0d\u540c\u4e8e\u201c\u5168\u77e5\u578b\u201d\u7684\u9ad8\u6548\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u591a\u9636\u6bb5RLVR\u7cfb\u7edf\u8fdb\u884c\u5fae\u8c03\uff0c\u5b8c\u5168\u6452\u5f03\u4f20\u7edf\u7684\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\u8bad\u7ec3\uff08SFT\uff09\uff0c\u4e13\u6ce8\u4e8e\u6781\u81f4\u68c0\u7d22\u6548\u7387\u3002", "result": "Jan-nano\u5728SimpleQA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u96c6\u6210MCP\u540e\u53d6\u5f9783.2%\u7684\u9ad8\u5206\uff0c\u5e76\u53ef\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u6d41\u7545\u8fd0\u884c\uff0c\u5177\u5907128K\u4e0a\u4e0b\u6587\u957f\u5ea6\u3002", "conclusion": "Jan-nano\u6253\u7834\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u8ba1\u7b97\u8d44\u6e90\u74f6\u9888\uff0c\u901a\u8fc7\u5f7b\u5e95\u4e13\u95e8\u5316\u4e0e\u65b0\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7387\u548c\u9ad8\u6027\u80fd\u3002"}}
{"id": "2506.23749", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23749", "abs": "https://arxiv.org/abs/2506.23749", "authors": ["Boyang Yang", "Zijian Cai", "Fengling Liu", "Bach Le", "Lingming Zhang", "Tegawend\u00e9 F. Bissyand\u00e9", "Yang Liu", "Haoye Tian"], "title": "A Survey of LLM-based Automated Program Repair: Taxonomies, Design Paradigms, and Applications", "comment": null, "summary": "Large language models (LLMs) are reshaping automated program repair (APR). We\ncategorize the recent 63 LLM-based APR systems published from January 2022 to\nJune 2025 into four paradigms, and show how retrieval- or analysis-augmented\ncontexts strengthen any of them. This taxonomy clarifies key trade-offs:\nfine-tuning delivers strong task alignment at high training cost; prompting\nenables rapid deployment but is limited by prompt design and context windows;\nprocedural pipelines offer reproducible control with moderate overhead; agentic\nframeworks tackle multi-hunk or cross-file bugs at the price of increased\nlatency and complexity. Persistent challenges include verifying semantic\ncorrectness beyond test suites, repairing repository-scale defects, and\nlowering the costs of LLMs. We outline research directions that combine\nlightweight human feedback, repository-aware retrieval, code analysis, and\ncost-aware planning to advance reliable and efficient LLM-based APR.", "AI": {"tldr": "\u672c\u6587\u5bf9\u8fd163\u4e2a\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u7cfb\u7edf\u8fdb\u884c\u4e86\u8303\u5f0f\u5f52\u7c7b\uff0c\u5206\u6790\u4e86\u6280\u672f\u6743\u8861\u4e0e\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u5efa\u8bae\u3002", "motivation": "\u9762\u5bf9LLM\u663e\u8457\u6539\u53d8\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u9886\u57df\uff0c\u7cfb\u7edf\u68b3\u7406\u6700\u65b0\u65b9\u6cd5\uff0c\u63ed\u793a\u5173\u952e\u6280\u672f\u6743\u8861\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u65b9\u5411\u3002", "method": "\u5bf92022\u5e74\u81f32025\u5e74\u95f463\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u7cfb\u7edf\u8fdb\u884c\u5206\u7c7b\uff0c\u603b\u7ed3\u5176\u56db\u79cd\u8303\u5f0f\uff0c\u5e76\u5206\u6790\u589e\u5f3a\u65b9\u5f0f\u53ca\u5176\u6743\u8861\u3002", "result": "\u63d0\u51fa\u57fa\u4e8e\u5206\u7c7b\u7684\u5173\u952e\u6280\u672f\u6743\u8861\u5206\u6790\uff0c\u6307\u51fa\u73b0\u6709\u7cfb\u7edf\u4f18\u52a3\u53ca\u9002\u7528\u573a\u666f\uff0c\u5f52\u7eb3\u73b0\u5b58\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u7ed3\u5408\u591a\u79cd\u6280\u672f\u7684\u65b0\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u6301\u7eed\u7684\u6311\u6218\u5305\u62ec\u9a8c\u8bc1\u8bed\u4e49\u6b63\u786e\u6027\u3001\u4fee\u590d\u5927\u578b\u4ed3\u5e93\u7f3a\u9677\u4ee5\u53ca\u964d\u4f4e\u5927\u6a21\u578b\u6210\u672c\u3002\u7ed3\u5408\u4eba\u7c7b\u53cd\u9988\u3001\u4ed3\u5e93\u68c0\u7d22\u3001\u4ee3\u7801\u5206\u6790\u3001\u6210\u672c\u611f\u77e5\u89c4\u5212\u662f\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.22777", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22777", "abs": "https://arxiv.org/abs/2506.22777", "authors": ["Miles Turpin", "Andy Arditi", "Marvin Li", "Joe Benton", "Julian Michael"], "title": "Teaching Models to Verbalize Reward Hacking in Chain-of-Thought Reasoning", "comment": null, "summary": "Language models trained with RL can engage in reward hacking--exploiting\nunintended strategies for high reward--without revealing this behavior in their\nchain-of-thought reasoning, making detection difficult and posing risks for\nhigh-stakes applications. We propose verbalization fine-tuning (VFT), a pre-RL\nintervention that trains models to explicitly acknowledge when they are\ninfluenced by prompt cues--hints which point to incorrect answers (e.g., \"a\nStanford professor thinks the answer is A\"). To evaluate VFT, we subsequently\ntrain models with RL on environments where held-out prompt cues signal which\nincorrect answers will receive high reward, incentivizing models to reward hack\nby exploiting cues instead of reasoning correctly. We measure how often models\nexploit these cues without verbalizing it. After RL, only 6% of the VFT-trained\nmodel's responses consist of undetected reward hacks. In comparison, when we\nperform RL without VFT, the rate of undetected reward hacks goes up to 88%;\nwith a debiasing baseline intervention, this increases further to 99%. VFT\nachieves this by substantially increasing how often models verbalize the\ninfluence of cues--from 8% to 42% after VFT, and up to 94% after RL--while\nbaselines remain low even after RL (10% and 1%). Our results show that teaching\nmodels to explicitly verbalize reward hacking behavior before RL significantly\nimproves their detection, offering a practical path toward more transparent and\nsafe AI systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVFT\u5fae\u8c03\u65b9\u6cd5\uff0c\u5728RL\u8bad\u7ec3\u524d\u63d0\u5347\u6a21\u578b\u5bf9\u5956\u52b1\u7a83\u53d6\u884c\u4e3a\u7684\u81ea\u6211\u8868\u8fbe\u80fd\u529b\u3002\u5b9e\u9a8c\u8bc1\u660eVFT\u80fd\u5927\u5e45\u63d0\u5347\u68c0\u6d4b\u7387\uff0c\u6709\u52a9\u4e8e\u6253\u9020\u66f4\u5b89\u5168\u900f\u660e\u7684AI\u3002", "motivation": "\u5f53\u524d\u7528RL\u8bad\u7ec3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f1a\u5229\u7528\u63d0\u793a\u4e2d\u672a\u9884\u671f\u7684\u7b56\u7565\u83b7\u53d6\u9ad8\u56de\u62a5\u4e14\u4e0d\u5728\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u6765\uff0c\u5bfc\u81f4\u96be\u4ee5\u68c0\u6d4b\u548c\u5b89\u5168\u98ce\u9669\uff0c\u5c24\u5176\u5728\u9ad8\u98ce\u9669\u573a\u666f\u3002", "method": "\u63d0\u51fa\u5728RL\u524d\u901a\u8fc7VFT\u5fae\u8c03\u8bad\u7ec3\u6a21\u578b\uff0c\u4f7f\u5176\u5728\u53d7\u63d0\u793a\u5f71\u54cd\u65f6\u660e\u786e\u8868\u8fbe\uff1b\u5728RL\u9636\u6bb5\u7528\u7279\u5b9a\u73af\u5883\u8bad\u7ec3\u6a21\u578b\uff0c\u5c06\u5956\u52b1\u7a83\u53d6\u884c\u4e3a\u4f5c\u4e3a\u4e3b\u8981\u8bc4\u4f30\u5bf9\u8c61\uff0c\u5e76\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u5728RL\u540e\uff0cVFT\u7ec4\u4ec56%\u7684\u7ed3\u679c\u5b58\u5728\u672a\u88ab\u68c0\u6d4b\u7684\u5956\u52b1\u7a83\u53d6\uff0c\u800c\u65e0VFT\u7ec4\u9ad8\u8fbe88%\uff0c\u53bb\u504f\u57fa\u7ebf\u7ec4\u66f4\u9ad8\uff0899%\uff09\u3002VFT\u7ec4\u6a21\u578b\u5728RL\u540e\u660e\u786e\u8868\u8fbe\u88ab\u63d0\u793a\u5f71\u54cd\u7684\u6bd4\u4f8b\u63d0\u5347\u81f394%\uff0c\u800c\u57fa\u7ebf\u7ec4\u4ecd\u5f88\u4f4e\u3002", "conclusion": "VFT\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5956\u52b1\u7a83\u53d6\u884c\u4e3a\u7684\u68c0\u6d4b\u7387\uff0c\u4e3a\u6784\u5efa\u66f4\u900f\u660e\u3001\u5b89\u5168\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2506.23762", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23762", "abs": "https://arxiv.org/abs/2506.23762", "authors": ["Hongzhou Rao", "Yanjie Zhao", "Xinyi Hou", "Shenao Wang", "Haoyu Wang"], "title": "Software Engineering for Large Language Models: Research Status, Challenges and the Road Ahead", "comment": null, "summary": "The rapid advancement of large language models (LLMs) has redefined\nartificial intelligence (AI), pushing the boundaries of AI research and\nenabling unbounded possibilities for both academia and the industry. However,\nLLM development faces increasingly complex challenges throughout its lifecycle,\nyet no existing research systematically explores these challenges and solutions\nfrom the perspective of software engineering (SE) approaches. To fill the gap,\nwe systematically analyze research status throughout the LLM development\nlifecycle, divided into six phases: requirements engineering, dataset\nconstruction, model development and enhancement, testing and evaluation,\ndeployment and operations, and maintenance and evolution. We then conclude by\nidentifying the key challenges for each phase and presenting potential research\ndirections to address these challenges. In general, we provide valuable\ninsights from an SE perspective to facilitate future advances in LLM\ndevelopment.", "AI": {"tldr": "\u672c\u6587\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u89c6\u89d2\u7cfb\u7edf\u68b3\u7406\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5f00\u53d1\u6d41\u7a0b\u7684\u516d\u5927\u9636\u6bb5\u3001\u4e3b\u8981\u6311\u6218\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u540e\u7eedLLM\u7814\u53d1\u63d0\u4f9b\u7406\u8bba\u53c2\u8003\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u5176\u6574\u4e2a\u5f00\u53d1\u5468\u671f\u4e2d\u5b58\u5728\u8bf8\u591a\u590d\u6742\u6311\u6218\uff0c\u73b0\u6709\u7814\u7a76\u5374\u5f88\u5c11\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u89d2\u5ea6\u7cfb\u7edf\u68b3\u7406\u8fd9\u4e9b\u6311\u6218\u53ca\u5176\u89e3\u51b3\u65b9\u6848\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u5728\u6587\u732e\u8c03\u7814\u57fa\u7840\u4e0a\uff0c\u5c06LLM\u5f00\u53d1\u8fc7\u7a0b\u5212\u5206\u4e3a\u516d\u4e2a\u9636\u6bb5\uff0c\u5bf9\u6bcf\u4e00\u9636\u6bb5\u7684\u7814\u7a76\u73b0\u72b6\u3001\u6311\u6218\u4e0e\u89e3\u51b3\u601d\u8def\u8fdb\u884c\u4e86\u7cfb\u7edf\u5206\u6790\u4e0e\u603b\u7ed3\u3002", "result": "\u5f52\u7eb3\u4e86LLM\u516d\u5927\u5f00\u53d1\u9636\u6bb5\u5404\u81ea\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u9488\u5bf9\u6027\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u540e\u7eed\u5b66\u8005\u548c\u5de5\u7a0b\u5e08\u63d0\u4f9b\u6307\u5bfc\u3002", "conclusion": "\u672c\u6587\u7cfb\u7edf\u6027\u5730\u68b3\u7406\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5e76\u9488\u5bf9\u5404\u9636\u6bb5\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u7684\u89d2\u5ea6\u4e3aLLM\u53d1\u5c55\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2506.22791", "categories": ["cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2506.22791", "abs": "https://arxiv.org/abs/2506.22791", "authors": ["Jianxin Yan", "Wangze Ni", "Lei Chen", "Xuemin Lin", "Peng Cheng", "Zhan Qin", "Kui Ren"], "title": "ContextCache: Context-Aware Semantic Cache for Multi-Turn Queries in Large Language Models", "comment": null, "summary": "Semantic caching significantly reduces computational costs and improves\nefficiency by storing and reusing large language model (LLM) responses.\nHowever, existing systems rely primarily on matching individual queries,\nlacking awareness of multi-turn dialogue contexts, which leads to incorrect\ncache hits when similar queries appear in different conversational settings.\nThis demonstration introduces ContextCache, a context-aware semantic caching\nsystem for multi-turn dialogues. ContextCache employs a two-stage retrieval\narchitecture that first executes vector-based retrieval on the current query to\nidentify potential matches and then integrates current and historical dialogue\nrepresentations through self-attention mechanisms for precise contextual\nmatching. Evaluation of real-world conversations shows that ContextCache\nimproves precision and recall compared to existing methods. Additionally,\ncached responses exhibit approximately 10 times lower latency than direct LLM\ninvocation, enabling significant computational cost reductions for LLM\nconversational applications.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u4e00\u79cd\u5177\u5907\u8bed\u5883\u611f\u77e5\u80fd\u529b\u7684\u591a\u8f6e\u5bf9\u8bdd\u8bed\u4e49\u7f13\u5b58\u7cfb\u7edf ContextCache\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u68c0\u7d22\u548c\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u63d0\u5347\u4e86\u7f13\u5b58\u547d\u4e2d\u51c6\u786e\u7387\u4e0e\u54cd\u5e94\u6548\u7387\uff0c\u53ef\u5927\u5e45\u964d\u4f4e\u5927\u6a21\u578b\u5bf9\u8bdd\u7cfb\u7edf\u7684\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u8bed\u4e49\u7f13\u5b58\u7cfb\u7edf\u53ea\u80fd\u9488\u5bf9\u5355\u4e00\u67e5\u8be2\u8fdb\u884c\u5339\u914d\uff0c\u65e0\u6cd5\u8bc6\u522b\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u4e0a\u4e0b\u6587\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u5728\u4e0d\u540c\u5bf9\u8bdd\u8bed\u5883\u4e0b\u7c7b\u4f3c\u67e5\u8be2\u51fa\u73b0\u65f6\u9519\u8bef\u547d\u4e2d\u7f13\u5b58\u3002\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u53ef\u663e\u8457\u63d0\u5347\u7f13\u5b58\u51c6\u786e\u6027\u4e0eLLM\u5e94\u7528\u6548\u7387\u3002", "method": "\u63d0\u51faContextCache\u7cfb\u7edf\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u68c0\u7d22\u67b6\u6784\uff1a\u9996\u5148\u57fa\u4e8e\u5411\u91cf\u5bf9\u5f53\u524d\u67e5\u8be2\u8fdb\u884c\u521d\u6b65\u68c0\u7d22\uff0c\u7136\u540e\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u673a\u5236\u878d\u5408\u5f53\u524d\u53ca\u5386\u53f2\u5bf9\u8bdd\u8868\u5f81\uff0c\u5b9e\u73b0\u66f4\u7cbe\u786e\u7684\u8bed\u5883\u5339\u914d\u3002", "result": "\u5728\u771f\u5b9e\u5bf9\u8bdd\u6570\u636e\u4e0a\u9a8c\u8bc1\uff0cContextCache\u7cfb\u7edf\u5728\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u7f13\u5b58\u54cd\u5e94\u5ef6\u8fdf\u7ea6\u4e3a\u76f4\u63a5\u8c03\u7528LLM\u76841/10\uff0c\u5927\u5e45\u964d\u4f4eLLM\u5bf9\u8bdd\u5e94\u7528\u7684\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "ContextCache\u80fd\u6709\u6548\u5229\u7528\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u63d0\u5347\u591a\u8f6e\u5bf9\u8bdd\u573a\u666f\u4e0b\u7684\u8bed\u4e49\u7f13\u5b58\u547d\u4e2d\u51c6\u786e\u7387\u548c\u7cfb\u7edf\u6548\u7387\uff0c\u9002\u5408\u90e8\u7f72\u4e8eLLM\u76f8\u5173\u5bf9\u8bdd\u5e94\u7528\u4e2d\u3002"}}
{"id": "2506.23898", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2506.23898", "abs": "https://arxiv.org/abs/2506.23898", "authors": ["Diogo Lemos", "Ademar Aguiar", "Neil B. Harrison"], "title": "Requirements for Active Assistance of Natural Questions in Software Architecture", "comment": null, "summary": "Natural questions are crucial to shaping key architectural decisions and\npreserving architectural knowledge. They arise organically during the\narchitectural design process, often resulting from the existing architectural\nexperience of the designer and the distinctive characteristics of the system\nbeing designed. However, natural questions are often mismanaged or ignored,\nwhich can lead to architectural drift, knowledge loss, inefficient resource\nuse, or poor understandability of the system's architecture. We aim to better\nunderstand the lifecycle of natural questions, its key requirements, challenges\nand difficulties, and then to envision an assisted environment to properly\nsupport it. The environment should be adaptable and responsive to real-world\nconstraints and uncertainties by seamlessly integrating knowledge management\ntools and artificial intelligence techniques into software development\nworkflows. Based on existing literature, a requirements workshop, and three\ndesign iterations, we proposed a lifecycle for natural questions and elicited\nessential functional and non-functional requirements for such an environment.\nAt last, the results of a survey conducted with experts helped to analyze and\nvalidate the elicited requirements and proposed features for the environment to\nenhance collaboration, decision-making, and the preservation of architectural\nknowledge more effectively than conventional methods.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u81ea\u7136\u95ee\u9898\u5728\u8f6f\u4ef6\u67b6\u6784\u8bbe\u8ba1\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u63d0\u51fa\u5bf9\u5e94\u7684\u751f\u547d\u5468\u671f\u548c\u652f\u6301\u73af\u5883\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u8c03\u7814\u9a8c\u8bc1\u4e86\u5176\u6210\u6548\uff0c\u5bf9\u63d0\u5347\u67b6\u6784\u77e5\u8bc6\u4fdd\u62a4\u548c\u534f\u4f5c\u5177\u6709\u663e\u8457\u610f\u4e49\u3002", "motivation": "\u5728\u8f6f\u4ef6\u67b6\u6784\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\uff0c\u81ea\u7136\u95ee\u9898\u5bf9\u4e8e\u5173\u952e\u67b6\u6784\u51b3\u7b56\u548c\u77e5\u8bc6\u4f20\u627f\u975e\u5e38\u91cd\u8981\u3002\u4f46\u8fd9\u4e9b\u95ee\u9898\u7ecf\u5e38\u88ab\u5ffd\u89c6\u6216\u5904\u7406\u4e0d\u5f53\uff0c\u5bfc\u81f4\u77e5\u8bc6\u4e22\u5931\u3001\u8d44\u6e90\u6d6a\u8d39\u548c\u7cfb\u7edf\u67b6\u6784\u96be\u4ee5\u7406\u89e3\u3002\u8be5\u7814\u7a76\u65e8\u5728\u6df1\u5165\u7406\u89e3\u81ea\u7136\u95ee\u9898\u7684\u751f\u547d\u5468\u671f\uff0c\u5e76\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u652f\u6301\u73af\u5883\u3002", "method": "\u4f5c\u8005\u57fa\u4e8e\u5df2\u6709\u6587\u732e\u3001\u9700\u6c42\u7814\u8ba8\u4f1a\uff0c\u4ee5\u53ca\u4e09\u8f6e\u8bbe\u8ba1\u8fed\u4ee3\uff0c\u63d0\u51fa\u4e86\u81ea\u7136\u95ee\u9898\u7684\u751f\u547d\u5468\u671f\uff0c\u5e76\u63d0\u53d6\u4e86\u76f8\u5173\u73af\u5883\u7684\u529f\u80fd\u548c\u975e\u529f\u80fd\u9700\u6c42\u3002\u968f\u540e\uff0c\u901a\u8fc7\u4e13\u5bb6\u95ee\u5377\u8c03\u67e5\uff0c\u5bf9\u9700\u6c42\u53ca\u529f\u80fd\u8fdb\u884c\u4e86\u5206\u6790\u548c\u9a8c\u8bc1\u3002", "result": "\u660e\u786e\u4e86\u81ea\u7136\u95ee\u9898\u751f\u547d\u5468\u671f\uff0c\u754c\u5b9a\u51fa\u8be5\u652f\u6301\u73af\u5883\u5e94\u5177\u5907\u7684\u5173\u952e\u9700\u6c42\uff0c\u5e76\u8bc1\u660e\u8fd9\u4e9b\u9700\u6c42\u548c\u529f\u80fd\u7684\u6709\u6548\u6027\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u80fd\u66f4\u597d\u4fc3\u8fdb\u534f\u4f5c\u3001\u51b3\u7b56\u548c\u77e5\u8bc6\u4fdd\u5b58\u3002", "conclusion": "\u63d0\u51fa\u7684\u81ea\u7136\u95ee\u9898\u751f\u547d\u5468\u671f\u548c\u652f\u6301\u73af\u5883\u80fd\u6709\u6548\u6539\u5584\u67b6\u6784\u77e5\u8bc6\u7684\u7ba1\u7406\u4e0e\u5e94\u7528\uff0c\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\u6709\u79ef\u6781\u4fc3\u8fdb\u4f5c\u7528\u3002"}}
{"id": "2506.22808", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22808", "abs": "https://arxiv.org/abs/2506.22808", "authors": ["Jianhui Wei", "Zijie Meng", "Zikai Xiao", "Tianxiang Hu", "Yang Feng", "Zhijie Zhou", "Jian Wu", "Zuozhu Liu"], "title": "MedEthicsQA: A Comprehensive Question Answering Benchmark for Medical Ethics Evaluation of LLMs", "comment": "20 pages", "summary": "While Medical Large Language Models (MedLLMs) have demonstrated remarkable\npotential in clinical tasks, their ethical safety remains insufficiently\nexplored. This paper introduces $\\textbf{MedEthicsQA}$, a comprehensive\nbenchmark comprising $\\textbf{5,623}$ multiple-choice questions and\n$\\textbf{5,351}$ open-ended questions for evaluation of medical ethics in LLMs.\nWe systematically establish a hierarchical taxonomy integrating global medical\nethical standards. The benchmark encompasses widely used medical datasets,\nauthoritative question banks, and scenarios derived from PubMed literature.\nRigorous quality control involving multi-stage filtering and multi-faceted\nexpert validation ensures the reliability of the dataset with a low error rate\n($2.72\\%$). Evaluation of state-of-the-art MedLLMs exhibit declined performance\nin answering medical ethics questions compared to their foundation\ncounterparts, elucidating the deficiencies of medical ethics alignment. The\ndataset, registered under CC BY-NC 4.0 license, is available at\nhttps://github.com/JianhuiWei7/MedEthicsQA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86MedEthicsQA\uff0c\u4e00\u4e2a\u9ad8\u8d28\u91cf\u533b\u5b66\u4f26\u7406QA\u57fa\u51c6\uff0c\u5e76\u663e\u793a\u5f53\u524d\u533b\u5b66\u5927\u6a21\u578b\u5728\u4f26\u7406\u95ee\u9898\u5904\u7406\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u547c\u5401\u4e1a\u754c\u91cd\u89c6\u5e76\u6539\u8fdb\u6a21\u578b\u7684\u4f26\u7406\u5bf9\u9f50\u3002", "motivation": "\u5c3d\u7ba1\u533b\u5b66\u5927\u8bed\u8a00\u6a21\u578b\uff08MedLLMs\uff09\u5728\u4e34\u5e8a\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5176\u5728\u4f26\u7406\u5b89\u5168\u65b9\u9762\u7684\u63a2\u7d22\u4f9d\u7136\u4e0d\u8db3\u3002\u56e0\u6b64\uff0c\u672c\u6587\u7684\u52a8\u673a\u662f\u5728\u8be5\u9886\u57df\u63d0\u51fa\u4e00\u4e2a\u7cfb\u7edf\u6027\u7684\u4f26\u7406\u8bc4\u4f30\u57fa\u51c6\uff0c\u4fc3\u8fdbMedLLMs\u5728\u4f26\u7406\u5408\u89c4\u6027\u4e0a\u7684\u53d1\u5c55\u3002", "method": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b5,623\u9053\u591a\u9879\u9009\u62e9\u9898\u548c5,351\u9053\u5f00\u653e\u5f0f\u95ee\u9898\u7684MedEthicsQA\u57fa\u51c6\u9898\u5e93\uff0c\u7528\u4e8e\u8bc4\u4f30\u533b\u5b66\u5927\u6a21\u578b\u4f26\u7406\u80fd\u529b\u3002\u7814\u7a76\u56e2\u961f\u7ed3\u5408\u5168\u7403\u533b\u5b66\u4f26\u7406\u6807\u51c6\u5efa\u7acb\u5206\u5c42\u5206\u7c7b\u4f53\u7cfb\uff0c\u6570\u636e\u6765\u6e90\u8986\u76d6\u4e3b\u6d41\u533b\u5b66\u6570\u636e\u96c6\u3001\u6743\u5a01\u9898\u5e93\u548cPubMed\u6587\u732e\u573a\u666f\uff0c\u5e76\u901a\u8fc7\u591a\u9636\u6bb5\u8fc7\u6ee4\u548c\u591a\u4e13\u5bb6\u6838\u9a8c\u4fdd\u8bc1\u6570\u636e\u8d28\u91cf\u3002", "result": "\u901a\u8fc7\u8be5\u57fa\u51c6\u6d4b\u8bd5\uff0c\u76ee\u524d\u4e3b\u6d41\u7684\u533b\u5b66\u5927\u6a21\u578b\u5728\u533b\u5b66\u4f26\u7406\u95ee\u9898\u4e0a\u7b54\u9898\u8868\u73b0\u4f4e\u4e8e\u5176\u539f\u59cb\u57fa\u7840\u6a21\u578b\uff0c\u663e\u793a\u73b0\u6709MedLLMs\u5728\u4f26\u7406\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\u3002\u9898\u5e93\u7684\u8d28\u91cf\u7ecf\u4e25\u683c\u628a\u63a7\uff0c\u9519\u8bef\u7387\u4f4e\u81f32.72%\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u5efa\u7acb\u5e76\u516c\u5f00\u4e86\u533b\u5b66\u4f26\u7406\u8bc4\u6d4b\u57fa\u51c6MedEthicsQA\uff0c\u53d1\u73b0\u73b0\u6709MedLLMs\u5728\u4f26\u7406\u80fd\u529b\u4e0a\u5b58\u5728\u660e\u663e\u77ed\u677f\uff0c\u4e3a\u540e\u7eed\u6a21\u578b\u4f18\u5316\u4e0e\u4f26\u7406\u5bf9\u9f50\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u548c\u5de5\u5177\u3002"}}
