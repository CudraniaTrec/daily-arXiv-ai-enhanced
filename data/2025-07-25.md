<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 15]
- [cs.LO](#cs.LO) [Total: 6]
- [cs.CL](#cs.CL) [Total: 15]
- [cs.DM](#cs.DM) [Total: 1]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Higher-Order Behavioural Conformances via Fibrations](https://arxiv.org/abs/2507.18509)
*Henning Urbat*

Main category: cs.PL

TL;DR: 本文基于范畴论统一推广了Howe方法，为高级定量程序的行为一致性在理论上给出通用的同余性证明方法，并在概率型高阶语言场景下得到了验证。


<details>
  <summary>Details</summary>
Motivation: 随着带有定量特征（如概率特性）的高级语言的兴起，传统的伴随归纳方法需要扩展，以适应更细致的行为一致性（如行为距离等）判定需求。为了保证推理的可靠性，必须证明行为一致性条件能够形成程序同余，即与语言操作兼容。现有方法（如Howe方法）对于不同语言和一致性判定方式适配复杂，缺乏统一框架。

Method: 本文提出一种统一的范畴论方法来推广Howe方法。有两个关键的抽象维度：1）用抽象高阶规范（AHOS）对高级语言进行范畴建模，2）用纤维化方法描述各种行为一致性（如关系、度量等）。通过在一般性范畴结构和操作规则下工作，建立了普适的同余定理。

Result: 证明了只要满足适当的范畴学和操作规则条件，在这种抽象框架下最大行为一致性关系（如双模拟等）一定形成同余。理论还被实际应用于概率型高阶语言，成功推导出它们的双模拟和行为伪度量的同余性。

Conclusion: 该文提出了一种适用于各类高级语言和行为一致性 notions 的统一同余性证明范畴学框架，既通用又便于推广，显著扩展了Howe方法的适用范围。对于含概率等定量特性的高级语言而言，该理论为行为等价与度量的推理提供了理论基础。

Abstract: Coinduction is a widely used technique for establishing behavioural
equivalence of programs in higher-order languages. In recent years, the rise of
languages with quantitative (e.g.~probabilistic) features has led to extensions
of coinductive methods to more refined types of behavioural conformances, most
notably notions of behavioural distance. To guarantee soundness of coinductive
reasoning, one needs to show that the behavioural conformance at hand forms a
program congruence, i.e. it is suitably compatible with the operations of the
language. This is usually achieved by a complex proof technique known as
\emph{Howe's method}, which needs to be carefully adapted to both the specific
language and the targeted notion of behavioural conformance. We develop a
uniform categorical approach to Howe's method that features two orthogonal
dimensions of abstraction: (1) the underlying higher-order language is modelled
by an \emph{abstract higher-order specification} (AHOS), a novel and very
general categorical account of operational semantics, and (2) notions of
behavioural conformance (such as relations or metrics) are modelled via
fibrations over the base category of an AHOS. Our main result is a fundamental
congruence theorem at this level of generality: Under natural conditions on the
categorical ingredients and the operational rules of a language modelled by an
AHOS, the greatest behavioural (bi)conformance on its operational model forms a
congruence. We illustrate our theory by deriving congruence of bisimilarity and
behavioural pseudometrics for probabilistic higher-order languages.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [How Software Engineers Engage with AI: A Pragmatic Process Model and Decision Framework Grounded in Industry Observations](https://arxiv.org/abs/2507.17930)
*Vahid Garousi,Zafar Jafarov*

Main category: cs.SE

TL;DR: 本文调研AI在软件工程实际开发中的应用，总结了AI辅助下的开发流程与决策框架，为开发者更好地平衡效率与质量、有效使用AI工具提供了具体和简明的指导。


<details>
  <summary>Details</summary>
Motivation: 人工智能（AI）已在软件工程（SE）领域表现出提升生产力和决策效率的潜力，但开发者在日常工作中如何使用、信任、调整或拒绝AI生成的结果，相关研究仍显不足。随着基于提示的“vibe coding”编程风格兴起，明晰AI辅助下的实际开发行为变得尤为重要。

Method: 该研究采用行业实地调研与直接观察相结合的方式，收集土耳其和阿塞拜疆三家企业的软件工程师实际使用AI工具（如GitHub Copilot和ChatGPT）过程中的资料，归纳开发者操作和决策要素。

Result: 提出了一个涵盖实践中AI辅助下SE活动的流程模型（如提示设计、结果检查、回退与完善），以及一个帮助开发者权衡节省工作量与输出质量的二维决策框架。这些模型结合实践案例，总结了人类监督下有效利用AI工具的规律。

Conclusion: 论文提供了结构化、实用的指导典范，推动了在软件工程领域中更有意识、高效利用AI辅助的实践，并为人机协作的进一步讨论提供理论支持。

Abstract: Artificial Intelligence (AI) has the potential to transform Software
Engineering (SE) by enhancing productivity, efficiency, and decision support.
Tools like GitHub Copilot and ChatGPT have given rise to "vibe coding"-an
exploratory, prompt-driven development style. Yet, how software engineers
engage with these tools in daily tasks, especially in deciding whether to
trust, refine, or reject AI-generated outputs, remains underexplored. This
paper presents two complementary contributions. First, a pragmatic process
model capturing real-world AI-assisted SE activities, including prompt design,
inspection, fallback, and refinement. Second, a 2D decision framework that
could help developers reason about trade-offs between effort saved and output
quality. Grounded in practitioner reports and direct observations in three
industry settings across Turkiye and Azerbaijan, our work illustrates how
engineers navigate AI use with human oversight. These models offer structured,
lightweight guidance to support more deliberate and effective use of AI tools
in SE, contributing to ongoing discussions on practical human-AI collaboration.

</details>


### [3] [Use as Directed? A Comparison of Software Tools Intended to Check Rigor and Transparency of Published Work](https://arxiv.org/abs/2507.17991)
*Peter Eckmann,Adrian Barnett,Alexandra Bannach-Brown,Elisa Pilar Bascunan Atria,Guillaume Cabanac,Louise Delwen Owen Franzen,Małgorzata Anna Gazda,Kaitlyn Hair,James Howison,Halil Kilicoglu,Cyril Labbe,Sarah McCann,Vladislav Nachev,Martijn Roelandse,Maia Salholz-Hillel,Robert Schulz,Gerben ter Riet,Colby Vorland,Anita Bandrowski,Tracey Weissgerber*

Main category: cs.SE

TL;DR: 本文系统比较了11种自动化工具在9项科研严谨性标准下的表现，发现部分场景中最佳工具突出，部分场景需多工具协作，并提出未来开发建议。


<details>
  <summary>Details</summary>
Motivation: 科学研究的可重复性危机部分源自报告缺乏标准化和透明性，现有的核查清单如ARRIVE和CONSORT并未被完全遵守，同行评议对缺失项的识别也有限。因此需要更有效的自动化工具来提升科研透明性和标准化。

Method: 对11个自动化工具在ScreenIT小组提出的9项不同科研严谨性标准上进行了广泛比较。对比分析各工具在不同标准上的表现，并结合工具进行组合测试，再评估其整体性能。

Result: 发现部分标准（如开放数据检测）下存在表现远优于其他的“获胜”工具，而在某些标准（如纳入和排除标准检测）下，工具组合的性能超过了任何单个工具。还指出了未来开发中亟需加强的关键方向。

Conclusion: 为严谨性和透明性自动检测工具的开发方、用户等各相关方提出了具体洞察和建议。研究数据和代码已开源。

Abstract: The causes of the reproducibility crisis include lack of standardization and
transparency in scientific reporting. Checklists such as ARRIVE and CONSORT
seek to improve transparency, but they are not always followed by authors and
peer review often fails to identify missing items. To address these issues,
there are several automated tools that have been designed to check different
rigor criteria. We have conducted a broad comparison of 11 automated tools
across 9 different rigor criteria from the ScreenIT group. We found some
criteria, including detecting open data, where the combination of tools showed
a clear winner, a tool which performed much better than other tools. In other
cases, including detection of inclusion and exclusion criteria, the combination
of tools exceeded the performance of any one tool. We also identified key areas
where tool developers should focus their effort to make their tool maximally
useful. We conclude with a set of insights and recommendations for stakeholders
in the development of rigor and transparency detection tools. The code and data
for the study is available at https://github.com/PeterEckmann1/tool-comparison.

</details>


### [4] [An Empirical Study of GenAI Adoption in Open-Source Game Development: Tools, Tasks, and Developer Challenges](https://arxiv.org/abs/2507.18029)
*Xiang Echo Chen,Wenhan Zhu,Guoshuai Albert Shi,Michael W. Godfrey*

Main category: cs.SE

TL;DR: 本文研究了生成式AI（GenAI）技术在开源游戏开发中的实际应用。通过分析GitHub上的issue，比较了GenAI、传统AI和非AI话题的使用场景、开发者诉求及集成难点，发现GenAI正在显著地影响开源游戏开发流程和开发者痛点。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能（GenAI）能力的不断提升正在改变游戏设计和开发方式，尤其是在内容创作、游戏玩法模拟和设计构思等方面。然而，现有研究主要关注AI在游戏中传统应用（如控制智能体或生成程序内容），缺乏对GenAI在现实世界、尤其是开源社区中实际采用情况的实证理解。

Method: 本文通过分析GitHub开源游戏项目中的issue讨论，研究GenAI技术在开源游戏开发中的讨论、采用与集成情况。构建涉及AI话题的开源游戏库数据集，对GenAI、传统AI（TradAI）以及非AI话题的issue进行分类采样，采用开放卡片分类和主题分析，对每条issue按类型和内容进行标注，进而进行群组间对比分析。

Result: 通过定性分析，揭示了GenAI相关issue在工具、任务和挑战方面与TradAI及NonAI话题的异同，展示了GenAI在使用模式、开发者关注点和集成实践上的独特性。结果指出GenAI技术正在改变开源游戏开发者的工作流程和主要痛点。

Conclusion: GenAI与传统AI及非AI方法在开源游戏开发领域中展现出显著不同的使用和集成模式。本文的发现为理解GenAI在开源游戏开发中的作用及其带来的挑战提供了数据支持与理论参考，有助于推动更有效的GenAI技术应用。

Abstract: The growing capabilities of generative AI (GenAI) have begun to reshape how
games are designed and developed, offering new tools for content creation,
gameplay simulation, and design ideation. While prior research has explored
traditional uses of AI in games, such as controlling agents or generating
procedural content. There is limited empirical understanding of how GenAI is
adopted by developers in real-world contexts, especially within the open-source
community. This study aims to explore how GenAI technologies are discussed,
adopted, and integrated into open-source game development by analyzing issue
discussions on GitHub. We investigate the tools, tasks, and challenges
associated with GenAI by comparing GenAI-related issues to those involving
traditional AI (TradAI) and NonAI topics. Our goal is to uncover how GenAI
differs from other approaches in terms of usage patterns, developer concerns,
and integration practices. To address this objective, we construct a dataset of
open-source game repositories that discuss AI-related topics. We apply open
card sorting and thematic analysis to a stratified sample of GitHub issues,
labelling each by type and content. These annotations enable comparative
analysis across GenAI, TradAI, and NonAI groups, and provide insight into how
GenAI is shaping the workflows and pain points of open-source game developers.

</details>


### [5] [Your ATs to Ts: MITRE ATT&CK Attack Technique to P-SSCRM Task Mapping](https://arxiv.org/abs/2507.18037)
*Sivana Hamer,Jacob Bowen,Md Nazmul Haque,Chris Madden,Laurie Williams*

Main category: cs.SE

TL;DR: 本研究构建了P-SSCRM与MITRE ATT&CK及其它主流框架的任务映射，有助于组织更体系化地管理软件供应链安全风险。


<details>
  <summary>Details</summary>
Motivation: 当前软件供应链攻击频发，行业急需有效的风险管理与防御措施。MITRE ATT&CK作为主流攻击技术框架，结合更系统的软件供应链风险管理框架（P-SSCRM）可以提升防御效率。

Method: 通过四种独立策略将P-SSCRM任务与MITRE ATT&CK攻击技术进行对应映射，并将P-SSCRM任务与10个主流政府和行业框架中的任务关联起来，形成交叉映射关系。

Result: 建立了P-SSCRM任务与MITRE ATT&CK技术及其它主流框架任务的详细映射关系，为软件组织精准应对供应链攻击提供了实际指导。

Conclusion: 该映射方案有助于软件组织更好地理解并关联各类安全框架和具体防御任务，从而提升整体供应链安全管理能力。

Abstract: The MITRE Adversarial Tactics, Techniques and Common Knowledge (MITRE ATT&CK)
Attack Technique to Proactive Software Supply Chain Risk Management Framework
(P-SSCRM) Task mapping described in this document helps software organizations
to determine how different tasks mitigate the attack techniques of software
supply chain attacks. The mapping was created through four independent
strategies to find agreed-upon mappings. Because each P-SSCRM task is mapped to
one or more tasks from the 10 frameworks, the mapping we provide is also a
mapping between MITRE ATT&CK and other prominent government and industry
frameworks.

</details>


### [6] [Factors Impacting Faculty Adoption of Project-Based Learning in Computing Education: a Survey](https://arxiv.org/abs/2507.18039)
*Ahmad D. Suleiman,Yiming Tang,Daqing Hou*

Main category: cs.SE

TL;DR: 项目制学习在计算机专业教师中备受推崇，但采用率受制于多种实际障碍。获得制度支持、同行合作、专业培训和项目资源是推广PjBL的关键。学校需建立全面的支持体系，鼓励教师尝试和推广此教学法。


<details>
  <summary>Details</summary>
Motivation: 尽管项目制学习（PjBL）在培养学生动机、参与度、批判性思维、协作和解决问题能力方面潜力巨大，但计算专业教师在实际采用时面临诸多障碍，导致其普及度不高。因此，有必要研究影响PjBL采用的因素、阻碍和促进条件。

Method: 本研究采用混合方法，对80位计算机教师进行在线问卷调查。问卷既包括封闭式问题（用于量化障碍、促进因素和资源需求），也包括开放式问题（用于收集质性见解）。定量数据通过统计方法分析，质性回答采用主题分析法。

Result: 结果显示：虽然PjBL被普遍认可，但其采用受限于规划与管理、项目设计以及制度支持（如时间、经费、助教）不足等问题。获得同行合作、专业发展和学校激励能大幅提升采用意愿。此外，从科研、行业合作和同行处获取项目也是重要推动因素。

Conclusion: PjBL在计算教学中具有明显优势，但其广泛采用需要系统性支持，包括同行协作、持续培训和制度激励等措施，帮助教师克服障碍，更好地推动PjBL教学模式的创新与扩展。

Abstract: This research full paper investigates the factors influencing computing
educators' adoption of project-based learning (PjBL) in software engineering
and computing curricula. Recognized as a student-centered pedagogical approach,
PjBL has the potential to enhance student motivation, engagement, critical
thinking, collaboration, and problem-solving skills. Despite these benefits,
faculty adoption remains inconsistent due to challenges such as insufficient
institutional support, time constraints, limited training opportunities,
designing or sourcing projects, and aligning them with course objectives. This
research explores these barriers and investigates the strategies and resources
that facilitate a successful adoption. Using a mixed-methods approach, data
from 80 computing faculty were collected through an online survey comprising
closed-ended questions to quantify barriers, enablers, and resource needs,
along with an open-ended question to gather qualitative insights. Quantitative
data were analyzed using statistical methods, while qualitative responses
underwent thematic analysis. Results reveal that while PjBL is widely valued,
its adoption is often selective and impacted by challenges in planning and
managing the learning process, designing suitable projects, and a lack of
institutional support, such as time, funding, and teaching assistants. Faculty
are more likely to adopt or sustain PjBL when they have access to peer
collaboration, professional development, and institutional incentives. In
addition, sourcing projects from research, industry partnerships, and borrowing
from peers emerged as key facilitators for new projects. These findings
underscore the need for systemic support structures to empower faculty to
experiment with and scale PjBL practices.

</details>


### [7] [An Empirical Study of Complexity, Heterogeneity, and Compliance of GitHub Actions Workflows](https://arxiv.org/abs/2507.18062)
*Edward Abrokwah,Taher A. Ghaleb*

Main category: cs.SE

TL;DR: 本文系统分析了开源项目中GitHub Actions（GHA）CI工作流的结构和合规情况，发现虽有部分实践合理简洁，但也存在复杂和不规范的现象，建议改进CI文档和实践指导。


<details>
  <summary>Details</summary>
Motivation: 随着持续集成（CI）成为现代软件工程的重要部分，GitHub Actions（GHA）由于其与GitHub的深度集成和丰富的生态系统，成为主流的CI服务。尽管有官方文档和最佳实践，但缺乏对开源真实CI工作流与这些实践一致性的实证研究，因此有必要分析当前开源项目GHA工作流的结构与实际执行情况。

Method: 本研究通过收集和分析大规模Java、Python和C++开源仓库中的GHA工作流，系统性地探索工作流的结构、复杂性、多样性以及其与GHA最佳实践的一致性。

Result: 研究将识别出工作流的复杂性、复用与异构结构模式、对最佳实践的遵循程度，以及不同编程语言下CI流程设计的差异。

Conclusion: 研究发现有些领域很好地遵循了最佳实践，但同时也揭示了许多工作流复杂且与CI实践的简洁性目标不符，指出需要在CI文档中提供更清晰的指导和更全面的示例。

Abstract: Continuous Integration (CI) has evolved from a tooling strategy to a
fundamental mindset in modern CI engineering. It enables teams to develop,
test, and deliver software rapidly and collaboratively. Among CI services,
GitHub Actions (GHA) has emerged as a dominant service due to its deep
integration with GitHub and a vast ecosystem of reusable workflow actions.
Although GHA provides official documentation and community-supported best
practices, there appears to be limited empirical understanding of how
open-source real-world CI workflows align with such practices. Many workflows
might be unnecessarily complex and not aligned with the simplicity goals of CI
practices. This study will investigate the structure, complexity,
heterogeneity, and compliance of GHA workflows in open-source software
repositories. Using a large dataset of GHA workflows from Java, Python, and C++
repositories, our goal is to (a) identify workflow complexities, (b) analyze
recurring and heterogeneous structuring patterns, (c) assess compliance with
GHA best practices, and (d) uncover differences in CI pipeline design across
programming languages. Our findings are expected to reveal both areas of strong
adherence to best practices and areas for improvement where needed. These
insights will also have implications for CI services, as they will highlight
the need for clearer guidelines and comprehensive examples in CI documentation.

</details>


### [8] [Identifier Name Similarities: An Exploratory Study](https://arxiv.org/abs/2507.18081)
*Carol Wong,Mai Abe,Silvia De Benedictis,Marissa Halim,Anthony Peruma*

Main category: cs.SE

TL;DR: 本文开发了标识符名称相似性的初步分类法，为研究名称相似性对代码理解与协作的影响提供了分析工具和理论基础。


<details>
  <summary>Details</summary>
Motivation: 标识符名称在代码理解中非常关键，但如果名称选择不当，会增加理解难度并影响协作。即使在孤立情况下看似易读的名称，在与其他结构或功能相似的名称同时出现时，也容易造成误解，目前对于标识符名称相似性的系统性研究有限。

Method: 本研究通过对软件项目中的标识符名称相似性进行探索性分析，开发了一套对标识符名称相似性进行分类的初步分类法（taxonomy）。

Result: 研究提出了一套初步的标识符名称相似性分类法，为后续分析名称相似性对代码理解、可维护性和开发者协作的影响提供了工具和平台。

Conclusion: 该初步分类法有助于推动标识符名称相似性方面的研究，为理解其对代码开发过程的影响奠定了基础，并期待社区对该分类法进行进一步完善和扩展。

Abstract: Identifier names, which comprise a significant portion of the codebase, are
the cornerstone of effective program comprehension. However, research has shown
that poorly chosen names can significantly increase cognitive load and hinder
collaboration. Even names that appear readable in isolation may lead to
misunderstandings in contexts when they closely resemble other names in either
structure or functionality. In this exploratory study, we present our
preliminary findings on the occurrence of identifier name similarity in
software projects through the development of a taxonomy that categorizes
different forms of identifier name similarity. We envision our initial taxonomy
providing researchers with a platform to analyze and evaluate the impact of
identifier name similarity on code comprehension, maintainability, and
collaboration among developers, while also allowing for further refinement and
expansion of the taxonomy.

</details>


### [9] [Understanding the Supply Chain and Risks of Large Language Model Applications](https://arxiv.org/abs/2507.18105)
*Yujie Ma,Lili Quan,Xiaofei Xie,Qiang Hu,Jiongchi Yu,Yao Zhang,Sen Chen*

Main category: cs.SE

TL;DR: 本文构建了首个关于大模型供应链安全的综合数据集，通过分析近4000个真实应用发现LLM生态存在严重的多层依赖与安全隐患，呼吁业界关注供应链整体安全并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）被广泛部署，但其供应链包括预训练模型、第三方库、数据集和基础设施等复杂环节，目前对供应链风险的系统性评估和数据集基本缺失。

Method: 构建并发布首个面向LLM供应链安全的综合数据集，收集了3,859个真实LLM应用，分析它们之间的依赖关系，识别相关模型、数据集、库，并梳理微调路径、数据集复用、库依赖情况。同时，从公开漏洞数据库收集风险事件，对供应链中的安全风险进行实证分析。

Result: 发现LLM应用存在深度嵌套的依赖关系，供应链各环节均存在大量安全风险，显示出仅关注单一环节远不能全面保障LLM系统的安全。

Conclusion: 需要将LLM系统的安全分析拓展到整个供应链层面，开发者与研究人员需关注生态系统内的系统性风险，并据此采取多元化的安全防护措施。

Abstract: The rise of Large Language Models (LLMs) has led to the widespread deployment
of LLM-based systems across diverse domains. As these systems proliferate,
understanding the risks associated with their complex supply chains is
increasingly important. LLM-based systems are not standalone as they rely on
interconnected supply chains involving pretrained models, third-party
libraries, datasets, and infrastructure. Yet, most risk assessments narrowly
focus on model or data level, overlooking broader supply chain vulnerabilities.
While recent studies have begun to address LLM supply chain risks, there
remains a lack of benchmarks for systematic research.
  To address this gap, we introduce the first comprehensive dataset for
analyzing and benchmarking LLM supply chain security. We collect 3,859
real-world LLM applications and perform interdependency analysis, identifying
109,211 models, 2,474 datasets, and 9,862 libraries. We extract model
fine-tuning paths, dataset reuse, and library reliance, mapping the ecosystem's
structure. To evaluate security, we gather 1,555 risk-related issues-50 for
applications, 325 for models, 18 for datasets, and 1,229 for libraries from
public vulnerability databases.
  Using this dataset, we empirically analyze component dependencies and risks.
Our findings reveal deeply nested dependencies in LLM applications and
significant vulnerabilities across the supply chain, underscoring the need for
comprehensive security analysis. We conclude with practical recommendations to
guide researchers and developers toward safer, more trustworthy LLM-enabled
systems.

</details>


### [10] [NoCode-bench: A Benchmark for Evaluating Natural Language-Driven Feature Addition](https://arxiv.org/abs/2507.18130)
*Le Deng,Zhonghao Jiang,Jialun Cao,Michael Pradel,Zhongxin Liu*

Main category: cs.SE

TL;DR: 作者建立了一个真实自然语言驱动代码功能添加的测试基准NoCode-bench，对主流LLM能力进行了系统测评，发现其性能有限（成功率仅15.79%），尚不足以支撑完全的自然语言无代码开发。


<details>
  <summary>Details</summary>
Motivation: 使用自然语言驱动的无代码开发有望提高开发效率并降低门槛，大型语言模型（LLM）在此方向表现出潜力。然而，现有对LLM在实际自然语言驱动的功能添加任务上的能力评估不充分，需要有针对性的基准进行系统评测。

Method: 作者提出了NoCode-bench，这是一个面向真实世界项目的基准，包括10个项目、634个任务和11.4万次代码变更。每个任务由文档更新和对应的代码实现组成，均通过开发者编写的测试用例验证。并从中筛选出114个高质量、人类核查的任务子集（NoCode-bench Verified）以保证评测的可靠性。

Result: 实验结果显示，即使是表现最好的LLM，在任务成功率上也仅达到15.79%，表明其在跨文件编辑、理解大型代码库及工具调用等方面存在显著挑战。

Conclusion: 当前LLM尚不能胜任完全基于自然语言的无代码开发任务，NoCode-bench为该领域的后续研究和进步奠定了基准和基础。

Abstract: Natural language-driven no-code development allows users to specify software
functionality using natural language (NL) instead of editing source code,
promising increased productivity and democratized development. Large language
models (LLMs) show potential in enabling this paradigm. In this context,
software documentation acts as an NL specification for functionality. This work
introduces NoCode-bench, a benchmark designed to evaluate LLMs on real-world
NL-driven feature addition tasks, consisting of 634 tasks across 10 projects
and 114k code changes. Each task pairs documentation updates with corresponding
code implementations, validated by developer-written test cases. A subset of
114 high-quality, human-verified instances, NoCode-bench Verified, ensures
reliable evaluation. Our experiments reveal that, despite high token usage, the
best LLMs achieve a task success rate of only 15.79%, highlighting challenges
in cross-file editing, codebase understanding, and tool calling. These findings
indicate that LLMs are not yet ready for fully NL-driven no-code development.
NoCode-bench lays the foundation for future advances in this area.

</details>


### [11] [SMECS: A Software Metadata Extraction and Curation Software](https://arxiv.org/abs/2507.18159)
*Stephan Ferenz,Aida Jafarbigloo,Oliver Werth,Astrid Nieße*

Main category: cs.SE

TL;DR: 本文提出了SMECS工具，能自动提取和管理研究软件的元数据，降低了研究人员创建高质量元数据的门槛，实验验证了其良好可用性，有助于研究软件FAIR化。


<details>
  <summary>Details</summary>
Motivation: 元数据对于促进研究软件的FAIR（可查找、可获取、可互操作、可重用）原则至关重要，但高质量元数据的创建过程较为费时费力。

Method: 开发了一款名为SMECS的元数据提取与管理软件，能够从如GitHub等在线代码库中自动提取元数据，并通过交互界面辅助用户完善、整理与导出为CodeMeta文件。

Result: 通过可用性实验对SMECS进行了评估，结果表明其提供了令人满意的用户体验。

Conclusion: SMECS能够简化元数据创建过程，推动研究软件FAIR原则的实现。

Abstract: Metadata play a crucial role in adopting the FAIR principles for research
software and enables findability and reusability. However, creating
high-quality metadata can be resource-intensive for researchers and research
software engineers. To address this challenge, we developed the Software
Metadata Extraction and Curation Software (SMECS) which integrates the
extraction of metadata from existing sources together with a user-friendly
interface for metadata curation. SMECS extracts metadata from online
repositories such as GitHub and presents it to researchers through an
interactive interface for further curation and export as a CodeMeta file. The
usability of SMECS was evaluated through usability experiments which confirmed
that SMECS provides a satisfactory user experience. SMECS supports the
FAIRification of research software by simplifying metadata creation.

</details>


### [12] [GenAI for Automotive Software Development: From Requirements to Wheels](https://arxiv.org/abs/2507.18223)
*Nenad Petrovic,Fengjunjie Pan,Vahid Zolfaghari,Krzysztof Lebioda,Andre Schamschurko,Alois Knoll*

Main category: cs.SE

TL;DR: 本研究提出了一套以生成式AI和模型驱动工程为基础的ADAS软件自动化开发方案，能自动生成需求摘要、仿真测试与目标平台代码，显著缩短开发周期并提高法律合规效率。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶和高级驾驶辅助系统（ADAS）软件开发中，提高自动化水平、减少开发与测试时间，并增强需求与法规符合性管理成为重要诉求。

Method: 提出了一种基于生成式AI的方法，实现从需求输入到仿真测试场景代码和目标硬件平台ADAS功能代码（Python和C++）的自动化生成，流程中引入了模型驱动工程（MDE）进行需求一致性检查，并结合大型语言模型（LLM）进行需求摘要和代码自动生成，同时采用检索增强生成（RAG）技术从法规文件中提升测试场景生成的质量。

Result: 该方法实现了ADAS相关能力开发与测试流程的自动化，有助于缩短合规和再工程周期，降低开发与测试成本，提高自动驾驶软件开发的效率和一致性。

Conclusion: 生成式AI与自动化工具相结合可有效提升ADAS软件的开发效率与法规符合性，有望推动汽车软件开发的智能化与自动化进程。

Abstract: This paper introduces a GenAI-empowered approach to automated development of
automotive software, with emphasis on autonomous and Advanced Driver Assistance
Systems (ADAS) capabilities. The process starts with requirements as input,
while the main generated outputs are test scenario code for simulation
environment, together with implementation of desired ADAS capabilities
targeting hardware platform of the vehicle connected to testbench. Moreover, we
introduce additional steps for requirements consistency checking leveraging
Model-Driven Engineering (MDE). In the proposed workflow, Large Language Models
(LLMs) are used for model-based summarization of requirements (Ecore metamodel,
XMI model instance and OCL constraint creation), test scenario generation,
simulation code (Python) and target platform code generation (C++).
Additionally, Retrieval Augmented Generation (RAG) is adopted to enhance test
scenario generation from autonomous driving regulations-related documents. Our
approach aims shorter compliance and re-engineering cycles, as well as reduced
development and testing time when it comes to ADAS-related capabilities.

</details>


### [13] [An Empirical Study on Embodied Artificial Intelligence Robot (EAIR) Software Bugs](https://arxiv.org/abs/2507.18267)
*Zeqin Liao,Zibin Zheng,Peifan Reng,Henglong Liang,Zixu Gao,Zhixiang Chen,Wei Li,Yuhong Nan*

Main category: cs.SE

TL;DR: 首次系统性分析了EAIR系统中的bug，明确归类了其症状、成因和分布，发现了多种EAIR特有问题，并建立了成因-模块映射，为未来EAIR bug检测和修复提供依据。


<details>
  <summary>Details</summary>
Motivation: 随着Embodied Artificial Intelligence Robots（EAIR）技术的发展，确保其程序的正确性至关重要，但目前对EAIR系统bug的全面、深入理解仍然很缺乏，影响了有效排查和修复bug的相关实践和技术发展。

Method: 系统性分析了80个EAIR项目中收集的885个系统bug，包括bug的症状、根本原因以及模块分布，并将其归类为18种根本原因、15种不同症状和13个受影响模块。

Result: 发现了8种EAIR系统特有的bug症状（多为严重的功能故障和潜在物理危险）和8种EAIR特有的根本原因（主要来自AI代理的推理与决策复杂性）。还建立了根本原因与其多发模块之间的映射，有助于精准高效地进行bug预测、检测和修复。

Conclusion: 本研究填补了EAIR系统bug全景认识的空白，揭示了EAIR特有的bug类型及其分布规律，为后续研究和实践提供了理论和方向支持。

Abstract: Embodied Artificial Intelligence Robots (EAIR) is an emerging and rapidly
evolving technological domain. Ensuring their program correctness is
fundamental to their successful deployment. However, a general and in-depth
understanding of EAIR system bugs remains lacking, which hinders the
development of practices and techniques to tackle EAIR system bugs.
  To bridge this gap, we conducted the first systematic study of 885 EAIR
system bugs collected from 80 EAIR system projects to investigate their
symptoms, underlying causes, and module distribution. Our analysis takes
considerable effort, which classifies these bugs into 18 underlying causes, 15
distinct symptoms, and identifies 13 affected modules. It reveals several new
interesting findings and implications which help shed light on future research
on tackling or repairing EAIR system bugs. First, among the 15 identified
symptoms, our findings highlight 8 symptoms specific to EAIR systems, which is
characterized by severe functional failures and potential physical hazards.
Second, within the 18 underlying causes, we define 8 EAIR-specific causes, the
majority of which stem from the intricate issues of AI- agent reasoning and
decision making. Finally, to facilitate precise and efficient bug prediction,
detection, and repair, we constructed a mapping between underlying causes and
the modules in which they most frequently occur, which enables researchers to
focus diagnostic efforts on the modules most susceptible to specific bug types.

</details>


### [14] [Scheduzz: Constraint-based Fuzz Driver Generation with Dual Scheduling](https://arxiv.org/abs/2507.18289)
*Yan Li,Wenzhang Yang,Yuekun Wang,Jian Gao,Shaohua Wang,Yinxing Xue,Lijun Zhang*

Main category: cs.SE

TL;DR: 本文提出了基于LLM和调度优化的新库模糊测试技术Scheduzz，显著提升覆盖率并发现多个新漏洞，兼顾效率与质量，优于多种现有方案。


<details>
  <summary>Details</summary>
Motivation: 现有库模糊测试(fuzzing)需要专家手动编写高质量fuzz driver，工作繁琐且容易出错。自动生成driver的方法却因不了解合理用法，导致生成低效、错误众多的driver，浪费计算资源并产生许多误报。

Method: 提出一种新颖的基于大语言模型(LLM)的自动库模糊测试技术Scheduzz。Scheduzz利用LLM理解库的合理用法并提取API组合约束，同时引入双调度框架高效管理API组合和driver，将driver生成与fuzz过程建模为在线优化问题并动态调度。

Result: 在33个真实世界库上，Scheduzz显著降低了计算开销，并在21个库中有16个超越了UTopia。其代码覆盖率分别比CKGFuzzer、Promptfuzz和OSS-Fuzz高出1.62倍、1.50倍和1.89倍，且共挖掘出33个新漏洞，其中3个被赋予CVE号。

Conclusion: Scheduzz有效解决了自动库模糊测试中driver低质与计算资源浪费问题，能够高效发现高质量新漏洞，提升了模糊测试的智能化与实用性。

Abstract: Fuzzing a library requires experts to understand the library usage well and
craft high-quality fuzz drivers, which is tricky and tedious. Therefore, many
techniques have been proposed to automatically generate fuzz drivers. However,
they fail to generate rational fuzz drivers due to the lack of adherence to
proper library usage conventions, such as ensuring a resource is closed after
being opened. To make things worse, existing library fuzzing techniques
unconditionally execute each driver, resulting in numerous irrational drivers
that waste computational resources while contributing little coverage and
generating false positive bug reports.
  To tackle these challenges, we propose a novel automatic library fuzzing
technique, Scheduzz, an LLM-based library fuzzing technique. It leverages LLMs
to understand rational usage of libraries and extract API combination
constraints. To optimize computational resource utilization, a dual scheduling
framework is implemented to efficiently manage API combinations and fuzz
drivers. The framework models driver generation and the corresponding fuzzing
campaign as an online optimization problem. Within the scheduling loop,
multiple API combinations are selected to generate fuzz drivers, while
simultaneously, various optimized fuzz drivers are scheduled for execution or
suspension.
  We implemented Scheduzz and evaluated it in 33 real-world libraries. Compared
to baseline approaches, Scheduzz significantly reduces computational overhead
and outperforms UTopia on 16 out of 21 libraries. It achieves 1.62x, 1.50x, and
1.89x higher overall coverage than the state-of-the-art techniques CKGFuzzer,
Promptfuzz, and the handcrafted project OSS-Fuzz, respectively. In addition,
Scheduzz discovered 33 previously unknown bugs in these well-tested libraries,
3 of which have been assigned CVEs.

</details>


### [15] [YATE: The Role of Test Repair in LLM-Based Unit Test Generation](https://arxiv.org/abs/2507.18316)
*Michael Konstantinou,Renzo Degiovanni,Jie M. Zhang,Mark Harman,Mike Papadakis*

Main category: cs.SE

TL;DR: YATE结合静态分析和二次提示修复错误测试用例，不仅提升了自动化测试的覆盖率和有效性，还显著优于其他LLM自动测试生成方法。


<details>
  <summary>Details</summary>
Motivation: 随着自动化测试生成技术的发展，语言模型在生成单元测试中表现出色，但常生成语法或语义错误的测试用例，这些错误测试若能修复可能极具价值，因此需要寻找自动修复方法利用这些“错失机会”。

Method: 提出了一种结合基于规则的静态分析与二次提示（re-prompting）的简单自动修复方法，并命名为YATE。通过静态分析发现有用但不正确的测试，再用LLM辅助修正后重新生成。

Result: YATE在6个开源项目上表现优异，相较于普通的LLM测试生成方法，平均多覆盖32.06%的代码行，杀死了21.77%更多的变异体。与HITS、SYMPROMPT、TESTSPARK和COVERUP等其他LLM方法对比，YATE行覆盖率和分支覆盖率分别高出22%与20%，杀死的变异体也多20%，且生成成本相当。

Conclusion: 本文提出的YATE方法能够有效修复语言模型生成的不正确测试，最大化利用这些测试的价值，并在多个开源项目上实现了显著优于现有方法的代码覆盖和错误检测能力。

Abstract: Recent advances in automated test generation utilises language models to
produce unit tests. While effective, language models tend to generate many
incorrect tests with respect to both syntax and semantics. Although such
incorrect tests can be easily detected and discarded, they constitute a "missed
opportunity" -- if fixed, they are often valuable as they directly add testing
value (they effectively target the underlying program logic to be tested) and
indirectly form good seeds for generating additional tests. To this end, we
propose a simple technique for repairing some of these incorrect tests through
a combination of rule-based static analysis and re-prompting. We evaluate this
simple approach, named YATE, on a set of 6 open-source projects and show that
it can effectively produce tests that cover on average 32.06% more lines and
kill 21.77% more mutants than a plain LLM-based method. We also compare YATE
with four other LLM-based methods, namely HITS, SYMPROMPT, TESTSPARK and
COVERUP and show that it produces tests that cover substantially more code.
YATE achieves 22% higher line coverage, 20% higher branch coverage and kill 20%
more mutants at a comparable cost (number of calls to LLMs).

</details>


### [16] [Gotta catch 'em all! Towards File Localisation from Issues at Large](https://arxiv.org/abs/2507.18319)
*Jesse Maarleveld,Jiapan Guo,Daniel Feitosa*

Main category: cs.SE

TL;DR: 该工作提出了构建全类型问题文件定位数据集的流程，发现现有以bug为中心的方法难以泛化，建议未来研究通用及可调优的定位技术。


<details>
  <summary>Details</summary>
Motivation: 目前自动定位需更改文件以修复bug的技术多聚焦于bug类问题，对其它类型问题的研究稀缺。作者希望扩展研究视角，涵盖所有类型的issue（问题），不限于bug。

Method: 作者提出一个能够处理任意分支与合并实践的数据处理流程，用以自动生成用于定位与问题相关文件的数据集，并基于传统信息检索手段给出基线性能评估。作者还通过统计分析探究了数据集受已知偏差的影响。

Result: 以bug为核心的启发式定位方法在泛化到其它问题类别时表现较差，说明需发展通用型模型。虽然不同类型issue之间性能差异存在但不大且统计显著，标识符的存在对大多数类型影响较小。很多结果依赖具体项目，因此应发展可针对不同项目调优的方法。

Conclusion: 目前主流bug定位技术对一般问题类型适应性较差，未来应研究通用及可项目自适应的定位方法。

Abstract: Bug localisation, the study of developing methods to localise the files
requiring changes to resolve bugs, has been researched for a long time to
develop methods capable of saving developers' time. Recently, researchers are
starting to consider issues outside of bugs. Nevertheless, most existing
research into file localisation from issues focusses on bugs or uses other
selection methods to ensure only certain types of issues are considered as part
of the focus of the work. Our goal is to work on all issues at large, without
any specific selection.
  In this work, we provide a data pipeline for the creation of issue file
localisation datasets, capable of dealing with arbitrary branching and merging
practices. We provide a baseline performance evaluation for the file
localisation problem using traditional information retrieval approaches.
Finally, we use statistical analysis to investigate the influence of biases
known in the bug localisation community on our dataset.
  Our results show that methods designed using bug-specific heuristics perform
poorly on general issue types, indicating a need for research into general
purpose models. Furthermore, we find that there are small, but statistically
significant differences in performance between different issue types. Finally,
we find that the presence of identifiers have a small effect on performance for
most issue types. Many results are project-dependent, encouraging the
development of methods which can be tuned to project-specific characteristics.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [17] [Program Logics via Distributive Monoidal Categories](https://arxiv.org/abs/2507.18238)
*Filippo Bonchi,Elena Di Lavore,Mario Román,Sam Staton*

Main category: cs.LO

TL;DR: 本文用范畴论统一推导出多种程序逻辑（如 Hoare 逻辑），并提出了适用的内部语言和组合子，为程序推理提供了统一坚实的理论框架。


<details>
  <summary>Details</summary>
Motivation: 现有的程序逻辑（如 Hoare 逻辑及其变种）理论较为分散，缺乏一个统一的公理化框架。本文旨在以范畴论为基础，为多种程序逻辑提供统一推导基础。

Method: 作者提出了一种命令式多范畴的内部语言，并以此为基础推导出适配 Dijkstra 守护命令语言的组合子。同时，从这个内部语言中系统地推导出程序逻辑的推理规则。

Result: 建立了一个以命令式范畴公理为核心的框架，统一导出多类程序逻辑，理论基础扎实，并配有适合程序推理的内部语言和组合子。

Conclusion: 本文成功展示了如何从命令式范畴的公理出发，统一推导出多种程序逻辑，包括正确性、错误性以及关系 Hoare 逻辑。

Abstract: We derive multiple program logics, including correctness, incorrectness, and
relational Hoare logic, from the axioms of imperative categories: uniformly
traced distributive copy-discard categories. We introduce an internal language
for imperative multicategories, on top of which we derive combinators for an
adaptation of Dijkstra's guarded command language. Rules of program logics are
derived from this internal language.

</details>


### [18] [Resourceful Traces for Commuting Processes](https://arxiv.org/abs/2507.18246)
*Matthew Earnshaw,Chad Nester,Mario Román*

Main category: cs.LO

TL;DR: 本文将Mazurkiewicz trace动作提升为具类型变换的操作，进而为effectful categories赋予全新图示化表示，并实现其自由范畴的可交换张量积组合，丰富了副作用计算语义建模。


<details>
  <summary>Details</summary>
Motivation: 以往Mazurkiewicz trace仅被当作原子动作符号处理，而现实的副作用计算场景常涉及动作对输入输出类型的变换。该文旨在填补这种从变换角度对trace动作解释的理论空白，并推动effectful categories的结构表达与组合研究。

Method: 将Mazurkiewicz trace的动作从“原子”转化为类型化变换，并借此发展effectful categories（广义Freyd categories）的表示理论，通过图形演算形式描述相关结构。运用这一表示，对free effectful categories之间的commuting tensor product进行了构造。

Result: 提出了基于类型化transformation的Mazurkiewicz trace动作的新颖表示，定义了effectful categories的图形演算，并构造出free effectful categories的commuting tensor product，有利于描述系统协作时动作交换及资源流动。

Conclusion: 将Mazurkiewicz trace的动作视为从指定类型输入到输出的变换，能够提出effectful categories的新表示方式，并为其组合和图形化提供理论基础。

Abstract: We show that, when the actions of a Mazurkiewicz trace are considered not
merely as atomic (i.e., mere names) but transformations from a specified type
of inputs to a specified type of outputs, we obtain a novel notion of
presentation for effectful categories (also known as generalised Freyd
categories), a well-known algebraic structure in the semantics of
side-effecting computation. Like the usual representation of traces as graphs,
our notion of presentation gives rise to a graphical calculus for effectful
categories. We use our presentations to give a construction of the commuting
tensor product of free effectful categories, capturing the combination of
systems in which the actions of each must commute with one another, while still
permitting exchange of resources

</details>


### [19] [Distributing Retractions, Weak Distributive Laws and Applications to Monads of Hyperspaces, Continuous Valuations and Measures](https://arxiv.org/abs/2507.18418)
*Jean Goubault-Larrecq*

Main category: cs.LO

TL;DR: 论文提出新方法，用分配缩退识别两个幺半群通过弱分配律合成的幺半群，并证明这种方法与弱分配律严格对应，展示其在Hausdorff紧空间范畴和相关幺半群中的应用。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在解决在范畴中，给定两个幺半群S、T及其弱分配律时，如何构造并准确描述其合成幺半群U的问题。此过程在数学结构及具体应用中具有广泛意义，但具体实现往往复杂。

Method: 作者首先提出了分配缩退（distributing retraction）的概念，通过该结构可以识别合成幺半群U。随后在2-范畴的框架下，证明了分配缩退与弱分配律一一对应。最后，通过具体例子（S为三种hyperspace幺半群，T为连续赋值的幺半群），展示方法的应用及其在Hausdorff紧空间范畴中的含义。

Result: 作者建立了分配缩退与弱分配律间的严格对应关系，从而系统性地识别合成幺半群U。此外，通过研究具体的幺半群（如Smyth、Hoare、Plotkin及赋值相关的幺半群），描述了预视monad（previsions）和forks的结构，以及超线性和次线性预视的代数结构。

Conclusion: 该论文为在范畴论中合成幺半群的识别和结构描述提供了一个统一、可操作的方法，扩展了幺半群、范畴论及其在连续赋值等应用领域的理论基础。

Abstract: Given two monads $S$, $T$ on a category where idempotents split, and a weak
distributive law between them, one can build a combined monad $U$. Making
explicit what this monad $U$ is requires some effort. When we already have an
idea what $U$ should be, we show how to recognize that $U$ is indeed the
combined monad obtained from $S$ and $T$: it suffices to exhibit what we call a
distributing retraction of $ST$ onto $U$. We show that distributing retractions
and weak distributive laws are in one-to-one correspondence, in a 2-categorical
setting. We give three applications, where $S$ is the Smyth, Hoare or Plotkin
hyperspace monad, $T$ is a monad of continuous valuations, and $U$ is a monad
of previsions or of forks, depending on the case. As a byproduct, this allows
us to describe the algebras of monads of superlinear, resp. sublinear
previsions. In the category of compact Hausdorff spaces, the Plotkin hyperspace
monad is sometimes known as the Vietoris monad, the monad of probability
valuations coincides with the Radon monad, and we infer that the associated
combined monad is the monad of normalized forks.

</details>


### [20] [Well-Founded Coalgebras Meet König's Lemma](https://arxiv.org/abs/2507.18539)
*Henning Urbat,Thorsten Wißmann*

Main category: cs.LO

TL;DR: 本文将König引理从有限分支树拓展到了适当范畴与余代数情形，建立了广义版定理，并据此给出了初始代数的新构造方法，实现了理论上的重要推广与简化。


<details>
  <summary>Details</summary>
Motivation: König引理是数学与计算机科学中关于树的一个基本定理，具有广泛应用。现有结论仅限于集合上的有限分支树，作者希望对其进行推广：一是从有限分支树推广至任意有限性函子的余代数结构，另一方面则把讨论范畴从集合扩展到更一般的局部有限呈现范畴（例如偏序集、名义集、凸集等），以适应更多抽象结构的分析需求。

Method: 基于范畴论的余代数理论，作者推广König引理，从集合上的树扩展到泛局部有限呈现范畴上的余代数。具体来说，给定一个有限性函子H和局部有限呈现范畴C，在适当假设下，他们证明：每个H的良基余代数都是其有限生成状态空间的良基子余代数量向上组合。此外，探讨了初始代数（等价于最终递归余代数）的新构造：即所有有限呈现状态空间的良基（或递归）余代数的余极限。

Result: 给出了广义“König引理”：良基余代数是所有有限生成状态空间的子余代数的指向并（directed join）。因此，良基余代数组成的范畴是局部可呈现的。得益于该结果，推出了若干变体König引理（如在topos、名义或凸迁移系统中的形式），同时得到关于初始代数的新建构方式，其中一种为全新提供，另一种证明了更短且透明。值得注意的是，即使在良基余代数和递归余代数不同的场合也成立。

Conclusion: 提出并证明了König引理的泛余代数版本，以及初始代数的两种新型构造与证明，拓展了原有定理的适用范围，为相关领域（例如拓扑、名义系统、状态转换系统等）提供了理论基础。

Abstract: K\"onig's lemma is a fundamental result about trees with countless
applications in mathematics and computer science. In contrapositive form, it
states that if a tree is finitely branching and well-founded (i.e. has no
infinite paths), then it is finite. We present a coalgebraic version of
K\"onig's lemma featuring two dimensions of generalization: from finitely
branching trees to coalgebras for a finitary endofunctor H, and from the base
category of sets to a locally finitely presentable category C, such as the
category of posets, nominal sets, or convex sets. Our coalgebraic K\"onig's
lemma states that, under mild assumptions on C and H, every well-founded
coalgebra for H is the directed join of its well-founded subcoalgebras with
finitely generated state space -- in particular, the category of well-founded
coalgebras is locally presentable. As applications, we derive versions of
K\"onig's lemma for graphs in a topos as well as for nominal and convex
transition systems. Additionally, we show that the key construction underlying
the proof gives rise to two simple constructions of the initial algebra
(equivalently, the final recursive coalgebra) for the functor H: The initial
algebra is both the colimit of all well-founded and of all recursive coalgebras
with finitely presentable state space. Remarkably, this result holds even in
settings where well-founded coalgebras form a proper subclass of recursive
ones. The first construction of the initial algebra is entirely new, while for
the second one our approach yields a short and transparent new correctness
proof.

</details>


### [21] [Proceedings 19th International Workshop on the ACL2 Theorem Prover and Its Applications](https://arxiv.org/abs/2507.18567)
*Ruben Gamboa,Panagiotis Manolios*

Main category: cs.LO

TL;DR: ACL2 Workshop聚焦于ACL2定理证明器及其相关研究，是专业交流的核心平台，ACL2等定理证明器因突出贡献获得ACM大奖。


<details>
  <summary>Details</summary>
Motivation: 推动ACL2定理证明器及其应用的研究交流，展示最新进展和成果。

Method: 通过ACL2 Workshop系列会议，提供交流平台，让研究者分享与ACL2及其家族定理证明器相关的研究和应用。

Result: ACL2及Boyer-Moore系列定理证明器获得了广泛认可，并因其贡献获得了2005年ACM软件系统奖。

Conclusion: ACL2 Workshop代表了ACL2社群的主要技术交流场所，促进了定理证明领域技术的进步与应用推广。

Abstract: The ACL2 Workshop series is the major technical forum for users of the ACL2
theorem proving system to present research related to the ACL2 theorem prover
and its applications. ACL2 is an industrial-strength automated reasoning
system, the latest in the Boyer-Moore family of theorem provers. The 2005 ACM
Software System Award was awarded to Boyer, Kaufmann, and Moore for their work
on ACL2 and the other theorem provers in the Boyer-Moore family.

</details>


### [22] [Approximate SMT Counting Beyond Discrete Domains](https://arxiv.org/abs/2507.18612)
*Arijit Shaw,Kuldeep S. Meel*

Main category: cs.LO

TL;DR: 本文提出的pact方法可高效地近似计数混合SMT公式的解数，在大量基准测试中显著优于传统方法，拓展了SMT模型计数在自动化推理中的应用范围。


<details>
  <summary>Details</summary>
Motivation: SMT求解器在自动化推理领域取得了巨大进展，但是现有方法如bit-blasting只适用于离散变量，难以在混合SMT公式上进行模型计数。因此，有必要扩展SMT求解器以高效解决混合公式的模型计数问题。

Method: 提出了pact方法，这是一种面向混合公式的SMT模型计数器，采用基于哈希的近似模型计数，能够以理论保证的误差范围高效估计解的数量，且SMT调用次数对投影变量数量为对数级。

Result: pact在大规模基准测试集上表现显著优于现有方法。在14,202个实例中，pact成功解决了603个实例，而基线方法仅成功解决了13个实例。

Conclusion: pact显著提升了混合SMT公式的模型计数能力，克服了现有技术的局限性，在性能上具有明显优势。

Abstract: Satisfiability Modulo Theory (SMT) solvers have advanced automated reasoning,
solving complex formulas across discrete and continuous domains. Recent
progress in propositional model counting motivates extending SMT capabilities
toward model counting, especially for hybrid SMT formulas. Existing approaches,
like bit-blasting, are limited to discrete variables, highlighting the
challenge of counting solutions projected onto the discrete domain in hybrid
formulas.
  We introduce pact, an SMT model counter for hybrid formulas that uses
hashing-based approximate model counting to estimate solutions with theoretical
guarantees. pact makes a logarithmic number of SMT solver calls relative to the
projection variables, leveraging optimized hash functions. pact achieves
significant performance improvements over baselines on a large suite of
benchmarks. In particular, out of 14,202 instances, pact successfully finished
on 603 instances, while Baseline could only finish on 13 instances.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [23] [Shop-R1: Rewarding LLMs to Simulate Human Behavior in Online Shopping via Reinforcement Learning](https://arxiv.org/abs/2507.17842)
*Yimeng Zhang,Tian Wang,Jiri Gesi,Ziyi Wang,Yuxuan Lu,Jiacheng Lin,Sinong Zhan,Vianne Gao,Ruochen Jiao,Junze Liu,Kun Qian,Yuxin Tang,Ran Xue,Houyu Zhang,Qingjun Cui,Yufan Guo,Dakuo Wang*

Main category: cs.CL

TL;DR: 论文提出Shop-R1，通过分阶段奖励与自监督等方法大幅提升了大模型在网络购物场景下模拟真实人类行为的能力，性能提升超过65%。


<details>
  <summary>Details</summary>
Motivation: 传统利用LLM生成的rationales并进行有监督微调（SFT）虽然提升了模型的推理能力，但仍受限于生成rationale的模型自身的推理水平，难以进一步突破在复杂行为模拟任务中的表现。

Method: 提出了Shop-R1框架，将人类网络购物行为模拟任务分为rationale生成和动作预测两阶段，分别引入不同奖励信号。rationale生成过程使用模型内部信号（如logit分布）进行自监督引导；动作预测阶段采用分层奖励结构并加入难度感知缩放，既能细粒度反馈也能防止策略作弊，对高层动作类型及其细节分别评估与奖励。

Result: 实验结果表明，Shop-R1方法在下游任务中的表现相比于传统基线方法提升超过65%。

Conclusion: Shop-R1有效提升了LLM在网络购物环境下模拟真实人类行为的推理与决策能力，显著优于已有方法。

Abstract: Large Language Models (LLMs) have recently demonstrated strong potential in
generating 'believable human-like' behavior in web environments. Prior work has
explored augmenting training data with LLM-synthesized rationales and applying
supervised fine-tuning (SFT) to enhance reasoning ability, which in turn can
improve downstream action prediction. However, the performance of such
approaches remains inherently bounded by the reasoning capabilities of the
model used to generate the rationales. In this paper, we introduce Shop-R1, a
novel reinforcement learning (RL) framework aimed at enhancing the reasoning
ability of LLMs for simulation of real human behavior in online shopping
environments Specifically, Shop-R1 decomposes the human behavior simulation
task into two stages: rationale generation and action prediction, each guided
by distinct reward signals. For rationale generation, we leverage internal
model signals (e.g., logit distributions) to guide the reasoning process in a
self-supervised manner. For action prediction, we propose a hierarchical reward
structure with difficulty-aware scaling to prevent reward hacking and enable
fine-grained reward assignment. This design evaluates both high-level action
types and the correctness of fine-grained sub-action details (attributes and
values), rewarding outputs proportionally to their difficulty. Experimental
results show that our method achieves a relative improvement of over 65%
compared to the baseline.

</details>


### [24] [Dynamic and Generalizable Process Reward Modeling](https://arxiv.org/abs/2507.17849)
*Zhangyue Yin,Qiushi Sun,Zhiyuan Zeng,Qinyuan Cheng,Xipeng Qiu,Xuanjing Huang*

Main category: cs.CL

TL;DR: 该文提出了一种动态、可泛化的过程奖励建模（DG-PRM）方法，通过奖励树记录多维度奖励标准，动态生成奖励信号，并采用帕累托支配方法筛选判别对。实验验证了其在多任务、多领域的优异性能和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有PRM主要依赖启发式方法，泛化能力差，难以适应复杂和跨领域场景。同时，基于静态、粗粒度标准的评价方法无法灵活适应复杂过程监督，且忽略了文本中的有意义指导信息。

Method: 提出了DG-PRM，包括奖励树机制，用于捕捉和存储细粒度、多维度的奖励标准，并动态选择奖励信号进行逐步评分。此外，创新性地采用帕累托支配估计来筛选区分性的正负奖励对。

Result: DG-PRM在多个密集奖励任务上显著提升模型能力，在泛化性测试中也表现优异。

Conclusion: DG-PRM表现卓越，能在主流基准测试上显著提升模型性能，且在分布外场景下显示出极强的泛化能力。

Abstract: Process Reward Models (PRMs) are crucial for guiding Large Language Models
(LLMs) in complex scenarios by providing dense reward signals. However,
existing PRMs primarily rely on heuristic approaches, which struggle with
cross-domain generalization. While LLM-as-judge has been proposed to provide
generalized rewards, current research has focused mainly on feedback results,
overlooking the meaningful guidance embedded within the text. Additionally,
static and coarse-grained evaluation criteria struggle to adapt to complex
process supervision. To tackle these challenges, we propose Dynamic and
Generalizable Process Reward Modeling (DG-PRM), which features a reward tree to
capture and store fine-grained, multi-dimensional reward criteria. DG-PRM
dynamically selects reward signals for step-wise reward scoring. To handle
multifaceted reward signals, we pioneeringly adopt Pareto dominance estimation
to identify discriminative positive and negative pairs. Experimental results
show that DG-PRM achieves stunning performance on prevailing benchmarks,
significantly boosting model performance across tasks with dense rewards.
Further analysis reveals that DG-PRM adapts well to out-of-distribution
scenarios, demonstrating exceptional generalizability.

</details>


### [25] [VeriMinder: Mitigating Analytical Vulnerabilities in NL2SQL](https://arxiv.org/abs/2507.17896)
*Shubham Mohole,Sainyam Galhotra*

Main category: cs.CL

TL;DR: 作者提出并实现了VeriMinder系统，能自动检测和缓解用户用NLIDB系统做数据分析时容易出现的认知偏见和“问错问题”，极大提升了自然语言数据分析的质量和可靠性。用户测试显示，系统帮助显著，代码已开源，利于社区发展与研究。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言界面数据库（NLIDB）系统的发展，越来越多用户可以直接以自然语言分析数据，但这些用户往往缺乏统计分析背景，容易在提问和分析过程中产生偏差性问题。目前大多研究关注文本转SQL的准确性，极少涉及用户认知偏见对分析结果的影响。

Method: 本文提出VeriMinder系统。核心创新有三：1）面向具体分析场景设计语义偏见映射框架；2）利用“难以变更原则”（Hard-to-Vary）设计系统性分析指导流程；3）开发基于大模型（LLM）的多候选、多轮自我反思高质量提示生成机制。系统以Web应用形式实现。

Result: 用户测试显示，82.5%的参与者认同该系统能提升分析质量。在与其它方案对比时，VeriMinder在具体性、完整性和准确性三项指标上分数至少高出20%。系统代码已开源。

Conclusion: VeriMinder可有效帮助普通用户识别并规避数据分析中的“提错问题”与偏见脆弱性，大幅提升分析质量，促进了NLIDB实用化和普及。

Abstract: Application systems using natural language interfaces to databases (NLIDBs)
have democratized data analysis. This positive development has also brought
forth an urgent challenge to help users who might use these systems without a
background in statistical analysis to formulate bias-free analytical questions.
Although significant research has focused on text-to-SQL generation accuracy,
addressing cognitive biases in analytical questions remains underexplored. We
present VeriMinder, https://veriminder.ai, an interactive system for detecting
and mitigating such analytical vulnerabilities. Our approach introduces three
key innovations: (1) a contextual semantic mapping framework for biases
relevant to specific analysis contexts (2) an analytical framework that
operationalizes the Hard-to-Vary principle and guides users in systematic data
analysis (3) an optimized LLM-powered system that generates high-quality,
task-specific prompts using a structured process involving multiple candidates,
critic feedback, and self-reflection.
  User testing confirms the merits of our approach. In direct user experience
evaluation, 82.5% participants reported positively impacting the quality of the
analysis. In comparative evaluation, VeriMinder scored significantly higher
than alternative approaches, at least 20% better when considered for metrics of
the analysis's concreteness, comprehensiveness, and accuracy. Our system,
implemented as a web application, is set to help users avoid "wrong question"
vulnerability during data analysis. VeriMinder code base with prompts,
https://reproducibility.link/veriminder, is available as an MIT-licensed
open-source software to facilitate further research and adoption within the
community.

</details>


### [26] [One Whisper to Grade Them All](https://arxiv.org/abs/2507.17918)
*Nhan Phan,Anusha Porwal,Yaroslav Getman,Ekaterina Voskoboinik,Tamás Grósz,Mikko Kurimo*

Main category: cs.CL

TL;DR: 本研究提出了一种高效的端到端多部分口语评分系统，无需转录，显著提升评分准确率和数据利用效率，对大规模语言学习有实际价值。


<details>
  <summary>Details</summary>
Motivation: 现有多部分口语自动评分系统通常依赖于分步建模和转录，存在推理时间长、资源消耗大等问题，无法高效地应用于大规模计算机辅助语言学习场景。

Method: 提出一个端到端的整体自动口语评估系统，创新性地利用单一的Whisper-small编码器处理全部四个口语回答，通过轻量级聚合器整合信息并预测最终分数，无需转录和分项目模型。并设计了新的数据采样策略，提升模型在类别不平衡情况下的数据利用率。

Result: 系统在评估中取得0.384的RMSE，优于基线文本方法（0.44），参数量最多为168M（约为Whisper-small的70%）。采用采样策略后，使用仅44.8%的说话者数据仍达到0.383的RMSE，证明了出色的数据效率和对不均衡类别的适应能力。

Conclusion: 提出的整体ASA系统高效且实用，在多部分外语口语评分任务中效果优于传统方法，显著降低了资源消耗并提高了数据利用效率，有望推动大规模智能语言学习应用的发展。

Abstract: We present an efficient end-to-end approach for holistic Automatic Speaking
Assessment (ASA) of multi-part second-language tests, developed for the 2025
Speak & Improve Challenge. Our system's main novelty is the ability to process
all four spoken responses with a single Whisper-small encoder, combine all
information via a lightweight aggregator, and predict the final score. This
architecture removes the need for transcription and per-part models, cuts
inference time, and makes ASA practical for large-scale Computer-Assisted
Language Learning systems.
  Our system achieved a Root Mean Squared Error (RMSE) of 0.384, outperforming
the text-based baseline (0.44) while using at most 168M parameters (about 70%
of Whisper-small). Furthermore, we propose a data sampling strategy, allowing
the model to train on only 44.8% of the speakers in the corpus and still reach
0.383 RMSE, demonstrating improved performance on imbalanced classes and strong
data efficiency.

</details>


### [27] [Evaluating the Performance of AI Text Detectors, Few-Shot and Chain-of-Thought Prompting Using DeepSeek Generated Text](https://arxiv.org/abs/2507.17944)
*Hulayyil Alshammari,Praveen Rao*

Main category: cs.CL

TL;DR: 主流AI文本检测器对DeepSeek生成内容的检测在原文和普通改写时表现良好，但面对人化等对抗袭击时准确率大幅下滑，需提升鲁棒性。DeepSeek自身通过few-shot和CoT推理方法能实现高效自检测。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）的广泛应用，AI生成文本的检测成为学界和行业的关键问题。尤其是新近发布的DeepSeek模型，其检测能力研究还存在明显空白。此外，文本改写、拟人化等对抗性攻击对检测器带来挑战，亟需评测主流检测工具在DeepSeek文本上的表现及脆弱性。

Method: 本研究选取六款常用AI文本检测工具（AI Text Classifier、Content Detector AI、Copyleaks、QuillBot、GPT-2、GPTZero），结合DeepSeek模型（通过few-shot prompting和chain-of-thought reasoning），检测人类与AI（DeepSeek-v3）生成的问答文本。通过标准化、拟人化改写等对抗性手段扩展样本，系统评估工具在原始及改写文本上的检测准确率。

Result: QuillBot和Copyleaks对原始及同义改写的DeepSeek文本检测表现极佳；而AI Text Classifier与GPT-2表现不稳定。人化改写是最有效的对抗攻击，使Copyleaks准确率降至71%、QuillBot降至58%、GPTZero降至52%。DeepSeek自身检测（few-shot+CoT方法）则表现出极高准确性（AI召回96%，人类召回100%）。

Conclusion: 部分主流检测器能较好识别原生或简单改写的DeepSeek生成文本，但在面对高阶对抗改写（如拟人化）时准确率显著下降。基于few-shot和CoT的DeepSeek自识别方案表现优异。当前检测工具的鲁棒性和泛化能力仍待提升。

Abstract: Large language models (LLMs) have rapidly transformed the creation of written
materials. LLMs have led to questions about writing integrity, thereby driving
the creation of artificial intelligence (AI) detection technologies.
Adversarial attacks, such as standard and humanized paraphrasing, inhibit
detectors' ability to detect machine-generated text. Previous studies have
mainly focused on ChatGPT and other well-known LLMs and have shown varying
accuracy across detectors. However, there is a clear gap in the literature
about DeepSeek, a recently published LLM. Therefore, in this work, we
investigate whether six generally accessible AI detection tools -- AI Text
Classifier, Content Detector AI, Copyleaks, QuillBot, GPT-2, and GPTZero -- can
consistently recognize text generated by DeepSeek. The detectors were exposed
to the aforementioned adversarial attacks. We also considered DeepSeek as a
detector by performing few-shot prompting and chain-of-thought reasoning (CoT)
for classifying AI and human-written text. We collected 49 human-authored
question-answer pairs from before the LLM era and generated matching responses
using DeepSeek-v3, producing 49 AI-generated samples. Then, we applied
adversarial techniques such as paraphrasing and humanizing to add 196 more
samples. These were used to challenge detector robustness and assess accuracy
impact. While QuillBot and Copyleaks showed near-perfect performance on
original and paraphrased DeepSeek text, others -- particularly AI Text
Classifier and GPT-2 -- showed inconsistent results. The most effective attack
was humanization, reducing accuracy to 71% for Copyleaks, 58% for QuillBot, and
52% for GPTZero. Few-shot and CoT prompting showed high accuracy, with the best
five-shot result misclassifying only one of 49 samples (AI recall 96%, human
recall 100%).

</details>


### [28] [Are LLM Belief Updates Consistent with Bayes' Theorem?](https://arxiv.org/abs/2507.17951)
*Sohaib Imran,Ihor Kendiukhov,Matthew Broerman,Aditya Thomas,Riccardo Campanella,Rob Lamb,Peter M. Atkinson*

Main category: cs.CL

TL;DR: 本文提出了衡量语言模型与贝叶斯定理由一致性的指标BCC，通过实验证明，大型、强大的语言模型在信念更新上更契合贝叶斯定理，这有助于更好理解与监管大模型。


<details>
  <summary>Details</summary>
Motivation: 本论文旨在探究更大、更强大的语言模型在面对新的证据时，是否能按照贝叶斯定理更一致地更新其“信念”。

Method: 作者提出了贝叶斯一致性系数（Bayesian Coherence Coefficient，BCC）这一指标，并构建了相应的数据集，对多种预训练大语言模型进行评测，比较了模型参数规模、训练数据量以及基准测试分数等因素下的BCC表现。

Result: 实验证据显示，更大规模、能力更强的预训练语言模型在信念赋值上与贝叶斯定理更为一致，即BCC更高。

Conclusion: 论文证明，随着语言模型的规模和能力提升，其信念更新过程更加符合贝叶斯推断，实现了更高的贝叶斯一致性。这对理解和治理大语言模型有重要意义。

Abstract: Do larger and more capable language models learn to update their "beliefs"
about propositions more consistently with Bayes' theorem when presented with
evidence in-context? To test this, we formulate a Bayesian Coherence
Coefficient (BCC) metric and generate a dataset with which to measure the BCC.
We measure BCC for multiple pre-trained-only language models across five model
families, comparing against the number of model parameters, the amount of
training data, and model scores on common benchmarks. Our results provide
evidence for our hypothesis that larger and more capable pre-trained language
models assign credences that are more coherent with Bayes' theorem. These
results have important implications for our understanding and governance of
LLMs.

</details>


### [29] [Natural Language Processing for Tigrinya: Current State and Future Directions](https://arxiv.org/abs/2507.17974)
*Fitsum Gaim,Jong C. Park*

Main category: cs.CL

TL;DR: 本文系统综述了Tigrinya自然语言处理近十五年来的研究进展、资源和挑战，总结了发展阶段和未来关键方向，并为研究者提供完整参考与元数据资源库。


<details>
  <summary>Details</summary>
Motivation: Tigrinya虽然有数百万使用者，但在自然语言处理（NLP）研究中依然极度稀缺。因此，需要对已有NLP相关研究进行系统梳理，明确当前进展及未来方向。

Method: 本文回顾和分析了2011至2025年间40余篇关于Tigrinya NLP的文献，涵盖10个下游任务，包括形态处理、机器翻译、语音识别和问答等领域，对现有资源、模型和应用进行了系统性综述。

Result: 研究描绘了Tigrinya NLP从基于规则的初步系统到现代神经网络体系的演进路径，发现每一次显著进展均与资源建设的里程碑紧密相关，并总结了形态复杂性和资源稀缺性等主要挑战，同时提出了形态感知建模、跨语言迁移、社区驱动资源开发等前沿研究方向。

Conclusion: 该综述为Tigrinya NLP提供了全面资料索引和研究蓝图，对研究人员具有基础参考意义，并公开了相关研究和资源元数据，促进该领域的后续发展。

Abstract: Despite being spoken by millions of people, Tigrinya remains severely
underrepresented in Natural Language Processing (NLP) research. This work
presents a comprehensive survey of NLP research for Tigrinya, analyzing over 40
studies spanning more than a decade of work from 2011 to 2025. We
systematically review the current state of computational resources, models, and
applications across ten distinct downstream tasks, including morphological
processing, machine translation, speech recognition, and question-answering.
Our analysis reveals a clear trajectory from foundational, rule-based systems
to modern neural architectures, with progress consistently unlocked by resource
creation milestones. We identify key challenges rooted in Tigrinya's
morphological complexity and resource scarcity, while highlighting promising
research directions, including morphology-aware modeling, cross-lingual
transfer, and community-centered resource development. This work serves as both
a comprehensive reference for researchers and a roadmap for advancing Tigrinya
NLP. A curated metadata of the surveyed studies and resources is made publicly
available.\footnote{Tigrinya NLP Anthology:
https://github.com/fgaim/tigrinya-nlp-anthology.

</details>


### [30] [Technical Report of TeleChat2, TeleChat2.5 and T1](https://arxiv.org/abs/2507.18013)
*Zihan Wang,Xinzhang Liu,Yitong Yao,Chao Wang,Yu Zhao,Zhihao Yang,Wenmin Deng,Kaipeng Jia,Jiaxin Peng,Yuyao Huang,Sishi Xiong,Zhuo Jiang,Kaidong Yu,Xiaohui Hu,Fubei Yao,Ruiyu Fang,Zhuoru Jiang,Ruiting Song,Qiyi Xie,Rui Xue,Xuewei He,Yanlei Xue,Zhu Yuan,Zhaoxi Zhang,Zilu Huang,Shiquan Wang,Xin Wang,Hanming Wu,Mingyuan Wang,Xufeng Zhan,Yuhan Sun,Zhaohu Xing,Yuhao Jiang,Bingkai Yang,Shuangyong Song,Yongxiang Li,Zhongjiang He,Xuelong Li*

Main category: cs.CL

TL;DR: TeleChat2、TeleChat2.5和T1系列模型通过更优训练（大规模预训练+持续学习+RL等），在推理、代码、数学任务上超越GPT-4o等主流闭源模型，实现性能与推理速度双提升，相关模型已开放给社区。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型需要在推理、代码生成、数学推理等复杂任务上获得进一步提升。以往版本TeleChat在这些方面仍有局限，且对模型速度和参数规模的需求不断增长。作者希望在不大幅更改模型结构的前提下，通过更优的训练方法和策略，提升模型性能，推动行业发展。

Method: 提出了TeleChat2、TeleChat2.5和T1系列模型。核心方法包括：（1）海量高质量数据（10万亿token）上的预训练；（2）监督微调（SFT）和直接偏好优化（DPO）增强能力；（3）在TeleChat2.5和T1中融入持续预训练（用领域特定数据）及强化学习（RL），提升代码生成和数学推理能力；（4）T1侧重于复杂链式推理及相关能力提升，TeleChat2.5优化推理速度。

Result: T1和TeleChat2.5均为115B参数的密集Transformer架构，在推理和常规任务上显著优于原始TeleChat，T1-115B在多项指标上超越了如OpenAI o1-mini和GPT-4o等业界领先专有模型。35B及115B参数版本已公开发布。

Conclusion: 本系列新模型在架构微调有限的情况下，通过改进训练策略显著提升了推理能力、数学和代码生成水平及推理速度。公开发布这些模型将促进开发者和学者在多样化应用中的创新。

Abstract: We introduce the latest series of TeleChat models: \textbf{TeleChat2},
\textbf{TeleChat2.5}, and \textbf{T1}, offering a significant upgrade over
their predecessor, TeleChat. Despite minimal changes to the model architecture,
the new series achieves substantial performance gains through enhanced training
strategies in both pre-training and post-training stages. The series begins
with \textbf{TeleChat2}, which undergoes pretraining on 10 trillion
high-quality and diverse tokens. This is followed by Supervised Fine-Tuning
(SFT) and Direct Preference Optimization (DPO) to further enhance its
capabilities. \textbf{TeleChat2.5} and \textbf{T1} expand the pipeline by
incorporating a continual pretraining phase with domain-specific datasets,
combined with reinforcement learning (RL) to improve performance in code
generation and mathematical reasoning tasks. The \textbf{T1} variant is
designed for complex reasoning, supporting long Chain-of-Thought (CoT)
reasoning and demonstrating substantial improvements in mathematics and coding.
In contrast, \textbf{TeleChat2.5} prioritizes speed, delivering rapid
inference. Both flagship models of \textbf{T1} and \textbf{TeleChat2.5} are
dense Transformer-based architectures with 115B parameters, showcasing
significant advancements in reasoning and general task performance compared to
the original TeleChat. Notably, \textbf{T1-115B} outperform proprietary models
such as OpenAI's o1-mini and GPT-4o. We publicly release \textbf{TeleChat2},
\textbf{TeleChat2.5} and \textbf{T1}, including post-trained versions with 35B
and 115B parameters, to empower developers and researchers with
state-of-the-art language models tailored for diverse applications.

</details>


### [31] [NeuralDB: Scaling Knowledge Editing in LLMs to 100,000 Facts with Neural KV Database](https://arxiv.org/abs/2507.18028)
*Weizhi Fei,Hao Shi,Jing Xu,Jingchen Peng,Jiazheng Li,Jingzhao Zhang,Bo Bai,Wei Han,Zhenyuan Chen,Xueyan Niu*

Main category: cs.CL

TL;DR: 作者提出NeuralDB框架，能在大语言模型中高效编辑和检索上万甚至十万条知识事实，同时保持模型整体能力不损失，解决了以往方法规模化编辑时遗忘和泛化能力下降的问题。


<details>
  <summary>Details</summary>
Motivation: 目前在大语言模型（LLM）中高效地编辑知识，可以实现无需大规模训练的模型更新。但现有的Locate-and-Edit（L&E）方法在面对大规模事实修改时，会削弱模型的通用能力，甚至产生遗忘已编辑事实的问题。需要一种方法来在保证编辑能力的同时，避免这些副作用。

Method: 本文将现有的线性L&E方法建模为Key-Value（KV）数据库检索，从而提出了NeuralDB。NeuralDB将被编辑的事实显式地表示成神经网络KV数据库，并配备了非线性门控检索模块，只有在推理涉及已编辑事实时才激活，从而尽量保护LLM的通用能力。

Result: 在ZsRE和CounterFacts数据集上，对GPT2-XL、GPT-J（6B）和Llama-3（8B）进行1万条事实的编辑实验，NeuralDB在编辑效率、泛化性、特异性、流畅度和一致性等方面表现优异，并且在六个文本理解与生成任务上整体表现不下降。进一步实验显示，NeuralDB在扩展到10万条事实时依然有效，比已有方法的规模提升了50倍。

Conclusion: NeuralDB作为一种新型的神经KV编辑框架，大幅提升了LLM在大规模知识编辑下的有效性和模型性能保持能力，适用于更广泛和大规模的知识更新场景。

Abstract: Efficiently editing knowledge stored in large language models (LLMs) enables
model updates without large-scale training. One possible solution is
Locate-and-Edit (L\&E), allowing simultaneous modifications of a massive number
of facts. However, such editing may compromise the general abilities of LLMs
and even result in forgetting edited facts when scaling up to thousands of
edits. In this paper, we model existing linear L\&E methods as querying a
Key-Value (KV) database. From this perspective, we then propose NeuralDB, an
editing framework that explicitly represents the edited facts as a neural KV
database equipped with a non-linear gated retrieval module, % In particular,
our gated module only operates when inference involves the edited facts,
effectively preserving the general abilities of LLMs. Comprehensive experiments
involving the editing of 10,000 facts were conducted on the ZsRE and
CounterFacts datasets, using GPT2-XL, GPT-J (6B) and Llama-3 (8B). The results
demonstrate that NeuralDB not only excels in editing efficacy, generalization,
specificity, fluency, and consistency, but also preserves overall performance
across six representative text understanding and generation tasks. Further
experiments indicate that NeuralDB maintains its effectiveness even when scaled
to 100,000 facts (\textbf{50x} more than in prior work).

</details>


### [32] [GrAInS: Gradient-based Attribution for Inference-Time Steering of LLMs and VLMs](https://arxiv.org/abs/2507.18043)
*Duy Nguyen,Archiki Prasad,Elias Stengel-Eskin,Mohit Bansal*

Main category: cs.CL

TL;DR: GrAInS是一种新颖的推理时模型引导方法，结合梯度归因与token级别控制，显著提高多模态与语言模型在准确率、幻觉率和对齐率等多个任务表现，无需微调，具备可解释性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 当前许多推理时引导（steering）方法虽然能在不更新模型参数的情况下调整大型语言模型和视觉-语言模型输出，但存在三大不足：（1）大多采用固定的全局干预向量，忽视了对每个输入token的因果归因；（2）未能有效利用模型logits的梯度信息，特别是在多模态场景下，图像和文本的贡献不均衡；（3）对模型解释性和细粒度调控能力有限。

Method: 作者提出了一种名为GrAInS的新方法，结合对比性、基于梯度的Integrated Gradients归因技术，识别出对输出正负贡献最大的top-k token，并利用这些token构建引导向量，实现从不期望到期望行为的语义转变。推理时，GrAInS根据token级归因信号，在transformer层调整隐层激活值，并进行归一化，以保持表征尺度，最终实现细粒度、可解释且可组合的模型行为控制，无需再训练或额外监督。

Result: GrAInS在多项基准测试中优于常规微调和现有引导基线：在Llama-3.1-8B模型上，TruthfulQA准确率提升13.22%；在LLaVA-1.6-7B模型上，MMHal-Bench幻觉率从0.624降至0.514；在SPA-VL对齐率提升8.11%；同时还能保持模型流畅性与通用能力。

Conclusion: GrAInS实现了无需模型重训练即可对大型语言模型和视觉-语言模型行为进行细粒度、可解释、模块化的推理时引导，效果显著优于主流方法。

Abstract: Inference-time steering methods offer a lightweight alternative to
fine-tuning large language models (LLMs) and vision-language models (VLMs) by
modifying internal activations at test time without updating model weights.
However, most existing approaches rely on fixed, global intervention vectors,
overlook the causal influence of individual input tokens, and fail to leverage
informative gradients from the model's logits, particularly in multimodal
settings where visual and textual inputs contribute unevenly. To address these
limitations, we introduce GrAInS, an inference-time steering approach that
operates across both language-only and vision-language models and tasks. GrAInS
uses contrastive, gradient-based attribution via Integrated Gradients to
identify the top-k most influential tokens, both positively and negatively
attributed based on their contribution to preferred versus dispreferred
outputs. These tokens are then used to construct directional steering vectors
that capture semantic shifts from undesirable to desirable behavior. During
inference, GrAInS adjusts hidden activations at transformer layers guided by
token-level attribution signals, and normalizes activations to preserve
representational scale. This enables fine-grained, interpretable, and modular
control over model behavior, without retraining or auxiliary supervision.
Empirically, GrAInS consistently outperforms both fine-tuning and existing
steering baselines: it achieves a 13.22% accuracy gain on TruthfulQA using
Llama-3.1-8B, reduces hallucination rates on MMHal-Bench from 0.624 to 0.514
with LLaVA-1.6-7B, and improves alignment win rates on SPA-VL by 8.11%, all
while preserving the model's fluency and general capabilities.

</details>


### [33] [Synthetic Data Generation for Phrase Break Prediction with Large Language Model](https://arxiv.org/abs/2507.18044)
*Hoyeon Lee,Sejung Son,Ye-Eun Kang,Jong-Hwan Kim*

Main category: cs.CL

TL;DR: 本文提出用大语言模型自动生成语句断句数据，减少人工标注负担，并验证该方法在多语言场景下的有效性，实验显示效果良好。


<details>
  <summary>Details</summary>
Motivation: 现有的语句断句预测方法需要大量人工标注，这不仅费时费力，还易受语音内部变异（如语音特性）的影响，导致数据一致性难以保证。本文受到大语言模型（LLM）在NLP数据合成方面取得成功的启发，尝试用LLM合成断句注释，以减少人工标注难题。

Method: 用大语言模型（LLM）自动生成合成的语句断句注释数据，并将其与传统人工注释方法进行比较，并评估其在多语言场景下的有效性。

Result: 实验表明，基于LLM的合成数据生成方法在语句断句预测任务中能有效解决数据获取难题，并能在多语言环境下发挥作用。

Conclusion: LLM用于生成断句合成数据是一种有效解决语音相关标注和断句预测任务数据难题的方法，为语音领域相关任务提供了新的思路。

Abstract: Current approaches to phrase break prediction address crucial prosodic
aspects of text-to-speech systems but heavily rely on vast human annotations
from audio or text, incurring significant manual effort and cost. Inherent
variability in the speech domain, driven by phonetic factors, further
complicates acquiring consistent, high-quality data. Recently, large language
models (LLMs) have shown success in addressing data challenges in NLP by
generating tailored synthetic data while reducing manual annotation needs.
Motivated by this, we explore leveraging LLM to generate synthetic phrase break
annotations, addressing the challenges of both manual annotation and
speech-related tasks by comparing with traditional annotations and assessing
effectiveness across multiple languages. Our findings suggest that LLM-based
synthetic data generation effectively mitigates data challenges in phrase break
prediction and highlights the potential of LLMs as a viable solution for the
speech domain.

</details>


### [34] [Privacy-Preserving Synthetic Review Generation with Diverse Writing Styles Using LLMs](https://arxiv.org/abs/2507.18055)
*Tevin Atwal,Chan Nam Tieu,Yefeng Yuan,Zhan Shi,Yuhong Liu,Liang Cheng*

Main category: cs.CL

TL;DR: 本文系统评估了大语言模型合成文本数据的多样性和隐私问题，发现主流模型存在明显不足，并提出了基于提示的改进方法以提升数据多样性和隐私保护能力。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）生成的合成数据广泛使用，如何评估其多样性和隐私风险成为紧迫问题，这些方面尚未得到充分研究。

Method: 本文提出了一套全面的度量标准，从语言表达、情感、用户视角等方面评估合成文本数据的多样性，并从再识别风险和文体异常点评估隐私风险。通过实验证明当前主流LLM生成数据的局限性，并基于这些评估提出了一种基于提示（prompt）的改进方法，以提升评论数据的多样性并保护隐私。

Result: 实验结果显示，现有LLM在生成多样且保护隐私的合成数据上存在明显不足。基于评估结果，所提的提示方法有效提升了合成评论的多样性并减小了隐私泄露风险。

Conclusion: 当前LLM生成的合成文本数据在多样性与隐私保护方面有明显不足，提出的评估体系和提升机制可有效改善数据质量和隐私安全。

Abstract: The increasing use of synthetic data generated by Large Language Models
(LLMs) presents both opportunities and challenges in data-driven applications.
While synthetic data provides a cost-effective, scalable alternative to
real-world data to facilitate model training, its diversity and privacy risks
remain underexplored. Focusing on text-based synthetic data, we propose a
comprehensive set of metrics to quantitatively assess the diversity (i.e.,
linguistic expression, sentiment, and user perspective), and privacy (i.e.,
re-identification risk and stylistic outliers) of synthetic datasets generated
by several state-of-the-art LLMs. Experiment results reveal significant
limitations in LLMs' capabilities in generating diverse and privacy-preserving
synthetic data. Guided by the evaluation results, a prompt-based approach is
proposed to enhance the diversity of synthetic reviews while preserving
reviewer privacy.

</details>


### [35] [TELEVAL: A Dynamic Benchmark Designed for Spoken Language Models in Chinese Interactive Scenarios](https://arxiv.org/abs/2507.18061)
*Zehan Li,Hongjie Chen,Yuxin Zhang,Jing Zhou,Xuening Wang,Hang Lv,Mengjie Du,Yaodong Song,Jie Lian,Jian Kang,Jie Li,Yongxiang Li,Zhongjiang He,Xuelong Li*

Main category: cs.CL

TL;DR: 本文提出TELEVAL基准，专注于衡量SLMs在真实中文对话场景中的综合能力，涵盖显式和隐式语义及系统表现，实验显示当前模型在自然交流中仍有提升空间，TELEVAL能够更好反映用户体验，促进SLMs实际应用能力提升。


<details>
  <summary>Details</summary>
Motivation: 当前的口语语言模型（SLMs）评测基准往往与现实中用户的实际对话需求有偏离，主要关注模型是否能完成类似大语言模型（LLMs）的复杂任务，未能充分评估模型在真实交互场景中的能力。

Method: 提出了TELEVAL基准，专为评估SLMs在现实中文交互中的对话能力设计。TELEVAL从显式语义、旁语言与隐式语义、系统能力三方面对模型进行动态评估，兼具文本和音频输出的独立评价，强调模型对用户隐含语境信息的捕捉与适当响应。

Result: 实验结果显示，尽管SLMs近年来取得了一些进步，但在自然对话任务中仍有较大的提升空间。

Conclusion: TELEVAL有望为口语语言模型提供更以用户为中心、更贴合实际体验的评估标准，推动面向对话的SLMs进一步发展。

Abstract: Spoken language models (SLMs) have seen rapid progress in recent years, along
with the development of numerous benchmarks for evaluating their performance.
However, most existing benchmarks primarily focus on evaluating whether SLMs
can perform complex tasks comparable to those tackled by large language models
(LLMs), often failing to align with how users naturally interact in real-world
conversational scenarios. In this paper, we propose TELEVAL, a dynamic
benchmark specifically designed to evaluate SLMs' effectiveness as
conversational agents in realistic Chinese interactive settings. TELEVAL
defines three evaluation dimensions: Explicit Semantics, Paralinguistic and
Implicit Semantics, and System Abilities. It adopts a dialogue format
consistent with real-world usage and evaluates text and audio outputs
separately. TELEVAL particularly focuses on the model's ability to extract
implicit cues from user speech and respond appropriately without additional
instructions. Our experiments demonstrate that despite recent progress,
existing SLMs still have considerable room for improvement in natural
conversational tasks. We hope that TELEVAL can serve as a user-centered
evaluation framework that directly reflects the user experience and contributes
to the development of more capable dialogue-oriented SLMs.

</details>


### [36] [Hybrid and Unitary Fine-Tuning of Large Language Models: Methods and Benchmarking under Resource Constraints](https://arxiv.org/abs/2507.18076)
*Haomin Qi,Zihan Dai,Chengbo Huang*

Main category: cs.CL

TL;DR: 本文提出一种结合BOFT与LoRA-GA优点的新型混合PEFT方法，在减少大量资源消耗的同时实现接近全微调的性能，适合大语言模型实际应用中的高效微调。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）因规模和内存需求大，微调过程消耗大量计算资源，成为实际应用中的瓶颈。研究动机在于寻找更高效、低资源消耗的参数高效微调（PEFT）方法。

Method: 全面评估了PEFT方法（如LoRA、BOFT、LoRA-GA和uRNN），并提出了一种结合BOFT正交稳定性和LoRA-GA梯度对齐快速收敛的新型混合策略。该方法通过基于梯度范数的层级自适应更新进行优化，并首次将uRNN单元原理应用于Transformer结构，增强梯度稳定性。

Result: 在GLUE、GSM8K、MT-Bench和HumanEval四个基准任务上，使用从7B到405B参数量的模型验证，混合方法在收敛速度、泛化性能上持续优于各单一基线方法，接近全参数微调的精度，同时训练时间减少最多2.1倍，内存消耗降低50%。

Conclusion: 提出的混合PEFT方法兼具效率与效果，为在资源受限条件下大模型的实际部署和微调提供了可行且可扩展的方案。

Abstract: Fine-tuning large language models (LLMs) remains a computational bottleneck
due to their scale and memory demands. This paper presents a comprehensive
evaluation of parameter-efficient fine-tuning (PEFT) techniques, including
LoRA, BOFT, LoRA-GA, and uRNN, and introduces a novel hybrid strategy that
dynamically integrates BOFT's orthogonal stability with LoRA-GA's
gradient-aligned rapid convergence. By computing per-layer adaptive updates
guided by gradient norms, the hybrid method achieves superior convergence
efficiency and generalization across diverse tasks. We also explore, for the
first time, the adaptation of unitary RNN (uRNN) principles to
transformer-based LLMs, enhancing gradient stability through structured unitary
constraints. Empirical evaluations on four benchmarks -- GLUE, GSM8K, MT-Bench,
and HumanEval -- using models ranging from 7B to 405B parameters demonstrate
that our hybrid method consistently outperforms individual PEFT baselines,
approaching full fine-tuning accuracy while reducing resource consumption by up
to 2.1 times in training time and 50 percent in memory usage. These findings
establish the hybrid approach as a practical and scalable fine-tuning solution
for real-world deployment of LLMs under resource constraints.

</details>


### [37] [A New Pair of GloVes](https://arxiv.org/abs/2507.18103)
*Riley Carlson,John Bauer,Christopher D. Manning*

Main category: cs.CL

TL;DR: 本文提出并详尽记录了新版2024 GloVe词向量，使用新语料训练，并展示其在新词汇覆盖和NER任务上优于2014年模型，结构任务表现相当。


<details>
  <summary>Details</summary>
Motivation: 原2014年GloVe模型虽然广泛使用，但数据和预处理文档不足且无法反映当前语言变化，需要更新和详细描述。

Method: 对比实验：分别在Wikipedia、Gigaword和Dolma子集上训练两组词嵌入模型，通过词汇比较、直接测试以及命名实体识别（NER）任务进行评估。

Result: 2024新模型在涵盖新词汇和NER任务上优于老模型，结构化任务表现持平。

Conclusion: 新的2024年版本的GloVe模型在最新的NER任务上表现更好，并且包含了更多与当今文化和语言相关的新词。整体性能与老模型在结构任务上相当。

Abstract: This report documents, describes, and evaluates new 2024 English GloVe
(Global Vectors for Word Representation) models. While the original GloVe
models built in 2014 have been widely used and found useful, languages and the
world continue to evolve and we thought that current usage could benefit from
updated models. Moreover, the 2014 models were not carefully documented as to
the exact data versions and preprocessing that were used, and we rectify this
by documenting these new models. We trained two sets of word embeddings using
Wikipedia, Gigaword, and a subset of Dolma. Evaluation through vocabulary
comparison, direct testing, and NER tasks shows that the 2024 vectors
incorporate new culturally and linguistically relevant words, perform
comparably on structural tasks like analogy and similarity, and demonstrate
improved performance on recent, temporally dependent NER datasets such as
non-Western newswire data.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [38] [In Reverie Together: Ten Years of Mathematical Discovery with a Machine Collaborator](https://arxiv.org/abs/2507.17780)
*Randy Davila,Boris Brimkov,Ryan Pepper*

Main category: cs.DM

TL;DR: 本文通过AI系统生成并筛选出四个经验成立但尚未解决的图论猜想，旨在激励数学家和AI共同思考与探索，展现AI在数学创意和合作中的新潜力。


<details>
  <summary>Details</summary>
Motivation: 本文旨在展示由自动猜想系统TxGraffiti生成的四条图论未解决猜想，表明AI可以在数学创意活动中扮演更积极的角色，并激发人类与机器的协作与反思。

Method: 利用TxGraffiti系统，基于符号模式识别与人工定义启发式方法生成数学猜想，并通过在数百个图上的经验验证，精炼和筛选出有意义且未被证伪的图论猜想。

Result: 得到四个基于自然图不变量、经过大量图形经验测试、现阶段既无法证明也未被反例驳倒的图论猜想。这些猜想成为数学新的研究难题，同时也展示了机器与人类在数学发现过程中的合作潜力。

Conclusion: 本文提出的猜想不仅为图论领域提供了新的研究方向，也激发了人机协作在数学创意过程中的反思和探索。希望这些工作能促进数学家与AI系统共同推动数学前沿发展。

Abstract: We present four open conjectures in graph theory generated by the automated
conjecturing system \texttt{TxGraffiti}. Each conjecture is concise, grounded
in natural graph invariants, and empirically validated across hundreds of
graphs. Despite extensive effort, these statements remain unresolved--defying
both proof and counterexample. They are not only mathematical challenges but
creative expressions--born of symbolic pattern recognition and
mathematician-defined heuristics, refined through years of human dialogue, and
now offered back to the community as collaborative artifacts. These conjectures
invite not only formal proof, but also reflection on how machines can evoke
wonder, spark curiosity, and contribute to the raw material of discovery. By
highlighting these problems, we aim to inspire both human mathematicians and AI
systems to engage with them--not only to solve them, but to reflect on what it
means when machines participate meaningfully in the creative process of
mathematical thought.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [39] [Time for Quiescence: Modelling quiescent behaviour in testing via time-outs in timed automata](https://arxiv.org/abs/2507.18205)
*Laura Brandán Briones,Marcus Gerhold,Petra van den Bos,Mariëlle Stoelinga*

Main category: cs.FL

TL;DR: 该论文提出一种为LTS模型引入简单定时机制的数学方法，可以用一个时钟和指定超时阈值M来正式判定沉默，从而将工业常用的超时做quiescence判定模式形式化。此方法无需引入全套复杂的定时自动机，且测试方法、测试判定与原LTS方法等价，兼具理论严密性与工程实用性。


<details>
  <summary>Details</summary>
Motivation: 在模型驱动测试（MBT）中，通常使用简单的模型如带标签的转换系统（LTS），但在实际工程中，难以优雅处理无可观察输出（沉默/quiescence），需要设置超时来判定沉默。然而，现有的定时MBT多数依赖于复杂的定时自动机（TA）框架，实际推广性较差。

Method: 该论文提出一个提升算子$\chi^{\scriptstyle M}\!$，它可在不引入传统定时自动机复杂度的前提下，为LTS模型引入定时操作。具体为：用户指定超时阈值M，系统行为需要在时钟值达到M前发生，否则即视为quiescence。该提升算子只使用一个时钟变量，有效简化时序行为建模。

Result: 1）证明实现的$ioco$一致性等价于其提升模型下的定时$tioco_M$一致性；2）无论在标准$ioco$测试生成前还是后应用提升算子，生成的测试集一致；3）提升后定时自动机版本和原LTS测试套件对任一实现的判决结果恒等。

Conclusion: 简化了在MBT下处理沉默与超时问题，为工业中常用的超时判定quiescence做了严谨的形式化基础铺垫，同时保留了测试判定和测试生成流程的等价性，便于工程落地。

Abstract: Model-based testing (MBT) derives test suites from a behavioural
specification of the system under test. In practice, engineers favour simple
models, such as labelled transition systems (LTSs). However, to deal with
quiescence - the absence of observable output - in practice, a time-out needs
to be set to conclude observation of quiescence. Timed MBT exists, but it
typically relies on the full arsenal of timed automata (TA).
  We present a lifting operator $\chi^{\scriptstyle M}\!$ that adds timing
without the TA overhead: given an LTS, $\chi^{\scriptstyle M}\!$ introduces a
single clock for a user chosen time bound $M>0$ to declare quiescence. In the
timed automaton, the clock is used to model that outputs should happen before
the clock reaches value $M$, while quiescence occurs exactly at time $M$. This
way we provide a formal basis for the industrial practice of choosing a
time-out to conclude quiescence. Our contributions are threefold: (1) an
implementation conforms under $\mathbf{ioco}$ if and only if its lifted version
conforms under timed $\mathbf{tioco_M}$ (2) applying $\chi^{\scriptstyle M}\!$
before or after the standard $\mathbf{ioco}$ test-generation algorithm yields
the same set of tests, and (3) the lifted TA test suite and the original LTS
test suite deliver identical verdicts for every implementation.

</details>
