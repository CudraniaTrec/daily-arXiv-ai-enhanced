{"id": "2508.03627", "categories": ["cs.FL"], "pdf": "https://arxiv.org/pdf/2508.03627", "abs": "https://arxiv.org/abs/2508.03627", "authors": ["Anirban Majumdar", "Sayan Mukherjee", "Jean-Fran\u00e7ois Raskin"], "title": "Learning Event-recording Automata Passively", "comment": "Shorter version of this article has been accepted at ATVA 2025", "summary": "This paper presents a state-merging algorithm for learning timed languages\ndefinable by Event-Recording Automata (ERA) using positive and negative samples\nin the form of symbolic timed words. Our algorithm, LEAP (Learning\nEvent-recording Automata Passively), constructs a possibly nondeterministic ERA\nfrom such samples based on merging techniques. We prove that determining\nwhether two ERA states can be merged while preserving sample consistency is an\nNP-complete problem, and address this with a practical SMT-based solution. Our\nimplementation demonstrates the algorithm's effectiveness through examples. We\nalso show that every ERA-definable language can be inferred using our algorithm\nwith a suitable sample.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u72b6\u6001\u5408\u5e76\u7b97\u6cd5\uff0c\u88ab\u79f0\u4e3aLEAP\uff0c\u53ef\u4ee5\u88ab\u52a8\u5b66\u4e60\u7531Event-Recording Automata\uff08ERA\uff09\u6240\u5b9a\u4e49\u7684\u5b9a\u65f6\u8bed\u8a00\uff0c\u8f93\u5165\u4e3a\u6b63\u8d1f\u6837\u672c\u7684\u7b26\u53f7\u5316\u5b9a\u65f6\u8bcd\u3002", "motivation": "\u5f53\u524d\u5b66\u4e60\u5b9a\u65f6\u8bed\u8a00\u81ea\u52a8\u673a\u5b58\u5728\u6311\u6218\uff0c\u5c24\u5176\u662f\u88ab\u52a8\u5b66\u4e60\uff08\u4ec5\u4f9d\u9760\u6837\u672c\u800c\u975e\u67e5\u8be2\uff09\u3002\u63d0\u51fa\u6b64\u7b97\u6cd5\u65e8\u5728\u9ad8\u6548\u3001\u51c6\u786e\u5730\u5b66\u4e60ERA\u6240\u63cf\u8ff0\u7684\u5b9a\u65f6\u8bed\u8a00\uff0c\u63d0\u5347\u81ea\u52a8\u673a\u5b66\u4e60\u7684\u80fd\u529b\u548c\u8986\u76d6\u9762\u3002", "method": "\u7b97\u6cd5\u57fa\u4e8e\u72b6\u6001\u5408\u5e76\u6280\u672f\uff0c\u6839\u636e\u6b63\u8d1f\u6837\u672c\u6784\u5efa\u4e00\u4e2a\u53ef\u80fd\u975e\u786e\u5b9a\u6027\u7684ERA\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSMT\uff08\u53ef\u6ee1\u8db3\u6027\u6a21\u5757\u7406\u8bba\uff09\u7684\u5b9e\u7528\u65b9\u6cd5\u89e3\u51b3\u72b6\u6001\u5408\u5e76\u7684\u4e00\u81f4\u6027\u95ee\u9898\u3002", "result": "\u8bc1\u660e\u4e86\u5224\u5b9aERA\u4e24\u4e2a\u72b6\u6001\u5728\u4fdd\u6301\u6837\u672c\u4e00\u81f4\u6027\u7684\u524d\u63d0\u4e0b\u662f\u5426\u80fd\u5408\u5e76\u4e3aNP\u5b8c\u5168\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86SMT\u89e3\u6cd5\u3002\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u5b9e\u7528\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u53ea\u8981\u6709\u5408\u9002\u7684\u6837\u672c\uff0c\u672c\u6587\u7b97\u6cd5\u80fd\u591f\u63a8\u65ad\u51fa\u6240\u6709ERA\u53ef\u5b9a\u4e49\u7684\u8bed\u8a00\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u3002"}}
{"id": "2508.03638", "categories": ["cs.FL", "cs.HC", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03638", "abs": "https://arxiv.org/abs/2508.03638", "authors": ["Marco T. Moraz\u00e1n", "Oliwia Kempinski", "Andr\u00e9s M. Garced"], "title": "Design Support for Multitape Turing Machines", "comment": "In Proceedings TFPiE 2025, arXiv:2508.02305", "summary": "Many Formal Languages and Automata Theory courses introduce students to\nTuring machine extensions. One of the most widely-used extensions endows Turing\nmachines with multiple tapes. Although multitape Turing machines are an\nabstraction to simplify Turing machine design, students find them no less\nchallenging. To aid students in understanding these machines, the FSM\nprogramming language provides support for their definition and execution. This,\nhowever, has proven insufficient for many students to understand the\noperational semantics of such machines and to understand why such machines\naccept or reject a word. To address this problem, three visualization tools\nhave been developed. The first is a dynamic visualization tool that simulates\nmachine execution. The second is a static visualization tool that automatically\nrenders a graphic for a multitape Turing machine's transition diagram. The\nthird is a static visualization tool that automatically renders computation\ngraphs for multitape Turing machines. This article presents these tools and\nillustrates how they are used to help students design and implement multitape\nTuring machines. In addition, empirical data is presented that suggests these\ntools are well-received and found useful by students.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e09\u79cd\u7528\u4e8e\u591a\u5e26\u56fe\u7075\u673a\u7684\u53ef\u89c6\u5316\u5b66\u4e60\u5de5\u5177\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u6570\u636e\u8868\u660e\uff0c\u8fd9\u4e9b\u5de5\u5177\u663e\u8457\u63d0\u5347\u4e86\u5b66\u751f\u7684\u7406\u89e3\u548c\u8bbe\u8ba1\u80fd\u529b\u3002", "motivation": "\u591a\u5e26\u56fe\u7075\u673a\u867d\u7136\u662f\u8bbe\u8ba1\u7b80\u5316\u7684\u62bd\u8c61\u5de5\u5177\uff0c\u4f46\u5b66\u751f\u4f9d\u7136\u96be\u4ee5\u7406\u89e3\u5176\u64cd\u4f5c\u8bed\u4e49\u4ee5\u53ca\u4f55\u65f6\u63a5\u53d7\u6216\u62d2\u7edd\u4e00\u4e2a\u5355\u8bcd\u3002\u5df2\u6709\u7684FSM\u7f16\u7a0b\u8bed\u8a00\u7684\u5b9a\u4e49\u548c\u6267\u884c\u652f\u6301\u4ecd\u4e0d\u8db3\u4ee5\u5e2e\u52a9\u7406\u89e3\u3002", "method": "\u5f00\u53d1\u4e86\u4e09\u79cd\u53ef\u89c6\u5316\u5de5\u5177\uff1a1\uff09\u52a8\u6001\u53ef\u89c6\u5316\u5de5\u5177\u6a21\u62df\u591a\u5e26\u56fe\u7075\u673a\u6267\u884c\u8fc7\u7a0b\uff1b2\uff09\u9759\u6001\u53ef\u89c6\u5316\u5de5\u5177\u81ea\u52a8\u7ed8\u5236\u591a\u5e26\u56fe\u7075\u673a\u7684\u72b6\u6001\u8f6c\u79fb\u56fe\uff1b3\uff09\u9759\u6001\u53ef\u89c6\u5316\u5de5\u5177\u81ea\u52a8\u7ed8\u5236\u591a\u5e26\u56fe\u7075\u673a\u7684\u8ba1\u7b97\u56fe\uff0c\u5e76\u5728\u8bfe\u7a0b\u4e2d\u914d\u5408\u8bbe\u8ba1\u548c\u5b9e\u73b0\u7ec3\u4e60\u52a0\u4ee5\u5e94\u7528\u3002", "result": "\u5de5\u5177\u5f97\u5230\u4e86\u5b66\u751f\u7684\u79ef\u6781\u53cd\u9988\uff0c\u8ba4\u4e3a\u5b83\u4eec\u5bf9\u4e8e\u7406\u89e3\u548c\u5e94\u7528\u591a\u5e26\u56fe\u7075\u673a\u975e\u5e38\u6709\u5e2e\u52a9\u3002", "conclusion": "\u4e09\u79cd\u53ef\u89c6\u5316\u5de5\u5177\u80fd\u6709\u6548\u5e2e\u52a9\u5b66\u751f\u7406\u89e3\u548c\u638c\u63e1\u591a\u5e26\u56fe\u7075\u673a\u7684\u8bbe\u8ba1\u4e0e\u5b9e\u73b0\uff0c\u5bf9\u6559\u5b66\u6709\u79ef\u6781\u4f5c\u7528\u3002"}}
{"id": "2508.03639", "categories": ["cs.FL", "cs.HC", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03639", "abs": "https://arxiv.org/abs/2508.03639", "authors": ["Marco T. Moraz\u00e1n", "Shamil Dzhatdoyev", "Josephine Des Rosiers", "Tijana Mini\u0107", "Andr\u00e9s M. Garced", "David Anthony K. Fields"], "title": "A Design Recipe and Recipe-Based Errors for Regular Expressions", "comment": "In Proceedings TFPiE 2025, arXiv:2508.02305", "summary": "This article presents a novel framework to provide Formal Languages and\nAutomata Theory students design support for the development of regular\nexpressions. This framework includes a design recipe for regular expressions\nand a customized error messaging system. The error messaging system produces\nrecipe-based errors that include the step of the design recipe not successfully\ncompleted. Furthermore, the error messages follow the established practices of\nbeing concise, succinct, jargon-free, and nonprescriptive. In addition, a\nshorthand syntax developed for writing unit tests is described. The in-class\nuse of the design recipe is illustrated, two debugging sessions using the\ndescribed system are discussed, and the implementation of the error messaging\nsystem is briefly sketched.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u57fa\u4e8e\u8bbe\u8ba1\u914d\u65b9\u548c\u53cb\u597d\u9519\u8bef\u4fe1\u606f\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\u8bbe\u8ba1\u652f\u6301\u7cfb\u7edf\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6709\u52a9\u4e8e\u5b66\u751f\u5b66\u4e60\u548c\u8c03\u8bd5\u3002", "motivation": "\u8bb8\u591a\u5f62\u5f0f\u8bed\u8a00\u4e0e\u81ea\u52a8\u673a\u7406\u8bba\u7684\u5b66\u751f\u5728\u5b66\u4e60\u548c\u8bbe\u8ba1\u6b63\u5219\u8868\u8fbe\u5f0f\u65f6\uff0c\u56e0\u6d41\u7a0b\u4e0d\u6e05\u6670\u548c\u9519\u8bef\u53cd\u9988\u4e0d\u53cb\u597d\u800c\u9047\u5230\u56f0\u96be\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u660e\u786e\u7684\u8bbe\u8ba1\u914d\u65b9\u548c\u53cb\u597d\u9519\u8bef\u63d0\u793a\u6539\u5584\u5b66\u4e60\u4f53\u9a8c\u548c\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u6b63\u5219\u8868\u8fbe\u5f0f\u8bbe\u8ba1\u652f\u6301\u7684\u5168\u65b0\u6846\u67b6\uff0c\u5305\u62ec\u5b9a\u5236\u5316\u9519\u8bef\u4fe1\u606f\u7cfb\u7edf\u548c\u8bbe\u8ba1\u914d\u65b9\uff0c\u4ee5\u53ca\u9488\u5bf9\u5355\u5143\u6d4b\u8bd5\u7684\u7b80\u5199\u8bed\u6cd5\u3002\u7cfb\u7edf\u80fd\u591f\u5728\u5b66\u751f\u8bbe\u8ba1\u6b63\u5219\u8868\u8fbe\u5f0f\u8fc7\u7a0b\u4e2d\u7ed9\u51fa\u57fa\u4e8e\u6b65\u9aa4\u7684\u9519\u8bef\u63d0\u793a\u3002", "result": "\u4f5c\u8005\u5c55\u793a\u4e86\u6b64\u6846\u67b6\u5728\u8bfe\u5802\u4e0a\u7684\u5e94\u7528\uff0c\u5e76\u8ba8\u8bba\u4e86\u4e24\u6b21\u8c03\u8bd5\u4f1a\u8bdd\uff0c\u8868\u660e\u7cfb\u7edf\u80fd\u5e2e\u52a9\u5b66\u751f\u5b9a\u4f4d\u548c\u4fee\u6b63\u9519\u8bef\uff0c\u63d0\u9ad8\u5b66\u4e60\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u6548\u7387\u4e0e\u8d28\u91cf\u3002\u8fd8\u7b80\u8981\u4ecb\u7ecd\u4e86\u9519\u8bef\u4fe1\u606f\u7cfb\u7edf\u7684\u5b9e\u73b0\u3002", "conclusion": "\u521b\u65b0\u8bbe\u8ba1\u914d\u65b9\u548c\u5b9a\u5236\u5316\u9519\u8bef\u4fe1\u606f\u80fd\u663e\u8457\u63d0\u5347\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u7cfb\u7edf\u6027\u652f\u6301\u548c\u7cbe\u786e\u53cd\u9988\u5e2e\u52a9\u5b66\u751f\u6709\u6548\u6539\u9519\u5e76\u63d0\u5347\u7406\u89e3\u3002"}}
{"id": "2508.03641", "categories": ["cs.FL", "cs.HC", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03641", "abs": "https://arxiv.org/abs/2508.03641", "authors": ["Marco T. Moraz\u00e1n", "David Anthony K. Fields", "Andr\u00e9s M. Garced", "Tijana Mini\u0107"], "title": "Visual Execution and Validation of Finite-State Machines and Pushdown Automata", "comment": "In Proceedings TFPiE 2025, arXiv:2508.02305", "summary": "In Formal Languages and Automata Theory courses, students find understanding\nnondeterministic finite-state and pushdown automata difficult. In many cases,\nthis means that it is challenging for them to comprehend the operational\nsemantics of such machines and, as a consequence, determine why a word is\naccepted or rejected. This is not entirely surprising, because students are\nmostly trained to design and implement deterministic programs. Comprehension of\npushdown automata is further complicated, because reasoning about the stack is\nnecessary. A common difficulty students face, for example, is understanding\nthat two different computations on the same word may reach the same state with\ndifferent stack values. To aid student understanding, we present two novel\ndynamic visualization tools for FSM -- a domain-specific programming language\nfor the Automata Theory classroom -- to support the design of such machines.\nThese tools visualize all computations that may be performed, respectively, by\na nondeterministic finite-state machine or by a pushdown automata in a stepwise\nmanner. In addition, these tools aid the machine verification process by\nallowing users to visually validate whether the properties a state represents\nhold when a machine transitions into it.", "AI": {"tldr": "\u901a\u8fc7\u5f15\u5165\u4e24\u79cd\u52a8\u6001\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u6781\u5927\u63d0\u5347\u4e86\u5b66\u751f\u5bf9\u975e\u786e\u5b9a\u6027\u81ea\u52a8\u673a\u548c\u4e0b\u63a8\u81ea\u52a8\u673a\u8fd0\u884c\u673a\u5236\u7684\u7406\u89e3\u4e0e\u9a8c\u8bc1\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5bf9\u590d\u6742\u8ba1\u7b97\u8def\u5f84\u548c\u6808\u64cd\u4f5c\u7684\u638c\u63e1\u3002", "motivation": "\u5b66\u751f\u4eec\u5728\u5f62\u5f0f\u8bed\u8a00\u4e0e\u81ea\u52a8\u673a\u7406\u8bba\u8bfe\u7a0b\u4e2d\uff0c\u5e38\u5e38\u96be\u4ee5\u7406\u89e3\u975e\u786e\u5b9a\u6027\u6709\u9650\u81ea\u52a8\u673a\u548c\u4e0b\u63a8\u81ea\u52a8\u673a\u7684\u5de5\u4f5c\u539f\u7406\u3002\u4e3b\u8981\u56f0\u96be\u5728\u4e8e\u4ed6\u4eec\u5927\u591a\u4e60\u60ef\u4e8e\u8bbe\u8ba1\u548c\u5b9e\u73b0\u786e\u5b9a\u6027\u7a0b\u5e8f\uff0c\u800c\u5bf9\u4e8e\u81ea\u52a8\u673a\u5c24\u5176\u662f\u6d89\u53ca\u6808\u64cd\u4f5c\u7684\u4e0b\u63a8\u81ea\u52a8\u673a\uff0c\u5b58\u5728\u72b6\u6001\u548c\u6808\u503c\u4e0d\u540c\u6b65\u7684\u7406\u89e3\u969c\u788d\u3002", "method": "\u4f5c\u8005\u5f00\u53d1\u4e86\u4e13\u7528\u4e8e\u81ea\u52a8\u673a\u7406\u8bba\u6559\u5b66\u7684\u9886\u57df\u7279\u5b9a\u7f16\u7a0b\u8bed\u8a00FSM\uff0c\u5e76\u57fa\u4e8e\u6b64\u5b9e\u73b0\u4e86\u4e24\u79cd\u52a8\u6001\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u5206\u522b\u9488\u5bf9\u975e\u786e\u5b9a\u6027\u6709\u9650\u81ea\u52a8\u673a\u548c\u4e0b\u63a8\u81ea\u52a8\u673a\uff0c\u80fd\u591f\u9010\u6b65\u5448\u73b0\u5176\u6240\u6709\u8ba1\u7b97\u60c5\u51b5\uff0c\u5e76\u652f\u6301\u72b6\u6001\u5c5e\u6027\u53ef\u89c6\u5316\u9a8c\u8bc1\u3002", "result": "\u672c\u6587\u63d0\u51fa\u7684\u4e24\u79cd\u52a8\u6001\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u80fd\u4ee5\u9010\u6b65\u6f14\u793a\u7684\u65b9\u5f0f\uff0c\u5bf9\u4e8e\u975e\u786e\u5b9a\u6027\u6709\u9650\u81ea\u52a8\u673a\u548c\u4e0b\u63a8\u81ea\u52a8\u673a\u8fdb\u884c\u6240\u6709\u53ef\u80fd\u8ba1\u7b97\u8def\u5f84\u7684\u52a8\u6001\u53ef\u89c6\u5316\uff0c\u5e2e\u52a9\u5b66\u751f\u548c\u7528\u6237\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u4e9b\u81ea\u52a8\u673a\u7684\u64cd\u4f5c\u8bed\u4e49\u548c\u8ba1\u7b97\u8fc7\u7a0b\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u5de5\u5177\u8fd8\u8f85\u52a9\u4e86\u81ea\u52a8\u673a\u7684\u9a8c\u8bc1\u8fc7\u7a0b\uff0c\u7528\u6237\u53ef\u901a\u8fc7\u53ef\u89c6\u5316\u754c\u9762\u76f4\u89c2\u9a8c\u8bc1\u72b6\u6001\u5c5e\u6027\u5728\u72b6\u6001\u8f6c\u79fb\u8fc7\u7a0b\u4e2d\u7684\u4fdd\u6301\u60c5\u51b5\u3002", "conclusion": "\u8fd9\u4e24\u79cd\u53ef\u89c6\u5316\u5de5\u5177\u6709\u6548\u5e2e\u52a9\u5b66\u751f\u6df1\u5165\u7406\u89e3\u975e\u786e\u5b9a\u6027\u81ea\u52a8\u673a\u548c\u4e0b\u63a8\u81ea\u52a8\u673a\u7684\u8fd0\u4f5c\u673a\u5236\uff0c\u5e76\u4e3a\u81ea\u52a8\u673a\u7406\u8bba\u8bfe\u5802\u548c\u76f8\u5173\u5e94\u7528\u63d0\u4f9b\u4e86\u76f4\u89c2\u6709\u6548\u7684\u5b9e\u8df5\u652f\u6301\u3002"}}
{"id": "2508.03361", "categories": ["cs.DM", "math.CO", "math.PR", "05C80, 68R10, 05C38"], "pdf": "https://arxiv.org/pdf/2508.03361", "abs": "https://arxiv.org/abs/2508.03361", "authors": ["Samuel Baguley", "Andreas G\u00f6bel", "Nicolas Klodt", "George Skretas", "John Sylvester", "Viktor Zamaraev"], "title": "Temporal Exploration of Random Spanning Tree Models", "comment": "42 pages, 8 Figures", "summary": "The Temporal Graph Exploration problem (TEXP) takes as input a temporal\ngraph, i.e., a sequence of graphs $(G_i)_{i\\in \\mathbb{N}}$ on the same vertex\nset, and asks for a walk of shortest length visiting all vertices, where the\n$i$-th step uses an edge from $G_i$. If each such $G_i$ is connected, then an\nexploration of length $n^2$ exists, and this is known to be the best possible\nup to a constant. More fine-grained lower and upper bounds have been obtained\nfor restricted temporal graph classes, however, for several fundamental\nclasses, a large gap persists between known bounds, and it remains unclear\nwhich properties of a temporal graph make it inherently difficult to explore.\n  Motivated by this limited understanding and the central role of the Temporal\nGraph Exploration problem in temporal graph theory, we study the problem in a\nrandomised setting. We introduce the Random Spanning Tree (RST) model, which\nconsists of a set of $n$-vertex trees together with an arbitrary probability\ndistribution $\\mu$ over this set. A random temporal graph generated by the RST\nmodel is a sequence of independent samples drawn from $\\mu$.\n  We initiate a systematic study of the Temporal Graph Exploration problem in\nsuch random temporal graphs and establish tight general bounds on exploration\ntime. Our first main result proves that any RST model can, with high\nprobability (w.h.p.), be explored in $O(n^{3/2})$ time, and we show that this\nbound is tight up to a constant factor. This demonstrates a fundamental\ndifference between the adversarial and random settings. Our second main result\nshows that if all trees of an RST are subgraphs of a fixed graph with $m$ edges\nthen, w.h.p.\\ , it can be explored in $O(m)$ time.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4e86\u65f6\u53d8\u56fe\u63a2\u7d22\u95ee\u9898\uff08TEXP\uff09\u5728\u968f\u673a\u751f\u6210\u7684\u6811\u65f6\u53d8\u56fe\uff08RST\u6a21\u578b\uff09\u4e2d\u7684\u8868\u73b0\uff0c\u7ed9\u51fa\u4e86\u7d27\u81f4\u7684\u4e0a\u4e0b\u754c\uff0c\u5c55\u793a\u4e86\u968f\u673a\u60c5\u666f\u4e0b\u4e0e\u5bf9\u6297\u6027\u60c5\u666f\u5728\u63a2\u7d22\u65f6\u95f4\u4e0a\u7684\u6839\u672c\u5dee\u5f02\u3002", "motivation": "\u5f53\u524dTEXP\u95ee\u9898\u5728\u90e8\u5206\u57fa\u672c\u65f6\u53d8\u56fe\u7c7b\u522b\u4e0a\u5df2\u77e5\u7684\u4e0a\u4e0b\u754c\u76f8\u5dee\u6781\u5927\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u54ea\u4e9b\u56fe\u5c5e\u6027\u51b3\u5b9a\u5176\u63a2\u7d22\u96be\u5ea6\u7684\u672c\u8d28\u7406\u89e3\u3002\u6587\u7ae0\u5f15\u5165\u968f\u673a\u6a21\u578b\u4ee5\u63ed\u793a\u56fe\u7ed3\u6784\u7279\u6027\u5bf9\u63a2\u7d22\u96be\u5ea6\u7684\u5f71\u54cd\uff0c\u63a8\u52a8\u65f6\u53d8\u56fe\u7406\u8bba\u53d1\u5c55\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86RST\uff08\u968f\u673a\u751f\u6210\u6811\uff09\u6a21\u578b\uff0c\u5c06\u65f6\u53d8\u56fe\u8868\u793a\u4e3a\u4e00\u7cfb\u5217\u72ec\u7acb\u7684\u6811\u6837\u672c\u3002\u9488\u5bf9\u8be5\u6a21\u578b\uff0c\u7406\u8bba\u5206\u6790\u5e76\u63a8\u5bfc\u4e86\u63a2\u7d22\u6240\u9700\u6700\u77ed\u6b65\u6570\u7684\u4e0a\u4e0b\u754c\uff08\u9ad8\u6982\u7387\u4e0b\uff09\u3002\u65b9\u6cd5\u4e0a\uff0c\u4e3b\u8981\u4f7f\u7528\u6982\u7387\u3001\u7ec4\u5408\u53ca\u56fe\u8bba\u5206\u6790\u6280\u672f\u3002", "result": "\u5728\u968f\u673a\u751f\u6210\u7684\u6811\u65f6\u53d8\u56fe\uff08RST\u6a21\u578b\uff09\u4e0a\uff0c\u63a2\u7d22\u65f6\u95f4w.h.p.\u4e3aO(n^{3/2})\uff0c\u4e14\u8fbe\u5230\u8be5\u4e0b\u754c\uff1b\u82e5\u6240\u6709\u6811\u4e3a\u67d0\u56fa\u5b9a\u56fe\u7684\u5b50\u56fe\uff0c\u5219\u63a2\u7d22\u65f6\u95f4\u4e3aO(m)\u3002\u8fd9\u4e9b\u7ed3\u679c\u7f29\u5c0f\u4e86\u4ee5\u5f80\u5728\u67d0\u4e9b\u7c7b\u522b\u4e2d\u7684\u4e0a\u4e0b\u754c\u95f4\u9699\uff0c\u5e76\u5c55\u793a\u4e86\u4e0e\u5bf9\u6297\u6027\u6a21\u578b\u5728\u63a2\u7d22\u590d\u6742\u5ea6\u4e0a\u7684\u5dee\u5f02\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u4efb\u610fRST\u6a21\u578b\u4e0b\uff0c\u9ad8\u6982\u7387\u4e0b\u53ef\u5728O(n^{3/2})\u65f6\u95f4\u5b8c\u6210\u63a2\u7d22\uff0c\u8fd9\u4e00\u7ed3\u679c\u5728\u5e38\u6570\u56e0\u5b50\u8303\u56f4\u5185\u662f\u6700\u4f18\u7684\uff1b\u82e5\u6240\u6709\u6811\u5747\u4e3a\u67d0\u4e2a\u56fa\u5b9am\u6761\u8fb9\u56fe\u7684\u5b50\u56fe\uff0c\u5219\u63a2\u7d22\u65f6\u95f4\u53ef\u964d\u81f3O(m)\u3002\u8fd9\u4e3aTEXP\u5728\u65f6\u53d8\u6811\u7684\u968f\u673a\u6a21\u578b\u4e0b\u63a2\u7d22\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u4e0e\u8fb9\u754c\u3002"}}
{"id": "2508.02857", "categories": ["cs.PL", "quant-ph"], "pdf": "https://arxiv.org/pdf/2508.02857", "abs": "https://arxiv.org/abs/2508.02857", "authors": ["Mikhail Mints", "Finn Voichick", "Leonidas Lampropoulos", "Robert Rand"], "title": "Compositional Quantum Control Flow with Efficient Compilation in Qunity", "comment": "88 pages, 30 figures", "summary": "Most existing quantum programming languages are based on the quantum circuit\nmodel of computation, as higher-level abstractions are particularly challenging\nto implement - especially ones relating to quantum control flow. The Qunity\nlanguage, proposed by Voichick et al., offered such an abstraction in the form\nof a quantum control construct, with great care taken to ensure that the\nresulting language is still realizable. However, Qunity lacked a working\nimplementation, and the originally proposed compilation procedure was very\ninefficient, with even simple quantum algorithms compiling to unreasonably\nlarge circuits.\n  In this work, we focus on the efficient compilation of high-level quantum\ncontrol flow constructs, using Qunity as our starting point. We introduce a\nwider range of abstractions on top of Qunity's core language that offer\ncompelling trade-offs compared to its existing control construct. We create a\ncomplete implementation of a Qunity compiler, which converts high-level Qunity\ncode into the quantum assembly language OpenQASM 3. We develop optimization\ntechniques for multiple stages of the Qunity compilation procedure, including\nboth low-level circuit optimizations as well as methods that consider the\nhigh-level structure of a Qunity program, greatly reducing the number of qubits\nand gates used by the compiler.", "AI": {"tldr": "\u672c\u6587\u4ee5Qunity\u4e3a\u57fa\u7840\uff0c\u63d0\u51fa\u66f4\u6709\u6548\u7684\u91cf\u5b50\u63a7\u5236\u62bd\u8c61\uff0c\u5b9e\u73b0\u4e86\u5b8c\u6574\u9ad8\u6548\u7684Qunity\u7f16\u8bd1\u5668\uff0c\u53ef\u5c06\u9ad8\u5c42\u4ee3\u7801\u4f18\u5316\u5e76\u8f93\u51fa\u4e3aOpenQASM 3\uff0c\u6709\u6548\u964d\u4f4e\u8d44\u6e90\u6d88\u8017\uff0c\u4e3a\u91cf\u5b50\u9ad8\u7ea7\u7f16\u7a0b\u62bd\u8c61\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002", "motivation": "\u76ee\u524d\u5927\u591a\u6570\u91cf\u5b50\u7f16\u7a0b\u8bed\u8a00\u90fd\u57fa\u4e8e\u91cf\u5b50\u7535\u8def\u6a21\u578b\uff0c\u5b9e\u73b0\u9ad8\u7ea7\u62bd\u8c61\uff08\u5982\u91cf\u5b50\u63a7\u5236\u6d41\uff09\u975e\u5e38\u5177\u6311\u6218\u6027\u3002\u6b64\u524d\u63d0\u51fa\u7684Qunity\u8bed\u8a00\u63d0\u51fa\u4e86\u91cf\u5b50\u63a7\u5236\u6d41\u7684\u65b0\u62bd\u8c61\uff0c\u4f46\u6ca1\u6709\u5b9e\u9645\u7684\u7f16\u8bd1\u5668\u5b9e\u73b0\uff0c\u4e14\u5176\u521d\u6b65\u7684\u7f16\u8bd1\u65b9\u6848\u6548\u7387\u6781\u4f4e\uff0c\u5bfc\u81f4\u7b80\u5355\u7b97\u6cd5\u4e5f\u7f16\u8bd1\u6210\u6781\u5927\u7684\u7535\u8def\u3002", "method": "\u4ee5Qunity\u4f5c\u4e3a\u57fa\u7840\uff0c\u63d0\u51fa\u66f4\u5e7f\u6cdb\u7684\u62bd\u8c61\u6765\u6539\u8fdb\u63a7\u5236\u7ed3\u6784\uff0c\u5e76\u5b9e\u73b0\u4e86\u5b8c\u6574\u7684Qunity\u7f16\u8bd1\u5668\uff0c\u53ef\u4ee5\u5c06\u9ad8\u9636Qunity\u4ee3\u7801\u7f16\u8bd1\u4e3aOpenQASM 3\u3002\u540c\u65f6\uff0c\u5728\u7f16\u8bd1\u8fc7\u7a0b\u7684\u591a\u4e2a\u9636\u6bb5\u5f15\u5165\u4e86\u4f18\u5316\u6280\u672f\uff0c\u5305\u62ec\u7535\u8def\u7ea7\u548c\u9762\u5411\u9ad8\u9636\u7ed3\u6784\u7684\u4f18\u5316\uff0c\u4ee5\u663e\u8457\u51cf\u5c11\u7f16\u8bd1\u540e\u4f7f\u7528\u7684\u91cf\u5b50\u6bd4\u7279\u6570\u548c\u95e8\u6570\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u5957\u9ad8\u6548\u7684Qunity\u7f16\u8bd1\u5668\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u5c06\u9ad8\u5c42Qunity\u4ee3\u7801\u8f6c\u6362\u4e3aOpenQASM 3\u4ee3\u7801\uff0c\u5e76\u901a\u8fc7\u591a\u7ea7\u4f18\u5316\u663e\u8457\u51cf\u5c11\u4e86\u6240\u9700\u7684\u91cf\u5b50\u8d44\u6e90\uff08\u5305\u62ec\u91cf\u5b50\u6bd4\u7279\u53ca\u95e8\u6570\uff09\u3002", "conclusion": "\u672c\u7814\u7a76\u4e0d\u4ec5\u5b9e\u73b0\u4e86Qunity\u8bed\u8a00\u7684\u5b9e\u9645\u7f16\u8bd1\u5de5\u5177\uff0c\u800c\u4e14\u901a\u8fc7\u591a\u79cd\u4f18\u5316\u624b\u6bb5\uff0c\u6781\u5927\u63d0\u5347\u4e86\u9488\u5bf9\u590d\u6742\u91cf\u5b50\u63a7\u5236\u6d41\u6784\u9020\u7684\u7f16\u8bd1\u6548\u7387\uff0c\u63a8\u52a8\u4e86\u91cf\u5b50\u9ad8\u7ea7\u62bd\u8c61\u5728\u5b9e\u9645\u7cfb\u7edf\u4e2d\u7684\u843d\u5730\u3002"}}
{"id": "2508.02764", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.02764", "abs": "https://arxiv.org/abs/2508.02764", "authors": ["Konstantin Doubrovinski"], "title": "When are two algorithms the same? Towards addressing Hilbert's 24th problem", "comment": null, "summary": "The informal question of when two theorem proofs are \"essentially the same\"\ngoes back to David Hilbert, who considered adding it (or something largely\nequivalent) to his famous list of open problems, but eventually decided to\nleave it out. Given that the notion of a formal proof is closely related to\nthat of a (computer) program, i.e. a recursive function, it may be useful to\nask the same question with regard to programs instead. Here we propose a\nminimalistic approach to this question within Recursion Theory, building\nheavily on the use of Kolmogorov Complexity.", "AI": {"tldr": "\u8be5\u6587\u501f\u52a9Kolmogorov\u590d\u6742\u5ea6\uff0c\u63d0\u51fa\u4e86\u9012\u5f52\u7406\u8bba\u4e0b\u8861\u91cf\u4e24\u4e2a\u7a0b\u5e8f\uff08\u6216\u5b9a\u7406\u8bc1\u660e\uff09\u672c\u8d28\u76f8\u540c\u6027\u7684\u6781\u7b80\u65b9\u6cd5\u3002", "motivation": "\u63a2\u8ba8\u5224\u5b9a\u4e24\u4e2a\u5b9a\u7406\u8bc1\u660e\u201c\u672c\u8d28\u4e0a\u662f\u5426\u76f8\u540c\u201d\u7684\u95ee\u9898\uff0c\u8fd9\u4e00\u95ee\u9898\u6700\u65e9\u53ef\u8ffd\u6eaf\u5230Hilbert\u3002\u7531\u4e8e\u5f62\u5f0f\u8bc1\u660e\u4e0e\u8ba1\u7b97\u673a\u7a0b\u5e8f\uff08\u9012\u5f52\u51fd\u6570\uff09\u6709\u5bc6\u5207\u5173\u8054\uff0c\u5bf9\u7a0b\u5e8f\u7684\u201c\u672c\u8d28\u76f8\u540c\u6027\u201d\u95ee\u9898\u540c\u6837\u503c\u5f97\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u5728\u9012\u5f52\u7406\u8bba\u6846\u67b6\u4e0b\u5229\u7528Kolmogorov\u590d\u6742\u5ea6\uff0c\u6784\u5efa\u4e00\u4e2a\u6781\u7b80\u4e3b\u4e49\u7684\u7814\u7a76\u65b9\u6cd5\u6765\u5206\u6790\u7a0b\u5e8f\uff08\u6216\u8bc1\u660e\uff09\u7684\u672c\u8d28\u76f8\u540c\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eKolmogorov\u590d\u6742\u5ea6\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u7528\u4e8e\u5224\u65ad\u4e24\u4e2a\u7a0b\u5e8f\u6216\u5b9a\u7406\u8bc1\u660e\u5728\u9012\u5f52\u7406\u8bba\u4e2d\u7684\u76f8\u4f3c\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06Kolmogorov\u590d\u6742\u5ea6\u5f15\u5165\u9012\u5f52\u7406\u8bba\uff0c\u4e3a\u5224\u5b9a\u7a0b\u5e8f\uff08\u5373\u8bc1\u660e\uff09\u201c\u672c\u8d28\u76f8\u540c\u201d\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u7406\u8bba\u5de5\u5177\u548c\u6781\u7b80\u9014\u5f84\u3002"}}
{"id": "2508.02808", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02808", "abs": "https://arxiv.org/abs/2508.02808", "authors": ["Radhika Dua", "Young Joon", "Kwon", "Siddhant Dogra", "Daniel Freedman", "Diana Ruan", "Motaz Nashawaty", "Danielle Rigau", "Daniel Alexander Alber", "Kang Zhang", "Kyunghyun Cho", "Eric Karl Oermann"], "title": "Clinically Grounded Agent-based Report Evaluation: An Interpretable Metric for Radiology Report Generation", "comment": null, "summary": "Radiological imaging is central to diagnosis, treatment planning, and\nclinical decision-making. Vision-language foundation models have spurred\ninterest in automated radiology report generation (RRG), but safe deployment\nrequires reliable clinical evaluation of generated reports. Existing metrics\noften rely on surface-level similarity or behave as black boxes, lacking\ninterpretability. We introduce ICARE (Interpretable and Clinically-grounded\nAgent-based Report Evaluation), an interpretable evaluation framework\nleveraging large language model agents and dynamic multiple-choice question\nanswering (MCQA). Two agents, each with either the ground-truth or generated\nreport, generate clinically meaningful questions and quiz each other. Agreement\non answers captures preservation and consistency of findings, serving as\ninterpretable proxies for clinical precision and recall. By linking scores to\nquestion-answer pairs, ICARE enables transparent, and interpretable assessment.\nClinician studies show ICARE aligns significantly more with expert judgment\nthan prior metrics. Perturbation analyses confirm sensitivity to clinical\ncontent and reproducibility, while model comparisons reveal interpretable error\npatterns.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ICARE\u6846\u67b6\uff0c\u4e00\u79cd\u53ef\u89e3\u91ca\u4e14\u4ee5\u4e34\u5e8a\u4e3a\u57fa\u7840\u7684\u81ea\u52a8\u5316\u653e\u5c04\u5b66\u62a5\u544a\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u751f\u6210\u548c\u7b54\u9898\u5b9e\u73b0\u62a5\u544a\u8bc4\u6d4b\uff0c\u7ed3\u679c\u66f4\u8d34\u5408\u4e34\u5e8a\u4e13\u5bb6\u5224\u65ad\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u5316\u653e\u5c04\u5b66\u62a5\u544a\u751f\u6210\u8bc4\u4f30\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u4e14\u96be\u4ee5\u4e0e\u4e34\u5e8a\u9700\u6c42\u7d27\u5bc6\u7ed3\u5408\uff0c\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u52a0\u900f\u660e\u3001\u53ef\u9760\u7684\u62a5\u544a\u8bc4\u6d4b\u65b9\u6cd5\u3002", "method": "\u6846\u67b6\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u57fa\u4e8eLLM\u7684\u4ee3\u7406\uff0c\u5206\u522b\u638c\u63e1\u771f\u5b9e\u62a5\u544a\u548c\u751f\u6210\u62a5\u544a\uff0c\u901a\u8fc7\u63d0\u51fa\u4e34\u5e8a\u76f8\u5173\u7684\u52a8\u6001\u9009\u62e9\u9898\u4e92\u76f8\u63d0\u95ee\uff0c\u53cc\u65b9\u5bf9\u95ee\u9898\u7684\u56de\u7b54\u5339\u914d\u5ea6\u53cd\u6620\u4e86\u62a5\u544a\u5185\u5bb9\u7684\u4fdd\u5b58\u548c\u4e00\u81f4\u6027\uff0c\u5e76\u53ef\u8ffd\u6eaf\u5177\u4f53\u5f97\u5206\u9879\u3002", "result": "ICARE\u80fd\u660e\u663e\u63d0\u5347\u62a5\u544a\u81ea\u52a8\u8bc4\u4f30\u7684\u53ef\u89e3\u91ca\u6027\u548c\u4e34\u5e8a\u76f8\u5173\u6027\uff0c\u5bf9\u5185\u5bb9\u6270\u52a8\u654f\u611f\u4e14\u5177\u6709\u53ef\u91cd\u73b0\u6027\uff0c\u5e76\u63ed\u793a\u4e0d\u540c\u751f\u6210\u6a21\u578b\u7684\u5177\u4f53\u8bef\u5dee\u6a21\u5f0f\uff0c\u53d7\u4e13\u5bb6\u8bc4\u5224\u9ad8\u5ea6\u8ba4\u53ef\u3002", "conclusion": "ICARE\u6846\u67b6\u8bc4\u4f30\u81ea\u52a8\u751f\u6210\u653e\u5c04\u5b66\u62a5\u544a\u7684\u7ed3\u679c\u663e\u8457\u4f18\u4e8e\u4ee5\u5f80\u6307\u6807\uff0c\u80fd\u66f4\u597d\u5730\u4e0e\u4e13\u5bb6\u610f\u89c1\u4e00\u81f4\uff0c\u5e76\u4e14\u8bc4\u6d4b\u8fc7\u7a0b\u900f\u660e\u3001\u53ef\u89e3\u91ca\u3002"}}
{"id": "2508.02721", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.02721", "abs": "https://arxiv.org/abs/2508.02721", "authors": ["Libin Qiu", "Yuhang Ye", "Zhirong Gao", "Xide Zou", "Junfu Chen", "Ziming Gui", "Weizhi Huang", "Xiaobo Xue", "Wenkai Qiu", "Kun Zhao"], "title": "Blueprint First, Model Second: A Framework for Deterministic LLM Workflow", "comment": "8 pages, 6 figures, 3 tables", "summary": "While powerful, the inherent non-determinism of large language model (LLM)\nagents limits their application in structured operational environments where\nprocedural fidelity and predictable execution are strict requirements. This\nlimitation stems from current architectures that conflate probabilistic,\nhigh-level planning with low-level action execution within a single generative\nprocess. To address this, we introduce the Source Code Agent framework, a new\nparadigm built on the \"Blueprint First, Model Second\" philosophy. Our framework\ndecouples the workflow logic from the generative model. An expert-defined\noperational procedure is first codified into a source code-based Execution\nBlueprint, which is then executed by a deterministic engine. The LLM is\nstrategically invoked as a specialized tool to handle bounded, complex\nsub-tasks within the workflow, but never to decide the workflow's path. We\nconduct a comprehensive evaluation on the challenging tau-bench benchmark,\ndesigned for complex user-tool-rule scenarios. Our results demonstrate that the\nSource Code Agent establishes a new state-of-the-art, outperforming the\nstrongest baseline by 10.1 percentage points on the average Pass^1 score while\ndramatically improving execution efficiency. Our work enables the verifiable\nand reliable deployment of autonomous agents in applications governed by strict\nprocedural logic.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSource Code Agent\uff0c\u5c06\u4e13\u5bb6\u7f16\u5199\u7684\u6d41\u7a0b\u84dd\u56fe\u4e0eLLM\u5206\u79bb\uff0c\u7531\u786e\u5b9a\u6027\u5f15\u64ce\u4e25\u683c\u6267\u884c\uff0cLLM\u4ec5\u89e3\u51b3\u590d\u6742\u5b50\u4efb\u52a1\u3002\u65b0\u6846\u67b6\u5728tau-bench\u6d4b\u8bd5\u4e2d\u521b\u4e0b\u65b0\u7eaa\u5f55\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u4e0e\u6548\u7387\uff0c\u5b9e\u73b0\u4e86\u81ea\u4e3b\u4ee3\u7406\u5728\u4e25\u683c\u64cd\u4f5c\u89c4\u8303\u4e0b\u7684\u53ef\u9760\u5e94\u7528\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u5177\u6709\u5f3a\u5927\u7684\u80fd\u529b\uff0c\u4f46\u7531\u4e8e\u5176\u56fa\u6709\u7684\u975e\u786e\u5b9a\u6027\uff0c\u96be\u4ee5\u6ee1\u8db3\u7ed3\u6784\u5316\u64cd\u4f5c\u73af\u5883\u5bf9\u8fc7\u7a0b\u51c6\u786e\u6027\u4e0e\u53ef\u9884\u6d4b\u6267\u884c\u7684\u4e25\u683c\u8981\u6c42\u3002\u8fd9\u4e00\u5c40\u9650\u6765\u6e90\u4e8e\u73b0\u6709\u67b6\u6784\u5c06\u9ad8\u5c42\u6982\u7387\u89c4\u5212\u548c\u4f4e\u5c42\u52a8\u4f5c\u6267\u884c\u6df7\u4e3a\u4e00\u4f53\u3002", "method": "\u63d0\u51faSource Code Agent\u6846\u67b6\uff0c\u91c7\u7528\u201c\u5148\u84dd\u56fe\u3001\u540e\u6a21\u578b\u201d\u7406\u5ff5\uff0c\u5c06\u5de5\u4f5c\u6d41\u7a0b\u903b\u8f91\u4e0e\u751f\u6210\u6a21\u578b\u89e3\u8026\u3002\u9996\u5148\u7531\u4e13\u5bb6\u5c06\u64cd\u4f5c\u6d41\u7a0b\u7f16\u7801\u4e3a\u6e90\u7801\u5f62\u5f0f\u7684\u6267\u884c\u84dd\u56fe\uff0c\u7136\u540e\u7531\u786e\u5b9a\u6027\u5f15\u64ce\u9010\u6b65\u6267\u884c\u3002LLM\u4ec5\u7528\u4e8e\u5728\u6d41\u7a0b\u5185\u5904\u7406\u6709\u9650\u4e14\u590d\u6742\u7684\u5b50\u4efb\u52a1\uff0c\u4f46\u4e0d\u53c2\u4e0e\u6d41\u7a0b\u51b3\u7b56\u3002", "result": "\u5728tau-bench\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cSource Code Agent\u8d85\u8d8a\u4e86\u6700\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u5e73\u5747Pass^1\u5f97\u5206\u63d0\u9ad8\u4e8610.1\u4e2a\u767e\u5206\u70b9\uff0c\u5e76\u5927\u5e45\u63d0\u5347\u4e86\u6267\u884c\u6548\u7387\u3002", "conclusion": "Source Code Agent\u6846\u67b6\u514b\u670d\u4e86LLM\u4ee3\u7406\u5728\u53ef\u9884\u6d4b\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u4e0a\u7684\u5c40\u9650\uff0c\u4f7f\u5f97\u81ea\u4e3b\u4ee3\u7406\u53ef\u5728\u4e25\u683c\u6d41\u7a0b\u903b\u8f91\u7ba1\u63a7\u7684\u5e94\u7528\u4e2d\u53ef\u9760\u90e8\u7f72\u3002"}}
{"id": "2508.03549", "categories": ["cs.DM", "math.CO", "05C15, 68R10", "G.2.1; G.2.2"], "pdf": "https://arxiv.org/pdf/2508.03549", "abs": "https://arxiv.org/abs/2508.03549", "authors": ["Diptimaya Behera", "Mathew C. Francis", "Sreejith K. Pallathumadam"], "title": "Adjacent vertex distinguishing total coloring of 3-degenerate graphs", "comment": null, "summary": "A total coloring of a simple undirected graph $G$ is an assignment of colors\nto its vertices and edges such that the colors given to the vertices form a\nproper vertex coloring, the colors given to the edges form a proper edge\ncoloring, and the color of every edge is different from that of its two\nendpoints. That is, $\\phi:V(G)\\cup E(G)\\rightarrow\\mathbb{N}$ is a total\ncoloring of $G$ if $\\phi(u)\\neq\\phi(v)$ and $\\phi(uv)\\neq\\phi(u)$ for all\n$uv\\in E(G)$, and $\\phi(uv)\\neq\\phi(uw)$ for any $u \\in V(G)$ and distinct $v,w\n\\in N(u)$ (here, $N(u)$ denotes the set of neighbours of $u$). A total coloring\n$\\phi$ of a graph $G$ is said to be ``Adjacent Vertex Distinguishing'' (or AVD\nfor short) if for all $uv\\in E(G)$, we have that $\\phi(\\{u\\}\\cup\\{uw:w\\in\nN(u)\\})\\neq\\phi(\\{v\\}\\cup\\{vw\\colon w\\in N(v)\\})$. The AVD Total Coloring\nConjecture of Zhang, Chen, Li, Yao, Lu, and Wang (Science in China Series A:\nMathematics, 48(3):289--299, 2005) states that every graph $G$ has an AVD total\ncoloring using at most $\\Delta(G)+3$ colors, where $\\Delta(G)$ denotes the\nmaximum degree of $G$. For some $s\\in\\mathbb{N}$, a graph $G$ is said to be\n$s$-degenerate if every subgraph of $G$ has minimum degree at most $s$. Miao,\nShi, Hu, and Luo (Discrete Mathematics, 339(10):2446--2449, 2016) showed that\nthe AVD Total Coloring Conjecture is true for 2-degenerate graphs. We verify\nthe conjecture for 3-degenerate graphs.", "AI": {"tldr": "\u672c\u6587\u5173\u6ce8\u56fe\u8bba\u4e2d\u7684\u603b\u7740\u8272\u95ee\u9898\uff0c\u7279\u522b\u662f\u201c\u90bb\u70b9\u53ef\u533a\u5206\u603b\u7740\u8272\u201d\uff08AVD\u603b\u7740\u8272\uff09\u731c\u60f3\u3002\u8be5\u731c\u60f3\u8ba4\u4e3a\u5bf9\u4e8e\u4efb\u610f\u56fe$G$\uff0c\u5b58\u5728\u4f7f\u7528\u4e0d\u8d85\u8fc7\u6700\u5927\u5ea6\u6570\u52a0\u4e09\uff08$\nDelta(G)+3$\uff09\u79cd\u989c\u8272\u7684AVD\u603b\u7740\u8272\u3002\u672c\u6587\u7684\u4e3b\u8981\u8d21\u732e\u662f\u8bc1\u5b9e\u4e86\u8be5\u731c\u60f3\u5bf9\u4e8e3-\u9000\u5316\u56fe\u6210\u7acb\u3002", "motivation": "AVD\u603b\u7740\u8272\u731c\u60f3\u662f\u56fe\u7740\u8272\u7406\u8bba\u4e2d\u7684\u91cd\u8981\u672a\u89e3\u95ee\u9898\uff0c\u5176\u63a8\u5e7f\u4e86\u7ecf\u5178\u7684\u9876\u70b9\u7740\u8272\u548c\u8fb9\u7740\u8272\u7406\u8bba\uff0c\u89e3\u51b3\u5b83\u53ef\u4ee5\u6df1\u5316\u5bf9\u56fe\u7740\u8272\u590d\u6742\u6027\u548c\u5206\u8fa8\u6027\u7684\u7406\u89e3\u3002\u6b64\u524d\uff0c\u4ec5\u5bf9\u5c0f\u65cf\u7c7b\u56fe\uff08\u59822-\u9000\u5316\u56fe\uff09\u6210\u7acb\uff0c\u4f5c\u8005\u5e0c\u671b\u63a8\u52a8\u8be5\u731c\u60f3\u5728\u66f4\u5e7f\u6cdb\u56fe\u7c7b\uff083-\u9000\u5316\u56fe\uff09\u4e0a\u7684\u8bc1\u660e\u3002", "method": "\u4f5c\u8005\u57fa\u4e8e\u5df2\u6709\u76842-\u9000\u5316\u56fe\u7ed3\u679c\uff0c\u8fd0\u7528\u56fe\u7684\u7ed3\u6784\u6027\u8d28\u548c\u9012\u5f52\u65b9\u6cd5\uff0c\u5c06\u8bc1\u660e\u6280\u5de7\u63a8\u5e7f\u52303-\u9000\u5316\u56fe\u3002\u65b9\u6cd5\u6d89\u53ca\u5bf9\u56fe\u7684\u5206\u89e3\u3001\u5b50\u56fe\u7740\u8272\u65b9\u6848\u7684\u6784\u9020\uff0c\u4ee5\u53ca\u5f52\u7eb3\u8bc1\u660e\u3002", "result": "\u8bba\u6587\u6210\u529f\u5730\u9a8c\u8bc1\u4e863-\u9000\u5316\u56fe\u6ee1\u8db3AVD\u603b\u7740\u8272\u731c\u60f3\u3002\u8fd9\u4e00\u7ed3\u679c\u63a8\u8fdb\u4e86\u603b\u7740\u8272\u731c\u60f3\u7814\u7a76\u7684\u524d\u6cbf\uff0c\u4e3a\u8fdb\u4e00\u6b65\u89e3\u51b3\u4e00\u822c\u56fe\u7684AVD\u603b\u7740\u8272\u731c\u60f3\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u8bba\u6587\u8bc1\u660e\u4e86\u5bf9\u6240\u67093-\u9000\u5316\u56fe\uff0cAVD\u603b\u7740\u8272\u731c\u60f3\u6210\u7acb\uff0c\u5373\u8fd9\u4e9b\u56fe\u90fd\u6700\u591a\u4f7f\u7528$\\Delta(G)+3$\u79cd\u989c\u8272\u5b9e\u73b0\u90bb\u70b9\u53ef\u533a\u5206\u603b\u7740\u8272\u3002"}}
{"id": "2508.03558", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.03558", "abs": "https://arxiv.org/abs/2508.03558", "authors": ["M Zafir Sadik Khan", "Nowfel Mashnoor", "Mohammad Akyash", "Kimia Azar", "Hadi Kamali"], "title": "SAGE-HLS: Syntax-Aware AST-Guided LLM for High-Level Synthesis Code Generation", "comment": "Accepted to the IEEE International Conference on Computer Design\n  (ICCD 2025)", "summary": "In today's rapidly evolving field of electronic design automation (EDA), the\ncomplexity of hardware designs is increasing, necessitating more sophisticated\nautomation solutions. High-level synthesis (HLS), as a pivotal solution,\nautomates hardware designs from high-level abstractions (e.g., C/C++). However,\nit faces significant challenges, particularly in design space exploration and\noptimization. While large language models (LLMs) have shown notable\ncapabilities in code generation, their application to HLS has been limited due\nto the scarcity of (publicly) available HLS code datasets. Hence, research in\nthis domain has primarily focused on techniques such as prompt engineering and\nretrieval-augmented generation (RAG). To overcome this limitation, this paper\nintroduces SAGE-HLS, the first-of-its-kind fine-tuned LLM specifically for HLS\ncode generation. Our method includes three key advancements: (i) We implement\nVerilog-to-C/C++ porting, converting verified and synthesizable Verilog codes\ninto corresponding C, creating a dataset of 16.7K HLS codes; (ii) We implement\na fine-tuning strategy, which is based on instruction prompting to code\ngeneration guided by abstract syntax tree (AST); (iii) We develop a\nsemi-automated evaluation framework using VerilogEval to assess the\nfunctionality of the generated HLS code. Our experiments show that SAGE-HLS,\nfined-tuned on the QwenCoder (2.5) 7B model, achieves a near 100% success rate\nin code synthesizability and a 75% success rate in functional correctness.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86SAGE-HLS\uff0c\u9996\u4e2a\u4e13\u4e3aHLS\u4ee3\u7801\u751f\u6210\u5fae\u8c03\u7684\u5927\u6a21\u578b\uff0c\u901a\u8fc7\u65b0\u6570\u636e\u96c6\u3001\u5fae\u8c03\u65b9\u6cd5\u548c\u81ea\u52a8\u8bc4\u6d4b\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86HLS\u4ee3\u7801\u7684\u53ef\u7efc\u5408\u6027\u548c\u6b63\u786e\u6027\u3002", "motivation": "\u7535\u5b50\u8bbe\u8ba1\u81ea\u52a8\u5316\uff08EDA\uff09\u9886\u57df\u786c\u4ef6\u8bbe\u8ba1\u590d\u6742\u5ea6\u4e0d\u65ad\u63d0\u5347\uff0c\u9700\u8981\u66f4\u5148\u8fdb\u7684\u81ea\u52a8\u5316\u65b9\u6848\u3002\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u867d\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u53d7\u9650\u4e8e\u9ad8\u8d28\u91cfHLS\u4ee3\u7801\u6570\u636e\u96c6\u7684\u7f3a\u4e4f\uff0c\u5176\u5728HLS\u9886\u57df\u5e94\u7528\u53d7\u963b\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u9488\u5bf9HLS\u4ee3\u7801\u751f\u6210\u5f00\u53d1\u4e13\u95e8\u7684\u6570\u636e\u96c6\u548c\u4f18\u5316\u7684\u5efa\u6a21\u3001\u8bc4\u4ef7\u4f53\u7cfb\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86SAGE-HLS\u6a21\u578b\uff0c\u662f\u9996\u4e2a\u4e13\u4e3a\u9ad8\u5c42\u6b21\u7efc\u5408\uff08HLS\uff09\u4ee3\u7801\u751f\u6210\u5fae\u8c03\u7684\u5927\u8bed\u8a00\u6a21\u578b\u3002\u5176\u4e3b\u8981\u65b9\u6cd5\u5305\u62ec\u4e09\u90e8\u5206\uff1a\uff081\uff09\u901a\u8fc7\u5c06\u7ecf\u8fc7\u9a8c\u8bc1\u7684Verilog\u4ee3\u7801\u8f6c\u6362\u4e3aC/C++\uff0c\u751f\u6210\u4e86\u4e00\u4e2a\u5305\u542b16,700\u4e2aHLS\u4ee3\u7801\u7684\u6570\u636e\u96c6\uff1b\uff082\uff09\u91c7\u7528\u57fa\u4e8e\u6307\u4ee4\u63d0\u793a\u548c\u8bed\u6cd5\u6811\uff08AST\uff09\u5f15\u5bfc\u7684\u4ee3\u7801\u751f\u6210\u5fae\u8c03\u7b56\u7565\uff1b\uff083\uff09\u5f00\u53d1\u4e86\u57fa\u4e8eVerilogEval\u7684\u534a\u81ea\u52a8\u8bc4\u6d4b\u6846\u67b6\uff0c\u8bc4\u4ef7\u751f\u6210HLS\u4ee3\u7801\u7684\u529f\u80fd\u6027\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\uff0c\u5fae\u8c03\u4e8eQwenCoder (2.5) 7B\u6a21\u578b\u7684SAGE-HLS\u5728\u4ee3\u7801\u53ef\u7efc\u5408\u6027\u65b9\u9762\u6210\u529f\u7387\u63a5\u8fd1100%\uff0c\u529f\u80fd\u6b63\u786e\u7387\u8fbe75%\u3002", "conclusion": "SAGE-HLS\u4e3a\u9ad8\u5c42\u6b21\u7efc\u5408\u4ee3\u7801\u751f\u6210\u9886\u57df\u63d0\u4f9b\u4e86\u9996\u4e2a\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u4e0e\u4e13\u7528\u5927\u6a21\u578b\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u5408\u6210\u6027\u548c\u529f\u80fd\u6b63\u786e\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u4ee5\u5f80\u65b9\u6cd5\uff0c\u4e3a\u63a8\u5e7fLLMs\u5728EDA\u81ea\u52a8\u5316\u4e2d\u7684\u5e94\u7528\u8fc8\u51fa\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2508.02774", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.02774", "abs": "https://arxiv.org/abs/2508.02774", "authors": ["Zoran Majkic"], "title": "Intensional FOL over Belnap's Billatice for Strong-AI Robotics", "comment": "28 pages", "summary": "AGI (Strong AI) aims to create intelligent robots that are quasi\nindistinguishable from the human mind. Like a child, the AGI robot would have\nto learn through input and experiences, constantly progressing and advancing\nits abilities over time. The AGI robot would require an intelligence more close\nto human's intelligence: it would have a self-aware consciousness that has the\nability to solve problems, learn, and plan. Based on this approach an\nIntensional many-sorted First-order Logic (IFOL), as an extension of a standard\nFOL with Tarskian's semantics, is proposed in order to avoid the problems of\nstandard 2-valued FOL with paradoxes (inconsistent formulae) and a necessity\nfor robots to work with incomplete (unknown) knowledge as well. This is a more\nsophisticated version of IFOL with the same syntax but different semantics,\nable to deal with truth-ordering and knowledge-ordering as well, based on the\nwell known Belnap's billatice with four truth-values that extend the set of\nclassical two truth-values.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u56db\u503c\u903b\u8f91\u6269\u5c55\u7684\u591a\u7c7b\u578b\u4e00\u9636\u903b\u8f91\uff0c\u7528\u4ee5\u652f\u6301AGI\u7cfb\u7edf\u5e94\u5bf9\u4e0d\u5b8c\u5168\u548c\u77db\u76fe\u4fe1\u606f\uff0c\u63d0\u5347\u5176\u7c7b\u4eba\u667a\u80fd\u6c34\u5e73\u3002", "motivation": "\u4e3a\u5b9e\u73b0\u7c7b\u4eba\u667a\u80fd\u7684AGI\uff08\u5f3a\u4eba\u5de5\u667a\u80fd\uff09\u673a\u5668\uff0c\u9700\u514b\u670d\u4f20\u7edf\u4e00\u9636\u903b\u8f91\u5728\u5904\u7406\u4e0d\u5b8c\u5168\u77e5\u8bc6\u548c\u77db\u76fe\u516c\u5f0f\u65f6\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTarskian\u8bed\u4e49\u7684\u591a\u7c7b\u578b\u610f\u5411\u6027\u4e00\u9636\u903b\u8f91\uff08IFOL\uff09\u6269\u5c55\u7248\u672c\uff0c\u8bed\u6cd5\u672a\u53d8\u4f46\u5f15\u5165\u4e86Belnap\u56db\u503c\u53cc\u683c\uff0c\u5904\u7406\u771f\u503c\u4e0e\u77e5\u8bc6\u6392\u5e8f\u95ee\u9898\u3002", "result": "\u8be5\u65b9\u6cd5\u53ef\u907f\u514d\u4f20\u7edf\u4e8c\u503cFOL\u7684\u6096\u8bba\u548c\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u591f\u5904\u7406\u4e0d\u5b8c\u5168\u548c\u77db\u76fe\u77e5\u8bc6\u3002", "conclusion": "\u6269\u5c55\u540e\u7684IFOL\u66f4\u8d34\u5408\u7c7b\u4eba\u667a\u80fd\u9700\u6c42\uff0c\u8ba9AGI\u673a\u5668\u4eba\u80fd\u50cf\u4eba\u7c7b\u4e00\u6837\u5904\u7406\u590d\u6742\u7684\u77e5\u8bc6\u4e0e\u7ecf\u9a8c\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u66f4\u5f3a\u7684\u667a\u80fd\u7cfb\u7edf\u3002"}}
{"id": "2508.02853", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.02853", "abs": "https://arxiv.org/abs/2508.02853", "authors": ["Yinuo Xu", "Veronica Derricks", "Allison Earl", "David Jurgens"], "title": "Modeling Annotator Disagreement with Demographic-Aware Experts and Synthetic Perspectives", "comment": "28 pages, 17 figures", "summary": "We present an approach to modeling annotator disagreement in subjective NLP\ntasks through both architectural and data-centric innovations. Our model,\nDEM-MoE (Demographic-Aware Mixture of Experts), routes inputs to expert\nsubnetworks based on annotator demographics, enabling it to better represent\nstructured, group-level variation compared to prior models. DEM-MoE\nconsistently performs competitively across demographic groups, and shows\nespecially strong results on datasets with high annotator disagreement. To\naddress sparse demographic coverage, we test whether LLM-generated synthetic\nannotations via zero-shot persona prompting can be used for data imputation. We\nshow these synthetic judgments align moderately well with human annotations on\nour data and offer a scalable way to potentially enrich training data. We then\npropose and evaluate approaches for blending real and synthetic data using\nstrategies tailored to dataset structure. We find that the optimal strategies\ndepend on dataset structure. Together, these contributions improve the\nrepresentation of diverse perspectives.", "AI": {"tldr": "DEM-MoE\u6a21\u578b\u7ed3\u5408\u6807\u6ce8\u8005\u4eba\u53e3\u4fe1\u606f\u4e0e\u5408\u6210\u6570\u636e\uff0c\u6539\u5584\u4e86\u4e3b\u89c2NLP\u4efb\u52a1\u4e2d\u7fa4\u4f53\u5206\u6b67\u7684\u5efa\u6a21\u6548\u679c\uff0c\u4f18\u5316\u4e86\u591a\u6837\u6027\u8868\u8fbe\uff0c\u5e76\u53ef\u5229\u7528LLM\u751f\u6210\u7684\u5408\u6210\u6807\u6ce8\u6269\u5c55\u6570\u636e\u96c6\uff0c\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u4e3b\u89c2NLP\u4efb\u52a1\u4e2d\u4e0d\u540c\u6807\u6ce8\u8005\u95f4\u5b58\u5728\u5206\u6b67\uff0c\u4e14\u5982\u4f55\u6709\u6548\u5efa\u6a21\u548c\u5229\u7528\u8fd9\u79cd\u5206\u6b67\uff08\u5c24\u5176\u662f\u4e0e\u6807\u6ce8\u8005\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u76f8\u5173\u7684\u5206\u6b67\uff09\u672a\u88ab\u5145\u5206\u89e3\u51b3\uff0c\u540c\u65f6\u5728\u6570\u636e\u4eba\u53e3\u8986\u76d6\u9762\u4e0d\u8db3\u7684\u60c5\u51b5\u4e0b\uff0c\u5408\u6210\u6807\u6ce8\u6570\u636e\u662f\u5426\u6709\u6548\u4e5f\u6709\u5f85\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578bDEM-MoE\uff08Demographic-Aware Mixture of Experts\uff09\uff0c\u5b83\u6839\u636e\u6807\u6ce8\u8005\u7684\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u5c06\u8f93\u5165\u5206\u914d\u7ed9\u4e0d\u540c\u4e13\u5bb6\u5b50\u7f51\u7edc\u4ee5\u66f4\u597d\u5730\u5efa\u6a21\u7fa4\u4f53\u95f4\u7ed3\u6784\u5316\u5dee\u5f02\u3002\u540c\u65f6\uff0c\u5f15\u5165\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u96f6\u6837\u672c\u89d2\u8272\u6a21\u62df\u751f\u6210\u5408\u6210\u6807\u6ce8\uff0c\u7528\u4ee5\u6570\u636e\u8865\u5168\uff0c\u5e76\u8bbe\u8ba1\u548c\u8bc4\u4f30\u4e86\u591a\u79cd\u6df7\u5408\u771f\u5b9e\u4e0e\u5408\u6210\u6570\u636e\u7684\u7b56\u7565\u3002", "result": "DEM-MoE\u6a21\u578b\u5728\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u7fa4\u4f53\u4e0a\u7684\u8868\u73b0\u5747\u5f88\u6709\u7ade\u4e89\u529b\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u6807\u6ce8\u8005\u5206\u6b67\u7a0b\u5ea6\u9ad8\u7684\u6570\u636e\u96c6\u3002\u5408\u6210\u6807\u6ce8\u4e0e\u4eba\u5de5\u6807\u6ce8\u6709\u4e2d\u7b49\u7a0b\u5ea6\u7684\u4e00\u81f4\u6027\uff0c\u53ef\u6709\u6548\u6269\u5c55\u8bad\u7ec3\u6570\u636e\u3002\u6700\u4f73\u6df7\u5408\u7b56\u7565\u4f9d\u8d56\u4e8e\u5177\u4f53\u6570\u636e\u7ed3\u6784\u3002\u6574\u4f53\u63d0\u5347\u4e86\u591a\u5143\u89c2\u70b9\u7684\u8868\u8fbe\u80fd\u529b\u3002", "conclusion": "DEM-MoE\u53ca\u76f8\u5173\u6570\u636e\u6df7\u5408\u7b56\u7565\u80fd\u591f\u66f4\u597d\u5730\u4ee3\u8868\u548c\u5efa\u6a21\u4e3b\u89c2\u4efb\u52a1\u4e2d\u4e0d\u540c\u7fa4\u4f53\u7684\u591a\u6837\u5316\u89c2\u70b9\uff0c\u5e76\u80fd\u5728\u6570\u636e\u6709\u9650\u65f6\u901a\u8fc7\u5408\u6210\u6570\u636e\u6269\u5145\u548c\u4f18\u5316\u8bad\u7ec3\u6548\u679c\u3002"}}
{"id": "2508.02729", "categories": ["cs.SE", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2508.02729", "abs": "https://arxiv.org/abs/2508.02729", "authors": ["Zhuoran Liu"], "title": "Interpreting Performance Profiles with Deep Learning", "comment": "Master of Science in Computer Science thesis, North Carolina State\n  University, 2022. Advisor: Dr. Xu Liu", "summary": "Profiling tools (also known as profilers) play an important role in\nunderstanding program performance at runtime, such as hotspots, bottlenecks,\nand inefficiencies. While profilers have been proven to be useful, they give\nextra burden to software engineers. Software engineers, as the users, are\nresponsible to interpret the complex performance data and identify actionable\noptimization in program source code. However, it can be challenging for users\nto associate inefficiencies with the program semantics, especially if the users\nare not the authors of the code, which limits the applicability of profilers.\n  In this thesis, we explore a new direction to combine performance profiles\nand program semantics with a deep learning approach. The key idea is to glean\ncode summary for semantic information (at a certain level) and integrate it\ninto a profiler, which can better understand program inefficiencies for\nactionable optimization. To be concrete, we combine profiles generated by Async\nProfiler (the state-of-the-art Java profiler) with code summarization from a\nfine-tuned CodeBERT-based model. We demonstrate the code summaries of any\nselected call path in a graphic user interface. Our system can effectively\nassist analysis on many Java benchmarks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u4ee3\u7801\u6458\u8981\u4e0e\u6027\u80fd\u5206\u6790\u7ed3\u5408\uff0c\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578bCodeBERT\u751f\u6210\u8bed\u4e49\u4fe1\u606f\uff0c\u5e76\u5728\u6027\u80fd\u5206\u6790\u5de5\u5177\u4e2d\u8fdb\u884c\u96c6\u6210\u4ea4\u4e92\uff0c\u63d0\u5347\u4e86\u7a0b\u5e8f\u6027\u80fd\u74f6\u9888\u7684\u5b9a\u4f4d\u548c\u4f18\u5316\u80fd\u529b\u3002\u7cfb\u7edf\u5bf9\u591a\u4e2aJava\u57fa\u51c6\u6d4b\u8bd5\u5206\u6790\u6548\u679c\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u7684\u6027\u80fd\u5206\u6790\u5de5\u5177\uff08profilers\uff09\u867d\u7136\u53ef\u4ee5\u6709\u6548\u5e2e\u52a9\u7406\u89e3\u7a0b\u5e8f\u8fd0\u884c\u65f6\u7684\u6027\u80fd\u95ee\u9898\uff0c\u4f46\u8981\u6c42\u7528\u6237\u81ea\u884c\u89e3\u8bfb\u590d\u6742\u7684\u6570\u636e\u5e76\u5c06\u95ee\u9898\u4e0e\u6e90\u4ee3\u7801\u4e2d\u7684\u5177\u4f53\u4f4d\u7f6e\u548c\u542b\u4e49\u76f8\u8054\u7cfb\u3002\u5bf9\u4e8e\u4e0d\u662f\u4ee3\u7801\u4f5c\u8005\u7684\u7528\u6237\uff0c\u8fd9\u4e00\u70b9\u5c24\u5176\u56f0\u96be\uff0c\u4ece\u800c\u9650\u5236\u4e86\u5206\u6790\u5de5\u5177\u7684\u5b9e\u9645\u5e94\u7528\u6548\u80fd\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u5c06\u6027\u80fd\u5206\u6790\uff08profiling\uff09\u4e0e\u6df1\u5ea6\u5b66\u4e60\u9a71\u52a8\u7684\u4ee3\u7801\u8bed\u4e49\u5206\u6790\u76f8\u7ed3\u5408\u3002\u5177\u4f53\u65b9\u6cd5\u662f\u63d0\u53d6\u4ee3\u7801\u6458\u8981\uff0c\u4ee5\u83b7\u53d6\u4e00\u5b9a\u5c42\u6b21\u7684\u4ee3\u7801\u8bed\u4e49\u4fe1\u606f\uff0c\u5e76\u4e0e\u57fa\u4e8eAsync Profiler\u751f\u6210\u7684\u6027\u80fd\u5206\u6790\u7ed3\u679c\u7ed3\u5408\u3002\u5229\u7528\u5fae\u8c03\u540e\u7684CodeBERT\u6a21\u578b\u5bf9\u4ee3\u7801\u8fdb\u884c\u6458\u8981\uff0c\u901a\u8fc7\u56fe\u5f62\u754c\u9762\u4e3a\u7528\u6237\u5c55\u793a\u4efb\u610f\u8c03\u7528\u8def\u5f84\u7684\u4ee3\u7801\u6458\u8981\u4fe1\u606f\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u5c06\u6027\u80fd\u5206\u6790\u7ed3\u679c\u4e0e\u4ee3\u7801\u6458\u8981\u7ed3\u5408\uff0c\u5e76\u5728\u56fe\u5f62\u7528\u6237\u754c\u9762\u4e2d\u53ef\u89c6\u5316\u5c55\u793a\uff0c\u8f85\u52a9\u7528\u6237\u66f4\u9ad8\u6548\u5730\u7406\u89e3\u548c\u5b9a\u4f4d\u7a0b\u5e8f\u4e2d\u7684\u6027\u80fd\u74f6\u9888\uff0c\u5728\u591a\u4e2aJava\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6709\u6548\u8f85\u52a9\u5206\u6790\u4efb\u52a1\u3002", "conclusion": "\u7ed3\u5408\u4ee3\u7801\u8bed\u4e49\u6458\u8981\u4e0e\u4f20\u7edf\u6027\u80fd\u5206\u6790\u7ed3\u679c\u7684\u65b0\u578b\u5206\u6790\u5de5\u5177\uff0c\u80fd\u5e2e\u52a9\u7528\u6237\u66f4\u597d\u5730\u7406\u89e3\u7a0b\u5e8f\u6027\u80fd\u95ee\u9898\uff0c\u4e3a\u6e90\u4ee3\u7801\u4f18\u5316\u5e26\u6765\u66f4\u76f4\u63a5\u548c\u4fbf\u6377\u7684\u652f\u6301\uff0c\u63d0\u5347\u5206\u6790\u5de5\u5177\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2508.03640", "categories": ["cs.PL", "D.3.2;D.3.4;K.3.1"], "pdf": "https://arxiv.org/pdf/2508.03640", "abs": "https://arxiv.org/abs/2508.03640", "authors": ["Pedro Vasconcelos"], "title": "Teaching Introductory Functional Programming Using Haskelite", "comment": "In Proceedings TFPiE 2025, arXiv:2508.02305", "summary": "Learning functional programming requires learning a substitution-based\ncomputational model. While substitution should be a familiar concept from\nhigh-school algebra, students often have difficulty applying it to new\nsettings, such as recursive definitions, algebraic data types and higher-order\nfunctions. Step-by-step interpreters have been shown to help beginners by\nclarifying misconceptions and improving understanding.\n  This paper reports on the experience of using a step-by-step tracing\ninterpreter for a subset of Haskell while teaching an introductory functional\nprogramming course at the University of Porto. We describe the use of the\ninterpreter, present some feedback obtained from students, reflect on the\nlessons learned and point directions for further work.", "AI": {"tldr": "\u4f7f\u7528\u9010\u6b65\u8ffd\u8e2a\u89e3\u91ca\u5668\u6709\u52a9\u4e8e\u65b0\u624b\u5b66\u751f\u7406\u89e3\u51fd\u6570\u5f0f\u7f16\u7a0b\u4e2d\u7684\u66ff\u6362\u6a21\u578b\uff0c\u5e76\u6f84\u6e05\u4ed6\u4eec\u7684\u8bef\u533a\u3002", "motivation": "\u5b66\u751f\u867d\u5728\u4e2d\u5b66\u9636\u6bb5\u63a5\u89e6\u8fc7\u66ff\u6362\u6982\u5ff5\uff0c\u4f46\u5728\u51fd\u6570\u5f0f\u7f16\u7a0b\u4e2d\u9762\u4e34\u9012\u5f52\u3001\u4ee3\u6570\u6570\u636e\u7c7b\u578b\u548c\u9ad8\u9636\u51fd\u6570\u7b49\u65b0\u573a\u666f\u65f6\u5e38\u611f\u8ff7\u60d1\u3002\u4e3a\u5e2e\u52a9\u5b66\u751f\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u4e9b\u6982\u5ff5\uff0c\u4f5c\u8005\u5c1d\u8bd5\u91c7\u7528\u9010\u6b65\u8ffd\u8e2a\u89e3\u91ca\u5668\u3002", "method": "\u5728\u8bfe\u7a0b\u6559\u5b66\u4e2d\u5f15\u5165\u9002\u7528\u4e8eHaskell\u5b50\u96c6\u7684\u9010\u6b65\u8ffd\u8e2a\u89e3\u91ca\u5668\uff0c\u5b9e\u9645\u8fd0\u7528\u540e\u6536\u96c6\u5b66\u751f\u53cd\u9988\u5e76\u5bf9\u6559\u5b66\u6548\u679c\u548c\u4f53\u9a8c\u8fdb\u884c\u603b\u7ed3\u5206\u6790\u3002", "result": "\u672c\u6587\u5c55\u793a\u4e86\u5728\u6ce2\u5c14\u56fe\u5927\u5b66\u7684\u521d\u7ea7\u51fd\u6570\u5f0f\u7f16\u7a0b\u8bfe\u7a0b\u4e2d\uff0c\u5982\u4f55\u5229\u7528\u9010\u6b65\u8ffd\u8e2a\u89e3\u91ca\u5668\u5e2e\u52a9\u5b66\u751f\u7406\u89e3\u57fa\u4e8e\u66ff\u6362\u7684\u8ba1\u7b97\u6a21\u578b\u3002\u4f5c\u8005\u4ecb\u7ecd\u4e86\u89e3\u91ca\u5668\u7684\u4f7f\u7528\u65b9\u6cd5\uff0c\u6536\u96c6\u4e86\u5b66\u751f\u53cd\u9988\uff0c\u5e76\u5bf9\u6559\u5b66\u8fc7\u7a0b\u4e2d\u7684\u6536\u83b7\u548c\u672a\u6765\u6539\u8fdb\u65b9\u5411\u8fdb\u884c\u4e86\u53cd\u601d\u3002", "conclusion": "\u9010\u6b65\u8ffd\u8e2a\u89e3\u91ca\u5668\u5bf9\u5165\u95e8\u5b66\u751f\u7406\u89e3\u590d\u6742\u7684\u51fd\u6570\u5f0f\u7f16\u7a0b\u6982\u5ff5\u975e\u5e38\u6709\u5e2e\u52a9\uff0c\u5b66\u751f\u53cd\u9988\u79ef\u6781\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u5b8c\u5584\u8be5\u5de5\u5177\u5e76\u63a2\u7d22\u5176\u5728\u5176\u4ed6\u7f16\u7a0b\u6559\u5b66\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2508.03574", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.03574", "abs": "https://arxiv.org/abs/2508.03574", "authors": ["Michael Benedikt", "Chia-Hsuan Lu", "Tony Tan"], "title": "Analysis of logics with arithmetic", "comment": null, "summary": "We present new results on finite satisfiability of logics with counting and\narithmetic. This includes tight bounds on the complexity for two-variable logic\nwith counting and cardinality comparisons between unary formulas, and also on\nlogics with so-called local Presburger quantifiers. In the process, we provide\nsimpler proofs of some key prior results on finite satisfiability and\nsemi-linearity of the spectrum for these logics.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5e26\u8ba1\u6570\u548c\u7b97\u672f\u7684\u903b\u8f91\u7cfb\u7edf\u7684\u6709\u9650\u53ef\u6ee1\u8db3\u6027\uff0c\u83b7\u5f97\u4e86\u590d\u6742\u6027\u7684\u6700\u4f18\u754c\u548c\u66f4\u7b80\u6d01\u7684\u8bc1\u660e\u65b9\u6cd5\u3002", "motivation": "\u6709\u9650\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u5728\u903b\u8f91\u548c\u7406\u8bba\u8ba1\u7b97\u673a\u79d1\u5b66\u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u5c24\u5176\u662f\u5728\u5e26\u8ba1\u6570\u548c\u7b97\u672f\u7684\u903b\u8f91\u7cfb\u7edf\u4e2d\uff0c\u590d\u6742\u6027\u548c\u53ef\u5224\u5b9a\u6027\u5206\u6790\u4e00\u76f4\u662f\u6311\u6218\u3002\u672c\u8bba\u6587\u65e8\u5728\u63a8\u52a8\u8fd9\u65b9\u9762\u7684\u7406\u89e3\u3002", "method": "\u5bf9\u5e26\u6709\u8ba1\u6570\u548c\u7b97\u672f\u7684\u4e24\u53d8\u91cf\u903b\u8f91\u3001\u5305\u542b\u5bf9\u4e00\u5143\u516c\u5f0f\u57fa\u6570\u6bd4\u8f83\u7684\u903b\u8f91\u4ee5\u53ca\u542b\u5c40\u90e8Presburger\u91cf\u8bcd\u7684\u903b\u8f91\uff0c\u7814\u7a76\u5176\u6709\u9650\u53ef\u6ee1\u8db3\u6027\uff1b\u540c\u65f6\u7ed9\u51fa\u5bf9\u5173\u952e\u5148\u524d\u7ed3\u679c\uff08\u5982\u6709\u9650\u53ef\u6ee1\u8db3\u6027\u548c\u8c31\u7684\u534a\u7ebf\u6027\uff09\u7684\u66f4\u7b80\u6d01\u8bc1\u660e\u3002", "result": "\u5f97\u5230\u4e86\u5e26\u8ba1\u6570\u548c\u57fa\u6570\u6bd4\u8f83\u7684\u4e24\u53d8\u91cf\u903b\u8f91\u4ee5\u53ca\u542b\u5c40\u90e8Presburger\u91cf\u8bcd\u7684\u903b\u8f91\u6709\u9650\u53ef\u6ee1\u8db3\u6027\u7684\u590d\u6742\u6027\u7d27\u81f4\u754c\uff0c\u540c\u65f6\u4e3a\u76f8\u5173\u903b\u8f91\u7684\u6709\u9650\u53ef\u6ee1\u8db3\u6027\u548c\u8c31\u7684\u534a\u7ebf\u6027\u63d0\u4f9b\u4e86\u66f4\u4e3a\u7b80\u660e\u7684\u8bc1\u660e\u3002", "conclusion": "\u672c\u8bba\u6587\u4e0d\u4ec5\u6539\u8fdb\u5e76\u7cbe\u7b80\u4e86\u73b0\u6709\u5173\u952e\u7ed3\u679c\u7684\u8bc1\u660e\u65b9\u6cd5\uff0c\u8fd8\u5728\u5305\u542b\u8ba1\u6570\u548c\u7b97\u672f\u7684\u903b\u8f91\u7cfb\u7edf\u6709\u9650\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u4e0a\u5f97\u51fa\u4e86\u590d\u6742\u6027\u7684\u7d27\u81f4\u754c\uff0c\u5bf9\u7406\u8bba\u8ba1\u7b97\u673a\u79d1\u5b66\u9886\u57df\u76f8\u5173\u7814\u7a76\u5177\u6709\u91cd\u8981\u63a8\u52a8\u4f5c\u7528\u3002"}}
{"id": "2508.02872", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.02872", "abs": "https://arxiv.org/abs/2508.02872", "authors": ["Giovanni Cherubin", "Andrew Paverd"], "title": "Highlight & Summarize: RAG without the jailbreaks", "comment": null, "summary": "Preventing jailbreaking and model hijacking of Large Language Models (LLMs)\nis an important yet challenging task. For example, when interacting with a\nchatbot, malicious users can input specially crafted prompts to cause the LLM\nto generate undesirable content or perform a completely different task from its\nintended purpose. Existing mitigations for such attacks typically rely on\nhardening the LLM's system prompt or using a content classifier trained to\ndetect undesirable content or off-topic conversations. However, these\nprobabilistic approaches are relatively easy to bypass due to the very large\nspace of possible inputs and undesirable outputs. In this paper, we present and\nevaluate Highlight & Summarize (H&S), a new design pattern for\nretrieval-augmented generation (RAG) systems that prevents these attacks by\ndesign. The core idea is to perform the same task as a standard RAG pipeline\n(i.e., to provide natural language answers to questions, based on relevant\nsources) without ever revealing the user's question to the generative LLM. This\nis achieved by splitting the pipeline into two components: a highlighter, which\ntakes the user's question and extracts relevant passages (\"highlights\") from\nthe retrieved documents, and a summarizer, which takes the highlighted passages\nand summarizes them into a cohesive answer. We describe several possible\ninstantiations of H&S and evaluate their generated responses in terms of\ncorrectness, relevance, and response quality. Surprisingly, when using an\nLLM-based highlighter, the majority of H&S responses are judged to be better\nthan those of a standard RAG pipeline.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9632\u6b62LLM\u8d8a\u72f1\u548c\u6a21\u578b\u52ab\u6301\u7684\u65b0\u8bbe\u8ba1\uff1aHighlight & Summarize\uff08H&S\uff09\uff0c\u901a\u8fc7\u5728\u4e0d\u66b4\u9732\u7528\u6237\u95ee\u9898\u7684\u60c5\u51b5\u4e0b\u751f\u6210\u7b54\u6848\uff0c\u6709\u6548\u63d0\u5347\u5b89\u5168\u6027\u548c\u54cd\u5e94\u8d28\u91cf\uff0c\u4e14\u5b9e\u9645\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6848\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5bb9\u6613\u53d7\u5230\u8d8a\u72f1\uff08jailbreaking\uff09\u548c\u6a21\u578b\u52ab\u6301\uff08model hijacking\uff09\u653b\u51fb\u3002\u6076\u610f\u7528\u6237\u53ef\u4ee5\u901a\u8fc7\u7279\u6b8a\u8bbe\u8ba1\u7684\u95ee\u9898\u4f7fLLM\u751f\u6210\u4e0d\u826f\u5185\u5bb9\u6216\u6267\u884c\u4e0e\u521d\u8877\u4e0d\u7b26\u7684\u4efb\u52a1\u3002\u73b0\u6709\u9632\u62a4\u65b9\u6cd5\u5f80\u5f80\u901a\u8fc7\u52a0\u56fa\u7cfb\u7edf\u63d0\u793a\u8bcd\u6216\u4f7f\u7528\u5185\u5bb9\u5206\u7c7b\u5668\u6765\u68c0\u6d4b\u4e0d\u826f\u5185\u5bb9\uff0c\u4f46\u8fd9\u4e9b\u6982\u7387\u6027\u65b9\u6cd5\u5bb9\u6613\u88ab\u89c4\u907f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u7684\u8bbe\u8ba1\u6a21\u5f0f\u2014\u2014Highlight & Summarize\uff08H&S\uff09\u3002\u5176\u6838\u5fc3\u601d\u60f3\u662f\u5728\u751f\u6210\u56de\u7b54\u65f6\uff0c\u4ece\u6574\u4e2a\u6d41\u7a0b\u4e2d\u9690\u85cf\u7528\u6237\u7684\u95ee\u9898\uff0c\u5373\u901a\u8fc7\u4e24\u6b65\u5b9e\u73b0\uff1a\uff081\uff09\u9ad8\u4eae\u5668\uff0c\u57fa\u4e8e\u7528\u6237\u63d0\u95ee\u4ece\u6587\u6863\u4e2d\u63d0\u53d6\u76f8\u5173\u91cd\u8981\u7247\u6bb5\uff1b\uff082\uff09\u6458\u8981\u5668\uff0c\u5bf9\u8fd9\u4e9b\u9ad8\u4eae\u7247\u6bb5\u751f\u6210\u603b\u7ed3\u6027\u56de\u7b54\u3002\u603b\u7ed3\u5668\u770b\u4e0d\u5230\u7528\u6237\u539f\u59cb\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u5bf9\u6bd4\u4e86H&S\u548c\u6807\u51c6RAG\u6d41\u7a0b\u7684\u8f93\u51fa\uff0c\u4ece\u6b63\u786e\u6027\u3001\u76f8\u5173\u6027\u548c\u7b54\u590d\u8d28\u91cf\u4e09\u4e2a\u65b9\u9762\u8bc4\u4f30\u3002\u7ed3\u679c\u663e\u793a\uff0c\u91c7\u7528\u57fa\u4e8eLLM\u7684\u9ad8\u4eae\u5668\u540e\uff0c\u5927\u591a\u6570H&S\u7684\u56de\u7b54\u88ab\u8bc4\u5224\u4e3a\u4f18\u4e8e\u4f20\u7edfRAG\u3002", "conclusion": "H&S\u6a21\u5f0f\u5728\u9884\u9632LLM\u8d8a\u72f1\u548c\u6a21\u578b\u52ab\u6301\u653b\u51fb\u65b9\u9762\u5929\u7136\u5177\u5907\u4f18\u52bf\u3002\u5728\u4e0d\u663e\u5f0f\u66b4\u9732\u7528\u6237\u95ee\u9898\u7ed9\u751f\u6210\u6a21\u578b\u7684\u524d\u63d0\u4e0b\uff0c\u4ecd\u80fd\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u81ea\u7136\u8bed\u8a00\u56de\u7b54\uff0c\u5e76\u5728\u591a\u9879\u8bc4\u6d4b\u4e0a\u8d85\u8d8a\u6807\u51c6RAG\u6d41\u7a0b\u3002"}}
{"id": "2508.02732", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02732", "abs": "https://arxiv.org/abs/2508.02732", "authors": ["Sherman Wong", "Jalaj Bhandari", "Leo Zhou Fan Yang", "Xylan Xu", "Yi Zhuang", "Cem Cayiroglu", "Payal Bhuptani", "Sheela Yadawad", "Hung Duong"], "title": "A Note on Code Quality Score: LLMs for Maintainable Large Codebases", "comment": "24 pages, ICLR format", "summary": "Maintaining code quality in large-scale software systems presents significant\nchallenges, particularly in settings where a large numbers of engineers work\nconcurrently on a codebase. This paper introduces Code Quality Score (CQS)\nsystem to automatically detect issues with a set of code changes and provide\nactionable insights. At its core, the CQS system is powered by two Llama3\nmodels, fine-tuned (with SFT and offline RL approaches), to a) detect common\ncode quality issues related to coding best practices and b) to provide good\n``critiques'' for LLM-generated code review respectively. To maintain good user\nexperience, we layer the system with hand-crafted rules to filter out incorrect\nresponses/hallucinations. Offline evaluations show that our CQS system is able\nto achieve an impressive precision rate for identifying valid issues. This\nsystem has already been rolled out to developers in an industrial scale setting\nand has consistently achieved 60\\% week over week user helpfulness rate,\ndemonstrating its effectiveness in a real-world environment. In this paper, we\npresent details of the CQS system along with some learnings on curating\ndeveloper feedback to create training data for LLM fine-tuning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u5957\u57fa\u4e8eLlama3\u5fae\u8c03\u5927\u6a21\u578b\u548c\u89c4\u5219\u8fc7\u6ee4\u7684\u81ea\u52a8\u5316\u4ee3\u7801\u8d28\u91cf\u68c0\u6d4b\u548c\u5efa\u8bae\u7cfb\u7edf\uff0c\u5df2\u5728\u5de5\u4e1a\u7ea7\u73af\u5883\u4e2d\u90e8\u7f72\u5e76\u5b9e\u73b0\u8f83\u9ad8\u6709\u6548\u7387\uff0c\u5bf9\u5927\u89c4\u6a21\u8f6f\u4ef6\u5f00\u53d1\u7684\u4ee3\u7801\u8d28\u91cf\u7ba1\u63a7\u6709\u660e\u663e\u52a9\u76ca\u3002", "motivation": "\u5728\u5927\u578b\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\uff0c\u4f17\u591a\u5de5\u7a0b\u5e08\u534f\u4f5c\u5f00\u53d1\u65f6\uff0c\u7ef4\u62a4\u4ee3\u7801\u8d28\u91cf\u6781\u5177\u6311\u6218\u3002\u5f53\u524d\u7f3a\u4e4f\u81ea\u52a8\u5316\u3001\u667a\u80fd\u5316\u7684\u5de5\u5177\u6765\u6709\u6548\u53d1\u73b0\u4ee3\u7801\u95ee\u9898\u5e76\u5411\u5f00\u53d1\u8005\u63d0\u4f9b\u6709\u7528\u5efa\u8bae\u3002\u4e3a\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u81ea\u52a8\u68c0\u6d4b\u4ee3\u7801\u8d28\u91cf\u95ee\u9898\u5e76\u7ed9\u51fa\u53ef\u64cd\u4f5c\u610f\u89c1\u7684\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86Code Quality Score (CQS)\u7cfb\u7edf\uff0c\u57fa\u4e8e\u4e24\u79cd\u7ecf\u8fc7SFT\u548c\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u7684Llama3\u6a21\u578b\uff1a\u4e00\u662f\u81ea\u52a8\u68c0\u6d4b\u4ee3\u7801\u8d28\u91cf\u95ee\u9898\uff0c\u4e8c\u662f\u9488\u5bf9LLM\u751f\u6210\u7684\u4ee3\u7801\u8bc4\u5ba1\u7ed9\u51fa\u9ad8\u8d28\u91cf\u7684\u6279\u6ce8\u3002\u4e3a\u4fdd\u8bc1\u7528\u6237\u4f53\u9a8c\uff0c\u7cfb\u7edf\u8fd8\u52a0\u5165\u4e86\u624b\u5de5\u89c4\u5219\u8fc7\u6ee4\u9519\u8bef\u6216\u5e7b\u89c9\u5185\u5bb9\u3002\u6b64\u5916\uff0c\u8fd8\u4ecb\u7ecd\u4e86\u5982\u4f55\u5229\u7528\u5f00\u53d1\u8005\u53cd\u9988\u6570\u636e\u6765\u4f5c\u4e3aLLM\u5fae\u8c03\u7684\u8bad\u7ec3\u96c6\u3002", "result": "\u5728\u79bb\u7ebf\u8bc4\u6d4b\u4e2d\uff0cCQS\u7cfb\u7edf\u5728\u6709\u6548\u95ee\u9898\u8bc6\u522b\u4e0a\u8868\u73b0\u51fa\u5f88\u9ad8\u7684\u7cbe\u786e\u5ea6\u3002\u76ee\u524d\u8be5\u7cfb\u7edf\u5df2\u5728\u5de5\u4e1a\u7ea7\u5f00\u53d1\u73af\u5883\u4e2d\u90e8\u7f72\uff0c\u4e14\u6bcf\u5468\u7528\u6237\u6709\u7528\u7387\u6301\u7eed\u8fbe60%\uff0c\u663e\u793a\u51fa\u5728\u5b9e\u9645\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "CQS\u7cfb\u7edf\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u89c4\u5219\u7ec4\u5408\uff0c\u53ef\u6709\u6548\u652f\u6301\u5927\u89c4\u6a21\u5f00\u53d1\u4e2d\u7684\u4ee3\u7801\u8d28\u91cf\u7ba1\u63a7\uff0c\u65e2\u80fd\u53ca\u65f6\u53d1\u73b0\u95ee\u9898\uff0c\u4e5f\u80fd\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u5b9e\u7528\u53cd\u9988\uff0c\u63d0\u5347\u4e86\u6574\u4f53\u5f00\u53d1\u6548\u7387\uff0c\u5e76\u4e3a\u7c7b\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u4e86\u6570\u636e\u4e0e\u7ecf\u9a8c\u3002"}}
{"id": "2508.01263", "categories": ["cs.CL", "cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.01263", "abs": "https://arxiv.org/abs/2508.01263", "authors": ["Long S. T. Nguyen", "Khang H. N. Vo", "Thu H. A. Nguyen", "Tuan C. Bui", "Duc Q. Nguyen", "Thanh-Tung Tran", "Anh D. Nguyen", "Minh L. Nguyen", "Fabien Baldacci", "Thang H. Bui", "Emanuel Di Nardo", "Angelo Ciaramella", "Son H. Le", "Ihsan Ullah", "Lorenzo Di Rocco", "Tho T. Quan"], "title": "Bridging LLMs and Symbolic Reasoning in Educational QA Systems: Insights from the XAI Challenge at IJCNN 2025", "comment": "The XAI Challenge @ TRNS-AI Workshop, IJCNN 2025: Explainable AI for\n  Educational Question Answering. Website:\n  https://sites.google.com/view/trns-ai/challenge/", "summary": "The growing integration of Artificial Intelligence (AI) into education has\nintensified the need for transparency and interpretability. While hackathons\nhave long served as agile environments for rapid AI prototyping, few have\ndirectly addressed eXplainable AI (XAI) in real-world educational contexts.\nThis paper presents a comprehensive analysis of the XAI Challenge 2025, a\nhackathon-style competition jointly organized by Ho Chi Minh City University of\nTechnology (HCMUT) and the International Workshop on Trustworthiness and\nReliability in Neurosymbolic AI (TRNS-AI), held as part of the International\nJoint Conference on Neural Networks (IJCNN 2025). The challenge tasked\nparticipants with building Question-Answering (QA) systems capable of answering\nstudent queries about university policies while generating clear, logic-based\nnatural language explanations. To promote transparency and trustworthiness,\nsolutions were required to use lightweight Large Language Models (LLMs) or\nhybrid LLM-symbolic systems. A high-quality dataset was provided, constructed\nvia logic-based templates with Z3 validation and refined through expert student\nreview to ensure alignment with real-world academic scenarios. We describe the\nchallenge's motivation, structure, dataset construction, and evaluation\nprotocol. Situating the competition within the broader evolution of AI\nhackathons, we argue that it represents a novel effort to bridge LLMs and\nsymbolic reasoning in service of explainability. Our findings offer actionable\ninsights for future XAI-centered educational systems and competitive research\ninitiatives.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86XAI Challenge 2025\u53ef\u89e3\u91caAI\u9ed1\u5ba2\u677e\uff0c\u63a8\u52a8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u7b26\u53f7\u63a8\u7406\u7ed3\u5408\u7528\u4e8e\u6559\u80b2\u95ee\u7b54\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u4e3a\u672a\u6765XAI\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u5728\u6559\u80b2\u9886\u57df\u7684\u6e17\u900f\uff0c\u5bf9AI\u7cfb\u7edf\u7684\u900f\u660e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u4f46\u5b9e\u9645\u6559\u80b2\u573a\u666f\u4e2d\u9488\u5bf9\u53ef\u89e3\u91caAI\uff08XAI\uff09\u7684\u9ed1\u5ba2\u9a6c\u62c9\u677e\u8f83\u5c11\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7ade\u8d5b\u63a8\u52a8\u900f\u660e\u3001\u53ef\u4fe1\u548c\u53ef\u89e3\u91ca\u7684AI\u7cfb\u7edf\u5f00\u53d1\u3002", "method": "\u7ade\u8d5b\u8981\u6c42\u53c2\u8d5b\u961f\u4f0d\u6784\u5efa\u80fd\u751f\u6210\u6e05\u6670\u903b\u8f91\u89e3\u91ca\u7684\u9ad8\u6821\u95ee\u7b54\u7cfb\u7edf\uff0c\u91c7\u7528\u8f7b\u91cf\u7ea7LLMs\u6216LLM-\u7b26\u53f7\u6df7\u5408\u6a21\u578b\u3002\u6570\u636e\u96c6\u57fa\u4e8e\u903b\u8f91\u6a21\u677f\u6784\u5efa\u5e76\u7528Z3\u5de5\u5177\u6821\u9a8c\uff0c\u7ecf\u5b66\u751f\u4e13\u5bb6\u5ba1\u67e5\uff0c\u786e\u4fdd\u8d34\u5408\u771f\u5b9e\u73af\u5883\u3002\u901a\u8fc7\u660e\u786e\u8bc4\u6d4b\u6d41\u7a0b\uff0c\u5bf9\u6a21\u578b\u8f93\u51fa\u548c\u89e3\u91ca\u8d28\u91cf\u8fdb\u884c\u7efc\u5408\u8bc4\u4ef7\u3002", "result": "XAI Challenge 2025\u7ade\u8d5b\u53d6\u5f97\u4e86\u7528\u8f7b\u91cf\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\u53ca\u6df7\u5408\u795e\u7ecf-\u7b26\u53f7AI\u7cfb\u7edf\u642d\u5efa\u53ef\u89e3\u91ca\u7684\u95ee\u7b54\u7cfb\u7edf\u7684\u521d\u6b65\u6210\u679c\uff0c\u5e76\u5b8c\u5584\u4e86\u6570\u636e\u96c6\u4e0e\u8bc4\u6d4b\u4f53\u7cfb\u3002\u7814\u7a76\u4e3a\u672a\u6765XAI\u6559\u80b2\u7cfb\u7edf\u548c\u76f8\u5173\u7ade\u8d5b\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u7ecf\u9a8c\u548c\u89c1\u89e3\u3002", "conclusion": "\u901a\u8fc7\u7ec4\u7ec7\u4ee5\u6559\u80b2\u573a\u666f\u548cXAI\u4e3a\u6838\u5fc3\u7684\u7ade\u8d5b\uff0c\u6709\u6548\u4fc3\u8fdb\u4e86\u795e\u7ecf\u7f51\u7edc\u4e0e\u7b26\u53f7\u63a8\u7406\u7ed3\u5408\u7684\u7cfb\u7edf\u5f00\u53d1\uff0c\u4e3a\u63d0\u5347AI\u7cfb\u7edf\u7684\u900f\u660e\u5ea6\u3001\u53ef\u9a8c\u8bc1\u6027\u548c\u9ad8\u6821\u6559\u80b2\u4e2d\u7684\u5b9e\u7528\u6027\u505a\u51fa\u4e86\u63a2\u7d22\u6027\u8d21\u732e\u3002"}}
{"id": "2508.02885", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.02885", "abs": "https://arxiv.org/abs/2508.02885", "authors": ["Elliot Murphy", "Rohan Venkatesh", "Edward Khokhlovich", "Andrey Vyshedskiy"], "title": "Merge-based syntax is mediated by distinct neurocognitive mechanisms: A clustering analysis of comprehension abilities in 84,000 individuals with language deficits across nine languages", "comment": null, "summary": "In the modern language sciences, the core computational operation of syntax,\n'Merge', is defined as an operation that combines two linguistic units (e.g.,\n'brown', 'cat') to form a categorized structure ('brown cat', a Noun Phrase).\nThis can then be further combined with additional linguistic units based on\nthis categorial information, respecting non-associativity such that abstract\ngrouping is respected. Some linguists have embraced the view that Merge is an\nelementary, indivisible operation that emerged in a single evolutionary step.\nFrom a neurocognitive standpoint, different mental objects constructed by Merge\nmay be supported by distinct mechanisms: (1) simple command constructions\n(e.g., \"eat apples\"); (2) the merging of adjectives and nouns (\"red boat\"); and\n(3) the merging of nouns with spatial prepositions (\"laptop behind the sofa\").\nHere, we systematically investigate participants' comprehension of sentences\nwith increasing levels of syntactic complexity. Clustering analyses revealed\nbehavioral evidence for three distinct structural types, which we discuss as\npotentially emerging at different developmental stages and subject to selective\nimpairment. While a Merge-based syntax may still have emerged suddenly in\nevolutionary time, responsible for the structured symbolic turn our species\ntook, different cognitive mechanisms seem to underwrite the processing of\nvarious types of Merge-based objects.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u5206\u6790\u4e86\u4eba\u7c7b\u5bf9\u7531Merge\u64cd\u4f5c\u751f\u6210\u7684\u4e0d\u540c\u8bed\u6cd5\u590d\u6742\u5ea6\u53e5\u5b50\u7684\u7406\u89e3\uff0c\u53d1\u73b0\u4e09\u79cd\u7ed3\u6784\u7c7b\u578b\u80cc\u540e\u53ef\u80fd\u6709\u4e0d\u540c\u7684\u8ba4\u77e5\u673a\u5236\u652f\u6301\uff0c\u8bf4\u660e\u4eba\u7c7b\u8bed\u6cd5\u5904\u7406\u5e76\u975e\u5b8c\u5168\u4f9d\u8d56\u5355\u4e00\u7a81\u73b0\u7684Merge\u673a\u5236\uff0c\u800c\u662f\u5728\u795e\u7ecf\u8ba4\u77e5\u4e0a\u5b58\u5728\u529f\u80fd\u5206\u5316\u3002", "motivation": "\u63a2\u7d22\u53e5\u6cd5\u6838\u5fc3\u64cd\u4f5cMerge\u5728\u8ba4\u77e5\u795e\u7ecf\u5c42\u9762\u7684\u57fa\u7840\uff0c\u5bf9\u4e0d\u540c\u7ed3\u6784\u7c7b\u578b\u7684\u7406\u89e3\u662f\u5426\u7531\u7edf\u4e00\u6216\u5206\u79bb\u7684\u673a\u5236\u652f\u6301\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u673a\u5236\u7684\u53d1\u5c55\u548c\u635f\u4f24\u654f\u611f\u6027\u3002", "method": "\u7cfb\u7edf\u6027\u5730\u8c03\u67e5\u53c2\u4e0e\u8005\u5bf9\u5305\u542b\u4e0d\u540c\u53e5\u6cd5\u590d\u6742\u5ea6\u7684\u53e5\u5b50\u7684\u7406\u89e3\u80fd\u529b\uff0c\u901a\u8fc7\u805a\u7c7b\u5206\u6790\u8bc6\u522b\u4e0d\u540c\u7684\u884c\u4e3a\u8868\u73b0\u7ed3\u6784\u7c7b\u578b\u3002", "result": "\u805a\u7c7b\u5206\u6790\u63ed\u793a\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u7ed3\u6784\u7c7b\u578b\uff0c\u5206\u522b\u5bf9\u5e94\u4e8e\u7b80\u5355\u547d\u4ee4\u53e5\u3001\u5f62\u5bb9\u8bcd\u4e0e\u540d\u8bcd\u7ed3\u5408\u3001\u540d\u8bcd\u4e0e\u7a7a\u95f4\u4ecb\u8bcd\u7ed3\u5408\uff0c\u8fd9\u4e9b\u7c7b\u578b\u53ef\u80fd\u5728\u53d1\u80b2\u9636\u6bb5\u4e0a\u6709\u6240\u5dee\u5f02\u5e76\u53d7\u9009\u62e9\u6027\u635f\u4f24\u5f71\u54cd\u3002", "conclusion": "\u5c3d\u7ba1\u57fa\u4e8eMerge\u7684\u53e5\u6cd5\u7ed3\u6784\u53ef\u80fd\u5728\u8fdb\u5316\u4e2d\u7a81\u73b0\uff0c\u4f46\u4e0d\u540c\u7c7b\u578b\u7684Merge\u57fa\u4f53\u5b9e\u9645\u7531\u4e0d\u540c\u7684\u8ba4\u77e5\u673a\u5236\u652f\u6301\uff0c\u5e76\u53ef\u80fd\u5728\u53d1\u5c55\u9636\u6bb5\u4e0a\u6709\u4e0d\u540c\u7684\u8868\u73b0\u53ca\u6613\u635f\u6027\u3002"}}
{"id": "2508.02733", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.02733", "abs": "https://arxiv.org/abs/2508.02733", "authors": ["Rijul Jain", "Shraddha Barke", "Gabriel Ebner", "Md Rakib Hossain Misu", "Shan Lu", "Sarah Fakhoury"], "title": "What's in a Proof? Analyzing Expert Proof-Writing Processes in F* and Verus", "comment": null, "summary": "Proof-oriented programming languages (POPLs) empower developers to write code\nalongside formal correctness proofs, providing formal guarantees that the code\nadheres to specified requirements. Despite their powerful capabilities, POPLs\npresent a steep learning curve and have not yet been adopted by the broader\nsoftware community. The lack of understanding about the proof-development\nprocess and how expert proof developers interact with POPLs has hindered the\nadvancement of effective proof engineering and the development of\nproof-synthesis models/tools.\n  In this work, we conduct a user study, involving the collection and analysis\nof fine-grained source code telemetry from eight experts working with two\nlanguages, F* and Verus. Results reveal interesting trends and patterns about\nhow experts reason about proofs and key challenges encountered during the proof\ndevelopment process. We identify three distinct strategies and multiple\ninformal practices that are not captured final code snapshots, yet are\npredictive of task outcomes. We translate these findings into concrete design\nguidance for AI proof assistants: bias toward early specification drafting,\nexplicit sub-goal decomposition, bounded active errors, and disciplined\nverifier interaction. We also present a case study of an F* proof agent\ngrounded in these recommendations, and demonstrate improved performance over\nbaseline LLMs", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5bf9F*\u548cVerus\u4e24\u79cdPOP\u8bed\u8a00\u7684\u4e13\u5bb6\u8bc1\u660e\u884c\u4e3a\u5206\u6790\uff0c\u603b\u7ed3\u51fa\u4e13\u5bb6\u7b56\u7565\u4e0e\u8bbe\u8ba1\u539f\u5219\uff0c\u5e76\u636e\u6b64\u6539\u8fdbAI\u8bc1\u660e\u52a9\u624b\uff0c\u4ece\u800c\u63d0\u5347\u6027\u80fd\uff0c\u4e3aPOP\u8bed\u8a00\u793e\u533a\u53d1\u5c55\u63d0\u4f9b\u501f\u9274\u3002", "motivation": "\u5c3d\u7ba1POP\u8bed\u8a00\u80fd\u591f\u63d0\u4f9b\u5f62\u5f0f\u5316\u7684\u6b63\u786e\u6027\u4fdd\u8bc1\uff0c\u4f46\u7531\u4e8e\u96be\u4ee5\u4e0a\u624b\uff0c\u5176\u5728\u66f4\u5e7f\u6cdb\u7684\u8f6f\u4ef6\u5f00\u53d1\u793e\u533a\u4e2d\u5c1a\u672a\u88ab\u5e7f\u6cdb\u91c7\u7528\u3002\u7f3a\u4e4f\u5bf9\u4e13\u5bb6\u5728POP\u8bed\u8a00\u4e2d\u8fdb\u884c\u8bc1\u660e\u5f00\u53d1\u8fc7\u7a0b\u7684\u7406\u89e3\uff0c\u8fdb\u4e00\u6b65\u963b\u788d\u4e86\u6709\u6548\u8bc1\u660e\u5de5\u7a0b\u548c\u8bc1\u660e\u5408\u6210\u5de5\u5177/\u6a21\u578b\u7684\u53d1\u5c55\u3002", "method": "\u672c\u6587\u901a\u8fc7\u7528\u6237\u7814\u7a76\uff0c\u91c7\u96c6\u5e76\u5206\u6790\u4e868\u4f4d\u4e13\u5bb6\u5728\u4e24\u79cdPOP\u8bed\u8a00\uff08F*\u548cVerus\uff09\u4e2d\u7684\u7ec6\u7c92\u5ea6\u6e90\u4ee3\u7801\u64cd\u4f5c\u6570\u636e\uff0c\u63ed\u793a\u4e13\u5bb6\u5982\u4f55\u8fdb\u884c\u8bc1\u660e\u6784\u601d\u4e0e\u5b9e\u65bd\uff0c\u5e76\u8bc6\u522b\u51fa\u7279\u6709\u7b56\u7565\u548c\u5b9e\u8df5\u3002\u968f\u540e\uff0c\u4f5c\u8005\u5c06\u7814\u7a76\u53d1\u73b0\u8f6c\u5316\u4e3aAI\u8bc1\u660e\u52a9\u624b\u7684\u8bbe\u8ba1\u5efa\u8bae\uff0c\u5e76\u57fa\u4e8e\u8fd9\u4e9b\u5efa\u8bae\u5f00\u53d1\u4e86F*\u8bc1\u660e\u667a\u80fd\u4f53\uff0c\u5e76\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u8bc6\u522b\u51fa\u4e09\u79cd\u72ec\u7279\u7684\u8bc1\u660e\u5f00\u53d1\u7b56\u7565\u53ca\u591a\u6761\u975e\u6b63\u5f0f\u5b9e\u8df5\uff0c\u8fd9\u4e9b\u5185\u5bb9\u5e76\u4e0d\u4f1a\u51fa\u73b0\u5728\u6700\u7ec8\u4ee3\u7801\u5feb\u7167\u4e2d\uff0c\u4f46\u5bf9\u4efb\u52a1\u7ed3\u679c\u5177\u6709\u9884\u6d4b\u6027\u3002\u91c7\u7eb3\u8bbe\u8ba1\u5efa\u8bae\u540e\u5f00\u53d1\u7684F*\u8bc1\u660e\u667a\u80fd\u4f53\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u5927\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "\u4e13\u5bb6\u5728POP\u8bed\u8a00\u4e2d\u7684\u8bc1\u660e\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u91c7\u7528\u4e86\u4e30\u5bcc\u548c\u7075\u6d3b\u7684\u65b9\u6cd5\uff0c\u7406\u89e3\u5e76\u501f\u9274\u8fd9\u4e9b\u7b56\u7565\uff0c\u6709\u52a9\u4e8eAI\u8bc1\u660e\u52a9\u624b\u4e0e\u8bc1\u660e\u5408\u6210\u5de5\u5177\u7684\u4f18\u5316\uff0c\u8fdb\u800c\u63a8\u52a8POP\u8bed\u8a00\u7684\u666e\u53ca\u548c\u9ad8\u6548\u5e94\u7528\u3002"}}
{"id": "2508.02820", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.02820", "abs": "https://arxiv.org/abs/2508.02820", "authors": ["David Svoboda", "Lori Flynn", "William Klieber", "Michael Duggan", "Nicholas Reimer", "Joseph Sible"], "title": "Automated Code Repair for C/C++ Static Analysis Alerts", "comment": null, "summary": "(Note: This work is a preprint.) Static analysis (SA) tools produce many\ndiagnostic alerts indicating that source code in C or C++ may be defective and\npotentially vulnerable to security exploits. Many of these alerts are false\npositives. Identifying the true-positive alerts and repairing the defects in\nthe associated code are huge efforts that automated program repair (APR) tools\ncan help with. Our experience showed us that APR can reduce the number of SA\nalerts significantly and reduce the manual effort of analysts to review code.\nThis engineering experience paper details the application of design,\ndevelopment, and performance testing to an APR tool we built that repairs C/C++\ncode associated with 3 categories of alerts produced by multiple SA tools. Its\nrepairs are simple and local. Furthermore, our findings convinced the\nmaintainers of the CERT Coding Standards to re-assess and update the metrics\nused to assess when violations of guidelines are detectable or repairable. We\ndiscuss engineering design choices made to support goals of trustworthiness and\nacceptability to developers. Our APR tool repaired 8718 out of 9234 alerts\nproduced by one SA tool on one codebase. It can repair 3 flaw categories. For 2\nflaw categories, 2 SA tools, and 2 codebases, our tool repaired or dismissed as\nfalse positives over 80% of alerts, on average. Tests showed repairs did not\nappreciably degrade the performance of the code or cause new alerts to appear\n(with the possible exception of sqlite3.c). This paper describes unique\ncontributions that include a new empirical analysis of SA data, our selection\nmethod for flaw categories to repair, publication of our APR tool, and a\ndataset of SA alerts from open-source SA tools run on open-source codebases. It\ndiscusses positive and negative results and lessons learned.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5de5\u7a0b\u5316\u5b9e\u73b0\u4e86\u4e00\u4e2a\u53ef\u81ea\u52a8\u4fee\u590d\u591a\u79cdC/C++\u9759\u6001\u5206\u6790\u544a\u8b66\u7684\u5de5\u5177\uff0c\u7ecf\u8fc7\u5927\u89c4\u6a21\u5b9e\u6d4b\u540e\u53d1\u73b0\uff0c\u5de5\u5177\u80fd\u591f\u4fee\u590d\u7edd\u5927\u591a\u6570\u544a\u8b66\u4e14\u4e0d\u4f1a\u5f71\u54cd\u4ee3\u7801\u6027\u80fd\uff0c\u5e76\u4fc3\u8fdb\u4e86\u7f16\u7801\u89c4\u8303\u66f4\u65b0\u3002", "motivation": "\u9759\u6001\u5206\u6790\uff08SA\uff09\u5de5\u5177\u5728\u5206\u6790C/C++\u4ee3\u7801\u65f6\u7ecf\u5e38\u4ea7\u751f\u5927\u91cf\u8bca\u65ad\u544a\u8b66\uff0c\u5176\u4e2d\u8bb8\u591a\u662f\u8bef\u62a5\u3002\u8bc6\u522b\u771f\u6b63\u7684\u6b63\u544a\u8b66\u5e76\u4fee\u590d\u76f8\u5173\u4ee3\u7801\u7f3a\u9677\u662f\u975e\u5e38\u8017\u65f6\u7684\u8fc7\u7a0b\uff0c\u56e0\u6b64\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u5de5\u5177\u53ef\u4ee5\u663e\u8457\u51cf\u8f7b\u5206\u6790\u5e08\u7684\u5de5\u4f5c\u8d1f\u62c5\u3002\u672c\u6587\u65e8\u5728\u603b\u7ed3\u4e00\u79cdAPR\u5de5\u5177\u7684\u5de5\u7a0b\u8bbe\u8ba1\u548c\u5e94\u7528\u7ecf\u9a8c\uff0c\u63a8\u52a8\u4ee3\u7801\u5b89\u5168\u4e0e\u5f00\u53d1\u6548\u7387\u63d0\u5347\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u80fd\u591f\u4fee\u590d\u591a\u7c7bSA\u5de5\u5177\u544a\u8b66\u7684APR\u5de5\u5177\u3002\u8be5\u5de5\u5177\u9488\u5bf93\u7c7b\u5e38\u89c1\u4ee3\u7801\u7f3a\u9677\uff0c\u5bf9\u5e94\u591a\u79cd\u9759\u6001\u5206\u6790\u5de5\u5177\u62a5\u8b66\uff0c\u91c7\u7528\u5c40\u90e8\u7b80\u5355\u4fee\u590d\u7b56\u7565\uff0c\u901a\u8fc7\u5de5\u7a0b\u8bbe\u8ba1\u548c\u5927\u91cf\u6027\u80fd\u6d4b\u8bd5\u9a8c\u8bc1\u5176\u6548\u679c\u3002\u540c\u65f6\uff0c\u7ecf\u9a8c\u6570\u636e\u7528\u4e8e\u6307\u5bfcSA\u6807\u51c6\uff08\u5982CERT\u7f16\u7801\u89c4\u8303\uff09\u8bc4\u4f30\u548c\u66f4\u65b0\u4fee\u590d/\u68c0\u6d4b\u6807\u51c6\u3002", "result": "\u8be5APR\u5de5\u5177\u5728\u4e00\u4e2a\u4ee3\u7801\u5e93\u4e2d\u80fd\u4fee\u590d8718\u4e2a\u544a\u8b66\uff08\u51719234\u4e2a\uff09\u3002\u57282\u7c7b\u7f3a\u9677\u30012\u4e2a\u9759\u6001\u5206\u6790\u5de5\u5177\u548c2\u4e2a\u4ee3\u7801\u5e93\u7684\u6570\u636e\u4e0b\uff0c\u5e73\u5747\u4fee\u590d\u6216\u8bc6\u522b\u4e3a\u8bef\u62a5\u7684\u544a\u8b66\u6bd4\u4f8b\u8d85\u8fc780%\u3002\u4fee\u590d\u64cd\u4f5c\u65e0\u660e\u663e\u6027\u80fd\u635f\u5931\uff0c\u4e5f\u672a\u5f15\u5165\u65b0\u544a\u8b66\uff08sqlite3.c\u9664\u5916\uff09\u3002\u8d21\u732e\u8fd8\u5305\u62ecAPR\u5de5\u5177\u5f00\u6e90\u53d1\u5e03\u548c\u5927\u89c4\u6a21SA\u6570\u636e\u96c6\u7684\u62ab\u9732\u3002", "conclusion": "\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\u5de5\u5177\u786e\u5b9e\u80fd\u6709\u6548\u51cf\u5c11\u9759\u6001\u5206\u6790\u8b66\u62a5\u6570\u4ee5\u53ca\u5f00\u53d1\u8005\u4eba\u5de5\u5904\u7406\u8d1f\u62c5\uff0c\u5bf9\u73b0\u6709\u7684\u4ee3\u7801\u89c4\u8303\u548c\u68c0\u6d4b\u6807\u51c6\u4ea7\u751f\u79ef\u6781\u63a8\u52a8\uff0c\u5e76\u5177\u5907\u8f83\u5f3a\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.02886", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.02886", "abs": "https://arxiv.org/abs/2508.02886", "authors": ["Wenjie Luo", "Ruocheng Li", "Shanshan Zhu", "Julian Perry"], "title": "Coherent Multimodal Reasoning with Iterative Self-Evaluation for Vision-Language Models", "comment": null, "summary": "Despite significant advancements, current large language models (LLMs) and\nvision-language models (LVLMs) continue to struggle with complex, multi-step,\ncross-modal common sense reasoning tasks, often exhibiting a lack of\n\"deliberative thinking.\" They tend to rely on superficial associations rather\nthan deep, chained inference, particularly when integrating visual information\nwith abstract concepts. To address this, we propose the Coherent Multimodal\nReasoning Framework (CMRF), a novel approach that enhances LVLMs' common sense\nreasoning capabilities through an iterative, self-evaluating inference\nmechanism. CMRF mimics human problem-solving by decomposing complex queries,\ngenerating step-by-step inferences, and self-correcting errors. Our framework\nintegrates three key modules: a Reasoning Decomposition Unit (RDU) for breaking\ndown problems into sub-questions, a Contextual Inference Engine (CIE) for\ncontextual inference, and a Coherence Assessment Module (CAM) for evaluating\nlogical consistency and confidence. Coupled with an Adaptive Iterative\nRefinement strategy, CMRF systematically refines its reasoning paths. Built\nupon LLaVA-1.6-34B and trained on a novel Multimodal Daily Activity Reasoning\n(MDAR) dataset, CMRF achieves state-of-the-art performance among open-source\nLVLMs on challenging benchmarks like VCR, A-OKVQA, and DailyLife-MRC. It\nattains an average accuracy of 69.4%, surpassing the best open-source baseline\nby +2.4 percentage points, with particular strength in complex reasoning\nscenarios. Extensive ablation studies and human evaluations confirm the\ncritical contributions of each module and the effectiveness of iterative\nrefinement in fostering more coherent and accurate reasoning.", "AI": {"tldr": "CMRF\u901a\u8fc7\u6a21\u5757\u5316\u5206\u89e3\u3001\u4e0a\u4e0b\u6587\u63a8\u7406\u4e0e\u903b\u8f91\u4e00\u81f4\u6027\u8bc4\u4f30\uff0c\u4ee5\u53ca\u8fed\u4ee3\u4f18\u5316\uff0c\u6781\u5927\u63d0\u5347\u4e86\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u8de8\u6a21\u6001\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u5237\u65b0\u4e86\u5f00\u6e90\u6a21\u578b\u7684\u51c6\u786e\u7387\u7eaa\u5f55\u3002", "motivation": "\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u5728\u590d\u6742\u3001\u591a\u6b65\u9aa4\u3001\u8de8\u6a21\u6001\u5e38\u8bc6\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u7f3a\u4e4f\u201c\u6df1\u5ea6\u63a8\u7406\u201d\u80fd\u529b\uff0c\u66f4\u5bb9\u6613\u4f9d\u8d56\u8868\u9762\u5173\u8054\u800c\u975e\u6df1\u5c42\u903b\u8f91\u63a8\u7406\u3002\u5982\u4f55\u8ba9LVLMs\u8fdb\u884c\u66f4\u50cf\u4eba\u7c7b\u7684\u903b\u8f91\u548c\u5e38\u8bc6\u63a8\u7406\uff0c\u662f\u8be5\u7814\u7a76\u5e0c\u671b\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u63a8\u7406\u6846\u67b6\uff08CMRF\uff09\uff0c\u5305\u62ec\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\u63a8\u7406\u5206\u89e3\u5355\u5143\uff08RDU\uff09\u5c06\u590d\u6742\u95ee\u9898\u62c6\u5206\u4e3a\u5b50\u95ee\u9898\uff1b\u4e0a\u4e0b\u6587\u63a8\u7406\u5f15\u64ce\uff08CIE\uff09\u8d1f\u8d23\u4e0a\u4e0b\u6587\u63a8\u7406\uff1b\u8fde\u8d2f\u6027\u8bc4\u4f30\u6a21\u5757\uff08CAM\uff09\u8bc4\u4f30\u903b\u8f91\u4e00\u81f4\u6027\u548c\u7f6e\u4fe1\u5ea6\u3002\u540c\u65f6\u5f15\u5165\u81ea\u9002\u5e94\u8fed\u4ee3\u4f18\u5316\u7b56\u7565\uff0c\u4eff\u7167\u4eba\u7c7b\u6b65\u9aa4\u63a8\u7406\u3001\u7ea0\u9519\u548c\u81ea\u6211\u5b8c\u5584\u7684\u8fc7\u7a0b\u3002\u8be5\u6846\u67b6\u57fa\u4e8eLLaVA-1.6-34B\u6a21\u578b\uff0c\u8bad\u7ec3\u5728\u65b0\u6784\u5efa\u7684MDAR\u6570\u636e\u96c6\u4e0a\u3002", "result": "CMRF\u5728\u591a\u4e2a\u6743\u5a01\u89c6\u89c9-\u8bed\u8a00\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff08VCR, A-OKVQA, DailyLife-MRC\uff09\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5e73\u5747\u51c6\u786e\u7387\u8fbe\u523069.4%\uff0c\u6bd4\u6700\u4f18\u5f00\u6e90\u57fa\u7ebf\u9ad82.4\u4e2a\u767e\u5206\u70b9\uff0c\u5c24\u5176\u5728\u590d\u6742\u63a8\u7406\u573a\u666f\u8868\u73b0\u7a81\u51fa\u3002\u6d88\u878d\u5b9e\u9a8c\u548c\u4eba\u5de5\u8bc4\u4f30\u5747\u9a8c\u8bc1\u4e86\u5404\u6a21\u5757\u4f5c\u7528\u548c\u8fed\u4ee3\u4f18\u5316\u5728\u63d0\u5347\u63a8\u7406\u8fde\u8d2f\u6027\u4e0e\u51c6\u786e\u6027\u4e0a\u7684\u51b3\u5b9a\u6027\u8d21\u732e\u3002", "conclusion": "CMRF\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86LVLM\u7684\u5e38\u8bc6\u63a8\u7406\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u591a\u6b65\u9aa4\u3001\u590d\u6742\u8de8\u6a21\u6001\u573a\u666f\u4e0b\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u548c\u8fed\u4ee3\u81ea\u6211\u4f18\u5316\u80fd\u53d6\u5f97\u66f4\u9ad8\u51c6\u786e\u6027\u548c\u8fde\u8d2f\u6027\u7684\u63a8\u7406\u7ed3\u679c\u3002"}}
{"id": "2508.03435", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.03435", "abs": "https://arxiv.org/abs/2508.03435", "authors": ["Thomas S. Heinze", "Andr\u00e9 Sch\u00e4fer", "Wolfram Amme"], "title": "StoneDetector: Conventional and versatile code clone detection for Java", "comment": "supplementary information available at\n  https://stonedetector.fmi.uni-jena.de/", "summary": "Copy & paste is a widespread practice when developing software and, thus,\nduplicated and subsequently modified code occurs frequently in software\nprojects. Since such code clones, i.e., identical or similar fragments of code,\ncan bloat software projects and cause issues like bug or vulnerability\npropagation, their identification is of importance. In this paper, we present\nthe StoneDetector platform and its underlying method for finding code clones in\nJava source and Bytecode. StoneDetector implements a conventional clone\ndetection approach based upon the textual comparison of paths derived from the\ncode's representation by dominator trees. In this way, the tool does not only\nfind exact and syntactically similar near-miss code clones, but also code\nclones that are harder to detect due to their larger variety in the syntax. We\ndemonstrate StoneDetector's versatility as a conventional clone detection\nplatform and analyze its various available configuration parameters, including\nthe usage of different string metrics, hashing algorithms, etc. In our\nexhaustive evaluation with other conventional clone detectors on several\nstate-of-the-art benchmarks, we can show StoneDetector's performance and\nscalability in finding code clones in both, Java source and Bytecode.", "AI": {"tldr": "StoneDetector\u662f\u4e00\u79cd\u57fa\u4e8e\u652f\u914d\u6811\u8def\u5f84\u6587\u672c\u6bd4\u8f83\u7684Java\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u5e73\u53f0\uff0c\u80fd\u591f\u5728\u6e90\u7801\u548c\u5b57\u8282\u7801\u4e2d\u6709\u6548\u68c0\u6d4b\u591a\u79cd\u7c7b\u578b\u514b\u9686\uff0c\u8868\u73b0\u4f18\u4e8e\u4e3b\u6d41\u540c\u7c7b\u5de5\u5177\u3002", "motivation": "\u4ee3\u7801\u590d\u5236\u548c\u7c98\u8d34\u662f\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e38\u89c1\u505a\u6cd5\uff0c\u5bfc\u81f4\u4e86\u5927\u91cf\u5197\u4f59\u4e14\u53ef\u80fd\u88ab\u4fee\u6539\u7684\u4ee3\u7801\u7247\u6bb5\uff08\u4ee3\u7801\u514b\u9686\uff09\u7684\u51fa\u73b0\u3002\u8fd9\u4e9b\u4ee3\u7801\u514b\u9686\u53ef\u80fd\u5f15\u53d1\u8bf8\u5982\u8f6f\u4ef6\u81a8\u80c0\u3001\u6f0f\u6d1e\u4e0ebug\u4f20\u64ad\u7b49\u95ee\u9898\uff0c\u6240\u4ee5\u9700\u8981\u6709\u6548\u7684\u514b\u9686\u68c0\u6d4b\u673a\u5236\u3002", "method": "\u63d0\u51fa\u4e86StoneDetector\u5e73\u53f0\u53ca\u5176\u5e95\u5c42\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u7531\u652f\u914d\u6811\u8868\u793a\u7684\u4ee3\u7801\u8def\u5f84\u8fdb\u884c\u6587\u672c\u6bd4\u8f83\u6765\u68c0\u6d4b\u514b\u9686\u3002StoneDetector\u96c6\u6210\u4e86\u4e0d\u540c\u7684\u5b57\u7b26\u4e32\u5ea6\u91cf\u3001\u54c8\u5e0c\u7b97\u6cd5\u7b49\u591a\u79cd\u914d\u7f6e\uff0c\u80fd\u591f\u5728Java\u6e90\u7801\u548c\u5b57\u8282\u7801\u4e2d\u68c0\u6d4b\u5b8c\u5168\u4e00\u81f4\u3001\u8bed\u6cd5\u76f8\u8fd1\u751a\u81f3\u7ed3\u6784\u53d8\u5316\u8f83\u5927\u7684\u514b\u9686\u4ee3\u7801\u3002", "result": "\u901a\u8fc7\u4e0e\u591a\u79cd\u4e3b\u6d41\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u5de5\u5177\u5728\u591a\u4e2a\u6743\u5a01\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u5bf9\u6bd4\uff0c\u8bc1\u660e\u4e86StoneDetector\u5728Java\u6e90\u4ee3\u7801\u548c\u5b57\u8282\u7801\u514b\u9686\u68c0\u6d4b\u4e2d\u7684\u6027\u80fd\u53ca\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "StoneDetector\u4f5c\u4e3a\u4e00\u6b3e\u4f20\u7edf\u514b\u9686\u68c0\u6d4b\u5e73\u53f0\uff0c\u4e0d\u4ec5\u53ef\u68c0\u6d4b\u5e38\u89c1\u7684\u8bed\u6cd5\u7ea7\u514b\u9686\uff0c\u8fd8\u53ef\u53d1\u73b0\u66f4\u96be\u8bc6\u522b\u7684\u7ed3\u6784\u53d8\u5316\u514b\u9686\uff0c\u4e14\u5177\u5907\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u914d\u7f6e\u7075\u6d3b\u6027\u3002"}}
{"id": "2508.02901", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.02901", "abs": "https://arxiv.org/abs/2508.02901", "authors": ["Osama Khalid", "Sanvesh Srivastava", "Padmini Srinivasan"], "title": "SLIM-LLMs: Modeling of Style-Sensory Language RelationshipsThrough Low-Dimensional Representations", "comment": null, "summary": "Sensorial language -- the language connected to our senses including vision,\nsound, touch, taste, smell, and interoception, plays a fundamental role in how\nwe communicate experiences and perceptions. We explore the relationship between\nsensorial language and traditional stylistic features, like those measured by\nLIWC, using a novel Reduced-Rank Ridge Regression (R4) approach. We demonstrate\nthat low-dimensional latent representations of LIWC features r = 24 effectively\ncapture stylistic information for sensorial language prediction compared to the\nfull feature set (r = 74). We introduce Stylometrically Lean Interpretable\nModels (SLIM-LLMs), which model non-linear relationships between these style\ndimensions. Evaluated across five genres, SLIM-LLMs with low-rank LIWC features\nmatch the performance of full-scale language models while reducing parameters\nby up to 80%.", "AI": {"tldr": "\u901a\u8fc7\u521b\u65b0\u7684\u964d\u79e9\u5cad\u56de\u5f52\u548c\u7cbe\u7b80\u6587\u4f53\u6a21\u578b\uff0c\u8bba\u6587\u8bc1\u660e\u4f4e\u7ef4\u6587\u4f53\u7279\u5f81\u5373\u53ef\u6709\u6548\u9884\u6d4b\u6587\u672c\u4e2d\u7684\u611f\u5b98\u8bed\u8a00\uff0c\u5927\u5927\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\u548c\u89e3\u91ca\u96be\u5ea6\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u63cf\u8ff0\u611f\u5b98\u4f53\u9a8c\u7684\u611f\u5b98\u8bed\u8a00\u4e0e\u4f20\u7edf\u6587\u4f53\u7279\u5f81\uff08\u5982LIWC\u91cf\u8868\u6d4b\u91cf\u7684\u7279\u5f81\uff09\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4ee5\u4fbf\u66f4\u9ad8\u6548\u5730\u5efa\u6a21\u548c\u9884\u6d4b\u6587\u672c\u4e2d\u7684\u611f\u5b98\u4fe1\u606f\u3002", "method": "\u91c7\u7528\u65b0\u9896\u7684\u964d\u79e9\u5cad\u56de\u5f52\uff08Reduced-Rank Ridge Regression, R4\uff09\u65b9\u6cd5\uff0c\u5206\u6790LIWC\u7279\u5f81\u5728\u4f4e\u7ef4\u6f5c\u5728\u7a7a\u95f4\u5185\u5bf9\u611f\u5b98\u8bed\u8a00\u7684\u9884\u6d4b\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u5efa\u6a21\u975e\u7ebf\u6027\u98ce\u683c\u7ef4\u5ea6\u5173\u7cfb\u7684SLIM-LLMs\uff08Stylistically Lean Interpretable Models\uff09\u3002\u5728\u4e94\u79cd\u6587\u672c\u4f53\u88c1\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u5bf9\u6bd4\u3002", "result": "\u53d1\u73b0LIWC\u7279\u5f81\u7684\u4f4e\u7ef4\u6f5c\u5728\u8868\u793a\uff08r=24\uff09\u5728\u611f\u5b98\u8bed\u8a00\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e0e\u4f7f\u7528\u5168\u90e8\u7279\u5f81\uff08r=74\uff09\u76f8\u6bd4\u6548\u679c\u63a5\u8fd1\u3002SLIM-LLMs\u5728\u53c2\u6570\u51cf\u5c11\u9ad8\u8fbe80%\u7684\u60c5\u51b5\u4e0b\uff0c\u6027\u80fd\u4e0e\u5168\u91cf\u8bed\u8a00\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "\u4f4e\u7ef4\u5ea6\u7684\u98ce\u683c\u7279\u5f81\u5728\u611f\u5b98\u8bed\u8a00\u5efa\u6a21\u4e2d\u8db3\u591f\u6709\u6548\uff0c\u53ef\u5728\u5927\u5e45\u51cf\u5c11\u6a21\u578b\u89c4\u6a21\u548c\u53c2\u6570\u7684\u540c\u65f6\u4fdd\u6301\u5bf9\u611f\u5b98\u8bed\u8a00\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u89e3\u91ca\u6027\u4e0e\u6548\u7387\u3002"}}
{"id": "2508.02827", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02827", "abs": "https://arxiv.org/abs/2508.02827", "authors": ["Ora Nova Fandina", "Eitan Farchi", "Shmulik Froimovich", "Rami Katan", "Alice Podolsky", "Orna Raz", "Avi Ziv"], "title": "Automated Validation of LLM-based Evaluators for Software Engineering Artifacts", "comment": null, "summary": "Automation in software engineering increasingly relies on large language\nmodels (LLMs) to generate, review, and assess code artifacts. However,\nestablishing LLMs as reliable evaluators remains an open challenge: human\nevaluations are costly, subjective and non scalable, while existing automated\nmethods fail to discern fine grained variations in artifact quality.\n  We introduce REFINE (Ranking Evaluators for FIne grained Nuanced Evaluation),\nan automated framework for benchmarking LLM based evaluators across software\nengineering tasks. REFINE comprises of two modules: Hierarchy Dataset Builder\napplies novel generation techniques to automatically synthesize artifacts with\nprogressively reduced quality, and Evaluator Tester quantifies each candidate\nevaluator configuration by measuring how closely its rankings align with\nexpected ordering.\n  A key feature of REFINE is controllability: users can tune the granularity of\ndegradation to progressively refine evaluator configurations, from coarse\nfiltering to stress testing on subtle quality gaps.\n  While the methodology is general, we focus on coding tasks reflecting the\npractical demands in our production setting. REFINE was integrated into IBM's\ninternal development workflows and applied to code generation, translation, and\nsummarization for COBOL, an enterprise critical programming language, using\nindustrial data. It was used to identify LLM as a Judge configurations that\nlifted alignment scores from below $0.7$ to above $0.9$ in some coding tasks.\nThese nuance sensitive evaluators are now actively used by model training teams\nto support model release decisions.", "AI": {"tldr": "REFINE\u662f\u4e00\u5957\u53ef\u81ea\u52a8\u5408\u6210\u5e26\u7ec6\u7c92\u5ea6\u9000\u5316\u5de5\u4ef6\u5e76\u8bc4\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u5224\u80fd\u529b\u7684\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bc4\u6d4b\u7ec6\u81f4\u5ea6\u548c\u4e00\u81f4\u6027\uff0c\u5df2\u5b9e\u8df5\u4e8eIBM\u5185\u90e8\u751f\u4ea7\u73af\u5883\uff0c\u6548\u679c\u663e\u8457\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u81ea\u52a8\u5316\u65b9\u9762\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u5982\u4f55\u8bc4\u4f30\u5176\u8bc4\u6d4b\u8005\u89d2\u8272\u7684\u53ef\u9760\u6027\u4ecd\u662f\u96be\u9898\uff0c\u73b0\u6709\u8bc4\u6d4b\u65b9\u5f0f\u4e0d\u80fd\u7cbe\u51c6\u533a\u5206\u5de5\u4ef6\u8d28\u91cf\u7ec6\u5fae\u5dee\u5f02\u3002\u63d0\u51fa\u4e00\u79cd\u81ea\u52a8\u5316\u4e14\u53ef\u8c03\u63a7\u7684\u8bc4\u6d4b\u65b9\u6cd5\u6765\u63d0\u5347\u53ef\u9760\u6027\u548c\u7075\u654f\u5ea6\u3002", "method": "\u63d0\u51faREFINE\u6846\u67b6\uff0c\u5305\u62ec\u81ea\u52a8\u751f\u6210\u5e26\u6709\u7ec6\u7c92\u5ea6\u9000\u5316\u7684\u4ee3\u7801\u5de5\u4ef6\u7684\u6570\u636e\u96c6\u548c\u8bc4\u6d4b\u914d\u7f6e\u7684\u81ea\u52a8\u5316\u6392\u540d\u6d4b\u8bd5\uff0c\u7ed3\u5408\u5de5\u4e1a\u7ea7\u7528\u4f8b\uff08\u5982COBOL\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\uff09\u8fdb\u884c\u5b9e\u9645\u5e94\u7528\u9a8c\u8bc1\u3002", "result": "REFINE\u88ab\u96c6\u6210\u8fdbIBM\u5f00\u53d1\u6d41\u7a0b\uff0c\u9488\u5bf9COBOL\u7b49\u5173\u952e\u4efb\u52a1\uff0c\u9009\u51fa\u4e86Nuance Sensitive Evaluator\uff0c\u5c06\u90e8\u5206\u4efb\u52a1\u7684alignment score\u4ece0.7\u4ee5\u4e0b\u63d0\u5347\u52300.9\u4ee5\u4e0a\uff0c\u5df2\u4e3a\u6a21\u578b\u56e2\u961f\u6240\u7528\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u53d1\u5e03\u51b3\u7b56\u7684\u8d28\u91cf\u3002", "conclusion": "REFINE\u80fd\u591f\u6709\u6548\u8bc6\u522b\u548c\u63d0\u5347\u5927\u6a21\u578b\u8bc4\u6d4b\u7684\u7075\u654f\u5ea6\uff0c\u5df2\u88ab\u5e94\u7528\u4e8e\u5b9e\u9645\u751f\u4ea7\u6d41\u7a0b\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bc4\u6d4b\u4e00\u81f4\u6027\u548c\u5206\u8fa8\u7ec6\u5fae\u8d28\u91cf\u5dee\u5f02\u7684\u80fd\u529b\u3002"}}
{"id": "2508.03603", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.03603", "abs": "https://arxiv.org/abs/2508.03603", "authors": ["Iti Shree", "Karine Even-Mendoz", "Tomasz Radzik"], "title": "ReFuzzer: Feedback-Driven Approach to Enhance Validity of LLM-Generated Test Programs", "comment": null, "summary": "Existing LLM-based compiler fuzzers often produce syntactically or\nsemantically invalid test programs, limiting their effectiveness in exercising\ncompiler optimizations and backend components. We introduce ReFuzzer, a\nframework for refining LLM-generated test programs by systematically detecting\nand correcting compilation and runtime violations (e.g. division by zero or\narray out-of-bounds accesses). ReFuzzer employs a feedback loop with a local\nLLM to validate and filter erroneous programs before execution, improving\nfuzzing effectiveness beyond crash detection and enabling the generation of\ndiverse yet valid test programs.\n  We evaluated ReFuzzer's effectiveness across black-, grey- and white-box\nfuzzing approaches targeting LLVM/Clang. ReFuzzer improved test programs'\nvalidity from 47.0-49.4% to 96.6-97.3%, with an average processing time of\n2.9-3.5 s per test program on a dual-GPU machine. Further, refuzzing\nsignificantly increased code coverage in critical optimization and IR\ngeneration components. For example, vectorization coverage had an absolute\nimprovement of 9.2%, 2.3%, and 7.1% in black-, grey-, and white-box fuzzing,\nenhancing testing effectiveness.", "AI": {"tldr": "ReFuzzer\u901a\u8fc7\u53cd\u9988\u4fee\u6b63\u673a\u5236\u6781\u5927\u63d0\u5347\u4e86\u5927\u6a21\u578b\u751f\u6210\u7f16\u8bd1\u5668\u6d4b\u8bd5\u7a0b\u5e8f\u7684\u6709\u6548\u6027\u548c\u8986\u76d6\u7387\uff0c\u662fLLM\u7f16\u8bd1\u5668\u6a21\u7cca\u6d4b\u8bd5\u7684\u6709\u6548\u589e\u5f3a\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7f16\u8bd1\u5668\u6a21\u7cca\u6d4b\u8bd5\u5668\u5f80\u5f80\u751f\u6210\u8bed\u6cd5\u6216\u8bed\u4e49\u65e0\u6548\u7684\u6d4b\u8bd5\u7a0b\u5e8f\uff0c\u5bfc\u81f4\u5bf9\u7f16\u8bd1\u5668\u4f18\u5316\u548c\u540e\u7aef\u7ec4\u4ef6\u6d4b\u8bd5\u6548\u679c\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e86ReFuzzer\u6846\u67b6\uff0c\u901a\u8fc7\u53cd\u9988\u56de\u8def\u548c\u672c\u5730LLM\u6765\u68c0\u6d4b\u548c\u4fee\u6b63\u7f16\u8bd1\u4e0e\u8fd0\u884c\u65f6\u8fdd\u89c4\uff08\u5982\u9664\u96f6\u6216\u6570\u7ec4\u8d8a\u754c\uff09\uff0c\u5728\u7a0b\u5e8f\u6267\u884c\u524d\u8fc7\u6ee4\u9519\u8bef\u6d4b\u8bd5\u7528\u4f8b\uff0c\u63d0\u5347\u6a21\u7cca\u6d4b\u8bd5\u7a0b\u5e8f\u7684\u6709\u6548\u6027\u3002", "result": "ReFuzzer\u5c06\u6d4b\u8bd5\u7a0b\u5e8f\u7684\u6709\u6548\u7387\u4ece47.0-49.4%\u63d0\u5347\u81f396.6-97.3%\uff0c\u5e73\u5747\u5904\u7406\u65f6\u95f4\u4e3a2.9-3.5\u79d2/\u7a0b\u5e8f\uff0c\u5e76\u5728\u5173\u952e\u4f18\u5316\u548c\u4e2d\u95f4\u8868\u793a\u751f\u6210\u7ec4\u4ef6\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u8986\u76d6\u7387\uff0c\u4f8b\u5982\u77e2\u91cf\u5316\u8986\u76d6\u7387\u5728\u9ed1\u3001\u7070\u3001\u767d\u76d2\u6a21\u7cca\u6d4b\u8bd5\u4e2d\u5206\u522b\u63d0\u5347\u4e869.2%\u30012.3%\u30017.1%\u3002", "conclusion": "ReFuzzer\u80fd\u663e\u8457\u63d0\u5347\u57fa\u4e8eLLM\u7684\u7f16\u8bd1\u5668\u6a21\u7cca\u6d4b\u8bd5\u7a0b\u5e8f\u7684\u6709\u6548\u6027\u548c\u8986\u76d6\u7387\uff0c\u6709\u6548\u589e\u5f3a\u7f16\u8bd1\u5668\u6d4b\u8bd5\u6548\u679c\uff0c\u5c24\u5176\u5728\u591a\u79cd\u6a21\u7cca\u6d4b\u8bd5\u573a\u666f\u4e0b\u5747\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2508.02931", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.02931", "abs": "https://arxiv.org/abs/2508.02931", "authors": ["Shengqi Li", "Amarnath Gupta"], "title": "Can LLMs Generate High-Quality Task-Specific Conversations?", "comment": null, "summary": "This paper introduces a parameterization framework for controlling\nconversation quality in large language models. We explore nine key parameters\nacross six dimensions that enable precise specification of dialogue properties.\nThrough experiments with state-of-the-art LLMs, we demonstrate that\nparameter-based control produces statistically significant differences in\ngenerated conversation properties. Our approach addresses challenges in\nconversation generation, including topic coherence, knowledge progression,\ncharacter consistency, and control granularity. The framework provides a\nstandardized method for conversation quality control with applications in\neducation, therapy, customer service, and entertainment. Future work will focus\non implementing additional parameters through architectural modifications and\ndeveloping benchmark datasets for evaluation.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u53c2\u6570\u5316\u6846\u67b6\u63a7\u5236\u5927\u6a21\u578b\u5bf9\u8bdd\u8d28\u91cf\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6709\u6548\uff0c\u5bf9\u591a\u9886\u57df\u5e94\u7528\u6709\u4fc3\u8fdb\u4f5c\u7528\u3002", "motivation": "\u5f53\u524d\u5bf9\u8bdd\u751f\u6210\u5b58\u5728\u4e3b\u9898\u8fde\u8d2f\u6027\u3001\u77e5\u8bc6\u63a8\u8fdb\u3001\u89d2\u8272\u4e00\u81f4\u6027\u548c\u63a7\u5236\u7c92\u5ea6\u7b49\u6311\u6218\uff0c\u7f3a\u4e4f\u6807\u51c6\u5316\u9ad8\u6548\u8d28\u91cf\u63a7\u5236\u624b\u6bb5\u3002", "method": "\u63d0\u51fa\u53c2\u6570\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u9a8c\u68c0\u9a8c\u4e5d\u4e2a\u5173\u952e\u53c2\u6570\u5bf9\u591a\u7ef4\u5bf9\u8bdd\u5c5e\u6027\u7684\u63a7\u5236\u6548\u679c\uff0c\u4f7f\u7528\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u53c2\u6570\u63a7\u5236\u80fd\u591f\u4ea7\u751f\u7edf\u8ba1\u663e\u8457\u7684\u5bf9\u8bdd\u5c5e\u6027\u5dee\u5f02\uff0c\u6210\u529f\u6539\u5584\u4e86\u5bf9\u8bdd\u7684\u591a\u9879\u8d28\u91cf\u6307\u6807\u3002", "conclusion": "\u53c2\u6570\u5316\u63a7\u5236\u5bf9\u5bf9\u8bdd\u751f\u6210\u8d28\u91cf\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4e3a\u5927\u6a21\u578b\u5bf9\u8bdd\u8d28\u91cf\u63a7\u5236\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u65b9\u6cd5\uff0c\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2508.02968", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.02968", "abs": "https://arxiv.org/abs/2508.02968", "authors": ["Shavindra Wickramathilaka", "John Grundy", "Kashumi Madampe", "Omar Haggag"], "title": "Developer Perceptions on Utilising Low-Code Approaches to Build Accessible and Adaptive Applications for Seniors", "comment": "This paper has been submitted to ACM Transactions on Software\n  Engineering and Methodology (TOSEM)", "summary": "The global ageing population presents a growing societal challenge, creating\nan urgent need for inclusive technologies that promote autonomy among older\nadults. Software practitioners can address this by delivering digital services\nthat enhance seniors' independence and reduce reliance on routine support from\nfamily members and healthcare infrastructure. However, traditional development\npractices, constrained by time and resources, often result in applications with\nmajor accessibility and personalisation barriers. Increasing pressure from\nregulatory requirements, such as the European Accessibility Act (EAA), and the\npersonal empathy many developers feel toward supporting their older loved ones\nand their own future selves have created a demand for tools that support the\ndevelopment of accessible and adaptive software. To address this demand, this\npaper presents an interview-based empirical study with 18 software\npractitioners, evaluating AdaptForge: a low-code model-driven engineering (MDE)\ntool that enables the efficient creation of accessible and adaptive\napplications for senior users by mitigating development constraints through\nautomated code generation. Based on these insights, we identify developer\nexpectations for adopting such tools as industry-standard solutions and provide\nempirically grounded recommendations for designing low-code tools that support\naccessible and adaptive software development.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u8bbf\u8c08\u8c03\u7814\uff0c\u8bc4\u4f30\u4e86\u4e00\u6b3e\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u7684\u4f4e\u4ee3\u7801\u5de5\u5177\u5bf9\u5f00\u53d1\u9762\u5411\u8001\u5e74\u4eba\u53ef\u8bbf\u95ee\u5e94\u7528\u7684\u4f5c\u7528\uff0c\u63d0\u51fa\u4e86\u63a8\u52a8\u6b64\u7c7b\u5de5\u5177\u884c\u4e1a\u91c7\u7eb3\u7684\u5efa\u8bae\u3002", "motivation": "\u968f\u7740\u5168\u7403\u8001\u9f84\u5316\u52a0\u5267\uff0c\u8001\u5e74\u4eba\u5bf9\u80fd\u63d0\u5347\u81ea\u4e3b\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u7684\u6570\u5b57\u4ea7\u54c1\u9700\u6c42\u6fc0\u589e\u3002\u73b0\u6709\u5f00\u53d1\u65b9\u6cd5\u7ecf\u5e38\u56e0\u65f6\u95f4\u548c\u8d44\u6e90\u53d7\u9650\uff0c\u96be\u4ee5\u6ee1\u8db3\u8fd9\u7c7b\u9700\u6c42\uff0c\u540c\u65f6\u9762\u4e34\u6cd5\u89c4\u538b\u529b\uff08\u5982\u6b27\u76df\u65e0\u969c\u788d\u6cd5\u6848\uff09\u548c\u5f00\u53d1\u8005\u81ea\u8eab\u5bf9\u8001\u5e74\u5bb6\u4eba\u7684\u5173\u5207\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5bf918\u4f4d\u8f6f\u4ef6\u4ece\u4e1a\u8005\u8fdb\u884c\u8bbf\u8c08\u6027\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc4\u4f30\u4e86\u540d\u4e3aAdaptForge\u7684\u4f4e\u4ee3\u7801\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\uff08MDE\uff09\u5de5\u5177\u3002\u8be5\u5de5\u5177\u901a\u8fc7\u81ea\u52a8\u5316\u4ee3\u7801\u751f\u6210\uff0c\u6709\u6548\u7f13\u89e3\u5f00\u53d1\u9650\u5236\uff0c\u4f7f\u5f00\u53d1\u8005\u9ad8\u6548\u5f00\u53d1\u9762\u5411\u8001\u5e74\u7528\u6237\u7684\u53ef\u8bbf\u95ee\u4e14\u81ea\u9002\u5e94\u7684\u5e94\u7528\u3002", "result": "\u7814\u7a76\u8bc6\u522b\u51fa\u5f00\u53d1\u8005\u5728\u91c7\u7eb3\u6b64\u7c7b\u4f4e\u4ee3\u7801\u5de5\u5177\u4e3a\u884c\u4e1a\u6807\u51c6\u89e3\u51b3\u65b9\u6848\u65f6\u7684\u671f\u671b\uff0c\u5e76\u57fa\u4e8e\u5b9e\u8bc1\u6570\u636e\uff0c\u63d0\u51fa\u4e86\u652f\u6301\u53ef\u8bbf\u95ee\u4e0e\u81ea\u9002\u5e94\u8f6f\u4ef6\u5f00\u53d1\u7684\u4f4e\u4ee3\u7801\u5de5\u5177\u8bbe\u8ba1\u5efa\u8bae\u3002", "conclusion": "\u5f00\u53d1\u81ea\u52a8\u5316\u3001\u4f4e\u4ee3\u7801\u5de5\u5177\u5982AdaptForge\u80fd\u6709\u6548\u5e2e\u52a9\u4ece\u4e1a\u8005\u5f00\u53d1\u9002\u5408\u8001\u5e74\u4eba\u7684\u9ad8\u53ef\u8bbf\u95ee\u6027\u3001\u81ea\u9002\u5e94\u5e94\u7528\uff0c\u5e76\u6709\u671b\u4f5c\u4e3a\u63a8\u52a8\u884c\u4e1a\u53d1\u5c55\u7684\u6807\u51c6\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2508.02997", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.02997", "abs": "https://arxiv.org/abs/2508.02997", "authors": ["Sri Durga Sai Sowmya Kadali", "Evangelos E. Papalexakis"], "title": "CoCoTen: Detecting Adversarial Inputs to Large Language Models through Latent Space Features of Contextual Co-occurrence Tensors", "comment": null, "summary": "The widespread use of Large Language Models (LLMs) in many applications marks\na significant advance in research and practice. However, their complexity and\nhard-to-understand nature make them vulnerable to attacks, especially\njailbreaks designed to produce harmful responses. To counter these threats,\ndeveloping strong detection methods is essential for the safe and reliable use\nof LLMs. This paper studies this detection problem using the Contextual\nCo-occurrence Matrix, a structure recognized for its efficacy in data-scarce\nenvironments. We propose a novel method leveraging the latent space\ncharacteristics of Contextual Co-occurrence Matrices and Tensors for the\neffective identification of adversarial and jailbreak prompts. Our evaluations\nshow that this approach achieves a notable F1 score of 0.83 using only 0.5% of\nlabeled prompts, which is a 96.6% improvement over baselines. This result\nhighlights the strength of our learned patterns, especially when labeled data\nis scarce. Our method is also significantly faster, speedup ranging from 2.3 to\n128.4 times compared to the baseline models. To support future research and\nreproducibility, we have made our implementation publicly available.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5171\u73b0\u77e9\u9635\u7684\u68c0\u6d4b\u65b9\u6cd5\uff0c\u80fd\u9ad8\u6548\u8bc6\u522bLLM\u7684\u5bf9\u6297\u4e0ejailbreak\u63d0\u793a\uff0c\u5bf9\u6570\u636e\u7a00\u7f3a\u573a\u666f\u5c24\u4e3a\u6709\u6548\uff0c\u4e14\u8fd0\u884c\u901f\u5ea6\u5927\u5e45\u5feb\u4e8e\u540c\u7c7b\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5404\u7c7b\u5e94\u7528\u5e7f\u6cdb\u90e8\u7f72\uff0c\u4f46\u56e0\u5176\u590d\u6742\u6027\u548c\u96be\u4ee5\u7406\u89e3\u6027\uff0c\u5bb9\u6613\u53d7\u5230\u653b\u51fb\uff08\u5982jailbreak\uff09\u5e76\u8f93\u51fa\u6709\u5bb3\u5185\u5bb9\uff0c\u56e0\u6b64\u6025\u9700\u9ad8\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u4fdd\u969c\u5176\u5b89\u5168\u6027\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528Contextual Co-occurrence Matrix\uff08\u4e0a\u4e0b\u6587\u5171\u73b0\u77e9\u9635\uff09\u548c\u5176\u6f5c\u5728\u7a7a\u95f4\u7279\u6027\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u5f20\u91cf\u5206\u6790\uff0c\u6765\u68c0\u6d4b\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u6297\u6027\u548cjailbreak\u63d0\u793a\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4ec5\u75280.5%\u6807\u6ce8\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0cF1\u5206\u6570\u8fbe\u52300.83\uff0c\u8f83\u57fa\u7ebf\u65b9\u6cd5\u670996.6%\u7684\u63d0\u5347\uff0c\u540c\u65f6\u68c0\u6d4b\u901f\u5ea6\u63d0\u53472.3\u5230128.4\u500d\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u5c11\u91cf\u6807\u6ce8\u6570\u636e\u6761\u4ef6\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u4f18\u5f02\u7684\u68c0\u6d4b\u8868\u73b0\uff0c\u5e76\u4e14\u6781\u5927\u52a0\u901f\u4e86\u68c0\u6d4b\u8fc7\u7a0b\uff0c\u516c\u5f00\u5b9e\u73b0\u4ee3\u7801\u6709\u52a9\u4e8e\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u590d\u73b0\u3002"}}
{"id": "2508.02998", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.02998", "abs": "https://arxiv.org/abs/2508.02998", "authors": ["Haiyang Li"], "title": "MRG-Bench: Evaluating and Exploring the Requirements of Context for Repository-Level Code Generation", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive capabilities in\ncode generation. However, current evaluation datasets suffer from issues such\nas the lack of runnable test cases, deviation from the distribution of\nreal-world code, and the ability to evaluate only the Python language. These\nlimitations undermine the credibility of the evaluation results.\n  To address these limitations, we introduce \\textbf{MRG-Bench} (Multi-language\nRepository-level Code Generation Benchmark), a novel dataset that provides a\nmore accurate evaluation of LLMs in practical repository-level code generation\ntasks. MRG-Bench has three main features: (1) practical data sourced from\nreal-world code repositories that align to the practical distribution, (2)\nmultiple programming languages support, including Python, Java, and Go, and (3)\nproject-level runnable test cases to assess the quality of the generated code.\n  Based on MRG-Bench, we conducted extensive experiments including large\nlanguage models, long-context models, and RAG-related methods. These evaluation\nresults demonstrate that \\textbf{current repository-level code generation\ntechniques suffer from significant performance deficiencies}. To further\ninvestigate why models fail, we designed novel experiments to annotate the\nunderlying causes of generation errors. The results explicitly show that the\nmajority of methods suffer from \"\\textbf{difficulty in understanding user\nrequirements},\" failing to comprehend their assigned tasks accurately.\nMoreover, the impact of different repository-level contexts on this issue\nexhibits significant disparities across different programming languages,\nsuggesting that, in practice, specialized contextual information needs to be\ndesigned for different languages.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMRG-Bench\u591a\u8bed\u8a00\u4ee3\u7801\u751f\u6210\u8bc4\u6d4b\u57fa\u51c6\uff0c\u5b9e\u9a8c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5bf9\u7528\u6237\u9700\u6c42\u7406\u89e3\u5dee\uff0c\u4e14\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u4e0a\u4e0b\u6587\u5f71\u54cd\u8f83\u5927\uff0c\u8868\u660e\u5b9e\u9645\u5e94\u7528\u9700\u66f4\u9488\u5bf9\u6027\u5730\u8bbe\u8ba1\u6a21\u578b\u548c\u8f93\u5165\u4e0a\u4e0b\u6587\u3002", "motivation": "\u76ee\u524d\u5927\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u867d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u8bc4\u6d4b\u6570\u636e\u96c6\u5b58\u5728\u53ef\u8fd0\u884c\u6027\u5dee\u3001\u53ea\u652f\u6301Python\u3001\u4e0e\u771f\u5b9e\u4ee3\u7801\u5206\u5e03\u6709\u504f\u79bb\u7684\u95ee\u9898\uff0c\u5f71\u54cd\u4e86\u8bc4\u4f30\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u63d0\u51faMRG-Bench\u6570\u636e\u96c6\uff0c\u5177\u5907\uff081\uff09\u771f\u5b9e\u4ed3\u5e93\u5206\u5e03\u7684\u4ee3\u7801\u6570\u636e\uff0c\uff082\uff09\u652f\u6301Python\u3001Java\u3001Go\u4e09\u79cd\u8bed\u8a00\uff0c\uff083\uff09\u5305\u542b\u9879\u76ee\u7ea7\u53ef\u8fd0\u884c\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5e76\u57fa\u4e8e\u6b64\u8fdb\u884c\u591a\u6a21\u578b\u548c\u591a\u65b9\u6cd5\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u73b0\u6709\u4ed3\u5e93\u7ea7\u4ee3\u7801\u751f\u6210\u6280\u672f\u6027\u80fd\u4e0d\u8db3\u3002\u8fdb\u4e00\u6b65\u5b9e\u9a8c\u5206\u6790\u53d1\u73b0\uff0c\u6a21\u578b\u591a\u6570\u95ee\u9898\u5728\u4e8e\u2018\u96be\u4ee5\u7406\u89e3\u7528\u6237\u9700\u6c42\u2019\uff0c\u800c\u4e14\u8be5\u95ee\u9898\u5728\u4e0d\u540c\u8bed\u8a00\u95f4\u4e0a\u4e0b\u6587\u5f71\u54cd\u5dee\u5f02\u663e\u8457\uff0c\u8bf4\u660e\u5b9e\u9645\u4e2d\u9700\u4e3a\u4e0d\u540c\u8bed\u8a00\u8bbe\u8ba1\u4e13\u95e8\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "conclusion": "MRG-Bench\u4e3a\u591a\u8bed\u8a00\u4ed3\u5e93\u7ea7\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u66f4\u73b0\u5b9e\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u7406\u89e3\u9700\u6c42\u548c\u591a\u8bed\u8a00\u652f\u6301\u4e0a\u7684\u663e\u8457\u4e0d\u8db3\u3002"}}
{"id": "2508.03037", "categories": ["cs.CL", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2508.03037", "abs": "https://arxiv.org/abs/2508.03037", "authors": ["Ariya Mukherjee-Gandhi", "Oliver Muellerklein"], "title": "When Algorithms Meet Artists: Topic Modeling the AI-Art Debate, 2013-2025", "comment": "18 pages, 5 figures, 5 tables", "summary": "As generative AI continues to reshape artistic production and alternate modes\nof human expression, artists whose livelihoods are most directly affected have\nraised urgent concerns about consent, transparency, and the future of creative\nlabor. However, the voices of artists are often marginalized in dominant public\nand scholarly discourse. This study presents a twelve-year analysis, from 2013\nto 2025, of English-language discourse surrounding AI-generated art. It draws\nfrom 439 curated 500-word excerpts sampled from opinion articles, news reports,\nblogs, legal filings, and spoken-word transcripts. Through a reproducible\nmethodology, we identify five stable thematic clusters and uncover a\nmisalignment between artists' perceptions and prevailing media narratives. Our\nfindings highlight how the use of technical jargon can function as a subtle\nform of gatekeeping, often sidelining the very issues artists deem most urgent.\nOur work provides a BERTopic-based methodology and a multimodal baseline for\nfuture research, alongside a clear call for deeper, transparency-driven\nengagement with artist perspectives in the evolving AI-creative landscape.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5bf9\u8fc7\u53bb\u5341\u4e8c\u5e74AI\u751f\u6210\u827a\u672f\u76f8\u5173\u82f1\u6587\u8bdd\u8bed\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u53d1\u73b0\u4e3b\u6d41\u5a92\u4f53\u5e38\u7528\u6280\u672f\u8bed\u8a00\u6392\u65a5\u4e86\u827a\u672f\u5bb6\u5173\u6ce8\u7684\u8bae\u9898\uff0c\u5021\u5bfc\u672a\u6765\u9700\u6784\u5efa\u66f4\u52a0\u900f\u660e\u3001\u5305\u5bb9\u827a\u672f\u5bb6\u89c6\u89d2\u7684\u7814\u7a76\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u65e5\u76ca\u6df1\u523b\u5730\u5f71\u54cd\u827a\u672f\u521b\u4f5c\u4ee5\u53ca\u4eba\u7c7b\u8868\u8fbe\u7684\u65b0\u65b9\u5f0f\uff0c\u827a\u672f\u5bb6\u7684\u751f\u8ba1\u53d7\u5230\u76f4\u63a5\u51b2\u51fb\uff0c\u4ed6\u4eec\u5bf9\u4e8e\u540c\u610f\u6743\u3001\u900f\u660e\u5ea6\u53ca\u521b\u610f\u52b3\u52a8\u672a\u6765\u8868\u8fbe\u51fa\u5f3a\u70c8\u62c5\u5fe7\u3002\u4f46\u5728\u4e3b\u6d41\u7684\u516c\u5171\u548c\u5b66\u672f\u8bdd\u8bed\u4e2d\uff0c\u827a\u672f\u5bb6\u7684\u58f0\u97f3\u5f80\u5f80\u88ab\u8fb9\u7f18\u5316\u3002\u8be5\u7814\u7a76\u65e8\u5728\u5206\u6790\u8fd9\u4e00\u73b0\u8c61\u80cc\u540e\u7684\u8bdd\u8bed\u504f\u79fb\u3002", "method": "\u672c\u6587\u91c7\u7528\u53ef\u590d\u73b0\u7684\u65b9\u6cd5\uff0c\u6536\u96c6\u4e862013\u5e74\u81f32025\u5e74\u95f4439\u7bc7\u4e0eAI\u751f\u6210\u827a\u672f\u76f8\u5173\u3001\u82f1\u6587\u7684500\u5b57\u7247\u6bb5\uff0c\u6765\u6e90\u6db5\u76d6\u8bc4\u8bba\u6587\u7ae0\u3001\u65b0\u95fb\u62a5\u9053\u3001\u535a\u5ba2\u3001\u6cd5\u5f8b\u6587\u4ef6\u548c\u53e3\u8bed\u8f6c\u5f55\u3002\u5229\u7528BERTopic\u4e3b\u9898\u5efa\u6a21\u6280\u672f\u8fdb\u884c\u805a\u7c7b\u5206\u6790\uff0c\u63d0\u53d6\u8bdd\u8bed\u4e2d\u7684\u5173\u952e\u4e3b\u9898\u3002", "result": "\u5171\u53d1\u73b0\u4e94\u4e2a\u7a33\u5b9a\u7684\u8bdd\u9898\u805a\u7c7b\uff0c\u63ed\u793a\u4e86\u827a\u672f\u5bb6\u89c2\u70b9\u4e0e\u4e3b\u6d41\u5a92\u4f53\u53d9\u4e8b\u4e4b\u95f4\u7684\u9519\u4f4d\uff0c\u5e76\u6307\u51fa\u6280\u672f\u672f\u8bed\u7684\u9891\u7e41\u4f7f\u7528\u5f62\u6210\u4e86\u4e00\u5b9a\u7684\u8bdd\u8bed\u95e8\u69db\uff0c\u5e38\u5e38\u5ffd\u89c6\u6216\u8fb9\u7f18\u5316\u827a\u672f\u5bb6\u6700\u5173\u5207\u7684\u95ee\u9898\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u5957\u57fa\u4e8eBERTopic\u7684\u591a\u6a21\u6001\u5206\u6790\u57fa\u7ebf\uff0c\u5f3a\u8c03\u4eca\u540e\u5728AI\u4e0e\u521b\u610f\u9886\u57df\u9700\u52a0\u5f3a\u900f\u660e\u5316\uff0c\u5145\u5206\u5438\u7eb3\u827a\u672f\u5bb6\u771f\u5b9e\u58f0\u97f3\u548c\u8bc9\u6c42\u3002"}}
{"id": "2508.03012", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03012", "abs": "https://arxiv.org/abs/2508.03012", "authors": ["Zexiong Ma", "Chao Peng", "Qunhong Zeng", "Pengfei Gao", "Yanzhen Zou", "Bing Xie"], "title": "Tool-integrated Reinforcement Learning for Repo Deep Search", "comment": null, "summary": "Issue localization, the process of identifying code locations that need\nmodification to resolve software issues, is a critical yet challenging task in\nsoftware development. The semantic gap between natural language issue\ndescriptions and faulty code requires complex multi-hop reasoning through code\ndependencies. Existing LLM-based agents attempt to address this by integrating\nrepository retrieval tools. However, this transforms issue localization into a\ndemanding task we call Repo Deep Search, which requires the LLM to effectively\nutilize various repository retrieval tools throughout a multi-step reasoning\nand navigation process. To tackle this challenge, we present ToolTrain, a\ntwo-stage tool-integrated training framework combining rejection-sampled\nsupervised fine-tuning and tool-integrated reinforcement learning to enhance\nLLMs' ability to use retrieval tools for issue localization. Experimental\nresults show that ToolTrain-trained models achieve state-of-the-art\nperformance, with our 32B model even surpassing Claude-3.7 on function-level\nlocalization. The results also show that improved localization performance\ntranslates to better end-to-end issue resolution performance. This further\ndemonstrates that training for issue localization is a viable and effective\nstrategy for improving automated software development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u540d\u4e3aToolTrain\u7684\u4e24\u9636\u6bb5\u5de5\u5177\u96c6\u6210\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5e26\u62d2\u7edd\u91c7\u6837\u7684\u6709\u76d1\u7763\u5fae\u8c03\u548c\u5de5\u5177\u5f3a\u5316\u5b66\u4e60\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6b65\u9aa4\u4ee3\u7801\u4f9d\u8d56\u63a8\u7406\u4e2d\u7684\u7f3a\u9677\u5b9a\u4f4d\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51fd\u6570\u7ea7\u5b9a\u4f4d\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u884c\u4e1a\u9886\u5148\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u867d\u96c6\u6210\u68c0\u7d22\u5de5\u5177\u8fdb\u884c\u4ed3\u5e93\u641c\u7d22\uff0c\u4f46\u9762\u5bf9\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u63cf\u8ff0\u4e0e\u4ee3\u7801\u903b\u8f91\u4e4b\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\uff0c\u591a\u6b65\u63a8\u7406\u4e0e\u5bfc\u822a\u80fd\u529b\u4ecd\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u65b9\u6cd5\u63d0\u5347\u5176\u590d\u6742\u573a\u666f\u4e0b\u7684\u5b9a\u4f4d\u548c\u68c0\u7d22\u80fd\u529b\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u4e3a\u5e26\u62d2\u7edd\u91c7\u6837\u7684\u6709\u76d1\u7763\u5fae\u8c03\uff0c\u7b2c\u4e8c\u9636\u6bb5\u4e3a\u4e0e\u68c0\u7d22\u5de5\u5177\u96c6\u6210\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u4ece\u800c\u589e\u5f3a\u6a21\u578b\u6709\u6548\u5229\u7528\u4ee3\u7801\u4ed3\u5e93\u4fe1\u606f\u7684\u80fd\u529b\u3002", "result": "ToolTrain\u8bad\u7ec3\u540e\u7684\u6a21\u578b\u5728\u51fd\u6570\u7ea7\u7f3a\u9677\u5b9a\u4f4d\u8d85\u8fc7\u4e86Claude-3.7\uff0c\u8868\u73b0\u8fbe\u5230\u4e86\u9886\u57df\u6700\u4f18\uff0c\u5e76\u4e14\u5b9a\u4f4d\u80fd\u529b\u7684\u63d0\u5347\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u7aef\u5230\u7aef\u7684\u81ea\u52a8\u5316\u95ee\u9898\u89e3\u51b3\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u9762\u5411\u7f3a\u9677\u5b9a\u4f4d\u4efb\u52a1\u8fdb\u884c\u4e13\u95e8\u8bad\u7ec3\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u8868\u73b0\uff0c\u5b9e\u73b0\u66f4\u7cbe\u51c6\u7684\u95ee\u9898\u5b9a\u4f4d\u548c\u89e3\u51b3\u3002"}}
{"id": "2508.03098", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.03098", "abs": "https://arxiv.org/abs/2508.03098", "authors": ["Haoran Wang", "Xiongxiao Xu", "Baixiang Huang", "Kai Shu"], "title": "Privacy-Aware Decoding: Mitigating Privacy Leakage of Large Language Models in Retrieval-Augmented Generation", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) enhances the factual accuracy of large\nlanguage models (LLMs) by conditioning outputs on external knowledge sources.\nHowever, when retrieval involves private or sensitive data, RAG systems are\nsusceptible to extraction attacks that can leak confidential information\nthrough generated responses. We propose Privacy-Aware Decoding (PAD), a\nlightweight, inference-time defense that adaptively injects calibrated Gaussian\nnoise into token logits during generation. PAD integrates confidence-based\nscreening to selectively protect high-risk tokens, efficient sensitivity\nestimation to minimize unnecessary noise, and context-aware noise calibration\nto balance privacy with generation quality. A \\renyi Differential Privacy (RDP)\naccountant rigorously tracks cumulative privacy loss, enabling explicit\nper-response $(\\varepsilon, \\delta)$-DP guarantees for sensitive outputs.\nUnlike prior approaches requiring retraining or corpus-level filtering, PAD is\nmodel-agnostic and operates entirely at decoding time with minimal\ncomputational overhead. Experiments on three real-world datasets demonstrate\nthat PAD substantially reduces private information leakage while preserving\nresponse utility, outperforming existing retrieval- and post-processing-based\ndefenses. Our work takes an important step toward mitigating privacy risks in\nRAG via decoding strategies, paving the way for universal and scalable privacy\nsolutions in sensitive domains. Our code is available:\nhttps://github.com/wang2226/PAD.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff08PAD\uff09\u6765\u63d0\u5347RAG\u7cfb\u7edf\u4e2d\u79c1\u5bc6\u6570\u636e\u7684\u5b89\u5168\u6027\uff0c\u901a\u8fc7\u5728\u751f\u6210\u9636\u6bb5\u5bf9\u9ad8\u98ce\u9669token\u52a0\u5165\u566a\u58f0\uff0c\u4ece\u800c\u51cf\u5c11\u4fe1\u606f\u6cc4\u9732\uff0c\u540c\u65f6\u4fdd\u8bc1\u8f93\u51fa\u8d28\u91cf\u3002", "motivation": "\u5c3d\u7ba1RAG\u80fd\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e8b\u5b9e\u6027\uff0c\u4f46\u5f53\u68c0\u7d22\u7684\u6570\u636e\u6d89\u53ca\u9690\u79c1\u65f6\uff0c\u751f\u6210\u5185\u5bb9\u5bb9\u6613\u6cc4\u9732\u654f\u611f\u4fe1\u606f\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u91cd\u8bad\u7ec3\u3001\u8981\u4e48\u6548\u7387\u4f4e\u6216\u9002\u7528\u8303\u56f4\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u9ad8\u6548\u3001\u6a21\u578b\u65e0\u5173\u4e14\u53ef\u6cdb\u5316\u7684\u9690\u79c1\u4fdd\u62a4\u65b9\u6848\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u9690\u79c1\u611f\u77e5\u89e3\u7801\uff08PAD\uff09\u65b9\u6cd5\uff1a\u5728\u751f\u6210\u9636\u6bb5\uff0c\u5bf9\u9ad8\u654f\u611f\u6027token\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7b5b\u67e5\u540e\uff0c\u65bd\u52a0\u6821\u51c6\u7684\u9ad8\u65af\u566a\u58f0\uff0c\u540c\u65f6\u5229\u7528\u6709\u6548\u7684\u654f\u611f\u6027\u4f30\u8ba1\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u566a\u58f0\u8c03\u6574\uff0c\u4ee5\u5e73\u8861\u9690\u79c1\u4e0e\u751f\u6210\u8d28\u91cf\uff0c\u518d\u7528RDP\u4f1a\u8ba1\u673a\u5236\u8ddf\u8e2a\u7d2f\u8ba1\u9690\u79c1\u635f\u5931\uff0c\u4ece\u800c\u4e3a\u6bcf\u4e00\u6b21\u751f\u6210\u63d0\u4f9b\u660e\u786e\u7684\u5dee\u5206\u9690\u79c1\u4fdd\u8bc1\u3002\u6b64\u65b9\u6cd5\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u6570\u636e\u8fc7\u6ee4\uff0c\u89e3\u7801\u9636\u6bb5\u5373\u53ef\u5b9e\u65bd\uff0c\u8ba1\u7b97\u5f00\u9500\u4f4e\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPAD\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u663e\u8457\u51cf\u5c11\u4e86\u79c1\u5bc6\u6570\u636e\u6cc4\u9732\uff08\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u4f18\uff09\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86\u751f\u6210\u7ed3\u679c\u7684\u6709\u7528\u6027\uff0c\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u6027\u548c\u5148\u8fdb\u6027\u3002", "conclusion": "PAD\u663e\u8457\u964d\u4f4e\u4e86RAG\u7cfb\u7edf\u5bf9\u79c1\u5bc6\u4fe1\u606f\u7684\u6cc4\u9732\u98ce\u9669\uff0c\u5e76\u4f18\u4e8e\u73b0\u6709\u7684\u68c0\u7d22\u578b\u6216\u540e\u5904\u7406\u578b\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u56de\u7b54\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.03215", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03215", "abs": "https://arxiv.org/abs/2508.03215", "authors": ["Dongming Jin", "Zhi Jin", "Linyu Li", "Zheng Fang", "Jia Li", "Xiaohong Chen"], "title": "A System Model Generation Benchmark from Natural Language Requirements", "comment": "16 pages, 14 figures", "summary": "System models, a critical artifact in software development, provide a formal\nabstraction of both the structural and behavioral aspects of software systems,\nwhich can facilitate the early requirements analysis and architecture design.\nHowever, developing system models remains challenging due to the specific\nsyntax of model description languages and the relative scarcity of public model\nexamples. While large language models (LLMs) have shown promise in generating\ncode with programming languages and could potentially aid in system model\ndevelopment, no benchmarks currently exist for evaluating their ability to\ngenerate system models with specific description languages. We present\nSysMBench, which comprises 151 human-curated scenarios spanning a wide range of\npopular domains and varying difficulty levels. Each scenario mainly comprises a\nnatural language requirements description, a system model expressed in a\nspecific model description language, and a visualized system model diagram. The\nrequirements description is fed as user input to the LLM, the system model with\ndescription language is used to verify if the generated system model conforms\nto the requirements, and the visualized diagram serves to support manual\nvalidation. We introduce SysMEval, a semantic-aware evaluation metric to\nevaluate the quality of generated system models. We evaluate 17 popular LLMs on\nthis task with three traditional metrics and SysMEval, from directly prompting\nto three commonly used enhancement strategies. Our in-depth evaluation shows\nthat LLMs perform poorly on SysMBench, with the highest BLEU of 4% and\nSysMEval-F1 of 62%. We release the SysMBench and its evaluation framework to\nenable future research on LLM-based system model generation.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86SysMBench\u57fa\u51c6\u6d4b\u8bd5\u96c6\u548cSysMEval\u8bed\u4e49\u611f\u77e5\u8bc4\u4ef7\u6307\u6807\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u751f\u6210\u7cfb\u7edf\u6a21\u578b\uff08\u7528\u7279\u5b9a\u7684\u6a21\u578b\u63cf\u8ff0\u8bed\u8a00\uff09\u7684\u80fd\u529b\u3002\u7ed3\u679c\u663e\u793a\u73b0\u6709LLM\u5728\u8be5\u4efb\u52a1\u4e0a\u8868\u73b0\u8f83\u5dee\u3002", "motivation": "\u7cfb\u7edf\u6a21\u578b\u662f\u8f6f\u4ef6\u5f00\u53d1\u7684\u91cd\u8981\u57fa\u7840\uff0c\u4f46\u53d7\u9650\u4e8e\u63cf\u8ff0\u8bed\u8a00\u96be\u5ea6\u53ca\u516c\u5171\u6837\u4f8b\u7a00\u7f3a\uff0c\u5f00\u53d1\u96be\u5ea6\u8f83\u5927\u3002\u867d\u7136LLM\u5c55\u73b0\u51fa\u4e00\u5b9a\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u7cfb\u7edf\u6a21\u578b\u751f\u6210\u7684\u57fa\u51c6\u548c\u7cfb\u7edf\u6027\u8bc4\u6d4b\u65b9\u6cd5\u3002\u8be5\u5de5\u4f5c\u610f\u5728\u586b\u8865\u6b64\u7a7a\u767d\u3002", "method": "\u4f5c\u8005\u5efa\u7acb\u4e86\u5305\u542b151\u4e2a\u4eba\u5de5\u7b56\u5212\u573a\u666f\u7684SysMBench\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u573a\u666f\u5305\u542b\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u63cf\u8ff0\u3001\u7cfb\u7edf\u6a21\u578b\uff08\u57fa\u4e8e\u7279\u5b9a\u63cf\u8ff0\u8bed\u8a00\uff09\uff0c\u4ee5\u53ca\u53ef\u89c6\u5316\u6a21\u578b\u56fe\uff0c\u540c\u65f6\u63d0\u51fa\u4e86SysMEval\u6307\u6807\uff1b\u8bc4\u4f30\u4e8617\u4e2a\u4e3b\u6d41LLM\u57fa\u4e8e\u76f4\u63a5\u63d0\u793a\u53ca\u4e09\u79cd\u589e\u5f3a\u7b56\u7565\u4e0b\u7684\u7cfb\u7edf\u5efa\u6a21\u80fd\u529b\u3002", "result": "\u6700\u4f18\u6a21\u578b\u5728BLEU\u6307\u6807\u4e0a\u4ec5\u5f974%\uff0cSysMEval-F1\u6700\u9ad8\u4ec562%\u3002\u663e\u793a\u73b0\u6709LLM\u5bf9\u4e8e\u7cfb\u7edf\u5efa\u6a21\u4efb\u52a1\u7684\u7406\u89e3\u4e0e\u751f\u6210\u80fd\u529b\u4ecd\u6709\u8f83\u5927\u63d0\u5347\u7a7a\u95f4\u3002\u4f5c\u8005\u516c\u5f00\u4e86\u6570\u636e\u96c6\u53ca\u5de5\u5177\u3002", "conclusion": "\u5f53\u524d\u4e3b\u6d41LLM\u5728\u7cfb\u7edf\u5efa\u6a21\u80fd\u529b\u65b9\u9762\u8868\u73b0\u8fdc\u672a\u8fbe\u6807\uff0c\u547c\u5401\u4eca\u540e\u7814\u7a76\u9488\u5bf9\u7cfb\u7edf\u6a21\u578b\u751f\u6210\u8fdb\u884c\u66f4\u591a\u63a2\u7d22\u3002SysMBench\u548c\u8bc4\u4ef7\u6846\u67b6\u7684\u53d1\u5e03\u4e3a\u540e\u7eed\u76f8\u5173\u9886\u57df\u7814\u7a76\u63d0\u4f9b\u4e86\u5207\u5b9e\u5de5\u5177\u548c\u6570\u636e\u3002"}}
{"id": "2508.03678", "categories": ["cs.CL", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.03678", "abs": "https://arxiv.org/abs/2508.03678", "authors": ["Yangtian Zi", "Harshitha Menon", "Arjun Guha"], "title": "More Than a Score: Probing the Impact of Prompt Specificity on LLM Code Generation", "comment": null, "summary": "State-of-the-art Large Language Models (LLMs) achieve high pass@1 on general\nbenchmarks like HumanEval but underperform on specialized suites such as\nParEval. Is this due to LLMs missing domain knowledge or insufficient prompt\ndetail is given? To answer this, we introduce PartialOrderEval, which augments\nany code generation benchmark with a partial order of prompts from minimal to\nmaximally detailed. Applying it to HumanEval and both serial and OpenMP subsets\nof ParEval, we measure how pass@1 scales with prompt specificity. Our\nexperiments with Llama-3.x and Qwen2.5-Coder demonstrate varying degrees of\nprompt sensitivity across different tasks, and a qualitative analysis\nhighlights explicit I/O specifications, edge-case handling, and stepwise\nbreakdowns as the key drivers of prompt detail improvement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5bf9\u63d0\u793a\u7ec6\u8282\u4ece\u4f4e\u5230\u9ad8\u6392\u5e8f\u7684\u8bc4\u6d4b\u65b9\u6cd5\uff0c\u53d1\u73b0\u5927\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u63d0\u793a\u8d8a\u8be6\u7ec6\uff0c\u8868\u73b0\u63d0\u5347\u8d8a\u5927\u3002\u8fb9\u754c\u5904\u7406\u3001I/O\u89c4\u8303\u53ca\u5206\u6b65\u63d0\u793a\u5c24\u5176\u5173\u952e\u3002", "motivation": "\u5f53\u524dLLM\u867d\u80fd\u5728\u4e00\u822c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u4e13\u4e1a\u9886\u57df\u5b58\u5728\u660e\u663e\u5dee\u8ddd\u3002\u672c\u6587\u5173\u6ce8\u8fd9\u4e00\u5dee\u8ddd\u662f\u5426\u7531\u6a21\u578b\u77e5\u8bc6\u5c40\u9650\u8fd8\u662f\u63d0\u793a\u7ec6\u8282\u4e0d\u8db3\u5bfc\u81f4\uff0c\u65e8\u5728\u5398\u6e05\u4e0d\u540c\u63d0\u793a\u7ec6\u5316\u7a0b\u5ea6\u5bf9\u6a21\u578b\u8868\u73b0\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u6d4b\u65b9\u6cd5PartialOrderEval\uff0c\u53ef\u5bf9\u5404\u79cd\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u96c6\u6784\u5efa\u4ece\u6700\u7b80\u5355\u5230\u6700\u8be6\u7ec6\u7684\u63d0\u793a\u5e8f\u5217\u3002\u901a\u8fc7\u5728\u4eba\u7c7b\u8bc4\u6d4b\u96c6(HumanEval)\u548cParEval\uff08\u5305\u542b\u4e32\u884c\u53caOpenMP\u5b50\u96c6\uff09\u4e0a\uff0c\u91c7\u7528Llama-3.x\u548cQwen2.5-Coder\u7b49\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7cfb\u7edf\u6d4b\u91cf\u4e86\u4ee3\u7801\u751f\u6210\u51c6\u786e\u7387\u968f\u63d0\u793a\u7ec6\u81f4\u7a0b\u5ea6\u7684\u53d8\u5316\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u6a21\u578b\u5728\u5904\u7406\u4e0d\u540c\u4efb\u52a1\u65f6\u5bf9\u63d0\u793a\u654f\u611f\u6027\u5b58\u5728\u5dee\u5f02\uff0c\u8be6\u7ec6\u7684I/O\u89c4\u8303\u3001\u8fb9\u754c\u60c5\u51b5\u7684\u5904\u7406\u548c\u9010\u6b65\u5206\u89e3\u662f\u63d0\u5347\u63d0\u793a\u6709\u6548\u6027\u7684\u4e3b\u8981\u56e0\u7d20\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9762\u5bf9\u4e0d\u540c\u7ec6\u5316\u7a0b\u5ea6\u7684\u63d0\u793a\u65f6\uff0c\u5176\u8868\u73b0\u4f1a\u6709\u663e\u8457\u53d8\u5316\uff0c\u63d0\u793a\u7ec6\u8282\u7684\u4e30\u5bcc\u7a0b\u5ea6\u662f\u5f71\u54cd\u4ee3\u7801\u751f\u6210\u51c6\u786e\u6027\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2508.03110", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.03110", "abs": "https://arxiv.org/abs/2508.03110", "authors": ["Zizhong Li", "Haopeng Zhang", "Jiawei Zhang"], "title": "Token-Level Precise Attack on RAG: Searching for the Best Alternatives to Mislead Generation", "comment": null, "summary": "While large language models (LLMs) have achieved remarkable success in\nproviding trustworthy responses for knowledge-intensive tasks, they still face\ncritical limitations such as hallucinations and outdated knowledge. To address\nthese issues, the retrieval-augmented generation (RAG) framework enhances LLMs\nwith access to external knowledge via a retriever, enabling more accurate and\nreal-time outputs about the latest events. However, this integration brings new\nsecurity vulnerabilities: the risk that malicious content in the external\ndatabase can be retrieved and used to manipulate model outputs. Although prior\nwork has explored attacks on RAG systems, existing approaches either rely\nheavily on access to the retriever or fail to jointly consider both retrieval\nand generation stages, limiting their effectiveness, particularly in black-box\nscenarios. To overcome these limitations, we propose Token-level Precise Attack\non the RAG (TPARAG), a novel framework that targets both white-box and\nblack-box RAG systems. TPARAG leverages a lightweight white-box LLM as an\nattacker to generate and iteratively optimize malicious passages at the token\nlevel, ensuring both retrievability and high attack success in generation.\nExtensive experiments on open-domain QA datasets demonstrate that TPARAG\nconsistently outperforms previous approaches in retrieval-stage and end-to-end\nattack effectiveness. These results further reveal critical vulnerabilities in\nRAG pipelines and offer new insights into improving their robustness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9 RAG \u7cfb\u7edf\u7684\u65b0\u578b token \u7ea7\u653b\u51fb\uff08TPARAG\uff09\uff0c\u5728\u68c0\u7d22\u548c\u751f\u6210\u4e24\u4e2a\u73af\u8282\u5747\u6709\u6548\uff0c\u4f18\u4e8e\u524d\u4eba\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e86\u73b0\u6709 RAG \u7cfb\u7edf\u7684\u5b89\u5168\u9690\u60a3\u5e76\u4e3a\u9632\u5fa1\u63d0\u4f9b\u4e86\u542f\u793a\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4ecd\u9762\u4e34\u5e7b\u89c9\u548c\u77e5\u8bc6\u8fc7\u65f6\u7b49\u95ee\u9898\u3002RAG \u6846\u67b6\u901a\u8fc7\u5f15\u5165\u5916\u90e8\u77e5\u8bc6\u589e\u5f3a\u4e86 LLM \u7684\u80fd\u529b\uff0c\u4f46\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff1a\u5916\u90e8\u6570\u636e\u5e93\u4e2d\u7684\u6076\u610f\u5185\u5bb9\u53ef\u80fd\u88ab\u68c0\u7d22\u5e76\u64cd\u63a7\u6a21\u578b\u8f93\u51fa\u3002\u76ee\u524d\u5bf9 RAG \u7cfb\u7edf\u7684\u653b\u51fb\u7814\u7a76\u5b58\u5728\u5c40\u9650\uff0c\u7279\u522b\u662f\u5728\u9ed1\u76d2\u573a\u666f\u4e0b\u653b\u51fb\u6548\u679c\u4e0d\u7406\u60f3\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Token-level Precise Attack on the RAG (TPARAG) \u7684\u65b0\u578b\u653b\u51fb\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u8f7b\u91cf\u7ea7\u767d\u76d2 LLM \u4f5c\u4e3a\u653b\u51fb\u8005\uff0c\u5728 token \u7ea7\u522b\u751f\u6210\u5e76\u8fed\u4ee3\u4f18\u5316\u6076\u610f\u6bb5\u843d\uff0c\u540c\u65f6\u517c\u987e\u53ef\u68c0\u7d22\u6027\u548c\u751f\u6210\u9636\u6bb5\u7684\u9ad8\u653b\u51fb\u6210\u529f\u7387\uff0c\u9002\u7528\u4e8e\u767d\u76d2\u548c\u9ed1\u76d2 RAG \u7cfb\u7edf\u3002", "result": "TPARAG \u5728\u5f00\u653e\u57df\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u663e\u793a\uff0c\u5176\u5bf9\u68c0\u7d22\u9636\u6bb5\u548c\u7aef\u5230\u7aef\u653b\u51fb\u7684\u6709\u6548\u6027\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "TPARAG \u63ed\u793a\u4e86 RAG \u6d41\u6c34\u7ebf\u4e2d\u7684\u91cd\u8981\u5b89\u5168\u6f0f\u6d1e\uff0c\u5e76\u4e3a\u63d0\u5347 RAG \u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002"}}
{"id": "2508.03258", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03258", "abs": "https://arxiv.org/abs/2508.03258", "authors": ["Yueyue Liu", "Hongyu Zhang", "Yuantian Miao"], "title": "SmartLLMs Scheduler: A Framework for Cost-Effective LLMs Utilization", "comment": null, "summary": "Large Language Models (LLMs) such as GPT-4 and Llama have shown remarkable\ncapabilities in a variety of software engineering tasks. Despite the\nadvancements, their practical deployment faces challenges, including high\nfinancial costs, long response time, and varying performance, especially when\nhandling a large number of queries (jobs). Existing optimization strategies for\ndeploying LLMs for diverse tasks focus on static scheduling, which requires\nextensive training data for performance prediction, increasing the\ncomputational costs and limiting the applicability and flexibility. In this\npaper, we propose the SmartLLMs Scheduler (SLS), a dynamic and cost-effective\nscheduling solution. The key idea is to learn LLMs' performance on diverse\ntasks and incorporate their real-time feedback to update strategies\nperiodically. Specifically, SLS incorporates three key components, including an\nAdaptive Cache Manager, a Performance-Cost Optimized Scheduler, and a Dynamic\nUpdate Manager. The Cache Manager stores the outputs of previously processed\nqueries and employs an adaptive strategy to reduce redundant computations and\nminimize response times. For queries not found in the cache, the Scheduler\ndynamically allocates them to the most suitable LLM based on the predicted\nperformance and cost from models that take both query-specific and LLM-specific\nfeatures as input. The Update Manager continuously refines the cache and\nscheduling strategies based on real-time feedback from the assigned queries to\nenhance decision-making and adapt to evolving task characteristics. To evaluate\nthe effectiveness of SLS, we conduct extensive experiments on two LLM-based\nsoftware engineering tasks, including log parsing and code generation. The\nresults show that SLS significantly outperforms the baseline methods, achieving\nan average performance improvement of 198.82% and an average processing time\nreduction of 63.28%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u52a8\u6001\u8c03\u5ea6\u53ca\u4f18\u5316LLM\u4efb\u52a1\u5206\u914d\u7684\u7cfb\u7edfSmartLLMs Scheduler\uff08SLS\uff09\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u964d\u4f4e\u54cd\u5e94\u65f6\u95f4\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u9762\u4e34\u9ad8\u6602\u6210\u672c\u3001\u54cd\u5e94\u7f13\u6162\u548c\u6027\u80fd\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\uff1b\u73b0\u6709\u4f18\u5316\u7b56\u7565\u591a\u4e3a\u9759\u6001\u8c03\u5ea6\uff0c\u4f9d\u8d56\u5927\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u9650\u5236\u4e86\u7075\u6d3b\u6027\u4e0e\u5b9e\u7528\u6027\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u79cd\u52a8\u6001\u3001\u53ef\u81ea\u9002\u5e94\u5e76\u964d\u4f4e\u6210\u672c\u7684\u8c03\u5ea6\u673a\u5236\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSmartLLMs Scheduler (SLS)\u7684\u52a8\u6001\u4e0e\u9ad8\u6027\u4ef7\u6bd4\u7684\u8c03\u5ea6\u65b9\u6848\u3002SLS\u5305\u542b\u81ea\u9002\u5e94\u7f13\u5b58\u7ba1\u7406\u5668\u3001\u6027\u80fd-\u6210\u672c\u4f18\u5316\u8c03\u5ea6\u5668\u53ca\u52a8\u6001\u66f4\u65b0\u7ba1\u7406\u5668\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff0c\u80fd\u7efc\u5408\u5229\u7528LLMs\u7684\u53cd\u9988\u5b9e\u65f6\u8c03\u6574\u4efb\u52a1\u5206\u914d\u3002\u5176\u6838\u5fc3\u505a\u6cd5\u662f\u7f13\u5b58\u5df2\u5904\u7406\u7684\u67e5\u8be2\uff0c\u5229\u7528\u81ea\u9002\u5e94\u7b56\u7565\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\uff0c\u5bf9\u672a\u547d\u4e2d\u7f13\u5b58\u7684\u67e5\u8be2\uff0c\u52a8\u6001\u7ed3\u5408\u4efb\u52a1\u548c\u6a21\u578b\u7279\u5f81\u5206\u914d\u7ed9\u6700\u4f18\u7684LLM\u3002\u6240\u6709\u5206\u914d\u548c\u7f13\u5b58\u7b56\u7565\u53ef\u6839\u636e\u67e5\u8be2\u5b9e\u65f6\u53cd\u9988\u4e0d\u65ad\u4f18\u5316\u3002", "result": "\u5728\u65e5\u5fd7\u89e3\u6790\u548c\u4ee3\u7801\u751f\u6210\u4e24\u4e2a\u573a\u666f\u4e0b\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSLS\u8f83\u57fa\u7ebf\u65b9\u6cd5\u5e73\u5747\u6027\u80fd\u63d0\u5347198.82%\uff0c\u5904\u7406\u65f6\u95f4\u7f29\u77ed63.28%\u3002", "conclusion": "SLS\u80fd\u591f\u901a\u8fc7\u81ea\u9002\u5e94\u548c\u52a8\u6001\u4f18\u5316\u7b56\u7565\u663e\u8457\u63d0\u5347LLMs\u7684\u5b9e\u7528\u8868\u73b0\uff0c\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u7075\u6d3b\u7684LLM\u90e8\u7f72\u3002"}}
{"id": "2508.03112", "categories": ["cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.03112", "abs": "https://arxiv.org/abs/2508.03112", "authors": ["Motaz Saad", "David Langlois", "Kamel Smaili"], "title": "Cross-lingual Opinions and Emotions Mining in Comparable Documents", "comment": "16 pages, 5 figures", "summary": "Comparable texts are topic-aligned documents in multiple languages that are\nnot direct translations. They are valuable for understanding how a topic is\ndiscussed across languages. This research studies differences in sentiments and\nemotions across English-Arabic comparable documents. First, texts are annotated\nwith sentiment and emotion labels. We apply a cross-lingual method to label\ndocuments with opinion classes (subjective/objective), avoiding reliance on\nmachine translation. To annotate with emotions (anger, disgust, fear, joy,\nsadness, surprise), we manually translate the English WordNet-Affect (WNA)\nlexicon into Arabic, creating bilingual emotion lexicons used to label the\ncomparable corpora. We then apply a statistical measure to assess the agreement\nof sentiments and emotions in each source-target document pair. This comparison\nis especially relevant when the documents originate from different sources. To\nour knowledge, this aspect has not been explored in prior literature. Our study\nincludes English-Arabic document pairs from Euronews, BBC, and Al-Jazeera\n(JSC). Results show that sentiment and emotion annotations align when articles\ncome from the same news agency and diverge when they come from different ones.\nThe proposed method is language-independent and generalizable to other language\npairs.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u8bed\u8a00\uff08\u82f1\u6587-\u963f\u62c9\u4f2f\u6587\uff09\u6bd4\u8f83\u4e3b\u9898\u6587\u672c\u60c5\u611f\u4e0e\u60c5\u7eea\u8868\u8fbe\u5dee\u5f02\u7684\u65b9\u6cd5\uff0c\u907f\u514d\u4e86\u4f9d\u8d56\u673a\u5668\u7ffb\u8bd1\uff0c\u5e76\u6784\u5efa\u4e86\u53cc\u8bed\u60c5\u7eea\u8bcd\u5178\u3002\u5b9e\u9a8c\u8bc1\u660e\u540c\u4e00\u65b0\u95fb\u673a\u6784\u7684\u4e0d\u540c\u8bed\u8a00\u62a5\u9053\u60c5\u611f/\u60c5\u7eea\u66f4\u4e00\u81f4\uff0c\u4e0d\u540c\u673a\u6784\u7684\u62a5\u9053\u5dee\u5f02\u66f4\u5927\uff0c\u8be5\u65b9\u6cd5\u53ef\u7528\u4e8e\u5176\u4ed6\u8bed\u8a00\u5bf9\u3002", "motivation": "\u7406\u89e3\u4e0d\u540c\u8bed\u8a00\u4e2d\u76f8\u540c\u4e3b\u9898\u7684\u6587\u672c\u5728\u60c5\u611f\u548c\u60c5\u7eea\u8868\u8fbe\u65b9\u9762\u7684\u5dee\u5f02\uff0c\u5c24\u5176\u5173\u6ce8\u82f1\u6587\u548c\u963f\u62c9\u4f2f\u6587\u4e4b\u95f4\u7684\u53ef\u6bd4\u6587\u672c\uff0c\u4e30\u5bcc\u8de8\u8bed\u8a00\u6bd4\u8f83\u3001\u5a92\u4f53\u62a5\u9053\u503e\u5411\u6027\u5206\u6790\u7b49\u76f8\u5173\u7814\u7a76\u9886\u57df\u3002", "method": "\u9996\u5148\u4e3a\u82f1\u963f\u53ef\u6bd4\u6587\u672c\u624b\u52a8\u6ce8\u91ca\u60c5\u611f\u548c\u60c5\u7eea\u6807\u7b7e\u3002\u91c7\u7528\u65e0\u9700\u673a\u5668\u7ffb\u8bd1\u7684\u8de8\u8bed\u8a00\u65b9\u6cd5\u5bf9\u6587\u672c\u8fdb\u884c\u4e3b\u89c2/\u5ba2\u89c2\u60c5\u611f\u7c7b\u522b\u6807\u6ce8\u3002\u4e3a\u6807\u6ce8\u60c5\u7eea\uff08\u6124\u6012\u3001\u538c\u6076\u3001\u6050\u60e7\u3001\u5feb\u4e50\u3001\u60b2\u4f24\u3001\u60ca\u8bb6\uff09\uff0c\u624b\u52a8\u5c06\u82f1\u6587WordNet-Affect\u8bcd\u5178\u7ffb\u8bd1\u4e3a\u963f\u62c9\u4f2f\u8bed\uff0c\u6784\u5efa\u53cc\u8bed\u60c5\u7eea\u8bcd\u5178\uff0c\u5e76\u7528\u5176\u6807\u6ce8\u8bed\u6599\u5e93\u3002\u6700\u540e\u5e94\u7528\u7edf\u8ba1\u65b9\u6cd5\u8861\u91cf\u5404\u5bf9\u6e90-\u76ee\u6807\u6587\u6863\u5728\u60c5\u611f\u4e0e\u60c5\u7eea\u4e0a\u7684\u4e00\u81f4\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u6587\u6863\u6765\u81ea\u540c\u4e00\u65b0\u95fb\u673a\u6784\u65f6\uff0c\u60c5\u611f\u548c\u60c5\u7eea\u6807\u6ce8\u6709\u8f83\u9ad8\u7684\u4e00\u81f4\u6027\uff1b\u800c\u5f53\u6587\u6863\u6765\u81ea\u4e0d\u540c\u65b0\u95fb\u673a\u6784\u65f6\uff0c\u8fd9\u79cd\u4e00\u81f4\u6027\u8f83\u4f4e\uff0c\u5b58\u5728\u66f4\u591a\u5dee\u5f02\u3002\u63d0\u51fa\u7684\u65b9\u6cd5\u5177\u6709\u8bed\u8a00\u65e0\u5173\u6027\uff0c\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u8bed\u8a00\u5bf9\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u8de8\u8bed\u8a00\u3001\u53ef\u63a8\u5e7f\u7684\u65b9\u6cd5\u53ef\u6709\u6548\u5bf9\u4e0d\u540c\u8bed\u8a00\u540c\u4e3b\u9898\u6587\u672c\u7684\u60c5\u611f\u548c\u60c5\u7eea\u8fdb\u884c\u5bf9\u9f50\u548c\u6bd4\u8f83\uff0c\u53d1\u73b0\u4e86\u65b0\u95fb\u6765\u6e90\u5bf9\u60c5\u611f/\u60c5\u7eea\u8868\u8fbe\u4e00\u81f4\u6027\u7684\u663e\u8457\u5f71\u54cd\u3002"}}
{"id": "2508.03298", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03298", "abs": "https://arxiv.org/abs/2508.03298", "authors": ["Kristian Kolthoff", "Felix Kretzer", "Christian Bartelt", "Alexander Maedche", "Simone Paolo Ponzetto"], "title": "GUI-ReRank: Enhancing GUI Retrieval with Multi-Modal LLM-based Reranking", "comment": null, "summary": "GUI prototyping is a fundamental component in the development of modern\ninteractive systems, which are now ubiquitous across diverse application\ndomains. GUI prototypes play a critical role in requirements elicitation by\nenabling stakeholders to visualize, assess, and refine system concepts\ncollaboratively. Moreover, prototypes serve as effective tools for early\ntesting, iterative evaluation, and validation of design ideas with both end\nusers and development teams. Despite these advantages, the process of\nconstructing GUI prototypes remains resource-intensive and time-consuming,\nfrequently demanding substantial effort and expertise. Recent research has\nsought to alleviate this burden through NL-based GUI retrieval approaches,\nwhich typically rely on embedding-based retrieval or tailored ranking models\nfor specific GUI repositories. However, these methods often suffer from limited\nretrieval performance and struggle to generalize across arbitrary GUI datasets.\nIn this work, we present GUI-ReRank, a novel framework that integrates rapid\nembedding-based constrained retrieval models with highly effective MLLM-based\nreranking techniques. GUI-ReRank further introduces a fully customizable GUI\nrepository annotation and embedding pipeline, enabling users to effortlessly\nmake their own GUI repositories searchable, which allows for rapid discovery of\nrelevant GUIs for inspiration or seamless integration into customized LLM-based\nRAG workflows. We evaluated our approach on an established NL-based GUI\nretrieval benchmark, demonstrating that GUI-ReRank significantly outperforms\nSOTA tailored LTR models in both retrieval accuracy and generalizability.\nAdditionally, we conducted a comprehensive cost and efficiency analysis of\nemploying MLLMs for reranking, providing valuable insights regarding the\ntrade-offs between retrieval effectiveness and computational resources. Video:\nhttps://youtu.be/_7x9UCh82ug", "AI": {"tldr": "\u63d0\u51fa\u4e86GUI-ReRank\uff0c\u4e00\u4e2a\u96c6\u6210\u5d4c\u5165\u68c0\u7d22\u4e0eMLLM\u91cd\u6392\u5e8f\u3001\u652f\u6301\u81ea\u5b9a\u4e49GUI\u4ed3\u5e93\u7684NL-GUI\u68c0\u7d22\u6846\u67b6\uff0c\u5728\u51c6\u786e\u7387\u4e0e\u6cdb\u5316\u6027\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u5176\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u73b0\u6709\u7684GUI\u539f\u578b\u5f00\u53d1\u6d41\u7a0b\u8017\u65f6\u4e14\u9700\u8981\u5927\u91cf\u4eba\u529b\uff0c\u4f20\u7edf\u7684\u81ea\u7136\u8bed\u8a00\u68c0\u7d22GUI\u65b9\u6cd5\u5b58\u5728\u6cdb\u5316\u80fd\u529b\u548c\u6027\u80fd\u74f6\u9888\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u8f7b\u91cf\u5316\u4e14\u6613\u4e8e\u5e94\u7528\u4e8e\u591a\u6837GUI\u4ed3\u5e93\u7684\u68c0\u7d22\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u5feb\u901f\u7684\u57fa\u4e8e\u5d4c\u5165\u7684\u7ea6\u675f\u6027\u68c0\u7d22\uff0c\u7528\u4e8e\u521d\u6b65\u8fc7\u6ee4GUI\u5019\u9009\u30022\uff09\u7ed3\u5408\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u8fdb\u884c\u9ad8\u6548\u91cd\u6392\u5e8f\uff0c\u63d0\u5347\u6700\u7ec8\u68c0\u7d22\u6548\u679c\u30023\uff09\u63d0\u51fa\u53ef\u5b8c\u5168\u81ea\u5b9a\u4e49\u7684GUI\u4ed3\u5e93\u6ce8\u91ca\u4e0e\u5d4c\u5165\u6d41\u7a0b\uff0c\u4f7f\u79c1\u6709GUI\u5e93\u652f\u6301\u81ea\u7136\u8bed\u8a00\u68c0\u7d22\u30024\uff09\u5728\u6807\u51c6\u8bc4\u6d4b\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u6027\u80fd\uff0c\u5e76\u7cfb\u7edf\u5206\u6790\u4e86MLLM\u91cd\u6392\u5e8f\u7684\u6548\u7387/\u8d44\u6e90\u6d88\u8017\u3002", "result": "\u6240\u63d0\u51fa\u7684GUI-ReRank\u6846\u67b6\u5728\u81ea\u7136\u8bed\u8a00GUI\u68c0\u7d22\u57fa\u51c6\u4efb\u52a1\u4e0a\uff0c\u6548\u679c\u660e\u663e\u8d85\u8d8a\u4e86\u5f53\u524d\u6700\u65b0\u7684\u4e13\u7528\u6392\u5e8f\u6a21\u578b\uff08LTR\uff09\uff0c\u540c\u65f6\u5177\u5907\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6b64\u5916\uff0c\u8fd8\u7ed9\u51fa\u4e86\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08MLLMs\uff09\u91cd\u6392\u5e8f\u7684\u6210\u672c\u4e0e\u6548\u7387\u5206\u6790\uff0c\u4f18\u5316\u4e86\u68c0\u7d22\u6548\u679c\u4e0e\u8ba1\u7b97\u8d44\u6e90\u4e4b\u95f4\u7684\u6743\u8861\u3002", "conclusion": "GUI-ReRank\u663e\u8457\u63d0\u5347\u4e86GUI\u539f\u578b\u7684\u81ea\u7136\u8bed\u8a00\u68c0\u7d22\u6027\u80fd\uff0c\u4e3a\u5f00\u53d1\u8005\u4e0e\u8bbe\u8ba1\u56e2\u961f\u5e26\u6765\u4e86\u7075\u6d3b\u7684GUI\u53d1\u73b0\u4e0e\u590d\u7528\u5de5\u5177\uff0c\u540c\u65f6\u5176\u5f00\u6e90\u7684\u6ce8\u91ca\u53ca\u5d4c\u5165\u6d41\u7a0b\u52a9\u529b\u4e2a\u6027\u5316GUI\u6570\u636e\u7684\u96c6\u6210\uff0c\u63a8\u52a8\u4e86LLM\u9a71\u52a8RAG\u6d41\u7a0b\u5728GUI\u5f00\u53d1\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2508.03137", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03137", "abs": "https://arxiv.org/abs/2508.03137", "authors": ["Ge Shi", "Kaiyu Huang", "Guochen Feng"], "title": "Long Story Generation via Knowledge Graph and Literary Theory", "comment": null, "summary": "The generation of a long story consisting of several thousand words is a\nsub-task in the field of long text generation~(LTG). Previous research has\naddressed this challenge through outline-based generation, which employs a\nmulti-stage method for generating outlines into stories. However, this approach\nsuffers from two common issues: almost inevitable theme drift caused by the\nloss of memory of previous outlines, and tedious plots with incoherent logic\nthat are less appealing to human readers.\n  In this paper, we propose the multi-agent Story Generator structure to\nimprove the multi-stage method, using large language models~(LLMs) as the core\ncomponents of agents. To avoid theme drift, we introduce a memory storage model\ncomprising two components: a long-term memory storage that identifies the most\nimportant memories, thereby preventing theme drift; and a short-term memory\nstorage that retains the latest outlines from each generation round. To\nincorporate engaging elements into the story, we design a story theme obstacle\nframework based on literary narratology theory that introduces uncertain\nfactors and evaluation criteria to generate outline. This framework calculates\nthe similarity of the former storyline and enhances the appeal of the story by\nbuilding a knowledge graph and integrating new node content. Additionally, we\nestablish a multi-agent interaction stage to simulate writer-reader interaction\nthrough dialogue and revise the story text according to feedback, to ensure it\nremains consistent and logical. Evaluations against previous methods\ndemonstrate that our approach can generate higher-quality long stories.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u7ed3\u5408\u5927\u6a21\u578b\u4e0e\u591a\u667a\u80fd\u4f53\u8bb0\u5fc6\u3001\u4e92\u52a8\u53cd\u9988\u4e0e\u77e5\u8bc6\u56fe\u8c31\u7684\u65b0\u67b6\u6784\uff0c\u7cfb\u7edf\u6027\u89e3\u51b3\u4e86\u4f20\u7edf\u957f\u7bc7\u6545\u4e8b\u751f\u6210\u7684\u4e3b\u9898\u6f02\u79fb\u548c\u60c5\u8282\u5355\u8c03\u7b49\u6838\u5fc3\u96be\u9898\uff0c\u6548\u679c\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u4ee5\u5f80\u957f\u7bc7\u6545\u4e8b\u81ea\u52a8\u751f\u6210\u65b9\u6cd5\uff08\u4e3b\u8981\u901a\u8fc7\u63d0\u7eb2\u5206\u9636\u6bb5\u751f\u6210\uff09\u5b58\u5728\u4e25\u91cd\u7684\u4e3b\u9898\u6f02\u79fb\u4ee5\u53ca\u60c5\u8282\u5355\u8c03\u3001\u903b\u8f91\u4e0d\u8fde\u8d2f\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u6545\u4e8b\u7f3a\u4e4f\u5438\u5f15\u529b\u3002\u4f5c\u8005\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\uff0c\u5e0c\u671b\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u7684\u957f\u6545\u4e8b\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u6545\u4e8b\u751f\u6210\u7ed3\u6784\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e3a\u667a\u80fd\u4f53\u6838\u5fc3\uff0c\u5e76\u5f15\u5165\u4e24\u5c42\u8bb0\u5fc6\u5b58\u50a8\uff08\u957f\u671f\u4e0e\u77ed\u671f\u8bb0\u5fc6\uff09\u9632\u6b62\u4e3b\u9898\u6f02\u79fb\u3002\u540c\u65f6\uff0c\u57fa\u4e8e\u6587\u5b66\u53d9\u4e8b\u7406\u8bba\u8bbe\u8ba1\u6545\u4e8b\u4e3b\u9898\u969c\u788d\u6846\u67b6\u6765\u6784\u5efa\u66f4\u7cbe\u5f69\u7684\u60c5\u8282\uff0c\u5f15\u5165\u4e0d\u786e\u5b9a\u56e0\u7d20\u4e0e\u8bc4\u4ef7\u6807\u51c6\uff1b\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u6545\u4e8b\u5185\u5bb9\uff1b\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u6a21\u62df\u201c\u4f5c\u5bb6-\u8bfb\u8005\u201d\u5bf9\u8bdd\u53cd\u9988\uff0c\u4e0d\u65ad\u4fee\u6b63\u6587\u672c\u4ee5\u4fdd\u8bc1\u4e00\u81f4\u6027\u548c\u903b\u8f91\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u751f\u6210\u903b\u8f91\u66f4\u8fde\u8d2f\u3001\u5185\u5bb9\u66f4\u5438\u5f15\u4eba\u7684\u9ad8\u8d28\u91cf\u957f\u7bc7\u6545\u4e8b\uff0c\u4f18\u4e8e\u4ee5\u5f80\u4e3b\u8981\u57fa\u4e8e\u63d0\u7eb2\u5206\u9636\u6bb5\u751f\u6210\u7684\u65b9\u6cd5\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u7ed3\u6784\u7ed3\u5408\u8bb0\u5fc6\u5b58\u50a8\u3001\u53d9\u8ff0\u7406\u8bba\u548c\u4e92\u52a8\u53cd\u9988\u673a\u5236\uff0c\u6709\u6548\u6539\u5584\u4e86\u957f\u7bc7\u6545\u4e8b\u81ea\u52a8\u751f\u6210\u7684\u4e3b\u9898\u4e00\u81f4\u6027\u3001\u903b\u8f91\u8fde\u8d2f\u6027\u53ca\u8da3\u5473\u6027\u3002"}}
{"id": "2508.03329", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03329", "abs": "https://arxiv.org/abs/2508.03329", "authors": ["Mari Ashiga", "Vardan Voskanyan", "Fateme Dinmohammadi", "Jingzhi Gong", "Paul Brookes", "Matthew Truscott", "Rafail Giavrimis", "Mike Basios", "Leslie Kanthan", "Wei Jie"], "title": "Industrial LLM-based Code Optimization under Regulation: A Mixture-of-Agents Approach", "comment": "Submitted to ASE'25 Industry Showcase", "summary": "Recent advancements in Large Language Models (LLMs) for code optimization\nhave enabled industrial platforms to automate software performance engineering\nat unprecedented scale and speed. Yet, organizations in regulated industries\nface strict constraints on which LLMs they can use - many cannot utilize\ncommercial models due to data privacy regulations and compliance requirements,\ncreating a significant challenge for achieving high-quality code optimization\nwhile maintaining cost-effectiveness. We address this by implementing a\nMixture-of-Agents (MoA) approach that directly synthesizes code from multiple\nspecialized LLMs, comparing it against TurinTech AI's vanilla Genetic Algorithm\n(GA)-based ensemble system and individual LLM optimizers using real-world\nindustrial codebases. Our key contributions include: (1) First MoA application\nto industrial code optimization using real-world codebases; (2) Empirical\nevidence that MoA excels with open-source models, achieving 14.3% to 22.2% cost\nsavings and 28.6% to 32.2% faster optimization times for regulated\nenvironments; (3) Deployment guidelines demonstrating GA's advantage with\ncommercial models while both ensembles outperform individual LLMs; and (4)\nReal-world validation across 50 code snippets and seven LLM combinations,\ngenerating over 8,700 variants, addresses gaps in industrial LLM ensemble\nevaluation. This provides actionable guidance for organizations balancing\nregulatory compliance with optimization performance in production environments.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u96c6\u6210\u65b9\u5f0f\uff0c\u7528\u5f00\u6e90LLM\u7ec4\u5408\u5b9e\u73b0\u4ea7\u4e1a\u7ea7\u4ee3\u7801\u4f18\u5316\uff0c\u6bd4\u5355\u4e00\u6a21\u578b\u548c\u4f20\u7edfGA\u6709\u66f4\u597d\u6210\u672c\u3001\u901f\u5ea6\u8868\u73b0\uff0c\u5e76\u9488\u5bf9\u53d7\u76d1\u7ba1\u73af\u5883\u7ed9\u51fa\u90e8\u7f72\u5efa\u8bae\u3002", "motivation": "\u53d7\u9650\u4e8e\u9690\u79c1\u4fdd\u62a4\u548c\u5408\u89c4\u9700\u6c42\uff0c\u8bb8\u591a\u53d7\u76d1\u7ba1\u884c\u4e1a\u65e0\u6cd5\u4f7f\u7528\u5546\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4ee3\u7801\u4f18\u5316\uff0c\u4e9f\u9700\u5bfb\u627e\u9ad8\u8d28\u91cf\u4e14\u6210\u672c\u6548\u76ca\u517c\u5177\u7684\u65b0\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u6df7\u5408\uff08Mixture-of-Agents, MoA\uff09\u67b6\u6784\uff0c\u8c03\u5ea6\u591a\u4e2a\u4e13\u7528\u7684\u5f00\u6e90LLM\u5171\u540c\u5408\u6210\u4f18\u5316\u4ee3\u7801\uff0c\u5e76\u4e0e\u73b0\u6709\u7684GA\uff08\u9057\u4f20\u7b97\u6cd5\uff09\u7cfb\u7edf\u53ca\u5355\u4e00LLM\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u4f7f\u7528\u771f\u5b9e\u5de5\u4e1a\u4ee3\u7801\u5e93\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "MoA\u65b9\u6cd5\u5728\u4f7f\u7528\u5f00\u6e90\u6a21\u578b\u7684\u573a\u666f\u4e0b\u76f8\u8f83\u4e8e\u5546\u7528\u6a21\u578b\u548c\u5355\u4e00LLM\u6709\u660e\u663e\u6536\u76ca\uff1a\u53ef\u8282\u770114.3%\u81f322.2%\u7684\u6210\u672c\uff0c\u4f18\u5316\u901f\u5ea6\u5feb28.6%\u81f332.2%\uff1bGA\u96c6\u6210\u5728\u4f7f\u7528\u5546\u7528LLM\u65f6\u8868\u73b0\u66f4\u4f18\uff0c\u4f46\u65e0\u8bbaMoA\u8fd8\u662fGA\u96c6\u6210\u90fd\u4f18\u4e8e\u5355\u4e00LLM\u3002\u5b9e\u9a8c\u8986\u76d67\u79cd\u6a21\u578b\u7ec4\u5408\u300150\u4efd\u5de5\u4e1a\u4ee3\u7801\u7247\u6bb5\uff0c\u603b\u751f\u6210\u7ea68700\u4e2a\u4ee3\u7801\u4f18\u5316\u53d8\u4f53\u3002", "conclusion": "\u5728\u53d7\u76d1\u7ba1\u573a\u666f\u4e0b\uff0c\u57fa\u4e8eMoA\u7684\u96c6\u6210\u591aLLM\u65b9\u6848\u80fd\u591f\u517c\u987e\u5408\u89c4\u4e0e\u4f18\u5316\u6548\u679c\uff0c\u4e3a\u4f01\u4e1a\u90e8\u7f72\u9ad8\u6548\u5408\u89c4\u7684\u81ea\u52a8\u4ee3\u7801\u4f18\u5316\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u7ebf\u548c\u5b9e\u8df5\u6307\u5f15\u3002"}}
{"id": "2508.03140", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.03140", "abs": "https://arxiv.org/abs/2508.03140", "authors": ["Junyao Yang", "Jianwei Wang", "Huiping Zhuang", "Cen Chen", "Ziqian Zeng"], "title": "RCP-Merging: Merging Long Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning Capability as Prior", "comment": "15 pages, 7 figures", "summary": "Large Language Models (LLMs) with long chain-of-thought (CoT) capability,\ntermed Reasoning Models, demonstrate superior intricate problem-solving\nabilities through multi-step long CoT reasoning. To create a dual-capability\nmodel with long CoT capability and domain-specific knowledge without\nsubstantial computational and data costs, model merging emerges as a highly\nresource-efficient method. However, significant challenges lie in merging\ndomain-specific LLMs with long CoT ones since nowadays merging methods suffer\nfrom reasoning capability degradation, even gibberish output and output\ncollapse. To overcome this, we introduce RCP-Merging: Merging Long\nChain-of-Thought Models with Domain-Specific Models by Considering Reasoning\nCapability as Prior, a novel merging framework designed to integrate\ndomain-specific LLMs with long CoT capability, meanwhile maintaining model\nperformance in the original domain. Treating reasoning model weights as\nfoundational prior, our method utilizes a reasoning capability indicator to\npreserve core long CoT capability model weights while selectively merging\nessential domain-specific weights. We conducted extensive experiments on\nQwen2.5-7B, Llama3.1-8B, and Qwen2.5-1.5B models in BioMedicine and Finance\ndomains. Our results show that RCP-Merging successfully merges a reasoning\nmodel with domain-specific ones, improving domain task performance by 9.5% and\n9.2% over state-of-the-art methods, without significantly harming the original\nlong CoT reasoning capability.", "AI": {"tldr": "\u63d0\u51faRCP-Merging\u6846\u67b6\uff0c\u5c06\u957f\u94fe\u63a8\u7406LLM\u4e0e\u9886\u57df\u7279\u5b9aLLM\u6709\u6548\u6574\u5408\uff0c\u5728\u4fdd\u8bc1\u63a8\u7406\u80fd\u529b\u7684\u60c5\u51b5\u4e0b\uff0c\u9886\u57df\u4efb\u52a1\u8868\u73b0\u5927\u5e45\u63d0\u5347\u3002", "motivation": "\u76ee\u524d\u62e5\u6709\u5f3a\u957f\u94fe\u5f0f\u601d\u7ef4\u80fd\u529b\uff08CoT\uff09\u7684LLM\u6a21\u578b\u64c5\u957f\u590d\u6742\u591a\u6b65\u63a8\u7406\u4efb\u52a1\uff0c\u800c\u5177\u5907\u9886\u57df\u77e5\u8bc6\u7684LLM\u4e5f\u975e\u5e38\u91cd\u8981\u3002\u76f4\u63a5\u8bad\u7ec3\u5177\u5907\u4e24\u79cd\u80fd\u529b\u7684\u65b0\u6a21\u578b\u8ba1\u7b97\u53ca\u6570\u636e\u6210\u672c\u8f83\u9ad8\uff0c\u56e0\u6b64\u6a21\u578b\u5408\u5e76\u662f\u4e00\u79cd\u8d44\u6e90\u9ad8\u6548\u7684\u9014\u5f84\uff0c\u4f46\u73b0\u6709\u5408\u5e76\u65b9\u6cd5\u5e38\u5e38\u5bfc\u81f4\u63a8\u7406\u80fd\u529b\u7684\u9000\u5316\u751a\u81f3\u6a21\u578b\u8f93\u51fa\u6df7\u4e71\u3002", "method": "\u63d0\u51faRCP-Merging\u65b9\u6cd5\uff0c\u5c06\u957f\u94fe\u5f0f\u601d\u7ef4\u6a21\u578b\u4e0e\u9886\u57df\u7279\u5b9a\u6a21\u578b\u8fdb\u884c\u6574\u5408\uff0c\u5229\u7528\u63a8\u7406\u80fd\u529b\u6307\u6807\u4fdd\u62a4\u539f\u6709CoT\u80fd\u529b\u7684\u91cd\u8981\u6743\u91cd\uff0c\u9009\u62e9\u6027\u5730\u7ed3\u5408\u9886\u57df\u7279\u5b9a\u6743\u91cd\uff0c\u5e76\u5c06\u63a8\u7406\u6a21\u578b\u53c2\u6570\u4f5c\u4e3a\u57fa\u7840\u524d\u7f6e\u3002", "result": "\u5728Qwen2.5-7B\u3001Llama3.1-8B\u548cQwen2.5-1.5B\u7b49\u6a21\u578b\u4e0a\uff0c\u5728\u751f\u7269\u533b\u7597\u548c\u91d1\u878d\u9886\u57df\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0cRCP-Merging\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u9886\u57df\u4efb\u52a1\u8868\u73b09.5%\u548c9.2%\uff0c\u540c\u65f6\u57fa\u672c\u4e0d\u635f\u5bb3\u539f\u6709\u957f\u94fe\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "RCP-Merging\u662f\u4e00\u79cd\u6709\u6548\u6574\u5408\u957f\u94fe\u63a8\u7406\u80fd\u529b\u4e0e\u9886\u57df\u77e5\u8bc6\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4fdd\u969c\u63a8\u7406\u80fd\u529b\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u9886\u57df\u4efb\u52a1\u8868\u73b0\u3002"}}
{"id": "2508.03340", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.03340", "abs": "https://arxiv.org/abs/2508.03340", "authors": ["Alex Wolf", "Marco Edoardo Palma", "Pooja Rani", "Harald C. Gall"], "title": "Key-Augmented Neural Triggers for Knowledge Sharing", "comment": null, "summary": "Repository-level code comprehension and knowledge sharing remain core\nchallenges in software engineering. Large language models (LLMs) have shown\npromise by generating explanations of program structure and logic. However,\nthese approaches still face limitations: First, relevant knowledge is\ndistributed across multiple files within a repository, aka semantic\nfragmentation. Second, retrieval inefficiency and attention saturation degrade\nperformance in RAG pipelines, where long, unaligned contexts overwhelm\nattention. Third, repository specific training data is scarce and often\noutdated. Finally, proprietary LLMs hinder industrial adoption due to privacy\nand deployment constraints. To address these issues, we propose Key-Augmented\nNeural Triggers (KANT), a novel approach that embeds knowledge anchors into\nboth training and inference. Unlike prior methods, KANT enables internal access\nto repository specific knowledge, reducing fragmentation and grounding\ninference in localized context. Moreover, we synthesize specialized data\ndirectly from code. At inference, knowledge anchors replace verbose context,\nreducing token overhead and latency while supporting efficient, on premise\ndeployment. We evaluate KANT via: a qualitative human evaluation of the\nsynthesized dataset's intent coverage and quality across five dimensions;\ncompare against SOTA baselines across five qualitative dimensions and inference\nspeed; and replication across different LLMs to assess generalizability.\nResults show that the synthetic training data aligned with information-seeking\nneeds. KANT achieved over 60% preference from human annotators and a LocalStack\nexpert (preferring 79% of cases). Also, KANT reduced inference latency by up to\n85% across all models. Overall, it is well-suited for scalable, low-latency,\non-premise deployments, providing a strong foundation for code comprehension.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u77e5\u8bc6\u951a\u70b9\u63d0\u5347\u4e86\u4ee3\u7801\u4ed3\u5e93\u77e5\u8bc6\u7406\u89e3\u7684\u6548\u7387\u548c\u7cfb\u7edf\u90e8\u7f72\u7684\u7075\u6d3b\u6027\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u63a8\u7406\u5ef6\u8fdf\uff0c\u5e76\u5728\u591a\u4e2a\u7ef4\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\uff0c\u7406\u89e3\u548c\u5171\u4eab\u4ee3\u7801\u4ed3\u5e93\u7ea7\u522b\u7684\u77e5\u8bc6\u4e00\u76f4\u5b58\u5728\u8bf8\u591a\u6311\u6218\u3002\u867d\u7136\u5927\u6a21\u578b\u80fd\u591f\u751f\u6210\u4ee3\u7801\u7ed3\u6784\u548c\u903b\u8f91\u7684\u89e3\u91ca\uff0c\u4f46\u5728\u77e5\u8bc6\u5206\u5e03\u5206\u6563\u3001\u68c0\u7d22\u6548\u7387\u3001\u4e0a\u4e0b\u6587\u5197\u957f\u548c\u6570\u636e\u7a00\u7f3a\u7b49\u65b9\u9762\u4ecd\u5b58\u5728\u4e0d\u8db3\u3002\u6b64\u5916\uff0c\u4e13\u6709\u5927\u6a21\u578b\u7684\u9650\u5236\u4e5f\u59a8\u788d\u4e86\u5176\u5728\u884c\u4e1a\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u2014\u2014Key-Augmented Neural Triggers\uff08KANT\uff09\uff0c\u901a\u8fc7\u5728\u8bad\u7ec3\u4e0e\u63a8\u7406\u9636\u6bb5\u5d4c\u5165\u77e5\u8bc6\u951a\u70b9\uff0c\u4f7f\u5f97\u6a21\u578b\u53ef\u4ee5\u5185\u90e8\u8bbf\u95ee\u7279\u5b9a\u4ed3\u5e93\u77e5\u8bc6\u3001\u51cf\u5c11\u8bed\u4e49\u788e\u7247\u5316\uff0c\u5e76\u5408\u6210\u57fa\u4e8e\u4ee3\u7801\u7684\u4e13\u7528\u6570\u636e\u4f9b\u8bad\u7ec3\u548c\u63a8\u7406\u3002\u5728\u63a8\u7406\u65f6\uff0c\u7528\u77e5\u8bc6\u951a\u70b9\u66ff\u4ee3\u8868\u8ff0\u5197\u957f\u7684\u4e0a\u4e0b\u6587\uff0c\u4ece\u800c\u51cf\u5c0f\u6a21\u578b\u63a8\u7406\u65f6\u7684token\u8d1f\u62c5\u5e76\u63d0\u9ad8\u901f\u5ea6\u3002", "result": "KANT\u751f\u6210\u7684\u8bad\u7ec3\u6570\u636e\u80fd\u591f\u8986\u76d6\u4fe1\u606f\u5bfb\u6c42\u9700\u6c42\u3002\u4eba\u7c7b\u8bc4\u4f30\u663e\u793aKANT\u5728\u4e94\u4e2a\u7ef4\u5ea6\u4e0a\u76f8\u6bd4SOTA\u57fa\u7ebf\u66f4\u53d7\u9752\u7750\uff0c\u5728\u63a8\u7406\u901f\u5ea6\u4e0a\u8868\u73b0\u66f4\u5feb\uff08\u6700\u591a\u63d0\u534785%\uff09\uff0c\u5e76\u80fd\u9002\u914d\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f53\u73b0\u826f\u597d\u7684\u6cdb\u5316\u6027\u3002", "conclusion": "KANT\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4ee3\u7801\u4ed3\u5e93\u77e5\u8bc6\u63a8\u7406\u4e2d\u7684\u788e\u7247\u5316\u3001\u9ad8\u5ef6\u8fdf\u548c\u4ea7\u4e1a\u843d\u5730\u96be\u7b49\u95ee\u9898\uff0c\u662f\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u3001\u4f4e\u5ef6\u8fdf\u3001\u672c\u5730\u90e8\u7f72\u4ee3\u7801\u7406\u89e3\u7cfb\u7edf\u7684\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2508.03178", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.03178", "abs": "https://arxiv.org/abs/2508.03178", "authors": ["Chenyang Wang", "Liang Wen", "Shousheng Jia", "Xiangzheng Zhang", "Liang Xu"], "title": "Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following", "comment": "12 pages, 10 figures, 7 tables", "summary": "While advancements in the reasoning abilities of LLMs have significantly\nenhanced their performance in solving mathematical problems, coding tasks, and\ngeneral puzzles, their effectiveness in accurately adhering to instructions\nremains inconsistent, particularly with more complex directives. Our\ninvestigation identifies lazy reasoning during the thinking stage as the\nprimary factor contributing to poor instruction adherence. To mitigate this\nissue, we propose a comprehensive framework designed to enable rigorous\nreasoning processes involving preview and self-checking, essential for\nsatisfying strict instruction constraints. Specifically, we first generate\ninstructions with complex constraints and apply a filtering process to obtain\nvalid prompts, resulting in three distinct prompt datasets categorized as hard,\neasy, and pass. Then, we employ rejection sampling on the pass prompts to\ncurate a small yet high-quality dataset, enabling a cold-start initialization\nof the model and facilitating its adaptation to effective reasoning patterns.\nSubsequently, we employ an entropy-preserving supervised fine-tuning\n(Entropy-SFT) strategy coupled with token-wise entropy-adaptive (TEA-RL)\nreinforcement learning guided by rule-based dense rewards. This approach\nencourages the model to transform its reasoning mechanism, ultimately fostering\ngeneralizable reasoning abilities that encompass preview and self-checking.\nExtensive experiments conducted on instruction-following benchmarks demonstrate\nremarkable performance improvements across various model scales. Notably, our\nLight-IF-32B model surpasses both larger open-source models such as DeepSeek-R1\nand closed-source models like Doubao-1.6.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u9884\u6f14\u3001\u81ea\u68c0\u3001\u9ad8\u8d28\u91cf\u6570\u636e\u7b5b\u9009\u53ca\u65b0\u578b\u8bad\u7ec3\u7b56\u7565\uff08Entropy-SFT+TEA-RL\uff09\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u5927\u6a21\u578b\u590d\u6742\u6307\u4ee4\u7684\u9075\u5faa\u6548\u679c\uff0c\u5b9e\u9a8c\u4f18\u4e8e\u4e3b\u6d41\u5f00\u6e90\u548c\u95ed\u6e90\u5927\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u5927\u6a21\u578b\u5728\u6570\u5b66\u3001\u7f16\u7801\u7b49\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u5353\u8d8a\uff0c\u4f46\u5728\u590d\u6742\u6307\u4ee4\u7684\u9075\u5faa\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\u3002\u8bba\u6587\u65e8\u5728\u5206\u6790\u4e0e\u63d0\u5347\u5927\u6a21\u578b\u7684\u6307\u4ee4\u6267\u884c\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u65b0\u6846\u67b6\uff0c\u5305\u542b\u9884\u6f14\uff08preview\uff09\u548c\u81ea\u68c0\uff08self-checking\uff09\uff0c\u8bbe\u8ba1\u590d\u6742\u7ea6\u675f\u6307\u4ee4\u5e76\u5206\u7c7b\u7b5b\u9009\u4e3ahard\u3001easy\u3001pass\u4e09\u79cd\u7c7b\u578b\uff0c\u901a\u8fc7\u62d2\u7edd\u91c7\u6837\u9009\u53d6\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u51b7\u542f\u52a8\u6a21\u578b\u3002\u4e4b\u540e\u7ed3\u5408\u4fe1\u606f\u71b5\u4fdd\u6301\u7684\u6709\u76d1\u7763\u5fae\u8c03\uff08Entropy-SFT\uff09\u548c\u57fa\u4e8e\u5bc6\u96c6\u5956\u52b1\u7684token\u7ea7\u71b5\u81ea\u9002\u5e94\u5f3a\u5316\u5b66\u4e60\uff08TEA-RL\uff09\uff0c\u9f13\u52b1\u6a21\u578b\u5f62\u6210\u89c4\u8303\u5316\u63a8\u7406\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u5404\u5c3a\u5ea6\u6a21\u578b\u4e0a\u90fd\u5b9e\u73b0\u4e86\u663e\u8457\u63d0\u5347\u3002Light-IF-32B\u6a21\u578b\u8d85\u8d8a\u4e86\u5982DeepSeek-R1\u7b49\u66f4\u5927\u5f00\u6e90\u6a21\u578b\u53ca\u95ed\u6e90\u7684Doubao-1.6\u6a21\u578b\u3002", "conclusion": "\u52a0\u5f3a\u63a8\u7406\u73af\u8282\u4e2d\u7684\u81ea\u68c0\u673a\u5236\u53ca\u9488\u5bf9\u590d\u6742\u6307\u4ee4\u7684\u4e25\u683c\u8bad\u7ec3\uff0c\u80fd\u591f\u5927\u5e45\u63d0\u5347\u5927\u6a21\u578b\u5bf9\u6307\u4ee4\u7684\u9075\u5faa\u80fd\u529b\uff0c\u65b9\u6cd5\u5728\u6807\u51c6\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u9886\u5148\u8868\u73b0\u3002"}}
