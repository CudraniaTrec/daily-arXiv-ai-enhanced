<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 5]
- [cs.SE](#cs.SE) [Total: 18]
- [cs.LO](#cs.LO) [Total: 8]
- [cs.CL](#cs.CL) [Total: 19]
- [cs.DM](#cs.DM) [Total: 1]
- [cs.FL](#cs.FL) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Towards Automatic Error Recovery in Parsing Expression](https://arxiv.org/abs/2507.03629)
*Sérgio Queiroz de Medeiros,Fabio Mascarenhas*

Main category: cs.PL

TL;DR: 本文提出了一种自动为PEG文法添加错误标签和恢复表达式的算法，通过在Titan语言解析器上的实验，展示了算法有效性，有助于实现具备错误恢复能力的自动化解析器。


<details>
  <summary>Details</summary>
Motivation: 在集成开发环境（IDE）中，解析器需要能够处理语法错误，以便即使在存在语法错误的情况下也能构建抽象语法树（AST），从而支持自动重构和代码补全等功能。当前，基于Parsing Expressions Grammars（PEGs）的错误恢复手段需要手动为文法添加标签和恢复表达式，过程复杂且繁琐。

Method: 作者提出了一种算法，能够自动为PEG文法添加错误标签及相应的错误恢复表达式，从而简化错误恢复机制的建设。作者还通过在Titan编程语言的解析器中引入该算法，进行实证评估。

Result: 实验结果表明，该算法仅需少量人工干预，就能够在大多数备择分支互斥的PEG文法中，自动构建具备错误恢复能力的解析器。

Conclusion: 该研究为基于PEG的解析器提供了一种实用且自动化的错误恢复机制，有助于提升IDE中相关技术的易用性和健壮性。

Abstract: Error recovery is an essential feature for a parser that should be plugged in
Integrated Development Environments (IDEs), which must build Abstract Syntax
Trees (ASTs) even for syntactically invalid programs in order to offer features
such as automated refactoring and code completion.
  Parsing Expressions Grammars (PEGs) are a formalism that naturally describes
recursive top-down parsers using a restricted form of backtracking. Labeled
failures are a conservative extension of PEGs that adds an error reporting
mechanism for PEG parsers, and these labels can also be associated with
recovery expressions to also be an error recovery mechanism. These expressions
can use the full expressivity of PEGs to recover from syntactic errors.
  Manually annotating a large grammar with labels and recovery expressions can
be difficult. In this work, we present an algorithm that automatically
annotates a PEG with labels, and builds their corresponding recovery
expressions. We evaluate this algorithm by adding error recovery to the parser
of the Titan programming language. The results shown that with a small amount
of manual intervention our algorithm can be used to produce error recovering
parsers for PEGs where most of the alternatives are disjoint.

</details>


### [2] [Semantically Separating Nominal Wyvern for Usability and Decidability](https://arxiv.org/abs/2507.03867)
*Yu Xiang Zhu,Amos Robinson,Sophia Roshal,Timothy Mou,Julian Mackay,Jonathan Aldrich,Alex Potanin*

Main category: cs.PL

TL;DR: Nominal Wyvern 通过将递归类型声明与结构化精化分离，结合material/shape分离技术，实现了既强表达力又可判定的依赖对象类型系统，无需牺牲易用性和OOP特性。


<details>
  <summary>Details</summary>
Motivation: DOT (Dependent Object Types) 结合了函数式语言与传统面向对象特性的表达能力，但这导致子类型判定不可判定。本领域为提升可判定性常需牺牲表达能力或易用性，递归类型及类型界限的无约束构造也加剧了难题。

Method: 提出了名为Nominal Wyvern的DOT风格依赖类型系统，引入“语义分离”，即在递归类型的声明上采用名义化，在类型使用时引入结构化精化，辅以material/shape分离技术以保障子类型判定性。

Result: Nominal Wyvern通过名义与结构的分离，实现了子类型的可判定性，同时保持了面向对象常用的F-有界多态和模块系统的表达能力，对OOP用户而言语法结构也较为熟悉。

Conclusion: 通过创新性的类型系统设计，Nominal Wyvern兼顾了表达性和判定性，能解决DOT系统难以判定子类型的问题，且便于实际应用。

Abstract: The Dependent Object Types (DOT) calculus incorporates concepts from
functional languages (e.g. modules) with traditional object-oriented features
(e.g. objects, subtyping) to achieve greater expressivity (e.g. F-bounded
polymorphism). However, this merger of paradigms comes at the cost of subtype
decidability. Recent work on bringing decidability to DOT has either sacrificed
expressiveness or ease of use. The unrestricted construction of recursive types
and type bounds has made subtype decidability a much harder problem than in
traditional object-oriented programming.
  Recognizing this, our paper introduces Nominal Wyvern, a DOT-like dependent
type system that takes an alternative approach: instead of having a uniform
structural syntax like DOT, Nominal Wyvern is designed around a "semantic
separation" between the nominal declaration of recursive types on the one hand,
and the structural refinement of those types when they are used on the other.
This design naturally guides the user to avoid writing undecidably recursive
structural types.
  From a technical standpoint, this separation also makes guaranteeing
decidability possible by allowing for an intuitive adaptation of material/shape
separation, a technique for achieving subtype decidability by separating types
responsible for subtyping constraints from types that represent concrete data.
The result is a type system with syntax and structure familiar to OOP users
that achieves decidability without compromising the expressiveness of F-bounded
polymorphism and module systems as they are used in practice.

</details>


### [3] [CCR 2.0: High-level Reasoning for Conditional Refinements](https://arxiv.org/abs/2507.04298)
*Youngju Song,Minki Cho*

Main category: cs.PL

TL;DR: 本文提出CCR 2.0，有效融合精化与分离逻辑的优势，提升了低层系统形式验证中的组合性与证明复用，相关方法已在Coq中形式化。


<details>
  <summary>Details</summary>
Motivation: 现有的两种主流低层系统形式验证方法——精化(refinement)与分离逻辑(separation logic)——各自有不同且互补的可组合性优势，因此有需求将两者优点融合。此前提出的CCR 1.0初步实现了这点，但存在改进空间。

Method: 作者改进并拓展了CCR 1.0模型，提出了CCR 2.0，并在其中引入了更新的组合性定理与更高效的证明技术。这些方法有效地隐藏了底层模型细节，结果在Coq中得到形式化。

Result: CCR 2.0具有更好的组合性定理，能带来更多证明复用，且新证明技术让用户免于处理分离逻辑底层资源；模型经过Coq形式验证。

Conclusion: CCR 2.0为融合系统验证的主流方法提供了更强的理论基础和工具支持，提升了证明工作的效率与可复用性。

Abstract: In recent years, great progress has been made in the field of formal
verification for low-level systems. Many of them are based on one of two
popular approaches: refinement or separation logic. These two approaches are
very different in nature and offer complementary benefits in terms of
compositionality. Recently, to fuse these benefits in a unified mechanism, a
new approach called Conditional Contextual Refinement (CCR 1.0 for short) was
proposed. In this paper, we advance the model of CCR 1.0 and provide novel and
intuitive reasoning principles, resulting in: CCR 2.0. Specifically, CCR 2.0
(i) comes with a better compositionality theorem, having the practical benefit
of facilitating more proof reuse, and (ii) provides a proof technique that
hides model-level (i.e., resources of the separation logic) details from the
user. Achieving this goal was challenging due to non-trivial counterexamples
which necessitated us to devise novel notions. Our results are formalized in
Coq.

</details>


### [4] [Retargeting an Abstract Interpreter for a New Language by Partial Evaluation](https://arxiv.org/abs/2507.04316)
*Jay Lee*

Main category: cs.PL

TL;DR: 本文提出了一种通过偏特化自动将抽象解释器迁移到新语言的方法，无需从头开发分析器，实验验证方法有效。


<details>
  <summary>Details</summary>
Motivation: 尽管已知可以从具体解释器系统性地推导出抽象解释器，但开发静态分析器仍然耗时且难以自动化。减少开发工作量与实现分析器开发自动化仍是挑战。能否自动将现有抽象解释器用于新语言，是该研究关注的问题。

Method: 本文利用偏特化（partial evaluation）技术，将现有的抽象解释器针对源语言进行专业化，并结合将目标语言语义写作源语言的方式，实现自动化转换。

Result: 通过实验与方法展示，作者成功用该技术将一种语言的抽象解释器转换为另一种语言的静态分析器，证明了该方法的有效性和正确性。

Conclusion: 该方法可以有效地将一个语言的抽象解释器重定向（retarget）为另一个语言的正确分析器，无需从头开发新的分析器。

Abstract: It is well-known that abstract interpreters can be systematically derived
from their concrete counterparts using a "recipe," but developing sound static
analyzers remains a time-consuming task. Reducing the effort required and
mechanizing the process of developing analyzers continues to be a significant
challenge. Is it possible to automatically retarget an existing abstract
interpreter for a new language?
  We propose a novel technique to automatically derive abstract interpreters
for various languages from an existing abstract interpreter. By leveraging
partial evaluation, we specialize an abstract interpreter for a source
language. The specialization is performed using the semantics of target
languages written in the source language. Our approach eliminates the need to
develop analyzers for new targets from scratch. We show that our method can
effectively retarget an abstract interpreter for one language into a correct
analyzer for another language.

</details>


### [5] [React-tRace: A Semantics for Understanding React Hooks](https://arxiv.org/abs/2507.05234)
*Jay Lee,Joongwon Ahn,Kwangkeun Yi*

Main category: cs.PL

TL;DR: 论文通过React-tRace形式化模型和可视化工具，提高了开发者把控React Hooks语义及行为的能力。


<details>
  <summary>Details</summary>
Motivation: React Hooks抽象复杂，开发者难以理解其真实语义，易导致UI bug，缺少清晰的行为模式和分析工具。

Method: 提出了React-tRace，形式化描述React Hooks的本质语义，并结合理论分析和实证测试套件对其与官方实现进行对比，同时基于该形式化语义实现了可视化工具帮助开发者理解。

Result: 理论层面证明React-tRace捕捉了Hooks的核心属性，实验上通过测试集对比表明其准确模拟React行为，并开发出配套可视化工具助力理解。

Conclusion: 通过形式化模型和可视化工具，显著提升了开发者对React Hooks工作机制的理解，有助于减少bug和优化开发。

Abstract: React has become the most widely used web front-end framework, enabling the
creation of user interfaces in a declarative and compositional manner. Hooks
are a set of APIs that manage side effects in functional components in React.
However, their semantics are often seen as opaque to developers, leading to UI
bugs. In this paper, we formalize the semantics of the essence of React Hooks
we name React-tRace, providing a framework that clarifies their behavior. We
demonstrate that our model captures the behavior of React, by theoretically
showing that it embodies essential properties of Hooks and empirically
comparing our React-tRace-definitional interpreter against a test suite.
Furthermore, we showcase a practical visualization tool based on the
formalization to demonstrate how developers can better understand the semantics
of Hooks.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [6] [The Impact of LLM-Assistants on Software Developer Productivity: A Systematic Literature Review](https://arxiv.org/abs/2507.03156)
*Amr Mohamed,Maram Assi,Mariam Guizani*

Main category: cs.SE

TL;DR: 本综述分析了LLM助手在软件开发中的影响，总结了益处和风险，并指出当前研究存在评估维度不足和缺乏长期实证等主要缺口。为未来LLM辅助开发研究提供了参考和建议。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM助手在软件开发的多个环节被广泛采用，但尚缺乏对其对开发者生产力影响的系统性综述。本研究旨在填补这一空白，归纳现有研究成果并指出未来方向。

Method: 系统性文献回顾，对2014年至2024年间37篇同行评议文章进行综合分析，聚焦LLM助手对开发者生产力的影响及相关维度。

Result: LLM助手常带来开发提速、降低重复性劳动等好处，但也可能导致认知懈怠、协作减少和代码质量波动等问题。大部分研究关注SPACE框架中的多维度生产力，但整体评估仍显片面，影响全貌尚需进一步探索。

Conclusion: LLM助手为软件开发者带来了可观的益处，但也存在不容忽视的风险。研究往往关注于开发者的满意度、绩效和效率，而在团队协作和具体开发活动上的探讨较少。缺乏长期和基于团队的系统评估，未来研究需补足这些不足。

Abstract: Large language model assistants (LLM-assistants) present new opportunities to
transform software development. Developers are increasingly adopting these
tools across tasks, including coding, testing, debugging, documentation, and
design. Yet, despite growing interest, there is no synthesis of how
LLM-assistants affect software developer productivity. In this paper, we
present a systematic literature review of 37 peer-reviewed studies published
between January 2014 and December 2024 that examine this impact. Our analysis
reveals that LLM-assistants offer both considerable benefits and critical
risks. Commonly reported gains include minimized code search, accelerated
development, and the automation of trivial and repetitive tasks. However,
studies also highlight concerns around cognitive offloading, reduced team
collaboration, and inconsistent effects on code quality. While the majority of
studies (92%) adopt a multi-dimensional perspective by examining at least two
SPACE dimensions, reflecting increased awareness of the complexity of developer
productivity, only 14% extend beyond three dimensions, indicating substantial
room for more integrated evaluations. Satisfaction, Performance, and Efficiency
are the most frequently investigated dimensions, whereas Communication and
Activity remain underexplored. Most studies are exploratory (64%) and
methodologically diverse, but lack longitudinal and team-based evaluations.
This review surfaces key research gaps and provides recommendations for future
research and practice. All artifacts associated with this study are publicly
available at https://zenodo.org/records/15788502.

</details>


### [7] [Assessing Small Language Models for Code Generation: An Empirical Study with Benchmarks](https://arxiv.org/abs/2507.03160)
*Md Mahade Hasan,Muhammad Waseem,Kai-Kristian Kemell,Jussi Raskua,Juha Ala-Rantalaa,Pekka Abrahamsson*

Main category: cs.SE

TL;DR: 通过对20个小型语言模型在多项代码生成基准上的实证评估，发现部分轻量模型在保证效率前提下表现优异，适合资源有限环境。但进一步提升准确性需更大模型，带来更高计算成本，且不同编程语言总体无显著性能差异。


<details>
  <summary>Details</summary>
Motivation: 随着小型语言模型（SLMs）技术的进步，它们在代码生成领域展现了高效且经济的优势。相比大型语言模型（LLMs），SLMs适用于资源受限的环境，但目前缺乏对SLMs在代码生成能力、局限性及性能权衡的实证评估。

Method: 本文综合评估了20个开源SLMs（0.4B至10B参数），在五个多样化的代码相关基准（HumanEval、MBPP、Mercury、HumanEvalPack和CodeXGLUE）上，从生成代码的功能正确性、计算效率和多编程语言性能三个维度进行分析。

Result: 研究发现，一些小型SLMs能够在保证性能与效率平衡的前提下，取得较有竞争力的结果，适合部署在资源受限环境中。但精度进一步提升需选用更大的模型，然而大模型对计算资源需求显著提升。例如，性能提升10%时显存消耗可增加4倍。此外，虽多语言分析显示Python、Java和PHP表现较好，Go、C++、Ruby较弱，但统计分析表明性能差异不大，SLMs具备跨语言泛化能力。

Conclusion: 综合实验结果表明，SLMs在高效代码生成和多语言任务中有实际应用潜力，为实际部署和模型选择提供了指导和参考。

Abstract: The recent advancements of Small Language Models (SLMs) have opened new
possibilities for efficient code generation. SLMs offer lightweight and
cost-effective alternatives to Large Language Models (LLMs), making them
attractive for use in resource-constrained environments. However, empirical
understanding of SLMs, particularly their capabilities, limitations, and
performance trade-offs in code generation remains limited. This study presents
a comprehensive empirical evaluation of 20 open-source SLMs ranging from 0.4B
to 10B parameters on five diverse code-related benchmarks (HumanEval, MBPP,
Mercury, HumanEvalPack, and CodeXGLUE). The models are assessed along three
dimensions: i) functional correctness of generated code, ii) computational
efficiency and iii) performance across multiple programming languages. The
findings of this study reveal that several compact SLMs achieve competitive
results while maintaining a balance between performance and efficiency, making
them viable for deployment in resource-constrained environments. However,
achieving further improvements in accuracy requires switching to larger models.
These models generally outperform their smaller counterparts, but they require
much more computational power. We observe that for 10% performance
improvements, models can require nearly a 4x increase in VRAM consumption,
highlighting a trade-off between effectiveness and scalability. Besides, the
multilingual performance analysis reveals that SLMs tend to perform better in
languages such as Python, Java, and PHP, while exhibiting relatively weaker
performance in Go, C++, and Ruby. However, statistical analysis suggests these
differences are not significant, indicating a generalizability of SLMs across
programming languages. Based on the findings, this work provides insights into
the design and selection of SLMs for real-world code generation tasks.

</details>


### [8] [Analyzing C/C++ Library Migrations at the Package-level: Prevalence, Domains, Targets and Rationals across Seven Package Management Tools](https://arxiv.org/abs/2507.03263)
*Haiqiao Gu,Yiliang Zhao,Kai Gao,Minghui Zhou*

Main category: cs.SE

TL;DR: 本文填补了C/C++库迁移研究的空白，基于近2万个项目构建迁移数据集，分析迁移现象和原因，并对比其它主流语言，总结出C/C++库迁移的独特性，可助力迁移工具设计。


<details>
  <summary>Details</summary>
Motivation: 此前关于C/C++库迁移的研究较少，主要因为其依赖管理实践分散且复杂。现有绝大多数关于库迁移的研究集中在依赖管理集中的编程语言生态（如Python、JavaScript、Java），C/C++方面尚属空白。填补这一知识空白对于理解C/C++生态下的库迁移及工具设计具有重要意义。

Method: 本文分析了19,943个使用不同包管理工具的C/C++项目，构建了首个C/C++库迁移数据集。基于该数据集，系统性地调研了C/C++库迁移的流行程度、涉及领域、目标库及迁移原因，并与Python、JavaScript和Java三个主流编程语言进行了对比。

Result: C/C++库迁移的整体趋势与Java相似，也观测到跨不同包管理工具的迁移。C/C++中，库迁移主要发生在GUI、构建和操作系统开发领域，在测试和日志等领域迁移则较少，与其它语言有显著不同。83.46%的源库仅有一个迁移目标，迁移原因有四项是C/C++特有的，如减少编译时间和依赖管理统一。

Conclusion: 研究为C/C++社区首次带来大规模库迁移的实证数据，揭示了其领域和迁移动机的独特性，并能直接为库迁移推荐提供数据支撑，对C/C++迁移工具的设计开发具有启发价值。

Abstract: Library migration happens when a library can not meet the project's
requirements and is non-trivial to accomplish. To mitigate the problem,
substantial efforts have been devoted to understanding its characteristics and
recommending alternative libraries, especially for programming language (PL)
ecosystems with a central package hosting platform, such as Python (PyPI).
However, to the best of our knowledge, understanding of C/C++ library
migrations is still lacking, possibly due to challenges resulting from the
fragmented and complicated dependency management practices in the C/C++
ecosystem. To bridge this knowledge gap, this paper analyzes 19,943 C/C++
projects that utilize different package management tools and establishes the
first C/C++ library migration dataset. Based on the dataset, we investigate the
prevalence, domains, target library, and rationale of C/C++ library migrations
and compare the results with three widely investigated PLs: Python, JavaScript,
and Java. We find that the overall trend in the number of C/C++ library
migrations is similar to Java. Migrations across different package management
tools are also observed. In C/C++, library migrations mainly occur in GUI,
Build, and OS development, but are rare in domains (e.g., Testing and Logging)
that dominate library migrations in the three compared PLs. 83.46\% of C/C++
source libraries only have one migration target, suggesting that our library
migration dataset could be used directly to recommend migration targets. We
find four C/C++-specific migration reasons, such as less compile time and
unification of dependency management, revealing the unique dependency
management requirements in C/C++ projects. We believe our findings can help
C/C++ developers make more informed library migration decisions and shed light
on the design of C/C++ library migration tools.

</details>


### [9] [scikit-package -- software packaging standards and roadmap for sharing reproducible scientific software](https://arxiv.org/abs/2507.03328)
*S. Lee,C. Myers,A. Yang,T. Zhang,S. J. L. Billinge*

Main category: cs.SE

TL;DR: 该论文介绍了 scikit-package，通过教程和自动化工具帮助非专业的软件开发者（如科学家）实现代码复用、提高软件可维护性与可复现性，促进科学成果共享。


<details>
  <summary>Details</summary>
Motivation: 科学研究的进步依赖于结果的共享与可复现性。然而，当科学家使用自写软件进行数据分析和计算时，代码的版本管理、质量控制和共享方面存在挑战。

Method: scikit-package 通过结合教程与自动化、集中的可重用工作流，为代码复用和共享制定了路径。该项目为没有专业软件工程背景的科学家提供理论和实践工具，帮助他们提升代码的可重用性与可维护性。

Result: scikit-package 提供了社区维护的工具集和路线图，帮助科学家提升其软件的可复现性和可共享性，支持从代码块函数化到成熟软件包发布的多层次代码复用。

Conclusion: scikit-package 旨在降低科学家开发可重用、可维护软件难度，促进科学软件的复用与传播。

Abstract: Scientific advancement relies on the ability to share and reproduce results.
When data analysis or calculations are carried out using software written by
scientists there are special challenges around code versions, quality and code
sharing. scikit-package provides a roadmap to facilitate code reuse and sharing
with minimal effort through tutorials coupled with automated and centralized
reusable workflows. The goal of the project is to provide pedagogical and
practical tools for scientists who are not professionally trained software
engineers to write more reusable and maintainable software code. Code reuse can
occur at multiple levels of complexity-from turning a code block into a
function within a single script, to publishing a publicly installable, fully
tested, and documented software package scikit-package provides a community
maintained set of tools, and a roadmap, to help scientists bring their software
higher levels of reproducibility and shareability.

</details>


### [10] [Prompt Engineering Guidelines for Using Large Language Models in Requirements Engineering](https://arxiv.org/abs/2507.03405)
*Krishna Ronanki,Simon Arvidsson,Johan Axell*

Main category: cs.SE

TL;DR: LLM在需求工程中的应用正增长，但针对性提示工程指南缺乏。本文通过综述和专家访谈，总结现有指南并为未来研究提出方向。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI模型（如大型语言模型LLMs）在各个领域（包括需求工程RE）的应用，确保LLM生成内容的质量和准确性变得非常关键。提示工程作为引导模型响应的关键技术，但现有文献中很少有专门针对需求工程活动的提示工程指导。

Method: 本研究首先进行系统性文献综述，整理现有的提示工程指南。随后与需求工程领域专家进行访谈，结合专家反馈评估这些指南在需求工程领域的适用性、优点和局限性。

Result: 文献综述显示，现有针对需求工程等领域的提示工程指南非常有限。论文提出的指南映射有助于弥补这个空白，并在需求工程领域应用LLM时提供参考。

Conclusion: 提示工程对在需求工程活动中有效利用LLM至关重要，但目前相关的指南有限。本研究通过文献回顾和专家访谈，整理并评估了现有提示工程指南，并提出了改进建议，为该领域未来研究指出了新方向。

Abstract: The rapid emergence of generative AI models like Large Language Models (LLMs)
has demonstrated its utility across various activities, including within
Requirements Engineering (RE). Ensuring the quality and accuracy of
LLM-generated output is critical, with prompt engineering serving as a key
technique to guide model responses. However, existing literature provides
limited guidance on how prompt engineering can be leveraged, specifically for
RE activities. The objective of this study is to explore the applicability of
existing prompt engineering guidelines for the effective usage of LLMs within
RE. To achieve this goal, we began by conducting a systematic review of primary
literature to compile a non-exhaustive list of prompt engineering guidelines.
Then, we conducted interviews with RE experts to present the extracted
guidelines and gain insights on the advantages and limitations of their
application within RE. Our literature review indicates a shortage of prompt
engineering guidelines for domain-specific activities, specifically for RE. Our
proposed mapping contributes to addressing this shortage. We conclude our study
by identifying an important future line of research within this field.

</details>


### [11] [Enhancing Uncertainty Quantification for Runtime Safety Assurance Using Causal Risk Analysis and Operational Design Domain](https://arxiv.org/abs/2507.03515)
*Radouane Bouchekir,Michell Guzman Cancimance*

Main category: cs.SE

TL;DR: 本文提出基于风险因果分析、融合环境信息的贝叶斯网络方法，实现了自动化系统运行时更全面的不确定性和安全性度量，并在自动代客泊车目标检测场景下进行了验证。


<details>
  <summary>Details</summary>
Motivation: 目前自动化系统的运行安全性面对深度学习组件不确定性及对环境变化敏感性存在挑战。本文提出对现有不确定性评估方式的增强，旨在结合运行环境的信息进行更准确的风险量化，提升复杂环境下系统的安全保障能力。

Method: 结合风险导向的因果分析，使用HARA（危险分析与风险评估）和故障树建模，识别影响系统功能的关键运行条件，并将这些条件与数据和模型的不确定性一同集成到统一的贝叶斯网络（BN）中。运行时利用实时环境观测对BN进行实例化，推断安全估计的概率分布。

Result: 提出的方法能够结合环境条件，实现动态、多上下文感知的不确定性度量。通过对自动代客泊车（AVP）中的目标检测（OD）组件案例研究，验证了方法的有效性。

Conclusion: 通过整合环境因素、数据和模型不确定性到统一框架，实现了更精细化、动态的安全估计手段，为自动化系统运行安全提供了新的解决方案，可根据实时环境对不确定性进行自适应调整。

Abstract: Ensuring the runtime safety of autonomous systems remains challenging due to
deep learning components' inherent uncertainty and their sensitivity to
environmental changes. In this paper, we propose an enhancement of traditional
uncertainty quantification by explicitly incorporating environmental conditions
using risk-based causal analysis. We leverage Hazard Analysis and Risk
Assessment (HARA) and fault tree modeling to identify critical operational
conditions affecting system functionality. These conditions, together with
uncertainties from the data and model, are integrated into a unified Bayesian
Network (BN). At runtime, this BN is instantiated using real-time environmental
observations to infer a probabilistic distribution over the safety estimation.
This distribution enables the computation of both expected performance and its
associated variance, providing a dynamic and context-aware measure of
uncertainty. We demonstrate our approach through a case study of the Object
Detection (OD) component in an Automated Valet Parking (AVP).

</details>


### [12] [The Role of Humour in Software Engineering -- A Literature Review and Preliminary Taxonomy](https://arxiv.org/abs/2507.03527)
*Dulaji Hidellaarachchi,John Grundy,Rashina Hoda*

Main category: cs.SE

TL;DR: 本文通过文献综述，提出了幽默在软件工程团队中的分类和应用框架，指出其对团队气氛和生产力有重要作用，同时提醒需负责任使用和进一步实证验证。


<details>
  <summary>Details</summary>
Motivation: 幽默被广泛认为能提升创造力、团队效能和员工幸福感，但在软件工程团队中的应用与影响尚未被充分探索。作者希望系统梳理和探讨幽默在软件工程团队中的作用。

Method: 本文采用文献综述方法，系统汇总心理学、社会学和组织行为学相关研究，提出幽默理论、风格、模型和量表的分类框架。

Result: 提出了一套系统的幽默分类方法，为SE（软件工程）专业人士与研究者理解并应用幽默提供了结构化、理论化的参考。文章还指出在SE实践中应用幽默面临的独特挑战，并强调需要更多实证研究加以验证。

Conclusion: 研究为在软件工程团队中更有效地使用幽默打开新路径，强调合理使用幽默可以促进团队凝聚力、创造力及心理支持。此框架有助于构建更积极、健康的工作环境。

Abstract: Humour has long been recognized as a key factor in enhancing creativity,
group effectiveness, and employee well-being across various domains. However,
its occurrence and impact within software engineering (SE) teams remains
under-explored. This paper introduces a comprehensive, literature review-based
taxonomy exploring the characterisation and use of humour in SE teams, with the
goal of boosting productivity, improving communication, and fostering a
positive work environment while emphasising the responsible use of humour to
mitigate its potential negative impacts. Drawing from a wide array of studies
in psychology, sociology, and organizational behaviour, our proposed framework
categorizes humour into distinct theories, styles, models, and scales, offering
SE professionals and researchers a structured approach to understanding humour
in their work. This study also addresses the unique challenges of applying
humour in SE, highlighting its potential benefits while acknowledging the need
for further empirical validation in this context. Ultimately, our study aims to
pave the way for more cohesive, creative, and psychologically supportive SE
environments through the strategic use of humour.

</details>


### [13] [ACE: Automated Technical Debt Remediation with Validated Large Language Model Refactorings](https://arxiv.org/abs/2507.03536)
*Adam Tornhill,Markus Borg,Nadim Hagatulah,Emma Söderberg*

Main category: cs.SE

TL;DR: AI 生成代码很快，但开发难点在于代码理解。ACE 工具借助 LLM 自动化优化代码结构、减轻技术债务，既保证质量又不影响功能，获得正面用户反馈。


<details>
  <summary>Details</summary>
Motivation: 虽然 AI 及 LLM 让机器自动写代码能力增强，但开发者消耗最多的时间是在理解现有代码。提升代码可理解性和易维护性成为保证开发效率与项目可控性的关键。

Method: 本研究采用数据驱动方法，通过集成并验证 LLM 的生成结果，确保代码重构建议在提升代码质量的同时不影响程序正确性。

Result: ACE 能自动生成可靠的重构建议，兼顾代码质量提升与功能正确性，实践中有助于减少开发者处理技术债务的负担。

Conclusion: ACE 工具利用经过验证的大语言模型（LLM）输出，实现了自动化的代码优化，能够有效减少技术债务并提升代码可理解性。用户早期反馈积极，表明 AI 驱动的重构建议确实帮助了解决日常被忽视的代码层面问题。

Abstract: The remarkable advances in AI and Large Language Models (LLMs) have enabled
machines to write code, accelerating the growth of software systems. However,
the bottleneck in software development is not writing code but understanding
it; program understanding is the dominant activity, consuming approximately 70%
of developers' time. This implies that improving existing code to make it
easier to understand has a high payoff and - in the age of AI-assisted coding -
is an essential activity to ensure that a limited pool of developers can keep
up with ever-growing codebases. This paper introduces Augmented Code
Engineering (ACE), a tool that automates code improvements using validated LLM
output. Developed through a data-driven approach, ACE provides reliable
refactoring suggestions by considering both objective code quality improvements
and program correctness. Early feedback from users suggests that AI-enabled
refactoring helps mitigate code-level technical debt that otherwise rarely gets
acted upon.

</details>


### [14] [Is It Time To Treat Prompts As Code? A Multi-Use Case Study For Prompt Optimization Using DSPy](https://arxiv.org/abs/2507.03620)
*Francisca Lemos,Victor Alves,Filipa Ferraz*

Main category: cs.SE

TL;DR: DSPy自动化优化提示可提升LLM表现，但改进幅度依任务不同，有些用例明显增益，有些仅微幅提升。


<details>
  <summary>Details</summary>
Motivation: 提示工程对于LLM发挥全部潜力至关重要，但高效提示的设计依赖于耗时的人工试错。本研究旨在探索是否可以通过编程化的优化框架简化和提升提示设计效率。

Method: 研究采用Declarative Self-improving Python（DSPy）优化框架，通过自动生成和优化提示，在五种用例下（规范执行、代码幻觉检测、代码生成、路由代理、提示评价）进行实验，并分别分析DSPy优化提示对不同任务表现的影响。

Result: 不同用例改善幅度差异较大：针对提示评价任务准确率从46.2%大幅提升到64.0%；路由代理任务提示优化使准确率从85.0%提升到90.0%，但“便宜”模型借助优化后提示未明显超越原本的强模型。其他用例如规范执行和幻觉检测则只取得细微提升。

Conclusion: DSPy自动化提示优化在某些任务（如提示评价）表现突出，可有效提升LLM任务表现，尤其是在说明调优和示例选择协同优化时。但不同任务影响差异显著，提示优化应基于具体任务效果评估。

Abstract: Although prompt engineering is central to unlocking the full potential of
Large Language Models (LLMs), crafting effective prompts remains a
time-consuming trial-and-error process that relies on human intuition. This
study investigates Declarative Self-improving Python (DSPy), an optimization
framework that programmatically creates and refines prompts, applied to five
use cases: guardrail enforcement, hallucination detection in code, code
generation, routing agents, and prompt evaluation. Each use case explores how
prompt optimization via DSPy influences performance. While some cases
demonstrated modest improvements - such as minor gains in the guardrails use
case and selective enhancements in hallucination detection - others showed
notable benefits. The prompt evaluation criterion task demonstrated a
substantial performance increase, rising accuracy from 46.2% to 64.0%. In the
router agent case, the possibility of improving a poorly performing prompt and
of a smaller model matching a stronger one through optimized prompting was
explored. Although prompt refinement increased accuracy from 85.0% to 90.0%,
using the optimized prompt with a cheaper model did not improve performance.
Overall, this study's findings suggest that DSPy's systematic prompt
optimization can enhance LLM performance, particularly when instruction tuning
and example selection are optimized together. However, the impact varies by
task, highlighting the importance of evaluating specific use cases in prompt
optimization research.

</details>


### [15] [Specification-Guided Repair of Arithmetic Errors in Dafny Programs using LLMs](https://arxiv.org/abs/2507.03659)
*Valentina Wu,Alexandra Mendes,Alexandre Abreu*

Main category: cs.SE

TL;DR: 本文提出Dafny自动程序修复工具，结合形式规范与大语言模型，定位准确率89.6%，最高修复率74.18%，效果突出。


<details>
  <summary>Details</summary>
Motivation: 形式化验证能保障软件正确性，但遇到验证失败时定位和修复错误极为复杂和耗时。自动程序修复（APR）旨在自动定位和修复错误，但传统方法依赖测试集易出现覆盖不足的问题。因此，结合形式化规范实现更高标准的错误修复成为需求。

Method: 提出了一种针对Dafny（验证感知的编程语言）的创新APR工具。该工具利用形式化规范（前置条件、后置条件、不变量）作为定位和修复依据，主要针对算术错误。结合Hoare逻辑分析语句状态，利用多种大型语言模型（如GPT-4o mini、Llama 3、Mistral 7B和Llemma 7B）生成修复建议。

Result: 在实际Dafny程序基准集（DafnyBench）上测试显示，工具在错误定位上的准确率为89.6%，修复成功率（GPT-4o mini最高）为74.18%。

Conclusion: 结合正式推理与大语言模型的方案可有效提升自动程序修复工具在形式化编程环境中的定位及修复能力。

Abstract: Formal verification offers strong assurances of software correctness.
However, debugging and repairing the underlying faults can be complex and
time-consuming when verification fails. Automated Program Repair (APR) aims to
ease this by automatically identifying and fixing faults. Traditional APR
techniques often depend on test suites for validation, but these may fail to
capture all scenarios. In contrast, formal specifications provide stronger
correctness criteria for effective repairs.
  We present an innovative APR tool for Dafny, a verification-aware programming
language that uses formal specifications - including pre-conditions,
post-conditions, and invariants - as oracles for fault localization and repair.
Assuming the correctness of the specifications and focusing on arithmetic bugs,
we localize faults through a series of steps, which include using Hoare Logic
to determine the state of each statement within the program and
state-of-the-art Large Language Models (LLMs) to synthesize candidate fixes.
The chosen models were GPT-4o mini, Llama 3, Mistral 7B, and Llemma 7B.
  We evaluate our approach using DafnyBench, a benchmark of real-world Dafny
programs. Our tool achieves 89.6% accuracy in fault localization, with GPT-4o
mini yielding the highest repair success rate (74.18%). These results highlight
the potential of combining formal reasoning with LLM-driven program synthesis
for automated program repair.

</details>


### [16] [Efficient Detection of Intermittent Job Failures Using Few-Shot Learning](https://arxiv.org/abs/2507.04173)
*Henri Aïdasso,Francis Bordeleau,Ali Tizghadam*

Main category: cs.SE

TL;DR: 本文针对持续集成流水线中的间歇性作业失败检测，提出了基于小样本学习的分类框架，只需极少手工标注即可大幅提升检测准确率，优于现有主流方法，有助于实际工程应用。


<details>
  <summary>Details</summary>
Motivation: 现有通过作业重运行启发式来标签划分常规/间歇性失败的数据集存在严重误标问题，影响了检测模型的实际效果。人工大量标注成本过高，因此需要一种在小样本数据下仍有良好表现的方法。

Method: 利用小样本学习（FSL）框架，先选取少量经过人工标注的日志样本，对小型语言模型进行微调，随后用该模型提取日志嵌入信息，输入到机器学习分类器中进行间歇性失败检测。与传统依靠日志重运行的启发式方式作对比实验，评估方法效果。

Result: 提出的方法仅需12个手工标注样本就能在所有项目中达到70-88%的F1分数，显著优于现有方法（SOTA在4个项目上仅34-52%的F1），有效减少了数据误标导致的负面影响，提高了检测的实用性和效率。

Conclusion: 提出了一种基于小样本学习（FSL）的方法，通过对少量手工标注的日志样本微调小型语言模型，并使用其生成的嵌入向量来训练分类器，可以更加高效和准确地检测CI/CD中的间歇性作业失败，显著优于现有主流方法。

Abstract: One of the main challenges developers face in the use of continuous
integration (CI) and deployment pipelines is the occurrence of intermittent job
failures, which result from unexpected non-deterministic issues (e.g., flaky
tests or infrastructure problems) rather than regular code-related errors such
as bugs. Prior studies developed machine-learning (ML) models trained on large
datasets of job logs to classify job failures as either intermittent or
regular. As an alternative to costly manual labeling of large datasets, the
state-of-the-art (SOTA) approach leveraged a heuristic based on
non-deterministic job reruns. However, this method mislabels intermittent job
failures as regular in contexts where rerunning suspicious job failures is not
an explicit policy, and therefore limits the SOTA's performance in practice. In
fact, our manual analysis of 2,125 job failures from 5 industrial and 1
open-source projects reveals that, on average, 32\% of intermittent job
failures are mislabeled as regular. To address these limitations, this paper
introduces a novel approach to intermittent job failure detection using
few-shot learning (FSL). Specifically, we fine-tune a small language model
using a few number of manually labeled log examples to generate rich
embeddings, which are then used to train an ML classifier. Our FSL-based
approach achieves 70-88\% F1-score with only 12 shots in all projects,
outperforming the SOTA, which proved ineffective (34-52\% F1-score) in 4
projects. Overall, this study underlines the importance of data quality over
quantity and provides a more efficient and practical framework for the
detection of intermittent job failures in organizations.

</details>


### [17] [From Legal Text to Tech Specs: Generative AI's Interpretation of Consent in Privacy Law](https://arxiv.org/abs/2507.04185)
*Aniket Kesari,Travis Breaux,Tom Norton,Sarah Santos,Anmol Singhal*

Main category: cs.SE

TL;DR: 本文研究了大语言模型在将隐私法“同意”要求转化为软件开发操作中的作用。结果表明LLM可部分自动化合规性判断，但仍需人工辅助以弥补逻辑推理和法律细节上的缺陷。


<details>
  <summary>Details</summary>
Motivation: 随着各国隐私法规（如CCPA）强化同意要求，开发者如何将法律义务落实到软件开发过程变得极为复杂，现有流程不透明，亟需更高效、智能的技术支持。

Method: 研究采用三步法：1) 利用LLM对软件用例进行合规性分类；2) 对不合规用例生成LLM修改建议；3) 手动校验这些变动是否符合法律标准。

Result: 初步结果显示LLMs可助力软体合规性检查自动化，虽展现出一定能力，但在深层推理及与复杂法律标准对齐方面存在不足。

Conclusion: LLMs具备自动化合规任务的潜力，但在推理能力方面仍有局限性，需要配合人工校验以确保符合法律标准。

Abstract: Privacy law and regulation have turned to "consent" as the legitimate basis
for collecting and processing individuals' data. As governments have rushed to
enshrine consent requirements in their privacy laws, such as the California
Consumer Privacy Act (CCPA), significant challenges remain in understanding how
these legal mandates are operationalized in software. The opaque nature of
software development processes further complicates this translation. To address
this, we explore the use of Large Language Models (LLMs) in requirements
engineering to bridge the gap between legal requirements and technical
implementation. This study employs a three-step pipeline that involves using an
LLM to classify software use cases for compliance, generating LLM modifications
for non-compliant cases, and manually validating these changes against legal
standards. Our preliminary findings highlight the potential of LLMs in
automating compliance tasks, while also revealing limitations in their
reasoning capabilities. By benchmarking LLMs against real-world use cases, this
research provides insights into leveraging AI-driven solutions to enhance legal
compliance of software.

</details>


### [18] [Improving Deep Learning Framework Testing with Model-Level Metamorphic Testing](https://arxiv.org/abs/2507.04354)
*Yanzhou Mu,Juan Zhai,Chunrong Fang,Xiang Chen,Zhixiang Cao,Peiran Yang,Kexin Zhao,An Guo,Zhenyu Chen*

Main category: cs.SE

TL;DR: 本文提出了一种面向模型结构的变异测试方法（ModelMeta）用于深度学习框架，能够通过扩展模型和多接口组合，在训练损失和资源利用等角度精准发现更多类型的框架缺陷，有效解决了现有方法在结构复杂性和接口广泛性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习框架测试方法由于浮点误差、随机性以及测试输入复杂性，导致难以有效分析执行结果，缺乏适当的测试判定标准（test oracle）。变异测试虽然一定程度上解决了这个问题，但在结构复杂性、接口泛化性、多接口组合检测等方面仍存在明显局限。

Method: 提出了一种基于模型级变异测试的方法（ModelMeta），利用四种聚焦于深度学习模型结构特征的变异关系。通过扩展种子模型和多接口组合生成等价测试输入，并结合QR-DQN策略，引导测试生成。该方法进一步通过训练损失、梯度、内存/GPU资源利用和执行时间等多维度细粒度分析发现框架缺陷。

Result: ModelMeta能够覆盖更多的接口组合与模型结构，生成多样化的测试输入，并能检测到更多与多接口组合及运行时指标相关的深度学习框架缺陷，提升了缺陷检测的有效性和广泛性。

Conclusion: ModelMeta弥补了现有方法在测试输入多样性、接口泛化性以及检测能覆盖多接口组合和运行时指标方面的不足，为DL框架的自动化安全测试提供了更有效的手段。

Abstract: Deep learning (DL) frameworks are essential to DL-based software systems, and
framework bugs may lead to substantial disasters, thus requiring effective
testing. Researchers adopt DL models or single interfaces as test inputs and
analyze their execution results to detect bugs. However, floating-point errors,
inherent randomness, and the complexity of test inputs make it challenging to
analyze execution results effectively, leading to existing methods suffering
from a lack of suitable test oracles. Some researchers utilize metamorphic
testing to tackle this challenge. They design Metamorphic Relations (MRs) based
on input data and parameter settings of a single framework interface to
generate equivalent test inputs, ensuring consistent execution results between
original and generated test inputs. Despite their promising effectiveness, they
still face certain limitations. (1) Existing MRs overlook structural
complexity, limiting test input diversity. (2) Existing MRs focus on limited
interfaces, which limits generalization and necessitates additional
adaptations. (3) Their detected bugs are related to the result consistency of
single interfaces and far from those exposed in multi-interface combinations
and runtime metrics (e.g., resource usage). To address these limitations, we
propose ModelMeta, a model-level metamorphic testing method for DL frameworks
with four MRs focused on the structure characteristics of DL models. ModelMeta
augments seed models with diverse interface combinations to generate test
inputs with consistent outputs, guided by the QR-DQN strategy. It then detects
bugs through fine-grained analysis of training loss/gradients, memory/GPU
usage, and execution time.

</details>


### [19] [DevMuT: Testing Deep Learning Framework via Developer Expertise-Based Mutation](https://arxiv.org/abs/2507.04360)
*Yanzhou Mu,Juan Zhai,Chunrong Fang,Xiang Chen,Zhixiang Cao,Peiran Yang,Yinglong Zou,Tao Zheng,Zhenyu Chen*

Main category: cs.SE

TL;DR: 本文提出了结合开发者实际操作的新型深度学习框架测试方法DevMuT，能检测到更有意义、高价值的缺陷，在多个主流深度学习框架和实际应用中表现优异，并已在社区中成功应用。


<details>
  <summary>Details</summary>
Motivation: 深度学习框架是众多DL应用的基础设施，框架中的缺陷可能导致严重事故，因此需要高效的缺陷检测方法。此前的方法多通过变异技术生成多样的测试模型，但大多只能发现边缘或被开发者忽略的琐碎缺陷。亟需一种方法能发现开发者真正关心的重要缺陷。

Method: 提出了一种新的深度学习框架测试方法DevMuT。该方法结合开发者经验设计变异操作及约束，模拟开发者常见操作，涵盖DL模型生命周期多个阶段（如训练和推理），以生成更加多样且实用的测试模型，用于发现更多有实际意义的缺陷。

Result: DevMuT在PyTorch、JAX和MindSpore三个主流框架及九类行业任务的29个模型上测试，模型多样性提升71.68%，生成模型合法率提升28.20%；共检测到117个缺陷，其中63个被确认，24个已修复，8个被开发者认为是高价值缺陷。

Conclusion: DevMuT能发现开发者关心、贴近真实场景的框架缺陷，优于现有方法，并已经在MindSpore社区实际部署应用，验证了其实用价值。

Abstract: Deep learning (DL) frameworks are the fundamental infrastructure for various
DL applications. Framework defects can profoundly cause disastrous accidents,
thus requiring sufficient detection. In previous studies, researchers adopt DL
models as test inputs combined with mutation to generate more diverse models.
Though these studies demonstrate promising results, most detected defects are
considered trivial (i.e., either treated as edge cases or ignored by the
developers). To identify important bugs that matter to developers, we propose a
novel DL framework testing method DevMuT, which generates models by adopting
mutation operators and constraints derived from developer expertise. DevMuT
simulates developers'common operations in development and detects more diverse
defects within more stages of the DL model lifecycle (e.g., model training and
inference). We evaluate the performance of DevMuT on three widely used DL
frameworks (i.e., PyTorch, JAX, and Mind- Spore) with 29 DL models from nine
types of industry tasks. The experiment results show that DevMuT outperforms
state-of-the-art baselines: it can achieve at least 71.68% improvement on
average in the diversity of generated models and 28.20% improvement on average
in the legal rates of generated models. Moreover, DevMuT detects 117 defects,
63 of which are confirmed, 24 are fixed, and eight are of high value confirmed
by developers. Finally, DevMuT has been deployed in the MindSpore community
since December 2023. These demonstrate the effectiveness of DevMuT in detecting
defects that are close to the real scenes and are of concern to developers.

</details>


### [20] [Exploring React Library Related Questions on Stack Overflow: Answered vs. Unanswered](https://arxiv.org/abs/2507.04390)
*Vanesya Aura Ardity,Yusuf Sulistyo Nugroho,Syful Islam*

Main category: cs.SE

TL;DR: 本文通过对SO上53万多条React问题的分析，发现浏览量、代码等有利于问题被回答，而评论数、长度、图片等不利于反应，同时有经验的人倾向于提出更难的问题。


<details>
  <summary>Details</summary>
Motivation: 虽然React相关的问题在Stack Overflow（SO）上数量众多且热门，但仍有大量问题未被回答，因此该研究旨在分析影响React相关问题可回答性及难度的因素。

Method: 应用探索性数据分析（EDA），结合文本挖掘和统计分析，对23个React相关标签下共534,820个问题进行分析。采用逻辑回归模型识别影响问题可回答性的属性，使用简单线性回归分析用户声誉与难度分数之间的关系。

Result: 浏览量、代码片段、代码行数和用户声誉提升了问题回答的概率；评论数量、问题长度与图片的存在则降低了回应概率。用户声誉越高，其提出问题的PD分数越低，表明经验丰富用户 tend to 提出更复杂的技术问题。

Conclusion: 研究发现问题的某些特征（如浏览量、包含代码片段、代码行数和用户声誉）正向影响问题的可回答性，而评论数量、问题长度和图片的存在反向影响回答概率。此外，用户声誉与问题难度得分（PD Score）呈负相关，高声誉用户更可能提出复杂技术问题。

Abstract: React is a popular JavaScript framework in modern web application
development. Due to its high performance and efficiency, many developers use
this framework. Although React library offers many advantages, it is not
without its challenges. When using React library, developers often face
problems where they often seek solutions through question-and-answer forums,
such as Stack Overflow (SO). However, despite its high popularity, many
React-related questions on SO remain unanswered. Thus, this study aims to
analyze the factors associated with question answerability and difficulty
levels of React-related questions on SO. To facilitate our study, Exploratory
Data Analysis was applied to 534,820 questions, where they are filtered based
on 23 React-related tags. We implemented a quantitative approach through text
mining and statistical analysis. A logistic regression model was used to
identify attributes associated with question answerability, while a simple
linear regression model was employed to examine the correlation between user
reputations and performance difficulty scores (PD Score). The results show that
some attributes, such as number of views, code snippet inclusion, number of
lines of code, and user reputation, positively affect the likelihood of
question answerability. In contrast, the number of comments, question lengths,
and presence of images in React-related questions reduce the probability of a
question receiving responses from users. Further investigation indicates a
negative correlation between user reputations and PD Score, where reputation
increase corresponds to -0.092 reduction in PD score, signaling experienced
users tend to propose more complex technical inquiries. This study provides
insights into the characteristics of technical question-and-answer platforms,
such as SO, that users need to consider the answerability factors when posting
questions related to React.

</details>


### [21] [Learning Software Bug Reports: A Systematic Literature Review](https://arxiv.org/abs/2507.04422)
*Guoming Long,Jingzhi Gong,Hui Fang,Tao Chen*

Main category: cs.SE

TL;DR: 本文对机器学习在软件漏洞报告分析中的应用进行了系统综述，详细总结了当前主流的技术、方法和面临的挑战，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 人工智能，特别是机器学习在软件工程中的漏洞报告分析领域影响日益显著，然而相关方法和进展尚缺乏系统性综述。

Method: 采用系统性文献综述方法，检索1825篇相关论文，并对其中204篇进行了深入分析。

Result: 总结了当前应用的主要机器学习模型（如CNN、LSTM、kNN）、特征提取方式（Word2Vec、TF-IDF和深度学习）、预处理手段（停用词删除等），以及主流评估数据集、任务类型、关注重点、评测指标与模型验证方法，并发现多数研究缺乏严谨的统计检验。

Conclusion: 本文系统性梳理了机器学习用于漏洞报告分析的主要方法、现状与挑战，指明了未来六大研究方向，为该领域的学术研究和工业应用提供有价值的借鉴和参考。

Abstract: The recent advancement of artificial intelligence, especially machine
learning (ML), has significantly impacted software engineering research,
including bug report analysis. ML aims to automate the understanding,
extraction, and correlation of information from bug reports. Despite its
growing importance, there has been no comprehensive review in this area. In
this paper, we present a systematic literature review covering 1,825 papers,
selecting 204 for detailed analysis. We derive seven key findings: 1) Extensive
use of CNN, LSTM, and $k$NN for bug report analysis, with advanced models like
BERT underutilized due to their complexity. 2) Word2Vec and TF-IDF are popular
for feature representation, with a rise in deep learning approaches. 3) Stop
word removal is the most common preprocessing, with structural methods rising
after 2020. 4) Eclipse and Mozilla are the most frequently evaluated software
projects. 5) Bug categorization is the most common task, followed by bug
localization and severity prediction. 6) There is increasing attention on
specific bugs like non-functional and performance bugs. 7) Common evaluation
metrics are F1-score, Recall, Precision, and Accuracy, with $k$-fold
cross-validation preferred for model evaluation. 8) Many studies lack robust
statistical tests. We also identify six promising future research directions to
provide useful insights for practitioners.

</details>


### [22] [SPIRA: Building an Intelligent System for Respiratory Insufficiency Detection](https://arxiv.org/abs/2507.04548)
*Renato Cordeiro Ferreira,Dayanne Gomes,Vitor Tamae,Francisco Wernke,Alfredo Goldman*

Main category: cs.SE

TL;DR: 该论文介绍了一种利用声音检测呼吸功能不全的智能系统SPIRA，重点讨论了两次系统实现中的关键挑战，并总结了数据收集、训练与推断的实践经验，对未来相关项目有重要参考价值。


<details>
  <summary>Details</summary>
Motivation: 呼吸功能不全是一种导致血液含氧量下降的医学症状。为预警和检测该症状，开发一种基于声音分析的智能检测系统，对提高诊断效率具有重大意义。

Method: 通过两次连续实现同一架构，系统化总结了搭建过程中的挑战，并对数据收集、模型训练和推断流程进行了经验归纳。

Result: 系统总结了两次系统实现过程中遇到的挑战，并为未来类似系统的研究和开发提供了重要经验和策略。

Conclusion: 该论文总结了基于声音检测呼吸功能不全的智能系统SPIRA的两代实现经验，并提炼了数据收集、模型训练以及推断过程中的关键经验教训。

Abstract: Respiratory insufficiency is a medic symptom in which a person gets a reduced
amount of oxygen in the blood. This paper reports the experience of building
SPIRA: an intelligent system for detecting respiratory insufficiency from
voice. It compiles challenges faced in two succeeding implementations of the
same architecture, summarizing lessons learned on data collection, training,
and inference for future projects in similar systems.

</details>


### [23] [Testing, Evaluation, Verification and Validation (TEVV) of Digital Twins: A Comprehensive Framework](https://arxiv.org/abs/2507.04555)
*Gabriella Waters*

Main category: cs.SE

TL;DR: 随着数字孪生技术发展，本文提出了一套用于数字孪生测试与验证的框架，以提升其准确性与可信度。


<details>
  <summary>Details</summary>
Motivation: 数字孪生在多个领域得到广泛应用，但其日益复杂性对准确性、可靠性及伦理实现提出了更高要求，亟需建立系统的测试和评估方法。

Method: 文中使用了文献回顾与理论分析，总结了当前数字孪生应用中面临的主要问题，并提出了系统性的TEVV流程框架。

Result: 研究形成了面向数字孪生模型的TEVV系统方法，有助于促进其安全、高效和合规应用。

Conclusion: 本文提出了一个完善的数字孪生测试、评估、验证与确认（TEVV）框架，用以全面解决数字孪生模型在当前及未来发展中的一系列独特挑战。

Abstract: Digital twins have emerged as a powerful technology for modeling and
simulating complex systems across various domains (Fuller et al., 2020; Tao et
al., 2019). As virtual representations of physical assets, processes, or
systems, digital twins enable real-time monitoring, predictive analysis, and
optimization. However, as digital twins become more sophisticated and integral
to decision-making processes, ensuring their accuracy, reliability, and ethical
implementation is essential. This paper presents a comprehensive framework for
the Testing, Evaluation, Verification and Validation (TEVV) of digital twins to
address the unique challenges posed by these dynamic and complex virtual
models.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [24] [The Dependently Typed Higher-Order Form for the TPTP World](https://arxiv.org/abs/2507.03208)
*Daniel Ranalter,Cezary Kaliszyk,Florian Rabe,Geoff Sutcliffe*

Main category: cs.LO

TL;DR: 本文提出了TPTP依赖型高阶形式（DTF），在保留原语言兼容性的基础上增强了自动推理表达能力，并已在多个实例和工具中得到应用。


<details>
  <summary>Details</summary>
Motivation: 自动推理领域很多研究和开发基于TPTP World。TPTP语言在该领域广泛采用，但需要扩展其表达能力以适应更高级的推理需求。

Method: 本文提出了TPTP语言的依赖型高阶形式（DTF），是对现有Typed Higher-order Form (THF)的最小侵入性扩展，并且重用既有语法机制。还提供了100多个样例问题展示DTF的实用性，并讨论了已有能够支持DTF推理的工具。

Result: DTF在语法和功能上对TPTP语言进行了增强，并展示了实际应用案例，同时已有工具能够对DTF问题进行推理。

Conclusion: DTF形式增强了TPTP语言体系，提高了其表达力和工具兼容性，推进了自动推理领域的发展。

Abstract: Much of the current research and development in the field of automated
reasoning builds on the infrastructure provided by the TPTP World. The TPTP
language for logical formulae is central to the far-reaching adoption of the
TPTP World. This paper introduces the Dependently Typed higher-order Form (DTF)
of the TPTP language. It takes advantage of already established binders in the
syntax, and is thus a minimally intrusive extension to the Typed Higher-order
Form (THF). A starting set of over 100 problems is provided to exhibit the
usefulness and incite interest in DTF. Some tools that are already able to
reason about problems in the DTF language are discussed.

</details>


### [25] [Partial Label Learning for Automated Theorem Proving](https://arxiv.org/abs/2507.03314)
*Zsolt Zombori,Balázs Indruck*

Main category: cs.LO

TL;DR: 本论文首次将部分标签学习理论引入自动定理证明，提出新颖的理论框架处理替代性证明路径，并通过plCoP证明器实验验证，证实PLL方法能提升自动定理证明性能。


<details>
  <summary>Details</summary>
Motivation: 在自动定理证明中，常常存在多种证明路径，如何在学习过程中有效处理和利用这些不同的证明选择是一个挑战。部分标签学习为处理有多重标签选择的学习场景提供了解决思路，因此尝试将其应用到定理证明领域。

Method: 将学习驱动的自动定理证明问题建模为部分标签学习问题，并利用plCoP定理证明器，结合PLL领域的方法进行实验验证。

Result: 采用部分标签学习方法后，实验结果显示可有效提升带有学习辅助的定理证明器的性能。

Conclusion: 将自动定理证明（Automated Theorem Proving, ATP）与部分标签学习（Partial Label Learning, PLL）结合，可以为处理学习过程中存在的多种可能证明方式提供理论支持，并提升定理证明器的表现。

Abstract: We formulate learning guided Automated Theorem Proving as Partial Label
Learning, building the first bridge across these fields of research and
providing a theoretical framework for dealing with alternative proofs during
learning. We use the plCoP theorem prover to demonstrate that methods from the
Partial Label Learning literature tend to increase the performance of learning
assisted theorem provers.

</details>


### [26] [Difference of Constrained Patterns in Logically Constrained Term Rewrite Systems (Full Version)](https://arxiv.org/abs/2507.04080)
*Naoki Nishida,Misaki Kojima,Yuto Nakamura*

Main category: cs.LO

TL;DR: 本文扩展了差异与补集算法以覆盖逻辑约束重写系统中的受约束线性模式，从而使准可约性在特定LCTRS中可判定，并提升了相关算子的适用范围。


<details>
  <summary>Details</summary>
Motivation: 在术语重写系统（特别是逻辑约束术语重写系统，LCTRSs）中，准确表示和分析模式之间的差异与补集对判定某些性质（如准可约性）至关重要。现有方法对于带约束的线性模式（constrained linear patterns）及其补集算法存在限制，因此有必要扩展这些基本运算，以增强对更广泛系统的分析能力。

Method: 本文扩展了现有针对线性模式的“差异算子”和“补集算法”，使其适用于LCTRS中受约束的线性模式，前提是其中不包含带内建值类型的用户自定义构造子项。并借助这种扩展的算法，进一步证明了针对这类LCTRS，若内建理论可判定，则准可约性也可判定。此外，对于差异算子而言，只需要被除数（divisor）模式是线性的，而被减数（dividend）可以更一般。

Result: 本文提出的扩展算法能够有效生成受约束线性模式的差异集与补集，从而支持上述LCTRS中准可约性的可判定性分析，并进一步放宽了差异算子对被减数模式的要求。

Conclusion: 通过对差异算子与补集算法的扩展，本文使得LCTRS（在特定条件下）上的准可约性判定成为可能，并为此类推理任务提供了理论工具和算法基础。

Abstract: Considering patterns as sets of their instances, a difference operator over
patterns computes a finite set of two given patterns, which represents the
difference between the dividend pattern and the divisor pattern. A complement
of a pattern is a set of patterns, the ground constructor instances of which
comprise the complement set of the ground constructor instances of the former
pattern. Given finitely many unconstrained linear patterns, using a difference
operator over linear patterns, a known complement algorithm returns a finite
set of linear patterns as a complement of the given patterns. In this paper, we
extend the difference operator and complement algorithm to constrained linear
patterns used in logically constrained term rewrite systems (LCTRSs, for short)
that have no user-defined constructor term with a sort for built-in values.
Then, as for left-linear TRSs, using the complement algorithm, we show that
quasi-reducibility is decidable for such LCTRSs with decidable built-in
theories. For the single use of the difference operator over (constrained)
patterns, only divisor patterns are required to be linear.

</details>


### [27] [A Note on Runtime Verification of Concurrent Systems](https://arxiv.org/abs/2507.04830)
*Martin Leucker*

Main category: cs.LO

TL;DR: 提出基于部分有序轨迹的三值LTrL逻辑和监控器合成方法，以提升并发系统验证的效率和一致性。


<details>
  <summary>Details</summary>
Motivation: 为了提高验证并发系统时的信息获取效率，希望从一次执行中推导出所有与并发相关的等价执行，并检查它们是否满足线性规范。传统的基于序列的方法难以高效实现这一目标，因此需要新的理论工具。

Method: 提出使用基于轨迹（trace-based）的逻辑LTrL（Linear Temporal Logic over Mazurkiewicz Traces），它以部分有序执行为基础。该方法推广到三值形式，能够区分正确、错误和不确定三种情况，并结合trace-consistent Büchi自动机实现监控器（monitor）的自动化合成。

Result: 提出了一种三值LTrL，并设计了相应的监控器合成过程。对于任意观测到的部分有序轨迹，无论采用哪种等价线性化，监控器都能给出一致的验证结论。

Conclusion: 基于轨迹的逻辑和监控器合成方法能更高效地验证并发系统的一致性和正确性，相比传统方法显著提升了信息利用率和自动化程度。

Abstract: To maximize the information gained from a single execution when verifying a
concurrent system, one can derive all concurrency-aware equivalent executions
and check them against linear specifications. This paper offers an alternative
perspective on verification of concurrent systems by leveraging trace-based
logics rather than sequence-based formalisms. Linear Temporal Logic over
Mazurkiewicz Traces (LTrL) operates on partial-order representations of
executions, meaning that once a single execution is specified, all equivalent
interleavings are implicitly considered. This paper introduces a three valued
version of LTrL, indicating whether the so-far observed execution of the
concurrent system is one of correct, incorrect or inconclusive, together with a
suitable monitor synthesis procedure. To this end, the paper recalls a
construction of trace-consistent B\"uchi automata for LTrL formulas and
explains how to employ it in well-understood monitor synthesis procedures. In
this way, a monitor results that yields for any linearization of an observed
trace the same verification verdict.

</details>


### [28] [Omega-regular Verification and Control for Distributional Specifications in MDPs](https://arxiv.org/abs/2507.04286)
*S. Akshay,Ouldouz Neysari,Đorđe Žikelić*

Main category: cs.LO

TL;DR: 提出了首个针对MDP分布性ω正则规范的全自动验证和控制方法，理论上可靠并在实验中具备实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 传统对马尔可夫决策过程（MDP）的研究以状态变换为主，但在实际应用中，MDP可以作为分布变换器，其中策略下的MDP生成一系列MDP状态的概率分布序列。分布视角下的概率验证和控制问题比经典状态视角更难，相关基础问题已经被证明在计算上是困难的。已有方法的自动化验证仅适用于特定的分布性目标和规范。

Method: 本文首次提出了一种针对MDPs分布性ω正则规范的自动化验证与控制方法。核心创新是提出了分布性证明证书的全新概念，可作为证明策略下MDP满足某种分布性ω正则规范的完整证明规则。利用这些证书，设计了基于模板综合法的全自动算法，并提供了可靠性和相对完备性的理论保证。

Result: 算法在PSPACE复杂度下工作，并经过原型实现，对多个来自文献中的挑战性例子进行了实验，展示了其实用性。

Conclusion: 该工作首次实现了对MDP分布性ω正则规范的全自动验证和控制，并推动了分布视角下MDP理论和应用的自动化能力。

Abstract: A classical approach to studying Markov decision processes (MDPs) is to view
them as state transformers. However, MDPs can also be viewed as distribution
transformers, where an MDP under a strategy generates a sequence of probability
distributions over MDP states. This view arises in several applications, even
as the probabilistic model checking problem becomes much harder compared to the
classical state transformer counterpart. It is known that even distributional
reachability and safety problems become computationally intractable (Skolem-
and positivity-hard). To address this challenge, recent works focused on sound
but possibly incomplete methods for verification and control of MDPs under the
distributional view. However, existing automated methods are applicable only to
distributional reachability, safety and reach-avoidance specifications.
  In this work, we present the first automated method for verification and
control of MDPs with respect to distributional omega-regular specifications. To
achieve this, we propose a novel notion of distributional certificates, which
are sound and complete proof rules for proving that an MDP under a
distributionally memoryless strategy satisfies some distributional
omega-regular specification. We then use our distributional certificates to
design the first fully automated algorithms for verification and control of
MDPs with respect to distributional omega-regular specifications. Our
algorithms follow a template-based synthesis approach and provide soundness and
relative completeness guarantees, while running in PSPACE. Our prototype
implementation demonstrates practical applicability of our algorithms to
challenging examples collected from the literature.

</details>


### [29] [Shininess, strong politeness, and unicorns](https://arxiv.org/abs/2507.04445)
*Benjamin Przybocki,Guilherme V. Toledo,Yoni Zohar*

Main category: cs.LO

TL;DR: 本文完善理论组合中Shininess和Strong Politeness两个属性的关系分类，证明Shininess总是可判定且意味着Strong Politeness，同时构造了非Shiny但Strong Polite的不可判定理论，彻底解决了此前的所有未解问题。


<details>
  <summary>Details</summary>
Motivation: 理论组合中的Shininess和Strong Politeness属性在判定性和理论结构分析中十分重要。此前研究未能穷尽所有两者之间的关系，本研究旨在完善分类并解决剩余的开放性问题。

Method: 在已有理论的基础上，细致分析了Shininess和Strong Politeness之间的关系。通过构造反例和理论证明等手段，展示了Shininess总是可判定且意味着Strong Politeness，以及存在不可判定但Strong Politeness成立而非Shininess的理论。

Result: 主要结果包括：Shininess总是可判定且因此必然Strong Polite；但存在不可判定的Strong Polite理论却不满足Shininess。该研究彻底完成了理论组合属性间关系的分类工作。

Conclusion: 本文通过对理论组合中Shininess和Strong Politeness特性的研究，完成并完善了之前关于这些特性相互关系的分类工作，解决了全部遗留的开放问题。

Abstract: Shininess and strong politeness are properties related to theory combination
procedures. In a paper titled "Many-sorted equivalence of shiny and strongly
polite theories", Casal and Rasga proved that for decidable theories, these
properties are equivalent. We refine their result by showing that: (i) shiny
theories are always decidable, and therefore strongly polite; and (ii) there
are (undecidable) strongly polite theories that are not shiny. This line of
research is tightly related to a recent series of papers that have sought to
classify all the relations between theory combination properties. We finally
complete this project, resolving all of the remaining problems that were
previously left open.

</details>


### [30] [Proof Analysis of A Foundational Classical Singlesuccedent Sequent Calculus](https://arxiv.org/abs/2507.04449)
*Khashayar Irani*

Main category: cs.LO

TL;DR: 该文提出一种新的经典单结论序列演算系统G-Calculus，通过严谨论证表明其可填补现有系统不足，成为Gentzen的人LK系统的理想继承者，并在理论和推理能力上达到经典证明论预期。


<details>
  <summary>Details</summary>
Motivation: 目前尚无一个公认的经典单结论序列演算能够被视作Gentzen的LK系统的正统继承者。现有如Negri和von Plato的相关系统，并未充分满足经典证明论家的理论期望。论文旨在填补这一区域的理论空白。

Method: 通过分析并对比现有的经典单结论序列演算，结合对其优缺点的梳理，作者制定出一套新的序列演算系统G-Calculus并重点介绍其经典化分支（Gc），并对比其与前人系统的不同及优势。

Result: 提出了G-Calculus及其经典分支Gc，系统性地论证其在形式、推理能力及理论完整性等方面满足了经典证明论家的各项期望，并以命题和谓词两层面进行详尽分析。

Conclusion: G-Calculus及其Gc分支已经被设计为经典单结论序列演算领域中达成理论完善性的新方案，可作为LK系统的合格继任者。现有系统仍有不足，而该系统可弥补并超越先前的局限。

Abstract: In this paper we investigate the question: 'How can A Foundational Classical
Singlesuccedent Sequent Calculus be formulated?' The choice of this particular
area of proof-theoretic study is based on a particular ground that is, to
formulate a robust and foundational classical singlesuccedent sequent calculus
that includes a number of novel rules with the ultimate aim of deriving the
singlesuccedent sequent {\Gamma} sequent arrow C. To this end, we argue that
among all standard sequent calculi (at least to the best of our knowledge)
there is no classical singlesuccedent sequent calculus that can be considered
the rightful successor to Gerhard Gentzen's (1935) original LK system. However,
we also contend that while several classical singlesuccedent sequent calculi
exist such as Sara Negri's and Jan von Plato's (2001 & 2011) G3ip+Gem-at and
G0ip+Gem0-at calculi, none of these proof systems possess the classical
proof-theoretic potential to meet the formal expectations of a dedicated
classical proof theorist. Conversely, we shall demonstrate that our forthcoming
system, namely G-Calculus through its classical division i.e. Gc has been
entirely designed to meet these expectations. Prior to commencing our enquiry,
a supplementary note must be made and that is in this work when discussing
various sequent calculi, for proof-theoretic purposes, we are primarily
concerned with their propositional components rather than their predicate
divisions except in G-Calculus where we examine both aspects.

</details>


### [31] [Testing for Renamability to Classes of Clause Sets](https://arxiv.org/abs/2507.05044)
*Albert Brandl,Christian G. Fermüller,Gernot Salzer*

Main category: cs.LO

TL;DR: 本论文研究了通过谓词重命名判断子句集是否属于某些逻辑类，并发现部分类（如Horn和OCC1N）可多项式判定，而PVD类该问题为NP-完全。采用超分辨率判定方法。


<details>
  <summary>Details</summary>
Motivation: 该论文关注逻辑子句集是否属于某些文献中已定义的类，尤其是通过谓词重命名实现。重命名是否可将正负文字调整到满足某些条件，是判定特定逻辑表达能力及自动推理划分复杂度的关键。

Method: 论文分析了通过谓词重命名来判断逻辑子句集是否属于如Horn、OCC1N、PVD等逻辑类的方法。主要利用超分辨率技术，构建判定过程，并能够从最终的饱和子句集中提取有效重命名。

Result: 发现对于Horn类和OCC1N类，通过谓词重命名判断其成员性可以在多项式时间内完成；而针对PVD类，该判定问题是NP-完全的。

Conclusion: 论文表明，不同逻辑类在谓词重命名下的成员检测复杂度存在巨大差异，并提出了相应的高效算法和复杂性下界。

Abstract: This paper investigates the problem of testing clause sets for membership in
classes known from literature. In particular, we are interested in classes
defined via renaming: Is it possible to rename the predicates in a way such
that positive and negative literals satisfy certain conditions? We show that
for classes like Horn or OCC1N, the existence of such renamings can be decided
in polynomial time, whereas the same problem is NP-complete for class PVD. The
decision procedures are based on hyper-resolution; if a renaming exists, it can
be extracted from the final saturated clause set.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [32] [Loki's Dance of Illusions: A Comprehensive Survey of Hallucination in Large Language Models](https://arxiv.org/abs/2507.02870)
*Chaozhuo Li,Pengbo Wang,Chenxu Wang,Litian Zhang,Zheng Liu,Qiwei Ye,Yuanbo Xu,Feiran Huang,Xi Zhang,Philip S. Yu*

Main category: cs.CL

TL;DR: 本文系统梳理了大语言模型幻觉问题的产生原因、检测方法和应对策略，评估了现有措施的有效性，为创新性解决方案提供了理论支持，对幻觉问题的研究起到了推动作用。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的普及，其在生成文本信息时所产生的“幻觉”（即看似真实但实际为虚假的信息）问题日益突出。该问题在金融、法律、医疗等高风险领域可能导致重大损失。因此，理解、检测和解决幻觉问题成为该领域的重要研究动机。

Method: 该研究系统性地对LLM幻觉现象进行了分类，分析了其成因，并梳理了相关的检测方法和解决方案。此外，研究还着重评估了当前主流策略在揭示幻觉生成机制上的有效性。

Result: 研究对LLM幻觉的成因及解决措施进行了系统的归纳和评估，指出了现有策略的优缺点，并为创新性更强的应对方法提供了理论基础。

Conclusion: 该研究加深了对大语言模型中幻觉现象的理解，总结了有效的检测和干预策略，并为未来开发更强大且创新的方法应对幻觉问题奠定了基础。

Abstract: Edgar Allan Poe noted, "Truth often lurks in the shadow of error,"
highlighting the deep complexity intrinsic to the interplay between truth and
falsehood, notably under conditions of cognitive and informational asymmetry.
This dynamic is strikingly evident in large language models (LLMs). Despite
their impressive linguistic generation capabilities, LLMs sometimes produce
information that appears factually accurate but is, in reality, fabricated, an
issue often referred to as 'hallucinations'. The prevalence of these
hallucinations can mislead users, affecting their judgments and decisions. In
sectors such as finance, law, and healthcare, such misinformation risks causing
substantial economic losses, legal disputes, and health risks, with
wide-ranging consequences.In our research, we have methodically categorized,
analyzed the causes, detection methods, and solutions related to LLM
hallucinations. Our efforts have particularly focused on understanding the
roots of hallucinations and evaluating the efficacy of current strategies in
revealing the underlying logic, thereby paving the way for the development of
innovative and potent approaches. By examining why certain measures are
effective against hallucinations, our study aims to foster a comprehensive
approach to tackling this issue within the domain of LLMs.

</details>


### [33] [ChatGPT is not A Man but Das Man: Representativeness and Structural Consistency of Silicon Samples Generated by Large Language Models](https://arxiv.org/abs/2507.02919)
*Dai Li,Linzhuo Li,Huilian Sophie Qiu*

Main category: cs.CL

TL;DR: 该研究指出，当前主流LLM在模拟人类意见时存在结构性失真和少数声音被忽略的问题，警惕其应用于社会科学调查和政策制定。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）如ChatGPT和Llama被用作“硅样本”来模拟人类意见，学界对其是否能真实反映人口意见结构产生质疑。

Method: 作者通过让ChatGPT（GPT-4）和Meta的Llama 3.1系列（8B、70B、405B）回答美国国家选举研究（ANES）2020中关于堕胎和非法移民的问题，来比较其与真实人类数据之间的差异。

Result: 研究发现，LLMs的回答存在明显的结构性不一致以及对少数意见的严重同质化，即相比真实人群，模型更倾向于给出主流答案，忽视了少数意见。

Conclusion: LLMs目前并不能作为可靠的“人类意见替代品”。直接用它们模拟舆情数据会失真，甚至可能加剧刻板印象、误导政策。

Abstract: Large language models (LLMs) in the form of chatbots like ChatGPT and Llama
are increasingly proposed as "silicon samples" for simulating human opinions.
This study examines this notion, arguing that LLMs may misrepresent
population-level opinions. We identify two fundamental challenges: a failure in
structural consistency, where response accuracy doesn't hold across demographic
aggregation levels, and homogenization, an underrepresentation of minority
opinions. To investigate these, we prompted ChatGPT (GPT-4) and Meta's Llama
3.1 series (8B, 70B, 405B) with questions on abortion and unauthorized
immigration from the American National Election Studies (ANES) 2020. Our
findings reveal significant structural inconsistencies and severe
homogenization in LLM responses compared to human data. We propose an
"accuracy-optimization hypothesis," suggesting homogenization stems from
prioritizing modal responses. These issues challenge the validity of using
LLMs, especially chatbots AI, as direct substitutes for human survey data,
potentially reinforcing stereotypes and misinforming policy.

</details>


### [34] [A Unified Speech LLM for Diarization and Speech Recognition in Multilingual Conversations](https://arxiv.org/abs/2507.02927)
*Phurich Saengthong,Boonnithi Jiaramaneepinit,Sheng Li,Manabu Okumura,Takahiro Shinozaki*

Main category: cs.CL

TL;DR: 提出了一种能同时进行说话人分离和语音识别的统一型语音LLM，通过创新数据与推理流程，在多语种对话挑战赛中显著优于基线，并在小模型条件下获得第8名。


<details>
  <summary>Details</summary>
Motivation: 尽管语音大语言模型（Speech LLM）提升了语音识别和对话建模等能力，但目前在真实多语种对话中的表现受到自然对话数据匮乏的限制。MLC-SLM挑战赛提供了对应的数据集和评测任务，有助于推动该方向的发展。

Method: 本文专注于Task II（联合说话人分离和语音识别任务），提出了一种端到端（end-to-end）的统一型语音LLM模型，通过重新设计训练数据格式和调整推理过程，实现了对未预分割音频的有效处理。同时也在Task I上采用微调的模型进行实验对比。

Result: 在Task II上，该模型在tcpWER/tcpCER指标上对比baseline取得了54.87%的相对提升，并在整体排名中获得第8名，且所用LLM主干小于其他队伍。此外，也报告了Task I的实验结果。

Conclusion: 联合建模、数据格式创新与推理流程优化，使得端到端的语音LLM显著提升了多语种自然对话环境下的识别与分离表现，即使在计算资源有限的条件下（小模型），也能取得较好成绩。

Abstract: Speech Large Language Models (Speech LLMs) have emerged as a crucial paradigm
in recent years, extending the capabilities of traditional LLMs to speech tasks
such as automatic speech recognition (ASR) and spoken dialogue modeling.
However, their effectiveness in real-world multilingual conversations remains
limited by the scarcity of data that captures natural conversational phenomena.
To address this, the MLC-SLM Challenge provides a multilingual conversational
dataset and evaluates models on two tasks: ASR with oracle segmentation (Task
I) and joint diarization and recognition without oracle information (Task II).
In this paper, we focus on Task II and propose a unified speech LLM that
jointly performs diarization and ASR in an end-to-end manner. By reformulating
the training data format and modifying the inference procedure, our model
addresses the ambiguity inherent in pre-segmented audio and achieves a 54.87\%
relative improvement in tcpWER/tcpCER over the baseline, ranking 8th overall,
despite using a smaller LLM backbone. We also report results from Task I using
a fine-tuned speech LLM.

</details>


### [35] [Mitigating Hidden Confounding by Progressive Confounder Imputation via Large Language Models](https://arxiv.org/abs/2507.02928)
*Hao Yang,Haoxuan Li,Luyu Chen,Haoxiang Wang,Xu Chen,Mingming Gong*

Main category: cs.CL

TL;DR: 本文提出ProCI方法，首次尝试利用大语言模型减轻观测数据中隐藏混杂导致的因果偏差。方法在多个数据集和模型上表现优异，有效提升了处理效应估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 在观测数据中估计处理效应时，隐藏混杂因素会导致因果估计产生偏差。虽然大语言模型（LLMs）已被用于因果推断，但现有方法大多依赖无混杂假设，难以应对隐藏混杂问题。

Method: 提出了ProCI（Progressive Confounder Imputation）框架，利用LLMs的语义推理能力和世界知识，迭代生成、填充并验证隐藏混杂变量。ProCI采取分布式推理而非直接值填充，以增强鲁棒性并避免输出收敛。

Result: 大量实验表明，ProCI能够发现有意义的混杂变量，并且在多种数据集和LLM模型上显著提升了处理效应估计的准确性。

Conclusion: ProCI通过调动LLMs的知识与推理能力，首次展示了利用大模型减轻隐藏混杂的可能性，为因果推断领域带来新的解决路径。

Abstract: Hidden confounding remains a central challenge in estimating treatment
effects from observational data, as unobserved variables can lead to biased
causal estimates. While recent work has explored the use of large language
models (LLMs) for causal inference, most approaches still rely on the
unconfoundedness assumption. In this paper, we make the first attempt to
mitigate hidden confounding using LLMs. We propose ProCI (Progressive
Confounder Imputation), a framework that elicits the semantic and world
knowledge of LLMs to iteratively generate, impute, and validate hidden
confounders. ProCI leverages two key capabilities of LLMs: their strong
semantic reasoning ability, which enables the discovery of plausible
confounders from both structured and unstructured inputs, and their embedded
world knowledge, which supports counterfactual reasoning under latent
confounding. To improve robustness, ProCI adopts a distributional reasoning
strategy instead of direct value imputation to prevent the collapsed outputs.
Extensive experiments demonstrate that ProCI uncovers meaningful confounders
and significantly improves treatment effect estimation across various datasets
and LLMs.

</details>


### [36] [Theory of Mind in Action: The Instruction Inference Task](https://arxiv.org/abs/2507.02935)
*Fardin Saad,Pradeep K. Murukannaiah,Munindar P. Singh*

Main category: cs.CL

TL;DR: 本文提出Instruction Inference任务，并实现了Tomcat智能体，通过结构化推理和常识提升AI的ToM能力，经实验验证在某些设定下Tomcat表现接近人类，为人机协作AI发展提供新视角。


<details>
  <summary>Details</summary>
Motivation: 理论心智(ToM)是智能体推断他人心理状态的能力，对协作至关重要，但在动态、目标导向、协同环境下，对AI ToM能力的系统测试较少。本文旨在填补这一评估空白。

Method: 作者提出了"Instruction Inference"新任务：在间接或模糊指令下，测评AI智能体协助他人达成目标的能力。提出Tomcat——一种基于大语言模型(LLM)的ToM推理型智能体，包含两种实现：（1）Fs-CoT(以少量范例演示结构化推理)；（2）CP(利用常识知识和上下文)。分别在GPT-4o、DeepSeek-R1、Gemma-3-27B三种LLM上实现。通过与52名人类参与者对比，采用intent accuracy、action optimality和planning optimality三个指标评估。

Result: Fs-CoT版本的Tomcat（尤其在GPT-4o和DeepSeek-R1上）在ToM相关指标上表现与人类参与者相当，显示出AI在人机协作中的心智推理潜力。

Conclusion: 基于大语言模型并经结构化推理训练的智能体，可展现与人类接近的理论心智推理能力，有望提升AI在人机协作领域的应用。

Abstract: The Theory of Mind (ToM) refers to an agent's capacity to infer the mental
states of other agents. ToM is essential for effective collaboration. To assess
ToM in a dynamic, goal-oriented, and collaborative environment, we introduce a
novel task, Instruction Inference, in which an agent assists a principal in
reaching a goal by interpreting indirect or ambiguous instructions. We present
Tomcat, an LLM-based agent, designed to exhibit ToM reasoning in interpreting
and responding to the principal's instructions. We implement two variants of
Tomcat. One, dubbed Fs-CoT, is based on a small number of examples (i.e.,
few-shot or Fs) demonstrating the requisite structured reasoning (i.e.,
chain-of-thought or CoT). One, dubbed CP, relies on commonsense knowledge and
information about the problem (i.e., commonsense prompt or CP). We realized
both variants of Tomcat on three leading large language models (LLMs), namely,
GPT-4o, DeepSeek-R1, and Gemma-3-27B. To evaluate the effectiveness of Tomcat,
we conducted a study with 52 human participants in which we provided
participants with the same information as the CP variant of Tomcat. We computed
intent accuracy, action optimality, and planning optimality to measure the ToM
capabilities of Tomcat and our study participants. We found that Tomcat with
Fs-CoT, particularly with GPT-4o and DeepSeek-R1, achieves performance
comparable to the human participants, underscoring its ToM potential for
human-AI collaboration.

</details>


### [37] [A Large Language Model-Empowered Agent for Reliable and Robust Structural Analysis](https://arxiv.org/abs/2507.02938)
*Jiachen Liu,Ziheng Geng,Ran Cao,Lu Cheng,Paolo Bocchini,Minghui Cheng*

Main category: cs.CL

TL;DR: 本文评估了LLM在梁结构分析中的可靠性与鲁棒性，发现其原始能力有限。通过代码生成新范式及自动执行，显著提升性能，准确率超99%。为LLM在工程领域的应用提供了切实可行的路径。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在许多通用领域任务中表现优异，但在如土木工程等专业领域的应用尚未充分研究。基于此，作者希望探索并提升LLM在结构力学分析（如梁的分析）中的可靠性与鲁棒性。

Method: （1）评价LLM（Llama-3.3 70B Instruct）在梁结构分析中的可靠性（多次同题输出正确率）和鲁棒性（在不同荷载和边界条件下的表现）；（2）提出将结构分析问题转化为代码生成任务，并开发集成链式思维与few-shot提示的LLM-agent，实现自动生产并运行 OpenSeesPy 代码；（3）通过消融实验分析影响性能提升的关键要素。

Result: 初步测试显示，虽然LLM对结构力学有一定定性理解，但在工程应用上可靠性和鲁棒性不足。基于代码生成的新方法显著提升了性能，LLM-agent在基准集上的准确率超过99.0%，鲁棒性优良。消融实验发现完整案例和函数使用示例是性能提升的关键。

Conclusion: LLM原生用于土木工程结构分析尚不具备工程级可靠性，但通过将任务转化为代码生成并自动执行，可极大提升可靠性和鲁棒性，显示出LLM在专业工程领域应用的巨大潜力。该方法对其他专业领域也有参考意义。

Abstract: Large language models (LLMs) have exhibited remarkable capabilities across
diverse open-domain tasks, yet their application in specialized domains such as
civil engineering remains largely unexplored. This paper starts bridging this
gap by evaluating and enhancing the reliability and robustness of LLMs in
structural analysis of beams. Reliability is assessed through the accuracy of
correct outputs under repetitive runs of the same problems, whereas robustness
is evaluated via the performance across varying load and boundary conditions. A
benchmark dataset, comprising eight beam analysis problems, is created to test
the Llama-3.3 70B Instruct model. Results show that, despite a qualitative
understanding of structural mechanics, the LLM lacks the quantitative
reliability and robustness for engineering applications. To address these
limitations, a shift is proposed that reframes the structural analysis as code
generation tasks. Accordingly, an LLM-empowered agent is developed that (a)
integrates chain-of-thought and few-shot prompting to generate accurate
OpeeSeesPy code, and (b) automatically executes the code to produce structural
analysis results. Experimental results demonstrate that the agent achieves
accuracy exceeding 99.0% on the benchmark dataset, exhibiting reliable and
robust performance across diverse conditions. Ablation studies highlight the
complete example and function usage examples as the primary contributors to the
agent's enhanced performance.

</details>


### [38] [Towards a Comparative Framework for Compositional AI Models](https://arxiv.org/abs/2507.02940)
*Tiffany Duneau*

Main category: cs.CL

TL;DR: 本研究基于DisCoCirc框架，利用范畴理论对自然语言处理模型的可组合性和可解释性进行了分析与实验。对比量子与经典模型，发现两者在某些可组合性任务上表现接近，但在系统性和泛化倾向上存在显著差异。神经网络易过拟合，且模型可组合性解释有可操作路径。


<details>
  <summary>Details</summary>
Motivation: 近年来，自然语言处理领域对模型的可组合性关注提高。本研究旨在探究不同模型（包括量子电路模型和经典神经网络）在文本可组合性、泛化能力和可解释性方面的行为及差异。

Method: 作者在DisCoCirc框架下，利用范畴理论形式化描述了可组合性与可解释性。然后基于bAbI任务扩展出的数据集，设计并对比了量子电路类模型与经典神经网络在多项可组合性任务上的表现。还进一步分析其中一个训练后的模型，解释了其模块间如何交互并驱动模型行为。

Result: 在产出性和可替换性任务中，两类模型表现相近，得分差距在5%以内。但在系统性任务上差距至少达到10%，在过度泛化任务上趋势也不同。神经网络模型在训练集上更容易过拟合。作者还展示了对一个训练模型的组合行为的解释。

Conclusion: DisCoCirc框架和相应的基准任务有助于系统性分析模型的可组合性及可解释性。量子与经典模型在可组合泛化上的细微表现差异揭示其各自的优劣。该框架有助于进一步探索和提升自然语言处理模型的泛化及解释能力。

Abstract: The DisCoCirc framework for natural language processing allows the
construction of compositional models of text, by combining units for individual
words together according to the grammatical structure of the text. The
compositional nature of a model can give rise to two things: compositional
generalisation -- the ability of a model to generalise outside its training
distribution by learning compositional rules underpinning the entire data
distribution -- and compositional interpretability -- making sense of how the
model works by inspecting its modular components in isolation, as well as the
processes through which these components are combined. We present these notions
in a framework-agnostic way using the language of category theory, and adapt a
series of tests for compositional generalisation to this setting.
  Applying this to the DisCoCirc framework, we consider how well a selection of
models can learn to compositionally generalise. We compare both quantum circuit
based models, as well as classical neural networks, on a dataset derived from
one of the bAbI tasks, extended to test a series of aspects of
compositionality. Both architectures score within 5% of one another on the
productivity and substitutivity tasks, but differ by at least 10% for the
systematicity task, and exhibit different trends on the overgeneralisation
tasks. Overall, we find the neural models are more prone to overfitting the
Train data. Additionally, we demonstrate how to interpret a compositional model
on one of the trained models. By considering how the model components interact
with one another, we explain how the model behaves.

</details>


### [39] [The Application of Large Language Models on Major Depressive Disorder Support Based on African Natural Products](https://arxiv.org/abs/2507.02947)
*Linyan Zou*

Main category: cs.CL

TL;DR: 本研究结合非洲传统草药知识与大型语言模型，开发了智能化抑郁症支持系统，有望为患者提供科学、安全、个性化和注重文化的治疗建议。


<details>
  <summary>Details</summary>
Motivation: 传统抗抑郁药物存在起效慢、副作用大和部分患者治疗无效等局限。因此，研究人员寻求替代疗法，非洲传统医学中丰富的草药资源成为开发新型抗抑郁治疗手段的重要方向。

Method: 本研究系统分析了具有抗抑郁作用的非洲药用植物及其药理机制，并开发了一个结合DeepSeek大型语言模型能力的AI支持系统，能够为用户提供基于证据的非洲草药信息、临床应用、安全性和治疗方案。

Result: 该系统能够科学、合理地提供与非洲传统药物相关的抑郁症支持服务，实现传统智慧与现代医疗的融合，并确保个性化和文化适应性。

Conclusion: 大型语言模型有潜力作为传统知识与现代医疗之间的重要桥梁，有助于为抑郁症患者提供更具文化适应性和科学依据的治疗与支持。

Abstract: Major depressive disorder represents one of the most significant global
health challenges of the 21st century, affecting millions of people worldwide
and creating substantial economic and social burdens. While conventional
antidepressant therapies have provided relief for many individuals, their
limitations including delayed onset of action, significant side effects, and
treatment resistance in a substantial portion of patients have prompted
researchers and healthcare providers to explore alternative therapeutic
approaches (Kasneci et al.). African traditional medicine, with its rich
heritage of plant-based remedies developed over millennia, offers a valuable
resource for developing novel antidepressant treatments that may address some
of these limitations. This paper examines the integration of large language
models with African natural products for depression support, combining
traditional knowledge with modern artificial intelligence technology to create
accessible, evidence-based mental health support systems.
  The research presented here encompasses a comprehensive analysis of African
medicinal plants with documented antidepressant properties, their
pharmacological mechanisms, and the development of an AI-powered support system
that leverages DeepSeek's advanced language model capabilities. The system
provides evidence-based information about African herbal medicines, their
clinical applications, safety considerations, and therapeutic protocols while
maintaining scientific rigor and appropriate safety standards. Our findings
demonstrate the potential for large language models to serve as bridges between
traditional knowledge and modern healthcare, offering personalized, culturally
appropriate depression support that honors both traditional wisdom and
contemporary medical understanding.

</details>


### [40] [RADIANT: Retrieval AugmenteD entIty-context AligNmenT -- Introducing RAG-ability and Entity-Context Divergence](https://arxiv.org/abs/2507.02949)
*Vipula Rawte,Rajarshi Roy,Gurpreet Singh,Danush Khanna,Yaswanth Narsupalli,Basab Ghosh,Abhay Gupta,Argha Kamal Samanta,Aditya Shingote,Aadi Krishna Vikram,Vinija Jain,Aman Chadha,Amit Sheth,Amitava Das*

Main category: cs.CL

TL;DR: 本文提出度量 LLM 融合外部检索信息能力的新指标及 Radiant 框架，系统提升 RAG 事实一致性和内容保真度。


<details>
  <summary>Details</summary>
Motivation: 尽管 RAG 技术为大语言模型引入了外部知识以提升事实准确性，但当前 LLM 往往难以将检索到的证据真实、准确地反映到生成内容中，导致事实不一致。为此提出新的度量和改进技巧。

Method: 提出了新的指标 ECD（Entity-Context Divergence）用于量化检索信息与生成内容的偏离程度，并系统评估了多种主流 LLM 的 RAG-ability。进一步，提出 Radiant（Retrieval AugmenteD entIty-context AligNmenT）框架，通过扩展 Direct Preference Optimization 教会模型更好地融合检索到的信息。

Result: 实验证明，多数 LLM 的 RAG-ability 较低，事实一致性和实体保真有待提升。引入 Radiant 框架后，无论在有噪声的网络环境、知识冲突还是减缓幻觉等场景下，模型都表现更优。

Conclusion: Radiant 框架显著提升了当前大语言模型在融合检索外部知识时的准确性和一致性，改善了事实一致性和上下文保真度。该方法为生成更加可靠和基于证据的内容提供了有效解决思路。

Abstract: As Large Language Models (LLMs) continue to advance, Retrieval-Augmented
Generation (RAG) has emerged as a vital technique to enhance factual accuracy
by integrating external knowledge into the generation process. However, LLMs
often fail to faithfully integrate retrieved evidence into their generated
responses, leading to factual inconsistencies. To quantify this gap, we
introduce Entity-Context Divergence (ECD), a metric that measures the extent to
which retrieved information is accurately reflected in model outputs. We
systematically evaluate contemporary LLMs on their ability to preserve factual
consistency in retrieval-augmented settings, a capability we define as
RAG-ability. Our empirical analysis reveals that RAG-ability remains low across
most LLMs, highlighting significant challenges in entity retention and context
fidelity. This paper introduces Radiant (Retrieval AugmenteD entIty-context
AligNmenT), a novel framework that merges RAG with alignment designed to
optimize the interplay between retrieved evidence and generated content.
Radiant extends Direct Preference Optimization (DPO) to teach LLMs how to
integrate provided additional information into subsequent generations. As a
behavior correction mechanism, Radiant boosts RAG performance across varied
retrieval scenarios, such as noisy web contexts, knowledge conflicts, and
hallucination reduction. This enables more reliable, contextually grounded, and
factually coherent content generation.

</details>


### [41] [Evaluating AI Counseling in Japanese: Counselor, Client, and Evaluator Roles Assessed by Motivational Interviewing Criteria](https://arxiv.org/abs/2507.02950)
*Keita Kiuchi,Yoshikazu Fujimoto,Hideyuki Goto,Tomonori Hosokawa,Makoto Nishimura,Yosuke Sato,Izumi Sezai*

Main category: cs.CL

TL;DR: 本研究首次系统评估了大语言模型在日语咨询场景中的多角色表现，发现结构化多步对话提示显著提升AI咨询质量，且现有模型与来访者模拟仍待改进。同时，为非英语环境下AI心理健康应用提供了基准和优化方向。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在全面评估大语言模型（LLM）在日语治疗环境中，担任三种咨询相关角色时的表现，并探讨其在非英语文化下的适用性和局限性。

Method: 研究评估了不同角色的AI系统，包括辅导者AI（采用GPT-4-turbo零样本提示或结构化多步对话提示（SMDP）、Claude-3-Opus-SMDP）、来访者AI模拟，以及评价AI（o3，Claude-3.7-Sonnet，Gemini-2.5-pro）。由15位具备丰富咨询经验的人类专家，使用动机性访谈治疗完整性（MITI）编码手册4.2.1，对AI生成的对话进行评分。

Result: SMDP方法显著提升了辅导者AI在全部MITI评分指标上的表现，超过了零样本提示，且GPT与Opus的SMDP效果无显著差异。评价AI在鼓励积极变革言语方面与人类持平，但在减缓抵抗言语和整体质量上倾向高估。特定模型偏好明确（如Gemini重视权力共享，o3注重技术规范，Sonnet关注情感表达）。来访AI模拟情感范围有限、顺从度异常高，表现不够真实。

Conclusion: 该研究为非英语语境下AI辅导奠定了性能基准，提出通过高级提示工程、检索增强生成和针对性微调提升AI表现，强调开发具文化敏感性的AI心理健康工具的重要性。

Abstract: This study provides the first comprehensive evaluation of large language
model (LLM) performance across three counseling roles in Japanese-language
therapeutic contexts. We simultaneously assessed counselor artificial
intelligence (AI) systems (GPT-4-turbo with zeroshot prompting or Structured
Multi-step Dialogue Prompts (SMDP), Claude-3-Opus-SMDP), client AI simulations,
and evaluation AI systems (o3, Claude-3.7-Sonnet, Gemini-2.5-pro). Human
experts (n = 15) with extensive counseling experience evaluated AI-generated
dialogues using the Motivational Interviewing Treatment Integrity (MITI) Coding
Manual 4.2.1.
  Notably, SMDP implementation significantly enhanced counselor AI performance
across all MITI global ratings compared with zeroshot prompting, with no
significant differences between GPT-SMDP and Opus-SMDP. Evaluation AIs showed
comparable performance to human raters for Cultivating Change Talk but
systematically overestimated Softening Sustain Talk and the overall quality
metrics. Model-specific biases emerged: Gemini emphasized power-sharing, o3
focused on technical proficiency, and Sonnet prioritized emotional expression.
Client AI simulations exhibited a limited emotional range and unnaturally high
compliance, indicating the need for enhanced realism.
  These findings establish benchmarks for AI-assisted counseling in non-English
contexts and identify critical areas for improvement through advanced prompt
engineering, retrieval-augmented generation, and targeted fine-tuning, with
important implications for developing culturally sensitive AI mental health
tools.

</details>


### [42] [Advanced Financial Reasoning at Scale: A Comprehensive Evaluation of Large Language Models on CFA Level III](https://arxiv.org/abs/2507.02954)
*Pranam Shetty,Abhisek Upadhayaya,Parth Mitesh Shah,Srikanth Jagabathula,Shilpi Nayak,Anna Joo Fee*

Main category: cs.CL

TL;DR: 本论文评测了23个LLM在CFA三级考试上的表现，主流模型取得了接近或超过77%的分数，显示出LLM在高级金融推理任务上的巨大进步，对现实应用和模型选择具有重要参考意义，但实际部署仍面临成本和解释等难题。


<details>
  <summary>Details</summary>
Motivation: 随着金融机构越来越多地采用大型语言模型（LLMs），为了确保负责任地部署，必须进行严格的领域专属评估。CFA考试是金融推理领域的金标准，因此以其为评测对象，可以直接反映LLMs在高端金融推理任务中的能力。

Method: 作者构建了一个全面的基准测试，评估了23个先进的LLM在CFA三级考试上的表现。测试涵盖了选择题和论述题，并采用了多种提示策略（如Chain-of-Thought和Self-Discover），同时对论述题成绩采用了更严格的评分方法。

Result: 领先模型（如o4-mini和Gemini 2.5 Flash）在CFA三级考试中分别取得了79.1%和77.3%的综合分数，这些成绩均基于严格修订过的论述题评分标准。这说明LLMs在高要求金融任务能力上取得了明显进步。

Conclusion: 研究为金融领域实际用户在模型选择上提供了指南，同时指出在成本效益部署和模型表现专业解读方面仍有挑战。

Abstract: As financial institutions increasingly adopt Large Language Models (LLMs),
rigorous domain-specific evaluation becomes critical for responsible
deployment. This paper presents a comprehensive benchmark evaluating 23
state-of-the-art LLMs on the Chartered Financial Analyst (CFA) Level III exam -
the gold standard for advanced financial reasoning. We assess both
multiple-choice questions (MCQs) and essay-style responses using multiple
prompting strategies including Chain-of-Thought and Self-Discover. Our
evaluation reveals that leading models demonstrate strong capabilities, with
composite scores such as 79.1% (o4-mini) and 77.3% (Gemini 2.5 Flash) on CFA
Level III. These results, achieved under a revised, stricter essay grading
methodology, indicate significant progress in LLM capabilities for high-stakes
financial applications. Our findings provide crucial guidance for practitioners
on model selection and highlight remaining challenges in cost-effective
deployment and the need for nuanced interpretation of performance against
professional benchmarks.

</details>


### [43] [Real-World En Call Center Transcripts Dataset with PII Redaction](https://arxiv.org/abs/2507.02958)
*Ha Dao,Gaurav Chawla,Raghu Banda,Caleb DeLeeuw*

Main category: cs.CL

TL;DR: 作者发布了迄今最大规模的呼叫中心英文转录数据集CallCenterEN，去除了个人隐私信息，仅开放文本转录，为非商业语音AI研究提供了宝贵资源。


<details>
  <summary>Details</summary>
Motivation: 在客户支持和销售AI系统领域，真实且规模化的呼叫中心语音文本数据极为稀缺，限制了语音识别与对话理解相关研究的发展。

Method: 作者收集了真实的呼叫中心英文通话数据集，经过高质量人工转录和PII去除处理，并未包含原始音频。涉及印度、菲律宾和美国等多种口音，支持呼入与呼出的客户服务场景。

Result: 最终得到的数据集包含91706条通话，总时长10448小时，是迄今最大规模的开放呼叫中心英文转录数据。所有PII信息已被严格去除，数据集以CC BY-NC 4.0协议面向非商业研究开放。

Conclusion: CallCenterEN数据集为学界和业界在真实场景下的语音识别、客户支持和会话AI研究提供了重要基础，填补了公开呼叫中心数据的空白。

Abstract: We introduce CallCenterEN, a large-scale (91,706 conversations, corresponding
to 10448 audio hours), real-world English call center transcript dataset
designed to support research and development in customer support and sales AI
systems. This is the largest release to-date of open source call center
transcript data of this kind. The dataset includes inbound and outbound calls
between agents and customers, with accents from India, the Philippines and the
United States. The dataset includes high-quality, PII-redacted human-readable
transcriptions. All personally identifiable information (PII) has been
rigorously removed to ensure compliance with global data protection laws. The
audio is not included in the public release due to biometric privacy concerns.
Given the scarcity of publicly available real-world call center datasets,
CallCenterEN fills a critical gap in the landscape of available ASR corpora,
and is released under a CC BY-NC 4.0 license for non-commercial research use.

</details>


### [44] [RAG-R1 : Incentivize the Search and Reasoning Capabilities of LLMs through Multi-query Parallelism](https://arxiv.org/abs/2507.02962)
*Zhiwen Tan,Jiaming Huang,Qintong Wu,Hongxuan Zhang,Chenyi Zhuang,Jinjie Gu*

Main category: cs.CL

TL;DR: RAG-R1通过多查询并行和知识自适应融合，大幅提升LLM问答能力且推理更快，优于主流RAG方法。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法在强化学习驱动下虽有效，但推理时间长、能力受限于单查询，同时训练不稳定，无法充分利用内外部知识。

Method: 提出了一种新的训练框架RAG-R1，使LLM能自适应地结合内部与外部知识；并将生成与检索过程从单查询扩展为多查询并行，提高效率和能力。进行了七个问答基准测试。

Result: RAG-R1方法基于七个基准上的实验能提升准确率最多13.2%，推理时间减少11.1%。

Conclusion: RAG-R1方法能够显著提升LLM在问答任务上的表现，并有效缩短推理时间，超越当前最强基线。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
various tasks, while they remain prone to generating hallucinated or outdated
responses due to their static internal knowledge. Recent advancements in
Retrieval-Augmented Generation (RAG) methods have explored enhancing models'
search and reasoning capabilities through reinforcement learning (RL). Although
these methods demonstrate promising results, they face challenges in training
stability and encounter issues such as substantial inference time and
restricted capabilities due to the single-query mode. In this paper, we propose
RAG-R1, a novel training framework designed to enable LLMs to adaptively
leverage internal and external knowledge during the reasoning process. We
further expand the generation and retrieval processes within the framework from
single-query mode to multi-query parallelism, aimed at reducing inference time
and enhancing the model's capabilities. Extensive experiments on seven
question-answering benchmarks demonstrate that our method outperforms the
strongest baseline by up to 13.2% and decreases inference time by 11.1%.

</details>


### [45] [Less Data, More Security: Advancing Cybersecurity LLMs Specialization via Resource-Efficient Domain-Adaptive Continuous Pre-training with Minimal Tokens](https://arxiv.org/abs/2507.02964)
*Salahuddin Salahuddin,Ahmed Hussain,Jussi Löppönen,Toni Jutila,Panos Papadimitratos*

Main category: cs.CL

TL;DR: 该论文提出领域自适应连续预训练（DAP）方法，将现有LLM在网络安全领域微调，在数据量大幅减少的情况下实现了超越现有专业模型的表现，为低成本高效特化AI提供新路径。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型（LLMs）在自然语言处理方面表现出色，但通用模型在网络安全分析领域缺乏专门知识。因此，提升LLMs在网络安全领域的专业理解能力成为研究的动力。

Method: 采用领域自适应连续预训练（DAP）方法，将三种主流LLM架构（Llama-3.1-8B、DeepSeek-R1-Distill-Qwen-14B、Llama-3.3-70B-Instruct）在一个由标准文献、学术论文等组成的1.26亿词网络安全语料库上进行定向微调，训练时采取参数和资源约束以平衡领域特化和知识保留。

Result: 经过DAP方法训练后，所有LLM模型在三个网络安全基准测试（CTI-MCQ、CyberMetric、SecEval）上的表现均有显著提升。其中Llama-3.3-70B-Ins-DAP模型分别获得0.718、0.933、0.864的最高准确率，超越了包括Llama-Primus-Base在内的专业模型。

Conclusion: 论文验证了在数据量远小于以往的情况下，通过定向的持续预训练，可以在保持语言通用能力的前提下，显著提升LLMs的网络安全领域知识，实现高效可行的领域特化，为未来威胁分析等AI助手开发提供了坚实基础，也挑战了LLM领域特化对大规模数据需求的传统认知。

Abstract: While Large Language Models (LLMs) demonstrate exceptional natural language
capabilities, general-purpose models lack specialized domain knowledge for
effective cybersecurity analysis. In this work, we investigate Domain-Adaptive
Continuous Pretraining (DAP) as a methodology for enhancing cybersecurity
understanding in pretrained LLMs while preserving general language
capabilities. We systematically adapted three decoder-based architectures --
Llama-3.1-8B, DeepSeek-R1-Distill-Qwen-14B, and Llama-3.3-70B-Instruct -- using
a curated 126-million-word cybersecurity corpus from standards, academic
literature, and various other sources. Our approach employed constrained
training parameters and distributed FSDP training to balance domain
specialization with knowledge preservation. Evaluation across three
cybersecurity benchmarks, namely, CTI-MCQ, CyberMetric, and SecEval,
demonstrates consistent improvements post-adaptation. The Llama-3.3-70B-Ins-DAP
model achieved state-of-the-art accuracies of 0.718, 0.933, and 0.864,
respectively, outperforming specialized models, including Llama-Primus-Base.
Notably, competitive performance was achieved using substantially smaller
datasets (118.8 million versus 2.77 billion tokens), demonstrating efficient
domain specialization viability. We establish that targeted continuous
pretraining enables effective cybersecurity domain adaptation with
computational feasibility, providing foundations for specialized AI assistants
in threat analysis, vulnerability assessment, and security documentation while
challenging prevailing assumptions about data requirements for LLM
specialization.

</details>


### [46] [PB-LLMs: Privacy- and Bias-aware NLP Models using Named-Entity Recognition](https://arxiv.org/abs/2507.02966)
*Gonzalo Mancera,Aythami Morales,Julian Fierrez,Ruben Tolosana,Alejandro Penna,Miguel Lopez-Duran,Francisco Jurado,Alvaro Ortigosa*

Main category: cs.CL

TL;DR: 利用NER技术和多种匿名化方法对简历评分LLM进行隐私保护，并引入去性别偏见机制，最终提出可拓展的PB-LLMs，在保障隐私和系统性能的同时增加公平性与用户信任。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）广泛应用于高风险的AI场景中，例如招聘简历评分，随之而来的隐私、数据保护和透明度等法律/伦理问题日益突出。为应对这些挑战，研究迫切需要发展能在保护隐私前提下仍具备良好性能的NLP方法。

Method: 提出利用NER（命名实体识别）技术，匿名化文本数据中的敏感信息（如个人身份、地理位置信息），并基于六种不同的匿名化算法（Presidio、FLAIR、BERT及不同版本GPT）在两个语言模型（BERT与RoBERTa）和24000份候选人简历数据库上进行评估。此外，结合现有减少性别偏见的方法，对LLM进行隐私和偏见双重保护，形成PB-LLMs。

Result: 实验结果表明，提出的匿名化与隐私保护技术可以有效保护候选人隐私，同时几乎不影响系统性能，即在真实场景下既能保密又具备准确评分能力。同时，PB-LLMs进一步减少了性别偏见。该方法虽以简历评分为例，但具备广泛适用于其他LLM应用场景的潜力。

Conclusion: 通过结合NER匿名化和去偏见技术，可同时提升LLM的隐私保护及公平性，增强用户对AI系统的信任。该框架在招聘评分背景下验证有效，为未来高风险AI场景中的隐私及道德问题提供了一种可行解决方案。

Abstract: The use of Natural Language Processing (NLP) in high-stakes AI-based
applications has increased significantly in recent years, especially since the
emergence of Large Language Models (LLMs). However, despite their strong
performance, LLMs introduce important legal/ethical concerns, particularly
regarding privacy, data protection, and transparency. Due to these concerns,
this work explores the use of Named-Entity Recognition (NER) to facilitate the
privacy-preserving training (or adaptation) of LLMs. We propose a framework
that uses NER technologies to anonymize sensitive information in text data,
such as personal identities or geographic locations. An evaluation of the
proposed privacy-preserving learning framework was conducted to measure its
impact on user privacy and system performance in a particular high-stakes and
sensitive setup: AI-based resume scoring for recruitment processes. The study
involved two language models (BERT and RoBERTa) and six anonymization
algorithms (based on Presidio, FLAIR, BERT, and different versions of GPT)
applied to a database of 24,000 candidate profiles. The findings indicate that
the proposed privacy preservation techniques effectively maintain system
performance while playing a critical role in safeguarding candidate
confidentiality, thus promoting trust in the experimented scenario. On top of
the proposed privacy-preserving approach, we also experiment applying an
existing approach that reduces the gender bias in LLMs, thus finally obtaining
our proposed Privacy- and Bias-aware LLMs (PB-LLMs). Note that the proposed
PB-LLMs have been evaluated in a particular setup (resume scoring), but are
generally applicable to any other LLM-based AI application.

</details>


### [47] [We Need Knowledge Distillation for Solving Math Word Problems](https://arxiv.org/abs/2507.02982)
*Zhenquan Shen,Xinguo Yu,Xiaotian Cheng,Rao Peng,Hao Ming*

Main category: cs.CL

TL;DR: 本文提出将BERT嵌入向量压缩并知识蒸馏到小型学生模型，用于解决数学文字题，在仅用1/12参数下保持近九成性能，并指出词性信息是压缩可行的关键，显著提升了智能教育系统的效率和普适性。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型在数学教育中的应用受到高昂计算资源消耗的限制，尤其是在中小学教育和智能辅导系统中。为降低成本，提高实际应用可行性，研究尝试对这些模型进行压缩。

Method: 本研究通过对BERT编码的嵌入向量进行压缩，并采用知识蒸馏方法，训练出一个小型学生模型以解决数学文字题（MWPs），并评估其在保持性能和参数规模之间的平衡。还分析了嵌入向量可压缩的原因。

Result: 学生模型仅用1/12参数，能保持教师模型近90%的性能。压缩后的向量在所有MWPs相关任务表现良好，蒸馏方法通用且非任务特定。研究发现词性信息比实体识别更关键，促进了压缩性。

Conclusion: 通过向量压缩与知识蒸馏，可大幅减少资源消耗，同时保留高性能，实现智能教育系统成本效益提升和通用化发展。嵌入向量的可压缩性与词性信息有关。

Abstract: The enhancement of mathematical capabilities in large language models (LLMs)
fosters new developments in mathematics education within primary and secondary
schools, particularly as they relate to intelligent tutoring systems. However,
LLMs require substantial computational resources, resulting in significant
costs in educational contexts. To mitigate this drawback, this paper
investigates the feasibility of compressing LLMs for solving math word problems
(MWPs). We compress the embedded vectors encoded by BERT and distill a
considerably smaller student model. Our findings indicate that the student
model can maintain nearly 90% of the performance of the teacher model while
utilizing only 1/12 of its parameters. In addition to achieving high accuracy,
the model exhibits strong generalizability, as the compressed vectors perform
well across all tasks related to MWPs, and the distillation process is not
task-specific. The success of this distillation demonstrates that the
underlying principles are generic and not limited to a specific task. We
further explore the reasons behind the compressibility of embedded vectors,
revealing that part-of-speech information, rather than entity recognition, is
crucial for MWPs, which may significantly contribute to their compressibility.
The improvements in efficiency and cost reduction provide substantial value for
intelligent tutoring systems and significantly advance the field of intelligent
education.

</details>


### [48] [Truth, Trust, and Trouble: Medical AI on the Edge](https://arxiv.org/abs/2507.02983)
*Mohammad Anas Azeez,Rafiq Ali,Ebad Shabbir,Zohaib Hasan Siddiqui,Gautam Siddharth Kashyap,Jiechao Gao,Usman Naseem*

Main category: cs.CL

TL;DR: 该论文提出了面向医学问答的LLM基准评测方法，对比了多款模型在准确性和安全性等方面的表现，发现即便有技术进步，复杂问题仍存在有用性挑战，为今后数字健康LLM的发展指明了方向。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在推动数字健康领域尤其是自动医学问答方面有巨大潜力，但要达到行业在事实准确性、有用性和安全性上的高标准依然具有挑战，尤其是开源模型。

Method: 提出了一个严格的基准测试体系，采用1000多个健康问题对比评估模型的诚实性（honesty）、有用性（helpfulness）和无害性（harmlessness），并测试了Mistral-7B、BioMistral-7B-DARE和AlpaCare-13B等模型。

Result: AlpaCare-13B在准确率（91.7%）和无害性（0.92）上表现最佳；BioMistral-7B-DARE通过领域专属微调，在小规模下提升了安全性（0.90）；少样本提示（few-shot prompting）可将准确率从78%提升至85%；所有模型在处理复杂医学问答时有用性下降，反映出临床问答中的持续挑战。

Conclusion: 不同模型在事实可靠性和安全性之间存在权衡。尽管部分模型经过专用调优能提升安全性，但整体在复杂医疗问答场景下仍需改进。提出的基准体系为未来医学健康类LLM评测提供了标准。

Abstract: Large Language Models (LLMs) hold significant promise for transforming
digital health by enabling automated medical question answering. However,
ensuring these models meet critical industry standards for factual accuracy,
usefulness, and safety remains a challenge, especially for open-source
solutions. We present a rigorous benchmarking framework using a dataset of over
1,000 health questions. We assess model performance across honesty,
helpfulness, and harmlessness. Our results highlight trade-offs between factual
reliability and safety among evaluated models -- Mistral-7B,
BioMistral-7B-DARE, and AlpaCare-13B. AlpaCare-13B achieves the highest
accuracy (91.7%) and harmlessness (0.92), while domain-specific tuning in
BioMistral-7B-DARE boosts safety (0.90) despite its smaller scale. Few-shot
prompting improves accuracy from 78% to 85%, and all models show reduced
helpfulness on complex queries, highlighting ongoing challenges in clinical QA.

</details>


### [49] [From Answers to Rationales: Self-Aligning Multimodal Reasoning with Answer-Oriented Chain-of-Thought](https://arxiv.org/abs/2507.02984)
*Wentao Tan,Qiong Cao,Yibing Zhan,Chao Xue,Changxing Ding*

Main category: cs.CL

TL;DR: SMART框架为多模态大模型引入正负推理自动生成与自对齐，模型泛化推理能力增强，实验表明优于人工标注数据训练方法。


<details>
  <summary>Details</summary>
Motivation: 目前多模态大语言模型（MLLMs）在人类级推理方面还有很大的提升空间，现有方法偏重于生成正向推理路径，忽视了负向推理（错误推理路径）对模型辨别能力的训练作用。

Method: 提出了SMART框架，引入Answer-oriented Chain-of-Thought (AoT)机制。该方法自动生成高质量的正向和负向推理路径，通过自对齐步骤强化模型推理能力。具体做法为：以答案为导向引导模型抽取关键视觉信息，对应于正确答案生成正向推理路径，对应于错误答案生成合理但错误的推理路径，实现正负推理样本自动构建。

Result: 使用AoT机制生成的数据进行训练的模型，在推理能力上显著超过使用人工标注数据集训练的模型。SMART方法对不同架构、规模、预训练数据集的MLLM都有效提升其推理表现。

Conclusion: SMART框架通过引入正负推理路径的自对齐训练及迭代优化，显著提升了多模态大语言模型的人类级推理能力，并为后续模型偏好优化和高质量数据生成提供了新方向。

Abstract: Achieving human-like reasoning capabilities in Multimodal Large Language
Models (MLLMs) has long been a goal. Current methodologies primarily focus on
synthesizing positive rationales, while overlooking the critical role of
negative rationales in training models to discern flawed reasoning patterns. To
address this gap, we propose a novel framework: \textbf{S}elf-Aligning
\textbf{M}ultimodal Reasoning with \textbf{A}nswer-O\textbf{r}iented
Chain-of-\textbf{T}hought (SMART). This framework enables models to utilize
AoT-Oriented Chain-of-Thought (AoT) prompts to automatically generate
high-quality positive and negative reasoning paths, followed by self-alignment
to enhance their reasoning abilities. Inspired by human strategies for solving
proof-based problems, AoT uses answers as a guide to help the model extract
critical visual information that links questions and answers. When provided
with ground truth answers, the model produces strong positive rationales.
Conversely, when correct answers are replaced with misleading alternatives, the
model generates an erroneous yet compelling reasoning path, serving as a form
of discriminative negative rationale. Models trained with AoT-generated data
outperform those trained on manually annotated datasets, demonstrating superior
reasoning capabilities. This encourages the use of improved models to generate
higher-quality preference data for further optimization. Consequently, SMART
establishes an iterative generation-optimization method that continually
enhances the model's reasoning skills. Experiments indicate that the SMART
framework significantly improves various MLLMs, regardless of model
architecture, parameter size, or pre-training dataset. The code, datasets, and
models will be released.

</details>


### [50] [GAF-Guard: An Agentic Framework for Risk Management and Governance in Large Language Models](https://arxiv.org/abs/2507.02986)
*Seshu Tirupathi,Dhaval Salwala,Elizabeth Daly,Inge Vejsbjerg*

Main category: cs.CL

TL;DR: 本文提出GAF-Guard代理式治理框架，实现了以用户和用例为核心的大语言模型部署风险监测，提升了AI治理的安全性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）被广泛应用于不同领域，在实际部署过程中需要有效监控，以防止负面后果并保证其稳健性。同时，LLM需要与人类价值观对齐，防止有害内容、保障负责任的使用。现有自动化监控大多聚焦于生成幻觉等通用问题，缺乏对特定用例和用户偏好的针对性考虑。

Method: 提出了一种新型代理式治理框架GAF-Guard，将用户、用例和模型三者置于监控核心。该方法通过自主代理对风险进行识别，并在具体用例中激活风险检测工具，实现持续监控和风险报告。

Result: GAF-Guard能够根据不同应用场景和用户需求，有效识别、检测和报告LLM部署中的风险，提升了AI安全性和对用户期望的满足度。

Conclusion: GAF-Guard框架为LLM的稳健部署和治理提供了更具针对性和自主性的解决方案，有助于实现责任化、风险可控的AI应用。

Abstract: As Large Language Models (LLMs) continue to be increasingly applied across
various domains, their widespread adoption necessitates rigorous monitoring to
prevent unintended negative consequences and ensure robustness. Furthermore,
LLMs must be designed to align with human values, like preventing harmful
content and ensuring responsible usage. The current automated systems and
solutions for monitoring LLMs in production are primarily centered on
LLM-specific concerns like hallucination etc, with little consideration given
to the requirements of specific use-cases and user preferences. This paper
introduces GAF-Guard, a novel agentic framework for LLM governance that places
the user, the use-case, and the model itself at the center. The framework is
designed to detect and monitor risks associated with the deployment of LLM
based applications. The approach models autonomous agents that identify risks,
activate risk detection tools, within specific use-cases and facilitate
continuous monitoring and reporting to enhance AI safety, and user
expectations. The code is available at
https://github.com/IBM/risk-atlas-nexus-demos/tree/main/gaf-guard.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [51] [Combination generators with optimal cache utilization and communication free parallel execution](https://arxiv.org/abs/2507.03980)
*Xi He,Max. A. Little*

Main category: cs.DM

TL;DR: 本文提出了一种在效率、并行性和递归特性上均具最优表现的组合生成器，并首次推广至嵌套生成结构，兼顾理论美和实际计算优势。


<details>
  <summary>Details</summary>
Motivation: 现有组合生成器在效率、并行性、缓存利用、递归结构等方面难以兼顾，尤其在需要遍历、剪枝和并行的组合优化任务中，缺乏最优实现。为解决这一问题，作者提出兼容并行和递归且方便剪枝的新型组合生成器。

Method: 作者采用Bird代数化计算方法，从规范化规格推导出高效实现，运用方程推理将递归和分治策略结合，为组合相关生成问题设计出结构优雅、效率优越的生成算法，并实现Gray码顺序生成器变体。

Result: 提出的生成器实现了常数摊销时间、缓存高效、易并行、支持递归和剪枝的最优效率。进一步推广到K-排列、组合嵌套结构等，首次报道了嵌套结构生成器，并开发出Gray码顺序的变体以支持更复杂的生成需求。

Conclusion: 本文提出了一种高效且优雅的组合生成器，不仅适用于组合、还可扩展至排列及嵌套组合－排列结构，在回溯搜索和并行计算中具有独特优势，并填补了文献空白。

Abstract: We introduce an efficient and elegant combination generator for producing all
combinations of size less than or equal to K, designed for exhaustive
generation and combinatorial optimization tasks. This generator can be
implemented to achieve what we define as optimal efficiency: constant amortized
time, optimal cache utilization, embarrassingly parallel execution, and a
recursive structure compatible with pruning-based search. These properties are
difficult to satisfy simultaneously in existing generators. For example,
classical Gray code or lexicographic generators are typically list-based and
sequentially defined, making them difficult to vectorized, inefficient in cache
usage, and inherently hard to parallelize. Generators based on unranking
methods, while easy to parallelize, are non-recursive. These limitations reduce
their applicability in our target applications, where both computational
efficiency and recursion are crucial. We adapt Bird's algebra of
programming-style calculation to derive our algorithms, a formalism for
developing correct-by-construction programs from specifications. As a result,
all generators in this paper are first formulated in their clearest
specification, and efficient definitions are derived constructively through
equational reasoning, resulting in concise and elegant divide-and-conquer
definitions. Beyond presenting a combination generator, we extend our approach
to construct generators for K-permutations, nested combinations of
combinations, and nested permutation-combination structures. To the best of our
knowledge, the literature has not previously reported generators for these
nested structures. We also develop sequential variants that produce
configurations in Gray code-compatible orders -- such as the revolving door
ordering -- which are particularly useful for constructing nested generators.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [52] [On Complementation of Nondeterministic Finite Automata without Full Determinization (Technical Report)](https://arxiv.org/abs/2507.03439)
*Lukáš Holík,Ondřej Lengál,Juraj Major,Adéla Štěpková,Jan Strejček*

Main category: cs.FL

TL;DR: 传统NFA补全集中转DFA但膨胀严重，本文提出利用反向幂集及两种新结构方案，实验显示可有效缩减自动机构建规模。


<details>
  <summary>Details</summary>
Motivation: 有限自动机的补全（complementation）是很多实际应用中的基础操作。然而，对于非确定性有限自动机（NFA），常规的补全方式需要先转为等价的确定性有限自动机（DFA），再取补。但DFA的状态数可能呈指数级膨胀，从而带来效率和存储上的巨大负担。

Method: 本文研究了几种替代性的补全方法，包括基于反向幂集（reverse powerset）构造和两种新提出的方法，这两种新方法利用了NFA中常见的一种结构特性。作者对这些不同方法进行了实验对比。

Result: 实验结果表明，在实际数据集上，使用非传统的补全方法可获得显著更小的补自动机（complement）。这意味着替代方法在实际应用中有潜在的效率提升空间。

Conclusion: 本文证明了替代性补全技术在许多情况下能有效减小补自动机规模，挑战了传统的DFA补全主导地位，为NFA补全提供了更高效的方案选择。

Abstract: Complementation of finite automata is a basic operation used in numerous
applications. The standard way to complement a nondeterministic finite
automaton (NFA) is to transform it into an equivalent deterministic finite
automaton (DFA) and complement the DFA. The DFA can, however, be exponentially
larger than the corresponding NFA. In this paper, we study several alternative
approaches to complementation, which are based either on reverse powerset
construction or on two novel constructions that exploit a commonly occurring
structure of NFAs. Our experiment on a large data set shows that using a
different than the classical approach can in many cases yield significantly
smaller complements.

</details>


### [53] [Deciding Sparseness of Regular Languages of Finite Trees and Infinite Words](https://arxiv.org/abs/2507.03465)
*Kord Eickmeyer,Georg Schindling*

Main category: cs.FL

TL;DR: 本文证明了正规树语言和无限字正规语言的“稀疏性”问题是可判定的，并针对不同情形给出了高效算法和特征化方法，对形式验证和XML等自动机应用具有应用价值。


<details>
  <summary>Details</summary>
Motivation: 稀疏性与自动机理论及形式验证密切相关，是判断系统特定行为可达概率和进行模型检测时的重要关注点。此外，在XML schema等实际应用场景，稀疏性有助于更高效的数据验证和质量控制。

Method: 作者对正规树语言通过禁止子树和树自动机进行了特征化，提出了线性时间决策流程；对无限字的正规语言采用inf保全性来刻画，并给出了新的可判定性证明。对于非稀疏的情况，算法还可构造出可测的反例集。

Result: 提出了一种线性时间算法判断正规树语言的稀疏性，以及一种对无限字正规语言稀疏性的可判定方法。算法分析和特征化为相关模型检测等领域提供了工具，能在非稀疏情况下找到反例。

Conclusion: 本文研究了“稀疏性”在有限树和无限字上正规语言中的判定问题，并给出了相关的判定算法和特征化方法。稀疏性对正规树语言和无限字语言均是可判定的，并可高效实现。

Abstract: We study the notion of sparseness for regular languages over finite trees and
infinite words. A language of trees is called sparse if the relative number of
$n$-node trees in the language tends to zero, and a language of infinite words
is called sparse if it has measure zero in the Bernoulli probability space. We
show that sparseness is decidable for regular tree languages and for regular
languages of infinite words. For trees, we provide characterisations in terms
of forbidden subtrees and tree automata, leading to a linear time decision
procedure. For infinite words, we present a characterisation via infix
completeness and give a novel proof of decidability. Moreover, in the
non-sparse case, our algorithm computes a measurable subset of accepted words
that can serve as counterexamples in almost-sure model checking. Our findings
have applications to automata based model checking in formal verifications and
XML schemas, among others.

</details>
