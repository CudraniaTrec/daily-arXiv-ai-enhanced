<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 13]
- [cs.LO](#cs.LO) [Total: 7]
- [cs.CL](#cs.CL) [Total: 24]
- [cs.DM](#cs.DM) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Oriented Metrics for Bottom-Up Enumerative Synthesis](https://arxiv.org/abs/2511.02491)
*Roland Meyer,Jakob Tepe*

Main category: cs.PL

TL;DR: 论文提出有向度量用于约束语法引导合成中的搜索空间，并通过多技术集成显著提升搜索效率，实验证明新算法表现远超现有解决方案。


<details>
  <summary>Details</summary>
Motivation: 语法引导合成面临搜索空间巨大导致的效率瓶颈，现有方法未能充分利用程序之间的结构性距离，尤其在字符串和位向量领域中操作具有方向性而非对称性，因此亟需新方法来有效组织和约束搜索空间。

Method: 开发了多种针对字符串和位向量领域的新型有向度量，并提出了基于有向度量的四种减少搜索空间的技术：搜索空间剪枝、等价类分解、度量抽象与细化、以及基于抽象信息的枚举顺序优化。将这些技术集成到新的合成算法及求解器中，该求解器以有向度量为通用框架。

Result: 在字符串和位向量领域进行实验，集成了有向度量的算法与求解器在性能上稳定超越最先进方法，提升幅度超过一个数量级。

Conclusion: 通过引入和利用“有向度量”结构，这项工作大幅提高了语法引导合成中的搜索效率，实现了超过现有方法一个数量级的性能提升。

Abstract: In syntax-guided synthesis, one of the challenges is to reduce the enormous
size of the search space. We observe that most search spaces are not just flat
sets of programs, but can be endowed with a structure that we call an oriented
metric. Oriented metrics measure the distance between programs, like ordinary
metrics do, but are designed for settings in which operations have an
orientation. Our focus is on the string and the bitvector domains, where
operations like concatenation and bitwise conjunction transform an input into
an output in a way that is not symmetric. We develop several new oriented
metrics for these domains. Oriented metrics are designed for search space
reduction, and we present four techniques: (i) pruning the search space to a
ball around the ground truth, (ii) factorizing the search space by an
equivalence that is induced by the oriented metric, (iii) abstracting the
oriented metric (and hence the equivalence) and refining it, and (iv) improving
the enumeration order by learning from abstract information. We acknowledge
that these techniques are inspired by developments in the literature. By
understanding their roots in oriented metrics, we can substantially increase
their applicability and efficiency. We have integrated these techniques into a
new synthesis algorithm and implemented the algorithm in a new solver. Notably,
our solver is generic in the oriented metric over which it computes. We
conducted experiments in the string and the bitvector domains, and consistently
improve the performance over the state-of-the-art by more than an order of
magnitude.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [Detecting Vulnerabilities from Issue Reports for Internet-of-Things](https://arxiv.org/abs/2511.01941)
*Sogol Masoumzadeh*

Main category: cs.SE

TL;DR: 本论文首次将机器学习和大语言模型应用于IoT项目漏洞问题报告检测，提出了多种模型并验证其性能，为未来IoT系统安全自动化检测铺路。


<details>
  <summary>Details</summary>
Motivation: 尽早识别反映软件漏洞的问题报告对于物联网（IoT）系统尤其重要，因为对这些系统的分析往往慢于非IoT系统。虽然机器学习和大语言模型已被用于非IoT系统漏洞检测，但在IoT领域的应用尚未充分探索。

Method: 提出两种方法：1）结合机器学习、LLM与NLP技术，检测21个Eclipse IoT项目的问题报告中的漏洞指示信息；2）在11,000条GitHub问题上微调预训练的BERT掩码语言模型（MLM），用于漏洞分类。

Result: 基于BERT NLP特征的支持向量机（SVM）取得最佳性能，AUC达到0.65。微调后的BERT模型准确率为0.26，强调了训练时应暴露全部数据的重要性。

Conclusion: 本研究首次探索用ML与LLM检测IoT系统漏洞相关问题报告，为IoT领域的准确漏洞检测奠定了基础。

Abstract: Timely identification of issue reports reflecting software vulnerabilities is
crucial, particularly for Internet-of-Things (IoT) where analysis is slower
than non-IoT systems. While Machine Learning (ML) and Large Language Models
(LLMs) detect vulnerability-indicating issues in non-IoT systems, their IoT use
remains unexplored. We are the first to tackle this problem by proposing two
approaches: (1) combining ML and LLMs with Natural Language Processing (NLP)
techniques to detect vulnerability-indicating issues of 21 Eclipse IoT projects
and (2) fine-tuning a pre-trained BERT Masked Language Model (MLM) on 11,000
GitHub issues for classifying \vul. Our best performance belongs to a Support
Vector Machine (SVM) trained on BERT NLP features, achieving an Area Under the
receiver operator characteristic Curve (AUC) of 0.65. The fine-tuned BERT
achieves 0.26 accuracy, emphasizing the importance of exposing all data during
training. Our contributions set the stage for accurately detecting IoT
vulnerabilities from issue reports, similar to non-IoT systems.

</details>


### [3] [Metamorphic Testing of Large Language Models for Natural Language Processing](https://arxiv.org/abs/2511.02108)
*Steven Cho,Stefano Ruberto,Valerio Terragni*

Main category: cs.SE

TL;DR: 本论文系统性地论证了变形测试在大型语言模型自动行为识别中的应用价值，通过广泛文献综述和大规模实验，验证了该方法的有效性及不足之处。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽然在自然语言处理（NLP）任务上表现优秀，但常常出现错误结果。自动识别这些错误行为对于提升LLMs的有效性非常重要。然而，受限于标注数据集的稀缺，判断LLMs结果正确与否变得困难，需要新的测试方法来解决这个问题。

Method: 采用变形测试（Metamorphic Testing, MT）方法，通过提出和分析变形关系（MRs）在没有明确标签数据集的情况下自动评估LLMs行为。论文通过文献综述，收集了191种用于NLP任务的MR，并选取36种代表性MR在三个主流LLM上进行实验，测试约56万次。

Result: 实验揭示了变形测试方法在LLMs应用中的能力和机会，同时也指出了其局限性。

Conclusion: 论文表明，变形测试是一种非常有价值的、可应用于无标签数据集环境下评估LLMs表现的方法，但也需要关注其局限性。

Abstract: Using large language models (LLMs) to perform natural language processing
(NLP) tasks has become increasingly pervasive in recent times. The versatile
nature of LLMs makes them applicable to a wide range of such tasks. While the
performance of recent LLMs is generally outstanding, several studies have shown
that they can often produce incorrect results. Automatically identifying these
faulty behaviors is extremely useful for improving the effectiveness of LLMs.
One obstacle to this is the limited availability of labeled datasets, which
necessitates an oracle to determine the correctness of LLM behaviors.
Metamorphic testing (MT) is a popular testing approach that alleviates this
oracle problem. At the core of MT are metamorphic relations (MRs), which define
relationships between the outputs of related inputs. MT can expose faulty
behaviors without the need for explicit oracles (e.g., labeled datasets). This
paper presents the most comprehensive study of MT for LLMs to date. We
conducted a literature review and collected 191 MRs for NLP tasks. We
implemented a representative subset (36 MRs) to conduct a series of experiments
with three popular LLMs, running approximately 560,000 metamorphic tests. The
results shed light on the capabilities and opportunities of MT for LLMs, as
well as its limitations.

</details>


### [4] [Open the Oyster: Empirical Evaluation and Improvement of Code Reasoning Confidence in LLMs](https://arxiv.org/abs/2511.02197)
*Shufan Wang,Xing Hu,Junkai Chen,Zhiyuan Pan,Xin Xia*

Main category: cs.SE

TL;DR: 本论文针对代码推理任务，提出了一套针对大语言模型的置信度分析与增强框架，系统评估了主流模型的置信度可靠性，并验证了策略优化与数学校准的有效性。实验证明DeepSeek-Reasoner及复合增强策略表现突出，并揭示置信度提升的工程与研究价值。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在代码智能领域的广泛应用，其在代码推理任务中的输出可靠性和可控性越来越受到关注。信心估计被认为是评估这些性能的有效途径。

Method: 提出一个专为代码推理任务设计的大语言模型信心分析与增强框架；对主流模型在不同任务下的置信度可靠性进行实证研究，并评估提示策略优化和数学校准（如Platt Scaling）等技术提升置信度可靠性的效果。

Result: DeepSeek-Reasoner在各项任务中表现最佳，相比其他模型在ECE、Brier分数和性能分数方面分别提升了0.680、0.636和13.652。结合再评估提示策略与Platt Scaling的混合策略在上述三项指标上对原始性能分别提升了0.541、0.628和15.084。推理能力强的模型具有更好的置信度可靠性，混合策略在增强置信度可靠性上最为有效。

Conclusion: 不同任务复杂度、模型规模及策略明显影响模型置信度表现，目前在复杂推理任务上的置信度仍有提升空间。本研究为LLM辅助软件工程中的置信度机制应用提供了技术参考，也为未来优化和工程部署提出了方向。

Abstract: With the widespread application of large language models (LLMs) in the field
of code intelligence, increasing attention has been paid to the reliability and
controllability of their outputs in code reasoning tasks. Confidence estimation
serves as an effective and convenient approach for evaluating these aspects.
This paper proposes a confidence analysis and enhancement framework for LLMs
tailored to code reasoning tasks. We conduct a comprehensive empirical study on
the confidence reliability of mainstream LLMs across different tasks, and
further evaluate the effectiveness of techniques such as prompt strategy
optimisation and mathematical calibration (e.g., Platt Scaling) in improving
confidence reliability. Our results show that DeepSeek-Reasoner achieves the
best performance across various tasks, outperforming other models by up to
$0.680$, $0.636$, and $13.652$ in terms of ECE, Brier Score, and Performance
Score, respectively. The hybrid strategy combining the reassess prompt strategy
and Platt Scaling achieves improvements of up to $0.541$, $0.628$, and $15.084$
over the original performance in the aforementioned three metrics. These
results indicate that models with reasoning capabilities demonstrate superior
confidence reliability, and that the hybrid strategy is the most effective in
enhancing the confidence reliability of various models. Meanwhile, we elucidate
the impact of different task complexities, model scales, and strategies on
confidence performance, and highlight that the confidence of current LLMs in
complex reasoning tasks still has considerable room for improvement. This study
not only provides a research foundation and technical reference for the
application of confidence in LLM-assisted software engineering, but also points
the way for future optimisation and engineering deployment of confidence
mechanisms.

</details>


### [5] [LLMs as Judges: Toward The Automatic Review of GSN-compliant Assurance Cases](https://arxiv.org/abs/2511.02203)
*Gerhard Yu,Mithila Sivakumar,Alvine B. Belle,Soude Ghari,Song Wang,Timothy C. Lethbridge*

Main category: cs.SE

TL;DR: 论文提出用大语言模型自动审查关键系统保障案例的新方法，并以DeepSeek-R1等模型实测，发现AI可显著提升审查效率，但目前仍需人工修正，不能完全替代人类审查。


<details>
  <summary>Details</summary>
Motivation: 高风险系统（如自动驾驶、航空电子、空中交通控制等）的安全性、可靠性审核需要耗费大量人力、时间。传统保障案例文档冗长，人工审查易出错、效率低，亟需自动化审查方法提升保障质量和效率。

Method: 提出LLM-as-a-judge范式，基于生成式AI和大语言模型自动化审查保障案例。设计谓词规则形式化传统审查标准，并生成适用LLM的定制化审查提示。在主流LLM上（GPT-4o，GPT-4.1，DeepSeek-R1，Gemini 2.0 Flash）进行实验对比模型表现。

Result: 绝大多数LLM模型具备较好的审查能力，其中DeepSeek-R1和GPT-4.1表现尤为突出，DeepSeek-R1最终效果最佳。但实验表明LLM审查结果仍需人工进一步修订完善。

Conclusion: 基于LLM的自动化保障案例审查方法显著提升了效率和一致性，DeepSeek-R1在此任务上表现最佳，但LLM尚不能完全替代人工审查，人工把关依然必要。

Abstract: Assurance cases allow verifying the correct implementation of certain
non-functional requirements of mission-critical systems, including their
safety, security, and reliability. They can be used in the specification of
autonomous driving, avionics, air traffic control, and similar systems. They
aim to reduce risks of harm of all kinds including human mortality,
environmental damage, and financial loss. However, assurance cases often tend
to be organized as extensive documents spanning hundreds of pages, making their
creation, review, and maintenance error-prone, time-consuming, and tedious.
Therefore, there is a growing need to leverage (semi-)automated techniques,
such as those powered by generative AI and large language models (LLMs), to
enhance efficiency, consistency, and accuracy across the entire assurance-case
lifecycle. In this paper, we focus on assurance case review, a critical task
that ensures the quality of assurance cases and therefore fosters their
acceptance by regulatory authorities. We propose a novel approach that
leverages the \textit{LLM-as-a-judge} paradigm to automate the review process.
Specifically, we propose new predicate-based rules that formalize
well-established assurance case review criteria, allowing us to craft LLM
prompts tailored to the review task. Our experiments on several
state-of-the-art LLMs (GPT-4o, GPT-4.1, DeepSeek-R1, and Gemini 2.0 Flash) show
that, while most LLMs yield relatively good review capabilities, DeepSeek-R1
and GPT-4.1 demonstrate superior performance, with DeepSeek-R1 ultimately
outperforming GPT-4.1. However, our experimental results also suggest that
human reviewers are still needed to refine the reviews LLMs yield.

</details>


### [6] [SWE-Sharp-Bench: A Reproducible Benchmark for C# Software Engineering Tasks](https://arxiv.org/abs/2511.02352)
*Sanket Mhatre,Yasharth Bajpai,Sumit Gulwani,Emerson Murphy-Hill,Gustavo Soares*

Main category: cs.SE

TL;DR: 本文提出并公开了面向C#的自动化软件工程基准SWE-Sharp-Bench，发现AI代码代理在C#上的表现远低于Python，揭示了跨语言AI代码工具性能的显著差异，并为C#相关研究提供标准和资源。


<details>
  <summary>Details</summary>
Motivation: 在现有的AI代码代理和软件工程基准测试中，诸如Python、Java和C等语言都有相应的测试集，但主流企业级语言C#却缺乏相关基准，阻碍了AI代码工具在C#领域的发展和评估。

Method: 作者提出了SWE-Sharp-Bench，这是针对C#开发的软件工程基准数据集，包含150个实例，来自17个不同的代码库，并且复现了跨语言统一的评测配置，确保评价的公平和可对比性，同时开放了数据集和整个数据整理由工具链。

Result: 在相同的模型配置下，C#任务的解决率仅为40%，而Python任务可达70%，展现了AI代码代理在C#语言上的显著性能差距。

Conclusion: 本研究填补了C#语言在AI软件工程基准测试中的空白，提出了新的标准并证实了当前模型在C#领域的局限，为后续C#相关自动化工具发展和优化提供了重要基础。

Abstract: AI coding agents have shown great progress on Python software engineering
benchmarks like SWE-Bench, and for other languages like Java and C in
benchmarks like Multi-SWE-Bench. However, C# -- a prominent enterprise language
ranking #5 in the TIOBE index -- remains absent from such benchmarks. We
introduce SWE-Sharp-Bench, a reproducible software engineering benchmark for
C\# featuring 150 instances from 17 repositories. Evaluating identical
model-agent configurations across languages reveals a significant performance
gap: while 70% of Python tasks in SWE-Bench Verified are solved, $only 40% of
our C\# tasks are resolved. We open-source SWE-Sharp-Bench and our entire
curation pipeline.

</details>


### [7] [EvoDev: An Iterative Feature-Driven Framework for End-to-End Software Development with LLM-based Agents](https://arxiv.org/abs/2511.02399)
*Junwei Liu,Chen Xu,Chong Wang,Tong Bai,Weitong Chen,Kaseng Wong,Yiling Lou,Xin Peng*

Main category: cs.SE

TL;DR: 本文提出EvoDev框架，通过构建特性依赖图和上下文传递机制，实现LLM驱动的软件开发迭代优化，并在复杂项目中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLM）在自动化软件开发中取得了进展，但主流方法多采用线性、瀑布式流程，无法有效处理现实中迭代性强、需求复杂的大型项目。作者希望弥补这一不足。

Method: 提出EvoDev框架，借鉴特性驱动开发理念，将用户需求分解为特性集合，通过有向无环图（Feature Map）建模特性间依赖。每个节点包含业务逻辑、设计与代码等多层信息，依赖传播为后续开发提供上下文。

Result: 在复杂的Android开发任务中，EvoDev相较最优基线方法（Claude Code）提升了56.8%，在不同基础LLM下的单体性能提升16.0%-76.6%。

Conclusion: EvoDev展示了依赖建模、上下文传递和面向流程的智能体设计对于复杂项目的重要性，并为未来LLM驱动的迭代软件开发框架和LLM训练提供了有益经验。

Abstract: Recent advances in large language model agents offer the promise of
automating end-to-end software development from natural language requirements.
However, existing approaches largely adopt linear, waterfall-style pipelines,
which oversimplify the iterative nature of real-world development and struggle
with complex, large-scale projects. To address these limitations, we propose
EvoDev, an iterative software development framework inspired by feature-driven
development. EvoDev decomposes user requirements into a set of user-valued
features and constructs a Feature Map, a directed acyclic graph that explicitly
models dependencies between features. Each node in the feature map maintains
multi-level information, including business logic, design, and code, which is
propagated along dependencies to provide context for subsequent development
iterations. We evaluate EvoDev on challenging Android development tasks and
show that it outperforms the best-performing baseline, Claude Code, by a
substantial margin of 56.8%, while improving single-agent performance by
16.0%-76.6% across different base LLMs, highlighting the importance of
dependency modeling, context propagation, and workflow-aware agent design for
complex software projects. Our work summarizes practical insights for designing
iterative, LLM-driven development frameworks and informs future training of
base LLMs to better support iterative software development.

</details>


### [8] [Who's Who? LLM-assisted Software Traceability with Architecture Entity Recognition](https://arxiv.org/abs/2511.02434)
*Dominik Fuchß,Haoyu Liu,Sophie Corallo,Tobias Hey,Jan Keim,Johannes von Geisau,Anne Koziolek*

Main category: cs.SE

TL;DR: 本文提出了基于大型语言模型的自动化架构实体识别方法ExArch和ArTEMiS，并和现有主流方法进行对比。结果显示，LLM方法无需手工建模即可接近甚至优于人工方案，推动了架构与代码追溯的自动化和实用性发展。


<details>
  <summary>Details</summary>
Motivation: 在软件架构文件与源代码之间建立可追踪性连接（TLR）对软件架构分析和维护至关重要。但架构模型（SAM）的人工创建过程耗时且易出错，因此研究如何利用大型语言模型（LLM）自动识别架构实体、生成SAM，提升效率和自动化水平。

Method: 提出了两种基于LLM的方法：ExArch从软件架构文档和源代码中自动提取组件名称，实现SAM自动生成；ArTEMiS则识别文档中的架构实体，并与SAM实体进行匹配。通过对比当前主流方法SWATTR、TransArC和ArDoCode进行评估。

Result: ExArch能够仅依赖架构文档和源码达到与需要手工SAM的TransArC相当的效果（F1:0.86 vs 0.87）；ArTEMiS与传统启发式的SWATTR表现一致（F1:0.81），且可与TransArC集成替换SWATTR；ExArch和ArTEMiS组合优于无需手工SAM的最佳基线方法ArDoCode。

Conclusion: LLM能够有效识别软件架构相关的文本实体，实现SAM的自动生成和可追踪性链接恢复，极大简化架构与代码的追踪，提升实际应用的可行性和便利性。

Abstract: Identifying architecturally relevant entities in textual artifacts is crucial
for Traceability Link Recovery (TLR) between Software Architecture
Documentation (SAD) and source code. While Software Architecture Models (SAMs)
can bridge the semantic gap between these artifacts, their manual creation is
time-consuming. Large Language Models (LLMs) offer new capabilities for
extracting architectural entities from SAD and source code to construct SAMs
automatically or establish direct trace links. This paper presents two
LLM-based approaches: ExArch extracts component names as simple SAMs from SAD
and source code to eliminate the need for manual SAM creation, while ArTEMiS
identifies architectural entities in documentation and matches them with
(manually or automatically generated) SAM entities. Our evaluation compares
against state-of-the-art approaches SWATTR, TransArC and ArDoCode. TransArC
achieves strong performance (F1: 0.87) but requires manually created SAMs;
ExArch achieves comparable results (F1: 0.86) using only SAD and code. ArTEMiS
is on par with the traditional heuristic-based SWATTR (F1: 0.81) and can
successfully replace it when integrated with TransArC. The combination of
ArTEMiS and ExArch outperforms ArDoCode, the best baseline without manual SAMs.
Our results demonstrate that LLMs can effectively identify architectural
entities in textual artifacts, enabling automated SAM generation and TLR,
making architecture-code traceability more practical and accessible.

</details>


### [9] [When Continuous Delivery Is Not an Option: Practical Paths to Continuous Engineering in Complex Organizations](https://arxiv.org/abs/2511.02445)
*Eriks Klotins,Magnus Ahlgren,Nicolas Martin Vivaldi,Even-Andre Karlsson*

Main category: cs.SE

TL;DR: 本研究分析了不同行业CSE采纳的障碍与动力，提出改进的模型和实用建议，强调即使采纳受限，内部持续改进依然能带来明显益处。


<details>
  <summary>Details</summary>
Motivation: 连续软件工程（CSE）虽有提升效率和响应性的潜力，但实际全面应用在受限于复杂产品、遗留系统、组织惯性和法规要求。该文旨在探索行业实际采用CSE时这些约束的影响。

Method: 通过扩展CSE工业准备度模型，对自动化、汽车、零售和化工等四个行业案例进行分析，并结合专家访谈与叙述综合，识别推动力和障碍。

Result: 提出了一个更新的准备度模型，增加了内部与外部反馈层次，区分了市场与组织层面的约束，更好地指导业界制定现实的CSE采纳目标。发现完全端到端的CSE应用通常不可行，但内部改进依然可行且有益。

Conclusion: 为组织在部分或受限的CSE转型中提供了基于实证的指导，强调即使无法实现完整采纳，积极的内部变革同样重要。

Abstract: Purpose: Continuous Software Engineering (CSE) promises improved efficiency,
quality, and responsiveness in software-intensive organizations. However, fully
adopting CSE is often constrained by complex products, legacy systems,
organizational inertia, and regulatory requirements. In this paper, we examine
four industrial cases from the automation, automotive, retail, and chemical
sectors to explore how such constraints shape CSE adoption in practice.
Methods: We apply and extend a previously proposed CSE Industry Readiness Model
to assess the current and potential levels of adoption in each case. Through
expert interviews and narrative synthesis, we identify common driving forces
and adoption barriers, including organizational preparedness,
cross-organizational dependencies, and limited customer demand for continuous
delivery. Results: Based on our findings, we propose an updated readiness model
that introduces additional levels of internal and external feedback,
distinguishes market- and organization-facing constraints, and better guides
practitioners in setting realistic CSE adoption goals. Conclusions: Our results
highlight that while full end-to-end CSE adoption may not always be feasible,
meaningful internal improvements are still possible and beneficial. This study
provides empirically grounded guidance for organizations navigating partial or
constrained CSE transformations.

</details>


### [10] [Lost in Code Generation: Reimagining the Role of Software Models in AI-driven Software Engineering](https://arxiv.org/abs/2511.02475)
*Jürgen Cito,Dominik Bork*

Main category: cs.SE

TL;DR: 生成式AI简化了软件开发但带来系统脆弱等问题。作者建议通过从AI生成代码中逆向恢复软件模型，提升可理解性、风险管控和系统可持续发展。


<details>
  <summary>Details</summary>
Motivation: 生成式AI迅速推动了自然语言生成软件系统的发展，但导致原型与工程化软件界限模糊，系统易脆弱，难以维护，缺乏安全性与鲁棒性。

Method: 提出模型在AI生成代码后用于补充设计与增进理解的新方法。

Result: 重塑模型在软件开发中的角色，让其作为理解、风险分析和系统改进的中介，有助于推进AI生成软件向更可靠、更可维护的方向发展。

Conclusion: 模型可以在AI生成代码后用于恢复理解、暴露风险，并指导后续改进，是实现可持续AI驱动的软件工程的关键中介。

Abstract: Generative AI enables rapid ``vibe coding," where natural language prompts
yield working software systems. While this lowers barriers to software
creation, it also collapses the boundary between prototypes and engineered
software, leading to fragile systems that lack robustness, security, and
maintainability. We argue that this shift motivates a reimagining of software
models. Rather than serving only as upfront blueprints, models can be recovered
post-hoc from AI-generated code to restore comprehension, expose risks, and
guide refinement. In this role, models serve as mediators between human intent,
AI generation, and long-term system evolution, providing a path toward
sustainable AI-driven software engineering.

</details>


### [11] [ReleaseEval: A Benchmark for Evaluating Language Models in Automated Release Note Generation](https://arxiv.org/abs/2511.02713)
*Qianru Meng,Zhaochun Ren,Joost Visser*

Main category: cs.SE

TL;DR: 论文提出了公开可复现的ReleaseEval基准，系统评测语言模型在自动生成发布说明上的能力，发现LLMs能有效利用结构化信息但处理细粒度代码差异仍需提升。


<details>
  <summary>Details</summary>
Motivation: 人工撰写发布说明耗时且易出错，现有自动化方法受数据集许可、复现能力、任务设计单一等限制，缺乏细粒度信息利用，亟需更科学系统的评测基准。

Method: 提出了一个名为ReleaseEval的新基准，包括三个任务（commit2sum, tree2sum, diff2sum），数据集涵盖多个编程语言和丰富数据层次，通过自动化和人工评估对比不同方法表现。

Result: LLMs在所有任务上均优于传统方法，尤其在利用结构化信息（如commit树结构）方面表现突出，对长代码差异（diff2sum）抽象提炼仍较困难。

Conclusion: 大语言模型在自动化发布说明生成任务上整体优于传统方法，但在处理细粒度代码变更（diff2sum）任务时仍有明显挑战。

Abstract: Automated release note generation addresses the challenge of documenting
frequent software updates, where manual efforts are time-consuming and prone to
human error. Although recent advances in language models further enhance this
process, progress remains hindered by dataset limitations, including the lack
of explicit licensing and limited reproducibility, and incomplete task design
that relies mainly on commit messages for summarization while overlooking
fine-grained contexts such as commit hierarchies and code changes. To fill this
gap, we introduce ReleaseEval, a reproducible and openly licensed benchmark
designed to systematically evaluate language models for automated release note
generation. ReleaseEval comprises 94,987 release notes from 3,369 repositories
across 6 programming languages, and supports three task settings with three
levels of input granularity: (1) commit2sum, which generates release notes from
commit messages; (2) tree2sum, which incorporates commit tree structures; and
(3) diff2sum, which leverages fine-grained code diffs. Both automated and human
evaluations show that large language models consistently outperform traditional
baselines across all tasks, achieving substantial gains on tree2sum, while
still struggling on diff2sum. These findings highlight LLMs' proficiency in
leveraging structured information while revealing challenges in abstracting
from long code diffs.

</details>


### [12] [Investigating the Experience of Autistic Individuals in Software Engineering](https://arxiv.org/abs/2511.02736)
*Madalena Sasportes,Grischa Liebel,Miguel Goulão*

Main category: cs.SE

TL;DR: 自闭症软件工程师表现出显著的逻辑思维、细节关注和专注力，偏好书面沟通及远程工作，与AI系统互动时更舒适。研究证实并补充了他们在软件工程中的独特优势，建议行业更好地发掘和利用这些能力，以提升包容性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注自闭症个体在软件工程中的挑战与适应，而忽视了他们的优势，如高度的细节关注和逻辑推理能力。本文旨在分析自闭症人士在软件工程实践中的优势，促进他们更好地参与和包容。

Method: 采用社会—技术扎根理论，通过半结构化访谈（16名自闭症软件工程师）及问卷调查（49名参与者，包括5名自闭症人士），并将研究主题与Gama等人关于神经多样性认知障碍对软件工程绩效影响的理论进行比较。

Result: 发现自闭症软件工程师在逻辑思维、细节关注和编程时的高度专注方面表现突出，喜欢学习新编程语言和相关技术，倾向于书面沟通及远程工作，并且与人工智能系统互动时感到舒适。结果进一步证实了他们的沟通和工作偏好。

Conclusion: 本研究扩展了前人的发现，进一步验证并强调了自闭症软件工程师在逻辑、专注、学习和技术适应性等方面的突出优势，为提升其行业参与和包容性提供了依据。

Abstract: Context: Autism spectrum disorder (ASD) leads to various issues in the
everyday life of autistic individuals, often resulting in unemployment and
mental health problems. To improve the inclusion of autistic adults, existing
studies have highlighted the strengths these individuals possess in comparison
to non-autistic individuals, e.g., high attention to detail or excellent
logical reasoning skills. If fostered, these strengths could be valuable in
software engineering activities, such for identifying specific kinds of bugs in
code. However, existing work in SE has primarily studied the challenges of
autistic individuals and possible accommodations, with little attention their
strengths. Objective: Our goal is to analyse the experiences of autistic
individuals in software engineering activities, such as code reviews, with a
particular emphasis on strengths. Methods: This study combines Social-Technical
Grounded Theory through semi-structured interviews with 16 autistic software
engineers and a survey with 49 respondents, including 5 autistic participants.
We compare the emerging themes with the theory by Gama et al. on the Effect of
Neurodivergent Cognitive Dysfunctions in Software Engineering Performance.
Results: Our results suggest that autistic software engineers are often skilled
in logical thinking, attention to detail, and hyperfocus in programming; and
they enjoy learning new programming languages and programming-related
technologies. Confirming previous work, they tend to prefer written
communication and remote work. Finally, we report a high comfort level in
interacting with AI-based systems. Conclusions: Our findings extend existing
work by providing further evidence on the strengths of autistic software
engineers.

</details>


### [13] [Formalizing Regression Testing for Agile and Continuous Integration Environments](https://arxiv.org/abs/2511.02810)
*Suddhasvatta Das,Kevin Gary*

Main category: cs.SE

TL;DR: 该文提出了适用于敏捷开发环境下的连续回归测试形式化模型，有效统一了新旧回归测试理论，并证明了模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 现代敏捷开发下，软件版本持续迭代，回归测试需要贯穿开发周期，传统回归测试理论无法很好地适应这一不断交付的背景，因此需要新的形式化模型。

Method: 将连续或近连续的回归测试形式化为按时间排序的构建链，对每一构建包含程序、需求和测试，并定义了构建之间的回归测试窗口。利用构建元组操作，无需额外假设，即可表达主流敏捷回归测试算法，并进行了其完备性和正确性的证明。

Result: 所提出的模型可完全表示主流敏捷回归测试算法，且模型的正确性和完备性得到证明，同时可以兼容于传统回归测试特例。

Conclusion: 本文提出的连续回归测试形式化模型有效地概括了软件版本迭代中回归测试的实际需求，并能涵盖经典两版本回归测试的语义。

Abstract: Software developed using modern agile practices delivers a stream of software
versions that require continuous regression testing rather than testing once
close to the delivery or maintenance phase, as assumed by classical
regression-testing theory. In this work, we formalize the phenomenon of
continuous or near-continuous regression testing using successive builds as a
time-ordered chain, where each build contains the program, requirements, and
the accompanying tests. We also formalize the regression test window between
any two builds, which captures the limited time budget available for regression
testing. As the time limit is set to infinity and the chain is closed to two
builds, the model degenerates to retest-all, thereby preserving semantics for
the classical two-version case. The formalization is validated by directly
representing two state-of-the-art agile regression testing algorithms in terms
of build-tuple operations without requiring auxiliary assumptions, followed by
proof of the soundness and completeness of our formalization.

</details>


### [14] [From Code Changes to Quality Gains: An Empirical Study in Python ML Systems with PyQu](https://arxiv.org/abs/2511.02827)
*Mohamed Almukhtar,Anwar Ghammam,Marouane Kessentini,Hua Ming*

Main category: cs.SE

TL;DR: 提出PyQu工具，深入分析3340个Python机器学习开源项目，发现和归纳出13类、共61种直接提升质量的代码变更，其中41%为首次发现，为今后自动化质量评估奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI和基于Python的机器学习系统广泛应用，代码质量问题日益突出，但目前缺乏有效的工具和方法将代码变更与软件质量影响直接关联。先前工作大多仅停留在描述变更内容，未明确阐述其对质量的具体影响。

Method: 大规模实证研究，分析了3340个开源Python机器学习项目，涉及370多万次提交和2.7万亿行代码。提出了新工具PyQu，基于底层软件度量识别提升质量的代码提交，并结合主题分析法对影响质量的代码变更进行分类。

Result: PyQu工具能够以0.84的平均准确率、精度和召回率以及0.85的F1分数识别提升质量的代码提交。共归纳出61种直接提升质量的代码变更，分为13类，其中41%为首次发现，未被现有检测工具覆盖。

Conclusion: 本文构建了代码变更与Python机器学习软件质量影响之间的桥梁，提出了新工具和变更分类，为自动化质量评估和最佳实践提供了理论与工具基础。

Abstract: In an era shaped by Generative Artificial Intelligence for code generation
and the rising adoption of Python-based Machine Learning systems (MLS),
software quality has emerged as a major concern. As these systems grow in
complexity and importance, a key obstacle lies in understanding exactly how
specific code changes affect overall quality-a shortfall aggravated by the lack
of quality assessment tools and a clear mapping between ML systems code changes
and their quality effects. Although prior work has explored code changes in
MLS, it mostly stops at what the changes are, leaving a gap in our knowledge of
the relationship between code changes and the MLS quality. To address this gap,
we conducted a large-scale empirical study of 3,340 open-source Python ML
projects, encompassing more than 3.7 million commits and 2.7 trillion lines of
code. We introduce PyQu, a novel tool that leverages low level software metrics
to identify quality-enhancing commits with an average accuracy, precision, and
recall of 0.84 and 0.85 of average F1 score. Using PyQu and a thematic
analysis, we identified 61 code changes, each demonstrating a direct impact on
enhancing software quality, and we classified them into 13 categories based on
contextual characteristics. 41% of the changes are newly discovered by our
study and have not been identified by state-of-the-art Python changes detection
tools. Our work offers a vital foundation for researchers, practitioners,
educators, and tool developers, advancing the quest for automated quality
assessment and best practices in Python-based ML software.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [15] [ScenicProver: A Framework for Compositional Probabilistic Verification of Learning-Enabled Systems](https://arxiv.org/abs/2511.02164)
*Eric Vin,Kyle A. Miller,Inigo Incer,Sanjit A. Seshia,Daniel J. Fremont*

Main category: cs.LO

TL;DR: ScenicProver是一种新型学习型CPS验证框架，通过组合分析、契约证明和证据追踪，能在现实复杂环境下实现比传统单一测试更强的保障效果。


<details>
  <summary>Details</summary>
Motivation: 由于存在黑盒组件和复杂的真实环境，支持学习的网络物理系统（CPS）全面验证一直非常困难。现有工具只能针对有限类型的系统提供形式化保证，或将整个系统作为整体测试，缺乏可用于复杂真实环境、能够采用多样化验证方法的通用组合分析框架。

Method: 提出了ScenicProver框架。该框架基于Scenic概率编程语言，支持可组合的系统描述，接口清晰，适用范围从可解释代码到黑盒组件；扩展了线性时序逻辑，实现了包含任意Scenic表达式的假设-保证契约；可通过测试、Lean 4形式化证明以及外部假设导入生成证据，并可系统性地组合这些证据，通过契约算子合成保障，并自动生成基于来源跟踪的系统级保障论证。

Result: 在自动驾驶汽车的自动紧急制动系统（包含传感器融合）案例中，展示了框架的有效性。结合雷达和激光传感器的厂家担保，并对不确定条件进行重点测试，使得在相同计算资源下，系统获得比整体测试更强的概率性保障。

Conclusion: ScenicProver框架实现了学习型CPS的可组合分析，能够在复杂实际环境下，将多种验证技术结合，生成更强的系统性保证。

Abstract: Full verification of learning-enabled cyber-physical systems (CPS) has long
been intractable due to challenges including black-box components and complex
real-world environments. Existing tools either provide formal guarantees for
limited types of systems or test the system as a monolith, but no general
framework exists for compositional analysis of learning-enabled CPS using
varied verification techniques over complex real-world environments. This paper
introduces ScenicProver, a verification framework that aims to fill this gap.
Built upon the Scenic probabilistic programming language, the framework
supports: (1) compositional system description with clear component interfaces,
ranging from interpretable code to black boxes; (2) assume-guarantee contracts
over those components using an extension of Linear Temporal Logic containing
arbitrary Scenic expressions; (3) evidence generation through testing, formal
proofs via Lean 4 integration, and importing external assumptions; (4)
systematic combination of generated evidence using contract operators; and (5)
automatic generation of assurance cases tracking the provenance of system-level
guarantees. We demonstrate the framework's effectiveness through a case study
on an autonomous vehicle's automatic emergency braking system with sensor
fusion. By leveraging manufacturer guarantees for radar and laser sensors and
focusing testing efforts on uncertain conditions, our approach enables stronger
probabilistic guarantees than monolithic testing with the same computational
budget.

</details>


### [16] [Non-commutative linear logic fragments with sub-context-free complexity](https://arxiv.org/abs/2511.02348)
*Yusaku Nishimiya,Masaya Taniguchi*

Main category: cs.LO

TL;DR: 本文基于Lambek演算片段首次明确刻画了三类形式语言（REG、LCFL、CFL）与逻辑复杂性的对应关系，提出更简洁的证明工具，丰富了计算与逻辑关系的理论基础，有助于后续细致复杂度分离研究。


<details>
  <summary>Details</summary>
Motivation: 以往复杂度刻画方法复杂，且对计算与逻辑之间细粒度关系的理解不足。文章试图为不同序列演算提供更细致的复杂度分层，并揭示计算与逻辑交互的基础。

Method: 作者通过限制Lambek演算中的推理规则、公式大小和可用连结词来描述不同复杂度类。通过类型逻辑与形式文法之间的直接转换以及对可证序列的结构归纳，简化了证明过程，并首次以简单直观方式实现了相关复杂度的刻画。

Result: （1）首次将Lambek演算的特定部分与REG和LCFL证明复杂性一一对应；（2）证明了某种最弱逻辑变体具有CFL复杂性；（3）方法基于更加直接和直观的工具，并明确了Lambek语法中的Greibach范式。

Conclusion: 文章首次将Lambek演算的若干片段与正规语言（REG）、线性上下文无关语言（LCFL）和上下文无关语言（CFL）的证明复杂性进行了明确对应，提出这类逻辑片段与相关复杂度类的具体关系，并利用Cut-elimination定理建立了分析工具，对形式语法和序列演算进行比较。

Abstract: We present new descriptive complexity characterisations of classes REG
(regular languages), LCFL (linear context-free languages) and CFL (context-free
languages) as restrictions on inference rules, size of formulae and permitted
connectives in the Lambek calculus; fragments of the intuitionistic
non-commutative linear logic with direction-sensitive implication connectives.
Our identification of the Lambek calculus fragments with proof complexity REG
and LCFL is the first result of its kind. We further show the CFL complexity of
one of the strictly `weakest' possible variants of the logic, admitting only a
single inference rule. The proof thereof, moreover, is based on a direct
translation between type-logical and formal grammar and structural induction on
provable sequents; a simpler and more intuitive method than those employed in
prior works. We thereby establish a clear conceptual utility of the
Cut-elimination theorem for comparing formal grammar and sequent calculus, and
identify the exact analogue of the Greibach Normal Form in Lambek grammar. We
believe the result presented herein constitutes a first step toward a more
extensive and richer characterisation of the interaction between computation
and logic, as well as a finer-grained complexity separation of various sequent
calculi.

</details>


### [17] [Large Lemma Miners: Can LLMs do Induction Proofs for Hardware?](https://arxiv.org/abs/2511.02521)
*Romy Peled,Daniel Kroening,Michael Tautschnig,Yakir Vizel*

Main category: cs.LO

TL;DR: 本研究利用LLMs结合神经符号方法自动化生成硬件归纳证明，减少人工验证工作。在87%测试问题中，自动方法成功生成可证明的论证，展现了实际工业价值。


<details>
  <summary>Details</summary>
Motivation: 手动的硬件形式化验证工作量大，效率低，寻求用LLMs自动化生成归纳证明以提高效率和赋能工业应用。

Method: 提出了一种神经符号方法，结合了两个提示框架，用于生成候选不变量，并用形式化符号工具进行验证。

Result: 在开放源代码的中等规模RTL设计中，经过充分重提示，LLMs能够成功生成归纳论证。在87%的问题中，至少有一种提示方法成功生成了可被证明正确的归纳论证。

Conclusion: LLMs能够生成用于硬件验证的归纳证明，并且在大部分测试问题上取得了成功，显著减少了人工工作并具备工业应用价值。

Abstract: Large Language Models (LLMs) have shown potential for solving mathematical
tasks. We show that LLMs can be utilized to generate proofs by induction for
hardware verification and thereby replace some of the manual work done by
Formal Verification engineers and deliver industrial value. We present a
neurosymbolic approach that includes two prompting frameworks to generate
candidate invariants, which are checked using a formal, symbolic tool. Our
results indicate that with sufficient reprompting, LLMs are able to generate
inductive arguments for mid-size open-source RTL designs. For $87\%$ of our
problem set, at least one of the prompt setups succeeded in producing a
provably correct inductive argument.

</details>


### [18] [The Limit of Recursion in State-based Systems](https://arxiv.org/abs/2511.02594)
*Bahareh Afshari,Giacomo Barlucchi,Graham E. Leigh*

Main category: cs.LO

TL;DR: 本文通过保守型well-注释理论，证明了在所有可数结构下，模态可定义函数达到固定点时所需的迭代次数严格小于omega^2，修正并扩展了此前的相关结论。


<details>
  <summary>Details</summary>
Motivation: 此前关于mu演算闭包序数的边界存在不足或错误，需建立更精确的理论，澄清模态可定义函数固定点迭代的复杂性上限。并希望利用Kozen的well-注释方法找到新的分析路径。

Method: 引入保守型well-注释理论，分析注释最小性和结构的局部决定性，采用well-注释进行直接的“pumping”过程，以证明迭代次数的严格上界。

Result: 获得了omega^2的严格界限，排除了间断区间的可能性，完善了关于mu演算和模态逻辑中固定点迭代的理论基础。

Conclusion: omega^2 是可数结构中模态可定义函数达到不动点所需迭代次数的严格上界，修正并扩展了之前关于交替自由mu演算闭包序数的结果。通过引入保守型well-注释理论，保证注释的最小性，定位了结构中影响公式闭包序数的局部部分，并通过well-注释实现了直接清晰的排除方法，排除了omega^2与可数极限之间的闭包序数。

Abstract: We prove that omega^2 strictly bounds the iterations required for modal
definable functions to reach a fixed point across all countable structures. The
result corrects and extends the previously claimed result by the first and
third authors on closure ordinals of the alternation-free mu-calculus in [3].
The new approach sees a reincarnation of Kozen's well-annotations, devised for
showing the finite model property for the modal mu-calculus. We develop a
theory of 'conservative' well-annotations where minimality of annotations is
guaranteed, and isolate parts of the structure that locally determine the
closure ordinal of relevant formulas. This adoption of well-annotations enables
a direct and clear pumping process that rules out closure ordinals between
omega^2 and the limit of countability.

</details>


### [19] [Nominal Algebraic-Coalgebraic Data Types, with Applications to Infinitary Lambda-Calculi](https://arxiv.org/abs/2511.02595)
*Rémy Cerda*

Main category: cs.LO

TL;DR: 本文扩展了名义数据类型理论，引入混合绑定签名及混合归纳-余归纳项类型，从而支持更复杂的无限λ项及其替换操作的名义描述和管理。


<details>
  <summary>Details</summary>
Motivation: 此前的研究表明，利用名义技巧可以设计带有变量绑定的余代数数据类型，能够在无限项的α-等价类上直接定义核心递归原则。但原有方法限于单一绑定规则，无法应对更复杂的绑定场景。本文动机在于扩展名义技巧的应用，让其支持混合绑定签名，以适应如abc-无限λ项等更复杂的类型和操作场景。

Method: 引入“混合绑定签名”和对应的混合归纳-余归纳项类型，在此框架下将以往的名义数据类型理论扩展到能够处理更复杂绑定结构的场景。

Result: 该方法允许对集合Lambda_abc（abc-无限λ项）的名义描述，并能在这些项的α-等价类上定义避免捕获的替换操作。这样实现了对复杂无限结构的严格和有效赋值处理。

Conclusion: 通过扩展名义数据类型理论到混合绑定和混合归纳-余归纳项，本文实现了对复杂无限λ项的α-等价类及其捕获避免替换操作的直接支持，推动了相关领域数据结构理论的发展。

Abstract: Ten years ago, it was shown that nominal techniques can be used to design
coalgebraic data types with variable binding, so that alpha-equivalence classes
of infinitary terms are directly endowed with a corecursion principle. We
introduce "mixed" binding signatures, as well as the corresponding type of
mixed inductive-coinductive terms. We extend the aforementioned work to this
setting. In particular, this allows for a nominal description of the sets
Lambda_abc of abc-infinitary lambda-terms (for a, b, c in {0,1}) and of
capture-avoiding substitution on alpha-equivalence classes of such terms.

</details>


### [20] [Characterizing the Exponential-Space Hierarchy Via Partial Fixpoints](https://arxiv.org/abs/2511.02596)
*Florian Bruse,David Kronenberger,Martin Lange*

Main category: cs.LO

TL;DR: 本文拓展了PSPACE与一阶部分不动点逻辑的对应关系，提出任意k的EXPSPACE查询可用(k+1)-阶高阶部分不动点逻辑表达，对高阶情况无需有序结构约束，深化了复杂性与逻辑刻画理论。


<details>
  <summary>Details</summary>
Motivation: Vardi(1982)提出了PSPACE查询在有序结构上与具有部分不动点的一阶逻辑之间的刻画。这一结果在描述性复杂性理论领域具有奠基意义。本文旨在拓展这一经典结果，为更高复杂度的k-EXPSPACE查询寻找对应的逻辑刻画。

Method: 通过理论化的方法，将更高阶的k-EXPSPACE查询与带有部分不动点的(k+1)-阶高阶逻辑进行等价刻画。特别分析了当k>1时，高阶逻辑的表达能力是否还需要对结构有序性加以限制。

Result: 证明了任意k的k-EXPSPACE查询可以恰好通过带有部分不动点的(k+1)-阶高阶逻辑来表达。当k>1时，得益于高阶逻辑强大的表达能力，对结构的有序性限制不再是必须条件。

Conclusion: 将描述性复杂性中的经典PSPACE刻画扩展到任意k的EXPSPACE，建立了与高阶逻辑和部分不动点的新对应关系，并消除了对结构有序性的部分限制，丰富了复杂性与逻辑之间的理论联系。

Abstract: The characterization of PSPACE-queries over ordered structures as exactly
those expressible in first-order logic with partial fixpoints (Vardi'82) is one
of the classical results in the field of descriptive complexity. In this paper,
we extend this result to characterizations of k-EXPSPACE-queries for arbitrary
k, characterizing them as exactly those expressible in order-k+1-higher-order
logic with partial fixpoints. For k>1, the restriction to ordered structures is
no longer necessary due to the high expressive power of higher-order logic.

</details>


### [21] [The mu-calculus' Alternation Hierarchy is Strict over Non-Trivial Fusion Logics](https://arxiv.org/abs/2511.02597)
*Leonardo Pacheco*

Main category: cs.LO

TL;DR: 本文证明多模态μ-演算的交替层级在大多数模态逻辑融合中是严格的，但在如S5等特定情况会坍缩为普通模态逻辑。


<details>
  <summary>Details</summary>
Motivation: 模态μ-演算是一种通过引入最小和最大不动点算子扩展模态逻辑的形式系统，其交替层级能反映μ-公式中不动点算子的相互依赖程度。理解这种层级的严格性对于刻画不同逻辑系统的表达能力具有重要意义。

Method: 作者分析了μ-演算在多模态情况下的交替层级，重点讨论了该层级在不同模态逻辑融合背景下的表现，并比较了几种特殊情形（如S5框架）下μ-演算层级的坍缩现象。

Result: 结果表明，多模态μ-演算的交替层级在非平凡的模态逻辑融合上是严格的——即对于任意层级n，都存在某一更高层级的公式不能用较低层级公式表达。同时指出，在特定多模态逻辑（如S5）下，μ-演算可以完全等价于无不动点算子的模态逻辑。

Conclusion: 该研究扩展了μ-演算交替层级的理论，证明了在更广泛的模态逻辑结构下该层级的严格性。还关注了μ-演算在某些特殊系统中退化为传统模态逻辑的情形。

Abstract: The modal mu-calculus is obtained by adding least and greatest fixed-point
operators to modal logic. Its alternation hierarchy classifies the mu-formulas
by their alternation depth: a measure of the codependence of their least and
greatest fixed-point operators. The mu-calculus' alternation hierarchy is
strict over the class of all Kripke frames: for all n, there is a mu-formula
with alternation depth n+1 which is not equivalent to any formula with
alternation depth n. This does not always happen if we restrict the semantics.
For example, every mu-formula is equivalent to a formula without fixed-point
operators over S5 frames. We show that the multimodal mu-calculus' alternation
hierarchy is strict over non-trivial fusions of modal logics. We also comment
on two examples of multimodal logics where the mu-calculus collapses to modal
logic.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [22] [Multi-Personality Generation of LLMs at Decoding-time](https://arxiv.org/abs/2511.01891)
*Rongxin Chen,Yunfan Li,Yige Yuan,Bingbing Xu,Huawei Shen*

Main category: cs.CL

TL;DR: MPG框架使大模型能灵活高效地融合多个人格特征，无需额外训练，配合SCR采样显著提高多人格生成质量和效率。


<details>
  <summary>Details</summary>
Motivation: 实现LLM在不重新训练或依赖外部模型的前提下，同时展现多种个性属性，解决多个个性合成的灵活性和效率问题。

Method: 提出MPG框架，通过解码时的隐式密度比组合单维模型，利用“免费午餐”方法实现个性聚合采样，并设计了SCR采样方法，以chunk为单位生成和验证，降低计算成本。

Result: 在MBTI人格和角色扮演任务上，MPG框架带来16%-18%的生成提升，且维持高质量。

Conclusion: MPG框架无需额外训练或大型多维模型，能够高效且灵活地实现多个性生成，提升了可扩展性和生成效果。

Abstract: Multi-personality generation for LLMs, enabling simultaneous embodiment of
multiple personalization attributes, is a fundamental challenge. Existing
retraining-based approaches are costly and poorly scalable, while decoding-time
methods often rely on external models or heuristics, limiting flexibility and
robustness. In this paper, we propose a novel Multi-Personality Generation
(MPG) framework under the decoding-time combination paradigm. It flexibly
controls multi-personality without relying on scarce multi-dimensional models
or extra training, leveraging implicit density ratios in single-dimensional
models as a "free lunch" to reformulate the task as sampling from a target
strategy aggregating these ratios. To implement MPG efficiently, we design
Speculative Chunk-level based Rejection sampling (SCR), which generates
responses in chunks and parallelly validates them via estimated thresholds
within a sliding window. This significantly reduces computational overhead
while maintaining high-quality generation. Experiments on MBTI personality and
Role-Playing demonstrate the effectiveness of MPG, showing improvements up to
16%-18%. Code and data are available at https://github.com/Libra117/MPG .

</details>


### [23] [Rethinking LLM Human Simulation: When a Graph is What You Need](https://arxiv.org/abs/2511.02135)
*Joseph Suh,Suhong Moon,Serina Chang*

Main category: cs.CL

TL;DR: 本文提出GEMS模型，通过图神经网络完成离散选择类人类行为模拟任务，效果优于或不逊于LLM，且效率更高，是人类模拟领域的有前景的轻量解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLM）被广泛用于模拟人类行为，但其规模庞大，计算资源消耗高。作者提出疑问：是否一定需要LLM，或者更小的、领域相关模型也能完成类似任务？

Method: 提出了一种基于图神经网络（GNN）的模型GEMS，将离散选择的模拟任务转化为图上的链路预测问题，并在需要时结合语言表征。与LLM进行对比实验。

Result: 在三种场景、三个模拟数据集上，GEMS在准确率上可与LLM媲美甚至超越，并且效率、可解释性和透明性更高。

Conclusion: 图神经网络为人类行为模拟提供了轻量级、有效的替代方案，无需大型语言模型即可获得高质量模拟效果。

Abstract: Large language models (LLMs) are increasingly used to simulate humans, with
applications ranging from survey prediction to decision-making. However, are
LLMs strictly necessary, or can smaller, domain-grounded models suffice? We
identify a large class of simulation problems in which individuals make choices
among discrete options, where a graph neural network (GNN) can match or surpass
strong LLM baselines despite being three orders of magnitude smaller. We
introduce Graph-basEd Models for human Simulation (GEMS), which casts discrete
choice simulation tasks as a link prediction problem on graphs, leveraging
relational knowledge while incorporating language representations only when
needed. Evaluations across three key settings on three simulation datasets show
that GEMS achieves comparable or better accuracy than LLMs, with far greater
efficiency, interpretability, and transparency, highlighting the promise of
graph-based modeling as a lightweight alternative to LLMs for human simulation.
Our code is available at https://github.com/schang-lab/gems.

</details>


### [24] [IG-Pruning: Input-Guided Block Pruning for Large Language Models](https://arxiv.org/abs/2511.02213)
*Kangyu Qiao,Shaolei Zhang,Yang Feng*

Main category: cs.CL

TL;DR: 提出一种无需大量训练即可动态剪枝Transformer层的新方法IG-Pruning，在保证效果的同时显著提升了大模型的推理效率，对实际部署有重要意义。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型计算需求的增长，提高推理效率变得越来越重要。现有的深度剪枝方法多采用固定的层（block）掩码，难以适应不同任务和输入，可能导致性能不佳。

Method: 提出了一种全新的基于输入感知的块级剪枝方法（IG-Pruning），能在推理时动态选择层掩码。方法分为两个阶段：通过语义聚类和L0优化发现多样化的掩码候选，然后无需大量训练即可实现高效动态剪枝。

Result: 实验结果表明，该方法在各种情况下都优于当前主流的静态深度剪枝方法，显著提升了大模型在资源受限环境下的实用性。

Conclusion: IG-Pruning展示了动态、输入感知剪枝在提升大语言模型部署效率方面的潜力，特别适用于资源受限场景。

Abstract: With the growing computational demands of large language models (LLMs),
efficient inference has become increasingly critical for practical deployment.
Depth pruning has emerged as a promising approach for reducing the
computational costs of large language models by removing transformer layers.
However, existing methods typically rely on fixed block masks, which can lead
to suboptimal performance across different tasks and inputs. In this paper, we
propose IG-Pruning, a novel input-aware block-wise pruning method that
dynamically selects layer masks at inference time. Our approach consists of two
stages: (1) Discovering diverse mask candidates through semantic clustering and
L0 optimization, and (2) Implementing efficient dynamic pruning without the
need for extensive training. Experimental results demonstrate that our method
consistently outperforms state-of-the-art static depth pruning methods, making
it particularly suitable for resource-constrained deployment scenarios.

</details>


### [25] [Demo: Statistically Significant Results On Biases and Errors of LLMs Do Not Guarantee Generalizable Results](https://arxiv.org/abs/2511.02246)
*Jonathan Liu,Haoling Qiu,Jonathan Lasko,Damianos Karakos,Mahsa Yarmohammadi,Mark Dredze*

Main category: cs.CL

TL;DR: 论文提出自动化系统探测医疗场景下LLM幻觉和偏见，发现不同LLM评审不一致，建议多模型联合评估与公开一致性数据。代码和数据集已开源。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）在日常应用中常见幻觉、疏漏以及偏见，但在医疗场景下，尤其涉及患者人口统计等非医疗因素时，必须保证建议的一致性和公正性。为探查LLM在医疗场景下失效的具体条件，研究者提出了新的探索方法。

Method: 该论文开发了一个基础设施：1）自动生成用于探查LLM反应的查询问题，2）通过多种LLM担任评审和不同提示词，评估这些答案。生成问题时，系统会综合抽样患者的不同人口统计特征、病史、疾病及写作风格以构建真实问题。评估流程提供基于LLM担任裁判的幻觉与疏漏检测、代理式工作流，以及LLM担任的治疗类别检测器。

Result: 实证分析显示，不同的LLM评审者之间一致性很低（Cohen's Kappa平均仅为0.118），且只有特殊的“问答-评估”LLM组合在写作风格、性别、种族等分组下显示出统计显著差异。结论建议评估研究应同时采用多个LLM作为评审者，并发布LLM间一致性指标，以提升透明度并避免因缺失真实标签导致的不具泛化性的显著结论。

Conclusion: LLM作为医疗问答评判者在幻觉和疏漏检测上的一致性较差，研究应综合多种LLM评审，公开评审一致性结果，以避免得出误导性结论。

Abstract: Recent research has shown that hallucinations, omissions, and biases are
prevalent in everyday use-cases of LLMs. However, chatbots used in medical
contexts must provide consistent advice in situations where non-medical factors
are involved, such as when demographic information is present. In order to
understand the conditions under which medical chatbots fail to perform as
expected, we develop an infrastructure that 1) automatically generates queries
to probe LLMs and 2) evaluates answers to these queries using multiple
LLM-as-a-judge setups and prompts. For 1), our prompt creation pipeline samples
the space of patient demographics, histories, disorders, and writing styles to
create realistic questions that we subsequently use to prompt LLMs. In 2), our
evaluation pipeline provides hallucination and omission detection using
LLM-as-a-judge as well as agentic workflows, in addition to LLM-as-a-judge
treatment category detectors. As a baseline study, we perform two case studies
on inter-LLM agreement and the impact of varying the answering and evaluation
LLMs. We find that LLM annotators exhibit low agreement scores (average Cohen's
Kappa $\kappa=0.118$), and only specific (answering, evaluation) LLM pairs
yield statistically significant differences across writing styles, genders, and
races. We recommend that studies using LLM evaluation use multiple LLMs as
evaluators in order to avoid arriving at statistically significant but
non-generalizable results, particularly in the absence of ground-truth data. We
also suggest publishing inter-LLM agreement metrics for transparency. Our code
and dataset are available here:
https://github.com/BBN-E/medic-neurips-2025-demo.

</details>


### [26] [LTD-Bench: Evaluating Large Language Models by Letting Them Draw](https://arxiv.org/abs/2511.02347)
*Liuhao Lin,Ke Li,Zihan Xu,Yuchen Shi,Yulei Qin,Yan Zhang,Xing Sun,Rongrong Ji*

Main category: cs.CL

TL;DR: 提出LTD-Bench，将大模型评估由抽象分数转为可视化输出，显著揭示其空间推理能力不足，有助于推动AI模型评估方式革新。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型评估方式依赖于不透明的数值指标，这掩盖了模型在空间推理方面的局限性，且无法直观理解模型能力。这样的缺陷导致模型实际能力与报告结果存在重大脱节，尤其在需要物理世界理解的应用场景下可能带来严重后果。

Method: 提出LTD-Bench基准，通过让模型生成点阵绘图或可执行代码，将评估从抽象分数转向可视化输出。基准包含生成任务（测试空间想象力）和识别任务（评估空间感知），涵盖三种渐进难度，全面考察语言-空间双向映射能力。

Result: 用LTD-Bench对主流模型进行广泛实验，发现它们虽然在传统基准上表现优异，但在语言与空间概念的双向映射上仍存在明显能力缺口，这严重影响了它们作为真实世界模型的潜力。

Conclusion: LTD-Bench能直观暴露大模型在空间推理上的根本不足，为模型能力的感性评估提供工具，并有助于深入诊断和分析模型的异同，推动更有效的AI评估发展。

Abstract: Current evaluation paradigms for large language models (LLMs) represent a
critical blind spot in AI research--relying on opaque numerical metrics that
conceal fundamental limitations in spatial reasoning while providing no
intuitive understanding of model capabilities. This deficiency creates a
dangerous disconnect between reported performance and practical abilities,
particularly for applications requiring physical world understanding. We
introduce LTD-Bench, a breakthrough benchmark that transforms LLM evaluation
from abstract scores to directly observable visual outputs by requiring models
to generate drawings through dot matrices or executable code. This approach
makes spatial reasoning limitations immediately apparent even to non-experts,
bridging the fundamental gap between statistical performance and intuitive
assessment. LTD-Bench implements a comprehensive methodology with complementary
generation tasks (testing spatial imagination) and recognition tasks (assessing
spatial perception) across three progressively challenging difficulty levels,
methodically evaluating both directions of the critical language-spatial
mapping. Our extensive experiments with state-of-the-art models expose an
alarming capability gap: even LLMs achieving impressive results on traditional
benchmarks demonstrate profound deficiencies in establishing bidirectional
mappings between language and spatial concept--a fundamental limitation that
undermines their potential as genuine world models. Furthermore, LTD-Bench's
visual outputs enable powerful diagnostic analysis, offering a potential
approach to investigate model similarity.

</details>


### [27] [Let Multimodal Embedders Learn When to Augment Query via Adaptive Query Augmentation](https://arxiv.org/abs/2511.02358)
*Wongyu Kim,Hochang Lee,Sanghak Lee,Yoonsung Kim,Jaehyun Park*

Main category: cs.CL

TL;DR: 本文针对查询扩展带来的延迟和性能负面影响问题，提出了可自适应判断是否需要扩展的多模态嵌入模型M-Solomon，实现了更优的检索性能和更低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的查询扩展方法使用大型语言模型进行多任务训练，同时进行嵌入和生成，可以提升查询质量。但所有查询都进行扩展会显著增加延迟，并且对于部分查询反而降低性能。此外，之前的方法在多模态场景下研究较少。

Method: 提出了M-Solomon，一种通用的多模态嵌入模型，可以自适应地判断何时对查询进行扩展。训练阶段将数据集中的查询分为需要扩展和不需要扩展两组，对需扩展的查询通过强大的多模态LLM合成适当的扩展内容。推理阶段，模型通过生成/augment或/embed前缀，决定是否进行扩展，从而实现适应性查询扩展。

Result: 实验结果显示，M-Solomon不仅大幅超越了无扩展的基线，还优于始终扩展的基线，同时大幅提升了嵌入延迟。

Conclusion: M-Solomon有效实现了自适应、快速的多模态查询扩展和嵌入，提升了性能和效率。

Abstract: Query augmentation makes queries more meaningful by appending further
information to the queries to find relevant documents. Current studies have
proposed Large Language Model (LLM)-based embedders, which learn representation
for embedding and generation for query augmentation in a multi-task manner by
leveraging the generative capabilities of LLM. During inference, these jointly
trained embedders have conducted query augmentation followed by embedding,
showing effective results. However, augmenting every query leads to substantial
embedding latency and query augmentation can be detrimental to performance for
some queries. Also, previous methods have not been explored in multimodal
environments. To tackle these problems, we propose M-Solomon, a universal
multimodal embedder that can adaptively determine when to augment queries. Our
approach first divides the queries of the training datasets into two groups at
the dataset level. One includes queries that require augmentation and the other
includes queries that do not. Then, we introduces a synthesis process that
generates appropriate augmentations for queries that require them by leveraging
a powerful Multimodal LLM (MLLM). Next, we present adaptive query augmentation.
Through this step, M-Solomon can conduct query augmentation only when necessary
by learning to generate synthetic augmentations with the prefix /augment for
queries that demand them and to generate the simple string /embed for others.
Experimental results showed that M-Solomon not only surpassed the baseline
without augmentation by a large margin but also outperformed the baseline that
always used augmentation, providing much faster embedding latency.

</details>


### [28] [LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context](https://arxiv.org/abs/2511.02366)
*Yudong Li,Zhongliang Yang,Kejiang Chen,Wenxuan Wang,Tianxin Zhang,Sifang Wan,Kecheng Wang,Haitian Li,Xu Wang,Lefan Cheng,Youdan Yang,Baocheng Chen,Ziyu Liu,Yufei Sun,Liyan Wu,Wenya Wen,Xingchi Gu,Peiru Yang*

Main category: cs.CL

TL;DR: 作者提出了面向中文应用场景且持续动态更新的LLM安全评测基准LiveSecBench，涵盖六个关键安全维度，已评测18款模型并公开排行榜，为中文AI安全评估提供了重要基础。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）安全评测多集中于英文场景，缺乏针对中文实际应用需求的安全基准。作者希望构建一个针对中文语境，与中国法律和社会框架相关联的安全基准，以动态应对不断变化的新安全威胁。

Method: 提出了LiveSecBench，一个动态更新的中文LLM安全评测基准，从合法性、伦理性、事实性、隐私保护、对抗鲁棒性、推理安全六个维度出发进行评测。系统会定期引入新的安全评测维度（如文本到图像生成安全、Agentic安全），并根据最新威胁及时扩展测试内容。

Result: 当前版本LiveSecBench (v251030)已对18个主流中文LLM进行了安全评估，形成了公开的安全排行榜。

Conclusion: LiveSecBench为中文场景下的LLM安全性评估提供了权威、实时、透明的工具，并随着新威胁不断动态拓展，有助于推动中文LLM安全标准发展。

Abstract: In this work, we propose LiveSecBench, a dynamic and continuously updated
safety benchmark specifically for Chinese-language LLM application scenarios.
LiveSecBench evaluates models across six critical dimensions (Legality, Ethics,
Factuality, Privacy, Adversarial Robustness, and Reasoning Safety) rooted in
the Chinese legal and social frameworks. This benchmark maintains relevance
through a dynamic update schedule that incorporates new threat vectors, such as
the planned inclusion of Text-to-Image Generation Safety and Agentic Safety in
the next update. For now, LiveSecBench (v251030) has evaluated 18 LLMs,
providing a landscape of AI safety in the context of Chinese language. The
leaderboard is publicly accessible at https://livesecbench.intokentech.cn/.

</details>


### [29] [AyurParam: A State-of-the-Art Bilingual Language Model for Ayurveda](https://arxiv.org/abs/2511.02374)
*Mohd Nauman,Sravan Gvm,Vijay Devane,Shyam Pawar,Viraj Thakur,Kundeshwar Pundalik,Piyush Sawarkar,Rohit Saluja,Maunendra Desarkar,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: 本文提出了专门针对阿育吠陀医学的双语微调大模型AyurParam-2.9B，其在权威基准上超越了同级别甚至更大模型，证明通过高质量数据和领域适配可以大幅提升医疗领域AI表现。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）虽然在通用任务上表现优异，但在需要深厚文化、语言和专业知识的高度专业化领域（如传统医学系统——阿育吠陀）表现不佳。主流LLM难以准确解释和应用这些复杂的医学知识，因此需要开发专用模型。

Method: 提出并训练了AyurParam-2.9B，这是在Param-1-2.9B基础上微调而来的、专门用于阿育吠陀医学的双语（英语和印地语）模型。模型训练数据为大量经过专家精心整理的经典文献及临床指导内容，包含情境理解、推理、客观问答Q&A，严格保证事实准确性和指导性。

Result: 在BhashaBench-Ayur基准测试上，AyurParam-2.9B表现优于同参数量（1.5-3B参数）的开源指令微调模型，对比更大规模的模型也有竞争力，甚至有些性能更佳。

Conclusion: AyurParam-2.9B的实验结果凸显了真实领域适配和高质量监督对于高可靠性、更贴合文化背景的专业医疗AI的重要性。开发领域专用LLM能够弥补主流LLM在专业知识领域的不足。

Abstract: Current large language models excel at broad, general-purpose tasks, but
consistently underperform when exposed to highly specialized domains that
require deep cultural, linguistic, and subject-matter expertise. In particular,
traditional medical systems such as Ayurveda embody centuries of nuanced
textual and clinical knowledge that mainstream LLMs fail to accurately
interpret or apply. We introduce AyurParam-2.9B, a domain-specialized,
bilingual language model fine-tuned from Param-1-2.9B using an extensive,
expertly curated Ayurveda dataset spanning classical texts and clinical
guidance. AyurParam's dataset incorporates context-aware, reasoning, and
objective-style Q&A in both English and Hindi, with rigorous annotation
protocols for factual precision and instructional clarity. Benchmarked on
BhashaBench-Ayur, AyurParam not only surpasses all open-source
instruction-tuned models in its size class (1.5--3B parameters), but also
demonstrates competitive or superior performance compared to much larger
models. The results from AyurParam highlight the necessity for authentic domain
adaptation and high-quality supervision in delivering reliable, culturally
congruent AI for specialized medical knowledge.

</details>


### [30] [AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of Large Language Models](https://arxiv.org/abs/2511.02376)
*Aashray Reddy,Andrew Zagula,Nicholas Saban*

Main category: cs.CL

TL;DR: 作者提出了无需训练的自动多轮攻击框架AutoAdv，显著提升了在不同大模型上的jailbreaking攻击成功率，揭示现有模型单轮优化的安全策略在多轮交互下失效，强调多轮防御机制的紧迫需求。


<details>
  <summary>Details</summary>
Motivation: 目前，大型语言模型在面对jailbreaking攻击，即通过对抗性提示词诱导模型输出有害内容时仍然脆弱。现有评估大多只关注单轮交互，但真实世界中攻击通常是多轮、适应性强的对话。本文旨在填补多轮jailbreaking攻击自动化评测的方法空白。

Method: 提出AutoAdv框架，无需额外训练即可进行自动化多轮jailbreaking攻击。AutoAdv融合三种适应性机制：1）模式管理器学习成功攻击提升未来提示词；2）温度管理器根据失败情况动态调整采样参数；3）两阶段重写策略，先伪装有害请求再迭代优化。

Result: 在Llama-3.1-8B上，AutoAdv六轮内可达95%攻击成功率，比单轮提升24%。在GPT-4o-mini、Qwen3-235B、Mistral-7B等多个模型的实验表明，多轮攻击始终优于单轮。当前安全机制在多轮场景下均存在持续性漏洞。

Conclusion: 优化为单轮交互的模型安全方案无法在多轮对话中保持鲁棒性，亟需针对多轮交互设计防御机制以提升大型语言模型安全性。

Abstract: Large Language Models (LLMs) remain vulnerable to jailbreaking attacks where
adversarial prompts elicit harmful outputs, yet most evaluations focus on
single-turn interactions while real-world attacks unfold through adaptive
multi-turn conversations. We present AutoAdv, a training-free framework for
automated multi-turn jailbreaking that achieves up to 95% attack success rate
on Llama-3.1-8B within six turns a 24 percent improvement over single turn
baselines. AutoAdv uniquely combines three adaptive mechanisms: a pattern
manager that learns from successful attacks to enhance future prompts, a
temperature manager that dynamically adjusts sampling parameters based on
failure modes, and a two-phase rewriting strategy that disguises harmful
requests then iteratively refines them. Extensive evaluation across commercial
and open-source models (GPT-4o-mini, Qwen3-235B, Mistral-7B) reveals persistent
vulnerabilities in current safety mechanisms, with multi-turn attacks
consistently outperforming single-turn approaches. These findings demonstrate
that alignment strategies optimized for single-turn interactions fail to
maintain robustness across extended conversations, highlighting an urgent need
for multi-turn-aware defenses.

</details>


### [31] [Merging Continual Pretraining Models for Domain-Specialized LLMs: A Case Study in Finance](https://arxiv.org/abs/2511.02451)
*Kentaro Ueda,François Portet,Hirohiko Suwa,Keiichi Yasumoto*

Main category: cs.CL

TL;DR: 提出并评估了不同领域CPT专家模型的融合方法，验证了融合策略对于提升金融等专领域LLM能力的有效性，并给出了构建多技能模型的经验与建议。


<details>
  <summary>Details</summary>
Motivation: LLMs虽然在通用任务表现优异，但在金融等专业领域存在显著挑战。这些领域需要多样化的知识、数学推理和多语种处理能力。多技能训练成本高且不稳定，因此作者提出融合领域专用CPT专家模型作为解决方案。此前，针对监督微调模型融合已有研究，但CPT模型融合尚未被充分探索。

Method: 作者创建了来自金融、数学和日语领域的专家模型，并提出了三阶段评估框架：知识恢复、互补性和涌现性。采用三种模型融合方法（Task Arithmetic、TIES和DARE-TIES），在由8个公开数据集涵盖18项任务的金融基准上进行评测。分析了模型融合后的表现和产生跨领域技能的能力。

Result: 将专家与基础模型融合可恢复CPT过程中丢失的通用知识；多专家融合能提升性能，并有可能涌现出新的跨领域能力。Task Arithmetic性能强但对超参数敏感，TIES方法更为稳健。模型相似性与融合成功度相关，但涌现技能受更复杂因素影响。

Conclusion: 本研究首次系统性分析了领域专属CPT模型融合，提出评估框架，并为构建多技能LLM提供了可操作性指南。

Abstract: While LLMs excel at general tasks, they struggle in specialized domains like
finance, requiring diverse skills in domain knowledge, mathematical reasoning,
and multilingual processing. Merging domain-specific Continual Pre-training
(CPT) "experts" offers a practical alternative to costly and unstable
multi-skill training. However, unlike established Supervised Fine-Tuning (SFT)
model-based merging, CPT model merging remains largely unexplored. We address
this gap by creating financial LLMs from experts in finance, math, and
Japanese. We propose a three-stage evaluation focusing on knowledge recovery,
complementarity, and emergence, and assess three merging methods (Task
Arithmetic, TIES, and DARE-TIES) on a comprehensive financial benchmark curated
from 18 tasks across 8 established datasets. Results show that merging an
expert with its base model recovers general knowledge lost during CPT, while
merging experts improves performance and can yield emergent cross-domain
skills. Among the methods, Task Arithmetic performs strongly but is
hyperparameter-sensitive, whereas TIES is more robust. Our findings also
suggest that while model similarity correlates with merging success, emergent
skills depend on more complex factors. This work presents the first
foundational analysis of CPT model merging, establishing a principled framework
and providing clear guidance for building multi-skill LLMs from existing
assets.

</details>


### [32] [Prompting for Policy: Forecasting Macroeconomic Scenarios with Synthetic LLM Personas](https://arxiv.org/abs/2511.02458)
*Giulia Iadisernia,Carolina Camassa*

Main category: cs.CL

TL;DR: 本文发现，GPT-4o在宏观经济预测上能匹敌人类专家，加人人设提示不提升预测水平，可忽略该过程以节省资源。提示词多样化并未明显改善模型表现，模型输出远比人类专家共识更趋同质化。


<details>
  <summary>Details</summary>
Motivation: 探讨在宏观经济预测任务中，基于人格化提示（persona-based prompting）是否能提升大型语言模型（LLM）的预测准确性。鉴于LLM在专业领域应用中的迅速发展，作者希望了解人格化描述能否成为提升模型性能的有效方法。

Method: 使用PersonaHub语料库中的2,368个经济相关角色，通过人格化提示在GPT-4o中模拟欧洲央行专业预测者调查的50个季度（2013-2025）。分别对四个目标变量（HICP、核心HICP、GDP增长、失业率）和四个预测时间跨度进行比较，同时与无角色描述的100个基线预测结果进行对比，以剥离人格化提示的实际效应。

Result: GPT-4o与人类专家在预测准确性上非常接近，尽管差异在统计层面显著，但实际影响较小。GPT-4o在2024-2025年未见样本数据上的准确性依然具有竞争力。此外，消融实验表明，加入人格化描述并未给预测带来实质性优势，表明可省略该步骤以节省算力成本且不影响准确性。不同提示词下的模型预测结果异质性远低于人类专家小组。

Conclusion: GPT-4o在宏观经济预测中能在有相关背景数据的情况下达到与人类专家相近的准确性，且无需复杂的人设提示，提示多样化并未改进预测效果，反而模型输出高度同质化。对于实际应用，可以省略人设提示以降低计算成本。

Abstract: We evaluate whether persona-based prompting improves Large Language Model
(LLM) performance on macroeconomic forecasting tasks. Using 2,368
economics-related personas from the PersonaHub corpus, we prompt GPT-4o to
replicate the ECB Survey of Professional Forecasters across 50 quarterly rounds
(2013-2025). We compare the persona-prompted forecasts against the human
experts panel, across four target variables (HICP, core HICP, GDP growth,
unemployment) and four forecast horizons. We also compare the results against
100 baseline forecasts without persona descriptions to isolate its effect. We
report two main findings. Firstly, GPT-4o and human forecasters achieve
remarkably similar accuracy levels, with differences that are statistically
significant yet practically modest. Our out-of-sample evaluation on 2024-2025
data demonstrates that GPT-4o can maintain competitive forecasting performance
on unseen events, though with notable differences compared to the in-sample
period. Secondly, our ablation experiment reveals no measurable forecasting
advantage from persona descriptions, suggesting these prompt components can be
omitted to reduce computational costs without sacrificing accuracy. Our results
provide evidence that GPT-4o can achieve competitive forecasting accuracy even
on out-of-sample macroeconomic events, if provided with relevant context data,
while revealing that diverse prompts produce remarkably homogeneous forecasts
compared to human panels.

</details>


### [33] [Smart-Hiring: An Explainable end-to-end Pipeline for CV Information Extraction and Job Matching](https://arxiv.org/abs/2511.02537)
*Kenza Khelkhal,Dihia Lanasri*

Main category: cs.CL

TL;DR: 本文提出了自动分析简历与职位描述、减少人工偏见与工作量的NLP系统，在实际数据上展现出高准确率与可解释性，为智能招聘迈出重要一步。


<details>
  <summary>Details</summary>
Motivation: 传统的招聘过程往往需要人工筛选大量简历，耗时耗力，容易出错且存在人为偏见。因此，亟需一种自动化且高效的解决方法以提升招聘质量和效率。

Method: 提出了名为Smart-Hiring的端到端NLP流程，包括文档解析、命名实体识别和上下文文本嵌入技术。该系统将简历和职位描述编码到同一向量空间，通过计算相似度实现候选人与职位的语义匹配，具备模块化和可解释性。

Result: 在覆盖多个职业领域的真实简历和职位描述数据集上实验，系统展示出较强的鲁棒性和可行性，匹配准确率具有竞争力，同时保证了决策过程的高度可解释性和透明度。

Conclusion: Smart-Hiring为招聘分析提供了一个可扩展、实用的NLP框架，展现了消除偏见、公平建模和大规模自动化招聘的潜力。

Abstract: Hiring processes often involve the manual screening of hundreds of resumes
for each job, a task that is time and effort consuming, error-prone, and
subject to human bias. This paper presents Smart-Hiring, an end-to-end Natural
Language Processing (NLP) pipeline de- signed to automatically extract
structured information from unstructured resumes and to semantically match
candidates with job descriptions. The proposed system combines document
parsing, named-entity recognition, and contextual text embedding techniques to
capture skills, experience, and qualifications. Using advanced NLP technics,
Smart-Hiring encodes both resumes and job descriptions in a shared vector space
to compute similarity scores between candidates and job postings. The pipeline
is modular and explainable, allowing users to inspect extracted entities and
matching rationales. Experiments were conducted on a real-world dataset of
resumes and job descriptions spanning multiple professional domains,
demonstrating the robustness and feasibility of the proposed approach. The
system achieves competitive matching accuracy while preserving a high degree of
interpretability and transparency in its decision process. This work introduces
a scalable and practical NLP frame- work for recruitment analytics and outlines
promising directions for bias mitigation, fairness-aware modeling, and
large-scale deployment of data-driven hiring solutions.

</details>


### [34] [The Analysis of Lexical Errors in Machine Translation from English into Romanian](https://arxiv.org/abs/2511.02587)
*Angela Stamatie*

Main category: cs.CL

TL;DR: 本研究分析了230篇官方及医学类新冠相关文本在谷歌翻译英译罗时的词汇错误，指出其词汇选择问题，并为机器翻译质量提升建议改进方案。


<details>
  <summary>Details</summary>
Motivation: 鉴于涉疫官方和医学信息准确性的高度要求，以及机器翻译在实际应用中的不足，亟需分析并提升其词汇选择和减少翻译错误。

Method: 通过收集230篇与新冠相关、官方及医学性信息文本，分析谷歌翻译英译罗的词汇错误类型与分布。

Result: 揭示了谷歌翻译在医学和官方信息翻译中存在明显的词汇错误，通过分析这些错误为改进机器翻译系统提供了实践依据。

Conclusion: 研究强调了谷歌翻译在英语到罗马尼亚语医学与官方信息翻译上的词汇错误，表明词汇选择改进对提升机器翻译质量至关重要。

Abstract: The research explores error analysis in the performance of translating by
Machine Translation from English into Romanian, and it focuses on lexical
errors found in texts which include official information, provided by the World
Health Organization (WHO), the Gavi Organization, by the patient information
leaflet (the information about the active ingredients of the vaccines or the
medication, the indications, the dosage instructions, the storage instructions,
the side effects and warning, etc.). All of these texts are related to Covid-19
and have been translated by Google Translate, a multilingual Machine
Translation that was created by Google. In the last decades, Google has
actively worked to develop a more accurate and fluent automatic translation
system. This research, specifically focused on improving Google Translate, aims
to enhance the overall quality of Machine Translation by achieving better
lexical selection and by reducing errors. The investigation involves a
comprehensive analysis of 230 texts that have been translated from English into
Romanian.

</details>


### [35] [Next Token Knowledge Tracing: Exploiting Pretrained LLM Representations to Decode Student Behaviour](https://arxiv.org/abs/2511.02599)
*Max Norris,Kobi Gal,Sahan Bulathwela*

Main category: cs.CL

TL;DR: 该论文提出一种融合大语言模型的知识追踪新方法，通过文本序列化学生历史和问题内容，显著提升KT预测效果，并在新问题和新用户场景下具备更强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有学生知识追踪（KT）模型通常忽略了问题文本这一重要教学习得信息源，限制了个性化预测的能力，因此有必要探索将问题文本纳入KT以提升模型表现。

Method: 提出了一种新的KT方法——Next Token Knowledge Tracing（NTKT），将KT任务转化为预训练大语言模型（LLM）上的下一个token预测，同时把学生历史和问题内容都表示为文本序列，让LLM能够同时学习行为和语言模式。

Result: NTKT在多组实验中相比现有最优神经KT模型表现出显著提升，尤其在冷启动问题和新用户上的泛化性能更优。

Conclusion: 问题内容对于知识追踪任务至关重要，利用预训练LLM表达能够更有效地学习学生知识，实现更优的个性化学习预测。

Abstract: Modelling student knowledge is a key challenge when leveraging AI in
education, with major implications for personalised learning. The Knowledge
Tracing (KT) task aims to predict how students will respond to educational
questions in learning environments, based on their prior interactions. Existing
KT models typically use response correctness along with metadata like skill
tags and timestamps, often overlooking the question text, which is an important
source of pedagogical insight. This omission poses a lost opportunity while
limiting predictive performance. We propose Next Token Knowledge Tracing
(NTKT), a novel approach that reframes KT as a next-token prediction task using
pretrained Large Language Models (LLMs). NTKT represents both student histories
and question content as sequences of text, allowing LLMs to learn patterns in
both behaviour and language. Our series of experiments significantly improves
performance over state-of-the-art neural KT models and generalises much better
to cold-start questions and users. These findings highlight the importance of
question content in KT and demonstrate the benefits of leveraging pretrained
representations of LLMs to model student learning more effectively.

</details>


### [36] [CGES: Confidence-Guided Early Stopping for Efficient and Accurate Self-Consistency](https://arxiv.org/abs/2511.02603)
*Ehsan Aghazadeh,Ahmad Ghasemi,Hedyeh Beyhaghi,Hossein Pishro-Nik*

Main category: cs.CL

TL;DR: 该文提出了利用置信信号引导自适应采样停止的新方法CGES，可在保证模型预测准确性的前提下，显著减少模型调用次数，具有理论与实验优势。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在测试阶段常常进行多次查询，并通过多数投票的方式汇总预测结果。然而，这种自洽策略需要固定次数的模型调用，并且在正确答案罕见时效果不佳。

Method: 作者提出了Confidence-Guided Early Stopping（CGES）方法。这是一种贝叶斯框架，基于token概率或奖励模型推断出的置信信号，对候选答案形成后验分布，并在某个候选的后验质量超过阈值时自适应地停止采样。该方法兼容理想校准置信度和现实中的噪声置信信号，并提供理论保证。

Result: 在五个推理基准测试中，CGES将平均模型调用次数减少约69%（例如从16.0次减少到4.9次），且准确率与自洽策略相差不到0.06百分点。

Conclusion: CGES方法能够大幅降低查询次数，同时几乎不损失准确率，是多数投票自洽策略的有效替代。

Abstract: Large language models (LLMs) are often queried multiple times at test time,
with predictions aggregated by majority vote. While effective, this
self-consistency strategy (arXiv:2203.11171) requires a fixed number of calls
and can fail when the correct answer is rare. We introduce Confidence-Guided
Early Stopping (CGES), a Bayesian framework that forms posteriors over
candidate answers using scalar confidence signals derived from token
probabilities or reward models. CGES adaptively halts sampling once the
posterior mass of a candidate exceeds a threshold. We provide theoretical
guarantees for both perfectly calibrated confidences and realistic noisy
confidence signals. Across five reasoning benchmarks, CGES reduces the average
number of model calls by about 69 percent (for example, from 16.0 to 4.9) while
matching the accuracy of self-consistency within 0.06 percentage points.

</details>


### [37] [The Realignment Problem: When Right becomes Wrong in LLMs](https://arxiv.org/abs/2511.02623)
*Aakash Sen Sharma,Debdeep Sanyal,Vivek Srivastava,Shirish Karande,Murari Mandal*

Main category: cs.CL

TL;DR: 论文针对LLMs因社会规范变化频繁带来的“对齐-现实差距”问题，提出TRACE框架，以程序化、精准的方式调整模型偏好，实现高效、动态的模型重新对齐，并在多个模型和实际基准上验证了效果，推动了LLM安全和持续部署的进程。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）的人类价值对齐，存在模型静态、易破裂且维护成本高等问题，难以适应不断变化的社会规范和政策，造成“对齐-现实差距”（Alignment-Reality Gap）。

Method: 提出了TRACE框架，将重新对齐视为程序化的政策应用问题。TRACE能够筛选与最新政策冲突的偏好数据，通过对齐影响分数精确定位高冲突点，并以混合优化方式反转、丢弃或保留偏好，确保模型性能，避免大规模注释或暴力式卸载的弊端。

Result: TRACE在多种主流模型（如Qwen2.5-7B、Gemma-2-9B、Llama-3.1-8B）和合成基准测试及PKU-SafeRLHF数据集上进行了政策变化下实证评估。结果表明，不损失通用能力的前提下，TRACE能有效施加新原则，实现稳健的模型重新对齐。

Conclusion: TRACE提供了一种可扩展、动态且经济高效的LLM持续对齐新范式，为负责任和可持续的AI部署奠定基础。

Abstract: The alignment of Large Language Models (LLMs) with human values is central to
their safe deployment, yet current practice produces static, brittle, and
costly-to-maintain models that fail to keep pace with evolving norms and
policies. This misalignment, which we term the Alignment-Reality Gap, poses a
growing challenge for reliable long-term use. Existing remedies are inadequate:
large-scale re-annotation is economically prohibitive, and standard unlearning
methods act as blunt instruments that erode utility rather than enable precise
policy updates. We introduce TRACE (Triage and Re-align by Alignment Conflict
Evaluation), a framework for principled unlearning that reconceives
re-alignment as a programmatic policy application problem. TRACE
programmatically triages existing preference data against a new policy,
identifies high-impact conflicts via a alignment impact score, and applies a
hybrid optimization that cleanly inverts, discards, or preserves preferences
while safeguarding model performance. Empirical results show that TRACE
achieves robust re-alignment across diverse model families (Qwen2.5-7B,
Gemma-2-9B, Llama-3.1-8B). On both synthetic benchmarks and the PKU-SafeRLHF
dataset under complex policy shift, TRACE enforces new principles without
degrading general capabilities. Our work establishes a scalable, dynamic, and
cost-effective paradigm for maintaining LLM alignment, providing a foundation
for sustainable and responsible AI deployment.

</details>


### [38] [Understanding New-Knowledge-Induced Factual Hallucinations in LLMs: Analysis, Solution, and Interpretation](https://arxiv.org/abs/2511.02626)
*Renfei Dang,Peng Hu,Changjiang Gao,Shujian Huang*

Main category: cs.CL

TL;DR: 引入新知识训练大语言模型会显著增加事实幻觉，特别是针对某类知识的高度陌生性。本研究揭示了幻觉发生机制，并提出KnownPatch方法通过补充少量已知知识有效缓解这一问题，同时提升模型注意力分布和任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究尚未深入探讨大模型引入新知识后产生情报幻觉的具体表现与机制，本研究旨在分析其成因并寻求缓解方案。

Method: 设计了受控数据集Biography-Reasoning，在多个知识类型和两类任务（问答与知识推理）下细粒度分析幻觉现象及其机制，并通过注意力机制分析验证其影响。提出了KnownPatch方法，在训练后期引入少量已知知识以减少新知识带来的负面影响。

Result: 发现对某一知识类型的新知识陌生性比总体新知识比例更能导致模型幻觉；幻觉倾向可在问答任务中扩散至其他知识类型。KnownPatch方法有效改善了模型注意力分配，减少幻觉并提升问答表现。

Conclusion: 通过在训练后阶段加入少量已知知识样本的方法KnownPatch，能有效缓解因引入新知识而导致的大模型虚假信息（factual hallucinations）问题，并提升模型性能。

Abstract: Previous studies show that introducing new knowledge during large language
models (LLMs) fine-tuning can lead to the generation of erroneous output when
tested on known information, thereby triggering factual hallucinations.
However, existing studies have not deeply investigated the specific
manifestations and underlying mechanisms of these hallucinations. Our work
addresses this gap by designing a controlled dataset Biography-Reasoning, and
conducting a fine-grained analysis across multiple knowledge types and two task
types, including knowledge question answering (QA) and knowledge reasoning
tasks. We find that when fine-tuned on a dataset in which a specific knowledge
type consists entirely of new knowledge, LLMs exhibit significantly increased
hallucination tendencies. This suggests that the high unfamiliarity of a
particular knowledge type, rather than the overall proportion of new knowledge,
is a stronger driver of hallucinations, and these tendencies can even affect
other knowledge types in QA tasks. To mitigate such factual hallucinations, we
propose KnownPatch, which patches a small number of known knowledge samples in
the later stages of training, effectively alleviating new-knowledge-induced
hallucinations. Through attention analysis, we find that learning new knowledge
reduces the model's attention to key entities in the question, thus causing
excessive focus on the surrounding context, which may increase the risk of
hallucination. Moreover, the attention pattern can propagate to similar
contexts, facilitating the spread of hallucinations to textually similar
questions. Our method effectively mitigates the disruption of new knowledge
learning to the model's attention on key entities, accompanied by improved
performance.

</details>


### [39] [Optimal Singular Damage: Efficient LLM Inference in Low Storage Regimes](https://arxiv.org/abs/2511.02681)
*Mohammadsajad Alipour,Mohammad Mohammadi Amiri*

Main category: cs.CL

TL;DR: 本文提出了一种结合低秩近似和选择性稀疏化的新方法，有效提升了微调参数存储效率，同时在同样存储条件下精度优于传统方案。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）越来越广泛地应用于各类场景，但由于其规模巨大，存储和处理能力仅限于少数资源充足的组织。即使是针对具体任务微调后的模型，也面临着存储难题，因此急需提高微调模型参数存储的效率。

Method: 本文通过分析微调后的参数更新，发现这些更新具有低秩和稀疏性。本文提出了一种新的方法——optimal singular damage，通过对低秩近似参数进行选择性稀疏化，利用奇异向量的重要性排序，保留对模型效果影响最大的组分，提升存储效率。

Result: 通过大量实验验证，采用该方法后，在相同的存储预算下，能够显著提升存储效率，并且模型精度高于仅使用低秩近似或稀疏化的方法。

Conclusion: 本文提出的方法可以在不损失模型表现的前提下，大幅提升微调大语言模型参数的存储效率，为模型部署和应用带来的存储压力提供解决思路。

Abstract: Large language models (LLMs) are increasingly prevalent across diverse
applications. However, their enormous size limits storage and processing
capabilities to a few well-resourced stakeholders. As a result, most
applications rely on pre-trained LLMs, fine-tuned for specific tasks. However,
even storing the fine-tuned versions of these models remains a significant
challenge due to the wide range of tasks they address. Recently, studies show
that fine-tuning these models primarily affects a small fraction of parameters,
highlighting the need for more efficient storage of fine-tuned models. This
paper focuses on efficient storage of parameter updates in pre-trained models
after fine-tuning. To address this challenge, we leverage the observation that
fine-tuning updates are both low-rank and sparse, which can be utilized for
storage efficiency. However, using only low-rank approximation or
sparsification may discard critical singular components that enhance model
expressivity. We first observe that given the same memory budget, sparsified
low-rank approximations with larger ranks outperform standard low-rank
approximations with smaller ranks. Building on this, we propose our method,
optimal singular damage, that selectively sparsifies low-rank approximated
updates by leveraging the interleaved importance of singular vectors, ensuring
that the most impactful components are retained. We demonstrate through
extensive experiments that our proposed methods lead to significant storage
efficiency and superior accuracy within the same memory budget compared to
employing the low-rank approximation or sparsification individually.

</details>


### [40] [PragExTra: A Multilingual Corpus of Pragmatic Explicitation in Translation](https://arxiv.org/abs/2511.02721)
*Doreen Osmelak,Koel Dutta Chowdhury,Uliana Sentsova,Cristina España-Bonet,Josef van Genabith*

Main category: cs.CL

TL;DR: 本文提出并构建了首个多语种翻译显化语料库PragExTra，以及自动检测框架，对8种语言对进行了系统研究。结果显示主动学习能显著提升显化检测效果，并为建设更具文化意识的机器翻译系统提供了工具和数据基础。


<details>
  <summary>Details</summary>
Motivation: 翻译过程中，译者常常需要为不同文化背景的读者补充隐含信息，这一现象被称为“语用显化”。虽然翻译理论对其有较多讨论，但在计算建模方面却研究甚少。

Method: 本文提出了PragExTra，这是首个针对语用显化的多语言语料库及检测框架，涵盖8种语言对，并利用TED-Multi和Europarl数据，结合主动学习和人工标注来筛选和精炼显化实例。

Result: 通过主动学习方法，将分类器准确率提升了7-8个百分点，最高达到0.88的准确率和0.82的F1值。实体和系统级别的显化最为常见。

Conclusion: PragExTra语料库和框架证明了语用显化是一种可度量、可跨语言研究的现象，并为未来文化敏感的机器翻译研究奠定了基础。

Abstract: Translators often enrich texts with background details that make implicit
cultural meanings explicit for new audiences. This phenomenon, known as
pragmatic explicitation, has been widely discussed in translation theory but
rarely modeled computationally. We introduce PragExTra, the first multilingual
corpus and detection framework for pragmatic explicitation. The corpus covers
eight language pairs from TED-Multi and Europarl and includes additions such as
entity descriptions, measurement conversions, and translator remarks. We
identify candidate explicitation cases through null alignments and refined
using active learning with human annotation. Our results show that entity and
system-level explicitations are most frequent, and that active learning
improves classifier accuracy by 7-8 percentage points, achieving up to 0.88
accuracy and 0.82 F1 across languages. PragExTra establishes pragmatic
explicitation as a measurable, cross-linguistic phenomenon and takes a step
towards building culturally aware machine translation. Keywords: translation,
multilingualism, explicitation

</details>


### [41] [AI Diffusion in Low Resource Language Countries](https://arxiv.org/abs/2511.02752)
*Amit Misra,Syed Waqas Zamir,Wassim Hamidouche,Inbal Becker-Reshef,Juan Lavista Ferres*

Main category: cs.CL

TL;DR: 前沿大语言模型在低资源语言国家表现不佳，导致这些国家AI用户比例低20%，语言障碍是AI普及的重要阻碍因素。


<details>
  <summary>Details</summary>
Motivation: 尽管全球人工智能（AI）扩散速度极快，但在不同地区的采用情况存在不均衡，尤其是低资源语言国家（LRLCs）采用较少。现有前沿大语言模型（LLMs）在低资源语言上的表现较差，作者怀疑这影响了AI在这些国家的实用性和普及速度。

Method: 作者采用加权回归模型，剥离语言效应与社会经济及人口因素的影响，分析低资源语言国家的AI用户比例。

Result: 研究发现，低资源语言国家的AI用户比例大约比其基线低20%。

Conclusion: 语言可及性是AI公平扩散的显著且独立的障碍。

Abstract: Artificial intelligence (AI) is diffusing globally at unprecedented speed,
but adoption remains uneven. Frontier Large Language Models (LLMs) are known to
perform poorly on low-resource languages due to data scarcity. We hypothesize
that this performance deficit reduces the utility of AI, thereby slowing
adoption in Low-Resource Language Countries (LRLCs). To test this, we use a
weighted regression model to isolate the language effect from socioeconomic and
demographic factors, finding that LRLCs have a share of AI users that is
approximately 20% lower relative to their baseline. These results indicate that
linguistic accessibility is a significant, independent barrier to equitable AI
diffusion.

</details>


### [42] [Controlling Performance and Budget of a Centralized Multi-agent LLM System with Reinforcement Learning](https://arxiv.org/abs/2511.02755)
*Bowen Jin,TJ Collins,Donghan Yu,Mert Cemri,Shenao Zhang,Mengyu Li,Jay Tang,Tian Qin,Zhiyang Xu,Jiarui Lu,Guoli Yin,Jiawei Han,Zirui Wang*

Main category: cs.CL

TL;DR: 作者提出集中式多LLM协作方法CoRL，通过强化学习控制专家模型选择，实现了高效、可控的推理成本，同时在多个任务和预算设定下性能优异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在不同领域各有优势，但推理成本不一。这促使研究者设计多模型协作系统，以期高效协作、平衡性能与成本。现有方案多为去中心化框架，推理成本高且难以控制。

Method: 作者提出一种集中式多LLM框架，由一个控制器LLM根据任务和预算在专家模型池中选择合适的模型进行协作。该协调问题被建模为带有双重目标（最大化性能、最小化成本）的强化学习任务。提出了CoRL强化学习框架，在多预算环境下优化性能与成本的权衡。

Result: 在四个不同的基准测试上，CoRL框架在高预算下超越了最优单一专家LLM，在低预算模式下也能保持较强性能，显示了集中式协调方法在可扩展与成本效益上的优越性。

Conclusion: 集中式多LLM协作系统（如CoRL）能有效权衡推理性能与成本，实现多预算下的高效协作，是构建可控成本多智能体系统的有效新范式。

Abstract: Large language models (LLMs) exhibit complementary strengths across domains
and come with varying inference costs, motivating the design of multi-agent LLM
systems where specialized models collaborate efficiently. Existing approaches
predominantly rely on decentralized frameworks, which invoke multiple LLMs for
every input and thus lead to substantial and uncontrolled inference costs. In
this work, we introduce a centralized multi-LLM framework, where a controller
LLM selectively coordinates a pool of expert models in a cost-efficient and
cost-controllable manner. We formulate this coordination problem as
reinforcement learning with dual objectives: maximizing task performance while
minimizing the overall inference cost. In addition, we expect the multi-agent
system to have adapted behavior with different budget conditions during
inference. To this end, we propose CoRL, a reinforcement learning framework
that optimizes the performance cost trade-off in a controllable multi-budget
setting. Experiments on four diverse benchmarks demonstrate that CoRL enables a
single system to surpass the best expert LLM under high-budget settings, while
maintaining strong performance in more economical low-budget modes,
highlighting the effectiveness of centralized coordination for scalable and
cost-efficient multi-agent LLM systems.

</details>


### [43] [Beyond Single Embeddings: Capturing Diverse Targets with Multi-Query Retrieval](https://arxiv.org/abs/2511.02770)
*Hung-Ting Chen,Xiang Liu,Shauli Ravfogel,Eunsol Choi*

Main category: cs.CL

TL;DR: 本文提出了自回归多嵌入检索器AMER，能生成多个查询向量显著提升多模态检索性能，在多个数据集上取得优于传统单向量模型的结果。


<details>
  <summary>Details</summary>
Motivation: 传统文本检索器通常只生成一个查询向量来检索相关文档，但实际情况下，一个查询的相关文档分布可能是多模态的，即表示查询的多种解释。这种情况下，单一查询向量难以覆盖所有相关文档。

Method: 提出了自回归多嵌入检索器（AMER）架构，该模型以自回归方式生成多个查询向量，并利用这些查询向量同时在语料库中检索文档。

Result: 在合成向量数据上，AMER能完美捕捉多目标分布，性能比单嵌入模型提升了4倍。在真实多答案检索数据集上微调并评估，AMER在两组数据集上相较单一嵌入基线分别带来了4%和21%的相对提升；对目标文档分布不相似的子数据集，性能提升更为显著。

Conclusion: 多查询向量检索器（AMER）能够更好地处理多模式分布的检索任务，尤其在目标文档分布差异较大时效果突出，展示了今后多向量检索方向的潜力。

Abstract: Most text retrievers generate \emph{one} query vector to retrieve relevant
documents. Yet, the conditional distribution of relevant documents for the
query may be multimodal, e.g., representing different interpretations of the
query. We first quantify the limitations of existing retrievers. All retrievers
we evaluate struggle more as the distance between target document embeddings
grows. To address this limitation, we develop a new retriever architecture,
\emph{A}utoregressive \emph{M}ulti-\emph{E}mbedding \emph{R}etriever (AMER).
Our model autoregressively generates multiple query vectors, and all the
predicted query vectors are used to retrieve documents from the corpus. We show
that on the synthetic vectorized data, the proposed method could capture
multiple target distributions perfectly, showing 4x better performance than
single embedding model. We also fine-tune our model on real-world multi-answer
retrieval datasets and evaluate in-domain. AMER presents 4 and 21\% relative
gains over single-embedding baselines on two datasets we evaluate on.
Furthermore, we consistently observe larger gains on the subset of dataset
where the embeddings of the target documents are less similar to each other. We
demonstrate the potential of using a multi-query vector retriever and open up a
new direction for future work.

</details>


### [44] [MemSearcher: Training LLMs to Reason, Search and Manage Memory via End-to-End Reinforcement Learning](https://arxiv.org/abs/2511.02805)
*Qianhao Yuan,Jie Lou,Zichao Li,Jiawei Chen,Yaojie Lu,Hongyu Lin,Le Sun,Debing Zhang,Xianpei Han*

Main category: cs.CL

TL;DR: 该论文提出一种紧凑记忆管理的检索智能体MemSearcher，结合多上下文强化学习优化，显著提升了准确率和效率，3B参数版本甚至超越7B基线，为智能体在多轮检索任务中的应用提供了高效解决方案。代码已开源。


<details>
  <summary>Details</summary>
Motivation: 当前主流的检索智能体在与大模型（LLM）交互时，将整个对话历史拼接进上下文，虽然完整保留了信息，但会导致上下文过长、噪声大，计算和内存开销大。而只使用当前轮对话则虽节约资源，但会丢失关键信息。这种权衡限制了检索智能体的可扩展性。

Method: 提出了一种名为MemSearcher的智能体工作流，迭代地维护一份精简的记忆，将当前轮信息与记忆融合使用。每轮中，MemSearcher将用户问题与记忆结合生成推理轨迹，执行检索并更新记忆，保证仅保留任务必需的信息，从而保持稳定的上下文长度，提高效率同时不损失准确性。为进一步优化流程，作者提出了多上下文GRPO（multi-context GRPO）强化学习框架，能联合优化推理、检索策略与记忆管理。其通过在不同上下文下采样一组轨迹，将轨迹级优势传播到所有对话中，实现端到端优化。

Result: 在相同数据集上，MemSearcher在七个公开基准上相对主流方法显著提升：Qwen2.5-3B-Instruct提升11%，Qwen2.5-7B-Instruct提升12%。尤其是3B版本的MemSearcher超越了7B基线模型，展示了在信息完整性与效率之间取得平衡可实现更高准确率和更低算力消耗。

Conclusion: MemSearcher通过紧凑记忆管理和强化学习联合优化方案，在保证信息充分的基础上大幅提高检索效率和性能，且低参数模型可超越高参数基线，对于提升检索智能体的扩展性和实用性具有重大意义。

Abstract: Typical search agents concatenate the entire interaction history into the LLM
context, preserving information integrity but producing long, noisy contexts,
resulting in high computation and memory costs. In contrast, using only the
current turn avoids this overhead but discards essential information. This
trade-off limits the scalability of search agents. To address this challenge,
we propose MemSearcher, an agent workflow that iteratively maintains a compact
memory and combines the current turn with it. At each turn, MemSearcher fuses
the user's question with the memory to generate reasoning traces, perform
search actions, and update memory to retain only information essential for
solving the task. This design stabilizes context length across multi-turn
interactions, improving efficiency without sacrificing accuracy. To optimize
this workflow, we introduce multi-context GRPO, an end-to-end RL framework that
jointly optimize reasoning, search strategies, and memory management of
MemSearcher Agents. Specifically, multi-context GRPO samples groups of
trajectories under different contexts and propagates trajectory-level
advantages across all conversations within them. Trained on the same dataset as
Search-R1, MemSearcher achieves significant improvements over strong baselines
on seven public benchmarks: +11% on Qwen2.5-3B-Instruct and +12% on
Qwen2.5-7B-Instruct relative average gains. Notably, the 3B-based MemSearcher
even outperforms 7B-based baselines, demonstrating that striking a balance
between information integrity and efficiency yields both higher accuracy and
lower computational overhead. The code and models will be publicly available at
https://github.com/icip-cas/MemSearcher

</details>


### [45] [Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities](https://arxiv.org/abs/2511.02817)
*Amanda Bertsch,Adithya Pratapa,Teruko Mitamura,Graham Neubig,Matthew R. Gormley*

Main category: cs.CL

TL;DR: 提出Oolong长上下文推理基准，包含挑战性的分析和聚合任务。主流大模型表现不佳，准确率均低于50%。公开数据集和评测工具，推动模型对长文本推理能力的提升。


<details>
  <summary>Details</summary>
Motivation: 当前评测长上下文能力的方法多以检索任务为主，忽略了要求模型全局理解和推理的任务类型。作者希望填补这一空白，探索模型在复杂长文本推理上的真实能力。

Method: 该论文提出了Oolong基准，包括Oolong-synth（可控的自然化合成任务）和Oolong-real（真实世界对话数据），要求模型对大量文本片段进行原子级分析，并聚合分析结果来回答分布性问题。通过分类、计数及时序和用户关系推理，对当前大模型进行评测。

Result: 包括GPT-5、Claude-Sonnet-4、Gemini-2.5-Pro在128K文本长度下准确率低于50%，说明这些模型难以有效处理Oolong基准的挑战性任务。论文同时公开了数据集和评测框架。

Conclusion: 即使是最前沿的大模型，在Oolong基准上的表现也不理想，在128K长度下两种任务的准确率都低于50%。这表明现有模型在长上下文推理任务上仍有较大提升空间。

Abstract: As model context lengths continue to grow, concerns about whether models
effectively use the full context length have persisted. While several carefully
designed long-context evaluations have recently been released, these
evaluations tend to rely on retrieval from one or more sections of the context,
which allows nearly all of the context tokens to be disregarded as noise. This
represents only one type of task that might be performed with long context. We
introduce Oolong, a benchmark of long-context reasoning tasks that require
analyzing individual chunks of text on an atomic level, and then aggregating
these analyses to answer distributional questions. Oolong is separated into two
task sets: Oolong-synth, a set of naturalistic synthetic tasks, where we can
easily ablate components of the reasoning problem; and Oolong-real, a
downstream setting which requires reasoning over real-world conversational
data. Oolong requires models to reason over large quantities of examples, to
perform both classification and counting in-context, and to reason over
temporal and user relations. Even frontier models struggle on Oolong, with
GPT-5, Claude-Sonnet-4, and Gemini-2.5-Pro all achieving less than 50% accuracy
on both splits at 128K. We release the data and evaluation harness for Oolong
to enable further development of models that can reason over large quantities
of text.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [46] [Fixed-parameter tractability and hardness for Steiner rooted and locally connected orientations](https://arxiv.org/abs/2511.02081)
*Kristóf Bérczi,Florian Hörsch,András Imolay,Tamás Schwarcz*

Main category: cs.DM

TL;DR: 论文研究了定根Steiner k-弧连通有向化问题的参数化复杂性，提出了以终端数t和连通度k为参数的固定参数可解（FPT）算法，并证明在k或t为输入时问题仍为NP难，获得了参数化意义下的最优结果。方法框架可推广到更广泛的有向化连通度问题，成果对网络设计和可靠性有重要应用价值。


<details>
  <summary>Details</summary>
Motivation: 该问题在网络设计和可靠性中具有重要意义，保证指定关键节点间的强鲁棒通信。经典算法可高效解决非定根情形，但定根Steiner连通问题复杂性更高，部分情况下为NP难。本文旨在系统分析该问题两参数k和t上的复杂性，并探讨其一般性推广。

Method: 通过参数化算法设计，给出关于关键节点数量t和连通度k的定根Steiner有向化问题的完整算法复杂性分析。提出一个固定参数可解算法，其时间复杂度为f(k,t)·n^{O(1)}。同时理论性证明：当k或t为输入时问题依然NP难，表明给出算法在参数化视角下已近乎最优。方法框架还推广到局部连通度需求的更一般有向化问题。

Result: 该问题对参数t和k为固定参数可解（FPT），即有算法在f(k,t)·n^{O(1)}时间内求解。进一步证明，只要k或t为输入，则问题仍NP难，说明获得的FPT结果已最优。框架可扩展到一类更一般的有向化与连通度问题，在参数“总需求”下同样FPT。

Conclusion: 本文系统刻画了定根Steiner k-弧连通有向化问题的参数化复杂性，提出了最优（参数化意义下）求解方法，且方法广泛适用于更一般的局部连通度有向化问题。研究为网络可靠性相关问题提供了理论基础与高效工具。

Abstract: Finding a Steiner strongly $k$-arc-connected orientation is particularly
relevant in network design and reliability, as it guarantees robust
communication between a designated set of critical nodes. Kir\'aly and Lau
(FOCS 2006) introduced a rooted variant, called the Steiner Rooted Orientation
problem, where one is given an undirected graph on $n$ vertices, a root vertex,
and a set of $t$ terminals. The goal is to find an orientation of the graph
such that the resulting directed graph is Steiner rooted $k$-arc-connected.
This problem generalizes several classical connectivity results in graph
theory, such as those on edge-disjoint paths and spanning-tree packings. While
the maximum $k$ for which a Steiner strongly $k$-arc-connected orientation
exists can be determined in polynomial time via Nash-Williams' orientation
theorem, its rooted counterpart is significantly harder: the problem is NP-hard
when both $k$ and $t$ are part of the input. In this work, we provide a
complete understanding of the problem with respect to these two parameters. In
particular, we give an algorithm that solves the problem in time $f(k,t)\cdot
n^{O(1)}$, establishing fixed-parameter tractability with respect to the number
of terminals $t$ and the target connectivity $k$. We further show that the
problem remains NP-hard if either $k$ or $t$ is treated as part of the input,
meaning that our algorithm is essentially optimal from a parameterized
perspective. Importantly, our results extend far beyond the Steiner setting:
the same framework applies to the more general orientation problem with local
connectivity requirements, establishing fixed-parameter tractability when
parameterized by the total demand and thereby covering a wide range of
arc-connectivity orientation problems.

</details>
