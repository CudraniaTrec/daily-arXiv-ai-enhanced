<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 7]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.CL](#cs.CL) [Total: 39]
- [cs.DM](#cs.DM) [Total: 1]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [A Verified Compiler for Quantum Simulation](https://arxiv.org/abs/2509.18583)
*Liyi Li,Fenfen An,Federico Zahariev,Zhi Xiang Chong,Amr Sabry,Mark Gordon*

Main category: cs.PL

TL;DR: 该论文提出了QBlue，一个基于第二量子化的形式化验证编译框架，用于量子哈密顿模拟。通过类型系统和端到端机械化证明，保障了编译器的安全和正确性，实现了数字和模拟量子电路的自动生成，是领域内首个全面验证的平台。


<details>
  <summary>Details</summary>
Motivation: 量子计算中的哈密顿模拟对于物理系统建模和解决复杂优化问题有重要应用。现有编译器多基于Pauli算符实现，导致可编程性受限，同时在整个编译流程中缺乏形式化正确性保证。

Method: 提出了QBlue——一个基于第二量子化形式主义的高级、形式化验证的编译框架。QBlue利用粒子的产生和湮灭算符描述量子系统，引入了类型系统以追踪粒子类型并强制Hermite结构，支持编译成数字和模拟量子电路，并通过Rocq证明框架对所有组件实现机械化验证。

Result: QBlue实现了哈密顿模拟的高层次表达，保证了编译流程的安全性和正确性，能生成多种平台的量子电路。它是首个实现第二量子化哈密顿模拟端到端验证的编译器。

Conclusion: QBlue显著提升了哈密顿模拟编译器的可编程性与正确性保障，推动了量子计算应用的可靠发展。

Abstract: Hamiltonian simulation is a central application of quantum computing, with
significant potential in modeling physical systems and solving complex
optimization problems. Existing compilers for such simulations typically focus
on low-level representations based on Pauli operators, limiting programmability
and offering no formal guarantees of correctness across the compilation
pipeline. We introduce QBlue, a high-level, formally verified framework for
compiling Hamiltonian simulations. QBlue is based on the formalism of second
quantization, which provides a natural and expressive way to describe quantum
particle systems using creation and annihilation operators. To ensure safety
and correctness, QBlue includes a type system that tracks particle types and
enforces Hermitian structure. The framework supports compilation to both
digital and analog quantum circuits and captures multiple layers of semantics,
from static constraints to dynamic evolution. All components of QBlue,
including its language design, type system, and compilation correctness, are
fully mechanized in the Rocq proof framework, making it the first end-to-end
verified compiler for second-quantized Hamiltonian simulation.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [CoRaCMG: Contextual Retrieval-Augmented Framework for Commit Message Generation](https://arxiv.org/abs/2509.18337)
*Bo Xiong,Linghao Zhang,Chong Wang,Peng Liang*

Main category: cs.SE

TL;DR: 本论文提出一种名为CoRaCMG的检索增强型提交消息生成方法，通过引入历史示例，使LLM能够生成更加精准、高质量的提交消息。实验证明，该方法能显著提升主流LLM性能，尤其在学习项目特定写作风格和术语方面效果突出。


<details>
  <summary>Details</summary>
Motivation: 现有的自动生成提交消息（CMG）技术虽有进展，但LLM生成的提交消息效果有限，常常质量不高、信息不全。为提升生成效果，需利用项目历史数据，提高LLM生成消息的准确性和信息量。

Method: 提出CoRaCMG框架，分三步：1）检索相似的代码变更及其对应消息对；2）将检索到的信息与当前查询变更组合成结构化输入；3）引导LLM生成更优质、个性化提交消息，通过示例学习项目术语和风格。

Result: 用多种LLM（闭源GPT、开源DeepSeek）实验，CoRaCMG大幅提升四项指标（BLEU、Rouge-L、METEOR、CIDEr），如DeepSeek-R1在增添单一检索示例时，BLEU提升76%，CIDEr提升71%。GPT-4o单例增长率最高，BLEU提升89%。多于三个示例提升趋于平缓，提升原因在于模型更好地捕捉了项目术语与写作风格。

Conclusion: 检索增强的提示策略能有效提升LLM在提交消息生成任务中的表现，能进一步学习和复用人类编写的项目专属风格与术语，解决了自动CMG效果不佳的问题。

Abstract: Commit messages play a key role in documenting the intent behind code
changes. However, they are often low-quality, vague, or incomplete, limiting
their usefulness. Commit Message Generation (CMG) aims to automatically
generate descriptive commit messages from code diffs to reduce developers'
effort and improve message quality. Although recent advances in LLMs have shown
promise in automating CMG, their performance remains limited. This paper aims
to enhance CMG performance by retrieving similar diff-message pairs to guide
LLMs to generate commit messages that are more precise and informative. We
proposed CoRaCMG, a Contextual Retrieval-augmented framework for Commit Message
Generation, structured in three phases: (1) Retrieve: retrieving the similar
diff-message pairs; (2) Augment: combining them with the query diff into a
structured prompt; and (3) Generate: generating commit messages corresponding
to the query diff via LLMs. CoRaCMG enables LLMs to learn project-specific
terminologies and writing styles from the retrieved diff-message pairs, thereby
producing high-quality commit messages. We evaluated our method on various
LLMs, including closed-source GPT models and open-source DeepSeek models.
Experimental results show that CoRaCMG significantly boosts LLM performance
across four metrics (BLEU, Rouge-L, METEOR, and CIDEr). Specifically,
DeepSeek-R1 achieves relative improvements of 76% in BLEU and 71% in CIDEr when
augmented with a single retrieved example pair. After incorporating the single
example pair, GPT-4o achieves the highest improvement rate, with BLEU
increasing by 89%. Moreover, performance gains plateau after more than three
examples are used, indicating diminishing returns. Further analysis shows that
the improvements are attributed to the model's ability to capture the
terminologies and writing styles of human-written commit messages from the
retrieved example pairs.

</details>


### [3] [Reading Between the Lines: Scalable User Feedback via Implicit Sentiment in Developer Prompts](https://arxiv.org/abs/2509.18361)
*Daye Nam,Malgorzata Salawa,Satish Chandra*

Main category: cs.SE

TL;DR: 该论文提出用开发者提示语的情感分析来捕捉AI助手用户满意度，能发现比显式反馈多13倍的信号，对大规模开发者体验评估有实用价值。


<details>
  <summary>Details</summary>
Motivation: 现有的开发者满意度评估方法要么无法规模化（如用户调研），要么量化信号过于浅显或稀疏（如应用日志/内置评分），难以全面、可靠地反映真实用户体验。

Method: 通过对372名专业开发者的工业使用日志进行情感分析，挖掘开发者的提示语中蕴含的隐式满意度反馈，并与传统显式反馈进行对比。

Result: 情感分析可在约8%的交互中识别隐式满意度信号，这一识别率是显式反馈的13倍以上，同时采用现成情感分析工具也能保证较高准确率。

Conclusion: 利用情感分析技术可以比传统显式反馈获得更多且有效的开发者满意度信号，从而提升大规模评估对话式AI助手的可行性。

Abstract: Evaluating developer satisfaction with conversational AI assistants at scale
is critical but challenging. User studies provide rich insights, but are
unscalable, while large-scale quantitative signals from logs or in-product
ratings are often too shallow or sparse to be reliable. To address this gap, we
propose and evaluate a new approach: using sentiment analysis of developer
prompts to identify implicit signals of user satisfaction. With an analysis of
industrial usage logs of 372 professional developers, we show that this
approach can identify a signal in ~8% of all interactions, a rate more than 13
times higher than explicit user feedback, with reasonable accuracy even with an
off-the-shelf sentiment analysis approach. This new practical approach to
complement existing feedback channels would open up new directions for building
a more comprehensive understanding of the developer experience at scale.

</details>


### [4] [SC2Tools: StarCraft II Toolset and Dataset API](https://arxiv.org/abs/2509.18454)
*Andrzej Białecki,Piotr Białecki,Piotr Sowiński,Mateusz Budziak,Jan Gajewski*

Main category: cs.SE

TL;DR: SC2Tools是一个面向StarCraft 2及其它游戏数据处理的工具集，大幅降低数据处理难度，支持大规模数据集生成及标准化实验流程，为电竞领域研究提供了实用基础设施。


<details>
  <summary>Details</summary>
Motivation: 当前游戏与电竞领域因AI和机器学习的应用而迅速发展，但科学研究中的数据处理和工具开发门槛较高，限制了一部分研究者的参与。亟需简化工具以降低技术门槛。

Method: 开发了一套名为SC2Tools的工具集，内含多个可扩展子模块，支持数据处理及大规模数据集生成，并配备了PyTorch及PyTorch Lightning的API以便于数据访问。

Result: 利用SC2Tools工具集成功构建了迄今最大规模StarCraft 2赛事数据集，并提供了便捷的数据访问接口，部分工具还支持其它类型数据集创建。

Conclusion: 提出的SC2Tools工具集有效简化了数据收集、预处理和自定义代码开发流程，有助于促进更多研究者参与游戏和电竞领域，并为StarCraft 2实验流程标准化奠定基础。

Abstract: Computer games, as fully controlled simulated environments, have been
utilized in significant scientific studies demonstrating the application of
Reinforcement Learning (RL). Gaming and esports are key areas influenced by the
application of Artificial Intelligence (AI) and Machine Learning (ML) solutions
at scale. Tooling simplifies scientific workloads and is essential for
developing the gaming and esports research area.
  In this work, we present ``SC2Tools'', a toolset containing multiple
submodules responsible for working with, and producing larger datasets. We
provide a modular structure of the implemented tooling, leaving room for future
extensions where needed. Additionally, some of the tools are not StarCraft~2
exclusive and can be used with other types of data for dataset creation.
  The tools we present were leveraged in creating one of the largest
StarCraft~2 tournament datasets to date with a separate PyTorch and PyTorch
Lightning application programming interface (API) for easy access to the data.
  We conclude that alleviating the burden of data collection, preprocessing,
and custom code development is essential for less technically proficient
researchers to engage in the growing gaming and esports research area. Finally,
our solution provides some foundational work toward normalizing experiment
workflow in StarCraft~2

</details>


### [5] [Locking Down Science Gateways](https://arxiv.org/abs/2509.18548)
*Steven R Brandt,Max Morris,Patrick Diehl,Christopher Bowen,Jacob Tucker,Lauren Bristol,Golden G. Richard III*

Main category: cs.SE

TL;DR: 本文探讨了Linux新安全特性Landlock在科学网关中的应用，通过实验加固三款科学代码，并用Landlock替代用户认证，实现了更高效且安全的数据访问控制。


<details>
  <summary>Details</summary>
Motivation: Linux内核引入了Landlock功能，旨在增强应用程序安全性。科学网关应用在启动MPI时需要网络访问，但在读取用户参数文件之前，为了安全需要限制网络访问。本文旨在探索Landlock是否能有效增强科学代码的安全性。

Method: 研究者通过修改和加固三个成熟的科学代码：Einstein Toolkit、Octo-Tiger和FUKA，实验性地锁定和限制其资源访问。同时，他们实现了一个完全基于Landlock的FUKA科学网关，不再依赖用户认证来保证安全。

Result: 实验结果表明，Landlock可以有效地用于科学网关安全加固，并能够代替传统的用户认证机制，以资源访问控制提高整体安全性。

Conclusion: Landlock提供了一种可靠的安全机制，有助于科学代码运行中资源访问的动态限制，从而提升科学网关应用的安全水平。

Abstract: The most recent Linux kernels have a new feature for securing applications:
Landlock. Like Seccomp before it, Landlock makes it possible for a running
process to give up access to resources. For applications running as Science
Gateways, network access is required while starting up MPI, but for the sake of
security, it should be taken away prior to the reading of user-supplied
parameter files. We explore the usefulness of Landlock by modifying and locking
down three mature scientific codes: The Einstein Toolkit (a code that studies
the dynamics of relativistic astrophysics, e.g. neutron star collisions),
Octo-Tiger (a code for studying the dynamics of non-relativistic astrophysics,
e.g. white dwarfs), and FUKA (an initial data solver for relativistic codes).
Finally, we implement a fully-functioning FUKA science gateway that relies on
Landlock (instead of user authentication) for security.

</details>


### [6] [SR-Eval: Evaluating LLMs on Code Generation under Stepwise Requirement Refinement](https://arxiv.org/abs/2509.18808)
*Zexun Zhan,Shuzheng Gao,Ruida Hu,Cuiyun Gao*

Main category: cs.SE

TL;DR: 本文针对现实开发中逐步迭代的需求，提出SR-Eval基准，完整覆盖多回合、多粒度代码生成评测。实验证明，主流LLM在该场景下表现不佳，且提示方式影响显著，亟需更强的模型和策略。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型(LLMs)代码生成基准只关注静态、单回合任务，忽视了现实软件开发中需求逐步变化与迭代的流程。这种不匹配制约了对LLMs在真实开发场景下支持能力的理解。

Method: 提出SR-Eval基准，专门评估LLMs在逐步需求细化下的迭代式代码生成。该基准覆盖Python和Java的函数级和仓库级任务，采用多代理需求生成模拟开发过程，结合语义感知判别性测试用例生成，确保每回合评测具区分性和一致性。共包含443个多回合任务和1,857个问题。

Result: 在SR-Eval基准下，评测了11个代表性LLM和三种不同提示策略。结果显示，逐步需求细化下的迭代代码生成仍极具挑战，最优模型在函数级任务完成率仅22.67%，仓库级任务为20.00%。提示策略对性能影响显著。

Conclusion: 逐步需求细化场景下，当前LLMs在迭代代码生成能力远未满足实际需求，提示策略的改进也至关重要。

Abstract: Large language models (LLMs) have achieved remarkable progress in code
generation. However, existing benchmarks mainly formalize the task as a static,
single-turn problem, overlooking the stepwise requirement changes and iterative
workflows in real-world software development. This mismatch limits the
understanding of how well LLMs can support real-world development workflows.
Constructing such iterative benchmarks is challenging due to the lack of public
interaction traces and the difficulty of creating discriminative, turn-specific
test cases.
  To bridge this gap, we present SR-Eval, a benchmark specifically designed to
assess LLMs on iterative code generation under Stepwise requirements
Refinement. SR-Eval spans both function-level and repository-level tasks in
Python and Java, enabling fine-grained and progressive evaluation across
evolving requirements. The construction of SR-Eval follows a carefully designed
pipeline that first leverages a multi-agent-based requirement generation method
to simulate the development process and recover the multi-round interaction
process from final requirements, then employs a semantic-aware discriminative
test case generation component to ensure discriminative and consistent
evaluation at each turn. SR-Eval comprises 443 multi-turn tasks and 1,857
questions at both function and repository levels. Using SR-Eval, we evaluate 11
representative LLMs with three prompting strategies that simulate different
usage patterns. Results show that iterative code generation under stepwise
requirement refinement remains highly challenging: the best-performing model
achieves only 22.67% completion rate on function-level tasks and 20.00% on
repository-level tasks. We further observe that prompting strategies
substantially influence performance, highlighting the need for the development
of advanced methods.

</details>


### [7] [On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language](https://arxiv.org/abs/2509.19136)
*Sébastien Salva,Redha Taguelmimt*

Main category: cs.SE

TL;DR: 本文针对GUI应用的自然语言测试，分析LLM直接执行该类测试的可靠性与一致性问题，提出了加护栏的算法与评价指标。实验证明部分大模型如Llama 3.1 70B具备较高可用性，研究推动了NL测试向实用转变并提出未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 手写可执行测试脚本用于GUI应用验证成本高、维护难。自然语言测试用例结合LLMs有望降低成本并提升灵活性，但自然语言测试存在不一致性和不可靠性问题。

Method: 提出了一种配备护栏机制和专门智能体的算法，动态验证每一步测试的正确执行；设计了新指标衡量LLM的测试执行能力及一致性，并定义了弱不可靠度以量化可接受的执行环境。

Result: 在包括Meta Llama 3.1 70B等八个不同规模的LLM上进行了实验，Meta Llama 3.1 70B能以较高一致性（高于3-sigma水平）执行自然语言测试用例。

Conclusion: 现有LLM在GUI自然语言测试具有潜力但还有限制，尝试通过护栏机制和智能体增强可靠性与一致性，部分模型已达到工业可接受标准，并提供了工具和数据集支持实践。

Abstract: The use of natural language (NL) test cases for validating graphical user
interface (GUI) applications is emerging as a promising direction to manually
written executable test scripts, which are costly to develop and difficult to
maintain. Recent advances in large language models (LLMs) have opened the
possibility of the direct execution of NL test cases by LLM agents. This paper
investigates this direction, focusing on the impact on NL test case unsoundness
and on test case execution consistency. NL test cases are inherently unsound,
as they may yield false failures due to ambiguous instructions or unpredictable
agent behaviour. Furthermore, repeated executions of the same NL test case may
lead to inconsistent outcomes, undermining test reliability. To address these
challenges, we propose an algorithm for executing NL test cases with guardrail
mechanisms and specialised agents that dynamically verify the correct execution
of each test step. We introduce measures to evaluate the capabilities of LLMs
in test execution and one measure to quantify execution consistency. We propose
a definition of weak unsoundness to characterise contexts in which NL test case
execution remains acceptable, with respect to the industrial quality levels Six
Sigma. Our experimental evaluation with eight publicly available LLMs, ranging
from 3B to 70B parameters, demonstrates both the potential and current
limitations of current LLM agents for GUI testing. Our experiments show that
Meta Llama 3.1 70B demonstrates acceptable capabilities in NL test case
execution with high execution consistency (above the level 3-sigma). We provide
prototype tools, test suites, and results.

</details>


### [8] [An Empirical Study of Testing Practices in Open Source AI Agent Frameworks and Agentic Applications](https://arxiv.org/abs/2509.19185)
*Mohammed Mehedi Hasan,Hao Li,Emad Fallahzadeh,Gopi Krishnan Rajbahadur,Bram Adams,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 该论文首次系统分析了基础模型驱动AI Agent的测试实践，发现现有测试主要聚焦于确定性组件，对关键的Prompt等部分关注严重不足，呼吁行业加强新型测试方法与Prompt相关测试。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型驱动的AI Agent在各领域广泛应用，其非确定性和不可复现性带来了测试和质量保证的难题。当前的评测多为任务层面，开发者在开发过程中如何验证AI Agent内部正确性尚不清楚。该研究旨在填补此领域的知识空白。

Method: 对39个开源AI Agent框架和439个Agent应用进行大规模实证分析，归纳测试模式并将其与Agent架构组件关联，统计不同组件的测试分布情况。

Result: 共识别出十种测试模式，创新性Agent测试方法如DeepEval仅被采用1%，而传统模式如负面测试和成员测试被广泛用于应对基础模型的不确定性。测试主要集中在工具和工作流等确定性组件（占70%以上），而基础模型驱动的规划主体仅收到不到5%的测试。触发组件（如Prompt）几乎被忽视，仅出现约1%的测试中。

Conclusion: AI Agent测试实践对非确定性已做出一定适应，但存在明显不足。为提升鲁棒性，建议：框架开发者完善新型测试方法支持，应用开发者应采用Prompt回归测试，研究者应探究测试方法采纳障碍。

Abstract: Foundation model (FM)-based AI agents are rapidly gaining adoption across
diverse domains, but their inherent non-determinism and non-reproducibility
pose testing and quality assurance challenges. While recent benchmarks provide
task-level evaluations, there is limited understanding of how developers verify
the internal correctness of these agents during development.
  To address this gap, we conduct the first large-scale empirical study of
testing practices in the AI agent ecosystem, analyzing 39 open-source agent
frameworks and 439 agentic applications. We identify ten distinct testing
patterns and find that novel, agent-specific methods like DeepEval are seldom
used (around 1%), while traditional patterns like negative and membership
testing are widely adapted to manage FM uncertainty. By mapping these patterns
to canonical architectural components of agent frameworks and agentic
applications, we uncover a fundamental inversion of testing effort:
deterministic components like Resource Artifacts (tools) and Coordination
Artifacts (workflows) consume over 70% of testing effort, while the FM-based
Plan Body receives less than 5%. Crucially, this reveals a critical blind spot,
as the Trigger component (prompts) remains neglected, appearing in around 1% of
all tests.
  Our findings offer the first empirical testing baseline in FM-based agent
frameworks and agentic applications, revealing a rational but incomplete
adaptation to non-determinism. To address it, framework developers should
improve support for novel testing methods, application developers must adopt
prompt regression testing, and researchers should explore barriers to adoption.
Strengthening these practices is vital for building more robust and dependable
AI agents.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [9] [Proceedings Seventh International Conference on Applied Category Theory 2024](https://arxiv.org/abs/2509.18357)
*Michael Johnson,David Jaz Myers*

Main category: cs.LO

TL;DR: ACT 2024会议汇集了范畴论在多个学科的最新研究进展与应用。


<details>
  <summary>Details</summary>
Motivation: 推动范畴论跨学科发展，拓展其在实际问题中的应用。

Method: 本次会议通过理论研究和应用案例，涵盖各个学科领域的专题报告。

Result: 涵盖了从理论到实际应用的众多学科，展示了范畴论的多元潜力和学术影响力。

Conclusion: ACT 2024展示了范畴论在科学与工程中广泛的应用价值。

Abstract: Proceedings of the Seventh International Conference on Applied Category
Theory, held at the University of Oxford on 17 - 21 June 2024. The
contributions to ACT 2024 ranged from pure to applied and included
contributions in a wide range of disciplines in science and engineering. ACT
2024 included talks in classical mechanics, quantum physics, probability
theory, linguistics, decision theory, machine learning, epidemiology,
thermodynamics, engineering, and logic.

</details>


### [10] [Singleton algorithms for the Constraint Satisfaction Problem](https://arxiv.org/abs/2509.18434)
*Dmitriy Zhuk*

Main category: cs.LO

TL;DR: 本文提出CSP算法的singleton版本，并用组合和代数工具刻画其求解能力，证明了在小规模域上的全部可解CSP都能由此算法解决，揭示了其优于线性规划的本质及多态性对称结构的作用，丰富了CSP理论与算法设计。


<details>
  <summary>Details</summary>
Motivation: 研究CSP（约束满足问题）时，推动算法效能的自然方式是引入它的singleton版本，即先固定约束关系中的某个元组再运行算法，从而分析负面答案时移除该元组。这推动了对singleton版本算法能力的深入理解。

Method: 通过将CSP（promise情形下）上的通用算法的singleton版本能力，与minion同态的存在条件进行特征刻画。利用Hales-Jewett 定理，将有限关系结构中的minion条件与具有某种对称性的多态性（palette block symmetric polymorphisms）的存在性建立等价。通过构造具体的CSP模板并分析多态性的结构和性质，证明算法性能。

Result: 证明了对于域大小最多为7的所有可解CSP，单例版本的BLP+AIP算法都能求解。进一步通过具体CSP模板，揭示了线性规划的局限、singleton算法版本的优势，以及palette block symmetric polymorphisms结构的简洁性和问题解的美学。

Conclusion: 该工作通过刻画singleton版本CSP算法的判定能力，与多态性和对称结构结合，为CSP的算法分析与设计提供了新方向，也揭示了传统方法如线性规划的能力边界。

Abstract: A natural strengthening of an algorithm for the (promise) constraint
satisfaction problem is its singleton version: we first fix a constraint to
some tuple from the constraint relation, then run the algorithm, and remove the
tuple from the constraint if the answer is negative. We characterize the power
of the singleton versions of standard universal algorithms for the (promise)
CSP over a fixed template in terms of the existence of a minion homomorphism.
Using the Hales-Jewett theorem, we show that for finite relational structures
this minion condition is equivalent to the existence of polymorphisms with
certain symmetries, called palette block symmetric polymorphisms. By proving
the existence of such polymorphisms we establish that the singleton version of
the BLP+AIP algorithm solves all tractable CSPs over domains of size at most 7.
Finally, by providing concrete CSP templates, we illustrate the limitations of
linear programming, the power of the singleton versions, and the elegance of
the palette block symmetric polymorphisms.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [11] [Dynamic Prompt Fusion for Multi-Task and Cross-Domain Adaptation in LLMs](https://arxiv.org/abs/2509.18113)
*Xin Hu,Yue Kang,Guanzi Yao,Tianze Kang,Mengjie Wang,Heyao Liu*

Main category: cs.CL

TL;DR: 本文提出了一种解决大模型在多任务与跨领域泛化受限的新方法。通过动态提示调度机制，有效提升模型在不同任务与领域下的适应性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 针对现有方法依赖固定模板、泛化能力差的问题，希望通过动态和任务相关的提示组合，提升模型在多任务及跨领域设定下的泛化能力。

Method: 采用了一个提示池（prompt pool）和任务感知调度策略，根据任务动态融合和调整提示，利用任务嵌入与门控机制精细控制提示传递，实现灵活的任务间共享。同时引入联合多任务学习目标和提示权重自动学习策略，以优化提示调度。

Result: 通过多项敏感性实验（如提示温度参数和任务数量变化），验证了所提方法在稳定性和迁移能力上的提升，在多种语言理解和知识推理任务上均取得了更优的性能。

Conclusion: 实验结果显示，动态提示调度机制显著提升了模型在语言理解与知识推理等任务上的表现，验证了方法在统一多任务建模和跨领域适应方面的有效性。

Abstract: This study addresses the generalization limitations commonly observed in
large language models under multi-task and cross-domain settings. Unlike prior
methods such as SPoT, which depends on fixed prompt templates, our study
introduces a unified multi-task learning framework with dynamic prompt
scheduling mechanism. By introducing a prompt pool and a task-aware scheduling
strategy, the method dynamically combines and aligns prompts for different
tasks. This enhances the model's ability to capture semantic differences across
tasks. During prompt fusion, the model uses task embeddings and a gating
mechanism to finely control the prompt signals. This ensures alignment between
prompt content and task-specific demands. At the same time, it builds flexible
sharing pathways across tasks. In addition, the proposed optimization objective
centers on joint multi-task learning. It incorporates an automatic learning
strategy for scheduling weights, which effectively mitigates task interference
and negative transfer. To evaluate the effectiveness of the method, a series of
sensitivity experiments were conducted. These experiments examined the impact
of prompt temperature parameters and task number variation. The results confirm
the advantages of the proposed mechanism in maintaining model stability and
enhancing transferability. Experimental findings show that the prompt
scheduling method significantly improves performance on a range of language
understanding and knowledge reasoning tasks. These results fully demonstrate
its applicability and effectiveness in unified multi-task modeling and
cross-domain adaptation.

</details>


### [12] [GAUSS: Benchmarking Structured Mathematical Skills for Large Language Models](https://arxiv.org/abs/2509.18122)
*Yue Zhang,Jiaxin Zhang,Qiuyu Ren,Tahsin Saffat,Xiaoxuan Liu,Zitong Yang,Banghua Zhu,Yi Ma*

Main category: cs.CL

TL;DR: GAUSS提出细粒度、多维度的数学技能基准，通过实际测试展示其能精准分析LLM的能力分布和短板，为模型评测带来更高解释性。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM数学能力评测方法粒度粗、解释性弱，缺乏对底层结构化技能的细致分析，难以全面反映模型真实数学智能水平。

Method: 设计GAUSS基准，将数学能力划分为十二项核心技能，涵盖知识理解、问题解决与交流、元技能与创造力三大领域。所有题目均按技能分类，针对性出题，从而细致、定量地刻画模型能力画像。

Result: 以GPT-5-thinking为例，利用GAUSS获得了其细粒度的技能矩阵，清晰揭示其强项、弱点及与o4-mini-high模型的差异。

Conclusion: GAUSS基准实现了多维度、以技能为核心的LLM数学能力评测，极大丰富了模型能力解释和对比手段。

Abstract: We introduce \textbf{GAUSS} (\textbf{G}eneral \textbf{A}ssessment of
\textbf{U}nderlying \textbf{S}tructured \textbf{S}kills in Mathematics), a
benchmark that evaluates LLMs' mathematical abilities across twelve core skill
dimensions, grouped into three domains: knowledge and understanding, problem
solving and communication, and meta-skills and creativity. By categorizing
problems according to cognitive skills and designing tasks that isolate
specific abilities, GAUSS constructs comprehensive, fine-grained, and
interpretable profiles of models' mathematical abilities. These profiles
faithfully represent their underlying mathematical intelligence. To exemplify
how to use the \textsc{GAUSS} benchmark, we have derived the skill profile of
\textsc{GPT-5-thinking}, revealing its strengths and weaknesses as well as its
differences relative to \textsc{o4-mini-high}, thereby underscoring the value
of multidimensional, skill-based evaluation.

</details>


### [13] [Event Causality Identification with Synthetic Control](https://arxiv.org/abs/2509.18156)
*Haoyu Wang,Fengze Liu,Jiayao Zhang,Dan Roth,Kyle Richardson*

Main category: cs.CL

TL;DR: 该论文针对事件因果关系识别的准确性问题，创新性地引入因果推断模型和合成控制方法，并利用文本嵌入技术生成“双生者”来模拟干预效果。实验结果表明，比现有方法更强，尤其在难点因果性基准测试中超越了GPT-4。


<details>
  <summary>Details</summary>
Motivation: 事件因果关系识别（ECI）是从文本中提取事件间因果关系的过程，对于区分因果关系与相关性至关重要。传统方法主要依赖于语言模式和多跳推理，容易因非正式用法或虚假的图推理出现误判。为提升因果识别的准确性，需要更严谨的方法。

Method: 采用Rubin因果模型，将两个有时间顺序的事件视为处理（treatment）和结果（outcome），并通过操控处理事件以及估算结果事件概率变化来判断因果关系。由于文本域无法真实操作事件，作者提出寻找主角的“双生者”，即在处理事件发生前有相同经历但处理事件有干预的个体。实际匹配困难，作者采用合成控制法，利用文本嵌入合成与反演技术，生成“双生者”。

Result: 该方法在因果性基准测试 COPES-hard 上表现优越，识别因果关系的鲁棒性和准确性超过了以往方法，包括GPT-4。

Conclusion: 通过Rubin因果模型结合合成控制方法，可以更坚实、精确地在文本中识别事件因果关系，有效规避传统方法的局限性。

Abstract: Event causality identification (ECI), a process that extracts causal
relations between events from text, is crucial for distinguishing causation
from correlation. Traditional approaches to ECI have primarily utilized
linguistic patterns and multi-hop relational inference, risking false causality
identification due to informal usage of causality and specious graphical
inference. In this paper, we adopt the Rubin Causal Model to identify event
causality: given two temporally ordered events, we see the first event as the
treatment and the second one as the observed outcome. Determining their
causality involves manipulating the treatment and estimating the resultant
change in the likelihood of the outcome. Given that it is only possible to
implement manipulation conceptually in the text domain, as a work-around, we
try to find a twin for the protagonist from existing corpora. This twin should
have identical life experiences with the protagonist before the treatment but
undergoes an intervention of treatment. However, the practical difficulty of
locating such a match limits its feasibility. Addressing this issue, we use the
synthetic control method to generate such a twin' from relevant historical
data, leveraging text embedding synthesis and inversion techniques. This
approach allows us to identify causal relations more robustly than previous
methods, including GPT-4, which is demonstrated on a causality benchmark,
COPES-hard.

</details>


### [14] [ZERA: Zero-init Instruction Evolving Refinement Agent - From Zero Instructions to Structured Prompts via Principle-based Optimization](https://arxiv.org/abs/2509.18158)
*Seungyoun Yi,Minsoo Khang,Sungrae Park*

Main category: cs.CL

TL;DR: 提出ZERA框架，通过结构化标准同时优化系统与用户提示词，显著提升LLM多任务表现，较传统方法更高效且开源。


<details>
  <summary>Details</summary>
Motivation: 现有的自动提示词优化（APO）方法通常只关注用户提示词，依赖无结构化反馈，并且需要大量样本和长时间迭代，导致成本高且效果不稳定。

Method: 提出了ZERA（Zero-init Instruction Evolving Refinement Agent）框架，能够通过结构化评价标准同时优化系统和用户提示词。ZERA基于八个通用标准及自动推断的权重，对提示词进行评分并基于结构化反馈进行修正。该方法可以快速收敛到高质量提示词，所需样本和迭代周期较少。

Result: 在五个不同的大语言模型和九个跨多任务数据集（包括推理、摘要、代码生成等）上进行评估，结果显示ZERA在各项任务中均优于强基线方法。消融实验进一步验证了各组成部分对提示词质量的提升作用。

Conclusion: ZERA可以以较低成本、高效率，结构化优化提示词，显著提升多任务大语言模型的性能，并且实现开源。

Abstract: Automatic Prompt Optimization (APO) improves large language model (LLM)
performance by refining prompts for specific tasks. However, prior APO methods
typically focus only on user prompts, rely on unstructured feedback, and
require large sample sizes and long iteration cycles-making them costly and
brittle. We propose ZERA (Zero-init Instruction Evolving Refinement Agent), a
novel framework that jointly optimizes both system and user prompts through
principled, low-overhead refinement. ZERA scores prompts using eight
generalizable criteria with automatically inferred weights, and revises prompts
based on these structured critiques. This enables fast convergence to
high-quality prompts using minimal examples and short iteration cycles. We
evaluate ZERA across five LLMs and nine diverse datasets spanning reasoning,
summarization, and code generation tasks. Experimental results demonstrate
consistent improvements over strong baselines. Further ablation studies
highlight the contribution of each component to more effective prompt
construction. Our implementation including all prompts is publicly available at
https://github.com/younatics/zera-agent.

</details>


### [15] [Thinking in a Crowd: How Auxiliary Information Shapes LLM Reasoning](https://arxiv.org/abs/2509.18163)
*Haodong Zhao,Chenyan Zhao,Yansi Li,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.CL

TL;DR: 大模型遇到误导信息时，思考/推理过程会放大错误，暴露出思维鲁棒性的弱点。需提升模型批判性信息评估能力。SciAux数据集支持相关研究。


<details>
  <summary>Details</summary>
Motivation: 探究实际应用中大模型面对外部辅助信息时，在复杂推理任务中的表现及其脆弱性，尤其是模型遇到误导性信息时推理-思考机制带来的影响。

Method: 提出并构建了SciAux数据集，系统性地对不同类型辅助信息（有用、无关、误导）下，拥有显式逐步推理能力的大语言模型的鲁棒性进行测试。

Result: 发现大模型遇到误导信息时，“思考”步骤不仅未增强鲁棒性，反而进一步加剧了错误，模型在错误信息干扰下性能骤降。

Conclusion: 大模型进行逐步推理时，受外部辅助信息显著影响：有用信息能提高准确率，但误导信息会使性能灾难性下降，且推理环节会放大错误影响。关键问题在于模型需具备批判性地评估输入信息的能力，而不仅是展开推理过程。

Abstract: The capacity of Large Language Models (LLMs) to reason is fundamental to
their application in complex, knowledge-intensive domains. In real-world
scenarios, LLMs are often augmented with external information that can be
helpful, irrelevant, or even misleading. This paper investigates the causal
impact of such auxiliary information on the reasoning process of LLMs with
explicit step-by-step thinking capabilities. We introduce SciAux, a new dataset
derived from ScienceQA, to systematically test the robustness of the model
against these types of information. Our findings reveal a critical
vulnerability: the model's deliberative "thinking mode" is a double-edged
sword. While helpful context improves accuracy, misleading information causes a
catastrophic drop in performance, which is amplified by the thinking process.
Instead of conferring robustness, thinking reinforces the degree of error when
provided with misinformation. This highlights that the challenge is not merely
to make models "think", but to endow them with the critical faculty to evaluate
the information upon which their reasoning is based. The SciAux dataset is
available at https://huggingface.co/datasets/billhdzhao/SciAux.

</details>


### [16] [SIRAG: Towards Stable and Interpretable RAG with A Process-Supervised Multi-Agent Framework](https://arxiv.org/abs/2509.18167)
*Junlin Wang,Zehao Wu,Shaowei Lu,Yanlan Li,Xinghao Huang*

Main category: cs.CL

TL;DR: 本文提出RAG多智能体过程监督框架，通过决策与知识筛选代理、奖励机制与树形回溯探索，有效提升了检索生成协同、多跳问答准确率及系统可解释性，无需修改原有RAG组件，具强实际应用意义。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法中，检索器与生成器各自独立开发，交互不佳，易导致检索相关性低或证据利用不足，影响下游任务性能。

Method: 引入决策者和知识选择者两个轻量代理，结合LLM-as-a-Judge过程奖励机制，采用树形回溯探索与PPO端到端训练方式。

Result: 在单跳与多跳问答基准上实现更高准确率、更稳定收敛和更可解释的推理路径，对比标准RAG基线显著提升；此外，该方法无需更改原检索器或生成器，易于实际应用。

Conclusion: 该工作提出了一种多智能体过程监督框架，有效促进了检索器与生成器之间的协调，提高了RAG在问答任务中的表现，且方法具有较强的可插拔性和实际应用价值。

Abstract: Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to
access external knowledge sources, but the effectiveness of RAG relies on the
coordination between the retriever and the generator. Since these components
are developed independently, their interaction is often suboptimal: the
retriever may return irrelevant or redundant documents, while the generator may
fail to fully leverage retrieved evidence. In this work, we propose a
process-supervised multi-agent framework to bridge the gap between retriever
and generator. The framework introduces two lightweight agents: a Decision
Maker, which determines when to continue retrieval or stop for answer
generation, and a Knowledge Selector, which filters retrieved documents to
retain only the most useful evidence. To provide fine-grained supervision, we
employ an LLM-as-a-Judge that evaluates each intermediate action with
process-level rewards, ensuring more accurate credit assignment than relying
solely on final answer correctness. We further adopt a tree-structured rollout
strategy to explore diverse reasoning paths, and train both agents with
Proximal Policy Optimization (PPO) in an end-to-end manner. Experiments on
single-hop and multi-hop question answering benchmarks show that our approach
achieves higher accuracy, more stable convergence, and produces more
interpretable reasoning trajectories compared with standard RAG baselines.
Importantly, the proposed framework is modular and plug-and-play, requiring no
modification to the retriever or generator, making it practical for real-world
RAG applications.

</details>


### [17] [ERFC: Happy Customers with Emotion Recognition and Forecasting in Conversation in Call Centers](https://arxiv.org/abs/2509.18175)
*Aditi Debsharma,Bhushan Jagyasi,Surajit Sen,Priyanka Pandey,Devicharith Dovari,Yuvaraj V. C,Rosalin Parida,Gopali Contractor*

Main category: cs.CL

TL;DR: 该论文提出了一种同时识别和预测会话情绪的新架构ERFC，在多个情绪属性、上下文与多模态基础上挖掘说话者互动，实验验证有效，为呼叫中心等行业提升客户满意度提供数据支持。


<details>
  <summary>Details</summary>
Motivation: 在呼叫中心等行业场景下，客户的情绪管理对于提升客户体验具有重要意义。现有的会话情绪识别方法，通常忽略对未来话语情绪的预测，而客户与座席之间的情绪互动和影响极大影响最终结果。座席能适时判断并预测客户情绪变化，有助于更准确地调节自身情绪并提供合适的服务，提高客户满意度。

Method: 文章提出了一种新颖的架构，称为ERFC（会话中的情绪识别与预测）。该方法结合了多模态信息、情绪的不同属性、会话上下文，以及说话者之间的话语依赖关系，通过对未来话语情绪的预测，辅助座席更好地与客户互动。该架构在IEMOCAP数据集上进行了深入实验验证。

Result: 实验结果表明，ERFC架构能够有效实现会话中的情绪识别并预测未来话语情绪，证明了方法的可行性。为实际应用（如呼叫中心）带来显著业务价值，能够帮助提升客户满意度。

Conclusion: ERFC架构通过结合多模态和上下文信息，不仅能准确识别当前会话情绪，还能预测后续话语情绪，有效改善客户体验，具有广泛商业应用前景。

Abstract: Emotion Recognition in Conversation has been seen to be widely applicable in
call center analytics, opinion mining, finance, retail, healthcare, and other
industries. In a call center scenario, the role of the call center agent is not
just confined to receiving calls but to also provide good customer experience
by pacifying the frustration or anger of the customers. This can be achieved by
maintaining neutral and positive emotion from the agent. As in any
conversation, the emotion of one speaker is usually dependent on the emotion of
other speaker. Hence the positive emotion of an agent, accompanied with the
right resolution will help in enhancing customer experience. This can change an
unhappy customer to a happy one. Imparting the right resolution at right time
becomes easier if the agent has the insight of the emotion of future
utterances. To predict the emotions of the future utterances we propose a novel
architecture, Emotion Recognition and Forecasting in Conversation. Our proposed
ERFC architecture considers multi modalities, different attributes of emotion,
context and the interdependencies of the utterances of the speakers in the
conversation. Our intensive experiments on the IEMOCAP dataset have shown the
feasibility of the proposed ERFC. This approach can provide a tremendous
business value for the applications like call center, where the happiness of
customer is utmost important.

</details>


### [18] [Evaluating Large Language Models for Detecting Antisemitism](https://arxiv.org/abs/2509.18293)
*Jay Patel,Hrudayangam Mehta,Jeremy Blackburn*

Main category: cs.CL

TL;DR: 本文针对反犹太内容检测，评估了八种开源LLMs，通过创新性的Guided-CoT提示方式，显著提升了模型表现，并揭示了各模型在解释性和可靠性上的差异，尤其Llama 3.1 70B表现优越。


<details>
  <summary>Details</summary>
Motivation: 检测仇恨内容，尤其是反犹太内容，是一项极具挑战性且重要的任务。自动化工具如机器学习模型可以协助这一工作，但由于社交媒体内容不断变化，这些模型需要持续训练。本文旨在评估开源大模型（LLMs）在检测反犹内容上的能力，促进在线环境治理。

Method: 本文评估了八个开源LLMs用于检测反犹太内容的能力，采用上下文定义作为政策指导。探索了多种提示技术，并设计了一种新的连锁式思维（CoT）提示——Guided-CoT，通过引导模型对政策进行理解。文章还分析了模型错误，并引入了衡量语义偏差的新指标，用于考察生成推理的差异。

Result: Guided-CoT能够很好地结合政策定义，提升了所有模型的表现，无论模型大小、设置或推理能力。Llama 3.1 70B在检测反犹内容方面表现优于微调的GPT-3.5。对模型错误的分析和语义偏差量化揭示了各模型在推理能力上存在显著差异和一些矛盾行为。

Conclusion: Guided-CoT能够提升开源LLMs在仇恨言论检测中的性能，尤其是在对政策理解的任务中。不同大模型在实用性、可解释性及可靠性上存在显著差异，Llama 3.1 70B在此任务上拥有领先优势。

Abstract: Detecting hateful content is a challenging and important problem. Automated
tools, like machine-learning models, can help, but they require continuous
training to adapt to the ever-changing landscape of social media. In this work,
we evaluate eight open-source LLMs' capability to detect antisemitic content,
specifically leveraging in-context definition as a policy guideline. We explore
various prompting techniques and design a new CoT-like prompt, Guided-CoT.
Guided-CoT handles the in-context policy well, increasing performance across
all evaluated models, regardless of decoding configuration, model sizes, or
reasoning capability. Notably, Llama 3.1 70B outperforms fine-tuned GPT-3.5.
Additionally, we examine LLM errors and introduce metrics to quantify semantic
divergence in model-generated rationales, revealing notable differences and
paradoxical behaviors among LLMs. Our experiments highlight the differences
observed across LLMs' utility, explainability, and reliability.

</details>


### [19] [Exploiting Tree Structure for Credit Assignment in RL Training of LLMs](https://arxiv.org/abs/2509.18314)
*Hieu Tran,Zonghai Yao,Hong Yu*

Main category: cs.CL

TL;DR: 该论文提出了基于前缀树的新型强化学习算法TEMPO，解决了token级奖励归因难题，不依赖价值网络，能在多项数学和医学推理基准上大幅提升大语言模型的推理准确率。


<details>
  <summary>Details</summary>
Motivation: 强化学习能够提升大语言模型（LLM）的推理能力，但在处理长序列时，由于奖励稀疏且多为延迟，如何进行精确的token级归因成为关键瓶颈。尤其是在答案可验证的场景（如数学和医学问答），只有少数决策token真正影响最终结果，因此该领域亟需更高效和可推广的方法。

Method: 作者提出了一种全新的方法Prefix-to-Tree（P2T），它将多个响应组织为前缀树，通过聚合后代结果在不依赖参数模型的情况下计算前缀值。同时，基于P2T，作者提出了TEMPO算法，这是一种无critic模型的改进版GRPO方法，通过树结构注入了分支控制的时序差分校正项，在分支token处可以实现精确的token级归因，无需价值网络或额外的监督信号。

Result: 在Qwen3-1.7B和Qwen3-4B模型上，TEMPO算法在MATH和MedQA等原分布任务以及GSM-HARD、AMC23、MedMCQA、MMLU-Medical等跨分布任务上均优于传统的PPO和GRPO方法。同时，TEMPO能在基本相同的训练时间内获得更高的验证准确率。

Conclusion: TEMPO是一种基于前缀树、无需critic模型、支持可验证奖励的方法，可有效实现token级归因，提升LLM在推理和问答任务中的表现，对复杂决策点具有显著优势。

Abstract: Reinforcement learning improves LLM reasoning, yet sparse delayed reward over
long sequences makes token-level credit assignment the key bottleneck. We study
the verifiable-reward setting, where the final answer is checkable and multiple
responses can be drawn per prompt. Reasoning tasks in math and medical QA align
with this setup, where only a few decision tokens significantly impact the
outcome. PPO offers token-level advantages with a learned value model, but it
is complex to train both the actor and critic models simultaneously, and it is
not easily generalizable, as the token-level values from the critic model can
make training prone to overfitting. GRPO is critic-free and supports verifiable
rewards, but spreads a single sequence-level return across tokens and ignores
branching. We introduce \textbf{Prefix-to-Tree (P2T)}, a simple procedure that
converts a group of responses into a prefix tree and computes
\emph{nonparametric} prefix values \(V(s)\) by aggregating descendant outcomes.
Built on P2T, we propose \textbf{TEMPO} (\emph{\textbf{T}ree-\textbf{E}stimated
\textbf{M}ean Prefix Value for \textbf{P}olicy \textbf{O}ptimization}), a
critic-free algorithm that augments the group-relative outcome signal of GRPO
with \emph{branch-gated} temporal-difference corrections derived from the tree.
At non-branch tokens, the temporal-difference (TD) term is zero, so TEMPO
reduces to GRPO; at branching tokens, it supplies precise token-level credit
without a learned value network or extra judges/teachers. On Qwen3-1.7B/4B,
TEMPO outperforms PPO and GRPO on in-distribution (MATH, MedQA) and
out-of-distribution (GSM-HARD, AMC23, MedMCQA, MMLU-Medical) benchmarks, and
reaches higher validation accuracy with roughly the same wall-clock time.

</details>


### [20] [Brittleness and Promise: Knowledge Graph Based Reward Modeling for Diagnostic Reasoning](https://arxiv.org/abs/2509.18316)
*Saksham Khatwani,He Cheng,Majid Afshar,Dmitriy Dligach,Yanjun Gao*

Main category: cs.CL

TL;DR: 本文提出用大语言模型作为知识图谱推理路径的奖励模型，评估其提升医学推理可靠性的潜力。系统实验显示，虽然能提升路径评判能力，但在下游诊断任务中的泛化和迁移表现仍有限，揭示了结构化奖励监督对医学GenAI的挑战和机遇。


<details>
  <summary>Details</summary>
Motivation: 大语言模型 (LLMs) 在诊断推理方面具有潜力，但在可靠性和知识推理能力上仍然存在不足。知识图谱 (KGs) 提供了结构化的医学知识，有助于提升推理的可信度。以往的方法多通过检索增强生成或微调，将知识图谱内容直接嵌入提示词，而未能充分利用其进行结构化推理。因此，本文提出探索一种新的范式：将LLM作为KG推理路径的奖励模型，学习判断某一候选路径是否能帮助做出正确诊断。

Method: 作者将大语言模型视作评判知识图谱推理路径的奖励模型，评估不同路径对于病人输入能否导致正确诊断。具体分为两步：首先系统性评估五种知识路径判断任务和八种训练范式；其次考察路径判断能力能否迁移到实际诊断任务，比如诊断总结和医学问答。实验基于三个开源、instruct-tuned的LLMs进行。

Result: 结果表明，特定的奖励优化和蒸馏技术能够显著提升路径判断性能，但这种能力迁移到下游诊断任务的表现较弱，模型在泛化能力上仍有限。

Conclusion: 本文首次系统性验证了“奖励模型式”结构化知识图谱推理在临床应用中的有效性，显示奖励监督能够提升结构化诊断推理，但对于实际诊断任务的直接迁移仍需进一步研究。

Abstract: Large language models (LLMs) show promise for diagnostic reasoning but often
lack reliable, knowledge grounded inference. Knowledge graphs (KGs), such as
the Unified Medical Language System (UMLS), offer structured biomedical
knowledge that can support trustworthy reasoning. Prior approaches typically
integrate KGs via retrieval augmented generation or fine tuning, inserting KG
content into prompts rather than enabling structured reasoning. We explore an
alternative paradigm: treating the LLM as a reward model of KG reasoning paths,
where the model learns to judge whether a candidate path leads to correct
diagnosis for a given patient input. This approach is inspired by recent work
that leverages reward training to enhance model reasoning abilities, and
grounded in computational theory, which suggests that verifying a solution is
often easier than generating one from scratch. It also parallels physicians'
diagnostic assessment, where they judge which sequences of findings and
intermediate conditions most plausibly support a diagnosis. We first
systematically evaluate five task formulation for knowledge path judging and
eight training paradigm. Second, we test whether the path judging abilities
generalize to downstream diagnostic tasks, including diagnosis summarization
and medical question answering. Experiments with three open source
instruct-tuned LLMs reveal both promise and brittleness: while specific reward
optimization and distillation lead to strong path-judging performance, the
transferability to downstream tasks remain weak. Our finding provides the first
systematic assessment of "reward model style" reasoning over clinical KGs,
offering insights into how structured, reward-based supervision influences
diagnostic reasoning in GenAI systems for healthcare.

</details>


### [21] [Speculate Deep and Accurate: Lossless and Training-Free Acceleration for Offloaded LLMs via Substitute Speculative Decoding](https://arxiv.org/abs/2509.18344)
*Pei-Shuo Wang,Jian-Jia Chen,Chun-Che Yang,Chi-Chih Chang,Ning-Chi Huang,Mohamed S. Abdelfattah,Kai-Chiang Wu*

Main category: cs.CL

TL;DR: 论文针对大语言模型因显存受限难部署的问题，提出了无需训练的SubSpec方法，通过低比特量化替换层和资源共享实现高度对齐的草稿模型，显著提升加速效果（最高达12.5倍），且不影响模型表现。


<details>
  <summary>Details</summary>
Motivation: 由于大语言模型（LLM）参数规模巨大，消费者级别的GPU在部署时面临内存限制。传统的模型压缩会影响模型质量，参数卸载虽然保持质量但推理速度慢。现有的推测解码方法虽能一定程度加速，但对目标模型的适配不充分，速度提升有限。

Method: 提出了SubSpec方法，属于即插即用的加速参数卸载方案。该方法无需任何训练，通过从卸载部分的目标LLM生成低比特量化的替代层，构建高度对齐的草稿模型。同时共享GPU驻留层与KV-Cache以减少内存占用并提升模型对齐度。

Result: SubSpec在Qwen2.5 7B模型上（8GB显存限制）的MT-Bench测试达到9.1倍加速，在Qwen2.5 32B模型上（24GB显存限制）的主流生成基准测试平均达12.5倍加速。

Conclusion: SubSpec方法能够无损、免训练地大幅提升参数卸载场景下LLM推理速度，显著减少内存占用且无需牺牲模型质量。

Abstract: The immense model sizes of large language models (LLMs) challenge deployment
on memory-limited consumer GPUs. Although model compression and parameter
offloading are common strategies to address memory limitations, compression can
degrade quality, and offloading maintains quality but suffers from slow
inference. Speculative decoding presents a promising avenue to accelerate
parameter offloading, utilizing a fast draft model to propose multiple draft
tokens, which are then verified by the target LLM in parallel with a single
forward pass. This method reduces the time-consuming data transfers in forward
passes that involve offloaded weight transfers. Existing methods often rely on
pretrained weights of the same family, but require additional training to align
with custom-trained models. Moreover, approaches that involve draft model
training usually yield only modest speedups. This limitation arises from
insufficient alignment with the target model, preventing higher token
acceptance lengths. To address these challenges and achieve greater speedups,
we propose SubSpec, a plug-and-play method to accelerate parameter offloading
that is lossless and training-free. SubSpec constructs a highly aligned draft
model by generating low-bit quantized substitute layers from offloaded target
LLM portions. Additionally, our method shares the remaining GPU-resident layers
and the KV-Cache, further reducing memory overhead and enhance alignment.
SubSpec achieves a high average acceptance length, delivering 9.1x speedup for
Qwen2.5 7B on MT-Bench (8GB VRAM limit) and an average of 12.5x speedup for
Qwen2.5 32B on popular generation benchmarks (24GB VRAM limit).

</details>


### [22] [Speech Vecalign: an Embedding-based Method for Aligning Parallel Speech Documents](https://arxiv.org/abs/2509.18360)
*Chutong Meng,Philipp Koehn*

Main category: cs.CL

TL;DR: 作者提出一种无需文本转录、对齐更长、噪音更低的语音文档对齐方法Speech Vecalign，在英德语音翻译任务中取得显著提升，并在低资源条件下实现高质量效果，优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 现有语音挖掘方法（如Global Mining和Local Mining）在语音文档对齐时存在对齐长度短、噪音大或依赖文本转录的问题。作者旨在解决这些不足，以便于更高效地构建高质量的语音平行数据用于翻译模型训练。

Method: 提出Speech Vecalign，通过对语音片段嵌入进行单调对齐，无需文本转录，提升了对齐长度和噪音控制能力；在3,000小时的英德语音数据上获得1,000小时高质量对齐样本，并用于训练语音到语音翻译模型。

Result: Speech Vecalign比Global Mining方法提高了英到德和德到英的ASR-BLEU分数（分别提升0.37和0.18），且模型性能匹敌甚至超过SpeechMatrix，所需原始语音文档数量减少8倍。

Conclusion: Speech Vecalign方法用于并行语音文档对齐，能够提升对齐长度和质量，并在低资源条件下取得卓越的语音到语音翻译效果。

Abstract: We present Speech Vecalign, a parallel speech document alignment method that
monotonically aligns speech segment embeddings and does not depend on text
transcriptions. Compared to the baseline method Global Mining, a variant of
speech mining, Speech Vecalign produces longer speech-to-speech alignments. It
also demonstrates greater robustness than Local Mining, another speech mining
variant, as it produces less noise. We applied Speech Vecalign to 3,000 hours
of unlabeled parallel English-German (En-De) speech documents from VoxPopuli,
yielding about 1,000 hours of high-quality alignments. We then trained En-De
speech-to-speech translation models on the aligned data. Speech Vecalign
improves the En-to-De and De-to-En performance over Global Mining by 0.37 and
0.18 ASR-BLEU, respectively. Moreover, our models match or outperform
SpeechMatrix model performance, despite using 8 times fewer raw speech
documents.

</details>


### [23] [Interactive Real-Time Speaker Diarization Correction with Human Feedback](https://arxiv.org/abs/2509.18377)
*Xinlu He,Yiwen Guan,Badrivishal Paurana,Zilin Dai,Jacob Whitehill*

Main category: cs.CL

TL;DR: 提出了一种结合大语言模型与用户反馈的说话人归属纠错系统，相比传统方法，能实时提升准确性并大幅减少错误。


<details>
  <summary>Details</summary>
Motivation: 现有的自动语音处理系统通常没有用户反馈，因而在说话人归属存在错误时难以纠正。引入用户，特别是在循环中实时修正说话人的方法，可以提升准确率。

Method: 提出了一种结合大语言模型（LLM）辅助的说话人分离纠错系统。系统流程包括流式ASR和说话人分离、利用LLM向用户推送摘要信息、收集并快速应用用户语音反馈。同时，设计了split-when-merged（SWM）技术分离由ASR错误归属的多说话人片段，并在用户纠错基础上在线采集说话人信息供后续使用。

Result: 在AMI测试集上的LLM驱动仿真表明，该系统将说话人错误率（DER）降低了9.92%，说话人混淆错误下降了44.23%。还分析了摘要展示、听写全文、在线注册数量与纠错频率等不同设置下的效果。

Conclusion: 通过引入LLM和用户在环的说话人纠错系统，能够实时改进说话人的归属准确性，并显著降低系统错误，验证了方法的有效性。

Abstract: Most automatic speech processing systems operate in "open loop" mode without
user feedback about who said what; yet, human-in-the-loop workflows can
potentially enable higher accuracy. We propose an LLM-assisted speaker
diarization correction system that lets users fix speaker attribution errors in
real time. The pipeline performs streaming ASR and diarization, uses an LLM to
deliver concise summaries to the users, and accepts brief verbal feedback that
is immediately incorporated without disrupting interactions. Moreover, we
develop techniques to make the workflow more effective: First, a
split-when-merged (SWM) technique detects and splits multi-speaker segments
that the ASR erroneously attributes to just a single speaker. Second, online
speaker enrollments are collected based on users' diarization corrections, thus
helping to prevent speaker diarization errors from occurring in the future.
LLM-driven simulations on the AMI test set indicate that our system
substantially reduces DER by 9.92% and speaker confusion error by 44.23%. We
further analyze correction efficacy under different settings, including summary
vs full transcript display, the number of online enrollments limitation, and
correction frequency.

</details>


### [24] [NormGenesis: Multicultural Dialogue Generation via Exemplar-Guided Social Norm Modeling and Violation Recovery](https://arxiv.org/abs/2509.18395)
*Minki Hong,Jangho Choi,Jihie Kim*

Main category: cs.CL

TL;DR: 本文提出NormGenesis，一个跨英中韩三语、关注社会规范的对话生成与标注框架，创造性引入违规-修复（V2R）对话类型，以及范例细化流程。结果表明，该数据集在对话自然度与规范适应性上优于现有方案，并推动多文化环境下的对话系统发展。


<details>
  <summary>Details</summary>
Motivation: 当前的对话系统虽然追求内容连贯性，但往往缺乏对不同文化背景下社会规范的把握，容易产生不符合社交习惯或不适当的回复。因此，需要一种能够适应多文化、多语种、关注社会规范的对话建模方法。

Method: 作者提出了NormGenesis，一个涵盖英语、中文、韩语的多文化对话框架，能够生成并标注社会规范相关的对话。引入“违规-修复（V2R）”对话类型，模拟规范违规、识别和修复的对话进展；并在数据合成早期采用基于范例的迭代细化，提升语言和文化一致性。最终构建了10800个多轮对话的数据集，对每一轮标注规范遵守情况、说话意图和情感反应。

Result: 通过人工和大模型评测，NormGenesis在对话细腻度、自然度和泛化性能上显著优于现有数据集；基于V2R数据训练的模型在道德敏感环境下具有更强的语用能力。

Conclusion: NormGenesis为文化适应性对话建模树立了新的基准，并提出了一种可扩展的方法，支持在多语种、多文化场景下的社会规范感知式对话生成。

Abstract: Social norms govern culturally appropriate behavior in communication,
enabling dialogue systems to produce responses that are not only coherent but
also socially acceptable. We present NormGenesis, a multicultural framework for
generating and annotating socially grounded dialogues across English, Chinese,
and Korean. To model the dynamics of social interaction beyond static norm
classification, we propose a novel dialogue type, Violation-to-Resolution
(V2R), which models the progression of conversations following norm violations
through recognition and socially appropriate repair. To improve pragmatic
consistency in underrepresented languages, we implement an exemplar-based
iterative refinement early in the dialogue synthesis process. This design
introduces alignment with linguistic, emotional, and sociocultural expectations
before full dialogue generation begins. Using this framework, we construct a
dataset of 10,800 multi-turn dialogues annotated at the turn level for norm
adherence, speaker intent, and emotional response. Human and LLM-based
evaluations demonstrate that NormGenesis significantly outperforms existing
datasets in refinement quality, dialogue naturalness, and generalization
performance. We show that models trained on our V2R-augmented data exhibit
improved pragmatic competence in ethically sensitive contexts. Our work
establishes a new benchmark for culturally adaptive dialogue modeling and
provides a scalable methodology for norm-aware generation across linguistically
and culturally diverse languages.

</details>


### [25] [Evaluating the Creativity of LLMs in Persian Literary Text Generation](https://arxiv.org/abs/2509.18401)
*Armin Tourajmehr,Mohammad Reza Modarres,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 该论文评估了大型语言模型在波斯语文学文本生成及创造力维度上的表现，采用标准化评分体系和自动化评审方式，发现模型虽有显著能力却也存在不足，亟需针对非英语文学进一步优化。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）在生成文学文本方面展现了不错的创造力，尤其是诗歌和短篇故事，但现有研究主要聚焦于英文，缺少对非英语文学传统的探讨，也没有标准化的创造力评估方法。因此，该论文旨在评估LLM在波斯语文学创作（尤其是富含文化相关表达的文本生成）方面的能力。

Method: 论文构建了一个覆盖20个不同话题的波斯语文学用户生成文本数据集，并采用Torrance创造性思维测验（适当修改后）从原创性、流畅性、灵活性和细致性四个维度评估模型输出。此外，为了降低评估成本，论文使用LLM作为自动评分的评审者，并通过级间相关系数方法与人工评价进行一致性验证。论文还分析了模型理解和运用四种主要文学修辞手法（明喻、隐喻、夸张、对立）的能力。

Result: 模型在波斯语文学文本生成方面表现出一定的优势，在创造力四个维度的测评与人类评审有较高一致性，同时在修辞手法的运用上有所体现。但也揭示了模型的不足，强调需要进一步优化以适应非英语文学创作的特殊性。

Conclusion: LLM在波斯语文学文本生成和创造力表现方面有亮点，但现阶段仍存在局限，需进一步提升以更好支持不同文化语境下的文学创作。

Abstract: Large language models (LLMs) have demonstrated notable creative abilities in
generating literary texts, including poetry and short stories. However, prior
research has primarily centered on English, with limited exploration of
non-English literary traditions and without standardized methods for assessing
creativity. In this paper, we evaluate the capacity of LLMs to generate Persian
literary text enriched with culturally relevant expressions. We build a dataset
of user-generated Persian literary spanning 20 diverse topics and assess model
outputs along four creativity dimensions-originality, fluency, flexibility, and
elaboration-by adapting the Torrance Tests of Creative Thinking. To reduce
evaluation costs, we adopt an LLM as a judge for automated scoring and validate
its reliability against human judgments using intraclass correlation
coefficients, observing strong agreement. In addition, we analyze the models'
ability to understand and employ four core literary devices: simile, metaphor,
hyperbole, and antithesis. Our results highlight both the strengths and
limitations of LLMs in Persian literary text generation, underscoring the need
for further refinement.

</details>


### [26] [Developing an AI framework to automatically detect shared decision-making in patient-doctor conversations](https://arxiv.org/abs/2509.18439)
*Oscar J. Ponce-Ponte,David Toro-Tobon,Luis F. Figueroa,Michael Gionfriddo,Megan Branda,Victor M. Montori,Saturnino Luz,Juan P. Brito*

Main category: cs.CL

TL;DR: 该研究利用深度学习与BERT模型，创新性地开发了通过对话一致性分数自动测量患者-医生沟通中共享决策的新方法，具备大规模应用潜力。


<details>
  <summary>Details</summary>
Motivation: 共享决策(SDM)是实现以患者为中心医疗护理的重要环节，但目前尚无可自动化、规模化测量SDM的方法。此研究旨在开发一种基于语言建模和对话一致性分数(CA分数)的自动化SDM测量方法。

Method: 本研究收集了157例关于房颤抗凝决策的病患-医生对话视频，转录后分割为42,559个句子，采用上下文-响应配对与负采样训练深度学习(DL)模型，并通过下一个句子预测(NSP)任务微调BERT模型。每个最佳模型计算四种CA分数。随后用随机效应分析，调整相关人口统计学变量，评估CA分数与SDM结局(Decisional Conflict Scale和OPTION12分数)之间的关联，并对多重比较进行校正。

Result: DL模型（无风格策略）召回率为0.227，微调过的BERTbase召回率最高为0.640。无风格DL模型生成的AbsMax和Max CA分数与OPTION12显著相关，微调BERTbase生成的Max CA分数与DCS分数显著相关。BERT模型尺寸对关联性无显著影响。

Conclusion: 本研究提出了一种自动化、可扩展的方法，可以通过可解释的CA分数来衡量病患-医生交流中的共享决策水平，为大规模评估SDM策略提供可能。

Abstract: Shared decision-making (SDM) is necessary to achieve patient-centred care.
Currently no methodology exists to automatically measure SDM at scale. This
study aimed to develop an automated approach to measure SDM by using language
modelling and the conversational alignment (CA) score. A total of 157
video-recorded patient-doctor conversations from a randomized multi-centre
trial evaluating SDM decision aids for anticoagulation in atrial fibrillations
were transcribed and segmented into 42,559 sentences. Context-response pairs
and negative sampling were employed to train deep learning (DL) models and
fine-tuned BERT models via the next sentence prediction (NSP) task. Each
top-performing model was used to calculate four types of CA scores. A
random-effects analysis by clinician, adjusting for age, sex, race, and trial
arm, assessed the association between CA scores and SDM outcomes: the
Decisional Conflict Scale (DCS) and the Observing Patient Involvement in
Decision-Making 12 (OPTION12) scores. p-values were corrected for multiple
comparisons with the Benjamini-Hochberg method. Among 157 patients (34% female,
mean age 70 SD 10.8), clinicians on average spoke more words than patients
(1911 vs 773). The DL model without the stylebook strategy achieved a recall@1
of 0.227, while the fine-tuned BERTbase (110M) achieved the highest recall@1
with 0.640. The AbsMax (18.36 SE7.74 p=0.025) and Max CA (21.02 SE7.63 p=0.012)
scores generated with the DL without stylebook were associated with OPTION12.
The Max CA score generated with the fine-tuned BERTbase (110M) was associated
with the DCS score (-27.61 SE12.63 p=0.037). BERT model sizes did not have an
impact the association between CA scores and SDM. This study introduces an
automated, scalable methodology to measure SDM in patient-doctor conversations
through explainable CA scores, with potential to evaluate SDM strategies at
scale.

</details>


### [27] [CogniLoad: A Synthetic Natural Language Reasoning Benchmark With Tunable Length, Intrinsic Difficulty, and Distractor Density](https://arxiv.org/abs/2509.18458)
*Daniel Kaiser,Arnoldo Frigessi,Ali Ramezani-Kebrya,Benjamin Ricaud*

Main category: cs.CL

TL;DR: 本文提出了基于认知负荷理论的长上下文推理评测新基准CogniLoad，可以精确调控任务难度、干扰项比例和长度，系统分析并诊断模型表现，为指导LLM发展提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）长上下文推理评测标准，往往无法清晰区分任务固有复杂性、干扰项影响以及任务长度等关键因素，导致难以精确分析模型失败原因。

Method: 提出CogniLoad，这是一个基于认知负荷理论（CLT）的新型合成基准。CogniLoad能够生成自然语言逻辑谜题，并对任务的固有难度、干扰项比例以及任务长度等参数进行独立调节，从而精确控制认知负荷的不同维度。

Result: 通过对22个最先进的推理型LLM进行评测，CogniLoad揭示了模型在不同认知负荷参数下的表现敏感性。例如，任务长度是主要的性能约束，模型对任务复杂度的耐受性存在差异，对干扰项比例则表现出U型响应。

Conclusion: CogniLoad为分析大型语言模型在推理方面的局限性提供了可控、可复现和诊断丰富的工具，有助于推动模型未来的发展。

Abstract: Current benchmarks for long-context reasoning in Large Language Models (LLMs)
often blur critical factors like intrinsic task complexity, distractor
interference, and task length. To enable more precise failure analysis, we
introduce CogniLoad, a novel synthetic benchmark grounded in Cognitive Load
Theory (CLT). CogniLoad generates natural-language logic puzzles with
independently tunable parameters that reflect CLT's core dimensions: intrinsic
difficulty ($d$) controls intrinsic load; distractor-to-signal ratio ($\rho$)
regulates extraneous load; and task length ($N$) serves as an operational proxy
for conditions demanding germane load. Evaluating 22 SotA reasoning LLMs,
CogniLoad reveals distinct performance sensitivities, identifying task length
as a dominant constraint and uncovering varied tolerances to intrinsic
complexity and U-shaped responses to distractor ratios. By offering systematic,
factorial control over these cognitive load dimensions, CogniLoad provides a
reproducible, scalable, and diagnostically rich tool for dissecting LLM
reasoning limitations and guiding future model development.

</details>


### [28] [LAWCAT: Efficient Distillation from Quadratic to Linear Attention with Convolution across Tokens for Long Context Modeling](https://arxiv.org/abs/2509.18467)
*Zeyu Liu,Souvik Kundu,Lianghao Jiang,Anni Li,Srikanth Ronanki,Sravan Bodapati,Gourav Datta,Peter A. Beerel*

Main category: cs.CL

TL;DR: LAWCAT是一种高效线性注意力框架，通过结合卷积和注意力方法，实现用极少数据和计算资源训练出高性能长上下文模型，显著提升推理速度和应用范围。


<details>
  <summary>Details</summary>
Motivation: Transformer架构在各领域表现出色，但由于计算复杂度随序列长度呈二次增长，仍是长上下文、低延迟应用的瓶颈。尽管线性复杂度的替代方案逐渐成熟，仍需高昂的训练成本。该文旨在寻找高效方法，将已有高性能Transformer能力迁移到线性注意力结构。

Method: 提出LAWCAT（Linear Attention with Convolution Across Time）框架，通过融合因果Conv1D层以提升局部依赖建模，并采用归一化门控线性注意力以加强不同上下文长度的泛化能力。该方法以蒸馏已有Transformer模型，以实现高效的线性注意力架构。

Result: 蒸馏Mistral-7B模型，仅用长度为1K的序列数据，即可在长达22K令牌的验证下获得超过90%的Passkey检索准确率，显著扩展了有效上下文窗口。Llama3.2-1B LAWCAT在多种长序列任务上取得与原始模型媲美的表现，同时所需预训练数据仅为原模型的0.1%。在8K长度以上序列上，LAWCAT预填速度超过FlashAttention-2。

Conclusion: LAWCAT可高效将预训练Transformer能力转移到长序列线性模型，无需大量长序列数据和算力，性能强劲，适合边缘设备部署。为长上下文需求提供资源友好的解决方案。

Abstract: Although transformer architectures have achieved state-of-the-art performance
across diverse domains, their quadratic computational complexity with respect
to sequence length remains a significant bottleneck, particularly for
latency-sensitive long-context applications. While recent linear-complexity
alternatives are increasingly powerful, effectively training them from scratch
is still resource-intensive. To overcome these limitations, we propose LAWCAT
(Linear Attention with Convolution Across Time), a novel linearization
framework designed to efficiently transfer the capabilities of pre-trained
transformers into a performant linear attention architecture. LAWCAT integrates
causal Conv1D layers to enhance local dependency modeling and employs
normalized gated linear attention to improve generalization across varying
context lengths. Our comprehensive evaluations demonstrate that, distilling
Mistral-7B with only 1K-length sequences yields over 90\% passkey retrieval
accuracy up to 22K tokens, significantly extending its effective context
window. Similarly, Llama3.2-1B LAWCAT variant achieves competitive performance
on S-NIAH 1\&2\&3 tasks (1K-8K context length) and BABILong benchmark
(QA2\&QA3, 0K-16K context length), requiring less than 0.1\% pre-training
tokens compared with pre-training models. Furthermore, LAWCAT exhibits faster
prefill speeds than FlashAttention-2 for sequences exceeding 8K tokens. LAWCAT
thus provides an efficient pathway to high-performance, long-context linear
models suitable for edge deployment, reducing reliance on extensive
long-sequence training data and computational resources.

</details>


### [29] [Actions Speak Louder than Prompts: A Large-Scale Study of LLMs for Graph Inference](https://arxiv.org/abs/2509.18487)
*Ben Finkelshtein,Silviu Cucerzan,Sujay Kumar Jauhar,Ryen White*

Main category: cs.CL

TL;DR: 本文系统评估了大语言模型在图型任务中的多种交互方式，发现代码生成模式表现最佳，尤其适用于长文本、高度节点或异质性图，并提出设计建议以优化未来LLMs图数据应用。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）越来越多地应用于富文本图机器学习任务，如节点分类，在反欺诈和推荐系统等重要领域表现突出。然而，LLMs对图数据的处理能力尚缺乏系统性理解，研究者亟需探索LLMs与图数据交互的各种模式与优势。

Method: 本文在多个关键变量轴上（如交互模式、数据集领域、图结构、特征属性、模型规模）进行大规模、受控评估，系统性测试LLMs在与图数据交互时的表现。采用的方法包括特征截断、边删除、标签移除，由此分析模型对不同输入类型的依赖。

Result: （1）LLMs作为代码生成器在图数据任务中表现最优，特别是在长文本与高度节点的图结构下优势明显。（2）所有交互策略在异质性强的图上仍有效，反驳了低同质性下LLMs性能下降的传统观点。（3）代码生成方式能灵活调整对结构、特征与标签的依赖，充分利用最有信息量的输入类型。

Conclusion: LLMs在图数据任务中的表现受交互模式、数据特征等多方面影响，代码生成模式具备突出优势。研究揭示了LLMs与图数据交互的关键设计原则，为未来方法提供了重要参考。

Abstract: Large language models (LLMs) are increasingly used for text-rich graph
machine learning tasks such as node classification in high-impact domains like
fraud detection and recommendation systems. Yet, despite a surge of interest,
the field lacks a principled understanding of the capabilities of LLMs in their
interaction with graph data. In this work, we conduct a large-scale, controlled
evaluation across several key axes of variability to systematically assess the
strengths and weaknesses of LLM-based graph reasoning methods in text-based
applications. The axes include the LLM-graph interaction mode, comparing
prompting, tool-use, and code generation; dataset domains, spanning citation,
web-link, e-commerce, and social networks; structural regimes contrasting
homophilic and heterophilic graphs; feature characteristics involving both
short- and long-text node attributes; and model configurations with varying LLM
sizes and reasoning capabilities. We further analyze dependencies by
methodically truncating features, deleting edges, and removing labels to
quantify reliance on input types. Our findings provide practical and actionable
guidance. (1) LLMs as code generators achieve the strongest overall performance
on graph data, with especially large gains on long-text or high-degree graphs
where prompting quickly exceeds the token budget. (2) All interaction
strategies remain effective on heterophilic graphs, challenging the assumption
that LLM-based methods collapse under low homophily. (3) Code generation is
able to flexibly adapt its reliance between structure, features, or labels to
leverage the most informative input type. Together, these findings provide a
comprehensive view of the strengths and limitations of current LLM-graph
interaction modes and highlight key design principles for future approaches.

</details>


### [30] [A Rhythm-Aware Phrase Insertion for Classical Arabic Poetry Composition](https://arxiv.org/abs/2509.18514)
*Mohamad Elzohbi,Richard Zhao*

Main category: cs.CL

TL;DR: 本文提出结合ByT5和节拍规则，将短语插入阿拉伯诗歌时实现高韵律一致性和语义连贯性，为阿拉伯诗歌创作提供有力支持。


<details>
  <summary>Details</summary>
Motivation: 对阿拉伯诗歌插入短语时，如何保证插入内容符合特定韵律，以支持古典诗歌的创作。

Method: 提出了一种基于ByT5（字节级多语Transformer模型）方法，结合规则驱动的字素到节拍转换，采用条件去噪目标对ByT5进行微调，并用课程学习方法先在通用数据训练，再在诗歌数据上微调，同时探索了英文到阿拉伯文的跨语迁移。

Result: 实验结果表明，该模型能够实现高水平的节奏对齐，同时保证语义连贯性。

Conclusion: 所提模型有潜力用于协同创作古典阿拉伯诗歌，为自动生成符合韵律需求的诗句提供有效工具。

Abstract: This paper presents a methodology for inserting phrases in Arabic poems to
conform to a specific rhythm using ByT5, a byte-level multilingual
transformer-based model. Our work discusses a rule-based grapheme-to-beat
transformation tailored for extracting the rhythm from fully diacritized Arabic
script. Our approach employs a conditional denoising objective to fine-tune
ByT5, where the model reconstructs masked words to match a target rhythm. We
adopt a curriculum learning strategy, pre-training on a general Arabic dataset
before fine-tuning on poetic dataset, and explore cross-lingual transfer from
English to Arabic. Experimental results demonstrate that our models achieve
high rhythmic alignment while maintaining semantic coherence. The proposed
model has the potential to be used in co-creative applications in the process
of composing classical Arabic poems.

</details>


### [31] [Trace Is In Sentences: Unbiased Lightweight ChatGPT-Generated Text Detector](https://arxiv.org/abs/2509.18535)
*Mo Mu,Dianqiao Lei,Chang Li*

Main category: cs.CL

TL;DR: 提出了不用大模型和在线LLM的新型轻量结构检测框架，能准确检测原版及被词级修改的AI文本，规避原文偏见和数据偏差，在实测数据集表现优越。


<details>
  <summary>Details</summary>
Motivation: 由于ChatGPT等AI文本生成工具广泛使用，现有检测方法容易被词级修改（如换句话说/paraphrasing等）规避，且存在模型偏见、对修改文本准确性下降等问题，亟需更鲁棒且高效的检测方案。

Method: 提出了一种基于文本内部结构的轻量级检测框架，利用预训练语言模型获得句子嵌入，并通过注意力机制建模句子关系。采用对比学习减少嵌入偏差，并引入因果图及反事实技术隔离结构特征与主题相关偏差。

Result: 实验表明，该方法在两个数据集（摘要比对和FAQ问答文本）上均取得优越的检测效果，验证了其有效性和鲁棒性。

Conclusion: 新方法能够有效识别原始及经过词级修改的AI生成文本，且比现有方法更鲁棒、更高效。

Abstract: The widespread adoption of ChatGPT has raised concerns about its misuse,
highlighting the need for robust detection of AI-generated text. Current
word-level detectors are vulnerable to paraphrasing or simple prompts (PSP),
suffer from biases induced by ChatGPT's word-level patterns (CWP) and training
data content, degrade on modified text, and often require large models or
online LLM interaction. To tackle these issues, we introduce a novel task to
detect both original and PSP-modified AI-generated texts, and propose a
lightweight framework that classifies texts based on their internal structure,
which remains invariant under word-level changes. Our approach encodes sentence
embeddings from pre-trained language models and models their relationships via
attention. We employ contrastive learning to mitigate embedding biases from
autoregressive generation and incorporate a causal graph with counterfactual
methods to isolate structural features from topic-related biases. Experiments
on two curated datasets, including abstract comparisons and revised life FAQs,
validate the effectiveness of our method.

</details>


### [32] [CCQA: Generating Question from Solution Can Improve Inference-Time Reasoning in SLMs](https://arxiv.org/abs/2509.18536)
*Jin Young Kim,Ji Won Yoon*

Main category: cs.CL

TL;DR: 提出了CCQA循环一致性问答推理方法，在8个小型语言模型推理任务中均优于现有SOTA结果，尤其擅长数学与常识推理，并建立了新的高效推理基线。


<details>
  <summary>Details</summary>
Motivation: 目前基于推理策略在大语言模型（LLM）推理准确性上已有提升，但在更小规模的语言模型（SLM）上效果不佳。传统方法在SLM中的性能提升有限，亟需新方案。

Method: 提出了一种基于Cycle-Consistency的问答推理方法CCQA。具体地，对每条推理路径及其答案生成问题，以生成的问题与原问题的相似性为分数，分数最高的答案被选为最终结果。为提升SLM问题生成能力，使用一个专门精炼于问题生成的轻量级Flan-T5模型辅助此过程。

Result: 实验显示，CCQA在8个模型上的数学与常识推理基准测试中均优于现有最先进方法，表现出一致的性能提升。

Conclusion: CCQA为SLM推理建立了更高效的新实用基线，并显著提升SLM在数学与常识推理任务上的性能。

Abstract: Recently, inference-time reasoning strategies have further improved the
accuracy of large language models (LLMs), but their effectiveness on smaller
models remains unclear. Based on the observation that conventional approaches
often fail to improve performance in this context, we propose
\textbf{C}ycle-\textbf{C}onsistency in \textbf{Q}uestion \textbf{A}nswering
(CCQA), a novel reasoning method that can be effectively applied to SLMs.
Inspired by cycle consistency, CCQA generates a question from each reasoning
path and answer, evaluates each by its similarity to the original question, and
then selects the candidate solution with the highest similarity score as the
final response. Since conventional SLMs struggle to generate accurate questions
from their own reasoning paths and answers, we employ a lightweight Flan-T5
model specialized for question generation to support this process efficiently.
From the experimental results, it is verified that CCQA consistently
outperforms existing state-of-the-art (SOTA) methods across eight models on
mathematical and commonsense reasoning benchmarks. Furthermore, our method
establishes a new practical baseline for efficient reasoning in SLMs. Source
code can be found at https://github.com/scai-research/ccqa_official.

</details>


### [33] [Prior-based Noisy Text Data Filtering: Fast and Strong Alternative For Perplexity](https://arxiv.org/abs/2509.18577)
*Yeongbin Seo,Gayoung Kim,Jaehyung Kim,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 作者提出了一种无需推断、基于词统计的高效数据筛选方法，在速度与效果上均优于传统PPL筛选，并适用于多语种和符号化场景。


<details>
  <summary>Details</summary>
Motivation: 以往利用PPL（困惑度）筛选大规模语言模型的预训练数据效果不错，但存在耗时高、模型对噪声和分布外样本不可靠的问题，因此需要更高效可靠的数据筛选方法。

Method: 提出了一种基于先验的简单高效数据筛选方法：利用语料库词频等统计量估算token发生的先验概率，然后基于token先验的均值及标准差进行文档筛选，无需模型推断。

Result: 该方法在20个下游任务中获得了最佳平均性能，且在耗时上相较PPL筛选提升超过1000倍。同时对代码、数学等符号语言适用，并能够自适应多语种语料。

Conclusion: 基于先验的数据筛选法无需推断、计算速度极快，筛选效果优越，能广泛适用于各种类型与多语种大模型训练数据筛选场景。

Abstract: As large language models (LLMs) are pretrained on massive web corpora,
careful selection of data becomes essential to ensure effective and efficient
learning. While perplexity (PPL)-based filtering has shown strong performance,
it suffers from drawbacks: substantial time costs and inherent unreliability of
the model when handling noisy or out-of-distribution samples. In this work, we
propose a simple yet powerful alternative: a prior-based data filtering method
that estimates token priors using corpus-level term frequency statistics,
inspired by linguistic insights on word roles and lexical density. Our approach
filters documents based on the mean and standard deviation of token priors,
serving as a fast proxy to PPL while requiring no model inference. Despite its
simplicity, the prior-based filter achieves the highest average performance
across 20 downstream benchmarks, while reducing time cost by over 1000x
compared to PPL-based filtering. We further demonstrate its applicability to
symbolic languages such as code and math, and its dynamic adaptability to
multilingual corpora without supervision

</details>


### [34] [TsqLoRA: Towards Sensitivity and Quality Low-Rank Adaptation for Efficient Fine-Tuning](https://arxiv.org/abs/2509.18585)
*Yu Chen,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: TsqLoRA通过结合高质量数据采样和层级敏感度动态秩分配，显著降低了大模型微调的计算和内存需求，同时保持甚至提升模型性能，适合资源受限场景下高效NLP微调。


<details>
  <summary>Details</summary>
Motivation: 大规模预训练模型在NLP领域广泛应用，但全部参数微调计算和内存开销巨大，尤其在资源有限环境下尤为突出。现有高效微调方法虽然减少了可训练参数量，但忽视了模型层敏感性和训练数据质量的重要性。

Method: 提出了TsqLoRA方法，创新性地结合了数据质量驱动的数据选择与对模型层敏感度感知的低秩适配。具体包括两个组件：一是基于训练数据质量的采样机制，优先选择信息量大的数据；二是动态分配每层低秩分解的秩，根据各层对参数更新的敏感性调整秩大小。

Result: 实验结果表明，TsqLoRA在多项NLP任务上提升了微调效率，并能保持甚至提升模型性能。

Conclusion: TsqLoRA能够高效、有效地微调大模型，在效率和性能之间取得良好平衡。

Abstract: Fine-tuning large pre-trained models for downstream tasks has become a
fundamental approach in natural language processing. Fully fine-tuning all
model parameters is computationally expensive and memory-intensive, especially
in resource-constrained environments. Existing parameter-efficient fine-tuning
methods reduce the number of trainable parameters but typically overlook the
varying sensitivity of different model layers and the importance of training
data. In this work, we propose TsqLoRA, a novel method that integrates
data-quality-driven selection with sensitivity-aware low-rank adaptation,
consisted of two main components: a quality-aware sampling mechanism for
selecting the most informative training data, and a dynamic rank allocation
module that adjusts the rank of each layer based on its sensitivity to
parameter updates. The experimental results demonstrate that TsqLoRA improves
fine-tuning efficiency while maintaining or even improving performance on a
variety of NLP tasks. Our code will be available at
https://github.com/Benjamin-Ricky/TsqLoRA.

</details>


### [35] [UniECG: Understanding and Generating ECG in One Unified Model](https://arxiv.org/abs/2509.18588)
*Jiarui Jin,Haoyu Wang,Xiang Lan,Jun Li,Gaofeng Cheng,Hongyan Li,Shenda Hong*

Main category: cs.CL

TL;DR: UniECG是首个能够同时进行心电图解释和生成的统一模型，通过两阶段训练，实现了医疗领域的多任务能力提升。


<details>
  <summary>Details</summary>
Motivation: 现有的统一模型（如GPT-5）在视觉-语言任务上取得了进展，但在心电图（ECG）信号理解和生成方面存在明显局限，无法满足医疗诊断需求。

Method: 采用了解耦的两阶段训练方法：首先训练ECG到文本的解释能力，然后通过潜在空间对齐注入文本到ECG的生成能力。

Result: UniECG能够根据用户输入自主选择心电图解读或生成任务，显著拓展了当前ECG模型的能力边界。相关代码和模型检查点将在开源平台公开。

Conclusion: UniECG模型扩展了现有ECG模型的能力，实现了基于证据的心电图解读和文本条件下的心电图生成。

Abstract: Recent unified models such as GPT-5 have achieved encouraging progress on
vision-language tasks. However, these unified models typically fail to
correctly understand ECG signals and provide accurate medical diagnoses, nor
can they correctly generate ECG signals. To address these limitations, we
propose UniECG, the first unified model for ECG capable of concurrently
performing evidence-based ECG interpretation and text-conditioned ECG
generation tasks. Through a decoupled two-stage training approach, the model
first learns evidence-based interpretation skills (ECG-to-Text), and then
injects ECG generation capabilities (Text-to-ECG) via latent space alignment.
UniECG can autonomously choose to interpret or generate an ECG based on user
input, significantly extending the capability boundaries of current ECG models.
Our code and checkpoints will be made publicly available at
https://github.com/PKUDigitalHealth/UniECG upon acceptance.

</details>


### [36] [A Good Plan is Hard to Find: Aligning Models with Preferences is Misaligned with What Helps Users](https://arxiv.org/abs/2509.18632)
*Nishant Balepur,Matthew Shu,Yoo Yeon Sung,Seraphina Goldfarb-Tarrant,Shi Feng,Fumeng Yang,Rachel Rudinger,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: 大模型计划生成如果仅依据用户偏好进行对齐，会和真正的用户帮助发生偏离。真实用户交互反馈比偏好更能指导模型对齐，未来应着重从真实互动中优化计划有效性。


<details>
  <summary>Details</summary>
Motivation: 现有大模型计划生成主要依据用户偏好进行训练和评估，假定用户偏好等同于真正对用户有帮助，但这一假设并未被充分检验。作者希望评估偏好与真正帮助之间的实际差异。

Method: 作者提出Planorama平台，邀请126名用户基于大语言模型计划解决300个多步骤问题，收集4388个执行案例和5584组计划对比，用于分析用户成功率和计划偏好。实验还在智能体和奖励模型中复现该流程，以观测模型本身的偏好及其与用户实际帮助的关系。

Result: 实验证明用户/模型偏好与真实帮助（即QA成功率）之间高度不一致。常见的对齐方式可能反而会和“有帮助”产生偏离。用户自身偏好与帮助率无强关联，表面特征如简洁性和与问题的相似度虽能影响偏好，但无法有效预测真实帮助程度。

Conclusion: 仅用用户偏好去指导大模型计划生成存在局限，无法保障实际帮助用户。模型需要借助真实用户交互反馈进行对齐，不能只基于外观上“看似有帮助”的偏好。作者建议NLP社区设计基于真实用户互动的反馈机制以提升计划的有效性。

Abstract: To assist users in complex tasks, LLMs generate plans: step-by-step
instructions towards a goal. While alignment methods aim to ensure LLM plans
are helpful, they train (RLHF) or evaluate (ChatbotArena) on what users prefer,
assuming this reflects what helps them. We test this with Planorama: an
interface where 126 users answer 300 multi-step questions with LLM plans. We
get 4388 plan executions and 5584 comparisons to measure plan helpfulness (QA
success) and user preferences on plans, and recreate the setup in agents and
reward models to see if they simulate or prefer what helps users. We expose: 1)
user/model preferences and agent success do not accurately predict which plans
help users, so common alignment feedback can misalign with helpfulness; 2) this
gap is not due to user-specific preferences, as users are similarly successful
when using plans they prefer/disprefer; 3) surface-level cues like brevity and
question similarity strongly link to preferences, but such biases fail to
predict helpfulness. In all, we argue aligning helpful LLMs needs feedback from
real user interactions, not just preferences of what looks helpful, so we
discuss the plan NLP researchers can execute to solve this problem.

</details>


### [37] [Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop Question Answering](https://arxiv.org/abs/2509.18655)
*Lingwen Deng,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: 本文提出了针对多跳问答任务的一致性增强型知识编辑框架CAPE-KG，有效提升了知识更新后的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱的PPKE方法在多跳推理时一致性较差，导致知识污染和更新不稳定，从而影响知识编辑的可靠性。

Method: 提出了CAPE-KG框架，使知识图谱的构建、更新和检索与多跳问答的需求保持一致，解决了现有方法中的一致性问题。

Result: 在MQuAKE基准上的广泛实验表明，CAPE-KG显著提升了PPKE在多跳问答中的准确性，证实了提升一致性后的有效性。

Conclusion: CAPE-KG有效提升了参数保持型知识编辑（PPKE）在多跳问答任务中的一致性和可靠性。

Abstract: Parameter-Preserving Knowledge Editing (PPKE) enables updating models with
new or corrected information without retraining or parameter adjustment. Recent
PPKE approaches based on knowledge graphs (KG) to extend knowledge editing (KE)
capabilities to multi-hop question answering (MHQA). However, these methods
often lack consistency, leading to knowledge contamination, unstable updates,
and retrieval behaviors that fail to reflect the intended edits. Such
inconsistencies undermine the reliability of PPKE in multi- hop reasoning. We
present CAPE-KG, Consistency-Aware Parameter-Preserving Editing with Knowledge
Graphs, a novel consistency-aware framework for PPKE on MHQA. CAPE-KG ensures
KG construction, update, and retrieval are always aligned with the requirements
of the MHQA task, maintaining coherent reasoning over both unedited and edited
knowledge. Extensive experiments on the MQuAKE benchmark show accuracy
improvements in PPKE performance for MHQA, demonstrating the effectiveness of
addressing consistency in PPKE.

</details>


### [38] [Analyzing Uncertainty of LLM-as-a-Judge: Interval Evaluations with Conformal Prediction](https://arxiv.org/abs/2509.18658)
*Huanxin Sheng,Xinyi Liu,Hangfeng He,Jieyu Zhao,Jian Kang*

Main category: cs.CL

TL;DR: LLM在NLG评估中的不确定性影响其可靠性。本文用保形预测为评分提供预测区间，并设计新方法提升评分准确性，通过实验验证有效性。


<details>
  <summary>Details</summary>
Motivation: LLM被广泛用于自然语言生成（NLG）的评估，但其评估的不确定性问题尚未充分研究，影响了在实际应用中的可靠性。

Method: 提出了利用保形预测（conformal prediction）为LLM评估得分提供预测区间的框架，并针对离散评分任务设计了序数边界调整。同时提出区间中点作为较低偏差的评分方法。

Result: 实验表明，保形预测可以为LLM评分提供有效的、带有覆盖保证的预测区间。区间中点和多次提问（judge reprompting）能提升评判结果的可靠性。

Conclusion: 本文首次为LLM评估NLG任务建立了不确定性分析框架，有效提升了评分结果的可靠性及解释性。

Abstract: LLM-as-a-judge has become a promising paradigm for using large language
models (LLMs) to evaluate natural language generation (NLG), but the
uncertainty of its evaluation remains underexplored. This lack of reliability
may limit its deployment in many applications. This work presents the first
framework to analyze the uncertainty by offering a prediction interval of
LLM-based scoring via conformal prediction. Conformal prediction constructs
continuous prediction intervals from a single evaluation run, and we design an
ordinal boundary adjustment for discrete rating tasks. We also suggest a
midpoint-based score within the interval as a low-bias alternative to raw model
score and weighted average. We perform extensive experiments and analysis,
which show that conformal prediction can provide valid prediction interval with
coverage guarantees. We also explore the usefulness of interval midpoint and
judge reprompting for better judgment.

</details>


### [39] [MemOrb: A Plug-and-Play Verbal-Reinforcement Memory Layer for E-Commerce Customer Service](https://arxiv.org/abs/2509.18713)
*Yizhe Huang,Yang Liu,Ruiyu Zhao,Xiaolong Zhong,Xingming Yue,Ling Jiang*

Main category: cs.CL

TL;DR: MemOrb是一种新的记忆层方法，无需微调，通过策略反思提升LLM代理在客户服务中的稳定性与成功率，实验显示性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 目前基于大语言模型（LLM）的代理在客户服务中的应用越来越广泛，但存在遗忘、重复错误、以及缺乏持续自我改进机制等问题。这使得它们在需要稳定性和一致性的动态环境中表现不可靠。作者希望解决这些问题，提升LLM代理的稳定性和持久表现。

Method: 作者提出了MemOrb，一种轻量且可插拔的口头强化记忆层。MemOrb将多轮交互提炼为简明的策略反思，并存储于共享记忆库中，在不需要微调的情况下检索出来以引导决策。

Result: 实验结果表明，MemOrb显著提升了成功率和系统稳定性，在多轮交互任务中成功率最高提升了63个百分点，并且在多次重复实验中表现更加一致。

Conclusion: 结构化反思是增强冻结LLM代理在客户服务场景下长期可靠性的强大机制。

Abstract: Large Language Model-based agents(LLM-based agents) are increasingly deployed
in customer service, yet they often forget across sessions, repeat errors, and
lack mechanisms for continual self-improvement. This makes them unreliable in
dynamic settings where stability and consistency are critical. To better
evaluate these properties, we emphasize two indicators: task success rate as a
measure of overall effectiveness, and consistency metrics such as Pass$^k$ to
capture reliability across multiple trials. To address the limitations of
existing approaches, we propose MemOrb, a lightweight and plug-and-play verbal
reinforcement memory layer that distills multi-turn interactions into compact
strategy reflections. These reflections are stored in a shared memory bank and
retrieved to guide decision-making, without requiring any fine-tuning.
Experiments show that MemOrb significantly improves both success rate and
stability, achieving up to a 63 percentage-point gain in multi-turn success
rate and delivering more consistent performance across repeated trials. Our
results demonstrate that structured reflection is a powerful mechanism for
enhancing long-term reliability of frozen LLM agents in customer service
scenarios.

</details>


### [40] [LOTUSDIS: A Thai far-field meeting corpus for robust conversational ASR](https://arxiv.org/abs/2509.18722)
*Pattara Tipaksorn,Sumonmas Thatphithakkul,Vataya Chunwijitra,Kwanchiva Thangthai*

Main category: cs.CL

TL;DR: 作者公开了一个泰语远场对话语音数据集并提供基线系统，微调后大幅提升Whisper模型在远距离的识别性能，强调了多距离数据对ASR鲁棒性的重要性。


<details>
  <summary>Details</summary>
Motivation: 针对泰语远场对话语音识别（ASR）领域数据和研究方法匮乏的问题，研究者开发了一个公开的泰语会议语料库，以推动远场ASR的进步。

Method: 采集了114小时真人自发对话，三人小组自由交谈，录制使用6类9台独立录音设备，摆放距离从0.12米到10米，涵盖丰富的话筒距离和重叠语音情形。数据集区分训练、开发、测试集，并构建了可复现的基线ASR系统，评估了Whisper多种模型（零样本与微调两种方式）。

Result: Whisper原始模型在处理远场泰语语音时性能大幅下降，微调后显著提升：整体WER由64.3降至38.3，远场WER由81.6降至49.5，尤其在最远麦克风处提升最为明显。

Conclusion: 距离多样化数据对远场ASR系统的稳健性至关重要。LOTUSDIS语料库以及开放的基线系统推动了可复现的泰语远场ASR研究。

Abstract: We present LOTUSDIS, a publicly available Thai meeting corpus designed to
advance far-field conversational ASR. The dataset comprises 114 hours of
spontaneous, unscripted dialogue collected in 15-20 minute sessions with three
participants, where overlapping speech is frequent and natural. Speech was
recorded simultaneously by nine independent single-channel devices spanning six
microphone types at distances from 0.12 m to 10 m, preserving the authentic
effects of reverberation, noise, and device coloration without relying on
microphone arrays. We provide standard train, dev, test splits and release a
reproducible baseline system. We benchmarked several Whisper variants under
zero-shot and fine-tuned conditions. Off-the-shelf models showed strong
degradation with distance, confirming a mismatch between pre-training data and
Thai far-field speech. Fine-tuning on LOTUSDIS dramatically improved
robustness: a Thai Whisper baseline reduced overall WER from 64.3 to 38.3 and
far-field WER from 81.6 to 49.5, with especially large gains on the most
distant microphones. These results underscore the importance of
distance-diverse training data for robust ASR. The corpus is available under
CC-BY-SA 4.0. We also release training and evaluation scripts as a baseline
system to promote reproducible research in this field.

</details>


### [41] [Global-Recent Semantic Reasoning on Dynamic Text-Attributed Graphs with Large Language Models](https://arxiv.org/abs/2509.18742)
*Yunan Wang,Jianxin Li,Ziwei Zhang*

Main category: cs.CL

TL;DR: 提出了结合LLMs与时序GNN的新方法DyGRASP，用创新机制高效处理动态图中的文本与结构语义演化，实验显著提升检索性能并具备良好泛化性。


<details>
  <summary>Details</summary>
Motivation: 动态文本属性图（DyTAGs）广泛存在于真实应用中，但现有方法多关注于静态TAG，未能有效处理DyTAG中的时序文本语义演变，以及如何高效使用LLMs处理海量动态文本面临挑战。

Method: 提出DyGRASP方法，结合LLMs和时序GNNs，通过节点中心的隐式推理与滑动窗口机制高效捕捉近期语义，同时利用针对性prompt与类似RNN链式结构进行显式推理，以捕捉节点的长期语义动态。随后，通过更新和融合层有效整合近期和长期语义以及动态图结构信息。

Result: 在DyTAG基准任务上，DyGRASP在目标节点检索（Hit@10）指标上提升高达34%。此外，DyGRASP泛化能力强，能适配不同类型的时序GNN与LLMs。

Conclusion: DyGRASP高效融合近期和全局语义，能有效解决DyTAG时序语义推理与效率问题，在性能和泛化性方面均优于现有方法。

Abstract: Dynamic Text-Attribute Graphs (DyTAGs), characterized by time-evolving graph
interactions and associated text attributes, are prevalent in real-world
applications. Existing methods, such as Graph Neural Networks (GNNs) and Large
Language Models (LLMs), mostly focus on static TAGs. Extending these existing
methods to DyTAGs is challenging as they largely neglect the recent-global
temporal semantics: the recent semantic dependencies among interaction texts
and the global semantic evolution of nodes over time. Furthermore, applying
LLMs to the abundant and evolving text in DyTAGs faces efficiency issues. To
tackle these challenges, we propose Dynamic Global-Recent Adaptive Semantic
Processing (DyGRASP), a novel method that leverages LLMs and temporal GNNs to
efficiently and effectively reason on DyTAGs. Specifically, we first design a
node-centric implicit reasoning method together with a sliding window mechanism
to efficiently capture recent temporal semantics. In addition, to capture
global semantic dynamics of nodes, we leverage explicit reasoning with tailored
prompts and an RNN-like chain structure to infer long-term semantics. Lastly,
we intricately integrate the recent and global temporal semantics as well as
the dynamic graph structural information using updating and merging layers.
Extensive experiments on DyTAG benchmarks demonstrate DyGRASP's superiority,
achieving up to 34% improvement in Hit@10 for destination node retrieval task.
Besides, DyGRASP exhibits strong generalization across different temporal GNNs
and LLMs.

</details>


### [42] [False Friends Are Not Foes: Investigating Vocabulary Overlap in Multilingual Language Models](https://arxiv.org/abs/2509.18750)
*Julie Kallini,Dan Jurafsky,Christopher Potts,Martijn Bartelds*

Main category: cs.CL

TL;DR: 本文系统实验发现，跨语言共享词元（尤其有语义关联）有助于多语言模型的迁移和语义能力，建议多语言分词器设计中应优先考虑词表共享。


<details>
  <summary>Details</summary>
Motivation: 多语言模型中的子词分词器在不同语言间自然会产生重叠的词元，但这些重叠究竟是促进跨语言迁移还是引入干扰，现有研究结论不一且受各种变量影响。为厘清这一问题，作者希望以更严格的方法探究词元重叠及其语义相似度如何影响跨语言迁移。

Method: 作者设计了一个受控实验，训练多对双语自回归模型，并系统性改变各自的词表重叠程度；同时分析共享词元的语义相似度对跨语言迁移的影响。采用了模型隐藏表示分析，及在XNLI和XQuAD上的迁移性能评测。

Result: 实验发现，无论何种类型的词元重叠，都能让嵌入空间捕捉跨语言语义关系，而词表完全不重叠时这一效果明显减弱。在下游任务XNLI和XQuAD上，有词元重叠的模型性能优于完全独立词表，且重叠越多表现越好。

Conclusion: 词元重叠能显著改善多语言模型中的跨语言迁移与语义表示，说明共享词表对于多语言分词器是有益的设计选择。

Abstract: Subword tokenizers trained on multilingual corpora naturally produce
overlapping tokens across languages. Does token overlap facilitate
cross-lingual transfer or instead introduce interference between languages?
Prior work offers mixed evidence, partly due to varied setups and confounders,
such as token frequency or subword segmentation granularity. To address this
question, we devise a controlled experiment where we train bilingual
autoregressive models on multiple language pairs under systematically varied
vocabulary overlap settings. Crucially, we explore a new dimension to
understanding how overlap affects transfer: the semantic similarity of tokens
shared across languages. We first analyze our models' hidden representations
and find that overlap of any kind creates embedding spaces that capture
cross-lingual semantic relationships, while this effect is much weaker in
models with disjoint vocabularies. On XNLI and XQuAD, we find that models with
overlap outperform models with disjoint vocabularies, and that transfer
performance generally improves as overlap increases. Overall, our findings
highlight the advantages of token overlap in multilingual models and show that
substantial shared vocabulary remains a beneficial design choice for
multilingual tokenizers.

</details>


### [43] [When Long Helps Short: How Context Length in Supervised Fine-tuning Affects Behavior of Large Language Models](https://arxiv.org/abs/2509.18762)
*Yingming Zheng,Hanqi Li,Kai Yu,Lu Chen*

Main category: cs.CL

TL;DR: 长文本SFT可提升短文本任务表现，但存在知识偏置，混合训练方案更优。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在自然语言处理任务中取得优异成绩，对更长上下文处理能力的需求日益增加。虽然延续预训练时数据长度的影响被广泛研究，但其在有监督微调（SFT）阶段的影响尚不明确。本文旨在系统性地探索SFT时长文本数据对短文本任务表现的作用。

Method: 系统性研究SFT数据长度对大语言模型在短上下文任务中表现的影响，分别分析多头注意力（MHA）和前馈神经网络（FFN）组件，并研究它们之间的交互与知识偏好偏置。同时，验证混合训练能否缓解偏置。

Result: （1）长上下文SFT反而提升了模型在短上下文任务上的表现，与当前长上下文预训练下降的常见观点相反；（2）MHA和FFN两个模块独立均能受益于长文本SFT；（3）长文本SFT更促进上下文知识，短文本SFT更倾向参数知识，只用长文本SFT会有偏置问题；（4）混合训练能有效减轻该偏置。

Conclusion: 只用长文本SFT并非最优策略，应采用混合训练以平衡不同类型知识的习得，从而为大语言模型微调提供解释性指导。

Abstract: Large language models (LLMs) have achieved impressive performance across
natural language processing (NLP) tasks. As real-world applications
increasingly demand longer context windows, continued pretraining and
supervised fine-tuning (SFT) on long-context data has become a common approach.
While the effects of data length in continued pretraining have been extensively
studied, their implications for SFT remain unclear. In this work, we
systematically investigate how SFT data length influences LLM behavior on
short-context tasks. Counterintuitively, we find that long-context SFT improves
short-context performance, contrary to the commonly observed degradation from
long-context pretraining. To uncover the underlying mechanisms of this
phenomenon, we first decouple and analyze two key components, Multi-Head
Attention (MHA) and Feed-Forward Network (FFN), and show that both
independently benefit from long-context SFT. We further study their interaction
and reveal a knowledge preference bias: long-context SFT promotes contextual
knowledge, while short-context SFT favors parametric knowledge, making
exclusive reliance on long-context SFT suboptimal. Finally, we demonstrate that
hybrid training mitigates this bias, offering explainable guidance for
fine-tuning LLMs.

</details>


### [44] [Financial Risk Relation Identification through Dual-view Adaptation](https://arxiv.org/abs/2509.18775)
*Wei-Ning Chiu,Yu-Hsiang Wang,Andy Hsiao,Yu-Shiang Huang,Chuan-Ju Wang*

Main category: cs.CL

TL;DR: 本论文提出了一种基于10-K财报和自然语言处理的新方法，自动、客观地识别公司间风险关系，实验结果显示新方法效果优于主流模型，为金融风险管理带来更高效和可靠的工具。


<details>
  <summary>Details</summary>
Motivation: 现有的公司间风险关系识别主要依靠专家判断和人工分析，过程主观、费力且难以扩展，随着风险事件（如监管变动、地缘政治紧张）频繁发生，需要更高效、系统的方法来分析公司间的风险关联。

Method: 利用10-K表格等权威、标准化财务文件作为数据源，结合自然语言处理前沿技术，通过无监督微调手段挖掘文件的时序和词汇模式，以此建立领域专用金融文本编码器，并提出透明、可解释的定量风险关联评分方法。

Result: 提出的方法在多个评估设置下均优于当前强基线模型，有效地识别和量化公司间的风险关系。

Conclusion: 该系统化方法能够高效、客观地分析公司间的风险关系，为投资组合管理和投资策略等领域提供更透明、可扩展的风险评估工具。

Abstract: A multitude of interconnected risk events -- ranging from regulatory changes
to geopolitical tensions -- can trigger ripple effects across firms.
Identifying inter-firm risk relations is thus crucial for applications like
portfolio management and investment strategy. Traditionally, such assessments
rely on expert judgment and manual analysis, which are, however, subjective,
labor-intensive, and difficult to scale. To address this, we propose a
systematic method for extracting inter-firm risk relations using Form 10-K
filings -- authoritative, standardized financial documents -- as our data
source. Leveraging recent advances in natural language processing, our approach
captures implicit and abstract risk connections through unsupervised
fine-tuning based on chronological and lexical patterns in the filings. This
enables the development of a domain-specific financial encoder with a deeper
contextual understanding and introduces a quantitative risk relation score for
transparency, interpretable analysis. Extensive experiments demonstrate that
our method outperforms strong baselines across multiple evaluation settings.

</details>


### [45] [AECBench: A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field](https://arxiv.org/abs/2509.18776)
*Chen Liang,Zhaoqi Huang,Haofen Wang,Fu Chai,Chunying Yu,Huanhuan Wei,Zhengjie Liu,Yanpeng Li,Hongjun Wang,Ruifeng Luo,Xianzhong Zhao*

Main category: cs.CL

TL;DR: 通过构建AECBench基准，系统评估了现有LLM在建筑工程领域多认知任务上的强弱。结果显示现有模型在基础任务上表现尚可，但在高阶实际应用中仍有明显短板，为后续研究和应用提供参考。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）在建筑、工程和施工（AEC）领域的广泛应用，其能显著提升建筑全生命周期流程效率，但其在专业性强且安全关键的领域内的可靠性和稳健性还未得到系统评估。为解决这一挑战，本文提出了专门的评测基准。

Method: 提出并构建了AECBench基准，包括基于五级认知框架的23项典型任务。框架覆盖知识记忆、理解、推理、计算、应用，任务内容源于实际AEC场景。设计了含多种格式的4800道题，由工程师制定并经专家双轮审核。评价方法创新地采用“LLM评判者”机制，根据专家评分标准对复杂问答结果进行一致且可扩展的评估。

Result: 对9个主流LLM的评测揭示其在五个认知层级上性能逐级下降。虽然在基础的知识记忆和理解层表现较好，但在执行复杂推理、计算、读取建筑规范表格、生成专用文件等高级任务上存在明显不足。

Conclusion: 本文奠定了未来将LLMs稳健、可靠地集成至安全关键工程实践的基础，为该领域进一步研发和应用指明了方向。

Abstract: Large language models (LLMs), as a novel information technology, are seeing
increasing adoption in the Architecture, Engineering, and Construction (AEC)
field. They have shown their potential to streamline processes throughout the
building lifecycle. However, the robustness and reliability of LLMs in such a
specialized and safety-critical domain remain to be evaluated. To address this
challenge, this paper establishes AECBench, a comprehensive benchmark designed
to quantify the strengths and limitations of current LLMs in the AEC domain.
The benchmark defines 23 representative tasks within a five-level
cognition-oriented evaluation framework encompassing Knowledge Memorization,
Understanding, Reasoning, Calculation, and Application. These tasks were
derived from authentic AEC practice, with scope ranging from codes retrieval to
specialized documents generation. Subsequently, a 4,800-question dataset
encompassing diverse formats, including open-ended questions, was crafted
primarily by engineers and validated through a two-round expert review.
Furthermore, an LLM-as-a-Judge approach was introduced to provide a scalable
and consistent methodology for evaluating complex, long-form responses
leveraging expert-derived rubrics. Through the evaluation of nine LLMs, a clear
performance decline across five cognitive levels was revealed. Despite
demonstrating proficiency in foundational tasks at the Knowledge Memorization
and Understanding levels, the models showed significant performance deficits,
particularly in interpreting knowledge from tables in building codes, executing
complex reasoning and calculation, and generating domain-specific documents.
Consequently, this study lays the groundwork for future research and
development aimed at the robust and reliable integration of LLMs into
safety-critical engineering practices.

</details>


### [46] [Beyond the Leaderboard: Understanding Performance Disparities in Large Language Models via Model Diffing](https://arxiv.org/abs/2509.18792)
*Sabri Boughorbel,Fahim Dalvi,Nadir Durrani,Majd Hawasly*

Main category: cs.CL

TL;DR: 本文采用模型对比技术，细致分析了两款大语言模型微调后的能力差异，发现SimPO增强版在安全、多语言和指令遵从上有显著提升，同时减少对自我指涉与幻觉管理的关注。该方法为理解模型性能差异提供了新的解释工具。


<details>
  <summary>Details</summary>
Motivation: 随着微调成为提升大语言模型性能的主流方法，了解微调过程中模型发生的具体变化变得越来越重要。传统的基准测试往往无法解释一个模型为何优于另一个模型。

Method: 采用模型对比（model diffing）方法，这是一种机械可解释性分析技术。具体通过crosscoders工具，识别并分类两款模型（Gemma-2-9b-it与SimPO增强版）之间的潜在表示差异。

Result: SimPO通过额外训练获得的潜在概念主要增强了安全机制（提升32.8%）、多语言能力（提升43.8%）和指令遵从性（提升151.7%）；同时对模型自我指涉（降低44.1%）和幻觉管理能力（降低68.5%）的关注有所减少。

Conclusion: 模型对比分析不仅能揭示排行榜无法体现的细粒度能力差异，也能将性能差距归因到具体的机械能力，为大语言模型的对比提供了透明、可针对性的分析框架。

Abstract: As fine-tuning becomes the dominant paradigm for improving large language
models (LLMs), understanding what changes during this process is increasingly
important. Traditional benchmarking often fails to explain why one model
outperforms another. In this work, we use model diffing, a mechanistic
interpretability approach, to analyze the specific capability differences
between Gemma-2-9b-it and a SimPO-enhanced variant. Using crosscoders, we
identify and categorize latent representations that differentiate the two
models. We find that SimPO acquired latent concepts predominantly enhance
safety mechanisms (+32.8%), multilingual capabilities (+43.8%), and
instruction-following (+151.7%), while its additional training also reduces
emphasis on model self-reference (-44.1%) and hallucination management
(-68.5%). Our analysis shows that model diffing can yield fine-grained insights
beyond leaderboard metrics, attributing performance gaps to concrete
mechanistic capabilities. This approach offers a transparent and targeted
framework for comparing LLMs.

</details>


### [47] [MAPEX: A Multi-Agent Pipeline for Keyphrase Extraction](https://arxiv.org/abs/2509.18813)
*Liting Zhang,Shiwan Zhao,Aobo Kong,Qicheng Li*

Main category: cs.CL

TL;DR: 本文提出了首个多智能体框架MAPEX用于关键短语提取，通过专家招募与动态双路径策略，提升了LLM的关键短语提取能力，实验结果显示MAPEX显著优于现有方法，具有良好的通用性和表现。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）用于关键短语提取时，多数无监督提示方法采用单一推理流程和统一提示策略，无论文档长度或模型架构。这种一刀切设计难以充分发挥LLM的推理和生成能力，限制了在多样场景下的应用表现。

Method: 提出名为MAPEX的多智能体协作关键短语提取框架。MAPEX通过专家招募、候选提取、主题引导、知识增强和后处理等模块协调不同LLM智能体，采用双路径策略：对短文本采用知识驱动提取，对长文本采用主题引导提取。

Result: 在六个基准数据集和三种不同LLM上进行了广泛实验，MAPEX在F1@5上平均超过现有最先进无监督方法2.44%，比标准LLM基线高4.01%，展现出强泛化和通用性。

Conclusion: 通过引入多智能体和动态双路径机制，MAPEX显著提升了LLM在无监督关键短语提取任务中的性能，为跨文档长度和模型架构的场景提供了更具适应性的解决方案。

Abstract: Keyphrase extraction is a fundamental task in natural language processing.
However, existing unsupervised prompt-based methods for Large Language Models
(LLMs) often rely on single-stage inference pipelines with uniform prompting,
regardless of document length or LLM backbone. Such one-size-fits-all designs
hinder the full exploitation of LLMs' reasoning and generation capabilities,
especially given the complexity of keyphrase extraction across diverse
scenarios. To address these challenges, we propose MAPEX, the first framework
that introduces multi-agent collaboration into keyphrase extraction. MAPEX
coordinates LLM-based agents through modules for expert recruitment, candidate
extraction, topic guidance, knowledge augmentation, and post-processing. A
dual-path strategy dynamically adapts to document length: knowledge-driven
extraction for short texts and topic-guided extraction for long texts.
Extensive experiments on six benchmark datasets across three different LLMs
demonstrate its strong generalization and universality, outperforming the
state-of-the-art unsupervised method by 2.44\% and standard LLM baselines by
4.01\% in F1@5 on average. Code is available at
https://github.com/NKU-LITI/MAPEX.

</details>


### [48] [Are Smaller Open-Weight LLMs Closing the Gap to Proprietary Models for Biomedical Question Answering?](https://arxiv.org/abs/2509.18843)
*Damian Stachura,Joanna Konieczna,Artur Nowak*

Main category: cs.CL

TL;DR: 作者比较开源和闭源大型语言模型在生物医学问答的能力，发现开源模型在某些场景下可媲美甚至超越闭源大模型，集成策略尤为有效，相关代码已开源。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）开源版本的能力逐渐追上了专有模型，作者关注小型开源LLMs能否有效取代封闭大型模型，尤其在生物医学问答领域。

Method: 对比多种开源模型与如GPT-4o、GPT-4.1、Claude 3.5/3.7等顶尖闭源系统，采用片段检索、上下文学习、结构化输出，并针对部分模型采用集成策略提升问答能力。

Result: 开源LLMs在某些情况下已能媲美甚至超越闭源模型，尤其集成策略下表现更为突出。

Conclusion: 小型开源LLMs在生物医学问答等专业领域，有潜力替代部分大型闭源模型。所有代码已开源公布。

Abstract: Open-weight versions of large language models (LLMs) are rapidly advancing,
with state-of-the-art models like DeepSeek-V3 now performing comparably to
proprietary LLMs. This progression raises the question of whether small
open-weight LLMs are capable of effectively replacing larger closed-source
models. We are particularly interested in the context of biomedical
question-answering, a domain we explored by participating in Task 13B Phase B
of the BioASQ challenge. In this work, we compare several open-weight models
against top-performing systems such as GPT-4o, GPT-4.1, Claude 3.5 Sonnet, and
Claude 3.7 Sonnet. To enhance question answering capabilities, we use various
techniques including retrieving the most relevant snippets based on embedding
distance, in-context learning, and structured outputs. For certain submissions,
we utilize ensemble approaches to leverage the diverse outputs generated by
different models for exact-answer questions. Our results demonstrate that
open-weight LLMs are comparable to proprietary ones. In some instances,
open-weight LLMs even surpassed their closed counterparts, particularly when
ensembling strategies were applied. All code is publicly available at
https://github.com/evidenceprime/BioASQ-13b.

</details>


### [49] [Multi-Hierarchical Feature Detection for Large Language Model Generated Text](https://arxiv.org/abs/2509.18862)
*Luyan Zhang,Xinyu Xie*

Main category: cs.CL

TL;DR: 论文系统性评估了多层级特征集成在AI文本检测中的作用，发现性能提升极为有限且成本高，表明单一神经模型已很高效。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型技术快速发展，学界关注多特征融合是否能显著提升AI文本检测性能。虽然理论上语义、句法和统计特征的结合理应有互补优势，但在现代LLM生成文本下缺乏严格实证。作者旨在检验多特征融合的实用价值。

Method: 提出MHFD（Multi-Hierarchical Feature Detection），融合DeBERTa语义分析、句法解析和统计概率特征，通过自适应机制进行集成，对比现有检测方法，通过多数据集进行实证评估。

Result: 实验表明，MHFD在文本检测准确率上，在同域达89.7%、跨域稳定保持84.2%，比现有方法有0.4-2.6%的提升，但融合带来的性能改善仅有0.4-0.5%，计算开销却增加4.2倍。

Conclusion: 多层级特征融合对现代AI文本检测提升有限，成本远高于收益，表明当前神经语言模型已能充分捕捉关键检测信号，多特征集成的投入难以被实际性能增益所证明。

Abstract: With the rapid advancement of large language model technology, there is
growing interest in whether multi-feature approaches can significantly improve
AI text detection beyond what single neural models achieve. While intuition
suggests that combining semantic, syntactic, and statistical features should
provide complementary signals, this assumption has not been rigorously tested
with modern LLM-generated text. This paper provides a systematic empirical
investigation of multi-hierarchical feature integration for AI text detection,
specifically testing whether the computational overhead of combining multiple
feature types is justified by performance gains. We implement MHFD
(Multi-Hierarchical Feature Detection), integrating DeBERTa-based semantic
analysis, syntactic parsing, and statistical probability features through
adaptive fusion. Our investigation reveals important negative results: despite
theoretical expectations, multi-feature integration provides minimal benefits
(0.4-0.5% improvement) while incurring substantial computational costs (4.2x
overhead), suggesting that modern neural language models may already capture
most relevant detection signals efficiently. Experimental results on multiple
benchmark datasets demonstrate that the MHFD method achieves 89.7% accuracy in
in-domain detection and maintains 84.2% stable performance in cross-domain
detection, showing modest improvements of 0.4-2.6% over existing methods.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [50] [A Scalable Lift-and-Project Differentiable Approach For the Maximum Cut Problem](https://arxiv.org/abs/2509.18612)
*Ismail Alkhouri,Mian Wu,Cunxi Yu,Jia Liu,Rongrong Wang,Alvaro Velasquez*

Main category: cs.DM

TL;DR: 该论文提出无需训练数据的最大割问题高效GPU求解框架，并通过升维、交替优化策略提升性能，在多种图数据上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 最大割问题是图论中的经典优化问题，但现有方法在处理大规模图数据时效率和可扩展性受到限制。

Method: 提出了一种可扩展的框架，利用投影梯度上升方法在GPU上进行二次目标优化，采用连续放松和并行多初始化策略。引入了升维二次形式和DECO维度交替算法以跳出局部最优，并结合重要性度数初始化和基于种群的进化超参数搜索。

Result: 该方法在多种类型的大规模图上均获得与最新数据驱动或无数据、GPU加速采样方法相当或更优的性能。

Conclusion: 提出的非机器学习、高效且可扩展的最大割问题求解框架，理论和实验证明其在大规模图上的优越性。

Abstract: We propose a scalable framework for solving the Maximum Cut (MaxCut) problem
in large graphs using projected gradient ascent on quadratic objectives.
Notably, while our approach is differentiable and leverages GPUs for
gradient-based optimization, it is not a machine learning method and does not
require training data beyond the given problem formulation. Starting from a
continuous relaxation of the classical quadratic binary formulation, we present
a parallelized strategy that explores multiple initialization vectors in batch,
offering an efficient and memory-friendly alternative to traditional solvers.
We analyze the relaxed objective, showing it is convex and has fixed-points
corresponding to local optima -- particularly at boundary points --
highlighting a key challenge in non-convex optimization. To address this, we
introduce a lifted quadratic formulation that over-parameterizes the solution
space, allowing the algorithm to escape poor fixed-points. We also provide a
theoretical characterization of these lifted fixed-points. Finally, we propose
DECO, a dimension-alternating algorithm that switches between the unlifted and
lifted formulations, leveraging their complementary strengths along with
importance-based degree initialization and a population-based evolutionary
hyper-parameter search. Experiments on diverse graph families show that our
methods attain comparable or superior performance relative to recent
training-data-intensive, dataless, and GPU-accelerated sampling approaches.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [51] [A Layered Implementation Framework for Regular Languages](https://arxiv.org/abs/2509.18232)
*Baudouin Le Charlier*

Main category: cs.FL

TL;DR: 本文提出并实现了一个高效分层的正规语言表示系统，通过表达式规范化和等价归类，实现了统一且紧凑的正规语言管理，并用实验验证了其实用性和高效性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在设计和实现一个用于操作正规语言表示的系统，以提高正规语言表示的紧凑性、效率和集成度。过去的正规语言工具存在表示臃肿、效率低下等问题，作者希望通过分层架构与规范化表达式解决这些痛点。

Method: 系统采用两层结构：第一层用规范化正规表达式确保其所有语法导数有限，并通过唯一标识（整数）实现高效管理；第二层背景层将等价的规范化表达式划分为等价类，选择代表表达式，并可用于分析表达式及其导数之间的关系。两个层次均从高层抽象设计到低层细致实现进行了详细描述。

Result: 实验结果显示，该系统能够有效、统一地表示大量不同的正规语言，保证不同标识符代表不同语言，每种语言既有小型化的表达式，也有其最小确定性自动机。

Conclusion: 该系统在保证表达式表达能力和表示紧凑性的同时，显著提高了正规语言操作的效率和可扩展性，为后续正规语言理论与应用开发提供了坚实的工具基础。

Abstract: I present the most fundamental features of an implemented system designed to
manipulate representations of regular languages. The system is structured into
two layers, allowing regular languages to be represented in an increasingly
compact, efficient, and integrated way. Both layers are first presented at a
high level, adequate to design and prove the correctness of abstract
algorithms. Then, their low-level implementations are described meticulously.
  At the high level, the first layer offers a notion of normalized regular
expressions ensuring that the set of all syntactic derivatives of an expression
is finite. At the low level, normalized expressions are uniquely represented by
identifiers, i.e. by standard integers.
  The second layer, called the background, introduces additional notions to
record, integrate, and simplify things computed within the first layer. At the
high level, normalized expressions denoting the same regular language can be
unified by grouping them into equivalence classes. One shortest expression is
chosen in each class as its representative, which can be used to form equations
relating expressions to their derivatives.
  This paper also presents extensive experimental results to demonstrate the
usefulness of the proposed framework and, in particular, the fact that it makes
it possible to represent large sets of regular languages in a unified way where
distinct identifiers designate different languages, represented by both a small
expression and a minimal deteministic automaton.

</details>
