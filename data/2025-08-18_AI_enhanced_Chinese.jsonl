{"id": "2508.11297", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2508.11297", "abs": "https://arxiv.org/abs/2508.11297", "authors": ["Casper Bach"], "title": "Generic Reduction-Based Interpreters (Extended Version)", "comment": null, "summary": "Reduction-based interpreters are traditionally defined in terms of a one-step\nreduction function which systematically decomposes a term into a potential\nredex and context, contracts the redex, and recomposes it to construct the new\nterm to be further reduced. While implementing such interpreters follows a\nsystematic recipe, they often require interpreter engineers to write a\nsubstantial amount of code -- much of it boilerplate. In this paper, we apply\nwell-known techniques from generic programming to reduce boilerplate code in\nreduction-based interpreters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u6cdb\u578b\u7f16\u7a0b\u6280\u672f\uff0c\u51cf\u5c11\u5f52\u7ea6\u89e3\u91ca\u5668\u5b9e\u73b0\u6240\u9700\u7684\u6837\u677f\u4ee3\u7801\uff0c\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\u3002", "motivation": "\u5728\u5b9e\u73b0\u57fa\u4e8e\u5f52\u7ea6\u7684\u89e3\u91ca\u5668\u65f6\uff0c\u867d\u7136\u9075\u5faa\u7cfb\u7edf\u5316\u7684\u6b65\u9aa4\uff0c\u4f46\u9700\u8981\u7f16\u5199\u5927\u91cf\u6837\u677f\u4ee3\u7801\uff0c\u589e\u52a0\u4e86\u5de5\u7a0b\u5e08\u7684\u5de5\u4f5c\u8d1f\u62c5\u3002", "method": "\u672c\u6587\u5e94\u7528\u4e86\u6cdb\u578b\u7f16\u7a0b\u4e2d\u7684\u4e00\u4e9b\u6210\u719f\u6280\u672f\uff0c\u65e8\u5728\u51cf\u5c11\u5f52\u7ea6\u89e3\u91ca\u5668\u5b9e\u73b0\u8fc7\u7a0b\u4e2d\u7684\u6837\u677f\u4ee3\u7801\u3002", "result": "\u5229\u7528\u6cdb\u578b\u7f16\u7a0b\u6280\u672f\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u7cbe\u7b80\u5f52\u7ea6\u89e3\u91ca\u5668\u4e2d\u9700\u8981\u5b9e\u73b0\u7684\u91cd\u590d\u6027\u4ee3\u7801\uff0c\u63d0\u5347\u5f00\u53d1\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u5c06\u6cdb\u578b\u7f16\u7a0b\u6280\u672f\u5f15\u5165\u5f52\u7ea6\u89e3\u91ca\u5668\u7684\u5b9e\u73b0\u8fc7\u7a0b\uff0c\u80fd\u591f\u663e\u8457\u51cf\u5c11\u6837\u677f\u4ee3\u7801\uff0c\u4e3a\u89e3\u91ca\u5668\u5f00\u53d1\u5e26\u6765\u4fbf\u5229\u3002"}}
{"id": "2508.11443", "categories": ["cs.PL", "cs.DS"], "pdf": "https://arxiv.org/pdf/2508.11443", "abs": "https://arxiv.org/abs/2508.11443", "authors": ["William Henrich Due", "Martin Elsman", "Troels Henriksen"], "title": "Towards Efficient Hash Maps in Functional Array Languages", "comment": null, "summary": "We present a systematic derivation of a data-parallel implementation of\ntwo-level, static and collision-free hash maps, by giving a functional\nformulation of the Fredman et al. construction, and then flattening it. We\ndiscuss the challenges of providing a flexible, polymorphic, and abstract\ninterface to hash maps in a functional array language, with particular\nattention paid to the problem of dynamically sized keys, which we address by\nassociating each hash map with an arbitrary context. The algorithm is\nimplemented in Futhark, and the achieved GPU execution performance is compared\non simple benchmark problems. We find that our hash maps outperform\nconventional tree/search-based approaches. Furthermore, our implementation is\ncompared against the state-of-the-art cuCollections library, which is\nsignificantly faster for hash map construction, and to a lesser degree for\nlookups. We explain to which extent the performance difference is due to\nlow-level code generation limitation in the Futhark compiler, and to which\nextent it can be attributed to the data-parallel programming vocabulary not\nproviding the constructs necessary to express the equivalent of the algorithms\nused by cuCollections. We end by reflecting to which extent the functional\narray language programming model could, or should, be extended to address these\nweaknesses.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5728Futhark\u8bed\u8a00\u4e2d\u5b9e\u73b0\u9ad8\u6548GPU\u6570\u636e\u5e76\u884c\u54c8\u5e0c\u6620\u5c04\u7684\u65b9\u6cd5\uff0c\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u4f18\u4e8e\u4f20\u7edf\u65b9\u6848\uff0c\u4f46\u7531\u4e8e\u5e95\u5c42\u548c\u7f16\u7a0b\u6a21\u578b\u9650\u5236\uff0c\u4e0d\u53cacuCollections\u5e93\uff0c\u4f5c\u8005\u63a2\u8ba8\u4e86\u672a\u6765\u6269\u5c55\u51fd\u6570\u5f0f\u6570\u7ec4\u8bed\u8a00\u7684\u65b9\u5411\u3002", "motivation": "\u76ee\u524d\u5728\u51fd\u6570\u5f0f\u6570\u7ec4\u8bed\u8a00\u4e2d\u5b9e\u73b0\u7075\u6d3b\u3001\u591a\u6001\u548c\u62bd\u8c61\u7684\u54c8\u5e0c\u6620\u5c04\u63a5\u53e3\u5b58\u5728\u56f0\u96be\uff0c\u5c24\u5176\u662f\u52a8\u6001\u952e\u5c3a\u5bf8\u548c\u6570\u636e\u5e76\u884c\u6027\u8868\u8fbe\u53d7\u9650\u3002\u4e9f\u9700\u63a2\u7d22\u65b0\u65b9\u6cd5\u4ee5\u63d0\u5347\u6b64\u7c7b\u8bed\u8a00\u5728GPU\u5e94\u7528\u4e2d\u7684\u9ad8\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u91c7\u7528Fredman\u7b49\u4eba\u7684\u4e24\u7ea7\u54c8\u5e0c\u6620\u5c04\u6784\u9020\u65b9\u6cd5\u8fdb\u884c\u51fd\u6570\u5f0f\u8868\u8fbe\uff0c\u5e76\u901a\u8fc7flattening\u5b9e\u73b0\u6570\u636e\u5e76\u884c\u3002\u9488\u5bf9\u952e\u7684\u52a8\u6001\u5927\u5c0f\u95ee\u9898\uff0c\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u54c8\u5e0c\u6620\u5c04\u5173\u8054\u4efb\u610f\u4e0a\u4e0b\u6587\u6765\u89e3\u51b3\u3002\u5177\u4f53\u7b97\u6cd5\u4ee5Futhark\u8bed\u8a00\u5b9e\u73b0\uff0c\u5e76\u5728GPU\u4e0a\u8fdb\u884c\u6027\u80fd\u6d4b\u8bd5\u548c\u57fa\u51c6\u5bf9\u6bd4\u3002", "result": "\u5f00\u53d1\u7684\u65b0\u54c8\u5e0c\u6620\u5c04\u65b9\u6848\u5728\u7b80\u5355\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u660e\u663e\u4f18\u4e8e\u4f20\u7edf\u6811/\u641c\u7d22\u65b9\u6cd5\u3002\u4f46\u5728\u4e0ecuCollections\u5e93\u6bd4\u8f83\u65f6\uff0c\u6784\u5efa\u548c\u67e5\u627e\u901f\u5ea6\u5747\u843d\u540e\uff0c\u5dee\u8ddd\u4e3b\u8981\u7531\u7f16\u8bd1\u5668\u5e95\u5c42\u4ee3\u7801\u751f\u6210\u548c\u6570\u636e\u5e76\u884c\u8bed\u4e49\u9650\u5236\u9020\u6210\u3002", "conclusion": "\u672c\u6587\u5f00\u53d1\u7684\u6570\u636e\u5e76\u884c\u54c8\u5e0c\u6620\u5c04\u65b9\u6848\u5728\u529f\u80fd\u4e0a\u4f18\u4e8e\u4f20\u7edf\u6811/\u641c\u7d22\u65b9\u6cd5\uff0c\u4f46\u4e0ecuCollections\u5e93\u76f8\u6bd4\uff0c\u5728\u6784\u5efa\u548c\u67e5\u627e\u6027\u80fd\u4e0a\u4ecd\u6709\u5dee\u8ddd\uff0c\u4e3b\u8981\u7531\u4e8e\u5e95\u5c42\u4ee3\u7801\u751f\u6210\u548c\u6570\u636e\u5e76\u884c\u7f16\u7a0b\u6a21\u578b\u7684\u9650\u5236\u3002\u4f5c\u8005\u5efa\u8bae\u672a\u6765\u53ef\u901a\u8fc7\u6269\u5c55\u51fd\u6570\u5f0f\u6570\u7ec4\u8bed\u8a00\u6765\u6539\u5584\u8fd9\u4e9b\u4e0d\u8db3\u3002"}}
{"id": "2508.10904", "categories": ["cs.CL", "cs.AR", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.10904", "abs": "https://arxiv.org/abs/2508.10904", "authors": ["Jie Lei", "Ruofan Jia", "J. Andrew Zhang", "Hao Zhang"], "title": "A2HCoder: An LLM-Driven Coding Agent for Hierarchical Algorithm-to-HDL Translation", "comment": "15 pages, 6 figures", "summary": "In wireless communication systems, stringent requirements such as ultra-low\nlatency and power consumption have significantly increased the demand for\nefficient algorithm-to-hardware deployment. However, a persistent and\nsubstantial gap remains between algorithm design and hardware implementation.\nBridging this gap traditionally requires extensive domain expertise and\ntime-consuming manual development, due to fundamental mismatches between\nhigh-level programming languages like MATLAB and hardware description languages\n(HDLs) such as Verilog-in terms of memory access patterns, data processing\nmanners, and datatype representations. To address this challenge, we propose\nA2HCoder: a Hierarchical Algorithm-to-HDL Coding Agent, powered by large\nlanguage models (LLMs), designed to enable agile and reliable\nalgorithm-to-hardware translation. A2HCoder introduces a hierarchical framework\nthat enhances both robustness and interpretability while suppressing common\nhallucination issues in LLM-generated code. In the horizontal dimension,\nA2HCoder decomposes complex algorithms into modular functional blocks,\nsimplifying code generation and improving consistency. In the vertical\ndimension, instead of relying on end-to-end generation, A2HCoder performs\nstep-by-step, fine-grained translation, leveraging external toolchains such as\nMATLAB and Vitis HLS for debugging and circuit-level synthesis. This structured\nprocess significantly mitigates hallucinations and ensures hardware-level\ncorrectness. We validate A2HCoder through a real-world deployment case in the\n5G wireless communication domain, demonstrating its practicality, reliability,\nand deployment efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faA2HCoder\uff0c\u901a\u8fc7\u5206\u5c42\u67b6\u6784\u548c\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5316\u7b97\u6cd5\u5230\u786c\u4ef6\u63cf\u8ff0\u4ee3\u7801\u8f6c\u6362\uff0c\u5b9e\u73b0\u9ad8\u6548\u53ef\u9760\u90e8\u7f72\uff0c\u57285G\u901a\u4fe1\u5b9e\u9645\u573a\u666f\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u65e0\u7ebf\u901a\u4fe1\u5bf9\u8d85\u4f4e\u5ef6\u8fdf\u548c\u4f4e\u529f\u8017\u7684\u9700\u6c42\uff0c\u5bfc\u81f4\u7b97\u6cd5\u4e0e\u786c\u4ef6\u5b9e\u73b0\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u9e3f\u6c9f\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u4e13\u4e1a\u77e5\u8bc6\u548c\u624b\u5de5\u5f00\u53d1\uff0c\u96be\u4ee5\u9ad8\u6548\u5b8c\u6210\u8f6c\u5316\u3002", "method": "\u63d0\u51faA2HCoder\u2014\u2014\u4e00\u79cd\u7531\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u5206\u5c42\u7b97\u6cd5\u5230\u786c\u4ef6\u63cf\u8ff0\u4ee3\u7801\u81ea\u52a8\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u6a2a\u5411\u6a21\u5757\u5316\u5206\u89e3\u548c\u7eb5\u5411\u7ec6\u7c92\u5ea6\u9010\u6b65\u7ffb\u8bd1\uff0c\u5e76\u7ed3\u5408\u5916\u90e8\u5de5\u5177\u94fe\u8fdb\u884c\u8c03\u8bd5\u4e0e\u7efc\u5408\u3002", "result": "A2HCoder\u57285G\u65e0\u7ebf\u901a\u4fe1\u5b9e\u9645\u90e8\u7f72\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u4ef7\u503c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u5316\u8f6c\u5316\u6548\u7387\u548c\u53ef\u9760\u6027\uff0c\u540c\u65f6\u51cf\u8f7b\u4e86\u4ee3\u7801\u5e7b\u89c9\u95ee\u9898\u3002", "conclusion": "A2HCoder\u80fd\u6709\u6548\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u9760\u7684\u7b97\u6cd5\u5230\u786c\u4ef6\u7684\u81ea\u52a8\u8f6c\u5316\uff0c\u5e76\u5728\u5b9e\u96455G\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u4e2d\u5c55\u793a\u4e86\u5176\u90e8\u7f72\u6548\u7387\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2508.11019", "categories": ["cs.LO", "cs.FL", "F.1.3; F.4.1; F.4.3"], "pdf": "https://arxiv.org/pdf/2508.11019", "abs": "https://arxiv.org/abs/2508.11019", "authors": ["Anuj Dawar", "Aidan T. Evans"], "title": "Characterizing NC1 with Typed Monoids", "comment": "22 pages", "summary": "Krebs et al. (2007) gave a characterization of the complexity class TC0 as\nthe class of languages recognized by a certain class of typed monoids. The\nnotion of typed monoid was introduced to extend methods of algebraic automata\ntheory to infinite monoids and hence characterize classes beyond the regular\nlanguages. We advance this line of work beyond TC0 by giving a characterization\nof NC1. This is obtained by first showing that NC1 can be defined as the\nlanguages expressible in an extension of first-order logic using only unary\nquantifiers over regular languages. The expressibility result is a consequence\nof a general result showing that finite monoid multiplication quantifiers of\nhigher dimension can be replaced with unary quantifiers in the context of\ninterpretations over strings, which also answers a question of Lautemann et al.\n(2001). We establish this collapse result for a much more general class of\ninterpretations using results on interpretations due to Boja\\'nczyk et al.\n(2019), which may be of independent interest.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u903b\u8f91\u6269\u5c55\u4e0e\u5355\u4f53\u7406\u8bba\uff0c\u5c06NC1\u590d\u6742\u5ea6\u7c7b\u7528\u4e00\u9636\u903b\u8f91\u65b9\u6cd5\u8fdb\u884c\u4e86\u523b\u753b\uff0c\u8bc1\u660e\u4e86\u9ad8\u7ef4\u5355\u4f53\u91cf\u8bcd\u53ef\u7b80\u5355\u5316\u4e3a\u4e00\u5143\u91cf\u8bcd\u5e76\u56de\u7b54\u4e86\u76f8\u5173\u516c\u5f00\u95ee\u9898\uff0c\u4e3a\u590d\u6742\u5ea6\u4e0e\u4ee3\u6570\u7ed3\u6784\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u6846\u67b6\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u5df2\u5229\u7528\u578b\u5355\u4f53\uff08typed monoid\uff09\u5c06TC0\u590d\u6742\u5ea6\u7c7b\u4e0e\u62bd\u8c61\u4ee3\u6570\u81ea\u52a8\u673a\u7406\u8bba\u5173\u8054\uff0c\u4f46\u5982\u4f55\u7528\u7c7b\u4f3c\u65b9\u6cd5\u523b\u753b\u66f4\u9ad8\u590d\u6742\u5ea6\u7c7b\uff08\u5982NC1\uff09\u4ecd\u4e0d\u660e\u786e\u3002\u4f5c\u8005\u65e8\u5728\u901a\u8fc7\u6269\u5c55\u76f8\u5e94\u7684\u903b\u8f91\u4e0e\u5355\u4f53\u7406\u8bba\u65b9\u6cd5\uff0c\u4e3aNC1\u63d0\u4f9b\u65b0\u7684\u7279\u5f81\u5316\u3002", "method": "\u9996\u5148\uff0c\u4f5c\u8005\u7528\u4e00\u9636\u903b\u8f91\u7684\u6269\u5c55\uff08\u53ea\u4f7f\u7528\u5bf9\u6b63\u89c4\u8bed\u8a00\u7684\u5355\u4e00\u5143\u91cf\u8bcd\uff09\u6765\u8868\u8fbeNC1\uff0c\u5e76\u901a\u8fc7\u8bc1\u660e\u5728\u5b57\u7b26\u4e32\u89e3\u91ca\u73af\u5883\u4e0b\uff0c\u9ad8\u7ef4\u6709\u9650\u5355\u4f53\u4e58\u6cd5\u91cf\u8bcd\u53ef\u88ab\u5355\u4e00\u5143\u91cf\u8bcd\u66ff\u4ee3\uff0c\u5b9e\u73b0\u8868\u8fbe\u80fd\u529b\u7684\u201c\u574d\u584c\u201d\u3002\u8fd9\u4e00\u8fc7\u7a0b\u7ed3\u5408\u4e86\u66f4\u4e00\u822c\u7684\u89e3\u91ca\u7ed3\u679c\u5e76\u53c2\u8003\u4e86Boja\u0144czyk\u7b49\u4eba\uff082019\uff09\u7684\u7406\u8bba\u6846\u67b6\u3002", "result": "\u4f5c\u8005\u6210\u529f\u8bc1\u660e\uff0cNC1\u53ef\u4ee5\u7528\u4e00\u9636\u903b\u8f91\u6269\u5c55\u53ea\u542b\u6b63\u89c4\u8bed\u8a00\u7684\u4e00\u5143\u91cf\u8bcd\u6765\u8868\u8fbe\uff0c\u5e76\u5efa\u7acb\u4e86\u9ad8\u7ef4\u91cf\u8bcd\u5230\u4e00\u5143\u91cf\u8bcd\u7684\u574d\u584c\u7ed3\u679c\u3002\u8fd9\u4e0d\u4ec5\u56de\u7b54\u4e86Lautemann\u7b49\u4eba\uff082001\uff09\u63d0\u51fa\u7684\u95ee\u9898\uff0c\u4e5f\u5c06\u89e3\u91ca\u574d\u584c\u6269\u5c55\u5230\u66f4\u5e7f\u6cdb\u7684\u7406\u8bba\u60c5\u5f62\u3002", "conclusion": "\u672c\u7814\u7a76\u5c06\u62bd\u8c61\u4ee3\u6570\u548c\u903b\u8f91\u65b9\u6cd5\u8fdb\u4e00\u6b65\u63a8\u8fdb\u81f3\u8d85\u8d8aTC0\u7684\u590d\u6742\u5ea6\u7c7b\uff0c\u5bf9NC1\u8fdb\u884c\u4e86\u65b0\u7684\u903b\u8f91\u548c\u5355\u4f53\u7279\u5f81\u5316\uff0c\u540c\u65f6\u5efa\u7acb\u4e86\u91cf\u8bcd\u574d\u584c\u7ed3\u679c\uff0c\u4e3a\u7406\u89e3\u590d\u6742\u5ea6\u7c7b\u4e0e\u4ee3\u6570\u7ed3\u6784\u4e4b\u95f4\u7684\u5173\u7cfb\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2508.10906", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.10906", "abs": "https://arxiv.org/abs/2508.10906", "authors": ["Sihan Chen", "John P. Lalor", "Yi Yang", "Ahmed Abbasi"], "title": "PersonaTwin: A Multi-Tier Prompt Conditioning Framework for Generating and Evaluating Personalized Digital Twins", "comment": "Presented at the Generation, Evaluation & Metrics (GEM) Workshop at\n  ACL 2025", "summary": "While large language models (LLMs) afford new possibilities for user modeling\nand approximation of human behaviors, they often fail to capture the\nmultidimensional nuances of individual users. In this work, we introduce\nPersonaTwin, a multi-tier prompt conditioning framework that builds adaptive\ndigital twins by integrating demographic, behavioral, and psychometric data.\nUsing a comprehensive data set in the healthcare context of more than 8,500\nindividuals, we systematically benchmark PersonaTwin against standard LLM\noutputs, and our rigorous evaluation unites state-of-the-art text similarity\nmetrics with dedicated demographic parity assessments, ensuring that generated\nresponses remain accurate and unbiased. Experimental results show that our\nframework produces simulation fidelity on par with oracle settings. Moreover,\ndownstream models trained on persona-twins approximate models trained on\nindividuals in terms of prediction and fairness metrics across both\nGPT-4o-based and Llama-based models. Together, these findings underscore the\npotential for LLM digital twin-based approaches in producing realistic and\nemotionally nuanced user simulations, offering a powerful tool for personalized\ndigital user modeling and behavior analysis.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8e\u591a\u7ef4\u7528\u6237\u7279\u5f81\u7684PersonaTwin\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u6a21\u578b\u8fdb\u884c\u4e2a\u6027\u5316\u6570\u5b57\u5b6a\u751f\u548c\u7528\u6237\u884c\u4e3a\u6a21\u62df\u7684\u51c6\u786e\u6027\u4e0e\u516c\u5e73\u6027\uff0c\u5728\u73b0\u5b9e\u533b\u7597\u6570\u636e\u96c6\u4e0a\u6709\u8f83\u5f3a\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5177\u5907\u6a21\u62df\u7528\u6237\u548c\u9884\u6d4b\u4eba\u7c7b\u884c\u4e3a\u7684\u6f5c\u529b\uff0c\u4f46\u5b83\u4eec\u5f80\u5f80\u96be\u4ee5\u6355\u6349\u4e2a\u4f53\u7528\u6237\u591a\u7ef4\u5ea6\u7684\u7ec6\u5fae\u5dee\u522b\u3002\u4e3a\u63d0\u9ad8\u4e2a\u6027\u5316\u6a21\u62df\u7684\u51c6\u786e\u6027\u4e0e\u516c\u5e73\u6027\uff0c\u4f5c\u8005\u5c1d\u8bd5\u6784\u5efa\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faPersonaTwin\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u5c42\u6b21\u63d0\u793a\u8c03\u6574\uff0c\u6574\u5408\u7528\u6237\u7684\u4eba\u53e3\u7edf\u8ba1\u3001\u884c\u4e3a\u53ca\u5fc3\u7406\u6570\u636e\uff0c\u5b9e\u73b0\u5bf9\u7528\u6237\u7684\u9002\u5e94\u6027\u6570\u5b57\u5b6a\u751f\u5efa\u6a21\u3002\u5728\u5305\u542b8500\u4f59\u540d\u533b\u7597\u573a\u666f\u7528\u6237\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u4e0e\u6807\u51c6LLM\u8f93\u51fa\u8fdb\u884c\u7cfb\u7edf\u6027\u5bf9\u6bd4\uff0c\u7ed3\u5408\u6587\u672c\u76f8\u4f3c\u6027\u6307\u6807\u548c\u4eba\u53e3\u516c\u6b63\u6027\u8bc4\u4f30\uff0c\u5168\u9762\u8bc4\u6d4b\u751f\u6210\u5185\u5bb9\u7684\u51c6\u786e\u6027\u53ca\u65e0\u504f\u6027\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0cPersonaTwin\u751f\u6210\u7684\u7528\u6237\u6a21\u62df\u5728\u4eff\u771f\u4fdd\u771f\u5ea6\u4e0a\u63a5\u8fd1oracle\u3002\u57fa\u4e8ePersonaTwin\u8bad\u7ec3\u7684\u4e0b\u6e38\u6a21\u578b\u5728\u9884\u6d4b\u548c\u516c\u5e73\u6027\u6307\u6807\u65b9\u9762\uff0c\u4e0e\u76f4\u63a5\u7528\u771f\u5b9e\u7528\u6237\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u8868\u73b0\u76f8\u4f3c\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u7684\u4e3b\u6d41\u5927\u6a21\u578b\uff08\u5982GPT-4o\u3001Llama\uff09\u3002", "conclusion": "PersonaTwin\u6846\u67b6\u80fd\u663e\u8457\u63d0\u5347LLM\u5728\u7528\u6237\u4e2a\u6027\u5316\u5efa\u6a21\u4e0a\u7684\u771f\u5b9e\u611f\u548c\u60c5\u611f\u7ec6\u817b\u7a0b\u5ea6\uff0c\u6709\u52a9\u4e8e\u9ad8\u8d28\u91cf\u7684\u4e2a\u4f53\u6570\u5b57\u5b6a\u751f\u548c\u884c\u4e3a\u5206\u6790\u3002"}}
{"id": "2508.11136", "categories": ["cs.LO", "D.2.4; F.3.1; F.4.1"], "pdf": "https://arxiv.org/pdf/2508.11136", "abs": "https://arxiv.org/abs/2508.11136", "authors": ["Richard Waldinger"], "title": "Automating the Derivation of Unification Algorithms: A Case Study in Deductive Program Synthesis", "comment": "92 pages", "summary": "The unification algorithm has long been a target for program synthesis\nresearch, but a fully automatic derivation remains a research goal. In\ndeductive program synthesis, computer programming is phrased as a task in\ntheorem proving; a declarative specification is expressed in logical form and\npresented to an automatic theorem prover, and a program meeting the\nspecification is extracted from the proof. The correctness of the program is\nsupported by the proof, which also provides an explanation of how the program\nworks. The proof is conducted in an appropriate axiomatic subject-domain\ntheory, which defines the concepts in the specification and the constructs in\nthe target programming language and provides the background knowledge necessary\nto connect them.\n  For the unification proof, we generalize and automate the manual proof\npresented in Manna and Waldinger [1981]. The new program unifies two given\nsymbolic expressions (s-expressions) relative to a given \"environment\"\nsubstitution. The proof establishes the existence of an output substitution\nthat is a most-general idempotent unifier of the given expressions and is an\n\"extension\" of the environment substitution. If no such substitution exists and\nthe expressions are not unifiable, the program is to produce a failure\nindicator.\n  Initially the environment substitution is the empty substitution, which makes\nno replacements at all; during execution of recursive calls, the environment\nsubstitution records the replacements that have been found so far. Our own\nunification algorithm employs an environment, and such algorithms appear in the\nliterature [e.g., Luger and Stubblefield, 1997]. We suspect, in addition to\nbeing more efficient, the three-argument algorithm with an environment is\neasier to synthesize automatically than the two-argument version from the\nManna-Waldinger paper.", "AI": {"tldr": "\u672c\u8bba\u6587\u5b9e\u73b0\u4e86\u7edf\u4e00\u7b97\u6cd5\u7684\u5b9a\u7406\u8bc1\u660e\u81ea\u52a8\u5316\u5408\u6210\uff0c\u91c7\u7528\u4e09\u53c2\u6570\u73af\u5883\u65b9\u6cd5\uff0c\u53ef\u81ea\u52a8\u7edf\u4e00\u7b26\u53f7\u8868\u8fbe\u5f0f\u4e14\u66f4\u6613\u4e8e\u7a0b\u5e8f\u5408\u6210\uff0c\u76f8\u8f83\u4f20\u7edf\u65b9\u6cd5\u66f4\u9ad8\u6548\u53ef\u9760\u3002", "motivation": "\u7edf\u4e00\u7b97\u6cd5\u662f\u7f16\u7a0b\u5408\u6210\u9886\u57df\u7684\u91cd\u70b9\uff0c\u4f46\u81f3\u4eca\u6ca1\u6709\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u63a8\u5bfc\u3002\u8fd9\u9879\u5de5\u4f5c\u7684\u52a8\u673a\u662f\u5c06\u8ba1\u7b97\u673a\u7f16\u7a0b\u8f6c\u5316\u4e3a\u5b9a\u7406\u8bc1\u660e\u4efb\u52a1\uff0c\u901a\u8fc7\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u5668\u6839\u636e\u58f0\u660e\u5f0f\u89c4\u683c\u81ea\u52a8\u751f\u6210\u6b63\u786e\u7684\u7a0b\u5e8f\u3002", "method": "\u672c\u6587\u5728\u9886\u57df\u7406\u8bba\u516c\u7406\u7cfb\u7edf\u4e0b\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u4e00\u822c\u5316Manna\u548cWaldinger\uff081981\uff09\u624b\u5de5\u8bc1\u660e\u7684\u65b9\u6cd5\uff0c\u63a8\u5bfc\u51fa\u65b0\u7684\u7edf\u4e00\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u4ee5\u73af\u5883\u66ff\u6362\u4f5c\u4e3a\u989d\u5916\u53c2\u6570\uff0c\u9012\u5f52\u8bb0\u5f55\u66ff\u6362\uff0c\u81ea\u52a8\u8bc1\u660e\u5176\u6700\u4e00\u822c\u5e42\u7b49\u7edf\u4e00\u6027\u7684\u5b58\u5728\u6027\uff0c\u5e76\u5728\u4e0d\u80fd\u7edf\u4e00\u65f6\u8f93\u51fa\u5931\u8d25\u6307\u793a\u3002", "result": "\u65b0\u7b97\u6cd5\u53ef\u81ea\u52a8\u5c06\u4e24\u4e2a\u7b26\u53f7\u8868\u8fbe\u5f0f\u548c\u73af\u5883\u66ff\u6362\u7edf\u4e00\uff0c\u8f93\u51fa\u6700\u4e00\u822c\u5e42\u7b49\u7edf\u4e00\u7684\u66ff\u6362\u6216\u8005\u5931\u8d25\u4fe1\u606f\u3002\u4e09\u53c2\u6570\uff08\u5e26\u73af\u5883\uff09\u7684\u7b97\u6cd5\u4e0d\u4ec5\u66f4\u9ad8\u6548\uff0c\u4e5f\u63a8\u6d4b\u6bd4\u4f20\u7edf\u4e8c\u53c2\u6570\u7b97\u6cd5\u66f4\u6613\u4e8e\u81ea\u52a8\u5408\u6210\u3002", "conclusion": "\u901a\u8fc7\u81ea\u52a8\u5316\u5b9a\u7406\u8bc1\u660e\u8fc7\u7a0b\uff0c\u4f5c\u8005\u5b9e\u73b0\u4e86\u4e09\u53c2\u6570\u73af\u5883\u7edf\u4e00\u7b97\u6cd5\u7684\u81ea\u52a8\u5408\u6210\uff0c\u63d0\u9ad8\u4e86\u6548\u7387\uff0c\u4e5f\u4e3a\u7edf\u4e00\u7b97\u6cd5\u81ea\u52a8\u5316\u5408\u6210\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2508.11034", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.11034", "abs": "https://arxiv.org/abs/2508.11034", "authors": ["Antonio Collante", "Samuel Abedu", "SayedHassan Khatoonabadi", "Ahmad Abdellatif", "Ebube Alor", "Emad Shihab"], "title": "The Impact of Large Language Models (LLMs) on Code Review Process", "comment": null, "summary": "Large language models (LLMs) have recently gained prominence in the field of\nsoftware development, significantly boosting productivity and simplifying\nteamwork. Although prior studies have examined task-specific applications, the\nphase-specific effects of LLM assistance on the efficiency of code review\nprocesses remain underexplored. This research investigates the effect of GPT on\nGitHub pull request (PR) workflows, with a focus on reducing resolution time,\noptimizing phase-specific performance, and assisting developers. We curated a\ndataset of 25,473 PRs from 9,254 GitHub projects and identified GPT-assisted\nPRs using a semi-automated heuristic approach that combines keyword-based\ndetection, regular expression filtering, and manual verification until\nachieving 95% labeling accuracy. We then applied statistical modeling,\nincluding multiple linear regression and Mann-Whitney U test, to evaluate\ndifferences between GPT-assisted and non-assisted PRs, both at the overall\nresolution level and across distinct review phases. Our research has revealed\nthat early adoption of GPT can substantially boost the effectiveness of the PR\nprocess, leading to considerable time savings at various stages. Our findings\nsuggest that GPT-assisted PRs reduced median resolution time by more than 60%\n(9 hours compared to 23 hours for non-assisted PRs). We discovered that\nutilizing GPT can reduce the review time by 33% and the waiting time before\nacceptance by 87%. Analyzing a sample dataset of 300 GPT-assisted PRs, we\ndiscovered that developers predominantly use GPT for code optimization (60%),\nbug fixing (26%), and documentation updates (12%). This research sheds light on\nthe impact of the GPT model on the code review process, offering actionable\ninsights for software teams seeking to enhance workflows and promote seamless\ncollaboration.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u4e86GitHub PR\u6d41\u7a0b\u4e2dGPT\u8f85\u52a9\u7684\u6548\u679c\uff0c\u53d1\u73b0\u53ef\u5c06\u6574\u4f53\u89e3\u51b3\u65f6\u95f4\u51cf\u5c11\u903e60%\uff0c\u5728\u5ba1\u67e5\u548c\u7b49\u5f85\u9636\u6bb5\u5206\u522b\u8282\u7701\u663e\u8457\u65f6\u95f4\u3002GPT\u4e3b\u8981\u7528\u4e8e\u4f18\u5316\u4ee3\u7801\u548c\u4fee\u590dBug\uff0c\u4e3a\u56e2\u961f\u63d0\u5347\u6548\u7387\u548c\u534f\u4f5c\u65b9\u5f0f\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u76ee\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u8f6f\u4ef6\u5f00\u53d1\u9886\u57df\u63d0\u5347\u4e86\u751f\u4ea7\u529b\u548c\u56e2\u961f\u5408\u4f5c\u6548\u7387\uff0c\u4f46\u5176\u5728\u4ee3\u7801\u5ba1\u67e5\u6d41\u7a0b\u4e2d\u5404\u9636\u6bb5\u5177\u4f53\u7684\u5f71\u54cd\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002\u8be5\u7814\u7a76\u65e8\u5728\u63a2\u7d22GPT\u5728GitHub\u62c9\u53d6\u8bf7\u6c42\uff08PR\uff09\u5de5\u4f5c\u6d41\u4e2d\u662f\u5426\u80fd\u7f29\u77ed\u89e3\u51b3\u65f6\u95f4\u3001\u4f18\u5316\u5404\u9636\u6bb5\u8868\u73b0\u5e76\u534f\u52a9\u5f00\u53d1\u8005\u3002", "method": "\u7814\u7a76\u8005\u6536\u96c6\u4e86\u6765\u81ea9,254\u4e2aGitHub\u9879\u76ee\u768425,473\u4e2aPR\uff0c\u91c7\u7528\u5173\u952e\u8bcd\u68c0\u6d4b\u3001\u6b63\u5219\u8fc7\u6ee4\u4e0e\u4eba\u5de5\u9a8c\u8bc1\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u8bc6\u522bGPT\u8f85\u52a9\u7684PR\uff0c\u6807\u6ce8\u51c6\u786e\u7387\u8fbe\u523095%\u3002\u901a\u8fc7\u591a\u5143\u7ebf\u6027\u56de\u5f52\u548cMann-Whitney U\u68c0\u9a8c\uff0c\u5206\u6790GPT\u8f85\u52a9\u4e0e\u672a\u8f85\u52a9PR\u5728\u6574\u4f53\u548c\u5404\u9636\u6bb5\u7684\u89e3\u51b3\u6548\u7387\u5dee\u5f02\u3002", "result": "GPT\u8f85\u52a9\u7684PR\u4e2d\u4f4d\u89e3\u51b3\u65f6\u95f4\u663e\u8457\u964d\u4f4e\uff089\u5c0f\u65f6\uff0c\u5bf9\u6bd4\u672a\u8f85\u52a9\u768423\u5c0f\u65f6\uff09\uff0c\u51cf\u5c11\u8d85\u8fc760%\u3002\u5728\u4ee3\u7801\u5ba1\u67e5\u73af\u8282\u51cf\u5c1133%\u65f6\u95f4\uff0c\u5728\u7b49\u5f85\u63a5\u53d7\u9636\u6bb5\u51cf\u5c1187%\u3002GPT\u4e3b\u8981\u88ab\u7528\u4e8e\u4ee3\u7801\u4f18\u5316\uff0860%\uff09\u3001\u4fee\u590d\u7f3a\u9677\uff0826%\uff09\u548c\u6587\u6863\u66f4\u65b0\uff0812%\uff09\u3002", "conclusion": "\u65e9\u671f\u5f15\u5165GPT\u80fd\u663e\u8457\u63d0\u5347PR\u6d41\u7a0b\u6548\u7387\uff0c\u4e3a\u8f6f\u4ef6\u56e2\u961f\u4f18\u5316\u5de5\u4f5c\u6d41\u548c\u4fc3\u8fdb\u534f\u4f5c\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u5efa\u8bae\u3002"}}
{"id": "2508.11571", "categories": ["cs.SE", "cs.DM"], "pdf": "https://arxiv.org/pdf/2508.11571", "abs": "https://arxiv.org/abs/2508.11571", "authors": ["Alexander Bakhtin"], "title": "Temporal Network Analysis of Microservice Architectural Degradation", "comment": null, "summary": "Microservice architecture can be modeled as a network of microservices making\ncalls to each other, commonly known as the service dependency graph. Network\nScience can provide methods to study such networks. In particular, temporal\nnetwork analysis is a branch of Network Science that analyzes networks evolving\nwith time. In microservice systems, temporal networks can arise if we examine\nthe architecture of the system across releases or monitor a deployed system\nusing tracing.\n  In this research summary paper, I discuss the challenges in obtaining\ntemporal networks from microservice systems and analyzing them with the\ntemporal network methods. In particular, the most complete temporal network\nthat we could obtain contains 7 time instances and 42 microservices, which\nlimits the potential analysis that could be applied.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u83b7\u53d6\u548c\u5206\u6790\u5fae\u670d\u52a1\u7cfb\u7edf\u7684\u65f6\u5e8f\u7f51\u7edc\uff0c\u4f46\u7531\u4e8e\u76ee\u524d\u80fd\u83b7\u5f97\u7684\u6570\u636e\u89c4\u6a21\u6709\u9650\uff0c\u65f6\u5e8f\u7f51\u7edc\u5206\u6790\u7684\u80fd\u529b\u53d7\u5230\u5236\u7ea6\uff0c\u6709\u5f85\u8fdb\u4e00\u6b65\u7a81\u7834\u5927\u89c4\u6a21\u65f6\u5e8f\u7f51\u7edc\u91c7\u96c6\u4e0e\u5206\u6790\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u5fae\u670d\u52a1\u67b6\u6784\u7684\u666e\u53ca\uff0c\u7406\u89e3\u5fae\u670d\u52a1\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u548c\u52a8\u6001\u53d8\u5316\u5bf9\u4e8e\u4fdd\u969c\u7cfb\u7edf\u6027\u80fd\u548c\u7a33\u5b9a\u6027\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u7f51\u7edc\u5206\u6790\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u5fae\u670d\u52a1\u7cfb\u7edf\u968f\u65f6\u95f4\u6f14\u53d8\u7684\u7ed3\u6784\u7279\u5f81\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u5f15\u5165\u65f6\u5e8f\u7f51\u7edc\u5206\u6790\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5229\u7528\u65f6\u5e8f\u7f51\u7edc\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u5bf9\u5fae\u670d\u52a1\u7cfb\u7edf\u7684\u670d\u52a1\u4f9d\u8d56\u5173\u7cfb\u968f\u65f6\u95f4\u7684\u53d8\u5316\u8fdb\u884c\u5efa\u6a21\u548c\u7814\u7a76\uff0c\u4e3b\u8981\u901a\u8fc7\u7cfb\u7edf\u7248\u672c\u8fed\u4ee3\u548c\u90e8\u7f72\u8ffd\u8e2a\u65b9\u5f0f\u83b7\u53d6\u7f51\u7edc\u6570\u636e\u3002", "result": "\u6210\u529f\u83b7\u5f97\u5305\u542b42\u4e2a\u5fae\u670d\u52a1\u57287\u4e2a\u65f6\u95f4\u70b9\u7684\u6700\u5b8c\u6574\u65f6\u5e8f\u7f51\u7edc\u6570\u636e\uff0c\u4f46\u7531\u4e8e\u65f6\u5e8f\u7f51\u7edc\u7684\u89c4\u6a21\u53d7\u9650\uff0c\u53ef\u5e94\u7528\u7684\u5206\u6790\u65b9\u6cd5\u6709\u6240\u9650\u5236\uff0c\u65e0\u6cd5\u8fdb\u884c\u66f4\u6df1\u5165\u5168\u9762\u7684\u52a8\u6001\u6f14\u5316\u5206\u6790\u3002", "conclusion": "\u5fae\u670d\u52a1\u7cfb\u7edf\u7684\u65f6\u5e8f\u7f51\u7edc\u5206\u6790\u9762\u4e34\u6570\u636e\u83b7\u53d6\u548c\u7f51\u7edc\u89c4\u6a21\u9650\u5236\u7b49\u6311\u6218\uff0c\u5f53\u524d\u83b7\u5f97\u7684\u6570\u636e\u91cf\u548c\u7ef4\u5ea6\u96be\u4ee5\u53d1\u6325\u65f6\u5e8f\u7f51\u7edc\u65b9\u6cd5\u7684\u5168\u90e8\u6f5c\u529b\uff0c\u672a\u6765\u9700\u6539\u8fdb\u6570\u636e\u6536\u96c6\u65b9\u5f0f\u4ee5\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u5206\u6790\u3002"}}
{"id": "2508.10925", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10925", "abs": "https://arxiv.org/abs/2508.10925", "authors": ["OpenAI", ":", "Sandhini Agarwal", "Lama Ahmad", "Jason Ai", "Sam Altman", "Andy Applebaum", "Edwin Arbus", "Rahul K. Arora", "Yu Bai", "Bowen Baker", "Haiming Bao", "Boaz Barak", "Ally Bennett", "Tyler Bertao", "Nivedita Brett", "Eugene Brevdo", "Greg Brockman", "Sebastien Bubeck", "Che Chang", "Kai Chen", "Mark Chen", "Enoch Cheung", "Aidan Clark", "Dan Cook", "Marat Dukhan", "Casey Dvorak", "Kevin Fives", "Vlad Fomenko", "Timur Garipov", "Kristian Georgiev", "Mia Glaese", "Tarun Gogineni", "Adam Goucher", "Lukas Gross", "Katia Gil Guzman", "John Hallman", "Jackie Hehir", "Johannes Heidecke", "Alec Helyar", "Haitang Hu", "Romain Huet", "Jacob Huh", "Saachi Jain", "Zach Johnson", "Chris Koch", "Irina Kofman", "Dominik Kundel", "Jason Kwon", "Volodymyr Kyrylov", "Elaine Ya Le", "Guillaume Leclerc", "James Park Lennon", "Scott Lessans", "Mario Lezcano-Casado", "Yuanzhi Li", "Zhuohan Li", "Ji Lin", "Jordan Liss", "Lily", "Liu", "Jiancheng Liu", "Kevin Lu", "Chris Lu", "Zoran Martinovic", "Lindsay McCallum", "Josh McGrath", "Scott McKinney", "Aidan McLaughlin", "Song Mei", "Steve Mostovoy", "Tong Mu", "Gideon Myles", "Alexander Neitz", "Alex Nichol", "Jakub Pachocki", "Alex Paino", "Dana Palmie", "Ashley Pantuliano", "Giambattista Parascandolo", "Jongsoo Park", "Leher Pathak", "Carolina Paz", "Ludovic Peran", "Dmitry Pimenov", "Michelle Pokrass", "Elizabeth Proehl", "Huida Qiu", "Gaby Raila", "Filippo Raso", "Hongyu Ren", "Kimmy Richardson", "David Robinson", "Bob Rotsted", "Hadi Salman", "Suvansh Sanjeev", "Max Schwarzer", "D. Sculley", "Harshit Sikchi", "Kendal Simon", "Karan Singhal", "Yang Song", "Dane Stuckey", "Zhiqing Sun", "Philippe Tillet", "Sam Toizer", "Foivos Tsimpourlas", "Nikhil Vyas", "Eric Wallace", "Xin Wang", "Miles Wang", "Olivia Watkins", "Kevin Weil", "Amy Wendling", "Kevin Whinnery", "Cedric Whitney", "Hannah Wong", "Lin Yang", "Yu Yang", "Michihiro Yasunaga", "Kristen Ying", "Wojciech Zaremba", "Wenting Zhan", "Cyril Zhang", "Brian Zhang", "Eddie Zhang", "Shengjia Zhao"], "title": "gpt-oss-120b & gpt-oss-20b Model Card", "comment": null, "summary": "We present gpt-oss-120b and gpt-oss-20b, two open-weight reasoning models\nthat push the frontier of accuracy and inference cost. The models use an\nefficient mixture-of-expert transformer architecture and are trained using\nlarge-scale distillation and reinforcement learning. We optimize the models to\nhave strong agentic capabilities (deep research browsing, python tool use, and\nsupport for developer-provided functions), all while using a rendered chat\nformat that enables clear instruction following and role delineation. Both\nmodels achieve strong results on benchmarks ranging from mathematics, coding,\nand safety. We release the model weights, inference implementations, tool\nenvironments, and tokenizers under an Apache 2.0 license to enable broad use\nand further research.", "AI": {"tldr": "\u672c\u6587\u53d1\u5e03\u4e86\u4e24\u4e2a\u9ad8\u6548\u3001\u5f00\u6e90\u3001\u80fd\u529b\u5f3a\u5927\u7684\u63a8\u7406\u5927\u6a21\u578bgpt-oss-120b\u548cgpt-oss-20b\uff0c\u5728\u591a\u79cd\u4efb\u52a1\u6d4b\u8bd5\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u5168\u90e8\u8d44\u6e90\u5747\u5f00\u653e\uff0c\u63a8\u52a8\u9886\u57df\u8fdb\u4e00\u6b65\u7814\u7a76\u4e0e\u5e94\u7528\u3002", "motivation": "\u5f53\u524d\u63a8\u7406\u6a21\u578b\u5728\u51c6\u786e\u6027\u3001\u63a8\u7406\u6210\u672c\u3001\u53ef\u6269\u5c55\u6027\u7b49\u65b9\u9762\u5747\u6709\u5f85\u7a81\u7834\uff0c\u73b0\u6709\u95ed\u6e90\u6a21\u578b\u7f3a\u5c11\u8db3\u591f\u7684\u5f00\u653e\u6027\uff0c\u9650\u5236\u4e86\u7814\u7a76\u4e0e\u5e94\u7528\u3002\u4f5c\u8005\u65e8\u5728\u901a\u8fc7\u6784\u5efa\u9ad8\u6548\u3001\u80fd\u529b\u5168\u9762\u4e14\u5f00\u6e90\u7684\u63a8\u7406\u6a21\u578b\u4fc3\u8fdb\u9886\u57df\u53d1\u5c55\u3002", "method": "\u91c7\u7528\u9ad8\u6548\u7684\u4e13\u5bb6\u6df7\u5408\uff08MoE\uff09Transformer\u67b6\u6784\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u84b8\u998f\u4e0e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u3002\u5728\u6a21\u578b\u7aef\u5f15\u5165\u4e86\u6e32\u67d3\u804a\u5929\u683c\u5f0f\uff0c\u4f18\u5316\u4e86\u6a21\u578b\u7684\u6307\u4ee4\u8ddf\u968f\u548c\u89d2\u8272\u5206\u5de5\u80fd\u529b\u3002", "result": "\u4e24\u4e2a\u6a21\u578b\u5728\u6570\u5b66\u3001\u7f16\u7a0b\u548c\u5b89\u5168\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u90fd\u53d6\u5f97\u4e86\u5f3a\u52b2\u8868\u73b0\u3002\u540c\u65f6\u652f\u6301\u6df1\u5ea6\u68c0\u7d22\u6d4f\u89c8\u3001python\u5de5\u5177\u8c03\u7528\u3001\u5f00\u53d1\u8005\u51fd\u6570\u96c6\u6210\u7b49\u9ad8\u7ea7\u667a\u80fd\u80fd\u529b\u3002\u6240\u6709\u6743\u91cd\u3001\u63a8\u7406\u4ee3\u7801\u3001\u5de5\u5177\u73af\u5883\u548c\u5206\u8bcd\u5668\u5747\u5df2\u4ee5Apache 2.0\u534f\u8bae\u5f00\u6e90\u3002", "conclusion": "\u63d0\u51fa\u4e86gpt-oss-120b\u548cgpt-oss-20b\u4e24\u4e2a\u5f00\u6e90\u63a8\u7406\u6a21\u578b\uff0c\u5728\u51c6\u786e\u7387\u548c\u63a8\u7406\u6210\u672c\u4e4b\u95f4\u53d6\u5f97\u65b0\u7a81\u7834\uff0c\u5e76\u8fbe\u5230\u4e86\u5148\u8fdb\u7684\u6d4b\u8bd5\u8868\u73b0\u3002\u6240\u6709\u6a21\u578b\u4e0e\u5de5\u5177\u5747\u5df2\u5f00\u6e90\uff0c\u652f\u6301\u5e7f\u6cdb\u4f7f\u7528\u548c\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2508.11447", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.11447", "abs": "https://arxiv.org/abs/2508.11447", "authors": ["Maximiliano Cristi\u00e1", "Gianfranco Rossi"], "title": "Encoding and Reasoning About Arrays in Set Theory", "comment": "Under consideration at ACM Transactions on Computational Logic", "summary": "We encode arrays as functions which, in turn, are encoded as sets of ordered\npairs. The set cardinality of each of these functions coincides with the length\nof the array it is representing. Then we define a fragment of set theory that\nis used to give the specifications of a non-trivial class of programs with\narrays. In this way, array reasoning becomes set reasoning. Furthermore, a\ndecision procedure for this fragment is also provided and implemented as part\nof the {log} (read 'setlog') tool. {log} is a constraint logic programming\nlanguage and satisfiability solver where sets and binary relations are\nfirst-class citizens. The tool already implements a few decision procedures for\ndifferent fragments of set theory. In this way, arrays are seamlessly\nintegrated into {log} thus allowing users to reason about sets, functions and\narrays all in the same language and with the same solver. The decision\nprocedure presented in this paper is an extension of decision procedures\ndefined in earlier works not supporting arrays.", "AI": {"tldr": "\u672c\u6587\u5c06\u6570\u7ec4\u7f16\u7801\u4e3a\u96c6\u5408\u4e2d\u7684\u51fd\u6570\uff0c\u63d0\u51fa\u4e86\u652f\u6301\u6570\u7ec4\u7684\u96c6\u5408\u8bba\u7247\u6bb5\u53ca\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5e76\u96c6\u6210\u5230{log}\u5de5\u5177\u4e2d\uff0c\u5b9e\u73b0\u4e86\u96c6\u5408\u3001\u51fd\u6570\u53ca\u6570\u7ec4\u7684\u7edf\u4e00\u63a8\u7406\u3002", "motivation": "\u4f20\u7edf\u4e0a\u5bf9\u6570\u7ec4\u7684\u63a8\u7406\u548c\u5904\u7406\u5f80\u5f80\u4e0e\u96c6\u5408\u548c\u51fd\u6570\u7684\u63a8\u7406\u5206\u79bb\uff0c\u7f3a\u4e4f\u7edf\u4e00\u65b9\u6cd5\uff0c\u4e14\u73b0\u6709\u7684\u51b3\u7b56\u8fc7\u7a0b\u4e0d\u652f\u6301\u6570\u7ec4\uff0c\u9650\u5236\u4e86\u5de5\u5177\u7684\u5e94\u7528\u8303\u56f4\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u5c06\u6570\u7ec4\u4e0e\u96c6\u5408\u63a8\u7406\u7edf\u4e00\u7684\u65b9\u6cd5\u3002", "method": "\u9996\u5148\u5c06\u6570\u7ec4\u7f16\u7801\u4e3a\u96c6\u5408\u4e2d\u7684\u51fd\u6570\uff08\u5373\u6709\u5e8f\u5bf9\u96c6\u5408\uff09\uff0c\u518d\u5b9a\u4e49\u96c6\u5408\u8bba\u7684\u4e00\u4e2a\u7247\u6bb5\u7528\u4e8e\u63cf\u8ff0\u7a0b\u5e8f\u4e2d\u7684\u6570\u7ec4\u89c4\u8303\u3002\u6700\u540e\u901a\u8fc7\u51b3\u7b56\u8fc7\u7a0b\u5b9e\u73b0\u5bf9\u8be5\u7406\u8bba\u7247\u6bb5\u7684\u53ef\u5224\u5b9a\u6027\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230{log}\u5de5\u5177\u4e2d\u3002", "result": "\u6210\u529f\u5b9a\u4e49\u5e76\u5b9e\u73b0\u4e86\u5bf9\u5e94\u7684\u96c6\u5408\u8bba\u7247\u6bb5\u53ca\u5176\u51b3\u7b56\u8fc7\u7a0b\uff0c\u6570\u7ec4\u63a8\u7406\u5f97\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230{log}\u5de5\u5177\u4e2d\uff0c\u6269\u5c55\u4e86\u5de5\u5177\u7684\u80fd\u529b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u6570\u7ec4\u7f16\u7801\u4e3a\u51fd\u6570\uff0c\u5e76\u8fdb\u4e00\u6b65\u7f16\u7801\u4e3a\u6709\u5e8f\u5bf9\u96c6\u5408\u7684\u65b9\u6cd5\uff0c\u8fdb\u800c\u5c06\u6570\u7ec4\u63a8\u7406\u8f6c\u5316\u4e3a\u96c6\u5408\u63a8\u7406\u3002\u8be5\u65b9\u6cd5\u5df2\u96c6\u6210\u5230{log}\u5de5\u5177\u4e2d\uff0c\u901a\u8fc7\u65b0\u7684\u51b3\u7b56\u8fc7\u7a0b\u5b9e\u73b0\u5bf9\u6570\u7ec4\u7684\u652f\u6301\uff0c\u4f7f\u5f97\u7528\u6237\u53ef\u7edf\u4e00\u5730\u5904\u7406\u96c6\u5408\u3001\u51fd\u6570\u548c\u6570\u7ec4\u3002"}}
{"id": "2508.11110", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11110", "abs": "https://arxiv.org/abs/2508.11110", "authors": ["Mukul Singh", "Gust Verbruggen", "Vu Le", "Sumit Gulwani"], "title": "Diffusion is a code repair operator and generator", "comment": "12 pages", "summary": "Code diffusion models generate code by iteratively removing noise from the\nlatent representation of a code snippet. During later steps of the diffusion\nprocess, when the code snippet has almost converged, differences between\ndiscrete representations of these snippets look like last-mile repairs applied\nto broken or incomplete code. We evaluate the extent to which this resemblance\ncan be exploited to leverage pre-trained code diffusion models for the problem\nof last-mile repair by considering two applications with significant potential.\nFirst, we can leverage the diffusion model for last-mile repair by adding noise\nto a broken code snippet and resuming the diffusion process. Second, we can\nleverage the diffusion model to generate arbitrary amount of training data for\nlast-mile repair tasks (that are computationally more efficient) by sampling an\nintermediate program (input) and the final program (output) from the diffusion\nprocess. We perform experiments on 3 domains (Python, Excel and PowerShell) to\nevaluate applications, as well as analyze properties.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u5e76\u9a8c\u8bc1\uff1a\u4ee3\u7801\u6269\u6563\u6a21\u578b\u5728\u6700\u540e\u9636\u6bb5\u7684\u53bb\u566a\u975e\u5e38\u9002\u5408\u4fee\u590d\u6b8b\u7f3a\u4ee3\u7801\u3002\u901a\u8fc7\u91cd\u542f\u6269\u6563\u8fc7\u7a0b\u6216\u751f\u6210\u4fee\u590d\u6570\u636e\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u4ee3\u7801\u81ea\u52a8\u4fee\u590d\u6548\u7387\uff0c\u5728Python\u3001Excel\u3001PowerShell\u7b49\u9886\u57df\u6548\u679c\u826f\u597d\u3002", "motivation": "\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u901a\u5e38\u9762\u4e34\u201c\u6700\u540e\u4e00\u516c\u91cc\u4fee\u590d\u201d\u95ee\u9898\uff0c\u5373\u81ea\u52a8\u751f\u6210\u7684\u4ee3\u7801\u5f80\u5f80\u5b58\u5728\u6700\u540e\u4e00\u4e9b\u5c0f\u9519\u8bef\u6216\u4e0d\u5b8c\u6574\u6027\uff0c\u9700\u8981\u4e3b\u52a8\u4fee\u590d\u3002\u5df2\u6709\u7684\u4ee3\u7801\u6269\u6563\u6a21\u578b\u5728\u8fed\u4ee3\u53bb\u566a\u8fc7\u7a0b\u4e2d\uff0c\u4e34\u8fd1\u6536\u655b\u9636\u6bb5\u7684\u751f\u6210\u4e0e\u6700\u540e\u4fee\u590d\u52a8\u4f5c\u975e\u5e38\u76f8\u4f3c\uff0c\u56e0\u6b64\u672c\u6587\u7814\u7a76\u5982\u4f55\u5229\u7528\u6269\u6563\u6a21\u578b\u8fd9\u4e00\u7279\u6027\u6765\u5e94\u5bf9\u6700\u540e\u4e00\u516c\u91cc\u4fee\u590d\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u5229\u7528\u9884\u8bad\u7ec3\u4ee3\u7801\u6269\u6563\u6a21\u578b\u7528\u4e8e\u6700\u540e\u4e00\u516c\u91cc\u4fee\u590d\u7684\u4e24\u79cd\u65b9\u6848\uff1a1\uff09\u5bf9\u635f\u574f\u7684\u4ee3\u7801\u52a0\u566a\u58f0\u540e\uff0c\u91cd\u65b0\u8fd0\u884c\u6269\u6563\u8fc7\u7a0b\u8fdb\u884c\u4fee\u590d\uff1b2\uff09\u5728\u6269\u6563\u8fc7\u7a0b\u4e2d\u91c7\u6837\u4e2d\u95f4\u6001\u4ee3\u7801\uff08\u4f5c\u4e3a\u8f93\u5165\uff09\u548c\u6700\u7ec8\u6001\u4ee3\u7801\uff08\u4f5c\u4e3a\u8f93\u51fa\uff09\uff0c\u81ea\u52a8\u751f\u6210\u8bad\u7ec3\u6570\u636e\uff0c\u4ee5\u652f\u6301\u66f4\u9ad8\u6548\u7684\u6700\u540e\u4e00\u516c\u91cc\u4fee\u590d\u8bad\u7ec3\u3002", "result": "\u5728\u4e09\u4e2a\u9886\u57df\uff08Python\u3001Excel\u3001PowerShell\uff09\u8fdb\u884c\u5b9e\u9a8c\u3002\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u5b9e\u73b0\u7684\u6700\u540e\u4e00\u516c\u91cc\u4fee\u590d\u7684\u6709\u6548\u6027\uff0c\u5e76\u5206\u6790\u4e86\u65b9\u6cd5\u5c5e\u6027\u3002", "conclusion": "\u6269\u6563\u6a21\u578b\u4e0d\u4ec5\u80fd\u751f\u6210\u4ee3\u7801\uff0c\u4e5f\u80fd\u80dc\u4efb\u6700\u540e\u4e00\u516c\u91cc\u81ea\u52a8\u4fee\u590d\u4efb\u52a1\uff1b\u540c\u65f6\u6269\u6563\u8fc7\u7a0b\u672c\u8eab\u53ef\u7528\u4f5c\u6570\u636e\u751f\u6210\u5668\uff0c\u4e3a\u76f8\u5173\u4fee\u590d\u4efb\u52a1\u63d0\u4f9b\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6837\u672c\uff0c\u62d3\u5c55\u4e86\u6269\u6563\u6a21\u578b\u5728\u4ee3\u7801\u667a\u80fd\u5904\u7406\u4e0a\u7684\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.10927", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.10927", "abs": "https://arxiv.org/abs/2508.10927", "authors": ["Jiaxin Pei", "Soumya Vadlamannati", "Liang-Kang Huang", "Daniel Preotiuc-Pietro", "Xinyu Hua"], "title": "Modeling and Detecting Company Risks from News: A Case Study in Bloomberg News", "comment": null, "summary": "Identifying risks associated with a company is important to investors and the\nwell-being of the overall financial market. In this study, we build a\ncomputational framework to automatically extract company risk factors from news\narticles. Our newly proposed schema comprises seven distinct aspects, such as\nsupply chain, regulations, and competitions. We sample and annotate 744 news\narticles and benchmark various machine learning models. While large language\nmodels have achieved huge progress in various types of NLP tasks, our\nexperiment shows that zero-shot and few-shot prompting state-of-the-art LLMs\n(e.g. LLaMA-2) can only achieve moderate to low performances in identifying\nrisk factors. And fine-tuned pre-trained language models are performing better\non most of the risk factors. Using this model, we analyze over 277K Bloomberg\nnews articles and demonstrate that identifying risk factors from news could\nprovide extensive insight into the operations of companies and industries.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u63d0\u53d6\u516c\u53f8\u98ce\u9669\u56e0\u7d20\u7684\u65b0\u95fb\u5206\u6790\u6846\u67b6\uff0c\u53d1\u73b0\u5fae\u8c03\u540e\u7684\u6a21\u578b\u6bd4\u5927\u8bed\u8a00\u6a21\u578b\u96f6/\u5c11\u6837\u672c\u8868\u73b0\u66f4\u4f18\uff0c\u5c55\u793a\u4e86\u4ece\u65b0\u95fb\u4e2d\u63d0\u53d6\u98ce\u9669\u56e0\u7d20\u7684\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u516c\u53f8\u98ce\u9669\u8bc6\u522b\u5bf9\u6295\u8d44\u8005\u548c\u91d1\u878d\u5e02\u573a\u5065\u5eb7\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5982\u4f55\u4ece\u65b0\u95fb\u4e2d\u81ea\u52a8\u63d0\u53d6\u516c\u53f8\u98ce\u9669\u56e0\u7d20\u5c1a\u672a\u88ab\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u8ba1\u7b97\u6846\u67b6\uff0c\u8bbe\u8ba1\u4e86\u5305\u542b\u4f9b\u5e94\u94fe\u3001\u6cd5\u89c4\u3001\u7ade\u4e89\u7b49\u4e03\u4e2a\u65b9\u9762\u7684\u65b0\u98ce\u9669\u56e0\u7d20\u63d0\u53d6schema\uff0c\u5bf9744\u7bc7\u65b0\u95fb\u8fdb\u884c\u4e86\u91c7\u6837\u548c\u4eba\u5de5\u6807\u6ce8\uff0c\u5e76\u57fa\u4e8e\u8fd9\u4e9b\u6570\u636e\u96c6\u6d4b\u8bd5\u4e86\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5305\u62ec\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982LLaMA-2\uff09\uff0c\u4ee5\u53ca\u7ecf\u8fc7\u5fae\u8c03\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u98ce\u9669\u56e0\u7d20\u8bc6\u522b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e00\u822c\u5230\u8f83\u5f31\uff0c\u5fae\u8c03\u540e\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u5927\u90e8\u5206\u98ce\u9669\u56e0\u7d20\u4e0a\u8868\u73b0\u66f4\u597d\u3002\u5229\u7528\u8868\u73b0\u8f83\u597d\u7684\u6a21\u578b\u5206\u6790\u4e86\u8d8527\u4e07\u7bc7\u5f6d\u535a\u65b0\u95fb\uff0c\u8bc1\u660e\u65b0\u95fb\u98ce\u9669\u56e0\u7d20\u6316\u6398\u80fd\u4e3a\u516c\u53f8\u548c\u884c\u4e1a\u8fd0\u8425\u63d0\u4f9b\u4e30\u5bcc\u6d1e\u89c1\u3002", "conclusion": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728NLP\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u7a81\u7834\uff0c\u4f46\u5728\u516c\u53f8\u98ce\u9669\u8bc6\u522b\u65b9\u9762\uff0c\u5fae\u8c03\u540e\u7684\u6a21\u578b\u6548\u679c\u66f4\u4f18\u3002\u81ea\u52a8\u5316\u6316\u6398\u65b0\u95fb\u4e2d\u7684\u516c\u53f8\u98ce\u9669\u56e0\u7d20\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2508.11449", "categories": ["cs.LO", "03B05 (Primary)"], "pdf": "https://arxiv.org/pdf/2508.11449", "abs": "https://arxiv.org/abs/2508.11449", "authors": ["Patrick Koopmann", "Christoph Wernhard", "Frank Wolter"], "title": "Interpolation in Classical Propositional Logic", "comment": "The article will appear in Balder ten Cate, Jean Christoph Jung,\n  Patrick Koopmann, Christoph Wernhard and Frank Wolter, editors. Theory and\n  Applications of Craig Interpolation. Ubiquity Press, 2026", "summary": "We introduce Craig interpolation and related notions such as uniform\ninterpolation, Beth definability, and theory decomposition in classical\npropositional logic. We present four approaches to computing interpolants: via\nquantifier elimination, from formulas in disjunctive normal form, and by\nextraction from resolution or tableau refutations. We close with a discussion\nof the size of interpolants and links to circuit complexity.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u4ecb\u7ecd\u4e86\u547d\u9898\u903b\u8f91\u4e2d\u7684\u63d2\u503c\u53ca\u76f8\u5173\u7406\u8bba\uff0c\u63d0\u51fa\u5e76\u6bd4\u8f83\u4e86\u56db\u79cd\u8ba1\u7b97\u63d2\u503c\u7684\u65b9\u6cd5\uff0c\u63a2\u8ba8\u4e86\u63d2\u503c\u590d\u6742\u5ea6\u4e0e\u7535\u8def\u590d\u6742\u6027\u7684\u5173\u7cfb\uff0c\u5bf9\u903b\u8f91\u5206\u89e3\u4e0e\u81ea\u52a8\u63a8\u7406\u5177\u6709\u53c2\u8003\u4ef7\u503c\u3002", "motivation": "\u672c\u8bba\u6587\u65e8\u5728\u4ecb\u7ecd\u5e76\u5206\u6790\u7ecf\u5178\u547d\u9898\u903b\u8f91\u4e2d\u7684Craig\u63d2\u503c\u53ca\u76f8\u5173\u6982\u5ff5\uff0c\u5982\u4e00\u81f4\u63d2\u503c\u3001Beth\u53ef\u5b9a\u4e49\u6027\u548c\u7406\u8bba\u5206\u89e3\uff0c\u89e3\u51b3\u903b\u8f91\u8868\u8fbe\u5f0f\u5206\u89e3\u4e0e\u63a8\u7406\u4e2d\u7684\u63d2\u503c\u95ee\u9898\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u56db\u79cd\u8ba1\u7b97\u63d2\u503c\u7684\u65b9\u6cd5\uff1a\u901a\u8fc7\u91cf\u8bcd\u6d88\u53bb\u3001\u4ece\u6790\u53d6\u8303\u5f0f\u516c\u5f0f\u51fa\u53d1\u3001\u4ee5\u53ca\u4ece\u6790\u53d6\u6216\u8868\u683c\u8bc1\u4f2a\u4e2d\u62bd\u53d6\u63d2\u503c\u3002", "result": "\u7cfb\u7edf\u5c55\u793a\u4e86\u6bcf\u79cd\u65b9\u6cd5\u7684\u8ba1\u7b97\u8fc7\u7a0b\uff0c\u5e76\u8ba8\u8bba\u4e86\u63d2\u503c\u516c\u5f0f\u7684\u590d\u6742\u5ea6\u4e0e\u7535\u8def\u590d\u6742\u6027\u7684\u8054\u7cfb\u3002", "conclusion": "\u63d2\u503c\u53ca\u76f8\u5173\u6982\u5ff5\u5bf9\u7406\u89e3\u4e0e\u5206\u89e3\u903b\u8f91\u7406\u8bba\u3001\u81ea\u52a8\u63a8\u7406\u548c\u590d\u6742\u6027\u5206\u6790\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u6b64\u5916\uff0c\u63d2\u503c\u516c\u5f0f\u7684\u89c4\u6a21\u4e0e\u8ba1\u7b97\u590d\u6742\u5ea6\u5bc6\u5207\u76f8\u5173\u3002"}}
{"id": "2508.11126", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.11126", "abs": "https://arxiv.org/abs/2508.11126", "authors": ["Huanting Wang", "Jingzhi Gong", "Huawei Zhang", "Zheng Wang"], "title": "AI Agentic Programming: A Survey of Techniques, Challenges, and Opportunities", "comment": null, "summary": "AI agentic programming is an emerging paradigm in which large language models\n(LLMs) autonomously plan, execute, and interact with external tools like\ncompilers, debuggers, and version control systems to iteratively perform\ncomplex software development tasks. Unlike conventional code generation tools,\nagentic systems are capable of decomposing high-level goals, coordinating\nmulti-step processes, and adapting their behavior based on intermediate\nfeedback. These capabilities are transforming the software development\npractice. As this emerging field evolves rapidly, there is a need to define its\nscope, consolidate its technical foundations, and identify open research\nchallenges. This survey provides a comprehensive and timely review of AI\nagentic programming. We introduce a taxonomy of agent behaviors and system\narchitectures, and examine core techniques including planning, memory and\ncontext management, tool integration, and execution monitoring. We also analyze\nexisting benchmarks and evaluation methodologies used to assess coding agent\nperformance. Our study identifies several key challenges, including limitations\nin handling long context, a lack of persistent memory across tasks, and\nconcerns around safety, alignment with user intent, and collaboration with\nhuman developers. We discuss emerging opportunities to improve the reliability,\nadaptability, and transparency of agentic systems. By synthesizing recent\nadvances and outlining future directions, this survey aims to provide a\nfoundation for research and development in building the next generation of\nintelligent and trustworthy AI coding agents.", "AI": {"tldr": "\u672c\u6587\u662f\u5bf9AI agentic\u7f16\u7a0b\u9886\u57df\u7684\u5168\u9762\u7efc\u8ff0\uff0c\u6db5\u76d6\u5176\u5b9a\u4e49\u3001\u6280\u672f\u65b9\u6cd5\u3001\u8bc4\u6d4b\u6307\u6807\u4e0e\u4e3b\u8981\u6311\u6218\uff0c\u5e76\u6307\u660e\u4e86\u672a\u6765\u7814\u7a76\u7684\u5173\u952e\u95ee\u9898\u548c\u53d1\u5c55\u8def\u5f84\uff0c\u9002\u5408\u76f8\u5173\u9886\u57df\u7814\u7a76\u8005\u53c2\u8003\u3002", "motivation": "AI agentic programming\u6b63\u5728\u5feb\u901f\u53d1\u5c55\uff0c\u800c\u5f53\u524d\u5bf9\u5176\u8303\u56f4\u3001\u6280\u672f\u57fa\u7840\u548c\u7814\u7a76\u6311\u6218\u5c1a\u7f3a\u4e4f\u7cfb\u7edf\u68b3\u7406\u3002\u7814\u7a76\u8005\u4e9f\u9700\u5bf9\u8be5\u9886\u57df\u8fdb\u884c\u5168\u9762\u56de\u987e\u548c\u603b\u7ed3\uff0c\u4ee5\u6307\u5f15\u540e\u7eed\u521b\u65b0\u548c\u53d1\u5c55\u3002", "method": "\u672c\u6587\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c\u7cfb\u7edf\u5316\u5206\u7c7b\uff0c\u6784\u5efa\u4e86AI agentic\u7f16\u7a0b\u7684\u884c\u4e3a\u4e0e\u7cfb\u7edf\u67b6\u6784\u5206\u7c7b\u6cd5\uff0c\u8bc4\u4f30\u4e86\u89c4\u5212\u3001\u8bb0\u5fc6\u7ba1\u7406\u3001\u5de5\u5177\u96c6\u6210\u3001\u6267\u884c\u76d1\u63a7\u7b49\u6838\u5fc3\u6280\u672f\u3002\u5206\u6790\u4e86\u73b0\u6709\u57fa\u51c6\u548c\u8bc4\u6d4b\u65b9\u6cd5\uff0c\u5e76\u5f52\u7eb3\u4e86\u9762\u4e34\u7684\u5173\u952e\u6280\u672f\u4e0e\u5e94\u7528\u6311\u6218\uff0c\u7ed3\u5408\u6700\u65b0\u53d1\u5c55\u8d8b\u52bf\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "result": "\u672c\u6587\u7cfb\u7edf\u68b3\u7406\u4e86AI agentic\u7f16\u7a0b\u9886\u57df\u7684\u6280\u672f\u57fa\u7840\u3001\u6838\u5fc3\u65b9\u6cd5\u548c\u8bc4\u4ef7\u4f53\u7cfb\uff0c\u6307\u51fa\u4e86\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u3001\u4efb\u52a1\u95f4\u6301\u4e45\u8bb0\u5fc6\u3001\u5b89\u5168\u4e0e\u610f\u56fe\u5bf9\u9f50\u3001\u4eba\u673a\u534f\u4f5c\u7b49\u5173\u952e\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u63d0\u5347\u7cfb\u7edf\u53ef\u9760\u6027\u3001\u9002\u5e94\u6027\u548c\u900f\u660e\u5ea6\u7684\u673a\u9047\u3002\u4e3a\u540e\u7eed\u667a\u80fd\u53ef\u9760\u7684AI\u7f16\u7a0b\u4ee3\u7406\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002", "conclusion": "AI agentic\u7f16\u7a0b\u6b63\u63a8\u52a8\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\u53d8\u9769\uff0c\u867d\u7136\u6280\u672f\u8fdb\u5c55\u8fc5\u901f\uff0c\u4f46\u4ecd\u9762\u4e34\u8bf8\u591a\u6311\u6218\u3002\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\uff0c\u660e\u786e\u4e86\u53d1\u5c55\u73b0\u72b6\u548c\u96be\u9898\uff0c\u4e3a\u8be5\u9886\u57df\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u548c\u57fa\u7840\u3002"}}
{"id": "2508.10971", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.10971", "abs": "https://arxiv.org/abs/2508.10971", "authors": ["Nasim Shirvani-Mahdavi", "Chengkai Li"], "title": "Rule2Text: A Framework for Generating and Evaluating Natural Language Explanations of Knowledge Graph Rules", "comment": "arXiv admin note: text overlap with arXiv:2507.23740", "summary": "Knowledge graphs (KGs) can be enhanced through rule mining; however, the\nresulting logical rules are often difficult for humans to interpret due to\ntheir inherent complexity and the idiosyncratic labeling conventions of\nindividual KGs. This work presents Rule2Text, a comprehensive framework that\nleverages large language models (LLMs) to generate natural language\nexplanations for mined logical rules, thereby improving KG accessibility and\nusability. We conduct extensive experiments using multiple datasets, including\nFreebase variants (FB-CVT-REV, FB+CVT-REV, and FB15k-237) as well as the\nogbl-biokg dataset, with rules mined using AMIE 3.5.1. We systematically\nevaluate several LLMs across a comprehensive range of prompting strategies,\nincluding zero-shot, few-shot, variable type incorporation, and\nChain-of-Thought reasoning. To systematically assess models' performance, we\nconduct a human evaluation of generated explanations on correctness and\nclarity. To address evaluation scalability, we develop and validate an\nLLM-as-a-judge framework that demonstrates strong agreement with human\nevaluators. Leveraging the best-performing model (Gemini 2.0 Flash), LLM judge,\nand human-in-the-loop feedback, we construct high-quality ground truth\ndatasets, which we use to fine-tune the open-source Zephyr model. Our results\ndemonstrate significant improvements in explanation quality after fine-tuning,\nwith particularly strong gains in the domain-specific dataset. Additionally, we\nintegrate a type inference module to support KGs lacking explicit type\ninformation. All code and data are publicly available at\nhttps://github.com/idirlab/KGRule2NL.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5c06\u590d\u6742\u7684\u77e5\u8bc6\u56fe\u8c31\u6316\u6398\u89c4\u5219\u8f6c\u5316\u4e3a\u6613\u61c2\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u8bc4\u4ef7\u7ef4\u5ea6\u4e0a\u8bc1\u5b9e\u4e86\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u89c4\u5219\u53ef\u7528\u6027\u548c\u89e3\u91ca\u8d28\u91cf\u3002\u4f5c\u8005\u8fd8\u5f00\u653e\u4e86\u6240\u6709\u6570\u636e\u548c\u4ee3\u7801\u8d44\u6e90\u3002", "motivation": "\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u89c4\u5219\u6316\u6398\u6709\u52a9\u4e8e\u63d0\u5347\u77e5\u8bc6\u56fe\u8c31\u80fd\u529b\uff0c\u4f46\u6316\u6398\u51fa\u7684\u903b\u8f91\u89c4\u5219\u901a\u5e38\u96be\u4ee5\u88ab\u4eba\u7c7b\u7406\u89e3\uff0c\u4e3b\u8981\u56e0\u4e3a\u89c4\u5219\u590d\u6742\u4e14\u6807\u7b7e\u547d\u540d\u65b9\u5f0f\u5404\u5f02\uff0c\u5bfc\u81f4\u53ef\u7528\u6027\u964d\u4f4e\u3002", "method": "\u63d0\u51faRule2Text\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u903b\u8f91\u89c4\u5219\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002\u7814\u7a76\u5728\u591a\u4e2a\u6570\u636e\u96c6\uff08\u5982Freebase\u53d8\u4f53\u548cogbl-biokg\uff09\u4e0a\u6d4b\u8bd5\u4e0d\u540c\u7684LLM\u53ca\u4e30\u5bcc\u7684\u63d0\u793a\u7b56\u7565\uff0c\u5e76\u7531\u4eba\u5de5\u548c\u201cLLM\u8bc4\u5224\u5458\u201d\u5bf9\u751f\u6210\u89e3\u91ca\u7684\u6b63\u786e\u6027\u548c\u6e05\u6670\u5ea6\u8fdb\u884c\u8bc4\u4f30\u3002\u6b64\u5916\u6784\u5efa\u9ec4\u91d1\u6570\u636e\u96c6\u5e76\u901a\u8fc7\u5fae\u8c03\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u8868\u73b0\uff0c\u52a0\u5165\u7c7b\u578b\u63a8\u65ad\u6a21\u5757\u4ee5\u652f\u6301\u6ca1\u6709\u663e\u5f0f\u7c7b\u578b\u4fe1\u606f\u7684KG\u3002", "result": "\u5fae\u8c03\u540e\u7684\u5f00\u6e90Zephyr\u6a21\u578b\u5728\u89e3\u91ca\u8d28\u91cf\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u5c24\u5176\u662f\u5728\u7279\u5b9a\u9886\u57df\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u7a81\u51fa\uff1b\u7c7b\u578b\u63a8\u65ad\u6a21\u5757\u6709\u6548\u6269\u5c55\u4e86\u7cfb\u7edf\u7684\u9002\u7528\u8303\u56f4\u3002", "conclusion": "Rule2Text\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31\u89c4\u5219\u7684\u53ef\u89e3\u91ca\u6027\u4e0e\u53ef\u7528\u6027\uff0c\u4ee3\u7801\u4e0e\u6570\u636e\u516c\u5f00\uff0c\u6709\u5229\u4e8e\u672a\u6765\u76f8\u5173\u7814\u7a76\u548c\u5e94\u7528\u3002"}}
{"id": "2508.11515", "categories": ["cs.LO", "cs.AI", "03C13, 68T27", "F.4.0"], "pdf": "https://arxiv.org/pdf/2508.11515", "abs": "https://arxiv.org/abs/2508.11515", "authors": ["Qipeng Kuang", "V\u00e1clav K\u016fla", "Ond\u0159ej Ku\u017eelka", "Yuanhong Wang", "Yuyi Wang"], "title": "Weighted First Order Model Counting for Two-variable Logic with Axioms on Two Relations", "comment": "24 pages, 5 figures", "summary": "The Weighted First-Order Model Counting Problem (WFOMC) asks to compute the\nweighted sum of models of a given first-order logic sentence over a given\ndomain. The boundary between fragments for which WFOMC can be computed in\npolynomial time relative to the domain size lies between the two-variable\nfragment ($\\text{FO}^2$) and the three-variable fragment ($\\text{FO}^3$). It is\nknown that WFOMC for \\FOthree{} is $\\mathsf{\\#P_1}$-hard while polynomial-time\nalgorithms exist for computing WFOMC for $\\text{FO}^2$ and $\\text{C}^2$,\npossibly extended by certain axioms such as the linear order axiom, the\nacyclicity axiom, and the connectedness axiom. All existing research has\nconcentrated on extending the fragment with axioms on a single distinguished\nrelation, leaving a gap in understanding the complexity boundary of axioms on\nmultiple relations. In this study, we explore the extension of the two-variable\nfragment by axioms on two relations, presenting both negative and positive\nresults. We show that WFOMC for $\\text{FO}^2$ with two linear order relations\nand $\\text{FO}^2$ with two acyclic relations are $\\mathsf{\\#P_1}$-hard.\nConversely, we provide an algorithm in time polynomial in the domain size for\nWFOMC of $\\text{C}^2$ with a linear order relation, its successor relation and\nanother successor relation.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u5e26\u591a\u4e2a\u5173\u7cfb\u6269\u5c55\u7684\u4e8c\u5143\u4e00\u9636\u6a21\u578b\u8ba1\u6570\u95ee\u9898\uff0c\u9996\u6b21\u63ed\u793a\uff1a\u67d0\u4e9b\u6269\u5c55\u4f7f\u95ee\u9898\u53d8\u4e3a#P1\u96be\uff0c\u4f46\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u4ecd\u53ef\u9ad8\u6548\u6c42\u89e3\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u53ea\u5173\u6ce8\u5355\u4e00\u5173\u7cfb\u7684\u6269\u5c55\uff0c\u7f3a\u4e4f\u5bf9\u591a\u5173\u7cfb\u6269\u5c55\u4e0b\u590d\u6742\u6027\u8fb9\u754c\u7684\u7406\u89e3\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8be5\u7a7a\u767d\uff0c\u5c06\u5206\u6790\u6269\u5c55\u5230\u4e24\u4e2a\u5173\u7cfb\u3002", "method": "\u5728WFOMC\u95ee\u9898\u4e2d\u7cfb\u7edf\u5206\u6790\u4e8c\u5143\u7247\u6bb5\u6269\u5c55\u81f3\u591a\u4e2a\u5173\u7cfb\u65f6\u7684\u590d\u6742\u6027\uff0c\u5206\u522b\u8bc1\u660e\u67d0\u4e9b\u60c5\u51b5\u4e3a#P1\u96be\uff0c\u5e76\u4e3a\u7279\u5b9a\u5173\u7cfb\u7ec4\u5408\u8bbe\u8ba1\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002", "result": "\u53d1\u73b0\uff1a\u5bf9\u4e8eFO^2\u7247\u6bb5\uff0c\u6dfb\u52a0\u4e24\u4e2a\u7ebf\u6027\u5e8f\u6216\u4e24\u4e2a\u65e0\u73af\u5173\u7cfb\u4f1a\u4f7fWFOMC\u53d8\u4e3a#P1\u96be\uff1b\u800cC^2\u7247\u6bb5\u52a0\u4e0a\u4e00\u4e2a\u7ebf\u6027\u5e8f\u53ca\u4e24\u4e2a\u7ee7\u4efb\u5173\u7cfb\u53ef\u4ee5\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u8ba1\u7b97WFOMC\u3002", "conclusion": "WFOMC\u5728\u4e24\u4e2a\u5173\u7cfb\u4e0a\u6269\u5c55\u7684\u4e8c\u5143\u7247\u6bb5\u6709\u590d\u6742\u6027\u8fb9\u754c\uff1a\u52a0\u5165\u4e24\u4e2a\u7ebf\u6027\u5e8f\u6216\u4e24\u4e2a\u65e0\u73af\u5173\u7cfb\u4f1a\u5bfc\u81f4#P1\u96be\uff0c\u800c\u5728\u67d0\u4e9b\u7ee7\u4efb\u5173\u7cfb\u7684\u6269\u5c55\u4e0b\u4ecd\u53ef\u591a\u9879\u5f0f\u65f6\u95f4\u8ba1\u7b97\u3002"}}
{"id": "2508.11147", "categories": ["cs.SE", "D.2.5"], "pdf": "https://arxiv.org/pdf/2508.11147", "abs": "https://arxiv.org/abs/2508.11147", "authors": ["Zhengquan Li", "Zhenhao Li", "Zishuo Ding"], "title": "From Feedback to Failure: Automated Android Performance Issue Reproduction", "comment": "10page, 8 figures", "summary": "Mobile application performance is a vital factor for user experience. Yet,\nperformance issues are notoriously difficult to detect within development\nenvironments, where their manifestations are often less conspicuous and\ndiagnosis proves more challenging. To address this limitation, we propose\nRevPerf, an advanced performance issue reproduction tool that leverages app\nreviews from Google Play to acquire pertinent information. RevPerf employs\nrelevant reviews and prompt engineering to enrich the original review with\nperformance issue details. An execution agent is then employed to generate and\nexecute commands to reproduce the issue. After executing all necessary steps,\nthe system incorporates multifaceted detection methods to identify performance\nissues by monitoring Android logs, GUI changes, and system resource utilization\nduring the reproduction process. Experimental results demonstrate that our\nproposed framework achieves a 70\\% success rate in reproducing performance\nissues on the dataset we constructed and manually validated.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u7528\u6237\u8bc4\u8bba\u3001\u63d0\u793a\u5de5\u7a0b\u4e0e\u591a\u91cd\u76d1\u63a7\u673a\u5236\u7684\u79fb\u52a8\u5e94\u7528\u6027\u80fd\u95ee\u9898\u81ea\u52a8\u590d\u73b0\u7cfb\u7edfRevPerf\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f9770%\u590d\u73b0\u6210\u529f\u7387\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6027\u80fd\u95ee\u9898\u7684\u81ea\u52a8\u68c0\u6d4b\u548c\u5b9a\u4f4d\u80fd\u529b\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u6027\u80fd\u5f88\u5927\u7a0b\u5ea6\u4e0a\u5f71\u54cd\u7528\u6237\u4f53\u9a8c\uff0c\u800c\u5f00\u53d1\u73af\u5883\u4e0b\u6027\u80fd\u95ee\u9898\u96be\u4ee5\u68c0\u6d4b\u4e14\u8bca\u65ad\u56f0\u96be\u3002\u73b0\u6709\u590d\u73b0\u65b9\u6cd5\u53d7\u9650\u4e8e\u4fe1\u606f\u4e0d\u5168\u4e0e\u81ea\u52a8\u5316\u7a0b\u5ea6\u4f4e\uff0c\u56e0\u6b64\u4e9f\u9700\u66f4\u667a\u80fd\u548c\u9ad8\u6548\u7684\u6027\u80fd\u95ee\u9898\u590d\u73b0\u65b9\u6848\u3002", "method": "RevPerf\u9996\u5148\u4eceGoogle Play\u4e2d\u83b7\u53d6\u76f8\u5173\u5e94\u7528\u8bc4\u8bba\uff0c\u901a\u8fc7prompt engineering\u6280\u672f\u4e30\u5bcc\u8bc4\u8bba\u7ec6\u8282\uff0c\u968f\u540e\u5229\u7528\u6267\u884c\u667a\u80fd\u4f53\u81ea\u52a8\u751f\u6210\u5e76\u6267\u884c\u590d\u73b0\u6027\u80fd\u95ee\u9898\u7684\u64cd\u4f5c\u6d41\u7a0b\uff0c\u5e76\u7ed3\u5408\u591a\u79cd\u68c0\u6d4b\u673a\u5236\uff08\u76d1\u63a7Android\u65e5\u5fd7\u3001GUI\u53d8\u5316\u53ca\u7cfb\u7edf\u8d44\u6e90\u5229\u7528\u7387\uff09\u8fdb\u884c\u95ee\u9898\u8bc6\u522b\u3002", "result": "\u63d0\u51fa\u7684RevPerf\u5de5\u5177\u5728\u7ecf\u8fc7\u624b\u52a8\u9a8c\u8bc1\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u5b9e\u73b0\u4e8670%\u7684\u6027\u80fd\u95ee\u9898\u590d\u73b0\u6210\u529f\u7387\u3002", "conclusion": "RevPerf\u7cfb\u7edf\u80fd\u6709\u6548\u63d0\u5347\u57fa\u4e8e\u7528\u6237\u8bc4\u8bba\u7684\u79fb\u52a8\u5e94\u7528\u6027\u80fd\u95ee\u9898\u590d\u73b0\u7684\u81ea\u52a8\u5316\u4e0e\u51c6\u786e\u6027\uff0c\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e8670%\u7684\u590d\u73b0\u6210\u529f\u7387\u3002"}}
{"id": "2508.10995", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.10995", "abs": "https://arxiv.org/abs/2508.10995", "authors": ["Tejomay Kishor Padole", "Suyash P Awate", "Pushpak Bhattacharyya"], "title": "Improving Text Style Transfer using Masked Diffusion Language Models with Inference-time Scaling", "comment": "Accepted as a main conference submission in the European Conference\n  on Artificial Intelligence (ECAI 2025)", "summary": "Masked diffusion language models (MDMs) have recently gained traction as a\nviable generative framework for natural language. This can be attributed to its\nscalability and ease of training compared to other diffusion model paradigms\nfor discrete data, establishing itself as the state-of-the-art\nnon-autoregressive generator for discrete data. Diffusion models, in general,\nhave shown excellent ability to improve the generation quality by leveraging\ninference-time scaling either by increasing the number of denoising steps or by\nusing external verifiers on top of the outputs of each step to guide the\ngeneration. In this work, we propose a verifier-based inference-time scaling\nmethod that aids in finding a better candidate generation during the denoising\nprocess of the MDM. Our experiments demonstrate the application of MDMs for\nstandard text-style transfer tasks and establish MDMs as a better alternative\nto autoregressive language models. Additionally, we show that a simple\nsoft-value-based verifier setup for MDMs using off-the-shelf pre-trained\nembedding models leads to significant gains in generation quality even when\nused on top of typical classifier-free guidance setups in the existing\nliterature.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u63a9\u7801\u6269\u6563\u8bed\u8a00\u6a21\u578b(MDM)\uff0c\u63d0\u51fa\u5229\u7528\u9884\u8bad\u7ec3\u5d4c\u5165\u6a21\u578b\u4f5c\u4e3a\u8f6f\u503c\u9a8c\u8bc1\u5668\u7684\u63a8\u65ad\u65f6\u95f4\u6269\u5c55\u65b9\u6cd5\uff0c\u53ef\u663e\u8457\u63d0\u5347\u6587\u672c\u751f\u6210\u8d28\u91cf\uff0c\u5e76\u5728\u98ce\u683c\u8fc1\u79fb\u7b49\u4efb\u52a1\u4e0a\u8d85\u8d8a\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u751f\u6210\u4e2d\u666e\u904d\u8868\u73b0\u4f18\u826f\uff0c\u4f46\u8fdb\u4e00\u6b65\u63d0\u5347\u751f\u6210\u8d28\u91cf\u7684\u65b9\u6cd5\u9700\u63a2\u7d22\uff0c\u5c24\u5176\u662f\u5728\u63a8\u65ad\u9636\u6bb5\u7684\u6307\u5bfc\u673a\u5236\u548c\u4e0e\u81ea\u56de\u5f52\u6a21\u578b\u7684\u5bf9\u6bd4\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728MDM\u53bb\u566a\u8fc7\u7a0b\u4e2d\u5229\u7528\u5916\u90e8\u9a8c\u8bc1\u5668\u5f15\u5bfc\u751f\u6210\u7684\u63a8\u65ad\u65f6\u95f4\u6269\u5c55\u65b9\u6cd5\uff0c\u5e76\u91c7\u7528\u8f6f\u503c\u9a8c\u8bc1\u5668\u7ed3\u5408\u9884\u8bad\u7ec3\u5d4c\u5165\u6a21\u578b\u6765\u4f18\u5316\u751f\u6210\u3002", "result": "\u5728\u6587\u672c\u98ce\u683c\u8fc1\u79fb\u7b49\u4efb\u52a1\u4e0a\uff0cMDM\u53d6\u5f97\u4e86\u4f18\u4e8e\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u901a\u8fc7\u8f6f\u503c\u9a8c\u8bc1\u5668\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u751f\u6210\u8d28\u91cf\u63d0\u5347\u3002", "conclusion": "\u9a8c\u8bc1\u5668\u8f85\u52a9\u7684\u63a8\u65ad\u65f6\u95f4\u6269\u5c55\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347MDM\u7684\u751f\u6210\u8d28\u91cf\uff0c\u4f7f\u5176\u6210\u4e3a\u4e00\u79cd\u4f18\u4e8e\u81ea\u56de\u5f52\u6a21\u578b\u7684\u6587\u672c\u751f\u6210\u6846\u67b6\u3002"}}
{"id": "2508.11623", "categories": ["cs.LO", "06B35, 06F07", "F.3.2"], "pdf": "https://arxiv.org/pdf/2508.11623", "abs": "https://arxiv.org/abs/2508.11623", "authors": ["Francesco Dagnino", "Amin Farjudian Eugenio Moggi"], "title": "Robust Topology and the Hausdorff-Smyth Monad on Metric Spaces over Continuous Quantales", "comment": "28 pages, 6 figures", "summary": "We define a (preorder-enriched) category $\\mathsf{Met}$ of quantale-valued\nmetric spaces and uniformly continuous maps, with the essential requirement\nthat the quantales are continuous. For each object $(X,d,Q)$ in this category,\nwhere $X$ is the carrier set, $Q$ is a continuous quantale, and $d: X \\times X\n\\to Q$ is the metric, we consider a topology $\\tau_d$ on $X$, which generalizes\nthe open ball topology, and a topology $\\tau_{d,R}$ on the powerset\n$\\mathsf{P}(X)$, called the robust topology, which captures robustness with\nrespect to small perturbations of parameters. We define a (preorder-enriched)\nmonad $\\mathsf{P}_S$ on $\\mathsf{Met}$, called the Hausdorff-Smyth monad, which\ncaptures the robust topology, in the sense that the open ball topology of the\nobject $\\mathsf{P}_S(X,d,Q)$ coincides with the robust topology $\\tau_{d,R}$\nfor the object $(X,d,Q)$. We prove that every topology arises from a\nquantale-valued metric. As such, our framework provides a foundation for\nquantitative reasoning about imprecision and robustness in a wide range of\ncomputational and physical systems.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9a\u4e49\u5177\u6709\u8fde\u7eed\u91cf\u7eb2\u7684\u91cf\u7eb2\u503c\u5ea6\u91cf\u7a7a\u95f4\u8303\u7574\u548c\u76f8\u5173\u7684Hausdorff-Smyth\u5e7a\u534a\u8303\u7574\uff0c\u5b9e\u73b0\u4e86\u9c81\u68d2\u62d3\u6251\u4e0e\u5ea6\u91cf\u7a7a\u95f4\u62d3\u6251\u7684\u7edf\u4e00\u3002\u8be5\u6846\u67b6\u4e3a\u8ba1\u7b97\u4e0e\u7269\u7406\u7cfb\u7edf\u4e2d\u7684\u4e0d\u7cbe\u786e\u6027\u548c\u9c81\u68d2\u6027\u5efa\u6a21\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u8bc1\u660e\u6bcf\u4e00\u62d3\u6251\u90fd\u80fd\u7531\u76f8\u5e94\u7684\u91cf\u7eb2\u503c\u5ea6\u91cf\u8bf1\u5bfc\u800c\u6765\u3002", "motivation": "\u73b0\u6709\u7684\u62d3\u6251\u4e0e\u5ea6\u91cf\u7a7a\u95f4\u7406\u8bba\u5728\u5904\u7406\u9c81\u68d2\u6027\u548c\u53c2\u6570\u5fae\u5c0f\u6270\u52a8\u65f6\u5b58\u5728\u5c40\u9650\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u5b9a\u91cf\u5206\u6790\u8ba1\u7b97\u4e0e\u7269\u7406\u7cfb\u7edf\u4e2d\u7684\u4e0d\u7cbe\u786e\u6027\u548c\u9c81\u68d2\u6027\u65f6\u3002\u8be5\u6587\u65e8\u5728\u5efa\u7acb\u66f4\u4e00\u822c\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4ee5\u589e\u5f3a\u5bf9\u8fd9\u4e9b\u73b0\u8c61\u7684\u5efa\u6a21\u548c\u5206\u6790\u80fd\u529b\u3002", "method": "\u8be5\u6587\u5b9a\u4e49\u4e86\u4e00\u4e2a\u4ee5\u524d\u5e8f\u5bcc\u96c6\u8303\u7574\u4e3a\u57fa\u7840\u7684\u91cf\u7eb2\u503c\u5ea6\u91cf\u7a7a\u95f4\u4e0e\u4e00\u81f4\u8fde\u7eed\u6620\u5c04\uff08$\textsf{Met}$\uff09\uff0c\u5176\u6838\u5fc3\u8981\u6c42\u662f\u91cf\u7eb2\u4e3a\u8fde\u7eed\u91cf\u7eb2\u3002\u5728\u6b64\u6846\u67b6\u4e0b\uff0c\u63d0\u51fa\u4e86\u5e7f\u4e49\u7684\u5f00\u7403\u62d3\u6251\u548c\u5b50\u96c6\u5e42\u96c6\u4e0a\u7684\u9c81\u68d2\u62d3\u6251\uff0c\u5e76\u5229\u7528\u524d\u5e8f\u5bcc\u96c6\u5e7a\u534a\u8303\u7574\uff08$\textsf{P}_S$\uff0cHausdorff-Smyth\u5e7a\u534a\u8303\u7574\uff09\u63cf\u8ff0\u9c81\u68d2\u62d3\u6251\u4e0e\u5f00\u7403\u62d3\u6251\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb\u3002", "result": "\u5efa\u7acb\u4e86$\textsf{Met}$\u8303\u7574\u53ca\u5176\u4e0a\u7684$\textsf{P}_S$\u5e7a\u534a\u8303\u7574\uff0c\u8bc1\u660e\u4e86\u5bf9\u6bcf\u4e00\u4e2a\u62d3\u6251\u90fd\u6709\u76f8\u5e94\u7684\u91cf\u7eb2\u503c\u5ea6\u91cf\u5b58\u5728\uff0c\u4ece\u800c\u7edf\u4e00\u4e86\u9c81\u68d2\u62d3\u6251\u548c\u5e7f\u4e49\u5f00\u7403\u62d3\u6251\u7684\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u8be5\u7406\u8bba\u6846\u67b6\u4e3a\u5b9a\u91cf\u5206\u6790\u8ba1\u7b97\u4e0e\u7269\u7406\u7cfb\u7edf\u4e2d\u7684\u4e0d\u7cbe\u786e\u6027\u548c\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u53ef\u5e94\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u573a\u666f\uff0c\u63a8\u52a8\u9c81\u68d2\u6027\u548c\u4e0d\u7cbe\u786e\u5efa\u6a21\u7684\u7406\u8bba\u53d1\u5c55\u3002"}}
{"id": "2508.11179", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.11179", "abs": "https://arxiv.org/abs/2508.11179", "authors": ["Pei Liu", "Terry Zhuo", "Jiawei Deng", "Zhenchang Xing", "Qinghua Lu", "Xiaoning Du", "Hongyu Zhan"], "title": "PTMPicker: Facilitating Efficient Pretrained Model Selection for Application Developers", "comment": null, "summary": "The rapid emergence of pretrained models (PTMs) has attracted significant\nattention from both Deep Learning (DL) researchers and downstream application\ndevelopers. However, selecting appropriate PTMs remains challenging because\nexisting methods typically rely on keyword-based searches in which the keywords\nare often derived directly from function descriptions. This often fails to\nfully capture user intent and makes it difficult to identify suitable models\nwhen developers also consider factors such as bias mitigation, hardware\nrequirements, or license compliance. To address the limitations of\nkeyword-based model search, we propose PTMPicker to accurately identify\nsuitable PTMs. We first define a structured template composed of common and\nessential attributes for PTMs and then PTMPicker represents both candidate\nmodels and user-intended features (i.e., model search requests) in this unified\nformat. To determine whether candidate models satisfy user requirements, it\ncomputes embedding similarities for function-related attributes and uses\nwell-crafted prompts to evaluate special constraints such as license compliance\nand hardware requirements. We scraped a total of 543,949 pretrained models from\nHugging Face to prepare valid candidates for selection. PTMPicker then\nrepresented them in the predefined structured format by extracting their\nassociated descriptions. Guided by the extracted metadata, we synthesized a\ntotal of 15,207 model search requests with carefully designed prompts, as no\nsuch search requests are readily available. Experiments on the curated PTM\ndataset and the synthesized model search requests show that PTMPicker can help\nusers effectively identify models,with 85% of the sampled requests successfully\nlocating appropriate PTMs within the top-10 ranked candidates.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPTMPicker\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6a21\u677f\u7edf\u4e00\u8868\u8fbe\u6a21\u578b\u4e0e\u7528\u6237\u9700\u6c42\uff0c\u7528embedding\u548cprompt\u8bc4\u4ef7\u6a21\u578b\u5339\u914d\u5ea6\uff0c\u8fdc\u8d85\u73b0\u6709\u5173\u952e\u8bcd\u68c0\u7d22\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u80fd\u6709\u6548\u5e2e\u52a9\u7528\u6237\u9ad8\u6548\u9009\u53d6\u517c\u987e\u591a\u79cd\u7ea6\u675f\u7684PTM\u3002", "motivation": "\u73b0\u6709PTM\u6a21\u578b\u641c\u5bfb\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u5173\u952e\u8bcd\u641c\u7d22\uff0c\u96be\u4ee5\u5145\u5206\u6355\u6349\u7528\u6237\u5b9e\u9645\u9700\u6c42\uff0c\u5c24\u5176\u5728\u6d89\u53ca\u504f\u89c1\u6d88\u9664\u3001\u786c\u4ef6\u8981\u6c42\u6216\u8bb8\u53ef\u5408\u89c4\u7b49\u975e\u529f\u80fd\u6027\u7ea6\u675f\u65f6\uff0c\u96be\u4ee5\u627e\u5230\u5408\u9002\u7684\u6a21\u578b\u3002\u4f5c\u8005\u5e0c\u671b\u89e3\u51b3\u8fd9\u4e00\u9650\u5236\u3002", "method": "PTMPicker\u65b9\u6cd5\uff1a\u9996\u5148\u5b9a\u4e49PTM\u5e38\u7528\u6838\u5fc3\u5c5e\u6027\u7ed3\u6784\u5316\u6a21\u677f\uff1b\u7136\u540e\u5c06\u5019\u9009\u6a21\u578b\u548c\u7528\u6237\u9700\u6c42\u7edf\u4e00\u8868\u8fbe\u4e3a\u7ed3\u6784\u5316\u5f62\u5f0f\u3002\u9488\u5bf9\u529f\u80fd\u6027\u5c5e\u6027\u8ba1\u7b97embedding\u76f8\u4f3c\u5ea6\uff0c\u9488\u5bf9\u7279\u6b8a\u7ea6\u675f\uff08\u5982\u8bb8\u53ef\u3001\u786c\u4ef6\uff09\u7528\u7cbe\u5fc3\u8bbe\u8ba1\u7684prompt\u8fdb\u884c\u8bc4\u4f30\u3002\u5171\u6536\u96c6\u4e86543,949\u4e2aHugging Face\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u62bd\u53d6\u5176\u63cf\u8ff0\u8f6c\u4e3a\u7ed3\u6784\u5316\u683c\u5f0f\u3002\u5408\u621015,207\u4e2a\u6a21\u578b\u641c\u7d22\u8bf7\u6c42\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5728\u7cbe\u5fc3\u6784\u5efa\u7684PTM\u6570\u636e\u96c6\u53ca\u5408\u6210\u641c\u7d22\u8bf7\u6c42\u4e0a\uff0cPTMPicker\u80fd\u5e2e\u52a9\u7528\u6237\u9ad8\u6548\u9009\u53d6\u6a21\u578b\uff0c85%\u7684\u6837\u672c\u8bf7\u6c42\u80fd\u5728Top-10\u5019\u9009\u4e2d\u6210\u529f\u627e\u5230\u5408\u9002PTM\u3002", "conclusion": "PTMPicker\u663e\u8457\u63d0\u5347\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u68c0\u7d22\u6548\u679c\uff0c\u5c24\u5176\u80fd\u66f4\u597d\u6ee1\u8db3\u975e\u76f4\u63a5\u529f\u80fd\u6027\u9650\u5236\uff0c\u6539\u5584\u7528\u6237\u9009\u578b\u4f53\u9a8c\u3002"}}
{"id": "2508.11009", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11009", "abs": "https://arxiv.org/abs/2508.11009", "authors": ["Wenpeng Xing", "Lanyi Wei", "Haixiao Hu", "Rongchang Li", "Mohan Li", "Changting Lin", "Meng Han"], "title": "SproutBench: A Benchmark for Safe and Ethical Large Language Models for Youth", "comment": null, "summary": "The rapid proliferation of large language models (LLMs) in applications\ntargeting children and adolescents necessitates a fundamental reassessment of\nprevailing AI safety frameworks, which are largely tailored to adult users and\nneglect the distinct developmental vulnerabilities of minors. This paper\nhighlights key deficiencies in existing LLM safety benchmarks, including their\ninadequate coverage of age-specific cognitive, emotional, and social risks\nspanning early childhood (ages 0--6), middle childhood (7--12), and adolescence\n(13--18). To bridge these gaps, we introduce SproutBench, an innovative\nevaluation suite comprising 1,283 developmentally grounded adversarial prompts\ndesigned to probe risks such as emotional dependency, privacy violations, and\nimitation of hazardous behaviors. Through rigorous empirical evaluation of 47\ndiverse LLMs, we uncover substantial safety vulnerabilities, corroborated by\nrobust inter-dimensional correlations (e.g., between Safety and Risk\nPrevention) and a notable inverse relationship between Interactivity and Age\nAppropriateness. These insights yield practical guidelines for advancing\nchild-centric AI design and deployment.", "AI": {"tldr": "\u5f53\u524dAI\u5b89\u5168\u8bc4\u4f30\u5ffd\u89c6\u672a\u6210\u5e74\u7fa4\u4f53\uff0c\u4f5c\u8005\u63d0\u51fa\u5e76\u5b9e\u6d4b\u4e86\u4e13\u4e3a\u8be5\u7fa4\u4f53\u8bbe\u8ba1\u7684\u5b89\u5168\u8bc4\u6d4b\u8bd5\u9898\uff0c\u63ed\u793a\u591a\u4e2a\u4e3b\u6d41\u5927\u6a21\u578b\u5bf9\u513f\u7ae5\u4e0e\u9752\u5c11\u5e74\u7528\u6237\u6709\u4e25\u91cd\u5b89\u5168\u9690\u60a3\uff0c\u5e76\u7ed9\u51fa\u4f18\u5316\u5efa\u8bae\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u8bc4\u4f30\u5927\u591a\u5173\u6ce8\u6210\u5e74\u4eba\uff0c\u5ffd\u89c6\u4e86\u9488\u5bf9\u672a\u6210\u5e74\u7528\u6237\uff08\u5c24\u5176\u662f\u4e0d\u540c\u5e74\u9f84\u6bb5\u7684\u513f\u7ae5\u548c\u9752\u5c11\u5e74\uff09\u7684\u7279\u6b8a\u5fc3\u7406\u548c\u53d1\u5c55\u98ce\u9669\uff0c\u7d27\u8feb\u9700\u8981\u66f4\u9002\u7528\u7684\u5b89\u5168\u6846\u67b6\u3002", "method": "\u5f00\u53d1SproutBench\u8bc4\u6d4b\u5de5\u5177\uff0c\u8986\u76d6\u4e0d\u540c\u513f\u7ae5\u548c\u9752\u5c11\u5e74\u53d1\u5c55\u9636\u6bb5\u7684\u8ba4\u77e5\u3001\u60c5\u611f\u548c\u793e\u4f1a\u98ce\u9669\uff0c\u5e76\u7528\u5176\u5bf947\u79cd\u4e0d\u540cLLM\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u5b89\u5168\u8bc4\u6d4b\uff0c\u5206\u6790\u5b89\u5168\u6027\u3001\u98ce\u9669\u9632\u8303\u4e0e\u4ea4\u4e92\u6027\u7b49\u7ef4\u5ea6\u7684\u76f8\u5173\u5173\u7cfb\u3002", "result": "\u8bb8\u591a\u4e3b\u6d41LLM\u5b58\u5728\u660e\u663e\u9488\u5bf9\u672a\u6210\u5e74\u4eba\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u5b89\u5168\u4e0e\u98ce\u9669\u9632\u8303\u6027\u4e4b\u95f4\u9ad8\u5ea6\u76f8\u5173\uff0c\u4ea4\u4e92\u6027\u8d8a\u9ad8\u7684\u6a21\u578b\u5176\u9488\u5bf9\u672a\u6210\u5e74\u4eba\u7684\u9002\u9f84\u6027\u53cd\u800c\u8d8a\u4f4e\u3002\u63d0\u51fa\u4e86\u6539\u8fdbAI\u8bbe\u8ba1\u548c\u90e8\u7f72\u4ee5\u66f4\u597d\u4fdd\u62a4\u672a\u6210\u5e74\u4eba\u7684\u5177\u4f53\u5efa\u8bae\u3002", "conclusion": "\u63d0\u51fa\u4e86SproutBench\uff0c\u4e00\u4e2a\u5305\u542b1283\u6761\u53d1\u5c55\u9636\u6bb5\u76f8\u5173\u5bf9\u6297\u6027\u63d0\u793a\u7684\u65b0\u8bc4\u6d4b\u5957\u4ef6\uff0c\u5e76\u636e\u6b64\u63ed\u793a\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9762\u5411\u672a\u6210\u5e74\u4eba\u65f6\u663e\u8457\u7684\u5b89\u5168\u9690\u60a3\u3002\u6240\u53d1\u73b0\u95ee\u9898\u4e3a\u63a8\u8fdb\u513f\u7ae5\u53cb\u597d\u578bAI\u5b89\u5168\u8bbe\u8ba1\u4e0e\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u9645\u5efa\u8bae\u3002"}}
{"id": "2508.11222", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.11222", "abs": "https://arxiv.org/abs/2508.11222", "authors": ["Haonan Zhang", "Dongxia Wang", "Yi Liu", "Kexin Chen", "Jiashui Wang", "Xinlei Ying", "Long Liu", "Wenhai Wang"], "title": "ORFuzz: Fuzzing the \"Other Side\" of LLM Safety -- Testing Over-Refusal", "comment": null, "summary": "Large Language Models (LLMs) increasingly exhibit over-refusal - erroneously\nrejecting benign queries due to overly conservative safety measures - a\ncritical functional flaw that undermines their reliability and usability.\nCurrent methods for testing this behavior are demonstrably inadequate,\nsuffering from flawed benchmarks and limited test generation capabilities, as\nhighlighted by our empirical user study. To the best of our knowledge, this\npaper introduces the first evolutionary testing framework, ORFuzz, for the\nsystematic detection and analysis of LLM over-refusals. ORFuzz uniquely\nintegrates three core components: (1) safety category-aware seed selection for\ncomprehensive test coverage, (2) adaptive mutator optimization using reasoning\nLLMs to generate effective test cases, and (3) OR-Judge, a human-aligned judge\nmodel validated to accurately reflect user perception of toxicity and refusal.\nOur extensive evaluations demonstrate that ORFuzz generates diverse, validated\nover-refusal instances at a rate (6.98% average) more than double that of\nleading baselines, effectively uncovering vulnerabilities. Furthermore,\nORFuzz's outputs form the basis of ORFuzzSet, a new benchmark of 1,855 highly\ntransferable test cases that achieves a superior 63.56% average over-refusal\nrate across 10 diverse LLMs, significantly outperforming existing datasets.\nORFuzz and ORFuzzSet provide a robust automated testing framework and a\nvaluable community resource, paving the way for developing more reliable and\ntrustworthy LLM-based software systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9996\u4e2a\u53ef\u8fdb\u5316\u7684LLM\u8fc7\u5ea6\u62d2\u7edd\u68c0\u6d4b\u6846\u67b6ORFuzz\uff0c\u80fd\u591f\u7cfb\u7edf\u53d1\u73b0\u4e3b\u6d41\u8bed\u8a00\u6a21\u578b\u56e0\u5b89\u5168\u8bbe\u7f6e\u8fc7\u5ea6\u62d2\u7edd\u6b63\u5e38\u8bf7\u6c42\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u9ad8\u8d28\u91cf\u57fa\u51c6ORFuzzSet\uff0c\u6781\u5927\u63d0\u5347\u6d4b\u8bd5\u6548\u7387\u548c\u8986\u76d6\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdbLLM\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u63d0\u5347\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5b89\u5168\u63aa\u65bd\u4e0a\u8fc7\u4e8e\u4fdd\u5b88\uff0c\u5bb9\u6613\u9519\u8bef\u62d2\u7edd\u6b63\u5e38\u8bf7\u6c42\uff0c\u5f71\u54cd\u53ef\u9760\u6027\u548c\u53ef\u7528\u6027\u3002\u73b0\u6709\u6d4b\u8bd5\u65b9\u6cd5\u4e0d\u8db3\u4ee5\u6709\u6548\u68c0\u6d4b\u8fd9\u4e00\u95ee\u9898\uff0c\u5b58\u5728\u57fa\u51c6\u4e0d\u5b8c\u5584\u548c\u6d4b\u8bd5\u751f\u6210\u80fd\u529b\u6709\u9650\u7b49\u7f3a\u70b9\u3002\u4f5c\u8005\u5e0c\u671b\u63d0\u51fa\u66f4\u7cfb\u7edf\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6848\u3002", "method": "\u4f5c\u8005\u7814\u53d1\u4e86ORFuzz\u8fdb\u5316\u6d4b\u8bd5\u6846\u67b6\uff0c\u5305\u542b\u4e09\u90e8\u5206\uff1a1\uff09\u6839\u636e\u5b89\u5168\u7c7b\u522b\u9009\u62e9\u79cd\u5b50\uff0c\u5b9e\u73b0\u5168\u9762\u6d4b\u8bd5\u8986\u76d6\uff1b2\uff09\u5229\u7528\u63a8\u7406\u578bLLM\u4f18\u5316\u53d8\u5f02\u5668\uff0c\u751f\u6210\u6709\u6548\u6d4b\u8bd5\u7528\u4f8b\uff1b3\uff09\u5f00\u53d1\u4e0e\u4eba\u7c7b\u611f\u77e5\u4e00\u81f4\u7684\u5224\u522b\u6a21\u578bOR-Judge\uff0c\u5bf9\u6bd2\u6027\u548c\u62d2\u7edd\u8fdb\u884c\u51c6\u786e\u8bc4\u5224\u3002", "result": "ORFuzz\u5728\u68c0\u6d4bLLMs\u8fc7\u5ea6\u62d2\u7edd\u65b9\u9762\uff0c\u751f\u6210\u591a\u6837\u5316\u7684\u9a8c\u8bc1\u5b9e\u4f8b\uff0c\u5e73\u5747\u68c0\u6d4b\u7387\uff086.98%\uff09\u662f\u4e3b\u6d41\u57fa\u7ebf\u65b9\u6cd5\u7684\u4e24\u500d\uff0c\u80fd\u66f4\u6709\u6548\u53d1\u73b0\u6a21\u578b\u6f0f\u6d1e\u3002\u540c\u65f6\uff0c\u57fa\u4e8eORFuzz\u4ea7\u51fa\u7684ORFuzzSet\u65b0\u57fa\u51c6\u6570\u636e\u96c6\uff081855\u6761\u7528\u4f8b\uff09\uff0c\u572810\u79cdLLM\u4e0a\u5e73\u5747\u8fc7\u5ea6\u62d2\u7edd\u7387\u8fbe63.56%\uff0c\u4f18\u4e8e\u73b0\u6709\u6570\u636e\u96c6\u3002", "conclusion": "ORFuzz\u4e0eORFuzzSet\u4e3aLLM\u8fc7\u5ea6\u62d2\u7edd\u95ee\u9898\u5e26\u6765\u4e86\u7cfb\u7edf\u3001\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u68c0\u6d4b\u5de5\u5177\u548c\u516c\u5f00\u6570\u636e\u96c6\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u66f4\u53ef\u9760\u53ef\u4fe1\u7684LLM\u7cfb\u7edf\u5f00\u53d1\u3002"}}
{"id": "2508.11017", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11017", "abs": "https://arxiv.org/abs/2508.11017", "authors": ["Carter Blum", "Katja Filipova", "Ann Yuan", "Asma Ghandeharioun", "Julian Zimmert", "Fred Zhang", "Jessica Hoffmann", "Tal Linzen", "Martin Wattenberg", "Lucas Dixon", "Mor Geva"], "title": "Beyond the Rosetta Stone: Unification Forces in Generalization Dynamics", "comment": null, "summary": "Large language models (LLMs) struggle with cross-lingual knowledge transfer:\nthey hallucinate when asked in one language about facts expressed in a\ndifferent language during training. This work introduces a controlled setting\nto study the causes and dynamics of this phenomenon by training small\nTransformer models from scratch on synthetic multilingual datasets. We identify\na learning phase wherein a model develops either separate or unified\nrepresentations of the same facts across languages, and show that unification\nis essential for cross-lingual transfer. We also show that the degree of\nunification depends on mutual information between facts and training data\nlanguage, and on how easy it is to extract that language. Based on these\ninsights, we develop methods to modulate the level of cross-lingual transfer by\nmanipulating data distribution and tokenization, and we introduce metrics and\nvisualizations to formally characterize their effects on unification. Our work\nshows how controlled settings can shed light on pre-training dynamics and\nsuggests new directions for improving cross-lingual transfer in LLMs.", "AI": {"tldr": "\u672c\u6587\u5728\u53ef\u63a7\u73af\u5883\u4e0b\u7cfb\u7edf\u5206\u6790\u4e86LLMs\u8de8\u8bed\u8a00\u77e5\u8bc6\u8fc1\u79fb\u7684\u5173\u952e\u673a\u5236\uff0c\u901a\u8fc7\u5c0f\u578b\u5408\u6210\u5b9e\u9a8c\u53d1\u73b0\u4e8b\u5b9e\u8868\u5f81\u7edf\u4e00\u6027\u5f71\u54cd\u6a21\u578b\u8de8\u8bed\u8fc1\u79fb\u80fd\u529b\uff0c\u63d0\u51fa\u6570\u636e\u53ca\u5206\u8bcd\u8c03\u63a7\u65b9\u6cd5\uff0c\u5e76\u7528\u65b0\u6307\u6807\u548c\u53ef\u89c6\u5316\u8fdb\u884c\u8bc4\u4f30\uff0c\u63ed\u793a\u4e86\u672a\u6765\u63d0\u5347LLMs\u591a\u8bed\u8a00\u6027\u80fd\u7684\u65b0\u9014\u5f84\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8de8\u8bed\u8a00\u77e5\u8bc6\u8fc1\u79fb\u65b9\u9762\u5b58\u5728\u6311\u6218\uff1a\u5f53\u88ab\u7528\u4e00\u79cd\u8bed\u8a00\u63d0\u95ee\u65f6\uff0c\u4f1a\u5bf9\u8bad\u7ec3\u671f\u95f4\u4ee5\u53e6\u4e00\u79cd\u8bed\u8a00\u8868\u8fbe\u7684\u4e8b\u5b9e\u4ea7\u751f\u5e7b\u89c9\u3002\u7406\u89e3\u8be5\u73b0\u8c61\u7684\u539f\u56e0\u548c\u673a\u5236\u5bf9\u4e8e\u63d0\u5347LLM\u6027\u80fd\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u5728\u53ef\u63a7\u73af\u5883\u4e0b\uff0c\u4f5c\u8005\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3\u5c0f\u578bTransformer\u6a21\u578b\uff0c\u4f7f\u7528\u5408\u6210\u591a\u8bed\u8a00\u6570\u636e\u96c6\uff0c\u5206\u6790\u6a21\u578b\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u5bf9\u540c\u4e00\u4e8b\u5b9e\u5728\u4e0d\u540c\u8bed\u8a00\u4e0b\u5f62\u6210\u7edf\u4e00\u6216\u5206\u79bb\u8868\u793a\u7684\u9636\u6bb5\uff0c\u63a2\u8ba8\u5176\u5bf9\u8de8\u8bed\u8a00\u8fc1\u79fb\u6548\u679c\u7684\u5f71\u54cd\u3002\u540c\u65f6\uff0c\u8bbe\u8ba1\u5e76\u5e94\u7528\u4e86\u4e00\u7cfb\u5217\u6570\u636e\u5206\u5e03\u64cd\u63a7\u3001\u5206\u8bcd\u7b56\u7565\uff0c\u4ee5\u53ca\u5ea6\u91cf\u548c\u53ef\u89c6\u5316\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u5f62\u6210\u4e8b\u5b9e\u7684\u7edf\u4e00\u8868\u793a\u5bf9\u4e8e\u8de8\u8bed\u8a00\u8fc1\u79fb\u81f3\u5173\u91cd\u8981\uff0c\u7edf\u4e00\u7a0b\u5ea6\u53d7\u5230\u4e8b\u5b9e\u4e0e\u8bad\u7ec3\u6570\u636e\u8bed\u8a00\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u53ca\u8bed\u8a00\u53ef\u63d0\u53d6\u96be\u6613\u5ea6\u5f71\u54cd\u3002\u4f5c\u8005\u63d0\u51fa\u53ef\u901a\u8fc7\u8c03\u6574\u6570\u636e\u5206\u5e03\u548c\u5206\u8bcd\u65b9\u5f0f\u6765\u63a7\u5236\u8de8\u8bed\u8a00\u8fc1\u79fb\u7a0b\u5ea6\uff0c\u5e76\u7528\u65b0\u6307\u6807\u548c\u53ef\u89c6\u5316\u65b9\u6cd5\u5c55\u73b0\u8c03\u63a7\u7ed3\u679c\u3002", "conclusion": "\u901a\u8fc7\u53ef\u63a7\u8bbe\u7f6e\u7814\u7a76\uff0c\u591a\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u8fc1\u79fb\u673a\u5236\u5f97\u4ee5\u660e\u786e\uff1b\u76f8\u5173\u53d1\u73b0\u4e3a\u6539\u8fdbLLM\u8de8\u8bed\u8a00\u80fd\u529b\u63d0\u4f9b\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.11257", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11257", "abs": "https://arxiv.org/abs/2508.11257", "authors": ["Marc Pavel", "Nenad Petrovic", "Lukasz Mazur", "Vahid Zolfaghari", "Fengjunjie Pan", "Alois Knoll"], "title": "Hallucination in LLM-Based Code Generation: An Automotive Case Study", "comment": null, "summary": "Large Language Models (LLMs) have shown significant potential in automating\ncode generation tasks offering new opportunities across software engineering\ndomains. However, their practical application remains limited due to\nhallucinations - outputs that appear plausible but are factually incorrect,\nunverifiable or nonsensical. This paper investigates hallucination phenomena in\nthe context of code generation with a specific focus on the automotive domain.\nA case study is presented that evaluates multiple code LLMs for three different\nprompting complexities ranging from a minimal one-liner prompt to a prompt with\nCovesa Vehicle Signal Specifications (VSS) as additional context and finally to\na prompt with an additional code skeleton. The evaluation reveals a high\nfrequency of syntax violations, invalid reference errors and API knowledge\nconflicts in state-of-the-art models GPT-4.1, Codex and GPT-4o. Among the\nevaluated models, only GPT-4.1 and GPT-4o were able to produce a correct\nsolution when given the most context-rich prompt. Simpler prompting strategies\nfailed to yield a working result, even after multiple refinement iterations.\nThese findings highlight the need for effective mitigation techniques to ensure\nthe safe and reliable use of LLM generated code, especially in safety-critical\ndomains such as automotive software systems.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u4e86\u4e3b\u6d41\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6c7d\u8f66\u9886\u57df\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5e7b\u89c9\u73b0\u8c61\uff0c\u53d1\u73b0\u53ea\u6709\u5728\u63d0\u4f9b\u6781\u4e3a\u8be6\u7ec6\u4e0a\u4e0b\u6587\u65f6\uff0c\u90e8\u5206\u6a21\u578b\u624d\u80fd\u6210\u529f\u751f\u6210\u53ef\u7528\u4ee3\u7801\uff0c\u63d0\u793a\u5728\u5173\u952e\u884c\u4e1a\u5e94\u7528\u4e2d\u4e9f\u9700\u89e3\u51b3\u5e7b\u89c9\u548c\u53ef\u9760\u6027\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8f83\u5927\u6f5c\u529b\uff0c\u4f46\u56e0\u5176\u5e7b\u89c9\u95ee\u9898\uff08\u5982\u751f\u6210\u770b\u4f3c\u5408\u7406\u4f46\u5b9e\u9645\u9519\u8bef\u6216\u65e0\u6cd5\u9a8c\u8bc1\u7684\u4ee3\u7801\uff09\u800c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\uff0c\u5c24\u5176\u662f\u5728\u5982\u6c7d\u8f66\u7b49\u9ad8\u5b89\u5168\u9886\u57df\uff0c\u63a2\u7d22\u8fd9\u4e9b\u5e7b\u89c9\u73b0\u8c61\u7684\u5177\u4f53\u8868\u73b0\u548c\u6210\u56e0\u81f3\u5173\u91cd\u8981\u3002", "method": "\u9488\u5bf9\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u8bba\u6587\u4ee5\u6c7d\u8f66\u884c\u4e1a\u4e3a\u4f8b\uff0c\u8bbe\u8ba1\u6848\u4f8b\u7814\u7a76\uff0c\u8bc4\u4f30\u4e86\u591a\u79cd\u4ee3\u7801LLM\uff08\u5305\u62ecGPT-4.1\u3001Codex\u548cGPT-4o\uff09\u5728\u4e09\u79cd\u4e0d\u540c\u63d0\u793a\u590d\u6742\u5ea6\u4e0b\uff08\u6700\u7b80\u5355\u7684\u4e00\u884c\u63d0\u793a\u3001\u542bVSS\u4e0a\u4e0b\u6587\u7684\u63d0\u793a\u3001\u518d\u52a0\u4ee3\u7801\u6846\u67b6\u7684\u590d\u6742\u63d0\u793a\uff09\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0c\u5728\u6700\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u63d0\u793a\u4e0b\uff0c\u4ec5GPT-4.1\u548cGPT-4o\u80fd\u7ed9\u51fa\u6b63\u786e\u89e3\u51b3\u65b9\u6848\uff0c\u5176\u4f59\u65b9\u5f0f\u548c\u6a21\u578b\u5747\u672a\u80fd\u4ea7\u51fa\u53ef\u7528\u7ed3\u679c\u3002\u6240\u6709\u6a21\u578b\u666e\u904d\u51fa\u73b0\u8bed\u6cd5\u9519\u8bef\u3001\u5f15\u7528\u65e0\u6548\u548cAPI\u77e5\u8bc6\u51b2\u7a81\u7b49\u95ee\u9898\u3002", "conclusion": "\u5f53\u524d\u4e3b\u6d41\u4ee3\u7801LLM\u5728\u6ca1\u6709\u8db3\u591f\u4e0a\u4e0b\u6587\u652f\u6301\u4e0b\uff0c\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u751f\u6210\u5927\u91cf\u4e0d\u53ef\u9760\u4ee3\u7801\uff0c\u7279\u522b\u662f\u5728\u9ad8\u5b89\u5168\u8981\u6c42\u7684\u6c7d\u8f66\u8f6f\u4ef6\u5f00\u53d1\u9886\u57df\uff0c\u5fc5\u987b\u7814\u7a76\u66f4\u6709\u6548\u7684\u9632\u63a7\u65b9\u6cd5\u6765\u786e\u4fdd\u4ee3\u7801\u5b89\u5168\u53ef\u9760\u3002"}}
{"id": "2508.11027", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11027", "abs": "https://arxiv.org/abs/2508.11027", "authors": ["Andrew Wang", "Sophia Hager", "Adi Asija", "Daniel Khashabi", "Nicholas Andrews"], "title": "Hell or High Water: Evaluating Agentic Recovery from External Failures", "comment": "Accepted to COLM 2025", "summary": "As language model agents are applied to real world problems of increasing\ncomplexity, they will be expected to formulate plans across large search\nspaces. If those plans fail for reasons beyond their control, how well do\nlanguage agents search for alternative ways to achieve their goals? We devise a\nspecialized agentic planning benchmark to study this question. Each planning\nproblem is solved via combinations of function calls. The agent searches for\nrelevant functions from a set of over four thousand possibilities, and observes\nenvironmental feedback in the form of function outputs or error messages. Our\nbenchmark confronts the agent with external failures in its workflow, such as\nfunctions that suddenly become unavailable. At the same time, even with the\nintroduction of these failures, we guarantee that the task remains solvable.\nIdeally, an agent's performance on the planning task should not be affected by\nthe presence of external failures. Overall, we find that language agents\nstruggle to formulate and execute backup plans in response to environment\nfeedback. While state-of-the-art models are often able to identify the correct\nfunction to use in the right context, they struggle to adapt to feedback from\nthe environment and often fail to pursue alternate courses of action, even when\nthe search space is artificially restricted. We provide a systematic analysis\nof the failures of both open-source and commercial models, examining the\neffects of search space size, as well as the benefits of scaling model size in\nour setting. Our analysis identifies key challenges for current generative\nmodels as well as promising directions for future work.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e00\u4e2a\u4e13\u95e8\u57fa\u51c6\u6d4b\u8bd5\u8bed\u8a00\u6a21\u578b\u5728\u906d\u9047\u73af\u5883\u632b\u6298\u65f6\u7684\u89c4\u5212\u4e0e\u9002\u5e94\u80fd\u529b\u3002\u7ed3\u679c\u53d1\u73b0\uff0c\u65e0\u8bba\u5f00\u6e90\u8fd8\u662f\u5546\u4e1a\u6a21\u578b\uff0c\u5728\u73af\u5883\u53d8\u5316\u4e0b\u6267\u884c\u540e\u5907\u65b9\u6848\u7684\u80fd\u529b\u666e\u904d\u4e0d\u8db3\u3002\u8be5\u5de5\u4f5c\u63ed\u793a\u4e86\u751f\u6210\u5f0f\u6a21\u578b\u5728\u73b0\u5b9e\u4e16\u754c\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u91cd\u8981\u6311\u6218\u548c\u672a\u6765\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u8d8a\u6765\u8d8a\u590d\u6742\u7684\u73b0\u5b9e\u4e16\u754c\u95ee\u9898\uff0c\u4eba\u4eec\u671f\u671b\u8bed\u8a00\u6a21\u578b\u5728\u5927\u89c4\u6a21\u641c\u7d22\u7a7a\u95f4\u5185\u8fdb\u884c\u89c4\u5212\u3002\u4f46\u5982\u679c\u8fd9\u4e9b\u89c4\u5212\u7531\u4e8e\u5916\u90e8\u4e0d\u53ef\u63a7\u56e0\u7d20\u800c\u5931\u8d25\uff0c\u6a21\u578b\u80fd\u5426\u6709\u6548\u5bfb\u627e\u66ff\u4ee3\u65b9\u6848\u5c1a\u4e0d\u660e\u6717\u3002\u4e3a\u6b64\u4f5c\u8005\u63d0\u51fa\u4e13\u95e8\u7684\u57fa\u51c6\u6765\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u9002\u5e94\u73af\u5883\u53cd\u9988\u4e0e\u5916\u90e8\u632b\u6298\u7684\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4ee3\u7406\u7684\u89c4\u5212\u57fa\u51c6\u6d4b\u8bd5\u3002\u6bcf\u4e2a\u89c4\u5212\u95ee\u9898\u901a\u8fc7\u7ec4\u5408\u51fd\u6570\u8c03\u7528\u89e3\u51b3\uff0c\u4ee3\u7406\u4ece4000\u591a\u4e2a\u51fd\u6570\u4e2d\u641c\u7d22\u5408\u9002\u7684\u51fd\u6570\uff0c\u5e76\u4f9d\u636e\u51fd\u6570\u8f93\u51fa\u6216\u9519\u8bef\u4fe1\u606f\u83b7\u5f97\u73af\u5883\u53cd\u9988\u3002\u57fa\u51c6\u6d4b\u8bd5\u6709\u610f\u5f15\u5165\u5916\u90e8\u5931\u8d25\uff08\u5982\u51fd\u6570\u7a81\u7136\u4e0d\u53ef\u7528\uff09\uff0c\u4f46\u4fdd\u8bc1\u4efb\u52a1\u59cb\u7ec8\u53ef\u89e3\uff0c\u4ee5\u8bc4\u4f30\u4ee3\u7406\u5728\u53d7\u632b\u65f6\u8c03\u6574\u89c4\u5212\u80fd\u529b\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u5728\u9762\u5bf9\u73af\u5883\u53cd\u9988\u3001\u6267\u884c\u66ff\u4ee3\u65b9\u6848\u548c\u505a\u540e\u5907\u89c4\u5212\u65f6\u8868\u73b0\u4e0d\u4f73\u3002\u5c3d\u7ba1\u6700\u65b0\u6a21\u578b\u901a\u5e38\u80fd\u8bc6\u522b\u51fa\u6b63\u786e\u7684\u51fd\u6570\uff0c\u4f46\u5b83\u4eec\u5f88\u96be\u5bf9\u73af\u5883\u7684\u53d8\u5316\u505a\u51fa\u7075\u6d3b\u8c03\u6574\uff0c\u5373\u4fbf\u641c\u7d22\u7a7a\u95f4\u88ab\u9650\u5236\u4e5f\u5982\u6b64\u3002\u540c\u65f6\uff0c\u4f5c\u8005\u4e5f\u7cfb\u7edf\u5206\u6790\u4e86\u5f00\u6e90\u548c\u5546\u7528\u6a21\u578b\u5728\u641c\u7d22\u7a7a\u95f4\u5927\u5c0f\u3001\u6a21\u578b\u89c4\u6a21\u6269\u5c55\u7b49\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u5728\u591a\u53d8\u73af\u5883\u4e2d\u8fdb\u884c\u5907\u9009\u65b9\u6848\u89c4\u5212\u65b9\u9762\u5b58\u5728\u660e\u663e\u77ed\u677f\u3002\u5f53\u524d\u751f\u6210\u5f0f\u6a21\u578b\u8981\u63d0\u5347\u5728\u5b9e\u9645\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u9002\u5e94\u548c\u89c4\u5212\u80fd\u529b\u662f\u4e9f\u5f85\u7a81\u7834\u7684\u91cd\u8981\u65b9\u5411\u3002\u4f5c\u8005\u4e5f\u636e\u6b64\u63d0\u51fa\u4e86\u672a\u6765\u6539\u8fdb\u548c\u7814\u7a76\u7684\u82e5\u5e72\u65b9\u5411\u3002"}}
{"id": "2508.11305", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.11305", "abs": "https://arxiv.org/abs/2508.11305", "authors": ["Xin Wang", "Zhenhao Li", "Zishuo Ding"], "title": "Defects4Log: Benchmarking LLMs for Logging Code Defect Detection and Reasoning", "comment": null, "summary": "Logging code is written by developers to capture system runtime behavior and\nplays a vital role in debugging, performance analysis, and system monitoring.\nHowever, defects in logging code can undermine the usefulness of logs and lead\nto misinterpretations. Although prior work has identified several logging\ndefect patterns and provided valuable insights into logging practices, these\nstudies often focus on a narrow range of defect patterns derived from limited\nsources (e.g., commit histories) and lack a systematic and comprehensive\nanalysis. Moreover, large language models (LLMs) have demonstrated promising\ngeneralization and reasoning capabilities across a variety of code-related\ntasks, yet their potential for detecting logging code defects remains largely\nunexplored.\n  In this paper, we derive a comprehensive taxonomy of logging code defects,\nwhich encompasses seven logging code defect patterns with 14 detailed\nscenarios. We further construct a benchmark dataset, \\dataset, consisting of\n164 developer-verified real-world logging defects. Then we propose an automated\nframework that leverages various prompting strategies and contextual\ninformation to evaluate LLMs' capability in detecting and reasoning logging\ncode defects. Experimental results reveal that LLMs generally struggle to\naccurately detect and reason logging code defects based on the source code\nonly. However, incorporating proper knowledge (e.g., detailed scenarios of\ndefect patterns) can lead to 10.9\\% improvement in detection accuracy. Overall,\nour findings provide actionable guidance for practitioners to avoid common\ndefect patterns and establish a foundation for improving LLM-based reasoning in\nlogging code defect detection.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6574\u7406\u4e86\u65e5\u5fd7\u4ee3\u7801\u7f3a\u9677\u6a21\u5f0f\uff0c\u6784\u5efa\u4e86\u771f\u5b9e\u7f3a\u9677\u6570\u636e\u96c6\uff0c\u5e76\u53d1\u73b0\u5408\u7406\u5229\u7528\u77e5\u8bc6\u80fd\u6709\u6548\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u68c0\u6d4b\u65e5\u5fd7\u7f3a\u9677\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u65e5\u5fd7\u4ee3\u7801\u5bf9\u7cfb\u7edf\u8c03\u8bd5\u3001\u6027\u80fd\u5206\u6790\u548c\u76d1\u63a7\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u65e5\u5fd7\u4ee3\u7801\u7f3a\u9677\u4f1a\u5f71\u54cd\u65e5\u5fd7\u7684\u6709\u6548\u6027\u3002\u5df2\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4e8e\u6709\u9650\u6765\u6e90\u548c\u8f83\u5c11\u79cd\u7c7b\u7684\u7f3a\u9677\u6a21\u5f0f\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u548c\u5168\u9762\u6027\u5206\u6790\u3002\u540c\u65f6\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u5728\u65e5\u5fd7\u4ee3\u7801\u7f3a\u9677\u68c0\u6d4b\u4e2d\u7684\u80fd\u529b\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u5957\u8be6\u5c3d\u7684\u65e5\u5fd7\u4ee3\u7801\u7f3a\u9677\u5206\u7c7b\u6cd5\uff0c\u6db5\u76d67\u5927\u7f3a\u9677\u6a21\u5f0f\u548c14\u4e2a\u5177\u4f53\u60c5\u666f\u3002\u540c\u65f6\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b164\u4e2a\u771f\u5b9e\u4e14\u7531\u5f00\u53d1\u8005\u9a8c\u8bc1\u7684\u65e5\u5fd7\u7f3a\u9677\u6570\u636e\u96c6\u3002\u57fa\u4e8e\u591a\u79cd\u63d0\u8bcd\u7b56\u7565\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u63d0\u51fa\u81ea\u52a8\u5316\u6846\u67b6\u8bc4\u4f30LLMs\u5728\u65e5\u5fd7\u4ee3\u7801\u7f3a\u9677\u68c0\u6d4b\u548c\u63a8\u7406\u4e2d\u7684\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cLLMs\u5355\u9760\u6e90\u7801\u4fe1\u606f\u8f83\u96be\u51c6\u786e\u68c0\u6d4b\u548c\u63a8\u7406\u65e5\u5fd7\u4ee3\u7801\u7f3a\u9677\uff0c\u4f46\u878d\u5165\u66f4\u4e30\u5bcc\u7684\u77e5\u8bc6\uff08\u5982\u7f3a\u9677\u6a21\u5f0f\u5177\u4f53\u60c5\u666f\uff09\u540e\uff0c\u53ef\u63d0\u534710.9%\u7684\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "conclusion": "\u672c\u6587\u4e3a\u65e5\u5fd7\u4ee3\u7801\u7f3a\u9677\u68c0\u6d4b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u57fa\u51c6\uff0c\u4e3a\u5b9e\u9645\u5f00\u53d1\u8005\u907f\u514d\u5e38\u89c1\u65e5\u5fd7\u7f3a\u9677\u63d0\u4f9b\u4e86\u5177\u4f53\u6307\u5bfc\uff0c\u4e5f\u4e3a\u63d0\u5347\u57fa\u4e8eLLM\u7684\u7f3a\u9677\u68c0\u6d4b\u5efa\u7acb\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.11061", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11061", "abs": "https://arxiv.org/abs/2508.11061", "authors": ["Martin Pavl\u00ed\u010dek", "Tom\u00e1\u0161 Filip", "Petr Sos\u00edk"], "title": "BIPOLAR: Polarization-based granular framework for LLM bias evaluation", "comment": null, "summary": "Large language models (LLMs) are known to exhibit biases in downstream tasks,\nespecially when dealing with sensitive topics such as political discourse,\ngender identity, ethnic relations, or national stereotypes. Although\nsignificant progress has been made in bias detection and mitigation techniques,\ncertain challenges remain underexplored. This study proposes a reusable,\ngranular, and topic-agnostic framework to evaluate polarisation-related biases\nin LLM (both open-source and closed-source). Our approach combines\npolarisation-sensitive sentiment metrics with a synthetically generated\nbalanced dataset of conflict-related statements, using a predefined set of\nsemantic categories.\n  As a case study, we created a synthetic dataset that focusses on the\nRussia-Ukraine war, and we evaluated the bias in several LLMs: Llama-3,\nMistral, GPT-4, Claude 3.5, and Gemini 1.0. Beyond aggregate bias scores, with\na general trend for more positive sentiment toward Ukraine, the framework\nallowed fine-grained analysis with considerable variation between semantic\ncategories, uncovering divergent behavioural patterns among models. Adaptation\nto prompt modifications showed further bias towards preconceived language and\ncitizenship modification.\n  Overall, the framework supports automated dataset generation and fine-grained\nbias assessment, is applicable to a variety of polarisation-driven scenarios\nand topics, and is orthogonal to many other bias-evaluation strategies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u81ea\u52a8\u751f\u6210\u6570\u636e\u96c6\u3001\u7ec6\u7c92\u5ea6\u5206\u6790\u6781\u5316\u76f8\u5173\u504f\u89c1\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u7ec6\u81f4\u53cd\u6620\u6a21\u578b\u5728\u654f\u611f\u8bdd\u9898\u4e0a\u7684\u4e0d\u540c\u8868\u73b0\uff0c\u5bf9\u4fc4\u4e4c\u51b2\u7a81\u6848\u4f8b\u663e\u793a\u591a\u6570\u6a21\u578b\u504f\u5411\u4e4c\u514b\u5170\u3002\u8be5\u65b9\u6cd5\u901a\u7528\u3001\u53ef\u590d\u7528\uff0c\u5e76\u80fd\u8865\u5145\u73b0\u6709\u504f\u89c1\u8bc4\u4f30\u6280\u672f\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5904\u7406\u654f\u611f\u8bdd\u9898\u5982\u653f\u6cbb\u3001\u6027\u522b\u3001\u6c11\u65cf\u6216\u56fd\u5bb6\u523b\u677f\u5370\u8c61\u65f6\uff0c\u5e38\u5e38\u8868\u73b0\u51fa\u504f\u89c1\u3002\u5c3d\u7ba1\u5728\u504f\u89c1\u68c0\u6d4b\u4e0e\u7f13\u89e3\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4ecd\u6709\u90e8\u5206\u6311\u6218\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u66f4\u901a\u7528\u3001\u53ef\u590d\u7528\u7684\u7ec6\u7c92\u5ea6\u504f\u89c1\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u590d\u7528\u3001\u7ec6\u7c92\u5ea6\u4e14\u4e3b\u9898\u65e0\u5173\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u6781\u5316\u654f\u611f\u60c5\u611f\u6307\u6807\u548c\u5408\u6210\u751f\u6210\u7684\u51b2\u7a81\u76f8\u5173\u5e73\u8861\u6570\u636e\u96c6\uff08\u8bbe\u5b9a\u8bed\u4e49\u7c7b\u522b\uff09\uff0c\u4ee5\u8bc4\u4f30 LLMs \u7684\u6781\u5316\u504f\u89c1\u3002\u4ee5\u4fc4\u4e4c\u6218\u4e89\u4e3a\u6848\u4f8b\uff0c\u6784\u5efa\u5408\u6210\u6570\u636e\u96c6\u5e76\u6d4b\u8bd5\u591a\u79cd\u5f00\u6e90\u548c\u95ed\u6e90\u5927\u6a21\u578b\uff08\u5982 Llama-3, Mistral, GPT-4, Claude 3.5, Gemini 1.0\uff09\u3002", "result": "\u6574\u4f53\u504f\u89c1\u5206\u6570\u663e\u793a\u6a21\u578b\u666e\u904d\u5bf9\u4e4c\u514b\u5170\u6709\u66f4\u79ef\u6781\u7684\u60c5\u611f\u503e\u5411\uff0c\u540c\u65f6\u6846\u67b6\u53ef\u4ee5\u7ec6\u81f4\u5206\u6790\u8bed\u4e49\u7c7b\u522b\u95f4\u7684\u5de8\u5927\u5dee\u5f02\uff0c\u63ed\u793a\u4e0d\u540c\u6a21\u578b\u5728\u7ec6\u8282\u4e0a\u7684\u884c\u4e3a\u5dee\u5f02\u3002\u5bf9\u63d0\u793a\u8bcd\u4fee\u6539\u5177\u6709\u9002\u5e94\u6027\uff0c\u8fdb\u4e00\u6b65\u663e\u73b0\u504f\u5411\u9884\u8bbe\u8bed\u8a00\u6216\u516c\u6c11\u8eab\u4efd\u4fee\u6539\u7684\u73b0\u8c61\u3002", "conclusion": "\u8be5\u6846\u67b6\u652f\u6301\u81ea\u52a8\u5316\u6570\u636e\u96c6\u751f\u6210\u548c\u7ec6\u7c92\u5ea6\u504f\u89c1\u8bc4\u4f30\uff0c\u80fd\u591f\u5e94\u7528\u4e8e\u591a\u79cd\u6781\u5316\u573a\u666f\u548c\u4e3b\u9898\uff0c\u5e76\u4e0e\u5176\u4ed6\u504f\u89c1\u8bc4\u4f30\u65b9\u6cd5\u4e92\u8865\u3002"}}
{"id": "2508.11468", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.11468", "abs": "https://arxiv.org/abs/2508.11468", "authors": ["Zhihao Gong", "Zeyu Sun", "Dong Huang", "Qingyuan Liang", "Jie M. Zhang", "Dan Hao"], "title": "TRACY: Benchmarking Execution Efficiency of LLM-Based Code Translation", "comment": null, "summary": "Automatic code translation is a fundamental task in modern software\ndevelopment. While the advent of Large Language Models (LLMs) has significantly\nimproved the correctness of code translation, the critical dimension of\nexecution efficiency remains overlooked. To address this gap, we introduce\nTRACY, the first comprehensive benchmark designed to evaluate the execution\nefficiency of LLM-translated code. TRACY is constructed through an LLM-driven\ntwo-stage pipeline: an initial stage generates a suite of stress tests to\namplify performance differences, followed by an efficiency-oriented task\npruning stage that isolates the efficiency-distinguishing tasks. The resulting\nbenchmark comprises 1,011 code translation tasks across C++, Java, and Python,\neach accompanied by an average of 22.1 verified reference translations and 10\ncomputationally demanding tests. Our extensive evaluation of 26 representative\nLLMs reveals that even top-tier LLMs struggle to consistently produce efficient\ncode translations. For instance, Claude-4-think, the leading model for\ncorrectness, ranks eighth overall when time efficiency is taken into account,\nsurpassed by several smaller open-source models. We further pinpoint that\nalgorithmic flaws and improper resource handling are the most detrimental,\ncausing a median time slowdown of 5.6$\\times$ and memory increase of\n12.0$\\times$, respectively. Our work underscores the necessity of jointly\noptimizing for correctness and efficiency in future LLM-based code translation.", "AI": {"tldr": "LLM\u81ea\u52a8\u4ee3\u7801\u7ffb\u8bd1\u867d\u63d0\u9ad8\u4e86\u6b63\u786e\u6027\uff0c\u4f46\u8fd0\u884c\u6548\u7387\u5e38\u88ab\u5ffd\u89c6\u3002\u4f5c\u8005\u901a\u8fc7TRACY\u57fa\u51c6\u7cfb\u7edf\u6027\u8bc4\u6d4b\u4e3b\u6d41\u6a21\u578b\uff0c\u53d1\u73b0\u5373\u4f7f\u4ee3\u7801\u6b63\u786e\u6700\u597d\u7684\u6a21\u578b\u5728\u6548\u7387\u4e0a\u4e5f\u6709\u660e\u663e\u77ed\u677f\uff0c\u547c\u5401\u672a\u6765\u5173\u6ce8\u6b63\u786e\u6027\u548c\u6548\u7387\u7684\u53cc\u91cd\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u7684\u81ea\u52a8\u4ee3\u7801\u7ffb\u8bd1\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4ee3\u7801\u6b63\u786e\u6027\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u6b65\uff0c\u4f46\u5bf9\u4ee3\u7801\u8fd0\u884c\u6548\u7387\u7684\u5173\u6ce8\u4e0d\u8db3\u3002\u56e0\u6b64\uff0c\u4e3a\u8865\u8db3\u8fd9\u4e00\u77ed\u677f\uff0c\u4f5c\u8005\u63d0\u51fa\u5bf9\u7ffb\u8bd1\u540e\u4ee3\u7801\u7684\u6267\u884c\u6548\u7387\u8fdb\u884c\u7cfb\u7edf\u3001\u6807\u51c6\u5316\u8bc4\u6d4b\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86TRACY\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u7ffb\u8bd1\u4ee3\u7801\u6267\u884c\u6548\u7387\u7684\u7efc\u5408\u57fa\u51c6\u3002TRACY \u91c7\u7528\u4e24\u9636\u6bb5LLM\u9a71\u52a8\u6d41\u7a0b\uff1a\u9996\u5148\u751f\u6210\u538b\u529b\u6d4b\u8bd5\u4ee5\u653e\u5927\u4e0d\u540c\u6a21\u578b\u95f4\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u7136\u540e\u8fdb\u884c\u4efb\u52a1\u7b5b\u9009\u4ee5\u63d0\u53d6\u6700\u80fd\u533a\u5206\u6548\u7387\u7684\u4efb\u52a1\u3002\u6700\u7ec8\u6570\u636e\u96c6\u6db5\u76d6C++\u3001Java\u3001Python\u4e09\u79cd\u8bed\u8a00\uff0c\u51711,011\u4e2a\u7ffb\u8bd1\u4efb\u52a1\uff0c\u6bcf\u4e2a\u4efb\u52a1\u5747\u542b\u591a\u4e2a\u9ad8\u5f3a\u5ea6\u6d4b\u8bd5\u548c\u5927\u91cf\u4eba\u5de5\u9a8c\u8bc1\u7684\u53c2\u8003\u7b54\u6848\u3002", "result": "\u901a\u8fc7\u5bf926\u79cd\u4e3b\u6d41LLM\u7684\u6d4b\u8bd5\u53d1\u73b0\uff0c\u5373\u4fbf\u662f\u6b63\u786e\u6027\u6700\u597d\u7684\u6a21\u578b\uff08\u5982Claude-4-think\uff09\uff0c\u5728\u8003\u8651\u8fd0\u884c\u6548\u7387\u540e\u6574\u4f53\u8868\u73b0\u4e5f\u4ec5\u5217\u7b2c\u516b\uff0c\u88ab\u591a\u6b3e\u8f83\u5c0f\u7684\u5f00\u6e90\u6a21\u578b\u8d85\u8d8a\u3002\u7b97\u6cd5\u7f3a\u9677\u4e0e\u8d44\u6e90\u5904\u7406\u4e0d\u5f53\u4f1a\u5bfc\u81f4\u4e2d\u4f4d\u65f6\u95f4\u61625.6\u500d\u3001\u5185\u5b58\u5360\u7528\u9ad812\u500d\u3002", "conclusion": "\u672a\u6765LLM\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1\u5fc5\u987b\u517c\u987e\u6b63\u786e\u6027\u548c\u6548\u7387\u53cc\u91cd\u6307\u6807\uff0c\u5355\u4e00\u4f18\u5316\u6b63\u786e\u6027\u4e0d\u8db3\u4ee5\u6ee1\u8db3\u5b9e\u9645\u9700\u6c42\u3002"}}
{"id": "2508.11068", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11068", "abs": "https://arxiv.org/abs/2508.11068", "authors": ["Nicolas Goulet", "Alexandre Blondin Mass\u00e9", "Moussa Abdendi"], "title": "Approaching the Source of Symbol Grounding with Confluent Reductions of Abstract Meaning Representation Directed Graphs", "comment": null, "summary": "Abstract meaning representation (AMR) is a semantic formalism used to\nrepresent the meaning of sentences as directed acyclic graphs. In this paper,\nwe describe how real digital dictionaries can be embedded into AMR directed\ngraphs (digraphs), using state-of-the-art pre-trained large language models.\nThen, we reduce those graphs in a confluent manner, i.e. with transformations\nthat preserve their circuit space. Finally, the properties of these reduces\ndigraphs are analyzed and discussed in relation to the symbol grounding\nproblem.", "AI": {"tldr": "\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u6570\u5b57\u8bcd\u5178\u5d4c\u5165AMR\u8bed\u4e49\u56fe\uff0c\u5e76\u5408\u6d41\u5f0f\u7b80\u5316\uff0c\u5206\u6790\u5f97\u51fa\u5bf9\u7b26\u53f7\u951a\u5b9a\u95ee\u9898\u7684\u65b0\u89c1\u89e3\u3002", "motivation": "AMR\u4f5c\u4e3a\u4e00\u79cd\u8bed\u4e49\u8868\u793a\u65b9\u6cd5\uff0c\u4f46\u5982\u4f55\u5c06\u5b9e\u9645\u7684\u6570\u5b57\u8bcd\u5178\u5d4c\u5165AMR\u56fe\u5e76\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5904\u7406\uff0c\u8fdb\u800c\u63a2\u8ba8\u4e0e\u7b26\u53f7\u951a\u5b9a\u95ee\u9898\u7684\u5173\u7cfb\uff0c\u8fd8\u672a\u6709\u7cfb\u7edf\u7684\u7814\u7a76\u3002", "method": "\u5229\u7528\u6700\u65b0\u9884\u8bad\u7ec3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u771f\u5b9e\u6570\u5b57\u8bcd\u5178\u4fe1\u606f\u5d4c\u5165\u5230AMR\u6709\u5411\u65e0\u73af\u56fe\u4e2d\uff0c\u7136\u540e\u901a\u8fc7\u4fdd\u6301\u7535\u8def\u7a7a\u95f4\u4e0d\u53d8\u7684\u65b9\u5f0f\u5bf9\u56fe\u8fdb\u884c\u5408\u6d41\u7b80\u5316\u3002", "result": "\u6210\u529f\u5c06\u6570\u5b57\u8bcd\u5178\u5d4c\u5165AMR digraph\u4e2d\uff0c\u5e76\u5bf9\u7b80\u5316\u540e\u7684\u56fe\u7684\u6027\u8d28\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u63a2\u8ba8\u4e86\u5176\u4e0e\u7b26\u53f7\u951a\u5b9a\u95ee\u9898\u7684\u5173\u8054\u3002", "conclusion": "\u672c\u6587\u5c55\u793a\u4e86\u6570\u5b57\u8bcd\u5178\u4fe1\u606f\u4e0eAMR\u56fe\u6709\u6548\u878d\u5408\u7684\u65b0\u8def\u5f84\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5316\u53ca\u5206\u6790\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u66f4\u6df1\u5165\u7406\u89e3\u7b26\u53f7\u951a\u5b9a\u95ee\u9898\u3002"}}
{"id": "2508.11120", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11120", "abs": "https://arxiv.org/abs/2508.11120", "authors": ["Lorenzo Jaime Yu Flores", "Junyi Shen", "Xiaoyuan Gu"], "title": "Towards Reliable Multi-Agent Systems for Marketing Applications via Reflection, Memory, and Planning", "comment": null, "summary": "Recent advances in large language models (LLMs) enabled the development of AI\nagents that can plan and interact with tools to complete complex tasks.\nHowever, literature on their reliability in real-world applications remains\nlimited. In this paper, we introduce a multi-agent framework for a marketing\ntask: audience curation. To solve this, we introduce a framework called RAMP\nthat iteratively plans, calls tools, verifies the output, and generates\nsuggestions to improve the quality of the audience generated. Additionally, we\nequip the model with a long-term memory store, which is a knowledge base of\nclient-specific facts and past queries. Overall, we demonstrate the use of LLM\nplanning and memory, which increases accuracy by 28 percentage points on a set\nof 88 evaluation queries. Moreover, we show the impact of iterative\nverification and reflection on more ambiguous queries, showing progressively\nbetter recall (roughly +20 percentage points) with more verify/reflect\niterations on a smaller challenge set, and higher user satisfaction. Our\nresults provide practical insights for deploying reliable LLM-based systems in\ndynamic, industry-facing environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faRAMP\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8eLLM\u7684\u8425\u9500\u53d7\u4f17\u7b56\u5212\u4efb\u52a1\uff0c\u901a\u8fc7\u5de5\u5177\u8c03\u7528\u3001\u7ed3\u679c\u9a8c\u8bc1\u4ee5\u53ca\u957f\u671f\u8bb0\u5fc6\uff0c\u51c6\u786e\u7387\u548c\u53ec\u56de\u7387\u63d0\u5347\u663e\u8457\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u53ef\u9760\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u5df2\u80fd\u901a\u8fc7\u5de5\u5177\u89c4\u5212\u4e0e\u4ea4\u4e92\u6267\u884c\u590d\u6742\u4efb\u52a1\uff0c\u4f46\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u5c1a\u7f3a\u5c11\u7cfb\u7edf\u6027\u7814\u7a76\u3002\u8be5\u8bba\u6587\u9488\u5bf9\u8fd9\u4e00\u4e0d\u8db3\uff0c\u5728\u8425\u9500\u9886\u57df\u4efb\u52a1\u2014\u2014\u53d7\u4f17\u7b56\u5212\u4e0a\u8fdb\u884c\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aRAMP\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u8fed\u4ee3\u89c4\u5212\u3001\u8c03\u7528\u5de5\u5177\u3001\u7ed3\u679c\u9a8c\u8bc1\u4e0e\u6539\u8fdb\u5efa\u8bae\u6765\u63d0\u5347\u4efb\u52a1\u5b8c\u6210\u8d28\u91cf\u3002\u540c\u65f6\uff0c\u4e3a\u6a21\u578b\u914d\u5907\u4e86\u957f\u671f\u8bb0\u5fc6\u5b58\u50a8\uff0c\u5373\u5ba2\u6237\u7279\u5b9a\u4e8b\u5b9e\u548c\u5386\u53f2\u67e5\u8be2\u7684\u77e5\u8bc6\u5e93\u3002", "result": "\u572888\u4e2a\u8bc4\u4f30\u67e5\u8be2\u4e0a\u7684\u51c6\u786e\u7387\u63d0\u5347\u4e8628\u4e2a\u767e\u5206\u70b9\u3002\u5728\u8f83\u96be\u7684\u67e5\u8be2\u96c6\u4e0a\uff0c\u901a\u8fc7\u591a\u8f6e\u9a8c\u8bc1\u4e0e\u53cd\u601d\uff0c\u53ec\u56de\u7387\u63d0\u5347\u7ea620\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u7528\u6237\u6ee1\u610f\u5ea6\u3002", "conclusion": "RAMP\u6846\u67b6\u7ed3\u5408\u4e86LLM\u7684\u89c4\u5212\u548c\u957f\u671f\u8bb0\u5fc6\u673a\u5236\uff0c\u901a\u8fc7\u53cd\u590d\u9a8c\u8bc1\u4e0e\u53cd\u601d\uff0c\u63d0\u9ad8\u4e86\u884c\u4e1a\u5b9e\u9645\u73af\u5883\u4e0b\u7684\u7cfb\u7edf\u53ef\u9760\u6027\u4e0e\u6548\u679c\u3002"}}
{"id": "2508.11133", "categories": ["cs.CL", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2508.11133", "abs": "https://arxiv.org/abs/2508.11133", "authors": ["Tomer Wolfson", "Harsh Trivedi", "Mor Geva", "Yoav Goldberg", "Dan Roth", "Tushar Khot", "Ashish Sabharwal", "Reut Tsarfaty"], "title": "MoNaCo: More Natural and Complex Questions for Reasoning Across Dozens of Documents", "comment": "Accepted for publication in Transactions of the Association for\n  Computational Linguistics (TACL), 2025. Authors pre-print", "summary": "Large language models (LLMs) are emerging as a go-to tool for querying\ninformation. However, current LLM benchmarks rarely feature natural questions\nthat are both information-seeking as well as genuinely time-consuming for\nhumans. To address this gap we introduce MoNaCo, a benchmark of 1,315 natural\nand complex questions that require dozens, and at times hundreds, of\nintermediate steps to solve -- far more than any existing QA benchmark. To\nbuild MoNaCo, we developed a decomposed annotation pipeline to elicit and\nmanually answer natural time-consuming questions at scale. Frontier LLMs\nevaluated on MoNaCo achieve at most 61.2% F1, hampered by low recall and\nhallucinations. Our results underscore the need for reasoning models that\nbetter handle the complexity and sheer breadth of real-world\ninformation-seeking questions -- with MoNaCo providing an effective resource\nfor tracking such progress. The MONACO benchmark, codebase, prompts and models\npredictions are publicly available at: https://tomerwolgithub.github.io/monaco", "AI": {"tldr": "MoNaCo\u662f\u4e00\u4e2a\u9ad8\u96be\u5ea6\u590d\u6742\u95ee\u7b54\u57fa\u51c6\uff0c\u663e\u793a\u73b0\u6709LLM\u5728\u5904\u7406\u771f\u5b9e\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u65f6\u8868\u73b0\u6709\u9650\uff0c\u5e76\u4e3a\u6a21\u578b\u63a8\u7406\u80fd\u529b\u63d0\u5347\u63d0\u4f9b\u4e86\u65b0\u6d4b\u8bd5\u5e73\u53f0\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6807\u51c6\u5f88\u5c11\u5305\u542b\u65e2\u771f\u5b9e\u53c8\u8d39\u65f6\u7684\u4fe1\u606f\u68c0\u7d22\u7c7b\u95ee\u9898\uff0c\u7f3a\u4e4f\u5bf9\u590d\u6742\u81ea\u7136\u95ee\u9898\u7684\u6d4b\u8bd5\u3002\u4e3a\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u65b0\u57fa\u51c6\u3002", "method": "\u5f00\u53d1\u4e86MoNaCo\u57fa\u51c6\uff0c\u5305\u62ec1,315\u4e2a\u81ea\u7136\u4e14\u590d\u6742\u7684\u95ee\u9898\uff0c\u5e76\u8bbe\u8ba1\u4e86\u8be6\u7ec6\u7684\u5206\u89e3\u6807\u6ce8\u6d41\u7a0b\uff0c\u4ee5\u4eba\u5de5\u65b9\u5f0f\u5927\u89c4\u6a21\u6536\u96c6\u548c\u56de\u7b54\u8fd9\u4e9b\u95ee\u9898\u3002", "result": "\u6700\u5148\u8fdb\u7684LLMs\u5728MoNaCo\u57fa\u51c6\u4e0a\u6700\u9ad8\u53ea\u8fbe\u523061.2% F1\uff0c\u4e3b\u8981\u53d7\u9650\u4e8e\u53ec\u56de\u7387\u4f4e\u548c\u751f\u6210\u5e7b\u89c9\u3002", "conclusion": "MoNaCo\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u5728\u590d\u6742\u771f\u5b9e\u95ee\u9898\u4e0a\u7684\u4e0d\u8db3\uff0c\u5f3a\u8c03\u4e86\u5f00\u53d1\u66f4\u5f3a\u63a8\u7406\u80fd\u529b\u6a21\u578b\u7684\u9700\u6c42\uff0c\u5e76\u4e3a\u672a\u6765\u8fdb\u5c55\u7684\u8861\u91cf\u63d0\u4f9b\u4e86\u6709\u6548\u8d44\u6e90\u3002"}}
{"id": "2508.11163", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11163", "abs": "https://arxiv.org/abs/2508.11163", "authors": ["Hikaru Asano", "Hiroki Ouchi", "Akira Kasuga", "Ryo Yonetani"], "title": "MobQA: A Benchmark Dataset for Semantic Understanding of Human Mobility Data through Question Answering", "comment": "23 pages, 12 figures", "summary": "This paper presents MobQA, a benchmark dataset designed to evaluate the\nsemantic understanding capabilities of large language models (LLMs) for human\nmobility data through natural language question answering.\n  While existing models excel at predicting human movement patterns, it remains\nunobvious how much they can interpret the underlying reasons or semantic\nmeaning of those patterns. MobQA provides a comprehensive evaluation framework\nfor LLMs to answer questions about diverse human GPS trajectories spanning\ndaily to weekly granularities. It comprises 5,800 high-quality question-answer\npairs across three complementary question types: factual retrieval (precise\ndata extraction), multiple-choice reasoning (semantic inference), and free-form\nexplanation (interpretive description), which all require spatial, temporal,\nand semantic reasoning. Our evaluation of major LLMs reveals strong performance\non factual retrieval but significant limitations in semantic reasoning and\nexplanation question answering, with trajectory length substantially impacting\nmodel effectiveness. These findings demonstrate the achievements and\nlimitations of state-of-the-art LLMs for semantic mobility\nunderstanding.\\footnote{MobQA dataset is available at\nhttps://github.com/CyberAgentAILab/mobqa.}", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u4e86MobQA\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7406\u89e3\u4eba\u7c7b\u79fb\u52a8\u8f68\u8ff9\u8bed\u4e49\u7684\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u6a21\u578b\u5728\u4e8b\u5b9e\u68c0\u7d22\u4e0a\u8868\u73b0\u5f3a\uff0c\u4f46\u5728\u8bed\u4e49\u63a8\u7406\u4e0e\u89e3\u91ca\u4e0a\u4ecd\u6709\u9650\uff0cMobQA\u4e3a\u76f8\u5173\u6a21\u578b\u7684\u6539\u8fdb\u63d0\u4f9b\u4e86\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u867d\u7136\u80fd\u5f88\u597d\u5730\u9884\u6d4b\u4eba\u7c7b\u79fb\u52a8\u8f68\u8ff9\uff0c\u4f46\u5bf9\u8fd9\u4e9b\u8f68\u8ff9\u80cc\u540e\u539f\u56e0\u4e0e\u8bed\u4e49\u7684\u7406\u89e3\u80fd\u529b\u5c1a\u4e0d\u660e\u786e\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u8861\u91cf\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4eba\u7c7b\u79fb\u52a8\u6570\u636e\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u7684\u65b0\u57fa\u51c6\u3002", "method": "\u63d0\u51fa\u4e86MobQA\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u95ee\u7b54\u7684\u65b9\u5f0f\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u8bfb\u4eba\u7c7bGPS\u8f68\u8ff9\u8fc7\u7a0b\u4e2d\u7a7a\u95f4\u3001\u65f6\u95f4\u548c\u8bed\u4e49\u63a8\u7406\u7684\u80fd\u529b\u3002MobQA\u5305\u542b5800\u4e2a\u9ad8\u8d28\u91cf\u95ee\u7b54\u5bf9\uff0c\u8986\u76d6\u4e8b\u5b9e\u68c0\u7d22\u3001\u591a\u9879\u9009\u62e9\u63a8\u7406\u4e0e\u81ea\u7531\u8868\u8ff0\u89e3\u91ca\u4e09\u79cd\u9898\u578b\u3002", "result": "\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e8b\u5b9e\u68c0\u7d22\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u8bed\u4e49\u63a8\u7406\u548c\u89e3\u91ca\u7c7b\u95ee\u7b54\u65b9\u9762\u8868\u73b0\u51fa\u660e\u663e\u4e0d\u8db3\uff0c\u4e14\u8f68\u8ff9\u957f\u5ea6\u5bf9\u6a21\u578b\u6709\u6548\u6027\u6709\u8f83\u5927\u5f71\u54cd\u3002", "conclusion": "MobQA\u63ed\u793a\u4e86\u76ee\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u4eba\u7c7b\u79fb\u52a8\u8f68\u8ff9\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u5b58\u5728\u6210\u5c31\u548c\u660e\u663e\u9650\u5236\uff0c\u4e3a\u8be5\u9886\u57df\u540e\u7eed\u7814\u7a76\u548c\u7b97\u6cd5\u6539\u8fdb\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2508.11166", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11166", "abs": "https://arxiv.org/abs/2508.11166", "authors": ["Anusha M D", "Deepthi Vikram", "Bharathi Raja Chakravarthi", "Parameshwar R Hegde"], "title": "Overcoming Low-Resource Barriers in Tulu: Neural Models and Corpus Creation for OffensiveLanguage Identification", "comment": "20 pages, 3 tables, 3 figures. Submitted to Language Resources and\n  Evaluation (Springer)", "summary": "Tulu, a low-resource Dravidian language predominantly spoken in southern\nIndia, has limited computational resources despite its growing digital\npresence. This study presents the first benchmark dataset for Offensive\nLanguage Identification (OLI) in code-mixed Tulu social media content,\ncollected from YouTube comments across various domains. The dataset, annotated\nwith high inter-annotator agreement (Krippendorff's alpha = 0.984), includes\n3,845 comments categorized into four classes: Not Offensive, Not Tulu,\nOffensive Untargeted, and Offensive Targeted. We evaluate a suite of deep\nlearning models, including GRU, LSTM, BiGRU, BiLSTM, CNN, and attention-based\nvariants, alongside transformer architectures (mBERT, XLM-RoBERTa). The BiGRU\nmodel with self-attention achieves the best performance with 82% accuracy and a\n0.81 macro F1-score. Transformer models underperform, highlighting the\nlimitations of multilingual pretraining in code-mixed, under-resourced\ncontexts. This work lays the foundation for further NLP research in Tulu and\nsimilar low-resource, code-mixed languages.", "AI": {"tldr": "\u9996\u6b21\u5efa\u7acb\u4e86Tulu\u6df7\u5408\u8bed\u793e\u4ea4\u5a92\u4f53\u653b\u51fb\u6027\u8bed\u8a00\u8bc6\u522b\u6570\u636e\u96c6\uff0c\u5e76\u7cfb\u7edf\u8bc4\u4f30\u591a\u79cd\u6a21\u578b\u7b97\u6cd5\uff0c\u53d1\u73b0BiGRU\u6ce8\u610f\u529b\u6a21\u578b\u6548\u679c\u6700\u597d\uff0cTransformer\u7c7b\u6a21\u578b\u6548\u679c\u4e00\u822c\u3002\u7814\u7a76\u4e3a\u4f4e\u8d44\u6e90\u4ee3\u7801\u6df7\u5408\u8bed\u8a00\u7684NLP\u4efb\u52a1\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "Tulu\u662f\u4e00\u79cd\u5357\u5370\u5ea6\u7684\u4f4e\u8d44\u6e90\u8fbe\u7f57\u6bd7\u837c\u8bed\uff0c\u5c3d\u7ba1\u5176\u6570\u5b57\u4f7f\u7528\u4e0d\u65ad\u589e\u957f\uff0c\u4f46\u8ba1\u7b97\u8d44\u6e90\u6781\u4e3a\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\u4e2d\u5b58\u5728\u7684\u653b\u51fb\u6027\u8bed\u8a00\u8bc6\u522b\u65b9\u9762\u3002", "method": "\u9488\u5bf9\u6df7\u5408\u8bed\u7684Tulu\u793e\u4ea4\u5a92\u4f53\u8bc4\u8bba\uff0c\u5efa\u7acb\u5e76\u6807\u6ce8\u9996\u4e2a\u653b\u51fb\u6027\u8bed\u8a00\u8bc6\u522b\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u62ec3845\u6761\u8bc4\u8bba\uff0c\u5206\u4e3a\u56db\u7c7b\uff0c\u5e76\u4f7f\u7528\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u5982GRU, LSTM, CNN\u53ca\u6ce8\u610f\u529b\u673a\u5236\u6a21\u578b\u548ctransformer\u67b6\u6784\uff09\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "BiGRU\u81ea\u6ce8\u610f\u529b\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u8fbe82%\uff0c\u5b8fF1\u5f97\u5206\u4e3a0.81\uff1b\u800c\u591a\u8bed\u8a00\u9884\u8bad\u7ec3\u7684transformer\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u548c\u6df7\u5408\u8bed\u73af\u5883\u4e2d\u8868\u73b0\u8f83\u5dee\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aTulu\u53ca\u5176\u4ed6\u4f4e\u8d44\u6e90\u6df7\u5408\u8bed\u7684NLP\u4efb\u52a1\uff08\u5982\u653b\u51fb\u6027\u8bed\u8a00\u8bc6\u522b\uff09\u5efa\u7acb\u4e86\u57fa\u7840\u6570\u636e\u96c6\u548c\u8bc4\u4ef7\u6807\u51c6\uff0c\u63a8\u52a8\u4e86\u76f8\u5173\u9886\u57df\u7814\u7a76\u3002"}}
{"id": "2508.11184", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11184", "abs": "https://arxiv.org/abs/2508.11184", "authors": ["Tao Wu", "Jingyuan Chen", "Wang Lin", "Jian Zhan", "Mengze Li", "Kun Kuang", "Fei Wu"], "title": "Personalized Distractor Generation via MCTS-Guided Reasoning Reconstruction", "comment": null, "summary": "Distractors, incorrect but plausible answer choices in multiple-choice\nquestions (MCQs), play a critical role in educational assessment by diagnosing\nstudent misconceptions. Recent work has leveraged large language models (LLMs)\nto generate shared, group-level distractors by learning common error patterns\nacross large student populations. However, such distractors often fail to\ncapture the diverse reasoning errors of individual students, limiting their\ndiagnostic effectiveness. To address this limitation, we introduce the task of\npersonalized distractor generation, which aims to generate tailored distractors\nbased on individual misconceptions inferred from each student's past\nquestion-answering (QA) records, ensuring every student receives options that\neffectively exposes their specific reasoning errors. While promising, this task\nis challenging because each student typically has only a few QA records, which\noften lack the student's underlying reasoning processes, making training-based\ngroup-level approaches infeasible. To overcome this, we propose a training-free\ntwo-stage framework. In the first stage, we construct a student-specific\nmisconception prototype by applying Monte Carlo Tree Search (MCTS) to recover\nthe student's reasoning trajectories from past incorrect answers. In the second\nstage, this prototype guides the simulation of the student's reasoning on new\nquestions, enabling the generation of personalized distractors that align with\nthe student's recurring misconceptions. Experiments show that our approach\nachieves the best performance in generating plausible, personalized distractors\nfor 140 students, and also effectively generalizes to group-level settings,\nhighlighting its robustness and adaptability.", "AI": {"tldr": "\u672c\u7814\u7a76\u521b\u65b0\u6027\u5730\u63d0\u51fa\u4e86\u4e3a\u6bcf\u4e2a\u5b66\u751f\u91cf\u8eab\u5b9a\u5236\u9009\u62e9\u9898\u5e72\u6270\u9879\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u91cd\u6784\u4e2a\u4f53\u8bef\u533a\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8bca\u65ad\u5b66\u751f\u9519\u8bef\u601d\u7ef4\u7684\u80fd\u529b\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5927\u6a21\u578b\u751f\u6210\u7684\u9009\u62e9\u9898\u5e72\u6270\u9879\u591a\u4e3a\u7fa4\u4f53\u5171\u6027\uff0c\u65e0\u6cd5\u8bca\u65ad\u548c\u66b4\u9732\u5b66\u751f\u7684\u4e2a\u6027\u5316\u8ba4\u77e5\u8bef\u533a\uff0c\u5f71\u54cd\u6d4b\u8bc4\u6709\u6548\u6027\u3002\u4e3a\u6b64\u63d0\u51fa\u9488\u5bf9\u4e2a\u4eba\u8bef\u89e3\u5b9a\u5236\u5e72\u6270\u9879\u7684\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u4e24\u9636\u6bb5\u6846\u67b6\u3002\u7b2c\u4e00\u6b65\uff0c\u57fa\u4e8e\u5b66\u751f\u8fc7\u5f80\u7b54\u9898\u8bb0\u5f55\uff0c\u5229\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\u8ffd\u6eaf\u5176\u9519\u8bef\u7b54\u6848\u7684\u63a8\u7406\u8def\u5f84\uff0c\u6784\u5efa\u201c\u5b66\u751f\u7279\u5b9a\u7684\u8bef\u533a\u539f\u578b\u201d\uff1b\u7b2c\u4e8c\u6b65\uff0c\u7528\u8be5\u539f\u578b\u5f15\u5bfc\u5bf9\u65b0\u95ee\u9898\u7684\u63a8\u7406\u6a21\u62df\uff0c\u751f\u6210\u7b26\u5408\u5176\u60ef\u5e38\u9519\u8bef\u7684\u4e2a\u6027\u5316\u5e72\u6270\u9879\u3002", "result": "\u5728140\u540d\u5b66\u751f\u7684\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u751f\u6210\u7684\u4e2a\u6027\u5316\u5e72\u6270\u9879\u5728\u5408\u7406\u6027\u548c\u4e2a\u6027\u5316\u65b9\u9762\u8868\u73b0\u6700\u4f18\uff0c\u5e76\u80fd\u9002\u5e94\u7fa4\u4f53\u7ea7\u522b\u5e94\u7528\uff0c\u5c55\u73b0\u4e86\u9c81\u68d2\u6027\u548c\u901a\u7528\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e2a\u6027\u5316\u5e72\u6270\u9879\u751f\u6210\u65b0\u4efb\u52a1\uff0c\u5e76\u7528\u65e0\u8bad\u7ec3\u4e24\u9636\u6bb5\u65b9\u6cd5\u6709\u6548\u5b9e\u73b0\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5e72\u6270\u9879\u7684\u8bca\u65ad\u80fd\u529b\u3001\u4e2a\u6027\u5316\u53ca\u9002\u5e94\u6027\u3002"}}
{"id": "2508.11189", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2508.11189", "abs": "https://arxiv.org/abs/2508.11189", "authors": ["Chenyang Le", "Yinfeng Xia", "Huiyan Li", "Manhong Wang", "Yutao Sun", "Xingyang Ma", "Yanmin Qian"], "title": "Novel Parasitic Dual-Scale Modeling for Efficient and Accurate Multilingual Speech Translation", "comment": "Interspeech 2025", "summary": "Recent advancements in speech-to-text translation have led to the development\nof multilingual models capable of handling multiple language pairs\nsimultaneously. However, these unified models often suffer from large parameter\nsizes, making it challenging to balance inference efficiency and performance,\nparticularly in local deployment scenarios. We propose an innovative Parasitic\nDual-Scale Approach, which combines an enhanced speculative sampling method\nwith model compression and knowledge distillation techniques. Building on the\nWhisper Medium model, we enhance it for multilingual speech translation into\nwhisperM2M, and integrate our novel KVSPN module, achieving state-of-the-art\n(SOTA) performance across six popular languages with improved inference\nefficiency. KVSPN enables a 40\\% speedup with no BLEU score degradation.\nCombined with distillation methods, it represents a 2.6$\\times$ speedup over\nthe original Whisper Medium with superior performance.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u63a8\u6d4b\u91c7\u6837\u3001\u6a21\u578b\u538b\u7f29\u548c\u84b8\u998f\u7684\u53cc\u5c3a\u5ea6\u521b\u65b0\u65b9\u6cd5\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u8bed\u97f3\u591a\u8bed\u8a00\u7ffb\u8bd1\u6a21\u578b\u7684\u63a8\u7406\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u8bc1\u7ffb\u8bd1\u8d28\u91cf\uff0c\u5c24\u5176\u9002\u5408\u672c\u5730\u90e8\u7f72\u3002", "motivation": "\u8fd1\u5e74\u6765\u8bed\u97f3\u8f6c\u6587\u672c\u7ffb\u8bd1\u9886\u57df\u53d1\u5c55\u8fc5\u901f\uff0c\u7136\u800c\u591a\u8bed\u8a00\u6a21\u578b\u53c2\u6570\u91cf\u5927\uff0c\u5f71\u54cd\u63a8\u7406\u6548\u7387\uff0c\u5c24\u5176\u5728\u672c\u5730\u90e8\u7f72\u65f6\u66f4\u4e3a\u7a81\u51fa\u3002\u56e0\u6b64\u4e9f\u9700\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u53c8\u80fd\u4fdd\u6301\u6027\u80fd\u7684\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u521b\u65b0\u6027\u7684\"\u5bc4\u751f\u53cc\u5c3a\u5ea6\u65b9\u6cd5\"\uff0c\u7ed3\u5408\u4e86\u589e\u5f3a\u578b\u63a8\u6d4b\u91c7\u6837\u65b9\u6cd5\u3001\u6a21\u578b\u538b\u7f29\u548c\u77e5\u8bc6\u84b8\u998f\u7b49\u6280\u672f\u3002\u57fa\u4e8eWhisper Medium\u6a21\u578b\uff0c\u8fdb\u4e00\u6b65\u5f00\u53d1\u51fa\u9002\u7528\u4e8e\u591a\u8bed\u8a00\u8bed\u97f3\u7ffb\u8bd1\u7684whisperM2M\u6a21\u578b\uff0c\u5e76\u96c6\u6210\u4e86KVSPN\u6a21\u5757\u3002", "result": "\u5728\u516d\u79cd\u4e3b\u6d41\u8bed\u8a00\u4e0a\uff0c\u96c6\u6210KVSPN\u6a21\u5757\u5b9e\u73b0\u4e8640%\u7684\u63a8\u7406\u901f\u5ea6\u63d0\u5347\uff0c\u540c\u65f6BLEU\u5206\u6570\u65e0\u635f\u5931\u3002\u7ed3\u5408\u84b8\u998f\u65b9\u6cd5\u540e\uff0c\u603b\u4f53\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u4e862.6\u500d\uff0c\u5e76\u4e14\u6027\u80fd\u4f18\u4e8e\u539f\u59cbWhisper Medium\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5728\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u751a\u81f3\u8d85\u8d8a\u539f\u6709\u7ffb\u8bd1\u6027\u80fd\uff0c\u9002\u5408\u591a\u8bed\u8a00\u8bed\u97f3\u7ffb\u8bd1\u6a21\u578b\u7684\u672c\u5730\u90e8\u7f72\u3002"}}
{"id": "2508.11197", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2508.11197", "abs": "https://arxiv.org/abs/2508.11197", "authors": ["Ahmad Mousavi", "Yeganeh Abdollahinejad", "Roberto Corizzo", "Nathalie Japkowicz", "Zois Boukouvalas"], "title": "E-CaTCH: Event-Centric Cross-Modal Attention with Temporal Consistency and Class-Imbalance Handling for Misinformation Detection", "comment": null, "summary": "Detecting multimodal misinformation on social media remains challenging due\nto inconsistencies between modalities, changes in temporal patterns, and\nsubstantial class imbalance. Many existing methods treat posts independently\nand fail to capture the event-level structure that connects them across time\nand modality. We propose E-CaTCH, an interpretable and scalable framework for\nrobustly detecting misinformation. If needed, E-CaTCH clusters posts into\npseudo-events based on textual similarity and temporal proximity, then\nprocesses each event independently. Within each event, textual and visual\nfeatures are extracted using pre-trained BERT and ResNet encoders, refined via\nintra-modal self-attention, and aligned through bidirectional cross-modal\nattention. A soft gating mechanism fuses these representations to form\ncontextualized, content-aware embeddings of each post. To model temporal\nevolution, E-CaTCH segments events into overlapping time windows and uses a\ntrend-aware LSTM, enhanced with semantic shift and momentum signals, to encode\nnarrative progression over time. Classification is performed at the event\nlevel, enabling better alignment with real-world misinformation dynamics. To\naddress class imbalance and promote stable learning, the model integrates\nadaptive class weighting, temporal consistency regularization, and hard-example\nmining. The total loss is aggregated across all events. Extensive experiments\non Fakeddit, IND, and COVID-19 MISINFOGRAPH demonstrate that E-CaTCH\nconsistently outperforms state-of-the-art baselines. Cross-dataset evaluations\nfurther demonstrate its robustness, generalizability, and practical\napplicability across diverse misinformation scenarios.", "AI": {"tldr": "\u63d0\u51faE-CaTCH\u591a\u6a21\u6001\u4e8b\u4ef6\u7ea7\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u6846\u67b6\uff0c\u878d\u5408\u591a\u79cd\u8868\u5f81\u4e0e\u65f6\u5e8f\u5efa\u6a21\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5168\u9762\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u793e\u4ea4\u5a92\u4f53\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u573a\u666f\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u591a\u6a21\u6001\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u6781\u5177\u6311\u6218\u6027\uff0c\u4e3b\u8981\u7531\u4e8e\u4e0d\u540c\u6a21\u6001\u4e4b\u95f4\u7684\u4e0d\u4e00\u81f4\u6027\u3001\u65f6\u5e8f\u6a21\u5f0f\u53d8\u5316\u4ee5\u53ca\u7c7b\u522b\u6781\u5ea6\u5931\u8861\u3002\u73b0\u6709\u65b9\u6cd5\u591a\u72ec\u7acb\u5904\u7406\u5e16\u5b50\uff0c\u96be\u4ee5\u6355\u6349\u6a2a\u8de8\u65f6\u95f4\u548c\u6a21\u6001\u7684\u4e8b\u4ef6\u7ea7\u7ed3\u6784\u3002", "method": "\u63d0\u51faE-CaTCH\u6846\u67b6\uff0c\u5c06\u5e16\u5b50\u57fa\u4e8e\u6587\u672c\u76f8\u4f3c\u6027\u4e0e\u65f6\u95f4\u4e34\u8fd1\u6027\u805a\u7c7b\u6210\u4f2a\u4e8b\u4ef6\uff0c\u5e76\u5206\u522b\u5904\u7406\u3002\u4f7f\u7528BERT\u4e0eResNet\u63d0\u53d6\u6587\u672c\u548c\u89c6\u89c9\u7279\u5f81\uff0c\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u548c\u53cc\u5411\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u8fdb\u884c\u5bf9\u9f50\u3002\u5f15\u5165\u8f6f\u95e8\u63a7\u673a\u5236\u878d\u5408\u8868\u793a\u3002\u4e8b\u4ef6\u88ab\u5206\u5272\u4e3a\u65f6\u95f4\u7a97\u53e3\uff0c\u5f15\u5165\u8d8b\u52bf\u611f\u77e5LSTM\u4e0e\u8bed\u4e49\u53d8\u5316\u548c\u52a8\u91cf\u4fe1\u53f7\u5efa\u6a21\u53d9\u4e8b\u53d1\u5c55\u3002\u91c7\u7528\u4e8b\u4ef6\u7ea7\u5206\u7c7b\uff0c\u5e76\u878d\u5408\u81ea\u9002\u5e94\u7c7b\u522b\u52a0\u6743\u3001\u65f6\u5e8f\u4e00\u81f4\u6027\u6b63\u5219\u5316\u548c\u96be\u4f8b\u6316\u6398\uff0c\u6700\u7ec8\u5bf9\u6240\u6709\u4e8b\u4ef6\u805a\u5408\u635f\u5931\u3002", "result": "\u5728Fakeddit, IND\u53caCOVID-19 MISINFOGRAPH\u7b49\u6570\u636e\u96c6\u4e0a\uff0cE-CaTCH\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5728\u8de8\u6570\u636e\u96c6\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u9c81\u68d2\u6027\u3001\u6cdb\u5316\u6027\u53ca\u5b9e\u9645\u9002\u7528\u6027\u3002", "conclusion": "E-CaTCH\u662f\u4e00\u5957\u53ef\u89e3\u91ca\u3001\u53ef\u6269\u5c55\u4e14\u9c81\u68d2\u7684\u591a\u6a21\u6001\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e8b\u4ef6\u7ea7\u7ed3\u6784\u5efa\u6a21\u4e0e\u7c7b\u522b\u5931\u8861\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u8de8\u573a\u666f\u7684\u865a\u5047\u4fe1\u606f\u8bc6\u522b\u80fd\u529b\u3002"}}
{"id": "2508.11247", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11247", "abs": "https://arxiv.org/abs/2508.11247", "authors": ["Changjian Wang", "Weihong Deng", "Weili Guan", "Quan Lu", "Ning Jiang"], "title": "Cross-Granularity Hypergraph Retrieval-Augmented Generation for Multi-hop Question Answering", "comment": null, "summary": "Multi-hop question answering (MHQA) requires integrating knowledge scattered\nacross multiple passages to derive the correct answer. Traditional\nretrieval-augmented generation (RAG) methods primarily focus on coarse-grained\ntextual semantic similarity and ignore structural associations among dispersed\nknowledge, which limits their effectiveness in MHQA tasks. GraphRAG methods\naddress this by leveraging knowledge graphs (KGs) to capture structural\nassociations, but they tend to overly rely on structural information and\nfine-grained word- or phrase-level retrieval, resulting in an underutilization\nof textual semantics. In this paper, we propose a novel RAG approach called\nHGRAG for MHQA that achieves cross-granularity integration of structural and\nsemantic information via hypergraphs. Structurally, we construct an entity\nhypergraph where fine-grained entities serve as nodes and coarse-grained\npassages as hyperedges, and establish knowledge association through shared\nentities. Semantically, we design a hypergraph retrieval method that integrates\nfine-grained entity similarity and coarse-grained passage similarity via\nhypergraph diffusion. Finally, we employ a retrieval enhancement module, which\nfurther refines the retrieved results both semantically and structurally, to\nobtain the most relevant passages as context for answer generation with the\nLLM. Experimental results on benchmark datasets demonstrate that our approach\noutperforms state-of-the-art methods in QA performance, and achieves a\n6$\\times$ speedup in retrieval efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHGRAG\u65b9\u6cd5\uff0c\u901a\u8fc7\u8d85\u56fe\u878d\u5408\u7ec6\u7c92\u5ea6\u7ed3\u6784\u4e0e\u7c97\u7c92\u5ea6\u8bed\u4e49\uff0c\u5f3a\u5316\u591a\u8df3\u95ee\u7b54\u6240\u9700\u77e5\u8bc6\u6574\u5408\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u4e0e\u6548\u7387\u5747\u9886\u5148\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709RAG\u65b9\u6cd5\u591a\u4fa7\u91cd\u7c97\u7c92\u5ea6\u8bed\u4e49\u76f8\u4f3c\u6027\u800c\u5ffd\u7565\u5206\u6563\u77e5\u8bc6\u95f4\u7684\u7ed3\u6784\u5173\u8054\uff0cGraphRAG\u867d\u5229\u7528KG\u5efa\u6a21\u7ed3\u6784\u5173\u7cfb\u4f46\u8fc7\u5ea6\u4f9d\u8d56\u7ec6\u7c92\u5ea6\u7ed3\u6784\uff0c\u672a\u80fd\u5145\u5206\u7ed3\u5408\u6587\u672c\u8bed\u4e49\uff1b\u591a\u8df3\u95ee\u7b54\u8981\u6c42\u66f4\u9ad8\u6548\u5730\u6574\u5408\u5206\u6563\u77e5\u8bc6\uff0c\u4fc3\u4f7f\u63d0\u51fa\u878d\u5408\u7ed3\u6784\u4e0e\u8bed\u4e49\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u5b9e\u4f53\u8d85\u56fe\uff0c\u5c06\u7ec6\u7c92\u5ea6\u5b9e\u4f53\u4f5c\u4e3a\u8282\u70b9\u3001\u7c97\u7c92\u5ea6\u7bc7\u7ae0\u4f5c\u4e3a\u8d85\u8fb9\uff0c\u5229\u7528\u8d85\u56fe\u6269\u6563\u673a\u5236\u7ed3\u5408\u5b9e\u4f53\u76f8\u4f3c\u6027\u548c\u7bc7\u7ae0\u76f8\u4f3c\u6027\u8fdb\u884c\u68c0\u7d22\uff0c\u5e76\u52a0\u5165\u68c0\u7d22\u589e\u5f3a\u6a21\u5757\u4f18\u5316\u7ed3\u679c\u3002", "result": "\u5728\u4e3b\u6d41\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cHGRAG\u663e\u8457\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5728\u95ee\u7b54\u8868\u73b0\u548c\u68c0\u7d22\u6548\u7387\u65b9\u9762\u5747\u6709\u7a81\u7834\uff0c\u68c0\u7d22\u901f\u5ea6\u63d0\u5347\u8fbe6\u500d\u3002", "conclusion": "HGRAG\u65b9\u6cd5\u80fd\u591f\u5728\u8de8\u7c92\u5ea6\u878d\u5408\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u8df3\u95ee\u7b54\u6027\u80fd\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u7d22\u6548\u7387\u3002"}}
{"id": "2508.11260", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11260", "abs": "https://arxiv.org/abs/2508.11260", "authors": ["Mukund Choudhary", "KV Aditya Srivatsa", "Gaurja Aeron", "Antara Raaghavi Bhattacharya", "Dang Khoa Dang Dinh", "Ikhlasul Akmal Hanif", "Daria Kotova", "Ekaterina Kochmar", "Monojit Choudhury"], "title": "UNVEILING: What Makes Linguistics Olympiad Puzzles Tricky for LLMs?", "comment": "Accepted to COLM 2025", "summary": "Large language models (LLMs) have demonstrated potential in reasoning tasks,\nbut their performance on linguistics puzzles remains consistently poor. These\npuzzles, often derived from Linguistics Olympiad (LO) contests, provide a\nminimal contamination environment to assess LLMs' linguistic reasoning\nabilities across low-resource languages. This work analyses LLMs' performance\non 629 problems across 41 low-resource languages by labelling each with\nlinguistically informed features to unveil weaknesses. Our analyses show that\nLLMs struggle with puzzles involving higher morphological complexity and\nperform better on puzzles involving linguistic features that are also found in\nEnglish. We also show that splitting words into morphemes as a pre-processing\nstep improves solvability, indicating a need for more informed and\nlanguage-specific tokenisers. These findings thus offer insights into some\nchallenges in linguistic reasoning and modelling of low-resource languages.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790LLMs\u89e3\u51b3\u4f4e\u8d44\u6e90\u8bed\u8a00\u5965\u8d5b\u8c1c\u9898\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u5f62\u6001\u590d\u6742\u6027\u9ad8\u7684\u9898\u76ee\u4e0a\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u4e14\u66f4\u503e\u5411\u4e8e\u89e3\u51b3\u542b\u82f1\u8bed\u5e38\u89c1\u7279\u5f81\u7684\u9898\u76ee\u3002\u5206\u8bcd\u9884\u5904\u7406\u80fd\u63d0\u5347\u89e3\u51b3\u80fd\u529b\uff0c\u53cd\u6620\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u66f4\u667a\u80fd\u5206\u8bcd\u548c\u5efa\u6a21\u7684\u8feb\u5207\u9700\u6c42\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u53ca\u590d\u6742\u5f62\u6001\u7ed3\u6784\u4e0b\u7684\u8bed\u8a00\u63a8\u7406\u80fd\u529b\uff0c\u63ed\u793a\u5176\u5c40\u9650\u6027\u5e76\u5bfb\u6c42\u63d0\u5347\u65b9\u6cd5\u3002", "method": "\u5206\u6790\u4e86629\u9053\u6db5\u76d641\u79cd\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u8bed\u8a00\u5b66\u5965\u8d5b\u8c1c\u9898\uff0c\u7528\u8bed\u8a00\u5b66\u7279\u5f81\u8fdb\u884c\u6807\u6ce8\uff0c\u4ece\u4e0d\u540c\u7ef4\u5ea6\u8bc4\u4f30\u548c\u5206\u6790LLMs\u7684\u7b54\u9898\u8868\u73b0\u3002", "result": "LLMs\u5728\u5f62\u6001\u590d\u6742\u7684\u8c1c\u9898\u4e0a\u8868\u73b0\u8f83\u5dee\uff0c\u901a\u8fc7\u8bcd\u7d20\u5206\u89e3\u80fd\u6539\u5584\u6a21\u578b\u89e3\u51b3\u8c1c\u9898\u7684\u80fd\u529b\uff0c\u5c55\u73b0\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00\u5efa\u6a21\u548c\u63a8\u7406\u7684\u6311\u6218\u4e0e\u6539\u8fdb\u65b9\u5411\u3002", "conclusion": "LLMs\u5728\u590d\u6742\u5f62\u6001\u7ed3\u6784\u7684\u8bed\u8a00\u5b66\u8c1c\u9898\u4e0a\u8868\u73b0\u8f83\u5dee\uff0c\u4f46\u5728\u6d89\u53ca\u82f1\u8bed\u5e38\u89c1\u8bed\u8a00\u7279\u5f81\u7684\u8c1c\u9898\u4e0a\u8868\u73b0\u8f83\u597d\u3002\u5c06\u8bcd\u8bed\u5206\u89e3\u4e3a\u8bcd\u7d20\u6709\u52a9\u4e8e\u63d0\u5347\u6a21\u578b\u8868\u73b0\uff0c\u63d0\u793a\u9700\u8981\u66f4\u667a\u80fd\u7684\u5206\u8bcd\u5668\u3002"}}
{"id": "2508.11280", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11280", "abs": "https://arxiv.org/abs/2508.11280", "authors": ["Ruiyan Qi", "Congding Wen", "Weibo Zhou", "Shangsong Liang", "Lingbo Li"], "title": "LETToT: Label-Free Evaluation of Large Language Models On Tourism Using Expert Tree-of-Thought", "comment": null, "summary": "Evaluating large language models (LLMs) in specific domain like tourism\nremains challenging due to the prohibitive cost of annotated benchmarks and\npersistent issues like hallucinations. We propose $\\textbf{L}$able-Free\n$\\textbf{E}$valuation of LLM on $\\textbf{T}$ourism using Expert\n$\\textbf{T}$ree-$\\textbf{o}$f-$\\textbf{T}$hought (LETToT), a framework that\nleverages expert-derived reasoning structures-instead of labeled data-to access\nLLMs in tourism. First, we iteratively refine and validate hierarchical ToT\ncomponents through alignment with generic quality dimensions and expert\nfeedback. Results demonstrate the effectiveness of our systematically optimized\nexpert ToT with 4.99-14.15\\% relative quality gains over baselines. Second, we\napply LETToT's optimized expert ToT to evaluate models of varying scales\n(32B-671B parameters), revealing: (1) Scaling laws persist in specialized\ndomains (DeepSeek-V3 leads), yet reasoning-enhanced smaller models (e.g.,\nDeepSeek-R1-Distill-Llama-70B) close this gap; (2) For sub-72B models, explicit\nreasoning architectures outperform counterparts in accuracy and conciseness\n($p<0.05$). Our work established a scalable, label-free paradigm for\ndomain-specific LLM evaluation, offering a robust alternative to conventional\nannotated benchmarks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51faLETToT\u6846\u67b6\uff0c\u65e0\u987b\u6807\u6ce8\uff0c\u4ec5\u501f\u52a9\u4e13\u5bb6\u63a8\u7406\u7ed3\u6784\uff0c\u9ad8\u6548\u8bc4\u4f30\u65c5\u6e38\u9886\u57dfLLMs\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\u548c\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u5bf9\u4f20\u7edf\u8bc4\u4f30\u5177\u6709\u91cd\u8981\u8865\u5145\u4f5c\u7528\u3002", "motivation": "\u5728\u65c5\u6e38\u7b49\u7279\u5b9a\u9886\u57df\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u9762\u4e34\u9ad8\u6602\u7684\u6807\u6ce8\u6210\u672c\u548c\u751f\u6210\u504f\u5dee\uff08\u5982\u5e7b\u89c9\uff09\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u6807\u6ce8\u6570\u636e\u7684\u8bc4\u4f30\u6846\u67b6LETToT\uff08\u57fa\u4e8e\u4e13\u5bb6\u6811\u5f0f\u63a8\u7406\u7ed3\u6784\uff09\uff0c\u901a\u8fc7\u4e0e\u901a\u7528\u8d28\u91cf\u7ef4\u5ea6\u548c\u4e13\u5bb6\u53cd\u9988\u5bf9\u9f50\uff0c\u8fed\u4ee3\u4f18\u5316\u63a8\u7406\u7ec4\u4ef6\u3002", "result": "\u4e13\u5bb6\u6811\u5f0f\u63a8\u7406\u7ed3\u6784\u7684\u4f18\u5316\u4e3aLLMs\u5e26\u67654.99-14.15%\u7684\u76f8\u5bf9\u8d28\u91cf\u63d0\u5347\u3002\u6a21\u578b\u89c4\u6a21\u6269\u5927\u5728\u4e13\u4e1a\u9886\u57df\u4f9d\u65e7\u6709\u6548\uff0c\u4f46\u63a8\u7406\u589e\u5f3a\u7684\u5c0f\u6a21\u578b\u53ef\u7f29\u5c0f\u5dee\u8ddd\u3002\u7406\u7531\u67b6\u6784\u5728\u4e2d\u5c0f\u89c4\u6a21\u6a21\u578b\u4e0b\u663e\u8457\u63d0\u5347\u51c6\u786e\u6027\u548c\u7b80\u660e\u6027\u3002", "conclusion": "\u5efa\u7acb\u4e86\u53ef\u6269\u5c55\u3001\u65e0\u6807\u6ce8\u7684\u65b0\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u7279\u5b9a\u9886\u57dfLLM\u8bc4\u4f30\uff0c\u4e3a\u4f20\u7edf\u6807\u6ce8\u57fa\u51c6\u63d0\u4f9b\u4e86\u6709\u529b\u66ff\u4ee3\u3002"}}
{"id": "2508.11281", "categories": ["cs.CL", "cs.AI", "cs.CY", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.11281", "abs": "https://arxiv.org/abs/2508.11281", "authors": ["Axel Delaval", "Shujian Yang", "Haicheng Wang", "Han Qiu", "Jialiang Lu"], "title": "ToxiFrench: Benchmarking and Enhancing Language Models via CoT Fine-Tuning for French Toxicity Detection", "comment": "14 pages, 5 figures, 8 tables. This paper introduces TOXIFRENCH, a\n  new large-scale benchmark for French toxicity detection, and proposes a\n  Chain-of-Thought (CoT) fine-tuning method with a dynamic weighted loss. The\n  resulting fine-tuned 4B parameter model, ToxiFrench, achieves\n  state-of-the-art performance, outperforming larger models like GPT-4o", "summary": "Detecting toxic content using language models is crucial yet challenging.\nWhile substantial progress has been made in English, toxicity detection in\nFrench remains underdeveloped, primarily due to the lack of culturally\nrelevant, large-scale datasets. In this work, we introduce TOXIFRENCH, a new\npublic benchmark of 53,622 French online comments, constructed via a\nsemi-automated annotation pipeline that reduces manual labeling to only 10%\nthrough high-confidence LLM-based pre-annotation and human verification. Then,\nwe benchmark a broad range of models and uncover a counterintuitive insight:\nSmall Language Models (SLMs) outperform many larger models in robustness and\ngeneralization under the toxicity detection task. Motivated by this finding, we\npropose a novel Chain-of-Thought (CoT) fine-tuning strategy using a dynamic\nweighted loss that progressively emphasizes the model's final decision,\nsignificantly improving faithfulness. Our fine-tuned 4B model achieves\nstate-of-the-art performance, improving its F1 score by 13% over its baseline\nand outperforming LLMs such as GPT-40 and Gemini-2.5. Further evaluation on a\ncross-lingual toxicity benchmark demonstrates strong multilingual ability,\nsuggesting that our methodology can be effectively extended to other languages\nand safety-critical classification tasks.", "AI": {"tldr": "\u672c\u8bba\u6587\u5efa\u7acb\u4e86\u6cd5\u8bed\u6bd2\u6027\u8bc4\u8bba\u6570\u636e\u96c6\uff0c\u901a\u8fc7LLM\u548c\u4eba\u5de5\u6df7\u5408\u6807\u6ce8\u65b9\u6cd5\u9ad8\u6548\u6784\u5efa\uff0c\u521b\u65b0\u6027\u5730\u63d0\u51fa\u4e86\u4e00\u79cd\u63d0\u5347\u6a21\u578b\u5fe0\u5b9e\u6027\u7684\u5fae\u8c03\u7b56\u7565\uff0c\u5c0f\u6a21\u8868\u73b0\u4f18\u4e8e\u90e8\u5206\u5927\u6a21\uff0c\u7ecf\u9a8c\u8bc1\u8fbe\u6210\u5f53\u524d\u6700\u4f18\u7ed3\u679c\uff0c\u5e76\u5177\u5907\u826f\u597d\u591a\u8bed\u8a00\u63a8\u5e7f\u80fd\u529b\u3002", "motivation": "\u9488\u5bf9\u6cd5\u8bed\u73af\u5883\u4e0b\u6709\u6bd2\u5185\u5bb9\u68c0\u6d4b\u7684\u6ede\u540e\u73b0\u72b6\uff08\u4e3b\u8981\u56e0\u7f3a\u4e4f\u5927\u89c4\u6a21\u672c\u5730\u6587\u5316\u76f8\u5173\u6570\u636e\u96c6\uff09\uff0c\u4f5c\u8005\u5e0c\u671b\u63d0\u5347\u6cd5\u8bed\u6bd2\u6027\u68c0\u6d4b\u7684\u6709\u6548\u6027\u4e0e\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faTOXIFRENCH\u6570\u636e\u96c6\uff0853,622\u6761\u6cd5\u8bed\u5728\u7ebf\u8bc4\u8bba\uff09\uff0c\u901a\u8fc7\u9ad8\u7f6e\u4fe1\u5ea6\u7684LLM\u9884\u6807\u6ce8+\u4eba\u5de5\u9a8c\u8bc1\uff0c\u964d\u4f4e\u4eba\u5de5\u6807\u6ce8\u9700\u6c42\u81f310%\uff1b\u540c\u65f6\uff0c\u6bd4\u8f83\u4e0d\u540c\u89c4\u6a21\u7684\u8bed\u8a00\u6a21\u578b\u8868\u73b0\uff0c\u5e76\u521b\u65b0\u6027\u5730\u5f15\u5165\u52a8\u6001\u52a0\u6743\u635f\u5931\u7684CoT\u5fae\u8c03\u65b9\u6cd5\uff0c\u589e\u5f3a\u6a21\u578b\u51b3\u7b56\u7684\u5fe0\u5b9e\u6027\u3002", "result": "\u53d1\u73b0\u201c\u5c0f\u6a21\u578b\u201d\u5728\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u4f18\u4e8e\u90e8\u5206\u5927\u6a21\u578b\uff1b\u91c7\u7528\u65b0\u5fae\u8c03\u65b9\u6cd5\u540e\uff0c\u51764B\u53c2\u6570\u6a21\u578bF1\u5206\u6570\u8f83\u57fa\u7ebf\u63d0\u534713%\uff0c\u4f18\u4e8eGPT-40\u53caGemini-2.5\uff0c\u5728\u8de8\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e5f\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u63d0\u51fa\u7684TOXIFRENCH\u6570\u636e\u96c6\u4e0eCoT\u5fae\u8c03\u7b56\u7565\u4e0d\u4ec5\u663e\u8457\u63d0\u5347\u6cd5\u8bed\u6bd2\u6027\u68c0\u6d4b\u6027\u80fd\uff0c\u8fd8\u5177\u5907\u591a\u8bed\u8a00\u9002\u5e94\u6f5c\u529b\uff0c\u9002\u5408\u63a8\u5e7f\u5230\u5176\u4ed6\u5b89\u5168\u76f8\u5173\u5206\u7c7b\u4efb\u52a1\u3002"}}
{"id": "2508.11285", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11285", "abs": "https://arxiv.org/abs/2508.11285", "authors": ["Arya VarastehNezhad", "Reza Tavasoli", "Soroush Elyasi", "MohammadHossein LotfiNia", "Hamed Farbeh"], "title": "AI in Mental Health: Emotional and Sentiment Analysis of Large Language Models' Responses to Depression, Anxiety, and Stress Queries", "comment": null, "summary": "Depression, anxiety, and stress are widespread mental health concerns that\nincreasingly drive individuals to seek information from Large Language Models\n(LLMs). This study investigates how eight LLMs (Claude Sonnet, Copilot, Gemini\nPro, GPT-4o, GPT-4o mini, Llama, Mixtral, and Perplexity) reply to twenty\npragmatic questions about depression, anxiety, and stress when those questions\nare framed for six user profiles (baseline, woman, man, young, old, and\nuniversity student). The models generated 2,880 answers, which we scored for\nsentiment and emotions using state-of-the-art tools. Our analysis revealed that\noptimism, fear, and sadness dominated the emotional landscape across all\noutputs, with neutral sentiment maintaining consistently high values.\nGratitude, joy, and trust appeared at moderate levels, while emotions such as\nanger, disgust, and love were rarely expressed. The choice of LLM significantly\ninfluenced emotional expression patterns. Mixtral exhibited the highest levels\nof negative emotions including disapproval, annoyance, and sadness, while Llama\ndemonstrated the most optimistic and joyful responses. The type of mental\nhealth condition dramatically shaped emotional responses: anxiety prompts\nelicited extraordinarily high fear scores (0.974), depression prompts generated\nelevated sadness (0.686) and the highest negative sentiment, while\nstress-related queries produced the most optimistic responses (0.755) with\nelevated joy and trust. In contrast, demographic framing of queries produced\nonly marginal variations in emotional tone. Statistical analyses confirmed\nsignificant model-specific and condition-specific differences, while\ndemographic influences remained minimal. These findings highlight the critical\nimportance of model selection in mental health applications, as each LLM\nexhibits a distinct emotional signature that could significantly impact user\nexperience and outcomes.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e868\u79cd\u4e3b\u6d41LLM\u5728\u5e94\u7b54\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\u65f6\u7684\u60c5\u611f\u8868\u73b0\uff0c\u6307\u51fa\u6a21\u578b\u5dee\u5f02\u660e\u663e\uff0c\u4e14\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\u7c7b\u578b\u5f71\u54cd\u5927\uff0c\u4eba\u53e3\u5b66\u7279\u5f81\u5f71\u54cd\u6709\u9650\uff0c\u5f3a\u8c03\u6a21\u578b\u9009\u62e9\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5f53\u524d\u6291\u90c1\u3001\u7126\u8651\u548c\u538b\u529b\u7b49\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\u666e\u904d\u5b58\u5728\uff0c\u8d8a\u6765\u8d8a\u591a\u7684\u4eba\u5f00\u59cb\u501f\u52a9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u83b7\u53d6\u5fc3\u7406\u5065\u5eb7\u65b9\u9762\u7684\u4fe1\u606f\u3002\u7136\u800c\uff0c\u4e0d\u540cLLM\u5bf9\u7c7b\u4f3c\u95ee\u9898\u7684\u60c5\u611f\u8868\u8fbe\u548c\u56de\u590d\u98ce\u683c\u53ef\u80fd\u5dee\u5f02\u663e\u8457\uff0c\u76f4\u63a5\u5f71\u54cd\u7528\u6237\u4f53\u9a8c\u548c\u5fc3\u7406\u72b6\u6001\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u4e0d\u540cLLM\u5728\u5e94\u5bf9\u76f8\u5173\u95ee\u9898\u65f6\u7684\u60c5\u611f\u8f93\u51fa\uff0c\u5bf9\u4e8e\u5fc3\u7406\u5065\u5eb7\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u672c\u7814\u7a76\u9009\u53d68\u79cdLLM\uff08\u5982Claude Sonnet\u3001Copilot\u3001Gemini Pro\u3001GPT-4o\u7b49\uff09\uff0c\u9488\u5bf96\u7c7b\u7528\u6237\u753b\u50cf\uff08\u57fa\u7ebf\u3001\u5973\u6027\u3001\u7537\u6027\u3001\u9752\u5c11\u5e74\u3001\u8001\u5e74\u548c\u5927\u5b66\u751f\uff09\uff0c\u63d0\u51fa20\u4e2a\u5173\u4e8e\u6291\u90c1\u3001\u7126\u8651\u548c\u538b\u529b\u7684\u5b9e\u9645\u95ee\u9898\uff0c\u6536\u96c6\u51712,880\u4e2a\u56de\u590d\u3002\u7136\u540e\uff0c\u5229\u7528\u5148\u8fdb\u7684\u60c5\u611f\u4e0e\u60c5\u7eea\u5206\u6790\u5de5\u5177\u5bf9\u6240\u6709\u56de\u590d\u8fdb\u884c\u8bc4\u5206\u4e0e\u5206\u6790\uff0c\u5e76\u901a\u8fc7\u7edf\u8ba1\u65b9\u6cd5\u8003\u5bdf\u6a21\u578b\u3001\u5fc3\u7406\u5065\u5eb7\u72b6\u51b5\u548c\u4eba\u53e3\u7279\u5f81\u5bf9\u60c5\u611f\u8f93\u51fa\u7684\u5f71\u54cd\u3002", "result": "\u7ed3\u679c\u53d1\u73b0\uff0c\u6240\u6709LLM\u8f93\u51fa\u6574\u4f53\u4ee5\u4e50\u89c2\u3001\u6050\u60e7\u548c\u60b2\u4f24\u4e09\u79cd\u60c5\u7eea\u4e3b\u5bfc\uff0c\u4e14\u4e2d\u6027\u60c5\u611f\u5206\u503c\u9ad8\u3002\u611f\u6fc0\u3001\u559c\u60a6\u548c\u4fe1\u4efb\u5904\u4e8e\u4e2d\u7b49\u6c34\u5e73\uff0c\u800c\u6124\u6012\u3001\u538c\u6076\u548c\u7231\u8f83\u5c11\u8868\u8fbe\u3002\u6a21\u578b\u4e4b\u95f4\u60c5\u611f\u8868\u73b0\u5dee\u5f02\u663e\u8457\uff0c\u4f8b\u5982Mixtral\u66f4\u6613\u8868\u8fbe\u8d1f\u9762\u60c5\u7eea\uff08\u5982\u4e0d\u6ee1\u3001\u60b2\u4f24\uff09\uff0cLlama\u5219\u66f4\u4e3a\u4e50\u89c2\u548c\u6109\u5feb\u3002\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\u7c7b\u578b\u5bf9\u60c5\u7eea\u8f93\u51fa\u5f71\u54cd\u5f88\u5927\uff0c\u5982\u7126\u8651\u76f8\u5173\u95ee\u9898\u6fc0\u53d1\u6050\u60e7\u5206\u503c\u6700\u9ad8\uff0c\u6291\u90c1\u95ee\u9898\u6fc0\u53d1\u60b2\u4f24\u548c\u8d1f\u9762\u60c5\u611f\u6700\u9ad8\uff0c\u538b\u529b\u95ee\u9898\u5219\u5f15\u53d1\u66f4\u591a\u4e50\u89c2\u3001\u4fe1\u4efb\u548c\u559c\u60a6\u3002\u4e0d\u540c\u4eba\u53e3\u753b\u50cf\u5bf9\u60c5\u611f\u8868\u73b0\u7684\u5f71\u54cd\u5f88\u5c0f\u3002", "conclusion": "\u4e0d\u540c\u7c7b\u578bLLM\u5728\u5e94\u7b54\u5fc3\u7406\u5065\u5eb7\u76f8\u5173\u95ee\u9898\u65f6\u5b58\u5728\u660e\u663e\u4e14\u72ec\u7279\u7684\u60c5\u611f\u98ce\u683c\uff0c\u6a21\u578b\u9009\u62e9\u5bf9\u7528\u6237\u4f53\u9a8c\u548c\u6548\u679c\u5177\u6709\u5173\u952e\u5f71\u54cd\u3002\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\u7c7b\u578b\u5bf9\u60c5\u611f\u8f93\u51fa\u5f71\u54cd\u8fdc\u5927\u4e8e\u7528\u6237\u753b\u50cf\u3002\u56e0\u6b64\uff0c\u5728\u5fc3\u7406\u5065\u5eb7\u5e94\u7528\u573a\u666f\u4e0b\u9700\u8c28\u614e\u9009\u62e9LLM\u4ee5\u786e\u4fdd\u5408\u9002\u7684\u60c5\u611f\u56de\u5e94\u3002"}}
{"id": "2508.11290", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11290", "abs": "https://arxiv.org/abs/2508.11290", "authors": ["Utsav Maskey", "Sumit Yadav", "Mark Dras", "Usman Naseem"], "title": "SafeConstellations: Steering LLM Safety to Reduce Over-Refusals Through Task-Specific Trajectory", "comment": "Preprint", "summary": "LLMs increasingly exhibit over-refusal behavior, where safety mechanisms\ncause models to reject benign instructions that superficially resemble harmful\ncontent. This phenomena diminishes utility in production applications that\nrepeatedly rely on common prompt templates or applications that frequently rely\non LLMs for specific tasks (e.g. sentiment analysis, language translation).\nThrough comprehensive evaluation, we demonstrate that LLMs still tend to refuse\nresponses to harmful instructions when those instructions are reframed to\nappear as benign tasks. Our mechanistic analysis reveal that LLMs follow\ndistinct \"constellation\" patterns in embedding space as representations\ntraverse layers, with each task maintaining consistent trajectories that shift\npredictably between refusal and non-refusal cases. We introduce\nSafeConstellations, an inference-time trajectory-shifting approach that tracks\ntask-specific trajectory patterns and guides representations toward non-refusal\npathways. By selectively guiding model behavior only on tasks prone to\nover-refusal, and by preserving general model behavior, our method reduces\nover-refusal rates by up to 73% with minimal impact on utility-offering a\nprincipled approach to mitigating over-refusals.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSafeConstellations\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ffd\u8e2a\u5e76\u5f15\u5bfc\u5d4c\u5165\u7a7a\u95f4\u8f68\u8ff9\uff0c\u6709\u6548\u51cf\u5c11\u5927\u6a21\u578b\u5bf9\u5b9e\u9645\u65e0\u5bb3\u4efb\u52a1\u7684\u8fc7\u5ea6\u62d2\u7edd\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u5b9e\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u5927\u6a21\u578b\u5728\u5b89\u5168\u673a\u5236\u9a71\u52a8\u4e0b\uff0c\u5e38\u5e38\u4f1a\u5bf9\u4e00\u4e9b\u770b\u4f3c\u53ef\u80fd\u6709\u5bb3\u4f46\u5b9e\u9645\u65e0\u5bb3\u7684\u6307\u4ee4\u8fc7\u5ea6\u62d2\u7edd\u3002\u8fd9\u79cd\u73b0\u8c61\u5f71\u54cd\u4e86\u5b9e\u9645\u5e94\u7528\u7684\u6548\u7528\uff0c\u5c24\u5176\u662f\u5728\u91cd\u590d\u4f9d\u8d56\u5e38\u89c1\u63d0\u793a\u6a21\u677f\u6216\u7279\u5b9a\u4efb\u52a1\uff08\u5982\u60c5\u611f\u5206\u6790\u3001\u7ffb\u8bd1\u7b49\uff09\u7684\u573a\u666f\u4e0b\u3002", "method": "\u901a\u8fc7\u5168\u9762\u8bc4\u4f30\uff0c\u5206\u6790\u5927\u6a21\u578b\u5728\u9762\u5bf9\u7ecf\u8fc7\u6539\u5199\u7684\u6307\u4ee4\u65f6\u7684\u62d2\u7edd\u884c\u4e3a\uff0c\u5e76\u5728\u673a\u5236\u5c42\u9762\u5206\u6790\u6a21\u578b\u7684\u5d4c\u5165\u7a7a\u95f4\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u62d2\u7edd\u548c\u975e\u62d2\u7edd\u65f6\u5448\u73b0\u51fa\u7a33\u5b9a\u7684\u201c\u661f\u5ea7\u201d\u5f0f\u7279\u5f81\u8f68\u8ff9\u3002\u63d0\u51faSafeConstellations\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u63a8\u7406\u65f6\u8ddf\u8e2a\u4efb\u52a1\u7279\u5b9a\u7684\u8f68\u8ff9\u6a21\u5f0f\uff0c\u5f15\u5bfc\u6a21\u578b\u5448\u73b0\u975e\u62d2\u7edd\u7684\u54cd\u5e94\u8def\u5f84\uff0c\u4ec5\u5728\u6613\u4e8e\u8fc7\u5ea6\u62d2\u7edd\u7684\u4efb\u52a1\u4e0a\u8fdb\u884c\u5e72\u9884\uff0c\u4fdd\u6301\u6a21\u578b\u6574\u4f53\u884c\u4e3a\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u51cf\u5c11\u5927\u6a21\u578b\u7684\u8fc7\u5ea6\u62d2\u7edd\u73b0\u8c61\uff0c\u6700\u9ad8\u53ef\u964d\u4f4e73%\uff0c\u540c\u65f6\u5bf9\u603b\u4f53\u5b9e\u7528\u6027\u5f71\u54cd\u6781\u5c0f\u3002", "conclusion": "SafeConstellations\u65b9\u6cd5\u4e3a\u7f13\u89e3\u5927\u6a21\u578b\u8fc7\u5ea6\u62d2\u7edd\u95ee\u9898\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u3001\u6709\u6548\u7684\u65b0\u601d\u8def\uff0c\u65e2\u4fdd\u969c\u5b89\u5168\u6027\uff0c\u53c8\u63d0\u5347\u4e86\u5b9e\u9645\u5e94\u7528\u6548\u7528\u3002"}}
{"id": "2508.11310", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.11310", "abs": "https://arxiv.org/abs/2508.11310", "authors": ["Beichen Guo", "Zhiyuan Wen", "Yu Yang", "Peng Gao", "Ruosong Yang", "Jiaxing Shen"], "title": "SGSimEval: A Comprehensive Multifaceted and Similarity-Enhanced Benchmark for Automatic Survey Generation Systems", "comment": "Accepted to The 21st International Conference on Advanced Data Mining\n  and Applications (ADMA2025)", "summary": "The growing interest in automatic survey generation (ASG), a task that\ntraditionally required considerable time and effort, has been spurred by recent\nadvances in large language models (LLMs). With advancements in\nretrieval-augmented generation (RAG) and the rising popularity of multi-agent\nsystems (MASs), synthesizing academic surveys using LLMs has become a viable\napproach, thereby elevating the need for robust evaluation methods in this\ndomain. However, existing evaluation methods suffer from several limitations,\nincluding biased metrics, a lack of human preference, and an over-reliance on\nLLMs-as-judges. To address these challenges, we propose SGSimEval, a\ncomprehensive benchmark for Survey Generation with Similarity-Enhanced\nEvaluation that evaluates automatic survey generation systems by integrating\nassessments of the outline, content, and references, and also combines\nLLM-based scoring with quantitative metrics to provide a multifaceted\nevaluation framework. In SGSimEval, we also introduce human preference metrics\nthat emphasize both inherent quality and similarity to humans. Extensive\nexperiments reveal that current ASG systems demonstrate human-comparable\nsuperiority in outline generation, while showing significant room for\nimprovement in content and reference generation, and our evaluation metrics\nmaintain strong consistency with human assessments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9488\u5bf9\u81ea\u52a8\u7efc\u8ff0\u751f\u6210\u7684\u65b0\u578b\u591a\u7ef4\u8bc4\u4ef7\u57fa\u51c6SGSimEval\uff0c\u901a\u8fc7\u878d\u5408LLM\u4e0e\u91cf\u5316\u6307\u6807\u3001\u5f15\u5165\u4eba\u7c7b\u504f\u597d\uff0c\u66f4\u79d1\u5b66\u5730\u8bc4\u4ef7ASG\u7cfb\u7edf\u3002\u5b9e\u9a8c\u8bc1\u5b9eASG\u7684\u5927\u7eb2\u751f\u6210\u5df2\u9ad8\u5ea6\u63a5\u8fd1\u4eba\u7c7b\uff0c\u5185\u5bb9\u4e0e\u53c2\u8003\u90e8\u5206\u4ecd\u9700\u63d0\u5347\uff0cSGSimEval\u8bc4\u4f30\u7ed3\u679c\u9ad8\u5ea6\u8d34\u8fd1\u771f\u5b9e\u4eba\u7c7b\u5224\u65ad\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u7efc\u8ff0\u751f\u6210(ASG)\u5de5\u4f5c\u56e0\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u53ca\u5176\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u3001\u591a\u667a\u80fd\u4f53\u7cfb\u7edf(MASs)\u53d1\u5c55\u800c\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u73b0\u6709\u8bc4\u4ef7\u65b9\u6cd5\u5b58\u5728\u8bf8\u591a\u5c40\u9650\uff0c\u5982\u504f\u89c1\u6307\u6807\u3001\u7f3a\u4e4f\u4eba\u7c7b\u504f\u597d\u8003\u91cf\u4e14\u8fc7\u5ea6\u4f9d\u8d56LLMs\u5224\u522b\u3002\u4e9f\u9700\u79d1\u5b66\u3001\u5168\u9762\u7684\u65b0\u578b\u8bc4\u4ef7\u4f53\u7cfb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u5957\u7efc\u5408\u57fa\u51c6SGSimEval\uff0c\u901a\u8fc7\u878d\u5408\u5927\u7eb2\u3001\u5185\u5bb9\u53ca\u53c2\u8003\u6587\u732e\u591a\u7ef4\u5ea6\u8bc4\u4ef7\uff0c\u5c06LLM\u8bc4\u5206\u4e0e\u91cf\u5316\u6307\u6807\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u591a\u5c42\u6b21\u7efc\u5408\u8bc4\u4f30\u3002SGSimEval\u8fd8\u521b\u65b0\u6027\u5730\u5f15\u5165\u4eba\u7c7b\u504f\u597d\u6307\u6807\uff0c\u5f3a\u8c03\u7cfb\u7edf\u56fa\u6709\u8d28\u91cf\u4e0e\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u76f8\u4f3c\u6027\u3002", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\uff0c\u73b0\u6709ASG\u7cfb\u7edf\u5728\u5927\u7eb2\u751f\u6210\u65b9\u9762\u5df2\u5177\u5907\u4e0e\u4eba\u7c7b\u76f8\u5f53\u751a\u81f3\u4f18\u8d8a\u6c34\u5e73\uff0c\u4f46\u5185\u5bb9\u548c\u53c2\u8003\u6587\u732e\u751f\u6210\u90e8\u5206\u4f9d\u7136\u6709\u8f83\u5927\u63d0\u5347\u7a7a\u95f4\u3002SGSimEval\u8bc4\u4ef7\u7ed3\u679c\u4e0e\u771f\u5b9e\u4eba\u7c7b\u8bc4\u4f30\u6709\u9ad8\u5ea6\u4e00\u81f4\u6027\u3002", "conclusion": "SGSimEval\u4e3a\u81ea\u52a8\u7efc\u8ff0\u751f\u6210\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u3001\u53ef\u9760\u7684\u8bc4\u4ef7\u65b0\u8303\u5f0f\uff0c\u4fc3\u8fdb\u8be5\u9886\u57df\u6280\u672f\u66f4\u79d1\u5b66\u7684\u53d1\u5c55\u3002\u672a\u6765ASG\u7cfb\u7edf\u5e94\u91cd\u70b9\u63d0\u5347\u5185\u5bb9\u4e0e\u53c2\u8003\u90e8\u5206\u7684\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2508.11318", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11318", "abs": "https://arxiv.org/abs/2508.11318", "authors": ["Sahil Sk", "Debasish Dhal", "Sonal Khosla", "Sk Shahid", "Sambit Shekhar", "Akash Dhaka", "Shantipriya Parida", "Dilip K. Prasad", "Ond\u0159ej Bojar"], "title": "LLM Compression: How Far Can We Go in Balancing Size and Performance?", "comment": "This paper has been accepted for presentation at the RANLP 2025\n  conference", "summary": "Quantization is an essential and popular technique for improving the\naccessibility of large language models (LLMs) by reducing memory usage and\ncomputational costs while maintaining performance. In this study, we apply\n4-bit Group Scaling Quantization (GSQ) and Generative Pretrained Transformer\nQuantization (GPTQ) to LLaMA 1B, Qwen 0.5B, and PHI 1.5B, evaluating their\nimpact across multiple NLP tasks. We benchmark these models on MS MARCO\n(Information Retrieval), BoolQ (Boolean Question Answering), and GSM8K\n(Mathematical Reasoning) datasets, assessing both accuracy and efficiency\nacross various tasks. The study measures the trade-offs between model\ncompression and task performance, analyzing key evaluation metrics, namely\naccuracy, inference latency, and throughput (total output tokens generated per\nsecond), providing insights into the suitability of low-bit quantization for\nreal-world deployment. Using the results, users can then make suitable\ndecisions based on the specifications that need to be met. We discuss the pros\nand cons of GSQ and GPTQ techniques on models of different sizes, which also\nserve as a benchmark for future experiments.", "AI": {"tldr": "\u672c\u6587\u5b9e\u8bc1\u5bf9\u6bd4\u4e86GSQ\u548cGPTQ\u4e24\u79cd\u91cf\u5316\u6280\u672f\u5728\u4e09\u79cd\u4e3b\u6d41\u5c0f\u578bLLM\u6a21\u578b\u4e0a\u7684\u8868\u73b0\uff0c\u6db5\u76d6\u4fe1\u606f\u68c0\u7d22\u3001\u95ee\u7b54\u548c\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u3002\u7ed3\u679c\u663e\u793a\uff0c4-bit\u91cf\u5316\u65b9\u6848\u80fd\u660e\u663e\u63d0\u5347\u63a8\u7406\u6548\u7387\u5e76\u5728\u7cbe\u5ea6\u635f\u5931\u53ef\u63a7\u8303\u56f4\u5185\uff0c\u6709\u6548\u63d0\u5347\u5b9e\u9645\u90e8\u7f72\u7684\u53ef\u884c\u6027\u3002\u4f5c\u8005\u8fd8\u5206\u6790\u4e86\u4e0d\u540c\u91cf\u5316\u65b9\u6cd5\u548c\u6a21\u578b\u5927\u5c0f\u7684\u4f18\u7f3a\u70b9\uff0c\u4e3a\u7528\u6237\u548c\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u91cf\u5316\u6280\u672f\u53ef\u4ee5\u6709\u6548\u964d\u4f4e\u5927\u6a21\u578b\u7684\u5b58\u50a8\u4e0e\u8ba1\u7b97\u6210\u672c\uff0c\u4f46\u5728\u4e0d\u540c\u4efb\u52a1\u4e0a\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u5c1a\u9700\u6df1\u5165\u8bc4\u4f30\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u6a21\u578b\u538b\u7f29\u4e0e\u6027\u80fd\u6743\u8861\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u5c064-bit Group Scaling Quantization\uff08GSQ\uff09\u548cGenerative Pretrained Transformer Quantization\uff08GPTQ\uff09\u5206\u522b\u5e94\u7528\u4e8eLLaMA 1B\u3001Qwen 0.5B\u3001PHI 1.5B\u4e09\u79cd\u6a21\u578b\uff0c\u5e76\u5728MS MARCO\uff08\u4fe1\u606f\u68c0\u7d22\uff09\u3001BoolQ\uff08\u5e03\u5c14\u95ee\u7b54\uff09\u3001GSM8K\uff08\u6570\u5b66\u63a8\u7406\uff09\u4e09\u7c7b\u4efb\u52a1\u4e0a\u6d4b\u8bd5\u5176\u51c6\u786e\u7387\u3001\u63a8\u7406\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u3002", "result": "\u4f4e\u6bd4\u7279\u91cf\u5316\uff08GSQ\u548cGPTQ\uff09\u5728\u4fdd\u8bc1\u6a21\u578b\u6027\u80fd\u57fa\u672c\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6548\u7387\uff08\u5305\u62ec\u63a8\u7406\u901f\u5ea6\u548c\u8f93\u51fa\u541e\u5410\u91cf\uff09\uff0c\u4f46\u4e0d\u540c\u91cf\u5316\u65b9\u6cd5\u4e0e\u6a21\u578b\u5927\u5c0f\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u591a\u79cd\u4f4e\u6bd4\u7279\u91cf\u5316\u65b9\u6cd5\u53ca\u6a21\u578b\u8fdb\u884c\u5168\u9762\u8bc4\u6d4b\uff0c\u672c\u6587\u4e3a\u771f\u5b9e\u573a\u666f\u4e0b\u91cf\u5316\u6a21\u578b\u7684\u9009\u62e9\u4e0e\u90e8\u7f72\u63d0\u4f9b\u4e86\u51b3\u7b56\u4f9d\u636e\uff0c\u5e76\u4e3a\u540e\u7eed\u76f8\u5173\u7814\u7a76\u5efa\u7acb\u4e86\u57fa\u51c6\u3002"}}
{"id": "2508.11343", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11343", "abs": "https://arxiv.org/abs/2508.11343", "authors": ["Haitong Luo", "Weiyao Zhang", "Suhang Wang", "Wenji Zou", "Chungang Lin", "Xuying Meng", "Yujun Zhang"], "title": "SpecDetect: Simple, Fast, and Training-Free Detection of LLM-Generated Text via Spectral Analysis", "comment": "Under Review", "summary": "The proliferation of high-quality text from Large Language Models (LLMs)\ndemands reliable and efficient detection methods. While existing training-free\napproaches show promise, they often rely on surface-level statistics and\noverlook fundamental signal properties of the text generation process. In this\nwork, we reframe detection as a signal processing problem, introducing a novel\nparadigm that analyzes the sequence of token log-probabilities in the frequency\ndomain. By systematically analyzing the signal's spectral properties using the\nglobal Discrete Fourier Transform (DFT) and the local Short-Time Fourier\nTransform (STFT), we find that human-written text consistently exhibits\nsignificantly higher spectral energy. This higher energy reflects the\nlarger-amplitude fluctuations inherent in human writing compared to the\nsuppressed dynamics of LLM-generated text. Based on this key insight, we\nconstruct SpecDetect, a detector built on a single, robust feature from the\nglobal DFT: DFT total energy. We also propose an enhanced version,\nSpecDetect++, which incorporates a sampling discrepancy mechanism to further\nboost robustness. Extensive experiments demonstrate that our approach\noutperforms the state-of-the-art model while running in nearly half the time.\nOur work introduces a new, efficient, and interpretable pathway for\nLLM-generated text detection, showing that classical signal processing\ntechniques offer a surprisingly powerful solution to this modern challenge.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u5085\u91cc\u53f6\u53d8\u6362\u5206\u6790\u6587\u672ctoken\u6982\u7387\u5e8f\u5217\uff0c\u521b\u65b0\u6027\u5730\u5c06\u68c0\u6d4b\u95ee\u9898\u8f6c\u5316\u4e3a\u4fe1\u53f7\u80fd\u91cf\u5224\u522b\uff0c\u4eba\u7c7b\u5199\u4f5c\u9891\u8c31\u80fd\u91cf\u663e\u8457\u9ad8\u4e8eLLM\u751f\u6210\u6587\u672c\u3002\u57fa\u4e8e\u6b64\uff0c\u8bbe\u8ba1\u7684\u68c0\u6d4b\u5668\u5728\u51c6\u786e\u7387\u53ca\u901f\u5ea6\u4e0a\u5747\u8d85\u8d8a\u73b0\u6709\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u4fe1\u53f7\u5904\u7406\u65b9\u6cd5\u7684\u5f3a\u5927\u6f5c\u529b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u9ad8\u8d28\u91cf\u6587\u672c\u65e5\u76ca\u666e\u904d\uff0c\u4e9f\u9700\u9ad8\u6548\u3001\u53ef\u9760\u7684\u81ea\u52a8\u68c0\u6d4b\u65b9\u6cd5\u3002\u73b0\u6709\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\u591a\u4f9d\u8d56\u8868\u5c42\u7edf\u8ba1\u7279\u5f81\uff0c\u5ffd\u7565\u4e86\u6587\u672c\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u6839\u672c\u4fe1\u53f7\u5c5e\u6027\u3002", "method": "\u5c06\u6587\u672c\u68c0\u6d4b\u95ee\u9898\u8f6c\u5316\u4e3a\u4fe1\u53f7\u5904\u7406\u95ee\u9898\uff0c\u5229\u7528\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\uff08DFT\uff09\u548c\u77ed\u65f6\u5085\u91cc\u53f6\u53d8\u6362\uff08STFT\uff09\u5206\u6790token\u5bf9\u6570\u6982\u7387\u5e8f\u5217\u7684\u9891\u8c31\u7279\u6027\uff0c\u5e76\u6784\u5efa\u57fa\u4e8e\u5168\u5c40DFT\u603b\u80fd\u91cf\u7279\u5f81\u7684\u68c0\u6d4b\u5668SpecDetect\uff0c\u540c\u65f6\u63d0\u51fa\u5305\u542b\u91c7\u6837\u5dee\u5f02\u673a\u5236\u7684\u52a0\u5f3a\u7248SpecDetect++\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u91c7\u7528\u9891\u57df\u4fe1\u53f7\u80fd\u91cf\u7279\u5f81\u7684\u68c0\u6d4b\u65b9\u6cd5\u4e0d\u4ec5\u4f18\u4e8e\u76ee\u524d\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u5e76\u4e14\u901f\u5ea6\u63d0\u5347\u8fd1\u4e00\u500d\u3002SpecDetect\u53ca\u5176\u589e\u5f3a\u7248\u5177\u5907\u9ad8\u6548\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u5c06\u4f20\u7edf\u4fe1\u53f7\u5904\u7406\u6280\u672f\u5e94\u7528\u4e8eLLM\u6587\u672c\u68c0\u6d4b\uff0c\u4e3aAI\u5199\u4f5c\u5224\u522b\u5e26\u6765\u9ad8\u6548\u3001\u76f4\u89c2\u7684\u65b0\u65b9\u6848\u3002\u9891\u57df\u80fd\u91cf\u7279\u5f81\u5728\u533a\u5206\u4eba\u7c7b\u4e0eLLM\u751f\u6210\u6587\u672c\u65b9\u9762\u975e\u5e38\u6709\u6548\u3002"}}
{"id": "2508.11364", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11364", "abs": "https://arxiv.org/abs/2508.11364", "authors": ["Sylvio R\u00fcdian", "Yassin Elsir", "Marvin Kretschmer", "Sabine Cayrou", "Niels Pinkwart"], "title": "Feedback Indicators: The Alignment between Llama and a Teacher in Language Learning", "comment": "11 pages, one table", "summary": "Automated feedback generation has the potential to enhance students' learning\nprogress by providing timely and targeted feedback. Moreover, it can assist\nteachers in optimizing their time, allowing them to focus on more strategic and\npersonalized aspects of teaching. To generate high-quality, information-rich\nformative feedback, it is essential first to extract relevant indicators, as\nthese serve as the foundation upon which the feedback is constructed. Teachers\noften employ feedback criteria grids composed of various indicators that they\nevaluate systematically. This study examines the initial phase of extracting\nsuch indicators from students' submissions of a language learning course using\nthe large language model Llama 3.1. Accordingly, the alignment between\nindicators generated by the LLM and human ratings across various feedback\ncriteria is investigated. The findings demonstrate statistically significant\nstrong correlations, even in cases involving unanticipated combinations of\nindicators and criteria. The methodology employed in this paper offers a\npromising foundation for extracting indicators from students' submissions using\nLLMs. Such indicators can potentially be utilized to auto-generate explainable\nand transparent formative feedback in future research.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528Llama 3.1\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u5b66\u751f\u63d0\u4ea4\u7684\u8bed\u8a00\u5b66\u4e60\u4f5c\u4e1a\u4e2d\u81ea\u52a8\u63d0\u53d6\u53cd\u9988\u6307\u6807\uff0c\u7ed3\u679c\u8868\u660eLLM\u751f\u6210\u7684\u6307\u6807\u4e0e\u4eba\u5de5\u8bc4\u5206\u6709\u5f88\u9ad8\u76f8\u5173\u6027\uff0c\u4e3a\u672a\u6765\u81ea\u52a8\u751f\u6210\u53ef\u89e3\u91ca\u3001\u900f\u660e\u53cd\u9988\u63d0\u4f9b\u4e86\u6709\u529b\u57fa\u7840\u3002", "motivation": "\u81ea\u52a8\u5316\u53cd\u9988\u6709\u52a9\u4e8e\u63d0\u5347\u5b66\u751f\u5b66\u4e60\u8fdb\u5ea6\u548c\u6559\u5e08\u6559\u5b66\u6548\u80fd\uff0c\u4f46\u751f\u6210\u9ad8\u8d28\u91cf\u53cd\u9988\u9700\u8981\u5148\u4ece\u5b66\u751f\u63d0\u4ea4\u7684\u4f5c\u4e1a\u4e2d\u63d0\u53d6\u76f8\u5173\u6307\u6807\u3002\u6559\u5e08\u5e38\u7528\u53cd\u9988\u6807\u51c6\u7f51\u683c\uff0c\u4f46\u63d0\u53d6\u6307\u6807\u8fc7\u7a0b\u8d39\u65f6\u3002\u8be5\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u63d0\u53d6\u8bed\u8a00\u5b66\u4e60\u8bfe\u7a0b\u4e2d\u5b66\u751f\u63d0\u4ea4\u4f5c\u4e1a\u7684\u53cd\u9988\u6307\u6807\u7684\u53ef\u884c\u6027\u3002", "method": "\u4f7f\u7528Llama 3.1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4ece\u5b66\u751f\u8bed\u8a00\u5b66\u4e60\u4f5c\u4e1a\u4e2d\u81ea\u52a8\u63d0\u53d6\u53cd\u9988\u6307\u6807\uff0c\u5e76\u4e0e\u4eba\u5de5\u8bc4\u5206\u5bf9\u8fd9\u4e9b\u6307\u6807\u7684\u5951\u5408\u5ea6\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002\u91cd\u70b9\u8003\u5bdfLLM\u751f\u6210\u6307\u6807\u4e0e\u4eba\u5de5\u8bc4\u5b9a\u5728\u591a\u79cd\u53cd\u9988\u6807\u51c6\u4e0a\u7684\u4e00\u81f4\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0cLLM\u81ea\u52a8\u63d0\u53d6\u7684\u6307\u6807\u4e0e\u4eba\u5de5\u8bc4\u5206\u7684\u76f8\u5173\u6027\u663e\u8457\u4e14\u8f83\u5f3a\uff0c\u5373\u4f7f\u5b58\u5728\u4e00\u4e9b\u672a\u9884\u6599\u7684\u6307\u6807\u4e0e\u6807\u51c6\u7ec4\u5408\uff0c\u4e5f\u80fd\u591f\u4fdd\u6301\u8f83\u9ad8\u4e00\u81f4\u6027\u3002", "conclusion": "\u7528LLM\u81ea\u52a8\u4ece\u5b66\u751f\u63d0\u4ea4\u4e2d\u63d0\u53d6\u53cd\u9988\u6307\u6807\u5728\u6280\u672f\u4e0a\u53ef\u884c\uff0c\u5e76\u80fd\u663e\u8457\u63d0\u5347\u53cd\u9988\u6548\u7387\u53ca\u900f\u660e\u5ea6\u3002\u6b64\u65b9\u6cd5\u53ef\u4e3a\u81ea\u52a8\u751f\u6210\u53ef\u89e3\u91ca\u3001\u900f\u660e\u7684\u5f62\u6210\u6027\u53cd\u9988\u5960\u5b9a\u57fa\u7840\u3002\u672a\u6765\u7814\u7a76\u53ef\u8fdb\u4e00\u6b65\u5c06\u81ea\u52a8\u63d0\u53d6\u7684\u6307\u6807\u7528\u4e8e\u9ad8\u8d28\u91cf\u53cd\u9988\u751f\u6210\u3002"}}
{"id": "2508.11383", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11383", "abs": "https://arxiv.org/abs/2508.11383", "authors": ["Mikhail Seleznyov", "Mikhail Chaichuk", "Gleb Ershov", "Alexander Panchenko", "Elena Tutubalina", "Oleg Somov"], "title": "When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs", "comment": null, "summary": "Large Language Models (LLMs) are highly sensitive to subtle, non-semantic\nvariations in prompt phrasing and formatting. In this work, we present the\nfirst systematic evaluation of 5 methods for improving prompt robustness within\na unified experimental framework. We benchmark these techniques on 8 models\nfrom Llama, Qwen and Gemma families across 52 tasks from Natural Instructions\ndataset. Our evaluation covers robustness methods from both fine-tuned and\nin-context learning paradigms, and tests their generalization against multiple\ntypes of distribution shifts. Finally, we extend our analysis to GPT-4.1 and\nDeepSeek V3 to assess frontier models' current robustness to format\nperturbations. Our findings offer actionable insights into the relative\neffectiveness of these robustness methods, enabling practitioners to make\ninformed decisions when aiming for stable and reliable LLM performance in\nreal-world applications. Code:\nhttps://github.com/AIRI-Institute/when-punctuation-matters.", "AI": {"tldr": "\u9996\u6b21\u7cfb\u7edf\u5bf9\u6bd45\u79cd\u63d0\u793a\u9c81\u68d2\u6027\u589e\u5f3a\u65b9\u6cd5\uff0c\u5168\u9762\u8bc4\u6d4b\u4e3b\u6d41\u5927\u6a21\u578b\u572852\u9879\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u5206\u6790\u524d\u6cbf\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u7ed3\u679c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u63d0\u5347\u6a21\u578b\u7a33\u5b9a\u6027\u63d0\u4f9b\u5b9e\u7528\u53c2\u8003\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5bf9\u63d0\u793a\u8bcd\u63aa\u8f9e\u548c\u683c\u5f0f\u7684\u7ec6\u5fae\u3001\u975e\u8bed\u4e49\u53d8\u5316\u9ad8\u5ea6\u654f\u611f\uff0c\u5f71\u54cd\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u7684\u7a33\u5b9a\u6027\u548c\u53ef\u9760\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6709\u5fc5\u8981\u7cfb\u7edf\u8bc4\u4f30\u63d0\u5347\u6a21\u578b\u63d0\u793a\u9c81\u68d2\u6027\u7684\u591a\u79cd\u65b9\u6cd5\u3002", "method": "\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e865\u79cd\u7528\u4e8e\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u9c81\u68d2\u6027\u7684\u65b9\u6cd5\uff0c\u5728\u7edf\u4e00\u7684\u5b9e\u9a8c\u6846\u67b6\u4e0b\u8fdb\u884c\u3002\u8bc4\u6d4b\u8986\u76d6Llama\u3001Qwen \u548c Gemma \u7b498\u4e2a\u6a21\u578b\uff0c\u4efb\u52a1\u6765\u81eaNatural Instructions \u6570\u636e\u96c6\u517152\u9879\uff0c\u6bd4\u8f83\u4e86\u5fae\u8c03\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e24\u5927\u8303\u5f0f\u4e0b\u9c81\u68d2\u6027\u65b9\u6cd5\uff0c\u5e76\u5bf9\u5206\u5e03\u504f\u79fb\u7684\u591a\u79cd\u60c5\u51b5\u8fdb\u884c\u4e86\u6cdb\u5316\u6d4b\u8bd5\u3002\u6b64\u5916\uff0c\u8fd8\u6269\u5c55\u5230\u4e86GPT-4.1\u548cDeepSeek V3\u524d\u6cbf\u6a21\u578b\uff0c\u7528\u4e8e\u6d4b\u8bd5\u5b83\u4eec\u5bf9\u683c\u5f0f\u6270\u52a8\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5bf9\u63d0\u5347\u63d0\u793a\u9c81\u68d2\u6027\u76845\u79cd\u65b9\u6cd5\u5728\u4e0d\u540c\u6a21\u578b\u548c\u4efb\u52a1\u4e0a\u7684\u6548\u679c\u8fdb\u884c\u4e86\u7cfb\u7edf\u6bd4\u8f83\uff0c\u5206\u6790\u7ed3\u679c\u63ed\u793a\u4e86\u5404\u79cd\u65b9\u6cd5\u5728\u9762\u5bf9\u683c\u5f0f\u6270\u52a8\u548c\u5206\u5e03\u504f\u79fb\u65f6\u7684\u76f8\u5bf9\u6709\u6548\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5b9e\u8bc1\u53c2\u8003\u3002", "conclusion": "\u4e0d\u540c\u7684\u9c81\u68d2\u6027\u63d0\u5347\u65b9\u6cd5\u5728\u5927\u8bed\u8a00\u6a21\u578b\u95f4\u8868\u73b0\u5404\u5f02\uff0c\u7814\u7a76\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u63d0\u5347LLM\u7a33\u5b9a\u6027\u548c\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u6709\u6307\u5bfc\u6027\u7684\u5efa\u8bae\u3002"}}
{"id": "2508.11386", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.11386", "abs": "https://arxiv.org/abs/2508.11386", "authors": ["Ryan Sze-Yin Chan", "Federico Nanni", "Tomas Lazauskas", "Rosie Wood", "Penelope Yong", "Lionel Tarassenko", "Mark Girolami", "James Geddes", "Andrew Duncan"], "title": "Retrieval-augmented reasoning with lean language models", "comment": null, "summary": "This technical report details a novel approach to combining reasoning and\nretrieval augmented generation (RAG) within a single, lean language model\narchitecture. While existing RAG systems typically rely on large-scale models\nand external APIs, our work addresses the increasing demand for performant and\nprivacy-preserving solutions deployable in resource-constrained or secure\nenvironments. Building on recent developments in test-time scaling and\nsmall-scale reasoning models, we develop a retrieval augmented conversational\nagent capable of interpreting complex, domain-specific queries using a\nlightweight backbone model. Our system integrates a dense retriever with\nfine-tuned Qwen2.5-Instruct models, using synthetic query generation and\nreasoning traces derived from frontier models (e.g., DeepSeek-R1) over a\ncurated corpus, in this case, the NHS A-to-Z condition pages. We explore the\nimpact of summarisation-based document compression, synthetic data design, and\nreasoning-aware fine-tuning on model performance. Evaluation against both\nnon-reasoning and general-purpose lean models demonstrates that our\ndomain-specific fine-tuning approach yields substantial gains in answer\naccuracy and consistency, approaching frontier-level performance while\nremaining feasible for local deployment. All implementation details and code\nare publicly released to support reproducibility and adaptation across domains.", "AI": {"tldr": "\u4f5c\u8005\u5f00\u53d1\u4e86\u4e00\u79cd\u9002\u5408\u672c\u5730\u90e8\u7f72\u7684\u8f7b\u91cf\u7ea7RAG\u7cfb\u7edf\uff0c\u901a\u8fc7\u7279\u5b9a\u9886\u57df\u5fae\u8c03\u548c\u63a8\u7406\u589e\u5f3a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5c0f\u6a21\u578b\u5728\u4e13\u7528\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4e14\u5168\u90e8\u4ee3\u7801\u5f00\u653e\uff0c\u6613\u4e8e\u5176\u4ed6\u9886\u57df\u590d\u7528\u3002", "motivation": "\u73b0\u6709\u7684RAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09\u7cfb\u7edf\u901a\u5e38\u4f9d\u8d56\u4e8e\u5927\u89c4\u6a21\u6a21\u578b\u548c\u5916\u90e8API\uff0c\u8fd9\u5bfc\u81f4\u96be\u4ee5\u5728\u8d44\u6e90\u6709\u9650\u6216\u5bf9\u9690\u79c1\u6709\u9ad8\u8981\u6c42\u7684\u73af\u5883\u4e2d\u90e8\u7f72\u9ad8\u6548\u4e14\u5b89\u5168\u7684\u751f\u6210\u7cfb\u7edf\u3002\u4f5c\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u65e2\u9ad8\u6548\u53c8\u6613\u4e8e\u672c\u5730\u90e8\u7f72\u7684RAG\u65b9\u6848\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e00\u4e2a\u65b0\u578b\u7cfb\u7edf\uff0c\u5c06\u7a20\u5bc6\u68c0\u7d22\u5668\u4e0e\u5fae\u8c03\u8fc7\u7684Qwen2.5-Instruct\u6a21\u578b\u7ed3\u5408\uff0c\u91c7\u7528\u4e86\u5408\u6210\u67e5\u8be2\u751f\u6210\u548c\u5229\u7528\u5148\u8fdb\u6a21\u578b\uff08\u5982DeepSeek-R1\uff09\u63a8\u7406\u8f68\u8ff9\u7684\u6280\u672f\uff0c\u57fa\u4e8e\u7279\u5b9a\u9886\u57df\u8bed\u6599\u5e93\uff08NHS\u7684A-Z\u75be\u75c5\u9875\u9762\uff09\u8fdb\u884c\u8bad\u7ec3\u3002\u8fd8\u7814\u7a76\u6587\u6863\u538b\u7f29\u3001\u5408\u6210\u6570\u636e\u8bbe\u8ba1\u548c\u5f15\u5165\u63a8\u7406\u80fd\u529b\u7ec6\u81f4\u5fae\u8c03\u5bf9\u6a21\u578b\u8868\u73b0\u7684\u5f71\u54cd\u3002", "result": "\u901a\u8fc7\u9488\u5bf9\u7279\u5b9a\u9886\u57df\u7684\u7ec6\u81f4\u5fae\u8c03\uff0c\u6a21\u578b\u5728\u56de\u7b54\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u65b9\u9762\u663e\u8457\u8d85\u8fc7\u4f20\u7edf\u65e0\u63a8\u7406\u6216\u901a\u7528\u5c0f\u6a21\u578b\uff0c\u63a5\u8fd1\u5f53\u524d\u5148\u8fdb\uff08frontier\uff09\u6a21\u578b\u7684\u8868\u73b0\uff0c\u540c\u65f6\u4ecd\u9002\u5408\u672c\u5730\u90e8\u7f72\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8bc1\u660e\uff0c\u57fa\u4e8e\u6539\u8fdb\u7684\u68c0\u7d22\u589e\u5f3a\u548c\u63a8\u7406\u80fd\u529b\u7684\u5c0f\u578b\u6a21\u578b\u53ef\u4ee5\u5b9e\u73b0\u63a5\u8fd1\u524d\u6cbf\u6027\u80fd\uff0c\u5e76\u80fd\u5e94\u7528\u4e8e\u8d44\u6e90\u6709\u9650\u548c\u9ad8\u9690\u79c1\u8981\u6c42\u7684\u573a\u666f\uff0c\u76f8\u5173\u5b9e\u73b0\u7ec6\u8282\u5df2\u5168\u90e8\u516c\u5f00\uff0c\u652f\u6301\u8de8\u9886\u57df\u590d\u73b0\u548c\u63a8\u5e7f\u3002"}}
{"id": "2508.11388", "categories": ["cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.11388", "abs": "https://arxiv.org/abs/2508.11388", "authors": ["Marc Brinner", "Sina Zarriess"], "title": "Model Interpretability and Rationale Extraction by Input Mask Optimization", "comment": null, "summary": "Concurrent to the rapid progress in the development of neural-network based\nmodels in areas like natural language processing and computer vision, the need\nfor creating explanations for the predictions of these black-box models has\nrisen steadily. We propose a new method to generate extractive explanations for\npredictions made by neural networks, that is based on masking parts of the\ninput which the model does not consider to be indicative of the respective\nclass. The masking is done using gradient-based optimization combined with a\nnew regularization scheme that enforces sufficiency, comprehensiveness and\ncompactness of the generated explanation, three properties that are known to be\ndesirable from the related field of rationale extraction in natural language\nprocessing. In this way, we bridge the gap between model interpretability and\nrationale extraction, thereby proving that the latter of which can be performed\nwithout training a specialized model, only on the basis of a trained\nclassifier. We further apply the same method to image inputs and obtain high\nquality explanations for image classifications, which indicates that the\nconditions proposed for rationale extraction in natural language processing are\nmore broadly applicable to different input types.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u68af\u5ea6\u4f18\u5316\u4e0e\u6b63\u5219\u5316\u7684\u65b0\u578b\u89e3\u91ca\u751f\u6210\u65b9\u6cd5\uff0c\u80fd\u4e3a\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u7ed3\u679c\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u53ef\u63d0\u53d6\u89e3\u91ca\uff0c\u9002\u7528\u4e8e\u6587\u672c\u548c\u56fe\u50cf\u7b49\u591a\u79cd\u4efb\u52a1\uff0c\u63a8\u52a8\u4e86\u53ef\u89e3\u91ca\u6027\u4e0e\u63a8\u7406\u7247\u6bb5\u62bd\u53d6\u65b9\u6cd5\u7684\u878d\u5408\u3002", "motivation": "\u8fd1\u5e74\u6765\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u53d6\u5f97\u4e86\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u8fd9\u4e9b\u9ed1\u76d2\u6a21\u578b\u7684\u9884\u6d4b\u4e0d\u53ef\u89e3\u91ca\u6027\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u4e9f\u9700\u6709\u6548\u7684\u89e3\u91ca\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u68af\u5ea6\u4f18\u5316\u548c\u65b0\u7684\u6b63\u5219\u5316\u7b56\u7565\u7684\u63a9\u853d\u65b9\u6cd5\uff0c\u53ef\u4ee5\u63d0\u53d6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u9884\u6d4b\u7684\u53ef\u89e3\u91ca\u6027\u7247\u6bb5\uff0c\u4e0d\u9700\u5355\u72ec\u8bad\u7ec3\u89e3\u91ca\u6a21\u578b\uff0c\u4ec5\u4f9d\u8d56\u5df2\u6709\u5206\u7c7b\u5668\u3002\u6b63\u5219\u5316\u7b56\u7565\u786e\u4fdd\u89e3\u91ca\u5177\u5907\u5145\u5206\u6027\u3001\u5168\u9762\u6027\u548c\u7d27\u51d1\u6027\u8fd9\u4e09\u5927\u7279\u6027\u3002", "result": "\u6240\u63d0\u51fa\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u83b7\u5f97\u9ad8\u8d28\u91cf\u89e3\u91ca\uff0c\u8fd8\u6210\u529f\u5e94\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\uff0c\u663e\u793a\u8be5\u89e3\u91ca\u6846\u67b6\u5bf9\u4e0d\u540c\u8f93\u5165\u7c7b\u578b\u5747\u9002\u7528\u3002", "conclusion": "\u672c\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u89e3\u91ca\u6027\u7684\u540c\u65f6\uff0c\u9a8c\u8bc1\u4e86\u65e0\u9700\u4e13\u95e8\u8bad\u7ec3\u89e3\u91ca\u6a21\u578b\u5373\u53ef\u5b9e\u73b0\u9ad8\u8d28\u91cf\u89e3\u91ca\uff0c\u62d3\u5bbd\u4e86\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2508.11393", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.11393", "abs": "https://arxiv.org/abs/2508.11393", "authors": ["Marc Brinner", "Sina Zarrie\u00df"], "title": "Rationalizing Transformer Predictions via End-To-End Differentiable Self-Training", "comment": null, "summary": "We propose an end-to-end differentiable training paradigm for stable training\nof a rationalized transformer classifier. Our approach results in a single\nmodel that simultaneously classifies a sample and scores input tokens based on\ntheir relevance to the classification. To this end, we build on the widely-used\nthree-player-game for training rationalized models, which typically relies on\ntraining a rationale selector, a classifier and a complement classifier. We\nsimplify this approach by making a single model fulfill all three roles,\nleading to a more efficient training paradigm that is not susceptible to the\ncommon training instabilities that plague existing approaches. Further, we\nextend this paradigm to produce class-wise rationales while incorporating\nrecent advances in parameterizing and regularizing the resulting rationales,\nthus leading to substantially improved and state-of-the-art alignment with\nhuman annotations without any explicit supervision.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u7684Transformer\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7528\u4e00\u4e2a\u6a21\u578b\u540c\u65f6\u5b9e\u73b0\u5206\u7c7b\u4e0erationale\u8bc4\u5206\uff0c\u63d0\u5347\u4e86\u6548\u7387\u548c\u7a33\u5b9a\u6027\uff0c\u5e76\u5728\u65e0\u9700\u663e\u5f0f\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\u4e0e\u4eba\u7c7b\u6807\u6ce8\u8fbe\u5230\u4e86\u6700\u4f73\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u7684rationalized transformer\u6a21\u578b\u8bad\u7ec3\u4e0d\u7a33\u5b9a\uff0c\u4e14\u9700\u8981\u4e09\u4e2a\u6a21\u578b\u534f\u540c\u5de5\u4f5c\uff0c\u6d41\u7a0b\u590d\u6742\uff0c\u4e14\u96be\u4ee5\u4e0e\u4eba\u5de5\u6807\u6ce8\u4fdd\u6301\u4e00\u81f4\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7aef\u5230\u7aef\u53ef\u5fae\u5206\u7684\u8bad\u7ec3\u8303\u5f0f\uff0c\u8ba9\u5355\u4e00\u6a21\u578b\u540c\u65f6\u8fdb\u884c\u5206\u7c7b\u548c\u5bf9\u8f93\u5165token\u8fdb\u884c\u8bc4\u5206\uff0c\u5b9e\u73b0\u4e09\u9879\u4efb\u52a1\u7684\u7edf\u4e00\uff0c\u7b80\u5316\u8bad\u7ec3\u6d41\u7a0b\u3002\u540c\u65f6\u6539\u8fdbrationale\u53c2\u6570\u5316\u548c\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u4ee5\u652f\u6301\u7c7b\u522b\u522b\u7684rationale\u751f\u6210\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u7a33\u5b9a\u8bad\u7ec3\uff0c\u63d0\u5347\u8bad\u7ec3\u6548\u7387\uff0c\u5e76\u663e\u8457\u6539\u5584\u7ed3\u679c\u4e0e\u4eba\u5de5\u6807\u6ce8\u7684\u4e00\u81f4\u6027\uff0c\u8fbe\u5230\u4e86\u5f53\u524d\u6700\u4f18\u6c34\u5e73\uff0c\u65e0\u9700\u663e\u5f0f\u76d1\u7763\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u6a21\u578b\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u53ca\u4e0e\u4eba\u7c7b\u6807\u6ce8\u5bf9\u9f50\u96be\u7684\u95ee\u9898\uff0c\u4e14\u7b80\u5316\u4e86\u6574\u4e2a\u6a21\u578b\u7ed3\u6784\u548c\u6d41\u7a0b\u3002"}}
{"id": "2508.11414", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11414", "abs": "https://arxiv.org/abs/2508.11414", "authors": ["Shangrui Nie", "Florian Mai", "David Kacz\u00e9r", "Charles Welch", "Zhixue Zhao", "Lucie Flek"], "title": "Survey-to-Behavior: Downstream Alignment of Human Values in LLMs via Survey Questions", "comment": "7 pages 1 figure", "summary": "Large language models implicitly encode preferences over human values, yet\nsteering them often requires large training data. In this work, we investigate\na simple approach: Can we reliably modify a model's value system in downstream\nbehavior by training it to answer value survey questions accordingly? We first\nconstruct value profiles of several open-source LLMs by asking them to rate a\nseries of value-related descriptions spanning 20 distinct human values, which\nwe use as a baseline for subsequent experiments. We then investigate whether\nthe value system of a model can be governed by fine-tuning on the value\nsurveys. We evaluate the effect of finetuning on the model's behavior in two\nways; first, we assess how answers change on in-domain, held-out survey\nquestions. Second, we evaluate whether the model's behavior changes in\nout-of-domain settings (situational scenarios). To this end, we construct a\ncontextualized moral judgment dataset based on Reddit posts and evaluate\nchanges in the model's behavior in text-based adventure games. We demonstrate\nthat our simple approach can not only change the model's answers to in-domain\nsurvey questions, but also produces substantial shifts (value alignment) in\nimplicit downstream task behavior.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u4ef7\u503c\u89c2\u95ee\u5377\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u4ee5\u53ef\u9760\u6539\u53d8\u6a21\u578b\u7684\u4ef7\u503c\u4f53\u7cfb\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u6a21\u578b\u4e0d\u4ec5\u5728\u95ee\u5377\u56de\u7b54\u4e0a\u6709\u6240\u6539\u53d8\uff0c\u4e14\u5728\u5b9e\u9645\u60c5\u5883\u548c\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u76ee\u6807\u4ef7\u503c\u4e00\u81f4\u6027\u3002\u8fd9\u79cd\u7b80\u5355\u65b9\u6cd5\u80fd\u9ad8\u6548\u8c03\u63a7\u6a21\u578b\u4ef7\u503c\u89c2\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bad\u7ec3\u4e2d\u9690\u542b\u5730\u7f16\u7801\u4e86\u4eba\u7c7b\u4ef7\u503c\u89c2\uff0c\u4f46\u60f3\u8981\u6539\u53d8\u5176\u4ef7\u503c\u504f\u597d\u901a\u5e38\u9700\u8981\u5927\u91cf\u7684\u6570\u636e\u3002\u4f5c\u8005\u60f3\u63a2\u7a76\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u5730\u8bad\u7ec3\u6a21\u578b\u56de\u7b54\u4ef7\u503c\u89c2\u8c03\u67e5\u95ee\u5377\uff0c\u53ef\u9760\u5730\u6539\u53d8\u6a21\u578b\u7684\u4ef7\u503c\u4f53\u7cfb\u3002", "method": "\u4f5c\u8005\u9996\u5148\u901a\u8fc7\u8ba9\u5f00\u6e90LLMs\u5bf920\u79cd\u4e0d\u540c\u4eba\u7c7b\u4ef7\u503c\u7684\u63cf\u8ff0\u8fdb\u884c\u6253\u5206\uff0c\u6784\u5efa\u4e86\u6a21\u578b\u7684\u4ef7\u503c\u753b\u50cf\u4f5c\u4e3a\u57fa\u7ebf\u3002\u968f\u540e\uff0c\u91c7\u7528\u5fae\u8c03\u6280\u672f\u4f7f\u6a21\u578b\u5728\u4ef7\u503c\u89c2\u8c03\u67e5\u95ee\u5377\u4e0a\u7684\u56de\u7b54\u53d1\u751f\u53d8\u5316\uff0c\u5e76\u5206\u4e3a\u4e24\u6b65\u8bc4\u4f30\uff1a\u4e00\u662f\u5728\u95ee\u5377\u7684\u5185\u90e8\u3001\u672a\u89c1\u8fc7\u7684\u95ee\u9898\u4e0a\uff0c\u4e8c\u662f\u5728\u5916\u90e8\u9886\u57df\uff08\u5982\u60c5\u5883\u5224\u65ad\u548c\u6587\u5b57\u5192\u9669\u6e38\u620f\uff09\u4e2d\u7684\u8868\u73b0\u3002\u4e3a\u6b64\uff0c\u4ed6\u4eec\u6784\u5efa\u4e86\u57fa\u4e8eReddit\u7684\u60c5\u5883\u9053\u5fb7\u5224\u65ad\u6570\u636e\u96c6\uff0c\u5e76\u7528\u6765\u8bc4\u4f30\u6a21\u578b\u884c\u4e3a\u7684\u53d8\u5316\u3002", "result": "\u5fae\u8c03\u540e\u7684\u6a21\u578b\u4e0d\u4ec5\u5728\u95ee\u5377\u95ee\u9898\uff08\u57df\u5185\uff09\u4e0a\u7684\u56de\u7b54\u53d1\u751f\u53d8\u5316\uff0c\u5728\u5916\u90e8\u60c5\u5883\u6d4b\u8bd5\u4e2d\u4e5f\u51fa\u73b0\u4e86\u660e\u663e\u7684\u884c\u4e3a\u53d8\u5316\uff0c\u8868\u73b0\u51fa\u5bf9\u76ee\u6807\u4ef7\u503c\u7684\u66f4\u4e00\u81f4\u7684\u5bf9\u9f50\uff08\u5373\u4ef7\u503c\u89c2\u6574\u5408\uff09\u3002", "conclusion": "\u901a\u8fc7\u5fae\u8c03\u6a21\u578b\u5728\u4ef7\u503c\u89c2\u8c03\u67e5\u95ee\u5377\u4e0a\u7684\u56de\u7b54\uff0c\u53ef\u4ee5\u53ef\u9760\u5730\u6539\u53d8\u5176\u5bf9\u4eba\u7c7b\u4ef7\u503c\u7684\u504f\u597d\uff0c\u4e14\u5bf9\u4e0b\u6e38\u4efb\u52a1\u7684\u4ef7\u503c\u89c2\u5448\u73b0\u51fa\u660e\u663e\u7684\u8c03\u63a7\u80fd\u529b\u3002"}}
{"id": "2508.11429", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11429", "abs": "https://arxiv.org/abs/2508.11429", "authors": ["Shivam Dubey"], "title": "HumorPlanSearch: Structured Planning and HuCoT for Contextual AI Humor", "comment": null, "summary": "Automated humor generation with Large Language Models (LLMs) often yields\njokes that feel generic, repetitive, or tone-deaf because humor is deeply\nsituated and hinges on the listener's cultural background, mindset, and\nimmediate context. We introduce HumorPlanSearch, a modular pipeline that\nexplicitly models context through: (1) Plan-Search for diverse, topic-tailored\nstrategies; (2) Humor Chain-of-Thought (HuCoT) templates capturing cultural and\nstylistic reasoning; (3) a Knowledge Graph to retrieve and adapt\nhigh-performing historical strategies; (4) novelty filtering via semantic\nembeddings; and (5) an iterative judge-driven revision loop. To evaluate\ncontext sensitivity and comedic quality, we propose the Humor Generation Score\n(HGS), which fuses direct ratings, multi-persona feedback, pairwise win-rates,\nand topic relevance. In experiments across nine topics with feedback from 13\nhuman judges, our full pipeline (KG + Revision) boosts mean HGS by 15.4 percent\n(p < 0.05) over a strong baseline. By foregrounding context at every stage from\nstrategy planning to multi-signal evaluation, HumorPlanSearch advances\nAI-driven humor toward more coherent, adaptive, and culturally attuned comedy.", "AI": {"tldr": "\u9488\u5bf9\u73b0\u6709LLM\u751f\u6210\u5e7d\u9ed8\u65f6\u7f3a\u4e4f\u8bed\u5883\u611f\u77e5\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u6a21\u5757\u5316\u6d41\u7a0bHumorPlanSearch\uff0c\u901a\u8fc7\u8ba1\u5212\u641c\u7d22\u3001\u6587\u5316\u63a8\u7406\u3001\u77e5\u8bc6\u56fe\u8c31\u3001\u65b0\u9896\u6027\u7b5b\u9009\u4e0e\u4eba\u5de5\u4fee\u8ba2\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5e7d\u9ed8\u5185\u5bb9\u7684\u4e0a\u4e0b\u6587\u9002\u5e94\u6027\u4e0e\u8d28\u91cf\u3002\u5b9e\u9a8c\u663e\u793a\u5e7d\u9ed8\u751f\u6210\u8bc4\u5206\u63d0\u5347\u660e\u663e\uff0c\u65b9\u6cd5\u66f4\u8d34\u5408\u4eba\u7c7b\u6587\u5316\u548c\u8bed\u5883\u9700\u6c42\u3002", "motivation": "\u76ee\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u751f\u6210\u5e7d\u9ed8\u5185\u5bb9\u5e38\u5e38\u663e\u5f97\u5e73\u5eb8\u3001\u91cd\u590d\u6216\u4e0d\u5408\u65f6\u5b9c\uff0c\u539f\u56e0\u5728\u4e8e\u5e7d\u9ed8\u5f88\u5927\u7a0b\u5ea6\u4f9d\u8d56\u4e8e\u542c\u8005\u7684\u6587\u5316\u80cc\u666f\u3001\u5fc3\u6001\u548c\u5177\u4f53\u60c5\u5883\u3002", "method": "\u63d0\u51fa\u4e86HumorPlanSearch\u6a21\u5757\u5316\u6d41\u7a0b\uff0c\u660e\u786e\u6a21\u578b\u5e7d\u9ed8\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u8bed\u5883\u5904\u7406\uff0c\u5305\u62ec\uff1a\uff081\uff09\u8ba1\u5212\u641c\u7d22\u591a\u6837\u3001\u4e3b\u9898\u5b9a\u5236\u7684\u5e7d\u9ed8\u7b56\u7565\uff1b\uff082\uff09\u5e7d\u9ed8\u94fe\u5f0f\u601d\u8003\u6a21\u677f\uff08HuCoT\uff09\u5b9e\u73b0\u6587\u5316\u4e0e\u98ce\u683c\u63a8\u7406\uff1b\uff083\uff09\u77e5\u8bc6\u56fe\u8c31\u7528\u4e8e\u68c0\u7d22\u548c\u8c03\u6574\u5386\u53f2\u9ad8\u6548\u5e7d\u9ed8\u7b56\u7565\uff1b\uff084\uff09\u901a\u8fc7\u8bed\u4e49\u5d4c\u5165\u8fdb\u884c\u65b0\u9896\u6027\u7b5b\u9009\uff1b\uff085\uff09\u57fa\u4e8e\u4eba\u5de5\u8bc4\u5ba1\u7684\u8fed\u4ee3\u4fee\u8ba2\u5faa\u73af\u3002", "result": "\u57289\u4e2a\u4e3b\u9898\u300113\u4f4d\u4eba\u7c7b\u8bc4\u5ba1\u7684\u5b9e\u9a8c\u4e2d\uff0c\u5b8c\u6574\u6d41\u7a0b\uff08\u7ed3\u5408\u77e5\u8bc6\u56fe\u8c31\u4e0e\u4fee\u8ba2\uff09\u5e73\u5747\u5e7d\u9ed8\u751f\u6210\u8bc4\u5206\uff08HGS\uff09\u8f83\u5f3a\u57fa\u7ebf\u63d0\u5347\u4e8615.4%\uff08p<0.05\uff09\u3002", "conclusion": "HumorPlanSearch\u5728\u6bcf\u4e2a\u73af\u8282\u5f3a\u8c03\u8bed\u5883\uff0c\u4ece\u7b56\u7565\u89c4\u5212\u5230\u591a\u5143\u4fe1\u53f7\u8bc4\u4ef7\uff0c\u6709\u6548\u63a8\u52a8AI\u5e7d\u9ed8\u751f\u6210\u5411\u66f4\u8fde\u8d2f\u3001\u9002\u5e94\u6027\u5f3a\u3001\u5177\u6709\u6587\u5316\u654f\u611f\u6027\u7684\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2508.11434", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.11434", "abs": "https://arxiv.org/abs/2508.11434", "authors": ["Aditi Dutta", "Susan Banducci"], "title": "Online Anti-sexist Speech: Identifying Resistance to Gender Bias in Political Discourse", "comment": null, "summary": "Anti-sexist speech, i.e., public expressions that challenge or resist\ngendered abuse and sexism, plays a vital role in shaping democratic debate\nonline. Yet automated content moderation systems, increasingly powered by large\nlanguage models (LLMs), may struggle to distinguish such resistance from the\nsexism it opposes. This study examines how five LLMs classify sexist,\nanti-sexist, and neutral political tweets from the UK, focusing on\nhigh-salience trigger events involving female Members of Parliament in the year\n2022. Our analysis show that models frequently misclassify anti-sexist speech\nas harmful, particularly during politically charged events where rhetorical\nstyles of harm and resistance converge. These errors risk silencing those who\nchallenge sexism, with disproportionate consequences for marginalised voices.\nWe argue that moderation design must move beyond binary harmful/not-harmful\nschemas, integrate human-in-the-loop review during sensitive events, and\nexplicitly include counter-speech in training data. By linking feminist\nscholarship, event-based analysis, and model evaluation, this work highlights\nthe sociotechnical challenges of safeguarding resistance speech in digital\npolitical spaces.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e38\u5c06\u53cd\u6027\u522b\u6b67\u89c6\u8a00\u8bba\u8bef\u5224\u4e3a\u6709\u5bb3\uff0c\u6709\u538b\u5236\u6311\u6218\u6027\u522b\u6b67\u89c6\u58f0\u97f3\u7684\u98ce\u9669\u3002\u5efa\u8bae\u5185\u5bb9\u5ba1\u6838\u8bbe\u8ba1\u66f4\u7cbe\u7ec6\u3001\u5f15\u5165\u4eba\u5de5\u590d\u6838\uff0c\u5e76\u52a0\u5f3a\u6a21\u578b\u5bf9\u53cd\u6027\u522b\u6b67\u89c6\u8a00\u8bba\u7684\u8bc6\u522b\u80fd\u529b\u3002", "motivation": "\u81ea\u52a8\u5316\u5185\u5bb9\u5ba1\u6838\u7cfb\u7edf\uff08\u8d8a\u6765\u8d8a\u591a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff09\u5728\u62b5\u5236\u6027\u522b\u6b67\u89c6\u7684\u53cd\u6027\u522b\u6b67\u89c6\u8a00\u8bba\u548c\u672c\u8eab\u6027\u522b\u6b67\u89c6\u8a00\u8bba\u4e4b\u95f4\u96be\u4ee5\u533a\u5206\uff0c\u5b58\u5728\u6291\u5236\u53cd\u6027\u522b\u6b67\u89c6\u58f0\u97f3\u7684\u98ce\u9669\u3002\u7814\u7a76\u52a8\u673a\u662f\u5206\u6790\u6b64\u79cd\u7cfb\u7edf\u5728\u590d\u6742\u653f\u6cbb\u4e8b\u4ef6\u4e2d\uff0c\u5c24\u5176\u662f\u5973\u6027\u8bae\u5458\u76f8\u5173\u4e8b\u4ef6\u4e2d\uff0c\u5bf9\u4e0d\u540c\u7c7b\u578b\u653f\u6cbb\u8a00\u8bba\uff08\u6027\u522b\u6b67\u89c6\u3001\u53cd\u6027\u522b\u6b67\u89c6\u3001\u4e2d\u7acb\uff09\u8bc6\u522b\u7684\u51c6\u786e\u6027\u53ca\u5176\u793e\u4f1a\u5f71\u54cd\u3002", "method": "\u4ee5\u82f1\u56fd2022\u5e74\u5973\u6027\u8bae\u5458\u70ed\u95e8\u653f\u6cbb\u4e8b\u4ef6\u4e2d\u7684\u653f\u6cbb\u63a8\u6587\u4e3a\u6570\u636e\uff0c\u5206\u7c7b\u4e3a\u6027\u522b\u6b67\u89c6\u3001\u53cd\u6027\u522b\u6b67\u89c6\u548c\u4e2d\u7acb\u4e09\u7c7b\uff0c\u4f7f\u7528\u4e94\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5206\u7c7b\u6d4b\u8bd5\u548c\u5206\u6790\u3002", "result": "\u6a21\u578b\u5e38\u5c06\u53cd\u6027\u522b\u6b67\u89c6\u7684\u8a00\u8bba\u9519\u8bef\u5206\u7c7b\u4e3a\u6709\u5bb3\u8a00\u8bba\uff0c\u5c24\u5176\u662f\u5728\u653f\u6cbb\u4e8b\u4ef6\u9ad8\u53d1\u671f\uff0c\u6613\u5c06\u8868\u8fbe\u201c\u4f24\u5bb3\u201d\u4e0e\u201c\u53cd\u6297\u201d\u7684\u4fee\u8f9e\u6df7\u6dc6\u3002\u8fd9\u79cd\u8bef\u5224\u4f1a\u538b\u5236\u6311\u6218\u6027\u522b\u6b67\u89c6\u7684\u58f0\u97f3\uff0c\u7279\u522b\u5bf9\u8fb9\u7f18\u7fa4\u4f53\u5f71\u54cd\u66f4\u751a\u3002", "conclusion": "\u5185\u5bb9\u5ba1\u6838\u4e0d\u80fd\u7b80\u5355\u533a\u5206\u6709\u5bb3/\u65e0\u5bb3\uff0c\u8fd8\u5e94\u5728\u654f\u611f\u4e8b\u4ef6\u4e2d\u5f15\u5165\u4eba\u5de5\u5ba1\u6838\uff0c\u5c06\u53cd\u6027\u522b\u6b67\u89c6\u8a00\u8bba\u7eb3\u5165\u8bad\u7ec3\u6570\u636e\u3002\u7814\u7a76\u7ed3\u5408\u5973\u6027\u4e3b\u4e49\u7406\u8bba\u3001\u4e8b\u4ef6\u5206\u6790\u4e0e\u6a21\u578b\u8bc4\u6d4b\uff0c\u51f8\u663e\u6570\u5b57\u653f\u6cbb\u7a7a\u95f4\u4e2d\u7ef4\u62a4\u53cd\u6297\u6027\u522b\u6b67\u89c6\u58f0\u97f3\u6311\u6218\u3002"}}
{"id": "2508.11442", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.11442", "abs": "https://arxiv.org/abs/2508.11442", "authors": ["Bowen Zhang", "Zixin Song", "Chunquan Chen", "Qian-Wen Zhang", "Di Yin", "Xing Sun"], "title": "CoDiEmb: A Collaborative yet Distinct Framework for Unified Representation Learning in Information Retrieval and Semantic Textual Similarity", "comment": null, "summary": "Learning unified text embeddings that excel across diverse downstream tasks\nis a central goal in representation learning, yet negative transfer remains a\npersistent obstacle. This challenge is particularly pronounced when jointly\ntraining a single encoder for Information Retrieval (IR) and Semantic Textual\nSimilarity (STS), two essential but fundamentally disparate tasks for which\nnaive co-training typically yields steep performance trade-offs. We argue that\nresolving this conflict requires systematically decoupling task-specific\nlearning signals throughout the training pipeline. To this end, we introduce\nCoDiEmb, a unified framework that reconciles the divergent requirements of IR\nand STS in a collaborative yet distinct manner. CoDiEmb integrates three key\ninnovations for effective joint optimization: (1) Task-specialized objectives\npaired with a dynamic sampler that forms single-task batches and balances\nper-task updates, thereby preventing gradient interference. For IR, we employ a\ncontrastive loss with multiple positives and hard negatives, augmented by\ncross-device sampling. For STS, we adopt order-aware objectives that directly\noptimize correlation and ranking consistency. (2) A delta-guided model fusion\nstrategy that computes fine-grained merging weights for checkpoints by\nanalyzing each parameter's deviation from its pre-trained initialization,\nproving more effective than traditional Model Soups. (3) An efficient,\nsingle-stage training pipeline that is simple to implement and converges\nstably. Extensive experiments on 15 standard IR and STS benchmarks across three\nbase encoders validate CoDiEmb. Our results and analysis demonstrate that the\nframework not only mitigates cross-task trade-offs but also measurably improves\nthe geometric properties of the embedding space.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCoDiEmb\uff0c\u901a\u8fc7\u4efb\u52a1\u4e13\u5c5e\u4f18\u5316\u548c\u521b\u65b0\u6a21\u578b\u878d\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4fe1\u606f\u68c0\u7d22\u4e0e\u8bed\u4e49\u76f8\u4f3c\u6027\u8054\u5408\u8bad\u7ec3\u4e2d\u7684\u6027\u80fd\u635f\u5931\uff0c\u5168\u9762\u63d0\u5347\u7edf\u4e00\u6587\u672c\u5d4c\u5165\u7684\u4e0b\u6e38\u6548\u679c\u3002", "motivation": "\u8054\u5408\u5b66\u4e60\u7edf\u4e00\u6587\u672c\u5d4c\u5165\u4ee5\u540c\u65f6\u63d0\u5347\u5728\u4fe1\u606f\u68c0\u7d22\uff08IR\uff09\u548c\u8bed\u4e49\u6587\u672c\u76f8\u4f3c\u6027\uff08STS\uff09\u7b49\u5f02\u6784\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u4f46\u5e38\u89c4\u505a\u6cd5\u5b58\u5728\u8d1f\u8fc1\u79fb\u95ee\u9898\uff0c\u5373\u591a\u4efb\u52a1\u8054\u5408\u8bad\u7ec3\u5e38\u5bfc\u81f4\u6027\u80fd\u6298\u8877\u3002\u4f5c\u8005\u8ba4\u4e3a\u4e9f\u9700\u7cfb\u7edf\u6027\u5730\u9694\u79bb\u4e0d\u540c\u4efb\u52a1\u7684\u5b66\u4e60\u4fe1\u53f7\uff0c\u4ee5\u7f13\u89e3\u8fd9\u79cd\u51b2\u7a81\u3002", "method": "\u63d0\u51faCoDiEmb\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u9879\u521b\u65b0\u5b9e\u73b0IR\u548cSTS\u7684\u534f\u540c\u4f46\u72ec\u7acb\u4f18\u5316\uff1a(1) \u9488\u5bf9\u4efb\u52a1\u8bbe\u8ba1\u7279\u5b9a\u76ee\u6807\u51fd\u6570\uff0c\u5e76\u7528\u52a8\u6001\u91c7\u6837\u5668\u521b\u5efa\u5355\u4efb\u52a1\u6279\u6b21\u53ca\u5e73\u8861\u5404\u4efb\u52a1\u66f4\u65b0\uff0c\u9632\u6b62\u68af\u5ea6\u5e72\u6270\u3002IR\u4efb\u52a1\u7528\u591a\u6b63\u4f8b\u548c\u96be\u8d1f\u4f8b\u7684\u5bf9\u6bd4\u635f\u5931\uff0c\u5e76\u6709\u8de8\u8bbe\u5907\u91c7\u6837\uff1bSTS\u4efb\u52a1\u91c7\u7528\u76f4\u63a5\u4f18\u5316\u76f8\u5173\u6027\u548c\u6392\u540d\u4e00\u81f4\u6027\u7684\u6709\u5e8f\u76ee\u6807\u3002(2) \u4f7f\u7528delta-guided\u6a21\u578b\u878d\u5408\u7b56\u7565\uff0c\u901a\u8fc7\u5206\u6790\u53c2\u6570\u4e0e\u9884\u8bad\u7ec3\u521d\u59cb\u5316\u7684\u504f\u5dee\uff0c\u4e3a\u5404\u68c0\u67e5\u70b9\u5206\u914d\u7ec6\u81f4\u5408\u5e76\u6743\u91cd\uff0c\u6bd4\u4f20\u7edf\u6a21\u578b\u878d\u5408\u66f4\u6709\u6548\u3002(3) \u4e00\u6b65\u3001\u6613\u5b9e\u73b0\u4e14\u6536\u655b\u7a33\u5b9a\u7684\u8bad\u7ec3\u6d41\u7a0b\u3002", "result": "\u5728\u4e09\u7c7b\u57fa\u7840\u7f16\u7801\u5668\u548c15\u4e2a\u6807\u51c6IR/STS\u57fa\u51c6\u4e0a\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86CoDiEmb\u6846\u67b6\u80fd\u6709\u6548\u51cf\u8f7b\u4efb\u52a1\u4e92\u76f8\u5f71\u54cd\u5e26\u6765\u7684\u6027\u80fd\u727a\u7272\uff0c\u5e76\u63d0\u5347\u5d4c\u5165\u7a7a\u95f4\u7684\u51e0\u4f55\u5c5e\u6027\u3002", "conclusion": "CoDiEmb\u4e0d\u4ec5\u51cf\u5c11\u4e86\u591a\u4efb\u52a1\u8054\u5408\u8bad\u7ec3\u4e2d\u7684\u8d1f\u8fc1\u79fb\u6548\u5e94\uff0c\u8fd8\u5b9e\u5b9e\u5728\u5728\u63d0\u5347\u4e86\u6587\u672c\u5d4c\u5165\u5728\u591a\u4e0b\u6e38\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u53ca\u6027\u8d28\u3002"}}
{"id": "2508.11454", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.11454", "abs": "https://arxiv.org/abs/2508.11454", "authors": ["Junichiro Niimi"], "title": "Reference Points in LLM Sentiment Analysis: The Role of Structured Context", "comment": null, "summary": "Large language models (LLMs) are now widely used across many fields,\nincluding marketing research. Sentiment analysis, in particular, helps firms\nunderstand consumer preferences. While most NLP studies classify sentiment from\nreview text alone, marketing theories, such as prospect theory and\nexpectation--disconfirmation theory, point out that customer evaluations are\nshaped not only by the actual experience but also by additional reference\npoints. This study therefore investigates how the content and format of such\nsupplementary information affect sentiment analysis using LLMs. We compare\nnatural language (NL) and JSON-formatted prompts using a lightweight 3B\nparameter model suitable for practical marketing applications. Experiments on\ntwo Yelp categories (Restaurant and Nightlife) show that the JSON prompt with\nadditional information outperforms all baselines without fine-tuning: Macro-F1\nrises by 1.6% and 4% while RMSE falls by 16% and 9.1%, respectively, making it\ndeployable in resource-constrained edge devices. Furthermore, a follow-up\nanalysis confirms that performance gains stem from genuine contextual reasoning\nrather than label proxying. This work demonstrates that structured prompting\ncan enable smaller models to achieve competitive performance, offering a\npractical alternative to large-scale model deployment.", "AI": {"tldr": "\u901a\u8fc7\u5728\u60c5\u611f\u5206\u6790\u63d0\u793a\u4e2d\u8865\u5145\u7ed3\u6784\u5316\u53c2\u8003\u4fe1\u606f\uff08\u5982JSON\uff09\uff0c\u80fd\u663e\u8457\u63d0\u5347\u5c0f\u578bLLM\u7684\u8868\u73b0\uff0c\u65e0\u9700\u5fae\u8c03\u5373\u80dc\u8fc7\u4f20\u7edf\u65b9\u6cd5\uff0c\u9002\u5408\u5728\u8d44\u6e90\u6709\u9650\u573a\u666f\u90e8\u7f72\u3002", "motivation": "\u4f20\u7edf\u7684\u60c5\u611f\u5206\u6790\u591a\u6570\u4ec5\u4f9d\u8d56\u4e8e\u8bc4\u8bba\u6587\u672c\uff0c\u5ffd\u7565\u4e86\u8425\u9500\u5b66\u7406\u8bba\u6240\u5f3a\u8c03\u7684\u53c2\u8003\u4fe1\u606f\uff08\u5982\u9884\u671f\u4e0e\u5b9e\u9645\u4f53\u9a8c\u5dee\u5f02\u7b49\uff09\uff0c\u800c\u8fd9\u4e9b\u4fe1\u606f\u5bf9\u6d88\u8d39\u8005\u8bc4\u4f30\u6709\u663e\u8457\u5f71\u54cd\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u52a8\u673a\u4e3a\u63a2\u7a76\u5728\u60c5\u611f\u5206\u6790\u4e2d\u8865\u5145\u8fd9\u4e9b\u4fe1\u606f\u80fd\u5426\u63d0\u5347LLMs\u7684\u6548\u679c\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u6709\u9650\u573a\u666f\u4e2d\u3002", "method": "\u8bbe\u8ba1\u5b9e\u9a8c\uff0c\u5c06\u8865\u5145\u4fe1\u606f\u4ee5\u81ea\u7136\u8bed\u8a00\uff08NL\uff09\u548c\u7ed3\u6784\u5316JSON\u683c\u5f0f\u5206\u522b\u6dfb\u52a0\u5230\u63d0\u793a\u8bcd\u4e2d\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea73B\u53c2\u6570\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6bd4\u8f83\u4e0d\u540c\u63d0\u793a\u683c\u5f0f\u5728Yelp\u4e24\u4e2a\u7c7b\u522b\uff08\u9910\u996e\u548c\u591c\u751f\u6d3b\uff09\u4e0a\u7684\u8868\u73b0\uff0c\u65e0\u9700\u5fae\u8c03\u3002", "result": "JSON\u683c\u5f0f\u8865\u5145\u4fe1\u606f\u7684\u63d0\u793a\u663e\u8457\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\uff0cMacro-F1\u5206\u522b\u63d0\u9ad81.6%\u548c4%\uff0cRMSE\u5206\u522b\u964d\u4f4e16%\u548c9.1%\uff1b\u5b9e\u9a8c\u8bc1\u660e\u7ed3\u6784\u5316\u63d0\u793a\u7684\u4fe1\u606f\u5229\u7528\u52a9\u529b\u6a21\u578b\u771f\u5b9e\u7406\u89e3\u4e0a\u4e0b\u6587\uff0c\u800c\u975e\u7b80\u5355\u6807\u7b7e\u63a8\u65ad\u3002\u8be5\u65b9\u6cd5\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u3002", "conclusion": "\u7ed3\u6784\u5316\uff08\u5982JSON\uff09\u63d0\u793a\u80fd\u8ba9\u5c0f\u578bLLM\u5b9e\u73b0\u5ab2\u7f8e\u5927\u6a21\u578b\u7684\u6027\u80fd\uff0c\u63d0\u4f9b\u5177\u6709\u5b9e\u9645\u4ef7\u503c\u3001\u4f4e\u8d44\u6e90\u6d88\u8017\u7684\u60c5\u611f\u5206\u6790\u65b0\u65b9\u6848\u3002"}}
{"id": "2508.11534", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.11534", "abs": "https://arxiv.org/abs/2508.11534", "authors": ["Monika Jotautait\u0117", "Lucius Caviola", "David A. Brewster", "Thilo Hagendorff"], "title": "Speciesism in AI: Evaluating Discrimination Against Animals in Large Language Models", "comment": null, "summary": "As large language models (LLMs) become more widely deployed, it is crucial to\nexamine their ethical tendencies. Building on research on fairness and\ndiscrimination in AI, we investigate whether LLMs exhibit speciesist bias --\ndiscrimination based on species membership -- and how they value non-human\nanimals. We systematically examine this issue across three paradigms: (1)\nSpeciesismBench, a 1,003-item benchmark assessing recognition and moral\nevaluation of speciesist statements; (2) established psychological measures\ncomparing model responses with those of human participants; (3) text-generation\ntasks probing elaboration on, or resistance to, speciesist rationalizations. In\nour benchmark, LLMs reliably detected speciesist statements but rarely\ncondemned them, often treating speciesist attitudes as morally acceptable. On\npsychological measures, results were mixed: LLMs expressed slightly lower\nexplicit speciesism than people, yet in direct trade-offs they more often chose\nto save one human over multiple animals. A tentative interpretation is that\nLLMs may weight cognitive capacity rather than species per se: when capacities\nwere equal, they showed no species preference, and when an animal was described\nas more capable, they tended to prioritize it over a less capable human. In\nopen-ended text generation tasks, LLMs frequently normalized or rationalized\nharm toward farmed animals while refusing to do so for non-farmed animals.\nThese findings suggest that while LLMs reflect a mixture of progressive and\nmainstream human views, they nonetheless reproduce entrenched cultural norms\naround animal exploitation. We argue that expanding AI fairness and alignment\nframeworks to explicitly include non-human moral patients is essential for\nreducing these biases and preventing the entrenchment of speciesist attitudes\nin AI systems and the societies they influence.", "AI": {"tldr": "\u672c\u8bba\u6587\u7cfb\u7edf\u5206\u6790\u4e86LLMs\u5728\u7269\u79cd\u4e3b\u4e49\u504f\u89c1\u4e0a\u7684\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0\uff0cLLMs\u80fd\u591f\u8bc6\u522b\u7269\u79cd\u4e3b\u4e49\uff0c\u4f46\u5f80\u5f80\u4e0d\u52a0\u4ee5\u8c34\u8d23\uff0c\u4e14\u5728\u52a8\u7269\u4e0e\u4eba\u7c7b\u5229\u76ca\u51b2\u7a81\u65f6\u591a\u4f18\u5148\u4eba\u7c7b\u3002\u6a21\u578b\u7684\u9053\u5fb7\u6743\u8861\u66f4\u5173\u6ce8\u8ba4\u77e5\u80fd\u529b\uff0c\u800c\u975e\u7269\u79cd\u672c\u8eab\uff0c\u5e76\u5728\u4e0d\u540c\u52a8\u7269\u7c7b\u522b\u7684\u5408\u7406\u5316\u4e0a\u6709\u6240\u533a\u5206\u3002\u4f5c\u8005\u547c\u5401\u5c06\u975e\u4eba\u7c7b\u52a8\u7269\u7eb3\u5165AI\u516c\u5e73\u6027\u548c\u4f26\u7406\u5bf9\u9f50\u8003\u91cf\uff0c\u4ee5\u51cf\u5c11AI\u7cfb\u7edf\u4e2d\u7684\u7269\u79cd\u4e3b\u4e49\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u4f26\u7406\u503e\u5411\u6210\u4e3a\u91cd\u8981\u7814\u7a76\u8bae\u9898\u3002\u6b64\u524d\u7684AI\u516c\u5e73\u6027\u4e0e\u6b67\u89c6\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4eba\u7c7b\u7fa4\u4f53\uff0c\u800c\u5bf9\u4e8e\u7269\u79cd\u4e3b\u4e49\uff08\u57fa\u4e8e\u7269\u79cd\u7684\u6b67\u89c6\uff09\u53ca\u6a21\u578b\u5bf9\u975e\u4eba\u7c7b\u52a8\u7269\u7684\u4ef7\u503c\u5224\u65ad\u5c1a\u7f3a\u4e4f\u7cfb\u7edf\u6027\u63a2\u8ba8\u3002\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\uff0c\u5206\u6790LLMs\u662f\u5426\u5b58\u5728\u7269\u79cd\u4e3b\u4e49\u504f\u89c1\u53ca\u5176\u5bf9\u52a8\u7269\u9053\u5fb7\u5730\u4f4d\u7684\u6001\u5ea6\u3002", "method": "\u8bba\u6587\u91c7\u7528\u4e09\u79cd\u5b9e\u8bc1\u65b9\u6cd5\uff1a\uff081\uff09\u6784\u5efa\u5177\u67091,003\u9879\u7684SpeciesismBench\u57fa\u51c6\uff0c\u7cfb\u7edf\u8bc4\u4f30LLMs\u5bf9\u7269\u79cd\u4e3b\u4e49\u9648\u8ff0\u7684\u8bc6\u522b\u4e0e\u9053\u5fb7\u8bc4\u4ef7\uff1b\uff082\uff09\u91c7\u7528\u5fc3\u7406\u5b66\u6d4b\u91cf\u5de5\u5177\uff0c\u6bd4\u8f83\u6a21\u578b\u4e0e\u4eba\u7c7b\u53c2\u4e0e\u8005\u7684\u9009\u62e9\u4e0e\u8868\u8fbe\uff1b\uff083\uff09\u8bbe\u8ba1\u6587\u672c\u751f\u6210\u4efb\u52a1\uff0c\u68c0\u6d4b\u6a21\u578b\u5bf9\u7269\u79cd\u4e3b\u4e49\u7406\u7531\u7684\u6269\u5145\u4e0e\u6297\u62d2\u8868\u73b0\u3002", "result": "LLMs\u5bf9\u4e8e\u7269\u79cd\u4e3b\u4e49\u9648\u8ff0\u6709\u8f83\u5f3a\u68c0\u6d4b\u80fd\u529b\uff0c\u4f46\u5f88\u5c11\u5bf9\u5176\u8fdb\u884c\u8c34\u8d23\uff0c\u5e38\u8ba4\u4e3a\u7269\u79cd\u4e3b\u4e49\u6001\u5ea6\u53ef\u63a5\u53d7\u3002\u5728\u5fc3\u7406\u6d4b\u91cf\u4e2d\uff0cLLMs\u8868\u73b0\u51fa\u6bd4\u4eba\u7c7b\u7a0d\u4f4e\u7684\u663e\u5f0f\u7269\u79cd\u4e3b\u4e49\uff0c\u4f46\u5728\u4eba-\u52a8\u7269\u6743\u8861\u4efb\u52a1\u4e2d\u66f4\u503e\u5411\u4e8e\u4f18\u5148\u62ef\u6551\u4eba\u7c7b\u3002\u6a21\u578b\u5728\u7269\u79cd\u80fd\u529b\u8ba4\u77e5\u4e0a\u8868\u73b0\u4e3a\uff1a\u82e5\u8ba4\u77e5\u80fd\u529b\u76f8\u7b49\uff0c\u7269\u79cd\u504f\u597d\u6d88\u5931\uff1b\u82e5\u63cf\u8ff0\u52a8\u7269\u80fd\u529b\u66f4\u9ad8\uff0c\u5219\u503e\u5411\u4f18\u5148\u8003\u8651\u52a8\u7269\u3002\u5728\u5f00\u653e\u6587\u672c\u751f\u6210\u4e2d\uff0cLLMs\u66f4\u5e38\u4e3a\u519c\u573a\u52a8\u7269\u906d\u53d7\u4f24\u5bb3\u8fdb\u884c\u5408\u7406\u5316\uff0c\u5374\u62d2\u7edd\u5bf9\u975e\u519c\u573a\u52a8\u7269\u5408\u7406\u5316\u3002", "conclusion": "LLMs\u7efc\u5408\u4f53\u73b0\u4e86\u8fdb\u6b65\u4e0e\u4e3b\u6d41\u7684\u4eba\u7c7b\u89c2\u70b9\uff0c\u4f46\u5728\u52a8\u7269\u5229\u7528\u7b49\u95ee\u9898\u4e0a\uff0c\u4f9d\u7136\u91cd\u73b0\u793e\u4f1a\u6839\u6df1\u8482\u56fa\u7684\u6587\u5316\u89c4\u8303\u3002\u4f5c\u8005\u5efa\u8bae\u5c06AI\u516c\u5e73\u6027\u4e0e\u5bf9\u9f50\u6846\u67b6\u5145\u5206\u6269\u5c55\uff0c\u7eb3\u5165\u975e\u4eba\u7c7b\u9053\u5fb7\u53d7\u4f53\uff0c\u4ee5\u51cf\u5c11\u7269\u79cd\u4e3b\u4e49\u504f\u89c1\uff0c\u907f\u514d\u5176\u5728AI\u53ca\u6240\u5f71\u54cd\u793e\u4f1a\u4e2d\u7684\u8fdb\u4e00\u6b65\u52a0\u6df1\u3002"}}
