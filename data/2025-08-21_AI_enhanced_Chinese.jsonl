{"id": "2508.14045", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.14045", "abs": "https://arxiv.org/abs/2508.14045", "authors": ["Admitos Passadakis", "Yingjin Song", "Albert Gatt"], "title": "From Image Captioning to Visual Storytelling", "comment": "16 pages (including references), 5 figures and 6 tables", "summary": "Visual Storytelling is a challenging multimodal task between Vision &\nLanguage, where the purpose is to generate a story for a stream of images. Its\ndifficulty lies on the fact that the story should be both grounded to the image\nsequence but also narrative and coherent. The aim of this work is to balance\nbetween these aspects, by treating Visual Storytelling as a superset of Image\nCaptioning, an approach quite different compared to most of prior relevant\nstudies. This means that we firstly employ a vision-to-language model for\nobtaining captions of the input images, and then, these captions are\ntransformed into coherent narratives using language-to-language methods. Our\nmultifarious evaluation shows that integrating captioning and storytelling\nunder a unified framework, has a positive impact on the quality of the produced\nstories. In addition, compared to numerous previous studies, this approach\naccelerates training time and makes our framework readily reusable and\nreproducible by anyone interested. Lastly, we propose a new metric/tool, named\nideality, that can be used to simulate how far some results are from an oracle\nmodel, and we apply it to emulate human-likeness in visual storytelling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4ee5\u63cf\u8ff0\u4e3a\u4e2d\u4ecb\u7684\u89c6\u89c9\u6545\u4e8b\u751f\u6210\u65b0\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u751f\u6210\u8d28\u91cf\u548c\u6548\u7387\uff0c\u5e76\u5f15\u5165\u65b0\u8bc4\u4ef7\u6307\u6807\u3002", "motivation": "\u89c6\u89c9\u6545\u4e8b\u751f\u6210\u9700\u8981\u65e2\u4f9d\u8d56\u56fe\u7247\u5e8f\u5217\uff0c\u53c8\u4fdd\u8bc1\u6545\u4e8b\u7684\u8fde\u8d2f\u6027\u548c\u53d9\u4e8b\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u4e24\u8005\u3002", "method": "\u5c06\u89c6\u89c9\u6545\u4e8b\u751f\u6210\u89c6\u4e3a\u56fe\u50cf\u63cf\u8ff0\u7684\u8d85\u96c6\u3002\u9996\u5148\u7528\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4e3a\u8f93\u5165\u56fe\u7247\u751f\u6210\u63cf\u8ff0\uff0c\u518d\u7528\u8bed\u8a00-\u8bed\u8a00\u65b9\u6cd5\u5c06\u63cf\u8ff0\u8f6c\u4e3a\u8fde\u8d2f\u6545\u4e8b\u3002\u63d0\u51fa\u4e86\u65b0\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u5e76\u5f15\u5165\u4e86\u201c\u7406\u60f3\u6027\u201d\u65b0\u6307\u6807\u3002", "result": "\u7ed3\u5408\u56fe\u50cf\u63cf\u8ff0\u548c\u6545\u4e8b\u751f\u6210\u7684\u7edf\u4e00\u6846\u67b6\u53ef\u4ee5\u63d0\u5347\u751f\u6210\u6545\u4e8b\u7684\u8d28\u91cf\u3002\u540c\u65f6\uff0c\u8be5\u65b9\u6cd5\u52a0\u901f\u8bad\u7ec3\u3001\u6846\u67b6\u53ef\u590d\u7528\u6027\u548c\u53ef\u590d\u73b0\u6027\u5f3a\u3002\u65b0\u6307\u6807\u201c\u7406\u60f3\u6027\u201d\u53ef\u7528\u4e8e\u8bc4\u4f30\u751f\u6210\u7ed3\u679c\u4e0e\u7406\u60f3\u6a21\u578b\u7684\u8ddd\u79bb\u3002", "conclusion": "\u7edf\u4e00\u7684\u63cf\u8ff0-\u6545\u4e8b\u6846\u67b6\u63d0\u5347\u4e86\u89c6\u89c9\u6545\u4e8b\u751f\u6210\u7684\u8d28\u91cf\u548c\u6548\u7387\uff0c\u201c\u7406\u60f3\u6027\u201d\u6307\u6807\u4e3a\u8bc4\u4ef7\u63d0\u4f9b\u4e86\u65b0\u65b9\u5f0f\u3002"}}
{"id": "2508.14051", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.14051", "abs": "https://arxiv.org/abs/2508.14051", "authors": ["Kezia Oketch", "John P. Lalor", "Ahmed Abbasi"], "title": "Benchmarking Sociolinguistic Diversity in Swahili NLP: A Taxonomy-Guided Approach", "comment": null, "summary": "We introduce the first taxonomy-guided evaluation of Swahili NLP, addressing\ngaps in sociolinguistic diversity. Drawing on health-related psychometric\ntasks, we collect a dataset of 2,170 free-text responses from Kenyan speakers.\nThe data exhibits tribal influences, urban vernacular, code-mixing, and\nloanwords. We develop a structured taxonomy and use it as a lens for examining\nmodel prediction errors across pre-trained and instruction-tuned language\nmodels. Our findings advance culturally grounded evaluation frameworks and\nhighlight the role of sociolinguistic variation in shaping model performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u9488\u5bf9\u65af\u74e6\u5e0c\u91cc\u8bed\u7684\u5206\u7c7b\u6cd5\u5f15\u5bfc\u8bc4\u4ef7\u65b9\u6cd5\uff0c\u6536\u96c6\u771f\u5b9e\u7b54\u590d\u5e76\u5206\u6790\u6a21\u578b\u5728\u4e0d\u540c\u8bed\u8a00\u53d8\u5f02\u4e0b\u7684\u9519\u8bef\uff0c\u63a8\u52a8\u4e86\u66f4\u5177\u6587\u5316\u591a\u6837\u6027\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6a21\u578b\u8bc4\u4ef7\u3002", "motivation": "\u5f53\u524d\u65af\u74e6\u5e0c\u91cc\u8bed\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u9886\u57df\u5728\u793e\u4f1a\u8bed\u8a00\u591a\u6837\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4e9f\u9700\u6784\u5efa\u66f4\u5177\u6587\u5316\u548c\u8bed\u8a00\u4ee3\u8868\u6027\u7684\u8bc4\u4ef7\u6846\u67b6\u3002", "method": "\u6536\u96c6\u4e862170\u4efd\u80af\u5c3c\u4e9a\u8bf4\u8bdd\u8005\u7684\u81ea\u7531\u6587\u672c\u7b54\u590d\uff0c\u6db5\u76d6\u90e8\u843d\u5f71\u54cd\u3001\u57ce\u5e02\u4fda\u8bed\u3001\u4ee3\u7801\u6df7\u5408\u548c\u5916\u6765\u8bcd\uff0c\u5e76\u636e\u6b64\u6784\u5efa\u7ed3\u6784\u5316\u5206\u7c7b\u6cd5\u3002\u5229\u7528\u8be5\u5206\u7c7b\u6cd5\u5206\u6790\u4e0d\u540c\u9884\u8bad\u7ec3\u4e0e\u6307\u4ee4\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u7684\u9884\u6d4b\u8bef\u5dee\u3002", "result": "\u5efa\u7acb\u4e86\u80fd\u591f\u6355\u6349\u793e\u4f1a\u8bed\u8a00\u591a\u6837\u6027\u7684\u8bc4\u4ef7\u6846\u67b6\uff0c\u5e76\u5c55\u793a\u4e86\u793e\u4f1a\u8bed\u8a00\u53d8\u5f02\u5bf9\u6a21\u578b\u6027\u80fd\u5177\u6709\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u8bba\u6587\u63a8\u8fdb\u4e86\u4ee5\u6587\u5316\u4e3a\u57fa\u7840\u7684\u8bc4\u4ef7\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e86\u793e\u4f1a\u8bed\u8a00\u591a\u6837\u6027\u5728\u6a21\u578b\u8bc4\u4f30\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5bf9\u65af\u74e6\u5e0c\u91cc\u8bedNLP\u53d1\u5c55\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2508.14054", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.14054", "abs": "https://arxiv.org/abs/2508.14054", "authors": ["Yiran Rex Ma"], "title": "Contrastive Analysis of Constituent Order Preferences Within Adverbial Roles in English and Chinese News: A Large-Language-Model-Driven Approach", "comment": null, "summary": "Based on comparable English-Chinese news corpora annotated by Large Language\nModel (LLM), this paper attempts to explore the differences in constituent\norder of English-Chinese news from the perspective of functional chunks with\nadverbial roles, and analyze their typical positional preferences and\ndistribution patterns. It is found that: (1) English news prefers linear\nnarrative of core information first, and functional chunks are mostly\npost-positioned, while Chinese news prefers overall presentation mode of\nbackground first, and functional chunks are often pre-positioned; (2) In SVO\nstructure, both English and Chinese news show differences in the distribution\nof functional chunks, but the tendency of Chinese pre-positioning is more\nsignificant, while that of English post-positioning is relatively mild; (3)\nWhen function blocks are co-occurring, both English and Chinese news show high\nflexibility, and the order adjustment is driven by information and pragmatic\npurposes. The study reveals that word order has both systematic preference and\ndynamic adaptability, providing new empirical support for contrastive study of\nEnglish-Chinese information structure.", "AI": {"tldr": "\u672c\u6587\u5229\u7528LLM\u6807\u6ce8\u7684\u5927\u578b\u82f1\u6c49\u65b0\u95fb\u8bed\u6599\uff0c\u53d1\u73b0\u82f1\u6587\u65b0\u95fb\u504f\u540e\u7f6e\u4fee\u9970\u6210\u5206\uff0c\u4e2d\u6587\u504f\u524d\u7f6e\uff0c\u8bed\u5e8f\u6709\u4e0d\u540c\u7684\u7cfb\u7edf\u6027\u504f\u597d\u53ca\u7075\u6d3b\u9002\u5e94\u6027\uff0c\u4e30\u5bcc\u4e86\u82f1\u6c49\u5bf9\u6bd4\u4fe1\u606f\u7ed3\u6784\u7814\u7a76\u3002", "motivation": "\u76ee\u524d\u82f1\u6c49\u65b0\u95fb\u6587\u672c\u4e2d\uff0c\u6210\u5206\u987a\u5e8f\u7684\u5dee\u5f02\u5bf9\u4fe1\u606f\u5448\u73b0\u6709\u91cd\u8981\u5f71\u54cd\u3002\u4ee5\u5f80\u5bf9\u8bed\u5e8f\u7684\u5bf9\u6bd4\u7814\u7a76\u591a\u505c\u7559\u4e8e\u7406\u8bba\u5c42\u9762\uff0c\u7f3a\u4e4f\u7ed3\u5408\u5927\u89c4\u6a21\u771f\u5b9e\u8bed\u6599\u7684\u7ec6\u81f4\u5b9e\u8bc1\u5206\u6790\u3002\u672c\u6587\u7ed3\u5408LLM\u6807\u6ce8\u7684\u5927\u578b\u82f1\u6c49\u65b0\u95fb\u8bed\u6599\uff0c\u5c1d\u8bd5\u4ece\u529f\u80fd\u5757\uff08\u5c24\u5176\u4fee\u9970\u6027\u6210\u5206\uff09\u7684\u89d2\u5ea6\uff0c\u7ec6\u81f4\u5206\u6790\u82f1\u6c49\u65b0\u95fb\u8bed\u5e8f\u504f\u597d\u53ca\u5206\u5e03\u6a21\u5f0f\u3002", "method": "\u57fa\u4e8e\u7531\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6807\u6ce8\u7684\u53ef\u6bd4\u82f1\u6c49\u65b0\u95fb\u8bed\u6599\u5e93\uff0c\u7edf\u8ba1\u548c\u5206\u6790\u82f1\u6c49\u65b0\u95fb\u4e2d\u627f\u62c5\u72b6\u8bed\u7b49\u4fee\u9970\u6027\u529f\u80fd\u5757\u7684\u5178\u578b\u8bed\u5e8f\u3001\u5206\u5e03\u53ca\u5176\u504f\u597d\uff0c\u7ed3\u5408SVO\u7ed3\u6784\u548c\u529f\u80fd\u5757\u5171\u73b0\u65f6\u7684\u8bed\u5e8f\u53d8\u5316\uff0c\u63a2\u8ba8\u4fe1\u606f\u7ed3\u6784\u548c\u8bed\u7528\u9a71\u52a8\u5bf9\u8bed\u5e8f\u7684\u5f71\u54cd\u3002", "result": "\uff081\uff09\u82f1\u6587\u65b0\u95fb\u504f\u597d\u5148\u5448\u73b0\u6838\u5fc3\u4fe1\u606f\uff0c\u529f\u80fd\u5757\u591a\u540e\u7f6e\uff1b\u4e2d\u6587\u65b0\u95fb\u5219\u503e\u5411\u5148\u7ed9\u80cc\u666f\u4fe1\u606f\uff0c\u529f\u80fd\u5757\u5e38\u524d\u7f6e\u3002\uff082\uff09\u5728SVO\u7ed3\u6784\u4e2d\uff0c\u4e24\u8bed\u8a00\u5bf9\u529f\u80fd\u5757\u5206\u5e03\u90fd\u8868\u73b0\u51fa\u5dee\u5f02\uff0c\u4f46\u4e2d\u6587\u7684\u524d\u7f6e\u503e\u5411\u66f4\u663e\u8457\uff0c\u82f1\u6587\u540e\u7f6e\u503e\u5411\u8f83\u4e3a\u6e29\u548c\u3002\uff083\uff09\u529f\u80fd\u5757\u5171\u73b0\u65f6\uff0c\u82f1\u6c49\u5747\u663e\u793a\u9ad8\u5ea6\u7075\u6d3b\u6027\uff0c\u8bed\u5e8f\u8c03\u6574\u53d7\u4fe1\u606f\u548c\u8bed\u7528\u76ee\u7684\u9a71\u52a8\u3002", "conclusion": "\u82f1\u6c49\u65b0\u95fb\u8bed\u5e8f\u65e2\u6709\u7cfb\u7edf\u6027\u504f\u597d\uff0c\u4e5f\u5177\u5907\u52a8\u6001\u9002\u5e94\u6027\uff0c\u5448\u73b0\u51fa\u4fe1\u606f\u7ed3\u6784\u7684\u5bf9\u6bd4\u7279\u70b9\u3002\u672c\u6587\u4e3a\u82f1\u6c49\u8bed\u5bf9\u6bd4\u4fe1\u606f\u7ed3\u6784\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u5b9e\u8bc1\u4f9d\u636e\u3002"}}
{"id": "2508.14055", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14055", "abs": "https://arxiv.org/abs/2508.14055", "authors": ["Tim Luka Horstmann", "Baptiste Geisenberger", "Mehwish Alam"], "title": "T-REX: Table -- Refute or Entail eXplainer", "comment": null, "summary": "Verifying textual claims against structured tabular data is a critical yet\nchallenging task in Natural Language Processing with broad real-world impact.\nWhile recent advances in Large Language Models (LLMs) have enabled significant\nprogress in table fact-checking, current solutions remain inaccessible to\nnon-experts. We introduce T-REX (T-REX: Table -- Refute or Entail eXplainer),\nthe first live, interactive tool for claim verification over multimodal,\nmultilingual tables using state-of-the-art instruction-tuned reasoning LLMs.\nDesigned for accuracy and transparency, T-REX empowers non-experts by providing\naccess to advanced fact-checking technology. The system is openly available\nonline.", "AI": {"tldr": "T-REX\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u65f6\u8868\u683c\u4e8b\u5b9e\u9a8c\u8bc1\u5de5\u5177\uff0c\u5f00\u653e\u5728\u7ebf\uff0c\u5e2e\u52a9\u975e\u4e13\u4e1a\u7528\u6237\u9ad8\u6548\u5b8c\u6210\u4e3b\u5f20\u6838\u67e5\u3002", "motivation": "\u9a8c\u8bc1\u6587\u672c\u4e3b\u5f20\u4e0e\u7ed3\u6784\u5316\u8868\u683c\u6570\u636e\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u662fNLP\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u73b0\u5b9e\u610f\u4e49\uff0c\u4f46\u76ee\u524d\u7684\u89e3\u51b3\u65b9\u6848\u5bf9\u975e\u4e13\u4e1a\u4eba\u58eb\u4e0d\u53cb\u597d\u3002", "method": "\u63d0\u51fa\u4e86T-REX\uff0c\u4e00\u4e2a\u57fa\u4e8e\u6700\u5148\u8fdb\u7684\u6307\u4ee4\u5fae\u8c03\u63a8\u7406\u578b\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u65f6\u4ea4\u4e92\u5f0f\u5de5\u5177\uff0c\u652f\u6301\u591a\u6a21\u6001\u3001\u591a\u8bed\u8a00\u8868\u683c\u7684\u4e3b\u5f20\u9a8c\u8bc1\u3002", "result": "T-REX\u4f7f\u975e\u4e13\u5bb6\u80fd\u591f\u8bbf\u95ee\u548c\u4f7f\u7528\u5148\u8fdb\u7684\u4e8b\u5b9e\u6838\u67e5\u6280\u672f\uff0c\u5e76\u8ffd\u6c42\u9ad8\u51c6\u786e\u6027\u548c\u9ad8\u900f\u660e\u5ea6\uff0c\u7cfb\u7edf\u5df2\u5f00\u653e\u5728\u7ebf\u4f7f\u7528\u3002", "conclusion": "T-REX\u5b9e\u73b0\u4e86\u8868\u683c\u4e3b\u5f20\u9a8c\u8bc1\u5de5\u5177\u7684\u6c11\u4e3b\u5316\u548c\u6613\u7528\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u975e\u4e13\u4e1a\u7528\u6237\u573a\u666f\u3002"}}
{"id": "2508.14104", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14104", "abs": "https://arxiv.org/abs/2508.14104", "authors": ["Yutong Bian", "Xianhao Lin", "Yupeng Xie", "Tianyang Liu", "Mingchen Zhuge", "Siyuan Lu", "Haoming Tang", "Jinlin Wang", "Jiayi Zhang", "Jiaqi Chen", "Xiangru Tang", "Yongxin Ni", "Sirui Hong", "Chenglin Wu"], "title": "You Don't Know Until You Click:Automated GUI Testing for Production-Ready Software Evaluation", "comment": null, "summary": "Large Language Models (LLMs) and code agents in software development are\nrapidly evolving from generating isolated code snippets to producing\nfull-fledged software applications with graphical interfaces, interactive\nlogic, and dynamic behaviors. However, current benchmarks fall short in\nevaluating such production-ready software, as they often rely on static checks\nor binary pass/fail scripts, failing to capture the interactive behaviors and\nruntime dynamics that define real-world usability - qualities that only emerge\nwhen an application is actively used. This is the blind spot of current\nevaluation: you don't know if an app works until you click through it, interact\nwith it, and observe how it responds. To bridge this gap, we introduce\nRealDevWorld, a novel evaluation framework for automated end-to-end assessment\nof LLMs' ability to generate production-ready repositories from scratch. It\nfeatures two key components: (1) RealDevBench, a diverse collection of 194\nopen-ended software engineering tasks across multiple domains, incorporating\nmultimodal elements to reflect real-world complexity; and (2) AppEvalPilot, a\nnew agent-as-a-judge evaluation system that simulates realistic, GUI-based user\ninteractions to automatically and holistically assess software functional\ncorrectness, visual fidelity, and runtime behavior. The framework delivers\nfine-grained, task-specific diagnostic feedback, supporting nuanced evaluation\nbeyond simple success/failure judgments. Empirical results show that\nRealDevWorld delivers effective, automatic, and human-aligned evaluations,\nachieving an accuracy of 0.92 and a correlation of 0.85 with expert human\nassessments, while significantly reducing the reliance on manual review. This\nenables scalable, human-aligned assessment of production-level software\ngenerated by LLMs. Our code is available on GitHub.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u4e86RealDevWorld\u81ea\u52a8\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u4e13\u4e3a\u8bc4\u4f30\u5927\u6a21\u578b\u751f\u6210\u7684\u751f\u4ea7\u7ea7\u8f6f\u4ef6\u8bbe\u8ba1\uff0c\u7ed3\u5408\u591a\u6837\u4efb\u52a1\u96c6\u548c\u81ea\u52a8\u5316\u4ea4\u4e92\u4ee3\u7406\uff0c\u53ef\u5168\u9762\u3001\u7ec6\u7c92\u5ea6\u5730\u8bc4\u4f30\u8f6f\u4ef6\u8d28\u91cf\uff0c\u5176\u6027\u80fd\u4e0e\u4eba\u5de5\u4e13\u5bb6\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5927\u5e45\u63d0\u9ad8\u4e86\u8bc4\u4f30\u6548\u7387\u4e0e\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30\u7531\u5927\u6a21\u578b\u548c\u4ee3\u7801\u4ee3\u7406\u751f\u6210\u7684\u771f\u5b9e\u751f\u4ea7\u7ea7\u8f6f\u4ef6\uff0c\u7279\u522b\u662f\u7f3a\u4e4f\u5bf9\u4ea4\u4e92\u884c\u4e3a\u548c\u8fd0\u884c\u65f6\u52a8\u6001\u7684\u8003\u5bdf\uff0c\u4ec5\u4f9d\u8d56\u9759\u6001\u6216\u4e8c\u5143\u5224\u5b9a\u65b9\u5f0f\uff0c\u65e0\u6cd5\u53cd\u6620\u5b9e\u9645\u53ef\u7528\u6027\u3002", "method": "\u63d0\u51fa\u4e86RealDevWorld\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u62ec\uff1a1\uff09RealDevBench\uff0c194\u9879\u5f00\u653e\u5f0f\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\uff0c\u6db5\u76d6\u591a\u9886\u57df\u5e76\u5e26\u6709\u591a\u6a21\u6001\u5143\u7d20\uff1b2\uff09AppEvalPilot\uff0c\u57fa\u4e8e\u4ee3\u7406\u7684\u81ea\u52a8\u8bc4\u5224\u7cfb\u7edf\uff0c\u901a\u8fc7GUI\u7528\u6237\u6a21\u62df\u4ea4\u4e92\u81ea\u52a8\u5168\u9762\u8bc4\u4f30\u8f6f\u4ef6\u7684\u529f\u80fd\u6b63\u786e\u6027\u3001\u89c6\u89c9\u6548\u679c\u3001\u8fd0\u884c\u884c\u4e3a\u3002\u8be5\u6846\u67b6\u53ef\u4ee5\u81ea\u52a8\u751f\u6210\u7ec6\u7c92\u5ea6\u3001\u4efb\u52a1\u76f8\u5173\u7684\u8bca\u65ad\u53cd\u9988\u3002", "result": "\u5b9e\u9645\u6d4b\u8bd5\u663e\u793a\uff0c\u8be5\u6846\u67b6\u81ea\u52a8\u8bc4\u4f30\u7ed3\u679c\u4e0e\u4eba\u5de5\u4e13\u5bb6\u9ad8\u5ea6\u4e00\u81f4\uff08\u51c6\u786e\u73870.92\uff0c\u76f8\u5173\u60270.85\uff09\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u5de5\u5ba1\u6838\u9700\u6c42\u3002", "conclusion": "RealDevWorld\u6846\u67b6\u80fd\u591f\u81ea\u52a8\u3001\u53ef\u6269\u5c55\u4e14\u4e0e\u4eba\u5de5\u4e00\u81f4\u5730\u8bc4\u4f30\u5927\u6a21\u578b\u751f\u6210\u7684\u751f\u4ea7\u7ea7\u5e94\u7528\u8f6f\u4ef6\uff0c\u63a8\u8fdb\u4e86\u8f6f\u4ef6\u667a\u80fd\u751f\u6210\u7684\u8bc4\u6d4b\u65b9\u6cd5\u3002"}}
{"id": "2508.14274", "categories": ["cs.FL"], "pdf": "https://arxiv.org/pdf/2508.14274", "abs": "https://arxiv.org/abs/2508.14274", "authors": ["Mona Alluwayma", "Yong Li", "Sven Schewe", "Qiyi Tang"], "title": "Efficient Learning of Weak Deterministic B\u00fcchi Automata", "comment": "accepted at 28th European Conference on Artificial Intelligence (ECAI\n  2025), 9 pages, 6 figures", "summary": "We present an efficient Angluin-style learning algorithm for weak\ndeterministic B\\\"uchi automata (wDBAs). Different to ordinary deterministic\nB\\\"uchi and co-B\\\"uchi automata, wDBAs have a minimal normal form, and we show\nthat we can learn this minimal normal form efficiently. We provide an improved\nresult on the number of queries required and show on benchmarks that this\ntheoretical advantage translates into significantly fewer queries: while\nprevious approaches require a quintic number of queries, we only require\nquadratically many queries in the size of the canonic wDBA that recognises the\ntarget language.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684wDBA\u5b66\u4e60\u7b97\u6cd5\uff0c\u5c06\u67e5\u8be2\u590d\u6742\u5ea6\u4ece\u4e94\u6b21\u65b9\u964d\u81f3\u4e8c\u6b21\u65b9\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u76f8\u6bd4\u4e8e\u666e\u901a\u7684\u786e\u5b9a\u6027B\u00fcchi\u548cco-B\u00fcchi\u81ea\u52a8\u673a\uff0cwDBA\u5b58\u5728\u53ef\u552f\u4e00\u786e\u5b9a\u7684\u6700\u5c0f\u89c4\u8303\u5f62\u5f0f\uff0c\u4e14\u73b0\u6709\u5b66\u4e60\u65b9\u6cd5\u67e5\u8be2\u590d\u6742\u5ea6\u8f83\u9ad8\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u7814\u7a76\u66f4\u9ad8\u6548\u7684\u5b66\u4e60\u7b97\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u5b66\u4e60\u7b97\u6cd5\uff0c\u5c06\u76ee\u6807\u8bed\u8a00\u7684wDBA\u5f52\u7ea6\u4e3a\u5176\u6700\u5c0f\u89c4\u8303\u5f62\u5f0f\uff0c\u5206\u6790\u548c\u6539\u8fdb\u4e86\u67e5\u8be2\u590d\u6742\u5ea6\uff0c\u5e76\u4e0e\u4ee5\u5f80\u65b9\u6cd5\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u7406\u8bba\u4e0a\u5c06\u67e5\u8be2\u590d\u6742\u5ea6\u4ece\u4e94\u6b21\u65b9\u964d\u81f3\u4e8c\u6b21\u65b9\uff0c\u5e76\u901a\u8fc7\u57fa\u51c6\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5b9e\u9645\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u6240\u9700\u7684\u67e5\u8be2\u6b21\u6570\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u57fa\u4e8eAngluin\u98ce\u683c\u7684\u7b97\u6cd5\uff0c\u80fd\u6709\u6548\u5b66\u4e60\u5f31\u786e\u5b9a\u6027B\u00fcchi\u81ea\u52a8\u673a\uff08wDBA\uff09\u7684\u6700\u5c0f\u89c4\u8303\u5f62\u5f0f\uff0c\u5e76\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u5747\u63d0\u5347\u4e86\u5b66\u4e60\u6548\u7387\u3002"}}
{"id": "2508.14394", "categories": ["cs.PL", "cs.SE", "D.3; D.2.5; G.3"], "pdf": "https://arxiv.org/pdf/2508.14394", "abs": "https://arxiv.org/abs/2508.14394", "authors": ["Ryan Tjoa", "Poorva Garg", "Harrison Goldstein", "Todd Millstein", "Benjamin Pierce", "Guy Van den Broeck"], "title": "Tuning Random Generators: Property-Based Testing as Probabilistic Programming", "comment": "Extended version of OOPSLA '25 paper", "summary": "Property-based testing validates software against an executable specification\nby evaluating it on randomly generated inputs. The standard way that PBT users\ngenerate test inputs is via generators that describe how to sample test inputs\nthrough random choices. To achieve a good distribution over test inputs, users\nmust tune their generators, i.e., decide on the weights of these individual\nrandom choices. Unfortunately, it is very difficult to understand how to choose\nindividual generator weights in order to achieve a desired distribution, so\ntoday this process is tedious and limits the distributions that can be\npractically achieved.\n  In this paper, we develop techniques for the automatic and offline tuning of\ngenerators. Given a generator with undetermined symbolic weights and an\nobjective function, our approach automatically learns values for these weights\nthat optimize for the objective. We describe useful objective functions that\nallow users to (1) target desired distributions and (2) improve the diversity\nand validity of their test cases. We have implemented our approach in a novel\ndiscrete probabilistic programming system, Loaded Dice, that supports\ndifferentiation and parameter learning, and use it as a language for\ngenerators. We empirically demonstrate that our approach is effective at\noptimizing generator distributions according to the specified objective\nfunctions. We also perform a thorough evaluation on PBT benchmarks,\ndemonstrating that, when automatically tuned for diversity and validity, the\ngenerators exhibit a 3.1-7.4x speedup in bug finding.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5229\u7528\u6982\u7387\u7f16\u7a0b\u7cfb\u7edf\u81ea\u52a8\u8c03\u4f18PBT\u6d4b\u8bd5\u8f93\u5165\u751f\u6210\u5668\u6743\u91cd\u7684\u65b9\u6cd5\uff0c\u80fd\u5927\u5e45\u63d0\u5347\u6d4b\u8bd5\u5206\u5e03\u8d28\u91cf\u548cbug\u53d1\u73b0\u6548\u7387\u3002", "motivation": "\u5728\u5c5e\u6027\u57fa\u7840\u6d4b\u8bd5\uff08PBT\uff09\u4e2d\uff0c\u4e3a\u4e86\u751f\u6210\u5177\u6709\u826f\u597d\u5206\u5e03\u7684\u6d4b\u8bd5\u8f93\u5165\uff0c\u7528\u6237\u9700\u5fae\u8c03\u751f\u6210\u5668\u6743\u91cd\uff0c\u4f46\u624b\u52a8\u8c03\u6574\u6743\u91cd\u56f0\u96be\u4e14\u8017\u65f6\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u53ef\u8fbe\u7684\u6d4b\u8bd5\u8f93\u5165\u5206\u5e03\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u3001\u79bb\u7ebf\u8c03\u6574\u751f\u6210\u5668\u6743\u91cd\u7684\u6280\u672f\u3002\u901a\u8fc7\u8ba9\u751f\u6210\u5668\u6743\u91cd\u7b26\u53f7\u5316\uff0c\u5e76\u7ed3\u5408\u76ee\u6807\u51fd\u6570\uff0c\u7cfb\u7edf\u81ea\u52a8\u5b66\u4e60\u6700\u4f18\u6743\u91cd\u3002\u5b9e\u73b0\u5e76\u5e94\u7528\u4e8e\u4e00\u4e2a\u65b0\u9896\u7684\u79bb\u6563\u6982\u7387\u7f16\u7a0b\u7cfb\u7edf Loaded Dice\uff0c\u652f\u6301\u5fae\u5206\u548c\u53c2\u6570\u5b66\u4e60\uff0c\u7528\u4e8e\u751f\u6210\u6d4b\u8bd5\u8f93\u5165\u3002", "result": "\u7cfb\u7edf\u80fd\u6709\u6548\u4f18\u5316\u751f\u6210\u5668\u7684\u5206\u5e03\u4ee5\u6ee1\u8db3\u76ee\u6807\u51fd\u6570\u8981\u6c42\u3002\u5728PBT\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u81ea\u52a8\u8c03\u4f18\u540e\u7684\u751f\u6210\u5668\u5728\u53d1\u73b0bug\u901f\u5ea6\u4e0a\u63d0\u5347\u4e863.1-7.4\u500d\u3002", "conclusion": "\u81ea\u52a8\u5316\u8c03\u4f18\u751f\u6210\u5668\u6743\u91cd\u7684\u65b9\u6cd5\u80fd\u4f7f\u5c5e\u6027\u57fa\u7840\u6d4b\u8bd5\u5728\u5206\u5e03\u8986\u76d6\u548c\u6548\u7387\u4e0a\u5b9e\u73b0\u663e\u8457\u63d0\u5347\uff0c\u964d\u4f4e\u4e86\u624b\u52a8\u8c03\u6574\u96be\u5ea6\uff0c\u6709\u52a9\u4e8e\u53d1\u73b0\u66f4\u591abug\u3002"}}
{"id": "2508.14399", "categories": ["cs.DM", "stat.AP"], "pdf": "https://arxiv.org/pdf/2508.14399", "abs": "https://arxiv.org/abs/2508.14399", "authors": ["Pierre Miasnikof", "Alexander Y. Shetopaloff"], "title": "A statistical test for network similarity", "comment": "19 pages, 8 tables, 5 figures", "summary": "In this article, we revisit and expand our prior work on graph similarity. In\nthis version of our work, we offer an extensive array of empirical tests. We\nalso examine the sensitivity of our test to network variations. Our test\nperforms exactly as expected, on synthetic and real-world graphs. It offers a\nvery accurate measure of graph (dis)similarity.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6269\u5c55\u4e86\u65e9\u671f\u5173\u4e8e\u56fe\u76f8\u4f3c\u6027\u7684\u5de5\u4f5c\uff0c\u901a\u8fc7\u5927\u91cf\u5b9e\u8bc1\u68c0\u9a8c\uff0c\u8bc1\u660e\u6240\u63d0\u51fa\u7684\u6d4b\u8bd5\u65b9\u6cd5\u80fd\u51c6\u786e\u8861\u91cf\u56fe\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u548c\u5dee\u5f02\u6027\uff0c\u65e0\u8bba\u662f\u5728\u5408\u6210\u6570\u636e\u8fd8\u662f\u771f\u5b9e\u7f51\u7edc\u4e2d\u3002", "motivation": "\u4f5c\u8005\u5e0c\u671b\u6539\u8fdb\u56fe\u76f8\u4f3c\u6027\u6d4b\u91cf\u65b9\u6cd5\uff0c\u5e76\u6d4b\u8bd5\u5176\u5728\u4e0d\u540c\u7f51\u7edc\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u8fdb\u884c\u5927\u91cf\u5b9e\u8bc1\u6d4b\u8bd5\uff0c\u5206\u6790\u6d4b\u8bd5\u5bf9\u7f51\u7edc\u53d8\u5316\u7684\u654f\u611f\u6027\uff0c\u5e76\u5728\u5408\u6210\u548c\u771f\u5b9e\u56fe\u6570\u636e\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u6d4b\u8bd5\u65b9\u6cd5\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u56fe\uff08\u5305\u62ec\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u7684\u56fe\uff09\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u80fd\u591f\u51c6\u786e\u6d4b\u91cf\u56fe\u7684\u76f8\u4f3c\u6027\u548c\u5dee\u5f02\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6d4b\u8bd5\u65b9\u6cd5\u80fd\u6709\u6548\u3001\u51c6\u786e\u5730\u8861\u91cf\u56fe\u4e4b\u95f4\u7684\uff08\u4e0d\uff09\u76f8\u4f3c\u6027\uff0c\u4e14\u8868\u73b0\u7b26\u5408\u9884\u671f\u3002"}}
{"id": "2508.14249", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.14249", "abs": "https://arxiv.org/abs/2508.14249", "authors": ["Matthias Hetzenberger", "Georg Moser", "Florian Zuleger"], "title": "To Zip Through the Cost Analysis of Probabilistic Programs", "comment": null, "summary": "Probabilistic programming and the formal analysis of probabilistic algorithms\nare active areas of research, driven by the widespread use of randomness to\nimprove performance. While functional correctness has seen substantial\nprogress, automated reasoning about expected runtime remains comparatively\nlimited. In this work, we address this challenge by introducing a\nrefinement-typed probability monad in Liquid Haskell. Our monad enables\nautomated reasoning about expected values and costs by encoding probabilistic\nbehaviour directly in types. Initially defined for discrete distributions over\nfinite support, it is extended to support infinite distributions via an\naxiomatic approach. By leveraging Liquid Haskell's SMT-based refinement type\nchecking, our framework provides a high degree of automation. We evaluate our\napproach through four case studies: meldable heaps, coupon collector,\nrandomised quicksort, and zip trees. The first two demonstrate automation with\nminimal annotation overhead. The latter two showcase how our monad integrates\nwith interactive proofs, including the first formal verification of the\nexpected runtime of zip trees.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5728Liquid Haskell\u4e2d\u7f16\u7801\u6982\u7387\u884c\u4e3a\u7684\u6982\u7387monad\uff0c\u5b9e\u73b0\u4e86\u6982\u7387\u7b97\u6cd5\u671f\u671b\u8fd0\u884c\u65f6\u95f4\u7684\u81ea\u52a8\u5316\u63a8\u7406\uff0c\u5e76\u5728\u5b9e\u9645\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\uff0c\u63a8\u52a8\u4e86\u6982\u7387\u7a0b\u5e8f\u5206\u6790\u81ea\u52a8\u5316\u7684\u53d1\u5c55\u3002", "motivation": "\u6982\u7387\u7f16\u7a0b\u548c\u6982\u7387\u7b97\u6cd5\u7684\u5f62\u5f0f\u5316\u5206\u6790\u56e0\u5e7f\u6cdb\u4f7f\u7528\u968f\u673a\u6027\u63d0\u5347\u6027\u80fd\u800c\u6210\u4e3a\u7814\u7a76\u70ed\u70b9\uff0c\u4f46\u5173\u4e8e\u671f\u671b\u8fd0\u884c\u65f6\u95f4\u7684\u81ea\u52a8\u5316\u63a8\u7406\u4ecd\u8f83\u4e3a\u6709\u9650\u3002\u8be5\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u81ea\u52a8\u63a8\u7406\u6982\u7387\u7b97\u6cd5\u671f\u671b\u8fd0\u884c\u65f6\u95f4\u7684\u6311\u6218\u3002", "method": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5728Liquid Haskell\u4e2d\u5f15\u5165\u7ec6\u5316\u7c7b\u578b\u6982\u7387monad\uff0c\u5c06\u6982\u7387\u884c\u4e3a\u76f4\u63a5\u7f16\u7801\u5230\u7c7b\u578b\u4e2d\uff0c\u4ece\u800c\u81ea\u52a8\u5316\u63a8\u7406\u671f\u671b\u503c\u548c\u8fd0\u884c\u6210\u672c\u3002\u6700\u521d\u4ec5\u652f\u6301\u6709\u9650\u79bb\u6563\u5206\u5e03\uff0c\u540e\u901a\u8fc7\u516c\u7406\u5316\u65b9\u6cd5\u6269\u5c55\u5230\u65e0\u9650\u5206\u5e03\uff0c\u5e76\u5229\u7528Liquid Haskell\u7684SMT\u9a71\u52a8\u7c7b\u578b\u68c0\u67e5\u63d0\u5347\u81ea\u52a8\u5316\u7a0b\u5ea6\u3002", "result": "\u901a\u8fc7\u56db\u4e2a\u6848\u4f8b\u7814\u7a76\uff08\u53ef\u5408\u5e76\u5806\u3001\u96c6\u6362\u5238\u6536\u96c6\u8005\u3001\u968f\u673a\u5feb\u901f\u6392\u5e8f\u3001zip\u6811\uff09\u8fdb\u884c\u4e86\u65b9\u6cd5\u8bc4\u4f30\u3002\u524d\u4e24\u4e2a\u6848\u4f8b\u663e\u793a\u81ea\u52a8\u5316\u63a8\u7406\u51e0\u4e4e\u65e0\u9700\u989d\u5916\u6807\u6ce8\uff0c\u540e\u4e24\u4e2a\u5c55\u793a\u4e86monad\u4e0e\u4ea4\u4e92\u5f0f\u8bc1\u660e\u7684\u96c6\u6210\uff0c\u5c24\u5176\u5b9e\u73b0\u4e86zip\u6811\u671f\u671b\u8fd0\u884c\u65f6\u95f4\u7684\u9996\u6b21\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7ec6\u5316\u7c7b\u578b\u4e0e\u6982\u7387monad\u7684\u65b0\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u6982\u7387\u7b97\u6cd5\u671f\u671b\u503c\u548c\u8fd0\u884c\u65f6\u95f4\u7684\u81ea\u52a8\u63a8\u7406\uff0c\u5728\u5b9e\u9645\u6848\u4f8b\u4e2d\u5c55\u793a\u4e86\u9ad8\u6548\u6027\u4e0e\u81ea\u52a8\u5316\uff0c\u4e3a\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6982\u7387\u7b97\u6cd5\u6027\u80fd\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002"}}
{"id": "2508.14056", "categories": ["cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2508.14056", "abs": "https://arxiv.org/abs/2508.14056", "authors": ["Sepideh Entezari Maleki", "Mohammadreza Pourreza", "Davood Rafiei"], "title": "Confidence Estimation for Text-to-SQL in Large Language Models", "comment": null, "summary": "Confidence estimation for text-to-SQL aims to assess the reliability of\nmodel-generated SQL queries without having access to gold answers. We study\nthis problem in the context of large language models (LLMs), where access to\nmodel weights and gradients is often constrained. We explore both black-box and\nwhite-box confidence estimation strategies, evaluating their effectiveness on\ncross-domain text-to-SQL benchmarks. Our evaluation highlights the superior\nperformance of consistency-based methods among black-box models and the\nadvantage of SQL-syntax-aware approaches for interpreting LLM logits in\nwhite-box settings. Furthermore, we show that execution-based grounding of\nqueries provides a valuable supplementary signal, improving the effectiveness\nof both approaches.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e0b\u6587\u672c\u5230SQL\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\uff0c\u5206\u522b\u8bc4\u4f30\u4e86\u9ed1\u76d2\u4e00\u81f4\u6027\u3001\u767d\u76d2SQL\u8bed\u6cd5\u589e\u5f3a\u4ee5\u53ca\u6267\u884c\u4fe1\u53f7\u7684\u65b9\u6cd5\u7ec4\u5408\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u7ed3\u5408\u591a\u79cd\u65b9\u6cd5\u80fd\u63d0\u5347\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u53ef\u9760\u6027\u3002", "motivation": "\u6587\u672c\u5230SQL\u7684\u8f6c\u6362\u8fc7\u7a0b\u4e2d\uff0c\u9700\u8bc4\u4f30\u6a21\u578b\u751f\u6210\u7684SQL\u67e5\u8be2\u7684\u53ef\u9760\u6027\uff0c\u800c\u65e0\u9700\u4f9d\u8d56\u6807\u51c6\u7b54\u6848\u3002\u9762\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6743\u91cd\u548c\u68af\u5ea6\u4e0d\u53ef\u83b7\u53d6\u7684\u7ea6\u675f\u4e0b\uff0c\u8fd9\u9879\u5de5\u4f5c\u53d8\u5f97\u66f4\u52a0\u91cd\u8981\u3002", "method": "\u7814\u7a76\u4e86\u9ed1\u76d2\u548c\u767d\u76d2\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u65b9\u6cd5\uff0c\u9ed1\u76d2\u65b9\u6cd5\u7740\u91cd\u4e8e\u4e00\u81f4\u6027\u57fa\u7840\uff0c\u800c\u767d\u76d2\u65b9\u6cd5\u7ed3\u5408SQL\u8bed\u6cd5\u4fe1\u606f\u5229\u7528LLMs\u7684logits\u3002\u6b64\u5916\uff0c\u5206\u6790\u4e86\u57fa\u4e8eSQL\u6267\u884c\u7ed3\u679c\u7684\u589e\u5f3a\u4fe1\u53f7\u5bf9\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u7684\u8f85\u52a9\u4f5c\u7528\u3002", "result": "\u4e00\u81f4\u6027\u65b9\u6cd5\u5728\u9ed1\u76d2\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u4e2d\u8868\u73b0\u6700\u4f73\uff1b\u800c\u5173\u6ce8SQL\u8bed\u6cd5\u5e76\u5229\u7528LLM logits\u7684\u767d\u76d2\u65b9\u6cd5\u5219\u5728\u89e3\u91ca\u6027\u4e0a\u66f4\u5177\u4f18\u52bf\u3002\u901a\u8fc7\u6267\u884c\u67e5\u8be2\u83b7\u5f97\u7684\u5b9e\u9645\u4fe1\u53f7\u80fd\u663e\u8457\u63d0\u9ad8\u8fd9\u4e24\u7c7b\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7efc\u5408\u9ed1\u76d2\u4e00\u81f4\u6027\u548c\u767d\u76d2\u8bed\u6cd5\u589e\u5f3a\u65b9\u6cd5\u540e\uff0c\u7ed3\u5408\u6267\u884c\u7ed3\u679c\u53ef\u4ee5\u66f4\u51c6\u786e\u5730\u4f30\u8ba1\u6587\u672c\u5230SQL\u7684\u7f6e\u4fe1\u5ea6\uff0c\u9002\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u573a\u666f\u3002"}}
{"id": "2508.14114", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14114", "abs": "https://arxiv.org/abs/2508.14114", "authors": ["Aditey Nandan", "Viraj Kumar"], "title": "Ambiguity Resolution with Human Feedback for Code Writing Tasks", "comment": "Accepted at the Proceedings of the 33rd International Conference on\n  Computers in Education (ICCE 2025), Asia-Pacific Society for Computers in\n  Education (APSCE)", "summary": "Specifications for code writing tasks are usually expressed in natural\nlanguage and may be ambiguous. Programmers must therefore develop the ability\nto recognize ambiguities in task specifications and resolve them by asking\nclarifying questions. We present and evaluate a prototype system, based on a\nnovel technique (ARHF: Ambiguity Resolution with Human Feedback), that (1)\nsuggests specific inputs on which a given task specification may be ambiguous,\n(2) seeks limited human feedback about the code's desired behavior on those\ninputs, and (3) uses this feedback to generate code that resolves these\nambiguities. We evaluate the efficacy of our prototype, and we discuss the\nimplications of such assistive systems on Computer Science education.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faARHF\u6280\u672f\uff0c\u901a\u8fc7\u81ea\u52a8\u68c0\u6d4b\u6b67\u4e49\u3001\u83b7\u53d6\u4eba\u7c7b\u53cd\u9988\u751f\u6210\u660e\u786e\u4ee3\u7801\uff0c\u63d0\u5347\u7a0b\u5e8f\u5458\u5904\u7406\u4efb\u52a1\u6b67\u4e49\u7684\u80fd\u529b\uff0c\u5bf9\u7f16\u7a0b\u6559\u80b2\u6709\u79ef\u6781\u5f71\u54cd\u3002", "motivation": "\u4ee3\u7801\u7f16\u5199\u4efb\u52a1\u7684\u89c4\u8303\u5e38\u7528\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\uff0c\u5bb9\u6613\u4ea7\u751f\u6b67\u4e49\uff0c\u7a0b\u5e8f\u5458\u9700\u8981\u5177\u5907\u8bc6\u522b\u548c\u6d88\u9664\u4efb\u52a1\u6b67\u4e49\u7684\u80fd\u529b\u3002\u672c\u6587\u5e0c\u671b\u501f\u52a9\u8f85\u52a9\u7cfb\u7edf\u63d0\u5347\u8fd9\u4e00\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6280\u672fARHF\uff08\u4eba\u7c7b\u53cd\u9988\u7684\u6b67\u4e49\u6d88\u89e3\uff09\uff0c\u8ba9\u7cfb\u7edf\u81ea\u52a8\u8bc6\u522b\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u4e2d\u7684\u6f5c\u5728\u6b67\u4e49\uff0c\u9488\u5bf9\u5177\u4f53\u8f93\u5165\u5bfb\u6c42\u4eba\u7c7b\u53cd\u9988\uff0c\u5e76\u5229\u7528\u53cd\u9988\u751f\u6210\u65e0\u6b67\u4e49\u7684\u4ee3\u7801\u3002\u5e76\u901a\u8fc7\u539f\u578b\u7cfb\u7edf\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u539f\u578b\u7cfb\u7edf\u53ef\u81ea\u52a8\u68c0\u6d4b\u6b67\u4e49\u8f93\u5165\u3001\u6709\u6548\u6536\u96c6\u4eba\u7c7b\u53cd\u9988\uff0c\u5e76\u636e\u6b64\u751f\u6210\u6d88\u89e3\u6b67\u4e49\u7684\u4ee3\u7801\u3002\u7cfb\u7edf\u6027\u80fd\u5f97\u5230\u4e86\u5b9e\u8bc1\u8bc4\u4f30\u3002", "conclusion": "ARHF\u6280\u672f\u548c\u539f\u578b\u7cfb\u7edf\u80fd\u8f85\u52a9\u7a0b\u5e8f\u5458\u8bc6\u522b\u548c\u89e3\u51b3\u89c4\u8303\u6b67\u4e49\uff0c\u5bf9\u4e8e\u63d0\u9ad8\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u8d28\u91cf\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2508.14614", "categories": ["cs.PL", "D.3.0; D.3.1"], "pdf": "https://arxiv.org/pdf/2508.14614", "abs": "https://arxiv.org/abs/2508.14614", "authors": ["Ashish Mishra", "Suresh Jagannathan"], "title": "Close is Good Enough: Component-Based Synthesis Modulo Logical Similarity", "comment": null, "summary": "Component-based synthesis (CBS) aims to generate loop-free programs from a\nset of libraries whose methods are annotated with specifications and whose\noutput must satisfy a set of logical constraints, expressed as a query. The\neffectiveness of a CBS algorithm critically depends on the severity of the\nconstraints imposed by the query. The more exact these constraints are, the\nsparser the space of feasible solutions. This maxim also applies when we enrich\nthe expressiveness of the specifications affixed to library methods. In both\ncases, the search must now contend with constraints that may only hold over a\nsmall number of the possible execution paths that can be enumerated by a CBS\nprocedure.\n  In this paper, we address this challenge by equipping CBS search with the\nability to reason about logical similarities among the paths it explores. Our\nsetting considers library methods equipped with refinement-type specifications\nthat enrich ordinary base types with a set of rich logical qualifiers to\nconstrain the set of values accepted by that type. We perform a search over a\ntree automata variant called Qualified Tree Automata that intelligently records\ninformation about enumerated terms, leveraging subtyping constraints over the\nrefinement types associated with these terms to enable reasoning about\nsimilarity among candidate solutions as search proceeds, thereby avoiding\nexploration of semantically similar paths.\n  We present an implementation of this idea in a tool called \\name, and provide\na comprehensive evaluation that demonstrates \\name's ability to synthesize\nsolutions to complex CBS queries that go well-beyond the capabilities of the\nexisting state-of-the-art.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u903b\u8f91\u76f8\u4f3c\u6027\u548c\u7c7b\u578b\u7ea6\u675f\u7684CBS\u7b97\u6cd5\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7Qualified Tree Automata\u4f18\u5316\u641c\u7d22\u8fc7\u7a0b\uff0c\u5e76\u5b9e\u73b0\u4e86\u5de5\u5177\\name\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u66f4\u590d\u6742\u7684CBS\u95ee\u9898\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "CBS\u7b97\u6cd5\u7684\u6709\u6548\u6027\u53d7\u5230\u67e5\u8be2\u7ea6\u675f\u7684\u5f71\u54cd\uff0c\u9762\u5bf9\u590d\u6742\u4e14\u7a00\u758f\u7684\u53ef\u884c\u65b9\u6848\u7a7a\u95f4\u65f6\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\uff0c\u56e0\u6b64\u4f5c\u8005\u63d0\u51fa\u63d0\u5347CBS\u641c\u7d22\u80fd\u529b\u7684\u9700\u6c42\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u589e\u5f3aCBS\u641c\u7d22\uff0c\u4f7f\u5176\u80fd\u591f\u63a8\u7406\u63a2\u7d22\u8def\u5f84\u95f4\u7684\u903b\u8f91\u76f8\u4f3c\u6027\u3002\u5229\u7528\u5177\u5907\u4e30\u5bcc\u903b\u8f91\u9650\u5b9a\u7b26\u7684\u7cbe\u5316\u7c7b\u578b\u89c4\u8303\u7684\u5e93\u65b9\u6cd5\uff0c\u91c7\u7528Qualified Tree Automata\u53d8\u4f53\u8bb0\u5f55\u679a\u4e3e\u9879\u7684\u4fe1\u606f\uff0c\u901a\u8fc7\u7cbe\u5316\u7c7b\u578b\u7684\u5b50\u7c7b\u578b\u7ea6\u675f\uff0c\u907f\u514d\u641c\u7d22\u8bed\u4e49\u8fd1\u4f3c\u7684\u8def\u5f84\u3002", "result": "\u4f5c\u8005\u5b9e\u73b0\u4e86\u8fd9\u4e00\u601d\u8def\u7684\u5de5\u5177\uff08\u79f0\u4e3a\\name\uff09\uff0c\u5e76\u901a\u8fc7\u5168\u9762\u7684\u8bc4\u4f30\u5c55\u793a\u4e86\u5176\u80fd\u5408\u6210\u8fdc\u8d85\u73b0\u6709\u6280\u672f\u590d\u6742CBS\u67e5\u8be2\u7684\u65b9\u6848\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u8def\u5f84\u95f4\u903b\u8f91\u76f8\u4f3c\u6027\u53ca\u7c7b\u578b\u95f4\u7684\u7ea6\u675f\uff0c\u6709\u6548\u63d0\u5347\u4e86CBS\u7684\u5408\u6210\u80fd\u529b\u548c\u6548\u7387\uff0c\u6269\u5c55\u4e86\u5176\u5728\u590d\u6742\u7ea6\u675f\u4e0b\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2508.14531", "categories": ["cs.LO", "quant-ph"], "pdf": "https://arxiv.org/pdf/2508.14531", "abs": "https://arxiv.org/abs/2508.14531", "authors": ["Julien Saan Joachim", "Marc de Visme", "Stefan Haar"], "title": "Quantum Petri Nets with Event Structures semantics", "comment": null, "summary": "Classical Petri nets provide a canonical model of concurrency, with unfolding\nsemantics linking nets, occurrence nets, and event structures. No comparable\nframework exists for quantum concurrency: existing ''quantum Petri nets'' lack\nrigorous concurrent and sound quantum semantics, analysis tools, and unfolding\ntheory. We introduce Quantum Petri Nets (QPNs), Petri nets equipped with a\nquantum valuation compatible with the quantum event structure semantics of\nClairambault, De Visme, and Winskel (2019). Our contributions are: (i) a local\ndefinition of Quantum Occurrence Nets (LQONs) compatible with quantum event\nstructures, (ii) a construction of QPNs with a well-defined unfolding\nsemantics, (iii) a compositional framework for QPNs. This establishes a\nsemantically well grounded model of quantum concurrency, bridging Petri net\ntheory and quantum programming.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u91cf\u5b50Petri\u7f51\uff08QPNs\uff09\u53ca\u5176\u5c55\u5f00\u548c\u7ec4\u5408\u7406\u8bba\uff0c\u5f25\u8865\u4e86\u91cf\u5b50\u5e76\u53d1\u5efa\u6a21\u7684\u7406\u8bba\u7a7a\u767d\uff0c\u4e3a\u91cf\u5b50\u7a0b\u5e8f\u548c\u5e76\u53d1\u5206\u6790\u5de5\u5177\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002", "motivation": "\u4f20\u7edf\u7684Petri\u7f51\u5728\u5e76\u53d1\u5efa\u6a21\u65b9\u9762\u6709\u7740\u6210\u719f\u7684\u7406\u8bba\u548c\u5de5\u5177\uff0c\u4f46\u5728\u91cf\u5b50\u5e76\u53d1\u9886\u57df\uff0c\u76ee\u524d\u7f3a\u4e4f\u7c7b\u4f3c\u7684\u3001\u4e25\u5bc6\u7684\u7406\u8bba\u6846\u67b6\u3002\u73b0\u6709\u7684\u201c\u91cf\u5b50Petri\u7f51\u201d\u65e0\u6cd5\u63d0\u4f9b\u5b8c\u5584\u7684\u91cf\u5b50\u8bed\u4e49\u4e0e\u5e76\u53d1\u5206\u6790\u5de5\u5177\u53ca\u7406\u8bba\u57fa\u7840\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86Quantum Petri Nets\uff08QPNs\uff09\uff0c\u5e76\u7ed3\u5408\u4e86\u91cf\u5b50\u4e8b\u4ef6\u7ed3\u6784\u7684\u8bed\u4e49\u8fdb\u884c\u5efa\u6a21\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a\uff08i\uff09\u63d0\u51fa\u4e86\u517c\u5bb9\u91cf\u5b50\u4e8b\u4ef6\u7ed3\u6784\u7684\u5c40\u90e8\u91cf\u5b50\u53d1\u751f\u7f51\uff08LQONs\uff09\uff1b\uff08ii\uff09\u6784\u5efa\u4e86\u5177\u6709\u660e\u786e\u5b9a\u4e49\u7684\u5c55\u5f00\u8bed\u4e49\u7684QPNs\uff1b\uff08iii\uff09\u5efa\u7acb\u4e86QPNs\u7684\u7ec4\u5408\u5f0f\u6846\u67b6\u3002", "result": "\u4f5c\u8005\u5efa\u7acb\u4e86\u4e00\u79cd\u8bed\u4e49\u4e0a\u6709\u575a\u5b9e\u57fa\u7840\u7684\u91cf\u5b50\u5e76\u53d1\u6a21\u578b\uff0c\u4f7fPetri\u7f51\u7406\u8bba\u80fd\u591f\u5ef6\u4f38\u5230\u91cf\u5b50\u7f16\u7a0b\u9886\u57df\uff0c\u586b\u8865\u4e86\u91cf\u5b50Petri\u7f51\u5728\u5c55\u5f00\u8bed\u4e49\u548c\u7ec4\u5408\u5f0f\u5efa\u6a21\u4e0a\u7684\u7a7a\u767d\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u9996\u6b21\u5728\u91cf\u5b50\u5e76\u53d1\u9886\u57df\u6784\u5efa\u4e86\u4e0e\u4f20\u7edfPetri\u7f51\u7406\u8bba\u540c\u7b49\u4e25\u5bc6\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u91cf\u5b50\u5e76\u53d1\u548c\u91cf\u5b50\u7a0b\u5e8f\u5206\u6790\u5de5\u5177\u7684\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2508.14062", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14062", "abs": "https://arxiv.org/abs/2508.14062", "authors": ["Badrinath Ramakrishnan", "Akshaya Balaji"], "title": "Assessing and Mitigating Data Memorization Risks in Fine-Tuned Large Language Models", "comment": "14 pages, 2 figures. Code and experimental framework available at\n  https://github.com/akshayaaa10/llm-privacy-research", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\ndiverse natural language processing tasks, but their tendency to memorize\ntraining data poses significant privacy risks, particularly during fine-tuning\nprocesses. This paper presents a comprehensive empirical analysis of data\nmemorization in fine-tuned LLMs and introduces a novel multi-layered privacy\nprotection framework. Through controlled experiments on modern LLM\narchitectures including GPT-2, Phi-3, and Gemma-2, we demonstrate that\nfine-tuning with repeated sensitive data increases privacy leakage rates from\nbaseline levels of 0-5% to 60-75%, representing a 64.2% average increase across\ntested models. We propose and rigorously evaluate four complementary privacy\nprotection methods: semantic data deduplication, differential privacy during\ngeneration, entropy-based filtering, and pattern-based content filtering. Our\nexperimental results show that these techniques can reduce data leakage to 0%\nwhile maintaining 94.7% of original model utility.", "AI": {"tldr": "\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u4f1a\u663e\u8457\u589e\u52a0\u9690\u79c1\u6570\u636e\u6cc4\u6f0f\u98ce\u9669\uff0c\u672c\u6587\u63d0\u51fa\u7684\u591a\u5c42\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u53ef\u6709\u6548\u9632\u6b62\u6570\u636e\u6cc4\u6f0f\uff0c\u4e14\u6a21\u578b\u6027\u80fd\u51e0\u4e4e\u4e0d\u53d7\u5f71\u54cd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5404\u79cd\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u5bb9\u6613\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\uff0c\u5e26\u6765\u4e25\u91cd\u7684\u9690\u79c1\u98ce\u9669\u3002\u672c\u7814\u7a76\u65e8\u5728\u8be6\u7ec6\u5206\u6790LLMs\u5fae\u8c03\u65f6\u7684\u6570\u636e\u8bb0\u5fc6\u73b0\u8c61\uff0c\u5e76\u63a2\u7d22\u6709\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u57fa\u4e8e\u73b0\u6709\u4e3b\u6d41LLMs\u5982GPT-2\u3001Phi-3\u548cGemma-2\uff0c\u8bbe\u8ba1\u4e86\u5305\u542b\u91cd\u590d\u654f\u611f\u6570\u636e\u7684\u5bf9\u7167\u5b9e\u9a8c\uff0c\u6d4b\u8bd5\u5fae\u8c03\u540e\u6570\u636e\u6cc4\u6f0f\u7684\u6bd4\u4f8b\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u8bed\u4e49\u53bb\u91cd\u3001\u751f\u6210\u65f6\u5dee\u5206\u9690\u79c1\u3001\u57fa\u4e8e\u71b5\u7684\u8fc7\u6ee4\u548c\u57fa\u4e8e\u6a21\u5f0f\u7684\u5185\u5bb9\u8fc7\u6ee4\u56db\u79cd\u9690\u79c1\u9632\u62a4\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5fae\u8c03\u65f6\u5982\u5305\u542b\u91cd\u590d\u654f\u611f\u6570\u636e\uff0c\u9690\u79c1\u6cc4\u6f0f\u7387\u4ece\u57fa\u7ebf\u76840-5%\u663e\u8457\u4e0a\u5347\u523060-75%\uff0c\u5e73\u5747\u4e0a\u534764.2%\u3002\u7ecf\u8fc7\u56db\u79cd\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u5904\u7406\u540e\uff0c\u6570\u636e\u6cc4\u6f0f\u7387\u53ef\u964d\u81f30%\uff0c\u4e14\u6a21\u578b\u6548\u7528\u53ef\u4fdd\u755994.7%\u3002", "conclusion": "\u5fae\u8c03LLMs\u5e26\u6765\u663e\u8457\u9690\u79c1\u98ce\u9669\uff0c\u4f46\u7ec4\u5408\u591a\u5c42\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u80fd\u517c\u987e\u9690\u79c1\u4e0e\u6a21\u578b\u6548\u7528\uff0c\u57fa\u672c\u6d88\u9664\u6570\u636e\u6cc4\u6f0f\u9690\u60a3\u3002"}}
{"id": "2508.14288", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.14288", "abs": "https://arxiv.org/abs/2508.14288", "authors": ["Yewei Song", "Tiezhu Sun", "Xunzhu Tang", "Prateek Rajput", "Tegawende F. Bissyande", "Jacques Klein"], "title": "Measuring LLM Code Generation Stability via Structural Entropy", "comment": "ASE-NIER", "summary": "Assessing the stability of code generation from large language models (LLMs)\nis essential for judging their reliability in real-world development. We extend\nprior \"structural-entropy concepts\" to the program domain by pairing entropy\nwith abstract syntax tree (AST) analysis. For any fixed prompt, we collect the\nmultiset of depth-bounded subtrees of AST in each generated program and treat\ntheir relative frequencies as a probability distribution. We then measure\nstability in two complementary ways: (i) Jensen-Shannon divergence, a\nsymmetric, bounded indicator of structural overlap, and (ii) a Structural\nCross-Entropy ratio that highlights missing high-probability patterns. Both\nmetrics admit structural-only and token-aware variants, enabling separate views\non control-flow shape and identifier-level variability. Unlike pass@k, BLEU, or\nCodeBLEU, our metrics are reference-free, language-agnostic, and\nexecution-independent. We benchmark several leading LLMs on standard code\ngeneration tasks, demonstrating that AST-driven structural entropy reveals\nnuances in model consistency and robustness. The method runs in O(n,d) time\nwith no external tests, providing a lightweight addition to the code-generation\nevaluation toolkit.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAST\u5b50\u6811\u5206\u5e03\u7684\u7ed3\u6784\u71b5\u5206\u6790\u6cd5\uff0c\u80fd\u591f\u65e0\u53c2\u8003\u3001\u65e0\u6267\u884c\u5224\u65ad\u3001\u8de8\u8bed\u8a00\u5730\u8bc4\u4f30LLM\u751f\u6210\u4ee3\u7801\u7684\u7a33\u5b9a\u6027\uff0c\u5e76\u7528\u8be5\u65b9\u6cd5\u63ed\u793a\u4e86\u4e3b\u6d41\u6a21\u578b\u5728\u4e00\u81f4\u6027\u548c\u5065\u58ee\u6027\u4e0a\u7684\u5dee\u5f02\uff0c\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u5b9e\u7528\u7684\u65b0\u8bc4\u4ef7\u5de5\u5177\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4ee3\u7801\u751f\u6210\u9886\u57df\u7684\u5e94\u7528\u9010\u6e10\u5e7f\u6cdb\uff0c\u4f46\u8bc4\u4f30\u5176\u751f\u6210\u4ee3\u7801\u7684\u7a33\u5b9a\u6027\u5bf9\u5b9e\u9645\u5f00\u53d1\u7684\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u6307\u6807\u5982pass@k\u3001BLEU\u7b49\u5b58\u5728\u4f9d\u8d56\u53c2\u8003\u7b54\u6848\u3001\u7279\u5b9a\u8bed\u8a00\u6216\u6267\u884c\u4f9d\u8d56\u7b49\u5c40\u9650\uff0c\u96be\u4ee5\u5168\u9762\u53cd\u6620\u4ee3\u7801\u751f\u6210\u7684\u4e00\u81f4\u6027\u548c\u7ed3\u6784\u7a33\u5065\u6027\u3002", "method": "\u8be5\u8bba\u6587\u5c06\u7ed3\u6784\u71b5\uff08structural-entropy\uff09\u6269\u5c55\u5230\u7a0b\u5e8f\u9886\u57df\uff0c\u5e76\u7ed3\u5408\u62bd\u8c61\u8bed\u6cd5\u6811\uff08AST\uff09\u5206\u6790\u3002\u5177\u4f53\u505a\u6cd5\u4e3a\uff1a\u9488\u5bf9\u67d0\u4e00\u56fa\u5b9a\u63d0\u793a\uff0c\u4ece\u6bcf\u4e2a\u751f\u6210\u7a0b\u5e8f\u4e2d\u6536\u96c6AST\u7684\u9650\u5b9a\u6df1\u5ea6\u5b50\u6811\u96c6\u5408\uff0c\u5e76\u5c06\u5176\u76f8\u5bf9\u9891\u7387\u89c6\u4e3a\u6982\u7387\u5206\u5e03\u3002\u968f\u540e\uff0c\u91c7\u7528Jensen-Shannon\u6563\u5ea6\u548c\u7ed3\u6784\u4ea4\u53c9\u71b5\u6bd4\u7387\u4e24\u79cd\u65b9\u5f0f\u8bc4\u4f30\u4ee3\u7801\u751f\u6210\u7684\u7a33\u5b9a\u6027\u3002\u8fd9\u4e24\u79cd\u5ea6\u91cf\u65e2\u6709\u4ec5\u5173\u6ce8\u7ed3\u6784\u7684\u5f62\u5f0f\uff0c\u4e5f\u6709\u5173\u6ce8\u6807\u8bc6\u7b26\u7b49Token\u7ec6\u8282\u7684\u53d8\u4f53\uff0c\u65e0\u9700\u53c2\u8003\u7b54\u6848\u3001\u6267\u884c\u6216\u8bed\u8a00\u7279\u5b9a\u4fe1\u606f\u3002", "result": "\u7528\u8be5\u65b9\u6cd5\u5728\u4e3b\u6d41\u4ee3\u7801\u751f\u6210LLM\u53ca\u6807\u51c6\u4efb\u52a1\u96c6\u4e0a\u8fdb\u884c\u8bc4\u6d4b\uff0c\u7ed3\u679c\u663e\u793a\uff1a\u57fa\u4e8eAST\u7684\u7ed3\u6784\u71b5\u80fd\u591f\u63ed\u793a\u6a21\u578b\u5728\u4e00\u81f4\u6027\u548c\u5065\u58ee\u6027\u65b9\u9762\u66f4\u7ec6\u5fae\u7684\u8868\u73b0\u5dee\u5f02\u3002\u6b64\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u4f4e\uff08O(n,d)\uff09\uff0c\u65e0\u9700\u5916\u90e8\u6d4b\u8bd5\uff0c\u9002\u5408\u4f5c\u4e3a\u8f7b\u91cf\u7ea7\u4ee3\u7801\u751f\u6210\u8bc4\u6d4b\u5de5\u5177\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u7684\u7ed3\u6784\u71b5\u8bc4\u4f30\u65b9\u6cd5\u80fd\u66f4\u52a0\u5168\u9762\u4e14\u9ad8\u6548\u5730\u8861\u91cfLLM\u4ee3\u7801\u751f\u6210\u7a33\u5b9a\u6027\uff0c\u7a81\u7834\u4e86\u73b0\u6709\u6307\u6807\u7684\u591a\u9879\u9650\u5236\uff0c\u4e3a\u540e\u7eed\u76f8\u5173\u7814\u7a76\u548c\u5b9e\u9645\u5f00\u53d1\u5e94\u7528\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2508.14851", "categories": ["cs.LO", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.14851", "abs": "https://arxiv.org/abs/2508.14851", "authors": ["Rados\u0142aw Jan Rowicki", "Adrian Francalanza", "Alceste Scalas"], "title": "Correct Black-Box Monitors for Distributed Deadlock Detection: Formalisation and Implementation (Technical Report)", "comment": null, "summary": "Many software applications rely on concurrent and distributed (micro)services\nthat interact via message-passing and various forms of remote procedure calls\n(RPC). As these systems organically evolve and grow in scale and complexity,\nthe risk of introducing deadlocks increases and their impact may worsen: even\nif only a few services deadlock, many other services may block while awaiting\nresponses from the deadlocked ones. As a result, the \"core\" of the deadlock can\nbe obfuscated by its consequences on the rest of the system, and diagnosing and\nfixing the problem can be challenging.\n  In this work we tackle the challenge by proposing distributed black-box\nmonitors that are deployed alongside each service and detect deadlocks by only\nobserving the incoming and outgoing messages, and exchanging probes with other\nmonitors. We present a formal model that captures popular RPC-based application\nstyles (e.g., gen_servers in Erlang/OTP), and a distributed black-box\nmonitoring algorithm that we prove sound and complete (i.e., identifies\ndeadlocked services with neither false positives nor false negatives). We\nimplement our results in a tool called DDMon for the monitoring of Erlang/OTP\napplications, and we evaluate its performance.\n  This is the first work that formalises, proves the correctness, and\nimplements distributed black-box monitors for deadlock detection. Our results\nare mechanised in Coq. DDMon is the companion artifact of this paper.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5206\u5e03\u5f0f\u5fae\u670d\u52a1\u6b7b\u9501\u96be\u4ee5\u8bca\u65ad\u95ee\u9898\uff0c\u63d0\u51fa\u5e76\u8bc1\u660e\u4e86\u9996\u4e2a\u5206\u5e03\u5f0f\u9ed1\u76d2\u6b7b\u9501\u76d1\u63a7\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u5de5\u5177DDMon\u5728Erlang/OTP\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u6548\u679c\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u5e76\u53d1\u548c\u5206\u5e03\u5f0f\uff08\u5fae\uff09\u670d\u52a1\u7684\u6f14\u5316\uff0c\u5176\u590d\u6742\u5ea6\u548c\u89c4\u6a21\u4e0d\u65ad\u589e\u52a0\uff0c\u6b7b\u9501\u7684\u98ce\u9669\u4e5f\u968f\u4e4b\u5347\u9ad8\u3002\u800c\u6b7b\u9501\u5f71\u54cd\u5f80\u5f80\u4e0d\u4ec5\u9650\u4e8e\u53d1\u751f\u6b7b\u9501\u7684\u670d\u52a1\uff0c\u8fd8\u4f1a\u6ce2\u53ca\u4f9d\u8d56\u5176\u54cd\u5e94\u7684\u5176\u4ed6\u670d\u52a1\uff0c\u4f7f\u5f97\u771f\u6b63\u7684\u6b7b\u9501\u4f4d\u7f6e\u96be\u4ee5\u8bca\u65ad\u548c\u4fee\u590d\u3002\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u9ed1\u76d2\u76d1\u63a7\u65b9\u6cd5\uff1a\u4e3a\u6bcf\u4e2a\u670d\u52a1\u90e8\u7f72\u76d1\u63a7\u5668\uff0c\u4ec5\u901a\u8fc7\u89c2\u5bdf\u8fdb\u51fa\u6d88\u606f\u548c\u4e0e\u5176\u5b83\u76d1\u63a7\u5668\u4ea4\u6362\u63a2\u9488\u5b9e\u73b0\u6b7b\u9501\u68c0\u6d4b\u3002\u5efa\u7acb\u4e86\u8986\u76d6\u6d41\u884cRPC\u5e94\u7528\u6a21\u5f0f\uff08\u5982Erlang/OTP\u7684gen_servers\uff09\u7684\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u63d0\u51fa\u5e76\u8bc1\u660e\u4e86\u5206\u5e03\u5f0f\u9ed1\u76d2\u76d1\u63a7\u7b97\u6cd5\u7684\u6b63\u786e\u6027\uff08\u65e0\u8bef\u62a5\u3001\u6f0f\u62a5\uff09\u3002", "result": "\u7b97\u6cd5\u5df2\u5728\u5de5\u5177DDMon\u4e2d\u5b9e\u73b0\uff0c\u5e76\u9488\u5bf9Erlang/OTP\u5e94\u7528\u8fdb\u884c\u4e86\u6027\u80fd\u8bc4\u4f30\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u5de5\u5177\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u6b7b\u9501\u3002\u76f8\u5173\u7406\u8bba\u7ed3\u679c\u5df2\u5728Coq\u4e2d\u673a\u68b0\u5316\u8bc1\u660e\u3002", "conclusion": "\u9996\u6b21\u5b9e\u73b0\u4e86\u9488\u5bf9RPC\u670d\u52a1\u7684\u5206\u5e03\u5f0f\u9ed1\u76d2\u6b7b\u9501\u76d1\u63a7\u5668\u7684\u5f62\u5f0f\u5316\u3001\u6b63\u786e\u6027\u8bc1\u660e\u53ca\u5b9e\u73b0\uff0c\u5e76\u5c55\u793a\u4e86\u5b9e\u9645\u5de5\u5177DDMon\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2508.14670", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2508.14670", "abs": "https://arxiv.org/abs/2508.14670", "authors": ["Sarah Meng Li", "Michele Mosca", "Neil J. Ross", "John van de Wetering", "Yuming Zhao"], "title": "A Complete and Natural Rule Set for Multi-Qutrit Clifford Circuits", "comment": "In Proceedings QPL 2025, arXiv:2508.13619", "summary": "We present a complete set of rewrite rules for n-qutrit Clifford circuits\nwhere n is any non-negative integer. This is the first completeness result for\nany fragment of quantum circuits in odd prime dimensions. We first generalize\nSelinger's normal form for n-qubit Clifford circuits to the qutrit setting.\nThen, we present a rewrite system by which any Clifford circuit can be reduced\nto this normal form. We then simplify the rewrite rules in this procedure to a\nsmall natural set of rules, giving a clean presentation of the group of qutrit\nClifford unitaries in terms of generators and relations.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u7b2c\u4e00\u5957\u9002\u7528\u4e8en-qutrit Clifford\u7535\u8def\u7684\u5b8c\u5907\u91cd\u5199\u89c4\u5219\uff0c\u7ed9\u51fa\u4e86\u8be5\u7c7b\u7535\u8def\u6b63\u89c4\u5f62\uff0c\u5e76\u4ee5\u7b80\u6d01\u89c4\u5219\u660e\u6670\u63cf\u8ff0\u4e86\u5176\u7fa4\u7ed3\u6784\u3002", "motivation": "\u76ee\u524d\u5173\u4e8e\u91cf\u5b50\u7535\u8def\uff0c\u5c24\u5176\u662f\u5947\u7d20\u6570\u7ef4\u5ea6\u4e0b\u7684\u7406\u8bba\u8fd8\u4e0d\u5b8c\u5584\u3002\u5bf9\u4e8en-qutrit Clifford\u7535\u8def\uff0c\u5c1a\u65e0\u5b8c\u5907\u7684\u91cd\u5199\u89c4\u5219\u96c6\uff0c\u9650\u5236\u4e86\u76f8\u5173\u8ba1\u7b97\u548c\u7406\u8bba\u5206\u6790\u3002", "method": "\u4f5c\u8005\u9996\u5148\u5c06Selinger\u63d0\u51fa\u7684n-qubit Clifford\u7535\u8def\u7684\u6b63\u89c4\u5f62\u63a8\u5e7f\u5230qutrit\u573a\u666f\uff0c\u5efa\u7acb\u4e86\u65b0\u7684\u91cd\u5199\u7cfb\u7edf\uff0c\u7136\u540e\u5c06\u89c4\u5219\u7cbe\u7b80\u4e3a\u5c0f\u800c\u81ea\u7136\u7684\u4e00\u5957\u89c4\u5219\uff0c\u5b8c\u6574\u5730\u7528\u751f\u6210\u5143\u548c\u5173\u7cfb\u63cf\u8ff0\u4e86qutrit Clifford\u5e7a\u6b63\u7fa4\u3002", "result": "\u63d0\u51fa\u4e86\u9996\u4e2a\u9002\u7528\u4e8en-qutrit Clifford\u7535\u8def\uff08n\u4e3a\u4efb\u610f\u975e\u8d1f\u6574\u6570\uff09\u7684\u5b8c\u5907\u91cd\u5199\u89c4\u5219\uff0c\u5e76\u5c06\u8be5\u7c7b\u7535\u8def\u7684\u7fa4\u7ed3\u6784\u4ee5\u751f\u6210\u5143\u4e0e\u5173\u7cfb\u7684\u5f62\u5f0f\u6e05\u6670\u523b\u753b\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u4e3a\u4efb\u4f55\u5947\u7d20\u6570\u7ef4\u5ea6\u4e2d\u7684\u91cf\u5b50\u7535\u8def\u7247\u6bb5\uff08n-qutrit Clifford\u7535\u8def\uff09\u7ed9\u51fa\u5b8c\u5907\u6027\u7ed3\u679c\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u5957\u7b80\u660e\u3001\u6709\u6548\u7684\u751f\u6210\u5143-\u5173\u7cfb\u63cf\u8ff0\u65b9\u6cd5\u3002"}}
{"id": "2508.14067", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14067", "abs": "https://arxiv.org/abs/2508.14067", "authors": ["Sonakshi Chauhan", "Maheep Chaudhary", "Koby Choy", "Samuel Nellessen", "Nandi Schoots"], "title": "Punctuation and Predicates in Language Models", "comment": null, "summary": "In this paper we explore where information is collected and how it is\npropagated throughout layers in large language models (LLMs). We begin by\nexamining the surprising computational importance of punctuation tokens which\nprevious work has identified as attention sinks and memory aids. Using\nintervention-based techniques, we evaluate the necessity and sufficiency (for\npreserving model performance) of punctuation tokens across layers in GPT-2,\nDeepSeek, and Gemma. Our results show stark model-specific differences: for\nGPT-2, punctuation is both necessary and sufficient in multiple layers, while\nthis holds far less in DeepSeek and not at all in Gemma. Extending beyond\npunctuation, we ask whether LLMs process different components of input (e.g.,\nsubjects, adjectives, punctuation, full sentences) by forming early static\nsummaries reused across the network, or if the model remains sensitive to\nchanges in these components across layers. Extending beyond punctuation, we\ninvestigate whether different reasoning rules are processed differently by\nLLMs. In particular, through interchange intervention and layer-swapping\nexperiments, we find that conditional statements (if, then), and universal\nquantification (for all) are processed very differently. Our findings offer new\ninsight into the internal mechanisms of punctuation usage and reasoning in LLMs\nand have implications for interpretability.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u5c42\u7ea7\u5bf9\u6807\u70b9\u53ca\u63a8\u7406\u5143\u7d20\u7684\u5904\u7406\u673a\u5236\uff0c\u53d1\u73b0\u4e0d\u540c\u6a21\u578b\u5bf9\u8fd9\u4e9b\u5143\u7d20\u7684\u91cd\u8981\u6027\u53ca\u5904\u7406\u65b9\u5f0f\u5b58\u5728\u5de8\u5927\u5dee\u5f02\uff0c\u4e3a\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u5e26\u6765\u65b0\u542f\u793a\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63ed\u793a\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5185\u90e8\u4fe1\u606f\u662f\u5982\u4f55\u88ab\u6536\u96c6\u548c\u8de8\u5c42\u4f20\u64ad\u7684\uff0c\u7279\u522b\u5173\u6ce8\u6807\u70b9\u7b26\u53f7\u548c\u4e0d\u540c\u8f93\u5165\u6210\u5206\u5728\u6a21\u578b\u5904\u7406\u8fc7\u7a0b\u4e2d\u7684\u4f5c\u7528\u673a\u5236\u3002", "method": "\u91c7\u7528\u5e72\u9884\u5f0f\u6280\u672f\uff08intervention-based techniques\uff09\u6765\u5206\u6790GPT-2\u3001DeepSeek\u548cGemma\u7b49\u6a21\u578b\u4e2d\u6807\u70b9\u7b26\u53f7\u5728\u5404\u5c42\u7684\u5fc5\u8981\u6027\u548c\u5145\u5206\u6027\uff0c\u5e76\u901a\u8fc7\u4e92\u6362\u5e72\u9884\u548c\u5c42\u4ea4\u6362\u5b9e\u9a8c\uff0c\u7814\u7a76\u6a21\u578b\u5bf9\u63a8\u7406\u89c4\u5219\u7684\u5904\u7406\u65b9\u5f0f\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cGPT-2\u5728\u591a\u4e2a\u5c42\u7ea7\u4e0a\u6807\u70b9\u7b26\u53f7\u65e2\u5fc5\u8981\u53c8\u5145\u5206\uff0c\u800cDeepSeek\u548cGemma\u5219\u660e\u663e\u8f83\u5f31\u3002\u6b64\u5916\uff0c\u6a21\u578b\u5bf9\u4e8e\u6761\u4ef6\u8bed\u53e5\uff08if, then\uff09\u548c\u5168\u79f0\u91cf\u5316\uff08for all\uff09\u7684\u5904\u7406\u65b9\u5f0f\u6709\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5185\u90e8\u5c42\u7ea7\u5904\u7406\u4e2d\u5bf9\u4e8e\u6807\u70b9\u548c\u63a8\u7406\u89c4\u5219\u7684\u5229\u7528\u65b9\u5f0f\u6709\u663e\u8457\u5dee\u5f02\uff0c\u8fd9\u4e3a\u7406\u89e3\u548c\u89e3\u91ca\u6a21\u578b\u5185\u90e8\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2508.14419", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2508.14419", "abs": "https://arxiv.org/abs/2508.14419", "authors": ["Scott Blyth", "Sherlock A. Licorish", "Christoph Treude", "Markus Wagner"], "title": "Static Analysis as a Feedback Loop: Enhancing LLM-Generated Code Beyond Correctness", "comment": null, "summary": "Large language models (LLMs) have demonstrated impressive capabilities in\ncode generation, achieving high scores on benchmarks such as HumanEval and\nMBPP. However, these benchmarks primarily assess functional correctness and\nneglect broader dimensions of code quality, including security, reliability,\nreadability, and maintainability. In this work, we systematically evaluate the\nability of LLMs to generate high-quality code across multiple dimensions using\nthe PythonSecurityEval benchmark. We introduce an iterative static\nanalysis-driven prompting algorithm that leverages Bandit and Pylint to\nidentify and resolve code quality issues. Our experiments with GPT-4o show\nsubstantial improvements: security issues reduced from >40% to 13%, readability\nviolations from >80% to 11%, and reliability warnings from >50% to 11% within\nten iterations. These results demonstrate that LLMs, when guided by static\nanalysis feedback, can significantly enhance code quality beyond functional\ncorrectness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u9759\u6001\u5206\u6790\u5de5\u5177\u9a71\u52a8\u63d0\u793a\u8fed\u4ee3\u63d0\u5347LLM\u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u6027\u3001\u53ef\u8bfb\u6027\u548c\u53ef\u9760\u6027\uff0c\u5728GPT-4o\u548cPythonSecurityEval\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u663e\u8457\u6548\u679c\uff0c\u8bf4\u660eLLM\u901a\u8fc7\u9759\u6001\u53cd\u9988\u80fd\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u4ee3\u7801\u3002", "motivation": "\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4e3b\u6d41\u8bc4\u6d4b\uff08\u5982HumanEval\u548cMBPP\uff09\u4ec5\u5173\u6ce8\u529f\u80fd\u6b63\u786e\u6027\uff0c\u5ffd\u7565\u4e86\u4ee3\u7801\u5b89\u5168\u6027\u3001\u53ef\u8bfb\u6027\u3001\u53ef\u9760\u6027\u7b49\u66f4\u5e7f\u6cdb\u7684\u8d28\u91cf\u7ef4\u5ea6\u3002\u4f5c\u8005\u8ba4\u4e3a\u6709\u5fc5\u8981\u7efc\u5408\u8bc4\u4f30\u548c\u63d0\u5347LLM\u751f\u6210\u4ee3\u7801\u7684\u6574\u4f53\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fed\u4ee3\u9759\u6001\u5206\u6790\u9a71\u52a8\u7684\u63d0\u793a\u7b97\u6cd5\uff0c\u7ed3\u5408Bandit\u548cPylint\u5de5\u5177\u81ea\u52a8\u68c0\u6d4b\u5e76\u4fee\u590d\u4ee3\u7801\u4e2d\u7684\u5b89\u5168\u6027\u3001\u53ef\u8bfb\u6027\u548c\u53ef\u9760\u6027\u7b49\u95ee\u9898\u3002\u5728\u6bcf\u4e00\u8f6e\uff0c\u9759\u6001\u5206\u6790\u53d1\u73b0\u95ee\u9898\u540e\uff0cLLM\u6839\u636e\u53cd\u9988\u518d\u6b21\u751f\u6210\u6539\u8fdb\u540e\u7684\u4ee3\u7801\uff0c\u53cd\u590d\u8fed\u4ee3\u3002\u8bc4\u6d4b\u57fa\u4e8ePythonSecurityEval\u57fa\u51c6\u548cGPT-4o\u6a21\u578b\u8fdb\u884c\u3002", "result": "\u901a\u8fc7\u5341\u8f6e\u8fed\u4ee3\uff0c\u5b89\u5168\u95ee\u9898\u4ece40%\u4ee5\u4e0a\u964d\u81f313%\uff0c\u53ef\u8bfb\u6027\u95ee\u9898\u4ece80%\u4ee5\u4e0a\u964d\u81f311%\uff0c\u53ef\u9760\u6027\u8b66\u544a\u4ece50%\u4ee5\u4e0a\u964d\u81f311%\u3002", "conclusion": "\u7ed3\u5408\u9759\u6001\u5206\u6790\u53cd\u9988\u53ef\u4ee5\u663e\u8457\u63d0\u5347LLM\u751f\u6210\u4ee3\u7801\u5728\u591a\u4e2a\u8d28\u91cf\u7ef4\u5ea6\u4e0a\u7684\u8868\u73b0\uff0c\u7a81\u7834\u4e86\u4ec5\u5173\u6ce8\u529f\u80fd\u6b63\u786e\u6027\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2508.14725", "categories": ["cs.LO", "cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2508.14725", "abs": "https://arxiv.org/abs/2508.14725", "authors": ["Daniel Hausmann", "Shufang Zhu", "Gianmarco Parretti", "Christoph Weinhuber", "Giuseppe De Giacomo", "Nir Piterman"], "title": "Emerson-Lei and Manna-Pnueli Games for LTLf+ and PPLTL+ Synthesis", "comment": null, "summary": "Recently, the Manna-Pnueli Hierarchy has been used to define the temporal\nlogics LTLfp and PPLTLp, which allow to use finite-trace LTLf/PPLTL techniques\nin infinite-trace settings while achieving the expressiveness of full LTL. In\nthis paper, we present the first actual solvers for reactive synthesis in these\nlogics. These are based on games on graphs that leverage DFA-based techniques\nfrom LTLf/PPLTL to construct the game arena. We start with a symbolic solver\nbased on Emerson-Lei games, which reduces lower-class properties (guarantee,\nsafety) to higher ones (recurrence, persistence) before solving the game. We\nthen introduce Manna-Pnueli games, which natively embed Manna-Pnueli objectives\ninto the arena. These games are solved by composing solutions to a DAG of\nsimpler Emerson-Lei games, resulting in a provably more efficient approach. We\nimplemented the solvers and practically evaluated their performance on a range\nof representative formulas. The results show that Manna-Pnueli games often\noffer significant advantages, though not universally, indicating that combining\nboth approaches could further enhance practical performance.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u9002\u7528\u4e8eLTLfp/PPLTLp\u7684\u53cd\u5e94\u5f0f\u7efc\u5408\u6c42\u89e3\u5668\uff0c\u5e76\u5b9e\u73b0\u3001\u8bc4\u4f30\u4e86\u5b83\u4eec\u3002\u5b9e\u9a8c\u8868\u660eManna-Pnueli\u6e38\u620f\u901a\u5e38\u66f4\u9ad8\u6548\uff0c\u4e24\u7c7b\u65b9\u6cd5\u7ed3\u5408\u6709\u671b\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "motivation": "LTLfp\u548cPPLTLp\u5141\u8bb8\u5728\u65e0\u9650\u8f68\u8ff9\u4e0a\u5229\u7528\u6709\u9650\u8f68\u8ff9LTLf/PPLTL\u6280\u672f\uff0c\u4ece\u800c\u5b9e\u73b0\u4e0e\u5b8c\u6574LTL\u540c\u7b49\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u4f46\u7f3a\u5c11\u9ad8\u6548\u7684\u53cd\u5e94\u5f0f\u7efc\u5408\u95ee\u9898\u6c42\u89e3\u5668\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u57fa\u4e8e\u56fe\u6e38\u620f\u7684\u4e24\u79cd\u6c42\u89e3\u5668\uff1a\u4e00\u79cd\u901a\u8fc7Emerson-Lei\u6e38\u620f\u5148\u5c06\u7b80\u5355\u76ee\u6807\u5f52\u7ea6\u4e3a\u590d\u6742\u76ee\u6807\uff0c\u53e6\u4e00\u79cd\u76f4\u63a5\u5728\u56fe\u4e2d\u5d4c\u5165Manna-Pnueli\u76ee\u6807\uff0c\u5e76\u7ea7\u8054\u6c42\u89e3DAG\u4e0a\u7684\u5b50\u6e38\u620f\u3002\u5b9e\u9645\u5728\u4ee3\u8868\u6027\u516c\u5f0f\u4e0a\u8fdb\u884c\u6027\u80fd\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cManna-Pnueli\u6e38\u620f\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u6027\u80fd\u4f18\u4e8e\u57fa\u4e8eEmerson-Lei\u6e38\u620f\u7684\u65b9\u6848\uff0c\u4f46\u4e5f\u6709\u4f8b\u5916\u3002\u4e24\u79cd\u65b9\u6cd5\u7ed3\u5408\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u5b9e\u9645\u6027\u80fd\u3002", "conclusion": "Manna-Pnueli games\u5728\u6c42\u89e3\u53cd\u5e94\u5f0f\u7efc\u5408\u95ee\u9898\u65f6\u901a\u5e38\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u9ad8\u6548\uff0c\u4f46\u4e0d\u662f\u6240\u6709\u573a\u666f\u90fd\u5360\u4f18\uff0c\u5b9e\u9645\u5e94\u7528\u4e2d\u4e24\u79cd\u65b9\u6cd5\u7ed3\u5408\u4f7f\u7528\u53ef\u80fd\u8fdb\u4e00\u6b65\u4f18\u5316\u6027\u80fd\u3002"}}
{"id": "2508.14090", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14090", "abs": "https://arxiv.org/abs/2508.14090", "authors": ["Chen Xu", "Dawei Yang"], "title": "DLLMQuant: Quantizing Diffusion-based Large Language Models", "comment": "12 pages, 6 figures", "summary": "Diffusion-based large language models (DLLMs) have shown promise for\nnon-autoregressive text generation, but their deployment is constrained by\nlarge model sizes and heavy computational costs. Post-training quantization\n(PTQ), a widely used method for compressing and accelerating Large Language\nModels (LLMs), suffers from severe accuracy degradation and reduced\ngeneralization performance when directly applied to DLLMs (e.g., AWQ suffers a\n16% accuracy drop on LLADA under W4A4). This paper explores how DLLMs' key\nmechanisms - dynamic masking, iterative generation, bidirectional attention -\nclash with quantization. We identify three core issues: 1) Iterative generation\nand dynamic masking ratios lead to distinct token distributions across decoding\nsteps, which are not adequately captured by existing PTQ calibration methods;\n2) Quantization errors are accumulated and amplified progressively during\niteration in DLLMs, causing quantized models to perform worse as decoding steps\nprogress; 3) Unmasked tokens stabilize while masked remain probabilistic,\nmaking overall feature distribution incompatible with existing PTQ methods. To\naddress these issues, we propose DLLMQuant, a PTQ framework tailored for DLLMs,\nwhich incorporates three novel techniques: 1) Temporal-Mask Adaptive Sampling\n(TMAS), a calibration method that accounts for both time and mask factors, with\nthe capacity to capture distributions across timesteps. 2) Interaction-Aware\nActivation Quantization (IA-AQ), which utilizes bidirectional attention's\ninteraction signals to dynamically allocate quantization resources. 3)\nCertainty-Guided Quantization (CGQ), which integrates mask status and token\nscores as key weighting criteria into error compensation, making weight\nquantization more suitable for DLLMs. Experiments show that DLLMQuant achieves\nsignificant performance gains while enhancing efficiency.", "AI": {"tldr": "DLLM\u7684\u91cf\u5316\u5f88\u96be\uff0c\u4e3b\u8981\u7531\u4e8e\u5176\u7279\u6b8a\u7684\u751f\u6210\u673a\u5236\u548c\u5206\u5e03\u7279\u70b9\u3002\u672c\u6587\u5206\u6790\u96be\u70b9\uff0c\u63d0\u51fa\u4e13\u7528\u91cf\u5316\u65b9\u6848DLLMQuant\uff08\u6db5\u76d6\u91c7\u6837\u3001\u6fc0\u6d3b\u91cf\u5316\u548c\u6743\u91cd\u8bef\u5dee\u8865\u507f\u4e09\u6280\u672f\uff09\uff0c\u76f8\u6bd4\u901a\u7528PTQ\u663e\u8457\u63d0\u5347\u51c6\u786e\u6027\u548c\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u975e\u81ea\u56de\u5f52\u6269\u6563\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\uff08DLLMs\uff09\u867d\u6709\u6f5c\u529b\uff0c\u4f46\u53d7\u9650\u4e8e\u6a21\u578b\u4f53\u79ef\u5927\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u73b0\u6709\u4e3b\u6d41\u7684\u540e\u8bad\u7ec3\u91cf\u5316\uff08PTQ\uff09\u538b\u7f29\u65b9\u6cd5\u5728DLLM\u4e0a\u5e94\u7528\u65f6\u4f1a\u5e26\u6765\u4e25\u91cd\u7cbe\u5ea6\u4e0b\u964d\u548c\u6cdb\u5316\u9000\u5316\u3002\u4f5c\u8005\u5e0c\u671b\u89e3\u51b3DLLM\u91cf\u5316\u7684\u7279\u6b8a\u6311\u6218\u3002", "method": "\u5206\u6790DLLM\u7684\u6838\u5fc3\u673a\u5236\u4e0e\u91cf\u5316\u65b9\u6cd5\u7684\u51b2\u7a81\uff0c\u5f52\u7eb3\u51fa\u4e09\u5927\u95ee\u9898\uff1a\u5206\u6b65\u751f\u6210\u548c\u52a8\u6001mask\u5bfc\u81f4token\u5206\u5e03\u53d8\u5316\u3001\u91cf\u5316\u8bef\u5dee\u968f\u8fed\u4ee3\u7d2f\u79ef\u653e\u5927\u3001\u7279\u5f81\u5206\u5e03\u4e0e\u73b0\u6709\u91cf\u5316\u517c\u5bb9\u6027\u4e0d\u8db3\u3002\u4e3a\u6b64\u63d0\u51faDLLMQuant\u6846\u67b6\uff0c\u5305\u62ec\u4e09\u9879\u65b0\u6280\u672f\uff1a\u65f6\u95f4mask\u81ea\u9002\u5e94\u91c7\u6837\uff08TMAS\uff09\u3001\u4ea4\u4e92\u611f\u77e5\u6fc0\u6d3b\u91cf\u5316\uff08IA-AQ\uff09\u3001\u786e\u5b9a\u6027\u5bfc\u5411\u91cf\u5316\uff08CGQ\uff09\u3002", "result": "DLLMQuant\u5728\u591a\u4e2a\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u9002\u7528\u6027\uff0c\u53ef\u660e\u663e\u63d0\u5347DLLM\u7684\u91cf\u5316\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u5bf9DLLM\u7684\u91cf\u5316\u9700\u4e13\u7528\u65b9\u6cd5\uff0c\u63d0\u51fa\u7684DLLMQuant\u6709\u6548\u7f13\u89e3\u4e86\u4f20\u7edfPTQ\u9762\u4e34\u7684\u4e09\u5927\u95ee\u9898\uff0c\u5e76\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u548c\u9ad8\u6548\u7387\u3002"}}
{"id": "2508.14451", "categories": ["cs.SE", "K.6.3; E.0"], "pdf": "https://arxiv.org/pdf/2508.14451", "abs": "https://arxiv.org/abs/2508.14451", "authors": ["Richard Sserujongi", "Daniel Ogenrwot", "Nicholas Niwamanya", "Noah Nsimbe", "Martin Bbaale", "Benjamin Ssempala", "Noble Mutabazi", "Raja Fidel Wabinyai", "Deo Okure", "Engineer Bainomugisha"], "title": "Design and Evaluation of a Scalable Data Pipeline for AI-Driven Air Quality Monitoring in Low-Resource Settings", "comment": "15 pages, 11 figures, 34th International Conference on Software\n  Engineering and Data Engineering", "summary": "The increasing adoption of low-cost environmental sensors and AI-enabled\napplications has accelerated the demand for scalable and resilient data\ninfrastructures, particularly in data-scarce and resource-constrained regions.\nThis paper presents the design, implementation, and evaluation of the AirQo\ndata pipeline: a modular, cloud-native Extract-Transform-Load (ETL) system\nengineered to support both real-time and batch processing of heterogeneous air\nquality data across urban deployments in Africa. It is Built using open-source\ntechnologies such as Apache Airflow, Apache Kafka, and Google BigQuery. The\npipeline integrates diverse data streams from low-cost sensors, third-party\nweather APIs, and reference-grade monitors to enable automated calibration,\nforecasting, and accessible analytics. We demonstrate the pipeline's ability to\ningest, transform, and distribute millions of air quality measurements monthly\nfrom over 400 monitoring devices while achieving low latency, high throughput,\nand robust data availability, even under constrained power and connectivity\nconditions. The paper details key architectural features, including workflow\norchestration, decoupled ingestion layers, machine learning-driven sensor\ncalibration, and observability frameworks. Performance is evaluated across\noperational metrics such as resource utilization, ingestion throughput,\ncalibration accuracy, and data availability, offering practical insights into\nbuilding sustainable environmental data platforms. By open-sourcing the\nplatform and documenting deployment experiences, this work contributes a\nreusable blueprint for similar initiatives seeking to advance environmental\nintelligence through data engineering in low-resource settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5f00\u6e90\u4e86AirQo\u4e91\u539f\u751f\u73af\u5883\u6570\u636e\u7ba1\u9053\u7cfb\u7edf\uff0c\u5728\u8d44\u6e90\u6709\u9650\u3001\u7f51\u7edc\u4e0d\u7a33\u5b9a\u7684\u975e\u6d32\u57ce\u5e02\u5927\u89c4\u6a21\u73af\u5883\u76d1\u6d4b\u9879\u76ee\u4e2d\uff0c\u5c55\u73b0\u4e86\u9ad8\u6548\u3001\u7a33\u5b9a\u3001\u6613\u7528\u7684\u6570\u636e\u5904\u7406\u80fd\u529b\uff0c\u4e3a\u4f4e\u6210\u672c\u73af\u5883\u667a\u80fd\u5e73\u53f0\u5efa\u8bbe\u63d0\u4f9b\u4e86\u53ef\u501f\u9274\u7ecf\u9a8c\u3002", "motivation": "\u7531\u4e8e\u4f4e\u6210\u672c\u73af\u5883\u4f20\u611f\u5668\u548cAI\u5e94\u7528\u7684\u666e\u53ca\uff0c\u5c24\u5176\u662f\u5728\u6570\u636e\u7a00\u7f3a\u548c\u8d44\u6e90\u6709\u9650\u7684\u5730\u533a\uff0c\u4e9f\u9700\u53ef\u6269\u5c55\u4e14\u5177\u5907\u5f39\u6027\u7684\u73af\u5883\u6570\u636e\u57fa\u7840\u8bbe\u65bd\u3002", "method": "\u8bbe\u8ba1\u3001\u5b9e\u73b0\u5e76\u8bc4\u4f30\u4e86AirQo\u6570\u636e\u7ba1\u9053\u2014\u2014\u4e00\u79cd\u6a21\u5757\u5316\u3001\u4e91\u539f\u751f\u7684ETL\u7cfb\u7edf\uff0c\u80fd\u591f\u652f\u6301\u57ce\u5e02\u533a\u57df\u5927\u89c4\u6a21\u90e8\u7f72\u4e0b\u7684\u591a\u6837\u5316\u5b9e\u65f6\u4e0e\u6279\u5904\u7406\u7a7a\u6c14\u8d28\u91cf\u6570\u636e\u96c6\u6210\u3002\u8be5\u7cfb\u7edf\u7ed3\u5408\u5f00\u6e90\u6280\u672f\uff08\u5982Apache Airflow\u3001Kafka\u548cGoogle BigQuery\uff09\uff0c\u5b9e\u73b0\u81ea\u52a8\u91c7\u96c6\u3001\u6821\u51c6\u3001\u9884\u62a5\u4e0e\u5206\u6790\u529f\u80fd\u3002", "result": "AirQo\u7ba1\u9053\u80fd\u591f\u6bcf\u6708\u4f4e\u5ef6\u8fdf\u9ad8\u541e\u5410\u5730\u4ece400\u591a\u4e2a\u8bbe\u5907\u4e2d\u7a33\u5b9a\u91c7\u96c6\u548c\u5206\u53d1\u6570\u767e\u4e07\u7a7a\u6c14\u8d28\u91cf\u6570\u636e\uff0c\u5373\u4f7f\u5728\u7535\u529b\u3001\u8fde\u63a5\u53d7\u9650\u573a\u666f\u4e0b\u4e5f\u4fdd\u6301\u6570\u636e\u53ef\u7528\u3002\u7cfb\u7edf\u5728\u8d44\u6e90\u5229\u7528\u3001\u541e\u5410\u91cf\u3001\u6821\u51c6\u7cbe\u5ea6\u548c\u53ef\u7528\u6027\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u6587\u4e2d\u5f00\u6e90\u4e14\u6587\u6863\u5b8c\u5584\u7684\u5e73\u53f0\u548c\u7ecf\u9a8c\u4e3a\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u53ef\u6301\u7eed\u73af\u5883\u6570\u636e\u57fa\u7840\u8bbe\u65bd\u5efa\u8bbe\u63d0\u4f9b\u4e86\u53ef\u590d\u7528\u84dd\u56fe\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u73af\u5883\u667a\u80fd\u7684\u666e\u53ca\u3002"}}
{"id": "2508.14838", "categories": ["cs.LO", "03E65, 68Q19", "G.0"], "pdf": "https://arxiv.org/pdf/2508.14838", "abs": "https://arxiv.org/abs/2508.14838", "authors": ["Claude Tardif"], "title": "Constraint satisfaction problems, compactness and non-measurable sets", "comment": "7 pages", "summary": "A finite relational structure A is called compact if for any infinite\nrelational structure B of the same type, the existence of a homomorphism from B\nto A is equivalent to the existence of homomorphisms from all finite\nsubstructures of B to A. We show that if A has width one, then the compactness\nof A can be proved in the axiom system of Zermelo and Fraenkel, but otherwise,\nthe compactness of A implies the existence of non-measurable sets in 3-space.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u6709\u9650\u5173\u7cfb\u7ed3\u6784\u7d27\u6027\u7684\u8bc1\u660e\u6240\u9700\u96c6\u5408\u8bba\u516c\u7406\uff1a\u5bbd\u5ea6\u4e3a\u4e00\u7684\u60c5\u5f62\u5728ZF\u7cfb\u7edf\u4e2d\u53ef\u8bc1\u660e\uff0c\u5426\u5219\u5219\u9700\u63a5\u53d7\u66f4\u5f3a\u7684\u96c6\u5408\u8bba\u7ed3\u8bba\uff0c\u5982\u4e09\u7ef4\u7a7a\u95f4\u7684\u4e0d\u53ef\u6d4b\u96c6\u5b58\u5728\u3002", "motivation": "\u7814\u7a76\u6709\u9650\u5173\u7cfb\u7ed3\u6784\u7684\u7d27\u6027\u4e0e\u96c6\u5408\u8bba\u516c\u7406\u7cfb\u7edf\u7684\u5173\u8054\uff0c\u63ed\u793a\u5176\u6570\u5b66\u57fa\u7840\u5c5e\u6027\u3002", "method": "\u8fd0\u7528\u6a21\u578b\u8bba\u548c\u96c6\u5408\u8bba\u5de5\u5177\uff0c\u5206\u6790\u4e0d\u540c\u5bbd\u5ea6\u7684\u6709\u9650\u5173\u7cfb\u7ed3\u6784\u7d27\u6027\u7684\u8bc1\u660e\u9700\u6c42\u3002", "result": "\u5bf9\u4e8e\u5bbd\u5ea6\u4e3a\u4e00\u7684\u6709\u9650\u5173\u7cfb\u7ed3\u6784\uff0c\u5176\u7d27\u6027\u53ef\u5728Zermelo-Fraenkel(ZF)\u516c\u7406\u7cfb\u7edf\u4e2d\u8bc1\u660e\uff1b\u5426\u5219\uff0c\u82e5\u8be5\u7ed3\u6784\u7d27\u6027\u6210\u7acb\uff0c\u5219\u4f1a\u8574\u542b\u4e09\u7ef4\u7a7a\u95f4\u4e2d\u5b58\u5728\u4e0d\u53ef\u6d4b\u96c6\u3002", "conclusion": "\u5bbd\u5ea6\u4e3a\u4e00\u7684\u6709\u9650\u5173\u7cfb\u7ed3\u6784\u7684\u7d27\u6027\u8f83\u5f31\uff0c\u6613\u4e8e\u5728\u666e\u901a\u96c6\u5408\u8bba\u4e2d\u5904\u7406\uff0c\u800c\u66f4\u9ad8\u5bbd\u5ea6\u7684\u7d27\u6027\u5219\u610f\u5473\u7740\u5bf9\u96c6\u5408\u8bba\u57fa\u7840\u6709\u66f4\u5f3a\u9700\u6c42\u3002"}}
{"id": "2508.14146", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.14146", "abs": "https://arxiv.org/abs/2508.14146", "authors": ["Xian Gao", "Jiacheng Ruan", "Zongyun Zhang", "Jingsheng Gao", "Ting Liu", "Yuzhuo Fu"], "title": "MMReview: A Multidisciplinary and Multimodal Benchmark for LLM-Based Peer Review Automation", "comment": "Work in progress", "summary": "With the rapid growth of academic publications, peer review has become an\nessential yet time-consuming responsibility within the research community.\nLarge Language Models (LLMs) have increasingly been adopted to assist in the\ngeneration of review comments; however, current LLM-based review tasks lack a\nunified evaluation benchmark to rigorously assess the models' ability to\nproduce comprehensive, accurate, and human-aligned assessments, particularly in\nscenarios involving multimodal content such as figures and tables. To address\nthis gap, we propose \\textbf{MMReview}, a comprehensive benchmark that spans\nmultiple disciplines and modalities. MMReview includes multimodal content and\nexpert-written review comments for 240 papers across 17 research domains within\nfour major academic disciplines: Artificial Intelligence, Natural Sciences,\nEngineering Sciences, and Social Sciences. We design a total of 13 tasks\ngrouped into four core categories, aimed at evaluating the performance of LLMs\nand Multimodal LLMs (MLLMs) in step-wise review generation, outcome\nformulation, alignment with human preferences, and robustness to adversarial\ninput manipulation. Extensive experiments conducted on 16 open-source models\nand 5 advanced closed-source models demonstrate the thoroughness of the\nbenchmark. We envision MMReview as a critical step toward establishing a\nstandardized foundation for the development of automated peer review systems.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u6db5\u76d6\u591a\u5b66\u79d1\u548c\u591a\u6a21\u6001\u5185\u5bb9\u7684\u8bc4\u5ba1\u57fa\u51c6MMReview\uff0c\u5e76\u901a\u8fc7\u5927\u91cf\u6a21\u578b\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u6709\u671b\u6210\u4e3a\u81ea\u52a8\u5316\u5b66\u672f\u8bc4\u5ba1\u6807\u51c6\u7684\u91cd\u8981\u57fa\u7840\u3002", "motivation": "\u5b66\u672f\u51fa\u7248\u7269\u6570\u91cf\u5feb\u901f\u589e\u957f\u4f7f\u5f97\u540c\u884c\u8bc4\u5ba1\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u4f46\u8017\u65f6\uff0c\u76ee\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9010\u6e10\u5e94\u7528\u4e8e\u8bc4\u5ba1\u610f\u89c1\u751f\u6210\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u57fa\u51c6\u4ee5\u8bc4\u4f30\u5176\u5728\u751f\u6210\u5168\u9762\u3001\u51c6\u786e\u4e14\u7b26\u5408\u4eba\u7c7b\u6807\u51c6\u8bc4\u5ba1\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5c24\u5176\u5728\u5305\u542b\u591a\u6a21\u6001\u5185\u5bb9\uff08\u5982\u56fe\u8868\uff09\u7684\u573a\u666f\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86MMReview\uff0c\u4e00\u4e2a\u6db5\u76d6\u591a\u5b66\u79d1\u3001\u591a\u6a21\u6001\u7684\u8bc4\u6d4b\u57fa\u51c6\u3002MMReview\u6536\u5f55\u4e8617\u4e2a\u7814\u7a76\u9886\u57df\u7684240\u7bc7\u8bba\u6587\u7684\u591a\u6a21\u6001\u5185\u5bb9\u53ca\u4e13\u5bb6\u8bc4\u5ba1\u610f\u89c1\uff0c\u5206\u4e3a\u56db\u5927\u5b66\u79d1\u2014\u2014\u4eba\u5de5\u667a\u80fd\u3001\u81ea\u7136\u79d1\u5b66\u3001\u5de5\u7a0b\u79d1\u5b66\u548c\u793e\u4f1a\u79d1\u5b66\u3002\u5305\u542b13\u9879\u4efb\u52a1\u30014\u5927\u6838\u5fc3\u7c7b\u522b\uff0c\u7cfb\u7edf\u6027\u8bc4\u4f30LLM\u548c\u591a\u6a21\u6001LLM\u5728\u8bc4\u5ba1\u751f\u6210\u3001\u7ed3\u679c\u5236\u5b9a\u3001\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u53ca\u5bf9\u6297\u8f93\u5165\u9c81\u68d2\u6027\u7b49\u65b9\u9762\u7684\u8868\u73b0\u3002\u5e76\u5bf916\u4e2a\u5f00\u6e90\u6a21\u578b\u4e0e5\u4e2a\u95ed\u6e90\u6a21\u578b\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "MMReview\u901a\u8fc7\u5e7f\u6cdb\u7684\u6a21\u578b\u8bc4\u6d4b\u9a8c\u8bc1\u4e86\u5176\u5168\u9762\u6027\uff0c\u80fd\u591f\u8bc4\u4f30\u6a21\u578b\u5728\u591a\u6a21\u6001\u5b66\u672f\u8bc4\u5ba1\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "conclusion": "MMReview\u4e3a\u81ea\u52a8\u5316\u540c\u884c\u8bc4\u5ba1\u7cfb\u7edf\u7684\u5f00\u53d1\u5960\u5b9a\u4e86\u6807\u51c6\u5316\u7684\u57fa\u7840\uff0c\u662f\u5efa\u7acb\u81ea\u52a8\u5316\u8bc4\u5ba1\u6807\u51c6\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2508.14511", "categories": ["cs.SE", "D.2.11"], "pdf": "https://arxiv.org/pdf/2508.14511", "abs": "https://arxiv.org/abs/2508.14511", "authors": ["Eagon Meng", "Daniel Jackson"], "title": "What You See Is What It Does: A Structural Pattern for Legible Software", "comment": "16 pages. Appearing in Onward! at SPLASH 2025", "summary": "The opportunities offered by LLM coders (and their current limitations)\ndemand a reevaluation of how software is structured. Software today is often\n\"illegible\" - lacking a direct correspondence between code and observed\nbehavior - and insufficiently modular, leading to a failure of three key\nrequirements of robust coding: incrementality (the ability to deliver small\nincrements by making localized changes), integrity (avoiding breaking prior\nincrements) and transparency (making clear what has changed at build time, and\nwhat actions have happened at runtime).\n  A new structural pattern offers improved legibility and modularity. Its\nelements are concepts and synchronizations: fully independent services and\nevent-based rules that mediate between them. A domain-specific language for\nsynchronizations allows behavioral features to be expressed in a granular and\ndeclarative way (and thus readily generated by an LLM). A case study of the\nRealWorld benchmark is used to illustrate and evaluate the approach.", "AI": {"tldr": "\u73b0\u6709\u8f6f\u4ef6\u7ed3\u6784\u4e0d\u591f\u6e05\u6670\u4e0e\u6a21\u5757\u5316\uff0c\u4e0d\u5229\u4e8e\u589e\u91cf\u5f00\u53d1\u4e0e\u53ef\u7ef4\u62a4\u6027\u3002\u4f5c\u8005\u63d0\u51fa\u57fa\u4e8e\u201c\u6982\u5ff5-\u540c\u6b65\u201d\u4ee5\u53ca\u4e8b\u4ef6\u89c4\u5219\u7684\u65b0\u7ed3\u6784\u6a21\u5f0f\uff0c\u7528\u4e13\u7528\u8bed\u8a00\u63d0\u9ad8\u8868\u8fbe\u548c\u751f\u6210\u80fd\u529b\u3002\u5b9e\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6709\u5229\u4e8e\u6784\u5efaLLM\u53cb\u597d\u7684\u3001\u9ad8\u5ea6\u6a21\u5757\u5316\u7684\u8f6f\u4ef6\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524dLLM\u4ee3\u7801\u751f\u6210\u5668\u5e26\u6765\u4e86\u673a\u9047\uff0c\u540c\u65f6\u4e5f\u66b4\u9732\u51fa\u73b0\u6709\u8f6f\u4ef6\u7ed3\u6784\u5728\u53ef\u8bfb\u6027\u4e0e\u6a21\u5757\u5316\u65b9\u9762\u7684\u4e0d\u8db3\uff1a\u4ee3\u7801\u4e0e\u884c\u4e3a\u5173\u8054\u4e0d\u660e\u6670\u3001\u6a21\u5757\u5316\u7a0b\u5ea6\u4f4e\uff0c\u5f71\u54cd\u4e86\u589e\u91cf\u5f00\u53d1\u3001\u5b8c\u6574\u6027\u548c\u900f\u660e\u5ea6\u7b49\u5173\u952e\u8981\u6c42\u3002\u4f5c\u8005\u5e0c\u671b\u63a8\u52a8\u8f6f\u4ef6\u7ed3\u6784\u7684\u91cd\u65b0\u8bbe\u8ba1\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u7ed3\u6784\u5316\u6a21\u5f0f\uff0c\u7531\u6982\u5ff5\u548c\u540c\u6b65\u5143\u7d20\u6784\u5efa\uff1a\u5373\u5b8c\u5168\u72ec\u7acb\u7684\u670d\u52a1\u4e0e\u57fa\u4e8e\u4e8b\u4ef6\u7684\u89c4\u5219\u6765\u534f\u8c03\u5b83\u4eec\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e13\u7528\u9886\u57df\u8bed\u8a00\u63cf\u8ff0\u540c\u6b65\u89c4\u5219\uff0c\u4ece\u800c\u5b9e\u73b0\u884c\u4e3a\u7279\u6027\u7684\u7ec6\u7c92\u5ea6\u3001\u58f0\u660e\u5f0f\u8868\u8fbe\u3002\u7136\u540e\u7528RealWorld\u57fa\u51c6\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\u4ee5\u6f14\u793a\u548c\u8bc4\u4f30\u8fd9\u4e00\u65b9\u6cd5\u3002", "result": "\u65b0\u7ed3\u6784\u5728\u53ef\u8bfb\u6027\u548c\u6a21\u5757\u5316\u65b9\u9762\u5e26\u6765\u6539\u8fdb\u3002\u5229\u7528\u7279\u5b9a\u9886\u57df\u8bed\u8a00\u5b9e\u73b0\u884c\u4e3a\u63cf\u8ff0\u7684\u7c92\u5ea6\u548c\u8868\u8fbe\u80fd\u529b\uff0c\u63d0\u5347\u4e86\u8f6f\u4ef6\u7684\u589e\u91cf\u5f00\u53d1\u6027\u3001\u5b8c\u6574\u6027\u4fdd\u969c\u53ca\u900f\u660e\u5ea6\u3002\u6848\u4f8b\u5206\u6790\u652f\u6301\u4e86\u8fd9\u79cd\u7ed3\u6784\u5316\u65b9\u6848\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5e94\u91cd\u6784\u73b0\u6709\u8f6f\u4ef6\u7684\u7ed3\u6784\uff0c\u91c7\u7528\u6982\u5ff5+\u540c\u6b65\u7684\u6a21\u5757\u5316\u65b0\u6a21\u5f0f\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u4ee3\u7801\u4e0e\u884c\u4e3a\u7684\u5bf9\u5e94\u6027\u548c\u7cfb\u7edf\u7684\u53ef\u7ef4\u62a4\u6027\uff0c\u540c\u65f6\u8ba9LLM\u8f85\u52a9\u5f00\u53d1\u53d8\u5f97\u66f4\u6709\u6548\u3002\u4e13\u7528\u540c\u6b65\u8bed\u8a00\u6781\u5927\u5730\u5229\u4e8e\u81ea\u52a8\u4ee3\u7801\u751f\u6210\u548c\u7ba1\u7406\u590d\u6742\u884c\u4e3a\u3002"}}
{"id": "2508.14148", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14148", "abs": "https://arxiv.org/abs/2508.14148", "authors": ["Xinhua Chen", "Sitao Huang", "Cong Guo", "Chiyue Wei", "Yintao He", "Jianyi Zhang", "Hai \"Hellen\" Li", "Yiran Chen"], "title": "DPad: Efficient Diffusion Language Models with Suffix Dropout", "comment": null, "summary": "Diffusion-based Large Language Models (dLLMs) parallelize text generation by\nframing decoding as a denoising process, but suffer from high computational\noverhead since they predict all future suffix tokens at each step while\nretaining only a small fraction. We propose Diffusion Scratchpad (DPad), a\ntraining-free method that restricts attention to a small set of nearby suffix\ntokens, preserving fidelity while eliminating redundancy. DPad integrates two\nstrategies: (i) a sliding window, which maintains a fixed-length suffix window,\nand (ii) distance-decay dropout, which deterministically removes distant suffix\ntokens before attention computation. This simple design is compatible with\nexisting optimizations such as prefix caching and can be implemented with only\na few lines of code. Comprehensive evaluations across multiple benchmarks on\nLLaDA-1.5 and Dream models demonstrate that DPad delivers up to\n$\\mathbf{61.4\\times}$ speedup over vanilla dLLMs while maintaining comparable\naccuracy, highlighting its potential for efficient and scalable long-sequence\ninference. Our code is available at https://github.com/Crys-Chen/DPad.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDPad\u65b9\u6cd5\uff0c\u901a\u8fc7\u6ed1\u52a8\u7a97\u53e3\u548c\u8ddd\u79bb\u8870\u51cfdropout\u4f18\u5316\u6269\u6563\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8fc7\u7a0b\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u517c\u5bb9\u73b0\u6709\u4ee3\u7801\uff0c\u5b9e\u73b0\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u6700\u9ad861.4\u500d\u4e14\u7cbe\u5ea6\u51e0\u4e4e\u4e0d\u53d8\uff0c\u975e\u5e38\u9002\u5408\u957f\u5e8f\u5217\u63a8\u7406\u573a\u666f\u3002", "motivation": "\u6269\u6563\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\uff08dLLMs\uff09\u5728\u751f\u6210\u6587\u672c\u65f6\u867d\u7136\u80fd\u591f\u5e76\u884c\u5316\u64cd\u4f5c\uff0c\u4f46\u7531\u4e8e\u6bcf\u4e00\u6b65\u90fd\u4f1a\u9884\u6d4b\u6240\u6709\u672a\u6765\u7684\u540e\u7f00\u8bcd\u5143\uff0c\u5bfc\u81f4\u8ba1\u7b97\u5f00\u9500\u6781\u5927\u4e14\u6548\u7387\u4f4e\u4e0b\u3002\u8be5\u95ee\u9898\u9650\u5236\u4e86\u5176\u5728\u957f\u5e8f\u5217\u63a8\u7406\u4e0a\u7684\u5b9e\u9645\u5e94\u7528\u80fd\u529b\u3002", "method": "\u63d0\u51faDiffusion Scratchpad\uff08DPad\uff09\u65b9\u6cd5\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\uff0c\u901a\u8fc7\u4e24\u79cd\u7b56\u7565\u4f18\u5316\u540e\u7f00\u8bcd\u5143\u7684\u5904\u7406\uff1a\uff081\uff09\u6ed1\u52a8\u7a97\u53e3\uff0c\u4ec5\u5173\u6ce8\u56fa\u5b9a\u957f\u5ea6\u7684\u8fd1\u7aef\u540e\u7f00\uff1b\uff082\uff09\u8ddd\u79bb\u8870\u51cfdropout\uff0c\u5728\u6ce8\u610f\u529b\u8ba1\u7b97\u524d\u53bb\u9664\u8fdc\u7aef\u540e\u7f00\u3002\u8fd9\u79cd\u8bbe\u8ba1\u4e0d\u4ec5\u7b80\u5355\u6613\u7528\uff0c\u8fd8\u517c\u5bb9\u73b0\u6709\u4f18\u5316\u624b\u6bb5\uff0c\u6bd4\u5982\u524d\u7f00\u7f13\u5b58\uff0c\u53ef\u8f7b\u677e\u96c6\u6210\u5230\u4ee3\u7801\u4e2d\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982LLaDA-1.5\u548cDream\u6a21\u578b\uff09\u4e0a\uff0cDPad\u65b9\u6848\u76f8\u8f83\u4e8e\u539f\u59cbdLLMs\u5b9e\u73b0\u4e86\u6700\u9ad861.4\u500d\u7684\u63a8\u7406\u52a0\u901f\uff0c\u540c\u65f6\u5728\u7cbe\u5ea6\u4e0a\u57fa\u672c\u65e0\u635f\u3002", "conclusion": "DPad\u663e\u8457\u63d0\u9ad8\u4e86\u6269\u6563\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u957f\u5e8f\u5217\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5176\u6548\u679c\u5f3a\u5927\u4e14\u6613\u4e8e\u96c6\u6210\u3002"}}
{"id": "2508.14532", "categories": ["cs.SE", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.14532", "abs": "https://arxiv.org/abs/2508.14532", "authors": ["Zhongyi Wang", "Tengjie Lin", "Mingshuai Chen", "Mingqi Yang", "Haokun Li", "Xiao Yi", "Shengchao Qin", "Jianwei Yin"], "title": "Preguss: It Analyzes, It Specifies, It Verifies", "comment": "Position paper to appear in the 1st International Workshop on\n  Language Models and Programming Languages (LMPL '25)", "summary": "Fully automated verification of large-scale software and hardware systems is\narguably the holy grail of formal methods. Large language models (LLMs) have\nrecently demonstrated their potential for enhancing the degree of automation in\nformal verification by, e.g., generating formal specifications as essential to\ndeductive verification, yet exhibit poor scalability due to context-length\nlimitations and, more importantly, the difficulty of inferring complex,\ninterprocedural specifications. This paper outlines Preguss - a modular,\nfine-grained framework for automating the generation and refinement of formal\nspecifications. Preguss synergizes between static analysis and deductive\nverification by orchestrating two components: (i) potential runtime error\n(RTE)-guided construction and prioritization of verification units, and (ii)\nLLM-aided synthesis of interprocedural specifications at the unit level. We\nenvisage that Preguss paves a compelling path towards the automated\nverification of large-scale programs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPreguss\u6846\u67b6\uff0c\u901a\u8fc7RTE\u5f15\u5bfc\u9759\u6001\u5206\u6790\u4e0eLLM\u8f85\u52a9\u89c4\u8303\u5408\u6210\uff0c\u63d0\u5347\u4e86\u5927\u578b\u7a0b\u5e8f\u7684\u81ea\u52a8\u5316\u9a8c\u8bc1\u80fd\u529b\uff0c\u89e3\u51b3\u4e86LLM\u5728\u53ef\u6269\u5c55\u6027\u548c\u590d\u6742\u89c4\u8303\u63a8\u7406\u4e0a\u7684\u74f6\u9888\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u81ea\u52a8\u5316\u5f62\u5f0f\u5316\u9a8c\u8bc1\u4e2d\u5c55\u73b0\u4e86\u6f5c\u529b\uff0c\u4f46\u53d7\u9650\u4e8e\u4e0a\u4e0b\u6587\u957f\u5ea6\u548c\u63a8\u7406\u590d\u6742\u8de8\u8fc7\u7a0b\u89c4\u8303\u7684\u56f0\u96be\uff0c\u5bfc\u81f4\u53ef\u6269\u5c55\u6027\u8f83\u5dee\u3002\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u5bf9\u4e8e\u5927\u89c4\u6a21\u7cfb\u7edf\u7684\u81ea\u52a8\u5316\u9a8c\u8bc1\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86Preguss\uff0c\u4e00\u4e2a\u6a21\u5757\u5316\u4e0e\u7ec6\u7c92\u5ea6\u6846\u67b6\u3002\u5176\u901a\u8fc7\u9759\u6001\u5206\u6790\u4e0e\u6f14\u7ece\u9a8c\u8bc1\u7ed3\u5408\uff0c\u5305\u542b\u4e24\u5927\u7ec4\u4ef6\uff1a(1)\u5229\u7528\u6f5c\u5728\u8fd0\u884c\u65f6\u9519\u8bef\uff08RTE\uff09\u5f15\u5bfc\u6784\u5efa\u548c\u4f18\u5148\u9a8c\u8bc1\u5355\u5143\uff1b(2)\u901a\u8fc7LLM\u8f85\u52a9\u5728\u5355\u5143\u7ea7\u522b\u5408\u6210\u8de8\u8fc7\u7a0b\u89c4\u8303\u3002\u534f\u540c\u4e24\u8005\u4ee5\u63d0\u5347\u81ea\u52a8\u751f\u6210\u4e0e\u5b8c\u5584\u5f62\u5f0f\u5316\u89c4\u8303\u7684\u80fd\u529b\u3002", "result": "\u5b55\u80b2\u51fa\u4e86\u4e00\u6761\u4fc3\u8fdb\u5927\u578b\u7a0b\u5e8f\u81ea\u52a8\u5316\u9a8c\u8bc1\u7684\u53ef\u884c\u9053\u8def\uff0c\u63d0\u5347\u4e86\u89c4\u8303\u751f\u6210\u4e0e\u81ea\u52a8\u5316\u9a8c\u8bc1\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "Preguss\u6846\u67b6\u6709\u6548\u7ed3\u5408\u4e86\u9759\u6001\u5206\u6790\u4e0eLLM\u7684\u4f18\u52bf\uff0c\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u3001\u53ef\u6269\u5c55\u7684\u5f62\u5f0f\u5316\u89c4\u8303\u751f\u6210\u65b0\u8303\u5f0f\uff0c\u6709\u671b\u63a8\u52a8\u5927\u89c4\u6a21\u7a0b\u5e8f\u7684\u81ea\u52a8\u5316\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002"}}
{"id": "2508.14170", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.14170", "abs": "https://arxiv.org/abs/2508.14170", "authors": ["Johannes Zschache", "Tilman Hartwig"], "title": "Comparing energy consumption and accuracy in text classification inference", "comment": "Key results in Figure 1, submitted to Nature Communications, 25 pages", "summary": "The increasing deployment of large language models (LLMs) in natural language\nprocessing (NLP) tasks raises concerns about energy efficiency and\nsustainability. While prior research has largely focused on energy consumption\nduring model training, the inference phase has received comparatively less\nattention. This study systematically evaluates the trade-offs between model\naccuracy and energy consumption in text classification inference across various\nmodel architectures and hardware configurations. Our empirical analysis shows\nthat the best-performing model in terms of accuracy can also be\nenergy-efficient, while larger LLMs tend to consume significantly more energy\nwith lower classification accuracy. We observe substantial variability in\ninference energy consumption ($<$mWh to $>$kWh), influenced by model type,\nmodel size, and hardware specifications. Additionally, we find a strong\ncorrelation between inference energy consumption and model runtime, indicating\nthat execution time can serve as a practical proxy for energy usage in settings\nwhere direct measurement is not feasible. These findings have implications for\nsustainable AI development, providing actionable insights for researchers,\nindustry practitioners, and policymakers seeking to balance performance and\nresource efficiency in NLP applications.", "AI": {"tldr": "\u8bba\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u6587\u672c\u5206\u7c7b\u63a8\u7406\u9636\u6bb5\u4e0d\u540c\u6a21\u578b\u548c\u786c\u4ef6\u4e0b\u7684\u51c6\u786e\u7387\u4e0e\u80fd\u8017\u6743\u8861\uff0c\u53d1\u73b0\u9ad8\u51c6\u786e\u7387\u6a21\u578b\u53ef\u517c\u5177\u9ad8\u80fd\u6548\uff0c\u800c\u5927\u578b\u6a21\u578b\u80fd\u8017\u9ad8\u53cd\u800c\u8868\u73b0\u4e00\u822c\u3002\u63a8\u7406\u8fd0\u884c\u65f6\u95f4\u53ef\u4f5c\u4e3a\u80fd\u8017\u7684\u7b80\u6613\u4ee3\u7406\uff0c\u4e3a\u53ef\u6301\u7eedAI\u5e94\u7528\u548c\u51b3\u7b56\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u5728\u5927\u6a21\u578b\u6301\u7eed\u90e8\u7f72\u5230NLP\u4efb\u52a1\u7684\u8d8b\u52bf\u4e0b\uff0c\u8fc7\u53bb\u5173\u6ce8\u66f4\u591a\u7684\u662f\u8bad\u7ec3\u9636\u6bb5\u80fd\u8017\uff0c\u63a8\u7406\u9636\u6bb5\u80fd\u8017\u5374\u88ab\u5ffd\u89c6\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63a2\u7d22\u6a21\u578b\u63a8\u7406\u65f6\u7684\u80fd\u6548\u4e0e\u6027\u80fd\u5173\u7cfb\u3002", "method": "\u5bf9\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u548c\u786c\u4ef6\u914d\u7f6e\u7684\u6587\u672c\u5206\u7c7b\u63a8\u7406\u8fc7\u7a0b\u8fdb\u884c\u7cfb\u7edf\u5b9e\u8bc1\u5206\u6790\uff0c\u8861\u91cf\u51c6\u786e\u7387\u4e0e\u80fd\u8017\u7684\u6743\u8861\u3002", "result": "\u6700\u4f73\u51c6\u786e\u7387\u6a21\u578b\u4ea6\u53ef\u80fd\u80fd\u6548\u8f83\u9ad8\uff1b\u8f83\u5927\u6a21\u578b\u8017\u80fd\u660e\u663e\u589e\u52a0\u4e14\u5206\u7c7b\u51c6\u786e\u7387\u8f83\u4f4e\u3002\u80fd\u8017\u4e0e\u8fd0\u884c\u65f6\u95f4\u6709\u5f3a\u76f8\u5173\u6027\uff0c\u4e0d\u540c\u6a21\u578b\u3001\u786c\u4ef6\u4e0b\u80fd\u8017\u5dee\u5f02\u5de8\u5927\u3002", "conclusion": "\u8fd0\u884c\u65f6\u95f4\u53ef\u4ee5\u4f5c\u4e3a\u80fd\u8017\u7684\u4ee3\u7406\uff0c\u540c\u65f6\u51c6\u786e\u7387\u9ad8\u7684\u6a21\u578b\u4e5f\u53ef\u80fd\u517c\u5177\u80fd\u6548\uff0c\u4f46\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u8017\u8f83\u9ad8\u4e14\u51c6\u786e\u7387\u53cd\u800c\u8f83\u4f4e\u3002"}}
{"id": "2508.14540", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14540", "abs": "https://arxiv.org/abs/2508.14540", "authors": ["Dennis Schiese", "Andreas Both"], "title": "Post-hoc LLM-Supported Debugging of Distributed Processes", "comment": "Presented at ICWE 2025, Delft (30 June - 03 July 2025)", "summary": "In this paper, we address the problem of manual debugging, which nowadays\nremains resource-intensive and in some parts archaic. This problem is\nespecially evident in increasingly complex and distributed software systems.\nTherefore, our objective of this work is to introduce an approach that can\npossibly be applied to any system, at both the macro- and micro-level, to ease\nthis debugging process. This approach utilizes a system's process data, in\nconjunction with generative AI, to generate natural-language explanations.\nThese explanations are generated from the actual process data, interface\ninformation, and documentation to guide the developers more efficiently to\nunderstand the behavior and possible errors of a process and its sub-processes.\nHere, we present a demonstrator that employs this approach on a component-based\nJava system. However, our approach is language-agnostic. Ideally, the generated\nexplanations will provide a good understanding of the process, even if\ndevelopers are not familiar with all the details of the considered system. Our\ndemonstrator is provided as an open-source web application that is freely\naccessible to all users.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u7528\u751f\u6210\u5f0fAI\u548c\u6d41\u7a0b\u6570\u636e\u81ea\u52a8\u751f\u6210\u7cfb\u7edf\u884c\u4e3a\u89e3\u91ca\uff0c\u8f85\u52a9\u5f00\u53d1\u8005\u8c03\u8bd5\uff0c\u5c55\u793a\u4e86\u4e00\u4e2aJava\u7cfb\u7edf\u6f14\u793a\u5668\uff0c\u65b9\u6cd5\u5177\u6709\u8bed\u8a00\u65e0\u5173\u6027\uff0c\u53ef\u6210\u4e3a\u63d0\u5347\u8c03\u8bd5\u6548\u7387\u7684\u901a\u7528\u65b9\u6848\u3002", "motivation": "\u5982\u4eca\u624b\u52a8\u8c03\u8bd5\u4f9d\u7136\u8017\u65f6\u4e14\u6548\u7387\u4f4e\u4e0b\uff0c\u5c24\u5176\u5728\u590d\u6742\u3001\u5206\u5e03\u5f0f\u7684\u8f6f\u4ef6\u7cfb\u7edf\u91cc\u5c24\u4e3a\u7a81\u51fa\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u8c03\u8bd5\u6548\u7387\u3002", "method": "\u5229\u7528\u7cfb\u7edf\u7684\u6d41\u7a0b\u6570\u636e\uff0c\u7ed3\u5408\u751f\u6210\u5f0fAI\uff0c\u81ea\u52a8\u751f\u6210\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002\u8fd9\u4e9b\u89e3\u91ca\u7ed3\u5408\u4e86\u5b9e\u9645\u6d41\u7a0b\u6570\u636e\u3001\u63a5\u53e3\u4fe1\u606f\u548c\u6587\u6863\u5185\u5bb9\uff0c\u4ece\u800c\u8f85\u52a9\u5f00\u53d1\u8005\u7406\u89e3\u7cfb\u7edf\u8fc7\u7a0b\u53ca\u5176\u5b50\u8fc7\u7a0b\u7684\u884c\u4e3a\u548c\u53ef\u80fd\u51fa\u9519\u70b9\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7ec4\u4ef6\u7684Java\u7cfb\u7edf\u6f14\u793a\u5668\uff0c\u5c55\u793a\u8be5\u65b9\u6cd5\u5b9e\u9645\u4f7f\u7528\u6548\u679c\u3002\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u4e8e\u5177\u4f53\u7f16\u7a0b\u8bed\u8a00\uff0c\u9002\u7528\u4e8e\u4efb\u610f\u7cfb\u7edf\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u3001\u53ef\u5e94\u7528\u4e8e\u4e0d\u540c\u7cfb\u7edf\u5c42\u7ea7\u7684\u81ea\u52a8\u5316\u8c03\u8bd5\u8f85\u52a9\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u751f\u6210\u89e3\u91ca\u63d0\u5347\u5f00\u53d1\u8005\u5bf9\u7cfb\u7edf\u53ca\u6545\u969c\u7684\u7406\u89e3\uff0c\u662f\u8c03\u8bd5\u6548\u7387\u63d0\u5347\u7684\u65b0\u65b9\u5411\u3002"}}
{"id": "2508.14273", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2508.14273", "abs": "https://arxiv.org/abs/2508.14273", "authors": ["Krishna Garg", "Firoz Shaikh", "Sambaran Bandyopadhyay", "Cornelia Caragea"], "title": "Let's Use ChatGPT To Write Our Paper! Benchmarking LLMs To Write the Introduction of a Research Paper", "comment": "20 pages, 15 figures", "summary": "As researchers increasingly adopt LLMs as writing assistants, generating\nhigh-quality research paper introductions remains both challenging and\nessential. We introduce Scientific Introduction Generation (SciIG), a task that\nevaluates LLMs' ability to produce coherent introductions from titles,\nabstracts, and related works. Curating new datasets from NAACL 2025 and ICLR\n2025 papers, we assess five state-of-the-art models, including both open-source\n(DeepSeek-v3, Gemma-3-12B, LLaMA 4-Maverick, MistralAI Small 3.1) and\nclosed-source GPT-4o systems, across multiple dimensions: lexical overlap,\nsemantic similarity, content coverage, faithfulness, consistency, citation\ncorrectness, and narrative quality. Our comprehensive framework combines\nautomated metrics with LLM-as-a-judge evaluations. Results demonstrate LLaMA-4\nMaverick's superior performance on most metrics, particularly in semantic\nsimilarity and faithfulness. Moreover, three-shot prompting consistently\noutperforms fewer-shot approaches. These findings provide practical insights\ninto developing effective research writing assistants and set realistic\nexpectations for LLM-assisted academic writing. To foster reproducibility and\nfuture research, we will publicly release all code and datasets.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u79d1\u7814\u8bba\u6587\u5f15\u8a00\u7684\u80fd\u529b\uff0c\u63d0\u51fa\u4e86SciIG\u4efb\u52a1\u548c\u6570\u636e\u96c6\u3002\u7ed3\u679c\u663e\u793a\uff0cLLaMA-4 Maverick\u8868\u73b0\u6700\u4f73\uff0c\u4e09\u6b21\u793a\u4f8b\u8f93\u5165\u6548\u679c\u66f4\u4f18\uff0c\u76f8\u5173\u8d44\u6e90\u5c06\u516c\u5f00\uff0c\u4e3a\u5b66\u672f\u5199\u4f5c\u8f85\u52a9\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u7814\u7a76\u4eba\u5458\u8d8a\u6765\u8d8a\u591a\u5730\u91c7\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f5c\u4e3a\u5199\u4f5c\u52a9\u624b\uff0c\u4f46\u5982\u4f55\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u8bba\u6587\u5f15\u8a00\u4ecd\u5177\u6311\u6218\u6027\u4e14\u5341\u5206\u91cd\u8981\u3002\u672c\u8bba\u6587\u65e8\u5728\u8bc4\u4f30LLMs\u5728\u57fa\u4e8e\u6807\u9898\u3001\u6458\u8981\u548c\u76f8\u5173\u5de5\u4f5c\u81ea\u52a8\u751f\u6210\u79d1\u5b66\u8bba\u6587\u5f15\u8a00\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86Scientific Introduction Generation\uff08SciIG\uff09\u4efb\u52a1\uff0c\u5e76\u65b0\u5efa\u4e86\u5305\u542bNAACL 2025\u548cICLR 2025\u8bba\u6587\u7684\u65b0\u6570\u636e\u96c6\u3002\u6bd4\u8f83\u4e86\u4e94\u4e2a\u5148\u8fdb\u6a21\u578b\uff08\u5305\u62ec\u5f00\u6e90\u4e0e\u95ed\u6e90\uff09\uff0c\u5728\u8bcd\u6c47\u91cd\u5408\u5ea6\u3001\u8bed\u4e49\u76f8\u4f3c\u6027\u3001\u5185\u5bb9\u5168\u9762\u6027\u3001\u771f\u5b9e\u6027\u3001\u4e00\u81f4\u6027\u3001\u5f15\u7528\u6b63\u786e\u6027\u548c\u53d9\u4e8b\u8d28\u91cf\u7b49\u591a\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u8bc4\u6d4b\u3002\u91c7\u7528\u4e86\u81ea\u52a8\u6307\u6807\u7ed3\u5408LLM\u5224\u5b98\u8bc4\u4f30\u7684\u65b9\u6cd5\u3002", "result": "LLaMA-4 Maverick\u5728\u5927\u90e8\u5206\u6307\u6807\uff0c\u5c24\u5176\u662f\u5728\u8bed\u4e49\u76f8\u4f3c\u6027\u548c\u771f\u5b9e\u6027\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002\u6b64\u5916\uff0c\u4e09\u6b21\u793a\u4f8b\u63d0\u793a\uff08three-shot prompting\uff09\u59cb\u7ec8\u4f18\u4e8e\u66f4\u5c11\u793a\u4f8b\u3002\u76f8\u5173\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5c06\u516c\u5f00\u53d1\u5e03\uff0c\u4fc3\u8fdb\u91cd\u73b0\u6027\u4e0e\u540e\u7eed\u7814\u7a76\u3002", "conclusion": "\u672c\u6587\u4e3a\u6784\u5efa\u9ad8\u6548\u7814\u7a76\u5199\u4f5c\u52a9\u624b\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6307\u5bfc\uff0c\u5e76\u4e3aLLM\u8f85\u52a9\u5b66\u672f\u5199\u4f5c\u7684\u80fd\u529b\u8bbe\u5b9a\u4e86\u73b0\u5b9e\u9884\u671f\uff0c\u5bf9\u672a\u6765\u7814\u7a76\u5177\u6709\u63a8\u52a8\u4f5c\u7528\u3002"}}
{"id": "2508.14553", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14553", "abs": "https://arxiv.org/abs/2508.14553", "authors": ["Dennis Schiese", "Aleksandr Perevalov", "Andreas Both"], "title": "Towards LLM-generated explanations for Component-based Knowledge Graph Question Answering Systems", "comment": "Presented at ICWI 2024, Zagreb. Released with ISBN:\n  978-989-8704-62-7. Data source:\n  https://figshare.com/articles/dataset/Towards_LLM-generated_explanations_for_component-based_knowledge_graph_question_answering_systems/27079687", "summary": "Over time, software systems have reached a level of complexity that makes it\ndifficult for their developers and users to explain particular decisions made\nby them. In this paper, we focus on the explainability of component-based\nsystems for Question Answering (QA). These components often conduct processes\ndriven by AI methods, in which behavior and decisions cannot be clearly\nexplained or justified, s.t., even for QA experts interpreting the executed\nprocess and its results is hard. To address this challenge, we present an\napproach that considers the components' input and output data flows as a source\nfor representing the behavior and provide explanations for the components,\nenabling users to comprehend what happened. In the QA framework used here, the\ndata flows of the components are represented as SPARQL queries (inputs) and RDF\ntriples (outputs). Hence, we are also providing valuable insights on\nverbalization regarding these data types. In our experiments, the approach\ngenerates explanations while following template-based settings (baseline) or\nvia the use of Large Language Models (LLMs) with different configurations\n(automatic generation). Our evaluation shows that the explanations generated\nvia LLMs achieve high quality and mostly outperform template-based approaches\naccording to the users' ratings. Therefore, it enables us to automatically\nexplain the behavior and decisions of QA components to humans while using RDF\nand SPARQL as a context for explanations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u8f93\u5165\u8f93\u51fa\u6570\u636e\u6d41\u4e3a\u95ee\u7b54\u7ec4\u4ef6\u7684\u51b3\u7b56\u884c\u4e3a\u81ea\u52a8\u751f\u6210\u53ef\u89e3\u91ca\u7ed3\u679c\uff0c\u5b9e\u9a8c\u663e\u793aLLM\u751f\u6210\u7684\u89e3\u91ca\u4f18\u4e8e\u6a21\u677f\u65b9\u6cd5\uff0c\u589e\u5f3a\u4e86\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u7cfb\u7edf\u7684\u884c\u4e3a\u51b3\u7b56\u53d8\u5f97\u96be\u4ee5\u89e3\u91ca\u548c\u7406\u89e3\uff0c\u5c24\u5176\u662f\u5728\u57fa\u4e8e\u7ec4\u4ef6\u7684\u95ee\u7b54\u7cfb\u7edf\u4e2d\uff0cAI\u9a71\u52a8\u7684\u51b3\u7b56\u96be\u4ee5\u4e3a\u5f00\u53d1\u8005\u548c\u7528\u6237\u6240\u89e3\u91ca\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7ec4\u4ef6\u8f93\u5165/\u8f93\u51fa\u6570\u636e\u6d41\u6765\u89e3\u91ca\u7cfb\u7edf\u884c\u4e3a\u7684\u65b9\u6cd5\uff0c\u5e76\u5728\u95ee\u7b54\u6846\u67b6\u4e2d\u5c06\u6570\u636e\u6d41\u8f6c\u5316\u4e3aSPARQL\u67e5\u8be2\u548cRDF\u4e09\u5143\u7ec4\uff0c\u901a\u8fc7\u6a21\u677f\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u89e3\u91ca\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u91c7\u7528LLM\u81ea\u52a8\u751f\u6210\u89e3\u91ca\u7684\u8d28\u91cf\u9ad8\u4e8e\u6a21\u677f\u65b9\u6cd5\uff0c\u5927\u90e8\u5206\u60c5\u51b5\u4e0b\u83b7\u5f97\u7528\u6237\u66f4\u9ad8\u8bc4\u4ef7\u3002", "conclusion": "\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u57fa\u4e8eRDF\u548cSPARQL\u7684\u95ee\u7b54\u7ec4\u4ef6\u7684\u81ea\u52a8\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u7528\u6237\u7406\u89e3\u5176\u884c\u4e3a\u548c\u51b3\u7b56\u63d0\u4f9b\u4e86\u5e2e\u52a9\u3002"}}
{"id": "2508.14275", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14275", "abs": "https://arxiv.org/abs/2508.14275", "authors": ["Cliff O'Reilly", "Ernesto Jimenez-Ruiz", "Tillman Weyde"], "title": "Disentangling concept semantics via multilingual averaging in Sparse Autoencoders", "comment": null, "summary": "Connecting LLMs with formal knowledge representation and reasoning is a\npromising approach to address their shortcomings. Embeddings and sparse\nautoencoders are widely used to represent textual content, but the semantics\nare entangled with syntactic and language-specific information. We propose a\nmethod that isolates concept semantics in Large Langue Models by averaging\nconcept activations derived via Sparse Autoencoders. We create English text\nrepresentations from OWL ontology classes, translate the English into French\nand Chinese and then pass these texts as prompts to the Gemma 2B LLM. Using the\nopen source Gemma Scope suite of Sparse Autoencoders, we obtain concept\nactivations for each class and language version. We average the different\nlanguage activations to derive a conceptual average. We then correlate the\nconceptual averages with a ground truth mapping between ontology classes. Our\nresults give a strong indication that the conceptual average aligns to the true\nrelationship between classes when compared with a single language by itself.\nThe result hints at a new technique which enables mechanistic interpretation of\ninternal network states with higher accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u7684\u591a\u8bed\u8a00\u5e73\u5747\u6982\u5ff5\u6fc0\u6d3b\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u5bf9\u672c\u4f53\u6982\u5ff5\u8bed\u4e49\u7684\u8868\u793a\u4e0e\u5185\u90e8\u673a\u5236\u89e3\u91ca\u80fd\u529b\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u4f18\u4e8e\u5355\u8bed\u8a00\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8bed\u4e49\u63a8\u7406\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u76ee\u524d\u5e38\u7528\u7684\u6587\u672c\u8868\u793a\u65b9\u6cd5\u5982\u5d4c\u5165\u548c\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u4f1a\u6df7\u5408\u8bed\u4e49\u548c\u8bed\u6cd5\u4fe1\u606f\uff0c\u5f71\u54cd\u5bf9\u6982\u5ff5\u7684\u51c6\u786e\u8868\u8fbe\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u7ed3\u5408\u5f62\u5f0f\u77e5\u8bc6\u8868\u8fbe\u4e0e\u63a8\u7406\uff0c\u63d0\u5347LLMs\u7684\u8bed\u4e49\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u83b7\u53d6\u7531OWL\u672c\u4f53\u7c7b\u751f\u6210\u7684\u82f1\u6587\u6587\u672c\u8868\u793a\uff0c\u5e76\u5c06\u82f1\u6587\u7ffb\u8bd1\u4e3a\u6cd5\u8bed\u548c\u4e2d\u6587\uff0c\u518d\u5206\u522b\u8f93\u5165Gemma 2B LLM\u8fdb\u884c\u6982\u5ff5\u6fc0\u6d3b\u83b7\u53d6\u3002\u5c06\u4e0d\u540c\u8bed\u8a00\u4e0b\u83b7\u5f97\u7684\u6fc0\u6d3b\u7ed3\u679c\u8fdb\u884c\u5e73\u5747\uff0c\u5f97\u5230\u6982\u5ff5\u5e73\u5747\u503c\uff0c\u5e76\u4e0e\u672c\u4f53\u7c7b\u7684\u771f\u5b9e\u6620\u5c04\u8fdb\u884c\u76f8\u5173\u6027\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u8de8\u8bed\u8a00\u6982\u5ff5\u5e73\u5747\u6fc0\u6d3b\u80fd\u66f4\u51c6\u786e\u5730\u53cd\u6620\u672c\u4f53\u7c7b\u4e4b\u95f4\u7684\u771f\u5b9e\u8bed\u4e49\u5173\u7cfb\uff0c\u76f8\u8f83\u4e8e\u4ec5\u7528\u5355\u4e00\u8bed\u8a00\u7684\u6fc0\u6d3b\u7ed3\u679c\u6027\u80fd\u66f4\u4f18\u3002", "conclusion": "\u591a\u8bed\u8a00\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u6fc0\u6d3b\u5e73\u5747\u503c\u6709\u52a9\u4e8e\u9694\u79bb\u6982\u5ff5\u8bed\u4e49\uff0c\u5e76\u5728\u673a\u5236\u5c42\u9762\u63d0\u5347\u5bf9LLM\u5185\u90e8\u72b6\u6001\u7684\u89e3\u8bfb\u51c6\u786e\u5ea6\uff0c\u4e3a\u6982\u5ff5\u8868\u793a\u548c\u89e3\u91ca\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u6cd5\u601d\u8def\u3002"}}
