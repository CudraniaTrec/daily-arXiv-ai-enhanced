{"id": "2511.06862", "categories": ["cs.LO", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.06862", "abs": "https://arxiv.org/abs/2511.06862", "authors": ["Huan Sun", "David San\u00e1n", "Jingyi Wang", "Yongwang Zhao", "Jun Sun", "Wenhai Wang"], "title": "Generalized Security-Preserving Refinement for Concurrent Systems", "comment": null, "summary": "Ensuring compliance with Information Flow Security (IFS) is known to be challenging, especially for concurrent systems with large codebases such as multicore operating system (OS) kernels. Refinement, which verifies that an implementation preserves certain properties of a more abstract specification, is promising for tackling such challenges. However, in terms of refinement-based verification of security properties, existing techniques are still restricted to sequential systems or lack the expressiveness needed to capture complex security policies for concurrent systems.\n  In this work, we present a generalized security-preserving refinement technique, particularly for verifying the IFS of concurrent systems governed by potentially complex security policies. We formalize the IFS properties for concurrent systems and present a refinement-based compositional approach to prove that the generalized security properties (e.g., intransitive noninterference) are preserved between implementation and abstraction. The key intuition enabling such reasoning, compared to previous refinement work, is to establish a step-mapping relation between the implementation and the abstraction, which is sufficient to ensure that every paired step (in the abstraction and the implementation, respectively) is either permitted or prohibited by the security policy. We apply our approach to verify two non-trivial case studies against a collection of security policies. Our proofs are fully mechanized in Isabelle/HOL, during which we identified that two covert channels previously reported in the ARINC 653 single-core standard also exist in the ARINC 653 multicore standard. We subsequently proved the correctness of the revised mechanism, showcasing the effectiveness of our approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u57fa\u4e8e\u7cbe\u5316\u7684\u4fe1\u606f\u6d41\u5b89\u5168\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u590d\u6742\u5b89\u5168\u7b56\u7565\u4e0b\u7684\u5e76\u53d1\u7cfb\u7edf\u3002\u7406\u8bba\u521b\u65b0\u70b9\u5728\u4e8e\u62bd\u8c61\u548c\u5b9e\u73b0\u4e4b\u95f4\u7684\u9010\u6b65\u6620\u5c04\uff0c\u65b9\u6cd5\u5df2\u5728Isabelle/HOL\u4e0b\u8fdb\u884c\u673a\u68b0\u5316\u9a8c\u8bc1\uff0c\u5e76\u6210\u529f\u53d1\u73b0\u53ca\u4fee\u6b63\u4e86\u591a\u6838\u822a\u7a7a\u6807\u51c6\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "motivation": "\u4fe1\u606f\u6d41\u5b89\u5168(IFC)\u5bf9\u5e76\u53d1\u7cfb\u7edf\uff0c\u5c24\u5176\u662f\u5927\u89c4\u6a21\u4ee3\u7801\u57fa\u7840\uff08\u5982\u591a\u6838OS\u5185\u6838\uff09\u6765\u8bf4\u6781\u5177\u6311\u6218\u6027\u3002\u73b0\u6709\u57fa\u4e8e\u7cbe\u5316\u7684\u5b89\u5168\u9a8c\u8bc1\u6280\u672f\u8981\u4e48\u4ec5\u9002\u7528\u987a\u5e8f\u7cfb\u7edf\uff0c\u8981\u4e48\u96be\u4ee5\u8868\u8fbe\u5e76\u53d1\u7cfb\u7edf\u4e2d\u7684\u590d\u6742\u5b89\u5168\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u5e76\u5f62\u5f0f\u5316\u4e86\u4e00\u79cd\u57fa\u4e8e\u7cbe\u5316\u7684\u7ec4\u5408\u5f0f\u5b89\u5168\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u5b9e\u73b0\u548c\u62bd\u8c61\u4e4b\u95f4\u5efa\u7acb\u9010\u6b65\u6620\u5c04\u5173\u7cfb\uff0c\u8bc1\u660e\u63a8\u5e7f\u5316\u7684\u4fe1\u606f\u6d41\u5b89\u5168\u5c5e\u6027\uff08\u5982\u975e\u4f20\u9012\u975e\u5e72\u6d89\u6027\uff09\u5728\u5b9e\u73b0\u4e0e\u62bd\u8c61\u4e4b\u95f4\u5f97\u5230\u4fdd\u6301\u3002\u6240\u6709\u8bc1\u660e\u90fd\u5728Isabelle/HOL\u4e2d\u673a\u68b0\u5316\u5b8c\u6210\u3002", "result": "\u6240\u63d0\u65b0\u65b9\u6cd5\uff081\uff09\u5728\u7406\u8bba\u4e0a\u63a8\u5e7f\u4e86\u7cbe\u5316\u6280\u672f\u652f\u6301\u590d\u6742\u7b56\u7565\u4e0b\u5e76\u53d1\u7cfb\u7edf\u7684IFC\uff1b\uff082\uff09\u901a\u8fc7\u4e24\u4e2a\u975e\u5e73\u51e1\u6848\u4f8b\u7684\u5168\u9762\u673a\u68b0\u5316\u9a8c\u8bc1\uff0c\u53d1\u73b0\u5e76\u4fee\u6b63\u4e86ARINC 653\u591a\u6838\u6807\u51c6\u4e2d\u7684\u9690\u853d\u901a\u9053\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u5730\u5bf9\u5e76\u53d1\u7cfb\u7edf\u4e2d\u7684\u4fe1\u606f\u6d41\u5b89\u5168\u6027(IFC)\u8fdb\u884c\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u5e76\u80fd\u53d1\u73b0\u5e76\u4fee\u6b63\u590d\u6742\u5b89\u5168\u7b56\u7565\u4e0b\u7684\u5b89\u5168\u6f0f\u6d1e\u3002"}}
{"id": "2511.07293", "categories": ["cs.LO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.07293", "abs": "https://arxiv.org/abs/2511.07293", "authors": ["Mohammad Afzal", "S. Akshay", "Ashutosh Gupta"], "title": "Verifying rich robustness properties for neural networks", "comment": null, "summary": "Robustness is a important problem in AI alignment and safety, with models such as neural networks being increasingly used in safety-critical systems. In the last decade, a large body of work has emerged on local robustness, i.e., checking if the decision of a neural network remains unchanged when the input is slightly perturbed. However, many of these approaches require specialized encoding and often ignore the confidence of a neural network on its output. In this paper, our goal is to build a generalized framework to specify and verify variants of robustness in neural network verification. We propose a specification framework using a simple grammar, which is flexible enough to capture most existing variants. This allows us to introduce new variants of robustness that take into account the confidence of the neural network in its outputs. Next, we develop a novel and powerful unified technique to verify all such variants in a homogeneous way, viz., by adding a few additional layers to the neural network. This enables us to use any state-of-the-art neural network verification tool, without having to tinker with the encoding within, while incurring an approximation error that we show is bounded. We perform an extensive experimental evaluation over a large suite of 8870 benchmarks having 138M parameters in a largest network, and show that we are able to capture a wide set of robustness variants and outperform direct encoding approaches by a significant margin.", "AI": {"tldr": "\u8fd9\u9879\u5de5\u4f5c\u63d0\u51fa\u4e86\u901a\u7528\u4e14\u7075\u6d3b\u7684\u795e\u7ecf\u7f51\u7edc\u9c81\u68d2\u6027\u9a8c\u8bc1\u6846\u67b6\uff0c\u80fd\u7edf\u4e00\u5904\u7406\u591a\u79cd\u9c81\u68d2\u6027\u53d8\u4f53\u548c\u7f6e\u4fe1\u5ea6\u9700\u6c42\uff0c\u4e0d\u4f9d\u8d56\u7e41\u7410\u7f16\u7801\uff0c\u5b9e\u9a8c\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347AI\u5b89\u5168\u9a8c\u8bc1\u80fd\u529b\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u5728\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u5bf9\u5176\u9c81\u68d2\u6027\uff08\u5728\u8f93\u5165\u6270\u52a8\u4e0b\u51b3\u7b56\u4e0d\u53d8\u6027\uff09\u9a8c\u8bc1\u5c24\u4e3a\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\u4e8e\u7279\u5b9a\u7f16\u7801\u4e14\u5e38\u5ffd\u89c6\u7f51\u7edc\u8f93\u51fa\u7684\u7f6e\u4fe1\u5ea6\uff0c\u7f3a\u4e4f\u901a\u7528\u9a8c\u8bc1\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7b80\u5355\u8bed\u6cd5\u89c4\u8303\u7684\u901a\u7528\u6846\u67b6\uff0c\u53ef\u4ee5\u7075\u6d3b\u63cf\u8ff0\u548c\u9a8c\u8bc1\u5927\u591a\u6570\u5df2\u77e5\u53ca\u65b0\u7684\u9c81\u68d2\u6027\u53d8\u4f53\uff08\u5305\u62ec\u8f93\u51fa\u7f6e\u4fe1\u5ea6\u56e0\u7d20\uff09\u3002\u6838\u5fc3\u65b9\u6cd5\u662f\u901a\u8fc7\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u589e\u52a0\u51e0\u5c42\uff0c\u5b9e\u73b0\u5bf9\u6240\u6709\u9c81\u68d2\u6027\u53d8\u4f53\u7684\u7edf\u4e00\u9a8c\u8bc1\uff0c\u5e76\u80fd\u76f4\u63a5\u914d\u5408\u4efb\u4f55\u73b0\u6709\u9a8c\u8bc1\u5de5\u5177\uff0c\u65e0\u9700\u4fee\u6539\u5e95\u5c42\u7f16\u7801\uff0c\u540c\u65f6\u4fdd\u8bc1\u8bef\u5dee\u6709\u754c\u3002", "result": "\u57288870\u4e2a\u57fa\u51c6\uff08\u6700\u5927\u7f51\u7edc\u53c2\u6570\u91cf\u8fbe1.38\u4ebf\uff09\u4e0a\u5927\u89c4\u6a21\u5b9e\u9a8c\uff0c\u6210\u529f\u6355\u6349\u5e7f\u6cdb\u7684\u9c81\u68d2\u6027\u53d8\u4f53\uff0c\u9a8c\u8bc1\u6846\u67b6\u5728\u6548\u7387\u548c\u8868\u73b0\u4e0a\u4f18\u4e8e\u4f20\u7edf\u76f4\u63a5\u7f16\u7801\u65b9\u6cd5\uff0c\u5e76\u5177\u5907\u5e7f\u6cdb\u9002\u7528\u6027\u3002", "conclusion": "\u8bba\u6587\u6784\u5efa\u4e86\u7075\u6d3b\u4e14\u901a\u7528\u7684\u795e\u7ecf\u7f51\u7edc\u9c81\u68d2\u6027\u9a8c\u8bc1\u6846\u67b6\uff0c\u5c06\u591a\u4e2a\u9c81\u68d2\u6027\u53d8\u4f53\u53ca\u7f6e\u4fe1\u5ea6\u56e0\u7d20\u7edf\u4e00\u7eb3\u5165\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u5927\u5e45\u63d0\u5347\u9a8c\u8bc1\u6548\u7387\u548c\u8303\u56f4\u3002\u8be5\u6846\u67b6\u5bf9\u5b89\u5168\u5173\u952e\u5e94\u7528\u7684AI\u7cfb\u7edf\u53ef\u4fe1\u5ea6\u63d0\u5347\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.05626", "categories": ["cs.SE", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.05626", "abs": "https://arxiv.org/abs/2511.05626", "authors": ["Caetano Melone", "Daniel Nichols", "Konstantinos Parasyris", "Todd Gamblin", "Harshitha Menon"], "title": "LLMs as Packagers of HPC Software", "comment": null, "summary": "High performance computing (HPC) software ecosystems are inherently heterogeneous, comprising scientific applications that depend on hundreds of external packages, each with distinct build systems, options, and dependency constraints. Tools such as Spack automate dependency resolution and environment management, but their effectiveness relies on manually written build recipes. As these ecosystems grow, maintaining existing specifications and creating new ones becomes increasingly labor-intensive. While large language models (LLMs) have shown promise in code generation, automatically producing correct and maintainable Spack recipes remains a significant challenge. We present a systematic analysis of how LLMs and context-augmentation methods can assist in the generation of Spack recipes. To this end, we introduce SpackIt, an end-to-end framework that combines repository analysis, retrieval of relevant examples, and iterative refinement through diagnostic feedback. We apply SpackIt to a representative subset of 308 open-source HPC packages to assess its effectiveness and limitations. Our results show that SpackIt increases installation success from 20% in a zero-shot setting to over 80% in its best configuration, demonstrating the value of retrieval and structured feedback for reliable package synthesis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SpackIt\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u3001\u68c0\u7d22\u548c\u53cd\u9988\u673a\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u4e86LLM\u81ea\u52a8\u751f\u6210Spack\u5305\u914d\u65b9\u7684\u53ef\u9760\u6027\u548c\u6210\u529f\u7387\uff0c\u4e3aHPC\u751f\u6001\u7cfb\u7edf\u7684\u4f9d\u8d56\u7ba1\u7406\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u590d\u6742\uff0c\u7ef4\u62a4\u548c\u521b\u5efaSpack\u4f9d\u8d56\u5305\u914d\u65b9\uff08recipe\uff09\u5341\u5206\u7e41\u7410\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u5de5\u5177\u4f9d\u8d56\u624b\u5de5\u7f16\u5199\uff0c\u9762\u4e34\u53ef\u6269\u5c55\u6027\u6311\u6218\u3002\u7814\u7a76\u52a8\u673a\u662f\u5bfb\u6c42\u81ea\u52a8\u5316\u3001\u53ef\u7ef4\u62a4\u7684\u4f9d\u8d56\u7ba1\u7406\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSpackIt\u6846\u67b6\uff0c\u6574\u5408\u4ee3\u7801\u4ed3\u5e93\u5206\u6790\u3001\u76f8\u5173\u793a\u4f8b\u68c0\u7d22\u548c\u57fa\u4e8e\u8bca\u65ad\u53cd\u9988\u7684\u8fed\u4ee3\u7cbe\u70bc\uff0c\u7cfb\u7edf\u6027\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u53ca\u4e0a\u4e0b\u6587\u589e\u5f3a\u65b9\u6cd5\u751f\u6210Spack\u914d\u65b9\u7684\u80fd\u529b\uff0c\u5e76\u5728308\u4e2a\u5f00\u6e90HPC\u8f6f\u4ef6\u5305\u4e0a\u6d4b\u8bd5\u3002", "result": "SpackIt\u6846\u67b6\u5c06Spack\u5305\u5b89\u88c5\u6210\u529f\u7387\u4ece\u96f6\u6837\u672c\uff08zero-shot\uff09\u768420%\u63d0\u5347\u5230\u6700\u4f18\u914d\u7f6e\u4e0b\u768480%\u4ee5\u4e0a\uff0c\u6709\u6548\u5229\u7528\u4fe1\u606f\u68c0\u7d22\u4e0e\u7ed3\u6784\u5316\u53cd\u9988\uff0c\u63d0\u9ad8\u5305\u6784\u5efa\u7684\u81ea\u52a8\u5316\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u3001\u793a\u4f8b\u68c0\u7d22\u548c\u8bca\u65ad\u53cd\u9988\u80fd\u660e\u663e\u63d0\u9ad8\u81ea\u52a8\u751f\u6210Spack\u5305\u914d\u65b9\u7684\u51c6\u786e\u7387\u548c\u53ef\u7ef4\u62a4\u6027\uff0c\u662f\u81ea\u52a8\u5316\u901a\u7528\u5305\u7ba1\u7406\u7684\u91cd\u8981\u6280\u672f\u9014\u5f84\u3002"}}
{"id": "2511.05516", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2511.05516", "abs": "https://arxiv.org/abs/2511.05516", "authors": ["Canxiang Yan", "Chunxiang Jin", "Dawei Huang", "Haibing Yu", "Han Peng", "Hui Zhan", "Jie Gao", "Jing Peng", "Jingdong Chen", "Jun Zhou", "Kaimeng Ren", "Ming Yang", "Mingxue Yang", "Qiang Xu", "Qin Zhao", "Ruijie Xiong", "Shaoxiong Lin", "Xuezhi Wang", "Yi Yuan", "Yifei Wu", "Yongjie Lyu", "Zhengyu He", "Zhihao Qiu", "Zhiqiang Fang", "Ziyuan Huang"], "title": "Ming-UniAudio: Speech LLM for Joint Understanding, Generation and Editing with Unified Representation", "comment": "32 pages, 8 figures", "summary": "Existing speech models suffer from competing requirements on token representations by understanding and generation tasks. This discrepancy in representation prevents speech language models from performing instruction-based free-form editing. To solve this challenge, we introduce a novel framework that unifies speech understanding, generation, and editing. The core of our unified model is a unified continuous speech tokenizer MingTok-Audio, the first continuous tokenizer to effectively integrate semantic and acoustic features, which makes it suitable for both understanding and generation tasks. Based on this unified continuous audio tokenizer, we developed the speech language model Ming-UniAudio, which achieved a balance between generation and understanding capabilities. Ming-UniAudio sets new state-of-the-art (SOTA) records on 8 out of 12 metrics on the ContextASR benchmark. Notably, for Chinese voice cloning, it achieves a highly competitive Seed-TTS-WER of 0.95. Leveraging this foundational model, we further trained a dedicated speech editing model Ming-UniAudio-Edit, the first speech language model that enables universal, free-form speech editing guided solely by natural language instructions, handling both semantic and acoustic modifications without timestamp condition. To rigorously assess the editing capability and establish a foundation for future research, we introduce Ming-Freeform-Audio-Edit, the first comprehensive benchmark tailored for instruction-based free-form speech editing, featuring diverse scenarios and evaluation dimensions spanning semantic correctness, acoustic quality, and instruction alignment. We open-sourced the continuous audio tokenizer, the unified foundational model, and the free-form instruction-based editing model to facilitate the development of unified audio understanding, generation, and manipulation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u53ef\u7edf\u4e00\u7406\u89e3\u3001\u751f\u6210\u53ca\u7f16\u8f91\u7684\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u4e0e\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u65b0\u8fde\u7eed\u5206\u8bcd\u5668\u4e0e\u7edf\u4e00\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u9886\u5148\u7684\u8bed\u97f3\u7406\u89e3\u4e0e\u751f\u6210\u6027\u80fd\uff0c\u9996\u6b21\u652f\u6301\u57fa\u4e8e\u81ea\u7531\u6307\u4ee4\u7684\u8bed\u97f3\u7f16\u8f91\uff0c\u5e76\u5f00\u6e90\u4e86\u6240\u6709\u65b9\u6cd5\u4e0e\u8bc4\u6d4b\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u7684\u8bed\u97f3\u6a21\u578b\u5728\u7406\u89e3\u4e0e\u751f\u6210\u4efb\u52a1\u5bf9 token \u8868\u793a\u7684\u9700\u6c42\u4e0a\u5b58\u5728\u51b2\u7a81\u3002\u8fd9\u79cd\u8868\u793a\u4e0a\u7684\u4e0d\u4e00\u81f4\u4f7f\u5f97\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u8fdb\u884c\u57fa\u4e8e\u6307\u4ee4\u7684\u81ea\u7531\u7f16\u8f91\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u8bed\u97f3\u7406\u89e3\u3001\u751f\u6210\u4e0e\u7f16\u8f91\u7684\u6846\u67b6\u3002", "method": "\u672c\u6587\u6838\u5fc3\u65b9\u6cd5\u662f\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u8fde\u7eed\u8bed\u97f3\u5206\u8bcd\u5668 MingTok-Audio\uff0c\u80fd\u6709\u6548\u6574\u5408\u8bed\u4e49\u4e0e\u58f0\u5b66\u7279\u5f81\uff0c\u5e76\u636e\u6b64\u5f00\u53d1\u4e86\u7edf\u4e00\u8bed\u97f3\u8bed\u8a00\u6a21\u578b Ming-UniAudio\uff0c\u5b9e\u73b0\u7406\u89e3\u4e0e\u751f\u6210\u80fd\u529b\u7684\u5e73\u8861\u3002\u6b64\u5916\uff0c\u8fdb\u4e00\u6b65\u8bad\u7ec3\u4e86\u4e13\u7528\u8bed\u97f3\u7f16\u8f91\u6a21\u578b Ming-UniAudio-Edit\uff0c\u5b9e\u73b0\u7eaf\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u7684\u8bed\u97f3\u81ea\u7531\u7f16\u8f91\uff0c\u65e0\u9700\u65f6\u95f4\u6233\u6761\u4ef6\uff0c\u5e76\u63a8\u51fa\u4e86\u7efc\u5408\u6027\u57fa\u51c6 Ming-Freeform-Audio-Edit\u3002", "result": "Ming-UniAudio \u5728 ContextASR \u57fa\u51c6\u4e0a\u7684 12 \u9879\u6307\u6807\u4e2d\u5237\u65b0 8 \u9879 SOTA \u7eaa\u5f55\uff0c\u5e76\u5728\u4e2d\u6587\u8bed\u97f3\u514b\u9686\u4efb\u52a1\u4e2d\u83b7\u5f97 Seed-TTS-WER 0.95 \u7684\u7ade\u4e89\u6027\u6210\u7ee9\u3002Ming-UniAudio-Edit \u53ef\u5b9e\u73b0\u8bed\u4e49\u4e0e\u58f0\u5b66\u7684\u6307\u4ee4\u6027\u81ea\u7531\u7f16\u8f91\uff0cMing-Freeform-Audio-Edit \u4f5c\u4e3a\u9996\u4e2a\u76f8\u5173\u57fa\u51c6\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u8bc4\u6d4b\u57fa\u7840\u3002", "conclusion": "\u672c\u6587\u5f00\u6e90\u4e86\u8fde\u7eed\u97f3\u9891\u5206\u8bcd\u5668\u3001\u7edf\u4e00\u57fa\u7840\u6a21\u578b\u53ca\u7f16\u8f91\u6a21\u578b\uff0c\u63a8\u52a8\u4e86\u7edf\u4e00\u97f3\u9891\u7406\u89e3\u3001\u751f\u6210\u4e0e\u7f16\u8f91\u7684\u53d1\u5c55\uff0c\u4e3a\u6307\u4ee4\u4e3a\u5bfc\u5411\u7684\u8bed\u97f3\u5904\u7406\u4efb\u52a1\u5960\u5b9a\u4e86\u6280\u672f\u4e0e\u8bc4\u6d4b\u57fa\u7840\u3002"}}
{"id": "2511.05663", "categories": ["cs.SE", "physics.acc-ph"], "pdf": "https://arxiv.org/pdf/2511.05663", "abs": "https://arxiv.org/abs/2511.05663", "authors": ["M. Gonzalez", "M. Acosta"], "title": "Accelerating Control Systems with GitOps: A Path to Automation and Reliability", "comment": null, "summary": "GitOps is a foundational approach for modernizing infrastructure by leveraging Git as the single source of truth for declarative configurations. The poster explores how GitOps transforms traditional control system infrastructure, services and applications by enabling fully automated, auditable, and version-controlled infrastructure management. Cloud-native and containerized environments are shifting the ecosystem not only in the IT industry but also within the computational science field, as is the case of CERN [1] and Diamond Light Source [2] among other Accelerator/Science facilities which are slowly shifting towards modern software and infrastructure paradigms. The ACORN project, which aims to modernize Fermilab's control system infrastructure and software is implementing proven best-practices and cutting-edge technology standards including GitOps, containerization, infrastructure as code and modern data pipelines for control system data acquisition and the inclusion of AI/ML in our accelerator complex.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c55\u793a\u4e86\u901a\u8fc7GitOps\u7b49\u73b0\u4ee3\u6280\u672f\u624b\u6bb5\uff0c\u79d1\u5b66\u5b9e\u9a8c\u8bbe\u65bd\u5982\u4f55\u5b9e\u73b0\u57fa\u7840\u8bbe\u65bd\u548c\u5e94\u7528\u7684\u81ea\u52a8\u5316\u3001\u667a\u80fd\u5316\u4e0e\u73b0\u4ee3\u5316\u5347\u7ea7\u3002", "motivation": "\u79d1\u5b66\u8bbe\u65bd\uff08\u5982CERN\u3001Diamond Light Source\u7b49\uff09\u6b63\u9010\u6b65\u8fc8\u5411\u73b0\u4ee3\u8f6f\u4ef6\u4e0e\u57fa\u7840\u8bbe\u65bd\u6a21\u5f0f\uff0c\u4f46\u5b9e\u9645\u8f6c\u578b\u9762\u4e34\u6311\u6218\u3002\u672c\u9879\u76ee\u65e8\u5728\u52a0\u5feb\u8bbe\u65bd\u7ba1\u7406\u4e0e\u6570\u636e\u91c7\u96c6\u7684\u81ea\u52a8\u5316\u548c\u667a\u80fd\u5316\u8fdb\u7a0b\u3002", "method": "\u901a\u8fc7\u5728\u50cfFermilab\u8fd9\u6837\u7684\u79d1\u5b66\u52a0\u901f\u5668\u8bbe\u65bd\u5f15\u5165GitOps\u3001\u5bb9\u5668\u5316\u3001\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801\u3001\u73b0\u4ee3\u6570\u636e\u7ba1\u9053\uff0c\u4ee5\u53caAI/ML\u6280\u672f\uff0c\u5b9e\u8df5\u5e76\u63a2\u7d22\u8fd9\u4e9b\u65b9\u6cd5\u7684\u5e94\u7528\u6548\u679c\u3002", "result": "ACORN\u9879\u76ee\u5df2\u5c06GitOps\u53ca\u76f8\u5173\u6280\u672f\u5e94\u7528\u4e8e\u63a7\u5236\u7cfb\u7edf\u73b0\u4ee3\u5316\uff0c\u5305\u62ec\u5b9e\u73b0\u81ea\u52a8\u5316\u90e8\u7f72\u4e0e\u7ba1\u7406\uff0c\u63d0\u5347\u6570\u636e\u5904\u7406\u80fd\u529b\uff0c\u5e76\u5f00\u59cb\u878d\u5408AI/ML\u4f18\u5316\u8bbe\u65bd\u8fd0\u8425\u3002", "conclusion": "GitOps\u7b49\u73b0\u4ee3\u5de5\u7a0b\u5b9e\u8df5\u6709\u52a9\u4e8e\u5b9e\u73b0\u81ea\u52a8\u5316\u3001\u53ef\u5ba1\u8ba1\u548c\u7248\u672c\u63a7\u5236\u7684\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\uff0c\u63a8\u52a8\u79d1\u5b66\u8bbe\u65bd\u7684\u8f6f\u4ef6\u4e0e\u786c\u4ef6\u73b0\u4ee3\u5316\u3002"}}
{"id": "2511.05518", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05518", "abs": "https://arxiv.org/abs/2511.05518", "authors": ["Myeongseob Ko", "Nikhil Reddy Billa", "Adam Nguyen", "Charles Fleming", "Ming Jin", "Ruoxi Jia"], "title": "Retracing the Past: LLMs Emit Training Data When They Get Lost", "comment": "The 2025 Conference on Empirical Methods in Natural Language Processing", "summary": "The memorization of training data in large language models (LLMs) poses significant privacy and copyright concerns. Existing data extraction methods, particularly heuristic-based divergence attacks, often exhibit limited success and offer limited insight into the fundamental drivers of memorization leakage. This paper introduces Confusion-Inducing Attacks (CIA), a principled framework for extracting memorized data by systematically maximizing model uncertainty. We empirically demonstrate that the emission of memorized text during divergence is preceded by a sustained spike in token-level prediction entropy. CIA leverages this insight by optimizing input snippets to deliberately induce this consecutive high-entropy state. For aligned LLMs, we further propose Mismatched Supervised Fine-tuning (SFT) to simultaneously weaken their alignment and induce targeted confusion, thereby increasing susceptibility to our attacks. Experiments on various unaligned and aligned LLMs demonstrate that our proposed attacks outperform existing baselines in extracting verbatim and near-verbatim training data without requiring prior knowledge of the training data. Our findings highlight persistent memorization risks across various LLMs and offer a more systematic method for assessing these vulnerabilities.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u6a21\u578b\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u9ad8\u70b9\uff0c\u63d0\u51faCIA\u6846\u67b6\uff0c\u53ef\u9ad8\u6548\u63d0\u53d6LLMs\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u63ed\u793a\u4e3b\u6d41LLMs\u666e\u904d\u5b58\u5728\u8bb0\u5fc6\u6cc4\u6f0f\u98ce\u9669\uff0c\u5bf9\u654f\u611f\u6570\u636e\u5e94\u7528\u5e26\u6765\u8b66\u793a\u3002", "motivation": "\u5f53\u524d\u5927\u6a21\u578b\u5bf9\u8bad\u7ec3\u6570\u636e\u7684\u8bb0\u5fc6\u5e26\u6765\u9690\u79c1\u548c\u7248\u6743\u98ce\u9669\uff0c\u800c\u73b0\u6709\u6570\u636e\u63d0\u53d6\u65b9\u6cd5\u6548\u679c\u6709\u9650\uff0c\u4e14\u672a\u80fd\u6df1\u5165\u63ed\u793a\u8bb0\u5fc6\u6cc4\u6f0f\u7684\u5173\u952e\u673a\u5236\u3002\u56e0\u6b64\u4e9f\u9700\u66f4\u7cfb\u7edf\u4e14\u6709\u6548\u7684\u653b\u51fb\u4e0e\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51faConfusion-Inducing Attacks\uff08CIA\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u8f93\u5165\u5e8f\u5217\u4f7f\u6a21\u578b\u4ea7\u751f\u8fde\u7eed\u9ad8\u71b5\u72b6\u6001\uff0c\u4ece\u800c\u5bfc\u81f4\u6a21\u578b\u6cc4\u6f0f\u8bb0\u5fc6\u5185\u5bb9\u3002\u540c\u65f6\u9488\u5bf9\u5bf9\u9f50\u540e\u7684LLMs\uff0c\u63d0\u51faMismatched Supervised Fine-tuning\uff08SFT\uff09\u65b9\u6cd5\u4ee5\u524a\u5f31\u6a21\u578b\u5bf9\u9f50\uff0c\u63d0\u5347\u653b\u51fb\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cCIA\u653b\u51fb\u5728\u591a\u79cd\uff08\u5bf9\u9f50\u4e0e\u975e\u5bf9\u9f50\uff09LLMs\u4e0a\u80fd\u591f\u66f4\u9ad8\u6548\u5730\u63d0\u53d6\u539f\u6587\u6216\u8fd1\u4f3c\u539f\u6587\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u4e14\u65e0\u9700\u9884\u77e5\u8bad\u7ec3\u96c6\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5404\u7c7bLLMs\u90fd\u5b58\u5728\u6301\u7eed\u7684\u8bb0\u5fc6\u6cc4\u6f0f\u98ce\u9669\uff0c\u901a\u8fc7\u4f5c\u8005\u63d0\u51fa\u7684CIA\u65b9\u6cd5\u53ef\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u548c\u6316\u6398\u8fd9\u4e9b\u98ce\u9669\uff0c\u73b0\u6709\u9632\u62a4\u63aa\u65bd\u5b58\u5728\u4e0d\u8db3\u3002"}}
{"id": "2511.06117", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.06117", "abs": "https://arxiv.org/abs/2511.06117", "authors": ["Yacine Hakimi", "Riyadh Baghdadi"], "title": "A Data-driven Analysis of Code Optimizations", "comment": null, "summary": "As the demand for computational power grows, optimizing code through compilers becomes increasingly crucial. In this context, we focus on fully automatic code optimization techniques that automate the process of selecting and applying code transformations for better performance without manual intervention. Understanding how these transformations behave and interact is key to designing more effective optimization strategies. Compiler developers must make numerous design choices when constructing these heuristics. For instance, they may decide whether to allow transformations to be explored in any arbitrary order or to enforce a fixed sequence. While the former may theoretically offer the best performance gains, it significantly increases the search space. This raises an important question: Can a predefined, fixed order of applying transformations speed up the search without severely compromising optimization potential? In this paper, we address this and other related questions that arise in the design of automatic code optimization algorithms. Using a data-driven approach, we generate a large dataset of random programs, apply random optimization sequences, and record their execution times. Through statistical analysis, we provide insights that guide the development of more efficient automatic code optimization algorithms.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5927\u89c4\u6a21\u6570\u636e\u5b9e\u9a8c\uff0c\u5206\u6790\u4e86\u81ea\u52a8\u4ee3\u7801\u4f18\u5316\u4e2d\u4f18\u5316\u987a\u5e8f\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u56fa\u5b9a\u987a\u5e8f\u53ef\u517c\u987e\u6548\u7387\u548c\u6027\u80fd\uff0c\u4e3a\u7f16\u8bd1\u5668\u4f18\u5316\u7b56\u7565\u63d0\u4f9b\u65b0\u601d\u8def\u3002", "motivation": "\u968f\u7740\u8ba1\u7b97\u9700\u6c42\u7684\u589e\u957f\uff0c\u81ea\u52a8\u5316\u7f16\u8bd1\u5668\u4f18\u5316\u53d8\u5f97\u6108\u53d1\u91cd\u8981\u3002\u5982\u4f55\u81ea\u52a8\u9009\u62e9\u548c\u5e94\u7528\u4f18\u5316\u53d8\u6362\u4ee5\u63d0\u5347\u6027\u80fd\uff0c\u4e14\u65e0\u9700\u4eba\u5de5\u5e72\u9884\uff0c\u662f\u5f53\u524d\u9762\u4e34\u7684\u6838\u5fc3\u6311\u6218\u3002\u7406\u89e3\u4e0d\u540c\u53d8\u6362\u4e4b\u95f4\u7684\u4f5c\u7528\u548c\u76f8\u4e92\u5f71\u54cd\uff0c\u6709\u52a9\u4e8e\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u4f18\u5316\u7b56\u7565\u3002\u540c\u65f6\uff0c\u5982\u4f55\u6743\u8861\u641c\u7d22\u7a7a\u95f4\u4e0e\u4f18\u5316\u6f5c\u529b\uff0c\u662f\u7f16\u8bd1\u5668\u5f00\u53d1\u4e2d\u96be\u4ee5\u56de\u907f\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff1a\u751f\u6210\u5927\u91cf\u968f\u673a\u7a0b\u5e8f\uff0c\u968f\u673a\u8fdb\u884c\u4f18\u5316\u53d8\u6362\u987a\u5e8f\uff0c\u5e76\u8bb0\u5f55\u6bcf\u4e2a\u7a0b\u5e8f\u7684\u6267\u884c\u65f6\u95f4\u3002\u4e4b\u540e\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\uff0c\u63a2\u8ba8\u4e0d\u540c\u4f18\u5316\u987a\u5e8f\u5bf9\u641c\u7d22\u7a7a\u95f4\u548c\u4f18\u5316\u6548\u679c\u7684\u5f71\u54cd\u3002", "result": "\u901a\u8fc7\u6570\u636e\u5206\u6790\uff0c\u63ed\u793a\u4e86\u4f18\u5316\u53d8\u6362\u987a\u5e8f\u7684\u8bbe\u8ba1\u5bf9\u81ea\u52a8\u5316\u7f16\u8bd1\u4f18\u5316\u7b97\u6cd5\u6548\u7387\u548c\u6f5c\u529b\u7684\u5f71\u54cd\uff0c\u4e3a\u66f4\u9ad8\u6548\u81ea\u52a8\u4f18\u5316\u7b97\u6cd5\u7684\u8bbe\u8ba1\u63d0\u4f9b\u6570\u636e\u652f\u6301\u3002", "conclusion": "\u9884\u5b9a\u4e49\u3001\u56fa\u5b9a\u7684\u4f18\u5316\u987a\u5e8f\u5728\u63d0\u5347\u641c\u7d22\u901f\u5ea6\u65b9\u9762\u5177\u6709\u5b9e\u9645\u4ef7\u503c\uff0c\u4e14\u4e0d\u4f1a\u4e25\u91cd\u635f\u5bb3\u4f18\u5316\u6f5c\u529b\u3002\u76f8\u5173\u53d1\u73b0\u4e3a\u81ea\u52a8\u4ee3\u7801\u4f18\u5316\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u51fa\u4e86\u53ef\u884c\u6027\u5efa\u8bae\u3002"}}
{"id": "2511.05532", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05532", "abs": "https://arxiv.org/abs/2511.05532", "authors": ["Rufan Zhang", "Lin Zhang", "Xianghang Mi"], "title": "Beyond One-Size-Fits-All: Personalized Harmful Content Detection with In-Context Learning", "comment": null, "summary": "The proliferation of harmful online content--e.g., toxicity, spam, and negative sentiment--demands robust and adaptable moderation systems. However, prevailing moderation systems are centralized and task-specific, offering limited transparency and neglecting diverse user preferences--an approach ill-suited for privacy-sensitive or decentralized environments. We propose a novel framework that leverages in-context learning (ICL) with foundation models to unify the detection of toxicity, spam, and negative sentiment across binary, multi-class, and multi-label settings. Crucially, our approach enables lightweight personalization, allowing users to easily block new categories, unblock existing ones, or extend detection to semantic variations through simple prompt-based interventions--all without model retraining. Extensive experiments on public benchmarks (TextDetox, UCI SMS, SST2) and a new, annotated Mastodon dataset reveal that: (i) foundation models achieve strong cross-task generalization, often matching or surpassing task-specific fine-tuned models; (ii) effective personalization is achievable with as few as one user-provided example or definition; and (iii) augmenting prompts with label definitions or rationales significantly enhances robustness to noisy, real-world data. Our work demonstrates a definitive shift beyond one-size-fits-all moderation, establishing ICL as a practical, privacy-preserving, and highly adaptable pathway for the next generation of user-centric content safety systems. To foster reproducibility and facilitate future research, we publicly release our code on GitHub and the annotated Mastodon dataset on Hugging Face.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u57fa\u4e8eICL\u548c\u5927\u6a21\u578b\u7684\u5185\u5bb9\u5ba1\u6838\u65b0\u6846\u67b6\uff0c\u5b9e\u73b0\u6bd2\u6027\u3001\u5783\u573e\u4fe1\u606f\u3001\u8d1f\u9762\u60c5\u7eea\u591a\u4efb\u52a1\u7edf\u4e00\u68c0\u6d4b\u3002\u65e0\u9700\u518d\u8bad\u7ec3\uff0c\u5177\u5907\u6781\u5f3a\u4e2a\u6027\u5316\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5b9e\u9a8c\u8868\u73b0\u51fa\u8272\uff0c\u5df2\u5f00\u6e90\u4ee3\u7801\u548c\u6570\u636e\u3002", "motivation": "\u5f53\u524d\u6709\u5bb3\u5185\u5bb9\uff08\u5982\u6bd2\u6027\u8a00\u8bba\u3001\u5783\u573e\u4fe1\u606f\u3001\u8d1f\u9762\u60c5\u7eea\uff09\u5728\u7f51\u7edc\u4e2d\u6cdb\u6ee5\uff0c\u4f20\u7edf\u7684\u5185\u5bb9\u5ba1\u6838\u7cfb\u7edf\u9ad8\u5ea6\u4e2d\u5fc3\u5316\u4e14\u9488\u5bf9\u5355\u4e00\u4efb\u52a1\uff0c\u4e0d\u900f\u660e\u4e14\u96be\u4ee5\u9002\u5e94\u7528\u6237\u591a\u6837\u5316\u9700\u6c42\uff0c\u5c24\u5176\u5728\u9690\u79c1\u654f\u611f\u6216\u53bb\u4e2d\u5fc3\u5316\u73af\u5883\u4e2d\u95ee\u9898\u7a81\u51fa\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u521b\u65b0\u6027\u6846\u67b6\uff0c\u5229\u7528\u5927\u6a21\u578b\u7684in-context learning\uff08ICL\uff09\u80fd\u529b\uff0c\u5c06\u6709\u5bb3\u5185\u5bb9\u68c0\u6d4b\u4efb\u52a1\uff08\u6bd2\u6027\u3001\u5783\u573e\u4fe1\u606f\u3001\u8d1f\u9762\u60c5\u7eea\uff09\u7edf\u4e00\u4e8e\u4e8c\u5206\u7c7b\u3001\u591a\u5206\u7c7b\u548c\u591a\u6807\u7b7e\u573a\u666f\u4e0b\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u7b80\u5355\u7684\u63d0\u793a\u8bcd\u914d\u7f6e\u5b9e\u73b0\u8f7b\u91cf\u5316\u4e2a\u6027\u5316\uff0c\u65e0\u9700\u6a21\u578b\u518d\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u5185\u5bb9\u5ba1\u6838\u7c7b\u522b\u7684\u5feb\u901f\u6dfb\u52a0\u3001\u89e3\u9664\u6216\u8bed\u4e49\u6269\u5c55\uff0c\u53ea\u9700\u63d0\u4f9b\u5c11\u91cf\u7528\u6237\u6837\u4f8b\u6216\u5b9a\u4e49\u5373\u53ef\u8fdb\u884c\u4e2a\u6027\u5316\u8bbe\u7f6e\u3002", "result": "\u5728TextDetox\u3001UCI SMS\u3001SST2\u7b49\u516c\u5f00\u6570\u636e\u96c6\u53ca\u65b0\u6807\u6ce8\u7684Mastodon\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793a\uff1a1\uff09\u57fa\u7840\u6a21\u578b\u6709\u5f88\u5f3a\u7684\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\uff0c\u6027\u80fd\u4e0e\u6216\u4f18\u4e8e\u4efb\u52a1\u4e13\u7528\u5fae\u8c03\u6a21\u578b\uff1b2\uff09\u7528\u6237\u4e2a\u6027\u5316\u4ec5\u9700\u5355\u4e2a\u7528\u6237\u6837\u4f8b\u6216\u5b9a\u4e49\u5373\u53ef\u6709\u6548\u5b9e\u73b0\uff1b3\uff09\u63d0\u793a\u8bcd\u4e2d\u8865\u5145\u6807\u7b7e\u5b9a\u4e49\u6216\u7406\u7531\u53ef\u663e\u8457\u63d0\u5347\u6a21\u578b\u5bf9\u771f\u5b9e\u573a\u666f\u4e2d\u566a\u58f0\u6570\u636e\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u672c\u5de5\u4f5c\u5c55\u73b0\u4e86\u5185\u5bb9\u5ba1\u6838\u4ece\u201c\u4e00\u5200\u5207\u201d\u5411\u7528\u6237\u4e2a\u6027\u5316\u3001\u9ad8\u9002\u5e94\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u65b9\u5411\u7684\u8f6c\u53d8\uff0c\u8bc1\u660e\u4e86ICL\u5728\u4e0b\u4e00\u4ee3\u7528\u6237\u4e2d\u5fc3\u5185\u5bb9\u5b89\u5168\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u53ef\u884c\u6027\uff0c\u5e76\u5df2\u5f00\u6e90\u4ee3\u7801\u4e0e\u6570\u636e\u96c6\u4ee5\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2511.05813", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05813", "abs": "https://arxiv.org/abs/2511.05813", "authors": ["In-on Wiratsin", "Chaiyong Ragkhitwetsagul", "Matheus Paixao", "Denis De Sousa", "Pongpop Lapvikai", "Peter Haddawy"], "title": "An Empirical Study of Java Code Improvements Based on Stack Overflow Answer Edits", "comment": null, "summary": "Suboptimal code is prevalent in software systems. Developers often write low-quality code due to factors like technical knowledge gaps, insufficient experience, time pressure, management decisions, or personal factors. Once integrated, the accumulation of this suboptimal code leads to significant maintenance costs and technical debt.\n  Developers frequently consult external knowledge bases, such as API documentation and Q&A websites like Stack Overflow (SO), to aid their programming tasks. SO's crowdsourced, collaborative nature has created a vast repository of programming knowledge. Its community-curated content is constantly evolving, with new answers posted or existing ones edited.\n  In this paper, we present an empirical study of SO Java answer edits and their application to improving code in open-source projects. We use a modified code clone search tool to analyze SO code snippets with version history and apply it to open-source Java projects. This identifies outdated or unoptimized code and suggests improved alternatives. Analyzing 140,840 Java accepted answers from SOTorrent and 10,668 GitHub Java projects, we manually categorized SO answer edits and created pull requests to open-source projects with the suggested code improvements. Our results show that 6.91% of SO Java accepted answers have more than one revision (average of 2.82). Moreover, 49.24% of the code snippets in the answer edits are applicable to open-source projects, and 11 out of 36 proposed bug fixes based on these edits were accepted by the GitHub project maintainers.", "AI": {"tldr": "\u7814\u7a76\u5c06Stack Overflow Java\u7b54\u6848\u7684\u7f16\u8f91\u7528\u4e8e\u5f00\u6e90\u9879\u76ee\u4ee3\u7801\u4f18\u5316\uff0c\u901a\u8fc7\u4ee3\u7801\u514b\u9686\u4e0e\u624b\u52a8\u5206\u6790\uff0c\u53d1\u73b0\u7ea6\u534a\u6570\u7f16\u8f91\u53ef\u76f4\u63a5\u7528\u5728\u5b9e\u9645\u9879\u76ee\uff0c\u90e8\u5206\u5efa\u8bae\u5df2\u88ab\u9879\u76ee\u91c7\u7eb3\uff0c\u663e\u793aSO\u793e\u533a\u534f\u4f5c\u77e5\u8bc6\u6709\u52a9\u4e8e\u63d0\u5347\u8f6f\u4ef6\u8d28\u91cf\u3002", "motivation": "\u9274\u4e8e\u5f00\u53d1\u8005\u5e38\u56e0\u591a\u79cd\u539f\u56e0\u7f16\u5199\u6b21\u4f18\u4ee3\u7801\uff0c\u7ef4\u62a4\u6210\u672c\u548c\u6280\u672f\u503a\u52a1\u968f\u4e4b\u589e\u52a0\uff0c\u56e0\u6b64\u63a2\u7d22\u5229\u7528SO\u4ee3\u7801\u7247\u6bb5\u6539\u8fdb\u5f00\u6e90\u9879\u76ee\u4ee3\u7801\u7684\u53ef\u80fd\u6027\u3002", "method": "\u901a\u8fc7\u6539\u8fdb\u7684\u4ee3\u7801\u514b\u9686\u641c\u7d22\u5de5\u5177\uff0c\u5206\u6790\u5e26\u6709\u5386\u53f2\u7248\u672c\u7684SO Java\u4ee3\u7801\u7247\u6bb5\uff0c\u5e76\u5bf9\u5f00\u6e90\u9879\u76ee\u8fdb\u884c\u5bf9\u6bd4\uff0c\u624b\u52a8\u5206\u7c7b\u7f16\u8f91\u7c7b\u578b\u5e76\u521b\u5efaPR\uff08\u62c9\u53d6\u8bf7\u6c42\uff09\u5e94\u7528\u4ee3\u7801\u6539\u8fdb\u3002", "result": "6.91%\u7684SO Java\u7b54\u6848\u6709\u591a\u6b21\u4fee\u8ba2\uff0c49.24%\u7684\u7f16\u8f91\u4ee3\u7801\u6bb5\u53ef\u5b9e\u9645\u7528\u4e8e\u5f00\u6e90\u9879\u76ee\uff0c\u5efa\u8bae\u768436\u4e2aBug\u4fee\u590d\u4e2d\u670911\u4e2a\u88ab\u6b63\u5f0f\u9879\u76ee\u63a5\u53d7\u3002", "conclusion": "SO\u4e0a\u7684\u7b54\u6848\u7f16\u8f91\u80fd\u4e3a\u5f00\u6e90\u9879\u76ee\u4ee3\u7801\u4f18\u5316\u548c\u9519\u8bef\u4fee\u590d\u63d0\u4f9b\u5b9e\u9645\u5e2e\u52a9\uff0c\u793e\u533a\u534f\u4f5c\u77e5\u8bc6\u5e93\u5bf9\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\u53d1\u6325\u4e86\u79ef\u6781\u4f5c\u7528\u3002"}}
{"id": "2511.05533", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05533", "abs": "https://arxiv.org/abs/2511.05533", "authors": ["Bharathi Kannan Nithyanantham", "Tobias Sesterhenn", "Ashwin Nedungadi", "Sergio Peral Garijo", "Janis Zenkner", "Christian Bartelt", "Stefan L\u00fcdtke"], "title": "MCP4IFC: IFC-Based Building Design Using Large Language Models", "comment": null, "summary": "Bringing generative AI into the architecture, engineering and construction (AEC) field requires systems that can translate natural language instructions into actions on standardized data models. We present MCP4IFC, a comprehensive open-source framework that enables Large Language Models (LLMs) to directly manipulate Industry Foundation Classes (IFC) data through the Model Context Protocol (MCP). The framework provides a set of BIM tools, including scene querying tools for information retrieval, predefined functions for creating and modifying common building elements, and a dynamic code-generation system that combines in-context learning with retrieval-augmented generation (RAG) to handle tasks beyond the predefined toolset. Experiments demonstrate that an LLM using our framework can successfully perform complex tasks, from building a simple house to querying and editing existing IFC data. Our framework is released as open-source to encourage research in LLM-driven BIM design and provide a foundation for AI-assisted modeling workflows. Our code is available at https://show2instruct.github.io/mcp4ifc/.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faMCP4IFC\u5f00\u6e90\u6846\u67b6\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u7528\u81ea\u7136\u8bed\u8a00\u64cd\u4f5cBIM\u7684IFC\u6570\u636e\uff0c\u901a\u8fc7\u67e5\u8be2\u5de5\u5177\u3001\u6784\u4ef6\u9884\u8bbe\u51fd\u6570\u548cRAG\u6280\u672f\uff0cLLM\u53ef\u9ad8\u6548\u5b8c\u6210\u5efa\u6a21\u4e0e\u7f16\u8f91\u4efb\u52a1\uff0c\u663e\u8457\u63a8\u52a8AI\u5728\u5efa\u7b51\u884c\u4e1a\u7684\u5b9e\u9645\u5e94\u7528\u4e0e\u7814\u7a76\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5df2\u5728\u591a\u4e2a\u9886\u57df\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u67b6\u6784\u3001\u5de5\u7a0b\u548c\u5efa\u9020\uff08AEC\uff09\u884c\u4e1a\u4ecd\u7f3a\u4e4f\u80fd\u5c06\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u76f4\u63a5\u8f6c\u6362\u4e3a\u5bf9\u6807\u51c6\u5316\u6570\u636e\u6a21\u578b\u7684\u64cd\u4f5c\u7cfb\u7edf\u3002\u8be5\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u65b9\u9762\u7684\u6280\u672f\u7a7a\u767d\uff0c\u5b9e\u73b0AI\u5728BIM\u5de5\u4f5c\u6d41\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aMCP4IFC\u7684\u5f00\u6e90\u6846\u67b6\uff0c\u5141\u8bb8\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u901a\u8fc7Model Context Protocol\uff08MCP\uff09\u76f4\u63a5\u64cd\u63a7\u884c\u4e1a\u57fa\u7840\u7c7b\uff08IFC\uff09\u6570\u636e\u3002\u8be5\u6846\u67b6\u96c6\u6210\u4e86BIM\u5de5\u5177\uff0c\u5305\u62ec\u573a\u666f\u67e5\u8be2\u5de5\u5177\u3001\u7528\u4e8e\u5efa\u7b51\u5143\u7d20\u521b\u5efa\u4e0e\u4fee\u6539\u7684\u9884\u5b9a\u4e49\u51fd\u6570\uff0c\u4ee5\u53ca\u7ed3\u5408\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u52a8\u6001\u4ee3\u7801\u751f\u6210\u7cfb\u7edf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u8be5\u6846\u67b6\u7684LLM\u80fd\u591f\u6210\u529f\u5b8c\u6210\u4ece\u5efa\u9020\u7b80\u5355\u623f\u5c4b\u5230\u67e5\u8be2\u548c\u7f16\u8f91\u73b0\u6709IFC\u6570\u636e\u7b49\u590d\u6742\u4efb\u52a1\u3002\u4f5c\u8005\u8fd8\u5c06\u6846\u67b6\u5f00\u6e90\uff0c\u9f13\u52b1\u76f8\u5173\u9886\u57df\u7684\u7814\u7a76\u4e0e\u521b\u65b0\u3002", "conclusion": "MCP4IFC\u6846\u67b6\u4e3aLLM\u5728BIM\u8bbe\u8ba1\u4e2d\u76f4\u63a5\u64cd\u4f5cIFC\u6570\u636e\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\uff0c\u63a8\u52a8\u4e86AI\u9a71\u52a8\u7684\u5efa\u6a21\u5de5\u4f5c\u6d41\u53d1\u5c55\u3002\u5176\u5f00\u6e90\u6027\u8d28\u6709\u52a9\u4e8e\u4fc3\u8fdbAEC\u9886\u57dfAI\u5e94\u7528\u7814\u7a76\u3002"}}
{"id": "2511.05987", "categories": ["cs.SE", "cs.FL", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.05987", "abs": "https://arxiv.org/abs/2511.05987", "authors": ["Addison Crump", "Alexi Turcotte", "Jos\u00e9 Antonio Zamudio Amaya", "Andreas Zeller"], "title": "High-Performance Generation of Constrained Input", "comment": null, "summary": "Language-based testing combines context-free grammar definitions with semantic constraints over grammar elements to generate test inputs. By pairing context-free grammars with constraints, users have the expressiveness of unrestricted grammars while retaining simple structure. However, producing inputs in the presence of such constraints can be challenging. In past approaches, SMT solvers have been found to be very slow at finding string solutions; evolutionary algorithms are faster and more general, but current implementations still struggle with complex constraints that would be required for domains such as compiler testing. In this paper, we present a novel approach for evolutionary language-based testing that improves performance by 3-4 orders of magnitude over the current state of the art, reducing hours of generation and constraint solving time to seconds. We accomplish this by (1) carefully transforming grammar definitions into Rust types and trait implementations, ensuring that the compiler may near-maximally optimize arbitrary operations on arbitrary grammars; and (2) using better evolutionary algorithms that improve the ability of language-based testing to solve complex constraint systems. These performance and algorithmic improvements allow our prototype, FANDANGO-RS, to solve constraints that previous strategies simply cannot handle. We demonstrate this by a case study for a C subset, in which FANDANGO-RS is able to generate 401 diverse, complex, and valid test inputs for a C compiler per minute.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eRust\u548c\u4f18\u5316\u8fdb\u5316\u7b97\u6cd5\u7684\u65b0\u578b\u8bed\u8a00\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\uff0c\u6781\u5927\u52a0\u901f\u4e86\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u548c\u7ea6\u675f\u6c42\u89e3\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\uff0c\u9002\u914d\u66f4\u590d\u6742\u6d4b\u8bd5\u9700\u6c42\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8bed\u8a00\u7684\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u4e0a\u4e0b\u6587\u65e0\u5173\u6587\u6cd5\u4e0e\u8bed\u4e49\u7ea6\u675f\u7ed3\u5408\uff0c\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u3002\u4f46\u5728\u590d\u6742\u7ea6\u675f\u573a\u666f\u4e0b\uff0c\u73b0\u6709\u65b9\u6cd5\uff08\u5982SMT\u6c42\u89e3\u5668\u548c\u8fdb\u5316\u7b97\u6cd5\uff09\u6548\u7387\u4f4e\u6216\u96be\u4ee5\u5e94\u5bf9\u9ad8\u590d\u6742\u5ea6\u7ea6\u675f\uff0c\u5f71\u54cd\u7f16\u8bd1\u5668\u7b49\u9886\u57df\u7684\u6d4b\u8bd5\u9700\u6c42\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8fdb\u5316\u5f0f\u57fa\u4e8e\u8bed\u8a00\u7684\u6d4b\u8bd5\u65b9\u6848\uff1a\u4e00\u65b9\u9762\u5c06\u6587\u6cd5\u8f6c\u5316\u4e3aRust\u7c7b\u578b\u4e0etrait\uff0c\u4ee5\u5145\u5206\u5229\u7528\u7f16\u8bd1\u5668\u4f18\u5316\uff1b\u53e6\u4e00\u65b9\u9762\u5f15\u5165\u66f4\u4f18\u7684\u8fdb\u5316\u7b97\u6cd5\uff0c\u4ee5\u589e\u5f3a\u7ea6\u675f\u6c42\u89e3\u80fd\u529b\u3002", "result": "\u65b0\u539f\u578bFANDANGO-RS\u76f8\u6bd4\u65e2\u6709\u65b9\u6cd5\u6027\u80fd\u63d0\u53473-4\u4e2a\u6570\u91cf\u7ea7\uff0c\u80fd\u5728\u6570\u79d2\u5185\u5b8c\u6210\u4ee5\u5f80\u9700\u6570\u5c0f\u65f6\u7684\u751f\u6210\u4e0e\u6c42\u89e3\u4efb\u52a1\u3002\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cFANDANGO-RS\u6bcf\u5206\u949f\u53ef\u4e3aC\u5b50\u96c6\u7f16\u8bd1\u5668\u4ea7\u751f401\u4e2a\u591a\u6837\u3001\u590d\u6742\u4e14\u6709\u6548\u7684\u6d4b\u8bd5\u7528\u4f8b\u3002", "conclusion": "\u901a\u8fc7\u5c06\u6587\u6cd5\u9ad8\u6548\u6620\u5c04\u4e3aRust\u7c7b\u578b\u5e76\u4f18\u5316\u8fdb\u5316\u7b97\u6cd5\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u8bed\u8a00\u7684\u6d4b\u8bd5\u5728\u5904\u7406\u590d\u6742\u7ea6\u675f\u65f6\u7684\u6027\u80fd\uff0c\u5e76\u53ef\u6269\u5c55\u81f3\u66f4\u590d\u6742\u7684\u5b9e\u9645\u6d4b\u8bd5\u573a\u666f\u3002"}}
{"id": "2511.05820", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05820", "abs": "https://arxiv.org/abs/2511.05820", "authors": ["Zishuo Xu", "Dezhong Yao", "Yao Wan"], "title": "WAR-Re: Web API Recommendation with Semantic Reasoning", "comment": null, "summary": "With the development of cloud computing, the number of Web APIs has increased dramatically, further intensifying the demand for efficient Web API recommendation. Despite the demonstrated success of previous Web API recommendation solutions, two critical challenges persist: 1) a fixed top-N recommendation that cannot accommodate the varying API cardinality requirements of different mashups, and 2) these methods output only ranked API lists without accompanying reasons, depriving users of understanding the recommendation. To address these challenges, we propose WAR-Re, an LLM-based model for Web API recommendation with semantic reasoning for justification. WAR-Re leverages special start and stop tokens to handle the first challenge and uses two-stage training: supervised fine-tuning and reinforcement learning via Group Relative Policy Optimization (GRPO) to enhance the model's ability in both tasks. Comprehensive experimental evaluations on the ProgrammableWeb dataset demonstrate that WAR-Re achieves a gain of up to 21.59\\% over the state-of-the-art baseline model in recommendation accuracy, while consistently producing high-quality semantic reasons for recommendations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u8bed\u4e49\u63a8\u7406\u7684\u65b0Web API\u63a8\u8350\u65b9\u6cd5WAR-Re\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u63a8\u8350\u51c6\u786e\u7387\uff0c\u8fd8\u80fd\u81ea\u52a8\u751f\u6210\u63a8\u8350\u7406\u7531\uff0c\u6709\u6548\u8865\u8db3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e3b\u8981\u4e0d\u8db3\u3002", "motivation": "\u4e91\u8ba1\u7b97\u7684\u53d1\u5c55\u4f7fWeb API\u6570\u91cf\u6025\u5267\u589e\u52a0\uff0c\u63a8\u52a8\u4e86\u9ad8\u6548API\u63a8\u8350\u7684\u9700\u6c42\u3002\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e24\u5927\u6311\u6218\uff1a\u4e00\u662f\u63a8\u8350\u6570\u91cf\u56fa\u5b9a\uff0c\u65e0\u6cd5\u9002\u5e94\u4e0d\u540c\u9700\u6c42\uff1b\u4e8c\u662f\u53ea\u7ed9\u6392\u5e8f\u5217\u8868\uff0c\u6ca1\u6709\u89e3\u91ca\u539f\u56e0\uff0c\u7528\u6237\u7406\u89e3\u56f0\u96be\u3002", "method": "\u63d0\u51faWAR-Re\u6a21\u578b\uff0c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5229\u7528\u7279\u6b8a\u7684\u8d77\u6b62\u6807\u8bb0\u89e3\u51b3API\u63a8\u8350\u6570\u91cf\u53ef\u53d8\u7684\u95ee\u9898\uff0c\u5e76\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\uff1a\u6709\u76d1\u7763\u5fae\u8c03\u548c\u57fa\u4e8eGRPO\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u4ee5\u63d0\u5347\u63a8\u8350\u6548\u679c\u548c\u89e3\u91ca\u80fd\u529b\u3002", "result": "\u5728ProgrammableWeb\u6570\u636e\u96c6\u4e0a\uff0cWAR-Re\u6a21\u578b\u7684\u63a8\u8350\u51c6\u786e\u7387\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u6a21\u578b\u63d0\u5347\u4e86\u6700\u591a21.59%\uff0c\u4e14\u80fd\u6301\u7eed\u8f93\u51fa\u9ad8\u8d28\u91cf\u7684\u63a8\u8350\u7406\u7531\u3002", "conclusion": "WAR-Re\u663e\u8457\u63d0\u5347\u4e86Web API\u63a8\u8350\u7684\u7075\u6d3b\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u6210\u4e3aAPI\u63a8\u8350\u9886\u57df\u7684\u6709\u6548\u65b0\u65b9\u6848\u3002"}}
{"id": "2511.05534", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05534", "abs": "https://arxiv.org/abs/2511.05534", "authors": ["Kunxi Li", "Yufan Xiong", "Zhonghua Jiang", "Yiyun Zhou", "Zhaode Wang", "Chengfei Lv", "Shengyu Zhang"], "title": "FlowMM: Cross-Modal Information Flow Guided KV Cache Merging for Efficient Multimodal Context Inference", "comment": null, "summary": "Traditional KV cache eviction strategies, which discard less critical KV-pairs based on attention scores, often degrade generation quality, causing context loss or hallucinations. Recent efforts shift toward KV merging, merging eviction tokens with retention tokens based on similarity. However, in multimodal scenarios, distributional biases across modality tokens and attentional biases in cross-modal interactions limit its effectiveness. This work introduces FlowMM, an adaptive framework for cross-modal information flow-guided multimodal KV cache merging. FlowMM leverages cross-modal information flow to dynamically apply layer-specific merging strategies, capturing modality-specific patterns while preserving contextual integrity. Furthermore, we introduce a sensitivity-adaptive token matching mechanism that jointly evaluates token similarity and task-critical sensitivity, merging low-risk tokens while safeguarding high-sensitivity ones. Extensive experiments across diverse leading MLLMs show that FlowMM reduces KV cache memory by 80% to 95% and decoding latency by 1.3-1.8x, while maintaining competitive task performance.", "AI": {"tldr": "\u63d0\u51fa\u8de8\u6a21\u6001\u4fe1\u606f\u6d41\u5f15\u5bfc\u7684KV\u7f13\u5b58\u5408\u5e76\u6846\u67b6FlowMM\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684KV\u7f13\u5b58\u7ba1\u7406\uff0c\u5927\u5e45\u964d\u4f4e\u5185\u5b58\u548c\u5ef6\u8fdf\uff0c\u540c\u65f6\u786e\u4fdd\u591a\u6a21\u6001\u6a21\u578b\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u6ce8\u610f\u529b\u5206\u6570\u8fdb\u884cKV\u7f13\u5b58\u5254\u9664\uff0c\u5728\u591a\u6a21\u6001\u573a\u666f\u4e0b\u6613\u9020\u6210\u4e0a\u4e0b\u6587\u4e22\u5931\u6216\u5e7b\u89c9\uff0c\u65b0\u5174KV\u5408\u5e76\u65b9\u6cd5\u53d7\u9650\u4e8e\u6a21\u6001\u5206\u5e03\u504f\u5dee\u548c\u4ea4\u4e92\u504f\u5dee\uff0c\u4e9f\u9700\u66f4\u667a\u80fd\u7684\u8de8\u6a21\u6001KV\u7f13\u5b58\u7ba1\u7406\u7b56\u7565\u3002", "method": "\u63d0\u51faFlowMM\u6846\u67b6\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u4fe1\u606f\u6d41\u81ea\u9002\u5e94\u5730\u6307\u5bfcKV\u7f13\u5b58\u5408\u5e76\uff0c\u7ed3\u5408\u5c42\u7ea7\u5dee\u5f02\u5316\u7b56\u7565\u53ca\u654f\u611f\u5ea6\u81ea\u9002\u5e94\u7684token\u5339\u914d\u673a\u5236\u3002", "result": "FlowMM\u53ef\u4f7fKV\u7f13\u5b58\u51cf\u5c1180%-95%\uff0c\u89e3\u7801\u5ef6\u8fdf\u964d\u4f4e1.3-1.8\u500d\uff0c\u5e76\u5728\u591a\u79cd\u4e3b\u6d41\u591a\u6a21\u6001\u5927\u6a21\u578b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4e0e\u539f\u59cb\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "FlowMM\u5728\u964d\u4f4eKV\u7f13\u5b58\u5185\u5b58\u6d88\u8017\u548c\u89e3\u7801\u5ef6\u8fdf\u7684\u540c\u65f6\uff0c\u80fd\u591f\u4fdd\u6301\u4e3b\u6d41\u591a\u6a21\u6001\u5927\u6a21\u578b\u7684\u4efb\u52a1\u6027\u80fd\u3002"}}
{"id": "2511.05821", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05821", "abs": "https://arxiv.org/abs/2511.05821", "authors": ["Rujiphart Charatvaraphan", "Bunradar Chatchaiyadech", "Thitirat Sukijprasert", "Chaiyong Ragkhitwetsagul", "Morakot Choetkiertikul", "Raula Gaikovina Kula", "Thanwadee Sunetnanta", "Kenichi Matsumoto"], "title": "PyGress: Tool for Analyzing the Progression of Code Proficiency in Python OSS Projects", "comment": null, "summary": "Assessing developer proficiency in open-source software (OSS) projects is essential for understanding project dynamics, especially for expertise. This paper presents PyGress, a web-based tool designed to automatically evaluate and visualize Python code proficiency using pycefr, a Python code proficiency analyzer. By submitting a GitHub repository link, the system extracts commit histories, analyzes source code proficiency across CEFR-aligned levels (A1 to C2), and generates visual summaries of individual and project-wide proficiency. The PyGress tool visualizes per-contributor proficiency distribution and tracks project code proficiency progression over time. PyGress offers an interactive way to explore contributor coding levels in Python OSS repositories. The video demonstration of the PyGress tool can be found at https://youtu.be/hxoeK-ggcWk, and the source code of the tool is publicly available at https://github.com/MUICT-SERU/PyGress.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u81ea\u52a8\u8bc4\u4f30\u548c\u53ef\u89c6\u5316\u5f00\u6e90\u9879\u76ee\u5f00\u53d1\u8005Python\u4ee3\u7801\u6c34\u5e73\u7684\u5de5\u5177PyGress\uff0c\u5b9e\u73b0\u57fa\u4e8e\u6e90\u7801\u548c\u63d0\u4ea4\u5386\u53f2\u7684\u80fd\u529b\u5206\u5e03\u4e0e\u8fdb\u5c55\u8ffd\u8e2a\uff0c\u652f\u6301\u66f4\u6df1\u5165\u7684\u9879\u76ee\u7ba1\u7406\u548c\u56e2\u961f\u80fd\u529b\u5206\u6790\u3002", "motivation": "\u5f00\u6e90\u9879\u76ee\u7684\u53d1\u5c55\u4f9d\u8d56\u4e8e\u5f00\u53d1\u8005\u7684\u80fd\u529b\u8bc4\u4f30\uff0c\u5c24\u5176\u5728\u7406\u89e3\u56e2\u961f\u6210\u5458\u7684\u7f16\u7a0b\u6c34\u5e73\u4ee5\u53ca\u9879\u76ee\u6574\u4f53\u6280\u80fd\u52a8\u6001\u65b9\u9762\u81f3\u5173\u91cd\u8981\u3002\u4f46\u76ee\u524d\u7528\u4e8e\u81ea\u52a8\u8bc4\u4f30\u548c\u53ef\u89c6\u5316\u5f00\u53d1\u8005\u7f16\u7a0b\u80fd\u529b\u7684\u5de5\u5177\u8f83\u5c11\uff0c\u5355\u9760\u624b\u52a8\u8bc4\u4f30\u6548\u7387\u4f4e\uff0c\u6613\u53d7\u4e3b\u89c2\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86PyGress\uff0c\u4e00\u4e2a\u57fa\u4e8e\u7f51\u9875\u7684\u5de5\u5177\u3002\u7528\u6237\u53ea\u9700\u63d0\u4ea4GitHub\u4ed3\u5e93\u94fe\u63a5\uff0c\u7cfb\u7edf\u5229\u7528pycefr\uff08Python\u4ee3\u7801\u80fd\u529b\u5206\u6790\u5668\uff09\u81ea\u52a8\u63d0\u53d6\u4ee3\u7801\u63d0\u4ea4\u8bb0\u5f55\uff0c\u6309\u7167CEFR\u7b49\u7ea7\uff08A1\u5230C2\uff09\u5206\u6790\u6e90\u7801\uff0c\u5e76\u751f\u6210\u4e2a\u4eba\u548c\u9879\u76ee\u6574\u4f53\u80fd\u529b\u7684\u53ef\u89c6\u5316\u7ed3\u679c\u3002\u5de5\u5177\u53ef\u8ffd\u8e2a\u5404\u8d21\u732e\u8005\u7684\u80fd\u529b\u5206\u5e03\u53ca\u9879\u76ee\u80fd\u529b\u968f\u65f6\u95f4\u7684\u6f14\u53d8\u3002", "result": "PyGress\u5b9e\u73b0\u4e86Python\u5f00\u6e90\u9879\u76ee\u8d21\u732e\u8005\u80fd\u529b\u81ea\u52a8\u8bc4\u4f30\u4e0e\u52a8\u6001\u53ef\u89c6\u5316\uff0c\u652f\u6301\u9879\u76ee\u548c\u4e2a\u4eba\u89d2\u5ea6\u7684\u80fd\u529b\u8ffd\u8e2a\uff0c\u5de5\u5177\u5f00\u6e90\uff0c\u4e14\u6709\u64cd\u4f5c\u6f14\u793a\u89c6\u9891\u3002", "conclusion": "PyGress\u4e3a\u63a2\u7d22\u548c\u8bc4\u4f30\u5f00\u6e90\u9879\u76ee\u8d21\u732e\u8005\u7f16\u7a0b\u6c34\u5e73\u63d0\u4f9b\u4e86\u65b0\u7684\u81ea\u52a8\u5316\u53ef\u89c6\u5316\u65b9\u5f0f\uff0c\u6709\u52a9\u4e8e\u9879\u76ee\u7ba1\u7406\u51b3\u7b56\u548c\u5f00\u53d1\u56e2\u961f\u80fd\u529b\u63d0\u5347\u3002"}}
{"id": "2511.05535", "categories": ["cs.CL", "cs.DB", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.05535", "abs": "https://arxiv.org/abs/2511.05535", "authors": ["Trivikram Satharasi", "S Sitharama Iyengar"], "title": "Future of AI Models: A Computational perspective on Model collapse", "comment": "Submitted to Springer Nature. Code Available at https://github.com/t-satharasi/AI-Modal-Collapse-Code-for-Reproduction.git", "summary": "Artificial Intelligence, especially Large Language Models (LLMs), has transformed domains such as software engineering, journalism, creative writing, academia, and media (Naveed et al. 2025; arXiv:2307.06435). Diffusion models like Stable Diffusion generate high-quality images and videos from text. Evidence shows rapid expansion: 74.2% of newly published webpages now contain AI-generated material (Ryan Law 2025), 30-40% of the active web corpus is synthetic (Spennemann 2025; arXiv:2504.08755), 52% of U.S. adults use LLMs for writing, coding, or research (Staff 2025), and audits find AI involvement in 18% of financial complaints and 24% of press releases (Liang et al. 2025). The underlying neural architectures, including Transformers (Vaswani et al. 2023; arXiv:1706.03762), RNNs, LSTMs, GANs, and diffusion networks, depend on large, diverse, human-authored datasets (Shi & Iyengar 2019). As synthetic content dominates, recursive training risks eroding linguistic and semantic diversity, producing Model Collapse (Shumailov et al. 2024; arXiv:2307.15043; Dohmatob et al. 2024; arXiv:2402.07712). This study quantifies and forecasts collapse onset by examining year-wise semantic similarity in English-language Wikipedia (filtered Common Crawl) from 2013 to 2025 using Transformer embeddings and cosine similarity metrics. Results reveal a steady rise in similarity before public LLM adoption, likely driven by early RNN/LSTM translation and text-normalization pipelines, though modest due to a smaller scale. Observed fluctuations reflect irreducible linguistic diversity, variable corpus size across years, finite sampling error, and an exponential rise in similarity after the public adoption of LLM models. These findings provide a data-driven estimate of when recursive AI contamination may significantly threaten data richness and model generalization.", "AI": {"tldr": "\u5927\u91cfAI\u5408\u6210\u5185\u5bb9\u7684\u9012\u5f52\u8bad\u7ec3\u6b63\u5728\u5bfc\u81f4\u4e92\u8054\u7f51\u8bed\u4e49\u591a\u6837\u6027\u5feb\u901f\u6536\u655b\u3002\u6839\u636e\u82f1\u6587\u7ef4\u57fa\u767e\u79d1\u7684\u5206\u6790\uff0c\u8bed\u4e49\u76f8\u4f3c\u5ea6\u6307\u6570\u4e0a\u5347\u5df2\u7ecf\u53d1\u751f\uff0c\u5373\u5c06\u5a01\u80c1\u6570\u636e\u591a\u6837\u6027\u548c\u6a21\u578b\u80fd\u529b\u3002", "motivation": "\u672c\u8bba\u6587\u5173\u6ce8\u5f53\u524dAI\u6280\u672f\uff0c\u5c24\u5176\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u56fe\u751f\u6210\u6269\u6563\u6a21\u578b\u5728\u5404\u884c\u4e1a\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4ee5\u53ca\u7531\u6b64\u5bfc\u81f4\u7684\u5927\u91cf\u5408\u6210\u5185\u5bb9\u5bf9\u4e92\u8054\u7f51\u6570\u636e\u7ed3\u6784\u548c\u591a\u6837\u6027\u9020\u6210\u7684\u6f5c\u5728\u5f71\u54cd\u3002\u4f5c\u8005\u5e0c\u671b\u63ed\u793a\u8fd9\u79cd\u9ad8\u5ea6\u5408\u6210\u5185\u5bb9\u9012\u5f52\u8bad\u7ec3\u4f1a\u5bfc\u81f4\u8bed\u4e49\u548c\u8bed\u8a00\u591a\u6837\u6027\u4e27\u5931\uff0c\u6700\u7ec8\u5f15\u53d1\u201c\u6a21\u578b\u574d\u7f29\u201d\u3002", "method": "\u4f5c\u8005\u4f7f\u7528\u4e86Transformer\u6a21\u578b\u5d4c\u5165\u53ca\u4f59\u5f26\u76f8\u4f3c\u5ea6\u6765\u8861\u91cf\u82f1\u6587\u7ef4\u57fa\u767e\u79d1\uff08\u62bd\u53d6\u81eaCommon Crawl\uff09\u57282013\u81f32025\u5e74\u95f4\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6\u5e74\u53d8\u5316\u3002\u901a\u8fc7\u6298\u5e74\u5206\u6790\uff0c\u91cf\u5316\u5e76\u9884\u6d4b\u4e86\u8bed\u4e49\u6536\u655b\u548c\u201c\u6a21\u578b\u574d\u7f29\u201d\u98ce\u9669\u7684\u65f6\u70b9\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5728\u516c\u4f17\u5e7f\u6cdb\u91c7\u7528LLM\u524d\uff0c\u5185\u5bb9\u8bed\u4e49\u76f8\u4f3c\u5ea6\u7a33\u6b65\u4e0a\u5347\uff08\u53d7\u65e9\u671fRNN/LSTM\u9a71\u52a8\uff09\uff0c\u4f46\u89c4\u6a21\u8f83\u5c0f\u3002LLM\u5927\u89c4\u6a21\u91c7\u7528\u540e\uff0c\u8bed\u4e49\u76f8\u4f3c\u5ea6\u5448\u6307\u6570\u589e\u957f\u3002\u6ce2\u52a8\u53cd\u6620\u4e0d\u53ef\u6d88\u9664\u7684\u8bed\u8a00\u591a\u6837\u6027\u3001\u5e74\u4efd\u6837\u672c\u91cf\u5dee\u5f02\u53ca\u6709\u9650\u91c7\u6837\u8bef\u5dee\u3002", "conclusion": "\u5408\u6210\u5185\u5bb9\u9012\u5f52\u8bad\u7ec3\u5df2\u5f00\u59cb\u5927\u5e45\u63d0\u5347\u8bed\u4e49\u76f8\u4f3c\u5ea6\uff0c\u5982\u679c\u8fd9\u79cd\u8d8b\u52bf\u7ee7\u7eed\uff0c\u5c06\u663e\u8457\u5a01\u80c1\u4e92\u8054\u7f51\u6570\u636e\u7684\u591a\u6837\u6027\u4e0e\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002\u8fd9\u9879\u7814\u7a76\u4e3aAI\u5185\u5bb9\u6c61\u67d3\u663e\u8457\u5f71\u54cd\u6570\u636e\u4e30\u5bcc\u6027\u7684\u65f6\u95f4\u8282\u70b9\u63d0\u51fa\u4e86\u6570\u636e\u9a71\u52a8\u7684\u9884\u4f30\u3002"}}
{"id": "2511.05824", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05824", "abs": "https://arxiv.org/abs/2511.05824", "authors": ["Chaiyong Ragkhitwetsagul", "Morakot Choetkiertikul", "Srisupa Palakvangsa-Na-Ayudhya", "Thanwadee Sunetnanta", "Nattanee Satchanawakul"], "title": "The Impact of COVID-19 and Remote Work on Software Development in Thailand", "comment": null, "summary": "The COVID-19 pandemic impacted the way of working, including software development. During the pandemic, software companies were forced to work remotely, and many companies have been using such work arrangements. There are prior studies showing the benefits and drawbacks of remote work in software development during COVID-19. However, there is no study that targets Thailand, one of the growing software markets in Asia, specifically. This paper performs an empirical study of the effects of COVID-19 on software development in Thailand. We surveyed 194 Thai software developers regarding the challenges and benefits they faced while working remotely during the COVID-19 period. The results show no statistically significant changes in the productivity and well-being of Thai software developers before and after working remotely due to the pandemic. The results show that software developers in Thailand both received benefits and faced challenges from remote work during COVID-19, similar to results reported by other studies, but with some unique differences. This study can be beneficial to similar Asian countries or other low- and middle-income countries around the world.", "AI": {"tldr": "\u672c\u7814\u7a76\u8c03\u67e5\u4e86\u6cf0\u56fd\u8f6f\u4ef6\u5f00\u53d1\u8005\u75ab\u60c5\u671f\u95f4\u8fdc\u7a0b\u5de5\u4f5c\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u751f\u4ea7\u529b\u548c\u5e78\u798f\u611f\u65e0\u663e\u8457\u53d8\u5316\uff0c\u65e2\u6709\u6311\u6218\u4e5f\u6709\u6536\u83b7\uff0c\u7ed3\u679c\u53ef\u4e3a\u7c7b\u4f3c\u56fd\u5bb6\u63d0\u4f9b\u501f\u9274\u3002", "motivation": "\u75ab\u60c5\u6539\u53d8\u4e86\u8f6f\u4ef6\u5f00\u53d1\u7684\u5de5\u4f5c\u6a21\u5f0f\uff0c\u5c24\u5176\u662f\u8fdc\u7a0b\u529e\u516c\u3002\u867d\u7136\u6709\u8bb8\u591a\u5173\u4e8e\u75ab\u60c5\u671f\u95f4\u8f6f\u4ef6\u5f00\u53d1\u8fdc\u7a0b\u5de5\u4f5c\u7684\u7814\u7a76\uff0c\u4f46\u5c1a\u65e0\u4e13\u95e8\u9488\u5bf9\u6cf0\u56fd\u8fd9\u4e00\u4e9a\u6d32\u589e\u957f\u578b\u5e02\u573a\u7684\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u95ee\u5377\u8c03\u67e5194\u540d\u6cf0\u56fd\u8f6f\u4ef6\u5f00\u53d1\u4eba\u5458\uff0c\u5206\u6790\u4ed6\u4eec\u5728\u75ab\u60c5\u671f\u95f4\u8fdc\u7a0b\u5de5\u4f5c\u9762\u4e34\u7684\u6311\u6218\u4e0e\u6536\u83b7\u3002", "result": "\u6cf0\u56fd\u8f6f\u4ef6\u5f00\u53d1\u8005\u5728\u75ab\u60c5\u524d\u540e\u751f\u4ea7\u529b\u548c\u5e78\u798f\u611f\u4e0a\u6ca1\u6709\u7edf\u8ba1\u5b66\u663e\u8457\u53d8\u5316\u3002\u8fdc\u7a0b\u5de5\u4f5c\u65e2\u5e26\u6765\u4e86\u673a\u9047\u4e5f\u5e26\u6765\u4e86\u6311\u6218\uff0c\u7ed3\u679c\u4e0e\u5176\u4ed6\u7814\u7a76\u7c7b\u4f3c\uff0c\u4f46\u4e5f\u6709\u6cf0\u56fd\u72ec\u7279\u7684\u5dee\u5f02\u3002", "conclusion": "\u6cf0\u56fd\u8f6f\u4ef6\u5f00\u53d1\u5458\u5728\u75ab\u60c5\u671f\u95f4\u8fdc\u7a0b\u5de5\u4f5c\u7ecf\u9a8c\u53ef\u4e3a\u4e9a\u6d32\u5176\u4ed6\u56fd\u5bb6\u53ca\u5168\u7403\u4f4e\u4e2d\u6536\u5165\u56fd\u5bb6\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2511.05541", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05541", "abs": "https://arxiv.org/abs/2511.05541", "authors": ["Usha Bhalla", "Alex Oesterling", "Claudio Mayrink Verdun", "Himabindu Lakkaraju", "Flavio P. Calmon"], "title": "Temporal Sparse Autoencoders: Leveraging the Sequential Nature of Language for Interpretability", "comment": "23 Pages, 10 figures", "summary": "Translating the internal representations and computations of models into concepts that humans can understand is a key goal of interpretability. While recent dictionary learning methods such as Sparse Autoencoders (SAEs) provide a promising route to discover human-interpretable features, they suffer from a variety of problems, including a systematic failure to capture the rich conceptual information that drives linguistic understanding. Instead, they exhibit a bias towards shallow, token-specific, or noisy features, such as \"the phrase 'The' at the start of sentences\". In this work, we propose that this is due to a fundamental issue with how dictionary learning methods for LLMs are trained. Language itself has a rich, well-studied structure spanning syntax, semantics, and pragmatics; however, current unsupervised methods largely ignore this linguistic knowledge, leading to poor feature discovery that favors superficial patterns over meaningful concepts. We focus on a simple but important aspect of language: semantic content has long-range dependencies and tends to be smooth over a sequence, whereas syntactic information is much more local. Building on this insight, we introduce Temporal Sparse Autoencoders (T-SAEs), which incorporate a novel contrastive loss encouraging consistent activations of high-level features over adjacent tokens. This simple yet powerful modification enables SAEs to disentangle semantic from syntactic features in a self-supervised manner. Across multiple datasets and models, T-SAEs recover smoother, more coherent semantic concepts without sacrificing reconstruction quality. Strikingly, they exhibit clear semantic structure despite being trained without explicit semantic signal, offering a new pathway for unsupervised interpretability in language models.", "AI": {"tldr": "T-SAEs\u5728\u65e0\u76d1\u7763\u60c5\u5883\u4e0b\u901a\u8fc7\u65f6\u95f4\u4e00\u81f4\u6027\u7ea6\u675f\u6539\u8fdb\u4e86\u7279\u5f81\u5b66\u4e60\uff0c\u53ef\u4ee5\u8ba9\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5206\u79bb\u548c\u53d1\u73b0\u8bed\u4e49\u7ed3\u6784\uff0c\u663e\u8457\u63d0\u5347\u89e3\u91ca\u6027\uff0c\u65b9\u6cd5\u7b80\u5355\u6709\u6548\u3002", "motivation": "\u5f53\u524dSAE\u7b49\u5b57\u5178\u5b66\u4e60\u65b9\u6cd5\u867d\u7136\u80fd\u53d1\u73b0\u53ef\u89e3\u91ca\u7279\u5f81\uff0c\u4f46\u5f80\u5f80\u53ea\u6355\u6349\u5230\u6d45\u5c42\u3001\u566a\u58f0\u6216\u5c40\u90e8\u8bed\u8a00\u7279\u5f81\uff0c\u672a\u80fd\u6709\u6548\u63ed\u793a\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u7684\u8bed\u4e49\u7ed3\u6784\uff0c\u539f\u56e0\u5728\u4e8e\u8bad\u7ec3\u65b9\u5f0f\u5ffd\u7565\u4e86\u8bed\u8a00\u7684\u4e30\u5bcc\u7ed3\u6784\u77e5\u8bc6\u3002", "method": "\u63d0\u51faTemporal Sparse Autoencoders (T-SAEs)\uff0c\u5728\u4f20\u7edfSAE\u57fa\u7840\u4e0a\u52a0\u5165\u65b0\u578b\u5bf9\u6bd4\u635f\u5931\uff0c\u9f13\u52b1\u9ad8\u5c42\u7279\u5f81\u5728\u76f8\u90bbtoken\u95f4\u4fdd\u6301\u4e00\u81f4\u6fc0\u6d3b\uff0c\u4ece\u800c\u81ea\u52a8\u533a\u5206\u8bed\u8a00\u4e2d\u7684\u8bed\u4e49\u548c\u53e5\u6cd5\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\uff0cT-SAE\u80fd\u6062\u590d\u66f4\u5e73\u6ed1\u3001\u8fde\u8d2f\u7684\u8bed\u4e49\u6982\u5ff5\uff0c\u6ca1\u6709\u727a\u7272\u91cd\u6784\u8d28\u91cf\uff0c\u5b9e\u73b0\u4e86\u8bed\u4e49\u7ed3\u6784\u7684\u81ea\u76d1\u7763\u5206\u79bb\u3002", "conclusion": "T-SAEs\u65e0\u9700\u663e\u5f0f\u8bed\u4e49\u4fe1\u53f7\u5373\u53ef\u5206\u79bb\u8bed\u4e49\u548c\u53e5\u6cd5\u7279\u5f81\uff0c\u4e3a\u8bed\u8a00\u6a21\u578b\u65e0\u76d1\u7763\u53ef\u89e3\u91ca\u6027\u5f00\u8f9f\u65b0\u8def\u5f84\u3002"}}
{"id": "2511.05825", "categories": ["cs.SE", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.05825", "abs": "https://arxiv.org/abs/2511.05825", "authors": ["Boyang Liu"], "title": "Design and Implementation of Data Acquisition and Analysis System for Programming Debugging Process Based On VS Code Plug-In", "comment": null, "summary": "In order to meet the needs of students' programming debugging ability training, this paper designs and implements a data acquisition and analysis system for programming debugging process based on VS Code plug-in, which aims to solve the limitation of traditional assessment methods that are difficult to fully evaluate students' debugging ability. The system supports a variety of programming languages, integrates debugging tasks and data acquisition functions, captures students' debugging behavior in the local editor in real time, and uploads the data to the platform database to realize the whole process monitoring and feedback, provides accurate debugging guidance for teachers, and improves the teaching effect. In terms of data analysis, the system proposed a debugging behavior analysis model based on abstract syntax tree, combined with node annotation, sequence recognition and cluster analysis and other technologies, to automatically track the context of students' debugging process and accurately identify key features in the debugging path. Through this tool, the system realizes the intelligent identification and labeling of the debugging direction and behavior pattern, and improves the refinement level of debugging data analysis. In this research system, a complex debugging scenario of multi-file and multi-task is introduced into the debugging problem design, which optimizes the multi-dimensional capturing ability of debugging data and lays a foundation for accurate debugging behavior analysis. Through several practical teaching tests, the feasibility and stability of the system are verified, which proves that it can effectively support procedural evaluation in programming debugging teaching, and provides a new direction for debugging behavior analysis research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8eVS Code\u63d2\u4ef6\u7684\u7f16\u7a0b\u8c03\u8bd5\u6570\u636e\u91c7\u96c6\u4e0e\u5206\u6790\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u79cd\u6280\u672f\u81ea\u52a8\u5316\u8bc6\u522b\u5b66\u751f\u8c03\u8bd5\u884c\u4e3a\uff0c\u652f\u6301\u66f4\u7cbe\u7ec6\u7684\u6559\u5b66\u8bc4\u4f30\uff0c\u7cfb\u7edf\u5728\u6559\u5b66\u5b9e\u9645\u6d4b\u8bd5\u4e2d\u8868\u73b0\u6709\u6548\u548c\u7a33\u5b9a\u3002", "motivation": "\u73b0\u6709\u7684\u4f20\u7edf\u8bc4\u4f30\u65b9\u5f0f\u96be\u4ee5\u5168\u9762\u8bc4\u4f30\u5b66\u751f\u7684\u7f16\u7a0b\u8c03\u8bd5\u80fd\u529b\uff0c\u6545\u9700\u4e00\u79cd\u65b0\u7684\u7cfb\u7edf\u6765\u6ee1\u8db3\u5b66\u751f\u8c03\u8bd5\u80fd\u529b\u8bad\u7ec3\u548c\u8bc4\u4f30\u7684\u9700\u6c42\u3002", "method": "\u57fa\u4e8eVS Code\u63d2\u4ef6\uff0c\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u652f\u6301\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u7684\u6570\u636e\u91c7\u96c6\u4e0e\u5206\u6790\u7cfb\u7edf\uff0c\u5b9e\u65f6\u6355\u6349\u5b66\u751f\u8c03\u8bd5\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u5e73\u53f0\u6570\u636e\u5e93\u8fdb\u884c\u5168\u7a0b\u76d1\u63a7\u548c\u53cd\u9988\uff1b\u91c7\u7528\u57fa\u4e8e\u62bd\u8c61\u8bed\u6cd5\u6811\u7684\u8c03\u8bd5\u884c\u4e3a\u5206\u6790\u6a21\u578b\uff0c\u7ed3\u5408\u8282\u70b9\u6ce8\u91ca\u3001\u5e8f\u5217\u8bc6\u522b\u548c\u805a\u7c7b\u5206\u6790\u7b49\u6280\u672f\uff0c\u81ea\u52a8\u8ddf\u8e2a\u8c03\u8bd5\u8fc7\u7a0b\u4e0a\u4e0b\u6587\u5e76\u8bc6\u522b\u5173\u952e\u7279\u5f81\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u5b9e\u65f6\u76d1\u63a7\u5b66\u751f\u8c03\u8bd5\u884c\u4e3a\uff0c\u667a\u80fd\u5316\u8bc6\u522b\u8c03\u8bd5\u65b9\u5411\u4e0e\u884c\u4e3a\u6a21\u5f0f\uff0c\u5b9e\u73b0\u7cbe\u7ec6\u5316\u8c03\u8bd5\u6570\u636e\u5206\u6790\u3002\u901a\u8fc7\u5f15\u5165\u591a\u6587\u4ef6\u591a\u4efb\u52a1\u590d\u6742\u573a\u666f\uff0c\u63d0\u5347\u4e86\u6570\u636e\u591a\u7ef4\u6355\u6349\u80fd\u529b\u3002\u7ecf\u8fc7\u591a\u6b21\u6559\u5b66\u6d4b\u8bd5\uff0c\u8bc1\u660e\u4e86\u7cfb\u7edf\u7684\u53ef\u884c\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u53ef\u6709\u6548\u652f\u6301\u8c03\u8bd5\u6559\u5b66\u4e2d\u7684\u7a0b\u5e8f\u5316\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e0d\u4ec5\u4f18\u5316\u548c\u63d0\u5347\u4e86\u5b66\u751f\u8c03\u8bd5\u884c\u4e3a\u5206\u6790\u7684\u7cbe\u5ea6\uff0c\u8fd8\u4e3a\u8c03\u8bd5\u884c\u4e3a\u5206\u6790\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u80fd\u591f\u6539\u5584\u6559\u5e08\u7684\u6559\u5b66\u6548\u679c\uff0c\u8f85\u52a9\u66f4\u52a0\u79d1\u5b66\u7cbe\u51c6\u7684\u8c03\u8bd5\u80fd\u529b\u8bc4\u4f30\u3002"}}
{"id": "2511.05560", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05560", "abs": "https://arxiv.org/abs/2511.05560", "authors": ["Patrick Haller", "Jonas Golde", "Alan Akbik"], "title": "Sample-Efficient Language Modeling with Linear Attention and Lightweight Enhancements", "comment": null, "summary": "We study architectural and optimization techniques for sample-efficient language modeling under the constraints of the BabyLM 2025 shared task. Our model, BLaLM, replaces self-attention with a linear-time mLSTM token mixer and explores lightweight enhancements, including short convolutions, sliding window attention with dynamic modulation, and Hedgehog feature maps. To support training in low-resource settings, we curate a high-quality corpus emphasizing readability and pedagogical structure. Experiments across both STRICT and STRICT-SMALL tracks show that (1) linear attention combined with sliding window attention consistently improves zero-shot performance, and (2) the Muon optimizer stabilizes convergence and reduces perplexity over AdamW. These results highlight effective strategies for efficient language modeling without relying on scale.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u91c7\u7528mLSTM\u548c\u591a\u79cd\u8f7b\u91cf\u5316\u6539\u8fdb\u7684BLaLM\u6a21\u578b\uff0c\u5e76\u5728BabyLM 2025\u4efb\u52a1\u8bbe\u5b9a\u4e0b\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002\u4e3b\u8981\u521b\u65b0\u5305\u62ec\u7ebf\u6027\u6ce8\u610f\u529b\u4e0e\u6ed1\u52a8\u7a97\u6ce8\u610f\u529b\uff0c\u53ca\u65b0\u578bMuon\u4f18\u5316\u5668\uff0c\u5747\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u7684\u8868\u73b0\uff0c\u8868\u660e\u5c0f\u89c4\u6a21\u4f46\u9ad8\u6548\u7684\u8bed\u8a00\u6a21\u578b\u5177\u6709\u5b9e\u9645\u53ef\u884c\u6027\u3002", "motivation": "\u5728BabyLM 2025\u6311\u6218\u9650\u5236\u4e0b\uff0c\u9700\u8981\u5f00\u53d1\u5728\u8d44\u6e90\u6709\u9650\u60c5\u51b5\u4e0b\u4ecd\u80fd\u9ad8\u6548\u8fdb\u884c\u8bed\u8a00\u5efa\u6a21\u7684\u65b9\u6cd5\u548c\u67b6\u6784\u3002\u73b0\u6709\u6a21\u578b\u4f9d\u8d56\u4e8e\u5927\u89c4\u6a21\u8bad\u7ec3\uff0c\u8d44\u6e90\u6d88\u8017\u5927\uff0c\u56e0\u6b64\u5bfb\u627e\u66f4\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u975e\u5e38\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86BLaLM\u6a21\u578b\uff0c\u7528mLSTM\u66ff\u6362\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5e76\u7ed3\u5408\u77ed\u5377\u79ef\u3001\u6ed1\u52a8\u7a97\u6ce8\u610f\u529b\uff08\u53ef\u52a8\u6001\u8c03\u5236\uff09\u3001Hedgehog\u7279\u5f81\u6620\u5c04\u7b49\u8f7b\u91cf\u5316\u6539\u8fdb\uff1b\u540c\u65f6\uff0c\u6574\u7406\u4e86\u4e00\u5957\u9ad8\u8d28\u91cf\u3001\u5f3a\u8c03\u53ef\u8bfb\u6027\u548c\u6559\u5b66\u7ed3\u6784\u7684\u6570\u636e\u96c6\u4ee5\u9002\u5e94\u4f4e\u8d44\u6e90\u8bbe\u5b9a\u3002\u4f18\u5316\u5668\u65b9\u9762\uff0c\u5c1d\u8bd5\u4e86Muon\u4ee5\u63d0\u5347\u6536\u655b\u7a33\u5b9a\u6027\u548c\u51cf\u5c11\u56f0\u60d1\u5ea6\u3002", "result": "\u5728STRICT\u548cSTRICT-SMALL\u4e24\u4e2a\u8bc4\u6d4b\u8d5b\u9053\u4e0a\uff0c\u7ebf\u6027\u6ce8\u610f\u529b\u4e0e\u6ed1\u52a8\u7a97\u6ce8\u610f\u529b\u7ed3\u5408\u80fd\u7a33\u5b9a\u63d0\u5347\u96f6\u6837\u672c\u4efb\u52a1\u8868\u73b0\uff1bMuon\u4f18\u5316\u5668\u5bf9\u4e8e\u6a21\u578b\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\u548c\u56f0\u60d1\u5ea6\u5747\u4f18\u4e8e\u5e38\u7528\u7684AdamW\u3002", "conclusion": "\u65e0\u9700\u5927\u89c4\u6a21\u6a21\u578b\uff0c\u901a\u8fc7\u8f7b\u91cf\u5316\u67b6\u6784\u3001\u6709\u6548\u4f18\u5316\u7b56\u7565\u548c\u9ad8\u8d28\u91cf\u6570\u636e\uff0c\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u6548\u3001\u6837\u672c\u8282\u7ea6\u7684\u8bed\u8a00\u5efa\u6a21\u3002"}}
{"id": "2511.05862", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05862", "abs": "https://arxiv.org/abs/2511.05862", "authors": ["Xinlong Zhao", "Tong Jia", "Minghua He", "Ying Li", "Gang Huang"], "title": "ZeroLog: Zero-Label Generalizable Cross-System Log-based Anomaly Detection", "comment": "12 pages, 17 figures, and 3 tables; accepted by ISSRE 2025", "summary": "Log-based anomaly detection is an important task in ensuring the stability and reliability of software systems. One of the key problems in this task is the lack of labeled logs. Existing works usually leverage large-scale labeled logs from mature systems to train an anomaly detection model of a target system based on the idea of transfer learning. However, these works still require a certain number of labeled logs from the target system. In this paper, we take a step forward and study a valuable yet underexplored setting: zero-label cross-system log-based anomaly detection, that is, no labeled logs are available in the target system. Specifically, we propose ZeroLog, a system-agnostic representation meta-learning method that enables cross-system log-based anomaly detection under zero-label conditions. To achieve this, we leverage unsupervised domain adaptation to perform adversarial training between the source and target domains, aiming to learn system-agnostic general feature representations. By employing meta-learning, the learned representations are further generalized to the target system without any target labels. Experimental results on three public log datasets from different systems show that ZeroLog reaches over 80% F1-score without labels, comparable to state-of-the-art cross-system methods trained with labeled logs, and outperforms existing methods under zero-label conditions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faZeroLog\u65b9\u6cd5\u5b9e\u73b0\u96f6\u6807\u7b7e\u8de8\u7cfb\u7edf\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\uff0c\u901a\u8fc7\u5bf9\u6297\u8bad\u7ec3\u548c\u5143\u5b66\u4e60\u83b7\u5f97\u7cfb\u7edf\u65e0\u5173\u7279\u5f81\uff0c\u65e0\u9700\u76ee\u6807\u7cfb\u7edf\u6807\u7b7e\u53ef\u8fbe\u5148\u8fdb\u6027\u80fd\uff0c\u5927\u5e45\u964d\u4f4e\u5e94\u7528\u95e8\u69db\u3002", "motivation": "\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u5bf9\u4e8e\u8f6f\u4ef6\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u548c\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b9e\u9645\u4e2d\u5e38\u5e38\u7f3a\u4e4f\u6709\u6807\u7b7e\u7684\u65e5\u5fd7\u6570\u636e\u3002\u5f53\u524d\u65b9\u6cd5\u591a\u4f9d\u8d56\u8fc1\u79fb\u5b66\u4e60\uff0c\u501f\u52a9\u6210\u719f\u7cfb\u7edf\u7684\u5927\u91cf\u6807\u6ce8\u65e5\u5fd7\uff0c\u4f46\u4ecd\u9700\u76ee\u6807\u7cfb\u7edf\u7684\u90e8\u5206\u6807\u7b7e\u3002\u4f5c\u8005\u5173\u6ce8\u7684\u662f\u4e00\u4e2a\u66f4\u6781\u7aef\u4f46\u5b9e\u9645\u5e38\u89c1\u7684\u573a\u666f\uff1a\u76ee\u6807\u7cfb\u7edf\u5b8c\u5168\u7f3a\u4e4f\u6807\u7b7e\uff0c\u5373\u201c\u96f6\u6807\u7b7e\u8de8\u7cfb\u7edf\u201d\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u3002", "method": "\u63d0\u51faZeroLog\u65b9\u6cd5\uff0c\u91c7\u7528\u7cfb\u7edf\u65e0\u5173\u7684\u8868\u793a\u5143\u5b66\u4e60\u3002\u5177\u4f53\u505a\u6cd5\u5305\u62ec\uff1a\u5229\u7528\u65e0\u76d1\u7763\u9886\u57df\u81ea\u9002\u5e94\u6280\u672f\uff0c\u5728\u6e90\u7cfb\u7edf\u4e0e\u76ee\u6807\u7cfb\u7edf\u95f4\u8fdb\u884c\u5bf9\u6297\u8bad\u7ec3\uff0c\u83b7\u5f97\u7cfb\u7edf\u65e0\u5173\u7684\u901a\u7528\u7279\u5f81\u8868\u5f81\uff1b\u901a\u8fc7\u5143\u5b66\u4e60\u65b9\u5f0f\u8fdb\u4e00\u6b65\u63d0\u5347\u7279\u5f81\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5b9e\u73b0\u65e0\u9700\u76ee\u6807\u6807\u7b7e\u7684\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "\u5728\u4e09\u4e2a\u4e0d\u540c\u7cfb\u7edf\u7684\u516c\u5f00\u65e5\u5fd7\u6570\u636e\u96c6\u4e0a\uff0cZeroLog\u5728\u65e0\u6807\u7b7e\u60c5\u51b5\u4e0bF1\u5206\u6570\u8d85\u8fc780%\uff0c\u4e0d\u4ec5\u4e0e\u4f9d\u8d56\u5e26\u6807\u7b7e\u65e5\u5fd7\u7684\u6700\u65b0\u65b9\u6cd5\u6548\u679c\u76f8\u5f53\uff0c\u800c\u4e14\u5728\u96f6\u6807\u7b7e\u6761\u4ef6\u4e0b\u663e\u8457\u4f18\u4e8e\u5df2\u6709\u65b9\u6cd5\u3002", "conclusion": "ZeroLog\u9996\u6b21\u5b9e\u73b0\u4e86\u771f\u6b63\u7684\u96f6\u6807\u7b7e\u8de8\u7cfb\u7edf\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\uff0c\u4ec5\u9700\u6e90\u7cfb\u7edf\u6807\u6ce8\u6570\u636e\u5373\u53ef\u53d6\u5f97\u5353\u8d8a\u6548\u679c\uff0c\u5927\u5e45\u964d\u4f4e\u4e86\u5f02\u5e38\u68c0\u6d4b\u7684\u5b9e\u9645\u6570\u636e\u6807\u6ce8\u6210\u672c\u3002"}}
{"id": "2511.05578", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05578", "abs": "https://arxiv.org/abs/2511.05578", "authors": ["Preston Firestone", "Shubham Ugare", "Gagandeep Singh", "Sasa Misailovic"], "title": "UTF-8 Plumbing: Byte-level Tokenizers Unavoidably Enable LLMs to Generate Ill-formed UTF-8", "comment": "COLM 2025", "summary": "Subword tokenization segments input text according to a pre-defined vocabulary to feed it into a language model; the language model, in turn, generates a sequence made from this same vocabulary. The members of the vocabulary can be built of code points or bytes. Using code points means that all members of the vocabulary are valid UTF-8 characters. However, it also requires thousands of initial members to achieve acceptable coverage of inputs. Beginning with bytes, on the contrary, avoids out-of-vocabulary errors with only 256 initial members of the vocabulary, but the members of the vocabulary and sequences of them are not guaranteed to be valid UTF-8. Sequences that are not valid UTF-8 break code that assumes its input to be valid UTF-8. Applications of language models must account for the breakage thereby introduced. In this paper, we formalize tokenization using monoid theory and prove that tokenizers whose vocabularies contain tokens that are ill-formed UTF-8 can always produce sequences that are ill-formed UTF-8. We demonstrate formally that attempting to incrementally convert tokens back to a string and interpret the results as UTF-8 gives different results than converting the whole sequence of tokens at once. This formal result predicts real-world bugs: we evaluate mitigations for the problem identified and provide case studies of major foundation models, serving engines, and constrained generation systems.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6027\u5206\u6790\u4e86\u57fa\u4e8e\u5b57\u8282\u5b50\u8bcd\u5206\u8bcd\u5668\u5b58\u5728\u751f\u6210\u975e\u6cd5UTF-8\u5e8f\u5217\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u7406\u8bba\u8bc1\u660e\u5e76\u901a\u8fc7\u73b0\u5b9e\u6848\u4f8b\u5c55\u793a\u5f71\u54cd\uff0c\u8b66\u793a\u5206\u8bcd\u5668\u8bbe\u8ba1\u53ca\u6a21\u578b\u5e94\u7528\u9700\u9ad8\u5ea6\u5173\u6ce8\u8bcd\u5143\u5408\u6cd5\u6027\uff0c\u5426\u5219\u53ef\u80fd\u9020\u6210\u7cfb\u7edf\u6027Bug\u548c\u517c\u5bb9\u6027\u9690\u60a3\u3002", "motivation": "\u5f53\u524d\u7684\u5b50\u8bcd\u5206\u8bcd\u6280\u672f\u4f7f\u7528\u7edf\u4e00\u8bcd\u8868\u5c06\u8f93\u5165\u6587\u672c\u62c6\u5206\u540e\u9001\u5165\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u57fa\u4e8e\u5b57\u8282\u7684\u5206\u8bcd\u65b9\u5f0f\u53ef\u80fd\u9020\u6210\u5206\u8bcd\u7ed3\u679c\u4e0d\u662f\u6709\u6548\u7684UTF-8\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u4e0b\u6e38\u5e94\u7528\u51fa\u9519\u3002", "method": "\u4f5c\u8005\u5c06\u5206\u8bcd\u8fc7\u7a0b\u5f62\u5f0f\u5316\u4e3a\u5e7a\u534a\u7fa4\u7406\u8bba\uff0c\u5e76\u5bf9\u5206\u8bcd\u5668\u8bcd\u8868\u4e2d\u5b58\u5728\u975e\u5408\u6cd5UTF-8\u5206\u8bcd\u7684\u60c5\u5f62\u8fdb\u884c\u6570\u5b66\u8bc1\u660e\uff0c\u63ed\u793a\u7f16\u7801\u8f6c\u6362\u589e\u91cf\u5904\u7406\u548c\u6574\u4f53\u5904\u7406\u7ed3\u679c\u5dee\u5f02\uff0c\u540c\u65f6\u5bf9\u4e3b\u6d41\u57fa\u7840\u6a21\u578b\u548c\u63a8\u7406\u670d\u52a1\u7684\u7f13\u89e3\u63aa\u65bd\u53ca\u6848\u4f8b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bc1\u660e\u4e86\u53ea\u8981\u8bcd\u8868\u5305\u542b\u975e\u6cd5UTF-8\u5206\u8bcd\uff0c\u5c31\u5fc5\u7136\u53ef\u4ee5\u751f\u6210\u975e\u6cd5UTF-8\u5e8f\u5217\uff1b\u5b9e\u9a8c\u53ca\u6848\u4f8b\u5206\u6790\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u5e76\u8bc4\u4f30\u4e86\u73b0\u6709\u7f13\u89e3\u624b\u6bb5\u3002", "conclusion": "\u5206\u8bcd\u5668\u8bbe\u8ba1\u82e5\u5b58\u5728\u975e\u5408\u6cd5UTF-8\u8bcd\u5143\u4f1a\u5b9e\u8d28\u6027\u5f15\u5165\u540e\u7eed\u5904\u7406\u98ce\u9669\uff0c\u7cfb\u7edf\u9700\u660e\u786e\u8003\u91cf\u8bcd\u5143\u5408\u6cd5\u6027\u53ca\u76f8\u5173\u517c\u5bb9\u6027\u95ee\u9898\u3002"}}
{"id": "2511.05882", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05882", "abs": "https://arxiv.org/abs/2511.05882", "authors": ["Xinlong Zhao", "Tong Jia", "Minghua He", "Ying Li"], "title": "Generality Is Not Enough: Zero-Label Cross-System Log-Based Anomaly Detection via Knowledge-Level Collaboration", "comment": "5 pages, 2 figures, 1 table", "summary": "Log-based anomaly detection is crucial for ensuring software system stability. However, the scarcity of labeled logs limits rapid deployment to new systems. Cross-system transfer has become an important research direction. State-of-the-art approaches perform well with a few labeled target logs, but limitations remain: small-model methods transfer general knowledge but overlook mismatches with the target system's proprietary knowledge; LLM-based methods can capture proprietary patterns but rely on a few positive examples and incur high inference cost. Existing LLM-small model collaborations route 'simple logs' to the small model and 'complex logs' to the LLM based on output uncertainty. In zero-label cross-system settings, supervised sample complexity is unavailable, and such routing does not consider knowledge separation. To address this, we propose GeneralLog, a novel LLM-small model collaborative method for zero-label cross-system log anomaly detection. GeneralLog dynamically routes unlabeled logs, letting the LLM handle 'proprietary logs' and the small model 'general logs,' enabling cross-system generalization without labeled target logs. Experiments on three public log datasets show that GeneralLog achieves over 90% F1-score under a fully zero-label setting, significantly outperforming existing methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGeneralLog\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u77e5\u8bc6\u5206\u5de5\u5b9e\u73b0\u96f6\u6807\u7b7e\u8de8\u7cfb\u7edf\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\uff0c\u65e0\u9700\u76ee\u6807\u7cfb\u7edf\u6807\u6ce8\uff0c\u6027\u80fd\uff08F1>90%\uff09\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u65e5\u5fd7\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5728\u8de8\u7cfb\u7edf\u5e94\u7528\u65f6\u9762\u4e34\u96be\u4ee5\u83b7\u5f97\u76ee\u6807\u7cfb\u7edf\u5e26\u6807\u7b7e\u65e5\u5fd7\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u90e8\u7f72\u53d7\u9650\u3002\u867d\u7136\u6700\u65b0\u65b9\u6cd5\u5728\u5c11\u91cf\u6807\u6ce8\u4e0b\u8868\u73b0\u4e0d\u9519\uff0c\u4f46\u4f9d\u8d56\u6837\u672c\u590d\u6742\u5ea6\u4e14\u77e5\u8bc6\u8fc1\u79fb\u4e0d\u8db3\u6216\u63a8\u7406\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u6ee1\u8db3\u96f6\u6807\u7b7e\u573a\u666f\u9700\u6c42\u3002", "method": "\u63d0\u51faGeneralLog\u65b9\u6cd5\uff0c\u521b\u65b0\u6027\u5730\u7ed3\u5408LLM\u548c\u5c0f\u6a21\u578b\uff0c\u5728\u96f6\u6807\u7b7e\u8de8\u7cfb\u7edf\u573a\u666f\u4e0b\u6839\u636e\u65e5\u5fd7\u7c7b\u578b\u52a8\u6001\u5206\u914d\u5904\u7406\u4efb\u52a1\uff1aLLM\u8d1f\u8d23\u76ee\u6807\u7cfb\u7edf\u7684\u4e13\u6709\u65e5\u5fd7\uff0c\u5c0f\u6a21\u578b\u8d1f\u8d23\u901a\u7528\u65e5\u5fd7\uff0c\u5b9e\u73b0\u77e5\u8bc6\u5206\u5de5\u534f\u4f5c\uff0c\u65e0\u9700\u76ee\u6807\u7cfb\u7edf\u7684\u6807\u6ce8\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u65e5\u5fd7\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cGeneralLog\u5728\u5b8c\u5168\u65e0\u6807\u7b7e\u7684\u8bbe\u7f6e\u4e0b\u80fd\u53d6\u5f9790%\u4ee5\u4e0a\u7684F1\u5206\u6570\uff0c\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "GeneralLog\u6539\u53d8\u4e86\u8de8\u7cfb\u7edf\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u7684\u77e5\u8bc6\u5206\u914d\u7b56\u7565\uff0c\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u96f6\u6807\u7b7e\u4e0b\u9ad8\u6027\u80fd\u68c0\u6d4b\uff0c\u8fd8\u7a81\u7834\u4e86\u4ee5\u5f80\u6a21\u578b\u5728\u77e5\u8bc6\u8fc1\u79fb\u4e0e\u63a8\u7406\u6548\u7387\u4e0a\u7684\u9650\u5236\u3002"}}
{"id": "2511.05650", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05650", "abs": "https://arxiv.org/abs/2511.05650", "authors": ["Yichen Wang", "Chenghao Yang", "Tenghao Huang", "Muhao Chen", "Jonathan May", "Mina Lee"], "title": "Optimizing Diversity and Quality through Base-Aligned Model Collaboration", "comment": "52 pages, 16 figures", "summary": "Alignment has greatly improved large language models (LLMs)' output quality at the cost of diversity, yielding highly similar outputs across generations. We propose Base-Aligned Model Collaboration (BACo), an inference-time token-level model collaboration framework that dynamically combines a base LLM with its aligned counterpart to optimize diversity and quality. Inspired by prior work (Fei et al., 2025), BACo employs routing strategies that determine, at each token, from which model to decode based on next-token prediction uncertainty and predicted contents' semantic role. Prior diversity-promoting methods, such as retraining, prompt engineering, and multi-sampling methods, improve diversity but often degrade quality or require costly decoding or post-training. In contrast, BACo achieves both high diversity and quality post hoc within a single pass, while offering strong controllability. We explore a family of routing strategies, across three open-ended generation tasks and 13 metrics covering diversity and quality, BACo consistently surpasses state-of-the-art inference-time baselines. With our best router, BACo achieves a 21.3% joint improvement in diversity and quality. Human evaluations also mirror these improvements. The results suggest that collaboration between base and aligned models can optimize and control diversity and quality.", "AI": {"tldr": "BACo\u662f\u4e00\u79cd\u63a8\u7406\u9636\u6bb5\u52a8\u6001\u7ed3\u5408\u57fa\u7840\u4e0e\u5bf9\u9f50\u5927\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\uff0c\u65e0\u9700\u91cd\u8bad\u7ec3\u6216\u591a\u6b21\u91c7\u6837\u5373\u53ef\u540c\u6b65\u63d0\u5347\u8f93\u51fa\u7684\u591a\u6837\u6027\u548c\u8d28\u91cf\uff0c\u5e76\u5b9e\u73b0\u5f3a\u53ef\u63a7\u6027\uff0c\u5728\u591a\u9879\u4efb\u52a1\u548c\u5ea6\u91cf\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u5bf9\u9f50\u6280\u672f\u867d\u7136\u63d0\u5347\u4e86\u5927\u6a21\u578b\u8f93\u51fa\u7684\u8d28\u91cf\uff0c\u5374\u5bfc\u81f4\u751f\u6210\u7ed3\u679c\u9ad8\u5ea6\u76f8\u4f3c\uff0c\u727a\u7272\u4e86\u591a\u6837\u6027\uff0c\u4e9f\u9700\u4e00\u79cd\u65b9\u6cd5\u5728\u4e0d\u635f\u5931\u8d28\u91cf\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u591a\u6837\u6027\u3002", "method": "\u63d0\u51fa\u4e86Base-Aligned Model Collaboration\uff08BACo\uff09\u63a8\u7406\u9636\u6bb5\u7684token\u7ea7\u6a21\u578b\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u6574\u5408\u57fa\u7840\u6a21\u578b\u548c\u5bf9\u9f50\u540e\u7684\u6a21\u578b\uff0c\u57fa\u4e8e\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u8bed\u4e49\u89d2\u8272\uff0c\u8def\u7531\u51b3\u5b9a\u7531\u54ea\u4e2a\u6a21\u578b\u751f\u6210\u8be5token\uff0c\u4ece\u800c\u4f18\u5316\u7ed3\u679c\u7684\u591a\u6837\u6027\u4e0e\u8d28\u91cf\u3002", "result": "\u5728\u4e09\u7c7b\u5f00\u653e\u5f0f\u751f\u6210\u4efb\u52a1\u548c13\u79cd\u5ea6\u91cf\u6807\u51c6\u4e0b\uff0cBACo\u5728\u591a\u6837\u6027\u548c\u8d28\u91cf\u4e0a\u5747\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u63a8\u7406\u65b9\u6cd5\uff0c\u6700\u4f73\u8def\u7531\u5668\u5b9e\u73b0\u4e8621.3%\u7684\u591a\u6837\u6027\u4e0e\u8d28\u91cf\u8054\u5408\u63d0\u5347\uff0c\u4e14\u4eba\u7c7b\u8bc4\u4ef7\u540c\u6837\u8bc1\u660e\u4e86\u6539\u8fdb\u3002", "conclusion": "\u5728\u63a8\u7406\u9636\u6bb5\u57fa\u7840\u6a21\u578b\u4e0e\u5bf9\u9f50\u6a21\u578b\u5408\u4f5c\uff0c\u53ef\u5b9e\u73b0\u517c\u987e\u9ad8\u591a\u6837\u6027\u548c\u9ad8\u8d28\u91cf\u7684\u751f\u6210\u6548\u679c\uff0c\u5e76\u5927\u5e45\u63d0\u5347\u5bf9\u751f\u6210\u5185\u5bb9\u7684\u53ef\u63a7\u6027\u3002"}}
{"id": "2511.05722", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05722", "abs": "https://arxiv.org/abs/2511.05722", "authors": ["Zheng Du", "Hao Kang", "Song Han", "Tushar Krishna", "Ligeng Zhu"], "title": "OckBench: Measuring the Efficiency of LLM Reasoning", "comment": null, "summary": "Large language models such as GPT-4, Claude 3, and the Gemini series have improved automated reasoning and code generation. However, existing benchmarks mainly focus on accuracy and output quality, and they ignore an important factor: decoding token efficiency. In real systems, generating 10,000 tokens versus 100,000 tokens leads to large differences in latency, cost, and energy. In this work, we introduce OckBench, a model-agnostic and hardware-agnostic benchmark that evaluates both accuracy and token count for reasoning and coding tasks. Through experiments comparing multiple open- and closed-source models, we uncover that many models with comparable accuracy differ wildly in token consumption, revealing that efficiency variance is a neglected but significant axis of differentiation. We further demonstrate Pareto frontiers over the accuracy-efficiency plane and argue for an evaluation paradigm shift: we should no longer treat tokens as \"free\" to multiply. OckBench provides a unified platform for measuring, comparing, and guiding research in token-efficient reasoning. Our benchmarks are available at https://ockbench.github.io/ .", "AI": {"tldr": "OckBench\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u5927\u6a21\u578b\u8bc4\u4f30\u4e0d\u4ec5\u8981\u770b\u51c6\u786e\u7387\uff0c\u8fd8\u5e94\u5173\u6ce8token\u751f\u6210\u6548\u7387\u3002\u7814\u7a76\u8868\u660e\uff0c\u6a21\u578b\u5728token\u6d88\u8017\u4e0a\u7684\u5dee\u5f02\u663e\u8457\uff0c\u5ffd\u89c6\u6548\u7387\u4e0d\u5229\u4e8e\u6a21\u578b\u5b9e\u9645\u5e94\u7528\u3002OckBench\u4e3a\u4e1a\u754c\u548c\u5b66\u672f\u754c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u51c6\u786e\u7387\u4e0e\u6548\u7387\u5e76\u91cd\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\u3002", "motivation": "\u5f53\u524d\u5927\u6a21\u578b\u8bc4\u6d4b\u4e3b\u8981\u5173\u6ce8\u51c6\u786e\u7387\u548c\u8f93\u51fa\u8d28\u91cf\uff0c\u5ffd\u7565\u4e86\u5b9e\u9645\u5e94\u7528\u4e2dtoken\u751f\u6210\u6570\u91cf\u5bf9\u5ef6\u8fdf\u3001\u6210\u672c\u53ca\u80fd\u8017\u7684\u663e\u8457\u5f71\u54cd\u3002\u4f5c\u8005\u5e0c\u671b\u5efa\u7acb\u4e00\u4e2a\u53ef\u540c\u65f6\u8861\u91cf\u51c6\u786e\u7387\u548ctoken\u6548\u7387\u7684\u7edf\u4e00\u6807\u51c6\uff0c\u4ece\u800c\u63a8\u52a8\u6a21\u578b\u9ad8\u6548\u6027\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u4e86OckBench\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e0e\u6a21\u578b\u548c\u786c\u4ef6\u65e0\u5173\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u80fd\u8bc4\u4f30\u6a21\u578b\u5728\u63a8\u7406\u548c\u4ee3\u7801\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u7387\u53catoken\u6d88\u8017\u3002\u901a\u8fc7\u5bf9\u591a\u79cd\u5f00\u6e90\u548c\u95ed\u6e90\u5927\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\u6bd4\u8f83\uff0c\u5206\u6790\u4e86\u51c6\u786e\u7387\u4e0etoken\u6548\u7387\u7684\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff1a\u8bb8\u591a\u51c6\u786e\u7387\u63a5\u8fd1\u7684\u6a21\u578b\u5728token\u6d88\u8017\u4e0a\u5dee\u5f02\u5f88\u5927\uff0ctoken\u6548\u7387\u6210\u4e3a\u5ffd\u89c6\u4f46\u91cd\u8981\u7684\u80fd\u529b\u3002\u4f5c\u8005\u5c55\u793a\u4e86\u51c6\u786e\u7387-\u6548\u7387\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u8bc1\u660e\u4e86\u6548\u7387\u8003\u91cf\u7684\u5fc5\u8981\u6027\u3002OckBench\u6210\u4e3a\u8bc4\u4f30\u548c\u5f15\u5bfc\u9ad8\u6548\u63a8\u7406\u6a21\u578b\u7814\u7a76\u7684\u65b0\u5e73\u53f0\u3002", "conclusion": "OckBench\u63ed\u793a\u4e86\u5728\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u7684\u51c6\u786e\u7387\u548c\u751f\u6210token\u6548\u7387\u540c\u6837\u91cd\u8981\u3002\u5f88\u591a\u6a21\u578b\u51c6\u786e\u7387\u76f8\u8fd1\uff0c\u4f46token\u6d88\u8017\u5374\u5b58\u5728\u5de8\u5927\u5dee\u5f02\uff0c\u56e0\u6b64\u5e94\u91cd\u89c6token\u6548\u7387\u4f5c\u4e3a\u6a21\u578b\u8bc4\u4ef7\u7684\u5173\u952e\u7ef4\u5ea6\u3002\u4f5c\u8005\u63d0\u51fa\u4e0d\u5e94\u518d\u628atoken\u5f53\u4f5c\u201c\u514d\u8d39\u8d44\u6e90\u201d\u770b\u5f85\uff0c\u5021\u5bfc\u65b0\u7684\u8bc4\u4f30\u8303\u5f0f\u3002"}}
{"id": "2511.06090", "categories": ["cs.SE", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.06090", "abs": "https://arxiv.org/abs/2511.06090", "authors": ["Jeffrey Jian Ma", "Milad Hashemi", "Amir Yazdanbakhsh", "Kevin Swersky", "Ofir Press", "Enhui Li", "Vijay Janapa Reddi", "Parthasarathy Ranganathan"], "title": "SWE-fficiency: Can Language Models Optimize Real-World Repositories on Real Workloads?", "comment": "Data, code, and leaderboard are available at https://swefficiency.com/", "summary": "Optimizing the performance of large-scale software repositories demands expertise in code reasoning and software engineering (SWE) to reduce runtime while preserving program correctness. However, most benchmarks emphasize what to fix rather than how to fix code. We introduce \\textsc{SWE-fficiency}, a benchmark for evaluating repository-level performance optimization on real workloads. Our suite contains 498 tasks across nine widely used data-science, machine-learning, and HPC repositories (e.g., numpy, pandas, scipy): given a complete codebase and a slow workload, an agent must investigate code semantics, localize bottlenecks and relevant tests, and produce a patch that matches or exceeds expert speedup while passing the same unit tests. To enable this how-to-fix evaluation, our automated pipeline scrapes GitHub pull requests for performance-improving edits, combining keyword filtering, static analysis, coverage tooling, and execution validation to both confirm expert speedup baselines and identify relevant repository unit tests. Empirical evaluation of state-of-the-art agents reveals significant underperformance. On average, agents achieve less than 0.15x the expert speedup: agents struggle in localizing optimization opportunities, reasoning about execution across functions, and maintaining correctness in proposed edits. We release the benchmark and accompanying data pipeline to facilitate research on automated performance engineering and long-horizon software reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSWE-fficiency\u57fa\u51c6\uff0c\u81ea\u52a8\u4ece\u771f\u5b9e\u5f00\u6e90\u4ed3\u5e93\u91c7\u96c6\u6027\u80fd\u4f18\u5316\u4efb\u52a1\uff0c\u9488\u5bf9\u5b8c\u6574\u4ee3\u7801\u5e93\u53ca\u6162\u901f\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u7cfb\u7edf\u8bc4\u4f30\u667a\u80fd\u4f53\u7684\u5b9a\u4f4d\u3001\u4fee\u590d\u548c\u6d4b\u8bd5\u80fd\u529b\u3002\u7ed3\u679c\u663e\u793a\u73b0\u6709\u667a\u80fd\u4f53\u8fdc\u843d\u540e\u4e13\u5bb6\uff0c\u516c\u5f00\u7684\u6570\u636e\u548c\u57fa\u51c6\u5c06\u63a8\u52a8\u81ea\u52a8\u5316\u6027\u80fd\u5de5\u7a0b\u4e0e\u8f6f\u4ef6\u63a8\u7406\u9886\u57df\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u7684\u6027\u80fd\u4f18\u5316\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u4e8e\u4ee3\u7801\u9700\u8981\u4fee\u590d\u7684\u5730\u65b9\uff0c\u5373\u201c\u4fee\u4ec0\u4e48\u201d\uff0c\u800c\u5ffd\u7565\u4e86\u5177\u4f53\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u5373\u201c\u600e\u4e48\u4fee\u201d\u3002\u4e9f\u9700\u4e00\u4e2a\u80fd\u591f\u7efc\u5408\u8bc4\u4f30\u5927\u578b\u8f6f\u4ef6\u4ed3\u5e93\u6027\u80fd\u4f18\u5316\u80fd\u529b\u3001\u5c24\u5176\u5173\u6ce8\u4f18\u5316\u8def\u5f84\u548c\u65b9\u6cd5\u4e4b\u57fa\u51c6\u3002", "method": "\u672c\u7814\u7a76\u6784\u5efa\u4e86SWE-fficiency\u57fa\u51c6\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u5316\u6d41\u7a0b\uff1a\u4eceGitHub\u62c9\u53d6\u6027\u80fd\u4f18\u5316\u76f8\u5173\u7684Pull Request\uff0c\u7ed3\u5408\u5173\u952e\u8bcd\u7b5b\u9009\u3001\u9759\u6001\u5206\u6790\u3001\u8986\u76d6\u7387\u5de5\u5177\u548c\u6267\u884c\u9a8c\u8bc1\uff0c\u5f97\u5230\u6027\u80fd\u63d0\u5347\u7684\u4ee3\u7801\u4fee\u6b63\u548c\u76f8\u5173\u6d4b\u8bd5\u3002\u8be5\u57fa\u51c6\u8986\u76d69\u4e2a\u4e3b\u6d41\u7684\u6570\u636e\u79d1\u5b66\u3001\u673a\u5668\u5b66\u4e60\u548c\u9ad8\u6027\u80fd\u8ba1\u7b97\u4ed3\u5e93\uff0c\u5171\u8ba1498\u4e2a\u5177\u4f53\u4efb\u52a1\u3002\u8bc4\u4f30\u4e2d\uff0c\u8981\u6c42\u667a\u80fd\u4f53\u5b9a\u4f4d\u6027\u80fd\u74f6\u9888\u548c\u76f8\u5173\u6d4b\u8bd5\u3001\u5e76\u63d0\u4ea4\u80fd\u8fbe\u5230\u751a\u81f3\u8d85\u8fc7\u4e13\u5bb6\u52a0\u901f\u6548\u679c\u4e14\u901a\u8fc7\u6240\u6709\u5355\u5143\u6d4b\u8bd5\u7684\u8865\u4e01\u3002", "result": "\u73b0\u6709\u5148\u8fdb\u667a\u80fd\u4f53\u5e73\u5747\u4ec5\u80fd\u8fbe\u5230\u4e13\u5bb6\u52a0\u901f\u6548\u679c\u76840.15\u500d\uff0c\u4e3b\u8981\u5728\u4e8e\u667a\u80fd\u4f53\u5728\u5b9a\u4f4d\u4f18\u5316\u673a\u4f1a\u3001\u8de8\u51fd\u6570\u6267\u884c\u63a8\u7406\u4ee5\u53ca\u4fdd\u8bc1\u4ee3\u7801\u6b63\u786e\u6027\u65b9\u9762\u5b58\u5728\u8f83\u5927\u4e0d\u8db3\u3002", "conclusion": "SWE-fficiency\u57fa\u51c6\u4e3a\u8f6f\u4ef6\u6027\u80fd\u81ea\u52a8\u5316\u5de5\u7a0b\u4e0e\u590d\u6742\u4ee3\u7801\u4f18\u5316\u65b9\u6cd5\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u5e73\u53f0\u548c\u6570\u636e\uff0c\u5f53\u524d\u667a\u80fd\u4f53\u5728\u6b64\u4efb\u52a1\u4e0b\u4ecd\u9762\u4e34\u8f83\u5927\u6311\u6218\u3002\u7814\u7a76\u8005\u53ef\u4ee5\u636e\u6b64\u6539\u8fdb\u81ea\u52a8\u5316\u8f6f\u5de5\u667a\u80fd\u4f53\uff0c\u63d0\u9ad8\u5176\u5b9e\u9645\u6027\u80fd\u4f18\u5316\u80fd\u529b\u3002"}}
{"id": "2511.05743", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05743", "abs": "https://arxiv.org/abs/2511.05743", "authors": ["Kerem Sahin", "Sheridan Feucht", "Adam Belfki", "Jannik Brinkmann", "Aaron Mueller", "David Bau", "Chris Wendler"], "title": "In-Context Learning Without Copying", "comment": null, "summary": "Induction heads are attention heads that perform inductive copying by matching patterns from earlier context and copying their continuations verbatim. As models develop induction heads, they often experience a sharp drop in training loss, a phenomenon cited as evidence that induction heads may serve as a prerequisite for more complex in-context learning (ICL) capabilities. In this work, we ask whether transformers can still acquire ICL capabilities when inductive copying is suppressed. We propose Hapax, a setting where we omit the loss contribution of any token that can be correctly predicted by induction heads. Despite a significant reduction in inductive copying, performance on abstractive ICL tasks (i.e., tasks where the answer is not contained in the input context) remains comparable and surpasses the vanilla model on 13 of 21 tasks, even though 31.7\\% of tokens are omitted from the loss. Furthermore, our model achieves lower loss values on token positions that cannot be predicted correctly by induction heads. Mechanistic analysis further shows that models trained with Hapax develop fewer and weaker induction heads but still preserve ICL capabilities. Taken together, our findings indicate that inductive copying is not essential for learning abstractive ICL mechanisms.", "AI": {"tldr": "\u5f52\u7eb3\u5934\u4e0d\u662f\u62bd\u8c61\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u5fc5\u8981\u524d\u63d0\uff0c\u5373\u4fbf\u5927\u5e45\u51cf\u5c11\u5f52\u7eb3\u590d\u5236\uff0c\u6a21\u578b\u5728\u5404\u79cdICL\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4f9d\u7136\u4f18\u5f02\u751a\u81f3\u66f4\u597d\u3002", "motivation": "\u8fc7\u53bb\u7814\u7a76\u8ba4\u4e3a\uff0c\u5728Transformer\u6a21\u578b\u4e2d\u5f52\u7eb3\u590d\u5236\uff08inductive copying\uff09\u7531\u5f52\u7eb3\u5934\uff08induction heads\uff09\u5b9e\u73b0\uff0c\u662f\u66f4\u590d\u6742\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u80fd\u529b\u7684\u524d\u63d0\u3002\u672c\u6587\u8d28\u7591\u8fd9\u79cd\u5f52\u7eb3\u590d\u5236\u662f\u5426\u771f\u7684\u662f\u5fc5\u8981\u7684\u3002", "method": "\u63d0\u51fa\u201cHapax\u201d\u65b9\u6cd5\uff1a\u5728\u8bad\u7ec3\u4e2d\uff0c\u5bf9\u4e8e\u53ef\u4ee5\u7531\u5f52\u7eb3\u5934\u6b63\u786e\u9884\u6d4b\u7684token\uff0c\u5176\u635f\u5931\u4e0d\u8ba1\u5165\u8bad\u7ec3\u76ee\u6807\uff0c\u663e\u8457\u51cf\u5c11\u5f52\u7eb3\u590d\u5236\u73b0\u8c61\u3002\u7136\u540e\u5bf9\u6bd4Hapax\u8bad\u7ec3\u6a21\u578b\u548c\u5e38\u89c4\u6a21\u578b\u5728\u5404\u79cd\u62bd\u8c61ICL\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u5206\u6790\u5f52\u7eb3\u5934\u53d1\u5c55\u60c5\u51b5\u3002", "result": "\u5c3d\u7ba1\u5f52\u7eb3\u590d\u5236\u80fd\u529b\u663e\u8457\u4e0b\u964d\uff0cHapax\u6a21\u578b\u572813/21\u4e2a\u62bd\u8c61ICL\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e0e\u6807\u51c6\u6a21\u578b\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\uff0c\u800c\u4e14\u5728\u65e0\u6cd5\u88ab\u5f52\u7eb3\u5934\u590d\u5236\u7684\u4f4d\u7f6e\u4e0a\u6709\u66f4\u4f4e\u7684\u635f\u5931\u3002\u540c\u65f6\uff0cHapax\u6a21\u578b\u5177\u6709\u66f4\u5c11\u4e14\u66f4\u5f31\u7684\u5f52\u7eb3\u5934\uff0c\u4f46\u4ecd\u4fdd\u7559\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u3002", "conclusion": "\u5f52\u7eb3\u590d\u5236\uff08inductive copying\uff09\u4e0d\u662f\u5b66\u4e60\u62bd\u8c61\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u673a\u5236\u7684\u5fc5\u8981\u6761\u4ef6\u3002\u5373\u4f7f\u6291\u5236\u5f52\u7eb3\u590d\u5236\uff0cTransformer\u6a21\u578b\u4ecd\u80fd\u53d1\u5c55\u590d\u6742\u7684\u62bd\u8c61ICL\u80fd\u529b\u3002"}}
{"id": "2511.06103", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.06103", "abs": "https://arxiv.org/abs/2511.06103", "authors": ["Miguel Goul\u00e3o", "Vasco Amaral", "Marjan Mernik"], "title": "Quality in model-driven engineering: a tertiary study", "comment": null, "summary": "Model-driven engineering (MDE) is believed to have a significant impact in software quality. However, researchers and practitioners may have a hard time locating consolidated evidence on this impact, as the available information is scattered in several different publications. Our goal is to aggregate consolidated findings on quality in MDE, facilitating the work of researchers and practitioners in learning about the coverage and main findings of existing work as well as identifying relatively unexplored niches of research that need further attention. We performed a tertiary study on quality in MDE, in order to gain a better understanding of its most prominent findings and existing challenges, as reported in the literature. We identified 22 systematic literature reviews and mapping studies and the most relevant quality attributes addressed by each of those studies, in the context of MDE. Maintainability is clearly the most often studied and reported quality attribute impacted by MDE. Eighty out of 83 research questions in the selected secondary studies have a structure that is more often associated with mapping existing research than with answering more concrete research questions (e.g., comparing two alternative MDE approaches with respect to their impact on a specific quality attribute). We briefly outline the main contributions of each of the selected literature reviews. In the collected studies, we observed a broad coverage of software product quality, although frequently accompanied by notes on how much more empirical research is needed to further validate existing claims. Relatively, little attention seems to be devoted to the impact of MDE on the quality in use of products developed using MDE.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4e09\u7ea7\u7efc\u8ff0\u7cfb\u7edf\u6574\u5408\u4e86MDE\u5bf9\u8f6f\u4ef6\u8d28\u91cf\u7684\u5f71\u54cd\u7814\u7a76\uff0c\u53d1\u73b0\u53ef\u7ef4\u62a4\u6027\u4e3a\u5173\u6ce8\u91cd\u70b9\uff0c\u4f46\u66f4\u591a\u5b9e\u8bc1\u4e0e\u4f7f\u7528\u8d28\u91cf\u76f8\u5173\u7814\u7a76\u4e9f\u5f85\u52a0\u5f3a\u3002", "motivation": "\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\uff08MDE\uff09\u5bf9\u8f6f\u4ef6\u8d28\u91cf\u7684\u5f71\u54cd\u5e7f\u53d7\u5173\u6ce8\uff0c\u4f46\u76f8\u5173\u8bc1\u636e\u5206\u6563\u5728\u5927\u91cf\u4e0d\u540c\u6587\u732e\u4e2d\uff0c\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u96be\u4ee5\u7cfb\u7edf\u83b7\u53d6\u3002\u672c\u6587\u65e8\u5728\u6574\u5408MDE\u5bf9\u8f6f\u4ef6\u8d28\u91cf\u5f71\u54cd\u7684\u7814\u7a76\u6210\u679c\uff0c\u4e3a\u79d1\u7814\u4e0e\u5b9e\u8df5\u4eba\u5458\u63d0\u4f9b\u4fbf\u6377\u53c2\u8003\uff0c\u5e76\u63ed\u793a\u5c1a\u9700\u5173\u6ce8\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u4f5c\u8005\u8fdb\u884c\u4e86\u5173\u4e8eMDE\u4e0e\u8f6f\u4ef6\u8d28\u91cf\u7684\u4e09\u7ea7\u7814\u7a76\u7efc\u8ff0\uff0c\u7cfb\u7edf\u6536\u96c6\u548c\u5206\u6790\u4e86\u6587\u732e\u4e2d\u7684\u7a81\u51fa\u53d1\u73b0\u548c\u6311\u6218\u3002\u5728\u7b5b\u9009\u6587\u732e\u540e\uff0c\u786e\u5b9a\u4e8622\u9879\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u4e0e\u6620\u5c04\u7814\u7a76\uff0c\u5e76\u63d0\u53d6\u4e86\u5176\u4e2d\u6240\u6d89\u53ca\u7684\u4e3b\u8981\u8d28\u91cf\u5c5e\u6027\u3002", "result": "\u53d1\u73b0MDE\u6700\u5e38\u88ab\u7814\u7a76\u548c\u62a5\u544a\u7684\u8d28\u91cf\u5c5e\u6027\u662f\u53ef\u7ef4\u62a4\u6027\u3002\u88ab\u9009\u5b9a\u7684\u4e8c\u7ea7\u7814\u7a76\u4e2d\u7684\u5927\u591a\u6570\u7814\u7a76\u95ee\u9898\u503e\u5411\u4e8e\u68b3\u7406\u73b0\u6709\u7814\u7a76\uff0c\u800c\u975e\u5bf9\u5177\u4f53\u65b9\u6cd5\u8fdb\u884c\u76f4\u63a5\u5bf9\u6bd4\u3002\u5df2\u6536\u96c6\u7684\u7814\u7a76\u5bf9\u8f6f\u4ef6\u4ea7\u54c1\u8d28\u91cf\u6709\u5e7f\u6cdb\u8986\u76d6\uff0c\u4f46\u591a\u6570\u547c\u5401\u8fdb\u884c\u66f4\u591a\u5b9e\u8bc1\u7814\u7a76\u4ee5\u9a8c\u8bc1\u73b0\u6709\u89c2\u70b9\u3002MDE\u5bf9\u4ea7\u54c1\u4f7f\u7528\u8d28\u91cf\u7684\u5f71\u54cd\u5173\u6ce8\u8f83\u5c11\u3002", "conclusion": "MDE\u5bf9\u8f6f\u4ef6\u8d28\u91cf\u7684\u5f71\u54cd\u5df2\u6709\u8f83\u591a\u7efc\u8ff0\u6027\u7814\u7a76\u79ef\u7d2f\uff0c\u5c24\u5176\u662f\u53ef\u7ef4\u62a4\u6027\u9886\u57df\uff0c\u7136\u800c\u76f8\u5173\u5b9e\u8bc1\u6570\u636e\u548c\u5bf9\u4f7f\u7528\u8d28\u91cf\u7684\u5173\u6ce8\u8fd8\u663e\u4e0d\u8db3\u3002\u7814\u7a76\u8005\u9700\u8865\u8db3\u66f4\u5177\u4f53\u3001\u5bf9\u6bd4\u6027\u53ca\u5b9e\u8bc1\u6027\u7684\u7814\u7a76\uff0c\u5c24\u5176\u5728\u4ea7\u54c1\u4f7f\u7528\u8d28\u91cf\u65b9\u9762\u3002"}}
{"id": "2511.05752", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05752", "abs": "https://arxiv.org/abs/2511.05752", "authors": ["Xiangchen Song", "Yulin Huang", "Jinxu Guo", "Yuchen Liu", "Yaxuan Luan"], "title": "Multi-Scale Feature Fusion and Graph Neural Network Integration for Text Classification with Large Language Models", "comment": null, "summary": "This study investigates a hybrid method for text classification that integrates deep feature extraction from large language models, multi-scale fusion through feature pyramids, and structured modeling with graph neural networks to enhance performance in complex semantic contexts. First, the large language model captures contextual dependencies and deep semantic representations of the input text, providing a rich feature foundation for subsequent modeling. Then, based on multi-level feature representations, the feature pyramid mechanism effectively integrates semantic features of different scales, balancing global information and local details to construct hierarchical semantic expressions. Furthermore, the fused features are transformed into graph representations, and graph neural networks are employed to capture latent semantic relations and logical dependencies in the text, enabling comprehensive modeling of complex interactions among semantic units. On this basis, the readout and classification modules generate the final category predictions. The proposed method demonstrates significant advantages in robustness alignment experiments, outperforming existing models on ACC, F1-Score, AUC, and Precision, which verifies the effectiveness and stability of the framework. This study not only constructs an integrated framework that balances global and local information as well as semantics and structure, but also provides a new perspective for multi-scale feature fusion and structured semantic modeling in text classification tasks.", "AI": {"tldr": "\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u3001\u7279\u5f81\u91d1\u5b57\u5854\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u65b0\u578b\u6587\u672c\u5206\u7c7b\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u4e3b\u6d41\u8bc4\u4ef7\u6307\u6807\u4e0a\u8d85\u8d8a\u73b0\u6709\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u66f4\u5f3a\u7684\u590d\u6742\u8bed\u4e49\u5efa\u6a21\u80fd\u529b\u548c\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u590d\u6742\u8bed\u4e49\u73af\u5883\u4e0b\u5982\u4f55\u6709\u6548\u83b7\u53d6\u548c\u878d\u5408\u5168\u5c40\u4e0e\u5c40\u90e8\u7279\u5f81\uff0c\u5e76\u6355\u6349\u7ed3\u6784\u5316\u8bed\u4e49\u5173\u7cfb\uff0c\u4ee5\u63d0\u5347\u5206\u7c7b\u6027\u80fd\uff0c\u662f\u5f53\u524d\u7814\u7a76\u7684\u6311\u6218\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u65b9\u6cd5\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u6df1\u5c42\u7279\u5f81\u63d0\u53d6\uff0c\u901a\u8fc7\u7279\u5f81\u91d1\u5b57\u5854\u5b9e\u73b0\u591a\u5c3a\u5ea6\u7279\u5f81\u878d\u5408\uff0c\u518d\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u5efa\u6a21\u7ed3\u6784\u5316\u8bed\u4e49\u5173\u7cfb\uff0c\u6700\u540e\u901a\u8fc7\u5206\u7c7b\u6a21\u5757\u8f93\u51fa\u6587\u672c\u7c7b\u522b\u3002", "result": "\u6240\u63d0\u51fa\u65b9\u6cd5\u5728\u9c81\u68d2\u6027\u4e00\u81f4\u6027\u5b9e\u9a8c\u4e2d\uff0c\u5728\u51c6\u786e\u7387\u3001F1\u5206\u6570\u3001AUC\u3001\u7cbe\u786e\u7387\u7b49\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6784\u5efa\u4e86\u4e00\u4e2a\u517c\u987e\u5168\u5c40\u4e0e\u5c40\u90e8\u3001\u8bed\u4e49\u4e0e\u7ed3\u6784\u7684\u4fe1\u606f\u6574\u5408\u6846\u67b6\uff0c\u4e3a\u591a\u5c3a\u5ea6\u7279\u5f81\u878d\u5408\u53ca\u7ed3\u6784\u5316\u8bed\u4e49\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u6709\u671b\u63a8\u52a8\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.06110", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.06110", "abs": "https://arxiv.org/abs/2511.06110", "authors": ["Mafalda Santos", "Catarina Gralha", "Miguel Goul\u00e3o", "Jo\u00e3o Ara\u00fajo", "Ana Moreira"], "title": "On the impact of semantic transparency on understanding and reviewing social goal models", "comment": "preprint", "summary": "Context: i* is one of the most influential languages in the Requirements Engineering research community. Perhaps due to its complexity and low adoption in industry, it became a natural candidate for studies aiming at improving its concrete syntax and the stakeholders' ability to correctly interpret i* models.\n  Objectives: We evaluate the impact of semantic transparency on understanding and reviewing i* models, in the presence of a language key. Methods: We performed a quasi-experiment comparing the standard i* concrete syntax with an alternative that has an increased semantic transparency. We asked 57 novice participants to perform understanding and reviewing tasks on i* models, and measured their accuracy, speed and ease, using metrics of task success, time and effort, collected with eye-tracking and participants' feedback.\n  Results: We found no evidence of improved accuracy or speed attributable to the alternative concrete syntax. Although participants' perceived ease was similar, they devoted significantly less visual effort to the model and the provided language key, when using the alternative concrete syntax.\n  Conclusions: The context provided by the model and language key may mitigate the i* symbol recognition deficit reported in previous works. However, the alternative concrete syntax required a significantly lower visual effort.", "AI": {"tldr": "\u589e\u5f3a\u8bed\u4e49\u900f\u660e\u7684i*\u8bed\u6cd5\u5728\u51c6\u786e\u7387\u3001\u901f\u5ea6\u548c\u6613\u7528\u6027\u65e0\u663e\u8457\u63d0\u5347\uff0c\u4f46\u80fd\u663e\u8457\u51cf\u5c11\u89c6\u89c9\u5de5\u4f5c\u91cf\uff0c\u6a21\u578b\u4e0a\u4e0b\u6587\u548c\u8bed\u8a00\u8bf4\u660e\u80fd\u5e2e\u52a9\u7406\u89e3\u7b26\u53f7\u3002", "motivation": "i*\u8bed\u8a00\u867d\u7136\u5728\u9700\u6c42\u5de5\u7a0b\u9886\u57df\u5f88\u6709\u5f71\u54cd\u529b\uff0c\u4f46\u56e0\u5176\u590d\u6742\u6027\u548c\u884c\u4e1a\u91c7\u7528\u7387\u4f4e\uff0c\u5bfc\u81f4\u7814\u7a76\u8005\u5173\u6ce8\u63d0\u5347\u5176\u5177\u4f53\u8bed\u6cd5\u53ca\u7528\u6237\u5bf9\u6a21\u578b\u7684\u7406\u89e3\u80fd\u529b\u3002", "method": "\u91c7\u7528\u51c6\u5b9e\u9a8c\u7684\u65b9\u6cd5\uff0c\u5c06\u6807\u51c6i*\u8bed\u6cd5\u4e0e\u589e\u5f3a\u8bed\u4e49\u900f\u660e\u6027\u7684\u66ff\u4ee3\u8bed\u6cd5\u8fdb\u884c\u5bf9\u6bd4\uff0c\u9080\u8bf757\u540d\u65b0\u624b\u53c2\u4e0e\u6a21\u578b\u7406\u89e3\u4e0e\u5ba1\u67e5\u4efb\u52a1\uff0c\u901a\u8fc7\u4efb\u52a1\u6210\u529f\u7387\u3001\u65f6\u95f4\u3001\u5de5\u4f5c\u91cf\uff08\u7ed3\u5408\u773c\u52a8\u4eea\u548c\u53cd\u9988\uff09\u6765\u6d4b\u91cf\u8868\u73b0\u3002", "result": "\u672a\u53d1\u73b0\u66ff\u4ee3\u8bed\u6cd5\u5728\u51c6\u786e\u5ea6\u6216\u901f\u5ea6\u4e0a\u4f18\u4e8e\u6807\u51c6\u8bed\u6cd5\u3002\u4e24\u8005\u5728\u6613\u7528\u6027\u8ba4\u77e5\u4e0a\u4e5f\u76f8\u8fd1\uff0c\u4f46\u7528\u66ff\u4ee3\u8bed\u6cd5\u65f6\uff0c\u53c2\u4e0e\u8005\u5728\u6a21\u578b\u548c\u8bed\u8a00\u8bf4\u660e\u4e0a\u7684\u89c6\u89c9\u8017\u8d39\u663e\u8457\u8f83\u5c11\u3002", "conclusion": "\u6a21\u578b\u548c\u8bed\u8a00\u8bf4\u660e\u7684\u4e0a\u4e0b\u6587\u53ef\u51cf\u5f31i*\u7b26\u53f7\u8bc6\u522b\u7684\u969c\u788d\u3002\u867d\u7136\u51c6\u786e\u5ea6\u548c\u901f\u5ea6\u65e0\u63d0\u5347\uff0c\u4f46\u66ff\u4ee3\u8bed\u6cd5\u660e\u663e\u51cf\u5c11\u4e86\u89c6\u89c9\u52aa\u529b\u3002"}}
{"id": "2511.05759", "categories": ["cs.CL", "cs.AI", "cs.FL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05759", "abs": "https://arxiv.org/abs/2511.05759", "authors": ["Marcelo Arenas", "Pablo Barcel\u00f3", "Luis Cofr\u00e9", "Alexander Kozachinskiy"], "title": "Language Generation: Complexity Barriers and Implications for Learning", "comment": null, "summary": "Kleinberg and Mullainathan showed that, in principle, language generation is always possible: with sufficiently many positive examples, a learner can eventually produce sentences indistinguishable from those of a target language. However, the existence of such a guarantee does not speak to its practical feasibility. In this work, we show that even for simple and well-studied language families -- such as regular and context-free languages -- the number of examples required for successful generation can be extraordinarily large, and in some cases not bounded by any computable function. These results reveal a substantial gap between theoretical possibility and efficient learnability. They suggest that explaining the empirical success of modern language models requires a refined perspective -- one that takes into account structural properties of natural language that make effective generation possible in practice.", "AI": {"tldr": "\u867d\u7136\u7406\u8bba\u8bc1\u660e\u8bed\u8a00\u751f\u6210\u53ef\u884c\uff0c\u4f46\u6210\u529f\u751f\u6210\u9700\u8981\u7684\u4f8b\u5b50\u6570\u91cf\u5728\u5b9e\u9645\u4e2d\u53ef\u80fd\u6781\u5927\uff0c\u5b9e\u8df5\u4e2d\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u9ad8\u6548\u6027\u7684\u89e3\u91ca\u9700\u66f4\u7ec6\u81f4\u5730\u8003\u8651\u81ea\u7136\u8bed\u8a00\u7684\u7ed3\u6784\u7279\u6027\u3002", "motivation": "\u524d\u4eba\u8bc1\u660e\u4e86\u53ea\u8981\u6709\u8db3\u591f\u591a\u6b63\u4f8b\uff0c\u5b66\u4e60\u8005\u53ef\u4ee5\u65e0\u9650\u63a5\u8fd1\u76ee\u6807\u8bed\u8a00\uff0c\u4f46\u8be5\u7406\u8bba\u672a\u8ba8\u8bba\u5b9e\u9645\u53ef\u884c\u6027\u3002\u672c\u6587\u65e8\u5728\u5206\u6790\u5728\u5b9e\u9645\u5df2\u77e5\u8bed\u8a00\u5bb6\u65cf\u4e2d\u751f\u6210\u76ee\u6807\u8bed\u8a00\u6240\u9700\u4f8b\u5b50\u7684\u5b9e\u9645\u9700\u6c42\uff0c\u8bc4\u4f30\u7406\u8bba\u4e0e\u5b9e\u8df5\u95f4\u7684\u9e3f\u6c9f\u3002", "method": "\u5206\u6790\u6b63\u5219\u8bed\u8a00\u548c\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u8a00\u7b49\u7b80\u5355\u8bed\u8a00\u5bb6\u65cf\uff0c\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\uff0c\u8bc4\u4f30\u5b9e\u9645\u6210\u529f\u751f\u6210\u6240\u9700\u793a\u4f8b\u6570\u91cf\u7684\u4e0b\u754c\u3002", "result": "\u53d1\u73b0\u5373\u4f7f\u5bf9\u4e8e\u5df2\u7ecf\u88ab\u5145\u5206\u7814\u7a76\u7684\u8bed\u8a00\u5bb6\u65cf\uff0c\u6240\u9700\u7684\u4f8b\u5b50\u6570\u76ee\u53ef\u80fd\u6781\u5927\uff0c\u751a\u81f3\u4e0d\u53ef\u901a\u8fc7\u4efb\u4f55\u53ef\u8ba1\u7b97\u51fd\u6570\u8fdb\u884c\u754c\u5b9a\u3002\u8fd9\u663e\u793a\u4e86\u7406\u8bba\u53ef\u751f\u6210\u6027\u4e0e\u5b9e\u9645\u9ad8\u6548\u5b66\u4e60\u4e4b\u95f4\u7684\u5de8\u5927\u5206\u6b67\u3002", "conclusion": "\u7406\u8bba\u4e0a\uff0c\u8bed\u8a00\u751f\u6210\u603b\u662f\u53ef\u80fd\u7684\uff0c\u4f46\u8981\u6210\u529f\u751f\u6210\u6240\u9700\u7684\u6b63\u4f8b\u6570\u91cf\u5728\u5b9e\u9645\u4e2d\u53ef\u80fd\u6781\u5927\uff0c\u751a\u81f3\u65e0\u6cd5\u901a\u8fc7\u4efb\u4e00\u53ef\u8ba1\u7b97\u51fd\u6570\u754c\u5b9a\u3002\u7406\u8bba\u7684\u53ef\u80fd\u6027\u4e0e\u9ad8\u6548\u7684\u53ef\u5b66\u4e60\u6027\u4e4b\u95f4\u5b58\u5728\u5de8\u5927\u5dee\u8ddd\u3002"}}
{"id": "2511.06149", "categories": ["cs.SE", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.06149", "abs": "https://arxiv.org/abs/2511.06149", "authors": ["Dominique Briechle", "Mohammed Fahad Ali", "Marit Briechle-Mathiszig", "Tobias Geger", "Robert Werner", "Andreas Rausch"], "title": "The Lifecycle Workbench - A Configurable Framework for Digitized Product Maintenance Services", "comment": "This preprint has not undergone peer review or any post-submission improvements or corrections. Published at ECSA 2025 Tracks and Workshops", "summary": "The global production of electric goods is at an all-time high, causing negative environmental and health impacts as well as a continuing depletion of natural resources. Considering the worsening global climate change, a transition of current industrial processes is necessary to tackle the above-mentioned factors. To address this urgent issue, socio-economic systems like the Circular Economy (CE) provide options to reallocate the use of resources and products on a global scale. Especially in terms of product lifecycle-prolonging, this system provides suitable approaches to alter the current modes of product handling by society and industry alike, based on the condition of the products. Although the importance and benefits of sustainable services enabling these options are widely known, users tend to shy away from using them. One of the reasons is the missing reliability in terms of the knowledge of the costs associated with a particular service. This uncertainty in expected pricing can, therefore, lower the willingness of potential clients. However, not only clients struggle with the boundary conditions of such services. On the part of the potential providers of services, the monetary risk is often caused by the incapability to detect the condition of a product in advance. This can result on the provider side in a severe economic loss if this possibility is not covered by the service price or through the mass of items, which could allow equalization of serval service operations. To address these weak points in current service execution, the authors propose the \\textit{Lifecycle Workbench (LCW)}-ecosystem, which features digital representations to enhance the reliability of service pricing as well as the assessment of the condition of items, assemblies, and parts in the Circular Economy domain.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5faa\u73af\u7ecf\u6d4e\u670d\u52a1\u56e0\u5b9a\u4ef7\u4e0e\u4ea7\u54c1\u72b6\u51b5\u8bc4\u4f30\u4e0d\u786e\u5b9a\u5bfc\u81f4\u7684\u7528\u6237\u4e0e\u670d\u52a1\u5546\u98ce\u9669\uff0c\u63d0\u51faLCW\u6570\u5b57\u751f\u6001\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u670d\u52a1\u53ef\u9760\u6027\u4e0e\u7ecf\u6d4e\u6548\u76ca\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u5faa\u73af\u7ecf\u6d4e\u8f6c\u578b\u3002", "motivation": "\u5168\u7403\u7535\u5b50\u4ea7\u54c1\u751f\u4ea7\u9020\u6210\u73af\u5883\u5065\u5eb7\u5f71\u54cd\u548c\u8d44\u6e90\u67af\u7aed\uff0c\u5f53\u524d\u5de5\u4e1a\u6d41\u7a0b\u9700\u8f6c\u578b\u4ee5\u5e94\u5bf9\u6c14\u5019\u53d8\u5316\u3002\u5faa\u73af\u7ecf\u6d4e\uff08CE\uff09\u4f5c\u4e3a\u4e00\u79cd\u793e\u4f1a\u7ecf\u6d4e\u7cfb\u7edf\uff0c\u80fd\u5728\u5168\u7403\u8303\u56f4\u4e0a\u91cd\u65b0\u914d\u7f6e\u8d44\u6e90\u548c\u4ea7\u54c1\u4f7f\u7528\uff0c\u5c24\u5176\u5728\u5ef6\u957f\u4ea7\u54c1\u751f\u547d\u5468\u671f\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002\u7136\u800c\uff0c\u5c3d\u7ba1\u76f8\u5173\u53ef\u6301\u7eed\u670d\u52a1\u88ab\u666e\u904d\u8ba4\u77e5\uff0c\u5176\u4f7f\u7528\u7387\u4e0d\u9ad8\uff0c\u4e3b\u8981\u539f\u56e0\u4e4b\u4e00\u662f\u670d\u52a1\u5b9a\u4ef7\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5f71\u54cd\u7528\u6237\u548c\u670d\u52a1\u63d0\u4f9b\u5546\u7684\u610f\u613f\u548c\u5229\u76ca\u3002", "method": "\u63d0\u51faLifecycle Workbench (LCW)\u751f\u6001\u7cfb\u7edf\uff0c\u91c7\u7528\u6570\u5b57\u5316\u624b\u6bb5\u5b9e\u73b0\u670d\u52a1\u5b9a\u4ef7\u53ef\u9760\u6027\u548c\u4ea7\u54c1\u72b6\u6001\u8bc4\u4f30\u3002\u5177\u4f53\u65b9\u6cd5\u662f\u901a\u8fc7\u6570\u5b57\u5316\u8868\u793a\u7269\u54c1\u3001\u90e8\u4ef6\u7b49\uff0c\u4ee5\u652f\u6301\u5faa\u73af\u7ecf\u6d4e\u9886\u57df\u7684\u670d\u52a1\u6d41\u7a0b\u3002", "result": "LCW\u751f\u6001\u7cfb\u7edf\u80fd\u591f\u63d0\u5347\u4ea7\u54c1\u72b6\u6001\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u53ca\u670d\u52a1\u5b9a\u4ef7\u7684\u53ef\u9760\u6027\uff0c\u4ece\u800c\u964d\u4f4e\u7528\u6237\u548c\u670d\u52a1\u5546\u7684\u7ecf\u6d4e\u98ce\u9669\uff0c\u4fc3\u8fdb\u5faa\u73af\u7ecf\u6d4e\u76f8\u5173\u670d\u52a1\u7684\u4f7f\u7528\u3002", "conclusion": "\u901a\u8fc7LCW\u751f\u6001\u7cfb\u7edf\uff0c\u53ef\u4e3a\u5faa\u73af\u7ecf\u6d4e\u76f8\u5173\u670d\u52a1\u63d0\u4f9b\u66f4\u9ad8\u7684\u53ef\u9760\u6027\u548c\u7ecf\u6d4e\u53ef\u884c\u6027\uff0c\u7f13\u89e3\u5f53\u524d\u56e0\u5b9a\u4ef7\u548c\u7269\u54c1\u72b6\u6001\u4e0d\u786e\u5b9a\u5bfc\u81f4\u7684\u670d\u52a1\u91c7\u7eb3\u56f0\u96be\u4e0e\u98ce\u9669\u3002"}}
{"id": "2511.05784", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05784", "abs": "https://arxiv.org/abs/2511.05784", "authors": ["Yaxuan Wang", "Chris Yuhao Liu", "Quan Liu", "Jinglong Pang", "Wei Wei", "Yujia Bao", "Yang Liu"], "title": "DRAGON: Guard LLM Unlearning in Context via Negative Detection and Reasoning", "comment": "Please refer to the NeurIPS 2025 submission: https://openreview.net/forum?id=FNuul0hlin; The paper has been accepted to the ICML 2025 MUGen Workshop: https://openreview.net/forum?id=ET24oKP23c", "summary": "Unlearning in Large Language Models (LLMs) is crucial for protecting private data and removing harmful knowledge. Most existing approaches rely on fine-tuning to balance unlearning efficiency with general language capabilities. However, these methods typically require training or access to retain data, which is often unavailable in real world scenarios. Although these methods can perform well when both forget and retain data are available, few works have demonstrated equivalent capability in more practical, data-limited scenarios. To overcome these limitations, we propose Detect-Reasoning Augmented GeneratiON (DRAGON), a systematic, reasoning-based framework that utilizes in-context chain-of-thought (CoT) instructions to guard deployed LLMs before inference. Instead of modifying the base model, DRAGON leverages the inherent instruction-following ability of LLMs and introduces a lightweight detection module to identify forget-worthy prompts without any retain data. These are then routed through a dedicated CoT guard model to enforce safe and accurate in-context intervention. To robustly evaluate unlearning performance, we introduce novel metrics for unlearning performance and the continual unlearning setting. Extensive experiments across three representative unlearning tasks validate the effectiveness of DRAGON, demonstrating its strong unlearning capability, scalability, and applicability in practical scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DRAGON\u65b9\u6cd5\uff0c\u65e0\u9700\u4fdd\u7559\u6570\u636e\u5373\u53ef\u9ad8\u6548\u5b9e\u73b0LLM\u7684\u9057\u5fd8\u529f\u80fd\uff0c\u901a\u8fc7\u68c0\u6d4b\u4e0e\u94fe\u5f0f\u63a8\u7406\u5e72\u9884\u63d0\u5347\u6a21\u578b\u5b89\u5168\u6027\uff0c\u5e76\u8bbe\u8ba1\u4e86\u65b0\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u4ef7\u503c\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9057\u5fd8\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u5fae\u8c03\uff0c\u9700\u540c\u65f6\u83b7\u53d6\u4fdd\u7559\uff08retain\uff09\u548c\u9057\u5fd8\uff08forget\uff09\u6570\u636e\uff0c\u800c\u5b9e\u9645\u573a\u666f\u4e0b\u4fdd\u7559\u6570\u636e\u7ecf\u5e38\u7f3a\u5931\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5e94\u5bf9\u6570\u636e\u53d7\u9650\u7684\u73b0\u5b9e\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86Detect-Reasoning Augmented GeneratiON\uff08DRAGON\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u4e2d\u7684\u94fe\u5f0f\u63a8\u7406\u6307\u4ee4\uff08CoT instructions\uff09\u6765\u4fdd\u62a4LLM\u514d\u906d\u4e0d\u826f\u77e5\u8bc6\u89e6\u53d1\u3002\u8be5\u65b9\u6cd5\u4e0d\u9700\u4fee\u6539\u73b0\u6709\u6a21\u578b\uff0c\u5229\u7528LLM\u7684\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\uff0c\u5e76\u589e\u8bbe\u68c0\u6d4b\u6a21\u5757\u6765\u8bc6\u522b\u9700\u8981\u9057\u5fd8\u7684\u63d0\u793a\uff08prompts\uff09\uff0c\u5bf9\u4e8e\u8fd9\u4e9b\u63d0\u793a\uff0c\u901a\u8fc7\u4e13\u95e8\u7684CoT guard\u6a21\u578b\u8fdb\u884c\u5e72\u9884\uff0c\u65e0\u9700\u4fdd\u7559\u6570\u636e\u3002", "result": "DRAGON\u6846\u67b6\u5728\u4e09\u4e2a\u4ee3\u8868\u6027\u9057\u5fd8\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u65e0\u9700\u4fdd\u7559\u6570\u636e\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u9057\u5fd8\u80fd\u529b\u3001\u53ef\u6269\u5c55\u6027\u53ca\u5b9e\u9645\u5e94\u7528\u9002\u5e94\u6027\u3002\u540c\u65f6\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u7528\u4e8e\u6301\u7eed\u6027\u9057\u5fd8\u7684\u65b0\u8bc4\u4f30\u6307\u6807\uff0c\u589e\u5f3a\u4e86\u8bc4\u6d4b\u7684\u5168\u9762\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "DRAGON\u662f\u4e00\u79cd\u65e0\u9700\u4fdd\u7559\u6570\u636e\u7684\u3001\u9ad8\u6548\u53ef\u63a8\u5e7f\u7684\u5927\u8bed\u8a00\u6a21\u578b\u9057\u5fd8\u6846\u67b6\uff0c\u5b83\u5f3a\u5316\u4e86\u6a21\u578b\u5728\u5b9e\u9645\u6570\u636e\u6709\u9650\u60c5\u51b5\u4e0b\u7684\u654f\u611f\u77e5\u8bc6\u9057\u5fd8\u80fd\u529b\uff0c\u5bf9LLM\u5b89\u5168\u548c\u9690\u79c1\u4fdd\u62a4\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.06186", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.06186", "abs": "https://arxiv.org/abs/2511.06186", "authors": ["Lakshmi Priya Bodepudi", "Yutong Zhao", "Ming Quan Fu", "Yuanyuan Wu", "Sen He", "Yu Zhao"], "title": "Diagnosing and Resolving Android Applications Building Issues: An Empirical Study", "comment": "11 pages", "summary": "Building Android applications reliably remains a persistent challenge due to complex dependencies, diverse configurations, and the rapid evolution of the Android ecosystem. This study conducts an empirical analysis of 200 open-source Android projects written in Java and Kotlin to diagnose and resolve build failures. Through a five-phase process encompassing data collection, build execution, failure classification, repair strategy design, and LLM-assisted evaluation, we identified four primary types of build errors: environment issues, dependency and Gradle task errors, configuration problems, and syntax/API incompatibilities. Among the 135 projects that initially failed to build, our diagnostic and repair strategy enabled developers to resolve 102 cases (75.56%), significantly reducing troubleshooting effort. We further examined the potential of Large Language Models, such as GPT-5, to assist in error diagnosis, achieving a 53.3% success rate in suggesting viable fixes. An analysis of project attributes revealed that build success is influenced by programming language, project age, and app size. These findings provide practical insights into improving Android build reliability and advancing AI-assisted software maintenance.", "AI": {"tldr": "\u9488\u5bf9Android\u6784\u5efa\u9ad8\u5931\u8d25\u95ee\u9898\uff0c\u5b9e\u8bc1\u5206\u6790\u53d1\u73b0\u4fee\u590d\u7b56\u7565\u6709\u6548\u63d0\u5347\u6210\u529f\u7387\uff0cAI\uff08\u5982GPT-5\uff09\u80fd\u8f85\u52a9\u4fee\u590d\uff0c\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u4e0e\u5bf9\u5f71\u54cd\u56e0\u7d20\u7684\u5206\u6790\u3002", "motivation": "Android\u5e94\u7528\u6784\u5efa\u8fc7\u7a0b\u56e0\u4f9d\u8d56\u590d\u6742\u3001\u914d\u7f6e\u591a\u6837\u53ca\u751f\u6001\u53d8\u5316\u5feb\u800c\u9762\u4e34\u9ad8\u5931\u8d25\u7387\uff0c\u4e9f\u9700\u6709\u6548\u8bca\u65ad\u548c\u4fee\u590d\u65b9\u6848\u3002", "method": "\u5bf9200\u4e2a\u5f00\u6e90Android\u9879\u76ee\uff08Java\u548cKotlin\uff09\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u5305\u62ec\u6570\u636e\u6536\u96c6\u3001\u6784\u5efa\u6267\u884c\u3001\u6545\u969c\u5206\u7c7b\u3001\u4fee\u590d\u7b56\u7565\u8bbe\u8ba1\uff0c\u4ee5\u53ca\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u8bc4\u4f30\u5171\u4e94\u4e2a\u9636\u6bb5\u3002", "result": "\u521d\u6b21\u6784\u5efa\u5931\u8d25\u7684135\u4e2a\u9879\u76ee\u4e2d\uff0c\u901a\u8fc7\u8bca\u65ad\u548c\u4fee\u590d\u7b56\u7565\u6210\u529f\u89e3\u51b3\u4e86102\u4e2a\uff08\u536075.56%\uff09\u3002\u4f7f\u7528\u5927\u6a21\u578b\u8f85\u52a9\u4fee\u590d\u5b9e\u73b053.3%\u7684\u6210\u529f\u5efa\u8bae\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u8bca\u65ad\u4e0e\u4fee\u590d\u7b56\u7565\u6709\u6548\u63d0\u5347\u4e86Android\u9879\u76ee\u6784\u5efa\u7684\u6210\u529f\u7387\uff0cAI\u8f85\u52a9\u5177\u6709\u5b9e\u9645\u5e94\u7528\u524d\u666f\u3002\u540c\u65f6\u53d1\u73b0\u7f16\u7a0b\u8bed\u8a00\u3001\u9879\u76ee\u5e74\u9f84\u3001\u5e94\u7528\u89c4\u6a21\u5f71\u54cd\u6784\u5efa\u6210\u529f\u3002"}}
{"id": "2511.05852", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05852", "abs": "https://arxiv.org/abs/2511.05852", "authors": ["Yinjie Cheng", "Paul Youssef", "Christin Seifert", "J\u00f6rg Schl\u00f6tterer", "Zhixue Zhao"], "title": "Quantifying Edits Decay in Fine-tuned LLMs", "comment": "Under review at ICLR 2026", "summary": "Knowledge editing has emerged as a lightweight alternative to retraining for correcting or injecting specific facts in large language models (LLMs). Meanwhile, fine-tuning remains the default operation for adapting LLMs to new domains and tasks. Despite their widespread adoption, these two post-training interventions have been studied in isolation, leaving open a crucial question: if we fine-tune an edited model, do the edits survive? This question is motivated by two practical scenarios: removing covert or malicious edits, and preserving beneficial edits. If fine-tuning impairs edits as shown in Figure 1, current KE methods become less useful, as every fine-tuned model would require re-editing, which significantly increases the cost; if edits persist, fine-tuned models risk propagating hidden malicious edits, raising serious safety concerns. To this end, we systematically quantify edits decay after fine-tuning, investigating how fine-tuning affects knowledge editing. We evaluate two state-of-the-art editing methods (MEMIT, AlphaEdit) and three fine-tuning approaches (full-parameter, LoRA, DoRA) across five LLMs and three datasets, yielding 232 experimental configurations. Our results show that edits decay after fine-tuning, with survival varying across configurations, e.g., AlphaEdit edits decay more than MEMIT edits. Further, we propose selective-layer fine-tuning and find that fine-tuning edited layers only can effectively remove edits, though at a slight cost to downstream performance. Surprisingly, fine-tuning non-edited layers impairs more edits than full fine-tuning. Overall, our study establishes empirical baselines and actionable strategies for integrating knowledge editing with fine-tuning, and underscores that evaluating model editing requires considering the full LLM application pipeline.", "AI": {"tldr": "\u77e5\u8bc6\u7f16\u8f91\u540e\u7684\u6a21\u578b\u518d\u8fdb\u884c\u5fae\u8c03\uff0c\u7f16\u8f91\u5185\u5bb9\u901a\u5e38\u4f1a\u53d7\u5f71\u54cd\u800c\u8870\u51cf\uff0c\u5177\u4f53\u7a0b\u5ea6\u56e0\u65b9\u6cd5\u548c\u5fae\u8c03\u65b9\u5f0f\u800c\u5f02\u3002\u9488\u5bf9\u7f16\u8f91\u5b89\u5168\u6027\u548c\u6709\u6548\u6027\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u53ef\u64cd\u4f5c\u65b9\u6848\uff0c\u5e76\u5efa\u8bae\u8bc4\u4f30\u6a21\u578b\u7f16\u8f91\u65f6\u8981\u7ed3\u5408\u5b9e\u9645\u5e94\u7528\u5168\u6d41\u7a0b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5e94\u7528\u4e2d\u5e38\u5e38\u9700\u8981\u7ea0\u6b63\u6216\u6ce8\u5165\u7279\u5b9a\u77e5\u8bc6\uff0c\u77e5\u8bc6\u7f16\u8f91\uff08KE\uff09\u4f5c\u4e3a\u4e00\u79cd\u8f7b\u91cf\u65b9\u6cd5\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u4e0e\u5fae\u8c03\uff08fine-tuning\uff09\u901a\u5e38\u5404\u81ea\u72ec\u7acb\u8fdb\u884c\u3002\u4e00\u4e2a\u5173\u952e\u95ee\u9898\u662f\uff1a\u5728\u77e5\u8bc6\u7f16\u8f91\u540e\u518d\u5fae\u8c03\uff0c\u7f16\u8f91\u5185\u5bb9\u80fd\u5426\u88ab\u4fdd\u7559\uff1f\u6b64\u95ee\u9898\u5173\u4e4e\u5b9e\u9645\u5e94\u7528\u4e2d\u79fb\u9664\u6076\u610f\u7f16\u8f91\u548c\u4fdd\u7559\u6709\u76ca\u7f16\u8f91\u7684\u53ef\u884c\u6027\u4e0e\u5b89\u5168\u6027\u3002", "method": "\u8be5\u7814\u7a76\u7cfb\u7edf\u5730\u91cf\u5316\u4e86\u77e5\u8bc6\u7f16\u8f91\u5728\u5fae\u8c03\u540e\u7684\u8870\u51cf\u60c5\u51b5\uff0c\u8bc4\u4f30\u4e86\u4e24\u79cd\u4e3b\u6d41\u77e5\u8bc6\u7f16\u8f91\u65b9\u6cd5\uff08MEMIT\u3001AlphaEdit\uff09\u4e0e\u4e09\u79cd\u5fae\u8c03\u65b9\u6cd5\uff08\u5168\u53c2\u6570\u3001LoRA\u3001DoRA\uff09\uff0c\u5206\u522b\u5728\u4e94\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u505a\u4e86232\u79cd\u5b9e\u9a8c\u914d\u7f6e\u3002\u5e76\u63d0\u51fa\u9009\u62e9\u6027\u5c42\u5fae\u8c03\u65b9\u6cd5\uff0c\u53ea\u5fae\u8c03\u88ab\u7f16\u8f91\u7684\u5c42\u6216\u975e\u7f16\u8f91\u5c42\u3002", "result": "\u7ed3\u679c\u53d1\u73b0\uff0c\u77e5\u8bc6\u7f16\u8f91\u4e00\u822c\u5728\u5fae\u8c03\u540e\u4f1a\u53d1\u751f\u8870\u51cf\uff0c\u4e0d\u540c\u65b9\u6cd5\u751f\u5b58\u7387\u4e0d\u540c\uff0c\u5982AlphaEdit\u7684\u8870\u51cf\u6bd4MEMIT\u66f4\u660e\u663e\u3002\u9009\u62e9\u6027\u5c42\u5fae\u8c03\u53ef\u6709\u6548\u79fb\u9664\u7f16\u8f91\uff0c\u4e14\u53ea\u5fae\u8c03\u975e\u7f16\u8f91\u5c42\u65f6\u6bd4\u5168\u53c2\u6570\u5fae\u8c03\u8870\u51cf\u66f4\u5927\uff0c\u4f46\u4f1a\u7565\u5fae\u5f71\u54cd\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u5efa\u7acb\u4e86\u77e5\u8bc6\u7f16\u8f91\u4e0e\u5fae\u8c03\u7ed3\u5408\u7684\u5b9e\u8bc1\u57fa\u7ebf\u4e0e\u5b9e\u65bd\u7b56\u7565\uff0c\u5f3a\u8c03\u5728\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7f16\u8f91\u6548\u679c\u65f6\u9700\u8003\u8651\u5b8c\u6574\u7684\u5e94\u7528\u6d41\u7a0b\u3002"}}
{"id": "2511.06227", "categories": ["cs.SE", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2511.06227", "abs": "https://arxiv.org/abs/2511.06227", "authors": ["Anamul Haque Mollah", "Ahmed Aljohani", "Hyunsook Do"], "title": "Assertion-Aware Test Code Summarization with Large Language Models", "comment": "Accepted for publication at 2nd ACM International Conference on AI-powered Software (AIware 2025)", "summary": "Unit tests often lack concise summaries that convey test intent, especially in auto-generated or poorly documented codebases. Large Language Models (LLMs) offer a promising solution, but their effectiveness depends heavily on how they are prompted. Unlike generic code summarization, test-code summarization poses distinct challenges because test methods validate expected behavior through assertions rather than im- plementing functionality. This paper presents a new benchmark of 91 real-world Java test cases paired with developer-written summaries and conducts a controlled ablation study to investigate how test code-related components-such as the method under test (MUT), assertion messages, and assertion semantics-affect the performance of LLM-generated test summaries. We evaluate four code LLMs (Codex, Codestral, DeepSeek, and Qwen-Coder) across seven prompt configurations using n-gram metrics (BLEU, ROUGE-L, METEOR), semantic similarity (BERTScore), and LLM-based evaluation. Results show that prompting with as- sertion semantics improves summary quality by an average of 0.10 points (2.3%) over full MUT context (4.45 vs. 4.35) while requiring fewer input tokens. Codex and Qwen-Coder achieve the highest alignment with human-written summaries, while DeepSeek underperforms despite high lexical overlap. The replication package is publicly available at https://doi.org/10. 5281/zenodo.17067550", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6784\u5efa\u6d4b\u8bd5\u4ee3\u7801\u6458\u8981\u57fa\u51c6\uff0c\u7cfb\u7edf\u7814\u7a76\u4e86\u4e0d\u540c\u63d0\u793a\u4fe1\u606f\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6d4b\u8bd5\u6458\u8981\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5f3a\u8c03\u65ad\u8a00\u8bed\u4e49\u80fd\u6700\u4f73\u63d0\u5347\u6458\u8981\u8d28\u91cf\uff0c\u5e76\u5728\u591a\u79cd\u6a21\u578b\u548c\u8bc4\u4ef7\u65b9\u6cd5\u4e0b\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u5355\u5143\u6d4b\u8bd5\u4ee3\u7801\u5e38\u5e38\u7f3a\u4e4f\u8868\u8fbe\u6d4b\u8bd5\u610f\u56fe\u7684\u7b80\u6d01\u6458\u8981\uff0c\u7279\u522b\u662f\u5728\u81ea\u52a8\u751f\u6210\u6216\u7f3a\u4e4f\u6587\u6863\u7684\u4ee3\u7801\u5e93\u4e2d\u3002\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u6709\u671b\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f46\u5176\u751f\u6210\u6458\u8981\u7684\u6548\u679c\u53d7\u63d0\u793a\u65b9\u5f0f\u5f71\u54cd\u8f83\u5927\u3002\u4e0e\u901a\u7528\u4ee3\u7801\u6458\u8981\u4e0d\u540c\uff0c\u6d4b\u8bd5\u4ee3\u7801\u6458\u8981\u6709\u5176\u72ec\u7279\u6311\u6218\uff0c\u56e0\u4e3a\u6d4b\u8bd5\u65b9\u6cd5\u4fa7\u91cd\u4e8e\u9a8c\u8bc1\u9884\u671f\u884c\u4e3a\u800c\u4e0d\u662f\u5b9e\u73b0\u529f\u80fd\u3002", "method": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b91\u4e2a\u771f\u5b9eJava\u6d4b\u8bd5\u7528\u4f8b\u53ca\u5f00\u53d1\u8005\u64b0\u5199\u6458\u8981\u7684\u65b0\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u8bbe\u8ba1\u53d7\u63a7\u6d88\u878d\u5b9e\u9a8c\uff0c\u63a2\u7a76\u4e0e\u6d4b\u8bd5\u4ee3\u7801\u76f8\u5173\u7684\u7ec4\u4ef6\uff08\u5982\u88ab\u6d4b\u65b9\u6cd5\u3001\u65ad\u8a00\u4fe1\u606f\u3001\u65ad\u8a00\u8bed\u4e49\uff09\u5bf9LLM\u751f\u6210\u6d4b\u8bd5\u6458\u8981\u6027\u80fd\u7684\u5f71\u54cd\u3002\u7814\u7a76\u8bc4\u4f30\u4e86\u56db\u4e2a\u4ee3\u7801LLM\uff08Codex\u3001Codestral\u3001DeepSeek\u3001Qwen-Coder\uff09\uff0c\u901a\u8fc7\u4e03\u79cd\u63d0\u793a\u914d\u7f6e\uff0c\u4f7f\u7528n-gram\u6307\u6807\uff08BLEU\u3001ROUGE-L\u3001METEOR\uff09\u3001\u8bed\u4e49\u76f8\u4f3c\u5ea6\uff08BERTScore\uff09\u548c\u57fa\u4e8eLLM\u7684\u4e3b\u89c2\u8bc4\u4f30\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528\u65ad\u8a00\u8bed\u4e49\u4f5c\u4e3a\u63d0\u793a\u53ef\u4f7f\u6458\u8981\u8d28\u91cf\u5e73\u5747\u63d0\u53470.10\u5206\uff082.3%\uff09\uff0c\u4e14\u6240\u9700\u8f93\u5165token\u66f4\u5c11\u3002Codex\u548cQwen-Coder\u751f\u6210\u7684\u6458\u8981\u4e0e\u4eba\u7c7b\u7f16\u5199\u7684\u6458\u8981\u6700\u4e3a\u4e00\u81f4\uff1bDeepSeek\u5c3d\u7ba1\u8bcd\u6c47\u91cd\u5408\u5ea6\u9ad8\uff0c\u5374\u8868\u73b0\u8f83\u5dee\u3002", "conclusion": "\u9488\u5bf9\u6d4b\u8bd5\u4ee3\u7801\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u63d0\u793a\u80fd\u591f\u660e\u663e\u63d0\u5347LLM\u751f\u6210\u6458\u8981\u7684\u8d28\u91cf\uff0c\u5c24\u5176\u662f\u65ad\u8a00\u8bed\u4e49\u5bf9\u63d0\u5347\u6548\u679c\u6700\u4e3a\u663e\u8457\u3002"}}
{"id": "2511.05901", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05901", "abs": "https://arxiv.org/abs/2511.05901", "authors": ["Rui Yang", "Matthew Yu Heng Wong", "Huitao Li", "Xin Li", "Wentao Zhu", "Jingchi Liao", "Kunyu Yu", "Jonathan Chong Kai Liew", "Weihao Xuan", "Yingjian Chen", "Yuhe Ke", "Jasmine Chiat Ling Ong", "Douglas Teodoro", "Chuan Hong", "Daniel Shi Wei Ting", "Nan Liu"], "title": "Retrieval-Augmented Generation in Medicine: A Scoping Review of Technical Implementations, Clinical Applications, and Ethical Considerations", "comment": null, "summary": "The rapid growth of medical knowledge and increasing complexity of clinical practice pose challenges. In this context, large language models (LLMs) have demonstrated value; however, inherent limitations remain. Retrieval-augmented generation (RAG) technologies show potential to enhance their clinical applicability. This study reviewed RAG applications in medicine. We found that research primarily relied on publicly available data, with limited application in private data. For retrieval, approaches commonly relied on English-centric embedding models, while LLMs were mostly generic, with limited use of medical-specific LLMs. For evaluation, automated metrics evaluated generation quality and task performance, whereas human evaluation focused on accuracy, completeness, relevance, and fluency, with insufficient attention to bias and safety. RAG applications were concentrated on question answering, report generation, text summarization, and information extraction. Overall, medical RAG remains at an early stage, requiring advances in clinical validation, cross-linguistic adaptation, and support for low-resource settings to enable trustworthy and responsible global use.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86RAG\u6280\u672f\u5728\u533b\u5b66\u9886\u57df\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u5927\u591a\u4f9d\u8d56\u516c\u5f00\u6570\u636e\u4e14\u8bc4\u4f30\u6ce8\u610f\u529b\u504f\u91cd\u4f20\u7edf\u6307\u6807\uff0c\u5b9e\u9645\u4e34\u5e8a\u5e94\u7528\u548c\u533b\u5b66\u4e13\u5c5e\u6280\u672f\u5c1a\u4e0d\u8db3\uff0c\u672a\u6765\u4e9f\u9700\u5b9e\u73b0\u4e34\u5e8a\u6709\u6548\u6027\u3001\u8bed\u8a00\u591a\u6837\u6027\u53ca\u4f4e\u8d44\u6e90\u73af\u5883\u9002\u914d\u3002", "motivation": "\u533b\u5b66\u77e5\u8bc6\u7684\u5feb\u901f\u589e\u957f\u548c\u4e34\u5e8a\u5b9e\u8df5\u7684\u590d\u6742\u6027\u63d0\u51fa\u4e86\u65b0\u7684\u6311\u6218\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u4fe1\u606f\u5904\u7406\u65b9\u6cd5\u3002\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u9886\u57df\u5c55\u73b0\u4e86\u4ef7\u503c\uff0c\u4f46\u4ecd\u5b58\u5728\u5c40\u9650\uff0cRAG\u6280\u672f\u6709\u671b\u63d0\u5347\u5176\u4e34\u5e8a\u5e94\u7528\u6027\u3002", "method": "\u672c\u6587\u5bf9\u533b\u5b66\u9886\u57df\u4e2dRAG\u6280\u672f\u7684\u76f8\u5173\u5e94\u7528\u8fdb\u884c\u4e86\u7efc\u8ff0\u7814\u7a76\uff0c\u5206\u6790\u4e86\u6570\u636e\u6765\u6e90\u3001\u68c0\u7d22\u548c\u751f\u6210\u65b9\u6cd5\u3001\u8bc4\u4ef7\u6307\u6807\u4ee5\u53ca\u5e94\u7528\u573a\u666f\u3002", "result": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u4f9d\u8d56\u516c\u5f00\u6570\u636e\uff0c\u533b\u7597\u4e13\u5c5e\u79c1\u6709\u6570\u636e\u7684\u5e94\u7528\u6709\u9650\u3002\u82f1\u6587\u5411\u91cf\u6a21\u578b\u4e3a\u4e3b\u6d41\uff0c\u533b\u5b66\u4e13\u7528LLM\u5229\u7528\u8f83\u5c11\u3002\u81ea\u52a8\u6307\u6807\u7528\u4e8e\u8bc4\u4f30\u751f\u6210\u8d28\u91cf\u53ca\u4efb\u52a1\u8868\u73b0\uff0c\u4eba\u5de5\u8bc4\u4f30\u5173\u6ce8\u51c6\u786e\u6027\u3001\u5b8c\u6574\u6027\u3001\u76f8\u5173\u6027\u548c\u6d41\u7545\u6027\uff0c\u4f46\u5bf9\u504f\u89c1\u548c\u5b89\u5168\u6027\u5173\u6ce8\u4e0d\u8db3\u3002RAG\u5e94\u7528\u96c6\u4e2d\u4e8e\u533b\u5b66\u95ee\u7b54\u3001\u62a5\u544a\u751f\u6210\u3001\u6587\u672c\u6458\u8981\u53ca\u4fe1\u606f\u62bd\u53d6\u3002", "conclusion": "\u533b\u5b66\u9886\u57dfRAG\u6280\u672f\u4ecd\u5904\u4e8e\u65e9\u671f\uff0c\u9700\u8981\u63a8\u8fdb\u4e34\u5e8a\u9a8c\u8bc1\u3001\u8de8\u8bed\u8a00\u9002\u914d\u53ca\u4f4e\u8d44\u6e90\u573a\u666f\u652f\u6301\uff0c\u4ee5\u5b9e\u73b0\u5168\u7403\u8303\u56f4\u5185\u53ef\u4fe1\u4e14\u8d1f\u8d23\u4efb\u7684\u5e94\u7528\u3002"}}
{"id": "2511.06251", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06251", "abs": "https://arxiv.org/abs/2511.06251", "authors": ["Mingde Xu", "Zhen Yang", "Wenyi Hong", "Lihang Pan", "Xinyue Fan", "Yan Wang", "Xiaotao Gu", "Bin Xu", "Jie Tang"], "title": "WebVIA: A Web-based Vision-Language Agentic Framework for Interactive and Verifiable UI-to-Code Generation", "comment": "36 pages, 30 figures", "summary": "User interface (UI) development requires translating design mockups into functional code, a process that remains repetitive and labor-intensive. While recent Vision-Language Models (VLMs) automate UI-to-Code generation, they generate only static HTML/CSS/JavaScript layouts lacking interactivity. To address this, we propose WebVIA, the first agentic framework for interactive UI-to-Code generation and validation. The framework comprises three components: 1) an exploration agent to capture multi-state UI screenshots; 2) a UI2Code model that generates executable interactive code; 3) a validation module that verifies the interactivity. Experiments demonstrate that WebVIA-Agent achieves more stable and accurate UI exploration than general-purpose agents (e.g., Gemini-2.5-Pro). In addition, our fine-tuned WebVIA-UI2Code models exhibit substantial improvements in generating executable and interactive HTML/CSS/JavaScript code, outperforming their base counterparts across both interactive and static UI2Code benchmarks. Our code and models are available at \\href{https://zheny2751-dotcom.github.io/webvia.github.io/}{\\texttt{https://webvia.github.io}}.", "AI": {"tldr": "WebVIA\u63d0\u51fa\u4e86\u4e00\u5957\u521b\u65b0\u7684UI-to-Code\u81ea\u52a8\u751f\u6210\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7f51\u9875\u4ea4\u4e92\u4ee3\u7801\u7684\u751f\u6210\u548c\u81ea\u52a8\u9a8c\u8bc1\u80fd\u529b\uff0c\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u52a9\u529b\u9ad8\u6548UI\u5f00\u53d1\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u867d\u53ef\u8f85\u52a9\u8bbe\u8ba1\u7a3f\u5230\u4ee3\u7801\u7684\u81ea\u52a8\u8f6c\u5316\uff0c\u4f46\u4ec5\u80fd\u751f\u6210\u9759\u6001UI\u4ee3\u7801\uff0c\u7f3a\u4e4f\u9875\u9762\u4ea4\u4e92\u6027\uff0c\u4e14UI\u5f00\u53d1\u4ecd\u7136\u91cd\u590d\u4e14\u8017\u65f6\u3002\u4e9f\u9700\u80fd\u81ea\u52a8\u751f\u6210\u4e14\u9a8c\u8bc1\u4ea4\u4e92\u5f0fUI\u4ee3\u7801\u7684\u9ad8\u6548\u65b9\u6848\u3002", "method": "\u63d0\u51faWebVIA\u6846\u67b6\uff0c\u5305\u62ec\u4e09\u90e8\u5206\uff1a1\uff09\u5229\u7528\u63a2\u7d22agent\u81ea\u52a8\u6355\u6349\u591a\u72b6\u6001\u7684UI\u622a\u56fe\uff1b2\uff09UI2Code\u6a21\u578b\u53ef\u751f\u6210\u53ef\u6267\u884c\u7684\u4ea4\u4e92\u5f0f\u4ee3\u7801\uff1b3\uff09\u9a8c\u8bc1\u6a21\u5757\u81ea\u52a8\u68c0\u6d4b\u751f\u6210\u4ee3\u7801\u7684\u4ea4\u4e92\u6027\u3002\u901a\u8fc7\u7aef\u5230\u7aef\u7684\u96c6\u6210\u63d0\u5347UI-to-Code\u81ea\u52a8\u5316\u53ca\u4ea4\u4e92\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eWebVIA-Agent\u5728UI\u63a2\u7d22\u7684\u7a33\u5b9a\u6027\u4e0e\u51c6\u786e\u6027\u660e\u663e\u4f18\u4e8e\u901a\u7528\u578bagent\uff08\u5982Gemini-2.5-Pro\uff09\u3002WebVIA-UI2Code\u6a21\u578b\u5728\u4ea4\u4e92\u548c\u9759\u6001\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u57fa\u7840\u6a21\u578b\uff0c\u53ef\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u53ef\u4ea4\u4e92\u7684\u7f51\u9875\u4ee3\u7801\u3002", "conclusion": "WebVIA\u9996\u6b21\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u7684\u4ea4\u4e92\u5f0fUI-to-Code\u751f\u6210\u548c\u81ea\u52a8\u9a8c\u8bc1\uff0c\u63a8\u52a8UI\u5f00\u53d1\u81ea\u52a8\u5316\u6c34\u5e73\uff0c\u5e76\u63d0\u4f9b\u4e86\u516c\u5f00\u53ef\u7528\u7684\u4ee3\u7801\u548c\u6a21\u578b\u8d44\u6e90\u3002"}}
{"id": "2511.05913", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05913", "abs": "https://arxiv.org/abs/2511.05913", "authors": ["Hongtao Wang", "Renchi Yang", "Wenqing Lin"], "title": "NILC: Discovering New Intents with LLM-assisted Clustering", "comment": null, "summary": "New intent discovery (NID) seeks to recognize both new and known intents from unlabeled user utterances, which finds prevalent use in practical dialogue systems. Existing works towards NID mainly adopt a cascaded architecture, wherein the first stage focuses on encoding the utterances into informative text embeddings beforehand, while the latter is to group similar embeddings into clusters (i.e., intents), typically by K-Means. However, such a cascaded pipeline fails to leverage the feedback from both steps for mutual refinement, and, meanwhile, the embedding-only clustering overlooks nuanced textual semantics, leading to suboptimal performance. To bridge this gap, this paper proposes NILC, a novel clustering framework specially catered for effective NID. Particularly, NILC follows an iterative workflow, in which clustering assignments are judiciously updated by carefully refining cluster centroids and text embeddings of uncertain utterances with the aid of large language models (LLMs). Specifically, NILC first taps into LLMs to create additional semantic centroids for clusters, thereby enriching the contextual semantics of the Euclidean centroids of embeddings. Moreover, LLMs are then harnessed to augment hard samples (ambiguous or terse utterances) identified from clusters via rewriting for subsequent cluster correction. Further, we inject supervision signals through non-trivial techniques seeding and soft must links for more accurate NID in the semi-supervised setting. Extensive experiments comparing NILC against multiple recent baselines under both unsupervised and semi-supervised settings showcase that NILC can achieve significant performance improvements over six benchmark datasets of diverse domains consistently.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684NILC\u6846\u67b6\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u805a\u7c7b\u4e2d\u5fc3\u548c\u96be\u6837\u672c\u4f18\u5316\uff0c\u5728\u591a\u9886\u57df\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4e3b\u6d41NID\u65b9\u6cd5\u3002", "motivation": "NID\uff08\u65b0\u610f\u56fe\u53d1\u73b0\uff09\u5728\u5b9e\u9645\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u975e\u5e38\u91cd\u8981\uff0c\u73b0\u6709\u65b9\u6cd5\u91c7\u7528\u7ea7\u8054\u67b6\u6784\uff0c\u5b58\u5728\u5404\u9636\u6bb5\u65e0\u6cd5\u4e92\u76f8\u4f18\u5316\u3001\u805a\u7c7b\u4ec5\u4f9d\u8d56\u5d4c\u5165\u5bfc\u81f4\u8bed\u4e49\u6355\u6349\u80fd\u529b\u5f31\u7b49\u95ee\u9898\uff0c\u56e0\u6b64\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86NILC\u805a\u7c7b\u6846\u67b6\uff0c\u91c7\u7528\u8fed\u4ee3\u6d41\u7a0b\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8f85\u52a9\uff0c\u7cbe\u7ec6\u5316\u805a\u7c7b\u4e2d\u5fc3\u53ca\u96be\u5224\u6587\u672c\u5d4c\u5165\u3002\u5177\u4f53\u5305\u62ec\uff1a\u5229\u7528LLM\u751f\u6210\u8bed\u4e49\u805a\u7c7b\u4e2d\u5fc3\uff0c\u4e30\u5bcc\u539f\u6709\u5d4c\u5165\u8bed\u5883\uff1b\u9488\u5bf9\u96be\u5224\u8bed\u53e5\uff0c\u901a\u8fc7LLM\u6539\u5199\u589e\u5f3a\u6837\u672c\uff1b\u5728\u534a\u76d1\u7763\u573a\u666f\u4e0b\uff0c\u901a\u8fc7\u79cd\u5b50\u548c\u8f6f\u7ea6\u675f\u8fde\u63a5\u6ce8\u5165\u76d1\u7763\u4fe1\u53f7\u3002", "result": "\u5728\u516d\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cNILC\u5728\u65e0\u76d1\u7763\u548c\u534a\u76d1\u7763\u4e24\u79cd\u8bbe\u7f6e\u4e0b\u5747\u663e\u8457\u4f18\u4e8e\u8fd1\u671f\u4e3b\u6d41\u65b9\u6cd5\u3002", "conclusion": "NILC\u6709\u6548\u63d0\u5347\u4e86\u65b0\u610f\u56fe\u53d1\u73b0\u4efb\u52a1\u4e2d\u7684\u805a\u7c7b\u8868\u73b0\uff0c\u89e3\u51b3\u4e86\u5d4c\u5165\u805a\u7c7b\u8bed\u4e49\u4e0d\u591f\u4e30\u5bcc\u3001\u96be\u6837\u672c\u5904\u7406\u4e0d\u5230\u4f4d\u7b49\u95ee\u9898\uff0c\u901a\u8fc7LLM\u4e0e\u65b0\u805a\u7c7b\u6280\u672f\u914d\u5408\u53d6\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2511.06352", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.06352", "abs": "https://arxiv.org/abs/2511.06352", "authors": ["Sara Mahdavi Hezavehi", "Danny Weyns", "Paris Avgeriou"], "title": "State of the Art on Self-adaptive Systems: An Essay", "comment": "12", "summary": "In this essay, we introduce the basic concepts necessary to lay out the foundation for our PhD research on uncertainty and risk-aware adaptation, and discuss relevant related research.", "AI": {"tldr": "\u672c\u6587\u4e3a\u535a\u58eb\u7814\u7a76\u5960\u5b9a\u4e86\u4e0d\u786e\u5b9a\u6027\u4e0e\u98ce\u9669\u611f\u77e5\u9002\u5e94\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u68b3\u7406\u76f8\u5173\u524d\u6cbf\u7814\u7a76\u3002", "motivation": "\u4e3a\u63a8\u52a8\u535a\u58eb\u7814\u7a76\uff0c\u6709\u5fc5\u8981\u68b3\u7406\u5e76\u6574\u5408\u4e0d\u786e\u5b9a\u6027\u4e0e\u98ce\u9669\u611f\u77e5\u9886\u57df\u7684\u6838\u5fc3\u7406\u8bba\u548c\u73b0\u6709\u6210\u679c\u3002", "method": "\u9996\u5148\u4ecb\u7ecd\u76f8\u5173\u57fa\u7840\u6982\u5ff5\uff0c\u7136\u540e\u7efc\u8ff0\u76f8\u5173\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\u3002", "result": "\u6587\u4e2d\u5398\u6e05\u4e86\u8be5\u9886\u57df\u7684\u5173\u952e\u6982\u5ff5\uff0c\u7cfb\u7edf\u68b3\u7406\u4e86\u76f8\u5173\u7814\u7a76\uff0c\u4e3a\u540e\u7eed\u79d1\u7814\u63d0\u4f9b\u7406\u8bba\u652f\u6491\u3002", "conclusion": "\u672c\u6587\u603b\u7ed3\u4e86\u4e0d\u786e\u5b9a\u6027\u4e0e\u98ce\u9669\u611f\u77e5\u9002\u5e94\u7684\u57fa\u7840\u7406\u8bba\uff0c\u4e3a\u540e\u7eed\u535a\u58eb\u7814\u7a76\u505a\u597d\u7406\u8bba\u94fa\u57ab\u3002"}}
{"id": "2511.05921", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05921", "abs": "https://arxiv.org/abs/2511.05921", "authors": ["Ankan Mullick", "Sukannya Purkayastha", "Saransh Sharma", "Pawan Goyal", "Niloy Ganguly"], "title": "IDALC: A Semi-Supervised Framework for Intent Detection and Active Learning based Correction", "comment": "Paper accepted in IEEE Transactions on Artificial Intelligence (October 2025)", "summary": "Voice-controlled dialog systems have become immensely popular due to their ability to perform a wide range of actions in response to diverse user queries. These agents possess a predefined set of skills or intents to fulfill specific user tasks. But every system has its own limitations. There are instances where, even for known intents, if any model exhibits low confidence, it results in rejection of utterances that necessitate manual annotation. Additionally, as time progresses, there may be a need to retrain these agents with new intents from the system-rejected queries to carry out additional tasks. Labeling all these emerging intents and rejected utterances over time is impractical, thus calling for an efficient mechanism to reduce annotation costs. In this paper, we introduce IDALC (Intent Detection and Active Learning based Correction), a semi-supervised framework designed to detect user intents and rectify system-rejected utterances while minimizing the need for human annotation. Empirical findings on various benchmark datasets demonstrate that our system surpasses baseline methods, achieving a 5-10% higher accuracy and a 4-8% improvement in macro-F1. Remarkably, we maintain the overall annotation cost at just 6-10% of the unlabelled data available to the system. The overall framework of IDALC is shown in Fig. 1", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684IDALC\u6846\u67b6\u5927\u5e45\u964d\u4f4e\u4e86\u5bf9\u4eba\u5de5\u6807\u6ce8\u7684\u4f9d\u8d56\uff0c\u540c\u65f6\u63d0\u5347\u4e86\u8bed\u97f3\u5bf9\u8bdd\u7cfb\u7edf\u5bf9\u7528\u6237\u610f\u56fe\u7684\u68c0\u6d4b\u548c\u4fee\u6b63\u80fd\u529b\uff0c\u5b9e\u9a8c\u6548\u679c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u8bed\u97f3\u5bf9\u8bdd\u7cfb\u7edf\u867d\u7136\u5e7f\u53d7\u6b22\u8fce\uff0c\u4f46\u5728\u9762\u5bf9\u7cfb\u7edf\u4f4e\u7f6e\u4fe1\u5ea6\u6216\u65b0\u610f\u56fe\u65f6\uff0c\u5e38\u5e38\u9700\u8981\u5927\u91cf\u4eba\u5de5\u6807\u6ce8\u548c\u518d\u8bad\u7ec3\uff0c\u957f\u671f\u6765\u770b\u96be\u4ee5\u627f\u53d7\u9ad8\u6602\u7684\u6807\u6ce8\u6210\u672c\u3002\u5982\u4f55\u6709\u6548\u51cf\u5c11\u4eba\u5de5\u6807\u6ce8\uff0c\u5374\u53c8\u80fd\u53ca\u65f6\u63d0\u5347\u548c\u6269\u5c55\u7cfb\u7edf\u610f\u56fe\u8bc6\u522b\u80fd\u529b\uff0c\u662f\u5f53\u524d\u4e9f\u9700\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aIDALC\uff08\u57fa\u4e8e\u610f\u56fe\u68c0\u6d4b\u4e0e\u4e3b\u52a8\u5b66\u4e60\u7684\u4fee\u6b63\uff09\u534a\u76d1\u7763\u6846\u67b6\u3002\u5176\u6838\u5fc3\u601d\u8def\u662f\u5728\u5c3d\u91cf\u5c11\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u7684\u524d\u63d0\u4e0b\uff0c\u7ed3\u5408\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565\u548c\u610f\u56fe\u68c0\u6d4b\u6280\u672f\u81ea\u52a8\u8bc6\u522b\u5e76\u4fee\u6b63\u7cfb\u7edf\u62d2\u7edd\u7684\u8bed\u53e5\u3002", "result": "\u5728\u591a\u7ec4\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0cIDALC\u7cfb\u7edf\u7684\u51c6\u786e\u7387\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u4e865-10%\uff0c\u5b8f\u5e73\u5747F1\u63d0\u53474-8%\uff0c\u540c\u65f6\u6574\u4f53\u6807\u6ce8\u6210\u672c\u4ec5\u5360\u672a\u6807\u6ce8\u6570\u636e\u76846-10%\u3002", "conclusion": "IDALC\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u5de5\u6807\u6ce8\u91cf\u7684\u540c\u65f6\uff0c\u53ef\u4ee5\u66f4\u9ad8\u6548\u5730\u63d0\u5347\u8bed\u97f3\u5bf9\u8bdd\u7cfb\u7edf\u5bf9\u65b0\u610f\u56fe\u548c\u4f4e\u7f6e\u4fe1\u5ea6\u8bed\u53e5\u7684\u8bc6\u522b\u3001\u4fee\u6b63\u80fd\u529b\uff0c\u5177\u6709\u5f88\u597d\u7684\u5b9e\u9645\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.06362", "categories": ["cs.SE", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.06362", "abs": "https://arxiv.org/abs/2511.06362", "authors": ["Anastasiia Birillo", "Aleksei Rostovskii", "Yaroslav Golubev", "Hieke Keuning"], "title": "Understanding Student Interaction with AI-Powered Next-Step Hints: Strategies and Challenges", "comment": "Accepted to SIGCSE'26. 7 pages, 3 figures", "summary": "Automated feedback generation plays a crucial role in enhancing personalized learning experiences in computer science education. Among different types of feedback, next-step hint feedback is particularly important, as it provides students with actionable steps to progress towards solving programming tasks. This study investigates how students interact with an AI-driven next-step hint system in an in-IDE learning environment. We gathered and analyzed a dataset from 34 students solving Kotlin tasks, containing detailed hint interaction logs. We applied process mining techniques and identified 16 common interaction scenarios. Semi-structured interviews with 6 students revealed strategies for managing unhelpful hints, such as adapting partial hints or modifying code to generate variations of the same hint. These findings, combined with our publicly available dataset, offer valuable opportunities for future research and provide key insights into student behavior, helping improve hint design for enhanced learning support.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86\u5b66\u751f\u5728IDE\u4e2d\u4e0eAI\u63d0\u793a\u7cfb\u7edf\u7684\u4ea4\u4e92\uff0c\u53d1\u73b0\u4e86\u591a\u79cd\u5904\u7406\u63d0\u793a\u7684\u65b9\u6cd5\uff0c\u5e76\u603b\u7ed3\u884c\u4e3a\u6a21\u5f0f\u4e0e\u6539\u8fdb\u5efa\u8bae\uff0c\u4e3a\u672a\u6765\u7f16\u7a0b\u6559\u80b2\u4e2d\u81ea\u52a8\u5316\u63d0\u793a\u7cfb\u7edf\u7684\u4f18\u5316\u63d0\u4f9b\u4e86\u53c2\u8003\u3002", "motivation": "\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u4e2d\uff0c\u81ea\u52a8\u5316\u53cd\u9988\uff08\u5c24\u5176\u662f\u4e0b\u4e00\u6b65\u63d0\u793a\uff09\u5bf9\u4e2a\u6027\u5316\u5b66\u4e60\u81f3\u5173\u91cd\u8981\u3002\u5f53\u524d\u5c1a\u9700\u7cfb\u7edf\u4e86\u89e3\u5b66\u751f\u5982\u4f55\u4e0eAI\u9a71\u52a8\u7684\u63d0\u793a\u7cfb\u7edf\u4e92\u52a8\u53ca\u9762\u5bf9\u65e0\u6548\u63d0\u793a\u65f6\u7684\u5e94\u5bf9\u65b9\u5f0f\uff0c\u4ee5\u63a8\u52a8\u63d0\u793a\u7cfb\u7edf\u7684\u4f18\u5316\u3002", "method": "\u6536\u96c634\u540d\u5b66\u751f\u5728IDE\u73af\u5883\u4e0b\u89e3\u51b3Kotlin\u4efb\u52a1\u7684\u6570\u636e\uff0c\u5206\u6790\u8be6\u7ec6\u7684\u63d0\u793a\u4ea4\u4e92\u65e5\u5fd7\uff0c\u5e76\u5e94\u7528\u6d41\u7a0b\u6316\u6398\u6280\u672f\u8bc6\u522b16\u79cd\u5e38\u89c1\u7684\u4e92\u52a8\u573a\u666f\u3002\u6b64\u5916\uff0c\u5bf96\u540d\u5b66\u751f\u8fdb\u884c\u4e86\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u4ee5\u6df1\u5165\u7406\u89e3\u5176\u884c\u4e3a\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u6d41\u7a0b\u6316\u6398\uff0c\u8bc6\u522b\u51fa16\u79cd\u4ea4\u4e92\u573a\u666f\uff1b\u8bbf\u8c08\u63ed\u793a\u5b66\u751f\u9762\u5bf9\u6b64\u7c7b\u7cfb\u7edf\u5e38\u7528\u7684\u7b56\u7565\u3002\u7814\u7a76\u6570\u636e\u96c6\u516c\u5f00\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u652f\u6301\uff0c\u540c\u65f6\u4e3a\u63d0\u5347\u63d0\u793a\u8bbe\u8ba1\u4e0e\u5b66\u4e60\u652f\u6301\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002", "conclusion": "\u672c\u7814\u7a76\u603b\u7ed3\u4e86\u5b66\u751f\u4e0eAI\u9a71\u52a8\u7684\u4e0b\u4e00\u6b65\u63d0\u793a\u7cfb\u7edf\u7684\u4e92\u52a8\u884c\u4e3a\uff0c\u63ed\u793a\u4e86\u5b66\u751f\u4e3a\u5e94\u5bf9\u65e0\u6548\u63d0\u793a\u6240\u91c7\u7528\u7684\u7b56\u7565\uff0c\u5982\u8c03\u6574\u90e8\u5206\u63d0\u793a\u6216\u4fee\u6539\u4ee3\u7801\u4ee5\u83b7\u53d6\u4e0d\u540c\u7248\u672c\u7684\u63d0\u793a\u3002\u8fd9\u4e9b\u53d1\u73b0\u6709\u52a9\u4e8e\u6539\u8fdb\u81ea\u52a8\u5316\u63d0\u793a\u7cfb\u7edf\u7684\u8bbe\u8ba1\uff0c\u589e\u5f3a\u7f16\u7a0b\u5b66\u4e60\u7684\u4e2a\u6027\u5316\u4e0e\u6709\u6548\u6027\u3002"}}
{"id": "2511.05933", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05933", "abs": "https://arxiv.org/abs/2511.05933", "authors": ["Renfei Zhang", "Manasa Kaniselvan", "Niloofar Mireshghallah"], "title": "Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs", "comment": "`", "summary": "Reinforcement learning (RL) is often credited with improving language model reasoning and generalization at the expense of degrading memorized knowledge. We challenge this narrative by observing that RL-enhanced models consistently outperform their base and supervised fine-tuned (SFT) counterparts on pure knowledge recall tasks, particularly those requiring traversal of hierarchical, structured knowledge (e.g., medical codes). We hypothesize these gains stem not from newly acquired data, but from improved procedural skills in navigating and searching existing knowledge hierarchies within the model parameters. To support this hypothesis, we show that structured prompting, which explicitly guides SFTed models through hierarchical traversal, recovers most of the performance gap (reducing 24pp to 7pp on MedConceptsQA for DeepSeek-V3/R1). We further find that while prompting improves final-answer accuracy, RL-enhanced models retain superior ability to recall correct procedural paths on deep-retrieval tasks. Finally our layer-wise internal activation analysis reveals that while factual representations (e.g., activations for the statement \"code 57.95 refers to urinary infection\") maintain high cosine similarity between SFT and RL models, query representations (e.g., \"what is code 57.95\") diverge noticeably, indicating that RL primarily transforms how models traverse knowledge rather than the knowledge representation itself.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u5bf9\u7ed3\u6784\u5316\u77e5\u8bc6\u7684\u68c0\u7d22\u4e0e\u7a0b\u5e8f\u6027\u5bfc\u822a\u80fd\u529b\uff0c\u800c\u975e\u524a\u5f31\u8bb0\u5fc6\u6027\u77e5\u8bc6\u3002\u901a\u8fc7\u5206\u6790\u6a21\u578b\u8f93\u51fa\u548c\u5185\u90e8\u6fc0\u6d3b\uff0c\u4f5c\u8005\u6307\u51faRL\u4e13\u6ce8\u4e8e\u4f18\u5316\u6a21\u578b\u77e5\u8bc6\u68c0\u7d22\u65b9\u5f0f\uff0c\u800c\u4e0d\u662f\u6539\u53d8\u77e5\u8bc6\u672c\u8eab\u7684\u8868\u5f81\u3002\u7ed3\u6784\u5316\u63d0\u793a\u80fd\u8ba9SFT\u6a21\u578b\u90e8\u5206\u8ffd\u8d76RL\u6a21\u578b\uff0c\u4f46RL\u4ecd\u5728\u6df1\u5c42\u68c0\u7d22\u548c\u8def\u5f84\u8fd8\u539f\u65b9\u9762\u66f4\u80dc\u4e00\u7b79\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u8ba4\u4e3a\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u548c\u6cdb\u5316\u80fd\u529b\u4f1a\u635f\u5bb3\u6a21\u578b\u7684\u8bb0\u5fc6\u6027\u77e5\u8bc6\u3002\u4f46\u672c\u6587\u8d28\u7591\u8be5\u89c2\u70b9\uff0c\u5173\u6ce8RL\u5bf9\u6a21\u578b\u77e5\u8bc6\u68c0\u7d22\u80fd\u529b\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u7ed3\u6784\u5316\u3001\u5206\u5c42\u77e5\u8bc6\u9886\u57df\u3002", "method": "\u5bf9\u6bd4RL\u589e\u5f3a\u6a21\u578b\u4e0e\u57fa\u7840\u6a21\u578b\u53ca\u6709\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u6a21\u578b\u5728\u7eaf\u77e5\u8bc6\u68c0\u7d22\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff08\u5982\u533b\u7597\u7f16\u7801\uff09\uff0c\u5e76\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u8ba9SFT\u6a21\u578b\u663e\u5f0f\u8fdb\u884c\u5206\u5c42\u68c0\u7d22\u3002\u5206\u6790\u6a21\u578b\u5c42\u6b21\u6fc0\u6d3b\uff0c\u6bd4\u8f83\u77e5\u8bc6\u8868\u8ff0\u4e0e\u67e5\u8be2\u8868\u8ff0\u7684\u5411\u91cf\u7c7b\u4f3c\u6027\u3002", "result": "RL\u589e\u5f3a\u6a21\u578b\u5728\u7ed3\u6784\u5316\u77e5\u8bc6\u68c0\u7d22\u4efb\u52a1\u4e0a\u4f18\u4e8e\u57fa\u7840\u548cSFT\u6a21\u578b\u3002\u7ed3\u6784\u5316\u63d0\u793a\u80fd\u663e\u8457\u7f29\u5c0fSFT\u4e0eRL\u6a21\u578b\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u4f46RL\u6a21\u578b\u5728\u6df1\u5c42\u68c0\u7d22\u4efb\u52a1\u4e2d\u5bf9\u68c0\u7d22\u8def\u5f84\u7684\u56de\u5fc6\u80fd\u529b\u66f4\u5f3a\u3002\u5185\u90e8\u6fc0\u6d3b\u5206\u6790\u663e\u793a\uff0cRL\u6a21\u578b\u5728\u5982\u4f55\u68c0\u7d22\u77e5\u8bc6\uff08\u800c\u975e\u77e5\u8bc6\u672c\u8eab\u7684\u8868\u5f81\uff09\u65b9\u9762\u53d1\u751f\u4e3b\u8981\u53d8\u5316\u3002", "conclusion": "RL\u5e76\u672a\u635f\u5bb3\u6a21\u578b\u8bb0\u5fc6\u7684\u77e5\u8bc6\uff0c\u800c\u662f\u589e\u5f3a\u4e86\u6a21\u578b\u5bf9\u73b0\u6709\u77e5\u8bc6\u67b6\u6784\u7684\u68c0\u7d22\u548c\u7a0b\u5e8f\u6027\u63a2\u7d22\u80fd\u529b\u3002\u8fd9\u79cd\u80fd\u529b\u63d0\u5347\u4e0d\u662f\u56e0\u4e3a\u83b7\u5f97\u4e86\u65b0\u77e5\u8bc6\uff0c\u800c\u662f\u6539\u8fdb\u4e86\u5df2\u6709\u77e5\u8bc6\u7684\u4f7f\u7528\u65b9\u5f0f\u3002"}}
{"id": "2511.06367", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.06367", "abs": "https://arxiv.org/abs/2511.06367", "authors": ["Sara Mahdavi Hezavehi", "Danny Weyns", "Paris Avgeriou"], "title": "Methodological Considerations for Self-adaptive Systems: An Essay", "comment": "15", "summary": "In this essay, we provide an overview of methodological considerations necessary to lay out the foundation for our PhD research on uncertainty and risk-aware adaptation.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u548c\u98ce\u9669\u9002\u5e94\u6027\u7814\u7a76\u6240\u9700\u7684\u65b9\u6cd5\u8bba\u8981\u70b9\uff0c\u4e3a\u535a\u58eb\u8bfe\u9898\u642d\u5efa\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u65b0\u5174\u9886\u57df\u9700\u8981\u7cfb\u7edf\u6027\u7684\u7406\u8bba\u6846\u67b6\u6765\u6307\u5bfc\u5bf9\u4e0d\u786e\u5b9a\u6027\u53ca\u98ce\u9669\u611f\u77e5\u9002\u5e94\u6027\u7684\u7814\u7a76\u3002", "method": "\u7efc\u8ff0\u76f8\u5173\u65b9\u6cd5\u8bba\uff0c\u63a2\u8ba8\u5982\u4f55\u79d1\u5b66\u7814\u7a76\u4e0d\u786e\u5b9a\u6027\u548c\u98ce\u9669\u611f\u77e5\u7684\u9002\u5e94\u6027\u3002", "result": "\u6982\u8ff0\u4e86\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u548c\u98ce\u9669\u9002\u5e94\u7814\u7a76\u5e94\u5173\u6ce8\u7684\u5173\u952e\u65b9\u6cd5\u8bba\u95ee\u9898\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u53c2\u8003\u3002", "conclusion": "\u672c\u6587\u4e3b\u8981\u4e3a\u65e5\u540e\u535a\u58eb\u7814\u7a76\u5960\u5b9a\u57fa\u7840\uff0c\u805a\u7126\u4e8e\u4e0d\u786e\u5b9a\u6027\u548c\u98ce\u9669\u611f\u77e5\u7684\u9002\u5e94\u6027\u7814\u7a76\u65b9\u6cd5\u3002"}}
{"id": "2511.05969", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05969", "abs": "https://arxiv.org/abs/2511.05969", "authors": ["Anton Kolonin", "Anna Arinicheva"], "title": "Interpretable Recognition of Cognitive Distortions in Natural Language Texts", "comment": "9 pages, 4 figures", "summary": "We propose a new approach to multi-factor classification of natural language texts based on weighted structured patterns such as N-grams, taking into account the heterarchical relationships between them, applied to solve such a socially impactful problem as the automation of detection of specific cognitive distortions in psychological care, relying on an interpretable, robust and transparent artificial intelligence model. The proposed recognition and learning algorithms improve the current state of the art in this field. The improvement is tested on two publicly available datasets, with significant improvements over literature-known F1 scores for the task, with optimal hyper-parameters determined, having code and models available for future use by the community.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a0\u6743\u7ed3\u6784\u5316N-gram\u7684\u65b0\u591a\u56e0\u7d20\u6587\u672c\u5206\u7c7b\u65b9\u6cd5\uff0c\u6709\u6548\u8bc6\u522b\u5fc3\u7406\u8ba4\u77e5\u504f\u5dee\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5df2\u516c\u5f00\u4ee3\u7801\u548c\u6a21\u578b\u3002", "motivation": "\u81ea\u52a8\u5316\u68c0\u6d4b\u5fc3\u7406\u8ba4\u77e5\u504f\u5dee\u6709\u91cd\u8981\u793e\u4f1a\u610f\u4e49\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4e9f\u9700\u65b0\u7684\u9ad8\u6548\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u52a0\u6743\u7ed3\u6784\u5316N-gram\u65b9\u6cd5\uff0c\u7ed3\u5408\u5f02\u5c42\u7ea7\u5173\u7cfb\uff0c\u5e76\u8bbe\u8ba1\u4e86\u65b0\u7684\u8bc6\u522b\u548c\u5b66\u4e60\u7b97\u6cd5\uff0c\u5728\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u7136\u8bed\u8a00\u6587\u672c\u591a\u56e0\u7d20\u5206\u7c7b\u65b9\u6cd5\uff0c\u57fa\u4e8e\u52a0\u6743\u7ed3\u6784\u5316\u6a21\u5f0f\uff08\u5982N-gram\uff09\uff0c\u5e76\u8003\u8651\u4e86\u5176\u95f4\u7684\u5f02\u5c42\u7ea7\u5173\u7cfb\u3002\u6b64\u65b9\u6cd5\u5e94\u7528\u4e8e\u81ea\u52a8\u68c0\u6d4b\u5fc3\u7406\u62a4\u7406\u4e2d\u7684\u7279\u5b9a\u8ba4\u77e5\u504f\u5dee\uff0c\u4f9d\u8d56\u4e8e\u53ef\u89e3\u91ca\u3001\u5065\u58ee\u4e14\u900f\u660e\u7684\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u3002\u4f5c\u8005\u8bbe\u8ba1\u4e86\u65b0\u7684\u8bc6\u522b\u548c\u5b66\u4e60\u7b97\u6cd5\uff0c\u5e76\u5728\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u4e0e\u73b0\u6709\u6587\u732e\u76f8\u6bd4\uff0cF1\u5206\u6570\u663e\u8457\u63d0\u5347\uff0c\u540c\u65f6\u516c\u5f00\u4e86\u4ee3\u7801\u548c\u6a21\u578b\u4ee5\u4f9b\u793e\u533a\u672a\u6765\u4f7f\u7528\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5fc3\u7406\u8ba4\u77e5\u504f\u5dee\u81ea\u52a8\u68c0\u6d4b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5f53\u524d\u6700\u4f73\u65b9\u6cd5\uff0c\u4e14\u6a21\u578b\u5177\u6709\u8f83\u9ad8\u7684\u53ef\u89e3\u91ca\u6027\u548c\u900f\u660e\u5ea6\u3002"}}
{"id": "2511.06428", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06428", "abs": "https://arxiv.org/abs/2511.06428", "authors": ["Samuel Ferino", "Rashina Hoda", "John Grundy", "Christoph Treude"], "title": "Walking the Tightrope of LLMs for Software Development: A Practitioners' Perspective", "comment": null, "summary": "Background: Large Language Models emerged with the potential of provoking a revolution in software development (e.g., automating processes, workforce transformation). Although studies have started to investigate the perceived impact of LLMs for software development, there is a need for empirical studies to comprehend how to balance forward and backward effects of using LLMs. Objective: We investigated how LLMs impact software development and how to manage the impact from a software developer's perspective. Method: We conducted 22 interviews with software practitioners across 3 rounds of data collection and analysis, between October (2024) and September (2025). We employed socio-technical grounded theory (STGT) for data analysis to rigorously analyse interview participants' responses. Results: We identified the benefits (e.g., maintain software development flow, improve developers' mental model, and foster entrepreneurship) and disadvantages (e.g., negative impact on developers' personality and damage to developers' reputation) of using LLMs at individual, team, organisation, and society levels; as well as best practices on how to adopt LLMs. Conclusion: Critically, we present the trade-offs that software practitioners, teams, and organisations face in working with LLMs. Our findings are particularly useful for software team leaders and IT managers to assess the viability of LLMs within their specific context.", "AI": {"tldr": "\u6b64\u8bba\u6587\u901a\u8fc7\u8bbf\u8c08\u4e0e\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u7684\u591a\u5c42\u6b21\u5229\u5f0a\u548c\u7ba1\u7406\u5efa\u8bae\uff0c\u5c24\u5176\u5f3a\u8c03\u4e86\u9700\u8981\u7efc\u5408\u6743\u8861\u548c\u6700\u4f73\u5b9e\u8df5\uff0c\u5bf9\u56e2\u961f\u548c\u7ec4\u7ec7\u9886\u5bfc\u6709\u73b0\u5b9e\u6307\u5bfc\u4ef7\u503c\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u51fa\u73b0\uff0c\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u5f71\u54cd\u5de8\u5927\uff0c\u5982\u6d41\u7a0b\u81ea\u52a8\u5316\u3001\u52b3\u52a8\u529b\u8f6c\u578b\u7b49\u3002\u867d\u5df2\u6709\u521d\u6b65\u8ba8\u8bba\uff0c\u4f46\u7f3a\u4e4f\u5bf9LLM\u5e94\u7528\u4e8e\u8f6f\u4ef6\u5f00\u53d1\u524d\u540e\u5f71\u54cd\u5e73\u8861\u7684\u5b9e\u8bc1\u7814\u7a76\u3002\u4f5c\u8005\u5e0c\u671b\u7cfb\u7edf\u5730\u7406\u89e3LLM\u5bf9\u5f00\u53d1\u7684\u591a\u5c42\u6b21\u5f71\u54cd\u53ca\u7ba1\u7406\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u56e2\u961f\u57282024\u5e7410\u6708\u81f32025\u5e749\u6708\u671f\u95f4\uff0c\u5206\u4e09\u8f6e\u5bf922\u4f4d\u8f6f\u4ef6\u4ece\u4e1a\u8005\u8fdb\u884c\u8bbf\u8c08\uff0c\u91c7\u7528\u793e\u4f1a\u6280\u672f\u624e\u6839\u7406\u8bba\uff08STGT\uff09\u5206\u6790\u53c2\u4e0e\u8005\u7684\u8bbf\u8c08\u5185\u5bb9\uff0c\u4ee5\u83b7\u5f97\u5bf9LLM\u5f71\u54cd\u7684\u6df1\u5165\u7406\u89e3\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLM\u5e26\u6765\u8bf8\u591a\u76ca\u5904\uff0c\u5305\u62ec\u4fdd\u6301\u5f00\u53d1\u6d41\u7a0b\u6d41\u7545\u3001\u63d0\u5347\u5f00\u53d1\u8005\u5fc3\u667a\u6a21\u578b\u3001\u4fc3\u8fdb\u4f01\u4e1a\u521b\u65b0\uff0c\u540c\u65f6\u4e5f\u5b58\u5728\u8d1f\u9762\u5f71\u54cd\uff0c\u5982\u5bf9\u5f00\u53d1\u8005\u4e2a\u6027\u7684\u8d1f\u9762\u4f5c\u7528\u53ca\u635f\u5bb3\u5f00\u53d1\u8005\u58f0\u8a89\u3002\u5f71\u54cd\u4f53\u73b0\u4e8e\u4e2a\u4eba\u3001\u56e2\u961f\u3001\u7ec4\u7ec7\u548c\u793e\u4f1a\u56db\u4e2a\u5c42\u9762\uff0c\u4e14\u603b\u7ed3\u4e86LLM\u5e94\u7528\u4e2d\u7684\u6700\u4f73\u5b9e\u8df5\u3002", "conclusion": "\u8be5\u7814\u7a76\u6df1\u5165\u5256\u6790\u4e86\u5728\u5b9e\u9645\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u4f7f\u7528LLM\u6240\u9700\u9762\u5bf9\u7684\u6743\u8861\uff0c\u5e76\u5bf9\u56e2\u961f\u9886\u5bfc\u548cIT\u7ba1\u7406\u8005\u8bc4\u4f30\u5728\u5176\u5b9e\u9645\u573a\u666f\u4e2d\u5e94\u7528LLM\u7684\u53ef\u884c\u6027\uff0c\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u53c2\u8003\u3002"}}
{"id": "2511.05993", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05993", "abs": "https://arxiv.org/abs/2511.05993", "authors": ["Renren Jin", "Pengzhi Gao", "Yuqi Ren", "Zhuowen Han", "Tongxuan Zhang", "Wuwei Huang", "Wei Liu", "Jian Luan", "Deyi Xiong"], "title": "Revisiting Entropy in Reinforcement Learning for Large Reasoning Models", "comment": "16 pages, 11 figures, 3 tables", "summary": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a predominant approach for enhancing the reasoning capabilities of large language models (LLMs). However, the entropy of LLMs usually collapses during RLVR training, causing premature convergence to suboptimal local minima and hinder further performance improvement. Although various approaches have been proposed to mitigate entropy collapse, a comprehensive study of entropy in RLVR remains lacking. To address this gap, we conduct extensive experiments to investigate the entropy dynamics of LLMs trained with RLVR and analyze how model entropy correlates with response diversity, calibration, and performance across various benchmarks. Our findings reveal that the number of off-policy updates, the diversity of training data, and the clipping thresholds in the optimization objective are critical factors influencing the entropy of LLMs trained with RLVR. Moreover, we theoretically and empirically demonstrate that tokens with positive advantages are the primary contributors to entropy collapse, and that model entropy can be effectively regulated by adjusting the relative loss weights of tokens with positive and negative advantages during training.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86RLVR\u8bad\u7ec3\u4e0b\u5927\u8bed\u8a00\u6a21\u578b\u7684\u71b5\u52a8\u6001\uff0c\u53d1\u73b0off-policy\u66f4\u65b0\u3001\u8bad\u7ec3\u6570\u636e\u591a\u6837\u6027\u53ca\u635f\u5931\u526a\u5207\u9608\u503c\u663e\u8457\u5f71\u54cd\u71b5\uff0c\u6b63\u4f18\u52bftoken\u662f\u5bfc\u81f4\u71b5\u5d29\u584c\u7684\u5173\u952e\u3002\u901a\u8fc7\u8c03\u6574\u635f\u5931\u6743\u91cd\u53ef\u6709\u6548\u8c03\u63a7\u71b5\uff0c\u4e3a\u63d0\u5347\u5927\u6a21\u578b\u6027\u80fd\u548c\u591a\u6837\u6027\u63d0\u4f9b\u65b0\u601d\u8def\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4f7f\u7528\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLVR\uff09\u8fdb\u884c\u8bad\u7ec3\u65f6\uff0c\u6a21\u578b\u7684\u71b5\u5f80\u5f80\u8fc5\u901f\u4e0b\u964d\uff0c\u5bfc\u81f4\u6a21\u578b\u65e9\u65e9\u6536\u655b\u5230\u6b20\u4f73\u7684\u5c40\u90e8\u6700\u4f18\u72b6\u6001\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u6027\u80fd\u53d8\u5f97\u56f0\u96be\u3002\u5c3d\u7ba1\u5df2\u6709\u4e00\u4e9b\u65b9\u6cd5\u8bd5\u56fe\u7f13\u89e3\u71b5\u5d29\u584c\u7684\u95ee\u9898\uff0c\u4f46\u5bf9\u4e8eRLVR\u8fc7\u7a0b\u4e2d\u71b5\u53d8\u5316\u7684\u7cfb\u7edf\u6027\u7814\u7a76\u4ecd\u7136\u7f3a\u4e4f\u3002\u8be5\u8bba\u6587\u7684\u52a8\u673a\u5373\u662f\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86\u5927\u91cf\u5b9e\u9a8c\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u4f7f\u7528RLVR\u8bad\u7ec3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u6a21\u578b\u71b5\u7684\u52a8\u6001\u53d8\u5316\uff0c\u5e76\u7814\u7a76\u71b5\u4e0e\u54cd\u5e94\u591a\u6837\u6027\u3001\u6821\u51c6\u53ca\u6027\u80fd\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002\u6b64\u5916\uff0c\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u5bf9\u6bd4\u4e86\u4e0d\u540c\u8bad\u7ec3\u53c2\u6570\u5982off-policy\u66f4\u65b0\u6b21\u6570\u3001\u8bad\u7ec3\u6570\u636e\u591a\u6837\u6027\u3001\u76ee\u6807\u51fd\u6570\u4e2d\u526a\u5207\u9608\u503c\u7b49\u56e0\u7d20\u5bf9\u6a21\u578b\u71b5\u7684\u5177\u4f53\u5f71\u54cd\uff0c\u5e76\u8fdb\u4e00\u6b65\u5173\u6ce8\u6b63\u4f18\u52bftoken\u5728\u71b5\u5d29\u584c\u4e2d\u7684\u4f5c\u7528\uff0c\u901a\u8fc7\u8c03\u6574\u6b63\u8d1f\u4f18\u52bftoken\u7684\u635f\u5931\u6743\u91cd\u6765\u8c03\u63a7\u6a21\u578b\u71b5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1aoff-policy\u66f4\u65b0\u6b21\u6570\u3001\u8bad\u7ec3\u6570\u636e\u591a\u6837\u6027\u3001\u635f\u5931\u51fd\u6570\u4e2d\u7684\u526a\u5207\u9608\u503c\u662f\u5f71\u54cdRLVR\u8bad\u7ec3\u540e\u6a21\u578b\u71b5\u7684\u5173\u952e\u56e0\u7d20\u3002\u7406\u8bba\u548c\u5b9e\u9a8c\u7ed3\u679c\u5747\u8868\u660e\uff0c\u62e5\u6709\u6b63\u4f18\u52bf\u7684token\u662f\u5bfc\u81f4\u71b5\u5d29\u584c\u7684\u4e3b\u8981\u8d21\u732e\u8005\uff0c\u4e14\u901a\u8fc7\u8c03\u6574\u8fd9\u4e9btoken\u548c\u8d1f\u4f18\u52bftoken\u5728\u635f\u5931\u51fd\u6570\u4e2d\u7684\u6743\u91cd\uff0c\u53ef\u4ee5\u6709\u6548\u5b9e\u73b0\u5bf9\u6a21\u578b\u71b5\u7684\u8c03\u8282\u3002", "conclusion": "\u8bba\u6587\u7cfb\u7edf\u63ed\u793a\u4e86RLVR\u5927\u6a21\u578b\u8bad\u7ec3\u4e2d\u71b5\u52a8\u6001\u53d8\u5316\u7684\u8fc7\u7a0b\u53ca\u5176\u5f71\u54cd\u56e0\u7d20\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u8c03\u6574\u6b63\u8d1f\u4f18\u52bftoken\u635f\u5931\u6743\u91cd\u4f18\u5316\u71b5\u3001\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u548c\u54cd\u5e94\u591a\u6837\u6027\u7684\u6709\u6548\u65b9\u6cd5\u3002\u4e3a\u540e\u7eedRLVR\u9886\u57df\u7684\u4f18\u5316\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u548c\u5b9e\u8df5\u53c2\u8003\u3002"}}
{"id": "2511.06501", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.06501", "abs": "https://arxiv.org/abs/2511.06501", "authors": ["Antu Saha", "Mehedi Sun", "Oscar Chaparro"], "title": "Automatically Identifying Solution-Related Content in Issue Report Discussions with Language Models", "comment": "34 pages, 4 figures", "summary": "During issue resolution, software developers rely on issue reports to discuss solutions for defects, feature requests, and other changes. These discussions contain proposed solutions-from design changes to code implementations-as well as their evaluations. Locating solution-related content is essential for investigating reopened issues, addressing regressions, reusing solutions, and understanding code change rationale. Manually understanding long discussions to identify such content can be difficult and time-consuming.\n  This paper automates solution identification using language models as supervised classifiers. We investigate three applications-embeddings, prompting, and fine-tuning-across three classifier types: traditional ML models (MLMs), pre-trained language models (PLMs), and large language models (LLMs). Using 356 Mozilla Firefox issues, we created a dataset to train and evaluate six MLMs, four PLMs, and two LLMs across 68 configurations.\n  Results show that MLMs with LLM embeddings outperform TF-IDF features, prompting underperforms, and fine-tuned LLMs achieve the highest performance, with LLAMAft reaching 0.716 F1 score. Ensembles of the best models further improve results (0.737 F1). Misclassifications often arise from misleading clues or missing context, highlighting the need for context-aware classifiers. Models trained on Mozilla transfer to other projects, with a small amount of project-specific data, further enhancing results. This work supports software maintenance, issue understanding, and solution reuse.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u8bc6\u522b\u95ee\u9898\u62a5\u544a\u8ba8\u8bba\u4e2d\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u548c\u6280\u672f\uff0c\u5fae\u8c03LLM\u548c\u96c6\u6210\u6a21\u578b\u6548\u679c\u6700\u4f73\uff0c\u53ef\u63d0\u5347\u8f6f\u4ef6\u7ef4\u62a4\u548c\u7406\u89e3\u6548\u7387\uff0c\u4e14\u5177\u826f\u597d\u8fc1\u79fb\u80fd\u529b\u3002", "motivation": "\u8f6f\u4ef6\u5f00\u53d1\u8005\u5728\u89e3\u51b3\u95ee\u9898\u65f6\uff0c\u9700\u5728\u6f2b\u957f\u8ba8\u8bba\u4e2d\u8bc6\u522b\u65b9\u6848\u76f8\u5173\u5185\u5bb9\uff0c\u624b\u5de5\u8fc7\u7a0b\u96be\u4e14\u8d39\u65f6\u3002\u81ea\u52a8\u8bc6\u522b\u6b64\u5185\u5bb9\uff0c\u5c06\u6709\u52a9\u4e8e\u5904\u7406\u95ee\u9898\u91cd\u5f00\u3001\u56de\u5f52\u3001\u65b9\u6848\u590d\u7528\u53ca\u7406\u89e3\u4ee3\u7801\u53d8\u66f4\u539f\u56e0\u3002", "method": "\u672c\u6587\u63d0\u51fa\u7528\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u76d1\u7763\u5206\u7c7b\u5668\u81ea\u52a8\u8bc6\u522b\u95ee\u9898\u8ba8\u8bba\u4e2d\u7684\u89e3\u51b3\u65b9\u6848\u5185\u5bb9\u3002\u5206\u522b\u63a2\u7d22\u5d4c\u5165\u3001\u63d0\u793a\u3001\u5fae\u8c03\u4e09\u79cd\u65b9\u6848\uff0c\u5e76\u5728\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3001\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u3001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e09\u7c7b\u5206\u7c7b\u5668\u4e0a\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002\u4f7f\u7528356\u4e2aMozilla Firefox\u95ee\u9898\u62a5\u544a\u6784\u5efa\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u5e76\u8bc4\u4ef7\u516d\u79cdMLM\u3001\u56db\u79cdPLM\u548c\u4e24\u79cdLLM\u517168\u79cd\u914d\u7f6e\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a\u91c7\u7528LLM\u5d4c\u5165\u7684MLM\u4f18\u4e8eTF-IDF\u7279\u5f81\uff1b\u63d0\u793a\u65b9\u6cd5\u6548\u679c\u8f83\u5dee\uff1b\u5fae\u8c03LLM\u53d6\u5f97\u6700\u4f73\u6027\u80fd\uff0cLLAMAft F1\u503c\u8fbe0.716\u3002\u6700\u4f73\u6a21\u578b\u96c6\u6210\u63d0\u5347\u81f30.737 F1\u3002\u8bef\u5224\u4e3b\u8981\u56e0\u7ebf\u7d22\u8bef\u5bfc\u6216\u8bed\u5883\u7f3a\u5931\uff0c\u9700\u8bed\u5883\u611f\u77e5\u5206\u7c7b\u5668\u3002\u6a21\u578b\u53ef\u8fc1\u79fb\u5230\u5176\u4ed6\u9879\u76ee\uff0c\u5c11\u91cf\u9879\u76ee\u7279\u5b9a\u6570\u636e\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u6548\u679c\u3002", "conclusion": "\u81ea\u52a8\u65b9\u6848\u8bc6\u522b\u652f\u6301\u8f6f\u4ef6\u7ef4\u62a4\u3001\u95ee\u9898\u7406\u89e3\u4e0e\u65b9\u6848\u590d\u7528\u3002\u63d0\u51fa\u7684\u5206\u7c7b\u65b9\u6cd5\u5728\u591a\u4e2a\u6a21\u578b\u548c\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u662f\u5fae\u8c03LLM\u548c\u96c6\u6210\u6a21\u578b\uff0c\u4e14\u5177\u8f83\u597d\u9886\u57df\u8fc1\u79fb\u80fd\u529b\u3002"}}
{"id": "2511.06000", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06000", "abs": "https://arxiv.org/abs/2511.06000", "authors": ["Favour Yahdii Aghaebe", "Tanefa Apekey", "Elizabeth Williams", "Nafise Sadat Moosavi"], "title": "LLMs Do Not See Age: Assessing Demographic Bias in Automated Systematic Review Synthesis", "comment": "Accepted at AACL 2025", "summary": "Clinical interventions often hinge on age: medications and procedures safe for adults may be harmful to children or ineffective for older adults. However, as language models are increasingly integrated into biomedical evidence synthesis workflows, it remains uncertain whether these systems preserve such crucial demographic distinctions. To address this gap, we evaluate how well state-of-the-art language models retain age-related information when generating abstractive summaries of biomedical studies. We construct DemogSummary, a novel age-stratified dataset of systematic review primary studies, covering child, adult, and older adult populations. We evaluate three prominent summarisation-capable LLMs, Qwen (open-source), Longformer (open-source) and GPT-4.1 Nano (proprietary), using both standard metrics and a newly proposed Demographic Salience Score (DSS), which quantifies age-related entity retention and hallucination. Our results reveal systematic disparities across models and age groups: demographic fidelity is lowest for adult-focused summaries, and under-represented populations are more prone to hallucinations. These findings highlight the limitations of current LLMs in faithful and bias-free summarisation and point to the need for fairness-aware evaluation frameworks and summarisation pipelines in biomedical NLP.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u73b0\uff0c\u4e3b\u6d41\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u751f\u7269\u533b\u5b66\u7814\u7a76\u5e74\u9f84\u76f8\u5173\u6458\u8981\u65b9\u9762\u5b58\u5728\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u4e22\u5931\u548c\u504f\u5dee\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u6210\u4eba\u7ec4\u8868\u73b0\u6700\u5dee\uff0c\u5bf9\u5f31\u52bf\u6216\u4ee3\u8868\u6027\u4e0d\u8db3\u4eba\u7fa4\u66f4\u6613\u4ea7\u751f\u5e7b\u89c9\u3002\u8fd9\u4e00\u73b0\u8c61\u63d0\u793a\u4e9f\u9700\u9488\u5bf9\u516c\u5e73\u6027\u7684\u8bc4\u4f30\u548c\u4f18\u5316\u65b9\u6848\u3002", "motivation": "\u4e34\u5e8a\u5e72\u9884\u901a\u5e38\u4f9d\u8d56\u4e8e\u5e74\u9f84\u56e0\u7d20\uff0c\u4e0d\u540c\u5e74\u9f84\u6bb5\u7684\u60a3\u8005\u9762\u4e34\u836f\u7269\u548c\u6cbb\u7597\u65b9\u6cd5\u7684\u5b89\u5168\u6027\u6311\u6218\u3002\u968f\u7740\u8bed\u8a00\u6a21\u578b\u5728\u751f\u7269\u533b\u5b66\u8bc1\u636e\u7efc\u5408\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u5e94\u7528\uff0c\u5c1a\u4e0d\u6e05\u695a\u8fd9\u4e9b\u7cfb\u7edf\u662f\u5426\u80fd\u591f\u4fdd\u7559\u5173\u952e\u7684\u4eba\u53e3\u7edf\u8ba1\u5b66\u533a\u5206\uff08\u5982\u5e74\u9f84\u4fe1\u606f\uff09\u3002\u672c\u6587\u65e8\u5728\u8bc4\u4f30\u6700\u65b0\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u751f\u7269\u533b\u5b66\u7814\u7a76\u6458\u8981\u65f6\u5bf9\u5e74\u9f84\u76f8\u5173\u4fe1\u606f\u7684\u4fdd\u6301\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u5e74\u9f84\u5206\u5c42\u7cfb\u7edf\u7efc\u8ff0\u539f\u59cb\u7814\u7a76\u6570\u636e\u96c6DemogSummary\uff0c\u8986\u76d6\u513f\u7ae5\u3001\u6210\u4eba\u548c\u8001\u5e74\u4eba\u7fa4\u3002\u9488\u5bf9Qwen\u3001Longformer\u548cGPT-4.1 Nano\u4e09\u4e2a\u4e3b\u6d41\u6709\u6458\u8981\u80fd\u529b\u7684\u5927\u6a21\u578b\uff0c\u91c7\u7528\u6807\u51c6\u8bc4\u4ef7\u6307\u6807\u53ca\u65b0\u63d0\u51fa\u7684\u4eba\u53e3\u7edf\u8ba1\u663e\u8457\u6027\u8bc4\u5206\uff08Demographic Salience Score, DSS\uff09\uff0c\u91cf\u5316\u6a21\u578b\u5bf9\u5e74\u9f84\u5b9e\u4f53\u7684\u4fdd\u7559\u548c\u5e7b\u89c9\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u4e09\u4e2a\u6a21\u578b\u5728\u4e0d\u540c\u5e74\u9f84\u7fa4\u4f53\u4e0b\u5448\u73b0\u51fa\u7cfb\u7edf\u6027\u5dee\u5f02\uff1a\u57fa\u4e8e\u6210\u4eba\u7684\u6458\u8981\u5728\u4eba\u53e3\u7edf\u8ba1\u4fdd\u771f\u5ea6\u65b9\u9762\u6700\u4f4e\uff0c\u4e14\u5728\u4fe1\u606f\u8d2b\u4e4f\u7684\u5e74\u9f84\u7fa4\u4f53\uff08\u5982\u8001\u5e74\u4eba\u548c\u513f\u7ae5\uff09\u66f4\u6613\u4ea7\u751f\u4fe1\u606f\u5e7b\u89c9\u3002", "conclusion": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u51c6\u786e\u3001\u65e0\u504f\u89c1\u5730\u751f\u6210\u751f\u7269\u533b\u5b66\u6458\u8981\u65f6\u5728\u4fdd\u7559\u5173\u952e\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u65b9\u9762\u5b58\u5728\u660e\u663e\u5c40\u9650\u6027\uff0c\u4e9f\u9700\u5f00\u53d1\u66f4\u52a0\u5173\u6ce8\u516c\u5e73\u6027\u7684\u8bc4\u4ef7\u6846\u67b6\u548c\u603b\u7ed3\u6d41\u7a0b\u3002"}}
{"id": "2511.06552", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06552", "abs": "https://arxiv.org/abs/2511.06552", "authors": ["Mostafijur Rahman Akhond", "Saikat Chakraborty", "Gias Uddin"], "title": "LLM For Loop Invariant Generation and Fixing: How Far Are We?", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "A loop invariant is a property of a loop that remains true before and after each execution of the loop. The identification of loop invariants is a critical step to support automated program safety assessment. Recent advancements in Large Language Models (LLMs) have demonstrated potential in diverse software engineering (SE) and formal verification tasks. However, we are not aware of the performance of LLMs to infer loop invariants. We report an empirical study of both open-source and closed-source LLMs of varying sizes to assess their proficiency in inferring inductive loop invariants for programs and in fixing incorrect invariants. Our findings reveal that while LLMs exhibit some utility in inferring and repairing loop invariants, their performance is substantially enhanced when supplemented with auxiliary information such as domain knowledge and illustrative examples. LLMs achieve a maximum success rate of 78\\% in generating, but are limited to 16\\% in repairing the invariant.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7a0b\u5e8f\u5faa\u73af\u4e0d\u53d8\u5f0f\u63a8\u65ad\u4e0e\u4fee\u590d\u4e0a\u7684\u5e94\u7528\u80fd\u529b\uff0c\u53d1\u73b0\u5176\u867d\u6709\u4e00\u5b9a\u6f5c\u529b\uff0c\u4f46\u5728\u6ca1\u6709\u8f85\u52a9\u4fe1\u606f\u65f6\u6548\u679c\u6709\u9650\uff0c\u5c24\u5176\u5728\u4fee\u590d\u4e0d\u53d8\u5f0f\u65b9\u9762\uff0c\u6210\u529f\u7387\u8f83\u4f4e\u3002", "motivation": "\u5faa\u73af\u4e0d\u53d8\u5f0f\u8bc6\u522b\u662f\u81ea\u52a8\u5316\u7a0b\u5e8f\u5b89\u5168\u6027\u8bc4\u4f30\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u76ee\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u53ca\u5f62\u5f0f\u5316\u9a8c\u8bc1\u9886\u57df\u5c55\u73b0\u4e86\u6f5c\u529b\uff0c\u4f46\u5c1a\u672a\u6709\u7cfb\u7edf\u7814\u7a76\u5176\u5728\u63a8\u65ad\u5faa\u73af\u4e0d\u53d8\u5f0f\u65b9\u9762\u7684\u80fd\u529b\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u4f5c\u8005\u5bf9\u591a\u79cd\u5f00\u6e90\u53ca\u95ed\u6e90\u3001\u89c4\u6a21\u5404\u5f02\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc4\u4f30\u5176\u63a8\u65ad\u7a0b\u5e8f\u5f52\u7eb3\u5f0f\u5faa\u73af\u4e0d\u53d8\u5f0f\u4e0e\u4fee\u6b63\u9519\u8bef\u4e0d\u53d8\u5f0f\u7684\u80fd\u529b\u3002\u540c\u65f6\u8003\u5bdf\u5728\u8f85\u52a9\u4fe1\u606f\uff08\u5982\u9886\u57df\u77e5\u8bc6\u3001\u4f8b\u5b50\uff09\u7684\u8865\u5145\u4e0b\u6027\u80fd\u53d8\u5316\u3002", "result": "\u5728\u63a8\u65ad\u548c\u4fee\u590d\u5faa\u73af\u4e0d\u53d8\u5f0f\u65b9\u9762\uff0cLLMs\u6709\u4e00\u5b9a\u5b9e\u7528\u6027\u3002\u8865\u5145\u8f85\u52a9\u4fe1\u606f\u540e\uff0c\u8868\u73b0\u660e\u663e\u63d0\u5347\u3002\u63a8\u65ad\u5faa\u73af\u4e0d\u53d8\u5f0f\u7684\u6700\u5927\u6210\u529f\u7387\u4e3a78%\uff0c\u4fee\u590d\u9519\u8bef\u4e0d\u53d8\u5f0f\u7684\u6210\u529f\u7387\u4ec5\u4e3a16%\u3002", "conclusion": "LLMs\u5728\u63a8\u65ad\u5faa\u73af\u4e0d\u53d8\u5f0f\u9886\u57df\u5c55\u793a\u4e86\u4e00\u5b9a\u4ef7\u503c\uff0c\u4f46\u82e5\u4ec5\u4f9d\u8d56\u5176\u81ea\u8eab\u80fd\u529b\uff0c\u8868\u73b0\u4ecd\u6709\u9650\u3002\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u548c\u793a\u4f8b\u7b49\u8f85\u52a9\u4fe1\u606f\u53ef\u63d0\u5347\u6548\u679c\uff0c\u4e14\u4fee\u590d\u9519\u8bef\u4e0d\u53d8\u5f0f\u7684\u80fd\u529b\u76ee\u524d\u4ecd\u8f83\u5f31\u3002"}}
{"id": "2511.06023", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06023", "abs": "https://arxiv.org/abs/2511.06023", "authors": ["Deng Yixuan", "Ji Xiaoqiang"], "title": "Multi-Reward GRPO Fine-Tuning for De-biasing Large Language Models: A Study Based on Chinese-Context Discrimination Data", "comment": null, "summary": "Large Language Models (LLMs) often exhibit implicit biases and discriminatory tendencies that reflect underlying social stereotypes. While recent alignment techniques such as RLHF and DPO have mitigated some of these issues, they remain limited in addressing culturally specific and multi-dimensional forms of discrimination. This paper proposes a Multi-Reward Group Relative Policy Optimization (GRPO) framework to fine-tune LLMs toward ethical and bias-free behavior. Our approach constructs a synthetic English-language dataset derived from Chinese-context discrimination categories, including regional, ethnic, and occupational biases. Each instance is paired with both neutral and biased responses to train a reward model based on DeBERTa-v3, which provides multi-dimensional reward signals capturing fairness, neutrality, and linguistic quality. The trained reward model then guides GRPO fine-tuning to optimize model outputs along these ethical dimensions. Experimental results demonstrate significant reductions in bias intensity and improved alignment with non-discriminatory standards without compromising fluency or informativeness. This study highlights the effectiveness of GRPO-based multi-reward optimization for de-biasing LLMs and offers a replicable framework for cultural-contextual ethical alignment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGRPO\u591a\u5956\u52b1\u4f18\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u7ef4\u516c\u5e73\u6027\u5956\u52b1\u4fe1\u53f7\uff0c\u6709\u6548\u51cf\u5c11LLM\u6587\u5316\u8bed\u5883\u4e0b\u591a\u7ef4\u6b67\u89c6\u504f\u89c1\uff0c\u4fdd\u969c\u6a21\u578b\u6d41\u7545\u6027\u4e0e\u4fe1\u606f\u6027\uff0c\u5bf9LLM\u4f26\u7406\u5bf9\u9f50\u95ee\u9898\u63d0\u4f9b\u65b0\u601d\u8def\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u867d\u7136\u901a\u8fc7\u6700\u65b0\u7684\u5bf9\u9f50\u6280\u672f\uff08\u5982RLHF\u548cDPO\uff09\u7f13\u89e3\u4e86\u90e8\u5206\u504f\u89c1\u95ee\u9898\uff0c\u4f46\u5728\u5904\u7406\u5177\u6709\u6587\u5316\u7279\u6b8a\u6027\u3001\u591a\u7ef4\u5ea6\u7684\u6b67\u89c6\u65b9\u9762\u4ecd\u6709\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u5956\u52b1\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u6846\u67b6\uff1a\u9996\u5148\u6784\u5efa\u4ee5\u4e2d\u6587\u8bed\u5883\u6b67\u89c6\u7c7b\u522b\u4e3a\u57fa\u7840\u7684\u82f1\u6587\u6570\u636e\u96c6\uff0c\u5305\u62ec\u5730\u57df\u3001\u65cf\u7fa4\u53ca\u804c\u4e1a\u504f\u89c1\uff1b\u7528\u4e2d\u6027\u4e0e\u5e26\u504f\u89c1\u7684\u56de\u5e94\u5bf9\u6bcf\u4e2a\u5b9e\u4f8b\u8fdb\u884c\u914d\u5bf9\uff0c\u8bad\u7ec3\u4ee5DeBERTa-v3\u4e3a\u57fa\u7840\u7684\u5956\u52b1\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u540c\u65f6\u8003\u8651\u516c\u5e73\u6027\u3001\u4e2d\u7acb\u6027\u548c\u8bed\u8a00\u8d28\u91cf\u7b49\u591a\u7ef4\u5ea6\u5956\u52b1\u4fe1\u53f7\uff0c\u6307\u5bfcGRPO\u8fdb\u884c\u6a21\u578b\u5fae\u8c03\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u901a\u8fc7\u591a\u7ef4\u5ea6\u5956\u52b1\u4fe1\u53f7\u6307\u5bfc\u5fae\u8c03\uff0c\u4e0d\u5f71\u54cd\u6d41\u7545\u6027\u548c\u4fe1\u606f\u4e30\u5bcc\u6027\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u6a21\u578b\u504f\u89c1\u5f3a\u5ea6\uff0c\u63d0\u5347\u4e86\u5176\u4e0e\u975e\u6b67\u89c6\u6807\u51c6\u7684\u7b26\u5408\u5ea6\u3002", "conclusion": "GRPO\u591a\u5956\u52b1\u4f18\u5316\u673a\u5236\u5728LLM\u53bb\u504f\u89c1\u65b9\u9762\u6548\u679c\u663e\u8457\uff0c\u4e3a\u6a21\u578b\u5b9e\u73b0\u6587\u5316\u548c\u8bed\u5883\u76f8\u5173\u7684\u4f26\u7406\u5bf9\u9f50\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2511.06661", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.06661", "abs": "https://arxiv.org/abs/2511.06661", "authors": ["Tapti Palit", "Seyedhamed Ghavamnia", "Michalis Polychronakis"], "title": "PhaseSeed: Precise Call Graph Construction for Split-Phase Applications using Dynamic Seeding", "comment": null, "summary": "Precise and sound call graph construction is crucial for many software security mechanisms. Unfortunately, traditional static pointer analysis techniques used to generate application call graphs suffer from imprecision. These techniques are agnostic to the application's architecture and are designed for broad applicability. To mitigate this precision problem, we propose PhaseSeed, a novel technique that improves the accuracy of pointer analysis for split-phase applications, which have distinct initialization and processing phases. PhaseSeed analyzes the initialization phase dynamically, collecting the points-to relationships established at runtime. At the end of the initialization phase, it then seeds this information to a static analysis stage that performs pointer analysis for all code that stays in scope during the processing phase, improving precision. Our observations show that, given the same runtime configuration options, the points-to relationships established during the initialization phase remain constant across multiple runs. Therefore, PhaseSeed is sound with respect to a given initial configuration. We apply PhaseSeed to three security mechanisms: control flow integrity (CFI), software debloating, and system call filtering. PhaseSeed provides up to 92.6% precision improvement for CFI compared to static call graph construction techniques, and filters nine additional security-critical system calls when used to generate Seccomp profiles.", "AI": {"tldr": "PhaseSeed\u901a\u8fc7\u5148\u52a8\u6001\u5206\u6790\u521d\u59cb\u5316\u9636\u6bb5\u3001\u518d\u9759\u6001\u5206\u6790\u5904\u7406\u9636\u6bb5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5206\u9636\u6bb5\u5e94\u7528\u7684\u6307\u9488\u5206\u6790\u548c\u8c03\u7528\u56fe\u6784\u5efa\u7cbe\u5ea6\uff0c\u5728\u591a\u4e2a\u5b89\u5168\u673a\u5236\u573a\u666f\uff08\u5982CFI\u3001\u8f6f\u4ef6\u7626\u8eab\u3001\u7cfb\u7edf\u8c03\u7528\u8fc7\u6ee4\uff09\u4e2d\u90fd\u6709\u663e\u8457\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u7684\u9759\u6001\u6307\u9488\u5206\u6790\u6280\u672f\u5728\u5e94\u7528\u7a0b\u5e8f\u8c03\u7528\u56fe\u6784\u5efa\u4e2d\u5b58\u5728\u7cbe\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5b83\u4eec\u5ffd\u7565\u4e86\u5e94\u7528\u5206\u9636\u6bb5\uff08\u5982\u521d\u59cb\u5316\u548c\u5904\u7406\u9636\u6bb5\uff09\u7684\u7279\u70b9\u3002\u7814\u7a76\u8005\u5e0c\u671b\u63d0\u5347\u9488\u5bf9\u5206\u9636\u6bb5\u5e94\u7528\u7684\u6307\u9488\u5206\u6790\u7cbe\u5ea6\uff0c\u4ee5\u66f4\u597d\u5730\u670d\u52a1\u4e8e\u8f6f\u4ef6\u5b89\u5168\u673a\u5236\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86PhaseSeed\u6280\u672f\uff1a\u5728\u5e94\u7528\u521d\u59cb\u5316\u9636\u6bb5\u901a\u8fc7\u52a8\u6001\u5206\u6790\u6536\u96c6\u8fd0\u884c\u65f6\u5efa\u7acb\u7684points-to\u5173\u7cfb\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u5173\u7cfb\u4f5c\u4e3a\u79cd\u5b50\uff0c\u8f93\u5165\u5230\u9759\u6001\u5206\u6790\u9636\u6bb5\uff0c\u4e13\u6ce8\u5206\u6790\u5904\u7406\u9636\u6bb5\u7684\u6240\u6709\u4ee3\u7801\uff0c\u4ece\u800c\u63d0\u5347\u6307\u9488\u5206\u6790\u7684\u7cbe\u5ea6\u3002", "result": "PhaseSeed\u88ab\u5e94\u7528\u4e8e\u4e09\u79cd\u5b89\u5168\u673a\u5236\uff1a\u63a7\u5236\u6d41\u5b8c\u6574\u6027\uff08CFI\uff09\u3001\u8f6f\u4ef6\u7626\u8eab\u548c\u7cfb\u7edf\u8c03\u7528\u8fc7\u6ee4\u3002\u5728CFI\u573a\u666f\u4e0b\uff0cPhaseSeed\u8f83\u4f20\u7edf\u9759\u6001\u8c03\u7528\u56fe\u6784\u5efa\u6280\u672f\u5c06\u7cbe\u5ea6\u63d0\u5347\u9ad8\u8fbe92.6%\uff1b\u5728Seccomp\u914d\u7f6e\u6587\u4ef6\u751f\u6210\u4e2d\uff0c\u80fd\u591f\u8fc7\u6ee4\u591a9\u4e2a\u5173\u952e\u7cfb\u7edf\u8c03\u7528\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u52a8\u6001\u5206\u6790\u548c\u9759\u6001\u5206\u6790\uff0c\u5229\u7528\u521d\u59cb\u5316\u9636\u6bb5\u7684\u5b9e\u9645points-to\u5173\u7cfb\uff0cPhaseSeed\u663e\u8457\u63d0\u5347\u4e86\u9488\u5bf9\u5206\u9636\u6bb5\u5e94\u7528\u7684\u6307\u9488\u5206\u6790\u7cbe\u5ea6\uff0c\u4e3a\u591a\u7c7b\u5b89\u5168\u673a\u5236\u5e26\u6765\u5b9e\u8d28\u6027\u6539\u8fdb\u3002"}}
{"id": "2511.06048", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06048", "abs": "https://arxiv.org/abs/2511.06048", "authors": ["Xinyuan Yan", "Shusen Liu", "Kowshik Thopalli", "Bei Wang"], "title": "Visual Exploration of Feature Relationships in Sparse Autoencoders with Curated Concepts", "comment": "8 pages (5 main paper+3 refernce), 2 figures, pulished at Mechanistic Interpretability Workshop at NeurIPS 2025", "summary": "Sparse autoencoders (SAEs) have emerged as a powerful tool for uncovering interpretable features in large language models (LLMs) through the sparse directions they learn. However, the sheer number of extracted directions makes comprehensive exploration intractable. While conventional embedding techniques such as UMAP can reveal global structure, they suffer from limitations including high-dimensional compression artifacts, overplotting, and misleading neighborhood distortions. In this work, we propose a focused exploration framework that prioritizes curated concepts and their corresponding SAE features over attempts to visualize all available features simultaneously. We present an interactive visualization system that combines topology-based visual encoding with dimensionality reduction to faithfully represent both local and global relationships among selected features. This hybrid approach enables users to investigate SAE behavior through targeted, interpretable subsets, facilitating deeper and more nuanced analysis of concept representation in latent space.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e13\u6ce8\u6982\u5ff5\u7684\u6df7\u5408\u53ef\u89c6\u5316\u7cfb\u7edf\uff0c\u6539\u5584SAE\u7279\u5f81\u7684\u63a2\u7d22\u4e0e\u5206\u6790\uff0c\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u4e0e\u6548\u7387\u3002", "motivation": "\u9488\u5bf9\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u5b66\u4e60\u5230\u7684\u7279\u5f81\u6570\u91cf\u4f17\u591a\uff0c\u4f20\u7edf\u964d\u7ef4\u6216\u5d4c\u5165\u5de5\u5177\u5b58\u5728\u538b\u7f29\u4f2a\u5f71\u3001\u90bb\u57df\u5931\u771f\u7b49\u95ee\u9898\uff0c\u96be\u4ee5\u9ad8\u6548\u548c\u51c6\u786e\u5730\u63a2\u7d22\u5168\u90e8\u7279\u5f81\uff0c\u9700\u5f00\u53d1\u66f4\u805a\u7126\u548c\u53ef\u89e3\u91ca\u7684\u5206\u6790\u4f53\u7cfb\u3002", "method": "\u4f5c\u8005\u5f00\u53d1\u4e86\u4e00\u4e2a\u6df7\u5408\u53ef\u89c6\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u62d3\u6251\u5b66\u65b9\u6cd5\u548c\u4f20\u7edf\u964d\u7ef4\u6280\u672f\uff0c\u9762\u5411\u7279\u5b9a\u6982\u5ff5\u548c\u7279\u5f81\u96c6\u8fdb\u884c\u9488\u5bf9\u6027\u5c55\u793a\u5206\u6790\uff0c\u800c\u4e0d\u662f\u5bf9\u6240\u6709\u7279\u5f81\u6574\u4f53\u5197\u4f59\u5730\u53ef\u89c6\u5316\u3002", "result": "\u7cfb\u7edf\u80fd\u6709\u6548\u652f\u6301\u7528\u6237\u4ece\u5c40\u90e8\u548c\u5168\u5c40\u89d2\u5ea6\u5206\u6790\u9009\u5b9a\u7279\u5f81\u95f4\u7684\u5173\u7cfb\uff0c\u63d0\u9ad8\u5bf9SAE\u7279\u5f81\u3001\u6982\u5ff5\u8868\u793a\u7684\u7406\u89e3\u6df1\u5ea6\u4e0e\u5206\u6790\u6548\u7387\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e92\u52a8\u53ef\u89c6\u5316\u7cfb\u7edf\uff0c\u5c06\u62d3\u6251\u53ef\u89c6\u5316\u7f16\u7801\u4e0e\u964d\u7ef4\u65b9\u6cd5\u7ed3\u5408\uff0c\u7528\u4e8e\u5206\u6790\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\uff08SAE\uff09\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u7279\u5f81\u8868\u73b0\u3002\u8be5\u7cfb\u7edf\u4f18\u5148\u5c55\u793a\u7ecf\u8fc7\u7b56\u5212\u7684\u6982\u5ff5\u548c\u76f8\u5173SAE\u7279\u5f81\uff0c\u53ef\u66f4\u597d\u5730\u63ed\u793a\u5c40\u90e8\u548c\u5168\u5c40\u7279\u5f81\u5173\u7cfb\u3002"}}
{"id": "2511.06701", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.06701", "abs": "https://arxiv.org/abs/2511.06701", "authors": ["Karen Sargsyan"], "title": "Structural Enforcement of Statistical Rigor in AI-Driven Discovery: A Functional Architecture", "comment": null, "summary": "Sequential statistical protocols require meticulous state management and robust error handling -- challenges naturally suited to functional programming. We present a functional architecture for structural enforcement of statistical rigor in automated research systems (AI-Scientists). These LLM-driven systems risk generating spurious discoveries through dynamic hypothesis testing. We introduce the Research monad, a Haskell eDSL that enforces sequential statistical protocols (e.g., Online FDR (false discovery rate) control) using a monad transformer stack. To address risks in hybrid architectures where LLMs generate imperative code, we employ Declarative Scaffolding -- generating rigid harnesses that structurally constrain execution and prevent methodological errors like data leakage. We validate this approach through large-scale simulation (N=2000 hypotheses) and an end-to-end case study, demonstrating essential defense-in-depth for automated science integrity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528Haskell\u51fd\u6570\u5f0f\u67b6\u6784\u548c\u58f0\u660e\u6027\u6846\u67b6\uff0c\u7ed3\u6784\u6027\u4fdd\u969cAI\u79d1\u5b66\u7cfb\u7edf\u5728\u987a\u5e8f\u7edf\u8ba1\u534f\u8bae\u4e0b\u7684\u4e25\u8c28\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u9632\u6b62\u81ea\u52a8\u7814\u7a76\u4e2d\u7684\u7edf\u8ba1\u9519\u8bef\uff0c\u662f\u63d0\u5347\u81ea\u52a8\u79d1\u5b66\u8bda\u4fe1\u7684\u91cd\u8981\u9632\u7ebf\u3002", "motivation": "\u5728\u81ea\u52a8\u5316\u7814\u7a76\u7cfb\u7edf\uff08\u5982AI\u79d1\u5b66\u5bb6\uff09\u4e2d\uff0c\u987a\u5e8f\u7edf\u8ba1\u534f\u8bae\u9700\u8981\u7cbe\u786e\u7684\u72b6\u6001\u7ba1\u7406\u548c\u9519\u8bef\u5904\u7406\uff0c\u73b0\u6709\u7cfb\u7edf\u5f88\u5bb9\u6613\u56e0\u52a8\u6001\u5047\u8bbe\u68c0\u9a8c\u800c\u51fa\u73b0\u865a\u5047\u53d1\u73b0\u3002\u4f5c\u8005\u8ba4\u4e3a\u5f53\u524d\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8f85\u52a9\u79d1\u5b66\u53d1\u73b0\u65f6\uff0c\u7edf\u8ba1\u4e25\u8c28\u6027\u548c\u7ed3\u679c\u53ef\u4fe1\u6027\u4e9f\u9700\u7ed3\u6784\u6027\u4fdd\u969c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u51fd\u6570\u5f0f\u7f16\u7a0b\u7684\u201cResearch monad\u201d\uff08\u7814\u7a76\u5355\u5b50\uff09\u67b6\u6784\uff0c\u8fd9\u662f\u4e00\u79cdHaskell\u4e0a\u7684\u5d4c\u5165\u5f0f\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08eDSL\uff09\uff0c\u5229\u7528monad\u53d8\u6362\u5668\u6808\u5f3a\u5236\u9075\u5faa\u987a\u5e8f\u7edf\u8ba1\u534f\u8bae\uff08\u5982\u5728\u7ebfFDR\u63a7\u5236\uff09\u3002\u6b64\u5916\uff0c\u4f7f\u7528\u201c\u58f0\u660e\u6027\u811a\u624b\u67b6\u201d\u65b9\u6cd5\uff0c\u751f\u6210\u7ed3\u6784\u6027\u4e25\u683c\u7684\u7a0b\u5e8f\u6846\u67b6\uff0c\u6765\u7ea6\u675f\u7531LLM\u81ea\u52a8\u751f\u6210\u7684\u547d\u4ee4\u5f0f\u4ee3\u7801\uff0c\u9632\u6b62\u5982\u6570\u636e\u6cc4\u9732\u7b49\u65b9\u6cd5\u5b66\u9519\u8bef\u3002", "result": "\u901a\u8fc7\u5927\u89c4\u6a21\u4eff\u771f\u5b9e\u9a8c\uff08N=2000\u4e2a\u5047\u8bbe\uff09\u548c\u7aef\u5230\u7aef\u6848\u4f8b\u5206\u6790\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u9632\u8303\u81ea\u52a8\u5316\u79d1\u5b66\u53d1\u73b0\u4e2d\u7684\u7edf\u8ba1\u4e0d\u4e25\u8c28\u95ee\u9898\uff0c\u63d0\u5347\u7cfb\u7edf\u6574\u4f53\u7684\u79d1\u5b66\u8bda\u4fe1\u3002", "conclusion": "\u7ed3\u5408\u51fd\u6570\u5f0f\u67b6\u6784\u548c\u58f0\u660e\u6027\u811a\u624b\u67b6\u80fd\u591f\u4e3aAI\u79d1\u5b66\u5bb6\u7684\u81ea\u52a8\u7814\u7a76\u7cfb\u7edf\u63d0\u4f9b\u7ed3\u6784\u6027\u9632\u62a4\uff0c\u6709\u6548\u907f\u514d\u865a\u5047\u53d1\u73b0\u548c\u7edf\u8ba1\u8bef\u7528\uff0c\u5f3a\u5316\u81ea\u52a8\u79d1\u5b66\u53d1\u73b0\u7684\u4e25\u8c28\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2511.06051", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.06051", "abs": "https://arxiv.org/abs/2511.06051", "authors": ["Mahmoud El-Bahnasawi"], "title": "Efficient Hate Speech Detection: A Three-Layer LoRA-Tuned BERTweet Framework", "comment": "13 pages, 2 figures", "summary": "This paper addresses the critical challenge of developing computationally efficient hate speech detection systems that maintain competitive performance while being practical for real-time deployment. We propose a novel three-layer framework that combines rule-based pre-filtering with a parameter-efficient LoRA-tuned BERTweet model and continuous learning capabilities. Our approach achieves 0.85 macro F1 score - representing 94% of the performance of state-of-the-art large language models like SafePhi (Phi-4 based) while using a base model that is 100x smaller (134M vs 14B parameters). Compared to traditional BERT-based approaches with similar computational requirements, our method demonstrates superior performance through strategic dataset unification and optimized fine-tuning. The system requires only 1.87M trainable parameters (1.37% of full fine-tuning) and trains in approximately 2 hours on a single T4 GPU, making robust hate speech detection accessible in resource-constrained environments while maintaining competitive accuracy for real-world deployment.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u4e09\u5c42\u9ad8\u6548\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u7cfb\u7edf\uff0c\u4ee5\u6781\u4f4e\u53c2\u6570\u548c\u8bad\u7ec3\u65f6\u95f4\u5b9e\u73b0\u63a5\u8fd1\u5927\u6a21\u578b\u7684\u6027\u80fd\uff0c\u517c\u987e\u6613\u7528\u6027\u3001\u5b9e\u65f6\u6027\u548c\u51c6\u786e\u7387\uff0c\u9002\u5408\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u5f00\u53d1\u80fd\u591f\u5b9e\u65f6\u90e8\u7f72\u3001\u5728\u7b97\u529b\u6709\u9650\u73af\u5883\u4e0b\u4f9d\u7136\u8868\u73b0\u4f18\u5f02\u7684\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u7cfb\u7edf\uff0c\u4ee5\u5e94\u5bf9\u5927\u6a21\u578b\u7b97\u529b\u6d88\u8017\u5927\u3001\u4e0d\u9002\u5408\u5b9e\u9645\u5e94\u7528\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e09\u5c42\u67b6\u6784\uff1a\u9996\u5148\u5229\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u9884\u7b5b\u67e5\uff1b\u7136\u540e\u5f15\u5165\u4f4e\u53c2\u6570\u91cf\u3001\u901a\u8fc7LoRA\u5fae\u8c03\u7684BERTweet\u6a21\u578b\uff1b\u540c\u65f6\u652f\u6301\u6301\u7eed\u5b66\u4e60\u80fd\u529b\u3002\u901a\u8fc7\u6570\u636e\u96c6\u6574\u5408\u4e0e\u4f18\u5316\u5fae\u8c03\u63d0\u5347\u6574\u4f53\u6027\u80fd\u3002", "result": "\u7cfb\u7edf\u5728\u4f7f\u7528\u8fdc\u5c0f\u4e8e\u4e3b\u6d41\u5927\u6a21\u578b\u53c2\u6570\u91cf\uff08134M\u5bf9\u6bd414B\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e860.85\u7684macro F1\u5206\u6570\uff0c\u8fbe\u5230SafePhi\uff08\u4e00\u79cdPhi-4\u5927\u6a21\u578b\uff0994%\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u8f83\u540c\u53c2\u6570\u7ea7\u522b\u7684BERT\u57fa\u7ebf\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\u3002\u8bad\u7ec3\u4ec5\u97001.87M\u53ef\u8bad\u7ec3\u53c2\u6570\u30012\u5c0f\u65f6\uff08T4\uff09\uff0c\u9002\u5408\u4f4e\u8d44\u6e90\u73af\u5883\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6781\u5927\u964d\u4f4e\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u7684\u524d\u63d0\u4e0b\uff0c\u4fdd\u6301\u4e86\u4e0e\u5927\u89c4\u6a21\u6a21\u578b\u76f8\u8fd1\u7684\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u9002\u5408\u5b9e\u9645\u90e8\u7f72\uff0c\u53ef\u63a8\u5e7f\u81f3\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u3002"}}
{"id": "2511.06762", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.06762", "abs": "https://arxiv.org/abs/2511.06762", "authors": ["Rui Lu", "Lyuye Zhang", "Kaixuan Li", "Min Zhang", "Yixiang Chen"], "title": "Minimizing Breaking Changes and Redundancy in Mitigating Technical Lag for Java Projects", "comment": "ICSE26 accepted paper", "summary": "Re-using open-source software (OSS) can avoid reinventing the wheel, but failing to keep it up-to-date can lead to missing new features and persistent bugs or vulnerabilities that have already been resolved. The use of outdated OSS libraries introduces technical lag, necessitating timely upgrades. However, maintaining up-to-date libraries is challenging, as it may introduce incompatibility issues that break the project or redundant dependencies that unnecessarily increase the size of the project. These issues discourage developers from upgrading libraries, highlighting the need for a fully automated solution that balances version upgrades, reduces technical lag, ensures compatibility, and avoids redundant dependencies.\n  To this end, we propose DepUpdater, which ensures that upgrades minimize technical lag as much as possible while avoiding incompatibility issues and redundant dependencies. The comparison with existing dependency management tools demonstrates that DepUpdater more effectively reduces technical lag while ensuring compatibility and pruning redundant dependencies. Additionally, an ablation study highlights the potential benefits of considering pruning requirements during upgrades to mitigate incompatibility issues. Finally, leveraging DepUpdater, we investigate the impact of transitive dependency upgrades on client compatibility, providing insights for future research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DepUpdater\u5de5\u5177\uff0c\u80fd\u9ad8\u6548\u81ea\u52a8\u5316\u5730\u5347\u7ea7\u5f00\u6e90\u8f6f\u4ef6\u4f9d\u8d56\uff0c\u51cf\u5c11\u6280\u672f\u6ede\u540e\uff0c\u540c\u65f6\u4fdd\u8bc1\u9879\u76ee\u517c\u5bb9\u548c\u63a7\u5236\u5197\u4f59\u4f9d\u8d56\uff0c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\u5e76\u5e26\u6765\u517c\u5bb9\u6027\u63d0\u5347\u7684\u65b0\u53d1\u73b0\u3002", "motivation": "\u89e3\u51b3\u5f00\u6e90\u8f6f\u4ef6\u4f9d\u8d56\u5347\u7ea7\u96be\u9898\uff0c\u907f\u514d\u6280\u672f\u6ede\u540e\u3001\u517c\u5bb9\u6027\u95ee\u9898\u548c\u5197\u4f59\u4f9d\u8d56\u5806\u79ef\uff0c\u4e14\u73b0\u6709\u5de5\u5177\u672a\u80fd\u6709\u6548\u5e73\u8861\u8fd9\u4e9b\u9700\u6c42\u3002\u5e0c\u671b\u5b9e\u73b0\u81ea\u52a8\u5316\u4e14\u9ad8\u6548\u7684\u4f9d\u8d56\u5347\u7ea7\u6d41\u7a0b\u3002", "method": "\u63d0\u51faDepUpdater\u5de5\u5177\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u4e0e\u73b0\u6709\u4f9d\u8d56\u7ba1\u7406\u5de5\u5177\u8fdb\u884c\u4e86\u5bf9\u6bd4\u6d4b\u8bd5\uff0c\u540c\u65f6\u8fdb\u884c\u4e86\u6d88\u878d\u5b9e\u9a8c\u5206\u6790\u4e0d\u540c\u56e0\u7d20\u5bf9\u5347\u7ea7\u7ed3\u679c\u7684\u5f71\u54cd\u3002\u6700\u540e\u5229\u7528\u8be5\u5de5\u5177\u5206\u6790\u4e86\u4f20\u9012\u4f9d\u8d56\u5347\u7ea7\u5bf9\u517c\u5bb9\u6027\u7684\u5f71\u54cd\u3002", "result": "DepUpdater\u6bd4\u4f20\u7edf\u4f9d\u8d56\u7ba1\u7406\u5de5\u5177\u66f4\u6709\u6548\u5730\u51cf\u5c11\u4e86\u6280\u672f\u6ede\u540e\u5e76\u517c\u987e\u517c\u5bb9\u6027\u4e0e\u4f9d\u8d56\u5197\u4f59\uff0c\u6d88\u878d\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5197\u4f59\u4f9d\u8d56\u8003\u8651\u5728\u5347\u7ea7\u6d41\u7a0b\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63a2\u7d22\u4e86\u4f20\u9012\u4f9d\u8d56\u5347\u7ea7\u5bf9\u517c\u5bb9\u6027\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "conclusion": "DepUpdater\u80fd\u591f\u6709\u6548\u5e73\u8861\u4f9d\u8d56\u5347\u7ea7\u7684\u591a\u91cd\u8003\u8651\uff0c\u5b9e\u73b0\u6700\u5c0f\u5316\u6280\u672f\u6ede\u540e\u3001\u517c\u5bb9\u6027\u4fdd\u969c\u4ee5\u53ca\u5197\u4f59\u4f9d\u8d56\u7684\u88c1\u526a\u3002\u901a\u8fc7\u4e0e\u73b0\u6709\u5de5\u5177\u5bf9\u6bd4\uff0c\u5176\u6548\u679c\u66f4\u4f18\u3002"}}
{"id": "2511.06057", "categories": ["cs.CL", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.06057", "abs": "https://arxiv.org/abs/2511.06057", "authors": ["Bingbing Wang", "Zhengda Jin", "Bin Liang", "Jing Li", "Ruifeng Xu"], "title": "ReMoD: Rethinking Modality Contribution in Multimodal Stance Detection via Dual Reasoning", "comment": null, "summary": "Multimodal Stance Detection (MSD) is a crucial task for understanding public opinion on social media. Existing work simply fuses information from various modalities to learn stance representations, overlooking the varying contributions of stance expression from different modalities. Therefore, stance misunderstanding noises may be drawn into the stance learning process due to the risk of learning errors by rough modality combination. To address this, we get inspiration from the dual-process theory of human cognition and propose **ReMoD**, a framework that **Re**thinks **Mo**dality contribution of stance expression through a **D**ual-reasoning paradigm. ReMoD integrates *experience-driven intuitive reasoning* to capture initial stance cues with *deliberate reflective reasoning* to adjust for modality biases, refine stance judgments, and thereby dynamically weight modality contributions based on their actual expressive power for the target stance. Specifically, the intuitive stage queries the Modality Experience Pool (MEP) and Semantic Experience Pool (SEP) to form an initial stance hypothesis, prioritizing historically impactful modalities. This hypothesis is then refined in the reflective stage via two reasoning chains: Modality-CoT updates MEP with adaptive fusion strategies to amplify relevant modalities, while Semantic-CoT refines SEP with deeper contextual insights of stance semantics. These dual experience structures are continuously refined during training and recalled at inference to guide robust and context-aware stance decisions. Extensive experiments on the public MMSD benchmark demonstrate that our ReMoD significantly outperforms most baseline models and exhibits strong generalization capabilities.", "AI": {"tldr": "ReMoD\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u7684\u53cc\u8fc7\u7a0b\u673a\u5236\uff0c\u52a8\u6001\u6743\u8861\u591a\u6a21\u6001\u7acb\u573a\u4fe1\u606f\uff0c\u53d6\u5f97\u4e86\u4f18\u5f02\u5b9e\u9a8c\u6548\u679c\uff0c\u63d0\u5347\u4e86\u591a\u6a21\u6001\u7acb\u573a\u68c0\u6d4b\u7684\u51c6\u786e\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u7acb\u573a\u68c0\u6d4b\u4ec5\u7c97\u7cd9\u878d\u5408\u5404\u6a21\u6001\uff0c\u5ffd\u7565\u4e0d\u540c\u6a21\u6001\u8868\u8fbe\u7acb\u573a\u7684\u5dee\u5f02\u6027\uff0c\u53ef\u80fd\u5f15\u5165\u8bef\u5224\u566a\u58f0\u3002\u8be5\u5de5\u4f5c\u65e8\u5728\u66f4\u52a0\u7ec6\u81f4\u5730\u5229\u7528\u4e0d\u540c\u6a21\u6001\u4fe1\u606f\uff0c\u63d0\u5347\u7acb\u573a\u8bc6\u522b\u7684\u51c6\u786e\u6027\u3002", "method": "\u53c2\u8003\u4eba\u7c7b\u8ba4\u77e5\u7684\u53cc\u8fc7\u7a0b\u7406\u8bba\uff0cReMoD\u91c7\u7528\u7ecf\u9a8c\u9a71\u52a8\u7684\u76f4\u89c9\u63a8\u7406\u548c\u5ba1\u614e\u7684\u53cd\u601d\u6027\u63a8\u7406\u4e24\u9636\u6bb5\uff0c\u5206\u522b\u5229\u7528Modality Experience Pool\u548cSemantic Experience Pool\u52a8\u6001\u8c03\u6574\u5404\u6a21\u6001\u5bf9\u7acb\u573a\u8868\u8fbe\u7684\u8d21\u732e\u3002", "result": "ReMoD\u5728MMSD\u516c\u5f00\u57fa\u51c6\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0c\u660e\u663e\u8d85\u8fc7\u5927\u591a\u6570\u4e3b\u6d41\u65b9\u6cd5\uff0c\u5e76\u5c55\u73b0\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684ReMoD\u6846\u67b6\u80fd\u66f4\u6709\u6548\u5730\u5904\u7406\u591a\u6a21\u6001\u7acb\u573a\u68c0\u6d4b\u4efb\u52a1\uff0c\u5e76\u5728\u516c\u5f00\u57fa\u51c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u73b0\u4e86\u8f83\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2511.06864", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.06864", "abs": "https://arxiv.org/abs/2511.06864", "authors": ["Pallav Jain", "Yuvraj Agrawal", "Ashutosh Nigam", "Pushpak Patil"], "title": "MetricSynth: Framework for Aggregating DORA and KPI Metrics Across Multi-Platform Engineering", "comment": null, "summary": "In modern, large-scale software development, engineering leaders face the significant challenge of gaining a holistic and data-driven view of team performance and system health. Data is often siloed across numerous disparate tools, making manual report generation time-consuming and prone to inconsistencies. This paper presents the architecture and implementation of a centralized framework designed to provide near-real-time visibility into developer experience (DevEx) and Key Performance Indicator (KPI) metrics for a software ecosystem. By aggregating data from various internal tools and platforms, the system computes and visualizes metrics across key areas such as Developer Productivity, Quality, and Operational Efficiency. The architecture features a cron-based data ingestion layer, a dual-schema data storage approach, a processing engine for metric pre-computation, a proactive alerting system, and utilizes the open-source BI tool Metabase for visualization, all secured with role-based access control (RBAC). The implementation resulted in a significant reduction in manual reporting efforts, saving an estimated 20 person-hours per week, and enabled faster, data-driven bottleneck identification. Finally, we evaluate the system's scalability and discuss its trade-offs, positioning it as a valuable contribution to engineering intelligence platforms.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u96c6\u4e2d\u5f0f\u6570\u636e\u6846\u67b6\uff0c\u96c6\u6210\u5404\u7c7b\u5185\u90e8\u5de5\u5177\u6570\u636e\uff0c\u5b9e\u73b0\u5f00\u53d1\u4f53\u9a8c\u548cKPI\u7684\u5b9e\u65f6\u53ef\u89c6\u5316\u5206\u6790\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u5e76\u8282\u7701\u4eba\u529b\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u667a\u80fd\u5e73\u53f0\u5efa\u8bbe\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u5927\u578b\u8f6f\u4ef6\u5f00\u53d1\u4e2d\uff0c\u5de5\u7a0b\u9886\u5bfc\u8005\u96be\u4ee5\u5168\u9762\u4e14\u6570\u636e\u9a71\u52a8\u5730\u4e86\u89e3\u56e2\u961f\u7ee9\u6548\u4e0e\u7cfb\u7edf\u5065\u5eb7\uff0c\u56e0\u6570\u636e\u5206\u6563\u4e8e\u4e0d\u540c\u5de5\u5177\u4e14\u624b\u52a8\u62a5\u544a\u8017\u65f6\u4e14\u6613\u51fa\u9519\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u96c6\u4e2d\u5f0f\u6846\u67b6\uff0c\u901a\u8fc7\u5b9a\u65f6\u4efb\u52a1\u7684\u6570\u636e\u91c7\u96c6\u5c42\u3001\u53cc\u6a21\u5f0f\u5b58\u50a8\u3001\u6307\u6807\u9884\u8ba1\u7b97\u5f15\u64ce\u3001\u4e3b\u52a8\u544a\u8b66\u7cfb\u7edf\uff0c\u5e76\u91c7\u7528\u5f00\u6e90BI\u5de5\u5177Metabase\u8fdb\u884c\u53ef\u89c6\u5316\uff0c\u57fa\u4e8e\u89d2\u8272\u8bbf\u95ee\u63a7\u5236\u5b9e\u73b0\u5b89\u5168\u3002", "result": "\u6210\u529f\u5927\u5e45\u51cf\u5c11\u4e86\u624b\u52a8\u62a5\u544a\u7684\u5de5\u4f5c\u91cf\uff0c\u6bcf\u5468\u8282\u7701\u7ea620\u4eba\u5c0f\u65f6\uff0c\u5e76\u52a0\u5feb\u4e86\u6570\u636e\u9a71\u52a8\u7684\u74f6\u9888\u8bc6\u522b\u901f\u5ea6\u3002\u7cfb\u7edf\u5177\u5907\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u5bf9\u5176\u6743\u8861\u8fdb\u884c\u4e86\u8ba8\u8bba\u3002", "conclusion": "\u63d0\u51fa\u7684\u5de5\u7a0b\u667a\u80fd\u5e73\u53f0\u663e\u8457\u63d0\u5347\u4e86\u62a5\u544a\u6548\u7387\u548c\u56e2\u961f\u6d1e\u5bdf\u529b\uff0c\u662f\u5bf9DevEx\u548cKPI\u76d1\u63a7\u7684\u6709\u4ef7\u503c\u8865\u5145\u3002"}}
{"id": "2511.06067", "categories": ["cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.06067", "abs": "https://arxiv.org/abs/2511.06067", "authors": ["Haoyue Yang", "Xuanle Zhao", "Yujie Liu", "Zhuojun Zou", "Kailin Lyu", "Changchun Zhou", "Yao Zhu", "Jie Hao"], "title": "Automating Hardware Design and Verification from Architectural Papers via a Neural-Symbolic Graph Framework", "comment": "Preprint Version, Work in Progress", "summary": "The reproduction of hardware architectures from academic papers remains a significant challenge due to the lack of publicly available source code and the complexity of hardware description languages (HDLs). To this end, we propose \\textbf{ArchCraft}, a Framework that converts abstract architectural descriptions from academic papers into synthesizable Verilog projects with register-transfer level (RTL) verification. ArchCraft introduces a structured workflow, which uses formal graphs to capture the Architectural Blueprint and symbols to define the Functional Specification, translating unstructured academic papers into verifiable, hardware-aware designs. The framework then generates RTL and testbench (TB) code decoupled via these symbols to facilitate verification and debugging, ultimately reporting the circuit's Power, Area, and Performance (PPA). Moreover, we propose the first benchmark, \\textbf{ArchSynthBench}, for synthesizing hardware from architectural descriptions, with a complete set of evaluation indicators, 50 project-level circuits, and around 600 circuit blocks. We systematically assess ArchCraft on ArchSynthBench, where the experiment results demonstrate the superiority of our proposed method, surpassing direct generation methods and the VerilogCoder framework in both paper understanding and code completion. Furthermore, evaluation and physical implementation of the generated executable RTL code show that these implementations meet all timing constraints without violations, and their performance metrics are consistent with those reported in the original papers.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86ArchCraft\u6846\u67b6\uff0c\u80fd\u5c06\u5b66\u672f\u8bba\u6587\u4e2d\u7684\u786c\u4ef6\u67b6\u6784\u63cf\u8ff0\u81ea\u52a8\u8f6c\u6362\u4e3a\u53ef\u9a8c\u8bc1\u7684Verilog\u9879\u76ee\uff0c\u5e76\u63d0\u51fa\u4e86ArchSynthBench\u57fa\u51c6\u7528\u4e8e\u8bc4\u4f30\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u7406\u89e3\u8bba\u6587\u548c\u751f\u6210\u4ee3\u7801\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u751f\u6210\u7684RTL\u4ee3\u7801\u53ef\u7b26\u5408\u6027\u80fd\u548c\u65f6\u5e8f\u8981\u6c42\u3002", "motivation": "\u5f53\u524d\u5b66\u672f\u8bba\u6587\u4e2d\u7684\u786c\u4ef6\u67b6\u6784\u590d\u73b0\u9762\u4e34\u6781\u5927\u6311\u6218\uff0c\u4e3b\u8981\u7531\u4e8e\u7f3a\u5c11\u516c\u5f00\u6e90\u7801\u4ee5\u53ca\u786c\u4ef6\u63cf\u8ff0\u8bed\u8a00\u7684\u590d\u6742\u6027\uff0c\u4e25\u91cd\u5f71\u54cd\u4e86\u5b66\u672f\u6210\u679c\u590d\u73b0\u4e0e\u5bf9\u6bd4\u3002", "method": "\u63d0\u51faArchCraft\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u4e0d\u7ed3\u6784\u5316\u7684\u5b66\u672f\u8bba\u6587\u67b6\u6784\u63cf\u8ff0\u8f6c\u6362\u4e3a\u5f62\u5f0f\u5316\u7684\u67b6\u6784\u84dd\u56fe\uff08\u4f7f\u7528\u56fe\u7ed3\u6784\u63cf\u8ff0\uff09\u548c\u529f\u80fd\u89c4\u8303\uff08\u7b26\u53f7\u5b9a\u4e49\uff09\uff0c\u5e76\u81ea\u52a8\u751f\u6210Verilog\u4ee3\u7801\u4e0e\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5b9e\u73b0RTL\u7ea7\u9a8c\u8bc1\u3002\u6846\u67b6\u80fd\u81ea\u52a8\u62a5\u544a\u7535\u8def\u7684\u529f\u8017\u3001\u9762\u79ef\u548c\u6027\u80fd\u3002\u8fd8\u63d0\u51fa\u4e86\u9996\u4e2a\u7efc\u5408\u786c\u4ef6\u67b6\u6784\u63cf\u8ff0\u7684\u57fa\u51c6\u96c6ArchSynthBench\uff0c\u5305\u542b\u5168\u9762\u8bc4\u4f30\u6307\u6807\u548c\u5927\u91cf\u7535\u8def\u3002", "result": "ArchCraft\u5728ArchSynthBench\u4e0a\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5728\u8bba\u6587\u7406\u89e3\u548c\u4ee3\u7801\u751f\u6210\u65b9\u9762\u4f18\u4e8e\u76f4\u63a5\u751f\u6210\u65b9\u6cd5\u53caVerilogCoder\u6846\u67b6\u3002\u81ea\u52a8\u751f\u6210\u7684RTL\u4ee3\u7801\u7b26\u5408\u65f6\u5e8f\u7ea6\u675f\uff0c\u6027\u80fd\u6307\u6807\u4e0e\u539f\u8bba\u6587\u62a5\u544a\u4e00\u81f4\u3002", "conclusion": "ArchCraft\u663e\u8457\u63d0\u5347\u4e86\u5b66\u672f\u8bba\u6587\u4e2d\u786c\u4ef6\u67b6\u6784\u7684\u53ef\u590d\u73b0\u6027\u4e0e\u81ea\u52a8\u5316\u5b9e\u73b0\u80fd\u529b\uff0c\u63a8\u52a8\u4e86\u786c\u4ef6\u8bbe\u8ba1\u7814\u7a76\u7684\u5de5\u7a0b\u5316\u8fdb\u7a0b\u3002"}}
{"id": "2511.06885", "categories": ["cs.SE", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.06885", "abs": "https://arxiv.org/abs/2511.06885", "authors": ["Davis Byamugisha", "Francis Kamuganga", "Adones Rukundo", "John Businge"], "title": "A Collaborative Model for Improving Information Sharing among Cancer Care Groups using Software Engineering Principles", "comment": null, "summary": "Effective treatment of cancer requires early diagnosis which involves the patient's awareness of the early signs and symptoms, leading to a consultation with a health provider, who would then promptly refer the patient for confirmation of the diagnosis and thereafter treatment. However, this is not always the case because of delays arising from limited skilled manpower and health information management systems that are neither integrated nor organized in their design hence leading to information gap among care groups. Existing methods focus on using accumulated data to support decision making, enhancing the sharing of secondary data while others exclude some critical stakeholders like patient caretakers and administrators thus, leaving an information gap that creates delays and miscommunication during case management. We however notice some similarities between cancer treatment and software engineering information management especially when progress history needs to be maintained (versioning).\n  We analyze the similarities and propose a model for information sharing among cancer care groups using the software engineering principles approach. We model for reducing delays and improving coordination among care groups in cancer case management. Model design was guided by software engineering principles adopted in GitHub version control system for bug fixing in open-source code projects. Any-Logic simulation software was used to mimic the model realism in a virtual environment. Results show that bug resolution principles from software engineering and GitHub version control system can be adopted to coordinate collaboration and information sharing among care groups in a cancer case management environment while involving all stakeholders to improve care treatment outcomes, ensure early diagnosis and increase patient's survival chances.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06GitHub\u7248\u672c\u63a7\u5236\u7b49\u8f6f\u4ef6\u5de5\u7a0b\u539f\u5219\u7528\u4e8e\u764c\u75c7\u62a4\u7406\u4fe1\u606f\u5171\u4eab\u548c\u534f\u4f5c\uff0c\u6a21\u62df\u5b9e\u9a8c\u8868\u660e\u53ef\u6709\u6548\u51cf\u5c11\u4fe1\u606f\u5ef6\u8bef\uff0c\u52a0\u5f3a\u56e2\u961f\u534f\u8c03\uff0c\u63d0\u9ad8\u8bca\u65ad\u548c\u6cbb\u7597\u6548\u679c\u3002", "motivation": "\u764c\u75c7\u6cbb\u7597\u7684\u6709\u6548\u6027\u9700\u8981\u65e9\u671f\u8bca\u65ad\uff0c\u4f46\u73b0\u5b9e\u4e2d\u7531\u4e8e\u533b\u7597\u4eba\u529b\u6709\u9650\u548c\u4fe1\u606f\u7ba1\u7406\u7cfb\u7edf\u8bbe\u8ba1\u7f3a\u9677\uff0c\u5bfc\u81f4\u5404\u62a4\u7406\u56e2\u961f\u4e4b\u95f4\u5b58\u5728\u4fe1\u606f\u9e3f\u6c9f\uff0c\u8fdb\u800c\u9020\u6210\u8bca\u65ad\u5ef6\u8bef\u548c\u6c9f\u901a\u4e0d\u7545\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u51b3\u7b56\u652f\u6301\u548c\u6570\u636e\u5171\u4eab\u65b9\u9762\u6709\u6b20\u7f3a\uff0c\u4e14\u5ffd\u7565\u4e86\u67d0\u4e9b\u5173\u952e\u5229\u76ca\u76f8\u5173\u8005\uff0c\u672a\u80fd\u6709\u6548\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5206\u6790\u764c\u75c7\u6cbb\u7597\u4e0e\u8f6f\u4ef6\u5de5\u7a0b\u4fe1\u606f\u7ba1\u7406\u7684\u76f8\u4f3c\u6027\uff0c\u91c7\u7528\u8f6f\u4ef6\u5de5\u7a0bGitHub\u7248\u672c\u63a7\u5236\u7cfb\u7edf\u4e2d\u7684\u7f3a\u9677\u4fee\u590d\u539f\u5219\u8bbe\u8ba1\u4fe1\u606f\u5171\u4eab\u6a21\u578b\uff0c\u5e76\u5229\u7528Any-Logic\u4eff\u771f\u8f6f\u4ef6\u6a21\u62df\u6a21\u578b\u5728\u865a\u62df\u73af\u5883\u4e0b\u7684\u5b9e\u9645\u6548\u679c\u3002", "result": "\u6a21\u578b\u5c55\u793a\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u548cGitHub\u7248\u672c\u63a7\u5236\u7684\u7f3a\u9677\u4fee\u590d\u539f\u5219\u53ef\u4ee5\u6709\u6548\u534f\u8c03\u764c\u75c7\u62a4\u7406\u56e2\u961f\u4e4b\u95f4\u7684\u4fe1\u606f\u5171\u4eab\u548c\u534f\u4f5c\uff0c\u6d89\u53ca\u6240\u6709\u76f8\u5173\u5229\u76ca\u65b9\uff0c\u4ece\u800c\u63d0\u9ad8\u62a4\u7406\u6cbb\u7597\u6548\u679c\u3001\u786e\u4fdd\u65e9\u671f\u8bca\u65ad\u5e76\u63d0\u5347\u60a3\u8005\u7684\u751f\u5b58\u7387\u3002", "conclusion": "\u5c06\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u534f\u4f5c\u548c\u7248\u672c\u7ba1\u7406\u539f\u5219\u5e94\u7528\u5230\u764c\u75c7\u62a4\u7406\u7684\u4fe1\u606f\u5171\u4eab\uff0c\u6709\u52a9\u4e8e\u51cf\u5c11\u5ef6\u8bef\u3001\u6539\u5584\u534f\u8c03\u548c\u6c9f\u901a\uff0c\u6700\u7ec8\u63d0\u5347\u60a3\u8005\u83b7\u76ca\u548c\u6cbb\u7597\u6548\u679c\u3002"}}
{"id": "2511.06073", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.06073", "abs": "https://arxiv.org/abs/2511.06073", "authors": ["Simeon Emanuilov", "Richard Ackermann"], "title": "Stemming Hallucination in Language Models Using a Licensing Oracle", "comment": "23 pages, 4 figures, 8 tables. Introduces the Licensing Oracle, an architectural solution for eliminating hallucinations in language models through formal SHACL validation against knowledge graphs. All datasets and models are available at https://huggingface.co/collections/s-emanuilov/licensing-oracle-experiments", "summary": "Language models exhibit remarkable natural language generation capabilities but remain prone to hallucinations, generating factually incorrect information despite producing syntactically coherent responses. This study introduces the Licensing Oracle, an architectural solution designed to stem hallucinations in LMs by enforcing truth constraints through formal validation against structured knowledge graphs. Unlike statistical approaches that rely on data scaling or fine-tuning, the Licensing Oracle embeds a deterministic validation step into the model's generative process, ensuring that only factually accurate claims are made. We evaluated the effectiveness of the Licensing Oracle through experiments comparing it with several state-of-the-art methods, including baseline language model generation, fine-tuning for factual recall, fine-tuning for abstention behavior, and retrieval-augmented generation (RAG). Our results demonstrate that although RAG and fine-tuning improve performance, they fail to eliminate hallucinations. In contrast, the Licensing Oracle achieved perfect abstention precision (AP = 1.0) and zero false answers (FAR-NE = 0.0), ensuring that only valid claims were generated with 89.1% accuracy in factual responses. This work shows that architectural innovations, such as the Licensing Oracle, offer a necessary and sufficient solution for hallucinations in domains with structured knowledge representations, offering guarantees that statistical methods cannot match. Although the Licensing Oracle is specifically designed to address hallucinations in fact-based domains, its framework lays the groundwork for truth-constrained generation in future AI systems, providing a new path toward reliable, epistemically grounded models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u7ed3\u6784\u5316\u77e5\u8bc6\u9a8c\u8bc1\u5d4c\u5165\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6d41\u7a0b\uff0c\u6709\u6548\u6d88\u9664\u4e8b\u5b9e\u5e7b\u89c9\uff0c\u6bd4\u73b0\u6709\u7edf\u8ba1\u65b9\u6cd5\u66f4\u5177\u53ef\u9760\u6027\u548c\u786e\u5b9a\u6027\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\uff08LM\uff09\u5728\u81ea\u7136\u8bed\u8a00\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5bb9\u6613\u51fa\u73b0\u5e7b\u89c9\uff0c\u751f\u6210\u4e8b\u5b9e\u9519\u8bef\u7684\u4fe1\u606f\u3002\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u67b6\u6784\u2014\u2014Licensing Oracle\uff0c\u901a\u8fc7\u5bf9\u751f\u6210\u5185\u5bb9\u4e0e\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u5f62\u5f0f\u9a8c\u8bc1\uff0c\u5d4c\u5165\u786e\u5b9a\u6027\u9a8c\u8bc1\u73af\u8282\uff0c\u5f3a\u5236\u751f\u6210\u5185\u5bb9\u6ee1\u8db3\u4e8b\u5b9e\u7ea6\u675f\u3002\u5e76\u4e0e\u73b0\u6709\u65b9\u6cd5\uff08\u57fa\u7840\u6a21\u578b\u3001\u4e8b\u5b9e\u53ec\u56de\u5fae\u8c03\u3001\u5f03\u7b54\u5fae\u8c03\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210RAG\uff09\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "Licensing Oracle\u80fd\u591f\u5b9e\u73b0\u5b8c\u7f8e\u7684\u5f03\u7b54\u7cbe\u5ea6\uff08AP=1.0\uff09\u548c\u96f6\u9519\u8bef\u7b54\u6848\uff08FAR-NE=0.0\uff09\uff0c\u4ec5\u751f\u6210\u6709\u6548\u4e3b\u5f20\uff0c\u5e76\u4e14\u5728\u4e8b\u5b9e\u54cd\u5e94\u51c6\u786e\u7387\u4e0a\u8fbe\u523089.1%\u3002\u76f8\u8f83\u4e8e\u73b0\u6709\u7edf\u8ba1\u65b9\u6cd5\uff0c\u80fd\u5f7b\u5e95\u6d88\u9664\u5e7b\u89c9\u3002", "conclusion": "\u7ed3\u6784\u521b\u65b0\uff08\u5982Licensing Oracle\uff09\u5728\u57fa\u4e8e\u7ed3\u6784\u5316\u77e5\u8bc6\u7684\u9886\u57df\u9488\u5bf9\u5e7b\u89c9\u95ee\u9898\u63d0\u4f9b\u4e86\u5145\u5206\u4e14\u5fc5\u8981\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4fdd\u8bc1\u4e86\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7684\u53ef\u9760\u6027\uff0c\u4e3a\u672a\u6765\u53d7\u771f\u7406\u7ea6\u675f\u7684\u751f\u6210\u6a21\u578b\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.07017", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07017", "abs": "https://arxiv.org/abs/2511.07017", "authors": ["Ruida Hu", "Xinchen Wang", "Xin-Cheng Wen", "Zhao Zhang", "Bo Jiang", "Pengfei Gao", "Chao Peng", "Cuiyun Gao"], "title": "Benchmarking LLMs for Fine-Grained Code Review with Enriched Context in Practice", "comment": null, "summary": "Code review is a cornerstone of software quality assurance, and recent advances in Large Language Models (LLMs) have shown promise in automating this process. However, existing benchmarks for LLM-based code review face three major limitations. (1) Lack of semantic context: most benchmarks provide only code diffs without textual information such as issue descriptions, which are crucial for understanding developer intent. (2) Data quality issues: without rigorous validation, many samples are noisy-e.g., reviews on outdated or irrelevant code-reducing evaluation reliability. (3) Coarse granularity: most benchmarks operate at the file or commit level, overlooking the fine-grained, line-level reasoning essential for precise review.\n  We introduce ContextCRBench, a high-quality, context-rich benchmark for fine-grained LLM evaluation in code review. Our construction pipeline comprises: (1) Raw Data Crawling, collecting 153.7K issues and pull requests from top-tier repositories; (2) Comprehensive Context Extraction, linking issue-PR pairs for textual context and extracting the full surrounding function or class for code context; and (3) Multi-stage Data Filtering, combining rule-based and LLM-based validation to remove outdated, malformed, or low-value samples, resulting in 67,910 context-enriched entries.\n  ContextCRBench supports three evaluation scenarios aligned with the review workflow: (1) hunk-level quality assessment, (2) line-level defect localization, and (3) line-level comment generation. Evaluating eight leading LLMs (four closed-source and four open-source) reveals that textual context yields greater performance gains than code context alone, while current LLMs remain far from human-level review ability. Deployed at ByteDance, ContextCRBench drives a self-evolving code review system, improving performance by 61.98% and demonstrating its robustness and industrial utility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u4ee3\u7801\u8bc4\u5ba1\u57fa\u51c6ContextCRBench\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u8bc4\u6d4b\u96c6\u7f3a\u4e4f\u8bed\u4e49\u3001\u6837\u672c\u8d28\u91cf\u4f4e\u548c\u7c92\u5ea6\u7c97\u7b49\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u4ee3\u7801\u8bc4\u5ba1\u8868\u73b0\uff0c\u5e76\u5728\u5de5\u4e1a\u573a\u666f\u4e2d\u53d6\u5f97\u4e86\u5b9e\u9645\u5e94\u7528\u548c\u5927\u5e45\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7801\u8bc4\u5ba1\u7684\u57fa\u51c6\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u7f3a\u4e4f\u8bed\u4e49\u4e0a\u4e0b\u6587\uff08\u5982\u7f3a\u5c11\u95ee\u9898\u63cf\u8ff0\uff09\u3001\u6570\u636e\u8d28\u91cf\u4e0d\u9ad8\uff08\u6837\u672c\u5b58\u5728\u566a\u58f0\uff09\u3001\u7c92\u5ea6\u8fc7\u7c97\uff08\u5ffd\u7565\u7ec6\u7c92\u5ea6\u7684\u884c\u7ea7\u63a8\u7406\uff09\u3002\u8fd9\u4e9b\u95ee\u9898\u5f71\u54cd\u4e86\u4ee3\u7801\u8bc4\u5ba1\u81ea\u52a8\u5316\u7684\u6709\u6548\u6027\u548c\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u9ad8\u8d28\u91cf\u3001\u4e0a\u4e0b\u6587\u4e30\u5bcc\u7684\u4ee3\u7801\u8bc4\u5ba1\u57fa\u51c6ContextCRBench\uff0c\u901a\u8fc7\u4e09\u6b65\u6784\u5efa\u6d41\u7a0b\uff1a\u6570\u636e\u6293\u53d6\uff08\u6536\u96c6\u95ee\u9898\u548c\u62c9\u53d6\u8bf7\u6c42\uff09\u3001\u5168\u9762\u4e0a\u4e0b\u6587\u63d0\u53d6\uff08\u5173\u8054\u6587\u672c\u548c\u4ee3\u7801\u4e0a\u4e0b\u6587\uff09\u3001\u591a\u9636\u6bb5\u6570\u636e\u8fc7\u6ee4\uff08\u8054\u5408\u89c4\u5219\u548cLLM\u9a8c\u8bc1\uff09\uff0c\u6700\u7ec8\u83b7\u5f97\u8fd1\u4e03\u4e07\u6761\u4f18\u8d28\u591a\u4e0a\u4e0b\u6587\u8bc4\u5ba1\u6837\u672c\u3002\u5e76\u8bbe\u8ba1\u4e09\u7c7b\u8bc4\u4f30\u573a\u666f\uff1ahunk\u7ea7\u8d28\u91cf\u8bc4\u4f30\u3001\u884c\u7ea7\u7f3a\u9677\u5b9a\u4f4d\u3001\u884c\u7ea7\u8bc4\u5ba1\u8bc4\u8bba\u751f\u6210\u3002", "result": "\u6587\u672c\u4e0a\u4e0b\u6587\u80fd\u6bd4\u4ee3\u7801\u4e0a\u4e0b\u6587\u5355\u72ec\u5e26\u6765\u66f4\u5927\u6027\u80fd\u63d0\u5347\uff0c\u73b0\u6709\u4e3b\u6d41LLM\u5728\u4ee3\u7801\u8bc4\u5ba1\u4efb\u52a1\u4e0a\u8ddd\u79bb\u4eba\u7c7b\u6c34\u5e73\u8fd8\u6709\u8f83\u5927\u5dee\u8ddd\u3002ContextCRBench\u5df2\u5728\u5b57\u8282\u8df3\u52a8\u843d\u5730\u5e94\u7528\uff0c\u63a8\u52a8\u81ea\u8fdb\u5316\u4ee3\u7801\u8bc4\u5ba1\u7cfb\u7edf\uff0c\u6027\u80fd\u63d0\u5347\u8fbe61.98%\uff0c\u5c55\u73b0\u4e86\u5b9e\u9645\u5de5\u4e1a\u4ef7\u503c\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "ContextCRBench\u51ed\u501f\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u548c\u9ad8\u8d28\u91cf\u6837\u672c\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u51c6\u7684\u75db\u70b9\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86LLM\u8bc4\u5ba1\u6027\u80fd\uff0c\u8fd8\u5728\u5b9e\u9645\u5de5\u4e1a\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6548\u679c\u548c\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.06086", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.06086", "abs": "https://arxiv.org/abs/2511.06086", "authors": ["Saurabh Page", "Advait Joshi", "S. S. Sonawane"], "title": "MuonAll: Muon Variant for Efficient Finetuning of Large Language Models", "comment": null, "summary": "Muon optimizer has demonstrated robust results in pretraining of language models but its performance in finetuning of existing public pretrained models is not yet explored. Currently, Muon is used along with AdamW introducing a scope of improvement for adopting all parameters inside Muon. We introduce MuonAll, which incorporates all the parameters inside Muon by transforming into 2D matrices. We conduct extensive finetuning experiments across publicly available language models with model sizes upto half billion parameters. Muon and MuonAll perform at par with AdamW across major benchmarks, highlighting their effectiveness as alternative optimizers. We open-source the distributed implementations of Muon and MuonAll, available at https://github.com/Saurabh750/optimizer", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86MuonAll\u4f18\u5316\u5668\uff0c\u5c06\u6240\u6709\u53c2\u6570\u7eb3\u5165\uff0c\u5e7f\u6cdb\u6d4b\u8bd5\u53d1\u73b0\u5176\u4e0e\u73b0\u6709\u4e3b\u6d41\u4f18\u5316\u5668AdamW\u8868\u73b0\u6301\u5e73\uff0c\u662f\u4e00\u4e2a\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5e76\u5f00\u6e90\u4e86\u76f8\u5173\u5b9e\u73b0\u3002", "motivation": "Muon\u4f18\u5316\u5668\u5728\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u5728\u73b0\u6709\u516c\u5f00\u9884\u8bad\u7ec3\u6a21\u578b\u5fae\u8c03\u4e2d\u7684\u8868\u73b0\u8fd8\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002\u8fc7\u53bbMuon\u5e38\u4e0eAdamW\u5171\u540c\u4f7f\u7528\uff0c\u5c1a\u6709\u6539\u8fdb\u6f5c\u529b\uff08\u5373\u5c06\u6240\u6709\u53c2\u6570\u5747\u7eb3\u5165Muon\u4f18\u5316\u5668\uff09\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5MuonAll\uff0c\u901a\u8fc7\u5c06\u53c2\u6570\u53d8\u4e3a2D\u77e9\u9635\uff0c\u5c06\u6240\u6709\u53c2\u6570\u7eb3\u5165Muon\u4f18\u5316\u5668\u5185\u3002\u5728\u591a\u79cd\u516c\u5f00\u8bed\u8a00\u6a21\u578b\uff08\u6700\u5927\u53c2\u6570\u91cf\u8fbe\u4e94\u4ebf\uff09\u7684\u5fae\u8c03\u4efb\u52a1\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\u3002", "result": "Muon\u548cMuonAll\u5728\u4e3b\u6d41\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8868\u73b0\u4e0eAdamW\u76f8\u5f53\uff0c\u8bc1\u660e\u4e86\u5176\u4f5c\u4e3a\u66ff\u4ee3\u4f18\u5316\u5668\u7684\u6709\u6548\u6027\u3002", "conclusion": "MuonAll\u65b9\u6cd5\u80fd\u6709\u6548\u6574\u5408\u6240\u6709\u53c2\u6570\uff0c\u4e14Muon\u5bb6\u65cf\u4f18\u5316\u5668\u53ef\u4f5c\u4e3aAdamW\u7684\u6709\u6548\u66ff\u4ee3\u54c1\uff0c\u8868\u73b0\u7a33\u5065\u3002\u4e24\u79cd\u5206\u5e03\u5f0f\u5b9e\u73b0\u4e5f\u5bf9\u5916\u5f00\u6e90\u3002"}}
{"id": "2511.07257", "categories": ["cs.SE", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.07257", "abs": "https://arxiv.org/abs/2511.07257", "authors": ["Hanya Elhashemy", "Youssef Lotfy", "Yongjian Tang"], "title": "Bridging the Prototype-Production Gap: A Multi-Agent System for Notebooks Transformation", "comment": null, "summary": "The increasing adoption of Jupyter notebooks in data science and machine learning workflows has created a gap between exploratory code development and production-ready software systems. While notebooks excel at iterative development and visualization, they often lack proper software engineering principles, making their transition to production environments challenging. This paper presents Codelevate, a novel multi-agent system that automatically transforms Jupyter notebooks into well-structured, maintainable Python code repositories. Our system employs three specialized agents - Architect, Developer, and Structure - working in concert through a shared dependency tree to ensure architectural coherence and code quality. Our experimental results validate Codelevate's capability to bridge the prototype-to-production gap through autonomous code transformation, yielding quantifiable improvements in code quality metrics while preserving computational semantics.", "AI": {"tldr": "Codelevate\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u81ea\u52a8\u628aJupyter\u7b14\u8bb0\u672c\u8f6c\u4e3a\u9ad8\u8d28\u91cfPython\u4ee3\u7801\u5e93\uff0c\u663e\u8457\u63d0\u5347\u5de5\u7a0b\u89c4\u8303\u548c\u53ef\u7ef4\u62a4\u6027\uff0c\u5b9e\u73b0\u539f\u578b\u5230\u751f\u4ea7\u7684\u65e0\u7f1d\u8854\u63a5\u3002", "motivation": "Jupyter\u7b14\u8bb0\u672c\u5728\u6570\u636e\u79d1\u5b66\u548c\u673a\u5668\u5b66\u4e60\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u7b14\u8bb0\u672c\u4ee3\u7801\u901a\u5e38\u7f3a\u4e4f\u8f6f\u4ef6\u5de5\u7a0b\u89c4\u8303\uff0c\u96be\u4ee5\u76f4\u63a5\u8fc1\u79fb\u5230\u751f\u4ea7\u73af\u5883\uff0c\u56e0\u6b64\u4e9f\u9700\u4e00\u79cd\u81ea\u52a8\u5316\u5de5\u5177\u63d0\u5347\u4ee3\u7801\u7ed3\u6784\u548c\u5de5\u7a0b\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08\u5305\u62ecArchitect, Developer, Structure\u4e09\u4f4d\u4ee3\u7406\uff09\uff0c\u5229\u7528\u5171\u4eab\u4f9d\u8d56\u6811\u534f\u540c\u5c06Jupyter\u7b14\u8bb0\u672c\u81ea\u52a8\u8f6c\u5316\u4e3a\u9ad8\u8d28\u91cf\u3001\u7ed3\u6784\u6e05\u6670\u7684Python\u4ed3\u5e93\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCodelevate\u80fd\u591f\u663e\u8457\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\u6307\u6807\u5e76\u4fdd\u6301\u8ba1\u7b97\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u5b9e\u73b0\u539f\u578b\u4ee3\u7801\u5230\u751f\u4ea7\u4ee3\u7801\u7684\u987a\u5229\u8f6c\u5316\u3002", "conclusion": "Codelevate\u80fd\u591f\u6709\u6548\u5730\u5c06Jupyter\u7b14\u8bb0\u672c\u539f\u578b\u4ee3\u7801\u81ea\u52a8\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u3001\u6613\u7ef4\u62a4\u7684Python\u4ee3\u7801\u5e93\uff0c\u63d0\u9ad8\u4ee3\u7801\u8d28\u91cf\uff0c\u987a\u5229\u5b9e\u73b0\u4ece\u539f\u578b\u5230\u751f\u4ea7\u7684\u8fc7\u6e21\u3002"}}
{"id": "2511.06125", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.06125", "abs": "https://arxiv.org/abs/2511.06125", "authors": ["Nathan Scales", "Nathanael Sch\u00e4rli", "Olivier Bousquet"], "title": "Evaluation of retrieval-based QA on QUEST-LOFT", "comment": null, "summary": "Despite the popularity of retrieval-augmented generation (RAG) as a solution for grounded QA in both academia and industry, current RAG methods struggle with questions where the necessary information is distributed across many documents or where retrieval needs to be combined with complex reasoning. Recently, the LOFT study has shown that this limitation also applies to approaches based on long-context language models, with the QUEST benchmark exhibiting particularly large headroom. In this paper, we provide an in-depth analysis of the factors contributing to the poor performance on QUEST-LOFT, publish updated numbers based on a thorough human evaluation, and demonstrate that RAG can be optimized to significantly outperform long-context approaches when combined with a structured output format containing reasoning and evidence, optionally followed by answer re-verification.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86RAG\u548c\u957f\u4e0a\u4e0b\u6587\u6a21\u578b\u5728\u590d\u6742\u95ee\u7b54\u573a\u666f\u7684\u5c40\u9650\uff0c\u901a\u8fc7\u4eba\u7c7b\u8bc4\u6d4b\u548c\u7ed3\u6784\u5316\u63a8\u7406\u4f18\u5316\u8bc1\u660eRAG\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4f18\u4e8e\u957f\u4e0a\u4e0b\u6587\u65b9\u6cd5\u3002", "motivation": "RAG\u5728\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u975e\u5e38\u6d41\u884c\u7528\u4e8e\u57fa\u4e8e\u4e8b\u5b9e\u7684\u95ee\u7b54\uff0c\u4f46\u9762\u5bf9\u4fe1\u606f\u5206\u5e03\u4e8e\u591a\u6587\u6863\u6216\u9700\u8981\u590d\u6742\u63a8\u7406\u7684\u95ee\u9898\u65f6\uff0c\u73b0\u6709RAG\u8868\u73b0\u4e0d\u4f73\u3002\u8fd1\u671fLOFT\u7814\u7a76\u4e5f\u53d1\u73b0\u57fa\u4e8e\u957f\u4e0a\u4e0b\u6587\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6848\u540c\u6837\u5b58\u5728\u6b64\u6781\u9650\uff0c\u5c24\u5176\u5728QUEST\u57fa\u51c6\u4e0a\u7684\u5dee\u8ddd\u8f83\u5927\u3002", "method": "\u672c\u6587\u8be6\u7ec6\u5206\u6790\u5bfc\u81f4\u5728QUEST-LOFT\u8868\u73b0\u4e0d\u4f73\u7684\u539f\u56e0\uff0c\u901a\u8fc7\u4eba\u7c7b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u6027\u80fd\u6570\u636e\uff0c\u5e76\u63a2\u7d22\u5982\u4f55\u7ed3\u5408\u7ed3\u6784\u5316\u8f93\u51fa\u548c\u63a8\u7406\u8bc1\u636e\uff08\u53ef\u9009\u7684\u7b54\u6848\u91cd\u65b0\u9a8c\u8bc1\uff09\u6765\u4f18\u5316RAG\uff0c\u4f7f\u5176\u663e\u8457\u4f18\u4e8e\u957f\u4e0a\u4e0b\u6587\u6a21\u578b\u3002", "result": "\u6839\u636e\u66f4\u65b0\u7684\u4eba\u7c7b\u8bc4\u4f30\u6570\u636e\u548c\u5b9e\u9a8c\uff0c\u4f18\u5316\u540e\u7684RAG\uff08\u7ed3\u5408\u7ed3\u6784\u5316\u8f93\u51fa\u548c\u63a8\u7406\u8bc1\u636e\uff09\u5728\u590d\u6742\u95ee\u7b54\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8e\u957f\u4e0a\u4e0b\u6587\u6a21\u578b\u3002", "conclusion": "RAG\u65b9\u6cd5\u901a\u8fc7\u5408\u7406\u4f18\u5316\u548c\u7ed3\u6784\u5316\u63a8\u7406\u8f93\u51fa\uff0c\u53ef\u660e\u663e\u63d0\u5347\u591a\u6587\u6863\u548c\u590d\u6742\u63a8\u7406\u95ee\u9898\u4e0a\u7684\u95ee\u7b54\u51c6\u786e\u6027\uff0c\u8d85\u8fc7\u957f\u4e0a\u4e0b\u6587\u6a21\u578b\u65b9\u5f0f\u3002"}}
