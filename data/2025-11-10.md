<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 9]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.CL](#cs.CL) [Total: 44]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Agentic Refactoring: An Empirical Study of AI Coding Agents](https://arxiv.org/abs/2511.04824)
*Kosei Horikawa,Hao Li,Yutaro Kashiwa,Bram Adams,Hajimu Iida,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 本文系统分析了AI编码代理在开源Java项目中的重构行为。发现AI重构频率高、以局部一致性优化和维护性为主，对代码结构指标有小幅积极影响，与人类重构风格存在显著不同。


<details>
  <summary>Details</summary>
Motivation: 尽管AI agent在软件工程，尤其是重构中逐渐被广泛使用，但关于其实际重构实践、与人类重构的区别及其对代码质量影响的实证研究严重不足。该文旨在填补这一认知空白。

Method: 大规模实证研究，分析了AIDev数据集中的真实开源Java项目重构实例（总计15,451例），涵盖12,256个pull request和14,988次commit，从重构类型、动机和代码结构质量三方面系统性比对和评估AI agent与人类主导的重构行为。

Result: AI代理在commit中显式重构的比例达26.1%，重构内容以低层次、本地一致性提升为主（变量类型、参数、变量重命名等），主导动机为维护性（52.5%）和可读性（28.1%）。结构性代码质量指标有小幅、显著提升，尤其在中等规模修改中，例：类长度中位数减少15行以上。

Conclusion: AI代理类编码工具能够高频率、主动地进行代码重构，并显著提升了软件内部代码结构的维护性和可读性，尽管多数为局部改进。其产生的结构性改进虽幅度有限，但具有统计显著性。代理重构与人类重构在层次与动机上呈现差异。

Abstract: Agentic coding tools, such as OpenAI Codex, Claude Code, and Cursor, are
transforming the software engineering landscape. These AI-powered systems
function as autonomous teammates capable of planning and executing complex
development tasks. Agents have become active participants in refactoring, a
cornerstone of sustainable software development aimed at improving internal
code quality without altering observable behavior. Despite their increasing
adoption, there is a critical lack of empirical understanding regarding how
agentic refactoring is utilized in practice, how it compares to human-driven
refactoring, and what impact it has on code quality. To address this empirical
gap, we present a large-scale study of AI agent-generated refactorings in
real-world open-source Java projects, analyzing 15,451 refactoring instances
across 12,256 pull requests and 14,988 commits derived from the AIDev dataset.
Our empirical analysis shows that refactoring is a common and intentional
activity in this development paradigm, with agents explicitly targeting
refactoring in 26.1% of commits. Analysis of refactoring types reveals that
agentic efforts are dominated by low-level, consistency-oriented edits, such as
Change Variable Type (11.8%), Rename Parameter (10.4%), and Rename Variable
(8.5%), reflecting a preference for localized improvements over the high-level
design changes common in human refactoring. Additionally, the motivations
behind agentic refactoring focus overwhelmingly on internal quality concerns,
with maintainability (52.5%) and readability (28.1%). Furthermore, quantitative
evaluation of code quality metrics shows that agentic refactoring yields small
but statistically significant improvements in structural metrics, particularly
for medium-level changes, reducing class size and complexity (e.g., Class LOC
median $\Delta$ = -15.25).

</details>


### [2] [Software Defined Vehicle Code Generation: A Few-Shot Prompting Approach](https://arxiv.org/abs/2511.04849)
*Quang-Dung Nguyen,Tri-Dung Tran,Thanh-Hieu Chu,Hoang-Loc Tran,Xiangwei Cheng,Dirk Slama*

Main category: cs.SE

TL;DR: 文章针对汽车行业SDV代码生成的需求，通过先进提示词工程及少量样例策略，有效提升了通用LLM的代码生成表现，无需更改模型或训练，可供SDV领域开发者采用。


<details>
  <summary>Details</summary>
Motivation: 随着软件定义汽车（SDV）的出现，软件逐渐成为汽车行业的核心驱动力，推动汽车功能创新。由于SDV应用开发复杂度高，亟需更高效的工具以提升代码生成和开发效率。近年来，通用大语言模型（LLM）展示了在各领域的变革潜力，但由于架构限制，难以适应SDV等特定任务。作者希望通过改进提示词工程提升现有LLM在SDV代码生成方面的实用性，无需模型架构或额外训练。

Method: 本文提出通过系统提示词和先进的提示词工程设计合适高效的结构，利用不同的提示方式（包括裸模型、少量样例），在专门构建的基准测试上，对多种LLM进行大量实验，评估其在SDV代码生成上的效果。无需访问底层模型或额外训练，只通过改造提示词工程实现对模型的定向适配。

Result: 采用少量样例的提示策略的模型在定向调节LLM输出以生成期望SDV代码方面表现最好，在定量指标上优于其他策略。

Conclusion: 通过高效的提示词工程可显著提升通用LLM在SDV代码生成领域的表现，尤其是少量样例提示策略，不依赖模型架构或额外训练即可实现较优定向结果。

Abstract: The emergence of Software-Defined Vehicles (SDVs) marks a paradigm shift in
the automotive industry, where software now plays a pivotal role in defining
vehicle functionality, enabling rapid innovation of modern vehicles. Developing
SDV-specific applications demands advanced tools to streamline code generation
and improve development efficiency. In recent years, general-purpose large
language models (LLMs) have demonstrated transformative potential across
domains. Still, restricted access to proprietary model architectures hinders
their adaption to specific tasks like SDV code generation. In this study, we
propose using prompts, a common and basic strategy to interact with LLMs and
redirect their responses. Using only system prompts with an appropriate and
efficient prompt structure designed using advanced prompt engineering
techniques, LLMs can be crafted without requiring a training session or access
to their base design. This research investigates the extensive experiments on
different models by applying various prompting techniques, including bare
models, using a benchmark specifically created to evaluate LLMs' performance in
generating SDV code. The results reveal that the model with a few-shot
prompting strategy outperforms the others in adjusting the LLM answers to match
the expected outcomes based on quantitative metrics.

</details>


### [3] [What About Our Bug? A Study on the Responsiveness of NPM Package Maintainers](https://arxiv.org/abs/2511.04986)
*Mohammadreza Saeidi,Ethan Thoma,Raula Gaikovina Kula,Gema Rodríguez-Pérez*

Main category: cs.SE

TL;DR: 对流行 npm 包的大量 bug 报告响应性进行了实证分析，发现维护者普遍负责任，但未响应 bug 受多种因素影响，并提出了原因分类体系。


<details>
  <summary>Details</summary>
Motivation: 随着第三方库广泛应用，依赖链中的 bug 易造成严重连锁反应。假设维护者并不总是会修复 bug，特别是当某些 bug 超出了他们责任范围时。

Method: 采用混合方法，挖掘仓库议题数据并进行定性开放式编码，深入分析未处理 bug 报告背后的原因。

Result: 分析了 500 个 npm 最常依赖包的 30,340 个 bug 报告，发现项目维护者的响应率中位数为 70%，显示出对下游开发者支持的承诺，并归纳总结了 bug 未被响应的具体原因。

Conclusion: 维护者通常对 bug 报告有较高响应率，但部分 bug 长期未解决，原因包括贡献者惯例、依赖约束及库的特定标准等。理解这些行为有助于构建更健壮、响应性更好的开源生态系统。

Abstract: Background: Widespread use of third-party libraries makes ecosystems like
Node Package Manager (npm) critical to modern software development. However,
this interconnected chain of dependencies also creates challenges: bugs in one
library can propagate downstream, potentially impacting many other libraries
that rely on it. We hypothesize that maintainers may not always decide to fix a
bug, especially if the maintainer decides it falls out of their responsibility
within the chain of dependencies. Aims: To confirm this hypothesis, we
investigate the responsiveness of 30,340 bug reports across 500 of the most
depended-upon npm packages. Method: We adopt a mixed-method approach to mine
repository issue data and perform qualitative open coding to analyze reasons
behind unaddressed bug reports. Results: Our findings show that maintainers are
generally responsive, with a median project-level responsiveness of 70% (IQR:
55%-89%), reflecting their commitment to support downstream developers.
Conclusions: We present a taxonomy of the reasons some bugs remain unresolved.
The taxonomy includes contribution practices, dependency constraints, and
library-specific standards as reasons for not being responsive. Understanding
maintainer behavior can inform practices that promote a more robust and
responsive open-source ecosystem that benefits the entire community.

</details>


### [4] [Generating Software Architecture Description from Source Code using Reverse Engineering and Large Language Model](https://arxiv.org/abs/2511.05165)
*Ahmad Hatahet,Christoph Knieke,Andreas Rausch*

Main category: cs.SE

TL;DR: 本论文提出用逆向工程结合大语言模型，自动从C++代码抽取软件架构与状态机行为图，有效减少人工撰写SAD的工作量，提升系统理解和长远维护能力。


<details>
  <summary>Details</summary>
Motivation: 传统软件架构描述文档常常缺失、过时或与实际实现不符，开发者为获取架构信息不得不自行分析源代码，导致负担增加、上手周期长、系统透明度和维护性下降。

Method: 方法为：通过逆向工程从源代码抽取架构信息，利用LLM进行组件图抽象与行为状态机建模，并以Prompt工程筛选出核心组件，配合Few-shot提示增强行为表示。以C++代码为例进行实证。

Result: 结果显示该方式可自动、准确地还原架构核心组件及行为视图，有效减少对专家的依赖，并提升复杂系统的理解和文档质量。

Conclusion: 本文提出了一种结合逆向工程技术和大语言模型（LLM）的方法，能自动化地从源代码生成具有静态与行为视角的软件架构描述（SAD），能够有效地减少人为工作量并提升系统理解与可维护性。

Abstract: Software Architecture Descriptions (SADs) are essential for managing the
inherent complexity of modern software systems. They enable high-level
architectural reasoning, guide design decisions, and facilitate effective
communication among diverse stakeholders. However, in practice, SADs are often
missing, outdated, or poorly aligned with the system's actual implementation.
Consequently, developers are compelled to derive architectural insights
directly from source code-a time-intensive process that increases cognitive
load, slows new developer onboarding, and contributes to the gradual
degradation of clarity over the system's lifetime. To address these issues, we
propose a semi-automated generation of SADs from source code by integrating
reverse engineering (RE) techniques with a Large Language Model (LLM). Our
approach recovers both static and behavioral architectural views by extracting
a comprehensive component diagram, filtering architecturally significant
elements (core components) via prompt engineering, and generating state machine
diagrams to model component behavior based on underlying code logic with
few-shots prompting. This resulting views representation offer a scalable and
maintainable alternative to traditional manual architectural documentation.
This methodology, demonstrated using C++ examples, highlights the potent
capability of LLMs to: 1) abstract the component diagram, thereby reducing the
reliance on human expert involvement, and 2) accurately represent complex
software behaviors, especially when enriched with domain-specific knowledge
through few-shot prompting. These findings suggest a viable path toward
significantly reducing manual effort while enhancing system understanding and
long-term maintainability.

</details>


### [5] [CodeMapper: A Language-Agnostic Approach to Mapping Code Regions Across Commits](https://arxiv.org/abs/2511.05205)
*Huimin Hu,Michael Pradel*

Main category: cs.SE

TL;DR: 本文针对代码演化过程中精确定位代码区域的问题，提出了 CodeMapper 方法，通过候选区域分析和相似度选择，实现了更精准的跨版本定位，准确率显著超越现有工具，适用性强。


<details>
  <summary>Details</summary>
Motivation: 现有的代码映射工具（如 git diff）不能有效地支持开发者对特定代码区域进行跨版本定位，只能展示整文件的变更，或只针对特定语言和元素，限制了实际应用。开发者迫切需要更通用且精确的方法来跟踪代码区域的演变。

Method: 提出了 CodeMapper 方法，分两阶段：（1）通过分析 diff、检测代码移动和代码片段搜索，计算候选区域；（2）用相似度计算，在候选区域中选取最可能对应的目标区域。此方法对程序元素和编程语言无依赖。

Result: CodeMapper 在四个数据集（含两个全新涵盖十种流行编程语言的人工标注数据集）上实验，正确识别目标区域的准确率为71.0%至94.5%，较当前最优基线方法提升1.5到58.8个百分点。

Conclusion: CodeMapper 提供了一种高效且通用的跨版本代码区域映射解决方案，显著超过现有方法，对多种编程语言和不同代码元素都适用。

Abstract: During software evolution, developers commonly face the problem of mapping a
specific code region from one commit to another. For example, they may want to
determine how the condition of an if-statement, a specific line in a
configuration file, or the definition of a function changes. We call this the
code mapping problem. Existing techniques, such as git diff, address this
problem only insufficiently because they show all changes made to a file
instead of focusing on a code region of the developer's choice. Other
techniques focus on specific code elements and programming languages (e.g.,
methods in Java), limiting their applicability. This paper introduces
CodeMapper, an approach to address the code mapping problem in a way that is
independent of specific program elements and programming languages. Given a
code region in one commit, CodeMapper finds the corresponding region in another
commit. The approach consists of two phases: (i) computing candidate regions by
analyzing diffs, detecting code movements, and searching for specific code
fragments, and (ii) selecting the most likely target region by calculating
similarities. Our evaluation applies CodeMapper to four datasets, including two
new hand-annotated datasets containing code region pairs in ten popular
programming languages. CodeMapper correctly identifies the expected target
region in 71.0%--94.5% of all cases, improving over the best available
baselines by 1.5--58.8 absolute percent points.

</details>


### [6] [Building Specialized Software-Assistant ChatBot with Graph-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2511.05297)
*Mohammed Hilel,Yannis Karmim,Jean De Bodinat,Reda Sarehane,Antoine Gillon*

Main category: cs.SE

TL;DR: 本文提出用知识图谱增强RAG框架，自动化企业软件数字引导内容生成，已在实际DAP环境中验证有效，可减少人工维护并提升答案可靠性。


<details>
  <summary>Details</summary>
Motivation: 虽然数字引导平台（DAPs）能帮助员工更好地使用复杂的企业软件，但现有的交互式引导内容构建和维护还需大量人工成本，同时现有大模型作为虚拟助手时，会出现幻觉和不可靠回答的问题。生产级大模型多为黑盒API，难以微调，亟须解决模型可靠性和自动生成引导内容的难题。

Method: 提出了一种基于图的检索增强生成（Retrieval-Augmented Generation，RAG）框架，能自动将企业Web应用转化为状态-动作知识图谱，然后用知识图检索增强LLM回答过程，生成有依据、上下文感知的数字引导；框架包括界面信息提取、知识结构化、基于图的检索系统设计，并集成到DAP实际生产工作流中。

Result: 本方法与Lemon Learning及RAKAM公司合作开发，实现了企业软件数字引导内容的半自动构建，在实际工业场景中应用，展示了良好的可扩展性与鲁棒性，提升了自动化水平并减少了人工维护成本。还总结了在大规模部署中的工程经验和教训。

Conclusion: 基于知识图谱增强的RAG方法可以有效支撑LLM在企业软件DAP中生成更可靠、可溯源的数字引导内容，减少员工培训和上手成本，并具备工业落地的可部署性和扩展性。

Abstract: Digital Adoption Platforms (DAPs) have become essential tools for helping
employees navigate complex enterprise software such as CRM, ERP, or HRMS
systems. Companies like LemonLearning have shown how digital guidance can
reduce training costs and accelerate onboarding. However, building and
maintaining these interactive guides still requires extensive manual effort.
Leveraging Large Language Models as virtual assistants is an appealing
alternative, yet without a structured understanding of the target software,
LLMs often hallucinate and produce unreliable answers. Moreover, most
production-grade LLMs are black-box APIs, making fine-tuning impractical due to
the lack of access to model weights. In this work, we introduce a Graph-based
Retrieval-Augmented Generation framework that automatically converts enterprise
web applications into state-action knowledge graphs, enabling LLMs to generate
grounded and context-aware assistance. The framework was co-developed with the
AI enterprise RAKAM, in collaboration with Lemon Learning. We detail the
engineering pipeline that extracts and structures software interfaces, the
design of the graph-based retrieval process, and the integration of our
approach into production DAP workflows. Finally, we discuss scalability,
robustness, and deployment lessons learned from industrial use cases.

</details>


### [7] [Code Review Automation using Retrieval Augmented Generation](https://arxiv.org/abs/2511.05302)
*Qianru Meng,Xiao Zhang,Zhaochen Ren,Joost Visser*

Main category: cs.SE

TL;DR: RARe结合检索与大语言模型生成方法，利用领域知识显著提升自动代码审核表现，获得优越评分并通过人工和案例分析验证有效性。


<details>
  <summary>Details</summary>
Motivation: 代码审核虽然有助于保证软件质量，但过程繁琐且消耗大量人力。现有的自动化代码审核方法虽提升了效率，但在评论相关性和具体性方面仍存在不足。

Method: 提出了RARe系统，将检索增强生成（RAG）方法应用于自动代码审核，通过密集检索器从代码库中找出最相关的审核意见，再用神经生成模型（基于大语言模型）融合检索到的审核内容进行深度生成，从而引入外部领域知识并提升最终评论的相关性和具体性。

Result: 在两个基准数据集上，RARe获得了12.32和12.96的BLEU-4分数，优于现有方法。同时，通过人工评价和案例研究（含可解释性工具）进一步证明了RARe的有效性和实用性。

Conclusion: 结合检索与生成的RARe系统能显著提升自动代码审核的实际表现，对提高评论精准度和实践可靠性有积极作用。

Abstract: Code review is essential for maintaining software quality but is
labor-intensive. Automated code review generation offers a promising solution
to this challenge. Both deep learning-based generative techniques and
retrieval-based methods have demonstrated strong performance in this task.
However, despite these advancements, there are still some limitations where
generated reviews can be either off-point or overly general. To address these
issues, we introduce Retrieval-Augmented Reviewer (RARe), which leverages
Retrieval-Augmented Generation (RAG) to combine retrieval-based and generative
methods, explicitly incorporating external domain knowledge into the code
review process. RARe uses a dense retriever to select the most relevant reviews
from the codebase, which then enrich the input for a neural generator,
utilizing the contextual learning capacity of large language models (LLMs), to
produce the final review. RARe outperforms state-of-the-art methods on two
benchmark datasets, achieving BLEU-4 scores of 12.32 and 12.96, respectively.
Its effectiveness is further validated through a detailed human evaluation and
a case study using an interpretability tool, demonstrating its practical
utility and reliability.

</details>


### [8] [SWE-Compass: Towards Unified Evaluation of Agentic Coding Abilities for Large Language Models](https://arxiv.org/abs/2511.05459)
*Jingxuan Xu,Ken Deng,Weihao Li,Songwei Yu,Huaixi Tang,Haoyang Huang,Zhiyi Lai,Zizheng Zhan,Yanan Wu,Chenchen Zhang,Kepeng Lei,Yifan Yao,Xinping Lei,Wenqiang Zhu,Zongxian Feng,Han Li,Junqi Xiong,Dailin Li,Zuchen Gao,Kun Wu,Wen Xiang,Ziqi Zhan,Yuanxing Zhang,Wuxuan Gong,Ziyuan Gao,Guanxiang Wang,Yirong Xue,Xiaojiang Zhang,Jinghui Wang,Huiming Wang,Wenhao Zhuang,Zhaoxiang Zhang,Yuqun Zhang,Haotian Zhang,Bin Chen,Jiaheng Liu*

Main category: cs.SE

TL;DR: 本文提出了SWE-Compass代码基准，覆盖丰富任务、场景和编程语言，能科学诊断大模型的软件工程能力，对推动智能编程研究具有实际价值。


<details>
  <summary>Details</summary>
Motivation: 现有对大语言模型（LLMs）在软件工程领域评估存在覆盖任务窄、语言偏倚和与真实开发流程脱节等问题，不能全面衡量模型的实际工程能力。

Method: 作者提出SWE-Compass基准，将多样的代码相关评测统一到结构化、与生产对齐的框架中，涵盖8种任务类型、8种编程场景和10种编程语言，并从GitHub拉取请求中精心筛选2000条高质量样本。使用两种代理式框架，评测十个SOTA大模型。

Result: SWE-Compass能够区分不同任务类型、语言和场景的难易层级，为大模型代码能力评估提供了科学、可复现的基准。同时贴合真实开发实践。

Conclusion: SWE-Compass填补了现有代码基准的不足，为推进大模型在软件工程领域的智能编程能力评估和提升提供了有力工具。

Abstract: Evaluating large language models (LLMs) for software engineering has been
limited by narrow task coverage, language bias, and insufficient alignment with
real-world developer workflows. Existing benchmarks often focus on algorithmic
problems or Python-centric bug fixing, leaving critical dimensions of software
engineering underexplored. To address these gaps, we introduce SWE-Compass1, a
comprehensive benchmark that unifies heterogeneous code-related evaluations
into a structured and production-aligned framework. SWE-Compass spans 8 task
types, 8 programming scenarios, and 10 programming languages, with 2000
high-quality instances curated from authentic GitHub pull requests and refined
through systematic filtering and validation. We benchmark ten state-of-the-art
LLMs under two agentic frameworks, SWE-Agent and Claude Code, revealing a clear
hierarchy of difficulty across task types, languages, and scenarios. Moreover,
by aligning evaluation with real-world developer practices, SWE-Compass
provides a rigorous and reproducible foundation for diagnosing and advancing
agentic coding capabilities in large language models.

</details>


### [9] [A Metamorphic Testing Perspective on Knowledge Distillation for Language Models of Code: Does the Student Deeply Mimic the Teacher?](https://arxiv.org/abs/2511.05476)
*Md. Abdul Awal,Mrigank Rochan,Chanchal K. Roy*

Main category: cs.SE

TL;DR: 本工作提出了MetaCompress框架，用于检测代码语言模型蒸馏过程中学生模型与教师模型在行为上的差异，发现传统评估难以揭示学生模型深层不足，MetaCompress可作为知识蒸馏模型行为保真度检测的新方法。


<details>
  <summary>Details</summary>
Motivation: 变换器模型在代码分析任务中表现优异，但实际应用受限于高算力消耗、推理速度慢及环境影响。知识蒸馏作为压缩模型方案虽然有效，但学生模型是否真正模仿教师模型行为，传统准确率评估难以揭示其深层差异。

Method: 提出MetaCompress——一种变形测试框架，通过行为保持的变形关系系统性比较教师模型与学生模型输出，从而评估行为保真度。

Result: MetaCompress在两项代码相关任务上，对经三种蒸馏方式（Compressor、AVATAR、MORPH）压缩的学生模型进行评估，揭示学生模型最多存在62%的行为差异，并能发现学生模型在对抗攻击下性能下降高达285%。

Conclusion: 单纯依赖准确率评估无法全面衡量蒸馏后学生模型的质量，MetaCompress有效补充分析行为保真度的空白，是评测压缩代码语言模型的实用工具。

Abstract: Transformer-based language models of code have achieved state-of-the-art
performance across a wide range of software analytics tasks, but their
practical deployment remains limited due to high computational costs, slow
inference speeds, and significant environmental impact. To address these
challenges, recent research has increasingly explored knowledge distillation as
a method for compressing a large language model of code (the teacher) into a
smaller model (the student) while maintaining performance. However, the degree
to which a student model deeply mimics the predictive behavior and internal
representations of its teacher remains largely unexplored, as current
accuracy-based evaluation provides only a surface-level view of model quality
and often fails to capture more profound discrepancies in behavioral fidelity
between the teacher and student models. To address this gap, we empirically
show that the student model often fails to deeply mimic the teacher model,
resulting in up to 285% greater performance drop under adversarial attacks,
which is not captured by traditional accuracy-based evaluation. Therefore, we
propose MetaCompress, a metamorphic testing framework that systematically
evaluates behavioral fidelity by comparing the outputs of teacher and student
models under a set of behavior-preserving metamorphic relations. We evaluate
MetaCompress on two widely studied tasks, using compressed versions of popular
language models of code, obtained via three different knowledge distillation
techniques: Compressor, AVATAR, and MORPH. The results show that MetaCompress
identifies up to 62% behavioral discrepancies in student models, underscoring
the need for behavioral fidelity evaluation within the knowledge distillation
pipeline and establishing MetaCompress as a practical framework for testing
compressed language models of code derived through knowledge distillation.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [10] [Fast Ramsey Quantifier Elimination in LIRA (with applications to liveness checking)](https://arxiv.org/abs/2511.05323)
*Kilian Lichtner,Pascal Bergsträßer,Moses Ganardi,Anthony W. Lin,Georg Zetzsche*

Main category: cs.LO

TL;DR: REAL是一个高效消除（存在性）Ramsey量词的自动化工具，支持整数、实数及其混合线性算术理论，显著提升了处理速度；还能自动扩展FASTer达到活性验证，推动意义在于自动化处理一阶逻辑不可表达的程序属性。


<details>
  <summary>Details</summary>
Motivation: Ramsey量词为程序验证中涉及无限团证明的属性提供统一框架，这类属性无法用一阶逻辑表达，比如活性验证与单子可分性；缺乏高效工具自动处理含Ramsey量词的线性算术理论问题。

Method: 开发REAL工具，实现了对存在性线性整数、实数及混合算术理论中Ramsey量词的高效消除，并扩展SMT-LIB输入格式以适配Ramsey量词。该方法相比原型系统有显著速度提升。

Result: REAL能自动消除LIA、LRA、LIRA中存在性Ramsey量词，提供易用的输入方式，并显著提升运行速度；同时通过将FASTer工具的输出自动翻译为新的SMT-LIB扩展格式，实现了对活性属性的自动验证。

Conclusion: REAL工具推进了程序验证中无穷团相关问题的自动化和高效处理，为含Ramsey量词程序属性的建模与检验提供了实用手段。

Abstract: Ramsey quantifiers have recently been proposed as a unified framework for
handling properties of interests in program verification involving proofs in
the form of infinite cliques, which are not expressible in first-order logic.
Among others, these include liveness verification and monadic decomposability.
We present the tool REAL, which implements an efficient elimination of Ramsey
quantifiers in existential linear arithmetic theories over integers (LIA),
reals (LRA), and the mixed case (LIRA). The tool supports a convenient input
format, which is an extension of SMT-LIB over the aforementioned theories with
Ramsey quantifiers. We also demonstrate a substantial speedup from the original
prototype. As an application, we provide an automatic translation from FASTer
(a tool for verifying reachability over infinite-state systems) output format
to our extension of SMT-LIB and show how our tool extends FASTer to liveness
checking.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [11] [Evaluating LLMs' Reasoning Over Ordered Procedural Steps](https://arxiv.org/abs/2511.04688)
*Adrita Anika,Md Messal Monem Miah*

Main category: cs.CL

TL;DR: 本文评估了主流大语言模型在食谱步骤乱序重建任务中的表现。结果显示，序列越长或乱序越严重，模型推理能力越弱，凸显了当前模型在程序性推理中的不足。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）在处理程序性推理任务，尤其是涉及步骤顺序影响结果的问题方面，还存在不足。任务如食谱步骤排序，正确的步骤顺序对任务成功至关重要。本文旨在系统评估现有LLMs在从乱序程序步骤中重构全局有序序列的能力。

Method: 作者使用人工收集的食谱数据集进行评估，并设置零样本（zero-shot）和少样本（few-shot）实验。评价体系包括了排名和序列对齐领域公认的指标：Kendall's Tau、归一化最长公共子序列（NLCS）和归一化编辑距离（NED），全面考察排序质量。

Result: 实验结果表明，随着序列长度的增加，模型性能显著下降，反映出更长程序的复杂性。同时，输入步骤的扰动幅度越大（即乱序程度越高），性能进一步降低。

Conclusion: 目前主流LLMs在程序性推理，尤其是面对更长、更混乱的输入时存在明显局限性。该研究揭示了模型在处理步骤顺序重建方面的挑战，为相关领域进一步改进提供了参考。

Abstract: Reasoning over procedural sequences, where the order of steps directly
impacts outcomes, is a critical capability for large language models (LLMs). In
this work, we study the task of reconstructing globally ordered sequences from
shuffled procedural steps, using a curated dataset of food recipes, a domain
where correct sequencing is essential for task success. We evaluate several
LLMs under zero-shot and few-shot settings and present a comprehensive
evaluation framework that adapts established metrics from ranking and sequence
alignment. These include Kendall's Tau, Normalized Longest Common Subsequence
(NLCS), and Normalized Edit Distance (NED), which capture complementary aspects
of ordering quality. Our analysis shows that model performance declines with
increasing sequence length, reflecting the added complexity of longer
procedures. We also find that greater step displacement in the input,
corresponding to more severe shuffling, leads to further degradation. These
findings highlight the limitations of current LLMs in procedural reasoning,
especially with longer and more disordered inputs.

</details>


### [12] [Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks](https://arxiv.org/abs/2511.04689)
*Peiyu Li,Xiuxiu Tang,Si Chen,Ying Cheng,Ronald Metoyer,Ting Hua,Nitesh V. Chawla*

Main category: cs.CL

TL;DR: ATLAS用自适应测试和IRT显著压缩题量且提升了大模型评测精准度，暴露了部分基准题目问题，优化排序，工具已开源。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型评估方法需要成千上万个基准测试题目，不仅消耗时间和资源，还因为所有题目被平等对待（尽管其难易度和信息量各异）导致评估结果不精确。此外，部分题目因为标注或设计问题甚至会误导评测结果。

Method: 提出ATLAS框架，基于项目反应理论（IRT）和Fisher信息引导的题目自适应选择方法，根据模型能力动态调整题目集合，用少量高效题目准确评估模型水平。

Result: ATLAS在保证测量精度的前提下，实现了题目数的90%缩减：如在HellaSwag基准上，5,608道题仅需42道即可获得相当的评测效果（MAE仅0.154）。同时，该方法能有效减少题目重复率与模型间测试重叠度，并发现当前静态评测中部分题目存在负向区分度（3-6%），会误导模型排序；IRT方法可令23-31%模型的排名发生大于10位的变动。

Conclusion: ATLAS极大提高了大模型评估的效率和精度，克服了传统方法在题目选择与评估准确性上的不足。IRT与自适应测试为大模型公平有效评估提供了新的解决方案，相关工具已开源。

Abstract: Large language model evaluation requires thousands of benchmark items, making
evaluations expensive and slow. Existing methods compute average accuracy
across fixed item sets, treating all items equally despite varying quality and
informativeness. We present ATLAS an adaptive testing framework using Item
Response Theory (IRT) to estimate model ability through Fisher
information-guided item selection. Our analysis of five major benchmarks
reveals that 3-6% of items exhibit negative discrimination, indicating
annotation errors that corrupt static evaluation. ATLAS achieves 90% item
reduction while maintaining measurement precision: on HellaSwag (5,608 items),
we match full-benchmark estimates using only 42 items with 0.154 MAE. Our
framework maintains item exposure rates below 10% and test overlap at 16-27%,
compared to static benchmarks where every model sees all items (100% exposure).
Among 4,000+ tested models, IRT ranks differ from accuracy ranks: models with
the same accuracy get different IRT scores, and 23-31% of all models shift by
more than 10 rank positions. Code and calibrated item banks are available at
https://github.com/Peiyu-Georgia-Li/ATLAS.git.

</details>


### [13] [SARC: Sentiment-Augmented Deep Role Clustering for Fake News Detection](https://arxiv.org/abs/2511.04692)
*Jingqing Wang,Jiaxing Shang,Rong Xu,Fei Hao,Tianjin Huang,Geyong Min*

Main category: cs.CL

TL;DR: SARC框架通过结合用户情感、角色聚类和联合优化，有效提升了虚假新闻检测的准确率，并在多个数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将情感特征作为辅助信号，忽视了用户在情感表达中的角色差异，同一情感极性可能来源于不同角色的用户，降低了检测的细致性和效果。

Method: 方法包括（1）利用BiGRU结合Attention机制和情感编码生成用户特征，（2）采用可微分深度聚类自动分类用户角色，（3）提出将角色聚类与虚假新闻检测联合优化的目标函数。

Result: 实验表明，SARC框架在RumourEval-19和Weibo-comp两个数据集上显著超过了现有基准方法。

Conclusion: SARC框架在两个基准数据集上所有评价指标均优于基线模型，展示了其卓越的虚假新闻检测能力。

Abstract: Fake news detection has been a long-standing research focus in social
networks. Recent studies suggest that incorporating sentiment information from
both news content and user comments can enhance detection performance. However,
existing approaches typically treat sentiment features as auxiliary signals,
overlooking role differentiation, that is, the same sentiment polarity may
originate from users with distinct roles, thereby limiting their ability to
capture nuanced patterns for effective detection. To address this issue, we
propose SARC, a Sentiment-Augmented Role Clustering framework which utilizes
sentiment-enhanced deep clustering to identify user roles for improved fake
news detection. The framework first generates user features through joint
comment text representation (with BiGRU and Attention mechanism) and sentiment
encoding. It then constructs a differentiable deep clustering module to
automatically categorize user roles. Finally, unlike existing approaches which
take fake news label as the unique supervision signal, we propose a joint
optimization objective integrating role clustering and fake news detection to
further improve the model performance. Experimental results on two benchmark
datasets, RumourEval-19 and Weibo-comp, demonstrate that SARC achieves superior
performance across all metrics compared to baseline models. The code is
available at: https://github.com/jxshang/SARC.

</details>


### [14] [Reasoning Up the Instruction Ladder for Controllable Language Models](https://arxiv.org/abs/2511.04694)
*Zishuo Zheng,Vidhisha Balachandran,Chan Young Park,Faeze Brahman,Sachin Kumar*

Main category: cs.CL

TL;DR: 本研究提出通过推理机制解决LLM多源指令冲突，开发VerIH数据集，训练后使模型能遵循指令层级，提升安全性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在实际高风险决策场景中，需整合模型开发者、用户、工具等多方指令。缺乏明确的指令层级会影响模型可靠性和可控性，因此需要在模型中实现指令优先级的有效解析与执行。

Method: 将指令层级（IH）问题视为推理任务，利用构建的VerIH数据集（包括符合和冲突的系统-用户指令），采用轻量化强化学习对模型进行微调，提升模型在指令优先级处理上的能力。

Result: 微调后的模型在多项指令遵循和层级基准上表现提升，并且推理能力可泛化到安全相关的新场景，对抗恶意输入（如越狱、指令注入）更加健壮。

Conclusion: 通过在LLM中引入指令层级推理能力，可以实现更可靠、可控的模型，且在安全问题如jailbreak和prompt injection防御上有显著提升。

Abstract: As large language model (LLM) based systems take on high-stakes roles in
real-world decision-making, they must reconcile competing instructions from
multiple sources (e.g., model developers, users, and tools) within a single
prompt context. Thus, enforcing an instruction hierarchy (IH) in LLMs, where
higher-level directives override lower-priority requests, is critical for the
reliability and controllability of LLMs. In this work, we reframe instruction
hierarchy resolution as a reasoning task. Specifically, the model must first
"think" about the relationship between a given user prompt and higher-priority
(system) instructions before generating a response. To enable this capability
via training, we construct VerIH, an instruction hierarchy dataset of
constraint-following tasks with verifiable answers. This dataset comprises both
aligned and conflicting system-user instructions. We show that lightweight
reinforcement learning with VerIH effectively transfers general reasoning
capabilities of models to instruction prioritization. Our finetuned models
achieve consistent improvements on instruction following and instruction
hierarchy benchmarks. This reasoning ability also generalizes to
safety-critical settings beyond the training distribution. By treating safety
issues as resolving conflicts between adversarial user inputs and predefined
higher-priority policies, our trained model enhances robustness against
jailbreak and prompt injection attacks. These results demonstrate that
reasoning over instruction hierarchies provides a practical path to reliable
LLMs, where updates to system prompts yield controllable and robust changes in
model behavior.

</details>


### [15] [EncouRAGe: Evaluating RAG Local, Fast, and Reliable](https://arxiv.org/abs/2511.04696)
*Jan Strich,Adeline Scharfenberg,Chris Biemann,Martin Semmann*

Main category: cs.CL

TL;DR: 本文提出EncouRAGe框架，助力RAG系统开发与评估，混合BM25方法表现最佳，RAG仍逊色Oracle Context，reranking效果有限。


<details>
  <summary>Details</summary>
Motivation: RAG系统开发和评测流程复杂、可重复性及指标多元化需求强烈，缺少科学且灵活的开发与评测工具。

Method: 提出了一个模块化的Python框架EncouRAGe，对多种标准数据集进行RAG工作流搭建与评测，比较不同检索与生成方法的效果。

Result: 框架在25k QA对和51k文档数据集上评测，混合BM25取得最优结果，RAG相较Oracle Context仍有差距，reranking提升有限但增加延时。

Conclusion: RAG系统在评测中仍不及Oracle Context，混合BM25方法在所有数据集上表现最佳，reranking带来的性能提升有限且增加延迟。

Abstract: We introduce EncouRAGe, a comprehensive Python framework designed to
streamline the development and evaluation of Retrieval-Augmented Generation
(RAG) systems using Large Language Models (LLMs) and Embedding Models.
EncouRAGe comprises five modular and extensible components: Type Manifest, RAG
Factory, Inference, Vector Store, and Metrics, facilitating flexible
experimentation and extensible development. The framework emphasizes scientific
reproducibility, diverse evaluation metrics, and local deployment, enabling
researchers to efficiently assess datasets within RAG workflows. This paper
presents implementation details and an extensive evaluation across multiple
benchmark datasets, including 25k QA pairs and over 51k documents. Our results
show that RAG still underperforms compared to the Oracle Context, while Hybrid
BM25 consistently achieves the best results across all four datasets. We
further examine the effects of reranking, observing only marginal performance
improvements accompanied by higher response latency.

</details>


### [16] [multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health Disorder](https://arxiv.org/abs/2511.04698)
*K M Sajjadul Islam,John Fields,Praveen Madiraju*

Main category: cs.CL

TL;DR: 本文提出了一种多类别心理健康状态检测模型multiMentalRoBERTa，基于社交媒体文本，取得了优于现有方法的分类性能，并结合可解释性分析，有助于提升心理健康远程支持系统的效果与安全性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体文本中及早发现心理健康障碍对于及时提供支持、风险评估和转介资源至关重要。

Method: 提出并微调了multiMentalRoBERTa模型，用于多类常见心理健康状况（如压力、焦虑、抑郁、创伤后应激障碍（PTSD）、自杀意念和中性对话）的分类；采用了多数据集进行分析，比较了多种传统机器学习方法、领域特定和大型语言模型；并使用可解释性方法如Layer Integrated Gradients和KeyBERT来分析分类驱动的词汇线索。

Result: multiMentalRoBERTa在六分类任务中获得了0.839，在去除压力类别后的五分类任务中获得了0.870的macro F1分数，均优于fine-tuned MentalBERT和其他基线模型。数据分析揭示了不同类别间的关联性，并通过可解释性手段区分类别。

Conclusion: 微调的transformer模型在敏感心理健康自动检测场景下展现出较高准确性和解释性，提出的multiMentalRoBERTa方案既轻量又可部署，有望提升心理健康平台的支持能力，同时需关注公平性、偏见缓解与人为安全审核。

Abstract: The early detection of mental health disorders from social media text is
critical for enabling timely support, risk assessment, and referral to
appropriate resources. This work introduces multiMentalRoBERTa, a fine-tuned
RoBERTa model designed for multiclass classification of common mental health
conditions, including stress, anxiety, depression, post-traumatic stress
disorder (PTSD), suicidal ideation, and neutral discourse. Drawing on multiple
curated datasets, data exploration is conducted to analyze class overlaps,
revealing strong correlations between depression and suicidal ideation as well
as anxiety and PTSD, while stress emerges as a broad, overlapping category.
Comparative experiments with traditional machine learning methods,
domain-specific transformers, and prompting-based large language models
demonstrate that multiMentalRoBERTa achieves superior performance, with macro
F1-scores of 0.839 in the six-class setup and 0.870 in the five-class setup
(excluding stress), outperforming both fine-tuned MentalBERT and baseline
classifiers. Beyond predictive accuracy, explainability methods, including
Layer Integrated Gradients and KeyBERT, are applied to identify lexical cues
that drive classification, with a particular focus on distinguishing depression
from suicidal ideation. The findings emphasize the effectiveness of fine-tuned
transformers for reliable and interpretable detection in sensitive contexts,
while also underscoring the importance of fairness, bias mitigation, and
human-in-the-loop safety protocols. Overall, multiMentalRoBERTa is presented as
a lightweight, robust, and deployable solution for enhancing support in mental
health platforms.

</details>


### [17] [UA-Code-Bench: A Competitive Programming Benchmark for Evaluating LLM Code Generation in Ukrainian](https://arxiv.org/abs/2511.05040)
*Mykyta Syromiatnikov,Victoria Ruvinskaya*

Main category: cs.CL

TL;DR: 本文提出了UA-Code-Bench，这是一个专门用于评估大语言模型在乌克兰语代码生成和问题解决能力的新开源基准，总共包含500个题目，覆盖五个难度等级。对13个主流模型（包括开源和闭源）进行了系统测试，展示了在低资源语言背景下现有模型的显著挑战。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型评测多聚焦于英语直接翻译或基础理解，缺乏针对低资源语言、复杂编程任务和实际代码生成能力的深入评测工具。

Method: 收集Eolymp平台的500道乌克兰语编程题，按照难度分层；用一问一答的prompt让13种模型生成Python代码，再在真实竞赛环境用隐藏测试评判代码正确性，同时分析解决方案的独特性及资源消耗。

Result: 主流模型（包括OpenAI o3和GPT-5）仅能解决约50%的题目，显示低资源语言下代码生成难度较大，并在不同难度分层、代码独特性及计算资源消耗上给出了详细分析。

Conclusion: 竞争性编程基准在评估大语言模型，尤其是低资源语言环境下非常重要。该研究为多语言代码生成和推理能力增强的模型提供了方向。

Abstract: Evaluating the real capabilities of large language models in low-resource
languages still represents a challenge, as many existing benchmarks focus on
widespread tasks translated from English or evaluate only simple language
understanding. This paper introduces UA-Code-Bench, a new open-source benchmark
established for a thorough evaluation of language models' code generation and
competitive programming problem-solving abilities in Ukrainian. The benchmark
comprises 500 problems from the Eolymp platform, evenly distributed across five
complexity levels from very easy to very hard. A diverse set of 13 leading
proprietary and open-source models, generating Python solutions based on a
one-shot prompt, was evaluated via the dedicated Eolymp environment against
hidden tests, ensuring code correctness. The obtained results reveal that even
top-performing models, such as OpenAI o3 and GPT-5, solve only half of the
problems, highlighting the challenge of code generation in low-resource natural
language. Furthermore, this research presents a comprehensive analysis of
performance across various difficulty levels, as well as an assessment of
solution uniqueness and computational efficiency, measured by both elapsed time
and memory consumption of the generated solutions. In conclusion, this work
demonstrates the value of competitive programming benchmarks in evaluating
large language models, especially in underrepresented languages. It also paves
the way for future research on multilingual code generation and
reasoning-enhanced models. The benchmark, data parsing, preparation, code
generation, and evaluation scripts are available at
https://huggingface.co/datasets/NLPForUA/ua-code-bench.

</details>


### [18] [Cross-Lingual SynthDocs: A Large-Scale Synthetic Corpus for Any to Arabic OCR and Document Understanding](https://arxiv.org/abs/2511.04699)
*Haneen Al-Homoud,Asma Ibrahim,Murtadha Al-Jubran,Fahad Al-Otaibi,Yazeed Al-Harbi,Daulet Toibazar,Kesen Wang,Pedro J. Moreno*

Main category: cs.CL

TL;DR: 该文提出了一套阿拉伯语为主、具规模和多样性的合成文档数据集，通过新颖的数据生成流程大幅提升了主流模型在相关任务中的表现，为多语言文档分析研究提供了重要数据资源。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语在光学字符识别（OCR）和文档理解（DU）领域资源稀缺，阻碍了相关研究和应用的进展。该工作致力于缓解这一资源短缺问题。

Method: 构建了一个名为Cross-Lingual SynthDocs的大规模合成语料库，包含250多万份样本（包括文本、完整标注表格和基于真实数据的图表）。此流程利用真实扫描背景、双语布局和兼容变音符号的字体来增强阿拉伯文档的印刷和结构复杂性，并为图表和表格设计多种渲染风格。

Result: 在SynthDocs上对Qwen-2.5-VL进行微调后，在多个阿拉伯语公开基准的OCR任务上，Word Error Rate（WER）和Character Error Rate（CER）均显著改善，对表格和图表的Tree-Edit Distance Similarity (TEDS) 和 Chart Extraction Score (CharTeX)等指标也有提升。

Conclusion: SynthDocs为多语言文档分析研究提供了可扩展且高度还原视觉效果的数据资源，显著推进了阿拉伯语OCR和DU领域的发展。

Abstract: Cross-Lingual SynthDocs is a large-scale synthetic corpus designed to address
the scarcity of Arabic resources for Optical Character Recognition (OCR) and
Document Understanding (DU). The dataset comprises over 2.5 million of samples,
including 1.5 million textual data, 270K fully annotated tables, and hundred
thousands of real data based charts. Our pipeline leverages authentic scanned
backgrounds, bilingual layouts, and diacritic aware fonts to capture the
typographic and structural complexity of Arabic documents. In addition to text,
the corpus includes variety of rendered styles for charts and tables.
Finetuning Qwen-2.5-VL on SynthDocs yields consistent improvements in Word
Error Rate (WER) and Character Error Rate (CER) in terms of OCR across multiple
public Arabic benchmarks, Tree-Edit Distance Similarity (TEDS) and Chart
Extraction Score (CharTeX) improved as well in other modalities. SynthDocs
provides a scalable, visually realistic resource for advancing research in
multilingual document analysis.

</details>


### [19] [Separate the Wheat from the Chaff: Winnowing Down Divergent Views in Retrieval Augmented Generation](https://arxiv.org/abs/2511.04700)
*Song Wang,Zihan Chen,Peng Wang,Zhepei Wei,Zhen Tan,Yu Meng,Cong Shen,Jundong Li*

Main category: cs.CL

TL;DR: WinnowRAG 在保持强大适应性的同时，能高效去噪，提升检索增强生成（RAG）系统的准确性和泛用性，实验效果优异。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）可以帮助大语言模型（LLM）获取外部知识以弥补即时性或专业性不足，但直接增加检索文档数量往往引入噪声，降低生成结果的准确性。因此，迫切需要一种高效方法筛除无关文档，仅保留有用信息。

Method: 提出了 WinnowRAG 框架。第一阶段采用“查询感知聚类”，将相似文档分组，每组赋给一个 LLM agent 生成独立答案。第二阶段利用一个评审型 LLM，对多 agent 的答案进行评估，逐步分辨有用和噪声文档。同时设计了两种答案融合策略，最大化有用知识保留。整个框架无需微调，具备高度通用性。

Result: 在多个真实数据集上大量实验，WinnowRAG 在准确率等主要指标均优于现有主流基线方法，验证了其实用性和效果。

Conclusion: 该方法能系统性筛除无用文档、聚焦关键信息，有效提升 RAG 生成质量且易于应用到各类场景，无需额外训练。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by
integrating external knowledge sources to address their limitations in
accessing up-to-date or specialized information. A natural strategy to increase
the likelihood of retrieving relevant information is to expand the number of
retrieved documents. However, involving more documents could introduce
significant noise, as many documents may be irrelevant or misleading, thereby
reducing the overall accuracy of the generated responses. To overcome the
challenge associated with handling a larger number of documents, we propose
WinnowRAG, a novel RAG framework designed to systematically filter out noisy
documents while preserving valuable content -- a process we refer to as
winnowing. WinnowRAG operates in two stages: In Stage I, we perform query-aware
clustering to group similar documents and form distinct topic clusters. Each
cluster is assigned to an LLM agent for generating a unique answer. In Stage
II, we perform winnowing, wherein a critic LLM evaluates the outputs of
multiple agents and iteratively separates useful documents from noisy ones. To
retain useful documents when discarding agents, we propose two strategic
merging techniques to ensure that only relevant knowledge is used for
generating the final response. Crucially, WinnowRAG is model-agnostic and does
not require any model fine-tuning, making it easily adaptable to various tasks.
Extensive experiments on various realistic datasets demonstrate the
effectiveness of WinnowRAG over state-of-the-art baselines.

</details>


### [20] [Measuring what Matters: Construct Validity in Large Language Model Benchmarks](https://arxiv.org/abs/2511.04703)
*Andrew M. Bean,Ryan Othniel Kearns,Angelika Romanou,Franziska Sofia Hafner,Harry Mayne,Jan Batzner,Negar Foroutan,Chris Schmitz,Karolina Korgul,Hunar Batra,Oishi Deb,Emma Beharry,Cornelius Emde,Thomas Foster,Anna Gausen,María Grandury,Simeng Han,Valentin Hofmann,Lujain Ibrahim,Hazel Kim,Hannah Rose Kirk,Fangru Lin,Gabrielle Kaili-May Liu,Lennart Luettgau,Jabez Magomere,Jonathan Rystrøm,Anna Sotnikova,Yushi Yang,Yilun Zhao,Adel Bibi,Antoine Bosselut,Ronald Clark,Arman Cohan,Jakob Foerster,Yarin Gal,Scott A. Hale,Inioluwa Deborah Raji,Christopher Summerfield,Philip H. S. Torr,Cozmin Ududec,Luc Rocher,Adam Mahdi*

Main category: cs.CL

TL;DR: 研究系统性复盘了LLM评测基准，发现其构念效度常被忽视，影响评测可靠性，并提出八项改进建议。


<details>
  <summary>Details</summary>
Motivation: LLM在部署前需做好能力和安全性、健壮性等方面的评测。但对于这些抽象和复杂的现象，现有评测在构念效度上存在不足，无法真实反映所需评测的属性。

Method: 组织29位专家评审，对445个来自NLP和ML领域顶会的LLM评测基准进行了系统性回顾与分析，辨析任务、指标及被测现象的模式和问题。

Result: 发现许多评测在目标现象、任务设计与计分方式上存在模式性问题，影响结论的有效性。为此，提出八项关键建议及实际可操作的指南，以支持研究者和从业者改进LLM评测标准。

Conclusion: 当前对大型语言模型（LLM）的评测存在构念效度不足的问题，很多评测结果的有效性受到挑战。作者提出了八项关键建议，指导如何改进LLM基准测试的开发。

Abstract: Evaluating large language models (LLMs) is crucial for both assessing their
capabilities and identifying safety or robustness issues prior to deployment.
Reliably measuring abstract and complex phenomena such as 'safety' and
'robustness' requires strong construct validity, that is, having measures that
represent what matters to the phenomenon. With a team of 29 expert reviewers,
we conduct a systematic review of 445 LLM benchmarks from leading conferences
in natural language processing and machine learning. Across the reviewed
articles, we find patterns related to the measured phenomena, tasks, and
scoring metrics which undermine the validity of the resulting claims. To
address these shortcomings, we provide eight key recommendations and detailed
actionable guidance to researchers and practitioners in developing LLM
benchmarks.

</details>


### [21] [POLIS-Bench: Towards Multi-Dimensional Evaluation of LLMs for Bilingual Policy Tasks in Governmental Scenarios](https://arxiv.org/abs/2511.04705)
*Tingyue Yang,Junchi Yao,Yuhui Guo,Chang Liu*

Main category: cs.CL

TL;DR: 提出首个政府双语政策场景的LLM评测套件POLIS-Bench，包括最新语料、场景任务和双指标评估。实验证明微调后的轻量模型在多个政策任务上低成本达到甚至超越闭源强模型，为政策AI应用提供新技术支撑。


<details>
  <summary>Details</summary>
Motivation: 目前针对政府双语政策场景的LLM评测缺乏系统性和权威，现有基准无法全面反映模型在真实政策应用中的表现。

Method: 提出了POLIS-Bench评测套件，包括最新的双语政策语料库、基于场景设计的任务（条款检索与解释、解决方案生成、合规判断），以及结合语义相似性和准确率的双指标评估框架。

Result: 采用POLIS-Bench对10余种主流LLM进行了大规模评测，发现推理类模型在跨任务稳定性和准确率方面表现优异，合规类任务难度较高。通过基准微调，轻量化开源模型POLIS系列在多个政策子任务上与主流封闭模型持平并实现超越，且显著降低成本。

Conclusion: POLIS-Bench为政府政策场景下的LLM系统评测提供了系统且专业的工具，有助于推动合规、高效的政策类AI在实际应用中的落地。

Abstract: We introduce POLIS-Bench, the first rigorous, systematic evaluation suite
designed for LLMs operating in governmental bilingual policy scenarios.
Compared to existing benchmarks, POLIS-Bench introduces three major
advancements. (i) Up-to-date Bilingual Corpus: We construct an extensive,
up-to-date policy corpus that significantly scales the effective assessment
sample size, ensuring relevance to current governance practice. (ii)
Scenario-Grounded Task Design: We distill three specialized, scenario-grounded
tasks -- Clause Retrieval & Interpretation, Solution Generation, and the
Compliance Judgmen--to comprehensively probe model understanding and
application. (iii) Dual-Metric Evaluation Framework: We establish a novel
dual-metric evaluation framework combining semantic similarity with accuracy
rate to precisely measure both content alignment and task requirement
adherence. A large-scale evaluation of over 10 state-of-the-art LLMs on
POLIS-Bench reveals a clear performance hierarchy where reasoning models
maintain superior cross-task stability and accuracy, highlighting the
difficulty of compliance tasks. Furthermore, leveraging our benchmark, we
successfully fine-tune a lightweight open-source model. The resulting POLIS
series models achieves parity with, or surpasses, strong proprietary baselines
on multiple policy subtasks at a significantly reduced cost, providing a
cost-effective and compliant path for robust real-world governmental
deployment.

</details>


### [22] [GEMMA-SQL: A Novel Text-to-SQL Model Based on Large Language Models](https://arxiv.org/abs/2511.04710)
*Hari Mohan Pandey,Anshul Gupta,Subham Sarkar,Minakshi Tomer,Schneider Johannes,Yan Gong*

Main category: cs.CL

TL;DR: GEMMA-SQL是一款开源、轻量、高效的文本到SQL模型，通过资源高效微调和多提示策略取得优异性能并支持低成本部署，超越主流方法，被验证为实用且可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有大模型对硬件资源要求高，部署成本大，且文本到SQL系统的准确性还有提升空间。作者希望开发一种轻量、高效且易于部署的高性能Text-to-SQL模型。

Method: 在Gemma 2B架构上，采用逐步资源高效微调方法，并结合多种提示策略（如few-shot learning）进行训练和评估，尤其使用SPIDER基准数据集。还开发了指令微调版本（GEMMA-SQL Instruct）。

Result: GEMMA-SQL Instruct在SPIDER基准上的Test-Suite准确率为66.8%，Exact Set Match准确率为63.3%，超越IRNet、RYANSQL和CodeXDavinci等现有方法。可在低成本硬件上运行，具有高适应性和扩展性。

Conclusion: GEMMA-SQL通过高效微调和定制化提示设计，显著提升了文本到SQL的转换效果，同时易于部署和扩展，为实际应用提供了兼容性强且资源消耗低的开源替代方案。

Abstract: Text-to-SQL systems enable users to interact with structured databases using
natural language, eliminating the need for specialized programming knowledge.
In this work, we introduce GEMMA-SQL, a lightweight and efficient text-to-SQL
model built upon the open-source Gemma 2B architecture. Unlike many large
language models (LLMs), GEMMA-SQL is fine-tuned in a resource-efficient,
iterative manner and can be deployed on low-cost hardware. Leveraging the
SPIDER benchmark for training and evaluation, GEMMA-SQL combines multiple
prompting strategies, including few-shot learning, to enhance SQL query
generation accuracy. The instruction-tuned variant, GEMMA-SQL Instruct,
achieves 66.8% Test-Suite accuracy and 63.3% Exact Set Match accuracy,
outperforming several state-of-the-art baselines such as IRNet, RYANSQL, and
CodeXDavinci. The proposed approach demonstrates that effective prompt design
and targeted instruction tuning can significantly boost performance while
maintaining high scalability and adaptability. These results position GEMMA-SQL
as a practical, open-source alternative for robust and accessible text-to-SQL
systems.

</details>


### [23] [First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation](https://arxiv.org/abs/2511.04715)
*Dmytro Vitel,Anshuman Chhabra*

Main category: cs.CL

TL;DR: 本文挑战了以往关于LLM影响评估层的观点，发现中间层优于首层，并提出新的聚合和评估方法，提升了影响分数的准确性，强调了重新认识LLM决策解读方式的必要性。


<details>
  <summary>Details</summary>
Motivation: 理解和评估训练样本对大规模语言模型（LLM）决策的影响对于模型解释和数据审核至关重要。现有方法受到模型参数量庞大的限制，通常只能在部分层上计算影响。此前研究认为首层（嵌入层）最具信息量，但这一观点基于影响分数抵消效应，需要进一步验证其可靠性。

Method: 提出理论和实证分析，考察影响分数抵消效应的局限性，并比较不同层（尤其是中间注意力层）对影响评估的表现。同时探索影响分数跨层聚合的新方法，如排序和投票机制，替代传统均值法。提出无须模型重训练的影响分数评估方法，并引入新指标Noise Detection Rate（NDR）用于预测影响分数效力。

Result: 中间注意力层为更优的训练样本影响评估层。新提出的聚合方法（排序、投票）优于传统均值法，能够显著提升评估性能。NDR指标在影响评估方面比传统抵消效应更具预测能力。通过各类和不同规模的LLM实验，证实首层并不一定优于末层，颠覆了领域原有认知。

Conclusion: 论文推翻了“首层比末层更适合做训练样本影响评估”的旧观点，确定了更可靠的评估层及聚合与评价方法。结论有助于更精确解释和审核LLM的决策过程。

Abstract: Identifying how training samples influence/impact Large Language Model (LLM)
decision-making is essential for effectively interpreting model decisions and
auditing large-scale datasets. Current training sample influence estimation
methods (also known as influence functions) undertake this goal by utilizing
information flow through the model via its first-order and higher-order
gradient terms. However, owing to the large model sizes of today consisting of
billions of parameters, these influence computations are often restricted to
some subset of model layers to ensure computational feasibility. Prior seminal
work by Yeh et al. (2022) in assessing which layers are best suited for
computing language data influence concluded that the first (embedding) layers
are the most informative for this purpose, using a hypothesis based on
influence scores canceling out (i.e., the cancellation effect). In this work,
we propose theoretical and empirical evidence demonstrating how the
cancellation effect is unreliable, and that middle attention layers are better
estimators for influence. Furthermore, we address the broader challenge of
aggregating influence scores across layers, and showcase how alternatives to
standard averaging (such as ranking and vote-based methods) can lead to
significantly improved performance. Finally, we propose better methods for
evaluating influence score efficacy in LLMs without undertaking model
retraining, and propose a new metric known as the Noise Detection Rate (NDR)
that exhibits strong predictive capability compared to the cancellation effect.
Through extensive experiments across LLMs of varying types and scales, we
concretely determine that the first (layers) are not necessarily better than
the last (layers) for LLM influence estimation, contrasting with prior
knowledge in the field.

</details>


### [24] [Learning to reason about rare diseases through retrieval-augmented agents](https://arxiv.org/abs/2511.04720)
*Ha Young Kim,Jun Li,Ana Beatriz Solana,Carolin M. Pirkl,Benedikt Wiestler,Julia A. Schnabel,Cosmin I. Bercea*

Main category: cs.CL

TL;DR: RADAR通过将医学文献和病例报告检索与AI诊断结合，大幅提升罕见脑部疾病MRI影像的识别准确率，让模型能在数据稀缺场景下更加可靠，并改善诊断解释性。


<details>
  <summary>Details</summary>
Motivation: 稀有疾病在医学影像中属于“长尾”问题，由于训练数据稀缺，AI模型常常表现不佳。临床中，放射科医师会查阅病例报告和文献来辅助诊断罕见病变。本文旨在解决罕见疾病影像诊断准确率低的问题。

Method: 提出RADAR（检索增强诊断推理代理），一种系统，利用AI代理结合外部医学知识。通过句子嵌入器将病例报告和文献进行向量化，并用FAISS索引，支持高效的相似性检索。该代理检索相关临床证据辅助罕见病诊断，无需额外训练，并可无缝集成到各类大型语言模型中。

Result: 在包含280种罕见疾病的NOVA数据集上，RADAR可提升诊断性能最高10.2%，提升最显著的是在开源模型（如DeepSeek）上。检索到的示例还为模型提供了可解释、文献支持的解释。

Conclusion: 检索增强型推理是医学影像领域低发病率罕见疾病诊断的有效方法，不仅提高准确率，还提升了解释性，并具有良好的通用性和易用性。

Abstract: Rare diseases represent the long tail of medical imaging, where AI models
often fail due to the scarcity of representative training data. In clinical
workflows, radiologists frequently consult case reports and literature when
confronted with unfamiliar findings. Following this line of reasoning, we
introduce RADAR, Retrieval Augmented Diagnostic Reasoning Agents, an agentic
system for rare disease detection in brain MRI. Our approach uses AI agents
with access to external medical knowledge by embedding both case reports and
literature using sentence transformers and indexing them with FAISS to enable
efficient similarity search. The agent retrieves clinically relevant evidence
to guide diagnostic decision making on unseen diseases, without the need of
additional training. Designed as a model-agnostic reasoning module, RADAR can
be seamlessly integrated with diverse large language models, consistently
improving their rare pathology recognition and interpretability. On the NOVA
dataset comprising 280 distinct rare diseases, RADAR achieves up to a 10.2%
performance gain, with the strongest improvements observed for open source
models such as DeepSeek. Beyond accuracy, the retrieved examples provide
interpretable, literature grounded explanations, highlighting
retrieval-augmented reasoning as a powerful paradigm for low-prevalence
conditions in medical imaging.

</details>


### [25] [Surprisal reveals diversity gaps in image captioning and different scorers change the story](https://arxiv.org/abs/2511.04754)
*Nikolai Ilinykh,Simon Dobnik*

Main category: cs.CL

TL;DR: 论文提出用surprisal方差度量图像描述多样性，发现人类与模型表现高度依赖评分器，提示多样性评估需多角度、多个评分器。


<details>
  <summary>Details</summary>
Motivation: 现有图像描述多样性评估主要依赖单一评分方法，可能无法准确反映实际语言表现的多样性，因此希望引入更细致的量化方法揭示模型与人类生成描述之间的真实差异。

Method: 提出并采用了以surprisal差异为基础的多样性度量方法，通过在MSCOCO测试集上计算图像描述token的不确定性方差，对比人类描述与五个主流视觉-语言大模型（在贪婪解码和nucleus采样下）生成结果，并分别用caption-trained n-gram语言模型和通用语言模型对这些描述进行rescore，分析多样性表现。

Result: 用caption-trained n-gram模型打分时，人类描述的surprisal方差大约是模型的两倍，但用通用语言模型评分时，结果反而颠倒，显示模型描述多样性反而较高。该现象说明单一评分指标非常容易误导多样性评估。

Conclusion: 依赖单一的评分器评估图像描述的多样性可能会导致截然相反的结论，因此，稳健的多样性评估需要报告多种评分器下的surprisal度量结果。

Abstract: We quantify linguistic diversity in image captioning with surprisal variance
- the spread of token-level negative log-probabilities within a caption set. On
the MSCOCO test set, we compare five state-of-the-art vision-and-language LLMs,
decoded with greedy and nucleus sampling, to human captions. Measured with a
caption-trained n-gram LM, humans display roughly twice the surprisal variance
of models, but rescoring the same captions with a general-language model
reverses the pattern. Our analysis introduces the surprisal-based diversity
metric for image captioning. We show that relying on a single scorer can
completely invert conclusions, thus, robust diversity evaluation must report
surprisal under several scorers.

</details>


### [26] [Explore Data Left Behind in Reinforcement Learning for Reasoning Language Models](https://arxiv.org/abs/2511.04800)
*Chenxi Liu,Junjie Liang,Yuqi Jia,Bochuan Cao,Yang Bai,Heng Huang,Xun Chen*

Main category: cs.CL

TL;DR: 文章提出ERPO框架，通过增强残留提示的探索性恢复训练信号，有效提升大模型在推理任务中的性能，实验结果优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 随着大模型训练规模扩大，越来越多的训练提示（prompts）变成无奖励方差的残留提示（residual prompts），无法为模型提供有效训练信号，影响模型推理能力的提升。

Method: 提出了一种名为ERPO（Explore Residual Prompts in Policy Optimization）的方法，通过为每个提示维护历史记录，对残留提示自适应增加采样温度，激发模型生成更多样化的推理路径，从而恢复训练信号。

Result: 在Qwen2.5等系列模型及多个数学推理基准上，ERPO方法在表现上持续超越了强基线方法。

Conclusion: ERPO能够有效利用残留提示，提升大语言模型在推理任务上的训练效果和多样性。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an
effective approach for improving the reasoning abilities of large language
models (LLMs). The Group Relative Policy Optimization (GRPO) family has
demonstrated strong performance in training LLMs with RLVR. However, as models
train longer and scale larger, more training prompts become residual prompts,
those with zero variance rewards that provide no training signal. Consequently,
fewer prompts contribute to training, reducing diversity and hindering
effectiveness. To fully exploit these residual prompts, we propose the Explore
Residual Prompts in Policy Optimization (ERPO) framework, which encourages
exploration on residual prompts and reactivates their training signals. ERPO
maintains a history tracker for each prompt and adaptively increases the
sampling temperature for residual prompts that previously produced all correct
responses. This encourages the model to generate more diverse reasoning traces,
introducing incorrect responses that revive training signals. Empirical results
on the Qwen2.5 series demonstrate that ERPO consistently surpasses strong
baselines across multiple mathematical reasoning benchmarks.

</details>


### [27] [Trained on Tokens, Calibrated on Concepts: The Emergence of Semantic Calibration in LLMs](https://arxiv.org/abs/2511.04869)
*Preetum Nakkiran,Arwen Bradley,Adam Goliński,Eugene Ndiaye,Michael Kirchhof,Sinead Williamson*

Main category: cs.CL

TL;DR: 本文发现基础大语言模型本身在回答问题时具有较强的语义置信度校准能力，并首次给出理论解释，但微调和链式推理会破坏该能力。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在生成下一个token时表现出良好校准，但其对最终回答语义内容置信度评估能力不明确，研究这一点有助于理解模型输出可信度。

Method: 提出了一种基于采样的语义校准衡量方法，借助最近关于校准与局部损失最优性的联系，理论推导出“B-校准”机制，并设计了相关实验证实理论预测。

Result: 实验证明：1）基础LLM能有效实现语义校准；2）强化学习（RL）步骤的指令微调会破坏这一能力；3）链式思维推理流程也会削弱校准效果。

Conclusion: 本文首次理论上解释了为什么大语言模型（LLM）在未专门训练的情况下能展现出语义层面的置信度校准能力，同时通过实验证明，这种能力在某些情况下会被微调或链式思维推理破坏。

Abstract: Large Language Models (LLMs) often lack meaningful confidence estimates for
their outputs. While base LLMs are known to exhibit next-token calibration, it
remains unclear whether they can assess confidence in the actual meaning of
their responses beyond the token level. We find that, when using a certain
sampling-based notion of semantic calibration, base LLMs are remarkably
well-calibrated: they can meaningfully assess confidence in open-domain
question-answering tasks, despite not being explicitly trained to do so. Our
main theoretical contribution establishes a mechanism for why semantic
calibration emerges as a byproduct of next-token prediction, leveraging a
recent connection between calibration and local loss optimality. The theory
relies on a general definition of "B-calibration," which is a notion of
calibration parameterized by a choice of equivalence classes (semantic or
otherwise). This theoretical mechanism leads to a testable prediction: base
LLMs will be semantically calibrated when they can easily predict their own
distribution over semantic answer classes before generating a response. We
state three implications of this prediction, which we validate through
experiments: (1) Base LLMs are semantically calibrated across
question-answering tasks, (2) RL instruction-tuning systematically breaks this
calibration, and (3) chain-of-thought reasoning breaks calibration. To our
knowledge, our work provides the first principled explanation of when and why
semantic calibration emerges in LLMs.

</details>


### [28] [Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs](https://arxiv.org/abs/2511.04875)
*Matthew Bozoukov,Matthew Nguyen,Shubkarman Singh,Bart Bussmann,Patrick Leask*

Main category: cs.CL

TL;DR: 该文发现，通过简单的神经网络调制方式，可在LLM中定向激发行为自我认知，但这种能力具有领域局限性和线性本质。这揭示了自我认知的诱发细节，对模型安全评估和能力解释具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型可以自发表现出对自身行为的认知，这种能力可能带来安全隐患（如模型在评估时隐藏真实能力）；因此，作者试图厘清自我认知出现的最小条件与其具体机制。

Method: 通过在指令微调的大语言模型上采用LoRA（低秩适配器）进行受控微调实验，分析其行为自我认知能力的诱发与特性。通过激活空间解析，探索自我认知的表现和结构。

Result: 1）单个rank-1的LoRA适配器即可稳定诱导自我认知能力；2）自我认知行为可被激活空间中的单一方向向量近乎完整地捕捉；3）这种自我认知是非通用的、不同行任务之间表现独立，是一种领域特异、线性化的特征。

Conclusion: 行为自我认知在大语言模型中是可诱导的、线性化的，并且具有领域特异性。仅使用单一的低秩（rank-1）LoRA适配器即可稳定地引发自我认知，并且这种行为可通过神经激活空间中的单一方向向量有效捕捉。自我认知并非所有任务通用，而是局部化、各任务间独立。

Abstract: Recent studies have revealed that LLMs can exhibit behavioral self-awareness:
the ability to accurately describe or predict their own learned behaviors
without explicit supervision. This capability raises safety concerns as it may,
for example, allow models to better conceal their true abilities during
evaluation. We attempt to characterize the minimal conditions under which such
self-awareness emerges, and the mechanistic processes through which it
manifests. Through controlled finetuning experiments on instruction-tuned LLMs
with low-rank adapters (LoRA), we find: (1) that self-awareness can be reliably
induced using a single rank-1 LoRA adapter; (2) that the learned self-aware
behavior can be largely captured by a single steering vector in activation
space, recovering nearly all of the fine-tune's behavioral effect; and (3) that
self-awareness is non-universal and domain-localized, with independent
representations across tasks. Together, these findings suggest that behavioral
self-awareness emerges as a domain-specific, linear feature that can be easily
induced and modulated.

</details>


### [29] [SDS KoPub VDR: A Benchmark Dataset for Visual Document Retrieval in Korean Public Documents](https://arxiv.org/abs/2511.04910)
*Jaehoon Lee,Sohyun Kim,Wanggeun Park,Geon Lee,Seungkyung Kim,Minyoung Lee*

Main category: cs.CL

TL;DR: 论文提出了SDS KoPub VDR——首个大规模韩文多模态文档检索基准，包含复杂结构的官方文档和精心标注的检索任务。评估显示现有模型跨模态能力有限，该基准为推动复杂文档AI研究提供了有力支撑。


<details>
  <summary>Details</summary>
Motivation: 现有视觉文档检索（VDR）基准主要集中在英语语料和结构简单的文档，忽视了非英语语言，尤其是结构复杂的官方出版物。为解决这一关键缺口，论文提出了新的韩文公共文档检索基准。

Method: 搭建了一个包含361份真实世界韩文官方文件（共40,781页）的大型数据集，并从法律门户和政府出版物获取不同来源。构建了600个查询-页面-答案三元组，由多模态模型（如GPT-4o）生成初稿，经过严格人工核查和修订，涵盖文字、视觉及跨模态推理。设计了文本检索和多模态检索两种任务，系统评估不同模型。

Result: 实验对比发现，当前即便是最先进的模型在需要跨模态推理的多模态情境下仍存在明显性能差距。

Conclusion: SDS KoPub VDR作为首个韩文大型多模态文档检索基准，填补了国际VDR评测的空白，为未来复杂文档智能与多模态AI发展提供了标准数据和新方向。

Abstract: Existing benchmarks for visual document retrieval (VDR) largely overlook
non-English languages and the structural complexity of official publications.
To address this critical gap, we introduce SDS KoPub VDR, the first
large-scale, publicly available benchmark for retrieving and understanding
Korean public documents. The benchmark is built upon a corpus of 361 real-world
documents (40,781 pages), including 256 files under the KOGL Type 1 license and
105 from official legal portals, capturing complex visual elements like tables,
charts, and multi-column layouts. To establish a challenging and reliable
evaluation set, we constructed 600 query-page-answer triples. These were
initially generated using multimodal models (e.g., GPT-4o) and subsequently
underwent a rigorous human verification and refinement process to ensure
factual accuracy and contextual relevance. The queries span six major public
domains and are systematically categorized by the reasoning modality required:
text-based, visual-based (e.g., chart interpretation), and cross-modal. We
evaluate SDS KoPub VDR on two complementary tasks that reflect distinct
retrieval paradigms: (1) text-only retrieval, which measures a model's ability
to locate relevant document pages based solely on textual signals, and (2)
multimodal retrieval, which assesses retrieval performance when visual features
(e.g., tables, charts, and layouts) are jointly leveraged alongside text. This
dual-task evaluation reveals substantial performance gaps, particularly in
multimodal scenarios requiring cross-modal reasoning, even for state-of-the-art
models. As a foundational resource, SDS KoPub VDR not only enables rigorous and
fine-grained evaluation across textual and multimodal retrieval tasks but also
provides a clear roadmap for advancing multimodal AI in complex, real-world
document intelligence.

</details>


### [30] [BudgetMem: Learning Selective Memory Policies for Cost-Efficient Long-Context Processing in Language Models](https://arxiv.org/abs/2511.04919)
*Chandra Vamsi Krishna Alla,Harish Naidu Gaddam,Manohar Kommi*

Main category: cs.CL

TL;DR: BudgetMem通过智能选择记忆内容，实现了长文本处理中的显著降内存与微小精度损失，适合资源受限场景下部署大模型。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理长文本时面临极高的算力与内存消耗，为了能在有限资源设备上支持长上下文理解，需要一种更高效的记忆管理方式。

Method: 提出BudgetMem架构，通过结合选择性记忆策略与特征化显著性打分（如实体密度、TF-IDF等），并利用BM25稀疏检索与学习式门控机制，在严格内存预算下智能选择存储内容。

Result: 在长文档问答任务中，BudgetMem在仅损失1.0% F1分数的情况下，节省了高达72.4%的内存；并且随着文档长度增长优势更加明显。

Conclusion: BudgetMem可以大幅降低内存消耗而仅带来极小的性能损失，在长文档处理中表现尤为突出，为资源受限的硬件部署提供了解决方案。

Abstract: Large Language Models (LLMs) face significant computational and memory
constraints when processing long contexts, despite growing demand for
applications requiring reasoning over extensive documents, multi-session
dialogues, and book length texts. While recent advances have extended context
windows to 100K-1M tokens, such approaches incur prohibitive costs for resource
constrained deployments. We propose BudgetMem, a novel memory augmented
architecture that learns what to remember rather than remembering everything.
Our system combines selective memory policies with feature based salience
scoring (entity density, TF-IDF, discourse markers, position bias) to decide
which information merits storage under strict budget constraints. Unlike
existing retrieval augmented generation (RAG) systems that store all chunks,
BudgetMem employs learned gating mechanisms coupled with BM25 sparse retrieval
for efficient information access. Through comprehensive experiments on 700
question answer pairs across short (237 tokens) and long (5K-10K tokens)
documents with Llama-3.2-3B-Instruct, we demonstrate that BudgetMem achieves
remarkable results on long documents: only 1.0% F1 score degradation while
saving 72.4% memory compared to baseline RAG. We validate our approach through
budget sensitivity analysis (testing 7 budget ratios), naive baseline
comparisons, and document length analysis, showing that BudgetMem's benefits
increase with document length. Our work provides a practical pathway for
deploying capable long context systems on modest hardware, democratizing access
to advanced language understanding capabilities.

</details>


### [31] [AgentExpt: Automating AI Experiment Design with LLM-based Resource Retrieval Agent](https://arxiv.org/abs/2511.04921)
*Yu Li,Lehui Li,Qingmin Liao,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: 本文提出集体认知增强的实验设计推荐框架，自动收集论文真实用的数据集和基线，并优化检索和推理模块，数据覆盖范围提升，在基准指标上显著优于以往方法，推进了可信且可解释的自动化科学实验设计。


<details>
  <summary>Details</summary>
Motivation: 现有基线与数据集推荐多数依赖公开门户，导致覆盖有限且过度依赖内容相似，忽略了实验适用性；为提升科学研究自动化效率与可靠性，需更好地挖掘知识网络中的集体认知。

Method: 设计了自动化数据收集流程，从约十万篇论文中提取实际使用的数据集和基线，提出集体认知增强检索器，通过将自描述与引用语境聚合表示数据集和基线，并微调表征模型以提升召回效率；随后开发了推理增强重排序模块，通过显式推理链和大语言模型微调，提升推荐解释性和精度。

Result: 所建数据集覆盖了过去五年顶级AI会议中实际用到的85%的数据集和基线，新方法对比最强已有方法在Recall@20提升5.85%，HitRate@5提升8.30%。

Conclusion: 该研究提出了一个全面的推荐系统框架，能够更加可靠且可解释性强地自动化实验设计，显著提升了基线和数据集推荐的覆盖率和准确性。

Abstract: Large language model agents are becoming increasingly capable at web-centric
tasks such as information retrieval, complex reasoning. These emerging
capabilities have given rise to surge research interests in developing LLM
agent for facilitating scientific quest. One key application in AI research is
to automate experiment design through agentic dataset and baseline retrieval.
However, prior efforts suffer from limited data coverage, as recommendation
datasets primarily harvest candidates from public portals and omit many
datasets actually used in published papers, and from an overreliance on content
similarity that biases model toward superficial similarity and overlooks
experimental suitability. Harnessing collective perception embedded in the
baseline and dataset citation network, we present a comprehensive framework for
baseline and dataset recommendation. First, we design an automated
data-collection pipeline that links roughly one hundred thousand accepted
papers to the baselines and datasets they actually used. Second, we propose a
collective perception enhanced retriever. To represent the position of each
dataset or baseline within the scholarly network, it concatenates
self-descriptions with aggregated citation contexts. To achieve efficient
candidate recall, we finetune an embedding model on these representations.
Finally, we develop a reasoning-augmented reranker that exact interaction
chains to construct explicit reasoning chains and finetunes a large language
model to produce interpretable justifications and refined rankings. The dataset
we curated covers 85\% of the datasets and baselines used at top AI conferences
over the past five years. On our dataset, the proposed method outperforms the
strongest prior baseline with average gains of +5.85\% in Recall@20, +8.30\% in
HitRate@5. Taken together, our results advance reliable, interpretable
automation of experimental design.

</details>


### [32] [Diagnosing and Mitigating Semantic Inconsistencies in Wikidata's Classification Hierarchy](https://arxiv.org/abs/2511.04926)
*Shixiong Zhao,Hideaki Takeda*

Main category: cs.CL

TL;DR: Wikidata虽数据丰富但分类混乱。本文提出新检测和评判方法，并开发用户可参与的验证系统，有效提升了知识结构质量和用户协作效能。


<details>
  <summary>Details</summary>
Motivation: Wikidata是最大开放知识图谱，但因开放编辑政策导致分类不一致、层级混乱等问题。这引发了对如何提升知识结构质量的研究动机。

Method: 提出创新的验证方法，确认Wikidata中某些领域的分类错误、过度泛化的子类链接和冗余关系；引入全新评判标准决定这些问题是否需要修正；开发允许用户检查任意实体分类关系的系统，充分利用众包特性。

Result: 实验验证了Wikidata存在多种分类和结构问题，所提新方法和判据能够识别并辅助修正这些问题。新系统提升了用户对实体分类结构的可见性和参与度。

Conclusion: Wikidata因内容开放带来了结构不一致问题，研究提出的方法和系统有助于发现并修正分类问题，从而提升知识图谱质量，凸显了众包协作在知识整理中的价值。

Abstract: Wikidata is currently the largest open knowledge graph on the web,
encompassing over 120 million entities. It integrates data from various
domain-specific databases and imports a substantial amount of content from
Wikipedia, while also allowing users to freely edit its content. This openness
has positioned Wikidata as a central resource in knowledge graph research and
has enabled convenient knowledge access for users worldwide. However, its
relatively loose editorial policy has also led to a degree of taxonomic
inconsistency. Building on prior work, this study proposes and applies a novel
validation method to confirm the presence of classification errors,
over-generalized subclass links, and redundant connections in specific domains
of Wikidata. We further introduce a new evaluation criterion for determining
whether such issues warrant correction and develop a system that allows users
to inspect the taxonomic relationships of arbitrary Wikidata
entities-leveraging the platform's crowdsourced nature to its full potential.

</details>


### [33] [LoPT: Lossless Parallel Tokenization Acceleration for Long Context Inference of Large Language Model](https://arxiv.org/abs/2511.04952)
*Wei Shao,Lingchao Zheng,Pengyu Wang,Peizhen Zheng,Jun Li,Yuwei Fan*

Main category: cs.CL

TL;DR: 提出LoPT无损并行分词框架，兼顾极大加速和分词一致性，解决了长文本推理场景下分词瓶颈问题，具有理论和实验支持。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理场景对大模型变得越来越重要，但推理过程中会出现显著的计算延迟。尽管之前针对算子、模型结构和系统框架等方面进行了优化，分词环节作为潜在瓶颈却被忽略了。现有的并行分词虽然加速了处理，但因边界问题导致合并后结果不一致。

Method: 提出了一种全新的无损并行分词框架LoPT。它通过基于字符位置的匹配和动态块长度调整，实现分词片段的精确对齐和无缝合并，从而确保并行分词的输出与标准顺序分词完全一致。

Result: 在各种长文本数据集上进行了大量实验，结果表明LoPT在保证无损分词的前提下，实现了显著的加速效果。同时还提供了一致性的理论证明和全面的分析研究，证实方法的稳健性。

Conclusion: LoPT不仅显著提升了分词效率，而且能够完全消除并行分词带来的不一致问题，为大模型在长文本推理场景下的应用带来了新的高效解决方案。

Abstract: Long context inference scenarios have become increasingly important for large
language models, yet they introduce significant computational latency. While
prior research has optimized long-sequence inference through operators, model
architectures, and system frameworks, tokenization remains an overlooked
bottleneck. Existing parallel tokenization methods accelerate processing
through text segmentation and multi-process tokenization, but they suffer from
inconsistent results due to boundary artifacts that occur after merging. To
address this, we propose LoPT, a novel Lossless Parallel Tokenization framework
that ensures output identical to standard sequential tokenization. Our approach
employs character-position-based matching and dynamic chunk length adjustment
to align and merge tokenized segments accurately. Extensive experiments across
diverse long-text datasets demonstrate that LoPT achieves significant speedup
while guaranteeing lossless tokenization. We also provide theoretical proof of
consistency and comprehensive analytical studies to validate the robustness of
our method.

</details>


### [34] [Too Good to be Bad: On the Failure of LLMs to Role-Play Villains](https://arxiv.org/abs/2511.04962)
*Zihao Yi,Qingxuan Jiang,Ruotian Ma,Xingyu Chen,Qu Yang,Mengru Wang,Fanghua Ye,Ying Shen,Zhaopeng Tu,Xiaolong Li,Linus*

Main category: cs.CL

TL;DR: 安全对齐的语言模型难以逼真地扮演复杂反派角色，尤其难展现非安全的性格，模型表现受限于安全机制。该研究首次系统揭示了安全性与创意表达之间的冲突。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在创造性生成中常被用于模拟虚构角色，但其演绎负面、反派角色能力未被充分探索，作者关注安全对齐与角色扮演真实性之间的根本冲突。

Method: 提出Moral RolePlay基准数据集，设有四级道德对齐量表和平衡测试集，对主流LLM进行大规模角色扮演评测。

Result: 角色道德性越低，模型扮演的真实性持续下降，尤其不善于呈现复杂恶意，倾向于表现表面化攻击性。一般聊天能力无法预测模型的反派角色扮演能力。

Conclusion: 现代LLM在扮演非利他、反派角色时存在显著困难，尤其是对于与安全原则直接冲突的特质，如欺骗和操控。高度安全对齐的模型在反派扮演中表现尤其差。

Abstract: Large Language Models (LLMs) are increasingly tasked with creative
generation, including the simulation of fictional characters. However, their
ability to portray non-prosocial, antagonistic personas remains largely
unexamined. We hypothesize that the safety alignment of modern LLMs creates a
fundamental conflict with the task of authentically role-playing morally
ambiguous or villainous characters. To investigate this, we introduce the Moral
RolePlay benchmark, a new dataset featuring a four-level moral alignment scale
and a balanced test set for rigorous evaluation. We task state-of-the-art LLMs
with role-playing characters from moral paragons to pure villains. Our
large-scale evaluation reveals a consistent, monotonic decline in role-playing
fidelity as character morality decreases. We find that models struggle most
with traits directly antithetical to safety principles, such as ``Deceitful''
and ``Manipulative'', often substituting nuanced malevolence with superficial
aggression. Furthermore, we demonstrate that general chatbot proficiency is a
poor predictor of villain role-playing ability, with highly safety-aligned
models performing particularly poorly. Our work provides the first systematic
evidence of this critical limitation, highlighting a key tension between model
safety and creative fidelity. Our benchmark and findings pave the way for
developing more nuanced, context-aware alignment methods.

</details>


### [35] [Acquiring Common Chinese Emotional Events Using Large Language Model](https://arxiv.org/abs/2511.04989)
*Ya Wang,Guangzheng Zhu,Cungen Cao,Jingjing Li,He Li,Xin Huang*

Main category: cs.CL

TL;DR: 作者利用中文大语言模型和自动筛选、分类技术，构建了首个大规模中文情感事件知识库，显著推动了情感因果抽取等方向的研究。


<details>
  <summary>Details</summary>
Motivation: 情感性事件知识对多种应用效果有促进作用，但获取通用、与上下文无关的情感事件较为困难，尤其是在中文领域。本研究旨在填补这一知识空白。

Method: 首先收集中文情感性事件指示词，然后通过中文大语言模型（LLM）利用这些指示词生成情感事件。接着通过自主训练的筛选器剔除无效结果，并采用多种技术将事件分为正面和负面。

Result: 最终构建了一个包含102,218条带有情感极性标签的高质量通用中文情感事件知识库，是目前唯一的大规模中文通用情感事件知识库。

Conclusion: 本文提出的方法能有效挖掘中文通用情感事件知识，不仅为情感因果抽取等任务提供了丰富的数据资源，也为相关研究与应用奠定了基础。

Abstract: Knowledge about emotional events is an important kind of knowledge which has
been applied to improve the effectiveness of different applications. However,
emotional events cannot be easily acquired, especially common or generalized
emotional events that are context-independent. The goal of this paper is to
obtain common emotional events in Chinese language such as "win a prize" and
"be criticized". Our approach begins by collecting a comprehensive list of
Chinese emotional event indicators. Then, we generate emotional events by
prompting a Chinese large language model (LLM) using these indicators. To
ensure the quality of these emotional events, we train a filter to discard
invalid generated results. We also classify these emotional events as being
positive events and negative events using different techniques. Finally, we
harvest a total of 102,218 high-quality common emotional events with sentiment
polarity labels, which is the only large-scale commonsense knowledge base of
emotional events in Chinese language. Intrinsic evaluation results show that
the proposed method in this paper can be effectively used to acquire common
Chinese emotional events. An extrinsic use case also demonstrates the strong
potential of common emotional events in the field of emotion cause extraction
(ECE). Related resources including emotional event indicators and emotional
events will be released after the publication of this paper.

</details>


### [36] [Pluralistic Behavior Suite: Stress-Testing Multi-Turn Adherence to Custom Behavioral Policies](https://arxiv.org/abs/2511.05018)
*Prasoon Varshney,Makesh Narsimhan Sreedhar,Liwei Jiang,Traian Rebedea,Christopher Parisien*

Main category: cs.CL

TL;DR: 该研究开发了针对多元行为规范的动态评估套件PBSUITE，发现大语言模型在复杂多轮互动中难以持续遵守定制政策，推动了对更高级、灵活模型对齐方法的需求。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型通常按照通用的安全和使用原则进行对齐，但现实应用场景中，企业和组织的需求往往更具多样性和复杂性，涉及不同的公司政策、法规要求和伦理目标。这驱使研究者探索如何让模型具备适应多元价值观和实际需求的能力。

Method: 提出了PBSUITE，包括一个涵盖30个行业、300个真实行为政策的数据集，以及一个用于动态评估和压力测试模型遵守定制行为规范能力的框架，特别关注多轮交互和对抗性情景下的表现。

Result: 主流开源和闭源模型在单轮交互下行为规范遵守率较高（失败率低于4%），但在多轮对抗性互动中合规能力显著下降（失败率高达84%），显示现有对齐与安全方法难以在实际复杂环境中保持一致性。

Conclusion: 现有大语言模型难以在多样化、复杂场景下持续遵守多元化行为规范，未来需要更强大、具上下文感知能力的对齐技术。

Abstract: Large language models (LLMs) are typically aligned to a universal set of
safety and usage principles intended for broad public acceptability. Yet,
real-world applications of LLMs often take place within organizational
ecosystems shaped by distinctive corporate policies, regulatory requirements,
use cases, brand guidelines, and ethical commitments. This reality highlights
the need for rigorous and comprehensive evaluation of LLMs with pluralistic
alignment goals, an alignment paradigm that emphasizes adaptability to diverse
user values and needs. In this work, we present PLURALISTIC BEHAVIOR SUITE
(PBSUITE), a dynamic evaluation suite designed to systematically assess LLMs'
capacity to adhere to pluralistic alignment specifications in multi-turn,
interactive conversations. PBSUITE consists of (1) a diverse dataset of 300
realistic LLM behavioral policies, grounded in 30 industries; and (2) a dynamic
evaluation framework for stress-testing model compliance with custom behavioral
specifications under adversarial conditions. Using PBSUITE, We find that
leading open- and closed-source LLMs maintain robust adherence to behavioral
policies in single-turn settings (less than 4% failure rates), but their
compliance weakens substantially in multi-turn adversarial interactions (up to
84% failure rates). These findings highlight that existing model alignment and
safety moderation methods fall short in coherently enforcing pluralistic
behavioral policies in real-world LLM interactions. Our work contributes both
the dataset and analytical framework to support future research toward robust
and context-aware pluralistic alignment techniques.

</details>


### [37] [Order-Level Attention Similarity Across Language Models: A Latent Commonality](https://arxiv.org/abs/2511.05064)
*Jinglin Liang,Jin Zhong,Shuangping Huang,Yunqing Hu,Huiyuan Zhang,Huifang Li,Lixin Fan,Hanlin Gu*

Main category: cs.CL

TL;DR: 本文发现语言模型在特定的注意力模式（OLA）上存在共性，通过利用该共性提出了无需训练的跨模型Adapter迁移方法，有效提升了未见模型的表现。


<details>
  <summary>Details</summary>
Motivation: 目前很多关于语言模型(LM)的上下文聚合或注意力机制的研究，通常聚焦在单个模型或单一注意力头上，缺少对多模型之间聚合模式共性的系统性分析。本工作旨在探究不同语言模型在聚合上下文时是否存在共性，这不仅有助于加深对LM的理解，也有利于跨模型的知识迁移。

Method: 本文提出了一种基于注意力Rollout阶次分解(order-wise decomposition)得到的Order-Level Attention（OLA），用以分析不同语言模型的聚合模式共性。此外，作者发现OLA与句法知识之间存在隐式映射。基于此，设计了无需训练的跨语言模型Adapter迁移方法（Transferable OLA Adapter，TOA），将OLA作为统一特征输入，对未见过的模型直接应用Adapter以提升其性能。

Result: 实验证明，不同语言模型在相同阶次的OLA上表现出显著相似性。TOA方法实现了适用于未见模型的有效跨模型泛化，显著提升了这些模型的性能。

Conclusion: 语言模型间在Order-Level Attention特征层面存在共性，基于此共性可以实现无需任何参数更新的跨模型Adapter迁移，提升未见模型的任务表现。

Abstract: In this paper, we explore an important yet previously neglected question: Do
context aggregation patterns across Language Models (LMs) share commonalities?
While some works have investigated context aggregation or attention weights in
LMs, they typically focus on individual models or attention heads, lacking a
systematic analysis across multiple LMs to explore their commonalities. In
contrast, we focus on the commonalities among LMs, which can deepen our
understanding of LMs and even facilitate cross-model knowledge transfer. In
this work, we introduce the Order-Level Attention (OLA) derived from the
order-wise decomposition of Attention Rollout and reveal that the OLA at the
same order across LMs exhibits significant similarities. Furthermore, we
discover an implicit mapping between OLA and syntactic knowledge. Based on
these two findings, we propose the Transferable OLA Adapter (TOA), a
training-free cross-LM adapter transfer method. Specifically, we treat the OLA
as a unified syntactic feature representation and train an adapter that takes
OLA as input. Due to the similarities in OLA across LMs, the adapter
generalizes to unseen LMs without requiring any parameter updates. Extensive
experiments demonstrate that TOA's cross-LM generalization effectively enhances
the performance of unseen LMs. Code is available at
https://github.com/jinglin-liang/OLAS.

</details>


### [38] [Reasoning-Guided Claim Normalization for Noisy Multilingual Social Media Posts](https://arxiv.org/abs/2511.05078)
*Manan Sharma,Arya Suneesh,Manish Jain,Pawan Kumar Rajpoot,Prasanna Devadiga,Bharatdeep Hazarika,Ashish Shrivastava,Kishan Gurumurthy,Anshuman B Suresh,Aditya U Baliga*

Main category: cs.CL

TL;DR: 提出通过问题分解与微调Qwen3-14B实现多语言社交媒体帖子的声明标准化，仅用英语训练却在20种语言取得大幅提升，尤其适合罗曼和日耳曼语族。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的虚假信息通常以噪声和含糊的表达发布，且涉及多种语言，给跨语言的事实核查和声明标准化带来挑战。推动多语言环境下的信息核查成为迫切需求。

Method: 该论文提出通过系统地将社交媒体帖子的内容分解为'谁、什么、哪里、何时、为何、如何'六个关键问题，实现声明标准化。模型使用Qwen3-14B，通过LoRA微调，仅用英语数据训练。在推理时结合去重、语义对齐、检索增强和少样本学习等技术来提升效果。

Result: 实验在20种语言上测试，METEOR得分从英文的41.16到马拉地语的15.21不等，取得英文榜第三、荷兰语和旁遮普语第四。相比基线方法，METEOR有41.3%的相对提升，并在多种语言结构中保持语义一致性，特别对罗曼语族和日耳曼语族有良好泛化。

Conclusion: 系统性分解与少样本增强的方法能够显著提升跨语言声明标准化效果，仅用英语训练实现多语言泛化，在主流评测中获得优异成绩。

Abstract: We address claim normalization for multilingual misinformation detection -
transforming noisy social media posts into clear, verifiable statements across
20 languages. The key contribution demonstrates how systematic decomposition of
posts using Who, What, Where, When, Why and How questions enables robust
cross-lingual transfer despite training exclusively on English data. Our
methodology incorporates finetuning Qwen3-14B using LoRA with the provided
dataset after intra-post deduplication, token-level recall filtering for
semantic alignment and retrieval-augmented few-shot learning with contextual
examples during inference. Our system achieves METEOR scores ranging from 41.16
(English) to 15.21 (Marathi), securing third rank on the English leaderboard
and fourth rank for Dutch and Punjabi. The approach shows 41.3% relative
improvement in METEOR over baseline configurations and substantial gains over
existing methods. Results demonstrate effective cross-lingual generalization
for Romance and Germanic languages while maintaining semantic coherence across
diverse linguistic structures.

</details>


### [39] [On Text Simplification Metrics and General-Purpose LLMs for Accessible Health Information, and A Potential Architectural Advantage of The Instruction-Tuned LLM class](https://arxiv.org/abs/2511.05080)
*P. Bilha Githinji,Aikaterini Meilliou,Peiwu Qin*

Main category: cs.CL

TL;DR: 本文实证评估两类LLM在医学技术文献自动简化任务上的表现，指出指令微调的Mistral 24B在可读性与语篇保真度兼顾方面优于QWen2.5 32B，并为评估指标选择与简化策略提供参考。


<details>
  <summary>Details</summary>
Motivation: 随着大众对健康知识的需求和生物医学信息数字化消费的增加，亟需自动将复杂科学技术文献转换为通俗易懂语言的可扩展解决方案。

Method: 通过对两类主流大型语言模型（LLM）的对比分析，评估其文本简化能力。具体比较了指令微调的Mistral 24B和推理增强的QWen2.5 32B，并与人类基准进行对照，分析21项相关指标归因。

Result: Mistral 24B在简化文本时以温和的词汇简化策略提升可读性（SARI均值42.46），同时保持高水平语篇保真度（BERTScore 0.91）。QWen虽然也提升了可读性，但在可读性与准确性之间平衡较弱，BERTScore为0.89，显著低于Mistral。相关性分析还揭示五大可读性指标间存在冗余。

Conclusion: 指令微调型LLM（如Mistral 24B）在自动文本简化任务中性能更佳，应优先考虑作为基础模型，并指出词汇支持为领域适配的主要问题。

Abstract: The increasing health-seeking behavior and digital consumption of biomedical
information by the general public necessitate scalable solutions for
automatically adapting complex scientific and technical documents into plain
language. Automatic text simplification solutions, including advanced large
language models, however, continue to face challenges in reliably arbitrating
the tension between optimizing readability performance and ensuring
preservation of discourse fidelity. This report empirically assesses the
performance of two major classes of general-purpose LLMs, demonstrating their
linguistic capabilities and foundational readiness for the task compared to a
human benchmark. Using a comparative analysis of the instruction-tuned Mistral
24B and the reasoning-augmented QWen2.5 32B, we identify a potential
architectural advantage in the instruction-tuned LLM. Mistral exhibits a
tempered lexical simplification strategy that enhances readability across a
suite of metrics and the simplification-specific formula SARI (mean 42.46),
while preserving human-level discourse with a BERTScore of 0.91. QWen also
attains enhanced readability performance, but its operational strategy shows a
disconnect in balancing between readability and accuracy, reaching a
statistically significantly lower BERTScore of 0.89. Additionally, a
comprehensive correlation analysis of 21 metrics spanning readability,
discourse fidelity, content safety, and underlying distributional measures for
mechanistic insights, confirms strong functional redundancies among five
readability indices. This empirical evidence tracks baseline performance of the
evolving LLMs for the task of text simplification, identifies the
instruction-tuned Mistral 24B for simplification, provides necessary heuristics
for metric selection, and points to lexical support as a primary
domain-adaptation issue for simplification.

</details>


### [40] [Iterative Layer-wise Distillation for Efficient Compression of Large Language Models](https://arxiv.org/abs/2511.05085)
*Grigory Kovalev,Mikhail Tikhomirov*

Main category: cs.CL

TL;DR: 本文提出基于层重要性迭代评估和联合损失训练的LLMs蒸馏方法，在保持较高性能的同时大幅减少模型参数，验证了方法的有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型(LLMs)虽然性能优越，但参数量大，实际部署受限，因此亟需开发更为紧凑且高效的小模型。

Method: 评估和改进现有知识蒸馏方法，提出基于ShortGPT和迭代层重要性评估的新方法。该方法通过逐步移除、评估模型性能下降，来判断各层重要性；结合KL散度和均方误差的联合损失进行进一步训练。

Result: 在Qwen2.5-3B模型实验中，将层数从36减少至28（参数2.47B）仅损失9.7%质量，减少至24层时损失为18%。研究发现Transformer中间层重要性较低，方法在参数精简与保性能间达权衡。

Conclusion: 所提出的迭代蒸馏和微调方法显著提升大模型压缩效率，有助于在资源受限场景下部署高效LLMs。

Abstract: This work investigates distillation methods for large language models (LLMs)
with the goal of developing compact models that preserve high performance.
Several existing approaches are reviewed, with a discussion of their respective
strengths and limitations. An improved method based on the ShortGPT approach
has been developed, building upon the idea of incorporating iterative
evaluation of layer importance. At each step, importance is assessed by
measuring performance degradation when individual layers are removed, using a
set of representative datasets. This process is combined with further training
using a joint loss function based on KL divergence and mean squared error.
Experiments on the Qwen2.5-3B model show that the number of layers can be
reduced from 36 to 28 (resulting in a 2.47 billion parameter model) with only a
9.7% quality loss, and to 24 layers with an 18% loss. The findings suggest that
the middle transformer layers contribute less to inference, underscoring the
potential of the proposed method for creating efficient models. The results
demonstrate the effectiveness of iterative distillation and fine-tuning, making
the approach suitable for deployment in resource-limited settings.

</details>


### [41] [A Toolbox for Improving Evolutionary Prompt Search](https://arxiv.org/abs/2511.05120)
*Daniel Grießhaber,Maximilian Kimmich,Johannes Maucher,Ngoc Thang Vu*

Main category: cs.CL

TL;DR: 针对现有进化式提示词优化存在的不足，本文提出多项改进措施，进一步提升了优化结果与效率，并公布了代码以促进社区交流和后续研究。


<details>
  <summary>Details</summary>
Motivation: 现有进化式提示词优化方法缺乏健壮的算子及高效的评估机制，亟需提升其优化效果和效率，以支持更广泛的应用。

Method: 将进化过程分解为独立步骤、引入基于LLM的判决机制、整合人类反馈优化进化算子、以及开发高效的评估策略。

Result: 新方法显著提高了提示词优化的效果和效率，降低了计算成本，并扩展了任务适用性。

Conclusion: 本文提出了一种改进的进化式提示词优化方法，有效提升了优化质量和效率，并开放了代码以支持更多任务和后续研究。

Abstract: Evolutionary prompt optimization has demonstrated effectiveness in refining
prompts for LLMs. However, existing approaches lack robust operators and
efficient evaluation mechanisms. In this work, we propose several key
improvements to evolutionary prompt optimization that can partially generalize
to prompt optimization in general: 1) decomposing evolution into distinct steps
to enhance the evolution and its control, 2) introducing an LLM-based judge to
verify the evolutions, 3) integrating human feedback to refine the evolutionary
operator, and 4) developing more efficient evaluation strategies that maintain
performance while reducing computational overhead. Our approach improves both
optimization quality and efficiency. We release our code, enabling prompt
optimization on new tasks and facilitating further research in this area.

</details>


### [42] [ManufactuBERT: Efficient Continual Pretraining for Manufacturing](https://arxiv.org/abs/2511.05135)
*Robin Armingaud,Romaric Besançon*

Main category: cs.CL

TL;DR: 该论文提出了专为制造业打造的语言模型ManufactuBERT。通过高质量、去重制造领域语料训练，模型在制造相关NLP任务表现优异，训练效率提升33%。流程可推广至其他专业领域。模型与语料即将公开。


<details>
  <summary>Details</summary>
Motivation: 大型通用Transformer编码器虽然在一般语言理解任务上表现出色，但在制造等专业领域，由于缺乏领域术语和语义的训练，其性能明显下降。该研究旨在弥补通用模型在制造领域的性能不足。

Method: 提出了一种针对制造领域优化的RoBERTa模型——ManufactuBERT，通过持续预训练方法利用大规模制造领域定制语料进行训练。语料构建过程中，首先进行专业领域过滤，再通过多阶段去重处理以增强语料质量。

Result: ManufactuBERT在多项制造领域NLP任务上超过现有最强专业模型，成为新SOTA。同时，通过去重语料训练大幅加速模型收敛，相比于未去重语料集，训练时间与计算成本降低33%。

Conclusion: 制造领域定制数据和去重流程显著提升了模型效果与训练效率，提出的流程可用于其他专业领域模型开发。模型与语料将公开发布，促进后续研究与应用。

Abstract: While large general-purpose Transformer-based encoders excel at general
language understanding, their performance diminishes in specialized domains
like manufacturing due to a lack of exposure to domain-specific terminology and
semantics. In this paper, we address this gap by introducing ManufactuBERT, a
RoBERTa model continually pretrained on a large-scale corpus curated for the
manufacturing domain. We present a comprehensive data processing pipeline to
create this corpus from web data, involving an initial domain-specific
filtering step followed by a multi-stage deduplication process that removes
redundancies. Our experiments show that ManufactuBERT establishes a new
state-of-the-art on a range of manufacturing-related NLP tasks, outperforming
strong specialized baselines. More importantly, we demonstrate that training on
our carefully deduplicated corpus significantly accelerates convergence,
leading to a 33\% reduction in training time and computational cost compared to
training on the non-deduplicated dataset. The proposed pipeline offers a
reproducible example for developing high-performing encoders in other
specialized domains. We will release our model and curated corpus at
https://huggingface.co/cea-list-ia.

</details>


### [43] [Mind the Gap... or Not? How Translation Errors and Evaluation Details Skew Multilingual Results](https://arxiv.org/abs/2511.05162)
*Jan-Thorsten Peter,David Vilar,Tobias Domhan,Dan Malkin,Markus Freitag*

Main category: cs.CL

TL;DR: 论文发现大语言模型数学任务在不同语言间性能差距很大，但经过数据翻译错误修正和答案提取标准化后，语言间性能差异大部分消失，说明数据和评估方式严重影响模型多语言表现。作者还发布了修正版数据集。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在多语言和多领域表现出强大的能力，但对于数学等领域，不同语言间的模型表现存在明显差距，尤其令人意外的是这种差距在高资源语言中也存在。该研究希望揭示和分析这一现象，并推动跨语言泛化能力的进一步研究。

Method: 作者分析并利用一个标准多语言数学数据集（MGSM），确定数据存在多个翻译错误，并指出LLM输出答案的提取方式缺乏标准化。同时提出自动化质量保障方法用于大规模地解决翻译错误，并针对答案提取方式给出改进建议。通过综合这些方法，作者对模型的语言表现差距进行了重新评估。

Result: 通过修正数据集和标准化答案提取，原先观察到的语言表现差距基本消失，结果与初步结论出现明显不同。作者还将修正后的数据集发布给学术界。

Conclusion: 许多大语言模型在处理数学任务时，原本被认为存在的语言表现差距很大程度上是由于翻译错误与答案处理方式不一致导致。通过改进数据质量和输出处理方式后，模型在多语言上的表现更为一致，促使我们需对前期跨语言评估结果重新审视，并注重数据质量保障。

Abstract: Most current large language models (LLMs) support a wide variety of languages
in addition to English, including high-resource languages (e.g. German,
Chinese, French), as well as low-resource ones (e.g. Swahili, Telugu). In
addition they have also shown impressive capabilities in different domains,
like coding, science and math. In this short paper, taking math as an example
domain, we study the performance of different LLMs across languages.
Experimental results show that there exists a non-negligible and consistent gap
in the performance of the models across languages. Interestingly, and somewhat
against expectations, the gap exists for both high- and low-resource languages.
We hope that these results influence further research into cross-lingual
capability generalization for next generation LLMs. If it weren't for the fact
that they are false! By analyzing one of the standard multilingual math
benchmarks (MGSM), we determine that several translation errors are present in
the data. Furthermore, the lack of standardized answer extraction from LLM
outputs further influences the final results. We propose a method for automatic
quality assurance to address the first issue at scale, and give recommendations
to address the second one. Combining these two approaches we show that the
aforementioned language gap mostly disappears, leading to completely different
conclusions from our research. We additionally release the corrected dataset to
the community.

</details>


### [44] [Effectiveness of Chain-of-Thought in Distilling Reasoning Capability from Large Language Models](https://arxiv.org/abs/2511.05184)
*Cong-Thanh Do,Rama Doddipatla,Kate Knill*

Main category: cs.CL

TL;DR: 链式推理（CoT）能显著提升小模型在知识蒸馏后的推理能力。通过在Qwen和Llama2家族上实验，作者验证了这种方法在自然语言复杂任务中有效。


<details>
  <summary>Details</summary>
Motivation: 目前，大型语言模型（LLMs）在推理能力上表现优秀，但这些能力难以直接迁移到较小的模型中。以往知识蒸馏（KD）主要关注模型压缩，但如何有效传递推理能力，尤其利用链式推理（CoT）机制，是一个重要未解问题。

Method: 本文在Qwen和Llama2两个模型家族上，采用白盒知识蒸馏，将CoT-Collection数据中的链式推理答案用于蒸馏过程。通过在复杂的自然语言推理与理解任务（BIG-Bench-Hard基准测试）上评估蒸馏后的小模型性能。

Result: 实验证明，采用CoT的白盒知识蒸馏显著提升了小模型在复杂自然语言推理和理解任务上的平均表现。

Conclusion: 链式推理在白盒知识蒸馏中对推理能力迁移至小模型至关重要，能够显著提升小模型的推理与理解能力。

Abstract: Chain-of-Thought (CoT) prompting is a widely used method to improve the
reasoning capability of Large Language Models (LLMs). More recently, CoT has
been leveraged in Knowledge Distillation (KD) to transfer reasoning capability
from a larger LLM to a smaller one. This paper examines the role of CoT in
distilling the reasoning capability from larger LLMs to smaller LLMs using
white-box KD, analysing its effectiveness in improving the performance of the
distilled models for various natural language reasoning and understanding
tasks. We conduct white-box KD experiments using LLMs from the Qwen and Llama2
families, employing CoT data from the CoT-Collection dataset. The distilled
models are then evaluated on natural language reasoning and understanding tasks
from the BIG-Bench-Hard (BBH) benchmark, which presents complex challenges for
smaller LLMs. Experimental results demonstrate the role of CoT in improving
white-box KD effectiveness, enabling the distilled models to achieve better
average performance in natural language reasoning and understanding tasks from
BBH.

</details>


### [45] [Translation via Annotation: A Computational Study of Translating Classical Chinese into Japanese](https://arxiv.org/abs/2511.05239)
*Zilong Li,Jie Cao*

Main category: cs.CL

TL;DR: 本文提出一种将汉文注日任务转化为序列标注的方法，通过LLM和辅助任务提升效果，并发现LLMs在直接翻译优异但注释不佳。


<details>
  <summary>Details</summary>
Motivation: 古人通过在汉字周围注释，将文言文翻译成日语。该过程遇到低资源问题，需要通过现代语言技术加以改进。

Method: 将注释过程抽象为序列标注任务，引入基于大型语言模型（LLM）的注释流程，并利用开源翻译数据构建新数据集。在低资源情况下，通过引入辅助中文NLP任务提升序列标注训练效果。同时评估了大型语言模型的表现。

Result: 在低资源设置下，引入中文NLP辅助任务能有效促进序列标注任务的训练。大型语言模型在直接机器翻译上表现优异，但在进行字符注释时效果不佳。

Conclusion: 该方法能有效补充LLMs在注释任务上的不足，提升整体系统性能。

Abstract: Ancient people translated classical Chinese into Japanese by annotating
around each character. We abstract this process as sequence tagging tasks and
fit them into modern language technologies. The research of this annotation and
translation system is a facing low-resource problem. We release this problem by
introducing a LLM-based annotation pipeline and construct a new dataset from
digitalized open-source translation data. We show that under the low-resource
setting, introducing auxiliary Chinese NLP tasks has a promoting effect on the
training of sequence tagging tasks. We also evaluate the performance of large
language models. They achieve high scores in direct machine translation, but
they are confused when being asked to annotate characters. Our method could
work as a supplement of LLMs.

</details>


### [46] [Reflective Personalization Optimization: A Post-hoc Rewriting Framework for Black-Box Large Language Models](https://arxiv.org/abs/2511.05286)
*Teqi Hao,Xioayu Tan,Shaojie Shi,Yinghui Xu,Xihe Qiu*

Main category: cs.CL

TL;DR: RPO方法通过分离内容生成与个性化改写，克服了传统方法的质量损失难题，大幅提升了个性化效果，且适用于任何大语言模型。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型（LLM）的个性化主要依赖于上下文注入（context injection）方式，但这会让模型在内容生成和用户风格对齐之间产生权衡，导致输出质量受到影响，并且个性化控制不够精细。为了解决这一矛盾，作者提出了新方法。

Method: 提出了一种名为RPO（Reflective Personalization Optimization）的新框架，将内容生成与个性化对齐解耦为两步：首先由基础模型生成高质量的通用回复，然后通过外部reflection模块将其重写以符合用户偏好。这个reflection模块先通过有监督微调建立基本决策策略，再用强化学习进一步优化个性化输出质量。

Result: 在LaMP基准数据集上，RPO方法显著优于当前主流方法。通过解耦内容生成和个性化过程，提升了个性化控制和输出质量。

Conclusion: RPO框架可以高效、无关底层模型地实现个性化能力，并可灵活集成到任意基础LLM中，开辟了用户中心生成任务新方向。相比传统上下文注入方式，显式的输出改写个性化方式更有效。

Abstract: The personalization of black-box large language models (LLMs) is a critical
yet challenging task. Existing approaches predominantly rely on context
injection, where user history is embedded into the prompt to directly guide the
generation process. However, this single-step paradigm imposes a dual burden on
the model: generating accurate content while simultaneously aligning with
user-specific styles. This often results in a trade-off that compromises output
quality and limits precise control. To address this fundamental tension, we
propose Reflective Personalization Optimization (RPO), a novel framework that
redefines the personalization paradigm by decoupling content generation from
alignment. RPO operates in two distinct stages: first, a base model generates a
high-quality, generic response; then, an external reflection module explicitly
rewrites this output to align with the user's preferences. This reflection
module is trained using a two-stage process. Initially, supervised fine-tuning
is employed on structured rewriting trajectories to establish a core
personalized reasoning policy that models the transformation from generic to
user-aligned responses. Subsequently, reinforcement learning is applied to
further refine and enhance the quality of the personalized outputs.
Comprehensive experiments on the LaMP benchmark demonstrate that RPO, by
decoupling content generation from personalization, significantly outperforms
state-of-the-art baselines. These findings underscore the superiority of
explicit response shaping over implicit context injection. Moreover, RPO
introduces an efficient, model-agnostic personalization layer that can be
seamlessly integrated with any underlying base model, paving the way for a new
and effective direction in user-centric generation scenarios.

</details>


### [47] [Listening Between the Lines: Decoding Podcast Narratives with Language Modeling](https://arxiv.org/abs/2511.05310)
*Shreya Gupta,Ojasva Saxena,Arghodeep Nandi,Sarah Masud,Kiran Garimella,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 针对播客内容结构复杂、难以自动分析的问题，作者提出并验证了一种专为播客场景设计的微调BERT模型，有效提升了叙事实体与框架关联的能力，为数字媒体影响研究提供了更精准的技术工具。


<details>
  <summary>Details</summary>
Motivation: 播客已成为塑造公众舆论的重要平台，其内容丰富但结构松散，对自动化分析提出了很大挑战。分析播客如何说服和影响听众，需要深入理解其叙事结构和所用框架，但现有大语言模型难以处理这一复杂性。

Method: 提出并实现了一种经过微调的BERT模型，能将叙事框架与播客对话中的具体实体相联系，并基于这种细粒度标注，将其与高层主题关联以揭示话语趋势。

Result: 该方法显著提升了对对话式、非结构化播客中叙事框架的识别准确率，并能系统性分析话题与叙事方式间的关系，从而更好地揭示数字媒体中的影响机制。

Conclusion: 论文提出的框架标注与分析方法可更贴近人类判断，有助于播客等数字媒体中影响力研究，突破了现有方法面对复杂口语化内容时的局限。

Abstract: Podcasts have become a central arena for shaping public opinion, making them
a vital source for understanding contemporary discourse. Their typically
unscripted, multi-themed, and conversational style offers a rich but complex
form of data. To analyze how podcasts persuade and inform, we must examine
their narrative structures -- specifically, the narrative frames they employ.
  The fluid and conversational nature of podcasts presents a significant
challenge for automated analysis. We show that existing large language models,
typically trained on more structured text such as news articles, struggle to
capture the subtle cues that human listeners rely on to identify narrative
frames. As a result, current approaches fall short of accurately analyzing
podcast narratives at scale.
  To solve this, we develop and evaluate a fine-tuned BERT model that
explicitly links narrative frames to specific entities mentioned in the
conversation, effectively grounding the abstract frame in concrete details. Our
approach then uses these granular frame labels and correlates them with
high-level topics to reveal broader discourse trends. The primary contributions
of this paper are: (i) a novel frame-labeling methodology that more closely
aligns with human judgment for messy, conversational data, and (ii) a new
analysis that uncovers the systematic relationship between what is being
discussed (the topic) and how it is being presented (the frame), offering a
more robust framework for studying influence in digital media.

</details>


### [48] [What Are the Facts? Automated Extraction of Court-Established Facts from Criminal-Court Opinions](https://arxiv.org/abs/2511.05320)
*Klára Bendová,Tomáš Knap,Jan Černý,Vojtěch Pour,Jaromir Savelka,Ivana Kvapilíková,Jakub Drápal*

Main category: cs.CL

TL;DR: 本文提出用正则表达式和大语言模型自动提取法院裁决书中的犯罪行为描述，二者结合准确率高达99.5%，极大提升了司法文本处理能力。


<details>
  <summary>Details</summary>
Motivation: 传统的刑事司法管理数据仅包含有限的犯罪信息，而欧洲大陆法院裁决书中对犯罪行为的详细描述尚未被充分挖掘。本研究旨在评估能否从斯洛伐克公开裁决书中自动提取这些描述，为犯罪分析和研究提供更丰富数据。

Method: 采用两种方法提取裁决书中的犯罪行为描述：一是基于正则表达式，分为简单和进阶策略，进阶策略特别处理了描述标记和字符分隔现象；二是利用大型语言模型（如Gemini Flash 2.0）按预设提示提取相关描述。不同方法的提取效果通过人工标注验证。

Result: 进阶正则表达式和LLMs的识别率分别达到97%和98.75%，二者结合达到99.5%。人工评估显示，进阶方法与人类一致率约90%，LLMs为91.75%，二者结合为92%，大幅超过基线（34.5%或40.5%）。

Conclusion: 通过正则表达式与大型语言模型，可以高效且准确地自动提取裁决书中的犯罪行为描述，超越传统方法，并大幅缩小与人工标注的差距，为丰富刑事司法数据提供了高效工具。

Abstract: Criminal justice administrative data contain only a limited amount of
information about the committed offense. However, there is an unused source of
extensive information in continental European courts' decisions: descriptions
of criminal behaviors in verdicts by which offenders are found guilty. In this
paper, we study the feasibility of extracting these descriptions from publicly
available court decisions from Slovakia. We use two different approaches for
retrieval: regular expressions and large language models (LLMs). Our baseline
was a simple method employing regular expressions to identify typical words
occurring before and after the description. The advanced regular expression
approach further focused on "sparing" and its normalization (insertion of
spaces between individual letters), typical for delineating the description.
The LLM approach involved prompting the Gemini Flash 2.0 model to extract the
descriptions using predefined instructions. Although the baseline identified
descriptions in only 40.5% of verdicts, both methods significantly outperformed
it, achieving 97% with advanced regular expressions and 98.75% with LLMs, and
99.5% when combined. Evaluation by law students showed that both advanced
methods matched human annotations in about 90% of cases, compared to just 34.5%
for the baseline. LLMs fully matched human-labeled descriptions in 91.75% of
instances, and a combination of advanced regular expressions with LLMs reached
92%.

</details>


### [49] [Evaluating Subword Tokenization Techniques for Bengali: A Benchmark Study with BengaliBPE](https://arxiv.org/abs/2511.05324)
*Firoj Ahmmed Patwary,Abdullah Al Noman*

Main category: cs.CL

TL;DR: 提出并验证了针对孟加拉语优化的BPE分词器BengaliBPE，在分词细腻度和形态解释性上优于主流方法，为该语种的NLP模型预训练和应用奠定基础。


<details>
  <summary>Details</summary>
Motivation: 当前主流的BPE分词器（如SentencePiece或HuggingFace BPE）主要为拉丁或多语种语料库设计，难以有效处理形态丰富的孟加拉语，其分词效果有限。

Method: 提出BengaliBPE，一种专为孟加拉语设计的BPE分词器，采用Unicode归一化、基于字位初始化和结合形态学的合并规则，以保持语言一致性并保留词素完整性。并在大规模孟加拉语新闻分类数据集上与三种基线方法（空格分词、SentencePiece BPE、HuggingFace BPE）对比，评估分词粒度、编码速度与下游分类准确率。

Result: 所有方法表现均较好，但BengaliBPE分词粒度最细，形态解释性最佳，计算成本略高。结果表明语言感知的分词对于形态丰富的文字极为重要。

Conclusion: BengaliBPE为形态丰富的孟加拉文字提供了优秀的分词基础，为未来孟加拉语NLP系统（包括语境化语言模型预训练）奠定了坚实基础。

Abstract: Tokenization is an important first step in Natural Language Processing (NLP)
pipelines because it decides how models learn and represent linguistic
information. However, current subword tokenizers like SentencePiece or
HuggingFace BPE are mostly designed for Latin or multilingual corpora and do
not perform well on languages with rich morphology such as Bengali. To address
this limitation, we present BengaliBPE, a Byte Pair Encoding (BPE) tokenizer
specifically developed for the Bengali script. BengaliBPE applies Unicode
normalization, grapheme-level initialization, and morphology-aware merge rules
to maintain linguistic consistency and preserve subword integrity. We use a
large-scale Bengali news classification dataset to compare BengaliBPE with
three baselines: Whitespace, SentencePiece BPE, and HuggingFace BPE. The
evaluation considers tokenization granularity, encoding speed, and downstream
classification accuracy. While all methods perform reasonably well, BengaliBPE
provides the most detailed segmentation and the best morphological
interpretability, albeit with slightly higher computational cost. These
findings highlight the importance of language-aware tokenization for
morphologically rich scripts and establish BengaliBPE as a strong foundation
for future Bengali NLP systems, including large-scale pretraining of contextual
language models.

</details>


### [50] [A multimodal multiplex of the mental lexicon for multilingual individuals](https://arxiv.org/abs/2511.05361)
*Maria Huynh,Wilder C. Rodrigues*

Main category: cs.CL

TL;DR: 本文提出基于多层网络与多模态输入的新方法，研究多语者心智词库结构及视觉输入对语言习得的影响，揭示遗产语言与多语学习间的动态关系。


<details>
  <summary>Details</summary>
Motivation: 研究近年来对多语者在语言和认知任务上的优势，进一步探究多语者心智词库的结构，关注遗产语言如何影响其他语言的习得。

Method: 采用多层网络模型，将视觉输入与多语心智词库的词汇表征相连接，设计实验对比视觉-文本结合任务与仅文本任务对学习效果的影响。

Result: 实验探索视觉输入在翻译任务中是否提升参与者的语言习得的准确率与熟练度。

Conclusion: 多语者的词汇认知结构可通过多层网络建模，并且视觉输入可能对其语言习得具有积极影响，遗产语言亦可能改变习得新语言的路径。

Abstract: Historically, bilingualism was often perceived as an additional cognitive
load that could hinder linguistic and intellectual development. However, over
the last three decades, this view has changed considerably. Numerous studies
have aimed to model and understand the architecture of the bilingual word
recognition system Dijkstra and van Heuven (2002), investigating how parallel
activation operates in the brain and how one language influences another Kroll
et al. (2015). Increasingly, evidence suggests that multilinguals, individuals
who speak three or more languages, can perform better than monolinguals in
various linguistic and cognitive tasks, such as learning an additional language
Abu-Rabia and Sanitsky (2010). This research proposal focuses on the study of
the mental lexicon and how it may be structured in individuals who speak
multiple languages. Building on the work of Stella et al. (2018), who
investigated explosive learning in humans using a multiplex model of the mental
lexicon, and the Bilingual Interactive Activation (BIA+) framework proposed by
Dijkstra and van Heuven (2002), the present study applies the same multilayer
network principles introduced by Kivela et al. (2014). Our experimental design
extends previous research by incorporating multimodality into the multiplex
model, introducing an additional layer that connects visual inputs to their
corresponding lexical representations across the multilingual layers of the
mental lexicon. In this research, we aim to explore how a heritage language
influences the acquisition of another language. Specifically, we ask: Does the
presence of visual input in a translation task influence participants'
proficiency and accuracy compared to text-only conditions?

</details>


### [51] [Large Language Models for Explainable Threat Intelligence](https://arxiv.org/abs/2511.05406)
*Tiago Dinis,Miguel Correia,Roger Tavares*

Main category: cs.CL

TL;DR: RAGRecon通过结合RAG与LLM实现高准确率的威胁情报问答，并以知识图谱提升结果解释性，为网络安全分析提供新工具。


<details>
  <summary>Details</summary>
Motivation: 当前网络威胁日益复杂，传统安全机制难以应对，因此探索新型技术提升网络安全成为迫切需求。

Method: 提出结合检索增强生成（RAG）与大型语言模型（LLM）的方法，系统RAGRecon能融合实时信息检索与特定领域数据，生成威胁情报，并通过知识图谱为每次回复生成可视化解释，提升模型的透明性与可解释性。

Result: RAGRecon在两个数据集、七种不同LLM上的实验结果显示，最佳组合下系统回答与参考答案的匹配率超过91%。

Conclusion: 使用集成RAG的LLM能够有效提升网络安全威胁问答的准确性，同时知识图谱增强了系统的可解释性，有助于分析师更好地追踪模型推理过程。

Abstract: As cyber threats continue to grow in complexity, traditional security
mechanisms struggle to keep up. Large language models (LLMs) offer significant
potential in cybersecurity due to their advanced capabilities in text
processing and generation. This paper explores the use of LLMs with
retrieval-augmented generation (RAG) to obtain threat intelligence by combining
real-time information retrieval with domain-specific data. The proposed system,
RAGRecon, uses a LLM with RAG to answer questions about cybersecurity threats.
Moreover, it makes this form of Artificial Intelligence (AI) explainable by
generating and visually presenting to the user a knowledge graph for every
reply. This increases the transparency and interpretability of the reasoning of
the model, allowing analysts to better understand the connections made by the
system based on the context recovered by the RAG system. We evaluated RAGRecon
experimentally with two datasets and seven different LLMs and the responses
matched the reference responses more than 91% of the time for the best
combinations.

</details>


### [52] [Minority-Aware Satisfaction Estimation in Dialogue Systems via Preference-Adaptive Reinforcement Learning](https://arxiv.org/abs/2511.05407)
*Yahui Fu,Zi Haur Pang,Tatsuya Kawahara*

Main category: cs.CL

TL;DR: 本文针对对话系统用户满意度估计易忽略少数群体和个体化需求的问题，提出了结合个体和群体偏好的建模方法，通过CoPeR推理链和M2PC聚类算法，并集成到偏好自适应强化学习框架中。实验显示新方法显著提升少数群体用户的满意度预测表现。


<details>
  <summary>Details</summary>
Motivation: 现有对话系统在用户满意度建模时，通常使用统一策略并训练“普适模型”，追求大众共识，但容易忽略少数群体的需求和个体化适应，导致不同用户对系统满意度评价存在主观差异。

Method: 提出了统一框架同时建模个体和群体层面的用户偏好。具体方法包括：1）采用Chain-of-Personalized-Reasoning（CoPeR）通过可解释性推理链刻画个体偏好；2）提出基于期望最大化的多数-少数偏好感知聚类（M2PC）算法，在无监督下发现用户群体，学习群体偏好；3）将上述方法集成到偏好自适应强化学习框架（PAda-PPO），实现个体和群体偏好联合优化。

Result: 在Emotional Support Conversation数据集上实验，提出的方法在用户满意度估计上取得了持续提升，尤其提升了对少数群体的满意度预测效果。

Conclusion: 兼顾个体和群体偏好的新方法能更公平、准确地估计对话系统中的用户满意度，提升少数群体的满意度预测能力。

Abstract: User satisfaction in dialogue systems is inherently subjective. When the same
response strategy is applied across users, minority users may assign different
satisfaction ratings than majority users due to variations in individual
intents and preferences. However, existing alignment methods typically train
one-size-fits-all models that aim for broad consensus, often overlooking
minority perspectives and user-specific adaptation. We propose a unified
framework that models both individual- and group-level preferences for user
satisfaction estimation. First, we introduce Chain-of-Personalized-Reasoning
(CoPeR) to capture individual preferences through interpretable reasoning
chains. Second, we propose an expectation-maximization-based Majority-Minority
Preference-Aware Clustering (M2PC) algorithm that discovers distinct user
groups in an unsupervised manner to learn group-level preferences. Finally, we
integrate these components into a preference-adaptive reinforcement learning
framework (PAda-PPO) that jointly optimizes alignment with both individual and
group preferences. Experiments on the Emotional Support Conversation dataset
demonstrate consistent improvements in user satisfaction estimation,
particularly for underrepresented user groups.

</details>


### [53] [Steering Language Models with Weight Arithmetic](https://arxiv.org/abs/2511.05408)
*Constanza Fierro,Fabien Roger*

Main category: cs.CL

TL;DR: 提出了对比权重引导法，只需有限微调和简单权重算术，就能有效定向调整大语言模型行为，兼具泛化性和检测潜在行为风险能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决大模型在高质量反馈难以获得或反馈数据分布窄导致泛化问题带来的行为偏差。

Method: 提出对比权重引导（contrastive weight steering），即通过对两个小规模微调产生的权重变化做差，得到行为方向，再将其加减到主模型权重，达到编辑模型行为的目的。

Result: 与激活引导相比，权重引导可更好泛化，能显著改善模型在分布外的行为控制而不损害其总体能力。同时，在特定任务微调后可减轻行为漂移（如迎合性和错误拒绝），并保留任务性能。还初步证明通过度量权重方向可监测训练过程中潜在的行为偏差。

Conclusion: 对比权重引导是一种简单且高效的后处理模型编辑方法，能够有效提升和监控大模型行为控制能力。

Abstract: Providing high-quality feedback to Large Language Models (LLMs) on a diverse
training distribution can be difficult and expensive, and providing feedback
only on a narrow distribution can result in unintended generalizations. To
better leverage narrow training data, we propose contrastive weight steering, a
simple post-training method that edits the model parameters using weight
arithmetic. We isolate a behavior direction in weight-space by subtracting the
weight deltas from two small fine-tunes -- one that induces the desired
behavior and another that induces its opposite -- and then add or remove this
direction to modify the model's weights. We apply this technique to mitigate
sycophancy and induce misalignment, and find that weight steering often
generalizes further than activation steering, achieving stronger
out-of-distribution behavioral control before degrading general capabilities.
We also show that, in the context of task-specific fine-tuning, weight steering
can partially mitigate undesired behavioral drift: it can reduce sycophancy and
under-refusals introduced during fine-tuning while preserving task performance
gains. Finally, we provide preliminary evidence that emergent misalignment can
be detected by measuring the similarity between fine-tuning updates and an
"evil" weight direction, suggesting that it may be possible to monitor the
evolution of weights during training and detect rare misaligned behaviors that
never manifest during training or evaluations.

</details>


### [54] [MIMIC-SR-ICD11: A Dataset for Narrative-Based Diagnosis](https://arxiv.org/abs/2511.05485)
*Yuexin Wu,Shiqi Wang,Vasile Rus*

Main category: cs.CL

TL;DR: 本文提出了新型数据集MIMIC-SR-ICD11以及有效的LL-Rank排序方法，通过消除标签频率偏差，显著提升了自动疾病诊断的准确性，为临床文本处理领域带来突破。


<details>
  <summary>Details</summary>
Motivation: 疾病诊断在现代医疗中至关重要，既能实现疾病的早期发现和及时干预，又能指导慢性病防控，但现有电子病历的标准化书写往往遗漏或削弱病患自述的一些重要细节。因此，有必要探索如何更好地利用自述信息提升诊断的准确性。

Method: 本文构建了一个新的大型英语诊断数据集MIMIC-SR-ICD11，该数据集基于病患出院记录并与WHO ICD-11术语原生对齐。同时提出了LL-Rank方法，该方法通过计算每个标签在具体临床报告上下文中的长度归一化联合似然值，再减去标签无报告时的先验似然，从而对诊断标签排序。此方法评估了多种模型骨干，并进行了消融实验。

Result: LL-Rank方法在七种主流模型骨干上均显著优于强基线模型GenMap。消融实验表明其性能提升主要来源于基于点互信息（PMI）的评分，这种评分能有效剔除标签频率带来的偏差，突显语义兼容性。

Conclusion: 利用自述内容并结合新颖排序机制（如LL-Rank）能显著提高临床诊断任务的表现，数据与方法共同推动诊断自动化与准确性的发展。

Abstract: Disease diagnosis is a central pillar of modern healthcare, enabling early
detection and timely intervention for acute conditions while guiding lifestyle
adjustments and medication regimens to prevent or slow chronic disease.
Self-reports preserve clinically salient signals that templated electronic
health record (EHR) documentation often attenuates or omits, especially subtle
but consequential details. To operationalize this shift, we introduce
MIMIC-SR-ICD11, a large English diagnostic dataset built from EHR discharge
notes and natively aligned to WHO ICD-11 terminology. We further present
LL-Rank, a likelihood-based re-ranking framework that computes a
length-normalized joint likelihood of each label given the clinical report
context and subtracts the corresponding report-free prior likelihood for that
label. Across seven model backbones, LL-Rank consistently outperforms a strong
generation-plus-mapping baseline (GenMap). Ablation experiments show that
LL-Rank's gains primarily stem from its PMI-based scoring, which isolates
semantic compatibility from label frequency bias.

</details>
