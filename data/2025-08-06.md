<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.SE](#cs.SE) [Total: 16]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.CL](#cs.CL) [Total: 17]
- [cs.DM](#cs.DM) [Total: 2]
- [cs.FL](#cs.FL) [Total: 4]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Compositional Quantum Control Flow with Efficient Compilation in Qunity](https://arxiv.org/abs/2508.02857)
*Mikhail Mints,Finn Voichick,Leonidas Lampropoulos,Robert Rand*

Main category: cs.PL

TL;DR: 本文以Qunity为基础，提出更有效的量子控制抽象，实现了完整高效的Qunity编译器，可将高层代码优化并输出为OpenQASM 3，有效降低资源消耗，为量子高级编程抽象的实际应用提供了可行方案。


<details>
  <summary>Details</summary>
Motivation: 目前大多数量子编程语言都基于量子电路模型，实现高级抽象（如量子控制流）非常具挑战性。此前提出的Qunity语言提出了量子控制流的新抽象，但没有实际的编译器实现，且其初步的编译方案效率极低，导致简单算法也编译成极大的电路。

Method: 以Qunity作为基础，提出更广泛的抽象来改进控制结构，并实现了完整的Qunity编译器，可以将高阶Qunity代码编译为OpenQASM 3。同时，在编译过程的多个阶段引入了优化技术，包括电路级和面向高阶结构的优化，以显著减少编译后使用的量子比特数和门数。

Result: 开发了一套高效的Qunity编译器，实现了自动将高层Qunity代码转换为OpenQASM 3代码，并通过多级优化显著减少了所需的量子资源（包括量子比特及门数）。

Conclusion: 本研究不仅实现了Qunity语言的实际编译工具，而且通过多种优化手段，极大提升了针对复杂量子控制流构造的编译效率，推动了量子高级抽象在实际系统中的落地。

Abstract: Most existing quantum programming languages are based on the quantum circuit
model of computation, as higher-level abstractions are particularly challenging
to implement - especially ones relating to quantum control flow. The Qunity
language, proposed by Voichick et al., offered such an abstraction in the form
of a quantum control construct, with great care taken to ensure that the
resulting language is still realizable. However, Qunity lacked a working
implementation, and the originally proposed compilation procedure was very
inefficient, with even simple quantum algorithms compiling to unreasonably
large circuits.
  In this work, we focus on the efficient compilation of high-level quantum
control flow constructs, using Qunity as our starting point. We introduce a
wider range of abstractions on top of Qunity's core language that offer
compelling trade-offs compared to its existing control construct. We create a
complete implementation of a Qunity compiler, which converts high-level Qunity
code into the quantum assembly language OpenQASM 3. We develop optimization
techniques for multiple stages of the Qunity compilation procedure, including
both low-level circuit optimizations as well as methods that consider the
high-level structure of a Qunity program, greatly reducing the number of qubits
and gates used by the compiler.

</details>


### [2] [SAGE-HLS: Syntax-Aware AST-Guided LLM for High-Level Synthesis Code Generation](https://arxiv.org/abs/2508.03558)
*M Zafir Sadik Khan,Nowfel Mashnoor,Mohammad Akyash,Kimia Azar,Hadi Kamali*

Main category: cs.PL

TL;DR: 论文提出了SAGE-HLS，首个专为HLS代码生成微调的大模型，通过新数据集、微调方法和自动评测方案，显著提升了HLS代码的可综合性和正确性。


<details>
  <summary>Details</summary>
Motivation: 电子设计自动化（EDA）领域硬件设计复杂度不断提升，需要更先进的自动化方案。现有大语言模型虽在代码生成方面表现突出，但受限于高质量HLS代码数据集的缺乏，其在HLS领域应用受阻。因此，亟需针对HLS代码生成开发专门的数据集和优化的建模、评价体系。

Method: 该论文提出了SAGE-HLS模型，是首个专为高层次综合（HLS）代码生成微调的大语言模型。其主要方法包括三部分：（1）通过将经过验证的Verilog代码转换为C/C++，生成了一个包含16,700个HLS代码的数据集；（2）采用基于指令提示和语法树（AST）引导的代码生成微调策略；（3）开发了基于VerilogEval的半自动评测框架，评价生成HLS代码的功能性。

Result: 通过实验，微调于QwenCoder (2.5) 7B模型的SAGE-HLS在代码可综合性方面成功率接近100%，功能正确率达75%。

Conclusion: SAGE-HLS为高层次综合代码生成领域提供了首个高质量数据集与专用大模型，实验显示其在合成性和功能正确性方面均优于以往方法，为推广LLMs在EDA自动化中的应用迈出重要一步。

Abstract: In today's rapidly evolving field of electronic design automation (EDA), the
complexity of hardware designs is increasing, necessitating more sophisticated
automation solutions. High-level synthesis (HLS), as a pivotal solution,
automates hardware designs from high-level abstractions (e.g., C/C++). However,
it faces significant challenges, particularly in design space exploration and
optimization. While large language models (LLMs) have shown notable
capabilities in code generation, their application to HLS has been limited due
to the scarcity of (publicly) available HLS code datasets. Hence, research in
this domain has primarily focused on techniques such as prompt engineering and
retrieval-augmented generation (RAG). To overcome this limitation, this paper
introduces SAGE-HLS, the first-of-its-kind fine-tuned LLM specifically for HLS
code generation. Our method includes three key advancements: (i) We implement
Verilog-to-C/C++ porting, converting verified and synthesizable Verilog codes
into corresponding C, creating a dataset of 16.7K HLS codes; (ii) We implement
a fine-tuning strategy, which is based on instruction prompting to code
generation guided by abstract syntax tree (AST); (iii) We develop a
semi-automated evaluation framework using VerilogEval to assess the
functionality of the generated HLS code. Our experiments show that SAGE-HLS,
fined-tuned on the QwenCoder (2.5) 7B model, achieves a near 100% success rate
in code synthesizability and a 75% success rate in functional correctness.

</details>


### [3] [Teaching Introductory Functional Programming Using Haskelite](https://arxiv.org/abs/2508.03640)
*Pedro Vasconcelos*

Main category: cs.PL

TL;DR: 使用逐步追踪解释器有助于新手学生理解函数式编程中的替换模型，并澄清他们的误区。


<details>
  <summary>Details</summary>
Motivation: 学生虽在中学阶段接触过替换概念，但在函数式编程中面临递归、代数数据类型和高阶函数等新场景时常感迷惑。为帮助学生更好地理解这些概念，作者尝试采用逐步追踪解释器。

Method: 在课程教学中引入适用于Haskell子集的逐步追踪解释器，实际运用后收集学生反馈并对教学效果和体验进行总结分析。

Result: 本文展示了在波尔图大学的初级函数式编程课程中，如何利用逐步追踪解释器帮助学生理解基于替换的计算模型。作者介绍了解释器的使用方法，收集了学生反馈，并对教学过程中的收获和未来改进方向进行了反思。

Conclusion: 逐步追踪解释器对入门学生理解复杂的函数式编程概念非常有帮助，学生反馈积极，未来可进一步完善该工具并探索其在其他编程教学中的应用。

Abstract: Learning functional programming requires learning a substitution-based
computational model. While substitution should be a familiar concept from
high-school algebra, students often have difficulty applying it to new
settings, such as recursive definitions, algebraic data types and higher-order
functions. Step-by-step interpreters have been shown to help beginners by
clarifying misconceptions and improving understanding.
  This paper reports on the experience of using a step-by-step tracing
interpreter for a subset of Haskell while teaching an introductory functional
programming course at the University of Porto. We describe the use of the
interpreter, present some feedback obtained from students, reflect on the
lessons learned and point directions for further work.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [Blueprint First, Model Second: A Framework for Deterministic LLM Workflow](https://arxiv.org/abs/2508.02721)
*Libin Qiu,Yuhang Ye,Zhirong Gao,Xide Zou,Junfu Chen,Ziming Gui,Weizhi Huang,Xiaobo Xue,Wenkai Qiu,Kun Zhao*

Main category: cs.SE

TL;DR: 本文提出Source Code Agent，将专家编写的流程蓝图与LLM分离，由确定性引擎严格执行，LLM仅解决复杂子任务。新框架在tau-bench测试中创下新纪录，提升了性能与效率，实现了自主代理在严格操作规范下的可靠应用。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）代理具有强大的能力，但由于其固有的非确定性，难以满足结构化操作环境对过程准确性与可预测执行的严格要求。这一局限来源于现有架构将高层概率规划和低层动作执行混为一体。

Method: 提出Source Code Agent框架，采用“先蓝图、后模型”理念，将工作流程逻辑与生成模型解耦。首先由专家将操作流程编码为源码形式的执行蓝图，然后由确定性引擎逐步执行。LLM仅用于在流程内处理有限且复杂的子任务，但不参与流程决策。

Result: 在tau-bench基准测试上，Source Code Agent超越了最强基线模型，平均Pass^1得分提高了10.1个百分点，并大幅提升了执行效率。

Conclusion: Source Code Agent框架克服了LLM代理在可预测性和可验证性上的局限，使得自主代理可在严格流程逻辑管控的应用中可靠部署。

Abstract: While powerful, the inherent non-determinism of large language model (LLM)
agents limits their application in structured operational environments where
procedural fidelity and predictable execution are strict requirements. This
limitation stems from current architectures that conflate probabilistic,
high-level planning with low-level action execution within a single generative
process. To address this, we introduce the Source Code Agent framework, a new
paradigm built on the "Blueprint First, Model Second" philosophy. Our framework
decouples the workflow logic from the generative model. An expert-defined
operational procedure is first codified into a source code-based Execution
Blueprint, which is then executed by a deterministic engine. The LLM is
strategically invoked as a specialized tool to handle bounded, complex
sub-tasks within the workflow, but never to decide the workflow's path. We
conduct a comprehensive evaluation on the challenging tau-bench benchmark,
designed for complex user-tool-rule scenarios. Our results demonstrate that the
Source Code Agent establishes a new state-of-the-art, outperforming the
strongest baseline by 10.1 percentage points on the average Pass^1 score while
dramatically improving execution efficiency. Our work enables the verifiable
and reliable deployment of autonomous agents in applications governed by strict
procedural logic.

</details>


### [5] [Interpreting Performance Profiles with Deep Learning](https://arxiv.org/abs/2508.02729)
*Zhuoran Liu*

Main category: cs.SE

TL;DR: 该论文提出将代码摘要与性能分析结合，利用深度学习模型CodeBERT生成语义信息，并在性能分析工具中进行集成交互，提升了程序性能瓶颈的定位和优化能力。系统对多个Java基准测试分析效果良好。


<details>
  <summary>Details</summary>
Motivation: 现有的性能分析工具（profilers）虽然可以有效帮助理解程序运行时的性能问题，但要求用户自行解读复杂的数据并将问题与源代码中的具体位置和含义相联系。对于不是代码作者的用户，这一点尤其困难，从而限制了分析工具的实际应用效能。

Method: 作者提出将性能分析（profiling）与深度学习驱动的代码语义分析相结合。具体方法是提取代码摘要，以获取一定层次的代码语义信息，并与基于Async Profiler生成的性能分析结果结合。利用微调后的CodeBERT模型对代码进行摘要，通过图形界面为用户展示任意调用路径的代码摘要信息。

Result: 系统能够将性能分析结果与代码摘要结合，并在图形用户界面中可视化展示，辅助用户更高效地理解和定位程序中的性能瓶颈，在多个Java基准测试中有效辅助分析任务。

Conclusion: 结合代码语义摘要与传统性能分析结果的新型分析工具，能帮助用户更好地理解程序性能问题，为源代码优化带来更直接和便捷的支持，提升分析工具的适用性。

Abstract: Profiling tools (also known as profilers) play an important role in
understanding program performance at runtime, such as hotspots, bottlenecks,
and inefficiencies. While profilers have been proven to be useful, they give
extra burden to software engineers. Software engineers, as the users, are
responsible to interpret the complex performance data and identify actionable
optimization in program source code. However, it can be challenging for users
to associate inefficiencies with the program semantics, especially if the users
are not the authors of the code, which limits the applicability of profilers.
  In this thesis, we explore a new direction to combine performance profiles
and program semantics with a deep learning approach. The key idea is to glean
code summary for semantic information (at a certain level) and integrate it
into a profiler, which can better understand program inefficiencies for
actionable optimization. To be concrete, we combine profiles generated by Async
Profiler (the state-of-the-art Java profiler) with code summarization from a
fine-tuned CodeBERT-based model. We demonstrate the code summaries of any
selected call path in a graphic user interface. Our system can effectively
assist analysis on many Java benchmarks.

</details>


### [6] [A Note on Code Quality Score: LLMs for Maintainable Large Codebases](https://arxiv.org/abs/2508.02732)
*Sherman Wong,Jalaj Bhandari,Leo Zhou Fan Yang,Xylan Xu,Yi Zhuang,Cem Cayiroglu,Payal Bhuptani,Sheela Yadawad,Hung Duong*

Main category: cs.SE

TL;DR: 提出了一套基于Llama3微调大模型和规则过滤的自动化代码质量检测和建议系统，已在工业级环境中部署并实现较高有效率，对大规模软件开发的代码质量管控有明显助益。


<details>
  <summary>Details</summary>
Motivation: 在大型软件系统中，众多工程师协作开发时，维护代码质量极具挑战。当前缺乏自动化、智能化的工具来有效发现代码问题并向开发者提供有用建议。为此，作者提出了一个能自动检测代码质量问题并给出可操作意见的系统。

Method: 提出并实现了Code Quality Score (CQS)系统，基于两种经过SFT和离线强化学习微调的Llama3模型：一是自动检测代码质量问题，二是针对LLM生成的代码评审给出高质量的批注。为保证用户体验，系统还加入了手工规则过滤错误或幻觉内容。此外，还介绍了如何利用开发者反馈数据来作为LLM微调的训练集。

Result: 在离线评测中，CQS系统在有效问题识别上表现出很高的精确度。目前该系统已在工业级开发环境中部署，且每周用户有用率持续达60%，显示出在实际环境中的有效性。

Conclusion: CQS系统基于大语言模型与规则组合，可有效支持大规模开发中的代码质量管控，既能及时发现问题，也能为开发者提供实用反馈，提升了整体开发效率，并为类系统开发提供了数据与经验。

Abstract: Maintaining code quality in large-scale software systems presents significant
challenges, particularly in settings where a large numbers of engineers work
concurrently on a codebase. This paper introduces Code Quality Score (CQS)
system to automatically detect issues with a set of code changes and provide
actionable insights. At its core, the CQS system is powered by two Llama3
models, fine-tuned (with SFT and offline RL approaches), to a) detect common
code quality issues related to coding best practices and b) to provide good
``critiques'' for LLM-generated code review respectively. To maintain good user
experience, we layer the system with hand-crafted rules to filter out incorrect
responses/hallucinations. Offline evaluations show that our CQS system is able
to achieve an impressive precision rate for identifying valid issues. This
system has already been rolled out to developers in an industrial scale setting
and has consistently achieved 60\% week over week user helpfulness rate,
demonstrating its effectiveness in a real-world environment. In this paper, we
present details of the CQS system along with some learnings on curating
developer feedback to create training data for LLM fine-tuning.

</details>


### [7] [What's in a Proof? Analyzing Expert Proof-Writing Processes in F* and Verus](https://arxiv.org/abs/2508.02733)
*Rijul Jain,Shraddha Barke,Gabriel Ebner,Md Rakib Hossain Misu,Shan Lu,Sarah Fakhoury*

Main category: cs.SE

TL;DR: 本文通过对F*和Verus两种POP语言的专家证明行为分析，总结出专家策略与设计原则，并据此改进AI证明助手，从而提升性能，为POP语言社区发展提供借鉴。


<details>
  <summary>Details</summary>
Motivation: 尽管POP语言能够提供形式化的正确性保证，但由于难以上手，其在更广泛的软件开发社区中尚未被广泛采用。缺乏对专家在POP语言中进行证明开发过程的理解，进一步阻碍了有效证明工程和证明合成工具/模型的发展。

Method: 本文通过用户研究，采集并分析了8位专家在两种POP语言（F*和Verus）中的细粒度源代码操作数据，揭示专家如何进行证明构思与实施，并识别出特有策略和实践。随后，作者将研究发现转化为AI证明助手的设计建议，并基于这些建议开发了F*证明智能体，并进行性能评估。

Result: 研究识别出三种独特的证明开发策略及多条非正式实践，这些内容并不会出现在最终代码快照中，但对任务结果具有预测性。采纳设计建议后开发的F*证明智能体在性能上优于基线大语言模型。

Conclusion: 专家在POP语言中的证明开发过程中采用了丰富和灵活的方法，理解并借鉴这些策略，有助于AI证明助手与证明合成工具的优化，进而推动POP语言的普及和高效应用。

Abstract: Proof-oriented programming languages (POPLs) empower developers to write code
alongside formal correctness proofs, providing formal guarantees that the code
adheres to specified requirements. Despite their powerful capabilities, POPLs
present a steep learning curve and have not yet been adopted by the broader
software community. The lack of understanding about the proof-development
process and how expert proof developers interact with POPLs has hindered the
advancement of effective proof engineering and the development of
proof-synthesis models/tools.
  In this work, we conduct a user study, involving the collection and analysis
of fine-grained source code telemetry from eight experts working with two
languages, F* and Verus. Results reveal interesting trends and patterns about
how experts reason about proofs and key challenges encountered during the proof
development process. We identify three distinct strategies and multiple
informal practices that are not captured final code snapshots, yet are
predictive of task outcomes. We translate these findings into concrete design
guidance for AI proof assistants: bias toward early specification drafting,
explicit sub-goal decomposition, bounded active errors, and disciplined
verifier interaction. We also present a case study of an F* proof agent
grounded in these recommendations, and demonstrate improved performance over
baseline LLMs

</details>


### [8] [Automated Code Repair for C/C++ Static Analysis Alerts](https://arxiv.org/abs/2508.02820)
*David Svoboda,Lori Flynn,William Klieber,Michael Duggan,Nicholas Reimer,Joseph Sible*

Main category: cs.SE

TL;DR: 本文提出并工程化实现了一个可自动修复多种C/C++静态分析告警的工具，经过大规模实测后发现，工具能够修复绝大多数告警且不会影响代码性能，并促进了编码规范更新。


<details>
  <summary>Details</summary>
Motivation: 静态分析（SA）工具在分析C/C++代码时经常产生大量诊断告警，其中许多是误报。识别真正的正告警并修复相关代码缺陷是非常耗时的过程，因此自动化程序修复（APR）工具可以显著减轻分析师的工作负担。本文旨在总结一种APR工具的工程设计和应用经验，推动代码安全与开发效率提升。

Method: 作者设计并实现了一个能够修复多类SA工具告警的APR工具。该工具针对3类常见代码缺陷，对应多种静态分析工具报警，采用局部简单修复策略，通过工程设计和大量性能测试验证其效果。同时，经验数据用于指导SA标准（如CERT编码规范）评估和更新修复/检测标准。

Result: 该APR工具在一个代码库中能修复8718个告警（共9234个）。在2类缺陷、2个静态分析工具和2个代码库的数据下，平均修复或识别为误报的告警比例超过80%。修复操作无明显性能损失，也未引入新告警（sqlite3.c除外）。贡献还包括APR工具开源发布和大规模SA数据集的披露。

Conclusion: 自动化程序修复工具确实能有效减少静态分析警报数以及开发者人工处理负担，对现有的代码规范和检测标准产生积极推动，并具备较强的实用价值。

Abstract: (Note: This work is a preprint.) Static analysis (SA) tools produce many
diagnostic alerts indicating that source code in C or C++ may be defective and
potentially vulnerable to security exploits. Many of these alerts are false
positives. Identifying the true-positive alerts and repairing the defects in
the associated code are huge efforts that automated program repair (APR) tools
can help with. Our experience showed us that APR can reduce the number of SA
alerts significantly and reduce the manual effort of analysts to review code.
This engineering experience paper details the application of design,
development, and performance testing to an APR tool we built that repairs C/C++
code associated with 3 categories of alerts produced by multiple SA tools. Its
repairs are simple and local. Furthermore, our findings convinced the
maintainers of the CERT Coding Standards to re-assess and update the metrics
used to assess when violations of guidelines are detectable or repairable. We
discuss engineering design choices made to support goals of trustworthiness and
acceptability to developers. Our APR tool repaired 8718 out of 9234 alerts
produced by one SA tool on one codebase. It can repair 3 flaw categories. For 2
flaw categories, 2 SA tools, and 2 codebases, our tool repaired or dismissed as
false positives over 80% of alerts, on average. Tests showed repairs did not
appreciably degrade the performance of the code or cause new alerts to appear
(with the possible exception of sqlite3.c). This paper describes unique
contributions that include a new empirical analysis of SA data, our selection
method for flaw categories to repair, publication of our APR tool, and a
dataset of SA alerts from open-source SA tools run on open-source codebases. It
discusses positive and negative results and lessons learned.

</details>


### [9] [StoneDetector: Conventional and versatile code clone detection for Java](https://arxiv.org/abs/2508.03435)
*Thomas S. Heinze,André Schäfer,Wolfram Amme*

Main category: cs.SE

TL;DR: StoneDetector是一种基于支配树路径文本比较的Java代码克隆检测平台，能够在源码和字节码中有效检测多种类型克隆，表现优于主流同类工具。


<details>
  <summary>Details</summary>
Motivation: 代码复制和粘贴是软件开发中的常见做法，导致了大量冗余且可能被修改的代码片段（代码克隆）的出现。这些代码克隆可能引发诸如软件膨胀、漏洞与bug传播等问题，所以需要有效的克隆检测机制。

Method: 提出了StoneDetector平台及其底层方法。该方法基于由支配树表示的代码路径进行文本比较来检测克隆。StoneDetector集成了不同的字符串度量、哈希算法等多种配置，能够在Java源码和字节码中检测完全一致、语法相近甚至结构变化较大的克隆代码。

Result: 通过与多种主流代码克隆检测工具在多个权威基准上的实验对比，证明了StoneDetector在Java源代码和字节码克隆检测中的性能及可扩展性。

Conclusion: StoneDetector作为一款传统克隆检测平台，不仅可检测常见的语法级克隆，还可发现更难识别的结构变化克隆，且具备良好的可扩展性和配置灵活性。

Abstract: Copy & paste is a widespread practice when developing software and, thus,
duplicated and subsequently modified code occurs frequently in software
projects. Since such code clones, i.e., identical or similar fragments of code,
can bloat software projects and cause issues like bug or vulnerability
propagation, their identification is of importance. In this paper, we present
the StoneDetector platform and its underlying method for finding code clones in
Java source and Bytecode. StoneDetector implements a conventional clone
detection approach based upon the textual comparison of paths derived from the
code's representation by dominator trees. In this way, the tool does not only
find exact and syntactically similar near-miss code clones, but also code
clones that are harder to detect due to their larger variety in the syntax. We
demonstrate StoneDetector's versatility as a conventional clone detection
platform and analyze its various available configuration parameters, including
the usage of different string metrics, hashing algorithms, etc. In our
exhaustive evaluation with other conventional clone detectors on several
state-of-the-art benchmarks, we can show StoneDetector's performance and
scalability in finding code clones in both, Java source and Bytecode.

</details>


### [10] [Automated Validation of LLM-based Evaluators for Software Engineering Artifacts](https://arxiv.org/abs/2508.02827)
*Ora Nova Fandina,Eitan Farchi,Shmulik Froimovich,Rami Katan,Alice Podolsky,Orna Raz,Avi Ziv*

Main category: cs.SE

TL;DR: REFINE是一套可自动合成带细粒度退化工件并评测大语言模型评判能力的框架，显著提升了评测细致度和一致性，已实践于IBM内部生产环境，效果显著。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在软件工程自动化方面应用广泛，但如何评估其评测者角色的可靠性仍是难题，现有评测方式不能精准区分工件质量细微差异。提出一种自动化且可调控的评测方法来提升可靠性和灵敏度。

Method: 提出REFINE框架，包括自动生成带有细粒度退化的代码工件的数据集和评测配置的自动化排名测试，结合工业级用例（如COBOL代码相关任务）进行实际应用验证。

Result: REFINE被集成进IBM开发流程，针对COBOL等关键任务，选出了Nuance Sensitive Evaluator，将部分任务的alignment score从0.7以下提升到0.9以上，已为模型团队所用，提升了模型发布决策的质量。

Conclusion: REFINE能够有效识别和提升大模型评测的灵敏度，已被应用于实际生产流程中，显著提升了评测一致性和分辨细微质量差异的能力。

Abstract: Automation in software engineering increasingly relies on large language
models (LLMs) to generate, review, and assess code artifacts. However,
establishing LLMs as reliable evaluators remains an open challenge: human
evaluations are costly, subjective and non scalable, while existing automated
methods fail to discern fine grained variations in artifact quality.
  We introduce REFINE (Ranking Evaluators for FIne grained Nuanced Evaluation),
an automated framework for benchmarking LLM based evaluators across software
engineering tasks. REFINE comprises of two modules: Hierarchy Dataset Builder
applies novel generation techniques to automatically synthesize artifacts with
progressively reduced quality, and Evaluator Tester quantifies each candidate
evaluator configuration by measuring how closely its rankings align with
expected ordering.
  A key feature of REFINE is controllability: users can tune the granularity of
degradation to progressively refine evaluator configurations, from coarse
filtering to stress testing on subtle quality gaps.
  While the methodology is general, we focus on coding tasks reflecting the
practical demands in our production setting. REFINE was integrated into IBM's
internal development workflows and applied to code generation, translation, and
summarization for COBOL, an enterprise critical programming language, using
industrial data. It was used to identify LLM as a Judge configurations that
lifted alignment scores from below $0.7$ to above $0.9$ in some coding tasks.
These nuance sensitive evaluators are now actively used by model training teams
to support model release decisions.

</details>


### [11] [ReFuzzer: Feedback-Driven Approach to Enhance Validity of LLM-Generated Test Programs](https://arxiv.org/abs/2508.03603)
*Iti Shree,Karine Even-Mendoz,Tomasz Radzik*

Main category: cs.SE

TL;DR: ReFuzzer通过反馈修正机制极大提升了大模型生成编译器测试程序的有效性和覆盖率，是LLM编译器模糊测试的有效增强方案。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的编译器模糊测试器往往生成语法或语义无效的测试程序，导致对编译器优化和后端组件测试效果有限。

Method: 提出了ReFuzzer框架，通过反馈回路和本地LLM来检测和修正编译与运行时违规（如除零或数组越界），在程序执行前过滤错误测试用例，提升模糊测试程序的有效性。

Result: ReFuzzer将测试程序的有效率从47.0-49.4%提升至96.6-97.3%，平均处理时间为2.9-3.5秒/程序，并在关键优化和中间表示生成组件中显著提升了代码覆盖率，例如矢量化覆盖率在黑、灰、白盒模糊测试中分别提升了9.2%、2.3%、7.1%。

Conclusion: ReFuzzer能显著提升基于LLM的编译器模糊测试程序的有效性和覆盖率，有效增强编译器测试效果，尤其在多种模糊测试场景下均表现出色。

Abstract: Existing LLM-based compiler fuzzers often produce syntactically or
semantically invalid test programs, limiting their effectiveness in exercising
compiler optimizations and backend components. We introduce ReFuzzer, a
framework for refining LLM-generated test programs by systematically detecting
and correcting compilation and runtime violations (e.g. division by zero or
array out-of-bounds accesses). ReFuzzer employs a feedback loop with a local
LLM to validate and filter erroneous programs before execution, improving
fuzzing effectiveness beyond crash detection and enabling the generation of
diverse yet valid test programs.
  We evaluated ReFuzzer's effectiveness across black-, grey- and white-box
fuzzing approaches targeting LLVM/Clang. ReFuzzer improved test programs'
validity from 47.0-49.4% to 96.6-97.3%, with an average processing time of
2.9-3.5 s per test program on a dual-GPU machine. Further, refuzzing
significantly increased code coverage in critical optimization and IR
generation components. For example, vectorization coverage had an absolute
improvement of 9.2%, 2.3%, and 7.1% in black-, grey-, and white-box fuzzing,
enhancing testing effectiveness.

</details>


### [12] [Developer Perceptions on Utilising Low-Code Approaches to Build Accessible and Adaptive Applications for Seniors](https://arxiv.org/abs/2508.02968)
*Shavindra Wickramathilaka,John Grundy,Kashumi Madampe,Omar Haggag*

Main category: cs.SE

TL;DR: 该论文通过访谈调研，评估了一款自动生成代码的低代码工具对开发面向老年人可访问应用的作用，提出了推动此类工具行业采纳的建议。


<details>
  <summary>Details</summary>
Motivation: 随着全球老龄化加剧，老年人对能提升自主性和可访问性的数字产品需求激增。现有开发方法经常因时间和资源受限，难以满足这类需求，同时面临法规压力（如欧盟无障碍法案）和开发者自身对老年家人的关切。

Method: 本文通过对18位软件从业者进行访谈性的实证研究，评估了名为AdaptForge的低代码模型驱动工程（MDE）工具。该工具通过自动化代码生成，有效缓解开发限制，使开发者高效开发面向老年用户的可访问且自适应的应用。

Result: 研究识别出开发者在采纳此类低代码工具为行业标准解决方案时的期望，并基于实证数据，提出了支持可访问与自适应软件开发的低代码工具设计建议。

Conclusion: 开发自动化、低代码工具如AdaptForge能有效帮助从业者开发适合老年人的高可访问性、自适应应用，并有望作为推动行业发展的标准化解决方案。

Abstract: The global ageing population presents a growing societal challenge, creating
an urgent need for inclusive technologies that promote autonomy among older
adults. Software practitioners can address this by delivering digital services
that enhance seniors' independence and reduce reliance on routine support from
family members and healthcare infrastructure. However, traditional development
practices, constrained by time and resources, often result in applications with
major accessibility and personalisation barriers. Increasing pressure from
regulatory requirements, such as the European Accessibility Act (EAA), and the
personal empathy many developers feel toward supporting their older loved ones
and their own future selves have created a demand for tools that support the
development of accessible and adaptive software. To address this demand, this
paper presents an interview-based empirical study with 18 software
practitioners, evaluating AdaptForge: a low-code model-driven engineering (MDE)
tool that enables the efficient creation of accessible and adaptive
applications for senior users by mitigating development constraints through
automated code generation. Based on these insights, we identify developer
expectations for adopting such tools as industry-standard solutions and provide
empirically grounded recommendations for designing low-code tools that support
accessible and adaptive software development.

</details>


### [13] [MRG-Bench: Evaluating and Exploring the Requirements of Context for Repository-Level Code Generation](https://arxiv.org/abs/2508.02998)
*Haiyang Li*

Main category: cs.SE

TL;DR: 本文提出MRG-Bench多语言代码生成评测基准，实验发现现有模型对用户需求理解差，且不同编程语言上下文影响较大，表明实际应用需更针对性地设计模型和输入上下文。


<details>
  <summary>Details</summary>
Motivation: 目前大模型在代码生成方面虽表现优异，但评测数据集存在可运行性差、只支持Python、与真实代码分布有偏离的问题，影响了评估的可信度。

Method: 提出MRG-Bench数据集，具备（1）真实仓库分布的代码数据，（2）支持Python、Java、Go三种语言，（3）包含项目级可运行测试用例，并基于此进行多模型和多方法实验。

Result: 实验证明，现有仓库级代码生成技术性能不足。进一步实验分析发现，模型多数问题在于‘难以理解用户需求’，而且该问题在不同语言间上下文影响差异显著，说明实际中需为不同语言设计专门上下文信息。

Conclusion: MRG-Bench为多语言仓库级代码生成提供了更现实的评估基准，揭示了当前模型在理解需求和多语言支持上的显著不足。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in
code generation. However, current evaluation datasets suffer from issues such
as the lack of runnable test cases, deviation from the distribution of
real-world code, and the ability to evaluate only the Python language. These
limitations undermine the credibility of the evaluation results.
  To address these limitations, we introduce \textbf{MRG-Bench} (Multi-language
Repository-level Code Generation Benchmark), a novel dataset that provides a
more accurate evaluation of LLMs in practical repository-level code generation
tasks. MRG-Bench has three main features: (1) practical data sourced from
real-world code repositories that align to the practical distribution, (2)
multiple programming languages support, including Python, Java, and Go, and (3)
project-level runnable test cases to assess the quality of the generated code.
  Based on MRG-Bench, we conducted extensive experiments including large
language models, long-context models, and RAG-related methods. These evaluation
results demonstrate that \textbf{current repository-level code generation
techniques suffer from significant performance deficiencies}. To further
investigate why models fail, we designed novel experiments to annotate the
underlying causes of generation errors. The results explicitly show that the
majority of methods suffer from "\textbf{difficulty in understanding user
requirements}," failing to comprehend their assigned tasks accurately.
Moreover, the impact of different repository-level contexts on this issue
exhibits significant disparities across different programming languages,
suggesting that, in practice, specialized contextual information needs to be
designed for different languages.

</details>


### [14] [Tool-integrated Reinforcement Learning for Repo Deep Search](https://arxiv.org/abs/2508.03012)
*Zexiong Ma,Chao Peng,Qunhong Zeng,Pengfei Gao,Yanzhen Zou,Bing Xie*

Main category: cs.SE

TL;DR: 本文提出一种名为ToolTrain的两阶段工具集成训练框架，通过结合带拒绝采样的有监督微调和工具强化学习，提升大语言模型在多步骤代码依赖推理中的缺陷定位能力。实验表明，该方法在函数级定位任务上取得了行业领先的效果。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型虽集成检索工具进行仓库搜索，但面对自然语言问题描述与代码逻辑之间的语义鸿沟，多步推理与导航能力仍有限，需要开发新方法提升其复杂场景下的定位和检索能力。

Method: 采用两阶段训练方法：第一阶段为带拒绝采样的有监督微调，第二阶段为与检索工具集成的强化学习，从而增强模型有效利用代码仓库信息的能力。

Result: ToolTrain训练后的模型在函数级缺陷定位超过了Claude-3.7，表现达到了领域最优，并且定位能力的提升进一步提高了端到端的自动化问题解决效率。

Conclusion: 通过面向缺陷定位任务进行专门训练，可以有效提升大语言模型在自动化软件开发中的表现，实现更精准的问题定位和解决。

Abstract: Issue localization, the process of identifying code locations that need
modification to resolve software issues, is a critical yet challenging task in
software development. The semantic gap between natural language issue
descriptions and faulty code requires complex multi-hop reasoning through code
dependencies. Existing LLM-based agents attempt to address this by integrating
repository retrieval tools. However, this transforms issue localization into a
demanding task we call Repo Deep Search, which requires the LLM to effectively
utilize various repository retrieval tools throughout a multi-step reasoning
and navigation process. To tackle this challenge, we present ToolTrain, a
two-stage tool-integrated training framework combining rejection-sampled
supervised fine-tuning and tool-integrated reinforcement learning to enhance
LLMs' ability to use retrieval tools for issue localization. Experimental
results show that ToolTrain-trained models achieve state-of-the-art
performance, with our 32B model even surpassing Claude-3.7 on function-level
localization. The results also show that improved localization performance
translates to better end-to-end issue resolution performance. This further
demonstrates that training for issue localization is a viable and effective
strategy for improving automated software development.

</details>


### [15] [A System Model Generation Benchmark from Natural Language Requirements](https://arxiv.org/abs/2508.03215)
*Dongming Jin,Zhi Jin,Linyu Li,Zheng Fang,Jia Li,Xiaohong Chen*

Main category: cs.SE

TL;DR: 论文提出了SysMBench基准测试集和SysMEval语义感知评价指标，用于评估大语言模型（LLM）在生成系统模型（用特定的模型描述语言）的能力。结果显示现有LLM在该任务上表现较差。


<details>
  <summary>Details</summary>
Motivation: 系统模型是软件开发的重要基础，但受限于描述语言难度及公共样例稀缺，开发难度较大。虽然LLM展现出一定代码生成能力，但缺乏针对系统模型生成的基准和系统性评测方法。该工作意在填补此空白。

Method: 作者建立了包含151个人工策划场景的SysMBench数据集，每个场景包含自然语言需求描述、系统模型（基于特定描述语言），以及可视化模型图，同时提出了SysMEval指标；评估了17个主流LLM基于直接提示及三种增强策略下的系统建模能力。

Result: 最优模型在BLEU指标上仅得4%，SysMEval-F1最高仅62%。显示现有LLM对于系统建模任务的理解与生成能力仍有较大提升空间。作者公开了数据集及工具。

Conclusion: 当前主流LLM在系统建模能力方面表现远未达标，呼吁今后研究针对系统模型生成进行更多探索。SysMBench和评价框架的发布为后续相关领域研究提供了切实工具和数据。

Abstract: System models, a critical artifact in software development, provide a formal
abstraction of both the structural and behavioral aspects of software systems,
which can facilitate the early requirements analysis and architecture design.
However, developing system models remains challenging due to the specific
syntax of model description languages and the relative scarcity of public model
examples. While large language models (LLMs) have shown promise in generating
code with programming languages and could potentially aid in system model
development, no benchmarks currently exist for evaluating their ability to
generate system models with specific description languages. We present
SysMBench, which comprises 151 human-curated scenarios spanning a wide range of
popular domains and varying difficulty levels. Each scenario mainly comprises a
natural language requirements description, a system model expressed in a
specific model description language, and a visualized system model diagram. The
requirements description is fed as user input to the LLM, the system model with
description language is used to verify if the generated system model conforms
to the requirements, and the visualized diagram serves to support manual
validation. We introduce SysMEval, a semantic-aware evaluation metric to
evaluate the quality of generated system models. We evaluate 17 popular LLMs on
this task with three traditional metrics and SysMEval, from directly prompting
to three commonly used enhancement strategies. Our in-depth evaluation shows
that LLMs perform poorly on SysMBench, with the highest BLEU of 4% and
SysMEval-F1 of 62%. We release the SysMBench and its evaluation framework to
enable future research on LLM-based system model generation.

</details>


### [16] [SmartLLMs Scheduler: A Framework for Cost-Effective LLMs Utilization](https://arxiv.org/abs/2508.03258)
*Yueyue Liu,Hongyu Zhang,Yuantian Miao*

Main category: cs.SE

TL;DR: 提出了一个能动态调度及优化LLM任务分配的系统SmartLLMs Scheduler（SLS），显著提升性能并降低响应时间。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在实际部署中面临高昂成本、响应缓慢和性能不稳定等问题；现有优化策略多为静态调度，依赖大量训练数据，限制了灵活性与实用性。因此，亟需一种动态、可自适应并降低成本的调度机制。

Method: 本文提出了一种名为SmartLLMs Scheduler (SLS)的动态与高性价比的调度方案。SLS包含自适应缓存管理器、性能-成本优化调度器及动态更新管理器三个关键组件，能综合利用LLMs的反馈实时调整任务分配。其核心做法是缓存已处理的查询，利用自适应策略减少冗余计算，对未命中缓存的查询，动态结合任务和模型特征分配给最优的LLM。所有分配和缓存策略可根据查询实时反馈不断优化。

Result: 在日志解析和代码生成两个场景下广泛实验表明，SLS较基线方法平均性能提升198.82%，处理时间缩短63.28%。

Conclusion: SLS能够通过自适应和动态优化策略显著提升LLMs的实用表现，降低了计算成本，实现了高效、灵活的LLM部署。

Abstract: Large Language Models (LLMs) such as GPT-4 and Llama have shown remarkable
capabilities in a variety of software engineering tasks. Despite the
advancements, their practical deployment faces challenges, including high
financial costs, long response time, and varying performance, especially when
handling a large number of queries (jobs). Existing optimization strategies for
deploying LLMs for diverse tasks focus on static scheduling, which requires
extensive training data for performance prediction, increasing the
computational costs and limiting the applicability and flexibility. In this
paper, we propose the SmartLLMs Scheduler (SLS), a dynamic and cost-effective
scheduling solution. The key idea is to learn LLMs' performance on diverse
tasks and incorporate their real-time feedback to update strategies
periodically. Specifically, SLS incorporates three key components, including an
Adaptive Cache Manager, a Performance-Cost Optimized Scheduler, and a Dynamic
Update Manager. The Cache Manager stores the outputs of previously processed
queries and employs an adaptive strategy to reduce redundant computations and
minimize response times. For queries not found in the cache, the Scheduler
dynamically allocates them to the most suitable LLM based on the predicted
performance and cost from models that take both query-specific and LLM-specific
features as input. The Update Manager continuously refines the cache and
scheduling strategies based on real-time feedback from the assigned queries to
enhance decision-making and adapt to evolving task characteristics. To evaluate
the effectiveness of SLS, we conduct extensive experiments on two LLM-based
software engineering tasks, including log parsing and code generation. The
results show that SLS significantly outperforms the baseline methods, achieving
an average performance improvement of 198.82% and an average processing time
reduction of 63.28%.

</details>


### [17] [GUI-ReRank: Enhancing GUI Retrieval with Multi-Modal LLM-based Reranking](https://arxiv.org/abs/2508.03298)
*Kristian Kolthoff,Felix Kretzer,Christian Bartelt,Alexander Maedche,Simone Paolo Ponzetto*

Main category: cs.SE

TL;DR: 提出了GUI-ReRank，一个集成嵌入检索与MLLM重排序、支持自定义GUI仓库的NL-GUI检索框架，在准确率与泛化性上均优于现有方法，并分析了其资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有的GUI原型开发流程耗时且需要大量人力，传统的自然语言检索GUI方法存在泛化能力和性能瓶颈，需要更高效、轻量化且易于应用于多样GUI仓库的检索解决方案。

Method: 方法包括：1）快速的基于嵌入的约束性检索，用于初步过滤GUI候选。2）结合多模态大语言模型（MLLM）进行高效重排序，提升最终检索效果。3）提出可完全自定义的GUI仓库注释与嵌入流程，使私有GUI库支持自然语言检索。4）在标准评测基准上验证性能，并系统分析了MLLM重排序的效率/资源消耗。

Result: 所提出的GUI-ReRank框架在自然语言GUI检索基准任务上，效果明显超越了当前最新的专用排序模型（LTR），同时具备更好的泛化能力。此外，还给出了多模态大模型（MLLMs）重排序的成本与效率分析，优化了检索效果与计算资源之间的权衡。

Conclusion: GUI-ReRank显著提升了GUI原型的自然语言检索性能，为开发者与设计团队带来了灵活的GUI发现与复用工具，同时其开源的注释及嵌入流程助力个性化GUI数据的集成，推动了LLM驱动RAG流程在GUI开发中的应用。

Abstract: GUI prototyping is a fundamental component in the development of modern
interactive systems, which are now ubiquitous across diverse application
domains. GUI prototypes play a critical role in requirements elicitation by
enabling stakeholders to visualize, assess, and refine system concepts
collaboratively. Moreover, prototypes serve as effective tools for early
testing, iterative evaluation, and validation of design ideas with both end
users and development teams. Despite these advantages, the process of
constructing GUI prototypes remains resource-intensive and time-consuming,
frequently demanding substantial effort and expertise. Recent research has
sought to alleviate this burden through NL-based GUI retrieval approaches,
which typically rely on embedding-based retrieval or tailored ranking models
for specific GUI repositories. However, these methods often suffer from limited
retrieval performance and struggle to generalize across arbitrary GUI datasets.
In this work, we present GUI-ReRank, a novel framework that integrates rapid
embedding-based constrained retrieval models with highly effective MLLM-based
reranking techniques. GUI-ReRank further introduces a fully customizable GUI
repository annotation and embedding pipeline, enabling users to effortlessly
make their own GUI repositories searchable, which allows for rapid discovery of
relevant GUIs for inspiration or seamless integration into customized LLM-based
RAG workflows. We evaluated our approach on an established NL-based GUI
retrieval benchmark, demonstrating that GUI-ReRank significantly outperforms
SOTA tailored LTR models in both retrieval accuracy and generalizability.
Additionally, we conducted a comprehensive cost and efficiency analysis of
employing MLLMs for reranking, providing valuable insights regarding the
trade-offs between retrieval effectiveness and computational resources. Video:
https://youtu.be/_7x9UCh82ug

</details>


### [18] [Industrial LLM-based Code Optimization under Regulation: A Mixture-of-Agents Approach](https://arxiv.org/abs/2508.03329)
*Mari Ashiga,Vardan Voskanyan,Fateme Dinmohammadi,Jingzhi Gong,Paul Brookes,Matthew Truscott,Rafail Giavrimis,Mike Basios,Leslie Kanthan,Wei Jie*

Main category: cs.SE

TL;DR: 论文提出多智能体集成方式，用开源LLM组合实现产业级代码优化，比单一模型和传统GA有更好成本、速度表现，并针对受监管环境给出部署建议。


<details>
  <summary>Details</summary>
Motivation: 受限于隐私保护和合规需求，许多受监管行业无法使用商用大型语言模型进行代码优化，亟需寻找高质量且成本效益兼具的新方案。

Method: 提出并实现了基于多智能体混合（Mixture-of-Agents, MoA）架构，调度多个专用的开源LLM共同合成优化代码，并与现有的GA（遗传算法）系统及单一LLM进行对比实验，使用真实工业代码库进行验证。

Result: MoA方法在使用开源模型的场景下相较于商用模型和单一LLM有明显收益：可节省14.3%至22.2%的成本，优化速度快28.6%至32.2%；GA集成在使用商用LLM时表现更优，但无论MoA还是GA集成都优于单一LLM。实验覆盖7种模型组合、50份工业代码片段，总生成约8700个代码优化变体。

Conclusion: 在受监管场景下，基于MoA的集成多LLM方案能够兼顾合规与优化效果，为企业部署高效合规的自动代码优化系统提供了可行路线和实践指引。

Abstract: Recent advancements in Large Language Models (LLMs) for code optimization
have enabled industrial platforms to automate software performance engineering
at unprecedented scale and speed. Yet, organizations in regulated industries
face strict constraints on which LLMs they can use - many cannot utilize
commercial models due to data privacy regulations and compliance requirements,
creating a significant challenge for achieving high-quality code optimization
while maintaining cost-effectiveness. We address this by implementing a
Mixture-of-Agents (MoA) approach that directly synthesizes code from multiple
specialized LLMs, comparing it against TurinTech AI's vanilla Genetic Algorithm
(GA)-based ensemble system and individual LLM optimizers using real-world
industrial codebases. Our key contributions include: (1) First MoA application
to industrial code optimization using real-world codebases; (2) Empirical
evidence that MoA excels with open-source models, achieving 14.3% to 22.2% cost
savings and 28.6% to 32.2% faster optimization times for regulated
environments; (3) Deployment guidelines demonstrating GA's advantage with
commercial models while both ensembles outperform individual LLMs; and (4)
Real-world validation across 50 code snippets and seven LLM combinations,
generating over 8,700 variants, addresses gaps in industrial LLM ensemble
evaluation. This provides actionable guidance for organizations balancing
regulatory compliance with optimization performance in production environments.

</details>


### [19] [Key-Augmented Neural Triggers for Knowledge Sharing](https://arxiv.org/abs/2508.03340)
*Alex Wolf,Marco Edoardo Palma,Pooja Rani,Harald C. Gall*

Main category: cs.SE

TL;DR: 本文提出通过知识锚点提升了代码仓库知识理解的效率和系统部署的灵活性，显著减少了推理延迟，并在多个维度上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前在软件工程领域，理解和共享代码仓库级别的知识一直存在诸多挑战。虽然大模型能够生成代码结构和逻辑的解释，但在知识分布分散、检索效率、上下文冗长和数据稀缺等方面仍存在不足。此外，专有大模型的限制也妨碍了其在行业中的应用。

Method: 本文提出了一种新的方法——Key-Augmented Neural Triggers（KANT），通过在训练与推理阶段嵌入知识锚点，使得模型可以内部访问特定仓库知识、减少语义碎片化，并合成基于代码的专用数据供训练和推理。在推理时，用知识锚点替代表述冗长的上下文，从而减小模型推理时的token负担并提高速度。

Result: KANT生成的训练数据能够覆盖信息寻求需求。人类评估显示KANT在五个维度上相比SOTA基线更受青睐，在推理速度上表现更快（最多提升85%），并能适配多种大语言模型，体现良好的泛化性。

Conclusion: KANT能够有效解决代码仓库知识推理中的碎片化、高延迟和产业落地难等问题，是实现高效、可扩展、低延迟、本地部署代码理解系统的有力工具。

Abstract: Repository-level code comprehension and knowledge sharing remain core
challenges in software engineering. Large language models (LLMs) have shown
promise by generating explanations of program structure and logic. However,
these approaches still face limitations: First, relevant knowledge is
distributed across multiple files within a repository, aka semantic
fragmentation. Second, retrieval inefficiency and attention saturation degrade
performance in RAG pipelines, where long, unaligned contexts overwhelm
attention. Third, repository specific training data is scarce and often
outdated. Finally, proprietary LLMs hinder industrial adoption due to privacy
and deployment constraints. To address these issues, we propose Key-Augmented
Neural Triggers (KANT), a novel approach that embeds knowledge anchors into
both training and inference. Unlike prior methods, KANT enables internal access
to repository specific knowledge, reducing fragmentation and grounding
inference in localized context. Moreover, we synthesize specialized data
directly from code. At inference, knowledge anchors replace verbose context,
reducing token overhead and latency while supporting efficient, on premise
deployment. We evaluate KANT via: a qualitative human evaluation of the
synthesized dataset's intent coverage and quality across five dimensions;
compare against SOTA baselines across five qualitative dimensions and inference
speed; and replication across different LLMs to assess generalizability.
Results show that the synthetic training data aligned with information-seeking
needs. KANT achieved over 60% preference from human annotators and a LocalStack
expert (preferring 79% of cases). Also, KANT reduced inference latency by up to
85% across all models. Overall, it is well-suited for scalable, low-latency,
on-premise deployments, providing a strong foundation for code comprehension.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [20] [When are two algorithms the same? Towards addressing Hilbert's 24th problem](https://arxiv.org/abs/2508.02764)
*Konstantin Doubrovinski*

Main category: cs.LO

TL;DR: 该文借助Kolmogorov复杂度，提出了递归理论下衡量两个程序（或定理证明）本质相同性的极简方法。


<details>
  <summary>Details</summary>
Motivation: 探讨判定两个定理证明“本质上是否相同”的问题，这一问题最早可追溯到Hilbert。由于形式证明与计算机程序（递归函数）有密切关联，对程序的“本质相同性”问题同样值得研究。

Method: 提出在递归理论框架下利用Kolmogorov复杂度，构建一个极简主义的研究方法来分析程序（或证明）的本质相同性。

Result: 提出了一种基于Kolmogorov复杂度的分析方法，用于判断两个程序或定理证明在递归理论中的相似性。

Conclusion: 通过将Kolmogorov复杂度引入递归理论，为判定程序（即证明）“本质相同”提供了一种新的理论工具和极简途径。

Abstract: The informal question of when two theorem proofs are "essentially the same"
goes back to David Hilbert, who considered adding it (or something largely
equivalent) to his famous list of open problems, but eventually decided to
leave it out. Given that the notion of a formal proof is closely related to
that of a (computer) program, i.e. a recursive function, it may be useful to
ask the same question with regard to programs instead. Here we propose a
minimalistic approach to this question within Recursion Theory, building
heavily on the use of Kolmogorov Complexity.

</details>


### [21] [Intensional FOL over Belnap's Billatice for Strong-AI Robotics](https://arxiv.org/abs/2508.02774)
*Zoran Majkic*

Main category: cs.LO

TL;DR: 本文提出一种基于四值逻辑扩展的多类型一阶逻辑，用以支持AGI系统应对不完全和矛盾信息，提升其类人智能水平。


<details>
  <summary>Details</summary>
Motivation: 为实现类人智能的AGI（强人工智能）机器，需克服传统一阶逻辑在处理不完全知识和矛盾公式时的局限性。

Method: 提出了一种基于Tarskian语义的多类型意向性一阶逻辑（IFOL）扩展版本，语法未变但引入了Belnap四值双格，处理真值与知识排序问题。

Result: 该方法可避免传统二值FOL的悖论和一致性问题，使机器人能够处理不完全和矛盾知识。

Conclusion: 扩展后的IFOL更贴合类人智能需求，让AGI机器人能像人类一样处理复杂的知识与经验，有助于实现更强的智能系统。

Abstract: AGI (Strong AI) aims to create intelligent robots that are quasi
indistinguishable from the human mind. Like a child, the AGI robot would have
to learn through input and experiences, constantly progressing and advancing
its abilities over time. The AGI robot would require an intelligence more close
to human's intelligence: it would have a self-aware consciousness that has the
ability to solve problems, learn, and plan. Based on this approach an
Intensional many-sorted First-order Logic (IFOL), as an extension of a standard
FOL with Tarskian's semantics, is proposed in order to avoid the problems of
standard 2-valued FOL with paradoxes (inconsistent formulae) and a necessity
for robots to work with incomplete (unknown) knowledge as well. This is a more
sophisticated version of IFOL with the same syntax but different semantics,
able to deal with truth-ordering and knowledge-ordering as well, based on the
well known Belnap's billatice with four truth-values that extend the set of
classical two truth-values.

</details>


### [22] [Analysis of logics with arithmetic](https://arxiv.org/abs/2508.03574)
*Michael Benedikt,Chia-Hsuan Lu,Tony Tan*

Main category: cs.LO

TL;DR: 本文研究了带计数和算术的逻辑系统的有限可满足性，获得了复杂性的最优界和更简洁的证明方法。


<details>
  <summary>Details</summary>
Motivation: 有限可满足性问题在逻辑和理论计算机科学中具有重要意义，尤其是在带计数和算术的逻辑系统中，复杂性和可判定性分析一直是挑战。本论文旨在推动这方面的理解。

Method: 对带有计数和算术的两变量逻辑、包含对一元公式基数比较的逻辑以及含局部Presburger量词的逻辑，研究其有限可满足性；同时给出对关键先前结果（如有限可满足性和谱的半线性）的更简洁证明。

Result: 得到了带计数和基数比较的两变量逻辑以及含局部Presburger量词的逻辑有限可满足性的复杂性紧致界，同时为相关逻辑的有限可满足性和谱的半线性提供了更为简明的证明。

Conclusion: 本论文不仅改进并精简了现有关键结果的证明方法，还在包含计数和算术的逻辑系统有限可满足性问题上得出了复杂性的紧致界，对理论计算机科学领域相关研究具有重要推动作用。

Abstract: We present new results on finite satisfiability of logics with counting and
arithmetic. This includes tight bounds on the complexity for two-variable logic
with counting and cardinality comparisons between unary formulas, and also on
logics with so-called local Presburger quantifiers. In the process, we provide
simpler proofs of some key prior results on finite satisfiability and
semi-linearity of the spectrum for these logics.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [23] [Clinically Grounded Agent-based Report Evaluation: An Interpretable Metric for Radiology Report Generation](https://arxiv.org/abs/2508.02808)
*Radhika Dua,Young Joon,Kwon,Siddhant Dogra,Daniel Freedman,Diana Ruan,Motaz Nashawaty,Danielle Rigau,Daniel Alexander Alber,Kang Zhang,Kyunghyun Cho,Eric Karl Oermann*

Main category: cs.CL

TL;DR: 本文提出了ICARE框架，一种可解释且以临床为基础的自动化放射学报告评估方法，通过大语言模型代理生成和答题实现报告评测，结果更贴合临床专家判断。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化放射学报告生成评估方法缺乏可解释性，且难以与临床需求紧密结合，为解决这一问题，需要开发更加透明、可靠的报告评测方法。

Method: 框架设计了两个基于LLM的代理，分别掌握真实报告和生成报告，通过提出临床相关的动态选择题互相提问，双方对问题的回答匹配度反映了报告内容的保存和一致性，并可追溯具体得分项。

Result: ICARE能明显提升报告自动评估的可解释性和临床相关性，对内容扰动敏感且具有可重现性，并揭示不同生成模型的具体误差模式，受专家评判高度认可。

Conclusion: ICARE框架评估自动生成放射学报告的结果显著优于以往指标，能更好地与专家意见一致，并且评测过程透明、可解释。

Abstract: Radiological imaging is central to diagnosis, treatment planning, and
clinical decision-making. Vision-language foundation models have spurred
interest in automated radiology report generation (RRG), but safe deployment
requires reliable clinical evaluation of generated reports. Existing metrics
often rely on surface-level similarity or behave as black boxes, lacking
interpretability. We introduce ICARE (Interpretable and Clinically-grounded
Agent-based Report Evaluation), an interpretable evaluation framework
leveraging large language model agents and dynamic multiple-choice question
answering (MCQA). Two agents, each with either the ground-truth or generated
report, generate clinically meaningful questions and quiz each other. Agreement
on answers captures preservation and consistency of findings, serving as
interpretable proxies for clinical precision and recall. By linking scores to
question-answer pairs, ICARE enables transparent, and interpretable assessment.
Clinician studies show ICARE aligns significantly more with expert judgment
than prior metrics. Perturbation analyses confirm sensitivity to clinical
content and reproducibility, while model comparisons reveal interpretable error
patterns.

</details>


### [24] [Modeling Annotator Disagreement with Demographic-Aware Experts and Synthetic Perspectives](https://arxiv.org/abs/2508.02853)
*Yinuo Xu,Veronica Derricks,Allison Earl,David Jurgens*

Main category: cs.CL

TL;DR: DEM-MoE模型结合标注者人口信息与合成数据，改善了主观NLP任务中群体分歧的建模效果，优化了多样性表达，并可利用LLM生成的合成标注扩展数据集，提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有主观NLP任务中不同标注者间存在分歧，且如何有效建模和利用这种分歧（尤其是与标注者人口统计信息相关的分歧）未被充分解决，同时在数据人口覆盖面不足的情况下，合成标注数据是否有效也有待探索。

Method: 提出了一种新的模型DEM-MoE（Demographic-Aware Mixture of Experts），它根据标注者的人口统计信息将输入分配给不同专家子网络以更好地建模群体间结构化差异。同时，引入基于大型语言模型（LLM）的零样本角色模拟生成合成标注，用以数据补全，并设计和评估了多种混合真实与合成数据的策略。

Result: DEM-MoE模型在不同人口统计群体上的表现均很有竞争力，尤其适用于标注者分歧程度高的数据集。合成标注与人工标注有中等程度的一致性，可有效扩展训练数据。最佳混合策略依赖于具体数据结构。整体提升了多元观点的表达能力。

Conclusion: DEM-MoE及相关数据混合策略能够更好地代表和建模主观任务中不同群体的多样化观点，并能在数据有限时通过合成数据扩充和优化训练效果。

Abstract: We present an approach to modeling annotator disagreement in subjective NLP
tasks through both architectural and data-centric innovations. Our model,
DEM-MoE (Demographic-Aware Mixture of Experts), routes inputs to expert
subnetworks based on annotator demographics, enabling it to better represent
structured, group-level variation compared to prior models. DEM-MoE
consistently performs competitively across demographic groups, and shows
especially strong results on datasets with high annotator disagreement. To
address sparse demographic coverage, we test whether LLM-generated synthetic
annotations via zero-shot persona prompting can be used for data imputation. We
show these synthetic judgments align moderately well with human annotations on
our data and offer a scalable way to potentially enrich training data. We then
propose and evaluate approaches for blending real and synthetic data using
strategies tailored to dataset structure. We find that the optimal strategies
depend on dataset structure. Together, these contributions improve the
representation of diverse perspectives.

</details>


### [25] [Highlight & Summarize: RAG without the jailbreaks](https://arxiv.org/abs/2508.02872)
*Giovanni Cherubin,Andrew Paverd*

Main category: cs.CL

TL;DR: 本文提出了一种防止LLM越狱和模型劫持的新设计：Highlight & Summarize（H&S），通过在不暴露用户问题的情况下生成答案，有效提升安全性和响应质量，且实际效果优于传统方案。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）容易受到越狱（jailbreaking）和模型劫持（model hijacking）攻击。恶意用户可以通过特殊设计的问题使LLM生成不良内容或执行与初衷不符的任务。现有防护方法往往通过加固系统提示词或使用内容分类器来检测不良内容，但这些概率性方法容易被规避。

Method: 提出了一种新的基于检索增强生成（RAG）系统的设计模式——Highlight & Summarize（H&S）。其核心思想是在生成回答时，从整个流程中隐藏用户的问题，即通过两步实现：（1）高亮器，基于用户提问从文档中提取相关重要片段；（2）摘要器，对这些高亮片段生成总结性回答。总结器看不到用户原始问题。

Result: 实验对比了H&S和标准RAG流程的输出，从正确性、相关性和答复质量三个方面评估。结果显示，采用基于LLM的高亮器后，大多数H&S的回答被评判为优于传统RAG。

Conclusion: H&S模式在预防LLM越狱和模型劫持攻击方面天然具备优势。在不显式暴露用户问题给生成模型的前提下，仍能生成高质量的自然语言回答，并在多项评测上超越标准RAG流程。

Abstract: Preventing jailbreaking and model hijacking of Large Language Models (LLMs)
is an important yet challenging task. For example, when interacting with a
chatbot, malicious users can input specially crafted prompts to cause the LLM
to generate undesirable content or perform a completely different task from its
intended purpose. Existing mitigations for such attacks typically rely on
hardening the LLM's system prompt or using a content classifier trained to
detect undesirable content or off-topic conversations. However, these
probabilistic approaches are relatively easy to bypass due to the very large
space of possible inputs and undesirable outputs. In this paper, we present and
evaluate Highlight & Summarize (H&S), a new design pattern for
retrieval-augmented generation (RAG) systems that prevents these attacks by
design. The core idea is to perform the same task as a standard RAG pipeline
(i.e., to provide natural language answers to questions, based on relevant
sources) without ever revealing the user's question to the generative LLM. This
is achieved by splitting the pipeline into two components: a highlighter, which
takes the user's question and extracts relevant passages ("highlights") from
the retrieved documents, and a summarizer, which takes the highlighted passages
and summarizes them into a cohesive answer. We describe several possible
instantiations of H&S and evaluate their generated responses in terms of
correctness, relevance, and response quality. Surprisingly, when using an
LLM-based highlighter, the majority of H&S responses are judged to be better
than those of a standard RAG pipeline.

</details>


### [26] [Bridging LLMs and Symbolic Reasoning in Educational QA Systems: Insights from the XAI Challenge at IJCNN 2025](https://arxiv.org/abs/2508.01263)
*Long S. T. Nguyen,Khang H. N. Vo,Thu H. A. Nguyen,Tuan C. Bui,Duc Q. Nguyen,Thanh-Tung Tran,Anh D. Nguyen,Minh L. Nguyen,Fabien Baldacci,Thang H. Bui,Emanuel Di Nardo,Angelo Ciaramella,Son H. Le,Ihsan Ullah,Lorenzo Di Rocco,Tho T. Quan*

Main category: cs.CL

TL;DR: 本文分析了XAI Challenge 2025可解释AI黑客松，推动了大语言模型与符号推理结合用于教育问答系统的可解释性，并为未来XAI系统设计提供参考。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在教育领域的渗透，对AI系统的透明性和可解释性需求日益增长，但实际教育场景中针对可解释AI（XAI）的黑客马拉松较少。本文旨在通过竞赛推动透明、可信和可解释的AI系统开发。

Method: 竞赛要求参赛队伍构建能生成清晰逻辑解释的高校问答系统，采用轻量级LLMs或LLM-符号混合模型。数据集基于逻辑模板构建并用Z3工具校验，经学生专家审查，确保贴合真实环境。通过明确评测流程，对模型输出和解释质量进行综合评价。

Result: XAI Challenge 2025竞赛取得了用轻量级大语言模型及混合神经-符号AI系统搭建可解释的问答系统的初步成果，并完善了数据集与评测体系。研究为未来XAI教育系统和相关竞赛提供了有价值的经验和见解。

Conclusion: 通过组织以教育场景和XAI为核心的竞赛，有效促进了神经网络与符号推理结合的系统开发，为提升AI系统的透明度、可验证性和高校教育中的实用性做出了探索性贡献。

Abstract: The growing integration of Artificial Intelligence (AI) into education has
intensified the need for transparency and interpretability. While hackathons
have long served as agile environments for rapid AI prototyping, few have
directly addressed eXplainable AI (XAI) in real-world educational contexts.
This paper presents a comprehensive analysis of the XAI Challenge 2025, a
hackathon-style competition jointly organized by Ho Chi Minh City University of
Technology (HCMUT) and the International Workshop on Trustworthiness and
Reliability in Neurosymbolic AI (TRNS-AI), held as part of the International
Joint Conference on Neural Networks (IJCNN 2025). The challenge tasked
participants with building Question-Answering (QA) systems capable of answering
student queries about university policies while generating clear, logic-based
natural language explanations. To promote transparency and trustworthiness,
solutions were required to use lightweight Large Language Models (LLMs) or
hybrid LLM-symbolic systems. A high-quality dataset was provided, constructed
via logic-based templates with Z3 validation and refined through expert student
review to ensure alignment with real-world academic scenarios. We describe the
challenge's motivation, structure, dataset construction, and evaluation
protocol. Situating the competition within the broader evolution of AI
hackathons, we argue that it represents a novel effort to bridge LLMs and
symbolic reasoning in service of explainability. Our findings offer actionable
insights for future XAI-centered educational systems and competitive research
initiatives.

</details>


### [27] [Merge-based syntax is mediated by distinct neurocognitive mechanisms: A clustering analysis of comprehension abilities in 84,000 individuals with language deficits across nine languages](https://arxiv.org/abs/2508.02885)
*Elliot Murphy,Rohan Venkatesh,Edward Khokhlovich,Andrey Vyshedskiy*

Main category: cs.CL

TL;DR: 本研究系统分析了人类对由Merge操作生成的不同语法复杂度句子的理解，发现三种结构类型背后可能有不同的认知机制支持，说明人类语法处理并非完全依赖单一突现的Merge机制，而是在神经认知上存在功能分化。


<details>
  <summary>Details</summary>
Motivation: 探索句法核心操作Merge在认知神经层面的基础，对不同结构类型的理解是否由统一或分离的机制支持，以及这些机制的发展和损伤敏感性。

Method: 系统性地调查参与者对包含不同句法复杂度的句子的理解能力，通过聚类分析识别不同的行为表现结构类型。

Result: 聚类分析揭示了三种不同的结构类型，分别对应于简单命令句、形容词与名词结合、名词与空间介词结合，这些类型可能在发育阶段上有所差异并受选择性损伤影响。

Conclusion: 尽管基于Merge的句法结构可能在进化中突现，但不同类型的Merge基体实际由不同的认知机制支持，并可能在发展阶段上有不同的表现及易损性。

Abstract: In the modern language sciences, the core computational operation of syntax,
'Merge', is defined as an operation that combines two linguistic units (e.g.,
'brown', 'cat') to form a categorized structure ('brown cat', a Noun Phrase).
This can then be further combined with additional linguistic units based on
this categorial information, respecting non-associativity such that abstract
grouping is respected. Some linguists have embraced the view that Merge is an
elementary, indivisible operation that emerged in a single evolutionary step.
From a neurocognitive standpoint, different mental objects constructed by Merge
may be supported by distinct mechanisms: (1) simple command constructions
(e.g., "eat apples"); (2) the merging of adjectives and nouns ("red boat"); and
(3) the merging of nouns with spatial prepositions ("laptop behind the sofa").
Here, we systematically investigate participants' comprehension of sentences
with increasing levels of syntactic complexity. Clustering analyses revealed
behavioral evidence for three distinct structural types, which we discuss as
potentially emerging at different developmental stages and subject to selective
impairment. While a Merge-based syntax may still have emerged suddenly in
evolutionary time, responsible for the structured symbolic turn our species
took, different cognitive mechanisms seem to underwrite the processing of
various types of Merge-based objects.

</details>


### [28] [Coherent Multimodal Reasoning with Iterative Self-Evaluation for Vision-Language Models](https://arxiv.org/abs/2508.02886)
*Wenjie Luo,Ruocheng Li,Shanshan Zhu,Julian Perry*

Main category: cs.CL

TL;DR: CMRF通过模块化分解、上下文推理与逻辑一致性评估，以及迭代优化，极大提升了视觉-语言模型在跨模态复杂推理任务上的表现，并刷新了开源模型的准确率纪录。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLMs）和视觉-语言模型（LVLMs）在复杂、多步骤、跨模态常识推理任务上表现不佳，缺乏“深度推理”能力，更容易依赖表面关联而非深层逻辑推理。如何让LVLMs进行更像人类的逻辑和常识推理，是该研究希望解决的问题。

Method: 提出了一种新的多模态推理框架（CMRF），包括三个核心模块：推理分解单元（RDU）将复杂问题拆分为子问题；上下文推理引擎（CIE）负责上下文推理；连贯性评估模块（CAM）评估逻辑一致性和置信度。同时引入自适应迭代优化策略，仿照人类步骤推理、纠错和自我完善的过程。该框架基于LLaVA-1.6-34B模型，训练在新构建的MDAR数据集上。

Result: CMRF在多个权威视觉-语言推理基准测试（VCR, A-OKVQA, DailyLife-MRC）上表现优异，平均准确率达到69.4%，比最优开源基线高2.4个百分点，尤其在复杂推理场景表现突出。消融实验和人工评估均验证了各模块作用和迭代优化在提升推理连贯性与准确性上的决定性贡献。

Conclusion: CMRF框架有效提升了LVLM的常识推理能力，尤其是在多步骤、复杂跨模态场景下，通过模块化和迭代自我优化能取得更高准确性和连贯性的推理结果。

Abstract: Despite significant advancements, current large language models (LLMs) and
vision-language models (LVLMs) continue to struggle with complex, multi-step,
cross-modal common sense reasoning tasks, often exhibiting a lack of
"deliberative thinking." They tend to rely on superficial associations rather
than deep, chained inference, particularly when integrating visual information
with abstract concepts. To address this, we propose the Coherent Multimodal
Reasoning Framework (CMRF), a novel approach that enhances LVLMs' common sense
reasoning capabilities through an iterative, self-evaluating inference
mechanism. CMRF mimics human problem-solving by decomposing complex queries,
generating step-by-step inferences, and self-correcting errors. Our framework
integrates three key modules: a Reasoning Decomposition Unit (RDU) for breaking
down problems into sub-questions, a Contextual Inference Engine (CIE) for
contextual inference, and a Coherence Assessment Module (CAM) for evaluating
logical consistency and confidence. Coupled with an Adaptive Iterative
Refinement strategy, CMRF systematically refines its reasoning paths. Built
upon LLaVA-1.6-34B and trained on a novel Multimodal Daily Activity Reasoning
(MDAR) dataset, CMRF achieves state-of-the-art performance among open-source
LVLMs on challenging benchmarks like VCR, A-OKVQA, and DailyLife-MRC. It
attains an average accuracy of 69.4%, surpassing the best open-source baseline
by +2.4 percentage points, with particular strength in complex reasoning
scenarios. Extensive ablation studies and human evaluations confirm the
critical contributions of each module and the effectiveness of iterative
refinement in fostering more coherent and accurate reasoning.

</details>


### [29] [SLIM-LLMs: Modeling of Style-Sensory Language RelationshipsThrough Low-Dimensional Representations](https://arxiv.org/abs/2508.02901)
*Osama Khalid,Sanvesh Srivastava,Padmini Srinivasan*

Main category: cs.CL

TL;DR: 通过创新的降秩岭回归和精简文体模型，论文证明低维文体特征即可有效预测文本中的感官语言，大大降低模型复杂度和解释难度。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索描述感官体验的感官语言与传统文体特征（如LIWC量表测量的特征）之间的关系，以便更高效地建模和预测文本中的感官信息。

Method: 采用新颖的降秩岭回归（Reduced-Rank Ridge Regression, R4）方法，分析LIWC特征在低维潜在空间内对感官语言的预测力，并提出了建模非线性风格维度关系的SLIM-LLMs（Stylistically Lean Interpretable Models）。在五种文本体裁上进行了评估对比。

Result: 发现LIWC特征的低维潜在表示（r=24）在感官语言预测方面表现出色，与使用全部特征（r=74）相比效果接近。SLIM-LLMs在参数减少高达80%的情况下，性能与全量语言模型相当。

Conclusion: 低维度的风格特征在感官语言建模中足够有效，可在大幅减少模型规模和参数的同时保持对感官语言的预测能力，提升了模型的解释性与效率。

Abstract: Sensorial language -- the language connected to our senses including vision,
sound, touch, taste, smell, and interoception, plays a fundamental role in how
we communicate experiences and perceptions. We explore the relationship between
sensorial language and traditional stylistic features, like those measured by
LIWC, using a novel Reduced-Rank Ridge Regression (R4) approach. We demonstrate
that low-dimensional latent representations of LIWC features r = 24 effectively
capture stylistic information for sensorial language prediction compared to the
full feature set (r = 74). We introduce Stylometrically Lean Interpretable
Models (SLIM-LLMs), which model non-linear relationships between these style
dimensions. Evaluated across five genres, SLIM-LLMs with low-rank LIWC features
match the performance of full-scale language models while reducing parameters
by up to 80%.

</details>


### [30] [Can LLMs Generate High-Quality Task-Specific Conversations?](https://arxiv.org/abs/2508.02931)
*Shengqi Li,Amarnath Gupta*

Main category: cs.CL

TL;DR: 该文提出参数化框架控制大模型对话质量，实验证明有效，对多领域应用有促进作用。


<details>
  <summary>Details</summary>
Motivation: 当前对话生成存在主题连贯性、知识推进、角色一致性和控制粒度等挑战，缺乏标准化高效质量控制手段。

Method: 提出参数化框架，通过实验检验九个关键参数对多维对话属性的控制效果，使用先进的大语言模型进行评估。

Result: 参数控制能够产生统计显著的对话属性差异，成功改善了对话的多项质量指标。

Conclusion: 参数化控制对对话生成质量有显著影响，为大模型对话质量控制提供了标准化方法，具有广泛应用前景。

Abstract: This paper introduces a parameterization framework for controlling
conversation quality in large language models. We explore nine key parameters
across six dimensions that enable precise specification of dialogue properties.
Through experiments with state-of-the-art LLMs, we demonstrate that
parameter-based control produces statistically significant differences in
generated conversation properties. Our approach addresses challenges in
conversation generation, including topic coherence, knowledge progression,
character consistency, and control granularity. The framework provides a
standardized method for conversation quality control with applications in
education, therapy, customer service, and entertainment. Future work will focus
on implementing additional parameters through architectural modifications and
developing benchmark datasets for evaluation.

</details>


### [31] [CoCoTen: Detecting Adversarial Inputs to Large Language Models through Latent Space Features of Contextual Co-occurrence Tensors](https://arxiv.org/abs/2508.02997)
*Sri Durga Sai Sowmya Kadali,Evangelos E. Papalexakis*

Main category: cs.CL

TL;DR: 本论文提出了一种基于上下文共现矩阵的检测方法，能高效识别LLM的对抗与jailbreak提示，对数据稀缺场景尤为有效，且运行速度大幅快于同类方法。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在各类应用广泛部署，但因其复杂性和难以理解性，容易受到攻击（如jailbreak）并输出有害内容，因此急需高效的检测方法保障其安全性。

Method: 该论文提出了一种利用Contextual Co-occurrence Matrix（上下文共现矩阵）和其潜在空间特性的方法，结合张量分析，来检测针对大语言模型的对抗性和jailbreak提示。

Result: 所提出的方法在仅用0.5%标注数据的情况下，F1分数达到0.83，较基线方法有96.6%的提升，同时检测速度提升2.3到128.4倍。

Conclusion: 实验结果证明了该方法在少量标注数据条件下也能实现优异的检测表现，并且极大加速了检测过程，公开实现代码有助于进一步研究和复现。

Abstract: The widespread use of Large Language Models (LLMs) in many applications marks
a significant advance in research and practice. However, their complexity and
hard-to-understand nature make them vulnerable to attacks, especially
jailbreaks designed to produce harmful responses. To counter these threats,
developing strong detection methods is essential for the safe and reliable use
of LLMs. This paper studies this detection problem using the Contextual
Co-occurrence Matrix, a structure recognized for its efficacy in data-scarce
environments. We propose a novel method leveraging the latent space
characteristics of Contextual Co-occurrence Matrices and Tensors for the
effective identification of adversarial and jailbreak prompts. Our evaluations
show that this approach achieves a notable F1 score of 0.83 using only 0.5% of
labeled prompts, which is a 96.6% improvement over baselines. This result
highlights the strength of our learned patterns, especially when labeled data
is scarce. Our method is also significantly faster, speedup ranging from 2.3 to
128.4 times compared to the baseline models. To support future research and
reproducibility, we have made our implementation publicly available.

</details>


### [32] [When Algorithms Meet Artists: Topic Modeling the AI-Art Debate, 2013-2025](https://arxiv.org/abs/2508.03037)
*Ariya Mukherjee-Gandhi,Oliver Muellerklein*

Main category: cs.CL

TL;DR: 该研究通过对过去十二年AI生成艺术相关英文话语进行系统分析，发现主流媒体常用技术语言排斥了艺术家关注的议题，倡导未来需构建更加透明、包容艺术家视角的研究方法。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能日益深刻地影响艺术创作以及人类表达的新方式，艺术家的生计受到直接冲击，他们对于同意权、透明度及创意劳动未来表达出强烈担忧。但在主流的公共和学术话语中，艺术家的声音往往被边缘化。该研究旨在分析这一现象背后的话语偏移。

Method: 本文采用可复现的方法，收集了2013年至2025年间439篇与AI生成艺术相关、英文的500字片段，来源涵盖评论文章、新闻报道、博客、法律文件和口语转录。利用BERTopic主题建模技术进行聚类分析，提取话语中的关键主题。

Result: 共发现五个稳定的话题聚类，揭示了艺术家观点与主流媒体叙事之间的错位，并指出技术术语的频繁使用形成了一定的话语门槛，常常忽视或边缘化艺术家最关切的问题。

Conclusion: 提出了一套基于BERTopic的多模态分析基线，强调今后在AI与创意领域需加强透明化，充分吸纳艺术家真实声音和诉求。

Abstract: As generative AI continues to reshape artistic production and alternate modes
of human expression, artists whose livelihoods are most directly affected have
raised urgent concerns about consent, transparency, and the future of creative
labor. However, the voices of artists are often marginalized in dominant public
and scholarly discourse. This study presents a twelve-year analysis, from 2013
to 2025, of English-language discourse surrounding AI-generated art. It draws
from 439 curated 500-word excerpts sampled from opinion articles, news reports,
blogs, legal filings, and spoken-word transcripts. Through a reproducible
methodology, we identify five stable thematic clusters and uncover a
misalignment between artists' perceptions and prevailing media narratives. Our
findings highlight how the use of technical jargon can function as a subtle
form of gatekeeping, often sidelining the very issues artists deem most urgent.
Our work provides a BERTopic-based methodology and a multimodal baseline for
future research, alongside a clear call for deeper, transparency-driven
engagement with artist perspectives in the evolving AI-creative landscape.

</details>


### [33] [Privacy-Aware Decoding: Mitigating Privacy Leakage of Large Language Models in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.03098)
*Haoran Wang,Xiongxiao Xu,Baixiang Huang,Kai Shu*

Main category: cs.CL

TL;DR: 本论文提出了一种新方法（PAD）来提升RAG系统中私密数据的安全性，通过在生成阶段对高风险token加入噪声，从而减少信息泄露，同时保证输出质量。


<details>
  <summary>Details</summary>
Motivation: 尽管RAG能提升大语言模型的事实性，但当检索的数据涉及隐私时，生成内容容易泄露敏感信息，现有方法要么重训练、要么效率低或适用范围有限，因此需要一个高效、模型无关且可泛化的隐私保护方案。

Method: 作者提出了隐私感知解码（PAD）方法：在生成阶段，对高敏感性token基于置信度筛查后，施加校准的高斯噪声，同时利用有效的敏感性估计和上下文相关的噪声调整，以平衡隐私与生成质量，再用RDP会计机制跟踪累计隐私损失，从而为每一次生成提供明确的差分隐私保证。此方法无需重新训练或数据过滤，解码阶段即可实施，计算开销低。

Result: 实验结果表明，PAD在三个真实数据集上显著减少了私密数据泄露（比现有方法更优），同时保证了生成结果的有用性，验证了其实用性和先进性。

Conclusion: PAD显著降低了RAG系统对私密信息的泄露风险，并优于现有的检索型或后处理型隐私保护方法，同时保留了回答的实用性。

Abstract: Retrieval-Augmented Generation (RAG) enhances the factual accuracy of large
language models (LLMs) by conditioning outputs on external knowledge sources.
However, when retrieval involves private or sensitive data, RAG systems are
susceptible to extraction attacks that can leak confidential information
through generated responses. We propose Privacy-Aware Decoding (PAD), a
lightweight, inference-time defense that adaptively injects calibrated Gaussian
noise into token logits during generation. PAD integrates confidence-based
screening to selectively protect high-risk tokens, efficient sensitivity
estimation to minimize unnecessary noise, and context-aware noise calibration
to balance privacy with generation quality. A \renyi Differential Privacy (RDP)
accountant rigorously tracks cumulative privacy loss, enabling explicit
per-response $(\varepsilon, \delta)$-DP guarantees for sensitive outputs.
Unlike prior approaches requiring retraining or corpus-level filtering, PAD is
model-agnostic and operates entirely at decoding time with minimal
computational overhead. Experiments on three real-world datasets demonstrate
that PAD substantially reduces private information leakage while preserving
response utility, outperforming existing retrieval- and post-processing-based
defenses. Our work takes an important step toward mitigating privacy risks in
RAG via decoding strategies, paving the way for universal and scalable privacy
solutions in sensitive domains. Our code is available:
https://github.com/wang2226/PAD.

</details>


### [34] [More Than a Score: Probing the Impact of Prompt Specificity on LLM Code Generation](https://arxiv.org/abs/2508.03678)
*Yangtian Zi,Harshitha Menon,Arjun Guha*

Main category: cs.CL

TL;DR: 本文提出对提示细节从低到高排序的评测方法，发现大模型在代码生成任务中提示越详细，表现提升越大。边界处理、I/O规范及分步提示尤其关键。


<details>
  <summary>Details</summary>
Motivation: 当前LLM虽能在一般代码生成任务中表现优异，但在专业领域存在明显差距。本文关注这一差距是否由模型知识局限还是提示细节不足导致，旨在厘清不同提示细化程度对模型表现的影响。

Method: 提出了一种新的评测方法PartialOrderEval，可对各种代码生成基准测试集构建从最简单到最详细的提示序列。通过在人类评测集(HumanEval)和ParEval（包含串行及OpenMP子集）上，采用Llama-3.x和Qwen2.5-Coder等模型进行实验，系统测量了代码生成准确率随提示细致程度的变化。

Result: 结果显示，模型在处理不同任务时对提示敏感性存在差异，详细的I/O规范、边界情况的处理和逐步分解是提升提示有效性的主要因素。

Conclusion: 研究表明，大型语言模型在面对不同细化程度的提示时，其表现会有显著变化，提示细节的丰富程度是影响代码生成准确性的关键因素。

Abstract: State-of-the-art Large Language Models (LLMs) achieve high pass@1 on general
benchmarks like HumanEval but underperform on specialized suites such as
ParEval. Is this due to LLMs missing domain knowledge or insufficient prompt
detail is given? To answer this, we introduce PartialOrderEval, which augments
any code generation benchmark with a partial order of prompts from minimal to
maximally detailed. Applying it to HumanEval and both serial and OpenMP subsets
of ParEval, we measure how pass@1 scales with prompt specificity. Our
experiments with Llama-3.x and Qwen2.5-Coder demonstrate varying degrees of
prompt sensitivity across different tasks, and a qualitative analysis
highlights explicit I/O specifications, edge-case handling, and stepwise
breakdowns as the key drivers of prompt detail improvement.

</details>


### [35] [Token-Level Precise Attack on RAG: Searching for the Best Alternatives to Mislead Generation](https://arxiv.org/abs/2508.03110)
*Zizhong Li,Haopeng Zhang,Jiawei Zhang*

Main category: cs.CL

TL;DR: 本文提出了针对 RAG 系统的新型 token 级攻击（TPARAG），在检索和生成两个环节均有效，优于前人方法，强调了现有 RAG 系统的安全隐患并为防御提供了启示。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然在知识密集型任务上表现出色，但仍面临幻觉和知识过时等问题。RAG 框架通过引入外部知识增强了 LLM 的能力，但引入了新的安全风险：外部数据库中的恶意内容可能被检索并操控模型输出。目前对 RAG 系统的攻击研究存在局限，特别是在黑盒场景下攻击效果不理想。

Method: 本文提出了一种名为 Token-level Precise Attack on the RAG (TPARAG) 的新型攻击框架。该方法利用轻量级白盒 LLM 作为攻击者，在 token 级别生成并迭代优化恶意段落，同时兼顾可检索性和生成阶段的高攻击成功率，适用于白盒和黑盒 RAG 系统。

Result: TPARAG 在开放域问答数据集上的大量实验显示，其对检索阶段和端到端攻击的有效性均优于现有方法。

Conclusion: TPARAG 揭示了 RAG 流水线中的重要安全漏洞，并为提升 RAG 系统的安全性和鲁棒性提供了新见解。

Abstract: While large language models (LLMs) have achieved remarkable success in
providing trustworthy responses for knowledge-intensive tasks, they still face
critical limitations such as hallucinations and outdated knowledge. To address
these issues, the retrieval-augmented generation (RAG) framework enhances LLMs
with access to external knowledge via a retriever, enabling more accurate and
real-time outputs about the latest events. However, this integration brings new
security vulnerabilities: the risk that malicious content in the external
database can be retrieved and used to manipulate model outputs. Although prior
work has explored attacks on RAG systems, existing approaches either rely
heavily on access to the retriever or fail to jointly consider both retrieval
and generation stages, limiting their effectiveness, particularly in black-box
scenarios. To overcome these limitations, we propose Token-level Precise Attack
on the RAG (TPARAG), a novel framework that targets both white-box and
black-box RAG systems. TPARAG leverages a lightweight white-box LLM as an
attacker to generate and iteratively optimize malicious passages at the token
level, ensuring both retrievability and high attack success in generation.
Extensive experiments on open-domain QA datasets demonstrate that TPARAG
consistently outperforms previous approaches in retrieval-stage and end-to-end
attack effectiveness. These results further reveal critical vulnerabilities in
RAG pipelines and offer new insights into improving their robustness.

</details>


### [36] [Cross-lingual Opinions and Emotions Mining in Comparable Documents](https://arxiv.org/abs/2508.03112)
*Motaz Saad,David Langlois,Kamel Smaili*

Main category: cs.CL

TL;DR: 本研究提出了一种跨语言（英文-阿拉伯文）比较主题文本情感与情绪表达差异的方法，避免了依赖机器翻译，并构建了双语情绪词典。实验证明同一新闻机构的不同语言报道情感/情绪更一致，不同机构的报道差异更大，该方法可用于其他语言对。


<details>
  <summary>Details</summary>
Motivation: 理解不同语言中相同主题的文本在情感和情绪表达方面的差异，尤其关注英文和阿拉伯文之间的可比文本，丰富跨语言比较、媒体报道倾向性分析等相关研究领域。

Method: 首先为英阿可比文本手动注释情感和情绪标签。采用无需机器翻译的跨语言方法对文本进行主观/客观情感类别标注。为标注情绪（愤怒、厌恶、恐惧、快乐、悲伤、惊讶），手动将英文WordNet-Affect词典翻译为阿拉伯语，构建双语情绪词典，并用其标注语料库。最后应用统计方法衡量各对源-目标文档在情感与情绪上的一致性。

Result: 结果显示，当文档来自同一新闻机构时，情感和情绪标注有较高的一致性；而当文档来自不同新闻机构时，这种一致性较低，存在更多差异。提出的方法具有语言无关性，可推广到其他语言对。

Conclusion: 本文提出的跨语言、可推广的方法可有效对不同语言同主题文本的情感和情绪进行对齐和比较，发现了新闻来源对情感/情绪表达一致性的显著影响。

Abstract: Comparable texts are topic-aligned documents in multiple languages that are
not direct translations. They are valuable for understanding how a topic is
discussed across languages. This research studies differences in sentiments and
emotions across English-Arabic comparable documents. First, texts are annotated
with sentiment and emotion labels. We apply a cross-lingual method to label
documents with opinion classes (subjective/objective), avoiding reliance on
machine translation. To annotate with emotions (anger, disgust, fear, joy,
sadness, surprise), we manually translate the English WordNet-Affect (WNA)
lexicon into Arabic, creating bilingual emotion lexicons used to label the
comparable corpora. We then apply a statistical measure to assess the agreement
of sentiments and emotions in each source-target document pair. This comparison
is especially relevant when the documents originate from different sources. To
our knowledge, this aspect has not been explored in prior literature. Our study
includes English-Arabic document pairs from Euronews, BBC, and Al-Jazeera
(JSC). Results show that sentiment and emotion annotations align when articles
come from the same news agency and diverge when they come from different ones.
The proposed method is language-independent and generalizable to other language
pairs.

</details>


### [37] [Long Story Generation via Knowledge Graph and Literary Theory](https://arxiv.org/abs/2508.03137)
*Ge Shi,Kaiyu Huang,Guochen Feng*

Main category: cs.CL

TL;DR: 作者提出结合大模型与多智能体记忆、互动反馈与知识图谱的新架构，系统性解决了传统长篇故事生成的主题漂移和情节单调等核心难题，效果显著提升。


<details>
  <summary>Details</summary>
Motivation: 以往长篇故事自动生成方法（主要通过提纲分阶段生成）存在严重的主题漂移以及情节单调、逻辑不连贯等问题，导致生成的故事缺乏吸引力。作者提出改进方案，希望生成更高质量的长故事。

Method: 提出多智能体故事生成结构，使用大语言模型（LLM）为智能体核心，并引入两层记忆存储（长期与短期记忆）防止主题漂移。同时，基于文学叙事理论设计故事主题障碍框架来构建更精彩的情节，引入不确定因素与评价标准；通过知识图谱增强故事内容；在生成过程中模拟“作家-读者”对话反馈，不断修正文本以保证一致性和逻辑性。

Result: 实验表明，该方法能生成逻辑更连贯、内容更吸引人的高质量长篇故事，优于以往主要基于提纲分阶段生成的方法。

Conclusion: 多智能体结构结合记忆存储、叙述理论和互动反馈机制，有效改善了长篇故事自动生成的主题一致性、逻辑连贯性及趣味性。

Abstract: The generation of a long story consisting of several thousand words is a
sub-task in the field of long text generation~(LTG). Previous research has
addressed this challenge through outline-based generation, which employs a
multi-stage method for generating outlines into stories. However, this approach
suffers from two common issues: almost inevitable theme drift caused by the
loss of memory of previous outlines, and tedious plots with incoherent logic
that are less appealing to human readers.
  In this paper, we propose the multi-agent Story Generator structure to
improve the multi-stage method, using large language models~(LLMs) as the core
components of agents. To avoid theme drift, we introduce a memory storage model
comprising two components: a long-term memory storage that identifies the most
important memories, thereby preventing theme drift; and a short-term memory
storage that retains the latest outlines from each generation round. To
incorporate engaging elements into the story, we design a story theme obstacle
framework based on literary narratology theory that introduces uncertain
factors and evaluation criteria to generate outline. This framework calculates
the similarity of the former storyline and enhances the appeal of the story by
building a knowledge graph and integrating new node content. Additionally, we
establish a multi-agent interaction stage to simulate writer-reader interaction
through dialogue and revise the story text according to feedback, to ensure it
remains consistent and logical. Evaluations against previous methods
demonstrate that our approach can generate higher-quality long stories.

</details>


### [38] [RCP-Merging: Merging Long Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning Capability as Prior](https://arxiv.org/abs/2508.03140)
*Junyao Yang,Jianwei Wang,Huiping Zhuang,Cen Chen,Ziqian Zeng*

Main category: cs.CL

TL;DR: 提出RCP-Merging框架，将长链推理LLM与领域特定LLM有效整合，在保证推理能力的情况下，领域任务表现大幅提升。


<details>
  <summary>Details</summary>
Motivation: 目前拥有强长链式思维能力（CoT）的LLM模型擅长复杂多步推理任务，而具备领域知识的LLM也非常重要。直接训练具备两种能力的新模型计算及数据成本较高，因此模型合并是一种资源高效的途径，但现有合并方法常常导致推理能力的退化甚至模型输出混乱。

Method: 提出RCP-Merging方法，将长链式思维模型与领域特定模型进行整合，利用推理能力指标保护原有CoT能力的重要权重，选择性地结合领域特定权重，并将推理模型参数作为基础前置。

Result: 在Qwen2.5-7B、Llama3.1-8B和Qwen2.5-1.5B等模型上，在生物医疗和金融领域进行了实验，RCP-Merging方法相比现有先进方法，提升了领域任务表现9.5%和9.2%，同时基本不损害原有长链推理能力。

Conclusion: RCP-Merging是一种有效整合长链推理能力与领域知识的方法，能够在保障推理能力的前提下显著提升领域任务表现。

Abstract: Large Language Models (LLMs) with long chain-of-thought (CoT) capability,
termed Reasoning Models, demonstrate superior intricate problem-solving
abilities through multi-step long CoT reasoning. To create a dual-capability
model with long CoT capability and domain-specific knowledge without
substantial computational and data costs, model merging emerges as a highly
resource-efficient method. However, significant challenges lie in merging
domain-specific LLMs with long CoT ones since nowadays merging methods suffer
from reasoning capability degradation, even gibberish output and output
collapse. To overcome this, we introduce RCP-Merging: Merging Long
Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning
Capability as Prior, a novel merging framework designed to integrate
domain-specific LLMs with long CoT capability, meanwhile maintaining model
performance in the original domain. Treating reasoning model weights as
foundational prior, our method utilizes a reasoning capability indicator to
preserve core long CoT capability model weights while selectively merging
essential domain-specific weights. We conducted extensive experiments on
Qwen2.5-7B, Llama3.1-8B, and Qwen2.5-1.5B models in BioMedicine and Finance
domains. Our results show that RCP-Merging successfully merges a reasoning
model with domain-specific ones, improving domain task performance by 9.5% and
9.2% over state-of-the-art methods, without significantly harming the original
long CoT reasoning capability.

</details>


### [39] [Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following](https://arxiv.org/abs/2508.03178)
*Chenyang Wang,Liang Wen,Shousheng Jia,Xiangzheng Zhang,Liang Xu*

Main category: cs.CL

TL;DR: 本文提出结合预演、自检、高质量数据筛选及新型训练策略（Entropy-SFT+TEA-RL）的方法，显著提升大模型复杂指令的遵循效果，实验优于主流开源和闭源大模型。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在数学、编码等推理任务上表现卓越，但在复杂指令的遵循方面仍有不足。论文旨在分析与提升大模型的指令执行准确性。

Method: 提出新框架，包含预演（preview）和自检（self-checking），设计复杂约束指令并分类筛选为hard、easy、pass三种类型，通过拒绝采样选取高质量数据集，冷启动模型。之后结合信息熵保持的有监督微调（Entropy-SFT）和基于密集奖励的token级熵自适应强化学习（TEA-RL），鼓励模型形成规范化推理机制。

Result: 实验显示，该方法在各尺度模型上都实现了显著提升。Light-IF-32B模型超越了如DeepSeek-R1等更大开源模型及闭源的Doubao-1.6模型。

Conclusion: 加强推理环节中的自检机制及针对复杂指令的严格训练，能够大幅提升大模型对指令的遵循能力，方法在标准基准上取得了领先表现。

Abstract: While advancements in the reasoning abilities of LLMs have significantly
enhanced their performance in solving mathematical problems, coding tasks, and
general puzzles, their effectiveness in accurately adhering to instructions
remains inconsistent, particularly with more complex directives. Our
investigation identifies lazy reasoning during the thinking stage as the
primary factor contributing to poor instruction adherence. To mitigate this
issue, we propose a comprehensive framework designed to enable rigorous
reasoning processes involving preview and self-checking, essential for
satisfying strict instruction constraints. Specifically, we first generate
instructions with complex constraints and apply a filtering process to obtain
valid prompts, resulting in three distinct prompt datasets categorized as hard,
easy, and pass. Then, we employ rejection sampling on the pass prompts to
curate a small yet high-quality dataset, enabling a cold-start initialization
of the model and facilitating its adaptation to effective reasoning patterns.
Subsequently, we employ an entropy-preserving supervised fine-tuning
(Entropy-SFT) strategy coupled with token-wise entropy-adaptive (TEA-RL)
reinforcement learning guided by rule-based dense rewards. This approach
encourages the model to transform its reasoning mechanism, ultimately fostering
generalizable reasoning abilities that encompass preview and self-checking.
Extensive experiments conducted on instruction-following benchmarks demonstrate
remarkable performance improvements across various model scales. Notably, our
Light-IF-32B model surpasses both larger open-source models such as DeepSeek-R1
and closed-source models like Doubao-1.6.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [40] [Temporal Exploration of Random Spanning Tree Models](https://arxiv.org/abs/2508.03361)
*Samuel Baguley,Andreas Göbel,Nicolas Klodt,George Skretas,John Sylvester,Viktor Zamaraev*

Main category: cs.DM

TL;DR: 本文探索了时变图探索问题（TEXP）在随机生成的树时变图（RST模型）中的表现，给出了紧致的上下界，展示了随机情景下与对抗性情景在探索时间上的根本差异。


<details>
  <summary>Details</summary>
Motivation: 当前TEXP问题在部分基本时变图类别上已知的上下界相差极大，且缺乏对哪些图属性决定其探索难度的本质理解。文章引入随机模型以揭示图结构特性对探索难度的影响，推动时变图理论发展。

Method: 作者提出了RST（随机生成树）模型，将时变图表示为一系列独立的树样本。针对该模型，理论分析并推导了探索所需最短步数的上下界（高概率下）。方法上，主要使用概率、组合及图论分析技术。

Result: 在随机生成的树时变图（RST模型）上，探索时间w.h.p.为O(n^{3/2})，且达到该下界；若所有树为某固定图的子图，则探索时间为O(m)。这些结果缩小了以往在某些类别中的上下界间隙，并展示了与对抗性模型在探索复杂度上的差异。

Conclusion: 研究表明，在任意RST模型下，高概率下可在O(n^{3/2})时间完成探索，这一结果在常数因子范围内是最优的；若所有树均为某个固定m条边图的子图，则探索时间可降至O(m)。这为TEXP在时变树的随机模型下探索提供了理论基础与边界。

Abstract: The Temporal Graph Exploration problem (TEXP) takes as input a temporal
graph, i.e., a sequence of graphs $(G_i)_{i\in \mathbb{N}}$ on the same vertex
set, and asks for a walk of shortest length visiting all vertices, where the
$i$-th step uses an edge from $G_i$. If each such $G_i$ is connected, then an
exploration of length $n^2$ exists, and this is known to be the best possible
up to a constant. More fine-grained lower and upper bounds have been obtained
for restricted temporal graph classes, however, for several fundamental
classes, a large gap persists between known bounds, and it remains unclear
which properties of a temporal graph make it inherently difficult to explore.
  Motivated by this limited understanding and the central role of the Temporal
Graph Exploration problem in temporal graph theory, we study the problem in a
randomised setting. We introduce the Random Spanning Tree (RST) model, which
consists of a set of $n$-vertex trees together with an arbitrary probability
distribution $\mu$ over this set. A random temporal graph generated by the RST
model is a sequence of independent samples drawn from $\mu$.
  We initiate a systematic study of the Temporal Graph Exploration problem in
such random temporal graphs and establish tight general bounds on exploration
time. Our first main result proves that any RST model can, with high
probability (w.h.p.), be explored in $O(n^{3/2})$ time, and we show that this
bound is tight up to a constant factor. This demonstrates a fundamental
difference between the adversarial and random settings. Our second main result
shows that if all trees of an RST are subgraphs of a fixed graph with $m$ edges
then, w.h.p.\ , it can be explored in $O(m)$ time.

</details>


### [41] [Adjacent vertex distinguishing total coloring of 3-degenerate graphs](https://arxiv.org/abs/2508.03549)
*Diptimaya Behera,Mathew C. Francis,Sreejith K. Pallathumadam*

Main category: cs.DM

TL;DR: 本文关注图论中的总着色问题，特别是“邻点可区分总着色”（AVD总着色）猜想。该猜想认为对于任意图$G$，存在使用不超过最大度数加三（$
Delta(G)+3$）种颜色的AVD总着色。本文的主要贡献是证实了该猜想对于3-退化图成立。


<details>
  <summary>Details</summary>
Motivation: AVD总着色猜想是图着色理论中的重要未解问题，其推广了经典的顶点着色和边着色理论，解决它可以深化对图着色复杂性和分辨性的理解。此前，仅对小族类图（如2-退化图）成立，作者希望推动该猜想在更广泛图类（3-退化图）上的证明。

Method: 作者基于已有的2-退化图结果，运用图的结构性质和递归方法，将证明技巧推广到3-退化图。方法涉及对图的分解、子图着色方案的构造，以及归纳证明。

Result: 论文成功地验证了3-退化图满足AVD总着色猜想。这一结果推进了总着色猜想研究的前沿，为进一步解决一般图的AVD总着色猜想提供了理论基础。

Conclusion: 论文证明了对所有3-退化图，AVD总着色猜想成立，即这些图都最多使用$\Delta(G)+3$种颜色实现邻点可区分总着色。

Abstract: A total coloring of a simple undirected graph $G$ is an assignment of colors
to its vertices and edges such that the colors given to the vertices form a
proper vertex coloring, the colors given to the edges form a proper edge
coloring, and the color of every edge is different from that of its two
endpoints. That is, $\phi:V(G)\cup E(G)\rightarrow\mathbb{N}$ is a total
coloring of $G$ if $\phi(u)\neq\phi(v)$ and $\phi(uv)\neq\phi(u)$ for all
$uv\in E(G)$, and $\phi(uv)\neq\phi(uw)$ for any $u \in V(G)$ and distinct $v,w
\in N(u)$ (here, $N(u)$ denotes the set of neighbours of $u$). A total coloring
$\phi$ of a graph $G$ is said to be ``Adjacent Vertex Distinguishing'' (or AVD
for short) if for all $uv\in E(G)$, we have that $\phi(\{u\}\cup\{uw:w\in
N(u)\})\neq\phi(\{v\}\cup\{vw\colon w\in N(v)\})$. The AVD Total Coloring
Conjecture of Zhang, Chen, Li, Yao, Lu, and Wang (Science in China Series A:
Mathematics, 48(3):289--299, 2005) states that every graph $G$ has an AVD total
coloring using at most $\Delta(G)+3$ colors, where $\Delta(G)$ denotes the
maximum degree of $G$. For some $s\in\mathbb{N}$, a graph $G$ is said to be
$s$-degenerate if every subgraph of $G$ has minimum degree at most $s$. Miao,
Shi, Hu, and Luo (Discrete Mathematics, 339(10):2446--2449, 2016) showed that
the AVD Total Coloring Conjecture is true for 2-degenerate graphs. We verify
the conjecture for 3-degenerate graphs.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [42] [Learning Event-recording Automata Passively](https://arxiv.org/abs/2508.03627)
*Anirban Majumdar,Sayan Mukherjee,Jean-François Raskin*

Main category: cs.FL

TL;DR: 本文提出了一种通过状态合并算法，被称为LEAP，可以被动学习由Event-Recording Automata（ERA）所定义的定时语言，输入为正负样本的符号化定时词。


<details>
  <summary>Details</summary>
Motivation: 当前学习定时语言自动机存在挑战，尤其是被动学习（仅依靠样本而非查询）。提出此算法旨在高效、准确地学习ERA所描述的定时语言，提升自动机学习的能力和覆盖面。

Method: 算法基于状态合并技术，根据正负样本构建一个可能非确定性的ERA。同时，提出了一种基于SMT（可满足性模块理论）的实用方法解决状态合并的一致性问题。

Result: 证明了判定ERA两个状态在保持样本一致性的前提下是否能合并为NP完全问题，并提出了SMT解法。通过实验验证了算法的实用性和有效性。

Conclusion: 只要有合适的样本，本文算法能够推断出所有ERA可定义的语言。实验表明，该方法有效。

Abstract: This paper presents a state-merging algorithm for learning timed languages
definable by Event-Recording Automata (ERA) using positive and negative samples
in the form of symbolic timed words. Our algorithm, LEAP (Learning
Event-recording Automata Passively), constructs a possibly nondeterministic ERA
from such samples based on merging techniques. We prove that determining
whether two ERA states can be merged while preserving sample consistency is an
NP-complete problem, and address this with a practical SMT-based solution. Our
implementation demonstrates the algorithm's effectiveness through examples. We
also show that every ERA-definable language can be inferred using our algorithm
with a suitable sample.

</details>


### [43] [Design Support for Multitape Turing Machines](https://arxiv.org/abs/2508.03638)
*Marco T. Morazán,Oliwia Kempinski,Andrés M. Garced*

Main category: cs.FL

TL;DR: 本文提出了三种用于多带图灵机的可视化学习工具，并通过实证数据表明，这些工具显著提升了学生的理解和设计能力。


<details>
  <summary>Details</summary>
Motivation: 多带图灵机虽然是设计简化的抽象工具，但学生依然难以理解其操作语义以及何时接受或拒绝一个单词。已有的FSM编程语言的定义和执行支持仍不足以帮助理解。

Method: 开发了三种可视化工具：1）动态可视化工具模拟多带图灵机执行过程；2）静态可视化工具自动绘制多带图灵机的状态转移图；3）静态可视化工具自动绘制多带图灵机的计算图，并在课程中配合设计和实现练习加以应用。

Result: 工具得到了学生的积极反馈，认为它们对于理解和应用多带图灵机非常有帮助。

Conclusion: 三种可视化工具能有效帮助学生理解和掌握多带图灵机的设计与实现，对教学有积极作用。

Abstract: Many Formal Languages and Automata Theory courses introduce students to
Turing machine extensions. One of the most widely-used extensions endows Turing
machines with multiple tapes. Although multitape Turing machines are an
abstraction to simplify Turing machine design, students find them no less
challenging. To aid students in understanding these machines, the FSM
programming language provides support for their definition and execution. This,
however, has proven insufficient for many students to understand the
operational semantics of such machines and to understand why such machines
accept or reject a word. To address this problem, three visualization tools
have been developed. The first is a dynamic visualization tool that simulates
machine execution. The second is a static visualization tool that automatically
renders a graphic for a multitape Turing machine's transition diagram. The
third is a static visualization tool that automatically renders computation
graphs for multitape Turing machines. This article presents these tools and
illustrates how they are used to help students design and implement multitape
Turing machines. In addition, empirical data is presented that suggests these
tools are well-received and found useful by students.

</details>


### [44] [A Design Recipe and Recipe-Based Errors for Regular Expressions](https://arxiv.org/abs/2508.03639)
*Marco T. Morazán,Shamil Dzhatdoyev,Josephine Des Rosiers,Tijana Minić,Andrés M. Garced,David Anthony K. Fields*

Main category: cs.FL

TL;DR: 该文提出基于设计配方和友好错误信息的正则表达式设计支持系统，实验证明有助于学生学习和调试。


<details>
  <summary>Details</summary>
Motivation: 许多形式语言与自动机理论的学生在学习和设计正则表达式时，因流程不清晰和错误反馈不友好而遇到困难。作者希望通过明确的设计配方和友好错误提示改善学习体验和效果。

Method: 提出了一个用于正则表达式设计支持的全新框架，包括定制化错误信息系统和设计配方，以及针对单元测试的简写语法。系统能够在学生设计正则表达式过程中给出基于步骤的错误提示。

Result: 作者展示了此框架在课堂上的应用，并讨论了两次调试会话，表明系统能帮助学生定位和修正错误，提高学习正则表达式的效率与质量。还简要介绍了错误信息系统的实现。

Conclusion: 创新设计配方和定制化错误信息能显著提升正则表达式的学习过程，系统性支持和精确反馈帮助学生有效改错并提升理解。

Abstract: This article presents a novel framework to provide Formal Languages and
Automata Theory students design support for the development of regular
expressions. This framework includes a design recipe for regular expressions
and a customized error messaging system. The error messaging system produces
recipe-based errors that include the step of the design recipe not successfully
completed. Furthermore, the error messages follow the established practices of
being concise, succinct, jargon-free, and nonprescriptive. In addition, a
shorthand syntax developed for writing unit tests is described. The in-class
use of the design recipe is illustrated, two debugging sessions using the
described system are discussed, and the implementation of the error messaging
system is briefly sketched.

</details>


### [45] [Visual Execution and Validation of Finite-State Machines and Pushdown Automata](https://arxiv.org/abs/2508.03641)
*Marco T. Morazán,David Anthony K. Fields,Andrés M. Garced,Tijana Minić*

Main category: cs.FL

TL;DR: 通过引入两种动态可视化工具，极大提升了学生对非确定性自动机和下推自动机运行机制的理解与验证能力，尤其是对复杂计算路径和栈操作的掌握。


<details>
  <summary>Details</summary>
Motivation: 学生们在形式语言与自动机理论课程中，常常难以理解非确定性有限自动机和下推自动机的工作原理。主要困难在于他们大多习惯于设计和实现确定性程序，而对于自动机尤其是涉及栈操作的下推自动机，存在状态和栈值不同步的理解障碍。

Method: 作者开发了专用于自动机理论教学的领域特定编程语言FSM，并基于此实现了两种动态可视化工具，分别针对非确定性有限自动机和下推自动机，能够逐步呈现其所有计算情况，并支持状态属性可视化验证。

Result: 本文提出的两种动态可视化工具，能以逐步演示的方式，对于非确定性有限自动机和下推自动机进行所有可能计算路径的动态可视化，帮助学生和用户更好地理解这些自动机的操作语义和计算过程。此外，这些工具还辅助了自动机的验证过程，用户可通过可视化界面直观验证状态属性在状态转移过程中的保持情况。

Conclusion: 这两种可视化工具有效帮助学生深入理解非确定性自动机和下推自动机的运作机制，并为自动机理论课堂和相关应用提供了直观有效的实践支持。

Abstract: In Formal Languages and Automata Theory courses, students find understanding
nondeterministic finite-state and pushdown automata difficult. In many cases,
this means that it is challenging for them to comprehend the operational
semantics of such machines and, as a consequence, determine why a word is
accepted or rejected. This is not entirely surprising, because students are
mostly trained to design and implement deterministic programs. Comprehension of
pushdown automata is further complicated, because reasoning about the stack is
necessary. A common difficulty students face, for example, is understanding
that two different computations on the same word may reach the same state with
different stack values. To aid student understanding, we present two novel
dynamic visualization tools for FSM -- a domain-specific programming language
for the Automata Theory classroom -- to support the design of such machines.
These tools visualize all computations that may be performed, respectively, by
a nondeterministic finite-state machine or by a pushdown automata in a stepwise
manner. In addition, these tools aid the machine verification process by
allowing users to visually validate whether the properties a state represents
hold when a machine transitions into it.

</details>
