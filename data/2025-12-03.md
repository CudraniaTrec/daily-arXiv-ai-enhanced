<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.SE](#cs.SE) [Total: 9]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.CL](#cs.CL) [Total: 4]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Pushing Tensor Accelerators Beyond MatMul in a User-Schedulable Language](https://arxiv.org/abs/2512.02371)
*Yihong Zhang,Derek Gerstmann,Andrew Adams,Maaz Bin Safeer Ahmad*

Main category: cs.PL

TL;DR: 本文提出了一种编译器方法，显著简化了张量加速器的编程，并将其应用于图像处理等领域，实现了最高6.1倍的性能提升，拓展了加速器的使用场景。


<details>
  <summary>Details</summary>
Motivation: 张量加速器在现代CPU和GPU中的比重不断增加，但由于编程复杂，开发者主要依赖厂商提供的库，使用范围受到限制，仅限于面向传统机器学习和科学计算工作负载。

Method: 作者提出基于编译器的技术，利用Halide调度语法表达操作，并实现了基于等式饱和度（equality saturation）的灵活张量指令选择器，支持CPU和GPU上的张量加速器，与现有的调度操作兼容，方便开发者高效编写多样化加速器应用。

Result: 通过系统实现多种图像处理管线（如滤波、重采样和去噪），并与非加速基线进行对比，结果显示显著提速，如在Nvidia RTX 4070 GPU利用Tensor Cores对下采样例程加速6.1倍。

Conclusion: 张量加速器不仅适用于传统矩阵乘法与机器学习应用，借助本文提出的编译器级别方法，可大幅拓展张量加速器在图像处理等领域的应用范围并获取较高性能提升。

Abstract: Tensor accelerators now represent a growing share of compute resources in modern CPUs and GPUs. However, they are hard to program, leading developers to use vendor-provided kernel libraries that support tensor accelerators. As a result, the usage of tensor accelerators is limited to the provided interface, mainly designed for traditional ML and scientific computing workloads.
  In this paper, we show that tensor accelerators can improve the performance of applications beyond simple variants of MatMul. For example, many image processing pipelines are linear transformations over matrices in disguise and can therefore utilize such specialized hardware. This is nonetheless hindered by the difficulties in programming tensor accelerators. We tackle this problem with compiler-based techniques. We use the Halide user-schedulable language and express operations as Halide algorithms succinctly. To this end, we implement a flexible tensor instruction selector based on equality saturation. The tensor instruction selector supports both CPU- and GPU-attached tensor accelerators and works with existing scheduling operations (e.g., producer-consumer fusion). Together, this enables developers to write diverse accelerator-leveraging applications in a few dozen lines.
  Using our system, we demonstrate the potential of tensor accelerators beyond their traditional domains. We implement several image processing pipelines (e.g., filtering, resampling, and denoising) in our system and evaluate them against non-accelerator-leveraging baselines. We show that these pipelines can achieve significant speedups. For example, a downsampling routine is sped up by $6.1\times$ by utilizing Tensor Cores on an Nvidia RTX 4070 GPU.

</details>


### [2] [Probabilistic energy profiler for statically typed JVM-based programming languages](https://arxiv.org/abs/2512.02738)
*Joel Nyholm,Wojciech Mostowski,Christoph Reichenbach*

Main category: cs.PL

TL;DR: 本文提出了基于字节码与贝叶斯统计的语句级能耗建模方法，能高效准确预测Java/Scala程序能耗，并揭示了操作、数据类型和设备等因素对能耗的深远影响，为后续能耗分析工具提供了理论和实践基础。


<details>
  <summary>Details</summary>
Motivation: 当前各领域（如移动设备与数据中心）对能源消耗日益关注，开发者迫切需要细粒度的能耗数据以优化软件能耗，而现有方法主要聚焦于CPU和函数/程序层面，无法满足源代码语句级别的能耗建模与更广泛的硬件解释和统计推断需求。

Method: 提出了一种针对静态类型JVM编程语言（如Java、Scala）的能耗建模新方法：1）通过测量Java Bytecode模式的能耗，将源代码语句映射到字节码能耗，2）使用贝叶斯统计方法建立能耗的统计模型，能够对能耗进行概率分布建模与因子分析，模型包括数据规模、数据类型、操作类型和硬件平台等四类静态因子，3）在Java实现并在未见程序上进行了实验评估。

Result: 实验证明模型中所有四个因素对能耗均有显著影响，包括同型号设备之间的差异、操作类型和数据类型的能耗差别，以及程序能耗的高精度预测能力，验证了模型的有效性。

Conclusion: 提出的方法为未来如验证工具等能耗估算研究提供了可用的能耗建模范式，能在语句级别支持更精细、可解释且统计依据充分的能耗估算，为开发者优化软件能耗和理解硬件多样性影响提供了新手段。

Abstract: Energy consumption is a growing concern in several fields, from mobile devices to large data centers. Developers need detailed data on the energy consumption of their software to mitigate consumption issues. Previous approaches have a broader focus, such as on specific functions or programs, rather than source code statements. They primarily focus on estimating the CPU's energy consumption using point estimates, thereby disregarding other hardware effects and limiting their use for statistical reasoning and explainability. We developed a novel methodology to address the limitations of measuring only the CPU's consumption and using point estimates, focusing on predicting the energy usage of statically typed JVM-based programming languages, such as Java and Scala. We measure the energy consumption of Bytecode patterns, the translation from the programming language's source code statement to their Java Bytecode representation. With the energy measurements, we construct a statistical model using Bayesian statistics, which allows us to predict the energy consumption through statistical distributions and analyze individual factors. The model includes three factors we obtain statically from the code: data size, data type, operation, and one factor about the hardware platform the code executes on: device. To validate our methodology, we implemented it for Java and evaluated its energy predictions on unseen programs. We observe that all four factors are influential, notably that two devices of the same model may differ in energy consumption and that the operations and data types cause consumption differences. The experiments also show that the energy prediction of programs closely follows the program's real energy consumption, validating our approach. Our work presents a methodology for constructing an energy model that future work, such as verification tools, can use for their energy estimates.

</details>


### [3] [Lumos: Let there be Language Model System Certification](https://arxiv.org/abs/2512.02966)
*Isha Chaudhary,Vedaant Jain,Avaljot Singh,Kavya Sachdeva,Sayan Ranu,Gagandeep Singh*

Main category: cs.PL

TL;DR: 本文提出Lumos框架，首次用形式化方法规范并认证语言模型系统行为，能发现并量化顶尖VLM在自动驾驶等场景下的显著安全缺陷，为LMS安全认证提供新路径。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏系统化、可扩展且可认证语言模型系统行为的工具。随着LMS应用日益广泛，尤其是在关键领域（如自动驾驶），对其安全性和行为规范化的需求更为迫切。

Method: 方法论上，提出了Lumos语言：一种基于图的命令式概率编程DSL，通过抽象生成IID任务提示，并结合统计认证器，实现针对任意提示分布下的LMS认证。该框架具备组合性，可编码复杂时序和关系规范，并支持混合语义（操作语义+指称语义）解释规范。

Result: 1. 利用Lumos提出首套针对视觉语言模型（如自动驾驶场景下VLM）的安全规范。2. 实证发现顶尖VLM（Qwen-VL）在雨天右转驾驶场景下至少90%概率给出错误或不安全响应，存在严重安全风险。3. Lumos高可扩展性，能辅助快速定位缺陷和适应威胁变化。

Conclusion: Lumos是首个系统化、可扩展的语言模型系统（LMS）行为规范和认证框架，为LMS认证的广泛应用奠定了基础。

Abstract: We introduce the first principled framework, Lumos, for specifying and formally certifying Language Model System (LMS) behaviors. Lumos is an imperative probabilistic programming DSL over graphs, with constructs to generate independent and identically distributed prompts for LMS. It offers a structured view of prompt distributions via graphs, forming random prompts from sampled subgraphs. Lumos supports certifying LMS for arbitrary prompt distributions via integration with statistical certifiers. We provide hybrid (operational and denotational) semantics for Lumos, providing a rigorous way to interpret the specifications. Using only a small set of composable constructs, Lumos can encode existing LMS specifications, including complex relational and temporal specifications. It also facilitates specifying new properties - we present the first safety specifications for vision-language models (VLMs) in autonomous driving scenarios developed with Lumos. Using these, we show that the state-of-the-art VLM Qwen-VL exhibits critical safety failures, producing incorrect and unsafe responses with at least 90% probability in right-turn scenarios under rainy driving conditions, revealing substantial safety risks. Lumos's modular structure allows easy modification of the specifications, enabling LMS certification to stay abreast with the rapidly evolving threat landscape. We further demonstrate that specification programs written in Lumos enable finding specific failure cases exhibited by state-of-the-art LMS. Lumos is the first systematic and extensible language-based framework for specifying and certifying LMS behaviors, paving the way for a wider adoption of LMS certification.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [Bin2Vec: Interpretable and Auditable Multi-View Binary Analysis for Code Plagiarism Detection](https://arxiv.org/abs/2512.02197)
*Moussa Moussaoui,Tarik Houichime,Abdelalim Sadiq*

Main category: cs.SE

TL;DR: Bin2Vec框架结合静态与动态特征，实现软件相似性可视化和机器学习表示，实验支持其优越性，适用安全审计、溯源等多种实际场景。


<details>
  <summary>Details</summary>
Motivation: 现有软件相似性分析方法往往只侧重单一维度，缺乏对软件行为的全面、可解释融合。Bin2Vec旨在改善这一不足，为安全审计、溯源和自动化筛选提供更强的技术支撑。

Method: 该框架将软件的静态信息（如内置函数、导入和导出）与动态运行行为（如指令和内存用法）融合，通过多视图特征提取并以易于可视化的形式展现，最终合成为整体相似性评分，用于机器学习模型分析。

Result: 实验在PuTTY和7-Zip多个版本上验证了Bin2Vec的有效性，展示了不同软件在行为和内存活动上的可视差异，获得了优化且易于解读的分析结果，并确认了方法的可拓展性。

Conclusion: Bin2Vec框架能够实现对二进制软件的可靠且可解释的相似性评估，并且适用于多种实际应用场景。

Abstract: We introduce Bin2Vec, a new framework that helps compare software programs in a clear and explainable way. Instead of focusing only on one type of information, Bin2Vec combines what a program looks like (its built-in functions, imports, and exports) with how it behaves when it runs (its instructions and memory usage). This gives a more complete picture when deciding whether two programs are similar or not. Bin2Vec represents these different types of information as views that can be inspected separately using easy-to-read charts, and then brings them together into an overall similarity score. Bin2Vec acts as a bridge between binary representations and machine learning techniques by generating feature representations that can be efficiently processed by machine-learning models. We tested Bin2Vec on multiple versions of two well-known Windows programs, PuTTY and 7-Zip. The primary results strongly confirmed that our method compute an optimal and visualization-friendly representation of the analyzed software. For example, PuTTY versions showed more complex behavior and memory activity, while 7-Zip versions focused more on performance-related patterns. Overall, Bin2Vec provides decisions that are both reliable and explainable to humans. Because it is modular and easy to extend, it can be applied to tasks like auditing, verifying software origins, or quickly screening large numbers of programs in cybersecurity and reverse-engineering work.

</details>


### [5] [Towards autonomous normative multi-agent systems for Human-AI software engineering teams](https://arxiv.org/abs/2512.02329)
*Hoa Khanh Dam,Geeta Mahala,Rashina Hoda,Xi Zheng,Cristina Conati*

Main category: cs.SE

TL;DR: 本文提出了一种赋予AI代理人类似人类认知与协作规范的新范式，使其成为软件开发流程的主导者，大幅提升项目速度与质量，实现可信赖的未来人机软件工程团队。


<details>
  <summary>Details</summary>
Motivation: 现有的软件开发过程在速度、可靠性和适应性方面存在局限。借助AI可以带来突破性的转变，但人机协作、AI能力和合规性仍面临挑战。该文旨在提出一种全新的软件工程范式，利用先进AI推动核心开发活动。

Method: 提出并设计了一类新的软件工程代理（代理人），基于大语言模型，赋予其信念、欲望、意图和记忆，使其具备类人推理能力。代理人之间及与人类协作，通过规范（由承诺、义务、禁止和允许等模态表达）进行协调，确保开发流程合规。

Result: 这些具备高级认知和规范协同能力的AI代理人能与人类和其他代理人高效协作开展软件设计、实现、测试和部署，显著提升开发速度、可靠性和适应性。在团队规模、协作透明性和可信性方面带来突破。

Conclusion: 利用具备人类思维特征和合规交互的AI代理人，推动软件开发过程革新，实现更加智能、高效、可靠且可信赖的人机协同开发体系。

Abstract: This paper envisions a transformative paradigm in software engineering, where Artificial Intelligence, embodied in fully autonomous agents, becomes the primary driver of the core software development activities. We introduce a new class of software engineering agents, empowered by Large Language Models and equipped with beliefs, desires, intentions, and memory to enable human-like reasoning. These agents collaborate with humans and other agents to design, implement, test, and deploy software systems with a level of speed, reliability, and adaptability far beyond the current software development processes. Their coordination and collaboration are governed by norms expressed as deontic modalities - commitments, obligations, prohibitions and permissions - that regulate interactions and ensure regulatory compliance. These innovations establish a scalable, transparent and trustworthy framework for future Human-AI software engineering teams.

</details>


### [6] [Process-Centric Analysis of Agentic Software Systems](https://arxiv.org/abs/2512.02393)
*Shuyang Liu,Yang Chen,Rahul Krishna,Saurabh Sinha,Jatin Ganhotra,Reyhan Jabbarvand*

Main category: cs.SE

TL;DR: 本文提出Graphectory框架，用于分析和评估智能体系统行为过程，对比不同模型和提示条件、流程复杂度和效率，揭示现有智能体系统在过程层面存在的问题，比传统仅看结果的评估更加细致和全面。


<details>
  <summary>Details</summary>
Motivation: 目前对智能体系统的评估过于注重结果，忽视了执行过程中的决策、计划与行为变化，缺乏过程层面的质量分析方法。旨在填补这一差距，系统性、可解释性地刻画和评估智能体系统的行为与流程。

Method: 提出了一种名为Graphectory的新型图结构，系统性地编码并分析智能体系统中的时序与语义关系。利用Graphectory，对4000条SWE-agent与OpenHands智能体工作流轨迹进行了自动化分析，结合4种主流大型语言模型，评估其在SWE-bench任务上的表现与过程特征。

Result: 发现提示更丰富或模型更强大的智能体会展现出更复杂且高效的流程结构，具备更深入的探索和更全面的验证环节；解决难题或者底层模型能力不同会导致智能体采用不同流程策略；即便任务成功，许多智能体流程仍有低效、冗长的问题。

Conclusion: 基于Graphectory分析，智能体系统在问题解决过程中，即使取得成功，依然可能存在效率低下和流程冗长的问题。不同模型和提示的复杂度对智能体的探索深度、问题策略和轨迹结构有显著影响。传统以结果为中心的评估指标低估了流程中发生的复杂智能行为。

Abstract: Agentic systems are modern software systems: they consist of orchestrated modules, expose interfaces, and are deployed in software pipelines. Unlike conventional programs, their execution (i.e., trajectories) is inherently stochastic and adaptive to the problem they are solving. Evaluation of such systems is often outcome-centric, judging their performance based on success or failure at the final step. This narrow focus overlooks detailed insights about such systems, failing to explain how agents reason, plan, act, or change their strategies over time. Inspired by the structured representation of conventional software systems as graphs, we introduce Graphectory to systematically encode the temporal and semantic relations in such software systems. Graphectory facilitates the design of process-centric metrics and analyses to assess the quality of agentic workflows independent of final success.
  Using Graphectory, we analyze 4000 trajectories of two dominant agentic programming workflows, namely SWE-agent and OpenHands, with a combination of four backbone Large Language Models (LLMs), attempting to resolve SWE-bench Verified issues. Our fully automated analyses reveal that: (1) agents using richer prompts or stronger LLMs exhibit more complex Graphectory, reflecting deeper exploration, broader context gathering, and more thorough validation before patch submission; (2) agents' problem-solving strategies vary with both problem difficulty and the underlying LLM -- for resolved issues, the strategies often follow coherent localization-patching-validation steps, while unresolved ones exhibit chaotic, repetitive, or backtracking behaviors; (3) even when successful, agentic programming systems often display inefficient processes, leading to unnecessarily prolonged trajectories.

</details>


### [7] [Feedback Loops and Code Perturbations in LLM-based Software Engineering: A Case Study on a C-to-Rust Translation System](https://arxiv.org/abs/2512.02567)
*Martin Weiss,Jesko Hecking-Harbusch,Jochen Quante,Matthias Woehrle*

Main category: cs.SE

TL;DR: 自动反馈环和代码扰动提升了C到Rust翻译的自动系统性能，不同大模型的表现差距随着反馈增加而变小。


<details>
  <summary>Details</summary>
Motivation: 现有自动代码生成、翻译工具需更高可靠性才可应用于工业领域，自动反馈机制、LLM模型选择、以及代码干扰对自动化系统实际表现影响未明，需深入实验测评。

Method: 基于生成与校验的自动翻译系统，自动检测LLM生成的Rust代码能否通过编译并行为等价于原C代码，负面结果触发LLM反馈修复，系统在不同LLM、反馈环数、代码扰动等设定下进行多组实验对比。

Result: a) 不用反馈环时，LLM差异对翻译成功率影响大；b) 加入反馈环后，不同LLM表现差距缩小；c) 代码扰动提升了系统多样性并可带来更好的总体表现。

Conclusion: 引入自动化反馈环节后，C到Rust自动翻译系统在不同大型语言模型（LLM）之间的表现差距显著减少，系统整体性能和鲁棒性提升。同时，代码扰动带来的多样性还可能进一步提升系统表现。

Abstract: The advent of strong generative AI has a considerable impact on various software engineering tasks such as code repair, test generation, or language translation. While tools like GitHub Copilot are already in widespread use in interactive settings, automated approaches require a higher level of reliability before being usable in industrial practice. In this paper, we focus on three aspects that directly influence the quality of the results: a) the effect of automated feedback loops, b) the choice of Large Language Model (LLM), and c) the influence of behavior-preserving code changes.
  We study the effect of these three variables on an automated C-to-Rust translation system. Code translation from C to Rust is an attractive use case in industry due to Rust's safety guarantees. The translation system is based on a generate-and-check pattern, in which Rust code generated by the LLM is automatically checked for compilability and behavioral equivalence with the original C code. For negative checking results, the LLM is re-prompted in a feedback loop to repair its output. These checks also allow us to evaluate and compare the respective success rates of the translation system when varying the three variables.
  Our results show that without feedback loops LLM selection has a large effect on translation success. However, when the translation system uses feedback loops the differences across models diminish. We observe this for the average performance of the system as well as its robustness under code perturbations. Finally, we also identify that diversity provided by code perturbations can even result in improved system performance.

</details>


### [8] [Empirical Assessment of the Perception of Software Product Line Engineering by an SME before Migrating its Code Base](https://arxiv.org/abs/2512.02707)
*Thomas Georges,Marianne Huchard,Mélanie König,Clémentine Nebut,Chouki Tibermacine*

Main category: cs.SE

TL;DR: 本研究对一家中小企业从现有代码迁移到SPL的过程进行了分析，发现让全员持续参与并保持沟通，有助于平稳过渡和降低风险。


<details>
  <summary>Details</summary>
Motivation: 软件变体迁移到软件产品线虽有益处但过程复杂且成本高，尤其会对企业内部流程和开发人员实践产生显著影响，因此需评估风险和收益。

Method: 对合作企业的开发流程进行了深入评估。采用面向主要开发相关利益相关者的访谈，并对访谈结果进行了定性分析。

Result: 参与各环节的利益相关者皆发现迁移SPL对本职工作有好处。研究表明，让利益相关者持续参与和保持沟通、结合已有优良开发实践，是有效的风险缓解策略。

Conclusion: 所有参与者都认识到迁移至SPL带来的益处，并且通过让利益相关者全程参与、保持沟通以及尽量保留原有优秀实践，有助于平稳迁移及降低风险。

Abstract: Migrating a set of software variants into a software product line (SPL) is an expensive and potentially challenging endeavor. Indeed, SPL engineering can significantly impact a company's development process and often requires changes to established developer practices. The work presented in this paper stems from a collaboration with a Small and Medium-sized Enterprise (SME) that decided to migrate its existing code base into an SPL. In this study, we conducted an in-depth evaluation of the company's current development processes and practices, as well as the anticipated benefits and risks associated with the migration. Key stakeholders involved in software development participated in this evaluation to provide insight into their perceptions of the migration and their potential resistance to change. This paper describes the design of the interviews conducted with these stakeholders and presents an analysis of the results. Among the qualitative findings, we observed that all participants, regardless of their role in the development process, identified benefits of the migration relevant to their own activities. Furthermore, our results suggest that an effective risk mitigation strategy involves keeping stakeholders informed and engaged throughout the process, preserving as many good practices as possible, and actively involving them in the migration to ensure a smooth transition and minimize potential challenges.

</details>


### [9] [Integrative Analysis of Risk Management Methodologies in Data Science Projects](https://arxiv.org/abs/2512.02728)
*Sabrina Delmondes da Costa Feitosa*

Main category: cs.SE

TL;DR: 通过文献综述比较主流数据科学风险管理方法，发现传统法有限且新兴框架能更好应对伦理与治理风险，并建议发展技术、组织、伦理兼顾的混合型方法。


<details>
  <summary>Details</summary>
Motivation: 数据科学项目常常由于技术、组织和风险管理不足而失败，文献指出数据成熟度低、治理缺失、技术和业务团队失调、缺乏应对伦理和社会技术风险的结构性机制等问题。研究动机在于梳理和比较数据科学项目所应用的主要风险管理方法，明确其优势、短板和空白。

Method: 本研究采用了系统性的文献综述方法，在数据库中以结构化协议筛选和分析文献，重点评估ISO 31000、PMBOK风险管理、NIST RMF以及数据科学特有的CRISP DM和DS EthiCo RMF等标准和框架。

Result: 研究发现，传统风险管理方法对新兴风险的覆盖有局限性，而新近模型能更好地融合伦理监管、治理和持续监督等多维度结构。对比分析表明，不同框架在风险应对维度和实施细节上存在差异。

Conclusion: 本文为开发整合技术效率、组织协同与负责任数据实践于一体的混合型风险管理框架提供了理论支持，并指出了当前方法存在的研究空白与未来改进方向。

Abstract: Data science initiatives frequently exhibit high failure rates, driven by technical constraints, organizational limitations and insufficient risk management practices. Challenges such as low data maturity, lack of governance, misalignment between technical and business teams, and the absence of structured mechanisms to address ethical and sociotechnical risks have been widely identified in the literature. In this context, the purpose of this study is to conduct a comparative analysis of the main risk management methodologies applied to data science projects, aiming to identify, classify, and synthesize their similarities, differences and existing gaps. An integrative literature review was performed using indexed databases and a structured protocol for selection and content analysis. The study examines widely adopted risk management standards ISO 31000, PMBOK Risk Management and NIST RMF, as well as frameworks specific to data science workflows, such as CRISP DM and the recently proposed DS EthiCo RMF, which incorporates ethical and sociotechnical dimensions into the project life cycle. The findings reveal that traditional approaches provide limited coverage of emerging risks, whereas contemporary models propose multidimensional structures capable of integrating ethical oversight, governance and continuous monitoring. As a contribution, this work offers theoretical support for the development of hybrid frameworks that balance technical efficiency, organizational alignment and responsible data practices, while highlighting research gaps that can guide future investigations.

</details>


### [10] [Model-Based Diagnosis with Multiple Observations: A Unified Approach for C Software and Boolean Circuits](https://arxiv.org/abs/2512.02898)
*Pedro Orvalho,Marta Kwiatkowska,Mikoláš Janota,Vasco Manquinho*

Main category: cs.SE

TL;DR: CFaults是一种融合MaxSAT与MBD的新型故障定位工具，针对多故障场景，有效提升了诊断一致性和减少冗余，实验显示其在C程序上优于主流工具，对电路场景也较为竞争。


<details>
  <summary>Details</summary>
Motivation: 现有公式化故障定位方法在多故障情况下往往无法保证所有失败测试的诊断一致性，且易产生冗余、非最小化的诊断集合，影响效率和准确性。作者旨在解决该痛点。

Method: 提出CFaults工具，将所有失败测试案例转化为统一的MaxSAT公式，并利用模型诊断方法（MBD）在多观测点下进行故障定位，保证诊断结果的一致性与最小冗余性。对TCAS、C-Pack-IPAs、ISCAS85等基准集进行实证对比分析。

Result: CFaults在C软件基准上定位速度快于BugAssist、SNIPER、HSD，在ISCAS85电路基准上定位覆盖率仅比HSD低6%。且CFaults能生成去冗余、子集最小的故障诊断集合，其余方法易产生冗余。

Conclusion: CFaults工具利用多观测点的模型诊断方法，对失败测试进行统一处理，提高了多故障场景下的定位一致性和诊断简洁性。相比现有工具，CFaults在C软件诊断速度更快，且输出去冗余的故障集合，仅略逊于其他方法在部分电路（如ISCAS85）上的覆盖率。

Abstract: Debugging is one of the most time-consuming and expensive tasks in software development and circuit design. Several formula-based fault localisation (FBFL) methods have been proposed, but they fail to guarantee a set of diagnoses across all failing tests or may produce redundant diagnoses that are not subset-minimal, particularly for programs/circuits with multiple faults.
  This paper introduces CFaults, a novel fault localisation tool for C software and Boolean circuits with multiple faults. CFaults leverages Model-Based Diagnosis (MBD) with multiple observations and aggregates all failing test cases into a unified Maximum Satisfiability (MaxSAT) formula. Consequently, our method guarantees consistency across observations and simplifies the fault localisation procedure. Experimental results on three benchmark sets, two of C programs, TCAS and C-Pack-IPAs, and one of Boolean circuits, ISCAS85, show that CFaults is faster at localising faults in C software than other FBFL approaches such as BugAssist, SNIPER, and HSD. On the ISCAS85 benchmark, CFaults is generally slower than HSD; however, it localises faults in only 6% fewer circuits, demonstrating that it remains competitive in this domain. Furthermore, CFaults produces only subset-minimal diagnoses of faulty statements, whereas the other approaches tend to enumerate redundant diagnoses (e.g., BugAssist and SNIPER).

</details>


### [11] ["Can you feel the vibes?": An exploration of novice programmer engagement with vibe coding](https://arxiv.org/abs/2512.02750)
*Kiev Gama,Filipe Calegario,Victoria Jackson,Alexander Nolte,Luiz Augusto Morais,Vinicius Garcia*

Main category: cs.SE

TL;DR: 本研究通过黑客松探讨vibe coding对新手和混合经验团体的教育影响，显示其促进快速原型、跨学科协作和信心提升，但需有效引导防止思维收敛和提升代码质量，强调人机协作与批判性评价。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能兴起以及AI辅助编程普及，带来了“vibe coding”新趋势，该方法允许通过自然语言而非直接编程开发软件。其有望普及软件开发流程，但对教育影响尚未深入研究。

Method: 作者设计了一场为期一天的教育黑客松活动，在巴西一所公立大学举办，召集了31名来自计算机及非计算机学科的本科生，分为九个团队。通过观察、问卷调查和半结构化访谈，分析了创意过程、工具使用模式、协作动力和学习成果。

Result: 研究发现，vibe coding有助于快速原型实现和跨学科协作，参与者培养了提示工程能力，并能在有限时间内完成功能展示。但也存在思想收敛过快、代码质量不均需返工、核心软工实践参与度有限等问题。团队采用多AI工具联用的复杂工作流，并且人工判断仍对关键优化不可或缺。短时间活动有效激发新手自信，适合时间有限参与者。

Conclusion: vibe coding黑客松为低风险学习环境，若辅以鼓励发散思维、批判AI输出和现实质量预期的引导措施，将为编程教育提供有价值支持。

Abstract: Emerging alongside generative AI and the broader trend of AI-assisted coding, the term "vibe coding" refers to creating software via natural language prompts rather than direct code authorship. This approach promises to democratize software development, but its educational implications remain underexplored. This paper reports on a one-day educational hackathon investigating how novice programmers and mixed-experience teams engage with vibe coding. We organized an inclusive event at a Brazilian public university with 31 undergraduate participants from computing and non-computing disciplines, divided into nine teams. Through observations, an exit survey, and semi-structured interviews, we examined creative processes, tool usage patterns, collaboration dynamics, and learning outcomes. Findings reveal that vibe coding enabled rapid prototyping and cross-disciplinary collaboration, with participants developing prompt engineering skills and delivering functional demonstrations within time constraints. However, we observed premature convergence in ideation, uneven code quality requiring rework, and limited engagement with core software engineering practices. Teams adopted sophisticated workflows combining multiple AI tools in pipeline configurations, with human judgment remaining essential for critical refinement. The short format (9 hours) proved effective for confidence-building among newcomers while accommodating participants with limited availability. We conclude that vibe coding hackathons can serve as valuable low-stakes learning environments when coupled with explicit scaffolds for divergent thinking, critical evaluation of AI outputs, and realistic expectations about production quality.

</details>


### [12] [Towards Observation Lakehouses: Living, Interactive Archives of Software Behavior](https://arxiv.org/abs/2512.02795)
*Marcus Kessel*

Main category: cs.SE

TL;DR: 本文提出了观察湖仓，持续收集和存储代码运行行为，易于分析与扩展，并能在单机高效工作，为行为驱动的代码评估和训练打开新路径。


<details>
  <summary>Details</summary>
Motivation: 传统代码生成型大型语言模型主要学习静态信息，容易吸收错误代码，无法有效验证语义功能。由于复杂语义属性一般是不可判定的，作者希望通过动态运行行为的观测，作为代码行为的真实依据，用于更高质量的模型评估和训练。

Method: 提出了观察湖仓（Observation Lakehouse）体系，持续性地收集和存储SRC（Stimulus-Response Cube）的原始观测数据，实现数据的持久化、可扩展演化与交互分析；具体技术实现包括基于Apache Parquet、Iceberg和DuckDB，结合从自动化流程和CI管道采集的行为数据，并通过SQL查询按需生成分析视图。

Result: 方案在509个问题的基准上成功采集并存储了约8.6百万行观测行为数据（<51MiB），可在普通笔记本电脑上以<100ms的速度重建分析视图与聚类，无需分布式集群。系统及数据已开源。

Conclusion: 观察湖仓使行为型数据成为与其他运行时数据同等重要的一等公民，并为行为感知的评估与训练提供了基础设施。

Abstract: Code-generating LLMs are trained largely on static artifacts (source, comments, specifications) and rarely on materializations of run-time behavior. As a result, they readily internalize buggy or mislabeled code. Since non-trivial semantic properties are undecidable in general, the only practical way to obtain ground-truth functionality is by dynamic observation of executions. In prior work, we addressed representation with Sequence Sheets, Stimulus-Response Matrices (SRMs), and Stimulus-Response Cubes (SRCs) to capture and compare behavior across tests, implementations, and contexts. These structures make observation data analyzable offline and reusable, but they do not by themselves provide persistence, evolution, or interactive analytics at scale. In this paper, therefore, we introduce observation lakehouses that operationalize continual SRCs: a tall, append-only observations table storing every actuation (stimulus, response, context) and SQL queries that materialize SRC slices on demand. Built on Apache Parquet + Iceberg + DuckDB, the lakehouse ingests data from controlled pipelines (LASSO) and CI pipelines (e.g., unit test executions), enabling n-version assessment, behavioral clustering, and consensus oracles without re-execution. On a 509-problem benchmark, we ingest $\approx$8.6M observation rows ($<$51MiB) and reconstruct SRM/SRC views and clusters in $<$100ms on a laptop, demonstrating that continual behavior mining is practical without a distributed cluster of machines. This makes behavioral ground truth first-class alongside other run-time data and provides an infrastructure path toward behavior-aware evaluation and training. The Observation Lakehouse, together with the accompanying dataset, is publicly available as an open-source project on GitHub: https://github.com/SoftwareObservatorium/observation-lakehouse

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [13] [The role of counting quantifiers in laminar set systems](https://arxiv.org/abs/2512.02617)
*Rutger Campbell,Noleen Köhler*

Main category: cs.LO

TL;DR: 本论文证明利用单一的MSO逻辑即可完成层状集系统与层状树转换，促进了图分解理论的简化，同时对MSO能否模拟计数量词做了深入探讨，对图算法和逻辑领域有积极推动作用。


<details>
  <summary>Details</summary>
Motivation: 层状集系统是许多图分解（如模分解、分裂分解、双连接分解等）的基础结构。过去相关分解通常依赖更复杂的逻辑如CMSO，而MSO更加自然且充分，因而研究其表达和构造能力对于理论和应用都有重要意义。

Method: 主要方法是利用一阶统计算术归纳逻辑（MSO transduction）从层状集系统构造其对应层状树，并结合已有工具推广MSO在图分解领域中的应用。

Result: 作者证明了可以用MSO逻辑完成从层状集系统到层状树的转换，并依托近期结果可以实现传统分解的MSO刻画。此外，对MSO的表达力做了计数量词角度的分析。

Conclusion: 论文解决了Courcelle提出的开放问题，即如何通过MSO逻辑将层状集系统转换为对应的层状树。同时论文对计数量词在MSO下的表达能力进行了分析，提出了可以以及不能模拟的情形。

Abstract: Laminar set systems consist of non-crossing subsets of a universe with set inclusion essentially corresponding to the descendant relationship of a tree, the so-called laminar tree. Laminar set systems lie at the core of many graph decompositions such as modular decompositions, split decompositions, and bi-join decompositions. We show that from a laminar set system we can obtain the corresponding laminar tree by means of a monadic second order logic (MSO) transduction. This resolves an open question originally asked by Courcelle and is a satisfying resolution as MSO is the natural logic for set systems and is sufficient to define the property ``laminar''. Using results from Campbell et al. [STACS 2025], we can now obtain transductions for obtaining modular decompositions, co-trees, split decompositions and bi-join decompositions using MSO instead of CMSO. We further gain some insight into the expressive power of counting quantifiers and provide some results towards determining when counting quantifiers can be simulated in MSO in laminar set systems and when they cannot.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [14] [Human-Level and Beyond: Benchmarking Large Language Models Against Clinical Pharmacists in Prescription Review](https://arxiv.org/abs/2512.02024)
*Yan Yang,Mouxiao Bian,Peiling Li,Bingjian Wen,Ruiyao Chen,Kangkun Mao,Xiaojun Ye,Tianbin Li,Pengcheng Chen,Bing Han,Jie Xu,Kaifeng Qiu,Junyan Wu*

Main category: cs.CL

TL;DR: 本文提出RxBench，系统评估了18个语言模型在药物处方审核中的表现，发现部分模型已优于药师，且基准可助力开发更专用临床AI工具。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在临床决策支持，尤其是处方审核中应用日益广泛，但缺乏系统性和细致化的评估工具。本文为此开发并提出RxBench，以标准化、细分处方错误类型，为模型评估和专用工具开发提供基础。

Method: 构建了覆盖常见处方审核类别的RxBench基准，涵盖14种常见处方错误类型。题库包括单项选择题、多项选择题和简答题并由临床药师审核。基于RxBench评测了18种最先进LLM，并对表现进行了分层分析。比较LLMs与药师实际表现，并针对中间层模型进行了微调。

Result: Gemini-2.5-pro-preview-05-06、Grok-4-0709和DeepSeek-R1-0528等模型在准确性和鲁棒性上表现最佳，可与药师媲美甚至超过。微调后的中层模型在简答题任务上表现接近顶尖通用模型。

Conclusion: RxBench奠定了面向处方错误类型的标准化评估框架，揭示了前沿LLMs在临床处方审核能力和局限，为开发更可靠、专业的临床工具提供基础资源。

Abstract: The rapid advancement of large language models (LLMs) has accelerated their integration into clinical decision support, particularly in prescription review. To enable systematic and fine-grained evaluation, we developed RxBench, a comprehensive benchmark that covers common prescription review categories and consolidates 14 frequent types of prescription errors drawn from authoritative pharmacy references. RxBench consists of 1,150 single-choice, 230 multiple-choice, and 879 short-answer items, all reviewed by experienced clinical pharmacists. We benchmarked 18 state-of-the-art LLMs and identified clear stratification of performance across tasks. Notably, Gemini-2.5-pro-preview-05-06, Grok-4-0709, and DeepSeek-R1-0528 consistently formed the first tier, outperforming other models in both accuracy and robustness. Comparisons with licensed pharmacists indicated that leading LLMs can match or exceed human performance in certain tasks. Furthermore, building on insights from our benchmark evaluation, we performed targeted fine-tuning on a mid-tier model, resulting in a specialized model that rivals leading general-purpose LLMs in performance on short-answer question tasks. The main contribution of RxBench lies in establishing a standardized, error-type-oriented framework that not only reveals the capabilities and limitations of frontier LLMs in prescription review but also provides a foundational resource for building more reliable and specialized clinical tools.

</details>


### [15] [Deep Research: A Systematic Survey](https://arxiv.org/abs/2512.02038)
*Zhengliang Shi,Yiqun Chen,Haitao Li,Weiwei Sun,Shiyu Ni,Yougang Lyu,Run-Ze Fan,Bowen Jin,Yixuan Weng,Minjun Zhu,Qiujie Xie,Xinyu Guo,Qu Yang,Jiayi Wu,Jujia Zhao,Xiaqiang Tang,Xinbei Ma,Cunxiang Wang,Jiaxin Mao,Qingyao Ai,Jen-Tse Huang,Wenxuan Wang,Yue Zhang,Yiming Yang,Zhaopeng Tu,Zhaochun Ren*

Main category: cs.CL

TL;DR: 本文系统性综述了Deep Research系统的发展，包括架构、组件、优化、评估标准及挑战，并提出了未来研究方向与更新路线。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型能力提升，单一提示或标准检索生成已难以满足复杂任务需求，因此需要整合推理与外部工具以实现复杂问题求解。

Method: 采用综述和系统性分析的方法，梳理和分类了Deep Research系统的架构、关键组件、优化技术及评价标准。

Result: 提出了Deep Research的三阶段路线图，详细区分其与相关范式，构建了四大核心组件的细致分类，总结了优化与训练技术，并整合了评估标准与挑战。

Conclusion: 论文总结了Deep Research系统的整体进展和面临的挑战，强调其未来发展方向和持续更新的承诺，以促进领域的进一步发展。

Abstract: Large language models (LLMs) have rapidly evolved from text generators into powerful problem solvers. Yet, many open tasks demand critical thinking, multi-source, and verifiable outputs, which are beyond single-shot prompting or standard retrieval-augmented generation. Recently, numerous studies have explored Deep Research (DR), which aims to combine the reasoning capabilities of LLMs with external tools, such as search engines, thereby empowering LLMs to act as research agents capable of completing complex, open-ended tasks. This survey presents a comprehensive and systematic overview of deep research systems, including a clear roadmap, foundational components, practical implementation techniques, important challenges, and future directions. Specifically, our main contributions are as follows: (i) we formalize a three-stage roadmap and distinguish deep research from related paradigms; (ii) we introduce four key components: query planning, information acquisition, memory management, and answer generation, each paired with fine-grained sub-taxonomies; (iii) we summarize optimization techniques, including prompting, supervised fine-tuning, and agentic reinforcement learning; and (iv) we consolidate evaluation criteria and open challenges, aiming to guide and facilitate future development. As the field of deep research continues to evolve rapidly, we are committed to continuously updating this survey to reflect the latest progress in this area.

</details>


### [16] [Mirror, Mirror on the Wall -- Which is the Best Model of Them All?](https://arxiv.org/abs/2512.02043)
*Dina Sayed,Heiko Schuldt*

Main category: cs.CL

TL;DR: 本文分析了当前LLM模型在实际应用选型时的复杂性，重点讨论定量维度（排行榜/基准），以医疗领域举案例，提出了系统化模型选择方法（MSM），为实际部署提供参考。


<details>
  <summary>Details</summary>
Motivation: 面对不断更新的基础模型和多领域需求，如何科学选型LLM变得日益复杂，亟需一套系统性选择方法来指导实际应用。

Method: 通过分析现有的LLM排行榜与基准测试，特别以医学领域为案例，综合定性和定量维度，提出模型选择流程。

Result: 定量维度分析（如排行榜、标准化基准）已成为选型重要依据，作者以医学领域演示了基于这些数据的模型筛选流程，并给出具体实用的方法论。

Conclusion: 作者提出了一种系统性模型选择方法（MSM），帮助用户在快速变化的基础模型领域，选择最适合特定应用场景的LLM。

Abstract: Large Language Models (LLMs) have become one of the most transformative tools across many applications, as they have significantly boosted productivity and achieved impressive results in various domains such as finance, healthcare, education, telecommunications, and law, among others. Typically, state-of-the-art (SOTA) foundation models are developed by large corporations based on large data collections and substantial computational and financial resources required to pretrain such models from scratch. These foundation models then serve as the basis for further development and domain adaptation for specific use cases or tasks. However, given the dynamic and fast-paced nature of launching new foundation models, the process of selecting the most suitable model for a particular use case, application, or domain becomes increasingly complex. We argue that there are two main dimensions that need to be taken into consideration when selecting a model for further training: a qualitative dimension (which model is best suited for a task based on information, for instance, taken from model cards) and a quantitative dimension (which is the best performing model). The quantitative performance of models is assessed through leaderboards, which rank models based on standardized benchmarks and provide a consistent framework for comparing different LLMs. In this work, we address the analysis of the quantitative dimension by exploring the current leaderboards and benchmarks. To illustrate this analysis, we focus on the medical domain as a case study, demonstrating the evolution, current landscape, and practical significance of this quantitative evaluation dimension. Finally, we propose a Model Selection Methodology (MSM), a systematic approach designed to guide the navigation, prioritization, and selection of the model that best aligns with a given use case.

</details>


### [17] [Beyond Confidence: Adaptive and Coherent Decoding for Diffusion Language Models](https://arxiv.org/abs/2512.02044)
*Kecheng Chen,Ziru Liu,Xijia Tao,Hui Liu,Xinyu Fu,Suiyun Zhang,Dandan Tu,Lingpeng Kong,Rui Liu,Haoliang Li*

Main category: cs.CL

TL;DR: 提出的CCD方法通过上下文感知轨迹修正和自适应采样，显著提升了扩散语言模型的推理速度和生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散语言模型推理方法依赖于局部即时指标（如置信度和熵），缺乏整体和连贯的评价视角，导致生成轨迹不可靠及质量下降。本研究旨在提升生成序列的整体一致性和推理效率。

Method: 通过引入基于上下文一致性的轨迹修正机制和自适应采样策略，动态调整解码预算，提升生成序列的连贯性和采样效率。理论上，该机制等价于利用条件互信息评估历史步骤的上下文一致性。

Result: 所提CCD方法在Dream和LLaDA等多个基准数据集上，同时取得了推理速度和生成性能的大幅提升，为扩散语言模型的生成推理提供了新的高效解法。

Conclusion: 所提出的Coherent Contextual Decoding（CCD）显著提升了DLM模型的生成质量和推理速度，在多个基准测试中取得了3.48倍的推理速度提升和3.91%的性能提升。

Abstract: Diffusion Language Models (DLMs) have recently achieved significant success due to their any-order generation capabilities. However, existing inference methods typically rely on local, immediate-step metrics such as confidence or entropy which inherently lack a more reliable perspective. This limitation frequently leads to inconsistent sampling trajectories and suboptimal generation quality. To address this, we propose Coherent Contextual Decoding (CCD), a novel inference framework built upon two core innovations. First, CCD employs a trajectory rectification mechanism that leverages historical context to enhance sequence coherence, enabling the early rejection of suboptimal paths. We demonstrate that this mechanism is theoretically equivalent to modeling the consistency of historical steps via the conditional mutual information between context and token predictions. Building on this theoretical insight, we further address the inefficiency of conventional uniform decoding budgets. Instead of rigid allocations based on diffusion steps, we introduce an adaptive sampling strategy that dynamically adjusts the unmasking budget for each step according to our consistency metric. Consequently, our method significantly improves the quality of generation trajectories while accelerating the sampling process. Empirically, our method achieves a simultaneous enhancement in both inference speed and performance across diverse benchmarks on Dream and LLaDA, delivering up to 3.48x speedup alongside 3.91% performance improvement.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [18] [Symbolic ω-automata with obligations](https://arxiv.org/abs/2512.02873)
*Luca Di Stefano*

Main category: cs.FL

TL;DR: 论文提出obligation自动机来提升处理无限字母表的能力，模型比现有自动机更简便且表达力更强，并可通过相关工具进行自动化操作。


<details>
  <summary>Details</summary>
Motivation: 解决面对无限字母表时，现有ω-自动机如符号化跃迁和寄存器自动机在信息处理和可实现性上的不足。

Method: 结合存在与全称分支及Emerson-Lei接受条件，形式化obligation自动机，并开发了对应的操作工具。

Result: 证明obligation自动机能覆盖Büchi、Rabin、Strett和parity自动机等经典模型，并识别更广泛的语言；实现了相关自动机操作工具。

Conclusion: 提出了基于obligation的自动机模型，并说明该模型能识别严格超出ω-正则语言的语言类别，具有理论和实际应用的潜力。

Abstract: Extensions of ω-automata to infinite alphabets typically rely on symbolic guards to keep the transition relation finite, and on registers or memory cells to preserve information from past symbols. Symbolic transitions alone are ill-suited to act on this information, and register automata have intricate formal semantics and issues with tractability. We propose a slightly different approach based on obligations, i.e., assignment-like constructs attached to transitions. Whenever a transition with an obligation is taken, the obligation is evaluated against the current symbol and yields a constraint on the next symbol that the automaton will read. We formalize obligation automata with existential and universal branching and Emerson-Lei acceptance conditions, which subsume classic families such as Büchi, Rabin, Strett, and parity automata. We show that these automata recognise a strict superset of ω-regular languages. To illustrate the practicality of our proposal, we also introduce a machine-readable format to express obligation automata and describe a tool implementing several operations over them, including automata product and emptiness checking.

</details>
