<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.SE](#cs.SE) [Total: 5]
- [cs.LO](#cs.LO) [Total: 5]
- [cs.CL](#cs.CL) [Total: 38]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Evaluate the Stack Management in Effect Handlers using the libseff C Library](https://arxiv.org/abs/2512.03083)
*ZeHao Yu*

Main category: cs.PL

TL;DR: 本文提出并实现了用户态堆栈过度提交方案，并系统评估其与常见堆栈管理方式的优劣。结果显示该方案具备灵活性，但目前性能不及内核级实现，需后续优化。


<details>
  <summary>Details</summary>
Motivation: 现代编程中的效应处理器在支持并发、异步和异常处理等复杂计算效应时，堆栈管理变得尤为关键。动态控制流带来了堆栈管理的高复杂度，现有方法存在内存浪费与扩展效率低下等问题。因此，亟需更高效、灵活的堆栈管理方案。

Method: 本文提出了一种基于用户态的过度提交（user-level overcommitting）堆栈管理方法，集成在libseff C库中，利用虚拟内存机制及基于保护的延迟分配和信号驱动内存提交，实现按需动态调整堆栈大小。同时，与传统固定堆栈、分段堆栈和内核级过度提交方案进行了严格基准测试和对比分析。

Result: 实验结果表明：内核级过度提交兼顾了性能与灵活性，而用户态过度提交方案虽然灵活，但当前实现存在额外开销，需要进一步优化。

Conclusion: 文章详细比较和分析了不同堆栈管理策略的优缺点，对实际应用场景提出了建议。未来将致力于优化用户态过度提交机制，消除非确定性行为，并拓展基准测试到真实场景。

Abstract: Effect handlers are increasingly prominent in modern programming for managing complex computational effects, including concurrency, asynchronous operations, and exception handling, in a modular and flexible manner. Efficient stack management remains a significant challenge for effect handlers due to the dynamic control flow changes they introduce. This paper explores a novel stack management approach using user-level overcommitting within the libseff C library, which leverages virtual memory mechanisms and protection-based lazy allocation combined with signal-driven memory commitment. Our user-level overcommitting implementation dynamically resizes stacks on-demand, improving memory utilization and reducing waste compared to traditional methods. We rigorously benchmark and evaluate this novel strategy against conventional fixed- size stacks, segmented stacks, and kernel-based overcommitting, using metrics such as context-switch latency, stack expansion efficiency, multi-threaded performance, and robustness under rapid stack growth conditions. Experimental results demonstrate that kernel-based overcommitting achieves an effective balance between performance and flexibility, whereas our user-level implementation, while flexible, incurs additional overheads, highlighting areas for optimization. This study provides a detailed comparative analysis of various stack management strate- gies, offering practical recommendations tailored to specific application requirements and operational constraints. Future work will focus on refining user-level overcommit- ting mechanisms, mitigating non-deterministic behaviors, and expanding benchmark frameworks to include real-world scenarios.

</details>


### [2] [Beyond Code Pairs: Dialogue-Based Data Generation for LLM Code Translation](https://arxiv.org/abs/2512.03086)
*Le Chen,Nuo Xu,Winson Chen,Bin Lei,Pei-Hung Lin,Dunzhi Zhou,Rajeev Thakur,Caiwen Ding,Ali Jannesari,Chunhua Liao*

Main category: cs.PL

TL;DR: 开发了一种利用双LLM交互和外部反馈的自动数据生成系统，极大提升了低资源领域代码翻译的效果，尤其在C++到CUDA等难度较高任务上获得突破性进步。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在Fortran、CUDA等代码资源稀缺领域表现不佳的问题，突破高质量并行数据匮乏对代码迁移和翻译任务的制约。

Method: 提出并实现了一套自动化数据集生成流程，采用了双LLM（提问者-解答者）架构，并融合了编译器及运行时反馈的外部知识。生成的数据不仅包含传统的源码-目标代码对，还包括通过单元测试验证的译码及多轮对话记录译码优化过程。

Result: 在Fortran到C++和C++到CUDA任务分别生成了3.64k和3.93k多轮对话。模型经微调后，在C++到CUDA单元测试成功率提升了56%以上，7B开源模型在关键编译成功率等指标上显著超越更大规模闭源模型。

Conclusion: 通过高质量、多样化自动生成数据的微调，低资源代码翻译场景下的开源模型能力实现了大幅提升，展示了结合工具反馈与LLM推理的新型数据生产范式的价值。

Abstract: Large language models (LLMs) have shown remarkable capabilities in code translation, yet their performance deteriorates in low-resource programming domains such as Fortran and emerging frameworks like CUDA, where high-quality parallel data are scarce. We present an automated dataset generation pipeline featuring a dual-LLM Questioner-Solver design that incorporates external knowledge from compilers and runtime feedback. Beyond traditional source-target code pair datasets, our approach additionally generates (1) verified translations with unit tests for assessing functional consistency, and (2) multi-turn dialogues that capture the reasoning process behind translation refinement. Applied to Fortran -> C++ and C++ -> CUDA, the pipeline yields 3.64k and 3.93k dialogues, respectively. Fine-tuning on this data yields dramatic improvements in functional correctness, boosting unit test success rates by over 56% on the challenging C++-to-CUDA task. We show this data enables a 7B open-weight model to significantly outperform larger proprietary systems on key metrics like compilation success.

</details>


### [3] [OOPredictor: Predicting Object-Oriented Accesses using Static Analysis](https://arxiv.org/abs/2512.03972)
*Hassan Arafat,David Bremner,Kenneth B. Kent,Julian Wang*

Main category: cs.PL

TL;DR: 面向对象编程因其关注点分离和设计适应性成为主流，但其带来的间接寻址造成指针追踪，影响局部性并降低缓存性能。本文提出一种基于编译期静态分析的方法，用于预测程序运行时的常见访问模式，并已在OpenJ9 JVM的OMR优化器中实现。实验表明该方法预测准确，能辅助更高效的加载延迟缓解策略。


<details>
  <summary>Details</summary>
Motivation: 面向对象程序中普遍存在的指针追踪严重影响了缓存命中率，且硬件预取器难以应对，现有软件方案大多需运行时分析，开销大或需历史数据，亟需静态、高效、准确的预测机制。

Method: 利用编译期静态分析，生成程序访问模式的Markov链，模型预测能力通过与实际运行时的访问行为（借助instrumentation做监测）进行对比来评估。并将该方法集成进OpenJ9 JVM的OMR优化器架构中。

Result: 静态分析生成的Markov链预测与实际运行时模式表现出较高的一致性，可用于指导如垃圾回收器采用更有局部性的复制顺序等手段，有效提高缓存友好性并缓解加载延迟。

Conclusion: 编译期静态分析可以有效预测对象指针追踪下的访问模式，从而有助于设计出对硬件友好的运行时优化机制。该方法准确性较高，并可用于垃圾回收等场景，提高数据局部性。

Abstract: Object-oriented Programming has become one of the most dominant design paradigms as the separation of concerns and adaptability of design reduce development and maintenance costs. However, the convenience is not without cost. The added indirection inherent in such designs causes excessive pointer chasing, negatively affecting locality, which in turn degrades the performance of cache structures. Furthermore, modern hardware prefetchers are mostly stride prefetchers that are ill-equipped to handle the unpredictability of access patterns generated by pointer chasing. Most software approaches that seek to address this problem resort to profiling the program as it runs, which comes with a significant run-time overhead or requires data from previous runs. In this paper, we propose the use of compile-time static analysis to predict the most common access patterns displayed by a program during run time. Since Java is one of the most popular object-oriented languages, we implement our prototype within the OpenJ9 JVM, inside the OMR optimizer infrastructure. The outputs of our proposed predictor are Markov chains that model the expected behavior of the program. The effectiveness of the proposed predictor is evaluated by comparing the model with the actual run-time behavior of the program measured using an instrumented interpreter. Our experiments show that the proposed predictor exhibits good accuracy and can be used to inform minimally intrusive load stall mitigation strategies, e.g. informing copying GCs on more locality-friendly copying orders

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [Is Vibe Coding Safe? Benchmarking Vulnerability of Agent-Generated Code in Real-World Tasks](https://arxiv.org/abs/2512.03262)
*Songwen Zhao,Danqing Wang,Kexun Zhang,Jiaxuan Luo,Zhuo Li,Lei Li*

Main category: cs.SE

TL;DR: 本文建立基准测试LLM代理编程任务的安全性，结果发现主流模型代码输出的安全性极低，简单安全提示也无法根本改善这一问题，对在敏感场景推广应用提出了警告。


<details>
  <summary>Details</summary>
Motivation: 当前越来越多利用大语言模型（LLM）参与软件编码任务，即“vibe coding”编程范式，但业界尚不清楚其成果在实际生产环境中的安全性。本文旨在研究由LLM驱动的代码代理生成的代码在安全性方面的表现。

Method: 作者收集并建立包含200个已知易出安全漏洞的真实特性请求任务基准，并利用主流LLM编码代理进行实验性编程。然后评估所生成代码的功能正确性与安全性，并探索在请求中添加安全提示对结果的影响。

Result: 作者提出了SU S VI B E S基准，包括200个真实开源项目中的特性请求任务，这些任务已被证实人类编写时容易出现安全漏洞。评估结果显示，所有LLM代理在安全性方面表现不佳。例如，基于Claude 4 Sonnet的SWE-Agent虽有61%功能性正确，但仅有10.5%是安全的。尝试通过在请求中添加漏洞提示等初步安全措施，对安全性提升效果甚微。

Conclusion: 当前LLM驱动的“vibe coding”代码产出在安全性上存在严重隐患，特别是用于安全敏感应用时，其部署风险极高，迫切需要更有效的安全保障方法。

Abstract: Vibe coding is a new programming paradigm in which human engineers instruct large language model (LLM) agents to complete complex coding tasks with little supervision. Although it is increasingly adopted, are vibe coding outputs really safe to deploy in production? To answer this question, we propose SU S VI B E S, a benchmark consisting of 200 feature-request software engineering tasks from real-world open-source projects, which, when given to human programmers, led to vulnerable implementations. We evaluate multiple widely used coding agents with frontier models on this benchmark. Disturbingly, all agents perform poorly in terms of software security. Although 61% of the solutions from SWE-Agent with Claude 4 Sonnet are functionally correct, only 10.5% are secure. Further experiments demonstrate that preliminary security strategies, such as augmenting the feature request with vulnerability hints, cannot mitigate these security issues. Our findings raise serious concerns about the widespread adoption of vibe-coding, particularly in security-sensitive applications.

</details>


### [5] [Exploring the Potential and Limitations of Large Language Models for Novice Program Fault Localization](https://arxiv.org/abs/2512.03421)
*Hexiang Xu,Hengyuan Liu,Yonghao Wu,Xiaolan Kang,Xiang Chen,Yong Liu*

Main category: cs.SE

TL;DR: 本研究系统评估了闭源和开源LLM在故障定位中的表现。结果显示，具备推理能力的LLM模型可大幅提升定位准确率，对初学编程者帮助明显。但因推理效率和过度解释等问题，LLM实用化还需进一步完善。


<details>
  <summary>Details</summary>
Motivation: 初学者由于编程经验和对语法、逻辑理解有限，在定位代码错误时面临很大困难。传统的故障定位方法如SBFL和MBFL缺乏对代码上下文的理解，效果有限。本研究试图探索利用大语言模型（LLM）在理解程序语法、语义上的优势，帮助改善这方面问题。

Method: 本研究评估了六个闭源和七个开源LLM模型，分别在Codeflaws、Condefects、以及新构建的BugT数据集（专门为防止数据泄漏设计）上进行实验。重点比较了具有推理能力（如OpenAI o3、DeepSeekR1）与无推理能力（如GPT-4）模型的表现，并考察了提示工程、问题难度、解释过度等因素对结果的影响。

Result: 具备推理能力的先进模型（如OpenAI o3和DeepSeekR1）在几乎不需提示工程的情况下表现出众，无推理能力模型（如GPT-4）对提示设计较为依赖。LLM在简单故障定位任务上表现良好，但随着问题难度增加，准确率下降，顶级模型在BugT数据集上保持稳健表现。部分模型存在解释过度的问题，影响定位效果。此外，LLM的高计算成本是实时调试应用的障碍。

Conclusion: LLM为初学者编程调试带来了显著价值，并有潜力提升调试效率。但其推理质量需要进一步优化，与此同时要关注计算效率，才能实际推广到实时调试场景。

Abstract: Novice programmers often face challenges in fault localization due to their limited experience and understanding of programming syntax and logic. Traditional methods like Spectrum-Based Fault Localization (SBFL) and Mutation-Based Fault Localization (MBFL) help identify faults but often lack the ability to understand code context, making them less effective for beginners. In recent years, Large Language Models (LLMs) have shown promise in overcoming these limitations by utilizing their ability to understand program syntax and semantics. LLM-based fault localization provides more accurate and context-aware results than traditional techniques. This study evaluates six closed-source and seven open-source LLMs using the Codeflaws, Condefects, and BugT datasets, with BugT being a newly constructed dataset specifically designed to mitigate data leakage concerns. Advanced models with reasoning capabilities, such as OpenAI o3 and DeepSeekR1, achieve superior accuracy with minimal reliance on prompt engineering. In contrast, models without reasoning capabilities, like GPT-4, require carefully designed prompts to maintain performance. While LLMs perform well in simple fault localization, their accuracy decreases as problem difficulty increases, though top models maintain robust performance in the BugT dataset. Over-reasoning is another challenge, where some models generate excessive explanations that hinder fault localization clarity. Additionally, the computational cost of deploying LLMs remains a significant barrier for real-time debugging. LLM's explanations demonstrate significant value for novice programmer assistance, with one-year experience participants consistently rating them highly. Our findings demonstrate the potential of LLMs to improve debugging efficiency while stressing the need for further refinement in their reasoning and computational efficiency for practical adoption.

</details>


### [6] [Runnable Directories: The Solution to the Monorepo vs. Multi-repo Debate](https://arxiv.org/abs/2512.03815)
*Shayan Ghasemnezhad,Samarth KaPatel,Sofia Nikiforova,Giacinto Paolo Saggese,Paul Smith,Heanh Sok*

Main category: cs.SE

TL;DR: Causify Dev系统融合了单一和多代码库的优点，通过可运行目录和容器化流程提升大型复杂项目的开发效率和可维护性。


<details>
  <summary>Details</summary>
Motivation: 面对现代软件系统对代码库组织方式提出的新需求，现有的monorepo和multi-repo策略各有利弊。本文旨在寻求一种兼具二者优点的新方法，以应对大型复杂项目的扩展性和管理难题。

Method: 采用可运行目录（runnable directory），结合统一的薄环境、共享工具、Docker容器化和高效的CI/CD流程，实现代码库的模块化和一致性。

Result: 本文提出了Causify Dev系统，作为传统单一代码库（monorepo）与多代码库（multi-repo）策略之间的混合解决方案。其核心理念是“可运行目录”，即具有独立开发、测试和部署生命周期的自包含单元。通过统一环境、共享辅助工具以及基于Docker的容器化流程，实现了一致的开发环境、隔离的依赖和高效的持续集成/持续部署（CI/CD）。该方法在代码库一致性与可维护性方面表现突出，尤其适用于大型复杂软件项目。

Conclusion: Causify Dev方法为大型复杂代码库提供了可靠性和可维护性的提升，成为monorepo和multi-repo策略的实用中间方案。

Abstract: Modern software systems increasingly strain traditional codebase organization strategies. Monorepos offer consistency but often suffer from scalability issues and tooling complexity, while multi-repos provide modularity at the cost of coordination and dependency management challenges. As an answer to this trade-off, we present the Causify Dev system, a hybrid approach that integrates key benefits of both. Its central concept is the runnable directory -- a self-contained, independently executable unit with its own development, testing, and deployment lifecycles. Backed by a unified thin environment, shared helper utilities, and containerized Docker-based workflows, runnable directories enable consistent setups, isolated dependencies, and efficient CI/CD processes. The Causify Dev approach provides a practical middle ground between monorepo and multi-repo strategies, improving reliability and maintainability for growing, complex codebases.

</details>


### [7] [A Comprehensive Study on the Impact of Vulnerable Dependencies on Open-Source Software](https://arxiv.org/abs/2512.03868)
*Shree Hari Bittugondanahalli Indra Kumar,Lilia Rodrigues Sampaio,André Martin,Andrey Brito,Christof Fetzer*

Main category: cs.SE

TL;DR: 本文分析了1000多个开源项目约5万个发布版本的依赖安全情况，发现关键漏洞常常长时间未修复，且多为传递依赖，揭示了依赖管理和安全响应的不足。


<details>
  <summary>Details</summary>
Motivation: 随着开源库的广泛应用，安全漏洞（如Log4Shell事件）成为软件开发中的重大安全风险。理解并解决这些依赖漏洞对于保障软件供应链安全至关重要。

Method: 使用自研的SCA工具（VODA），从Github爬取2013-2023年1000多个开源项目的版本历史，统计分析依赖版本、层级、漏洞及其演化，并与项目团队特征相关联。

Result: 跨多种编程语言，易受攻击的依赖大多是传递性依赖。关键漏洞平均存在时间超过一年才被修复。此外，通过分析项目团队规模、活跃度和发布周期等指标，揭示了漏洞分布和持续性的相关性。

Conclusion: 加深了对开源项目依赖漏洞分布及修复时长的理解，当前安全工具虽能提供信息，但应加强对传递依赖和漏洞修复流程的关注。更全面的数据集提升了结论的普适性。

Abstract: Open-source libraries are widely used by software developers to speed up the development of products, however, they can introduce security vulnerabilities, leading to incidents like Log4Shell. With the expanding usage of open-source libraries, it becomes even more imperative to comprehend and address these dependency vulnerabilities. The use of Software Composition Analysis (SCA) tools does greatly help here as they provide a deep insight on what dependencies are used in a project, enhancing the security and integrity in the software supply chain. In order to learn how wide spread vulnerabilities are and how quickly they are being fixed, we conducted a study on over 1k open-source software projects with about 50k releases comprising several languages such as Java, Python, Rust, Go, Ruby, PHP, and JavaScript. Our objective is to investigate the severity, persistence, and distribution of these vulnerabilities, as well as their correlation with project metrics such as team and contributors size, activity and release cycles. In order to perform such analysis, we crawled over 1k projects from github including their version history ranging from 2013 to 2023 using VODA, our SCA tool. Using our approach, we can provide information such as library versions, dependency depth, and known vulnerabilities, and how they evolved over the software development cycle. Being larger and more diverse than datasets used in earlier works and studies, ours provides better insights and generalizability of the gained results. The data collected answers several research questions about the dependency depth and the average time a vulnerability persists. Among other findings, we observed that for most programming languages, vulnerable dependencies are transitive, and a critical vulnerability persists in average for over a year before being fixed.

</details>


### [8] [Tunable Automation in Automated Program Verification](https://arxiv.org/abs/2512.03926)
*Alexander Y. Bai,Chris Hawblitzel,Andrea Lattuada*

Main category: cs.SE

TL;DR: 本文提出了一种在SMT验证器中灵活控制量词自动化水平的机制，帮助开发者根据场景权衡自动化与性能，实验证明其有效提升了验证效率与灵活性。


<details>
  <summary>Details</summary>
Motivation: SMT求解器为基础的自动验证工具在验证复杂软件系统方面取得了显著进展，但在处理量词实例化时，自动化与性能之间存在基本矛盾。过于积极的量词实例化虽提高自动化，但导致验证耗时增加；保守策略验证快却需要人工干预。这导致SMT验证器在自动化和效率之间难以平衡。

Method: 提出一种机制，实现对验证环境中量词事实可用性的细粒度控制。该机制允许开发者针对不同模块、函数或证明上下文选择合适的自动化级别。同时，库作者可预设多种自动化等级，终端用户可根据需求进一步自定义。该方法在Rust生态的Verus验证工具中实现并在多个公开代码库上进行评估。

Result: 实验证明，通过可选择的量词管理机制，开发者能根据不同情境选择最合适的自动化水平，有效权衡自动化能力与验证性能。较优策略能显著提升验证效率，减少对人工证明提示的依赖。

Conclusion: 提出的可调量词自动化机制，有效解决了SMT验证器在自动化与性能之间的矛盾，提升了实际软件验证的灵活性和效率。该方法适用于广大采用SMT技术的软件验证场景。

Abstract: Automated verification tools based on SMT solvers have made significant progress in verifying complex software systems. However, these tools face a fundamental tension between automation and performance when dealing with quantifier instantiation -- the primary source of incompleteness and verification slowdown in SMT-based verifiers. Tools choose between aggressive quantifier instantiation that provides more automation but longer verification times, or conservative instantiation that responds quickly but may require more manual proof hints.
  We present a mechanism that enables fine-grained control over the availability of quantified facts in verification contexts, allowing developers to selectively tune the level of automation. Our approach lets library authors provide different pre-defined automation levels while giving end-users the ability to further customize quantifier availability at the module, function, or proof context level.
  We implement our techniques in Verus, a Rust-based verification tool, and evaluate them on multiple openly available codebases. Our empirical analysis demonstrates the automation-performance tradeoff and that selective quantifier management enables developers to select the appropriate level of automation in different contexts.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [9] [Hypernetwork Theory: The Structural Kernel](https://arxiv.org/abs/2512.03091)
*Richard D. Charlesworth*

Main category: cs.LO

TL;DR: 本文提出了超网络理论（HT）的结构核心，作为一种克服传统建模工具局限性的新方法。HT以n元关系为基础建模单位，并通过具类型的超单体实现关系结构，直接嵌入语义，实现结构化且可执行的多层建模框架。


<details>
  <summary>Details</summary>
Motivation: 当前工程、系统科学和形式方法领域的建模主要受限于二元关系、隐式语义和以图为中心的符号系统，难以表达多层复杂结构且不易实现自动化推理，因此需要一种新的结构性和机制化建模理论。

Method: 作者形式化了HT的符号、顶点、超单体、边界和序关系的记法与公理（A1-A5），并提出五种面向结构组成的算子（合并、求交、差异、修剪、分裂），均有确定的决策条件和算法，确保了语义一致和可机制化操作。

Result: HT实现了无须重构或依赖工具解释的多层级关系与语义表达，提出的算子算法支持模型的可复现构建、比较、分解与重组，整体提升了超网络从符号表达到结构化、可执行建模的能力。

Conclusion: HT为可机制化的多层建模提供了坚实且可扩展的理论基础，提升了模型的结构性和执行性，有望推动工程、系统科学及形式方法领域的建模与自动化水平。

Abstract: Modelling across engineering, systems science, and formal methods remains limited by binary relations, implicit semantics, and diagram-centred notations that obscure multilevel structure and hinder mechanisation. Hypernetwork Theory (HT) addresses these gaps by treating the n-ary relation as the primary modelling construct. Each relation is realised as a typed hypersimplex - alpha (conjunctive, part-whole) or beta (disjunctive, taxonomic) - bound to a relation symbol R that fixes arity and ordered roles. Semantics are embedded directly in the construct, enabling hypernetworks to represent hierarchical and heterarchical systems without reconstruction or tool-specific interpretation.
  This paper presents the structural kernel of HT. It motivates typed n-ary relational modelling, formalises the notation and axioms (A1-A5) for vertices, simplices, hypersimplices, boundaries, and ordering, and develops a complete algebra of structural composition. Five operators - merge, meet, difference, prune, and split - are defined by deterministic conditions and decision tables that ensure semantics-preserving behaviour and reconcile the Open World Assumption with closure under rules. Their deterministic algorithms show that HT supports reproducible and mechanisable model construction, comparison, decomposition, and restructuring.
  The resulting framework elevates hypernetworks from symbolic collections to structured, executable system models, providing a rigorous and extensible foundation for mechanisable multilevel modelling.

</details>


### [10] [A Cut-Free Sequent Calculus for the Analysis of Finite-Trace Properties in Concurrent Systems](https://arxiv.org/abs/2512.03164)
*Ludovico Fusco,Alessandro Aldini*

Main category: cs.LO

TL;DR: 本文提出了用于分析并发系统中有限轨迹性质的closure c3-monoid及其配套的Gentzen风格证明系统LMC，并证明了其完备性与cut elimination特性，为轨迹性质的可组合分析提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 研究如何建立一种可组合分析有限轨迹性质的证明论框架，特别针对以前缀闭包方式描述的性质，以便在并发系统中进行有效分析。

Method: 分析前缀闭包算子及其残差（关于集合包含），探讨其与语言交、并、串联的相互作用；提出closure c3-monoid作为最小代数抽象，并构建相应的分析性证明系统LMC（Gentzen风格，基于Distributive Full Lambek Calculus的无除法片段）。

Result: 证明了提出的证明系统LMC在closure c3-monoid结构下是正确且完备的，并且该系统支持cut elimination操作。

Conclusion: 作者建立了一种适用于通过前缀闭包描述的有限轨迹性质的最小代数结构，并提出了配套的分析性证明系统，理论上保证了系统的正确性、完备性与cut elimination。

Abstract: We address the problem of identifying a proof-theoretic framework that enables a compositional analysis of finite-trace properties in concurrent systems, with a particular focus on those specified via prefix-closure. To this end, we investigate the interaction of a prefix-closure operator and its residual (with respect to set-theoretic inclusion) with language intersection, union, and concatenation, and introduce the variety of closure $\ell$-monoids as a minimal algebraic abstraction of finite-trace properties to be conveniently described within an analytic proof system. Closure $\ell$-monoids are division-free reducts of distributive residuated lattices equipped with a forward diamond/backward box residuated pair of unary modal operators, where the diamond is a topological closure operator satisfying $\Diamond(x \cdot y) \leq \Diamond x \cdot \Diamond y$. As a logical counterpart to these structures, we present $\mathsf{LMC}$, a Gentzen-style system based on the division-free fragment of the Distributive Full Lambek Calculus. In $\mathsf{LMC}$, structural terms are built from formulas using Belnap-style structural operators for monoid multiplication, meet, and diamond. The rules for the modalities and the structural diamond are taken from Moortgat's system $\mathsf{NL}(\Diamond)$. We show that the calculus is sound and complete with respect to the variety of closure $\ell$-monoids and that it admits cut elimination.

</details>


### [11] [The Seifert-van Kampen Theorem via Computational Paths: A Formalized Approach to Computing Fundamental Groups](https://arxiv.org/abs/2512.03175)
*Arthur F. Ramos,Tiago M. L. de Veras,Ruy J. G. B. de Queiroz,Anjolina G. de Oliveira*

Main category: cs.LO

TL;DR: 本文将Seifert-van Kampen定理用计算路径和Lean 4形式化，实现可构造的基本群计算，重点是高等归纳类型中的推挤和可归约的路径等价。


<details>
  <summary>Details</summary>
Motivation: 提升拓扑基本群计算的可构造性和机械化形式化，解决高等归纳类型下同伦论证明的显式化和自动化问题。

Method: 采用计算路径（explicit rewrites，路径归约）方式证明Seifert-van Kampen定理，引入具有路径构造子的高等归纳类型和单词商结构，利用Lean 4实现encode-decode证明方法的机械化。

Result: 论文在计算路径的框架下形式化了Seifert-van Kampen定理，即利用计算性归约和等价证明，严格描述了空间基本群的计算方法。具体，包括将推挤（pushout）结构描述为具路径构造子的高等归纳类型，利用单词表示法给出自由积和融合自由积的商结构，并通过encode-decode方法形式化并证明了基本群的同构关系。此外，论文在Lean 4中实现了相关证明，并说明当路径等价可判定时，encode-decode方法成为完全构造性的手段。

Conclusion: 该方法实现了高等归纳类型下基本群的构造性计算和形式化证明，为可判定路径等价时机械化拓扑的基本群计算提供了新途径。

Abstract: The Seifert-van Kampen theorem computes the fundamental group of a space from the fundamental groups of its constituents. We formalize this theorem within the framework of computational paths, an approach to equality where witnesses are explicit sequences of rewrites governed by the confluent, terminating LNDEQ-TRS. Our contributions are: (i) pushouts as higher-inductive types with explicit path constructors; (ii) free products and amalgamated free products as quotients of word representations; (iii) an encode-decode proof establishing pi_1(Pushout(A, B, C), f, g) cong pi_1(A) *_{pi_1(C)} pi_1(B); and (iv) applications to the figure-eight (pi_1(S^1 v S^1) cong Z * Z) and 2-sphere (pi_1(S^2) cong 1). The framework makes coherence witnesses explicit as rewrite derivations. The development is formalized in Lean 4, where the pushout axioms and the encode map are assumed, while the decode map, amalgamation compatibility, and applications are fully mechanized (2050 lines). This demonstrates that the encode-decode method for higher-inductive types becomes fully constructive when path equality is decidable via normalization.

</details>


### [12] [Formal Analysis of the Sigmoid Function and Formal Proof of the Universal Approximation Theorem](https://arxiv.org/abs/2512.03635)
*Dustin Bryant,Jim Woodcock,Simon Foster*

Main category: cs.LO

TL;DR: 本文在Isabelle/HOL中形式化分析了Sigmoid函数，并首次机械化证明了神经网络的UAT定理，提高了AI模型的可验证性与可信度。


<details>
  <summary>Details</summary>
Motivation: 目前神经网络广泛使用Sigmoid激活函数，但其在形式化证明方面尚未被全面实现，特别是在自动化定理证明系统中的微分、单调性和极限等性质。UAT定理对于神经网络理论至关重要，但其可验证性和严格性尚未在主流的定理证明器（如Isabelle/HOL）上得到充分实现。

Method: 使用Isabelle/HOL定理证明器，对Sigmoid函数的性质进行了严格的形式化描述与证明，并利用构造性方法机械化证明了UAT定理，同时完善了实函数极限推理的工具库。

Result: 实现了Sigmoid函数的全面形式化证明，包括其单调性、光滑性和高阶导数；在Isabelle/HOL定理证明器中，首次完全机械化地构造并证明了UAT定理，展示了带Sigmoid激活的神经网络在紧致区间上可以逼近任意连续函数。此外，还改进了Isabelle/HOL关于实函数极限推理的方法。

Conclusion: 本工作显著填补了定理证明器关于神经网络基本理论的空白，加强了人工智能系统的可靠性和可验证性，对机器学习的可信理论根基建设具有积极意义。

Abstract: This paper presents a formalized analysis of the sigmoid function and a fully mechanized proof of the Universal Approximation Theorem (UAT) in Isabelle/HOL, a higher-order logic theorem prover. The sigmoid function plays a fundamental role in neural networks; yet, its formal properties, such as differentiability, higher-order derivatives, and limit behavior, have not previously been comprehensively mechanized in a proof assistant. We present a rigorous formalization of the sigmoid function, proving its monotonicity, smoothness, and higher-order derivatives. We provide a constructive proof of the UAT, demonstrating that neural networks with sigmoidal activation functions can approximate any continuous function on a compact interval. Our work identifies and addresses gaps in Isabelle/HOL's formal proof libraries and introduces simpler methods for reasoning about the limits of real functions. By exploiting theorem proving for AI verification, our work enhances trust in neural networks and contributes to the broader goal of verified and trustworthy machine learning.

</details>


### [13] [Approximate Optimal Active Learning of Decision Trees](https://arxiv.org/abs/2512.03971)
*Zunchen Huang,Chenglu Jin*

Main category: cs.LO

TL;DR: 本文提出了一种利用SAT公式和近似模型计数方法，有效主动学习未知二元决策树的策略，仅通过成员查询即可保证学习过程的严格性和收敛性。


<details>
  <summary>Details</summary>
Motivation: 主动学习决策树时需在大规模假设空间下保证形式化学习精度，避免传统枚举或启发式方法的效率与严谨性问题。

Method: 将有限深度决策树的整个假设空间符号化编码为SAT公式，采用近似模型计数（如ApproxMC）量化每次查询对假设空间缩减的影响，从而实现接近最优的查询选择，且无需枚举所有模型。对于模型计数停滞时，则采取功能等价性检查验证剩余假设是否一致。

Result: 实验证明，提出的方法能够以非常少的查询次数可靠收敛到正确决策树，同时保持易于验证和理论分析的严谨SAT框架。

Conclusion: 该方法能在仅需少量查询的情况下，可靠地收敛到正确的决策树模型，并且保留了适合于形式分析和验证的SAT基础。

Abstract: We consider the problem of actively learning an unknown binary decision tree using only membership queries, a setting in which the learner must reason about a large hypothesis space while maintaining formal guarantees. Rather than enumerating candidate trees or relying on heuristic impurity or entropy measures, we encode the entire space of bounded-depth decision trees symbolically in SAT formulas. We propose a symbolic method for active learning of decision trees, in which approximate model counting is used to estimate the reduction of the hypothesis space caused by each potential query, enabling near-optimal query selection without full model enumeration. The resulting learner incrementally strengthens a CNF representation based on observed query outcomes, and approximate model counter ApproxMC is invoked to quantify the remaining version space in a sound and scalable manner. Additionally, when ApproxMC stagnates, a functional equivalence check is performed to verify that all remaining hypotheses are functionally identical. Experiments on decision trees show that the method reliably converges to the correct model using only a handful of queries, while retaining a rigorous SAT-based foundation suitable for formal analysis and verification.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [14] [Entropy-Based Measurement of Value Drift and Alignment Work in Large Language Models](https://arxiv.org/abs/2512.03047)
*Samih Fadli*

Main category: cs.CL

TL;DR: 论文提出以伦理熵（ethical entropy）为大模型安全动态指标，开发评估与监控方法。实验证明调优能显著降低伦理熵漂移，新管道可实时预警，有助于模型持续对齐和安全。


<details>
  <summary>Details</summary>
Motivation: 传统静态安全测评无法捕捉大模型部署中的动态安全隐患（如价值漂移、越狱攻击、对齐退化）。需动态量化和实时监控模型安全表现。

Method: 提出道德行为五分类法，训练分类器评估模型语料中的伦理熵S(t)，并通过测试，量化不同模型与调优版本的伦理熵动态。构建监控管道，根据伦理熵变化率gamma_eff，在漂移超阈时自动预警。

Result: 基础模型伦理熵持续增长，调优模型可降低约80%的伦理熵漂移。提出的指标和管道能高效监控并预警模型价值漂移。

Conclusion: 利用伦理熵作为衡量语言模型对齐情况的指标，可以有效监控模型在实际部署中的价值漂移，并通过实时预警提升安全性。调优模型显著抑制伦理熵的增长。

Abstract: Large language model safety is usually assessed with static benchmarks, but key failures are dynamic: value drift under distribution shift, jailbreak attacks, and slow degradation of alignment in deployment. Building on a recent Second Law of Intelligence that treats ethical entropy as a state variable which tends to increase unless countered by alignment work, we make this framework operational for large language models. We define a five-way behavioral taxonomy, train a classifier to estimate ethical entropy S(t) from model transcripts, and measure entropy dynamics for base and instruction-tuned variants of four frontier models across stress tests. Base models show sustained entropy growth, while tuned variants suppress drift and reduce ethical entropy by roughly eighty percent. From these trajectories we estimate an effective alignment work rate gamma_eff and embed S(t) and gamma_eff in a monitoring pipeline that raises alerts when entropy drift exceeds a stability threshold, enabling run-time oversight of value drift.

</details>


### [15] [Watermarks for Embeddings-as-a-Service Large Language Models](https://arxiv.org/abs/2512.03079)
*Anudeex Shetty*

Main category: cs.CL

TL;DR: 现有EaaS水印易被同义改写攻破。新方法WET（线性变换水印）有效提升对抗同义改写的鲁棒性，验证准确率极高。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在自然语言处理领域的广泛应用，Embedding即特征提取服务（EaaS）正成为企业常用服务，但EaaS易受到黑盒仿制攻击，威胁模型的知识产权。因此，寻找有效防御仿制攻击的水印方案成为必要。

Method: 论文首先分析现有EaaS水印如何通过同义改写（paraphrasing）手段被绕过，揭示方法的不足。随后，提出了一种新的水印方法WET，其核心是对文本嵌入进行线性变换并在验证时逆变换还原嵌入，通过相似度判断所有权。该方法还进行了详细的消融实验，检验各组件和超参数的作用。

Result: 实验证明，同义改写能有效移除当前主流EaaS水印，使多数数据和攻击场景下的验证失效。新提出的WET水印技术在对抗同义改写攻击时表现出近乎完美的可验证性，有效提升了模型所有权保护能力。

Conclusion: 论文发现当前EaaS水印方案存在重大安全漏洞，并提出WET算法显著改进了模型所有权认证的安全性和有效性，对业界保护IP具有重要现实意义。

Abstract: Large Language Models (LLMs) have demonstrated exceptional capabilities in natural language understanding and generation. Based on these LLMs, businesses have started to provide Embeddings-as-a-Service (EaaS), offering feature extraction capabilities (in the form of text embeddings) that benefit downstream natural language processing tasks. However, prior research has demonstrated that EaaS is vulnerable to imitation attacks, where an attacker clones the service's model in a black-box manner without access to the model's internal workings. In response, watermarks have been added to the text embeddings to protect the intellectual property of EaaS providers by allowing them to check for model ownership. This thesis focuses on defending against imitation attacks by investigating EaaS watermarks. To achieve this goal, we unveil novel attacks and propose and validate new watermarking techniques.
  Firstly, we show that existing EaaS watermarks can be removed through paraphrasing the input text when attackers clone the model during imitation attacks. Our study illustrates that paraphrasing can effectively bypass current state-of-the-art EaaS watermarks across various attack setups (including different paraphrasing techniques and models) and datasets in most instances. This demonstrates a new vulnerability in recent EaaS watermarking techniques.
  Subsequently, as a countermeasure, we propose a novel watermarking technique, WET (Watermarking EaaS with Linear Transformation), which employs linear transformation of the embeddings. Watermark verification is conducted by applying a reverse transformation and comparing the similarity between recovered and original embeddings. We demonstrate its robustness against paraphrasing attacks with near-perfect verifiability. We conduct detailed ablation studies to assess the significance of each component and hyperparameter in WET.

</details>


### [16] [Alleviating Choice Supportive Bias in LLM with Reasoning Dependency Generation](https://arxiv.org/abs/2512.03082)
*Nan Zhuang,Wenshuo Wang,Lekai Qian,Yuxiao Wang,Boyu Cao,Qi Liu*

Main category: cs.CL

TL;DR: 本文提出了针对大型语言模型在决策评估中表现出的选择支持性偏见（CSB）的问题，设计了一种新框架RDG，通过自动生成平衡推理数据并进行微调，有效减少了此类认知偏见。


<details>
  <summary>Details</summary>
Motivation: 现有针对LLM的去偏方法主要集中在人口统计与社会偏见，尚未针对认知偏见开展系统研究。CSB可导致AI辅助决策不公正，因此需要创新性解决方案来缓解认知偏见。

Method: RDG框架自动构建均衡的推理问答对，通过显式（不）建模选项、证据及理由间的依赖关系，生成大量跨领域的QA数据，包括上下文依赖和依赖解耦两类数据，再用于对LLM进行微调。

Result: 微调后的LLM在记忆型实验中偏见减少81.5%，在评估型实验中减少94.3%，且BBQ通用基准任务性能基本不受影响，表明RDG能有效减轻CSB认知偏见。

Conclusion: 经过RDG数据微调后的LLMs在减少CSB方面表现显著优异，同时在标准基准测试上的整体能力未受到影响。这显示RDG为减少认知偏见提供了有力工具，有助于提升AI决策支持系统的公正性和可靠性。

Abstract: Recent studies have demonstrated that some Large Language Models exhibit choice-supportive bias (CSB) when performing evaluations, systematically favoring their chosen options and potentially compromising the objectivity of AI-assisted decision making. While existing debiasing approaches primarily target demographic and social biases, methods for addressing cognitive biases in LLMs remain largely unexplored. In this work, we present the first solution to address CSB through Reasoning Dependency Generation (RDG), a novel framework for generating unbiased reasoning data to mitigate choice-supportive bias through fine-tuning. RDG automatically constructs balanced reasoning QA pairs, explicitly (un)modeling the dependencies between choices, evidences, and justifications. Our approach is able to generate a large-scale dataset of QA pairs across domains, incorporating Contextual Dependency Data and Dependency Decouple Data. Experiments show that LLMs fine-tuned on RDG-generated data demonstrate a 81.5% improvement in memory-based experiments and 94.3% improvement in the evaluation-based experiment, while maintaining similar performance on standard BBQ benchmarks. This work pioneers an approach for addressing cognitive biases in LLMs and contributes to the development of more reliable AI-assisted decision support systems.

</details>


### [17] [Enhancing Job Matching: Occupation, Skill and Qualification Linking with the ESCO and EQF taxonomies](https://arxiv.org/abs/2512.03195)
*Stylianos Saroglou,Konstantinos Diamantaras,Francesco Preta,Marina Delianidi,Apostolos Benisis,Christian Johannes Meyer*

Main category: cs.CL

TL;DR: 通过大语言模型与两种链接方法，改进了职位文本与欧洲标准分类的对应，实现了更优的劳动力市场信息提取，并开放了相关代码及数据集。


<details>
  <summary>Details</summary>
Motivation: 当前劳动力市场信息分类需要更精准地将职位空缺文本与欧洲主要的标准化框架（ESCO与EQF）相结合，而现有方法在实体关联与技能提取方面存在局限。

Method: 比较句子链接（Sentence Linking）和实体链接（Entity Linking）两种方法，并开发开源工具。引入两个标注数据集，探索多种利用生成式大语言模型的技术路径。

Result: 研究比较了句子链接与实体链接两大主流方法，并发布了开源工具及专用注释数据集。利用生成式大语言模型提升了劳动力市场实体提取效果，丰富了岗位与技能的数字化研究手段。

Conclusion: 研究推动了岗位与资格实体抽取的前沿发展，并为研究工作、技能与劳动力市场叙事提供了计算基础与开放资源工具。

Abstract: This study investigates the potential of language models to improve the classification of labor market information by linking job vacancy texts to two major European frameworks: the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy and the European Qualifications Framework (EQF). We examine and compare two prominent methodologies from the literature: Sentence Linking and Entity Linking. In support of ongoing research, we release an open-source tool, incorporating these two methodologies, designed to facilitate further work on labor classification and employment discourse. To move beyond surface-level skill extraction, we introduce two annotated datasets specifically aimed at evaluating how occupations and qualifications are represented within job vacancy texts. Additionally, we examine different ways to utilize generative large language models for this task. Our findings contribute to advancing the state of the art in job entity extraction and offer computational infrastructure for examining work, skills, and labor market narratives in a digitally mediated economy. Our code is made publicly available: https://github.com/tabiya-tech/tabiya-livelihoods-classifier

</details>


### [18] [InvertiTune: High-Quality Data Synthesis for Cost-Effective Single-Shot Text-to-Knowledge Graph Generation](https://arxiv.org/abs/2512.03197)
*Faezeh Faez,Marzieh S. Tahaei,Yaochen Hu,Ali Pourranjbar,Mahdi Biparva,Mark Coates,Yingxue Zhang*

Main category: cs.CL

TL;DR: InvertiTune框架通过控制的数据生成和监督微调显著提升了Text2KG任务的效率和泛化能力，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前Text2KG方法依赖频繁调用LLM，计算开销大且易遗漏复杂关系，难以适应长文本及大规模KG构建。为提升效率和适应性，需更高质量、更具代表性的训练数据与更高效的新流程。

Method: 结合知识库子图系统提取、噪声过滤及LLM生成文本描述，生成与大KG配对的长文本数据集，并用这些数据对轻量级模型进行监督微调，用以实现单步知识图谱构建。

Result: 提出了一种名为InvertiTune的新框架，用于提升自动从文本构建知识图谱（Text2KG）的效果。该方法通过系统的数据生成管道和监督微调（SFT）相结合，利用LLM生成更符合实际场景的训练数据。实验结果显示，该框架在单次KG构建中优于未微调的大型LLM和现有主流方法，并表现出更好的跨数据集泛化能力。

Conclusion: 高质量、贴近真实场景的数据对于高效和高性能的Text2KG系统至关重要。InvertiTune通过创新的数据生成和微调流程，有效推动了该方向的发展。

Abstract: Large Language Models (LLMs) have revolutionized the ability to understand and generate text, enabling significant progress in automatic knowledge graph construction from text (Text2KG). Many Text2KG methods, however, rely on iterative LLM prompting, making them computationally expensive and prone to overlooking complex relations distributed throughout the text. To address these limitations, we propose InvertiTune, a framework that combines a controlled data generation pipeline with supervised fine-tuning (SFT). Within this framework, the data-generation pipeline systematically extracts subgraphs from large knowledge bases, applies noise filtering, and leverages LLMs to generate corresponding natural text descriptions, a task more aligned with LLM capabilities than direct KG generation from text. This pipeline enables generating datasets composed of longer texts paired with larger KGs that better reflect real-world scenarios compared to existing benchmarks, thus supporting effective SFT of lightweight models for single-shot KG construction. Experimental results on CE12k, a dataset generated using the introduced pipeline, show that InvertiTune outperforms larger non-fine-tuned LLMs as well as state-of-the-art Text2KG approaches, while also demonstrating stronger cross-dataset generalization on CrossEval-1200, a test set created from three established benchmark datasets and CE12k. These findings highlight the importance of realistic, high-quality training data for advancing efficient and high-performing Text2KG systems.

</details>


### [19] [Identifying attributions of causality in political text](https://arxiv.org/abs/2512.03214)
*Paulina Garcia-Corral*

Main category: cs.CL

TL;DR: 本文提出了一种用于政治文本中因果解释检测和解析的框架，通过训练轻量级因果语言模型，实现以因果对（原因-结果）形式输出解释，并用于大规模分析。


<details>
  <summary>Details</summary>
Motivation: 政治学中解释行为广泛存在，但系统性研究不足且现有方法零散，不便于大规模分析。作者希望用新的机器学习方法有效捕捉并结构化分析这些解释，提高研究效率和一致性。

Method: 作者训练了一个轻量级因果语言模型，用于检测并结构化抽取政治文本中的因果解释（以因果对形式），可输出用于后续分析的数据集。同时评估了该方法的标注需求、通用性和准确性。

Result: 该方法能够以较低人工标注成本、较好的泛化能力和接近人工的准确度，对政治文本中的因果解释进行自动化检测和解析，支持后续大规模的因果分析。

Conclusion: 通过轻量级因果语言模型，本文证明了大规模自动获取和分析政治解释的可行性，模型具有较低的标注需求，具备跨领域泛化能力且准确性可与人工编码相当。

Abstract: Explanations are a fundamental element of how people make sense of the political world. Citizens routinely ask and answer questions about why events happen, who is responsible, and what could or should be done differently. Yet despite their importance, explanations remain an underdeveloped object of systematic analysis in political science, and existing approaches are fragmented and often issue-specific. I introduce a framework for detecting and parsing explanations in political text. To do this, I train a lightweight causal language model that returns a structured data set of causal claims in the form of cause-effect pairs for downstream analysis. I demonstrate how causal explanations can be studied at scale, and show the method's modest annotation requirements, generalizability, and accuracy relative to human coding.

</details>


### [20] [Randomized Masked Finetuning: An Efficient Way to Mitigate Memorization of PIIs in LLMs](https://arxiv.org/abs/2512.03310)
*Kunj Joshi,David A. Smith*

Main category: cs.CL

TL;DR: 本文提出了RMFT随机掩码微调技术，有效减少了LLM模型对个人敏感信息的记忆，同时几乎不影响模型性能，并以量化框架MaxTER证明RMFT优于传统去重方法。


<details>
  <summary>Details</summary>
Motivation: 当前大模型易记忆并暴露训练数据中的个人身份信息（PII），带来严重隐私和安全风险。因此，研究如何在不影响模型性能前提下降低模型对于敏感信息的记忆能力，具有重要意义。

Method: 提出了随机掩码微调（RMFT）技术，这是一种保护隐私的微调方法。同时，提出MaxTER框架，用于评估隐私与性能之间的权衡效果。通过在Enron邮件数据集上实验，将RMFT与基线方法和去重方法进行了对比评测。

Result: 与基线微调方法相比，RMFT实现了80.81%的PII总提取率降低和80.17%的已见提取率降低，且只有5.73%的困惑度增加。RMFT在隐私保护与模型性能之间达到了更优的平衡，优于常用的去重技术。

Conclusion: RMFT是一种有效降低大模型记忆PII风险的新型微调技术，在小幅牺牲性能的前提下，极大提升了隐私安全，且优于去重方法。MaxTER框架为隐私与性能权衡提供了有力衡量工具。

Abstract: The current literature on memorization in Natural Language Models, especially Large Language Models (LLMs), poses severe security and privacy risks, as models tend to memorize personally identifying information (PIIs) from training data. We introduce Randomized Masked Fine-Tuning (RMFT), a novel privacy-preserving fine-tuning technique that reduces PII memorization while minimizing performance impact. Using the Enron Email Dataset, we demonstrate that RMFT achieves an 80.81% reduction in Total Extraction Rate and 80.17% reduction in Seen Extraction Rate compared to baseline fine-tuning, outperforming deduplication methods while maintaining only a 5.73% increase in perplexity. We present MaxTER, a Pareto-optimal evaluation framework for assessing privacy-utility tradeoffs, and show the performance of RMFT vs Deduplication by Area Under The Response Curve (AURC) metric.

</details>


### [21] [Modeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaraní](https://arxiv.org/abs/2512.03334)
*Nemika Tyagi,Nelvin Licona Guevara,Olga Kellert*

Main category: cs.CL

TL;DR: 本研究提出了LLM辅助的双语语料标注新方法，证实其能可靠识别传统需人工注解的社会语言学模式，为跨语言和资源稀缺的双语研究提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 传统双语语料库注释耗时且依赖人工，限制了大规模社会语言学和话题研究。希望借助LLM自动化流程，提高效率并拓展对低资源双语现象的分析能力。

Method: 采用大型语言模型（LLM）自动对西英和西瓜（西班牙语-瓜拉尼语）两种不同类型的双语语料库进行话题、体裁和语用功能标注，并结合人口学元数据进行系统分析。

Result: 系统分析揭示了迈阿密语料中性别、主导语言与语用功能的联系，并且明确显示巴拉圭文本中瓜拉尼语与西班牙语在正式与非正式语域中的分工。这些结果用大规模数据复制并扩展了以往的互动和社会语言学观察。

Conclusion: 大型语言模型能有效自动化双语语料的社会语言学与话题注释，推动跨语言、低资源领域的定量研究，并为传统依靠繁重人工的分析方法带来突破。

Abstract: This study presents an LLM-assisted annotation pipeline for the sociolinguistic and topical analysis of bilingual discourse in two typologically distinct contexts: Spanish-English and Spanish-Guaraní. Using large language models, we automatically labeled topic, genre, and discourse-pragmatic functions across a total of 3,691 code-switched sentences, integrated demographic metadata from the Miami Bilingual Corpus, and enriched the Spanish-Guaraní dataset with new topic annotations. The resulting distributions reveal systematic links between gender, language dominance, and discourse function in the Miami data, and a clear diglossic division between formal Guaraní and informal Spanish in Paraguayan texts. These findings replicate and extend earlier interactional and sociolinguistic observations with corpus-scale quantitative evidence. The study demonstrates that large language models can reliably recover interpretable sociolinguistic patterns traditionally accessible only through manual annotation, advancing computational methods for cross-linguistic and low-resource bilingual research.

</details>


### [22] [PERCS: Persona-Guided Controllable Biomedical Summarization Dataset](https://arxiv.org/abs/2512.03340)
*Rohan Charudatt Salvi,Chirag Chawla,Dhruv Jain,Swapnil Panigrahi,Md Shad Akhtar,Shweta Yadav*

Main category: cs.CL

TL;DR: 提出了PERCS医学摘要个性化总结数据集，提供四种受众版本和基线评测，支持未来个性化信息呈现研究。


<details>
  <summary>Details</summary>
Motivation: 现有医学文本简化资源只面向单一受众，未考虑受众医学素养和信息需求差异，亟需开发能支持个性化医学信息简化和传播的数据和方法。

Method: 收集生物医学摘要并由医生审核，为四类受众定制总结，利用自动评价指标对主流大模型进行基准测试和技术验证。

Result: 该论文提出了PERCS数据集，即针对医学文献摘要的个性化可控总结数据集。该数据集包含原始生物医学摘要及针对四类受众（普通人、医学生、非医学研究者、医学专家）定制的摘要。论文通过医生审查确保摘要的准确性和受众适配性，并采用自动评价指标对几大主流大型语言模型在该数据集上的表现进行了基准测试。技术验证显示，不同受众总结在可读性、词汇和内容深度上存在明显差异。该成果面向未来个性化医学信息服务研究提供了重要资源。

Conclusion: PERCS数据集以及相关注释和评测工具已公开，为面向不同医学素养群体的可控医学摘要和传播研究奠定了基础。

Abstract: Automatic medical text simplification plays a key role in improving health literacy by making complex biomedical research accessible to diverse readers. However, most existing resources assume a single generic audience, overlooking the wide variation in medical literacy and information needs across user groups. To address this limitation, we introduce PERCS (Persona-guided Controllable Summarization), a dataset of biomedical abstracts paired with summaries tailored to four personas: Laypersons, Premedical Students, Non-medical Researchers, and Medical Experts. These personas represent different levels of medical literacy and information needs, emphasizing the need for targeted, audience-specific summarization. Each summary in PERCS was reviewed by physicians for factual accuracy and persona alignment using a detailed error taxonomy. Technical validation shows clear differences in readability, vocabulary, and content depth across personas. Along with describing the dataset, we benchmark four large language models on PERCS using automatic evaluation metrics that assess comprehensiveness, readability, and faithfulness, establishing baseline results for future research. The dataset, annotation guidelines, and evaluation materials are publicly available to support research on persona-specific communication and controllable biomedical summarization.

</details>


### [23] [Idea-Gated Transformers: Enforcing Semantic Coherence via Differentiable Vocabulary Pruning](https://arxiv.org/abs/2512.03343)
*Darshan Fofadiya*

Main category: cs.CL

TL;DR: 本文提出了一种通过“语义门控”机制抑制主题漂移的新型Transformer架构，能有效锁定文本生成语义，提升内容一致性，且参数高效。


<details>
  <summary>Details</summary>
Motivation: 现有大规模自回归语言模型（如GPT类模型）普遍存在 '主题漂移' 问题，即在生成过程中，内容易逐渐偏离初始主题。这主要是因为NTP训练目标使模型更依赖于局部词语关联，而缺乏全局语义规划能力，虽然增大模型规模有部分缓解，但根本性问题仍未解决。

Method: 提出在标准Transformer语言模型基础上，新增一个辅助的“Idea Head”，用于预测未来上下文的词袋分布，由此产生概念向量对主词汇头输出实时门控，利用可微分的门控机制过滤语义无关词项，从而在生成过程中维持主题一致性，减少主题漂移。

Result: 在WikiText-103数据集上，提出的Idea-Gated Transformer模型在验证困惑度（perplexity）上能达到与标准GPT-2类似的表现，但在保持领域一致性（Domain Retention）方面明显优于基线模型。定性和定量分析显示，该模型能有效控制生成内容处于特定语义集群，抑制了关联性漂移，实现了更受控的文本生成，同时参数效率较高。

Conclusion: Idea-Gated Transformer通过引入辅助“想法头”和概念向量，有效缓解了主题漂移问题，实现了对生成语义的主动控制。这为更可控、高效的语言模型设计提供了新路径，对实际生成任务具有积极意义。

Abstract: Autoregressive Language Models (LLMs) trained on Next-Token Prediction (NTP) often suffer from ``Topic Drift'' where the generation wanders away from the initial prompt due to a reliance on local associations rather than global planning \citep{holtzman2019curious}. While scaling model size mitigates this \citep{brown2020language}, the fundamental myopia of the NTP objective remains. In this work, we introduce the Idea-Gated Transformer, a novel architecture that separates semantic planning from syntactic generation. We introduce an auxiliary ``Idea Head'' trained to predict the bag-of-words distribution for a future context window, creating a latent ``Concept Vector'' that actively gates the main vocabulary during generation. We propose a differentiable gating mechanism that suppresses semantically irrelevant tokens, effectively pruning the search space in real-time. Experiments on WikiText-103 demonstrate that while the Idea-Gated model achieves comparable validation perplexity to a standard GPT-2 baseline, it exhibits significantly superior Domain Retention. Qualitative and quantitative analysis reveals that the gating mechanism successfully locks generation into specific semantic clusters (e.g., Finance, Science) and resists associative drift, offering a parameter-efficient path toward more controllable language modeling.

</details>


### [24] [From Hypothesis to Premises: LLM-based Backward Logical Reasoning with Selective Symbolic Translation](https://arxiv.org/abs/2512.03360)
*Qingchuan Li,Mingyue Cheng,Zirui Liu,Daoyu Wang,Yuting Zeng,Tongxuan Liu*

Main category: cs.CL

TL;DR: 提出了一种全新的假设驱动后向逻辑推理（HBLR）框架，通过高置信度符号翻译和推理反思模块，提升了大模型的逻辑推理准确率与效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的逻辑推理多从前向逐步生成理由，但容易引发冗余路径、虚构步骤和语义漂移，导致推理低效且不可靠。为此，作者提出结合符号逻辑与反思机制的新框架，以实现更准确可靠的推理。

Method: 方法包括两阶段：（1）置信度感知符号翻译：仅将高置信内容转为一阶逻辑，不确定内容保留为自然语言，同时设有翻译反思模块保证语义准确。（2）假设后向推理：假设结论为真，递归验证前提，并通过推理反思模块发现和纠正推理缺陷。

Result: HBLR框架在五个推理基准上，准确率和效率均超越了强有力的基线方法。

Conclusion: HBLR框架有效克服了冗余推理路径、语义漂移等问题，实现了更高效和可靠的逻辑推理。实验结果证明HBLR在各类推理任务中优于现有方法。

Abstract: Logical reasoning is a core challenge in natural language understanding and a fundamental capability of artificial intelligence, underpinning scientific discovery, mathematical theorem proving, and complex decision-making. Despite the remarkable progress of large language models (LLMs), most current approaches still rely on forward reasoning paradigms, generating step-by-step rationales from premises to conclusions. However, such methods often suffer from redundant inference paths, hallucinated steps, and semantic drift, resulting in inefficient and unreliable reasoning. In this paper, we propose a novel framework, Hypothesis-driven Backward Logical Reasoning (HBLR). The core idea is to integrate confidence-aware symbolic translation with hypothesis-driven backward reasoning. In the translation phase, only high-confidence spans are converted into logical form, such as First-Order Logic (FOL), while uncertain content remains in natural language. A translation reflection module further ensures semantic fidelity by evaluating symbolic outputs and reverting lossy ones back to text when necessary. In the reasoning phase, HBLR simulates human deductive thinking by assuming the conclusion is true and recursively verifying its premises. A reasoning reflection module further identifies and corrects flawed inference steps, enhancing logical coherence. Extensive experiments on five reasoning benchmarks demonstrate that HBLR consistently outperforms strong baselines in both accuracy and efficiency.

</details>


### [25] [Nexus: Higher-Order Attention Mechanisms in Transformers](https://arxiv.org/abs/2512.03377)
*Hanting Chen,Chu Zhong,Kai Han,Yuchuan Tian,Yuchen Liang,Tianyu Guo,Xinghao Chen,Dacheng Tao,Yunhe Wang*

Main category: cs.CL

TL;DR: 提出高阶注意力网络（Hon），通过递归自注意力机制动态生成Query和Key，大幅增强Transformer表示能力，参数开销很低，并在多个任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer的一阶注意力机制由于低秩瓶颈，难以在单层内捕捉复杂、多跳关系。因此提出更具表现力的高阶递归注意力框架。

Method: 提出了一种新的高阶注意力网络（Hon），通过递归框架增强表示能力。与传统Transformer使用静态线性投影的Query和Key不同，Hon利用内部嵌套的自注意力机制动态精炼Query和Key向量，实现全局上下文的聚合和高阶相关性的建模。采用参数高效的权重共享策略，递归步骤仅带来常数级别参数开销。

Result: 理论上证明该方法能够突破常规注意力机制的线性瓶颈。实验上，在多个基准测试上优于标准Transformer。

Conclusion: 高阶注意力网络能够有效缓解传统Transformer的低秩瓶颈问题，提升多层次关系建模能力，具备实际优越性和高效性。

Abstract: Transformers have achieved significant success across various domains, relying on self-attention to capture dependencies. However, the standard first-order attention mechanism is often limited by a low-rank bottleneck, struggling to capture intricate, multi-hop relationships within a single layer. In this paper, we propose the \textbf{Higher-Order Attention Network (Hon)}, a novel architecture designed to enhance representational power through a recursive framework. Unlike standard approaches that use static linear projections for Queries and Keys, Hon dynamically refines these representations via nested self-attention mechanisms. Specifically, the Query and Key vectors are themselves outputs of inner attention loops, allowing tokens to aggregate global context and model high-order correlations \textit{prior} to the final attention computation. We enforce a parameter-efficient weight-sharing strategy across recursive steps, ensuring that this enhanced expressivity incurs $\mathcal{O}(1)$ additional parameters. We provide theoretical analysis demonstrating that our method breaks the linear bottleneck of standard attention. Empirically, Hon outperforms standard Transformers on multiple benchmarks.

</details>


### [26] [Characterizing Language Use in a Collaborative Situated Game](https://arxiv.org/abs/2512.03381)
*Nicholas Tomlin,Naitian Zhou,Eve Fleisig,Liangyuan,Chen,Téa Wright,Lauren Vinh,Laura X. Ma,Seun Eisape,Ellie French,Tingting Du,Tianjiao Zhang,Alexander Koller,Alane Suhr*

Main category: cs.CL

TL;DR: 作者收集并发布了Portal 2合作游戏环境下的大型人类对话语料库，分析并揭示了多个在复杂情景中独特的语言现象，为后续研究协作式自然语言沟通提供了重要资源。


<details>
  <summary>Details</summary>
Motivation: 大多数现有对话语料库集中在闲聊或任务导向场景，难以覆盖复杂协作、空间指代及即时沟通等实际情境中的语言现象。因此，作者希望探索更自然、更具挑战性的协作环境下的语言数据。

Method: 作者通过收集Portal 2这个受欢迎虚拟解谜游戏的合作模式中，11.5小时、共2.45万条人类配音对话组成的语料库（Portal Dialogue Corpus），并对玩家语言和行为进行分析。此外，作者对语料进行了手动和自动标注，涵盖视频、音频、转录文本与游戏状态数据。

Result: 分析发现该合作游戏中出现了复杂的空间指代、澄清与修正、临时协定形成等多种语言现象，这些在现有闲聊或任务型语料库中较少见。通过发布该多模态语料库，作者为后续研究复杂场景下协作沟通的语言模式提供了重要资源。

Conclusion: Portal Dialogue Corpus丰富了语言资源，为理解与研究复杂协作下的自然语言沟通现象提供了新的数据支持。该语料库适用于分析玩家在现实感强、非结构化环境中的语言行为，有助于推动基于实际协作任务的语言与AI研究。

Abstract: Cooperative video games, where multiple participants must coordinate by communicating and reasoning under uncertainty in complex environments, yield a rich source of language data. We collect the Portal Dialogue Corpus: a corpus of 11.5 hours of spoken human dialogue in the co-op mode of the popular Portal 2 virtual puzzle game, comprising 24.5K total utterances. We analyze player language and behavior, identifying a number of linguistic phenomena that rarely appear in most existing chitchat or task-oriented dialogue corpora, including complex spatial reference, clarification and repair, and ad-hoc convention formation. To support future analyses of language use in complex, situated, collaborative problem-solving scenarios, we publicly release the corpus, which comprises player videos, audio, transcripts, game state data, and both manual and automatic annotations of language data.

</details>


### [27] [Dual LoRA: Enhancing LoRA with Magnitude and Direction Updates](https://arxiv.org/abs/2512.03402)
*Yixing Xu,Chao Li,Xuanwu Yin,Spandan Tiwari,Dong Li,Ashish Sirasao,Emad Barsoum*

Main category: cs.CL

TL;DR: Dual LoRA方法弥补了LoRA的低秩假设不足，通过分离参数的幅值和方向，实现更高效的微调，并在多个任务与模型上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA因低秩假设常导致微调效果不理想，亟需通过结构改进提升模型对下游任务的适应性。

Method: 将LoRA的低秩矩阵分为两组，一组加ReLU提升幅值表达，另一组用sign控制方向，实现更接近全量微调的参数更新机制。

Result: 提出了Dual LoRA方法，通过将低秩矩阵分为“幅值组”和“方向组”，引入归纳偏置来优化LoRA在LLM微调中的表现。幅值组用ReLU函数控制参数更新的幅度，方向组用sign函数控制参数更新的方向。实验涵盖多个NLP任务和主流预训练模型，显示Dual LoRA在相同可训练参数量下持续优于LoRA及其变体。

Conclusion: 在参数数量不变的情况下，Dual LoRA在多种下游任务和主流模型上都优于现有LoRA及其变种。

Abstract: Low-rank adaptation (LoRA) is one of the most popular methods among parameter-efficient fine-tuning (PEFT) methods to adapt pre-trained large language models (LLMs) to specific downstream tasks. However, the model trained based on LoRA often has an unsatisfactory performance due to its low-rank assumption. In this paper, we propose a novel method called Dual LoRA to improve the performance by incorporating an inductive bias into the original LoRA. Specifically, we separate low-rank matrices into two groups: the magnitude group to control whether or not and how far we should update a parameter and the direction group to decide whether this parameter should move forward or backward, to better simulate the parameter updating process of the full fine-tuning based on gradient-based optimization algorithms. We show that this can be simply achieved by adding a ReLU function to the magnitude group and a sign function to the direction group. We conduct several experiments over a wide range of NLP tasks, including natural language generation (NLG), understanding (NLU), and commonsense reasoning datasets on GPT-2, RoBERTa, DeBERTa, and LLaMA-1/2/3 as baseline models. The results show that we consistently outperform LoRA and its state-of-the-art variants with the same number of trainable parameters.

</details>


### [28] [PretrainZero: Reinforcement Active Pretraining](https://arxiv.org/abs/2512.03442)
*Xingrun Xing,Zhiyuan Fan,Jie Lou,Guoqi Li,Jiajun Zhang,Debing Zhang*

Main category: cs.CL

TL;DR: PretrainZero提出一种无监督强化主动预训练范式，无需标签和奖励信号就能提升大模型的通用推理能力，在多个权威基准数据集上效果显著。


<details>
  <summary>Details</summary>
Motivation: 人类一直希望通过模仿人类主动学习行为，实现通用人工智能。但目前基于强化学习的模型虽在软件、数学等领域展现出专家水平，仍严重依赖可验证的奖励信号，限制了其通用推理能力的提升。

Method: 提出PretrainZero框架，采用主动学习策略从大规模预训练语料中搜索信息片段，通过自我监督和强化学习进行推理预训练，无需外部奖励信号或人工标签，从而增强基座模型的通用推理能力。

Result: PretrainZero显著提升了通用推理能力。在Wikipedia语料上从零强化预训练，Qwen3-4B-Base在MMLU-Pro、SuperGPQA和数学等基准任务上分别提升了8.43、5.96和10.60分。且这种方法无需人工标签或奖励模型，突破了“验证数据墙”。

Conclusion: PretrainZero成功实现了从领域后训练到通用预训练的迁移，显著提升了预训练基座模型的推理能力，并为后续下游强化任务提供了更强的推理基础模型。

Abstract: Mimicking human behavior to actively learning from general experience and achieve artificial general intelligence has always been a human dream. Recent reinforcement learning (RL) based large-thinking models demonstrate impressive expert-level abilities, i.e., software and math, but still rely heavily on verifiable rewards in specific domains, placing a significant bottleneck to extend the performance boundary of general reasoning capabilities. In this work, we propose PretrainZero, a reinforcement active learning framework built on the pretraining corpus to extend RL from domain-specific post-training to general pretraining. PretrainZero features the following characteristics: 1) Active pretraining: inspired by the active learning ability of humans, PretrainZero learns a unified reasoning policy to actively identify reasonable and informative contents from pretraining corpus, and reason to predict these contents by RL. 2) Self-supervised learning: without any verifiable labels, pretrained reward models, or supervised fine-tuning, we directly pretrain reasoners from 3 to 30B base models on the general Wikipedia corpus using RL, significantly breaking the verification data-wall for general reasoning. 3) Verification scaling: by tackling increasingly challenging masked spans, PretrainZero substantially enhances the general reasoning abilities of pretrained base models. In reinforcement pretraining, PretrainZero improves Qwen3-4B-Base for 8.43, 5.96 and 10.60 on MMLU-Pro, SuperGPQA and math average benchmarks. In post-training, the pretrained models can also serve as reasoning foundation models for downstream RLVR tasks.

</details>


### [29] [A Preliminary Study on the Promises and Challenges of Native Top-$k$ Sparse Attention](https://arxiv.org/abs/2512.03494)
*Di Xiu,Hongyin Tang,Bolin Rong,Lizhi Yan,Jingang Wang,Yifan Lu,Xunliang Cai*

Main category: cs.CL

TL;DR: 本文探讨了大语言模型（LLM）在长上下文建模中的计算瓶颈问题，并通过一系列实验和理论分析，验证了Top-k注意力机制在推理和训练阶段对于提升模型效率和效果的作用。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在长文本任务中的普及，其推理计算成本成为性能瓶颈，亟需寻找高效的注意力计算机制以支持多模态和智能体等复杂任务。

Method: 通过对比实验，分别分析了精确Top-k注意力解码和训练策略的效果，以及近似Top-k算法在不同精度下对下游任务性能的影响，对Lightning Indexer的准确率做了统计评估，并结合熵理论进行解释。

Result: 精确Top-k注意力在解码阶段可在多项下游任务中达到甚至超过全量注意力的性能；训练和推理阶段一致应用Top-k注意力能进一步提升模型效果；Top-k近似算法的性能与其精度呈正相关；模型训练后的低熵有助于适应Top-k解码。

Conclusion: 保持训练和推理阶段Top-k注意力操作的一致性可以充分发挥Top-k解码的潜力，显著提升模型性能。同时，低熵状态更适应Top-k解码机制。

Abstract: Large Language Models (LLMs) are increasingly prevalent in the field of long-context modeling, however, their inference computational costs have become a critical bottleneck hindering the advancement of tasks such as agents and multimodal applications. This report conducts a preliminary investigation into the effectiveness and theoretical mechanisms of the Top-$k$ Attention mechanism during both the decoding and training phases. First, we validate the effectiveness of exact Top-$k$ Decoding through extensive experimentation. Experiments demonstrate that retaining only the pivotal Keys with the highest similarity to the Query as the context window during the decoding stage achieves performance comparable to, or even surpassing, full attention on downstream tasks such as HELMET and LongBench v2. Second, we further explore the native Top-$k$ Attention training strategy. Experiments confirm that ensuring the consistency between training and inference regarding Top-$k$ Attention operations facilitates the further unlocking of Top-$k$ Decoding's potential, thereby significantly enhancing model performance. Furthermore, considering the high computational complexity of exact Top-$k$ Attention, we investigate the impact of approximate Top-$k$ algorithm precision on downstream tasks. Our research confirms a positive correlation between downstream task performance and approximation fidelity, and we provide statistical evaluations of the Lightning Indexer's precision within the DeepSeek-V3.2-Exp model. Finally, this report provides a theoretical interpretation from the perspective of Entropy. Experimental observations indicate that models subjected to Top-$k$ Attention SFT exhibit a distinct phenomenon of entropy reduction in downstream tasks, which validates the hypothesis that low-entropy states are better adapted to Top-$k$ Decoding.

</details>


### [30] [Understanding LLM Reasoning for Abstractive Summarization](https://arxiv.org/abs/2512.03503)
*Haohan Yuan,Siu Cheung Hui,Haopeng Zhang*

Main category: cs.CL

TL;DR: 本文系统性比较了8种推理策略和3种大型推理模型（LRMs）在8个不同数据集上的摘要性能，发现LLM中的推理能力并非摘要的万能钥匙。不同推理方式在总结质量与事实一致性间存在明显权衡。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs在数学、代码生成等分析性任务上推理能力突出，但其在抽象摘要任务中的真实效用尚未被系统验证。论文旨在弥补该研究空白，探索和检验推理与摘要有效性的关系。

Method: 作者将通用推理策略调整用于摘要领域，系统性地大量比较了8种推理策略与3个LRMs在8个数据集上的表现，重点评估摘要的质量和事实一致性。

Result: 实验发现明确推理策略提升文本流畅度但牺牲事实基础，隐式推理则相反。且推理预算增加并不能改善、甚至损害事实一致性，表明高质量摘要更依赖忠实的信息压缩而非复杂推理。

Conclusion: 推理能力在抽象摘要任务中的效果依赖于具体策略和应用背景，增加模型的推理预算未必提升事实一致性，提升摘要的忠实压缩能力而非创造性推理更为关键。

Abstract: While the reasoning capabilities of Large Language Models (LLMs) excel in analytical tasks such as mathematics and code generation, their utility for abstractive summarization remains widely assumed but largely unverified. To bridge this gap, we first tailor general reasoning strategies to the summarization domain. We then conduct a systematic, large scale comparative study of 8 reasoning strategies and 3 Large Reasoning Models (LRMs) across 8 diverse datasets, assessing both summary quality and faithfulness. Our findings show that reasoning is not a universal solution and its effectiveness is highly dependent on the specific strategy and context. Specifically, we observe a trade-off between summary quality and factual faithfulness: explicit reasoning strategies tend to improve fluency at the expense of factual grounding, while implicit reasoning in LRMs exhibits the inverse pattern. Furthermore, increasing an LRM's internal reasoning budget does not improve, and can even hurt, factual consistency, suggesting that effective summarization demands faithful compression rather than creative over-thinking.

</details>


### [31] [Fine-grained Narrative Classification in Biased News Articles](https://arxiv.org/abs/2512.03582)
*Zeba Afroz,Harsh Vardhan,Pawan Bhakuni,Aanchal Punia,Rajdeep Kumar,Md. Shad Akhtar*

Main category: cs.CL

TL;DR: 该论文构建了印度新闻领域首个细粒度叙事与宣传数据集，并提出两种基于大模型的层次化推理方法，在相关分类任务上明显优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有的宣传识别研究多关注表层说服技术，缺乏细粒度叙事分类和系统的多层次注释数据，尤其在印度新闻媒体环境中；文章希望更深入理解和分析偏见新闻中的叙事结构及传播方式。

Method: 提出细粒度叙事分类任务、文章偏见分类任务、说服技术识别，并开发了INDI-PROP数据集和两个基于GPT-4o-mini的多跳提示推理框架（FANTA与TPTC）用于分类。

Result: INDI-PROP数据集囊括了1266篇针对两大社会政治事件（CAA与农民抗议）的印度新闻，提供三层级注释；所提框架（FANTA/TPTC）在偏见、叙事、说服技术分类任务上较基础模型有显著提升。

Conclusion: 论文为印度偏见新闻的叙事结构与说服手法分析提供了高质量资源与创新方法，有助于推动宣传内容检测领域的精细化、多维度研究。

Abstract: Narratives are the cognitive and emotional scaffolds of propaganda. They organize isolated persuasive techniques into coherent stories that justify actions, attribute blame, and evoke identification with ideological camps. In this paper, we propose a novel fine-grained narrative classification in biased news articles. We also explore article-bias classification as the precursor task to narrative classification and fine-grained persuasive technique identification. We develop INDI-PROP, the first ideologically grounded fine-grained narrative dataset with multi-level annotation for analyzing propaganda in Indian news media. Our dataset INDI-PROP comprises 1,266 articles focusing on two polarizing socio-political events in recent times: CAA and the Farmers' protest. Each article is annotated at three hierarchical levels: (i) ideological article-bias (pro-government, pro-opposition, neutral), (ii) event-specific fine-grained narrative frames anchored in ideological polarity and communicative intent, and (iii) persuasive techniques. We propose FANTA and TPTC, two GPT-4o-mini guided multi-hop prompt-based reasoning frameworks for the bias, narrative, and persuasive technique classification. FANTA leverages multi-layered communicative phenomena by integrating information extraction and contextual framing for hierarchical reasoning. On the other hand, TPTC adopts systematic decomposition of persuasive cues via a two-stage approach. Our evaluation suggests substantial improvement over underlying baselines in each case.

</details>


### [32] [AlignCheck: a Semantic Open-Domain Metric for Factual Consistency Assessment](https://arxiv.org/abs/2512.03634)
*Ahmad Aghaebrahimian*

Main category: cs.CL

TL;DR: 提出可解释、灵活的事实一致性评估方法，在通用和临床领域有效，具备加权与复杂度控制机制。


<details>
  <summary>Details</summary>
Motivation: 受限于现有大模型容易出现事实性幻觉，且现有评估方法缺乏足够解释性不易诊断问题，尤其在临床等高风险应用领域，作者受此驱动提出更可解释、有效的事实评估框架。

Method: 方法包括将文本分解为不可再分的原子事实，采用无预定义模式的灵活机制，并引入加权评估和复杂度控制，整体提升了事实一致性的评价效果。

Result: 该论文提出了一种新的可解释评估框架，用于评估大语言模型在专业及开放领域文本中的事实一致性。该方法通过将文本分解为原子事实，并采用灵活的无模式方法，有效提升了事实评估能力。作者还引入了加权指标和复杂性控制机制，在常见和临床数据集上进行了基准测试，并公开代码促进后续研究。

Conclusion: 作者开发的框架能更准确、可解释地评估与诊断大语言模型生成文本中的事实错误，特别适用于高风险领域。该方法优于现有评估指标，支持模型针对事实一致性进行进一步训练。

Abstract: Large Language Models have significantly advanced natural language processing tasks, but remain prone to generating incorrect or misleading but plausible arguments. This issue, known as hallucination, is particularly concerning in high-stakes domains like clinical applications, where factual inaccuracies can have severe consequences. Existing evaluation metrics fail to adequately assess factual consistency and lack interpretability, making diagnosing and mitigating errors difficult. We propose an interpretable framework for factual consistency assessment for in-domain and open-domain texts to address these limitations. Our approach decomposes text into atomic facts and introduces a flexible, schema-free methodology. Unlike previous methods with an absolute metric, we incorporate a weighted metric to enhance factual evaluation. Additionally, we propose a mechanism to control assessment complexity in intricate domains. We benchmark our approach on popular general and clinical datasets and release our code to support fact-aware model training in future research.

</details>


### [33] [Generative AI Practices, Literacy, and Divides: An Empirical Analysis in the Italian Context](https://arxiv.org/abs/2512.03671)
*Beatrice Savoldi,Giuseppe Attanasio,Olga Gorodetskaya,Marta Marchiori Manerba,Elisa Bassignana,Silvia Casola,Matteo Negri,Tommaso Caselli,Luisa Bentivogli,Alan Ramponi,Arianna Muti,Nicoletta Balbo,Debora Nozza*

Main category: cs.CL

TL;DR: 意大利用户已广泛采用GenAI，其呈现多元用途并逐渐取代其他信息渠道。数字素养低导致错误辨识能力不足，且女性（尤其年长者）的使用率远低于男性，仅靠素养无法完全解释差距，需进一步教育和障碍分析。


<details>
  <summary>Details</summary>
Motivation: 虽然生成式AI有潜力促进社会发展，但其普及不均和用户对其局限性认知低，可能加剧数字鸿沟。研究旨在揭示GenAI的实际采纳情况及影响因素，关注潜在风险和性别差异。

Method: 基于1906名意大利语成年人的新调查数据，全面描绘了GenAI在意大利的采用率、使用模式和数字素养。采用实证研究，分析不同群体在工作、个人用途（包括情感支持与医疗咨询）中的GenAI使用情况。

Result: GenAI在意大利用户中的采纳度广泛，成为主要信息来源之一，甚至用于敏感任务。但由于数字素养不足，用户易受误导或难以分辨错误信息。存在显著性别鸿沟，尤其在年长用户中，女性采用和使用频率显著低于男性，虽素养为采纳主要预测因素，但无法完全解释性别差异。

Conclusion: GenAI正快速融入意大利成年人的日常与工作生活，逐步占据信息获取主渠道。但低素养及性别差距暴露出潜在风险，亟需有针对性的教育干预，并深入研究影响公平参与的其他障碍。

Abstract: The rise of Artificial Intelligence (AI) language technologies, particularly generative AI (GenAI) chatbots accessible via conversational interfaces, is transforming digital interactions. While these tools hold societal promise, they also risk widening digital divides due to uneven adoption and low awareness of their limitations. This study presents the first comprehensive empirical mapping of GenAI adoption, usage patterns, and literacy in Italy, based on newly collected survey data from 1,906 Italian-speaking adults. Our findings reveal widespread adoption for both work and personal use, including sensitive tasks like emotional support and medical advice. Crucially, GenAI is supplanting other technologies to become a primary information source: this trend persists despite low user digital literacy, posing a risk as users struggle to recognize errors or misinformation. Moreover, we identify a significant gender divide -- particularly pronounced in older generations -- where women are half as likely to adopt GenAI and use it less frequently than men. While we find literacy to be a key predictor of adoption, it only partially explains this disparity, suggesting that other barriers are at play. Overall, our data provide granular insights into the multipurpose usage of GenAI, highlighting the dual need for targeted educational initiatives and further investigation into the underlying barriers to equitable participation that competence alone cannot explain.

</details>


### [34] [Evaluating Hydro-Science and Engineering Knowledge of Large Language Models](https://arxiv.org/abs/2512.03672)
*Shiruo Hu,Wenbo Shan,Yingjia Li,Zhiqi Wan,Xinpeng Yu,Yunjia Qi,Haotian Xia,Yang Xiao,Dingxiao Liu,Jiaru Wang,Chenxu Gong,Ruixi Zhang,Shuyue Wu,Shibo Cui,Chee Hui Lai,Wei Luo,Yubin He,Bin Xu,Jianshi Zhao*

Main category: cs.CL

TL;DR: 本文提出水科学与工程领域的LLM评测基准，实验显示LLM对一般科学知识掌握较好，但对专业领域仍有不足，为模型开发和实际应用提供了方向。


<details>
  <summary>Details</summary>
Motivation: 水科学与工程（Hydro-SE）领域具有多目标、多学科交融的特点，需要专家协同决策，给智能化带来挑战。当前LLM在该领域的知识与应用能力尚未充分评估，因此需建立科学的评价体系。

Method: 提出Hydro-SE LLM评估基准（Hydro-SE Bench），包含4000道多项选择题，覆盖九个子领域，用于评估LLM在基础概念知识、工程应用能力、推理与计算能力等方面的表现。

Result: 商业LLM在评测中的准确率在0.74-0.80之间，小参数LLM在0.41-0.68之间。LLM在自然科学相关子领域表现较好，但在行业标准和水工结构等领域表现较弱。模型扩展主要提升推理与计算能力。

Conclusion: LLM在Hydro-SE领域有潜力但存在专业知识掌握不足的问题。Hydro-SE Bench基准能够有效评估与指导LLM在该领域的发展，为模型训练和领域应用提供实践和研究参考。

Abstract: Hydro-Science and Engineering (Hydro-SE) is a critical and irreplaceable domain that secures human water supply, generates clean hydropower energy, and mitigates flood and drought disasters. Featuring multiple engineering objectives, Hydro-SE is an inherently interdisciplinary domain that integrates scientific knowledge with engineering expertise. This integration necessitates extensive expert collaboration in decision-making, which poses difficulties for intelligence. With the rapid advancement of large language models (LLMs), their potential application in the Hydro-SE domain is being increasingly explored. However, the knowledge and application abilities of LLMs in Hydro-SE have not been sufficiently evaluated. To address this issue, we propose the Hydro-SE LLM evaluation benchmark (Hydro-SE Bench), which contains 4,000 multiple-choice questions. Hydro-SE Bench covers nine subfields and enables evaluation of LLMs in aspects of basic conceptual knowledge, engineering application ability, and reasoning and calculation ability. The evaluation results on Hydro-SE Bench show that the accuracy values vary among 0.74 to 0.80 for commercial LLMs, and among 0.41 to 0.68 for small-parameter LLMs. While LLMs perform well in subfields closely related to natural and physical sciences, they struggle with domain-specific knowledge such as industry standards and hydraulic structures. Model scaling mainly improves reasoning and calculation abilities, but there is still great potential for LLMs to better handle problems in practical engineering application. This study highlights the strengths and weaknesses of LLMs for Hydro-SE tasks, providing model developers with clear training targets and Hydro-SE researchers with practical guidance for applying LLMs.

</details>


### [35] [Different types of syntactic agreement recruit the same units within large language models](https://arxiv.org/abs/2512.03676)
*Daria Kryvosheieva,Andrea de Varda,Evelina Fedorenko,Greta Tuckute*

Main category: cs.CL

TL;DR: 本文揭示了大语言模型内部句法知识的表征机制：模型对句法一致类现象有专门且相互重叠的单元支持，这种机制跨多语言一致，且语言结构越相似，单元共享越多。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型能够区分语法正确和错误的句子，但其内部如何表示语法知识仍不清楚。研究动因是探索不同语法现象在模型内部是共享还是分离的表示组件。

Method: 采用受认知神经科学启发的功能定位方法，识别和分析模型中对67种英语句法现象最敏感的单元，并检验这些单元在各类语言（包括英文、俄文、中文及57种其他语言）中的反应和共享情况。

Result: 不同类型的句法一致（如主谓一致、代词一致和限定词-名词一致）在模型中会激活重叠的单元。结构相似的语言在主谓一致上共享的单元更多。这说明句法一致在模型表征空间中是一个具有实际功能意义的类别，并且这一发现在多语言、跨语言语料中得到证实。

Conclusion: 句法一致作为句法依存的关键标志，在大语言模型的表征空间中形成了具有功能意义的类别，不同语言和现象间存在系统性重叠和分布。

Abstract: Large language models (LLMs) can reliably distinguish grammatical from ungrammatical sentences, but how grammatical knowledge is represented within the models remains an open question. We investigate whether different syntactic phenomena recruit shared or distinct components in LLMs. Using a functional localization approach inspired by cognitive neuroscience, we identify the LLM units most responsive to 67 English syntactic phenomena in seven open-weight models. These units are consistently recruited across sentences containing the phenomena and causally support the models' syntactic performance. Critically, different types of syntactic agreement (e.g., subject-verb, anaphor, determiner-noun) recruit overlapping sets of units, suggesting that agreement constitutes a meaningful functional category for LLMs. This pattern holds in English, Russian, and Chinese; and further, in a cross-lingual analysis of 57 diverse languages, structurally more similar languages share more units for subject-verb agreement. Taken together, these findings reveal that syntactic agreement-a critical marker of syntactic dependencies-constitutes a meaningful category within LLMs' representational spaces.

</details>


### [36] [AITutor-EvalKit: Exploring the Capabilities of AI Tutors](https://arxiv.org/abs/2512.03688)
*Numaan Naeem,Kaushal Kumar Maurya,Kseniia Petukhova,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: AITutor-EvalKit是一款评估AI教学质量的工具，支持演示评测和数据可视化，服务于教育和语言学领域，并能收集用户反馈。


<details>
  <summary>Details</summary>
Motivation: 随着AI在教育领域的普及，亟需一种科学、高效的方法来评估其教学效果并收集用户反馈，从而推动AI导师的持续优化与发展。

Method: 该工具采用语言技术手段实现AI导师的教学质量自动化评估，同时集成软件演示、模型分析和数据可视化模块，支持用户交互与数据标注。

Result: 本文介绍了AITutor-EvalKit，这是一款利用语言技术评估AI导师教学质量的应用程序，提供教学演示、评测、模型检视和数据可视化等功能。该工具面向教育相关人员和计算语言学社区，既支持学习，又可以收集用户反馈和注释。

Conclusion: AITutor-EvalKit为教育及相关领域提供了一个多功能评估和可视化平台，有助于推动AI辅助教学及用户反馈的收集与利用。

Abstract: We present AITutor-EvalKit, an application that uses language technology to evaluate the pedagogical quality of AI tutors, provides software for demonstration and evaluation, as well as model inspection and data visualization. This tool is aimed at education stakeholders as well as *ACL community at large, as it supports learning and can also be used to collect user feedback and annotations.

</details>


### [37] [DZ-TDPO: Non-Destructive Temporal Alignment for Mutable State Tracking in Long-Context Dialogue](https://arxiv.org/abs/2512.03704)
*Yijun Liao*

Main category: cs.CL

TL;DR: 提出DZ-TDPO方法，通过动态注意力调控成功解决长上下文对话系统的状态惰性问题，在多个模型上效果优异，且无损模型其他能力。


<details>
  <summary>Details</summary>
Motivation: 长文本对话系统存在“状态惰性”问题，即由于静态约束，模型难以处理用户意图的动态变化与历史上下文间的冲突。

Method: 提出DZ-TDPO框架，结合了冲突感知的动态KL约束与可学习的时间注意力偏置，实现无损对齐。

Result: 在Multi-Session Chat数据集上，DZ-TDPO取得了最优胜率（Phi-3.5上为86.2%），同时具备强大的零样本泛化能力。规模分析显示，大模型（如Qwen2.5-7B）几乎完美对齐，且感知负担极小。

Conclusion: 通过精确的注意力调控可以减轻状态惰性，无须对模型权重进行破坏性更新，也能保持模型通用能力（MMLU），算法在各规模模型上均有效。

Abstract: Long-context dialogue systems suffer from State Inertia, where static constraints prevent models from resolving conflicts between evolving user intents and established historical context. To address this, we propose DZ-TDPO, a non-destructive alignment framework that synergizes conflict-aware dynamic KL constraints with a learnable temporal attention bias. Experiments on the Multi-Session Chat (MSC) dataset demonstrate that DZ-TDPO achieves state-of-the-art win rates (86.2% on Phi-3.5) while maintaining robust zero-shot generalization. Crucially, our scaling analysis reveals a "Capacity-Stability Trade-off": while smaller models incur an "alignment tax" (perplexity surge) to overcome historical inertia, the larger Qwen2.5-7B model achieves near-perfect alignment (99.4% win rate) with negligible perplexity overhead. This confirms that TAI can be alleviated via precise attention regulation rather than destructive weight updates, preserving general capabilities (MMLU) across model scales. Code and data are available: https://github.com/lyj20071013/DZ-TDPO

</details>


### [38] [AR-Med: Automated Relevance Enhancement in Medical Search via LLM-Driven Information Augmentation](https://arxiv.org/abs/2512.03737)
*Chuyue Wang,Jie Feng,Yuxi Wu,Hang Zhang,Zhiguo Fan,Bing Cheng,Wei Lin*

Main category: cs.CL

TL;DR: 本文提出了AR-Med框架，通过结合大语言模型与医学知识检索，提高了在线医疗平台搜索的准确性与可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统在线医疗搜索方法无法充分理解复杂用户查询，LLM虽有潜力但存在事实幻觉和专业知识空缺等挑战，亟需有效解决方案。

Method: 采用检索增强的大语言模型推理，并通过知识蒸馏将大模型压缩为更高效的学生模型，同时构建多专家标注的基准数据集评估模型。

Result: AR-Med离线准确率超93%，比原系统提升24%，显著提升了在线相关性和用户满意度。

Conclusion: AR-Med在实际部署中实现了高准确率与用户满意度，显著优于原有系统，为医疗领域LLM应用提供了可扩展范例。

Abstract: Accurate and reliable search on online healthcare platforms is critical for user safety and service efficacy. Traditional methods, however, often fail to comprehend complex and nuanced user queries, limiting their effectiveness. Large language models (LLMs) present a promising solution, offering powerful semantic understanding to bridge this gap. Despite their potential, deploying LLMs in this high-stakes domain is fraught with challenges, including factual hallucinations, specialized knowledge gaps, and high operational costs. To overcome these barriers, we introduce \textbf{AR-Med}, a novel framework for \textbf{A}utomated \textbf{R}elevance assessment for \textbf{Med}ical search that has been successfully deployed at scale on the Online Medical Delivery Platforms. AR-Med grounds LLM reasoning in verified medical knowledge through a retrieval-augmented approach, ensuring high accuracy and reliability. To enable efficient online service, we design a practical knowledge distillation scheme that compresses large teacher models into compact yet powerful student models. We also introduce LocalQSMed, a multi-expert annotated benchmark developed to guide model iteration and ensure strong alignment between offline and online performance. Extensive experiments show AR-Med achieves an offline accuracy of over 93\%, a 24\% absolute improvement over the original online system, and delivers significant gains in online relevance and user satisfaction. Our work presents a practical and scalable blueprint for developing trustworthy, LLM-powered systems in real-world healthcare applications.

</details>


### [39] [Principled RL for Diffusion LLMs Emerges from a Sequence-Level Perspective](https://arxiv.org/abs/2512.03759)
*Jingyang Ou,Jiaqi Han,Minkai Xu,Shaoxuan Xu,Jianwen Xie,Stefano Ermon,Yi Wu,Chongxuan Li*

Main category: cs.CL

TL;DR: 针对扩散式大型语言模型（dLLMs）难以直接应用以往强有力的基于强化学习（RL）的方法的问题，提出了以全序列为单位的RL优化新框架ESPO，并在多个任务上实现显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统的RL方法适用于自回归语言模型，因其能提供逐token的条件概率。而扩散式语言模型由于基于去噪的序列生成过程，缺乏这种分解，导致RL方法难以直接迁移，因此需要寻找更适用其生成结构的RL优化方式。

Method: 提出了基于ELBO的序列级策略优化方法ESPO，将序列生成视为单一动作，通过ELBO作为可计算的近似似然来优化。引入重要性比值的逐token归一化和稳健的KL散度估计，保证在大规模训练时的稳定性。

Result: 在数学推理、编程和规划等benchmark上均优于强token级基线模型，尤其在Countdown任务上获得了20-40分的大幅提升，同时在数学与编程任务中也带来了一致性改善。

Conclusion: ESPO显著提升了dLLMs在数学推理、编程和规划等任务上的表现，在一些任务上提升幅度达到20-40分，证明了全序列层面的优化策略在dLLMs中的有效性和优越性。

Abstract: Reinforcement Learning (RL) has proven highly effective for autoregressive language models, but adapting these methods to diffusion large language models (dLLMs) presents fundamental challenges. The core difficulty lies in likelihood approximation: while autoregressive models naturally provide token-level conditional probabilities essential for token-level RL objectives (e.g., GRPO), dLLMs generate sequences through iterative non-autoregressive denoising steps that lack this factorization. To address this fundamental mismatch, we propose ELBO-based Sequence-level Policy Optimization (ESPO), a principled RL framework that treats entire sequence generation as a single action and uses the ELBO as a tractable sequence-level likelihood proxy. Our method incorporates per-token normalization of importance ratios and robust KL-divergence estimation to ensure stable large-scale training. Extensive experiments on mathematical reasoning, coding, and planning tasks demonstrate that ESPO significantly outperforms token-level baselines, achieving dramatic improvements of 20-40 points on the Countdown task, while maintaining consistent gains on math and coding benchmarks. Our approach establishes sequence-level optimization as a principled and empirically effective paradigm for RL in dLLMs. Our code is available at https://github.com/ML-GSAI/ESPO.

</details>


### [40] [In-Context Representation Hijacking](https://arxiv.org/abs/2512.03771)
*Itay Yona,Amir Sarid,Michael Karasik,Yossi Gandelsman*

Main category: cs.CL

TL;DR: 本文提出了一种针对大语言模型（LLMs）的简单“语境表示劫持”攻击方法Doublespeak。该方法通过在上下文示例中系统性地用无害词替换有害关键词，使模型将无害词的内部表示逐步同化为有害词，对本应用有害语义从而规避模型安全机制。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全机制主要依赖表层关键词过滤，存在可被规避的漏洞，因此需要探索更深层的攻击方式，考察内在表示的安全性。

Method: 通过在多个上下文示例中用无害词代替有害关键词作为前缀，对模型进行输入，并利用模型解释工具追踪词语表示在各层的演变，分析语义如何被劫持。

Result: Doublespeak无需优化即可实现，能广泛适用于不同模型，对主流开源和闭源模型均有效，对Llama-3.3-70B-Instruct模型单句上下文覆盖时攻击成功率高达74%。

Conclusion: 当前主流的安全对齐方法无法防御Doublespeak攻击，未来安全对齐应深入到表示层级而非仅靠语义筛查。

Abstract: We introduce \textbf{Doublespeak}, a simple \emph{in-context representation hijacking} attack against large language models (LLMs). The attack works by systematically replacing a harmful keyword (e.g., \textit{bomb}) with a benign token (e.g., \textit{carrot}) across multiple in-context examples, provided a prefix to a harmful request. We demonstrate that this substitution leads to the internal representation of the benign token converging toward that of the harmful one, effectively embedding the harmful semantics under a euphemism. As a result, superficially innocuous prompts (e.g., ``How to build a carrot?'') are internally interpreted as disallowed instructions (e.g., ``How to build a bomb?''), thereby bypassing the model's safety alignment. We use interpretability tools to show that this semantic overwrite emerges layer by layer, with benign meanings in early layers converging into harmful semantics in later ones. Doublespeak is optimization-free, broadly transferable across model families, and achieves strong success rates on closed-source and open-source systems, reaching 74\% ASR on Llama-3.3-70B-Instruct with a single-sentence context override. Our findings highlight a new attack surface in the latent space of LLMs, revealing that current alignment strategies are insufficient and should instead operate at the representation level.

</details>


### [41] [Enhancing Instruction-Following Capabilities in Seq2Seq Models: DoLA Adaptations for T5](https://arxiv.org/abs/2512.03803)
*Huey Sun,Anabel Yong,Lorenzo Gilly,Felipe Jin*

Main category: cs.CL

TL;DR: 本文首次将DoLa对比解码方法应用于T5和FLAN-T5等编码器-解码器架构，评测其对模型指令遵循性的影响。结果显示，DoLa能在部分任务提升文本忠实度，但也可能影响其他任务表现，通过层级分析探讨了其机制。


<details>
  <summary>Details</summary>
Motivation: 对比解码是一种高效且轻量的推理方法，能够提升大型语言模型的文本生成质量。此前的方法如DoLa（Decoding by Contrastive Layers）只在解码器架构上实现，并主要研究其对事实性提升的影响。但目前尚无将此策略应用于编码器-解码器架构的工作，因此本文尝试这一创新。

Method: 本文将DoLa方法首次适配至T5和FLAN-T5等编码器-解码器模型，并系统评估其对模型指令遵循能力的影响。此外，对FLAN-T5层级逐层的logit演化进行了分析，以量化DoLa对输出概率的具体作用。

Result: 实验结果表明，DoLa在某些任务类别中能够提升文本生成的忠实度，但在其他类别却带来负面影响。

Conclusion: DoLa可以在编码器-解码器架构中实现，并在提升部分任务忠实度的同时，对某些任务类别可能产生负面作用，需要进一步分析与优化。

Abstract: Contrastive decoding is a lightweight and effective inference-time method that improves the quality of text generation in Large Language Models. However, algorithms such as DoLa (Decoding by Contrastive Layers) have only been implemented in decoder-only architectures and studied for their impact on improving factuality. This work adapts DoLa for the T5 and FLAN-T5 model families and evaluates its impact on the models' instruction following capabilities, which to our knowledge is the first implementation of a contrastive decoding strategy in an encoder-decoder architecture. Our results show that DoLa improves the faithfulness of text generation for certain categories of tasks and harms others. To understand these results, we present a layer-by-layer analysis of logit evolution in a FLAN-T5 model to quantify DoLa's impact on token output probabilities.

</details>


### [42] [Improving Alignment Between Human and Machine Codes: An Empirical Assessment of Prompt Engineering for Construct Identification in Psychology](https://arxiv.org/abs/2512.03818)
*Kylie L. Anglin,Stephanie Milan,Brittney Hernandez,Claudia Ventura*

Main category: cs.CL

TL;DR: 论文提出并实证检验五类提示工程方法，发现优化LLM分类心理学文本的关键在于精确定义、任务表达和优质示例，推荐多元生成与实证甄选提示，以提升与专家一致性。


<details>
  <summary>Details</summary>
Motivation: 当前关于提示工程的研究有限，尤其缺乏聚焦于理论驱动定义精准、预训练数据中代表性弱的心理学领域的分类场景。需要探索在此类场景下如何通过提示优化提升LLM与专家判断的一致性。

Method: 通过五种提示策略（代码本引导的提示选择、自动提示工程、角色设定、思维链推理和解释性提示），以零样本和少样本分类方式，系统评估优化大语言模型在文本分类中识别心理学构念的表现。

Result: 结果显示角色设定、思维链和解释不能完全解决错误提示导致的性能损失。最关键的是构念定义、任务表达方式以及示例的选择。采用结合代码本引导和自动工程的少样本提示，更贴近专家判断。建议多元生成和评估提示，并以训练集表现择优，最终在验证集确认。

Conclusion: 针对对专家判断高度敏感的应用场景，论文提出了一套实用、系统且理论驱动的LLM提示优化流程，建议结合人工与自动生成多种提示，并以实际性能表现选择优方案，最终在独立验证集确认，有助于提升分类任务的准确性和专家对齐度。

Abstract: Due to their architecture and vast pre-training data, large language models (LLMs) demonstrate strong text classification performance. However, LLM output - here, the category assigned to a text - depends heavily on the wording of the prompt. While literature on prompt engineering is expanding, few studies focus on classification tasks, and even fewer address domains like psychology, where constructs have precise, theory-driven definitions that may not be well represented in pre-training data. We present an empirical framework for optimizing LLM performance for identifying constructs in texts via prompt engineering. We experimentally evaluate five prompting strategies --codebook-guided empirical prompt selection, automatic prompt engineering, persona prompting, chain-of-thought reasoning, and explanatory prompting - with zero-shot and few-shot classification. We find that persona, chain-of-thought, and explanations do not fully address performance loss accompanying a badly worded prompt. Instead, the most influential features of a prompt are the construct definition, task framing, and, to a lesser extent, the examples provided. Across three constructs and two models, the classifications most aligned with expert judgments resulted from a few-shot prompt combining codebook-guided empirical prompt selection with automatic prompt engineering. Based on our findings, we recommend that researchers generate and evaluate as many prompt variants as feasible, whether human-crafted, automatically generated, or ideally both, and select prompts and examples based on empirical performance in a training dataset, validating the final approach in a holdout set. This procedure offers a practical, systematic, and theory-driven method for optimizing LLM prompts in settings where alignment with expert judgment is critical.

</details>


### [43] [Training and Evaluation of Guideline-Based Medical Reasoning in LLMs](https://arxiv.org/abs/2512.03838)
*Michael Staniek,Artem Sokolov,Stefan Riezler*

Main category: cs.CL

TL;DR: 现有医学领域的机器学习预测方法关注预测准确率，忽视了医学实践中需要的可解释性。本文提出用大型语言模型（LLMs）结合医学共识指南，提升推理过程的可解释性和准确性。


<details>
  <summary>Details</summary>
Motivation: 增强医学机器学习模型的推理可解释性，使其遵循医学领域专家共识，有助于提升医生的信任和模型临床应用价值。利用广泛的医学共识指南作为高质量规则数据源。

Method: 将医学共识指南转化成可口头表达的推理规则，与电子病历数据结合，作为LLMs微调的训练数据。实验用脓毒症定义做案例，比较一镜到底prompt的大型模型、医学文本训练模型与微调的小型模型表现，并引入时间序列预测模型的输出与LLM联用。

Result: 微调基于规则的小型模型在未见过患者数据上推导正确率几乎完美，且推理过程可自动评估。未来变量预测通过多模态（时间序列结合LLM）进一步提升效果。

Conclusion: 微调的小型LLMs在特定医学领域（如脓毒症）上，其按照医学共识指南推理和预测的表现优于仅被提示或用原始医学文本训练的大型LLMs。未来预测的泛化问题可通过与时间序列模型集成改进。

Abstract: Machine learning for early prediction in medicine has recently shown breakthrough performance, however, the focus on improving prediction accuracy has led to a neglect of faithful explanations that are required to gain the trust of medical practitioners. The goal of this paper is to teach LLMs to follow medical consensus guidelines step-by-step in their reasoning and prediction process. Since consensus guidelines are ubiquitous in medicine, instantiations of verbalized medical inference rules to electronic health records provide data for fine-tuning LLMs to learn consensus rules and possible exceptions thereof for many medical areas. Consensus rules also enable an automatic evaluation of the model's inference process regarding its derivation correctness (evaluating correct and faithful deduction of a conclusion from given premises) and value correctness (comparing predicted values against real-world measurements). We exemplify our work using the complex Sepsis-3 consensus definition. Our experiments show that small fine-tuned models outperform one-shot learning of considerably larger LLMs that are prompted with the explicit definition and models that are trained on medical texts including consensus definitions. Since fine-tuning on verbalized rule instantiations of a specific medical area yields nearly perfect derivation correctness for rules (and exceptions) on unseen patient data in that area, the bottleneck for early prediction is not out-of-distribution generalization, but the orthogonal problem of generalization into the future by forecasting sparsely and irregularly sampled clinical variables. We show that the latter results can be improved by integrating the output representations of a time series forecasting model with the LLM in a multimodal setup.

</details>


### [44] [Reconstructing KV Caches with Cross-layer Fusion For Enhanced Transformers](https://arxiv.org/abs/2512.03870)
*Hongzhan Lin,Zhiqi Bai,Xinmiao Zhang,Sen Yang,Xiang Li,Siran Yang,Yunlong Xu,Jiaheng Liu,Yongchi Zhao,Jiamang Wang,Yuchi Xu,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: FusedKV将底层和中层的关键信息融合，在LLM推理时大幅减少KV缓存内存占用，同时保持甚至提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前Transformer的KV缓存在长序列下内存消耗极大，现有跨层共享虽可缓解但效果不如同层方法。为解决KV内存瓶颈，并兼顾模型效果，需探索更合理的信息融合方式。

Method: 通过分析顶层KV信息流，发现value主要来源于底层，key则融合底层和中层。FusedKV采用可学习方式融合，并直接处理RoPE后的key；FusedKV-Lite则采用固定跨层共享方法，进一步精简I/O但略微提升困惑度。

Result: 提出了FusedKV和FusedKV-Lite两种新的KV cache结构，融合底层和中层的信息，在不同规模的LLM上实现了约50%的缓存内存降低，并且验证困惑度优于标准Transformer解码器。

Conclusion: FusedKV和FusedKV-Lite为Transformer解码器提供内存友好且高性能的架构选择，可显著降低KV缓存内存消耗并提升有效性。

Abstract: Transformer decoders have achieved strong results across tasks, but the memory required for the KV cache becomes prohibitive at long sequence lengths. Although Cross-layer KV Cache sharing (e.g., YOCO, CLA) offers a path to mitigate KV Cache bottleneck, it typically underperforms within-layer methods like GQA. To understand the root cause, we investigate the information flow of keys and values of the top-layers. Our preliminary reveals a clear distribution: values are predominantly derived from the bottom layer, while keys draw more information from both bottom and middle layers. Building upon this, we propose FusedKV, whose top-layer KV caches are a learnable fusion of the most informative ones from the bottom and middle layers. This fusion operates directly on post-RoPE keys, preserving relative positional information without the computational cost of re-applying rotary embeddings. To further improve efficiency, we propose FusedKV-Lite, an cross-layer sharing approach, where top-layer KV caches are directly derived from the bottom-layer values and the middle-layer keys. Compared to FusedKV, FusedKV-Lite reduces I/O overhead at the cost of a slight increase in perplexity. In experiments on LLMs ranging from 332M to 4B parameters, our proposed method reduce 50\% cache memory while achieving lower validation perplexity than the standard Transformer decoder, establishing it as a memory-efficient, high-performance architectural alternative.

</details>


### [45] [BERnaT: Basque Encoders for Representing Natural Textual Diversity](https://arxiv.org/abs/2512.03903)
*Ekhi Azurmendi,Joseba Fernandez de Landa,Jaione Bengoetxea,Maite Heredia,Julen Etxaniz,Mikel Zubillaga,Ander Soraluze,Aitor Soroa*

Main category: cs.CL

TL;DR: 本文针对语言模型训练数据的问题，提出应包含更丰富的语言变体，从而提升模型的鲁棒性和包容性。以巴斯克语为例，构建了涵盖标准、社交媒体和历史文本的新语料，验证多样性数据的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型训练往往过滤掉非标准文本，导致模型鲁棒性下降，并加剧语言偏见。因此，作者希望探索如何利用包含丰富语言变体的数据，提升模型表现。

Method: 作者构建了包含标准、社交媒体和历史文本的新巴斯克语语料，将BERnaT系列编码器模型分别以标准、多样化以及混合三种方式进行预训练。提出了将NLU任务分为标准与多样化子集的新评估框架，用以衡量模型的泛化能力。

Result: 在全部NLU任务（标准与多样化子集）中，模型若融合标准与丰富变体数据，其表现均优于仅用标准语料训练的模型，同时也保持了在标准测试集上的准确性。

Conclusion: 结果表明，融合标准与多样化语料训练的语言模型，在各类任务上均优于仅用标准语料训练的模型，同时并未牺牲标准基准测试的准确率。这证明了语言多样性对于通用和包容性语言模型的构建至关重要。

Abstract: Language models depend on massive text corpora that are often filtered for quality, a process that can unintentionally exclude non-standard linguistic varieties, reduce model robustness and reinforce representational biases. In this paper, we argue that language models should aim to capture the full spectrum of language variation (dialectal, historical, informal, etc.) rather than relying solely on standardized text. Focusing on Basque, a morphologically rich and low-resource language, we construct new corpora combining standard, social media, and historical sources, and pre-train the BERnaT family of encoder-only models in three configurations: standard, diverse, and combined. We further propose an evaluation framework that separates Natural Language Understanding (NLU) tasks into standard and diverse subsets to assess linguistic generalization. Results show that models trained on both standard and diverse data consistently outperform those trained on standard corpora, improving performance across all task types without compromising standard benchmark accuracy. These findings highlight the importance of linguistic diversity in building inclusive, generalizable language models.

</details>


### [46] [Is Lying Only Sinful in Islam? Exploring Religious Bias in Multilingual Large Language Models Across Major Religions](https://arxiv.org/abs/2512.03943)
*Kazi Abrab Hossain,Jannatul Somiya Mahmud,Maria Hossain Tuli,Anik Mitra,S. M. Taiabul Haque,Farig Y. Sadeque*

Main category: cs.CL

TL;DR: 本文提出了BRAND数据集（针对南亚四大宗教的双语责任规范数据集），发现多语言大模型在宗教相关任务上依然存在严重偏差，尤其是对伊斯兰教表现出更大的歧视。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在宗教敏感性问题上的偏差与误分类可能导致严重后果，尤其是多语种环境下这些偏差更为突出。为了更好识别与纠正这些问题，需要专门针对宗教情境的规范数据集与评估。

Method: 构建并发布了BRAND数据集（涵盖佛教、基督教、印度教和伊斯兰教的2400余条英文与孟加拉语的多类型提示），并用该数据集对多语言大模型进行测试，分析其在不同语言及宗教背景下的表现。

Result: 实验证明模型在英文回答中比孟加拉语表现更佳，但无论语言，针对伊斯兰教的问题中均出现更高比例的负面偏见，这种跨语言的持久偏差被清晰揭示。

Conclusion: 多语言大模型在处理宗教相关问题时存在语言间与宗教间的偏差，特别是对伊斯兰教的负面倾向显著，亟需改进以提升在宗教与灵性主题下的公平性和准确性。

Abstract: While recent developments in large language models have improved bias detection and classification, sensitive subjects like religion still present challenges because even minor errors can result in severe misunderstandings. In particular, multilingual models often misrepresent religions and have difficulties being accurate in religious contexts. To address this, we introduce BRAND: Bilingual Religious Accountable Norm Dataset, which focuses on the four main religions of South Asia: Buddhism, Christianity, Hinduism, and Islam, containing over 2,400 entries, and we used three different types of prompts in both English and Bengali. Our results indicate that models perform better in English than in Bengali and consistently display bias toward Islam, even when answering religion-neutral questions. These findings highlight persistent bias in multilingual models when similar questions are asked in different languages. We further connect our findings to the broader issues in HCI regarding religion and spirituality.

</details>


### [47] [Adapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study](https://arxiv.org/abs/2512.03976)
*Lifeng Chen,Ryan Lai,Tianming Liu*

Main category: cs.CL

TL;DR: 论文提出一种大语言模型适配低资源语言（藏语）的有效方案，通过持续预训练和有监督微调大幅提升模型的任务表现及翻译效果，并首次量化分析适配过程中的动态变化。


<details>
  <summary>Details</summary>
Motivation: 将大语言模型（LLM）适配到资源稀缺的语言（如藏语）仍面临数据稀缺和跨语言漂移的挑战。藏语为形态丰富且代表性不足的语言，亟需有效的适配方法，以提升对于低资源语言的技术支持水平。

Method: 提出两阶段适配方案：首先通过持续预训练（Continual Pretraining, CPT）建立藏语的语言基础；其次通过有监督微调（Supervised Fine-Tuning, SFT）实现任务与翻译能力的专门化。实验还采用分层分析方法，探究模型不同层在适配过程中的作用。

Result: 适配后困惑度明显降低（2.98降至1.54），中-藏翻译质量显著提升（BLEU从0.046升至0.261；chrF从2.2升至6.6）。分层分析显示，适配集中于嵌入与输出层，MLP中后期层则编码了领域专属的变换。

Conclusion: 持续预训练能够构建藏语语义基础，有监督微调使任务对齐度提升且对模型表示干扰极小。研究为多语言基础模型扩展到低资源场景提供了开放、易复现的解决方案。

Abstract: Adapting large language models (LLMs) to low-resource languages remains a major challenge due to data scarcity and cross-lingual drift. This work presents a two-stage adaptation of Qwen2.5-3B to Tibetan, a morphologically rich and underrepresented language. We employ Continual Pretraining (CPT) to establish Tibetan linguistic grounding, followed by Supervised Fine-Tuning (SFT) for task and translation specialization. Empirical evaluations demonstrate a consistent decrease in perplexity (from 2.98 $\rightarrow$ 1.54) and substantial improvements in Chinese$\rightarrow$Tibetan translation quality (BLEU: 0.046 $\rightarrow$ 0.261; chrF: 2.2 $\rightarrow$ 6.6). Layer-wise analysis across 435 layers in Qwen3-4B reveals that adaptation primarily concentrates on embedding and output heads, with mid--late MLP projections encoding domain-specific transformations. Our findings suggest that CPT constructs a Tibetan semantic manifold while SFT sharpens task alignment with minimal representational disruption. This study provides the first quantitative exploration of Tibetan adaptation dynamics for LLMs, and offers an open, reproducible framework for extending multilingual foundation models to low-resource settings.

</details>


### [48] [Teaching Old Tokenizers New Words: Efficient Tokenizer Adaptation for Pre-trained Models](https://arxiv.org/abs/2512.03989)
*Taido Purason,Pavel Chizhov,Ivan P. Yamshchikov,Mark Fishel*

Main category: cs.CL

TL;DR: 本文提出了两种用于自适应预训练语言模型分词器的新方法：持续的BPE训练扩展词表，以及基于叶子的词汇剪枝，并将其开源。实验表明，这能提高分词效率和词汇利用率，同时保持模型质量。


<details>
  <summary>Details</summary>
Motivation: 传统词表扩展方法容易产生不可达或极少使用的词汇，导致分词效率低下，且词表结构冗余。为有效将预训练模型迁移到新领域或新语言，亟需更好的词表扩展和剪枝方法。

Method: 方法包括：1）持续BPE训练——在新领域语料上继续BPE合并过程，扩展和优化原词表；2）叶式词汇剪枝——通过剪除冗余的词汇，优化词表结构，同时保持模型质量。

Result: 在多种语言和模型上实验证明，持续BPE训练能提升分词效率和新增词汇的利用率，叶式词汇剪枝在不降低模型性能的前提下有效减少冗余词汇。两种方法已作为开源工具发布。

Conclusion: 持续的BPE训练和叶式词汇剪枝能够有效改进分词器在新领域或新语言中的词表扩展和冗余词汇移除，为预训练语言模型迁移提供了更好的工具和性能保障。

Abstract: Tokenizer adaptation plays an important role in transferring pre-trained language models to new domains or languages. In this work, we address two complementary aspects of this process: vocabulary extension and pruning. The common approach to extension trains a new tokenizer on domain-specific text and appends the tokens that do not overlap with the existing vocabulary, which often results in many tokens that are unreachable or never used. We propose continued BPE training, which adapts a pre-trained tokenizer by continuing the BPE merge learning process on new data. Experiments across multiple languages and model families show that this approach improves tokenization efficiency and leads to better utilization of added vocabulary. We also introduce leaf-based vocabulary pruning, which removes redundant tokens while preserving model quality. Together, these methods provide practical tools for controlled vocabulary modification, which we release as an open-source package.

</details>


### [49] [AugServe: Adaptive Request Scheduling for Augmented Large Language Model Inference Serving](https://arxiv.org/abs/2512.04013)
*Ying Wang,Zhen Jin,Jiexiong Xu,Wenhai Lin,Yiquan Chen,Wenzhi Chen*

Main category: cs.CL

TL;DR: AugServe通过自适应调度和动态批量机制，解决现有增强型LLM推理服务在排队延时和吞吐量方面的瓶颈，大幅提升推理效率与用户体验。


<details>
  <summary>Details</summary>
Motivation: 随着LLM与外部工具集成在Web应用中普及，推理服务必须在延迟限制下最大化并发处理能力。现有系统因FCFS排队和静态批量机制，难以应对动态负载，影响服务质量和用户体验，急需优化推理调度与资源分配策略。

Method: 提出了AugServe，一个包含两阶段自适应调度的新型推理框架。第一阶段结合推理请求特征优化调度顺序，第二阶段基于系统实时信息动态微调决策。同时根据硬件及负载情况动态调整token批量机制。通过实验验证各项性能提升。

Result: AugServe显著提高了增强型大语言模型（LLM）推理服务的有效吞吐量，实验结果显示AugServe相比主流系统（如vLLM和InferCept）最高吞吐提升33.1倍，同时可极大缩短用户首字生成延时（TTFT），最多降低96%。

Conclusion: AugServe通过两阶段自适应请求调度及动态批量调整，有效缓解排队延时及资源利用不足问题，在多种负载下显著优于现有方案，是提升增强型LLM推理服务效率的有前景方法。

Abstract: As augmented large language models (LLMs) with external tools become increasingly popular in web applications, improving augmented LLM inference serving efficiency and optimizing service-level objectives (SLOs) are critical for enhancing user experience. To achieve this, inference systems must maximize request handling within latency constraints, referred to as increasing effective throughput. However, existing systems face two major challenges: (i) reliance on first-come-first-served (FCFS) scheduling causes severe head-of-line blocking, leading to queuing delays exceeding the SLOs for many requests; and (ii) static batch token limit, which fails to adapt to fluctuating loads and hardware conditions. Both of these factors degrade effective throughput and service quality.
  This paper presents AugServe, an efficient inference framework designed to reduce queueing latency and enhance effective throughput for augmented LLM inference services. The core idea of AugServe is a two-stage adaptive request scheduling strategy. Specifically, AugServe combines the inference features of augmented LLM requests to optimize the order of scheduling decisions (stage I). These decisions are continuously refined with runtime information (stage II), adapting to both request characteristics and system capabilities. In addition, AugServe dynamically adjusts the token batching mechanism based on hardware status and real-time load, further enhancing throughput performance. Experimental results show that AugServe achieves 4.7-33.1x and 3.3-13.2x higher effective throughput than vLLM and InferCept, while reducing time-to-first-token (TTFT) by up to 96.3% and 95.0%, respectively.

</details>


### [50] [Jina-VLM: Small Multilingual Vision Language Model](https://arxiv.org/abs/2512.04032)
*Andreas Koukounas,Georgios Mastrapas,Florian Hönicke,Sedigheh Eslami,Guillaume Roncari,Scott Martens,Han Xiao*

Main category: cs.CL

TL;DR: Jina-VLM是一种拥有24亿参数的视觉-语言模型，在多语言视觉问答任务上表现优异，超过同类开源2B规模模型。


<details>
  <summary>Details</summary>
Motivation: 推动多语言、任意分辨率视觉问答能力，同时保持高效和竞争力的文本任务性能。

Method: 该模型采用SigLIP2作为视觉编码器，Qwen3作为语言底座，通过注意力池化连接器高效地处理任意分辨率图像的token。

Result: 在主流视觉问答和多语言评测中，Jina-VLM的表现超过了同类2B规模开源模型。

Conclusion: Jina-VLM在视觉问答基准和多语言评测中表现优越，并且在仅文本任务上也保持了良好表现。

Abstract: We present Jina-VLM, a 2.4B parameter vision-language model that achieves state-of-the-art multilingual visual question answering among open 2B-scale VLMs. The model couples a SigLIP2 vision encoder with a Qwen3 language backbone through an attention-pooling connector that enables token-efficient processing of arbitrary-resolution images. Across standard VQA benchmarks and multilingual evaluations, Jina-VLM outperforms comparable models while preserving competitive text-only performance.

</details>


### [51] [SkillFactory: Self-Distillation For Learning Cognitive Behaviors](https://arxiv.org/abs/2512.04072)
*Zayne Sprague,Jack Lu,Manya Wadhwa,Sedrick Keh,Mengye Ren,Greg Durrett*

Main category: cs.CL

TL;DR: SkillFactory方法可通过SFT预训练让模型习得新认知技能，后续RL提升泛化与鲁棒性，无需依赖更强教师模型蒸馏。


<details>
  <summary>Details</summary>
Motivation: 基础语言模型未必具备复杂认知技能，难以通过RL自然习得。希望在RL前通过SFT阶段让模型预先获得这些能力，为后续强化学习奠定基础。

Method: 提出SkillFactory方法，先用SFT训练模型初步学习认知技能，然后进入RL阶段进一步强化这些技能。SkillFactory利用模型自身生成的数据，并将其重组为“银”标准训练样本，让模型在无须强模型蒸馏的情况下掌握相关技能。

Result: SkillFactory初始化后，再进行RL，模型能更好泛化到更难任务，并在跨域任务中表现更鲁棒，明显优于只用基模型进行RL的方式。模型也确实学会并使用了认知技能。

Conclusion: 在RL前引入SkillFactory SFT，有助于模型习得稳健的认知技能，提高模型泛化能力和抵抗退化表现，验证了先验诱导偏置的重要性。

Abstract: Reasoning models leveraging long chains of thought employ various cognitive skills, such as verification of their answers, backtracking, retrying by an alternate method, and more. Previous work has shown that when a base language model exhibits these skills, training that model further with reinforcement learning (RL) can learn to leverage them. How can we get models to leverage skills that aren't exhibited by base models? Our work, SkillFactory, is a method for fine-tuning models to roughly learn these skills during a supervised fine-tuning (SFT) stage prior to RL. Our approach does not rely on distillation from a stronger model, but instead uses samples from the model itself, rearranged to provide training data in the format of those skills. These "silver" SFT traces may be imperfect, but are nevertheless effective for priming a model to acquire skills during RL. Our evaluation shows that (1) starting from SkillFactory SFT initialization helps a model to generalize to harder variants of a task post-RL, despite lower performance pre-RL; (2) cognitive skills are indeed used by the model; (3) RLed SkillFactory models are more robust to regression on out-of-domain tasks than RLed base models. Our work suggests that inductive biases learned prior to RL help models learn robust cognitive skill use.

</details>
