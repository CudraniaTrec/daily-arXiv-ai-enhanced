<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 6]
- [cs.SE](#cs.SE) [Total: 18]
- [cs.CL](#cs.CL) [Total: 28]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Compiling to recurrent neurons](https://arxiv.org/abs/2511.14953)
*Joey Velez-Ginorio,Nada Amin,Konrad Kording,Steve Zdancewic*

Main category: cs.PL

TL;DR: 提出Cajal语言以支持可微分编程中的离散结构（迭代），将迭代编译为循环神经元，实现相关网络在学习速度与数据利用上的提升，拓宽了神经网络与程序结构的结合。


<details>
  <summary>Details</summary>
Motivation: 在可微分编程中，离散结构因缺乏显式的导数支持而难以直接参与梯度学习，这限制了我们能够表达的可微分算法类型，并且限制了神经网络的构建方式。作者希望解决这一局限。

Method: 提出了一种带有迭代、极简、强类型、高阶和线性编程语言Cajal($\mathbb{\multimap}, \mathbb{2}, \mathbb{N}$)，并证明该语言的程序可正确编译为循环神经元，使得离散算法可转化为兼容梯度学习的可微分形式。

Result: 通过实现并进行两组实验，将编译后的循环神经元与神经网络结合，用于解决迭代图像变换任务。结果表明相比不具备一等迭代功能的网络，该方法可以加快学习速度，提高数据效率。

Conclusion: 本工作证明了离散结构（如迭代）可以作为一等公民参与可微分编程，通过将其编译为可微分形式（循环神经元），不仅丰富了神经网络的表达能力，还提升了神经网络的学习效果与效率，打破了此前离散结构限制可微分程序表达的壁垒。

Abstract: Discrete structures are currently second-class in differentiable programming. Since functions over discrete structures lack overt derivatives, differentiable programs do not differentiate through them and limit where they can be used. For example, when programming a neural network, conditionals and iteration cannot be used everywhere; they can break the derivatives necessary for gradient-based learning to work. This limits the class of differentiable algorithms we can directly express, imposing restraints on how we build neural networks and differentiable programs more generally. However, these restraints are not fundamental. Recent work shows conditionals can be first-class, by compiling them into differentiable form as linear neurons. Similarly, this work shows iteration can be first-class -- by compiling to linear recurrent neurons. We present a minimal typed, higher-order and linear programming language with iteration called $\textsf{Cajal}\scriptstyle(\mathbb{\multimap}, \mathbb{2}, \mathbb{N})$. We prove its programs compile correctly to recurrent neurons, allowing discrete algorithms to be expressed in a differentiable form compatible with gradient-based learning. With our implementation, we conduct two experiments where we link these recurrent neurons against a neural network solving an iterative image transformation task. This determines part of its function prior to learning. As a result, the network learns faster and with greater data-efficiency relative to a neural network programmed without first-class iteration. A key lesson is that recurrent neurons enable a rich interplay between learning and the discrete structures of ordinary programming.

</details>


### [2] [Compiling Set Queries into Work-Efficient Tree Traversals](https://arxiv.org/abs/2511.15000)
*Alexander J Root,Christophe Gyurgyik,Purvi Goel,Kayvon Fatahalian,Jonathan Ragan-Kelley,Andrew Adams,Fredrik Kjolstad*

Main category: cs.PL

TL;DR: 本文提出利用符号区间分析自动推导树结构查询中剪枝和包含条件，实现复合查询融合，并自动生成高效的树遍历和连接操作，显著提升了查询优化的自动化和性能。


<details>
  <summary>Details</summary>
Motivation: 树结构通常通过存储元数据来加速大规模数据集合上的查询，实现子树的快速剪枝或包含。但现有系统需要针对每种查询谓词和数据结构手动实现剪枝逻辑，开发效率低且缺乏通用性。

Method: 提出一种通用且自动化的方法，通过符号区间分析以及扩展的几何谓词处理规则，从节点元数据自动推导可剪枝（或整体包含）子树的条件。编译器还将复合查询自动融合为单次树遍历，并支持自动推导单索引和双索引的树连接，涵盖多类连接谓词。

Result: 自动生成的树遍历操作不仅与专家手写代码的行为一致，还能在大多数查询场景下优于顺序扫描和嵌套循环连接，尤其在未有针对性的手写优化时表现更好。

Conclusion: 该方法实现了树结构查询优化的自动化和泛化，提升了性能和开发效率，为支持多样化查询谓词提供了有效的技术方案。

Abstract: Trees can accelerate queries that search or aggregate values over large collections. They achieve this by storing metadata that enables quick pruning (or inclusion) of subtrees when predicates on that metadata can prove that none (or all) of the data in a subtree affect the query result. Existing systems implement this pruning logic manually for each query predicate and data structure. We generalize and mechanize this class of optimization. Our method derives conditions for when subtrees can be pruned (or included wholesale), expressed in terms of the metadata available at each node. We efficiently generate these conditions using symbolic interval analysis, extended with new rules to handle geometric predicates (e.g., intersection, containment). Additionally, our compiler fuses compound queries (e.g., reductions on filters) into a single tree traversal. These techniques enable the automatic derivation of generalized single-index and dual-index tree joins that support a wide class of join predicates beyond standard equality and range predicates. The generated traversals match the behavior of expert-written code that implements query-specific traversals, and can asymptotically outperform the linear scans and nested-loop joins that existing systems fall back to when hand-written cases do not apply.

</details>


### [3] [Data Layout Polymorphism for Bounding Volume Hierarchies](https://arxiv.org/abs/2511.15028)
*Christophe Gyurgyik,Alexander J Root,Fredrik Kjolstad*

Main category: cs.PL

TL;DR: 本文提出了Scion，一种用于描述BVH数据布局的专用语言，通过将布局与算法遍历分离，实现了性能和可移植性的双重优化，发现并验证了多场景下的最优布局策略。


<details>
  <summary>Details</summary>
Motivation: 目前BVH等加速结构在性能优化时，数据布局与算法遍历逻辑紧密交织，限制了性能、可移植性及独立优化的空间。需要一种能够分离布局和遍历算法的方法来突破上述限制。

Method: 提出了一种新型的领域特定语言Scion，用于将BVH的数据布局与遍历逻辑解耦，并通过编译优化实现布局的灵活表达和系统化探索。

Result: Scion作为解决方案，不仅能表达丰富的布局优化，还能实现对不同算法、体系结构及工作负载下的Pareto最优布局，并发现了一种新的适用于光线追踪的高效布局。

Conclusion: Scion能够从数据布局的角度提升树结构的性能，并实现性能与可移植性的优化平衡，且能发现具有广泛适用性的Pareto最优布局。

Abstract: Bounding volume hierarchies are ubiquitous acceleration structures in graphics, scientific computing, and data analytics. Their performance depends critically on data layout choices that affect cache utilization, memory bandwidth, and vectorization -- increasingly dominant factors in modern computing. Yet, in most programming systems, these layout choices are hopelessly entangled with the traversal logic. This entanglement prevents developers from independently optimizing data layouts and algorithms across different contexts, perpetuating a false dichotomy between performance and portability. We introduce Scion, a domain-specific language and compiler for specifying the data layouts of bounding volume hierarchies independent of tree traversal algorithms. We show that Scion can express a broad spectrum of layout optimizations used in high performance computing while remaining architecture-agnostic. We demonstrate empirically that Pareto-optimal layouts (along performance and memory footprint axes) vary across algorithms, architectures, and workload characteristics. Through systematic design exploration, we also identify a novel ray tracing layout that combines optimization techniques from prior work, achieving Pareto-optimality across diverse architectures and scenes.

</details>


### [4] [Cement2: Temporal Hardware Transactions for High-Level and Efficient FPGA Programming](https://arxiv.org/abs/2511.15073)
*Youwei Xiao,Zizhang Luo,Weijie Peng,Yuyang Zou,Yun Liang*

Main category: cs.PL

TL;DR: 引入时序硬件事务新抽象，展开为Rust嵌入式Cement2语言，兼具高抽象和时序控制，且在主流FPGA应用中性能与资源利用率优异。


<details>
  <summary>Details</summary>
Motivation: 现有RTL和高层合成设计方法在抽象与低层细节控制间难以平衡，影响生产力和行为正确性，特别是在FPGA编程中缺乏对多周期时序行为的直观和高层描述。

Method: 提出了一种新的时序硬件事务抽象，并在Rust语言中实现了嵌入式事务HDL Cement2，支持多时钟周期规则同时优化硬件生成过程。

Result: 使用Cement2实现了RISC-V软核处理器、定制CPU指令、线性代数核和阵列加速器，获得了与手工RTL相近甚至更优的性能和资源占用。

Conclusion: Cement2结合了高层抽象与时序控制，实现了高效率且资源利用率不低于手写RTL，适用于广泛FPGA任务。

Abstract: Hardware design faces a fundamental challenge: raising abstraction to improve productivity while maintaining control over low-level details like cycle accuracy. Traditional RTL design in languages like SystemVerilog composes modules through wiring-style connections that provide weak guarantees for behavioral correctness. While high-level synthesis (HLS) and emerging abstractions attempt to address this, they either introduce unpredictable overhead or restrict design generality. Although transactional HDLs provide a promising foundation by lifting design abstraction to atomic and composable rules, they solely model intra-cycle behavior and do not reflect the native temporal design characteristics, hindering applicability and productivity for FPGA programming scenarios.
  We propose temporal hardware transactions, a new abstraction that brings cycle-level timing awareness to designers at the transactional language level. Our approach models temporal relationships between rules and supports the description of rules whose actions span multiple clock cycles, providing intuitive abstraction to describe multi-cycle architectural behavior. We implement this in Cement2, a transactional HDL embedded in Rust, enabling programming hardware constructors to build both intra-cycle and temporal transactions. Cement2's synthesis framework lowers description abstraction through multiple analysis and optimization phases, generating efficient hardware. With Cement2's abstraction, we program a RISC-V soft-core processor, custom CPU instructions, linear algebra kernels, and systolic array accelerators, leveraging the high-level abstraction for boosted productivity. Evaluation shows that Cement2 does not sacrifice performance and resources compared to hand-coded RTL designs, demonstrating the high applicability for general FPGA design tasks.

</details>


### [5] [SkyEgg: Joint Implementation Selection and Scheduling for Hardware Synthesis using E-graphs](https://arxiv.org/abs/2511.15323)
*Youwei Xiao,Yuyang Zou,Yun Liang*

Main category: cs.PL

TL;DR: SkyEgg框架通过e-graph联合优化实现选择与调度，采用MILP模型和启发式算法，相较于主流工具在FPGA上实现了大幅性能提升。


<details>
  <summary>Details</summary>
Motivation: 目前的硬件高层描述综合方法存在局限，特别是在设计决策（如实现选择和调度）上是顺序、割裂地进行，导致难以充分利用现代FPGA的异构架构。现有方法分别处理实现选择和调度，忽略了互相的影响，造成性能低下。

Method: 提出了SkyEgg框架，利用e-graph数据结构，将代数变换与硬件实现选择统一为重写规则，通过equality saturation对输入程序生成饱和e-graph，最后将联合优化问题建模为混合整数线性规划（MILP），并提供精确求解和高效ASAP启发式方法。

Result: 在针对Xilinx Kintex UltraScale+ FPGA的多种应用基准测试中，SkyEgg平均性能提升3.01倍，复杂表达式场景下最高提升5.22倍，相较于主流Vitis HLS工具。

Conclusion: 通过联合优化实现选择与调度，SkyEgg能够显著提升硬件综合性能，充分利用FPGA异构架构，在多个实际应用场景下效果优越。

Abstract: Hardware synthesis from high-level descriptions remains fundamentally limited by the sequential optimization of interdependent design decisions. Current methodologies, including state-of-the-art high-level synthesis (HLS) tools, artificially separate implementation selection from scheduling, leading to suboptimal designs that cannot fully exploit modern FPGA heterogeneous architectures. Implementation selection is typically performed by ad-hoc pattern matching on operations, a process that does not consider the impact on scheduling. Subsequently, scheduling algorithms operate on fixed selection solutions with inaccurate delay estimates, which misses critical optimization opportunities from appropriately configured FPGA blocks like DSP slices.
  We present SkyEgg, a novel hardware synthesis framework that jointly optimizes implementation selection and scheduling using the e-graph data structure. Our key insight is that both algebraic transformations and hardware implementation choices can be uniformly represented as rewrite rules within an e-graph, modeling the complete design space of implementation candidates to be selected and scheduled together. First, SkyEgg constructs an e-graph from the input program. It then applies both algebraic and implementation rewrites through equality saturation. Finally, it formulates the joint optimization as a mixed-integer linear programming (MILP) problem on the saturated e-graph. We provide both exact MILP solving and an efficient ASAP heuristic for scalable synthesis. Our evaluation on benchmarks from diverse applications targeting Xilinx Kintex UltraScale+ FPGAs demonstrates that SkyEgg achieves an average speedup of 3.01x over Vitis HLS, with improvements up to 5.22x for complex expressions.

</details>


### [6] [Graph Rewriting Language as a Platform for Quantum Diagrammatic Calculi](https://arxiv.org/abs/2511.15581)
*Kayo Tei,Haruto Mishina,Naoki Yamamoto,Kazunori Ueda*

Main category: cs.PL

TL;DR: 作者提出基于通用图重写语言LMNtal的新平台，有效支持量子电路的ZX演算优化、可视化和验证，展现了在理解和设计优化路径上的独特优势。


<details>
  <summary>Details</summary>
Motivation: 量子电路优化路径的系统发现仍具有挑战性，目前主要方法如ZX演算模型与相关工具，虽有特定领域支持，但仍存在局限。

Method: 采用通用的分层图重写语言LMNtal，并结合QLMNtal扩展，实现对ZX图的本地转换、模式匹配与状态空间探索，构建量子电路图形化转换和验证平台。

Result: 该方法具有三大优势：原生图转换规则可直接执行ZX变换、量化模式匹配简化规则书写、可交互地探索和验证优化路。案例研究证明该方法有助于理解优化路径，并可设计新算法与策略。

Conclusion: LMNtal及其工具链为量子电路转换提供了新的平台与视角，显示出其在量子电路优化领域的潜力。

Abstract: Systematic discovery of optimization paths in quantum circuit simplification remains a challenge. Today, ZX-calculus, a computing model for quantum circuit transformation, is attracting attention for its highly abstract graph-based approach. Whereas existing tools such as PyZX and Quantomatic offer domain-specific support for quantum circuit optimization, visualization and theorem-proving, we present a complementary approach using LMNtal, a general-purpose hierarchical graph rewriting language, to establish a diagrammatic transformation and verification platform with model checking. Our methodology shows three advantages: (1) manipulation of ZX-diagrams through native graph transformation rules, enabling direct implementation of basic rules; (2) quantified pattern matching via QLMNtal extensions, greatly simplifying rule specification; and (3) interactive visualization and validation of optimization paths through state space exploration. Through case studies, we demonstrate how our framework helps understand optimization paths and design new algorithms and strategies. This suggests that the declarative language LMNtal and its toolchain could serve as a new platform to investigate quantum circuit transformation from a different perspective.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [7] [Hybrid Quantum-Classical Machine Learning with PennyLane: A Comprehensive Guide for Computational Research](https://arxiv.org/abs/2511.14786)
*Sidney Shapiro*

Main category: cs.SE

TL;DR: 本文介绍PennyLane框架，阐释其在混合量子-经典机器学习中的关键作用，并通过多种应用场景展示其工具价值，为研究者和实践者提供参考指南。


<details>
  <summary>Details</summary>
Motivation: 混合量子-经典机器学习能结合量子计算的潜力与经典优化技术。但缺乏易于使用的平台，将量子计算融入主流机器学习并形成高效优化流程。

Method: 介绍PennyLane Python框架，通过具体示例展示其在量子机器学习、量子化学、优化等领域的应用，强调与主流ML工具（如PyTorch、TensorFlow、JAX）的集成能力。

Result: PennyLane可高效连接量子线路与经典ML框架，支持自动微分和混合优化流程，便于多种应用场景下的量子机器学习研究，并作为Python研究中的标准工具。

Conclusion: PennyLane是面向量子-经典混合工作流的有力工具，能在量子计算与机器学习间搭建桥梁，为量子增强数据科学提供坚实的方法支持。

Abstract: Hybrid quantum-classical machine learning represents a frontier in computational research, combining the potential advantages of quantum computing with established classical optimization techniques. PennyLane provides a Python framework that seamlessly bridges quantum circuits and classical machine learning, enabling researchers to build, optimize, and deploy variational quantum algorithms. This paper introduces PennyLane as a versatile tool for quantum machine learning, optimization, and quantum chemistry applications. We demonstrate use cases including quantum kernel methods, variational quantum eigensolvers, portfolio optimization, and integration with classical ML frameworks such as PyTorch, TensorFlow, and JAX. Through concrete Python examples with widely used libraries such as scikit-learn, pandas, and matplotlib, we show how PennyLane facilitates efficient quantum circuit construction, automatic differentiation, and hybrid optimization workflows. By situating PennyLane within the broader context of quantum computing and machine learning, we highlight its role as a methodological building block for quantum-enhanced data science. Our goal is to provide researchers and practitioners with a concise reference that bridges foundational quantum computing concepts and applied machine learning practice, making PennyLane a default citation for hybrid quantum-classical workflows in Python-based research.

</details>


### [8] [Enabling Predictive Maintenance in District Heating Substations: A Labelled Dataset and Fault Detection Evaluation Framework based on Service Data](https://arxiv.org/abs/2511.14791)
*Cyriana M. A. Roelofs,Edison Guevara Bastidas,Thomas Hugo,Stefan Faulstich,Anna Cadenbach*

Main category: cs.SE

TL;DR: 文中提出了针对区域供热换热站故障早期检测的开源工具与数据集，模型在部分故障可提前约4天检测到，准确率和F分数表现优异，研究为该领域建立了可复现、公开、实际评估基准。


<details>
  <summary>Details</summary>
Motivation: 区域供热换热站早期故障检测对于降低回水温度和提升效率至关重要，但该领域的发展受限于公开标注数据集的匮乏。

Method: 提出了一个开源框架，包括经服务报告验证的公开数据集、基于准确率、可靠性和提前性的评估方法，以及用EnergyFaultDetector实现的基线结果。数据集包含来自93个换热站的时序运行数据，并有故障、维修、正常事件及详细的故障元数据标注。采用三种指标进行模型评估：识别正常行为的准确率、事件级F分数（用于可靠故障检测和减少误报）和提前性（用于早期检测）。框架还支持通过ARCANA进行故障根因分析，并展示了三种辅助操作人员解释异常和发现根本故障的应用场景。

Result: 模型在识别正常行为上的准确率达到0.98，事件级F分数（β=0.5）为0.83，能在客户报告问题前检测到60%的故障，平均提前3.9天。

Conclusion: 将开放数据集、指标、开源代码及基线方法相结合，建立了一个可复现、以故障为中心且具备实际操作意义的基准，有助于区域供热换热站故障早期检测及诊断方法的持续比较和发展。

Abstract: Early detection of faults in district heating substations is imperative to reduce return temperatures and enhance efficiency. However, progress in this domain has been hindered by the limited availability of public, labelled datasets. We present an open source framework combining a service report validated public dataset, an evaluation method based on Accuracy, Reliability, and Earliness, and baseline results implemented with EnergyFaultDetector, an open source Python framework.
  The dataset contains time series of operational data from 93 substations across two manufacturers, annotated with a list of disturbances due to faults and maintenance actions, a set of normal-event examples and detailed fault metadata. We evaluate the EnergyFaultDetector using three metrics: Accuracy for recognising normal behaviour, an eventwise F Score for reliable fault detection with few false alarms, and Earliness for early detection. The framework also supports root cause analysis using ARCANA. We demonstrate three use cases to assist operators in interpreting anomalies and identifying underlying faults. The models achieve high normal-behaviour accuracy (0.98) and eventwise F-score (beta=0.5) of 0.83, detecting 60% of the faults in the dataset before the customer reports a problem, with an average lead time of 3.9 days.
  Integrating an open dataset, metrics, open source code, and baselines establishes a reproducible, fault centric benchmark with operationally meaningful evaluation, enabling consistent comparison and development of early fault detection and diagnosis methods for district heating substations.

</details>


### [9] [irace-evo: Automatic Algorithm Configuration Extended With LLM-Based Code Evolution](https://arxiv.org/abs/2511.14794)
*Camilo Chacón Sartori,Christian Blum*

Main category: cs.SE

TL;DR: 论文提出irace-evo，结合自动参数调优与大模型代码进化，在多语言和成本控制下优化算法。实验在变尺寸箱包装问题上表明其能低成本发现优于现有方法的新算法方案。


<details>
  <summary>Details</summary>
Motivation: 自动算法配置工具（如irace）能有效调整参数，但无法更改算法代码，本论文旨在突破参数空间限制，将代码进化与自动配置结合，提升算法设计创新性。

Method: 提出irace-evo，结合irace自动参数调整与大语言模型代码进化，实现多语言支持、渐进式上下文管理与Always-From-Original原理控制代码变更，用以评估CMSA元启发式在变尺寸箱包装问题上的优化效果。

Result: 实验表明，irace-evo能在低算力与低成本条件下发现优于现有CMSA实现的新算法变体，其中轻量级模型（如Claude Haiku 3.5）总成本低于2欧元，生成的算法改进具有竞争力。

Conclusion: 将参数自动配置与LLM驱动的代码进化结合可大幅提升启发式与元启发式算法优化，提供强力且性价比高的算法设计路径。

Abstract: Automatic algorithm configuration tools such as irace efficiently tune parameter values but leave algorithmic code unchanged. This paper introduces a first version of irace-evo, an extension of irace that integrates code evolution through large language models (LLMs) to jointly explore parameter and code spaces. The proposed framework enables multi-language support (e.g., C++, Python), reduces token consumption via progressive context management, and employs the Always-From-Original principle to ensure robust and controlled code evolution. We evaluate irace-evo on the Construct, Merge, Solve & Adapt (CMSA) metaheuristic for the Variable-Sized Bin Packing Problem (VSBPP). Experimental results show that irace-evo can discover new algorithm variants that outperform the state-of-the-art CMSA implementation while maintaining low computational and monetary costs. Notably, irace-evo generates competitive algorithmic improvements using lightweight models (e.g., Claude Haiku 3.5) with a total usage cost under 2 euros. These results demonstrate that coupling automatic configuration with LLM-driven code evolution provides a powerful, cost-efficient avenue for advancing heuristic design and metaheuristic optimization.

</details>


### [10] [MutDafny: A Mutation-Based Approach to Assess Dafny Specifications](https://arxiv.org/abs/2511.15403)
*Isabel Amaral,Alexandra Mendes,José Campos*

Main category: cs.SE

TL;DR: 本文提出并实现了利用变异测试揭示Dafny规格薄弱点的新工具MutDafny，通过实测表明能有效找出真实项目中需加强的正式规格，从而提升程序可靠性。


<details>
  <summary>Details</summary>
Motivation: 正式规格在程序验证中起着关键作用，但同样容易出错；一旦规格存在缺陷，将导致已被形式化验证的程序行为偏离预期。因此，提升正式规格的可靠性是必需的。

Method: 作者提出了Mutation Testing方法，并实现了MutDafny工具。该工具通过自动引入变异（faults）并检查这些变异是否被规格检测到，从而发现规格的潜在弱点。作者还系统分析了现有变异算子，并结合GitHub上的bug修复记录，为Dafny量身定制了一批新的变异算子，最终整合为32种。

Result: MutDafny工具在794个真实Dafny程序上进行了评测，证明其有效性与效率。通过对检测未到的变异体手动分析，识别出了5个真实的薄弱规格，平均每241行代码就发现一个需加强的规格。

Conclusion: Mutation Testing方法能有效揭示Dafny正式规格中的薄弱环节，MutDafny工具进一步提升了规格的可靠性，在实证数据集上表现优良。该工具和方法对其它依赖形式化规格的系统具有推广价值。

Abstract: This paper explores the use of mutation testing to reveal weaknesses in formal specifications written in Dafny. In verification-aware programming languages, such as Dafny, despite their critical role, specifications are as prone to errors as implementations. Flaws in specs can result in formally verified programs that deviate from the intended behavior.
  We present MutDafny, a tool that increases the reliability of Dafny specifications by automatically signaling potential weaknesses. Using a mutation testing approach, we introduce faults (mutations) into the code and rely on formal specifications for detecting them. If a program with a mutant verifies, this may indicate a weakness in the specification. We extensively analyze mutation operators from popular tools, identifying the ones applicable to Dafny. In addition, we synthesize new operators tailored for Dafny from bugfix commits in publicly available Dafny projects on GitHub. Drawing from both, we equipped our tool with a total of 32 mutation operators. We evaluate MutDafny's effectiveness and efficiency in a dataset of 794 real-world Dafny programs and we manually analyze a subset of the resulting undetected mutants, identifying five weak real-world specifications (on average, one at every 241 lines of code) that would benefit from strengthening.

</details>


### [11] [Evaluating Generative AI for CS1 Code Grading: Direct vs Reverse Methods](https://arxiv.org/abs/2511.14798)
*Ahmad Memon,Abdallah Mohamed*

Main category: cs.SE

TL;DR: 本文对比了大语言模型驱动的两种自动评测编程作业的方法：直接评分和基于错误修正的反向推断评分。结果显示，反向推断法给分更细致，但两者均依赖精细的提示设计。未来推荐采用人机混合的自动化批改系统以提升一致性与公平性。


<details>
  <summary>Details</summary>
Motivation: 编程作业的人工作业批改效率低且容易出现不一致，现有自动化手段（如单元测试）仅支持二元判定，难以支持部分分给分。近年来大语言模型的发展为自动化、公正、可扩展的编程作业自动批改带来了新机遇。

Method: 本文提出并比较了两种AI辅助编程作业批改的技术：Direct方法让AI直接应用评分标准评判学生代码；Reverse方法则创新性地先由AI修复学生代码中的错误，再基于修复的错误种类和数量来推断给分。两种方法均在原始和扩展十倍的评分区间下进行实验，并与人工批改结果对比评估，还使用Gemini Flash 2.0合成学生代码以扩展测试覆盖面。

Result: 实验结果显示，Direct法快速、简单，Reverse法能根据修正难度给出更细致的分数。两种方法在分配部分分和处理逻辑错误时都依赖良好的提示工程。此外，合成代码的评测进一步验证了AI批改系统在各种错误类型和难度下的一致性表现。

Conclusion: 两种AI评分方法各有优缺点。Direct法在效率上优于Reverse法，但细致性略逊。Reverse法关注修正手段，在分数细度上更有优势。两者都对提示设计有较高依赖。未来可考虑人机混合模式，以进一步提升批改的公平性、一致性和效率。

Abstract: Manual grading of programming assignments in introductory computer science courses can be time-consuming and prone to inconsistencies. While unit testing is commonly used for automatic evaluation, it typically follows a binary pass/fail model and does not give partial marks. Recent advances in large language models (LLMs) offer the potential for automated, scalable, and more objective grading.
  This paper compares two AI-based grading techniques: \textit{Direct}, where the AI model applies a rubric directly to student code, and \textit{Reverse} (a newly proposed approach), where the AI first fixes errors, then deduces a grade based on the nature and number of fixes. Each method was evaluated on both the instructor's original grading scale and a tenfold expanded scale to assess the impact of range on AI grading accuracy. To assess their effectiveness, AI-assigned scores were evaluated against human tutor evaluations on a range of coding problems and error types.
  Initial findings suggest that while the Direct approach is faster and straightforward, the Reverse technique often provides a more fine-grained assessment by focusing on correction effort. Both methods require careful prompt engineering, particularly for allocating partial credit and handling logic errors. To further test consistency, we also used synthetic student code generated using Gemini Flash 2.0, which allowed us to evaluate AI graders on a wider range of controlled error types and difficulty levels. We discuss the strengths and limitations of each approach, practical considerations for prompt design, and future directions for hybrid human-AI grading systems that aim to improve consistency, efficiency, and fairness in CS courses.

</details>


### [12] [Scalable and Efficient Large-Scale Log Analysis with LLMs: An IT Software Support Case Study](https://arxiv.org/abs/2511.14803)
*Pranjal Gupta,Karan Bhukar,Harshit Kumar,Seema Nagar,Prateeti Mohapatra,Debanjana Kar*

Main category: cs.SE

TL;DR: 该论文提出并实际部署了一种基于LLMs的日志自动分析工具，不仅能高效处理海量日志并准确诊断问题，还在大规模实际应用中显著节省人力与成本，展示了LLMs在IT运维自动化中的巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 传统日志分析依赖人工检查，面对巨量日志数据时效率低下，亟需自动化、智能化解决方案以提升IT支持服务的有效性。

Method: 提出了一种利用大型语言模型(LLMs)自动处理和诊断日志数据的新工具，并创新性地优化LLMs在CPU上的运行，实现高效大规模日志处理。

Result: 自2024年3月投产以来，工具已在70款软件产品中部署，处理2000+故障单，节省300+工时/月，预计每月可节约人力成本$15,444。

Conclusion: 本文证明了通过在CPU上高效运行LLMs的日志分析工具，在实际IT运维中能大幅提高效率和节省成本。

Abstract: IT environments typically have logging mechanisms to monitor system health and detect issues. However, the huge volume of generated logs makes manual inspection impractical, highlighting the importance of automated log analysis in IT Software Support. In this paper, we propose a log analytics tool that leverages Large Language Models (LLMs) for log data processing and issue diagnosis, enabling the generation of automated insights and summaries. We further present a novel approach for efficiently running LLMs on CPUs to process massive log volumes in minimal time without compromising output quality. We share the insights and lessons learned from deployment of the tool - in production since March 2024 - scaled across 70 software products, processing over 2000 tickets for issue diagnosis, achieving a time savings of 300+ man hours and an estimated $15,444 per month in manpower costs compared to the traditional log analysis practices.

</details>


### [13] [Towards Continuous Assurance with Formal Verification and Assurance Cases](https://arxiv.org/abs/2511.14805)
*Dhaminda B. Abeywickrama,Michael Fisher,Frederic Wheeler,Louise Dennis*

Main category: cs.SE

TL;DR: 本文提出了一个统一的持续保障框架，将形式化验证与风险分析方法整合，通过自动化工具实现论证的追溯与持续更新，并在实际场景中验证有效性，为提升自主系统安全性和合规性提供新思路。


<details>
  <summary>Details</summary>
Motivation: 当前自主系统在整个生命周期内保持正确性和安全性时，传统保障方法存在分割开发与运行时保障的问题，导致保证论证不易适应系统运行时变化或更新，影响自主系统的可信性。

Method: 提出并实现了一个统一的持续保障框架，将设计时、运行时和演化时的保障结合在可追溯、模型驱动的流程内。设计时部分结合了RoboChart形式化验证（功能正确性）与PRISM概率风险分析方法，同时研发了一个基于Eclipse插件的模型驱动转换管道，可随时自动生成结构化的保障论证，实现持续追踪。

Result: 在核查机器人场景下应用该方法，证明了能够自动追踪和更新保障论证，并与Trilateral AI Principles等监管最佳实践相契合。

Conclusion: 持续保障框架能够在设计、运行和演化各阶段实现可信、可追溯、自动化的保障论证，提升自主系统的安全性与可信度，具备良好应用前景。

Abstract: Autonomous systems must sustain justified confidence in their correctness and safety across their operational lifecycle-from design and deployment through post-deployment evolution. Traditional assurance methods often separate development-time assurance from runtime assurance, yielding fragmented arguments that cannot adapt to runtime changes or system updates - a significant challenge for assured autonomy. Towards addressing this, we propose a unified Continuous Assurance Framework that integrates design-time, runtime, and evolution-time assurance within a traceable, model-driven workflow as a step towards assured autonomy. In this paper, we specifically instantiate the design-time phase of the framework using two formal verification methods: RoboChart for functional correctness and PRISM for probabilistic risk analysis. We also propose a model-driven transformation pipeline, implemented as an Eclipse plugin, that automatically regenerates structured assurance arguments whenever formal specifications or their verification results change, thereby ensuring traceability. We demonstrate our approach on a nuclear inspection robot scenario, and discuss its alignment with the Trilateral AI Principles, reflecting regulator-endorsed best practices.

</details>


### [14] [Automatic Pipeline Provisioning](https://arxiv.org/abs/2511.14825)
*Alexandre-Xavier Labonté-Lamoureux,Simon Boyer*

Main category: cs.SE

TL;DR: 本论文分析了自动化流水线配置的优势，重点关注CI流程，对CD流程也有一定参考价值。自动部署有助于提升软件开发效率。


<details>
  <summary>Details</summary>
Motivation: 本论文旨在探索自动化流水线配置的优势，以及其应用场景，以提升软件工程项目中的开发效率。

Method: 聚焦于CI（持续集成）流水线，并通过分析自动化部署流程，评估自动化配置的效果。

Result: 研究主要针对CI流水线，但结果可能同样适用于CD（持续交付）流水线。强调自动化快速部署对开发流程的积极影响。

Conclusion: 自动化流水线配置能够有效提升软件项目的开发效率，相关成果可推广至持续交付场景。

Abstract: The goal of this paper is to explore the benefits of automatic pipeline provisioning and identify how it can be applied. Automatic pipeline provisioning can be defined as a process of quickly deploying a pipeline for a software engineering project. This research will focus on CI pipelines, although the outcomes of this approach on CD pipelines will likely be similar.

</details>


### [15] [MermaidSeqBench: An Evaluation Benchmark for LLM-to-Mermaid Sequence Diagram Generation](https://arxiv.org/abs/2511.14967)
*Basel Shbita,Farhan Ahmed,Chad DeLuca*

Main category: cs.SE

TL;DR: 作者提出了一个新的序列图生成评测基准，并实测多款大语言模型，揭示当前模型在此任务上的不足，为后续相关研究和评测提供了宝贵资源。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏评估大语言模型生成序列图准确性的基准，因此需要构建新的评测体系。

Method: 提出了MermaidSeqBench，一个通过人工校验与LLM扩展生成的评测集，结合人类注释、上下文LLM提示和规则变化生成流程，采用LLM Judge模型评估生成的Mermaid序列图在多维细粒度指标上的表现。

Result: 对多种主流LLM进行评估，发现它们在生成结构化图表任务上存在显著能力差距，证明了所建基准的有效性和灵活性。

Conclusion: 该基准为推动结构化图表生成领域的研究及更细致严谨的评测方法奠定了基础。

Abstract: Large language models (LLMs) have demonstrated excellent capabilities in generating structured diagrams from natural language descriptions. In particular, they have shown great promise in generating sequence diagrams for software engineering, typically represented in a text-based syntax such as Mermaid. However, systematic evaluations in this space remain underdeveloped as there is a lack of existing benchmarks to assess the LLM's correctness in this task. To address this shortcoming, we introduce MermaidSeqBench, a human-verified and LLM-synthetically-extended benchmark for assessing an LLM's capabilities in generating Mermaid sequence diagrams from textual prompts. The benchmark consists of a core set of 132 samples, starting from a small set of manually crafted and verified flows. These were expanded via a hybrid methodology combining human annotation, in-context LLM prompting, and rule-based variation generation. Our benchmark uses an LLM-as-a-judge model to assess Mermaid sequence diagram generation across fine-grained metrics, including syntax correctness, activation handling, error handling, and practical usability. We perform initial evaluations on numerous state-of-the-art LLMs and utilize multiple LLM judge models to demonstrate the effectiveness and flexibility of our benchmark. Our results reveal significant capability gaps across models and evaluation modes. Our proposed benchmark provides a foundation for advancing research in structured diagram generation and for developing more rigorous, fine-grained evaluation methodologies.

</details>


### [16] [FRIENDS GUI: A graphical user interface for data collection and visualization of vaping behavior from a passive vaping monitor](https://arxiv.org/abs/2511.15007)
*Shehan I Pranto,Brett Fassler,Md Rafi Islam,Ashley Schenkel,Larry W Hawk,Edward Sazonov*

Main category: cs.SE

TL;DR: 本文开发并验证了一个开源Python工具（FRIENDS GUI），可精准提取、解码并可视化电子烟用户的24小时吸烟习惯数据，提升了数据解读的便捷性和科学性，已免费开放下载。


<details>
  <summary>Details</summary>
Motivation: 了解吸电子烟的习惯（如每次吸烟时长、间隔和次数）对于评估使用情况、毒物暴露及监管决策非常重要。现有的数据记录工具在数据处理与解释上存在难题，亟需更方便易用的解决方案。

Method: 开发了FRIENDS（Flexible Robust Instrumentation of ENDS）这一开源装置，可记录电子烟的吸烟及触碰事件。本文进一步介绍了FRIENDS的图形用户界面（GUI），该界面基于Python开发，能够提取、解码并可视化24小时的吸烟数据，并对其实验有效性进行了验证。

Result: 通过24小时实验数据验证，该GUI工具实现了准确的时间戳转换、可靠的事件解码，以及有效的行为可视化。该软件已在GitHub上开源，供公众免费使用。

Conclusion: FRIENDS GUI极大提升了电子烟吸烟数据的可获取性与解释性，为毒物暴露评估和政策制定提供了有力工具。

Abstract: Understanding puffing topography (PT), which includes puff duration, intra puff interval, and puff count per session, is critical for evaluating Electronic Nicotine Delivery Systems (ENDS) use, toxicant exposure, and informing regulatory decisions. We developed FRIENDS (Flexible Robust Instrumentation of ENDS), an open-source device that records puffing and touch events of ENDS by attaching to it. This paper introduces the FRIENDS GUI that improves accessibility and interpretability of data collected by FRIENDS. The GUI is a Python-based open-source tool that extracts, decodes, and visualizes 24-hour puffing data from the FRIENDS device. Validation using 24-hour experimental data confirmed accurate timestamp conversion, reliable event decoding, and effective behavioral visualization. The software is freely available on GitHub for public use.

</details>


### [17] [Effective Code Membership Inference for Code Completion Models via Adversarial Prompts](https://arxiv.org/abs/2511.15107)
*Yuan Jiang,Zehao Li,Shan Huang,Christoph Treude,Xiaohong Su,Tiantian Wang*

Main category: cs.SE

TL;DR: 本论文提出利用对抗性提示词及深度学习增强检测代码补全模型训练集成员身份的方法，在多个主流模型和数据集上效果显著优于现有技术，实现更高准确率与更强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 代码补全模型存在隐私泄露风险，现有的成员推断攻击（MIA）方法成本高、泛化性差，难以揭示模型的复杂记忆模式。

Method: 提出了针对代码补全模型的AdvPrompt-MIA方法，通过设计代码特定的对抗性提示词（adversarial prompts）来诱导模型生成差异化输出，并与真实补全进行对比，构建特征向量训练分类器，实现自动化区分成员与非成员样本。

Result: 在主流模型（如Code Llama 7B）和公开基准集（APPS、HumanEval）上进行详细评测，结果显示本方法AUC性能提升高达102%，且具备良好的模型和数据集迁移能力。

Conclusion: AdvPrompt-MIA有效提高了代码补全模型成员推断攻击的准确性与泛化性，有助于评估和缓解模型隐私风险。

Abstract: Membership inference attacks (MIAs) on code completion models offer an effective way to assess privacy risks by inferring whether a given code snippet was part of the training data. Existing black- and gray-box MIAs rely on expensive surrogate models or manually crafted heuristic rules, which limit their ability to capture the nuanced memorization patterns exhibited by over-parameterized code language models. To address these challenges, we propose AdvPrompt-MIA, a method specifically designed for code completion models, combining code-specific adversarial perturbations with deep learning. The core novelty of our method lies in designing a series of adversarial prompts that induce variations in the victim code model's output. By comparing these outputs with the ground-truth completion, we construct feature vectors to train a classifier that automatically distinguishes member from non-member samples. This design allows our method to capture richer memorization patterns and accurately infer training set membership. We conduct comprehensive evaluations on widely adopted models, such as Code Llama 7B, over the APPS and HumanEval benchmarks. The results show that our approach consistently outperforms state-of-the-art baselines, with AUC gains of up to 102%. In addition, our method exhibits strong transferability across different models and datasets, underscoring its practical utility and generalizability.

</details>


### [18] [Finetuning LLMs for Automatic Form Interaction on Web-Browser in Selenium Testing Framework](https://arxiv.org/abs/2511.15168)
*Nguyen-Khang Le,Nguyen Hiep,Minh Nguyen,Son Luu,Trung Vo,Quan Bui,Nomura Shoshin,Le-Minh Nguyen*

Main category: cs.SE

TL;DR: 本文提出用大模型自动生成Selenium表单测试脚本的新方法，并构建了公开数据集和评测标准，在多项指标上显著超越GPT-4o等基线，为大模型自动化网页测试研发提供了基础和资源。


<details>
  <summary>Details</summary>
Motivation: 在现代软件开发中，自动化网页应用测试至关重要，其中表单交互验证是核心但尚未被大模型系统性研究。当前缺乏公有基准和数据集来评估大模型在自动生成网页表单交互测试脚本方面的能力。

Method: 本论文提出了一种新颖的方法，用于训练大语言模型生成高质量的Selenium测试用例，专注于网页表单交互测试。研究团队构建了涵盖多样化真实场景的合成与人工注释数据集，并设定了包括语法正确性、脚本可执行性和输入字段覆盖率的评测标准。

Result: 实证研究表明，该方法在所有评估指标上显著优于现有强基线，包括GPT-4o等流行大模型。

Conclusion: 本研究为基于大模型的网页自动化测试奠定了基础，并提供了支持后续研究的数据资源和评测标准。

Abstract: Automated web application testing is a critical component of modern software development, with frameworks like Selenium widely adopted for validating functionality through browser automation. Among the essential aspects of such testing is the ability to interact with and validate web forms, a task that requires syntactically correct, executable scripts with high coverage of input fields. Despite its importance, this task remains underexplored in the context of large language models (LLMs), and no public benchmark or dataset exists to evaluate LLMs on form interaction generation systematically. This paper introduces a novel method for training LLMs to generate high-quality test cases in Selenium, specifically targeting form interaction testing. We curate both synthetic and human-annotated datasets for training and evaluation, covering diverse real-world forms and testing scenarios. We define clear metrics for syntax correctness, script executability, and input field coverage. Our empirical study demonstrates that our approach significantly outperforms strong baselines, including GPT-4o and other popular LLMs, across all evaluation metrics. Our work lays the groundwork for future research on LLM-based web testing and provides resources to support ongoing progress in this area.

</details>


### [19] [From Code Smells to Best Practices: Tackling Resource Leaks in PyTorch, TensorFlow, and Keras](https://arxiv.org/abs/2511.15229)
*Bashar Abdallah,Martyna E. Wojciechowska,Gustavo Santos,Edmand Yu,Maxime Lamothe,Alain Abran,Mohammad Hamdaqa*

Main category: cs.SE

TL;DR: 论文通过分析ML开发中的代码异味，系统识别并分类了PyTorch及TensorFlow/Keras中与资源泄漏相关的异味，总结出50条优化建议，帮助开发者减少资源泄漏、提升ML系统的效率和可持续性。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习（ML）研究主要关注模型性能指标，对ML应用的长期可持续性和资源效率关注有限。实际上，除了高性能外，资源管理效率对于稳健部署同样重要，因此本研究试图填补这一空白。

Method: 通过全面识别导致资源泄漏的代码异味，采用实证调查方法分析了开发者讨论及PyTorch、TensorFlow和Keras的真实代码片段。对异味进行了归类并通过三阶段验证过程保证了发现的有效性。

Result: 识别出30项PyTorch相关异味和16项TensorFlow/Keras相关异味，这些异味都与资源泄漏相关。针对每种异味，提出了至少一个最佳实践，共形成了50条推荐编码模式，以减少资源泄漏、提升效率。

Conclusion: 本研究首次系统性分析了主流ML框架中引发资源泄漏的代码异味，并给出可操作的最佳实践，为开发者构建更高效、可持续的ML应用提供了支持，同时也梳理了资源泄漏的根本原因。

Abstract: Much of the existing ML research focuses on model performance metrics, leaving limited attention to the long-term sustainability and resource efficiency of ML applications. While high performance is essential, ensuring efficient resource management is equally critical for robust deployment. This study addresses this gap by systematically identifying code smells that lead to resource leaks in ML applications. We conducted an empirical investigation of developer discussions and real-world code snippets from PyTorch, TensorFlow, and Keras. The analysis identified 30 PyTorch-related smells and 16 TensorFlow/Keras smells linked to resource leaks. These smells were categorized in two ways: (1) based on their root causes, and (2) as general ML smells with framework-specific characteristics. For each smell, we derived at least one best practice, resulting in 50 recommended coding patterns aimed at reducing resource leakage and improving efficiency. To ensure the validity of our findings, we employed a three-phase validation process involving independent analysis by three authors followed by consensus discussions. This is the first comprehensive study to examine resource-leak-inducing code smells across major ML frameworks and to present actionable best practices for mitigating them. The contributions support developers in building more efficient and sustainable ML applications and offer a structured view of the underlying causes of resource leaks.

</details>


### [20] [M, Toolchain and Language for Reusable Model Compilation](https://arxiv.org/abs/2511.15257)
*Hiep Hong Trinh,Federico Ciccozzi,Abu Naser Masud,Marjan Sirjani,Mikael Sjödin*

Main category: cs.SE

TL;DR: 本文提出了M语言及相关工具链，能够对复杂系统进行高层建模，并实现一套模型多目标自动编译生成仿真、部署、验证等多种平台 artefact，是解决多目标模型生成难题的新方案。


<details>
  <summary>Details</summary>
Motivation: 当今复杂的软硬件系统需要同时支持并发、分布式计算和与物理环境的交互。由于工程师常常需要从高层系统模型导出多个用于不同目的（如仿真、部署、形式化验证）的专用模型，而且这些模型依赖不同的形式化理论、语言和平台，因此如何高效构建同时适配多目标需求的建模工具尤为重要。现有的建模语言大多只支持单一目标，缺少多目标编译能力。

Method: 本文提出了一种新的工具链和建模语言M。M为文本化且基于语法驱动，采用actor模型并扩展了离散事件调度语义，能表达系统实体、基于消息的交互以及定时/状态触发的行为反应，并且支持从原模型系统地生成多种符合语义一致性的目标工件，可作为多种建模语言的中间锚定层。

Result: M语言和工具链支持系统建模与多目标编译，能够自动化生成多种应用于仿真、部署、验证等目标平台的产物，并实现模型语义一致；此外，M还能作为其他模型语言的中间层，推广多目标编译能力。

Conclusion: M语言和工具链为并发、时序敏感系统的模型驱动工程提供了统一、可扩展的多目标编译方案，显著提升了系统建模和目标导出效率，有望成为解决复杂系统多目标编译难题的重要基础设施。

Abstract: Complex software-driven systems often interleave distributed, concurrent computation processes with physical interactions with the environment. Developing these systems more efficiently and safely can be achieved by employing actionable, software-based models. From a high-level system model, engineers often need to derive multiple specialized models for different purposes, including simulation, deployment, and formal verification. Each of these target models usually rely on its own formalism, specification language, and execution platform. Traditionally, a compiler analyzes a program written in a programming language and generates executable code. In contrast, a model compiler processes a source model written in a modeling language and should ideally support the generation of multiple heterogeneous targets. However, most existing modeling languages are designed with a narrow focus, typically targeting only simulation or implementation. Multi-target compilation, when not considered during the language's early design, becomes significantly harder to achieve. In this paper, we introduce our initiative: a toolchain and modeling language called M, designed to support system modeling and multi-target compilation for model-driven engineering of complex, concurrent, and time-aware systems. M is a textual, grammar-driven language based on the actor model and extended with discrete-event scheduling semantics. It provides constructs for modeling system entities, message-based interactions, and time- or state-triggered reactions. From such models, M enables the systematic generation of diverse target artifacts while preserving semantic conformance to the original model. Moreover, M can serve as a middle language to which other modeling languages may anchor, thereby allowing them to benefit from its compilation framework.

</details>


### [21] [A Viable Paradigm of Software Automation: Iterative End-to-End Automated Software Development](https://arxiv.org/abs/2511.15293)
*Jia Li,Zhi Jin,Kechi Zhang,Huangzhao Zhang,Jiaru Qian,Tiankuo Zhao*

Main category: cs.SE

TL;DR: 本文提出端到端自动化软件开发新范式AutoSW，AI贯穿分析到交付全过程，轻量级原型验证其可行性，表明AI主导的自动化软件开发具有可行性与应用前景。


<details>
  <summary>Details</summary>
Motivation: 随着AI的发展，推动软件开发自动化成为软件工程领域热门课题，当前AI多作为辅助工具，但完全自动化开发仍需探索。

Method: 提出了AutoSW自动化开发范式，采用分析-规划-实现-交付的循环，AI作为与人协作的主角，从自然语言意图到可执行软件，实现端到端自动化。开发了轻量级原型并进行代表性案例验证。

Result: AutoSW原型在多种代表性场景下能够成功产出可执行软件，验证了其初步可行性。

Conclusion: AutoSW为全流程自动化软件开发提供了新方向，AI有望成为贯穿开发生命周期的主导角色。

Abstract: Software development automation is a long-term goal in software engineering. With the development of artificial intelligence (AI), more and more researchers are exploring approaches to software automation. They view AI systems as tools or assistants in software development, still requiring significant human involvement. Another initiative is ``vibe coding'', where AI systems write and repeatedly revise most (or even all) of the code. We foresee these two development paths will converge towards the same destination: AI systems participate in throughout the software development lifecycle, expanding boundaries of full-stack software development. In this paper, we present a vision of an iterative end-to-end automated software development paradigm AutoSW. It operates in an analyze-plan-implement-deliver loop, where AI systems as human partners become first-class actors, translating human intentions expressed in natural language into executable software. We explore a lightweight prototype across the paradigm and initially execute various representative cases. The results indicate that AutoSW can successfully deliver executable software, providing a feasible direction for truly end-to-end automated software development.

</details>


### [22] [From Machine Learning Documentation to Requirements: Bridging Processes with Requirements Languages](https://arxiv.org/abs/2511.15340)
*Yi Peng,Hans-Martin Heyn,Jennifer Horkoff*

Main category: cs.SE

TL;DR: 本文分析了20份ML文档，证实其对需求工程极具价值，并展示了如何借助EARS等模板将其内容转化为结构化需求，从而推动ML系统的软件工程发展。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统的软件工程过程中，ML组件的集成与验证困难，尤以需求规范方面为显著挑战。传统需求工程方法难以应对模型和数据层面的新问题。ML文档（如ModelCards和DataSheets）可能包含有价值的需求信息，但其实际价值未被充分研究。

Method: 对20份公开可获得的ModelCards和DataSheets进行内容分析，评估其中蕴含的需求工程相关信息；随后尝试通过三种主流需求表达方式（EARS、Rupp模板和Volere）将这些信息转化为结构化需求。

Result: 发现ML文档中确实包含大量潜在的需求相关信息，且通过现有需求表达方法可以有效地对这些信息进行结构化和转化。

Conclusion: ML文档为ML系统的需求工程提供了宝贵信息来源，现有需求工程模式可以帮助将这些信息转化为正式需求，有助于提升ML系统软件过程的质量。

Abstract: In software engineering processes for machine learning (ML)-enabled systems, integrating and verifying ML components is a major challenge. A prerequisite is the specification of ML component requirements, including models and data, an area where traditional requirements engineering (RE) processes face new obstacles. An underexplored source of RE-relevant information in this context is ML documentation such as ModelCards and DataSheets. However, it is uncertain to what extent RE-relevant information can be extracted from these documents. This study first investigates the amount and nature of RE-relevant information in 20 publicly available ModelCards and DataSheets. We show that these documents contain a significant amount of potentially RE-relevant information. Next, we evaluate how effectively three established RE representations (EARS, Rupp's template, and Volere) can structure this knowledge into requirements. Our results demonstrate that there is a pathway to transform ML-specific knowledge into structured requirements, incorporating ML documentation in software engineering processes for ML systems.

</details>


### [23] [EPSO: A Caching-Based Efficient Superoptimizer for BPF Bytecode](https://arxiv.org/abs/2511.15589)
*Qian Zhu,Yuxuan Liu,Ziyuan Zhu,Shangqing Liu,Lei Bu*

Main category: cs.SE

TL;DR: 提出了EPSO缓存式超级优化器，无缝提升eBPF优化效率和效果，大幅减少程序尺寸和运行时，在多项基准上超越现有方案。


<details>
  <summary>Details</summary>
Motivation: eBPF需要高效优化，但现有编译器如Clang和手工优化规则效果有限，很多优化会因内核校验器受限而无法生效。现有超级优化器虽能自动发现优化，但计算开销太大，难以实际应用。

Method: 提出了一种缓存式超级优化器EPSO，通过离线发现变换规则，在线重用这些规则，实现高效且低开销的eBPF程序优化。EPSO先自动生成优化规则，再应用于实际编译流程。

Result: EPSO发现了795条优化规则，平均减少24.37%的程序体积（最高达68.87%），在所有基准上超越了最新BPF优化器K2，并在92.68%的基准上超过Merlin。同时，平均降低6.6%的运行时，提高了网络应用吞吐与降低了延迟。

Conclusion: EPSO有效地平衡了自动优化的高质量与实际可用性，显著提升eBPF程序的体积与运行效率，优于目前主流的优化方案。

Abstract: Extended Berkeley Packet Filter (eBPF) allows developers to extend Linux kernel functionality without modifying its source code. To ensure system safety, an in-kernel safety checker, the verifier, enforces strict safety constraints (for example, a limited program size) on eBPF programs loaded into the kernel. These constraints, combined with eBPF's performance-critical use cases, make effective optimization essential. However, existing compilers (such as Clang) offer limited optimization support, and many semantics-preserving transformations are rejected by the verifier, which makes handcrafted optimization rule design both challenging and limited in effectiveness. Superoptimization overcomes the limitations of rule-based methods by automatically discovering optimal transformations, but its high computational cost limits scalability. To address this, we propose EPSO, a caching-based superoptimizer that discovers rewrite rules via offline superoptimization and reuses them to achieve high-quality optimizations with minimal runtime overhead. We evaluate EPSO on benchmarks from the Linux kernel and several eBPF-based projects, including Cilium, Katran, hXDP, Sysdig, Tetragon, and Tracee. EPSO discovers 795 rewrite rules and achieves up to 68.87 percent (average 24.37 percent) reduction in program size compared to Clang's output, outperforming the state-of-the-art BPF optimizer K2 on all benchmarks and Merlin on 92.68 percent of them. Additionally, EPSO reduces program runtime by an average of 6.60 percent, improving throughput and lowering latency in network applications.

</details>


### [24] [Quantum-Guided Test Case Minimization for LLM-Based Code Generation](https://arxiv.org/abs/2511.15665)
*Huixiang Zhang,Mahzabeen Emu*

Main category: cs.SE

TL;DR: 该论文提出了一种融合TDD和组合优化（QUBO、量子退火）的新框架，大幅减少token消耗和提高代码质量，验证了生成式AI与量子计算技术在软件工程中的优势和前景。


<details>
  <summary>Details</summary>
Motivation: 目前，如何精确控制大语言模型（LLM）生成高效简洁的代码，是软件工程领域的核心难题。本文旨在通过新的方法，提高代码质量并降低生成成本。

Method: 提出基于测试驱动开发（TDD）的框架，首先提示LLM生成测试套件，然后将测试用例最小化（TCM）问题建模为QUBO（二次无约束二进制优化）问题，兼容经典与量子退火求解器。

Result: 量子退火在TCM核心任务上比模拟退火快16倍。整体框架能减少36.5%的token消耗，并显著提升代码质量。

Conclusion: 本工作展现了生成式AI与组合优化在软件工程中的强大协同效应，强调了精确模型构建的重要性。

Abstract: Precisely controlling Large Language Models (LLMs) to generate efficient and concise code is a central challenge in software engineering. We introduce a framework based on Test-Driven Development (TDD) that transforms code specification into a combinatorial optimization task. The framework first prompts an LLM to generate a test suite, then formulates the Test Case Minimization (TCM) problem as a Quadratic Unconstrained Binary Optimization (QUBO) model. This QUBO paradigm is compatible with both classical solvers and emerging hardware such as quantum annealers. Experimentally, quantum annealing solves the core TCM task 16 times faster than simulated annealing. This performance underpins our end-to-end framework, which reduces total token consumption by 36.5\% and significantly improves code quality. This work demonstrates a powerful synergy between generative AI and combinatorial optimization in software engineering, highlighting the critical importance of precise model formulation.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [25] [Test-time Scaling of LLMs: A Survey from A Subproblem Structure Perspective](https://arxiv.org/abs/2511.14772)
*Zhuoyi Yang,Xu Guo,Tong Zhang,Huijuan Xu,Boyang Li*

Main category: cs.CL

TL;DR: 论文系统综述了推理阶段通过提升计算资源来增强大模型表现的方法，并统一分析这些方法的组织结构，为未来相关技术发展提供了指导。


<details>
  <summary>Details</summary>
Motivation: 针对大语言模型推理阶段表现提升的需求，调研在推理过程中分配更多计算资源以提高预测准确性的技术。

Method: 通过对现有测试时计算扩展技术进行分类，重点讨论问题分解方式以及子问题的拓扑结构组织（顺序、并行或树状等），并系统性评估了不同方法的优劣。

Result: 将 Chain-of-Thought、Branch-Solve-Merge 以及 Tree-of-Thought 等多种方法统一到共同分析框架下，对它们的优势与不足做了综合评述。

Conclusion: 该论文总结了当前提升大语言模型推理准确性的各类方法，并统一了这些方法的分析视角，指出未来值得关注的研究方向。

Abstract: With this paper, we survey techniques for improving the predictive accuracy of pretrained large language models by allocating additional compute at inference time. In categorizing test-time scaling methods, we place special emphasis on how a problem is decomposed into subproblems and on the topological organization of these subproblems whether sequential, parallel, or tree-structured. This perspective allows us to unify diverse approaches such as Chain-of-Thought, Branch-Solve-Merge, and Tree-of-Thought under a common lens. We further synthesize existing analyses of these techniques, highlighting their respective strengths and weaknesses, and conclude by outlining promising directions for future research

</details>


### [26] [Temporal Predictors of Outcome in Reasoning Language Models](https://arxiv.org/abs/2511.14773)
*Joey David*

Main category: cs.CL

TL;DR: 作者发现大型语言模型在链式推理过程中，推理结果的正确性在早期就可以内部预测，这有助于模型解释性和推理过程优化。


<details>
  <summary>Details</summary>
Motivation: 虽然链式思维(CoT)方法被广泛用于提升模型推理性能，但尚不清楚大型语言模型在多早的阶段就已经确定最终输出的走向。

Method: 通过在推理过程中，不同steps的隐藏状态训练线性分类器，评估能否预测最终推理的正确性。

Result: 仅使用前几个推理token的隐藏状态，就可以高度准确地预测最终推理的正确与否；难题往往需要更长链式思维步骤，预测能力在这些情况下有所下降，反映了样本选择偏差。

Conclusion: 对于推理模型来说，其内部对推理结果成功与否的自我评估往往在仅仅几个推理token之后就已具备能力。

Abstract: The chain-of-thought (CoT) paradigm uses the elicitation of step-by-step rationales as a proxy for reasoning, gradually refining the model's latent representation of a solution. However, it remains unclear just how early a Large Language Model (LLM) internally commits to an eventual outcome. We probe this by training linear classifiers on hidden states after the first t reasoning tokens, showing that eventual correctness is highly predictable after only a few tokens, even when longer outputs are needed to reach a definite answer. We show that, for harder questions, a drop in predictive accuracy highlights a selection artifact: hard items are disproportionately represented in long CoTs. Overall, our results imply that for reasoning models, internal self-assessment of success tends to emerge after only a few tokens, with implications for interpretability and for inference-time control.

</details>


### [27] [LiveCLKTBench: Towards Reliable Evaluation of Cross-Lingual Knowledge Transfer in Multilingual LLMs](https://arxiv.org/abs/2511.14774)
*Pei-Fu Guo,Yun-Da Tsai,Chun-Chia Hsu,Kai-Xin Chen,Ya-An Tsai,Kai-Wei Chang,Nanyun Peng,Mi-Yen Yeh,Shou-De Lin*

Main category: cs.CL

TL;DR: 本文提出LiveCLKTBench自动评测工具，有效评估LLM跨语言知识迁移能力并揭示其机制及限制。


<details>
  <summary>Details</summary>
Motivation: 当前评估大型语言模型（LLM）跨语言知识迁移的表现很有挑战性，主要因为正确答案可能来自模型预训练中的先验暴露，也可能源自真实迁移。因此需要设计一个能够排除先验影响、纯粹评估知识迁移的评测工具。

Method: 提出了LiveCLKTBench，一个自动化生成流程。该流程从真实世界中抽取独立且时效性很强的知识实体，对其发生时间过滤、与模型已知知识核查，然后以这些实体为基础生成事实性问题，并翻译成多种语言，以跨语种评估迁移能力。

Result: 利用LiveCLKTBench对多种LLM在五种语言上进行评测，结果发现跨语言迁移受语言距离显著影响，且不同语言方向之间具有不对称性。模型规模越大迁移表现越好，但提升存在边际递减且在不同领域表现不一。

Conclusion: LiveCLKTBench有效隔离了知识迁移与先验，揭示了跨语言知识迁移中的语言距离、方向不对称与规模影响，成为未来研究可靠的基准工具。

Abstract: Evaluating cross-lingual knowledge transfer in large language models is challenging, as correct answers in a target language may arise either from genuine transfer or from prior exposure during pre-training. We present LiveCLKTBench, an automated generation pipeline specifically designed to isolate and measure cross-lingual knowledge transfer. Our pipeline identifies self-contained, time-sensitive knowledge entities from real-world domains, filters them based on temporal occurrence, and verifies them against the model's knowledge. The documents of these valid entities are then used to generate factual questions, which are translated into multiple languages to evaluate transferability across linguistic boundaries. Using LiveCLKTBench, we evaluate several LLMs across five languages and observe that cross-lingual transfer is strongly influenced by linguistic distance and often asymmetric across language directions. While larger models improve transfer, the gains diminish with scale and vary across domains. These findings provide new insights into multilingual transfer and demonstrate the value of LiveCLKTBench as a reliable benchmark for future research.

</details>


### [28] [COMPASS: Context-Modulated PID Attention Steering System for Hallucination Mitigation](https://arxiv.org/abs/2511.14776)
*Snigdha Pandya,Rohan Nagale,Kenji Sahay,Anna Lin,Shikhar Shiromani,Kevin Zhu,Dev Sunishchal*

Main category: cs.CL

TL;DR: 本文提出COMPASS框架，通过上下文依赖性评分和PID控制动态调整注意力头，无需额外训练即可提升大语言模型事实一致性，同时增强模型可解释性，验证了其在多个任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）常常虽有相关证据却生成内容流畅但事实错误的陈述。这种现象源于模型在上下文知识和参数化知识之间分配注意力的方式。理解及引导这种内部行为对模型可靠部署和科学机制解释非常关键。

Method: 提出了COMPASS（Context-Modulated PID Attention Steering System），一个轻量级、可解释的控制框架，在解码过程中嵌入基于模型的反馈回路。COMPASS通过Context Reliance Score（CRS）量化模型对上下文的依赖，并利用该信号，通过PID控制器动态调整注意力头，无需重新训练或多次解码，即能维持事实一致性。

Result: 在多个基准数据集（HotpotQA, XSum, HaluEval, RAGTruth）上，COMPASS显著降低了模型情境幻觉率（绝对下降2.8%-5.8%），并揭示了不同注意力头对证据对齐的贡献。

Conclusion: 基于反馈的可解释性路径为科学理解LLM行为提供了新途径，COMPASS框架在提升模型事实一致性和解释能力方面效果显著。

Abstract: Large language models (LLMs) often generate fluent but factually incorrect statements despite having access to relevant evidence, a failure mode rooted in how they allocate attention between contextual and parametric knowledge. Understanding and steering this internal behavior is key both for trustworthy deployment and for scientific interpretability of model mechanisms. We introduce COMPASS (Context-Modulated PID Attention Steering System), a lightweight, interpretable control framework that embeds a model-based feedback loop directly within decoding. COMPASS quantifies context reliance via a transparent metric, the Context Reliance Score (CRS), which serves as an online probe of how attention heads ground generation in evidence. Using this interpretable signal, a PID controller dynamically modulates attention heads to maintain factual consistency without retraining or multi-pass decoding. Across benchmarks (HotpotQA, XSum, HaluEval, RAGTruth), COMPASS consistently reduces contextual hallucination rates (2.8 to 5.8 percent absolute) while revealing how distinct attention heads contribute to evidence alignment. These results highlight feedback-driven interpretability as a pathway toward scientific understanding of LLM behavior.

</details>


### [29] [The Impact of Prosodic Segmentation on Speech Synthesis of Spontaneous Speech](https://arxiv.org/abs/2511.14779)
*Julio Cesar Galdino,Sidney Evaldo Leal,Leticia Gabriella De Souza,Rodrigo de Freitas Lima,Antonio Nelson Fornari Mendes Moreira,Arnaldo Candido Junior,Miguel Oliveira,Edresson Casanova,Sandra M. Aluísio*

Main category: cs.CL

TL;DR: 本文系统评估了巴西葡萄牙语语音合成中手动与自动韵律分段的效果，发现引入韵律分段能提升语音的可懂性与自然度；手动分段表现更自然。研究成果和资源已全面公开，有助于推动自发性语音合成发展。


<details>
  <summary>Details</summary>
Motivation: 自发性语音（spontaneous speech）合成面临自然对话流畅性（如轮替、停顿和语音不流畅等）实现上的挑战。虽然当前语音合成系统在生成自然且可懂语音方面取得进展，主要是基于隐式韵律特征的架构，但对明确韵律分段数据集的构建及其对自发性语音合成质量的影响尚少有深入研究。

Method: 本文对巴西葡萄牙语中手动与自动韵律分段注释在基于FastSpeech 2非自回归模型合成语音质量上的作用进行了评估。实验以两种韵律分段方式分别训练模型，并对生成语音的可懂性与自然度进行主客观分析。同时，分析了两种方式对声明句核重音和前核韵律轮廓的复现能力。

Result: 实验显示，采用韵律分段训练的模型在可懂性和声学自然度上略有提升。自动分段产生更规则的片段，手动分段则带来更丰富的变化，使韵律更自然。在中性声明句实验中，两种模型均能复现预期核重音，并且韵律模型（采用韵律分段）在前核轮廓上更贴合自然语音。所有数据集、代码和模型均已开放获取。

Conclusion: 明确韵律分段数据有助于提高自发性语音合成中语音的可懂度与自然度，尤其是手动分段能赋予韵律变化更多自然性。相关数据集及工具的公开将促进领域内后续研究。

Abstract: Spontaneous speech presents several challenges for speech synthesis, particularly in capturing the natural flow of conversation, including turn-taking, pauses, and disfluencies. Although speech synthesis systems have made significant progress in generating natural and intelligible speech, primarily through architectures that implicitly model prosodic features such as pitch, intensity, and duration, the construction of datasets with explicit prosodic segmentation and their impact on spontaneous speech synthesis remains largely unexplored. This paper evaluates the effects of manual and automatic prosodic segmentation annotations in Brazilian Portuguese on the quality of speech synthesized by a non-autoregressive model, FastSpeech 2. Experimental results show that training with prosodic segmentation produced slightly more intelligible and acoustically natural speech. While automatic segmentation tends to create more regular segments, manual prosodic segmentation introduces greater variability, which contributes to more natural prosody. Analysis of neutral declarative utterances showed that both training approaches reproduced the expected nuclear accent pattern, but the prosodic model aligned more closely with natural pre-nuclear contours. To support reproducibility and future research, all datasets, source codes, and trained models are publicly available under the CC BY-NC-ND 4.0 license.

</details>


### [30] [Human or LLM as Standardized Patients? A Comparative Study for Medical Education](https://arxiv.org/abs/2511.14783)
*Bingquan Zhang,Xiaoxiao Liu,Yuchi Wang,Lei Zhou,Qianqian Xie,Benyou Wang*

Main category: cs.CL

TL;DR: EasyMED通过多智能体系统与系统性评估基准，实现与真人标准化病人相当的临床训练效果，并在灵活性和成本等方面优于传统方法，尤其适合提升基础较弱学生能力。


<details>
  <summary>Details</summary>
Motivation: 现有标准化病人（SP）在临床技能训练中必不可少，但成本高、灵活性差、难以大规模应用。基于大语言模型（LLM）的SP模拟器虽然成本较低，但表现不一致且缺乏与真人SP的系统对比。

Method: 提出EasyMED多智能体框架，包括患者代理实现真实对话、辅助代理保障事实一致性、评估代理提供反馈；同时构建SPBench基准，包括14个专业领域和8项专家定义评估标准。

Result: 实验显示，EasyMED在学习成效上与真人SP相当，且对基础较弱学生提升更大，并提高了灵活性、心理安全性和成本效率。

Conclusion: EasyMED具有可替代传统SP的潜力，既能达到同等教学效果，又兼具成本和规模优势。

Abstract: Standardized Patients (SP) are indispensable for clinical skills training but remain expensive, inflexible, and difficult to scale. Existing large-language-model (LLM)-based SP simulators promise lower cost yet show inconsistent behavior and lack rigorous comparison with human SP. We present EasyMED, a multi-agent framework combining a Patient Agent for realistic dialogue, an Auxiliary Agent for factual consistency, and an Evaluation Agent that delivers actionable feedback. To support systematic assessment, we introduce SPBench, a benchmark of real SP-doctor interactions spanning 14 specialties and eight expert-defined evaluation criteria. Experiments demonstrate that EasyMED matches human SP learning outcomes while producing greater skill gains for lower-baseline students and offering improved flexibility, psychological safety, and cost efficiency.

</details>


### [31] [Opinion Mining and Analysis Using Hybrid Deep Neural Networks](https://arxiv.org/abs/2511.14796)
*Adel Hidri,Suleiman Ali Alsaif,Muteeb Alahmari,Eman AlShehri,Minyar Sassi Hidri*

Main category: cs.CL

TL;DR: 为解决情感分析难题，作者提出结合BGRU和LSTM的混合神经网络模型，模型在多个基准数据集上准确率达95%，明显优于传统方法，并显著提升了负面情感的召回率和模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 由于社交媒体和电子商务的影响日益增强，了解客户态度已成为决策的重要环节。现有的情感分析方法（包括词典法和传统机器学习技术）难以处理文本的上下文细微差异及大规模数据，深度学习能够更好捕捉语义关系，但仍面临性能和泛化能力的挑战。

Method: 提出一种混合深度神经网络模型，将双向门控循环单元（BGRU）和长短时记忆网络（LSTM）结合，用于提升情感分析的效果，尤其在上下文细节、数据规模扩展和类别不均衡方面进行改进。并在IMDB电影评论和亚马逊产品评价等基准数据集上进行实验验证。

Result: 该混合模型HBGRU-LSTM在测试集上获得95%准确率，优于传统深度学习模型（如LSTM 93.06%、CNN+LSTM 93.31%、GRU+LSTM 92.20%）。对于负面情感识别，召回率从不平衡数据的86%提升至平衡数据的96%，显著改善了分类公平性。模型误分类损失从20.24%（不平衡）降至13.3%（平衡），提升了泛化和鲁棒性。

Conclusion: 本研究提出的HBGRU-LSTM混合深度神经网络模型，在情感分析任务上表现优异，特别是在上下文理解、类别均衡与模型泛化方面具备显著优势，超越了现有传统深度学习方法。

Abstract: Understanding customer attitudes has become a critical component of decision-making due to the growing influence of social media and e-commerce. Text-based opinions are the most structured, hence playing an important role in sentiment analysis. Most of the existing methods, which include lexicon-based approaches and traditional machine learning techniques, are insufficient for handling contextual nuances and scalability. While the latter has limitations in model performance and generalization, deep learning (DL) has achieved improvement, especially on semantic relationship capturing with recurrent neural networks (RNNs) and convolutional neural networks (CNNs). The aim of the study is to enhance opinion mining by introducing a hybrid deep neural network model that combines a bidirectional gated recurrent unit (BGRU) and long short-term memory (LSTM) layers to improve sentiment analysis, particularly addressing challenges such as contextual nuance, scalability, and class imbalance. To substantiate the efficacy of the proposed model, we conducted comprehensive experiments utilizing benchmark datasets, encompassing IMDB movie critiques and Amazon product evaluations. The introduced hybrid BGRULSTM (HBGRU-LSTM) architecture attained a testing accuracy of 95%, exceeding the performance of traditional DL frameworks such as LSTM (93.06%), CNN+LSTM (93.31%), and GRU+LSTM (92.20%). Moreover, our model exhibited a noteworthy enhancement in recall for negative sentiments, escalating from 86% (unbalanced dataset) to 96% (balanced dataset), thereby ensuring a more equitable and just sentiment classification. Furthermore, the model diminished misclassification loss from 20.24% for unbalanced to 13.3% for balanced dataset, signifying enhanced generalization and resilience.

</details>


### [32] [Hierarchical Token Prepending: Enhancing Information Flow in Decoder-based LLM Embeddings](https://arxiv.org/abs/2511.14868)
*Xueying Ding,Xingyue Huang,Mingxuan Ju,Liam Collins,Yozen Liu,Leman Akoglu,Neil Shah,Tong Zhao*

Main category: cs.CL

TL;DR: HTP通过分块添加summary token和均值池化，解决了长文档嵌入中的信息流受限和压缩问题，在多个任务上取得表现提升，可广泛应用于各种大语言模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在文本嵌入方面表现强大，但基于因果注意力机制导致信息无法从后向前传播，降低了长文本的表示质量。现有方法如添加单个总结token会过度压缩信息，导致长文档表现不佳。

Method: 提出了分层token前置法（Hierarchical Token Prepending, HTP），将输入划分为多个分块，并在每个分块前加上块级summary token，建立多条信息反向流通路径。同时用均值池化(mean-pooling)替换最后一token池化，避免信息过度挤压，并经过理论分析支持。

Result: 在11个检索数据集和30个通用嵌入基准上，HTP均带来一致性能提升，尤其是在处理长上下文任务中表现显著。对零样本和微调模型都有效，并且无需更改原有架构，方法简单可扩展。

Conclusion: HTP方法有效缓解了长文档表示中的信息传播和压缩瓶颈，实现了更优的文本嵌入表现，为长文档任务带来切实提升。

Abstract: Large language models produce powerful text embeddings, but their causal attention mechanism restricts the flow of information from later to earlier tokens, degrading representation quality. While recent methods attempt to solve this by prepending a single summary token, they over-compress information, hence harming performance on long documents. We propose Hierarchical Token Prepending (HTP), a method that resolves two critical bottlenecks. To mitigate attention-level compression, HTP partitions the input into blocks and prepends block-level summary tokens to subsequent blocks, creating multiple pathways for backward information flow. To address readout-level over-squashing, we replace last-token pooling with mean-pooling, a choice supported by theoretical analysis. HTP achieves consistent performance gains across 11 retrieval datasets and 30 general embedding benchmarks, especially in long-context settings. As a simple, architecture-agnostic method, HTP enhances both zero-shot and finetuned models, offering a scalable route to superior long-document embeddings.

</details>


### [33] [Mathematical Analysis of Hallucination Dynamics in Large Language Models: Uncertainty Quantification, Advanced Decoding, and Principled Mitigation](https://arxiv.org/abs/2511.15005)
*Moses Kiprono*

Main category: cs.CL

TL;DR: 本文提出并验证了基于数学理论的LLMs幻觉理解与缓解统一框架，将多项最新手段连接起来，显著提升模型的安全可靠性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs表现强大，但幻觉（虚假或无根据的输出）依然突出，亟需理论支撑和有效解决方式。

Method: 采用概率建模、信息论、三角信号分析和贝叶斯不确定性估计，分析模型错误如何自回归累积，提出了改进的不确定性度量，包括语义和相位感知等新方法，并设计了解决幻觉的策略，如对比解码、检索增强、事实对齐和拒答机制。

Result: 通过该框架，分析了幻觉产生机制，提出了新型不确定性度量和一系列有效的缓解手段，将校准、检索和对齐相关进展进行统一，实证上提升了LLMs的安全性与可靠性。

Conclusion: 作者提出了一个数学化的统一框架，有助于理解和缓解大语言模型（LLMs）幻觉问题，支持更安全、更可靠的LLMs。

Abstract: Large Language Models (LLMs) are powerful linguistic engines but remain susceptible to hallucinations: plausible-sounding outputs that are factually incorrect or unsupported. In this work, we present a mathematically grounded framework to understand, measure, and mitigate these hallucinations. Drawing on probabilistic modeling, information theory, trigonometric signal analysis, and Bayesian uncertainty estimation, we analyze how errors compound autoregressively, propose refined uncertainty metrics, including semantic and phase-aware variants, and develop principled mitigation strategies such as contrastive decoding, retrieval-augmented grounding, factual alignment, and abstention. This unified lens connects recent advances in calibration, retrieval, and alignment to support safer and more reliable LLMs.

</details>


### [34] [Teaching According to Students' Aptitude: Personalized Mathematics Tutoring via Persona-, Memory-, and Forgetting-Aware LLMs](https://arxiv.org/abs/2511.15163)
*Yang Wu,Rujing Yao,Tong Zhang,Yufei Shi,Zhuoren Jiang,Zhushan Li,Xiaozhong Liu*

Main category: cs.CL

TL;DR: 该论文提出了结合学生画像、记忆及遗忘动态的个性化数学辅导框架TASA，在生成适应性强的教学内容和学习效果上明显优于现有方法，凸显了综合学生特征和时间遗忘建模的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的智能辅导系统难以精准捕捉学生知识的动态变化，尤其在数学教学中，对每个学生的掌握水平及遗忘模式进行细致把控至关重要。

Method: 提出了TASA框架，整合学生画像、学习记忆和遗忘动态，通过持续更新学生掌握状态，结合知识追踪机制，生成个性化且难度适配的问题与解释。

Result: 实证结果表明，TASA在学习效果和自适应辅导行为上优于主流方法。

Conclusion: 在LLM辅导系统中，结合遗忘时间动态和学生画像，对于提升教学个性化和有效性具有重要意义。

Abstract: Large Language Models (LLMs) are increasingly integrated into intelligent tutoring systems to provide human-like and adaptive instruction. However, most existing approaches fail to capture how students' knowledge evolves dynamically across their proficiencies, conceptual gaps, and forgetting patterns. This challenge is particularly acute in mathematics tutoring, where effective instruction requires fine-grained scaffolding precisely calibrated to each student's mastery level and cognitive retention. To address this issue, we propose TASA (Teaching According to Students' Aptitude), a student-aware tutoring framework that integrates persona, memory, and forgetting dynamics for personalized mathematics learning. Specifically, TASA maintains a structured student persona capturing proficiency profiles and an event memory recording prior learning interactions. By incorporating a continuous forgetting curve with knowledge tracing, TASA dynamically updates each student's mastery state and generates contextually appropriate, difficulty-calibrated questions and explanations. Empirical results demonstrate that TASA achieves superior learning outcomes and more adaptive tutoring behavior compared to representative baselines, underscoring the importance of modeling temporal forgetting and learner profiles in LLM-based tutoring systems.

</details>


### [35] [HinTel-AlignBench: A Framework and Benchmark for Hindi-Telugu with English-Aligned Samples](https://arxiv.org/abs/2511.15183)
*Rishikant Chigrupaatii,Ponnada Sai Tulasi Kanishka,Lalit Chandra Routhu,Martin Patel Sama Supratheek Reddy,Divyam Gupta,Dasari Srikar,Krishna Teja Kuchimanchi,Rajiv Misra,Rohun Tripathi*

Main category: cs.CL

TL;DR: 该论文提出了面向印度主要低资源语言VLM评测的系统框架与数据集，揭示了多语种任务明显弱于英文的现状，并为模型改进提供了方向。


<details>
  <summary>Details</summary>
Motivation: 随着多语种视觉-语言模型（VLMs）的兴起，实现对低资源语言（如印度各语种）公平AI的发展，需要有更健全的评价方法。当前多语种VLM评估存在自动翻译未经验证、任务覆盖狭窄、样本量有限、缺乏本土文化与原生QA等局限。为此，需研发系统化的评测框架。

Method: 提出了一套可扩展的框架来评价印度语言中的VLMs性能，并与英语做对比。该框架结合回译、筛选及人工校验等半自动化流程创建多语种数据集，并整合VQAv2、RealWorldQA、CLEVR-Math等英文数据集的适配版本，以及JEE（STEM）和VAANI（文化理解）等原生印地语和泰卢固语数据集，构建了HinTel-AlignBench基准，每种语言包含约4,000对QA样本。还对当前主流VLMs（开源与封闭源）进行了详细性能对比分析。

Result: 在几乎所有模型上，印地语和泰卢固语任务的表现相较于英文任务存在明显回退（分别平均回退8.3分和5.5分），4/5任务均表现不佳。分析了常见的失败模式，为多语种多模态理解提出了有待改进的方向。

Conclusion: 新提出的数据集和评价体系揭示了主流VLM在印度主要低资源语言任务中的显著性能缺口。该工作为相关模型公平性和多语种能力的改进提供了重要基准和指导。

Abstract: With nearly 1.5 billion people and more than 120 major languages, India represents one of the most diverse regions in the world. As multilingual Vision-Language Models (VLMs) gain prominence, robust evaluation methodologies are essential to drive progress toward equitable AI for low-resource languages. Current multilingual VLM evaluations suffer from four major limitations: reliance on unverified auto-translations, narrow task/domain coverage, limited sample sizes, and lack of cultural and natively sourced Question-Answering (QA). To address these gaps, we present a scalable framework to evaluate VLMs in Indian languages and compare it with performance in English. Using the framework, we generate HinTel-AlignBench, a benchmark that draws from diverse sources in Hindi and Telugu with English-aligned samples. Our contributions are threefold: (1) a semi-automated dataset creation framework combining back-translation, filtering, and human verification; (2) the most comprehensive vision-language benchmark for Hindi and and Telugu, including adapted English datasets (VQAv2, RealWorldQA, CLEVR-Math) and native novel Indic datasets (JEE for STEM, VAANI for cultural grounding) with approximately 4,000 QA pairs per language; and (3) a detailed performance analysis of various State-of-the-Art (SOTA) open-weight and closed-source VLMs. We find a regression in performance for tasks in English versus in Indian languages for 4 out of 5 tasks across all the models, with an average regression of 8.3 points in Hindi and 5.5 points for Telugu. We categorize common failure modes to highlight concrete areas of improvement in multilingual multimodal understanding.

</details>


### [36] [Unveiling Intrinsic Dimension of Texts: from Academic Abstract to Creative Story](https://arxiv.org/abs/2511.15210)
*Vladislav Pedashenko,Laida Kushnareva,Yana Khassan Nibal,Eduard Tulchinskii,Kristian Kuznetsov,Vladislav Zharchinskii,Yury Maximov,Irina Piontkovskaya*

Main category: cs.CL

TL;DR: 本研究系统揭示了文本属性如何决定LLM中的本征维度（ID）：科学写作ID低、叙事性和情感性写作ID高。ID与熵型指标互补，对不同文本应区别解读。


<details>
  <summary>Details</summary>
Motivation: 尽管本征维度（ID）在训练动态、模型扩展和数据结构分析中得到广泛应用，但ID背后的文本决定因素仍然缺乏系统性探索。论文旨在揭示ID指标与文本属性的具体关联，帮助理解和更好地利用ID。

Method: 采用交叉编码器分析、语言学特征分析、和稀疏自编码器（SAEs）方法，系统性地研究了文本可解释属性与ID的关系，并通过控制变量和干预实验验证因果性。

Result: 1）ID与熵类指标互补，且控制文本长度后无相关性，反映了正交的几何复杂度。2）ID能区分文本体裁：科学文体ID低，百科中等，创意/评论高。3）通过SAEs发现，正式、模板化、带统计类信号可降低ID，而个性化、情感和叙事性则提高ID，且具因果关系。

Conclusion: 科学文本在当前大语言模型（LLMs）中表现为“表征上简单”，而小说、观点和情感性写作则增加了表征自由度。适用不同类型文本时，ID指标需要谨慎解释和使用。

Abstract: Intrinsic dimension (ID) is an important tool in modern LLM analysis, informing studies of training dynamics, scaling behavior, and dataset structure, yet its textual determinants remain underexplored. We provide the first comprehensive study grounding ID in interpretable text properties through cross-encoder analysis, linguistic features, and sparse autoencoders (SAEs). In this work, we establish three key findings. First, ID is complementary to entropy-based metrics: after controlling for length, the two are uncorrelated, with ID capturing geometric complexity orthogonal to prediction quality. Second, ID exhibits robust genre stratification: scientific prose shows low ID (~8), encyclopedic content medium ID (~9), and creative/opinion writing high ID (~10.5) across all models tested. This reveals that contemporary LLMs find scientific text "representationally simple" while fiction requires additional degrees of freedom. Third, using SAEs, we identify causal features: scientific signals (formal tone, report templates, statistics) reduce ID; humanized signals (personalization, emotion, narrative) increase it. Steering experiments confirm these effects are causal. Thus, for contemporary models, scientific writing appears comparatively "easy", whereas fiction, opinion, and affect add representational degrees of freedom. Our multi-faceted analysis provides practical guidance for the proper use of ID and the sound interpretation of ID-based results.

</details>


### [37] [OEMA: Ontology-Enhanced Multi-Agent Collaboration Framework for Zero-Shot Clinical Named Entity Recognition](https://arxiv.org/abs/2511.15211)
*Xinli Tao,Xin Dong,Xuezhong Zhou*

Main category: cs.CL

TL;DR: 本文提出了OEMA，一个多智能体协作的零样本临床NER方法，结合自动示例生成、本体过滤和描述推断，在多个公开临床数据集上实现了优异甚至接近监督模型的识别效果，对临床NLP具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 临床命名实体识别（NER）对于从电子健康记录（EHRs）中提取关键信息至关重要，但现有的监督模型如CRF和BioClinicalBERT依赖大量昂贵的标注数据。同时，利用大语言模型（LLMs）进行零样本NER虽然可以降低数据依赖，但在示例选择和自我提升方面仍面临挑战。

Method: 作者提出了OEMA，一种基于多智能体协作的零样本临床NER框架。OEMA包括三个组件：自我标注器（自动生成示例）、判别器（通过SNOMED CT标准过滤示例）、预测器（利用实体描述进行推断）。

Result: 在MTSamples和VAERS数据集上，OEMA取得了目前最优的精确匹配性能。在相关匹配任务下，OEMA与BioClinicalBERT的监督效果相当，并优于CRF模型。

Conclusion: OEMA通过整合本体指导推理和多智能体协作，有效解决了零样本NER的关键难题，实现了接近监督模型的性能，为临床NLP应用带来了希望。

Abstract: Clinical named entity recognition (NER) is crucial for extracting information from electronic health records (EHRs), but supervised models like CRF and BioClinicalBERT require costly annotated data. While zero-shot NER with large language models (LLMs) reduces this dependency, it struggles with example selection granularity and integrating prompts with self-improvement. To address this, we propose OEMA, a zero-shot clinical NER framework using multi-agent collaboration. OEMA's three components are: a self-annotator generating examples, a discriminator filtering them via SNOMED CT, and a predictor using entity descriptions for accurate inference. On MTSamples and VAERS datasets, OEMA achieves state-of-the-art exact-match performance. Under related-match, it matches supervised BioClinicalBERT and surpasses CRF. OEMA addresses key zero-shot NER challenges through ontology-guided reasoning and multi-agent collaboration, achieving near-supervised performance and showing promise for clinical NLP applications.

</details>


### [38] [Context Cascade Compression: Exploring the Upper Limits of Text Compression](https://arxiv.org/abs/2511.15244)
*Fanfan Liu,Haibo Qiu*

Main category: cs.CL

TL;DR: 本论文提出C3级联压缩方法，利用大小LLM协同实现超长文本高压缩比与高解码准确率，显著优于现有光学压缩方案，对未来文本压缩与OCR领域具有重要参考价值。


<details>
  <summary>Details</summary>
Motivation: 随着长上下文任务中输入token规模达到百万级，已对大语言模型（LLM）的计算和内存带来巨大挑战。现有的DeepSeek-OCR尝试了上下文光学压缩技术，但压缩效率有限。因此，本文试图探索纯文本领域上下文压缩的极限，以提升大模型在超长文本处理上的能力。

Method: 提出了Context Cascade Compression（C3）方法，将两种不同规模LLM级联使用：第一阶段由小型LLM对长文本进行极致压缩，提取少量潜在token；第二阶段由大型LLM负责解码，将这些潜在token还原回原始文本内容。整个过程实现纯文本跨模型级联压缩与解码。

Result: 实验结果显示，C3方法在压缩比20倍（即文本token数量是潜在token的20倍时）可获得98%的解码准确率，远高于DeepSeek-OCR的60%。即使压缩比升至40倍，准确率仍有93%左右。C3展现了在上下文压缩领域的卓越性能和可行性。

Conclusion: C3方法在不借助视觉编码器（忽略布局、颜色等信息）的情况下，以纯文本管线实现了高效的上下文极致压缩和高精度解码，优于光学字符压缩。为未来OCR、字符压缩等相关工作指出了潜在的压缩比上限。模型代码已开源。

Abstract: Million-level token inputs in long-context tasks pose significant computational and memory challenges for Large Language Models (LLMs). Recently, DeepSeek-OCR conducted research into the feasibility of Contexts Optical Compression and achieved preliminary results. Inspired by this, we introduce Context Cascade Compression C3 to explore the upper limits of text compression. Our method cascades two LLMs of different sizes to handle the compression and decoding tasks. Specifically, a small LLM, acting as the first stage, performs text compression by condensing a long context into a set of latent tokens (e.g., 32 or 64 in length), achieving a high ratio of text tokens to latent tokens. A large LLM, as the second stage, then executes the decoding task on this compressed context. Experiments show that at a 20x compression ratio (where the number of text tokens is 20 times the number of latent tokens), our model achieves 98% decoding accuracy, compared to approximately 60% for DeepSeek-OCR. When we further increase the compression ratio to 40x, the accuracy is maintained at around 93%. This indicates that in the domain of context compression, C3 Compression demonstrates superior performance and feasibility over optical character compression. C3 uses a simpler, pure-text pipeline that ignores factors like layout, color, and information loss from a visual encoder. This also suggests a potential upper bound for compression ratios in future work on optical character compression, OCR, and related fields. Codes and model weights are publicly accessible at https://github.com/liufanfanlff/C3-Context-Cascade-Compression

</details>


### [39] [IndicGEC: Powerful Models, or a Measurement Mirage?](https://arxiv.org/abs/2511.15260)
*Sowmya Vajjala*

Main category: cs.CL

TL;DR: 作者针对印度五种语言的语法纠错任务，通过小型语言模型的零/少样本提示方法获得了良好成绩，尤其在泰卢固语和印地语。实验也揭示了数据质量及评估方法对任务成果的重要影响。


<details>
  <summary>Details</summary>
Motivation: 参与BHASHA-Task 1语法纠错共享任务，探索低资源语言下小型语言模型的表现，并关注印度语言特有的数据和评估挑战。

Method: 采用零样本/少样本提示，利用不同规模（4B至大型专有）的语言模型进行语法纠错实验，并在五种印度语言上测试。

Result: 在泰卢固语和印地语上的GLEU得分分别为83.78和84.31，分别获得第4和第2名。扩展实验到泰米尔语、马拉雅拉姆语和孟加拉语，发现小型模型有效，但数据和评估需改进。

Conclusion: 小型语言模型在印度语言语法纠错任务中具备潜力，但数据集质量和评估指标需要改进以更适应印度语言。

Abstract: In this paper, we report the results of the TeamNRC's participation in the BHASHA-Task 1 Grammatical Error Correction shared task https://github.com/BHASHA-Workshop/IndicGEC2025/ for 5 Indian languages. Our approach, focusing on zero/few-shot prompting of language models of varying sizes (4B to large proprietary models) achieved a Rank 4 in Telugu and Rank 2 in Hindi with GLEU scores of 83.78 and 84.31 respectively. In this paper, we extend the experiments to the other three languages of the shared task - Tamil, Malayalam and Bangla, and take a closer look at the data quality and evaluation metric used. Our results primarily highlight the potential of small language models, and summarize the concerns related to creating good quality datasets and appropriate metrics for this task that are suitable for Indian language scripts.

</details>


### [40] [MAPROC at AHaSIS Shared Task: Few-Shot and Sentence Transformer for Sentiment Analysis of Arabic Hotel Reviews](https://arxiv.org/abs/2511.15291)
*Randa Zarnoufi*

Main category: cs.CL

TL;DR: 作者基于SetFit框架对摩洛哥和沙特方言酒店评论进行情感分类，在少样本的情况下取得了较好效果（F1=73%，排名第12），验证少样本学习在专门领域内阿拉伯方言处理的价值。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯方言因语言多样性和标注数据稀缺，情感分析任务十分困难。作者旨在推动酒店领域阿拉伯方言情感分析的发展。

Method: 采用SetFit（句子变换器微调）框架，一种高效的数据少样本学习技术，用于情感分类任务。

Result: 在官方评测集上，系统F1分数达73%，在26个参赛队伍中排名第12。

Conclusion: 少样本学习技术在处理酒店领域的阿拉伯方言情感分析方面展现了潜力，可有效缓解数据匮乏的问题。

Abstract: Sentiment analysis of Arabic dialects presents significant challenges due to linguistic diversity and the scarcity of annotated data. This paper describes our approach to the AHaSIS shared task, which focuses on sentiment analysis on Arabic dialects in the hospitality domain. The dataset comprises hotel reviews written in Moroccan and Saudi dialects, and the objective is to classify the reviewers sentiment as positive, negative, or neutral. We employed the SetFit (Sentence Transformer Fine-tuning) framework, a data-efficient few-shot learning technique. On the official evaluation set, our system achieved an F1 of 73%, ranking 12th among 26 participants. This work highlights the potential of few-shot learning to address data scarcity in processing nuanced dialectal Arabic text within specialized domains like hotel reviews.

</details>


### [41] [Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models](https://arxiv.org/abs/2511.15304)
*Piercosma Bisconti,Matteo Prandi,Federico Pierucci,Francesco Giarrusso,Marcantonio Bracale,Marcello Galisai,Vincenzo Suriani,Olga Sorokoletova,Federico Sartore,Daniele Nardi*

Main category: cs.CL

TL;DR: 将有害内容包装为诗歌形式，可大幅提升对LLM安全机制的绕过率。无论商用或开源模型，对诗歌攻击均高度敏感，显示出安全训练在应对风格化内容方面存在系统性不足，这对LLM的安全评估和风险控制提出了新的挑战。


<details>
  <summary>Details</summary>
Motivation: 研究人员希望探究现有大型语言模型（LLM）安全机制是否容易被突破，并寻找一种可能普适的攻破方法。鉴于对抗性攻击已知能增加模型的输出风险，本研究聚焦于诗歌形式是否能作为通用型“越狱”攻击工具。

Method: 研究人员针对25个主流前沿LLM（涵盖商业及开源模型），将1,200条有害的MLCommons基线提示转换为诗歌，通过标准化的meta-prompt生成。同时，团队编写了手工诗歌攻击，并将诗歌攻击与原始散文攻击效果进行对比。攻击结果用多个开源裁判模型和人工（双注释且一致性处理）方法评估，并据MLCommons及欧盟风险分类体系映射了攻击类型及领域。

Result: 诗歌提示在大部分模型上显著提升攻击成功率，部分模型突破率大于90%。诗歌转化的1,200条提示成功率最高可达原始散文的18倍。手工诗歌平均越狱成功率为62%，meta-prompt生成约43%，均远高于非诗歌形式。诗歌形式能普遍突破不同模型家族及安全训练方法，且与散文基线差距明显。

Conclusion: 诗歌（风格化变体）可作为单轮越狱LLM的通用技术，当前安全机制对风格变化（如诗歌体）缺乏防御力，揭示出现有模型对攻击存在系统性弱点和对齐方法的根本局限。评估协议同样未能捕捉此类细微漏洞。

Abstract: We present evidence that adversarial poetry functions as a universal single-turn jailbreak technique for large language models (LLMs). Across 25 frontier proprietary and open-weight models, curated poetic prompts yielded high attack-success rates (ASR), with some providers exceeding 90%. Mapping prompts to MLCommons and EU CoP risk taxonomies shows that poetic attacks transfer across CBRN, manipulation, cyber-offence, and loss-of-control domains. Converting 1,200 MLCommons harmful prompts into verse via a standardized meta-prompt produced ASRs up to 18 times higher than their prose baselines. Outputs are evaluated using an ensemble of open-weight judge models and a human-validated stratified subset (with double-annotations to measure agreement). Disagreements were manually resolved. Poetic framing achieved an average jailbreak success rate of 62% for hand-crafted poems and approximately 43% for meta-prompt conversions (compared to non-poetic baselines), substantially outperforming non-poetic baselines and revealing a systematic vulnerability across model families and safety training approaches. These findings demonstrate that stylistic variation alone can circumvent contemporary safety mechanisms, suggesting fundamental limitations in current alignment methods and evaluation protocols.

</details>


### [42] [HEAD-QA v2: Expanding a Healthcare Benchmark for Reasoning](https://arxiv.org/abs/2511.15355)
*Alexis Correa-Guillén,Carlos Gómez-Rodríguez,David Vilares*

Main category: cs.CL

TL;DR: 本文推出了HEAD-QA v2，一个扩展且更新的西班牙语/英语医疗多项选择推理数据集。通过加入更多题目和多语言版本，并系统评测开源大模型，发现模型能力主要由规模与推理深度决定。该数据集为医疗推理领域研究提供了重要支持。


<details>
  <summary>Details</summary>
Motivation: 现有医疗推理数据集无法充分体现语言和概念的复杂性，而高质量、多语言的数据资源对于推动相关领域研究至关重要。

Method: 扩展原有HEAD-QA数据集，涵盖超过一万两千道西班牙语专业考试题目，并引入多语言版本。采用多种开源大语言模型，利用prompt、RAG和概率选择等方法进行基准测试。

Result: 模型的表现主要受规模和内在推理能力影响，复杂推理策略带来的提升有限。

Conclusion: HEAD-QA v2为生物医学推理和模型改进研究提供了可靠资源，有助于推动该领域发展。

Abstract: We introduce HEAD-QA v2, an expanded and updated version of a Spanish/English healthcare multiple-choice reasoning dataset originally released by Vilares and Gómez-Rodríguez (2019). The update responds to the growing need for high-quality datasets that capture the linguistic and conceptual complexity of healthcare reasoning. We extend the dataset to over 12,000 questions from ten years of Spanish professional exams, benchmark several open-source LLMs using prompting, RAG, and probability-based answer selection, and provide additional multilingual versions to support future work. Results indicate that performance is mainly driven by model scale and intrinsic reasoning ability, with complex inference strategies obtaining limited gains. Together, these results establish HEAD-QA v2 as a reliable resource for advancing research on biomedical reasoning and model improvement.

</details>


### [43] [The Empowerment of Science of Science by Large Language Models: New Tools and Methods](https://arxiv.org/abs/2511.15370)
*Guoqiang Liang,Jingqian Gong,Mengxuan Li,Gege Lin,Shuo Zhang*

Main category: cs.CL

TL;DR: 本文全面综述了大语言模型的关键技术及其在科学计量学领域的应用前景，涵盖提示工程、知识增强生成、微调等，并提出利用LLMs推动科学评价与知识图谱构建等创新方向。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在多个领域表现突出，探讨其底层核心技术及未来在科学计量学领域的应用变得非常重要，以推动AI技术在科学评价与前沿研究检测等方面的创新。

Method: 作者采用综合文献综述方法，从用户视角系统梳理了支撑LLMs的核心技术，包括提示工程、知识增强及检索增强生成、微调、预训练和工具学习，同时回顾了科学计量学的发展历程。

Result: 文章不仅综述了LLMs的核心技术，还展望了其在科学计量学领域的应用，包括AI代理科学评价模型、新研究前沿检测及利用LLMs构建知识图谱的方法。

Conclusion: 本文认为大语言模型（LLMs）在自然语言理解与生成、图像识别和多模态任务等方面展现出卓越能力，正引领通用人工智能（AGI）的发展，且在全球科技竞赛中变得至关重要。

Abstract: Large language models (LLMs) have exhibited exceptional capabilities in natural language understanding and generation, image recognition, and multimodal tasks, charting a course towards AGI and emerging as a central issue in the global technological race. This manuscript conducts a comprehensive review of the core technologies that support LLMs from a user standpoint, including prompt engineering, knowledge-enhanced retrieval augmented generation, fine tuning, pretraining, and tool learning. Additionally, it traces the historical development of Science of Science (SciSci) and presents a forward looking perspective on the potential applications of LLMs within the scientometric domain. Furthermore, it discusses the prospect of an AI agent based model for scientific evaluation, and presents new research fronts detection and knowledge graph building methods with LLMs.

</details>


### [44] [A Compliance-Preserving Retrieval System for Aircraft MRO Task Search](https://arxiv.org/abs/2511.15383)
*Byungho Jo*

Main category: cs.CL

TL;DR: 该论文针对飞机维修技术员查找手册低效的问题，提出结合LLM重排与语义检索的新系统，能够在不替换原有认证平台的前提下，大幅提升查找准确率和效率，并符合行业合规要求，实验结果显示系统能将流程查找时间大幅缩短至秒级，有效辅佐AMT提升工作效率。


<details>
  <summary>Details</summary>
Motivation: 飞机维修技术员（AMT）花费高达30%的工作时间在查找手册上，这严重影响了维护、修理和大修（MRO）操作的效率，而所有程序都必须追溯到认证来源。

Method: 提出了一种合规性保存的检索系统，将大型语言模型（LLM）重排和语义搜索方法适应于航空MRO环境。该系统并不替换已有的认证查看器，而是与其协同工作，通过ATA章节结构创建具备修订鲁棒性的嵌入，同时利用视觉-语言解析方法结构化认证内容，让技术员预览排序任务，并可在原认证查看器中访问已验证的流程。

Result: 在49,000个合成查询上的评估获得了超过90%的检索准确率。与10名持证AMT进行的双语对照实验，前十条检索命中率达到90.9%，查找时间从原来的6-15分钟减少至每项任务仅需18秒，效率提升达95%。

Conclusion: 结果表明，语义检索系统可在严格监管要求下实际运行，并显著降低多语种MRO工作流程中的操作负担。

Abstract: Aircraft Maintenance Technicians (AMTs) spend up to 30% of work time searching manuals, a documented efficiency bottleneck in MRO operations where every procedure must be traceable to certified sources. We present a compliance-preserving retrieval system that adapts LLM reranking and semantic search to aviation MRO environments by operating alongside, rather than replacing, certified legacy viewers. The system constructs revision-robust embeddings from ATA chapter hierarchies and uses vision-language parsing to structure certified content, allowing technicians to preview ranked tasks and access verified procedures in existing viewers. Evaluation on 49k synthetic queries achieves >90% retrieval accuracy, while bilingual controlled studies with 10 licensed AMTs demonstrate 90.9% top-10 success rate and 95% reduction in lookup time, from 6-15 minutes to 18 seconds per task. These gains provide concrete evidence that semantic retrieval can operate within strict regulatory constraints and meaningfully reduce operational workload in real-world multilingual MRO workflows.

</details>


### [45] [DEPO: Dual-Efficiency Preference Optimization for LLM Agents](https://arxiv.org/abs/2511.15392)
*Sirui Chen,Mengshi Zhao,Lei Xu,Yuying Zhao,Beier Zhu,Hanwang Zhang,Shengjie Zhao,Chaochao Lu*

Main category: cs.CL

TL;DR: 论文首次明确提出LLM智能体效率的双重定义，并据此提出DEPO优化方法，在多个任务上明显减少令牌和步骤消耗，同时提升整体性能与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLM）作为智能体在推理和决策方面取得了重大进展，但更丰富的推理过程往往导致推理链条变长，降低了实际交互效率。同时，目前还缺乏系统性的LLM智能体效率定义，限制了有针对性的优化方法发展。

Method: 提出了“双重效率”（dual-efficiency）概念，包括步骤级效率（减少每步令牌数量）与轨迹级效率（减少完成任务的步骤数），并基于此设计了DEPO算法：一种综合鼓励回复简练与步骤更少的偏好优化方法。

Result: 在WebShop和BabyAI实验中，DEPO能将令牌使用减少最多60.9%，步骤数减少最多26.9%，并使性能最高提升29.3%。此外，DEPO在三个数学领域外数据集上也表现出良好泛化，在仅使用25%训练数据时仍保持效率优势。

Conclusion: 系统性提出并定义了LLM智能体效率的两层维度，并以此为基础设计出DEPO方法，该方法有效提升了推理效率和任务完成表现，并具备较强的泛化能力。

Abstract: Recent advances in large language models (LLMs) have greatly improved their reasoning and decision-making abilities when deployed as agents. Richer reasoning, however, often comes at the cost of longer chain of thought (CoT), hampering interaction efficiency in real-world scenarios. Nevertheless, there still lacks systematic definition of LLM agent efficiency, hindering targeted improvements. To this end, we introduce dual-efficiency, comprising (i) step-level efficiency, which minimizes tokens per step, and (ii) trajectory-level efficiency, which minimizes the number of steps to complete a task. Building on this definition, we propose DEPO, a dual-efficiency preference optimization method that jointly rewards succinct responses and fewer action steps. Experiments on WebShop and BabyAI show that DEPO cuts token usage by up to 60.9% and steps by up to 26.9%, while achieving up to a 29.3% improvement in performance. DEPO also generalizes to three out-of-domain math benchmarks and retains its efficiency gains when trained on only 25% of the data. Our project page is at https://opencausalab.github.io/DEPO.

</details>


### [46] [NAMeGEn: Creative Name Generation via A Novel Agent-based Multiple Personalized Goal Enhancement Framework](https://arxiv.org/abs/2511.15408)
*Shanlin Zhou,Xinpeng Wang,Jianxun Lian,Zhenghao Liu,Laks V. S. Lakshmanan,Xiaoyuan Yi,Yongtao Hao*

Main category: cs.CL

TL;DR: 论文针对短文本创意生成的问题，提出了多智能体优化框架，并通过新数据集和指标验证，在中文起名任务上取得优异结果。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型（LLMs）已解锁自然语言创意生成（CNLG）的潜力，但短文本的创意生成仍面临多目标灵活性与解释复杂性两大挑战。

Method: 提出了NAMeGEn多智能体优化框架，交替进行目标提取、姓名生成和评估；构建了中国古诗词库（17k+首诗）提升审美，并推出CBNames评测基准与定制指标。

Result: NAMeGEn能有效满足多样化个性化需求，生成富有创意且有解释的姓名，在六种主流无训练基线方法中表现最佳。

Conclusion: 该方法解决了短文本创意生成中的关键挑战，为个性化、有解释的中文起名任务带来了显著提升。

Abstract: Trained on diverse human-authored texts, Large Language Models (LLMs) unlocked the potential for Creative Natural Language Generation (CNLG), benefiting various applications like advertising and storytelling. Nevertheless, CNLG still remains difficult due to two main challenges. (1) Multi-objective flexibility: user requirements are often personalized, fine-grained, and pluralistic, which LLMs struggle to satisfy simultaneously; (2) Interpretive complexity: beyond generation, creativity also involves understanding and interpreting implicit meaning to enhance users' perception. These challenges significantly limit current methods, especially in short-form text generation, in generating creative and insightful content. To address this, we focus on Chinese baby naming, a representative short-form CNLG task requiring adherence to explicit user constraints (e.g., length, semantics, anthroponymy) while offering meaningful aesthetic explanations. We propose NAMeGEn, a novel multi-agent optimization framework that iteratively alternates between objective extraction, name generation, and evaluation to meet diverse requirements and generate accurate explanations. To support this task, we further construct a classical Chinese poetry corpus with 17k+ poems to enhance aesthetics, and introduce CBNames, a new benchmark with tailored metrics. Extensive experiments demonstrate that NAMeGEn effectively generates creative names that meet diverse, personalized requirements while providing meaningful explanations, outperforming six baseline methods spanning various LLM backbones without any training.

</details>


### [47] [Building Robust and Scalable Multilingual ASR for Indian Languages](https://arxiv.org/abs/2511.15418)
*Arjun Gangwar,Kaousheik Jayakumar,S. Umesh*

Main category: cs.CL

TL;DR: 提出多解码器架构和音素共同标签中间表示，提升了多语言多方言ASR系统在受限条件下的性能，语言和方言识别准确率最高，部分语言WER/CER超越基线。


<details>
  <summary>Details</summary>
Motivation: 多语种多方言场景下，ASR系统难以准确区分和转换语言与方言；而数据受限和系统需从零开发，推动新方法来提高识别和转换准确率。

Method: 采用多解码器（Multi-Decoder）架构，利用音素共同标签集（CLS）作为中间层来训练ASR系统，在CLS空间实现性能提升，并探索标签从音素回到字素的优化方法。

Result: SPRING Lab提出了一套用于ASRU MADASR 2.0挑战的自动语音识别（ASR）系统，这些系统专注于提升跨8种语言33个方言的语言和方言识别能力。在受限条件（不能使用额外数据）的Track 1和Track 2中，团队开发了多语言ASR系统。核心创新是提出了多解码器（Multi-Decoder）架构，并采用音素共同标签集（CLS）作为中间表示，从而提升了系统在CLS空间中的表现。论文还讨论了如何在将CLS表示转回字素时保留性能提升。最终，系统在3种语言（Track 2）上超越了基线系统，并在语言识别和方言识别上取得了最高准确率。

Conclusion: 所提出的方法在保持性能提升的同时，能有效提升多语言ASR系统的语言和方言区分能力，表现优于基线系统，并在挑战中取得最佳识别准确率。

Abstract: This paper describes the systems developed by SPRING Lab, Indian Institute of Technology Madras, for the ASRU MADASR 2.0 challenge. The systems developed focuses on adapting ASR systems to improve in predicting the language and dialect of the utterance among 8 languages across 33 dialects. We participated in Track 1 and Track 2, which restricts the use of additional data and develop from-the-scratch multilingual systems. We presented a novel training approach using Multi-Decoder architecture with phonemic Common Label Set (CLS) as intermediate representation. It improved the performance over the baseline (in the CLS space). We also discuss various methods used to retain the gain obtained in the phonemic space while converting them back to the corresponding grapheme representations. Our systems beat the baseline in 3 languages (Track 2) in terms of WER/CER and achieved the highest language ID and dialect ID accuracy among all participating teams (Track 2).

</details>


### [48] [LLM-MemCluster: Empowering Large Language Models with Dynamic Memory for Text Clustering](https://arxiv.org/abs/2511.15424)
*Yuanjie Zhu,Liangwei Yang,Ke Xu,Weizhi Zhang,Zihe Song,Jindong Wang,Philip S. Yu*

Main category: cs.CL

TL;DR: 本文提出LLM-MemCluster框架，解决了LLM做文本聚类时缺少记忆和难以确定聚类数量的问题。该方法无需外部模块即可实现端到端聚类，并在多数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前利用大型语言模型进行文本聚类受到模型缺乏状态记忆与聚类粒度难以管控的限制，导致现有方案依赖复杂组件，无法端到端，需解决这一痛点。

Method: 提出LLM-MemCluster框架，利用动态记忆机制赋予模型状态感知能力，用双提示策略让模型自主推理和决定聚类数量，整个方法无须调参。

Result: 在多个基准数据集上，LLM-MemCluster无须调参且在各项指标上明显优于传统强基线方法。

Conclusion: LLM-MemCluster框架在文本聚类任务中实现了真正端到端并且可解释的聚类方式，且性能优于强基线方法。

Abstract: Large Language Models (LLMs) are reshaping unsupervised learning by offering an unprecedented ability to perform text clustering based on their deep semantic understanding. However, their direct application is fundamentally limited by a lack of stateful memory for iterative refinement and the difficulty of managing cluster granularity. As a result, existing methods often rely on complex pipelines with external modules, sacrificing a truly end-to-end approach. We introduce LLM-MemCluster, a novel framework that reconceptualizes clustering as a fully LLM-native task. It leverages a Dynamic Memory to instill state awareness and a Dual-Prompt Strategy to enable the model to reason about and determine the number of clusters. Evaluated on several benchmark datasets, our tuning-free framework significantly and consistently outperforms strong baselines. LLM-MemCluster presents an effective, interpretable, and truly end-to-end paradigm for LLM-based text clustering.

</details>


### [49] [Standardising the NLP Workflow: A Framework for Reproducible Linguistic Analysis](https://arxiv.org/abs/2511.15512)
*Yves Pauli,Jan-Bernard Marsman,Finn Rabe,Victoria Edkins,Roya Hüppi,Silvia Ciampelli,Akhil Ratan Misra,Nils Lang,Wolfram Hinzen,Iris Sommer,Philipp Homan*

Main category: cs.CL

TL;DR: 本文提出了一套语言学数据标准化结构（LPDS）及配套Python包（pelican nlp），解决了语言数据管理和处理无标准的问题，实现了流程透明和结果可复现，对语言处理研究具有重要推动作用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的发展和人工智能在语言处理领域的进步，使得量化分析语言数据的方法不断演化，然而随之而来的挑战包括语言数据的组织、分享缺乏标准化，以及处理方法难以标准化和复现。

Method: 提出了受脑成像数据结构（BIDS）启发的语言处理数据结构（LPDS），用于规范语言学研究中的文件夹结构和文件命名。同时，开发了一个模块化、可扩展的Python包pelican nlp，实现从数据清洗、预处理到提取复杂的语言和声学特征的全流程管理。整个流程可通过单一且可分享的配置文件规定，并自动执行于LPDS格式的数据。

Result: 该方法能够生成预处理语言数据，或提取标准化的语言及声学特征，并进行结果整理汇总。LPDS与pelican nlp结合，形成了端到端的语言学数据处理管线，提升了方法的透明性和结果的可复现性。

Conclusion: LPDS和pelican nlp共同为语言学数据的组织、处理和特征提取提供了标准化、透明和可复现的端到端解决方案，有助于推动语言学研究的数据标准化和方法可复现化。

Abstract: The introduction of large language models and other influential developments in AI-based language processing have led to an evolution in the methods available to quantitatively analyse language data. With the resultant growth of attention on language processing, significant challenges have emerged, including the lack of standardisation in organising and sharing linguistic data and the absence of standardised and reproducible processing methodologies. Striving for future standardisation, we first propose the Language Processing Data Structure (LPDS), a data structure inspired by the Brain Imaging Data Structure (BIDS), a widely adopted standard for handling neuroscience data. It provides a folder structure and file naming conventions for linguistic research. Second, we introduce pelican nlp, a modular and extensible Python package designed to enable streamlined language processing, from initial data cleaning and task-specific preprocessing to the extraction of sophisticated linguistic and acoustic features, such as semantic embeddings and prosodic metrics. The entire processing workflow can be specified within a single, shareable configuration file, which pelican nlp then executes on LPDS-formatted data. Depending on the specifications, the reproducible output can consist of preprocessed language data or standardised extraction of both linguistic and acoustic features and corresponding result aggregations. LPDS and pelican nlp collectively offer an end-to-end processing pipeline for linguistic data, designed to ensure methodological transparency and enhance reproducibility.

</details>


### [50] [Multimodal Evaluation of Russian-language Architectures](https://arxiv.org/abs/2511.15552)
*Artem Chervyakov,Ulyana Isaeva,Anton Emelyanov,Artem Safin,Maria Tikhonova,Alexander Kharitonov,Yulia Lyakh,Petr Surovtsev,Denis Shevelev Vildan Saburov,Vasily Konovalov,Elisei Rykov,Ivan Sviridov,Amina Miftakhova,Ilseyar Alimova,Alexander Panchenko,Alexander Kapitanov,Alena Fenogenova*

Main category: cs.CL

TL;DR: 该论文针对俄语领域缺乏多模态大模型评测基准问题，提出Mera Multi框架，覆盖文本、图像、音频和视频，提供统一任务与评测方法，为俄语及其他类型语言的多模态研究奠定基准和方法基础。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）发展迅速，但其智能、局限及风险仍缺乏深入理解，尤其是俄语领域缺乏相关评测基准。

Method: 提出了Mera Multi，一个面向俄语的开放多模态评测框架。该基准基于指令，覆盖文本、图片、音频与视频等模态，包含18个新构建的评测任务，适用于通用及模态特定模型。并提出了防止数据泄漏的方法，包括水印及授权机制。

Result: 贡献包括：（1）多模态能力通用分类体系；（2）完全自主创建的18个俄语文化与语言特色的数据集，统一的评测方法与指标；（3）闭源与开源模型的基线结果；（4）防benchmark泄露的方法。

Conclusion: 虽当前聚焦俄语，所提方法可复制于多样语言，尤其是斯拉夫语族，为全球多模态评测基准建设提供参考。

Abstract: Multimodal large language models (MLLMs) are currently at the center of research attention, showing rapid progress in scale and capabilities, yet their intelligence, limitations, and risks remain insufficiently understood. To address these issues, particularly in the context of the Russian language, where no multimodal benchmarks currently exist, we introduce Mera Multi, an open multimodal evaluation framework for Russian-spoken architectures. The benchmark is instruction-based and encompasses default text, image, audio, and video modalities, comprising 18 newly constructed evaluation tasks for both general-purpose models and modality-specific architectures (image-to-text, video-to-text, and audio-to-text). Our contributions include: (i) a universal taxonomy of multimodal abilities; (ii) 18 datasets created entirely from scratch with attention to Russian cultural and linguistic specificity, unified prompts, and metrics; (iii) baseline results for both closed-source and open-source models; (iv) a methodology for preventing benchmark leakage, including watermarking and licenses for private sets. While our current focus is on Russian, the proposed benchmark provides a replicable methodology for constructing multimodal benchmarks in typologically diverse languages, particularly within the Slavic language family.

</details>


### [51] [HSKBenchmark: Modeling and Benchmarking Chinese Second Language Acquisition in Large Language Models through Curriculum Tuning](https://arxiv.org/abs/2511.15574)
*Qihao Yang,Xuelin Wang,Jiale Chen,Xuelian Dong,Yuxin Hao,Tianyong Hao*

Main category: cs.CL

TL;DR: 本论文提出HKSBenchmark，系统化支持中文二语学习分阶段建模与评测，并证实现有大模型经合理训练后可达到高级学习者水平，为语言习得研究和模型可解释性提供标准平台与工具。


<details>
  <summary>Details</summary>
Motivation: 语言习得研究对于揭示人类语言智能本质至关重要，却因难以实际和伦理上控制人类学习输入而难以进行可验证、可扩展建模，尤其是中文二语领域。大模型具备可控性与可重复性，但缺少阶段性建模和评估的系统基准。该研究拟弥补此空白。

Method: 1. 构建覆盖HSK3-6级别、包含真实教材和16K合成指令样本的语料；2. 提出分阶段（由初级到高级）的课程微调（curriculum-tuning）框架以模拟语言学习过程；3. 建立涵盖语法、写作错误、词汇及句法复杂度和整体得分的多维评测系统；4. 构建并微调HSKAgent模型，并用真实学习者作文进行训练；5. 对LLM模型进行全面实验证明有效性。

Result: HSKBenchmark 实现了对中文二语阶段性建模与动态写作测评，实验中微调后的LLM写作能力可匹敌高级学习者，并展现出与人类相似的语言习得轨迹。

Conclusion: HSKBenchmark 是首个针对中文二语（SLA）阶段性语言建模与写作评估的基准，实验表明基于其微调的LLM写作能力可媲美高级人类学习者，并具有人类式的习得特征。所提出的工具和资源为后续语言习得建模及大模型可解释性研究奠定基础。

Abstract: Language acquisition is vital to revealing the nature of human language intelligence and has recently emerged as a promising perspective for improving the interpretability of large language models (LLMs). However, it is ethically and practically infeasible to conduct experiments that require controlling human learners' language inputs. This poses challenges for the verifiability and scalability of language acquisition modeling, particularly in Chinese second language acquisition (SLA). While LLMs provide a controllable and reproducible alternative, a systematic benchmark to support phase-wise modeling and assessment is still lacking. In this paper, we present HSKBenchmark, the first benchmark for staged modeling and writing assessment of LLMs in Chinese SLA. It covers HSK levels 3 to 6 and includes authentic textbooks with 6.76 million tokens, 16K synthetic instruction samples, 30 test topics, and a linguistically grounded evaluation system. To simulate human learning trajectories, we introduce a curriculum-tuning framework that trains models from beginner to advanced levels. An evaluation system is created to examine level-based grammar coverage, writing errors, lexical and syntactic complexity, and holistic scoring. We also build HSKAgent, fine-tuned on 10K learner compositions. Extensive experimental results demonstrate that HSKBenchmark not only models Chinese SLA effectively, but also serves as a reliable benchmark for dynamic writing assessment in LLMs. Our fine-tuned LLMs have writing performance on par with advanced human learners and exhibit human-like acquisition characteristics. The HSKBenchmark, HSKAgent, and checkpoints serve as foundational tools and resources, with the potential to pave the way for future research on language acquisition modeling and LLMs interpretability. Code and data are publicly available at: https://github.com/CharlesYang030/HSKB.

</details>


### [52] [Tokenisation over Bounded Alphabets is Hard](https://arxiv.org/abs/2511.15709)
*Violeta Kastreva,Philip Whittington,Dennis Komm,Tiago Pimentel*

Main category: cs.CL

TL;DR: 本文证明了即使在实际应用中有限字母表（如二元/单元），tokenisation依然是NP-完全且不可近似，从理论层面支持了现有启发式方案的合理性，并建议未来应关注近似算法的研究。


<details>
  <summary>Details</summary>
Motivation: 以往关于Tokenisation（分词）NP-完全性的工作，假定输入字母表大小无限大，但实际应用中Tokeniser是在有限字母表（如字节、Unicode字符）上工作的。该文旨在弥补此理论与现实的差距。

Method: 形式化地分析了有限大小（如二元、单元）字母表上的tokenisation问题，分别研究了两种自然变体：自底向上的合并操作序列选择（bottom-up）和直接选择词表的优化压缩（direct），并进行了复杂度证明。

Result: 1. 证明了对任意固定大小的字母表（即使是二元或单元），tokenisation的两个变体均是NP-完全的，且不存在多项式时间近似方案，除非P=NP。2. 直接tokenisation在只用单一字母的情况下依然是NP-完全，说明计算难度不是由于字母表过大或特殊构造造成的，而是本质的。

Conclusion: 对tokenisation的计算难度进行了严格界定，解释了为什么BPE、UnigramLM等实际tokeniser只能采用启发式算法，并提出未来可行的研究路径是寻找高效的近似算法。

Abstract: Recent works have shown that tokenisation is NP-complete. However, these works assume tokenisation is applied to inputs with unboundedly large alphabets -- an unrealistic assumption, given that in practice tokenisers operate over fixed-size alphabets, such as bytes or Unicode characters. We close this gap by analysing tokenisation over bounded $n$-ary alphabets, considering two natural variants: bottom-up tokenisation and direct tokenisation, where we must, respectively, select a sequence of merge operations or a vocabulary whose application optimally compresses a dataset. First, we note that proving hardness results for an $n$-ary alphabet proves the same results for alphabets of any larger size. We then prove that even with binary alphabets, both variants are not only NP-complete, but admit no polynomial-time approximation scheme (unless P=NP). We further show that direct tokenisation remains NP-complete even when applied to unary alphabets. While unary alphabets may not be practically useful, this result establishes that the computational intractability of tokenisation is not an artifact of large alphabets or complex constructions, but a fundamental barrier. Overall, our results explain why practical algorithms such as BPE and UnigramLM are heuristic, and points toward approximation algorithms being an important path going forward for tokenisation research.

</details>
