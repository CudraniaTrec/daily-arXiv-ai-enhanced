<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]
- [cs.SE](#cs.SE) [Total: 12]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.CL](#cs.CL) [Total: 25]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Filling the Gaps of Polarity: Implementing Dependent Data and Codata Types with Implicit Arguments](https://arxiv.org/abs/2511.15819)
*Bohdan Liesnikov,David Binder,Tim Süberkrüb*

Main category: cs.PL

TL;DR: 本文针对表达问题，提出了 Polarity 依赖类型语言的类型系统算法与统一算法，首次实现了对归纳与余归纳类型的对称支持和隐式参数推理，提升了语言的可用性并为相关领域技术发展提供了范例。


<details>
  <summary>Details</summary>
Motivation: 现有依赖类型语言在扩展数据类型（如函数式编程中的代数数据类型）和扩展构造器（如面向对象编程中的接口实现）时存在权衡，且对后者支持较弱。Polarity 语言旨在对两种类型扩展提供对称支持，但目前缺乏一些先进功能（如隐式参数）。作者希望为 Polarity 设计一个兼容对称核心的隐式参数推理系统。

Method: 作者为 Polarity 语言构建了完整的类型系统算法描述，并提出了针对任意归纳和余归纳类型的统一算法。包括约简语义规则、转换检测以及模式匹配统一算法，确保实现的可用性。

Result: 成功设计了适用于 Polarity 的类型系统和统一算法。这些算法已在原型实现中应用，并能处理归纳与余归纳类型的推理及匹配。

Conclusion: 论文为同时支持归纳和余归纳类型的依赖类型语言提供了明确、完整的类型推理及统一算法方案，不仅推动了 Polarity 语言发展，也可为其他同类语言提供借鉴。

Abstract: The expression problem describes a fundamental tradeoff between two types of extensibility: extending a type with new operations, such as by pattern matching on an algebraic data type in functional programming, and extending a type with new constructors, such as by adding a new object implementing an interface in object-oriented programming. Most dependently typed languages have good support for the former style through inductive types, but support for the latter style through coinductive types is usually much poorer. Polarity is a language that treats both kinds of types symmetrically and allows the developer to switch between type representations.However, it currently lacks several features expected of a state-of-the-art dependently typed language, such as implicit arguments. The central aim of this paper is to provide an algorithmic type system and inference algorithm for implicit arguments that respect the core symmetry of the language. Our work provides two key contributions: a complete algorithmic description of the type system backing Polarity, and a comprehensive description of a unification algorithm that covers arbitrary inductive and coinductive types. We give rules for reduction semantics, conversion checking, and a unification algorithm for pattern-matching, which are essential for a usable implementation. A work-in-progress implementation of the algorithms in this paper is available at https://polarity-lang.github.io/. We expect that the comprehensive account of the unification algorithm and our design decisions can serve as a blueprint for other dependently typed languages that support inductive and coinductive types symmetrically.

</details>


### [2] [Chorex: Restartable, Language-Integrated Choreographies](https://arxiv.org/abs/2511.15820)
*Ashton Wiersdorf,Ben Greenman*

Main category: cs.PL

TL;DR: Chorex是一种为Elixir设计的编舞式编程语言，支持actor失效自动恢复，并通过元编程实现与主语言的紧密结合，提升了分布式应用的鲁棒性与可维护性。


<details>
  <summary>Details</summary>
Motivation: 现有编舞式编程语言在actor失效容错能力有限，且与主语言集成度不足。为提升分布式应用鲁棒性，需更好兼容Elixir并支持actor重启与状态恢复。

Method: 设计了Chorex编程语言，将编舞式编程理念融入Elixir，并实现了容错机制。通过示例应用（如高阶书商与安全远程密码协议）和性能测量展示其效果。

Result: Chorex能容忍actor失败、自动重启并恢复状态；利用元编程实现与Elixir的深度整合；静态检测actor源码与编舞契约不一致；性能开销（如checkpointing）得到实测；投影为无状态函数集方法具普适性。

Conclusion: Chorex通过容错和紧密整合Elixir，展现了编舞式编程在分布式应用中的实用性。其投影策略可推广到其他语言以支持可重启actor。

Abstract: We built Chorex, a language that brings choreographic programming to Elixir as a path toward robust distributed applications. Chorex is unique among choreographic languages because it tolerates failure among actors: when an actor crashes, Chorex spawns a new process, restores state using a checkpoint, and updates the network configuration for all actors. Chorex also proves that full-featured choreographies can be implemented via metaprogramming, and that doing so achieves tight integration with the host language. For example, mismatches between choreography requirements and an actor implementation are reported statically and in terms of source code rather than macro-expanded code. This paper illustrates Chorex on several examples, ranging from a higher-order bookseller to a secure remote password protocol, details its implementation, and measures the overhead of checkpointing. We conjecture that Chorex's projection strategy, which outputs sets of stateless functions, is a viable approach for other languages to support restartable actors.

</details>


### [3] [BlueScript: A Disaggregated Virtual Machine for Microcontrollers](https://arxiv.org/abs/2511.15821)
*Fumika Mochizuki,Tetsuro Yamazaki,Shigeru Chiba*

Main category: cs.PL

TL;DR: 本文针对微控制器VM功能受限问题，提出分散式虚拟机架构，将多数组件卸载到主机，极大提升了交互性、功能和执行速度。设计的BlueScript VM通过实验验证，在性能和开发体验上优于现有方案，展示了该方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 微控制器由于内存有限，常用的虚拟机（VM）功能受限，难以兼顾高交互性与高执行速度。现有的VM通常无法提供丰富的开发体验，而对于组件的卸载也受限。

Method: 提出了一种分散式虚拟机（disaggregated VM）架构，将尽可能多的VM组件卸载到主机上，通过主机强大的内存与处理能力来增强虚拟机功能。借此，设计并实现了称为BlueScript VM的实例，并采用影子机（shadow machine）数据结构来减少主机和微控制器之间的通信开销。

Result: 大量组件卸载至主机后，并未显著影响预期性能，卸载的增量编译器比MicroPython与Espruino执行速度更快，同时交互性与MicroPython相当。卸载的动态编译器也进一步提升了VM性能。

Conclusion: 在微控制器这样内存受限的平台上，通过分散式虚拟机架构，将功能卸载到主机，不仅保持高交互性和高性能，还能丰富开发环境的功能，证明了提供高级特性的可行性。

Abstract: Virtual machines (VMs) are highly beneficial for microcontroller development. 
In particular, interactive programming environments greatly facilitate iterative development processes, 
and higher execution speeds expand the range of applications that can be developed. 
However, due to their limited memory size, microcontroller VMs provide a limited set of features. 
Widely used VMs for microcontrollers often lack interactive responsiveness and/or high execution speed. 
While researchers have investigated offloading certain VM components to other machines,the types of components that can be offloaded are still restricted. 
In this paper, we propose a disaggregated VM that offloads as many components as possible to a host machine. 
This makes it possible to exploit the abundant memory of the host machine and its powerful processing capability to provide rich features through the VM. 
As an instance of a disaggregated VM, we design and implement a BlueScript VM. 
The BlueScript VM is a virtual machine for microcontrollers that provides an interactive development environment. 
We offload most of the components of the BlueScript VM to a host machine. 
To reduce communication overhead between the host machine and the microcontroller,  
we employed a data structure called a shadow machine on the host machine, 
which mirrors the execution state of the microcontroller. 
Through our experiments, we confirmed that offloading components does not seriously compromise their expected benefits.  
We assess that an offloaded incremental compiler results in faster execution speed than MicroPython and Espruino,  
while keeping interactivity comparable with MicroPython.  
In addition, our experiments observe that the offloaded dynamic compiler improves VM performance. 
Through this investigation, we demonstrate the feasibility of providing rich features even on VMs for memory-limited microcontrollers.

</details>


### [4] [Operon: Incremental Construction of Ragged Data via Named Dimensions](https://arxiv.org/abs/2511.16080)
*Sungbin Moon,Jiho Park,Suyoung Hwang,Donghyun Koh,Seunghyun Moon,Minhyeong Lee*

Main category: cs.PL

TL;DR: Operon是一种面向不规则数据（ragged data）的高效并行工作流引擎，形式化了部分形状推理并通过多队列结构有效提升了数据处理能力，实验验证显著优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 现有工作流引擎无法原生支持变长数据，用户需手动维护复杂的索引和依赖。这限制了自然语言、科学测量、AI等领域对大规模不规则数据处理的效率和可靠性。

Method: 采用命名维度和显式依赖关系，在DSL中声明并静态检查流水线，通过增量算法动态调度，支持部分已知数据形状的推理和任务分发，多队列架构实现高效并行，理论上证明确定性和合流性。

Result: 本文提出了Operon，一种基于Rust的工作流引擎。Operon通过带有命名维度和显式依赖关系的新型形式化机制，支持变长（ragged）数据元素的处理。它让用户用特定领域语言（DSL）声明带有维度注解的流水线，并在编译时静态校验正确性，执行时根据数据逐步发现的形状动态调度任务。Operon在数学上形式化了部分形状的推理方法，并证明了其增量构建算法在并行状态下可保证确定性和合流性。该系统还具有强大的持久性和恢复机制，同时通过每任务多队列架构高效实现并行。实验显示，Operon比现有引擎的基准开销下降14.94倍，且在大规模任务下保持近线性输出率。

Conclusion: Operon能高效并可靠地处理不规则数据工作流，尤其适用于大规模机器学习等数据生成应用，显著降低系统开销，提升并行效率。

Abstract: Modern data processing workflows frequently encounter ragged data: collections with variable-length elements that arise naturally in domains like natural language processing, scientific measurements, and autonomous AI agents. Existing workflow engines lack native support for tracking the shapes and dependencies inherent to ragged data, forcing users to manage complex indexing and dependency bookkeeping manually. We present Operon, a Rust-based workflow engine that addresses these challenges through a novel formalism of named dimensions with explicit dependency relations. Operon provides a domain-specific language where users declare pipelines with dimension annotations that are statically verified for correctness, while the runtime system dynamically schedules tasks as data shapes are incrementally discovered during execution. We formalize the mathematical foundation for reasoning about partial shapes and prove that Operon's incremental construction algorithm guarantees deterministic and confluent execution in parallel settings. The system's explicit modeling of partially-known states enables robust persistence and recovery mechanisms, while its per-task multi-queue architecture achieves efficient parallelism across heterogeneous task types. Empirical evaluation demonstrates that Operon outperforms an existing workflow engine with 14.94x baseline overhead reduction while maintaining near-linear end-to-end output rates as workloads scale, making it particularly suitable for large-scale data generation pipelines in machine learning applications.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [5] [Technique to Baseline QE Artefact Generation Aligned to Quality Metrics](https://arxiv.org/abs/2511.15733)
*Eitan Farchi,Kiran Nayak,Papia Ghosh Majumdar,Saritha Route*

Main category: cs.SE

TL;DR: 本文提出了结合大语言模型生成、逆向生成以及基于量化标准迭代优化的工件评估方法，实验证明逆向生成能提升低质输入工件质量，最终实现大规模高可靠性的自动化质量工程工件验证。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在质量工程领域自动化生成需求、测试用例等，但保证这些产出物的质量仍然困难，需要系统化的评估方法。

Method: 提出了一种系统方法，将LLM生成、逆向生成以及基于量化标准（如清晰度、完整性、一致性和可测试性）的迭代改进相结合，进行工件的基线评估与验证。

Result: 在12个项目的实验中，逆向生成的工件在输入质量低时能超越原始工件，当输入质量高时也能保持高标准。

Conclusion: 该框架提升了质量工程工件的评估与验证的可靠性与可扩展性，实现了自动化与责任制的结合。

Abstract: Large Language Models (LLMs) are transforming Quality Engineering (QE) by automating the generation of artefacts such as requirements, test cases, and Behavior Driven Development (BDD) scenarios. However, ensuring the quality of these outputs remains a challenge. This paper presents a systematic technique to baseline and evaluate QE artefacts using quantifiable metrics. The approach combines LLM-driven generation, reverse generation , and iterative refinement guided by rubrics technique for clarity, completeness, consistency, and testability. Experimental results across 12 projects show that reverse-generated artefacts can outperform low-quality inputs and maintain high standards when inputs are strong. The framework enables scalable, reliable QE artefact validation, bridging automation with accountability.

</details>


### [6] [Rethinking Kernel Program Repair: Benchmarking and Enhancing LLMs with RGym](https://arxiv.org/abs/2511.15757)
*Kareem Shehada,Yifan Wu,Wyatt D. Feng,Adithya Iyer,Gryphon Kumfert,Yangruibo Ding,Zhiyun Qian*

Main category: cs.SE

TL;DR: 本文提出RGym，一个轻量级、可在本地运行的Linux内核自动化修复评测框架，克服了现有工具高成本和效率低的问题。基于GPT-5 Thinking和新颖的bug定位策略，在143个实际内核bug上修复率高达43.36%，平均成本极低。实验显示定位方法和反馈重试均能显著增强修复效果。该工作为内核空间程序自动修复提供了新路径。


<details>
  <summary>Details</summary>
Motivation: 当前自动化程序修复（APR）的基准测试主要集中在用户空间应用，而忽略了具有高度复杂性的内核空间调试与修复，尤其是Linux内核，由于其单体结构、并发性以及硬件底层交互，修复难度极大。现有内核相关工具如KGym和CrashFixer成功率低或成本高，缺乏高效、普适的平台。

Method: 作者提出了RGym，一个轻量、跨平台的Linux内核APR评测框架，可在本地普通硬件上运行。基于RGym，他们设计了一个简易却有效的APR流程，利用专门的定位技术（如调用栈分析和blamed commits），避免了KGym中对oracle的依赖，并在经过筛选和验证的143个bug数据集上评估方法效果。

Result: 在143个内核bug上，方案使用GPT-5 Thinking模型达到43.36%的修复通过率，单个bug成本低于$0.20。进一步消融实验表明，定位策略、提示结构和模型选择均有显著贡献，并且基于反馈的重试机制显著提升修复成功率。

Conclusion: RGym及其APR流程为Linux内核空间程序自动修复提供了高效、低成本的新选择，突破了现有工具的成本和通用性限制，内核修复领域有显著提升空间。

Abstract: Large Language Models (LLMs) have revolutionized automated program repair (APR) but current benchmarks like SWE-Bench predominantly focus on userspace applications and overlook the complexities of kernel-space debugging and repair. The Linux kernel poses unique challenges due to its monolithic structure, concurrency, and low-level hardware interactions. Prior efforts such as KGym and CrashFixer have highlighted the difficulty of APR in this domain, reporting low success rates or relying on costly and complex pipelines and pricey cloud infrastructure. In this work, we introduce RGym, a lightweight, platform-agnostic APR evaluation framework for the Linux kernel designed to operate on local commodity hardware. Built on RGym, we propose a simple yet effective APR pipeline leveraging specialized localization techniques (e.g., call stacks and blamed commits) to overcome the unrealistic usage of oracles in KGym. We test on a filtered and verified dataset of 143 bugs. Our method achieves up to a 43.36% pass rate with GPT-5 Thinking while maintaining a cost of under $0.20 per bug. We further conduct an ablation study to analyze contributions from our proposed localization strategy, prompt structure, and model choice, and demonstrate that feedback-based retries can significantly enhance success rates.

</details>


### [7] [A Causal Perspective on Measuring, Explaining and Mitigating Smells in \llm-Generated Code](https://arxiv.org/abs/2511.15817)
*Alejandro Velasco,Daniel Rodriguez-Cardenas,Dipin Khati,David N. Palacio,Luftar Rahman Alif,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: 本文提出并验证了PSC度量，大语言模型生成代码的结构质量问题可被识别并部分缓解，提示词和模型架构优化能有效减少代码异味，为高质量代码生成提供了理论和工具支持。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）在软件工程领域取得了快速应用，但其生成代码的结构质量仍受质疑，特别是代码中易出现“代码异味”等不良编程习惯的复制，影响可读性和可维护性。现有研究大多关注检测或修复这些问题，对于代码异味在生成过程中如何出现、何时出现了解不足。

Method: 本文基于概率度量工具Propensity Smelly Score（PSC）来系统性地测量、解释和缓解大模型生成代码的异味倾向。作者用PSC工具进行因果分析，评估生成策略、模型规模、架构及提示词设计如何影响生成代码的结构属性，并通过用户研究验证PSC对开发者理解和评估代码质量的帮助。

Result: 研究发现，提示词设计和模型架构对代码异味倾向具有决定性影响，并提出了实用的缓解策略，有效减少异味的出现。用户研究显示PSC可辅助开发者判断模型行为和代码质量。

Conclusion: PSC是一种可靠的代码结构质量信号，有助于理解和改善LLM生成代码的结构问题，为将质量感知评价纳入LLM评测和部署提供了方法基础。

Abstract: Recent advances in large language models (LLMs) have accelerated their adoption in software engineering contexts. However, concerns persist about the structural quality of the code they produce. In particular, LLMs often replicate poor coding practices, introducing code smells (i.e., patterns that hinder readability, maintainability, or design integrity). Although prior research has examined the detection or repair of smells, we still lack a clear understanding of how and when these issues emerge in generated code.
  This paper addresses this gap by systematically measuring, explaining and mitigating smell propensity in LLM-generated code. We build on the Propensity Smelly Score (PSC), a probabilistic metric that estimates the likelihood of generating particular smell types, and establish its robustness as a signal of structural quality. Using PSC as an instrument for causal analysis, we identify how generation strategy, model size, model architecture and prompt formulation shape the structural properties of generated code. Our findings show that prompt design and architectural choices play a decisive role in smell propensity and motivate practical mitigation strategies that reduce its occurrence. A user study further demonstrates that PSC helps developers interpret model behavior and assess code quality, providing evidence that smell propensity signals can support human judgement. Taken together, our work lays the groundwork for integrating quality-aware assessments into the evaluation and deployment of LLMs for code.

</details>


### [8] [AI-Enabled Orchestration of Event-Driven Business Processes in Workday ERP for Healthcare Enterprises](https://arxiv.org/abs/2511.15852)
*Monu Sharma*

Main category: cs.SE

TL;DR: 本文提出AI驱动的事件编排框架，集成Workday ERP，显著提升了医疗行业流程效率和管理能力，为智能ERP自动化提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 云端ERP系统如Workday在医疗卫生领域集成财务、供应链和人力流程，但传统ERP工作流对于高事件驱动和数据密集型医疗环境适应性不足。

Method: 提出AI驱动的事件导向编排框架，集成于Workday ERP，利用机器学习触发器、异常检测与流程挖掘分析，实现跨医疗机构的财务与供应链自动化同步。

Result: 通过多组织案例分析，证明该框架在流程效率、成本可视化和决策准确性方面取得了可量化提升。

Conclusion: 将AI能力嵌入Workday事件驱动架构提升了医疗企业的运营韧性、治理能力和可扩展性，并为智能ERP集成和下一代自动化策略树立了参考。

Abstract: The adoption of cloud-based Enterprise Resource Planning (ERP) platforms such as Workday has transformed healthcare operations by integrating financial, supply-chain, and workforce processes into a unified ecosystem. However, traditional workflow logic in ERP systems often lacks the adaptability required to manage event-driven and data-intensive healthcare environments.
  This study proposes an AI-enabled event-driven orchestration framework within Workday ERP that intelligently synchronizes financial and supply-chain workflows across distributed healthcare entities. The framework employs machine-learning triggers, anomaly detection, and process mining analytics to anticipate and automate responses to operational events such as inventory depletion, payment delays, or patient demand fluctuations. A multi-organization case analysis demonstrates measurable gains in process efficiency, cost visibility, and decision accuracy.
  Results confirm that embedding AI capabilities into Workday's event-based architecture enhances operational resilience, governance, and scalability. The proposed model contributes to the broader understanding of intelligent ERP integration and establishes a reference for next-generation automation strategies in healthcare enterprises.

</details>


### [9] [RE for AI in Practice: Managing Data Annotation Requirements for AI Autonomous Driving Systems](https://arxiv.org/abs/2511.15859)
*Hina Saeeda,Mazen Mohamad,Eric Knauss,Jennifer Horkoff,Ali Nouri*

Main category: cs.SE

TL;DR: 本文通过访谈与主题分析，系统梳理了自动驾驶AI系统数据标注需求的现状、挑战及改进方法，首次提出了实证指导，有助于提升标注质量、合规性与系统可靠性，并推动AI软件工程与需求工程领域融合。


<details>
  <summary>Details</summary>
Motivation: 高质量数据标注需求对于AI感知系统安全可靠至关重要，但其制定与管理尚未被充分研究，导致实际应用中存在一致性差、安全风险和合规隐患。

Method: 通过对来自六家国际公司和四家研究机构的19次半结构化访谈，进行主题分析以总结挑战和最佳实践。

Result: 发现了五大主要挑战（歧义、边界案例复杂性、需求演化、不一致性、资源受限）、三类最佳实践（伦理合规、需求指南改进、质量嵌入），揭示了需求缺陷如何影响整个AIePS开发流程。

Conclusion: 本研究首次对高质量数据标注需求在自动驾驶AI感知系统中的定义、实施及其挑战进行了系统性的实证分析，并提出了改进建议，为行业提供了操作性指导。

Abstract: High-quality data annotation requirements are crucial for the development of safe and reliable AI-enabled perception systems (AIePS) in autonomous driving. Although these requirements play a vital role in reducing bias and enhancing performance, their formulation and management remain underexplored, leading to inconsistencies, safety risks, and regulatory concerns. Our study investigates how annotation requirements are defined and used in practice, the challenges in ensuring their quality, practitioner-recommended improvements, and their impact on AIePS development and performance. We conducted $19$ semi-structured interviews with participants from six international companies and four research organisations. Our thematic analysis reveals five main key challenges: ambiguity, edge case complexity, evolving requirements, inconsistencies, and resource constraints and three main categories of best practices, including ensuring compliance with ethical standards, improving data annotation requirements guidelines, and embedded quality assurance for data annotation requirements. We also uncover critical interrelationships between annotation requirements, annotation practices, annotated data quality, and AIePS performance and development, showing how requirement flaws propagate through the AIePS development pipeline. To the best of our knowledge, this study is the first to offer empirically grounded guidance on improving annotation requirements, offering actionable insights to enhance annotation quality, regulatory compliance, and system reliability. It also contributes to the emerging fields of Software Engineering (SE for AI) and Requirements Engineering (RE for AI) by bridging the gap between RE and AI in a timely and much-needed manner.

</details>


### [10] [InfCode: Adversarial Iterative Refinement of Tests and Patches for Reliable Software Issue Resolution](https://arxiv.org/abs/2511.16004)
*KeFan Li,Mengfei Wang,Hengzhi Zhang,Zhichao Li,Yuan Yuan,Mu Li,Xiang Gao,Hailong Sun,Chunming Hu,Weifeng Lv*

Main category: cs.SE

TL;DR: 本文提出InfCode对抗性多智能体框架，实现软件仓库级自动缺陷修复。利用测试与补丁生成器的对抗交互提升了修复质量，实验在主流数据集上取得新最佳表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在软件工程自动化方面取得了进展，但解决真实世界中的软件问题依然困难，原因包括需要仓库级推理、准确的诊断，以及强验证信号。目前的agent和流水线方法常依赖于不足的测试，导致只满足验证却未真正修复缺陷。

Method: InfCode提出了一种对抗性多智能体框架用于自动仓库级别问题解决。通过测试补丁生成器和代码补丁生成器之间的对抗交互，迭代细化测试和补丁。同时，选择器代理负责选出最可靠的修复方案。整个框架在容器化环境中运行，支持真实仓库检查、修改和验证。

Result: 在SWE-bench Lite和SWE-bench Verified上进行的实验表明，InfCode持续优于强基线方法。使用如DeepSeek-V3和Claude 4.5 Sonnet等模型，InfCode在SWE-bench Verified上取得了79.4%的表现，达到了新的最先进水平。

Conclusion: InfCode通过多智能体对抗和选择机制，有效提升了自动仓库级别缺陷修复的准确性与可靠性，达到了新的业界最佳水平并已开源。

Abstract: Large language models have advanced software engineering automation, yet resolving real-world software issues remains difficult because it requires repository-level reasoning, accurate diagnostics, and strong verification signals. Existing agent-based and pipeline-based methods often rely on insufficient tests, which can lead to patches that satisfy verification but fail to fix the underlying defect. We present InfCode, an adversarial multi-agent framework for automated repository-level issue resolution. InfCode iteratively refines both tests and patches through adversarial interaction between a Test Patch Generator and a Code Patch Generator, while a Selector agent identifies the most reliable fix. The framework runs inside a containerized environment that supports realistic repository inspection, modification, and validation. Experiments on SWE-bench Lite and SWE-bench Verified using models such as DeepSeek-V3 and Claude 4.5 Sonnet show that InfCode consistently outperforms strong baselines. It achieves 79.4% performance on SWE-bench Verified, establishing a new state-of-the-art. We have released InfCode as an open-source project at https://github.com/Tokfinity/InfCode.

</details>


### [11] [InfCode-C++: Intent-Guided Semantic Retrieval and AST-Structured Search for C++ Issue Resolution](https://arxiv.org/abs/2511.16005)
*Qingao Dong,Mengfei Wang,Hengzhi Zhang,Zhichao Li,Yuan Yuan,Mu Li,Xiang Gao,Hailong Sun,Chunming Hu,Weifeng Lv*

Main category: cs.SE

TL;DR: 本文提出首个面向 C++ 的仓库级自动修复系统 INFCODE-C++，通过语义与结构双重检索显著提升 C++ 项目的 issue 解决能力，性能大幅领先以 Python 为主的现有方法，并强调了多语言软件智能体需具备语言感知推理，奠定了未来 LLM 自动修复复杂静态语言的软件基础。


<details>
  <summary>Details</summary>
Motivation: 目前基于大语言模型（LLM）的智能体在代码仓库层面的 issue 解决上展现出强大能力，但大多系统仅针对 Python 设计，主要依赖词法检索和浅层代码导航。这种方法在面对复杂的 C++ 项目时效果不佳，因为 C++ 存在重载标识符、嵌套命名空间、模板实例化以及复杂控制流结构，导致上下文检索和错误定位变得更加困难。

Method: 提出了 INFCODE-C++ 系统，首次针对 C++ 实现端到端的 autonomous issue 解决方案。该系统结合了语义代码意图检索和基于确定性 AST 结构的查询两种互补检索机制，能够为修复任务构造准确、具有语言感知的上下文。

Result: 在 MultiSWE-bench-CPP 基准测试集上，INFCODE-C++ 达到 25.58% 的 issue 解决率，超过了之前最强的智能体 10.85 个百分点，并且性能是 MSWE-agent 的两倍以上。消融实验和行为研究表明语义检索、结构化分析以及高保真重现对 C++ 问题解决至关重要。

Conclusion: INFCODE-C++ 证明了多语言软件智能体需要具备语言感知推理能力，推动了面向复杂静态类型生态系统的可扩展 LLM 自动修复的研究基础。

Abstract: Large language model (LLM) agents have recently shown strong performance on repository-level issue resolution, but existing systems are almost exclusively designed for Python and rely heavily on lexical retrieval and shallow code navigation. These approaches transfer poorly to C++ projects, where overloaded identifiers, nested namespaces, template instantiations, and deep control-flow structures make context retrieval and fault localization substantially more difficult. As a result, state-of-the-art Python-oriented agents show a drastic performance drop on the C++ subset of MultiSWE-bench. We introduce INFCODE-C++, the first C++-aware autonomous system for end-to-end issue resolution. The system combines two complementary retrieval mechanisms -- semantic code-intent retrieval and deterministic AST-structured querying -- to construct accurate, language-aware context for repair.These components enable precise localization and robust patch synthesis in large, statically typed C++ repositories. Evaluated on the \texttt{MultiSWE-bench-CPP} benchmark, INFCODE-C++ achieves a resolution rate of 25.58\%, outperforming the strongest prior agent by 10.85 percentage points and more than doubling the performance of MSWE-agent. Ablation and behavioral studies further demonstrate the critical role of semantic retrieval, structural analysis, and accurate reproduction in C++ issue resolution. INFCODE-C++ highlights the need for language-aware reasoning in multi-language software agents and establishes a foundation for future research on scalable, LLM-driven repair for complex, statically typed ecosystems.

</details>


### [12] [The Future of Development Environments with AI Foundation Models: NII Shonan Meeting 222 Report](https://arxiv.org/abs/2511.16092)
*Xing Hu,Raula Gaikovina Kula,Christoph Treude*

Main category: cs.SE

TL;DR: 本文报告了33位专家围绕生成式人工智能对集成开发环境（IDE）影响的专题讨论，总结了相关挑战与前沿机遇，对未来IDE的智能化发展提出了重要见解。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能（GenAI）在软件工程各项任务获得显著进展，有望提升开发过程抽象层次，改变开发者与IDE的互动方式，因此需要探讨其对集成开发环境（IDE）的影响。

Method: 邀请来自软件工程、人工智能和人机交互领域的33位专家，在Shonan Meeting 222进行讨论，总结形成报告。

Result: 专家们讨论了GenAI在IDE中的挑战与机遇，内容涉及代码生成、测试、代码评审、程序修复等任务对开发环境的潜在改变。

Conclusion: GenAI可显著提升IDE的开发效率和智能化水平，但同时也带来新挑战。进一步研究与实践有助于把握其机遇、应对挑战。

Abstract: Generative Artificial Intelligence (GenAI) models are achieving remarkable performance in various tasks, including code generation, testing, code review, and program repair. The ability to increase the level of abstraction away from writing code has the potential to change the Human-AI interaction within the integrated development environment (IDE). To explore the impact of GenAI on IDEs, 33 experts from the Software Engineering, Artificial Intelligence, and Human-Computer Interaction domains gathered to discuss challenges and opportunities at Shonan Meeting 222. This is the report

</details>


### [13] [Domain-constrained Synthesis of Inconsistent Key Aspects in Textual Vulnerability Descriptions](https://arxiv.org/abs/2511.16123)
*Linyi Han,Shidong Pan,Zhenchang Xing,Sofonias Yitagesu,Xiaowang Zhang,Zhiyong Feng,Jiamou Sun,Qing Huang*

Main category: cs.SE

TL;DR: 本文针对多源文本漏洞描述信息不一致问题，提出了一个三阶段LLM综合框架，实现了高效统一关键细节，并开发了信息可视化工具，显著提升性能和用户体验。


<details>
  <summary>Details</summary>
Motivation: 文本漏洞描述（TVDs）对安全分析师理解和解决软件漏洞至关重要，但由于来自不同仓库的TVDs在关键信息上存在不一致性，导致难以全面了解漏洞。现有方法通过与外部知识库对齐TVDs来缓解这种不一致，但常常丢弃有价值信息，无法合成全面表征。为解决此问题，本文提出统一TVD关键信息的新方法。

Method: 提出了一个基于领域约束的大语言模型（LLM）综合框架，包括三阶段：1) 采用基于规则的模板提取所有关键细节；2) 利用领域特定锚词自我评估语义变异性；3) 通过信息熵融合，消除不一致并优先保留相关信息。还开发了Digest Labels工具，用于可视化TVDs。

Result: 该框架提高了TVD综合性能，将关键信息增强的F1分数从0.82提升至0.87，并使理解与效率提升超过30%。Digest Labels工具的可用性也显著提升（经验评估）。

Conclusion: 新的LLM综合框架能有效统一并增强多源TVD关键信息，为漏洞理解与安全分析提供更高效、全面的工具；Digest Labels工具提升了TVD可用性和人机交互效果。

Abstract: Textual Vulnerability Descriptions (TVDs) are crucial for security analysts to understand and address software vulnerabilities. However, the key aspect inconsistencies in TVDs from different repositories pose challenges for achieving a comprehensive understanding of vulnerabilities. Existing approaches aim to mitigate inconsistencies by aligning TVDs with external knowledge bases, but they often discard valuable information and fail to synthesize comprehensive representations. In this paper, we propose a domain-constrained LLM-based synthesis framework for unifying key aspects of TVDs. Our framework consists of three stages: 1) Extraction, guided by rule-based templates to ensure all critical details are captured; 2) Self-evaluation, using domain-specific anchor words to assess semantic variability across sources; and 3) Fusion, leveraging information entropy to reconcile inconsistencies and prioritize relevant details. This framework improves synthesis performance, increasing the F1 score for key aspect augmentation from 0.82 to 0.87, while enhancing comprehension and efficiency by over 30\%. We further develop Digest Labels, a practical tool for visualizing TVDs, which human evaluations show significantly boosts usability.

</details>


### [14] [Beyond Code Similarity: Benchmarking the Plausibility, Efficiency, and Complexity of LLM-Generated Smart Contracts](https://arxiv.org/abs/2511.16224)
*Francesco Salzano,Simone Scalabrino,Rocco Oliveto,Simone Scalabrino*

Main category: cs.SE

TL;DR: 本文评估了主流LLM生成Solidity智能合约的功能与非功能属性。结果显示，虽然生成代码在语义上与真实合约相似，但功能正确性较低，尤其常缺乏关键的验证逻辑。检索增强生成（RAG）能显著提升正确率，然而实现真正可靠、可生产的合约代码仍充满挑战，需人工专家严格把关。


<details>
  <summary>Details</summary>
Motivation: 智能合约在区块链生态系统中非常关键。目前主流的智能合约编程语言是Solidity。尽管大语言模型（LLM）在通用代码生成任务上表现出色，但智能合约开发有许多独特约束（如gas消耗、安全性和确定性），这些都影响了LLM生成Solidity代码的可靠性。现有研究未能全面评价这些关键的功能性与非功能性属性。

Method: 作者对四个主流大语言模型进行了基准测试，分别在零样本和检索增强生成（RAG）设置下，对500个真实智能合约函数展开评估。评估方法包括代码相似度、语义嵌入、自动化测试执行、gas消耗分析、认知与圈复杂度分析等多项指标。

Result: 实验结果发现，LLM生成的合约代码虽然与真实合约有较高语义相似性，但其功能正确性很低：仅有20%到26%的零样本生成代码在测试下与标准实现行为完全一致。生成代码通常更简洁，复杂度和gas消耗更低，但经常省略了必要的验证逻辑。加入RAG后，功能正确性显著提升，最高可达45%，且代码更简明高效。

Conclusion: LLM生成智能合约代码在语义相似性和功能可行性之间存在显著差距。RAG能够有效提升性能，但要实现可用于生产的高质量代码生成，仍需专家仔细验证。

Abstract: Smart Contracts are critical components of blockchain ecosystems, with Solidity as the dominant programming language. While LLMs excel at general-purpose code generation, the unique constraints of Smart Contracts, such as gas consumption, security, and determinism, raise open questions about the reliability of LLM-generated Solidity code. Existing studies lack a comprehensive evaluation of these critical functional and non-functional properties. We benchmark four state-of-the-art models under zero-shot and retrieval-augmented generation settings across 500 real-world functions. Our multi-faceted assessment employs code similarity metrics, semantic embeddings, automated test execution, gas profiling, and cognitive and cyclomatic complexity analysis. Results show that while LLMs produce code with high semantic similarity to real contracts, their functional correctness is low: only 20% to 26% of zero-shot generations behave identically to ground-truth implementations under testing. The generated code is consistently simpler, with significantly lower complexity and gas consumption, often due to omitted validation logic. Retrieval-Augmented Generation markedly improves performance, boosting functional correctness by up to 45% and yielding more concise and efficient code. Our findings reveal a significant gap between semantic similarity and functional plausibility in LLM-generated Smart Contracts. We conclude that while RAG is a powerful enhancer, achieving robust, production-ready code generation remains a substantial challenge, necessitating careful expert validation.

</details>


### [15] [Data Annotation Quality Problems in AI-Enabled Perception System Development](https://arxiv.org/abs/2511.16410)
*Hina Saeeda,Tommy Johansson,Mazen Mohamad,Eric Knauss*

Main category: cs.SE

TL;DR: 本文系统梳理和分类了自动驾驶AI感知系统数据标注中的18种常见错误，提出了分类法并获业界验证，对提升数据标注质量和供应链合作有重要参考价值。


<details>
  <summary>Details</summary>
Motivation: AI感知系统在自动驾驶中的性能、安全和可靠性高度依赖于数据标注质量，但在复杂的汽车产业供应链中，标注错误易于产生和传播，相关经验总结匮乏，因此有必要深入分析和分类标注错误，以辅助系统化改进。

Method: 作者在欧洲及英国的6家公司和4家研究机构开展了多组织案例研究，通过对20位专家的19次半结构化访谈（总时长50小时）及六阶段主题分析，梳理并归纳了数据标注错误的类型和特征，并以业界实践者反馈验证分类法有效性。

Result: 梳理出涵盖完整性、准确性和一致性三大维度的18种数据标注常见错误，并构建了一套类似失效模式分析（FMEA）的错误分类法，被业界实践者证实有益于根因分析、供应商质量复盘、新员工培训和优化标注规范。分类法被认为是诊断和提升数据标注质量的有力工具。

Conclusion: 本文通过多组织案例研究，提出了影响AI驱动自动驾驶感知系统标注数据质量的18种常见错误类型，并构建了标注错误分类法，有助于产业界诊断、改进数据标注流程，提高AI系统的可靠性和安全性。

Abstract: Data annotation is essential but highly error-prone in the development of AI-enabled perception systems (AIePS) for automated driving, and its quality directly influences model performance, safety, and reliability. However, the industry lacks empirical insights into how annotation errors emerge and spread across the multi-organisational automotive supply chain. This study addresses this gap through a multi-organisation case study involving six companies and four research institutes across Europe and the UK. Based on 19 semi-structured interviews with 20 experts (50 hours of transcripts) and a six-phase thematic analysis, we develop a taxonomy of 18 recurring annotation error types across three data-quality dimensions: completeness (e.g., attribute omission, missing feedback loops, edge-case omissions, selection bias), accuracy (e.g., mislabelling, bounding-box inaccuracies, granularity mismatches, bias-driven errors), and consistency (e.g., inter-annotator disagreement, ambiguous instructions, misaligned hand-offs, cross-modality inconsistencies). The taxonomy was validated with industry practitioners, who reported its usefulness for root-cause analysis, supplier quality reviews, onboarding, and improving annotation guidelines. They described it as a failure-mode catalogue similar to FMEA. By conceptualising annotation quality as a lifecycle and supply-chain issue, this study contributes to SE4AI by offering a shared vocabulary, diagnostic toolset, and actionable guidance for building trustworthy AI-enabled perception systems.

</details>


### [16] [Green Resilience of Cyber-Physical Systems: Doctoral Dissertation](https://arxiv.org/abs/2511.16593)
*Diaeddin Rimawi*

Main category: cs.SE

TL;DR: 本文提出面向OL-CAIS系统的弹性与绿色平衡建模与决策框架，通过多策略优化与度量体系，在协作机器人实验中验证能显著提升恢复效率、减碳并保持系统性能。


<details>
  <summary>Details</summary>
Motivation: OL-CAIS是结合人类协作与在线学习的网络物理系统，易受干扰事件影响降低性能。决策者需在恢复性能与减少能耗之间权衡，因此需要研究如何在弹性与绿色之间实现平衡。

Method: 构建OL-CAIS的弹性建模，通过自动状态检测区分三种操作状态；提出GResilience框架，分别使用多目标优化（一代理）、博弈论（二代理）和强化学习（RL代理）进行恢复策略决策；设计弹性与绿色的测量框架。实验基于协作机器人进行真实与模拟对象分类任务。

Result: 弹性模型能捕捉干扰期间的性能变化，GResilience策略可实现更绿色的恢复，缩短恢复时间、稳定性能、减少对人的依赖。RL代理表现最优，但CO2排放略增。多次干扰后出现灾难性遗忘，所提策略可缓解。容器化运行能将碳排放减少一半。

Conclusion: 本文为OL-CAIS绿色恢复提供了模型、度量与策略，兼顾弹性和绿色目标，促进系统高效、绿色地应对干扰。

Abstract: Cyber-physical systems (CPS) combine computational and physical components. Online Collaborative AI System (OL-CAIS) is a type of CPS that learn online in collaboration with humans to achieve a common goal, which makes it vulnerable to disruptive events that degrade performance. Decision-makers must therefore restore performance while limiting energy impact, creating a trade-off between resilience and greenness. This research addresses how to balance these two properties in OL-CAIS. It aims to model resilience for automatic state detection, develop agent-based policies that optimize the greenness-resilience trade-off, and understand catastrophic forgetting to maintain performance consistency. We model OL-CAIS behavior through three operational states: steady, disruptive, and final. To support recovery during disruptions, we introduce the GResilience framework, which provides recovery strategies through multi-objective optimization (one-agent), game-theoretic decision-making (two-agent), and reinforcement learning (RL-agent). We also design a measurement framework to quantify resilience and greenness. Empirical evaluation uses real and simulated experiments with a collaborative robot learning object classification from human demonstrations. Results show that the resilience model captures performance transitions during disruptions, and that GResilience policies improve green recovery by shortening recovery time, stabilizing performance, and reducing human dependency. RL-agent policies achieve the strongest results, although with a marginal increase in CO2 emissions. We also observe catastrophic forgetting after repeated disruptions, while our policies help maintain steadiness. A comparison with containerized execution shows that containerization cuts CO2 emissions by half. Overall, this research provides models, metrics, and policies that ensure the green recovery of OL-CAIS.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [17] [Synthesis of Safety Specifications for Probabilistic Systems](https://arxiv.org/abs/2511.16579)
*Gaspard Ohlmann,Edwin Hamel-De le Court,Francesco Belardinelli*

Main category: cs.LO

TL;DR: 本文提出了支持更强表述能力的PCTL安全规范合成新方法，定义了CPCTL片段，并给出了基于值迭代的合成算法，证明了其正确性和完备性。


<details>
  <summary>Details</summary>
Motivation: 在安全关键环境中，确保智能体满足安全规范至关重要。但现有的方法多将安全时序规范限制于概率规避约束，难以表达更一般的安全需求。因此，需有方法支持用更具表达力的规范，增强安全系统的设计能力。

Method: 本文提出了一个新理论框架用于安全PCTL规范（safe-PCTL specifications）的合成。具体包括：1）将全局规范满足问题转化为局部约束，并定义了CPCTL（一类安全PCTL片段）；2）提出了一种基于值迭代（Value Iteration）的方法来解决这些更一般化时序属性下的合成问题，并证明其正确性与完备性。

Result: 实验验证了CPCTL片段的表达能力，对于合成问题具有相关性。提出的算法能够有效地求解广义时序属性下的策略合成问题，且方法具有正确性与完备性。

Conclusion: 该研究突破了以往安全规范合成方法的表达能力限制，支持更一般的概率时序逻辑规范（PCTL），为安全关键系统的合成提供了更强的理论与算法工具。

Abstract: Ensuring that agents satisfy safety specifications can be crucial in safety-critical environments. While methods exist for controller synthesis with safe temporal specifications, most existing methods restrict safe temporal specifications to probabilistic-avoidance constraints. Formal methods typically offer more expressive ways to express safety in probabilistic systems, such as Probabilistic Computation Tree Logic (PCTL) formulas. Thus, in this paper, we develop a new approach that supports more general temporal properties expressed in PCTL. Our contribution is twofold. First, we develop a theoretical framework for the Synthesis of safe-PCTL specifications. We show how the reducing global specification satisfaction to local constraints, and define CPCTL, a fragment of safe-PCTL. We demonstrate how the expressiveness of CPCTL makes it a relevant fragment for the Synthesis Problem. Second, we leverage these results and propose a new Value Iteration-based algorithm to solve the synthesis problem for these more general temporal properties, and we prove the soundness and completeness of our method.

</details>


### [18] [Faster Certified Symmetry Breaking Using Orders With Auxiliary Variables](https://arxiv.org/abs/2511.16637)
*Markus Anders,Bart Bogaerts,Benjamin Bogø,Arthur Gontier,Wietze Koops,Ciaran McCreesh,Magnus O. Myreen,Jakob Nordström,Andy Oertel,Adrian Rebola-Pardo,Yong Kiam Tan*

Main category: cs.LO

TL;DR: 本文提出了一种用辅助变量编码代替大整数，显著提升了对称性打破证明生成与检查效率，在实际SAT任务中取得了数量级的加速。


<details>
  <summary>Details</summary>
Motivation: 对称性打破在组合问题求解中非常重要，但其正确实现很难保证。现有“认证型”求解器通过输出解决方案及其数学证明，以验证正确性，但如何高效地在证明中体现对称性推理长期未有好方法。最近的通用方法依赖于大整数编码序，但大规模对称性下会极其低效。

Method: 采用辅助变量编码序的方法，用于证明过程中对称性推理，大幅减少对大整数操作的依赖，结合satsuma与VeriPB进行实验测试。

Result: 提出了一种用辅助变量编码序的方法，理论与实践上均显著提升了证明生成和检查效率。该方法在SAT对称性打破任务中通过satsuma求解器与VeriPB工具链实验验证，速度提升达数个数量级。

Conclusion: 新方法可高效生成和验证对称性打破相关证明，有助于推动认证型组合求解器的实际应用。

Abstract: Symmetry breaking is a crucial technique in modern combinatorial solving, but it is difficult to be sure it is implemented correctly. The most successful approach to deal with bugs is to make solvers certifying, so that they output not just a solution, but also a mathematical proof of correctness in a standard format, which can then be checked by a formally verified checker. This requires justifying symmetry reasoning within the proof, but developing efficient methods for this has remained a long-standing open challenge. A fully general approach was recently proposed by Bogaerts et al. (2023), but it relies on encoding lexicographic orders with big integers, which quickly becomes infeasible for large symmetries. In this work, we develop a method for instead encoding orders with auxiliary variables. We show that this leads to orders-of-magnitude speed-ups in both theory and practice by running experiments on proof logging and checking for SAT symmetry breaking using the state-of-the-art satsuma symmetry breaker and the VeriPB proof checking toolchain.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [19] [What Really Counts? Examining Step and Token Level Attribution in Multilingual CoT Reasoning](https://arxiv.org/abs/2511.15886)
*Jeremias Ferrao,Ezgi Basar,Khondoker Ittehadul Islam,Mahrokh Hassani*

Main category: cs.CL

TL;DR: 本研究分析了多语种大模型（LLM）在链式思维（CoT）推理任务中的归因模式，通过ContextCite和Inseq两种归因方法，探索模型推理的可信度与可解释性。


<details>
  <summary>Details</summary>
Motivation: 尽管CoT已被证实能提升大模型推理能力，但其推理链的可信度和可解释性在多语种场景下尚未被系统性评估，因而需要深入分析和归因。

Method: 采用ContextCite进行推理步骤归因，Inseq进行细粒度的token级归因，对Qwen2.5 1.5B-Instruct模型在MGSM基准下进行多语言实证分析，并引入否定与干扰句作对照实验。

Result: 1）归因分数过度集中于推理末步骤，错误率更高时尤甚；2）结构化CoT提示对资源丰富的拉丁字母语种提升显著；3）引入否定与干扰，模型准确率及归因一致性均下降，显示CoT在解释性和多语种适应上的局限。

Conclusion: 尽管CoT提示能提升部分语言的任务准确率，但在多语种背景下仍存在鲁棒性和解释性不足的问题。模型过于依赖最后一步推理，且容易受噪音干扰准确性和归因一致性。

Abstract: This study investigates the attribution patterns underlying Chain-of-Thought (CoT) reasoning in multilingual LLMs. While prior works demonstrate the role of CoT prompting in improving task performance, there are concerns regarding the faithfulness and interpretability of the generated reasoning chains. To assess these properties across languages, we applied two complementary attribution methods--ContextCite for step-level attribution and Inseq for token-level attribution--to the Qwen2.5 1.5B-Instruct model using the MGSM benchmark. Our experimental results highlight key findings such as: (1) attribution scores excessively emphasize the final reasoning step, particularly in incorrect generations; (2) structured CoT prompting significantly improves accuracy primarily for high-resource Latin-script languages; and (3) controlled perturbations via negation and distractor sentences reduce model accuracy and attribution coherence. These findings highlight the limitations of CoT prompting, particularly in terms of multilingual robustness and interpretive transparency.

</details>


### [20] [Mind the Motions: Benchmarking Theory-of-Mind in Everyday Body Language](https://arxiv.org/abs/2511.15887)
*Seungbeen Lee,Jinhong Jeong,Donghyun Kim,Yejin Son,Youngjae Yu*

Main category: cs.CL

TL;DR: 本文提出了一种新的框架Motion2Mind，用于评估机器在理解非言语线索（NVCs）上的心智理论（ToM）能力，并展示了当前AI在此方面的显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有心智理论（ToM）评测多关注于虚假信念推理，忽略了人类丰富的非言语交流和信念以外的多种心智状态。本文旨在填补这一评估空白，从而更全面地检验AI对复杂人类沟通的理解能力。

Method: 作者构建了Motion2Mind视频数据集，包含222种非言语线索和397种心智状态，所有线索和解释都经过专家和心理学验证，并与人体语言知识库匹配，用以测试与评估AI的非言语心智理论能力。

Result: 结果显示，现有AI系统在识别非言语线索和对应心智状态方面远不及人类 annotators，特别在解释方面过度解读，说明AI的心智理论能力有待提升。

Conclusion: 当前AI系统在检测和解释人类非言语交流时，表现大大落后于人类，特别是在解释时有过度解读的倾向。

Abstract: Our ability to interpret others' mental states through nonverbal cues (NVCs) is fundamental to our survival and social cohesion. While existing Theory of Mind (ToM) benchmarks have primarily focused on false-belief tasks and reasoning with asymmetric information, they overlook other mental states beyond belief and the rich tapestry of human nonverbal communication. We present Motion2Mind, a framework for evaluating the ToM capabilities of machines in interpreting NVCs. Leveraging an expert-curated body-language reference as a proxy knowledge base, we build Motion2Mind, a carefully curated video dataset with fine-grained nonverbal cue annotations paired with manually verified psychological interpretations. It encompasses 222 types of nonverbal cues and 397 mind states. Our evaluation reveals that current AI systems struggle significantly with NVC interpretation, exhibiting not only a substantial performance gap in Detection, as well as patterns of over-interpretation in Explanation compared to human annotators.

</details>


### [21] [TOD-ProcBench: Benchmarking Complex Instruction-Following in Task-Oriented Dialogues](https://arxiv.org/abs/2511.15976)
*Sarik Ghazarian,Abhinav Gullapalli,Swair Shah,Anurag Beniwal,Nanyun Peng,Narayanan Sadagopan,Zhou Yu*

Main category: cs.CL

TL;DR: 提出了全面评测LLM在多轮复杂指令型对话中表现的新基准TOD-ProcBench，包括三大任务，深入分析了模型服从性，并探索了多语言与指令格式的影响。


<details>
  <summary>Details</summary>
Motivation: 目前现实世界中的任务型对话系统需要严格遵循复杂的自然语言指令，但以往TOD基准仅以简化结构表示指令，未能反映实际复杂度。因此，亟需更具挑战性和系统性的基准来评估LLM在复杂指令下多轮对话中的服从能力。

Method: 构建TOD-ProcBench基准，包括基于高质量ABCD数据集并经人工质控的多轮对话和复杂指令文档，将指令设计为多层次条件-动作语句，提出三项任务全面评测LLM在复杂指令下的表现，并研究多语言和不同文本格式对服从性的影响。

Result: TOD-ProcBench系统性检验了多种LLM在多轮任务型对话中对复杂指令的理解与执行能力，涉及检索相关指令、辨别违反指令的回复及生成合规回复任务，同时验证了多语言和文本格式对结果的影响。

Conclusion: TOD-ProcBench为评估大模型在复杂任务对话中指令服从能力提供了新的挑战基准，推动LLM实际应用中的能力提升。

Abstract: In real-world task-oriented dialogue (TOD) settings, agents are required to strictly adhere to complex instructions while conducting multi-turn conversations with customers. These instructions are typically presented in natural language format and include general guidelines and step-by-step procedures with complex constraints. Existing TOD benchmarks often oversimplify the complex nature of these instructions by reducing them to simple schemas composed of intents, slots, and API call configurations. To address this gap and systematically benchmark LLMs' instruction-following capabilities, we propose TOD-ProcBench, a challenging benchmark featuring complex process instructions with intricate, fine-grained constraints that evaluates various LLMs' abilities to understand and follow instructions in multi-turn TODs. Our benchmark dataset comprises instruction documents derived from the high-quality ABCD dataset with corresponding conversations under human quality control. We formulate fine-grained constraints and action procedures as multi-level condition-action instruction statements. We design three tasks to comprehensively benchmark LLMs' complex instruction-following capabilities in multi-turn TODs. Task 1 evaluates how LLMs retrieve the most relevant statement from a complex instruction and predict the corresponding next action. In Task 2, we synthesize instruction-violating responses by injecting inconsistencies and manipulating the original instructions, and then we analyze how effectively LLMs can identify instruction-violating responses. Task 3 investigates LLMs' abilities in conditional generation of instruction-following responses based on the original complex instructions. Additionally, we conduct studies on the impact of multilingual settings and different instruction text formats on compliance performance. We release our benchmark under the Llama 3.3 Community License Agreement.

</details>


### [22] [Liars' Bench: Evaluating Lie Detectors for Language Models](https://arxiv.org/abs/2511.16035)
*Kieron Kretschmar,Walter Laurito,Sharan Maiya,Samuel Marks*

Main category: cs.CL

TL;DR: 本文提出了一个包含近七万三千条谎言与诚实回答的测试基准LIARS' BENCH，系统评估了主流模型说谎检测技术，发现这些方法难以识别某些类型的谎言，尤其在仅凭对话内容难以判定时，显现明显局限。该基准为推动说谎检测技术发展提供了新的实验工具和方向。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）说谎检测技术多在狭窄场景下验证，难以覆盖模型可能生成的多样谎言。

Method: 作者提出了LIARS' BENCH测试平台，包括72,863条由四个开源权重模型、七个数据集生成的谎言与诚实回应，涵盖了模型说谎的不同原因和针对的信念对象，并评估了三种主流说谎检测技术。

Result: 实验发现，现有的说谎检测方法对于部分类型的谎言，尤其是无法单凭输出转录判断时，检测效果显著失效。

Conclusion: LIARS' BENCH揭示了当前说谎检测工具的局限性，并为说谎检测研究提供了一个实用测试平台。

Abstract: Prior work has introduced techniques for detecting when large language models (LLMs) lie, that is, generating statements they believe are false. However, these techniques are typically validated in narrow settings that do not capture the diverse lies LLMs can generate. We introduce LIARS' BENCH, a testbed consisting of 72,863 examples of lies and honest responses generated by four open-weight models across seven datasets. Our settings capture qualitatively different types of lies and vary along two dimensions: the model's reason for lying and the object of belief targeted by the lie. Evaluating three black- and white-box lie detection techniques on LIARS' BENCH, we find that existing techniques systematically fail to identify certain types of lies, especially in settings where it's not possible to determine whether the model lied from the transcript alone. Overall, LIARS' BENCH reveals limitations in prior techniques and provides a practical testbed for guiding progress in lie detection.

</details>


### [23] [Learning Tractable Distributions Of Language Model Continuations](https://arxiv.org/abs/2511.16054)
*Gwen Yidou-Weng,Ian Li,Anji Liu,Oliver Broadrick,Guy Van den Broeck,Benjie Wang*

Main category: cs.CL

TL;DR: LTLA结合深度语言模型和HMM，提升了受控生成任务的约束、上下文感知及多模态兼容性，且推理高效。


<details>
  <summary>Details</summary>
Motivation: 现有可处理代理方法（如HMM）虽然可用于受控文本生成，但上下文感知能力不足，导致生成文本质量不高。直接对自回归语言模型施加全局约束推理难度大，因此需要既高效又能增强上下文利用的混合生成方法。

Method: LTLA方法结合了基础语言模型为前缀进行丰富编码，以及一个固定的可处理代理模型（如HMM）用于计算精确的延续概率，通过一次批量HMM更新处理所有下一个token候选，同时只用基础语言模型的隐藏状态来调整代理模型的先验，而保持代理解码器不变，使计算在不同前缀间可复用。

Result: LTLA在受控生成任务中，相比于无条件HMM提升了条件似然和约束满足度，并能近似多模态任务中的延续分布，同时保持与以往模型相当的流畅性和较低的推理开销。

Conclusion: 提出的方法LTLA能够有效提升受控文本生成的约束满足度和条件似然，同时推理开销较低，且适用于无法单独编码视觉上下文的多模态任务。

Abstract: Controlled language generation conditions text on sequence-level constraints (for example, syntax, style, or safety). These constraints may depend on future tokens, which makes directly conditioning an autoregressive language model (LM) generally intractable. Prior work uses tractable surrogates such as hidden Markov models (HMMs) to approximate the distribution over continuations and adjust the model's next-token logits at decoding time. However, we find that these surrogates are often weakly context aware, which reduces query quality. We propose Learning to Look Ahead (LTLA), a hybrid approach that pairs the same base language model for rich prefix encoding with a fixed tractable surrogate model that computes exact continuation probabilities. Two efficiency pitfalls arise when adding neural context: (i) naively rescoring the prefix with every candidate next token requires a sweep over the entire vocabulary at each step, and (ii) predicting fresh surrogate parameters for each prefix, although tractable at a single step, forces recomputation of future probabilities for every new prefix and eliminates reuse. LTLA avoids both by using a single batched HMM update to account for all next-token candidates at once, and by conditioning only the surrogate's latent state prior on the LM's hidden representations while keeping the surrogate decoder fixed, so computations can be reused across prefixes. Empirically, LTLA attains higher conditional likelihood than an unconditional HMM, approximates continuation distributions for vision-language models where a standalone HMM cannot encode visual context, and improves constraint satisfaction at comparable fluency on controlled-generation tasks, with minimal inference overhead.

</details>


### [24] [Early science acceleration experiments with GPT-5](https://arxiv.org/abs/2511.16072)
*Sébastien Bubeck,Christian Coester,Ronen Eldan,Timothy Gowers,Yin Tat Lee,Alexandru Lupsasca,Mehtaab Sawhney,Robert Scherrer,Mark Sellke,Brian K. Spears,Derya Unutmaz,Kevin Weil,Steven Yin,Nikita Zhivotovskiy*

Main category: cs.CL

TL;DR: 本文通过多个科学领域的案例，展示了GPT-5在实际科研中的创新性应用和取得的具体成果，突出其加速和辅助研究的作用，同时提示AI尚不能完全替代专家。


<details>
  <summary>Details</summary>
Motivation: AI模型如GPT-5正在成为科学家们日益重要的工具，但许多人仍不了解前沿AI的能力。作者希望通过案例展示AI在前沿科学领域的潜力，推动更多科研人员关注与应用AI。

Method: 采用案例研究的方法，在数学、物理、天文学、计算机科学、生物学和材料科学等领域，记录并分析GPT-5参与实际科研项目的过程和成果，包括人与AI的互动细节。

Result: GPT-5在多个科学领域推动了新科研进展，其中包括数学领域四项新结果，并通过案例展示了AI提升科研效率，同时指出了AI的局限性和人类专家不可替代的作用。

Conclusion: 虽然AI如GPT-5在科学研究中展现出显著价值，能加速进展并解决部分难题，但人类专家的指导与验证仍然不可或缺。前沿AI的发展速度使其应用前景深远，值得科研界关注和投入。

Abstract: AI models like GPT-5 are an increasingly valuable tool for scientists, but many remain unaware of the capabilities of frontier AI. We present a collection of short case studies in which GPT-5 produced new, concrete steps in ongoing research across mathematics, physics, astronomy, computer science, biology, and materials science. In these examples, the authors highlight how AI accelerated their work, and where it fell short; where expert time was saved, and where human input was still key. We document the interactions of the human authors with GPT-5, as guiding examples of fruitful collaboration with AI. Of note, this paper includes four new results in mathematics (carefully verified by the human authors), underscoring how GPT-5 can help human mathematicians settle previously unsolved problems. These contributions are modest in scope but profound in implication, given the rate at which frontier AI is progressing.

</details>


### [25] [ELPO: Ensemble Learning Based Prompt Optimization for Large Language Models](https://arxiv.org/abs/2511.16122)
*Qing Zhang,Bing Xu,Xudong Zhang,Yifan Shi,Yang Li,Chen Zhang,Yik Chung Wu,Ngai Wong,Yijie Chen,Hong Dai,Xiansen Chen,Mian Zhang*

Main category: cs.CL

TL;DR: 本文提出了基于集成学习的提示优化框架ELPO，有效整合多种生成与搜索策略，突破了单一方法的局限，实验表明ELPO在多任务下均表现优越。


<details>
  <summary>Details</summary>
Motivation: 手工提示工程耗时且难以扩展，现有自动化方法受限于单一模型或算法，不能很好应对复杂任务，亟需更强大、更泛化的提示优化技术。

Method: 提出了基于集成学习的自动提示优化新框架ELPO，采用投票机制并结合不同搜索方法与共享生成策略，设计了更高效的提示生成和搜索算法。

Result: 在多个任务中，ELPO效果显著，提升了如ArSarcasm数据集上的F1分数（提升7.6）。

Conclusion: ELPO模型在不同任务中均优于现有自动化提示优化方法，实现了更高的准确性和鲁棒性。

Abstract: The remarkable performance of Large Language Models (LLMs) highly relies on crafted prompts. However, manual prompt engineering is a laborious process, creating a core bottleneck for practical application of LLMs. This phenomenon has led to the emergence of a new research area known as Automatic Prompt Optimization (APO), which develops rapidly in recent years. Existing APO methods such as those based on evolutionary algorithms or trial-and-error approaches realize an efficient and accurate prompt optimization to some extent. However, those researches focus on a single model or algorithm for the generation strategy and optimization process, which limits their performance when handling complex tasks. To address this, we propose a novel framework called Ensemble Learning based Prompt Optimization (ELPO) to achieve more accurate and robust results. Motivated by the idea of ensemble learning, ELPO conducts voting mechanism and introduces shared generation strategies along with different search methods for searching superior prompts. Moreover, ELPO creatively presents more efficient algorithms for the prompt generation and search process. Experimental results demonstrate that ELPO outperforms state-of-the-art prompt optimization methods across different tasks, e.g., improving F1 score by 7.6 on ArSarcasm dataset.

</details>


### [26] [TS-PEFT: Token-Selective Parameter-Efficient Fine-Tuning with Learnable Threshold Gating](https://arxiv.org/abs/2511.16147)
*Dabiao Ma,Ziming Dai,Zhimin Xin,Shu Wang,Ye Wang,Haojun Fei*

Main category: cs.CL

TL;DR: 提出TS-PEFT只对部分位置进行参数模块修改，比传统PEFT方法更高效，且实验表现更好。


<details>
  <summary>Details</summary>
Motivation: 目前PEFT方法对所有参数位置都进行修改，作者怀疑这种做法是否必要，尝试寻找更高效的参数微调方式。

Method: 提出Token-Selective PEFT（TS-PEFT），通过函数S仅对部分位置指数进行PEFT修改，并在下游任务上进行实验评估。

Result: 实验结果表明，在所有位置上无差别应用PEFT不仅可能多余，甚至有时效果更差，选择性应用可提升性能。

Conclusion: 对所有位置指数无差别地应用PEFT并非总是最优，Token-Selective PEFT（TS-PEFT）方法更加高效和合理。

Abstract: In the field of large models (LMs) for natural language processing (NLP) and computer vision (CV), Parameter-Efficient Fine-Tuning (PEFT) has emerged as a resource-efficient method that modifies a limited number of parameters while keeping the pretrained weights fixed. This paper investigates the traditional PEFT approach, which applies modifications to all position indices, and questions its necessity. We introduce a new paradigm called Token-Selective PEFT (TS-PEFT), in which a function S selectively applies PEFT modifications to a subset of position indices, potentially enhancing performance on downstream tasks. Our experimental results reveal that the indiscriminate application of PEFT to all indices is not only superfluous, but may also be counterproductive. This study offers a fresh perspective on PEFT, advocating for a more targeted approach to modifications and providing a framework for future research to optimize the fine-tuning process for large models.

</details>


### [27] [SemanticCite: Citation Verification with AI-Powered Full-Text Analysis and Evidence-Based Reasoning](https://arxiv.org/abs/2511.16198)
*Sebastian Haan*

Main category: cs.CL

TL;DR: 本论文提出了可扩展的AI驱动引用验证框架SemanticCite，通过细粒度分类和透明证据解释，显著提升引用准确性，并以轻量化开源方案支持学术和AI内容质量管理。


<details>
  <summary>Details</summary>
Motivation: 科学交流依赖于准确的引用，但当前学术文献面临诸多挑战，如语义引用错误、AI生成的虚假引用，以及传统引用格式无法准确定位证据。需要一种高效系统来验证引用准确性，提升文献质量和研究诚信。

Method: 提出SemanticCite系统，结合多种检索方法与四分类体系（支持、部分支持、不支持、不确定），通过AI进行全文源分析，细致提供证据和推理片段，并以轻量化模型实现高效验证。

Result: 实验结果显示，经过微调的轻量级语言模型在性能上可与大型商业系统媲美但计算消耗更低，实现了高效可扩展的引用验证。此外，系统透明地给出证据与解释，用户更易理解和信任。

Conclusion: SemanticCite系统有效解决了语义引用错误、AI伪引用及引用定位不准等难题，为大规模引用验证、同行评审、AI内容质量控制等提供了开源基础，提升了学术研究诚信。

Abstract: Effective scientific communication depends on accurate citations that validate sources and guide readers to supporting evidence. Yet academic literature faces mounting challenges: semantic citation errors that misrepresent sources, AI-generated hallucinated references, and traditional citation formats that point to entire papers without indicating which sections substantiate specific claims. We introduce SemanticCite, an AI-powered system that verifies citation accuracy through full-text source analysis while providing rich contextual information via detailed reasoning and relevant text snippets. Our approach combines multiple retrieval methods with a four-class classification system (Supported, Partially Supported, Unsupported, Uncertain) that captures nuanced claim-source relationships and enables appropriate remedial actions for different error types. Our experiments show that fine-tuned lightweight language models achieve performance comparable to large commercial systems with significantly lower computational requirements, making large-scale citation verification practically feasible. The system provides transparent, evidence-based explanations that support user understanding and trust. We contribute a comprehensive dataset of over 1,000 citations with detailed alignments, functional classifications, semantic annotations, and bibliometric metadata across eight disciplines, alongside fine-tuned models and the complete verification framework as open-source software. SemanticCite addresses critical challenges in research integrity through scalable citation verification, streamlined peer review, and quality control for AI-generated content, providing an open-source foundation for maintaining citation accuracy at scale.

</details>


### [28] [SeSE: A Structural Information-Guided Uncertainty Quantification Framework for Hallucination Detection in LLMs](https://arxiv.org/abs/2511.16275)
*Xingtao Zhao,Hao Peng,Dingli Su,Xianghua Zeng,Chunyang Liu,Jinzhi Liao,Philip S. Yu*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的语义结构熵（SeSE）方法，通过构建并压缩语义图，更准确地量化大模型的不确定性，在幻觉检测任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLMs）在安全关键场景下的部署需要可靠的不确定性量化（UQ），以便模型在面对不确定时可以拒绝回答，从而避免捏造虚假信息。然而，当前主流UQ方法主要依赖语义概率分布或成对距离，忽略了潜在语义结构信息，这限制了其不确定性估计的精确性。

Method: 提出了语义结构熵（Semantic Structural Entropy, SeSE）框架，从结构信息角度量化LLM的语义不确定性。具体方法包括：1）提出自适应稀疏有向语义图构建算法，捕捉语义依赖并自动剪枝无用连接；2）通过分层抽象，利用最优语义编码树的结构熵定义SeSE，衡量经最优压缩后的内在不确定性；3）将SeSE扩展到长文本生成场景，通过建模句子间的随机语义交互，对单个事实主张进行细粒度UQ。

Result: 在29组模型-数据集组合上的大量实验验证中，SeSE在不确定性量化任务上明显优于包括强监督方法和最新KLE方法在内的主流UQ基线。

Conclusion: SeSE通过挖掘语义结构信息，能更准确地量化LLM的不确定性，并用于检测幻觉现象，提升了模型的安全可靠性。

Abstract: Reliable uncertainty quantification (UQ) is essential for deploying large language models (LLMs) in safety-critical scenarios, as it enables them to abstain from responding when uncertain, thereby avoiding hallucinating falsehoods. However, state-of-the-art UQ methods primarily rely on semantic probability distributions or pairwise distances, overlooking latent semantic structural information that could enable more precise uncertainty estimates. This paper presents Semantic Structural Entropy (SeSE), a principled UQ framework that quantifies the inherent semantic uncertainty of LLMs from a structural information perspective for hallucination detection. Specifically, to effectively model semantic spaces, we first develop an adaptively sparsified directed semantic graph construction algorithm that captures directional semantic dependencies while automatically pruning unnecessary connections that introduce negative interference. We then exploit latent semantic structural information through hierarchical abstraction: SeSE is defined as the structural entropy of the optimal semantic encoding tree, formalizing intrinsic uncertainty within semantic spaces after optimal compression. A higher SeSE value corresponds to greater uncertainty, indicating that LLMs are highly likely to generate hallucinations. In addition, to enhance fine-grained UQ in long-form generation -- where existing methods often rely on heuristic sample-and-count techniques -- we extend SeSE to quantify the uncertainty of individual claims by modeling their random semantic interactions, providing theoretically explicable hallucination detection. Extensive experiments across 29 model-dataset combinations show that SeSE significantly outperforms advanced UQ baselines, including strong supervised methods and the recently proposed KLE.

</details>


### [29] [SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning](https://arxiv.org/abs/2511.16324)
*Wei Xia,Zhi-Hong Deng*

Main category: cs.CL

TL;DR: 本文提出SDA框架，可在无需重训练的情况下高效提升LLM输出与人类意图的对齐度，实证显示其对开源模型在多维度性能上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）在实际应用中的普及，用更高效、经济的方式使模型更贴近人类意图，特别是在推理阶段无需昂贵重训练或大量监督，实现模型输出对齐，成为亟需解决的问题。

Method: 提出了一种无需训练、模型无关的对齐框架——SDA（Steering-Driven Distribution Alignment）。该方法根据用户定义的对齐指令动态调整模型输出概率，实现模型行为与人类意图的对齐。SDA可独立运行于推理阶段，亦可与传统训练对齐结合，且支持个性化偏好控制。

Result: 在8个不同规模及来源的开源LLM上进行测试，在有用性、无害性、和诚实性三个维度上，SDA平均提升分别为64.4%、30%和11.5%。

Conclusion: SDA方法有效提高了开源LLM在多模型、多应用场景下的对齐能力，无需微调且资源消耗低，具有广泛适用性和一定的推广价值。

Abstract: With the rapid advancement of large language models (LLMs), their deployment in real-world applications has become increasingly widespread. LLMs are expected to deliver robust performance across diverse tasks, user preferences, and practical scenarios. However, as demands grow, ensuring that LLMs produce responses aligned with human intent remains a foundational challenge. In particular, aligning model behavior effectively and efficiently during inference, without costly retraining or extensive supervision, is both a critical requirement and a non-trivial technical endeavor. To address the challenge, we propose SDA (Steering-Driven Distribution Alignment), a training-free and model-agnostic alignment framework designed for open-source LLMs. SDA dynamically redistributes model output probabilities based on user-defined alignment instructions, enhancing alignment between model behavior and human intents without fine-tuning. The method is lightweight, resource-efficient, and compatible with a wide range of open-source LLMs. It can function independently during inference or be integrated with training-based alignment strategies. Moreover, SDA supports personalized preference alignment, enabling flexible control over the model response behavior. Empirical results demonstrate that SDA consistently improves alignment performance across 8 open-source LLMs with varying scales and diverse origins, evaluated on three key alignment dimensions, helpfulness, harmlessness, and honesty (3H). Specifically, SDA achieves average gains of 64.4% in helpfulness, 30% in honesty and 11.5% in harmlessness across the tested models, indicating its effectiveness and generalization across diverse models and application scenarios.

</details>


### [30] [Incorporating Self-Rewriting into Large Language Model Reasoning Reinforcement](https://arxiv.org/abs/2511.16331)
*Jiashu Yao,Heyan Huang,Shuang Zeng,Chuwei Luo,WangJie You,Jie Tang,Qingsong Liu,Yuhang Guo,Yangyang Kang*

Main category: cs.CL

TL;DR: 本文提出了针对大型推理模型的自我重写机制，通过仅对稳定正确的推理进行重写并学习，提高了模型的推理准确性、推理效率和内部推理质量，实验显示优于现有方法，且实现开销低。


<details>
  <summary>Details</summary>
Motivation: 现有的大型推理模型（LRM）主要通过最终正确性奖励进行强化学习，但这种单一的奖励方式无法细致监督模型的内部推理过程，导致推理质量问题（如过度推理、推理不够、冗余推理和混乱推理）。

Method: 提出了自我重写（self-rewriting）框架，让模型自动重写自己的推理文本，并从重写的推理中学习，以提升内部思考质量。设计上采用选择性重写策略，只对模型能够稳定正确回答的“简单”样本进行重写，以保留原始奖励信号；在实现上，重写和生成写入同一批次，保证算法扩展性，开销仅增加约10%。

Result: 在各种任务和不同规模模型上的大量实验显示，自我重写方法在准确性和推理长度权衡方面优于强基线，准确率提升0.6个百分点，推理长度缩短46%；在内部推理质量方面，LLM-as-a-judge评分提升7.2分，有效减少内部推理瑕疵。

Conclusion: 自我重写框架在提升大型推理模型的准确率、推理长度以及内部推理质量方面均取得了显著进展，且具有较好的可扩展性和低额外计算成本。

Abstract: Through reinforcement learning (RL) with outcome correctness rewards, large reasoning models (LRMs) with scaled inference computation have demonstrated substantial success on complex reasoning tasks. However, the one-sided reward, focused solely on final correctness, limits its ability to provide detailed supervision over internal reasoning process. This deficiency leads to suboptimal internal reasoning quality, manifesting as issues like over-thinking, under-thinking, redundant-thinking, and disordered-thinking. Inspired by the recent progress in LRM self-rewarding, we introduce self-rewriting framework, where a model rewrites its own reasoning texts, and subsequently learns from the rewritten reasoning to improve the internal thought process quality. For algorithm design, we propose a selective rewriting approach wherein only "simple" samples, defined by the model's consistent correctness, are rewritten, thereby preserving all original reward signals of GRPO. For practical implementation, we compile rewriting and vanilla generation within one single batch, maintaining the scalability of the RL algorithm and introducing only ~10% overhead. Extensive experiments on diverse tasks with different model sizes validate the effectiveness of self-rewriting. In terms of the accuracy-length tradeoff, the self-rewriting approach achieves improved accuracy (+0.6) with substantially shorter reasoning (-46%) even without explicit instructions in rewriting prompts to reduce reasoning length, outperforming existing strong baselines. In terms of internal reasoning quality, self-rewriting achieves significantly higher scores (+7.2) under the LLM-as-a-judge metric, successfully mitigating internal reasoning flaws.

</details>


### [31] [NLP Datasets for Idiom and Figurative Language Tasks](https://arxiv.org/abs/2511.16345)
*Blake Matheny,Phuong Minh Nguyen,Minh Le Nguyen,Stephanie Reynolds*

Main category: cs.CL

TL;DR: 本文介绍了三个新的成语与比喻语言数据集，旨在提升大语言模型在识别和理解成语、比喻等非字面语言方面的能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在NLP任务中表现优异，但面对成语与比喻等非字面表达时仍表现不佳。现有方法如微调有所改进，但数据不足仍是瓶颈，因此需要更大更优的数据集提升模型表现。

Method: 作者整合了近期现有的成语与比喻语言数据集，筛选出成语清单，并从大型语料库中提取相关上下文语句，生成一个大规模候选数据集和两个经过人工标注的高质量数据集。之后，对这些数据集进行后处理，使之适用于各类模型训练，并用它们在槽标注和序列标注任务上对大语言模型进行评测。

Result: 构建了一个大规模候选成语/比喻数据集和两个经过人工标注的高质量数据集，并证明它们有助于评估和提高预训练语言模型在成语识别上的能力。

Conclusion: 通过新数据集的训练与评测，验证了当前主流大语言模型在成语和比喻表达检测任务上的能力，并为未来模型改进和研究提供了基础资源。

Abstract: Idiomatic and figurative language form a large portion of colloquial speech and writing. With social media, this informal language has become more easily observable to people and trainers of large language models (LLMs) alike. While the advantage of large corpora seems like the solution to all machine learning and Natural Language Processing (NLP) problems, idioms and figurative language continue to elude LLMs. Finetuning approaches are proving to be optimal, but better and larger datasets can help narrow this gap even further. The datasets presented in this paper provide one answer, while offering a diverse set of categories on which to build new models and develop new approaches. A selection of recent idiom and figurative language datasets were used to acquire a combined idiom list, which was used to retrieve context sequences from a large corpus. One large-scale dataset of potential idiomatic and figurative language expressions and two additional human-annotated datasets of definite idiomatic and figurative language expressions were created to evaluate the baseline ability of pre-trained language models in handling figurative meaning through idiom recognition (detection) tasks. The resulting datasets were post-processed for model agnostic training compatibility, utilized in training, and evaluated on slot labeling and sequence tagging.

</details>


### [32] [Learning from Sufficient Rationales: Analysing the Relationship Between Explanation Faithfulness and Token-level Regularisation Strategies](https://arxiv.org/abs/2511.16353)
*Jonathan Kamp,Lisa Beinborn,Antske Fokkens*

Main category: cs.CL

TL;DR: 本研究发现传统评估rationales的信息度方法（如sufficiency）有局限，实际rationales对模型分类效果影响复杂，需要更系统的评价指标。


<details>
  <summary>Details</summary>
Motivation: 现有的sufficiency指标只能粗略估计rationales的信息度，难以反映rationales对模型表现的真实影响，需要结合新的视角分析其作用机制和评价方法。

Method: 引入两种建模范式：通过token分类能力评估模型识别rationale token的能力，以及通过将rationale包含在输入（利用attention正则化）评估是否能提升模型性能。实验分析了rationales的信息度和模型表现的关系。

Result: （1）高度信息性的rationales未必有助于正确分类；（2）sufficiency实际反映的是非rationale上下文对分类的影响，会干扰rationale作用；（3）rationales有助于跨领域分类，但效果依任务和模型不同；（4）sufficiency与token分类能力无关。

Conclusion: 高度信息性的rationales未必有助于模型正确分类实例，sufficiency更多体现了非rationale上下文对分类的影响，同时rationales的作用依任务和模型而异，当前用于衡量rationale的信息度的指标还需进一步研究。

Abstract: Human explanations of natural language, rationales, form a tool to assess whether models learn a label for the right reasons or rely on dataset-specific shortcuts. Sufficiency is a common metric for estimating the informativeness of rationales, but it provides limited insight into the effects of rationale information on model performance. We address this limitation by relating sufficiency to two modelling paradigms: the ability of models to identify which tokens are part of the rationale (through token classification) and the ability of improving model performance by incorporating rationales in the input (through attention regularisation). We find that highly informative rationales are not likely to help classify the instance correctly. Sufficiency conversely captures the classification impact of the non-rationalised context, which interferes with rationale information in the same input. We also find that incorporating rationale information in model inputs can boost cross-domain classification, but results are inconsistent per task and model type. Finally, sufficiency and token classification appear to be unrelated. These results exemplify the complexity of rationales, showing that metrics capable of systematically capturing this type of information merit further investigation.

</details>


### [33] [AICC: Parse HTML Finer, Make Models Better -- A 7.3T AI-Ready Corpus Built by a Model-Based HTML Parser](https://arxiv.org/abs/2511.16397)
*Ren Ma,Jiantao Qiu,Chao Xu,Pei Chu,Kaiwen Liu,Pengli Ren,Yuan Qu,Jiahui Peng,Linfeng Hou,Mengjie Liu,Lindong Lu,Wenchang Ning,Jia Yu,Rui Min,Jin Shi,Haojiong Chen,Peng Zhang,Wenjian Zhang,Qian Jiang,Zengjie Hu,Guoqiang Yang,Zhenxiang Li,Fukai Shang,Zhongying Tu,Wentao Zhang,Dahua Lin,Conghui He*

Main category: cs.CL

TL;DR: 本文提出基于语言模型的HTML到文本抽取方法MinerU-HTML，有效提升结构信息保留与下游模型性能，并公开了高质量基准与大规模语料库，为Web预训练语料构建树立新标准。


<details>
  <summary>Details</summary>
Motivation: 当前Web语料库主要依赖于基于启发式的HTML抽取方法（如Trafilatura），但这些方法常常损坏诸如公式、代码和表格等结构化元素，且HTML到文本的抽取过程通常被视为固定的预处理步骤，未充分重视其质量对大模型下游性能的影响。作者认为提升抽取质量对于模型能力的提升与过滤策略同等重要。

Method: 提出MinerU-HTML，一个将内容抽取转化为序列标注问题，并通过一个0.6B参数的语言模型解决的新型抽取流水线。流程包括：利用语言模型进行语义理解，两阶段格式化管道显式分类语义元素再转换为Markdown。此外，还公开了MainWebBench大规模网页标注数据集，以作为性能基准。

Result: 在MainWebBench基准上，MinerU-HTML获得81.8% ROUGE-N F1（Trafilatura仅为63.6%），且代码块和公式等结构化元素的保留率分别达90.9%和94.0%。用MinerU-HTML构建的AICC语料用于相同过滤实验后，预训练模型在13个基准测试中平均准确率达50.8%，较TfCC高出1.08个百分点，同时在部分关键基准上超越RefinedWeb和FineWeb。

Conclusion: HTML抽取质量对于Web大模型语料构建至关重要，矿工式抽取流水线及公开评测集和语料库将显著提升相关研究的性能表现和标准化水平。

Abstract: While web data quality is crucial for large language models, most curation efforts focus on filtering and deduplication,treating HTML-to-text extraction as a fixed pre-processing step. Existing web corpora rely on heuristic-based extractors like Trafilatura, which struggle to preserve document structure and frequently corrupt structured elements such as formulas, codes, and tables. We hypothesize that improving extraction quality can be as impactful as aggressive filtering strategies for downstream performance. We introduce MinerU-HTML, a novel extraction pipeline that reformulates content extraction as a sequence labeling problem solved by a 0.6B-parameter language model. Unlike text-density heuristics, MinerU-HTML leverages semantic understanding and employs a two-stage formatting pipeline that explicitly categorizes semantic elements before converting to Markdown. Crucially, its model-based approach is inherently scalable, whereas heuristic methods offer limited improvement pathways. On MainWebBench, our benchmark of 7,887 annotated web pages, MinerU-HTML achieves 81.8\% ROUGE-N F1 compared to Trafilatura's 63.6\%, with exceptional structured element preservation (90.9\% for code blocks, 94.0\% for formulas). Using MinerU-HTML, we construct AICC (AI-ready Common Crawl), a 7.3-trillion token multilingual corpus from two Common Crawl snapshots. In controlled pretraining experiments where AICC and Trafilatura-extracted TfCC undergo identical filtering, models trained on AICC (62B tokens) achieve 50.8\% average accuracy across 13 benchmarks, outperforming TfCC by 1.08pp-providing direct evidence that extraction quality significantly impacts model capabilities. AICC also surpasses RefinedWeb and FineWeb on key benchmarks. We publicly release MainWebBench, MinerU-HTML, and AICC, demonstrating that HTML extraction is a critical, often underestimated component of web corpus construction.

</details>


### [34] [Classification of worldwide news articles by perceived quality, 2018-2024](https://arxiv.org/abs/2511.16416)
*Connor McElroy,Thiago E. A. de Oliveira,Chris Brogly*

Main category: cs.CL

TL;DR: 该研究构建了百万级英文新闻数据集，用传统机器学习和深度学习方法自动区分高低质量新闻。深度学习模型（ModernBERT等）表现尤为突出，准确率和ROC AUC均远优于传统方法。证明了自动化、大规模新闻质量识别的可行性。


<details>
  <summary>Details</summary>
Motivation: 近年来，新闻信息的质量参差不齐，辨别不同质量的新闻对社会舆论和信息获取具有重要意义。本文旨在探索能否利用机器学习和深度学习模型，自动区分感知上的高质量与低质量新闻。

Method: 作者采用了一套新创建的大型英文新闻数据集（共1,412,272篇，来源于2018-2024年期间的Common Crawl），并依据579个新闻网站的专家共识评分进行标签划分（取中位数分割为高低质量类，各约70万篇），每篇文章包含194个语言特征。采用了三种传统机器学习分类器（如随机森林）和三种现代深度学习模型（如ModernBERT-large、DistilBERT-base）评估其区分能力。

Result: 三种传统机器学习模型（以随机森林为例，准确率0.7355，ROC AUC为0.8131）表现良好。深度学习表现卓越，其中ModernBERT-large（256 context length）准确率达0.8744、ROC AUC 0.9593、F1 0.8739；DistilBERT-base（512 context length）准确率0.8685、ROC AUC 0.9554。其他深度模型也表现优异。

Conclusion: 无论是传统的CPU型机器学习模型还是深度学习模型，都能有效区分全球新闻文章的感知质量，为自动化新闻质量评估提供了实证支持。

Abstract: This study explored whether supervised machine learning and deep learning models can effectively distinguish perceived lower-quality news articles from perceived higher-quality news articles. 3 machine learning classifiers and 3 deep learning models were assessed using a newly created dataset of 1,412,272 English news articles from the Common Crawl over 2018-2024. Expert consensus ratings on 579 source websites were split at the median, creating perceived low and high-quality classes of about 706,000 articles each, with 194 linguistic features per website-level labelled article. Traditional machine learning classifiers such as the Random Forest demonstrated capable performance (0.7355 accuracy, 0.8131 ROC AUC). For deep learning, ModernBERT-large (256 context length) achieved the best performance (0.8744 accuracy; 0.9593 ROC-AUC; 0.8739 F1), followed by DistilBERT-base (512 context length) at 0.8685 accuracy and 0.9554 ROC-AUC. DistilBERT-base (256 context length) reached 0.8478 accuracy and 0.9407 ROC-AUC, while ModernBERT-base (256 context length) attained 0.8569 accuracy and 0.9470 ROC-AUC. These results suggest that the perceived quality of worldwide news articles can be effectively differentiated by traditional CPU-based machine learning classifiers and deep learning classifiers.

</details>


### [35] [ESGBench: A Benchmark for Explainable ESG Question Answering in Corporate Sustainability Reports](https://arxiv.org/abs/2511.16438)
*Sherine George,Nithish Saji*

Main category: cs.CL

TL;DR: ESGBench为ESG领域AI系统提供了高质量评测基准，揭示主流大模型在领域内的可解释性挑战，推动相关研究。


<details>
  <summary>Details</summary>
Motivation: 现有ESG问答系统缺乏可解释性与精细评估，需要透明负责任的AI工具支持ESG领域发展。

Method: 构建了ESGBench基准数据集和评估框架，包括多主题ESG问题、人工生成答案和证据，并用此测试主流大模型。

Result: 分析显示，现有大模型在事实一致性、证据溯源及专业领域表现上仍有难点。

Conclusion: ESGBench能够有效推动ESG方向可解释AI系统的研发，促进系统透明性和责任追溯。

Abstract: We present ESGBench, a benchmark dataset and evaluation framework designed to assess explainable ESG question answering systems using corporate sustainability reports. The benchmark consists of domain-grounded questions across multiple ESG themes, paired with human-curated answers and supporting evidence to enable fine-grained evaluation of model reasoning. We analyze the performance of state-of-the-art LLMs on ESGBench, highlighting key challenges in factual consistency, traceability, and domain alignment. ESGBench aims to accelerate research in transparent and accountable ESG-focused AI systems.

</details>


### [36] [Anatomy of an Idiom: Tracing Non-Compositionality in Language Models](https://arxiv.org/abs/2511.16467)
*Andrew Gomes*

Main category: cs.CL

TL;DR: 本文提出新颖方法揭示了变换器模型处理习语的特殊注意力机制与电路结构，包括“习语头”和增强接受现象，为理解模型处理非组合性语言及更复杂语法结构提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 习语作为非组合性表达，传统 NLP 方法难以处理。本文旨在揭示变换器模型在处理习语时的内部计算机制，为理解模型如何处理复杂语言结构提供理论基础。

Method: 采用经过改进的路径修补算法（path patching）进行电路发现，并对模型中的注意力头与习语处理相关的特征进行分析，包括习语头和增强的注意力机制。

Result: 发现了一类名为“习语头”的注意力头，分析了习语 token 之间因早期处理而增强的注意力（增强接受），总结了这些现象对应的电路特性及对变换器模型理解的启示。

Conclusion: 变换器模型能够通过特定的注意力机制和电路结构有效处理习语（不具组合性的语言），展示出模型的鲁棒性与计算效率之间的平衡方式。

Abstract: We investigate the processing of idiomatic expressions in transformer-based language models using a novel set of techniques for circuit discovery and analysis. First discovering circuits via a modified path patching algorithm, we find that idiom processing exhibits distinct computational patterns. We identify and investigate ``Idiom Heads,'' attention heads that frequently activate across different idioms, as well as enhanced attention between idiom tokens due to earlier processing, which we term ``augmented reception.'' We analyze these phenomena and the general features of the discovered circuits as mechanisms by which transformers balance computational efficiency and robustness. Finally, these findings provide insights into how transformers handle non-compositional language and suggest pathways for understanding the processing of more complex grammatical constructions.

</details>


### [37] [Arctic-Extract Technical Report](https://arxiv.org/abs/2511.16470)
*Mateusz Chiliński,Julita Ołtusek,Wojciech Jaśkowski*

Main category: cs.CL

TL;DR: Arctic-Extract是一款轻量高效的文档结构数据抽取模型，适用于资源受限设备，能处理长文档，性能优异。


<details>
  <summary>Details</summary>
Motivation: 现有文档结构数据抽取模型往往对硬件资源要求较高，因此设计一种轻量且性能强大的模型，对于实际应用尤其是受限硬件环境下部署具有重要意义。

Method: 通过详细介绍Arctic-Extract的训练协议，并进行性能评估实验。

Result: Arctic-Extract模型大小仅6.6 GiB，可在A10 24GB显存的GPU上一次处理最多125页A4文档。实验结果证明其在文档理解领域有很强的性能。

Conclusion: Arctic-Extract模型在文档结构化数据抽取任务上表现优异，并适合资源受限的硬件环境。

Abstract: Arctic-Extract is a state-of-the-art model designed for extracting structural data (question answering, entities and tables) from scanned or digital-born business documents. Despite its SoTA capabilities, the model is deployable on resource-constrained hardware, weighting only 6.6 GiB, making it suitable for deployment on devices with limited resources, such as A10 GPUs with 24 GB of memory. Arctic-Extract can process up to 125 A4 pages on those GPUs, making suitable for long document processing. This paper highlights Arctic-Extract's training protocols and evaluation results, demonstrating its strong performance in document understanding.

</details>


### [38] [TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval](https://arxiv.org/abs/2511.16528)
*Özay Ezerceli,Mahmoud El Hussieni,Selva Taş,Reyhan Bayraktar,Fatma Betül Terzioğlu,Yusuf Çelebi,Yağız Asker*

Main category: cs.CL

TL;DR: 本研究首次系统比较了土耳其语信息检索中的密集编码器与晚交互模型，发现小规模晚交互模型能以更高参数效率超越大模型密集编码器，MUVERA算法可提升检索速度和精度，进而实现低延迟土耳其语信息检索。但该研究仍需更大规模及真实数据验证其成果。


<details>
  <summary>Details</summary>
Motivation: 土耳其语等形态丰富、资源较少的语言在神经信息检索方面研究不足，当前多用密集编码器，未系统评估晚交互类模型。希望通过新基准测试，探索更高效、更强性能的土耳其语IR模型，并提升实际应用潜力。

Method: 提出了TurkColBERT作为第一套系统性比较密集编码器（dense encoder）和晚交互模型（late-interaction model）的土耳其语信息检索基准。使用两阶段适配流程：首先在土耳其语NLI/STS任务上微调英语和多语种编码器，再通过PyLate工具转换为ColBERT风格检索器，并用MS MARCO-TR进行训练。对10种模型在5个涵盖不同领域的Turkish BEIR数据集上进行评估；并对不同索引算法（MUVERA+Rerank，PLAID）进行对比。

Result: 极小（1.0M参数）的colbert-hash-nano-tr模型保持71%以上的平均mAP，远小于600M参数的turkish-e5-large。3-5倍规模较小的晚交互模型在领域任务上显著超越密集编码器，ColmmBERT-base-TR表现突出，最高提升13.8% mAP。MUVERA+Rerank索引算法速度为PLAID的3.33倍，且精度提升1.7%。ColmmBERT-base-TR在MUVERA下查询时间低至0.54毫秒。

Conclusion: 晚交互模型在土耳其语检索任务上优于密集编码器，且参数效率更高，能够在极小的模型规模下保持较高性能。MUVERA算法能进一步提升速度和精度，但还需在更大规模和真实数据上验证。

Abstract: Neural information retrieval systems excel in high-resource languages but remain underexplored for morphologically rich, lower-resource languages such as Turkish. Dense bi-encoders currently dominate Turkish IR, yet late-interaction models -- which retain token-level representations for fine-grained matching -- have not been systematically evaluated. We introduce TurkColBERT, the first comprehensive benchmark comparing dense encoders and late-interaction models for Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders on Turkish NLI/STS tasks, then converts them into ColBERT-style retrievers using PyLate trained on MS MARCO-TR. We evaluate 10 models across five Turkish BEIR datasets covering scientific, financial, and argumentative domains. Results show strong parameter efficiency: the 1.0M-parameter colbert-hash-nano-tr is 600$\times$ smaller than the 600M turkish-e5-large dense encoder while preserving over 71\% of its average mAP. Late-interaction models that are 3--5$\times$ smaller than dense encoders significantly outperform them; ColmmBERT-base-TR yields up to +13.8\% mAP on domain-specific tasks. For production-readiness, we compare indexing algorithms: MUVERA+Rerank is 3.33$\times$ faster than PLAID and offers +1.7\% relative mAP gain. This enables low-latency retrieval, with ColmmBERT-base-TR achieving 0.54 ms query times under MUVERA. We release all checkpoints, configs, and evaluation scripts. Limitations include reliance on moderately sized datasets ($\leq$50K documents) and translated benchmarks, which may not fully reflect real-world Turkish retrieval conditions; larger-scale MUVERA evaluations remain necessary.

</details>


### [39] [Beyond Tokens in Language Models: Interpreting Activations through Text Genre Chunks](https://arxiv.org/abs/2511.16540)
*Éloïse Benito-Rodriguez,Einar Urdshals,Jasmina Nasufi,Nicky Pochinkov*

Main category: cs.CL

TL;DR: 作者首次尝试利用LLM激活而非输出，配合普通机器学习模型预测文本流派，取得了极高的准确率，验证了激活数据的可解释潜力。


<details>
  <summary>Details</summary>
Motivation: 当前对于大型语言模型（LLMs）的理解不足，尤其是在可解释性和输出人类评估方面存在困难。因此，研究如何利用模型的内部激活来预测文本的相关属性是一个重要且实际的议题。本文的动机是探索能否依靠LLM的激活数据，开发一种无需人工评判，却能预测文本流派（genre）的框架。

Method: 作者利用Mistral-7B模型和两组数据集，通过提取每个文本对应的LLM激活，将这些激活作为特征输入scikit-learn机器学习分类器，探索激活与文本流派之间的关系，并通过F1-score指标进行评估。

Result: 实验结果表明，流派可以通过浅层学习模型对LLM激活进行分类，分别在两组数据集上取得了最高98%和71%的F1分数，且效果始终优于对照任务。

Conclusion: 本文证明了LLM内部激活承载丰富文本信息，通过浅层机器学习能够高效准确地推断文本流派，为未来可解释性与自动评估任务打下了基础。

Abstract: Understanding Large Language Models (LLMs) is key to ensure their safe and beneficial deployment. This task is complicated by the difficulty of interpretability of LLM structures, and the inability to have all their outputs human-evaluated. In this paper, we present the first step towards a predictive framework, where the genre of a text used to prompt an LLM, is predicted based on its activations. Using Mistral-7B and two datasets, we show that genre can be extracted with F1-scores of up to 98% and 71% using scikit-learn classifiers. Across both datasets, results consistently outperform the control task, providing a proof of concept that text genres can be inferred from LLMs with shallow learning models.

</details>


### [40] [WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue](https://arxiv.org/abs/2511.16544)
*Zachary Ellis,Jared Joselowitz,Yash Deo,Yajie He,Anna Kalygina,Aisling Higham,Mana Rahimzadeh,Yan Jia,Ibrahim Habli,Ernest Lim*

Main category: cs.CL

TL;DR: ASR在医疗领域已广泛应用，但词错误率等传统指标无法有效衡量实际临床风险，本文构建专家基准，并用优化的LLM达到专家级评判，推动ASR评估向真实临床安全性转变。


<details>
  <summary>Details</summary>
Motivation: 随着自动语音识别（ASR）在临床对话中的普及，现有的评估方法主要依赖词错误率（WER）。文章关注传统评估指标是否能真实反映转录错误的临床影响，提出需要更贴合实际医疗场景的评估方式。

Method: 本文建立了黄金标准基准：由专家医生对比真实语句与ASR生成语句，给出转录差异的临床影响标签（无影响、轻微影响、重大影响），并分析WER等常用指标与标签的相关性。同时，提出了LLM-as-a-Judge方法，利用GEPA优化LLM（Gemini-2.5-Pro），以复制临床专家评估过程。

Result: 分析表明：词错误率（WER）及其他常用评估指标与临床风险标签相关性很差。优化后的Gemini-2.5-Pro模型作为“裁判”，能够以90%的准确率、Cohen's κ=0.816的成绩，实现与专家医生近似的评估效果。

Conclusion: 传统基于WER的ASR评估在临床场景中无法有效反映安全性，需要引入自动化、可扩展的新方法。本文提出的优化LLM评估框架，为临床语音识别提供了安全性评价的新标准。

Abstract: As Automatic Speech Recognition (ASR) is increasingly deployed in clinical dialogue, standard evaluations still rely heavily on Word Error Rate (WER). This paper challenges that standard, investigating whether WER or other common metrics correlate with the clinical impact of transcription errors. We establish a gold-standard benchmark by having expert clinicians compare ground-truth utterances to their ASR-generated counterparts, labeling the clinical impact of any discrepancies found in two distinct doctor-patient dialogue datasets. Our analysis reveals that WER and a comprehensive suite of existing metrics correlate poorly with the clinician-assigned risk labels (No, Minimal, or Significant Impact). To bridge this evaluation gap, we introduce an LLM-as-a-Judge, programmatically optimized using GEPA to replicate expert clinical assessment. The optimized judge (Gemini-2.5-Pro) achieves human-comparable performance, obtaining 90% accuracy and a strong Cohen's $κ$ of 0.816. This work provides a validated, automated framework for moving ASR evaluation beyond simple textual fidelity to a necessary, scalable assessment of safety in clinical dialogue.

</details>


### [41] [Integrating Symbolic Natural Language Understanding and Language Models for Word Sense Disambiguation](https://arxiv.org/abs/2511.16577)
*Kexin Zhao,Ken Forbus*

Main category: cs.CL

TL;DR: 作者用大模型（无需人工标注）辅助符号NLP系统做词义消歧，自动选出更复杂语义表示的正确解释，其性能接近人工标注结果。


<details>
  <summary>Details</summary>
Motivation: 传统词义消歧方法依赖粗粒度语义表示（如WordNet、FrameNet）和人工标注数据，难以自动处理更复杂的本体（如OpenCyc）语义需求，实际应用受限。因此需新的无标注、高适应性的消歧方法。

Method: 利用统计语言模型（如大模型）作为词义消歧的“oracle”。具体做法是：将符号NLP系统产生的多个候选语义转换为可区分的自然语言表达，用LLM进行上下文判断，选择合适解释，并将结果反馈给符号系统。

Result: 与人工金标答案对比评测，证实方法有效，能准确地自动选择上下文适当的语义解释。

Conclusion: 提出的方法无需手工标注训练数据，即可实现更丰富语义表示的词义消歧，且效果接近人工标注答案。

Abstract: Word sense disambiguation is a fundamental challenge in natural language understanding. Current methods are primarily aimed at coarse-grained representations (e.g. WordNet synsets or FrameNet frames) and require hand-annotated training data to construct. This makes it difficult to automatically disambiguate richer representations (e.g. built on OpenCyc) that are needed for sophisticated inference. We propose a method that uses statistical language models as oracles for disambiguation that does not require any hand-annotation of training data. Instead, the multiple candidate meanings generated by a symbolic NLU system are converted into distinguishable natural language alternatives, which are used to query an LLM to select appropriate interpretations given the linguistic context. The selected meanings are propagated back to the symbolic NLU system. We evaluate our method against human-annotated gold answers to demonstrate its effectiveness.

</details>


### [42] [Comparison of Text-Based and Image-Based Retrieval in Multimodal Retrieval Augmented Generation Large Language Model Systems](https://arxiv.org/abs/2511.16654)
*Elias Lumer,Alex Cardenas,Matt Melich,Myles Mason,Sara Dieter,Vamse Kumar Subbiah,Pradeep Honaganahalli Basavaraju,Roberto Hernandez*

Main category: cs.CL

TL;DR: 分析多模态RAG检索方案，将图片直接以多模态嵌入存储，显著优于基于摘要文本的做法，在金融文档问答上提升相关性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态RAG系统在图片预处理时丢失关键信息，影响下游检索和问答，亟需探索更有效的多模态检索方式以提升性能。

Method: 分别评估文本摘要嵌入检索和直接多模态嵌入检索在金融文档问答任务中的效果，对比多种LLM和多模态嵌入模型，基于新构建的金融收益电话会议基准，包括40组问答对，每组含1图像和1文本块。

Result: 直接多模态嵌入检索在mAP@5高13%、nDCG@5高11%，分别为相对提升32%、20%；同时在准确性和事实一致性上更优，充分证明了保留视觉细节的重要性。

Conclusion: 直接将图像以多模态嵌入方式存储和检索，比先进行LLM文本化摘要的做法更能保留关键信息，因此性能更优，尤其在事实准确性和相关性上表现更突出。

Abstract: Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models (LLMs) to access multimodal knowledge bases containing both text and visual information such as charts, diagrams, and tables in financial documents. However, existing multimodal RAG systems rely on LLM-based summarization to convert images into text during preprocessing, storing only text representations in vector databases, which causes loss of contextual information and visual details critical for downstream retrieval and question answering. To address this limitation, we present a comprehensive comparative analysis of two retrieval approaches for multimodal RAG systems, including text-based chunk retrieval (where images are summarized into text before embedding) and direct multimodal embedding retrieval (where images are stored natively in the vector space). We evaluate all three approaches across 6 LLM models and a two multi-modal embedding models on a newly created financial earnings call benchmark comprising 40 question-answer pairs, each paired with 2 documents (1 image and 1 text chunk). Experimental results demonstrate that direct multimodal embedding retrieval significantly outperforms LLM-summary-based approaches, achieving absolute improvements of 13% in mean average precision (mAP@5) and 11% in normalized discounted cumulative gain. These gains correspond to relative improvements of 32% in mAP@5 and 20% in nDCG@5, providing stronger evidence of their practical impact. We additionally find that direct multimodal retrieval produces more accurate and factually consistent answers as measured by LLM-as-a-judge pairwise comparisons. We demonstrate that LLM summarization introduces information loss during preprocessing, whereas direct multimodal embeddings preserve visual context for retrieval and inference.

</details>


### [43] [Nemotron Elastic: Towards Efficient Many-in-One Reasoning LLMs](https://arxiv.org/abs/2511.16664)
*Ali Taghibakhshi,Sharath Turuvekere Sreenivas,Saurav Muralidharan,Ruisi Cai,Marcin Chochowski,Ameya Sunil Mahabaleshwarkar,Yoshi Suhara,Oluwatobi Olabiyi,Daniel Korzekwa,Mostofa Patwary,Mohammad Shoeybi,Jan Kautz,Bryan Catanzaro,Ashwath Aithal,Nima Tajbakhsh,Pavlo Molchanov*

Main category: cs.CL

TL;DR: Nemotron Elastic通过权重共享、嵌套结构和多技术融合，大幅降低推理型LLM多规模训练成本，支持一体化部署，性能优异。


<details>
  <summary>Details</summary>
Motivation: 训练不同规模的大语言模型（LLM）以适应不同部署需求，成本极其高昂。传统剪枝和知识蒸馏虽然降低了部分成本，但仍需针对每个压缩模型进行大量训练，资源消耗巨大。

Method: 提出Nemotron Elastic框架，在单一主模型中嵌入多个权重共享的嵌套子模型，配备端到端训练的路由器，结合适用于推理任务的两阶段训练课程。同时引入群感知的SSM弹性化、异构MLP弹性化、归一化MSE层重要性深度选择算法，以及支持多预算同时优化的知识蒸馏。

Result: 在Nemotron Nano V2 12B模型上实现，同时生成9B和6B子模型，仅使用110B训练tokens，相比从零训练节省了360倍成本，相比现有压缩技术节省约7倍成本。所有子模型精度达到或超越现有压缩技术水平。

Conclusion: Nemotron Elastic实现了多嵌套、共享权重的推理型LLM，相比传统方法大幅降低训练与部署成本，且支持一体化模型部署，无需额外资源。

Abstract: Training a family of large language models targeting multiple scales and deployment objectives is prohibitively expensive, requiring separate training runs for each different size. Recent work on model compression through pruning and knowledge distillation has reduced this cost; however, this process still incurs hundreds of billions of tokens worth of training cost per compressed model. In this paper, we present Nemotron Elastic, a framework for building reasoning-oriented LLMs, including hybrid Mamba-Attention architectures, that embed multiple nested submodels within a single parent model, each optimized for different deployment configurations and budgets. Each of these submodels shares weights with the parent model and can be extracted zero-shot during deployment without additional training or fine-tuning. We enable this functionality through an end-to-end trained router, tightly coupled to a two-stage training curriculum designed specifically for reasoning models. We additionally introduce group-aware SSM elastification that preserves Mamba's structural constraints, heterogeneous MLP elastification, normalized MSE-based layer importance for improved depth selection, and knowledge distillation enabling simultaneous multi-budget optimization. We apply Nemotron Elastic to the Nemotron Nano V2 12B model, simultaneously producing a 9B and a 6B model using only 110B training tokens; this results in over 360x cost reduction compared to training model families from scratch, and around 7x compared to SoTA compression techniques. Each of the nested models performs on par or better than the SoTA in accuracy. Moreover, unlike other compression methods, the nested capability of our approach allows having a many-in-one reasoning model that has constant deployment memory against the number of models in the family.

</details>
