{"id": "2509.18583", "categories": ["cs.PL", "quant-ph"], "pdf": "https://arxiv.org/pdf/2509.18583", "abs": "https://arxiv.org/abs/2509.18583", "authors": ["Liyi Li", "Fenfen An", "Federico Zahariev", "Zhi Xiang Chong", "Amr Sabry", "Mark Gordon"], "title": "A Verified Compiler for Quantum Simulation", "comment": "Paper accepted to the Quantum Programming Languages (QPL) 2025\n  conference; available from: https://qpl2025.github.io/accepted/", "summary": "Hamiltonian simulation is a central application of quantum computing, with\nsignificant potential in modeling physical systems and solving complex\noptimization problems. Existing compilers for such simulations typically focus\non low-level representations based on Pauli operators, limiting programmability\nand offering no formal guarantees of correctness across the compilation\npipeline. We introduce QBlue, a high-level, formally verified framework for\ncompiling Hamiltonian simulations. QBlue is based on the formalism of second\nquantization, which provides a natural and expressive way to describe quantum\nparticle systems using creation and annihilation operators. To ensure safety\nand correctness, QBlue includes a type system that tracks particle types and\nenforces Hermitian structure. The framework supports compilation to both\ndigital and analog quantum circuits and captures multiple layers of semantics,\nfrom static constraints to dynamic evolution. All components of QBlue,\nincluding its language design, type system, and compilation correctness, are\nfully mechanized in the Rocq proof framework, making it the first end-to-end\nverified compiler for second-quantized Hamiltonian simulation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86QBlue\uff0c\u4e00\u4e2a\u57fa\u4e8e\u7b2c\u4e8c\u91cf\u5b50\u5316\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7f16\u8bd1\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5b50\u54c8\u5bc6\u987f\u6a21\u62df\u3002\u901a\u8fc7\u7c7b\u578b\u7cfb\u7edf\u548c\u7aef\u5230\u7aef\u673a\u68b0\u5316\u8bc1\u660e\uff0c\u4fdd\u969c\u4e86\u7f16\u8bd1\u5668\u7684\u5b89\u5168\u548c\u6b63\u786e\u6027\uff0c\u5b9e\u73b0\u4e86\u6570\u5b57\u548c\u6a21\u62df\u91cf\u5b50\u7535\u8def\u7684\u81ea\u52a8\u751f\u6210\uff0c\u662f\u9886\u57df\u5185\u9996\u4e2a\u5168\u9762\u9a8c\u8bc1\u7684\u5e73\u53f0\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u4e2d\u7684\u54c8\u5bc6\u987f\u6a21\u62df\u5bf9\u4e8e\u7269\u7406\u7cfb\u7edf\u5efa\u6a21\u548c\u89e3\u51b3\u590d\u6742\u4f18\u5316\u95ee\u9898\u6709\u91cd\u8981\u5e94\u7528\u3002\u73b0\u6709\u7f16\u8bd1\u5668\u591a\u57fa\u4e8ePauli\u7b97\u7b26\u5b9e\u73b0\uff0c\u5bfc\u81f4\u53ef\u7f16\u7a0b\u6027\u53d7\u9650\uff0c\u540c\u65f6\u5728\u6574\u4e2a\u7f16\u8bd1\u6d41\u7a0b\u4e2d\u7f3a\u4e4f\u5f62\u5f0f\u5316\u6b63\u786e\u6027\u4fdd\u8bc1\u3002", "method": "\u63d0\u51fa\u4e86QBlue\u2014\u2014\u4e00\u4e2a\u57fa\u4e8e\u7b2c\u4e8c\u91cf\u5b50\u5316\u5f62\u5f0f\u4e3b\u4e49\u7684\u9ad8\u7ea7\u3001\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u7f16\u8bd1\u6846\u67b6\u3002QBlue\u5229\u7528\u7c92\u5b50\u7684\u4ea7\u751f\u548c\u6e6e\u706d\u7b97\u7b26\u63cf\u8ff0\u91cf\u5b50\u7cfb\u7edf\uff0c\u5f15\u5165\u4e86\u7c7b\u578b\u7cfb\u7edf\u4ee5\u8ffd\u8e2a\u7c92\u5b50\u7c7b\u578b\u5e76\u5f3a\u5236Hermite\u7ed3\u6784\uff0c\u652f\u6301\u7f16\u8bd1\u6210\u6570\u5b57\u548c\u6a21\u62df\u91cf\u5b50\u7535\u8def\uff0c\u5e76\u901a\u8fc7Rocq\u8bc1\u660e\u6846\u67b6\u5bf9\u6240\u6709\u7ec4\u4ef6\u5b9e\u73b0\u673a\u68b0\u5316\u9a8c\u8bc1\u3002", "result": "QBlue\u5b9e\u73b0\u4e86\u54c8\u5bc6\u987f\u6a21\u62df\u7684\u9ad8\u5c42\u6b21\u8868\u8fbe\uff0c\u4fdd\u8bc1\u4e86\u7f16\u8bd1\u6d41\u7a0b\u7684\u5b89\u5168\u6027\u548c\u6b63\u786e\u6027\uff0c\u80fd\u751f\u6210\u591a\u79cd\u5e73\u53f0\u7684\u91cf\u5b50\u7535\u8def\u3002\u5b83\u662f\u9996\u4e2a\u5b9e\u73b0\u7b2c\u4e8c\u91cf\u5b50\u5316\u54c8\u5bc6\u987f\u6a21\u62df\u7aef\u5230\u7aef\u9a8c\u8bc1\u7684\u7f16\u8bd1\u5668\u3002", "conclusion": "QBlue\u663e\u8457\u63d0\u5347\u4e86\u54c8\u5bc6\u987f\u6a21\u62df\u7f16\u8bd1\u5668\u7684\u53ef\u7f16\u7a0b\u6027\u4e0e\u6b63\u786e\u6027\u4fdd\u969c\uff0c\u63a8\u52a8\u4e86\u91cf\u5b50\u8ba1\u7b97\u5e94\u7528\u7684\u53ef\u9760\u53d1\u5c55\u3002"}}
{"id": "2509.18612", "categories": ["cs.DM"], "pdf": "https://arxiv.org/pdf/2509.18612", "abs": "https://arxiv.org/abs/2509.18612", "authors": ["Ismail Alkhouri", "Mian Wu", "Cunxi Yu", "Jia Liu", "Rongrong Wang", "Alvaro Velasquez"], "title": "A Scalable Lift-and-Project Differentiable Approach For the Maximum Cut Problem", "comment": null, "summary": "We propose a scalable framework for solving the Maximum Cut (MaxCut) problem\nin large graphs using projected gradient ascent on quadratic objectives.\nNotably, while our approach is differentiable and leverages GPUs for\ngradient-based optimization, it is not a machine learning method and does not\nrequire training data beyond the given problem formulation. Starting from a\ncontinuous relaxation of the classical quadratic binary formulation, we present\na parallelized strategy that explores multiple initialization vectors in batch,\noffering an efficient and memory-friendly alternative to traditional solvers.\nWe analyze the relaxed objective, showing it is convex and has fixed-points\ncorresponding to local optima -- particularly at boundary points --\nhighlighting a key challenge in non-convex optimization. To address this, we\nintroduce a lifted quadratic formulation that over-parameterizes the solution\nspace, allowing the algorithm to escape poor fixed-points. We also provide a\ntheoretical characterization of these lifted fixed-points. Finally, we propose\nDECO, a dimension-alternating algorithm that switches between the unlifted and\nlifted formulations, leveraging their complementary strengths along with\nimportance-based degree initialization and a population-based evolutionary\nhyper-parameter search. Experiments on diverse graph families show that our\nmethods attain comparable or superior performance relative to recent\ntraining-data-intensive, dataless, and GPU-accelerated sampling approaches.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u65e0\u9700\u8bad\u7ec3\u6570\u636e\u7684\u6700\u5927\u5272\u95ee\u9898\u9ad8\u6548GPU\u6c42\u89e3\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u5347\u7ef4\u3001\u4ea4\u66ff\u4f18\u5316\u7b56\u7565\u63d0\u5347\u6027\u80fd\uff0c\u5728\u591a\u79cd\u56fe\u6570\u636e\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u6700\u5927\u5272\u95ee\u9898\u662f\u56fe\u8bba\u4e2d\u7684\u7ecf\u5178\u4f18\u5316\u95ee\u9898\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u56fe\u6570\u636e\u65f6\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u53d7\u5230\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u5229\u7528\u6295\u5f71\u68af\u5ea6\u4e0a\u5347\u65b9\u6cd5\u5728GPU\u4e0a\u8fdb\u884c\u4e8c\u6b21\u76ee\u6807\u4f18\u5316\uff0c\u91c7\u7528\u8fde\u7eed\u653e\u677e\u548c\u5e76\u884c\u591a\u521d\u59cb\u5316\u7b56\u7565\u3002\u5f15\u5165\u4e86\u5347\u7ef4\u4e8c\u6b21\u5f62\u5f0f\u548cDECO\u7ef4\u5ea6\u4ea4\u66ff\u7b97\u6cd5\u4ee5\u8df3\u51fa\u5c40\u90e8\u6700\u4f18\uff0c\u5e76\u7ed3\u5408\u91cd\u8981\u6027\u5ea6\u6570\u521d\u59cb\u5316\u548c\u57fa\u4e8e\u79cd\u7fa4\u7684\u8fdb\u5316\u8d85\u53c2\u6570\u641c\u7d22\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u7c7b\u578b\u7684\u5927\u89c4\u6a21\u56fe\u4e0a\u5747\u83b7\u5f97\u4e0e\u6700\u65b0\u6570\u636e\u9a71\u52a8\u6216\u65e0\u6570\u636e\u3001GPU\u52a0\u901f\u91c7\u6837\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u975e\u673a\u5668\u5b66\u4e60\u3001\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u6700\u5927\u5272\u95ee\u9898\u6c42\u89e3\u6846\u67b6\uff0c\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u5927\u89c4\u6a21\u56fe\u4e0a\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2509.18357", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2509.18357", "abs": "https://arxiv.org/abs/2509.18357", "authors": ["Michael Johnson", "David Jaz Myers"], "title": "Proceedings Seventh International Conference on Applied Category Theory 2024", "comment": null, "summary": "Proceedings of the Seventh International Conference on Applied Category\nTheory, held at the University of Oxford on 17 - 21 June 2024. The\ncontributions to ACT 2024 ranged from pure to applied and included\ncontributions in a wide range of disciplines in science and engineering. ACT\n2024 included talks in classical mechanics, quantum physics, probability\ntheory, linguistics, decision theory, machine learning, epidemiology,\nthermodynamics, engineering, and logic.", "AI": {"tldr": "ACT 2024\u4f1a\u8bae\u6c47\u96c6\u4e86\u8303\u7574\u8bba\u5728\u591a\u4e2a\u5b66\u79d1\u7684\u6700\u65b0\u7814\u7a76\u8fdb\u5c55\u4e0e\u5e94\u7528\u3002", "motivation": "\u63a8\u52a8\u8303\u7574\u8bba\u8de8\u5b66\u79d1\u53d1\u5c55\uff0c\u62d3\u5c55\u5176\u5728\u5b9e\u9645\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u672c\u6b21\u4f1a\u8bae\u901a\u8fc7\u7406\u8bba\u7814\u7a76\u548c\u5e94\u7528\u6848\u4f8b\uff0c\u6db5\u76d6\u5404\u4e2a\u5b66\u79d1\u9886\u57df\u7684\u4e13\u9898\u62a5\u544a\u3002", "result": "\u6db5\u76d6\u4e86\u4ece\u7406\u8bba\u5230\u5b9e\u9645\u5e94\u7528\u7684\u4f17\u591a\u5b66\u79d1\uff0c\u5c55\u793a\u4e86\u8303\u7574\u8bba\u7684\u591a\u5143\u6f5c\u529b\u548c\u5b66\u672f\u5f71\u54cd\u529b\u3002", "conclusion": "ACT 2024\u5c55\u793a\u4e86\u8303\u7574\u8bba\u5728\u79d1\u5b66\u4e0e\u5de5\u7a0b\u4e2d\u5e7f\u6cdb\u7684\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.18232", "categories": ["cs.FL", "E.1; F.4; I.1"], "pdf": "https://arxiv.org/pdf/2509.18232", "abs": "https://arxiv.org/abs/2509.18232", "authors": ["Baudouin Le Charlier"], "title": "A Layered Implementation Framework for Regular Languages", "comment": null, "summary": "I present the most fundamental features of an implemented system designed to\nmanipulate representations of regular languages. The system is structured into\ntwo layers, allowing regular languages to be represented in an increasingly\ncompact, efficient, and integrated way. Both layers are first presented at a\nhigh level, adequate to design and prove the correctness of abstract\nalgorithms. Then, their low-level implementations are described meticulously.\n  At the high level, the first layer offers a notion of normalized regular\nexpressions ensuring that the set of all syntactic derivatives of an expression\nis finite. At the low level, normalized expressions are uniquely represented by\nidentifiers, i.e. by standard integers.\n  The second layer, called the background, introduces additional notions to\nrecord, integrate, and simplify things computed within the first layer. At the\nhigh level, normalized expressions denoting the same regular language can be\nunified by grouping them into equivalence classes. One shortest expression is\nchosen in each class as its representative, which can be used to form equations\nrelating expressions to their derivatives.\n  This paper also presents extensive experimental results to demonstrate the\nusefulness of the proposed framework and, in particular, the fact that it makes\nit possible to represent large sets of regular languages in a unified way where\ndistinct identifiers designate different languages, represented by both a small\nexpression and a minimal deteministic automaton.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u9ad8\u6548\u5206\u5c42\u7684\u6b63\u89c4\u8bed\u8a00\u8868\u793a\u7cfb\u7edf\uff0c\u901a\u8fc7\u8868\u8fbe\u5f0f\u89c4\u8303\u5316\u548c\u7b49\u4ef7\u5f52\u7c7b\uff0c\u5b9e\u73b0\u4e86\u7edf\u4e00\u4e14\u7d27\u51d1\u7684\u6b63\u89c4\u8bed\u8a00\u7ba1\u7406\uff0c\u5e76\u7528\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u6027\u548c\u9ad8\u6548\u6027\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u8bbe\u8ba1\u548c\u5b9e\u73b0\u4e00\u4e2a\u7528\u4e8e\u64cd\u4f5c\u6b63\u89c4\u8bed\u8a00\u8868\u793a\u7684\u7cfb\u7edf\uff0c\u4ee5\u63d0\u9ad8\u6b63\u89c4\u8bed\u8a00\u8868\u793a\u7684\u7d27\u51d1\u6027\u3001\u6548\u7387\u548c\u96c6\u6210\u5ea6\u3002\u8fc7\u53bb\u7684\u6b63\u89c4\u8bed\u8a00\u5de5\u5177\u5b58\u5728\u8868\u793a\u81c3\u80bf\u3001\u6548\u7387\u4f4e\u4e0b\u7b49\u95ee\u9898\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u5206\u5c42\u67b6\u6784\u4e0e\u89c4\u8303\u5316\u8868\u8fbe\u5f0f\u89e3\u51b3\u8fd9\u4e9b\u75db\u70b9\u3002", "method": "\u7cfb\u7edf\u91c7\u7528\u4e24\u5c42\u7ed3\u6784\uff1a\u7b2c\u4e00\u5c42\u7528\u89c4\u8303\u5316\u6b63\u89c4\u8868\u8fbe\u5f0f\u786e\u4fdd\u5176\u6240\u6709\u8bed\u6cd5\u5bfc\u6570\u6709\u9650\uff0c\u5e76\u901a\u8fc7\u552f\u4e00\u6807\u8bc6\uff08\u6574\u6570\uff09\u5b9e\u73b0\u9ad8\u6548\u7ba1\u7406\uff1b\u7b2c\u4e8c\u5c42\u80cc\u666f\u5c42\u5c06\u7b49\u4ef7\u7684\u89c4\u8303\u5316\u8868\u8fbe\u5f0f\u5212\u5206\u4e3a\u7b49\u4ef7\u7c7b\uff0c\u9009\u62e9\u4ee3\u8868\u8868\u8fbe\u5f0f\uff0c\u5e76\u53ef\u7528\u4e8e\u5206\u6790\u8868\u8fbe\u5f0f\u53ca\u5176\u5bfc\u6570\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u4e24\u4e2a\u5c42\u6b21\u5747\u4ece\u9ad8\u5c42\u62bd\u8c61\u8bbe\u8ba1\u5230\u4f4e\u5c42\u7ec6\u81f4\u5b9e\u73b0\u8fdb\u884c\u4e86\u8be6\u7ec6\u63cf\u8ff0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u3001\u7edf\u4e00\u5730\u8868\u793a\u5927\u91cf\u4e0d\u540c\u7684\u6b63\u89c4\u8bed\u8a00\uff0c\u4fdd\u8bc1\u4e0d\u540c\u6807\u8bc6\u7b26\u4ee3\u8868\u4e0d\u540c\u8bed\u8a00\uff0c\u6bcf\u79cd\u8bed\u8a00\u65e2\u6709\u5c0f\u578b\u5316\u7684\u8868\u8fbe\u5f0f\uff0c\u4e5f\u6709\u5176\u6700\u5c0f\u786e\u5b9a\u6027\u81ea\u52a8\u673a\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5728\u4fdd\u8bc1\u8868\u8fbe\u5f0f\u8868\u8fbe\u80fd\u529b\u548c\u8868\u793a\u7d27\u51d1\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6b63\u89c4\u8bed\u8a00\u64cd\u4f5c\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u540e\u7eed\u6b63\u89c4\u8bed\u8a00\u7406\u8bba\u4e0e\u5e94\u7528\u5f00\u53d1\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u5de5\u5177\u57fa\u7840\u3002"}}
{"id": "2509.18337", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.18337", "abs": "https://arxiv.org/abs/2509.18337", "authors": ["Bo Xiong", "Linghao Zhang", "Chong Wang", "Peng Liang"], "title": "CoRaCMG: Contextual Retrieval-Augmented Framework for Commit Message Generation", "comment": "15 pages, 4 images, 6 tables, Manuscript submitted to a Journal\n  (2025)", "summary": "Commit messages play a key role in documenting the intent behind code\nchanges. However, they are often low-quality, vague, or incomplete, limiting\ntheir usefulness. Commit Message Generation (CMG) aims to automatically\ngenerate descriptive commit messages from code diffs to reduce developers'\neffort and improve message quality. Although recent advances in LLMs have shown\npromise in automating CMG, their performance remains limited. This paper aims\nto enhance CMG performance by retrieving similar diff-message pairs to guide\nLLMs to generate commit messages that are more precise and informative. We\nproposed CoRaCMG, a Contextual Retrieval-augmented framework for Commit Message\nGeneration, structured in three phases: (1) Retrieve: retrieving the similar\ndiff-message pairs; (2) Augment: combining them with the query diff into a\nstructured prompt; and (3) Generate: generating commit messages corresponding\nto the query diff via LLMs. CoRaCMG enables LLMs to learn project-specific\nterminologies and writing styles from the retrieved diff-message pairs, thereby\nproducing high-quality commit messages. We evaluated our method on various\nLLMs, including closed-source GPT models and open-source DeepSeek models.\nExperimental results show that CoRaCMG significantly boosts LLM performance\nacross four metrics (BLEU, Rouge-L, METEOR, and CIDEr). Specifically,\nDeepSeek-R1 achieves relative improvements of 76% in BLEU and 71% in CIDEr when\naugmented with a single retrieved example pair. After incorporating the single\nexample pair, GPT-4o achieves the highest improvement rate, with BLEU\nincreasing by 89%. Moreover, performance gains plateau after more than three\nexamples are used, indicating diminishing returns. Further analysis shows that\nthe improvements are attributed to the model's ability to capture the\nterminologies and writing styles of human-written commit messages from the\nretrieved example pairs.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u540d\u4e3aCoRaCMG\u7684\u68c0\u7d22\u589e\u5f3a\u578b\u63d0\u4ea4\u6d88\u606f\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5386\u53f2\u793a\u4f8b\uff0c\u4f7fLLM\u80fd\u591f\u751f\u6210\u66f4\u52a0\u7cbe\u51c6\u3001\u9ad8\u8d28\u91cf\u7684\u63d0\u4ea4\u6d88\u606f\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u4e3b\u6d41LLM\u6027\u80fd\uff0c\u5c24\u5176\u5728\u5b66\u4e60\u9879\u76ee\u7279\u5b9a\u5199\u4f5c\u98ce\u683c\u548c\u672f\u8bed\u65b9\u9762\u6548\u679c\u7a81\u51fa\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u751f\u6210\u63d0\u4ea4\u6d88\u606f\uff08CMG\uff09\u6280\u672f\u867d\u6709\u8fdb\u5c55\uff0c\u4f46LLM\u751f\u6210\u7684\u63d0\u4ea4\u6d88\u606f\u6548\u679c\u6709\u9650\uff0c\u5e38\u5e38\u8d28\u91cf\u4e0d\u9ad8\u3001\u4fe1\u606f\u4e0d\u5168\u3002\u4e3a\u63d0\u5347\u751f\u6210\u6548\u679c\uff0c\u9700\u5229\u7528\u9879\u76ee\u5386\u53f2\u6570\u636e\uff0c\u63d0\u9ad8LLM\u751f\u6210\u6d88\u606f\u7684\u51c6\u786e\u6027\u548c\u4fe1\u606f\u91cf\u3002", "method": "\u63d0\u51faCoRaCMG\u6846\u67b6\uff0c\u5206\u4e09\u6b65\uff1a1\uff09\u68c0\u7d22\u76f8\u4f3c\u7684\u4ee3\u7801\u53d8\u66f4\u53ca\u5176\u5bf9\u5e94\u6d88\u606f\u5bf9\uff1b2\uff09\u5c06\u68c0\u7d22\u5230\u7684\u4fe1\u606f\u4e0e\u5f53\u524d\u67e5\u8be2\u53d8\u66f4\u7ec4\u5408\u6210\u7ed3\u6784\u5316\u8f93\u5165\uff1b3\uff09\u5f15\u5bfcLLM\u751f\u6210\u66f4\u4f18\u8d28\u3001\u4e2a\u6027\u5316\u63d0\u4ea4\u6d88\u606f\uff0c\u901a\u8fc7\u793a\u4f8b\u5b66\u4e60\u9879\u76ee\u672f\u8bed\u548c\u98ce\u683c\u3002", "result": "\u7528\u591a\u79cdLLM\uff08\u95ed\u6e90GPT\u3001\u5f00\u6e90DeepSeek\uff09\u5b9e\u9a8c\uff0cCoRaCMG\u5927\u5e45\u63d0\u5347\u56db\u9879\u6307\u6807\uff08BLEU\u3001Rouge-L\u3001METEOR\u3001CIDEr\uff09\uff0c\u5982DeepSeek-R1\u5728\u589e\u6dfb\u5355\u4e00\u68c0\u7d22\u793a\u4f8b\u65f6\uff0cBLEU\u63d0\u534776%\uff0cCIDEr\u63d0\u534771%\u3002GPT-4o\u5355\u4f8b\u589e\u957f\u7387\u6700\u9ad8\uff0cBLEU\u63d0\u534789%\u3002\u591a\u4e8e\u4e09\u4e2a\u793a\u4f8b\u63d0\u5347\u8d8b\u4e8e\u5e73\u7f13\uff0c\u63d0\u5347\u539f\u56e0\u5728\u4e8e\u6a21\u578b\u66f4\u597d\u5730\u6355\u6349\u4e86\u9879\u76ee\u672f\u8bed\u4e0e\u5199\u4f5c\u98ce\u683c\u3002", "conclusion": "\u68c0\u7d22\u589e\u5f3a\u7684\u63d0\u793a\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347LLM\u5728\u63d0\u4ea4\u6d88\u606f\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u80fd\u8fdb\u4e00\u6b65\u5b66\u4e60\u548c\u590d\u7528\u4eba\u7c7b\u7f16\u5199\u7684\u9879\u76ee\u4e13\u5c5e\u98ce\u683c\u4e0e\u672f\u8bed\uff0c\u89e3\u51b3\u4e86\u81ea\u52a8CMG\u6548\u679c\u4e0d\u4f73\u7684\u95ee\u9898\u3002"}}
{"id": "2509.18113", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18113", "abs": "https://arxiv.org/abs/2509.18113", "authors": ["Xin Hu", "Yue Kang", "Guanzi Yao", "Tianze Kang", "Mengjie Wang", "Heyao Liu"], "title": "Dynamic Prompt Fusion for Multi-Task and Cross-Domain Adaptation in LLMs", "comment": null, "summary": "This study addresses the generalization limitations commonly observed in\nlarge language models under multi-task and cross-domain settings. Unlike prior\nmethods such as SPoT, which depends on fixed prompt templates, our study\nintroduces a unified multi-task learning framework with dynamic prompt\nscheduling mechanism. By introducing a prompt pool and a task-aware scheduling\nstrategy, the method dynamically combines and aligns prompts for different\ntasks. This enhances the model's ability to capture semantic differences across\ntasks. During prompt fusion, the model uses task embeddings and a gating\nmechanism to finely control the prompt signals. This ensures alignment between\nprompt content and task-specific demands. At the same time, it builds flexible\nsharing pathways across tasks. In addition, the proposed optimization objective\ncenters on joint multi-task learning. It incorporates an automatic learning\nstrategy for scheduling weights, which effectively mitigates task interference\nand negative transfer. To evaluate the effectiveness of the method, a series of\nsensitivity experiments were conducted. These experiments examined the impact\nof prompt temperature parameters and task number variation. The results confirm\nthe advantages of the proposed mechanism in maintaining model stability and\nenhancing transferability. Experimental findings show that the prompt\nscheduling method significantly improves performance on a range of language\nunderstanding and knowledge reasoning tasks. These results fully demonstrate\nits applicability and effectiveness in unified multi-task modeling and\ncross-domain adaptation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u5927\u6a21\u578b\u5728\u591a\u4efb\u52a1\u4e0e\u8de8\u9886\u57df\u6cdb\u5316\u53d7\u9650\u7684\u65b0\u65b9\u6cd5\u3002\u901a\u8fc7\u52a8\u6001\u63d0\u793a\u8c03\u5ea6\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u6a21\u578b\u5728\u4e0d\u540c\u4efb\u52a1\u4e0e\u9886\u57df\u4e0b\u7684\u9002\u5e94\u6027\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u9488\u5bf9\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u6a21\u677f\u3001\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898\uff0c\u5e0c\u671b\u901a\u8fc7\u52a8\u6001\u548c\u4efb\u52a1\u76f8\u5173\u7684\u63d0\u793a\u7ec4\u5408\uff0c\u63d0\u5347\u6a21\u578b\u5728\u591a\u4efb\u52a1\u53ca\u8de8\u9886\u57df\u8bbe\u5b9a\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u91c7\u7528\u4e86\u4e00\u4e2a\u63d0\u793a\u6c60\uff08prompt pool\uff09\u548c\u4efb\u52a1\u611f\u77e5\u8c03\u5ea6\u7b56\u7565\uff0c\u6839\u636e\u4efb\u52a1\u52a8\u6001\u878d\u5408\u548c\u8c03\u6574\u63d0\u793a\uff0c\u5229\u7528\u4efb\u52a1\u5d4c\u5165\u4e0e\u95e8\u63a7\u673a\u5236\u7cbe\u7ec6\u63a7\u5236\u63d0\u793a\u4f20\u9012\uff0c\u5b9e\u73b0\u7075\u6d3b\u7684\u4efb\u52a1\u95f4\u5171\u4eab\u3002\u540c\u65f6\u5f15\u5165\u8054\u5408\u591a\u4efb\u52a1\u5b66\u4e60\u76ee\u6807\u548c\u63d0\u793a\u6743\u91cd\u81ea\u52a8\u5b66\u4e60\u7b56\u7565\uff0c\u4ee5\u4f18\u5316\u63d0\u793a\u8c03\u5ea6\u3002", "result": "\u901a\u8fc7\u591a\u9879\u654f\u611f\u6027\u5b9e\u9a8c\uff08\u5982\u63d0\u793a\u6e29\u5ea6\u53c2\u6570\u548c\u4efb\u52a1\u6570\u91cf\u53d8\u5316\uff09\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u5728\u7a33\u5b9a\u6027\u548c\u8fc1\u79fb\u80fd\u529b\u4e0a\u7684\u63d0\u5347\uff0c\u5728\u591a\u79cd\u8bed\u8a00\u7406\u89e3\u548c\u77e5\u8bc6\u63a8\u7406\u4efb\u52a1\u4e0a\u5747\u53d6\u5f97\u4e86\u66f4\u4f18\u7684\u6027\u80fd\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u52a8\u6001\u63d0\u793a\u8c03\u5ea6\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u8bed\u8a00\u7406\u89e3\u4e0e\u77e5\u8bc6\u63a8\u7406\u7b49\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u5728\u7edf\u4e00\u591a\u4efb\u52a1\u5efa\u6a21\u548c\u8de8\u9886\u57df\u9002\u5e94\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.18434", "categories": ["cs.LO", "cs.CC"], "pdf": "https://arxiv.org/pdf/2509.18434", "abs": "https://arxiv.org/abs/2509.18434", "authors": ["Dmitriy Zhuk"], "title": "Singleton algorithms for the Constraint Satisfaction Problem", "comment": null, "summary": "A natural strengthening of an algorithm for the (promise) constraint\nsatisfaction problem is its singleton version: we first fix a constraint to\nsome tuple from the constraint relation, then run the algorithm, and remove the\ntuple from the constraint if the answer is negative. We characterize the power\nof the singleton versions of standard universal algorithms for the (promise)\nCSP over a fixed template in terms of the existence of a minion homomorphism.\nUsing the Hales-Jewett theorem, we show that for finite relational structures\nthis minion condition is equivalent to the existence of polymorphisms with\ncertain symmetries, called palette block symmetric polymorphisms. By proving\nthe existence of such polymorphisms we establish that the singleton version of\nthe BLP+AIP algorithm solves all tractable CSPs over domains of size at most 7.\nFinally, by providing concrete CSP templates, we illustrate the limitations of\nlinear programming, the power of the singleton versions, and the elegance of\nthe palette block symmetric polymorphisms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCSP\u7b97\u6cd5\u7684singleton\u7248\u672c\uff0c\u5e76\u7528\u7ec4\u5408\u548c\u4ee3\u6570\u5de5\u5177\u523b\u753b\u5176\u6c42\u89e3\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u5728\u5c0f\u89c4\u6a21\u57df\u4e0a\u7684\u5168\u90e8\u53ef\u89e3CSP\u90fd\u80fd\u7531\u6b64\u7b97\u6cd5\u89e3\u51b3\uff0c\u63ed\u793a\u4e86\u5176\u4f18\u4e8e\u7ebf\u6027\u89c4\u5212\u7684\u672c\u8d28\u53ca\u591a\u6001\u6027\u5bf9\u79f0\u7ed3\u6784\u7684\u4f5c\u7528\uff0c\u4e30\u5bcc\u4e86CSP\u7406\u8bba\u4e0e\u7b97\u6cd5\u8bbe\u8ba1\u3002", "motivation": "\u7814\u7a76CSP\uff08\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\uff09\u65f6\uff0c\u63a8\u52a8\u7b97\u6cd5\u6548\u80fd\u7684\u81ea\u7136\u65b9\u5f0f\u662f\u5f15\u5165\u5b83\u7684singleton\u7248\u672c\uff0c\u5373\u5148\u56fa\u5b9a\u7ea6\u675f\u5173\u7cfb\u4e2d\u7684\u67d0\u4e2a\u5143\u7ec4\u518d\u8fd0\u884c\u7b97\u6cd5\uff0c\u4ece\u800c\u5206\u6790\u8d1f\u9762\u7b54\u6848\u65f6\u79fb\u9664\u8be5\u5143\u7ec4\u3002\u8fd9\u63a8\u52a8\u4e86\u5bf9singleton\u7248\u672c\u7b97\u6cd5\u80fd\u529b\u7684\u6df1\u5165\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u5c06CSP\uff08promise\u60c5\u5f62\u4e0b\uff09\u4e0a\u7684\u901a\u7528\u7b97\u6cd5\u7684singleton\u7248\u672c\u80fd\u529b\uff0c\u4e0eminion\u540c\u6001\u7684\u5b58\u5728\u6761\u4ef6\u8fdb\u884c\u7279\u5f81\u523b\u753b\u3002\u5229\u7528Hales-Jewett \u5b9a\u7406\uff0c\u5c06\u6709\u9650\u5173\u7cfb\u7ed3\u6784\u4e2d\u7684minion\u6761\u4ef6\u4e0e\u5177\u6709\u67d0\u79cd\u5bf9\u79f0\u6027\u7684\u591a\u6001\u6027\uff08palette block symmetric polymorphisms\uff09\u7684\u5b58\u5728\u6027\u5efa\u7acb\u7b49\u4ef7\u3002\u901a\u8fc7\u6784\u9020\u5177\u4f53\u7684CSP\u6a21\u677f\u5e76\u5206\u6790\u591a\u6001\u6027\u7684\u7ed3\u6784\u548c\u6027\u8d28\uff0c\u8bc1\u660e\u7b97\u6cd5\u6027\u80fd\u3002", "result": "\u8bc1\u660e\u4e86\u5bf9\u4e8e\u57df\u5927\u5c0f\u6700\u591a\u4e3a7\u7684\u6240\u6709\u53ef\u89e3CSP\uff0c\u5355\u4f8b\u7248\u672c\u7684BLP+AIP\u7b97\u6cd5\u90fd\u80fd\u6c42\u89e3\u3002\u8fdb\u4e00\u6b65\u901a\u8fc7\u5177\u4f53CSP\u6a21\u677f\uff0c\u63ed\u793a\u4e86\u7ebf\u6027\u89c4\u5212\u7684\u5c40\u9650\u3001singleton\u7b97\u6cd5\u7248\u672c\u7684\u4f18\u52bf\uff0c\u4ee5\u53capalette block symmetric polymorphisms\u7ed3\u6784\u7684\u7b80\u6d01\u6027\u548c\u95ee\u9898\u89e3\u7684\u7f8e\u5b66\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u523b\u753bsingleton\u7248\u672cCSP\u7b97\u6cd5\u7684\u5224\u5b9a\u80fd\u529b\uff0c\u4e0e\u591a\u6001\u6027\u548c\u5bf9\u79f0\u7ed3\u6784\u7ed3\u5408\uff0c\u4e3aCSP\u7684\u7b97\u6cd5\u5206\u6790\u4e0e\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u4e5f\u63ed\u793a\u4e86\u4f20\u7edf\u65b9\u6cd5\u5982\u7ebf\u6027\u89c4\u5212\u7684\u80fd\u529b\u8fb9\u754c\u3002"}}
{"id": "2509.18361", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.18361", "abs": "https://arxiv.org/abs/2509.18361", "authors": ["Daye Nam", "Malgorzata Salawa", "Satish Chandra"], "title": "Reading Between the Lines: Scalable User Feedback via Implicit Sentiment in Developer Prompts", "comment": null, "summary": "Evaluating developer satisfaction with conversational AI assistants at scale\nis critical but challenging. User studies provide rich insights, but are\nunscalable, while large-scale quantitative signals from logs or in-product\nratings are often too shallow or sparse to be reliable. To address this gap, we\npropose and evaluate a new approach: using sentiment analysis of developer\nprompts to identify implicit signals of user satisfaction. With an analysis of\nindustrial usage logs of 372 professional developers, we show that this\napproach can identify a signal in ~8% of all interactions, a rate more than 13\ntimes higher than explicit user feedback, with reasonable accuracy even with an\noff-the-shelf sentiment analysis approach. This new practical approach to\ncomplement existing feedback channels would open up new directions for building\na more comprehensive understanding of the developer experience at scale.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u7528\u5f00\u53d1\u8005\u63d0\u793a\u8bed\u7684\u60c5\u611f\u5206\u6790\u6765\u6355\u6349AI\u52a9\u624b\u7528\u6237\u6ee1\u610f\u5ea6\uff0c\u80fd\u53d1\u73b0\u6bd4\u663e\u5f0f\u53cd\u9988\u591a13\u500d\u7684\u4fe1\u53f7\uff0c\u5bf9\u5927\u89c4\u6a21\u5f00\u53d1\u8005\u4f53\u9a8c\u8bc4\u4f30\u6709\u5b9e\u7528\u4ef7\u503c\u3002", "motivation": "\u73b0\u6709\u7684\u5f00\u53d1\u8005\u6ee1\u610f\u5ea6\u8bc4\u4f30\u65b9\u6cd5\u8981\u4e48\u65e0\u6cd5\u89c4\u6a21\u5316\uff08\u5982\u7528\u6237\u8c03\u7814\uff09\uff0c\u8981\u4e48\u91cf\u5316\u4fe1\u53f7\u8fc7\u4e8e\u6d45\u663e\u6216\u7a00\u758f\uff08\u5982\u5e94\u7528\u65e5\u5fd7/\u5185\u7f6e\u8bc4\u5206\uff09\uff0c\u96be\u4ee5\u5168\u9762\u3001\u53ef\u9760\u5730\u53cd\u6620\u771f\u5b9e\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u901a\u8fc7\u5bf9372\u540d\u4e13\u4e1a\u5f00\u53d1\u8005\u7684\u5de5\u4e1a\u4f7f\u7528\u65e5\u5fd7\u8fdb\u884c\u60c5\u611f\u5206\u6790\uff0c\u6316\u6398\u5f00\u53d1\u8005\u7684\u63d0\u793a\u8bed\u4e2d\u8574\u542b\u7684\u9690\u5f0f\u6ee1\u610f\u5ea6\u53cd\u9988\uff0c\u5e76\u4e0e\u4f20\u7edf\u663e\u5f0f\u53cd\u9988\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u60c5\u611f\u5206\u6790\u53ef\u5728\u7ea68%\u7684\u4ea4\u4e92\u4e2d\u8bc6\u522b\u9690\u5f0f\u6ee1\u610f\u5ea6\u4fe1\u53f7\uff0c\u8fd9\u4e00\u8bc6\u522b\u7387\u662f\u663e\u5f0f\u53cd\u9988\u768413\u500d\u4ee5\u4e0a\uff0c\u540c\u65f6\u91c7\u7528\u73b0\u6210\u60c5\u611f\u5206\u6790\u5de5\u5177\u4e5f\u80fd\u4fdd\u8bc1\u8f83\u9ad8\u51c6\u786e\u7387\u3002", "conclusion": "\u5229\u7528\u60c5\u611f\u5206\u6790\u6280\u672f\u53ef\u4ee5\u6bd4\u4f20\u7edf\u663e\u5f0f\u53cd\u9988\u83b7\u5f97\u66f4\u591a\u4e14\u6709\u6548\u7684\u5f00\u53d1\u8005\u6ee1\u610f\u5ea6\u4fe1\u53f7\uff0c\u4ece\u800c\u63d0\u5347\u5927\u89c4\u6a21\u8bc4\u4f30\u5bf9\u8bdd\u5f0fAI\u52a9\u624b\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2509.18122", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18122", "abs": "https://arxiv.org/abs/2509.18122", "authors": ["Yue Zhang", "Jiaxin Zhang", "Qiuyu Ren", "Tahsin Saffat", "Xiaoxuan Liu", "Zitong Yang", "Banghua Zhu", "Yi Ma"], "title": "GAUSS: Benchmarking Structured Mathematical Skills for Large Language Models", "comment": "120 pages (including appendix)", "summary": "We introduce \\textbf{GAUSS} (\\textbf{G}eneral \\textbf{A}ssessment of\n\\textbf{U}nderlying \\textbf{S}tructured \\textbf{S}kills in Mathematics), a\nbenchmark that evaluates LLMs' mathematical abilities across twelve core skill\ndimensions, grouped into three domains: knowledge and understanding, problem\nsolving and communication, and meta-skills and creativity. By categorizing\nproblems according to cognitive skills and designing tasks that isolate\nspecific abilities, GAUSS constructs comprehensive, fine-grained, and\ninterpretable profiles of models' mathematical abilities. These profiles\nfaithfully represent their underlying mathematical intelligence. To exemplify\nhow to use the \\textsc{GAUSS} benchmark, we have derived the skill profile of\n\\textsc{GPT-5-thinking}, revealing its strengths and weaknesses as well as its\ndifferences relative to \\textsc{o4-mini-high}, thereby underscoring the value\nof multidimensional, skill-based evaluation.", "AI": {"tldr": "GAUSS\u63d0\u51fa\u7ec6\u7c92\u5ea6\u3001\u591a\u7ef4\u5ea6\u7684\u6570\u5b66\u6280\u80fd\u57fa\u51c6\uff0c\u901a\u8fc7\u5b9e\u9645\u6d4b\u8bd5\u5c55\u793a\u5176\u80fd\u7cbe\u51c6\u5206\u6790LLM\u7684\u80fd\u529b\u5206\u5e03\u548c\u77ed\u677f\uff0c\u4e3a\u6a21\u578b\u8bc4\u6d4b\u5e26\u6765\u66f4\u9ad8\u89e3\u91ca\u6027\u3002", "motivation": "\u5f53\u524d\u7684LLM\u6570\u5b66\u80fd\u529b\u8bc4\u6d4b\u65b9\u6cd5\u7c92\u5ea6\u7c97\u3001\u89e3\u91ca\u6027\u5f31\uff0c\u7f3a\u4e4f\u5bf9\u5e95\u5c42\u7ed3\u6784\u5316\u6280\u80fd\u7684\u7ec6\u81f4\u5206\u6790\uff0c\u96be\u4ee5\u5168\u9762\u53cd\u6620\u6a21\u578b\u771f\u5b9e\u6570\u5b66\u667a\u80fd\u6c34\u5e73\u3002", "method": "\u8bbe\u8ba1GAUSS\u57fa\u51c6\uff0c\u5c06\u6570\u5b66\u80fd\u529b\u5212\u5206\u4e3a\u5341\u4e8c\u9879\u6838\u5fc3\u6280\u80fd\uff0c\u6db5\u76d6\u77e5\u8bc6\u7406\u89e3\u3001\u95ee\u9898\u89e3\u51b3\u4e0e\u4ea4\u6d41\u3001\u5143\u6280\u80fd\u4e0e\u521b\u9020\u529b\u4e09\u5927\u9886\u57df\u3002\u6240\u6709\u9898\u76ee\u5747\u6309\u6280\u80fd\u5206\u7c7b\uff0c\u9488\u5bf9\u6027\u51fa\u9898\uff0c\u4ece\u800c\u7ec6\u81f4\u3001\u5b9a\u91cf\u5730\u523b\u753b\u6a21\u578b\u80fd\u529b\u753b\u50cf\u3002", "result": "\u4ee5GPT-5-thinking\u4e3a\u4f8b\uff0c\u5229\u7528GAUSS\u83b7\u5f97\u4e86\u5176\u7ec6\u7c92\u5ea6\u7684\u6280\u80fd\u77e9\u9635\uff0c\u6e05\u6670\u63ed\u793a\u5176\u5f3a\u9879\u3001\u5f31\u70b9\u53ca\u4e0eo4-mini-high\u6a21\u578b\u7684\u5dee\u5f02\u3002", "conclusion": "GAUSS\u57fa\u51c6\u5b9e\u73b0\u4e86\u591a\u7ef4\u5ea6\u3001\u4ee5\u6280\u80fd\u4e3a\u6838\u5fc3\u7684LLM\u6570\u5b66\u80fd\u529b\u8bc4\u6d4b\uff0c\u6781\u5927\u4e30\u5bcc\u4e86\u6a21\u578b\u80fd\u529b\u89e3\u91ca\u548c\u5bf9\u6bd4\u624b\u6bb5\u3002"}}
{"id": "2509.18454", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.18454", "abs": "https://arxiv.org/abs/2509.18454", "authors": ["Andrzej Bia\u0142ecki", "Piotr Bia\u0142ecki", "Piotr Sowi\u0144ski", "Mateusz Budziak", "Jan Gajewski"], "title": "SC2Tools: StarCraft II Toolset and Dataset API", "comment": null, "summary": "Computer games, as fully controlled simulated environments, have been\nutilized in significant scientific studies demonstrating the application of\nReinforcement Learning (RL). Gaming and esports are key areas influenced by the\napplication of Artificial Intelligence (AI) and Machine Learning (ML) solutions\nat scale. Tooling simplifies scientific workloads and is essential for\ndeveloping the gaming and esports research area.\n  In this work, we present ``SC2Tools'', a toolset containing multiple\nsubmodules responsible for working with, and producing larger datasets. We\nprovide a modular structure of the implemented tooling, leaving room for future\nextensions where needed. Additionally, some of the tools are not StarCraft~2\nexclusive and can be used with other types of data for dataset creation.\n  The tools we present were leveraged in creating one of the largest\nStarCraft~2 tournament datasets to date with a separate PyTorch and PyTorch\nLightning application programming interface (API) for easy access to the data.\n  We conclude that alleviating the burden of data collection, preprocessing,\nand custom code development is essential for less technically proficient\nresearchers to engage in the growing gaming and esports research area. Finally,\nour solution provides some foundational work toward normalizing experiment\nworkflow in StarCraft~2", "AI": {"tldr": "SC2Tools\u662f\u4e00\u4e2a\u9762\u5411StarCraft 2\u53ca\u5176\u5b83\u6e38\u620f\u6570\u636e\u5904\u7406\u7684\u5de5\u5177\u96c6\uff0c\u5927\u5e45\u964d\u4f4e\u6570\u636e\u5904\u7406\u96be\u5ea6\uff0c\u652f\u6301\u5927\u89c4\u6a21\u6570\u636e\u96c6\u751f\u6210\u53ca\u6807\u51c6\u5316\u5b9e\u9a8c\u6d41\u7a0b\uff0c\u4e3a\u7535\u7ade\u9886\u57df\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\u8bbe\u65bd\u3002", "motivation": "\u5f53\u524d\u6e38\u620f\u4e0e\u7535\u7ade\u9886\u57df\u56e0AI\u548c\u673a\u5668\u5b66\u4e60\u7684\u5e94\u7528\u800c\u8fc5\u901f\u53d1\u5c55\uff0c\u4f46\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u6570\u636e\u5904\u7406\u548c\u5de5\u5177\u5f00\u53d1\u95e8\u69db\u8f83\u9ad8\uff0c\u9650\u5236\u4e86\u4e00\u90e8\u5206\u7814\u7a76\u8005\u7684\u53c2\u4e0e\u3002\u4e9f\u9700\u7b80\u5316\u5de5\u5177\u4ee5\u964d\u4f4e\u6280\u672f\u95e8\u69db\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u5957\u540d\u4e3aSC2Tools\u7684\u5de5\u5177\u96c6\uff0c\u5185\u542b\u591a\u4e2a\u53ef\u6269\u5c55\u5b50\u6a21\u5757\uff0c\u652f\u6301\u6570\u636e\u5904\u7406\u53ca\u5927\u89c4\u6a21\u6570\u636e\u96c6\u751f\u6210\uff0c\u5e76\u914d\u5907\u4e86PyTorch\u53caPyTorch Lightning\u7684API\u4ee5\u4fbf\u4e8e\u6570\u636e\u8bbf\u95ee\u3002", "result": "\u5229\u7528SC2Tools\u5de5\u5177\u96c6\u6210\u529f\u6784\u5efa\u4e86\u8fc4\u4eca\u6700\u5927\u89c4\u6a21StarCraft 2\u8d5b\u4e8b\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u4f9b\u4e86\u4fbf\u6377\u7684\u6570\u636e\u8bbf\u95ee\u63a5\u53e3\uff0c\u90e8\u5206\u5de5\u5177\u8fd8\u652f\u6301\u5176\u5b83\u7c7b\u578b\u6570\u636e\u96c6\u521b\u5efa\u3002", "conclusion": "\u63d0\u51fa\u7684SC2Tools\u5de5\u5177\u96c6\u6709\u6548\u7b80\u5316\u4e86\u6570\u636e\u6536\u96c6\u3001\u9884\u5904\u7406\u548c\u81ea\u5b9a\u4e49\u4ee3\u7801\u5f00\u53d1\u6d41\u7a0b\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u66f4\u591a\u7814\u7a76\u8005\u53c2\u4e0e\u6e38\u620f\u548c\u7535\u7ade\u9886\u57df\uff0c\u5e76\u4e3aStarCraft 2\u5b9e\u9a8c\u6d41\u7a0b\u6807\u51c6\u5316\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2509.18156", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18156", "abs": "https://arxiv.org/abs/2509.18156", "authors": ["Haoyu Wang", "Fengze Liu", "Jiayao Zhang", "Dan Roth", "Kyle Richardson"], "title": "Event Causality Identification with Synthetic Control", "comment": null, "summary": "Event causality identification (ECI), a process that extracts causal\nrelations between events from text, is crucial for distinguishing causation\nfrom correlation. Traditional approaches to ECI have primarily utilized\nlinguistic patterns and multi-hop relational inference, risking false causality\nidentification due to informal usage of causality and specious graphical\ninference. In this paper, we adopt the Rubin Causal Model to identify event\ncausality: given two temporally ordered events, we see the first event as the\ntreatment and the second one as the observed outcome. Determining their\ncausality involves manipulating the treatment and estimating the resultant\nchange in the likelihood of the outcome. Given that it is only possible to\nimplement manipulation conceptually in the text domain, as a work-around, we\ntry to find a twin for the protagonist from existing corpora. This twin should\nhave identical life experiences with the protagonist before the treatment but\nundergoes an intervention of treatment. However, the practical difficulty of\nlocating such a match limits its feasibility. Addressing this issue, we use the\nsynthetic control method to generate such a twin' from relevant historical\ndata, leveraging text embedding synthesis and inversion techniques. This\napproach allows us to identify causal relations more robustly than previous\nmethods, including GPT-4, which is demonstrated on a causality benchmark,\nCOPES-hard.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u4e8b\u4ef6\u56e0\u679c\u5173\u7cfb\u8bc6\u522b\u7684\u51c6\u786e\u6027\u95ee\u9898\uff0c\u521b\u65b0\u6027\u5730\u5f15\u5165\u56e0\u679c\u63a8\u65ad\u6a21\u578b\u548c\u5408\u6210\u63a7\u5236\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u6587\u672c\u5d4c\u5165\u6280\u672f\u751f\u6210\u201c\u53cc\u751f\u8005\u201d\u6765\u6a21\u62df\u5e72\u9884\u6548\u679c\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u5f3a\uff0c\u5c24\u5176\u5728\u96be\u70b9\u56e0\u679c\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u4e86GPT-4\u3002", "motivation": "\u4e8b\u4ef6\u56e0\u679c\u5173\u7cfb\u8bc6\u522b\uff08ECI\uff09\u662f\u4ece\u6587\u672c\u4e2d\u63d0\u53d6\u4e8b\u4ef6\u95f4\u56e0\u679c\u5173\u7cfb\u7684\u8fc7\u7a0b\uff0c\u5bf9\u4e8e\u533a\u5206\u56e0\u679c\u5173\u7cfb\u4e0e\u76f8\u5173\u6027\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e8e\u8bed\u8a00\u6a21\u5f0f\u548c\u591a\u8df3\u63a8\u7406\uff0c\u5bb9\u6613\u56e0\u975e\u6b63\u5f0f\u7528\u6cd5\u6216\u865a\u5047\u7684\u56fe\u63a8\u7406\u51fa\u73b0\u8bef\u5224\u3002\u4e3a\u63d0\u5347\u56e0\u679c\u8bc6\u522b\u7684\u51c6\u786e\u6027\uff0c\u9700\u8981\u66f4\u4e25\u8c28\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528Rubin\u56e0\u679c\u6a21\u578b\uff0c\u5c06\u4e24\u4e2a\u6709\u65f6\u95f4\u987a\u5e8f\u7684\u4e8b\u4ef6\u89c6\u4e3a\u5904\u7406\uff08treatment\uff09\u548c\u7ed3\u679c\uff08outcome\uff09\uff0c\u5e76\u901a\u8fc7\u64cd\u63a7\u5904\u7406\u4e8b\u4ef6\u4ee5\u53ca\u4f30\u7b97\u7ed3\u679c\u4e8b\u4ef6\u6982\u7387\u53d8\u5316\u6765\u5224\u65ad\u56e0\u679c\u5173\u7cfb\u3002\u7531\u4e8e\u6587\u672c\u57df\u65e0\u6cd5\u771f\u5b9e\u64cd\u4f5c\u4e8b\u4ef6\uff0c\u4f5c\u8005\u63d0\u51fa\u5bfb\u627e\u4e3b\u89d2\u7684\u201c\u53cc\u751f\u8005\u201d\uff0c\u5373\u5728\u5904\u7406\u4e8b\u4ef6\u53d1\u751f\u524d\u6709\u76f8\u540c\u7ecf\u5386\u4f46\u5904\u7406\u4e8b\u4ef6\u6709\u5e72\u9884\u7684\u4e2a\u4f53\u3002\u5b9e\u9645\u5339\u914d\u56f0\u96be\uff0c\u4f5c\u8005\u91c7\u7528\u5408\u6210\u63a7\u5236\u6cd5\uff0c\u5229\u7528\u6587\u672c\u5d4c\u5165\u5408\u6210\u4e0e\u53cd\u6f14\u6280\u672f\uff0c\u751f\u6210\u201c\u53cc\u751f\u8005\u201d\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u56e0\u679c\u6027\u57fa\u51c6\u6d4b\u8bd5 COPES-hard \u4e0a\u8868\u73b0\u4f18\u8d8a\uff0c\u8bc6\u522b\u56e0\u679c\u5173\u7cfb\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u8d85\u8fc7\u4e86\u4ee5\u5f80\u65b9\u6cd5\uff0c\u5305\u62ecGPT-4\u3002", "conclusion": "\u901a\u8fc7Rubin\u56e0\u679c\u6a21\u578b\u7ed3\u5408\u5408\u6210\u63a7\u5236\u65b9\u6cd5\uff0c\u53ef\u4ee5\u66f4\u575a\u5b9e\u3001\u7cbe\u786e\u5730\u5728\u6587\u672c\u4e2d\u8bc6\u522b\u4e8b\u4ef6\u56e0\u679c\u5173\u7cfb\uff0c\u6709\u6548\u89c4\u907f\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2509.18548", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.18548", "abs": "https://arxiv.org/abs/2509.18548", "authors": ["Steven R Brandt", "Max Morris", "Patrick Diehl", "Christopher Bowen", "Jacob Tucker", "Lauren Bristol", "Golden G. Richard III"], "title": "Locking Down Science Gateways", "comment": null, "summary": "The most recent Linux kernels have a new feature for securing applications:\nLandlock. Like Seccomp before it, Landlock makes it possible for a running\nprocess to give up access to resources. For applications running as Science\nGateways, network access is required while starting up MPI, but for the sake of\nsecurity, it should be taken away prior to the reading of user-supplied\nparameter files. We explore the usefulness of Landlock by modifying and locking\ndown three mature scientific codes: The Einstein Toolkit (a code that studies\nthe dynamics of relativistic astrophysics, e.g. neutron star collisions),\nOcto-Tiger (a code for studying the dynamics of non-relativistic astrophysics,\ne.g. white dwarfs), and FUKA (an initial data solver for relativistic codes).\nFinally, we implement a fully-functioning FUKA science gateway that relies on\nLandlock (instead of user authentication) for security.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86Linux\u65b0\u5b89\u5168\u7279\u6027Landlock\u5728\u79d1\u5b66\u7f51\u5173\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u5b9e\u9a8c\u52a0\u56fa\u4e09\u6b3e\u79d1\u5b66\u4ee3\u7801\uff0c\u5e76\u7528Landlock\u66ff\u4ee3\u7528\u6237\u8ba4\u8bc1\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u4e14\u5b89\u5168\u7684\u6570\u636e\u8bbf\u95ee\u63a7\u5236\u3002", "motivation": "Linux\u5185\u6838\u5f15\u5165\u4e86Landlock\u529f\u80fd\uff0c\u65e8\u5728\u589e\u5f3a\u5e94\u7528\u7a0b\u5e8f\u5b89\u5168\u6027\u3002\u79d1\u5b66\u7f51\u5173\u5e94\u7528\u5728\u542f\u52a8MPI\u65f6\u9700\u8981\u7f51\u7edc\u8bbf\u95ee\uff0c\u4f46\u5728\u8bfb\u53d6\u7528\u6237\u53c2\u6570\u6587\u4ef6\u4e4b\u524d\uff0c\u4e3a\u4e86\u5b89\u5168\u9700\u8981\u9650\u5236\u7f51\u7edc\u8bbf\u95ee\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22Landlock\u662f\u5426\u80fd\u6709\u6548\u589e\u5f3a\u79d1\u5b66\u4ee3\u7801\u7684\u5b89\u5168\u6027\u3002", "method": "\u7814\u7a76\u8005\u901a\u8fc7\u4fee\u6539\u548c\u52a0\u56fa\u4e09\u4e2a\u6210\u719f\u7684\u79d1\u5b66\u4ee3\u7801\uff1aEinstein Toolkit\u3001Octo-Tiger\u548cFUKA\uff0c\u5b9e\u9a8c\u6027\u5730\u9501\u5b9a\u548c\u9650\u5236\u5176\u8d44\u6e90\u8bbf\u95ee\u3002\u540c\u65f6\uff0c\u4ed6\u4eec\u5b9e\u73b0\u4e86\u4e00\u4e2a\u5b8c\u5168\u57fa\u4e8eLandlock\u7684FUKA\u79d1\u5b66\u7f51\u5173\uff0c\u4e0d\u518d\u4f9d\u8d56\u7528\u6237\u8ba4\u8bc1\u6765\u4fdd\u8bc1\u5b89\u5168\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLandlock\u53ef\u4ee5\u6709\u6548\u5730\u7528\u4e8e\u79d1\u5b66\u7f51\u5173\u5b89\u5168\u52a0\u56fa\uff0c\u5e76\u80fd\u591f\u4ee3\u66ff\u4f20\u7edf\u7684\u7528\u6237\u8ba4\u8bc1\u673a\u5236\uff0c\u4ee5\u8d44\u6e90\u8bbf\u95ee\u63a7\u5236\u63d0\u9ad8\u6574\u4f53\u5b89\u5168\u6027\u3002", "conclusion": "Landlock\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u9760\u7684\u5b89\u5168\u673a\u5236\uff0c\u6709\u52a9\u4e8e\u79d1\u5b66\u4ee3\u7801\u8fd0\u884c\u4e2d\u8d44\u6e90\u8bbf\u95ee\u7684\u52a8\u6001\u9650\u5236\uff0c\u4ece\u800c\u63d0\u5347\u79d1\u5b66\u7f51\u5173\u5e94\u7528\u7684\u5b89\u5168\u6c34\u5e73\u3002"}}
{"id": "2509.18158", "categories": ["cs.CL", "cs.LG", "I.2.7"], "pdf": "https://arxiv.org/pdf/2509.18158", "abs": "https://arxiv.org/abs/2509.18158", "authors": ["Seungyoun Yi", "Minsoo Khang", "Sungrae Park"], "title": "ZERA: Zero-init Instruction Evolving Refinement Agent - From Zero Instructions to Structured Prompts via Principle-based Optimization", "comment": "9 pages, 4 figures. To appear in EMNLP 2025 Main Conference (Oral\n  Presentation)", "summary": "Automatic Prompt Optimization (APO) improves large language model (LLM)\nperformance by refining prompts for specific tasks. However, prior APO methods\ntypically focus only on user prompts, rely on unstructured feedback, and\nrequire large sample sizes and long iteration cycles-making them costly and\nbrittle. We propose ZERA (Zero-init Instruction Evolving Refinement Agent), a\nnovel framework that jointly optimizes both system and user prompts through\nprincipled, low-overhead refinement. ZERA scores prompts using eight\ngeneralizable criteria with automatically inferred weights, and revises prompts\nbased on these structured critiques. This enables fast convergence to\nhigh-quality prompts using minimal examples and short iteration cycles. We\nevaluate ZERA across five LLMs and nine diverse datasets spanning reasoning,\nsummarization, and code generation tasks. Experimental results demonstrate\nconsistent improvements over strong baselines. Further ablation studies\nhighlight the contribution of each component to more effective prompt\nconstruction. Our implementation including all prompts is publicly available at\nhttps://github.com/younatics/zera-agent.", "AI": {"tldr": "\u63d0\u51faZERA\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6807\u51c6\u540c\u65f6\u4f18\u5316\u7cfb\u7edf\u4e0e\u7528\u6237\u63d0\u793a\u8bcd\uff0c\u663e\u8457\u63d0\u5347LLM\u591a\u4efb\u52a1\u8868\u73b0\uff0c\u8f83\u4f20\u7edf\u65b9\u6cd5\u66f4\u9ad8\u6548\u4e14\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u63d0\u793a\u8bcd\u4f18\u5316\uff08APO\uff09\u65b9\u6cd5\u901a\u5e38\u53ea\u5173\u6ce8\u7528\u6237\u63d0\u793a\u8bcd\uff0c\u4f9d\u8d56\u65e0\u7ed3\u6784\u5316\u53cd\u9988\uff0c\u5e76\u4e14\u9700\u8981\u5927\u91cf\u6837\u672c\u548c\u957f\u65f6\u95f4\u8fed\u4ee3\uff0c\u5bfc\u81f4\u6210\u672c\u9ad8\u4e14\u6548\u679c\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51fa\u4e86ZERA\uff08Zero-init Instruction Evolving Refinement Agent\uff09\u6846\u67b6\uff0c\u80fd\u591f\u901a\u8fc7\u7ed3\u6784\u5316\u8bc4\u4ef7\u6807\u51c6\u540c\u65f6\u4f18\u5316\u7cfb\u7edf\u548c\u7528\u6237\u63d0\u793a\u8bcd\u3002ZERA\u57fa\u4e8e\u516b\u4e2a\u901a\u7528\u6807\u51c6\u53ca\u81ea\u52a8\u63a8\u65ad\u7684\u6743\u91cd\uff0c\u5bf9\u63d0\u793a\u8bcd\u8fdb\u884c\u8bc4\u5206\u5e76\u57fa\u4e8e\u7ed3\u6784\u5316\u53cd\u9988\u8fdb\u884c\u4fee\u6b63\u3002\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5feb\u901f\u6536\u655b\u5230\u9ad8\u8d28\u91cf\u63d0\u793a\u8bcd\uff0c\u6240\u9700\u6837\u672c\u548c\u8fed\u4ee3\u5468\u671f\u8f83\u5c11\u3002", "result": "\u5728\u4e94\u4e2a\u4e0d\u540c\u7684\u5927\u8bed\u8a00\u6a21\u578b\u548c\u4e5d\u4e2a\u8de8\u591a\u4efb\u52a1\u6570\u636e\u96c6\uff08\u5305\u62ec\u63a8\u7406\u3001\u6458\u8981\u3001\u4ee3\u7801\u751f\u6210\u7b49\uff09\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793aZERA\u5728\u5404\u9879\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002\u6d88\u878d\u5b9e\u9a8c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u5404\u7ec4\u6210\u90e8\u5206\u5bf9\u63d0\u793a\u8bcd\u8d28\u91cf\u7684\u63d0\u5347\u4f5c\u7528\u3002", "conclusion": "ZERA\u53ef\u4ee5\u4ee5\u8f83\u4f4e\u6210\u672c\u3001\u9ad8\u6548\u7387\uff0c\u7ed3\u6784\u5316\u4f18\u5316\u63d0\u793a\u8bcd\uff0c\u663e\u8457\u63d0\u5347\u591a\u4efb\u52a1\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5b9e\u73b0\u5f00\u6e90\u3002"}}
{"id": "2509.18808", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.18808", "abs": "https://arxiv.org/abs/2509.18808", "authors": ["Zexun Zhan", "Shuzheng Gao", "Ruida Hu", "Cuiyun Gao"], "title": "SR-Eval: Evaluating LLMs on Code Generation under Stepwise Requirement Refinement", "comment": null, "summary": "Large language models (LLMs) have achieved remarkable progress in code\ngeneration. However, existing benchmarks mainly formalize the task as a static,\nsingle-turn problem, overlooking the stepwise requirement changes and iterative\nworkflows in real-world software development. This mismatch limits the\nunderstanding of how well LLMs can support real-world development workflows.\nConstructing such iterative benchmarks is challenging due to the lack of public\ninteraction traces and the difficulty of creating discriminative, turn-specific\ntest cases.\n  To bridge this gap, we present SR-Eval, a benchmark specifically designed to\nassess LLMs on iterative code generation under Stepwise requirements\nRefinement. SR-Eval spans both function-level and repository-level tasks in\nPython and Java, enabling fine-grained and progressive evaluation across\nevolving requirements. The construction of SR-Eval follows a carefully designed\npipeline that first leverages a multi-agent-based requirement generation method\nto simulate the development process and recover the multi-round interaction\nprocess from final requirements, then employs a semantic-aware discriminative\ntest case generation component to ensure discriminative and consistent\nevaluation at each turn. SR-Eval comprises 443 multi-turn tasks and 1,857\nquestions at both function and repository levels. Using SR-Eval, we evaluate 11\nrepresentative LLMs with three prompting strategies that simulate different\nusage patterns. Results show that iterative code generation under stepwise\nrequirement refinement remains highly challenging: the best-performing model\nachieves only 22.67% completion rate on function-level tasks and 20.00% on\nrepository-level tasks. We further observe that prompting strategies\nsubstantially influence performance, highlighting the need for the development\nof advanced methods.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u73b0\u5b9e\u5f00\u53d1\u4e2d\u9010\u6b65\u8fed\u4ee3\u7684\u9700\u6c42\uff0c\u63d0\u51faSR-Eval\u57fa\u51c6\uff0c\u5b8c\u6574\u8986\u76d6\u591a\u56de\u5408\u3001\u591a\u7c92\u5ea6\u4ee3\u7801\u751f\u6210\u8bc4\u6d4b\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u4e3b\u6d41LLM\u5728\u8be5\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u63d0\u793a\u65b9\u5f0f\u5f71\u54cd\u663e\u8457\uff0c\u4e9f\u9700\u66f4\u5f3a\u7684\u6a21\u578b\u548c\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u53ea\u5173\u6ce8\u9759\u6001\u3001\u5355\u56de\u5408\u4efb\u52a1\uff0c\u5ffd\u89c6\u4e86\u73b0\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u9700\u6c42\u9010\u6b65\u53d8\u5316\u4e0e\u8fed\u4ee3\u7684\u6d41\u7a0b\u3002\u8fd9\u79cd\u4e0d\u5339\u914d\u5236\u7ea6\u4e86\u5bf9LLMs\u5728\u771f\u5b9e\u5f00\u53d1\u573a\u666f\u4e0b\u652f\u6301\u80fd\u529b\u7684\u7406\u89e3\u3002", "method": "\u63d0\u51faSR-Eval\u57fa\u51c6\uff0c\u4e13\u95e8\u8bc4\u4f30LLMs\u5728\u9010\u6b65\u9700\u6c42\u7ec6\u5316\u4e0b\u7684\u8fed\u4ee3\u5f0f\u4ee3\u7801\u751f\u6210\u3002\u8be5\u57fa\u51c6\u8986\u76d6Python\u548cJava\u7684\u51fd\u6570\u7ea7\u548c\u4ed3\u5e93\u7ea7\u4efb\u52a1\uff0c\u91c7\u7528\u591a\u4ee3\u7406\u9700\u6c42\u751f\u6210\u6a21\u62df\u5f00\u53d1\u8fc7\u7a0b\uff0c\u7ed3\u5408\u8bed\u4e49\u611f\u77e5\u5224\u522b\u6027\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\uff0c\u786e\u4fdd\u6bcf\u56de\u5408\u8bc4\u6d4b\u5177\u533a\u5206\u6027\u548c\u4e00\u81f4\u6027\u3002\u5171\u5305\u542b443\u4e2a\u591a\u56de\u5408\u4efb\u52a1\u548c1,857\u4e2a\u95ee\u9898\u3002", "result": "\u5728SR-Eval\u57fa\u51c6\u4e0b\uff0c\u8bc4\u6d4b\u4e8611\u4e2a\u4ee3\u8868\u6027LLM\u548c\u4e09\u79cd\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u3002\u7ed3\u679c\u663e\u793a\uff0c\u9010\u6b65\u9700\u6c42\u7ec6\u5316\u4e0b\u7684\u8fed\u4ee3\u4ee3\u7801\u751f\u6210\u4ecd\u6781\u5177\u6311\u6218\uff0c\u6700\u4f18\u6a21\u578b\u5728\u51fd\u6570\u7ea7\u4efb\u52a1\u5b8c\u6210\u7387\u4ec522.67%\uff0c\u4ed3\u5e93\u7ea7\u4efb\u52a1\u4e3a20.00%\u3002\u63d0\u793a\u7b56\u7565\u5bf9\u6027\u80fd\u5f71\u54cd\u663e\u8457\u3002", "conclusion": "\u9010\u6b65\u9700\u6c42\u7ec6\u5316\u573a\u666f\u4e0b\uff0c\u5f53\u524dLLMs\u5728\u8fed\u4ee3\u4ee3\u7801\u751f\u6210\u80fd\u529b\u8fdc\u672a\u6ee1\u8db3\u5b9e\u9645\u9700\u6c42\uff0c\u63d0\u793a\u7b56\u7565\u7684\u6539\u8fdb\u4e5f\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2509.18163", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18163", "abs": "https://arxiv.org/abs/2509.18163", "authors": ["Haodong Zhao", "Chenyan Zhao", "Yansi Li", "Zhuosheng Zhang", "Gongshen Liu"], "title": "Thinking in a Crowd: How Auxiliary Information Shapes LLM Reasoning", "comment": "Work in progress", "summary": "The capacity of Large Language Models (LLMs) to reason is fundamental to\ntheir application in complex, knowledge-intensive domains. In real-world\nscenarios, LLMs are often augmented with external information that can be\nhelpful, irrelevant, or even misleading. This paper investigates the causal\nimpact of such auxiliary information on the reasoning process of LLMs with\nexplicit step-by-step thinking capabilities. We introduce SciAux, a new dataset\nderived from ScienceQA, to systematically test the robustness of the model\nagainst these types of information. Our findings reveal a critical\nvulnerability: the model's deliberative \"thinking mode\" is a double-edged\nsword. While helpful context improves accuracy, misleading information causes a\ncatastrophic drop in performance, which is amplified by the thinking process.\nInstead of conferring robustness, thinking reinforces the degree of error when\nprovided with misinformation. This highlights that the challenge is not merely\nto make models \"think\", but to endow them with the critical faculty to evaluate\nthe information upon which their reasoning is based. The SciAux dataset is\navailable at https://huggingface.co/datasets/billhdzhao/SciAux.", "AI": {"tldr": "\u5927\u6a21\u578b\u9047\u5230\u8bef\u5bfc\u4fe1\u606f\u65f6\uff0c\u601d\u8003/\u63a8\u7406\u8fc7\u7a0b\u4f1a\u653e\u5927\u9519\u8bef\uff0c\u66b4\u9732\u51fa\u601d\u7ef4\u9c81\u68d2\u6027\u7684\u5f31\u70b9\u3002\u9700\u63d0\u5347\u6a21\u578b\u6279\u5224\u6027\u4fe1\u606f\u8bc4\u4f30\u80fd\u529b\u3002SciAux\u6570\u636e\u96c6\u652f\u6301\u76f8\u5173\u7814\u7a76\u3002", "motivation": "\u63a2\u7a76\u5b9e\u9645\u5e94\u7528\u4e2d\u5927\u6a21\u578b\u9762\u5bf9\u5916\u90e8\u8f85\u52a9\u4fe1\u606f\u65f6\uff0c\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u53ca\u5176\u8106\u5f31\u6027\uff0c\u5c24\u5176\u662f\u6a21\u578b\u9047\u5230\u8bef\u5bfc\u6027\u4fe1\u606f\u65f6\u63a8\u7406-\u601d\u8003\u673a\u5236\u5e26\u6765\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u5e76\u6784\u5efa\u4e86SciAux\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u6027\u5730\u5bf9\u4e0d\u540c\u7c7b\u578b\u8f85\u52a9\u4fe1\u606f\uff08\u6709\u7528\u3001\u65e0\u5173\u3001\u8bef\u5bfc\uff09\u4e0b\uff0c\u62e5\u6709\u663e\u5f0f\u9010\u6b65\u63a8\u7406\u80fd\u529b\u7684\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9c81\u68d2\u6027\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u53d1\u73b0\u5927\u6a21\u578b\u9047\u5230\u8bef\u5bfc\u4fe1\u606f\u65f6\uff0c\u201c\u601d\u8003\u201d\u6b65\u9aa4\u4e0d\u4ec5\u672a\u589e\u5f3a\u9c81\u68d2\u6027\uff0c\u53cd\u800c\u8fdb\u4e00\u6b65\u52a0\u5267\u4e86\u9519\u8bef\uff0c\u6a21\u578b\u5728\u9519\u8bef\u4fe1\u606f\u5e72\u6270\u4e0b\u6027\u80fd\u9aa4\u964d\u3002", "conclusion": "\u5927\u6a21\u578b\u8fdb\u884c\u9010\u6b65\u63a8\u7406\u65f6\uff0c\u53d7\u5916\u90e8\u8f85\u52a9\u4fe1\u606f\u663e\u8457\u5f71\u54cd\uff1a\u6709\u7528\u4fe1\u606f\u80fd\u63d0\u9ad8\u51c6\u786e\u7387\uff0c\u4f46\u8bef\u5bfc\u4fe1\u606f\u4f1a\u4f7f\u6027\u80fd\u707e\u96be\u6027\u4e0b\u964d\uff0c\u4e14\u63a8\u7406\u73af\u8282\u4f1a\u653e\u5927\u9519\u8bef\u5f71\u54cd\u3002\u5173\u952e\u95ee\u9898\u5728\u4e8e\u6a21\u578b\u9700\u5177\u5907\u6279\u5224\u6027\u5730\u8bc4\u4f30\u8f93\u5165\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u800c\u4e0d\u4ec5\u662f\u5c55\u5f00\u63a8\u7406\u8fc7\u7a0b\u3002"}}
{"id": "2509.19136", "categories": ["cs.SE", "cs.AI", "D.2.4; D.2.5; F.3.1"], "pdf": "https://arxiv.org/pdf/2509.19136", "abs": "https://arxiv.org/abs/2509.19136", "authors": ["S\u00e9bastien Salva", "Redha Taguelmimt"], "title": "On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language", "comment": null, "summary": "The use of natural language (NL) test cases for validating graphical user\ninterface (GUI) applications is emerging as a promising direction to manually\nwritten executable test scripts, which are costly to develop and difficult to\nmaintain. Recent advances in large language models (LLMs) have opened the\npossibility of the direct execution of NL test cases by LLM agents. This paper\ninvestigates this direction, focusing on the impact on NL test case unsoundness\nand on test case execution consistency. NL test cases are inherently unsound,\nas they may yield false failures due to ambiguous instructions or unpredictable\nagent behaviour. Furthermore, repeated executions of the same NL test case may\nlead to inconsistent outcomes, undermining test reliability. To address these\nchallenges, we propose an algorithm for executing NL test cases with guardrail\nmechanisms and specialised agents that dynamically verify the correct execution\nof each test step. We introduce measures to evaluate the capabilities of LLMs\nin test execution and one measure to quantify execution consistency. We propose\na definition of weak unsoundness to characterise contexts in which NL test case\nexecution remains acceptable, with respect to the industrial quality levels Six\nSigma. Our experimental evaluation with eight publicly available LLMs, ranging\nfrom 3B to 70B parameters, demonstrates both the potential and current\nlimitations of current LLM agents for GUI testing. Our experiments show that\nMeta Llama 3.1 70B demonstrates acceptable capabilities in NL test case\nexecution with high execution consistency (above the level 3-sigma). We provide\nprototype tools, test suites, and results.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9GUI\u5e94\u7528\u7684\u81ea\u7136\u8bed\u8a00\u6d4b\u8bd5\uff0c\u5206\u6790LLM\u76f4\u63a5\u6267\u884c\u8be5\u7c7b\u6d4b\u8bd5\u7684\u53ef\u9760\u6027\u4e0e\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u52a0\u62a4\u680f\u7684\u7b97\u6cd5\u4e0e\u8bc4\u4ef7\u6307\u6807\u3002\u5b9e\u9a8c\u8bc1\u660e\u90e8\u5206\u5927\u6a21\u578b\u5982Llama 3.1 70B\u5177\u5907\u8f83\u9ad8\u53ef\u7528\u6027\uff0c\u7814\u7a76\u63a8\u52a8\u4e86NL\u6d4b\u8bd5\u5411\u5b9e\u7528\u8f6c\u53d8\u5e76\u63d0\u51fa\u672a\u6765\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u624b\u5199\u53ef\u6267\u884c\u6d4b\u8bd5\u811a\u672c\u7528\u4e8eGUI\u5e94\u7528\u9a8c\u8bc1\u6210\u672c\u9ad8\u3001\u7ef4\u62a4\u96be\u3002\u81ea\u7136\u8bed\u8a00\u6d4b\u8bd5\u7528\u4f8b\u7ed3\u5408LLMs\u6709\u671b\u964d\u4f4e\u6210\u672c\u5e76\u63d0\u5347\u7075\u6d3b\u6027\uff0c\u4f46\u81ea\u7136\u8bed\u8a00\u6d4b\u8bd5\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\u548c\u4e0d\u53ef\u9760\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u914d\u5907\u62a4\u680f\u673a\u5236\u548c\u4e13\u95e8\u667a\u80fd\u4f53\u7684\u7b97\u6cd5\uff0c\u52a8\u6001\u9a8c\u8bc1\u6bcf\u4e00\u6b65\u6d4b\u8bd5\u7684\u6b63\u786e\u6267\u884c\uff1b\u8bbe\u8ba1\u4e86\u65b0\u6307\u6807\u8861\u91cfLLM\u7684\u6d4b\u8bd5\u6267\u884c\u80fd\u529b\u53ca\u4e00\u81f4\u6027\uff0c\u5e76\u5b9a\u4e49\u4e86\u5f31\u4e0d\u53ef\u9760\u5ea6\u4ee5\u91cf\u5316\u53ef\u63a5\u53d7\u7684\u6267\u884c\u73af\u5883\u3002", "result": "\u5728\u5305\u62ecMeta Llama 3.1 70B\u7b49\u516b\u4e2a\u4e0d\u540c\u89c4\u6a21\u7684LLM\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0cMeta Llama 3.1 70B\u80fd\u4ee5\u8f83\u9ad8\u4e00\u81f4\u6027\uff08\u9ad8\u4e8e3-sigma\u6c34\u5e73\uff09\u6267\u884c\u81ea\u7136\u8bed\u8a00\u6d4b\u8bd5\u7528\u4f8b\u3002", "conclusion": "\u73b0\u6709LLM\u5728GUI\u81ea\u7136\u8bed\u8a00\u6d4b\u8bd5\u5177\u6709\u6f5c\u529b\u4f46\u8fd8\u6709\u9650\u5236\uff0c\u5c1d\u8bd5\u901a\u8fc7\u62a4\u680f\u673a\u5236\u548c\u667a\u80fd\u4f53\u589e\u5f3a\u53ef\u9760\u6027\u4e0e\u4e00\u81f4\u6027\uff0c\u90e8\u5206\u6a21\u578b\u5df2\u8fbe\u5230\u5de5\u4e1a\u53ef\u63a5\u53d7\u6807\u51c6\uff0c\u5e76\u63d0\u4f9b\u4e86\u5de5\u5177\u548c\u6570\u636e\u96c6\u652f\u6301\u5b9e\u8df5\u3002"}}
{"id": "2509.18167", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18167", "abs": "https://arxiv.org/abs/2509.18167", "authors": ["Junlin Wang", "Zehao Wu", "Shaowei Lu", "Yanlan Li", "Xinghao Huang"], "title": "SIRAG: Towards Stable and Interpretable RAG with A Process-Supervised Multi-Agent Framework", "comment": "5 pages,2 figures, IRAC under review", "summary": "Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to\naccess external knowledge sources, but the effectiveness of RAG relies on the\ncoordination between the retriever and the generator. Since these components\nare developed independently, their interaction is often suboptimal: the\nretriever may return irrelevant or redundant documents, while the generator may\nfail to fully leverage retrieved evidence. In this work, we propose a\nprocess-supervised multi-agent framework to bridge the gap between retriever\nand generator. The framework introduces two lightweight agents: a Decision\nMaker, which determines when to continue retrieval or stop for answer\ngeneration, and a Knowledge Selector, which filters retrieved documents to\nretain only the most useful evidence. To provide fine-grained supervision, we\nemploy an LLM-as-a-Judge that evaluates each intermediate action with\nprocess-level rewards, ensuring more accurate credit assignment than relying\nsolely on final answer correctness. We further adopt a tree-structured rollout\nstrategy to explore diverse reasoning paths, and train both agents with\nProximal Policy Optimization (PPO) in an end-to-end manner. Experiments on\nsingle-hop and multi-hop question answering benchmarks show that our approach\nachieves higher accuracy, more stable convergence, and produces more\ninterpretable reasoning trajectories compared with standard RAG baselines.\nImportantly, the proposed framework is modular and plug-and-play, requiring no\nmodification to the retriever or generator, making it practical for real-world\nRAG applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRAG\u591a\u667a\u80fd\u4f53\u8fc7\u7a0b\u76d1\u7763\u6846\u67b6\uff0c\u901a\u8fc7\u51b3\u7b56\u4e0e\u77e5\u8bc6\u7b5b\u9009\u4ee3\u7406\u3001\u5956\u52b1\u673a\u5236\u4e0e\u6811\u5f62\u56de\u6eaf\u63a2\u7d22\uff0c\u6709\u6548\u63d0\u5347\u4e86\u68c0\u7d22\u751f\u6210\u534f\u540c\u3001\u591a\u8df3\u95ee\u7b54\u51c6\u786e\u7387\u53ca\u7cfb\u7edf\u53ef\u89e3\u91ca\u6027\uff0c\u65e0\u9700\u4fee\u6539\u539f\u6709RAG\u7ec4\u4ef6\uff0c\u5177\u5f3a\u5b9e\u9645\u5e94\u7528\u610f\u4e49\u3002", "motivation": "\u73b0\u6709RAG\u65b9\u6cd5\u4e2d\uff0c\u68c0\u7d22\u5668\u4e0e\u751f\u6210\u5668\u5404\u81ea\u72ec\u7acb\u5f00\u53d1\uff0c\u4ea4\u4e92\u4e0d\u4f73\uff0c\u6613\u5bfc\u81f4\u68c0\u7d22\u76f8\u5173\u6027\u4f4e\u6216\u8bc1\u636e\u5229\u7528\u4e0d\u8db3\uff0c\u5f71\u54cd\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002", "method": "\u5f15\u5165\u51b3\u7b56\u8005\u548c\u77e5\u8bc6\u9009\u62e9\u8005\u4e24\u4e2a\u8f7b\u91cf\u4ee3\u7406\uff0c\u7ed3\u5408LLM-as-a-Judge\u8fc7\u7a0b\u5956\u52b1\u673a\u5236\uff0c\u91c7\u7528\u6811\u5f62\u56de\u6eaf\u63a2\u7d22\u4e0ePPO\u7aef\u5230\u7aef\u8bad\u7ec3\u65b9\u5f0f\u3002", "result": "\u5728\u5355\u8df3\u4e0e\u591a\u8df3\u95ee\u7b54\u57fa\u51c6\u4e0a\u5b9e\u73b0\u66f4\u9ad8\u51c6\u786e\u7387\u3001\u66f4\u7a33\u5b9a\u6536\u655b\u548c\u66f4\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8def\u5f84\uff0c\u5bf9\u6bd4\u6807\u51c6RAG\u57fa\u7ebf\u663e\u8457\u63d0\u5347\uff1b\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u65e0\u9700\u66f4\u6539\u539f\u68c0\u7d22\u5668\u6216\u751f\u6210\u5668\uff0c\u6613\u4e8e\u5b9e\u9645\u5e94\u7528\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u8fc7\u7a0b\u76d1\u7763\u6846\u67b6\uff0c\u6709\u6548\u4fc3\u8fdb\u4e86\u68c0\u7d22\u5668\u4e0e\u751f\u6210\u5668\u4e4b\u95f4\u7684\u534f\u8c03\uff0c\u63d0\u9ad8\u4e86RAG\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4e14\u65b9\u6cd5\u5177\u6709\u8f83\u5f3a\u7684\u53ef\u63d2\u62d4\u6027\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.19185", "categories": ["cs.SE", "cs.ET"], "pdf": "https://arxiv.org/pdf/2509.19185", "abs": "https://arxiv.org/abs/2509.19185", "authors": ["Mohammed Mehedi Hasan", "Hao Li", "Emad Fallahzadeh", "Gopi Krishnan Rajbahadur", "Bram Adams", "Ahmed E. Hassan"], "title": "An Empirical Study of Testing Practices in Open Source AI Agent Frameworks and Agentic Applications", "comment": null, "summary": "Foundation model (FM)-based AI agents are rapidly gaining adoption across\ndiverse domains, but their inherent non-determinism and non-reproducibility\npose testing and quality assurance challenges. While recent benchmarks provide\ntask-level evaluations, there is limited understanding of how developers verify\nthe internal correctness of these agents during development.\n  To address this gap, we conduct the first large-scale empirical study of\ntesting practices in the AI agent ecosystem, analyzing 39 open-source agent\nframeworks and 439 agentic applications. We identify ten distinct testing\npatterns and find that novel, agent-specific methods like DeepEval are seldom\nused (around 1%), while traditional patterns like negative and membership\ntesting are widely adapted to manage FM uncertainty. By mapping these patterns\nto canonical architectural components of agent frameworks and agentic\napplications, we uncover a fundamental inversion of testing effort:\ndeterministic components like Resource Artifacts (tools) and Coordination\nArtifacts (workflows) consume over 70% of testing effort, while the FM-based\nPlan Body receives less than 5%. Crucially, this reveals a critical blind spot,\nas the Trigger component (prompts) remains neglected, appearing in around 1% of\nall tests.\n  Our findings offer the first empirical testing baseline in FM-based agent\nframeworks and agentic applications, revealing a rational but incomplete\nadaptation to non-determinism. To address it, framework developers should\nimprove support for novel testing methods, application developers must adopt\nprompt regression testing, and researchers should explore barriers to adoption.\nStrengthening these practices is vital for building more robust and dependable\nAI agents.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u7cfb\u7edf\u5206\u6790\u4e86\u57fa\u7840\u6a21\u578b\u9a71\u52a8AI Agent\u7684\u6d4b\u8bd5\u5b9e\u8df5\uff0c\u53d1\u73b0\u73b0\u6709\u6d4b\u8bd5\u4e3b\u8981\u805a\u7126\u4e8e\u786e\u5b9a\u6027\u7ec4\u4ef6\uff0c\u5bf9\u5173\u952e\u7684Prompt\u7b49\u90e8\u5206\u5173\u6ce8\u4e25\u91cd\u4e0d\u8db3\uff0c\u547c\u5401\u884c\u4e1a\u52a0\u5f3a\u65b0\u578b\u6d4b\u8bd5\u65b9\u6cd5\u4e0ePrompt\u76f8\u5173\u6d4b\u8bd5\u3002", "motivation": "\u968f\u7740\u57fa\u7840\u6a21\u578b\u9a71\u52a8\u7684AI Agent\u5728\u5404\u9886\u57df\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u975e\u786e\u5b9a\u6027\u548c\u4e0d\u53ef\u590d\u73b0\u6027\u5e26\u6765\u4e86\u6d4b\u8bd5\u548c\u8d28\u91cf\u4fdd\u8bc1\u7684\u96be\u9898\u3002\u5f53\u524d\u7684\u8bc4\u6d4b\u591a\u4e3a\u4efb\u52a1\u5c42\u9762\uff0c\u5f00\u53d1\u8005\u5728\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u5982\u4f55\u9a8c\u8bc1AI Agent\u5185\u90e8\u6b63\u786e\u6027\u5c1a\u4e0d\u6e05\u695a\u3002\u8be5\u7814\u7a76\u65e8\u5728\u586b\u8865\u6b64\u9886\u57df\u7684\u77e5\u8bc6\u7a7a\u767d\u3002", "method": "\u5bf939\u4e2a\u5f00\u6e90AI Agent\u6846\u67b6\u548c439\u4e2aAgent\u5e94\u7528\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\uff0c\u5f52\u7eb3\u6d4b\u8bd5\u6a21\u5f0f\u5e76\u5c06\u5176\u4e0eAgent\u67b6\u6784\u7ec4\u4ef6\u5173\u8054\uff0c\u7edf\u8ba1\u4e0d\u540c\u7ec4\u4ef6\u7684\u6d4b\u8bd5\u5206\u5e03\u60c5\u51b5\u3002", "result": "\u5171\u8bc6\u522b\u51fa\u5341\u79cd\u6d4b\u8bd5\u6a21\u5f0f\uff0c\u521b\u65b0\u6027Agent\u6d4b\u8bd5\u65b9\u6cd5\u5982DeepEval\u4ec5\u88ab\u91c7\u75281%\uff0c\u800c\u4f20\u7edf\u6a21\u5f0f\u5982\u8d1f\u9762\u6d4b\u8bd5\u548c\u6210\u5458\u6d4b\u8bd5\u88ab\u5e7f\u6cdb\u7528\u4e8e\u5e94\u5bf9\u57fa\u7840\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u6d4b\u8bd5\u4e3b\u8981\u96c6\u4e2d\u5728\u5de5\u5177\u548c\u5de5\u4f5c\u6d41\u7b49\u786e\u5b9a\u6027\u7ec4\u4ef6\uff08\u536070%\u4ee5\u4e0a\uff09\uff0c\u800c\u57fa\u7840\u6a21\u578b\u9a71\u52a8\u7684\u89c4\u5212\u4e3b\u4f53\u4ec5\u6536\u5230\u4e0d\u52305%\u7684\u6d4b\u8bd5\u3002\u89e6\u53d1\u7ec4\u4ef6\uff08\u5982Prompt\uff09\u51e0\u4e4e\u88ab\u5ffd\u89c6\uff0c\u4ec5\u51fa\u73b0\u7ea61%\u7684\u6d4b\u8bd5\u4e2d\u3002", "conclusion": "AI Agent\u6d4b\u8bd5\u5b9e\u8df5\u5bf9\u975e\u786e\u5b9a\u6027\u5df2\u505a\u51fa\u4e00\u5b9a\u9002\u5e94\uff0c\u4f46\u5b58\u5728\u660e\u663e\u4e0d\u8db3\u3002\u4e3a\u63d0\u5347\u9c81\u68d2\u6027\uff0c\u5efa\u8bae\uff1a\u6846\u67b6\u5f00\u53d1\u8005\u5b8c\u5584\u65b0\u578b\u6d4b\u8bd5\u65b9\u6cd5\u652f\u6301\uff0c\u5e94\u7528\u5f00\u53d1\u8005\u5e94\u91c7\u7528Prompt\u56de\u5f52\u6d4b\u8bd5\uff0c\u7814\u7a76\u8005\u5e94\u63a2\u7a76\u6d4b\u8bd5\u65b9\u6cd5\u91c7\u7eb3\u969c\u788d\u3002"}}
{"id": "2509.18175", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18175", "abs": "https://arxiv.org/abs/2509.18175", "authors": ["Aditi Debsharma", "Bhushan Jagyasi", "Surajit Sen", "Priyanka Pandey", "Devicharith Dovari", "Yuvaraj V. C", "Rosalin Parida", "Gopali Contractor"], "title": "ERFC: Happy Customers with Emotion Recognition and Forecasting in Conversation in Call Centers", "comment": "7 pages, 6 Figures, 4 Tables, 18 References", "summary": "Emotion Recognition in Conversation has been seen to be widely applicable in\ncall center analytics, opinion mining, finance, retail, healthcare, and other\nindustries. In a call center scenario, the role of the call center agent is not\njust confined to receiving calls but to also provide good customer experience\nby pacifying the frustration or anger of the customers. This can be achieved by\nmaintaining neutral and positive emotion from the agent. As in any\nconversation, the emotion of one speaker is usually dependent on the emotion of\nother speaker. Hence the positive emotion of an agent, accompanied with the\nright resolution will help in enhancing customer experience. This can change an\nunhappy customer to a happy one. Imparting the right resolution at right time\nbecomes easier if the agent has the insight of the emotion of future\nutterances. To predict the emotions of the future utterances we propose a novel\narchitecture, Emotion Recognition and Forecasting in Conversation. Our proposed\nERFC architecture considers multi modalities, different attributes of emotion,\ncontext and the interdependencies of the utterances of the speakers in the\nconversation. Our intensive experiments on the IEMOCAP dataset have shown the\nfeasibility of the proposed ERFC. This approach can provide a tremendous\nbusiness value for the applications like call center, where the happiness of\ncustomer is utmost important.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540c\u65f6\u8bc6\u522b\u548c\u9884\u6d4b\u4f1a\u8bdd\u60c5\u7eea\u7684\u65b0\u67b6\u6784ERFC\uff0c\u5728\u591a\u4e2a\u60c5\u7eea\u5c5e\u6027\u3001\u4e0a\u4e0b\u6587\u4e0e\u591a\u6a21\u6001\u57fa\u7840\u4e0a\u6316\u6398\u8bf4\u8bdd\u8005\u4e92\u52a8\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\uff0c\u4e3a\u547c\u53eb\u4e2d\u5fc3\u7b49\u884c\u4e1a\u63d0\u5347\u5ba2\u6237\u6ee1\u610f\u5ea6\u63d0\u4f9b\u6570\u636e\u652f\u6301\u3002", "motivation": "\u5728\u547c\u53eb\u4e2d\u5fc3\u7b49\u884c\u4e1a\u573a\u666f\u4e0b\uff0c\u5ba2\u6237\u7684\u60c5\u7eea\u7ba1\u7406\u5bf9\u4e8e\u63d0\u5347\u5ba2\u6237\u4f53\u9a8c\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u73b0\u6709\u7684\u4f1a\u8bdd\u60c5\u7eea\u8bc6\u522b\u65b9\u6cd5\uff0c\u901a\u5e38\u5ffd\u7565\u5bf9\u672a\u6765\u8bdd\u8bed\u60c5\u7eea\u7684\u9884\u6d4b\uff0c\u800c\u5ba2\u6237\u4e0e\u5ea7\u5e2d\u4e4b\u95f4\u7684\u60c5\u7eea\u4e92\u52a8\u548c\u5f71\u54cd\u6781\u5927\u5f71\u54cd\u6700\u7ec8\u7ed3\u679c\u3002\u5ea7\u5e2d\u80fd\u9002\u65f6\u5224\u65ad\u5e76\u9884\u6d4b\u5ba2\u6237\u60c5\u7eea\u53d8\u5316\uff0c\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u8c03\u8282\u81ea\u8eab\u60c5\u7eea\u5e76\u63d0\u4f9b\u5408\u9002\u7684\u670d\u52a1\uff0c\u63d0\u9ad8\u5ba2\u6237\u6ee1\u610f\u5ea6\u3002", "method": "\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u67b6\u6784\uff0c\u79f0\u4e3aERFC\uff08\u4f1a\u8bdd\u4e2d\u7684\u60c5\u7eea\u8bc6\u522b\u4e0e\u9884\u6d4b\uff09\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u591a\u6a21\u6001\u4fe1\u606f\u3001\u60c5\u7eea\u7684\u4e0d\u540c\u5c5e\u6027\u3001\u4f1a\u8bdd\u4e0a\u4e0b\u6587\uff0c\u4ee5\u53ca\u8bf4\u8bdd\u8005\u4e4b\u95f4\u7684\u8bdd\u8bed\u4f9d\u8d56\u5173\u7cfb\uff0c\u901a\u8fc7\u5bf9\u672a\u6765\u8bdd\u8bed\u60c5\u7eea\u7684\u9884\u6d4b\uff0c\u8f85\u52a9\u5ea7\u5e2d\u66f4\u597d\u5730\u4e0e\u5ba2\u6237\u4e92\u52a8\u3002\u8be5\u67b6\u6784\u5728IEMOCAP\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u6df1\u5165\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cERFC\u67b6\u6784\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u4f1a\u8bdd\u4e2d\u7684\u60c5\u7eea\u8bc6\u522b\u5e76\u9884\u6d4b\u672a\u6765\u8bdd\u8bed\u60c5\u7eea\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u3002\u4e3a\u5b9e\u9645\u5e94\u7528\uff08\u5982\u547c\u53eb\u4e2d\u5fc3\uff09\u5e26\u6765\u663e\u8457\u4e1a\u52a1\u4ef7\u503c\uff0c\u80fd\u591f\u5e2e\u52a9\u63d0\u5347\u5ba2\u6237\u6ee1\u610f\u5ea6\u3002", "conclusion": "ERFC\u67b6\u6784\u901a\u8fc7\u7ed3\u5408\u591a\u6a21\u6001\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4e0d\u4ec5\u80fd\u51c6\u786e\u8bc6\u522b\u5f53\u524d\u4f1a\u8bdd\u60c5\u7eea\uff0c\u8fd8\u80fd\u9884\u6d4b\u540e\u7eed\u8bdd\u8bed\u60c5\u7eea\uff0c\u6709\u6548\u6539\u5584\u5ba2\u6237\u4f53\u9a8c\uff0c\u5177\u6709\u5e7f\u6cdb\u5546\u4e1a\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2509.18293", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.18293", "abs": "https://arxiv.org/abs/2509.18293", "authors": ["Jay Patel", "Hrudayangam Mehta", "Jeremy Blackburn"], "title": "Evaluating Large Language Models for Detecting Antisemitism", "comment": "Accepted to EMNLP 2025 Main Conference", "summary": "Detecting hateful content is a challenging and important problem. Automated\ntools, like machine-learning models, can help, but they require continuous\ntraining to adapt to the ever-changing landscape of social media. In this work,\nwe evaluate eight open-source LLMs' capability to detect antisemitic content,\nspecifically leveraging in-context definition as a policy guideline. We explore\nvarious prompting techniques and design a new CoT-like prompt, Guided-CoT.\nGuided-CoT handles the in-context policy well, increasing performance across\nall evaluated models, regardless of decoding configuration, model sizes, or\nreasoning capability. Notably, Llama 3.1 70B outperforms fine-tuned GPT-3.5.\nAdditionally, we examine LLM errors and introduce metrics to quantify semantic\ndivergence in model-generated rationales, revealing notable differences and\nparadoxical behaviors among LLMs. Our experiments highlight the differences\nobserved across LLMs' utility, explainability, and reliability.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u53cd\u72b9\u592a\u5185\u5bb9\u68c0\u6d4b\uff0c\u8bc4\u4f30\u4e86\u516b\u79cd\u5f00\u6e90LLMs\uff0c\u901a\u8fc7\u521b\u65b0\u6027\u7684Guided-CoT\u63d0\u793a\u65b9\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u8868\u73b0\uff0c\u5e76\u63ed\u793a\u4e86\u5404\u6a21\u578b\u5728\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u4e0a\u7684\u5dee\u5f02\uff0c\u5c24\u5176Llama 3.1 70B\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u68c0\u6d4b\u4ec7\u6068\u5185\u5bb9\uff0c\u5c24\u5176\u662f\u53cd\u72b9\u592a\u5185\u5bb9\uff0c\u662f\u4e00\u9879\u6781\u5177\u6311\u6218\u6027\u4e14\u91cd\u8981\u7684\u4efb\u52a1\u3002\u81ea\u52a8\u5316\u5de5\u5177\u5982\u673a\u5668\u5b66\u4e60\u6a21\u578b\u53ef\u4ee5\u534f\u52a9\u8fd9\u4e00\u5de5\u4f5c\uff0c\u4f46\u7531\u4e8e\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\u4e0d\u65ad\u53d8\u5316\uff0c\u8fd9\u4e9b\u6a21\u578b\u9700\u8981\u6301\u7eed\u8bad\u7ec3\u3002\u672c\u6587\u65e8\u5728\u8bc4\u4f30\u5f00\u6e90\u5927\u6a21\u578b\uff08LLMs\uff09\u5728\u68c0\u6d4b\u53cd\u72b9\u5185\u5bb9\u4e0a\u7684\u80fd\u529b\uff0c\u4fc3\u8fdb\u5728\u7ebf\u73af\u5883\u6cbb\u7406\u3002", "method": "\u672c\u6587\u8bc4\u4f30\u4e86\u516b\u4e2a\u5f00\u6e90LLMs\u7528\u4e8e\u68c0\u6d4b\u53cd\u72b9\u592a\u5185\u5bb9\u7684\u80fd\u529b\uff0c\u91c7\u7528\u4e0a\u4e0b\u6587\u5b9a\u4e49\u4f5c\u4e3a\u653f\u7b56\u6307\u5bfc\u3002\u63a2\u7d22\u4e86\u591a\u79cd\u63d0\u793a\u6280\u672f\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u8fde\u9501\u5f0f\u601d\u7ef4\uff08CoT\uff09\u63d0\u793a\u2014\u2014Guided-CoT\uff0c\u901a\u8fc7\u5f15\u5bfc\u6a21\u578b\u5bf9\u653f\u7b56\u8fdb\u884c\u7406\u89e3\u3002\u6587\u7ae0\u8fd8\u5206\u6790\u4e86\u6a21\u578b\u9519\u8bef\uff0c\u5e76\u5f15\u5165\u4e86\u8861\u91cf\u8bed\u4e49\u504f\u5dee\u7684\u65b0\u6307\u6807\uff0c\u7528\u4e8e\u8003\u5bdf\u751f\u6210\u63a8\u7406\u7684\u5dee\u5f02\u3002", "result": "Guided-CoT\u80fd\u591f\u5f88\u597d\u5730\u7ed3\u5408\u653f\u7b56\u5b9a\u4e49\uff0c\u63d0\u5347\u4e86\u6240\u6709\u6a21\u578b\u7684\u8868\u73b0\uff0c\u65e0\u8bba\u6a21\u578b\u5927\u5c0f\u3001\u8bbe\u7f6e\u6216\u63a8\u7406\u80fd\u529b\u3002Llama 3.1 70B\u5728\u68c0\u6d4b\u53cd\u72b9\u5185\u5bb9\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u5fae\u8c03\u7684GPT-3.5\u3002\u5bf9\u6a21\u578b\u9519\u8bef\u7684\u5206\u6790\u548c\u8bed\u4e49\u504f\u5dee\u91cf\u5316\u63ed\u793a\u4e86\u5404\u6a21\u578b\u5728\u63a8\u7406\u80fd\u529b\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\u548c\u4e00\u4e9b\u77db\u76fe\u884c\u4e3a\u3002", "conclusion": "Guided-CoT\u80fd\u591f\u63d0\u5347\u5f00\u6e90LLMs\u5728\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u4e2d\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u5bf9\u653f\u7b56\u7406\u89e3\u7684\u4efb\u52a1\u4e2d\u3002\u4e0d\u540c\u5927\u6a21\u578b\u5728\u5b9e\u7528\u6027\u3001\u53ef\u89e3\u91ca\u6027\u53ca\u53ef\u9760\u6027\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0cLlama 3.1 70B\u5728\u6b64\u4efb\u52a1\u4e0a\u62e5\u6709\u9886\u5148\u4f18\u52bf\u3002"}}
{"id": "2509.18314", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18314", "abs": "https://arxiv.org/abs/2509.18314", "authors": ["Hieu Tran", "Zonghai Yao", "Hong Yu"], "title": "Exploiting Tree Structure for Credit Assignment in RL Training of LLMs", "comment": "15 pages", "summary": "Reinforcement learning improves LLM reasoning, yet sparse delayed reward over\nlong sequences makes token-level credit assignment the key bottleneck. We study\nthe verifiable-reward setting, where the final answer is checkable and multiple\nresponses can be drawn per prompt. Reasoning tasks in math and medical QA align\nwith this setup, where only a few decision tokens significantly impact the\noutcome. PPO offers token-level advantages with a learned value model, but it\nis complex to train both the actor and critic models simultaneously, and it is\nnot easily generalizable, as the token-level values from the critic model can\nmake training prone to overfitting. GRPO is critic-free and supports verifiable\nrewards, but spreads a single sequence-level return across tokens and ignores\nbranching. We introduce \\textbf{Prefix-to-Tree (P2T)}, a simple procedure that\nconverts a group of responses into a prefix tree and computes\n\\emph{nonparametric} prefix values \\(V(s)\\) by aggregating descendant outcomes.\nBuilt on P2T, we propose \\textbf{TEMPO} (\\emph{\\textbf{T}ree-\\textbf{E}stimated\n\\textbf{M}ean Prefix Value for \\textbf{P}olicy \\textbf{O}ptimization}), a\ncritic-free algorithm that augments the group-relative outcome signal of GRPO\nwith \\emph{branch-gated} temporal-difference corrections derived from the tree.\nAt non-branch tokens, the temporal-difference (TD) term is zero, so TEMPO\nreduces to GRPO; at branching tokens, it supplies precise token-level credit\nwithout a learned value network or extra judges/teachers. On Qwen3-1.7B/4B,\nTEMPO outperforms PPO and GRPO on in-distribution (MATH, MedQA) and\nout-of-distribution (GSM-HARD, AMC23, MedMCQA, MMLU-Medical) benchmarks, and\nreaches higher validation accuracy with roughly the same wall-clock time.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u524d\u7f00\u6811\u7684\u65b0\u578b\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5TEMPO\uff0c\u89e3\u51b3\u4e86token\u7ea7\u5956\u52b1\u5f52\u56e0\u96be\u9898\uff0c\u4e0d\u4f9d\u8d56\u4ef7\u503c\u7f51\u7edc\uff0c\u80fd\u5728\u591a\u9879\u6570\u5b66\u548c\u533b\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u5927\u5e45\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u51c6\u786e\u7387\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u80fd\u591f\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5728\u5904\u7406\u957f\u5e8f\u5217\u65f6\uff0c\u7531\u4e8e\u5956\u52b1\u7a00\u758f\u4e14\u591a\u4e3a\u5ef6\u8fdf\uff0c\u5982\u4f55\u8fdb\u884c\u7cbe\u786e\u7684token\u7ea7\u5f52\u56e0\u6210\u4e3a\u5173\u952e\u74f6\u9888\u3002\u5c24\u5176\u662f\u5728\u7b54\u6848\u53ef\u9a8c\u8bc1\u7684\u573a\u666f\uff08\u5982\u6570\u5b66\u548c\u533b\u5b66\u95ee\u7b54\uff09\uff0c\u53ea\u6709\u5c11\u6570\u51b3\u7b56token\u771f\u6b63\u5f71\u54cd\u6700\u7ec8\u7ed3\u679c\uff0c\u56e0\u6b64\u8be5\u9886\u57df\u4e9f\u9700\u66f4\u9ad8\u6548\u548c\u53ef\u63a8\u5e7f\u7684\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u65b0\u7684\u65b9\u6cd5Prefix-to-Tree\uff08P2T\uff09\uff0c\u5b83\u5c06\u591a\u4e2a\u54cd\u5e94\u7ec4\u7ec7\u4e3a\u524d\u7f00\u6811\uff0c\u901a\u8fc7\u805a\u5408\u540e\u4ee3\u7ed3\u679c\u5728\u4e0d\u4f9d\u8d56\u53c2\u6570\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u8ba1\u7b97\u524d\u7f00\u503c\u3002\u540c\u65f6\uff0c\u57fa\u4e8eP2T\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86TEMPO\u7b97\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u65e0critic\u6a21\u578b\u7684\u6539\u8fdb\u7248GRPO\u65b9\u6cd5\uff0c\u901a\u8fc7\u6811\u7ed3\u6784\u6ce8\u5165\u4e86\u5206\u652f\u63a7\u5236\u7684\u65f6\u5e8f\u5dee\u5206\u6821\u6b63\u9879\uff0c\u5728\u5206\u652ftoken\u5904\u53ef\u4ee5\u5b9e\u73b0\u7cbe\u786e\u7684token\u7ea7\u5f52\u56e0\uff0c\u65e0\u9700\u4ef7\u503c\u7f51\u7edc\u6216\u989d\u5916\u7684\u76d1\u7763\u4fe1\u53f7\u3002", "result": "\u5728Qwen3-1.7B\u548cQwen3-4B\u6a21\u578b\u4e0a\uff0cTEMPO\u7b97\u6cd5\u5728MATH\u548cMedQA\u7b49\u539f\u5206\u5e03\u4efb\u52a1\u4ee5\u53caGSM-HARD\u3001AMC23\u3001MedMCQA\u3001MMLU-Medical\u7b49\u8de8\u5206\u5e03\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u7684PPO\u548cGRPO\u65b9\u6cd5\u3002\u540c\u65f6\uff0cTEMPO\u80fd\u5728\u57fa\u672c\u76f8\u540c\u7684\u8bad\u7ec3\u65f6\u95f4\u5185\u83b7\u5f97\u66f4\u9ad8\u7684\u9a8c\u8bc1\u51c6\u786e\u7387\u3002", "conclusion": "TEMPO\u662f\u4e00\u79cd\u57fa\u4e8e\u524d\u7f00\u6811\u3001\u65e0\u9700critic\u6a21\u578b\u3001\u652f\u6301\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u65b9\u6cd5\uff0c\u53ef\u6709\u6548\u5b9e\u73b0token\u7ea7\u5f52\u56e0\uff0c\u63d0\u5347LLM\u5728\u63a8\u7406\u548c\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5bf9\u590d\u6742\u51b3\u7b56\u70b9\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2509.18316", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18316", "abs": "https://arxiv.org/abs/2509.18316", "authors": ["Saksham Khatwani", "He Cheng", "Majid Afshar", "Dmitriy Dligach", "Yanjun Gao"], "title": "Brittleness and Promise: Knowledge Graph Based Reward Modeling for Diagnostic Reasoning", "comment": null, "summary": "Large language models (LLMs) show promise for diagnostic reasoning but often\nlack reliable, knowledge grounded inference. Knowledge graphs (KGs), such as\nthe Unified Medical Language System (UMLS), offer structured biomedical\nknowledge that can support trustworthy reasoning. Prior approaches typically\nintegrate KGs via retrieval augmented generation or fine tuning, inserting KG\ncontent into prompts rather than enabling structured reasoning. We explore an\nalternative paradigm: treating the LLM as a reward model of KG reasoning paths,\nwhere the model learns to judge whether a candidate path leads to correct\ndiagnosis for a given patient input. This approach is inspired by recent work\nthat leverages reward training to enhance model reasoning abilities, and\ngrounded in computational theory, which suggests that verifying a solution is\noften easier than generating one from scratch. It also parallels physicians'\ndiagnostic assessment, where they judge which sequences of findings and\nintermediate conditions most plausibly support a diagnosis. We first\nsystematically evaluate five task formulation for knowledge path judging and\neight training paradigm. Second, we test whether the path judging abilities\ngeneralize to downstream diagnostic tasks, including diagnosis summarization\nand medical question answering. Experiments with three open source\ninstruct-tuned LLMs reveal both promise and brittleness: while specific reward\noptimization and distillation lead to strong path-judging performance, the\ntransferability to downstream tasks remain weak. Our finding provides the first\nsystematic assessment of \"reward model style\" reasoning over clinical KGs,\noffering insights into how structured, reward-based supervision influences\ndiagnostic reasoning in GenAI systems for healthcare.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u8def\u5f84\u7684\u5956\u52b1\u6a21\u578b\uff0c\u8bc4\u4f30\u5176\u63d0\u5347\u533b\u5b66\u63a8\u7406\u53ef\u9760\u6027\u7684\u6f5c\u529b\u3002\u7cfb\u7edf\u5b9e\u9a8c\u663e\u793a\uff0c\u867d\u7136\u80fd\u63d0\u5347\u8def\u5f84\u8bc4\u5224\u80fd\u529b\uff0c\u4f46\u5728\u4e0b\u6e38\u8bca\u65ad\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u548c\u8fc1\u79fb\u8868\u73b0\u4ecd\u6709\u9650\uff0c\u63ed\u793a\u4e86\u7ed3\u6784\u5316\u5956\u52b1\u76d1\u7763\u5bf9\u533b\u5b66GenAI\u7684\u6311\u6218\u548c\u673a\u9047\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b (LLMs) \u5728\u8bca\u65ad\u63a8\u7406\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u53ef\u9760\u6027\u548c\u77e5\u8bc6\u63a8\u7406\u80fd\u529b\u4e0a\u4ecd\u7136\u5b58\u5728\u4e0d\u8db3\u3002\u77e5\u8bc6\u56fe\u8c31 (KGs) \u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u7684\u533b\u5b66\u77e5\u8bc6\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u63a8\u7406\u7684\u53ef\u4fe1\u5ea6\u3002\u4ee5\u5f80\u7684\u65b9\u6cd5\u591a\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6216\u5fae\u8c03\uff0c\u5c06\u77e5\u8bc6\u56fe\u8c31\u5185\u5bb9\u76f4\u63a5\u5d4c\u5165\u63d0\u793a\u8bcd\uff0c\u800c\u672a\u80fd\u5145\u5206\u5229\u7528\u5176\u8fdb\u884c\u7ed3\u6784\u5316\u63a8\u7406\u3002\u56e0\u6b64\uff0c\u672c\u6587\u63d0\u51fa\u63a2\u7d22\u4e00\u79cd\u65b0\u7684\u8303\u5f0f\uff1a\u5c06LLM\u4f5c\u4e3aKG\u63a8\u7406\u8def\u5f84\u7684\u5956\u52b1\u6a21\u578b\uff0c\u5b66\u4e60\u5224\u65ad\u67d0\u4e00\u5019\u9009\u8def\u5f84\u662f\u5426\u80fd\u5e2e\u52a9\u505a\u51fa\u6b63\u786e\u8bca\u65ad\u3002", "method": "\u4f5c\u8005\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u89c6\u4f5c\u8bc4\u5224\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u8def\u5f84\u7684\u5956\u52b1\u6a21\u578b\uff0c\u8bc4\u4f30\u4e0d\u540c\u8def\u5f84\u5bf9\u4e8e\u75c5\u4eba\u8f93\u5165\u80fd\u5426\u5bfc\u81f4\u6b63\u786e\u8bca\u65ad\u3002\u5177\u4f53\u5206\u4e3a\u4e24\u6b65\uff1a\u9996\u5148\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e94\u79cd\u77e5\u8bc6\u8def\u5f84\u5224\u65ad\u4efb\u52a1\u548c\u516b\u79cd\u8bad\u7ec3\u8303\u5f0f\uff1b\u5176\u6b21\u8003\u5bdf\u8def\u5f84\u5224\u65ad\u80fd\u529b\u80fd\u5426\u8fc1\u79fb\u5230\u5b9e\u9645\u8bca\u65ad\u4efb\u52a1\uff0c\u6bd4\u5982\u8bca\u65ad\u603b\u7ed3\u548c\u533b\u5b66\u95ee\u7b54\u3002\u5b9e\u9a8c\u57fa\u4e8e\u4e09\u4e2a\u5f00\u6e90\u3001instruct-tuned\u7684LLMs\u8fdb\u884c\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u7279\u5b9a\u7684\u5956\u52b1\u4f18\u5316\u548c\u84b8\u998f\u6280\u672f\u80fd\u591f\u663e\u8457\u63d0\u5347\u8def\u5f84\u5224\u65ad\u6027\u80fd\uff0c\u4f46\u8fd9\u79cd\u80fd\u529b\u8fc1\u79fb\u5230\u4e0b\u6e38\u8bca\u65ad\u4efb\u52a1\u7684\u8868\u73b0\u8f83\u5f31\uff0c\u6a21\u578b\u5728\u6cdb\u5316\u80fd\u529b\u4e0a\u4ecd\u6709\u9650\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u6027\u9a8c\u8bc1\u4e86\u201c\u5956\u52b1\u6a21\u578b\u5f0f\u201d\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u5728\u4e34\u5e8a\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\uff0c\u663e\u793a\u5956\u52b1\u76d1\u7763\u80fd\u591f\u63d0\u5347\u7ed3\u6784\u5316\u8bca\u65ad\u63a8\u7406\uff0c\u4f46\u5bf9\u4e8e\u5b9e\u9645\u8bca\u65ad\u4efb\u52a1\u7684\u76f4\u63a5\u8fc1\u79fb\u4ecd\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2509.18344", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18344", "abs": "https://arxiv.org/abs/2509.18344", "authors": ["Pei-Shuo Wang", "Jian-Jia Chen", "Chun-Che Yang", "Chi-Chih Chang", "Ning-Chi Huang", "Mohamed S. Abdelfattah", "Kai-Chiang Wu"], "title": "Speculate Deep and Accurate: Lossless and Training-Free Acceleration for Offloaded LLMs via Substitute Speculative Decoding", "comment": "Accepted by NeurIPS 2025", "summary": "The immense model sizes of large language models (LLMs) challenge deployment\non memory-limited consumer GPUs. Although model compression and parameter\noffloading are common strategies to address memory limitations, compression can\ndegrade quality, and offloading maintains quality but suffers from slow\ninference. Speculative decoding presents a promising avenue to accelerate\nparameter offloading, utilizing a fast draft model to propose multiple draft\ntokens, which are then verified by the target LLM in parallel with a single\nforward pass. This method reduces the time-consuming data transfers in forward\npasses that involve offloaded weight transfers. Existing methods often rely on\npretrained weights of the same family, but require additional training to align\nwith custom-trained models. Moreover, approaches that involve draft model\ntraining usually yield only modest speedups. This limitation arises from\ninsufficient alignment with the target model, preventing higher token\nacceptance lengths. To address these challenges and achieve greater speedups,\nwe propose SubSpec, a plug-and-play method to accelerate parameter offloading\nthat is lossless and training-free. SubSpec constructs a highly aligned draft\nmodel by generating low-bit quantized substitute layers from offloaded target\nLLM portions. Additionally, our method shares the remaining GPU-resident layers\nand the KV-Cache, further reducing memory overhead and enhance alignment.\nSubSpec achieves a high average acceptance length, delivering 9.1x speedup for\nQwen2.5 7B on MT-Bench (8GB VRAM limit) and an average of 12.5x speedup for\nQwen2.5 32B on popular generation benchmarks (24GB VRAM limit).", "AI": {"tldr": "\u8bba\u6587\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u56e0\u663e\u5b58\u53d7\u9650\u96be\u90e8\u7f72\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65e0\u9700\u8bad\u7ec3\u7684SubSpec\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f4e\u6bd4\u7279\u91cf\u5316\u66ff\u6362\u5c42\u548c\u8d44\u6e90\u5171\u4eab\u5b9e\u73b0\u9ad8\u5ea6\u5bf9\u9f50\u7684\u8349\u7a3f\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u52a0\u901f\u6548\u679c\uff08\u6700\u9ad8\u8fbe12.5\u500d\uff09\uff0c\u4e14\u4e0d\u5f71\u54cd\u6a21\u578b\u8868\u73b0\u3002", "motivation": "\u7531\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u53c2\u6570\u89c4\u6a21\u5de8\u5927\uff0c\u6d88\u8d39\u8005\u7ea7\u522b\u7684GPU\u5728\u90e8\u7f72\u65f6\u9762\u4e34\u5185\u5b58\u9650\u5236\u3002\u4f20\u7edf\u7684\u6a21\u578b\u538b\u7f29\u4f1a\u5f71\u54cd\u6a21\u578b\u8d28\u91cf\uff0c\u53c2\u6570\u5378\u8f7d\u867d\u7136\u4fdd\u6301\u8d28\u91cf\u4f46\u63a8\u7406\u901f\u5ea6\u6162\u3002\u73b0\u6709\u7684\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\u867d\u80fd\u4e00\u5b9a\u7a0b\u5ea6\u52a0\u901f\uff0c\u4f46\u5bf9\u76ee\u6807\u6a21\u578b\u7684\u9002\u914d\u4e0d\u5145\u5206\uff0c\u901f\u5ea6\u63d0\u5347\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e86SubSpec\u65b9\u6cd5\uff0c\u5c5e\u4e8e\u5373\u63d2\u5373\u7528\u7684\u52a0\u901f\u53c2\u6570\u5378\u8f7d\u65b9\u6848\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u4efb\u4f55\u8bad\u7ec3\uff0c\u901a\u8fc7\u4ece\u5378\u8f7d\u90e8\u5206\u7684\u76ee\u6807LLM\u751f\u6210\u4f4e\u6bd4\u7279\u91cf\u5316\u7684\u66ff\u4ee3\u5c42\uff0c\u6784\u5efa\u9ad8\u5ea6\u5bf9\u9f50\u7684\u8349\u7a3f\u6a21\u578b\u3002\u540c\u65f6\u5171\u4eabGPU\u9a7b\u7559\u5c42\u4e0eKV-Cache\u4ee5\u51cf\u5c11\u5185\u5b58\u5360\u7528\u5e76\u63d0\u5347\u6a21\u578b\u5bf9\u9f50\u5ea6\u3002", "result": "SubSpec\u5728Qwen2.5 7B\u6a21\u578b\u4e0a\uff088GB\u663e\u5b58\u9650\u5236\uff09\u7684MT-Bench\u6d4b\u8bd5\u8fbe\u52309.1\u500d\u52a0\u901f\uff0c\u5728Qwen2.5 32B\u6a21\u578b\u4e0a\uff0824GB\u663e\u5b58\u9650\u5236\uff09\u7684\u4e3b\u6d41\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u5e73\u5747\u8fbe12.5\u500d\u52a0\u901f\u3002", "conclusion": "SubSpec\u65b9\u6cd5\u80fd\u591f\u65e0\u635f\u3001\u514d\u8bad\u7ec3\u5730\u5927\u5e45\u63d0\u5347\u53c2\u6570\u5378\u8f7d\u573a\u666f\u4e0bLLM\u63a8\u7406\u901f\u5ea6\uff0c\u663e\u8457\u51cf\u5c11\u5185\u5b58\u5360\u7528\u4e14\u65e0\u9700\u727a\u7272\u6a21\u578b\u8d28\u91cf\u3002"}}
{"id": "2509.18360", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18360", "abs": "https://arxiv.org/abs/2509.18360", "authors": ["Chutong Meng", "Philipp Koehn"], "title": "Speech Vecalign: an Embedding-based Method for Aligning Parallel Speech Documents", "comment": "Accepted by EMNLP 2025 (main)", "summary": "We present Speech Vecalign, a parallel speech document alignment method that\nmonotonically aligns speech segment embeddings and does not depend on text\ntranscriptions. Compared to the baseline method Global Mining, a variant of\nspeech mining, Speech Vecalign produces longer speech-to-speech alignments. It\nalso demonstrates greater robustness than Local Mining, another speech mining\nvariant, as it produces less noise. We applied Speech Vecalign to 3,000 hours\nof unlabeled parallel English-German (En-De) speech documents from VoxPopuli,\nyielding about 1,000 hours of high-quality alignments. We then trained En-De\nspeech-to-speech translation models on the aligned data. Speech Vecalign\nimproves the En-to-De and De-to-En performance over Global Mining by 0.37 and\n0.18 ASR-BLEU, respectively. Moreover, our models match or outperform\nSpeechMatrix model performance, despite using 8 times fewer raw speech\ndocuments.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u6587\u672c\u8f6c\u5f55\u3001\u5bf9\u9f50\u66f4\u957f\u3001\u566a\u97f3\u66f4\u4f4e\u7684\u8bed\u97f3\u6587\u6863\u5bf9\u9f50\u65b9\u6cd5Speech Vecalign\uff0c\u5728\u82f1\u5fb7\u8bed\u97f3\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u5e76\u5728\u4f4e\u8d44\u6e90\u6761\u4ef6\u4e0b\u5b9e\u73b0\u9ad8\u8d28\u91cf\u6548\u679c\uff0c\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8bed\u97f3\u6316\u6398\u65b9\u6cd5\uff08\u5982Global Mining\u548cLocal Mining\uff09\u5728\u8bed\u97f3\u6587\u6863\u5bf9\u9f50\u65f6\u5b58\u5728\u5bf9\u9f50\u957f\u5ea6\u77ed\u3001\u566a\u97f3\u5927\u6216\u4f9d\u8d56\u6587\u672c\u8f6c\u5f55\u7684\u95ee\u9898\u3002\u4f5c\u8005\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u4e0d\u8db3\uff0c\u4ee5\u4fbf\u4e8e\u66f4\u9ad8\u6548\u5730\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u8bed\u97f3\u5e73\u884c\u6570\u636e\u7528\u4e8e\u7ffb\u8bd1\u6a21\u578b\u8bad\u7ec3\u3002", "method": "\u63d0\u51faSpeech Vecalign\uff0c\u901a\u8fc7\u5bf9\u8bed\u97f3\u7247\u6bb5\u5d4c\u5165\u8fdb\u884c\u5355\u8c03\u5bf9\u9f50\uff0c\u65e0\u9700\u6587\u672c\u8f6c\u5f55\uff0c\u63d0\u5347\u4e86\u5bf9\u9f50\u957f\u5ea6\u548c\u566a\u97f3\u63a7\u5236\u80fd\u529b\uff1b\u57283,000\u5c0f\u65f6\u7684\u82f1\u5fb7\u8bed\u97f3\u6570\u636e\u4e0a\u83b7\u5f971,000\u5c0f\u65f6\u9ad8\u8d28\u91cf\u5bf9\u9f50\u6837\u672c\uff0c\u5e76\u7528\u4e8e\u8bad\u7ec3\u8bed\u97f3\u5230\u8bed\u97f3\u7ffb\u8bd1\u6a21\u578b\u3002", "result": "Speech Vecalign\u6bd4Global Mining\u65b9\u6cd5\u63d0\u9ad8\u4e86\u82f1\u5230\u5fb7\u548c\u5fb7\u5230\u82f1\u7684ASR-BLEU\u5206\u6570\uff08\u5206\u522b\u63d0\u53470.37\u548c0.18\uff09\uff0c\u4e14\u6a21\u578b\u6027\u80fd\u5339\u654c\u751a\u81f3\u8d85\u8fc7SpeechMatrix\uff0c\u6240\u9700\u539f\u59cb\u8bed\u97f3\u6587\u6863\u6570\u91cf\u51cf\u5c118\u500d\u3002", "conclusion": "Speech Vecalign\u65b9\u6cd5\u7528\u4e8e\u5e76\u884c\u8bed\u97f3\u6587\u6863\u5bf9\u9f50\uff0c\u80fd\u591f\u63d0\u5347\u5bf9\u9f50\u957f\u5ea6\u548c\u8d28\u91cf\uff0c\u5e76\u5728\u4f4e\u8d44\u6e90\u6761\u4ef6\u4e0b\u53d6\u5f97\u5353\u8d8a\u7684\u8bed\u97f3\u5230\u8bed\u97f3\u7ffb\u8bd1\u6548\u679c\u3002"}}
{"id": "2509.18377", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18377", "abs": "https://arxiv.org/abs/2509.18377", "authors": ["Xinlu He", "Yiwen Guan", "Badrivishal Paurana", "Zilin Dai", "Jacob Whitehill"], "title": "Interactive Real-Time Speaker Diarization Correction with Human Feedback", "comment": null, "summary": "Most automatic speech processing systems operate in \"open loop\" mode without\nuser feedback about who said what; yet, human-in-the-loop workflows can\npotentially enable higher accuracy. We propose an LLM-assisted speaker\ndiarization correction system that lets users fix speaker attribution errors in\nreal time. The pipeline performs streaming ASR and diarization, uses an LLM to\ndeliver concise summaries to the users, and accepts brief verbal feedback that\nis immediately incorporated without disrupting interactions. Moreover, we\ndevelop techniques to make the workflow more effective: First, a\nsplit-when-merged (SWM) technique detects and splits multi-speaker segments\nthat the ASR erroneously attributes to just a single speaker. Second, online\nspeaker enrollments are collected based on users' diarization corrections, thus\nhelping to prevent speaker diarization errors from occurring in the future.\nLLM-driven simulations on the AMI test set indicate that our system\nsubstantially reduces DER by 9.92% and speaker confusion error by 44.23%. We\nfurther analyze correction efficacy under different settings, including summary\nvs full transcript display, the number of online enrollments limitation, and\ncorrection frequency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u7528\u6237\u53cd\u9988\u7684\u8bf4\u8bdd\u4eba\u5f52\u5c5e\u7ea0\u9519\u7cfb\u7edf\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\uff0c\u80fd\u5b9e\u65f6\u63d0\u5347\u51c6\u786e\u6027\u5e76\u5927\u5e45\u51cf\u5c11\u9519\u8bef\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u8bed\u97f3\u5904\u7406\u7cfb\u7edf\u901a\u5e38\u6ca1\u6709\u7528\u6237\u53cd\u9988\uff0c\u56e0\u800c\u5728\u8bf4\u8bdd\u4eba\u5f52\u5c5e\u5b58\u5728\u9519\u8bef\u65f6\u96be\u4ee5\u7ea0\u6b63\u3002\u5f15\u5165\u7528\u6237\uff0c\u7279\u522b\u662f\u5728\u5faa\u73af\u4e2d\u5b9e\u65f6\u4fee\u6b63\u8bf4\u8bdd\u4eba\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u63d0\u5347\u51c6\u786e\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8f85\u52a9\u7684\u8bf4\u8bdd\u4eba\u5206\u79bb\u7ea0\u9519\u7cfb\u7edf\u3002\u7cfb\u7edf\u6d41\u7a0b\u5305\u62ec\u6d41\u5f0fASR\u548c\u8bf4\u8bdd\u4eba\u5206\u79bb\u3001\u5229\u7528LLM\u5411\u7528\u6237\u63a8\u9001\u6458\u8981\u4fe1\u606f\u3001\u6536\u96c6\u5e76\u5feb\u901f\u5e94\u7528\u7528\u6237\u8bed\u97f3\u53cd\u9988\u3002\u540c\u65f6\uff0c\u8bbe\u8ba1\u4e86split-when-merged\uff08SWM\uff09\u6280\u672f\u5206\u79bb\u7531ASR\u9519\u8bef\u5f52\u5c5e\u7684\u591a\u8bf4\u8bdd\u4eba\u7247\u6bb5\uff0c\u5e76\u5728\u7528\u6237\u7ea0\u9519\u57fa\u7840\u4e0a\u5728\u7ebf\u91c7\u96c6\u8bf4\u8bdd\u4eba\u4fe1\u606f\u4f9b\u540e\u7eed\u4f7f\u7528\u3002", "result": "\u5728AMI\u6d4b\u8bd5\u96c6\u4e0a\u7684LLM\u9a71\u52a8\u4eff\u771f\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5c06\u8bf4\u8bdd\u4eba\u9519\u8bef\u7387\uff08DER\uff09\u964d\u4f4e\u4e869.92%\uff0c\u8bf4\u8bdd\u4eba\u6df7\u6dc6\u9519\u8bef\u4e0b\u964d\u4e8644.23%\u3002\u8fd8\u5206\u6790\u4e86\u6458\u8981\u5c55\u793a\u3001\u542c\u5199\u5168\u6587\u3001\u5728\u7ebf\u6ce8\u518c\u6570\u91cf\u4e0e\u7ea0\u9519\u9891\u7387\u7b49\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u7684\u6548\u679c\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165LLM\u548c\u7528\u6237\u5728\u73af\u7684\u8bf4\u8bdd\u4eba\u7ea0\u9519\u7cfb\u7edf\uff0c\u80fd\u591f\u5b9e\u65f6\u6539\u8fdb\u8bf4\u8bdd\u4eba\u7684\u5f52\u5c5e\u51c6\u786e\u6027\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u7cfb\u7edf\u9519\u8bef\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.18395", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18395", "abs": "https://arxiv.org/abs/2509.18395", "authors": ["Minki Hong", "Jangho Choi", "Jihie Kim"], "title": "NormGenesis: Multicultural Dialogue Generation via Exemplar-Guided Social Norm Modeling and Violation Recovery", "comment": "39 pages, 17 figures, EMNLP 2025 Main Conference", "summary": "Social norms govern culturally appropriate behavior in communication,\nenabling dialogue systems to produce responses that are not only coherent but\nalso socially acceptable. We present NormGenesis, a multicultural framework for\ngenerating and annotating socially grounded dialogues across English, Chinese,\nand Korean. To model the dynamics of social interaction beyond static norm\nclassification, we propose a novel dialogue type, Violation-to-Resolution\n(V2R), which models the progression of conversations following norm violations\nthrough recognition and socially appropriate repair. To improve pragmatic\nconsistency in underrepresented languages, we implement an exemplar-based\niterative refinement early in the dialogue synthesis process. This design\nintroduces alignment with linguistic, emotional, and sociocultural expectations\nbefore full dialogue generation begins. Using this framework, we construct a\ndataset of 10,800 multi-turn dialogues annotated at the turn level for norm\nadherence, speaker intent, and emotional response. Human and LLM-based\nevaluations demonstrate that NormGenesis significantly outperforms existing\ndatasets in refinement quality, dialogue naturalness, and generalization\nperformance. We show that models trained on our V2R-augmented data exhibit\nimproved pragmatic competence in ethically sensitive contexts. Our work\nestablishes a new benchmark for culturally adaptive dialogue modeling and\nprovides a scalable methodology for norm-aware generation across linguistically\nand culturally diverse languages.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faNormGenesis\uff0c\u4e00\u4e2a\u8de8\u82f1\u4e2d\u97e9\u4e09\u8bed\u3001\u5173\u6ce8\u793e\u4f1a\u89c4\u8303\u7684\u5bf9\u8bdd\u751f\u6210\u4e0e\u6807\u6ce8\u6846\u67b6\uff0c\u521b\u9020\u6027\u5f15\u5165\u8fdd\u89c4-\u4fee\u590d\uff08V2R\uff09\u5bf9\u8bdd\u7c7b\u578b\uff0c\u4ee5\u53ca\u8303\u4f8b\u7ec6\u5316\u6d41\u7a0b\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6570\u636e\u96c6\u5728\u5bf9\u8bdd\u81ea\u7136\u5ea6\u4e0e\u89c4\u8303\u9002\u5e94\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\uff0c\u5e76\u63a8\u52a8\u591a\u6587\u5316\u73af\u5883\u4e0b\u7684\u5bf9\u8bdd\u7cfb\u7edf\u53d1\u5c55\u3002", "motivation": "\u5f53\u524d\u7684\u5bf9\u8bdd\u7cfb\u7edf\u867d\u7136\u8ffd\u6c42\u5185\u5bb9\u8fde\u8d2f\u6027\uff0c\u4f46\u5f80\u5f80\u7f3a\u4e4f\u5bf9\u4e0d\u540c\u6587\u5316\u80cc\u666f\u4e0b\u793e\u4f1a\u89c4\u8303\u7684\u628a\u63e1\uff0c\u5bb9\u6613\u4ea7\u751f\u4e0d\u7b26\u5408\u793e\u4ea4\u4e60\u60ef\u6216\u4e0d\u9002\u5f53\u7684\u56de\u590d\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u591a\u6587\u5316\u3001\u591a\u8bed\u79cd\u3001\u5173\u6ce8\u793e\u4f1a\u89c4\u8303\u7684\u5bf9\u8bdd\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86NormGenesis\uff0c\u4e00\u4e2a\u6db5\u76d6\u82f1\u8bed\u3001\u4e2d\u6587\u3001\u97e9\u8bed\u7684\u591a\u6587\u5316\u5bf9\u8bdd\u6846\u67b6\uff0c\u80fd\u591f\u751f\u6210\u5e76\u6807\u6ce8\u793e\u4f1a\u89c4\u8303\u76f8\u5173\u7684\u5bf9\u8bdd\u3002\u5f15\u5165\u201c\u8fdd\u89c4-\u4fee\u590d\uff08V2R\uff09\u201d\u5bf9\u8bdd\u7c7b\u578b\uff0c\u6a21\u62df\u89c4\u8303\u8fdd\u89c4\u3001\u8bc6\u522b\u548c\u4fee\u590d\u7684\u5bf9\u8bdd\u8fdb\u5c55\uff1b\u5e76\u5728\u6570\u636e\u5408\u6210\u65e9\u671f\u91c7\u7528\u57fa\u4e8e\u8303\u4f8b\u7684\u8fed\u4ee3\u7ec6\u5316\uff0c\u63d0\u5347\u8bed\u8a00\u548c\u6587\u5316\u4e00\u81f4\u6027\u3002\u6700\u7ec8\u6784\u5efa\u4e8610800\u4e2a\u591a\u8f6e\u5bf9\u8bdd\u7684\u6570\u636e\u96c6\uff0c\u5bf9\u6bcf\u4e00\u8f6e\u6807\u6ce8\u89c4\u8303\u9075\u5b88\u60c5\u51b5\u3001\u8bf4\u8bdd\u610f\u56fe\u548c\u60c5\u611f\u53cd\u5e94\u3002", "result": "\u901a\u8fc7\u4eba\u5de5\u548c\u5927\u6a21\u578b\u8bc4\u6d4b\uff0cNormGenesis\u5728\u5bf9\u8bdd\u7ec6\u817b\u5ea6\u3001\u81ea\u7136\u5ea6\u548c\u6cdb\u5316\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6570\u636e\u96c6\uff1b\u57fa\u4e8eV2R\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u9053\u5fb7\u654f\u611f\u73af\u5883\u4e0b\u5177\u6709\u66f4\u5f3a\u7684\u8bed\u7528\u80fd\u529b\u3002", "conclusion": "NormGenesis\u4e3a\u6587\u5316\u9002\u5e94\u6027\u5bf9\u8bdd\u5efa\u6a21\u6811\u7acb\u4e86\u65b0\u7684\u57fa\u51c6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u652f\u6301\u5728\u591a\u8bed\u79cd\u3001\u591a\u6587\u5316\u573a\u666f\u4e0b\u7684\u793e\u4f1a\u89c4\u8303\u611f\u77e5\u5f0f\u5bf9\u8bdd\u751f\u6210\u3002"}}
{"id": "2509.18401", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18401", "abs": "https://arxiv.org/abs/2509.18401", "authors": ["Armin Tourajmehr", "Mohammad Reza Modarres", "Yadollah Yaghoobzadeh"], "title": "Evaluating the Creativity of LLMs in Persian Literary Text Generation", "comment": null, "summary": "Large language models (LLMs) have demonstrated notable creative abilities in\ngenerating literary texts, including poetry and short stories. However, prior\nresearch has primarily centered on English, with limited exploration of\nnon-English literary traditions and without standardized methods for assessing\ncreativity. In this paper, we evaluate the capacity of LLMs to generate Persian\nliterary text enriched with culturally relevant expressions. We build a dataset\nof user-generated Persian literary spanning 20 diverse topics and assess model\noutputs along four creativity dimensions-originality, fluency, flexibility, and\nelaboration-by adapting the Torrance Tests of Creative Thinking. To reduce\nevaluation costs, we adopt an LLM as a judge for automated scoring and validate\nits reliability against human judgments using intraclass correlation\ncoefficients, observing strong agreement. In addition, we analyze the models'\nability to understand and employ four core literary devices: simile, metaphor,\nhyperbole, and antithesis. Our results highlight both the strengths and\nlimitations of LLMs in Persian literary text generation, underscoring the need\nfor further refinement.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6ce2\u65af\u8bed\u6587\u5b66\u6587\u672c\u751f\u6210\u53ca\u521b\u9020\u529b\u7ef4\u5ea6\u4e0a\u7684\u8868\u73b0\uff0c\u91c7\u7528\u6807\u51c6\u5316\u8bc4\u5206\u4f53\u7cfb\u548c\u81ea\u52a8\u5316\u8bc4\u5ba1\u65b9\u5f0f\uff0c\u53d1\u73b0\u6a21\u578b\u867d\u6709\u663e\u8457\u80fd\u529b\u5374\u4e5f\u5b58\u5728\u4e0d\u8db3\uff0c\u4e9f\u9700\u9488\u5bf9\u975e\u82f1\u8bed\u6587\u5b66\u8fdb\u4e00\u6b65\u4f18\u5316\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u751f\u6210\u6587\u5b66\u6587\u672c\u65b9\u9762\u5c55\u73b0\u4e86\u4e0d\u9519\u7684\u521b\u9020\u529b\uff0c\u5c24\u5176\u662f\u8bd7\u6b4c\u548c\u77ed\u7bc7\u6545\u4e8b\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u805a\u7126\u4e8e\u82f1\u6587\uff0c\u7f3a\u5c11\u5bf9\u975e\u82f1\u8bed\u6587\u5b66\u4f20\u7edf\u7684\u63a2\u8ba8\uff0c\u4e5f\u6ca1\u6709\u6807\u51c6\u5316\u7684\u521b\u9020\u529b\u8bc4\u4f30\u65b9\u6cd5\u3002\u56e0\u6b64\uff0c\u8be5\u8bba\u6587\u65e8\u5728\u8bc4\u4f30LLM\u5728\u6ce2\u65af\u8bed\u6587\u5b66\u521b\u4f5c\uff08\u5c24\u5176\u662f\u5bcc\u542b\u6587\u5316\u76f8\u5173\u8868\u8fbe\u7684\u6587\u672c\u751f\u6210\uff09\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u8bba\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u8986\u76d620\u4e2a\u4e0d\u540c\u8bdd\u9898\u7684\u6ce2\u65af\u8bed\u6587\u5b66\u7528\u6237\u751f\u6210\u6587\u672c\u6570\u636e\u96c6\uff0c\u5e76\u91c7\u7528Torrance\u521b\u9020\u6027\u601d\u7ef4\u6d4b\u9a8c\uff08\u9002\u5f53\u4fee\u6539\u540e\uff09\u4ece\u539f\u521b\u6027\u3001\u6d41\u7545\u6027\u3001\u7075\u6d3b\u6027\u548c\u7ec6\u81f4\u6027\u56db\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u6a21\u578b\u8f93\u51fa\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u964d\u4f4e\u8bc4\u4f30\u6210\u672c\uff0c\u8bba\u6587\u4f7f\u7528LLM\u4f5c\u4e3a\u81ea\u52a8\u8bc4\u5206\u7684\u8bc4\u5ba1\u8005\uff0c\u5e76\u901a\u8fc7\u7ea7\u95f4\u76f8\u5173\u7cfb\u6570\u65b9\u6cd5\u4e0e\u4eba\u5de5\u8bc4\u4ef7\u8fdb\u884c\u4e00\u81f4\u6027\u9a8c\u8bc1\u3002\u8bba\u6587\u8fd8\u5206\u6790\u4e86\u6a21\u578b\u7406\u89e3\u548c\u8fd0\u7528\u56db\u79cd\u4e3b\u8981\u6587\u5b66\u4fee\u8f9e\u624b\u6cd5\uff08\u660e\u55bb\u3001\u9690\u55bb\u3001\u5938\u5f20\u3001\u5bf9\u7acb\uff09\u7684\u80fd\u529b\u3002", "result": "\u6a21\u578b\u5728\u6ce2\u65af\u8bed\u6587\u5b66\u6587\u672c\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u4e00\u5b9a\u7684\u4f18\u52bf\uff0c\u5728\u521b\u9020\u529b\u56db\u4e2a\u7ef4\u5ea6\u7684\u6d4b\u8bc4\u4e0e\u4eba\u7c7b\u8bc4\u5ba1\u6709\u8f83\u9ad8\u4e00\u81f4\u6027\uff0c\u540c\u65f6\u5728\u4fee\u8f9e\u624b\u6cd5\u7684\u8fd0\u7528\u4e0a\u6709\u6240\u4f53\u73b0\u3002\u4f46\u4e5f\u63ed\u793a\u4e86\u6a21\u578b\u7684\u4e0d\u8db3\uff0c\u5f3a\u8c03\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u9002\u5e94\u975e\u82f1\u8bed\u6587\u5b66\u521b\u4f5c\u7684\u7279\u6b8a\u6027\u3002", "conclusion": "LLM\u5728\u6ce2\u65af\u8bed\u6587\u5b66\u6587\u672c\u751f\u6210\u548c\u521b\u9020\u529b\u8868\u73b0\u65b9\u9762\u6709\u4eae\u70b9\uff0c\u4f46\u73b0\u9636\u6bb5\u4ecd\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8fdb\u4e00\u6b65\u63d0\u5347\u4ee5\u66f4\u597d\u652f\u6301\u4e0d\u540c\u6587\u5316\u8bed\u5883\u4e0b\u7684\u6587\u5b66\u521b\u4f5c\u3002"}}
{"id": "2509.18439", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18439", "abs": "https://arxiv.org/abs/2509.18439", "authors": ["Oscar J. Ponce-Ponte", "David Toro-Tobon", "Luis F. Figueroa", "Michael Gionfriddo", "Megan Branda", "Victor M. Montori", "Saturnino Luz", "Juan P. Brito"], "title": "Developing an AI framework to automatically detect shared decision-making in patient-doctor conversations", "comment": "53 pages, 1 figure, 4 tables, 5 supplementary figures, 13\n  supplementary tables", "summary": "Shared decision-making (SDM) is necessary to achieve patient-centred care.\nCurrently no methodology exists to automatically measure SDM at scale. This\nstudy aimed to develop an automated approach to measure SDM by using language\nmodelling and the conversational alignment (CA) score. A total of 157\nvideo-recorded patient-doctor conversations from a randomized multi-centre\ntrial evaluating SDM decision aids for anticoagulation in atrial fibrillations\nwere transcribed and segmented into 42,559 sentences. Context-response pairs\nand negative sampling were employed to train deep learning (DL) models and\nfine-tuned BERT models via the next sentence prediction (NSP) task. Each\ntop-performing model was used to calculate four types of CA scores. A\nrandom-effects analysis by clinician, adjusting for age, sex, race, and trial\narm, assessed the association between CA scores and SDM outcomes: the\nDecisional Conflict Scale (DCS) and the Observing Patient Involvement in\nDecision-Making 12 (OPTION12) scores. p-values were corrected for multiple\ncomparisons with the Benjamini-Hochberg method. Among 157 patients (34% female,\nmean age 70 SD 10.8), clinicians on average spoke more words than patients\n(1911 vs 773). The DL model without the stylebook strategy achieved a recall@1\nof 0.227, while the fine-tuned BERTbase (110M) achieved the highest recall@1\nwith 0.640. The AbsMax (18.36 SE7.74 p=0.025) and Max CA (21.02 SE7.63 p=0.012)\nscores generated with the DL without stylebook were associated with OPTION12.\nThe Max CA score generated with the fine-tuned BERTbase (110M) was associated\nwith the DCS score (-27.61 SE12.63 p=0.037). BERT model sizes did not have an\nimpact the association between CA scores and SDM. This study introduces an\nautomated, scalable methodology to measure SDM in patient-doctor conversations\nthrough explainable CA scores, with potential to evaluate SDM strategies at\nscale.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u4e0eBERT\u6a21\u578b\uff0c\u521b\u65b0\u6027\u5730\u5f00\u53d1\u4e86\u901a\u8fc7\u5bf9\u8bdd\u4e00\u81f4\u6027\u5206\u6570\u81ea\u52a8\u6d4b\u91cf\u60a3\u8005-\u533b\u751f\u6c9f\u901a\u4e2d\u5171\u4eab\u51b3\u7b56\u7684\u65b0\u65b9\u6cd5\uff0c\u5177\u5907\u5927\u89c4\u6a21\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u5171\u4eab\u51b3\u7b56(SDM)\u662f\u5b9e\u73b0\u4ee5\u60a3\u8005\u4e3a\u4e2d\u5fc3\u533b\u7597\u62a4\u7406\u7684\u91cd\u8981\u73af\u8282\uff0c\u4f46\u76ee\u524d\u5c1a\u65e0\u53ef\u81ea\u52a8\u5316\u3001\u89c4\u6a21\u5316\u6d4b\u91cfSDM\u7684\u65b9\u6cd5\u3002\u6b64\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u57fa\u4e8e\u8bed\u8a00\u5efa\u6a21\u548c\u5bf9\u8bdd\u4e00\u81f4\u6027\u5206\u6570(CA\u5206\u6570)\u7684\u81ea\u52a8\u5316SDM\u6d4b\u91cf\u65b9\u6cd5\u3002", "method": "\u672c\u7814\u7a76\u6536\u96c6\u4e86157\u4f8b\u5173\u4e8e\u623f\u98a4\u6297\u51dd\u51b3\u7b56\u7684\u75c5\u60a3-\u533b\u751f\u5bf9\u8bdd\u89c6\u9891\uff0c\u8f6c\u5f55\u540e\u5206\u5272\u4e3a42,559\u4e2a\u53e5\u5b50\uff0c\u91c7\u7528\u4e0a\u4e0b\u6587-\u54cd\u5e94\u914d\u5bf9\u4e0e\u8d1f\u91c7\u6837\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60(DL)\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u4e0b\u4e00\u4e2a\u53e5\u5b50\u9884\u6d4b(NSP)\u4efb\u52a1\u5fae\u8c03BERT\u6a21\u578b\u3002\u6bcf\u4e2a\u6700\u4f73\u6a21\u578b\u8ba1\u7b97\u56db\u79cdCA\u5206\u6570\u3002\u968f\u540e\u7528\u968f\u673a\u6548\u5e94\u5206\u6790\uff0c\u8c03\u6574\u76f8\u5173\u4eba\u53e3\u7edf\u8ba1\u5b66\u53d8\u91cf\uff0c\u8bc4\u4f30CA\u5206\u6570\u4e0eSDM\u7ed3\u5c40(Decisional Conflict Scale\u548cOPTION12\u5206\u6570)\u4e4b\u95f4\u7684\u5173\u8054\uff0c\u5e76\u5bf9\u591a\u91cd\u6bd4\u8f83\u8fdb\u884c\u6821\u6b63\u3002", "result": "DL\u6a21\u578b\uff08\u65e0\u98ce\u683c\u7b56\u7565\uff09\u53ec\u56de\u7387\u4e3a0.227\uff0c\u5fae\u8c03\u8fc7\u7684BERTbase\u53ec\u56de\u7387\u6700\u9ad8\u4e3a0.640\u3002\u65e0\u98ce\u683cDL\u6a21\u578b\u751f\u6210\u7684AbsMax\u548cMax CA\u5206\u6570\u4e0eOPTION12\u663e\u8457\u76f8\u5173\uff0c\u5fae\u8c03BERTbase\u751f\u6210\u7684Max CA\u5206\u6570\u4e0eDCS\u5206\u6570\u663e\u8457\u76f8\u5173\u3002BERT\u6a21\u578b\u5c3a\u5bf8\u5bf9\u5173\u8054\u6027\u65e0\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u3001\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u901a\u8fc7\u53ef\u89e3\u91ca\u7684CA\u5206\u6570\u6765\u8861\u91cf\u75c5\u60a3-\u533b\u751f\u4ea4\u6d41\u4e2d\u7684\u5171\u4eab\u51b3\u7b56\u6c34\u5e73\uff0c\u4e3a\u5927\u89c4\u6a21\u8bc4\u4f30SDM\u7b56\u7565\u63d0\u4f9b\u53ef\u80fd\u3002"}}
{"id": "2509.18458", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50 (Primary) 68T07, 68T05, 68T20, 68T27 (Secondary)", "I.2.7; I.2.6; I.2.4; I.2.8"], "pdf": "https://arxiv.org/pdf/2509.18458", "abs": "https://arxiv.org/abs/2509.18458", "authors": ["Daniel Kaiser", "Arnoldo Frigessi", "Ali Ramezani-Kebrya", "Benjamin Ricaud"], "title": "CogniLoad: A Synthetic Natural Language Reasoning Benchmark With Tunable Length, Intrinsic Difficulty, and Distractor Density", "comment": "29 pages (main: 12 + supplemental material: 17), 6 figures, 4 tables,\n  Code: https://github.com/kaiserdan/cogniload, Data:\n  https://huggingface.co/datasets/cogniloadteam/cogniload", "summary": "Current benchmarks for long-context reasoning in Large Language Models (LLMs)\noften blur critical factors like intrinsic task complexity, distractor\ninterference, and task length. To enable more precise failure analysis, we\nintroduce CogniLoad, a novel synthetic benchmark grounded in Cognitive Load\nTheory (CLT). CogniLoad generates natural-language logic puzzles with\nindependently tunable parameters that reflect CLT's core dimensions: intrinsic\ndifficulty ($d$) controls intrinsic load; distractor-to-signal ratio ($\\rho$)\nregulates extraneous load; and task length ($N$) serves as an operational proxy\nfor conditions demanding germane load. Evaluating 22 SotA reasoning LLMs,\nCogniLoad reveals distinct performance sensitivities, identifying task length\nas a dominant constraint and uncovering varied tolerances to intrinsic\ncomplexity and U-shaped responses to distractor ratios. By offering systematic,\nfactorial control over these cognitive load dimensions, CogniLoad provides a\nreproducible, scalable, and diagnostically rich tool for dissecting LLM\nreasoning limitations and guiding future model development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u8ba4\u77e5\u8d1f\u8377\u7406\u8bba\u7684\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u8bc4\u6d4b\u65b0\u57fa\u51c6CogniLoad\uff0c\u53ef\u4ee5\u7cbe\u786e\u8c03\u63a7\u4efb\u52a1\u96be\u5ea6\u3001\u5e72\u6270\u9879\u6bd4\u4f8b\u548c\u957f\u5ea6\uff0c\u7cfb\u7edf\u5206\u6790\u5e76\u8bca\u65ad\u6a21\u578b\u8868\u73b0\uff0c\u4e3a\u6307\u5bfcLLM\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u8bc4\u6d4b\u6807\u51c6\uff0c\u5f80\u5f80\u65e0\u6cd5\u6e05\u6670\u533a\u5206\u4efb\u52a1\u56fa\u6709\u590d\u6742\u6027\u3001\u5e72\u6270\u9879\u5f71\u54cd\u4ee5\u53ca\u4efb\u52a1\u957f\u5ea6\u7b49\u5173\u952e\u56e0\u7d20\uff0c\u5bfc\u81f4\u96be\u4ee5\u7cbe\u786e\u5206\u6790\u6a21\u578b\u5931\u8d25\u539f\u56e0\u3002", "method": "\u63d0\u51faCogniLoad\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u8ba4\u77e5\u8d1f\u8377\u7406\u8bba\uff08CLT\uff09\u7684\u65b0\u578b\u5408\u6210\u57fa\u51c6\u3002CogniLoad\u80fd\u591f\u751f\u6210\u81ea\u7136\u8bed\u8a00\u903b\u8f91\u8c1c\u9898\uff0c\u5e76\u5bf9\u4efb\u52a1\u7684\u56fa\u6709\u96be\u5ea6\u3001\u5e72\u6270\u9879\u6bd4\u4f8b\u4ee5\u53ca\u4efb\u52a1\u957f\u5ea6\u7b49\u53c2\u6570\u8fdb\u884c\u72ec\u7acb\u8c03\u8282\uff0c\u4ece\u800c\u7cbe\u786e\u63a7\u5236\u8ba4\u77e5\u8d1f\u8377\u7684\u4e0d\u540c\u7ef4\u5ea6\u3002", "result": "\u901a\u8fc7\u5bf922\u4e2a\u6700\u5148\u8fdb\u7684\u63a8\u7406\u578bLLM\u8fdb\u884c\u8bc4\u6d4b\uff0cCogniLoad\u63ed\u793a\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u8ba4\u77e5\u8d1f\u8377\u53c2\u6570\u4e0b\u7684\u8868\u73b0\u654f\u611f\u6027\u3002\u4f8b\u5982\uff0c\u4efb\u52a1\u957f\u5ea6\u662f\u4e3b\u8981\u7684\u6027\u80fd\u7ea6\u675f\uff0c\u6a21\u578b\u5bf9\u4efb\u52a1\u590d\u6742\u5ea6\u7684\u8010\u53d7\u6027\u5b58\u5728\u5dee\u5f02\uff0c\u5bf9\u5e72\u6270\u9879\u6bd4\u4f8b\u5219\u8868\u73b0\u51faU\u578b\u54cd\u5e94\u3002", "conclusion": "CogniLoad\u4e3a\u5206\u6790\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u53ef\u63a7\u3001\u53ef\u590d\u73b0\u548c\u8bca\u65ad\u4e30\u5bcc\u7684\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u6a21\u578b\u672a\u6765\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.18467", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18467", "abs": "https://arxiv.org/abs/2509.18467", "authors": ["Zeyu Liu", "Souvik Kundu", "Lianghao Jiang", "Anni Li", "Srikanth Ronanki", "Sravan Bodapati", "Gourav Datta", "Peter A. Beerel"], "title": "LAWCAT: Efficient Distillation from Quadratic to Linear Attention with Convolution across Tokens for Long Context Modeling", "comment": "17 pages, 8 figures", "summary": "Although transformer architectures have achieved state-of-the-art performance\nacross diverse domains, their quadratic computational complexity with respect\nto sequence length remains a significant bottleneck, particularly for\nlatency-sensitive long-context applications. While recent linear-complexity\nalternatives are increasingly powerful, effectively training them from scratch\nis still resource-intensive. To overcome these limitations, we propose LAWCAT\n(Linear Attention with Convolution Across Time), a novel linearization\nframework designed to efficiently transfer the capabilities of pre-trained\ntransformers into a performant linear attention architecture. LAWCAT integrates\ncausal Conv1D layers to enhance local dependency modeling and employs\nnormalized gated linear attention to improve generalization across varying\ncontext lengths. Our comprehensive evaluations demonstrate that, distilling\nMistral-7B with only 1K-length sequences yields over 90\\% passkey retrieval\naccuracy up to 22K tokens, significantly extending its effective context\nwindow. Similarly, Llama3.2-1B LAWCAT variant achieves competitive performance\non S-NIAH 1\\&2\\&3 tasks (1K-8K context length) and BABILong benchmark\n(QA2\\&QA3, 0K-16K context length), requiring less than 0.1\\% pre-training\ntokens compared with pre-training models. Furthermore, LAWCAT exhibits faster\nprefill speeds than FlashAttention-2 for sequences exceeding 8K tokens. LAWCAT\nthus provides an efficient pathway to high-performance, long-context linear\nmodels suitable for edge deployment, reducing reliance on extensive\nlong-sequence training data and computational resources.", "AI": {"tldr": "LAWCAT\u662f\u4e00\u79cd\u9ad8\u6548\u7ebf\u6027\u6ce8\u610f\u529b\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5377\u79ef\u548c\u6ce8\u610f\u529b\u65b9\u6cd5\uff0c\u5b9e\u73b0\u7528\u6781\u5c11\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u8bad\u7ec3\u51fa\u9ad8\u6027\u80fd\u957f\u4e0a\u4e0b\u6587\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u901f\u5ea6\u548c\u5e94\u7528\u8303\u56f4\u3002", "motivation": "Transformer\u67b6\u6784\u5728\u5404\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7531\u4e8e\u8ba1\u7b97\u590d\u6742\u5ea6\u968f\u5e8f\u5217\u957f\u5ea6\u5448\u4e8c\u6b21\u589e\u957f\uff0c\u4ecd\u662f\u957f\u4e0a\u4e0b\u6587\u3001\u4f4e\u5ef6\u8fdf\u5e94\u7528\u7684\u74f6\u9888\u3002\u5c3d\u7ba1\u7ebf\u6027\u590d\u6742\u5ea6\u7684\u66ff\u4ee3\u65b9\u6848\u9010\u6e10\u6210\u719f\uff0c\u4ecd\u9700\u9ad8\u6602\u7684\u8bad\u7ec3\u6210\u672c\u3002\u8be5\u6587\u65e8\u5728\u5bfb\u627e\u9ad8\u6548\u65b9\u6cd5\uff0c\u5c06\u5df2\u6709\u9ad8\u6027\u80fdTransformer\u80fd\u529b\u8fc1\u79fb\u5230\u7ebf\u6027\u6ce8\u610f\u529b\u7ed3\u6784\u3002", "method": "\u63d0\u51faLAWCAT\uff08Linear Attention with Convolution Across Time\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u56e0\u679cConv1D\u5c42\u4ee5\u63d0\u5347\u5c40\u90e8\u4f9d\u8d56\u5efa\u6a21\uff0c\u5e76\u91c7\u7528\u5f52\u4e00\u5316\u95e8\u63a7\u7ebf\u6027\u6ce8\u610f\u529b\u4ee5\u52a0\u5f3a\u4e0d\u540c\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u6cdb\u5316\u80fd\u529b\u3002\u8be5\u65b9\u6cd5\u4ee5\u84b8\u998f\u5df2\u6709Transformer\u6a21\u578b\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u6548\u7684\u7ebf\u6027\u6ce8\u610f\u529b\u67b6\u6784\u3002", "result": "\u84b8\u998fMistral-7B\u6a21\u578b\uff0c\u4ec5\u7528\u957f\u5ea6\u4e3a1K\u7684\u5e8f\u5217\u6570\u636e\uff0c\u5373\u53ef\u5728\u957f\u8fbe22K\u4ee4\u724c\u7684\u9a8c\u8bc1\u4e0b\u83b7\u5f97\u8d85\u8fc790%\u7684Passkey\u68c0\u7d22\u51c6\u786e\u7387\uff0c\u663e\u8457\u6269\u5c55\u4e86\u6709\u6548\u4e0a\u4e0b\u6587\u7a97\u53e3\u3002Llama3.2-1B LAWCAT\u5728\u591a\u79cd\u957f\u5e8f\u5217\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e0e\u539f\u59cb\u6a21\u578b\u5ab2\u7f8e\u7684\u8868\u73b0\uff0c\u540c\u65f6\u6240\u9700\u9884\u8bad\u7ec3\u6570\u636e\u4ec5\u4e3a\u539f\u6a21\u578b\u76840.1%\u3002\u57288K\u957f\u5ea6\u4ee5\u4e0a\u5e8f\u5217\u4e0a\uff0cLAWCAT\u9884\u586b\u901f\u5ea6\u8d85\u8fc7FlashAttention-2\u3002", "conclusion": "LAWCAT\u53ef\u9ad8\u6548\u5c06\u9884\u8bad\u7ec3Transformer\u80fd\u529b\u8f6c\u79fb\u5230\u957f\u5e8f\u5217\u7ebf\u6027\u6a21\u578b\uff0c\u65e0\u9700\u5927\u91cf\u957f\u5e8f\u5217\u6570\u636e\u548c\u7b97\u529b\uff0c\u6027\u80fd\u5f3a\u52b2\uff0c\u9002\u5408\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u3002\u4e3a\u957f\u4e0a\u4e0b\u6587\u9700\u6c42\u63d0\u4f9b\u8d44\u6e90\u53cb\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.18487", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18487", "abs": "https://arxiv.org/abs/2509.18487", "authors": ["Ben Finkelshtein", "Silviu Cucerzan", "Sujay Kumar Jauhar", "Ryen White"], "title": "Actions Speak Louder than Prompts: A Large-Scale Study of LLMs for Graph Inference", "comment": null, "summary": "Large language models (LLMs) are increasingly used for text-rich graph\nmachine learning tasks such as node classification in high-impact domains like\nfraud detection and recommendation systems. Yet, despite a surge of interest,\nthe field lacks a principled understanding of the capabilities of LLMs in their\ninteraction with graph data. In this work, we conduct a large-scale, controlled\nevaluation across several key axes of variability to systematically assess the\nstrengths and weaknesses of LLM-based graph reasoning methods in text-based\napplications. The axes include the LLM-graph interaction mode, comparing\nprompting, tool-use, and code generation; dataset domains, spanning citation,\nweb-link, e-commerce, and social networks; structural regimes contrasting\nhomophilic and heterophilic graphs; feature characteristics involving both\nshort- and long-text node attributes; and model configurations with varying LLM\nsizes and reasoning capabilities. We further analyze dependencies by\nmethodically truncating features, deleting edges, and removing labels to\nquantify reliance on input types. Our findings provide practical and actionable\nguidance. (1) LLMs as code generators achieve the strongest overall performance\non graph data, with especially large gains on long-text or high-degree graphs\nwhere prompting quickly exceeds the token budget. (2) All interaction\nstrategies remain effective on heterophilic graphs, challenging the assumption\nthat LLM-based methods collapse under low homophily. (3) Code generation is\nable to flexibly adapt its reliance between structure, features, or labels to\nleverage the most informative input type. Together, these findings provide a\ncomprehensive view of the strengths and limitations of current LLM-graph\ninteraction modes and highlight key design principles for future approaches.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u578b\u4efb\u52a1\u4e2d\u7684\u591a\u79cd\u4ea4\u4e92\u65b9\u5f0f\uff0c\u53d1\u73b0\u4ee3\u7801\u751f\u6210\u6a21\u5f0f\u8868\u73b0\u6700\u4f73\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u957f\u6587\u672c\u3001\u9ad8\u5ea6\u8282\u70b9\u6216\u5f02\u8d28\u6027\u56fe\uff0c\u5e76\u63d0\u51fa\u8bbe\u8ba1\u5efa\u8bae\u4ee5\u4f18\u5316\u672a\u6765LLMs\u56fe\u6570\u636e\u5e94\u7528\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8d8a\u6765\u8d8a\u591a\u5730\u5e94\u7528\u4e8e\u5bcc\u6587\u672c\u56fe\u673a\u5668\u5b66\u4e60\u4efb\u52a1\uff0c\u5982\u8282\u70b9\u5206\u7c7b\uff0c\u5728\u53cd\u6b3a\u8bc8\u548c\u63a8\u8350\u7cfb\u7edf\u7b49\u91cd\u8981\u9886\u57df\u8868\u73b0\u7a81\u51fa\u3002\u7136\u800c\uff0cLLMs\u5bf9\u56fe\u6570\u636e\u7684\u5904\u7406\u80fd\u529b\u5c1a\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7406\u89e3\uff0c\u7814\u7a76\u8005\u4e9f\u9700\u63a2\u7d22LLMs\u4e0e\u56fe\u6570\u636e\u4ea4\u4e92\u7684\u5404\u79cd\u6a21\u5f0f\u4e0e\u4f18\u52bf\u3002", "method": "\u672c\u6587\u5728\u591a\u4e2a\u5173\u952e\u53d8\u91cf\u8f74\u4e0a\uff08\u5982\u4ea4\u4e92\u6a21\u5f0f\u3001\u6570\u636e\u96c6\u9886\u57df\u3001\u56fe\u7ed3\u6784\u3001\u7279\u5f81\u5c5e\u6027\u3001\u6a21\u578b\u89c4\u6a21\uff09\u8fdb\u884c\u5927\u89c4\u6a21\u3001\u53d7\u63a7\u8bc4\u4f30\uff0c\u7cfb\u7edf\u6027\u6d4b\u8bd5LLMs\u5728\u4e0e\u56fe\u6570\u636e\u4ea4\u4e92\u65f6\u7684\u8868\u73b0\u3002\u91c7\u7528\u7684\u65b9\u6cd5\u5305\u62ec\u7279\u5f81\u622a\u65ad\u3001\u8fb9\u5220\u9664\u3001\u6807\u7b7e\u79fb\u9664\uff0c\u7531\u6b64\u5206\u6790\u6a21\u578b\u5bf9\u4e0d\u540c\u8f93\u5165\u7c7b\u578b\u7684\u4f9d\u8d56\u3002", "result": "\uff081\uff09LLMs\u4f5c\u4e3a\u4ee3\u7801\u751f\u6210\u5668\u5728\u56fe\u6570\u636e\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u7279\u522b\u662f\u5728\u957f\u6587\u672c\u4e0e\u9ad8\u5ea6\u8282\u70b9\u7684\u56fe\u7ed3\u6784\u4e0b\u4f18\u52bf\u660e\u663e\u3002\uff082\uff09\u6240\u6709\u4ea4\u4e92\u7b56\u7565\u5728\u5f02\u8d28\u6027\u5f3a\u7684\u56fe\u4e0a\u4ecd\u6709\u6548\uff0c\u53cd\u9a73\u4e86\u4f4e\u540c\u8d28\u6027\u4e0bLLMs\u6027\u80fd\u4e0b\u964d\u7684\u4f20\u7edf\u89c2\u70b9\u3002\uff083\uff09\u4ee3\u7801\u751f\u6210\u65b9\u5f0f\u80fd\u7075\u6d3b\u8c03\u6574\u5bf9\u7ed3\u6784\u3001\u7279\u5f81\u4e0e\u6807\u7b7e\u7684\u4f9d\u8d56\uff0c\u5145\u5206\u5229\u7528\u6700\u6709\u4fe1\u606f\u91cf\u7684\u8f93\u5165\u7c7b\u578b\u3002", "conclusion": "LLMs\u5728\u56fe\u6570\u636e\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u53d7\u4ea4\u4e92\u6a21\u5f0f\u3001\u6570\u636e\u7279\u5f81\u7b49\u591a\u65b9\u9762\u5f71\u54cd\uff0c\u4ee3\u7801\u751f\u6210\u6a21\u5f0f\u5177\u5907\u7a81\u51fa\u4f18\u52bf\u3002\u7814\u7a76\u63ed\u793a\u4e86LLMs\u4e0e\u56fe\u6570\u636e\u4ea4\u4e92\u7684\u5173\u952e\u8bbe\u8ba1\u539f\u5219\uff0c\u4e3a\u672a\u6765\u65b9\u6cd5\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2509.18514", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18514", "abs": "https://arxiv.org/abs/2509.18514", "authors": ["Mohamad Elzohbi", "Richard Zhao"], "title": "A Rhythm-Aware Phrase Insertion for Classical Arabic Poetry Composition", "comment": "Accepted for the Third Arabic Natural Language Processing Conference\n  (ArabicNLP 2025)", "summary": "This paper presents a methodology for inserting phrases in Arabic poems to\nconform to a specific rhythm using ByT5, a byte-level multilingual\ntransformer-based model. Our work discusses a rule-based grapheme-to-beat\ntransformation tailored for extracting the rhythm from fully diacritized Arabic\nscript. Our approach employs a conditional denoising objective to fine-tune\nByT5, where the model reconstructs masked words to match a target rhythm. We\nadopt a curriculum learning strategy, pre-training on a general Arabic dataset\nbefore fine-tuning on poetic dataset, and explore cross-lingual transfer from\nEnglish to Arabic. Experimental results demonstrate that our models achieve\nhigh rhythmic alignment while maintaining semantic coherence. The proposed\nmodel has the potential to be used in co-creative applications in the process\nof composing classical Arabic poems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408ByT5\u548c\u8282\u62cd\u89c4\u5219\uff0c\u5c06\u77ed\u8bed\u63d2\u5165\u963f\u62c9\u4f2f\u8bd7\u6b4c\u65f6\u5b9e\u73b0\u9ad8\u97f5\u5f8b\u4e00\u81f4\u6027\u548c\u8bed\u4e49\u8fde\u8d2f\u6027\uff0c\u4e3a\u963f\u62c9\u4f2f\u8bd7\u6b4c\u521b\u4f5c\u63d0\u4f9b\u6709\u529b\u652f\u6301\u3002", "motivation": "\u5bf9\u963f\u62c9\u4f2f\u8bd7\u6b4c\u63d2\u5165\u77ed\u8bed\u65f6\uff0c\u5982\u4f55\u4fdd\u8bc1\u63d2\u5165\u5185\u5bb9\u7b26\u5408\u7279\u5b9a\u97f5\u5f8b\uff0c\u4ee5\u652f\u6301\u53e4\u5178\u8bd7\u6b4c\u7684\u521b\u4f5c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eByT5\uff08\u5b57\u8282\u7ea7\u591a\u8bedTransformer\u6a21\u578b\uff09\u65b9\u6cd5\uff0c\u7ed3\u5408\u89c4\u5219\u9a71\u52a8\u7684\u5b57\u7d20\u5230\u8282\u62cd\u8f6c\u6362\uff0c\u91c7\u7528\u6761\u4ef6\u53bb\u566a\u76ee\u6807\u5bf9ByT5\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u7528\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6cd5\u5148\u5728\u901a\u7528\u6570\u636e\u8bad\u7ec3\uff0c\u518d\u5728\u8bd7\u6b4c\u6570\u636e\u4e0a\u5fae\u8c03\uff0c\u540c\u65f6\u63a2\u7d22\u4e86\u82f1\u6587\u5230\u963f\u62c9\u4f2f\u6587\u7684\u8de8\u8bed\u8fc1\u79fb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u5b9e\u73b0\u9ad8\u6c34\u5e73\u7684\u8282\u594f\u5bf9\u9f50\uff0c\u540c\u65f6\u4fdd\u8bc1\u8bed\u4e49\u8fde\u8d2f\u6027\u3002", "conclusion": "\u6240\u63d0\u6a21\u578b\u6709\u6f5c\u529b\u7528\u4e8e\u534f\u540c\u521b\u4f5c\u53e4\u5178\u963f\u62c9\u4f2f\u8bd7\u6b4c\uff0c\u4e3a\u81ea\u52a8\u751f\u6210\u7b26\u5408\u97f5\u5f8b\u9700\u6c42\u7684\u8bd7\u53e5\u63d0\u4f9b\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2509.18535", "categories": ["cs.CL", "eess.SP"], "pdf": "https://arxiv.org/pdf/2509.18535", "abs": "https://arxiv.org/abs/2509.18535", "authors": ["Mo Mu", "Dianqiao Lei", "Chang Li"], "title": "Trace Is In Sentences: Unbiased Lightweight ChatGPT-Generated Text Detector", "comment": null, "summary": "The widespread adoption of ChatGPT has raised concerns about its misuse,\nhighlighting the need for robust detection of AI-generated text. Current\nword-level detectors are vulnerable to paraphrasing or simple prompts (PSP),\nsuffer from biases induced by ChatGPT's word-level patterns (CWP) and training\ndata content, degrade on modified text, and often require large models or\nonline LLM interaction. To tackle these issues, we introduce a novel task to\ndetect both original and PSP-modified AI-generated texts, and propose a\nlightweight framework that classifies texts based on their internal structure,\nwhich remains invariant under word-level changes. Our approach encodes sentence\nembeddings from pre-trained language models and models their relationships via\nattention. We employ contrastive learning to mitigate embedding biases from\nautoregressive generation and incorporate a causal graph with counterfactual\nmethods to isolate structural features from topic-related biases. Experiments\non two curated datasets, including abstract comparisons and revised life FAQs,\nvalidate the effectiveness of our method.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e0d\u7528\u5927\u6a21\u578b\u548c\u5728\u7ebfLLM\u7684\u65b0\u578b\u8f7b\u91cf\u7ed3\u6784\u68c0\u6d4b\u6846\u67b6\uff0c\u80fd\u51c6\u786e\u68c0\u6d4b\u539f\u7248\u53ca\u88ab\u8bcd\u7ea7\u4fee\u6539\u7684AI\u6587\u672c\uff0c\u89c4\u907f\u539f\u6587\u504f\u89c1\u548c\u6570\u636e\u504f\u5dee\uff0c\u5728\u5b9e\u6d4b\u6570\u636e\u96c6\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u7531\u4e8eChatGPT\u7b49AI\u6587\u672c\u751f\u6210\u5de5\u5177\u5e7f\u6cdb\u4f7f\u7528\uff0c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5bb9\u6613\u88ab\u8bcd\u7ea7\u4fee\u6539\uff08\u5982\u6362\u53e5\u8bdd\u8bf4/paraphrasing\u7b49\uff09\u89c4\u907f\uff0c\u4e14\u5b58\u5728\u6a21\u578b\u504f\u89c1\u3001\u5bf9\u4fee\u6539\u6587\u672c\u51c6\u786e\u6027\u4e0b\u964d\u7b49\u95ee\u9898\uff0c\u4e9f\u9700\u66f4\u9c81\u68d2\u4e14\u9ad8\u6548\u7684\u68c0\u6d4b\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6587\u672c\u5185\u90e8\u7ed3\u6784\u7684\u8f7b\u91cf\u7ea7\u68c0\u6d4b\u6846\u67b6\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u83b7\u5f97\u53e5\u5b50\u5d4c\u5165\uff0c\u5e76\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u5efa\u6a21\u53e5\u5b50\u5173\u7cfb\u3002\u91c7\u7528\u5bf9\u6bd4\u5b66\u4e60\u51cf\u5c11\u5d4c\u5165\u504f\u5dee\uff0c\u5e76\u5f15\u5165\u56e0\u679c\u56fe\u53ca\u53cd\u4e8b\u5b9e\u6280\u672f\u9694\u79bb\u7ed3\u6784\u7279\u5f81\u4e0e\u4e3b\u9898\u76f8\u5173\u504f\u5dee\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e24\u4e2a\u6570\u636e\u96c6\uff08\u6458\u8981\u6bd4\u5bf9\u548cFAQ\u95ee\u7b54\u6587\u672c\uff09\u4e0a\u5747\u53d6\u5f97\u4f18\u8d8a\u7684\u68c0\u6d4b\u6548\u679c\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u8bc6\u522b\u539f\u59cb\u53ca\u7ecf\u8fc7\u8bcd\u7ea7\u4fee\u6539\u7684AI\u751f\u6210\u6587\u672c\uff0c\u4e14\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u9c81\u68d2\u3001\u66f4\u9ad8\u6548\u3002"}}
{"id": "2509.18536", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18536", "abs": "https://arxiv.org/abs/2509.18536", "authors": ["Jin Young Kim", "Ji Won Yoon"], "title": "CCQA: Generating Question from Solution Can Improve Inference-Time Reasoning in SLMs", "comment": "Published as a main conference paper at EMNLP 2025", "summary": "Recently, inference-time reasoning strategies have further improved the\naccuracy of large language models (LLMs), but their effectiveness on smaller\nmodels remains unclear. Based on the observation that conventional approaches\noften fail to improve performance in this context, we propose\n\\textbf{C}ycle-\\textbf{C}onsistency in \\textbf{Q}uestion \\textbf{A}nswering\n(CCQA), a novel reasoning method that can be effectively applied to SLMs.\nInspired by cycle consistency, CCQA generates a question from each reasoning\npath and answer, evaluates each by its similarity to the original question, and\nthen selects the candidate solution with the highest similarity score as the\nfinal response. Since conventional SLMs struggle to generate accurate questions\nfrom their own reasoning paths and answers, we employ a lightweight Flan-T5\nmodel specialized for question generation to support this process efficiently.\nFrom the experimental results, it is verified that CCQA consistently\noutperforms existing state-of-the-art (SOTA) methods across eight models on\nmathematical and commonsense reasoning benchmarks. Furthermore, our method\nestablishes a new practical baseline for efficient reasoning in SLMs. Source\ncode can be found at https://github.com/scai-research/ccqa_official.", "AI": {"tldr": "\u63d0\u51fa\u4e86CCQA\u5faa\u73af\u4e00\u81f4\u6027\u95ee\u7b54\u63a8\u7406\u65b9\u6cd5\uff0c\u57288\u4e2a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709SOTA\u7ed3\u679c\uff0c\u5c24\u5176\u64c5\u957f\u6570\u5b66\u4e0e\u5e38\u8bc6\u63a8\u7406\uff0c\u5e76\u5efa\u7acb\u4e86\u65b0\u7684\u9ad8\u6548\u63a8\u7406\u57fa\u7ebf\u3002", "motivation": "\u76ee\u524d\u57fa\u4e8e\u63a8\u7406\u7b56\u7565\u5728\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\u51c6\u786e\u6027\u4e0a\u5df2\u6709\u63d0\u5347\uff0c\u4f46\u5728\u66f4\u5c0f\u89c4\u6a21\u7684\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\u4e0a\u6548\u679c\u4e0d\u4f73\u3002\u4f20\u7edf\u65b9\u6cd5\u5728SLM\u4e2d\u7684\u6027\u80fd\u63d0\u5347\u6709\u9650\uff0c\u4e9f\u9700\u65b0\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCycle-Consistency\u7684\u95ee\u7b54\u63a8\u7406\u65b9\u6cd5CCQA\u3002\u5177\u4f53\u5730\uff0c\u5bf9\u6bcf\u6761\u63a8\u7406\u8def\u5f84\u53ca\u5176\u7b54\u6848\u751f\u6210\u95ee\u9898\uff0c\u4ee5\u751f\u6210\u7684\u95ee\u9898\u4e0e\u539f\u95ee\u9898\u7684\u76f8\u4f3c\u6027\u4e3a\u5206\u6570\uff0c\u5206\u6570\u6700\u9ad8\u7684\u7b54\u6848\u88ab\u9009\u4e3a\u6700\u7ec8\u7ed3\u679c\u3002\u4e3a\u63d0\u5347SLM\u95ee\u9898\u751f\u6210\u80fd\u529b\uff0c\u4f7f\u7528\u4e00\u4e2a\u4e13\u95e8\u7cbe\u70bc\u4e8e\u95ee\u9898\u751f\u6210\u7684\u8f7b\u91cf\u7ea7Flan-T5\u6a21\u578b\u8f85\u52a9\u6b64\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cCCQA\u57288\u4e2a\u6a21\u578b\u4e0a\u7684\u6570\u5b66\u4e0e\u5e38\u8bc6\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "CCQA\u4e3aSLM\u63a8\u7406\u5efa\u7acb\u4e86\u66f4\u9ad8\u6548\u7684\u65b0\u5b9e\u7528\u57fa\u7ebf\uff0c\u5e76\u663e\u8457\u63d0\u5347SLM\u5728\u6570\u5b66\u4e0e\u5e38\u8bc6\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002"}}
{"id": "2509.18577", "categories": ["cs.CL", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2509.18577", "abs": "https://arxiv.org/abs/2509.18577", "authors": ["Yeongbin Seo", "Gayoung Kim", "Jaehyung Kim", "Jinyoung Yeo"], "title": "Prior-based Noisy Text Data Filtering: Fast and Strong Alternative For Perplexity", "comment": null, "summary": "As large language models (LLMs) are pretrained on massive web corpora,\ncareful selection of data becomes essential to ensure effective and efficient\nlearning. While perplexity (PPL)-based filtering has shown strong performance,\nit suffers from drawbacks: substantial time costs and inherent unreliability of\nthe model when handling noisy or out-of-distribution samples. In this work, we\npropose a simple yet powerful alternative: a prior-based data filtering method\nthat estimates token priors using corpus-level term frequency statistics,\ninspired by linguistic insights on word roles and lexical density. Our approach\nfilters documents based on the mean and standard deviation of token priors,\nserving as a fast proxy to PPL while requiring no model inference. Despite its\nsimplicity, the prior-based filter achieves the highest average performance\nacross 20 downstream benchmarks, while reducing time cost by over 1000x\ncompared to PPL-based filtering. We further demonstrate its applicability to\nsymbolic languages such as code and math, and its dynamic adaptability to\nmultilingual corpora without supervision", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u63a8\u65ad\u3001\u57fa\u4e8e\u8bcd\u7edf\u8ba1\u7684\u9ad8\u6548\u6570\u636e\u7b5b\u9009\u65b9\u6cd5\uff0c\u5728\u901f\u5ea6\u4e0e\u6548\u679c\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edfPPL\u7b5b\u9009\uff0c\u5e76\u9002\u7528\u4e8e\u591a\u8bed\u79cd\u548c\u7b26\u53f7\u5316\u573a\u666f\u3002", "motivation": "\u4ee5\u5f80\u5229\u7528PPL\uff08\u56f0\u60d1\u5ea6\uff09\u7b5b\u9009\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u6570\u636e\u6548\u679c\u4e0d\u9519\uff0c\u4f46\u5b58\u5728\u8017\u65f6\u9ad8\u3001\u6a21\u578b\u5bf9\u566a\u58f0\u548c\u5206\u5e03\u5916\u6837\u672c\u4e0d\u53ef\u9760\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9ad8\u6548\u53ef\u9760\u7684\u6570\u636e\u7b5b\u9009\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5148\u9a8c\u7684\u7b80\u5355\u9ad8\u6548\u6570\u636e\u7b5b\u9009\u65b9\u6cd5\uff1a\u5229\u7528\u8bed\u6599\u5e93\u8bcd\u9891\u7b49\u7edf\u8ba1\u91cf\u4f30\u7b97token\u53d1\u751f\u7684\u5148\u9a8c\u6982\u7387\uff0c\u7136\u540e\u57fa\u4e8etoken\u5148\u9a8c\u7684\u5747\u503c\u53ca\u6807\u51c6\u5dee\u8fdb\u884c\u6587\u6863\u7b5b\u9009\uff0c\u65e0\u9700\u6a21\u578b\u63a8\u65ad\u3002", "result": "\u8be5\u65b9\u6cd5\u572820\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u83b7\u5f97\u4e86\u6700\u4f73\u5e73\u5747\u6027\u80fd\uff0c\u4e14\u5728\u8017\u65f6\u4e0a\u76f8\u8f83PPL\u7b5b\u9009\u63d0\u5347\u8d85\u8fc71000\u500d\u3002\u540c\u65f6\u5bf9\u4ee3\u7801\u3001\u6570\u5b66\u7b49\u7b26\u53f7\u8bed\u8a00\u9002\u7528\uff0c\u5e76\u80fd\u591f\u81ea\u9002\u5e94\u591a\u8bed\u79cd\u8bed\u6599\u3002", "conclusion": "\u57fa\u4e8e\u5148\u9a8c\u7684\u6570\u636e\u7b5b\u9009\u6cd5\u65e0\u9700\u63a8\u65ad\u3001\u8ba1\u7b97\u901f\u5ea6\u6781\u5feb\uff0c\u7b5b\u9009\u6548\u679c\u4f18\u8d8a\uff0c\u80fd\u5e7f\u6cdb\u9002\u7528\u4e8e\u5404\u79cd\u7c7b\u578b\u4e0e\u591a\u8bed\u79cd\u5927\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u7b5b\u9009\u573a\u666f\u3002"}}
{"id": "2509.18585", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18585", "abs": "https://arxiv.org/abs/2509.18585", "authors": ["Yu Chen", "Yifei Han", "Long Zhang", "Yue Du", "Bin Li"], "title": "TsqLoRA: Towards Sensitivity and Quality Low-Rank Adaptation for Efficient Fine-Tuning", "comment": "5 pages, 4 figures, published to ICASSP2026", "summary": "Fine-tuning large pre-trained models for downstream tasks has become a\nfundamental approach in natural language processing. Fully fine-tuning all\nmodel parameters is computationally expensive and memory-intensive, especially\nin resource-constrained environments. Existing parameter-efficient fine-tuning\nmethods reduce the number of trainable parameters but typically overlook the\nvarying sensitivity of different model layers and the importance of training\ndata. In this work, we propose TsqLoRA, a novel method that integrates\ndata-quality-driven selection with sensitivity-aware low-rank adaptation,\nconsisted of two main components: a quality-aware sampling mechanism for\nselecting the most informative training data, and a dynamic rank allocation\nmodule that adjusts the rank of each layer based on its sensitivity to\nparameter updates. The experimental results demonstrate that TsqLoRA improves\nfine-tuning efficiency while maintaining or even improving performance on a\nvariety of NLP tasks. Our code will be available at\nhttps://github.com/Benjamin-Ricky/TsqLoRA.", "AI": {"tldr": "TsqLoRA\u901a\u8fc7\u7ed3\u5408\u9ad8\u8d28\u91cf\u6570\u636e\u91c7\u6837\u548c\u5c42\u7ea7\u654f\u611f\u5ea6\u52a8\u6001\u79e9\u5206\u914d\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5927\u6a21\u578b\u5fae\u8c03\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u9002\u5408\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e0b\u9ad8\u6548NLP\u5fae\u8c03\u3002", "motivation": "\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u5728NLP\u9886\u57df\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5168\u90e8\u53c2\u6570\u5fae\u8c03\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u5de8\u5927\uff0c\u5c24\u5176\u5728\u8d44\u6e90\u6709\u9650\u73af\u5883\u4e0b\u5c24\u4e3a\u7a81\u51fa\u3002\u73b0\u6709\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u867d\u7136\u51cf\u5c11\u4e86\u53ef\u8bad\u7ec3\u53c2\u6570\u91cf\uff0c\u4f46\u5ffd\u89c6\u4e86\u6a21\u578b\u5c42\u654f\u611f\u6027\u548c\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u7684\u91cd\u8981\u6027\u3002", "method": "\u63d0\u51fa\u4e86TsqLoRA\u65b9\u6cd5\uff0c\u521b\u65b0\u6027\u5730\u7ed3\u5408\u4e86\u6570\u636e\u8d28\u91cf\u9a71\u52a8\u7684\u6570\u636e\u9009\u62e9\u4e0e\u5bf9\u6a21\u578b\u5c42\u654f\u611f\u5ea6\u611f\u77e5\u7684\u4f4e\u79e9\u9002\u914d\u3002\u5177\u4f53\u5305\u62ec\u4e24\u4e2a\u7ec4\u4ef6\uff1a\u4e00\u662f\u57fa\u4e8e\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u7684\u91c7\u6837\u673a\u5236\uff0c\u4f18\u5148\u9009\u62e9\u4fe1\u606f\u91cf\u5927\u7684\u6570\u636e\uff1b\u4e8c\u662f\u52a8\u6001\u5206\u914d\u6bcf\u5c42\u4f4e\u79e9\u5206\u89e3\u7684\u79e9\uff0c\u6839\u636e\u5404\u5c42\u5bf9\u53c2\u6570\u66f4\u65b0\u7684\u654f\u611f\u6027\u8c03\u6574\u79e9\u5927\u5c0f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cTsqLoRA\u5728\u591a\u9879NLP\u4efb\u52a1\u4e0a\u63d0\u5347\u4e86\u5fae\u8c03\u6548\u7387\uff0c\u5e76\u80fd\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "TsqLoRA\u80fd\u591f\u9ad8\u6548\u3001\u6709\u6548\u5730\u5fae\u8c03\u5927\u6a21\u578b\uff0c\u5728\u6548\u7387\u548c\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2509.18588", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18588", "abs": "https://arxiv.org/abs/2509.18588", "authors": ["Jiarui Jin", "Haoyu Wang", "Xiang Lan", "Jun Li", "Gaofeng Cheng", "Hongyan Li", "Shenda Hong"], "title": "UniECG: Understanding and Generating ECG in One Unified Model", "comment": null, "summary": "Recent unified models such as GPT-5 have achieved encouraging progress on\nvision-language tasks. However, these unified models typically fail to\ncorrectly understand ECG signals and provide accurate medical diagnoses, nor\ncan they correctly generate ECG signals. To address these limitations, we\npropose UniECG, the first unified model for ECG capable of concurrently\nperforming evidence-based ECG interpretation and text-conditioned ECG\ngeneration tasks. Through a decoupled two-stage training approach, the model\nfirst learns evidence-based interpretation skills (ECG-to-Text), and then\ninjects ECG generation capabilities (Text-to-ECG) via latent space alignment.\nUniECG can autonomously choose to interpret or generate an ECG based on user\ninput, significantly extending the capability boundaries of current ECG models.\nOur code and checkpoints will be made publicly available at\nhttps://github.com/PKUDigitalHealth/UniECG upon acceptance.", "AI": {"tldr": "UniECG\u662f\u9996\u4e2a\u80fd\u591f\u540c\u65f6\u8fdb\u884c\u5fc3\u7535\u56fe\u89e3\u91ca\u548c\u751f\u6210\u7684\u7edf\u4e00\u6a21\u578b\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4e86\u533b\u7597\u9886\u57df\u7684\u591a\u4efb\u52a1\u80fd\u529b\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684\u7edf\u4e00\u6a21\u578b\uff08\u5982GPT-5\uff09\u5728\u89c6\u89c9-\u8bed\u8a00\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5728\u5fc3\u7535\u56fe\uff08ECG\uff09\u4fe1\u53f7\u7406\u89e3\u548c\u751f\u6210\u65b9\u9762\u5b58\u5728\u660e\u663e\u5c40\u9650\uff0c\u65e0\u6cd5\u6ee1\u8db3\u533b\u7597\u8bca\u65ad\u9700\u6c42\u3002", "method": "\u91c7\u7528\u4e86\u89e3\u8026\u7684\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\uff1a\u9996\u5148\u8bad\u7ec3ECG\u5230\u6587\u672c\u7684\u89e3\u91ca\u80fd\u529b\uff0c\u7136\u540e\u901a\u8fc7\u6f5c\u5728\u7a7a\u95f4\u5bf9\u9f50\u6ce8\u5165\u6587\u672c\u5230ECG\u7684\u751f\u6210\u80fd\u529b\u3002", "result": "UniECG\u80fd\u591f\u6839\u636e\u7528\u6237\u8f93\u5165\u81ea\u4e3b\u9009\u62e9\u5fc3\u7535\u56fe\u89e3\u8bfb\u6216\u751f\u6210\u4efb\u52a1\uff0c\u663e\u8457\u62d3\u5c55\u4e86\u5f53\u524dECG\u6a21\u578b\u7684\u80fd\u529b\u8fb9\u754c\u3002\u76f8\u5173\u4ee3\u7801\u548c\u6a21\u578b\u68c0\u67e5\u70b9\u5c06\u5728\u5f00\u6e90\u5e73\u53f0\u516c\u5f00\u3002", "conclusion": "UniECG\u6a21\u578b\u6269\u5c55\u4e86\u73b0\u6709ECG\u6a21\u578b\u7684\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8e\u8bc1\u636e\u7684\u5fc3\u7535\u56fe\u89e3\u8bfb\u548c\u6587\u672c\u6761\u4ef6\u4e0b\u7684\u5fc3\u7535\u56fe\u751f\u6210\u3002"}}
{"id": "2509.18632", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18632", "abs": "https://arxiv.org/abs/2509.18632", "authors": ["Nishant Balepur", "Matthew Shu", "Yoo Yeon Sung", "Seraphina Goldfarb-Tarrant", "Shi Feng", "Fumeng Yang", "Rachel Rudinger", "Jordan Lee Boyd-Graber"], "title": "A Good Plan is Hard to Find: Aligning Models with Preferences is Misaligned with What Helps Users", "comment": "EMNLP 2025", "summary": "To assist users in complex tasks, LLMs generate plans: step-by-step\ninstructions towards a goal. While alignment methods aim to ensure LLM plans\nare helpful, they train (RLHF) or evaluate (ChatbotArena) on what users prefer,\nassuming this reflects what helps them. We test this with Planorama: an\ninterface where 126 users answer 300 multi-step questions with LLM plans. We\nget 4388 plan executions and 5584 comparisons to measure plan helpfulness (QA\nsuccess) and user preferences on plans, and recreate the setup in agents and\nreward models to see if they simulate or prefer what helps users. We expose: 1)\nuser/model preferences and agent success do not accurately predict which plans\nhelp users, so common alignment feedback can misalign with helpfulness; 2) this\ngap is not due to user-specific preferences, as users are similarly successful\nwhen using plans they prefer/disprefer; 3) surface-level cues like brevity and\nquestion similarity strongly link to preferences, but such biases fail to\npredict helpfulness. In all, we argue aligning helpful LLMs needs feedback from\nreal user interactions, not just preferences of what looks helpful, so we\ndiscuss the plan NLP researchers can execute to solve this problem.", "AI": {"tldr": "\u5927\u6a21\u578b\u8ba1\u5212\u751f\u6210\u5982\u679c\u4ec5\u4f9d\u636e\u7528\u6237\u504f\u597d\u8fdb\u884c\u5bf9\u9f50\uff0c\u4f1a\u548c\u771f\u6b63\u7684\u7528\u6237\u5e2e\u52a9\u53d1\u751f\u504f\u79bb\u3002\u771f\u5b9e\u7528\u6237\u4ea4\u4e92\u53cd\u9988\u6bd4\u504f\u597d\u66f4\u80fd\u6307\u5bfc\u6a21\u578b\u5bf9\u9f50\uff0c\u672a\u6765\u5e94\u7740\u91cd\u4ece\u771f\u5b9e\u4e92\u52a8\u4e2d\u4f18\u5316\u8ba1\u5212\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u5927\u6a21\u578b\u8ba1\u5212\u751f\u6210\u4e3b\u8981\u4f9d\u636e\u7528\u6237\u504f\u597d\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\uff0c\u5047\u5b9a\u7528\u6237\u504f\u597d\u7b49\u540c\u4e8e\u771f\u6b63\u5bf9\u7528\u6237\u6709\u5e2e\u52a9\uff0c\u4f46\u8fd9\u4e00\u5047\u8bbe\u5e76\u672a\u88ab\u5145\u5206\u68c0\u9a8c\u3002\u4f5c\u8005\u5e0c\u671b\u8bc4\u4f30\u504f\u597d\u4e0e\u771f\u6b63\u5e2e\u52a9\u4e4b\u95f4\u7684\u5b9e\u9645\u5dee\u5f02\u3002", "method": "\u4f5c\u8005\u63d0\u51faPlanorama\u5e73\u53f0\uff0c\u9080\u8bf7126\u540d\u7528\u6237\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u8ba1\u5212\u89e3\u51b3300\u4e2a\u591a\u6b65\u9aa4\u95ee\u9898\uff0c\u6536\u96c64388\u4e2a\u6267\u884c\u6848\u4f8b\u548c5584\u7ec4\u8ba1\u5212\u5bf9\u6bd4\uff0c\u7528\u4e8e\u5206\u6790\u7528\u6237\u6210\u529f\u7387\u548c\u8ba1\u5212\u504f\u597d\u3002\u5b9e\u9a8c\u8fd8\u5728\u667a\u80fd\u4f53\u548c\u5956\u52b1\u6a21\u578b\u4e2d\u590d\u73b0\u8be5\u6d41\u7a0b\uff0c\u4ee5\u89c2\u6d4b\u6a21\u578b\u672c\u8eab\u7684\u504f\u597d\u53ca\u5176\u4e0e\u7528\u6237\u5b9e\u9645\u5e2e\u52a9\u7684\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u7528\u6237/\u6a21\u578b\u504f\u597d\u4e0e\u771f\u5b9e\u5e2e\u52a9\uff08\u5373QA\u6210\u529f\u7387\uff09\u4e4b\u95f4\u9ad8\u5ea6\u4e0d\u4e00\u81f4\u3002\u5e38\u89c1\u7684\u5bf9\u9f50\u65b9\u5f0f\u53ef\u80fd\u53cd\u800c\u4f1a\u548c\u201c\u6709\u5e2e\u52a9\u201d\u4ea7\u751f\u504f\u79bb\u3002\u7528\u6237\u81ea\u8eab\u504f\u597d\u4e0e\u5e2e\u52a9\u7387\u65e0\u5f3a\u5173\u8054\uff0c\u8868\u9762\u7279\u5f81\u5982\u7b80\u6d01\u6027\u548c\u4e0e\u95ee\u9898\u7684\u76f8\u4f3c\u5ea6\u867d\u80fd\u5f71\u54cd\u504f\u597d\uff0c\u4f46\u65e0\u6cd5\u6709\u6548\u9884\u6d4b\u771f\u5b9e\u5e2e\u52a9\u7a0b\u5ea6\u3002", "conclusion": "\u4ec5\u7528\u7528\u6237\u504f\u597d\u53bb\u6307\u5bfc\u5927\u6a21\u578b\u8ba1\u5212\u751f\u6210\u5b58\u5728\u5c40\u9650\uff0c\u65e0\u6cd5\u4fdd\u969c\u5b9e\u9645\u5e2e\u52a9\u7528\u6237\u3002\u6a21\u578b\u9700\u8981\u501f\u52a9\u771f\u5b9e\u7528\u6237\u4ea4\u4e92\u53cd\u9988\u8fdb\u884c\u5bf9\u9f50\uff0c\u4e0d\u80fd\u53ea\u57fa\u4e8e\u5916\u89c2\u4e0a\u201c\u770b\u4f3c\u6709\u5e2e\u52a9\u201d\u7684\u504f\u597d\u3002\u4f5c\u8005\u5efa\u8baeNLP\u793e\u533a\u8bbe\u8ba1\u57fa\u4e8e\u771f\u5b9e\u7528\u6237\u4e92\u52a8\u7684\u53cd\u9988\u673a\u5236\u4ee5\u63d0\u5347\u8ba1\u5212\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.18655", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18655", "abs": "https://arxiv.org/abs/2509.18655", "authors": ["Lingwen Deng", "Yifei Han", "Long Zhang", "Yue Du", "Bin Li"], "title": "Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop Question Answering", "comment": "Submitted to ICASSP 2026", "summary": "Parameter-Preserving Knowledge Editing (PPKE) enables updating models with\nnew or corrected information without retraining or parameter adjustment. Recent\nPPKE approaches based on knowledge graphs (KG) to extend knowledge editing (KE)\ncapabilities to multi-hop question answering (MHQA). However, these methods\noften lack consistency, leading to knowledge contamination, unstable updates,\nand retrieval behaviors that fail to reflect the intended edits. Such\ninconsistencies undermine the reliability of PPKE in multi- hop reasoning. We\npresent CAPE-KG, Consistency-Aware Parameter-Preserving Editing with Knowledge\nGraphs, a novel consistency-aware framework for PPKE on MHQA. CAPE-KG ensures\nKG construction, update, and retrieval are always aligned with the requirements\nof the MHQA task, maintaining coherent reasoning over both unedited and edited\nknowledge. Extensive experiments on the MQuAKE benchmark show accuracy\nimprovements in PPKE performance for MHQA, demonstrating the effectiveness of\naddressing consistency in PPKE.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u7684\u4e00\u81f4\u6027\u589e\u5f3a\u578b\u77e5\u8bc6\u7f16\u8f91\u6846\u67b6CAPE-KG\uff0c\u6709\u6548\u63d0\u5347\u4e86\u77e5\u8bc6\u66f4\u65b0\u540e\u7684\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684PPKE\u65b9\u6cd5\u5728\u591a\u8df3\u63a8\u7406\u65f6\u4e00\u81f4\u6027\u8f83\u5dee\uff0c\u5bfc\u81f4\u77e5\u8bc6\u6c61\u67d3\u548c\u66f4\u65b0\u4e0d\u7a33\u5b9a\uff0c\u4ece\u800c\u5f71\u54cd\u77e5\u8bc6\u7f16\u8f91\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u4e86CAPE-KG\u6846\u67b6\uff0c\u4f7f\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u3001\u66f4\u65b0\u548c\u68c0\u7d22\u4e0e\u591a\u8df3\u95ee\u7b54\u7684\u9700\u6c42\u4fdd\u6301\u4e00\u81f4\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u4e00\u81f4\u6027\u95ee\u9898\u3002", "result": "\u5728MQuAKE\u57fa\u51c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cCAPE-KG\u663e\u8457\u63d0\u5347\u4e86PPKE\u5728\u591a\u8df3\u95ee\u7b54\u4e2d\u7684\u51c6\u786e\u6027\uff0c\u8bc1\u5b9e\u4e86\u63d0\u5347\u4e00\u81f4\u6027\u540e\u7684\u6709\u6548\u6027\u3002", "conclusion": "CAPE-KG\u6709\u6548\u63d0\u5347\u4e86\u53c2\u6570\u4fdd\u6301\u578b\u77e5\u8bc6\u7f16\u8f91\uff08PPKE\uff09\u5728\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u4e00\u81f4\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2509.18658", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18658", "abs": "https://arxiv.org/abs/2509.18658", "authors": ["Huanxin Sheng", "Xinyi Liu", "Hangfeng He", "Jieyu Zhao", "Jian Kang"], "title": "Analyzing Uncertainty of LLM-as-a-Judge: Interval Evaluations with Conformal Prediction", "comment": "To appear in EMNLP 2025. Our code and data are available at\n  \\url{https://github.com/BruceSheng1202/Analyzing_Uncertainty_of_LLM-as-a-Judge", "summary": "LLM-as-a-judge has become a promising paradigm for using large language\nmodels (LLMs) to evaluate natural language generation (NLG), but the\nuncertainty of its evaluation remains underexplored. This lack of reliability\nmay limit its deployment in many applications. This work presents the first\nframework to analyze the uncertainty by offering a prediction interval of\nLLM-based scoring via conformal prediction. Conformal prediction constructs\ncontinuous prediction intervals from a single evaluation run, and we design an\nordinal boundary adjustment for discrete rating tasks. We also suggest a\nmidpoint-based score within the interval as a low-bias alternative to raw model\nscore and weighted average. We perform extensive experiments and analysis,\nwhich show that conformal prediction can provide valid prediction interval with\ncoverage guarantees. We also explore the usefulness of interval midpoint and\njudge reprompting for better judgment.", "AI": {"tldr": "LLM\u5728NLG\u8bc4\u4f30\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u5f71\u54cd\u5176\u53ef\u9760\u6027\u3002\u672c\u6587\u7528\u4fdd\u5f62\u9884\u6d4b\u4e3a\u8bc4\u5206\u63d0\u4f9b\u9884\u6d4b\u533a\u95f4\uff0c\u5e76\u8bbe\u8ba1\u65b0\u65b9\u6cd5\u63d0\u5347\u8bc4\u5206\u51c6\u786e\u6027\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "LLM\u88ab\u5e7f\u6cdb\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u751f\u6210\uff08NLG\uff09\u7684\u8bc4\u4f30\uff0c\u4f46\u5176\u8bc4\u4f30\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u5c1a\u672a\u5145\u5206\u7814\u7a76\uff0c\u5f71\u54cd\u4e86\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u5229\u7528\u4fdd\u5f62\u9884\u6d4b\uff08conformal prediction\uff09\u4e3aLLM\u8bc4\u4f30\u5f97\u5206\u63d0\u4f9b\u9884\u6d4b\u533a\u95f4\u7684\u6846\u67b6\uff0c\u5e76\u9488\u5bf9\u79bb\u6563\u8bc4\u5206\u4efb\u52a1\u8bbe\u8ba1\u4e86\u5e8f\u6570\u8fb9\u754c\u8c03\u6574\u3002\u540c\u65f6\u63d0\u51fa\u533a\u95f4\u4e2d\u70b9\u4f5c\u4e3a\u8f83\u4f4e\u504f\u5dee\u7684\u8bc4\u5206\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4fdd\u5f62\u9884\u6d4b\u53ef\u4ee5\u4e3aLLM\u8bc4\u5206\u63d0\u4f9b\u6709\u6548\u7684\u3001\u5e26\u6709\u8986\u76d6\u4fdd\u8bc1\u7684\u9884\u6d4b\u533a\u95f4\u3002\u533a\u95f4\u4e2d\u70b9\u548c\u591a\u6b21\u63d0\u95ee\uff08judge reprompting\uff09\u80fd\u63d0\u5347\u8bc4\u5224\u7ed3\u679c\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u4e3aLLM\u8bc4\u4f30NLG\u4efb\u52a1\u5efa\u7acb\u4e86\u4e0d\u786e\u5b9a\u6027\u5206\u6790\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8bc4\u5206\u7ed3\u679c\u7684\u53ef\u9760\u6027\u53ca\u89e3\u91ca\u6027\u3002"}}
{"id": "2509.18713", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18713", "abs": "https://arxiv.org/abs/2509.18713", "authors": ["Yizhe Huang", "Yang Liu", "Ruiyu Zhao", "Xiaolong Zhong", "Xingming Yue", "Ling Jiang"], "title": "MemOrb: A Plug-and-Play Verbal-Reinforcement Memory Layer for E-Commerce Customer Service", "comment": null, "summary": "Large Language Model-based agents(LLM-based agents) are increasingly deployed\nin customer service, yet they often forget across sessions, repeat errors, and\nlack mechanisms for continual self-improvement. This makes them unreliable in\ndynamic settings where stability and consistency are critical. To better\nevaluate these properties, we emphasize two indicators: task success rate as a\nmeasure of overall effectiveness, and consistency metrics such as Pass$^k$ to\ncapture reliability across multiple trials. To address the limitations of\nexisting approaches, we propose MemOrb, a lightweight and plug-and-play verbal\nreinforcement memory layer that distills multi-turn interactions into compact\nstrategy reflections. These reflections are stored in a shared memory bank and\nretrieved to guide decision-making, without requiring any fine-tuning.\nExperiments show that MemOrb significantly improves both success rate and\nstability, achieving up to a 63 percentage-point gain in multi-turn success\nrate and delivering more consistent performance across repeated trials. Our\nresults demonstrate that structured reflection is a powerful mechanism for\nenhancing long-term reliability of frozen LLM agents in customer service\nscenarios.", "AI": {"tldr": "MemOrb\u662f\u4e00\u79cd\u65b0\u7684\u8bb0\u5fc6\u5c42\u65b9\u6cd5\uff0c\u65e0\u9700\u5fae\u8c03\uff0c\u901a\u8fc7\u7b56\u7565\u53cd\u601d\u63d0\u5347LLM\u4ee3\u7406\u5728\u5ba2\u6237\u670d\u52a1\u4e2d\u7684\u7a33\u5b9a\u6027\u4e0e\u6210\u529f\u7387\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u76ee\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4ee3\u7406\u5728\u5ba2\u6237\u670d\u52a1\u4e2d\u7684\u5e94\u7528\u8d8a\u6765\u8d8a\u5e7f\u6cdb\uff0c\u4f46\u5b58\u5728\u9057\u5fd8\u3001\u91cd\u590d\u9519\u8bef\u3001\u4ee5\u53ca\u7f3a\u4e4f\u6301\u7eed\u81ea\u6211\u6539\u8fdb\u673a\u5236\u7b49\u95ee\u9898\u3002\u8fd9\u4f7f\u5f97\u5b83\u4eec\u5728\u9700\u8981\u7a33\u5b9a\u6027\u548c\u4e00\u81f4\u6027\u7684\u52a8\u6001\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u53ef\u9760\u3002\u4f5c\u8005\u5e0c\u671b\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u5347LLM\u4ee3\u7406\u7684\u7a33\u5b9a\u6027\u548c\u6301\u4e45\u8868\u73b0\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86MemOrb\uff0c\u4e00\u79cd\u8f7b\u91cf\u4e14\u53ef\u63d2\u62d4\u7684\u53e3\u5934\u5f3a\u5316\u8bb0\u5fc6\u5c42\u3002MemOrb\u5c06\u591a\u8f6e\u4ea4\u4e92\u63d0\u70bc\u4e3a\u7b80\u660e\u7684\u7b56\u7565\u53cd\u601d\uff0c\u5e76\u5b58\u50a8\u4e8e\u5171\u4eab\u8bb0\u5fc6\u5e93\u4e2d\uff0c\u5728\u4e0d\u9700\u8981\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u68c0\u7d22\u51fa\u6765\u4ee5\u5f15\u5bfc\u51b3\u7b56\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMemOrb\u663e\u8457\u63d0\u5347\u4e86\u6210\u529f\u7387\u548c\u7cfb\u7edf\u7a33\u5b9a\u6027\uff0c\u5728\u591a\u8f6e\u4ea4\u4e92\u4efb\u52a1\u4e2d\u6210\u529f\u7387\u6700\u9ad8\u63d0\u5347\u4e8663\u4e2a\u767e\u5206\u70b9\uff0c\u5e76\u4e14\u5728\u591a\u6b21\u91cd\u590d\u5b9e\u9a8c\u4e2d\u8868\u73b0\u66f4\u52a0\u4e00\u81f4\u3002", "conclusion": "\u7ed3\u6784\u5316\u53cd\u601d\u662f\u589e\u5f3a\u51bb\u7ed3LLM\u4ee3\u7406\u5728\u5ba2\u6237\u670d\u52a1\u573a\u666f\u4e0b\u957f\u671f\u53ef\u9760\u6027\u7684\u5f3a\u5927\u673a\u5236\u3002"}}
{"id": "2509.18722", "categories": ["cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2509.18722", "abs": "https://arxiv.org/abs/2509.18722", "authors": ["Pattara Tipaksorn", "Sumonmas Thatphithakkul", "Vataya Chunwijitra", "Kwanchiva Thangthai"], "title": "LOTUSDIS: A Thai far-field meeting corpus for robust conversational ASR", "comment": null, "summary": "We present LOTUSDIS, a publicly available Thai meeting corpus designed to\nadvance far-field conversational ASR. The dataset comprises 114 hours of\nspontaneous, unscripted dialogue collected in 15-20 minute sessions with three\nparticipants, where overlapping speech is frequent and natural. Speech was\nrecorded simultaneously by nine independent single-channel devices spanning six\nmicrophone types at distances from 0.12 m to 10 m, preserving the authentic\neffects of reverberation, noise, and device coloration without relying on\nmicrophone arrays. We provide standard train, dev, test splits and release a\nreproducible baseline system. We benchmarked several Whisper variants under\nzero-shot and fine-tuned conditions. Off-the-shelf models showed strong\ndegradation with distance, confirming a mismatch between pre-training data and\nThai far-field speech. Fine-tuning on LOTUSDIS dramatically improved\nrobustness: a Thai Whisper baseline reduced overall WER from 64.3 to 38.3 and\nfar-field WER from 81.6 to 49.5, with especially large gains on the most\ndistant microphones. These results underscore the importance of\ndistance-diverse training data for robust ASR. The corpus is available under\nCC-BY-SA 4.0. We also release training and evaluation scripts as a baseline\nsystem to promote reproducible research in this field.", "AI": {"tldr": "\u4f5c\u8005\u516c\u5f00\u4e86\u4e00\u4e2a\u6cf0\u8bed\u8fdc\u573a\u5bf9\u8bdd\u8bed\u97f3\u6570\u636e\u96c6\u5e76\u63d0\u4f9b\u57fa\u7ebf\u7cfb\u7edf\uff0c\u5fae\u8c03\u540e\u5927\u5e45\u63d0\u5347Whisper\u6a21\u578b\u5728\u8fdc\u8ddd\u79bb\u7684\u8bc6\u522b\u6027\u80fd\uff0c\u5f3a\u8c03\u4e86\u591a\u8ddd\u79bb\u6570\u636e\u5bf9ASR\u9c81\u68d2\u6027\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u9488\u5bf9\u6cf0\u8bed\u8fdc\u573a\u5bf9\u8bdd\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u9886\u57df\u6570\u636e\u548c\u7814\u7a76\u65b9\u6cd5\u532e\u4e4f\u7684\u95ee\u9898\uff0c\u7814\u7a76\u8005\u5f00\u53d1\u4e86\u4e00\u4e2a\u516c\u5f00\u7684\u6cf0\u8bed\u4f1a\u8bae\u8bed\u6599\u5e93\uff0c\u4ee5\u63a8\u52a8\u8fdc\u573aASR\u7684\u8fdb\u6b65\u3002", "method": "\u91c7\u96c6\u4e86114\u5c0f\u65f6\u771f\u4eba\u81ea\u53d1\u5bf9\u8bdd\uff0c\u4e09\u4eba\u5c0f\u7ec4\u81ea\u7531\u4ea4\u8c08\uff0c\u5f55\u5236\u4f7f\u75286\u7c7b9\u53f0\u72ec\u7acb\u5f55\u97f3\u8bbe\u5907\uff0c\u6446\u653e\u8ddd\u79bb\u4ece0.12\u7c73\u523010\u7c73\uff0c\u6db5\u76d6\u4e30\u5bcc\u7684\u8bdd\u7b52\u8ddd\u79bb\u548c\u91cd\u53e0\u8bed\u97f3\u60c5\u5f62\u3002\u6570\u636e\u96c6\u533a\u5206\u8bad\u7ec3\u3001\u5f00\u53d1\u3001\u6d4b\u8bd5\u96c6\uff0c\u5e76\u6784\u5efa\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u7ebfASR\u7cfb\u7edf\uff0c\u8bc4\u4f30\u4e86Whisper\u591a\u79cd\u6a21\u578b\uff08\u96f6\u6837\u672c\u4e0e\u5fae\u8c03\u4e24\u79cd\u65b9\u5f0f\uff09\u3002", "result": "Whisper\u539f\u59cb\u6a21\u578b\u5728\u5904\u7406\u8fdc\u573a\u6cf0\u8bed\u8bed\u97f3\u65f6\u6027\u80fd\u5927\u5e45\u4e0b\u964d\uff0c\u5fae\u8c03\u540e\u663e\u8457\u63d0\u5347\uff1a\u6574\u4f53WER\u753164.3\u964d\u81f338.3\uff0c\u8fdc\u573aWER\u753181.6\u964d\u81f349.5\uff0c\u5c24\u5176\u5728\u6700\u8fdc\u9ea6\u514b\u98ce\u5904\u63d0\u5347\u6700\u4e3a\u660e\u663e\u3002", "conclusion": "\u8ddd\u79bb\u591a\u6837\u5316\u6570\u636e\u5bf9\u8fdc\u573aASR\u7cfb\u7edf\u7684\u7a33\u5065\u6027\u81f3\u5173\u91cd\u8981\u3002LOTUSDIS\u8bed\u6599\u5e93\u4ee5\u53ca\u5f00\u653e\u7684\u57fa\u7ebf\u7cfb\u7edf\u63a8\u52a8\u4e86\u53ef\u590d\u73b0\u7684\u6cf0\u8bed\u8fdc\u573aASR\u7814\u7a76\u3002"}}
{"id": "2509.18742", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18742", "abs": "https://arxiv.org/abs/2509.18742", "authors": ["Yunan Wang", "Jianxin Li", "Ziwei Zhang"], "title": "Global-Recent Semantic Reasoning on Dynamic Text-Attributed Graphs with Large Language Models", "comment": null, "summary": "Dynamic Text-Attribute Graphs (DyTAGs), characterized by time-evolving graph\ninteractions and associated text attributes, are prevalent in real-world\napplications. Existing methods, such as Graph Neural Networks (GNNs) and Large\nLanguage Models (LLMs), mostly focus on static TAGs. Extending these existing\nmethods to DyTAGs is challenging as they largely neglect the recent-global\ntemporal semantics: the recent semantic dependencies among interaction texts\nand the global semantic evolution of nodes over time. Furthermore, applying\nLLMs to the abundant and evolving text in DyTAGs faces efficiency issues. To\ntackle these challenges, we propose Dynamic Global-Recent Adaptive Semantic\nProcessing (DyGRASP), a novel method that leverages LLMs and temporal GNNs to\nefficiently and effectively reason on DyTAGs. Specifically, we first design a\nnode-centric implicit reasoning method together with a sliding window mechanism\nto efficiently capture recent temporal semantics. In addition, to capture\nglobal semantic dynamics of nodes, we leverage explicit reasoning with tailored\nprompts and an RNN-like chain structure to infer long-term semantics. Lastly,\nwe intricately integrate the recent and global temporal semantics as well as\nthe dynamic graph structural information using updating and merging layers.\nExtensive experiments on DyTAG benchmarks demonstrate DyGRASP's superiority,\nachieving up to 34% improvement in Hit@10 for destination node retrieval task.\nBesides, DyGRASP exhibits strong generalization across different temporal GNNs\nand LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7ed3\u5408LLMs\u4e0e\u65f6\u5e8fGNN\u7684\u65b0\u65b9\u6cd5DyGRASP\uff0c\u7528\u521b\u65b0\u673a\u5236\u9ad8\u6548\u5904\u7406\u52a8\u6001\u56fe\u4e2d\u7684\u6587\u672c\u4e0e\u7ed3\u6784\u8bed\u4e49\u6f14\u5316\uff0c\u5b9e\u9a8c\u663e\u8457\u63d0\u5347\u68c0\u7d22\u6027\u80fd\u5e76\u5177\u5907\u826f\u597d\u6cdb\u5316\u6027\u3002", "motivation": "\u52a8\u6001\u6587\u672c\u5c5e\u6027\u56fe\uff08DyTAGs\uff09\u5e7f\u6cdb\u5b58\u5728\u4e8e\u771f\u5b9e\u5e94\u7528\u4e2d\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u591a\u5173\u6ce8\u4e8e\u9759\u6001TAG\uff0c\u672a\u80fd\u6709\u6548\u5904\u7406DyTAG\u4e2d\u7684\u65f6\u5e8f\u6587\u672c\u8bed\u4e49\u6f14\u53d8\uff0c\u4ee5\u53ca\u5982\u4f55\u9ad8\u6548\u4f7f\u7528LLMs\u5904\u7406\u6d77\u91cf\u52a8\u6001\u6587\u672c\u9762\u4e34\u6311\u6218\u3002", "method": "\u63d0\u51faDyGRASP\u65b9\u6cd5\uff0c\u7ed3\u5408LLMs\u548c\u65f6\u5e8fGNNs\uff0c\u901a\u8fc7\u8282\u70b9\u4e2d\u5fc3\u7684\u9690\u5f0f\u63a8\u7406\u4e0e\u6ed1\u52a8\u7a97\u53e3\u673a\u5236\u9ad8\u6548\u6355\u6349\u8fd1\u671f\u8bed\u4e49\uff0c\u540c\u65f6\u5229\u7528\u9488\u5bf9\u6027prompt\u4e0e\u7c7b\u4f3cRNN\u94fe\u5f0f\u7ed3\u6784\u8fdb\u884c\u663e\u5f0f\u63a8\u7406\uff0c\u4ee5\u6355\u6349\u8282\u70b9\u7684\u957f\u671f\u8bed\u4e49\u52a8\u6001\u3002\u968f\u540e\uff0c\u901a\u8fc7\u66f4\u65b0\u548c\u878d\u5408\u5c42\u6709\u6548\u6574\u5408\u8fd1\u671f\u548c\u957f\u671f\u8bed\u4e49\u4ee5\u53ca\u52a8\u6001\u56fe\u7ed3\u6784\u4fe1\u606f\u3002", "result": "\u5728DyTAG\u57fa\u51c6\u4efb\u52a1\u4e0a\uff0cDyGRASP\u5728\u76ee\u6807\u8282\u70b9\u68c0\u7d22\uff08Hit@10\uff09\u6307\u6807\u4e0a\u63d0\u5347\u9ad8\u8fbe34%\u3002\u6b64\u5916\uff0cDyGRASP\u6cdb\u5316\u80fd\u529b\u5f3a\uff0c\u80fd\u9002\u914d\u4e0d\u540c\u7c7b\u578b\u7684\u65f6\u5e8fGNN\u4e0eLLMs\u3002", "conclusion": "DyGRASP\u9ad8\u6548\u878d\u5408\u8fd1\u671f\u548c\u5168\u5c40\u8bed\u4e49\uff0c\u80fd\u6709\u6548\u89e3\u51b3DyTAG\u65f6\u5e8f\u8bed\u4e49\u63a8\u7406\u4e0e\u6548\u7387\u95ee\u9898\uff0c\u5728\u6027\u80fd\u548c\u6cdb\u5316\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2509.18750", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18750", "abs": "https://arxiv.org/abs/2509.18750", "authors": ["Julie Kallini", "Dan Jurafsky", "Christopher Potts", "Martijn Bartelds"], "title": "False Friends Are Not Foes: Investigating Vocabulary Overlap in Multilingual Language Models", "comment": null, "summary": "Subword tokenizers trained on multilingual corpora naturally produce\noverlapping tokens across languages. Does token overlap facilitate\ncross-lingual transfer or instead introduce interference between languages?\nPrior work offers mixed evidence, partly due to varied setups and confounders,\nsuch as token frequency or subword segmentation granularity. To address this\nquestion, we devise a controlled experiment where we train bilingual\nautoregressive models on multiple language pairs under systematically varied\nvocabulary overlap settings. Crucially, we explore a new dimension to\nunderstanding how overlap affects transfer: the semantic similarity of tokens\nshared across languages. We first analyze our models' hidden representations\nand find that overlap of any kind creates embedding spaces that capture\ncross-lingual semantic relationships, while this effect is much weaker in\nmodels with disjoint vocabularies. On XNLI and XQuAD, we find that models with\noverlap outperform models with disjoint vocabularies, and that transfer\nperformance generally improves as overlap increases. Overall, our findings\nhighlight the advantages of token overlap in multilingual models and show that\nsubstantial shared vocabulary remains a beneficial design choice for\nmultilingual tokenizers.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5b9e\u9a8c\u53d1\u73b0\uff0c\u8de8\u8bed\u8a00\u5171\u4eab\u8bcd\u5143\uff08\u5c24\u5176\u6709\u8bed\u4e49\u5173\u8054\uff09\u6709\u52a9\u4e8e\u591a\u8bed\u8a00\u6a21\u578b\u7684\u8fc1\u79fb\u548c\u8bed\u4e49\u80fd\u529b\uff0c\u5efa\u8bae\u591a\u8bed\u8a00\u5206\u8bcd\u5668\u8bbe\u8ba1\u4e2d\u5e94\u4f18\u5148\u8003\u8651\u8bcd\u8868\u5171\u4eab\u3002", "motivation": "\u591a\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5b50\u8bcd\u5206\u8bcd\u5668\u5728\u4e0d\u540c\u8bed\u8a00\u95f4\u81ea\u7136\u4f1a\u4ea7\u751f\u91cd\u53e0\u7684\u8bcd\u5143\uff0c\u4f46\u8fd9\u4e9b\u91cd\u53e0\u7a76\u7adf\u662f\u4fc3\u8fdb\u8de8\u8bed\u8a00\u8fc1\u79fb\u8fd8\u662f\u5f15\u5165\u5e72\u6270\uff0c\u73b0\u6709\u7814\u7a76\u7ed3\u8bba\u4e0d\u4e00\u4e14\u53d7\u5404\u79cd\u53d8\u91cf\u5f71\u54cd\u3002\u4e3a\u5398\u6e05\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u5e0c\u671b\u4ee5\u66f4\u4e25\u683c\u7684\u65b9\u6cd5\u63a2\u7a76\u8bcd\u5143\u91cd\u53e0\u53ca\u5176\u8bed\u4e49\u76f8\u4f3c\u5ea6\u5982\u4f55\u5f71\u54cd\u8de8\u8bed\u8a00\u8fc1\u79fb\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u53d7\u63a7\u5b9e\u9a8c\uff0c\u8bad\u7ec3\u591a\u5bf9\u53cc\u8bed\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u5e76\u7cfb\u7edf\u6027\u6539\u53d8\u5404\u81ea\u7684\u8bcd\u8868\u91cd\u53e0\u7a0b\u5ea6\uff1b\u540c\u65f6\u5206\u6790\u5171\u4eab\u8bcd\u5143\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6\u5bf9\u8de8\u8bed\u8a00\u8fc1\u79fb\u7684\u5f71\u54cd\u3002\u91c7\u7528\u4e86\u6a21\u578b\u9690\u85cf\u8868\u793a\u5206\u6790\uff0c\u53ca\u5728XNLI\u548cXQuAD\u4e0a\u7684\u8fc1\u79fb\u6027\u80fd\u8bc4\u6d4b\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0c\u65e0\u8bba\u4f55\u79cd\u7c7b\u578b\u7684\u8bcd\u5143\u91cd\u53e0\uff0c\u90fd\u80fd\u8ba9\u5d4c\u5165\u7a7a\u95f4\u6355\u6349\u8de8\u8bed\u8a00\u8bed\u4e49\u5173\u7cfb\uff0c\u800c\u8bcd\u8868\u5b8c\u5168\u4e0d\u91cd\u53e0\u65f6\u8fd9\u4e00\u6548\u679c\u660e\u663e\u51cf\u5f31\u3002\u5728\u4e0b\u6e38\u4efb\u52a1XNLI\u548cXQuAD\u4e0a\uff0c\u6709\u8bcd\u5143\u91cd\u53e0\u7684\u6a21\u578b\u6027\u80fd\u4f18\u4e8e\u5b8c\u5168\u72ec\u7acb\u8bcd\u8868\uff0c\u4e14\u91cd\u53e0\u8d8a\u591a\u8868\u73b0\u8d8a\u597d\u3002", "conclusion": "\u8bcd\u5143\u91cd\u53e0\u80fd\u663e\u8457\u6539\u5584\u591a\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u8de8\u8bed\u8a00\u8fc1\u79fb\u4e0e\u8bed\u4e49\u8868\u793a\uff0c\u8bf4\u660e\u5171\u4eab\u8bcd\u8868\u5bf9\u4e8e\u591a\u8bed\u8a00\u5206\u8bcd\u5668\u662f\u6709\u76ca\u7684\u8bbe\u8ba1\u9009\u62e9\u3002"}}
{"id": "2509.18762", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18762", "abs": "https://arxiv.org/abs/2509.18762", "authors": ["Yingming Zheng", "Hanqi Li", "Kai Yu", "Lu Chen"], "title": "When Long Helps Short: How Context Length in Supervised Fine-tuning Affects Behavior of Large Language Models", "comment": null, "summary": "Large language models (LLMs) have achieved impressive performance across\nnatural language processing (NLP) tasks. As real-world applications\nincreasingly demand longer context windows, continued pretraining and\nsupervised fine-tuning (SFT) on long-context data has become a common approach.\nWhile the effects of data length in continued pretraining have been extensively\nstudied, their implications for SFT remain unclear. In this work, we\nsystematically investigate how SFT data length influences LLM behavior on\nshort-context tasks. Counterintuitively, we find that long-context SFT improves\nshort-context performance, contrary to the commonly observed degradation from\nlong-context pretraining. To uncover the underlying mechanisms of this\nphenomenon, we first decouple and analyze two key components, Multi-Head\nAttention (MHA) and Feed-Forward Network (FFN), and show that both\nindependently benefit from long-context SFT. We further study their interaction\nand reveal a knowledge preference bias: long-context SFT promotes contextual\nknowledge, while short-context SFT favors parametric knowledge, making\nexclusive reliance on long-context SFT suboptimal. Finally, we demonstrate that\nhybrid training mitigates this bias, offering explainable guidance for\nfine-tuning LLMs.", "AI": {"tldr": "\u957f\u6587\u672cSFT\u53ef\u63d0\u5347\u77ed\u6587\u672c\u4efb\u52a1\u8868\u73b0\uff0c\u4f46\u5b58\u5728\u77e5\u8bc6\u504f\u7f6e\uff0c\u6df7\u5408\u8bad\u7ec3\u65b9\u6848\u66f4\u4f18\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u4f18\u5f02\u6210\u7ee9\uff0c\u5bf9\u66f4\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u80fd\u529b\u7684\u9700\u6c42\u65e5\u76ca\u589e\u52a0\u3002\u867d\u7136\u5ef6\u7eed\u9884\u8bad\u7ec3\u65f6\u6570\u636e\u957f\u5ea6\u7684\u5f71\u54cd\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5176\u5728\u6709\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u9636\u6bb5\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u6027\u5730\u63a2\u7d22SFT\u65f6\u957f\u6587\u672c\u6570\u636e\u5bf9\u77ed\u6587\u672c\u4efb\u52a1\u8868\u73b0\u7684\u4f5c\u7528\u3002", "method": "\u7cfb\u7edf\u6027\u7814\u7a76SFT\u6570\u636e\u957f\u5ea6\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u77ed\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u8868\u73b0\u7684\u5f71\u54cd\uff0c\u5206\u522b\u5206\u6790\u591a\u5934\u6ce8\u610f\u529b\uff08MHA\uff09\u548c\u524d\u9988\u795e\u7ecf\u7f51\u7edc\uff08FFN\uff09\u7ec4\u4ef6\uff0c\u5e76\u7814\u7a76\u5b83\u4eec\u4e4b\u95f4\u7684\u4ea4\u4e92\u4e0e\u77e5\u8bc6\u504f\u597d\u504f\u7f6e\u3002\u540c\u65f6\uff0c\u9a8c\u8bc1\u6df7\u5408\u8bad\u7ec3\u80fd\u5426\u7f13\u89e3\u504f\u7f6e\u3002", "result": "\uff081\uff09\u957f\u4e0a\u4e0b\u6587SFT\u53cd\u800c\u63d0\u5347\u4e86\u6a21\u578b\u5728\u77ed\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u4e0e\u5f53\u524d\u957f\u4e0a\u4e0b\u6587\u9884\u8bad\u7ec3\u4e0b\u964d\u7684\u5e38\u89c1\u89c2\u70b9\u76f8\u53cd\uff1b\uff082\uff09MHA\u548cFFN\u4e24\u4e2a\u6a21\u5757\u72ec\u7acb\u5747\u80fd\u53d7\u76ca\u4e8e\u957f\u6587\u672cSFT\uff1b\uff083\uff09\u957f\u6587\u672cSFT\u66f4\u4fc3\u8fdb\u4e0a\u4e0b\u6587\u77e5\u8bc6\uff0c\u77ed\u6587\u672cSFT\u66f4\u503e\u5411\u53c2\u6570\u77e5\u8bc6\uff0c\u53ea\u7528\u957f\u6587\u672cSFT\u4f1a\u6709\u504f\u7f6e\u95ee\u9898\uff1b\uff084\uff09\u6df7\u5408\u8bad\u7ec3\u80fd\u6709\u6548\u51cf\u8f7b\u8be5\u504f\u7f6e\u3002", "conclusion": "\u53ea\u7528\u957f\u6587\u672cSFT\u5e76\u975e\u6700\u4f18\u7b56\u7565\uff0c\u5e94\u91c7\u7528\u6df7\u5408\u8bad\u7ec3\u4ee5\u5e73\u8861\u4e0d\u540c\u7c7b\u578b\u77e5\u8bc6\u7684\u4e60\u5f97\uff0c\u4ece\u800c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u63d0\u4f9b\u89e3\u91ca\u6027\u6307\u5bfc\u3002"}}
{"id": "2509.18775", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.18775", "abs": "https://arxiv.org/abs/2509.18775", "authors": ["Wei-Ning Chiu", "Yu-Hsiang Wang", "Andy Hsiao", "Yu-Shiang Huang", "Chuan-Ju Wang"], "title": "Financial Risk Relation Identification through Dual-view Adaptation", "comment": "11 pages, 3 figures, EMNLP 2025 Main Conference", "summary": "A multitude of interconnected risk events -- ranging from regulatory changes\nto geopolitical tensions -- can trigger ripple effects across firms.\nIdentifying inter-firm risk relations is thus crucial for applications like\nportfolio management and investment strategy. Traditionally, such assessments\nrely on expert judgment and manual analysis, which are, however, subjective,\nlabor-intensive, and difficult to scale. To address this, we propose a\nsystematic method for extracting inter-firm risk relations using Form 10-K\nfilings -- authoritative, standardized financial documents -- as our data\nsource. Leveraging recent advances in natural language processing, our approach\ncaptures implicit and abstract risk connections through unsupervised\nfine-tuning based on chronological and lexical patterns in the filings. This\nenables the development of a domain-specific financial encoder with a deeper\ncontextual understanding and introduces a quantitative risk relation score for\ntransparency, interpretable analysis. Extensive experiments demonstrate that\nour method outperforms strong baselines across multiple evaluation settings.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e10-K\u8d22\u62a5\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u65b0\u65b9\u6cd5\uff0c\u81ea\u52a8\u3001\u5ba2\u89c2\u5730\u8bc6\u522b\u516c\u53f8\u95f4\u98ce\u9669\u5173\u7cfb\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u65b0\u65b9\u6cd5\u6548\u679c\u4f18\u4e8e\u4e3b\u6d41\u6a21\u578b\uff0c\u4e3a\u91d1\u878d\u98ce\u9669\u7ba1\u7406\u5e26\u6765\u66f4\u9ad8\u6548\u548c\u53ef\u9760\u7684\u5de5\u5177\u3002", "motivation": "\u73b0\u6709\u7684\u516c\u53f8\u95f4\u98ce\u9669\u5173\u7cfb\u8bc6\u522b\u4e3b\u8981\u4f9d\u9760\u4e13\u5bb6\u5224\u65ad\u548c\u4eba\u5de5\u5206\u6790\uff0c\u8fc7\u7a0b\u4e3b\u89c2\u3001\u8d39\u529b\u4e14\u96be\u4ee5\u6269\u5c55\uff0c\u968f\u7740\u98ce\u9669\u4e8b\u4ef6\uff08\u5982\u76d1\u7ba1\u53d8\u52a8\u3001\u5730\u7f18\u653f\u6cbb\u7d27\u5f20\uff09\u9891\u7e41\u53d1\u751f\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u5206\u6790\u516c\u53f8\u95f4\u7684\u98ce\u9669\u5173\u8054\u3002", "method": "\u5229\u752810-K\u8868\u683c\u7b49\u6743\u5a01\u3001\u6807\u51c6\u5316\u8d22\u52a1\u6587\u4ef6\u4f5c\u4e3a\u6570\u636e\u6e90\uff0c\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u5904\u7406\u524d\u6cbf\u6280\u672f\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u5fae\u8c03\u624b\u6bb5\u6316\u6398\u6587\u4ef6\u7684\u65f6\u5e8f\u548c\u8bcd\u6c47\u6a21\u5f0f\uff0c\u4ee5\u6b64\u5efa\u7acb\u9886\u57df\u4e13\u7528\u91d1\u878d\u6587\u672c\u7f16\u7801\u5668\uff0c\u5e76\u63d0\u51fa\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u5b9a\u91cf\u98ce\u9669\u5173\u8054\u8bc4\u5206\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u591a\u4e2a\u8bc4\u4f30\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u5f53\u524d\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u6709\u6548\u5730\u8bc6\u522b\u548c\u91cf\u5316\u516c\u53f8\u95f4\u7684\u98ce\u9669\u5173\u7cfb\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5316\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u3001\u5ba2\u89c2\u5730\u5206\u6790\u516c\u53f8\u95f4\u7684\u98ce\u9669\u5173\u7cfb\uff0c\u4e3a\u6295\u8d44\u7ec4\u5408\u7ba1\u7406\u548c\u6295\u8d44\u7b56\u7565\u7b49\u9886\u57df\u63d0\u4f9b\u66f4\u900f\u660e\u3001\u53ef\u6269\u5c55\u7684\u98ce\u9669\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2509.18776", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18776", "abs": "https://arxiv.org/abs/2509.18776", "authors": ["Chen Liang", "Zhaoqi Huang", "Haofen Wang", "Fu Chai", "Chunying Yu", "Huanhuan Wei", "Zhengjie Liu", "Yanpeng Li", "Hongjun Wang", "Ruifeng Luo", "Xianzhong Zhao"], "title": "AECBench: A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field", "comment": null, "summary": "Large language models (LLMs), as a novel information technology, are seeing\nincreasing adoption in the Architecture, Engineering, and Construction (AEC)\nfield. They have shown their potential to streamline processes throughout the\nbuilding lifecycle. However, the robustness and reliability of LLMs in such a\nspecialized and safety-critical domain remain to be evaluated. To address this\nchallenge, this paper establishes AECBench, a comprehensive benchmark designed\nto quantify the strengths and limitations of current LLMs in the AEC domain.\nThe benchmark defines 23 representative tasks within a five-level\ncognition-oriented evaluation framework encompassing Knowledge Memorization,\nUnderstanding, Reasoning, Calculation, and Application. These tasks were\nderived from authentic AEC practice, with scope ranging from codes retrieval to\nspecialized documents generation. Subsequently, a 4,800-question dataset\nencompassing diverse formats, including open-ended questions, was crafted\nprimarily by engineers and validated through a two-round expert review.\nFurthermore, an LLM-as-a-Judge approach was introduced to provide a scalable\nand consistent methodology for evaluating complex, long-form responses\nleveraging expert-derived rubrics. Through the evaluation of nine LLMs, a clear\nperformance decline across five cognitive levels was revealed. Despite\ndemonstrating proficiency in foundational tasks at the Knowledge Memorization\nand Understanding levels, the models showed significant performance deficits,\nparticularly in interpreting knowledge from tables in building codes, executing\ncomplex reasoning and calculation, and generating domain-specific documents.\nConsequently, this study lays the groundwork for future research and\ndevelopment aimed at the robust and reliable integration of LLMs into\nsafety-critical engineering practices.", "AI": {"tldr": "\u901a\u8fc7\u6784\u5efaAECBench\u57fa\u51c6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u73b0\u6709LLM\u5728\u5efa\u7b51\u5de5\u7a0b\u9886\u57df\u591a\u8ba4\u77e5\u4efb\u52a1\u4e0a\u7684\u5f3a\u5f31\u3002\u7ed3\u679c\u663e\u793a\u73b0\u6709\u6a21\u578b\u5728\u57fa\u7840\u4efb\u52a1\u4e0a\u8868\u73b0\u5c1a\u53ef\uff0c\u4f46\u5728\u9ad8\u9636\u5b9e\u9645\u5e94\u7528\u4e2d\u4ecd\u6709\u660e\u663e\u77ed\u677f\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5efa\u7b51\u3001\u5de5\u7a0b\u548c\u65bd\u5de5\uff08AEC\uff09\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u80fd\u663e\u8457\u63d0\u5347\u5efa\u7b51\u5168\u751f\u547d\u5468\u671f\u6d41\u7a0b\u6548\u7387\uff0c\u4f46\u5176\u5728\u4e13\u4e1a\u6027\u5f3a\u4e14\u5b89\u5168\u5173\u952e\u7684\u9886\u57df\u5185\u7684\u53ef\u9760\u6027\u548c\u7a33\u5065\u6027\u8fd8\u672a\u5f97\u5230\u7cfb\u7edf\u8bc4\u4f30\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e13\u95e8\u7684\u8bc4\u6d4b\u57fa\u51c6\u3002", "method": "\u63d0\u51fa\u5e76\u6784\u5efa\u4e86AECBench\u57fa\u51c6\uff0c\u5305\u62ec\u57fa\u4e8e\u4e94\u7ea7\u8ba4\u77e5\u6846\u67b6\u768423\u9879\u5178\u578b\u4efb\u52a1\u3002\u6846\u67b6\u8986\u76d6\u77e5\u8bc6\u8bb0\u5fc6\u3001\u7406\u89e3\u3001\u63a8\u7406\u3001\u8ba1\u7b97\u3001\u5e94\u7528\uff0c\u4efb\u52a1\u5185\u5bb9\u6e90\u4e8e\u5b9e\u9645AEC\u573a\u666f\u3002\u8bbe\u8ba1\u4e86\u542b\u591a\u79cd\u683c\u5f0f\u76844800\u9053\u9898\uff0c\u7531\u5de5\u7a0b\u5e08\u5236\u5b9a\u5e76\u7ecf\u4e13\u5bb6\u53cc\u8f6e\u5ba1\u6838\u3002\u8bc4\u4ef7\u65b9\u6cd5\u521b\u65b0\u5730\u91c7\u7528\u201cLLM\u8bc4\u5224\u8005\u201d\u673a\u5236\uff0c\u6839\u636e\u4e13\u5bb6\u8bc4\u5206\u6807\u51c6\u5bf9\u590d\u6742\u95ee\u7b54\u7ed3\u679c\u8fdb\u884c\u4e00\u81f4\u4e14\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u3002", "result": "\u5bf99\u4e2a\u4e3b\u6d41LLM\u7684\u8bc4\u6d4b\u63ed\u793a\u5176\u5728\u4e94\u4e2a\u8ba4\u77e5\u5c42\u7ea7\u4e0a\u6027\u80fd\u9010\u7ea7\u4e0b\u964d\u3002\u867d\u7136\u5728\u57fa\u7840\u7684\u77e5\u8bc6\u8bb0\u5fc6\u548c\u7406\u89e3\u5c42\u8868\u73b0\u8f83\u597d\uff0c\u4f46\u5728\u6267\u884c\u590d\u6742\u63a8\u7406\u3001\u8ba1\u7b97\u3001\u8bfb\u53d6\u5efa\u7b51\u89c4\u8303\u8868\u683c\u3001\u751f\u6210\u4e13\u7528\u6587\u4ef6\u7b49\u9ad8\u7ea7\u4efb\u52a1\u4e0a\u5b58\u5728\u660e\u663e\u4e0d\u8db3\u3002", "conclusion": "\u672c\u6587\u5960\u5b9a\u4e86\u672a\u6765\u5c06LLMs\u7a33\u5065\u3001\u53ef\u9760\u5730\u96c6\u6210\u81f3\u5b89\u5168\u5173\u952e\u5de5\u7a0b\u5b9e\u8df5\u7684\u57fa\u7840\uff0c\u4e3a\u8be5\u9886\u57df\u8fdb\u4e00\u6b65\u7814\u53d1\u548c\u5e94\u7528\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2509.18792", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18792", "abs": "https://arxiv.org/abs/2509.18792", "authors": ["Sabri Boughorbel", "Fahim Dalvi", "Nadir Durrani", "Majd Hawasly"], "title": "Beyond the Leaderboard: Understanding Performance Disparities in Large Language Models via Model Diffing", "comment": "12 pages, accepted to the 2025 Conference on Empirical Methods in\n  Natural Language Processing (EMNLP 2025)", "summary": "As fine-tuning becomes the dominant paradigm for improving large language\nmodels (LLMs), understanding what changes during this process is increasingly\nimportant. Traditional benchmarking often fails to explain why one model\noutperforms another. In this work, we use model diffing, a mechanistic\ninterpretability approach, to analyze the specific capability differences\nbetween Gemma-2-9b-it and a SimPO-enhanced variant. Using crosscoders, we\nidentify and categorize latent representations that differentiate the two\nmodels. We find that SimPO acquired latent concepts predominantly enhance\nsafety mechanisms (+32.8%), multilingual capabilities (+43.8%), and\ninstruction-following (+151.7%), while its additional training also reduces\nemphasis on model self-reference (-44.1%) and hallucination management\n(-68.5%). Our analysis shows that model diffing can yield fine-grained insights\nbeyond leaderboard metrics, attributing performance gaps to concrete\nmechanistic capabilities. This approach offers a transparent and targeted\nframework for comparing LLMs.", "AI": {"tldr": "\u672c\u6587\u91c7\u7528\u6a21\u578b\u5bf9\u6bd4\u6280\u672f\uff0c\u7ec6\u81f4\u5206\u6790\u4e86\u4e24\u6b3e\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u540e\u7684\u80fd\u529b\u5dee\u5f02\uff0c\u53d1\u73b0SimPO\u589e\u5f3a\u7248\u5728\u5b89\u5168\u3001\u591a\u8bed\u8a00\u548c\u6307\u4ee4\u9075\u4ece\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u540c\u65f6\u51cf\u5c11\u5bf9\u81ea\u6211\u6307\u6d89\u4e0e\u5e7b\u89c9\u7ba1\u7406\u7684\u5173\u6ce8\u3002\u8be5\u65b9\u6cd5\u4e3a\u7406\u89e3\u6a21\u578b\u6027\u80fd\u5dee\u5f02\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u91ca\u5de5\u5177\u3002", "motivation": "\u968f\u7740\u5fae\u8c03\u6210\u4e3a\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u4e3b\u6d41\u65b9\u6cd5\uff0c\u4e86\u89e3\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u6a21\u578b\u53d1\u751f\u7684\u5177\u4f53\u53d8\u5316\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u4f20\u7edf\u7684\u57fa\u51c6\u6d4b\u8bd5\u5f80\u5f80\u65e0\u6cd5\u89e3\u91ca\u4e00\u4e2a\u6a21\u578b\u4e3a\u4f55\u4f18\u4e8e\u53e6\u4e00\u4e2a\u6a21\u578b\u3002", "method": "\u91c7\u7528\u6a21\u578b\u5bf9\u6bd4\uff08model diffing\uff09\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u673a\u68b0\u53ef\u89e3\u91ca\u6027\u5206\u6790\u6280\u672f\u3002\u5177\u4f53\u901a\u8fc7crosscoders\u5de5\u5177\uff0c\u8bc6\u522b\u5e76\u5206\u7c7b\u4e24\u6b3e\u6a21\u578b\uff08Gemma-2-9b-it\u4e0eSimPO\u589e\u5f3a\u7248\uff09\u4e4b\u95f4\u7684\u6f5c\u5728\u8868\u793a\u5dee\u5f02\u3002", "result": "SimPO\u901a\u8fc7\u989d\u5916\u8bad\u7ec3\u83b7\u5f97\u7684\u6f5c\u5728\u6982\u5ff5\u4e3b\u8981\u589e\u5f3a\u4e86\u5b89\u5168\u673a\u5236\uff08\u63d0\u534732.8%\uff09\u3001\u591a\u8bed\u8a00\u80fd\u529b\uff08\u63d0\u534743.8%\uff09\u548c\u6307\u4ee4\u9075\u4ece\u6027\uff08\u63d0\u5347151.7%\uff09\uff1b\u540c\u65f6\u5bf9\u6a21\u578b\u81ea\u6211\u6307\u6d89\uff08\u964d\u4f4e44.1%\uff09\u548c\u5e7b\u89c9\u7ba1\u7406\u80fd\u529b\uff08\u964d\u4f4e68.5%\uff09\u7684\u5173\u6ce8\u6709\u6240\u51cf\u5c11\u3002", "conclusion": "\u6a21\u578b\u5bf9\u6bd4\u5206\u6790\u4e0d\u4ec5\u80fd\u63ed\u793a\u6392\u884c\u699c\u65e0\u6cd5\u4f53\u73b0\u7684\u7ec6\u7c92\u5ea6\u80fd\u529b\u5dee\u5f02\uff0c\u4e5f\u80fd\u5c06\u6027\u80fd\u5dee\u8ddd\u5f52\u56e0\u5230\u5177\u4f53\u7684\u673a\u68b0\u80fd\u529b\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u6bd4\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u53ef\u9488\u5bf9\u6027\u7684\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2509.18813", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.18813", "abs": "https://arxiv.org/abs/2509.18813", "authors": ["Liting Zhang", "Shiwan Zhao", "Aobo Kong", "Qicheng Li"], "title": "MAPEX: A Multi-Agent Pipeline for Keyphrase Extraction", "comment": null, "summary": "Keyphrase extraction is a fundamental task in natural language processing.\nHowever, existing unsupervised prompt-based methods for Large Language Models\n(LLMs) often rely on single-stage inference pipelines with uniform prompting,\nregardless of document length or LLM backbone. Such one-size-fits-all designs\nhinder the full exploitation of LLMs' reasoning and generation capabilities,\nespecially given the complexity of keyphrase extraction across diverse\nscenarios. To address these challenges, we propose MAPEX, the first framework\nthat introduces multi-agent collaboration into keyphrase extraction. MAPEX\ncoordinates LLM-based agents through modules for expert recruitment, candidate\nextraction, topic guidance, knowledge augmentation, and post-processing. A\ndual-path strategy dynamically adapts to document length: knowledge-driven\nextraction for short texts and topic-guided extraction for long texts.\nExtensive experiments on six benchmark datasets across three different LLMs\ndemonstrate its strong generalization and universality, outperforming the\nstate-of-the-art unsupervised method by 2.44\\% and standard LLM baselines by\n4.01\\% in F1@5 on average. Code is available at\nhttps://github.com/NKU-LITI/MAPEX.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6MAPEX\u7528\u4e8e\u5173\u952e\u77ed\u8bed\u63d0\u53d6\uff0c\u901a\u8fc7\u4e13\u5bb6\u62db\u52df\u4e0e\u52a8\u6001\u53cc\u8def\u5f84\u7b56\u7565\uff0c\u63d0\u5347\u4e86LLM\u7684\u5173\u952e\u77ed\u8bed\u63d0\u53d6\u80fd\u529b\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aMAPEX\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5177\u6709\u826f\u597d\u7684\u901a\u7528\u6027\u548c\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7528\u4e8e\u5173\u952e\u77ed\u8bed\u63d0\u53d6\u65f6\uff0c\u591a\u6570\u65e0\u76d1\u7763\u63d0\u793a\u65b9\u6cd5\u91c7\u7528\u5355\u4e00\u63a8\u7406\u6d41\u7a0b\u548c\u7edf\u4e00\u63d0\u793a\u7b56\u7565\uff0c\u65e0\u8bba\u6587\u6863\u957f\u5ea6\u6216\u6a21\u578b\u67b6\u6784\u3002\u8fd9\u79cd\u4e00\u5200\u5207\u8bbe\u8ba1\u96be\u4ee5\u5145\u5206\u53d1\u6325LLM\u7684\u63a8\u7406\u548c\u751f\u6210\u80fd\u529b\uff0c\u9650\u5236\u4e86\u5728\u591a\u6837\u573a\u666f\u4e0b\u7684\u5e94\u7528\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u540d\u4e3aMAPEX\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5173\u952e\u77ed\u8bed\u63d0\u53d6\u6846\u67b6\u3002MAPEX\u901a\u8fc7\u4e13\u5bb6\u62db\u52df\u3001\u5019\u9009\u63d0\u53d6\u3001\u4e3b\u9898\u5f15\u5bfc\u3001\u77e5\u8bc6\u589e\u5f3a\u548c\u540e\u5904\u7406\u7b49\u6a21\u5757\u534f\u8c03\u4e0d\u540cLLM\u667a\u80fd\u4f53\uff0c\u91c7\u7528\u53cc\u8def\u5f84\u7b56\u7565\uff1a\u5bf9\u77ed\u6587\u672c\u91c7\u7528\u77e5\u8bc6\u9a71\u52a8\u63d0\u53d6\uff0c\u5bf9\u957f\u6587\u672c\u91c7\u7528\u4e3b\u9898\u5f15\u5bfc\u63d0\u53d6\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548c\u4e09\u79cd\u4e0d\u540cLLM\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0cMAPEX\u5728F1@5\u4e0a\u5e73\u5747\u8d85\u8fc7\u73b0\u6709\u6700\u5148\u8fdb\u65e0\u76d1\u7763\u65b9\u6cd52.44%\uff0c\u6bd4\u6807\u51c6LLM\u57fa\u7ebf\u9ad84.01%\uff0c\u5c55\u73b0\u51fa\u5f3a\u6cdb\u5316\u548c\u901a\u7528\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u591a\u667a\u80fd\u4f53\u548c\u52a8\u6001\u53cc\u8def\u5f84\u673a\u5236\uff0cMAPEX\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u65e0\u76d1\u7763\u5173\u952e\u77ed\u8bed\u63d0\u53d6\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u4e3a\u8de8\u6587\u6863\u957f\u5ea6\u548c\u6a21\u578b\u67b6\u6784\u7684\u573a\u666f\u63d0\u4f9b\u4e86\u66f4\u5177\u9002\u5e94\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.18843", "categories": ["cs.CL", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.18843", "abs": "https://arxiv.org/abs/2509.18843", "authors": ["Damian Stachura", "Joanna Konieczna", "Artur Nowak"], "title": "Are Smaller Open-Weight LLMs Closing the Gap to Proprietary Models for Biomedical Question Answering?", "comment": "CLEF 2025 Working Notes, 9-12 September 2025, Madrid, Spain", "summary": "Open-weight versions of large language models (LLMs) are rapidly advancing,\nwith state-of-the-art models like DeepSeek-V3 now performing comparably to\nproprietary LLMs. This progression raises the question of whether small\nopen-weight LLMs are capable of effectively replacing larger closed-source\nmodels. We are particularly interested in the context of biomedical\nquestion-answering, a domain we explored by participating in Task 13B Phase B\nof the BioASQ challenge. In this work, we compare several open-weight models\nagainst top-performing systems such as GPT-4o, GPT-4.1, Claude 3.5 Sonnet, and\nClaude 3.7 Sonnet. To enhance question answering capabilities, we use various\ntechniques including retrieving the most relevant snippets based on embedding\ndistance, in-context learning, and structured outputs. For certain submissions,\nwe utilize ensemble approaches to leverage the diverse outputs generated by\ndifferent models for exact-answer questions. Our results demonstrate that\nopen-weight LLMs are comparable to proprietary ones. In some instances,\nopen-weight LLMs even surpassed their closed counterparts, particularly when\nensembling strategies were applied. All code is publicly available at\nhttps://github.com/evidenceprime/BioASQ-13b.", "AI": {"tldr": "\u4f5c\u8005\u6bd4\u8f83\u5f00\u6e90\u548c\u95ed\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u7269\u533b\u5b66\u95ee\u7b54\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5f00\u6e90\u6a21\u578b\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u53ef\u5ab2\u7f8e\u751a\u81f3\u8d85\u8d8a\u95ed\u6e90\u5927\u6a21\u578b\uff0c\u96c6\u6210\u7b56\u7565\u5c24\u4e3a\u6709\u6548\uff0c\u76f8\u5173\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5f00\u6e90\u7248\u672c\u7684\u80fd\u529b\u9010\u6e10\u8ffd\u4e0a\u4e86\u4e13\u6709\u6a21\u578b\uff0c\u4f5c\u8005\u5173\u6ce8\u5c0f\u578b\u5f00\u6e90LLMs\u80fd\u5426\u6709\u6548\u53d6\u4ee3\u5c01\u95ed\u5927\u578b\u6a21\u578b\uff0c\u5c24\u5176\u5728\u751f\u7269\u533b\u5b66\u95ee\u7b54\u9886\u57df\u3002", "method": "\u5bf9\u6bd4\u591a\u79cd\u5f00\u6e90\u6a21\u578b\u4e0e\u5982GPT-4o\u3001GPT-4.1\u3001Claude 3.5/3.7\u7b49\u9876\u5c16\u95ed\u6e90\u7cfb\u7edf\uff0c\u91c7\u7528\u7247\u6bb5\u68c0\u7d22\u3001\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001\u7ed3\u6784\u5316\u8f93\u51fa\uff0c\u5e76\u9488\u5bf9\u90e8\u5206\u6a21\u578b\u91c7\u7528\u96c6\u6210\u7b56\u7565\u63d0\u5347\u95ee\u7b54\u80fd\u529b\u3002", "result": "\u5f00\u6e90LLMs\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u5df2\u80fd\u5ab2\u7f8e\u751a\u81f3\u8d85\u8d8a\u95ed\u6e90\u6a21\u578b\uff0c\u5c24\u5176\u96c6\u6210\u7b56\u7565\u4e0b\u8868\u73b0\u66f4\u4e3a\u7a81\u51fa\u3002", "conclusion": "\u5c0f\u578b\u5f00\u6e90LLMs\u5728\u751f\u7269\u533b\u5b66\u95ee\u7b54\u7b49\u4e13\u4e1a\u9886\u57df\uff0c\u6709\u6f5c\u529b\u66ff\u4ee3\u90e8\u5206\u5927\u578b\u95ed\u6e90\u6a21\u578b\u3002\u6240\u6709\u4ee3\u7801\u5df2\u5f00\u6e90\u516c\u5e03\u3002"}}
{"id": "2509.18862", "categories": ["cs.CL", "I.2.7; I.2.1"], "pdf": "https://arxiv.org/pdf/2509.18862", "abs": "https://arxiv.org/abs/2509.18862", "authors": ["Luyan Zhang", "Xinyu Xie"], "title": "Multi-Hierarchical Feature Detection for Large Language Model Generated Text", "comment": "9 pages, 6 tables, empirical study on multi-feature AI text detection", "summary": "With the rapid advancement of large language model technology, there is\ngrowing interest in whether multi-feature approaches can significantly improve\nAI text detection beyond what single neural models achieve. While intuition\nsuggests that combining semantic, syntactic, and statistical features should\nprovide complementary signals, this assumption has not been rigorously tested\nwith modern LLM-generated text. This paper provides a systematic empirical\ninvestigation of multi-hierarchical feature integration for AI text detection,\nspecifically testing whether the computational overhead of combining multiple\nfeature types is justified by performance gains. We implement MHFD\n(Multi-Hierarchical Feature Detection), integrating DeBERTa-based semantic\nanalysis, syntactic parsing, and statistical probability features through\nadaptive fusion. Our investigation reveals important negative results: despite\ntheoretical expectations, multi-feature integration provides minimal benefits\n(0.4-0.5% improvement) while incurring substantial computational costs (4.2x\noverhead), suggesting that modern neural language models may already capture\nmost relevant detection signals efficiently. Experimental results on multiple\nbenchmark datasets demonstrate that the MHFD method achieves 89.7% accuracy in\nin-domain detection and maintains 84.2% stable performance in cross-domain\ndetection, showing modest improvements of 0.4-2.6% over existing methods.", "AI": {"tldr": "\u8bba\u6587\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e86\u591a\u5c42\u7ea7\u7279\u5f81\u96c6\u6210\u5728AI\u6587\u672c\u68c0\u6d4b\u4e2d\u7684\u4f5c\u7528\uff0c\u53d1\u73b0\u6027\u80fd\u63d0\u5347\u6781\u4e3a\u6709\u9650\u4e14\u6210\u672c\u9ad8\uff0c\u8868\u660e\u5355\u4e00\u795e\u7ecf\u6a21\u578b\u5df2\u5f88\u9ad8\u6548\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u6280\u672f\u5feb\u901f\u53d1\u5c55\uff0c\u5b66\u754c\u5173\u6ce8\u591a\u7279\u5f81\u878d\u5408\u662f\u5426\u80fd\u663e\u8457\u63d0\u5347AI\u6587\u672c\u68c0\u6d4b\u6027\u80fd\u3002\u867d\u7136\u7406\u8bba\u4e0a\u8bed\u4e49\u3001\u53e5\u6cd5\u548c\u7edf\u8ba1\u7279\u5f81\u7684\u7ed3\u5408\u7406\u5e94\u6709\u4e92\u8865\u4f18\u52bf\uff0c\u4f46\u5728\u73b0\u4ee3LLM\u751f\u6210\u6587\u672c\u4e0b\u7f3a\u4e4f\u4e25\u683c\u5b9e\u8bc1\u3002\u4f5c\u8005\u65e8\u5728\u68c0\u9a8c\u591a\u7279\u5f81\u878d\u5408\u7684\u5b9e\u7528\u4ef7\u503c\u3002", "method": "\u63d0\u51faMHFD\uff08Multi-Hierarchical Feature Detection\uff09\uff0c\u878d\u5408DeBERTa\u8bed\u4e49\u5206\u6790\u3001\u53e5\u6cd5\u89e3\u6790\u548c\u7edf\u8ba1\u6982\u7387\u7279\u5f81\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u673a\u5236\u8fdb\u884c\u96c6\u6210\uff0c\u5bf9\u6bd4\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMHFD\u5728\u6587\u672c\u68c0\u6d4b\u51c6\u786e\u7387\u4e0a\uff0c\u5728\u540c\u57df\u8fbe89.7%\u3001\u8de8\u57df\u7a33\u5b9a\u4fdd\u630184.2%\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u67090.4-2.6%\u7684\u63d0\u5347\uff0c\u4f46\u878d\u5408\u5e26\u6765\u7684\u6027\u80fd\u6539\u5584\u4ec5\u67090.4-0.5%\uff0c\u8ba1\u7b97\u5f00\u9500\u5374\u589e\u52a04.2\u500d\u3002", "conclusion": "\u591a\u5c42\u7ea7\u7279\u5f81\u878d\u5408\u5bf9\u73b0\u4ee3AI\u6587\u672c\u68c0\u6d4b\u63d0\u5347\u6709\u9650\uff0c\u6210\u672c\u8fdc\u9ad8\u4e8e\u6536\u76ca\uff0c\u8868\u660e\u5f53\u524d\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\u5df2\u80fd\u5145\u5206\u6355\u6349\u5173\u952e\u68c0\u6d4b\u4fe1\u53f7\uff0c\u591a\u7279\u5f81\u96c6\u6210\u7684\u6295\u5165\u96be\u4ee5\u88ab\u5b9e\u9645\u6027\u80fd\u589e\u76ca\u6240\u8bc1\u660e\u3002"}}
