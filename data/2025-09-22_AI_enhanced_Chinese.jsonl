{"id": "2509.16172", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2509.16172", "abs": "https://arxiv.org/abs/2509.16172", "authors": ["Sergei Leonov", "Liam Davis"], "title": "Two Optimizations on the St\u00e5lmarck Procedure", "comment": "Presented at the FMCAD 2025 Student Forum. Not part of the official\n  FMCAD proceedings", "summary": "In this paper, we introduce StalmarckSAT, the a modern re-implementation of\nthe St\\aa lmarck Procedure for SAT solving, and present two novel strategies to\nimprove the Procedure, Cardinality Driven Branching (CDB) and Deductive\nPriority Ordering (DPO). CDB is a heuristic to improve branching with the\ndilemma rule, and DPO intelligently orders simple rules based on their\ndeductive potential. Our results demonstrate improved solve times with both\nstrategies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8eSt\u00e5 lmarck\u8fc7\u7a0b\u7684\u73b0\u4ee3SAT\u6c42\u89e3\u5668StalmarckSAT\uff0c\u5e76\u7528\u4e24\u4e2a\u65b0\u7b56\u7565\uff08CDB\u548cDPO\uff09\u63d0\u5347\u4e86\u89e3\u9898\u6548\u7387\uff0c\u5b9e\u9a8c\u6548\u679c\u660e\u663e\u3002", "motivation": "\u73b0\u6709St\u00e5 lmarck\u8fc7\u7a0b\u5728SAT\u95ee\u9898\u4e0a\u7684\u5206\u652f\u548c\u63a8\u7406\u6548\u7387\u6709\u9650\uff0c\u4e9f\u9700\u6539\u8fdb\u4ee5\u63d0\u5347\u6c42\u89e3\u80fd\u529b\u3002", "method": "\u672c\u6587\u91cd\u65b0\u5b9e\u73b0\u4e86St\u00e5 lmarck\u6c42\u89e3\u8fc7\u7a0b\uff0c\u5e76\u5f15\u5165\u4e86\u4e24\u79cd\u65b0\u7b56\u7565\uff1aCDB\uff08\u57fa\u4e8e\u57fa\u6570\u7684\u5206\u652f\uff09\u548cDPO\uff08\u57fa\u4e8e\u63a8\u7406\u4f18\u5148\u7ea7\u6392\u5e8f\uff09\u3002", "result": "\u91c7\u7528CDB\u548cDPO\u7b56\u7565\u540e\uff0cSAT\u6c42\u89e3\u7684\u5e73\u5747\u6c42\u89e3\u65f6\u95f4\u5f97\u5230\u4e86\u6539\u5584\u3002", "conclusion": "StalmarckSAT\u7ed3\u5408\u4e86CDB\u548cDPO\u4e24\u79cd\u7b56\u7565\uff0c\u5b9e\u9a8c\u8868\u660e\u80fd\u591f\u663e\u8457\u63d0\u5347\u6c42\u89e3\u6548\u7387\u3002"}}
{"id": "2509.15248", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15248", "abs": "https://arxiv.org/abs/2509.15248", "authors": ["Zitong Yang", "Aonan Zhang", "Hong Liu", "Tatsunori Hashimoto", "Emmanuel Cand\u00e8s", "Chong Wang", "Ruoming Pang"], "title": "Synthetic bootstrapped pretraining", "comment": null, "summary": "We introduce Synthetic Bootstrapped Pretraining (SBP), a language model (LM)\npretraining procedure that first learns a model of relations between documents\nfrom the pretraining dataset and then leverages it to synthesize a vast new\ncorpus for joint training. While the standard pretraining teaches LMs to learn\ncausal correlations among tokens within a single document, it is not designed\nto efficiently model the rich, learnable inter-document correlations that can\npotentially lead to better performance. We validate SBP by designing a\ncompute-matched pretraining setup and pretrain a 3B-parameter model on up to 1T\ntokens from scratch. We find SBP consistently improves upon a strong repetition\nbaseline and delivers a significant fraction of performance improvement\nattainable by an oracle upper bound with access to 20x more unique data.\nQualitative analysis reveals that the synthesized documents go beyond mere\nparaphrases -- SBP first abstracts a core concept from the seed material and\nthen crafts a new narration on top of it. Besides strong empirical performance,\nSBP admits a natural Bayesian interpretation: the synthesizer implicitly learns\nto abstract the latent concepts shared between related documents.", "AI": {"tldr": "\u901a\u8fc7\u5408\u6210\u57fa\u4e8e\u6587\u6863\u5173\u7cfb\u7684\u65b0\u6570\u636e\uff0cSBP\u9884\u8bad\u7ec3\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u5bf9\u4e30\u5bcc\u548c\u9ad8\u6548\u5229\u7528\u9884\u8bad\u7ec3\u6570\u636e\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002", "motivation": "\u4f20\u7edf\u7684\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u4e3b\u8981\u5b66\u4e60\u5355\u4e2a\u6587\u6863\u5185\u90e8\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u7136\u800c\u8fd9\u79cd\u65b9\u6cd5\u65e0\u6cd5\u9ad8\u6548\u5efa\u6a21\u6587\u6863\u95f4\u7684\u4e30\u5bcc\u76f8\u5173\u6027\uff0c\u9650\u5236\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u80fd\u529b\u63d0\u5347\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5229\u7528\u6587\u6863\u95f4\u8054\u7cfb\u7684\u65b0\u578b\u9884\u8bad\u7ec3\u65b9\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5408\u6210\u81ea\u4e3e\u9884\u8bad\u7ec3\uff08SBP\uff09\u65b9\u6cd5\uff1a\u9996\u5148\u901a\u8fc7\u539f\u59cb\u9884\u8bad\u7ec3\u6570\u636e\u96c6\u5b66\u4e60\u6587\u6863\u95f4\u7684\u5173\u7cfb\u6a21\u578b\uff0c\u7136\u540e\u5229\u7528\u8be5\u6a21\u578b\u5408\u6210\u51fa\u5927\u89c4\u6a21\u7684\u65b0\u8bed\u6599\u5e93\uff0c\u6700\u540e\u57fa\u4e8e\u539f\u59cb\u548c\u5408\u6210\u6570\u636e\u8054\u5408\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u3002\u5b9e\u9a8c\u4ee53B\u53c2\u6570\u6a21\u578b\u4e3a\u4f8b\uff0c\u5e76\u8fdb\u884c\u4e86\u7b97\u529b\u5bf9\u9f50\u7684\u8bad\u7ec3\u8bbe\u7f6e\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cSBP\u65b9\u6cd5\u5728\u4e00\u7ec4\u5f3a\u57fa\u7ebf\u6a21\u578b\u4e0a\u8868\u73b0\u51fa\u6301\u7eed\u63d0\u5347\uff0c\u5e76\u63a5\u8fd1\u4e8e\u7406\u60f3\u60c5\u51b5\u4e0b\u4f7f\u752820\u500d\u72ec\u7279\u6570\u636e\u65f6\u7684\u6027\u80fd\u4e0a\u9650\u3002\u540c\u65f6\uff0c\u5b9a\u6027\u5206\u6790\u53d1\u73b0\u5408\u6210\u65b0\u6587\u6863\u4e0d\u4ec5\u4ec5\u662f\u7b80\u5355\u7684\u590d\u8ff0\uff0c\u800c\u662f\u80fd\u62bd\u8c61\u6838\u5fc3\u6982\u5ff5\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u751f\u6210\u65b0\u53d9\u8ff0\u3002", "conclusion": "SBP\u6709\u6548\u5730\u5229\u7528\u6587\u6863\u95f4\u7684\u77e5\u8bc6\u62bd\u8c61\uff0c\u63a8\u52a8\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5177\u6709\u81ea\u7136\u7684\u8d1d\u53f6\u65af\u89e3\u91ca\u57fa\u7840\uff0c\u5373\u6a21\u578b\u80fd\u81ea\u52a8\u53d1\u73b0\u5e76\u62bd\u8c61\u51fa\u6587\u6863\u4e4b\u95f4\u7684\u6f5c\u5728\u6982\u5ff5\u3002"}}
{"id": "2509.15834", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2509.15834", "abs": "https://arxiv.org/abs/2509.15834", "authors": ["Shardul Chiplunkar", "Cl\u00e9ment Pit-Claudel"], "title": "Automatic layout of railroad diagrams", "comment": "24 pages (+2 appendix, +3 references); 22 figures (+4 appendix); 3\n  tables", "summary": "Railroad diagrams (also called \"syntax diagrams\") are a common, intuitive\nvisualization of grammars, but limited tooling and a lack of formal attention\nto their layout mostly confines them to hand-drawn documentation. We present\nthe first formal treatment of railroad diagram layout along with a principled,\npractical implementation. We characterize the problem as compiling a *diagram\nlanguage* (specifying conceptual components and how they connect and compose)\nto a *layout language* (specifying basic graphical shapes and their sizes and\npositions). We then implement a compiler that performs *line wrapping* to meet\na target width, as well as vertical *alignment* and horizontal *justification*\nper user-specified policies. We frame line wrapping as an optimization problem,\nwhere we describe principled dimensions of optimality and implement\ncorresponding heuristics. For front-end evaluation, we show that our diagram\nlanguage is well-suited for common applications by describing how regular\nexpressions and Backus-Naur form can be compiled to it. For back-end\nevaluation, we argue that our compiler is practical by comparing its output to\ndiagrams laid out by hand and by other tools.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5f62\u5f0f\u5316\u5206\u6790\u5e76\u5b9e\u73b0\u94c1\u8def\u56fe\u81ea\u52a8\u5e03\u5c40\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f16\u8bd1\u56fe\u8bed\u8a00\u5230\u5e03\u5c40\u8bed\u8a00\uff0c\u652f\u6301\u6362\u884c\u548c\u5bf9\u9f50\u4f18\u5316\uff0c\u5b9e\u9a8c\u8bc1\u660e\u751f\u6210\u8d28\u91cf\u5ab2\u7f8e\u624b\u7ed8\u548c\u73b0\u6709\u5de5\u5177\uff0c\u89e3\u51b3\u4e86\u94c1\u8def\u56fe\u81ea\u52a8\u5316\u548c\u89c4\u8303\u5e03\u5c40\u7684\u96be\u9898\u3002", "motivation": "\u94c1\u8def\u56fe\u5728\u6587\u6863\u89c4\u8303\u53ef\u89c6\u5316\u65b9\u9762\u5177\u6709\u76f4\u89c2\u4f18\u52bf\uff0c\u4f46\u73b0\u6709\u5de5\u5177\u6709\u9650\u4e14\u7f3a\u4e4f\u5f62\u5f0f\u5316\u5e03\u5c40\u65b9\u6cd5\uff0c\u901a\u5e38\u53ea\u80fd\u624b\u7ed8\uff0c\u5f71\u54cd\u5b9e\u9645\u5e94\u7528\u548c\u81ea\u52a8\u751f\u4ea7\u3002\u4f5c\u8005\u65e8\u5728\u586b\u8865\u8be5\u5f62\u5f0f\u5316\u548c\u5de5\u5177\u5316\u7a7a\u767d\u3002", "method": "\u5c06\u94c1\u8def\u56fe\u5e03\u5c40\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u5c06\u201c\u56fe\u8bed\u8a00\u201d\u7f16\u8bd1\u4e3a\u201c\u5e03\u5c40\u8bed\u8a00\u201d\uff0c\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u652f\u6301\u81ea\u52a8\u6362\u884c\u3001\u5782\u76f4\u5bf9\u9f50\u548c\u6c34\u5e73\u5bf9\u9f50\u7684\u7f16\u8bd1\u5668\uff0c\u901a\u8fc7\u4f18\u5316\u6362\u884c\u8fc7\u7a0b\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u542f\u53d1\u5f0f\u4f18\u5316\u65b9\u6cd5\u3002\u901a\u8fc7\u5c06\u6b63\u5219\u8868\u8fbe\u5f0f\u548cBackus-Naur\u5f62\u5f0f\u8f6c\u6362\u4e3a\u94c1\u8def\u56fe\uff0c\u8fdb\u884c\u4e86\u524d\u7aef\u9a8c\u8bc1\uff1b\u901a\u8fc7\u4e0e\u624b\u7ed8\u548c\u5176\u4ed6\u5de5\u5177\u7684\u6210\u679c\u5bf9\u6bd4\uff0c\u8fdb\u884c\u4e86\u540e\u7aef\u5b9e\u7528\u6027\u9a8c\u8bc1\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u4e14\u5b9e\u7528\u7684\u94c1\u8def\u56fe\u7f16\u8bd1\u548c\u5e03\u5c40\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6ee1\u8db3\u7528\u6237\u5e03\u5c40\u9700\u6c42\u7684\u81ea\u52a8\u5316\u94c1\u8def\u56fe\u751f\u4ea7\uff0c\u6548\u679c\u4e0e\u4eba\u5de5\u7ed8\u5236\u53ca\u73b0\u6709\u5de5\u5177\u76f8\u5f53\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u5bf9\u94c1\u8def\u56fe\u5e03\u5c40\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\u7814\u7a76\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u5b9e\u73b0\u65b9\u6848\u3002\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u81ea\u52a8\u5316\u751f\u6210\u5e03\u5c40\u826f\u597d\u7684\u94c1\u8def\u56fe\uff0c\u4e14\u5176\u5b9e\u7528\u6027\u63a5\u8fd1\u624b\u7ed8\u548c\u73b0\u6709\u5de5\u5177\u3002"}}
{"id": "2509.15283", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.PL", "I.2.7; F.2.2; I.2.2"], "pdf": "https://arxiv.org/pdf/2509.15283", "abs": "https://arxiv.org/abs/2509.15283", "authors": ["Kadin Matotek", "Heather Cassel", "Md Amiruzzaman", "Linh B. Ngo"], "title": "Evaluating the Limitations of Local LLMs in Solving Complex Programming Challenges", "comment": "Comments: 16 pages, 3 figures, 8 tables, accepted to CCSC Eastern\n  2025", "summary": "This study examines the performance of today's open-source, locally hosted\nlarge-language models (LLMs) in handling complex competitive programming tasks\nwith extended problem descriptions and contexts. Building on the original\nFramework for AI-driven Code Generation Evaluation (FACE), the authors retrofit\nthe pipeline to work entirely offline through the Ollama runtime, collapsing\nFACE's sprawling per-problem directory tree into a handful of consolidated JSON\nfiles, and adding robust checkpointing so multi-day runs can resume after\nfailures. The enhanced framework generates, submits, and records solutions for\nthe full Kattis corpus of 3,589 problems across eight code-oriented models\nranging from 6.7-9 billion parameters. The submission results show that the\noverall pass@1 accuracy is modest for the local models, with the best models\nperforming at approximately half the acceptance rate of the proprietary models,\nGemini 1.5 and ChatGPT-4. These findings expose a persistent gap between\nprivate, cost-controlled LLM deployments and state-of-the-art proprietary\nservices, yet also highlight the rapid progress of open models and the\npractical benefits of an evaluation workflow that organizations can replicate\non in-house hardware.", "AI": {"tldr": "\u4f5c\u8005\u5c06\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u6d41\u7a0b\u5f7b\u5e95\u672c\u5730\u5316\uff0c\u5bf98\u79cd\u5f00\u6e90\u5927\u6a21\u578b\u505a\u4e86\u5927\u89c4\u6a21\u7f16\u7a0b\u9898\u6d4b\u8bc4\uff0c\u53d1\u73b0\u5176\u8868\u73b0\u7ea6\u4e3a\u5546\u7528\u9876\u5c16\u6a21\u578b\u7684\u4e00\u534a\uff0c\u4f46\u80fd\u52a9\u529b\u7ec4\u7ec7\u79bb\u7ebf\u81ea\u8bc4\u548c\u5f00\u6e90\u6a21\u578b\u8fdb\u6b65\u3002", "motivation": "\u968f\u7740\u5bf9\u672c\u5730\u5316\u3001\u5f00\u6e90LLM\u9700\u6c42\u589e\u957f\uff0c\u4f5c\u8005\u5e0c\u671b\u91cf\u5316\u8fd9\u4e9b\u6a21\u578b\u5728\u5b9e\u9645\u590d\u6742\u7f16\u7a0b\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u4e3a\u79bb\u7ebf\u3001\u672c\u5730\u5316\u8bc4\u6d4b\u63d0\u4f9b\u5de5\u5177\u57fa\u7840\u3002", "method": "\u6539\u8fdb\u5e76\u6269\u5c55\u539f\u6709\u7684AI\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u6846\u67b6\uff08FACE\uff09\uff0c\u5b9e\u73b0\u4e86\u5b8c\u5168\u79bb\u7ebf\u8fd0\u884c\uff0c\u4f7f\u7528Ollama runtime\uff0c\u9ad8\u5ea6\u6574\u5408\u76ee\u5f55\u7ed3\u6784\u5e76\u65b0\u589e\u5f3a\u5927\u7684\u65ad\u70b9\u7eed\u8dd1\u529f\u80fd\u3002\u6d4b\u8bd58\u4e2a\u53c2\u6570\u91cf6.7-9B\u7684\u672c\u5730\u6a21\u578b\uff0c\u9488\u5bf93589\u4e2aKattis\u9898\u76ee\u81ea\u52a8\u751f\u6210\u3001\u63d0\u4ea4\u548c\u8bc4\u4ef7\u4ee3\u7801\u89e3\u7b54\u3002", "result": "\u672c\u5730\u6a21\u578b\u7684pass@1\u51c6\u786e\u7387\u76f8\u5bf9\u8f83\u4f4e\uff0c\u6700\u597d\u6a21\u578b\u7684\u901a\u8fc7\u7387\u5927\u7ea6\u53ea\u6709Gemini 1.5\u548cChatGPT-4\u768450%\uff0c\u4f46\u5f00\u6e90\u6a21\u578b\u8fdb\u6b65\u8fc5\u901f\uff0c\u6240\u63d0\u51fa\u8bc4\u6d4b\u6d41\u7a0b\u6709\u52a9\u4e8e\u5404\u673a\u6784\u72ec\u7acb\u3001\u53ef\u63a7\u5730\u8bc4\u4f30AI\u7f16\u7a0b\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5c3d\u7ba1\u5f00\u6e90\u672c\u5730\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u89e3\u51b3\u590d\u6742\u7f16\u7a0b\u4efb\u52a1\u65b9\u9762\u7684\u8868\u73b0\u8f83\u4e3a\u6709\u9650\uff0c\u76ee\u524d\u4e0e\u4e3b\u6d41\u4e13\u6709\u6a21\u578b\uff08\u5982Gemini 1.5\u548cChatGPT-4\uff09\u4ecd\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u4f46\u5f00\u6e90\u6a21\u578b\u7684\u6027\u80fd\u6b63\u5728\u5feb\u901f\u63d0\u5347\uff0c\u672c\u5730\u53ef\u590d\u73b0\u7684\u8bc4\u6d4b\u4f53\u7cfb\u4e3a\u7ec4\u7ec7\u5185\u90e8\u8bc4\u4f30\u5e26\u6765\u5b9e\u9645\u597d\u5904\u3002"}}
{"id": "2509.15255", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.15255", "abs": "https://arxiv.org/abs/2509.15255", "authors": ["Tandin Wangchuk", "Tad Gonsalves"], "title": "Comparative Analysis of Tokenization Algorithms for Low-Resource Language Dzongkha", "comment": "10 Pages", "summary": "Large Language Models (LLMs) are gaining popularity and improving rapidly.\nTokenizers are crucial components of natural language processing, especially\nfor LLMs. Tokenizers break down input text into tokens that models can easily\nprocess while ensuring the text is accurately represented, capturing its\nmeaning and structure. Effective tokenizers enhance the capabilities of LLMs by\nimproving a model's understanding of context and semantics, ultimately leading\nto better performance in various downstream tasks, such as translation,\nclassification, sentiment analysis, and text generation. Most pre-trained\ntokenizers are suitable for high-resource languages like English but perform\npoorly for low-resource languages. Dzongkha, Bhutan's national language spoken\nby around seven hundred thousand people, is a low-resource language, and its\nlinguistic complexity poses unique NLP challenges. Despite some progress,\nsignificant research in Dzongkha NLP is lacking, particularly in tokenization.\nThis study evaluates the training and performance of three common tokenization\nalgorithms in comparison to other popular methods. Specifically, Byte-Pair\nEncoding (BPE), WordPiece, and SentencePiece (Unigram) were evaluated for their\nsuitability for Dzongkha. Performance was assessed using metrics like Subword\nFertility, Proportion of Continued Words, Normalized Sequence Length, and\nexecution time. The results show that while all three algorithms demonstrate\npotential, SentencePiece is the most effective for Dzongkha tokenization,\npaving the way for further NLP advancements. This underscores the need for\ntailored approaches for low-resource languages and ongoing research. In this\nstudy, we presented three tokenization algorithms for Dzongkha, paving the way\nfor building Dzongkha Large Language Models.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u4e09\u79cd\u5206\u8bcd\u7b97\u6cd5\u7528\u4e8e\u4e0d\u4e39\u5b97\u5361\u8bed\uff0c\u53d1\u73b0SentencePiece\u6700\u6709\u6548\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00NLP\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u9ad8\u8d44\u6e90\u8bed\u8a00\u7684\u9884\u8bad\u7ec3\u5206\u8bcd\u5668\u8868\u73b0\u4f18\u826f\uff0c\u4f46\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u5982\u5b97\u5361\u8bed\u652f\u6301\u4e0d\u8db3\u3002\u5b97\u5361\u8bed\u8bed\u8a00\u5b66\u7279\u6027\u590d\u6742\uff0c\u5206\u8bcd\u9886\u57df\u7814\u7a76\u6b20\u7f3a\uff0c\u4e9f\u9700\u6709\u6548\u7b97\u6cd5\u4ee5\u652f\u6301\u540e\u7eedNLP\u4efb\u52a1\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5efa\u8bbe\u3002", "method": "\u8bc4\u4f30\u548c\u6bd4\u8f83\u4e86\u4e09\u79cd\u5e38\u89c1\u5206\u8bcd\u7b97\u6cd5\u5728\u5b97\u5361\u8bed\u4e0a\u7684\u8bad\u7ec3\u4e0e\u8868\u73b0\uff0c\u5206\u522b\u4e3aBPE\u3001WordPiece\u548cSentencePiece\uff08Unigram\uff09\uff1b\u5229\u7528\u5b50\u8bcd\u7e41\u6b96\u7387\uff08Subword Fertility\uff09\u3001\u8fde\u7eed\u8bcd\u5360\u6bd4\u3001\u5f52\u4e00\u5316\u5e8f\u5217\u957f\u5ea6\u53ca\u6267\u884c\u65f6\u95f4\u7b49\u6307\u6807\u8fdb\u884c\u5b9a\u91cf\u5206\u6790\u3002", "result": "\u4e09\u79cd\u7b97\u6cd5\u5747\u6709\u4e00\u5b9a\u6548\u679c\uff0c\u4f46SentencePiece\uff08Unigram\uff09\u5728\u5404\u9879\u6307\u6807\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u88ab\u8ba4\u4e3a\u6700\u9002\u5408\u5b97\u5361\u8bed\u3002\u5b9e\u9a8c\u5960\u5b9a\u4e86\u5b97\u5361\u8bed\u8bed\u8a00\u6a21\u578b\u4e0eNLP\u5e94\u7528\u7684\u57fa\u7840\u3002", "conclusion": "\u4e09\u79cd\u4e3b\u6d41\u5206\u8bcd\u7b97\u6cd5\uff08BPE\u3001WordPiece\u3001SentencePiece\uff09\u5747\u5177\u6709\u5bf9\u5b97\u5361\u8bed\u5206\u8bcd\u7684\u6f5c\u529b\uff0c\u4f46SentencePiece\uff08Unigram\uff09\u8868\u73b0\u6700\u4f18\uff0c\u9002\u5408\u5b97\u5361\u8bed\u5206\u8bcd\uff0c\u63a8\u52a8\u76f8\u5173NLP\u7684\u53d1\u5c55\u3002\u547c\u5401\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u91c7\u7528\u5b9a\u5236\u5316\u65b9\u6cd5\u5e76\u6301\u7eed\u7814\u7a76\u3002"}}
{"id": "2509.15397", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.15397", "abs": "https://arxiv.org/abs/2509.15397", "authors": ["Simantika Bhattacharjee Dristi", "Matthew B. Dwyer"], "title": "LoCaL: Countering Surface Bias in Code Evaluation Metrics", "comment": null, "summary": "With the increasing popularity of large language models (LLMs) and LLM-based\nagents, reliable and effective code evaluation metrics (CEMs) have become\ncrucial for progress across several software engineering tasks. While popular\nbenchmarks often provide test cases to assess the correctness of generated\ncode, crafting and executing test cases is expensive. Reference-based CEMs\nprovide a cheaper alternative by scoring a candidate program based on its\nfunctional similarity to a reference. Although prior research has focused on\nreporting the weak correlation between these CEMs and functional correctness,\nthe causes are only assumed, and plausible solutions remain unexplored. In this\nwork, we critically evaluate four state-of-the-art reference-based CEMs,\nrevealing their strong bias towards surface-level features rather than code\nfunctionality. Despite this surface bias, current evaluation datasets for these\nCEMs rarely include code pairs that are surface-similar yet functionally\ndissimilar, or functionally similar yet surface-dissimilar. To mitigate this\ngap, we propose LoCaL (Looks Can Lie), a CEM evaluation benchmark, with 3117\ncode pairs at both the method and program levels. Each pair is labeled with a\nfunctional similarity score and aims to target regions where CEMs are likely to\nperform poorly. The functional similarity scores are calculated through\ndifferential fuzzing, which eliminates the need for predefined test cases and,\nat the same time, improves the reliability of the scores by executing an order\nof magnitude more tests than prior work. We find that all four CEMs show\nsignificant performance degradation on LoCaL, compared to the baselines.\nFinally, based on our findings, we draw the implication that exposing CEMs to\nLoCaL-like data might facilitate the development of metrics that are robust to\nsurface bias.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u73b0\u6709\u4ee3\u7801\u8bc4\u4f30\u6307\u6807\u8fc7\u4e8e\u4f9d\u8d56\u8868\u5c42\u7279\u5f81\uff0c\u5b9e\u9645\u5728\u517c\u987e\u8868\u5c42\u4e0e\u529f\u80fd\u5dee\u5f02\u7684\u65b0\u57fa\u51c6LoCaL\u4e0a\u7684\u8868\u73b0\u660e\u663e\u4e0b\u964d\u3002\u63d0\u51faLoCaL\u57fa\u51c6\u4e0e\u5dee\u5206\u6a21\u7cca\u6d4b\u8bd5\uff0c\u6709\u671b\u4fc3\u4f7f\u65b0\u578b\u3001\u66f4\u5177\u529f\u80fd\u6027\u7684\u4ee3\u7801\u8bc4\u4f30\u65b9\u6cd5\u7814\u7a76\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u53ca\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u8d8a\u6765\u8d8a\u6d41\u884c\uff0c\u56e0\u6b64\u5bf9\u4ee3\u7801\u8bc4\u4f30\u6307\u6807\uff08CEM\uff09\u7684\u53ef\u9760\u6027\u548c\u6709\u6548\u6027\u63d0\u51fa\u4e86\u66f4\u9ad8\u8981\u6c42\u3002\u76ee\u524d\u8bc4\u4f30\u4ee3\u7801\u6b63\u786e\u6027\u4e3b\u8981\u4f9d\u8d56\u6d4b\u8bd5\u7528\u4f8b\uff0c\u4f46\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u548c\u6267\u884c\u6210\u672c\u9ad8\u6602\u3002\u57fa\u4e8e\u53c2\u8003\u7684CEM\u867d\u7136\u4f5c\u4e3a\u4f4e\u6210\u672c\u66ff\u4ee3\uff0c\u4f46\u5b83\u4eec\u4e0e\u529f\u80fd\u6b63\u786e\u6027\u7684\u76f8\u5173\u6027\u8f83\u5f31\u4e14\u539f\u56e0\u672a\u88ab\u6df1\u5165\u7814\u7a76\u3002", "method": "\u4f5c\u8005\u6279\u5224\u6027\u5730\u8bc4\u4f30\u4e86\u56db\u79cd\u4e3b\u6d41\u7684\u53c2\u8003\u578bCEM\uff0c\u53d1\u73b0\u5b83\u4eec\u504f\u91cd\u4ee3\u7801\u7684\u8868\u5c42\u7279\u5f81\u800c\u975e\u5b9e\u9645\u529f\u80fd\u3002\u9488\u5bf9\u73b0\u6709\u6570\u636e\u96c6\u4e0d\u8db3\u4ee5\u8986\u76d6\u8868\u5c42\u76f8\u4f3c\u4f46\u529f\u80fd\u4e0d\u540c\u3001\u6216\u529f\u80fd\u7c7b\u4f3c\u800c\u8868\u9762\u4e0d\u540c\u7684\u4ee3\u7801\u5bf9\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u8bc4\u6d4b\u57fa\u51c6LoCaL\u3002LoCaL\u57fa\u51c6\u5305\u542b3117\u5bf9\u4ee3\u7801\u7247\u6bb5\uff0c\u6db5\u76d6\u65b9\u6cd5\u7ea7\u548c\u7a0b\u5e8f\u7ea7\uff0c\u5e76\u901a\u8fc7\u5dee\u5206\u6a21\u7cca\u6d4b\u8bd5\uff08differential fuzzing\uff09\u65e0\u987b\u9884\u5b9a\u4e49\u6d4b\u8bd5\u7528\u4f8b\u3001\u4e14\u80fd\u8fdb\u884c\u5927\u91cf\u6709\u6548\u6d4b\u8bd5\uff0c\u4e3a\u6bcf\u5bf9\u4ee3\u7801\u6807\u6ce8\u529f\u80fd\u76f8\u4f3c\u6027\u5206\u6570\u3002", "result": "\u56db\u4e2aCEM\u5728LoCaL\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u5747\u663e\u8457\u5f31\u4e8e\u57fa\u7ebf\u6570\u636e\u3002\u529f\u80fd\u5c42\u9762\u7684\u51c6\u786e\u6027\u4e0b\u964d\uff0c\u66b4\u9732\u51fa\u8bc4\u4f30\u6307\u6807\u4e25\u91cd\u7684\u8868\u5c42\u504f\u5dee\u3002", "conclusion": "\u73b0\u6709\u53c2\u8003\u578bCEM\u6613\u53d7\u4ee3\u7801\u8868\u5c42\u7279\u5f81\u5f71\u54cd\uff0c\u4e0d\u80fd\u51c6\u786e\u8bc4\u4f30\u4ee3\u7801\u529f\u80fd\u3002\u901a\u8fc7LoCaL\u8fd9\u6837\u9488\u5bf9\u8868\u5c42\u4e0e\u529f\u80fd\u5dee\u5f02\u8bbe\u8ba1\u7684\u6570\u636e\u96c6\uff0c\u53ef\u4ee5\u63a8\u52a8\u5f00\u53d1\u66f4\u5177\u9c81\u68d2\u6027\u7684\u65b0\u8bc4\u4f30\u6307\u6807\u3002"}}
{"id": "2509.15260", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.15260", "abs": "https://arxiv.org/abs/2509.15260", "authors": ["Yujia Hu", "Ming Shan Hee", "Preslav Nakov", "Roy Ka-Wei Lee"], "title": "Toxicity Red-Teaming: Benchmarking LLM Safety in Singapore's Low-Resource Languages", "comment": "9 pages, EMNLP 2025", "summary": "The advancement of Large Language Models (LLMs) has transformed natural\nlanguage processing; however, their safety mechanisms remain under-explored in\nlow-resource, multilingual settings. Here, we aim to bridge this gap. In\nparticular, we introduce \\textsf{SGToxicGuard}, a novel dataset and evaluation\nframework for benchmarking LLM safety in Singapore's diverse linguistic\ncontext, including Singlish, Chinese, Malay, and Tamil. SGToxicGuard adopts a\nred-teaming approach to systematically probe LLM vulnerabilities in three\nreal-world scenarios: \\textit{conversation}, \\textit{question-answering}, and\n\\textit{content composition}. We conduct extensive experiments with\nstate-of-the-art multilingual LLMs, and the results uncover critical gaps in\ntheir safety guardrails. By offering actionable insights into cultural\nsensitivity and toxicity mitigation, we lay the foundation for safer and more\ninclusive AI systems in linguistically diverse environments.\\footnote{Link to\nthe dataset: https://github.com/Social-AI-Studio/SGToxicGuard.}\n\\textcolor{red}{Disclaimer: This paper contains sensitive content that may be\ndisturbing to some readers.}", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u516c\u5f00\u4e86\u9996\u4e2a\u65b0\u52a0\u5761\u591a\u8bed\u79cd\u7684LLM\u5b89\u5168\u6d4b\u8bd5\u6846\u67b6\u548c\u6570\u636e\u96c6SGToxicGuard\uff0c\u63ed\u793a\u4e86\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u73b0\u6709LLM\u5b89\u5168\u673a\u5236\u7684\u4e0d\u8db3\uff0c\u4e3a\u672a\u6765\u66f4\u5b89\u5168\u3001\u5305\u5bb9\u7684AI\u7cfb\u7edf\u5efa\u8bbe\u63d0\u4f9b\u4e86\u65b9\u5411\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u5de8\u5927\u8fdb\u5c55\uff0c\u4f46\u5728\u8d44\u6e90\u532e\u4e4f\u3001\u591a\u8bed\u79cd\u73af\u5883\u4e0b\u7684\u5b89\u5168\u6027\u673a\u5236\u7814\u7a76\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u65b0\u52a0\u5761\u8fd9\u79cd\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86SGToxicGuard\uff0c\u8fd9\u662f\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u65b0\u52a0\u5761\u591a\u5143\u8bed\u8a00\u73af\u5883\uff08\u5305\u62ecSinglish\u3001\u4e2d\u6587\u3001\u9a6c\u6765\u8bed\u548c\u6cf0\u7c73\u5c14\u8bed\uff09\u4e0b\u5bf9LLM\u5b89\u5168\u6027\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002\u91c7\u7528red-teaming\u65b9\u6cd5\uff0c\u7cfb\u7edf\u6027\u5730\u5728\u5bf9\u8bdd\u3001\u95ee\u7b54\u3001\u5185\u5bb9\u521b\u4f5c\u4e09\u79cd\u771f\u5b9e\u573a\u666f\u4e2d\u6d4b\u8bd5LLM\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "result": "\u901a\u8fc7\u5bf9\u5f53\u524d\u5148\u8fdb\u7684\u591a\u8bed\u79cdLLM\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\uff0c\u53d1\u73b0\u8fd9\u4e9b\u6a21\u578b\u5728\u5b89\u5168\u9632\u62a4\u673a\u5236\u4e0a\u5b58\u5728\u91cd\u8981\u7f3a\u53e3\u3002", "conclusion": "SGToxicGuard\u4e3a\u63a2\u7a76\u591a\u8bed\u8a00\u3001\u591a\u6587\u5316\u73af\u5883\u4e0b\u7684AI\u5b89\u5168\u548c\u5305\u5bb9\u6027\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u63a8\u8fdb\u4e86\u6587\u5316\u654f\u611f\u6027\u548c\u6709\u5bb3\u5185\u5bb9\u9632\u62a4\u7684\u7814\u7a76\u3002"}}
{"id": "2509.15567", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.15567", "abs": "https://arxiv.org/abs/2509.15567", "authors": ["Hongyu Kuang", "Ning Zhang", "Hui Gao", "Xin Zhou", "Wesley K. G. Assun\u00e7\u00e3o", "Xiaoxing Ma", "Dong Shao", "Guoping Rong", "He Zhang"], "title": "Brevity is the Soul of Wit: Condensing Code Changes to Improve Commit Message Generation", "comment": null, "summary": "Commit messages are valuable resources for describing why code changes are\ncommitted to repositories in version control systems (e.g., Git). They\neffectively help developers understand code changes and better perform software\nmaintenance tasks. Unfortunately, developers often neglect to write\nhigh-quality commit messages in practice. Therefore, a growing body of work is\nproposed to generate commit messages automatically. These works all\ndemonstrated that how to organize and represent code changes is vital in\ngenerating good commit messages, including the use of fine-grained graphs or\nembeddings to better represent code changes. In this study, we choose an\nalternative way to condense code changes before generation, i.e., proposing\nbrief yet concise text templates consisting of the following three parts: (1)\nsummarized code changes, (2) elicited comments, and (3) emphasized code\nidentifiers. Specifically, we first condense code changes by using our proposed\ntemplates with the help of a heuristic-based tool named ChangeScribe, and then\nfine-tune CodeLlama-7B on the pairs of our proposed templates and corresponding\ncommit messages. Our proposed templates better utilize pre-trained language\nmodels, while being naturally brief and readable to complement generated commit\nmessages for developers. Our evaluation based on a widely used dataset showed\nthat our approach can outperform six baselines in terms of BLEU-Norm, METEOR,\nand ROUGE-L, with average improvements of 51.7%, 78.7%, and 62.5%,\nrespectively. The ablation study and human evaluation also provide further\ninsights into the effectiveness of our approach.", "AI": {"tldr": "\u901a\u8fc7\u5f15\u5165\u5b9a\u5236\u5316\u4ee3\u7801\u53d8\u66f4\u6a21\u677f\u548c\u9884\u8bad\u7ec3\u6a21\u578b\u5fae\u8c03\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u66f4\u6709\u6548\u7684commit message\u81ea\u52a8\u751f\u6210\u65b9\u6cd5\uff0c\u5e76\u5728\u591a\u9879\u6307\u6807\u4e0a\u8d85\u8fc7\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u7684commit message\u5bf9\u63d0\u9ad8\u8f6f\u4ef6\u7ef4\u62a4\u6548\u7387\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728code change\u8868\u5f81\u4e0a\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u201c\u4e09\u90e8\u5206\u6587\u672c\u6a21\u677f\u201d\uff08\u4ee3\u7801\u53d8\u66f4\u6458\u8981\u3001\u63d0\u53d6\u6ce8\u91ca\u3001\u7a81\u51fa\u4ee3\u7801\u6807\u8bc6\u7b26\uff09\u7684\u65b9\u6cd5\uff0c\u7528ChangeScribe\u5de5\u5177\u63d0\u53d6\u6a21\u677f\uff0c\u5e76\u5fae\u8c03CodeLlama-7B\u8fdb\u884ccommit message\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728BLEU-Norm\u3001METEOR\u548cROUGE-L\u6307\u6807\u4e0a\u5206\u522b\u6bd4\u516d\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u5e73\u5747\u63d0\u534751.7%\uff0c78.7%\uff0c62.5%\u3002\u6d88\u878d\u5b9e\u9a8c\u53ca\u4eba\u5de5\u8bc4\u4f30\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u8be5\u65b9\u6848\u6709\u6548\u3002", "conclusion": "\u7ed3\u6784\u5316\u7b80\u660e\u4ee3\u7801\u53d8\u66f4\u6a21\u677f\u7ed3\u5408\u5927\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u80fd\u663e\u8457\u63d0\u5347\u81ea\u52a8commit message\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2509.15335", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.15335", "abs": "https://arxiv.org/abs/2509.15335", "authors": ["Charlott Jakob", "David Harbecke", "Patrick Parschan", "Pia Wenzel Neves", "Vera Schmitt"], "title": "PolBiX: Detecting LLMs' Political Bias in Fact-Checking through X-phemisms", "comment": null, "summary": "Large Language Models are increasingly used in applications requiring\nobjective assessment, which could be compromised by political bias. Many\nstudies found preferences for left-leaning positions in LLMs, but downstream\neffects on tasks like fact-checking remain underexplored. In this study, we\nsystematically investigate political bias through exchanging words with\neuphemisms or dysphemisms in German claims. We construct minimal pairs of\nfactually equivalent claims that differ in political connotation, to assess the\nconsistency of LLMs in classifying them as true or false. We evaluate six LLMs\nand find that, more than political leaning, the presence of judgmental words\nsignificantly influences truthfulness assessment. While a few models show\ntendencies of political bias, this is not mitigated by explicitly calling for\nobjectivism in prompts.", "AI": {"tldr": "\u5927\u6a21\u578b\u6838\u67e5\u4e8b\u5b9e\u65f6\u7528\u8bcd\u597d\u574f\uff08\u5982\u59d4\u5a49\u6216\u8d2c\u635f\uff09\u5f71\u54cd\u6bd4\u653f\u6cbb\u53d6\u5411\u66f4\u5927\uff0c\u5f3a\u8c03\u5ba2\u89c2\u6027\u4e5f\u65e0\u6cd5\u5b8c\u5168\u6d88\u9664\u8fd9\u4e00\u504f\u89c1\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u9010\u6e10\u5e94\u7528\u4e8e\u9700\u8981\u5ba2\u89c2\u8bc4\u4f30\u7684\u4efb\u52a1\uff0c\u4f46\u5176\u6f5c\u5728\u7684\u653f\u6cbb\u504f\u89c1\u53ef\u80fd\u5f71\u54cd\u8fd9\u4e9b\u5e94\u7528\u7684\u516c\u6b63\u6027\u3002\u76ee\u524d\uff0c\u591a\u9879\u7814\u7a76\u53d1\u73b0LLMs\u504f\u5411\u5de6\u7ffc\u7acb\u573a\uff0c\u4f46\u8fd9\u4e9b\u504f\u89c1\u5bf9\u8bf8\u5982\u4e8b\u5b9e\u6838\u67e5\u7b49\u4e0b\u6e38\u4efb\u52a1\u7684\u5f71\u54cd\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u5728\u5fb7\u8bed\u58f0\u660e\u4e2d\u4f7f\u7528\u59d4\u5a49\u8bed\u548c\u8d2c\u635f\u8bed\u66ff\u6362\u5173\u952e\u8bcd\uff0c\u6784\u9020\u653f\u6cbb\u5185\u6db5\u4e0d\u540c\u4f46\u4e8b\u5b9e\u7b49\u4ef7\u7684\u58f0\u660e\u5bf9\uff0c\u5e76\u8ba9\u591a\u79cdLLM\u5bf9\u8fd9\u4e9b\u58f0\u660e\u7684\u771f\u5b9e\u6027\u8fdb\u884c\u5206\u7c7b\u3002\u7814\u7a76\u5171\u8bc4\u4f30\u4e86\u516d\u79cdLLM\uff0c\u5e76\u6d4b\u8bd5\u5b83\u4eec\u5728\u653f\u6cbb\u7acb\u573a\u53ca\u63aa\u8f9e\u503e\u5411\u6027\u4e0b\u7684\u5224\u65ad\u4e00\u81f4\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u76f8\u8f83\u4e8e\u653f\u6cbb\u503e\u5411\uff0c\u5e26\u6709\u8bc4\u4ef7\u8272\u5f69\u7684\u7528\u8bcd\uff08\u5982\u59d4\u5a49\u8bed\u6216\u8d2c\u635f\u8bed\uff09\u5bf9\u6a21\u578b\u7684\u771f\u5b9e\u6027\u5224\u65ad\u5f71\u54cd\u66f4\u5927\u3002\u867d\u7136\u90e8\u5206\u6a21\u578b\u5c55\u73b0\u51fa\u4e00\u5b9a\u7684\u653f\u6cbb\u504f\u89c1\uff0c\u4f46\u5728\u63d0\u793a\u65f6\u660e\u786e\u8981\u6c42\u5ba2\u89c2\u6027\uff0c\u5e76\u672a\u6d88\u9664\u8fd9\u79cd\u504f\u89c1\u3002", "conclusion": "LLMs\u5728\u4e8b\u5b9e\u6838\u67e5\u7b49\u4efb\u52a1\u4e2d\u53d7\u63aa\u8f9e\u8bc4\u4ef7\u8272\u5f69\u5f71\u54cd\u8f83\u5927\uff0c\u653f\u6cbb\u504f\u89c1\u867d\u5b58\u5728\u4f46\u8f83\u5f31\uff0c\u4e14\u5f3a\u8c03\u5ba2\u89c2\u6027\u96be\u4ee5\u5b8c\u5168\u6d88\u9664\u6a21\u578b\u7684\u5224\u65ad\u504f\u89c1\u3002"}}
{"id": "2509.15777", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.15777", "abs": "https://arxiv.org/abs/2509.15777", "authors": ["Haoran Xu", "Zhi Chen", "Junxiao Han", "Xinkui Zhao", "Jianwei Yin", "Shuiguang Deng"], "title": "How Far Are We? An Empirical Analysis of Current Vulnerability Localization Approaches", "comment": null, "summary": "Open-source software vulnerability patch detection is a critical component\nfor maintaining software security and ensuring software supply chain integrity.\nTraditional manual detection methods face significant scalability challenges\nwhen processing large volumes of commit histories, while being prone to human\nerrors and omissions. Existing automated approaches, including heuristic-based\nmethods and pre-trained model solutions, suffer from limited accuracy, poor\ngeneralization capabilities, and inherent methodological constraints that\nhinder their practical deployment. To address these fundamental challenges,\nthis paper conducts a comprehensive empirical study of existing vulnerability\npatch detection methods, revealing four key insights that guide the design of\neffective solutions: the critical impact of search space reduction, the\nsuperiority of pre-trained semantic understanding over architectural\ncomplexity, the temporal limitations of web crawling approaches, and the\nadvantages of knowledge-driven methods. Based on these insights, we propose a\nnovel two-stage framework that combines version-driven candidate filtering with\nlarge language model-based multi-round dialogue voting to achieve accurate and\nefficient vulnerability patch identification. Extensive experiments on a\ndataset containing 750 real vulnerabilities demonstrate that our method\noutperforms current approaches.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5f00\u6e90\u8f6f\u4ef6\u8865\u4e01\u68c0\u6d4b\uff0c\u63d0\u51fa\u7ed3\u5408\u7248\u672c\u7b5b\u9009\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u8bdd\u7684\u65b0\u6846\u67b6\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u6548\u679c\u9886\u5148\u73b0\u6709\u65b9\u6cd5\uff0c\u5177\u6709\u63a8\u5e7f\u4ef7\u503c\u3002", "motivation": "\u5f53\u524d\u5f00\u6e90\u8f6f\u4ef6\u6f0f\u6d1e\u8865\u4e01\u68c0\u6d4b\u5b58\u5728\u89c4\u6a21\u5316\u56f0\u96be\u4e0e\u4eba\u4e3a\u9519\u8bef\uff0c\u4f20\u7edf\u81ea\u52a8\u5316\u548c\u9884\u8bad\u7ec3\u6a21\u578b\u65b9\u6cd5\u4e5f\u5b58\u5728\u51c6\u786e\u7387\u4f4e\u548c\u6cdb\u5316\u80fd\u529b\u5dee\u7b49\u95ee\u9898\u3002\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u6839\u672c\u6311\u6218\uff0c\u63d0\u5347\u8f6f\u4ef6\u5b89\u5168\u4e0e\u4f9b\u5e94\u94fe\u5b8c\u6574\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u5305\u62ec\u57fa\u4e8e\u7248\u672c\u7684\u5019\u9009\u8fc7\u6ee4\u4e0e\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u8f6e\u5bf9\u8bdd\u6295\u7968\uff0c\u4ee5\u63d0\u5347\u6f0f\u6d1e\u8865\u4e01\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002\u65b9\u6cd5\u8bbe\u8ba1\u53d7\u5230\u56db\u4e2a\u5b9e\u8bc1\u53d1\u73b0\u7684\u6307\u5bfc\uff1a\u68c0\u7d22\u7a7a\u95f4\u7684\u6709\u6548\u7f29\u5c0f\u3001\u8bed\u4e49\u7406\u89e3\u7684\u4f18\u8d8a\u6027\u3001\u7f51\u9875\u722c\u53d6\u65f6\u6548\u6027\u9650\u5236\u548c\u77e5\u8bc6\u9a71\u52a8\u65b9\u6cd5\u7684\u4f18\u52bf\u3002", "result": "\u5728\u5305\u542b750\u4e2a\u771f\u5b9e\u6f0f\u6d1e\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u7387\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u7684\u4e3b\u6d41\u68c0\u6d4b\u65b9\u6cd5\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u7684\u4e24\u9636\u6bb5\u5927\u6a21\u578b\u65b9\u6cd5\u5728\u81ea\u52a8\u68c0\u6d4b\u5f00\u6e90\u8f6f\u4ef6\u6f0f\u6d1e\u8865\u4e01\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6548\u679c\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u51c6\u786e\u7387\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u7684\u4e0d\u8db3\u3002"}}
{"id": "2509.15339", "categories": ["cs.CL", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2509.15339", "abs": "https://arxiv.org/abs/2509.15339", "authors": ["Yeongbin Seo", "Dongha Lee", "Jinyoung Yeo"], "title": "Quantifying Self-Awareness of Knowledge in Large Language Models", "comment": null, "summary": "Hallucination prediction in large language models (LLMs) is often interpreted\nas a sign of self-awareness. However, we argue that such performance can arise\nfrom question-side shortcuts rather than true model-side introspection. To\ndisentangle these factors, we propose the Approximate Question-side Effect\n(AQE), which quantifies the contribution of question-awareness. Our analysis\nacross multiple datasets reveals that much of the reported success stems from\nexploiting superficial patterns in questions. We further introduce SCAO\n(Semantic Compression by Answering in One word), a method that enhances the use\nof model-side signals. Experiments show that SCAO achieves strong and\nconsistent performance, particularly in settings with reduced question-side\ncues, highlighting its effectiveness in fostering genuine self-awareness in\nLLMs.", "AI": {"tldr": "\u5927\u6a21\u578b\u5e7b\u89c9\u9884\u6d4b\u5e38\u501f\u52a9\u95ee\u9898\u7ebf\u7d22\uff0c\u672c\u6587\u7528AQE\u91cf\u5316\u8fd9\u4e00\u5f71\u54cd\uff0c\u5e76\u63d0\u51faSCAO\u65b9\u6cd5\u51cf\u5c11\u7ebf\u7d22\u4f9d\u8d56\uff0c\u589e\u5f3a\u6a21\u578b\u81ea\u6211\u8ba4\u77e5\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u6a21\u578b\u5e7b\u89c9\u9884\u6d4b\u80fd\u529b\u5e38\u88ab\u89c6\u4e3a\u81ea\u6211\u8ba4\u77e5\u7684\u4f53\u73b0\uff0c\u4f46\u5176\u5b9e\u4e3b\u8981\u53d7\u5230\u95ee\u9898\u7aef\u7ebf\u7d22\u5f71\u54cd\uff0c\u7f3a\u4e4f\u5bf9\u6a21\u578b\u771f\u6b63\u5185\u7701\u80fd\u529b\u7684\u8bc4\u4f30\u3002", "method": "\u63d0\u51fa\u4e86AQE\uff08Approximate Question-side Effect\uff09\u6765\u91cf\u5316\u95ee\u9898\u7aef\u5bf9\u5e7b\u89c9\u9884\u6d4b\u7684\u5f71\u54cd\uff0c\u5e76\u5f15\u5165SCAO\uff08Semantic Compression by Answering in One word\uff09\u65b9\u6cd5\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8bb8\u591a\u6210\u529f\u6848\u4f8b\u6e90\u81ea\u6a21\u578b\u5229\u7528\u95ee\u9898\u8868\u9762\u7279\u5f81\uff0c\u91c7\u7528SCAO\u540e\u5927\u5e45\u63d0\u5347\u4e86\u6a21\u578b\u5185\u5728\u4fe1\u53f7\u7684\u5229\u7528\uff0c\u663e\u793a\u66f4\u771f\u5b9e\u7684\u81ea\u6211\u8ba4\u77e5\u3002", "conclusion": "SCAO\u65b9\u6cd5\u5728\u51cf\u5c11\u95ee\u9898\u7aef\u63d0\u793a\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u66f4\u6709\u6548\u6fc0\u53d1\u5927\u6a21\u578b\u7684\u81ea\u6211\u8ba4\u77e5\u80fd\u529b\u3002"}}
