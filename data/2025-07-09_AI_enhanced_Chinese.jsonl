{"id": "2507.05919", "categories": ["cs.DM"], "pdf": "https://arxiv.org/pdf/2507.05919", "abs": "https://arxiv.org/abs/2507.05919", "authors": ["Thierry Marchant", "Sandip Sarkar"], "title": "Axiomatic characterizations of dissimilarity orderings and distances between sets", "comment": null, "summary": "We characterize the orderings of pairs of sets induced by several distances:\nHamming, Jaccard, S\\o rensen-Dice and Overlap. We also characterize these\ndistances.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86Hamming\u3001Jaccard\u3001Sorensen-Dice\u548cOverlap\u56db\u79cd\u96c6\u5408\u8ddd\u79bb\u6307\u6807\u5728\u96c6\u5408\u5bf9\u6392\u5e8f\u4e2d\u7684\u5177\u4f53\u7279\u6027\u53ca\u5176\u76f8\u4e92\u5173\u7cfb\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u9009\u62e9\u5408\u9002\u7684\u96c6\u5408\u8ddd\u79bb\u5ea6\u91cf\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002", "motivation": "\u7814\u7a76\u96c6\u5408\u4e4b\u95f4\u7684\u8ddd\u79bb\uff08\u76f8\u4f3c\u6027/\u5dee\u5f02\u6027\u5ea6\u91cf\uff09\u5728\u6570\u636e\u5206\u6790\u3001\u4fe1\u606f\u68c0\u7d22\u7b49\u9886\u57df\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u4e0d\u540c\u8ddd\u79bb\u5ea6\u91cf\uff08\u5982Hamming\u3001Jaccard\u3001Sorensen-Dice\u3001Overlap\uff09\u4e4b\u95f4\u7684\u6392\u5e8f\u5173\u7cfb\u4e0d\u660e\u786e\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u523b\u753b\u8fd9\u4e9b\u5e38\u7528\u8ddd\u79bb\u5ea6\u91cf\u5bf9\u96c6\u5408\u5bf9\u6392\u5e8f\u7684\u5f71\u54cd\u53ca\u5176\u76f8\u4e92\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u65b9\u6cd5\uff0c\u5bf9Hamming\u3001Jaccard\u3001Sorensen-Dice\u548cOverlap\u8fd9\u51e0\u79cd\u4e3b\u6d41\u96c6\u5408\u8ddd\u79bb\u8fdb\u884c\u5f62\u5f0f\u5316\u63cf\u8ff0\uff0c\u5e76\u5bf9\u7531\u8fd9\u4e9b\u8ddd\u79bb\u5b9a\u4e49\u7684\u96c6\u5408\u5bf9\u6392\u5e8f\u8fdb\u884c\u7cfb\u7edf\u523b\u753b\u548c\u5bf9\u6bd4\u3002", "result": "\u6210\u529f\u523b\u753b\u4e86Hamming\u3001Jaccard\u3001Sorensen-Dice\u4e0eOverlap\u8ddd\u79bb\u5ea6\u91cf\u5728\u96c6\u5408\u5bf9\u6392\u5e8f\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u63ed\u793a\u4e86\u8fd9\u4e9b\u8ddd\u79bb\u7684\u76f8\u5173\u6027\u8d28\u3002", "conclusion": "\u7814\u7a76\u4e3a\u96c6\u5408\u8ddd\u79bb\u7684\u7406\u89e3\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u660e\u786e\u4e86\u4e0d\u540c\u96c6\u5408\u8ddd\u79bb\u5ea6\u91cf\u7684\u6392\u5e8f\u7279\u6027\u53ca\u5176\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4e3a\u5b9e\u9645\u9009\u62e9\u5408\u9002\u7684\u8ddd\u79bb\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2502.06055", "categories": ["cs.LO", "cs.DM", "cs.SC", "math.CO"], "pdf": "https://arxiv.org/pdf/2502.06055", "abs": "https://arxiv.org/abs/2502.06055", "authors": ["Zhengyu Li", "Conor Duggan", "Curtis Bright", "Vijay Ganesh"], "title": "Verified Certificates via SAT and Computer Algebra Systems for the Ramsey $R(3, 8)$ and $R(3, 9)$ Problems", "comment": "To appear at IJCAI 2025", "summary": "The Ramsey problem $R(3, k)$ seeks to determine the smallest value of $n$\nsuch that any red/blue edge coloring of the complete graph on $n$ vertices must\neither contain a blue triangle (3-clique) or a red clique of size $k$. Despite\nits significance, many previous computational results for the Ramsey $R(3, k)$\nproblem such as $R(3, 8)$ and $R(3, 9)$ lack formal verification. To address\nthis issue, we use the software MathCheck to generate certificates for Ramsey\nproblems $R(3, 8)$ and $R(3, 9)$ (and symmetrically $R(8, 3)$ and $R(9, 3)$) by\nintegrating a Boolean satisfiability (SAT) solver with a computer algebra\nsystem (CAS). Our SAT+CAS approach significantly outperforms traditional\nSAT-only methods, demonstrating an improvement of several orders of magnitude\nin runtime. For instance, our SAT+CAS approach solves $R(3, 8)$ (resp., $R(8,\n3)$) sequentially in 59 hours (resp., in 11 hours), while a SAT-only approach\nusing state-of-the-art CaDiCaL solver times out after 7 days. Additionally, in\norder to be able to scale to harder Ramsey problems $R(3, 9)$ and $R(9, 3)$ we\nfurther optimized our SAT+CAS tool using a parallelized cube-and-conquer\napproach. Our results provide the first independently verifiable certificates\nfor these Ramsey numbers, ensuring both correctness and completeness of the\nexhaustive search process of our SAT+CAS tool.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8eSAT+CAS\u7684\u65b0\u65b9\u6cd5\uff0c\u6709\u6548\u4e14\u9ad8\u6548\u5730\u6c42\u89e3\u5e76\u9a8c\u8bc1\u4e86R(3,8)\u548cR(3,9)\u7b49Ramsey\u6570\uff0c\u9996\u6b21\u63d0\u4f9b\u4e86\u53ef\u9a8c\u8bc1\u8bc1\u4e66\uff0c\u5e76\u5927\u5e45\u63d0\u5347\u8ba1\u7b97\u901f\u5ea6\u3002", "motivation": "Ramsey\u95ee\u9898R(3, k)\u5728\u7ec4\u5408\u6570\u5b66\u548c\u56fe\u8bba\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u6b64\u524d\u5bf9\u5982R(3,8)\u548cR(3,9)\u7b49\u95ee\u9898\u7684\u8ba1\u7b97\u7ed3\u679c\u7f3a\u4e4f\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002\u4f5c\u8005\u5e0c\u671b\u89e3\u51b3\u8fd9\u4e00\u53ef\u9760\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u91c7\u7528MathCheck\u5de5\u5177\uff0c\u5c06\u5e03\u5c14\u53ef\u6ee1\u8db3\u6027(SAT)\u6c42\u89e3\u5668\u4e0e\u8ba1\u7b97\u673a\u4ee3\u6570\u7cfb\u7edf(CAS)\u7ed3\u5408\uff0c\u63d0\u51faSAT+CAS\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5e76\u884c\u5316cube-and-conquer\u6280\u672f\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "result": "SAT+CAS\u65b9\u6cd5\u5728R(3,8)\uff0859\u5c0f\u65f6\uff09\u548cR(8,3)\uff0811\u5c0f\u65f6\uff09\u4e0a\u8fdc\u5feb\u4e8e\u4f20\u7edfSAT\u65b9\u6cd5\uff087\u5929\u4ecd\u672a\u5b8c\u6210\uff09\uff0c\u5bf9\u4e8e\u66f4\u96be\u7684\u95ee\u9898R(3,9)\u548cR(9,3)\u4e5f\u901a\u8fc7\u4f18\u5316\u5e76\u884c\u5316\u5904\u7406\u3002\u9996\u6b21\u4e3a\u8fd9\u4e9bRamsey\u6570\u63d0\u4f9b\u53ef\u72ec\u7acb\u9a8c\u8bc1\u7684\u8bc1\u4e66\uff0c\u786e\u4fdd\u8fc7\u7a0b\u5b8c\u6574\u6027\u548c\u6b63\u786e\u6027\u3002", "conclusion": "SAT+CAS\u6cd5\u4e0d\u4ec5\u5927\u5e45\u52a0\u901f\u4e86Ramsey\u6570\u8ba1\u7b97\uff0c\u5e76\u901a\u8fc7\u53ef\u9a8c\u8bc1\u8bc1\u4e66\u5b9e\u73b0\u4e86\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff0c\u63d0\u5347\u4e86\u8ba1\u7b97\u6570\u5b66\u7684\u7ed3\u679c\u53ef\u9760\u6027\u3002"}}
{"id": "2507.05327", "categories": ["cs.LO", "math.AC", "14F30 (Primary) 13J05 (Secondary)"], "pdf": "https://arxiv.org/pdf/2507.05327", "abs": "https://arxiv.org/abs/2507.05327", "authors": ["Antoine Chambert-Loir", "Mar\u00eda In\u00e9s de Frutos-Fern\u00e1ndez"], "title": "A Formalization of Divided Powers in Lean", "comment": "16th International Conference on Interactive Theorem Proving (ITP\n  '25), 2025, Reykjavik, Iceland", "summary": "Given an ideal $I$ in a commutative ring $A$, a divided power structure on\n$I$ is a collection of maps $\\{\\gamma_n \\colon I \\to A\\}_{n \\in \\mathbb{N}}$,\nsubject to axioms that imply that it behaves like the family $\\{x \\mapsto\n\\frac{x^n}{n!}\\}_{n \\in \\mathbb{N}}$, but which can be defined even when\ndivision by factorials is not possible in $A$. Divided power structures have\nimportant applications in diverse areas of mathematics, including algebraic\ntopology, number theory and algebraic geometry.\n  In this article we describe a formalization in Lean 4 of the basic theory of\ndivided power structures, including divided power morphisms and sub-divided\npower ideals, and we provide several fundamental constructions, in particular\nquotients and sums. This constitutes the first formalization of this theory in\nany theorem prover.\n  As a prerequisite of general interest, we expand the formalized theory of\nmultivariate power series rings, endowing them with a topology and defining\nevaluation and substitution of power series.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5728Lean 4\u4e2d\u5f62\u5f0f\u5316\u4e86\u5206\u5f0f\u5e42\u7ed3\u6784\u7406\u8bba\uff0c\u5305\u62ec\u4ee3\u6570\u64cd\u4f5c\u4e0e\u57fa\u7840\u6784\u9020\uff0c\u5e76\u6269\u5c55\u4e86\u591a\u5143\u5e42\u7ea7\u6570\u73af\u7684\u5f62\u5f0f\u5316\u5de5\u5177\uff0c\u4e30\u5bcc\u4e86\u6570\u5b66\u9886\u57df\u81ea\u52a8\u8bc1\u660e\u7684\u652f\u6301\u5de5\u5177\u3002", "motivation": "\u5728\u8bb8\u591a\u6570\u5b66\u9886\u57df\uff08\u5982\u4ee3\u6570\u62d3\u6251\u3001\u6570\u8bba\u548c\u4ee3\u6570\u51e0\u4f55\uff09\u4e2d\uff0c\u5206\u5f0f\u5e42\u7ed3\u6784\u662f\u4e00\u79cd\u5173\u952e\u5de5\u5177\uff0c\u4f46\u5176\u7406\u8bba\u5c1a\u672a\u5728\u5f62\u5f0f\u5316\u8bc1\u660e\u7cfb\u7edf\u4e2d\u7cfb\u7edf\u5b9e\u73b0\u3002\u8be5\u5de5\u4f5c\u65e8\u5728\u586b\u8865\u5206\u5f0f\u5e42\u7ed3\u6784\u5728\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u7f3a\u4e4f\u6b63\u5f0f\u57fa\u7840\u8bbe\u65bd\u7684\u7a7a\u767d\u3002", "method": "\u4f5c\u8005\u5728Lean 4\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u5bf9\u5206\u5f0f\u5e42\u7ed3\u6784\u7684\u57fa\u672c\u7406\u8bba\u8fdb\u884c\u5f62\u5f0f\u5316\uff0c\u5305\u62ec\u5206\u5f0f\u5e42\u6001\u5c04\u548c\u5b50\u5206\u5f0f\u5e42\u7406\u60f3\uff0c\u5e76\u7ed9\u51fa\u4e86\u5546\u3001\u76f4\u548c\u7b49\u57fa\u7840\u6784\u9020\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u6269\u5c55\u4e86\u591a\u5143\u5e42\u7ea7\u6570\u73af\u7684\u5f62\u5f0f\u5316\u7406\u8bba\uff0c\u5b9e\u73b0\u4e86\u5176\u62d3\u6251\u7ed3\u6784\u3001\u5e42\u7ea7\u6570\u7684\u8d4b\u503c\u4e0e\u66ff\u6362\u5b9a\u4e49\u3002", "result": "\u4f5c\u8005\u9996\u6b21\u5728\u4efb\u4f55\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u5f62\u5f0f\u5316\u4e86\u5206\u5f0f\u5e42\u7ed3\u6784\u7684\u7406\u8bba\uff0c\u5e76\u5b8c\u5584\u4e86\u76f8\u5173\u591a\u5143\u5e42\u7ea7\u6570\u73af\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u652f\u6301\u5f62\u5f0f\u5316\u5206\u5f0f\u5e42\u76f8\u5173\u64cd\u4f5c\u3002", "conclusion": "\u672c\u6587\u4e3a\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u9886\u57df\u4e2d\u7684\u5206\u5f0f\u5e42\u7ed3\u6784\u7406\u8bba\u63d0\u4f9b\u4e86\u9996\u4e2a\u7cfb\u7edf\u7684\u5f62\u5f0f\u5316\u5b9e\u73b0\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.05269", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05269", "abs": "https://arxiv.org/abs/2507.05269", "authors": ["Danning Xie", "Mingwei Zheng", "Xuwei Liu", "Jiannan Wang", "Chengpeng Wang", "Lin Tan", "Xiangyu Zhang"], "title": "CORE: Benchmarking LLMs Code Reasoning Capabilities through Static Analysis Tasks", "comment": null, "summary": "Large language models (LLMs) have been widely adopted across diverse software\nengineering domains, such as code generation, program repair, and vulnerability\ndetection. These applications require understanding beyond surface-level code\npatterns: value propagation, control flow, and interdependence between program\nelements. However, existing benchmarks primarily evaluate end-to-end outcomes,\nsuch as whether code is correctly repaired or generated, leaving the models\nability for program semantic reasoning underexplored. This work presents CoRe,\na high-quality, human-verified benchmark designed to evaluate LLMs on\nfundamental static analysis tasks. CoRe includes 12,553 task instances spanning\ndata dependency, control dependency, and information flow across programs\nwritten in C/C++, Java, and Python. To ensure semantic diversity and reasoning\ncomplexity, we propose a semantics-aware diverse sampling strategy that selects\ntargets and task instances based on structural coverage and dependency depth.\nWe evaluate 10 mainstream LLMs and show that, while they perform well at\nidentifying dependencies, models still struggle with tasks that require deeper\nsemantic understanding and multi-step reasoning. We further conduct qualitative\nanalyses to uncover key challenges, such as complex control structures and\nbackward dependency patterns, offering insights into improving LLMs code\nreasoning capabilities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CoRe\u57fa\u51c6\uff0c\u7528\u4e8e\u8861\u91cf\u5927\u6a21\u578b\u5bf9\u7a0b\u5e8f\u7684\u4f9d\u8d56\u5206\u6790\u548c\u4fe1\u606f\u6d41\u7b49\u9759\u6001\u5206\u6790\u63a8\u7406\u80fd\u529b\u3002\u8bc4\u6d4b\u7ed3\u679c\u663e\u793a\u4e3b\u6d41\u5927\u6a21\u578b\u5728\u6df1\u5c42\u6b21\u8bed\u4e49\u63a8\u7406\u548c\u590d\u6742\u4f9d\u8d56\u5206\u6790\u80fd\u529b\u4e0a\u5b58\u5728\u6311\u6218\uff0c\u672a\u6765\u9700\u8fdb\u4e00\u6b65\u63d0\u5347\u76f8\u5173\u63a8\u7406\u6c34\u5e73\u3002", "motivation": "\u5f53\u524d\u5927\u6a21\u578b\u5e7f\u6cdb\u5e94\u7528\u4e8e\u4ee3\u7801\u751f\u6210\u3001\u7a0b\u5e8f\u4fee\u590d\u548c\u6f0f\u6d1e\u68c0\u6d4b\u7b49\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\uff0c\u4f46\u73b0\u6709\u57fa\u51c6\u591a\u805a\u7126\u4e8e\u6700\u7ec8\u7ed3\u679c\uff0c\u5982\u4ee3\u7801\u751f\u6210\u6216\u4fee\u590d\u662f\u5426\u6b63\u786e\uff0c\u7f3a\u4e4f\u5bf9\u6a21\u578b\u7a0b\u5e8f\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u7684\u6df1\u5ea6\u8003\u5bdf\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86CoRe\u9ad8\u8d28\u91cf\u57fa\u51c6\uff0c\u7528\u4ee5\u8bc4\u4f30\u5927\u6a21\u578b\u5728\u57fa\u672c\u9759\u6001\u5206\u6790\u4efb\u52a1\uff08\u6570\u636e\u4f9d\u8d56\u3001\u63a7\u5236\u4f9d\u8d56\u3001\u4fe1\u606f\u6d41\uff09\u7684\u63a8\u7406\u80fd\u529b\u3002\u57fa\u51c6\u8986\u76d6C/C++\u3001Java\u548cPython\uff0c\u901a\u8fc7\u8bed\u4e49\u611f\u77e5\u7684\u591a\u6837\u6027\u91c7\u6837\u7b56\u7565\uff0c\u63d0\u5347\u4efb\u52a1\u5b9e\u4f8b\u7684\u7ed3\u6784\u8986\u76d6\u5ea6\u548c\u4f9d\u8d56\u6df1\u5ea6\uff0c\u5e76\u5bf910\u4e2a\u4e3b\u6d41\u5927\u6a21\u578b\u8fdb\u884c\u8bc4\u6d4b\u548c\u5b9a\u6027\u5206\u6790\u3002", "result": "\u5404\u4e3b\u6d41\u5927\u6a21\u578b\u5728\u4f9d\u8d56\u8bc6\u522b\u4efb\u52a1\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9700\u8981\u66f4\u590d\u6742\u8bed\u4e49\u7406\u89e3\u548c\u591a\u6b65\u63a8\u7406\u7684\u4efb\u52a1\u4e0a\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u5c24\u5176\u662f\u5bf9\u590d\u6742\u63a7\u5236\u7ed3\u6784\u548c\u9006\u5411\u4f9d\u8d56\u6a21\u5f0f\u96be\u4ee5\u5904\u7406\u3002", "conclusion": "\u63d0\u51fa\u7684CoRe\u57fa\u51c6\u6709\u6548\u8865\u9f50\u8bc4\u6d4b\u5927\u6a21\u578b\u7a0b\u5e8f\u63a8\u7406\u80fd\u529b\u7684\u77ed\u677f\u3002\u5f53\u524d\u6a21\u578b\u5728\u590d\u6742\u8bed\u4e49\u63a8\u7406\u548c\u591a\u6b65\u5206\u6790\u4e0a\u8868\u73b0\u6709\u9650\uff0c\u4e3a\u540e\u7eed\u63d0\u5347\u5927\u6a21\u578b\u4ee3\u7801\u7406\u89e3\u4e0e\u63a8\u7406\u80fd\u529b\u6307\u660e\u65b9\u5411\u3002"}}
{"id": "2507.05261", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.05261", "abs": "https://arxiv.org/abs/2507.05261", "authors": ["Yingtai Xiao", "Yuqing Zhu", "Sirat Samyoun", "Wanrong Zhang", "Jiachen T. Wang", "Jian Du"], "title": "TokenShapley: Token Level Context Attribution with Shapley Value", "comment": null, "summary": "Large language models (LLMs) demonstrate strong capabilities in in-context\nlearning, but verifying the correctness of their generated responses remains a\nchallenge. Prior work has explored attribution at the sentence level, but these\nmethods fall short when users seek attribution for specific keywords within the\nresponse, such as numbers, years, or names. To address this limitation, we\npropose TokenShapley, a novel token-level attribution method that combines\nShapley value-based data attribution with KNN-based retrieval techniques\ninspired by recent advances in KNN-augmented LLMs. By leveraging a precomputed\ndatastore for contextual retrieval and computing Shapley values to quantify\ntoken importance, TokenShapley provides a fine-grained data attribution\napproach. Extensive evaluations on four benchmarks show that TokenShapley\noutperforms state-of-the-art baselines in token-level attribution, achieving an\n11-23% improvement in accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86TokenShapley\uff0c\u4e00\u79cd\u5c06Shapley\u503c\u5f52\u56e0\u4e0eKNN\u68c0\u7d22\u76f8\u7ed3\u5408\u7684\u65b0\u578btoken\u7ea7\u5f52\u56e0\u65b9\u6cd5\u3002\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u7cbe\u786e\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u63a8\u8fdb\u4e86LLM\u54cd\u5e94\u7ec6\u7c92\u5ea6\u9a8c\u8bc1\u7684\u53d1\u5c55\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u9762\u80fd\u529b\u5f3a\uff0c\u4f46\u5176\u751f\u6210\u54cd\u5e94\u5185\u5bb9\u7684\u6b63\u786e\u6027\u96be\u4ee5\u9a8c\u8bc1\u3002\u73b0\u6709\u65b9\u6cd5\u591a\u9488\u5bf9\u4e8e\u53e5\u5b50\u7ea7\u5f52\u56e0\uff0c\u96be\u4ee5\u6ee1\u8db3\u7528\u6237\u9488\u5bf9\u5173\u952e\u8bcd\uff08\u5982\u6570\u5b57\u3001\u5e74\u4efd\u3001\u59d3\u540d\uff09\u5c42\u9762\u7684\u5f52\u56e0\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684token\u7ea7\u5f52\u56e0\u65b9\u6cd5TokenShapley\uff0c\u7ed3\u5408\u4e86\u57fa\u4e8eShapley\u503c\u7684\u6570\u636e\u5f52\u56e0\u548cKNN\u68c0\u7d22\u6280\u672f\u3002\u901a\u8fc7\u9884\u8ba1\u7b97\u6570\u636e\u5b58\u50a8\u8fdb\u884c\u4e0a\u4e0b\u6587\u68c0\u7d22\uff0c\u5e76\u7528Shapley\u503c\u91cf\u5316\u6bcf\u4e2atoken\u7684\u91cd\u8981\u6027\uff0c\u5b9e\u73b0\u66f4\u7ec6\u7c92\u5ea6\u7684\u6570\u636e\u5f52\u56e0\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u6d4b\u8868\u660e\uff0cTokenShapley\u5728token\u7ea7\u5f52\u56e0\u51c6\u786e\u7387\u4e0a\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u9ad8\u51fa11-23%\u3002", "conclusion": "TokenShapley\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u7ec6\u81f4\u4e14\u6709\u6548\u7684token\u7ea7\u6570\u636e\u5f52\u56e0\u65b9\u6cd5\uff0c\u5927\u5e45\u63d0\u9ad8\u4e86\u5f52\u56e0\u51c6\u786e\u6027\u3002"}}
{"id": "2507.05272", "categories": ["cs.SE", "cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.05272", "abs": "https://arxiv.org/abs/2507.05272", "authors": ["Daragh King", "Vasileios Koutavas", "Laura Kovacs"], "title": "FuzzFeed: An Automatic Approach to Weakest Precondition Generation using LLMs and Fuzzing", "comment": null, "summary": "The weakest precondition (WP) of a program describes the largest set of\ninitial states from which all terminating executions of the program satisfy a\ngiven postcondition. The generation of WPs is an important task with practical\napplications in areas ranging from verification to run-time error checking.\n  This paper proposes the combination of Large Language Models (LLMs) and fuzz\ntesting for generating WPs. In pursuit of this goal, we introduce Fuzzing\nGuidance (FG); FG acts as a means of directing LLMs towards correct WPs using\nprogram execution feedback. FG utilises fuzz testing for approximately checking\nthe validity and weakness of candidate WPs, this information is then fed back\nto the LLM as a means of context refinement.\n  We demonstrate the effectiveness of our approach on a comprehensive benchmark\nset of deterministic array programs in Java. Our experiments indicate that LLMs\nare capable of producing viable candidate WPs, and that this ability can be\npractically enhanced through FG.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408LLM\u4e0e\u6a21\u7cca\u6d4b\u8bd5\uff0c\u901a\u8fc7Fuzzing Guidance\u53cd\u9988\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86\u7a0b\u5e8fWP\u7684\u81ea\u52a8\u751f\u6210\u8d28\u91cf\uff0c\u5728Java\u6570\u7ec4\u7a0b\u5e8f\u6d4b\u8bd5\u96c6\u4e0a\u6548\u679c\u663e\u8457\u3002", "motivation": "\u5f31\u524d\u7f6e\u6761\u4ef6\uff08WP\uff09\u662f\u7a0b\u5e8f\u9a8c\u8bc1\u4e0e\u8fd0\u884c\u65f6\u9519\u8bef\u68c0\u6d4b\u7b49\u5e94\u7528\u4e2d\u7684\u5173\u952e\u751f\u6210\u4efb\u52a1\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u9762\u4e34\u51c6\u786e\u6027\u4e0e\u9ad8\u6548\u6027\u6311\u6218\uff0c\u56e0\u6b64\u7814\u7a76\u7ed3\u5408AI\u8f85\u52a9\u4e0e\u7a0b\u5e8f\u6d4b\u8bd5\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u5c06\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0e\u6a21\u7cca\u6d4b\u8bd5\u7ed3\u5408\uff0c\u63d0\u51faFuzzing Guidance\uff08FG\uff09\u673a\u5236\uff0c\u901a\u8fc7\u7a0b\u5e8f\u6267\u884c\u53cd\u9988\u5f15\u5bfcLLM\u4f18\u5316WP\u751f\u6210\uff1b\u5229\u7528\u6a21\u7cca\u6d4b\u8bd5\u68c0\u67e5\u5019\u9009WP\u7684\u6709\u6548\u6027\u4e0e\u5f31\u5ea6\uff0c\u518d\u5c06\u4fe1\u606f\u53cd\u9988\u56deLLM\u8fdb\u884c\u4e0a\u4e0b\u6587\u4f18\u5316\u3002", "result": "LLM\u80fd\u6709\u6548\u751f\u6210\u53ef\u884c\u7684WP\uff0c\u7ed3\u5408FG\u53cd\u9988\u540e\uff0c\u5176\u751f\u6210\u7ed3\u679c\u5728Java\u6570\u7ec4\u7a0b\u5e8f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u8d8a\u3002", "conclusion": "LLM\u751f\u6210\u7684WP\u5728FG\u65b9\u6cd5\u7684\u8f85\u52a9\u4e0b\uff0c\u5176\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u5f97\u5230\u4e86\u660e\u663e\u63d0\u5347\u3002"}}
{"id": "2507.05270", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.05270", "abs": "https://arxiv.org/abs/2507.05270", "authors": ["Boyuan Li", "Chengwei Liu", "Lingling Fan", "Sen Chen", "Zhenlin Zhang", "Zheli Liu"], "title": "Open Source, Hidden Costs: A Systematic Literature Review on OSS License Management", "comment": null, "summary": "Integrating third-party software components is a common practice in modern\nsoftware development, offering significant advantages in terms of efficiency\nand innovation. However, this practice is fraught with risks related to\nsoftware licensing. A lack of understanding may lead to disputes, which can\npose serious legal and operational challenges. To these ends, both academia and\nindustry have conducted various investigations and proposed solutions and tools\nto deal with these challenges. However, significant limitations still remain.\nMoreover, the rapid evolution of open-source software (OSS) licenses, as well\nas the rapidly incorporated generative software engineering techniques, such as\nlarge language models for code (CodeLLMs), are placing greater demands on the\nsystematic management of software license risks. To unveil the severe\nchallenges and explore possible future directions, we conduct the first\nsystematic literature review (SLR) on 80 carefully selected OSS license-related\npapers, classifying existing research into three key categories, i.e., license\nidentification, license risk assessment, and license risk mitigation. Based on\nthese, we discuss challenges in existing solutions, conclude the opportunities\nto shed light on future research directions and offer practical recommendations\nfor practitioners. We hope this thorough review will help bridge the gaps\nbetween academia and industry and accelerate the ecosystem-wide governance of\nlegitimate software risks within the software engineering community.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u68b3\u7406\u4e86\u5f00\u6e90\u8f6f\u4ef6\u8bb8\u53ef\u7684\u8bc6\u522b\u3001\u98ce\u9669\u53ca\u7f13\u89e3\u4e09\u5927\u65b9\u5411\uff0c\u603b\u7ed3\u5f53\u524d\u6311\u6218\u5e76\u5c55\u671b\u672a\u6765\uff0c\u65e8\u5728\u5e2e\u52a9\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u66f4\u597d\u5e94\u5bf9\u76f8\u5173\u6cd5\u5f8b\u53ca\u5408\u89c4\u98ce\u9669\u3002", "motivation": "\u968f\u7740\u73b0\u4ee3\u8f6f\u4ef6\u5f00\u53d1\u8d8a\u6765\u8d8a\u4f9d\u8d56\u7b2c\u4e09\u65b9\u8f6f\u4ef6\u7ec4\u4ef6\uff0c\u867d\u7136\u80fd\u63d0\u9ad8\u6548\u7387\u548c\u521b\u65b0\u6027\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u590d\u6742\u7684\u8f6f\u4ef6\u8bb8\u53ef\u98ce\u9669\u548c\u6cd5\u5f8b\u95ee\u9898\u3002\u5f53\u524d\u5b66\u672f\u754c\u4e0e\u5de5\u4e1a\u754c\u867d\u6709\u6240\u5e94\u5bf9\uff0c\u4f46\u4ecd\u6709\u91cd\u5927\u5c40\u9650\uff0c\u5c24\u5176\u9762\u4e34\u5f00\u6e90\u8bb8\u53ef\u8bc1\u5feb\u901f\u53d8\u5316\u4e0e\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u65b0\u6280\u672f\u7684\u6311\u6218\u3002", "method": "\u672c\u8bba\u6587\u5bf980\u7bc7\u4e0e\u5f00\u6e90\u8f6f\u4ef6\u8bb8\u53ef\u76f8\u5173\u7684\u8bba\u6587\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff08Systematic Literature Review, SLR\uff09\uff0c\u5c06\u73b0\u6709\u7814\u7a76\u5206\u4e3a\u4e09\u4e2a\u4e3b\u8981\u7c7b\u522b\uff1a\u8bb8\u53ef\u8bc6\u522b\u3001\u8bb8\u53ef\u98ce\u9669\u8bc4\u4f30\u548c\u8bb8\u53ef\u98ce\u9669\u7f13\u89e3\u3002", "result": "\u901a\u8fc7\u5206\u7c7b\u68b3\u7406\u73b0\u6709\u7814\u7a76\uff0c\u8bba\u6587\u603b\u7ed3\u5e76\u8ba8\u8bba\u4e86\u5f53\u524d\u89e3\u51b3\u65b9\u6848\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5e76\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u5b9e\u8df5\u5efa\u8bae\u3002", "conclusion": "\u672c\u7efc\u8ff0\u6709\u52a9\u4e8e\u5b66\u672f\u754c\u548c\u4e1a\u754c\u4e86\u89e3\u8f6f\u4ef6\u8bb8\u53ef\u98ce\u9669\u6cbb\u7406\u7684\u73b0\u72b6\u4e0e\u6311\u6218\uff0c\u7f29\u5c0f\u4e24\u8005\u95f4\u7684\u6c9f\u901a\u9e3f\u6c9f\uff0c\u5e76\u63a8\u52a8\u6574\u4e2a\u8f6f\u4ef6\u5de5\u7a0b\u793e\u533a\u5bf9\u5408\u6cd5\u6027\u98ce\u9669\u7684\u6cbb\u7406\u3002"}}
{"id": "2507.05266", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05266", "abs": "https://arxiv.org/abs/2507.05266", "authors": ["Sougata Saha", "Monojit Choudhury"], "title": "User Behavior Prediction as a Generic, Robust, Scalable, and Low-Cost Evaluation Strategy for Estimating Generalization in LLMs", "comment": null, "summary": "Measuring the generalization ability of Large Language Models (LLMs) is\nchallenging due to data contamination. As models grow and computation becomes\ncheaper, ensuring tasks and test cases are unseen during training phases will\nbecome nearly impossible. We argue that knowledge-retrieval and reasoning tasks\nare not ideal for measuring generalization, as LLMs are not trained for\nspecific tasks. Instead, we propose user behavior prediction, also a key aspect\nof personalization, as a theoretically sound, scalable, and robust alternative.\nWe introduce a novel framework for this approach and test it on movie and music\nrecommendation datasets for GPT-4o, GPT-4o-mini, and Llama-3.1-8B-Instruct.\nResults align with our framework's predictions, showing GPT-4o outperforms\nGPT-4o-mini and Llama, though all models have much room for improvement,\nespecially Llama.", "AI": {"tldr": "\u672c\u6587\u8ba4\u4e3a\u73b0\u6709\u6cdb\u5316\u80fd\u529b\u8bc4\u6d4b\u53d7\u6570\u636e\u6c61\u67d3\u5f71\u54cd\uff0c\u63d0\u51fa\u7528\u7528\u6237\u884c\u4e3a\u9884\u6d4b\u4f5c\u4e3a\u66f4\u5408\u9002\u7684\u8bc4\u6d4b\u65b9\u5f0f\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u53ef\u884c\uff0cGPT-4o\u8868\u73b0\u6700\u597d\uff0c\u4f46\u6574\u4f53\u4ecd\u6709\u8f83\u5927\u63d0\u5347\u7a7a\u95f4\u3002", "motivation": "\u5f53\u524d\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u6d4b\u91cf\u56e0\u6570\u636e\u6c61\u67d3\u95ee\u9898\u53d8\u5f97\u56f0\u96be\uff0c\u968f\u7740\u6a21\u578b\u4f53\u91cf\u589e\u5927\u548c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\uff0c\u786e\u4fdd\u6d4b\u8bd5\u4efb\u52a1\u548c\u6570\u636e\u672a\u5728\u8bad\u7ec3\u4e2d\u51fa\u73b0\u53d8\u5f97\u51e0\u4e4e\u4e0d\u53ef\u80fd\u3002\u56e0\u6b64\uff0c\u73b0\u6709\u57fa\u4e8e\u77e5\u8bc6\u68c0\u7d22\u4e0e\u63a8\u7406\u7684\u6cdb\u5316\u8bc4\u4f30\u65b9\u5f0f\u5e76\u4e0d\u7406\u60f3\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u5c06\u7528\u6237\u884c\u4e3a\u9884\u6d4b\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u4e14\u5065\u5168\u7684\u6cdb\u5316\u80fd\u529b\u8bc4\u6d4b\u65b9\u6cd5\uff0c\u5e76\u6784\u5efa\u4e86\u76f8\u5e94\u7684\u8bc4\u6d4b\u6846\u67b6\u3002\u4f5c\u8005\u5728\u7535\u5f71\u4e0e\u97f3\u4e50\u63a8\u8350\u6570\u636e\u96c6\u4e0a\uff0c\u5bf9GPT-4o\u3001GPT-4o-mini\u4ee5\u53caLlama-3.1-8B-Instruct\u8fdb\u884c\u4e86\u5b9e\u8bc1\u6d4b\u8bd5\u3002", "result": "\u6d4b\u8bd5\u7ed3\u679c\u663e\u793a\uff0cGPT-4o\u4f18\u4e8eGPT-4o-mini\u548cLlama-3.1-8B-Instruct\uff0c\u4f46\u6240\u6709\u6a21\u578b\uff08\u7279\u522b\u662fLlama\uff09\u5728\u63a8\u8350\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u90fd\u8fd8\u6709\u663e\u8457\u63d0\u5347\u7a7a\u95f4\u3002", "conclusion": "\u7528\u6237\u884c\u4e3a\u9884\u6d4b\u4f5c\u4e3a\u6cdb\u5316\u80fd\u529b\u7684\u8bc4\u6d4b\u65b9\u5f0f\uff0c\u5177\u6709\u7406\u8bba\u5408\u7406\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\uff0c\u66f4\u7b26\u5408\u5927\u6a21\u578b\u672a\u6765\u7684\u8bc4\u6d4b\u9700\u6c42\u3002\u6846\u67b6\u7684\u5b9e\u8bc1\u7ed3\u679c\u4e5f\u652f\u6301\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2507.05271", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05271", "abs": "https://arxiv.org/abs/2507.05271", "authors": ["Mohammad Zia Ur Rehman", "Aditya Shah", "Nagendra Kumar"], "title": "An Adaptive Supervised Contrastive Learning Framework for Implicit Sexism Detection in Digital Social Networks", "comment": null, "summary": "The global reach of social media has amplified the spread of hateful content,\nincluding implicit sexism, which is often overlooked by conventional detection\nmethods. In this work, we introduce an Adaptive Supervised Contrastive lEarning\nframework for implicit sexism detectioN (ASCEND). A key innovation of our\nmethod is the incorporation of threshold-based contrastive learning: by\ncomputing cosine similarities between embeddings, we selectively treat only\nthose sample pairs as positive if their similarity exceeds a learnable\nthreshold. This mechanism refines the embedding space by robustly pulling\ntogether representations of semantically similar texts while pushing apart\ndissimilar ones, thus reducing false positives and negatives. The final\nclassification is achieved by jointly optimizing a contrastive loss with a\ncross-entropy loss. Textual features are enhanced through a word-level\nattention module. Additionally, we employ sentiment, emotion, and toxicity\nfeatures. Evaluations on the EXIST2021 and MLSC datasets demonstrate that\nASCEND significantly outperforms existing methods, with average Macro F1\nimprovements of 9.86%, 29.63%, and 32.51% across multiple tasks, highlighting\nits efficacy in capturing the subtle cues of implicit sexist language.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u9002\u5e94\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u7684\u65b0\u65b9\u6cd5ASCEND\uff0c\u7528\u4e8e\u68c0\u6d4b\u793e\u4ea4\u5a92\u4f53\u4e2d\u7684\u9690\u6027\u6027\u522b\u6b67\u89c6\uff0c\u901a\u8fc7\u521b\u65b0\u5bf9\u6bd4\u673a\u5236\u3001\u7279\u5f81\u589e\u5f3a\u548c\u591a\u79cd\u635f\u5931\u4f18\u5316\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u4f20\u7edf\u7684\u68c0\u6d4b\u65b9\u6cd5\u5f80\u5f80\u96be\u4ee5\u8bc6\u522b\u793e\u4ea4\u5a92\u4f53\u4e2d\u9690\u542b\u7684\u6027\u522b\u6b67\u89c6\u8a00\u8bba\uff0c\u8fd9\u7c7b\u5185\u5bb9\u4f20\u64ad\u5e7f\u6cdb\u5374\u5e38\u88ab\u5ffd\u89c6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff08ASCEND\uff09\u7528\u4e8e\u9690\u6027\u6027\u522b\u6b67\u89c6\u68c0\u6d4b\u3002\u65b9\u6cd5\u6838\u5fc3\u4e3a\u57fa\u4e8e\u9608\u503c\u7684\u5bf9\u6bd4\u5b66\u4e60\uff0c\u901a\u8fc7\u8ba1\u7b97\u5d4c\u5165\u95f4\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff0c\u4ec5\u5c06\u76f8\u4f3c\u5ea6\u8d85\u8fc7\u5b66\u4e60\u9608\u503c\u7684\u6837\u672c\u5bf9\u4f5c\u4e3a\u6b63\u6837\u672c\uff0c\u4ee5\u4f18\u5316\u8bed\u4e49\u76f8\u4f3c\u6587\u672c\u7684\u5d4c\u5165\u5206\u5e03\uff0c\u5e76\u62c9\u5927\u4e0e\u4e0d\u76f8\u4f3c\u6587\u672c\u7684\u8ddd\u79bb\uff0c\u4ece\u800c\u51cf\u5c11\u8bef\u62a5\u548c\u6f0f\u62a5\u3002\u6700\u7ec8\u6a21\u578b\u91c7\u7528\u5bf9\u6bd4\u635f\u5931\u548c\u4ea4\u53c9\u71b5\u635f\u5931\u8054\u5408\u4f18\u5316\uff0c\u5e76\u5f15\u5165\u8bcd\u7ea7\u6ce8\u610f\u529b\u673a\u5236\u4ee5\u53ca\u60c5\u611f\u3001\u60c5\u7eea\u548c\u6709\u5bb3\u6027\u7279\u5f81\u63d0\u5347\u8868\u73b0\u3002", "result": "\u5728EXIST2021\u548cMLSC\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u591a\u4e2a\u4efb\u52a1\u7684Macro F1\u4e0a\u5206\u522b\u63d0\u5347\u4e869.86%\u300129.63%\u548c32.51%\uff0c\u6548\u679c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "ASCEND\u80fd\u591f\u66f4\u6709\u6548\u5730\u6355\u6349\u8bed\u53e5\u4e2d\u7684\u9690\u6027\u6027\u522b\u6b67\u89c6\u4fe1\u53f7\uff0c\u5bf9\u6bd4\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5177\u6709\u660e\u663e\u4f18\u52bf\u3002"}}
{"id": "2507.05279", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.05279", "abs": "https://arxiv.org/abs/2507.05279", "authors": ["Virgile Boraud", "Yannis Bendi-Ouis", "Paul Bernard", "Xavier Hinaut"], "title": "ReservoirChat: Interactive Documentation Enhanced with LLM and Knowledge Graph for ReservoirPy", "comment": null, "summary": "We introduce a tool designed to improve the capabilities of Large Language\nModels (LLMs) in assisting with code development using the ReservoirPy library,\nas well as in answering complex questions in the field of Reservoir Computing.\nBy incorporating external knowledge through Retrieval-Augmented Generation\n(RAG) and knowledge graphs, our approach aims to reduce hallucinations and\nincrease the factual accuracy of generated responses. The system provides an\ninteractive experience similar to ChatGPT, tailored specifically for\nReservoirPy, enabling users to write, debug, and understand Python code while\naccessing reliable domain-specific insights. In our evaluation, while\nproprietary models such as ChatGPT-4o and NotebookLM performed slightly better\non general knowledge questions, our model outperformed them on coding tasks and\nshowed a significant improvement over its base model, Codestral-22B.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u7ed3\u5408RAG\u548c\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3aLLM\u7528\u4e8eReservoirPy\u9886\u57df\u7684\u4ee3\u7801\u8f85\u52a9\u53ca\u95ee\u7b54\u7cfb\u7edf\uff0c\u7ed3\u679c\u663e\u793a\u5176\u5728\u7f16\u7a0b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u4e3b\u6d41LLM\uff0c\u5e76\u6709\u6548\u63d0\u5347\u4e86\u57fa\u7840\u6a21\u578b\u7684\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u7f16\u7801\u8f85\u52a9\u548c\u590d\u6742\u9886\u57df\u77e5\u8bc6\u95ee\u7b54\u4e2d\u5b58\u5728\u5e7b\u89c9\u548c\u51c6\u786e\u6027\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u4e13\u7528\u9886\u57df\u5982Reservoir Computing\u3002\u4e3a\u63d0\u5347LLM\u5e2e\u52a9\u5f00\u53d1\u548c\u77e5\u8bc6\u95ee\u7b54\u7684\u8d28\u91cf\uff0c\u9700\u8981\u5f15\u5165\u66f4\u53ef\u9760\u7684\u5916\u90e8\u77e5\u8bc6\u548c\u5de5\u5177\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4e0e\u77e5\u8bc6\u56fe\u8c31\u7684\u65b9\u6cd5\uff0c\u5c06\u5916\u90e8\u9886\u57df\u77e5\u8bc6\u5f15\u5165LLM\uff0c\u4e13\u95e8\u9488\u5bf9ReservoirPy\u5e93\u3002\u8be5\u7cfb\u7edf\u5177\u6709\u7c7b\u4f3cChatGPT\u7684\u4ea4\u4e92\u4f53\u9a8c\uff0c\u7528\u6237\u53ef\u7528\u5176\u7f16\u5199\u3001\u8c03\u8bd5\u548c\u7406\u89e3Python\u4ee3\u7801\uff0c\u5e76\u83b7\u53d6\u9ad8\u53ef\u4fe1\u5ea6\u7684\u9886\u57df\u77e5\u8bc6\u7b54\u6848\u3002", "result": "\u5728\u5b9e\u9a8c\u8bc4\u4f30\u4e2d\uff0c\u867d\u7136\u5546\u4e1a\u6a21\u578b\uff08\u5982ChatGPT-4o\u3001NotebookLM\uff09\u5728\u4e00\u822c\u77e5\u8bc6\u95ee\u7b54\u4e0a\u7565\u4f18\uff0c\u4f46\u8be5\u6a21\u578b\u5728\u7f16\u7801\u4efb\u52a1\u4e0a\u4f18\u4e8e\u4e0a\u8ff0\u6a21\u578b\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86\u81ea\u8eab\u57fa\u7840\u6a21\u578b\uff08Codestral-22B\uff09\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5c06RAG\u548c\u77e5\u8bc6\u56fe\u8c31\u5f15\u5165LLM\uff0c\u80fd\u591f\u663e\u8457\u589e\u5f3a\u5176\u5728ReservoirPy\u76f8\u5173\u7f16\u7801\u548c\u4e13\u6709\u9886\u57df\u77e5\u8bc6\u95ee\u7b54\u4e2d\u7684\u80fd\u529b\uff0c\u51cf\u5c11\u5e7b\u89c9\uff0c\u63d0\u5347\u51c6\u786e\u6027\u3002"}}
{"id": "2507.05285", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.IR", "I.2.7; I.2.1; K.3.1"], "pdf": "https://arxiv.org/pdf/2507.05285", "abs": "https://arxiv.org/abs/2507.05285", "authors": ["Miloud Mihoubi", "Meriem Zerkouk", "Belkacem Chikhaoui"], "title": "Beyond classical and contemporary models: a transformative ai framework for student dropout prediction in distance learning using rag, prompt engineering, and cross-modal fusion", "comment": "10 pages, 5 figures, 5 tables. Submitted to the 38th Canadian\n  Conference on Artificial Intelligence (Canadian AI 2025)", "summary": "Student dropout in distance learning remains a critical challenge, with\nprofound societal and economic consequences. While classical machine learning\nmodels leverage structured socio-demographic and behavioral data, they often\nfail to capture the nuanced emotional and contextual factors embedded in\nunstructured student interactions. This paper introduces a transformative AI\nframework that redefines dropout prediction through three synergistic\ninnovations: Retrieval-Augmented Generation (RAG) for domain-specific sentiment\nanalysis, prompt engineering to decode academic stressors, and cross-modal\nattention fusion to dynamically align textual, behavioral, and\nsocio-demographic insights. By grounding sentiment analysis in a curated\nknowledge base of pedagogical content, our RAG-enhanced BERT model interprets\nstudent comments with unprecedented contextual relevance, while optimized\nprompts isolate indicators of academic distress (e.g., \"isolation,\" \"workload\nanxiety\"). A cross-modal attention layer then fuses these insights with\ntemporal engagement patterns, creating holistic risk profiles. Evaluated on a\nlongitudinal dataset of 4 423 students, the framework achieves 89% accuracy and\nan F1-score of 0.88, outperforming conventional models by 7% and reducing false\nnegatives by 21%. Beyond prediction, the system generates interpretable\ninterventions by retrieving contextually aligned strategies (e.g., mentorship\nprograms for isolated learners). This work bridges the gap between predictive\nanalytics and actionable pedagogy, offering a scalable solution to mitigate\ndropout risks in global education systems", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eRAG\u3001Prompt\u5de5\u7a0b\u548c\u591a\u6a21\u6001\u878d\u5408\u7684\u65b0\u578bAI\u65b9\u6cd5\uff0c\u5927\u5e45\u63d0\u5347\u8fdc\u7a0b\u5b66\u4e60\u8f8d\u5b66\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u5e76\u80fd\u81ea\u52a8\u751f\u6210\u4e2a\u6027\u5316\u5e72\u9884\u5efa\u8bae\uff0c\u5b9e\u73b0\u8f8d\u5b66\u9632\u63a7\u7684\u667a\u80fd\u5316\u548c\u53ef\u64cd\u4f5c\u5316\u3002", "motivation": "\u8fdc\u7a0b\u5b66\u4e60\u4e2d\u7684\u5b66\u751f\u8f8d\u5b66\u7387\u9ad8\uff0c\u4ea7\u751f\u91cd\u5927\u7684\u793e\u4f1a\u548c\u7ecf\u6d4e\u5f71\u54cd\u3002\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u867d\u7136\u5229\u7528\u4e86\u7ed3\u6784\u5316\u7684\u4eba\u53e3\u7edf\u8ba1\u548c\u884c\u4e3a\u6570\u636e\uff0c\u4f46\u96be\u4ee5\u6355\u6349\u5230\u5b66\u751f\u4ea4\u6d41\u4e2d\u7684\u60c5\u611f\u53ca\u80cc\u666f\u56e0\u7d20\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u7ed3\u5408\u591a\u6a21\u6001\u6570\u636e\u548c\u66f4\u6df1\u5c42\u60c5\u611f\u5206\u6790\u7684\u65b0\u65b9\u6cd5\uff0c\u63d0\u5347\u8f8d\u5b66\u9884\u8b66\u7684\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u521b\u65b0\u6027AI\u6846\u67b6\uff0c\u5305\u62ec\u4e09\u5927\u521b\u65b0\uff1a1\uff09\u57fa\u4e8eRetrieval-Augmented Generation\uff08RAG\uff09\u7684\u9886\u57df\u7279\u5b9a\u60c5\u611f\u5206\u6790\u6a21\u578b\uff0c\u5c06BERT\u4e0e\u6559\u80b2\u5185\u5bb9\u77e5\u8bc6\u5e93\u7ed3\u5408\uff0c\u63d0\u5347\u5bf9\u5b66\u751f\u8bc4\u8bba\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\uff1b2\uff09\u901a\u8fc7Prompt\u5de5\u7a0b\uff0c\u4e13\u95e8\u63d0\u53d6\u5b66\u4e1a\u538b\u529b\u76f8\u5173\u7279\u5f81\uff08\u5982\u5b64\u7acb\u3001\u7126\u8651\u7b49\uff09\uff1b3\uff09\u91c7\u7528\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u878d\u5408\u673a\u5236\uff0c\u5c06\u6587\u672c\u60c5\u611f\u3001\u884c\u4e3a\u6570\u636e\u53ca\u4eba\u53e3\u5b66\u7279\u5f81\u52a8\u6001\u6574\u5408\uff0c\u5f62\u6210\u5168\u65b9\u4f4d\u5b66\u751f\u98ce\u9669\u753b\u50cf\u3002", "result": "\u5728\u5305\u542b4,423\u540d\u5b66\u751f\u7684\u7eb5\u5411\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u6846\u67b6\u5b9e\u73b0\u4e8689%\u7684\u51c6\u786e\u7387\u548c0.88\u7684F1\u5206\u6570\uff0c\u6bd4\u4f20\u7edf\u6a21\u578b\u63d0\u9ad87%\uff0c\u5047\u9634\u6027\u7387\u964d\u4f4e21%\u3002\u540c\u65f6\u7cfb\u7edf\u80fd\u591f\u68c0\u7d22\u4e0e\u5b66\u751f\u5177\u4f53\u56f0\u5883\u76f8\u5339\u914d\u7684\u5e72\u9884\u5efa\u8bae\uff0c\u63d0\u9ad8\u4e86\u64cd\u4f5c\u6027\u548c\u5b9e\u9645\u6559\u80b2\u6307\u5bfc\u610f\u4e49\u3002", "conclusion": "\u6587\u4e2dAI\u6846\u67b6\u4e0d\u4ec5\u63d0\u5347\u4e86\u8fdc\u7a0b\u5b66\u4e60\u8f8d\u5b66\u9884\u6d4b\u7684\u7cbe\u5ea6\u548c\u89e3\u91ca\u6027\uff0c\u8fd8\u80fd\u57fa\u4e8e\u5b9e\u9645\u5b66\u60c5\u63d0\u4f9b\u9488\u5bf9\u6027\u5e72\u9884\u7b56\u7565\uff0c\u5b9e\u73b0\u4ece\u6570\u636e\u9884\u6d4b\u5230\u6559\u80b2\u884c\u52a8\u7684\u6709\u6548\u8854\u63a5\uff0c\u5177\u6709\u63a8\u5e7f\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u4e3a\u5168\u7403\u6559\u80b2\u4f53\u7cfb\u7684\u8f8d\u5b66\u98ce\u9669\u9632\u63a7\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.05281", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05281", "abs": "https://arxiv.org/abs/2507.05281", "authors": ["Lingyue Fu", "Hao Guan", "Bolun Zhang", "Haowei Yuan", "Yaoming Zhu", "Jun Xu", "Zongyu Wang", "Lin Qiu", "Xunliang Cai", "Xuezhi Cao", "Weiwen Liu", "Weinan Zhang", "Yong Yu"], "title": "CoreCodeBench: A Configurable Multi-Scenario Repository-Level Benchmark", "comment": null, "summary": "As Large Language Models (LLMs) demonstrate increasingly sophisticated code\nprocessing capabilities, evaluating their performance on engineering-level code\nremains challenging. Existing repository-level benchmarks primarily focus on\nsingle scenarios, such as code generation or bug fixing, without adequately\ncapturing the diversity and complexity of real-world software or project\nengineering workflows. Furthermore, these benchmarks suffer from limited\ncontrollability in question positioning and reliability issues in their\ngenerated test cases. To address these limitations, we present CorePipe, a\nfully automated pipeline that converts repositories into comprehensive test\ncases, and introduce CoreCodeBench, a configurable multi-scenario\nrepository-level benchmark. To simulate real engineering scenarios, CorePipe\ngenerates three types of atomic questions (Development, BugFix, and Test-Driven\nDevelopment) specifically targeting core code segments. These atomic questions\nare further combined into three types of composite questions, with difficulty\nlevels flexibly adjusted through hyperparameter tuning. CoreCodeBench provides\na comprehensive and extensive repository-level benchmark to investigate the\napplicability of LLMs in real-world engineering projects. Experiments with 16\nLLMs across diverse scenarios reveal varying capabilities and offer\nmulti-dimensional insights into LLM performance in engineering contexts. The\ncode for CorePipe is available at\nhttps://github.com/AGI-Eval-Official/CoreCodeBench, and the data for\nCoreCodeBench can be accessed at\nhttps://huggingface.co/collections/tubehhh/corecodebench-68256d2faabf4b1610a08caa.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u81ea\u52a8\u751f\u6210\u4ed3\u5e93\u7ea7\u4ee3\u7801\u57fa\u51c6\u7684CorePipe\u65b9\u6cd5\u53ca\u7efc\u5408\u6027\u8bc4\u6d4b\u96c6CoreCodeBench\uff0c\u66f4\u597d\u5730\u8986\u76d6\u771f\u5b9e\u5de5\u7a0b\u573a\u666f\uff0c\u5bf916\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u8bc1\uff0c\u5c55\u73b0\u4e86\u5176\u5728\u590d\u6742\u591a\u6837\u5de5\u7a0b\u4efb\u52a1\u4e0b\u7684\u80fd\u529b\u4e0e\u4e0d\u8db3\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5904\u7406\u4ee3\u7801\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8d8a\u6765\u8d8a\u5f3a\u7684\u80fd\u529b\uff0c\u4f46\u73b0\u6709\u7684\u8bc4\u6d4b\u57fa\u51c6\u4e3b\u8981\u96c6\u4e2d\u5728\u5355\u4e00\u573a\u666f\uff0c\u5982\u4ee3\u7801\u751f\u6210\u6216\u4fee\u590d\uff0c\u96be\u4ee5\u8986\u76d6\u771f\u5b9e\u5de5\u7a0b\u9879\u76ee\u4e2d\u7684\u591a\u6837\u6027\u548c\u590d\u6742\u6027\u3002\u6b64\u5916\uff0c\u73b0\u6709\u57fa\u51c6\u4e5f\u5b58\u5728\u95ee\u9898\uff0c\u5982\u9898\u76ee\u5b9a\u4f4d\u4e0d\u6613\u63a7\u5236\u3001\u6d4b\u8bd5\u7528\u4f8b\u53ef\u9760\u6027\u4e0d\u8db3\u3002\u4f5c\u8005\u5e0c\u671b\u89e3\u51b3\u8fd9\u4e9b\u4e0d\u8db3\uff0c\u4ece\u800c\u66f4\u5408\u7406\u5730\u8bc4\u4f30\u548c\u4fc3\u8fdbLLMs\u5728\u771f\u5b9e\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86CorePipe\u2014\u2014\u4e00\u4e2a\u5168\u81ea\u52a8\u5316\u6d41\u7a0b\uff0c\u5c06\u5f00\u6e90\u4ee3\u7801\u5e93\u8f6c\u5316\u4e3a\u5168\u9762\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5e76\u57fa\u4e8e\u6b64\u6784\u5efa\u4e86CoreCodeBench\uff0c\u4e00\u4e2a\u53ef\u914d\u7f6e\u7684\u591a\u573a\u666f\u3001\u4ed3\u5e93\u7ea7\u522b\u7684\u8bc4\u6d4b\u57fa\u51c6\u3002CorePipe\u4f1a\u9488\u5bf9\u6838\u5fc3\u4ee3\u7801\u6bb5\u751f\u6210\u4e09\u79cd\u539f\u5b50\u95ee\u9898\uff08\u5f00\u53d1\u3001\u4fee\u590d\u3001\u6d4b\u8bd5\u9a71\u52a8\u5f00\u53d1\uff09\uff0c\u5e76\u53ef\u7ec4\u5408\u6210\u4e0d\u540c\u7c7b\u578b\u7684\u590d\u5408\u95ee\u9898\uff0c\u96be\u5ea6\u53ef\u901a\u8fc7\u8d85\u53c2\u6570\u7075\u6d3b\u8c03\u6574\u3002", "result": "\u5229\u7528CorePipe\u548cCoreCodeBench\uff0c\u4f5c\u8005\u5bf916\u79cd\u4e3b\u6d41LLM\u6a21\u578b\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u5c55\u793a\u4e86\u6a21\u578b\u80fd\u529b\u7684\u591a\u6837\u6027\uff0c\u63d0\u4f9b\u4e86\u5de5\u7a0b\u573a\u666f\u4e0b\u6a21\u578b\u8868\u73b0\u7684\u591a\u7ef4\u5ea6\u6d1e\u5bdf\u3002", "conclusion": "CorePipe\u4e0eCoreCodeBench\u663e\u8457\u63d0\u5347\u4e86\u5bf9LLM\u5728\u5de5\u7a0b\u7ea7\u4ee3\u7801\u4efb\u52a1\u8bc4\u6d4b\u7684\u5168\u9762\u6027\u4e0e\u53ef\u9760\u6027\uff0c\u53ef\u6709\u6548\u652f\u6301\u540e\u7eed\u76f8\u5173\u6a21\u578b\u7684\u5f00\u53d1\u548c\u7814\u7a76\u3002"}}
{"id": "2507.05319", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05319", "abs": "https://arxiv.org/abs/2507.05319", "authors": ["Cheng Yuan", "Xinkai Rui", "Yongqi Fan", "Yawei Fan", "Boyang Zhong", "Jiacheng Wang", "Weiyan Zhang", "Tong Ruan"], "title": "LCDS: A Logic-Controlled Discharge Summary Generation System Supporting Source Attribution and Expert Review", "comment": "ACL Demo 2025", "summary": "Despite the remarkable performance of Large Language Models (LLMs) in\nautomated discharge summary generation, they still suffer from hallucination\nissues, such as generating inaccurate content or fabricating information\nwithout valid sources. In addition, electronic medical records (EMRs) typically\nconsist of long-form data, making it challenging for LLMs to attribute the\ngenerated content to the sources. To address these challenges, we propose LCDS,\na Logic-Controlled Discharge Summary generation system. LCDS constructs a\nsource mapping table by calculating textual similarity between EMRs and\ndischarge summaries to constrain the scope of summarized content. Moreover,\nLCDS incorporates a comprehensive set of logical rules, enabling it to generate\nmore reliable silver discharge summaries tailored to different clinical fields.\nFurthermore, LCDS supports source attribution for generated content, allowing\nexperts to efficiently review, provide feedback, and rectify errors. The\nresulting golden discharge summaries are subsequently recorded for incremental\nfine-tuning of LLMs. Our project and demo video are in the GitHub repository\nhttps://github.com/ycycyc02/LCDS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684LCDS\u7cfb\u7edf\u7ed3\u5408\u6587\u672c\u76f8\u4f3c\u5ea6\u548c\u903b\u8f91\u89c4\u5219\u663e\u8457\u51cf\u5c11\u4e86LLM\u751f\u6210\u51fa\u9662\u5c0f\u7ed3\u65f6\u7684\u5e7b\u89c9\u73b0\u8c61\uff0c\u5b9e\u73b0\u4e86\u6765\u6e90\u53ef\u8ffd\u8e2a\u4e14\u4fbf\u4e8e\u4e13\u5bb6\u7ea0\u9519\u7684\u6587\u672c\u603b\u7ed3\u6d41\u7a0b\uff0c\u5e76\u53ef\u7528\u4e8e\u8fed\u4ee3\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u81ea\u52a8\u751f\u6210\u51fa\u9662\u5c0f\u7ed3\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5b83\u4eec\u4ecd\u53d7\u5e7b\u89c9\u95ee\u9898\u56f0\u6270\uff0c\u4f8b\u5982\u751f\u6210\u4e0d\u51c6\u786e\u6216\u51ed\u7a7a\u634f\u9020\u7684\u4fe1\u606f\u3002\u6b64\u5916\uff0c\u7535\u5b50\u75c5\u5386\uff08EMR\uff09\u901a\u5e38\u4e3a\u957f\u6587\u672c\u6570\u636e\uff0c\u4f7f\u5f97\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u8ffd\u6eaf\u548c\u5f52\u56e0\u751f\u6210\u5185\u5bb9\u6765\u6e90\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aLCDS\u7684\u201c\u903b\u8f91\u63a7\u5236\u51fa\u9662\u5c0f\u7ed3\u751f\u6210\u7cfb\u7edf\u201d\u3002\u8be5\u7cfb\u7edf\u901a\u8fc7\u8ba1\u7b97EMR\u4e0e\u51fa\u9662\u5c0f\u7ed3\u4e4b\u95f4\u7684\u6587\u672c\u76f8\u4f3c\u5ea6\u6784\u5efa\u6765\u6e90\u6620\u5c04\u8868\uff0c\u4ece\u800c\u7ea6\u675f\u603b\u7ed3\u5185\u5bb9\u7684\u8303\u56f4\u3002\u53e6\u5916\uff0c\u7cfb\u7edf\u6574\u5408\u4e86\u5b8c\u5584\u7684\u903b\u8f91\u89c4\u5219\uff0c\u63d0\u9ad8\u4e86\u751f\u6210\u7684\u51fa\u9662\u5c0f\u7ed3\u5728\u4e0d\u540c\u4e34\u5e8a\u9886\u57df\u7684\u53ef\u9760\u6027\u3002LCDS\u8fd8\u80fd\u5b9e\u73b0\u5185\u5bb9\u751f\u6210\u7684\u6765\u6e90\u5f52\u56e0\uff0c\u4fbf\u4e8e\u4e13\u5bb6\u5ba1\u6838\u4e0e\u7ea0\u9519\u3002\u6700\u7ec8\u751f\u6210\u7684\u9ad8\u8d28\u91cf\u5c0f\u7ed3\u88ab\u7528\u4e8e\u589e\u91cf\u5fae\u8c03LLM\u6a21\u578b\u3002", "result": "LCDS\u5b9e\u73b0\u4e86\u66f4\u53ef\u9760\u3001\u53ef\u8ffd\u6eaf\u548c\u6613\u4e8e\u5ba1\u6838\u7684\u81ea\u52a8\u51fa\u9662\u5c0f\u7ed3\u751f\u6210\uff0c\u53ef\u4ee5\u51cf\u5c11\u5e7b\u89c9\u73b0\u8c61\uff0c\u5e76\u53ef\u6301\u7eed\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "\u903b\u8f91\u63a7\u5236\u7ed3\u5408\u6765\u6e90\u5f52\u56e0\u673a\u5236\uff0c\u53ef\u6709\u6548\u63d0\u5347\u81ea\u52a8\u51fa\u9662\u5c0f\u7ed3\u751f\u6210\u8d28\u91cf\uff0c\u540c\u65f6\u4f18\u5316LLM\u7684\u5fae\u8c03\u6d41\u7a0b\u3002"}}
{"id": "2507.05289", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.05289", "abs": "https://arxiv.org/abs/2507.05289", "authors": ["Igor Regis da Silva Simoes", "Elaine Venson"], "title": "Measuring how changes in code readability attributes affect code quality evaluation by Large Language Models", "comment": null, "summary": "Code readability is one of the main aspects of code quality, influenced by\nvarious properties like identifier names, comments, code structure, and\nadherence to standards. However, measuring this attribute poses challenges in\nboth industry and academia. While static analysis tools assess attributes such\nas code smells and comment percentage, code reviews introduce an element of\nsubjectivity. This paper explores using Large Language Models (LLMs) to\nevaluate code quality attributes related to its readability in a standardized,\nreproducible, and consistent manner. We conducted a quasi-experiment study to\nmeasure the effects of code changes on Large Language Model (LLM)s\ninterpretation regarding its readability quality attribute. Nine LLMs were\ntested, undergoing three interventions: removing comments, replacing identifier\nnames with obscure names, and refactoring to remove code smells. Each\nintervention involved 10 batch analyses per LLM, collecting data on response\nvariability. We compared the results with a known reference model and tool. The\nresults showed that all LLMs were sensitive to the interventions, with\nagreement with the reference classifier being high for the original and\nrefactored code scenarios. The LLMs demonstrated a strong semantic sensitivity\nthat the reference model did not fully capture. A thematic analysis of the LLMs\nreasoning confirmed their evaluations directly reflected the nature of each\nintervention. The models also exhibited response variability, with 9.37% to\n14.58% of executions showing a standard deviation greater than zero, indicating\nresponse oscillation, though this did not always compromise the statistical\nsignificance of the results. LLMs demonstrated potential for evaluating\nsemantic quality aspects, such as coherence between identifier names, comments,\nand documentation with code purpose.", "AI": {"tldr": "\u672c\u6587\u5c55\u793aLLM\u53ef\u6709\u6548\u3001\u5ba2\u89c2\u5730\u8bc4\u4f30\u4ee3\u7801\u53ef\u8bfb\u6027\uff0c\u5bf9\u4e0d\u540c\u7c7b\u578b\u4ee3\u7801\u6539\u52a8\u6709\u654f\u611f\u53cd\u5e94\uff0c\u8fdb\u4e00\u6b65\u4e30\u5bcc\u4e86\u4ee3\u7801\u8d28\u91cf\u667a\u80fd\u5316\u5206\u6790\u624b\u6bb5\u3002", "motivation": "\u4ee3\u7801\u53ef\u8bfb\u6027\u662f\u4ee3\u7801\u8d28\u91cf\u7684\u91cd\u8981\u65b9\u9762\uff0c\u4f46\u5728\u5de5\u4e1a\u754c\u548c\u5b66\u672f\u754c\u5f88\u96be\u8fdb\u884c\u6807\u51c6\u5316\u3001\u5ba2\u89c2\u7684\u8861\u91cf\u3002\u76ee\u524d\u5e38\u7528\u7684\u9759\u6001\u5206\u6790\u548c\u4eba\u5de5\u4ee3\u7801\u8bc4\u5ba1\u65b9\u6cd5\u5404\u6709\u5c40\u9650\uff0c\u7f3a\u4e4f\u7edf\u4e00\u4e14\u6613\u590d\u73b0\u7684\u624b\u6bb5\u3002\u8fd9\u6fc0\u53d1\u4e86\u4f5c\u8005\u63a2\u7d22\u91c7\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f5c\u4e3a\u8bc4\u4f30\u5de5\u5177\u7684\u52a8\u673a\u3002", "method": "\u4f5c\u8005\u57fa\u4e8e\u51c6\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u5229\u7528\u4e5d\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e09\u79cd\u4ee3\u7801\u53d8\u66f4\u5bf9\u53ef\u8bfb\u6027\u7684\u5f71\u54cd\uff1a1\uff09\u79fb\u9664\u6ce8\u91ca\uff0c2\uff09\u7528\u6666\u6da9\u7684\u540d\u5b57\u66ff\u6362\u6807\u8bc6\u7b26\uff0c3\uff09\u91cd\u6784\u4ee3\u7801\u4ee5\u6d88\u9664\u574f\u5473\u9053\u3002\u6bcf\u4e2a\u6a21\u578b\u5bf9\u6bcf\u7c7b\u5e72\u9884\u5206\u522b\u8fdb\u884c10\u7ec4\u6279\u91cf\u5206\u6790\uff0c\u540c\u65f6\u4e0e\u4e00\u4e2a\u5df2\u77e5\u53c2\u8003\u6a21\u578b\u548c\u5de5\u5177\u5bf9\u6bd4\uff0c\u6536\u96c6\u54cd\u5e94\u5dee\u5f02\u6027\u7b49\u76f8\u5173\u6570\u636e\uff0c\u5e76\u5bf9LLM\u56de\u5e94\u7684\u63a8\u7406\u8fc7\u7a0b\u505a\u4e3b\u9898\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u6240\u6709LLM\u5bf9\u4ee3\u7801\u53d8\u66f4\u90fd\u8f83\u4e3a\u654f\u611f\uff0c\u5e76\u4e14\u5728\u539f\u59cb\u4e0e\u91cd\u6784\u4ee3\u7801\u60c5\u666f\u4e0b\u8f83\u597d\u5730\u4e0e\u53c2\u8003\u5206\u7c7b\u5668\u8fbe\u6210\u4e00\u81f4\u3002LLM\u5c55\u73b0\u51fa\u8f83\u5f3a\u7684\u8bed\u4e49\u654f\u611f\u6027\uff08\u5982\u8bc6\u522b\u6807\u8bc6\u7b26\u3001\u6ce8\u91ca\u4e0e\u4ee3\u7801\u76ee\u7684\u95f4\u4e00\u81f4\u6027\uff09\uff0c\u800c\u53c2\u8003\u6a21\u578b\u5bf9\u6b64\u628a\u63a7\u6709\u9650\u3002\u5c3d\u7ba19.37%-14.58%\u7684\u6267\u884c\u7ed3\u679c\u6709\u4e00\u5b9a\u6ce2\u52a8\uff0c\u4f46\u7edf\u8ba1\u610f\u4e49\u901a\u5e38\u672a\u53d7\u5f71\u54cd\u3002", "conclusion": "LLM\u5728\u8bc4\u4f30\u4ee3\u7801\u53ef\u8bfb\u6027\u7b49\u8bed\u4e49\u8d28\u91cf\u5c5e\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8f83\u9ad8\u6f5c\u529b\uff0c\u53ef\u5b9e\u73b0\u6807\u51c6\u5316\u3001\u53ef\u590d\u73b0\u3001\u7ed3\u679c\u4e00\u81f4\u7684\u5206\u6790\uff0c\u662f\u9759\u6001\u5206\u6790\u4e0e\u4eba\u5de5\u8bc4\u5ba1\u7684\u6709\u76ca\u8865\u5145\u3002"}}
{"id": "2507.05330", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05330", "abs": "https://arxiv.org/abs/2507.05330", "authors": ["Ming Gong", "Xucheng Huang", "Chenghan Yang", "Xianhan Peng", "Haoxin Wang", "Yang Liu", "Ling Jiang"], "title": "MindFlow: Revolutionizing E-commerce Customer Support with Multimodal LLM Agents", "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled new applications\nin e-commerce customer service. However, their capabilities remain constrained\nin complex, multimodal scenarios. We present MindFlow, the first open-source\nmultimodal LLM agent tailored for e-commerce. Built on the CoALA framework, it\nintegrates memory, decision-making, and action modules, and adopts a modular\n\"MLLM-as-Tool\" strategy for effect visual-textual reasoning. Evaluated via\nonline A/B testing and simulation-based ablation, MindFlow demonstrates\nsubstantial gains in handling complex queries, improving user satisfaction, and\nreducing operational costs, with a 93.53% relative improvement observed in\nreal-world deployments.", "AI": {"tldr": "MindFlow\u662f\u9996\u4e2a\u5f00\u6e90\u7535\u5546\u4e13\u7528\u591a\u6a21\u6001LLM\u667a\u80fd\u4f53\uff0c\u7ed3\u5408\u591a\u6a21\u5757\u5e76\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u590d\u6742\u5ba2\u6237\u670d\u52a1\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u591a\u6a21\u6001\u7535\u5546\u5ba2\u670d\u573a\u666f\u4e0b\u80fd\u529b\u6709\u9650\uff0c\u7f3a\u4e4f\u9762\u5411\u5b9e\u9645\u590d\u6742\u4efb\u52a1\u7684\u591a\u6a21\u6001\u667a\u80fd\u4f53\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u57fa\u4e8eCoALA\u6846\u67b6\uff0c\u8bbe\u8ba1\u4e86\u96c6\u6210\u8bb0\u5fc6\u3001\u51b3\u7b56\u548c\u884c\u52a8\u6a21\u5757\u7684\u591a\u6a21\u6001LLM agent\uff0c\u91c7\u7528\"MLLM-as-Tool\"\u6a21\u5757\u5316\u7b56\u7565\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u89c6\u89c9-\u6587\u672c\u63a8\u7406\u3002\u901a\u8fc7\u7ebf\u4e0aA/B\u6d4b\u8bd5\u548c\u4eff\u771f\u6d88\u878d\u5b9e\u9a8c\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "MindFlow\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u5b9e\u73b0\u4e8693.53%\u7684\u76f8\u5bf9\u6539\u8fdb\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u67e5\u8be2\u5904\u7406\u80fd\u529b\u3001\u7528\u6237\u6ee1\u610f\u5ea6\uff0c\u5e76\u964d\u4f4e\u4e86\u8fd0\u8425\u6210\u672c\u3002", "conclusion": "MindFlow\u663e\u8457\u63d0\u5347\u4e86\u7535\u5546\u590d\u6742\u5ba2\u6237\u670d\u52a1\u573a\u666f\u4e0b\u591a\u6a21\u6001\u667a\u80fd\u4f53\u7684\u8868\u73b0\uff0c\u6709\u6548\u63d0\u5347\u4e86\u7528\u6237\u6ee1\u610f\u5ea6\u548c\u964d\u4f4e\u4e86\u8fd0\u8425\u6210\u672c\u3002"}}
{"id": "2507.05294", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.05294", "abs": "https://arxiv.org/abs/2507.05294", "authors": ["William Law"], "title": "zkSDK: Streamlining zero-knowledge proof development through automated trace-driven ZK-backend selection", "comment": "undergrad thesis", "summary": "The rapid advancement of creating Zero-Knowledge (ZK) programs has led to the\ndevelopment of numerous tools designed to support developers. Popular options\ninclude being able to write in general-purpose programming languages like Rust\nfrom Risc Zero. Other languages exist like Circom, Lib-snark, and Cairo.\nHowever, developers entering the ZK space are faced with many different ZK\nbackends to choose from, leading to a steep learning curve and a fragmented\ndeveloper experience across different platforms. As a result, many developers\ntend to select a single ZK backend and remain tied to it. This thesis\nintroduces zkSDK, a modular framework that streamlines ZK application\ndevelopment by abstracting the backend complexities. At the core of zkSDK is\nPresto, a custom Python-like programming language that enables the profiling\nand analysis of a program to assess its computational workload intensity.\nCombined with user-defined criteria, zkSDK employs a dynamic selection\nalgorithm to automatically choose the optimal ZK-proving backend. Through an\nin-depth analysis and evaluation of real-world workloads, we demonstrate that\nzkSDK effectively selects the best-suited backend from a set of supported ZK\nbackends, delivering a seamless and user-friendly development experience.", "AI": {"tldr": "\u73b0\u6709ZK\u5f00\u53d1\u5de5\u5177\u4f17\u591a\uff0c\u9009\u62e9\u56f0\u96be\u3002zkSDK\u901a\u8fc7\u62bd\u8c61\u548c\u81ea\u52a8\u9009\u62e9\u6700\u4f18\u540e\u7aef\uff0c\u6781\u5927\u7b80\u5316\u4e86\u5f00\u53d1\u6d41\u7a0b\uff0c\u63d0\u9ad8\u5f00\u53d1\u8005\u4f53\u9a8c\u3002", "motivation": "\u968f\u7740\u96f6\u77e5\u8bc6\uff08ZK\uff09\u7a0b\u5e8f\u5f00\u53d1\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5e02\u9762\u4e0a\u6d8c\u73b0\u4e86\u591a\u79cd\u652f\u6301\u5f00\u53d1\u8005\u7684ZK\u5de5\u5177\u548c\u540e\u7aef\u3002\u7531\u4e8e\u9009\u62e9\u4f17\u591a\uff0c\u5f00\u53d1\u8005\u9762\u4e34\u8f83\u9ad8\u7684\u5b66\u4e60\u95e8\u69db\u4e0e\u5206\u88c2\u7684\u5f00\u53d1\u4f53\u9a8c\uff0c\u5f80\u5f80\u88ab\u8feb\u7ed1\u5b9a\u5728\u5355\u4e00\u540e\u7aef\uff0c\u5f71\u54cd\u5f00\u53d1\u6548\u7387\u4e0e\u7075\u6d3b\u6027\u3002", "method": "\u672c\u8bba\u6587\u63d0\u51fazkSDK\uff0c\u4e00\u4e2a\u6a21\u5757\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u62bd\u8c61ZK\u540e\u7aef\u7684\u590d\u6742\u6027\u6765\u7b80\u5316ZK\u5e94\u7528\u5f00\u53d1\u3002zkSDK\u6838\u5fc3\u4e3a\u81ea\u5b9a\u4e49Python\u98ce\u683c\u8bed\u8a00Presto\uff0c\u53ef\u5206\u6790\u7a0b\u5e8f\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5e76\u7ed3\u5408\u7528\u6237\u6807\u51c6\uff0c\u52a8\u6001\u81ea\u52a8\u9009\u62e9\u6700\u4f18ZK\u8bc1\u660e\u540e\u7aef\u3002", "result": "\u901a\u8fc7\u5bf9\u771f\u5b9e\u4e16\u754c\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5206\u6790\u4e0e\u8bc4\u6d4b\uff0czkSDK\u80fd\u591f\u4ece\u591a\u4e2a\u652f\u6301\u7684ZK\u540e\u7aef\u4e2d\u81ea\u52a8\u9009\u62e9\u6700\u9002\u5408\u7684\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f00\u53d1\u4f53\u9a8c\u7684\u4e00\u81f4\u6027\u4e0e\u4fbf\u6377\u6027\u3002", "conclusion": "zkSDK\u6846\u67b6\u6709\u6548\u7b80\u5316\u4e86ZK\u5e94\u7528\u5f00\u53d1\u6d41\u7a0b\uff0c\u6d88\u9664\u4e86\u540e\u7aef\u788e\u7247\u5316\u5e26\u6765\u7684\u95e8\u69db\uff0c\u8ba9\u5f00\u53d1\u8005\u65e0\u9700\u88ab\u8feb\u7ed1\u5b9a\u5355\u4e00\u540e\u7aef\uff0c\u589e\u5f3a\u5f00\u53d1\u81ea\u7531\u548c\u6548\u7387\u3002"}}
{"id": "2507.05346", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.05346", "abs": "https://arxiv.org/abs/2507.05346", "authors": ["William Fleshman", "Benjamin Van Durme"], "title": "LoRA-Augmented Generation (LAG) for Knowledge-Intensive Language Tasks", "comment": null, "summary": "The proliferation of fine-tuned language model experts for specific tasks and\ndomains signals the need for efficient selection and combination methods. We\npropose LoRA-Augmented Generation (LAG) for leveraging large libraries of\nknowledge and task-specific LoRA adapters. LAG requires no additional training\nor access to data, and efficiently filters, retrieves, and applies experts on a\nper-token and layer basis. We evaluate LAG on various knowledge-intensive\ntasks, achieving superior performance over existing data-free methods. We\nexplore scenarios where additional data is available, demonstrating LAG's\ncompatibility with alternative solutions such as retrieval-augmented generation\n(RAG).", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLAG\u65b9\u6cd5\uff0c\u9ad8\u6548\u6574\u5408\u591a\u4e2aLoRA\u4e13\u5bb6\uff0c\u65e0\u9700\u6570\u636e\u548c\u518d\u8bad\u7ec3\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5728\u77e5\u8bc6\u5bc6\u96c6\u4efb\u52a1\u4e0a\u6548\u679c\u9886\u5148\uff0c\u5e76\u80fd\u4e0e\u5176\u4ed6\u589e\u5f3a\u65b9\u6848\u7ed3\u5408\u3002", "motivation": "\u5f53\u524d\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u548c\u9886\u57df\u7684\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u4e13\u5bb6\u8d8a\u6765\u8d8a\u591a\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u8fdb\u884c\u9009\u62e9\u548c\u7ec4\u5408\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cdLoRA-Augmented Generation\uff08LAG\uff09\u65b9\u6cd5\uff0c\u80fd\u591f\u5229\u7528\u5927\u578b\u77e5\u8bc6\u5e93\u548c\u7279\u5b9a\u4efb\u52a1\u7684LoRA\u9002\u914d\u5668\u3002LAG\u4e0d\u9700\u8981\u989d\u5916\u8bad\u7ec3\u6216\u8bbf\u95ee\u6570\u636e\uff0c\u80fd\u591f\u5728\u6bcf\u4e2atoken\u548c\u5c42\u7ea7\u57fa\u7840\u4e0a\u9ad8\u6548\u7b5b\u9009\u3001\u68c0\u7d22\u3001\u5e94\u7528\u4e13\u5bb6\u6a21\u578b\u3002", "result": "\u5728\u591a\u79cd\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\uff0cLAG\u4f18\u4e8e\u73b0\u6709\u7684\u6570\u636e\u65e0\u5173\u65b9\u6cd5\uff1b\u6b64\u5916\u5728\u6709\u989d\u5916\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0cLAG\u8fd8\u80fd\u517c\u5bb9\u5982\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7b49\u5176\u4ed6\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "LAG\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u65b0\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u65e0\u9700\u6570\u636e\u548c\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u5229\u7528\u591a\u4e13\u5bb6\u6a21\u578b\uff0c\u6027\u80fd\u9886\u5148\uff0c\u5e76\u53ef\u7ed3\u5408\u5176\u4ed6\u65b9\u6cd5\u4f7f\u7528\u3002"}}
{"id": "2507.05307", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05307", "abs": "https://arxiv.org/abs/2507.05307", "authors": ["Xuanqi Gao", "Juan Zhai", "Shiqing Ma", "Siyi Xie", "Chao Shen"], "title": "ASSURE: Metamorphic Testing for AI-powered Browser Extensions", "comment": null, "summary": "The integration of Large Language Models (LLMs) into browser extensions has\nrevolutionized web browsing, enabling sophisticated functionalities like\ncontent summarization, intelligent translation, and context-aware writing\nassistance. However, these AI-powered extensions introduce unprecedented\nchallenges in testing and reliability assurance. Traditional browser extension\ntesting approaches fail to address the non-deterministic behavior,\ncontext-sensitivity, and complex web environment integration inherent to\nLLM-powered extensions. Similarly, existing LLM testing methodologies operate\nin isolation from browser-specific contexts, creating a critical gap in\neffective evaluation frameworks. To bridge this gap, we present ASSURE, a\nmodular automated testing framework specifically designed for AI-powered\nbrowser extensions. ASSURE comprises three principal components: (1) a modular\ntest case generation engine that supports plugin-based extension of testing\nscenarios, (2) an automated execution framework that orchestrates the complex\ninteractions between web content, extension processing, and AI model behavior,\nand (3) a configurable validation pipeline that systematically evaluates\nbehavioral consistency and security invariants rather than relying on exact\noutput matching. Our evaluation across six widely-used AI browser extensions\ndemonstrates ASSURE's effectiveness, identifying 531 distinct issues spanning\nsecurity vulnerabilities, metamorphic relation violations, and content\nalignment problems. ASSURE achieves 6.4x improved testing throughput compared\nto manual approaches, detecting critical security vulnerabilities within 12.4\nminutes on average. This efficiency makes ASSURE practical for integration into\ndevelopment pipelines, offering a comprehensive solution to the unique\nchallenges of testing AI-powered browser extensions.", "AI": {"tldr": "ASSURE\u662f\u4e3aAI\u9a71\u52a8\u6d4f\u89c8\u5668\u6269\u5c55\u4e13\u95e8\u8bbe\u8ba1\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u6846\u67b6\uff0c\u517c\u5177\u6a21\u5757\u5316\u751f\u6210\u3001\u81ea\u52a8\u5316\u6267\u884c\u548c\u7075\u6d3b\u9a8c\u8bc1\u529f\u80fd\u3002\u5b9e\u9a8c\u663e\u793a\uff0c\u5176\u5728\u53d1\u73b0\u95ee\u9898\u6570\u91cf\u548c\u6548\u7387\u4e0a\u8fdc\u8d85\u4eba\u5de5\u6d4b\u8bd5\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u6d4f\u89c8\u5668AI\u6269\u5c55\u7684\u590d\u6742\u6d4b\u8bd5\u9700\u6c42\u3002", "motivation": "\u5f53\u524dLLM\u9a71\u52a8\u7684\u6d4f\u89c8\u5668\u6269\u5c55\u4e3a\u7f51\u9875\u6d4f\u89c8\u5e26\u6765\u4e86\u521b\u65b0\u529f\u80fd\uff0c\u5982\u5185\u5bb9\u6458\u8981\u3001\u667a\u80fd\u7ffb\u8bd1\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u5199\u4f5c\u8f85\u52a9\uff0c\u4f46\u4e5f\u5f15\u5165\u4e86\u6d4b\u8bd5\u548c\u53ef\u9760\u6027\u4fdd\u8bc1\u65b9\u9762\u7684\u5168\u65b0\u6311\u6218\u3002\u4f20\u7edf\u7684\u6d4f\u89c8\u5668\u6269\u5c55\u6d4b\u8bd5\u65b9\u6cd5\u4e0d\u9002\u5e94LLM\u6269\u5c55\u7684\u975e\u786e\u5b9a\u6027\u884c\u4e3a\u548c\u590d\u6742\u96c6\u6210\uff0c\u73b0\u6709LLM\u6d4b\u8bd5\u65b9\u6cd5\u53c8\u8131\u79bb\u6d4f\u89c8\u5668\u4e0a\u4e0b\u6587\uff0c\u5bfc\u81f4\u8bc4\u4f30\u6846\u67b6\u5b58\u5728\u5173\u952e\u7f3a\u53e3\u3002", "method": "\u63d0\u51fa\u4e86ASSURE\uff1a\u4e00\u4e2a\u4e13\u4e3aAI\u9a71\u52a8\u6d4f\u89c8\u5668\u6269\u5c55\u8bbe\u8ba1\u7684\u6a21\u5757\u5316\u81ea\u52a8\u5316\u6d4b\u8bd5\u6846\u67b6\u3002ASSURE\u5305\u62ec\u4e09\u4e2a\u4e3b\u8981\u7ec4\u6210\u90e8\u5206\uff1a\uff081\uff09\u652f\u6301\u63d2\u4ef6\u6269\u5c55\u6d4b\u8bd5\u573a\u666f\u7684\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u5f15\u64ce\uff1b\uff082\uff09\u81ea\u52a8\u6267\u884c\u6846\u67b6\uff0c\u534f\u8c03\u7f51\u9875\u5185\u5bb9\u3001\u6269\u5c55\u6d41\u7a0b\u4e0eAI\u6a21\u578b\u884c\u4e3a\u7684\u590d\u6742\u4ea4\u4e92\uff1b\uff083\uff09\u53ef\u914d\u7f6e\u7684\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u7528\u4e8e\u7cfb\u7edf\u6027\u8bc4\u4f30\u884c\u4e3a\u4e00\u81f4\u6027\u548c\u5b89\u5168\u6027\uff0c\u800c\u975e\u4ec5\u9760\u8f93\u51fa\u7ed3\u679c\u7cbe\u786e\u5339\u914d\u3002", "result": "\u5728\u516d\u6b3e\u4e3b\u6d41AI\u6d4f\u89c8\u5668\u6269\u5c55\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cASSURE\u53d1\u73b0\u4e86531\u4e2a\u4e0d\u540c\u95ee\u9898\uff0c\u5305\u62ec\u5b89\u5168\u6f0f\u6d1e\u3001\u53d8\u5f62\u5173\u7cfb\u8fdd\u53cd\u548c\u5185\u5bb9\u5bf9\u9f50\u95ee\u9898\u3002\u4e0e\u4eba\u5de5\u6d4b\u8bd5\u76f8\u6bd4\uff0cASSURE\u6d4b\u8bd5\u541e\u5410\u91cf\u63d0\u9ad8\u4e866.4\u500d\uff0c\u5e73\u574712.4\u5206\u949f\u5185\u5373\u53ef\u53d1\u73b0\u5173\u952e\u5b89\u5168\u6f0f\u6d1e\u3002", "conclusion": "ASSURE\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3AI\u9a71\u52a8\u6d4f\u89c8\u5668\u6269\u5c55\u6d4b\u8bd5\u4e2d\u7684\u72ec\u7279\u6311\u6218\uff0c\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u4eba\u5de5\u65b9\u6cd5\uff0c\u9002\u5408\u96c6\u6210\u8fdb\u5b9e\u9645\u5f00\u53d1\u6d41\u7a0b\uff0c\u63d0\u5347\u6d4b\u8bd5\u7684\u5168\u9762\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2507.05362", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.05362", "abs": "https://arxiv.org/abs/2507.05362", "authors": ["Riccardo Alberghi", "Elizaveta Demyanenko", "Luca Biggio", "Luca Saglietti"], "title": "On the Bias of Next-Token Predictors Toward Systematically Inefficient Reasoning: A Shortest-Path Case Study", "comment": null, "summary": "Recent advances in natural language processing highlight two key factors for\nimproving reasoning in large language models (LLMs): (i) allocating more\ntest-time compute tends to help on harder problems but often introduces\nredundancy in the reasoning trace, and (ii) compute is most effective when\nreasoning is systematic and incremental, forming structured chains of thought\n(CoTs) akin to human problem-solving. To study these factors in isolation, we\nintroduce a controlled setting based on shortest-path tasks in layered graphs.\nWe train decoder-only transformers on question-trace-answer triples using a\ncustom tokenizer, comparing models trained on optimal bottom-up dynamic\nprogramming traces with those trained on longer, valid traces involving\nbacktracking. Surprisingly, with the same training-token budget, models trained\non inefficient traces generalize better to unseen graphs. This benefit is not\ndue to length alone-injecting arbitrary redundancy into reasoning traces fails\nto help and can even hurt performance. Instead, we find that generalization\ncorrelates with the model's confidence in next-token prediction, suggesting\nthat long, coherent, and locally incremental traces make the training signal\neasier to optimize.", "AI": {"tldr": "\u5bf9\u6bd4\u6700\u4f18\u548c\u5197\u957f\u9012\u8fdb\u63a8\u7406\u8f68\u8ff9\u8bad\u7ec3Transformer\uff0c\u53d1\u73b0\u8fde\u8d2f\u4e14\u9012\u8fdb\u7684\u957ftrace\u80fd\u63d0\u5347\u6a21\u578b\u6cdb\u5316\uff0c\u957f\u5ea6\u672c\u8eab\u6216\u968f\u673a\u5197\u4f59\u65e0\u6548\uff0c\u5173\u952e\u5728\u4e8e\u63a8\u7406\u4fe1\u53f7\u7684\u7ed3\u6784\u6027\u3002", "motivation": "\u5f53\u524dLLM\u63a8\u7406\u80fd\u529b\u63d0\u5347\u6d89\u53ca\u4e24\u4e2a\u5173\u952e\uff1a\u6d4b\u8bd5\u65f6\u589e\u52a0\u7b97\u529b\u5f80\u5f80\u5bfc\u81f4\u63a8\u7406\u8f68\u8ff9\u5197\u4f59\uff0c\u800c\u7cfb\u7edf\u6027\u3001\u9012\u8fdb\u5f0f\u7684\u63a8\u7406\uff08\u5982\u6709\u7ed3\u6784\u7684Chain-of-Thought\uff09\u53c8\u4e0e\u4eba\u7c7b\u63a8\u7406\u7c7b\u4f3c\uff0c\u80fd\u591f\u63d0\u5347\u63a8\u7406\u8d28\u91cf\uff0c\u8bba\u6587\u65e8\u5728\u5256\u6790\u8fd9\u4e24\u56e0\u7d20\u5728\u6a21\u578b\u6cdb\u5316\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u5728\u591a\u5c42\u56fe\u7684\u6700\u77ed\u8def\u5f84\u4efb\u52a1\u4e0a\uff0c\u8bbe\u8ba1\u4e86\u53d7\u63a7\u7684\u5b9e\u9a8c\u73af\u5883\uff0c\u91c7\u7528\u5b9a\u5236tokenizer\u548cdecoder-only transformer\uff0c\u8bad\u7ec3\u4e8e\u95ee\u9898-\u63a8\u7406\u8f68\u8ff9-\u7b54\u6848\u4e09\u5143\u7ec4\u3002\u5bf9\u6bd4\u4e86\u7528\u6700\u4f18\u52a8\u6001\u89c4\u5212trace\u548c\u5305\u542b\u56de\u6eaf\u7684\u5197\u957f\u4f46\u6709\u6548trace\u8fdb\u884c\u8bad\u7ec3\u7684\u8868\u73b0\uff0c\u5e76\u63a2\u8ba8\u4e86\u5f15\u5165\u968f\u673a\u5197\u4f59\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u7528\u5197\u957f\u4f46\u9012\u8fdb\u7684\u63a8\u7406\u8f68\u8ff9\u8fdb\u884c\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u6bd4\u7528\u6700\u4f18trace\u8bad\u7ec3\u7684\u6a21\u578b\u5bf9\u65b0\u56fe\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002\u8be5\u63d0\u5347\u5e76\u975etrace\u957f\u5ea6\u5bfc\u81f4\uff0c\u968f\u673a\u5197\u4f59\u53cd\u800c\u6709\u5bb3\uff0c\u5173\u952e\u5728\u4e8e\u63a8\u7406\u8fc7\u7a0b\u7684\u8fde\u8d2f\u6027\u4e0e\u5c40\u90e8\u589e\u91cf\u6027\u3002\u6cdb\u5316\u6548\u679c\u4e0e\u6a21\u578b\u5728\u9884\u6d4b\u4e0b\u4e00\u4e2atoken\u65f6\u7684\u7f6e\u4fe1\u5ea6\u6b63\u76f8\u5173\u3002", "conclusion": "\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u5982\u679c\u91c7\u7528\u5197\u957f\u4f46\u903b\u8f91\u8fde\u8d2f\u3001\u5c40\u90e8\u9012\u8fdb\u5f0f\u7684\u63a8\u7406\u8f68\u8ff9\uff08\u800c\u4e0d\u662f\u6700\u4f18\u6216\u968f\u673a\u5197\u4f59\u8f68\u8ff9\uff09\uff0c\u5176\u6cdb\u5316\u80fd\u529b\u4f1a\u66f4\u597d\u3002\u6cdb\u5316\u63d0\u5347\u4e0etrace\u957f\u5ea6\u672c\u8eab\u65e0\u5173\uff0c\u800c\u5728\u4e8e\u63a8\u7406\u8fc7\u7a0b\u7684\u8fde\u8d2f\u6027\u548c\u589e\u91cf\u6027\uff0c\u8fd9\u6837\u7684\u8bad\u7ec3\u4fe1\u53f7\u66f4\u6613\u4e8e\u6a21\u578b\u4f18\u5316\u3002"}}
{"id": "2507.05316", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05316", "abs": "https://arxiv.org/abs/2507.05316", "authors": ["Koren Lazar", "Matan Vetzler", "Kiran Kate", "Jason Tsay", "David Boaz Himanshu Gupta", "Avraham Shinnar", "Rohith D Vallam", "David Amid Esther Goldbraich", "Guy Uziel", "Jim Laredo", "Ateret Anaby Tavor"], "title": "OASBuilder: Generating OpenAPI Specifications from Online API Documentation with Large Language Models", "comment": null, "summary": "AI agents and business automation tools interacting with external web\nservices require standardized, machine-readable information about their APIs in\nthe form of API specifications. However, the information about APIs available\nonline is often presented as unstructured, free-form HTML documentation,\nrequiring external users to spend significant time manually converting it into\na structured format. To address this, we introduce OASBuilder, a novel\nframework that transforms long and diverse API documentation pages into\nconsistent, machine-readable API specifications. This is achieved through a\ncarefully crafted pipeline that integrates large language models and rule-based\nalgorithms which are guided by domain knowledge of the structure of\ndocumentation webpages. Our experiments demonstrate that OASBuilder generalizes\nwell across hundreds of APIs, and produces valid OpenAPI specifications that\nencapsulate most of the information from the original documentation. OASBuilder\nhas been successfully implemented in an enterprise environment, saving\nthousands of hours of manual effort and making hundreds of complex enterprise\nAPIs accessible as tools for LLMs.", "AI": {"tldr": "OASBuilder\u81ea\u52a8\u5c06\u590d\u6742API\u6587\u6863\u8f6c\u5316\u4e3a\u6807\u51c6\u5316\u673a\u5668\u53ef\u8bfb\u7684OpenAPI\u89c4\u683c\uff0c\u52a9\u529b\u4f01\u4e1a\u5927\u5e45\u8282\u7701\u4eba\u5de5\u3001\u63d0\u5347API\u53ef\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u7684API\u6587\u6863\u591a\u4ee5\u975e\u7ed3\u6784\u5316HTML\u7f51\u9875\u5f62\u5f0f\u5b58\u5728\uff0c\u4eba\u5de5\u8f6c\u6362\u4e3a\u6807\u51c6\u673a\u5668\u53ef\u8bfb\u7684API\u89c4\u683c\u8017\u65f6\u8d39\u529b\uff0c\u5f71\u54cdAI\u4ee3\u7406\u548c\u81ea\u52a8\u5316\u5de5\u5177\u7684\u63a5\u5165\u6548\u7387\u3002", "method": "\u63d0\u51faOASBuilder\u6846\u67b6\uff0c\u5c06\u5927\u91cf\u4e0d\u540c\u98ce\u683c\u7684API\u6587\u6863\u7f51\u9875\u81ea\u52a8\u8f6c\u5316\u4e3a\u6807\u51c6\u5316\u3001\u673a\u5668\u53ef\u8bfb\u7684API\u89c4\u683c(OpenAPI)\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u57fa\u4e8e\u89c4\u5219\u7684\u7b97\u6cd5\uff0c\u5e76\u878d\u5408\u4e86\u6587\u6863\u7f51\u9875\u7ed3\u6784\u7684\u9886\u57df\u77e5\u8bc6\u3002", "result": "OASBuilder\u5728\u6570\u767e\u4e2aAPI\u4e0a\u6cdb\u5316\u6027\u826f\u597d\uff0c\u80fd\u591f\u751f\u6210\u6709\u6548\u3001\u8986\u76d6\u539f\u59cb\u6587\u6863\u5173\u952e\u4fe1\u606f\u7684OpenAPI\u89c4\u683c\u3002\u5df2\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u6210\u529f\u5e94\u7528\uff0c\u663e\u8457\u8282\u7701\u4e86\u4eba\u5de5\u5de5\u65f6\u5e76\u63d0\u5347\u4e86API\u53ef\u7528\u6027\u3002", "conclusion": "OASBuilder\u5b9e\u73b0\u4e86API\u6587\u6863\u81ea\u52a8\u5316\u8f6c\u5316\u4e3a\u6807\u51c6\u89c4\u683c\u7684\u6d41\u7a0b\uff0c\u5927\u5e45\u63d0\u9ad8\u4e86API\u63a5\u5165\u6548\u7387\uff0c\u5bf9\u4f01\u4e1a\u548cAI\u5de5\u5177\u5177\u6709\u5b9e\u9645\u4ef7\u503c\u3002"}}
{"id": "2507.05385", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05385", "abs": "https://arxiv.org/abs/2507.05385", "authors": ["Guanzhong Pan", "Mei Tan", "Hyunji Nam", "Luc\u00eda Langlois", "James Malamut", "Liliana Deonizio", "Dorottya Demszky"], "title": "EduCoder: An Open-Source Annotation System for Education Transcript Data", "comment": null, "summary": "We introduce EduCoder, a domain-specialized tool designed to support\nutterance-level annotation of educational dialogue. While general-purpose text\nannotation tools for NLP and qualitative research abound, few address the\ncomplexities of coding education dialogue transcripts -- with diverse\nteacher-student and peer interactions. Common challenges include defining\ncodebooks for complex pedagogical features, supporting both open-ended and\ncategorical coding, and contextualizing utterances with external features, such\nas the lesson's purpose and the pedagogical value of the instruction. EduCoder\nis designed to address these challenges by providing a platform for researchers\nand domain experts to collaboratively define complex codebooks based on\nobserved data. It incorporates both categorical and open-ended annotation types\nalong with contextual materials. Additionally, it offers a side-by-side\ncomparison of multiple annotators' responses, allowing comparison and\ncalibration of annotations with others to improve data reliability. The system\nis open-source, with a demo video available.", "AI": {"tldr": "EduCoder\u662f\u4e00\u4e2a\u9762\u5411\u6559\u80b2\u5bf9\u8bdd\u9010\u53e5\u6807\u6ce8\u7684\u5f00\u6e90\u5e73\u53f0\uff0c\u652f\u6301\u590d\u6742\u4ee3\u7801\u672c\u5b9a\u4e49\u3001\u591a\u79cd\u6807\u6ce8\u7c7b\u578b\u53ca\u591a\u6807\u6ce8\u8005\u5bf9\u6bd4\uff0c\u6781\u5927\u63d0\u5347\u4e86\u6559\u80b2\u9886\u57df\u5bf9\u8bdd\u6807\u6ce8\u7684\u6548\u7387\u4e0e\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6587\u672c\u6807\u6ce8\u5de5\u5177\u96be\u4ee5\u6ee1\u8db3\u6559\u80b2\u5bf9\u8bdd\u7684\u590d\u6742\u6807\u6ce8\u9700\u6c42\uff0c\u4f8b\u5982\u591a\u6837\u7684\u5e08\u751f\u548c\u540c\u4f34\u4e92\u52a8\u3001\u590d\u6742\u7684\u6559\u5b66\u6027\u7279\u5f81\u7f16\u7801\uff0c\u4ee5\u53ca\u7ed3\u5408\u8bed\u5883\u4fe1\u606f\uff08\u5982\u8bfe\u7a0b\u76ee\u7684\u3001\u6559\u5b66\u4ef7\u503c\uff09\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u4e2a\u4e13\u95e8\u652f\u6301\u6559\u80b2\u5bf9\u8bdd\u9010\u53e5\u6807\u6ce8\u7684\u5de5\u5177\u3002", "method": "\u7814\u53d1\u4e86EduCoder\uff0c\u4e00\u4e2a\u652f\u6301\u6559\u80b2\u5bf9\u8bdd\u9010\u53e5\u6807\u6ce8\u7684\u5e73\u53f0\uff0c\u8be5\u5e73\u53f0\u5141\u8bb8\u7528\u6237\u534f\u4f5c\u5b9a\u4e49\u590d\u6742\u4ee3\u7801\u672c\u3001\u652f\u6301\u591a\u79cd\u6807\u6ce8\u7c7b\u578b\uff08\u5206\u7c7b\u548c\u5f00\u653e\u5f0f\uff09\u3001\u7ed3\u5408\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5e76\u80fd\u591a\u6807\u6ce8\u8005\u5e76\u6392\u5bf9\u6bd4\u8fdb\u884c\u6807\u6ce8\u6821\u51c6\u3002", "result": "EduCoder\u4e0d\u4ec5\u80fd\u591f\u6ee1\u8db3\u590d\u6742\u6559\u80b2\u5bf9\u8bdd\u7684\u6807\u6ce8\u9700\u6c42\uff0c\u8fd8\u63d0\u5347\u4e86\u6807\u6ce8\u7ed3\u679c\u7684\u53ef\u9760\u6027\uff0c\u76ee\u524d\u5df2\u5f00\u6e90\uff0c\u5e76\u6709\u6f14\u793a\u89c6\u9891\u3002", "conclusion": "EduCoder\u5e73\u53f0\u6709\u6548\u5730\u89e3\u51b3\u4e86\u6559\u80b2\u5bf9\u8bdd\u6807\u6ce8\u4e2d\u7684\u4e00\u7cfb\u5217\u96be\u70b9\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u7814\u7a76\u4eba\u5458\u548c\u4e13\u5bb6\u5408\u4f5c\u6807\u6ce8\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2507.05325", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.05325", "abs": "https://arxiv.org/abs/2507.05325", "authors": ["Lidiany Cerqueira", "Jo\u00e3o Pedro Bastos", "Danilo Neves", "Glauco Carneiro", "Rodrigo Sp\u00ednola", "S\u00e1vio Freire", "Jos\u00e9 Amancio Macedo Santos", "Manoel Mendon\u00e7a"], "title": "Exploring Empathy in Software Engineering: Insights from a Grey Literature Analysis of Practitioners' Perspectives", "comment": "This is the author's version of the paper accepted for publication in\n  ACM Transactions on Software Engineering and Methodology. The final version\n  will be available via the ACM Digital Library. The HTML preview may not\n  render some formatting correctly. Please refer to the PDF version for\n  accurate presentation", "summary": "Context. Empathy, a key social skill, is essential for communication and\ncollaboration in SE but remains an under-researched topic. Aims. This study\ninvestigates empathy in SE from practitioners' perspectives, aiming to\ncharacterize its meaning, identify barriers, discuss practices to overcome\nthem, and explore its effects. Method. A qualitative content analysis was\nconducted on 55 web articles from DEV and Medium, two communities widely used\nby practitioners. To strengthen our findings, we conducted a follow-up survey\nwith empathy experts. Results. The study proposes a definition of empathy in\nSE, identifies barriers such as toxic culture and excessive technical focus,\npractices to foster empathy in teams, and outcomes, including improved\ncollaboration, communication, and reduced anxiety, frustration, and stress.\nThese findings are synthesized into a conceptual framework. Conclusion. Survey\nresults indicate the framework is clear, valuable, and raises empathy\nawareness, with suggestions for improvements and integration into training.\nThis study paves the way for improving team dynamics by addressing barriers and\noffering strategies to cultivate empathy. Future work will explore empathy's\nbroader implications in SE practice.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u5206\u6790\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u5185\u540c\u7406\u5fc3\u6982\u5ff5\u3001\u969c\u788d\u3001\u4fc3\u8fdb\u65b9\u6cd5\u53ca\u6548\u679c\uff0c\u6784\u5efa\u5e76\u9a8c\u8bc1\u4e86\u540c\u7406\u5fc3\u6846\u67b6\uff0c\u4e3a\u63d0\u5347\u56e2\u961f\u534f\u4f5c\u548c\u6c9f\u901a\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u652f\u6301\u548c\u5b9e\u8df5\u65b9\u5411\u3002", "motivation": "\u540c\u7406\u5fc3\u662f\u5173\u952e\u7684\u793e\u4f1a\u6280\u80fd\uff0c\u5bf9\u4e8e\u6c9f\u901a\u4e0e\u534f\u4f5c\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5728\u8f6f\u4ef6\u5de5\u7a0b\uff08SE\uff09\u9886\u57df\u4ecd\u7136\u7814\u7a76\u4e0d\u8db3\u3002\u8be5\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u5b9e\u8df5\u8005\u89c6\u89d2\u4e0b\u7684\u540c\u7406\u5fc3\u5185\u6db5\u3001\u969c\u788d\u3001\u5b9e\u8df5\u65b9\u6cd5\u53ca\u5176\u5f71\u54cd\u3002", "method": "\u5b9a\u6027\u5185\u5bb9\u5206\u679055\u7bc7\u4e1a\u754c\u793e\u533a\u6587\u7ae0\uff0c\u968f\u540e\u901a\u8fc7\u540c\u7406\u5fc3\u4e13\u5bb6\u95ee\u5377\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u548c\u5b8c\u5584\u53d1\u73b0\u3002", "result": "\u63d0\u51fa\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u540c\u7406\u5fc3\u7684\u5b9a\u4e49\uff0c\u8bc6\u522b\u4e86\u963b\u788d\uff08\u5982\u6709\u6bd2\u6587\u5316\u3001\u8fc7\u5ea6\u6280\u672f\u5bfc\u5411\uff09\u3001\u4fc3\u8fdb\u56e2\u961f\u540c\u7406\u5fc3\u7684\u5b9e\u8df5\u65b9\u5f0f\uff0c\u4ee5\u53ca\u63d0\u5347\u56e2\u961f\u534f\u4f5c\u3001\u6c9f\u901a\u3001\u7f13\u89e3\u538b\u529b\u548c\u7126\u8651\u7684\u6548\u679c\uff0c\u6700\u7ec8\u7efc\u5408\u4e3a\u4e00\u4e2a\u6982\u5ff5\u6846\u67b6\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u7684\u540c\u7406\u5fc3\u6846\u67b6\u88ab\u8ba4\u4e3a\u6e05\u6670\u4e14\u5177\u6709\u4ef7\u503c\uff0c\u63d0\u9ad8\u4e86\u5f00\u53d1\u8005\u5bf9\u540c\u7406\u5fc3\u7684\u5173\u6ce8\uff0c\u5e76\u6709\u52a9\u4e8e\u56e2\u961f\u534f\u4f5c\u6c1b\u56f4\u4f18\u5316\u3002\u672a\u6765\u7684\u7814\u7a76\u5c06\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u4e2d\u8fdb\u4e00\u6b65\u63a2\u8ba8\u540c\u7406\u5fc3\u7684\u66f4\u5e7f\u6cdb\u5f71\u54cd\u3002"}}
{"id": "2507.05387", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05387", "abs": "https://arxiv.org/abs/2507.05387", "authors": ["Ruidi Chang", "Chunyuan Deng", "Hanjie Chen"], "title": "The Generalization Ridge: Information Flow in Natural Language Generation", "comment": null, "summary": "Transformer-based language models have achieved state-of-the-art performance\nin natural language generation (NLG) tasks, yet their internal mechanisms for\nsynthesizing task-relevant information remain insufficiently understood. While\nprior studies suggest that intermediate layers often yield more generalizable\nrepresentations than final layers, how this generalization ability emerges and\npropagates across layers during training remains unclear. To address this gap,\nwe propose InfoRidge, an information-theoretic framework, to characterize how\npredictive information-the mutual information between hidden representations\nand target outputs-varies across depth. Estimating this quantity enables us to\ntrace the flow of task-relevant information throughout the model during\ntraining. Our experiments across various models and datasets reveal a\nconsistent non-monotonic trend: predictive information peaks in upper-middle\nlayers-forming a generalization ridge-before declining in final layers,\nreflecting a transition between generalization and memorization. To further\ninvestigate this phenomenon, we introduce residual scaling\ncoefficients-trainable scalar parameters applied to each residual block-which\nserve as functional probes for assessing the relative importance of individual\ntransformer layers. These coefficients reveal that, under distribution shift,\nmodels downweight final layers and increasingly rely on ridge layers,\nhighlighting their role in generalization. Together, these findings offer new\ninsights into the internal mechanisms of transformers and underscore the\ncritical role of intermediate layers in supporting generalization.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4fe1\u606f\u8bba\u89c6\u89d2\uff08InfoRidge\uff09\u5206\u6790Transformer\u6a21\u578b\uff0c\u53d1\u73b0\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u4f9d\u8d56\u4e8e\u4e2d\u4e0a\u5c42\uff08\u800c\u975e\u6700\u7ec8\u5c42\uff09\uff0c\u5e76\u63d0\u51fa\u6b8b\u5dee\u7f29\u653e\u7cfb\u6570\u4f5c\u4e3a\u529f\u80fd\u6027\u63a2\u9488\u9a8c\u8bc1\u4e86\u8be5\u673a\u5236\u3002", "motivation": "\u867d\u7136Transformer\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5185\u90e8\u7684\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\u6574\u5408\u673a\u5236\u5c1a\u4e0d\u6e05\u695a\uff0c\u5c24\u5176\u662f\u4e2d\u95f4\u5c42\u5982\u4f55\u5b9e\u73b0\u6cdb\u5316\u80fd\u529b\u4ee5\u53ca\u76f8\u5173\u4fe1\u606f\u5982\u4f55\u968f\u5c42\u4f20\u64ad\u3002", "method": "\u63d0\u51faInfoRidge\u8fd9\u4e00\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u4f30\u7b97Transformer\u4e2d\u9690\u8868\u793a\u4e0e\u76ee\u6807\u8f93\u51fa\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\uff0c\u8ffd\u8e2a\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\u5728\u5404\u5c42\u7684\u6d41\u52a8\u3002\u540c\u65f6\u5f15\u5165\u53ef\u8bad\u7ec3\u7684\u6b8b\u5dee\u7f29\u653e\u7cfb\u6570\uff0c\u4ee5\u529f\u80fd\u6027\u63a2\u9488\u8bc4\u4f30\u5404\u5c42\u76f8\u5bf9\u91cd\u8981\u6027\u5e76\u7814\u7a76\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u4f5c\u7528\u53d8\u5316\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u4efb\u52a1\u76f8\u5173\u7684\u9884\u6d4b\u4fe1\u606f\u5728\u4e2d\u4e0a\u5c42\u8fbe\u5230\u5cf0\u503c\uff08\u5f62\u6210\u201c\u6cdb\u5316\u810a\u201d\uff0cgeneralization ridge\uff09\uff0c\u5728\u6700\u7ec8\u5c42\u4e0b\u964d\uff0c\u8868\u660e\u6a21\u578b\u7531\u6cdb\u5316\u8f6c\u5411\u8bb0\u5fc6\u3002\u6b8b\u5dee\u7f29\u653e\u7cfb\u6570\u5206\u6790\u8868\u660e\uff0c\u9762\u5bf9\u5206\u5e03\u504f\u79fb\u65f6\uff0c\u6a21\u578b\u4f1a\u51cf\u5f31\u5bf9\u6700\u7ec8\u5c42\u7684\u4f9d\u8d56\uff0c\u66f4\u4f9d\u8d56\u4e8e\u810a\u5c42\uff0c\u51f8\u663e\u4e2d\u95f4\u5c42\u5728\u6cdb\u5316\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u63d0\u51fa\u4e86\u53ef\u91cf\u5316\u548c\u53ef\u89e3\u91ca\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86Transformer\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u4e3b\u8981\u4f9d\u8d56\u4e8e\u4e2d\u95f4\u5c42\uff0c\u5e76\u5bf9\u5176\u5185\u90e8\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u7684\u6d1e\u89c1\u3002"}}
{"id": "2507.05504", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.05504", "abs": "https://arxiv.org/abs/2507.05504", "authors": ["Alex Kleijwegt", "Sinem Getir Yaman", "Radu Calinescu"], "title": "Tool for Supporting Debugging and Understanding of Normative Requirements Using LLMs", "comment": null, "summary": "Normative requirements specify social, legal, ethical, empathetic, and\ncultural (SLEEC) norms that must be observed by a system. To support the\nidentification of SLEEC requirements, numerous standards and regulations have\nbeen developed. These requirements are typically defined by stakeholders in the\nnon-technical system with diverse expertise (e.g., ethicists, lawyers, social\nscientists). Hence, ensuring their consistency and managing the requirement\nelicitation process are complex and error-prone tasks. Recent research has\naddressed this challenge using domain-specific languages to specify normative\nrequirements as rules, whose consistency can then be analyzed with formal\nmethods. Nevertheless, these approaches often present the results from formal\nverification tools in a way that is inaccessible to non-technical users. This\nhinders understanding and makes the iterative process of eliciting and\nvalidating these requirements inefficient in terms of both time and effort. To\naddress this problem, we introduce SLEEC-LLM, a tool that uses large language\nmodels (LLMs) to provide natural-language interpretations for model-checking\ncounterexamples corresponding to SLEEC rule inconsistencies. SLEEC-LLM improves\nthe efficiency and explainability of normative requirements elicitation and\nconsistency analysis. To demonstrate its effectiveness, we summarise its use in\ntwo real-world case studies involving non-technical stakeholders.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SLEEC-LLM\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u793e\u4f1a\u3001\u6cd5\u5f8b\u3001\u4f26\u7406\u7b49\u89c4\u8303\u6027\u9700\u6c42\u7684\u4e00\u81f4\u6027\u5206\u6790\u63d0\u4f9b\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u6781\u5927\u63d0\u5347\u4e86\u975e\u6280\u672f\u7528\u6237\u7684\u7406\u89e3\u4e0e\u53c2\u4e0e\u6548\u7387\u3002", "motivation": "\u968f\u7740\u793e\u4f1a\u3001\u6cd5\u5f8b\u3001\u4f26\u7406\u3001\u5171\u60c5\u548c\u6587\u5316\uff08SLEEC\uff09\u89c4\u8303\u8981\u6c42\u65e5\u76ca\u589e\u591a\uff0c\u7cfb\u7edf\u9700\u4e25\u683c\u9075\u5b88\u8fd9\u4e9b\u89c4\u8303\u3002\u4f46\u8fd9\u4e9b\u9700\u6c42\u5e38\u7531\u975e\u6280\u672f\u9886\u57df\u7684\u5229\u76ca\u76f8\u5173\u8005\u63d0\u51fa\uff0c\u9700\u6c42\u5f52\u7eb3\u548c\u4e00\u81f4\u6027\u7ba1\u7406\u8fc7\u7a0b\u65e2\u590d\u6742\u53c8\u6613\u51fa\u9519\uff0c\u73b0\u6709\u5f62\u5f0f\u5316\u65b9\u6cd5\u7ed3\u679c\u96be\u4ee5\u88ab\u975e\u6280\u672f\u7528\u6237\u7406\u89e3\uff0c\u5f71\u54cd\u9700\u6c42\u63d0\u70bc\u548c\u9a8c\u8bc1\u6548\u7387\u3002", "method": "\u63d0\u51faSLEEC-LLM\u5de5\u5177\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5bf9\u6a21\u578b\u68c0\u6d4b\u5f97\u5230\u7684SLEEC\u89c4\u5219\u4e0d\u4e00\u81f4\u7684\u53cd\u4f8b\uff0c\u7ed9\u4e88\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002\u63d0\u5347\u975e\u6280\u672f\u7528\u6237\u5bf9\u6b63\u5f0f\u9a8c\u8bc1\u7ed3\u679c\u7684\u7406\u89e3\u3002\u5e76\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9645\u6848\u4f8b\u8fdb\u884c\u65b9\u6cd5\u6548\u679c\u7684\u5c55\u793a\u3002", "result": "SLEEC-LLM\u663e\u8457\u63d0\u5347\u4e86SLEEC\u89c4\u8303\u6027\u9700\u6c42\u5f52\u7eb3\u4e0e\u4e00\u81f4\u6027\u5206\u6790\u7684\u6548\u7387\u3001\u53ef\u89e3\u91ca\u6027\u548c\u7528\u6237\u4f53\u9a8c\uff0c\u7ecf\u771f\u5b9e\u6848\u4f8b\u9a8c\u8bc1\uff0c\u8be5\u5de5\u5177\u5bf9\u975e\u6280\u672f\u5229\u76ca\u76f8\u5173\u8005\u6709\u826f\u597d\u9002\u7528\u6027\u3002", "conclusion": "SLEEC-LLM\u901a\u8fc7\u5c06\u590d\u6742\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7ed3\u679c\u8f6c\u5316\u4e3a\u6613\u4e8e\u7406\u89e3\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u6709\u6548\u589e\u5f3a\u4e86\u89c4\u8303\u6027\u9700\u6c42\u7684\u63d0\u70bc\u4e0e\u4e00\u81f4\u6027\u5206\u6790\u6d41\u7a0b\uff0c\u80fd\u66f4\u597d\u670d\u52a1\u975e\u6280\u672f\u9886\u57df\u7528\u6237\u3002"}}
{"id": "2507.05391", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05391", "abs": "https://arxiv.org/abs/2507.05391", "authors": ["Guillem Ram\u00edrez", "Alexandra Birch", "Ivan Titov"], "title": "Controlling What You Share: Assessing Language Model Adherence to Privacy Preferences", "comment": null, "summary": "Large language models (LLMs) are primarily accessed via commercial APIs, but\nthis often requires users to expose their data to service providers. In this\npaper, we explore how users can stay in control of their data by using privacy\nprofiles: simple natural language instructions that say what should and should\nnot be revealed. We build a framework where a local model uses these\ninstructions to rewrite queries, only hiding details deemed sensitive by the\nuser, before sending them to an external model, thus balancing privacy with\nperformance. To support this research, we introduce PEEP, a multilingual\ndataset of real user queries annotated to mark private content and paired with\nsynthetic privacy profiles. Our experiments with lightweight LLMs show they can\nfollow these instructions to some extent, but also face consistent challenges,\nhighlighting the need for models that better understand and comply with\nuser-defined privacy preferences.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u81ea\u7136\u8bed\u8a00\u9690\u79c1\u6307\u4ee4\u91cd\u5199\u67e5\u8be2\u4ee5\u4fdd\u62a4\u9690\u79c1\u7684\u6846\u67b6\uff0c\u5e76\u4ee5PEEP\u6570\u636e\u96c6\u652f\u6301\u5b9e\u9a8c\u3002\u7ed3\u679c\u663e\u793a\uff0c\u8f7b\u91cf\u7ea7LLMs\u5728\u9690\u79c1\u9075\u5faa\u4e0a\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "motivation": "\u9762\u5bf9\u901a\u8fc7\u5546\u4e1aAPI\u8bbf\u95eeLLM\u65f6\u7528\u6237\u6570\u636e\u9690\u79c1\u6cc4\u9732\u7684\u98ce\u9669\uff0c\u65e8\u5728\u4e3a\u7528\u6237\u63d0\u4f9b\u66f4\u5927\u6570\u636e\u63a7\u5236\u6743\uff0c\u5e76\u5e73\u8861\u9690\u79c1\u4fdd\u62a4\u4e0e\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u5229\u7528\u672c\u5730\u6a21\u578b\u6839\u636e\u7528\u6237\u81ea\u7136\u8bed\u8a00\u9690\u79c1\u6307\u4ee4\u91cd\u5199\u67e5\u8be2\u7684\u6846\u67b6\uff0c\u5f15\u5165\u4e86PEEP\u591a\u8bed\u8a00\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u9690\u79c1\u5185\u5bb9\u7684\u6807\u6ce8\u4e0e\u5904\u7406\u80fd\u529b\u3002\u5728\u5b9e\u9a8c\u4e2d\uff0c\u91c7\u7528\u8f7b\u91cf\u7ea7LLMs\u8bc4\u4f30\u7cfb\u7edf\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u524d\u8f7b\u91cf\u7ea7LLMs\u80fd\u591f\u6309\u7167\u9690\u79c1\u6307\u4ee4\u90e8\u5206\u9690\u85cf\u654f\u611f\u4fe1\u606f\uff0c\u5bf9\u9690\u79c1\u504f\u597d\u7684\u7406\u89e3\u4e0e\u9075\u5faa\u80fd\u529b\u6709\u5f85\u63d0\u5347\u3002", "conclusion": "\u8f7b\u91cf\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u80fd\u591f\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u6309\u7167\u7528\u6237\u81ea\u7136\u8bed\u8a00\u9690\u79c1\u6307\u4ee4\u5bf9\u67e5\u8be2\u8fdb\u884c\u91cd\u5199\uff0c\u4f46\u5728\u7406\u89e3\u548c\u670d\u4ece\u7528\u6237\u9690\u79c1\u504f\u597d\u65b9\u9762\u4ecd\u5b58\u5728\u660e\u663e\u6311\u6218\u3002"}}
{"id": "2507.05565", "categories": ["cs.SE", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.05565", "abs": "https://arxiv.org/abs/2507.05565", "authors": ["Sangwon Hyun", "Shaukat Ali", "M. Ali Babar"], "title": "Search-based Selection of Metamorphic Relations for Optimized Robustness Testing of Large Language Models", "comment": null, "summary": "Assessing the trustworthiness of Large Language Models (LLMs), such as\nrobustness, has garnered significant attention. Recently, metamorphic testing\nthat defines Metamorphic Relations (MRs) has been widely applied to evaluate\nthe robustness of LLM executions. However, the MR-based robustness testing\nstill requires a scalable number of MRs, thereby necessitating the optimization\nof selecting MRs. Most extant LLM testing studies are limited to automatically\ngenerating test cases (i.e., MRs) to enhance failure detection. Additionally,\nmost studies only considered a limited test space of single perturbation MRs in\ntheir evaluation of LLMs. In contrast, our paper proposes a search-based\napproach for optimizing the MR groups to maximize failure detection and\nminimize the LLM execution cost. Moreover, our approach covers the\ncombinatorial perturbations in MRs, facilitating the expansion of test space in\nthe robustness assessment. We have developed a search process and implemented\nfour search algorithms: Single-GA, NSGA-II, SPEA2, and MOEA/D with novel\nencoding to solve the MR selection problem in the LLM robustness testing. We\nconducted comparative experiments on the four search algorithms along with a\nrandom search, using two major LLMs with primary Text-to-Text tasks. Our\nstatistical and empirical investigation revealed two key findings: (1) the\nMOEA/D algorithm performed the best in optimizing the MR space for LLM\nrobustness testing, and (2) we identified silver bullet MRs for the LLM\nrobustness testing, which demonstrated dominant capabilities in confusing LLMs\nacross different Text-to-Text tasks. In LLM robustness assessment, our research\nsheds light on the fundamental problem for optimized testing and provides\ninsights into search-based solutions.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u641c\u7d22\u7684MR\u7ec4\u5408\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347LLM\u9c81\u68d2\u6027\u6d4b\u8bd5\u6548\u7387\u548c\u6548\u679c\uff0cMOEA/D\u7b97\u6cd5\u6548\u679c\u6700\u4f73\uff0c\u8fd8\u53d1\u73b0\u901a\u7528\u4e14\u5f3a\u6548\u7684\u5e72\u6270MR\u7ec4\u5408\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7a33\u5065\u6027\u6d4b\u8bd5\u4e3b\u8981\u4f9d\u8d56\u4e8e\u53d8\u5f62\u5173\u7cfb\uff08MRs\uff09\u6d4b\u8bd5\uff0c\u4f46\u9700\u8981\u5927\u91cf\u9ad8\u8d28\u91cf\u7684MRs\uff0c\u5e76\u9762\u4e34\u5982\u4f55\u4f18\u5316MR\u9009\u62e9\u4ee5\u63d0\u5347\u5931\u8d25\u68c0\u6d4b\u80fd\u529b\u3001\u964d\u4f4e\u6d4b\u8bd5\u6210\u672c\u7684\u95ee\u9898\u3002\u540c\u65f6\uff0c\u591a\u6570\u7814\u7a76\u4ec5\u5173\u6ce8\u5355\u4e00\u6270\u52a8\u7684\u6d4b\u8bd5\u7a7a\u95f4\uff0c\u8986\u76d6\u6709\u9650\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u641c\u7d22\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u56db\u79cd\u641c\u7d22\u7b97\u6cd5\uff08Single-GA\u3001NSGA-II\u3001SPEA2\u3001MOEA/D\uff09\uff0c\u5bf9MR\u7ec4\u5408\u8fdb\u884c\u4f18\u5316\u9009\u62e9\uff0c\u517c\u987e\u63d0\u9ad8\u5931\u8d25\u68c0\u6d4b\uff08\u9c81\u68d2\u6027\u6d4b\u8bd5\u7684\u6548\u80fd\uff09\u80fd\u529b\u548c\u964d\u4f4eLLM\u8fd0\u884c\u6210\u672c\u3002\u65b9\u6cd5\u521b\u65b0\u5730\u6db5\u76d6\u4e86\u591a\u91cd\u7ec4\u5408\u6270\u52a8MR\uff0c\u6269\u5927\u4e86\u8bc4\u6d4b\u7a7a\u95f4\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u7f16\u7801\u65b9\u5f0f\u6765\u89e3\u51b3MR\u9009\u62e9\u4f18\u5316\u95ee\u9898\u3002", "result": "\u5728\u4e24\u4e2a\u4e3b\u6d41LLM\u548c\u4e3b\u8981Text-to-Text\u4efb\u52a1\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7cfb\u7edf\u6bd4\u8f83\u56db\u79cd\u641c\u7d22\u7b97\u6cd5\u4e0e\u968f\u673a\u641c\u7d22\u7684\u6548\u679c\uff0c\u7ed3\u679c\u663e\u793aMOEA/D\u7b97\u6cd5\u5728LLM\u7a33\u5065\u6027\u6d4b\u8bd5\u7684MR\u7a7a\u95f4\u4f18\u5316\u4e0a\u8868\u73b0\u6700\u4f73\u3002\u6b64\u5916\uff0c\u53d1\u73b0\u4e86\u5177\u6709\u2018\u94f6\u5f39\u2019\u6548\u679c\u7684MRs\uff0c\u5b83\u4eec\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u90fd\u80fd\u6709\u6548\u8ff7\u60d1LLM\u3002", "conclusion": "\u641c\u7d22\u5f0fMR\u4f18\u5316\u80fd\u660e\u663e\u63d0\u5347LLM\u9c81\u68d2\u6027\u6d4b\u8bd5\u6548\u7387\u548c\u6548\u679c\uff0c\u7279\u522b\u662fMOEA/D\u7b97\u6cd5\u5728MR\u7ec4\u5408\u9009\u62e9\u4e0a\u5177\u6709\u4f18\u52bf\uff0c\u5b9e\u9a8c\u4e5f\u63ed\u793a\u90e8\u5206\u7ec4\u5408\u6270\u52a8MR\u5177\u5907\u901a\u7528\u7684\u6df7\u6dc6\u80fd\u529b\uff0c\u5bf9\u9c81\u68d2\u6027\u8bc4\u6d4b\u7814\u7a76\u5177\u6709\u91cd\u8981\u542f\u53d1\u3002"}}
{"id": "2507.05418", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.05418", "abs": "https://arxiv.org/abs/2507.05418", "authors": ["Jaedong Hwang", "Kumar Tanmay", "Seok-Jin Lee", "Ayush Agrawal", "Hamid Palangi", "Kumar Ayush", "Ila Fiete", "Paul Pu Liang"], "title": "Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning", "comment": null, "summary": "Large Language Models (LLMs) have achieved strong performance in domains like\nmathematics, factual QA, and code generation, yet their multilingual reasoning\ncapabilities in these tasks remain underdeveloped. Especially for low-resource\nlanguages such as Swahili or Thai, LLMs can often misinterpret prompts or\ndefault to reasoning in English. This implicit bias toward high-resource\nlanguages undermines factual accuracy, interpretability, and trust. Current\nmultilingual benchmarks focus only on final answers, overlooking whether models\nactually reason in the target language. To address this gap, we introduce\nGeoFact-X, a geography-based multilingual factual reasoning benchmark with\nannotated reasoning traces in five languages: English, Hindi, Japanese,\nSwahili, and Thai. We further propose BRIDGE, a novel training method that\nguides supervised fine-tuning and test-time reinforcement learning with a\nlanguage-consistency reward to align reasoning with the input language.\nFinally, we develop an automatic evaluation protocol using LLM-as-a-judge to\nassess answer correctness and the quality and language consistency of reasoning\ntraces, enabling nuanced and scalable analysis beyond surface-level metrics.\nOur results show that BRIDGE significantly enhances multilingual reasoning\nfidelity, demonstrating that reasoning-aware multilingual reinforcement\nlearning is crucial for robust cross-lingual generalization.\nhttps://jd730.github.io/projects/GeoFact-X_BRIDGE", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u65b0\u7684\u591a\u8bed\u8a00\u63a8\u7406\u57fa\u51c6GeoFact-X\u548cBRIDGE\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u8bed\u8a00\u4e00\u81f4\u6027\u7ea6\u675f\u548c\u81ea\u52a8\u8bc4\u6d4b\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u591a\u8bed\u8a00\uff0c\u7279\u522b\u662f\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0b\u7684\u63a8\u7406\u80fd\u529b\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bf8\u5982\u6570\u5b66\u3001\u4e8b\u5b9e\u95ee\u7b54\u548c\u4ee3\u7801\u751f\u6210\u7b49\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5728\u591a\u8bed\u8a00\u63a8\u7406\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5982\u65af\u74e6\u5e0c\u91cc\u8bed\u6216\u6cf0\u8bed\uff09\u65b9\u9762\u4ecd\u7136\u8584\u5f31\uff0c\u5e38\u5e38\u5c06\u63a8\u7406\u8fc7\u7a0b\u9ed8\u8ba4\u4e3a\u82f1\u8bed\u3002\u4f20\u7edf\u591a\u8bed\u8a00\u57fa\u51c6\u53ea\u5173\u6ce8\u6700\u7ec8\u7b54\u6848\uff0c\u5ffd\u7565\u4e86\u6a21\u578b\u662f\u5426\u5b9e\u9645\u5728\u76ee\u6807\u8bed\u8a00\u8fdb\u884c\u63a8\u7406\uff0c\u8fd9\u5f71\u54cd\u4e86\u51c6\u786e\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86GeoFact-X\uff0c\u4e00\u4e2a\u5305\u542b\u4e94\u79cd\u8bed\u8a00\uff08\u82f1\u8bed\u3001\u5370\u5730\u8bed\u3001\u65e5\u8bed\u3001\u65af\u74e6\u5e0c\u91cc\u8bed\u548c\u6cf0\u8bed\uff09\u7684\u5730\u7406\u5e38\u8bc6\u591a\u8bed\u8a00\u63a8\u7406\u57fa\u51c6\uff0c\u5e76\u63d0\u4f9b\u6807\u6ce8\u63a8\u7406\u8fc7\u7a0b\u3002\u540c\u65f6\uff0c\u63d0\u51faBRIDGE\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u8bed\u8a00\u4e00\u81f4\u6027\u5956\u52b1\uff0c\u7ed3\u5408\u6709\u76d1\u7763\u5fae\u8c03\u548c\u6d4b\u8bd5\u65f6\u5f3a\u5316\u5b66\u4e60\uff0c\u5c06\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e0e\u8f93\u5165\u8bed\u8a00\u66f4\u597d\u5bf9\u9f50\u3002\u6700\u540e\uff0c\u5229\u7528LLM\u81ea\u52a8\u8bc4\u5224\u7cfb\u7edf\uff0c\u8bc4\u4ef7\u7b54\u6848\u6b63\u786e\u6027\u53ca\u63a8\u7406\u8fc7\u7a0b\u7684\u8bed\u8a00\u4e00\u81f4\u6027\u548c\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cBRIDGE\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u591a\u8bed\u8a00\u63a8\u7406\u7684\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\uff0c\u5c24\u5176\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u8868\u73b0\u7a81\u51fa\uff0c\u5f3a\u5316\u4e86\u8de8\u8bed\u8a00\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u63a8\u7406\u611f\u77e5\u7684\u591a\u8bed\u8a00\u5f3a\u5316\u5b66\u4e60\u5bf9\u4e8e\u63d0\u5347\u5927\u6a21\u578b\u8de8\u8bed\u8a00\u63a8\u7406\u80fd\u529b\u81f3\u5173\u91cd\u8981\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u591a\u8bed\u8a00\u63a8\u7406\u7684\u8868\u73b0\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2507.05932", "categories": ["cs.SE", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.05932", "abs": "https://arxiv.org/abs/2507.05932", "authors": ["You Lu", "Dingji Wang", "Kaifeng Huang", "Bihuan Chen", "Xin Peng"], "title": "TigAug: Data Augmentation for Testing Traffic Light Detection in Autonomous Driving Systems", "comment": null, "summary": "Autonomous vehicle technology has been developed in the last decades with\nrecent advances in sensing and computing technology. There is an urgent need to\nensure the reliability and robustness of autonomous driving systems (ADSs).\nDespite the recent achievements in testing various ADS modules, little\nattention has been paid on the automated testing of traffic light detection\nmodels in ADSs. A common practice is to manually collect and label traffic\nlight data. However, it is labor-intensive, and even impossible to collect\ndiverse data under different driving environments.\n  To address these problems, we propose and implement TigAug to automatically\naugment labeled traffic light images for testing traffic light detection models\nin ADSs. We construct two families of metamorphic relations and three families\nof transformations based on a systematic understanding of weather environments,\ncamera properties, and traffic light properties. We use augmented images to\ndetect erroneous behaviors of traffic light detection models by\ntransformation-specific metamorphic relations, and to improve the performance\nof traffic light detection models by retraining. Large-scale experiments with\nfour state-of-the-art traffic light detection models and two traffic light\ndatasets have demonstrated that i) TigAug is effective in testing traffic light\ndetection models, ii) TigAug is efficient in synthesizing traffic light images,\nand iii) TigAug generates traffic light images with acceptable naturalness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684TigAug\u7cfb\u7edf\u53ef\u81ea\u52a8\u589e\u5f3a\u4ea4\u901a\u706f\u56fe\u50cf\uff0c\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u4ea4\u901a\u706f\u68c0\u6d4b\u6a21\u578b\u7684\u9ad8\u6548\u6d4b\u8bd5\u548c\u6027\u80fd\u63d0\u5347\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u5c3d\u7ba1\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\uff08ADS\uff09\u5728\u591a\u4e2a\u6a21\u5757\u6d4b\u8bd5\u4e0a\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u4ea4\u901a\u706f\u68c0\u6d4b\u6a21\u578b\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u53d7\u5230\u5ffd\u89c6\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6536\u96c6\u548c\u6807\u6ce8\u4ea4\u901a\u706f\u6570\u636e\uff0c\u65e2\u8d39\u65f6\u8d39\u529b\uff0c\u4e5f\u96be\u4ee5\u8986\u76d6\u591a\u6837\u5316\u73af\u5883\u3002\u6025\u9700\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u6d4b\u8bd5\u548c\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u4ee5\u63d0\u5347ADS\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86TigAug\u7cfb\u7edf\uff0c\u80fd\u591f\u81ea\u52a8\u589e\u5f3a\u5df2\u6807\u6ce8\u4ea4\u901a\u706f\u56fe\u50cf\u7528\u4e8eADS\u4ea4\u901a\u706f\u68c0\u6d4b\u6a21\u578b\u7684\u6d4b\u8bd5\u3002TigAug\u57fa\u4e8e\u5bf9\u5929\u6c14\u73af\u5883\u3001\u76f8\u673a\u5c5e\u6027\u548c\u4ea4\u901a\u706f\u5c5e\u6027\u7684\u7cfb\u7edf\u7406\u89e3\uff0c\u6784\u5efa\u4e86\u4e24\u7c7b\u53d8\u5f62\u5173\u7cfb\u548c\u4e09\u7c7b\u56fe\u50cf\u53d8\u6362\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u7279\u5b9a\u53d8\u6362\u7684\u53d8\u5f62\u5173\u7cfb\u68c0\u6d4b\u6a21\u578b\u9519\u8bef\u884c\u4e3a\uff0c\u5e76\u5229\u7528\u589e\u5f3a\u6570\u636e\u518d\u6b21\u8bad\u7ec3\u4ee5\u63d0\u5347\u6a21\u578b\u8868\u73b0\u3002", "result": "\u57284\u79cd\u6700\u524d\u6cbf\u4ea4\u901a\u706f\u68c0\u6d4b\u6a21\u578b\u548c2\u4e2a\u4ea4\u901a\u706f\u6570\u636e\u96c6\u4e0a\u7684\u5927\u89c4\u6a21\u5b9e\u9a8c\u8868\u660e\uff1aTigAug\u5728\u6d4b\u8bd5\u4ea4\u901a\u706f\u68c0\u6d4b\u6a21\u578b\u65b9\u9762\u6709\u6548\uff0c\u5728\u4ea4\u901a\u706f\u56fe\u50cf\u5408\u6210\u65b9\u9762\u9ad8\u6548\uff0c\u5e76\u80fd\u751f\u6210\u5177\u6709\u53ef\u63a5\u53d7\u81ea\u7136\u5ea6\u7684\u4ea4\u901a\u706f\u56fe\u50cf\u3002", "conclusion": "TigAug\u4e3a\u4ea4\u901a\u706f\u68c0\u6d4b\u6a21\u578b\u7684\u6d4b\u8bd5\u548c\u6539\u8fdb\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u81ea\u52a8\u5316\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u7684\u5065\u58ee\u6027\u548c\u6027\u80fd\uff0c\u6709\u52a9\u4e8e\u4fdd\u969c\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2507.05424", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05424", "abs": "https://arxiv.org/abs/2507.05424", "authors": ["Yufei Tao", "Adam Hiatt", "Rahul Seetharaman", "Ameeta Agrawal"], "title": "\"Lost-in-the-Later\": Framework for Quantifying Contextual Grounding in Large Language Models", "comment": null, "summary": "Large language models are capable of leveraging both contextual and\nparametric knowledge but how they prioritize and integrate these sources\nremains underexplored. We introduce CoPE, a novel evaluation framework that\nsystematically measures contextual knowledge (CK) and parametric knowledge (PK)\nacross models and languages. Using our MultiWikiAtomic dataset in English,\nSpanish, and Danish, we analyze how large language models (LLMs) integrate\ncontext, prioritize information, and incorporate PK in open-ended question\nanswering. Our analysis uncovers a phenomenon we call lost-in-the-later, where\nLLMs tend to overlook or deprioritize information that appears later in a given\ncontext, revealing a strong positional bias that affects contextual grounding.\nWe further find that reasoning models, as well as non-reasoning models prompted\nwith chain-of-thought (CoT), use context even less than non-reasoning models\nwithout CoT and fail to mitigate the lost-in-the-later effect. CoT prompting,\nin particular, results in lower recall and shorter responses, leading to\ndegraded contextual grounding. Based on these insights, we design prompt-based\nmethods to effectively leverage input context. A case study applying CoPE to\nsummarization demonstrates that CK-informed prompting improves factual\ngrounding and reduces hallucination.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faCoPE\u8bc4\u6d4b\u6846\u67b6\uff0c\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7406\u89e3\u4e0a\u4e0b\u6587\u65f6\u6613\u5ffd\u7565\u540e\u90e8\u4fe1\u606f\uff0c\u94fe\u5f0f\u601d\u8003\u4e0d\u4f46\u65e0\u6548\u53cd\u800c\u6709\u5bb3\u3002\u5408\u7406\u8bbe\u8ba1\u63d0\u793a\u8bcd\u80fd\u6539\u5584\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u51cf\u5c11\u5e7b\u89c9\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u5229\u7528\u53c2\u6570\u77e5\u8bc6\u548c\u8bed\u5883\u77e5\u8bc6\uff0c\u4f46\u4e24\u8005\u5982\u4f55\u88ab\u6574\u5408\u548c\u4f18\u5148\u7ea7\u5206\u914d\u5c1a\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7814\u7a76\uff0c\u5c24\u5176\u662f\u5728\u591a\u8bed\u8a00\u6761\u4ef6\u548c\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0b\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86CoPE\u8bc4\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408MultiWikiAtomic\u591a\u8bed\u8a00\u6570\u636e\u96c6\uff0c\u5b9a\u91cf\u5206\u6790\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u60c5\u5883\u77e5\u8bc6\uff08CK\uff09\u548c\u53c2\u6570\u77e5\u8bc6\uff08PK\uff09\u7684\u6574\u5408\u65b9\u5f0f\uff0c\u540c\u65f6\u8bbe\u8ba1\u6848\u4f8b\uff08\u5982\u6458\u8981\u4efb\u52a1\uff09\u5bf9\u63d0\u5347\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u5229\u7528\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u5b58\u5728\u660e\u663e\u7684\u4f4d\u7f6e\u4fe1\u606f\u504f\u5411\uff0c\u5bf9\u540e\u90e8\u4e0a\u4e0b\u6587\u5229\u7528\u4e0d\u8db3\uff08lost-in-the-later\u73b0\u8c61\uff09\uff0c\u4e14\u94fe\u5f0f\u601d\u8003\u63d0\u793a\u672a\u80fd\u7f13\u89e3\u8be5\u95ee\u9898\u3002\u901a\u8fc7CK\u5bfc\u5411\u7684\u63d0\u95ee\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e8b\u5b9e\u6027\u548c\u51cf\u5c11\u4e86\u5e7b\u89c9\u3002", "conclusion": "\u901a\u8fc7\u6784\u5efaCoPE\u8bc4\u6d4b\u6846\u67b6\uff0c\u8bba\u6587\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u201clost-in-the-later\u201d\u73b0\u8c61\uff0c\u5373\u6a21\u578b\u5bf9\u4e8e\u8bed\u5883\u4e2d\u8f83\u665a\u51fa\u73b0\u7684\u4fe1\u606f\u5bb9\u6613\u5ffd\u7565\u6216\u4f4e\u4f30\uff0c\u8868\u73b0\u51fa\u8f83\u5f3a\u7684\u4f4d\u7f6e\u6027\u504f\u5dee\uff0c\u5f71\u54cd\u4e86\u5176\u5bf9\u4e0a\u4e0b\u6587\u7684\u5229\u7528\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\u3002\u94fe\u5f0f\u601d\u8003\uff08CoT\uff09\u63d0\u793a\u53cd\u800c\u8fdb\u4e00\u6b65\u5f31\u5316\u4e86\u5bf9\u8bed\u5883\u7684\u5229\u7528\u3002\u57fa\u4e8e\u8fd9\u4e9b\u53d1\u73b0\uff0c\u8bba\u6587\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\uff0c\u66f4\u6709\u6548\u5730\u5229\u7528\u8f93\u5165\u8bed\u5883\u3002"}}
{"id": "2507.05981", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.05981", "abs": "https://arxiv.org/abs/2507.05981", "authors": ["Marc Oriol", "Quim Motger", "Jordi Marco", "Xavier Franch"], "title": "Multi-Agent Debate Strategies to Enhance Requirements Engineering with Large Language Models", "comment": null, "summary": "Context: Large Language Model (LLM) agents are becoming widely used for\nvarious Requirements Engineering (RE) tasks. Research on improving their\naccuracy mainly focuses on prompt engineering, model fine-tuning, and retrieval\naugmented generation. However, these methods often treat models as isolated\nblack boxes - relying on single-pass outputs without iterative refinement or\ncollaboration, limiting robustness and adaptability. Objective: We propose\nthat, just as human debates enhance accuracy and reduce bias in RE tasks by\nincorporating diverse perspectives, different LLM agents debating and\ncollaborating may achieve similar improvements. Our goal is to investigate\nwhether Multi-Agent Debate (MAD) strategies can enhance RE performance. Method:\nWe conducted a systematic study of existing MAD strategies across various\ndomains to identify their key characteristics. To assess their applicability in\nRE, we implemented and tested a preliminary MAD-based framework for RE\nclassification. Results: Our study identified and categorized several MAD\nstrategies, leading to a taxonomy outlining their core attributes. Our\npreliminary evaluation demonstrated the feasibility of applying MAD to RE\nclassification. Conclusions: MAD presents a promising approach for improving\nLLM accuracy in RE tasks. This study provides a foundational understanding of\nMAD strategies, offering insights for future research and refinements in RE\napplications.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u7d22\u591aLLM\u4ee3\u7406\u8fa9\u8bba\uff08MAD\uff09\u7b56\u7565\u5728\u9700\u6c42\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u5efa\u7acb\u5e76\u5b9e\u8bc1\u6d4b\u8bd5\u4e86\u76f8\u5173\u5206\u7c7b\u6846\u67b6\uff0c\u7ed3\u679c\u663e\u793aMAD\u6709\u52a9\u4e8e\u63d0\u9ad8\u4efb\u52a1\u51c6\u786e\u6027\uff0c\u4e3a\u4eca\u540e\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u65b9\u6cd5\u57fa\u7840\u3002", "motivation": "\u76ee\u524d\u7528\u4e8e\u9700\u6c42\u5de5\u7a0b\uff08RE\uff09\u4efb\u52a1\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63d0\u9ad8\u51c6\u786e\u7387\u7684\u65b9\u6cd5\u4e3b\u8981\u6709\u63d0\u793a\u5de5\u7a0b\u3001\u6a21\u578b\u5fae\u8c03\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3002\u8fd9\u4e9b\u65b9\u6cd5\u901a\u5e38\u628a\u6a21\u578b\u5f53\u4f5c\u5b64\u7acb\u7684\u9ed1\u76d2\u5904\u7406\uff0c\u4f9d\u8d56\u5355\u6b21\u8f93\u51fa\uff0c\u7f3a\u4e4f\u8fed\u4ee3\u4f18\u5316\u6216\u534f\u540c\uff0c\u5bfc\u81f4\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u6709\u9650\u3002\u4f5c\u8005\u8ba4\u4e3a\uff0c\u4eba\u7c7b\u7684\u8fa9\u8bba\u80fd\u591f\u901a\u8fc7\u591a\u6837\u5316\u89c2\u70b9\u63d0\u5347RE\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u548c\u964d\u4f4e\u504f\u89c1\uff0c\u56e0\u6b64\u5e0c\u671b\u9a8c\u8bc1\u591aLLM\u4ee3\u7406\u95f4\u8fa9\u8bba\u662f\u5426\u4e5f\u80fd\u5e26\u6765\u7c7b\u4f3c\u6548\u679c\u3002", "method": "\u672c\u7814\u7a76\u5bf9\u73b0\u6709\u591a\u4ee3\u7406\u8fa9\u8bba\uff08MAD\uff09\u7b56\u7565\u5728\u4e0d\u540c\u9886\u57df\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u68b3\u7406\uff0c\u603b\u7ed3\u5176\u4e3b\u8981\u7279\u5f81\uff0c\u5e76\u6784\u5efa\u4e86\u521d\u6b65\u7684\u57fa\u4e8eMAD\u7684RE\u4efb\u52a1\u5206\u7c7b\u6846\u67b6\uff0c\u8fdb\u884c\u5b9e\u8bc1\u6d4b\u8bd5\u3002", "result": "\u7814\u7a76\u5f52\u7eb3\u5e76\u5206\u7c7b\u4e86\u591a\u79cdMAD\u7b56\u7565\uff0c\u63d0\u51fa\u4e86\u76f8\u5173\u7684\u5c5e\u6027\u5206\u7c7b\u4f53\u7cfb\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5c06MAD\u65b9\u6cd5\u5e94\u7528\u4e8eRE\u4efb\u52a1\u5206\u7c7b\u662f\u53ef\u884c\u7684\u3002", "conclusion": "\u591a\u4ee3\u7406\u8fa9\u8bba\uff08MAD\uff09\u4e3a\u63d0\u5347LLM\u5728\u9700\u6c42\u5de5\u7a0b\u4efb\u52a1\u51c6\u786e\u5ea6\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u65b9\u6cd5\uff0c\u672c\u7814\u7a76\u4e3aMAD\u7b56\u7565\u5728\u8be5\u9886\u57df\u7684\u5e94\u7528\u548c\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.05443", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.05443", "abs": "https://arxiv.org/abs/2507.05443", "authors": ["Ashwin Rao", "Sze Yuh Nina Wang", "Kristina Lerman"], "title": "Gendered Divides in Online Discussions about Reproductive Rights", "comment": null, "summary": "The U.S. Supreme Court's 2022 ruling in Dobbs v. Jackson Women's Health\nOrganization marked a turning point in the national debate over reproductive\nrights. While the ideological divide over abortion is well documented, less is\nknown about how gender and local sociopolitical contexts interact to shape\npublic discourse. Drawing on nearly 10 million abortion-related posts on X\n(formerly Twitter) from users with inferred gender, ideology and location, we\nshow that gender significantly moderates abortion attitudes and emotional\nexpression, particularly in conservative regions, and independently of\nideology. This creates a gender gap in abortion attitudes that grows more\npronounced in conservative regions. The leak of the Dobbs draft opinion further\nintensified online engagement, disproportionately mobilizing pro-abortion women\nin areas where access was under threat. These findings reveal that abortion\ndiscourse is not only ideologically polarized but also deeply structured by\ngender and place, highlighting the central role of identity in shaping\npolitical expression during moments of institutional disruption.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790X\u5e73\u53f0\u8fd1\u5343\u4e07\u6761\u5815\u80ce\u76f8\u5173\u5e16\u5b50\uff0c\u63ed\u793a\u6027\u522b\u5728\u5815\u80ce\u6001\u5ea6\u53ca\u60c5\u611f\u8868\u8fbe\u4e2d\u7684\u8c03\u8282\u4f5c\u7528\uff0c\u5c24\u5176\u5728\u4fdd\u5b88\u5730\u533a\u4f7f\u6027\u522b\u5206\u6b67\u6269\u5927\uff0cDobbs\u88c1\u51b3\u6cc4\u9732\u66f4\u52a8\u5458\u4e86\u5973\u6027\u53c2\u4e0e\uff0c\u663e\u793a\u6027\u522b\u548c\u5730\u65b9\u7279\u5f81\u5728\u5815\u80ce\u4e89\u8bba\u4e0e\u653f\u6cbb\u8868\u8fbe\u4e2d\u7684\u6838\u5fc3\u89d2\u8272\u3002", "motivation": "\u6700\u9ad8\u6cd5\u96622022\u5e74\u5728Dobbs v. Jackson Women's Health Organization\u7684\u88c1\u51b3\u52a0\u5267\u4e86\u56f4\u7ed5\u5815\u80ce\u6743\u5229\u7684\u56fd\u5bb6\u4e89\u8bba\uff0c\u5b66\u754c\u5df2\u5173\u6ce8\u5230\u610f\u8bc6\u5f62\u6001\u5206\u6b67\uff0c\u4f46\u6027\u522b\u548c\u5730\u65b9\u793e\u4f1a\u653f\u6cbb\u80cc\u666f\u7684\u4ea4\u4e92\u5bf9\u5815\u80ce\u6001\u5ea6\u53ca\u60c5\u7eea\u8868\u8fbe\u7684\u5f71\u54cd\u4ecd\u4e86\u89e3\u6709\u9650\u3002", "method": "\u6536\u96c6\u5206\u6790\u8fd11000\u4e07\u6761\u4e0e\u5815\u80ce\u6709\u5173\u3001\u542b\u6709\u63a8\u65ad\u6027\u522b\u3001\u610f\u8bc6\u5f62\u6001\u548c\u5730\u7406\u4f4d\u7f6e\u4fe1\u606f\u7684X\uff08\u524dTwitter\uff09\u5e73\u53f0\u7528\u6237\u5e16\u5b50\uff0c\u8003\u5bdf\u6027\u522b\u3001\u610f\u8bc6\u5f62\u6001\u548c\u5730\u533a\u5982\u4f55\u5171\u540c\u5f71\u54cd\u516c\u4f17\u5173\u4e8e\u5815\u80ce\u7684\u6001\u5ea6\u53ca\u60c5\u7eea\u8868\u8fbe\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u6027\u522b\u5bf9\u5815\u80ce\u6001\u5ea6\u548c\u60c5\u611f\u8868\u8fbe\u5177\u6709\u663e\u8457\u8c03\u8282\u4f5c\u7528\uff0c\u8fd9\u79cd\u5f71\u54cd\u5728\u4fdd\u5b88\u5730\u533a\u5c24\u4e3a\u7a81\u51fa\u4e14\u72ec\u7acb\u4e8e\u610f\u8bc6\u5f62\u6001\uff0c\u5bfc\u81f4\u4fdd\u5b88\u5730\u533a\u5815\u80ce\u6001\u5ea6\u7684\u6027\u522b\u5dee\u8ddd\u6269\u5927\u3002Dobbs\u88c1\u51b3\u6cc4\u9732\u8fdb\u4e00\u6b65\u6fc0\u53d1\u4e86\u7f51\u4e0a\u8ba8\u8bba\uff0c\u5c24\u5176\u52a8\u5458\u4e86\u53d7\u5a01\u80c1\u5730\u533a\u7684\u652f\u6301\u5815\u80ce\u5973\u6027\u3002", "conclusion": "\u5815\u80ce\u76f8\u5173\u8bdd\u8bed\u4e0d\u4ec5\u5448\u73b0\u610f\u8bc6\u5f62\u6001\u4e24\u6781\u5206\u5316\uff0c\u8fd8\u53d7\u5230\u6027\u522b\u4e0e\u533a\u57df\u7684\u6df1\u523b\u7ed3\u6784\u6027\u5f71\u54cd\uff0c\u8eab\u4efd\u56e0\u7d20\u5728\u5236\u5ea6\u6027\u53d8\u52a8\u671f\u95f4\u5bf9\u653f\u6cbb\u8868\u8fbe\u6709\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2507.05995", "categories": ["cs.SE", "68Nxx", "D.2.0; D.2.8"], "pdf": "https://arxiv.org/pdf/2507.05995", "abs": "https://arxiv.org/abs/2507.05995", "authors": ["Pengzhou Chen", "Tao Chen"], "title": "PromiseTune: Unveiling Causally Promising and Explainable Configuration Tuning", "comment": "This paper has been accepted by ICSE26", "summary": "The high configurability of modern software systems has made configuration\ntuning a crucial step for assuring system performance, e.g., latency or\nthroughput. However, given the expensive measurements, large configuration\nspace, and rugged configuration landscape, existing tuners suffer\nineffectiveness due to the difficult balance of budget utilization between\nexploring uncertain regions (for escaping from local optima) and exploiting\nguidance of known good configurations (for fast convergence). The root cause is\nthat we lack knowledge of where the promising regions lay, which also causes\nchallenges in the explainability of the results.\n  In this paper, we propose PromiseTune that tunes configuration guided by\ncausally purified rules. PromiseTune is unique in the sense that we learn\nrules, which reflect certain regions in the configuration landscape, and purify\nthem with causal inference. The remaining rules serve as approximated\nreflections of the promising regions, bounding the tuning to emphasize these\nplaces in the landscape. This, as we demonstrate, can effectively mitigate the\nimpact of the exploration and exploitation trade-off. Those purified regions\ncan then be paired with the measured configurations to provide spatial\nexplainability at the landscape level. Comparing with 11 state-of-the-art\ntuners on 12 systems and varying budgets, we show that PromiseTune performs\nsignificantly better than the others with $42\\%$ superior rank to the overall\nsecond best while providing richer information to explain the hidden system\ncharacteristics.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86PromiseTune\u65b9\u6cd5\uff0c\u5229\u7528\u56e0\u679c\u89c4\u5219\u51c0\u5316\u6280\u672f\uff0c\u5728\u4fdd\u8bc1\u7cfb\u7edf\u6027\u80fd\u4f18\u5316\u7684\u540c\u65f6\uff0c\u63d0\u5347\u4e86\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u3002\u5b9e\u9a8c\u8bc1\u660ePromiseTune\u5728\u591a\u4e2a\u7cfb\u7edf\u4e0a\u5747\u4f18\u4e8e\u5df2\u6709\u8c03\u4f18\u5668\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u7cfb\u7edf\u9ad8\u5ea6\u53ef\u914d\u7f6e\uff0c\u4f7f\u5f97\u914d\u7f6e\u8c03\u4f18\u6210\u4e3a\u4fdd\u969c\u7cfb\u7edf\u6027\u80fd\uff08\u5982\u5ef6\u8fdf\u3001\u541e\u5410\u91cf\uff09\u7684\u5173\u952e\u6b65\u9aa4\u3002\u4f46\u5de8\u5927\u7684\u914d\u7f6e\u7a7a\u95f4\u548c\u6d4b\u91cf\u6210\u672c\u4ee5\u53ca\u590d\u6742\u7684\u914d\u7f6e\u5730\u5f62\uff0c\u5bfc\u81f4\u73b0\u6709\u8c03\u4f18\u65b9\u6cd5\u5728\u63a2\u7d22\u548c\u5229\u7528\u4e4b\u95f4\u96be\u4ee5\u5e73\u8861\uff0c\u4e14\u7ed3\u679c\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51faPromiseTune\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u89c4\u5219\u5e76\u7ed3\u5408\u56e0\u679c\u63a8\u65ad\u8fdb\u884c\u89c4\u5219\u51c0\u5316\uff0c\u8bc6\u522b\u5e76\u805a\u7126\u4e8e\u914d\u7f6e\u7a7a\u95f4\u4e2d\u6709\u524d\u666f\u7684\u533a\u57df\u8fdb\u884c\u8c03\u4f18\u3002\u51c0\u5316\u540e\u7684\u89c4\u5219\u7528\u4f5c\u6709\u524d\u666f\u533a\u57df\u7684\u8fd1\u4f3c\u53cd\u6620\uff0c\u8c03\u4f18\u8fc7\u7a0b\u4f18\u5148\u8003\u5bdf\u8fd9\u4e9b\u533a\u57df\uff0c\u5e76\u80fd\u591f\u63d0\u4f9b\u7a7a\u95f4\u5c42\u9762\u7684\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u4e0e11\u79cd\u4e3b\u6d41\u8c03\u4f18\u5668\u572812\u4e2a\u7cfb\u7edf\u3001\u4e0d\u540c\u9884\u7b97\u4e0b\u8fdb\u884c\u6bd4\u8f83\uff0cPromiseTune\u7684\u6548\u679c\u663e\u8457\u66f4\u597d\uff0c\u603b\u4f53\u4f18\u4e8e\u7b2c\u4e8c\u540d42%\uff0c\u540c\u65f6\u80fd\u66f4\u597d\u5730\u89e3\u91ca\u7cfb\u7edf\u7684\u9690\u85cf\u7279\u6027\u3002", "conclusion": "PromiseTune\u901a\u8fc7\u56e0\u679c\u89c4\u5219\u6307\u5bfc\u914d\u7f6e\u8c03\u4f18\uff0c\u6709\u6548\u6539\u5584\u4e86\u63a2\u7d22\u4e0e\u5229\u7528\u7684\u77db\u76fe\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u8c03\u4f18\u6548\u679c\uff0c\u8fd8\u589e\u5f3a\u4e86\u5bf9\u7cfb\u7edf\u7279\u6027\u7684\u89e3\u91ca\u80fd\u529b\u3002"}}
{"id": "2507.05444", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05444", "abs": "https://arxiv.org/abs/2507.05444", "authors": ["Sana Kang", "Myeongseok Gwon", "Su Young Kwon", "Jaewook Lee", "Andrew Lan", "Bhiksha Raj", "Rita Singh"], "title": "PhoniTale: Phonologically Grounded Mnemonic Generation for Typologically Distant Language Pairs", "comment": null, "summary": "Vocabulary acquisition poses a significant challenge for second-language (L2)\nlearners, especially when learning typologically distant languages such as\nEnglish and Korean, where phonological and structural mismatches complicate\nvocabulary learning. Recently, large language models (LLMs) have been used to\ngenerate keyword mnemonics by leveraging similar keywords from a learner's\nfirst language (L1) to aid in acquiring L2 vocabulary. However, most of this\nresearch has focused on native English speakers learning other languages,\nrather than the reverse. In this paper, we present PhoniTale, a novel\ncross-lingual mnemonic generation system that retrieves L1 keyword sequence\nbased on phonological similarity and uses LLMs to generate mnemonics. We\nevaluate PhoniTale using both automated metrics and human evaluations,\ncomparing its output to mnemonics created by humans and by previous automated\napproaches. To assess practical effectiveness, we also conduct a short-term\nrecall test measuring mnemonic helpfulness. Our findings show that PhoniTale\nperforms comparably to human-authored mnemonics. We also highlight key areas\nfor future improvement in mnemonic quality and methodology.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u58f0\u97f5\u76f8\u4f3c\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8de8\u8bed\u79cd\u52a9\u8bb0\u6cd5\u81ea\u52a8\u751f\u6210\u7cfb\u7edfPhoniTale\uff0c\u5e76\u901a\u8fc7\u591a\u79cd\u8bc4\u6d4b\u624b\u6bb5\u8bc1\u5b9e\u5176\u6548\u679c\u4e0e\u4eba\u5de5\u52a9\u8bb0\u6cd5\u76f8\u5f53\uff0c\u4e3a\u4e8c\u8bed\u8bcd\u6c47\u4e60\u5f97\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u65b0\u5de5\u5177\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u7b2c\u4e8c\u8bed\u8a00\u5b66\u4e60\u8005\u5728\u4e60\u5f97\u8bcd\u6c47\u65f6\uff0c\u5c24\u5176\u662f\u5728\u5b66\u4e60\u5982\u82f1\u8bed\u548c\u97e9\u8bed\u7b49\u7c7b\u578b\u8ddd\u79bb\u8f83\u8fdc\u7684\u8bed\u8a00\u65f6\uff0c\u4f1a\u9762\u4e34\u58f0\u97f5\u548c\u7ed3\u6784\u4e0a\u7684\u969c\u788d\u3002\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u901a\u8fc7\u6bcd\u8bed\u5173\u952e\u8bcd\u8f85\u52a9\u8bb0\u5fc6\u6765\u4fc3\u8fdb\u8bcd\u6c47\u4e60\u5f97\u662f\u4e2a\u65b0\u5174\u65b9\u5411\uff0c\u4f46\u591a\u6570\u5df2\u6709\u7814\u7a76\u5173\u6ce8\u7684\u662f\u82f1\u8bed\u6bcd\u8bed\u8005\u5b66\u4e60\u4ed6\u8bed\uff0c\u800c\u4e0d\u662f\u53cd\u5411\u60c5\u5f62\u3002", "method": "\u63d0\u51fa\u4e86PhoniTale\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5229\u7528\u58f0\u97f5\u76f8\u4f3c\u6027\u5728\u5b66\u4e60\u8005\u6bcd\u8bed\u4e2d\u68c0\u7d22\u5173\u952e\u8bcd\u5e8f\u5217\uff0c\u5e76\u7ed3\u5408LLMs\u751f\u6210\u52a9\u8bb0\u6cd5\u3002\u901a\u8fc7\u81ea\u52a8\u5316\u6307\u6807\u548c\u4eba\u5de5\u8bc4\u4f30\u5c06PhoniTale\u4e0e\u4eba\u5de5\u751f\u6210\u548c\u4ee5\u5f80\u81ea\u52a8\u5316\u65b9\u6cd5\u7684\u52a9\u8bb0\u6cd5\u8fdb\u884c\u5bf9\u6bd4\uff0c\u540c\u65f6\u8bbe\u8ba1\u4e86\u77ed\u671f\u56de\u5fc6\u6d4b\u8bd5\u8bc4\u4f30\u5176\u5b9e\u9645\u6548\u679c\u3002", "result": "PhoniTale\u7cfb\u7edf\u5728\u52a9\u8bb0\u6cd5\u6548\u679c\u4e0a\u4e0e\u4eba\u7c7b\u4f5c\u8005\u7684\u7ed3\u679c\u6301\u5e73\uff0c\u663e\u793a\u51fa\u826f\u597d\u7684\u5e94\u7528\u524d\u666f\u3002", "conclusion": "PhoniTale\u7cfb\u7edf\u5728\u5e2e\u52a9\u4e8c\u8bed\u5b66\u4e60\u8005\u4e60\u5f97\u8bcd\u6c47\u65b9\u9762\u6709\u6548\uff0c\u4e14\u5176\u81ea\u52a8\u751f\u6210\u7684\u52a9\u8bb0\u6cd5\u4e0e\u4eba\u5de5\u751f\u6210\u7ed3\u679c\u76f8\u5f53\u3002\u7814\u7a76\u540c\u65f6\u6307\u51fa\u4e86\u672a\u6765\u5728\u52a9\u8bb0\u6cd5\u8d28\u91cf\u4e0e\u65b9\u6cd5\u6539\u8fdb\u4e0a\u7684\u5173\u952e\u65b9\u5411\u3002"}}
{"id": "2507.06014", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.06014", "abs": "https://arxiv.org/abs/2507.06014", "authors": ["Tim Puhlf\u00fcr\u00df", "Julia Butzke", "Walid Maalej"], "title": "Model Cards Revisited: Bridging the Gap Between Theory and Practice for Ethical AI Requirements", "comment": "Accepted for publication at the 33rd IEEE International Requirements\n  Engineering 2025 conference", "summary": "Model cards are the primary documentation framework for developers of\nartificial intelligence (AI) models to communicate critical information to\ntheir users. Those users are often developers themselves looking for relevant\ndocumentation to ensure that their AI systems comply with the ethical\nrequirements of existing laws, guidelines, and standards. Recent studies\nindicate inadequate model documentation practices, suggesting a gap between AI\nrequirements and current practices in model documentation. To understand this\ngap and provide actionable guidance to bridge it, we conducted a thematic\nanalysis of 26 guidelines on ethics and AI, three AI documentation frameworks,\nthree quantitative studies of model cards, and ten actual model cards. We\nidentified a total of 43 ethical requirements relevant to model documentation\nand organized them into a taxonomy featuring four themes and twelve sub-themes\nrepresenting ethical principles. Our findings indicate that model developers\npredominantly emphasize model capabilities and reliability in the documentation\nwhile overlooking other ethical aspects, such as explainability, user autonomy,\nand fairness. This underscores the need for enhanced support in documenting\nethical AI considerations. Our taxonomy serves as a foundation for a revised\nmodel card framework that holistically addresses ethical AI requirements.", "AI": {"tldr": "AI\u6a21\u578b\u6587\u6863\u666e\u904d\u5ffd\u89c6\u4f26\u7406\u8981\u6c42\uff0c\u8bba\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u5206\u6790\u5f52\u7eb3\u51fa43\u6761\u4f26\u7406\u9700\u6c42\uff0c\u5efa\u7acb\u4e86\u6539\u8fdb\u6587\u6863\u7684\u4f26\u7406\u5206\u7c7b\u6cd5\uff0c\u5e76\u547c\u5401\u5f00\u53d1\u8005\u589e\u52a0\u5bf9\u53ef\u89e3\u91ca\u6027\u3001\u516c\u5e73\u6027\u7b49\u65b9\u9762\u7684\u91cd\u89c6\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u6587\u6863\uff08Model cards\uff09\u672a\u80fd\u5145\u5206\u6ee1\u8db3\u9053\u5fb7\u4e0e\u5408\u89c4\u6027\u9700\u6c42\uff0c\u5f00\u53d1\u8005\u548c\u4f7f\u7528\u8005\u96be\u4ee5\u83b7\u5f97\u5145\u5206\u7684\u9053\u5fb7\u4fe1\u606f\uff0c\u5bfc\u81f4AI\u7cfb\u7edf\u96be\u4ee5\u786e\u4fdd\u7b26\u5408\u76f8\u5173\u6cd5\u5f8b\u3001\u6807\u51c6\u3002\u9700\u8981\u660e\u786eAI\u9053\u5fb7\u8981\u6c42\u4e0e\u73b0\u6709\u6587\u6863\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "method": "\u4f5c\u8005\u5bf926\u4efdAI\u4f26\u7406\u6307\u5357\u30013\u5957AI\u6587\u6863\u6846\u67b6\u30013\u7bc7Model cards\u5b9a\u91cf\u7814\u7a76\u548c10\u4efd\u5b9e\u9645Model cards\u8fdb\u884c\u4e86\u4e3b\u9898\u5206\u6790\uff0c\u4ece\u4e2d\u5f52\u7eb3\u51fa\u4e0e\u6587\u6863\u76f8\u5173\u768443\u9879\u4f26\u7406\u8981\u6c42\uff0c\u5e76\u5efa\u7acb\u4e86\u5305\u542b4\u4e2a\u4e3b\u9898\u548c12\u4e2a\u5b50\u4e3b\u9898\u7684\u4f26\u7406\u539f\u5219\u5206\u7c7b\u6cd5\u3002", "result": "\u8bba\u6587\u53d1\u73b0\u5f00\u53d1\u8005\u5728Model cards\u6587\u6863\u4e2d\u4e3b\u8981\u5173\u6ce8\u6a21\u578b\u80fd\u529b\u548c\u53ef\u9760\u6027\uff0c\u5e38\u5e38\u5ffd\u7565\u4e86\u5177\u4f53\u7684\u4f26\u7406\u8981\u6c42\uff0c\u5982\u53ef\u89e3\u91ca\u6027\u3001\u7528\u6237\u81ea\u4e3b\u6027\u548c\u516c\u5e73\u6027\u7b49\u3002\u4f5c\u8005\u636e\u6b64\u63d0\u51fa\u4e86\u4e00\u4e2a\u66f4\u5168\u9762\u53cd\u6620\u4f26\u7406\u8981\u6c42\u7684\u65b0\u5206\u7c7b\u6cd5\uff0c\u4e3a\u6539\u8fdbModel cards\u6587\u6863\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "conclusion": "\u5f53\u524dAI\u6a21\u578b\u6587\u6863\u5c1a\u672a\u5145\u5206\u5305\u62ec\u6240\u6709\u4f26\u7406\u7ef4\u5ea6\u3002\u4f5c\u8005\u63d0\u51fa\u7684\u4f26\u7406\u5206\u7c7b\u6cd5\u4e3a\u6a21\u578b\u6587\u6863\u7ed3\u6784\u7684\u6539\u8fdb\u548c\u66f4\u597d\u5730\u6ee1\u8db3\u4f26\u7406\u8981\u6c42\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5f3a\u8c03\u9700\u8981\u5728Model cards\u4e2d\u52a0\u5f3a\u5bf9\u4f26\u7406\u95ee\u9898\u7684\u652f\u6301\u3002"}}
{"id": "2507.05448", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05448", "abs": "https://arxiv.org/abs/2507.05448", "authors": ["Martin Schuele"], "title": "On the Semantics of Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) such as ChatGPT demonstrated the potential to\nreplicate human language abilities through technology, ranging from text\ngeneration to engaging in conversations. However, it remains controversial to\nwhat extent these systems truly understand language. We examine this issue by\nnarrowing the question down to the semantics of LLMs at the word and sentence\nlevel. By examining the inner workings of LLMs and their generated\nrepresentation of language and by drawing on classical semantic theories by\nFrege and Russell, we get a more nuanced picture of the potential semantic\ncapabilities of LLMs.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7406\u8bba\u4e0e\u5b9e\u8bc1\u5206\u6790\uff0c\u8ba8\u8bba\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bcd\u53e5\u8bed\u4e49\u4e0a\u7684\u7406\u89e3\u6c34\u5e73\uff0c\u5e76\u6307\u51fa\u5176\u867d\u7136\u5177\u5907\u4e00\u5b9a\u7684\u8bed\u4e49\u5904\u7406\u80fd\u529b\uff0c\u4f46\u8ddd\u79bb\u771f\u6b63\u7684\u8bed\u8a00\u7406\u89e3\u4ecd\u6709\u5dee\u8ddd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5982ChatGPT\u5728\u4eff\u771f\u4eba\u7c7b\u8bed\u8a00\u80fd\u529b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u662f\u5426\u771f\u6b63\u7406\u89e3\u8bed\u8a00\u4ecd\u7136\u5b58\u5728\u4e89\u8bae\u3002\u672c\u6587\u5e0c\u671b\u901a\u8fc7\u6df1\u5165\u7814\u7a76LLM\u5728\u8bcd\u6c47\u548c\u53e5\u5b50\u5c42\u9762\u7684\u8bed\u4e49\u80fd\u529b\uff0c\u5398\u6e05\u5176\u201c\u7406\u89e3\u201d\u7a0b\u5ea6\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5206\u6790LLM\u7684\u5185\u90e8\u673a\u5236\u53ca\u5176\u751f\u6210\u7684\u8bed\u8a00\u8868\u5f81\uff0c\u5e76\u7ed3\u5408Frege\u548cRussell\u7b49\u7ecf\u5178\u8bed\u4e49\u7406\u8bba\uff0c\u5bf9\u6bd4LLM\u8bed\u4e49\u80fd\u529b\u4e0e\u4f20\u7edf\u8bed\u8a00\u5b66\u7406\u8bba\u8fdb\u884c\u6df1\u5165\u63a2\u8ba8\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86LLM\u5728\u751f\u6210\u8bed\u8a00\u548c\u8868\u793a\u8bed\u4e49\u65f6\u7684\u4e00\u4e9b\u6f5c\u5728\u80fd\u529b\uff0c\u540c\u65f6\u901a\u8fc7\u4e0e\u7ecf\u5178\u8bed\u4e49\u7406\u8bba\u7684\u5bf9\u6bd4\uff0c\u53d1\u73b0LLM\u5728\u67d0\u4e9b\u65b9\u9762\u8868\u73b0\u51fa\u63a5\u8fd1\u4f20\u7edf\u8bed\u4e49\u7406\u89e3\u7684\u7279\u6027\uff0c\u4f46\u5728\u201c\u771f\u6b63\u7406\u89e3\u201d\u8bed\u8a00\u65b9\u9762\u4ecd\u5b58\u5728\u4e00\u5b9a\u5c40\u9650\u3002", "conclusion": "LLM\u5728\u8bcd\u6c47\u548c\u53e5\u5b50\u5c42\u9762\u4e0a\u5c55\u73b0\u51fa\u590d\u6742\u7684\u8bed\u4e49\u8868\u5f81\u80fd\u529b\uff0c\u4f46\u5c1a\u672a\u5b8c\u5168\u8fbe\u5230\u4eba\u7c7b\u5bf9\u8bed\u8a00\u201c\u771f\u6b63\u7406\u89e3\u201d\u7684\u6807\u51c6\u3002\u8be5\u7814\u7a76\u4e3a\u8ba4\u77e5LLM\u7684\u8bed\u4e49\u80fd\u529b\u63d0\u4f9b\u4e86\u66f4\u7ec6\u81f4\u7684\u89c6\u89d2\u3002"}}
{"id": "2507.05455", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05455", "abs": "https://arxiv.org/abs/2507.05455", "authors": ["Ashima Suvarna", "Christina Chance", "Hamid Palangi", "Sophie Hao", "Thomas Hartvigsen", "Saadia Gabriel"], "title": "ModelCitizens:Representing Community Voices in Online Safety", "comment": null, "summary": "Automatic toxic language detection is critical for creating safe, inclusive\nonline spaces. However, it is a highly subjective task, with perceptions of\ntoxic language shaped by community norms and lived experience. Existing\ntoxicity detection models are typically trained on annotations that collapse\ndiverse annotator perspectives into a single ground truth, erasing important\ncontext-specific notions of toxicity such as reclaimed language. To address\nthis, we introduce MODELCITIZENS, a dataset of 6.8K social media posts and 40K\ntoxicity annotations across diverse identity groups. To capture the role of\nconversational context on toxicity, typical of social media posts, we augment\nMODELCITIZENS posts with LLM-generated conversational scenarios.\nState-of-the-art toxicity detection tools (e.g. OpenAI Moderation API,\nGPT-o4-mini) underperform on MODELCITIZENS, with further degradation on\ncontext-augmented posts. Finally, we release LLAMACITIZEN-8B and\nGEMMACITIZEN-12B, LLaMA- and Gemma-based models finetuned on MODELCITIZENS,\nwhich outperform GPT-o4-mini by 5.5% on in-distribution evaluations. Our\nfindings highlight the importance of community-informed annotation and modeling\nfor inclusive content moderation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u591a\u8eab\u4efd\u3001\u591a\u8bed\u5883\u7684\u6bd2\u6027\u68c0\u6d4b\u6570\u636e\u96c6\uff0c\u8bc1\u660e\u4e3b\u6d41\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e0a\u8868\u73b0\u6709\u9650\uff0c\u5e76\u901a\u8fc7\u5fae\u8c03\u65b0\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\uff0c\u5f3a\u8c03\u4e86\u793e\u533a\u8bed\u5883\u548c\u5dee\u5f02\u5316\u6807\u6ce8\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6709\u6bd2\u8bed\u8a00\u68c0\u6d4b\u6a21\u578b\u5927\u591a\u5c06\u4e0d\u540c\u6ce8\u91ca\u8005\u7684\u89c2\u70b9\u5408\u5e76\u4e3a\u5355\u4e00\u6807\u51c6\uff0c\u5ffd\u89c6\u4e86\u4e0d\u540c\u793e\u533a\u548c\u8eab\u4efd\u7fa4\u4f53\u5bf9\u6709\u6bd2\u8bed\u8a00\u7684\u591a\u6837\u7406\u89e3\uff0c\u7279\u522b\u662f\u5728\u793e\u4ea4\u5a92\u4f53\u73af\u5883\u4e0b\uff0c\u8bed\u5883\u548c\u7fa4\u4f53\u4f53\u9a8c\u5bf9\u6bd2\u6027\u5224\u5b9a\u6709\u91cd\u8981\u5f71\u54cd\u3002\u8be5\u7814\u7a76\u5e0c\u671b\u89e3\u51b3\u4e3b\u6d41\u6570\u636e\u96c6\u548c\u6a21\u578b\u5728\u8bed\u5883\u9002\u5e94\u6027\u548c\u5305\u5bb9\u6027\u4e0a\u7684\u5c40\u9650\u3002", "method": "\u8be5\u7814\u7a76\u6784\u5efa\u4e86MODELCITIZENS\u6570\u636e\u96c6\uff0c\u5305\u542b6800\u6761\u793e\u4ea4\u5a92\u4f53\u5e16\u5b50\u548c4\u4e07\u6761\u8de8\u591a\u5143\u8eab\u4efd\u7fa4\u4f53\u7684\u6bd2\u6027\u6807\u6ce8\uff0c\u5e76\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u5bf9\u8bdd\u8bed\u5883\u589e\u5f3a\u539f\u59cb\u5e16\u5b50\u3002\u4f5c\u8005\u8fd8\u57fa\u4e8eMODELCITIZENS\u5fae\u8c03\u4e86LLaMA\u548cGemma\u6a21\u578b\uff0c\u5206\u522b\u53d1\u5e03\u4e86LLAMACITIZEN-8B\u548cGEMMACITIZEN-12B\u3002", "result": "\u4e3b\u6d41\u6bd2\u6027\u68c0\u6d4b\u5de5\u5177\uff08\u5982OpenAI Moderation API\uff0cGPT-o4-mini\uff09\u5728MODELCITIZENS\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u8f83\u5dee\uff0c\u5e76\u4e14\u5728\u52a0\u5165\u5bf9\u8bdd\u8bed\u5883\u540e\u8868\u73b0\u8fdb\u4e00\u6b65\u4e0b\u964d\u3002\u4f5c\u8005\u8bad\u7ec3\u7684LLAMACITIZEN-8B\u548cGEMMACITIZEN-12B\u6a21\u578b\u5728\u5206\u5e03\u5185\u8bc4\u4f30\u4e2d\u6bd4GPT-o4-mini\u9ad8\u51fa5.5%\u3002", "conclusion": "\u793e\u533a\u77e5\u60c5\u7684\u6807\u6ce8\u548c\u9488\u5bf9\u6027\u5efa\u6a21\u5bf9\u4e8e\u5b9e\u73b0\u66f4\u5177\u5305\u5bb9\u6027\u7684\u5185\u5bb9\u5ba1\u6838\u81f3\u5173\u91cd\u8981\uff0c\u901a\u7528\u6a21\u578b\u5728\u591a\u5143\u8bed\u5883\u548c\u4eba\u7fa4\u4e0b\u6548\u679c\u6709\u9650\u3002\u901a\u8fc7\u4e30\u5bcc\u591a\u5143\u548c\u6709\u4e0a\u4e0b\u6587\u7684\u4fe1\u606f\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u6bd2\u6027\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027\u3002"}}
{"id": "2507.05517", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05517", "abs": "https://arxiv.org/abs/2507.05517", "authors": ["Jean-Philippe Corbeil", "Asma Ben Abacha", "George Michalopoulos", "Phillip Swazinna", "Miguel Del-Agua", "Jerome Tremblay", "Akila Jeeson Daniel", "Cari Bader", "Kevin Cho", "Pooja Krishnan", "Nathan Bodenstab", "Thomas Lin", "Wenxuan Teng", "Francois Beaulieu", "Paul Vozila"], "title": "Empowering Healthcare Practitioners with Language Models: Structuring Speech Transcripts in Two Real-World Clinical Applications", "comment": null, "summary": "Large language models (LLMs) such as GPT-4o and o1 have demonstrated strong\nperformance on clinical natural language processing (NLP) tasks across multiple\nmedical benchmarks. Nonetheless, two high-impact NLP tasks - structured tabular\nreporting from nurse dictations and medical order extraction from\ndoctor-patient consultations - remain underexplored due to data scarcity and\nsensitivity, despite active industry efforts. Practical solutions to these\nreal-world clinical tasks can significantly reduce the documentation burden on\nhealthcare providers, allowing greater focus on patient care. In this paper, we\ninvestigate these two challenging tasks using private and open-source clinical\ndatasets, evaluating the performance of both open- and closed-weight LLMs, and\nanalyzing their respective strengths and limitations. Furthermore, we propose\nan agentic pipeline for generating realistic, non-sensitive nurse dictations,\nenabling structured extraction of clinical observations. To support further\nresearch in both areas, we release SYNUR and SIMORD, the first open-source\ndatasets for nurse observation extraction and medical order extraction.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u62a4\u58eb\u53e3\u8ff0\u7ed3\u6784\u5316\u62a5\u544a\u548c\u533b\u7597\u533b\u5631\u62bd\u53d6\u4e24\u5927\u533b\u7597NLP\u4efb\u52a1\uff0c\u63d0\u51fa\u4ee3\u7406\u6d41\u7a0b\u751f\u6210\u6570\u636e\uff0c\u5b9e\u6d4b\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u5e03\u4e86\u91cd\u8981\u7684\u5f00\u6e90\u6570\u636e\u96c6\uff0c\u4e3a\u9886\u57df\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u5e26\u6765\u91cd\u8981\u63a8\u52a8\u3002", "motivation": "\u62a4\u58eb\u53e3\u8ff0\u751f\u6210\u7ed3\u6784\u5316\u8868\u683c\u548c\u533b\u751f-\u60a3\u8005\u4f1a\u8bca\u4e2d\u533b\u7597\u533b\u5631\u62bd\u53d6\u8fd9\u4e24\u9879\u9ad8\u5f71\u54cd\u529b\u4efb\u52a1\u56e0\u6570\u636e\u7a00\u7f3a\u548c\u654f\u611f\u59cb\u7ec8\u672a\u5f97\u5230\u5145\u5206\u63a2\u7a76\u3002\u6709\u6548\u89e3\u51b3\u8fd9\u4e9b\u5b9e\u9645\u95ee\u9898\uff0c\u53ef\u51cf\u5c11\u533b\u62a4\u6587\u4e66\u8d1f\u62c5\uff0c\u8ba9\u62a4\u7406\u4eba\u5458\u66f4\u4e13\u6ce8\u4e8e\u75c5\u60a3\u62a4\u7406\u3002", "method": "\u9488\u5bf9\u771f\u5b9e\u4e16\u754c\u7684\u4e34\u5e8aNLP\u4efb\u52a1\uff0c\u8bc4\u4f30\u4e86\u5f00\u6e90\u548c\u79c1\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u62a4\u58eb\u53e3\u8ff0\u7ed3\u6784\u5316\u62a5\u544a\u548c\u533b\u751f\u533b\u5631\u62bd\u53d6\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u751f\u6210\u73b0\u5b9e\u3001\u975e\u654f\u611f\u62a4\u58eb\u53e3\u8ff0\u7684\u4ee3\u7406\u6027\u6d41\u7a0b\u3002", "result": "\u63d0\u51fa\u4e86\u521b\u65b0\u7684\u4ee3\u7406\u6d41\u7a0b\u7528\u4e8e\u751f\u6210\u62a4\u58eb\u53e3\u8ff0\uff0c\u9a8c\u8bc1\u4e86\u4e0d\u540cLLMs\u5728\u4e24\u5927\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u5e76\u9996\u6b21\u516c\u5f00\u4e86\u76f8\u5173\u7684\u5f00\u6e90\u6570\u636e\u96c6SYNUR\u548cSIMORD\uff0c\u4fc3\u8fdb\u793e\u533a\u540e\u7eed\u7814\u7a76\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u548c\u5f00\u653e\u6570\u636e\u96c6\u80fd\u591f\u6709\u6548\u63a8\u52a8\u62a4\u58eb\u53e3\u8ff0\u7ed3\u6784\u5316\u62a5\u544a\u548c\u533b\u7597\u533b\u5631\u62bd\u53d6\u4e24\u5927\u533b\u7597NLP\u4efb\u52a1\u7684\u7814\u7a76\uff0c\u5e76\u6709\u671b\u7f13\u89e3\u533b\u7597\u6587\u6863\u5de5\u4f5c\u8d1f\u62c5\u3002"}}
{"id": "2507.05557", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05557", "abs": "https://arxiv.org/abs/2507.05557", "authors": ["Alex ZH Dou", "Zhongwei Wan", "Dongfei Cui", "Xin Wang", "Jing Xiong", "Haokun Lin", "Chaofan Tao", "Shen Yan", "Mi Zhang"], "title": "Enhancing Test-Time Scaling of Large Language Models with Hierarchical Retrieval-Augmented MCTS", "comment": "Technical Report", "summary": "Test-time scaling has emerged as a promising paradigm in language modeling,\nleveraging additional computational resources at inference time to enhance\nmodel performance. In this work, we introduce R2-LLMs, a novel and versatile\nhierarchical retrieval-augmented reasoning framework designed to improve\ntest-time scaling in large language models (LLMs) without requiring\ndistillation from more advanced models to obtain chain-of-thought (CoT)\ntraining data. R2-LLMs enhances inference-time generalization by integrating\ndual-level retrieval-based in-context learning: (1) At the coarse level, our\napproach extracts abstract templates from complex reasoning problems and\nretrieves similar problem-answer pairs to facilitate high-level in-context\nlearning; (2) At the fine level, during Monte Carlo Tree Search (MCTS), R2-LLMs\nefficiently retrieves analogous intermediate solution steps from reference\nmathematical problem datasets, refining step-wise reasoning with the aid of a\nprocess reward model (PRM) for scoring. R2-LLMs is a robust hierarchical\nreasoning-augmentation method that enhances in-context-level reasoning while\nseamlessly integrating with step-level tree search methods. Utilizing PRM, it\nrefines both candidate generation and decision-making for improved reasoning\naccuracy. Empirical evaluations on the MATH500, GSM8K, and OlympiadBench-TO\ndatasets achieve substantial relative improvement with an increase of up to 16%\nusing LLaMA-3.1-8B compared to the baselines, showcasing the effectiveness of\nour approach in complex reasoning tasks.", "AI": {"tldr": "\u63d0\u51faR2-LLMs\uff0c\u4e00\u79cd\u65e0\u987b\u6a21\u578b\u84b8\u998f\u7684\u5206\u5c42\u68c0\u7d22\u589e\u5f3a\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u7c97\u7ec6\u4e24\u7ea7\u68c0\u7d22\u548c\u63a8\u7406\u589e\u5f3a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u6a21\u578b\u5728\u6570\u5b66\u53ca\u590d\u6742\u95ee\u9898\u4e0a\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6548\u679c\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u548c\u590d\u6742\u6570\u5b66\u95ee\u9898\u4e0a\uff0c\u901a\u5e38\u9700\u8981\u66f4\u591a\u6837\u7684\u6570\u636e\u6216\u66f4\u5f3a\u6a21\u578b\u7684\u77e5\u8bc6\u84b8\u998f\u6765\u63d0\u5347\u63a8\u7406\u80fd\u529b\uff0c\u63a8\u7406\u589e\u5f3a\u4e0e\u6d4b\u8bd5\u65f6\u6269\u5c55\u5c1a\u672a\u5145\u5206\u6316\u6398\u9ad8\u6548\u5229\u7528\u68c0\u7d22\u7684\u4fe1\u606f\u3002", "method": "\u63d0\u51faR2-LLMs\uff0c\u4e00\u4e2a\u5206\u5c42\u7684\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u63a8\u7406\u7684\u63a8\u7406\u6846\u67b6\u3002\u5177\u4f53\u505a\u6cd5\uff1a1\uff09\u5728\u7c97\u7c92\u5ea6\u5c42\u9762\uff0c\u4ece\u590d\u6742\u95ee\u9898\u4e2d\u62bd\u8c61\u6a21\u677f\uff0c\u68c0\u7d22\u7c7b\u4f3c\u7684\u95ee\u9898-\u7b54\u6848\u5bf9\u4ee5\u5b9e\u73b0\u9ad8\u5c42\u6b21\u7684in-context\u5b66\u4e60\uff1b2\uff09\u5728\u7ec6\u7c92\u5ea6\u5c42\u9762\uff0cMCTS\u641c\u7d22\u8fc7\u7a0b\u4e2d\u4ece\u53c2\u8003\u6570\u636e\u96c6\u4e2d\u68c0\u7d22\u7c7b\u4f3c\u7684\u4e2d\u95f4\u8fc7\u7a0b\u6b65\u9aa4\uff0c\u5e76\u901a\u8fc7\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRM\uff09\u8bc4\u5206\uff0c\u63d0\u5347\u9010\u6b65\u63a8\u7406\u3002\u8be5\u65b9\u6cd5\u53ef\u65e0\u7f1d\u4e0e\u6811\u641c\u7d22\u7ed3\u5408\uff0c\u5e76\u5229\u7528PRM\u4f18\u5316\u5019\u9009\u751f\u6210\u548c\u51b3\u7b56\u8fc7\u7a0b\u3002", "result": "\u5728MATH500\u3001GSM8K\u548cOlympiadBench-TO\u7b49\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528LLaMA-3.1-8B\u6a21\u578b\uff0cR2-LLMs\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u76f8\u8f83\u4e8e\u57fa\u7ebf\u65b9\u6848\u53d6\u5f97\u4e86\u9ad8\u8fbe16%\u7684\u76f8\u5bf9\u63d0\u5347\u3002", "conclusion": "R2-LLMs\u4f5c\u4e3a\u4e00\u79cd\u5206\u5c42\u7684\u68c0\u7d22\u589e\u5f3a\u63a8\u7406\u65b9\u6cd5\uff0c\u65e0\u9700\u9ad8\u9636\u6a21\u578b\u7684\u84b8\u998f\uff0c\u5373\u53ef\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6cdb\u5316\u548c\u63a8\u7406\u8868\u73b0\u3002"}}
{"id": "2507.05598", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05598", "abs": "https://arxiv.org/abs/2507.05598", "authors": ["Sihyun Park"], "title": "Self-Review Framework for Enhancing Instruction Following Capability of LLM", "comment": null, "summary": "Various techniques have been proposed to improve large language models (LLMs)\nadherence to formatting and instruction constraints. One of the most effective\napproaches involves utilizing high-quality data generated by powerful models.\nHowever, such models often fail to fully comply with complex instructions in a\nsingle generation. To address this limitation, iterative revision methods have\nbeen introduced. Nevertheless, as the number of data points and revision\niterations increases, the associated monetary costs grow significantly. As a\nresource-efficient alternative, methods have been proposed that leverage\nhigh-performance evaluation tools to compensate for the limited self-evaluation\ncapabilities of open-source LLMs. However, these approaches often lead to a\ndegradation in output quality due to excessive revision. To overcome these\nchallenges, we propose Re5, a self-evaluation and revision framework designed\nto enhance instruction-following performance while preserving the quality of\nthe generated content. Re5 extracts task and constraint components from user\ninstructions, performs structural evaluations to prevent error accumulation,\nand applies fine-grained constraint-specific content evaluations followed by\nselective revisions. This process ensures precise and quality-preserving\nimprovements. The final high-quality outputs are used for alignment tuning,\nenabling long-term alignment improvements through a data-centric iterative\nrefinement loop. Experimental results demonstrate that Re5 achieves\ninstruction-following performance comparable to models trained on data\ngenerated by GPT-4o-mini, a high-performance model, even with a small amount of\ndata while maintaining response quality with a 64.24%-win rate over the\nnon-revised initial responses. These results validate Re5 as an efficient and\neffective solution for enhancing instruction adherence with minimal external\nsupervision.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u9075\u5faa\u590d\u6742\u6307\u4ee4\u96be\u3001\u4fee\u8ba2\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86Re5\u81ea\u8bc4\u4e0e\u4fee\u8ba2\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6b65\u7ed3\u6784\u5316\u81ea\u8bc4\u548c\u9009\u62e9\u6027\u5185\u5bb9\u4fee\u8ba2\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u4fdd\u6301\u9ad8\u8f93\u51fa\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6307\u4ee4\u9075\u5faa\u8868\u73b0\uff0c\u4e14\u8d44\u6e90\u9ad8\u6548\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u9075\u5faa\u683c\u5f0f\u548c\u6307\u4ee4\u7ea6\u675f\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4e14\u9ad8\u8d28\u91cf\u751f\u6210\u6570\u636e\u4f9d\u8d56\u5f3a\u5927\u6a21\u578b\u4f46\u6210\u672c\u9ad8\uff0c\u8fed\u4ee3\u4fee\u8ba2\u65b9\u6cd5\u867d\u7136\u6709\u6548\u4f46\u662f\u91d1\u94b1\u548c\u6548\u7387\u6210\u672c\u5f88\u5927\u3002\u73b0\u6709\u5229\u7528\u5916\u90e8\u8bc4\u4ef7\u5de5\u5177\u7684\u66ff\u4ee3\u65b9\u6cd5\u53c8\u5bb9\u6613\u5bfc\u81f4\u5185\u5bb9\u8d28\u91cf\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRe5\u7684\u81ea\u8bc4\u4e0e\u4fee\u8ba2\u6846\u67b6\u3002Re5\u4ece\u7528\u6237\u6307\u4ee4\u4e2d\u63d0\u53d6\u4efb\u52a1\u53ca\u7ea6\u675f\u90e8\u5206\uff0c\u8fdb\u884c\u7ed3\u6784\u5316\u8bc4\u4f30\u4ee5\u9632\u6b62\u9519\u8bef\u7d2f\u79ef\uff0c\u5e76\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7684\u7ea6\u675f\u76f8\u5173\u5185\u5bb9\u8bc4\u4f30\u4e0e\u9009\u62e9\u6027\u4fee\u8ba2\uff0c\u4ee5\u4fdd\u8bc1\u751f\u6210\u5185\u5bb9\u7684\u9ad8\u8d28\u91cf\u3002\u6700\u7ec8\u8f93\u51fa\u8fd8\u7528\u4e8e\u6a21\u578b\u5bf9\u9f50\u5fae\u8c03\uff0c\u4ee5\u5b9e\u73b0\u6570\u636e\u9a71\u52a8\u7684\u9010\u6b65\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRe5\u80fd\u591f\u5728\u4ec5\u4f7f\u7528\u5c11\u91cf\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u5176\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u53ef\u5ab2\u7f8e\u57fa\u4e8e\u66f4\u9ad8\u6027\u80fd\u6a21\u578b\uff08\u5982GPT-4o-mini\uff09\u751f\u6210\u6570\u636e\u8bad\u7ec3\u51fa\u7684\u6a21\u578b\uff0c\u540c\u65f6\u5728\u56de\u590d\u8d28\u91cf\u4e0a\uff0c\u76f8\u6bd4\u672a\u4fee\u8ba2\u7684\u521d\u59cb\u8f93\u51fa\u670964.24%\u7684\u80dc\u7387\u3002", "conclusion": "Re5\u80fd\u9ad8\u6548\u63d0\u5347\u5927\u6a21\u578b\u5bf9\u6307\u4ee4\u7684\u9075\u5faa\u5ea6\uff0c\u5e76\u5728\u8f83\u4f4e\u7684\u5916\u90e8\u76d1\u7763\u548c\u8d44\u6e90\u6210\u672c\u4e0b\uff0c\u5b9e\u73b0\u4e86\u4f18\u8d28\u5185\u5bb9\u751f\u6210\u548c\u6301\u7eed\u5bf9\u9f50\u4f18\u5316\u3002"}}
{"id": "2507.05617", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05617", "abs": "https://arxiv.org/abs/2507.05617", "authors": ["Mingzhe Li", "Jing Xiang", "Qishen Zhang", "Kaiyang Wan", "Xiuying Chen"], "title": "Flipping Knowledge Distillation: Leveraging Small Models' Expertise to Enhance LLMs in Text Matching", "comment": "Accepted by ACL 2025 main", "summary": "Knowledge distillation typically involves transferring knowledge from a Large\nLanguage Model (LLM) to a Smaller Language Model (SLM). However, in tasks such\nas text matching, fine-tuned smaller models often yield more effective\ndomain-specific representations, as they focus on optimizing the similarity of\ninput pairs. To leverage both the specialized strengths of small models and the\nrich semantic understanding of LLMs, we introduce a flipped knowledge\ndistillation paradigm, where LLM learns from SLM. Specifically, we address the\narchitectural gap between decoder-only LLMs and smaller encoder-based models by\nreinterpreting LLMs in an encoder-decoder manner using LoRA. The encoder\ngenerates compressed representations, while the decoder maps them to the output\nspace. During training, the encoder produces representations and their\nsimilarities, which are then aligned with the similarity scores produced by the\nteacher, using our proposed Margin-aware Contrastive Learning (MCL) approach.\nThe MCL ensures accurate similarity for both positive and negative pairs, and\nadaptively handles the internal differences within positive and negative\nsamples. Our paradigm requires only a reasonably good-performing SLM, allowing\nthe LLM to achieve improved performance. Experiments on financial and\nhealthcare benchmarks, as well as real-world applications, confirm its\neffectiveness, and the model has been fully deployed in an online environment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5927\u6a21\u578b\u5411\u5c0f\u6a21\u578b\u5b66\u4e60\u7684\u53cd\u5411\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u9002\u914d\u548c\u65b0\u578b\u5bf9\u6bd4\u635f\u5931\uff0c\u6709\u6548\u63d0\u5347\u5927\u6a21\u578b\u5728\u9886\u57df\u7279\u5b9a\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u5df2\u9a8c\u8bc1\u5176\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u5728\u6587\u672c\u5339\u914d\u7b49\u4efb\u52a1\u4e2d\uff0c\u7ecf\u8fc7\u5fae\u8c03\u7684\u5c0f\u6a21\u578b\u5f80\u5f80\u80fd\u83b7\u5f97\u66f4\u6709\u6548\u7684\u9886\u57df\u76f8\u5173\u8868\u793a\uff0c\u5c3d\u7ba1\u76ee\u524d\u77e5\u8bc6\u84b8\u998f\u5927\u591a\u662f\u4ece\u5927\u6a21\u578b\u5411\u5c0f\u6a21\u578b\u4f20\u9012\u77e5\u8bc6\u3002\u8bba\u6587\u5c1d\u8bd5\u7ed3\u5408\u5c0f\u6a21\u578b\u7684\u7279\u957f\u548c\u5927\u6a21\u578b\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u201c\u53cd\u5411\u77e5\u8bc6\u84b8\u998f\u201d\u8303\u5f0f\uff0c\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5411\u5c0f\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\u5b66\u4e60\u3002\u91c7\u7528LoRA\u91cd\u65b0\u89e3\u91ca\u5927\u6a21\u578b\u4e3a\u7f16\u7801\u5668-\u89e3\u7801\u5668\u7ed3\u6784\uff0c\u8bbe\u8ba1Margin-aware Contrastive Learning\uff08MCL\uff09\u65b9\u6cd5\u5bf9\u6b63\u8d1f\u6837\u672c\u7684\u76f8\u4f3c\u5ea6\u8fdb\u884c\u7cbe\u7ec6\u5316\u5bf9\u9f50\u3002", "result": "\u5728\u91d1\u878d\u548c\u533b\u7597\u7b49\u57fa\u51c6\u6570\u636e\u96c6\u53ca\u771f\u5b9e\u573a\u666f\u4e2d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b0\u8303\u5f0f\u7684\u6709\u6548\u6027\uff0c\u5e76\u5df2\u5b9e\u73b0\u7ebf\u4e0a\u90e8\u7f72\u3002", "conclusion": "\u53cd\u5411\u77e5\u8bc6\u84b8\u998f\u53ef\u4ee5\u517c\u987e\u5927\u6a21\u578b\u548c\u5c0f\u6a21\u578b\u7684\u4f18\u70b9\uff0c\u63d0\u5347\u4e86LLM\u5728\u7279\u5b9a\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u65b9\u6cd5\u5df2\u5728\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\u53d6\u5f97\u6210\u6548\u3002"}}
{"id": "2507.05633", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.05633", "abs": "https://arxiv.org/abs/2507.05633", "authors": ["Yiqiao Jin", "Kartik Sharma", "Vineeth Rakesh", "Yingtong Dou", "Menghai Pan", "Mahashweta Das", "Srijan Kumar"], "title": "SARA: Selective and Adaptive Retrieval-augmented Generation with Context Compression", "comment": "20 pages", "summary": "Retrieval-augmented Generation (RAG) extends large language models (LLMs)\nwith external knowledge but faces key challenges: restricted effective context\nlength and redundancy in retrieved documents. Pure compression-based approaches\nreduce input size but often discard fine-grained details essential for factual\naccuracy. We propose SARA, a unified RAG framework that balances local\nprecision and global knowledge coverage under tight context budgets. SARA\ncombines natural-language text snippets with semantic compression vectors to\njointly enhance context efficiency and answer correctness. It represents\ncontexts at two complementary levels: 1) fine-grained natural-language spans\nthat preserve critical entities and numerical values, and 2) compact,\ninterpretable vectors that summarize high-level semantics. An iterative\nevidence-selection module employs the compression vectors for dynamic reranking\nof contexts. Across 9 datasets and 5 open-source LLMs spanning 3 model families\n(Mistral, Llama, and Gemma), SARA consistently improves answer relevance\n(+17.71), answer correctness (+13.72), and semantic similarity (+15.53),\ndemonstrating the importance of integrating textual and compressed\nrepresentations for robust, context-efficient RAG.", "AI": {"tldr": "SARA\u662f\u4e00\u79cd\u7ed3\u5408\u6587\u672c\u4e0e\u8bed\u4e49\u538b\u7f29\u5411\u91cf\u7684\u65b0\u578bRAG\u65b9\u6cd5\uff0c\u5728\u6709\u9650\u4e0a\u4e0b\u6587\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u7b54\u6848\u51c6\u786e\u6027\u4e0e\u76f8\u5173\u6027\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5f00\u6e90\u5927\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\u5728\u5229\u7528\u5916\u90e8\u77e5\u8bc6\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u65f6\uff0c\u5f80\u5f80\u53d7\u9650\u4e8e\u6709\u6548\u4e0a\u4e0b\u6587\u957f\u5ea6\u6709\u9650\u4ee5\u53ca\u68c0\u7d22\u6587\u6863\u5197\u4f59\u95ee\u9898\u3002\u7b80\u5355\u4f9d\u9760\u538b\u7f29\u867d\u7136\u80fd\u51cf\u5c11\u8f93\u5165\u5927\u5c0f\uff0c\u4f46\u4f1a\u4e22\u5931\u4e8b\u5b9e\u6027\u5f3a\u7684\u7ec6\u7c92\u5ea6\u7ec6\u8282\uff0c\u5f71\u54cd\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faSARA\uff0c\u4e00\u4e2a\u7edf\u4e00\u7684RAG\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u7247\u6bb5\u548c\u8bed\u4e49\u538b\u7f29\u5411\u91cf\uff0c\u4f7f\u5f97\u5728\u6709\u9650\u7684\u4e0a\u4e0b\u6587\u9884\u7b97\u4e0b\uff0c\u80fd\u591f\u517c\u987e\u672c\u5730\u7cbe\u5ea6\u548c\u5168\u5c40\u77e5\u8bc6\u8986\u76d6\u3002SARA\u5c06\u4e0a\u4e0b\u6587\u8868\u793a\u4e3a\u7ec6\u7c92\u5ea6\u6587\u672c\u7247\u6bb5\u4e0e\u9ad8\u5c42\u8bed\u4e49\u538b\u7f29\u5411\u91cf\uff0c\u5e76\u91c7\u7528\u8fed\u4ee3\u8bc1\u636e\u9009\u62e9\u6a21\u5757\u8fdb\u884c\u52a8\u6001\u4e0a\u4e0b\u6587\u91cd\u6392\u3002", "result": "\u57289\u4e2a\u6570\u636e\u96c6\u30015\u4e2a\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff08\u6db5\u76d6Mistral\u3001Llama\u3001Gemma\u4e09\u5927\u6a21\u578b\u5bb6\u65cf\uff09\u4e2d\uff0cSARA\u5728\u7b54\u6848\u76f8\u5173\u6027\u3001\u6b63\u786e\u6027\u548c\u8bed\u4e49\u76f8\u4f3c\u6027\u4e0a\u5206\u522b\u63d0\u9ad8\u4e86+17.71\u3001+13.72\u3001+15.53\uff0c\u6709\u6548\u63d0\u5347\u4e86RAG\u7cfb\u7edf\u5728\u6709\u9650\u4e0a\u4e0b\u6587\u4e0b\u7684\u8868\u73b0\u3002", "conclusion": "SARA\u901a\u8fc7\u6574\u5408\u6587\u672c\u4e0e\u538b\u7f29\u8868\u793a\uff0c\u6709\u6548\u63d0\u5347\u4e86RAG\u7684\u4e0a\u4e0b\u6587\u5229\u7528\u6548\u7387\u548c\u7b54\u6848\u51c6\u786e\u6027\uff0c\u5c55\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u63a8\u5e7f\u80fd\u529b\u3002"}}
{"id": "2507.05639", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05639", "abs": "https://arxiv.org/abs/2507.05639", "authors": ["Haoxin Wang", "Xianhan Peng", "Xucheng Huang", "Yizhe Huang", "Ming Gong", "Chenghan Yang", "Yang Liu", "Ling Jiang"], "title": "ECom-Bench: Can LLM Agent Resolve Real-World E-commerce Customer Support Issues?", "comment": null, "summary": "In this paper, we introduce ECom-Bench, the first benchmark framework for\nevaluating LLM agent with multimodal capabilities in the e-commerce customer\nsupport domain. ECom-Bench features dynamic user simulation based on persona\ninformation collected from real e-commerce customer interactions and a\nrealistic task dataset derived from authentic e-commerce dialogues. These\ntasks, covering a wide range of business scenarios, are designed to reflect\nreal-world complexities, making ECom-Bench highly challenging. For instance,\neven advanced models like GPT-4o achieve only a 10-20% pass^3 metric in our\nbenchmark, highlighting the substantial difficulties posed by complex\ne-commerce scenarios. Upon publication, the code and data will be open-sourced\nto facilitate further research and development in this domain.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7535\u5546\u5ba2\u6237\u652f\u6301\u9886\u57df\u9996\u4e2a\u591a\u6a21\u6001LLM\u8bc4\u6d4b\u57fa\u51c6ECom-Bench\uff0c\u7ed3\u5408\u771f\u5b9e\u6570\u636e\u548c\u590d\u6742\u4efb\u52a1\uff0c\u6311\u6218\u6027\u6781\u9ad8\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u884c\u4e1a\u53d1\u5c55\uff0c\u540e\u7eed\u5c06\u5f00\u6e90\u3002", "motivation": "\u5f53\u524d\u7535\u5546\u5ba2\u6237\u652f\u6301\u573a\u666f\u7684\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08LLM agent\uff09\u5c1a\u7f3a\u4e4f\u4e13\u95e8\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u8bc4\u6d4b\u57fa\u51c6\u3002\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u6709\u6548\u8861\u91cf\u6a21\u578b\u5728\u771f\u5b9e\u7535\u5546\u73af\u5883\u7684\u7efc\u5408\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aECom-Bench\u7684\u8bc4\u6d4b\u6846\u67b6\uff0c\u5176\u4e2d\u5305\u542b\u57fa\u4e8e\u771f\u5b9e\u7535\u5546\u5bf9\u8bdd\u6570\u636e\u6784\u5efa\u7684\u7528\u6237\u753b\u50cf\u52a8\u6001\u6a21\u62df\u5668\u53ca\u4efb\u52a1\u96c6\u5408\u3002\u6db5\u76d6\u591a\u6837\u4e14\u590d\u6742\u7684\u7535\u5546\u4e1a\u52a1\u573a\u666f\uff0c\u5e76\u7528\u771f\u5b9e\u7528\u6237\u6570\u636e\u4e0e\u5bf9\u8bdd\u4f5c\u4e3a\u4efb\u52a1\u6837\u672c\u3002", "result": "\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u5927\u6a21\u578b\uff08\u5982GPT-4o\uff09\u5728\u8be5\u57fa\u51c6\u4e0a\u7684\u901a\u8fc7\u7387\uff08pass^3 metric\uff09\u4ec5\u4e3a10%-20%\uff0c\u8bc1\u660e\u6b64\u6846\u67b6\u6781\u5177\u6311\u6218\u6027\u3001\u5207\u5408\u5b9e\u9645\u573a\u666f\u3002", "conclusion": "ECom-Bench\u586b\u8865\u4e86\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u7535\u5546\u5ba2\u6237\u652f\u6301\u9886\u57df\u8bc4\u6d4b\u7684\u7a7a\u767d\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u8be5\u9886\u57df\u65b9\u6cd5\u7684\u8fdb\u6b65\u3002\u76f8\u5173\u4ee3\u7801\u4e0e\u6570\u636e\u5c06\u5f00\u6e90\uff0c\u4fbf\u4e8e\u8fdb\u4e00\u6b65\u7684\u5b66\u672f\u7814\u7a76\u548c\u6280\u672f\u5f00\u53d1\u3002"}}
{"id": "2507.05686", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05686", "abs": "https://arxiv.org/abs/2507.05686", "authors": ["SeungWon Ji", "Jungyup Lee", "Jemin Kim", "Sang Park", "SeungJae Lee"], "title": "Smoothie-Qwen: Post-Hoc Smoothing to Reduce Language Bias in Multilingual LLMs", "comment": null, "summary": "Multilingual large language models (LLMs) often exhibit language confusion, a\ntendency to generate responses in a dominant language irrespective of the\nprompt's language. To address this, we propose Smoothie-Qwen, a lightweight,\npost-hoc method that mitigates language bias without retraining. This technique\nselectively adjusts token-level output probabilities to effectively suppress\nundesired language generation. Applied to the Qwen model, our method reduces\nunintended Chinese output by over 95% while preserving task accuracy on\nmultilingual benchmarks. This work provides a practical and efficient solution\nfor enhancing the language controllability of LLMs, making them more reliable\nfor global applications.", "AI": {"tldr": "Smoothie-Qwen\u662f\u4e00\u79cd\u65e0\u9700\u91cd\u8bad\u7ec3\u7684\u540e\u5904\u7406\u65b9\u6cd5\uff0c\u80fd\u663e\u8457\u51cf\u5c11\u6a21\u578b\u751f\u6210\u7684\u8bed\u8a00\u504f\u5dee\uff0c\u63d0\u5347\u5728\u591a\u8bed\u8a00\u4efb\u52a1\u4e0b\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u591a\u8bed\u8a00\u5927\u6a21\u578b\u5bb9\u6613\u51fa\u73b0\u8bed\u8a00\u6df7\u6dc6\u73b0\u8c61\uff0c\u5373\u65e0\u89c6\u63d0\u793a\u8bed\u7684\u8bed\u8a00\u800c\u503e\u5411\u4e8e\u7528\u4e3b\u5bfc\u8bed\u8a00\u751f\u6210\u56de\u7b54\u3002\u8fd9\u5bfc\u81f4\u5728\u591a\u8bed\u8a00\u573a\u666f\u4e0b\u6a21\u578b\u7684\u5b9e\u9645\u5e94\u7528\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u63d0\u9ad8\u4e0d\u540c\u8bed\u8a00\u7684\u53ef\u63a7\u6027\u3002", "method": "\u63d0\u51faSmoothie-Qwen\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u8f7b\u91cf\u5316\u7684\u540e\u5904\u7406\u6280\u672f\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9009\u62e9\u6027\u8c03\u6574token\u7ea7\u8f93\u51fa\u6982\u7387\uff0c\u6709\u6548\u6291\u5236\u975e\u671f\u671b\u8bed\u8a00\u7684\u751f\u6210\u3002", "result": "\u5728Qwen\u6a21\u578b\u4e0a\u5e94\u7528\u8be5\u65b9\u6cd5\u540e\uff0c\u51cf\u5c11\u4e8695%\u4ee5\u4e0a\u7684\u975e\u671f\u671b\u4e2d\u6587\u8f93\u51fa\uff0c\u5e76\u4e14\u5728\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u4fdd\u6301\u4e86\u4efb\u52a1\u51c6\u786e\u5ea6\u3002", "conclusion": "Smoothie-Qwen\u65b9\u6cd5\u53ef\u5927\u5e45\u5ea6\u63d0\u5347\u5927\u6a21\u578b\u7684\u8bed\u8a00\u53ef\u63a7\u6027\uff0c\u9002\u7528\u4e8e\u5168\u7403\u591a\u8bed\u8a00\u5e94\u7528\u573a\u666f\uff0c\u5e76\u4e0d\u5f71\u54cd\u6a21\u578b\u4efb\u52a1\u8868\u73b0\u3002"}}
{"id": "2507.05707", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.05707", "abs": "https://arxiv.org/abs/2507.05707", "authors": ["Weihua Du", "Pranjal Aggarwal", "Sean Welleck", "Yiming Yang"], "title": "Agentic-R1: Distilled Dual-Strategy Reasoning", "comment": "Preprint. 15 pages. Project available at\n  https://github.com/StigLidu/DualDistill", "summary": "Current long chain-of-thought (long-CoT) models excel at mathematical\nreasoning but rely on slow and error-prone natural language traces.\nTool-augmented agents address arithmetic via code execution, but often falter\non complex logical tasks. We introduce a fine-tuning framework, DualDistill,\nthat distills complementary reasoning strategies from multiple teachers into a\nunified student model. Using this approach, we train Agentic-R1, which\ndynamically selects the optimal strategy for each query, invoking tools for\narithmetic and algorithmic problems, and using text-based reasoning for\nabstract ones. Our method improves accuracy across a range of tasks, including\nboth computation-intensive and standard benchmarks, demonstrating the\neffectiveness of multi-strategy distillation in achieving robust and efficient\nreasoning. Our project is available at https://github.com/StigLidu/DualDistill", "AI": {"tldr": "DualDistill\u6846\u67b6\u878d\u5408\u591a\u79cd\u63a8\u7406\u7b56\u7565\uff0c\u8bad\u7ec3\u51fa\u80fd\u52a8\u6001\u9009\u53d6\u63a8\u7406\u65b9\u5f0f\u7684Agentic-R1\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u957f\u94fe\u6761\u63a8\u7406\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u4f9d\u8d56\u81ea\u7136\u8bed\u8a00\u63a8\u5bfc\u8fc7\u7a0b\uff0c\u901f\u5ea6\u6162\u4e14\u6613\u51fa\u9519\uff1b\u800c\u5de5\u5177\u589e\u5f3a\u7684\u667a\u80fd\u4f53\u867d\u7136\u53ef\u4ee5\u901a\u8fc7\u4ee3\u7801\u6267\u884c\u89e3\u51b3\u7b97\u6570\u95ee\u9898\uff0c\u4f46\u9762\u5bf9\u590d\u6742\u903b\u8f91\u4efb\u52a1\u65f6\u5e38\u5e38\u5931\u6548\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u6574\u5408\u591a\u79cd\u63a8\u7406\u65b9\u5f0f\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u5347\u6574\u4f53\u63a8\u7406\u80fd\u529b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDualDistill\u7684\u5fae\u8c03\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u4ece\u591a\u4e2a\u6559\u5e08\u6a21\u578b\u63d0\u53d6\u4e92\u8865\u7684\u63a8\u7406\u7b56\u7565\uff0c\u878d\u5408\u5230\u4e00\u4e2a\u7edf\u4e00\u7684\u5b66\u751f\u6a21\u578b\u4e2d\u3002\u6700\u7ec8\u8bad\u7ec3\u5f97\u5230Agentic-R1\u6a21\u578b\uff0c\u80fd\u591f\u9488\u5bf9\u4e0d\u540c\u7c7b\u578b\u7684\u95ee\u9898\u52a8\u6001\u9009\u62e9\u6700\u4f73\u63a8\u7406\u65b9\u5f0f\uff0c\u5305\u62ec\u8c03\u7528\u5de5\u5177\u5904\u7406\u7b97\u672f\u548c\u7b97\u6cd5\u95ee\u9898\uff0c\u4ee5\u53ca\u4f7f\u7528\u6587\u672c\u63a8\u7406\u5904\u7406\u62bd\u8c61\u95ee\u9898\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0d\u4ec5\u5728\u8ba1\u7b97\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u63d0\u5347\uff0c\u5728\u6807\u51c6\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u540c\u6837\u8868\u73b0\u4f18\u5f02\uff0c\u6709\u6548\u9a8c\u8bc1\u4e86\u591a\u7b56\u7565\u84b8\u998f\u65b9\u6848\u5728\u589e\u5f3a\u63a8\u7406\u9c81\u68d2\u6027\u548c\u6548\u7387\u65b9\u9762\u7684\u4ef7\u503c\u3002", "conclusion": "DualDistill\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u6a21\u578b\u5728\u591a\u79cd\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca\u590d\u6742\u903b\u8f91\u548c\u7b97\u6cd5\u8ba1\u7b97\u7684\u95ee\u9898\u4e0a\uff0c\u901a\u8fc7\u878d\u5408\u591a\u79cd\u63a8\u7406\u7b56\u7565\uff0c\u63d0\u9ad8\u4e86\u63a8\u7406\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2507.05713", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05713", "abs": "https://arxiv.org/abs/2507.05713", "authors": ["Fedor Chernogorskii", "Sergei Averkiev", "Liliya Kudraleeva", "Zaven Martirosian", "Maria Tikhonova", "Valentin Malykh", "Alena Fenogenova"], "title": "DRAGON: Dynamic RAG Benchmark On News", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) is a widely adopted approach for\nimproving the factuality of large language models (LLMs) by incorporating\nexternal knowledge at inference time. Although there exist multiple RAG\nbenchmarks for English, evaluation resources for other languages, including\nRussian, remain scarce and static, failing to capture the dynamic nature of\nreal-world deployments.\n  In this work, we present DRAGON (Dynamic RAG Benchmark On News), the first\ndynamic benchmark for evaluating RAG systems in Russian on a changing news\ncorpora. DRAGON is built upon a regularly updated corpus of Russian news and\npublic documents and supports comprehensive evaluation of both the retriever\nand generator components. Question generation is performed automatically with\nthe use of Knowledge Graph constructed from the corpus and enables the\nextraction of four core question types aligned with distinct subgraph patterns.\nWe release a complete evaluation framework comprising the pipeline for\nautomatic question generation, evaluation scripts, which are potentially\nreusable for other languages and multilingual settings, and benchmark data. We\nalso launch a public leaderboard to encourage community participation and\ncomparison.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9996\u4e2a\u57fa\u4e8e\u4fc4\u6587\u65b0\u95fb\u8bed\u6599\u3001\u81ea\u52a8\u52a8\u6001\u66f4\u65b0\u7684\u95ee\u9898\u751f\u6210\u4e0e\u8bc4\u6d4b\u4f53\u7cfbDRAGON\uff0c\u516c\u5f00\u8bc4\u6d4b\u5de5\u5177\u548c\u6392\u884c\u699c\uff0c\u63a8\u52a8RAG\u5728\u975e\u82f1\u6587\u52a8\u6001\u73af\u5883\u4e0b\u7684\u6807\u51c6\u5316\u7814\u7a76\u3002", "motivation": "\u73b0\u6709RAG\u57fa\u51c6\u591a\u96c6\u4e2d\u4e8e\u82f1\u6587\uff0c\u5176\u4ed6\u8bed\u8a00\uff08\u5982\u4fc4\u8bed\uff09\u76f8\u5173\u8bc4\u6d4b\u8d44\u6e90\u7a00\u7f3a\u4e14\u9759\u6001\uff0c\u65e0\u6cd5\u53cd\u6620\u5b9e\u9645\u5e94\u7528\u4e2d\u77e5\u8bc6\u548c\u8bed\u6599\u52a8\u6001\u53d8\u5316\u7684\u573a\u666f\uff0c\u56e0\u6b64\u4e9f\u9700\u66f4\u8d34\u8fd1\u771f\u5b9e\u52a8\u6001\u73af\u5883\u7684\u4fc4\u6587RAG\u8bc4\u6d4b\u8d44\u6e90\u3002", "method": "DRAGON\u57fa\u4e8e\u5b9a\u671f\u66f4\u65b0\u7684\u4fc4\u6587\u65b0\u95fb\u548c\u516c\u5171\u6587\u6863\u8bed\u6599\uff0c\u91c7\u7528\u77e5\u8bc6\u56fe\u8c31\u81ea\u52a8\u751f\u6210\u591a\u79cd\u7c7b\u578b\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6d41\u7a0b\u5bf9RAG\u7684\u68c0\u7d22\u548c\u751f\u6210\u7ec4\u4ef6\u8fdb\u884c\u5168\u9762\u8bc4\u6d4b\uff0c\u5e76\u63d0\u4f9b\u4e86\u81ea\u52a8\u95ee\u9898\u751f\u6210\u7ba1\u9053\u548c\u8bc4\u6d4b\u811a\u672c\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u4fc4\u8bed\u65b0\u95fb\u9886\u57df\u52a8\u6001RAG\u8bc4\u6d4b\u57fa\u51c6DRAGON\uff0c\u5e76\u53d1\u5e03\u4e86\u5b8c\u6574\u7684\u8bc4\u6d4b\u5957\u4ef6\u548c\u52a8\u6001\u6392\u884c\u699c\uff0c\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u3001\u53ef\u6269\u5c55\u7684\u591a\u8bed\u8a00RAG\u8bc4\u6d4b\u5de5\u5177\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86DRAGON\uff0c\u8fd9\u662f\u9996\u4e2a\u9488\u5bf9\u4fc4\u6587\u65b0\u95fb\u8bed\u6599\u5b9e\u73b0\u52a8\u6001\u8bc4\u6d4b\u7684RAG\u7cfb\u7edf\u57fa\u51c6\u3002\u8be5\u57fa\u51c6\u4e3a\u5916\u90e8\u77e5\u8bc6\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u5728\u4fc4\u8bed\u73af\u5883\u4e0b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u3001\u52a8\u6001\u7684\u8bc4\u6d4b\u8d44\u6e90\u3002\u6846\u67b6\u53ca\u6570\u636e\u96c6\u5df2\u516c\u5f00\uff0c\u5e76\u5efa\u7acb\u4e86\u6392\u884c\u699c\u9f13\u52b1\u793e\u533a\u53c2\u4e0e\u3002"}}
{"id": "2507.05714", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.05714", "abs": "https://arxiv.org/abs/2507.05714", "authors": ["YiHan Jiao", "ZheHao Tan", "Dan Yang", "DuoLin Sun", "Jie Feng", "Jian Wang", "Peng Wei"], "title": "HIRAG: Hierarchical-Thought Instruction-Tuning Retrieval-Augmented Generation", "comment": null, "summary": "Retrieval-augmented generation (RAG) has become a fundamental paradigm for\naddressing the challenges faced by large language models in handling real-time\ninformation and domain-specific problems. Traditional RAG systems primarily\nrely on the in-context learning (ICL) capabilities of the large language model\nitself. Still, in-depth research on the specific capabilities needed by the RAG\ngeneration model is lacking, leading to challenges with inconsistent document\nquality and retrieval system imperfections. Even the limited studies that\nfine-tune RAG generative models often \\textit{lack a granular focus on RAG\ntask} or \\textit{a deeper utilization of chain-of-thought processes}. To\naddress this, we propose that RAG models should possess three progressively\nhierarchical abilities (1) Filtering: the ability to select relevant\ninformation; (2) Combination: the ability to combine semantic information\nacross paragraphs; and (3) RAG-specific reasoning: the ability to further\nprocess external knowledge using internal knowledge. Thus, we introduce our new\nRAG instruction fine-tuning method, Hierarchical-Thought Instruction-Tuning\nRetrieval-Augmented Generation (HIRAG) incorporates a \"think before answering\"\nstrategy. This method enhances the model's open-book examination capability by\nutilizing multi-level progressive chain-of-thought. Experiments show that the\nHIRAG training strategy significantly improves the model's performance on\ndatasets such as RGB, PopQA, MuSiQue, HotpotQA, and PubmedQA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5206\u5c42\u601d\u7ef4\u6307\u4ee4\u5fae\u8c03\uff08HIRAG\uff09RAG\u65b9\u6cd5\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0fChain-of-Thought\u63d0\u5347RAG\u751f\u6210\u8d28\u91cf\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684RAG\u7cfb\u7edf\u5728\u63d0\u5347\u751f\u6210\u6a21\u578b\u5904\u7406\u5b9e\u65f6\u4fe1\u606f\u548c\u9886\u57df\u95ee\u9898\u80fd\u529b\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u7ec6\u81f4\u5173\u6ce8\u4e8eRAG\u4efb\u52a1\u548c\u6df1\u5165\u5229\u7528Chain-of-Thought\u601d\u7ef4\u6d41\u7a0b\u65b9\u9762\u7814\u7a76\u8f83\u5c11\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684RAG\u6a21\u578b\u6307\u4ee4\u5fae\u8c03\u65b9\u6cd5\u2014\u2014\u5206\u5c42\u601d\u7ef4\u6307\u4ee4\u5fae\u8c03RAG\uff08HIRAG\uff09\u3002\u8be5\u65b9\u6cd5\u5c06\u201c\u5148\u601d\u8003\u540e\u56de\u7b54\u201d\u7b56\u7565\u4e0e\u591a\u5c42\u6b21\u6e10\u8fdb\u5f0fChain-of-Thought\u7ed3\u5408\uff0c\u5206\u4e3a\u8fc7\u6ee4\u3001\u4fe1\u606f\u7ec4\u5408\u548cRAG\u7279\u5b9a\u63a8\u7406\u4e09\u4e2a\u5c42\u6b21\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cHIRAG\u8bad\u7ec3\u7b56\u7565\u5728RGB\u3001PopQA\u3001MuSiQue\u3001HotpotQA\u548cPubmedQA\u7b49\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u8868\u73b0\u3002", "conclusion": "\u901a\u8fc7\u5206\u5c42\u7684\u601d\u7ef4\u94fe\uff0cHIRAG\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u589e\u5f3aRAG\u6a21\u578b\u7684\u4fe1\u606f\u8fc7\u6ee4\u3001\u878d\u5408\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u514b\u670d\u4e86\u4f20\u7edfRAG\u7cfb\u7edf\u7531\u4e8e\u5fae\u8c03\u4e0d\u6df1\u5165\u800c\u5bfc\u81f4\u7684\u6027\u80fd\u74f6\u9888\u3002"}}
{"id": "2507.05724", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.05724", "abs": "https://arxiv.org/abs/2507.05724", "authors": ["Zijin Gu", "Tatiana Likhomanenko", "Navdeep Jaitly"], "title": "Omni-Router: Sharing Routing Decisions in Sparse Mixture-of-Experts for Speech Recognition", "comment": null, "summary": "Mixture-of-experts (MoE) architectures have expanded from language modeling\nto automatic speech recognition (ASR). Traditional MoE methods, such as the\nSwitch Transformer, route experts independently within each layer. Our analysis\nreveals that routers in most layers make expert choices that are not strongly\ncorrelated with the choices of the routers in other layers. To increase the\ncooperation between experts in different layers and encourage greater\nspecialization, we use a shared router across different MoE layers. We call\nthis model \\emph{Omni-router Transformer}. Extensive experiments on a\nlarge-scale pseudo-labeled dataset and evaluations across 10 diverse,\nout-of-domain ASR benchmarks demonstrate that the Omni-router Transformer is\nable to achieve lower training loss and consistently outperform dense and\nSwitch Transformer models, reducing average word error rates by 11.2% and 8.2%,\nrespectively, while providing structured expert usage and improved robustness\nto diverse data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faOmni-router Transformer\uff0c\u901a\u8fc7\u5728MoE\u5c42\u95f4\u5171\u4eab\u8def\u7531\u5668\u589e\u5f3a\u591a\u5c42\u4e13\u5bb6\u5408\u4f5c\uff0c\u5728ASR\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u5bc6\u96c6\u548cSwitch Transformer\u6a21\u578b\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bcd\u9519\u8bef\u7387\u5e76\u63d0\u5347\u4e86\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edfMoE\uff08\u6df7\u5408\u4e13\u5bb6\uff09\u65b9\u6cd5\u4e2d\uff0c\u6bcf\u5c42\u7684\u8def\u7531\u5668\u662f\u72ec\u7acb\u5de5\u4f5c\u7684\uff0c\u4e0d\u540c\u5c42\u4e4b\u95f4\u7684\u4e13\u5bb6\u5206\u914d\u9009\u62e9\u76f8\u5173\u6027\u5f31\u3002\u8fd9\u9650\u5236\u4e86\u4e13\u5bb6\u95f4\u7684\u534f\u4f5c\u548c\u4e13\u95e8\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u4e0d\u540cMoE\u5c42\u95f4\u5171\u4eab\u8def\u7531\u5668\u7684\u67b6\u6784\uff0c\u88ab\u79f0\u4e3a\u201cOmni-router Transformer\u201d\uff0c\u4ee5\u589e\u5f3a\u4e0d\u540c\u5c42\u4e4b\u95f4\u4e13\u5bb6\u7684\u534f\u4f5c\u4e0e\u4e13\u95e8\u5316\u80fd\u529b\u3002", "result": "\u5728\u5927\u89c4\u6a21\u4f2a\u6807\u6ce8\u6570\u636e\u96c6\u548c10\u4e2a\u4e0d\u540c\u7c7b\u522b\u7684ASR\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u6a21\u578b\u8868\u73b0\u4f18\u8d8a\uff0c\u8bad\u7ec3\u635f\u5931\u66f4\u4f4e\uff0c\u5e73\u5747\u8bcd\u9519\u8bef\u7387\u76f8\u6bd4Dense\u6a21\u578b\u964d\u4f4e11.2%\uff0c\u76f8\u6bd4Switch Transformer\u964d\u4f4e8.2%\u3002\u5e76\u4e14\u4e13\u5bb6\u5206\u914d\u7ed3\u6784\u6027\u66f4\u5f3a\uff0c\u5bf9\u591a\u6837\u5316\u6570\u636e\u66f4\u5177\u9c81\u68d2\u6027\u3002", "conclusion": "Omni-router Transformer\u901a\u8fc7\u5171\u4eab\u8def\u7531\u5668\u589e\u5f3a\u4e86\u4e0d\u540c\u5c42\u4e13\u5bb6\u7684\u914d\u5408\u548c\u4e13\u7cbe\u5ea6\uff0c\u5728\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6bd4\u73b0\u6709\u6a21\u578b\u66f4\u597d\u7684\u6548\u679c\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.05740", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05740", "abs": "https://arxiv.org/abs/2507.05740", "authors": ["Yujia Hu", "Tuan-Phong Nguyen", "Shrestha Ghosh", "Moritz M\u00fcller", "Simon Razniewski"], "title": "GPTKB v1.5: A Massive Knowledge Base for Exploring Factual LLM Knowledge", "comment": "7 pages, 6 figures, 1 table", "summary": "Language models are powerful tools, yet their factual knowledge is still\npoorly understood, and inaccessible to ad-hoc browsing and scalable statistical\nanalysis. This demonstration introduces GPTKB v1.5, a densely interlinked\n100-million-triple knowledge base (KB) built for $14,000 from GPT-4.1, using\nthe GPTKB methodology for massive-recursive LLM knowledge materialization (Hu\net al., ACL 2025). The demonstration experience focuses on three use cases: (1)\nlink-traversal-based LLM knowledge exploration, (2) SPARQL-based structured LLM\nknowledge querying, (3) comparative exploration of the strengths and weaknesses\nof LLM knowledge. Massive-recursive LLM knowledge materialization is a\ngroundbreaking opportunity both for the research area of systematic analysis of\nLLM knowledge, as well as for automated KB construction. The GPTKB demonstrator\nis accessible at https://gptkb.org.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGPTKB v1.5\uff0c\u5229\u7528\u9012\u5f52\u5f0f\u5927\u6a21\u578b\u77e5\u8bc6\u8403\u53d6\u6280\u672f\uff0c\u4eceGPT-4.1\u4f4e\u6210\u672c\u9ad8\u6548\u751f\u6210\u4e861\u4ebf\u4e09\u5143\u7ec4\u7684\u77e5\u8bc6\u5e93\uff0c\u53ef\u7528\u4e8e\u77e5\u8bc6\u6d4f\u89c8\u3001\u67e5\u8be2\u4e0e\u5206\u6790\uff0c\u5bf9\u7406\u89e3\u548c\u5229\u7528LLM\u77e5\u8bc6\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u867d\u5f3a\u5927\uff0c\u4f46\u5176\u5185\u90e8\u4e8b\u5b9e\u77e5\u8bc6\u96be\u4ee5\u88ab\u7cfb\u7edf\u7406\u89e3\u3001\u6d4f\u89c8\u6216\u7edf\u8ba1\u5206\u6790\uff0c\u56e0\u6b64\u9700\u5f00\u53d1\u65b0\u65b9\u6cd5\u63ed\u793a\u5176\u77e5\u8bc6\u4f53\u7cfb\u4e0e\u8fb9\u754c\u3002", "method": "\u91c7\u7528 massive-recursive LLM knowledge materialization\uff08\u5927\u89c4\u6a21\u9012\u5f52\u5f0fLLM\u77e5\u8bc6\u5b9e\u5316\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7GPT-4.1\u751f\u6210\u4e86\u4e00\u4e2a\u5305\u542b1\u4ebf\u6761\u4e09\u5143\u7ec4\u7684\u77e5\u8bc6\u5e93\u3002\u7528\u6237\u53ef\u901a\u8fc7\u94fe\u63a5\u904d\u5386\u3001SPARQL\u67e5\u8be2\u548c\u5bf9\u6bd4\u63a2\u7d22\u8fdb\u884c\u77e5\u8bc6\u6d4f\u89c8\u4e0e\u5206\u6790\u3002", "result": "\u6210\u529f\u4eceGPT-4.1\u4ee5\u7ea614000\u7f8e\u5143\u6210\u672c\u6784\u5efa\u4e86GPTKB v1.5\u77e5\u8bc6\u5e93\uff0c\u5b9e\u73b0\u4e86\u7ed3\u6784\u5316\u67e5\u8be2\u3001\u8fde\u901a\u6027\u5206\u6790\u548c\u77e5\u8bc6\u5f31\u70b9\u63a2\u7d22\u7b49\u529f\u80fd\uff0c\u63a8\u52a8\u4e86LLM\u77e5\u8bc6\u7684\u53ef\u89e3\u91ca\u6027\u4e0e\u81ea\u52a8\u5316\u77e5\u8bc6\u5e93\u6784\u5efa\u7814\u7a76\u3002", "conclusion": "GPTKB v1.5 \u63d0\u4f9b\u4e86\u4e00\u79cd\u5168\u65b0\u4e14\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u4e8b\u5b9e\u77e5\u8bc6\u8fdb\u884c\u7cfb\u7edf\u89e3\u6790\u3001\u81ea\u52a8\u5316\u77e5\u8bc6\u5e93( KB )\u6784\u5efa\u548c\u4e92\u52a8\u5f0f\u63a2\u7d22\u3002"}}
{"id": "2507.05750", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05750", "abs": "https://arxiv.org/abs/2507.05750", "authors": ["Jing Yang Lee", "Hamed Bonab", "Nasser Zalmout", "Ming Zeng", "Sanket Lokegaonkar", "Colin Lockard", "Binxuan Huang", "Ritesh Sarkhel", "Haodong Wang"], "title": "DocTalk: Scalable Graph-based Dialogue Synthesis for Enhancing LLM Conversational Capabilities", "comment": "Accepted at SIGDIAL 2025", "summary": "Large Language Models (LLMs) are increasingly employed in multi-turn\nconversational tasks, yet their pre-training data predominantly consists of\ncontinuous prose, creating a potential mismatch between required capabilities\nand training paradigms. We introduce a novel approach to address this\ndiscrepancy by synthesizing conversational data from existing text corpora. We\npresent a pipeline that transforms a cluster of multiple related documents into\nan extended multi-turn, multi-topic information-seeking dialogue. Applying our\npipeline to Wikipedia articles, we curate DocTalk, a multi-turn pre-training\ndialogue corpus consisting of over 730k long conversations. We hypothesize that\nexposure to such synthesized conversational structures during pre-training can\nenhance the fundamental multi-turn capabilities of LLMs, such as context memory\nand understanding. Empirically, we show that incorporating DocTalk during\npre-training results in up to 40% gain in context memory and understanding,\nwithout compromising base performance. DocTalk is available at\nhttps://huggingface.co/datasets/AmazonScience/DocTalk.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9LLMs\u591a\u8f6e\u5bf9\u8bdd\u4efb\u52a1\u4e0e\u9884\u8bad\u7ec3\u6570\u636e\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u4ece\u6587\u6863\u805a\u7c7b\u4e2d\u81ea\u52a8\u5408\u6210\u4fe1\u606f\u578b\u591a\u8f6e\u5bf9\u8bdd\u8bed\u6599DocTalk\uff0c\u5728\u5b9e\u9a8c\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u4e0e\u7406\u89e3\u80fd\u529b\uff0c\u5e76\u5df2\u5f00\u653e\u8be5\u6570\u636e\u96c6\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e3b\u8981\u4ee5\u8fde\u8d2f\u7684\u4e66\u9762\u6587\u672c\u4f5c\u4e3a\u9884\u8bad\u7ec3\u6570\u636e\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u4e2d\u5e38\u9700\u5904\u7406\u591a\u8f6e\u5bf9\u8bdd\u4efb\u52a1\uff0c\u8fd9\u5bfc\u81f4\u80fd\u529b\u548c\u8bad\u7ec3\u8303\u5f0f\u4e4b\u95f4\u5b58\u5728\u4e0d\u5339\u914d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u73b0\u6709\u6587\u672c\u8bed\u6599\u4e2d\u5408\u6210\u5bf9\u8bdd\u6570\u636e\u7684\u65b0\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u6d41\u6c34\u7ebf\uff0c\u5c06\u76f8\u5173\u6587\u6863\u96c6\u8f6c\u5316\u4e3a\u591a\u8f6e\u591a\u8bdd\u9898\u7684\u4fe1\u606f\u578b\u5bf9\u8bdd\u3002\u4ee5Wikipedia\u4e3a\u4f8b\uff0c\u751f\u6210\u4e86\u540d\u4e3aDocTalk\u7684\u591a\u8f6e\u5bf9\u8bdd\u9884\u8bad\u7ec3\u8bed\u6599\u3002", "result": "\u5728\u9884\u8bad\u7ec3\u4e2d\u5f15\u5165DocTalk\u540e\uff0cLLMs\u5728\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u548c\u7406\u89e3\u80fd\u529b\u4e0a\u6700\u591a\u63d0\u5347\u4e8640%\uff0c\u4e14\u672a\u635f\u5931\u57fa\u672c\u6027\u80fd\u3002", "conclusion": "\u5408\u6210\u7684\u591a\u8f6e\u5bf9\u8bdd\u8bed\u6599\u53ef\u663e\u8457\u589e\u5f3aLLMs\u7684\u591a\u8f6e\u5bf9\u8bdd\u80fd\u529b\u3002DocTalk\u8bed\u6599\u5e93\u5df2\u5f00\u653e\u83b7\u53d6\u3002"}}
{"id": "2507.05788", "categories": ["cs.CL", "I.2.7; H.3.3"], "pdf": "https://arxiv.org/pdf/2507.05788", "abs": "https://arxiv.org/abs/2507.05788", "authors": ["Anand A. Rajasekar", "Praveen Tangarajan", "Anjali Nainani", "Amogh Batwal", "Vinay Rao Dandin", "Anusua Trivedi", "Ozan Ersoy"], "title": "Flippi: End To End GenAI Assistant for E-Commerce", "comment": "10 pages, 2 figures, 7 tables", "summary": "The emergence of conversational assistants has fundamentally reshaped user\ninteractions with digital platforms. This paper introduces Flippi-a\ncutting-edge, end-to-end conversational assistant powered by large language\nmodels (LLMs) and tailored for the e-commerce sector. Flippi addresses the\nchallenges posed by the vast and often overwhelming product landscape, enabling\ncustomers to discover products more efficiently through natural language\ndialogue. By accommodating both objective and subjective user requirements,\nFlippi delivers a personalized shopping experience that surpasses traditional\nsearch methods. This paper details how Flippi interprets customer queries to\nprovide precise product information, leveraging advanced NLP techniques such as\nQuery Reformulation, Intent Detection, Retrieval-Augmented Generation (RAG),\nNamed Entity Recognition (NER), and Context Reduction. Flippi's unique\ncapability to identify and present the most attractive offers on an e-commerce\nsite is also explored, demonstrating how it empowers users to make\ncost-effective decisions. Additionally, the paper discusses Flippi's\ncomparative analysis features, which help users make informed choices by\ncontrasting product features, prices, and other relevant attributes. The\nsystem's robust architecture is outlined, emphasizing its adaptability for\nintegration across various e-commerce platforms and the technological choices\nunderpinning its performance and accuracy. Finally, a comprehensive evaluation\nframework is presented, covering performance metrics, user satisfaction, and\nthe impact on customer engagement and conversion rates. By bridging the\nconvenience of online shopping with the personalized assistance traditionally\nfound in physical stores, Flippi sets a new standard for customer satisfaction\nand engagement in the digital marketplace.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u578b\u7535\u5546\u5bf9\u8bdd\u52a9\u624bFlippi\uff0c\u57fa\u4e8eLLMs\u5b9e\u73b0\u7cbe\u51c6\u7406\u89e3\u4e0e\u4e2a\u6027\u5316\u63a8\u8350\uff0c\u901a\u8fc7\u591a\u9879NLP\u6280\u672f\u63d0\u5347\u7528\u6237\u8d2d\u7269\u4f53\u9a8c\u548c\u5546\u5bb6\u8f6c\u5316\u6548\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7535\u5546\u641c\u7d22\u65b9\u5f0f\u3002", "motivation": "\u4f20\u7edf\u7535\u5546\u5e73\u53f0\u4ea7\u54c1\u7e41\u6742\uff0c\u7528\u6237\u5728\u641c\u7d22\u5546\u54c1\u65f6\u5f80\u5f80\u9762\u4e34\u4fe1\u606f\u8fc7\u8f7d\uff0c\u96be\u4ee5\u9ad8\u6548\u53d1\u73b0\u548c\u6bd4\u8f83\u5546\u54c1\uff0c\u4e2a\u6027\u5316\u7a0b\u5ea6\u6709\u9650\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u6ee1\u8db3\u7528\u6237\u7684\u4e3b\u89c2\u548c\u5ba2\u89c2\u9700\u6c42\uff0c\u5f71\u54cd\u8d2d\u7269\u4f53\u9a8c\u548c\u8f6c\u5316\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u7aef\u5230\u7aef\u5bf9\u8bdd\u5f0f\u52a9\u624bFlippi\uff0c\u4e13\u4e3a\u7535\u5546\u573a\u666f\u4f18\u5316\u3002\u91c7\u7528\u4e86\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\uff0c\u5305\u62ec\u67e5\u8be2\u91cd\u6784\uff08Query Reformulation\uff09\u3001\u610f\u56fe\u68c0\u6d4b\uff08Intent Detection\uff09\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u3001\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08NER\uff09\u3001\u4e0a\u4e0b\u6587\u7b80\u5316\u7b49\u3002\u7cfb\u7edf\u67b6\u6784\u9488\u5bf9\u591a\u7535\u5546\u5e73\u53f0\u6613\u4e8e\u96c6\u6210\uff0c\u652f\u6301\u6bd4\u8f83\u5206\u6790\u3001\u7279\u4ef7\u8bc6\u522b\u3001\u4e2a\u6027\u5316\u63a8\u8350\u7b49\u529f\u80fd\u3002", "result": "Flippi\u6709\u6548\u63d0\u5347\u4e86\u5546\u54c1\u53d1\u73b0\u6548\u7387\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u66f4\u52a0\u4e2a\u6027\u5316\u548c\u4fbf\u6377\u7684\u8d2d\u7269\u4f53\u9a8c\u3002\u5728\u7cbe\u786e\u63a8\u8350\u3001\u4ef7\u683c/\u529f\u80fd\u5bf9\u6bd4\u548c\u5438\u5f15\u529b\u4f18\u60e0\u53d1\u73b0\u7b49\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002\u901a\u8fc7\u7528\u6237\u6ee1\u610f\u5ea6\u3001\u8f6c\u5316\u7387\u548c\u4ea4\u4e92\u6307\u6807\u7684\u7efc\u5408\u8bc4\u4f30\uff0c\u8868\u660e\u7cfb\u7edf\u80fd\u663e\u8457\u63d0\u5347\u5ba2\u6237\u53c2\u4e0e\u5ea6\u548c\u8d2d\u4e70\u8f6c\u5316\u3002", "conclusion": "Flippi\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u8bdd\u7406\u89e3\u80fd\u529b\u4e0e\u7535\u5546\u573a\u666f\u6df1\u5ea6\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u7ebf\u4e0a\u8d2d\u7269\u4e2a\u6027\u5316\u548c\u667a\u80fd\u5316\uff0c\u4e3a\u6570\u5b57\u5e02\u573a\u6811\u7acb\u4e86\u66f4\u9ad8\u7684\u5ba2\u6237\u6ee1\u610f\u5ea6\u548c\u53c2\u4e0e\u6807\u51c6\u3002"}}
{"id": "2507.05799", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.05799", "abs": "https://arxiv.org/abs/2507.05799", "authors": ["Amane Watahiki", "Tomoki Doi", "Taiga Shinozaki", "Satoshi Nishida", "Takuya Niikawa", "Katsunori Miyahara", "Hitomi Yanaka"], "title": "Bridging Perception and Language: A Systematic Benchmark for LVLMs' Understanding of Amodal Completion Reports", "comment": "To appear in the Proceedings of the 47th Annual Meeting of the\n  Cognitive Science Society (COGSCI 2025)", "summary": "One of the main objectives in developing large vision-language models (LVLMs)\nis to engineer systems that can assist humans with multimodal tasks, including\ninterpreting descriptions of perceptual experiences. A central phenomenon in\nthis context is amodal completion, in which people perceive objects even when\nparts of those objects are hidden. Although numerous studies have assessed\nwhether computer-vision algorithms can detect or reconstruct occluded regions,\nthe inferential abilities of LVLMs on texts related to amodal completion remain\nunexplored. To address this gap, we constructed a benchmark grounded in Basic\nFormal Ontology to achieve a systematic classification of amodal completion.\nOur results indicate that while many LVLMs achieve human-comparable performance\noverall, their accuracy diverges for certain types of objects being completed.\nNotably, in certain categories, some LLaVA-NeXT variants and Claude 3.5 Sonnet\nexhibit lower accuracy on original images compared to blank stimuli lacking\nvisual content. Intriguingly, this disparity emerges only under Japanese\nprompting, suggesting a deficiency in Japanese-specific linguistic competence\namong these models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u8bc4\u6d4bLVLM\u5bf9\u8d85\u6a21\u6001\u8865\u5168\u76f8\u5173\u6587\u672c\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u65e5\u8bed\u7b49\u7279\u5b9a\u8bed\u5883\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u63ed\u793a\u4e86\u5176\u8bed\u8a00\u548c\u63a8\u7406\u80fd\u529b\u7684\u5c40\u9650\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u5bf9\u4e8e\u201c\u8d85\u6a21\u6001\u8865\u5168\u201d\uff08amodal completion, \u5373\u4eba\u7c7b\u5728\u7269\u4f53\u90e8\u5206\u88ab\u906e\u6321\u65f6\u5bf9\u5b8c\u6574\u6027\u7269\u4f53\u7684\u611f\u77e5\uff09\u76f8\u5173\u6587\u672c\u7684\u7406\u89e3\u4e0e\u63a8\u7406\u80fd\u529b\u5c1a\u672a\u88ab\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002", "method": "\u4f5c\u8005\u57fa\u4e8eBasic Formal Ontology\u6784\u5efa\u4e86\u4e00\u4e2a\u7528\u4e8e\u7cfb\u7edf\u5206\u7c7b\u4e0e\u8bc4\u6d4b\u8d85\u6a21\u6001\u8865\u5168\u80fd\u529b\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5bf9\u591a\u79cdLVLMs\u5728\u8be5\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u8bc4\u6d4b\u4e0e\u5206\u6790\uff0c\u7279\u522b\u5173\u6ce8\u4e0d\u540c\u7c7b\u522b\u4ee5\u53ca\u65e5\u8bed\u63d0\u793a\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u591a\u79cdLVLM\u6574\u4f53\u4e0a\u80fd\u8fbe\u5230\u4e0e\u4eba\u7c7b\u76f8\u5f53\u7684\u8868\u73b0\uff0c\u4f46\u6a21\u578b\u5728\u5b8c\u6210\u4e0d\u540c\u7c7b\u522b\u7269\u4f53\u65f6\u7684\u51c6\u786e\u7387\u5b58\u5728\u5dee\u5f02\u3002\u7279\u522b\u662f\u5728\u65e5\u8bed\u6307\u4ee4\u4e0b\uff0c\u90e8\u5206\u6a21\u578b\u5982LLaVA-NeXT\u53d8\u4f53\u548cClaude 3.5 Sonnet\u5728\u539f\u59cb\u56fe\u50cf\u4e0a\u7684\u8868\u73b0\u7adf\u7136\u4f4e\u4e8e\u65e0\u89c6\u89c9\u5185\u5bb9\u7684\u7a7a\u767d\u523a\u6fc0\uff0c\u53cd\u6620\u6a21\u578b\u5728\u65e5\u8bed\u591a\u6a21\u6001\u7406\u89e3\u4e0a\u7684\u4e0d\u8db3\u3002", "conclusion": "LVLMs\u867d\u7136\u6574\u4f53\u4e0a\u5177\u6709\u8f83\u5f3a\u7684\u8d85\u6a21\u6001\u8865\u5168\u6587\u5b57\u7406\u89e3\u80fd\u529b\uff0c\u4f46\u5728\u7ec6\u5206\u573a\u666f\u548c\u7279\u5b9a\u8bed\u8a00\uff08\u5982\u65e5\u8bed\uff09\u4e0b\u5b58\u5728\u77ed\u677f\uff0c\u63d0\u793a\u540e\u7eed\u7814\u7a76\u9700\u8981\u8fdb\u4e00\u6b65\u9488\u5bf9\u591a\u8bed\u8a00\u4e0e\u591a\u7c7b\u578b\u7269\u4f53\u8865\u5168\u80fd\u529b\u4f18\u5316\u6a21\u578b\u3002"}}
{"id": "2507.05885", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.05885", "abs": "https://arxiv.org/abs/2507.05885", "authors": ["Tanvina Patel", "Wiebke Hutiri", "Aaron Yi Ding", "Odette Scharenborg"], "title": "How to Evaluate Automatic Speech Recognition: Comparing Different Performance and Bias Measures", "comment": null, "summary": "There is increasingly more evidence that automatic speech recognition (ASR)\nsystems are biased against different speakers and speaker groups, e.g., due to\ngender, age, or accent. Research on bias in ASR has so far primarily focused on\ndetecting and quantifying bias, and developing mitigation approaches. Despite\nthis progress, the open question is how to measure the performance and bias of\na system. In this study, we compare different performance and bias measures,\nfrom literature and proposed, to evaluate state-of-the-art end-to-end ASR\nsystems for Dutch. Our experiments use several bias mitigation strategies to\naddress bias against different speaker groups. The findings reveal that\naveraged error rates, a standard in ASR research, alone is not sufficient and\nshould be supplemented by other measures. The paper ends with recommendations\nfor reporting ASR performance and bias to better represent a system's\nperformance for diverse speaker groups, and overall system bias.", "AI": {"tldr": "ASR\u7cfb\u7edf\u5b58\u5728\u9488\u5bf9\u4e0d\u540c\u8bf4\u8bdd\u7fa4\u4f53\u7684\u504f\u89c1\uff0c\u4ec5\u9760\u5e73\u5747\u9519\u8bef\u7387\u6307\u6807\u4e0d\u8db3\u4ee5\u5168\u9762\u8bc4\u4f30\u3002\u672c\u6587\u6bd4\u8f83\u591a\u79cd\u8861\u91cf\u65b9\u6cd5\uff0c\u5efa\u8bae\u91c7\u7528\u591a\u6837\u6307\u6807\uff0c\u5e76\u89c4\u8303\u7ed3\u679c\u62a5\u544a\uff0c\u4ee5\u66f4\u597d\u53cd\u6620\u7cfb\u7edf\u504f\u89c1\u548c\u7fa4\u4f53\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u7cfb\u7edf\u5728\u6027\u522b\u3001\u5e74\u9f84\u3001\u53e3\u97f3\u7b49\u65b9\u9762\u5bf9\u4e0d\u540c\u8bf4\u8bdd\u4eba\u6216\u7fa4\u4f53\u5b58\u5728\u504f\u89c1\u3002\u867d\u7136\u5df2\u6709\u5927\u91cf\u5173\u4e8e\u504f\u89c1\u7684\u68c0\u6d4b\u548c\u7f13\u89e3\u7814\u7a76\uff0c\u4f46\u5982\u4f55\u8861\u91cf\u7cfb\u7edf\u6027\u80fd\u548c\u504f\u89c1\u4f9d\u7136\u7f3a\u4e4f\u89c4\u8303\u3002", "method": "\u5c06\u6587\u732e\u4e2d\u5df2\u6709\u548c\u65b0\u63d0\u51fa\u7684\u591a\u79cd\u6027\u80fd\u53ca\u504f\u89c1\u8861\u91cf\u6307\u6807\u8fdb\u884c\u5bf9\u6bd4\uff0c\u7528\u4e8e\u8bc4\u4f30\u73b0\u4ee3\u7aef\u5230\u7aef\u8377\u5170\u8bedASR\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u4e0d\u540c\u504f\u89c1\u7f13\u89e3\u7b56\u7565\u5904\u7406\u9488\u5bf9\u4e0d\u540c\u8bf4\u8bdd\u7fa4\u4f53\u7684\u504f\u89c1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cASR\u9886\u57df\u5e38\u7528\u7684\u5e73\u5747\u9519\u8bef\u7387\u6307\u6807\u4e0d\u8db3\u4ee5\u5168\u9762\u53cd\u6620\u7cfb\u7edf\u6027\u80fd\uff0c\u5efa\u8bae\u7528\u5176\u4ed6\u8861\u91cf\u65b9\u5f0f\u8865\u5145\u3002\u5e76\u7ed9\u51fa\u5173\u4e8eASR\u7cfb\u7edf\u6027\u80fd\u548c\u504f\u89c1\u62a5\u544a\u7684\u5efa\u8bae\uff0c\u4ee5\u66f4\u597d\u5730\u4f53\u73b0\u5bf9\u591a\u6837\u5316\u8bf4\u8bdd\u4eba\u7fa4\u4f53\u7684\u8868\u73b0\u548c\u6574\u4f53\u7cfb\u7edf\u504f\u89c1\u3002", "conclusion": "\u5355\u4e00\u7684\u5e73\u5747\u9519\u8bef\u7387\u6307\u6807\u5bf9\u8861\u91cfASR\u7cfb\u7edf\u4e2d\u7684\u504f\u89c1\u548c\u591a\u6837\u4eba\u7fa4\u8868\u73b0\u662f\u4e0d\u591f\u7684\u3002\u9700\u8981\u591a\u5143\u5316\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u5e76\u7ed9\u51fa\u89c4\u8303\u5316\u7684\u62a5\u544a\u5efa\u8bae\u6765\u51cf\u5c11\u672a\u88ab\u53d1\u73b0\u7684\u504f\u89c1\u3002"}}
