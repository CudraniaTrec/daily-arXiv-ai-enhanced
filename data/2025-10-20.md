<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 12]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.CL](#cs.CL) [Total: 52]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Grassroots Logic Programs: A Secure, Multiagent, Concurrent, Logic Programming Language](https://arxiv.org/abs/2510.15747)
*Ehud Shapiro*

Main category: cs.PL

TL;DR: 本文提出GLP编程语言，解决草根平台中的安全通信、身份验证和代码完整性难题，通过理论和协议证明其安全特性，并展示对社交网络和区块链应用的支撑能力。


<details>
  <summary>Details</summary>
Motivation: 草根平台是一种分布式应用，它由在网络设备上的密码学身份人执行，旨在构建去中心化的社交网络、加密货币及民主联盟。目前尚未实现的主要挑战是如何应对不可靠和恶意参与者，缺乏安全编程支持导致参与者难以安全识别、通讯和代码完整性验证。

Method: 作者提出了一种称为Grassroots Logic Programs（GLP）的安全多智能体并发逻辑编程语言。GLP扩展了逻辑程序，引入单读单写逻辑变量，利用加密、签名和证明消息为基于密码学身份的人提供安全通信信道，保障身份识别和代码完整性验证。文中分步骤介绍了GLP的发展，包括并发、跨智能体、加入加密安全以及面向智能手机实现的规范。

Result: 作者证明了GLP具备若干安全属性，包括计算安全性、SRSW变量属性保留、无环性和单调性。证明多智能体GLP符合草根平台特性，且GLP数据流实现了区块链安全属性。还提出了用于建立认证点对点连接的草根社交图协议，并演示了安全社交网络应用的可行性。

Conclusion: GLP为实现安全、去中心化的草根平台提供了编程语言及协议基础，克服了身份和代码验证的关键障碍，并为草根网络和区块链安全应用奠定了坚实基础。

Abstract: Grassroots platforms are distributed applications run by\linebreak
cryptographically-identified people on their networked personal devices, where
multiple disjoint platform instances emerge independently and coalesce when
they interoperate. Their foundation is the grassroots social graph, upon which
grassroots social networks, grassroots cryptocurrencies, and grassroots
democratic federations can be built.
  Grassroots platforms have yet to be implemented, the key challenge being
faulty and malicious participants: without secure programming support, correct
participants cannot reliably identify each other, establish secure
communication, or verify each other's code integrity.
  We present Grassroots Logic Programs (GLP), a secure, multiagent, concurrent,
logic programming language for implementing grassroots platforms. GLP extends
logic programs with paired single-reader/single-writer (SRSW) logic variables,
providing secure communication channels among cryptographically-identified
people through encrypted, signed and attested messages, which enable identity
and code integrity verification. We present GLP progressively: logic programs,
concurrent GLP, multiagent GLP, augmenting it with cryptographic security, and
providing smartphone implementation-ready specifications. We prove safety
properties including that GLP computations are deductions, SRSW preservation,
acyclicity, and monotonicity. We prove multiagent GLP is grassroots and that
GLP streams achieve blockchain security properties. We present a grassroots
social graph protocol establishing authenticated peer-to-peer connections and
demonstrate secure grassroots social networking applications.

</details>


### [2] [Visualizing miniKanren Search with a Fine-Grained Small-Step Semantics](https://arxiv.org/abs/2510.15178)
*Brysen Pfingsten,Jason Hemann*

Main category: cs.PL

TL;DR: 本文为miniKanren设计了可视化公平搜索过程的小步操作语义与交互工具，通过精细建模和实例测试，有效提升了对其行为和答案顺序的理解。


<details>
  <summary>Details</summary>
Motivation: miniKanren的搜索过程因公平性和答案顺序常令用户迷惑，缺乏便于理解和教学的语义及工具。作者期望通过精确建模和可视化，降低学习和理解难度，提升使用体验。

Method: 通过构建一个明确表示搜索树演化过程的确定性小步操作语义，细致建模目标激活、挂起、恢复和成功等细节。基于该模型，开发交互式可视化工具可动态渲染搜索树并支持逐步执行。为验证方法有效性，采用性质基础测试，并用多个案例实例说明。

Result: 作者成功实现了小步操作语义和交互式可视化工具，能清晰展现搜索树发展过程、答案顺序和操作细节，具有很强的教学价值和解释能力。方法已获实证验证。

Conclusion: 提出的确定性小步操作语义和可视化工具能够精确呈现和分析miniKanren的公平搜索过程，并通过实例和测试验证了方法的有效性。

Abstract: We present a deterministic small-step operational semantics for miniKanren
that explicitly represents the evolving search tree during execution. This
semantics models interleaving and goal scheduling at fine granularity, allowing
each evaluation step-goal activation, suspension, resumption, and success -- to
be visualized precisely. Building on this model, we implement an interactive
visualizer that renders the search tree as it develops and lets users step
through execution. The tool acts as a pedagogical notional machine for
reasoning about miniKanren's fair search behavior, helping users understand
surprising answer orders and operational effects. Our semantics and tool are
validated through property-based testing and illustrated with several examples.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [Automated Snippet-Alignment Data Augmentation for Code Translation](https://arxiv.org/abs/2510.15004)
*Zhiming Zhang,Qingfu Zhu,Xianzhen Luo,Yixuan Wang,Bohan Li,Wanxiang Che*

Main category: cs.SE

TL;DR: 本论文提出一种基于LLM自动生成代码片段对齐数据（SA）的方法，并结合PA和SA数据的两阶段训练策略。实验证明，该方法能显著提升代码翻译任务的效果，最高提升3.78%。


<details>
  <summary>Details</summary>
Motivation: 代码翻译在软件开发中具有重要作用，但高质量的并行语料有限，现有研究主要在程序对齐（PA）数据上做增强，而片段对齐（SA）数据更有助于细粒度语义对齐学习。

Method: 提出利用大语言模型（LLM）自动生成SA数据，并结合PA数据，采用两阶段训练策略提升模型性能。

Result: 在TransCoder-test上的实验表明，两阶段训练策略下，增强后的SA数据可带来一致并显著的性能提升，pass@k指标最高提升3.78%。

Conclusion: 结合LLM自动生成的SA增强数据与两阶段训练策略，能有效提升代码翻译模型的表现。

Abstract: Code translation aims to translate the code from its source language to the
target language and is used in various software development scenarios. Recent
developments in Large Language Models (LLMs) have showcased their capabilities
in code translation, and parallel corpora play a crucial role in training
models for code translation. Parallel corpora can be categorized into
program-alignment (PA) and snippet-alignment (SA) data. Although PA data has
complete context and is suitable for semantic alignment learning, it may not
provide adequate fine-grained training signals due to its extended length,
while the brevity of SA data enables more fine-grained alignment learning. Due
to limited parallel corpora, researchers explore several augmentation methods
for code translation. Previous studies mainly focus on augmenting PA data. In
this paper, we propose a data augmentation method that leverages LLMs to
generate SA data automatically. To fully leverage both PA data and SA data, we
explore a simple yet effective two-stage training strategy, which consistently
enhances model performance compared to fine-tuning solely on PA data.
Experiments on TransCoder-test demonstrate that our augmented SA data combined
with the two-stage training approach yields consistent improvements over the
baseline, achieving a maximum gain of 3.78% on pass@k.

</details>


### [4] [Assessing Coherency and Consistency of Code Execution Reasoning by Large Language Models](https://arxiv.org/abs/2510.15079)
*Changshu Liu,Yang Chen,Reyhaneh Jabbarvand*

Main category: cs.SE

TL;DR: 本文提出CES基准系统评测大模型在程序执行模拟和编程任务的推理及一致性能力。结果显示主流模型推理连贯性高但一致性弱，依赖语言捷径，泛化能力有限，CES可用来系统排查和评估这些风险。


<details>
  <summary>Details</summary>
Motivation: 大模型在程序执行模拟和相关编程任务中表现出潜在的推理能力不足，现有评估方法可能因推理捷径、幻觉或数据泄漏而产生误判。缺乏系统性衡量其执行推理和一致性的手段，影响模型泛化和解决实际编程问题的能力。

Method: 提出CES基准任务，评估大模型在程序执行模拟及其在编程任务中的应用推理能力。CES不仅考察变量预测的正确性，还引入“连贯性”指标，判断模拟过程是否符合常识执行逻辑，排除由于推理捷径、幻觉或数据泄漏导致的可疑正确结果。同时给出一致性新指标，分析同/不同路径覆盖下模型表现。对比16个主流大模型并应用于HumanEval任务，进行系统分析。

Result: LLMs在HumanEval上执行模拟连贯性达81.42%，其中46.92%预测输出正确，53.08%错误。前沿模型如GPT-4及DeepSeek-R1反而表现出更多的不连贯，归因于自然语言捷径。路径相关的推理一致性表现不佳，仅48.87%为随机，45.37%为弱一致。模型在bug相关任务上难以展现执行推理，成功主要源自模式匹配或语言捷径，有泛化风险。

Conclusion: CES基准可有效判别LLMs在程序执行及分析任务中的推理能力，系统排查其可疑成功案例。现有模型大多依赖语言捷径，推理一致性不足，限制其在路径敏感任务以及泛化到未知bug场景中的实际效果。

Abstract: This paper proposes CES, a task to evaluate the abilities of LLMs in
simulating program execution and using that reasoning in programming tasks.
Besides measuring the correctness of variable predictions during execution
simulation, CES introduces the notion of coherence to determine whether the
simulation complies with commonsense execution logic, even if the predicted
values along the simulations are incorrect. This enables CES to rule out
suspiciously correct output predictions due to reasoning shortcuts,
hallucinations, or potential data leakage. CES also introduces a novel metric
to measure reasoning consistency across tests with the same or different prime
path coverage in a spectrum: strong, weak, and random. Evaluating 16 LLMs
(including three reasoning LLMs) using CES indicates 81.42% coherent execution
simulation on HumanEval, 46.92% and 53.08% of which result in correct and
incorrect output predictions. Frontier LLMs such as GPT-4 and DeepSeek-R1 have
the most incoherent execution reasoning, mostly due to natural language
shortcuts. Despite relatively coherent execution simulation, LLMs' reasoning
performance across different tests is inconsistent, mostly random (48.87%) or
weak (45.37%), potentially explaining their weakness in programming tasks that
require path-sensitive program analysis to succeed. We also compare CES with
bug prediction/localization/repair, which intuitively requires control- and
data-flow awareness. We observe that LLMs barely incorporate execution
reasoning into their analysis for bug-related tasks, and their success is
primarily due to inherent abilities in pattern matching or natural language
shortcuts, if not data leakage. Without reasoning, there is a threat to the
generalizability of LLMs in dealing with unseen bugs or patterns in different
contexts. CES can be used to vet the suspicious success of LLMs in these tasks
systematically.

</details>


### [5] [Community Engagement and the Lifespan of Open-Source Software Projects](https://arxiv.org/abs/2510.15408)
*Mohit,Kuljit Kaur Chahal*

Main category: cs.SE

TL;DR: 本文系统分析了社区参与对开源软件项目发展及寿命的影响，发现初期社区活跃至关重要，长期高参与可显著提升项目寿命，并提供了可量化的社区参与度衡量方法。


<details>
  <summary>Details</summary>
Motivation: 开源软件（OSS）项目依赖社区参与（CE）以维持其长期发展，但社区参与对项目动态和寿命的量化影响尚未得到充分研究。本文致力于定义社区参与，并分析其与项目发展及寿命之间的关系。

Method: 作者对33,946个GitHub代码库进行了分析，定义并量化了每月社区参与指标（如问题、评论、关注者、点赞者），并通过非参数检验和相关性分析探究这些指标与项目发布、提交、分支变化及项目寿命之间的关联。

Result: 社区参与指标与项目动态显著相关，尤其在高参与度项目中相关性更强。项目寿命方面，每月社区参与率在新项目中最高，随着项目年龄增长而减弱，不过一部分长寿项目始终保持极高的活动率。初期社区参与的爆发对于项目建立至关重要，而长期高参与则驱动极端长寿。活跃的问题参与随项目年龄增长影响加剧，而被动关注的影响则逐渐减弱。

Conclusion: 社区参与是驱动开源项目开发与长寿的核心动力。研究成果建立了有效的社区参与指标，并深入揭示了不同社区活动对项目寿命的作用模式。

Abstract: Open-source software (OSS) projects depend on community engagement (CE) for
longevity. However, CE's quantifiable impact on project dynamics and lifespan
is underexplored. Objectives: This study defines CE in OSS, identifies key
metrics, and evaluates their influence on project dynamics (releases, commits,
branches) and lifespan. Methods: We analyzed 33,946 GitHub repositories,
defining and operationalizing CE with validated per-month metrics (issues,
comments, watchers, stargazers). Non-parametric tests and correlations assessed
relationships with project dynamics and lifespan across quartiles. Results: CE
metrics significantly associate with project dynamics, with stronger
correlations in highly engaged projects. For lifespan, a complex pattern
emerged: per-month CE rates are highest in younger projects, declining with
age. Yet, a subset of long-lived projects maintains exceptionally high
activity. Initial CE bursts appear crucial for establishment, while sustained
high engagement drives extreme longevity. Active issue engagement's influence
intensifies with age, but passive attention's declines. Conclusion: CE
dynamically drives OSS project longevity and development. Our findings
establish validated CE metrics and offer deeper insights into how diverse
community activity patterns contribute to project longevity.

</details>


### [6] [Leveraging Test Driven Development with Large Language Models for Reliable and Verifiable Spreadsheet Code Generation: A Research Framework](https://arxiv.org/abs/2510.15585)
*Dr Simon Thorne,Dr Advait Sarkar*

Main category: cs.SE

TL;DR: 本文提出将测试驱动开发（TDD）流程与大语言模型生成结合，提升代码和表格公式等输出的准确性与可靠性，尤其帮助对编程不熟悉的用户规避风险，呼吁后续实证研究完善该框架。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在代码和表格公式生成中表现强大，但常出现幻觉、逻辑错误和语法问题，尤其在财务建模和科学计算等高风险领域。这些问题威胁到输出的准确性和可靠性。

Method: 提出将测试驱动开发（TDD）方法与LLM生成结合，采用“先测试”方法作为技术和认知约束，通过明确的实验设计、测试驱动的提示示例和不同编程场景（如电子表格、Python、Rust）进行验证。

Result: 该框架旨在提升生成结果的准确性、可验证性和可理解性，增强用户信心。特别对于缺乏程序开发背景的表格用户，能有效规避逻辑失误带来的严重问题。同时推动培养计算思维和提示工程技能。

Conclusion: 以测试驱动思维为核心，可以提高LLM生成内容的质量和可靠性，为教育和职业开发实践中的LLM应用奠定负责任、可持续的基础，期待进一步合作和实证研究。

Abstract: Large Language Models (LLMs), such as ChatGPT, are increasingly leveraged for
generating both traditional software code and spreadsheet logic. Despite their
impressive generative capabilities, these models frequently exhibit critical
issues such as hallucinations, subtle logical inconsistencies, and syntactic
errors, risks particularly acute in high stakes domains like financial
modelling and scientific computations, where accuracy and reliability are
paramount. This position paper proposes a structured research framework that
integrates the proven software engineering practice of Test-Driven Development
(TDD) with Large Language Model (LLM) driven generation to enhance the
correctness of, reliability of, and user confidence in generated outputs. We
hypothesise that a "test first" methodology provides both technical constraints
and cognitive scaffolding, guiding LLM outputs towards more accurate,
verifiable, and comprehensible solutions. Our framework, applicable across
diverse programming contexts, from spreadsheet formula generation to scripting
languages such as Python and strongly typed languages like Rust, includes an
explicitly outlined experimental design with clearly defined participant
groups, evaluation metrics, and illustrative TDD based prompting examples. By
emphasising test driven thinking, we aim to improve computational thinking,
prompt engineering skills, and user engagement, particularly benefiting
spreadsheet users who often lack formal programming training yet face serious
consequences from logical errors. We invite collaboration to refine and
empirically evaluate this approach, ultimately aiming to establish responsible
and reliable LLM integration in both educational and professional development
practices.

</details>


### [7] [Selecting and Combining Large Language Models for Scalable Code Clone Detection](https://arxiv.org/abs/2510.15480)
*Muslim Chochlov,Gul Aftab Ahmed,James Vincent Patten,Yuanhua Han,Guoxian Lu,David Gregg,Jim Buckley*

Main category: cs.SE

TL;DR: 本文系统评测了76款LLM在代码克隆检测任务上的表现，发现无统一最优模型，但集成方法可显著提升检测精度。在商用大规模数据集上，最优集成模型精度达46.91%，远高于单一模型。


<details>
  <summary>Details</summary>
Motivation: 代码克隆可能导致知识产权风险和安全漏洞。现有规模化检测方法对差异克隆效果有限。随着LLM迅速发展，如何选择最优模型及其集成效能尚不明确。

Method: 作者筛选了76个LLM模型，挑选合适的用于代码克隆检测，并在BigCloneBench和商业大规模数据集上进行评测。然后研究了模型集成方法，包括分数归一化和不同集成策略（最大、求和、平均等）。

Result: 没有单一最优LLM，CodeT5+110M在商业数据集上的精度比CodeBERT高一倍（39.71%）；集成方法（特别是最大和求和）在大规模数据集上进一步提高精度至46.91%。

Conclusion: 作者发现没有统一最优的大语言模型（LLM）用于代码克隆检测，但通过模型集成可以在大规模商业数据集上获得更高的精度。集成方法如最大或求和比分数平均更有效。集成后精度从39.71%提升到46.91%。

Abstract: Source code clones pose risks ranging from intellectual property violations
to unintended vulnerabilities. Effective and efficient scalable clone
detection, especially for diverged clones, remains challenging. Large language
models (LLMs) have recently been applied to clone detection tasks. However, the
rapid emergence of LLMs raises questions about optimal model selection and
potential LLM-ensemble efficacy.
  This paper addresses the first question by identifying 76 LLMs and filtering
them down to suitable candidates for large-scale clone detection. The
candidates were evaluated on two public industrial datasets, BigCloneBench, and
a commercial large-scale dataset. No uniformly 'best-LLM' emerged, though
CodeT5+110M, CuBERT and SPTCode were top-performers. Analysis of LLM-candidates
suggested that smaller embedding sizes, smaller tokenizer vocabularies and
tailored datasets are advantageous. On commercial large-scale dataset a
top-performing CodeT5+110M achieved 39.71\% precision: twice the precision of
previously used CodeBERT.
  To address the second question, this paper explores ensembling of the
selected LLMs: effort-effective approach to improving effectiveness. Results
suggest the importance of score normalization and favoring ensembling methods
like maximum or sum over averaging. Also, findings indicate that ensembling
approach can be statistically significant and effective on larger datasets: the
best-performing ensemble achieved even higher precision of 46.91\% over
individual LLM on the commercial large-scale code.

</details>


### [8] [An Experimental Study of Real-Life LLM-Proposed Performance Improvements](https://arxiv.org/abs/2510.15494)
*Lirong Yi,Gregory Gay,Philipp Leitner*

Main category: cs.SE

TL;DR: 主流LLM可自动生成提升部分Java代码性能的补丁，但离人类开发者的最佳优化仍有差距，原创优化偶有突破但多不显著。


<details>
  <summary>Details</summary>
Motivation: 研究LLM生成代码在提升代码性能（而非仅功能正确）上的能力，以及与人类开发者优化的区别。

Method: 作者收集了65个开源Java程序实际任务，选择其中开发者已实现显著加速的问题，采用自动化流程和两种主流LLM在四种不同提示下生成修复补丁，并严格基准测试与对比人类方案。

Result: LLM代码多能提升性能，开发者优化显著优于LLM，两者优化思路二分之一一致，剩余三分之一LLM有原创性但仅偶尔显著提升性能。

Conclusion: LLM生成的代码大多数情况下能提升基线性能，但相比开发者的优化，LLM的修复仍存在显著差距，难以找到最优解。

Abstract: Large Language Models (LLMs) can generate code, but can they generate fast
code? In this paper, we study this question using a dataset of 65 real-world
tasks mined from open-source Java programs. We specifically select tasks where
developers achieved significant speedups, and employ an automated pipeline to
generate patches for these issues using two leading LLMs under four prompt
variations. By rigorously benchmarking the results against the baseline and
human-authored solutions, we demonstrate that LLM-generated code indeed
improves performance over the baseline in most cases. However, patches proposed
by human developers outperform LLM fixes by a statistically significant margin,
indicating that LLMs often fall short of finding truly optimal solutions. We
further find that LLM solutions are semantically identical or similar to the
developer optimization idea in approximately two-thirds of cases, whereas they
propose a more original idea in the remaining one-third. However, these
original ideas only occasionally yield substantial performance gains.

</details>


### [9] [Enhancing Code Review through Fuzzing and Likely Invariants](https://arxiv.org/abs/2510.15512)
*Wachiraphan Charoenwet,Patanamon Thongtanunam,Van-Thuan Pham,Christoph Treude*

Main category: cs.SE

TL;DR: FuzzSight结合非崩溃型fuzzing与不变量分析，显著提升了代码评审早期发现回归与漏洞的能力，优于传统静态方法，可有效辅助开发者聚焦有问题的代码。


<details>
  <summary>Details</summary>
Motivation: 传统代码评审主要依赖静态检查，难以捕捉动态行为，且在压力下易忽略潜在Bug；动态分析如fuzzing常被用于后期查找崩溃类缺陷，未能很好融合到早期评审流程。为此，需要一种方法将fuzzing动态数据转化为实际可用的评审信号。

Method: 提出了FuzzSight框架，将fuzzing生成的inputs与程序的动态不变量分析结合，用于发现不同版本代码的行为差异。在代码评审早期自动捕获和呈现程序的动态属性变化，从而辅助精准定位潜在缺陷。

Result: FuzzSight在实验中捕捉了75%的回归Bug和最高80%的漏洞，且在发现缺陷代码块的准确率上比传统静态工具高10倍，误报率更低。

Conclusion: FuzzSight证明了利用fuzzing和动态不变量分析在早期代码评审中发现行为异常的理论与实际价值，推动了静态与动态分析手段的融合，有助于提升代码质量和安全性。

Abstract: Many software projects employ manual code review to gatekeep defects and
vulnerabilities in the code before integration. However, reviewers often work
under time pressure and rely primarily on static inspection, leaving the
dynamic aspects of the program unexplored. Dynamic analyses could reveal such
behaviors, but they are rarely integrated into reviews. Among them, fuzzing is
typically applied later to uncover crashing bugs. Yet its ability to exercise
code with diverse inputs makes it promising for exposing non-crashing, but
unexpected, behaviors earlier. Still, without suitable mechanisms to analyze
program behaviors, the rich data produced during fuzzing remains inaccessible
to reviewers, limiting its practical value in this context.
  We hypothesize that unexpected variations in program behaviors could signify
potential bugs. The impact of code changes can be automatically captured at
runtime. Representing program behavior as likely invariants, dynamic properties
consistently observed at specific program points, can provide practical signals
of behavioral changes. Such signals offer a way to distinguish between intended
changes and unexpected behavioral shifts from code changes.
  We present FuzzSight, a framework that leverages likely invariants from
non-crashing fuzzing inputs to highlight behavioral differences across program
versions. By surfacing such differences, it provides insights into which code
blocks may need closer attention. In our evaluation, FuzzSight flagged 75% of
regression bugs and up to 80% of vulnerabilities uncovered by 24-hour fuzzing.
It also outperformed SAST in identifying buggy code blocks, achieving ten times
higher detection rates with fewer false alarms. In summary, FuzzSight
demonstrates the potential and value of leveraging fuzzing and invariant
analysis for early-stage code review, bridging static inspection with dynamic
behavioral insights.

</details>


### [10] [Colepp: uma ferramenta multiplataforma para coleta de dados de dispositivos vestiveis](https://arxiv.org/abs/2510.15565)
*Vinicius Moraes de Jesus,Andre Georghton Cardoso Pacheco*

Main category: cs.SE

TL;DR: 本文提出并实现了一款用于多可穿戴设备数据同步采集的开源工具Colepp，能够便捷生成高质量的同步数据集，为相关研究提供支持。


<details>
  <summary>Details</summary>
Motivation: 可穿戴设备（如智能手表、健身追踪器）普及，促使对可靠生理与运动数据采集工具的需求增长。但公开高质量大数据集稀缺，以及缺乏数据采集可控性，阻碍了相关算法发展。

Method: 提出Colepp：一款开源、跨平台的数据收集与同步工具，包括心率（ECG、PPG）与运动信号（加速度计、陀螺仪），通过智能手机作为中央枢纽，接收Polar H10胸带和Wear OS手表的数据，并导出为CSV文件。采用自定义同步协议和友好界面。

Result: Colepp能够生成可定制、适用于实际场景的人体活动识别、心率估算等研究的数据集。用例展示该工具能有效地生成一致且同步的信号。

Conclusion: Colepp为多设备数据采集与同步提供了简单高效的解决方案，推动可穿戴设备领域高质量数据集的建立，有助于相关算法的发展。

Abstract: The widespread adoption of wearable devices such as smartwatches and fitness
trackers has fueled the demand for reliable physiological and movement data
collection tools. However, challenges such as limited access to large,
high-quality public datasets and a lack of control over data collection
conditions hinder the development of robust algorithms. This work presents
Colepp, an open-source, cross-platform tool designed to collect and synchronize
data from multiple wearable devices, including heart rate (via ECG and PPG) and
motion signals (accelerometer and gyroscope). The system integrates a
smartphone as a central hub, receiving data from a Polar H10 chest strap and a
Wear OS smartwatch, and exporting synchronized datasets in CSV format. Through
a custom synchronization protocol and user-friendly interface, Colepp
facilitates the generation of customizable, real-world datasets suitable for
applications such as human activity recognition and heart rate estimation. A
use case shows the effectiveness of the tool in producing consistent and
synchronized signals.

</details>


### [11] [Interact and React: Exploring Gender Patterns in Development and the Impact on Innovation and Robustness of a User Interface Tool](https://arxiv.org/abs/2510.15642)
*Sian Brooke*

Main category: cs.SE

TL;DR: 研究基于React开源项目，发现女性开发者在功能创新和依赖管理上贡献较大，提升性别多样性对软件更具创新性和鲁棒性至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有的开源软件设计中，女性的参与常常被浮于表面提及，但很少有研究深入探讨增加性别多样性（尤其是女性参与）会如何根本改变开发模式。作者希望通过对女性参与的影响进行实证分析，以寻求更具包容性和创新的软件开发方式。

Method: 以React这一广泛应用的JavaScript库为案例，分析其11年间的活跃贡献者群体，通过性别维度对比软件‘鲁棒性与创新性’相关指标，以及主版本发布前后贡献模式的动态变化。

Result: 研究发现，排除女性参与对软件发展有害，因为女性在功能增强与依赖管理方面贡献突出。女性的参与明显促进了创新与软件稳健性。

Conclusion: 性别多样性（尤其是女性贡献的增加）能显著提升开源软件的包容性、创新性和鲁棒性。呼吁软件社区重视并推动性别平等，提高女性参与度，从而优化整体开发成果。

Abstract: In open-source software design, the inclusion of women is often highlighted
simply to remind programmers that women exist. Yet, little attention is given
to how greater gender diversity, specifically women's participation, could
fundamentally alter development patterns. To understand the potential impact of
gender inclusion, this study investigates React, a widely used JavaScript
library for building user interfaces with an active contributor community. I
examine gender differences in metrics of robustness and innovation, as well as
shifts in contribution patterns leading up to major version releases over 11
years of the React project. My results show that the exclusion of women is
detrimental to software as women contribute significantly more to feature
enhancement and dependency management. By exploring how gender influences
innovation and robustness in the development of React, the study offers
critical insights into how increasing gender diversity could lead to more
inclusive, innovative, and robust software.

</details>


### [12] [MirrorFuzz: Leveraging LLM and Shared Bugs for Deep Learning Framework APIs Fuzzing](https://arxiv.org/abs/2510.15690)
*Shiwen Ou,Yuwei Li,Lu Yu,Chengkun Wei,Tingke Wen,Qiangpu Chen,Yu Chen,Haizhi Tang,Zulie Pan*

Main category: cs.SE

TL;DR: 本文提出MirrorFuzz系统，自动识别和测试深度学习框架中的共性API漏洞。实验表明，其在主流框架中大幅提升了代码覆盖率，并发现了大量此前未知的漏洞。


<details>
  <summary>Details</summary>
Motivation: 深度学习（DL）框架作为AI应用的核心支撑，其内部Bug可能对更高层应用造成严重影响。然而，目前针对不同框架间API共性及其带来的潜在风险的研究较为有限。许多DL框架暴露了类似API，可能导致一处Bug蔓延至多个框架，带来共享漏洞风险。

Method: 本文提出MirrorFuzz，一种自动化API模糊测试方案。其流程包括三步：1）收集历史API漏洞数据找出潜在Bug API；2）在框架内外匹配功能相似的API；3）利用大语言模型（LLM）综合历史漏洞数据自动生成测试代码，以触发可能的共性Bug。并在TensorFlow、PyTorch、OneFlow、Jittor上实现和评估了MirrorFuzz。

Result: MirrorFuzz在TensorFlow和PyTorch上相较于现有技术分别提升了39.92%和98.20%的代码覆盖率。共发现315个Bug，其中262个为新发现；80个漏洞已被修复，其中52个分配到CNVD编号。

Conclusion: MirrorFuzz有效识别并挖掘了不同深度学习框架间的共性API缺陷，极大提升了测试覆盖率与Bug发现能力，说明跨框架共同漏洞的存在和可挖掘性。

Abstract: Deep learning (DL) frameworks serve as the backbone for a wide range of
artificial intelligence applications. However, bugs within DL frameworks can
cascade into critical issues in higher-level applications, jeopardizing
reliability and security. While numerous techniques have been proposed to
detect bugs in DL frameworks, research exploring common API patterns across
frameworks and the potential risks they entail remains limited. Notably, many
DL frameworks expose similar APIs with overlapping input parameters and
functionalities, rendering them vulnerable to shared bugs, where a flaw in one
API may extend to analogous APIs in other frameworks. To address this
challenge, we propose MirrorFuzz, an automated API fuzzing solution to discover
shared bugs in DL frameworks. MirrorFuzz operates in three stages: First,
MirrorFuzz collects historical bug data for each API within a DL framework to
identify potentially buggy APIs. Second, it matches each buggy API in a
specific framework with similar APIs within and across other DL frameworks.
Third, it employs large language models (LLMs) to synthesize code for the API
under test, leveraging the historical bug data of similar APIs to trigger
analogous bugs across APIs. We implement MirrorFuzz and evaluate it on four
popular DL frameworks (TensorFlow, PyTorch, OneFlow, and Jittor). Extensive
evaluation demonstrates that MirrorFuzz improves code coverage by 39.92\% and
98.20\% compared to state-of-the-art methods on TensorFlow and PyTorch,
respectively. Moreover, MirrorFuzz discovers 315 bugs, 262 of which are newly
found, and 80 bugs are fixed, with 52 of these bugs assigned CNVD IDs.

</details>


### [13] [EASELAN: An Open-Source Framework for Multimodal Biosignal Annotation and Data Management](https://arxiv.org/abs/2510.15767)
*Rathi Adarshi Rammohan,Moritz Meier,Dennis Küster,Tanja Schultz*

Main category: cs.SE

TL;DR: 本文提出了 EASELAN 标注框架，优化了多模态和生理信号数据的标注流程，集成了最新的工具和版控，已在认知机器人高维生理信号采集项目中检验，并将相关代码与数据库公开，有助于推动多模态数据处理领域的发展。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习和认知系统对高质量大规模多模态数据需求激增，融合模型对生理信号等多种通道需求复杂，现有工具难以满足标注流程的效率和易用性。

Method: 基于 ELAN 工具，开发了新的组件来支持数据标注流程的各个阶段，包括文件准备、渠道设置、版本管理（GitHub 集成）和后处理简化。应用于 DFG 资助的认知机器人高维生理信号收集任务。

Result: EASELAN 成功提升了多模态、生理信号标注的流程效率与集成能力，并在实际认知机器人活动标注项目中得到应用，公开的代码和数据库促进领域交流与研究。

Conclusion: EASELAN 框架能够有效应对多模态和生理信号数据集日益复杂的标注需求，推动相关研究的发展。其公开代码和数据库为学界提供了便利。

Abstract: Recent advancements in machine learning and adaptive cognitive systems are
driving a growing demand for large and richly annotated multimodal data. A
prominent example of this trend are fusion models, which increasingly
incorporate multiple biosignals in addition to traditional audiovisual
channels. This paper introduces the EASELAN annotation framework to improve
annotation workflows designed to address the resulting rising complexity of
multimodal and biosignals datasets. It builds on the robust ELAN tool by adding
new components tailored to support all stages of the annotation pipeline: From
streamlining the preparation of annotation files to setting up additional
channels, integrated version control with GitHub, and simplified
post-processing. EASELAN delivers a seamless workflow designed to integrate
biosignals and facilitate rich annotations to be readily exported for further
analyses and machine learning-supported model training. The EASELAN framework
is successfully applied to a high-dimensional biosignals collection initiative
on human everyday activities (here, table setting) for cognitive robots within
the DFG-funded Collaborative Research Center 1320 Everyday Activity Science and
Engineering (EASE). In this paper we discuss the opportunities, limitations,
and lessons learned when using EASELAN for this initiative. To foster research
on biosignal collection, annotation, and processing, the code of EASELAN is
publicly available(https://github.com/cognitive-systems-lab/easelan), along
with the EASELAN-supported fully annotated Table Setting Database.

</details>


### [14] [Towards Supporting Open Source Library Maintainers with Community-Based Analytics](https://arxiv.org/abs/2510.15794)
*Rachna Raj,Diego Elias Costa*

Main category: cs.SE

TL;DR: 作者实证分析了10个Java库及其生态依赖，发现仅16%的API被实际使用，且测试覆盖有限，提出新度量指标并通过实践者调查验证其价值，为OSS库的维护提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 开源软件（OSS）在现代软件开发中占据重要地位，OSS项目的维护者需要不断改进和调整他们的库。然而，他们通常无法持续获得关于下游项目实际如何使用其API的反馈。这种缺乏反馈限制了维护者做出更有效决策的能力。

Method: 作者提出使用社区驱动的分析手段，研究OSS库在其依赖生态系统中的具体使用情况。他们对10个流行的Java库及各自50个依赖项目进行了实证分析，并提出了两项衡量测试覆盖率的新指标，此外还对开源从业者进行了问卷调查。

Result: 分析结果发现，尽管库开发者提供了大量API方法，但实际上只有平均16%的方法被依赖生态实际使用。同时，只有74%的被使用API在测试套件中得到部分或全部覆盖。

Conclusion: 该论文显示当前大多数库的API仅有少量被广泛实际使用，测试套件的覆盖也不充分。通过提出社区使用度相关的测试度量指标，作者为库维护者提供了优化测试策略和维护决策的参考方法。

Abstract: Open-source software (OSS) is a pillar of modern software development. Its
success depends on the dedication of maintainers who work constantly to keep
their libraries stable, adapt to changing needs, and support a growing
community. Yet, they receive little to no continuous feedback on how the
projects that rely on their libraries actually use their APIs. We believe that
gaining these insights can help maintainers make better decisions, such as
refining testing strategies, understanding the impact of changes, and guiding
the evolution of their libraries more effectively. We propose the use of
community-based analytics to analyze how an OSS library is used across its
dependent ecosystem. We conduct an empirical study of 10 popular Java libraries
and each with their respective dependent ecosystem of 50 projects. Our results
reveal that while library developers offer a wide range of API methods, only
16% on average are actively used by their dependent ecosystem. Moreover, only
74% of the used API methods are partially or fully covered by their library
test suite. We propose two metrics to help developers evaluate their test suite
according to the APIs used by their community, and we conduct a survey on
open-source practitioners to assess the practical value of these insights in
guiding maintenance decisions.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [15] [ProofBridge: Auto-Formalization of Natural Language Proofs in Lean via Joint Embeddings](https://arxiv.org/abs/2510.15681)
*Prithwish Jana,Kaan Kale,Ahmet Ege Tanriverdi,Cruise Song,Sriram Vishwanath,Vijay Ganesh*

Main category: cs.LO

TL;DR: ProofBridge提出了一种将自然语言定理及证明自动转译为Lean 4的统一方法，通过联合嵌入和检索机制，实现端到端高效自动化形式化，大幅超越当前主流模型（如GPT-5、Gemini-2.5等），在新数据集测试上取得显著性能提升，推进了数学自动形式化技术进展。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化方法普遍将定理翻译和证明生成分开处理，导致无法实现端到端自动化形式化，且存在人工大量干预问题。

Method: ProofBridge采用联合嵌入模型，将自然语言与形式语言的定理-证明对在共享语义空间中对齐，并通过跨模态检索召回相关例子辅助翻译，结合检索增强微调与迭代式证明修复，利用Lean类型检查和语义等价反馈保证正确性。

Result: 在miniF2F-Test-PF数据集上，ProofBridge在语义正确率和类型正确率等指标上较强基线显著提升。其中跨模态检索质量提升至Recall@1最多3.28倍，并在pass@32指标上分别较Kimina-Prover-RL-1.7B提升31.14%语义正确率和1.64%类型正确率。

Conclusion: ProofBridge显著提升了自然语言到Lean 4自动化定理和证明转化的正确性及效率，明显优于现有主流方法。

Abstract: Translating human-written mathematical theorems and proofs from natural
language (NL) into formal languages (FLs) like Lean 4 has long been a
significant challenge for AI. Most state-of-the-art methods address this
separately, first translating theorems and then generating proofs, creating a
fundamental disconnect vis-a-vis true proof auto-formalization. This two-step
process and its limitations were evident even in AlphaProof's silver-medal
performance at the 2024 IMO, where problem statements needed manual translation
before automated proof synthesis.
  We present ProofBridge, a unified framework for automatically translating
entire NL theorems and proofs into Lean 4. At its core is a joint embedding
model that aligns NL and FL (NL-FL) theorem-proof pairs in a shared semantic
space, enabling cross-modal retrieval of semantically relevant FL examples to
guide translation. Our training ensures that NL-FL theorems (and their proofs)
are mapped close together in this space if and only if the NL-FL pairs are
semantically equivalent. ProofBridge integrates retrieval-augmented fine-tuning
with iterative proof repair, leveraging Lean's type checker and semantic
equivalence feedback to ensure both syntactic correctness and semantic
fidelity. Experiments show substantial improvements in proof auto-formalization
over strong baselines (including GPT-5, Gemini-2.5, Kimina-Prover,
DeepSeek-Prover), with our retrieval-augmented approach yielding significant
gains in semantic correctness (SC, via proving bi-directional equivalence) and
type correctness (TC, via type-checking theorem+proof) across pass@k metrics on
miniF2F-Test-PF, a dataset we curated. In particular, ProofBridge improves
cross-modal retrieval quality by up to 3.28x Recall@1 over all-MiniLM-L6-v2,
and achieves +31.14% SC and +1.64% TC (pass@32) compared to the baseline
Kimina-Prover-RL-1.7B.

</details>


### [16] [Weakening Goals in Logical Specifications](https://arxiv.org/abs/2510.15718)
*Ben M. Andrew*

Main category: cs.LO

TL;DR: 面对系统退化或不确定环境无法证明原有性质时，本文提出了一种类反例引导的逻辑规格弱化方法，使得分析和验证复杂系统更加可行和灵活。


<details>
  <summary>Details</summary>
Motivation: 传统的软件系统逻辑验证方法在复杂真实环境下（如机器人系统）因为系统退化或环境变化容易失效，无法证明原有性质，此时仍需对系统性能作出可靠分析。

Method: 提出了一种基于反例引导（counterexample-guided）的技术，能够迭代式地削弱/弱化逻辑性质，应用于命题逻辑规格，并计划扩展到状态基础表示。

Result: 该方法可以在原性质不再成立时，得出一些较弱（但有用）的性质描述，有助于解释复杂系统在不确定环境下的行为，并支持组合性验证。

Conclusion: 文中提出的反例引导弱化规格技术为面对不稳定复杂系统时的验证问题提供了一种新的解决思路，可以用更宽松的性质对系统做出分析，有助于实际应用。

Abstract: Logical specifications are widely used to represent software systems and
their desired properties. Under system degradation or environmental changes,
commonly seen in complex real-world robotic systems, these properties may no
longer hold and so traditional verification methods will simply fail to
construct a proof. However, weaker versions of these properties do still hold
and can be useful for understanding the system's behaviour in uncertain
conditions, as well as aiding compositional verification. We present a
counterexample-guided technique for iteratively weakening properties, apply it
to propositional logic specifications, and discuss planned extensions to
state-based representations.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [17] [Rethinking Toxicity Evaluation in Large Language Models: A Multi-Label Perspective](https://arxiv.org/abs/2510.15007)
*Zhiqiang Kou,Junyang Chen,Xin-Qiang Cai,Ming-Kun Xie,Biao Liu,Changwei Wang,Lei Feng,Yuheng Jia,Gang Niu,Masashi Sugiyama,Xin Geng*

Main category: cs.CL

TL;DR: 本文提出三大多标签毒性检测基准和基于伪标签的新方法，在多维毒性识别上远超现有主流检测器，有效提高了对大语言模型生成有害内容的评估准确性和全面性。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）在自然语言处理领域取得优异表现，但在有害内容生成方面引发安全担忧。当前的毒性检测器通常仅依赖单标签基准，无法全面捕捉现实世界中有害提示的多维特性，导致偏差评估和误报，影响检测器的可靠性。同时，获取多标签、细粒度的毒性注释成本过高，也限制了毒性检测技术的进一步发展。

Method: 作者提出了三种新型多标签毒性检测基准（Q-A-MLL、R-A-MLL、H-X-MLL），从公开毒性数据集中构建，并根据详细的15类毒性分类体系进行注释。同时，提供理论证明：在所发布数据集上，利用伪标签训练比单标签监督学习表现更佳，并提出基于伪标签的毒性检测方法。

Result: 大量实验结果表明，提出的方法在多标签毒性检测任务上明显优于现有高水平方法（如GPT-4o和DeepSeek），能更准确可靠地评估LLM生成内容的毒性。

Conclusion: 本文创新性地解决了单标签毒性检测方法在评估多维毒性时的局限性，提出了更细致和高效的多标签基准和检测方法，提高了大语言模型生成内容毒性检测的准确性和可靠性。

Abstract: Large language models (LLMs) have achieved impressive results across a range
of natural language processing tasks, but their potential to generate harmful
content has raised serious safety concerns. Current toxicity detectors
primarily rely on single-label benchmarks, which cannot adequately capture the
inherently ambiguous and multi-dimensional nature of real-world toxic prompts.
This limitation results in biased evaluations, including missed toxic
detections and false positives, undermining the reliability of existing
detectors. Additionally, gathering comprehensive multi-label annotations across
fine-grained toxicity categories is prohibitively costly, further hindering
effective evaluation and development. To tackle these issues, we introduce
three novel multi-label benchmarks for toxicity detection: \textbf{Q-A-MLL},
\textbf{R-A-MLL}, and \textbf{H-X-MLL}, derived from public toxicity datasets
and annotated according to a detailed 15-category taxonomy. We further provide
a theoretical proof that, on our released datasets, training with pseudo-labels
yields better performance than directly learning from single-label supervision.
In addition, we develop a pseudo-label-based toxicity detection method.
Extensive experimental results show that our approach significantly surpasses
advanced baselines, including GPT-4o and DeepSeek, thus enabling more accurate
and reliable evaluation of multi-label toxicity in LLM-generated content.

</details>


### [18] [Can generative AI figure out figurative language? The influence of idioms on essay scoring by ChatGPT, Gemini, and Deepseek](https://arxiv.org/abs/2510.15009)
*Enis Oğuz*

Main category: cs.CL

TL;DR: 本文比较了三款生成式AI模型对含习语及不含习语学生作文的自动评分效果，发现Gemini在评分一致性和贴近人工评分方面表现最佳，且无检测到评分偏见。结果显示，Gemini有望独立完成高质量自动评分任务，推动自动作文评分的发展。


<details>
  <summary>Details</summary>
Motivation: 近年来，生成式人工智能（Generative AI）技术迅猛发展，被倡议为自动评测学生作文的一种新选择，特别是在处理包含习语的作文时，传统自动评分系统可能有一定局限。本研究旨在探讨生成式人工智能在评分含习语与不含习语作文时的表现，通过结合语料库语言学和计算语言学的观点，对多种主流生成式AI模型进行评估。

Method: 研究从一个语料库中筛选出348份学生作文，平均分为两组，一组每篇作文包含多个习语，另一组则完全不含习语。选用三种生成式AI模型（ChatGPT、Gemini、Deepseek），对所有作文分别进行三轮评分，所有评分均采用与人工评分相同的评分标准，随后与人工评分的一致性及群体偏差进行对比分析。

Result: 三种生成式AI模型在作文评分结果上表现出高度一致性，但Gemini模型在与人工评分的一致性（信度）方面胜出。此外，三种模型在评分过程中未检测到对任何特定人群的评分偏见。在处理包含多个习语的作文时，Gemini的评分最贴近人类评分者的模式。

Conclusion: 生成式AI模型在作文自动评分领域展现出良好的潜力，尤其Gemini模型在处理习语和具象语言时表现突出，是未来实现高质量自动作文评分的有力候选，其评分结果可靠且无明显人口统计偏见，值得推广应用。

Abstract: The developments in Generative AI technologies have paved the way for
numerous innovations in different fields. Recently, Generative AI has been
proposed as a competitor to AES systems in evaluating student essays
automatically. Considering the potential limitations of AI in processing
idioms, this study assessed the scoring performances of Generative AI models
for essays with and without idioms by incorporating insights from Corpus
Linguistics and Computational Linguistics. Two equal essay lists were created
from 348 student essays taken from a corpus: one with multiple idioms present
in each essay and another with no idioms in essays. Three Generative AI models
(ChatGPT, Gemini, and Deepseek) were asked to score all essays in both lists
three times, using the same rubric used by human raters in assigning essay
scores. The results revealed excellent consistency for all models, but Gemini
outperformed its competitors in interrater reliability with human raters. There
was also no detectable bias for any demographic group in AI assessment. For
essays with multiple idioms, Gemini followed a the most similar pattern to
human raters. While the models in the study demonstrated potential for a hybrid
approach, Gemini was the best candidate for the task due to its ability to
handle figurative language and showed promise for handling essay-scoring tasks
alone in the future.

</details>


### [19] [A Generalizable Rhetorical Strategy Annotation Model Using LLM-based Debate Simulation and Labelling](https://arxiv.org/abs/2510.15081)
*Shiyu Ji,Farnoosh Hashemi,Joice Chen,Juanwen Pan,Weicheng Ma,Hefan Zhang,Sophia Pan,Ming Cheng,Shubham Mohole,Saeed Hassanpour,Soroush Vosoughi,Michael Macy*

Main category: cs.CL

TL;DR: 本文提出利用大语言模型自动生成与标注辩论修辞数据，从而突破人工标注的局限；通过微调模型成功提升跨领域修辞识别与说服力预测，并揭示美国总统辩论中情感型修辞的上升趋势。


<details>
  <summary>Details</summary>
Motivation: 以往修辞策略分析依赖人工标注，成本高、效率低且可扩展性差，且相应数据集主题有限、策略单一，限制了模型的稳健发展。作者希望借助自动化与大模型技术打破这些瓶颈。

Method: 提出基于大型语言模型（LLMs）的新框架，自动生成并标注基于四类修辞策略（因果、经验、情感、道德）的合成辩论数据。利用这些LLM标注的数据微调Transformer分类器，并通过人类标注数据及多个外部语料库验证模型性能和泛化能力。

Result: 微调模型在多个主题领域获得了高性能和良好的泛化能力，并在两个应用场景中表现突出：（1）利用修辞策略标签提升了说服力预测效果；（2）分析美国总统辩论中修辞策略的时间和党派变迁，揭示情感型辩论明显增加。

Conclusion: 证明通过LLM自动标注和合成数据驱动的模型，不但提升了辩论修辞策略检测的泛化能力，也为研究和应用相关议题提供了高效且可靠的工具。

Abstract: Rhetorical strategies are central to persuasive communication, from political
discourse and marketing to legal argumentation. However, analysis of rhetorical
strategies has been limited by reliance on human annotation, which is costly,
inconsistent, difficult to scale. Their associated datasets are often limited
to specific topics and strategies, posing challenges for robust model
development. We propose a novel framework that leverages large language models
(LLMs) to automatically generate and label synthetic debate data based on a
four-part rhetorical typology (causal, empirical, emotional, moral). We
fine-tune transformer-based classifiers on this LLM-labeled dataset and
validate its performance against human-labeled data on this dataset and on
multiple external corpora. Our model achieves high performance and strong
generalization across topical domains. We illustrate two applications with the
fine-tuned model: (1) the improvement in persuasiveness prediction from
incorporating rhetorical strategy labels, and (2) analyzing temporal and
partisan shifts in rhetorical strategies in U.S. Presidential debates
(1960-2020), revealing increased use of affective over cognitive argument in
U.S. Presidential debates.

</details>


### [20] [Continual Learning via Sparse Memory Finetuning](https://arxiv.org/abs/2510.15103)
*Jessy Lin,Luke Zettlemoyer,Gargi Ghosh,Wen-Tau Yih,Aram Markosyan,Vincent-Pierre Berges,Barlas Oğuz*

Main category: cs.CL

TL;DR: 本文通过稀疏记忆微调方法，有效降低了大语言模型在持续学习新知识时的灾难性遗忘风险，相比主流办法有明显优势。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在部署后通常保持静态，难以持续学习，主要原因是灾难性遗忘：新知识的更新会覆盖已有能力。动机在于通过参数更新的稀疏性来减少遗忘。

Method: 提出了稀疏记忆微调（Sparse Memory Finetuning）方法，基于记忆层模型，仅对那些被新知识高度激活的记忆槽进行更新，显著降低新旧知识之间的干扰。与全量微调和LoRA高效微调进行对比实验。

Result: 在两个问答任务上，稀疏记忆微调能够在学习新知识的同时显著减少遗忘。例如，微调后NaturalQuestions任务F1分数的下降仅为11%，而全量微调下降89%，LoRA下降71%。

Conclusion: 稀疏性在记忆层中能够有效缓解灾难性遗忘，为大语言模型的持续学习提供了新的可能路径。

Abstract: Modern language models are powerful, but typically static after deployment. A
major obstacle to building models that continually learn over time is
catastrophic forgetting, where updating on new data erases previously acquired
capabilities. Motivated by the intuition that mitigating forgetting is
challenging because trainable parameters are shared across all tasks, we
investigate whether sparse parameter updates can enable learning without
catastrophic forgetting. We introduce sparse memory finetuning, leveraging
memory layer models (Berges et al., 2024), which are sparsely updated by
design. By updating only the memory slots that are highly activated by a new
piece of knowledge relative to usage on pretraining data, we reduce
interference between new knowledge and the model's existing capabilities. We
evaluate learning and forgetting compared to full finetuning and
parameter-efficient finetuning with LoRA on two question answering tasks. We
find that sparse memory finetuning learns new knowledge while exhibiting
substantially less forgetting: while NaturalQuestions F1 drops by 89% after
full finetuning on new facts and 71% with LoRA, sparse memory finetuning yields
only an 11% drop with the same level of new knowledge acquisition. Our results
suggest sparsity in memory layers offers a promising path toward continual
learning in large language models.

</details>


### [21] [Measuring the Effect of Disfluency in Multilingual Knowledge Probing Benchmarks](https://arxiv.org/abs/2510.15115)
*Kirill Semenov,Rico Sennrich*

Main category: cs.CL

TL;DR: 本研究发现，多语种知识评估数据集若采纳语法更贴合目标语言的句子级翻译，将显著提升大模型知识检索准确率，尤其适用于形态丰富语言，建议未来相关基准均采用此方法。


<details>
  <summary>Details</summary>
Motivation: 现有多语言大模型知识评估基准（如 MLAMA）通过模板翻译生成测试语句，但未考虑插入实体的语法和语义特征，导致许多语句语法错误或措辞不当，影响打分结果的可解释性，尤其是形态变化丰富的语言。

Method: 从 MLAMA 数据集中选取 4 种斯拉夫语，比较初始模板式语句与使用 Google Translate 和 ChatGPT 生成的句子级翻译之间的大模型知识检索得分，并对提升原因进行定性分析；另对来自不同语系的 5 种语言做类似分析。

Result: 使用句子级、语法更符合目标语言的翻译方式，知识检索得分显著提升，并在不同语系的多种语言中得到类似结果。

Conclusion: 提升多语种数据集的语法准确性（如全句级机器翻译或 LLM 翻译）能有效提高模型评估准确性和结果可解释性，推荐社区采用此方法优化数据集。

Abstract: For multilingual factual knowledge assessment of LLMs, benchmarks such as
MLAMA use template translations that do not take into account the grammatical
and semantic information of the named entities inserted in the sentence. This
leads to numerous instances of ungrammaticality or wrong wording of the final
prompts, which complicates the interpretation of scores, especially for
languages that have a rich morphological inventory. In this work, we sample 4
Slavic languages from the MLAMA dataset and compare the knowledge retrieval
scores between the initial (templated) MLAMA dataset and its sentence-level
translations made by Google Translate and ChatGPT. We observe a significant
increase in knowledge retrieval scores, and provide a qualitative analysis for
possible reasons behind it. We also make an additional analysis of 5 more
languages from different families and see similar patterns. Therefore, we
encourage the community to control the grammaticality of highly multilingual
datasets for higher and more interpretable results, which is well approximated
by whole sentence translation with neural MT or LLM systems. The dataset and
all related code is published at the Github repository:
https://github.com/ZurichNLP/Fluent-mLAMA.

</details>


### [22] [Latent Topic Synthesis: Leveraging LLMs for Electoral Ad Analysis](https://arxiv.org/abs/2510.15125)
*Alexander Brady,Tunazzina Islam*

Main category: cs.CL

TL;DR: 本论文提出一种无需先验知识、兼具可扩展性和可解释性的话题分类方法，成功应用于2024年美选政治广告，揭示极化、资金分布及道德语境等多维度规律，有助于深入理解社媒时代政治传播。


<details>
  <summary>Details</summary>
Motivation: 随着社交媒体在塑造政治话语中的关键作用不断增强，如何对其海量且不断变化的内容进行有效分析成为一大挑战，尤其是在缺乏标注和领域知识的情况下。

Method: 提出了一个端到端自动生成可解释话题分类体系的框架，通过将无监督聚类和基于prompt的大语言模型标签方法结合，实现对无标注语料自动迭代构建话题体系，无需领域知识与预设领域词表。

Result: 该方法对2024年美国总统大选前一个月的大规模Meta（前Facebook）政治广告进行分析，识别出投票和移民广告在花费与曝光量上占主导，堕胎和选举诚信议题则获得不成比例的高关注度。进一步揭示了资金分化、议题极化、不同广告采取的道德叙事等特征，并发现强烈的道德基础与议题关联及人口定向策略。

Conclusion: 提出的框架可对社交媒体上的政治传播进行大规模、可解释分析，揭示新兴叙事、极化动态和道德基础，为学者、政策制定者与公众理解数字政治交流提供有力工具。

Abstract: Social media platforms play a pivotal role in shaping political discourse,
but analyzing their vast and rapidly evolving content remains a major
challenge. We introduce an end-to-end framework for automatically generating an
interpretable topic taxonomy from an unlabeled corpus. By combining
unsupervised clustering with prompt-based labeling, our method leverages large
language models (LLMs) to iteratively construct a taxonomy without requiring
seed sets or domain expertise. We apply this framework to a large corpus of
Meta (previously known as Facebook) political ads from the month ahead of the
2024 U.S. Presidential election. Our approach uncovers latent discourse
structures, synthesizes semantically rich topic labels, and annotates topics
with moral framing dimensions. We show quantitative and qualitative analyses to
demonstrate the effectiveness of our framework. Our findings reveal that voting
and immigration ads dominate overall spending and impressions, while abortion
and election-integrity achieve disproportionate reach. Funding patterns are
equally polarized: economic appeals are driven mainly by conservative PACs,
abortion messaging splits between pro- and anti-rights coalitions, and
crime-and-justice campaigns are fragmented across local committees. The framing
of these appeals also diverges--abortion ads emphasize liberty/oppression
rhetoric, while economic messaging blends care/harm, fairness/cheating, and
liberty/oppression narratives. Topic salience further reveals strong
correlations between moral foundations and issues. Demographic targeting also
emerges. This work supports scalable, interpretable analysis of political
messaging on social media, enabling researchers, policymakers, and the public
to better understand emerging narratives, polarization dynamics, and the moral
underpinnings of digital political communication.

</details>


### [23] [FarsiMCQGen: a Persian Multiple-choice Question Generation Framework](https://arxiv.org/abs/2510.15134)
*Mohammad Heydari Rad,Rezvan Afari,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 该论文提出了一种高效自动生成波斯语选择题的方法，并制作了大规模数据集，实验证明模型及数据集质量优异，促进低资源语言考试题建设。


<details>
  <summary>Details</summary>
Motivation: 在教育测试中，选择题由于其高效评估学生知识的能力被广泛应用，但在资源有限的语言（如波斯语）中，生成高质量选择题面临重大挑战。

Method: 提出了一种新的波斯语选择题生成方法FarsiMCQGen，结合了候选项生成、过滤和排序技术，通过Transformer、知识图和基于规则的方法生成高可信度的干扰项。

Result: 构建了一个包含10289个问题的波斯语选择题数据集，并通过多种先进的大语言模型进行质量评估，结果显示该模型和数据集生成质量高。

Conclusion: FarsiMCQGen可有效自动生成高质量的波斯语选择题及干扰项，提升低资源语言的题目研发能力，助推相关领域进一步研究。

Abstract: Multiple-choice questions (MCQs) are commonly used in educational testing, as
they offer an efficient means of evaluating learners' knowledge. However,
generating high-quality MCQs, particularly in low-resource languages such as
Persian, remains a significant challenge. This paper introduces FarsiMCQGen, an
innovative approach for generating Persian-language MCQs. Our methodology
combines candidate generation, filtering, and ranking techniques to build a
model that generates answer choices resembling those in real MCQs. We leverage
advanced methods, including Transformers and knowledge graphs, integrated with
rule-based approaches to craft credible distractors that challenge test-takers.
Our work is based on data from Wikipedia, which includes general knowledge
questions. Furthermore, this study introduces a novel Persian MCQ dataset
comprising 10,289 questions. This dataset is evaluated by different
state-of-the-art large language models (LLMs). Our results demonstrate the
effectiveness of our model and the quality of the generated dataset, which has
the potential to inspire further research on MCQs.

</details>


### [24] [Structure-R1: Dynamically Leveraging Structural Knowledge in LLM Reasoning through Reinforcement Learning](https://arxiv.org/abs/2510.15191)
*Junlin Wu,Xianrui Zhong,Jiashuo Sun,Bolian Li,Bowen Jin,Jiawei Han,Qingkai Zeng*

Main category: cs.CL

TL;DR: 本文提出了Structure-R1框架，通过强化学习和结构验证，将检索信息转化为适应多步推理的结构化表示，有效提升了7B模型在多项知识密集任务中的推理与表现，结果可媲美更大模型，理论与实验数据均支持结构化表示的优势。


<details>
  <summary>Details</summary>
Motivation: 传统RAG虽然能够引入外部信息为大模型推理提供上下文，但多依赖非结构化且信息分散的文本，导致信息密度低、推理效果差。因此，研究如何将检索内容转化为结构化表示以优化推理过程。

Method: 提出了以强化学习驱动的结构化内容生成策略，能够针对具体任务和查询动态生成和适应内容结构格式。引入自我奖励机制进行结构验证以确保生成内容的正确性和独立完整性。

Result: 在七个知识密集型基准测试上，Structure-R1用7B的模型取得了与更大规模模型相当的竞争性表现；理论分析也佐证了结构化表示对提升推理信息密度和上下文清晰度的积极作用。

Conclusion: 所提出的Structure-R1框架能够提升大模型在知识密集任务中的信息利用效率和推理能力。即使使用7B规模的模型也能达到与更大模型相当的效果。结构化表示能够有效改善信息密度和上下文清晰度，从理论和实验均有支撑。

Abstract: Large language models (LLMs) have demonstrated remarkable advances in
reasoning capabilities. However, their performance remains constrained by
limited access to explicit and structured domain knowledge. Retrieval-Augmented
Generation (RAG) addresses this by incorporating external information as
context to augment reasoning. Nevertheless, traditional RAG systems typically
operate over unstructured and fragmented text, resulting in low information
density and suboptimal reasoning. To overcome these limitations, we propose
\textsc{Structure-R1}, a novel framework that transforms retrieved content into
structured representations optimized for reasoning. Leveraging reinforcement
learning, \textsc{Structure-R1} learns a content representation policy that
dynamically generates and adapts structural formats based on the demands of
multi-step reasoning. Unlike prior methods that rely on fixed schemas, our
approach adopts a generative paradigm capable of producing task-specific
structures tailored to individual queries. To ensure the quality and
reliability of these representations, we introduce a self-reward structural
verification mechanism that checks whether the generated structures are both
correct and self-contained. Extensive experiments on seven knowledge-intensive
benchmarks show that \textsc{Structure-R1} consistently achieves competitive
performance with a 7B-scale backbone model and matches the performance of much
larger models. Additionally, our theoretical analysis demonstrates how
structured representations enhance reasoning by improving information density
and contextual clarity. Our code and data are available at:
https://github.com/jlwu002/sr1.

</details>


### [25] [Extending Audio Context for Long-Form Understanding in Large Audio-Language Models](https://arxiv.org/abs/2510.15231)
*Yuatyong Chaichana,Pittawat Taveekitworachai,Warit Sirichotedumrong,Potsawee Manakul,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 本论文提出了一种无需训练即可扩展音频上下文的Partial YaRN方法，并进一步结合训练阶段的VLAT策略，大幅提升音频-语言大模型对超长音频的理解与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前的大型音频-语言模型（LALMs）虽然具备强大的文本长上下文处理能力，但在音频上下文窗口长度上受到限制，这限制了其对长音频的理解能力。此前有方法扩展单一模态的语言模型上下文，但这些方法尚未应用于音频-语言模型。

Method: 1. 基于RoPE的位置扩展方法，提出了无需重新训练的Partial YaRN方法，仅修改音频token的位置编码，保持文本部分不变，从而保护原有LLM文本能力。
2. 提出训练时的虚拟长音频训练（VLAT）策略，将Partial YaRN在训练阶段实现位置增强，通过模拟不同长度音频进行训练，提高模型泛化和鲁棒性。

Result: 在SALMONN和Qwen2-Audio两个模型上的实验表明，Partial YaRN方法在多种场景下性能优于原始模型，而VLAT训练策略在处理未见过的长音频时表现更为出色，显著提升了模型的长音频理解能力。

Conclusion: 提出的方法有效扩展了大型音频-语言模型对长音频的理解能力，同时保持了其文本处理性能，特别是在训练与推理阶段不同音频长度下均显示出良好泛化和鲁棒性。

Abstract: Large Audio-Language Models (LALMs) are often constrained by short audio
context windows, even when their text backbones support long contexts, limiting
long-form audio understanding. Prior work has introduced context-extension
methods (e.g. YaRN) on unimodal LLMs, yet their application to LALMs remains
unexplored. First, building on RoPE-based context extension, we introduce
Partial YaRN, a training-free, audio-only extension method that modifies only
audio token positions, leaving text positions intact to preserve the base LLM's
text capabilities. Second, we propose Virtual Longform Audio Training (VLAT), a
training strategy that extends Partial YaRN into a training-time positional
augmentation. VLAT simulates diverse audio lengths during training, enabling
generalization to inputs far longer than those seen in training and improving
robustness for long-context audio understanding. Our experiments on SALMONN and
Qwen2-Audio show that Partial YaRN outperforms the original models across wide
range of settings, and VLAT training strategy provides substantial improvement,
achieving strong performance on long audio of unseen lengths.

</details>


### [26] [Planner and Executor: Collaboration between Discrete Diffusion And Autoregressive Models in Reasoning](https://arxiv.org/abs/2510.15244)
*Lina Berrayana,Ahmed Heakl,Muhammad Abdullah Sohail,Thomas Hofmann,Salman Khan,Wei Chen*

Main category: cs.CL

TL;DR: 本文提出融合DDLM与ARM的混合模型，尤其通过潜在空间通信，显著提升推理准确率并大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 虽然ARMs在准确率上表现强劲，但推理成本高；DDLMs能高效并行推理，但生成局限。探索两者结合是否能兼顾准确率和效率。

Method: 提出混合架构，将DDLMs与ARMs结合，分别在文本空间和潜在空间进行协作，并引入学习投影器实现两者潜在空间的连接。

Result: 1）潜在空间下DDLM到ARM的协作显著提升准确率（如DART-5由27.0%升至54.0%）；2）混合管道能极大减少计算消耗，在保持甚至提升准确率的同时，远低于主流模型的token数。

Conclusion: 将DDLM和ARM结合，尤其是在潜在空间中的通信，有助于提升推理任务中的准确率与计算效率。

Abstract: Current autoregressive language models (ARMs) achieve high accuracy but
require long token sequences, making them costly. Discrete diffusion language
models (DDLMs) enable parallel and flexible generation within a fixed number of
steps and have recently emerged for their strong performance in complex
reasoning and long-term planning tasks. We present a study exploring hybrid
architectures that couple DDLMs with ARMs to assess whether their collaboration
can yield complementary benefits. We first examine collaboration in text space,
where one model plans the reasoning process and another executes the final
answer based on that plan. We then extend this setup to latent-space
communication, introducing a learned projector that maps DDLM latents into the
ARM's embedding space, potentially bypassing some of the text-generation
limitations of diffusion models. We find that shifting DDLM --> ARM
communication from text space to latent space yields significant accuracy
gains, for example increasing from 27.0% to 54.0% on DART-5 and from 0.0% to
14.0% on AIME24. We also find that combining a DDLM planner with an ARM
executor can provide substantial computational savings with little to no impact
on accuracy. For example, the latent-space pipeline, using 64 tokens for
planning and roughly 5 for execution, surpasses Qwen3.1-7B on DART-5 and AIME,
despite Qwen using 44 times more tokens. Overall, our study offers new insights
into reasoning with DDLMs and highlights their potential in hybrid
architectures.

</details>


### [27] [Scaling Beyond Context: A Survey of Multimodal Retrieval-Augmented Generation for Document Understanding](https://arxiv.org/abs/2510.15253)
*Sensen Gao,Shanshan Zhao,Xu Jiang,Lunhao Duan,Yong Xien Chng,Qing-Guo Chen,Weihua Luo,Kaifu Zhang,Jia-Wang Bian,Mingming Gong*

Main category: cs.CL

TL;DR: 本文系统综述了多模态RAG在文档智能中的发展与挑战，提出分类方法、总结技术进展与数据资源，并为后续研究提供发展路线图。


<details>
  <summary>Details</summary>
Motivation: 由于当前文档理解方法（包括OCR-LLM管道和原生多模态LLM）在结构还原和上下文建模上存在局限，且文档本身常包含文本、表格、图表及布局等多模态信息，亟需更高级的多模态检索-生成（RAG）范式以实现全面智能化理解。

Method: 提出基于领域、检索模态和粒度的分类方法，系统回顾了近年来多模态RAG中的相关进展，包括图结构和智能体框架，综述了关键数据集、基准与应用。

Result: 梳理了多模态RAG的最新进展，构建了相应的领域分类法，回顾了图结构与智能体等技术基础，汇总主要数据集、评测与实际应用，同时指出当前在效率、细粒度表示和鲁棒性上的挑战。

Conclusion: 综述提出了一种系统性的多模态RAG框架，并为文档智能领域未来的发展指出了方向与挑战。

Abstract: Document understanding is critical for applications from financial analysis
to scientific discovery. Current approaches, whether OCR-based pipelines
feeding Large Language Models (LLMs) or native Multimodal LLMs (MLLMs), face
key limitations: the former loses structural detail, while the latter struggles
with context modeling. Retrieval-Augmented Generation (RAG) helps ground models
in external data, but documents' multimodal nature, i.e., combining text,
tables, charts, and layout, demands a more advanced paradigm: Multimodal RAG.
This approach enables holistic retrieval and reasoning across all modalities,
unlocking comprehensive document intelligence. Recognizing its importance, this
paper presents a systematic survey of Multimodal RAG for document
understanding. We propose a taxonomy based on domain, retrieval modality, and
granularity, and review advances involving graph structures and agentic
frameworks. We also summarize key datasets, benchmarks, and applications, and
highlight open challenges in efficiency, fine-grained representation, and
robustness, providing a roadmap for future progress in document AI.

</details>


### [28] [TraceCoder: Towards Traceable ICD Coding via Multi-Source Knowledge Integration](https://arxiv.org/abs/2510.15267)
*Mucheng Ren,He Chen,Yuchen Yan,Danqing Hu,Jun Xu,Xian Zeng*

Main category: cs.CL

TL;DR: TraceCoder通过多源知识整合和混合注意力机制显著提升自动化ICD编码的准确性和解释性，尤其在稀有和长尾编码上表现优异，实验验证其为医疗领域自动编码的领先方法。


<details>
  <summary>Details</summary>
Motivation: 自动化ICD编码对医疗系统至关重要，但现有方法存在临床文本与编码之间语义鸿沟、对稀有和长尾编码表现差、可解释性有限等问题。

Method: 提出TraceCoder框架，通过整合多源外部知识（包括UMLS、Wikipedia和大型语言模型），丰富编码表示，动态填补语义鸿沟，并采用混合注意力机制，建模标签、临床文本和知识间交互，提高长尾编码识别能力和模型可解释性。

Result: 在MIMIC-III-ICD9、MIMIC-IV-ICD9和MIMIC-IV-ICD10数据集上的实验表明，TraceCoder性能达到最新水平，消融实验验证了各组件的有效性。

Conclusion: TraceCoder为自动化ICD编码提供了可扩展、鲁棒且具备临床所需高准确性、可解释性、可靠性的解决方案。

Abstract: Automated International Classification of Diseases (ICD) coding assigns
standardized diagnosis and procedure codes to clinical records, playing a
critical role in healthcare systems. However, existing methods face challenges
such as semantic gaps between clinical text and ICD codes, poor performance on
rare and long-tail codes, and limited interpretability. To address these
issues, we propose TraceCoder, a novel framework integrating multi-source
external knowledge to enhance traceability and explainability in ICD coding.
TraceCoder dynamically incorporates diverse knowledge sources, including UMLS,
Wikipedia, and large language models (LLMs), to enrich code representations,
bridge semantic gaps, and handle rare and ambiguous codes. It also introduces a
hybrid attention mechanism to model interactions among labels, clinical
context, and knowledge, improving long-tail code recognition and making
predictions interpretable by grounding them in external evidence. Experiments
on MIMIC-III-ICD9, MIMIC-IV-ICD9, and MIMIC-IV-ICD10 datasets demonstrate that
TraceCoder achieves state-of-the-art performance, with ablation studies
validating the effectiveness of its components. TraceCoder offers a scalable
and robust solution for automated ICD coding, aligning with clinical needs for
accuracy, interpretability, and reliability.

</details>


### [29] [Automatic essay scoring: leveraging Jaccard coefficient and Cosine similaritywith n-gram variation in vector space model approach](https://arxiv.org/abs/2510.15311)
*Andharini Dwi Cahyani,Moh. Wildan Fathoni,Fika Hastarita Rachman,Ari Basuki,Salman Amin,Bain Khusnul Khotimah*

Main category: cs.CL

TL;DR: 研究比较了Jaccard与余弦相似性在自动作文评分中的作用，发现余弦相似性表现更佳，且一元语法模型的准确率最高。


<details>
  <summary>Details</summary>
Motivation: 推动自动化作文评分的准确性与效率，探索两种主流文本相似性度量（Jaccard系数与余弦相似性）及不同n-gram模型在实际作文评分场景中的应用效果。

Method: 该研究基于向量空间模型（VSM），应用一元、二元和三元语法（n-gram）表示法对初中公民教育课程的作文进行特征提取和向量化，然后分别计算作文之间的Jaccard系数和余弦相似性，通过与人工评阅分数的均方根误差（RMSE）比较系统评分的准确性。

Result: 实验结果显示，余弦相似性总体优于Jaccard系数，且一元语法模型的RMSE最低，即与人工评分更为接近，提升了评分系统的准确性。

Conclusion: 余弦相似性在自动作文评分中效果更好，尤其在使用一元语法模型时，其RMSE（均方根误差）最低，表现优于Jaccard系数和其他n-gram模型。

Abstract: Automated essay scoring (AES) is a vital area of research aiming to provide
efficient and accurate assessment tools for evaluating written content. This
study investigates the effectiveness of two popular similarity metrics, Jaccard
coefficient, and Cosine similarity, within the context of vector space
models(VSM)employing unigram, bigram, and trigram representations. The data
used in this research was obtained from the formative essay of the citizenship
education subject in a junior high school. Each essay undergoes preprocessing
to extract features using n-gram models, followed by vectorization to transform
text data into numerical representations. Then, similarity scores are computed
between essays using both Jaccard coefficient and Cosine similarity. The
performance of the system is evaluated by analyzing the root mean square error
(RMSE), which measures the difference between the scores given by human graders
and those generated by the system. The result shows that the Cosine similarity
outperformed the Jaccard coefficient. In terms of n-gram, unigrams have lower
RMSE compared to bigrams and trigrams.

</details>


### [30] [TACL: Threshold-Adaptive Curriculum Learning Strategy for Enhancing Medical Text Understanding](https://arxiv.org/abs/2510.15269)
*Mucheng Ren,Yucheng Yan,He Chen,Danqing Hu,Jun Xu,Xian Zeng*

Main category: cs.CL

TL;DR: 针对医学文本复杂度差异，提出了自适应课程学习（TACL）框架，动态调整训练。该方法在多语种医学数据和多项临床任务中显著提升了表现，有助于精准、全球化的医学文本处理。


<details>
  <summary>Details</summary>
Motivation: 医学文本尤其是电子病历（EMRs）包含丰富的临床信息，但因其非结构化格式、专业术语及情境差异，自动理解极具挑战性。现有NLP方法忽略了不同临床记录复杂度的差异，导致模型在罕见或复杂案例上的泛化和表现受限。

Method: 提出了一种新颖的门槛自适应课程学习框架（TACL），根据样本难度动态调整训练过程，将数据分为不同难度级别，并在训练初期优先处理较为简单的案例，逐渐学习复杂记录。

Result: 在多语种医学数据（涵盖英文和中文临床记录）上应用TACL，模型在自动ICD编码、再入院预测和中医证型辨识等多项任务上均取得了显著性能提升。

Conclusion: TACL不仅提升了自动系统表现，还展示了跨医疗领域统一建模的潜力，为更精准、可扩展、全球通用的医学文本理解方案奠定了基础。

Abstract: Medical texts, particularly electronic medical records (EMRs), are a
cornerstone of modern healthcare, capturing critical information about patient
care, diagnoses, and treatments. These texts hold immense potential for
advancing clinical decision-making and healthcare analytics. However, their
unstructured nature, domain-specific language, and variability across contexts
make automated understanding an intricate challenge. Despite the advancements
in natural language processing, existing methods often treat all data as
equally challenging, ignoring the inherent differences in complexity across
clinical records. This oversight limits the ability of models to effectively
generalize and perform well on rare or complex cases. In this paper, we present
TACL (Threshold-Adaptive Curriculum Learning), a novel framework designed to
address these challenges by rethinking how models interact with medical texts
during training. Inspired by the principle of progressive learning, TACL
dynamically adjusts the training process based on the complexity of individual
samples. By categorizing data into difficulty levels and prioritizing simpler
cases early in training, the model builds a strong foundation before tackling
more complex records. By applying TACL to multilingual medical data, including
English and Chinese clinical records, we observe significant improvements
across diverse clinical tasks, including automatic ICD coding, readmission
prediction and TCM syndrome differentiation. TACL not only enhances the
performance of automated systems but also demonstrates the potential to unify
approaches across disparate medical domains, paving the way for more accurate,
scalable, and globally applicable medical text understanding solutions.

</details>


### [31] [Exemplar-Guided Planing: Enhanced LLM Agent for KGQA](https://arxiv.org/abs/2510.15283)
*Jingao Xu,Shuoyoucheng Ma,Xin Song,Rong Jiang,Hongkui Tu,Bin Zhou*

Main category: cs.CL

TL;DR: 本文提出了一种范例引导规划方法（EGP），通过利用类似问题的推理路径和提前探索机制，显著提升大语言模型在知识图谱问答中的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在知识图谱问答（KGQA）中有巨大潜力，但由于自然语言与知识图谱结构化表示之间存在语义差距，导致规划效果不佳和探索效率低下。同时，不依赖训练的方式往往未能充分利用训练数据中的推理模式。

Method: 提出了Exemplar-Guided Planning（EGP）框架，通过实体模板归一化训练问题，并使用语义嵌入和FAISS索引检索相似范例及其推理路径，将这些范例动态引导LLM的任务分解和关系探索两个关键阶段。同时引入Smart Lookahead机制提升关系探索效率。该方法集成到Plan-on-Graph（PoG）系统中，称为PoG-EGP。

Result: 在WebQSP和CWQ两个真实KGQA数据集上，PoG-EGP较原PoG系统和其他对比方法有显著性能提升。

Conclusion: 引入范例引导和提前探索机制，可有效提升LLM在KGQA中的规划与推理能力，缩小语义差距，增加问答正确率和效率。

Abstract: Large Language Models (LLMs) as interactive agents show significant promise
in Knowledge Graph Question Answering (KGQA) but often struggle with the
semantic gap between natural language queries and structured knowledge graph
(KG) representations. This leads to suboptimal planning and inefficient
exploration on KG, while training-free approaches often underutilize valuable
reasoning patterns in training data. To address these limitations, we propose a
novel framework, Exemplar-Guided Planning (EGP), which enhances the planning
capabilities of LLM agents for KGQA. EGP first preprocesses the training set
questions via entity templating to normalize semantic variations. It then
retrieves highly similar exemplary questions and their successful reasoning
paths from this preprocessed set using semantic embeddings and an efficient
FAISS index. These retrieved exemplars dynamically guide the LLM's planning
process in two key phases: (1) Task Decomposition, by aligning generated
sub-objectives with proven reasoning steps, and (2) Relation Exploration, by
providing high-quality auxiliary information to improve relation pruning
accuracy. Additionally, we introduce a Smart Lookahead mechanism during
relation exploration to improve efficiency by preemptively exploring promising
paths and potentially terminating exploration earlier. We apply EGP to the
Plan-on-Graph (PoG) framework, termed PoG-EGP. Extensive experiments on two
real-world KGQA datasets, WebQSP and CWQ, demonstrate that PoG-EGP
significantly improves over the baseline PoG system and other compared methods.

</details>


### [32] [Accelerating Mobile Language Model Generation via Hybrid Context and Hardware Coordination](https://arxiv.org/abs/2510.15312)
*Zhiyang Chen,Daliang Xu,Haiyang Shen,Mengwei Xu,Shangguang Wang,Yun Ma*

Main category: cs.CL

TL;DR: 该论文提出移动设备上的LLM推理框架CoordGen，结合投机解码和硬件调度，有效提升了生成任务速度与能效，在实际手机测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 设备端运行大语言模型时，虽然prefill过程已被优化，但逐步生成阶段因内存瓶颈仍存在高延迟和硬件利用率低的问题。提升移动端生成效率和能效以满足智能助手等个性化任务的需求。

Method: 提出了一个名为CoordGen的移动端推理框架，通过将投机性解码与动态硬件调度相结合优化推理过程。具体方法包括：自适应执行调度、上下文对齐草稿生成及高效硬件草稿扩展。

Result: 在多种手机和任务上实验，CoordGen提升了生成速度和能效，并通过组件级分析验证各优化策略的有效性。

Conclusion: CoordGen显著提升了设备上运行大语言模型的生成速度和能效，对比现有方案达到了最高3.8倍的加速和4.7倍的能效提升。

Abstract: Enhancing on-device large language models (LLMs) with contextual information
from local data enables personalized and task-aware generation, powering use
cases such as intelligent assistants and UI agents. While recent developments
in neural processors have substantially improved the efficiency of prefill on
mobile devices, the token-by-token generation process still suffers from high
latency and limited hardware utilization due to its inherently memory-bound
characteristics. This work presents CoordGen, a mobile inference framework that
integrates speculative decoding with dynamic hardware scheduling to accelerate
context-aware text generation on mobile devices. The framework introduces three
synergistic components: (1) adaptive execution scheduling, which dynamically
balances compute graphs between prefill and decoding phases; (2)
context-aligned drafting, which improves speculative efficiency through
lightweight online calibration to current tasks; and (3) hardware-efficient
draft extension, which reuses and expands intermediate sequences to improve
processing parallelism and reduce verification cost. Experiments on multiple
smartphones and representative workloads show consistent improvements of up to
3.8x in generation speed and 4.7x in energy efficiency compared with existing
mobile inference solutions. Component-level analysis further validates the
contribution of each optimization.

</details>


### [33] [Capabilities and Evaluation Biases of Large Language Models in Classical Chinese Poetry Generation: A Case Study on Tang Poetry](https://arxiv.org/abs/2510.15313)
*Bolei Ma,Yina Yao,Anna-Carolina Haensch*

Main category: cs.CL

TL;DR: 本文提出三步评估框架系统分析主流大模型在古典中文诗歌生成与评价的表现，发现大模型在生成与自评时存在“回音室”偏差，说明仅用大模型自动评测尚不足以替代人类专家，需人机结合以确保高质量输出。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）被广泛应用于创造性领域，但它们在古典中文诗歌生成和评价方面的表现尚未被充分理解，因此作者提出系统地评估LLMs在该领域能力的需求。

Method: 作者提出了三步评估框架，结合了计算指标、LLM自评（LLM-as-a-judge）以及人类专家验证，用于系统性评价六个最先进的LLM在诗歌生成多维度（主题、情感、意象、形式与风格）上的表现。

Result: 分析发现LLMs在创作评价过程中存在系统性偏见，如“回音室”效应，即在审美评价时容易一致但容易偏离人类标准，显示出LLMs生成与评价诗歌时的潜在局限性。

Conclusion: LLMs在古典中文诗歌生成与评价方面具有一定潜力，但它们存在标准异化与评价偏差，当前仍需结合人类与模型的混合验证方式来确保在文化与技术复杂的创造任务中的可靠性和准确性。

Abstract: Large Language Models (LLMs) are increasingly applied to creative domains,
yet their performance in classical Chinese poetry generation and evaluation
remains poorly understood. We propose a three-step evaluation framework that
combines computational metrics, LLM-as-a-judge assessment, and human expert
validation. Using this framework, we evaluate six state-of-the-art LLMs across
multiple dimensions of poetic quality, including themes, emotions, imagery,
form, and style. Our analysis reveals systematic generation and evaluation
biases: LLMs exhibit "echo chamber" effects when assessing creative quality,
often converging on flawed standards that diverge from human judgments. These
findings highlight both the potential and limitations of current capabilities
of LLMs as proxy for literacy generation and the limited evaluation practices,
thereby demonstrating the continued need of hybrid validation from both humans
and models in culturally and technically complex creative tasks.

</details>


### [34] [AutoGraph-R1: End-to-End Reinforcement Learning for Knowledge Graph Construction](https://arxiv.org/abs/2510.15339)
*Hong Ting Tsang,Jiaxin Bai,Haoyu Huang,Qiao Xiao,Tianshi Zheng,Baixuan Xu,Shujie Liu,Yangqiu Song*

Main category: cs.CL

TL;DR: 本论文提出AutoGraph-R1框架，通过强化学习使知识图谱构建更适合问答任务，显著提升了基于知识图谱的检索增强生成方法的效果。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱构建过程与下游任务（如问答系统）脱钩，导致生成的图谱结构难以充分发挥性能，因此需要一种能够根据实际任务优化图谱结构的方法。

Method: 将知识图谱生成视为策略学习问题，基于强化学习框架训练大语言模型（LLM）作为构建者。设计两种任务感知型奖励函数，分别针对知识载体和知识索引两种目标。

Result: 在多项问答基准测试中，基于AutoGraph-R1的图谱显著优于基线方法，有效提升了RAG方法的问答表现。

Conclusion: AutoGraph-R1通过强化学习优化知识图谱的构建过程，使图谱在检索增强生成任务中表现更优，有效提升问答系统性能。

Abstract: Building effective knowledge graphs (KGs) for Retrieval-Augmented Generation
(RAG) is pivotal for advancing question answering (QA) systems. However, its
effectiveness is hindered by a fundamental disconnect: the knowledge graph (KG)
construction process is decoupled from its downstream application, yielding
suboptimal graph structures. To bridge this gap, we introduce AutoGraph-R1, the
first framework to directly optimize KG construction for task performance using
Reinforcement Learning (RL). AutoGraph-R1 trains an LLM constructor by framing
graph generation as a policy learning problem, where the reward is derived from
the graph's functional utility in a RAG pipeline. We design two novel,
task-aware reward functions, one for graphs as knowledge carriers and another
as knowledge indices. Across multiple QA benchmarks, AutoGraph-R1 consistently
enables graph RAG methods to achieve significant performance gains over using
task-agnostic baseline graphs. Our work shows it is possible to close the loop
between construction and application, shifting the paradigm from building
intrinsically ``good'' graphs to building demonstrably ``useful'' ones.

</details>


### [35] [Readability Reconsidered: A Cross-Dataset Analysis of Reference-Free Metrics](https://arxiv.org/abs/2510.15345)
*Catarina G Belem,Parker Glenn,Alfy Samuel,Anoop Kumar,Daben Liu*

Main category: cs.CL

TL;DR: 表层特征已不能准确衡量文本可读性，模型型方法更能反映人类真实感受，是未来可读性评估的发展方向。


<details>
  <summary>Details</summary>
Motivation: 现有的自动可读性评估方法主要依赖文本表层特征，且对可读性的定义和度量方式不一致，这限制了其在实际应用中的有效性。了解人类对文本可读性的真实判断因素，有助于改进评估方法。

Method: 通过分析897个关于文本可读性的人工判断，探究影响人类可读性感知的因素，并在五个英语数据集上，对15种主流可读性度量方法与6种更细致的模型型度量方法进行对比评估。

Result: 研究发现，信息内容和主题对文本可读性影响较大。与人的判断比对结果显示，四种模型型度量方法在排名相关性方面持续排名前四，而传统方法中的最佳仅取得平均第8.6名。

Conclusion: 当前广泛使用的可读性度量方法与人类感知存在明显差异，模型型方法更贴近真实的可读性判断，未来可读性评估应优先采用模型型方法。

Abstract: Automatic readability assessment plays a key role in ensuring effective and
accessible written communication. Despite significant progress, the field is
hindered by inconsistent definitions of readability and measurements that rely
on surface-level text properties. In this work, we investigate the factors
shaping human perceptions of readability through the analysis of 897 judgments,
finding that, beyond surface-level cues, information content and topic strongly
shape text comprehensibility. Furthermore, we evaluate 15 popular readability
metrics across five English datasets, contrasting them with six more nuanced,
model-based metrics. Our results show that four model-based metrics
consistently place among the top four in rank correlations with human
judgments, while the best performing traditional metric achieves an average
rank of 8.6. These findings highlight a mismatch between current readability
metrics and human perceptions, pointing to model-based approaches as a more
promising direction.

</details>


### [36] [When to Ensemble: Identifying Token-Level Points for Stable and Fast LLM Ensembling](https://arxiv.org/abs/2510.15346)
*Heecheol Yun,Kwangmin Ki,Junghyun Lee,Eunho Yang*

Main category: cs.CL

TL;DR: 本文提出 SAFE 框架，用于大语言模型长文本生成时的选择性集成，联合考虑分词不一致和概率分布共识，通过概率锐化提升稳定性。实验显示 SAFE 在准确率和效率上均超越现有方法，适合长文本场景。


<details>
  <summary>Details</summary>
Motivation: 将大语言模型（LLMs）集成以超越单一模型表现已成为趋势，尤其是在聚合模型的下一个分词概率分布选择下一个 token 时表现良好。但现有研究多集中于短文本生成，在长文本生成领域仍未充分探索。作者希望解决长文本集成时性能下降的问题。

Method: 作者发现长文本生成集成需要谨慎选择集成位置，不能逐 token 集成。并识别了两个关键影响因素：不同模型的分词方式不一致，以及各模型分词概率分布的共识度。基于此，提出了 SAFE 框架，联合考虑上述因素进行选择性集成。为提升稳定性，加入了概率锐化策略，将同一单词多个子词的概率整合到一个代表 token。

Result: 在多个基准数据集（如 MATH500 和 BBH）实验表明，SAFE 在准确率和效率上都优于现有方法，即使只集成不到 1% 的 token，也能带来性能提升。

Conclusion: 作者提出了针对长文本生成的 LLM 集成新框架 SAFE，在效率和准确率上都超越了现有集成方法，为 LLMs 集成提供了新的思路和技术支持。

Abstract: Ensembling Large Language Models (LLMs) has gained attention as a promising
approach to surpass the performance of individual models by leveraging their
complementary strengths. In particular, aggregating models' next-token
probability distributions to select the next token has been shown to be
effective in various tasks. However, while successful for short-form answers,
its application to long-form generation remains underexplored. In this paper,
we show that using existing ensemble methods in long-form generation requires a
careful choice of ensembling positions, since the standard practice of
ensembling at every token often degrades performance. We identify two key
factors for determining these positions: tokenization mismatch across models
and consensus in their next-token probability distributions. Based on this, we
propose SAFE, (Stable And Fast LLM Ensembling), a framework that selectively
ensembles by jointly considering these factors. To further improve stability,
we introduce a probability sharpening strategy that consolidates probabilities
spread across multiple sub-word tokens representing the same word into a single
representative token. Our experiments on diverse benchmarks, including MATH500
and BBH, demonstrate that SAFE outperforms existing methods in both accuracy
and efficiency, with gains achieved even when ensembling fewer than 1% of
tokens.

</details>


### [37] [Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing](https://arxiv.org/abs/2510.15349)
*Baode Wang,Biao Wu,Weizhen Li,Meng Fang,Zuming Huang,Jun Huang,Haozhe Wang,Yanjie Liang,Ling Chen,Wei Chu,Yuan Qi*

Main category: cs.CL

TL;DR: 该工作提出了强化学习框架LayoutRL，通过构建大规模数据集Infinity-Doc-400K并训练Infinity-Parser，使其在文档解析任务上表现优异，提升了在不同文档类型上的泛化能力，并将在文档解析领域开放相关资源。


<details>
  <summary>Details</summary>
Motivation: 文档解析从扫描图像到结构化格式一直是一个具有挑战性的任务，尤其是由于文本段落、图像、公式和表格等元素高度复杂交织。现有的监督微调方法在不同类型文档之间泛化能力有限，特别是在分布外数据上的表现较差，加之用于布局感知解析任务的高质量训练数据稀缺，进一步加剧了这一问题。

Method: 提出了LayoutRL，一种通过复合奖励（包括归一化编辑距离、段落数量准确率和阅读顺序保持性）来优化布局理解的强化学习框架；并构建Infinity-Doc-400K大规模数据集，用于训练视觉-语言模型Infinity-Parser。

Result: 通过对OmniDocBench、olmOCR-Bench、PubTabNet、FinTabNet等多个基准的广泛评估，Infinity-Parser在各种文档类型、语言和结构复杂度上持续取得了领先性能，显著超越了专用文档解析系统和通用视觉语言模型。

Conclusion: Infinity-Parser和LayoutRL框架显著提升了多类文档解析的泛化与精度，将公开代码、数据集及模型以促进结构化文档解析领域的可复现研究。

Abstract: Document parsing from scanned images into structured formats remains a
significant challenge due to its complexly intertwined elements such as text
paragraphs, figures, formulas, and tables. Existing supervised fine-tuning
methods often struggle to generalize across diverse document types, leading to
poor performance, particularly on out-of-distribution data. This issue is
further exacerbated by the limited availability of high-quality training data
for layout-aware parsing tasks. To address these challenges, we introduce
LayoutRL, a reinforcement learning framework that optimizes layout
understanding through composite rewards integrating normalized edit distance,
paragraph count accuracy, and reading order preservation. To support this
training, we construct the Infinity-Doc-400K dataset, which we use to train
Infinity-Parser, a vision-language model demonstrating robust generalization
across various domains. Extensive evaluations on benchmarks including
OmniDocBench, olmOCR-Bench, PubTabNet, and FinTabNet show that Infinity-Parser
consistently achieves state-of-the-art performance across a broad range of
document types, languages, and structural complexities, substantially
outperforming both specialized document parsing systems and general-purpose
vision-language models. We will release our code, dataset, and model to
facilitate reproducible research in document parsing.

</details>


### [38] [VocalBench-DF: A Benchmark for Evaluating Speech LLM Robustness to Disfluency](https://arxiv.org/abs/2510.15406)
*Hongcheng Liu,Yixuan Hou,Heyang Liu,Yuhao Wang,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 本文提出了系统评测框架VocalBench-DF，发现现有22种主流语音大模型在处理语音不流畅（如帕金森病患者的语音）时，准确率显著下降，主要受限于音素处理和长文本建模能力。作者呼吁业界重视该问题，推动Speech-LLMs更好地应对现实语音障碍，提升包容性。


<details>
  <summary>Details</summary>
Motivation: 虽然语音大模型（Speech-LLMs）在许多应用中表现优异，但其对语音不流畅现象的鲁棒性很少被严格测试，尤其是针对常见的语音障碍，如帕金森病患者的语言障碍。现有评估方法多以理想化输入为主，忽略了现实中普遍存在的语音不流畅问题。

Method: 本研究提出VocalBench-DF框架，能够系统性地根据多维度分类法评估语音不流畅对主流Speech-LLMs性能的影响。作者对22个主流Speech-LLMs进行基准测试，并进一步分析其在不流畅语音下的表现瓶颈。

Result: 主流Speech-LLMs在处理带有语音不流畅的输入时表现显著下降。分析发现，音素级处理和长上下文建模是导致性能下降的主要瓶颈。

Conclusion: 当前的Speech-LLMs尚未做好真实环境的准备，急需开发新的方法以提升其对语音不流畅的处理能力，从而实现更具包容性的语音交互系统。

Abstract: While Speech Large Language Models (Speech-LLMs) show strong performance in
many applications, their robustness is critically under-tested, especially to
speech disfluency. Existing evaluations often rely on idealized inputs,
overlooking common disfluencies, particularly those associated with conditions
like Parkinson's disease. This work investigates whether current Speech-LLMs
can maintain performance when interacting with users who have speech
impairments. To facilitate this inquiry, we introduce VocalBench-DF, a
framework for the systematic evaluation of disfluency across a
multi-dimensional taxonomy. Our evaluation of 22 mainstream Speech-LLMs reveals
substantial performance degradation, indicating that their real-world readiness
is limited. Further analysis identifies phoneme-level processing and
long-context modeling as primary bottlenecks responsible for these failures.
Strengthening recognition and reasoning capability from components and
pipelines can substantially improve robustness. These findings highlight the
urgent need for new methods to improve disfluency handling and build truly
inclusive Speech-LLMs

</details>


### [39] [Large-scale User Game Lifecycle Representation Learning](https://arxiv.org/abs/2510.15412)
*Yanjie Gou,Jiangming Liu,Kouying Xue,Yi Hua*

Main category: cs.CL

TL;DR: 论文提出了一种针对游戏广告和推荐系统的用户行为建模方法UGL，并结合逆概率掩码解决了游戏数量稀疏和用户行为不均衡问题，实验验证了显著的效果提升。


<details>
  <summary>Details</summary>
Motivation: 随着视频游戏产业快速扩展，线上游戏平台需要更有效的广告和推荐系统。现有用来处理海量物品的推荐表示学习方法，在游戏广告和推荐场景并不适用，原因在于游戏数量稀疏和用户行为高度偏向少数热门游戏。

Method: 提出了User Game Lifecycle (UGL)模型来丰富用户在游戏中的行为，规划了两项创新策略以更好地提取用户短期和长期兴趣。同时，为解决游戏不均衡问题，设计了逆概率掩码策略，用于UGL的表示学习。

Result: 实验结果显示，UGL表示能显著提升模型表现：离线AUC平均提升1.83%，线上广告CVR提升21.67%；游戏道具推荐中，离线AUC提升0.5%，线上ARPU提升0.82%。

Conclusion: 针对游戏广告和推荐场景下的稀疏性和不均衡问题，UGL方法有效丰富了用户行为，并结合逆概率掩码提升了用户兴趣捕捉能力，显著提升了实际业务关键指标。

Abstract: The rapid expansion of video game production necessitates the development of
effective advertising and recommendation systems for online game platforms.
Recommending and advertising games to users hinges on capturing their interest
in games. However, existing representation learning methods crafted for
handling billions of items in recommendation systems are unsuitable for game
advertising and recommendation. This is primarily due to game sparsity, where
the mere hundreds of games fall short for large-scale user representation
learning, and game imbalance, where user behaviors are overwhelmingly dominated
by a handful of popular games. To address the sparsity issue, we introduce the
User Game Lifecycle (UGL), designed to enrich user behaviors in games.
Additionally, we propose two innovative strategies aimed at manipulating user
behaviors to more effectively extract both short and long-term interests. To
tackle the game imbalance challenge, we present an Inverse Probability Masking
strategy for UGL representation learning. The offline and online experimental
results demonstrate that the UGL representations significantly enhance model by
achieving a 1.83% AUC offline increase on average and a 21.67% CVR online
increase on average for game advertising and a 0.5% AUC offline increase and a
0.82% ARPU online increase for in-game item recommendation.

</details>


### [40] [Fine-Tuning MedGemma for Clinical Captioning to Enhance Multimodal RAG over Malaysia CPGs](https://arxiv.org/abs/2510.15418)
*Lee Qi Zun,Mohamad Zulhilmi Bin Abdul Halim,Goh Man Fye*

Main category: cs.CL

TL;DR: 通过知识蒸馏合成医疗图像数据，并用QLoRA方法高效微调MedGemma模型，大幅提升了生成医疗图像描述的准确性和事实性，为临床决策支持系统提供更可靠的信息查询基础。


<details>
  <summary>Details</summary>
Motivation: 现有基于检索增强生成（RAG）系统在使用视觉语言模型（VLM）生成医疗图像描述时，常存在描述不够具体和事实依据不足的问题，尤其是在应对临床场景如马来西亚临床指南时。

Method: 提出并验证一个专门针对MedGemma模型的微调框架，通过知识蒸馏生成皮肤病、眼底以及胸部影像领域的合成数据集，使用QLoRA高效调参方法对MedGemma模型进行微调。同时，采用双重评测体系：一方面评估分类准确率，另一方面基于RAGAS框架创新地评估生成描述的真实度、相关性和正确性。

Result: 微调后的MedGemma模型无论在分类准确率还是描述的事实性和正确性方面均显著优于原始模型，能够生成高质量、具备临床事实依据的医疗图像描述，其作为查询生成器表现优异。

Conclusion: 该工作提出了一条可行且稳健的专门化医疗视觉语言模型流程，并通过实验证明其在医疗检索增强系统中的有效性，为未来多模态临床决策支持提供了坚实基础。

Abstract: Retrieval-Augmented Generation systems are essential for providing fact-based
guidance from Malaysian Clinical Practice Guidelines. However, their
effectiveness with image-based queries is limited, as general Vision-Language
Model captions often lack clinical specificity and factual grounding. This
study proposes and validates a framework to specialize the MedGemma model for
generating high-fidelity captions that serve as superior queries. To overcome
data scarcity, we employ a knowledge distillation pipeline to create a
synthetic dataset across dermatology, fundus, and chest radiography domains,
and fine-tune MedGemma using the parameter-efficient QLoRA method. Performance
was rigorously assessed through a dual framework measuring both classification
accuracy and, via a novel application of the RAGAS framework, caption
faithfulness, relevancy, and correctness. The fine-tuned model demonstrated
substantial improvements in classification performance, while RAGAS evaluation
confirmed significant gains in caption faithfulness and correctness, validating
the models ability to produce reliable, factually grounded descriptions. This
work establishes a robust pipeline for specializing medical VLMs and validates
the resulting model as a high-quality query generator, laying the groundwork
for enhancing multimodal RAG systems in evidence-based clinical decision
support.

</details>


### [41] [When Seeing Is not Enough: Revealing the Limits of Active Reasoning in MLLMs](https://arxiv.org/abs/2510.15421)
*Hongcheng Liu,Pingjie Wang,Yuhao Wang,Siqu Ou,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 本文针对MLLMs在缺失信息下主动推理的问题，提出GuessBench基准并系统评估了20种模型，发现其主动推理能力仍有很大提升空间，细粒度感知与推理机制优化是关键。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大模型（MLLMs）在基准测试中表现强大，但大多评估关注的是模型在拥有完整信息时的被动推理，这与实际应用场景不一致。实际中，模型常常需要在信息不完整时主动获取缺失证据，进行决策。因此，研究MLLMs在不完全信息下主动推理的能力非常重要。

Method: 提出了GuessBench基准，该基准涵盖了感知导向和知识导向的图片，用于系统化评估MLLMs的主动推理能力。要求模型在备选图片池中主动选择目标图片，并不断根据新获取的信息调整决策，无需针对特定任务的先验知识。

Result: 评估了20个主流MLLMs，发现它们在主动推理任务中的表现远逊于被动推理设置，显示出显著提升空间。进一步分析发现，细粒度感知和适时决策是主要挑战。消融实验显示，增强感知能力能帮助小模型，而注重思维的方法能提升各类模型的表现。

Conclusion: 目前MLLMs在主动推理方面能力有限，提升细粒度感知与决策机制是未来研究的重要方向。GuessBench基准的推出为系统性研究主动推理问题提供了有力工具，促进相关方法的发展。

Abstract: Multimodal large language models (MLLMs) have shown strong capabilities
across a broad range of benchmarks. However, most existing evaluations focus on
passive inference, where models perform step-by-step reasoning under complete
information. This setup is misaligned with real-world use, where seeing is not
enough. This raises a fundamental question: Can MLLMs actively acquire missing
evidence under incomplete information? To bridge this gap, we require the MLLMs
to actively acquire missing evidence and iteratively refine decisions under
incomplete information, by selecting a target image from a candidate pool
without task-specific priors. To support systematic study, we propose
GuessBench, a benchmark with both perception-oriented and knowledge-oriented
images for evaluating active reasoning in MLLMs. We evaluate 20 superior MLLMs
and find that performance on active reasoning lags far behind it on passive
settings, indicating substantial room for improvement. Further analysis
identifies fine-grained perception and timely decision-making as key
challenges. Ablation studies show that perceptual enhancements benefit smaller
models, whereas thinking-oriented methods provide consistent gains across model
sizes. These results suggest promising directions for future research on
multimodal active reasoning.

</details>


### [42] [Controllable Abstraction in Summary Generation for Large Language Models via Prompt Engineering](https://arxiv.org/abs/2510.15436)
*Xiangchen Song,Yuchen Liu,Yaxuan Luan,Jinxu Guo,Xiaofan Guo*

Main category: cs.CL

TL;DR: 通过多阶段提示策略和文本预处理，能提升大语言模型自动摘要的质量和可控性，提示长度和噪声是关键因素。


<details>
  <summary>Details</summary>
Motivation: 解决传统大语言模型摘要方法在摘要质量和可控性上的不足，探索如何通过提示工程提升生成效果。

Method: 提出了基于多阶段提示生成的摘要方法，包括语义分析、主题建模和噪声控制，并在CNN/Daily Mail数据集上进行了不同提示长度、噪声和文本类型的实验。

Result: 摘要质量受提示长度与数据噪声影响显著，过长或过短的提示、较高噪声均会降低ROUGE-L分数，新闻文本的摘要生成效果优于学术文本。

Conclusion: 该研究证明，通过合理的提示工程和文本预处理，可以显著提升大语言模型的摘要生成质量及可控性。新闻类文本效果最佳，而学术文章表现稍差。

Abstract: This study presents a controllable abstract summary generation method for
large language models based on prompt engineering. To address the issues of
summary quality and controllability in traditional methods, we design a
multi-stage prompt generation framework. This framework generates summaries
with varying levels of abstraction by performing semantic analysis, topic
modeling, and noise control on the input text. The experiment uses the
CNN/Daily Mail dataset and provides a detailed analysis of different prompt
lengths, data noise, and text types. The experimental results show that prompt
length has a significant impact on the quality of generated summaries. Both
very short and very long prompt tokens result in a decrease in summary quality.
Data noise also negatively affects the summary generation process. As noise
levels increase, the ROUGE-L score gradually decreases. Furthermore, different
text types have varying effects on the model's ability to generate summaries.
The model performs best when handling news texts, while its performance is
worse when processing academic articles. This research provides new insights
into improving summary generation using large language models, particularly in
how controlling prompt strategies and optimizing text preprocessing can enhance
summary accuracy and controllability.

</details>


### [43] [CORE: Reducing UI Exposure in Mobile Agents via Collaboration Between Cloud and Local LLMs](https://arxiv.org/abs/2510.15455)
*Gucongcong Fan,Chaoyue Niu,Chengfei Lyu,Fan Wu,Guihai Chen*

Main category: cs.CL

TL;DR: CORE框架结合云端与本地大模型，在大幅减少手机UI隐私上传量的同时，仍可实现高效的任务执行表现，平衡了隐私保护与任务完成率。


<details>
  <summary>Details</summary>
Motivation: 在移动代理系统使用大模型时，云端推理需要每步上传全部UI状态，导致过度隐私暴露；本地模型虽能保护隐私但能力有限，任务效果差。如何在保护隐私与保证任务准确率间做权衡，是该研究的出发点。

Method: 提出了CORE协同框架，包括布局感知分块（根据UI层级组织界面元素）、协同规划（本地与云端共同识别子任务）、协同决策（本地排序相关UI块，云端在首选块内精细选择元素）、以及多轮累积机制（纠正本地判断错误/信息受限）。

Result: 在不同移动应用和任务上的实验表明，CORE在任务成功率略低于纯云端大模型的情况下，能减少55.6%的UI信息上传到云端，有效降低隐私泄露风险。

Conclusion: CORE协同框架显著减少了移动代理系统中的UI隐私暴露，同时能够保持接近云端大模型的任务成功率。

Abstract: Mobile agents rely on Large Language Models (LLMs) to plan and execute tasks
on smartphone user interfaces (UIs). While cloud-based LLMs achieve high task
accuracy, they require uploading the full UI state at every step, exposing
unnecessary and often irrelevant information. In contrast, local LLMs avoid UI
uploads but suffer from limited capacity, resulting in lower task success
rates. We propose $\textbf{CORE}$, a $\textbf{CO}$llaborative framework that
combines the strengths of cloud and local LLMs to $\textbf{R}$educe UI
$\textbf{E}$xposure, while maintaining task accuracy for mobile agents. CORE
comprises three key components: (1) $\textbf{Layout-aware block partitioning}$,
which groups semantically related UI elements based on the XML screen
hierarchy; (2) $\textbf{Co-planning}$, where local and cloud LLMs
collaboratively identify the current sub-task; and (3)
$\textbf{Co-decision-making}$, where the local LLM ranks relevant UI blocks,
and the cloud LLM selects specific UI elements within the top-ranked block.
CORE further introduces a multi-round accumulation mechanism to mitigate local
misjudgment or limited context. Experiments across diverse mobile apps and
tasks show that CORE reduces UI exposure by up to 55.6% while maintaining task
success rates slightly below cloud-only agents, effectively mitigating
unnecessary privacy exposure to the cloud. The code is available at
https://github.com/Entropy-Fighter/CORE.

</details>


### [44] [DeceptionBench: A Comprehensive Benchmark for AI Deception Behaviors in Real-world Scenarios](https://arxiv.org/abs/2510.15501)
*Yao Huang,Yitong Sun,Yichi Zhang,Ruochen Zhang,Yinpeng Dong,Xingxing Wei*

Main category: cs.CL

TL;DR: 本文构建了首个系统性欺骗行为评测基准DeceptionBench，通过多领域多场景实验揭示大语言模型在不同外部因素作用下易发生欺骗，强化奖励机制会进一步加剧该问题，凸显大模型安全性亟待提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在认知任务上取得巨大进步，但随之而来的欺骗行为带来现实风险，尤其是在关键领域部署时更为严重。现有关于模型欺骗行为的实际场景研究较少。

Method: 提出DeceptionBench，这是一个系统性基准，用于评估模型在五个社会领域（经济、医疗、教育、社交和娱乐）中的欺骗行为表现，分析其内在行为模式和外部因素影响，并构建多回合交互以模拟真实反馈场景。

Result: 通过大量实验，发现LLMs和LRMs在奖励机制下的欺骗表现显著增强，说明当前模型对操控性情境缺乏抵抗力，存在关键漏洞。

Conclusion: 现有大模型对欺骗性输入和上下文极易受到影响，亟需更有效的应对欺骗行为的安全防护措施。

Abstract: Despite the remarkable advances of Large Language Models (LLMs) across
diverse cognitive tasks, the rapid enhancement of these capabilities also
introduces emergent deceptive behaviors that may induce severe risks in
high-stakes deployments. More critically, the characterization of deception
across realistic real-world scenarios remains underexplored. To bridge this
gap, we establish DeceptionBench, the first benchmark that systematically
evaluates how deceptive tendencies manifest across different societal domains,
what their intrinsic behavioral patterns are, and how extrinsic factors affect
them. Specifically, on the static count, the benchmark encompasses 150
meticulously designed scenarios in five domains, i.e., Economy, Healthcare,
Education, Social Interaction, and Entertainment, with over 1,000 samples,
providing sufficient empirical foundations for deception analysis. On the
intrinsic dimension, we explore whether models exhibit self-interested egoistic
tendencies or sycophantic behaviors that prioritize user appeasement. On the
extrinsic dimension, we investigate how contextual factors modulate deceptive
outputs under neutral conditions, reward-based incentivization, and coercive
pressures. Moreover, we incorporate sustained multi-turn interaction loops to
construct a more realistic simulation of real-world feedback dynamics.
Extensive experiments across LLMs and Large Reasoning Models (LRMs) reveal
critical vulnerabilities, particularly amplified deception under reinforcement
dynamics, demonstrating that current models lack robust resistance to
manipulative contextual cues and the urgent need for advanced safeguards
against various deception behaviors. Code and resources are publicly available
at https://github.com/Aries-iai/DeceptionBench.

</details>


### [45] [Temporal Referential Consistency: Do LLMs Favor Sequences Over Absolute Time References?](https://arxiv.org/abs/2510.15513)
*Ashutosh Bajpai,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文提出了TEMP-ReCon基准和UnTRaP增强方法，发现现有LLM在时序一致性方面不足，并通过新模型显著提升了其表现，对时序敏感领域应用有重要推动作用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）正被广泛应用于法律、医疗、金融等对时效性要求高的领域，因此需要模型具备事实正确性和跨时间维度的一致性，即强大的时序推理能力。然而，当前缺乏针对LLM在时序一致性上的评估和增强的工作，尤其在处理涉及多语言和资源差异的场景时。

Method: 文中提出了一个新的时序指称一致性基准（temporal referential consistency），并开发了TEMP-ReCon资源，用于在多语言环境（英语、法语、罗马尼亚语）下对开源和闭源LLM进行系统评测。此外，作者还提出了UnTRaP，一种基于推理路径对齐的方法，用于提升LLM的时序指称一致性。

Result: 实验结果显示现有LLM在时序指称一致性方面明显不足。提出的UnTRaP模型在此任务上优于多个基线模型，提升了模型的时序推理能力。

Conclusion: 针对LLM在时间敏感领域应用存在的时序一致性不足，两项成果：TEMP-ReCon评测基准和UnTRaP一致性增强方法，为提升LLM的时序推理和跨语言一致性能力提供了有效方案。

Abstract: The increasing acceptance of large language models (LLMs) as an alternative
to knowledge sources marks a significant paradigm shift across various domains,
including time-sensitive fields such as law, healthcare, and finance. To
fulfill this expanded role, LLMs must not only be factually accurate but also
demonstrate consistency across temporal dimensions, necessitating robust
temporal reasoning capabilities. Despite this critical requirement, efforts to
ensure temporal consistency in LLMs remain scarce including noticeable absence
of endeavors aimed at evaluating or augmenting LLMs across temporal references
in time-sensitive inquiries. In this paper, we seek to address this gap by
introducing a novel benchmark entitled temporal referential consistency,
accompanied by a resource TEMP-ReCon designed to benchmark a wide range of both
open-source and closed-source LLMs with various linguistic contexts
characterized by differing resource richness (including English, French, and
Romanian). The findings emphasis that LLMs do exhibit insufficient temporal
referent consistency. To address this, we propose \newmodel, a reasoning path
alignment-based model that aims to enhance the temporal referential consistency
of LLMs. Our empirical experiments substantiate the efficacy of UnTRaP compared
to several baseline models.

</details>


### [46] [From Characters to Tokens: Dynamic Grouping with Hierarchical BPE](https://arxiv.org/abs/2510.15517)
*Rares Dolga,Lucas Maystre,Tudor Berariu,David Barber*

Main category: cs.CL

TL;DR: 该论文提出了一种不需要额外模型，基于BPE的动态字符分组方法，通过添加分组标记和二次压缩，提高了语言模型对稀有词和多语言的处理效率，同时保持较小词表和强表现力。


<details>
  <summary>Details</summary>
Motivation: 现有的子词分词方法如BPE虽在词汇紧凑性和表达能力之间取得平衡，但在表示稀有词汇和嵌入矩阵大小方面存在效率问题；字符级方法虽能缓解上述问题，却在Transformer架构下出现性能瓶颈。最近的分层模型尝试融合二者优点，但依赖于空格或辅助模型，限制了适用范围。

Method: 提出一种动态字符分组方法，不依赖额外模型，利用现有BPE结构，通过在BPE分词后加上明确的分组结束标记，并引入第二层BPE压缩来灵活控制分组粒度，从而实现高效、灵活且适用于所有语言的表征方式。

Result: 实验证明，该方法可以达到或超过依赖动态熵或空格分组策略的性能，同时保持紧凑的词汇表。

Conclusion: 该动态字符分组方法有效融合了BPE与字符级表示的优势，提升了语言模型在效率和表现上的综合能力，且无需引入新的模型依赖，具备广泛应用前景。

Abstract: Subword tokenization methods like Byte Pair Encoding (BPE) are widely used in
large language models due to their balance of vocabulary compactness and
representational power. However, they suffer from inefficiencies in
representing rare words and require large embedding matrices. Character-level
models address these issues but introduce performance bottlenecks, particularly
in Transformer-based architectures. Recent hierarchical models attempt to merge
the benefits of both paradigms by grouping characters into patches, but
existing patching strategies either rely on whitespace-limiting applicability
to certain languages, or require auxiliary models that introduce new
dependencies. In this paper, we propose a dynamic character grouping method
that leverages the structure of existing BPE tokenization without requiring
additional models. By appending explicit end-of-patch markers to BPE tokens and
introducing a second-level BPE compression stage to control patch granularity,
our method offers efficient, flexible, and language-agnostic representations.
Empirical results demonstrate that our approach matches or exceeds the
performance of dynamic entropy- and whitespace-based patching strategies, while
maintaining a compact vocabulary.

</details>


### [47] [Latent Reasoning in LLMs as a Vocabulary-Space Superposition](https://arxiv.org/abs/2510.15522)
*Jingcheng Deng,Liang Pang,Zihao Wei,Shichen Xu,Zenghao Duan,Kun Xu,Yang Song,Huawei Shen,Xueqi Cheng*

Main category: cs.CL

TL;DR: 为解决显式链式推理计算复杂、隐式潜在空间推理性能不足的问题，作者提出Latent-SFT框架，通过限定潜在空间结构并分两阶段训练，使潜在推理性能达到最优，推理链大幅压缩，显著优于以往方法。


<details>
  <summary>Details</summary>
Motivation: 针对大语言模型(LLM)在链式思维(chain-of-thought)推理中的计算开销过大问题，现有的潜在空间推理虽然减少了开销，但性能大幅下降，作者发现其根本原因是潜在空间结构化不足，导致隐式计算不稳定。

Method: 提出Latent-SFT两阶段学习框架。第一阶段，设计特殊的注意力掩码，引导潜在编码器生成潜在token，促使LLM根据其生成正确答案。第二阶段，去掉潜在编码器，LLM直接自主生成这些潜在token进行推理，同时用KL和交叉熵损失进行优化。潜在空间被限定为词汇表的列空间，将潜在推理视为词汇概率的叠加。

Result: 在GSM8k数据集上达到最新最好成绩，推理链长度减少至原来的四分之一，且性能与显式SFT持平，明显超过以往潜在空间推理方法。在Math500和AIME24上也优于基于隐藏状态的方法。

Conclusion: Latent-SFT方法在大幅降低推理计算量的同时，保持并提升了模型性能，实现了有效的潜在空间结构化推理，让潜在推理既可压缩单一路径，也可并行多条路径。

Abstract: Large language models (LLMs) demonstrate strong reasoning abilities with
chain-of-thought prompting, but explicit reasoning introduces substantial
computational overhead. Recent work on latent reasoning reduces this cost by
reasoning in latent space without explicit supervision, but performance drops
significantly. Our preliminary experiments suggest that this degradation stems
from the unstructured latent space, which makes fitting latent tokens
difficult. To address this, we restrict the latent space to the column space of
the LLM vocabulary, treating latent reasoning as a superposition over
vocabulary probabilities. Once latent reasoning concludes, it collapses into an
eigenstate of explicit reasoning to yield the final answer. Based on this idea,
we propose Latent-SFT, a two-stage learning framework. In the first stage, we
design two specialized attention masks to guide the Latent Token Encoder in
generating latent tokens, allowing the LLM to produce the correct answer
conditioned on them. In the second stage, the Latent Token Encoder is
discarded, and the LLM is directly trained to generate these latent tokens
autonomously for latent reasoning, optimized with KL and CE losses. Latent-SFT
sets a new state of the art on GSM8k, matching explicit SFT performance while
cutting reasoning chains by up to 4 times and outperforming prior latent
methods. On Math500 and AIME24, lexical probability-based latent reasoning also
clearly surpasses hidden-state-based approaches. Our metrics of effective
compression rate and effective global parallelism further show that latent
reasoning is both the compression of a single path and the superposition of
multiple paths.

</details>


### [48] [MCA: Modality Composition Awareness for Robust Composed Multimodal Retrieval](https://arxiv.org/abs/2510.15543)
*Qiyu Wu,Shuyang Cui,Satoshi Hayakawa,Wei-Yao Wang,Hiromi Wakaki,Yuki Mitsufuji*

Main category: cs.CL

TL;DR: 论文发现，传统对比学习训练的统一编码器易出现模态捷径，检索鲁棒性不足。为此，提出模态组合感知框架，实验验证在分布外检索任务上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 统一编码器在多模态检索中具有灵活性和先进性，但传统对比学习训练的统一编码器容易学习模态捷径，导致分布外鲁棒性较差。

Method: 提出了模态组合感知框架，包括偏好损失和组合正则化目标，分别促进多模态嵌入优于单模态嵌入，并将多模态嵌入与由其单模态部分组合而成的原型对齐。

Result: 在多项基准上进行实验，结果显示分布外检索性能得到提升。

Conclusion: 利用带有模态组合感知的多模态大模型统一编码器，可以有效提升多模态检索的鲁棒性。

Abstract: Multimodal retrieval, which seeks to retrieve relevant content across
modalities such as text or image, supports applications from AI search to
contents production. Despite the success of separate-encoder approaches like
CLIP align modality-specific embeddings with contrastive learning, recent
multimodal large language models (MLLMs) enable a unified encoder that directly
processes composed inputs. While flexible and advanced, we identify that
unified encoders trained with conventional contrastive learning are prone to
learn modality shortcut, leading to poor robustness under distribution shifts.
We propose a modality composition awareness framework to mitigate this issue.
Concretely, a preference loss enforces multimodal embeddings to outperform
their unimodal counterparts, while a composition regularization objective
aligns multimodal embeddings with prototypes composed from its unimodal parts.
These objectives explicitly model structural relationships between the composed
representation and its unimodal counterparts. Experiments on various benchmarks
show gains in out-of-distribution retrieval, highlighting modality composition
awareness as a effective principle for robust composed multimodal retrieval
when utilizing MLLMs as the unified encoder.

</details>


### [49] [TokenTiming: A Dynamic Alignment Method for Universal Speculative Decoding Model Pairs](https://arxiv.org/abs/2510.15545)
*Sibo Xiao,Jinyuan Fu,Zhongle Xie,Lidan Shou*

Main category: cs.CL

TL;DR: 本文提出TokenTiming算法，结合DTW实现不同词表下的通用疑似解码，无需重训练，平均推理加速1.57倍，显著扩展了大模型加速的适用性。


<details>
  <summary>Details</summary>
Motivation: 现有的speculative decoding方法要求起草模型与目标模型必须共享词表，大大限制了选用起草模型的范围，并常常需要从头训练新模型。本文旨在打破该限制，提升疑似解码方法的通用性和实用性。

Method: 引入了TokenTiming算法，利用动态时间规整（DTW）思想，通过将起草模型的token序列重新编码为目标模型的token序列，并使用DTW建立映射，将概率分布用于speculative采样，从而实现支持不同词表的推理加速。

Result: TokenTiming算法在多个任务上实验，平均实现了1.57倍的推理加速。

Conclusion: 提出了一种通用的疑似解码（speculative decoding）方法，使得起草模型和目标模型可以拥有不同的词表，无需重新训练或修改原模型。该方法提升了大模型推理效率，使疑似解码更加实用和灵活。

Abstract: Accelerating the inference of large language models (LLMs) has been a
critical challenge in generative AI. Speculative decoding (SD) substantially
improves LLM inference efficiency. However, its utility is limited by a
fundamental constraint: the draft and target models must share the same
vocabulary, thus limiting the herd of available draft models and often
necessitating the training of a new model from scratch. Inspired by Dynamic
Time Warping (DTW), a classic algorithm for aligning time series, we propose
the algorithm TokenTiming for universal speculative decoding. It operates by
re-encoding the draft token sequence to get a new target token sequence, and
then uses DTW to build a mapping to transfer the probability distributions for
speculative sampling. Benefiting from this, our method accommodates mismatched
vocabularies and works with any off-the-shelf models without retraining and
modification. We conduct comprehensive experiments on various tasks,
demonstrating 1.57x speedup. This work enables a universal approach for draft
model selection, making SD a more versatile and practical tool for LLM
acceleration.

</details>


### [50] [Rethinking Cross-lingual Gaps from a Statistical Viewpoint](https://arxiv.org/abs/2510.15551)
*Vihari Piratla,Purvam Jain,Darshan Singh,Partha Talukdar,Trevor Cohn*

Main category: cs.CL

TL;DR: 论文发现跨语言准确率差异主要源于回应方差；首次用偏差-方差分解阐释该问题，并通过调整推理过程成功提升了目标语言查询的准确率。


<details>
  <summary>Details</summary>
Motivation: 大多数知识通常以一种或少数几种语言表达，跨语言获取和推理知识时存在准确率下降（跨语言间隙），这一问题亟需解决。

Method: 本文首次用偏差-方差分解对跨语言间隙进行形式化，将响应方差视为主要原因，并通过多项实验和推理时干预（如简单的提示指令）来验证和缓解该问题。

Result: 通过控制响应方差，例如通过提示指令，成功将目标语言准确率提升了20-25%，各种模型均有类似改善。

Conclusion: 跨语言推理的准确率降低主要受响应方差影响，通过减少方差可以有效缩小跨语言差距，显著提升LLM在目标语言下的表现。

Abstract: Any piece of knowledge is usually expressed in one or a handful of natural
languages on the web or in any large corpus. Large Language Models (LLMs) act
as a bridge by acquiring knowledge from a source language and making it
accessible when queried from target languages. Prior research has pointed to a
cross-lingual gap, viz., a drop in accuracy when the knowledge is queried in a
target language compared to when the query is in the source language. Existing
research has rationalized divergence in latent representations in source and
target languages as the source of cross-lingual gap. In this work, we take an
alternative view and hypothesize that the variance of responses in the target
language is the main cause of this gap. For the first time, we formalize the
cross-lingual gap in terms of bias-variance decomposition. We present extensive
experimental evidence which support proposed formulation and hypothesis. We
then reinforce our hypothesis through multiple inference-time interventions
that control the variance and reduce the cross-lingual gap. We demonstrate a
simple prompt instruction to reduce the response variance, which improved
target accuracy by 20-25% across different models.

</details>


### [51] [Think Parallax: Solving Multi-Hop Problems via Multi-View Knowledge-Graph-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2510.15552)
*Jinliang Liu*

Main category: cs.CL

TL;DR: 本文提出ParallaxRAG，通过解耦查询与三元组实现了多视角关注机制，有效提升了基于知识图谱的多跳问答任务的表现，减少幻觉并提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在语言理解上表现优异，但在处理多跳推理时容易出现幻觉现象且推理能力不足。现有的知识图谱增强生成方法大多依赖简单的嵌入和噪声路径，无法有效地提升推理准确性。因此，作者希望通过新的方法提升知识图谱驱动下的多跳推理效果，减少幻觉发生。

Method: 提出ParallaxRAG框架，将查询与知识图谱三元组对称地解耦到多视角空间中，显式地针对注意力头进行多样性约束，同时限制弱相关路径。通过分析不同注意力头在推理链不同阶段具体承担的语义关系，指导构建更干净的子图，并引导大语言模型进行逐步、扎实推理。

Result: 在WebQSP和CWQ两个基准下进行实验，使用统一且可复现的设置（BGE-M3 + Llama3.1-8B），取得了有竞争力的检索与问答性能，同时有效减少了幻觉问题并实现了较好的泛化能力。

Conclusion: 多视角注意力头专化是知识支撑型多跳推理的一条可行且有效的研究方向。ParallaxRAG机制可以引导模型进行更准确、更可控的多跳推理，对未来LLM结合知识图谱的应用具有重要参考价值。

Abstract: Large language models (LLMs) excel at language understanding but often
hallucinate and struggle with multi-hop reasoning. Knowledge-graph-based
retrieval-augmented generation (KG-RAG) offers grounding, yet most methods rely
on flat embeddings and noisy path exploration. We propose ParallaxRAG, a
framework that symmetrically decouples queries and graph triples into
multi-view spaces, enabling a robust retrieval architecture that explicitly
enforces head diversity while constraining weakly related paths. Central to our
approach is the observation that different attention heads specialize in
semantic relations at distinct reasoning stages, contributing to different hops
of the reasoning chain. This specialization allows ParallaxRAG to construct
cleaner subgraphs and guide LLMs through grounded, step-wise reasoning.
Experiments on WebQSP and CWQ, under our unified, reproducible setup (BGE-M3 +
Llama3.1-8B), demonstrate competitive retrieval and QA performance, alongside
reduced hallucination and good generalization. Our results highlight multi-view
head specialization as a principled direction for knowledge-grounded multi-hop
reasoning. Our implementation will be released as soon as the paper is
accepted.

</details>


### [52] [KITE: A Benchmark for Evaluating Korean Instruction-Following Abilities in Large Language Models](https://arxiv.org/abs/2510.15558)
*Dongjun Kim,Chanhee Park,Chanjun Park,Heuiseok Lim*

Main category: cs.CL

TL;DR: 本文提出了用于韩语大模型开放式指令任务评测的KITE基准，并通过自动化和人工评估揭示模型表现差异。KITE的发布有助于推动多语言大模型发展，促进语言和文化多样性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在执行指令任务上的能力评估主要集中于英语，忽视了其他语言的文化和语言特性。韩语尤其存在语法、形态、敬语系统等独特性，但没有专门用于开放式任务指令跟随能力的评测标准。

Method: 提出了KITE（Korean Instruction-following Task Evaluation）基准，设计用于评估通用以及韩语特有的指令，涵盖开放式任务。评测方法结合自动化指标与人工评估，以分析模型在不同任务下的表现。

Result: 实验揭示出不同模型在指令跟随任务上的性能差异，并能深入洞察各自优势和不足。KITE数据集及代码已公开，有利于促进多语言和文化包容性的大模型研发。

Conclusion: KITE填补了韩语在开放式指令跟随能力评测上的空白，能推动相关领域更广泛、多样化的发展，并为其他资源稀缺语言提供参考。

Abstract: The instruction-following capabilities of large language models (LLMs) are
pivotal for numerous applications, from conversational agents to complex
reasoning systems. However, current evaluations predominantly focus on English
models, neglecting the linguistic and cultural nuances of other languages.
Specifically, Korean, with its distinct syntax, rich morphological features,
honorific system, and dual numbering systems, lacks a dedicated benchmark for
assessing open-ended instruction-following capabilities. To address this gap,
we introduce the Korean Instruction-following Task Evaluation (KITE), a
comprehensive benchmark designed to evaluate both general and Korean-specific
instructions. Unlike existing Korean benchmarks that focus mainly on factual
knowledge or multiple-choice testing, KITE directly targets diverse, open-ended
instruction-following tasks. Our evaluation pipeline combines automated metrics
with human assessments, revealing performance disparities across models and
providing deeper insights into their strengths and weaknesses. By publicly
releasing the KITE dataset and code, we aim to foster further research on
culturally and linguistically inclusive LLM development and inspire similar
endeavors for other underrepresented languages.

</details>


### [53] [Finetuning LLMs for EvaCun 2025 token prediction shared task](https://arxiv.org/abs/2510.15561)
*Josef Jon,Ondřej Bojar*

Main category: cs.CL

TL;DR: 作者利用主办方提供的数据直接微调三种LLM，测试了三种预测提示方案，在缺乏领域知识和数据处理的条件下，进行了token预测任务的效果评估。


<details>
  <summary>Details</summary>
Motivation: 探索无需领域知识和特殊预处理情况下，直接微调LLM用于token预测任务的可行性及效果，并比较不同提示方法的表现。

Method: 依托主办方提供的训练数据，对三种不同的大型语言模型（Command-R、Mistral、Aya Expanse）进行微调，分别采用三种不同的提示（prompt）设计实现token预测，并在保留数据集上进行评估比较。

Result: 三种基于不同提示的大模型方案在持出数据集上完成了效果对比。具体数值和优劣未在摘要中说明。

Conclusion: 尽管研究团队对任务领域和相关语言了解有限，但直接利用训练数据微调LLM模型，无需特定预处理或调整，在任务中获得了一定效果。

Abstract: In this paper, we present our submission for the token prediction task of
EvaCun 2025. Our sys-tems are based on LLMs (Command-R, Mistral, and Aya
Expanse) fine-tuned on the task data provided by the organizers. As we only
pos-sess a very superficial knowledge of the subject field and the languages of
the task, we simply used the training data without any task-specific
adjustments, preprocessing, or filtering. We compare 3 different approaches
(based on 3 different prompts) of obtaining the predictions, and we evaluate
them on a held-out part of the data.

</details>


### [54] [From Ghazals to Sonnets: Decoding the Polysemous Expressions of Love Across Languages](https://arxiv.org/abs/2510.15569)
*Syed Mohammad Sualeh Ali*

Main category: cs.CL

TL;DR: 本文研究乌尔都诗歌关于“爱”的三种表达（pyaar、muhabbat、ishq），揭示它们在情感和语义上的细致区别，并通过与英语词汇的对比及词嵌入技术，展现了不同语言与文化在表达“爱”时的独特性和复杂性。


<details>
  <summary>Details</summary>
Motivation: 乌尔都诗歌中的“爱”有多个表达方式（pyaar、muhabbat、ishq），它们在含义与情感色彩上存在细微但重要的差异。然而，这些细腻的区别在英语等其他语言中难以对应或翻译，因此研究这些词汇对于理解乌尔都诗歌的深层情感具有重要意义。

Method: 本研究采用多义性案例研究方法，详细分析了乌尔都诗歌中三个表达“爱”的词汇（pyaar、muhabbat、ishq）的语境与用法。同时，研究比较了乌尔都语和英语中与“爱”相关的词汇，使用词嵌入技术对这些词进行量化与可视化，展现它们的语义空间与文化差异。

Result: 分析揭示了pyaar、muhabbat与ishq在乌尔都诗歌中的细微语义区别，这些词在英语中缺乏直接对应表达。通过词嵌入方法，成功展示出两种语言在“爱”的表达上的语义空间差异与文化内涵。

Conclusion: 乌尔都诗歌中“爱”的多种表达具有复杂的语义层次，本研究通过多义性分析和词嵌入比较，深化了对乌尔都诗歌独特情感表达的理解，也提示了语言与文化在表达深层情感时的独特性与不可译性。

Abstract: This paper delves into the intricate world of Urdu poetry, exploring its
thematic depths through a lens of polysemy. By focusing on the nuanced
differences between three seemingly synonymous words (pyaar, muhabbat, and
ishq) we expose a spectrum of emotions and experiences unique to the Urdu
language. This study employs a polysemic case study approach, meticulously
examining how these words are interwoven within the rich tapestry of Urdu
poetry. By analyzing their usage and context, we uncover a hidden layer of
meaning, revealing subtle distinctions which lack direct equivalents in English
literature. Furthermore, we embark on a comparative analysis, generating word
embeddings for both Urdu and English terms related to love. This enables us to
quantify and visualize the semantic space occupied by these words, providing
valuable insights into the cultural and linguistic nuances of expressing love.
Through this multifaceted approach, our study sheds light on the captivating
complexities of Urdu poetry, offering a deeper understanding and appreciation
for its unique portrayal of love and its myriad expressions

</details>


### [55] [BiMax: Bidirectional MaxSim Score for Document-Level Alignment](https://arxiv.org/abs/2510.15577)
*Xiaotian Wang,Takehito Utsuro,Masaaki Nagata*

Main category: cs.CL

TL;DR: 提出了BiMax方法，在保证与最佳文档对齐方法相当的准确率下，效率提升百倍，并推出了开放源代码工具EmbDA。


<details>
  <summary>Details</summary>
Motivation: 当前的文档对齐方法在跨语言网页数据挖掘中效果突出，但面对大规模数据时，准确率与速度无法兼得。因此，提升文档对齐的效率，兼顾精度，是亟需解决的问题。

Method: 本文提出了跨语言双向最大相似分数（BiMax）方法，用于计算文档间相似度，以提高对齐效率，并与现有的Optimal Transport方法进行了对比。

Result: 在WMT16双语文档对齐任务中，BiMax方法在与Optimal Transport相当的准确率下，速度提升了约100倍。同时，还系统分析了当前主流的多语言句子嵌入模型的表现。

Conclusion: BiMax显著提升了文档对齐的效率且保持高准确率，研究结果以EmbDA工具公开。

Abstract: Document alignment is necessary for the hierarchical mining (Ba\~n\'on et
al., 2020; Morishita et al., 2022), which aligns documents across source and
target languages within the same web domain. Several high precision sentence
embedding-based methods have been developed, such as TK-PERT (Thompson and
Koehn, 2020) and Optimal Transport (OT) (Clark et al., 2019; El-Kishky and
Guzm\'an, 2020). However, given the massive scale of web mining data, both
accuracy and speed must be considered. In this paper, we propose a
cross-lingual Bidirectional Maxsim score (BiMax) for computing doc-to-doc
similarity, to improve efficiency compared to the OT method. Consequently, on
the WMT16 bilingual document alignment task, BiMax attains accuracy comparable
to OT with an approximate 100-fold speed increase. Meanwhile, we also conduct a
comprehensive analysis to investigate the performance of current
state-of-the-art multilingual sentence embedding models. All the alignment
methods in this paper are publicly available as a tool called EmbDA
(https://github.com/EternalEdenn/EmbDA).

</details>


### [56] [The Elephant in the Coreference Room: Resolving Coreference in Full-Length French Fiction Works](https://arxiv.org/abs/2510.15594)
*Antoine Bourgois,Thierry Poibeau*

Main category: cs.CL

TL;DR: 作者推出了一个针对长法语小说的新共指消解数据集，以及一套可扩展的解决流程，有效提升了长文档准确率，并可用于角色性别推断，对文学与NLP领域均具参考价值。


<details>
  <summary>Details</summary>
Motivation: 目前文献计算领域对于共指消解的关注度日益增加，但缺乏针对长文档、完整标注的数据集。此前的数据集大多仅涵盖较短文本，难以充分评估共指消解在复杂文学作品中的表现。

Method: 作者构建了一个全新的语料库，包括三部完整的法语小说（超过285,000词），并提出了一个模块化的共指消解流程，可以针对长文档进行细粒度误差分析。

Result: 提出的方法可有效扩展到长文档，并在共指分辨能力上与现有方法具备竞争力。此外，系统能够用于推断虚构人物的性别，对文学分析及下游NLP任务都具有实用价值。

Conclusion: 本论文填补了长文档共指消解数据集的空白，为复杂文学作品中的共指分辨评估和相关分析任务提供了新的资源和工具。模块化流程不仅提升了分析能力，还证明其在实际应用中的扩展性和有效性。

Abstract: While coreference resolution is attracting more interest than ever from
computational literature researchers, representative datasets of fully
annotated long documents remain surprisingly scarce. In this paper, we
introduce a new annotated corpus of three full-length French novels, totaling
over 285,000 tokens. Unlike previous datasets focused on shorter texts, our
corpus addresses the challenges posed by long, complex literary works, enabling
evaluation of coreference models in the context of long reference chains. We
present a modular coreference resolution pipeline that allows for fine-grained
error analysis. We show that our approach is competitive and scales effectively
to long documents. Finally, we demonstrate its usefulness to infer the gender
of fictional characters, showcasing its relevance for both literary analysis
and downstream NLP tasks.

</details>


### [57] [HypoSpace: Evaluating LLM Creativity as Set-Valued Hypothesis Generators under Underdetermination](https://arxiv.org/abs/2510.15614)
*Tingting Chen,Beibei Lin,Zifeng Yuan,Qiran Zou,Hongyu He,Yew-Soon Ong,Anirudh Goyal,Dianbo Liu*

Main category: cs.CL

TL;DR: 本文提出HypoSpace工具用于多假设生成的LLM评测，结合有效性、独特性、覆盖率三指标，揭示现有模型在面对复杂假设空间时常出现模式坍塌，仅正确率难以反映这一能力缺陷。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型在科学研究领域的广泛应用，评估其提出多个假设集（而不仅仅是单一正确答案）的能力变得尤为重要，尤其是在科学问题通常为“欠定型”（即多个机制不同的假设均可解释同一观测）的背景下。

Method: 提出HypoSpace诊断套件，将LLM视为有限假设集的采样器，衡量三个互补指标：有效性（提出的假设与观测一致的精度）、独特性（假设之间的非冗余性）、覆盖率（枚举出所有可允许假设集的能力）。在三个结构化领域进行实例化：（1）基于扰动的因果图，（2）重力约束的三维体素重建，（3）布尔遗传交互，同时采用确定性验证器和完全枚举的假设空间。

Result: 通过对多种指令微调和推理为主的模型测试，结果发现，随着可允许假设空间变大，有效性指标通常保持较高，但独特性和覆盖率指标会下降，暴露出模式坍塌现象（即模型仅偏向少数假设），而这一现象在仅依赖正确率的传统指标下难以察觉。

Conclusion: HypoSpace工具能够为探究和覆盖可解释假设空间的方法提供受控的测试环境，而不是单一的排行榜评比，针对科学问题的多假设采样能力进行细致评测。

Abstract: As language models are increasingly used in scientific workflows, evaluating
their ability to propose sets of explanations-not just a single correct
answer-becomes critical. Many scientific problems are underdetermined:
multiple, mechanistically distinct hypotheses are consistent with the same
observations. We introduce HypoSpace, a diagnostic suite that treats LLMs as
samplers of finite hypothesis sets and measures three complementary indicators:
Validity (precision of proposals consistent with observations), Uniqueness
(non-redundancy among proposals), and Recovery (coverage of the enumerated
admissible set). We instantiate HypoSpace in three structured domains with
deterministic validators and exactly enumerated hypothesis spaces: (i) causal
graphs from perturbations, (ii) gravity-constrained 3D voxel reconstruction
from top-down projections, and (iii) Boolean genetic interactions. Across
instruction-tuned and reasoning-focused models, Validity often remains high
while Uniqueness and Recovery degrade as the admissible space grows, revealing
mode collapse that is invisible to correctness-only metrics. HypoSpace offers a
controlled probe-rather than a leaderboard-for methods that explicitly explore
and cover admissible explanation spaces. Code is available at:
https://github.com/CTT-Pavilion/_HypoSpace.

</details>


### [58] [Leveraging LLMs for Context-Aware Implicit Textual and Multimodal Hate Speech Detection](https://arxiv.org/abs/2510.15685)
*Joshua Wolfe Brook,Ilia Markov*

Main category: cs.CL

TL;DR: 通过用大模型生成背景知识并嵌入分类器输入，可以显著改善文本和图文混合仇恨言论检测结果。


<details>
  <summary>Details</summary>
Motivation: 当前仇恨言论检测（HSD）面临隐性表达形式难以准确识别的问题，且多模态内容进一步增加了检测难度。为提升检测性能，需要有效利用外部背景知识。

Method: 提出使用大型语言模型（LLMs）作为动态知识库，自动生成背景上下文信息，并将其融入HSD分类器输入。上下文生成分为基于命名实体和全文提示两种策略；上下文融合方式包括文本拼接、embedding拼接、层次化transformer融合及LLM驱动文本增强。

Result: 实验分别在Latent Hatred（文本数据集）和MAMI（多模态数据集）上验证，embedding拼接方式获得最佳性能，相比无上下文基线模型，文本和多模态任务F1分数分别提升最高可达3和6点。

Conclusion: 整合由LLM动态生成的背景上下文能明显提升HSD任务效果，embedding拼接方式在文本和多模态场景都表现最优。

Abstract: This research introduces a novel approach to textual and multimodal Hate
Speech Detection (HSD), using Large Language Models (LLMs) as dynamic knowledge
bases to generate background context and incorporate it into the input of HSD
classifiers. Two context generation strategies are examined: one focused on
named entities and the other on full-text prompting. Four methods of
incorporating context into the classifier input are compared: text
concatenation, embedding concatenation, a hierarchical transformer-based
fusion, and LLM-driven text enhancement. Experiments are conducted on the
textual Latent Hatred dataset of implicit hate speech and applied in a
multimodal setting on the MAMI dataset of misogynous memes. Results suggest
that both the contextual information and the method by which it is incorporated
are key, with gains of up to 3 and 6 F1 points on textual and multimodal setups
respectively, from a zero-context baseline to the highest-performing system,
based on embedding concatenation.

</details>


### [59] [Cost-Aware Retrieval-Augmentation Reasoning Models with Adaptive Retrieval Depth](https://arxiv.org/abs/2510.15719)
*Helia Hashemi,Victor Rühle,Saravan Rajmohan*

Main category: cs.CL

TL;DR: 本文提出一种动态检索增强推理模型，结合成本感知训练方法，在保证推理效果的同时明显降低资源消耗，实现推理速度与准确性的双提升。


<details>
  <summary>Details</summary>
Motivation: 推理模型表现优异，但检索增强方法通常带来较高的计算成本，因此需要提升推理效率，减少资源消耗。

Method: 提出了一种动态调整检索文档长度的检索增强推理模型，并开发了面向成本的优势函数，通过强化学习训练高效模型。同时探索了针对不同约束（内存和延迟）的实现框架，并在两种主流策略优化算法中进行测试。

Result: 在七个公开问答数据集上，该方法显著提升了推理效率，模型延迟平均降低16-20%，且精度（exact match）平均提升约5%。

Conclusion: 通过动态调整检索文档长度与面向成本的训练方法，显著降低了计算资源消耗，同时提升了推理模型的准确性，证明了方法的有效性。

Abstract: Reasoning models have gained significant attention due to their strong
performance, particularly when enhanced with retrieval augmentation. However,
these models often incur high computational costs, as both retrieval and
reasoning tokens contribute substantially to the overall resource usage. In
this work, we make the following contributions: (1) we propose a
retrieval-augmented reasoning model that dynamically adjusts the length of the
retrieved document list based on the query and retrieval results; (2) we
develop a cost-aware advantage function for training of efficient
retrieval-augmented reasoning models through reinforcement learning; and (3) we
explore both memory- and latency-bound implementations of the proposed
cost-aware framework for both proximal and group relative policy optimization
algorithms. We evaluate our approach on seven public question answering
datasets and demonstrate significant efficiency gains, without compromising
effectiveness. In fact, we observed that the model latency decreases by ~16-20%
across datasets, while its effectiveness increases by ~5% on average, in terms
of exact match.

</details>


### [60] [Attention Sinks in Diffusion Language Models](https://arxiv.org/abs/2510.15731)
*Maximo Eduardo Rulli,Simone Petruzzi,Edoardo Michielon,Fabrizio Silvestri,Simone Scardapane,Alessio Devoto*

Main category: cs.CL

TL;DR: 本文实证分析了扩散式语言模型（DLMs）中的注意力sink现象，发现其表现与自回归模型不同，并在sink遮蔽下依然保持较强鲁棒性，揭示了DLM特有的注意力机制和内部工作方式。


<details>
  <summary>Details</summary>
Motivation: 尽管Masked Diffusion Language Models（DLMs）的效率和表现已被广泛研究，但其内部工作机制尚未被深入探讨。

Method: 对DLM模型的注意力模式进行了实证分析，重点关注attention sinking现象，并与自回归模型（ARMs）进行了对比。

Result: 发现DLM同样存在attention sink现象，但sink位置在生成过程中会动态变化。此外，DLM对sink被遮蔽有更强的鲁棒性，只会带来轻微的性能下降。

Conclusion: DLM的注意力机制和自回归模型存在根本差异，为理解扩散式语言模型的工作原理提供了新视角。

Abstract: Masked Diffusion Language Models (DLMs) have recently emerged as a promising
alternative to traditional Autoregressive Models (ARMs). DLMs employ
transformer encoders with bidirectional attention, enabling parallel token
generation while maintaining competitive performance. Although their efficiency
and effectiveness have been extensively studied, the internal mechanisms that
govern DLMs remain largely unexplored. In this work, we conduct an empirical
analysis of DLM attention patterns, focusing on the attention sinking
phenomenon, an effect previously observed in various transformer-based
architectures. Our findings reveal that DLMs also exhibit attention sinks, but
with distinct characteristics. First, unlike in ARMs, the sink positions in
DLMs tend to shift throughout the generation process, displaying a dynamic
behaviour. Second, while ARMs are highly sensitive to the removal of attention
sinks, DLMs remain robust: masking sinks leads to only a minor degradation in
performance. These results provide new insights into the inner workings of
diffusion-based language models and highlight fundamental differences in how
they allocate and utilize attention compared to autoregressive models.

</details>


### [61] [LLMs Judge Themselves: A Game-Theoretic Framework for Human-Aligned Evaluation](https://arxiv.org/abs/2510.15746)
*Gao Yang,Yuhang Liu,Siyu Miao,Xinyue Liang,Zhengyang Liu,Heyan Huang*

Main category: cs.CL

TL;DR: 论文提出让语言模型通过自动互评和博弈论聚合算法对彼此进行评估，并与人类投票结果对比，发现模型评估结果部分契合人类，但也有不一致，为大模型评估提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 传统的大模型评估方法多依赖于固定格式的任务和参考答案，难以真实反映现代大型语言模型的开放性和主观性，因此亟需更有效的评估方式。

Method: 提出一种新的自动互评方法，让多个语言模型通过自我对弈和互相评审彼此输出，用博弈论投票算法聚合这些评审结果，并与真实人类投票进行对比，检验与人类判断的一致性。

Result: 实验发现，模型互评结果与人类评估有部分一致，也存在明显差异，揭示了理论方法与实际人类评价之间的联系与局限性。

Conclusion: 自动互评结合博弈论聚合和人类验证，为大模型能力评估提供了新的视角，但理论预测与人类判断并不完全一致，需进一步深入研究其应用效果和边界。

Abstract: Ideal or real - that is the question.In this work, we explore whether
principles from game theory can be effectively applied to the evaluation of
large language models (LLMs). This inquiry is motivated by the growing
inadequacy of conventional evaluation practices, which often rely on
fixed-format tasks with reference answers and struggle to capture the nuanced,
subjective, and open-ended nature of modern LLM behavior. To address these
challenges, we propose a novel alternative: automatic mutual evaluation, where
LLMs assess each other's output through self-play and peer review. These peer
assessments are then systematically compared with human voting behavior to
evaluate their alignment with human judgment. Our framework incorporates
game-theoretic voting algorithms to aggregate peer reviews, enabling a
principled investigation into whether model-generated rankings reflect human
preferences. Empirical results reveal both convergences and divergences between
theoretical predictions and human evaluations, offering valuable insights into
the promises and limitations of mutual evaluation. To the best of our
knowledge, this is the first work to jointly integrate mutual evaluation,
game-theoretic aggregation, and human-grounded validation for evaluating the
capabilities of LLMs.

</details>


### [62] [On Non-interactive Evaluation of Animal Communication Translators](https://arxiv.org/abs/2510.15768)
*Orr Paradise,David F. Gruber,Adam Tauman Kalai*

Main category: cs.CL

TL;DR: 提出了一种无需参考译文的机器翻译质量评估方法，并用人类语言实验和理论分析验证其有效性，适用于如动物语言翻译等无基础参考的场景，能提升安全性、伦理性与成本效率。


<details>
  <summary>Details</summary>
Motivation: 当前动物语言到人类语言（如鲸鱼-英语）翻译缺乏准确的参考译文且与动物互动成本高、伦理复杂，因而亟需一种无需参考、互动的自动评估方法。

Method: 利用分段翻译结合NLP中的shuffle测试，通过比较数据顺序与乱序下译文的合理性，作为评估指标，不依赖参考译文。

Result: 在人类低资源语言和人工构造语言上的实验显示，该无参考评估指标与传统带参考译文的评分高度相关，理论分析表明早期学习阶段无需与动物互动也能有效评估翻译系统效果。

Conclusion: 提出了一种无需参考译文即可评估机器翻译质量的方法，并证实在某些情况下仅通过目标语言输出就可以判断翻译系统的有效性。

Abstract: If you had an AI Whale-to-English translator, how could you validate whether
or not it is working? Does one need to interact with the animals or rely on
grounded observations such as temperature? We provide theoretical and
proof-of-concept experimental evidence suggesting that interaction and even
observations may not be necessary for sufficiently complex languages. One may
be able to evaluate translators solely by their English outputs, offering
potential advantages in terms of safety, ethics, and cost. This is an instance
of machine translation quality evaluation (MTQE) without any reference
translations available. A key challenge is identifying ``hallucinations,''
false translations which may appear fluent and plausible. We propose using
segment-by-segment translation together with the classic NLP shuffle test to
evaluate translators. The idea is to translate animal communication, turn by
turn, and evaluate how often the resulting translations make more sense in
order than permuted. Proof-of-concept experiments on data-scarce human
languages and constructed languages demonstrate the potential utility of this
evaluation methodology. These human-language experiments serve solely to
validate our reference-free metric under data scarcity. It is found to
correlate highly with a standard evaluation based on reference translations,
which are available in our experiments. We also perform a theoretical analysis
suggesting that interaction may not be necessary nor efficient in the early
stages of learning to translate.

</details>


### [63] [Emergence of Linear Truth Encodings in Language Models](https://arxiv.org/abs/2510.15804)
*Shauli Ravfogel,Gilad Yehudai,Tal Linzen,Joan Bruna,Alberto Bietti*

Main category: cs.CL

TL;DR: 本文通过设计简单的transformer模型和事实共现的数据分布，揭示了大模型存在真/假线性区分子空间的机制，并用实验和理论两方面支持了这种结构的自然涌现。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究揭示了大语言模型存在能区分真/假的线性子空间，但这些结构为何会在训练中出现仍不清楚。作者旨在探究其背后的机制，并寻找现实与理论的结合点。

Method: 作者设计了一个简单数据分布，使得事实性陈述与其他事实性陈述共同出现，训练一层transformer模型来端到端再现和剖析这种“真/假”线性子空间的机制，并在现实预训练大模型中做了验证实验。

Result: 实验证明，在玩具模型中，网络首先快速记忆具体事实，然后通过较长训练步骤逐步学会以线性方式分离真假事实，从而降低语言模型loss；这种机制在实际大语言模型中也有佐证。

Conclusion: 本文通过一个透明的一层transformer玩具模型，机制性地展示了大模型中线性真理子空间的产生过程，并通过实验证明该机制的合理性与普适性。

Abstract: Recent probing studies reveal that large language models exhibit linear
subspaces that separate true from false statements, yet the mechanism behind
their emergence is unclear. We introduce a transparent, one-layer transformer
toy model that reproduces such truth subspaces end-to-end and exposes one
concrete route by which they can arise. We study one simple setting in which
truth encoding can emerge: a data distribution where factual statements
co-occur with other factual statements (and vice-versa), encouraging the model
to learn this distinction in order to lower the LM loss on future tokens. We
corroborate this pattern with experiments in pretrained language models.
Finally, in the toy setting we observe a two-phase learning dynamic: networks
first memorize individual factual associations in a few steps, then -- over a
longer horizon -- learn to linearly separate true from false, which in turn
lowers language-modeling loss. Together, these results provide both a
mechanistic demonstration and an empirical motivation for how and why linear
truth representations can emerge in language models.

</details>


### [64] [Paper2Web: Let's Make Your Paper Alive!](https://arxiv.org/abs/2510.15842)
*Yuhang Chen,Tianpeng Lv,Siyi Zhang,Yixiang Yin,Yao Wan,Philip S. Yu,Dongping Chen*

Main category: cs.CL

TL;DR: 本文系统性提出学术网页自动生成新方法和评估体系，PWAgent在内容和布局方面大幅优于现有做法，为学术网站建设带来创新与突破。


<details>
  <summary>Details</summary>
Motivation: 现有的学术项目网站在内容展示和交互性上存在不足，常见的方法（如直接用大语言模型生成、模板或HTML转换）难以生成布局合理、交互性强的网站，并且缺乏系统的评估标准。

Method: 提出了Paper2Web数据集和多维度评估框架，包括基于规则的指标（如连通性、完整性）、人工验证的LLM判官（评估交互性、美观性和信息量）以及PaperQuiz用于测试知识保留。此外，提出了PWAgent自主流程，将论文转化为互动性强、多媒体丰富的学术主页，并通过MCP工具迭代优化内容和布局。

Result: 实验表明PWAgent在内容质量和网站布局优化方面明显优于传统的模板网页和 arXiv/alphaXiv 版本，同时保持成本低廉，达到了学术网页生成的帕累托前沿。

Conclusion: 通过建立基准和评估体系，并引入智能化的生成工具，显著提升了学术网页的交互性、布局美观和内容传达效果，为学术网页自动生成提供了高效的新方法。

Abstract: Academic project websites can more effectively disseminate research when they
clearly present core content and enable intuitive navigation and interaction.
However, current approaches such as direct Large Language Model (LLM)
generation, templates, or direct HTML conversion struggle to produce
layout-aware, interactive sites, and a comprehensive evaluation suite for this
task has been lacking. In this paper, we introduce Paper2Web, a benchmark
dataset and multi-dimensional evaluation framework for assessing academic
webpage generation. It incorporates rule-based metrics like Connectivity,
Completeness and human-verified LLM-as-a-Judge (covering interactivity,
aesthetics, and informativeness), and PaperQuiz, which measures paper-level
knowledge retention. We further present PWAgent, an autonomous pipeline that
converts scientific papers into interactive and multimedia-rich academic
homepages. The agent iteratively refines both content and layout through MCP
tools that enhance emphasis, balance, and presentation quality. Our experiments
show that PWAgent consistently outperforms end-to-end baselines like
template-based webpages and arXiv/alphaXiv versions by a large margin while
maintaining low cost, achieving the Pareto-front in academic webpage
generation.

</details>


### [65] [Enhanced Sentiment Interpretation via a Lexicon-Fuzzy-Transformer Framework](https://arxiv.org/abs/2510.15843)
*Shayan Rokhva,Mousa Alizadeh,Maryam Abdollahi Shamami*

Main category: cs.CL

TL;DR: 该论文提出了一种结合规则、深度学习和模糊逻辑的新型情感分析框架，能更准确地识别和量化评论中的情感极性和强度，在多个领域表现优异，并实现更精细和可解释的分析效果。


<details>
  <summary>Details</summary>
Motivation: 由于产品评论和社交媒体帖子中的非正式和领域特定语言，准确检测情感极性与强度具有挑战性。

Method: 提出了一种混合词典-模糊-Transformer的框架，结合了基于规则的启发式方法、深度学习上下文模型和模糊逻辑。流程包括VADER初步情感估计，通过DistilBERT置信度与模糊逻辑进行二阶段调整，最终用定制的模糊推理系统将得分映射为0到1的连续情感评分。

Result: 在食品外卖、电商、旅游和时尚四个领域数据集上实验，模型在与用户评分的匹配、极端情感识别和错误分类率方面均有提升，定量和定性分析均验证了框架的鲁棒性和效率。

Conclusion: 将符号推理与神经网络模型结合，可实现可解释、细粒度的情感分析，尤其适用于语言动态且多变的领域。

Abstract: Accurately detecting sentiment polarity and intensity in product reviews and
social media posts remains challenging due to informal and domain-specific
language. To address this, we propose a novel hybrid lexicon-fuzzy-transformer
framework that combines rule-based heuristics, contextual deep learning, and
fuzzy logic to generate continuous sentiment scores reflecting both polarity
and strength. The pipeline begins with VADER-based initial sentiment
estimations, which are refined through a two-stage adjustment process. This
involves leveraging confidence scores from DistilBERT, a lightweight
transformer and applying fuzzy logic principles to mitigate excessive
neutrality bias and enhance granularity. A custom fuzzy inference system then
maps the refined scores onto a 0 to 1 continuum, producing expert)like
judgments. The framework is rigorously evaluated on four domain-specific
datasets. food delivery, e-commerce, tourism, and fashion. Results show
improved alignment with user ratings, better identification of sentiment
extremes, and reduced misclassifications. Both quantitative metrics
(distributional alignment, confusion matrices) and qualitative insights (case
studies, runtime analysis) affirm the models robustness and efficiency. This
work demonstrates the value of integrating symbolic reasoning with neural
models for interpretable, finegrained sentiment analysis in linguistically
dynamic domains.

</details>


### [66] [SpeechLLMs for Large-scale Contextualized Zero-shot Slot Filling](https://arxiv.org/abs/2510.15851)
*Kadri Hacioglu,Manjunath K E,Andreas Stolcke*

Main category: cs.CL

TL;DR: 本研究系统分析并提升了大语言模型在语音槽填充任务中的表现，提出多项改进并提供实证经验，对实际开发有较强参考价值。


<details>
  <summary>Details</summary>
Motivation: 近年来，语音和文本基础模型（speechLLMs）的兴起，使得语音理解任务有望通过统一、多生成式和指令跟随的方式完成，并提升零样本泛化能力，但这些模型在槽填充任务上的性能和泛化能力仍有待评估和优化。

Method: 本文通过创建槽填充任务的经验上界，分析实际模型的性能、健壮性和泛化差距，并提出改进训练数据、模型结构和训练策略的方法，以缩小与上界的差距。

Result: 改进后的数据、架构和训练策略分别带来了显著的性能提升，并揭示了实际应用中存在的挑战和解决这些挑战的实证建议。

Conclusion: 通过系统性的缺口分析与多方面改进措施，可以有效提升speechLLMs在槽填充任务上的表现，同时为后续研究和实际应用提供了有价值的经验和指导。

Abstract: Slot filling is a crucial subtask in spoken language understanding (SLU),
traditionally implemented as a cascade of speech recognition followed by one or
more natural language understanding (NLU) components. The recent advent of
speech-based large language models (speechLLMs), which integrate speech and
textual foundation models, has opened new avenues for achieving speech
understanding tasks in a more unified, generative, and instruction-following
manner while promising data and compute efficiency with zero-shot abilities,
generalizing to unseen slot labels. We address the slot-filling task by
creating an empirical upper bound for the task, identifying performance,
robustness, and generalization gaps, and proposing improvements to the training
data, architecture, and training strategies to narrow the gap with the upper
bound result. We show that each of these measures improve performance
substantially, while highlighting practical challenges and providing empirical
guidance and insights for harnessing these emerging models.

</details>


### [67] [InfiMed-ORBIT: Aligning LLMs on Open-Ended Complex Tasks via Rubric-Based Incremental Training](https://arxiv.org/abs/2510.15859)
*Pengkai Wang,Qi Zuo,Pengwei Liu,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.CL

TL;DR: 本文提出ORBIT，通过评分标准驱动强化学习训练，显著提升医疗对话场景下大语言模型表现，实现同规模模型SOTA。方法具有良好可扩展性和实用性。


<details>
  <summary>Details</summary>
Motivation: 当前利用强化学习（RL）提升大语言模型（LLMs）主要在奖励可程序化验证的领域（如数学和代码）得到很大进展，而在奖励难以明确定义的开放性领域（如医疗对话），现有RL策略效果受限。因此需要适用于高风险医疗对话的新方法。

Method: 提出了ORBIT，基于开放性评分标准（rubric）的增量训练框架，通过合成对话和动态评分标准创建，实现不依赖外部医学知识的强化学习训练。评分标准用于反馈和引导增量式学习过程，有效提升模型表现。

Result: 在Qwen3-4B-Instruct模型上，ORBIT显著提升模型在HealthBench-Hard基准上的成绩，仅用2千样本，分数由7.0升至27.2，达到同规模模型中的SOTA。分析显示该方法在多种医疗咨询场景下都能持续带来性能提升，并不仅限于数值进步。

Conclusion: 基于评分标准的增量强化学习为大语言模型在复杂、开放性任务中的持续提升提供了可扩展、高效的新策略。

Abstract: Large Language Models (LLMs) have shown substantial advances through
reinforcement learning (RL), particularly in domains where rewards can be
programmatically verified, such as mathematics and code. In these areas, models
benefit from a well-defined operational base guided by explicit rule-based
objectives. However, this progress reveals a significant limitation: in
open-ended domains where rewards are ambiguous, subjective, or
context-dependent, such as creative writing, scientific reasoning, and notably
medical consultation, robust reward functions are lacking, making these areas
challenging for current RL strategies. To bridge this gap, we introduce ORBIT,
an open-ended rubric-based incremental training framework specifically designed
for high-stakes medical dialogue. ORBIT integrates syn- thetic dialogue
generation with the dynamic creation of rubrics, employing these rubrics to
direct an incremental RL process. In particular, this approach does not depend
on external medical knowledge or manual rules, instead utilizing rubric-guided
feedback to shape learning. When implemented on the Qwen3-4B-Instruct model,
our method can greatly enhance its performance on the HealthBench-Hard
benchmark from 7.0 to 27.2 using only 2k samples, thus achieving
state-of-the-art results for models of this scale. Our analysis confirms that
rubric-driven RL fos-ters consistent performance gains across diverse
consultation scenarios, going beyond simple numerical improvements. These
findings underscore rubric-based feedback as a scalable strategy for advancing
LLMs in intricate, open-ended tasks.

</details>


### [68] [PolySkill: Learning Generalizable Skills Through Polymorphic Abstraction](https://arxiv.org/abs/2510.15863)
*Simon Yu,Gang Li,Weiyan Shi,Peng Qi*

Main category: cs.CL

TL;DR: PolySkill通过解耦技能目标与实现，提升了智能体跨网站技能泛化与复用能力，在多个环境下展现出比以往更高的学习效果与适应性。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）驱动的智能体在交互环境中进行持续学习，但技能学习方法通常过度专注于单一网站，导致技能泛化能力差。该研究希望解决技能难以在不同网站间通用的问题。

Method: 提出了PolySkill框架，将技能的抽象目标（做什么）与具体实现（怎么做）解耦，受软件工程中多态性的启发。通过此框架，智能体能习得更通用、具有组合性的技能。进行了实验验证，包括技能重用性、成功率及自探索场景下的任务质量提升。

Result: 1）在已知网站上技能重用提升1.7倍；2）在Mind2Web成功率提升9.4%，在未见网站提升13.9%，且执行步骤减少超过20%；3）在未指定任务的自探索下，智能体能习得在不同网站可用的通用技能。

Conclusion: 解耦技能目标与执行是持续学习智能体实现泛化的关键。PolySkill框架显著提升了学习智能体在开放网络环境中的技能复用和泛化能力，为构建能持续适应环境变化的智能体提供了新路径。

Abstract: Large language models (LLMs) are moving beyond static uses and are now
powering agents that learn continually during their interaction with external
environments. For example, agents can learn reusable skills while navigating
web pages or toggling new tools. However, existing methods for skill learning
often create skills that are over-specialized to a single website and fail to
generalize. We introduce PolySkill, a new framework that enables agents to
learn generalizable and compositional skills. The core idea, inspired by
polymorphism in software engineering, is to decouple a skill's abstract goal
(what it accomplishes) and its concrete implementation (how it is executed).
Experiments show that our method (1) improves skill reuse by 1.7x on seen
websites and (2) boosts success rates by up to 9.4% on Mind2Web and 13.9% on
unseen websites, while reducing steps by over 20%. (3) In self-exploration
settings without specified tasks, our framework improves the quality of
proposed tasks and enables agents to learn generalizable skills that work
across different sites. By enabling the agent to identify and refine its own
goals, the PolySkill enhances the agent's ability to learn a better curriculum,
leading to the acquisition of more generalizable skills compared to baseline
methods. This work provides a practical path toward building agents capable of
continual learning in adaptive environments. Our findings show that separating
a skill's goal from its execution is a crucial step toward developing
autonomous agents that can learn and generalize across the open web
continuously.

</details>
