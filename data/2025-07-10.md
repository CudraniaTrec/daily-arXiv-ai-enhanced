<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]
- [cs.SE](#cs.SE) [Total: 9]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.CL](#cs.CL) [Total: 44]
- [cs.DM](#cs.DM) [Total: 3]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Pyrosome: Verified Compilation for Modular Metatheory](https://arxiv.org/abs/2507.06360)
*Dustin Jamner,Gabriel Kammer,Ritam Nag,Adam Chlipala*

Main category: cs.PL

TL;DR: Pyrosome是一个在Coq中实现的编译器元理论通用框架，通过模块化与归纳方法，支持编译器的增量扩展与跨特性重用原有证明，有效提升了形式化编译器的可扩展性和模块化水平。


<details>
  <summary>Details</summary>
Motivation: 现有的语义推理技术往往紧密绑定于具体语言结构或编译器，扩展编译器或语言功能时极难重用原有的证明，缺乏模块化和可扩展性。

Method: 提出了Pyrosome，一个在Coq中实现的通用模块化语言元理论框架，使用依赖类型的等价理论，创新性地通过归纳表达等价保持性，支持增量式添加语言、目标语言以及编译器的新规则和特性，并通过类型检查和等式推理统一编译器正确性证明。

Result: Pyrosome实现了完全可扩展的形式化编译器，支持任意功能扩展（如新效应），可复用原有正确性证明。通过增量构造System F多遍编译器等案例，证明了支持纵向组合和特性扩展，同时也能处理线性类型和命令式特性。

Conclusion: Pyrosome突破性地实现了元理论上的编译器与语言的可扩展性与模块化，简化了扩展时的证明负担，为形式化编译器设计提供了实用性强的理论和实操工具。

Abstract: We present Pyrosome, a generic framework for modular language metatheory that
embodies a novel approach to extensible semantics and compilation, implemented
in Coq. Common techniques for semantic reasoning are often tied to the specific
structures of the languages and compilers that they support. In Pyrosome,
verified compilers are fully extensible, meaning that to extend a language
(even with a new kind of effect) simply requires defining and verifying the
compilation of the new feature, reusing the old correctness theorem for all
other cases. The novel enabling idea is an inductive formulation of equivalence
preservation that supports the addition of new rules to the source language,
target language, and compiler.
  Pyrosome defines a formal, deeply embedded notion of programming languages
with semantics given by dependently sorted equational theories, so all
compiler-correctness proofs boil down to type-checking and equational
reasoning. We support vertical composition of any compilers expressed in our
framework in addition to feature extension. As a case study, we present a
multipass compiler from System F with simple references, through CPS
translation and closure conversion. Specifically, we demonstrate how we can
build such a compiler incrementally by starting with a compiler for simply
typed lambda-calculus and adding natural numbers, the unit type, recursive
functions, and a global heap, then extending judgments with a type environment
and adding type abstraction, all while reusing the original theorems. We also
present a linear version of the simply typed CPS pass and compile a small
imperative language to the simply typed target to show how Pyrosome handles
substructural typing and imperative features.

</details>


### [2] [Fast Collection Operations from Indexed Stream Fusion](https://arxiv.org/abs/2507.06456)
*Scott Kovach,Praneeth Kolichala,Kyle A. Miller,David Broman,Fredrik Kjolstad*

Main category: cs.PL

TL;DR: 提出一种高效遍历和组合关联集合的新方法，无需特殊编译器，仅用索引流表示，就能高效表达复杂集合操作，并经过理论证明与多语言实现。


<details>
  <summary>Details</summary>
Motivation: 传统的迭代器库通常需要特殊的编译器支持或分阶段编译才能兼顾效率与可组合性，缺乏灵活通用且高性能的解决方案。

Method: 采用基于索引流（indexed streams）的表示方法，避免了中间内存分配，实现了高效的数据集合遍历与组合。

Result: 在Lean、Morphic和Rust三种编程语言中实现了该库，并在Lean中形式化证明了其函数式正确性。

Conclusion: 该系统不需要特殊的编译器基础设施或阶段式编译即可实现高效和可组合的遍历与组合操作，并且表达能力强且高效。

Abstract: We present a system of efficient methods for traversing and combining
associative collection data structures. A distinguishing feature of the system
is that, like traditional sequential iterator libraries, it does not require
specialized compiler infrastructure or staged compilation for efficiency and
composability. By using a representation based on indexed streams, the library
can express complex joins over input collections while using no intermediate
allocations. We implement the library for the Lean, Morphic, and Rust
programming languages and provide a mechanized proof of functional correctness
in Lean.

</details>


### [3] [Finding Compiler Bugs through Cross-Language Code Generator and Differential Testing](https://arxiv.org/abs/2507.06584)
*Qiong Feng,Xiaotian Ma,Ziyuan Feng,Marat Akhin,Wei Song,Peng Liang*

Main category: cs.PL

TL;DR: 本文提出了跨JVM语言通用测试框架CrossLangFuzzer，利用多种变异手段大量曝光编译器跨语言bug，首次系统化诊断并分析了跨语言编译场景下的相关问题，为改进多语言环境下编译器正确性奠定基础。


<details>
  <summary>Details</summary>
Motivation: 以往的编译器验证主要专注于单语言编译，然而多语言编译（即跨语言编译）的正确性研究较为薄弱。本文旨在填补跨语言编译场景下编译器正确性的研究空白。

Method: 提出了一种新的框架CrossLangFuzzer，其引入了通用中间表示（IR），可为JVM系语言自动生成具有多样类型参数和复杂继承结构的跨语言测试程序，并利用三种变异技术（LangShuffler、FunctionRemoval、TypeChanger）增加程序多样性，通过对不同编译器版本的原始与变异程序进行测试以发现编译器缺陷。

Result: CrossLangFuzzer在Kotlin编译器发现10个确认的bug，在Groovy编译器发现4个bug，在Scala 3发现7个，在Scala 2发现2个，在Java编译器发现1个。其中TypeChanger变异器最有效，发现了24个bug中的11个。

Conclusion: 本研究首次提出专门针对跨语言编译场景下编译器bug的测试与诊断方法，系统分析了异编译错误的症状及根因，并厘清了各语言编译器在此类场景下的责任，有助于提升多语言环境下编译器的正确性。

Abstract: Compilers play a central role in translating high-level code into executable
programs, making their correctness essential for ensuring code safety and
reliability. While extensive research has focused on verifying the correctness
of compilers for single-language compilation, the correctness of cross-language
compilation - which involves the interaction between two languages and their
respective compilers - remains largely unexplored. To fill this research gap,
we propose CrossLangFuzzer, a novel framework that introduces a universal
intermediate representation (IR) for JVM-based languages and automatically
generates cross-language test programs with diverse type parameters and complex
inheritance structures. After generating the initial IR, CrossLangFuzzer
applies three mutation techniques - LangShuffler, FunctionRemoval, and
TypeChanger - to enhance program diversity. By evaluating both the original and
mutated programs across multiple compiler versions, CrossLangFuzzer
successfully uncovered 10 confirmed bugs in the Kotlin compiler, 4 confirmed
bugs in the Groovy compiler, 7 confirmed bugs in the Scala 3 compiler, 2
confirmed bugs in the Scala 2 compiler, and 1 confirmed bug in the Java
compiler. Among all mutators, TypeChanger is the most effective, detecting 11
of the 24 compiler bugs. Furthermore, we analyze the symptoms and root causes
of cross-compilation bugs, examining the respective responsibilities of
language compilers when incorrect behavior occurs during cross-language
compilation. To the best of our knowledge, this is the firstwork specifically
focused on identifying and diagnosing compiler bugs in cross-language
compilation scenarios. Our research helps to understand these challenges and
contributes to improving compiler correctness in multi-language environments.

</details>


### [4] [Sound Interval-Based Synthesis for Probabilistic Programs](https://arxiv.org/abs/2507.06939)
*Guilherme Espada,Alcides Fonseca*

Main category: cs.PL

TL;DR: 本论文提出了一套自动、类型安全的概率程序生成方法，极大优化了模型搜索过程，让非统计专家也能便捷地选择和定制概率模型，实验证明该方法优于现有主流工具。


<details>
  <summary>Details</summary>
Motivation: 概率编程已广泛应用于科学领域（如基因学、生态学等），但领域专家在使用时，往往需要精通统计学以选择合适的模型。这对缺乏统计知识的用户是一大障碍。

Method: 提出了一种类型系统，可以在静态阶段拒绝无效的概率程序；同时设计了一个类型引导的自动生成算法，确保生成的程序在构建过程中就是类型安全的；还用启发式搜索方法来应对庞大的程序搜索空间。

Result: 对比现有的无类型随机搜索和数据驱动方法（DaPPer），本文方法在复杂程序的合成上有明显性能优势。显著提高了程序合成效率，促进了遗传编程等方法在复杂概率程序领域的应用。

Conclusion: 所提出的类型系统与类型引导的程序合成方法，可以自动生成高效且类型安全的概率模型，为非统计专业用户简化了概率模型选择流程，并推动了相关领域的研究。

Abstract: Probabilistic programming has become a standard practice to model stochastic
events and learn about the behavior of nature in different scientific contexts,
ranging from Genetics and Ecology to Linguistics and Psychology. However,
domain practitioners (such as biologists) also need to be experts in statistics
in order to select which probabilistic model is suitable for a given particular
problem, relying then on probabilistic inference engines such as Stan, Pyro or
Edward to fine-tune the parameters of that particular model. Probabilistic
Programming would be more useful if the model selection is made automatic,
without requiring statistics expertise from the end user. Automatically
selecting the model is challenging because of the large search space of
probabilistic programs needed to be explored, because the fact that most of
that search space contains invalid programs, and because invalid programs may
only be detected in some executions, due to its probabilistic nature. We
propose a type system to statically reject invalid probabilistic programs, a
type-directed synthesis algorithm that guarantees that generated programs are
type-safe by construction, and an heuristic search procedure to handle the vast
search space. We collect a number of probabilistic programs from the
literature, and use them to compare our method with both a type-agnostic random
search, and a data-guided method from the literature (DaPPer). Our results show
that our technique both outperforms random search and DaPPer, specially on more
complex programs. This drastic performance difference in synthesis allows for
fast sampling of programs and enables techniques that previously suffered from
the complexity of synthesis, such as Genetic Programming, to be applied.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [5] [Quality attributes of test cases and test suites -- importance & challenges from practitioners' perspectives](https://arxiv.org/abs/2507.06343)
*Huynh Khanh Vi Tran,Nauman bin Ali,Michael Unterkalmsteiner,Jürgen Börstler,Panagiota Chatzipetrou*

Main category: cs.SE

TL;DR: 本研究通过大规模业界问卷调查，总结了测试用例及测试套件的关键质量属性及面临的主要挑战，结果为未来学研与企业支持方向提供指导。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究识别了测试用例和测试套件的多种质量属性，但它们在实际工作中的相对重要性尚不明确，需要更深入的研究来理解从业者的实际认知和遇到的挑战。

Method: 基于文献综述确定的质量属性，设计问卷并通过LinkedIn发放，广泛调查具有软件测试经验的业界从业者，以收集他们的看法和遇到的挑战。

Result: 收集到354份从业者问卷回复，显示大多数从业者认为故障检测、可用性、可维护性、可靠性和覆盖率是最重要的质量属性。资源效率、可复用性和简洁性评价分歧较大，并且这些意见依赖于具体的软件测试情境。此外，重要属性共同面临定义不明确、缺乏有效度量标准、缺乏评审流程和外部支持等挑战。

Conclusion: 研究揭示了业界在实现高质量测试用例和测试套件方面最需支持的领域，为学术研究和企业提供实际指导，帮助优化测试质量保障。

Abstract: Context: The quality of the test suites and the constituent test cases
significantly impacts confidence in software testing. While research has
identified several quality attributes of test cases and test suites, there is a
need for a better understanding of their relative importance in practice.
Objective: We investigate practitioners' perceptions regarding the relative
importance of quality attributes of test cases and test suites and the
challenges they face in ensuring the perceived important quality attributes.
Method: We conducted an industrial survey using a questionnaire based on the
quality attributes identified in an extensive literature review. We used a
sampling strategy that leverages LinkedIn to draw a large and heterogeneous
sample of professionals with experience in software testing. Results: We
collected 354 responses from practitioners with a wide range of experience. We
found that the majority of practitioners rated Fault Detection, Usability,
Maintainability, Reliability, and Coverage to be the most important quality
attributes. Resource Efficiency, Reusability, and Simplicity received the most
divergent opinions, which, according to our analysis, depend on the
software-testing contexts. We identified common challenges that apply to the
important attributes, namely inadequate definition, lack of useful metrics,
lack of an established review process, and lack of external support.
Conclusion: The findings point out where practitioners actually need further
support with respect to achieving high-quality test cases and test suites under
different software testing contexts. The findings can serve as a guideline for
academic researchers when looking for research directions on the topic. The
findings can also be used to encourage companies to provide more support to
practitioners to achieve high-quality test cases and test suites.

</details>


### [6] [A proposal and assessment of an improved heuristic for the Eager Test smell detection](https://arxiv.org/abs/2507.06354)
*Huynh Khanh Vi Tran,Nauman bin Ali,Michael Unterkalmsteiner,Jürgen Börstler*

Main category: cs.SE

TL;DR: 本文提出并验证了一套更精准检测Eager Test味道的新启发式规则，能解决现有方法检测不充分和争议大的问题，为单位测试代码的质量提升提供了更有效的工具。


<details>
  <summary>Details</summary>
Motivation: 目前检测单元测试中的Eager Test味道主要依赖自动化工具，但这些工具的检测规则过于简单，难以满足实际需求，导致检测结果不准确。研究者和实践者都希望提升检测的精度和一致性。

Method: 作者对测试味道相关文献进行了系统梳理，分析Eager Test味道的定义和已有检测规则；基于这些分析，提出了一个新的、明确的Eager Test定义，并设计了新的检测启发式规则。通过对300个Java单元测试用例的人工应用新规则，与现有方法进行对比评估。

Result: 发现已有文献中Eager Test定义和检测规则存在解读不充分和实现不精确的问题，现有规则检测结果经常不一致。新提出的启发式规则能更准确地检测Eager Test及非Eager Test的模式，补足了已有规则的不足。

Conclusion: 新提出的检测启发式规则能更好地把握Eager Test的本质，提高了检测的准确性，有望解决实际应用中现有检测规则不充分的问题。

Abstract: Context: The evidence for the prevalence of test smells at the unit testing
level has relied on the accuracy of detection tools, which have seen intense
research in the last two decades. The Eager Test smell, one of the most
prevalent, is often identified using simplified detection rules that
practitioners find inadequate. Objective: We aim to improve the rules for
detecting the Eager Test smell. Method: We reviewed the literature on test
smells to analyze the definitions and detection rules of the Eager Test smell.
We proposed a novel, unambiguous definition of the test smell and a heuristic
to address the limitations of the existing rules. We evaluated our heuristic
against existing detection rules by manually applying it to 300 unit test cases
in Java. Results: Our review identified 56 relevant studies. We found that
inadequate interpretations of original definitions of the Eager Test smell led
to imprecise detection rules, resulting in a high level of disagreement in
detection outcomes. Also, our heuristic detected patterns of eager and
non-eager tests that existing rules missed. Conclusion: Our heuristic captures
the essence of the Eager Test smell more precisely; hence, it may address
practitioners' concerns regarding the adequacy of existing detection rules.

</details>


### [7] [Evaluating Efficiency and Novelty of LLM-Generated Code for Graph Analysis](https://arxiv.org/abs/2507.06463)
*Atieh Barati Nia,Mohammad Dindoost,David A. Bader*

Main category: cs.SE

TL;DR: 本研究系统比较了8种最先进LLM在C语言图算法实现效率上的表现，发现Anthropic Claude Sonnet 4 Extended在代码效率和集成性上优于其他模型及人类基线，但目前LLM仍难以发明全新算法。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型（LLMs）越来越多地被应用于软件开发自动化，但以往的评估主要集中在功能正确性或高级语言（如Python）。本研究动机是系统性地评估LLMs在生成高效C语言图算法代码能力，尤其强调对运行时和内存约束的满足能力。

Method: 研究对8种最先进的LLM（包括OpenAI ChatGPT、Anthropic Claude、Google Gemini、xAI Grok和DeepSeek DeepThink）进行了系统性基准测试。第一种评估方法考察LLM能否生成在现有基准中性能超越的算法；第二种方法评估其为基准库集成图算法代码的能力。

Result: Claude Sonnet 4 Extended在即用型代码生成与效率方面表现最佳，甚至在三角计数任务上超越了人类手写代码基线。综合研究显示，当前LLMs在优化和集成成熟算法方面表现出色，但尚不具备发明新算法的能力。

Conclusion: 现代LLMs在高效C代码生成、算法优化和集成方面具有很强实力，能够在特定任务（如三角计数）达到甚至超越人类基线，但在算法创新上仍有限。该研究提供了相关工具和生成内容，方便重现性研究。

Abstract: Large Language Models (LLMs) are increasingly used to automate software
development, yet most prior evaluations focus on functional correctness or
high-level languages such as Python. We present the first systematic study of
LLMs' ability to generate efficient C implementations of graph-analysis
routines--code that must satisfy the stringent runtime and memory constraints.
Eight state-of-the-art models (OpenAI ChatGPT o3 and o4-mini-high, Anthropic
Claude 4 Sonnet and Sonnet Extended, Google Gemini 2.5 Flash and Pro, xAI Grok
3-Think, and DeepSeek DeepThink R1) are benchmarked by two distinct approaches.
The first approach checks the ability of LLMs in generating an algorithm
outperforming other present algorithms in the benchmark. The second approach
evaluates the ability of LLMs to generate graph algorithms for integration into
the benchmark. Results show that Claude Sonnet 4 Extended achieves the best
result in the case of ready-to-use code generation and efficiency,
outperforming human-written baselines in triangle counting. The study confirms
that contemporary LLMs excel at optimizing and integrating established
algorithms but not inventing novel techniques. We provide prompts, the first
approach's generated code, and measurement scripts to foster reproducible
research.

</details>


### [8] [Issue Tracking Ecosystems: Context and Best Practices](https://arxiv.org/abs/2507.06704)
*Lloyd Montgomery*

Main category: cs.SE

TL;DR: 本论文首次对问题追踪生态系统（ITE）进行系统性研究，通过访谈与档案分析揭示了其情境依赖性，并开发了最佳实践本体，为推动研究与实践协同提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 虽然许多研究关注于问题追踪系统（ITSs），但作为整体的“问题追踪生态系统”（ITE）尚未得到充分探索。ITE涉及的复杂网络、各类关联的工件和流程会直接影响软件工程组织和产品成功。研究动机是理解和解决ITE的复杂性与多样性带来的问题。

Method: 本论文通过两种方式展开研究：（1）对多种ITS系统的实际用户（从业人员）进行访谈；（2）对不同ITS系统进行档案分析。这些方法帮助揭示了ITE问题的情境相关性。根据这些发现，作者还开发了一个 ITEs 最佳实践本体（Best Practice Ontology）。

Result: 研究显示，ITE中的问题极大程度依赖于具体环境（context-dependent），现有针对ITS问题的解决方案缺乏一致可比的上下文框架，导致实际应用和研究之间缺乏对齐。通过梳理，论文开发出一个用于统一和指导实践的最佳实践本体。

Conclusion: ITE的复杂性和多样性需要情境化的研究与解决方案。通过最佳实践本体的提出，为研究者和实践者在面对不同ITE情境时提供了参考框架，有助于提升整个生态系统的管理和产品质量。

Abstract: Issue Tracking Systems (ITSs), such as GitHub and Jira, are popular tools
that support Software Engineering (SE) organisations through the management of
``issues'', which represent different SE artefacts such as requirements,
development tasks, and maintenance items. ITSs also support internal linking
between issues, and external linking to other tools and information sources.
This provides SE organisations key forms of documentation, including forwards
and backwards traceability (e.g., Feature Requests linked to sprint releases
and code commits linked to Bug Reports). An Issue Tracking Ecosystem (ITE) is
the aggregate of the central ITS and the related SE artefacts, stakeholders,
and processes -- with an emphasis on how these contextual factors interact with
the ITS. The quality of ITEs is central to the success of these organisations
and their software products. There are challenges, however, within ITEs,
including complex networks of interlinked artefacts and diverse workflows.
While ITSs have been the subject of study in SE research for decades, ITEs as a
whole need further exploration.
  In this thesis, I undertake the challenge of understanding ITEs at a broader
level, addressing these questions regarding complexity and diversity. I
interviewed practitioners and performed archival analysis on a diverse set of
ITSs. These analyses revealed the context-dependent nature of ITE problems,
highlighting the need for context-specific ITE research. While previous work
has produced many solutions to specific ITS problems, these solutions are not
consistently framed in a context-rich and comparable way, leading to a desire
for more aligned solutions across research and practice. To address this
emergent information and lack of alignment, I created the Best Practice
Ontology for ITEs. <... truncated due to arXiv abstract character limit ...>

</details>


### [9] [Leveraging LLMs for Semantic Conflict Detection via Unit Test Generation](https://arxiv.org/abs/2507.06762)
*Nathalia Barbosa,Paulo Borba,Léuson Da Silva*

Main category: cs.SE

TL;DR: 本文将大语言模型Code Llama 70B集成到SMAT工具中，用于改进自动化测试以检测开发过程中的语义冲突。结果显示，虽然复杂场景下测试生成成本高但初步效果良好，未来有望进一步提升冲突检测能力。


<details>
  <summary>Details</summary>
Motivation: 在多人协作开发中，开发者的合并操作可能引入语义冲突，传统的合并工具无法检测到此类冲突，因此需要新的检测手段。SMAT等工具通过自动化单元测试帮助发现语义冲突，但现有测试生成工具如Randoop和Evosuite存在局限导致高假阴性率。作者希望探索大语言模型（LLM）是否能够改善这一问题。

Method: 作者将基于Code Llama 70B的大语言模型设计和集成到SMAT工具中，用作新的测试用例生成器，比较不同的交互策略、提示内容和参数配置，并通过两个数据集评估（一个为简单系统，一个为复杂真实系统）对冲突检测能力的提升。

Result: 实验证明，基于LLM的测试生成在复杂场景下仍然具有挑战且计算开销较高，但表现出提升语义冲突检测能力的潜力。

Conclusion: 将大语言模型集成到现有语义冲突检测工具SMAT中，可以在一定程度上弥补传统测试工具的不足，提高冲突检测的效果，尤其是在复杂系统中有应用前景，但目前仍需进一步优化以降低成本和增强稳定性。

Abstract: Semantic conflicts arise when a developer introduces changes to a codebase
that unintentionally affect the behavior of changes integrated in parallel by
other developers. Traditional merge tools are unable to detect such conflicts,
so complementary tools like SMAT have been proposed. SMAT relies on generating
and executing unit tests: if a test fails on the base version, passes on a
developer's modified version, but fails again after merging with another
developer's changes, a semantic conflict is indicated. While SMAT is effective
at detecting conflicts, it suffers from a high rate of false negatives, partly
due to the limitations of unit test generation tools such as Randoop and
Evosuite. To investigate whether large language models (LLMs) can overcome
these limitations, we propose and integrate a new test generation tool based on
Code Llama 70B into SMAT. We explore the model's ability to generate tests
using different interaction strategies, prompt contents, and parameter
configurations. Our evaluation uses two samples: a benchmark with simpler
systems from related work, and a more significant sample based on complex,
real-world systems. We assess the effectiveness of the new SMAT extension in
detecting conflicts. Results indicate that, although LLM-based test generation
remains challenging and computationally expensive in complex scenarios, there
is promising potential for improving semantic conflict detection.
  --
  Conflitos sem^anticos surgem quando um desenvolvedor introduz mudan\c{c}as em
uma base de c\'odigo que afetam, de forma n~ao intencional, o comportamento de
altera\c{c}~oes integradas em paralelo por outros desenvolvedores. Ferramentas
tradicionais de merge n~ao conseguem detectar esse tipo de conflito, por isso
ferramentas complementares como o SMAT foram propostas. O SMAT depende da
gera\c{c}~ao e execu\c{c}~ao de testes de unidade: se um teste falha na vers~ao
base, passa na vers~ao modificada por um desenvolvedor, mas volta a falhar
ap\'os o merge com as mudan\c{c}as de outro desenvolvedor, um conflito
sem^antico \'e identificado. Embora o SMAT seja eficaz na detec\c{c}~ao de
conflitos, apresenta alta taxa de falsos negativos, em parte devido \`as
limita\c{c}~oes das ferramentas de gera\c{c}~ao de testes como Randoop e
Evosuite. Para investigar se modelos de linguagem de grande porte (LLMs) podem
superar essas limita\c{c}~oes, propomos e integramos ao SMAT uma nova
ferramenta de gera\c{c}~ao de testes baseada no Code Llama 70B. Exploramos a
capacidade do modelo de gerar testes utilizando diferentes estrat\'egias de
intera\c{c}~ao, conte\'udos de prompts e configura\c{c}~oes de par^ametros.
Nossa avalia\c{c}~ao utiliza duas amostras: um benchmark com sistemas mais
simples, usados em trabalhos relacionados, e uma amostra mais significativa
baseada em sistemas complexos e reais. Avaliamos a efic\'acia da nova extens~ao
do SMAT na detec\c{c}~ao de conflitos. Os resultados indicam que, embora a
gera\c{c}~ao de testes por LLM em cen\'arios complexos ainda seja desafiadora e
custosa computacionalmente, h\'a potencial promissor para aprimorar a
detec\c{c}~ao de conflitos sem^anticos.

</details>


### [10] [Formalization of the AADL Run-Time Services with Time](https://arxiv.org/abs/2507.06881)
*Brian R Larson,Ehsan Ahmad*

Main category: cs.SE

TL;DR: 该文基于Kripke结构模态逻辑，加入时间因素，完善AADL运行时服务的形式建模，并将其支持扩展到BLESS状态机，帮助更好地支持复杂嵌入式系统的设计与验证。


<details>
  <summary>Details</summary>
Motivation: AADL是一种用于设计控制软件的物理系统的架构描述语言，但以往对AADL形式语义的建模未能包含时间因素。而运行时服务（RTS）中，特别是通信和定时服务，与时间强相关，现有工作满足不足。

Method: 本文使用以Kripke结构为基础的模态逻辑，明确引入并扩展对时间的形式化建模。扩展RTS的涵盖面，包括行为规范附录标准（BA）及其形式化语言BLESS下的状态转换机支持。

Result: 作者提出了包含时间建模的AADL RTS形式语义，并通过HAMR实现，用BLESS语言书写的状态机行为给出实例验证。

Conclusion: 论文将时间正式纳入AADL RTS的建模语义，增强了对实时和反应性行为的支持，有助于提升AADL控制系统的设计与验证能力。

Abstract: The Architecture Analysis & Design Language (AADL) is an architecture
description language for design of cyber-physical systems--machines controlled
by software. The AADL standard, SAE International AS5506D, describes Run-Time
Services (RTS) to be provided to execute AADL models in accordance with
semantics defined by the standard. The RTS of primary concern are transport
services and timing services. Although, the study presented in [1] sets a
foundation for the formal semantics of AADL, but without modeling time. This
paper extends and simplifies this formalization using a modal logic defined by
a Kripke structure, to explicitly include time. The RTS defined in the AADL
standard are also expanded to support reactive state-transition machines of the
Behavior Specification annex standard language (BA) and its closely-related,
formally-defined counterpart, the Behavior Language for Embedded Systems with
Software (BLESS). An example of AADL RTS with time, implemented by the High
Assurance Modeling and Rapid Engineering for Embedded Systems (HAMR) for
state-transition machine behavior written in BLESS, is also presented.

</details>


### [11] [Are They All Good? Evaluating the Quality of CoTs in LLM-based Code Generation](https://arxiv.org/abs/2507.06980)
*Binquan Zhang,Li Zhang,Zhiwen Luo,Yuxin Du,Fang Liu,Song Wang,Lin Shi*

Main category: cs.SE

TL;DR: 该论文分析了大语言模型在基于思维链提示下代码生成时，影响CoT质量的外部和内部因素。结果表明外部因素影响最大，且完善提示描述能有效提升代码生成质量，为改进LLM推理与可靠性提供了参考。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在代码生成领域表现优异，尤其是结合了思维链（CoT）提示技术后。然而，LLMs所生成的CoT的质量尚不明确，特别是在其影响代码正确性和可靠性方面。因此，本文旨在探索LLMs生成的CoT质量和可信度，分析其不足之处及改进空间。

Method: 本文通过实证分析，研究了两个广泛使用的代码生成基准上的1023个失败代码样本，探讨影响LLMs生成不理想CoT的外部和内部因素。同时，通过分析210组CoT与代码对，并利用LLMs对不满意的CoT进行细化，评估其对代码生成表现的影响。

Result: 研究发现：1）外部因素（如需求不明确、缺乏上下文）对CoT质量影响最大（53.60%），而内部因素（如模型误解提示）占40.10%；2）即使CoT正确，仍有18.5%的生成代码因指令执行问题出错，反之，有11.9%的正确代码配对了有缺陷的CoT；3）对低质量CoT进行细化能够提升LLMs生成效果，提供更详细描述可以改进输出质量。

Conclusion: 本文揭示了基于CoT的代码生成面临的重要挑战，并指出了提升LLM推理和可靠性的方向，强调需关注输入描述的清晰性与上下文完整性，以及细化提示对提升生成效果的可行性。

Abstract: Large language models (LLMs) have demonstrated impressive performance in code
generation, particularly when augmented with chain-of-thought (CoT) prompting
techniques. They break down requirements into intermediate reasoning steps,
which act as design rationales to guide LLMs in writing code like human
programmers. Thus, the quality of these steps is crucial for ensuring the
correctness and reliability of the generated code. However, little is known
about the quality of CoT generated by LLMs. To what extent can we trust the
thoughts generated by LLMs? How good are they? This paper empirically explores
the external and internal factors of why LLMs generate unsatisfactory CoTs by
analyzing 1,023 failed code samples on two widely used code generation
benchmarks. We also evaluate their impact on code generation performance by
analyzing 210 CoT-code pairs and refining the unsatisfied CoTs by prompting
LLMs. Our study reveals three key findings: (1) External factors (53.60%), such
as unclear requirements and lack of context, mainly affect CoT quality, while
internal factors (40.10%) stem from LLMs' misunderstanding prompts. (2) Even
when CoTs are correct, 18.5% of the generated code contains errors due to
instruction-following issues; conversely, 11.90% of correct code is paired with
flawed CoTs. (3) Refining low-quality CoTs is feasible, i.e., LLMs improve when
given detailed problem descriptions. These findings highlight key challenges in
CoT-based code generation and suggest directions for improving LLM reasoning
and reliability.

</details>


### [12] [Exploring Fairness Interventions in Open Source Projects](https://arxiv.org/abs/2507.07026)
*Sadia Afrin Mim,Fatema Tuz Zohra,Justin Smith,Brittany Johnson*

Main category: cs.SE

TL;DR: 本文梳理了62个开源ML公平性干预工具，结果发现仅有32%近一年仍活跃，半数工具支持偏见检测与缓解，呼吁关注其实用性和持续维护。


<details>
  <summary>Details</summary>
Motivation: 偏见的机器学习模型在刑事司法和健康领域带来了负面影响，虽然已有多种公平性干预方法，但实际应用较少，且开发者对其知之甚少。本文希望梳理已有开源干预工具，分析其使用现状与影响因素，促进公平性工具在实际中的采用。

Method: 系统性地收集并整理了62个开源公平性干预工具，并分析其活跃度、功能和维护状况。深入剖析这些工具的具体特性，探索影响开发者偏好的因素并监测其维护活跃性。

Result: 分析结果显示，32%的干预工具在过去一年仍保持活跃，50%的工具具备偏见检测与缓解双重功能，大多数属于in-processing阶段实现。

Conclusion: 目前虽然存在众多公平性干预工具，但真正得到持续维护和实际应用的工具相对较少，未来有必要加强对高效、易用且持续维护的公平性工具的开发和推广。

Abstract: The deployment of biased machine learning (ML) models has resulted in adverse
effects in crucial sectors such as criminal justice and healthcare. To address
these challenges, a diverse range of machine learning fairness interventions
have been developed, aiming to mitigate bias and promote the creation of more
equitable models. Despite the growing availability of these interventions,
their adoption in real-world applications remains limited, with many
practitioners unaware of their existence. To address this gap, we
systematically identified and compiled a dataset of 62 open source fairness
interventions and identified active ones. We conducted an in-depth analysis of
their specifications and features to uncover considerations that may drive
practitioner preference and to identify the software interventions actively
maintained in the open source ecosystem. Our findings indicate that 32% of
these interventions have been actively maintained within the past year, and 50%
of them offer both bias detection and mitigation capabilities, mostly during
inprocessing.

</details>


### [13] [5C Prompt Contracts: A Minimalist, Creative-Friendly, Token-Efficient Design Framework for Individual and SME LLM Usage](https://arxiv.org/abs/2507.07045)
*Ugur Ari*

Main category: cs.SE

TL;DR: 5C Prompt Contract通过五大核心要素，极大简化了LLM提示设计，降低工程和认知成本，实验显示输入更高效，输出仍具有创造性和一致性，适合个人和中小企业低成本高效使用。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）被越来越多地应用于关键领域，对科学、简明且通用的提示（prompt）设计框架需求迫切。现有许多方法如自定义语言或复杂模板，带来较高的学习与运算成本，限制模型创造性。作者为解决此困境提出新方法。

Method: 提出5C Prompt Contract 框架，将提示设计简化为五个核心要素：Character（角色）、Cause（动因）、Constraint（约束）、Contingency（意外处理）、Calibration（校准），并将回退机制与输出优化整合，提供可靠、可解释且有创造力的交互。通过对不同LLM（如OpenAI、Anthropic等）进行实验评估。

Result: 实验结果表明，5C框架在保持丰富且一致输出的同时，显著提高了输入token的使用效率，适用于多种主流LLM架构，特别有利于AI资源有限的个人与中小企业。

Conclusion: 作者提出的5C Prompt Contract 提示设计框架，能高效、可靠、低门槛地提升LLM交互质量，对想降低工程与认知门槛的用户具实际应用价值。

Abstract: The progression from traditional prompt engineering to a more rigorous
discipline of prompt design marks a pivotal shift in human-LLM interaction. As
Large Language Models (LLMs) become increasingly embedded in mission-critical
applications, there emerges a pressing need for frameworks that are not only
explicit and systematic but also minimal enough to remain practical and broadly
accessible. While many existing approaches address prompt structuring through
elaborate Domain-Specific Languages (DSLs) or multi-layered templates, such
methods can impose significant token and cognitive overhead, potentially
constraining the model's creative capacity. In this context, we propose the 5C
Prompt Contract, a framework that distills prompt design into five intuitive
components: Character, Cause, Constraint, Contingency, and Calibration. This
minimal cognitive schema explicitly integrates fallback and output optimization
directives, fostering reliable, interpretable, and creatively flexible AI
interactions. Experimental results demonstrate that the 5C framework
consistently achieves superior input token efficiency while maintaining rich
and consistent outputs across diverse LLM architectures (OpenAI, Anthropic,
DeepSeek, and Gemini), making it particularly suited for individuals and
Small-to-Medium Enterprises (SMEs) with limited AI engineering resources.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [14] [Towards Solving More Challenging IMO Problems via Decoupled Reasoning and Proving](https://arxiv.org/abs/2507.06804)
*Zhenwen Liang,Linfeng Song,Yang Li,Tao Yang,Feng Zhang,Haitao Mi,Dong Yu*

Main category: cs.LO

TL;DR: 本文提出了一种创新的解耦推理-证明的自动定理证明框架，通过分工协作显著提升了在难题上的解决能力，并为社区开放了高质量数据集。


<details>
  <summary>Details</summary>
Motivation: 目前LLMs在非正式推理表现优秀，但在正式自动定理证明上仍有巨大差距，且现有工作过于依赖浅层策略，缺乏深层推理能力。

Method: 提出将高层推理与低层证明生成解耦的框架，采用分别负责推理和证明的两个子模型：一个Reasoner生成分解子题（lemma），另一个Prover验证子题。

Result: 该方法在一组极具挑战性的“2000年后IMO问题”上首次取得自动证明成功，解决了其中5个问题，并发布全部生成和验证的lemma数据集。

Conclusion: 通过解耦推理与证明流程，模型能展现更强的深度推理能力，为AI解决高级数学难题带来重大进展，对未来自动证明研究具有推动作用。

Abstract: Automated Theorem Proving (ATP) in formal languages is a foundational
challenge for AI. While Large Language Models (LLMs) have driven remarkable
progress, a significant gap remains between their powerful informal reasoning
capabilities and their weak formal proving performance. Recent studies show
that the informal accuracy exceeds 80% while formal success remains below 8% on
benchmarks like PutnamBench. We argue this gap persists because current
state-of-the-art provers, by tightly coupling reasoning and proving, are
trained with paradigms that inadvertently punish deep reasoning in favor of
shallow, tactic-based strategies. To bridge this fundamental gap, we propose a
novel framework that decouples high-level reasoning from low-level proof
generation. Our approach utilizes two distinct, specialized models: a powerful,
general-purpose Reasoner to generate diverse, strategic subgoal lemmas, and an
efficient Prover to rigorously verify them. This modular design liberates the
model's full reasoning potential and bypasses the pitfalls of end-to-end
training. We evaluate our method on a challenging set of post-2000 IMO
problems, a problem set on which no prior open-source prover has reported
success. Our decoupled framework successfully solves 5 of these problems,
demonstrating a significant step towards automated reasoning on exceptionally
difficult mathematical challenges. To foster future research, we release our
full dataset of generated and verified lemmas for a wide range of IMO problems,
available at https://tencent-imo.github.io/ .

</details>


### [15] [Proof-Theoretic Functional Completeness for the Connexive Logic C](https://arxiv.org/abs/2507.06854)
*Sara Ayhan,Hrafn Valtýr Oddsson*

Main category: cs.LO

TL;DR: 本文应用纯证明论方法，结合证明与反证，针对具有强否定和联结性的C逻辑，证明了其连结词的函数完备性。


<details>
  <summary>Details</summary>
Motivation: 要分析和证明不一致逻辑C的连结词是否具有函数完备性，以及如何用证明论手段实现。C的特殊性包括拥有强否定和联结性。

Method: 仅采用纯粹的证明论方法，并引入双边主义（bilateralist）方式来处理证明和反证两方面。此外，针对C具有联结性，采用与传统不同的反证观念。

Result: 通过证明论技术，结合双边处理和联结性推理，成功证明了C逻辑连结词的函数完备性。

Conclusion: 本文证明了非平凡否定不一致逻辑C中连结词的函数完备性。

Abstract: We show the functional completeness for the connectives of the non-trivial
negation inconsistent logic C by using a well-established method implementing
purely proof-theoretic notions only. Firstly, given that C contains a strong
negation, expressing a notion of direct refutation, the proof needs to be
applied in a bilateralist way in that not only higher-order rule schemata for
proofs but also for refutations need to be considered. Secondly, given that C
is a connexive logic we need to take a connexive understanding of inference as
a basis, leading to a different conception of (higher-order) refutation than is
usually employed.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [16] [Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities](https://arxiv.org/abs/2507.06261)
*Gheorghe Comanici,Eric Bieber,Mike Schaekermann,Ice Pasupat,Noveen Sachdeva,Inderjit Dhillon,Marcel Blistein,Ori Ram,Dan Zhang,Evan Rosen,Luke Marris,Sam Petulla,Colin Gaffney,Asaf Aharoni,Nathan Lintz,Tiago Cardal Pais,Henrik Jacobsson,Idan Szpektor,Nan-Jiang Jiang,Krishna Haridasan,Ahmed Omran,Nikunj Saunshi,Dara Bahri,Gaurav Mishra,Eric Chu,Toby Boyd,Brad Hekman,Aaron Parisi,Chaoyi Zhang,Kornraphop Kawintiranon,Tania Bedrax-Weiss,Oliver Wang,Ya Xu,Ollie Purkiss,Uri Mendlovic,Ilaï Deutel,Nam Nguyen,Adam Langley,Flip Korn,Lucia Rossazza,Alexandre Ramé,Sagar Waghmare,Helen Miller,Vaishakh Keshava,Ying Jian,Xiaofan Zhang,Raluca Ada Popa,Kedar Dhamdhere,Blaž Bratanič,Kyuyeun Kim,Terry Koo,Ferran Alet,Yi-ting Chen,Arsha Nagrani,Hannah Muckenhirn,Zhiyuan Zhang,Corbin Quick,Filip Pavetić,Duc Dung Nguyen,Joao Carreira,Michael Elabd,Haroon Qureshi,Fabian Mentzer,Yao-Yuan Yang,Danielle Eisenbud,Anmol Gulati,Ellie Talius,Eric Ni,Sahra Ghalebikesabi,Edouard Yvinec,Alaa Saade,Thatcher Ulrich,Lorenzo Blanco,Dan A. Calian,Muhuan Huang,Aäron van den Oord,Naman Goyal,Terry Chen,Praynaa Rawlani,Christian Schallhart,Swachhand Lokhande,Xianghong Luo,Jyn Shan,Ceslee Montgomery,Victoria Krakovna,Federico Piccinini,Omer Barak,Jingyu Cui,Yiling Jia,Mikhail Dektiarev,Alexey Kolganov,Shiyu Huang,Zhe Chen,Xingyu Wang,Jessica Austin,Peter de Boursac,Evgeny Sluzhaev,Frank Ding,Huijian Li,Surya Bhupatiraju,Mohit Agarwal,Sławek Kwasiborski,Paramjit Sandhu,Patrick Siegler,Ahmet Iscen,Eyal Ben-David,Shiraz Butt,Miltos Allamanis,Seth Benjamin,Robert Busa-Fekete,Felix Hernandez-Campos,Sasha Goldshtein,Matt Dibb,Weiyang Zhang,Annie Marsden,Carey Radebaugh,Stephen Roller,Abhishek Nayyar,Jacob Austin,Tayfun Terzi,Bhargav Kanagal Shamanna,Pete Shaw,Aayush Singh,Florian Luisier,Artur Mendonça,Vaibhav Aggarwal,Larisa Markeeva,Claudio Fantacci,Sergey Brin,HyunJeong Choe,Guanyu Wang,Hartwig Adam,Avigail Dabush,Tatsuya Kiyono,Eyal Marcus,Jeremy Cole,Theophane Weber,Hongrae Lee,Ronny Huang,Alex Muzio,Leandro Kieliger,Maigo Le,Courtney Biles,Long Le,Archit Sharma,Chengrun Yang,Avery Lamp,Dave Dopson,Nate Hurley,Katrina,Xu,Zhihao Shan,Shuang Song,Jiewen Tan,Alexandre Senges,George Zhang,Chong You,Yennie Jun,David Raposo,Susanna Ricco,Xuan Yang,Weijie Chen,Prakhar Gupta,Arthur Szlam,Kevin Villela,Chun-Sung Ferng,Daniel Kasenberg,Chen Liang,Rui Zhu,Arunachalam Narayanaswamy,Florence Perot,Paul Pucciarelli,Anna Shekhawat,Alexey Stern,Rishikesh Ingale,Stefani Karp,Sanaz Bahargam,Adrian Goedeckemeyer,Jie Han,Sicheng Li,Andrea Tacchetti,Dian Yu,Abhishek Chakladar,Zhiying Zhang,Mona El Mahdy,Xu Gao,Dale Johnson,Samrat Phatale,AJ Piergiovanni,Hyeontaek Lim,Clement Farabet,Carl Lebsack,Theo Guidroz,John Blitzer,Nico Duduta,David Madras,Steve Li,Daniel von Dincklage,Xin Li,Mahdis Mahdieh,George Tucker,Ganesh Jawahar,Owen Xiao,Danny Tarlow,Robert Geirhos,Noam Velan,Daniel Vlasic,Kalesha Bullard,SK Park,Nishesh Gupta,Kellie Webster,Ayal Hitron,Jieming Mao,Julian Eisenschlos,Laurel Prince,Nina D'Souza,Kelvin Zheng,Sara Nasso,Gabriela Botea,Carl Doersch,Caglar Unlu,Chris Alberti,Alexey Svyatkovskiy,Ankita Goel,Krzysztof Choromanski,Pan-Pan Jiang,Richard Nguyen,Four Flynn,Daria Ćurko,Peter Chen,Nicholas Roth,Kieran Milan,Caleb Habtegebriel,Shashi Narayan,Michael Moffitt,Jake Marcus,Thomas Anthony,Brendan McMahan,Gowoon Cheon,Ruibo Liu,Megan Barnes,Lukasz Lew,Rebeca Santamaria-Fernandez,Mayank Upadhyay,Arjun Akula,Arnar Mar Hrafnkelsson,Alvaro Caceres,Andrew Bunner,Michal Sokolik,Subha Puttagunta,Lawrence Moore,Berivan Isik,Weilun Chen,Jay Hartford,Lawrence Chan,Pradeep Shenoy,Dan Holtmann-Rice,Jane Park,Fabio Viola,Alex Salcianu,Sujeevan Rajayogam,Ian Stewart-Binks,Zelin Wu,Richard Everett,Xi Xiong,Pierre-Antoine Manzagol,Gary Leung,Carl Saroufim,Bo Pang,Dawid Wegner,George Papamakarios,Jennimaria Palomaki,Helena Pankov,Guangda Lai,Guilherme Tubone,Shubin Zhao,Theofilos Strinopoulos,Seth Neel,Mingqiu Wang,Joe Kelley,Li Li,Pingmei Xu,Anitha Vijayakumar,Andrea D'olimpio,Omer Levy,Massimo Nicosia,Grigory Rozhdestvenskiy,Ni Lao,Sirui Xie,Yash Katariya,Jon Simon,Sanjiv Kumar,Florian Hartmann,Michael Kilgore,Jinhyuk Lee,Aroma Mahendru,Roman Ring,Tom Hennigan,Fiona Lang,Colin Cherry,David Steiner,Dawsen Hwang,Ray Smith,Pidong Wang,Jeremy Chen,Ming-Hsuan Yang,Sam Kwei,Philippe Schlattner,Donnie Kim,Ganesh Poomal Girirajan,Nikola Momchev,Ayushi Agarwal,Xingyi Zhou,Ilkin Safarli,Zachary Garrett,AJ Pierigiovanni,Sarthak Jauhari,Alif Raditya Rochman,Shikhar Vashishth,Quan Yuan,Christof Angermueller,Jon Blanton,Xinying Song,Nitesh Bharadwaj Gundavarapu,Thi Avrahami,Maxine Deines,Subhrajit Roy,Manish Gupta,Christopher Semturs,Shobha Vasudevan,Aditya Srikanth Veerubhotla,Shriya Sharma,Josh Jacob,Zhen Yang,Andreas Terzis,Dan Karliner,Auriel Wright,Tania Rojas-Esponda,Ashley Brown,Abhijit Guha Roy,Pawan Dogra,Andrei Kapishnikov,Peter Young,Wendy Kan,Vinodh Kumar Rajendran,Maria Ivanova,Salil Deshmukh,Chia-Hua Ho,Mike Kwong,Stav Ginzburg,Annie Louis,KP Sawhney,Slav Petrov,Jing Xie,Yunfei Bai,Georgi Stoyanov,Alex Fabrikant,Rajesh Jayaram,Yuqi Li,Joe Heyward,Justin Gilmer,Yaqing Wang,Radu Soricut,Luyang Liu,Qingnan Duan,Jamie Hayes,Maura O'Brien,Gaurav Singh Tomar,Sivan Eiger,Bahar Fatemi,Jeffrey Hui,Catarina Barros,Adaeze Chukwuka,Alena Butryna,Saksham Thakur,Austin Huang,Zhufeng Pan,Haotian Tang,Serkan Cabi,Tulsee Doshi,Michiel Bakker,Sumit Bagri,Ruy Ley-Wild,Adam Lelkes,Jennie Lees,Patrick Kane,David Greene,Shimu Wu,Jörg Bornschein,Gabriela Surita,Sarah Hodkinson,Fangtao Li,Chris Hidey,Sébastien Pereira,Sean Ammirati,Phillip Lippe,Adam Kraft,Pu Han,Sebastian Gerlach,Zifeng Wang,Liviu Panait,Feng Han,Brian Farris,Yingying Bi,Hannah DeBalsi,Miaosen Wang,Gladys Tyen,James Cohan,Susan Zhang,Jarred Barber,Da-Woon Chung,Jaeyoun Kim,Markus Kunesch,Steven Pecht,Nami Akazawa,Abe Friesen,James Lyon,Ali Eslami,Junru Wu,Jie Tan,Yue Song,Ravi Kumar,Chris Welty,Ilia Akolzin,Gena Gibson,Sean Augenstein,Arjun Pillai,Nancy Yuen,Du Phan,Xin Wang,Iain Barr,Heiga Zen,Nan Hua,Casper Liu,Jilei,Wang,Tanuj Bhatia,Hao Xu,Oded Elyada,Pushmeet Kohli,Mirek Olšák,Ke Chen,Azalia Mirhoseini,Noam Shazeer,Shoshana Jakobovits,Maggie Tran,Nolan Ramsden,Tarun Bharti,Fred Alcober,Yunjie Li,Shilpa Shetty,Jing Chen,Dmitry Kalashnikov,Megha Nawhal,Sercan Arik,Hanwen Chen,Michiel Blokzijl,Shubham Gupta,James Rubin,Rigel Swavely,Sophie Bridgers,Ian Gemp,Chen Su,Arun Suggala,Juliette Pluto,Mary Cassin,Alain Vaucher,Kaiyang Ji,Jiahao Cai,Andrew Audibert,Animesh Sinha,David Tian,Efrat Farkash,Amy Hua,Jilin Chen,Duc-Hieu Tran,Edward Loper,Nicole Brichtova,Lara McConnaughey,Ballie Sandhu,Robert Leland,Doug DeCarlo,Andrew Over,James Huang,Xing Wu,Connie Fan,Eric Li,Yun Lei,Deepak Sharma,Cosmin Paduraru,Luo Yu,Matko Bošnjak,Phuong Dao,Min Choi,Sneha Kudugunta,Jakub Adamek,Carlos Guía,Ali Khodaei,Jie Feng,Wenjun Zeng,David Welling,Sandeep Tata,Christina Butterfield,Andrey Vlasov,Seliem El-Sayed,Swaroop Mishra,Tara Sainath,Shentao Yang,RJ Skerry-Ryan,Jeremy Shar,Robert Berry,Arunkumar Rajendran,Arun Kandoor,Andrea Burns,Deepali Jain,Tom Stone,Wonpyo Park,Shibo Wang,Albin Cassirer,Guohui Wang,Hayato Kobayashi,Sergey Rogulenko,Vineetha Govindaraj,Mikołaj Rybiński,Nadav Olmert,Colin Evans,Po-Sen Huang,Kelvin Xu,Premal Shah,Terry Thurk,Caitlin Sikora,Mu Cai,Jin Xie,Elahe Dabir,Saloni Shah,Norbert Kalb,Carrie Zhang,Shruthi Prabhakara,Amit Sabne,Artiom Myaskovsky,Vikas Raunak,Blanca Huergo,Behnam Neyshabur,Jon Clark,Ye Zhang,Shankar Krishnan,Eden Cohen,Dinesh Tewari,James Lottes,Yumeya Yamamori,Hui,Li,Mohamed Elhawaty,Ada Maksutaj Oflazer,Adrià Recasens,Sheryl Luo,Duy Nguyen,Taylor Bos,Kalyan Andra,Ana Salazar,Ed Chi,Jeongwoo Ko,Matt Ginsberg,Anders Andreassen,Anian Ruoss,Todor Davchev,Elnaz Davoodi,Chenxi Liu,Min Kim,Santiago Ontanon,Chi Ming To,Dawei Jia,Rosemary Ke,Jing Wang,Anna Korsun,Moran Ambar,Ilya Kornakov,Irene Giannoumis,Toni Creswell,Denny Zhou,Yi Su,Ishaan Watts,Aleksandr Zaks,Evgenii Eltyshev,Ziqiang Feng,Sidharth Mudgal,Alex Kaskasoli,Juliette Love,Kingshuk Dasgupta,Sam Shleifer,Richard Green,Sungyong Seo,Chansoo Lee,Dale Webster,Prakash Shroff,Ganna Raboshchuk,Isabel Leal,James Manyika,Sofia Erell,Daniel Murphy,Zhisheng Xiao,Anton Bulyenov,Julian Walker,Mark Collier,Matej Kastelic,Nelson George,Sushant Prakash,Sailesh Sidhwani,Alexey Frolov,Steven Hansen,Petko Georgiev,Tiberiu Sosea,Chris Apps,Aishwarya Kamath,David Reid,Emma Cooney,Charlotte Magister,Oriana Riva,Alec Go,Pu-Chin Chen,Sebastian Krause,Nir Levine,Marco Fornoni,Ilya Figotin,Nick Roy,Parsa Mahmoudieh,Vladimir Magay,Mukundan Madhavan,Jin Miao,Jianmo Ni,Yasuhisa Fujii,Ian Chou,George Scrivener,Zak Tsai,Siobhan Mcloughlin,Jeremy Selier,Sandra Lefdal,Jeffrey Zhao,Abhijit Karmarkar,Kushal Chauhan,Shivanker Goel,Zhaoyi Zhang,Vihan Jain,Parisa Haghani,Mostafa Dehghani,Jacob Scott,Erin Farnese,Anastasija Ilić,Steven Baker,Julia Pawar,Li Zhong,Josh Camp,Yoel Zeldes,Shravya Shetty,Anand Iyer,Vít Listík,Jiaxian Guo,Luming Tang,Mark Geller,Simon Bucher,Yifan Ding,Hongzhi Shi,Carrie Muir,Dominik Grewe,Ramy Eskander,Octavio Ponce,Boqing Gong,Derek Gasaway,Samira Khan,Umang Gupta,Angelos Filos,Weicheng Kuo,Klemen Kloboves,Jennifer Beattie,Christian Wright,Leon Li,Alicia Jin,Sandeep Mariserla,Miteyan Patel,Jens Heitkaemper,Dilip Krishnan,Vivek Sharma,David Bieber,Christian Frank,John Lambert,Paul Caron,Martin Polacek,Mai Giménez,Himadri Choudhury,Xing Yu,Sasan Tavakkol,Arun Ahuja,Franz Och,Rodolphe Jenatton,Wojtek Skut,Bryan Richter,David Gaddy,Andy Ly,Misha Bilenko,Megh Umekar,Ethan Liang,Martin Sevenich,Mandar Joshi,Hassan Mansoor,Rebecca Lin,Sumit Sanghai,Abhimanyu Singh,Xiaowei Li,Sudheendra Vijayanarasimhan,Zaheer Abbas,Yonatan Bitton,Hansa Srinivasan,Manish Reddy Vuyyuru,Alexander Frömmgen,Yanhua Sun,Ralph Leith,Alfonso Castaño,DJ Strouse,Le Yan,Austin Kyker,Satish Kambala,Mary Jasarevic,Thibault Sellam,Chao Jia,Alexander Pritzel,Raghavender R,Huizhong Chen,Natalie Clay,Sudeep Gandhe,Sean Kirmani,Sayna Ebrahimi,Hannah Kirkwood,Jonathan Mallinson,Chao Wang,Adnan Ozturel,Kuo Lin,Shyam Upadhyay,Vincent Cohen-Addad,Sean Purser-haskell,Yichong Xu,Ebrahim Songhori,Babi Seal,Alberto Magni,Almog Gueta,Tingting Zou,Guru Guruganesh,Thais Kagohara,Hung Nguyen,Khalid Salama,Alejandro Cruzado Ruiz,Justin Frye,Zhenkai Zhu,Matthias Lochbrunner,Simon Osindero,Wentao Yuan,Lisa Lee,Aman Prasad,Lam Nguyen Thiet,Daniele Calandriello,Victor Stone,Qixuan Feng,Han Ke,Maria Voitovich,Geta Sampemane,Lewis Chiang,Ling Wu,Alexander Bykovsky,Matt Young,Luke Vilnis,Ishita Dasgupta,Aditya Chawla,Qin Cao,Bowen Liang,Daniel Toyama,Szabolcs Payrits,Anca Stefanoiu,Dimitrios Vytiniotis,Ankesh Anand,Tianxiao Shen,Blagoj Mitrevski,Michael Tschannen,Sreenivas Gollapudi,Aishwarya P S,José Leal,Zhe Shen,Han Fu,Wei Wang,Arvind Kannan,Doron Kukliansky,Sergey Yaroshenko,Svetlana Grant,Umesh Telang,David Wood,Alexandra Chronopoulou,Alexandru Ţifrea,Tao Zhou,Tony,Nguy\~ên,Muge Ersoy,Anima Singh,Meiyan Xie,Emanuel Taropa,Woohyun Han,Eirikur Agustsson,Andrei Sozanschi,Hui Peng,Alex Chen,Yoel Drori,Efren Robles,Yang Gao,Xerxes Dotiwalla,Ying Chen,Anudhyan Boral,Alexei Bendebury,John Nham,Chris Tar,Luis Castro,Jiepu Jiang,Canoee Liu,Felix Halim,Jinoo Baek,Andy Wan,Jeremiah Liu,Yuan Cao,Shengyang Dai,Trilok Acharya,Ruoxi Sun,Fuzhao Xue,Saket Joshi,Morgane Lustman,Yongqin Xian,Rishabh Joshi,Deep Karkhanis,Nora Kassner,Jamie Hall,Xiangzhuo Ding,Gan Song,Gang Li,Chen Zhu,Yana Kulizhskaya,Bin Ni,Alexey Vlaskin,Solomon Demmessie,Lucio Dery,Salah Zaiem,Yanping Huang,Cindy Fan,Felix Gimeno,Ananth Balashankar,Koji Kojima,Hagai Taitelbaum,Maya Meng,Dero Gharibian,Sahil Singla,Wei Chen,Ambrose Slone,Guanjie Chen,Sujee Rajayogam,Max Schumacher,Suyog Kotecha,Rory Blevins,Qifei Wang,Mor Hazan Taege,Alex Morris,Xin Liu,Fayaz Jamil,Richard Zhang,Pratik Joshi,Ben Ingram,Tyler Liechty,Ahmed Eleryan,Scott Baird,Alex Grills,Gagan Bansal,Shan Han,Kiran Yalasangi,Shawn Xu,Majd Al Merey,Isabel Gao,Felix Weissenberger,Igor Karpov,Robert Riachi,Ankit Anand,Gautam Prasad,Kay Lamerigts,Reid Hayes,Jamie Rogers,Mandy Guo,Ashish Shenoy,Qiong,Hu,Kyle He,Yuchen Liu,Polina Zablotskaia,Sagar Gubbi,Yifan Chang,Jay Pavagadhi,Kristian Kjems,Archita Vadali,Diego Machado,Yeqing Li,Renshen Wang,Dipankar Ghosh,Aahil Mehta,Dana Alon,George Polovets,Alessio Tonioni,Nate Kushman,Joel D'sa,Lin Zhuo,Allen Wu,Rohin Shah,John Youssef,Jiayu Ye,Justin Snyder,Karel Lenc,Senaka Buthpitiya,Matthew Tung,Jichuan Chang,Tao Chen,David Saxton,Jenny Lee,Lydia Lihui Zhang,James Qin,Prabakar Radhakrishnan,Maxwell Chen,Piotr Ambroszczyk,Metin Toksoz-Exley,Yan Zhong,Nitzan Katz,Brendan O'Donoghue,Tamara von Glehn,Adi Gerzi Rosenthal,Aga Świetlik,Xiaokai Zhao,Nick Fernando,Jinliang Wei,Jieru Mei,Sergei Vassilvitskii,Diego Cedillo,Pranjal Awasthi,Hui Zheng,Koray Kavukcuoglu,Itay Laish,Joseph Pagadora,Marc Brockschmidt,Christopher A. Choquette-Choo,Arunkumar Byravan,Yifeng Lu,Xu Chen,Mia Chen,Kenton Lee,Rama Pasumarthi,Sijal Bhatnagar,Aditya Shah,Qiyin Wu,Zhuoyuan Chen,Zack Nado,Bartek Perz,Zixuan Jiang,David Kao,Ganesh Mallya,Nino Vieillard,Lantao Mei,Sertan Girgin,Mandy Jordan,Yeongil Ko,Alekh Agarwal,Yaxin Liu,Yasemin Altun,Raoul de Liedekerke,Anastasios Kementsietsidis,Daiyi Peng,Dangyi Liu,Utku Evci,Peter Humphreys,Austin Tarango,Xiang Deng,Yoad Lewenberg,Kevin Aydin,Chengda Wu,Bhavishya Mittal,Tsendsuren Munkhdalai,Kleopatra Chatziprimou,Rodrigo Benenson,Uri First,Xiao Ma,Jinning Li,Armand Joulin,Hamish Tomlinson,Tingnan Zhang,Milad Nasr,Zhi Hong,Michaël Sander,Lisa Anne Hendricks,Anuj Sharma,Andrew Bolt,Eszter Vértes,Jiri Simsa,Tomer Levinboim,Olcan Sercinoglu,Divyansh Shukla,Austin Wu,Craig Swanson,Danny Vainstein,Fan Bu,Bo Wang,Ryan Julian,Charles Yoon,Sergei Lebedev,Antonious Girgis,Bernd Bandemer,David Du,Todd Wang,Xi Chen,Ying Xiao,Peggy Lu,Natalie Ha,Vlad Ionescu,Simon Rowe,Josip Matak,Federico Lebron,Andreas Steiner,Lalit Jain,Manaal Faruqui,Nicolas Lacasse,Georgie Evans,Neesha Subramaniam,Dean Reich,Giulia Vezzani,Aditya Pandey,Joe Stanton,Tianhao Zhou,Liam McCafferty,Henry Griffiths,Verena Rieser,Soheil Hassas Yeganeh,Eleftheria Briakou,Lu Huang,Zichuan Wei,Liangchen Luo,Erik Jue,Gabby Wang,Victor Cotruta,Myriam Khan,Jongbin Park,Qiuchen Guo,Peiran Li,Rong Rong,Diego Antognini,Anastasia Petrushkina,Chetan Tekur,Eli Collins,Parul Bhatia,Chester Kwak,Wenhu Chen,Arvind Neelakantan,Immanuel Odisho,Sheng Peng,Vincent Nallatamby,Vaibhav Tulsyan,Fabian Pedregosa,Peng Xu,Raymond Lin,Yulong Wang,Emma Wang,Sholto Douglas,Reut Tsarfaty,Elena Gribovskaya,Renga Aravamudhan,Manu Agarwal,Mara Finkelstein,Qiao Zhang,Elizabeth Cole,Phil Crone,Sarmishta Velury,Anil Das,Chris Sauer,Luyao Xu,Danfeng Qin,Chenjie Gu,Dror Marcus,CJ Zheng,Wouter Van Gansbeke,Sobhan Miryoosefi,Haitian Sun,YaGuang Li,Charlie Chen,Jae Yoo,Pavel Dubov,Alex Tomala,Adams Yu,Paweł Wesołowski,Alok Gunjan,Eddie Cao,Jiaming Luo,Nikhil Sethi,Arkadiusz Socala,Laura Graesser,Tomas Kocisky,Arturo BC,Minmin Chen,Edward Lee,Sophie Wang,Weize Kong,Qiantong Xu,Nilesh Tripuraneni,Yiming Li,Xinxin Yu,Allen Porter,Paul Voigtlaender,Biao Zhang,Arpi Vezer,Sarah York,Qing Wei,Geoffrey Cideron,Mark Kurzeja,Seungyeon Kim,Benny Li,Angéline Pouget,Hyo Lee,Kaspar Daugaard,Yang Li,Dave Uthus,Aditya Siddhant,Paul Cavallaro,Sriram Ganapathy,Maulik Shah,Rolf Jagerman,Jeff Stanway,Piermaria Mendolicchio,Li Xiao,Kayi Lee,Tara Thompson,Shubham Milind Phal,Jason Chase,Sun Jae Lee,Adrian N Reyes,Disha Shrivastava,Zhen Qin,Roykrong Sukkerd,Seth Odoom,Lior Madmoni,John Aslanides,Jonathan Herzig,Elena Pochernina,Sheng Zhang,Parker Barnes,Daisuke Ikeda,Qiujia Li,Shuo-yiin Chang,Shakir Mohamed,Jim Sproch,Richard Powell,Bidisha Samanta,Domagoj Ćevid,Anton Kovsharov,Shrestha Basu Mallick,Srinivas Tadepalli,Anne Zheng,Kareem Ayoub,Andreas Noever,Christian Reisswig,Zhuo Xu,Junhyuk Oh,Martin Matysiak,Tim Blyth,Shereen Ashraf,Julien Amelot,Boone Severson,Michele Bevilacqua,Motoki Sano,Ethan Dyer,Ofir Roval,Anu Sinha,Yin Zhong,Sagi Perel,Tea Sabolić,Johannes Mauerer,Willi Gierke,Mauro Verzetti,Rodrigo Cabrera,Alvin Abdagic,Steven Hemingray,Austin Stone,Jong Lee,Farooq Ahmad,Karthik Raman,Lior Shani,Jonathan Lai,Orhan Firat,Nathan Waters,Eric Ge,Mo Shomrat,Himanshu Gupta,Rajeev Aggarwal,Tom Hudson,Bill Jia,Simon Baumgartner,Palak Jain,Joe Kovac,Junehyuk Jung,Ante Žužul,Will Truong,Morteza Zadimoghaddam,Songyou Peng,Marco Liang,Rachel Sterneck,Balaji Lakshminarayanan,Machel Reid,Oliver Woodman,Tong Zhou,Jianling Wang,Vincent Coriou,Arjun Narayanan,Jay Hoover,Yenai Ma,Apoorv Jindal,Clayton Sanford,Doug Reid,Swaroop Ramaswamy,Alex Kurakin,Roland Zimmermann,Yana Lunts,Dragos Dena,Zalán Borsos,Vered Cohen,Shujian Zhang,Will Grathwohl,Robert Dadashi,Morgan Redshaw,Joshua Kessinger,Julian Odell,Silvano Bonacina,Zihang Dai,Grace Chen,Ayush Dubey,Pablo Sprechmann,Mantas Pajarskas,Wenxuan Zhou,Niharika Ahuja,Tara Thomas,Martin Nikoltchev,Matija Kecman,Bharath Mankalale,Andrey Ryabtsev,Jennifer She,Christian Walder,Jiaming Shen,Lu Li,Carolina Parada,Sheena Panthaplackel,Okwan Kwon,Matt Lawlor,Utsav Prabhu,Yannick Schroecker,Marc'aurelio Ranzato,Pete Blois,Iurii Kemaev,Ting Yu,Dmitry,Lepikhin,Hao Xiong,Sahand Sharifzadeh,Oleaser Johnson,Jeremiah Willcock,Rui Yao,Greg Farquhar,Sujoy Basu,Hidetoshi Shimokawa,Nina Anderson,Haiguang Li,Khiem Pham,Yizhong Liang,Sebastian Borgeaud,Alexandre Moufarek,Hideto Kazawa,Blair Kutzman,Marcin Sieniek,Sara Smoot,Ruth Wang,Natalie Axelsson,Nova Fallen,Prasha Sundaram,Yuexiang Zhai,Varun Godbole,Petros Maniatis,Alek Wang,Ilia Shumailov,Santhosh Thangaraj,Remi Crocker,Nikita Gupta,Gang Wu,Phil Chen,Gellért Weisz,Celine Smith,Mojtaba Seyedhosseini,Boya Fang,Xiyang Luo,Roey Yogev,Zeynep Cankara,Andrew Hard,Helen Ran,Rahul Sukthankar,George Necula,Gaël Liu,Honglong Cai,Praseem Banzal,Daniel Keysers,Sanjay Ghemawat,Connie Tao,Emma Dunleavy,Aditi Chaudhary,Wei Li,Maciej Mikuła,Chen-Yu Lee,Tiziana Refice,Krishna Somandepalli,Alexandre Fréchette,Dan Bahir,John Karro,Keith Rush,Sarah Perrin,Bill Rosgen,Xiaomeng Yang,Clara Huiyi Hu,Mahmoud Alnahlawi,Justin Mao-Jones,Roopal Garg,Hoang Nguyen,Bat-Orgil Batsaikhan,Iñaki Iturrate,Anselm Levskaya,Avi Singh,Ashyana Kachra,Tony Lu,Denis Petek,Zheng Xu,Mark Graham,Lukas Zilka,Yael Karov,Marija Kostelac,Fangyu Liu,Yaohui Guo,Weiyue Wang,Bernd Bohnet,Emily Pitler,Tony Bruguier,Keisuke Kinoshita,Chrysovalantis Anastasiou,Nilpa Jha,Ting Liu,Jerome Connor,Phil Wallis,Philip Pham,Eric Bailey,Shixin Li,Heng-Tze Cheng,Sally Ma,Haiqiong Li,Akanksha Maurya,Kate Olszewska,Manfred Warmuth,Christy Koh,Dominik Paulus,Siddhartha Reddy Jonnalagadda,Enrique Piqueras,Ali Elqursh,Geoff Brown,Hadar Shemtov,Loren Maggiore,Fei Xia,Ryan Foley,Beka Westberg,George van den Driessche,Livio Baldini Soares,Arjun Kar,Michael Quinn,Siqi Zuo,Jialin Wu,Kyle Kastner,Anna Bortsova,Aijun Bai,Ales Mikhalap,Luowei Zhou,Jennifer Brennan,Vinay Ramasesh,Honglei Zhuang,John Maggs,Johan Schalkwyk,Yuntao Xu,Hui Huang,Andrew Howard,Sasha Brown,Linting Xue,Gloria Shen,Brian Albert,Neha Jha,Daniel Zheng,Varvara Krayvanova,Spurthi Amba Hombaiah,Olivier Lacombe,Gautam Vasudevan,Dan Graur,Tian Xie,Meet Gandhi,Bangju Wang,Dustin Zelle,Harman Singh,Dahun Kim,Sébastien Cevey,Victor Ungureanu,Natasha Noy,Fei Liu,Annie Xie,Fangxiaoyu Feng,Katerina Tsihlas,Daniel Formoso,Neera Vats,Quentin Wellens,Yinan Wang,Niket Kumar Bhumihar,Samrat Ghosh,Matt Hoffman,Tom Lieber,Oran Lang,Kush Bhatia,Tom Paine,Aroonalok Pyne,Ronny Votel,Madeleine Clare Elish,Benoit Schillings,Alex Panagopoulos,Haichuan Yang,Adam Raveret,Zohar Yahav,Shuang Liu,Warren Chen,Dalia El Badawy,Nishant Agrawal,Mohammed Badawi,Mahdi Mirzazadeh,Carla Bromberg,Fan Ye,Chang Liu,Tatiana Sholokhova,George-Cristian Muraru,Gargi Balasubramaniam,Jonathan Malmaud,Alen Carin,Danilo Martins,Irina Jurenka,Pankil Botadra,Dave Lacey,Richa Singh,Mariano Schain,Dan Zheng,Isabelle Guyon,Victor Lavrenko,Seungji Lee,Xiang Zhou,Demis Hassabis,Jeshwanth Challagundla,Derek Cheng,Nikhil Mehta,Matthew Mauger,Michela Paganini,Pushkar Mishra,Kate Lee,Zhang Li,Lexi Baugher,Ondrej Skopek,Max Chang,Amir Zait,Gaurav Menghani,Lizzetth Bellot,Guangxing Han,Jean-Michel Sarr,Sharat Chikkerur,Himanshu Sahni,Rohan Anil,Arun Narayanan,Chandu Thekkath,Daniele Pighin,Hana Strejček,Marko Velic,Fred Bertsch,Manuel Tragut,Keran Rong,Alicia Parrish,Kai Bailey,Jiho Park,Isabela Albuquerque,Abhishek Bapna,Rajesh Venkataraman,Alec Kosik,Johannes Griesser,Zhiwei Deng,Alek Andreev,Qingyun Dou,Kevin Hui,Fanny Wei,Xiaobin Yu,Lei Shu,Avia Aharon,David Barker,Badih Ghazi,Sebastian Flennerhag,Chris Breaux,Yuchuan Liu,Matthew Bilotti,Josh Woodward,Uri Alon,Stephanie Winkler,Tzu-Kuo Huang,Kostas Andriopoulos,João Gabriel Oliveira,Penporn Koanantakool,Berkin Akin,Michael Wunder,Cicero Nogueira dos Santos,Mohammad Hossein Bateni,Lin Yang,Dan Horgan,Beer Changpinyo,Keyvan Amiri,Min Ma,Dayeong Lee,Lihao Liang,Anirudh Baddepudi,Tejasi Latkar,Raia Hadsell,Jun Xu,Hairong Mu,Michael Han,Aedan Pope,Snchit Grover,Frank Kim,Ankit Bhagatwala,Guan Sun,Yamini Bansal,Amir Globerson,Alireza Nazari,Samira Daruki,Hagen Soltau,Jane Labanowski,Laurent El Shafey,Matt Harvey,Yanif Ahmad,Elan Rosenfeld,William Kong,Etienne Pot,Yi-Xuan Tan,Aurora Wei,Victoria Langston,Marcel Prasetya,Petar Veličković,Richard Killam,Robin Strudel,Darren Ni,Zhenhai Zhu,Aaron Archer,Kavya Kopparapu,Lynn Nguyen,Emilio Parisotto,Hussain Masoom,Sravanti Addepalli,Jordan Grimstad,Hexiang Hu,Joss Moore,Avinatan Hassidim,Le Hou,Mukund Raghavachari,Jared Lichtarge,Adam R. Brown,Hilal Dib,Natalia Ponomareva,Justin Fu,Yujing Zhang,Altaf Rahman,Joana Iljazi,Edouard Leurent,Gabriel Dulac-Arnold,Cosmo Du,Chulayuth Asawaroengchai,Larry Jin,Ela Gruzewska,Ziwei Ji,Benigno Uria,Daniel De Freitas,Paul Barham,Lauren Beltrone,Víctor Campos,Jun Yan,Neel Kovelamudi,Arthur Nguyen,Elinor Davies,Zhichun Wu,Zoltan Egyed,Kristina Toutanova,Nithya Attaluri,Hongliang Fei,Peter Stys,Siddhartha Brahma,Martin Izzard,Siva Velusamy,Scott Lundberg,Vincent Zhuang,Kevin Sequeira,Adam Santoro,Ehsan Amid,Ophir Aharoni,Shuai Ye,Mukund Sundararajan,Lijun Yu,Yu-Cheng Ling,Stephen Spencer,Hugo Song,Josip Djolonga,Christo Kirov,Sonal Gupta,Alessandro Bissacco,Clemens Meyer,Mukul Bhutani,Andrew Dai,Weiyi Wang,Siqi Liu,Ashwin Sreevatsa,Qijun Tan,Maria Wang,Lucy Kim,Yicheng Wang,Alex Irpan,Yang Xiao,Stanislav Fort,Yifan He,Alex Gurney,Bryan Gale,Yue Ma,Monica Roy,Viorica Patraucean,Taylan Bilal,Golnaz Ghiasi,Anahita Hosseini,Melvin Johnson,Zhuowan Li,Yi Tay,Benjamin Beyret,Katie Millican,Josef Broder,Mayank Lunayach,Danny Swisher,Eugen Vušak,David Parkinson,MH Tessler,Adi Mayrav Gilady,Richard Song,Allan Dafoe,Yves Raimond,Masa Yamaguchi,Itay Karo,Elizabeth Nielsen,Kevin Kilgour,Mike Dusenberry,Rajiv Mathews,Jiho Choi,Siyuan Qiao,Harsh Mehta,Sahitya Potluri,Chris Knutsen,Jialu Liu,Tat Tan,Kuntal Sengupta,Keerthana Gopalakrishnan,Abodunrinwa Toki,Mencher Chiang,Mike Burrows,Grace Vesom,Zafarali Ahmed,Ilia Labzovsky,Siddharth Vashishtha,Preeti Singh,Ankur Sharma,Ada Ma,Jinyu Xie,Pranav Talluri,Hannah Forbes-Pollard,Aarush Selvan,Joel Wee,Loic Matthey,Tom Funkhouser,Parthasarathy Gopavarapu,Lev Proleev,Cheng Li,Matt Thomas,Kashyap Kolipaka,Zhipeng Jia,Ashwin Kakarla,Srinivas Sunkara,Joan Puigcerver,Suraj Satishkumar Sheth,Emily Graves,Chen Wang,Sadh MNM Khan,Kai Kang,Shyamal Buch,Fred Zhang,Omkar Savant,David Soergel,Kevin Lee,Linda Friso,Xuanyi Dong,Rahul Arya,Shreyas Chandrakaladharan,Connor Schenck,Greg Billock,Tejas Iyer,Anton Bakalov,Leslie Baker,Alex Ruiz,Angad Chandorkar,Trieu Trinh,Matt Miecnikowski,Yanqi Zhou,Yangsibo Huang,Jiazhong Nie,Ali Shah,Ashish Thapliyal,Sam Haves,Lun Wang,Uri Shaham,Patrick Morris-Suzuki,Soroush Radpour,Leonard Berrada,Thomas Strohmann,Chaochao Yan,Jingwei Shen,Sonam Goenka,Tris Warkentin,Petar Dević,Dan Belov,Albert Webson,Madhavi Yenugula,Puranjay Datta,Jerry Chang,Nimesh Ghelani,Aviral Kumar,Vincent Perot,Jessica Lo,Yang Song,Herman Schmit,Jianmin Chen,Vasilisa Bashlovkina,Xiaoyue Pan,Diana Mincu,Paul Roit,Isabel Edkins,Andy Davis,Yujia Li,Ben Horn,Xinjian Li,Pradeep Kumar S,Eric Doi,Wanzheng Zhu,Sri Gayatri Sundara Padmanabhan,Siddharth Verma,Jasmine Liu,Heng Chen,Mihajlo Velimirović,Malcolm Reynolds,Priyanka Agrawal,Nick Sukhanov,Abhinit Modi,Siddharth Goyal,John Palowitch,Nima Khajehnouri,Wing Lowe,David Klinghoffer,Sharon Silver,Vinh Tran,Candice Schumann,Francesco Piccinno,Xi Liu,Mario Lučić,Xiaochen Yang,Sandeep Kumar,Ajay Kannan,Ragha Kotikalapudi,Mudit Bansal,Fabian Fuchs,Javad Hosseini,Abdelrahman Abdelhamed,Dawn Bloxwich,Tianhe Yu,Ruoxin Sang,Gregory Thornton,Karan Gill,Yuchi Liu,Virat Shejwalkar,Jason Lin,Zhipeng Yan,Kehang Han,Thomas Buschmann,Michael Pliskin,Zhi Xing,Susheel Tatineni,Junlin Zhang,Sissie Hsiao,Gavin Buttimore,Marcus Wu,Zefei Li,Geza Kovacs,Legg Yeung,Tao Huang,Aaron Cohen,Bethanie Brownfield,Averi Nowak,Mikel Rodriguez,Tianze Shi,Hado van Hasselt,Kevin Cen,Deepanway Ghoshal,Kushal Majmundar,Weiren Yu,Warren,Chen,Danila Sinopalnikov,Hao Zhang,Vlado Galić,Di Lu,Zeyu Zheng,Maggie Song,Gary Wang,Gui Citovsky,Swapnil Gawde,Isaac Galatzer-Levy,David Silver,Ivana Balazevic,Dipanjan Das,Kingshuk Majumder,Yale Cong,Praneet Dutta,Dustin Tran,Hui Wan,Junwei Yuan,Daniel Eppens,Alanna Walton,Been Kim,Harry Ragan,James Cobon-Kerr,Lu Liu,Weijun Wang,Bryce Petrini,Jack Rae,Rakesh Shivanna,Yan Xiong,Chace Lee,Pauline Coquinot,Yiming Gu,Lisa Patel,Blake Hechtman,Aviel Boag,Orion Jankowski,Alex Wertheim,Alex Lee,Paul Covington,Hila Noga,Sam Sobell,Shanthal Vasanth,William Bono,Chirag Nagpal,Wei Fan,Xavier Garcia,Kedar Soparkar,Aybuke Turker,Nathan Howard,Sachit Menon,Yuankai Chen,Vikas Verma,Vladimir Pchelin,Harish Rajamani,Valentin Dalibard,Ana Ramalho,Yang Guo,Kartikeya Badola,Seojin Bang,Nathalie Rauschmayr,Julia Proskurnia,Sudeep Dasari,Xinyun Chen,Mikhail Sushkov,Anja Hauth,Pauline Sho,Abhinav Singh,Bilva Chandra,Allie Culp,Max Dylla,Olivier Bachem,James Besley,Heri Zhao,Timothy Lillicrap,Wei Wei,Wael Al Jishi,Ning Niu,Alban Rrustemi,Raphaël Lopez Kaufman,Ryan Poplin,Jewel Zhao,Minh Truong,Shikhar Bharadwaj,Ester Hlavnova,Eli Stickgold,Cordelia Schmid,Georgi Stephanov,Zhaoqi Leng,Frederick Liu,Léonard Hussenot,Shenil Dodhia,Juliana Vicente Franco,Lesley Katzen,Abhanshu Sharma,Sarah Cogan,Zuguang Yang,Aniket Ray,Sergi Caelles,Shen Yan,Ravin Kumar,Daniel Gillick,Renee Wong,Joshua Ainslie,Jonathan Hoech,Séb Arnold,Dan Abolafia,Anca Dragan,Ben Hora,Grace Hu,Alexey Guseynov,Yang Lu,Chas Leichner,Jinmeng Rao,Abhimanyu Goyal,Nagabhushan Baddi,Daniel Hernandez Diaz,Tim McConnell,Max Bain,Jake Abernethy,Qiqi Yan,Rylan Schaeffer,Paul Vicol,Will Thompson,Montse Gonzalez Arenas,Mathias Bellaiche,Pablo Barrio,Stefan Zinke,Riccardo Patana,Pulkit Mehta,JK Kearns,Avraham Ruderman,Scott Pollom,David D'Ambrosio,Cath Hope,Yang Yu,Andrea Gesmundo,Kuang-Huei Lee,Aviv Rosenberg,Yiqian Zhou,Yaoyiran Li,Drew Garmon,Yonghui Wu,Safeen Huda,Gil Fidel,Martin Baeuml,Jian Li,Phoebe Kirk,Rhys May,Tao Tu,Sara Mc Carthy,Toshiyuki Fukuzawa,Miranda Aperghis,Chih-Kuan Yeh,Toshihiro Yoshino,Bo Li,Austin Myers,Kaisheng Yao,Ben Limonchik,Changwan Ryu,Rohun Saxena,Alex Goldin,Ruizhe Zhao,Rocky Rhodes,Tao Zhu,Divya Tyam,Heidi Howard,Nathan Byrd,Hongxu Ma,Yan Wu,Ryan Mullins,Qingze Wang,Aida Amini,Sebastien Baur,Yiran Mao,Subhashini Venugopalan,Will Song,Wen Ding,Paul Collins,Sashank Reddi,Megan Shum,Andrei Rusu,Luisa Zintgraf,Kelvin Chan,Sheela Goenka,Mathieu Blondel,Michael Collins,Renke Pan,Marissa Giustina,Nikolai Chinaev,Christian Schuler,Ce Zheng,Jonas Valfridsson,Alyssa Loo,Alex Yakubovich,Jamie Smith,Tao Jiang,Rich Munoz,Gabriel Barcik,Rishabh Bansal,Mingyao Yang,Yilun Du,Pablo Duque,Mary Phuong,Alexandra Belias,Kunal Lad,Zeyu Liu,Tal Schuster,Karthik Duddu,Jieru Hu,Paige Kunkle,Matthew Watson,Jackson Tolins,Josh Smith,Denis Teplyashin,Garrett Bingham,Marvin Ritter,Marco Andreetto,Divya Pitta,Mohak Patel,Shashank Viswanadha,Trevor Strohman,Catalin Ionescu,Jincheng Luo,Yogesh Kalley,Jeremy Wiesner,Dan Deutsch,Derek Lockhart,Peter Choy,Rumen Dangovski,Chawin Sitawarin,Cat Graves,Tanya Lando,Joost van Amersfoort,Ndidi Elue,Zhouyuan Huo,Pooya Moradi,Jean Tarbouriech,Henryk Michalewski,Wenting Ye,Eunyoung Kim,Alex Druinsky,Florent Altché,Xinyi Chen,Artur Dwornik,Da-Cheng Juan,Rivka Moroshko,Horia Toma,Jarrod Kahn,Hai Qian,Maximilian Sieb,Irene Cai,Roman Goldenberg,Praneeth Netrapalli,Sindhu Raghuram,Yuan Gong,Lijie Fan,Evan Palmer,Yossi Matias,Valentin Gabeur,Shreya Pathak,Tom Ouyang,Don Metzler,Geoff Bacon,Srinivasan Venkatachary,Sridhar Thiagarajan,Alex Cullum,Eran Ofek,Vytenis Sakenas,Mohamed Hammad,Cesar Magalhaes,Mayank Daswani,Oscar Chang,Ashok Popat,Ruichao Li,Komal Jalan,Yanhan Hou,Josh Lipschultz,Antoine He,Wenhao Jia,Pier Giuseppe Sessa,Prateek Kolhar,William Wong,Sumeet Singh,Lukas Haas,Jay Whang,Hanna Klimczak-Plucińska,Georges Rotival,Grace Chung,Yiqing Hua,Anfal Siddiqui,Nicolas Serrano,Dongkai Chen,Billy Porter,Libin Bai,Keshav Shivam,Sho Arora,Partha Talukdar,Tom Cobley,Sangnie Bhardwaj,Evgeny Gladchenko,Simon Green,Kelvin Guu,Felix Fischer,Xiao Wu,Eric Wang,Achintya Singhal,Tatiana Matejovicova,James Martens,Hongji Li,Roma Patel,Elizabeth Kemp,Jiaqi Pan,Lily Wang,Blake JianHang Chen,Jean-Baptiste Alayrac,Navneet Potti,Erika Gemzer,Eugene Ie,Kay McKinney,Takaaki Saeki,Edward Chou,Pascal Lamblin,SQ Mah,Zach Fisher,Martin Chadwick,Jon Stritar,Obaid Sarvana,Andrew Hogue,Artem Shtefan,Hadi Hashemi,Yang Xu,Jindong Gu,Sharad Vikram,Chung-Ching Chang,Sabela Ramos,Logan Kilpatrick,Weijuan Xi,Jenny Brennan,Yinghao Sun,Abhishek Jindal,Ionel Gog,Dawn Chen,Felix Wu,Jason Lee,Sudhindra Kopalle,Srinadh Bhojanapalli,Oriol Vinyals,Natan Potikha,Burcu Karagol Ayan,Yuan Yuan,Michael Riley,Piotr Stanczyk,Sergey Kishchenko,Bing Wang,Dan Garrette,Antoine Yang,Vlad Feinberg,CJ Carey,Javad Azizi,Viral Shah,Erica Moreira,Chongyang Shi,Josh Feldman,Elizabeth Salesky,Thomas Lampe,Aneesh Pappu,Duhyeon Kim,Jonas Adler,Avi Caciularu,Brian Walker,Yunhan Xu,Yochai Blau,Dylan Scandinaro,Terry Huang,Sam El-Husseini,Abhishek Sinha,Lijie Ren,Taylor Tobin,Patrik Sundberg,Tim Sohn,Vikas Yadav,Mimi Ly,Emily Xue,Jing Xiong,Afzal Shama Soudagar,Sneha Mondal,Nikhil Khadke,Qingchun Ren,Ben Vargas,Stan Bileschi,Sarah Chakera,Cindy Wang,Boyu Wang,Yoni Halpern,Joe Jiang,Vikas Sindhwani,Petre Petrov,Pranavaraj Ponnuramu,Sanket Vaibhav Mehta,Yu Watanabe,Betty Chan,Matheus Wisniewski,Trang Pham,Jingwei Zhang,Conglong Li,Dario de Cesare,Art Khurshudov,Alex Vasiloff,Melissa Tan,Zoe Ashwood,Bobak Shahriari,Maryam Majzoubi,Garrett Tanzer,Olga Kozlova,Robin Alazard,James Lee-Thorp,Nguyet Minh Phu,Isaac Tian,Junwhan Ahn,Andy Crawford,Lauren Lax,Yuan,Shangguan,Iftekhar Naim,David Ross,Oleksandr Ferludin,Tongfei Guo,Andrea Banino,Hubert Soyer,Xiaoen Ju,Dominika Rogozińska,Ishaan Malhi,Marcella Valentine,Daniel Balle,Apoorv Kulshreshtha,Maciej Kula,Yiwen Song,Sophia Austin,John Schultz,Roy Hirsch,Arthur Douillard,Apoorv Reddy,Michael Fink,Summer Yue,Khyatti Gupta,Adam Zhang,Norman Rink,Daniel McDuff,Lei Meng,András György,Yasaman Razeghi,Ricky Liang,Kazuki Osawa,Aviel Atias,Matan Eyal,Tyrone Hill,Nikolai Grigorev,Zhengdong Wang,Nitish Kulkarni,Rachel Soh,Ivan Lobov,Zachary Charles,Sid Lall,Kazuma Hashimoto,Ido Kessler,Victor Gomes,Zelda Mariet,Danny Driess,Alessandro Agostini,Canfer Akbulut,Jingcao Hu,Marissa Ikonomidis,Emily Caveness,Kartik Audhkhasi,Saurabh Agrawal,Ioana Bica,Evan Senter,Jayaram Mudigonda,Kelly Chen,Jingchen Ye,Xuanhui Wang,James Svensson,Philipp Fränken,Josh Newlan,Li Lao,Eva Schnider,Sami Alabed,Joseph Kready,Jesse Emond,Afief Halumi,Tim Zaman,Chengxi Ye,Naina Raisinghani,Vilobh Meshram,Bo Chang,Ankit Singh Rawat,Axel Stjerngren,Sergey Levi,Rui Wang,Xiangzhu Long,Mitchelle Rasquinha,Steven Hand,Aditi Mavalankar,Lauren Agubuzu,Sudeshna Roy,Junquan Chen,Jarek Wilkiewicz,Hao Zhou,Michal Jastrzebski,Qiong Hu,Agustin Dal Lago,Ramya Sree Boppana,Wei-Jen Ko,Jennifer Prendki,Yao Su,Zhi Li,Eliza Rutherford,Girish Ramchandra Rao,Ramona Comanescu,Adrià Puigdomènech,Qihang Chen,Dessie Petrova,Christine Chan,Vedrana Milutinovic,Felipe Tiengo Ferreira,Chin-Yi Cheng,Ming Zhang,Tapomay Dey,Sherry Yang,Ramesh Sampath,Quoc Le,Howard Zhou,Chu-Cheng Lin,Hoi Lam,Christine Kaeser-Chen,Kai Hui,Dean Hirsch,Tom Eccles,Basil Mustafa,Shruti Rijhwani,Morgane Rivière,Yuanzhong Xu,Junjie Wang,Xinyang Geng,Xiance Si,Arjun Khare,Cheolmin Kim,Vahab Mirrokni,Kamyu Lee,Khuslen Baatarsukh,Nathaniel Braun,Lisa Wang,Pallavi LV,Richard Tanburn,Yuvein,Zhu,Fangda Li,Setareh Ariafar,Dan Goldberg,Ken Burke,Daniil Mirylenka,Meiqi Guo,Olaf Ronneberger,Hadas Natalie Vogel,Liqun Cheng,Nishita Shetty,Johnson Jia,Thomas Jimma,Corey Fry,Ted Xiao,Martin Sundermeyer,Ryan Burnell,Yannis Assael,Mario Pinto,JD Chen,Rohit Sathyanarayana,Donghyun Cho,Jing Lu,Rishabh Agarwal,Sugato Basu,Lucas Gonzalez,Dhruv Shah,Meng Wei,Dre Mahaarachchi,Rohan Agrawal,Tero Rissa,Yani Donchev,Ramiro Leal-Cavazos,Adrian Hutter,Markus Mircea,Alon Jacovi,Faruk Ahmed,Jiageng Zhang,Shuguang Hu,Bo-Juen Chen,Jonni Kanerva,Guillaume Desjardins,Andrew Lee,Nikos Parotsidis,Asier Mujika,Tobias Weyand,Jasper Snoek,Jo Chick,Kai Chen,Paul Chang,Ethan Mahintorabi,Zi Wang,Tolly Powell,Orgad Keller,Abhirut Gupta,Claire Sha,Kanav Garg,Nicolas Heess,Ágoston Weisz,Cassidy Hardin,Bartek Wydrowski,Ben Coleman,Karina Zainullina,Pankaj Joshi,Alessandro Epasto,Terry Spitz,Binbin Xiong,Kai Zhao,Arseniy Klimovskiy,Ivy Zheng,Johan Ferret,Itay Yona,Waleed Khawaja,Jean-Baptiste Lespiau,Maxim Krikun,Siamak Shakeri,Timothee Cour,Bonnie Li,Igor Krivokon,Dan Suh,Alex Hofer,Jad Al Abdallah,Nikita Putikhin,Oscar Akerlund,Silvio Lattanzi,Anurag Kumar,Shane Settle,Himanshu Srivastava,Folawiyo Campbell-Ajala,Edouard Rosseel,Mihai Dorin Istin,Nishanth Dikkala,Anand Rao,Nick Young,Kate Lin,Dhruva Bhaswar,Yiming Wang,Jaume Sanchez Elias,Kritika Muralidharan,James Keeling,Dayou Du,Siddharth Gopal,Gregory Dibb,Charles Blundell,Manolis Delakis,Jacky Liang,Marco Tulio Ribeiro,Georgi Karadzhov,Guillermo Garrido,Ankur Bapna,Jiawei Cao,Adam Sadovsky,Pouya Tafti,Arthur Guez,Coline Devin,Yixian Di,Jinwei Xing,Chuqiao,Xu,Hanzhao Lin,Chun-Te Chu,Sameera Ponda,Wesley Helmholz,Fan Yang,Yue Gao,Sara Javanmardi,Wael Farhan,Alex Ramirez,Ricardo Figueira,Khe Chai Sim,Yuval Bahat,Ashwin Vaswani,Liangzhe Yuan,Gufeng Zhang,Leland Rechis,Hanjun Dai,Tayo Oguntebi,Alexandra Cordell,Eugénie Rives,Kaan Tekelioglu,Naveen Kumar,Bing Zhang,Aurick Zhou,Nikolay Savinov,Andrew Leach,Alex Tudor,Sanjay Ganapathy,Yanyan Zheng,Mirko Rossini,Vera Axelrod,Arnaud Autef,Yukun Zhu,Zheng Zheng,Mingda Zhang,Baochen Sun,Jie Ren,Nenad Tomasev,Nithish Kannan,Amer Sinha,Charles Chen,Louis O'Bryan,Alex Pak,Aditya Kusupati,Weel Yang,Deepak Ramachandran,Patrick Griffin,Seokhwan Kim,Philipp Neubeck,Craig Schiff,Tammo Spalink,Mingyang Ling,Arun Nair,Ga-Young Joung,Linda Deng,Avishkar Bhoopchand,Lora Aroyo,Tom Duerig,Jordan Griffith,Gabe Barth-Maron,Jake Ades,Alex Haig,Ankur Taly,Yunting Song,Paul Michel,Dave Orr,Dean Weesner,Corentin Tallec,Carrie Grimes Bostock,Paul Niemczyk,Andy Twigg,Mudit Verma,Rohith Vallu,Henry Wang,Marco Gelmi,Kiranbir Sodhia,Aleksandr Chuklin,Omer Goldman,Jasmine George,Liang Bai,Kelvin Zhang,Petar Sirkovic,Efrat Nehoran,Golan Pundak,Jiaqi Mu,Alice Chen,Alex Greve,Paulo Zacchello,David Amos,Heming Ge,Eric Noland,Colton Bishop,Jeffrey Dudek,Youhei Namiki,Elena Buchatskaya,Jing Li,Dorsa Sadigh,Masha Samsikova,Dan Malkin,Damien Vincent,Robert David,Rob Willoughby,Phoenix Meadowlark,Shawn Gao,Yan Li,Raj Apte,Amit Jhindal,Stein Xudong Lin,Alex Polozov,Zhicheng Wang,Tomas Mery,Anirudh GP,Varun Yerram,Sage Stevens,Tianqi Liu,Noah Fiedel,Charles Sutton,Matthew Johnson,Xiaodan Song,Kate Baumli,Nir Shabat,Muqthar Mohammad,Hao Liu,Marco Selvi,Yichao Zhou,Mehdi Hafezi Manshadi,Chu-ling Ko,Anthony Chen,Michael Bendersky,Jorge Gonzalez Mendez,Nisarg Kothari,Amir Zandieh,Yiling Huang,Daniel Andor,Ellie Pavlick,Idan Brusilovsky,Jitendra Harlalka,Sally Goldman,Andrew Lampinen,Guowang Li,Asahi Ushio,Somit Gupta,Lei Zhang,Chuyuan Kelly Fu,Madhavi Sewak,Timo Denk,Jed Borovik,Brendan Jou,Avital Zipori,Prateek Jain,Junwen Bai,Thang Luong,Jonathan Tompson,Alice Li,Li Liu,George Powell,Jiajun Shen,Alex Feng,Grishma Chole,Da Yu,Yinlam Chow,Tongxin Yin,Eric Malmi,Kefan Xiao,Yash Pande,Shachi Paul,Niccolò Dal Santo,Adil Dostmohamed,Sergio Guadarrama,Aaron Phillips,Thanumalayan Sankaranarayana Pillai,Gal Yona,Amin Ghafouri,Preethi Lahoti,Benjamin Lee,Dhruv Madeka,Eren Sezener,Simon Tokumine,Adrian Collister,Nicola De Cao,Richard Shin,Uday Kalra,Parker Beak,Emily Nottage,Ryo Nakashima,Ivan Jurin,Vikash Sehwag,Meenu Gaba,Junhao Zeng,Kevin R. McKee,Fernando Pereira,Tamar Yakar,Amayika Panda,Arka Dhar,Peilin Zhong,Daniel Sohn,Mark Brand,Lars Lowe Sjoesund,Viral Carpenter,Sharon Lin,Shantanu Thakoor,Marcus Wainwright,Ashwin Chaugule,Pranesh Srinivasan,Muye Zhu,Bernett Orlando,Jack Weber,Ayzaan Wahid,Gilles Baechler,Apurv Suman,Jovana Mitrović,Gabe Taubman,Honglin Yu,Helen King,Josh Dillon,Cathy Yip,Dhriti Varma,Tomas Izo,Levent Bolelli,Borja De Balle Pigem,Julia Di Trapani,Fotis Iliopoulos,Adam Paszke,Nishant Ranka,Joe Zou,Francesco Pongetti,Jed McGiffin,Alex Siegman,Rich Galt,Ross Hemsley,Goran Žužić,Victor Carbune,Tao Li,Myle Ott,Félix de Chaumont Quitry,David Vilar Torres,Yuri Chervonyi,Tomy Tsai,Prem Eruvbetine,Samuel Yang,Matthew Denton,Jake Walker,Slavica Andačić,Idan Heimlich Shtacher,Vittal Premachandran,Harshal Tushar Lehri,Cip Baetu,Damion Yates,Lampros Lamprou,Mariko Iinuma,Ioana Mihailescu,Ben Albrecht,Shachi Dave,Susie Sargsyan,Bryan Perozzi,Lucas Manning,Chiyuan Zhang,Denis Vnukov,Igor Mordatch,Raia Hadsell Wolfgang Macherey,Ryan Kappedal,Jim Stephan,Aditya Tripathi,Klaus Macherey,Jun Qian,Abhishek Bhowmick,Shekoofeh Azizi,Rémi Leblond,Shiva Mohan Reddy Garlapati,Timothy Knight,Matthew Wiethoff,Wei-Chih Hung,Anelia Angelova,Georgios Evangelopoulos,Pawel Janus,Dimitris Paparas,Matthew Rahtz,Ken Caluwaerts,Vivek Sampathkumar,Daniel Jarrett,Shadi Noghabi,Antoine Miech,Chak Yeung,Geoff Clark,Henry Prior,Fei Zheng,Jean Pouget-Abadie,Indro Bhattacharya,Kalpesh Krishna,Will Bishop,Zhe Yuan,Yunxiao Deng,Ashutosh Sathe,Kacper Krasowiak,Ciprian Chelba,Cho-Jui Hsieh,Kiran Vodrahalli,Buhuang Liu,Thomas Köppe,Amr Khalifa,Lubo Litchev,Pichi Charoenpanit,Reed Roberts,Sachin Yadav,Yasumasa Onoe,Desi Ivanov,Megha Mohabey,Vighnesh Birodkar,Nemanja Rakićević,Pierre Sermanet,Vaibhav Mehta,Krishan Subudhi,Travis Choma,Will Ng,Luheng He,Kathie Wang,Tasos Kementsietsidis,Shane Gu,Mansi Gupta,Andrew Nystrom,Mehran Kazemi,Timothy Chung,Nacho Cano,Nikhil Dhawan,Yufei Wang,Jiawei Xia,Trevor Yacovone,Eric Jia,Mingqing Chen,Simeon Ivanov,Ashrith Sheshan,Sid Dalmia,Paweł Stradomski,Pengcheng Yin,Salem Haykal,Congchao Wang,Dennis Duan,Neslihan Bulut,Greg Kochanski,Liam MacDermed,Namrata Godbole,Shitao Weng,Jingjing Chen,Rachana Fellinger,Ramin Mehran,Daniel Suo,Hisham Husain,Tong He,Kaushal Patel,Joshua Howland,Randall Parker,Kelvin Nguyen,Sharath Maddineni,Chris Rawles,Mina Khan,Shlomi Cohen-Ganor,Amol Mandhane,Xinyi Wu,Chenkai Kuang,Iulia Comşa,Ramya Ganeshan,Hanie Sedghi,Adam Bloniarz,Nuo Wang Pierse,Anton Briukhov,Petr Mitrichev,Anita Gergely,Serena Zhan,Allan Zhou,Nikita Saxena,Eva Lu,Josef Dean,Ashish Gupta,Nicolas Perez-Nieves,Renjie Wu,Cory McLean,Wei Liang,Disha Jindal,Anton Tsitsulin,Wenhao Yu,Kaiz Alarakyia,Tom Schaul,Piyush Patil,Peter Sung,Elijah Peake,Hongkun Yu,Feryal Behbahani,JD Co-Reyes,Alan Ansell,Sean Sun,Clara Barbu,Jonathan Lee,Seb Noury,James Allingham,Bilal Piot,Mohit Sharma,Christopher Yew,Ivan Korotkov,Bibo Xu,Demetra Brady,Goran Petrovic,Shibl Mourad,Claire Cui,Aditya Gupta,Parker Schuh,Saarthak Khanna,Anna Goldie,Abhinav Arora,Vadim Zubov,Amy Stuart,Mark Epstein,Yun Zhu,Jianqiao Liu,Yury Stuken,Ziyue Wang,Karolis Misiunas,Dee Guo,Ashleah Gill,Ale Hartman,Zaid Nabulsi,Aurko Roy,Aleksandra Faust,Jason Riesa,Ben Withbroe,Mengchao Wang,Marco Tagliasacchi,Andreea Marzoca,James Noraky,Serge Toropov,Malika Mehrotra,Bahram Raad,Sanja Deur,Steve Xu,Marianne Monteiro,Zhongru Wu,Yi Luan,Sam Ritter,Nick Li,Håvard Garnes,Yanzhang He,Martin Zlocha,Jifan Zhu,Matteo Hessel,Will Wu,Spandana Raj Babbula,Chizu Kawamoto,Yuanzhen Li,Mehadi Hassen,Yan Wang,Brian Wieder,James Freedman,Yin Zhang,Xinyi Bai,Tianli Yu,David Reitter,XiangHai Sheng,Mateo Wirth,Aditya Kini,Dima Damen,Mingcen Gao,Rachel Hornung,Michael Voznesensky,Brian Roark,Adhi Kuncoro,Yuxiang Zhou,Rushin Shah,Anthony Brohan,Kuangyuan Chen,James Wendt,David Rim,Paul Kishan Rubenstein,Jonathan Halcrow,Michelle Liu,Ty Geri,Yunhsuan Sung,Jane Shapiro,Shaan Bijwadia,Chris Duvarney,Christina Sorokin,Paul Natsev,Reeve Ingle,Pramod Gupta,Young Maeng,Ndaba Ndebele,Kexin Zhu,Valentin Anklin,Katherine Lee,Yuan Liu,Yaroslav Akulov,Shaleen Gupta,Guolong Su,Flavien Prost,Tianlin Liu,Vitaly Kovalev,Pol Moreno,Martin Scholz,Sam Redmond,Zongwei Zhou,Alex Castro-Ros,André Susano Pinto,Dia Kharrat,Michal Yarom,Rachel Saputro,Jannis Bulian,Ben Caine,Ji Liu,Abbas Abdolmaleki,Shariq Iqbal,Tautvydas Misiunas,Mikhail Sirotenko,Shefali Garg,Guy Bensky,Huan Gui,Xuezhi Wang,Raphael Koster,Mike Bernico,Da Huang,Romal Thoppilan,Trevor Cohn,Ben Golan,Wenlei Zhou,Andrew Rosenberg,Markus Freitag,Tynan Gangwani,Vincent Tsang,Anand Shukla,Xiaoqi Ren,Minh Giang,Chi Zou,Andre Elisseeff,Charline Le Lan,Dheeru Dua,Shuba Lall,Pranav Shyam,Frankie Garcia,Sarah Nguyen,Michael Guzman,AJ Maschinot,Marcello Maggioni,Ming-Wei Chang,Karol Gregor,Lotte Weerts,Kumaran Venkatesan,Bogdan Damoc,Leon Liu,Jan Wassenberg,Lewis Ho,Becca Roelofs,Majid Hadian,François-Xavier Aubet,Yu Liang,Sami Lachgar,Danny Karmon,Yong Cheng,Amelio Vázquez-Reina,Angie Chen,Zhuyun Dai,Andy Brock,Shubham Agrawal,Chenxi Pang,Peter Garst,Mariella Sanchez-Vargas,Ivor Rendulic,Aditya Ayyar,Andrija Ražnatović,Olivia Ma,Roopali Vij,Neha Sharma,Ashwin Balakrishna,Bingyuan Liu,Ian Mackinnon,Sorin Baltateanu,Petra Poklukar,Gabriel Ibagon,Colin Ji,Hongyang Jiao,Isaac Noble,Wojciech Stokowiec,Zhihao Li,Jeff Dean,David Lindner,Mark Omernick,Kristen Chiafullo,Mason Dimarco,Vitor Rodrigues,Vittorio Selo,Garrett Honke,Xintian,Wu,Wei He,Adam Hillier,Anhad Mohananey,Vihari Piratla,Chang Ye,Chase Malik,Sebastian Riedel,Samuel Albanie,Zi Yang,Kenny Vassigh,Maria Bauza,Sheng Li,Yiqing Tao,Nevan Wichers,Andrii Maksai,Abe Ittycheriah,Ross Mcilroy,Bryan Seybold,Noah Goodman,Romina Datta,Steven M. Hernandez,Tian Shi,Yony Kochinski,Anna Bulanova,Ken Franko,Mikita Sazanovich,Nicholas FitzGerald,Praneeth Kacham,Shubha Srinivas Raghvendra,Vincent Hellendoorn,Alexander Grushetsky,Julian Salazar,Angeliki Lazaridou,Jason Chang,Jan-Thorsten Peter,Sushant Kafle,Yann Dauphin,Abhishek Rao,Filippo Graziano,Izhak Shafran,Yuguo Liao,Tianli Ding,Geng Yan,Grace Chu,Zhao Fu,Vincent Roulet,Gabriel Rasskin,Duncan Williams,Shahar Drath,Alex Mossin,Raphael Hoffmann,Jordi Orbay,Francesco Bertolini,Hila Sheftel,Justin Chiu,Siyang Xue,Yuheng Kuang,Ferjad Naeem,Swaroop Nath,Nana Nti,Phil Culliton,Kashyap Krishnakumar,Michael Isard,Pei Sun,Ayan Chakrabarti,Nathan Clement,Regev Cohen,Arissa Wongpanich,GS Oh,Ashwin Murthy,Hao Zheng,Jessica Hamrick,Oskar Bunyan,Suhas Ganesh,Nitish Gupta,Roy Frostig,John Wieting,Yury Malkov,Pierre Marcenac,Zhixin,Lai,Xiaodan Tang,Mohammad Saleh,Fedir Zubach,Chinmay Kulkarni,Huanjie Zhou,Vicky Zayats,Nan Ding,Anshuman Tripathi,Arijit Pramanik,Patrik Zochbauer,Harish Ganapathy,Vedant Misra,Zach Behrman,Hugo Vallet,Mingyang Zhang,Mukund Sridhar,Ye Jin,Mohammad Babaeizadeh,Siim Põder,Megha Goel,Divya Jain,Tajwar Nasir,Shubham Mittal,Tim Dozat,Diego Ardila,Aliaksei Severyn,Fabio Pardo,Sammy Jerome,Siyang Qin,Louis Rouillard,Amir Yazdanbakhsh,Zizhao Zhang,Shivani Agrawal,Kaushik Shivakumar,Caden Lu,Praveen Kallakuri,Rachita Chhaparia,Kanishka Rao,Charles Kwong,Asya Fadeeva,Shitij Nigam,Yan Virin,Yuan Zhang,Balaji Venkatraman,Beliz Gunel,Marc Wilson,Huiyu Wang,Abhinav Gupta,Xiaowei Xu,Adrien Ali Taïga,Kareem Mohamed,Doug Fritz,Daniel Rodriguez,Zoubin Ghahramani,Harry Askham,Lior Belenki,James Zhao,Rahul Gupta,Krzysztof Jastrzębski,Takahiro Kosakai,Kaan Katircioglu,Jon Schneider,Rina Panigrahy,Konstantinos Bousmalis,Peter Grabowski,Prajit Ramachandran,Chaitra Hegde,Mihaela Rosca,Angelo Scorza Scarpati,Kyriakos Axiotis,Ying Xu,Zach Gleicher,Assaf Hurwitz Michaely,Mandar Sharma,Sanil Jain,Christoph Hirnschall,Tal Marian,Xuhui Jia,Kevin Mather,Kilol Gupta,Linhai Qiu,Nigamaa Nayakanti,Lucian Ionita,Steven Zheng,Lucia Loher,Kurt Shuster,Igor Petrovski,Roshan Sharma,Rahma Chaabouni,Angel Yeh,James An,Arushi Gupta,Steven Schwarcz,Seher Ellis,Sam Conway-Rahman,Javier Snaider,Alex Zhai,James Atwood,Daniel Golovin,Liqian Peng,Te I,Vivian Xia,Salvatore Scellato,Mahan Malihi,Arthur Bražinskas,Vlad-Doru Ion,Younghoon Jun,James Swirhun,Soroosh Mariooryad,Jiao Sun,Steve Chien,Rey Coaguila,Ariel Brand,Yi Gao,Tom Kwiatkowski,Roee Aharoni,Cheng-Chun Lee,Mislav Žanić,Yichi Zhang,Dan Ethier,Vitaly Nikolaev,Pranav Nair,Yoav Ben Shalom,Hen Fitoussi,Jai Gupta,Hongbin Liu,Dee Cattle,Tolga Bolukbasi,Ben Murdoch,Fantine Huot,Yin Li,Chris Hahn*

Main category: cs.CL

TL;DR: Gemini 2.X模型家族带来全新高性能大模型，具备多模态、长上下文、强推理能力，覆盖从高端到低成本的多样化场景，推动智能体推理新高度。


<details>
  <summary>Details</summary>
Motivation: 提出了新的Gemini 2.X模型家族，旨在提升模型在编码、推理、多模态理解和长上下文处理能力方面的表现，同时覆盖不同性能、成本和延迟需求。

Method: 开发了Gemini 2.5 Pro（高性能）、Gemini 2.5 Flash（高性价比）、Gemini 2.0 Flash及Flash-Lite（低成本低延迟）等多种模型，测试其在前沿编码与推理基准、多模态任务（如支持长达3小时的视频处理）等方面的能力。

Result: Gemini 2.5 Pro在编码和推理基准上达到了当前最强性能，具备优异的多模态理解与处理长上下文的能力。Gemini 2.5 Flash在计算资源和延迟大幅降低的情况下，依然维持出色的推理能力。Gemini 2.0 Flash和Flash-Lite则在低延迟和低成本下实现了较高性能。整体上，2.X模型家族实现了能力和成本的最优折中。

Conclusion: Gemini 2.X模型家族不仅显著提升了模型综合实力，还满足了不同用户对性能和成本的多样需求，推动了多智能体复杂问题求解的新边界。

Abstract: In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and
Gemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite
models. Gemini 2.5 Pro is our most capable model yet, achieving SoTA
performance on frontier coding and reasoning benchmarks. In addition to its
incredible coding and reasoning skills, Gemini 2.5 Pro is a thinking model that
excels at multimodal understanding and it is now able to process up to 3 hours
of video content. Its unique combination of long context, multimodal and
reasoning capabilities can be combined to unlock new agentic workflows. Gemini
2.5 Flash provides excellent reasoning abilities at a fraction of the compute
and latency requirements and Gemini 2.0 Flash and Flash-Lite provide high
performance at low latency and cost. Taken together, the Gemini 2.X model
generation spans the full Pareto frontier of model capability vs cost, allowing
users to explore the boundaries of what is possible with complex agentic
problem solving.

</details>


### [17] [Humans overrely on overconfident language models, across languages](https://arxiv.org/abs/2507.06306)
*Neil Rathi,Dan Jurafsky,Kaitlyn Zhou*

Main category: cs.CL

TL;DR: 跨多语言分析发现在所有语言中，用户都容易依赖模型的自信输出，但表达不确定性的方式和用户反应根据语言和文化而异，提示多语言下LLM的安全校准需文化敏感化。


<details>
  <summary>Details</summary>
Motivation: 已有研究发现LLM在英文中表现出过度自信，导致用户过度依赖模型结论，但不同语言对表达不确定性的语气标记存在差异性，因此有必要探究LLM在多语言环境下的信心校准及相关安全风险。

Method: 分析了LLM在五种语言下生成的不确定性标记的分布，包括“绝对肯定”、“我认为”等表达，并结合人类用户对不同语言中模型生成的不确定性表达的依赖行为进行测量对比。

Result: 发现LLM在所有研究语言中均显示出过度自信的倾向，但对于不同语言的不确定性表达也具有敏感性。例如，在日语中生成最多的不确定性标记，而在德语和中文中生成最多的确定性标记。用户对模型自信输出的依赖在所有语言中都很高，但在日语中对不确定性表达的依赖显著高于英语。

Conclusion: 跨语言中使用大型语言模型时，用户对模型生成内容的过度依赖风险较高，且这种依赖因语言和文化而异。因此，模型的语言校准和安全评估需考虑文化和语言差异。

Abstract: As large language models (LLMs) are deployed globally, it is crucial that
their responses are calibrated across languages to accurately convey
uncertainty and limitations. Previous work has shown that LLMs are
linguistically overconfident in English, leading users to overrely on confident
generations. However, the usage and interpretation of epistemic markers (e.g.,
'It's definitely,' 'I think') can differ sharply across languages. Here, we
study the risks of multilingual linguistic (mis)calibration, overconfidence,
and overreliance across five languages to evaluate the safety of LLMs in a
global context.
  We find that overreliance risks are high across all languages. We first
analyze the distribution of LLM-generated epistemic markers, and observe that
while LLMs are cross-linguistically overconfident, they are also sensitive to
documented linguistic variation. For example, models generate the most markers
of uncertainty in Japanese and the most markers of certainty in German and
Mandarin. We then measure human reliance rates across languages, finding that
while users strongly rely on confident LLM generations in all languages,
reliance behaviors differ cross-linguistically: for example, users rely
significantly more on expressions of uncertainty in Japanese than in English.
Taken together, these results indicate high risk of reliance on overconfident
model generations across languages. Our findings highlight the challenges of
multilingual linguistic calibration and stress the importance of culturally and
linguistically contextualized model safety evaluations.

</details>


### [18] [ETT: Expanding the Long Context Understanding Capability of LLMs at Test-Time](https://arxiv.org/abs/2507.06313)
*Kiarash Zahirnia,Zahra Golpayegani,Walid Ahmad,Yang Liu*

Main category: cs.CL

TL;DR: 提出一种推理时拓展Transformer模型上下文长度的方法（ETT），可大幅提升长文本处理准确率，并且内存和计算开销可控。微调FFN特定层比全量微调表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的语言模型在处理长序列时，计算和内存开销呈二次增长，给长文本处理带来挑战。

Method: 提出一种名为ETT（Extend at Test-Time）的方法，通过将输入上下文分块并高效微调模型参数，在推理时拓展短上下文Transformer模型的上下文长度，实现常量内存需求和线性计算开销。

Result: 在LongBench数据集上，将GPT-Large和Phi-2的上下文长度从1k扩展到32k，最多提升了30%的准确率。详细消融实验发现，测试时微调前馈神经网络（FFN）第二层比全量微调更有效，进一步提升模型表现。

Conclusion: ETT方法可显著拓展语言模型的上下文长度，提升模型处理长文本的能力，同时保持低内存和线性计算成本。微调FFN特定层效果优于全量微调，有助于更高效的长文本任务建模。

Abstract: Transformer-based Language Models' computation and memory overhead increase
quadratically as a function of sequence length. The quadratic cost poses
challenges when employing LLMs for processing long sequences. In this work, we
introduce \ourmodelacronym~(Extend at Test-Time), method for extending the
context length of short context Transformer-based LLMs, with constant memory
requirement and linear computation overhead. ETT enable the extension of the
context length at test-time by efficient fine-tuning the model's parameters on
the input context, chunked into overlapping small subsequences. We evaluate ETT
on LongBench by extending the context length of GPT-Large and Phi-2 up to 32
times, increasing from 1k to 32k tokens. This results in up to a 30 percent
improvement in the model's accuracy. We also study how context can be stored in
LLM's weights effectively and efficiently. Through a detailed ablation study,
we examine which Transformer modules are most beneficial to fine-tune at
test-time. Interestingly, we find that fine-tuning the second layer of the FFNs
is more effective than full fine-tuning, leading to a further improvement in
the models' accuracy.

</details>


### [19] [Could the Road to Grounded, Neuro-symbolic AI be Paved with Words-as-Classifiers?](https://arxiv.org/abs/2507.06335)
*Casey Kennington,David Schlangen*

Main category: cs.CL

TL;DR: 本文总结了将语言三大语义理论统一的现有尝试，认为words-as-classifier模型是实现这一目标的重要路径，并通过文献综述、理论动因和实验验证，支持该模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的计算语义理论——形式语义、分布式语义和语义落地——各有优劣，单一模型无法兼容所有优势。过去研究已尝试将视觉知识融入语言模型，且有学者呼吁融合符号方法以借各家所长。本研究正是为了探索三者统一的途径。

Method: 梳理相关文献，结合认知科学的新进展来论证“words-as-classifiers”模型的重要性，并描述了一个小型实验来验证该理论框架的有效性。

Result: 综述了words-as-classifiers模型的相关文献，验证了其在对话场景中的应用效果，并简单阐述了该模型如何实现对三大语义理论的统一。

Conclusion: “Words-as-classifier”模型有潜力统一形式、分布式和语义落地三大学派，成为未来计算语义学研究的重要方向。

Abstract: Formal, Distributional, and Grounded theories of computational semantics each
have their uses and their drawbacks. There has been a shift to ground models of
language by adding visual knowledge, and there has been a call to enrich models
of language with symbolic methods to gain the benefits from formal,
distributional, and grounded theories. In this paper, we attempt to make the
case that one potential path forward in unifying all three semantic fields is
paved with the words-as-classifier model, a model of word-level grounded
semantics that has been incorporated into formalisms and distributional
language models in the literature, and it has been well-tested within
interactive dialogue settings. We review that literature, motivate the
words-as-classifiers model with an appeal to recent work in cognitive science,
and describe a small experiment. Finally, we sketch a model of semantics
unified through words-as-classifiers.

</details>


### [20] [Evaluating Morphological Alignment of Tokenizers in 70 Languages](https://arxiv.org/abs/2507.06378)
*Catherine Arnett,Marisa Hudspeth,Brendan O'Connor*

Main category: cs.CL

TL;DR: 作者扩展了MorphScore指标以支持70种语言，并系统评估形态边界对齐与下游任务性能的关系，结果显示二者相关性较差，提示分词器质量评估不能单靠形态对齐程度。


<details>
  <summary>Details</summary>
Motivation: 分词是语言建模中的关键步骤，但如何有效评估分词器质量仍不清楚。一个衡量标准是分词器能否保持语义上有意义的词素，将分词边界与词形边界对齐。本文旨在扩展当前用于评估分词器形态对齐的MorphScore指标，在更多语言上进行评估，并检验其与下游任务表现间的关系。

Method: 扩展MorphScore指标，从原本的22种语言增加到70种语言，并增强其灵活性及修正原有的一些不足。随后，作者在70种语言中，针对5个预训练语言模型，在7个下游任务上，分析分词器的形态对齐分数与任务表现的相关性。

Result: 形态学对齐分数与模型在各类下游任务上的表现相关性较弱，即形态对齐程度对模型任务性能的解释作用有限。

Conclusion: 单独以形态学对齐作为分词器质量评估标准并不足以预测模型的实际表现。分词边界与词形边界的对齐并非决定性影响下游任务性能的关键指标。

Abstract: While tokenization is a key step in language modeling, with effects on model
training and performance, it remains unclear how to effectively evaluate
tokenizer quality. One proposed dimension of tokenizer quality is the extent to
which tokenizers preserve linguistically meaningful subwords, aligning token
boundaries with morphological boundaries within a word. We expand MorphScore
(Arnett & Bergen, 2025), which previously covered 22 languages, to support a
total of 70 languages. The updated MorphScore offers more flexibility in
evaluation and addresses some of the limitations of the original version. We
then correlate our alignment scores with downstream task performance for five
pre-trained languages models on seven tasks, with at least one task in each of
the languages in our sample. We find that morphological alignment does not
explain very much variance in model performance, suggesting that morphological
alignment alone does not measure dimensions of tokenization quality relevant to
model performance.

</details>


### [21] [Hypermagmas and Colored Operads: Heads, Phases, and Theta Roles](https://arxiv.org/abs/2507.06393)
*Matilde Marcolli,Riny Huijbregts,Richard K. Larson*

Main category: cs.CL

TL;DR: 本文引入了magma、hypermagma与彩色算子等代数结构，将生成语法的多种结构与约束原则统一建模，不仅形式上更简洁，也有助于句法运算的整体解释与未来的自动化分析。


<details>
  <summary>Details</summary>
Motivation: 旨在通过更抽象与结构化的数学工具（如magma、hypermagma、colored operad等），更精确地描述和统一句法结构中的成分（如头、补足语、修饰语、相位等）及句法运算（如合并、移动等）及相应原则（如EPP、ECP、PIC等）。

Method: 运用代数结构（magma与hypermagma）、彩色算子（colored operad）与芽生成系统（bud generating system）对头和补足语、修饰语、相位等句法结构进行形式建模，将传统的句法约束用算子生成器统一表达。通过染色规则和结构生成过程中的筛选映射，实现内部合并的移动与多种句法原则的整合。

Result: 成功地将句法结构与操作（如头与补足语的关系、相位结构、内部合并等）建模为有兼容c-command、m-command关系的hypermagma与彩色算子系统，各种句法约束（EPP、ECP、PIC等）被统一编码，阶段结构与θ角色分配之间的兼容性可通过彩色算子的转导关系来表述。

Conclusion: 使用抽象代数工具能有效统一诸多句法对象与操作、约束原则的形式化表达，为句法理论的统一、精确和可计算性提供了新途径和工具。

Abstract: We show that head functions on syntactic objects extend the magma structure
to a hypermagma, with the c-command relation compatible with the magma
operation and the m-command relation with the hypermagma. We then show that the
structure of head and complement and specifier, additional modifier positions,
and the structure of phases in the Extended Projection can be formulated as a
bud generating system of a colored operad, in a form similar to the structure
of theta roles. We also show that, due to the special form of the colored
operad generators, the filtering of freely generated syntactic objects by these
coloring rules can be equivalently formulated as a filtering in the course of
structure formation via a colored Merge, which can in turn be related to the
hypermagma structure. The rules on movement by Internal Merge with respect to
phases, the Extended Projection Principle, Empty Category Principle, and Phase
Impenetrability Condition are all subsumed into the form of the colored operad
generators. Movement compatibilities between the phase structure and the theta
roles assignments can then be formulated in terms of the respective colored
operads and a transduction of colored operads.

</details>


### [22] [PERK: Long-Context Reasoning as Parameter-Efficient Test-Time Learning](https://arxiv.org/abs/2507.06415)
*Zeming Chen,Angelika Romanou,Gail Weiss,Antoine Bosselut*

Main category: cs.CL

TL;DR: PERK方法通过在测试时对轻量适配器进行训练，实现了更高效且内存友好的长文本推理，显著提升了小型和中型模型在长上下文任务中的效果。


<details>
  <summary>Details</summary>
Motivation: 长文本推理需要模型能在大量、嘈杂的上下文中准确识别相关信息。现有基于元学习的测试时学习方法虽然有效，但由于显著的内存消耗，难以用于长文本场景。

Method: 提出了PERK方法：在测试时通过对轻量级模型适配器进行梯度更新，高效地将长输入上下文编码到模型参数中。PERK采用两层嵌套优化循环进行元训练，内循环利用低秩适配器（LoRA）快速编码上下文，外循环学习如何用更新后的适配器从编码结果中准确检索与推理相关信息。

Result: PERK在多个长上下文推理任务中明显优于基线方法。对于小模型（如GPT-2）平均绝对性能提升高达90%，对更大模型（Qwen-2.5-0.5B）提升27%。此外，PERK在推理复杂度、长度外推和重要信息位置变化等方面表现更稳健。

Conclusion: PERK方法大幅提升了长文本推理中的相关信息提取和推理能力，尤其在长上下文及噪声背景下更具健壮性。虽然训练时内存消耗较大，但推理阶段比基于提示的推理方法更高效。

Abstract: Long-context reasoning requires accurately identifying relevant information
in extensive, noisy input contexts. Previous research shows that using
test-time learning to encode context directly into model parameters can
effectively enable reasoning over noisy information. However, meta-learning
methods for enabling test-time learning are prohibitively memory-intensive,
preventing their application to long context settings. In this work, we propose
PERK (Parameter Efficient Reasoning over Knowledge), a scalable approach for
learning to encode long input contexts using gradient updates to a lightweight
model adapter at test time. Specifically, PERK employs two nested optimization
loops in a meta-training phase. The inner loop rapidly encodes contexts into a
low-rank adapter (LoRA) that serves as a parameter-efficient memory module for
the base model. Concurrently, the outer loop learns to use the updated adapter
to accurately recall and reason over relevant information from the encoded long
context. Our evaluations on several long-context reasoning tasks show that PERK
significantly outperforms the standard prompt-based long-context baseline,
achieving average absolute performance gains of up to 90% for smaller models
(GPT-2) and up to 27% for our largest evaluated model, Qwen-2.5-0.5B. In
general, PERK is more robust to reasoning complexity, length extrapolation, and
the locations of relevant information in contexts. Finally, we show that while
PERK is memory-intensive during training, it scales more efficiently at
inference time than prompt-based long-context inference.

</details>


### [23] [Reward Models Can Improve Themselves: Reward-Guided Adversarial Failure Mode Discovery for Robust Reward Modeling](https://arxiv.org/abs/2507.06419)
*Pankayaraj Pathmanathan,Furong Huang*

Main category: cs.CL

TL;DR: 作者提出了一种无需先验知识的奖励模型自我改进方法REFORM，通过奖励模型自举生成并利用对抗样本增强训练，有效提升了模型的鲁棒性和对齐质量。


<details>
  <summary>Details</summary>
Motivation: 现有大模型（LLMs）在对齐人类偏好时，借助奖励建模（RM）方法，但由于人类偏好的复杂性和数据集覆盖有限，这些奖励模型在分布外环境或对抗干扰下容易失效。而现有识别失败模式的方法依赖于先验的偏好分布或失败特征，在实际应用中不太可行。

Method: 作者提出了一种新的、与偏好分布无关的奖励模型失败模式发现方法，基于奖励引导的受控生成（reward guided controlled decoding）。在此基础上，提出了REFORM：自我改进奖励建模框架。该方法用奖励模型自身引导生成评分错误的对抗样本，然后用这些对抗样本增强训练数据，从而修正奖励模型的失配行为。

Result: 在两个广泛使用的人类偏好数据集（Anthropic Helpful Harmless 和 PKU Beavertails）上，REFORM显著提升了模型的鲁棒性，但不降低奖励质量。在直接评测和下游policy训练中均保持了性能，并且通过去除虚假相关性进一步提升了对齐质量。

Conclusion: REFORM框架通过奖励模型自身引导生成并利用对抗样本，有效提升了奖励模型面对分布转移及对抗扰动时的鲁棒性，并改进了对齐质量。该方法无需先验信息，具有更高的实用性。

Abstract: Reward modeling (RM), which captures human preferences to align large
language models (LLMs), is increasingly employed in tasks such as model
finetuning, response filtering, and ranking. However, due to the inherent
complexity of human preferences and the limited coverage of available datasets,
reward models often fail under distributional shifts or adversarial
perturbations. Existing approaches for identifying such failure modes typically
rely on prior knowledge about preference distributions or failure attributes,
limiting their practicality in real-world settings where such information is
unavailable. In this work, we propose a tractable, preference-distribution
agnostic method for discovering reward model failure modes via reward guided
controlled decoding. Building on this, we introduce REFORM, a self-improving
reward modeling framework that enhances robustness by using the reward model
itself to guide the generation of falsely scored responses. These adversarial
examples are then used to augment the training data and patch the reward
model's misaligned behavior. We evaluate REFORM on two widely used preference
datasets Anthropic Helpful Harmless (HH) and PKU Beavertails and demonstrate
that it significantly improves robustness without sacrificing reward quality.
Notably, REFORM preserves performance both in direct evaluation and in
downstream policy training, and further improves alignment quality by removing
spurious correlations.

</details>


### [24] [Exploring Task Performance with Interpretable Models via Sparse Auto-Encoders](https://arxiv.org/abs/2507.06427)
*Shun Wang,Tyler Loakman,Youbo Lei,Yi Liu,Bohao Yang,Yuting Zhao,Dong Yang,Chenghua Lin*

Main category: cs.CL

TL;DR: 作者提出用稀疏自编码器分解LLM内部神经元，提取更有意义的单义特征，既提升了模型解释性，还通过自动优化提示词，让LLM在多个下游任务上的表现变得更好。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）被普遍认为是黑箱算法，缺乏可解释性和可信度，同时也限制了提升下游任务表现的方法探索。

Method: 本文提出利用稀疏自编码器的字典学习方法，对LLM进行分解，从多义神经元中提取单义特征。

Result: 该方法不仅识别了LLM内部的理解偏差，还能自动重构提示词，增加注释以帮助模型更好地理解任务，提高数学推理、隐喻检测等下游任务的表现。

Conclusion: 通过对LLM内部表示的有效分解，不仅提升了模型的可解释性和信任度，还显著提升了多个实际任务的性能。

Abstract: Large Language Models (LLMs) are traditionally viewed as black-box
algorithms, therefore reducing trustworthiness and obscuring potential
approaches to increasing performance on downstream tasks. In this work, we
apply an effective LLM decomposition method using a dictionary-learning
approach with sparse autoencoders. This helps extract monosemantic features
from polysemantic LLM neurons. Remarkably, our work identifies model-internal
misunderstanding, allowing the automatic reformulation of the prompts with
additional annotations to improve the interpretation by LLMs. Moreover, this
approach demonstrates a significant performance improvement in downstream
tasks, such as mathematical reasoning and metaphor detection.

</details>


### [25] [Temporal Analysis of Climate Policy Discourse: Insights from Dynamic Embedded Topic Modeling](https://arxiv.org/abs/2507.06435)
*Rafiu Adekoya Badekale,Adewale Akinfaderin*

Main category: cs.CL

TL;DR: 本文利用动态嵌入主题模型（DETM）对近三十年全球气候政策话语进行了动态分析，发现政策主题经历了显著转变，所用方法高效且适合大规模政策文本分析，可为其他领域政策研究提供参考。


<details>
  <summary>Details</summary>
Motivation: 气候变化等复杂挑战要求评估政策话语随着时间的演变。传统手工编码方法耗时且难以揭示话语复杂联动，需借助机器学习方法高效、系统地刻画政策主题演变。

Method: 收集1995年至2023年（排除2020年）的联合国气候变化框架公约政策决策文本，应用DETM进行预处理、模型训练及对话语主题时间演变的可视化分析。

Result: 模型揭示了政策话语由早期关注温室气体、国际公约，逐步转向实施、技术协作、能力建设、金融支持和全球协议等新兴主题，突显政策关注点的动态转变。

Conclusion: 动态嵌入主题模型（DETM）是分析全球气候政策话语演变的可扩展且有效的方法，可帮助理解政策关注点的变化，对政策分析有现实意义。

Abstract: Understanding how policy language evolves over time is critical for assessing
global responses to complex challenges such as climate change. Temporal
analysis helps stakeholders, including policymakers and researchers, to
evaluate past priorities, identify emerging themes, design governance
strategies, and develop mitigation measures. Traditional approaches, such as
manual thematic coding, are time-consuming and limited in capturing the
complex, interconnected nature of global policy discourse. With the increasing
relevance of unsupervised machine learning, these limitations can be addressed,
particularly under high-volume, complex, and high-dimensional data conditions.
In this work, we explore a novel approach that applies the dynamic embedded
topic model (DETM) to analyze the evolution of global climate policy discourse.
A probabilistic model designed to capture the temporal dynamics of topics over
time. We collected a corpus of United Nations Framework Convention on Climate
Change (UNFCCC) policy decisions from 1995 to 2023, excluding 2020 due to the
postponement of COP26 as a result of the COVID-19 pandemic. The model reveals
shifts from early emphases on greenhouse gases and international conventions to
recent focuses on implementation, technical collaboration, capacity building,
finance, and global agreements. Section 3 presents the modeling pipeline,
including preprocessing, model training, and visualization of temporal word
distributions. Our results show that DETM is a scalable and effective tool for
analyzing the evolution of global policy discourse. Section 4 discusses the
implications of these findings and we concluded with future directions and
refinements to extend this approach to other policy domains.

</details>


### [26] [Perception-Aware Policy Optimization for Multimodal Reasoning](https://arxiv.org/abs/2507.06448)
*Zhenhailong Wang,Xuehang Guo,Sofia Stoica,Haiyang Xu,Hongru Wang,Hyeonjeong Ha,Xiusi Chen,Yangyi Chen,Ming Yan,Fei Huang,Heng Ji*

Main category: cs.CL

TL;DR: 针对多模态推理中视觉感知薄弱的问题，作者提出了PAPO方法，通过引入感知相关的损失项显著提升了模型在多模态任务中的表现。该方法无需额外数据或外部奖励，显著降低感知错误，并为视觉推理型强化学习提供基础。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习与可验证奖励（RLVR）主要针对文本任务优化，应用于多模态推理（涉及视觉感知）时效果不佳，主要瓶颈来自视觉输入的理解错误。

Method: 提出了一种感知感知的策略优化方法（Perception-Aware Policy Optimization, PAPO），在现有GRPO基础上，加入隐式感知损失（KL divergence项）以推动模型在推理时同步提升感知能力，无需额外数据标注或外部奖励模型；同时通过双熵损失缓解了损失投机问题。

Result: PAPO在多模态基准任务中整体提升4.4%，在高视觉依赖任务中提升近8.0%；感知错误率降低30.5%。

Conclusion: PAPO实现了感知-aware监督的强化学习目标整合，提高了大模型多模态推理的准确性，并为视觉感知推理式RL方法提供了新方向。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be a
highly effective strategy for endowing Large Language Models (LLMs) with robust
multi-step reasoning abilities. However, its design and optimizations remain
tailored to purely textual domains, resulting in suboptimal performance when
applied to multimodal reasoning tasks. In particular, we observe that a major
source of error in current multimodal reasoning lies in the perception of
visual inputs. To address this bottleneck, we propose Perception-Aware Policy
Optimization (PAPO), a simple yet effective extension of GRPO that encourages
the model to learn to perceive while learning to reason, entirely from internal
supervision signals. Notably, PAPO does not rely on additional data curation,
external reward models, or proprietary models. Specifically, we introduce the
Implicit Perception Loss in the form of a KL divergence term to the GRPO
objective, which, despite its simplicity, yields significant overall
improvements (4.4%) on diverse multimodal benchmarks. The improvements are more
pronounced, approaching 8.0%, on tasks with high vision dependency. We also
observe a substantial reduction (30.5%) in perception errors, indicating
improved perceptual capabilities with PAPO. We conduct comprehensive analysis
of PAPO and identify a unique loss hacking issue, which we rigorously analyze
and mitigate through a Double Entropy Loss. Overall, our work introduces a
deeper integration of perception-aware supervision into RLVR learning
objectives and lays the groundwork for a new RL framework that encourages
visually grounded reasoning. Project page: https://mikewangwzhl.github.io/PAPO.

</details>


### [27] [A Semantic Parsing Framework for End-to-End Time Normalization](https://arxiv.org/abs/2507.06450)
*Xin Su,Sungduk Yu,Phillip Howard,Steven Bethard*

Main category: cs.CL

TL;DR: 本文将时间规范化视为基于SCATE框架的代码生成任务，利用大语言模型生成及增强标注数据，训练出了性能强、可部署且超越LLM本身的小模型，实现了复杂时间表达的准确解析。


<details>
  <summary>Details</summary>
Motivation: 时间规范化对于信息检索、问答系统和临床决策支持等下游任务至关重要，但传统基于ISO-TimeML模式的系统表达能力有限，难以处理复杂的时间表达，如组合式、事件相关或多段时间表达。

Method: 提出将时间规范化建模为代码生成任务，基于SCATE框架的符号和组合算子实现时间语义，开发了可执行的SCATE Python库，并利用大语言模型（LLMs）生成可执行SCATE代码，建立LLM驱动的数据增强流程以大规模合成标注数据。

Result: 小规模、本地可部署的模型在增强数据集上训练后，取得了优异的性能，甚至超过了原始的LLM模型，实现了实用、精确且可解释的时间规范化。

Conclusion: 通过将时间规范化重构为代码生成任务，并结合LLM数据增强，不仅突破了传统方法的限制，还极大提升了系统的表现与可解释性。

Abstract: Time normalization is the task of converting natural language temporal
expressions into machine-readable representations. It underpins many downstream
applications in information retrieval, question answering, and clinical
decision-making. Traditional systems based on the ISO-TimeML schema limit
expressivity and struggle with complex constructs such as compositional,
event-relative, and multi-span time expressions. In this work, we introduce a
novel formulation of time normalization as a code generation task grounded in
the SCATE framework, which defines temporal semantics through symbolic and
compositional operators. We implement a fully executable SCATE Python library
and demonstrate that large language models (LLMs) can generate executable SCATE
code. Leveraging this capability, we develop an automatic data augmentation
pipeline using LLMs to synthesize large-scale annotated data with code-level
validation. Our experiments show that small, locally deployable models trained
on this augmented data can achieve strong performance, outperforming even their
LLM parents and enabling practical, accurate, and interpretable time
normalization.

</details>


### [28] [A Systematic Analysis of Hybrid Linear Attention](https://arxiv.org/abs/2507.06457)
*Dustin Wang,Rui-Jie Zhu,Steven Abreu,Yong Shan,Taylor Kergan,Yuqi Pan,Yuhong Chou,Zheng Li,Ge Zhang,Wenhao Huang,Jason Eshraghian*

Main category: cs.CL

TL;DR: 本文系统评测了多种线性注意力与全注意力混合架构，在语言建模和回忆任务中发现，合理的混合比（3:1到6:1）与有效机制可高效提升模型性能，并开源了所有研究模型。


<details>
  <summary>Details</summary>
Motivation: Transformer架构在处理长序列时面临计算复杂度高和内存占用大的问题，导致研究人员采用固定大小隐藏状态的线性注意力机制。但线性模型的回忆能力受限，因此出现了混合线性与全注意力的混合模型。尽管混合结构得到了大量研究，但对于线性注意力部分的具体选择尚缺乏系统性探索。

Method: 本文系统评估了不同代际的线性注意力模型（如向量递归到高级门控机制），分别在单独和混合结构下进行实验。共训练并开源了72个模型，在340M和1.3B参数规模下分别有36个，涵盖六种线性注意力变体和五种混合比例。所有模型均在标准语言建模和回忆任务上进行了基准测试。

Result: 结果显示，表现最好的纯线性模型在混合结构中并不一定效果最佳。随着全注意力层比例增加，回忆性能显著提升，特别是在3:1以下混合比时。语言建模任务在不同混合比下较为稳定。选择性门控、分层递归和可控遗忘机制对于提升混合模型性能至关重要。

Conclusion: 建议采用如HGRN-2或GatedDeltaNet等结构，在3:1至6:1的线性与全注意力层混合比下，能高效达到与传统Transformer相媲美的回忆能力。本文所有模型均已开源。

Abstract: Transformers face quadratic complexity and memory issues with long sequences,
prompting the adoption of linear attention mechanisms using fixed-size hidden
states. However, linear models often suffer from limited recall performance,
leading to hybrid architectures that combine linear and full attention layers.
Despite extensive hybrid architecture research, the choice of linear attention
component has not been deeply explored. We systematically evaluate various
linear attention models across generations - vector recurrences to advanced
gating mechanisms - both standalone and hybridized. To enable this
comprehensive analysis, we trained and open-sourced 72 models: 36 at 340M
parameters (20B tokens) and 36 at 1.3B parameters (100B tokens), covering six
linear attention variants across five hybridization ratios. Benchmarking on
standard language modeling and recall tasks reveals that superior standalone
linear models do not necessarily excel in hybrids. While language modeling
remains stable across linear-to-full attention ratios, recall significantly
improves with increased full attention layers, particularly below a 3:1 ratio.
Our study highlights selective gating, hierarchical recurrence, and controlled
forgetting as critical for effective hybrid models. We recommend architectures
such as HGRN-2 or GatedDeltaNet with a linear-to-full ratio between 3:1 and 6:1
to achieve Transformer-level recall efficiently. Our models are open-sourced at
https://huggingface.co/collections/m-a-p/hybrid-linear-attention-research-686c488a63d609d2f20e2b1e.

</details>


### [29] [On the Robustness of Verbal Confidence of LLMs in Adversarial Attacks](https://arxiv.org/abs/2507.06489)
*Stephen Obadinma,Xiaodan Zhu*

Main category: cs.CL

TL;DR: 首个系统性研究LLM置信度表达在对抗攻击下的鲁棒性。提出新攻击框架，证实现有置信度方法易被绕过且防御措施无效，急需更强健的置信度机制。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在高风险领域的人机交互中广泛应用，要求其生成的置信度表达必须透明、可信且安全。作者发现，当前模型在表达置信度方面面临安全和信任隐患。

Method: 提出了一套新的攻击框架，通过扰动和“越狱”攻击两种方式，系统地攻击LLM输出的置信度分数。研究涵盖了不同的提示策略、模型规模及应用场景，并评估了现有防御方法的有效性。

Result: 实验发现，这些攻击显著影响LLM的置信度估计，导致频繁更改答案。现有的置信度生成与防御手段既脆弱又低效，有时甚至适得其反，即便极细微但语义无损的文本修改都能导致输出置信度明显误导。

Conclusion: 当前LLM的置信度表达机制存在严重漏洞，现有防御方法难以应对新的攻击。亟需设计更健壮的置信度表达机制，确保AI在人机交互中的可靠性和安全性。

Abstract: Robust verbal confidence generated by large language models (LLMs) is crucial
for the deployment of LLMs to ensure transparency, trust, and safety in
human-AI interactions across many high-stakes applications. In this paper, we
present the first comprehensive study on the robustness of verbal confidence
under adversarial attacks. We introduce a novel framework for attacking verbal
confidence scores through both perturbation and jailbreak-based methods, and
show that these attacks can significantly jeopardize verbal confidence
estimates and lead to frequent answer changes. We examine a variety of
prompting strategies, model sizes, and application domains, revealing that
current confidence elicitation methods are vulnerable and that commonly used
defence techniques are largely ineffective or counterproductive. Our findings
underscore the urgent need to design more robust mechanisms for confidence
expression in LLMs, as even subtle semantic-preserving modifications can lead
to misleading confidence in responses.

</details>


### [30] [Pun Intended: Multi-Agent Translation of Wordplay with Contrastive Learning and Phonetic-Semantic Embeddings](https://arxiv.org/abs/2507.06506)
*Russell Taylor,Benjamin Herbert,Michael Sana*

Main category: cs.CL

TL;DR: 本研究提出创新方法，结合大语言模型、语音语义嵌入及多智能体框架，实现高质量英法双关语翻译，并在国际竞赛中获佳绩，推动计算机自动幽默翻译的新进展。


<details>
  <summary>Details</summary>
Motivation: 跨语言的文字游戏翻译一直是专业人工翻译与机器翻译系统的难题，因为需要兼顾语言的创造性和幽默感，而不能仅仅作字面翻译。该研究致力于解决该领域长期存在的挑战。

Method: 提出了一套创新的三阶段方法：1）基于多种前沿大语言模型建立基线，并用新构建的对比学习数据集改进反馈；2）结合语音与语义嵌入，实现引导式思维链翻译管道；3）通过多智能体生成-判别框架对双关语进行自动评估和反馈再生。

Result: 所提出方法在CLEF JOKER 2025 Task 2竞赛中表现突出，获得了第一和第二名，参赛结果由法语母语专家人工评测。系统能够超越单纯字面翻译，更好地保留源文本的幽默和创造性。

Conclusion: 研究弥补了翻译学与计算语言学之间在双关语处理技术上的空白，验证了结合大语言模型与语言学启发技术能有效处理涉及语义歧义、语音相似性和文化语境的复杂幽默翻译任务，推动了自动化创意翻译能力的发展。

Abstract: Translating wordplay across languages presents unique challenges that have
long confounded both professional human translators and machine translation
systems. This research proposes a novel approach for translating puns from
English to French by combining state-of-the-art large language models with
specialized techniques for wordplay generation.
  Our methodology employs a three-stage approach. First, we establish a
baseline using multiple frontier large language models with feedback based on a
new contrastive learning dataset. Second, we implement a guided
chain-of-thought pipeline with combined phonetic-semantic embeddings. Third, we
implement a multi-agent generator-discriminator framework for evaluating and
regenerating puns with feedback.
  Moving beyond the limitations of literal translation, our methodology's
primary objective is to capture the linguistic creativity and humor of the
source text wordplay, rather than simply duplicating its vocabulary. Our best
runs earned first and second place in the CLEF JOKER 2025 Task 2 competition
where they were evaluated manually by expert native French speakers.
  This research addresses a gap between translation studies and computational
linguistics by implementing linguistically-informed techniques for wordplay
translation, advancing our understanding of how language models can be
leveraged to handle the complex interplay between semantic ambiguity, phonetic
similarity, and the implicit cultural and linguistic awareness needed for
successful humor.

</details>


### [31] [SpindleKV: A Novel KV Cache Reduction Method Balancing Both Shallow and Deep Layers](https://arxiv.org/abs/2507.06517)
*Zicong Tang,Shi Luohe,Zuchao Li,Baoyuan Qi,Guoming Liu,Lefei Zhang,Ping Wang*

Main category: cs.CL

TL;DR: KV缓存的内存消耗是阻碍LLMs高效推理的关键难题。本文提出了SpindleKV，通过不同层次采用结合注意力和码本的机制，显著减少内存占用，并在实验中表现优异且不损失性能。


<details>
  <summary>Details</summary>
Motivation: 近年来大语言模型（LLMs）的快速发展导致推理系统中KV缓存的内存消耗显著增加，给系统带来了巨大的挑战。而传统的KV缓存淘汰方法主要着重于深层，但对浅层的优化仍然不足。

Method: 提出了一种新的KV缓存压缩方法SpindleKV。该方法在深层采用基于注意力权重的淘汰机制，而在浅层则采用基于相似度学习和聚合策略得到的码本替换机制。同时，SpindleKV还解决了传统注意力淘汰方法在Grouped-Query Attention（GQA）上的难题。

Result: 在两个常用基准集和三种不同LLMs上的实验证明，SpindleKV在缓存压缩上优于现有方法，并能保持甚至部分提升模型性能。

Conclusion: SpindleKV作为一种KV缓存的高效压缩方法，可以兼顾浅层和深层的冗余问题，提高大语言模型的推理效率，同时保障模型性能。

Abstract: Large Language Models (LLMs) have achieved impressive accomplishments in
recent years. However, the increasing memory consumption of KV cache has
possessed a significant challenge to the inference system. Eviction methods
have revealed the inherent redundancy within the KV cache, demonstrating its
potential for reduction, particularly in deeper layers. However, KV cache
reduction for shallower layers has been found to be insufficient. Based on our
observation that, the KV cache exhibits a high degree of similarity. Based on
this observation, we proposed a novel KV cache reduction method, SpindleKV,
which balances both shallow and deep layers. For deep layers, we employ an
attention weight based eviction method, while for shallow layers, we apply a
codebook based replacement approach which is learnt by similarity and merging
policy. Moreover, SpindleKV addressed the Grouped-Query Attention (GQA) dilemma
faced by other attention based eviction methods. Experiments on two common
benchmarks with three different LLMs shown that SpindleKV obtained better KV
cache reduction effect compared to baseline methods, while preserving similar
or even better model performance.

</details>


### [32] [InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes under Herd Behavior](https://arxiv.org/abs/2507.06528)
*Huisheng Wang,Zhuoshi Pan,Hangjing Zhang,Mingxiao Liu,Hanqing Gao,H. Vicky Zhao*

Main category: cs.CL

TL;DR: 作者提出InvestAlign框架，用理论投资问题解生成高质量训练数据，用于监督微调LLM，解决真实用户数据稀缺和隐私问题。实验证明该方法能更有效地让模型学会模仿真实投资者的决策。


<details>
  <summary>Details</summary>
Motivation: 在行为金融学中，如何让大型语言模型（LLM）模拟投资者群体性决策过程是一项重大挑战。主要障碍是获取用于监督微调（SFT）的真实用户数据困难，既昂贵又涉及隐私风险。

Method: 作者提出了InvestAlign框架，通过利用理论解（而非复杂场景中的真实数据）生成高质量SFT训练数据。据此微调LLM，并开发了InvestAgent代理，评估其在投资决策任务上的表现。

Result: 理论分析显示，用InvestAlign生成的数据训练LLM时，参数收敛速度快于使用真实用户数据，学习效率更高。实验结果证实，微调后的InvestAgent在不同场景下都比未微调模型更接近真实用户行为。

Conclusion: InvestAlign利用理论问题解代替真实数据，有效对齐LLM于投资者决策过程，减少了数据收集成本及隐私风险，为LLM在复杂投资行为建模中提供了新方法。代码已开源。

Abstract: Aligning Large Language Models (LLMs) with investor decision-making processes
under herd behavior is a critical challenge in behavioral finance, which
grapples with a fundamental limitation: the scarcity of real-user data needed
for Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM
outputs and human behavioral patterns, its reliance on massive authentic data
imposes substantial collection costs and privacy risks. We propose InvestAlign,
a novel framework that constructs high-quality SFT datasets by leveraging
theoretical solutions to similar and simple optimal investment problems rather
than complex scenarios. Our theoretical analysis demonstrates that training
LLMs with InvestAlign-generated data achieves faster parameter convergence than
using real-user data, suggesting superior learning efficiency. Furthermore, we
develop InvestAgent, an LLM agent fine-tuned with InvestAlign, which
demonstrates significantly closer alignment to real-user data than pre-SFT
models in both simple and complex investment problems. This highlights our
proposed InvestAlign as a promising approach with the potential to address
complex optimal investment problems and align LLMs with investor
decision-making processes under herd behavior. Our code is publicly available
at https://github.com/thu-social-network-research-group/InvestAlign.

</details>


### [33] [Large Language Model for Extracting Complex Contract Information in Industrial Scenes](https://arxiv.org/abs/2507.06539)
*Yunyang Cao,Yanjun Li,Silong Dai*

Main category: cs.CL

TL;DR: 利用聚类与大模型自动标注，高质量扩充工业合同数据，通过微调与多种增强手段显著提升抽取准确性与效率，提出的新方法为工业合同信息抽取提供有效解决方案。


<details>
  <summary>Details</summary>
Motivation: 工业场景的合同信息抽取任务复杂，现有方法难以获得高质量数据集与提升模型的准确性与鲁棒性，亟需高效的解决方案。

Method: 首先对合同文本进行聚类分析，利用GPT-4和GPT-3.5自动抽取关键信息，标注高质量数据；然后通过关键词随机组合及GPT-3.5生成新型合同文本，扩充和增强数据集；最后采用微调大语言模型（并结合LoRA、数据均衡和增强手段）以提升模型性能。

Result: 微调后的大语言模型在合同信息抽取任务中整体表现优异，在字段召回率和精度方面均达到较高水平，同时解析效率良好。增强技术有效提升了模型的准确性与鲁棒性。

Conclusion: 本文方法为工业合同信息抽取提供了一套高效可靠的新型流程，实验结果验证了其在实际应用中的优越性和可行性。

Abstract: This paper proposes a high-quality dataset construction method for complex
contract information extraction tasks in industrial scenarios and fine-tunes a
large language model based on this dataset. Firstly, cluster analysis is
performed on industrial contract texts, and GPT-4 and GPT-3.5 are used to
extract key information from the original contract data, obtaining high-quality
data annotations. Secondly, data augmentation is achieved by constructing new
texts, and GPT-3.5 generates unstructured contract texts from randomly combined
keywords, improving model robustness. Finally, the large language model is
fine-tuned based on the high-quality dataset. Experimental results show that
the model achieves excellent overall performance while ensuring high field
recall and precision and considering parsing efficiency. LoRA, data balancing,
and data augmentation effectively enhance model accuracy and robustness. The
proposed method provides a novel and efficient solution for industrial contract
information extraction tasks.

</details>


### [34] [The Flaws of Others: An LLM-driven Framework for Scientific Knowledge Production](https://arxiv.org/abs/2507.06565)
*Juan B. Gutiérrez*

Main category: cs.CL

TL;DR: 本文提出将大语言模型和人类用户视为话语网络平等节点，揭示了“漂移、自我修正、新造假、外部检测”四类失真机制及其动态，开发FOO算法实现同行评议。结果表明，通过代理互评和结果合并可大幅降低系统错误率，提升信息可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在人机互动中的角色日益重要，但模型存在事实错误、逻辑失误等问题。现有研究侧重于孤立的“幻觉”现象，缺乏对整个交流网络失真机制的系统考察，因此作者提出以人大和LLM为节点的网络模型，以更全面地解释和应对信息失真的产生与传播。

Method: 作者提出了一种话语网络模型，将人和LLM作为平等节点，追踪其发言的流转。建立了广义的数学模型，探讨了“漂移-自我修正-新造假-外部检测”四类失真机制，并开发了开放源代码算法Flaws-of-Others (FOO)，允许系统中各代理互相批判，最终通过合并机制得到系统判断。

Result: 研究发现仅有“漂移”和“自我修正”机制时，网络错误率较低且可稳定。而一旦引入“新造假”，系统整体错误率急剧上升，接近当前LLM水平。只要允许每个错误言论有小概率获得同伴评议，整体系统会转向以真实为主的状态。

Conclusion: 研究结论是：提升新型人机写作沟通的可靠性，关键不在于单模型精度，而是将多个不完美代理组成互相监督的网络，从而集体保证信息可信度。

Abstract: Large-language models turn writing into a live exchange between humans and
software. We capture this new medium with a discursive-network model that
treats people and LLMs as equal nodes and tracks how their statements
circulate. Broadening the focus from isolated hallucinations, we define
invalidation (any factual, logical, or structural breach) and show it follows
four hazards: drift from truth, self-repair, fresh fabrication, and external
detection. A general mathematical model of discursive networks is developed to
provide valuable insights: A network governed only by drift and self-repair
stabilizes at a modest error rate; adding fabrication reproduces the high rates
seen in current LLMs. Giving each false claim even a small chance of peer
review shifts the system to a truth-dominant state. We operationalize peer
review with the open-source \emph{Flaws-of-Others (FOO) algorithm}: a
configurable loop in which any set of agents critique one another while a
harmoniser merges their verdicts. The takeaway is practical and cultural:
reliability in this new medium comes not from perfecting single models but from
wiring imperfect ones into networks that keep each other honest.

</details>


### [35] [Enhancing Food-Domain Question Answering with a Multimodal Knowledge Graph: Hybrid QA Generation and Diversity Analysis](https://arxiv.org/abs/2507.06571)
*Srihari K B,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 将多模态知识图谱与生成式AI结合，显著提升了食品问答系统的准确性、多样性和生成质量，尤其在图像和文本一致性方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的食品问答系统缺乏多模态知识和生成能力，难以提供可靠、多样和高质量的答案，因此需要一个结合结构化知识图谱与生成式AI的新型问答框架。

Method: 本文提出了一个统一的食品领域问答（QA）框架，将大规模多模态知识图谱（MMKG）与生成式AI结合。该MMKG包含了13000个食谱、3000种配料、14万个关系和14000幅图像。利用40种模板和LLaVA/DeepSeek数据增强生成了4万个QA对，并对Meta LLaMA 3.1-8B和Stable Diffusion 3.5-Large进行了联合微调。同时通过CLIP和LLaVA进行失配检测和幻觉校验，确保事实和视觉的准确性。

Result: 在BERTScore提升了16.2%，FID降低了37.8%，CLIP一致性提升了31.1%。CLIP失配检测从35.2%降至7.3%，图生成正确图像重用率94.1%，合成充分性85%。

Conclusion: 结构化知识融合多模态生成技术，能有效提升食品领域问答的可靠性与多样性。

Abstract: We propose a unified food-domain QA framework that combines a large-scale
multimodal knowledge graph (MMKG) with generative AI. Our MMKG links 13,000
recipes, 3,000 ingredients, 140,000 relations, and 14,000 images. We generate
40,000 QA pairs using 40 templates and LLaVA/DeepSeek augmentation. Joint
fine-tuning of Meta LLaMA 3.1-8B and Stable Diffusion 3.5-Large improves
BERTScore by 16.2\%, reduces FID by 37.8\%, and boosts CLIP alignment by
31.1\%. Diagnostic analyses-CLIP-based mismatch detection (35.2\% to 7.3\%) and
LLaVA-driven hallucination checks-ensure factual and visual fidelity. A hybrid
retrieval-generation strategy achieves 94.1\% accurate image reuse and 85\%
adequacy in synthesis. Our results demonstrate that structured knowledge and
multimodal generation together enhance reliability and diversity in food QA.

</details>


### [36] [Decoder-Hybrid-Decoder Architecture for Efficient Reasoning with Long Generation](https://arxiv.org/abs/2507.06607)
*Liliang Ren,Congcong Chen,Haoran Xu,Young Jin Kim,Adam Atkinson,Zheng Zhan,Jiankai Sun,Baolin Peng,Liyuan Liu,Shuohang Wang,Hao Cheng,Jianfeng Gao,Weizhu Chen,Yelong Shen*

Main category: cs.CL

TL;DR: 本文提出利用门控记忆单元（GMU）进行高效跨层内存共享的新架构SambaY，在提升长文本处理能力和推理效率的同时，超越此前主流模型YOCO，相关成果和代码已开源。


<details>
  <summary>Details</summary>
Motivation: 近年来，基于状态空间模型（SSMs）的高效序列建模方法表现突出，但对于在SSM层之间进行表示共享的效率潜力尚未被探索。

Method: 提出了一种新的门控记忆单元（GMU）机制，实现跨层的高效内存共享，并将其应用于新颖的SambaY结构（decoder-hybrid-decoder架构），在cross-decoder中集成GMU以共享Samba型self-decoder的内存读出状态。

Result: SambaY显著提升了解码效率，保持线性预填充时空复杂度，并增强了长上下文性能，无需显式位置编码。通过大规模实验，SambaY在不可约损失上显著优于YOCO基线模型，展示了更优的扩展性能。基于差分注意力机制的最大模型Phi4-mini-Flash-Reasoning在数学和推理任务中明显优于Phi4-mini-Reasoning，且在长输入情况下推理速度最高提升10倍。

Conclusion: 引入GMU机制的新型解码架构SambaY在效率和性能上均优于现有方法，特别适用大规模、高需求的语言建模任务，并已开源代码和数据。

Abstract: Recent advances in language modeling have demonstrated the effectiveness of
State Space Models (SSMs) for efficient sequence modeling. While hybrid
architectures such as Samba and the decoder-decoder architecture, YOCO, have
shown promising performance gains over Transformers, prior works have not
investigated the efficiency potential of representation sharing between SSM
layers. In this paper, we introduce the Gated Memory Unit (GMU), a simple yet
effective mechanism for efficient memory sharing across layers. We apply it to
create SambaY, a decoder-hybrid-decoder architecture that incorporates GMUs in
the cross-decoder to share memory readout states from a Samba-based
self-decoder. SambaY significantly enhances decoding efficiency, preserves
linear pre-filling time complexity, and boosts long-context performance, all
while eliminating the need for explicit positional encoding. Through extensive
scaling experiments, we demonstrate that our model exhibits a significantly
lower irreducible loss compared to a strong YOCO baseline, indicating superior
performance scalability under large-scale compute regimes. Our largest model
enhanced with Differential Attention, Phi4-mini-Flash-Reasoning, achieves
significantly better performance than Phi4-mini-Reasoning on reasoning tasks
such as Math500, AIME24/25, and GPQA Diamond without any reinforcement
learning, while delivering up to 10x higher decoding throughput on 2K-length
prompts with 32K generation length under the vLLM inference framework. We
release our training codebase on open-source data at
https://github.com/microsoft/ArchScale.

</details>


### [37] [FuDoBa: Fusing Document and Knowledge Graph-based Representations with Bayesian Optimisation](https://arxiv.org/abs/2507.06622)
*Boshko Koloski,Senja Pollak,Roberto Navigli,Blaž Škrlj*

Main category: cs.CL

TL;DR: 以贝叶斯优化为基础融合大语言模型嵌入和领域知识的FuDoBa方法，能生成低维、高效且对特定任务更有用的文档表示，并提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLM）虽然在文档嵌入领域表现出色，但其高维度且计算开销大的嵌入在特定领域应用中容易过于泛化且效率低下。该论文旨在解决LLM文档表示的维度高、解释性差以及领域适应性不足等问题。

Method: 提出FuDoBa方法，通过贝叶斯优化，将LLM嵌入与来自本地及外部知识库（如WikiData）的领域结构化知识融合，生成低维且领域相关的文档表示，并显著简化训练过程，同时产出具可解释性的融合权重。

Result: 在两个领域、六个数据集上实验，结果显示与专有LLM嵌入相比，FuDoBa结合强大AutoML分类器可获得相当或更优的表现。

Conclusion: FuDoBa能够有效融合LLM嵌入与领域知识，提升文档表示质量，兼具低维、可解释性和高分类性能。

Abstract: Building on the success of Large Language Models (LLMs), LLM-based
representations have dominated the document representation landscape, achieving
great performance on the document embedding benchmarks. However, the
high-dimensional, computationally expensive embeddings from LLMs tend to be
either too generic or inefficient for domain-specific applications. To address
these limitations, we introduce FuDoBa a Bayesian optimisation-based method
that integrates LLM-based embeddings with domain-specific structured knowledge,
sourced both locally and from external repositories like WikiData. This fusion
produces low-dimensional, task-relevant representations while reducing training
complexity and yielding interpretable early-fusion weights for enhanced
classification performance. We demonstrate the effectiveness of our approach on
six datasets in two domains, showing that when paired with robust AutoML-based
classifiers, our proposed representation learning approach performs on par
with, or surpasses, those produced solely by the proprietary LLM-based
embedding baselines.

</details>


### [38] [Expediting data extraction using a large language model (LLM) and scoping review protocol: a methodological study within a complex scoping review](https://arxiv.org/abs/2507.06623)
*James Stewart-Evans,Emma Wilson,Tessa Langley,Andrew Prayle,Angela Hands,Karen Exley,Jo Leonardi-Bee*

Main category: cs.CL

TL;DR: 本文评估了Claude 3.5 Sonnet在综述协议下提速数据提取的可行性。正则数据提取准确率高，对复杂主观内容和错误数据检出有限，整体召回率偏低。建议LLM数据提取需严谨评估，LLM反馈能促进协议优化。


<details>
  <summary>Details</summary>
Motivation: 数据提取是综述工作中的资源密集环节，研究者希望利用在线大模型（LLM）和综述协议来加速数据提取过程。本文关注如何验证LLM辅助下，基于综述协议的数据提取策略在实际案例研究中的表现。

Method: 采用Claude 3.5 Sonnet大模型，设计两种基于综述协议的提示，对10个证据源进行数据提取。所有提取数据均结合协议进行复核。同时对简单与复杂数据提取效果进行有限度性能评估，包含准确率、精确率、召回率和F1分数等指标，以真实和带故意错误的数据集分别进行测试。

Result: 对简单明确定义的引用信息提取准确率较高（83.3%、100%），但复杂主观信息准确率明显下降（9.6%、15.8%）。两种方法整体精确率均>90%，召回率均<25%，F1分数<40%。在带误差的数据集上，错误检出率非常低（5%）。LLM反馈对协议的修订有一定促进作用。

Conclusion: 基于综述协议快速数据提取虽然效率提升但仍面临准确性和召回率较差问题，特别是在处理复杂或开放型响应时表现有限。建议研究者在使用LLM进行数据提取时务必评估并详尽报告其性能，未来需更系统地在不同LLM和综述场景下验证其效益，相比传统提示工程方法仍需谨慎。

Abstract: The data extraction stages of reviews are resource-intensive, and researchers
may seek to expediate data extraction using online (large language models) LLMs
and review protocols. Claude 3.5 Sonnet was used to trial two approaches that
used a review protocol to prompt data extraction from 10 evidence sources
included in a case study scoping review. A protocol-based approach was also
used to review extracted data. Limited performance evaluation was undertaken
which found high accuracy for the two extraction approaches (83.3% and 100%)
when extracting simple, well-defined citation details; accuracy was lower (9.6%
and 15.8%) when extracting more complex, subjective data items. Considering all
data items, both approaches had precision >90% but low recall (<25%) and F1
scores (<40%). The context of a complex scoping review, open response types and
methodological approach likely impacted performance due to missed and
misattributed data. LLM feedback considered the baseline extraction accurate
and suggested minor amendments: four of 15 (26.7%) to citation details and 8 of
38 (21.1%) to key findings data items were considered to potentially add value.
However, when repeating the process with a dataset featuring deliberate errors,
only 2 of 39 (5%) errors were detected. Review-protocol-based methods used for
expediency require more robust performance evaluation across a range of LLMs
and review contexts with comparison to conventional prompt engineering
approaches. We recommend researchers evaluate and report LLM performance if
using them similarly to conduct data extraction or review extracted data. LLM
feedback contributed to protocol adaptation and may assist future review
protocol drafting.

</details>


### [39] [Elite Polarization in European Parliamentary Speeches: a Novel Measurement Approach Using Large Language Models](https://arxiv.org/abs/2507.06658)
*Gennadii Iakovlev*

Main category: cs.CL

TL;DR: 本研究通过AI方法量化分析议会发言者之间的互动和情绪，提出了新的精英极化（互相敌意）指数，并用英国、匈牙利、意大利数据验证其对重大事件敏感且具有效度。


<details>
  <summary>Details</summary>
Motivation: 现有的精英极化测量方法存在局限，本研究旨在用人工智能技术更精确地捕捉政治人物在议会发言中的互动与情绪，从而量化精英间的敌意。

Method: 运用人工智能技术检测议会演讲中的“行为者”和“主题”，辨别发言者及其针对的人物，并分析发言情绪。结合这些信息，构建精英间相互敌意（极化）指数，并收集英国过去40年、匈牙利和意大利过去20年的极化数据。

Result: 得出的极化指数可以按政党和季度聚合，且具有较好效度（对选举、危机、政党更替等事件有明显反应）。为欧盟未来20年级别的极化动态研究奠定数据基础。

Conclusion: 人工智能驱动的互动和情感分析可大幅提升精英极化的度量，所得指数动态与实际政治事件高度吻合，具有重要的学术和应用价值。

Abstract: This project introduces a new measure of elite polarization via actor and
subject detection using artificial intelligence. I identify when politicians
mention one another in parliamentary speeches, note who is speaking and who is
being addressed, and assess the emotional temperature behind these evaluations.
This maps how elites evaluate their various out-parties, allowing us to create
an index of mutual out-party hostility, that is, elite polarization. While I
analyzed polarization data over the past four decades for the UK, and two
decades for Hungary and Italy, my approach lays the groundwork for a
twenty-year, EU-wide time-series dataset on elite polarization. I obtain the
results that can be aggregated by party and quarter. The resulting index
demonstrates a good face validity: it reacts to events such as electoral
campaigns, country- and party-level crises, and to parties losing and assuming
power.

</details>


### [40] [CLI-RAG: A Retrieval-Augmented Framework for Clinically Structured and Context Aware Text Generation with LLMs](https://arxiv.org/abs/2507.06715)
*Garapati Keerthana,Manik Gupta*

Main category: cs.CL

TL;DR: 本文提出针对临床文本生成的CLI-RAG框架，通过分层块切分和双阶段检索，显著提升了结构化笔记生成的准确性和一致性，为大模型在临床实践应用提供了新方案。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在临床文本生成方面表现出色，但实际应用中面临两个主要挑战：患者数据高度非结构化且分散，且临床笔记长且语义密集，导致上下文长度限制和关键信息遗漏。

Method: 提出CLI-RAG（Clinically Informed Retrieval-Augmented Generation），一个结合领域知识的文本生成框架。该框架采用新的分层块切分策略，尊重临床文档结构，并引入任务特定的双阶段检索机制：全局阶段用于识别相关笔记类型，局部阶段则在笔记内抽取有价值内容，确保文档和章节层面都具相关性。

Result: 基于MIMIC-III数据集的15类临床笔记，CLI-RAG能生成结构化的患者住院进展笔记。实验表明，模型生成内容在住院期间的时序和语义一致性明显高于基线（87.7% vs 80.7%），且跨模型输出具有高度一致性。

Conclusion: CLI-RAG框架不仅提升了临床文本生成的结构性和一致性，也具备较强的可重现性和可靠性，对实际临床应用具有重要意义。

Abstract: Large language models (LLMs), including zero-shot and few-shot paradigms,
have shown promising capabilities in clinical text generation. However,
real-world applications face two key challenges: (1) patient data is highly
unstructured, heterogeneous, and scattered across multiple note types and (2)
clinical notes are often long and semantically dense, making naive prompting
infeasible due to context length constraints and the risk of omitting
clinically relevant information.
  We introduce CLI-RAG (Clinically Informed Retrieval-Augmented Generation), a
domain-specific framework for structured and clinically grounded text
generation using LLMs. It incorporates a novel hierarchical chunking strategy
that respects clinical document structure and introduces a task-specific
dual-stage retrieval mechanism. The global stage identifies relevant note types
using evidence-based queries, while the local stage extracts high-value content
within those notes creating relevance at both document and section levels.
  We apply the system to generate structured progress notes for individual
hospital visits using 15 clinical note types from the MIMIC-III dataset.
Experiments show that it preserves temporal and semantic alignment across
visits, achieving an average alignment score of 87.7%, surpassing the 80.7%
baseline from real clinician-authored notes. The generated outputs also
demonstrate high consistency across LLMs, reinforcing deterministic behavior
essential for reproducibility, reliability, and clinical trust.

</details>


### [41] [On the Effect of Uncertainty on Layer-wise Inference Dynamics](https://arxiv.org/abs/2507.06722)
*Sunwoo Kim,Haneul Yoo,Alice Oh*

Main category: cs.CL

TL;DR: 层级概率动态显示LLM推理阶段不确定性表征方式一致，简单判别不确定性不可行，解释方法可用于进一步分析。


<details>
  <summary>Details</summary>
Motivation: 理解大语言模型（LLMs）内部如何表征和处理不确定性对于检测模型不确定性和防止幻觉非常关键。虽然已有研究显示模型的不确定性信息被编码在隐藏状态中，但这些不确定性是如何影响模型在推理过程中对隐藏状态的处理尚未被深入探讨。

Method: 使用Tuned Lens（一种Logit Lens的变体）分析最终预测token在各层的概率轨迹，横跨11个数据集和5个不同模型，对正确（确信）和错误（高度不确定）预测的层级概率进行轨迹比对分析。

Result: 发现无论是确定预测还是不确定预测，其输出token概率在各层的动态变化高度一致，显示不确定性几乎不影响模型的推理动态。确信和不确定预测在接近的层都会出现信心的突增。此外，更强大的模型可能学会以不同方式处理不确定性。

Conclusion: 简单地依赖推理阶段的概率轨迹用于检测不确定性不可行；模型对不确定和确定预测的处理方式在大部分情况下类似。解释性方法有助于进一步理解LLM处理不确定性的机制。

Abstract: Understanding how large language models (LLMs) internally represent and
process their predictions is central to detecting uncertainty and preventing
hallucinations. While several studies have shown that models encode uncertainty
in their hidden states, it is underexplored how this affects the way they
process such hidden states. In this work, we demonstrate that the dynamics of
output token probabilities across layers for certain and uncertain outputs are
largely aligned, revealing that uncertainty does not seem to affect inference
dynamics. Specifically, we use the Tuned Lens, a variant of the Logit Lens, to
analyze the layer-wise probability trajectories of final prediction tokens
across 11 datasets and 5 models. Using incorrect predictions as those with
higher epistemic uncertainty, our results show aligned trajectories for certain
and uncertain predictions that both observe abrupt increases in confidence at
similar layers. We balance this finding by showing evidence that more competent
models may learn to process uncertainty differently. Our findings challenge the
feasibility of leveraging simplistic methods for detecting uncertainty at
inference. More broadly, our work demonstrates how interpretability methods may
be used to investigate the way uncertainty affects inference.

</details>


### [42] [KAConvText: Novel Approach to Burmese Sentence Classification using Kolmogorov-Arnold Convolution](https://arxiv.org/abs/2507.06753)
*Ye Kyaw Thu,Thura Aung,Thazin Myint Oo,Thepchai Supnithi*

Main category: cs.CL

TL;DR: 首次提出并验证KAConvText在文本分类的有效性，通过多embedding和分类头对比，实验结果体现其在多个任务上性能优越且可解释性强。


<details>
  <summary>Details</summary>
Motivation: 目前文本分类任务中常用的卷积神经网络（CNN）存在对复杂特征表达有限的问题。此外，存在类别不平衡和多标签的实际挑战。Kolmogorov-Arnold Convolution（KAConv）引入到文本领域（KAConvText），旨在提升模型对结构多样文本的表达能力和解释性。

Method: 本文首次将KAConvText模型应用于句子分类任务，覆盖三种场景：1）不平衡二分类仇恨言论检测，2）平衡多分类新闻分类，3）不平衡多分类民族语言识别。详尽比较了不同embedding方案，包括随机初始化和fastText的静态/微调（fine-tuned）版本，embedding维度分别为100和300（CBOW/Skip-gram）。基线设置为常规CNN和结合Kolmogorov-Arnold Network（KAN）的CNN-KAN，还对不同分类头（MLP和KAN）进行实验，其中KAN提升模型可解释性。

Result: KAConvText-MLP与微调后的fastText embedding结合，在各任务中均取得最优效果：仇恨言论检测准确率91.23%（F1 = 0.9109），新闻分类准确率92.66%（F1 = 0.9267），语言识别准确率99.82%（F1 = 0.9982）。

Conclusion: KAConvText模型在三类文本分类任务中普适高效，特别是在embedding和分类头合理选择下，能显著提升性能，并兼具可解释性，为文本分类任务提供了新的有效建模方式。

Abstract: This paper presents the first application of Kolmogorov-Arnold Convolution
for Text (KAConvText) in sentence classification, addressing three tasks:
imbalanced binary hate speech detection, balanced multiclass news
classification, and imbalanced multiclass ethnic language identification. We
investigate various embedding configurations, comparing random to fastText
embeddings in both static and fine-tuned settings, with embedding dimensions of
100 and 300 using CBOW and Skip-gram models. Baselines include standard CNNs
and CNNs augmented with a Kolmogorov-Arnold Network (CNN-KAN). In addition, we
investigated KAConvText with different classification heads - MLP and KAN,
where using KAN head supports enhanced interpretability. Results show that
KAConvText-MLP with fine-tuned fastText embeddings achieves the best
performance of 91.23% accuracy (F1-score = 0.9109) for hate speech detection,
92.66% accuracy (F1-score = 0.9267) for news classification, and 99.82%
accuracy (F1-score = 0.9982) for language identification.

</details>


### [43] [Checklist Engineering Empowers Multilingual LLM Judges](https://arxiv.org/abs/2507.06774)
*Mohammad Ghiasvand Mohammadkhani,Hamid Beigy*

Main category: cs.CL

TL;DR: 本文提出了一种基于checklist的多语言大模型自动评估方法，无需训练即可用开源模型实现，效果优于传统方法，媲美GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 自动化文本评价一直是自然语言处理领域的核心问题，近期逐渐转向使用大语言模型作为自动评估者（即LLM-as-a-Judge），但在多语言环境中的探索较少，尤其现有方法多依赖闭源模型或需大量训练数据，存在成本与效率问题。

Method: 提出了一种基于Checklist Engineering的训练无关（training-free）LLM-as-a-Judge方法（CE-Judge），利用开源模型，结合checklist直觉，实现多语言文本的自动化评估。

Result: 在多个语言和三大基准数据集下，不论是点对点还是对对比较，所提方法CE-Judge整体优于主流基线，与GPT-4o模型表现持平。

Conclusion: CE-Judge是一种无需训练、基于开源模型且适用于多语言自动化文本评价的新方法，可高效且低成本地实现跨语言评估，在多项基准任务中效果优异。

Abstract: Automated text evaluation has long been a central issue in Natural Language
Processing (NLP). Recently, the field has shifted toward using Large Language
Models (LLMs) as evaluators-a trend known as the LLM-as-a-Judge paradigm. While
promising and easily adaptable across tasks, this approach has seen limited
exploration in multilingual contexts. Existing multilingual studies often rely
on proprietary models or require extensive training data for fine-tuning,
raising concerns about cost, time, and efficiency. In this paper, we propose
Checklist Engineering based LLM-as-a-Judge (CE-Judge), a training-free
framework that uses checklist intuition for multilingual evaluation with an
open-source model. Experiments across multiple languages and three benchmark
datasets, under both pointwise and pairwise settings, show that our method
generally surpasses the baselines and performs on par with the GPT-4o model.

</details>


### [44] [Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining: Method, Evaluation and Applications](https://arxiv.org/abs/2507.06795)
*Seonwu Kim,Yohan Na,Kihun Kim,Hanhee Cho,Geun Lim,Mintae Kim,Seongik Park,Ki Hyun Kim,Youngsub Han,Byoung-Ki Jeon*

Main category: cs.CL

TL;DR: 为解决企业缺乏大模型基础设施的问题，作者将DACP方法应用于小型模型，通过实验验证其在多个领域取得了显著效果，既提升了专业领域表现，又保持了广泛能力，是成本效益高的企业级解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着开源大型语言模型（LLMs）的出现，企业应用机会增多，但受限于部署和维护大模型的基础设施，很多机构难以采用。成本和资源压力促使小型语言模型（sLLMs）成为实际选择，但性能有限。此外，基于领域自适应持续预训练（DACP）的方法虽然在学术上有研究，但其在商业领域的应用价值仍待探讨。

Method: 作者采用DACP（领域自适应持续预训练）方法，对多种基础模型和不同服务领域进行实验，评估sLLMs在实际商业环境下应用DACP后的效果，并通过大量实验和实际评估进行验证。

Result: 应用DACP的sLLMs在目标领域显著提升了性能，同时保留了通用能力，展示出成本效益高、易于扩展的特点，适合企业级别的部署需求。

Conclusion: DACP为企业在有限资源下实现领域定制和大规模模型落地提供了有效路径。小模型配合该方法，能够兼顾性能、通用性和部署成本，是面向企业级应用的可行方案。

Abstract: The emergence of open-source large language models (LLMs) has expanded
opportunities for enterprise applications; however, many organizations still
lack the infrastructure to deploy and maintain large-scale models. As a result,
small LLMs (sLLMs) have become a practical alternative, despite their inherent
performance limitations. While Domain Adaptive Continual Pretraining (DACP) has
been previously explored as a method for domain adaptation, its utility in
commercial applications remains under-examined. In this study, we validate the
effectiveness of applying a DACP-based recipe across diverse foundation models
and service domains. Through extensive experiments and real-world evaluations,
we demonstrate that DACP-applied sLLMs achieve substantial gains in target
domain performance while preserving general capabilities, offering a
cost-efficient and scalable solution for enterprise-level deployment.

</details>


### [45] [Text to model via SysML: Automated generation of dynamical system computational models from unstructured natural language text via enhanced System Modeling Language diagrams](https://arxiv.org/abs/2507.06803)
*Matthew Anderson Hendricks,Alice Cicirello*

Main category: cs.CL

TL;DR: 论文提出了结合NLP和LLM的自动系统模型生成流程，可从文档自动抽取系统要素并生成SysML图，最终得到动力系统的计算模型，在多案例下表现优于只用LLM的方式。


<details>
  <summary>Details</summary>
Motivation: 工程动态系统的设计和部署过程通常费时费力，特别是在系统模型的生成方面。为加速这一过程，论文致力于利用领域知识和专家知识，自动生成动力系统的计算模型。

Method: 提出了一种自动化流程，将相关文献和具体系统输入文档结合，经过五步操作利用SysML系统建模语言提取系统的依赖、属性和操作等信息。自然语言处理（NLP）策略和大语言模型（LLM）分别用于关键元素抽取、关系识别、属性赋值和自动生成SysML图。最后通过代码生成和模型生成两步进一步落地。

Result: 该方法可自动生成复杂动力系统的SysML图并进一步得到计算模型。案例研究（如单摆）表明，自动化程度高，并且生成结果优于仅用LLM的方案。该方法不限领域或具体软件。

Conclusion: 基于NLP和LLM协同SysML自动建模的方案，显著提升了动力系统计算模型的生成效率和准确性，具备广泛可适用性，并改善了现有自动建模的性能。

Abstract: This paper contributes to speeding up the design and deployment of
engineering dynamical systems by proposing a strategy for exploiting domain and
expert knowledge for the automated generation of dynamical system computational
model starting from a corpus of document relevant to the dynamical system of
interest and an input document describing the specific system. This strategy is
implemented in five steps and, crucially, it uses system modeling language
diagrams (SysML) to extract accurate information about the dependencies,
attributes, and operations of components. Natural Language Processing (NLP)
strategies and Large Language Models (LLMs) are employed in specific tasks to
improve intermediate outputs of the SySML diagrams automated generation, such
as: list of key nouns; list of extracted relationships; list of key phrases and
key relationships; block attribute values; block relationships; and BDD diagram
generation. The applicability of automated SysML diagram generation is
illustrated with different case studies. The computational models of complex
dynamical systems from SysML diagrams are then obtained via code generation and
computational model generation steps. In the code generation step, NLP
strategies are used for summarization, while LLMs are used for validation only.
The proposed approach is not limited to a specific system, domain, or
computational software. The applicability of the proposed approach is shown via
an end-to-end example from text to model of a simple pendulum, showing improved
performance compared to results yielded by LLMs only.

</details>


### [46] [Adaptive Termination for Multi-round Parallel Reasoning: An Universal Semantic Entropy-Guided Framework](https://arxiv.org/abs/2507.06829)
*Zenan Xu,Zexuan Qiu,Guanhua Huang,Kun Li,Siheng Li,Chenchen Zhang,Kejiao Li,Qi Yi,Yuhao Jiang,Bo Zhou,Fengzong Lian,Zhanhui Kang*

Main category: cs.CL

TL;DR: 本文提出使用语义熵评估推理分支多样性，将其用于协作推理框架，在提升效率的同时保证结果准确性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的推理扩展主要有顺序和并行两种方式，但各自存在终止机制不合理、效率低、协同性差和需要大量微调等问题，因此需要一种新的测试时推理框架，以兼顾两者优点并克服其缺陷。

Method: 作者提出了semantic entropy（语义熵）指标，量化并行生成的模型响应的语义多样性，并以此为推理质量的评估标准，用于动态终止和控制模型的推理流程。

Result: 实验表明，语义熵与模型推理准确率存在强烈负相关关系，作为质量衡量指标时，对提升协作推理效率和准确性有效。

Conclusion: 作者提出了一种结合了顺序推理和并行推理优点的协作性推理框架，通过动态控制提升推理效率和准确性。

Abstract: Recent advances in large language models (LLMs) have accelerated progress
toward artificial general intelligence, with inference-time scaling emerging as
a key technique. Contemporary approaches leverage either sequential reasoning
(iteratively extending chains of thought) or parallel reasoning (generating
multiple solutions simultaneously) to scale inference. However, both paradigms
face fundamental limitations: sequential scaling typically relies on arbitrary
token budgets for termination, leading to inefficiency or premature cutoff;
while parallel scaling often lacks coordination among parallel branches and
requires intrusive fine-tuning to perform effectively. In light of these
challenges, we aim to design a flexible test-time collaborative inference
framework that exploits the complementary strengths of both sequential and
parallel reasoning paradigms. Towards this goal, the core challenge lies in
developing an efficient and accurate intrinsic quality metric to assess model
responses during collaborative inference, enabling dynamic control and early
termination of the reasoning trace. To address this challenge, we introduce
semantic entropy (SE), which quantifies the semantic diversity of parallel
model responses and serves as a robust indicator of reasoning quality due to
its strong negative correlation with accuracy...

</details>


### [47] [Shifting from Ranking to Set Selection for Retrieval Augmented Generation](https://arxiv.org/abs/2507.06838)
*Dahyun Lee,Yongrae Jo,Haeju Park,Moontae Lee*

Main category: cs.CL

TL;DR: SETR通过链式思维和成组选择机制，有效提升了RAG系统对复杂问题的检索和答案能力，性能优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 当前RAG系统通常只基于单独检索结果的相关性进行rerank，难以满足多跳问答等复杂查询对全面信息的需求。作者希望解决现有方法在信息充分性方面的不足，提高RAG应用的表现。

Method: 作者提出了一种成组通道（set-wise）选择方法SET-R。SETR通过链式思维推理（Chain-of-Thought reasoning）显式识别查询所需的信息点，并挑选能够共同满足这些需求的最优文本集合。

Result: SETR在多跳RAG基准数据集上超越了主流的LLM reranker和开源baseline，不仅在答案准确性上更佳，而且检索质量更优，为RAG系统提供了一个高效可靠的新方案。

Conclusion: 以集为单位进行检索和选择能够显著提升RAG系统在复杂查询场景下的信息满足度和答案质量，SETR模式优于传统单通道rerank方案。

Abstract: Retrieval in Retrieval-Augmented Generation(RAG) must ensure that retrieved
passages are not only individually relevant but also collectively form a
comprehensive set. Existing approaches primarily rerank top-k passages based on
their individual relevance, often failing to meet the information needs of
complex queries in multi-hop question answering. In this work, we propose a
set-wise passage selection approach and introduce SETR, which explicitly
identifies the information requirements of a query through Chain-of-Thought
reasoning and selects an optimal set of passages that collectively satisfy
those requirements. Experiments on multi-hop RAG benchmarks show that SETR
outperforms both proprietary LLM-based rerankers and open-source baselines in
terms of answer correctness and retrieval quality, providing an effective and
efficient alternative to traditional rerankers in RAG systems. The code is
available at https://github.com/LGAI-Research/SetR

</details>


### [48] [Developing and Maintaining an Open-Source Repository of AI Evaluations: Challenges and Insights](https://arxiv.org/abs/2507.06893)
*Alexandra Abbas,Celia Waggoner,Justin Olive*

Main category: cs.CL

TL;DR: 文章总结了维护AI评测开源库的挑战与解决方案，提出了结构化管理、统计严谨和质量管控的实践方法，证明AI评测工作比普通软件开发更复杂且需特殊支持。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛应用，AI评测对于模型能力和安全性评估变得尤为重要，但实际操作中面临着可扩展性、可复现性及结果可靠性等难题。

Method: 文章基于对开源库inspect_evals八个月的维护经验，总结了关键挑战，通过结构化管理、统计方法和质量控制流程，提出了一系列解决方案。

Result: 作者提出了三大解决措施：1）结构化社区管理框架；2）用于模型重采样与对比的统计方法；3）系统化的质量控制流程，实现了可扩展和高质量的评测库维护。

Conclusion: AI评测不仅需要常规的软件开发实践，更需要专业的基础设施、严格的统计方法以及社区的协调与合作。

Abstract: AI evaluations have become critical tools for assessing large language model
capabilities and safety. This paper presents practical insights from eight
months of maintaining $inspect\_evals$, an open-source repository of 70+
community-contributed AI evaluations. We identify key challenges in
implementing and maintaining AI evaluations and develop solutions including:
(1) a structured cohort management framework for scaling community
contributions, (2) statistical methodologies for optimal resampling and
cross-model comparison with uncertainty quantification, and (3) systematic
quality control processes for reproducibility. Our analysis reveals that AI
evaluation requires specialized infrastructure, statistical rigor, and
community coordination beyond traditional software development practices.

</details>


### [49] [SCoRE: Streamlined Corpus-based Relation Extraction using Multi-Label Contrastive Learning and Bayesian kNN](https://arxiv.org/abs/2507.06895)
*Luca Mariotti,Veronica Guidetti,Federica Mandreoli*

Main category: cs.CL

TL;DR: SCoRE是一种高效、无需微调且适应性强的关系抽取系统，在多个基准测试上表现出色，并有效降低能耗，适合现实应用。


<details>
  <summary>Details</summary>
Motivation: 随着高效知识图谱（KG）扩充的需求日益增长，如何在低监督条件下结合大规模语言模型进行关系抽取（RE），并兼顾适应性和噪声鲁棒性成为挑战。

Method: 提出了SCoRE系统，结合了有监督对比学习与贝叶斯k近邻（kNN）分类器，实现无需微调、便于切换预训练语言模型，适应多样语料和知识图谱环境。系统还提出了两种新评估指标：关系结构相关距离（CSD）和R位精度（P@R）。同时公开了一个模拟实际场景的Wiki20d数据集。

Result: 在五个基准数据集上，SCoRE的表现达到或超越现有最优方法，并大幅减少能耗。分析还表明，提高模型复杂度反而降低性能，SCoRE的简洁设计更具优势。

Conclusion: SCoRE兼具高效、模块化、可扩展性，是实际关系抽取任务的优选方案。

Abstract: The growing demand for efficient knowledge graph (KG) enrichment leveraging
external corpora has intensified interest in relation extraction (RE),
particularly under low-supervision settings. To address the need for adaptable
and noise-resilient RE solutions that integrate seamlessly with pre-trained
large language models (PLMs), we introduce SCoRE, a modular and cost-effective
sentence-level RE system. SCoRE enables easy PLM switching, requires no
finetuning, and adapts smoothly to diverse corpora and KGs. By combining
supervised contrastive learning with a Bayesian k-Nearest Neighbors (kNN)
classifier for multi-label classification, it delivers robust performance
despite the noisy annotations of distantly supervised corpora. To improve RE
evaluation, we propose two novel metrics: Correlation Structure Distance (CSD),
measuring the alignment between learned relational patterns and KG structures,
and Precision at R (P@R), assessing utility as a recommender system. We also
release Wiki20d, a benchmark dataset replicating real-world RE conditions where
only KG-derived annotations are available. Experiments on five benchmarks show
that SCoRE matches or surpasses state-of-the-art methods while significantly
reducing energy consumption. Further analyses reveal that increasing model
complexity, as seen in prior work, degrades performance, highlighting the
advantages of SCoRE's minimal design. Combining efficiency, modularity, and
scalability, SCoRE stands as an optimal choice for real-world RE applications.

</details>


### [50] [VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation](https://arxiv.org/abs/2507.06899)
*Ziang Ye,Yang Zhang,Wentao Shi,Xiaoyu You,Fuli Feng,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 本文发现并验证了基于大型视觉语言模型的GUI智能体在视觉定位环节存在被隐蔽后门攻击的新型安全漏洞，提出了VisualTrap攻击方法，利用少量有毒数据即可实现跨环境、高隐蔽性的持续攻击，警示该领域安全风险需高度关注。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉语言模型赋能的GUI智能体极大提升了人机交互能力，但其与个人设备的深度融合也带来了大量尚未被充分探索的安全威胁，尤其是后门攻击的风险。

Method: 提出了一种名为VisualTrap的新型后门攻击方法，通过在视觉定位预训练阶段注入少量（约5%）的有毒数据，诱使模型将文本计划映射到错误位置，实现劫持和攻击效果。评估了这种攻击在不同环境及任务上的泛化能力和隐蔽性。

Result: 实验证明，VisualTrap只需注入5%的有毒数据，并采用对人眼不可见的视觉触发器，即可高效劫持视觉定位过程，这种攻击不仅在下游任务中依然有效，甚至能从移动/网页环境泛化至桌面环境。

Conclusion: 本文揭示了GUI智能体在视觉语言模型支持下存在严重的后门攻击隐患，尤其是在视觉定位（grounding）过程中可被注入隐蔽后门触发器，从而危及系统安全。强调了对GUI智能体安全性的进一步研究迫在眉睫。

Abstract: Graphical User Interface (GUI) agents powered by Large Vision-Language Models
(LVLMs) have emerged as a revolutionary approach to automating human-machine
interactions, capable of autonomously operating personal devices (e.g., mobile
phones) or applications within the device to perform complex real-world tasks
in a human-like manner. However, their close integration with personal devices
raises significant security concerns, with many threats, including backdoor
attacks, remaining largely unexplored. This work reveals that the visual
grounding of GUI agent-mapping textual plans to GUI elements-can introduce
vulnerabilities, enabling new types of backdoor attacks. With backdoor attack
targeting visual grounding, the agent's behavior can be compromised even when
given correct task-solving plans. To validate this vulnerability, we propose
VisualTrap, a method that can hijack the grounding by misleading the agent to
locate textual plans to trigger locations instead of the intended targets.
VisualTrap uses the common method of injecting poisoned data for attacks, and
does so during the pre-training of visual grounding to ensure practical
feasibility of attacking. Empirical results show that VisualTrap can
effectively hijack visual grounding with as little as 5% poisoned data and
highly stealthy visual triggers (invisible to the human eye); and the attack
can be generalized to downstream tasks, even after clean fine-tuning. Moreover,
the injected trigger can remain effective across different GUI environments,
e.g., being trained on mobile/web and generalizing to desktop environments.
These findings underscore the urgent need for further research on backdoor
attack risks in GUI agents.

</details>


### [51] [MIND: A Multi-agent Framework for Zero-shot Harmful Meme Detection](https://arxiv.org/abs/2507.06908)
*Ziyan Liu,Chunxiao Fan,Haoran Lou,Yuexin Wu,Kaiwei Deng*

Main category: cs.CL

TL;DR: 提出MIND多智能体零样本框架，结合相似梗图检索、双向推理和多智能体辩论机制，有效检测无标注数据的有害梗图，全面提升检测准确率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上恶意梗图（Memes）的快速增长，需要有效的方法检测有害内容。然而，传统的数据驱动方法难以跟上新型梗图的变化，且缺少最新的标注数据。

Method: 提出了MIND，一个多智能体的零样本（zero-shot）有害梗图检测框架，无需依赖标注数据。核心策略包括：1）检索未标注参考集中的相似梗图以提供上下文；2）提出双向洞察推理机制，全面理解相似梗图内容；3）采用多智能体辩论机制，通过推理仲裁提高决策鲁棒性。

Result: MIND 在三个梗图数据集上的大量实验证明，其不仅优于现有的零样本检测方法，还在不同模型结构和参数规模下表现出强泛化能力，具有良好的可扩展性。

Conclusion: MIND 框架能有效实现无需标注数据的有害梗图检测，在泛化能力和扩展性方面优于现有方法，为社交平台的内容安全提供了有力方案。

Abstract: The rapid expansion of memes on social media has highlighted the urgent need
for effective approaches to detect harmful content. However, traditional
data-driven approaches struggle to detect new memes due to their evolving
nature and the lack of up-to-date annotated data. To address this issue, we
propose MIND, a multi-agent framework for zero-shot harmful meme detection that
does not rely on annotated data. MIND implements three key strategies: 1) We
retrieve similar memes from an unannotated reference set to provide contextual
information. 2) We propose a bi-directional insight derivation mechanism to
extract a comprehensive understanding of similar memes. 3) We then employ a
multi-agent debate mechanism to ensure robust decision-making through reasoned
arbitration. Extensive experiments on three meme datasets demonstrate that our
proposed framework not only outperforms existing zero-shot approaches but also
shows strong generalization across different model architectures and parameter
scales, providing a scalable solution for harmful meme detection. The code is
available at https://github.com/destroy-lonely/MIND.

</details>


### [52] [MultiJustice: A Chinese Dataset for Multi-Party, Multi-Charge Legal Prediction](https://arxiv.org/abs/2507.06909)
*Xiao Wang,Jiahuan Pei,Diancheng Shui,Zhiguang Han,Xin Sun,Dawei Zhu,Xiaoyu Shen*

Main category: cs.CL

TL;DR: 本文首次系统研究了多被告多罪名对法律判决预测的影响，并提出了相关数据集和评估方案，发现情景越复杂，主流大模型性能下降越明显。


<details>
  <summary>Details</summary>
Motivation: 法律判决预测（LJP）在辅助法律从业者和研究者方面具有重要价值，但现有研究较少探讨在LJP任务中是否应分别处理多被告和多罪名的问题。本文旨在填补该领域的空白。

Method: 本文构建了一个新的数据集——多被告多罪名预测（MPMCP），并基于四种实际法律判决情景，评估多种主流法律大语言模型（LLM）。四种情景分别为：（1）单被告单罪名，（2）单被告多罪名，（3）多被告单罪名，（4）多被告多罪名。同时，在罪名预测与刑期预测两个任务上对其表现进行综合对比分析。

Result: 实验显示，涉及多被告多罪名的情景（S4）困难最大，其次依次为S2、S3和S1。不同模型在复杂场景下的表现差异明显，比如在S4与S1对比下，InternLM2模型F1下降约4.5%，LogD升高约2.8%；而Lawformer模型F1下降约19.7%，LogD升高约19.0%。

Conclusion: 多被告和多罪名的独立与联合建模对判决预测任务影响显著，复杂情景下模型性能下降明显。所创建的数据集为进一步研究这一问题提供了基础。

Abstract: Legal judgment prediction offers a compelling method to aid legal
practitioners and researchers. However, the research question remains
relatively under-explored: Should multiple defendants and charges be treated
separately in LJP? To address this, we introduce a new dataset namely
multi-person multi-charge prediction (MPMCP), and seek the answer by evaluating
the performance of several prevailing legal large language models (LLMs) on
four practical legal judgment scenarios: (S1) single defendant with a single
charge, (S2) single defendant with multiple charges, (S3) multiple defendants
with a single charge, and (S4) multiple defendants with multiple charges. We
evaluate the dataset across two LJP tasks, i.e., charge prediction and penalty
term prediction. We have conducted extensive experiments and found that the
scenario involving multiple defendants and multiple charges (S4) poses the
greatest challenges, followed by S2, S3, and S1. The impact varies
significantly depending on the model. For example, in S4 compared to S1,
InternLM2 achieves approximately 4.5% lower F1-score and 2.8% higher LogD,
while Lawformer demonstrates around 19.7% lower F1-score and 19.0% higher LogD.
Our dataset and code are available at
https://github.com/lololo-xiao/MultiJustice-MPMCP.

</details>


### [53] [Exploring LLMs for Predicting Tutor Strategy and Student Outcomes in Dialogues](https://arxiv.org/abs/2507.06910)
*Fareya Ikram,Alexander Scarlatos,Andrew Lan*

Main category: cs.CL

TL;DR: LLM难以准确预测教学对话中导师的后续策略，而导师策略对学生学习效果预测意义重大，需开发更强预测方法。


<details>
  <summary>Details</summary>
Motivation: 鉴于在线学习普及及AI导师能力的提升，理解并预测AI或人类导师行为对提升学习成效很重要，而现有研究鲜有关注对话中导师策略的预测，因此需要探索LLMs在该任务上的效果。

Method: 利用Llama 3和GPT-4o等大语言模型，在两个数学辅导对话数据集上预测导师的未来行动和学生结果，并分析其表现。

Result: 即使是最强大的LLM在预测未来导师策略方面依然效果有限，但导师策略对学生结果预测有显著指示作用，凸显当前方法的局限。

Conclusion: 当前最先进的大语言模型（如Llama 3和GPT-4o）在预测未来导师策略方面表现不佳，而导师的策略却高度影响学生的学习结果，显示需要更强大和专业的方法来解决这一任务。

Abstract: Tutoring dialogues have gained significant attention in recent years, given
the prominence of online learning and the emerging tutoring abilities of
artificial intelligence (AI) agents powered by large language models (LLMs).
Recent studies have shown that the strategies used by tutors can have
significant effects on student outcomes, necessitating methods to predict how
tutors will behave and how their actions impact students. However, few works
have studied predicting tutor strategy in dialogues. Therefore, in this work we
investigate the ability of modern LLMs, particularly Llama 3 and GPT-4o, to
predict both future tutor moves and student outcomes in dialogues, using two
math tutoring dialogue datasets. We find that even state-of-the-art LLMs
struggle to predict future tutor strategy while tutor strategy is highly
indicative of student outcomes, outlining a need for more powerful methods to
approach this task.

</details>


### [54] [Rethinking Verification for LLM Code Generation: From Generation to Testing](https://arxiv.org/abs/2507.06920)
*Zihan Ma,Taolin Zhang,Maosong Cao,Wenwei Zhang,Minnan Luo,Songyang Zhang,Kai Chen*

Main category: cs.CL

TL;DR: 论文发现现有LLM代码基准测试用例有限且单一，影响模型评价和强化学习奖励准确性。提出多维度评价+人机协作（SAGA）提升测试覆盖与质量，并开发TCGBench。实验显示新方法检测率和准确率明显优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在代码生成基准测试上表现优异，但现有测试集样本数量少且类型单一，导致一些细微错误未被发现。这不仅高估了模型表现，也影响了基于可验证奖励的强化学习（RLVR）框架的准确奖励评估。

Method: 本文提出一套多维度度量标准，以系统地量化测试集的覆盖度。并提出了一种人类-LLM协作生成测试用例的方法（SAGA），结合人类编程知识和LLM的推理能力。此外，本文还开发了TCGBench测试平台以支持测试用例生成任务。

Result: SAGA在TCGBench上的错误检测率为90.62%，验证器准确率为32.58%；使用SAGA合成的代码生成基准测试集的验证器准确率比LiveCodeBench-v6高10.78%。

Conclusion: 通过多维度量化和人机协作，显著提升了测试用例覆盖性和质量，为可靠的LLM代码评价打下了基础，有助于强化学习等领域的发展。

Abstract: Large language models (LLMs) have recently achieved notable success in
code-generation benchmarks such as HumanEval and LiveCodeBench. However, a
detailed examination reveals that these evaluation suites often comprise only a
limited number of homogeneous test cases, resulting in subtle faults going
undetected. This not only artificially inflates measured performance but also
compromises accurate reward estimation in reinforcement learning frameworks
utilizing verifiable rewards (RLVR). To address these critical shortcomings, we
systematically investigate the test-case generation (TCG) task by proposing
multi-dimensional metrics designed to rigorously quantify test-suite
thoroughness. Furthermore, we introduce a human-LLM collaborative method
(SAGA), leveraging human programming expertise with LLM reasoning capability,
aimed at significantly enhancing both the coverage and the quality of generated
test cases. In addition, we develop a TCGBench to facilitate the study of the
TCG task. Experiments show that SAGA achieves a detection rate of 90.62% and a
verifier accuracy of 32.58% on TCGBench. The Verifier Accuracy (Verifier Acc)
of the code generation evaluation benchmark synthesized by SAGA is 10.78%
higher than that of LiveCodeBench-v6. These results demonstrate the
effectiveness of our proposed method. We hope this work contributes to building
a scalable foundation for reliable LLM code evaluation, further advancing RLVR
in code generation, and paving the way for automated adversarial test synthesis
and adaptive benchmark integration.

</details>


### [55] [Investigating the Robustness of Retrieval-Augmented Generation at the Query Level](https://arxiv.org/abs/2507.06956)
*Sezen Perçin,Xin Su,Qutub Sha Syed,Phillip Howard,Aleksei Kuvshinov,Leo Schwinn,Kay-Ulrich Scholl*

Main category: cs.CL

TL;DR: 本文系统评估了RAG检索模块对查询变动的敏感性，发现性能容易因细微查询变化下降，提出了评估和提升其健壮性的框架和建议。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）更新新知识的成本高且效率低。RAG 作为一种能动态利用外部知识并提升模型事实一致性的方案，虽然有效但实际应用依赖于检索输入查询的质量，存在实际挑战。

Method: 系统分析RAG管道中不同模块对于查询扰动的敏感性。分别对各个模块及其在端到端问答系统中的表现进行实验，涵盖通用领域和专业领域数据集。同时提出了一个评估框架，以系统性地测试RAG管道对查询的健壮性，并基于逾1092次实验的结果提出实践性建议。

Result: 常用的检索器在面对微小查询变化时性能会显著下降。通过模块级及整体系统的实验证明了RAG系统对查询质量的高度敏感性。基于大量实验结果为开发者提供了RAG系统在健壮性方面的实用建议。

Conclusion: RAG系统性能受查询变化影响很大，需关注输入查询质量。文中实验和评估框架可帮助业内更合理地部署和优化RAG系统。

Abstract: Large language models (LLMs) are very costly and inefficient to update with
new information. To address this limitation, retrieval-augmented generation
(RAG) has been proposed as a solution that dynamically incorporates external
knowledge during inference, improving factual consistency and reducing
hallucinations. Despite its promise, RAG systems face practical challenges-most
notably, a strong dependence on the quality of the input query for accurate
retrieval. In this paper, we investigate the sensitivity of different
components in the RAG pipeline to various types of query perturbations. Our
analysis reveals that the performance of commonly used retrievers can degrade
significantly even under minor query variations. We study each module in
isolation as well as their combined effect in an end-to-end question answering
setting, using both general-domain and domain-specific datasets. Additionally,
we propose an evaluation framework to systematically assess the query-level
robustness of RAG pipelines and offer actionable recommendations for
practitioners based on the results of more than 1092 experiments we performed.

</details>


### [56] [FRaN-X: FRaming and Narratives-eXplorer](https://arxiv.org/abs/2507.06974)
*Artur Muratov,Hana Fatima Shaikh,Vanshikaa Jani,Tarek Mahmoud,Zhuohan Xie,Daniil Orel,Aaryamonvikram Singh,Yuxia Wang,Aadi Joshi,Hasan Iqbal,Ming Shan Hee,Dhruv Sahnan,Nikolaos Nikolaidis,Purificação Silvano,Dimitar Dimitrov,Roman Yangarber,Ricardo Campos,Alípio Jorge,Nuno Guimarães,Elisa Sartori,Nicolas Stefanovitch,Giovanni Da San Martino,Jakub Piskorski,Preslav Nakov*

Main category: cs.CL

TL;DR: FRaN-X是一款自动识别文本中实体叙述角色的多语种系统，具备细粒度分类、可视化及交互分析功能，已开源并公开访问，极大便利了媒体分析工作。


<details>
  <summary>Details</summary>
Motivation: 当前媒体分析领域缺乏自动化、细粒度地识别文本中实体叙述角色的工具，难以全面捕捉媒体报道中对实体的叙事定位和构架。

Method: 提出了FRaN-X系统，采用两阶段方法，先进行序列标注识别实体，再对实体进行细粒度叙述角色分类。系统支持五种语言和两个重要领域，通过独特的22类嵌套细分类别实现更精确的叙述角色判定。

Result: FRaN-X能有效自动地检测和标注原文中实体的叙述角色，并提供图形可视化、搜索、时间线分析等功能，展示群体文章推动的叙事框架，方便媒体分析人员比较和探索不同来源的框架差异。系统与模型均开源，支持网页交互访问。

Conclusion: FRaN-X系统显著提升了自动化文本实体叙述角色分析的效率和精度，为多语种多领域的媒体分析提供了实用的平台和工具。

Abstract: We present FRaN-X, a Framing and Narratives Explorer that automatically
detects entity mentions and classifies their narrative roles directly from raw
text. FRaN-X comprises a two-stage system that combines sequence labeling with
fine-grained role classification to reveal how entities are portrayed as
protagonists, antagonists, or innocents, using a unique taxonomy of 22
fine-grained roles nested under these three main categories. The system
supports five languages (Bulgarian, English, Hindi, Russian, and Portuguese)
and two domains (the Russia-Ukraine Conflict and Climate Change). It provides
an interactive web interface for media analysts to explore and compare framing
across different sources, tackling the challenge of automatically detecting and
labeling how entities are framed. Our system allows end users to focus on a
single article as well as analyze up to four articles simultaneously. We
provide aggregate level analysis including an intuitive graph visualization
that highlights the narrative a group of articles are pushing. Our system
includes a search feature for users to look up entities of interest, along with
a timeline view that allows analysts to track an entity's role transitions
across different contexts within the article. The FRaN-X system and the trained
models are licensed under an MIT License. FRaN-X is publicly accessible at
https://fran-x.streamlit.app/ and a video demonstration is available at
https://youtu.be/VZVi-1B6yYk.

</details>


### [57] [FlexOlmo: Open Language Models for Flexible Data Use](https://arxiv.org/abs/2507.07024)
*Weijia Shi,Akshita Bhagia,Kevin Farhat,Niklas Muennighoff,Pete Walsh,Jacob Morrison,Dustin Schwenk,Shayne Longpre,Jake Poznanski,Allyson Ettinger,Daogao Liu,Margaret Li,Dirk Groeneveld,Mike Lewis,Wen-tau Yih,Luca Soldaini,Kyle Lo,Noah A. Smith,Luke Zettlemoyer,Pang Wei Koh,Hannaneh Hajishirzi,Ali Farhadi,Sewon Min*

Main category: cs.CL

TL;DR: FlexOlmo是一种支持分布式、跨数据所有者合作训练且推理时能灵活控制数据使用的MoE语言模型，实现了数据隐私与模型性能的兼得，显著优于传统合并与经典MoE方法。


<details>
  <summary>Details</summary>
Motivation: 当前数据监管和隐私保护要求下，多数据所有者需要在不共享原始数据的情况下共同训练模型，并在推理阶段灵活控制使用哪些数据，有效解决了数据许可与融合的实际挑战。

Method: 提出了FlexOlmo，这是一种基于专家混合（MoE）架构的语言模型。各专家在闭集数据上独立训练，通过新的领域感知路由机制整合，无需联合训练。模型训练基于包含公开和七类领域特定闭集数据的FlexMix语料库，支持灵活的数据选择与推理组合。

Result: FlexOlmo能够结合基于公共数据训练的通用专家与独立数据所有者的专家，在多项任务上相较于单一通用专家提升41%。同时，该方法相比以往的模型合并方法平均提升10.1%，也优于同等算力条件下未做数据限制的传统MoE。

Conclusion: FlexOlmo为受监管行业和有敏感数据的数据所有者提供了一种无需数据分享即可灵活协作、提升模型效能的解决方案，兼顾数据隐私与性能优化。

Abstract: We introduce FlexOlmo, a new class of language models (LMs) that supports (1)
distributed training without data sharing, where different model parameters are
independently trained on closed datasets, and (2) data-flexible inference,
where these parameters along with their associated data can be flexibly
included or excluded from model inferences with no further training. FlexOlmo
employs a mixture-of-experts (MoE) architecture where each expert is trained
independently on closed datasets and later integrated through a new
domain-informed routing without any joint training. FlexOlmo is trained on
FlexMix, a corpus we curate comprising publicly available datasets alongside
seven domain-specific sets, representing realistic approximations of closed
sets. We evaluate models with up to 37 billion parameters (20 billion active)
on 31 diverse downstream tasks. We show that a general expert trained on public
data can be effectively combined with independently trained experts from other
data owners, leading to an average 41% relative improvement while allowing
users to opt out of certain data based on data licensing or permission
requirements. Our approach also outperforms prior model merging methods by
10.1% on average and surpasses the standard MoE trained without data
restrictions using the same training FLOPs. Altogether, this research presents
a solution for both data owners and researchers in regulated industries with
sensitive or protected data. FlexOlmo enables benefiting from closed data while
respecting data owners' preferences by keeping their data local and supporting
fine-grained control of data access during inference.

</details>


### [58] [UniConv: Unifying Retrieval and Response Generation for Large Language Models in Conversations](https://arxiv.org/abs/2507.07030)
*Fengran Mo,Yifan Gao,Chuan Meng,Xin Liu,Zhuofeng Wu,Kelong Mao,Zhengyang Wang,Pei Chen,Zheng Li,Xian Li,Bing Yin,Meng Jiang*

Main category: cs.CL

TL;DR: 本文提出一种将密集检索与响应生成统一到大语言模型中的方法，通过联合微调和一致性机制，提升了多轮对话搜索任务的整体表现，优于以往分开处理的基线。


<details>
  <summary>Details</summary>
Motivation: 当前对话式搜索系统通常将检索和生成分别建模，导致无法协同发挥两者的优势，影响检索和生成的效果。现有尝试统一建模的研究尚未很好地解决会话理解、独立检索和响应生成等问题。

Method: 本文探索如何将密集检索与响应生成在大规模语言模型中统一，通过联合微调多种目标，并设计两种机制减少模型不一致性及数据分歧。

Result: 在五个对话式搜索数据集上的实验评估表明，所提出的统一模型在检索和生成两个任务上均有提升，并优于现有基线方法。

Conclusion: 统一检索与生成任务的建模方式能够提升会话式搜索系统的整体性能，实现任务间的相互促进。

Abstract: The rapid advancement of conversational search systems revolutionizes how
information is accessed by enabling the multi-turn interaction between the user
and the system. Existing conversational search systems are usually built with
two different models. This separation restricts the system from leveraging the
intrinsic knowledge of the models simultaneously, which cannot ensure the
effectiveness of retrieval benefiting the generation. The existing studies for
developing unified models cannot fully address the aspects of understanding
conversational context, managing retrieval independently, and generating
responses. In this paper, we explore how to unify dense retrieval and response
generation for large language models in conversation. We conduct joint
fine-tuning with different objectives and design two mechanisms to reduce the
inconsistency risks while mitigating data discrepancy. The evaluations on five
conversational search datasets demonstrate that our unified model can mutually
improve both tasks and outperform the existing baselines.

</details>


### [59] [Discrete Diffusion Models for Language Generation](https://arxiv.org/abs/2507.07050)
*Ashen Weligalle*

Main category: cs.CL

TL;DR: 扩散模型用于自然语言生成处理速度快、支持并行，显示新的研究方向，但目前生成质量仍弱于自回归模型。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在连续数据生成（如图像、视频）领域效果显著，但将这一框架应用于离散数据（如自然语言）存在挑战，尤其是词元依赖性复杂与缺乏生成顺序。论文旨在探究离散扩散模型在自然语言生成中的可行性及其与现有主流自回归模型的优劣。

Method: 比较D3PM（Discrete Denoising Diffusion Probabilistic Model）与传统自回归语言模型在自然语言生成任务上的表现，通过BPT、NLL、PPL和批处理速度等指标进行评估，所有实验条件一致，均为每模型生成10万词元，批处理大小为4。

Result: 最优D3PM模型BPT达到5.72，均值为8.05，AR模型BPT均值更低（4.59），压缩性能更佳，但D3PM的处理速度显著更快（每秒最高3.97批次），显示出在非自回归生成领域的效率潜力。

Conclusion: 离散扩散模型（如D3PM）在自然语言生成中显示出一定潜力，但在生成质量（如BPT值）上仍不如传统自回归（AR）模型，优势在于批量处理速度较快，展示了并行生成的可能性，两者各有优劣。

Abstract: Diffusion models have emerged as a powerful class of generative models,
achieving state-of-the-art results in continuous data domains such as image and
video generation. Their core mechanism involves a forward diffusion process
that gradually transforms structured data into a Gaussian-like distribution,
followed by a learned reverse process to reconstruct the data. While successful
in continuous modalities, applying this framework to discrete data-particularly
natural language-remains challenging due to token dependency complexities and
the lack of a defined generation order.This thesis investigates the feasibility
and performance of discrete diffusion models for natural language generation.
Specifically, we evaluate the Discrete Denoising Diffusion Probabilistic Model
(D3PM) and compare it with traditional autoregressive (AR) language models. To
assess generative performance, we use Bits Per Token (BPT), Negative
Log-Likelihood (NLL), Perplexity (PPL), and Batch Processing Speed.
  Results show the best-performing D3PM model achieves a BPT of 5.72, with a
mean of 8.05. The AR model outperforms in compression with a lower mean BPT of
4.59, but D3PM achieves higher processing speed, reaching up to 3.97 batches
per sec., indicating potential for parallel generation.All evaluations were
conducted under consistent conditions-generating 100,000 tokens per model with
a fixed batch size of four-for fair comparison. This research presents a
detailed analysis of diffusion-based vs. autoregressive models, highlighting
trade-offs in generative quality and efficiency. Findings emphasize both the
promise and limitations of diffusion models for discrete data, supporting
future work in non-autoregressive language generation.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [60] [Improved Lower Bounds on Multiflow-Multicut Gaps](https://arxiv.org/abs/2507.06576)
*Sina Kalantarzadeh,Nikhil Kumar*

Main category: cs.DM

TL;DR: 该论文针对平面图首次将最大多路流与最小多路割的gap下界提升至20/9，并提出了新颖的证明技巧，对理论研究具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 多源-汇对的最大多路流和最小多路割问题是图论和网络优化中的经典问题，其间的差异倍数——多路流-多路割间隙（gap）对理论和实际应用都极为重要。尽管已有相关研究，但对于平面图的下界，几十年来一直未获得新的突破，因此有必要进一步提升对该gap的理论认知。

Method: 作者针对平面图类，构造性地改进和提升了多路流-多路割间隙的下界；同时，发展了新的数学技巧和方法来证明这个下界，从而可能对其它类似问题也具有借鉴价值。

Result: 本文证明了对于平面图，最大多路流与最小多路割的gap至少为20/9，突破了此前下界2的限制，并推动了理论界对平面图结构性质的进一步理解。

Conclusion: 研究取得了突破性的下界改进，提出并验证了新的证明方法，为未来研究多路流-多路割关系及相关算法问题提供了新思路。

Abstract: Given a set of source-sink pairs, the maximum multiflow problem asks for the
maximum total amount of flow that can be feasibly routed between them. The
minimum multicut, a dual problem to multiflow, seeks the minimum-cost set of
edges whose removal disconnects all the source-sink pairs. It is easy to see
that the value of the minimum multicut is at least that of the maximum
multiflow, and their ratio is called the multiflow-multicut gap. The classical
max-flow min-cut theorem states that when there is only one source-sink pair,
the gap is exactly one. However, in general, it is well known that this gap can
be arbitrarily large. In this paper, we study this gap for classes of planar
graphs and establish improved lower bound results. In particular, we show that
this gap is at least $\frac{20}{9}$ for the class of planar graphs, improving
upon the decades-old lower bound of 2. More importantly, we develop new
techniques for proving such a lower bound, which may be useful in other
settings as well.

</details>


### [61] [The Integrality Gap of the Traveling Salesman Problem is $4/3$ if the LP Solution Has at Most $n+6$ Non-zero Components](https://arxiv.org/abs/2507.07003)
*Tullio Villa,Eleonora Vercesi,Janos Barta,Monaldo Mastrolilli*

Main category: cs.DM

TL;DR: 作者针对度量TSP的SEP线性松弛提出Gap-Bounding算法，证明了当最优解至多有n+6个非零分量时，整体性缺口猜想（4/3）成立。这为整体猜想的证明迈出重要一步。


<details>
  <summary>Details</summary>
Motivation: 该论文研究的是著名的Dantzig-Fulkerson-Johnson模型下，度量旅行商问题（metric TSP）与其线性松弛（即子环消除问题，SEP）之间的整体性缺口。该缺口长期被猜测为4/3，但尚无全面证明。作者希望针对特殊情况推动该猜想的进一步验证。

Method: 作者针对具有n个节点的问题，提出了对最优SEP解中非零分量最多为n+6的情况进行研究。具体做法是：定义了一个参数k，并构造了包含所有具有n+k个非零分量的SEP极点的无限集合F_k。通过一个新提出的缩减步骤，将F_k的描述归约为有限集合；之后设计出了Gap-Bounding算法，为所有F_k族提供可证明的整体性缺口上界。该算法在k≤6的情况下辅以计算机辅助验证。

Result: 应用Gap-Bounding算法（k≤6）并结合计算机辅助结果，证明了若最优SEP解有至多n+6个非零分量，则整体性缺口的4/3猜想成立。

Conclusion: 论文首次在最优解稀疏性的特定情形下，计算机辅助地验证了4/3整体性缺口猜想，推动了TSP线性松弛界的研究。

Abstract: In this paper, we address the classical Dantzig-Fulkerson-Johnson formulation
of the metric Traveling Salesman Problem and study the integrality gap of its
linear relaxation, namely the Subtour Elimination Problem (SEP). This
integrality gap is conjectured to be $4/3$. We prove that, when solving a
problem on $n$ nodes, if the optimal SEP solution has at most $n+6$ non-zero
components, then the conjecture is true. To establish this result, we consider,
for a given integer $k$, the infinite family $F_k$ which gathers, among all the
vertices of all the SEP polytopes for $n \in \mathbb{N}$, the ones with exactly
$n+k$ non-zero components. Then, we introduce a procedure that reduces the
description of $F_k$ to a finite set, and we present the Gap-Bounding
algorithm, which provides provable upper bounds on the integrality gap for
entire families $F_k$. The application of the Gap-Bounding algorithm for $k
\leq 6$ yields a computer-aided proof that the conjectured bound holds in this
case.

</details>


### [62] [On Construction of Approximate Real Mutually Unbiased Bases for an infinite class of dimensions $d \not\equiv 0 \bmod 4$](https://arxiv.org/abs/2507.07028)
*Ajeet Kumar,Rakesh Kumar,Subhamoy Maitra,Uddipto Mandal*

Main category: cs.DM

TL;DR: 该文首次提出在许多非4倍数的奇数维度下，能够构造超过⌈√d⌉组近似实互不相干基（ARMUBs），基于假设存在的Hadamard矩阵，满足向量间近似互不相干，解决了该领域长期开放的组合构造难题。


<details>
  <summary>Details</summary>
Motivation: 已知对于大于2且不是4的倍数的维度d，不存在实互不相干基（MUBs），因此一个组合数学上的新问题是，如何在这些情形下构造参数较好的近似实互不相干基（ARMUBs）。

Method: 本论文首次提出一种利用大小为4n×4n的实Hadamard矩阵（假设存在性），构造一个（4n-t）×（4n-t）阶正交矩阵Y_{4n-t}，该矩阵每个元素的绝对值接近1/(4n-t)，并据此构造ARMUBs的方法。

Result: 对于某些形如d=(4n-t)s（t=1,2,3，n为自然数，s为奇素幂）的维度，可以构造大于⌈√d⌉个ARMUBs，且任意两个基之间的任意基向量对的内积绝对值上界为≤1/√d(1+O(d^{-1/2}))。这些d的类别是无限大的。

Conclusion: 首次指出可对某些非4的倍数的奇数维度，以特定参数构造超过⌈√d⌉个近似实互不相干基，并给出构造方法及性质，实现了对一直未解存在性问题下的突破。

Abstract: It is known that real Mutually Unbiased Bases (MUBs) do not exist for any
dimension $d > 2$ which is not divisible by 4. Thus, the next combinatorial
question is how one can construct Approximate Real MUBs (ARMUBs) in this
direction with encouraging parameters. In this paper, for the first time, we
show that it is possible to construct $> \lceil \sqrt{d} \rceil$ many ARMUBs
for certain odd dimensions $d$ of the form $d = (4n-t)s$, $t = 1, 2, 3$, where
$n$ is a natural number and $s$ is an odd prime power. Our method exploits any
available $4n \times 4n$ real Hadamard matrix $H_{4n}$ (conjectured to be true)
and uses this to construct an orthogonal matrix ${Y}_{4n-t}$ of size $(4n - t)
\times (4n - t)$, such that the absolute value of each entry varies a little
from $\frac{1}{4n-t}$. In our construction, the absolute value of the inner
product between any pair of basis vectors from two different ARMUBs will be
$\leq \frac{1}{\sqrt{d}}(1 + O(d^{-\frac{1}{2}})) < 2$, for proper choices of
parameters, the class of dimensions $d$ being infinitely large.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [63] [Stochastic Alignments: Matching an Observed Trace to Stochastic Process Models](https://arxiv.org/abs/2507.06472)
*Tian Li,Artem Polyvyanyy,Sander J. J. Leemans*

Main category: cs.FL

TL;DR: 本文针对传统过程挖掘中轨迹与概率模型匹配只关注最小偏差、忽视路径概率的问题，提出了兼顾偏差和概率的优化方法与启发式搜索算法，并用开源实现验证了其实用性，为分析提供了更具价值的诊断信息。


<details>
  <summary>Details</summary>
Motivation: 现有基于alignment的符合性检测方法在匹配时往往仅追求最小化偏差，但有时会选出不太可能发生的模型路径，限制了过程挖掘提供的分析价值。行业亟需同时兼顾路径可能性和匹配偏差的方法。

Method: 作者将观测到的轨迹与概率过程模型的匹配问题表述为优化问题，提出了一种以启发式引导的路径搜索算法进行求解，并实现了开源工具。

Result: 实验结果证明该方法不仅可行，还能为分析人员带来新的有益的诊断信息。

Conclusion: 本文提出的方法能更有效地将观测轨迹匹配到合理且概率高的模型路径，兼顾编辑距离和路径可能性，提升了过程挖掘分析的实用性和精度。

Abstract: Process mining leverages event data extracted from IT systems to generate
insights into the business processes of organizations. Such insights benefit
from explicitly considering the frequency of behavior in business processes,
which is captured by stochastic process models. Given an observed trace and a
stochastic process model, conventional alignment-based conformance checking
techniques face a fundamental limitation: They prioritize matching the trace to
a model path with minimal deviations, which may, however, lead to selecting an
unlikely path. In this paper, we study the problem of matching an observed
trace to a stochastic process model by identifying a likely model path with a
low edit distance to the trace. We phrase this as an optimization problem and
develop a heuristic-guided path-finding algorithm to solve it. Our open-source
implementation demonstrates the feasibility of the approach and shows that it
can provide new, useful diagnostic insights for analysts.

</details>
