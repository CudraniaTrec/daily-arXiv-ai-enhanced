{"id": "2507.22069", "categories": ["cs.PL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22069", "abs": "https://arxiv.org/abs/2507.22069", "authors": ["Tobias Sesterhenn", "Ian Berlot-Attwell", "Janis Zenkner", "Christian Bartelt"], "title": "A Compute-Matched Re-Evaluation of TroVE on MATH", "comment": null, "summary": "Reusing established theorems and formulas is central to mathematical problem\nsolving, serving as essential building blocks for tackling increasingly complex\nchallenges. Recent work, TroVE, argues that code-generating Large Language\nModels (LLMs) can benefit similarly on the MATH benchmark by inducing and\nreusing higher-level toolboxes. By allocating computational budget across an\nensemble of three modes -- directly generating code, creating tools, and\nreusing tools -- TroVE claims to outperform a PRIMITIVE baseline that only\nperforms direct generation. However, recent analysis (Berlot-Attwell et al.,\n2024) casts doubt on these gains, noting that the tools created are often\ntrivial or rarely reused, suggesting that improvements may stem from\nself-consistency or self-correction. In this work, we re-evaluate TroVE on\nMATH, analyze the impact of each of its modes, and show that its benefit does\nnot come from these mechanisms, but simply from a higher computational budget\nspent for TroVE compared to PRIMITIVE. To this end, we also perform a small\ncorrection in the original implementation of TroVE's selection mechanism,\nboosting TroVE's performance on MATH by 3\\% in accuracy. After matching for\ncompute, the benefit of TroVE reduces to a marginal improvement of 1\\%,\nsuggesting that this toolbox approach does not provide a significant benefit on\nMATH.", "AI": {"tldr": "TroVE\u5de5\u5177\u7bb1\u673a\u5236\u672c\u8eab\u8d21\u732e\u6709\u9650\uff0cMATH\u57fa\u51c6\u4e0b\u63d0\u5347\u4e3b\u8981\u7531\u8ba1\u7b97\u91cf\u589e\u52a0\u5e26\u6765\uff0c\u7ecf\u4fee\u6b63\u540e\u4ec5\u67091%\u7684\u5fae\u5f31\u6539\u8fdb\u3002", "motivation": "\u53ef\u91cd\u7528\u6027\u7684\u5b9a\u7406\u548c\u516c\u5f0f\u5728\u6570\u5b66\u95ee\u9898\u6c42\u89e3\u4e2d\u975e\u5e38\u5173\u952e\u3002TroVE\u8ba4\u4e3a\uff0c\u7c7b\u4f3c\u7684\u65b9\u6cd5\u53ef\u4ee5\u63d0\u5347\u5927\u6a21\u578b\u5728MATH\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\uff0c\u4f46\u6709\u58f0\u97f3\u8d28\u7591\u5176\u5b9e\u9645\u4f5c\u7528\u3002\u672c\u6587\u65e8\u5728\u91cd\u65b0\u8bc4\u4f30TroVE\u5728MATH\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u91cd\u65b0\u8bc4\u4f30\u4e86TroVE\u65b9\u6cd5\u5728MATH\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u5177\u4f53\u5206\u6790\u5176\u4e09\u79cd\u6a21\u5f0f\uff08\u76f4\u63a5\u751f\u6210\u4ee3\u7801\u3001\u521b\u5efa\u5de5\u5177\u3001\u590d\u7528\u5de5\u5177\uff09\u5bf9\u8868\u73b0\u7684\u5f71\u54cd\uff0c\u5e76\u8fdb\u884c\u4e86\u5b9e\u73b0\u4e0a\u7684\u5c0f\u4fee\u6b63\u4ee5\u63d0\u5347\u6027\u80fd\uff0c\u6b64\u5916\u5339\u914d\u8ba1\u7b97\u6d88\u8017\uff0c\u6bd4\u8f83TroVE\u548cPRIMITIVE\u7684\u5b9e\u9645\u6539\u8fdb\u5e45\u5ea6\u3002", "result": "TroVE\u6a21\u578b\u63d0\u5347\u4e3b\u8981\u6e90\u81ea\u5206\u914d\u4e86\u66f4\u9ad8\u7684\u8ba1\u7b97\u91cf\uff0c\u800c\u975e\u5de5\u5177\u7bb1\u673a\u5236\u672c\u8eab\u3002\u5b9e\u73b0\u4fee\u6b63\u540eMATH\u57fa\u51c6\u8868\u73b0\u63d0\u5347\u4e863%\uff0c\u4f46\u5728\u4e25\u683c\u5339\u914d\u8ba1\u7b97\u91cf\u540e\uff0cTroVE\u4ec5\u6bd4\u76f4\u63a5\u751f\u6210\u65b9\u6cd5\u63d0\u53471%\u3002", "conclusion": "TroVE\u7684\u5de5\u5177\u7bb1\u673a\u5236\u5bf9\u63d0\u5347MATH\u57fa\u51c6\u8868\u73b0\u5e76\u65e0\u663e\u8457\u4f5c\u7528\uff0c\u4e3b\u8981\u4f18\u52bf\u53ea\u662f\u6e90\u81ea\u4e8e\u6d88\u8017\u4e86\u66f4\u591a\u8ba1\u7b97\u8d44\u6e90\u3002"}}
{"id": "2507.22065", "categories": ["cs.SE", "cs.AI", "cs.CR", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.22065", "abs": "https://arxiv.org/abs/2507.22065", "authors": ["Xiaotao Feng", "Xiaogang Zhu", "Kun Hu", "Jincheng Wang", "Yingjie Cao", "Guang Gong", "Jianfeng Pan"], "title": "Fuzzing: Randomness? Reasoning! Efficient Directed Fuzzing via Large Language Models", "comment": null, "summary": "Fuzzing is highly effective in detecting bugs due to the key contribution of\nrandomness. However, randomness significantly reduces the efficiency of\nfuzzing, causing it to cost days or weeks to expose bugs. Even though directed\nfuzzing reduces randomness by guiding fuzzing towards target buggy locations,\nthe dilemma of randomness still challenges directed fuzzers. Two critical\ncomponents, which are seeds and mutators, contain randomness and are closely\ntied to the conditions required for triggering bugs. Therefore, to address the\nchallenge of randomness, we propose to use large language models (LLMs) to\nremove the randomness in seeds and reduce the randomness in mutators. With\ntheir strong reasoning and code generation capabilities, LLMs can be used to\ngenerate reachable seeds that target pre-determined locations and to construct\nbug-specific mutators tailored for specific bugs. We propose RandLuzz, which\nintegrates LLMs and directed fuzzing, to improve the quality of seeds and\nmutators, resulting in efficient bug exposure. RandLuzz analyzes function call\nchain or functionality to guide LLMs in generating reachable seeds. To\nconstruct bug-specific mutators, RandLuzz uses LLMs to perform bug analysis,\nobtaining information such as bug causes and mutation suggestions, which\nfurther help generate code that performs bug-specific mutations. We evaluate\nRandLuzz by comparing it with four state-of-the-art directed fuzzers, AFLGo,\nBeacon, WindRanger, and SelectFuzz. With RandLuzz-generated seeds, the fuzzers\nachieve an average speedup ranging from 2.1$\\times$ to 4.8$\\times$ compared to\nusing widely-used initial seeds. Additionally, when evaluated on individual\nbugs, RandLuzz achieves up to a 2.7$\\times$ speedup compared to the\nsecond-fastest exposure. On 8 bugs, RandLuzz can even expose them within 60\nseconds.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5b9a\u5411\u6a21\u7cca\u6d4b\u8bd5\u7684\u65b0\u6846\u67b6RandLuzz\uff0c\u901a\u8fc7\u667a\u80fd\u751f\u6210\u79cd\u5b50\u548c\u5b9a\u5236\u53d8\u5f02\u5668\uff0c\u663e\u8457\u63d0\u5347\u6f0f\u6d1e\u68c0\u6d4b\u6548\u7387\uff0c\u5728\u4e3b\u6d41\u65b9\u6cd5\u5bf9\u6bd4\u6d4b\u8bd5\u4e2d\u53d6\u5f972~5\u500d\u52a0\u901f\u6548\u679c\u3002", "motivation": "\u6a21\u7cca\u6d4b\u8bd5\uff08Fuzzing\uff09\u4f9d\u8d56\u968f\u673a\u6027\u6709\u6548\u53d1\u73b0\u6f0f\u6d1e\uff0c\u4f46\u968f\u673a\u6027\u4e5f\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\uff0c\u4f7f\u5f97\u6f0f\u6d1e\u66b4\u9732\u8fc7\u7a0b\u8017\u65f6\u3002\u5373\u4f7f\u5b9a\u5411\u6a21\u7cca\u6d4b\u8bd5\uff08Directed Fuzzing\uff09\u90e8\u5206\u51cf\u5f31\u4e86\u968f\u673a\u6027\uff0c\u4f46\u4ecd\u672a\u5b8c\u5168\u89e3\u51b3\u6548\u7387\u4e0e\u968f\u673a\u6027\u7684\u77db\u76fe\uff0c\u7279\u522b\u662f\u79cd\u5b50\uff08seed\uff09\u548c\u53d8\u5f02\u5668\uff08mutator\uff09\u8fd9\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\u4e2d\u7684\u968f\u673a\u6027\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51faRandLuzz\uff0c\u521b\u65b0\u6027\u5730\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u5b9a\u5411\u6a21\u7cca\u6d4b\u8bd5\u4ee5\u53bb\u9664\u6216\u51cf\u5c11\u79cd\u5b50\u548c\u53d8\u5f02\u5668\u4e2d\u7684\u968f\u673a\u6027\u3002RandLuzz\u5229\u7528LLM\u4f18\u52bf\u751f\u6210\u9488\u5bf9\u76ee\u6807\u4f4d\u7f6e\u53ef\u5230\u8fbe\u7684\u79cd\u5b50\uff0c\u5e76\u6839\u636e\u5177\u4f53\u6f0f\u6d1e\u5206\u6790\u7ed3\u679c\u5b9a\u5236bug-specific\u53d8\u5f02\u5668\uff0c\u4ece\u800c\u63d0\u5347\u6a21\u7cca\u6d4b\u8bd5\u6548\u7387\u3002RandLuzz\u4f1a\u5206\u6790\u51fd\u6570\u8c03\u7528\u94fe\u6216\u529f\u80fd\u6765\u5f15\u5bfcLLM\u751f\u6210\u53ef\u5230\u8fbe\u79cd\u5b50\uff0c\u5e76\u4f9d\u636e\u6f0f\u6d1e\u539f\u56e0\u4e0e\u53d8\u5f02\u5efa\u8bae\u751f\u6210\u5b9a\u5236\u5316\u4ee3\u7801\u53d8\u5f02\u5668\u3002", "result": "RandLuzz\u4e0eAFLGo\u3001Beacon\u3001WindRanger\u3001SelectFuzz\u56db\u4e2a\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5b9a\u5411\u6a21\u7cca\u5668\u5bf9\u6bd4\uff0c\u4f7f\u7528\u5176\u751f\u6210\u7684\u79cd\u5b50\uff0c\u6574\u4f53\u53d1\u73b0\u6f0f\u6d1e\u7684\u5e73\u5747\u901f\u5ea6\u63d0\u53472.1\u81f34.8\u500d\uff1b\u5728\u5355\u6f0f\u6d1e\u8bc4\u6d4b\u65f6\uff0c\u76f8\u6bd4\u7b2c\u4e8c\u5feb\u65b9\u6cd5\u63d0\u5347\u81f32.7\u500d\u3002\u67098\u4e2a\u6f0f\u6d1e\u53ef\u572860\u79d2\u5185\u88ab\u66b4\u9732\u3002", "conclusion": "\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u878d\u5408\u8fdb\u6a21\u7cca\u6d4b\u8bd5\u80fd\u591f\u663e\u8457\u51cf\u5c11\u76f8\u5173\u6838\u5fc3\u73af\u8282\uff08\u5982\u79cd\u5b50\u4e0e\u53d8\u5f02\u5668\uff09\u968f\u673a\u6027\uff0c\u5927\u5e45\u63d0\u5347\u68c0\u6d4b\u6f0f\u6d1e\u7684\u901f\u5ea6\u4e0e\u6548\u7387\u3002RandLuzz\u65b9\u6cd5\u5728\u5b9e\u9645\u591a\u9879\u8bc4\u4ef7\u4e2d\u90fd\u663e\u51fa\u660e\u663e\u4f18\u52bf\u3002"}}
{"id": "2507.22070", "categories": ["cs.SE", "cs.CE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.22070", "abs": "https://arxiv.org/abs/2507.22070", "authors": ["Y. Du"], "title": "Automated Test Data Generation for Enterprise Protobuf Systems: A Metaclass-Enhanced Statistical Approach", "comment": "7 pages", "summary": "Large-scale enterprise systems utilizing Protocol Buffers (protobuf) present\nsignificant challenges for performance testing, particularly when targeting\nintermediate business interfaces with complex nested data structures.\nTraditional test data generation approaches are inadequate for handling the\nintricate hierarchical and graph-like structures inherent in enterprise\nprotobuf schemas. This paper presents a novel test data generation framework\nthat leverages Python's metaclass system for dynamic type enhancement and\nstatistical analysis of production logs for realistic value domain extraction.\nOur approach combines automatic schema introspection, statistical value\ndistribution analysis, and recursive descent algorithms for handling deeply\nnested structures. Experimental evaluation on three real-world enterprise\nsystems demonstrates up to 95\\% reduction in test data preparation time and\n80\\% improvement in test coverage compared to existing approaches. The\nframework successfully handles protobuf structures with up to 15 levels of\nnesting and generates comprehensive test suites containing over 100,000 test\ncases within seconds.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u4f01\u4e1a protobuf \u590d\u6742\u5d4c\u5957\u7ed3\u6784\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u6570\u636e\u751f\u6210\u6846\u67b6\uff0c\u7ed3\u5408 Python \u5143\u7c7b\u673a\u5236\u548c\u65e5\u5fd7\u7edf\u8ba1\u5206\u6790\uff0c\u6709\u6548\u63d0\u5347\u6d4b\u8bd5\u6548\u7387\u4e0e\u8986\u76d6\u7387\uff0c\u80fd\u5feb\u901f\u751f\u6210\u5927\u89c4\u6a21\u3001\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u6570\u636e\u3002", "motivation": "\u5728\u5927\u578b\u4f01\u4e1a\u7cfb\u7edf\u4e2d\uff0c\u57fa\u4e8e Protocol Buffers (protobuf) \u7684\u590d\u6742\u5d4c\u5957\u6570\u636e\u7ed3\u6784\u4f7f\u5f97\u6027\u80fd\u6d4b\u8bd5\uff0c\u5c24\u5176\u662f\u9762\u5411\u4e2d\u95f4\u4e1a\u52a1\u63a5\u53e3\u7684\u6d4b\u8bd5\u6570\u636e\u751f\u6210\u5de5\u4f5c\u6781\u7aef\u56f0\u96be\u3002\u4f20\u7edf\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u4f01\u4e1a\u7ea7 protobuf \u67b6\u6784\u4e2d\u590d\u6742\u7684\u5c42\u7ea7\u548c\u7c7b\u56fe\u7ed3\u6784\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6d4b\u8bd5\u6570\u636e\u751f\u6210\u6846\u67b6\uff0c\u5229\u7528 Python \u7684\u5143\u7c7b\uff08metaclass\uff09\u673a\u5236\u5b9e\u73b0\u52a8\u6001\u7c7b\u578b\u589e\u5f3a\uff0c\u5e76\u901a\u8fc7\u5bf9\u751f\u4ea7\u65e5\u5fd7\u7684\u7edf\u8ba1\u5206\u6790\uff0c\u62bd\u53d6\u771f\u5b9e\u7684\u503c\u57df\u4fe1\u606f\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u81ea\u52a8\u67b6\u6784\u81ea\u7701\u3001\u7edf\u8ba1\u503c\u5206\u5e03\u5206\u6790\u548c\u9012\u5f52\u4e0b\u964d\u7b97\u6cd5\uff0c\u4ee5\u5e94\u5bf9\u6df1\u5ea6\u5d4c\u5957\u7ed3\u6784\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4f01\u4e1a\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u6d4b\u8bd5\u6570\u636e\u51c6\u5907\u65f6\u95f4\u4e0a\u6700\u591a\u53ef\u7f29\u77ed 95%\uff0c\u6d4b\u8bd5\u8986\u76d6\u7387\u63d0\u5347 80%\u3002\u7cfb\u7edf\u53ef\u5904\u7406\u591a\u8fbe 15 \u5c42\u5d4c\u5957\u7684 protobuf \u7ed3\u6784\uff0c\u5e76\u5728\u6570\u79d2\u5185\u751f\u6210\u8d85\u8fc7 10 \u4e07\u6761\u6d4b\u8bd5\u7528\u4f8b\u7684\u5b8c\u6574\u6d4b\u8bd5\u96c6\u3002", "conclusion": "\u8be5\u6846\u67b6\u6781\u5927\u63d0\u5347\u4e86\u57fa\u4e8e protobuf \u7684\u4f01\u4e1a\u7cfb\u7edf\u6027\u80fd\u6d4b\u8bd5\u7684\u6548\u7387\u4e0e\u6709\u6548\u6027\uff0c\u4e3a\u590d\u6742\u6570\u636e\u7ed3\u6784\u7684\u81ea\u52a8\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u6709\u529b\u652f\u6301\u3002"}}
{"id": "2507.22086", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.22086", "abs": "https://arxiv.org/abs/2507.22086", "authors": ["Honghua Dong", "Jiacheng Yang", "Xun Deng", "Yuhe Jiang", "Gennady Pekhimenko", "Fan Long", "Xujie Si"], "title": "TypyBench: Evaluating LLM Type Inference for Untyped Python Repositories", "comment": null, "summary": "Type inference for dynamic languages like Python is a persistent challenge in\nsoftware engineering. While large language models (LLMs) have shown promise in\ncode understanding, their type inference capabilities remain underexplored. We\nintroduce TypyBench, a benchmark designed to evaluate LLMs' type inference\nacross entire Python repositories. TypyBench features two novel metrics:\nTypeSim, which captures nuanced semantic relationships between predicted and\nground truth types, and TypeCheck, which assesses type consistency across\ncodebases. Our evaluation of various LLMs on a curated dataset of 50\nhigh-quality Python repositories reveals that, although LLMs achieve decent\nTypeSim scores, they struggle with complex nested types and exhibit significant\ntype consistency errors. These findings suggest that future research should\nshift focus from improving type similarity to addressing repository-level\nconsistency. TypyBench provides a foundation for this new direction, offering\ninsights into model performance across different type complexities and usage\ncontexts. Our code and data are available at\nhttps://github.com/typybench/typybench.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTypyBench\u57fa\u51c6\uff0c\u7cfb\u7edf\u8bc4\u6d4b\u5927\u6a21\u578b\u5728Python\u5168\u4ed3\u5e93\u7c7b\u578b\u63a8\u65ad\u4e0a\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u590d\u6742\u7c7b\u578b\u548c\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u6b20\u4f73\uff0c\u5efa\u8bae\u672a\u6765\u805a\u7126\u7c7b\u578b\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u5de5\u5177\u4e0e\u6570\u636e\u96c6\u5df2\u5f00\u6e90\u3002", "motivation": "\u52a8\u6001\u8bed\u8a00\u5982Python\u7c7b\u578b\u63a8\u65ad\u56f0\u96be\uff0c\u73b0\u6709LLMs\u5728\u4ee3\u7801\u7406\u89e3\u6709\u8fdb\u5c55\uff0c\u4f46\u5176\u7c7b\u578b\u63a8\u65ad\u80fd\u529b\u5c1a\u672a\u6df1\u5165\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u63d0\u51faTypyBench\u57fa\u51c6\uff0c\u5305\u542bTypeSim\u548cTypeCheck\u4e24\u79cd\u65b0\u8bc4\u6d4b\u6307\u6807\uff0c\u7cfb\u7edf\u8bc4\u6d4b\u591a\u79cd\u5927\u6a21\u578b\u572850\u4e2a\u9ad8\u8d28\u91cfPython\u4ed3\u5e93\u4e0a\u7684\u7c7b\u578b\u63a8\u65ad\u80fd\u529b\u3002", "result": "LLMs\u5728TypeSim\u6307\u6807\u4e0a\u8868\u73b0\u5c1a\u53ef\uff0c\u4f46\u5728\u590d\u6742\u5d4c\u5957\u7c7b\u578b\u3001\u4ee3\u7801\u5e93\u7ea7\u522b\u7c7b\u578b\u4e00\u81f4\u6027\u65b9\u9762\u4ecd\u6709\u8f83\u5927\u63d0\u5347\u7a7a\u95f4\u3002TypyBench\u63ed\u793a\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u7c7b\u578b\u590d\u6742\u5ea6\u548c\u573a\u666f\u4e0b\u7684\u8868\u73b0\u5dee\u5f02\u3002", "conclusion": "LLMs\u5728Python\u7c7b\u578b\u63a8\u65ad\u4e0a\u80fd\u53d6\u5f97\u4e0d\u9519\u7684\u76f8\u4f3c\u5ea6\u5206\u6570\uff0c\u4f46\u5728\u590d\u6742\u5d4c\u5957\u7c7b\u578b\u548c\u5e93\u7ea7\u522b\u7684\u4e00\u81f4\u6027\u4e0a\u8868\u73b0\u4e0d\u8db3\uff0c\u672a\u6765\u5e94\u5173\u6ce8\u63d0\u5347\u7c7b\u578b\u4e00\u81f4\u6027\u3002TypyBench\u4e3a\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u57fa\u51c6\u548c\u65b9\u5411\u3002"}}
{"id": "2507.22063", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22063", "abs": "https://arxiv.org/abs/2507.22063", "authors": ["Wenjie Jacky Mo", "Qin Liu", "Xiaofei Wen", "Dongwon Jung", "Hadi Askari", "Wenxuan Zhou", "Zhe Zhao", "Muhao Chen"], "title": "RedCoder: Automated Multi-Turn Red Teaming for Code LLMs", "comment": null, "summary": "Large Language Models (LLMs) for code generation (i.e., Code LLMs) have\ndemonstrated impressive capabilities in AI-assisted software development and\ntesting. However, recent studies have shown that these models are prone to\ngenerating vulnerable or even malicious code under adversarial settings.\nExisting red-teaming approaches rely on extensive human effort, limiting their\nscalability and practicality, and generally overlook the interactive nature of\nreal-world AI-assisted programming, which often unfolds over multiple turns. To\nbridge these gaps, we present RedCoder, a red-teaming agent that engages victim\nmodels in multi-turn conversation to elicit vulnerable code. The pipeline to\nconstruct RedCoder begins with a multi-agent gaming process that simulates\nadversarial interactions, yielding a set of prototype conversations and an\narsenal of reusable attack strategies. We then fine-tune an LLM on these\nprototype conversations to serve as the backbone of RedCoder. Once deployed,\nRedCoder autonomously engages Code LLMs in multi-turn conversations,\ndynamically retrieving relevant strategies from the arsenal to steer the\ndialogue toward vulnerability-inducing outputs. Experiments across multiple\nCode LLMs show that our approach outperforms prior single-turn and multi-turn\nred-team methods in inducing vulnerabilities in code generation, offering a\nscalable and effective tool for evaluating the security boundaries of modern\ncode-generation systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faRedCoder\u7cfb\u7edf\uff0c\u5229\u7528\u591aAgent\u535a\u5f08\u548c\u7b56\u7565\u5e93\uff0c\u5fae\u8c03LLM\u81ea\u52a8\u4e0e\u76ee\u6807\u4ee3\u7801\u751f\u6210\u6a21\u578b\u591a\u8f6e\u4ea4\u4e92\uff0c\u8bf1\u53d1\u5176\u8f93\u51fa\u542b\u6f0f\u6d1e\u4ee3\u7801\uff0c\u5b9e\u9a8c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u7ea2\u961f\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u5b89\u5168\u8bc4\u4f30\u6548\u7387\u548c\u5e7f\u5ea6\u3002", "motivation": "\u5f53\u524d\u7684\u4ee3\u7801\u751f\u6210\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08Code LLMs\uff09\u5728AI\u8f85\u52a9\u8f6f\u4ef6\u5f00\u53d1\u4e0e\u6d4b\u8bd5\u9886\u57df\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u5176\u5728\u5bf9\u6297\u6027\u573a\u666f\u4e0b\u6613\u751f\u6210\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\u751a\u81f3\u6076\u610f\u7684\u4ee3\u7801\u3002\u73b0\u6709\u7ea2\u961f\u6d4b\u8bd5\u65b9\u5f0f\u4f9d\u8d56\u5927\u91cf\u4eba\u5de5\u5e72\u9884\uff0c\u96be\u4ee5\u6269\u5c55\u4e14\u5ffd\u89c6\u4e86\u73b0\u5b9eAI\u7f16\u7a0b\u591a\u8f6e\u4ea4\u4e92\u7684\u7279\u70b9\u3002", "method": "\u63d0\u51faRedCoder\u7ea2\u961f\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u591aAgent\u5bf9\u6297\u6e38\u620f\u6a21\u62df\u653b\u51fb\u4ea4\u4e92\uff0c\u6536\u96c6\u5bf9\u8bdd\u539f\u578b\u4e0e\u653b\u51fb\u7b56\u7565\u3002\u518d\u4ee5\u5bf9\u8bdd\u539f\u578b\u5fae\u8c03LLM\uff0c\u6253\u9020\u53ef\u81ea\u52a8\u4e0e\u76ee\u6807\u6a21\u578b\u591a\u8f6e\u4ea4\u4e92\u3001\u52a8\u6001\u8c03\u7528\u7b56\u7565\u4ee5\u5f15\u5bfc\u6a21\u578b\u8f93\u51fa\u5b58\u5728\u6f0f\u6d1e\u4ee3\u7801\u7684\u7ea2\u961f\u667a\u80fd\u4f53\u3002", "result": "RedCoder\u53ef\u81ea\u4e3b\u4e0e\u591a\u79cdCode LLMs\u8fdb\u884c\u591a\u8f6e\u5bf9\u8bdd\uff0c\u52a8\u6001\u5229\u7528\u653b\u51fb\u7b56\u7565\u5f15\u5bfc\u76ee\u6807\u6a21\u578b\u751f\u6210\u6613\u53d7\u653b\u51fb\u4ee3\u7801\u3002\u5b9e\u9a8c\u663e\u793aRedCoder\u5728\u8bf1\u53d1\u4ee3\u7801\u6f0f\u6d1e\u80fd\u529b\u4e0a\u4f18\u4e8e\u73b0\u6709\u5355\u8f6e\u4e0e\u591a\u8f6e\u7ea2\u961f\u6d4b\u8bd5\u65b9\u6848\u3002", "conclusion": "RedCoder\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u81ea\u52a8\u5316\u7684\u65b9\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u73b0\u4ee3\u4ee3\u7801\u751f\u6210\u6a21\u578b\u5b89\u5168\u8fb9\u754c\u7684\u8bc4\u4f30\u80fd\u529b\u3002"}}
{"id": "2507.22536", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.22536", "abs": "https://arxiv.org/abs/2507.22536", "authors": ["Marco Peressotti"], "title": "Infinite Traces by Finality: a Sheaf-Theoretic Approach", "comment": null, "summary": "Kleisli categories have long been recognised as a setting for modelling the\nlinear behaviour of various types of systems. However, the final coalgebra in\nsuch settings does not, in general, correspond to a fixed notion of linear\nsemantics. While there are well-understood conditions under which final\ncoalgebras capture finite trace semantics, a general account of infinite trace\nsemantics via finality has remained elusive. In this work, we present a\nsheaf-theoretic framework for infinite trace semantics in Kleisli categories\nthat systematically constructs final coalgebras capturing infinite traces. Our\napproach combines Kleisli categories, sheaves over ordinals, and guarded\n(co)recursion, enabling infinite behaviours to emerge from coherent families of\nfinite approximations via amalgamation. We introduce the notion of guarded\nbehavioural functor and show that, under mild conditions, their final\ncoalgebras directly characterise infinite traces.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u6027\u7684sheaaf\u7406\u8bba\u65b9\u6cd5\uff0c\u7ed3\u5408Kleisli\u8303\u7574\u548cguarded\u9012\u5f52\uff0c\u6709\u6548\u6355\u6349\u5e76\u523b\u753b\u4e86\u7cfb\u7edf\u7684\u65e0\u9650\u8f68\u8ff9\u8bed\u4e49\uff0c\u5b8c\u5584\u4e86\u7ebf\u6027\u8bed\u4e49\u7684\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u5728Kleisli\u8303\u7574\u4e2d\uff0c\u5efa\u6a21\u5404\u79cd\u7cfb\u7edf\u7684\u7ebf\u6027\u884c\u4e3a\u662f\u4e00\u4e2a\u91cd\u8981\u4f46\u5c1a\u672a\u5b8c\u5168\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u5229\u7528\u7ec8\u4f59\u4ee3\u6570\uff08final coalgebra\uff09\u6355\u6349\u65e0\u9650\u8f68\u8ff9\u8bed\u4e49\u65b9\u9762\u8fd8\u5b58\u5728\u56f0\u96be\u3002\u4ee5\u5f80\u7684\u5de5\u4f5c\u5927\u591a\u5c40\u9650\u4e8e\u6709\u9650\u8f68\u8ff9\u8bed\u4e49\uff0c\u5bf9\u65e0\u9650\u60c5\u5f62\u7f3a\u4e4f\u7cfb\u7edf\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5c42\u53e0\u7406\u8bba\uff08sheaf-theoretic\uff09\u7684\u6846\u67b6\uff0c\u5c06Kleisli\u8303\u7574\u3001\u5e8f\u6570\u4e0a\u7684\u5c42\u53e0\u3001\u4fdd\u536b\uff08guarded\uff09(\u5171\u540c)\u9012\u5f52\u7ed3\u5408\uff0c\u4ece\u6709\u9650\u8fd1\u4f3c\u7684\u5408\u5e76\u4e2d\u7cfb\u7edf\u6027\u5730\u6784\u9020\u6355\u6349\u65e0\u9650\u8f68\u8ff9\u8bed\u4e49\u7684\u7ec8\u4f59\u4ee3\u6570\u3002\u7279\u522b\u5f15\u5165\u4e86\u4fdd\u536b\u884c\u4e3a\u51fd\u5b50\uff0c\u5e76\u5206\u6790\u5176\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\u7684\u6027\u8d28\u3002", "result": "\u5728\u6240\u63d0\u6846\u67b6\u548c\u9002\u5f53\u7684\u5047\u8bbe\u6761\u4ef6\u4e0b\uff0c\u6784\u9020\u51fa\u7684\u7ec8\u4f59\u4ee3\u6570\u53ef\u4ee5\u76f4\u63a5\u523b\u753b\u7cfb\u7edf\u7684\u65e0\u9650\u8f68\u8ff9\u8bed\u4e49\uff0c\u4ece\u800c\u4e3aKleisli\u8303\u7574\u4e2d\u65e0\u9650\u8f68\u8ff9\u63d0\u4f9b\u4e86\u4e00\u822c\u6027\u7684\u523b\u753b\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u9996\u6b21\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\uff0c\u5c06Kleisli\u8303\u7574\u4e0e\u5c42\u53e0\u7406\u8bba\u53ca\u4fdd\u536b(\u5171)\u9012\u5f52\u76f8\u7ed3\u5408\uff0c\u80fd\u591f\u81ea\u52a8\u6784\u9020\u5e76\u523b\u753b\u65e0\u9650\u8f68\u8ff9\u8bed\u4e49\u7684\u7ec8\u4f59\u4ee3\u6570\u3002\u62d3\u5c55\u4e86\u65e2\u6709\u6709\u9650\u8bed\u4e49\u7684\u7406\u89e3\uff0c\u4e3a\u7cfb\u7edf\u7684\u65e0\u9650\u884c\u4e3a\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u624b\u6bb5\u3002"}}
{"id": "2507.22159", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22159", "abs": "https://arxiv.org/abs/2507.22159", "authors": ["Vanessa Rebecca Wiyono", "David Anugraha", "Ayu Purwarianti", "Genta Indra Winata"], "title": "IndoPref: A Multi-Domain Pairwise Preference Dataset for Indonesian", "comment": "Preprint", "summary": "Over 200 million people speak Indonesian, yet the language remains\nsignificantly underrepresented in preference-based research for large language\nmodels (LLMs). Most existing multilingual datasets are derived from English\ntranslations, often resulting in content that lacks cultural and linguistic\nauthenticity. To address this gap, we introduce IndoPref, the first fully\nhuman-authored and multi-domain Indonesian preference dataset specifically\ndesigned to evaluate the naturalness and quality of LLM-generated text. All\nannotations are natively written in Indonesian and evaluated using\nKrippendorff's alpha, demonstrating strong inter-annotator agreement.\nAdditionally, we benchmark the dataset across multiple LLMs and assess the\noutput quality of each model.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u7531\u5370\u5c3c\u8bed\u6bcd\u8bed\u8005\u521b\u4f5c\u3001\u4e13\u7528\u4e8eLLM\u504f\u597d\u8bc4\u6d4b\u7684\u591a\u9886\u57df\u6570\u636e\u96c6IndoPref\uff0c\u4e3a\u5370\u5c3c\u8bed\u548c\u591a\u8bed\u8a00\u5927\u6a21\u578b\u7684\u8bc4\u4f30\u4e0e\u63d0\u5347\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u3002", "motivation": "\u5370\u5c3c\u8bed\u6709\u8d85\u8fc72\u4ebf\u4f7f\u7528\u8005\uff0c\u4f46\u5728\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u504f\u597d\u6027\u7814\u7a76\u4e2d\u5374\u4e25\u91cd\u7f3a\u4e4f\u4ee3\u8868\u6027\u3002\u73b0\u6709\u591a\u8bed\u8a00\u6570\u636e\u96c6\u5927\u591a\u6765\u6e90\u4e8e\u82f1\u6587\u7ffb\u8bd1\uff0c\u5bfc\u81f4\u5185\u5bb9\u7f3a\u4e4f\u6587\u5316\u4e0e\u8bed\u8a00\u7684\u771f\u5b9e\u6027\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u52a8\u673a\u662f\u89e3\u51b3\u5370\u5c3c\u8bed\u5728LLM\u504f\u597d\u6570\u636e\u4e2d\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u4f9b\u672c\u5730\u5316\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86IndoPref\uff0c\u8fd9\u662f\u9996\u4e2a\u5b8c\u5168\u7531\u4eba\u7c7b\u521b\u4f5c\u3001\u6db5\u76d6\u591a\u4e2a\u9886\u57df\u7684\u5370\u5c3c\u8bed\u504f\u597d\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u751f\u6210\u6587\u672c\u7684\u81ea\u7136\u6027\u4e0e\u8d28\u91cf\u3002\u6240\u6709\u6807\u6ce8\u5747\u7531\u5370\u5c3c\u8bed\u6bcd\u8bed\u4eba\u58eb\u4e66\u5199\uff0c\u5e76\u901a\u8fc7Krippendorff's alpha\u8fdb\u884c\u4e00\u81f4\u6027\u9a8c\u8bc1\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u5728\u591a\u4e2aLLM\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u8bc4\u4f30\u4e86\u5404\u6a21\u578b\u7684\u8f93\u51fa\u8d28\u91cf\u3002", "result": "IndoPref\u6570\u636e\u96c6\u7684\u6807\u6ce8\u663e\u793a\u4e86\u5f88\u5f3a\u7684\u4e00\u81f4\u6027\uff0c\u80fd\u6709\u6548\u8bc4\u4f30LLM\u7684\u6587\u672c\u751f\u6210\u8868\u73b0\u3002\u57fa\u4e8e\u8be5\u6570\u636e\u96c6\uff0c\u4e0d\u540cLLM\u5728\u5370\u5c3c\u8bed\u751f\u6210\u5185\u5bb9\u7684\u8d28\u91cf\u4e0a\u6709\u4e86\u6bd4\u8f83\u660e\u663e\u7684\u5bf9\u6bd4\u548c\u91cf\u5316\u6570\u636e\u3002", "conclusion": "IndoPref\u586b\u8865\u4e86\u5370\u5c3c\u8bedLLM\u8bc4\u6d4b\u6570\u636e\u96c6\u7684\u7a7a\u767d\uff0c\u4e3a\u540e\u7eed\u63d0\u5347LLM\u5728\u5370\u5c3c\u8bed\u53ca\u591a\u8bed\u8a00\u573a\u666f\u4e0b\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u6807\u51c6\u548c\u5b9e\u6d4b\u57fa\u7ebf\u3002\u8be5\u6210\u679c\u4e5f\u4e3a\u591a\u8bed\u8a00AI\u516c\u5e73\u6027\u3001\u771f\u5b9e\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u529b\u652f\u6301\u3002"}}
