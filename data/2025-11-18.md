<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]
- [cs.SE](#cs.SE) [Total: 7]
- [cs.LO](#cs.LO) [Total: 4]
- [cs.CL](#cs.CL) [Total: 5]
- [cs.FL](#cs.FL) [Total: 3]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Modular GPU Programming with Typed Perspectives](https://arxiv.org/abs/2511.11939)
*Manya Bansal,Daniel Sainati,Joseph W. Cutler,Saman Amarasinghe,Jonathan Ragan-Kelley*

Main category: cs.PL

TL;DR: 本文提出了GPU语言Prism，通过类型化视角解决了高性能集体操作与模块化编程的冲突，实现了既可安全模块化又不损失性能的GPU编程方案。


<details>
  <summary>Details</summary>
Motivation: 在现代GPU上实现峰值性能需要兼顾单线程行为控制和多线程协作操作，但这两者之间的冲突使得模块化编程容易出错。因此，亟需一种既能保证模块化，又能让程序员低层次控制集体操作的新方法。

Method: 提出了Prism这门新GPU语言，该语言通过类型化视角，在类型层面上明确程序员控制线程行为的粒度。包括Prism的设计、编译器实现以及理论基础（Bundl核心演算），并通过实现先进的GPU内核进行评估。

Result: Prism能为程序员提供安全保障，使其能够自信地编写模块化代码，同时不牺牲性能。其实测展现了对集体操作的低层次高效控制和优秀的模块化能力。

Conclusion: Prism语言解决了GPU编程中模块化和高性能集体操作间的矛盾，实现了安全且高效的程序开发方式。

Abstract: To achieve peak performance on modern GPUs, one must balance two frames of mind: issuing instructions to individual threads to control their behavior, while simultaneously tracking the convergence of many threads acting in concert to perform collective operations like Tensor Core instructions. The tension between these two mindsets makes modular programming error prone. Functions that encapsulate collective operations, despite being called per-thread, must be executed cooperatively by groups of threads.
  In this work, we introduce Prism, a new GPU language that restores modularity while still giving programmers the low-level control over collective operations necessary for high performance. Our core idea is typed perspectives, which materialize, at the type level, the granularity at which the programmer is controlling the behavior of threads. We describe the design of Prism, implement a compiler for it, and lay its theoretical foundations in a core calculus called Bundl. We implement state-of-the-art GPU kernels in Prism and find that it offers programmers the safety guarantees needed to confidently write modular code without sacrificing performance.

</details>


### [2] [The Search for Constrained Random Generators](https://arxiv.org/abs/2511.12253)
*Harrison Goldstein,Hila Peleg,Cassia Torczon,Daniel Sainati,Leonidas Lampropoulos,Benjamin C. Pierce*

Main category: cs.PL

TL;DR: 针对性质测试中的约束随机生成难题，作者提出了一种基于程序合成和递归变换的新方法，并在Lean定理证明器中实现了自动化生成器合成系统Palamedes，提高了测试用例的生成效率和覆盖度。


<details>
  <summary>Details</summary>
Motivation: 约束随机生成在性质测试中极具挑战性，尤其在满足谓词的值分布稀疏时，现有生成方法效率低下。高效自动生成满足约束的输入值，对于提高自动化测试工具（如PBT）的效果非常关键。

Method: 通过定义生成器的指称语义，设计一套合成规则，并利用Lean的证明搜索策略，自动合成能够正确生成满足约束条件的测试值的生成器。递归谓词采用消递归的方法（将谓词重写为消递归，并与相应的生递归匹配）。

Result: 提出了一种理论上简洁且表达力强的生成器自动合成方法；实现了Palamedes库，可扩展且易集成至Lean自动证明体系，有望改善复杂约束输入值的生成和性质测试的覆盖率。

Conclusion: 本文提出了使用程序合成思想来解决约束随机生成问题，并在Lean定理证明器上构建了一个原型系统Palamedes，实现自动化生成满足指定谓词的测试用例生成器。

Abstract: Among the biggest challenges in property-based testing (PBT) is the constrained random generation problem: given a predicate on program values, randomly sample from the set of all values satisfying that predicate, and only those values. Efficient solutions to this problem are critical, since the executable specifications used by PBT often have preconditions that input values must satisfy in order to be valid test cases, and satisfying values are often sparsely distributed.
  We propose a novel approach to this problem using ideas from deductive program synthesis. We present a set of synthesis rules, based on a denotational semantics of generators, that give rise to an automatic procedure for synthesizing correct generators. Our system handles recursive predicates by rewriting them as catamorphisms and then matching with appropriate anamorphisms; this is theoretically simpler than other approaches to synthesis for recursive functions, yet still extremely expressive.
  Our implementation, Palamedes, is an extensible library for the Lean theorem prover. The synthesis algorithm itself is built on standard proof-search tactics, reducing implementation burden and allowing the algorithm to benefit from further advances in Lean proof automation.

</details>


### [3] [Equivalence Checking of ML GPU Kernels](https://arxiv.org/abs/2511.12638)
*Kshitij Dubey,Benjamin Driscoll,Anjiang Wei,Neeraj Kayal,Rahul Sharma,Alex Aiken*

Main category: cs.PL

TL;DR: 本文提出了第一个GPU核函数等价性检查器VOLTA，能对手工、LLM和编译器优化的机器学习核函数进行形式化正确性验证，增强了深度学习GPU加速的可靠性与安全保障。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习和大语言模型的快速发展，公司在执行GPU核函数上的花费巨大，因此对这些核函数进行优化变得非常重要。目前，越来越多的研究利用大语言模型生成GPU核函数，但对于生成的核函数的正确性没有形式化保证。

Method: 作者提出了第一个用于GPU核函数等价性检查的工具，可用于形式化验证机器学习核函数（无论是手工优化、由LLM生成还是由编译器优化）。该工具可以验证卷积、矩阵乘法和注意力机制等机器学习计算的核函数正确性。

Result: 提出的等价性检查工具（VOLTA）能验证包括卷积、矩阵乘法和注意力机制等在内的各类GPU核函数。对于某一定义良好的GPU核函数类别，该工具是可靠且完备的。

Conclusion: 作者首次实现了GPU核函数的等价性检查，并利用其在手工、LLM及编译器优化的ML核函数上进行形式化验证，为深度学习加速与安全带来重要基础。

Abstract: With the rapid progress of deep learning and large language models (LLMs), companies now spend enormous sums executing GPU kernels. These kernels have, therefore, become prime targets for aggressive optimization. Recent efforts increasingly leverage LLMs to generate GPU kernels, but make no formal guarantees about the generated kernels. We present the first equivalence checker for GPU kernels and use it to formally verify the correctness of machine learning (ML) kernels optimized by hand, by LLMs, and by compilers. We show that our equivalence checker is sound and, for a well-defined class of GPU kernels which includes the programs of interest, complete. Our implementation, VOLTA, can verify ML computations such as convolutions, matrix multiplications, and various attention mechanisms.

</details>


### [4] [Cost-Driven Synthesis of Sound Abstract Interpreters](https://arxiv.org/abs/2511.13663)
*Qiuhan Gu,Avaljot Singh,Gagandeep Singh*

Main category: cs.PL

TL;DR: 本论文提出用LLM结合新的数学评价机制自动生成抽象解释器，实现神经网络验证，并有效生成具有高精度和可靠性的解释器，超越了手工设计的部分质量，显著简化了抽象解释中的难点。


<details>
  <summary>Details</summary>
Motivation: 构建能够提供全局可靠性保证的抽象解释器一直是抽象解释中的主要难题。作者希望通过利用现代大语言模型（LLM）来简化这一过程，自动生成高质量的抽象解释器。

Method: 作者把抽象解释器的合成建模为一个受约束的优化问题，并引入了新的数学基础成本函数来衡量不可靠性，同时施加严格的语法和语义约束。在此基础上，提出了统一的框架，将LLM生成、验证机制和基于成本反馈的优化结合起来。

Result: 实验证明，该框架不仅能达到手工设计解释器的质量，更重要的是能发现现有文献中缺乏的、针对复杂非线性算子的可靠高精度解释器。

Conclusion: 通过将LLM合成与数学和语义验证结合，作者框架能够高效地生成在多个抽象域下用于神经网络验证的高质量抽象解释器，有效降低构建全局可靠解释器的难度。

Abstract: Constructing abstract interpreters that provide global soundness guarantees remains a major obstacle in abstract interpretation. We investigate whether modern LLMs can reduce this burden by leveraging them to synthesize sound, non-trivial abstract interpreters across multiple abstract domains in the setting of neural network verification. We formulate synthesis as a constrained optimization problem and introduce a novel mathematically grounded cost function for measuring unsoundness under strict syntactic and semantic constraints. Based on this formulation, we develop a unified framework that unifies LLM-based generation with syntactic and semantic validation and a quantitative cost-guided feedback mechanism. Empirical results demonstrate that our framework not only matches the quality of handcrafted transformers, but more importantly, discovers sound, high-precision transformers for complex nonlinear operators that are absent from existing literature.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [5] [WITNESS: A lightweight and practical approach to fine-grained predictive mutation testing](https://arxiv.org/abs/2511.11999)
*Zeyu Lu,Peng Zhang,Chun Yong Chong,Shan Gao,Yibiao Yang,Yanhui Li,Lin Chen,Yuming Zhou*

Main category: cs.SE

TL;DR: 本文提出WITNESS方法，用轻量机器学习取代深度学习，支持方法内外变异体，有效提升变异体预测性能和效率，在实际测试优先级排序中近似真实表现，且更加可解释，优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 现有的细粒度预测变异测试方法主要依赖深度学习，但实际应用中存在高计算成本和适用范围受限两大问题。高昂的计算资源需求违背了降低成本的目标，而现有方法仅支持方法内部的变异体，无法处理方法外的变异体，限制了实际适用性。

Method: 提出了一种名为WITNESS的新型细粒度预测变异测试方法。WITNESS收集方法内外变异体的特征，适用于所有类型变异体，并采用轻量级的经典机器学习模型进行训练和预测，避免了深度学习带来的高计算成本。同时，这种方式便于解释模型决策过程。

Result: 在Defects4J项目上的评估显示，WITNESS在不同场景下稳定地实现了业界领先的预测性能，同时显著提升了kill matrix预测效率。事后分析指出，包含变异前后信息的特征对模型最为关键。基于预测kill matrix进行测试用例优先级排序时，结果接近实际kill matrix，优于基准方法。

Conclusion: WITNESS不仅解决了细粒度预测变异测试中的计算成本和适用性瓶颈，还在性能、效率和可解释性方面实现了突破，提升了变异测试工具的实际应用价值。

Abstract: Existing fine-grained predictive mutation testing studies predominantly rely on deep learning, which faces two critical limitations in practice: (1) Exorbitant computational costs. The deep learning models adopted in these studies demand significant computational resources for training and inference acceleration. This introduces high costs and undermines the cost-reduction goal of predictive mutation testing. (2) Constrained applicability. Although modern mutation testing tools generate mutants both inside and outside methods, current fine-grained predictive mutation testing approaches handle only inside-method mutants. As a result, they cannot predict outside-method mutants, limiting their applicability in real-world scenarios. We propose WITNESS, a new fine-grained predictive mutation testing approach. WITNESS adopts a twofold design: (1) With collected features from both inside-method and outside-method mutants, WITNESS is suitable for all generated mutants. (2) Instead of using computationally expensive deep learning, WITNESS employs lightweight classical machine learning models for training and prediction. This makes it more cost-effective and enabling straightforward explanations of the decision-making processes behind the adopted models. Evaluations on Defects4J projects show that WITNESS consistently achieves state-of-the-art predictive performance across different scenarios. Additionally, WITNESS significantly enhances the efficiency of kill matrix prediction. Post-hoc analysis reveals that features incorporating information from before and after the mutation are the most important among those used in WITNESS. Test case prioritization based on the predicted kill matrix shows that WITNESS delivers results much closer to those obtained by using the actual kill matrix, outperforming baseline approaches.

</details>


### [6] [A Code Smell Refactoring Approach using GNNs](https://arxiv.org/abs/2511.12069)
*HanYu Zhang,Tomoji Kishi*

Main category: cs.SE

TL;DR: 本研究通过采用GNN并结合半自动化的数据集生成，显著提升了长方法、大类和特征嫉妒等代码异味的自动重构效果，在多项基准上超过主流方法。


<details>
  <summary>Details</summary>
Motivation: 现有针对代码异味的重构方法存在不足，传统方法依赖手工定义的度量和规则，深度学习法受限于数据集和模型设计，因此亟需更有效的解决方案。

Method: 提出了一种基于图神经网络（GNN）的方法，通过构建类级和方法级的输入图，采用图分类和节点分类，针对三种常见代码异味（长方法、大类、特征嫉妒）进行重构，并利用半自动化数据集生成技术以扩大数据规模。实验使用了GCN、GraphSAGE和GAT三种GNN架构。

Result: 实验结果显示，该方法在重构性能上优于传统和先进的深度学习方法。

Conclusion: 基于图的深度学习方法为代码异味重构带来了有效且优异的解决方案，突破了传统方法的局限。

Abstract: Code smell is a great challenge in software refactoring, which indicates latent design or implementation flaws that may degrade the software maintainability and evolution. Over the past decades, a variety of refactoring approaches have been proposed, which can be broadly classified into metrics-based, rule-based, and machine learning-based approaches. Recent years, deep learning-based approaches have also attracted widespread attention. However, existing techniques exhibit various limitations. Metrics- and rule-based approaches rely heavily on manually defined heuristics and thresholds, whereas deep learning-based approaches are often constrained by dataset availability and model design. In this study, we proposed a graph-based deep learning approach for code smell refactoring. Specifically, we designed two types of input graphs (class-level and method-level) and employed both graph classification and node classification tasks to address the refactoring of three representative code smells: long method, large class, and feature envy. In our experiment, we propose a semi-automated dataset generation approach that could generate a large-scale dataset with minimal manual effort. We implemented the proposed approach with three classical GNN (graph neural network) architectures: GCN, GraphSAGE, and GAT, and evaluated its performance against both traditional and state-of-the-art deep learning approaches. The results demonstrate that proposed approach achieves superior refactoring performance.

</details>


### [7] [Actionable Warning Is Not Enough: Recommending Valid Actionable Warnings with Weak Supervision](https://arxiv.org/abs/2511.12229)
*Zhipeng Xue,Zhipeng Gao,Tongtong Xu,Xing Hu,Xin Xia,Shanping Li*

Main category: cs.SE

TL;DR: 论文针对静态分析工具虚警问题，提出了更准确的可执行警告数据集和高效推荐方法，并在实际项目验证了帮助开发者发现真实bug的能力。


<details>
  <summary>Details</summary>
Motivation: 静态分析工具因虚警率高而难以大规模应用。现有基于机器学习筛选可执行警告的方案，收集方式存在误差，导致大量无效警告。需要建立更准确的可执行警告数据集及高效推荐工具，帮助开发者从大量警告中快速定位真实bug。

Method: 构建了首个大规模可执行警告数据集（依据GitHub C项目的68,274次回滚），为每条可执行警告分配弱标签表征其为真实bug的可能性。提出两阶段框架ACWRecommender：先用预训练模型（UniXcoder）初步筛选，再基于弱监督学习对高概率真实bug的警告重新排序。

Result: 实验显示，ACWRecommender模型在nDCG和MRR两项指标上远超多个已有方法。在6个真实项目上验证，向开发者推荐的警告中，已有27项被确认是真实bug。工具有效提升开发者定位真实bug的效率。

Conclusion: 提出的方法和数据集显著提升了静态分析警告的实用性，有助于推动静态分析工具的实际落地应用。

Abstract: The use of static analysis tools has gained increasing popularity among developers in the last few years. However, the widespread adoption of static analysis tools is hindered by their high false alarm rates. Previous studies have introduced the concept of actionable warnings and built a machine-learning method to distinguish actionable warnings from false alarms. However, according to our empirical observation, the current assumption used for actionable warning(s) collection is rather shaky and inaccurate, leading to a large number of invalid actionable warnings. To address this problem, in this study, we build the first large actionable warning dataset by mining 68,274 reversions from Top-500 GitHub C repositories, we then take one step further by assigning each actionable warning a weak label regarding its likelihood of being a real bug. Following that, we propose a two-stage framework called ACWRecommender to automatically recommend the actionable warnings with high probability to be real bugs (AWHB). Our approach warms up the pre-trained model UniXcoder by identifying actionable warnings task (coarse-grained detection stage) and rerank AWHB to the top by weakly supervised learning (fine-grained reranking stage). Experimental results show that our proposed model outperforms several baselines by a large margin in terms of nDCG and MRR for AWHB recommendation. Moreover, we ran our tool on 6 randomly selected projects and manually checked the top-ranked warnings from 2,197 reported warnings, we reported top-10 recommended warnings to developers, 27 of them were already confirmed by developers as real bugs. Developers can quickly find real bugs among the massive amount of reported warnings, which verifies the practical usage of our tool.

</details>


### [8] [Reflections on the design, applications and implementations of the normative specification language eFLINT](https://arxiv.org/abs/2511.12276)
*L. Thomas van Binsbergen,Christopher A. Esterhuyse,Tim Müller*

Main category: cs.SE

TL;DR: 本文介绍并评估了eFLINT领域特定语言在自动化软件合规检查中的应用，分析了其设计流程、面临的需求与挑战，并总结了有益的设计经验。


<details>
  <summary>Details</summary>
Motivation: 随着软件与社会实践的紧密融合，法律、法规和合同的合规检查变得越来越重要且成本高昂。不断增长的数字化服务带来更多相关法规，迫切需要高度灵活的合规实践，自动化合规检查成为一种潜在解决方案。但自动化受限于法律解释的主观性、法规的不断变化，以及跨学科知识需求。

Method: 本文反思并探讨了为自动化合规实验所开发的特定领域软件语言eFLINT。该语言融合了声明式与过程式元素，能够对应静态情况和动态场景，用于明确和形式化法律与计算的联系，并能在系统运行前、中、后各阶段自动检查合规性。文章回顾了应用案例、需求及设计决策。

Result: eFLINT语言能够针对不同的目标和应用领域满足各种（甚至相互冲突的）需求。论文总结了eFLINT应用过程中得到的结果、洞见以及影响语言设计的关键因素，这些都为同行开发自动化合规相关语言带来借鉴意义。

Conclusion: eFLINT语言实现了法律概念与计算概念的形式化表达，为自动化合规提供了有效工具，其设计经验对自动化合规领域的语言开发者具有参考价值。

Abstract: Checking the compliance of software against laws, regulations and contracts is increasingly important and costly as the embedding of software into societal practices is getting more pervasive. Moreover, the digitalised services provided by governmental organisations and companies are governed by an increasing amount of laws and regulations, requiring highly adaptable compliance practices. A potential solution is to automate compliance using software. However, automating compliance is difficult for various reasons. Legal practices involve subjective processes such as interpretation and qualification. New laws and regulations come into effect regularly and laws and regulations, as well as their interpretations, are subjected to constant revision. In addition, computational reasoning with laws requires a cross-disciplinary process involving both legal and software expertise.
  This paper reflects on the domain-specific software language eFLINT developed to experiment with novel solutions. The language combines declarative and procedural elements to reason about situations and scenarios respectively, explicates and formalises connections between legal concepts and computational concepts, and is designed to automate compliance checks both before, during and after a software system runs. The various goals and applications areas for the language give rise to (conflicting) requirements. This paper reflects on the current design of the language by recalling various applications, the requirements they imposed, and subsequent design decisions. As such, this paper reports on results and insights of an investigation that can benefit language developers within the field of automated compliance.

</details>


### [9] [Reducing Hallucinations in LLM-Generated Code via Semantic Triangulation](https://arxiv.org/abs/2511.12288)
*Yihan Dai,Sijie Liang,Haotian Xu,Peichu Xie,Sergey Mechtaev*

Main category: cs.SE

TL;DR: 提出了‘语义三角测量’以提高代码生成共识的可靠性，能更好识别低采样概率和多等价解场景下的正确代码，比传统方法提升了21%可靠性，并支持多答案共识和智能弃权。


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成代码时，样本共识技术（如投票、自动生成测试）用于筛选正确代码，但在正确解采样概率低或存在多个等价解时表现不佳，且在没有正确解时难以自动弃权。

Method: 提出了‘语义三角测量’方法，通过对编程问题进行语义改变但仍可映射的变换，比较变换前后的解的一致性，从而提升模型判定正确解/弃权的能力；并用理论和实验验证其有效性。

Result: 在LiveCodeBench和CodeElo基准上，GPT-4o与DeepSeek-V3采样时，语义三角测量相比概率阈值法（0.5）可提高21%的可靠性，并能指出低至0.14采样概率的正确解，也是唯一能在有多个非等价答案时达到真正共识的方法。

Conclusion: 语义三角测量显著提升了LLM代码生成共识的可靠性，使模型更能筛选出泛化性强的代码，并能在采样概率低、解多样时更好筛选/弃权，解决了传统方法的缺陷。

Abstract: When generating code from natural language prompts, an LLM samples programs from a probability distribution, many of which might be incorrect. Sample consensus techniques - such as majority voting or validation against generated tests or specifications - aim to identify a correct program in the sample or abstain if none is valid. However, existing methods often fail to select a correct solution when its sampling probability is low, or when the problem permits multiple valid but non-equivalent solutions. Additionally, they often fail to abstain when no correct solution is present in the sample. To overcome these limitations, we introduce semantic triangulation, which transforms a programming problem in a way that non-trivially alters its semantics while preserving an exact, verifiable mapping between solutions before and after transformation. We theoretically establish that verifying consistency across such problem transformations increases confidence that generated programs reflect accurate generalization rather than spurious statistical correlations, enabling more reliable sample consensus and abstention. On the LiveCodeBench and CodeElo benchmarks, using GPT-4o and DeepSeek-V3 models, semantic triangulation increases reliability of generated code by 21% compared to the method that selects only high-confidence solutions with the probability threshold 0.5, while being able to pinpoint correct solutions at sampling probabilities as low as 0.14. Apart from that, it is also the only approach to consistently form true consensus on tasks with multiple valid but non-equivalent solutions.

</details>


### [10] [ProofWright: Towards Agentic Formal Verification of CUDA](https://arxiv.org/abs/2511.12294)
*Bodhisatwa Chatterjee,Drew Zagieboylo,Sana Damani,Siva Hari,Christos Kozyrakis*

Main category: cs.SE

TL;DR: 本文针对LLM自动生成GPU代码存在的可靠性与验证效率瓶颈，提出集成自动形式化验证与代码生成的新框架ProofWright。在保证开发者效率的同时，大幅提升了生成代码的安全性和正确性，为高性能代码可信自动生成奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM能够高效生成CUDA内核代码，但这些自动化生成的代码常常包含难以察觉的正确性错误，传统的测试和人工验证方法难以可靠且高效地匹配生成速度，因此存在验证瓶颈。

Method: 将自动化的形式化验证与LLM驱动的代码生成相结合，构建了一个agent化的验证流程，对生成的CUDA内核进行全面安全与正确性检查。

Result: 在KernelBench L1基准下，ProofWright对74%的内核成功完成安全验证，发现了常规测试遗漏的微妙错误，并在特定类型的内核上验证了语义等价性，每个内核平均验证耗时仅3分钟，展示了高效可扩展的性能。

Conclusion: 本文提出了ProofWright框架，实现了可扩展的自动化形式化验证，为LLM生成的CUDA内核代码在内存安全、线程安全和语义正确性上提供可靠保障。

Abstract: Large Language Models (LLMs) are increasingly used to automatically generate optimized CUDA kernels, substantially improving developer productivity. However, despite rapid generation, these kernels often contain subtle correctness bugs and lack formal safety guarantees. Runtime testing is inherently unreliable - limited input coverage and reward hacking can mask incorrect behavior - while manual formal verification is reliable but cannot scale to match LLM output rates, creating a critical validation bottleneck.
  We present ProofWright, an agentic verification framework that bridges this gap by integrating automated formal verification with LLM-based code generation. ProofWright provides end-to-end guarantees of memory safety, thread safety, and semantic correctness for LLM-generated CUDA kernels. On KernelBench L1, ProofWright verifies safety properties for 74% of generated kernels, uncovers subtle correctness errors missed by conventional testing, and establishes semantic equivalence for a class of element-wise kernels. With a modest overhead of 3 minutes per kernel, ProofWright demonstrates that scalable, automated formal verification of LLM-generated GPU code is feasible - offering a path toward trustworthy high-performance code generation without sacrificing developer productivity.

</details>


### [11] [High-level reasoning while low-level actuation in Cyber-Physical Systems: How efficient is it?](https://arxiv.org/abs/2511.12543)
*Burak Karaduman,Baris Tekin Tezel,Moharram Challenger*

Main category: cs.SE

TL;DR: 本文系统比较六种主流编程语言与框架在工业集成环境中的开发效率与运行时性能，揭示了抽象层级与推理机制对性能和工作量的影响，为工程师工具选择提供实证参考。


<details>
  <summary>Details</summary>
Motivation: 工业信息集成系统日益复杂，工程师在选择适合高级工业应用的软件开发工具时缺乏足够的实证依据，尤其是在智能行为、实时响应和高效开发方面。本文旨在为此提供数据支持。

Method: 本文以开发者为中心，测量并对比六种编程语言和框架（C++、Java、Jade、Jason、含符号和模糊推理机制的Jason BDI）在最坏情况执行时间（WCET）和开发时间上的表现，涵盖从传统过程式、面向对象到基于智能体的框架。分析抽象层级提升和推理能力增强对开发投入与系统运行的影响。

Result: 实验结果揭示抽象层级与推理机制对系统性能和开发者生产力具有显著影响，具体展现出开发工作量和执行效率之间的权衡。

Conclusion: 本研究为智能体和智能制造等复杂工业应用的软件技术选择提供了基于实证的数据和参考，支持集成效率、可维护性和响应能力提升，并为未来进一步研究语言特性、开发动态与运行行为间关系奠定了基础。

Abstract: The increasing complexity of industrial information-integration systems demands software technologies that enable intelligent behaviour, real-time response, and efficient development. Although many programming languages and frameworks exist, engineers still lack sufficient empirical evidence to guide the choice of tools for advanced industrial applications. This study addresses that need by measuring and comparing worst-case execution time (WCET) and development time across six languages and frameworks: C++, Java, Jade, Jason, and fuzzy Jason BDI with both loosely and tightly coupled integration. These technologies reflect a progression from procedural and object-oriented programming to agent-based frameworks capable of symbolic and fuzzy reasoning.
  Rather than relying on broad concepts such as paradigms or orientations, the study adopts a developer-centred approach grounded in measurable outcomes. The structured comparison examines how rising abstraction levels and reasoning capabilities affect both development effort and runtime behaviour. By analysing these dimensions, the study highlights concrete trade-offs between engineering workload and execution efficiency.
  The findings show how abstraction and reasoning mechanisms shape system performance and developer productivity, offering practical insight for designing intelligent, agent-based solutions that must operate under real-time constraints and complex decision-making requirements. Overall, the study contributes evidence-based guidance for selecting software technologies in industrial informatization, supporting improved integration efficiency, maintainability, and responsiveness, and laying groundwork for future research on the interplay between language features, development dynamics, and runtime behaviour in cyber-physical and smart manufacturing systems.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [12] [A Logspace Constructive Proof of L=SL](https://arxiv.org/abs/2511.12011)
*Sam Buss,Anant Dhayal,Valentine Kabanets,Antonina Kolokolova,Sasank Mouli*

Main category: cs.LO

TL;DR: 本文将SL=L定理的证明形式化到VL理论，突破了以往证明中的技术障碍，并成功证明了VL=VSL，解决了复杂性理论中的一项老问题。


<details>
  <summary>Details</summary>
Motivation: 旨在将空间复杂性理论中的重要结果（SL=L）的证明形式化到对应的有界算术理论，推进理论基础，为相关复杂性类之间的关系提供严格证明，同时回应长期的公开问题。

Method: 采用Rozenman-Vadhan对Reingold定理的替代证明，并通过组合方法（Buss等人的成果），避免了对特征值和特征向量的讨论，实现了在VL理论框架下的形式化。

Result: 成功在VL理论中形式化了SL=L，并得到VL=VSL，解决了Kolokolova提出的公开问题，为有界算术中的对称与一般对数空间推理建立了联系。

Conclusion: 本文在有界算术理论VL中形式化了Reingold定理（SL=L）的证明，并由此得出VL=VSL，从而解决了一个长期开放问题。

Abstract: We formalize the proof of Reingold's Theorem that SL=L [Rei05] in the theory of bounded arithmetic VL, which corresponds to ``logspace reasoning''. As a consequence, we get that VL=VSL, where VSL is the theory of bounded arithmetic for ``symmetric-logspace reasoning''. This resolves in the affirmative an old open question from Kolokolova [Kol05] (see also Cook-Nguyen [NC10]).
  Our proof relies on the Rozenman-Vadhan alternative proof of Reingold's Theorem ([RV05]). To formalize this proof in VL, we need to avoid reasoning about eigenvalues and eigenvectors (common in both original proofs of SL=L). We achieve this by using some results from Buss-Kabanets-Kolokolova-Koucký [Bus+20] that allow VL to reason about graph expansion in combinatorial terms.

</details>


### [13] [Proceedings Seventh International Workshop on Formal Methods for Autonomous Systems](https://arxiv.org/abs/2511.13245)
*Matt Luckcuck,Maike Schwammberger,Mengwei Xu*

Main category: cs.LO

TL;DR: FMAS 2025集中展示了全球自主系统形式化方法领域的研究进展，社区影响力及国际参与度持续提升，虽投稿数减少但新老作者积极参与，展现领域发展的活力和前景。


<details>
  <summary>Details</summary>
Motivation: 自主系统日益普及，相关独特挑战亟需通过形式化方法加以应对。FMAS研讨会旨在汇聚领域顶尖研究者，共同交流和推动形式化方法在自主系统中的应用与发展。

Method: 通过举办国际性研讨会，征集并筛选全球研究者在自主系统形式化方法方向的最新成果与经验。

Result: FMAS 2025共收到来自全球12个国家和地区的16篇投稿，涵盖老作者及新作者，反映出社区的凝聚力以及潜在的增长动力，虽然投稿数较去年略少，但国际参与度在上升。

Conclusion: FMAS社区继续保持活跃，网络影响力增强，吸引了来自全球的新老学者，未来发展潜力巨大。

Abstract: This EPTCS volume contains the papers from the Seventh International Workshop on Formal Methods for Autonomous Systems (FMAS 2025), which was held between the 17th and 19th of November 2025. The goal of the FMAS workshop series is to bring together leading researchers who are using formal methods to tackle the unique challenges that autonomous systems present, so that they can publish and discuss their work with a growing community of researchers. FMAS 2025 was co-located with the 20th International Conference on integrated Formal Methods (iFM'25), hosted by Inria Paris, France at the Inria Paris Center. 
  In total, FMAS 2025 received 16 submissions from researchers at institutions in: Canada, China, France, Germany, Ireland, Italy, Japan, the Netherlands, Portugal, Sweden, the United States of America, and the United Kingdom. Though we received fewer submissions than last year, we are encouraged to see the submissions being sent from a wide range of countries. Submissions come from both past and new FMAS authors, which shows us that the existing community appreciates the network that FMAS has built over the past 7 years, while new authors also show the FMAS community's great potential of growth.

</details>


### [14] [Multi-Objective Statistical Model Checking using Lightweight Strategy Sampling (extended version)](https://arxiv.org/abs/2511.13460)
*Pedro R. D'Argenio,Arnd Hartmanns,Patrick Wienhöft,Mark van Wijk*

Main category: cs.LO

TL;DR: 本文突破传统统计模型检查只支持单一属性验证的限制，首次提出并实现适用于多目标优化的统计模型检查方案，使用轻量采样和启发式策略，有效逼近真实Pareto前沿，经实验验证方法实用且高效。


<details>
  <summary>Details</summary>
Motivation: 以往的统计模型检查方法只能评估单一属性值，而现实中许多问题需要在多目标间寻求最优权衡（Pareto前沿）。针对这一需求，现有方法尚不能有效处理多目标优化。

Method: 提出首个适用于多目标Pareto查询的统计模型检查方法，通过轻量级策略采样在模型的不确定选择上进行优化。包含递增式方案，最终收敛于可信区间包围真实Pareto前沿，以及三种启发式方法，用于在有限采样预算下尽可能接近真实前沿。

Result: 将方法实现于Modest Toolset工具的'modes'仿真器，并在定量验证基准上进行了实验，实验证明新方法具有有效性。

Conclusion: 论文首次实现了多目标Pareto查询的统计模型检查，并验证了所提出方法在实际问题中的有效性。

Abstract: Statistical model checking delivers quantitative verification results with statistical guarantees by applying Monte Carlo simulation to formal models. It scales to model sizes and model types that are out of reach for exhaustive, analytical techniques. So far, it has been used to evaluate one property value at a time only. Many practical problems, however, require finding the Pareto front of optimal tradeoffs between multiple possibly conflicting optimisation objectives. In this paper, we present the first statistical model checking approach for such multi-objective Pareto queries, using lightweight strategy sampling to optimise over the model's nondeterministic choices. We first introduce an incremental scheme that almost surely converges to a statistically sound confidence band bounding the true Pareto front from both sides in the long run. To obtain a close underapproximation of the true front in finite time, we then propose three heuristic approaches that try to make the best of an a-priori fixed sampling budget. We implement our new techniques in the Modest Toolset's 'modes' simulator, and experimentally show their effectiveness on quantitative verification benchmarks.

</details>


### [15] [Subgraph Isomorphism: Prolog vs. Conventional](https://arxiv.org/abs/2511.13600)
*Claire Y. Yin,Peter M. Kogge*

Main category: cs.LO

TL;DR: 通过对比逻辑编程与常规编程解决子图同构问题的复杂性，发现逻辑编程如Prolog在处理复杂图模式和大规模图时更高效。


<details>
  <summary>Details</summary>
Motivation: 比较在逻辑编程（如Prolog）和传统编程方式下解决子图同构问题的复杂性差异。

Method: 将较为复杂的特定图模式转化为Prolog逻辑语句，并与传统（包括并行）实现进行对比，分析随图规模增加的特性。

Result: 分析结果显示，逻辑编程范式处理复杂图问题时具有高效性。

Conclusion: 针对复杂图模式，使用逻辑编程（例如Prolog）是一种高效的解决方案，尤其在图规模增加时表现突出。

Abstract: Subgraph Isomorphism uses a small graph as a pattern to identify within a larger graph a set of vertices that have matching edges. This paper addresses a logic program written in Prolog for a specific relatively complex graph pattern for which multiple conventional implementations (including parallel) exist. The goal is to understand the complexity differences between programming logically and programming conventionally. Discussion includes the process of converting the graph pattern into logic statements in Prolog, and the resulting characteristics as the size of the graph increased. The analysis shows that using a logic paradigm is an efficient way to attack complex graph problems.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [16] [TimeStampEval: A Simple LLM Eval and a Little Fuzzy Matching Trick to Improve Search Accuracy](https://arxiv.org/abs/2511.11594)
*James McCammon*

Main category: cs.CL

TL;DR: 针对不能逐字匹配的引用定位难题，提出基于预筛选和LLM验证的两阶段方法，大幅提升准确率和效率，在多领域、多长度的语音转录文本上表现优异，适合AI内容自动拼接等应用。


<details>
  <summary>Details</summary>
Motivation: 现有的模糊匹配方法在对比官方文稿和语音转录文本时，难以处理语义相同但句法不同的引用，因此对非逐字引用的精准定位成为急需解决的问题。这对于自动化播客内容制作等场景尤为重要。

Method: 提出TimeStampEval基准，并设计了一个简单的两阶段方法：首先用RapidFuzz对长文本进行预筛选，然后再通过大语言模型（LLM）对短片段进行精准边界判定。还通过对提示词设计、推理长度等要素进行系统实验。

Result: 新方法大幅提升了召回和准确率，对弱设定从37%提高到77%，强设定可超过90%；‘Assisted Fuzzy’方法提高了模糊匹配准确性高达50个点，并将推理成本和延迟削减了90%以上；针对不存在的目标还能保持95-100%的拒绝率。此外，对不同长度、领域的10份历史文档测试，方法表现出良好的稳健性。

Conclusion: 提出了适用于非逐字引用精准定位的有效解决方案（Assisted Fuzzy方法），显著提高了大规模语音文本比对任务中的效率与准确度，推动了AI内容拼接等应用的发展。

Abstract: Traditional fuzzy matching often fails when searching for quotes that are semantically identical but syntactically different across documents-a common issue when aligning official written records with speech-to-text transcripts. We introduce TimeStampEval, a benchmark for retrieving precise millisecond timestamps from long transcripts given non-verbatim quotes. Our simple two-stage method dramatically improves retrieval accuracy while cutting inference costs by over 90%. The motivating use case is an automated long-form podcast that assembles Congressional Record clips into AI-hosted narration. The technical challenge: given a sentence-timestamped transcript and a target quote that may differ due to transcription or editorial drift, return exact start and end boundaries. Standard algorithms handle verbatim text but break under fuzzier variants. Evaluating six modern LLMs on a 2,800-sentence (120k-token) transcript revealed four key findings. (1) Prompt design matters more than model choice: placing the query before the transcript and using compact formatting improved accuracy by 3-20 points while reducing token count by 30-40%. (2) Off-by-one errors form a distinct category, showing models understand the task but misplace boundaries. (3) A modest reasoning budget (600-850 tokens) raises accuracy from 37% to 77% for weak setups and to above 90% for strong ones. (4) Our "Assisted Fuzzy" approach-RapidFuzz pre-filtering followed by LLM verification on short snippets-improves fuzzy match accuracy by up to 50 points while halving latency and reducing cost per correct result by up to 96%. Extended tests on ten transcripts (50k-900k tokens, 1989-2025) confirm robustness to transcript length, vocabulary drift, and domain change, maintaining 95-100% rejection accuracy for absent targets.

</details>


### [17] [MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling](https://arxiv.org/abs/2511.11793)
*MiroMind Team,Song Bai,Lidong Bing,Carson Chen,Guanzheng Chen,Yuntao Chen,Zhe Chen,Ziyi Chen,Jifeng Dai,Xuan Dong,Yue Deng,Yunjie Fu,Junqi Ge,Chenxia Han,Tammy Huang,Zhenhang Huang,Jerry Jiao,Shilei Jiang,Tianyu Jiao,Xiaoqi Jian,Lei Lei,Ruilin Li,Ryan Luo,Tiantong Li,Xiang Lin,Ziyuan Liu,Zhiqi Li,Jie Ni,Qiang Ren,Pax Sun,Shiqian Su,Chenxin Tao,Bin Wang,Hellen Wang,Haonan Wang,James Wang,Jin Wang,Jojo Wang,Letian Wang,Shizun Wang,Weizhi Wang,Zixuan Wang,Jinfan Xu,Sen Xing,Chenyu Yang,Hai Ye,Jiaheng Yu,Yue Yu,Muyan Zhong,Tianchen Zhao,Xizhou Zhu,Yanpeng Zhou,Yifan Zhang,Zhi Zhu*

Main category: cs.CL

TL;DR: MiroThinker v1.0通过强化学习实现交互规模扩展，并在多项基准超越开源智能体，接近商用模型表现。交互扩展被证实是推动智能体进步的第三重要因素。


<details>
  <summary>Details</summary>
Motivation: 目前的研究型智能体主要通过增大模型规模或增加上下文长度来提升性能，但这些方法有局限。例如，长链推理易发生性能退化。因此，作者旨在探索更高效的智能体交互扩展方式。

Method: 提出并训练了MiroThinker v1.0，采用强化学习，使模型能在256K上下文窗口下进行多达600次工具调用，并利用环境反馈和外部信息矫正推理过程。实验选用GAIA、HLE、BrowseComp和BrowseComp-ZH等代表性基准进行评测。

Result: MiroThinker 72B在四大基准上分别取得了81.9%、37.7%、47.1%、55.6%的准确率，超越了现有开源方案，且接近GPT-5-high等商用强模型。实验表明，交互扩展明显提升智能体长期、多轮研究表现。

Conclusion: 交互扩展（interaction scaling）被确立为提升开放研究智能体性能的第三个关键维度，和模型容量、上下文窗口互为补充，为下一代研究型智能体的发展提供了新方向。

Abstract: We present MiroThinker v1.0, an open-source research agent designed to advance tool-augmented reasoning and information-seeking capabilities. Unlike previous agents that only scale up model size or context length, MiroThinker explores interaction scaling at the model level, systematically training the model to handle deeper and more frequent agent-environment interactions as a third dimension of performance improvement. Unlike LLM test-time scaling, which operates in isolation and risks degradation with longer reasoning chains, interactive scaling leverages environment feedback and external information acquisition to correct errors and refine trajectories. Through reinforcement learning, the model achieves efficient interaction scaling: with a 256K context window, it can perform up to 600 tool calls per task, enabling sustained multi-turn reasoning and complex real-world research workflows. Across four representative benchmarks-GAIA, HLE, BrowseComp, and BrowseComp-ZH-the 72B variant achieves up to 81.9%, 37.7%, 47.1%, and 55.6% accuracy respectively, surpassing previous open-source agents and approaching commercial counterparts such as GPT-5-high. Our analysis reveals that MiroThinker benefits from interactive scaling consistently: research performance improves predictably as the model engages in deeper and more frequent agent-environment interactions, demonstrating that interaction depth exhibits scaling behaviors analogous to model size and context length. These findings establish interaction scaling as a third critical dimension for building next-generation open research agents, complementing model capacity and context windows.

</details>


### [18] [On the Notion that Language Models Reason](https://arxiv.org/abs/2511.11810)
*Bertram Højer*

Main category: cs.CL

TL;DR: 语言模型产生类推理输出其实是统计规律匹配结果，而非拥有真正的逻辑推理机制，应谨慎理解并重视模型机制的描述与定义。


<details>
  <summary>Details</summary>
Motivation: 目前自然语言处理领域认为语言模型具有推理能力，但“推理”究竟意味着什么？动机在于分析现有关于推理的定义，以及这些定义是否真的适用于语言模型的实际工作原理。

Method: 通过梳理推理的定义以及相关关键论文，并提出假设：基于transformer的语言模型可视为实现了一个隐式有限阶马尔可夫核，将上下文映射至条件token分布。进而将语言模型表现出的“推理”理解为统计规律和近似统计不变性，而非真正的逻辑推理机制。

Result: 提出语言模型更像是“统计模式匹配器”而不是具备真实推理能力的系统。用统计学习理论解释了为何模型能产生类推理输出，但这些输出并不保证逻辑一致性。强调应重新审视语言模型的推理能力定义与其实际机制之间的差异。

Conclusion: 当前关于语言模型推理能力的表述与其真实底层机制不一致。语言模型输出的类推理结果来源于统计规律匹配而非真实的逻辑推理，需在NLP研究中更加关注和澄清此类定义与模型实际过程的描绘。

Abstract: Language models (LMs) are said to be exhibiting reasoning, but what does this entail? We assess definitions of reasoning and how key papers in the field of natural language processing (NLP) use the notion and argue that the definitions provided are not consistent with how LMs are trained, process information, and generate new tokens. To illustrate this incommensurability we assume the view that transformer-based LMs implement an \textit{implicit} finite-order Markov kernel mapping contexts to conditional token distributions. In this view, reasoning-like outputs correspond to statistical regularities and approximate statistical invariances in the learned kernel rather than the implementation of explicit logical mechanisms. This view is illustrative of the claim that LMs are "statistical pattern matchers"" and not genuine reasoners and provides a perspective that clarifies why reasoning-like outputs arise in LMs without any guarantees of logical consistency. This distinction is fundamental to how epistemic uncertainty is evaluated in LMs. We invite a discussion on the importance of how the computational processes of the systems we build and analyze in NLP research are described.

</details>


### [19] [Towards Autoformalization of LLM-generated Outputs for Requirement Verification](https://arxiv.org/abs/2511.11829)
*Mihir Gupte,Ramesh S*

Main category: cs.CL

TL;DR: 本文初步探索了使用LLM辅助的autoformalizer实现对自然语言需求和LLM输出进行一致性与逻辑检验，实验显示其具有发现逻辑等价与不一致的能力，为后续相关研究提供了方向。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型(LLM)的发展，将自然语言转化为形式化逻辑（autoformalization）变得日益重要，尤其是在需要验证LLM输出准确性的场景下。当前缺乏正式方法来判断LLM生成的结构化输出是否与原始需求一致。

Method: 本文探索了一种基于简单LLM的autoformalizer，通过对比自然语言需求与LLM输出，进行一致性和逻辑性验证。作者设计了两个实验：第一个检验不同表述的需求在逻辑上的等价性，第二个检测需求与生成输出之间的逻辑矛盾。

Result: 实验结果表明，autoformalizer能够识别不同表述之间的逻辑等价性，并能发现自然语言需求与LLM输出之间的逻辑不一致，展示了autoformalizer作为形式化验证工具的效用。

Conclusion: 尽管本研究规模有限，但autoformalization在提升LLM输出准确性与一致性方面展现出巨大潜力，为未来更深入的研究奠定了基础。

Abstract: Autoformalization, the process of translating informal statements into formal logic, has gained renewed interest with the emergence of powerful Large Language Models (LLMs). While LLMs show promise in generating structured outputs from natural language (NL), such as Gherkin Scenarios from NL feature requirements, there's currently no formal method to verify if these outputs are accurate. This paper takes a preliminary step toward addressing this gap by exploring the use of a simple LLM-based autoformalizer to verify LLM-generated outputs against a small set of natural language requirements. We conducted two distinct experiments. In the first one, the autoformalizer successfully identified that two differently-worded NL requirements were logically equivalent, demonstrating the pipeline's potential for consistency checks. In the second, the autoformalizer was used to identify a logical inconsistency between a given NL requirement and an LLM-generated output, highlighting its utility as a formal verification tool. Our findings, while limited, suggest that autoformalization holds significant potential for ensuring the fidelity and logical consistency of LLM-generated outputs, laying a crucial foundation for future, more extensive studies into this novel application.

</details>


### [20] [Scaling Open-Weight Large Language Models for Hydropower Regulatory Information Extraction: A Systematic Analysis](https://arxiv.org/abs/2511.11821)
*Hong-Jun Yoon,Faisal Ashraf,Thomas A. Ruggles,Debjani Singh*

Main category: cs.CL

TL;DR: 在水力发电合规文件信息抽取中，只有达到14B参数规模的模型，性能和验证才具备实际部署价值，小模型性能有限且易出错，大模型虽优秀但资源要求高。论文首次系统地量化了模型规模、性能和资源消耗的关系，为信息抽取任务模型选择提供了实证参考。


<details>
  <summary>Details</summary>
Motivation: 在监管文件中进行信息抽取任务，需要在模型性能与计算资源之间权衡。研究者希望通过评估不同规模的大型语言模型，为实际部署提供决策依据，特别是在水力发电许可相关文档领域。

Method: 评估了7个参数规模在0.6B到70B之间的开源大语言模型，对水力发电许可文件进行信息抽取，并分析模型性能及资源消耗之间的关系。重点考察模型在不同参数规模下的表现，并揭示F1值随参数数量变化的规律。

Result: 发现参数规模达到14B时，验证方法的效果才由无效（F1<0.15）转变为可行（F1=0.64）。消费级模型通过合理验证可达64% F1，而小型模型性能仅为51%。大模型虽可达77% F1，但需要企业级算力。还发现小模型存在系统性幻觉（hallucination）——回忆率过高反而为抽取失败的标志。首次给出了开源模型在监管信息抽取任务中的性能与资源映射。

Conclusion: 建立了开源大模型在监管信息抽取领域的综合性能-资源对照分析，为模型选择和实际部署提供了科学依据，既推动水力发电合规工作的自动化，也为相关任务的模型参数扩展研究提供了见解。

Abstract: Information extraction from regulatory documents using large language models presents critical trade-offs between performance and computational resources. We evaluated seven open-weight models (0.6B-70B parameters) on hydropower licensing documentation to provide empirical deployment guidance.
  Our analysis identified a pronounced 14B parameter threshold where validation methods transition from ineffective (F1 $<$ 0.15) to viable (F1 = 0.64). Consumer-deployable models achieve 64\% F1 through appropriate validation, while smaller models plateau at 51\%. Large-scale models approach 77\% F1 but require enterprise infrastructure.
  We identified systematic hallucination patterns where perfect recall indicates extraction failure rather than success in smaller models. Our findings establish the first comprehensive resource-performance mapping for open-weight information extraction in regulatory contexts, enabling evidence-based model selection.
  These results provide immediate value for hydropower compliance while contributing insights into parameter scaling effects that generalize across information extraction tasks.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [21] [Positive Characteristic Sets for Relational Pattern Languages](https://arxiv.org/abs/2511.12039)
*S. Mahmoud Mousawi,Sandra Zilles*

Main category: cs.FL

TL;DR: 本文针对字符串处理等领域，引入并分析了只包含正例的特征集（正特征集）的理论，为仅用正例学习关系模式语言提供了基础。


<details>
  <summary>Details</summary>
Motivation: 传统特征集需包含正负例，但实际很多应用场景只能获得正例，因此需研究仅包含正例的特征集理论，从而支持正例学习。

Method: 提出正特征集定义，并分析其在关系模式语言中的性质。理论研究为主，未提及具体算法实现。

Result: 明确了正特征集的理论基础，为字符串处理等领域仅用正例学习关系模式语言提供了方法与理论支持。

Conclusion: 本文提出了正特征集的概念，并对关系模式语言类中的正特征集进行了研究，证明其在仅用正例学习时的重要性。

Abstract: In the context of learning formal languages, data about an unknown target language L is given in terms of a set of (word,label) pairs, where a binary label indicates whether or not the given word belongs to L. A (polynomial-size) characteristic set for L, with respect to a reference class L of languages, is a set of such pairs that satisfies certain conditions allowing a learning algorithm to (efficiently) identify L within L. In this paper, we introduce the notion of positive characteristic set, referring to characteristic sets of only positive examples. These are of importance in the context of learning from positive examples only. We study this notion for classes of relational pattern languages, which are of relevance to various applications in string processing.

</details>


### [22] [Atomic Gliders and CA as Language Generators (Extended Version)](https://arxiv.org/abs/2511.12656)
*Dana Fisman,Noa Izsak*

Main category: cs.FL

TL;DR: 本文首次系统性地将细胞自动机作为语言生成器进行形式化研究，提出了glider生成语义，发现其生成的语言可超越正规与上下文无关语言，揭示了该模型在理论和应用中的强大能力。


<details>
  <summary>Details</summary>
Motivation: 细胞自动机（CA）以其简单局部规则下能够展现复杂全局行为而著称，但作为语言生成器的形式化理论尚不成熟。此次工作正是为弥补这一研究空白。

Method: 形式化定义了由一维、确定性、同步的细胞自动机（在bi-infinite栅格上运作）可表达的语言，具体为利用规则语言定义初始配置，然后投影分析达到的配置中的非静止段，进而得到有限单词集合。此外，提出了基于glider的生成语义，glider被定义为具有一定速度、携带符号的一元实体，并拥有明确的交互语义。

Result: 证明了即使在初始配置具有规则性、转换规则局部的条件下，最终可获得的语言可以超越正规语言，甚至超越上下文无关语言。这表明这一模型的表达能力远强于以往认识。

Conclusion: 经规则初始化的细胞自动机构成了一类极其丰富的计算模型，在形式化分析有序多代理系统（MAS）等领域具有潜在应用价值。

Abstract: Cellular automata (CA) are well-studied models of decentralized parallel computation, known for their ability to exhibit complex global behavior from simple local rules. While their dynamics have been widely explored through simulations, a formal treatment of CA as genuine language generators remains underdeveloped. We formalize CA-expressible languages as sets of finite words obtained by projecting the non-quiescent segments of configurations reachable by one-dimensional, deterministic, synchronous CA over bi-infinite grids. These languages are defined with respect to sets of initial configurations specified by a regular language as in regular model checking. To capture structured dynamics, we propose a glider-based generative semantics for CA. Inspired by the classical notion of gliders, we define a glider as a one-cell entity carrying a symbol in a certain velocity under well defined interaction semantics. We show that despite the regularity of the initial configurations and the locality of the transition rules, the resulting languages can exhibit non-regular and even non-context-free structure. This positions regular-initialized CA languages as a surprisingly rich computational model, with potential applications in the formal analysis of linearly ordered MAS.

</details>


### [23] [Formal Foundations for Controlled Stochastic Activity Networks](https://arxiv.org/abs/2511.12974)
*Ali Movaghar*

Main category: cs.FL

TL;DR: 该文提出并形式化了可控随机活动网络（Controlled SANs），支持在单一框架下统一建模随机、不确定、受控的分布式实时系统，可用于复杂系统的高可靠性设计、验证与分析。


<details>
  <summary>Details</summary>
Motivation: 在分布式实时系统的建模中，需有效结合不确定性（如随机性和非确定性）与显式控制策略，现有方法难以统一描述并支持复杂决策与系统分析。

Method: 提出了一种扩展的“可控随机活动网络”（Controlled SANs）形式化框架，将控制行动、概率分支和随机计时纳入统一的语义体系，采用分层的自动机语义理论描述，并定义了多种控制策略的结构分类及相关等价性理论，引入可比较的行为等价（如互模拟和随机同构）。

Result: Controlled SANs能广泛涵盖和推广传统如CTMDP等系统，系统性地支持基于策略的建模、系统抽象、组合推理与分析等能力，理论上刻画了不同控制策略的表达能力，并支持定量和定性分析。

Conclusion: Controlled SANs为在不确定性下、对可靠性要求高的系统（如安全关键系统）的规范、验证和综合提供了严谨的一体化建模基础。该方法整合了控制、计时与随机性，为系统设计与分析提供了更多理论工具。

Abstract: We introduce Controlled Stochastic Activity Networks (Controlled SANs), a formal extension of classical Stochastic Activity Networks that integrates explicit control actions into a unified semantic framework for modeling distributed real-time systems. Controlled SANs systematically capture dynamic behavior involving nondeterminism, probabilistic branching, and stochastic timing, while enabling policy-driven decision-making within a rigorous mathematical framework.
  We develop a hierarchical, automata-theoretic semantics for Controlled SANs that encompasses nondeterministic, probabilistic, and stochastic models in a uniform manner. A structured taxonomy of control policies, ranging from memoryless and finite-memory strategies to computationally augmented policies, is formalized, and their expressive power is characterized through associated language classes. To support model abstraction and compositional reasoning, we introduce behavioral equivalences, including bisimulation and stochastic isomorphism.
  Controlled SANs generalize classical frameworks such as continuous-time Markov decision processes (CTMDPs), providing a rigorous foundation for the specification, verification, and synthesis of dependable systems operating under uncertainty. This framework enables both quantitative and qualitative analysis, advancing the design of safety-critical systems where control, timing, and stochasticity are tightly coupled.

</details>
