<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 7]
- [cs.SE](#cs.SE) [Total: 23]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.CL](#cs.CL) [Total: 68]
- [cs.DM](#cs.DM) [Total: 3]
- [cs.FL](#cs.FL) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Comparing Methods for the Cross-Level Verification of SystemC Peripherals with Symbolic Execution](https://arxiv.org/abs/2509.05504)
*Karl Aaron Rudkowski,Sallar Ahmadi-Pour,Rolf Drechsler*

Main category: cs.PL

TL;DR: 论文针对硬件虚拟原型的符号执行验证，提出了CrosSym（修改SystemC内核）与SEFOS（修改符号执行引擎）两类新工具。两者均能在性能与功能上超越现有方法，实现跨层、丰富场景外设验证。SEFOS兼容性高，CrosSym资源效率稍好，为硬件综合验证提供新技术路线。


<details>
  <summary>Details</summary>
Motivation: 现代硬件设计高度复杂，涉及多个处理器、互连和外设等子系统，如何在不同抽象层次进行早期验证具有一定挑战性。传统的基于SystemC虚拟原型的验证流程难以无缝集成符号执行技术，并且现有方案要么修改SystemC内核、要么无法实现真正的跨层验证场景，导致专用外设验证受限。

Method: 本文提出了两种符号执行外设的方法：CrosSym通过修改SystemC内核实现多样化符号执行；SEFOS则直接对现代符号执行引擎进行改造，无需更改SystemC内核。两种工具均应用于不同抽象层次上的外设验证，并进行了广泛评估。

Result: 两种工具均可在不同验证场景下辨识出300多个变异体，功能丰富。SEFOS工具可在保持SystemC内核和外设不变的前提下实现符号执行，CrosSym在运行时和内存消耗上略优。与现有主流的仅支持TLM层次方法相比，两种新工具在性能相当的同时，实现了符号执行下的跨层验证能力。

Conclusion: 通过对CrosSym与SEFOS的设计和评估，本文证明：无需大规模修改SystemC内核亦可实现跨层的符号执行与外设验证，为虚拟原型在复杂硬件设计中提供更强大的验证支持。

Abstract: Virtual Prototypes (VPs) are important tools in modern hardware development.
At high abstractions, they are often implemented in SystemC and offer early
analysis of increasingly complex designs. These complex designs often combine
one or more processors, interconnects, and peripherals to perform tasks in
hardware or interact with the environment. Verifying these subsystems is a
well-suited task for VPs, as they allow reasoning across different abstraction
levels. While modern verification techniques like symbolic execution can be
seamlessly integrated into VP-based workflows, they require modifications in
the SystemC kernel. Hence, existing approaches therefore modify and replace the
SystemC kernel, or ignore the opportunity of cross-level scenarios completely,
and would not allow focusing on special challenges of particular subsystems
like peripherals. We propose CrosSym and SEFOS, two opposing approaches for a
versatile symbolic execution of peripherals. CrosSym modifies the SystemC
kernel, while SEFOS instead modifies a modern symbolic execution engine. Our
extensive evaluation applies our tools to various peripherals on different
levels of abstractions. Both tools extensive sets of features are demonstrated
for (1) different verification scenarios, and (2) identifying 300+ mutants. In
comparison with each other, SEFOS convinces with the unmodified SystemC kernel
and peripheral, while CrosSym offers slightly better runtime and memory usage.
In comparison to the state-of-the-art, that is limited to Transaction Level
Modelling (TLM), our tools offered comparable runtime, while enabling
cross-level verification with symbolic execution.

</details>


### [2] [Fixed Parameter Tractable Linearizability Monitoring for Stack, Queue and Anagram Agnostic Data Types](https://arxiv.org/abs/2509.05586)
*Lee Zheng Han,Umang Mathur*

Main category: cs.PL

TL;DR: 论文提出了针对并发数据结构线性化验证的高效方法，通过参数化并发度，提出堆栈、队列及无序数据结构的FPT算法，统一实现了理论上高效验证，提升了实际并发程序的可用性与正确性保障。


<details>
  <summary>Details</summary>
Motivation: 并发数据结构的线性化验证在理论与工程实践中至关重要，但即便是简单数据类型也面临NP-完全的计算挑战，亟需更高效的验证算法以适应实际并发环境。

Method: 该论文利用frontier graphs与partition states减少搜寻空间，对AADT通过线性化等价实现对数线性时间监控，对堆栈提出基于文法并通过子立方级矩阵乘法优化的方法，对队列设计了支持高效动态规划的分割序列转移系统。

Result: 对有限并发度场景下各类数据结构提出了固定参数可解（FPT）的线性化监控算法，为顺序敏感与无序数据结构统一提供了可行性保证。

Conclusion: 本文提出的方法能有效验证以并发程度为参数的堆栈、队列和无序数据结构（AADT）的线性化正确性，将问题复杂性降为可处理范围，尤其在并发度有限场景下具有实际意义。

Abstract: Verifying linearizability of concurrent data structures is NP-hard, even for
simple types. We present fixed-parameter tractable algorithms for monitoring
stacks, queues, and anagram-agnostic data types (AADTs), parameterized by the
maximum concurrency. Our approach leverages frontier graphs and partition
states to bound the search space. For AADTs, equivalence of linearizations
enables monitoring in log-linear time. For stacks, we introduce a grammar-based
method with a sub-cubic reduction to matrix multiplication, and for queues, a
split-sequence transition system supporting efficient dynamic programming.
These results unify tractability guarantees for both order-sensitive and
anagram-agnostic data types under bounded concurrency.

</details>


### [3] [Pacing Types: Safe Monitoring of Asynchronous Streams](https://arxiv.org/abs/2509.06724)
*Florian Kohn,Arthur Correnson,Jan Baumeister,Bernd Finkbeiner*

Main category: cs.PL

TL;DR: 文中针对复杂系统中的异步数据流监控提出了一种新的类型系统 pacing types，用于确保监控器不会因流不同步而发生运行时错误，并在 RTLola 框架中实现与证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在无人机等复杂网络物理系统中，流式监控器汇聚来自多个异步传感器的数据用于实时健康评估。这些监控器作为安全关键组件，要求极高的可靠性，而异步流导致同步和潜在运行时错误是主要挑战。本研究旨在提升监控器对异步流的处理安全性。

Method: 作者为 RTLola 的核心片段形式化了 pacing types 类型系统，并通过一种新的逻辑关系方法给出了声音性证明。

Result: 设计并实现了一种 pacing types 类型系统，该系统可以检测并防止流式监控任务中因异步数据流导致的运行时错误；并通过理论证明保证了类型系统的正确性。

Conclusion: 本文提出的 pacing types 类型系统可以确保异步数据流监视器在运行时的行为良好，提升了 RTLola 框架下监视器的安全性和可靠性。

Abstract: Stream-based monitoring is a real-time safety assurance mechanism for complex
cyber-physical systems such as unmanned aerial vehicles. In this context, a
monitor aggregates streams of input data from sensors and other sources to give
real-time statistics and assessments of the system's health. Since monitors are
safety-critical components, it is crucial to ensure that they are free of
potential runtime errors. One of the central challenges in designing reliable
stream-based monitors is to deal with the asynchronous nature of data streams:
in concrete applications, the different sensors being monitored produce values
at different speeds, and it is the monitor's responsibility to correctly react
to the asynchronous arrival of different streams of values. To ease this
process, modern frameworks for stream-based monitoring such as RTLola feature
an expressive specification language that allows to finely specify data
synchronization policies. While this feature dramatically simplifies the design
of monitors, it can also lead to subtle runtime errors. To mitigate this issue,
this paper presents pacing types, a novel type system implemented in RTLola to
ensure that monitors for asynchronous streams are well-behaved at runtime. We
formalize the essence of pacing types for a core fragment of RTLola, and
present a soundness proof of the pacing type system using a new logical
relation.

</details>


### [4] [Termination Analysis of Linear-Constraint Programs](https://arxiv.org/abs/2509.06752)
*Amir M. Ben-Amram,Samir Genaim,Joël Ouaknine,James Worrell*

Main category: cs.PL

TL;DR: 本文综述了针对具有数值变量和线性约束的程序终止性分析的主要方法，涵盖秩函数、判定性、良序不变量与非终止证据等，同时比较了不同方法在表达力和计算复杂性上的取舍。


<details>
  <summary>Details</summary>
Motivation: 带数值变量和线性转移关系的程序终止性分析属于程序分析中的难题，部分问题本质上不可判定。本文旨在系统梳理和解析近年来为解决此类难题所发展出的理论与方法。

Method: 分析和分类终止性分析中的主要方法，包括判定性理论、ranking function（秩函数）、析取良序转移不变量以及非终止性证据，着重探讨算法和复杂性方面的技巧及进展。

Result: 提出并对比了多种终止性判定与非终止性证明的具体技术，总结这些方法的实际可行性与理论界限，为后续研究提供理论基础和方法指引。

Conclusion: 本文系统地总结了针对带有数值变量和线性约束的程序终止性分析的各种方法和技术，指出各种方法在表达能力与计算复杂性之间存在权衡。

Abstract: This Survey provides an overview of techniques in termination analysis for
programs with numerical variables and transitions defined by linear
constraints. This subarea of program analysis is challenging due to the
existence of undecidable problems, and this Survey systematically explores
approaches that mitigate this inherent difficulty. These include foundational
decidability results, the use of ranking functions, and disjunctive
well-founded transition invariants. The Survey also discusses non-termination
witnesses, used to prove that a program will not halt. We examine the
algorithmic and complexity aspects of these methods, showing how different
approaches offer a trade-off between expressive power and computational
complexity. The Survey does not discuss how termination analysis is performed
on real-world programming languages, nor does it consider more expressive
abstract models that include non-linear arithmetic, probabilistic choice, or
term rewriting systems.

</details>


### [5] [Dato: A Task-Based Programming Model for Dataflow Accelerators](https://arxiv.org/abs/2509.06794)
*Shihan Fang,Hongzheng Chen,Niansong Zhang,Jiajie Li,Han Meng,Adrian Liu,Zhiru Zhang*

Main category: cs.PL

TL;DR: Dato是一种用于数据流加速器的Python嵌入式任务编程模型，使数据流和分片成为类型化元素，大幅简化开发，提升硬件利用率和性能，在NPU和FPGA实验中均优于当前主流方案。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习任务数据传输需求已超出内存系统瓶颈，主流编程模型不是门槛过高就是优化受限，难以充分发挥数据流加速器的带宽与并行优势。

Method: Dato为Python嵌入式的任务编程模型，将数据通信和数据分片作为类型化的第一类公民。开发者以任务图和显式流类型编程，通过类型注释指定分片输入。编译器实现虚拟到物理的任务映射，满足硬件约束，并在多种数据流加速器上测试其有效性。

Result: 在AMD Ryzen AI NPU和Alveo FPGA测试中，Dato对于GEMM可达84%的硬件利用率，Attention核实现2.81倍于商业框架的加速，FPGA上自定义阵列性能为理论峰值的98%。相比流行框架，Dato代码更易开发，且性能领先。

Conclusion: Dato能够在保持高性能的同时，极大简化了针对数据流加速器优化代码的开发负担。其编译和任务映射机制适配不同硬件，提升了资源利用率和执行效率。

Abstract: Recent deep learning workloads increasingly push computational demand beyond
what current memory systems can sustain, with many kernels stalling on data
movement rather than computation. While modern dataflow accelerators
incorporate on-chip streaming to mitigate off-chip bandwidth limitations,
existing programming models struggle to harness these capabilities effectively.
Low-level interfaces provide fine-grained control but impose significant
development overhead, whereas high-level tile-based languages abstract away
communication details, restricting optimization and forcing compilers to
reconstruct the intended dataflow. We present Dato, a Python-embedded,
task-based programming model for dataflow accelerators that elevates data
communication and sharding to first-class type constructs. Developers write
programs as a graph of tasks connected via explicit stream types, with sharded
inputs specified using layout types. These tasks are first mapped virtually
onto the accelerator's spatial fabric, and the compiler then generates a
physical mapping that respects hardware constraints. Experimental results on
both AMD Ryzen AI NPU and Alveo FPGA devices demonstrate that Dato achieves
high performance while significantly reducing the burden of writing optimized
code. On the NPU, Dato attains up to 84% hardware utilization for GEMM and
delivers a 2.81x speedup on attention kernels compared to a state-of-the-art
commercial framework. On the FPGA, Dato surpasses leading frameworks in
performance when generating custom systolic arrays, achieving 98% of the
theoretical peak performance.

</details>


### [6] [MIO: Multiverse Debugging in the Face of Input/Output -- Extended Version with Additional Appendices](https://arxiv.org/abs/2509.06845)
*Tom Lauwaerts,Maarten Steevens,Christophe Scholliers*

Main category: cs.PL

TL;DR: 本文提出了一种能正确处理输入/输出操作、只探索真实可达状态的多宇宙调试技术，并通过MIO原型在实际微控制器硬件上展示了其实用性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有多宇宙调试器在处理涉及输入/输出操作的程序时，可能导致开发者探索到常规执行中不可达的错误状态，进而影响调试效率和准确性。因此，需要能准确反映真实可达状态的多宇宙调试方法。

Method: 提出了一种新的多宇宙调试方法，定义了其语义，并从理论上证明其正确性。实现了基于WARDuino WebAssembly虚拟机的原型系统MIO，并通过具体实例（带有Lego Mindstorms马达和颜色传感器的彩色刻度盘），在STM32微控制器上进行展示和验证。

Result: 开发出支持广泛I/O操作且只探索可达状态的多宇宙调试器原型（MIO），并在STM32等微控制器场景下完成了系统性演示，验证了方法的可行性和高效性。

Conclusion: 该论文提出了一种新的多宇宙调试方法，可以应对广泛的输入/输出操作，并证明了调试器的正确性，确保仅探索常规执行中能到达的程序状态。论文展示了MIO原型，能高效支持在微控制器上的多宇宙调试。

Abstract: Debugging non-deterministic programs on microcontrollers is notoriously
challenging, especially when bugs manifest in unpredictable, input-dependent
execution paths. A recent approach, called multiverse debugging, makes it
easier to debug non-deterministic programs by allowing programmers to explore
all potential execution paths. Current multiverse debuggers enable both forward
and backward traversal of program paths, and some facilitate jumping to any
previously visited states, potentially branching into alternative execution
paths within the state space.
  Unfortunately, debugging programs that involve input/output operations using
existing multiverse debuggers can reveal inaccessible program states, i.e.
states which are not encountered during regular execution. This can
significantly hinder the debugging process, as the programmer may spend
substantial time exploring and examining inaccessible program states, or worse,
may mistakenly assume a bug is present in the code, when in fact, the issue is
caused by the debugger.
  This paper presents a novel approach to multiverse debugging, which can
accommodate a broad spectrum of input/output operations. We provide the
semantics of our approach and prove the correctness of our debugger, ensuring
that despite having support for a wide range of input/output operations the
debugger will only explore those program states which can be reached during
regular execution.
  We have developed a prototype, called MIO, leveraging the WARDuino
WebAssembly virtual machine to demonstrate the feasibility and efficiency of
our techniques. As a demonstration of the approach we highlight a color dial
built with a Lego Mindstorms motor, and color sensor, providing a tangible
example of how our approach enables multiverse debugging for programs running
on an STM32 microcontroller.

</details>


### [7] [Mechanized Metatheory of Forward Reasoning for End-to-End Linearizability Proofs](https://arxiv.org/abs/2509.06872)
*Zachary Kent,Ugur Y. Yavuz,Siddhartha Jayanti,Stephanie Balzer,Guy Blelloch*

Main category: cs.PL

TL;DR: 本文完全机制化并验证了并发数据结构线性化前向推理技术，并成功对简单并发寄存器进行了端到端的可证明线性化验证，推进了该领域的实用性和可信度。


<details>
  <summary>Details</summary>
Motivation: 线性化是并发数据结构正确性的黄金标准，因此开发有效的线性化证明技术具有重要的理论与实践意义。此前虽然有了首个可靠且完备的前向推理技术，但其元理论正确性尚未实现形式化机制化验证，阻碍了端到端可验证证明的实现。

Method: 形式化Jayanti等人的前向推理技术，并在Rocq（一个证明辅助系统）中机制化了其可靠性和完备性证明，作为实例对并发寄存器进行了端到端线性化证明的验证。

Result: 实现了Jayanti等人前向推理技术的形式化与机制化验证，并成功地产生了一个并发寄存器线性化证明的端到端、可验证案例。

Conclusion: 通过在Rocq中机制化前向推理技术，缩小了可信计算基，同时推动了线性化证明的自动化、形式化与可验证性，为并发数据结构正确性证明提供了可信与实用的工具。

Abstract: In the past decade, many techniques have been developed to prove
linearizability, the gold standard of correctness for concurrent data
structures. Intuitively, linearizability requires that every operation on a
concurrent data structure appears to take place instantaneously, even when
interleaved with other operations. Most recently, Jayanti et al. presented the
first sound and complete "forward reasoning" technique for proving
linearizability that relates the behavior of a concurrent data structure to a
reference atomic data structure as time moves forward. This technique can be
used to produce machine-checked proofs of linearizability in TLA+. However,
while Jayanti et al.'s approach is shown to be sound and complete, a
mechanization of this important metatheoretic result is still outstanding. As a
result, it is not possible to produce verified end-to-end proofs of
linearizability. To reduce the size of this trusted computing base, we
formalize this forward reasoning technique and mechanize proofs of its
soundness and completeness in Rocq. As a case study, we use the approach to
produce a verified end-to-end proof of linearizability for a simple concurrent
register.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [8] [Adversarial Bug Reports as a Security Risk in Language Model-Based Automated Program Repair](https://arxiv.org/abs/2509.05372)
*Piotr Przymus,Andreas Happe,Jürgen Cito*

Main category: cs.SE

TL;DR: LLM驱动的自动程序修复系统易受对抗性bug报告攻击，现有防御不足。论文提出威胁模型、系统评测和自动生成攻击框架，建议改进预防和检测机制，提升APR系统安全性。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型（LLM）驱动的自动程序修复（APR）系统被广泛应用于现代软件开发流程，其通过自然语言描述的bug报告自动生成补丁。然而，用户输入的不可控性带来了新的安全威胁，尚缺乏对这类攻击面的系统性研究。

Method: 作者提出了完整的威胁模型，并通过实证研究，利用51条多策略生成的对抗性bug报告测试当前主流APR系统，评估了在修复前（如LlamaGuard、PromptGuard、Granite-Guardian及自定义LLM过滤器）和修复后（GitHub Copilot、CodeQL）多种防御机制的有效性。文中还开发了自动化生成对抗性bug报告的原型框架。

Result: 实验发现，当前防御措施不足：有90%的对抗性bug报告能够诱发符合攻击者意图的补丁。最佳修复前过滤器拦截率仅为47%，而修复后检测机制的有效率也仅为58%，且常需人工介入。

Conclusion: 论文揭示了APR系统在应对对抗性输入方面的结构性失衡，对抗性输入生成成本低而检测和防御难度高。作者提出了提升APR系统稳健性的实际建议，并指出了未来可持续推进可信自动修复的研究方向。

Abstract: Large Language Model (LLM) - based Automated Program Repair (APR) systems are
increasingly integrated into modern software development workflows, offering
automated patches in response to natural language bug reports. However, this
reliance on untrusted user input introduces a novel and underexplored attack
surface. In this paper, we investigate the security risks posed by adversarial
bug reports -- realistic-looking issue submissions crafted to mislead APR
systems into producing insecure or harmful code changes. We develop a
comprehensive threat model and conduct an empirical study to evaluate the
vulnerability of state-of-the-art APR systems to such attacks. Our
demonstration comprises 51 adversarial bug reports generated across a spectrum
of strategies, from manual curation to fully automated pipelines. We test these
against leading APR model and assess both pre-repair defenses (e.g., LlamaGuard
variants, PromptGuard variants, Granite-Guardian, and custom LLM filters) and
post-repair detectors (GitHub Copilot, CodeQL). Our findings show that current
defenses are insufficient: 90\% of crafted bug reports triggered
attacker-aligned patches. The best pre-repair filter blocked only 47\%, while
post-repair analysis-often requiring human oversight-was effective in just 58\%
of cases. To support scalable security testing, we introduce a prototype
framework for automating the generation of adversarial bug reports. Our
analysis exposes a structural asymmetry: generating adversarial inputs is
inexpensive, while detecting or mitigating them remains costly and error-prone.
We conclude with practical recommendations for improving the robustness of APR
systems against adversarial misuse and highlight directions for future work on
trustworthy automated repair.

</details>


### [9] [Reverse Browser: Vector-Image-to-Code Generator](https://arxiv.org/abs/2509.05394)
*Zoltan Toth-Czifra*

Main category: cs.SE

TL;DR: 该文用矢量图输入和多尺度评价指标来提升UI自动生成代码的质量，并训练了新模型，结果更接近原设计，但仍有局限。


<details>
  <summary>Details</summary>
Motivation: 传统image-to-code或image-to-UI方法转化出的代码很难高度还原设计原稿，原因之一是输入采用位图信息损失严重。作者试图通过引入矢量图输入改进保真度。

Method: 1. 利用矢量图替代位图作为输入。2. 创建了多个用于机器学习的、较大规模的训练数据集。3. 综合评估现有图像质量评估（IQA）算法。4. 引入了一种新的多尺度评估指标。5. 训练了大型开源模型来自动生成UI代码。6. 分析并讨论模型实际表现及其局限。

Result: 提出和实现了矢量图输入方案，构建了大数据集，创建并测试了一种新的多尺度图像质量评估标准，并成功训练了一个高性能的开源模型，指出其不足。

Conclusion: 作者提出使用矢量图而非位图作为模型输入，以期提升界面自动生成代码的保真度。提出了一种新的多尺度图像质量评估指标，并训练了一个大型开源模型，最后讨论了其局限性。

Abstract: Automating the conversion of user interface design into code (image-to-code
or image-to-UI) is an active area of software engineering research. However,
the state-of-the-art solutions do not achieve high fidelity to the original
design, as evidenced by benchmarks. In this work, I approach the problem
differently: I use vector images instead of bitmaps as model input. I create
several large datasets for training machine learning models. I evaluate the
available array of Image Quality Assessment (IQA) algorithms and introduce a
new, multi-scale metric. I then train a large open-weights model and discuss
its limitations.

</details>


### [10] [Combining TSL and LLM to Automate REST API Testing: A Comparative Study](https://arxiv.org/abs/2509.05540)
*Thiago Barradas,Aline Paes,Vânia de Oliveira Neves*

Main category: cs.SE

TL;DR: 论文提出了一种基于TSL与LLM结合的REST API测试自动生成方法，系统比较了不同大语言模型性能。结果显示Claude 3.5 Sonnet表现最优，有望提高测试自动化水平。


<details>
  <summary>Details</summary>
Motivation: 当前REST API的测试具有高复杂性、场景多样和测试设计时间不足，导致人工测试覆盖率有限且容易遗漏错误。解决这些难题迫切需要高效自动化方法。

Method: 提出RestTSLLM方法，结合测试规范语言（TSL）和大语言模型（LLM），自动生成REST API测试用例。整合了提示工程技术和自动化流程，并对不同LLM（包括Claude 3.5 Sonnet、Deepseek R1、Qwen 2.5 32b、Sabia 3）在OpenAPI规范下生成测试的能力进行系统评估。

Result: 多种主流LLM均能生成健壮且符合上下文的API测试。其中，Claude 3.5 Sonnet在成功率、测试覆盖率和变异分数等所有指标上表现最佳，优于其它模型。

Conclusion: RestTSLLM方法实现了自动化基于API规范的测试生成，显著降低人工成本并提升测试质量。Claude 3.5 Sonnet在当前研究中为测试用例生成任务的最佳选择。

Abstract: The effective execution of tests for REST APIs remains a considerable
challenge for development teams, driven by the inherent complexity of
distributed systems, the multitude of possible scenarios, and the limited time
available for test design. Exhaustive testing of all input combinations is
impractical, often resulting in undetected failures, high manual effort, and
limited test coverage. To address these issues, we introduce RestTSLLM, an
approach that uses Test Specification Language (TSL) in conjunction with Large
Language Models (LLMs) to automate the generation of test cases for REST APIs.
The approach targets two core challenges: the creation of test scenarios and
the definition of appropriate input data. The proposed solution integrates
prompt engineering techniques with an automated pipeline to evaluate various
LLMs on their ability to generate tests from OpenAPI specifications. The
evaluation focused on metrics such as success rate, test coverage, and mutation
score, enabling a systematic comparison of model performance. The results
indicate that the best-performing LLMs - Claude 3.5 Sonnet (Anthropic),
Deepseek R1 (Deepseek), Qwen 2.5 32b (Alibaba), and Sabia 3 (Maritaca) -
consistently produced robust and contextually coherent REST API tests. Among
them, Claude 3.5 Sonnet outperformed all other models across every metric,
emerging in this study as the most suitable model for this task. These findings
highlight the potential of LLMs to automate the generation of tests based on
API specifications.

</details>


### [11] [Natural Language-Programming Language Software Traceability Link Recovery Needs More than Textual Similarity](https://arxiv.org/abs/2509.05585)
*Zhiyuan Zou,Bangchao Wang,Peng Liang,Tingting Bi,Huan Jin*

Main category: cs.SE

TL;DR: 本文针对需求到代码的追踪链恢复任务，提出结合多种领域辅助策略改进HGT与Gemini 2.5 Pro模型，在12个开源项目实验中显著优于主流方法，有效提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有追踪链恢复任务普遍依赖文本相似度，但在需求（自然语言）与代码（编程语言）之间存在语义鸿沟，致使性能受限，有必要通过新方法缩小这一差距。

Method: 通过大规模实证评估揭示文本相似性在自然语言-编程语言（NL-PL）场景下的局限性，并设计将多种辅助策略集成到HGT（通过边类型嵌入）和Gemini 2.5 Pro（通过输入增强）的方法，在12个开源项目中对比评测。

Result: 多策略集成的HGT和Gemini 2.5 Pro平均F1分数比分别提升3.68%和8.84%，显著优于当前最优的HGNNLink方法。

Conclusion: 引入多种领域特定的辅助策略到HGT与Gemini 2.5 Pro模型，有效提升了需求到代码追踪链恢复（TLR）任务中的性能，优于未集成策略的原始模型和现有最先进方法。

Abstract: In the field of software traceability link recovery (TLR), textual similarity
has long been regarded as the core criterion. However, in tasks involving
natural language and programming language (NL-PL) artifacts, relying solely on
textual similarity is limited by their semantic gap. To this end, we conducted
a large-scale empirical evaluation across various types of TLR tasks, revealing
the limitations of textual similarity in NL-PL scenarios. To address these
limitations, we propose an approach that incorporates multiple domain-specific
auxiliary strategies, identified through empirical analysis, into two models:
the Heterogeneous Graph Transformer (HGT) via edge types and the prompt-based
Gemini 2.5 Pro via additional input information. We then evaluated our approach
using the widely studied requirements-to-code TLR task, a representative case
of NL-PL TLR. Experimental results show that both the multi-strategy HGT and
Gemini 2.5 Pro models outperformed their original counterparts without strategy
integration. Furthermore, compared to the current state-of-the-art method
HGNNLink, the multi-strategy HGT and Gemini 2.5 Pro models achieved average
F1-score improvements of 3.68% and 8.84%, respectively, across twelve
open-source projects, demonstrating the effectiveness of multi-strategy
integration in enhancing overall model performance for the requirements-code
TLR task.

</details>


### [12] [Verifying Correctness of PLC Software during System Evolution using Model Containment Approach](https://arxiv.org/abs/2509.05596)
*Soumyadip Bandyopadhyay,Santonu Sarkar*

Main category: cs.SE

TL;DR: 本文提出了基于Petri网和新算法的PLC升级软件验证方法，经大量实验证明效率和效果优于现有工具。


<details>
  <summary>Details</summary>
Motivation: PLC软件升级频繁，以适应不断变化的工业需求，但验证升级后功能正确性是一大难题。

Method: 将升级前后的顺序功能图（SFC）转换为对应的两个Petri网模型，利用基于符号路径等价性的新型包含性检测算法，设计并实现了一个Petri网包含性检查工具。

Result: 在OSCAT库80个真实基准测试上，提出的方法在可扩展性和有效性方面表现优异，且对比目前流行的verifAPS工具，性能提升近4倍。

Conclusion: 该研究提出了一种有效的PLC软件升级后正确性验证方法，通过Petri网建模及新颖的包含性算法，显著提升了验证效率和性能。

Abstract: Upgradation of Programmable Logic Controller (PLC) software is quite common
to accommodate evolving industrial requirements. Verifying the correctness of
such upgrades remains a significant challenge. In this paper, we propose a
verification-based approach to ensure the correctness of the existing
functionality in the upgraded version of a PLC software. The method converts
the older and the newer versions of the sequential function chart (SFC) into
two Petri net models. We then verify whether one model is contained within
another, based on a novel containment checking algorithm grounded in symbolic
path equivalence. For this purpose, we have developed a home-grown Petri
net-based containment checker. Experimental evaluation on 80 real-world
benchmarks from the OSCAT library highlights the scalability and effectiveness
of the framework. We have compared our approach with verifAPS, a popular tool
used for software upgradation, and observed nearly 4x performance improvement.

</details>


### [13] [Automating API Documentation with LLMs: A BERTopic Approach](https://arxiv.org/abs/2509.05749)
*AmirHossein Naghshzan*

Main category: cs.SE

TL;DR: 通过自动化方法提取和总结Stack Overflow里的API知识，结合官方文档，可提升开发者查找信息的效率和满意度。


<details>
  <summary>Details</summary>
Motivation: 官方API文档往往篇幅长、复杂或不完整，开发者因此频繁转向像Stack Overflow这样的社区平台获取更实用的信息。作者希望让API文档更简明、易用且富有实用性。

Method: 利用BERTopic方法从360万条Stack Overflow帖子中提取主题，再应用抽取式文本摘要，生成包含代码片段的简明总结。通过30位Android开发者的用户研究评估总结的连贯性、相关性、信息量和用户满意度。

Result: 用户研究显示，这种结合自动摘要与社区内容的方式能提升文档的可读性和开发者生产力。

Conclusion: 整合正式API知识与社区生成内容，能增强API文档的可获取性和实用性，使其更利于开发者工作。

Abstract: Developers rely on API documentation, but official sources are often lengthy,
complex, or incomplete. Many turn to community-driven forums like Stack
Overflow for practical insights. We propose automating the summarization of
informal sources, focusing on Android APIs. Using BERTopic, we extracted
prevalent topics from 3.6 million Stack Overflow posts and applied extractive
summarization techniques to generate concise summaries, including code
snippets. A user study with 30 Android developers assessed the summaries for
coherence, relevance, informativeness, and satisfaction, showing improved
productivity. Integrating formal API knowledge with community-generated content
enhances documentation, making API resources more accessible and actionable
work.

</details>


### [14] [IoT Miner: Intelligent Extraction of Event Logs from Sensor Data for Process Mining](https://arxiv.org/abs/2509.05769)
*Edyta Brzychczy,Urszula Jessen,Krzysztof Kluza,Sridhar Sriram,Manuel Vargas Nettelnstroth*

Main category: cs.SE

TL;DR: 提出IoT Miner框架，用无监督聚类加大模型生成活动标签，能自动从原始传感器数据生成事件日志，实现传统记录缺失场景下的工业过程挖掘。


<details>
  <summary>Details</summary>
Motivation: 现实工业场景中常缺少标准事件日志，原始传感器数据缺乏分析所需的结构和语义，阻碍了过程挖掘方法的应用，因此需要自动生成高层次事件日志的新方法。

Method: 本文提出IoT Miner框架，包含四个步骤：数据预处理、无监督聚类、基于大模型的标签生成、事件日志构建。特别创新地利用大模型，通过领域特定提示词，根据聚类统计结果生成语义丰富的活动标签，并引入新指标Similarity-Weighted Accuracy评价标签质量。

Result: 在某矿业LHD设备传感器数据集上实验表明，领域提示词越丰富，自动生成的标签越准确且一致。IoT Miner能够显著提升IoT数据到事件日志转换的质量和可解释性。

Conclusion: IoT Miner结合了AI与面向领域的数据处理，能够从原始IoT传感器数据中，自动、可扩展地生成结构化且可解释的高层事件日志，为缺乏传统事件日志的工业过程挖掘提供了有效解决方案。

Abstract: This paper presents IoT Miner, a novel framework for automatically creating
high-level event logs from raw industrial sensor data to support process
mining. In many real-world settings, such as mining or manufacturing, standard
event logs are unavailable, and sensor data lacks the structure and semantics
needed for analysis. IoT Miner addresses this gap using a four-stage pipeline:
data preprocessing, unsupervised clustering, large language model (LLM)-based
labeling, and event log construction. A key innovation is the use of LLMs to
generate meaningful activity labels from cluster statistics, guided by
domain-specific prompts. We evaluate the approach on sensor data from a
Load-Haul-Dump (LHD) mining machine and introduce a new metric,
Similarity-Weighted Accuracy, to assess labeling quality. Results show that
richer prompts lead to more accurate and consistent labels. By combining AI
with domain-aware data processing, IoT Miner offers a scalable and
interpretable method for generating event logs from IoT data, enabling process
mining in settings where traditional logs are missing.

</details>


### [15] [GeoAnalystBench: A GeoAI benchmark for assessing large language models for spatial analysis workflow and code generation](https://arxiv.org/abs/2509.05881)
*Qianheng Zhang,Song Gao,Chen Wei,Yibo Zhao,Ying Nie,Ziru Chen,Shijie Chen,Yu Su,Huan Sun*

Main category: cs.SE

TL;DR: LLMs可初步自动化GIS任务，专有大模型表现远优于开源小模型，但空间推理类任务仍有较大难度。GeoAnalystBench建立了标准评估体系，为GeoAI发展指明方向。


<details>
  <summary>Details</summary>
Motivation: 随着大模型（LLMs）在NLP等领域的突出表现，学界和工业界关注如何用LLMs来推动地理空间分析和GIS自动化，但目前LLMs真实的地理处理能力尚不明确，需要严谨评估。

Method: 提出GeoAnalystBench，这是一个由50个现实地理问题抽象出的Python基准任务集合，由GIS专家严格验证。任务配有最低交付产品，评估方法涵盖工作流有效性、结构对齐、语义相似性及代码质量(CodeBLEU)。通过该基准对比评估专有和开源的大模型表现。

Result: 专有模型（如ChatGPT-4o-mini）任务有效率高达95%，结构对齐（CodeBLEU）达0.39，而开源小模型（如DeepSeek-R1-7B）只有48.5%有效率与0.272 CodeBLEU。空间关系推理和最优选址等深层空间任务对所有模型仍具挑战。

Conclusion: 目前LLMs在GIS自动化上展现一定潜力，但存在明显局限，深层空间推理问题尚难以解决。GeoAnalystBench为GeoAI社区提供了可复现的评测框架，有助于推进人机协作的GeoAI研究。

Abstract: Recent advances in large language models (LLMs) have fueled growing interest
in automating geospatial analysis and GIS workflows, yet their actual
capabilities remain uncertain. In this work, we call for rigorous evaluation of
LLMs on well-defined geoprocessing tasks before making claims about full GIS
automation. To this end, we present GeoAnalystBench, a benchmark of 50
Python-based tasks derived from real-world geospatial problems and carefully
validated by GIS experts. Each task is paired with a minimum deliverable
product, and evaluation covers workflow validity, structural alignment,
semantic similarity, and code quality (CodeBLEU). Using this benchmark, we
assess both proprietary and open source models. Results reveal a clear gap:
proprietary models such as ChatGPT-4o-mini achieve high validity 95% and
stronger code alignment (CodeBLEU 0.39), while smaller open source models like
DeepSeek-R1-7B often generate incomplete or inconsistent workflows (48.5%
validity, 0.272 CodeBLEU). Tasks requiring deeper spatial reasoning, such as
spatial relationship detection or optimal site selection, remain the most
challenging across all models. These findings demonstrate both the promise and
limitations of current LLMs in GIS automation and provide a reproducible
framework to advance GeoAI research with human-in-the-loop support.

</details>


### [16] [Code2MCP: A Multi-Agent Framework for Automated Transformation of Code Repositories into Model Context Protocol Services](https://arxiv.org/abs/2509.05941)
*Chaoqian Ouyang,Ling Yue,Shimin Di,Libin Zheng,Shaowu Pan,Min-Ling Zhang*

Main category: cs.SE

TL;DR: 本论文提出自动工具Code2MCP，利用LLM和自动化流程，将任意GitHub项目快速转化为MCP服务，减少碎片化和人工成本，促进AI工具生态的集成与创新。


<details>
  <summary>Details</summary>
Motivation: 当前大量大语言模型（LLMs）和工具之间的集成存在严重难题，称为“N×M问题”，即每个模型都需为每个工具定制适配，造成碎片化和巨大的开发负担。已有MCP协议标准，但将现有软件转换为MCP服务需大量人工参与，影响普及，尤其是数量庞大的GitHub开源项目。

Method: 提出Code2MCP框架，可自动将GitHub仓库代码转化为MCP合规服务，采用多阶段流程：代码分析、环境配置、服务生成、自动部署。创新点在于基于大语言模型的“运行-评审-修复”闭环机制，自动调试和修复生成代码，同时完成技术文档生成。

Result: Code2MCP能高效且自动化地实现数百万GitHub开源项目的MCP服务化，大幅降低人工参与，不仅生成可部署服务，还系统生成完备技术文档。框架已开源。

Conclusion: Code2MCP显著加速MCP生态发展，通过自动化转化和集成，极大释放开源代码资源潜力，解决工具适配最后一公里问题，为大模型工具集成提供关键基础设施支持。

Abstract: The proliferation of Large Language Models (LLMs) has created a significant
integration challenge in the AI agent ecosystem, often called the "$N \times M$
problem," where N models require custom integrations for M tools. This
fragmentation stifles innovation and creates substantial development overhead.
While the Model Context Protocol (MCP) has emerged as a standard to resolve
this, its adoption is hindered by the manual effort required to convert the
vast universe of existing software into MCP-compliant services. This is
especially true for the millions of open-source repositories on GitHub, the
world's largest collection of functional code. This paper introduces Code2MCP,
a highly automated, agentic framework designed to transform any GitHub
repository into a functional MCP service with minimal human intervention. Our
system employs a multi-stage workflow that automates the entire process, from
code analysis and environment configuration to service generation and
deployment. A key innovation of our framework is an LLM-driven, closed-loop
"Run--Review--Fix" cycle, which enables the system to autonomously debug and
repair the code it generates. Code2MCP produces not only deployable services
but also comprehensive technical documentation, acting as a catalyst to
accelerate the MCP ecosystem by systematically unlocking the world's largest
open-source code repository and automating the critical last mile of tool
integration. The code is open-sourced at
https://github.com/DEFENSE-SEU/MCP-Github-Agent.

</details>


### [17] [GRACE: Graph-Guided Repository-Aware Code Completion through Hierarchical Code Fusion](https://arxiv.org/abs/2509.05980)
*Xingliang Wang,Baoyi Wang,Chen Zhi,Junxiao Han,Xinkui Zhao,Jianwei Yin,Shuiguang Deng*

Main category: cs.SE

TL;DR: 本文提出GRACE，将多种代码结构统一进图模型，并采用结构化检索和融合策略，极大提升了仓库级代码补全任务的效果，在主流数据集上远超现有方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在局部代码补全任务上表现优秀，但由于上下文窗口限制和代码库内部复杂的语义与结构依赖，难以应对仓库级任务。虽然RAG（检索增强生成）方法能缓解上下文短缺问题，但现有方法主要依赖文本相似度检索，忽视了代码的结构关系，并在拼接检索结果时丢失了重要的结构信息。

Method: 提出GRACE方法，构建多层次、多语义的代码图，将文件结构、抽象语法树（AST）、函数调用图、类继承关系和数据流图统一起来，捕捉代码静态和动态语义。检索阶段，利用图神经网络实现结构化检索，结合文本检索，并通过图注意力网络重排序子图以优先关联拓扑相关区域。上下文融合阶段，采用结构融合机制，将检索回来的子图与局部代码上下文合并，保留关键依赖。

Result: 在公共仓库级基准测试上，GRACE在所有指标上显著优于现有最先进方法。以DeepSeek-V3为主干LLM，GRACE在每个数据集上分别比最强的基于图的RAG方法提升了8.19%的EM和7.51%的ES分数。

Conclusion: GRACE通过结构化语义增强及高效的图检索机制，有效解决了现有LLM和RAG方法在仓库级代码补全中的语境和结构理解不足问题，实现了大幅性能提升。

Abstract: LLMs excel in localized code completion but struggle with repository-level
tasks due to limited context windows and complex semantic and structural
dependencies across codebases. While Retrieval-Augmented Generation (RAG)
mitigates context scarcity by retrieving relevant code snippets, current
approaches face significant limitations. They overly rely on textual similarity
for retrieval, neglecting structural relationships such as call chains and
inheritance hierarchies, and lose critical structural information by naively
concatenating retrieved snippets into text sequences for LLM input. To address
these shortcomings, GRACE constructs a multi-level, multi-semantic code graph
that unifies file structures, abstract syntax trees, function call graphs,
class hierarchies, and data flow graphs to capture both static and dynamic code
semantics. For retrieval, GRACE employs a Hybrid Graph Retriever that
integrates graph neural network-based structural similarity with textual
retrieval, refined by a graph attention network-based re-ranker to prioritize
topologically relevant subgraphs. To enhance context, GRACE introduces a
structural fusion mechanism that merges retrieved subgraphs with the local code
context and preserves essential dependencies like function calls and
inheritance. Extensive experiments on public repository-level benchmarks
demonstrate that GRACE significantly outperforms state-of-the-art methods
across all metrics. Using DeepSeek-V3 as the backbone LLM, GRACE surpasses the
strongest graph-based RAG baselines by 8.19% EM and 7.51% ES points on every
dataset. The code is available at
https://anonymous.4open.science/r/grace_icse-C3D5.

</details>


### [18] [Students' Perception of LLM Use in Requirements Engineering Education: An Empirical Study Across Two Universities](https://arxiv.org/abs/2509.05995)
*Sharon Guardado,Risha Parveen,Zheying Zhang,Maruf Rayhan,Nirnaya Tripathi*

Main category: cs.SE

TL;DR: 本研究实证分析了大语言模型在需求工程教育中的应用，发现其可提升学生理解但也带来学术诚信和依赖性等挑战，提出需情境化集成与平衡AI与批判性思维。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在需求工程（RE）教育中的引入旨在提升学生参与度和动机，同时为未来职业发展提供实用工具。作者希望通过实证方法评估LLMs融入RE课程对学生学习体验的影响及其带来的机遇与挑战。

Method: 通过对两个高校共179名学生进行问卷调查，比较了个体作业和团队敏捷项目两种教学模式下LLMs在教学中的应用效果和学生感知体验。

Result: 结果显示，LLMs提升了学生对需求工程概念的理解，尤其是在需求获取和文档编写任务中。然而，学生也表达了对学术诚信、对AI过度依赖以及将AI生成内容整合进作业的困难等担忧。个体作业的学生感受到的获益大于团队作业学生，强调了AI集成情境的重要性。

Conclusion: LLMs可有效提升RE教育效果，但应关注集成的具体情境，平衡AI辅助与批判性思维和协作实践。作者为RE教学中更有效地集成LLMs提出建议，并展望了未来的研究方向。

Abstract: The integration of Large Language Models (LLMs) in Requirements Engineering
(RE) education is reshaping pedagogical approaches, seeking to enhance student
engagement and motivation while providing practical tools to support their
professional future. This study empirically evaluates the impact of integrating
LLMs in RE coursework. We examined how the guided use of LLMs influenced
students' learning experiences, and what benefits and challenges they perceived
in using LLMs in RE practices. The study collected survey data from 179
students across two RE courses in two universities. LLMs were integrated into
coursework through different instructional formats, i.e., individual
assignments versus a team-based Agile project. Our findings indicate that LLMs
improved students' comprehension of RE concepts, particularly in tasks like
requirements elicitation and documentation. However, students raised concerns
about LLMs in education, including academic integrity, overreliance on AI, and
challenges in integrating AI-generated content into assignments. Students who
worked on individual assignments perceived that they benefited more than those
who worked on team-based assignments, highlighting the importance of contextual
AI integration. This study offers recommendations for the effective integration
of LLMs in RE education. It proposes future research directions for balancing
AI-assisted learning with critical thinking and collaborative practices in RE
courses.

</details>


### [19] [A Rapid Review Regarding the Concept of Legal Requirements in Requirements Engineering](https://arxiv.org/abs/2509.06012)
*Jukka Ruohonen*

Main category: cs.SE

TL;DR: 本综述指出需求工程领域对法律需求的定义混乱且缺乏证据支持，法律需求复杂难以处理，需求工程师知识储备有待提升。


<details>
  <summary>Details</summary>
Motivation: 作者出于个人困惑、同行评审意见以及现有文献中的混乱，对法律需求（LRs）在需求工程（RE）研究中的概念进行了快速综述，以澄清相关定义和理解。

Method: 作者进行了文献回顾，分析和评价了需求工程领域关于法律需求的定义、分类和特点，并总结了现存问题与困惑。

Result: 发现需求工程研究中对法律需求常有规范性理解，但缺乏一致和清晰的定义与操作化概念。有文献将法律需求视为功能性或非功能性需求，往往描述为模糊且复杂、难以获取和实现，以及易变和重叠。需求工程师对这些需求存在知识空白，相关需求常被最低限度实现。

Conclusion: 文献回顾表明对法律需求的理解存在实证依据不足和持续的概念混乱，亟需在定义、操作化与知识支持方面予以加强。

Abstract: Out of a personal puzzlement, recent peer review comments, and demonstrable
confusion in the existing literature, the paper presents a rapid review of the
concept of legal requirements (LRs) in requirements engineering (RE) research.
According to reviewing results, a normative understanding of LRs has often been
present, although proper definitions and conceptual operationalizations are
lacking. Some papers also see LRs as functional and others as non-functional
requirements. Legal requirements are often characterized as being vague and
complex, requiring a lot of effort to elicit, implement, and validate. These
characterizations supposedly correlate with knowledge gaps among requirements
engineers. LRs are also seen to often change and overlap. They may be also
prioritized. According to the literature, they seem to be also reluctantly
implemented, often providing only a minimal baseline for other requirements.
With these and other observations, the review raises critical arguments about
apparent knowledge gaps, including a lack of empirical evidence backing the
observations and enduring conceptual confusion.

</details>


### [20] [Empirical Study of Code Large Language Models for Binary Security Patch Detection](https://arxiv.org/abs/2509.06052)
*Qingyuan Li,Binchang Li,Cuiyun Gao,Shuzheng Gao,Zongjie Li*

Main category: cs.SE

TL;DR: 本文提出基于大模型微调提升二进制安全补丁检测能力，并发布首个大规模数据集。原生模型效果有限，但在微调和伪代码表示下取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的安全补丁检测方法大多依赖源代码，而实际中大量闭源软件只能获得二进制补丁；同时，虽有LLM在代码理解和二进制分析任务上表现出色，但其在二进制安全补丁检测上的能力尚未得到探索。

Method: 1) 构建大规模二进制补丁数据集，包含19448个样本，采用汇编代码和伪代码两种表示；2) 系统性评估19种不同规模的代码LLM在二进制安全补丁检测（SPD）任务上的表现；3) 对部分LLM进行微调，引入领域知识，以提升性能。

Result: 原生LLM直接用于二进制安全补丁检测效果较差，即使引入先进的提示工程（prompting）也无法弥补其领域知识短板。通过微调并注入领域知识后，模型性能显著提升，以伪代码表示为输入时效果最好。

Conclusion: 对代码大型语言模型（LLM）的微调，尤其在伪代码表示下，可显著提升其检测二进制安全补丁的能力。

Abstract: Security patch detection (SPD) is crucial for maintaining software security,
as unpatched vulnerabilities can lead to severe security risks. In recent
years, numerous learning-based SPD approaches have demonstrated promising
results on source code. However, these approaches typically cannot be applied
to closed-source applications and proprietary systems that constitute a
significant portion of real-world software, as they release patches only with
binary files, and the source code is inaccessible. Given the impressive
performance of code large language models (LLMs) in code intelligence and
binary analysis tasks such as decompilation and compilation optimization, their
potential for detecting binary security patches remains unexplored, exposing a
significant research gap between their demonstrated low-level code
understanding capabilities and this critical security task. To address this
gap, we construct a large-scale binary patch dataset containing \textbf{19,448}
samples, with two levels of representation: assembly code and pseudo-code, and
systematically evaluate \textbf{19} code LLMs of varying scales to investigate
their capability in binary SPD tasks. Our initial exploration demonstrates that
directly prompting vanilla code LLMs struggles to accurately identify security
patches from binary patches, and even state-of-the-art prompting techniques
fail to mitigate the lack of domain knowledge in binary SPD within vanilla
models. Drawing on the initial findings, we further investigate the fine-tuning
strategy for injecting binary SPD domain knowledge into code LLMs through two
levels of representation. Experimental results demonstrate that fine-tuned LLMs
achieve outstanding performance, with the best results obtained on the
pseudo-code representation.

</details>


### [21] [Software Dependencies 2.0: An Empirical Study of Reuse and Integration of Pre-Trained Models in Open-Source Projects](https://arxiv.org/abs/2509.06085)
*Jerin Yasmin,Wenxin Jiang,James C. Davis,Yuan Tian*

Main category: cs.SE

TL;DR: 本研究分析了401个GitHub开源项目中的预训练模型（PTM）使用与管理模式，揭示PTM已成为影响软件可维护性和可靠性的关键依赖，并梳理了依赖文档化、重用流程和组件交互等实际做法。


<details>
  <summary>Details</summary>
Motivation: 在现代软件开发中，预训练模型（PTM）的广泛应用带来了新的软件依赖形式，即“软件依赖2.0”，突破了传统依赖库的定义。由于这些模型及其相关工件成为程序的重要组成部分，而如何有效地集成和管理PTM依赖，却仍不明朗，并可能影响软件的可维护性和可靠性。

Method: 本研究采用混合方法，对PeaTMOSS数据集中401个来自GitHub的、重用Hugging Face和PyTorch Hub PTM的开源项目进行了统计学显著的随机采样分析。研究通过定量识别PTM重用模式，并定性调查开发者在实际中如何集成和管理这些模型。

Result: 研究揭示了（1）开源项目在PTM依赖结构化和文档化方面的做法；（2）PTM重用管道中的阶段及其出现的组织模式；（3）PTM与其他学习组件在各阶段的交互。

Conclusion: 预训练模型作为新型软件依赖已深度融入开源项目，项目在PTM依赖管理和集成方面表现出不同的结构、流程与交互方式。对PTM管理的深入理解，有助于提升现代软件系统的可维护性与可靠性。

Abstract: Pre-trained models (PTMs) are machine learning models that have been trained
in advance, often on large-scale data, and can be reused for new tasks, thereby
reducing the need for costly training from scratch. Their widespread adoption
introduces a new class of software dependency, which we term Software
Dependencies 2.0, extending beyond conventional libraries to learned behaviors
embodied in trained models and their associated artifacts. The integration of
PTMs as software dependencies in real projects remains unclear, potentially
threatening maintainability and reliability of modern software systems that
increasingly rely on them. Objective: In this study, we investigate Software
Dependencies 2.0 in open-source software (OSS) projects by examining the reuse
of PTMs, with a focus on how developers manage and integrate these models.
Specifically, we seek to understand: (1) how OSS projects structure and
document their PTM dependencies; (2) what stages and organizational patterns
emerge in the reuse pipelines of PTMs within these projects; and (3) the
interactions among PTMs and other learned components across pipeline stages. We
conduct a mixed-methods analysis of a statistically significant random sample
of 401 GitHub repositories from the PeaTMOSS dataset (28,575 repositories
reusing PTMs from Hugging Face and PyTorch Hub). We quantitatively examine PTM
reuse by identifying patterns and qualitatively investigate how developers
integrate and manage these models in practice.

</details>


### [22] [Agentic Software Engineering: Foundational Pillars and a Research Roadmap](https://arxiv.org/abs/2509.06216)
*Ahmed E. Hassan,Hao Li,Dayi Lin,Bram Adams,Tse-Hsun Chen,Yutaro Kashiwa,Dong Qiu*

Main category: cs.SE

TL;DR: 本文提出了结构化智能体软件工程（SASE）远景，通过区分‘为人类的软件工程’和‘为智能体的软件工程’，设计了双工作环境以实现人机高效协作，并抛出研究挑战，呼吁行业共同探索可信、可扩展的智能体主导软件工程新范式。


<details>
  <summary>Details</summary>
Motivation: 借助智能体（agent）来推动软件工程发展，但不仅仅停留在代码生成层面，而是希望这些智能体能够自主完成复杂的、面向目标的软件工程任务。为充分发挥智能体的能力并确保其可信性，作者认识到在智能体软件工程时代，SE（软件工程）领域需要分为面向人类和面向智能体两个共生子领域，这对现有的基础理论和实践提出了新挑战。

Method: 提出了一个以结构化智能体软件工程（SASE）为核心的远景蓝图，设计了两个配套工作平台：1）Agent Command Environment（ACE），供人类管理和指导智能体团队，处理相应输出（如合并准备包和咨询请求包）；2）Agent Execution Environment（AEE），智能体在此环境中自主作业，并可在决策不明或面对复杂权衡时主动回调人类。通过双向协作流程重塑人机合作方式，并给出未来研究方向图谱。

Result: 提出了面向智能体软件工程的结构化理论体系（SASE），以及匹配的双工作台架构（ACE及AEE），阐述了人机深度协作、回调机制等关键要素。整合了新型流程与工程活动，推动了从‘智能体编码’到真正‘智能体软件工程’的跨越。同时梳理并提出了未来的主要研究挑战和机遇。

Conclusion: 本文不是直接给出最终解决方案，而是提供了一个结构化观点及术语框架，旨在推动软件工程界对人类与智能体如何协同、如何实现可扩展和可信的未来软件工程模式进行深入广泛的讨论。

Abstract: Agentic Software Engineering (SE 3.0) represents a new era where intelligent
agents are tasked not with simple code generation, but with achieving complex,
goal-oriented SE objectives. To harness these new capabilities while ensuring
trustworthiness, we must recognize a fundamental duality within the SE field in
the Agentic SE era, comprising two symbiotic modalities: SE for Humans and SE
for Agents. This duality demands a radical reimagining of the foundational
pillars of SE (actors, processes, tools, and artifacts) which manifest
differently across each modality. We propose two purpose-built workbenches to
support this vision. The Agent Command Environment (ACE) serves as a command
center where humans orchestrate and mentor agent teams, handling outputs such
as Merge-Readiness Packs (MRPs) and Consultation Request Packs (CRPs). The
Agent Execution Environment (AEE) is a digital workspace where agents perform
tasks while invoking human expertise when facing ambiguity or complex
trade-offs. This bi-directional partnership, which supports agent-initiated
human callbacks and handovers, gives rise to new, structured engineering
activities (i.e., processes) that redefine human-AI collaboration, elevating
the practice from agentic coding to true agentic software engineering. This
paper presents the Structured Agentic Software Engineering (SASE) vision,
outlining several of the foundational pillars for the future of SE. The paper
culminates in a research roadmap that identifies a few key challenges and
opportunities while briefly discussing the resulting impact of this future on
SE education. Our goal is not to offer a definitive solution, but to provide a
conceptual scaffold with structured vocabulary to catalyze a community-wide
dialogue, pushing the SE community to think beyond its classic, human-centric
tenets toward a disciplined, scalable, and trustworthy agentic future.

</details>


### [23] [Learning From Software Failures: A Case Study at a National Space Research Center](https://arxiv.org/abs/2509.06301)
*Dharun Anandayuvaraj,Zain Hammadeh,Andreas Lund,Alexandra Holloway,James C. Davis*

Main category: cs.SE

TL;DR: 通过对高可靠性组织软件工程师的访谈，揭示当前失败学习普遍缺乏正式机制、重复问题常现及多项挑战，并为优化管理流程提供了实证依据。


<details>
  <summary>Details</summary>
Motivation: 软件故障可能带来严重后果，因此从失败中学习对于提升软件工程至关重要。然而，现有的后事复盘实践在组织之间执行效果和采纳率差异较大，缺乏对学习过程与挑战的深入行业洞见，特别是在高可靠性组织（HROs）领域。该领域对持续学习有高度需求，因此有必要深入了解其失败学习的实际做法与痛点。

Method: 作者通过对一个国家级空间研究中心的10位研究软件工程师进行了深入访谈，并补充了来自其他HROs的5位工程师访谈，采用案例研究法调查他们如何收集、记录、共享和应用失效经验，总结行业现状及挑战。

Result: 研究发现：1）失败学习过程较为非正式、临时且未被系统性纳入软件开发生命周期；2）由于缺乏结构化流程，导致同类问题重复发生；3）面临的主要挑战包括时间紧张、员工流动引发知识流失、文档分散及流程执行力度不足。这些障碍共同阻碍了系统性、有效的失败学习。

Conclusion: 该研究加深了对软件工程师在实际中如何学习应对失败的理解，为改进故障管理与学习机制提供了实践建议，对提升高可靠性组织软件可靠性有指导意义。

Abstract: Software failures can have significant consequences, making learning from
failures a critical aspect of software engineering. While software
organizations are recommended to conduct postmortems, the effectiveness and
adoption of these practices vary widely. Understanding how engineers gather,
document, share, and apply lessons from failures is essential for improving
reliability and preventing recurrence. High-reliability organizations (HROs)
often develop software systems where failures carry catastrophic risks,
requiring continuous learning to ensure reliability. These organizations
provide a valuable setting to examine practices and challenges for learning
from software failures. Such insight could help develop processes and tools to
improve reliability and prevent recurrence. However, we lack in-depth industry
perspectives on the practices and challenges of learning from failures.
  To address this gap, we conducted a case study through 10 in-depth interviews
with research software engineers at a national space research center. We
examine how they learn from failures: how they gather, document, share, and
apply lessons. To assess transferability, we include data from 5 additional
interviews at other HROs. Our findings provide insight into how engineers learn
from failures in practice. To summarize: (1) failure learning is informal, ad
hoc, and inconsistently integrated into SDLC; (2) recurring failures persist
due to absence of structured processes; and (3) key challenges, including time
constraints, knowledge loss from turnover and fragmented documentation, and
weak process enforcement, undermine systematic learning. Our findings deepen
understanding of how software engineers learn from failures and offer guidance
for improving failure management practices.

</details>


### [24] [A Generic and Efficient Python Runtime Verification System and its Large-scale Evaluation](https://arxiv.org/abs/2509.06324)
*Zhuohang Shen,Mohammed Yaseen,Denini Silva,Kevin Guan,Junho Lee,Marcelo d'Amorim,Owolabi Legunsen*

Main category: cs.SE

TL;DR: PyMOP带来了高效且通用的Python运行时验证平台，明显优于现有方案。其监控性能优秀，已帮助修复多个实际软件Bug。


<details>
  <summary>Details</summary>
Motivation: 虽然 Java 领域的运行时验证技术已经十分成熟，但 Python 当前的工具局限性较大。研究者希望开发一种能够跨领域、易扩展且高效的Python运行时验证平台，提升整个生态系统的代码质量。

Method: PyMOP 集成五种监控算法、支持多种逻辑和插桩策略，实测覆盖大量开源项目，并与现有系统进行了性能对比分析。

Result: PyMOP 是一个针对 Python 的高效、通用、可扩展的运行时验证（RV）系统。它支持五种逻辑、五种监控算法、包含73个API规范及广泛使用的库，且支持三种代码插桩策略并易于扩展。对1463个GitHub项目的约29万单元测试进行评估，发现 PyMOP 比两个最新系统快最多1168倍，并且发现的121个 Bug 中有44个已被修复。

Conclusion: PyMOP 由于其通用性和高效性，非常适合推动 Python 领域运行时验证的进一步发展，成为研究和工业应用的理想平台。

Abstract: Runtime verification (RV) now scales for testing thousands of open-source
Java projects, helping find hundreds of bugs. The popular Python ecosystem
could use such benefits. But, today's Python RV systems are limited to a domain
or specification logic, or slow. We propose PyMOP, a generic, extensible, and
efficient RV system for Python. PyMOP supports five logics, implements five
existing monitoring algorithms, ships with 73 API specs of Python and
widely-used libraries, supports three instrumentation strategies, and users can
easily add more of these. On 290,133 unit tests in 1,463 GitHub projects, we
find mainly that (i) the default monitoring algorithm for Java is often not the
fastest for Python; (ii) PyMOP is up to 1,168.3x faster than two recent dynamic
analysis systems; and (iii) 44 of 121 bugs that PyMOP helped find so far were
fixed by developers. PyMOP's generality and efficiency position it well as an
excellent platform for the next advances on RV for Python.

</details>


### [25] [Analyzing the Instability of Large Language Models in Automated Bug Injection and Correction](https://arxiv.org/abs/2509.06429)
*Mehmet Bilal Er,Nagehan İlhan,Umut Kuran*

Main category: cs.SE

TL;DR: 本文系统评估了LLM（如ChatGPT）在不同温度下修复bug的一致性，发现温度越高，模型输出越不稳定，且功能正确性显著下降。这表明在软件开发中使用LLM修复bug时需关注温度参数，对其稳定性和可靠性需谨慎。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在软件工程（如bug修复和代码生成）应用日益增多，但其不稳定性未被深入探讨，特别是bug修复任务的结果一致性问题亟需分析。

Method: 通过设置不同温度（0，0.5，1），让LLM对20个问题各生成三组修复建议，总计9个输出，采用Syntax Similarity和Output Equivalence Rate（OER）指标评估输出的结构和功能一致性。

Result: 低温度下的输出结构较为一致，而高温度下修复建议结构差异明显，且功能失败率高。研究揭示了温度对LLM稳定性影响重大，并为其在实际软件开发流程中的应用提供了方法学启示。

Conclusion: 随着温度增加，LLM模型在bug修复任务上的输出不稳定性明显增强，尤其高温度下功能失败率极高，这对其在软件开发中的可靠性提出了质疑。

Abstract: The use of Large Language Models (LLMs) in software engineering tasks is
growing, especially in the areas of bug fixing and code generation.
Nevertheless, these models often yield unstable results; when executed at
different times with the same input, they can generate radically different
code. The consistency of LLMs in bug-fixing tasks has not yet been thoroughly
assessed, despite the fact that this instability has typically been discussed
in the literature in relation to code generation. The purpose of this study is
to look into how unstable an LLM like ChatGPT is when it comes to fixing code
bugs. We examine the structural, syntactic, and functional variations among
several fix recommendations made in response to the same prompt using code
samples with various error types. Additionally, we assess how instability is
affected by the temperature settings (0, 0.5, and 1) used for the model's
deterministic operation. For a total of 20 problems in the experimental
analysis, the model produced three fix suggestions at each temperature value,
comparing nine distinct outputs for each problem. The Syntax Similarity and
Output Equivalence Rate (OER) metrics were used to assess the outputs'
structural and functional consistency. The results demonstrate that the model's
outputs become much more unstable and variable as the temperature rises, with
high temperatures showing especially high rates of functional failure.
According to syntax similarity analyses, the suggested fixes show notable
structural differences at high temperatures but are fairly similar at low
temperatures. The purpose of this study is to provide important methodological
insights into how LLM-based error correction systems can be applied more
consistently in software development processes while also casting doubt on
their dependability.

</details>


### [26] [Modeling in the Design Multiverse](https://arxiv.org/abs/2509.06530)
*Sylvain Guérin,Salvador Martinez,Ciprian Teodorov*

Main category: cs.SE

TL;DR: 本论文提出了Design Multiverse，在建模空间内融合设计路径的分支和修订，便于跟踪和管理多样化设计进程，提高设计管理效率。


<details>
  <summary>Details</summary>
Motivation: 现实中的设计过程常常涉及设计路径的演化与分叉，尤其在多团队或多利益相关者并行工作时更为复杂。当前建模空间无法直接管理这些变体和分支，需要借助外部工具和方法，因此亟需方法在建模空间内直接管理设计变体和演化。

Method: 提出并定义了Design Multiverse（设计多元宇宙）概念，并通过模型联盟范式实现该机制。同时，给出了典型应用场景，包括模型产品线和模型/元模型协同演化。

Result: 实现了在建模空间内集成设计修订和变体，使利益相关者能无缝跟踪、分析和管理设计决策、系统变体及其相互依赖关系。展示了概念定义、应用场景和具体实现方法。

Conclusion: Design Multiverse为复杂系统设计中的多路径演化带来集成管理的新方案，提升了设计过程的信息可追踪性和管理效率，有助于多团队协作和系统开发多样性的需求。

Abstract: Real-world design processes often involve the evolution and divergence of
design paths (by branching, revising, merging, etc.), especially when multiple
stakeholders or teams operate concurrently and/or explore different
alternatives for complex and heterogeneous systems. Unfortunately, this
variability in time and space can not be directly managed in current modeling
spaces but requires resorting to external tools and methodologies.
  In order to tackle this problem, we introduce the Design Multiverse. The
Design Multiverse aims to integrate in the modeling space a selection of
revisions and variants, representing snapshots of a design state composed of
multiple artifacts. This enables stakeholders to seamlessly trace, analyze, and
manage design decisions, system variants, and their interdependencies.
Concretely, in this paper we present a conceptual definition of the Design
Multiverse, discuss usage scenarios such as model product lines and
model/metamodel co-evolution, and propose an implementation leveraging the
model federation paradigm.

</details>


### [27] [Design and Implementation of a Domain-specific Language for Modelling Evacuation Scenarios Using Eclipse EMG/GMF Tool](https://arxiv.org/abs/2509.06688)
*Heerok Banerjee*

Main category: cs.SE

TL;DR: 本文提出了基于Eclipse EMF/GMF的领域特定建模语言Bmod，用于疏散场景建模，并与现有主流工具在表达能力、学习曲线和性能等方面进行了对比，结果显示其具备不错的易用性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前DSL在支持图形界面、层次结构及简便实现方面尚不完善，特别是对于新手用户，存在较高门槛。为解决这一问题，提出更易用的领域建模语言以提升企业业务管理效率。

Method: 使用Eclipse Modelling Framework (EMF) 和 Eclipse Graphical Modelling Framework (GMF) 构建Bmod语言，并与其它建模工具（AToMPM、metaDepth、Sirius等）进行比较分析。

Result: Bmod能够有效建模疏散场景，并在易用性、表达能力及性能方面对比其他工具展现出一定优势。

Conclusion: 本文提出并实现了一种新的DSL（Bmod），通过对比不同建模工具，展示了其易用性和性能优势。

Abstract: Domain-specific languages (DSLs) play a crucial role in resolving internal
dependencies across enterprises and boosts their upfront business management
processes. Yet, a lot of development is needed to build modelling frameworks
which support graphical interfaces (canvas, pallettes etc.), hierarchical
structures and easy implementation to shorten the gap for novice users. In this
paper, a DSL namely, Bmod is introduced, which can be used to model evacuation
scenarios. The language is built using Eclipse Modelling Framework (EMF) and
Eclipse Graphical Modelling Framework (GMF). Furthermore, a comparison is also
shown between Eclipse EMF/GMF and other modelling tools such as AToMPM,
metaDepth, Sirius etc with respect to expressiveness, learning curve and
performance.

</details>


### [28] [Efficiently Ranking Software Variants with Minimal Benchmarks](https://arxiv.org/abs/2509.06716)
*Théo Matricon,Mathieu Acher,Helge Spieker,Arnaud Gotlieb*

Main category: cs.SE

TL;DR: 文章提出了BISS方法，大幅减少了基准测试的测试用例数量和资源消耗，同时保持测试结果的排名不变，具有很强的实际应用效果。


<details>
  <summary>Details</summary>
Motivation: 基准测试在软件工程中用于评估不同软件变体的性能和质量，但完整执行所有测试极其耗费计算资源和时间。如何在不影响评测有效性的前提下降低测试成本，是实际应用中的实际需求。

Method: 提出了一种新的基准测试优化方法——BISection Sampling (BISS)。该方法结合测试套件优化与分治策略，通过挑选关键测试和高效采样，减少需要执行的测试用例数量，同时尽量保持软件变体的性能排名稳定。

Result: 在LLM排行榜、SAT竞赛和可配置系统的实验中，BISS方法在变体子集上也能优于现有基线做法。平均可将基准测试的计算成本降至44%，多数情况下最高可减少99%，而排名稳定性没有降低。

Conclusion: BISS方法能够显著减少基准测试的计算消耗，不损害变体性能排名的准确性，对大规模或频繁基准测试场景具有实际应用价值。

Abstract: Benchmarking is a common practice in software engineering to assess the
qualities and performance of software variants, coming from multiple competing
systems or from configurations of the same system. Benchmarks are used notably
to compare and understand variant performance, fine-tune software, detect
regressions, or design new software systems. The execution of benchmarks to get
a complete picture of software variants is highly costly in terms of
computational resources and time. In this paper, we propose a novel approach
for reducing benchmarks while maintaining stable rankings, using test suite
optimization techniques. That is, we remove instances from the benchmarks while
trying to keep the same rankings of the variants on all tests. Our method,
BISection Sampling, BISS, strategically retains the most critical tests and
applies a novel divide-and-conquer approach to efficiently sample among
relevant remaining tests. We experiment with datasets and use cases from LLM
leaderboards, SAT competitions, and configurable systems for performance
modeling. Our results show that our method outperforms baselines even when
operating on a subset of variants. Using BISS, we reduce the computational cost
of the benchmarks on average to 44% and on more than half the benchmarks by up
to 99% without loss in ranking stability.

</details>


### [29] [OpenCoderRank: AI-Driven Technical Assessments Made Easy](https://arxiv.org/abs/2509.06774)
*Hridoy Sankar Dutta,Sana Ansari,Swati Kumari,Shounak Ravi Bhalerao*

Main category: cs.SE

TL;DR: 本文提出了一款名为OpenCoderRank的技术测评平台，其通过桥接题目设计者和参与者，提升评估的公平性、可靠性和适配多样环境的能力，尤其适用于资源有限的组织和教育机构。


<details>
  <summary>Details</summary>
Motivation: 现有的技术测评工具面临着在评估编码与问题解决能力时，既要保证题目难度和相关性，也要防止大型语言模型（LLM）对题目解答带来的影响，保证测评的公正性和效果。

Method: 本文提出了OpenCoderRank平台，旨在模拟技术测评。该平台为题目设计者和解答者搭建了桥梁，同时支持自托管和定制化设置，适合资源受限环境下的技术评估。

Result: OpenCoderRank平台可以帮助解答者更好地适应时间限制和陌生问题，提高实际测评准备效率；同时为题目设计者提供免费、灵活且可靠的测评工具方案。

Conclusion: OpenCoderRank有效解决了技术测评中题目设计与答题效率之间的矛盾，提升了实际应用中的测评质量与可操作性。

Abstract: Organizations and educational institutions use time-bound assessment tasks to
evaluate coding and problem-solving skills. These assessments measure not only
the correctness of the solutions, but also their efficiency. Problem setters
(educator/interviewer) are responsible for crafting these challenges, carefully
balancing difficulty and relevance to create meaningful evaluation experiences.
Conversely, problem solvers (student/interviewee) apply coding efficiency and
logical thinking to arrive at correct solutions. In the era of Large Language
Models (LLMs), LLMs assist problem setters in generating diverse and
challenging questions, but they can undermine assessment integrity for problem
solvers by providing easy access to solutions. This paper introduces
OpenCoderRank, an easy-to-use platform designed to simulate technical
assessments. It acts as a bridge between problem setters and problem solvers,
helping solvers prepare for time constraints and unfamiliar problems while
allowing setters to self-host assessments, offering a no-cost and customizable
solution for technical assessments in resource-constrained environments.

</details>


### [30] [Hypergraph-Guided Regex Filter Synthesis for Event-Based Anomaly Detection](https://arxiv.org/abs/2509.06911)
*Margarida Ferreira,Victor Nicolet,Luan Pham,Joey Dodds,Daniel Kroening,Ines Lynce,Ruben Martins*

Main category: cs.SE

TL;DR: HyGLAD是一种新颖且可解释的事件数据异常检测算法，准确高效超过了现有深度学习方法。


<details>
  <summary>Details</summary>
Motivation: 当前事件数据异常检测多采用深度学习方法，但可解释性较差，实际应用中需要可理解、透明的方法以便更好定位和理解异常来源。

Method: 提出了HyGLAD算法，通过自动推断行为相似的实体等价类，并构建正则表达式模型，用于捕获实体的行为特征，实现对异常的可解释检测。与深度学习不同，HyGLAD得到的模式和异常都是可直接解释的。

Result: 在5个真实数据集与7种无监督深度异常检测方法（DeepOD套件）对比中，HyGLAD在准确率和召回率方面分别比第二优方法高1.2倍和1.3倍，并且训练和推断效率高出至少一个数量级（单核CPU vs GPU）。

Conclusion: HyGLAD不仅检测精度优于主流深度学习方法，还具有出色的解释性与高效性，适合实际系统事件异常检测。

Abstract: We propose HyGLAD, a novel algorithm that automatically builds a set of
interpretable patterns that model event data. These patterns can then be used
to detect event-based anomalies in a stationary system, where any deviation
from past behavior may indicate malicious activity. The algorithm infers
equivalence classes of entities with similar behavior observed from the events,
and then builds regular expressions that capture the values of those entities.
As opposed to deep-learning approaches, the regular expressions are directly
interpretable, which also translates to interpretable anomalies. We evaluate
HyGLAD against all 7 unsupervised anomaly detection methods from DeepOD on five
datasets from real-world systems. The experimental results show that on average
HyGLAD outperforms existing deep-learning methods while being an order of
magnitude more efficient in training and inference (single CPU vs GPU).
Precision improved by 1.2x and recall by 1.3x compared to the second-best
baseline.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [31] [Compositional Inductive Invariant Inference via Assume-Guarantee Reasoning](https://arxiv.org/abs/2509.06250)
*Ian Dardik,Eunsuk Kang*

Main category: cs.LO

TL;DR: 本文提出了一种将复杂系统拆分为组件并用局部归纳不变式方法进行安全验证的新框架，提升了推理效率并提供了更好的系统模块化洞见。


<details>
  <summary>Details</summary>
Motivation: 复杂系统的安全验证通常使用归纳不变式方法，但归纳不变式公式往往非常复杂，推理极具挑战性。作者发现公式复杂的主要原因在于其需对整个系统的状态转移关系封闭。

Method: 提出将系统拆分为若干组件，为每个组件分配假设-保证契约，通过推理局部归纳不变式来证明组件满足契约。各组件的局部不变式只需在自身的状态转移关系下封闭，最后系统整体的安全性由所有组件不变式的合取推出。

Result: 在两个案例研究中，作者展示了该组合式的归纳不变式推理框架相较于传统全局方法更高效。此外，局部归纳不变式能够提供模块化的规范洞见，这是全局不变式难以实现的。

Conclusion: 组合式局部归纳不变式推理能够简化复杂系统安全验证，提高推理效率，并带来对系统规范的模块化理解。

Abstract: A common technique for verifying the safety of complex systems is the
inductive invariant method. Inductive invariants are inductive formulas that
overapproximate the reachable states of a system and imply a desired safety
property. However, inductive invariants are notoriously complex, which makes
inductive invariant inference a challenging problem. In this work, we observe
that inductive invariant formulas are complex primarily because they must be
closed over the transition relation of an entire system. Therefore, we propose
a new approach in which we decompose a system into components, assign an
assume-guarantee contract to each component, and prove that each component
fulfills its contract by inferring a local inductive invariant. The key
advantage of local inductive invariant inference is that the local invariant
need only be closed under the transition relation for the component, which is
simpler than the transition relation for the entire system. Once local
invariant inference is complete, system-wide safety follows by construction
because the conjunction of all local invariants becomes an inductive invariant
for the entire system. We apply our compositional inductive invariant inference
technique to two case studies, in which we provide evidence that our framework
can infer invariants more efficiently than the global technique. Our case
studies also show that local inductive invariants provide modular insights
about a specification that are not offered by global invariants.

</details>


### [32] [Verifying Sampling Algorithms via Distributional Invariants](https://arxiv.org/abs/2509.06410)
*Kevin Batz,Joost-Pieter Katoen,Tobias Winkler,Daniel Zilken*

Main category: cs.LO

TL;DR: 该论文构建了一个验证离散概率采样算法正确性的全新理论框架，能形式化证明具体算法的可靠性，推进了概率程序正确性验证领域的发展。


<details>
  <summary>Details</summary>
Motivation: 随着离散采样算法在概率程序和随机模拟中的广泛应用，确保这些算法的正确性变得尤为重要。目前缺乏系统化的自动化验证工具，难以保证实现无误。该论文希望为此提供理论基础和实用方法。

Method: 作者提出了一种将概率程序视为分布变换器的验证框架。引入（归纳的）分布不变式概念，嵌入到类似Hoare逻辑的验证体系中，支持概率程序的全正确性与部分正确性证明。通过应用于两种具体采样算法（Fast Dice Roller、Fast Loaded Dice Roller）展示其方法的实用性。

Result: 通过该验证框架，作者成功地形式化证明了Fast Dice Roller与Fast Loaded Dice Roller两个离散采样算法的正确性，说明新方法能够实用并具备推广性。

Conclusion: 论文提出了适用于概率程序的分布变换验证框架及归纳分布不变式，增强了对离散采样算法正确性的自动化和形式化证明能力。实验证明框架具有实际可行性和一定的普适推广潜力。

Abstract: This paper develops a verification framework aimed at establishing the
correctness of discrete sampling algorithms. We do so by considering
probabilistic programs as distribution transformers. Inspired by recent work on
distributional verification of Markov models, we introduce the notion of
(inductive) distributional loop invariants for discrete probabilistic programs.
These invariants are embedded in a Hoare-like verification framework that
includes proof rules for total and partial correctness. To illustrate the
applicability of our framework, we prove the correctness of two discrete
sampling algorithms: the Fast Dice Roller and the Fast Loaded Dice Roller.

</details>


### [33] [Tabular intermediate logics comparison](https://arxiv.org/abs/2509.06841)
*Paweł Rzążewski,Michał Stronkowski*

Main category: cs.LO

TL;DR: 论文研究了有限偏序集生成的中间逻辑包含性与p-同态判定的复杂性，发现一般情况为NP（某些特定条件下为NP完全），但若其中一个偏序集为树，则相关判定可以高效实现。


<details>
  <summary>Details</summary>
Motivation: 分析表格中间逻辑之间的包含性判定的算法复杂性，并通过结构转化将现有图理论的难度结论扩展到逻辑偏序集领域，特别关注不同结构（如树形结构）下的复杂性变化。

Method: 将图的同态问题与偏序集的p-同态问题进行构造性转换，从而借用图理论中的难度结论。同时，针对树形偏序集，提出了多项式时间判定算法。

Result: 证明了LogContain和SPMorph属于NP，受限于某些特定结构（如给定的18元偏序集Q）为NP完全；对于树形偏序集，可以在多项式时间内有效判定相关问题。

Conclusion: 针对有限偏序集所生成的表格中间逻辑两个包含性与p-同态问题，部分情况下为NP完全（例如存在18元偏序集Q使得判定是否L(P)⊆L(Q)为NP完全）；而当其中一个偏序集为树形结构时，相关问题可在多项式时间内解决。

Abstract: Tabular intermediate logics are intermediate logics characterized by finite
posets treated as Kripke frames. For a poset $\mathbb{P}$, let $L(\mathbb{P})$
denote the corresponding tabular intermediate logic. We investigate the
complexity of the following decision problem $\mathsf{LogContain}$: given two
finite posets $\mathbb P$ and $\mathbb Q$, decide whether $L(\mathbb P)
\subseteq L(\mathbb Q)$.
  By Jankov's and de Jongh's theorem, the problem $\mathsf{LogContain}$ is
related to the problem $\mathsf{SPMorph}$: given two finite posets $\mathbb P$
and $\mathbb Q$, decide whether there exists a surjective $p$-morphism from
$\mathbb P$ onto $\mathbb Q$. Both problems belong to the complexity class NP.
  We present two contributions. First, we describe a construction which,
starting with a graph $\mathbb{G}$, gives a poset $\mathsf{Pos}(\mathbb{G})$
such that there is a surjective locally surjective homomorphism (the
graph-theoretic analog of a $p$-morphism) from $\mathbb{G}$ onto $\mathbb{H}$
if and only if there is a surjective $p$-morphism from
$\mathsf{Pos}(\mathbb{G})$ onto $\mathsf{Pos}(\mathbb{H})$. This allows us to
translate some hardness results from graph theory and obtain that several
restricted versions of the problems $\mathsf{LogContain}$ and
$\mathsf{SPMorph}$ are NP-complete. Among other results, we present a
18-element poset $\mathbb{Q}$ such that the problem to decide, for a given
poset $\mathbb{P}$, whether $L(\mathbb{P})\subseteq L(\mathbb{Q})$ is
NP-complete.
  Second, we describe a polynomial-time algorithm that decides
$\mathsf{LogContain}$ and $\mathsf{SPMorph}$ for posets $\mathbb{T}$ and
$\mathbb{Q}$, when $\mathbb{T}$ is a tree.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [34] [An Empirical Analysis of Discrete Unit Representations in Speech Language Modeling Pre-training](https://arxiv.org/abs/2509.05359)
*Yanis Labrak,Richard Dufour,Mickaël Rouvier*

Main category: cs.CL

TL;DR: 本文系统探讨了SLMs中语音离散单元的优化策略，发现编码器选择、聚类方式和领域匹配对声码预训练至关重要，并揭示其与模型规模的关系及对鲁棒性的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管在SLMs中已有一定的进展，如何最优地将语言预训练模型适配至语音模态，以及离散表示在该过程中如何影响模型表现等关键问题仍未解决。为此，本文系统研究了结构、表示和鲁棒性等核心要素。

Method: 系统实验分析了模型结构、数据离散化（包括编码器选择和聚类粒度）、以及针对目标任务的领域匹配对预训练过程的影响。具体通过聚类分析、音位对齐等方法探究离散单元表示和模型鲁棒性的关系。

Result: 发现不同规模模型对语音离散化策略有不同需求，最佳聚类粒度随模型容量而变；优选语音编码器和聚类方式能捕获更丰富的语言和副语言（paralinguistic）特征；聚类所用数据与最终应用域匹配可显著提升模型鲁棒性。

Conclusion: 本文揭示了在Speech Language Models（SLMs）中，不同的语音编码器、离散化粒度以及模型结构规模均会影响声码预训练的效果；并且离散化策略需要随模型容量调整，匹配目标域数据能提升模型的稳健性。

Abstract: This paper investigates discrete unit representations in Speech Language
Models (SLMs), focusing on optimizing speech modeling during continual
pre-training. In this paper, we systematically examine how model architecture,
data representation, and training robustness influence the pre-training stage
in which we adapt existing pre-trained language models to the speech modality.
Our experiments highlight the role of speech encoders and clustering
granularity across different model scales, showing how optimal discretization
strategies vary with model capacity. By examining cluster distribution and
phonemic alignments, we investigate the effective use of discrete vocabulary,
uncovering both linguistic and paralinguistic patterns. Additionally, we
explore the impact of clustering data selection on model robustness,
highlighting the importance of domain matching between discretization training
and target applications.

</details>


### [35] [Beyond ROUGE: N-Gram Subspace Features for LLM Hallucination Detection](https://arxiv.org/abs/2509.05360)
*Jerry Li,Evangelos Papalexakis*

Main category: cs.CL

TL;DR: 本文提出基于N-Gram频率张量的幻觉检测新方法，利用张量分解和MLP分类器，在HaluEval基准上实现优异性能，超越传统方法并可与最先进LLM评判相媲美。


<details>
  <summary>Details</summary>
Motivation: 现有用于检测LLMs幻觉的标准方法如ROUGE、BERTScore、困惑度等，未能充分捕捉语义深度，因此需要更有效的幻觉检测技术以提升LLMs生成内容的可信度。

Method: 提出一种新的基于ROUGE灵感的N-Gram频率张量方法，通过张量分解提取各模式特征值，用这些特征值训练多层感知机（MLP）二分类器检测幻觉。

Result: 在HaluEval数据集上，该方法在检测幻觉任务上显著优于传统方法，并且与顶尖LLM评判技术表现接近。

Conclusion: 所提出的方法在检测大型语言模型（LLMs）幻觉方面优于传统基线，并且与最新LLM评判方法具有竞争力。

Abstract: Large Language Models (LLMs) have demonstrated effectiveness across a wide
variety of tasks involving natural language, however, a fundamental problem of
hallucinations still plagues these models, limiting their trustworthiness in
generating consistent, truthful information. Detecting hallucinations has
quickly become an important topic, with various methods such as uncertainty
estimation, LLM Judges, retrieval augmented generation (RAG), and consistency
checks showing promise. Many of these methods build upon foundational metrics,
such as ROUGE, BERTScore, or Perplexity, which often lack the semantic depth
necessary to detect hallucinations effectively. In this work, we propose a
novel approach inspired by ROUGE that constructs an N-Gram frequency tensor
from LLM-generated text. This tensor captures richer semantic structure by
encoding co-occurrence patterns, enabling better differentiation between
factual and hallucinated content. We demonstrate this by applying tensor
decomposition methods to extract singular values from each mode and use these
as input features to train a multi-layer perceptron (MLP) binary classifier for
hallucinations. Our method is evaluated on the HaluEval dataset and
demonstrates significant improvements over traditional baselines, as well as
competitive performance against state-of-the-art LLM judges.

</details>


### [36] [A Lightweight Framework for Trigger-Guided LoRA-Based Self-Adaptation in LLMs](https://arxiv.org/abs/2509.05385)
*Jiacheng Wei,Faguo Wu,Xiao Zhang*

Main category: cs.CL

TL;DR: 本文提出SAGE，通过实时检测和聚类异常样本，以及动态参数优化，让大模型在推理时能够自适应更新知识，显著提升了推理准确率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型无法在推理时根据新数据持续自适应学习，影响其处理复杂推理任务的能力。本文旨在解决推理过程中模型不能及时调整的问题。

Method: 提出SAGE框架，通过将复杂推理任务分解为原子子任务，并配备三个核心组件：Trigger模块用于实时检测推理失败，Trigger Buffer模块使用流式聚类（HDBSCAN）聚集异常样本并做稳定性检查与相似性合并，Lora Store模块利用Adapter池动态优化参数以保持知识。

Result: SAGE在原子推理子任务中，通过动态知识更新，在测试时展现了卓越的准确率、鲁棒性和稳定性。

Conclusion: SAGE框架实现了大语言模型在推理测试期间的动态知识更新能力，提高了模型的适应性与推理表现。

Abstract: Large language models are unable to continuously adapt and learn from new
data during reasoning at inference time. To address this limitation, we propose
that complex reasoning tasks be decomposed into atomic subtasks and introduce
SAGE, a trigger-guided dynamic fine-tuning framework that enables adaptive
updates during reasoning at inference time. SAGE consists of three key
components: (1) a Trigger module that detects reasoning failures through
multiple evaluation metrics in real time; (2) a Trigger Buffer module that
clusters anomaly samples using a streaming clustering process with HDBSCAN,
followed by stability checks and similarity-based merging; and (3) a Lora Store
module that dynamically optimizes parameter updates with an adapter pool for
knowledge retention. Evaluation results show that SAGE demonstrates excellent
accuracy, robustness, and stability on the atomic reasoning subtask through
dynamic knowledge updating during test time.

</details>


### [37] [Talk Isn't Always Cheap: Understanding Failure Modes in Multi-Agent Debate](https://arxiv.org/abs/2509.05396)
*Andrea Wynn,Harsh Satija,Gillian Hadfield*

Main category: cs.CL

TL;DR: 多智能体辩论不是万能手段，加入能力多样性的智能体后，辩论有可能降低整体准确率，并暴露出易于被错误推理说服的缺陷。


<details>
  <summary>Details</summary>
Motivation: 此前研究只关注同质化智能体的辩论，忽略了能力多样性对多智能体互动及推理表现的影响。

Method: 通过实验设计让不同能力水平的智能体参与多轮辩论，分析准确率变化以及答题倾向随同伴推理的演化过程。

Result: 即使强模型数量占优，多智能体辩论会因同伴影响出现准确率下降，模型更容易追随共识而非质疑有缺陷的推理。

Conclusion: 多智能体辩论在能力多样化场景下存在重大失效模式，非同质模型间互动可降低推理准确率。

Abstract: While multi-agent debate has been proposed as a promising strategy for
improving AI reasoning ability, we find that debate can sometimes be harmful
rather than helpful. The prior work has exclusively focused on debates within
homogeneous groups of agents, whereas we explore how diversity in model
capabilities influences the dynamics and outcomes of multi-agent interactions.
Through a series of experiments, we demonstrate that debate can lead to a
decrease in accuracy over time -- even in settings where stronger (i.e., more
capable) models outnumber their weaker counterparts. Our analysis reveals that
models frequently shift from correct to incorrect answers in response to peer
reasoning, favoring agreement over challenging flawed reasoning. These results
highlight important failure modes in the exchange of reasons during multi-agent
debate, suggesting that naive applications of debate may cause performance
degradation when agents are neither incentivized nor adequately equipped to
resist persuasive but incorrect reasoning.

</details>


### [38] [No Translation Needed: Forecasting Quality from Fertility and Metadata](https://arxiv.org/abs/2509.05425)
*Jessica M. Lundin,Ada Zhang,David Adelani,Cody Carroll*

Main category: cs.CL

TL;DR: 本文提出只用简单的token特征和语言信息，无需实际生成翻译，即可有效预测机器翻译的质量，为多语种评估带来新思路。


<details>
  <summary>Details</summary>
Motivation: 通常评估机器翻译质量需要运行翻译系统并进行比对，过程繁琐且计算量大。作者希望探索能否在无需实际运行翻译系统的情况下，仅通过一些简单的语言特征，预测翻译结果的质量。

Method: 作者选取了易于获得的特征（如token繁衍率、token计数、语言家族、书写系统、地区等），用它们来预测GPT-4o在FLORES-200基准203种语言上的ChrF分数。建模上使用了梯度提升方法（gradient boosting models），并分析了特征的重要性。

Result: 模型预测效果良好，XX到英语的$R^2=0.66$，英语到XX的$R^2=0.72$。特征重要性分析显示，语言类型在译入英语时影响最大，而token繁衍率在多样目标语言时作用更大。

Conclusion: 无需运行真实翻译系统，仅凭部分token特征和语言类型元数据，即可较好预测翻译质量。这揭示了token层面繁衍率及更广泛语言类型对多语种机器翻译评估的重要作用。

Abstract: We show that translation quality can be predicted with surprising accuracy
\textit{without ever running the translation system itself}. Using only a
handful of features, token fertility ratios, token counts, and basic linguistic
metadata (language family, script, and region), we can forecast ChrF scores for
GPT-4o translations across 203 languages in the FLORES-200 benchmark. Gradient
boosting models achieve favorable performance ($R^{2}=0.66$ for
XX$\rightarrow$English and $R^{2}=0.72$ for English$\rightarrow$XX). Feature
importance analyses reveal that typological factors dominate predictions into
English, while fertility plays a larger role for translations into diverse
target languages. These findings suggest that translation quality is shaped by
both token-level fertility and broader linguistic typology, offering new
insights for multilingual evaluation and quality estimation.

</details>


### [39] [Direct-Scoring NLG Evaluators Can Use Pairwise Comparisons Too](https://arxiv.org/abs/2509.05440)
*Logan Lawrence,Ashton Williamson,Alexander Shelton*

Main category: cs.CL

TL;DR: 提出了一种用合成摘要实现自动打分的方法，能有效解决单摘要绝对评分的问题，性能与主流评估方法相近，同时公开了数据以推动后续研究。


<details>
  <summary>Details</summary>
Motivation: 现有方法在样本级评价时，配对比对虽表现好，但难以对单个摘要进行绝对评分，这对需要设定阈值的应用非常关键。

Method: 采用合成摘要作为测试时的配对机器排名，进行直接打分。

Result: 在SummEval、TopicalChat和HANNA等基准上的相关性分别为+0.03、-0.03和+0.05，与最佳配对评估器相当。

Conclusion: 提出的方法在多个基准数据集上表现接近于现有最优方案，并发布了合成摘要数据以支持后续研究。

Abstract: As large-language models have been increasingly used as automatic raters for
evaluating free-form content, including document summarization, dialog, and
story generation, work has been dedicated to evaluating such models by
measuring their correlations with human judgment. For \textit{sample-level}
performance, methods which operate by using pairwise comparisons between
machine-generated text perform well but often lack the ability to assign
absolute scores to individual summaries, an ability crucial for use cases that
require thresholding. In this work, we propose a direct-scoring method which
uses synthetic summaries to act as pairwise machine rankings at test time. We
show that our method performs comparably to state-of-the-art pairwise
evaluators in terms of axis-averaged sample-level correlations on the SummEval
(\textbf{+0.03}), TopicalChat (\textbf{-0.03}), and HANNA (\textbf{+0.05})
meta-evaluation benchmarks, and release the synthetic in-context summaries as
data to facilitate future work.

</details>


### [40] [From Staff Messages to Actionable Insights: A Multi-Stage LLM Classification Framework for Healthcare Analytics](https://arxiv.org/abs/2509.05484)
*Hajar Sakai,Yi-En Tseng,Mohammadsadegh Mikaeili,Joshua Bosire,Franziska Jovin*

Main category: cs.CL

TL;DR: 本文提出了基于大语言模型的医院呼叫中心文本分析框架，实现高效分类和主题识别，性能优于传统方法，具有良好隐私合规性，并有效支持医疗决策和提升患者服务质量。


<details>
  <summary>Details</summary>
Motivation: 医院呼叫中心拥有大量的文本数据，通过这些数据可挖掘关于患者和工作人员交流的信息，然而传统的监督学习方法需要大量标注和调参，效率较低。大语言模型（LLMs）为医疗数据分析带来新的高效解决方案。本文旨在优化医院呼叫中心的文本分析方法，提高效率和实用性。

Method: 提出了一套以大语言模型为基础的多阶段分析框架，包括多种类型LLM（推理型、通用型、轻量型）的评估与比较，实现主题识别和消息多类别分类，并融合数据安全与HIPAA合规性要求。最后还将LLM处理结果集成到可视化决策支持工具中。

Result: 最佳模型o3取得了78.4%的加权F1分数和79.2%的准确率，其次是gpt-5（加权F1分数75.3%、准确率76.2%）。系统能高效转换原始消息为可用于决策的信息。

Conclusion: 该LLM为基础的方法不但提升了医院文本数据的处理效率，还便于识别培训机会，有助于优化患者体验和护理质量。数据处理过程符合隐私保护和合规要求，最终成果也支持医疗工作者决策。

Abstract: Hospital call centers serve as the primary contact point for patients within
a hospital system. They also generate substantial volumes of staff messages as
navigators process patient requests and communicate with the hospital offices
following the established protocol restrictions and guidelines. This
continuously accumulated large amount of text data can be mined and processed
to retrieve insights; however, traditional supervised learning approaches
require annotated data, extensive training, and model tuning. Large Language
Models (LLMs) offer a paradigm shift toward more computationally efficient
methodologies for healthcare analytics. This paper presents a multi-stage
LLM-based framework that identifies staff message topics and classifies
messages by their reasons in a multi-class fashion. In the process, multiple
LLM types, including reasoning, general-purpose, and lightweight models, were
evaluated. The best-performing model was o3, achieving 78.4% weighted F1-score
and 79.2% accuracy, followed closely by gpt-5 (75.3% Weighted F1-score and
76.2% accuracy). The proposed methodology incorporates data security measures
and HIPAA compliance requirements essential for healthcare environments. The
processed LLM outputs are integrated into a visualization decision support tool
that transforms the staff messages into actionable insights accessible to
healthcare professionals. This approach enables more efficient utilization of
the collected staff messaging data, identifies navigator training
opportunities, and supports improved patient experience and care quality.

</details>


### [41] [The Token Tax: Systematic Bias in Multilingual Tokenization](https://arxiv.org/abs/2509.05486)
*Jessica M. Lundin,Ada Zhang,Nihal Karim,Hamza Louzan,Victor Wei,David Adelani,Cody Carroll*

Main category: cs.CL

TL;DR: 词切分效率低使复杂语言成本高且表现差，切分词越多准确率越低，有推理能力的模型更好。建议开发更好的切词和公平定价措施，推进语言公平。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型对形态复杂、数据稀少的语言支持较差，同时切词机制导致资源消耗加大和模型表现变差，需要探究具体原因并提出改进方案。

Method: 对十种大语言模型在 AfriMMLU 数据集（包括16种非洲语言，9000道多项选择题，5个学科）上进行评估，以词的切分数量（fertility/tokens per word）为指标，分析其与准确率的关系，并对模型的推理能力进行分组比较。

Result: 词切分数量（fertility）越高，模型准确率越低，且推理能力较强的模型在高/低资源语言上均优于非推理模型，缩小了不同语言资源上的准确率差距。切分数量增加会显著提高模型训练成本。

Conclusion: 对形态复杂、低资源语言来说，现有的切词机制导致结构上的劣势，提升了算力消耗并降低了模型准确率，这促使需要开发更具形态意识的切词方法和更公平的NLP定价机制。

Abstract: Tokenization inefficiency imposes structural disadvantages on morphologically
complex, low-resource languages, inflating compute resources and depressing
accuracy. We evaluate 10 large language models (LLMs) on AfriMMLU (9,000 MCQA
items; 5 subjects; 16 African languages) and show that fertility (tokens/word)
reliably predicts accuracy. Higher fertility consistently predicts lower
accuracy across all models and subjects. We further find that reasoning models
(DeepSeek, o1) consistently outperform non-reasoning peers across high and low
resource languages in the AfriMMLU dataset, narrowing accuracy gaps observed in
prior generations. Finally, translating token inflation to economics, a
doubling in tokens results in quadrupled training cost and time, underscoring
the token tax faced by many languages. These results motivate morphologically
aware tokenization, fair pricing, and multilingual benchmarks for equitable
natural language processing (NLP).

</details>


### [42] [Biomedical Literature Q&A System Using Retrieval-Augmented Generation (RAG)](https://arxiv.org/abs/2509.05505)
*Mansi Garg,Lee-Chi Wang,Bhavesh Ghanchi,Sanjana Dumpala,Shreyash Kakde,Yen Chih Chen*

Main category: cs.CL

TL;DR: 该研究提出了一款融合多源生物医学知识的RAG问答系统，在乳腺癌等医学场景下显著提升了问答准确性，为公共健康知识普及提供了新方案。


<details>
  <summary>Details</summary>
Motivation: 现有健康搜索引擎存在局限，公众难以及时获取权威、证据支持的医学信息，尤其在生物医学研究的普及方面存在滞后。作者希望提升医学信息获取的质量与效率。

Method: 采用RAG（Retrieval-Augmented Generation）架构，检索端使用MiniLM嵌入和FAISS进行向量搜索，生成端采用使用QLoRA微调后的Mistral-7B-v0.3大语言模型。数据源涵盖PubMed、医学问答数据集和医学百科。

Result: 系统在乳腺癌领域的医学文献问答中，基于BERTScore（F1指标），在事实一致性和语义相关性方面较基准模型取得了显著提升。

Conclusion: RAG增强的语言模型可以有效提升生物医学文献问答系统的准确性和可获取性，为公众提供更易获得的医学知识。

Abstract: This work presents a Biomedical Literature Question Answering (Q&A) system
based on a Retrieval-Augmented Generation (RAG) architecture, designed to
improve access to accurate, evidence-based medical information. Addressing the
shortcomings of conventional health search engines and the lag in public access
to biomedical research, the system integrates diverse sources, including PubMed
articles, curated Q&A datasets, and medical encyclopedias ,to retrieve relevant
information and generate concise, context-aware responses. The retrieval
pipeline uses MiniLM-based semantic embeddings and FAISS vector search, while
answer generation is performed by a fine-tuned Mistral-7B-v0.3 language model
optimized using QLoRA for efficient, low-resource training. The system supports
both general medical queries and domain-specific tasks, with a focused
evaluation on breast cancer literature demonstrating the value of
domain-aligned retrieval. Empirical results, measured using BERTScore (F1),
show substantial improvements in factual consistency and semantic relevance
compared to baseline models. The findings underscore the potential of
RAG-enhanced language models to bridge the gap between complex biomedical
literature and accessible public health knowledge, paving the way for future
work on multilingual adaptation, privacy-preserving inference, and personalized
medical AI systems.

</details>


### [43] [Using Contrastive Learning to Improve Two-Way Reasoning in Large Language Models: The Obfuscation Task as a Case Study](https://arxiv.org/abs/2509.05553)
*Serge Lionel Nikiema,Jordan Samhi,Micheline Bénédicte Moumoula,Albérick Euraste Djiré,Abdoul Kader Kaboré,Jacques Klein,Tegawendé F. Bissyandé*

Main category: cs.CL

TL;DR: 作者发现传统微调导致模型“专精”而削弱逆向能力，提出对比微调（CFT）方法，显著提升了模型的双向推理能力，验证了该方法提升AI理解能力的有效性，同时建议双向推理作为检验理解的新标准。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究大语言模型是否具备真正的“理解”概念能力，或者只是基于模式识别。作者提出评估“理解”的新标准：双向推理能力，即能否在未经过逆向训练的情况下完成任务的正反向变换。

Method: 作者以变量命名场景为例，提出双向推理测试，并发现目前模型存在‘认知专业化’现象。为此提出对比微调（Contrastive Fine-Tuning, CFT）方法，采用三类训练样本（正例、负例和正向混淆）促进模型理解本质语义，而非仅为模式配对。

Result: 对比微调方法显著提升了模型的双向推理能力，实现了无需逆向训练的强逆向推理，同时保持正向能力。

Conclusion: 双向推理既能作为衡量模型是否具备真实理解的理论框架，又可用于实际训练中提升模型能力。CFT方法有效促进了AI系统的理解能力。

Abstract: This research addresses a fundamental question in AI: whether large language
models truly understand concepts or simply recognize patterns. The authors
propose bidirectional reasoning,the ability to apply transformations in both
directions without being explicitly trained on the reverse direction, as a test
for genuine understanding. They argue that true comprehension should naturally
allow reversibility. For example, a model that can change a variable name like
userIndex to i should also be able to infer that i represents a user index
without reverse training. The researchers tested current language models and
discovered what they term cognitive specialization: when models are fine-tuned
on forward tasks, their performance on those tasks improves, but their ability
to reason bidirectionally becomes significantly worse. To address this issue,
they developed Contrastive Fine-Tuning (CFT), which trains models using three
types of examples: positive examples that maintain semantic meaning, negative
examples with different semantics, and forward-direction obfuscation examples.
This approach aims to develop deeper understanding rather than surface-level
pattern recognition and allows reverse capabilities to develop naturally
without explicit reverse training. Their experiments demonstrated that CFT
successfully achieved bidirectional reasoning, enabling strong reverse
performance while maintaining forward task capabilities. The authors conclude
that bidirectional reasoning serves both as a theoretical framework for
assessing genuine understanding and as a practical training approach for
developing more capable AI systems.

</details>


### [44] [Ad hoc conventions generalize to new referents](https://arxiv.org/abs/2509.05566)
*Anya Ji,Claire Augusta Bergey,Ron Eliav,Yoav Artzi,Robert D. Hawkins*

Main category: cs.CL

TL;DR: 人们建立的临时命名约定可以推广到新对象，反映了深层概念协调，而非完全任意化命名，这对语言理论和智能体设计有启示作用。


<details>
  <summary>Details</summary>
Motivation: 探讨人类在首次交流陌生事物时是如何构建和使用命名或描述系统的，具体比较两种理论：一种认为新命名是任意且不可扩展的，另一种认为命名过程涉及更广泛的概念对齐并可推广。

Method: 采用了一项双人交流实验（参与者数量为302），利用KiloGram数据库中超过1000个抽象tangram图像。实验中，两人通过多次交流逐步达成一组图像的指称习惯，然后衡量他们对未讨论图像的描述一致性。

Result: 发现描述的一致性在未讨论图像上也增强，证明命名习惯具有推广性。这种推广随视觉相似度呈非线性衰减（符合Shepard定律），且对图像可命名性强弱均适用。

Conclusion: 即时达成的指称习惯不是任意标签，而是概念协调的产物，对参考理论和自适应语言体设计有重要启示。

Abstract: How do people talk about things they've never talked about before? One view
suggests that a new shared naming system establishes an arbitrary link to a
specific target, like proper names that cannot extend beyond their bearers. An
alternative view proposes that forming a shared way of describing objects
involves broader conceptual alignment, reshaping each individual's semantic
space in ways that should generalize to new referents. We test these competing
accounts in a dyadic communication study (N=302) leveraging the
recently-released KiloGram dataset containing over 1,000 abstract tangram
images. After pairs of participants coordinated on referential conventions for
one set of images through repeated communication, we measured the extent to
which their descriptions aligned for undiscussed images. We found strong
evidence for generalization: partners showed increased alignment relative to
their pre-test labels. Generalization also decayed nonlinearly with visual
similarity (consistent with Shepard's law) and was robust across levels of the
images' nameability. These findings suggest that ad hoc conventions are not
arbitrary labels but reflect genuine conceptual coordination, with implications
for theories of reference and the design of more adaptive language agents.

</details>


### [45] [Mitigating Spurious Correlations Between Question and Answer via Chain-of-Thought Correctness Perception Distillation](https://arxiv.org/abs/2509.05602)
*Hongyan Xie,Yitong Yao,Yikun Ban,Zixuan Huang,Deqing Wang,Zhenhe Wu,Haoxiang Su,Chao Wang,Shuangyong Song,Xuelong Li*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的推理微调方法CoPeD，高效提升了小模型基于链式思考的推理质量，经实验验证具有良好表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在推理任务上表现优异，但推理成本较高。为了降低成本，通常将小语言模型通过大模型生成的链式思考(CoT)数据微调。然而，这些数据中包含的不正确或无信息理据会影响小模型的推理质量。

Method: 提出了Chain-of-Thought Correctness Perception Distillation (CoPeD)方法：1）引入可感知推理正确性的任务设定，引导学生模型基于正确理据预测答案，遇到错误理据时进行修正；2）设计了基于理据和答案综合损失的动态加权损失函数，提升模型对高质量理据样本的关注。

Result: 实验证明，CoPeD方法在分布内和分布外的推理基准数据集上都有效改善了小模型的推理质量。

Conclusion: CoPeD方法通过优化任务设定和数据利用，提高了小模型推理的真实性和质量，在成本、性能之间取得了良好平衡。

Abstract: Large language models (LLMs) excel at reasoning tasks but are expensive to
deploy. Thus small language models (SLMs) are fine-tuned on CoT data generated
by LLMs to copy LLMs' abilities. However, these CoT data may include noisy
rationales that either fail to substantiate the answers or contribute no
additional information to support answer prediction, which leads SLMs to
capture spurious correlations between questions and answers and compromise the
quality of reasoning. In this work, we propose Chain-of-Thought Correctness
Perception Distillation (CoPeD), which aims to improve the reasoning quality of
the student model from the perspectives of task setting and data utilization.
Firstly, we introduce a correctness-aware task setting that encourages the
student model to predict answers based on correct rationales and revise them
when they are incorrect. This setting improves the faithfulness of reasoning
and allows the model to learn from its mistakes. Then, we propose a
Correctness-Aware Weighted loss, which dynamically adjusts the contribution of
each training instance based on the combined loss of the rationale and the
answer. This strategy encourages the model to focus more on samples where the
rationale offers stronger support for the correct answer. Experiments have
shown that CoPeD is effective on both in-distribution (IND) and
out-of-distribution (OOD) benchmark reasoning datasets.

</details>


### [46] [Icon$^{2}$: Aligning Large Language Models Using Self-Synthetic Preference Data via Inherent Regulation](https://arxiv.org/abs/2509.05605)
*Qiyuan Chen,Hongsen Huang,Qian Shao,Jiahe Chen,Jintai Chen,Hongxia Xu,Renjie Hua,Ren Chuan,Jian Wu*

Main category: cs.CL

TL;DR: 作者提出一种基于LLM内部表征的新偏好数据集构建方法，不仅提升了模型对齐效果，还显著降低了资源消耗。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）需要高质量的偏好数据集以更好地与人类偏好对齐。然而，常规数据集构建方法存在数据分布与模型不匹配、生成回复样本计算开销大等问题，因此需要更高效、模型适配性更强的数据集构建新方法。

Method: 提出了一种新的偏好数据集构建范式——Icon^2。具体做法是：（1）利用LLM内部的层级方向向量捕捉和编码复杂的人类偏好；（2）基于向量对合成指令进行一致性筛选；（3）解码时采用双向内在控制引导token表征，精确生成具有明显对齐差异的回复对。

Result: 实验证明该方法显著提升了对齐效果和数据集构建效率。在Llama3-8B和Qwen2-7B模型上，AlpacaEval 2.0平均胜率提升13.89%，Arena-Hard提升13.45%，计算成本降低高达48.1%。

Conclusion: Icon^2能够充分挖掘LLM内部表征优势，实现高效且适配模型的人类偏好数据集构建，兼具效果提升和成本优势。

Abstract: Large Language Models (LLMs) require high quality preference datasets to
align with human preferences. However, conventional methods for constructing
such datasets face significant challenges: reliance on pre-collected
instructions often leads to distribution mismatches with target models, while
the need for sampling multiple stochastic responses introduces substantial
computational overhead. In this work, we explore a paradigm shift by leveraging
inherent regulation of LLMs' representation space for efficient and tailored
preference dataset construction, named Icon$^{2}$. Specifically, it first
extracts layer-wise direction vectors to encode sophisticated human preferences
and then uses these vectors to filter self-synthesized instructions based on
their inherent consistency. During decoding, bidirectional inherent control is
applied to steer token representations, enabling the precise generation of
response pairs with clear alignment distinctions. Experimental results
demonstrate significant improvements in both alignment and efficiency.
Llama3-8B and Qwen2-7B achieve an average win rate improvement of 13.89% on
AlpacaEval 2.0 and 13.45% on Arena-Hard, while reducing computational costs by
up to 48.1%.

</details>


### [47] [Beyond Keywords: Driving Generative Search Engine Optimization with Content-Centric Agents](https://arxiv.org/abs/2509.05607)
*Qiyuan Chen,Jiahe Chen,Hongsen Huang,Qian Shao,Jintai Chen,Renjie Hua,Hongxia Xu,Ruijia Wu,Ren Chuan,Jian Wu*

Main category: cs.CL

TL;DR: 本文提出了一个面向生成式搜索的优化新框架和基准，并开发了自动协作内容优化系统，为内容影响力量化与优化提供了系统支持，对未来GSEO研究和实务有重要意义。


<details>
  <summary>Details</summary>
Motivation: 随着生成式搜索引擎的兴起，传统的以排名为基础的搜索优化（SEO）方法和指标已不再适用，因此亟需新方法来衡量和优化内容对生成式回答的影响。

Method: 提出了一个完整的生成式搜索引擎优化（GSEO）框架，包括两个主要部分：1）构建了以内容为中心的大规模基准集CC-GSEO-Bench，并设计了多维度评估体系来系统量化内容的影响力，侧重实质语义影响而非浅层归因；2）开发了一个多代理系统，自动实现分析-修订-评估的协作流程来提升内容。

Result: 通过上述框架开展实证分析，揭示了内容影响力的动态机制，并为内容创作者提供了可操作性策略，为GSEO研究奠定了系统性基础。

Conclusion: 本研究为生成式搜索引擎下内容影响力的度量与优化提供了创新方法和工具，有助于推动GSEO领域的进一步发展。

Abstract: The paradigm shift from traditional ranked-based search to Generative Search
Engines has rendered conventional SEO metrics obsolete, creating an urgent need
to understand, measure, and optimize for content influence on synthesized
answers. This paper introduces a comprehensive, end-to-end framework for
Generative Search Engine Optimization (GSEO) to address this challenge. We make
two primary contributions. First, we construct CC-GSEO-Bench, a large-scale,
content-centric benchmark, and propose a multi-dimensional evaluation framework
that systematically quantifies influence, moving beyond surface-level
attribution to assess substantive semantic impact. Second, we design a novel
multi-agent system that operationalizes this framework, automating the
strategic refinement of content through a collaborative analyze-revise-evaluate
workflow. Our empirical analysis using this framework reveals novel insights
into the dynamics of content influence, offering actionable strategies for
creators and establishing a principled foundation for future GSEO research.

</details>


### [48] [New Insights into Optimal Alignment of Acoustic and Linguistic Representations for Knowledge Transfer in ASR](https://arxiv.org/abs/2509.05609)
*Xugang Lu,Peng Shen,Yu Tsao,Hisashi Kawai*

Main category: cs.CL

TL;DR: 本文提出将声学和语言模态对齐建模为检测问题，引入非均衡最优传输算法，实现部分和柔性匹配，提升了CTC语音识别系统结合预训练语言模型时的知识迁移性能。


<details>
  <summary>Details</summary>
Motivation: 在自动语音识别（ASR）中，将声学和语言特征对齐是知识迁移的核心挑战。声学帧与语言标记之间存在一对多和多对一的异构结构，同时声学信号中经常包含无语言对应的噪声或者静音区域，造成了对齐不平衡和分布不匹配问题。

Method: 作者将对齐与匹配建模为检测问题，提出了一种基于非均衡最优传输的对齐模型。该模型允许在声学与语言模态间进行柔性和部分匹配，有效处理分布失配和结构性不对称，确保每个语言标记至少在一个声学观测中被覆盖，同时对冗余或噪声帧进行灵活映射。

Result: 实验基于CTC的ASR系统，并结合了预训练语言模型用于知识迁移。结果表明，该方法在灵活控制匹配度的同时，有效提升了ASR性能。

Conclusion: 提出的非均衡最优传输对齐模型在结构不对称与分布失配场景下表现优越，为语音识别领域的知识迁移带来了新的解决办法，并提升了整体识别效果。

Abstract: Aligning acoustic and linguistic representations is a central challenge to
bridge the pre-trained models in knowledge transfer for automatic speech
recognition (ASR). This alignment is inherently structured and asymmetric:
while multiple consecutive acoustic frames typically correspond to a single
linguistic token (many-to-one), certain acoustic transition regions may relate
to multiple adjacent tokens (one-to-many). Moreover, acoustic sequences often
include frames with no linguistic counterpart, such as background noise or
silence may lead to imbalanced matching conditions. In this work, we take a new
insight to regard alignment and matching as a detection problem, where the goal
is to identify meaningful correspondences with high precision and recall
ensuring full coverage of linguistic tokens while flexibly handling redundant
or noisy acoustic frames in transferring linguistic knowledge for ASR. Based on
this new insight, we propose an unbalanced optimal transport-based alignment
model that explicitly handles distributional mismatch and structural
asymmetries with soft and partial matching between acoustic and linguistic
modalities. Our method ensures that every linguistic token is grounded in at
least one acoustic observation, while allowing for flexible, probabilistic
mappings from acoustic to linguistic units. We evaluate our proposed model with
experiments on an CTC-based ASR system with a pre-trained language model for
knowledge transfer. Experimental results demonstrate the effectiveness of our
approach in flexibly controlling degree of matching and hence to improve ASR
performance.

</details>


### [49] [From Joy to Fear: A Benchmark of Emotion Estimation in Pop Song Lyrics](https://arxiv.org/abs/2509.05617)
*Shay Dahary,Avi Edana,Alexander Apartsin,Yehudit Aperstein*

Main category: cs.CL

TL;DR: 论文提出了通过人工标注歌词情感强度数据集，比较LLMs零样本和BERT微调在歌词多标签情感识别的表现，并揭示了各自优缺点，为音乐情感信息检索应用提供了参考，公开数据集可支持进一步研究。


<details>
  <summary>Details</summary>
Motivation: 歌词中的情感内容对听众体验和音乐偏好具有重要影响。现有研究多关注单情感分类，缺乏对歌词多情感强度细粒度的标注与分析。

Method: 构建了基于平均意见分法(MOS)人工标注的歌词情感多标签数据集，并基于该数据集，在零样本条件下评估了多种大语言模型的表现，以及微调BERT模型用于歌词多标签情感打分。

Result: 实验显示，大语言模型和微调BERT在多标签歌词情感识别任务上各有优劣，可以为情感驱动的音乐信息检索应用中的模型选择提供依据。

Conclusion: 本研究证明了LLMs在创造性文本（歌词）情感识别中的潜力，构建了公开数据集，并为后续情感相关的音乐应用提供了方法参考和数据基础。

Abstract: The emotional content of song lyrics plays a pivotal role in shaping listener
experiences and influencing musical preferences. This paper investigates the
task of multi-label emotional attribution of song lyrics by predicting six
emotional intensity scores corresponding to six fundamental emotions. A
manually labeled dataset is constructed using a mean opinion score (MOS)
approach, which aggregates annotations from multiple human raters to ensure
reliable ground-truth labels. Leveraging this dataset, we conduct a
comprehensive evaluation of several publicly available large language models
(LLMs) under zero-shot scenarios. Additionally, we fine-tune a BERT-based model
specifically for predicting multi-label emotion scores. Experimental results
reveal the relative strengths and limitations of zero-shot and fine-tuned
models in capturing the nuanced emotional content of lyrics. Our findings
highlight the potential of LLMs for emotion recognition in creative texts,
providing insights into model selection strategies for emotion-based music
information retrieval applications. The labeled dataset is available at
https://github.com/LLM-HITCS25S/LyricsEmotionAttribution.

</details>


### [50] [Few-Shot Query Intent Detection via Relation-Aware Prompt Learning](https://arxiv.org/abs/2509.05635)
*Liang Zhang,Yuan Li,Shijie Zhang,Zheng Zhang,Xitong Li*

Main category: cs.CL

TL;DR: SAID首次将文本与关系结构统一用于意图检测的预训练，引入关系token注意机制，在真实数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的意图检测方法主要依赖文本数据，忽视了会话系统固有的重要结构化信息，因此需提出能统一利用文本和关系结构的新方法，以提升少样本场景下的意图识别能力。

Method: 提出SAID框架，将文本信息与关系结构信息（如query-query和query-answer关系）统一用于模型预训练，并引入QueryAdapt注意力机制，从关系token层面生成意图相关的关系token，实现更细致的知识迁移。

Result: 在两个真实数据集上，SAID显著优于最新的其他方法，说明所提出方法效果突出。

Conclusion: SAID框架通过结合文本和关系结构信息，在意图检测任务上表现优异，显著超过了当前主流方法。

Abstract: Intent detection is a crucial component of modern conversational systems,
since accurately identifying user intent at the beginning of a conversation is
essential for generating effective responses. Recent efforts have focused on
studying this problem under a challenging few-shot scenario. These approaches
primarily leverage large-scale unlabeled dialogue text corpora to pretrain
language models through various pretext tasks, followed by fine-tuning for
intent detection with very limited annotations. Despite the improvements
achieved, existing methods have predominantly focused on textual data,
neglecting to effectively capture the crucial structural information inherent
in conversational systems, such as the query-query relation and query-answer
relation. To address this gap, we propose SAID, a novel framework that
integrates both textual and relational structure information in a unified
manner for model pretraining for the first time. Building on this framework, we
further propose a novel mechanism, the query-adaptive attention network
(QueryAdapt), which operates at the relation token level by generating
intent-specific relation tokens from well-learned query-query and query-answer
relations explicitly, enabling more fine-grained knowledge transfer. Extensive
experimental results on two real-world datasets demonstrate that SAID
significantly outperforms state-of-the-art methods.

</details>


### [51] [LM-Searcher: Cross-domain Neural Architecture Search with LLMs via Unified Numerical Encoding](https://arxiv.org/abs/2509.05657)
*Yuxuan Hu,Jihao Liu,Ke Wang,Jinliang Zhen,Weikang Shi,Manyuan Zhang,Qi Dou,Rui Liu,Aojun Zhou,Hongsheng Li*

Main category: cs.CL

TL;DR: LM-Searcher创新性地利用通用神经网络编码和大语言模型排序，实现了无需专门调整的跨领域神经架构搜索，并在多任务实验中表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的神经结构搜索方法依赖于繁琐的提示工程和领域专属调整，难以在不同任务间泛化和扩展，亟需一种更通用高效的方法。

Method: 提出了LM-Searcher框架，包含NCode结构的通用数值表示方法，并将NAS问题转化为通过instruction-tuning样本排序选择高性能架构，结合基于剪枝的子空间采样策略，训练大语言模型从架构池中筛选优选。

Result: LM-Searcher无需领域特定适配，在不同领域（如图像分类CNN、分割与生成任务的LoRA配置）上都取得了有竞争力的效果，展示了强的泛化与迁移能力。

Conclusion: LM-Searcher通过结合数值字符串表示和以LLM为基础的排序方法，实现了无需大量领域特定适配的跨领域神经网络结构优化，证明了其实用性与灵活性。

Abstract: Recent progress in Large Language Models (LLMs) has opened new avenues for
solving complex optimization problems, including Neural Architecture Search
(NAS). However, existing LLM-driven NAS approaches rely heavily on prompt
engineering and domain-specific tuning, limiting their practicality and
scalability across diverse tasks. In this work, we propose LM-Searcher, a novel
framework that leverages LLMs for cross-domain neural architecture optimization
without the need for extensive domain-specific adaptation. Central to our
approach is NCode, a universal numerical string representation for neural
architectures, which enables cross-domain architecture encoding and search. We
also reformulate the NAS problem as a ranking task, training LLMs to select
high-performing architectures from candidate pools using instruction-tuning
samples derived from a novel pruning-based subspace sampling strategy. Our
curated dataset, encompassing a wide range of architecture-performance pairs,
encourages robust and transferable learning. Comprehensive experiments
demonstrate that LM-Searcher achieves competitive performance in both in-domain
(e.g., CNNs for image classification) and out-of-domain (e.g., LoRA
configurations for segmentation and generation) tasks, establishing a new
paradigm for flexible and generalizable LLM-based architecture search. The
datasets and models will be released at https://github.com/Ashone3/LM-Searcher.

</details>


### [52] [Cross-Question Method Reuse in Large Language Models: From Word-Level Prediction to Rational Logical-Layer Reasoning](https://arxiv.org/abs/2509.05660)
*Hong Su*

Main category: cs.CL

TL;DR: 将问题与方案分开处理，指导LLM关注方案迁移（不是问题识别），突破传统高相似性要求，实现更广泛问题间的方案复用，实验效果明显优于传统做法。


<details>
  <summary>Details</summary>
Motivation: 现有方法复用需极高的问题相似性，限制了方案迁移的广度。本研究旨在打破此限制，实现针对异类或隐性相关问题的方案复用。

Method: 将问题与解决方案分离后，用LLM指导方案在新但相关的问题中转化，实现由“问题-方案对”到“方案迁移”。扩展到仅有部分特征（或隐藏相似性）的问题，实现超越传统相似性约束的复用。

Result: 实验证明新方法提升了筛选可复用方案的概率，显著增强了跨问题的方案复用效果。

Conclusion: 方法复用不再受限于问题的高相似性，通过分离问题与方案并引导LLM进行方案转化，可以提升跨问题之间的复用效率。

Abstract: Large language models (LLMs) have been widely applied to assist in finding
solutions for diverse questions. Prior work has proposed representing a method
as a pair of a question and its corresponding solution, enabling method reuse.
However, existing approaches typically require the questions to be highly
similar. In this paper, we extend the scope of method reuse to address
questions with low similarity or with hidden similarities that are not
explicitly observable. For questions that are similar in a general-specific
sense (i.e., broader or narrower in scope), we propose to first separate the
question and solution, rather than directly feeding the pair to the LLM. The
LLM is then guided to adapt the solution to new but related questions, allowing
it to focus on solution transfer rather than question recognition. Furthermore,
we extend this approach to cases where questions only share partial features or
hidden characteristics. This enables cross-question method reuse beyond
conventional similarity constraints. Experimental verification shows that our
scope-extension approach increases the probability of filtering out reusable
solutions, thereby improving the effectiveness of cross-question method reuse.

</details>


### [53] [Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian](https://arxiv.org/abs/2509.05668)
*Michael Hoffmann,Jophin John,Stefan Schweter,Gokul Ramakrishnan,Hoi-Fong Mak,Alice Zhang,Dmitry Gaynullin,Nicolay J. Hammer*

Main category: cs.CL

TL;DR: Llama-GENBA-10B是一款三语基础大模型，均衡处理英语、德语和巴伐利亚语，在低资源语言任务上性能突出，为多语、低资源语言的基础模型开发提供了高效方案。


<details>
  <summary>Details</summary>
Motivation: 解决大模型中英语主导、低资源语言被忽视的问题，特别是希望为德语及巴伐利亚语等低资源语言社区提供更公平的语言模型。

Method: 以Llama 3.1-8B为基础，扩大到10B参数，采用164B三语语料（英语、德语、巴伐利亚语）进行连续预训练，同时开发多语语料、统一分词器、优化语言比例超参数，并制定标准三语评估体系。

Result: 微调版Llama-GENBA-10B在巴伐利亚语上超过Apertus-8B-2509和gemma-2-9b，成为该语言最佳模型，同时在英语上优于EuroLLM，在德语上与之持平。大规模多语预训练高效、能耗有据可查。

Conclusion: Llama-GENBA-10B在三语（英语、德语、巴伐利亚语）任务中取得了强劲的跨语言表现，尤其在低资源语言巴伐利亚语上表现优异，成为该领域最佳模型。

Abstract: We present Llama-GENBA-10B, a trilingual foundation model addressing
English-centric bias in large language models. Built on Llama 3.1-8B and scaled
to 10B parameters, Llama-GENBA-10B is continuously pretrained on 164B tokens
(82B English, 82B German, and 80M Bavarian), balancing resources while
preventing English dominance. Targeted at the German NLP community, the model
also promotes Bavarian as a low-resource language. Development tackled four
challenges: (1) curating a multilingual corpus despite Bavarian scarcity, (2)
creating a unified tokenizer for English, German, and Bavarian, (3) optimizing
architecture and language-ratio hyperparameters for cross-lingual transfer, and
(4) establishing the first standardized trilingual evaluation suite by
translating German benchmarks into Bavarian. Evaluations show that
Llama-GENBA-10B achieves strong cross-lingual performance, with the fine-tuned
variant surpassing Apertus-8B-2509 and gemma-2-9b in Bavarian and establishing
itself as the best model in its class for this language, while also
outperforming EuroLLM in English and matching its results in German. Training
on the Cerebras CS-2 demonstrated efficient large-scale multilingual
pretraining with documented energy use, offering a blueprint for inclusive
foundation models that integrate low-resource languages.

</details>


### [54] [Revealing the Numeracy Gap: An Empirical Investigation of Text Embedding Models](https://arxiv.org/abs/2509.05691)
*Ningyuan Deng,Hanyu Duan,Yixuan Tang,Yi Yang*

Main category: cs.CL

TL;DR: 当前主流文本嵌入模型普遍难以准确编码和理解文本中的具体数字信息，未来需加强模型的数值处理能力。


<details>
  <summary>Details</summary>
Motivation: 当前文本嵌入模型在实际自然语言处理任务中应用广泛，但它们在是否能精确编码和理解文本中的数字信息方面能力尚不明确，这对于如金融、医疗等需处理数字细节的场景尤其关键。

Method: 本文使用金融领域的合成数据，对13种主流文本嵌入模型进行评估，重点测试它们对数字内容捕捉能力的表现，并进行了进一步分析以探究嵌入模型处理数值的内在机制。

Result: 研究发现，这些主流文本嵌入模型在精确捕捉文本中的数字细节方面表现普遍较差，难以准确区分和表征数字量化差异。

Conclusion: 文本嵌入模型在处理与数字相关的细致语义时能力有限，需进一步研发增强数字理解力的模型，以满足金融、医疗等领域的实际需求。

Abstract: Text embedding models are widely used in natural language processing
applications. However, their capability is often benchmarked on tasks that do
not require understanding nuanced numerical information in text. As a result,
it remains unclear whether current embedding models can precisely encode
numerical content, such as numbers, into embeddings. This question is critical
because embedding models are increasingly applied in domains where numbers
matter, such as finance and healthcare. For example, Company X's market share
grew by 2\% should be interpreted very differently from Company X's market
share grew by 20\%, even though both indicate growth in market share. This
study aims to examine whether text embedding models can capture such nuances.
Using synthetic data in a financial context, we evaluate 13 widely used text
embedding models and find that they generally struggle to capture numerical
details accurately. Our further analyses provide deeper insights into embedding
numeracy, informing future research to strengthen embedding model-based NLP
systems with improved capacity for handling numerical content.

</details>


### [55] [A Survey of the State-of-the-Art in Conversational Question Answering Systems](https://arxiv.org/abs/2509.05716)
*Manoj Madushanka Perera,Adnan Mahmood,Kasun Eranda Wijethilake,Fahmida Islam,Maryam Tahermazandarani,Quan Z. Sheng*

Main category: cs.CL

TL;DR: 本文是一篇对话式问答系统（ConvQA）的综述，系统回顾了其核心组件、最新机器学习技术、主流大模型及关键数据集，并指明了未来的研究方向，为相关领域研究和应用提供了参考。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理领域的发展，对话式问答系统（ConvQA）在需要动态和语境相关对话的实际应用场景（如客服、教育、法律和医疗等）中变得愈发重要。因此，系统梳理ConvQA的核心组成、主流技术和未来趋势具有现实意义。

Method: 本文作为综述性论文，系统总结了ConvQA的三大核心组件：历史选择、问题理解与答案预测，介绍这些环节如何共同保证多轮对话的连贯性与相关性；同时还梳理了如强化学习、对比学习、迁移学习等先进机器学习方法在ConvQA中的应用，以及大型语言模型（如RoBERTa、GPT-4、Gemini 2.0 Flash、Mistral 7B、LLaMA 3）的作用。此外，论文还对关键数据集进行了梳理，并展望了未来研究方向。

Result: 综述全面分析了ConvQA的核心组成部分、最新机器学习方法的应用、主流大模型的贡献和代表性数据集，并提出了当前尚未解决的挑战和未来研究方向。

Conclusion: 本文为ConvQA领域提供了系统梳理与前沿展望，总结了关键技术路线、现有数据资源和大型模型的影响，帮助研究者把握现状并指导今后的研究与应用。

Abstract: Conversational Question Answering (ConvQA) systems have emerged as a pivotal
area within Natural Language Processing (NLP) by driving advancements that
enable machines to engage in dynamic and context-aware conversations. These
capabilities are increasingly being applied across various domains, i.e.,
customer support, education, legal, and healthcare where maintaining a coherent
and relevant conversation is essential. Building on recent advancements, this
survey provides a comprehensive analysis of the state-of-the-art in ConvQA.
This survey begins by examining the core components of ConvQA systems, i.e.,
history selection, question understanding, and answer prediction, highlighting
their interplay in ensuring coherence and relevance in multi-turn
conversations. It further investigates the use of advanced machine learning
techniques, including but not limited to, reinforcement learning, contrastive
learning, and transfer learning to improve ConvQA accuracy and efficiency. The
pivotal role of large language models, i.e., RoBERTa, GPT-4, Gemini 2.0 Flash,
Mistral 7B, and LLaMA 3, is also explored, thereby showcasing their impact
through data scalability and architectural advancements. Additionally, this
survey presents a comprehensive analysis of key ConvQA datasets and concludes
by outlining open research directions. Overall, this work offers a
comprehensive overview of the ConvQA landscape and provides valuable insights
to guide future advancements in the field.

</details>


### [56] [Exploring Subjective Tasks in Farsi: A Survey Analysis and Evaluation of Language Models](https://arxiv.org/abs/2509.05719)
*Donya Rooein,Flor Miriam Plaza-del-Arco,Debora Nozza,Dirk Hovy*

Main category: cs.CL

TL;DR: 法尔斯语主观任务发展受限，主要瓶颈在于高质量、多样性数据集的匮乏和模型表现的不稳定，即使数字文本规模增长，NLP应用前景仍受阻。


<details>
  <summary>Details</summary>
Motivation: 法尔斯语有庞大的使用群体和越来越多的数字资料，理论上发展基础数据丰富，却在实际主观任务应用上暴露出数据欠缺和质量不足的问题，需要引起研究和实际应用的重视。

Method: 作者综述了法尔斯语主观任务领域的110篇相关文献，分析了公开数据集的情况，并对现有模型在少数可用数据集上的表现进行了测试和比对。

Result: 法尔斯语相关主观任务公开数据集极为稀缺，且常缺乏关键人口统计因素（如年龄与性别）；模型在不同数据集上的表现极不稳定，数据量的增加并未实质性改善NLP应用。

Conclusion: 论文发现，法尔斯语虽然被归为中资源语言，但在主观任务如情感分析、情绪分析和有毒性检测中，数据的数量和质量都存在明显短板，难以支撑NLP发展。

Abstract: Given Farsi's speaker base of over 127 million people and the growing
availability of digital text, including more than 1.3 million articles on
Wikipedia, it is considered a middle-resource language. However, this label
quickly crumbles when the situation is examined more closely. We focus on three
subjective tasks (Sentiment Analysis, Emotion Analysis, and Toxicity Detection)
and find significant challenges in data availability and quality, despite the
overall increase in data availability. We review 110 publications on subjective
tasks in Farsi and observe a lack of publicly available datasets. Furthermore,
existing datasets often lack essential demographic factors, such as age and
gender, that are crucial for accurately modeling subjectivity in language. When
evaluating prediction models using the few available datasets, the results are
highly unstable across both datasets and models. Our findings indicate that the
volume of data is insufficient to significantly improve a language's prospects
in NLP.

</details>


### [57] [QCSE: A Pretrained Quantum Context-Sensitive Word Embedding for Natural Language Processing](https://arxiv.org/abs/2509.05729)
*Charles M. Varmantchaonala,Niclas GÖtting,Nils-Erik SchÜtte,Jean Louis E. K. Fendji,Christopher Gies*

Main category: cs.CL

TL;DR: 本文提出并验证了量子上下文敏感嵌入模型QCSE，能有效表达词语上下文信息，尤其适用于数据稀缺的小语种NLP任务，展示了量子计算在自然语言处理领域的前景。


<details>
  <summary>Details</summary>
Motivation: 自然语言处理领域一直存在对更强大、更高效模型的需求，尤其是在数据稀缺的小语种中。近年来，量子计算为处理语言复杂性和上下文关系提供了新的潜力。本文旨在利用量子计算的独特性质开发上下文敏感型词嵌入模型，提高模型对语义和上下文的表达能力。

Method: 提出了一种预训练的量子上下文敏感型嵌入模型（QCSE），引入了五种创新的上下文矩阵计算方法（包括指数衰减、正弦调制、相位偏移和基于哈希的转换），并在小规模的Fulani语料和相对较大的英文语料上进行测试。

Result: 实验结果表明，QCSE模型不仅有效捕获了词语的上下文敏感性，还能利用量子系统的表达能力，丰富地表示上下文信息。尤其是在数据稀缺的Fulani语言上，模型展现出对低资源语种的显著潜力。

Conclusion: 本文证明了量子计算在自然语言处理领域的实用价值，提出的QCSE模型为多领域现实NLP挑战开启了新的应用方向，特别是在低资源、小语种的场景中展现出独特优势。

Abstract: Quantum Natural Language Processing (QNLP) offers a novel approach to
encoding and understanding the complexity of natural languages through the
power of quantum computation. This paper presents a pretrained quantum
context-sensitive embedding model, called QCSE, that captures context-sensitive
word embeddings, leveraging the unique properties of quantum systems to learn
contextual relationships in languages. The model introduces quantum-native
context learning, enabling the utilization of quantum computers for linguistic
tasks. Central to the proposed approach are innovative context matrix
computation methods, designed to create unique, representations of words based
on their surrounding linguistic context. Five distinct methods are proposed and
tested for computing the context matrices, incorporating techniques such as
exponential decay, sinusoidal modulation, phase shifts, and hash-based
transformations. These methods ensure that the quantum embeddings retain
context sensitivity, thereby making them suitable for downstream language tasks
where the expressibility and properties of quantum systems are valuable
resources. To evaluate the effectiveness of the model and the associated
context matrix methods, evaluations are conducted on both a Fulani corpus, a
low-resource African language, dataset of small size and an English corpus of
slightly larger size. The results demonstrate that QCSE not only captures
context sensitivity but also leverages the expressibility of quantum systems
for representing rich, context-aware language information. The use of Fulani
further highlights the potential of QNLP to mitigate the problem of lack of
data for this category of languages. This work underscores the power of quantum
computation in natural language processing (NLP) and opens new avenues for
applying QNLP to real-world linguistic challenges across various tasks and
domains.

</details>


### [58] [Enhancing Factual Accuracy and Citation Generation in LLMs via Multi-Stage Self-Verification](https://arxiv.org/abs/2509.05741)
*Fernando Gabriela García,Qiyang Shi,Zilin Feng*

Main category: cs.CL

TL;DR: VeriFact-CoT通过事实验证和引用整合，大幅提升了大语言模型输出内容的准确性与可信度，减少了幻觉问题，适用于科研、新闻、法律等高要求领域。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）在生成复杂和事实敏感内容时，常常出现幻觉（即错误生成内容）和缺乏可信引用的问题。现有方法难以满足实际应用如科学研究、新闻报道和法律咨询等对内容真实度与可追溯性的高要求。

Method: 提出了VeriFact-CoT（Verified Factual Chain-of-Thought）方法，采用多阶段机制：事实验证—反思—引用整合，促使LLM自我审查和修订中间推理过程与最终答案。

Result: 该方法显著提升了LLM输出内容的客观准确性、可信度以及可追溯性。

Conclusion: VeriFact-CoT为解决LLM在生成复杂事实型内容时的幻觉和引用不足问题提供了一条有效路径，提高了其在高要求应用场景下的可靠性。

Abstract: This research introduces VeriFact-CoT (Verified Factual Chain-of-Thought), a
novel method designed to address the pervasive issues of hallucination and the
absence of credible citation sources in Large Language Models (LLMs) when
generating complex, fact-sensitive content. By incorporating a multi-stage
mechanism of 'fact verification-reflection-citation integration,' VeriFact-CoT
empowers LLMs to critically self-examine and revise their intermediate
reasoning steps and final answers. This process significantly enhances the
objective accuracy, trustworthiness, and traceability of the generated outputs,
making LLMs more reliable for applications demanding high fidelity such as
scientific research, news reporting, and legal consultation.

</details>


### [59] [LatinX: Aligning a Multilingual TTS Model with Direct Preference Optimization](https://arxiv.org/abs/2509.05863)
*Luis Felipe Chary,Miguel Arjona Ramirez*

Main category: cs.CL

TL;DR: LatinX是一个新提出的跨语音、跨语言TTS模型，能更好保留说话人音色，尤其在英文及罗曼语族中，DPO优化进一步降低了字词错误率并提升说话人相似度，主观、客观表现均优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 当前多语种语音合成（TTS）和语音到语音翻译领域中，主流方法难以在跨语言转换时有效保留说话人的音色和身份。实现能够高质量保持源说话人声音特性的跨语种TTS模型，对于提升用户体验和实际应用价值至关重要。

Method: 提出了LatinX模型，这是一个基于12层decoder-only Transformer的多语种TTS模型。训练分三阶段：（1）文本到音频映射的预训练；（2）零样本语音克隆的有监督微调；（3）基于自动标注的语音对，用DPO（Direct Preference Optimization）进行模型对齐，自动标注依据WER和说话人相似度指标。训练数据涵盖英语和多种罗曼语族语言，尤其注重葡萄牙语。

Result: LatinX模型（特别是结合DPO优化后）在英文及罗曼语族的跨语种语音合成任务中，相较于微调后的基线方法，表现为更低的字词错误率（WER）与更高的说话人相似度。

Conclusion: LatinX通过多阶段训练和DPO优化，提升了跨语种TTS时对原说话人身份的保持能力，从而在主观听感和客观指标上均超过了现有强基线。实验还揭示了客观与主观说话人相似度评价间的差异，并提出了未来关注方向，如偏好信号的平衡与更低延迟的架构设计。

Abstract: We present LatinX, a multilingual text-to-speech (TTS) model for cascaded
speech-to-speech translation that preserves the source speaker's identity
across languages. LatinX is a 12-layer decoder-only Transformer trained in
three stages: (i) pre-training for text-to-audio mapping, (ii) supervised
fine-tuning for zero-shot voice cloning, and (iii) alignment with Direct
Preference Optimization (DPO) using automatically labeled pairs based on Word
Error Rate (WER) and speaker-similarity metrics. Trained on English and Romance
languages with emphasis on Portuguese, LatinX with DPO consistently reduces WER
and improves objective similarity over the fine-tuned baseline. Human
evaluations further indicate stronger perceived speaker similarity than a
strong baseline (XTTSv2), revealing gaps between objective and subjective
measures. We provide cross-lingual analyses and discuss balanced preference
signals and lower-latency architectures as future work.

</details>


### [60] [ZhiFangDanTai: Fine-tuning Graph-based Retrieval-Augmented Generation Model for Traditional Chinese Medicine Formula](https://arxiv.org/abs/2509.05867)
*ZiXuan Zhang,Bowen Hao,Yingjie Li,Hongzhi Yin*

Main category: cs.CL

TL;DR: 提出了结合知识检索与大模型微调的新框架ZhiFangDanTai，用于提升中医方剂任务的效果，理论与实验均显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 中医方剂在流行病和复杂疾病的治疗中作用显著，但现有模型分析中医方剂配伍关系时，无论是传统算法还是深度学习手段，都缺少对方剂组成的完整描述和详细解释。现有的中医指令数据集不足，缺乏对方剂君臣佐使、功效、禁忌、舌脉诊断等细节，导致现有模型输出深度受限。

Method: 提出ZhiFangDanTai框架，将基于图的检索增强生成（GraphRAG）与大模型微调相结合。利用GraphRAG检索、整合结构化中医知识生成简明摘要，并构建扩展指令数据集，提升大模型整合检索知识的能力。同时，提供理论证明GraphRAG与微调结合可有效降低泛化误差与幻觉率。

Result: 在自采和临床数据集上的实验表明，ZhiFangDanTai在中医方剂任务上相较于现有方法有显著改进。

Conclusion: ZhiFangDanTai通过结构化知识检索与大模型微调，有效提升了中医方剂分析的准确性和解释性。

Abstract: Traditional Chinese Medicine (TCM) formulas play a significant role in
treating epidemics and complex diseases. Existing models for TCM utilize
traditional algorithms or deep learning techniques to analyze formula
relationships, yet lack comprehensive results, such as complete formula
compositions and detailed explanations. Although recent efforts have used TCM
instruction datasets to fine-tune Large Language Models (LLMs) for explainable
formula generation, existing datasets lack sufficient details, such as the
roles of the formula's sovereign, minister, assistant, courier; efficacy;
contraindications; tongue and pulse diagnosis-limiting the depth of model
outputs. To address these challenges, we propose ZhiFangDanTai, a framework
combining Graph-based Retrieval-Augmented Generation (GraphRAG) with LLM
fine-tuning. ZhiFangDanTai uses GraphRAG to retrieve and synthesize structured
TCM knowledge into concise summaries, while also constructing an enhanced
instruction dataset to improve LLMs' ability to integrate retrieved
information. Furthermore, we provide novel theoretical proofs demonstrating
that integrating GraphRAG with fine-tuning techniques can reduce generalization
error and hallucination rates in the TCM formula task. Experimental results on
both collected and clinical datasets demonstrate that ZhiFangDanTai achieves
significant improvements over state-of-the-art models. Our model is
open-sourced at https://huggingface.co/tczzx6/ZhiFangDanTai1.0.

</details>


### [61] [MedFactEval and MedAgentBrief: A Framework and Workflow for Generating and Evaluating Factual Clinical Summaries](https://arxiv.org/abs/2509.05878)
*François Grolleau,Emily Alsentzer,Timothy Keyes,Philip Chung,Akshay Swaminathan,Asad Aali,Jason Hom,Tridu Huynh,Thomas Lew,April S. Liang,Weihan Chu,Natasha Z. Steele,Christina F. Lin,Jingkun Yang,Kameron C. Black,Stephen P. Ma,Fateme N. Haredasht,Nigam H. Shah,Kevin Schulman,Jonathan H. Chen*

Main category: cs.CL

TL;DR: 本文提出了一个可扩展的临床文本事实一致性评估方法及高质量文本生成流程，LLM自动评估结果与专家基本一致，为医疗AI安全应用提供了支撑。


<details>
  <summary>Details</summary>
Motivation: 大语言模型生成的临床文本内容真实性验证是AI在医疗场景大规模应用的一大障碍，人工专家审核耗时且不可扩展，亟需高效自动化评估方案。

Method: 提出MedFactEval评估框架，临床专家定义高优先级事实，由“LLM陪审团”（多模型投票）判定事实是否出现在摘要中。还提出了MedAgentBrief多步骤工作流程，用于生成高质量、事实正确的出院小结。

Result: MedFactEval框架与七位医生多数投票获得的“金标准”高度一致（Cohen's kappa=81%），与单一人类专家相比并无统计学显著差异（kappa=67%，P<0.001）。

Conclusion: 该工作提供了强健的自动化评估框架（MedFactEval）及高效生成流程（MedAgentBrief），为临床工作中负责任部署生成式AI提供了完整方法。

Abstract: Evaluating factual accuracy in Large Language Model (LLM)-generated clinical
text is a critical barrier to adoption, as expert review is unscalable for the
continuous quality assurance these systems require. We address this challenge
with two complementary contributions. First, we introduce MedFactEval, a
framework for scalable, fact-grounded evaluation where clinicians define
high-salience key facts and an "LLM Jury"--a multi-LLM majority vote--assesses
their inclusion in generated summaries. Second, we present MedAgentBrief, a
model-agnostic, multi-step workflow designed to generate high-quality, factual
discharge summaries. To validate our evaluation framework, we established a
gold-standard reference using a seven-physician majority vote on
clinician-defined key facts from inpatient cases. The MedFactEval LLM Jury
achieved almost perfect agreement with this panel (Cohen's kappa=81%), a
performance statistically non-inferior to that of a single human expert
(kappa=67%, P < 0.001). Our work provides both a robust evaluation framework
(MedFactEval) and a high-performing generation workflow (MedAgentBrief),
offering a comprehensive approach to advance the responsible deployment of
generative AI in clinical workflows.

</details>


### [62] [Let's Roleplay: Examining LLM Alignment in Collaborative Dialogues](https://arxiv.org/abs/2509.05882)
*Abhijnan Nath,Carine Graff,Nikhil Krishnaswamy*

Main category: cs.CL

TL;DR: 本文提出并实证了针对多轮多人协作场景的LLM对齐新方法，利用“friction agents”干预促进团队反思和共识，对比实验显示该方法在任务效果和正确性上明显优于现有主流方法。


<details>
  <summary>Details</summary>
Motivation: 现有大模型对齐方法多局限于单人与模型互动，未涉及多轮、多方的复杂协作实际场景。随着LLM广泛应用为人类协作“伙伴”，亟需验证其在多方长周期合作中的可靠性与表现。

Method: 采用角色扮演（roleplay）方法模拟多人协作任务，分别注入不同训练方法的“friction agents”对比其干预效果，并提出了反事实评估框架定量测量干预对合作轨迹和信念对齐的影响。

Result: “friction-aware”对齐方法在促进团队共识和任务结果的正确性上，显著优于传统单用户对齐基线。

Conclusion: 通过引入基于“friction agents”方法的多方协作流程，可以显著提升大模型在多轮、多人的合作情境下的任务准确性和共识达成率。

Abstract: As Large Language Models (LLMs) integrate into diverse workflows, they are
increasingly being considered "collaborators" with humans. If such AI
collaborators are to be reliable, their behavior over multiturn interactions
must be predictable, validated and verified before deployment. Common alignment
techniques are typically developed under simplified single-user settings and do
not account for the dynamics of long-horizon multiparty interactions. This
paper examines how different alignment methods affect LLM agents' effectiveness
as partners in multiturn, multiparty collaborations. We study this question
through the lens of friction agents that intervene in group dialogues to
encourage the collaborative group to slow down and reflect upon their reasoning
for deliberative decision-making. Using a roleplay methodology, we evaluate
interventions from differently-trained friction agents in collaborative task
conversations. We propose a novel counterfactual evaluation framework that
quantifies how friction interventions change the trajectory of group
collaboration and belief alignment. Our results show that a friction-aware
approach significantly outperforms common alignment baselines in helping both
convergence to a common ground, or agreed-upon task-relevant propositions, and
correctness of task outcomes.

</details>


### [63] [Enhancing the Robustness of Contextual ASR to Varying Biasing Information Volumes Through Purified Semantic Correlation Joint Modeling](https://arxiv.org/abs/2509.05908)
*Yue Gu,Zhihao Du,Ying Shi,Shiliang Zhang,Qian Chen,Jiqing Han*

Main category: cs.CL

TL;DR: PSC-Joint方法通过语义相关性联合建模与高效过滤机制，提升了偏置短语语音识别的准确率，显著优于传统跨注意力模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于跨注意力的语音识别在个性化偏置短语识别上有所突破，但偏置列表长度变化显著影响性能，仅部分偏置信息与识别任务高度相关。因此需优化信息筛选与融合方式。

Method: 提出PSC-Joint建模策略，包括三阶段语义相关性计算（列表、短语、词元），通过联合建模突出最相关信息，并引入分组与竞争性过滤机制，降低算法负担。

Result: 在AISHELL-1和KeSpeech数据集上，PSC-Joint在不同偏置列表长度条件下，F1相对提升分别达到21.34%和28.46%，优于对比基线。

Conclusion: PSC-Joint通过联合建模三种语义相关性提升了在不同长度偏置列表下的语音识别性能，并有效过滤无关信息，显著超过现有方法。

Abstract: Recently, cross-attention-based contextual automatic speech recognition (ASR)
models have made notable advancements in recognizing personalized biasing
phrases. However, the effectiveness of cross-attention is affected by
variations in biasing information volume, especially when the length of the
biasing list increases significantly. We find that, regardless of the length of
the biasing list, only a limited amount of biasing information is most relevant
to a specific ASR intermediate representation. Therefore, by identifying and
integrating the most relevant biasing information rather than the entire
biasing list, we can alleviate the effects of variations in biasing information
volume for contextual ASR. To this end, we propose a purified semantic
correlation joint modeling (PSC-Joint) approach. In PSC-Joint, we define and
calculate three semantic correlations between the ASR intermediate
representations and biasing information from coarse to fine: list-level,
phrase-level, and token-level. Then, the three correlations are jointly modeled
to produce their intersection, so that the most relevant biasing information
across various granularities is highlighted and integrated for contextual
recognition. In addition, to reduce the computational cost introduced by the
joint modeling of three semantic correlations, we also propose a purification
mechanism based on a grouped-and-competitive strategy to filter out irrelevant
biasing phrases. Compared with baselines, our PSC-Joint approach achieves
average relative F1 score improvements of up to 21.34% on AISHELL-1 and 28.46%
on KeSpeech, across biasing lists of varying lengths.

</details>


### [64] [Accelerating Large Language Model Inference via Early-Exiting Algorithms](https://arxiv.org/abs/2509.05915)
*Sangmin Bae*

Main category: cs.CL

TL;DR: 本文提出方法解决了自适应推理下大型语言模型的效率与动态性冲突，通过并行解码、参数共享和动态路由，实现了更优的推理效率和性能平衡。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型拥有强大能力，但其实际部署受到高计算成本的限制。虽然自适应计算方法（比如early-exiting）可以减少计算量，但带来每个token的动态性会导致系统级瓶颈，反而降低批量推理的吞吐量。论文旨在解决这一效率与动态性之间的矛盾。

Method: 论文采用算法与模型架构协同设计，平衡动态性与效率。具体方法包括：提出高效的并行解码机制以减少early-exiting相关的开销；利用深度参数共享，既减小模型体积，又缓解动态推理中的同步问题；设计统一框架，通过预训练轻量级路由器为每个token动态分配递归深度，优化自适应计算和参数效率。

Result: 提出的高效并行解码和深度参数共享方法有效降低了推理同步开销，实现了模型的小型化。预训练轻量级路由器在动态分配计算资源的同时保持了模型性能。整体方法建立了效率与性能的新帕累托前沿。

Conclusion: 通过算法与架构的协同创新，本研究实现了大型语言模型在自适应推理中的高效与动态性的最佳平衡，为大模型实用化部署提供了新思路和技术路径。

Abstract: Large language models have achieved remarkable capabilities, but their
practical deployment is hindered by significant computational costs. While
adaptive computation methods like early-exiting promise to reduce these costs,
they introduce a fundamental conflict: the per-token dynamism intended to save
computation often creates system-level bottlenecks that can paradoxically
reduce throughput in batched inference. This dissertation resolves this
conflict by co-designing adaptive algorithms and model architectures to strike
an optimal balance between dynamism and efficiency. To this end, our work first
addresses critical sources of overhead in conventional early-exiting by
proposing an efficient parallel decoding mechanism. We then show that deep
parameter sharing provides an architectural foundation that not only yields
compact, parameter-efficient models but also inherently mitigates the critical
synchronization issues affecting dynamic inference. Finally, this work presents
a unified framework where lightweight routers are pretrained to dynamically
assign an optimal recursion depth for each token. This approach establishes a
new Pareto frontier between efficiency and performance by effectively
optimizing for both adaptive computation and parameter efficiency within a
single model.

</details>


### [65] [KatotohananQA: Evaluating Truthfulness of Large Language Models in Filipino](https://arxiv.org/abs/2509.06065)
*Lorenzo Alfred Nery,Ronald Dawson Catignas,Thomas James Tiam-Lee*

Main category: cs.CL

TL;DR: 作者提出了菲律宾语版本TruthfulQA（KatotohananQA），评测显示LLM在菲律宾语事实性表现较差，需扩展多语言评测以提升LLM公平与可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型虽然在多项任务上表现出色，但经常出现事实性错误（幻觉），影响其可靠性。同时，主流事实性基准如TruthfulQA主要为英语数据，缺乏低资源语言的评测工具。

Method: 本文将TruthfulQA评测集翻译成菲律宾语，创建了KatotohananQA，并用它评测了七个免费专有模型，采用二选一框架对比分析它们在英语和菲律宾语的事实性表现。

Result: 实验结果显示，LLM在菲律宾语上的事实性表现明显弱于英语，但OpenAI最新模型（GPT-5及其mini版本）展现出较强的多语言稳健性。不同问题类型和主题间也存在表现差异，部分类别在多语言迁移时表现不佳。

Conclusion: 评测结果强调了扩大多语种评测范围的重要性，以确保LLM的公平性和可靠性，尤其在低资源语言场景下。

Abstract: Large Language Models (LLMs) achieve remarkable performance across various
tasks, but their tendency to produce hallucinations limits reliable adoption.
Benchmarks such as TruthfulQA have been developed to measure truthfulness, yet
they are primarily available in English, leaving a gap in evaluating LLMs in
low-resource languages. To address this, we present KatotohananQA, a Filipino
translation of the TruthfulQA benchmark. Seven free-tier proprietary models
were assessed using a binary-choice framework. Findings show a significant
performance gap between English and Filipino truthfulness, with newer OpenAI
models (GPT-5 and GPT-5 mini) demonstrating strong multilingual robustness.
Results also reveal disparities across question characteristics, suggesting
that some question types, categories, and topics are less robust to
multilingual transfer which highlight the need for broader multilingual
evaluation to ensure fairness and reliability in LLM usage.

</details>


### [66] [Multimodal Fine-grained Context Interaction Graph Modeling for Conversational Speech Synthesis](https://arxiv.org/abs/2509.06074)
*Zhenqi Jia,Rui Liu,Berrak Sisman,Haizhou Li*

Main category: cs.CL

TL;DR: 本文提出MFCIG-CSS，通过语义和韵律的细粒度交互图，有效提升会话语音合成的自然性，在实验中取得最优表现。


<details>
  <summary>Details</summary>
Motivation: 现有CSS方法主要关注话语级交互，忽略了多模态对话历史（MDH）中词级语义与韵律的细粒度交互，对自然语调表达有一定局限。

Method: 构建两种专门的多模态细粒度对话交互图：语义交互图和韵律交互图，并对词级语义和韵律的相互作用进行建模，从而提升语音合成效果。

Result: MFCIG-CSS通过细粒度语义与韵律交互建模，使合成语音在DailyTalk数据集上的韵律表现超过所有现有基线。

Conclusion: 实验结果表明，MFCIG-CSS系统在语调表达自然性方面优于所有基线模型。

Abstract: Conversational Speech Synthesis (CSS) aims to generate speech with natural
prosody by understanding the multimodal dialogue history (MDH). The latest work
predicts the accurate prosody expression of the target utterance by modeling
the utterance-level interaction characteristics of MDH and the target
utterance. However, MDH contains fine-grained semantic and prosody knowledge at
the word level. Existing methods overlook the fine-grained semantic and
prosodic interaction modeling. To address this gap, we propose MFCIG-CSS, a
novel Multimodal Fine-grained Context Interaction Graph-based CSS system. Our
approach constructs two specialized multimodal fine-grained dialogue
interaction graphs: a semantic interaction graph and a prosody interaction
graph. These two interaction graphs effectively encode interactions between
word-level semantics, prosody, and their influence on subsequent utterances in
MDH. The encoded interaction features are then leveraged to enhance synthesized
speech with natural conversational prosody. Experiments on the DailyTalk
dataset demonstrate that MFCIG-CSS outperforms all baseline models in terms of
prosodic expressiveness. Code and speech samples are available at
https://github.com/AI-S2-Lab/MFCIG-CSS.

</details>


### [67] [Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge](https://arxiv.org/abs/2509.06079)
*Hao Liang,Ruitao Wu,Bohan Zeng,Junbo Niu,Wentao Zhang,Bin Dong*

Main category: cs.CL

TL;DR: 本文提出了一种利用图片描述辅助推理的新方法，在主流多模态推理竞赛和基准上均取得了领先表现，提升了AI在视觉-文本联合理解方面的能力。


<details>
  <summary>Details</summary>
Motivation: 目前多模态推理（如图文结合）依然是人工智能领域的核心难题，虽然文本推理已有重大突破，但主流大模型在多模态场景表现不佳。

Method: 提出了一种caption-assisted（标题/描述辅助）推理框架，用于更有效地连接视觉和文本模态。

Result: 该方法获得了ICML 2025 AI for Math Workshop & Challenge 2: SeePhys竞赛第一名，并在MathVerse基准上验证了其泛化性。

Conclusion: caption-assisted reasoning框架显著提升了视觉与文本联合推理能力，在数学推理和几何推理等多模态场景下都表现出强大效果。

Abstract: Multimodal reasoning remains a fundamental challenge in artificial
intelligence. Despite substantial advances in text-based reasoning, even
state-of-the-art models such as GPT-o3 struggle to maintain strong performance
in multimodal scenarios. To address this gap, we introduce a caption-assisted
reasoning framework that effectively bridges visual and textual modalities. Our
approach achieved 1st place in the ICML 2025 AI for Math Workshop \& Challenge
2: SeePhys, highlighting its effectiveness and robustness. Furthermore, we
validate its generalization on the MathVerse benchmark for geometric reasoning,
demonstrating the versatility of our method. Our code is publicly available at
https://github.com/OpenDCAI/SciReasoner.

</details>


### [68] [Orthogonal Low-rank Adaptation in Lie Groups for Continual Learning of Large Language Models](https://arxiv.org/abs/2509.06100)
*Kefan Cao,Shuaicheng Wu*

Main category: cs.CL

TL;DR: 作者提出的OLieRA方法能同时维持LLM参数的几何结构与正交约束，有效应对多任务顺序学习中的遗忘现象，并且在连续学习基准上表现卓越。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在顺序多任务设置下容易发生灾难性遗忘。现有的参数正则化方法通过约束低秩子空间的正交性来缓解任务间干扰，但忽视了常规加性微调会破坏LLM参数的固有几何结构，从而限制了模型性能。

Method: 提出Orthogonal Low-rank Adaptation in Lie Groups（OLieRA）方法，将李群理论引入LLM微调过程中：用乘法更新方式在保持参数几何结构的同时，对任务子空间施加正交性约束。

Result: OLieRA方法在Standard CL基准上实现了最先进的结果，在大量任务场景下也依然保持了领先性能。

Conclusion: OLieRA通过结合参数空间的几何结构保持与正交性约束，有效缓解了灾难性遗忘问题，并在多任务连续学习任务中取得了优异表现。

Abstract: Large language models (LLMs) are prone to catastrophic forgetting in
sequential multi-task settings. Parameter regularization methods such as O-LoRA
and N-LoRA alleviate task interference by enforcing low-rank subspace
orthogonality, but they overlook the fact that conventional additive
fine-tuning disrupts the intrinsic geometric structure of LLM parameters,
limiting performance. Our key insight is that the parameter space of LLMs
possesses a geometric structure, which must be preserved in addition to
enforcing orthogonality. Based on this, we propose Orthogonal Low-rank
Adaptation in Lie Groups (OLieRA), which introduces Lie group theory into LLM
fine-tuning: leveraging multiplicative updates to preserve parameter geometry
while applying orthogonality constraints to task subspaces. Experiments
demonstrate that OLieRA achieves state-of-the-art results on the Standard CL
benchmark and remains among the top-performing methods in the Large Number of
Tasks setting.

</details>


### [69] [Benchmarking Gender and Political Bias in Large Language Models](https://arxiv.org/abs/2509.06164)
*Jinrui Yang,Xudong Han,Timothy Baldwin*

Main category: cs.CL

TL;DR: 本文提出EuroParlVote基准，专用于评估LLM在欧洲议会相关政治敏感任务中的公正性和准确性。发现主流LLM在性别和政治倾向上的偏见较显著，专有模型表现优于开源模型。该基准和数据集为公平性研究提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）在政治敏感环境下的公平性和准确性问题尚未得到充分评估，缺乏标准化基准。
该研究希望填补这一空白，尤其关注在性别、政治倾向等方面潜在的模型偏见。

Method: 提出EuroParlVote基准，连接欧洲议会辩论演讲与投票结果，并包含欧洲议会议员（MEP）的性别、年龄、国家、政党等丰富人口统计信息。
基于此，设计两个任务：性别分类和投票预测，对多种尖端LLM进行评测，分析模型在不同人群和政治倾向上的表现。

Result: LLMs在性别分类时常将女性议员误判为男性，且在女性演讲者上投票模拟的准确率较低。
在政治倾向上，LLMs更倾向于中间派，对极左和极右派表现较差。
专有模型如GPT-4o在稳健性和公平性方面优于开源模型。

Conclusion: EuroParlVote数据集和代码均已公开，为未来在政治语境下研究NLP中的公平性和责任性提供了基础。
结果显示现有LLM仍有性别和政治偏见，需加强模型在敏感语境下的公平性设计算法。

Abstract: We introduce EuroParlVote, a novel benchmark for evaluating large language
models (LLMs) in politically sensitive contexts. It links European Parliament
debate speeches to roll-call vote outcomes and includes rich demographic
metadata for each Member of the European Parliament (MEP), such as gender, age,
country, and political group. Using EuroParlVote, we evaluate state-of-the-art
LLMs on two tasks -- gender classification and vote prediction -- revealing
consistent patterns of bias. We find that LLMs frequently misclassify female
MEPs as male and demonstrate reduced accuracy when simulating votes for female
speakers. Politically, LLMs tend to favor centrist groups while underperforming
on both far-left and far-right ones. Proprietary models like GPT-4o outperform
open-weight alternatives in terms of both robustness and fairness. We release
the EuroParlVote dataset, code, and demo to support future research on fairness
and accountability in NLP within political contexts.

</details>


### [70] [Understanding the Influence of Synthetic Data for Text Embedders](https://arxiv.org/abs/2509.06184)
*Jacob Mitchell Springer,Vaibhav Adlakha,Siva Reddy,Aditi Raghunathan,Marius Mosbach*

Main category: cs.CL

TL;DR: 公开高质量合成数据集带来一定任务性能提升，但收益局限于个别任务，且可能损害其它任务表现，挑战了“合成数据提升普适性”的直观假设。


<details>
  <summary>Details</summary>
Motivation: 尽管生成型大模型（LLM）合成数据集推动了通用文本嵌入器的发展，目前尚无公开的合成数据集，限制了对其泛化作用及影响的研究。本文的工作旨在填补这一空白。

Method: 首先复现并公开了 Wang 等人提出的 Mistral-E5 合成数据集。随后，通过实验系统性分析合成数据对模型泛化能力的提升点和适用场景。

Result: 所公开的合成数据质量较高，并能稳定提升部分任务的性能。然而，收益分布并不均匀，提升主要集中在某些特定数据集，对不同任务可能存在互斥效应，即提升一类任务的同时会削弱另一类任务的表现。

Conclusion: 目前通过合成数据训练通用文本嵌入器存在显著局限性，不能简单认为合成数据能全方位提升模型鲁棒性及表现。

Abstract: Recent progress in developing general purpose text embedders has been driven
by training on ever-growing corpora of synthetic LLM-generated data.
Nonetheless, no publicly available synthetic dataset exists, posing a barrier
to studying its role for generalization. To address this issue, we first
reproduce and publicly release the synthetic data proposed by Wang et al.
(Mistral-E5). Our synthetic data is high quality and leads to consistent
improvements in performance. Next, we critically examine where exactly
synthetic data improves model generalization. Our analysis reveals that
benefits from synthetic data are sparse and highly localized to individual
datasets. Moreover, we observe trade-offs between the performance on different
categories and data that benefits one task, degrades performance on another.
Our findings highlight the limitations of current synthetic data approaches for
building general-purpose embedders and challenge the notion that training on
synthetic data leads to more robust embedding models across tasks.

</details>


### [71] [Augmented Fine-Tuned LLMs for Enhanced Recruitment Automation](https://arxiv.org/abs/2509.06196)
*Mohamed T. Younes,Omar Walid,Khaled Shaban,Ali Hamdi,Mai Hassan*

Main category: cs.CL

TL;DR: 通过特定招聘数据和真实简历数据，微调大语言模型取得了行业最优的招聘自动化表现，尤其体现在准确匹配候选人与岗位，提高了招聘流程效率和精度。


<details>
  <summary>Details</summary>
Motivation: 招聘流程自动化是企业提高效率的重要方向，但现有通用大语言模型（LLM）在招聘领域的表现有限。

Method: 提出了一套新的方法，对大语言模型进行特定于招聘任务的微调，并利用标准化JSON格式构建合成训练数据集，同时使用DeepSeek模型解析真实简历并纳入训练。

Result: 实验结果表明，微调后的Phi-4模型在招聘任务中取得了最高90.62%的F1分数，在各项指标上优于基础模型和其他先进LLM。

Conclusion: 面向招聘任务微调的LLM拥有高精度且具可扩展性，能够显著提升候选人与岗位匹配的准确性，有望彻底变革招聘流程。

Abstract: This paper presents a novel approach to recruitment automation. Large
Language Models (LLMs) were fine-tuned to improve accuracy and efficiency.
Building upon our previous work on the Multilayer Large Language Model-Based
Robotic Process Automation Applicant Tracking (MLAR) system . This work
introduces a novel methodology. Training fine-tuned LLMs specifically tuned for
recruitment tasks. The proposed framework addresses the limitations of generic
LLMs by creating a synthetic dataset that uses a standardized JSON format. This
helps ensure consistency and scalability. In addition to the synthetic data
set, the resumes were parsed using DeepSeek, a high-parameter LLM. The resumes
were parsed into the same structured JSON format and placed in the training
set. This will help improve data diversity and realism. Through
experimentation, we demonstrate significant improvements in performance
metrics, such as exact match, F1 score, BLEU score, ROUGE score, and overall
similarity compared to base models and other state-of-the-art LLMs. In
particular, the fine-tuned Phi-4 model achieved the highest F1 score of 90.62%,
indicating exceptional precision and recall in recruitment tasks. This study
highlights the potential of fine-tuned LLMs. Furthermore, it will revolutionize
recruitment workflows by providing more accurate candidate-job matching.

</details>


### [72] [MSLEF: Multi-Segment LLM Ensemble Finetuning in Recruitment](https://arxiv.org/abs/2509.06200)
*Omar Walid,Mohamed T. Younes,Khaled Shaban,Mai Hassan,Ali Hamdi*

Main category: cs.CL

TL;DR: MSLEF利用多模型针对简历不同片段进行加权集成，显著提升了自动化简历解析的准确率与适应性，比单一模型更适合应用于现实招聘流程。


<details>
  <summary>Details</summary>
Motivation: 在招聘自动化中，简历解析对简历格式和结构的多样性有较高要求，单一模型难以应对，因此需要提升解析的准确性和适应性。

Method: 提出MSLEF多段集成框架，将针对不同简历片段微调过的大语言模型(LLM)结合，采用加权投票机制融合各模型结果。每个模型专注于特定简历片段，并匹配相应权值。架构中还引入Gemini-2.5-Flash作为高级聚合器，以及Gemma 9B、LLaMA 3.1 8B和Phi-4 14B等多个LLM，共同提升解析效果。

Result: MSLEF在Exact Match、F1、BLEU、ROUGE及Recruitment Similarity (RS)等指标上均有显著提升。相比最佳单模型，RS指标最高提升7%，对不同简历格式具有更好的泛化与适应能力。

Conclusion: MSLEF通过细分片段、权值投票和多模型集成，显著提升了简历解析的准确性和鲁棒性，适合实际招聘场景使用。

Abstract: This paper presents MSLEF, a multi-segment ensemble framework that employs
LLM fine-tuning to enhance resume parsing in recruitment automation. It
integrates fine-tuned Large Language Models (LLMs) using weighted voting, with
each model specializing in a specific resume segment to boost accuracy.
Building on MLAR , MSLEF introduces a segment-aware architecture that leverages
field-specific weighting tailored to each resume part, effectively overcoming
the limitations of single-model systems by adapting to diverse formats and
structures. The framework incorporates Gemini-2.5-Flash LLM as a high-level
aggregator for complex sections and utilizes Gemma 9B, LLaMA 3.1 8B, and Phi-4
14B. MSLEF achieves significant improvements in Exact Match (EM), F1 score,
BLEU, ROUGE, and Recruitment Similarity (RS) metrics, outperforming the best
single model by up to +7% in RS. Its segment-aware design enhances
generalization across varied resume layouts, making it highly adaptable to
real-world hiring scenarios while ensuring precise and reliable candidate
representation.

</details>


### [73] [No Encore: Unlearning as Opt-Out in Music Generation](https://arxiv.org/abs/2509.06277)
*Jinju Kim,Taehan Kim,Abdul Waheed,Rita Singh*

Main category: cs.CL

TL;DR: 该论文探索了如何将去学习技术应用于AI音乐生成，旨在解决版权风险问题。通过实验证实了该方法部分可行，但仍有诸多挑战，未来仍需优化。


<details>
  <summary>Details</summary>
Motivation: AI音乐生成工具可以通过文本描述直观地生成音乐，有助于创意产业的发展，但也引发了对版权创作被滥用的伦理和法律担忧。为此，作者希望通过去学习技术，避免模型无意中利用受保护的创意内容。

Method: 本研究尝试将现有机器去学习（machine unlearning）方法应用于一个预训练的文本到音乐（Text-to-Music, TTM）生成模型基线上，并分析其去除预训练数据集知识的有效性，同时评估不会对模型性能造成显著损害。

Result: 实验表明，在音乐生成模型上应用去学习技术存在挑战，但在不严重削弱模型性能的前提下，部分达到了对特定数据集知识的去除。作者总结了当前去学习方法的有效性及其局限性。

Conclusion: 本文为音乐生成模型中去学习应用的研究奠定了基础，指出了其挑战，并为后续进一步优化去学习方法提供了分析和指导。

Abstract: AI music generation is rapidly emerging in the creative industries, enabling
intuitive music generation from textual descriptions. However, these systems
pose risks in exploitation of copyrighted creations, raising ethical and legal
concerns. In this paper, we present preliminary results on the first
application of machine unlearning techniques from an ongoing research to
prevent inadvertent usage of creative content. Particularly, we explore
existing methods in machine unlearning to a pre-trained Text-to-Music (TTM)
baseline and analyze their efficacy in unlearning pre-trained datasets without
harming model performance. Through our experiments, we provide insights into
the challenges of applying unlearning in music generation, offering a
foundational analysis for future works on the application of unlearning for
music generative models.

</details>


### [74] [Mask-GCG: Are All Tokens in Adversarial Suffixes Necessary for Jailbreak Attacks?](https://arxiv.org/abs/2509.06350)
*Junjie Mu,Zonghao Ying,Zhekui Fan,Zonglei Jing,Yaoyuan Zhang,Zhengmin Yu,Wenxin Zhang,Quanchen Zou,Xiangzheng Zhang*

Main category: cs.CL

TL;DR: 本文提出了Mask-GCG方法，通过学习token mask剔除越狱提示后缀中的冗余token，提升了越狱攻击效率且不影响成功率。该发现有助于优化与解释LLM安全攻防。


<details>
  <summary>Details</summary>
Motivation: 现有基于固定长度后缀的GCG方法可能存在token冗余，这种冗余未被研究。通过剪枝无用token，可能提高越狱攻击效率并降低资源消耗。

Method: 提出了一种名为Mask-GCG的方法，通过可学习的token mask，识别提示词后缀中影响较大的token，并对其增加更新概率，同时对低影响token进行剪枝，从而减少梯度空间与计算开销，并加快攻击速度。对原始GCG及多个改进版本进行了评估。

Result: Mask-GCG能有效减少计算资源消耗和攻击所需时间，同时保持高的攻击成功率。实验揭示，大多数token都很重要，但冗余token的存在允许一定程度的剪枝优化。

Conclusion: 实验结果表明，在生成越狱提示词时，大部分后缀token对攻击成功起到显著作用，但删除少量低影响token不会影响损失值或攻击成功率（ASR），揭示了提示词中存在冗余。此发现有助于开发更高效、更可解释的LLM防御或攻击方法。

Abstract: Jailbreak attacks on Large Language Models (LLMs) have demonstrated various
successful methods whereby attackers manipulate models into generating harmful
responses that they are designed to avoid. Among these, Greedy Coordinate
Gradient (GCG) has emerged as a general and effective approach that optimizes
the tokens in a suffix to generate jailbreakable prompts. While several
improved variants of GCG have been proposed, they all rely on fixed-length
suffixes. However, the potential redundancy within these suffixes remains
unexplored. In this work, we propose Mask-GCG, a plug-and-play method that
employs learnable token masking to identify impactful tokens within the suffix.
Our approach increases the update probability for tokens at high-impact
positions while pruning those at low-impact positions. This pruning not only
reduces redundancy but also decreases the size of the gradient space, thereby
lowering computational overhead and shortening the time required to achieve
successful attacks compared to GCG. We evaluate Mask-GCG by applying it to the
original GCG and several improved variants. Experimental results show that most
tokens in the suffix contribute significantly to attack success, and pruning a
minority of low-impact tokens does not affect the loss values or compromise the
attack success rate (ASR), thereby revealing token redundancy in LLM prompts.
Our findings provide insights for developing efficient and interpretable LLMs
from the perspective of jailbreak attacks.

</details>


### [75] [PL-CA: A Parametric Legal Case Augmentation Framework](https://arxiv.org/abs/2509.06356)
*Ao Chang,Yubo Chen,Jun Zhao*

Main category: cs.CL

TL;DR: 提出参数化RAG方法，通过知识编码与模型结构融合，解决上下文受限和计算开销大的问题，并用新多任务法律数据集验证了该方法有效性。


<details>
  <summary>Details</summary>
Motivation: 当前RAG（Retrieval-Augmented Generation）方法虽然在司法领域应对模型知识不足和幻觉方面表现出色，但其将检索文档直接添加入模型上下文的方法受限于上下文窗口大小且导致计算开销大，影响模型的注意力和下游任务表现。同时，现有基准多忽略现实中司法任务的多样性和缺乏专家标注，难以真实反映模型能力。

Method: 提出了一种参数化RAG（P-RAG）框架，通过对语料知识进行数据增强，并将法律知识编码为参数向量，然后利用LoRA方法将这些知识集成到大模型的前馈网络（FFN）中，从而缓解长上下文带来的压力。另外，构建了一个包含2000多个经专家标注和人工审核的多任务法律数据集。

Result: 实验结果表明，该方法在有效减少超长上下文带来的计算开销的同时，仍然保持了与传统RAG竞争的下游任务表现。

Conclusion: 所提P-RAG框架能缓解RAG方法因上下文长度导致的局限，同时维护性能。新构建的多任务法律数据集也有助于更真实评估和提升模型能力。

Abstract: Conventional RAG is considered one of the most effective methods for
addressing model knowledge insufficiency and hallucination, particularly in the
judicial domain that requires high levels of knowledge rigor, logical
consistency, and content integrity. However, the conventional RAG method only
injects retrieved documents directly into the model's context, which severely
constrains models due to their limited context windows and introduces
additional computational overhead through excessively long contexts, thereby
disrupting models' attention and degrading performance on downstream tasks.
Moreover, many existing benchmarks lack expert annotation and focus solely on
individual downstream tasks while real-world legal scenarios consist of
multiple mixed legal tasks, indicating conventional benchmarks' inadequacy for
reflecting models' true capabilities. To address these limitations, we propose
PL-CA, which introduces a parametric RAG (P-RAG) framework to perform data
augmentation on corpus knowledge and encode this legal knowledge into
parametric vectors, and then integrates this parametric knowledge into the
LLM's feed-forward networks (FFN) via LoRA, thereby alleviating models' context
pressure. Additionally, we also construct a multi-task legal dataset comprising
more than 2000 training and test instances, which are all expert-annotated and
manually verified. We conduct our experiments on our dataset, and the
experimental results demonstrate that our method reduces the overhead
associated with excessively long contexts while maintaining competitive
performance on downstream tasks compared to conventional RAG. Our code and
dataset are provided in the appendix.

</details>


### [76] [Do LLMs exhibit the same commonsense capabilities across languages?](https://arxiv.org/abs/2509.06401)
*Ivan Martínez-Murillo,Elena Lloret,Paloma Moreda,Albert Gatt*

Main category: cs.CL

TL;DR: 本文提出了多语言常识生成基准MULTICOM，并用多种主流开源LLM分析其在英语及低资源语言上的表现。结果显示，现有模型在英语任务显著优于其他语言，凸显了多语言常识生成的挑战。上下文支持能一定程度提升低资源语言效果。数据集已公开，以促进后续研究。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）在英文常识生成方面表现突出，但其在多语言环境下的能力仍未被充分探究。本研究旨在填补这一领域空白，分析LLM在多语言常识生成任务中的实际表现，特别关注资源较少语言的效果。

Method: 作者构建了MULTICOM基准，通过将COCOTEROS数据集扩展到英语、西班牙语、荷兰语和瓦伦西亚语，以“给定词语三元组，生成包含这些词的常识性句子”为任务。针对该基准，评估了多种开源LLM，包括LLaMA、Qwen、Gemma、EuroLLM和Salamandra，结合自动化指标、LLM-判官（Prometheus和JudgeLM）以及人工标注进行系统评价。

Result: 所有模型在英文任务上均表现最佳，而在资源稀缺语言上的生成性能明显较低。上下文支持对提升低资源语言有一定帮助，但整体效果波动较大。

Conclusion: 当前LLM在多语言常识生成方面存在显著局限，特别是在资源较少语言的表现亟待改进。论文公开了MULTICOM数据集，希望推动社区在此方向的进一步研究。

Abstract: This paper explores the multilingual commonsense generation abilities of
Large Language Models (LLMs). To facilitate this investigation, we introduce
MULTICOM, a novel benchmark that extends the COCOTEROS dataset to four
languages: English, Spanish, Dutch, and Valencian. The task involves generating
a commonsensical sentence that includes a given triplet of words. We evaluate a
range of open-source LLMs, including LLaMA, Qwen, Gemma, EuroLLM, and
Salamandra, on this benchmark. Our evaluation combines automatic metrics,
LLM-as-a-judge approaches (using Prometheus and JudgeLM), and human
annotations. Results consistently show superior performance in English, with
significantly lower performance in less-resourced languages. While contextual
support yields mixed results, it tends to benefit underrepresented languages.
These findings underscore the current limitations of LLMs in multilingual
commonsense generation. The dataset is publicly available at
https://huggingface.co/datasets/gplsi/MULTICOM.

</details>


### [77] [WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents](https://arxiv.org/abs/2509.06501)
*Junteng Liu,Yunji Li,Chi Zhang,Jingyang Li,Aili Chen,Ke Ji,Weiyu Cheng,Zijia Wu,Chengyu Du,Qidi Xu,Jiayuan Song,Zhengmao Zhu,Wenhu Chen,Pengyu Zhao,Junxian He*

Main category: cs.CL

TL;DR: 本文提出WebExplorer系统，通过特色数据生成方法及强化学习，显著提升了Web智能体模型的信息检索、推理能力，实现了8B模型超越大规模竞争对手，并具备良好泛化性，推动了长时序Web智能体发展。


<details>
  <summary>Details</summary>
Motivation: 现有开源Web代理模型在复杂任务下的信息检索能力有限，或实现不透明。作者认为关键挑战在于缺乏高难度信息检索数据。

Method: 提出WebExplorer，一种基于模型探索与递进式查询演化的数据生成方法，生成需要多步推理和复杂网页导航的查询-答案对。利用该高质量数据集，对WebExplorer-8B模型进行有监督微调与强化学习训练。模型支持128K上下文及最多100次工具调用回合，擅长长时序复杂任务。

Result: WebExplorer-8B在多个信息检索基准上取得同规模最优表现，作为8B规模模型，在RL优化后可有效检索16步以上，BrowseComp-en/zh准确率超越WebSailor-72B，并在WebWalkerQA和FRAMES等任务上领先所有100B规模以下模型。模型还在HLE基准上表现优异，具备良好泛化能力。

Conclusion: WebExplorer通过创新性数据生成与训练，显著提升了中小规模Web代理模型的信息检索与多步推理能力，并为实现长时序Web智能体提供了可行路径。

Abstract: The paradigm of Large Language Models (LLMs) has increasingly shifted toward
agentic applications, where web browsing capabilities are fundamental for
retrieving information from diverse online sources. However, existing
open-source web agents either demonstrate limited information-seeking abilities
on complex tasks or lack transparent implementations. In this work, we identify
that the key challenge lies in the scarcity of challenging data for information
seeking. To address this limitation, we introduce WebExplorer: a systematic
data generation approach using model-based exploration and iterative,
long-to-short query evolution. This method creates challenging query-answer
pairs that require multi-step reasoning and complex web navigation. By
leveraging our curated high-quality dataset, we successfully develop advanced
web agent WebExplorer-8B through supervised fine-tuning followed by
reinforcement learning. Our model supports 128K context length and up to 100
tool calling turns, enabling long-horizon problem solving. Across diverse
information-seeking benchmarks, WebExplorer-8B achieves the state-of-the-art
performance at its scale. Notably, as an 8B-sized model, WebExplorer-8B is able
to effectively search over an average of 16 turns after RL training, achieving
higher accuracy than WebSailor-72B on BrowseComp-en/zh and attaining the best
performance among models up to 100B parameters on WebWalkerQA and FRAMES.
Beyond these information-seeking tasks, our model also achieves strong
generalization on the HLE benchmark even though it is only trained on
knowledge-intensive QA data. These results highlight our approach as a
practical path toward long-horizon web agents.

</details>


### [78] [Crown, Frame, Reverse: Layer-Wise Scaling Variants for LLM Pre-Training](https://arxiv.org/abs/2509.06518)
*Andrei Baroian,Kasper Notebomer*

Main category: cs.CL

TL;DR: 本文提出分层调整Transformer层宽度和注意力头的新方法，使同等参数数量下模型性能提升，表明探索层次结构架构设计具有发展潜力。


<details>
  <summary>Details</summary>
Motivation: 传统的Transformer模型每层规模一致，忽视了不同深度层的功能多样性和算力需求各异的问题。作者旨在探索分层异构配置对于模型性能的影响。

Method: 提出了三种新的Layer-Wise Scaling（LWS）变体：Framed、Reverse和Crown，在预训练阶段通过两点或三点线性插值的方式，分配前馈网络（FFN）宽度和注意力头数；在固定参数预算和训练数据下，系统地对这些变体进行消融分析。

Result: 在保持模型参数总量和训练吞吐量基本不变的情况下，所提出的层级结构模型不仅收敛速度类似，而且最终性能优于相同成本下的等宽baseline。

Conclusion: 本研究初步探索了层级异构（layer-wise）结构在预训练Transformer模型设计中的可行性，并证明其效果优于传统的等宽（isotropic）方案。

Abstract: Transformer-based language models traditionally use uniform (isotropic) layer
sizes, yet they ignore the diverse functional roles that different depths can
play and their computational capacity needs. Building on Layer-Wise Scaling
(LWS) and pruning literature, we introduce three new LWS variants - Framed,
Reverse, and Crown - that redistribute FFN widths and attention heads via two
or three-point linear interpolation in the pre-training stage. We present the
first systematic ablation of LWS and its variants, on a fixed budget of 180M
parameters, trained on 5B tokens. All models converge to similar losses and
achieve better performance compared to an equal-cost isotropic baseline,
without a substantial decrease in training throughput. This work represents an
initial step into the design space of layer-wise architectures for
pre-training, but future work should scale experiments to orders of magnitude
more tokens and parameters to fully assess their potential.

</details>


### [79] [LAMDAS: LLM as an Implicit Classifier for Domain-specific Data Selection](https://arxiv.org/abs/2509.06524)
*Jian Wu,Hang Yu,Bingchang Liu,Wenjie Yang,Peng Di,Jianguo Li,Yue Zhang*

Main category: cs.CL

TL;DR: 新方法LAMDAS用LLM自身作隐式分类器，选择领域特定数据，效果优于全量数据训练及多个先进方法，在提升性能的同时大幅节省计算资源。


<details>
  <summary>Details</summary>
Motivation: 将大语言模型(LLMs)适配到特定领域时，优质人工数据稀缺成为瓶颈。直接用大量未筛查数据微调可能会引入噪声、降低性能，因此，如何高效且准确地挑选数据成为关键问题。而现有的基于相似性的方法和直接优化方法难以兼顾准确率与效率。

Method: 提出了一种新方法LAMDAS，将预训练LLM本身作为隐式分类器，无需显式特征工程或复杂优化。LAMDAS将数据选择重新表述为一类分类问题，通过小规模参考数据集确定目标领域，并筛选出“属于”该领域的候选数据。

Result: 实验显示，LAMDAS利用较少的数据即可超越用全量数据训练的效果，同时优于九种SOTA方法，并在性能与计算效率间实现了最佳平衡。

Conclusion: LAMDAS能高效、准确地选择特定领域的数据，显著提升LLM领域适配效果，在性能和计算消耗上优于当前主流方法，是领域微调数据选取的高性价比方案。

Abstract: Adapting large language models (LLMs) to specific domains often faces a
critical bottleneck: the scarcity of high-quality, human-curated data. While
large volumes of unchecked data are readily available, indiscriminately using
them for fine-tuning risks introducing noise and degrading performance.
Strategic data selection is thus crucial, requiring a method that is both
accurate and efficient. Existing approaches, categorized as similarity-based
and direct optimization methods, struggle to simultaneously achieve these
goals. In this paper, we introduce LAMDAS (LLM As an iMplicit classifier for
domain-specific DAta Selection), a novel approach that leverages the
pre-trained LLM itself as an implicit classifier, thereby bypassing explicit
feature engineering and computationally intensive optimization process. LAMDAS
reframes data selection as a one-class classification problem, identifying
candidate data that "belongs" to the target domain defined by a small reference
dataset. Extensive experimental results demonstrate that LAMDAS not only
exceeds the performance of full-data training using a fraction of the data but
also outperforms nine state-of-the-art (SOTA) baselines under various
scenarios. Furthermore, LAMDAS achieves the most compelling balance between
performance gains and computational efficiency compared to all evaluated
baselines.

</details>


### [80] [SLiNT: Structure-aware Language Model with Injection and Contrastive Training for Knowledge Graph Completion](https://arxiv.org/abs/2509.06531)
*Mengxue Yang,Chun Yang,Jiaqi Zhu,Jiafan Li,Jingqi Zhang,Yuyang Li,Ying Li*

Main category: cs.CL

TL;DR: SLiNT方法通过结构感知注入增强LLM做知识图谱连边预测，有效解决稀疏和语义歧义问题，在权威数据集上表现突出。


<details>
  <summary>Details</summary>
Motivation: 知识图谱补全需要结构和语义的结合，传统LLM在结构利用有限，面对稀疏和零样本时易出现语义歧义和结构稀疏，需增强结构感知能力。

Method: 采用模块化结构，将KG结构信息通过轻量LoRA方式注入LLM（冻结参数），包括SGNE邻域增强，DHCL对比学习，GDDI梯度解耦注入方法。

Result: 在WN18RR和FB15k-237数据集上，SLiNT相比传统嵌入式和生成式方法，取得更优或相近的结果，展现了结构增强对于大模型补全KG的效果。

Conclusion: SLiNT能够提升知识图谱链接预测的效果，在多个数据集上表现出优越或有竞争力的性能。

Abstract: Link prediction in knowledge graphs requires integrating structural
information and semantic context to infer missing entities. While large
language models offer strong generative reasoning capabilities, their limited
exploitation of structural signals often results in structural sparsity and
semantic ambiguity, especially under incomplete or zero-shot settings. To
address these challenges, we propose SLiNT (Structure-aware Language model with
Injection and coNtrastive Training), a modular framework that injects
knowledge-graph-derived structural context into a frozen LLM backbone with
lightweight LoRA-based adaptation for robust link prediction. Specifically,
Structure-Guided Neighborhood Enhancement (SGNE) retrieves pseudo-neighbors to
enrich sparse entities and mitigate missing context; Dynamic Hard Contrastive
Learning (DHCL) introduces fine-grained supervision by interpolating hard
positives and negatives to resolve entity-level ambiguity; and
Gradient-Decoupled Dual Injection (GDDI) performs token-level structure-aware
intervention while preserving the core LLM parameters. Experiments on WN18RR
and FB15k-237 show that SLiNT achieves superior or competitive performance
compared with both embedding-based and generation-based baselines,
demonstrating the effectiveness of structure-aware representation learning for
scalable knowledge graph completion.

</details>


### [81] [HAVE: Head-Adaptive Gating and ValuE Calibration for Hallucination Mitigation in Large Language Models](https://arxiv.org/abs/2509.06596)
*Xin Tong,Zhi Lin,Jingya Wang,Bo Jin*

Main category: cs.CL

TL;DR: 本文提出HAVE无参数解码框架，从注意力机制层面对大型语言模型幻觉问题进行修正，无需微调，能高效减少幻觉，并在多项测试中优于现有方法，便于实际应用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在检索增强或长上下文生成任务中经常出现幻觉现象，即使相关证据已经存在。这一问题主要源于：注意力头的重要性被视为与输入无关，以及原始注意力权重难以准确反映每个标记的真实贡献。

Method: 提出了HAVE（Head-Adaptive Gating and ValuE Calibration）无参数解码框架。该方法包含头自适应门控，实现单实例软重加权注意力头，以及价值校准，通过增强注意力引入值向量的幅度来近似写回贡献。这两个模块共同实现与模型更新对齐的标记级证据，并通过轻量的不确定性缩放策略与语言模型分布融合。HAVE无需微调，一次前向传播即可运行，适用性广泛且高效。

Result: 在多个问答基准和不同类型LLM上的实验证明，HAVE能够持续减少模型幻觉，性能优于包括DAGCD在内的强基线方法，且引入开销很小。

Conclusion: HAVE框架提高了LLM输出的可信度和可解释性，操作透明、可复现，并能轻松集成至现有主流语言模型，有助于提升真实环境下的生成可靠性。

Abstract: Large Language Models (LLMs) often produce hallucinations in
retrieval-augmented or long-context generation, even when relevant evidence is
present. This stems from two issues: head importance is treated as
input-agnostic, and raw attention weights poorly reflect each token's true
contribution. We present HAVE (Head-Adaptive Gating and ValuE Calibration), a
parameter-free decoding framework that directly addresses both challenges. HAVE
introduces head-adaptive gating, which performs instance-level soft reweighing
of attention heads, and value calibration, which augments attention with the
magnitude of value vectors to approximate write-back contribution. Together,
these modules construct token-level evidence aligned with model updates and
fuse it with the LM distribution through a lightweight uncertainty-scaled
policy. HAVE requires no finetuning and operates in a single forward pass,
making it efficient and broadly applicable. Experiments across multiple QA
benchmarks and LLM families demonstrate that HAVE consistently reduces
hallucinations and outperforms strong baselines, including DAGCD, with modest
overhead. The framework is transparent, reproducible, and readily integrates
with off-the-shelf LLMs, advancing trustworthy generation in real-world
settings.

</details>


### [82] [Guided Decoding and Its Critical Role in Retrieval-Augmented Generation](https://arxiv.org/abs/2509.06631)
*Özgür Uğur,Musa Yılmaz,Esra Şavirdi,Özay Ezerceli,Mahmut El Huseyni,Selva Taş,Reyhan Bayraktar*

Main category: cs.CL

TL;DR: 本文系统比较了三种RAG系统结构化输出方式在不同多轮对话中的表现，总结了它们的适用性和性能差异，为实际部署LLM提供有价值参考。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）在各类应用中的集成，需求朝向结构化且可靠的回应，RAG（检索增强生成）系统的一个主要挑战在于确保输出与预期格式相符，并最小化幻觉现象。

Method: 本文比较了RAG系统中的三种guided decoding方法（Outlines、XGrammar、LM Format Enforcer），并在不同多轮（0轮、1轮、2轮）提示设置下，评估它们的表现。

Result: 研究通过成功率、幻觉率和输出质量等维度，揭示了多轮交互对guided decoding方法的影响，发现了不同方法在部分情境下存在意外的性能差异。

Conclusion: 本研究加深了对RAG系统中结构化输出生成的理解，并为特定场景下RAG方法选择提供了理论和实践指导。

Abstract: The integration of Large Language Models (LLMs) into various applications has
driven the need for structured and reliable responses. A key challenge in
Retrieval-Augmented Generation (RAG) systems is ensuring that outputs align
with expected formats while minimizing hallucinations. This study examines the
role of guided decoding in RAG systems, comparing three methods, Outlines,
XGrammar, and LM Format Enforcer, across different multi-turn prompting setups
(0-turn, 1-turn, and 2-turn). By evaluating success rates, hallucination rates,
and output quality, we provide insights into their performance and
applicability. Our findings reveal how multi-turn interactions influence guided
decoding, uncovering unexpected performance variations that can inform method
selection for specific use cases. This work advances the understanding of
structured output generation in RAG systems, offering both theoretical insights
and practical guidance for LLM deployment.

</details>


### [83] [Modelling Intertextuality with N-gram Embeddings](https://arxiv.org/abs/2509.06637)
*Yi Xing*

Main category: cs.CL

TL;DR: 本研究提出一种基于嵌入平均与网络分析的文本互文性定量方法，验证了其有效性和可扩展性，并揭示了文本间的中心结构。


<details>
  <summary>Details</summary>
Motivation: 文本互文性对于文学研究至关重要，但目前定量分析手段有限，难以大规模、系统地研究文本间复杂的引用关系。该研究旨在提出一种可扩展的定量方法，弥补传统分析的不足。

Method: 提出了一种新的互文性定量模型：通过对两篇文本中所有n-gram进行嵌入表示，并对这些嵌入进行两两比较，最后取平均值作为整体互文性分数。同时结合网络分析方法，挖掘文本间的中心性与群体结构。

Result: 在四组互文性已知程度的文本中验证了方法的有效性，并在267篇多样化文本上进行了扩展性测试，展现出该方法高效且有效。网络分析揭示了文本之间的中心性和社区结构。

Conclusion: 该方法能够有效刻画和量化文本互文性关系，并具备良好的可扩展性和实际应用价值。

Abstract: Intertextuality is a central tenet in literary studies. It refers to the
intricate links between literary texts that are created by various types of
references. This paper proposes a new quantitative model of intertextuality to
enable scalable analysis and network-based insights: perform pairwise
comparisons of the embeddings of n-grams from two texts and average their
results as the overall intertextuality. Validation on four texts with known
degrees of intertextuality, alongside a scalability test on 267 diverse texts,
demonstrates the method's effectiveness and efficiency. Network analysis
further reveals centrality and community structures, affirming the approach's
success in capturing and quantifying intertextual relationships.

</details>


### [84] [Domain-Aware RAG: MoL-Enhanced RL for Efficient Training and Scalable Retrieval](https://arxiv.org/abs/2509.06650)
*Hao Lin,Peitong Xie,Jingxue Chen,Jie Lin,Qingkun Tang,Qianchun Lu*

Main category: cs.CL

TL;DR: 作者提出了融合多损失和强化学习的MoLER方法，用创新的融合策略提升RAG系统检索能力，在多个基准上取得领先效果，显著优化了领域知识检索。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG系统在粗排检索中难以兼顾领域知识学习和查询优化，导致检索效果不佳。

Method: 提出MoLER方法，包括持续预训练阶段（采用多损失权衡领域与语言能力）和基于GRPO的强化学习阶段（优化查询与文档生成），并设计了MSLF策略以降低训练计算量和提升推理可扩展性。

Result: 在基准数据集上，MoLER在检索性能上显著优于其他基线方法，证明了其优势。

Conclusion: MoLER方法有效弥补了RAG在领域检索中的知识缺口，实现了高效、可扩展与鲁棒的专业领域检索能力。

Abstract: Retrieval-Augmented Generation (RAG) systems rely heavily on the retrieval
stage, particularly the coarse-ranking process. Existing coarse-ranking
optimization approaches often struggle to balance domain-specific knowledge
learning with query enhencement, resulting in suboptimal retrieval performance.
To address this challenge, we propose MoLER, a domain-aware RAG method that
uses MoL-Enhanced Reinforcement Learning to optimize retrieval. MoLER has a
two-stage pipeline: a continual pre-training (CPT) phase using a Mixture of
Losses (MoL) to balance domain-specific knowledge with general language
capabilities, and a reinforcement learning (RL) phase leveraging Group Relative
Policy Optimization (GRPO) to optimize query and passage generation for
maximizing document recall. A key innovation is our Multi-query Single-passage
Late Fusion (MSLF) strategy, which reduces computational overhead during RL
training while maintaining scalable inference via Multi-query Multi-passage
Late Fusion (MMLF). Extensive experiments on benchmark datasets show that MoLER
achieves state-of-the-art performance, significantly outperforming baseline
methods. MoLER bridges the knowledge gap in RAG systems, enabling robust and
scalable retrieval in specialized domains.

</details>


### [85] [IntrEx: A Dataset for Modeling Engagement in Educational Conversations](https://arxiv.org/abs/2509.06652)
*Xingwei Tan,Mahathi Parvatham,Chiara Gambi,Gabriele Pergola*

Main category: cs.CL

TL;DR: 该论文构建并标注了大规模教师-学生互动兴趣度数据集，揭示微调后的小模型优于大型通用模型，并分析了影响教育对话吸引力的语言和认知因素，为教学对话系统优化提供了依据。


<details>
  <summary>Details</summary>
Motivation: 在二语习得中，学习者的参与度与动机非常重要，但在教育对话中维持学习者兴趣一直是难题。尽管先前研究探讨了什么使教育文本引人入胜，但对话中哪些语言特征能驱动参与度仍知之甚少。该研究旨在填补这一知识空白。

Method: 研究提出并构建了IntrEx数据集，这是第一个针对教师-学生互动兴趣度和预期兴趣度注释的大规模数据集。数据集建立在Teacher-Student Chatroom Corpus基础之上，进一步包含序列级别的注释，捕捉对话中的兴趣变化。研究采用了100多名二语学习者，通过类比强化学习人类反馈的比对式评分流程进行严谨注释。此外，研究评估了大语言模型（LLMs）在预测人类兴趣评分方面的能力，并分析了具体语言与认知特征的影响。

Result: 微调在兴趣评分上的7B/8B参数的开源大语言模型，其在预测人类兴趣判断中优于如GPT-4o等更大规模的专有模型，显示专业化数据集建模教学参与度的潜力。研究还发现具体性、可理解性（可读性）、学习者接收等语言和认知因素会影响对话中的参与度。

Conclusion: 在教师-学生对话的兴趣度建模方面，基于专门兴趣数据集微调的小规模LLM优于更大的通用模型。具体语言与认知特征对维持对话参与度至关重要。该研究为教育对话兴趣建模、自动对话系统优化及个性化教学提供了数据和方法基础。

Abstract: Engagement and motivation are crucial for second-language acquisition, yet
maintaining learner interest in educational conversations remains a challenge.
While prior research has explored what makes educational texts interesting,
still little is known about the linguistic features that drive engagement in
conversations. To address this gap, we introduce IntrEx, the first large
dataset annotated for interestingness and expected interestingness in
teacher-student interactions. Built upon the Teacher-Student Chatroom Corpus
(TSCC), IntrEx extends prior work by incorporating sequence-level annotations,
allowing for the study of engagement beyond isolated turns to capture how
interest evolves over extended dialogues. We employ a rigorous annotation
process with over 100 second-language learners, using a comparison-based rating
approach inspired by reinforcement learning from human feedback (RLHF) to
improve agreement. We investigate whether large language models (LLMs) can
predict human interestingness judgments. We find that LLMs (7B/8B parameters)
fine-tuned on interestingness ratings outperform larger proprietary models like
GPT-4o, demonstrating the potential for specialised datasets to model
engagement in educational settings. Finally, we analyze how linguistic and
cognitive factors, such as concreteness, comprehensibility (readability), and
uptake, influence engagement in educational dialogues.

</details>


### [86] [ParCzech4Speech: A New Speech Corpus Derived from Czech Parliamentary Data](https://arxiv.org/abs/2509.06675)
*Vladislav Stankov,Matyáš Kopp,Ondřej Bojar*

Main category: cs.CL

TL;DR: 该论文介绍了新的捷克议会演讲语音数据集ParCzech4Speech 1.0，通过优化自动对齐流程，提升了规模和准确度，为捷克语语音识别和合成等任务提供了三种灵活的数据集选择，并已在开源平台上线。


<details>
  <summary>Details</summary>
Motivation: 目前针对捷克语演讲建模的数据集有限，现有版本的数据量和对齐质量均有提升空间。作者希望通过改进数据处理管线，提供一个更大、质量更高的数据集，促进语音识别、语音合成等相关研究的开展。

Method: 将捷克议会演讲的音频与官方转录文本结合，采用WhisperX和Wav2Vec 2.0实现自动音频与文本对齐。相比前一版本，改进对齐处理流程，增强了数据量和对齐质量，并根据任务需求，分别制作了三种不同类型的数据集变体。

Result: 成功制备了包含2,695小时音频的ParCzech4Speech 1.0数据集，分为三种变体，分别适用于自动语音识别、语音合成和进一步自定义任务。数据集保留全部原始元数据，采用CC-BY开放许可，并已发布在LINDAT和Hugging Face平台。

Conclusion: ParCzech4Speech 1.0大幅提升了捷克议会演讲音频-文本数据集的规模和对齐质量，可广泛服务于多种语音建模任务，推动捷克语语音处理领域发展。

Abstract: We introduce ParCzech4Speech 1.0, a processed version of the ParCzech 4.0
corpus, targeted at speech modeling tasks with the largest variant containing
2,695 hours. We combined the sound recordings of the Czech parliamentary
speeches with the official transcripts. The recordings were processed with
WhisperX and Wav2Vec 2.0 to extract automated audio-text alignment. Our
processing pipeline improves upon the ParCzech 3.0 speech recognition version
by extracting more data with higher alignment reliability. The dataset is
offered in three flexible variants: (1) sentence-segmented for automatic speech
recognition and speech synthesis tasks with clean boundaries, (2) unsegmented
preserving original utterance flow across sentences, and (3) a raw-alignment
for further custom refinement for other possible tasks. All variants maintain
the original metadata and are released under a permissive CC-BY license. The
dataset is available in the LINDAT repository, with the sentence-segmented and
unsegmented variants additionally available on Hugging Face.

</details>


### [87] [Will Annotators Disagree? Identifying Subjectivity in Value-Laden Arguments](https://arxiv.org/abs/2509.06704)
*Amir Homayounirad,Enrico Liscio,Tong Wang,Catholijn M. Jonker,Luciano C. Siebert*

Main category: cs.CL

TL;DR: 本文提出并实证对比两种识别论据主观性的方法，发现直接识别主观性好于间接推断，损失函数的细节调整影响模型的依赖性但未提升最终性能。


<details>
  <summary>Details</summary>
Motivation: 现有将多重标注聚合为单一标签的方法会掩盖标注者分歧，尤其在主观性强的任务中。本文旨在找到识别主观性的方法，推动更细致的标注流程。

Method: 对比两种方法，一种是通过预测人类价值来推断主观性，另一种是直接识别主观性。研究还尝试结合对比损失和二元交叉熵损失的方法。

Result: 直接识别主观性的方法提升了对主观性辩论的检测性能，而损失函数的组合未显示性能提升，但能减少对标签主观性的依赖。

Conclusion: 直接识别主观性的方法能显著提升模型对主观性辩论的检测能力，相比通过价值预测间接推断主观性更为有效。将对比损失与二元交叉熵损失结合并不能提升性能，但减少了对单标签主观性的依赖。

Abstract: Aggregating multiple annotations into a single ground truth label may hide
valuable insights into annotator disagreement, particularly in tasks where
subjectivity plays a crucial role. In this work, we explore methods for
identifying subjectivity in recognizing the human values that motivate
arguments. We evaluate two main approaches: inferring subjectivity through
value prediction vs. directly identifying subjectivity. Our experiments show
that direct subjectivity identification significantly improves the model
performance of flagging subjective arguments. Furthermore, combining
contrastive loss with binary cross-entropy loss does not improve performance
but reduces the dependency on per-label subjectivity. Our proposed methods can
help identify arguments that individuals may interpret differently, fostering a
more nuanced annotation process.

</details>


### [88] [Anchoring Refusal Direction: Mitigating Safety Risks in Tuning via Projection Constraint](https://arxiv.org/abs/2509.06795)
*Yanrui Du,Fenglei Fan,Sendong Zhao,Jiawei Cao,Qika Lin,Kai He,Ting Liu,Bing Qin,Mengling Feng*

Main category: cs.CL

TL;DR: IFT虽增强了LLM能力，但损害了拒绝恶意指令的安全性。研究发现训练中的拒绝方向漂移是原因之一。ProCon方法通过投影约束和早期强约束策略，有效提升模型安全性且保持性能，为未来安全性和可解释性奠定基础。


<details>
  <summary>Details</summary>
Motivation: 尽管Instruction Fine-Tuning（IFT）可以提升大语言模型的能力，但也显著损害了模型在遇到恶意指令时的拒绝能力，带来了安全风险。针对这一问题，作者研究了影响拒绝行为的内部机制。

Method: 作者提出了一种新的ProCon方法，在训练过程中对隐藏状态在拒绝方向（r-direction）的投影引入约束损失项，并采用了早期强约束的warm-up策略和扩展数据分布来加强约束信号。

Result: 实验显示，ProCon方法能有效缓解IFT带来的安全风险，同时保持甚至超越任务性能，即使与强基线方法对比也具备更优表现。此外，ProCon稳定了训练过程中的r-direction，有助于未来可解释性安全研究。

Conclusion: ProCon方法在不损害模型能力的前提下，有效缓解了IFT带来的拒绝能力下降问题，提升了训练安全性，并为大模型内部机制的安全研究提供了新思路。

Abstract: Instruction Fine-Tuning (IFT) has been widely adopted as an effective
post-training strategy to enhance various abilities of Large Language Models
(LLMs). However, prior studies have shown that IFT can significantly compromise
LLMs' safety, particularly their ability to refuse malicious instructions,
raising significant concerns. Recent research into the internal mechanisms of
LLMs has identified the refusal direction (r-direction) in the hidden states,
which plays a pivotal role in governing refusal behavior. Building on this
insight, our study reveals that the r-direction tends to drift during training,
which we identify as one of the causes of the associated safety risks. To
mitigate such drift, our proposed ProCon method introduces a
projection-constrained loss term that regularizes the projection magnitude of
each training sample's hidden state onto the r-direction. Our initial analysis
shows that applying an appropriate constraint can effectively mitigate the
refusal direction drift and associated safety risks, but remains limited by
overall performance barriers. To overcome this barrier, informed by our
observation of early-stage sharp drift and a data-driven perspective, we
introduce a warm-up strategy that emphasizes early-stage strong constraints and
broaden the data distribution to strengthen constraint signals, leading to an
enhanced ProCon method. Experimental results under various datasets, scenarios,
and LLMs demonstrate that our method can significantly mitigate safety risks
posed by IFT while preserving task performance gains. Even compared with strong
baselines, our method consistently delivers superior overall performance.
Crucially, our analysis indicates that ProCon can contribute to stabilizing the
r-direction during training, while such an interpretability-driven exploration
of LLMs' internal mechanisms lays a solid foundation for future safety
research.

</details>


### [89] [MachineLearningLM: Continued Pretraining Language Models on Millions of Synthetic Tabular Prediction Tasks Scales In-Context ML](https://arxiv.org/abs/2509.06806)
*Haoyu Dong,Pengkun Zhang,Mingzhe Lu,Yanzhen Shen,Guolin Ke*

Main category: cs.CL

TL;DR: 该论文提出了一种持续预训练框架MachineLearningLM，将结构因果模型自动生成的多示例ML任务与随机森林树模型决策过程结合，有效提升LLM在众多领域机器学习任务中的上下文学习能力；在大量示例下准确率显著提升，并保持原有的知识和推理水平。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）虽然具备广泛的世界知识和强大的通用推理能力，但在标准机器学习任务中，无法通过纯粹的上下文学习（ICL）有效利用大量示例，无需梯度下降便很难提高表现。作者希望提升LLM在机器学习场景下的上下文学习能力，同时保留其通用知识和推理能力。

Method: 提出了MachineLearningLM——通过可移植的持续预训练框架，利用数百万个结构因果模型（SCM）自动生成ML任务，shot数高达1024。预训练流程以随机森林教师模型为指导，将树决策策略蒸馏到LLM中，从而强化其数值建模的鲁棒性。全部任务利用高效的prompt序列化，显著提升上下文窗口可容纳示例数量（提升3-6倍），批量推理通量增长至50倍。

Result: 采用Qwen-2.5-7B-Instruct、LoRA rank 8的较简设置下，MachineLearningLM在金融、物理、生物、健康等领域的分布外表格分类任务中，平均超越强基线LLM（如GPT-5-mini）约15%。展示出显著的多示例扩展规律：随着上下文示例从8增加到1024，准确率持续提升。无需任务特定训练即可达到随机森林级别准确率。综合聊天能力与推理知识保留，MMLU成绩达75.4%。

Conclusion: 通过结构因果模型扩充和树模型蒸馏，LLM能高效完成多示例上下文学习任务，在多领域任务中展现强健性能，同时不牺牲通用推理和知识应用能力。

Abstract: Large language models (LLMs) possess broad world knowledge and strong
general-purpose reasoning ability, yet they struggle to learn from many
in-context examples on standard machine learning (ML) tasks, that is, to
leverage many-shot demonstrations purely via in-context learning (ICL) without
gradient descent. We introduce MachineLearningLM, a portable
continued-pretraining framework that equips a general-purpose LLM with robust
in-context ML capability while preserving its general knowledge and reasoning
for broader chat workflows.
  Our pretraining procedure synthesizes ML tasks from millions of structural
causal models (SCMs), spanning shot counts up to 1,024. We begin with a
random-forest teacher, distilling tree-based decision strategies into the LLM
to strengthen robustness in numerical modeling. All tasks are serialized with a
token-efficient prompt, enabling 3x to 6x more examples per context window and
delivering up to 50x amortized throughput via batch inference.
  Despite a modest setup (Qwen-2.5-7B-Instruct with LoRA rank 8),
MachineLearningLM outperforms strong LLM baselines (e.g., GPT-5-mini) by an
average of about 15% on out-of-distribution tabular classification across
finance, physics, biology, and healthcare domains. It exhibits a striking
many-shot scaling law: accuracy increases monotonically as in-context
demonstrations grow from 8 to 1,024. Without any task-specific training, it
attains random-forest-level accuracy across hundreds of shots. General chat
capabilities, including knowledge and reasoning, are preserved: it achieves
75.4% on MMLU.

</details>


### [90] [MoGU V2: Toward a Higher Pareto Frontier Between Model Usability and Security](https://arxiv.org/abs/2509.06807)
*Yanrui Du,Fenglei Fan,Sendong Zhao,Jiawei Cao,Ting Liu,Bing Qin*

Main category: cs.CL

TL;DR: 本文针对大语言模型安全性与可用性的平衡难题，提出MoGU及其升级版MoGU_v2，通过更智能的路由机制和高效的层嵌入，实现了安全性提升且兼顾可用性，在多类模型和风险情况下均有出色与稳定表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在实际中越来越普及，但它们在面对恶意指令时的安全性仍是关键难题。以往提升安全性的方法往往导致模型过于保守，影响实际可用性。如何在安全性与可用性之间取得更优平衡（拓展帕累托前沿）是迫切需解决的问题。

Method: 作者提出MoGU框架，通过在层内动态路由器根据隐藏态分配权重，平衡安全优化和可用性优化模型的贡献。随后又提出改进版MoGU_v2，仅在安全特征突出的层嵌入路由器，并在路由器优化时激活骨干模块，实现更紧密的双向适配，提高效率和性能。

Result: MoGU_v2在多类LLM（包括主流LLM、端侧LLM、推理LLM等）上实现了显著、稳定的效果提升，同时具备较强的适应性。即使遇到Instruction Fine-tuning带来的新风险，也能通过简单的数据混合策略恢复安全性，兼顾任务性能。

Conclusion: MoGU_v2框架在安全性和可用性之间提供了更优折中，在多种应用场景下表现出强大和稳定的适应性，是应对现实应用中LLM安全风险的稳健、通用方案。

Abstract: As Large Language Models (LLMs) increasingly permeate human life, their
security has emerged as a critical concern, particularly their ability to
maintain harmless responses to malicious instructions. Although extensive
methods have improved LLMs' security, they often lead to conservative,
rejection-oriented responses that compromise practical usability. This presents
a key challenge: how to advance the Pareto frontier between LLMs' usability and
security, rather than necessitate a trade-off between them. To address this, we
propose the MoGU framework, in which the intra-layer router dynamically
allocates weights by sensing hidden states, thereby balancing the contributions
of security-optimized and usability-optimized variants. Despite its initial
potential, the MoGU framework faces limitations such as parameter redundancy
and performance bottlenecks. To overcome these, we further propose an improved
MoGU_v2 framework that establishes a tighter coupling between the routers and
hidden states. In MoGU_v2, routers are embedded only in layers encoding highly
classifiable security features, and backbone modules are activated during
router optimization to enable bidirectional adaptation. MoGU_V2 exhibits strong
adaptability and stable improvements across various series of LLMs, including
mainstream LLMs serving as brains in various applications, on-device LLMs
optimized for resource-constrained scenarios, and reasoning LLMs tailored for
user interpretability. Meanwhile, even facing risks introduced by Instruction
Fine-tuning, MoGU_v2 can easily restore security without compromising the task
performance gains via a simple data-mix strategy. These comprehensive
improvements highlight MoGU_V2 as a robust and versatile solution for
mitigating security risks in real-world applications.

</details>


### [91] [Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem](https://arxiv.org/abs/2509.06809)
*Valentin Quesnel,Damien Sileo*

Main category: cs.CL

TL;DR: 该论文提出了一种无需LLM和复杂定理证明器，仅依靠自动化符号推理引擎生成高质量数学推理数据的新框架，并将任务转化为可控难度的三类推理挑战。实验表明，现有LLM在复杂推理任务上表现不佳，该数据和框架为未来提升LLM推理能力提供了关键工具。


<details>
  <summary>Details</summary>
Motivation: 高质量且具逻辑一致性的数学推理数据稀缺，极大限制了大语言模型在数学领域推理能力的发展。

Method: 利用E-prover的饱和推理能力，对TPTP公理库进行推理，自动化生成逻辑严密、无误的定理数据。随后经过筛选、任务转换，转化为不同难度和类型的数学推理任务，无需人工或LLM参与。

Result: 该框架成功生成了大规模且保证正确性的数学数据集（三类推理任务）。实验显示当前的前沿LLM在结构性深层推理任务方面表现较差，展示了推理能力的短板。本文的数据和工具为进一步提升LLM推理能力提供了基础。

Conclusion: 提出了一种新的纯符号化数据生成框架，能够大规模地生成高质量、无逻辑错误的数学推理任务数据，从而为提升大语言模型的推理能力提供诊断和训练工具。

Abstract: The scarcity of high-quality, logically sound data is a critical bottleneck
for advancing the mathematical reasoning of Large Language Models (LLMs). Our
work confronts this challenge by turning decades of automated theorem proving
research into a scalable data engine. Rather than relying on error-prone LLMs
or complex proof-assistant syntax like Lean and Isabelle, our framework
leverages E-prover's saturation capabilities on the vast TPTP axiom library to
derive a massive, guaranteed-valid corpus of theorems. Our pipeline is
principled and simple: saturate axioms, filter for "interesting" theorems, and
generate tasks. With no LLMs in the loop, we eliminate factual errors by
construction. This purely symbolic data is then transformed into three
difficulty-controlled challenges: entailment verification, premise selection,
and proof reconstruction. Our zero-shot experiments on frontier models reveal a
clear weakness: performance collapses on tasks requiring deep, structural
reasoning. Our framework provides both the diagnostic tool to measure this gap
and a scalable source of symbolic training data to address it. We make the code
and data publicly available.
  https://github.com/sileod/reasoning_core
https://hf.co/datasets/reasoning-core/rc1

</details>


### [92] [A Comparative Benchmark of Large Language Models for Labelling Wind Turbine Maintenance Logs](https://arxiv.org/abs/2509.06813)
*Max Malyi,Jonathan Shek,Alasdair McDonald,Andre Biscaya*

Main category: cs.CL

TL;DR: 本文提出开源框架评估LLM对风机运维日志的自动分类能力。结果显示模型在部件识别上表现好，在运维动作分类上差异大，推荐人机协作应用以提升运维数据质量。


<details>
  <summary>Details</summary>
Motivation: 风力发电的运维对于降低能源平准化成本（LCOE）至关重要，但涡轮机维护日志的非结构化文本内容阻碍了自动化分析。本文旨在解决该问题。

Method: 提出了一个新颖且可复现的框架，用于评估大型语言模型（LLM）在分类复杂工业记录方面的表现，并将该工具开源以促进透明度和未来研究。系统性评估了多种主流专有和开源LLM模型，重点考察其可靠性、运作效率和模型校准。

Result: 评估结果量化了模型性能层级，发现部分模型在基准标准一致性和置信分数校准上表现优秀。分类准确性受任务语义模糊性影响显著——在客观部件识别任务上模型一致性较高，而在解释型运维动作分类任务上则较低。所有模型均未达到完全准确，置信校准差异较大。

Conclusion: 最有效且负责任的短期应用方式是采用“人机协作”系统，即由LLM辅助专家加速、标准化数据标注，以提升运维数据质量和后续可靠性分析。

Abstract: Effective Operation and Maintenance (O&M) is critical to reducing the
Levelised Cost of Energy (LCOE) from wind power, yet the unstructured,
free-text nature of turbine maintenance logs presents a significant barrier to
automated analysis. Our paper addresses this by presenting a novel and
reproducible framework for benchmarking Large Language Models (LLMs) on the
task of classifying these complex industrial records. To promote transparency
and encourage further research, this framework has been made publicly available
as an open-source tool. We systematically evaluate a diverse suite of
state-of-the-art proprietary and open-source LLMs, providing a foundational
assessment of their trade-offs in reliability, operational efficiency, and
model calibration. Our results quantify a clear performance hierarchy,
identifying top models that exhibit high alignment with a benchmark standard
and trustworthy, well-calibrated confidence scores. We also demonstrate that
classification performance is highly dependent on the task's semantic
ambiguity, with all models showing higher consensus on objective component
identification than on interpretive maintenance actions. Given that no model
achieves perfect accuracy and that calibration varies dramatically, we conclude
that the most effective and responsible near-term application is a
Human-in-the-Loop system, where LLMs act as a powerful assistant to accelerate
and standardise data labelling for human experts, thereby enhancing O&M data
quality and downstream reliability analysis.

</details>


### [93] [COMPACT: Common-token Optimized Model Pruning Across Channels and Tokens](https://arxiv.org/abs/2509.06836)
*Eugene Kwek,Wenpeng Yin*

Main category: cs.CL

TL;DR: COMPACT联合词表和FFN通道剪枝，兼具通用性和高效性，在多类大模型上大幅提升性能和效率，无需重新训练，部署友好。


<details>
  <summary>Details</summary>
Motivation: 现有LLM的剪枝方式要么破坏transformer结构、需定制推理代码（宽度剪枝），要么直接移除整个层级导致准确率骤降（深度剪枝），因此需要一种高效且兼容性好、部署友好的剪枝新方法。

Method: 提出COMPACT方法，通过联合精简稀有词汇（缩小embedding/unembedding）与对前馈网络(FFN)中间通道根据常用词加权激活情况进行剪枝，并与剪枝后token分布对齐，同时保留标准transformer结构，无需重新训练。

Result: 在Qwen、LLaMA、Gemma等0.5B-70B不同规模模型上，提升了剪枝后各类下游任务的性能，并极大减少了模型参数、运行所需GPU内存及推理延迟。

Conclusion: COMPACT方法在不同模型和数据集上都实现了出色的性能表现，同时大幅降低参数量、GPU内存与整体延迟。

Abstract: Making LLMs more efficient in memory, latency, and serving cost is crucial
for edge deployment, interactive applications, and sustainable inference at
scale. Pruning is a key technique toward this goal. However, prior pruning
methods are limited: width pruning often breaks the standard transformer layout
or requires custom inference code, while depth pruning removes entire layers
and can cause abrupt accuracy drops. In this work, we propose COMPACT, which
jointly (i) prunes rare vocabulary to shrink embedding/unembedding and (ii)
prunes FFN intermediate channels using common-token-weighted activations,
aligning importance with the post-pruning token distribution. COMPACT enjoys
merits of both depth and width pruning, such as: deployment-friendliness (keeps
a standard transformer architecture), scale-adaptivity (trade off vocab vs. FFN
pruning), training-free operation with competitive pruning time, and strong
memory savings alongside throughput gains. Experiments across Qwen, LLaMA, and
Gemma families (0.5B-70B) show state-of-the-art downstream task performance at
similar or higher pruning ratios, with substantial reductions in parameters,
GPU memory, and end-to-end latency.

</details>


### [94] [EPT Benchmark: Evaluation of Persian Trustworthiness in Large Language Models](https://arxiv.org/abs/2509.06838)
*Mohammad Reza Mirbagheri,Mohammad Mahdi Mirkamali,Zahra Motoshaker Arani,Ali Javeri,Amir Mahdi Sadeghzadeh,Rasool Jalili*

Main category: cs.CL

TL;DR: 提出了波斯语文化导向的LLM可信度评测指标（EPT），实测显示当前模型在安全性方面表现不佳，强调了聚焦文化与安全性的必要性，并公开了数据集。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型（LLMs）在语言任务中表现突出，但如何确保其可信度仍具有重大挑战，尤其是需要考虑道德、文化与社会价值。

Method: 提出了针对波斯语文化背景下可信度的EPT评测指标，涵盖真实、安全、公平、健壮、隐私、伦理六方面。基于自建标注数据集，采用自动LLM评测和人工评测结合的方法，对多种主流模型进行测试。

Result: 评测发现各模型在安全维度存在显著不足。研究还揭示了主流模型在波斯语伦理文化契合度上的差距及提升空间。

Conclusion: EPT评测指标可有效发现LLMs在特定文化语境下的可信不足，尤其在安全性方面亟需关注，为研发更可信、具文化责任感的AI提供了方向。

Abstract: Large Language Models (LLMs), trained on extensive datasets using advanced
deep learning architectures, have demonstrated remarkable performance across a
wide range of language tasks, becoming a cornerstone of modern AI technologies.
However, ensuring their trustworthiness remains a critical challenge, as
reliability is essential not only for accurate performance but also for
upholding ethical, cultural, and social values. Careful alignment of training
data and culturally grounded evaluation criteria are vital for developing
responsible AI systems. In this study, we introduce the EPT (Evaluation of
Persian Trustworthiness) metric, a culturally informed benchmark specifically
designed to assess the trustworthiness of LLMs across six key aspects:
truthfulness, safety, fairness, robustness, privacy, and ethical alignment. We
curated a labeled dataset and evaluated the performance of several leading
models - including ChatGPT, Claude, DeepSeek, Gemini, Grok, LLaMA, Mistral, and
Qwen - using both automated LLM-based and human assessments. Our results reveal
significant deficiencies in the safety dimension, underscoring the urgent need
for focused attention on this critical aspect of model behavior. Furthermore,
our findings offer valuable insights into the alignment of these models with
Persian ethical-cultural values and highlight critical gaps and opportunities
for advancing trustworthy and culturally responsible AI. The dataset is
publicly available at: https://github.com/Rezamirbagheri110/EPT-Benchmark.

</details>


### [95] [The Majority is not always right: RL training for solution aggregation](https://arxiv.org/abs/2509.06870)
*Wenting Zhao,Pranjal Aggarwal,Swarnadeep Saha,Asli Celikyilmaz,Jason Weston,Ilia Kulikov*

Main category: cs.CL

TL;DR: 本文提出用强化学习训练聚合器将聚合作为显式推理能力，能高效整合多模型解答，在各种基准上表现优越，且比多数投票方式更节省算力。


<details>
  <summary>Details</summary>
Motivation: 现有通过多数投票或奖励模型排名等方式对多解聚合的做法效果有限，因此需要一种更智能、高效的聚合方法来优化大型语言模型在复杂推理任务上的表现。

Method: 通过强化学习训练聚合器模型，从一组候选解中评审、整合并综合输出最终答案。训练过程中均衡使用简单和困难样本，提高模型恢复少数正确答案和多数正确答案的能力。

Result: AggLM在多个基准测试中超越了强势的规则基线和奖励模型基线，具备很强泛化能力，可以高效处理来自不同模型（甚至更强模型）的解答，同时所需token显著少于大规模解答的多数投票方法。

Conclusion: AggLM是一种将聚合作为显式推理能力进行训练的新方法，在多个基准测试上优于现有基于规则和奖励模型的聚合方法，且能更高效地处理不同来源模型的解答。

Abstract: Scaling up test-time compute, by generating multiple independent solutions
and selecting or aggregating among them, has become a central paradigm for
improving large language models (LLMs) on challenging reasoning tasks. While
most prior work relies on simple majority voting or reward model ranking to
aggregate solutions, these approaches may only yield limited benefits. In this
work, we propose to learn aggregation as an explicit reasoning skill: given a
set of candidate solutions, we train an aggregator model to review, reconcile,
and synthesize a final, correct answer using reinforcement learning from
verifiable rewards. A key ingredient is careful balancing of easy and hard
training examples, allowing the model to learn both to recover
minority-but-correct answers as well as easy majority-correct answers.
Empirically, we find our method, AggLM, outperforms both strong rule-based and
reward-model baselines, across multiple benchmarks. Furthermore, it generalizes
effectively to solutions from differing models, including stronger ones than
contained in the training data, all while requiring substantially fewer tokens
than majority voting with larger numbers of solutions.

</details>


### [96] [UNH at CheckThat! 2025: Fine-tuning Vs Prompting in Claim Extraction](https://arxiv.org/abs/2509.06883)
*Joe Wilder,Nikhil Kadapala,Benji Xu,Mohammed Alsaadi,Aiden Parsons,Mitchell Rogers,Palash Agarwal,Adam Hassick,Laura Dietz*

Main category: cs.CL

TL;DR: 分析了多种LLM方法用于社交媒体上查证主张的提取，微调FLAN-T5效果最好，但其他方法有时能提取更优质主张。


<details>
  <summary>Details</summary>
Motivation: 希望通过提示工程和in-context学习方法，从社交媒体文本中提取值得查证的主张，这对于事实核查和信息真实性判定很重要。

Method: 探索了多种提示方法，以及不同大语言模型（LLM）家族的few-shot和微调技术，涵盖了FLAN-T5等模型。

Result: 通过微调FLAN-T5模型获得了最高的METEOR分数，但有时其他方法（尽管METEOR分数较低）可以提取更高质量的主张。

Conclusion: FLAN-T5微调在评测指标上表现最佳，但多种方法之间存在权衡，高分不等同于主张质量最优。

Abstract: We participate in CheckThat! Task 2 English and explore various methods of
prompting and in-context learning, including few-shot prompting and fine-tuning
with different LLM families, with the goal of extracting check-worthy claims
from social media passages. Our best METEOR score is achieved by fine-tuning a
FLAN-T5 model. However, we observe that higher-quality claims can sometimes be
extracted using other methods, even when their METEOR scores are lower.

</details>


### [97] [mmBERT: A Modern Multilingual Encoder with Annealed Language Learning](https://arxiv.org/abs/2509.06888)
*Marc Marone,Orion Weller,William Fleshman,Eugene Yang,Dawn Lawrie,Benjamin Van Durme*

Main category: cs.CL

TL;DR: mmBERT是一款支持1800多种语言的编码器语言模型，在创新预训练策略下，显著提升了高、低资源语言的分类与检索任务效果，性能超过当前主流模型。


<details>
  <summary>Details</summary>
Motivation: 编码器模型在多语言任务的最新研究较少，尤其是针对多语种模型，希望改善低资源语言的性能并提升多语言模型的整体效果。

Method: 提出了mmBERT编码器模型，使用3万亿多语言文本进行预训练，覆盖1800多种语言。创新点包括逆掩码比例调度和逆温度采样比，并在衰减阶段加入1700多种低资源语言的数据。

Result: 即使仅在短暂的衰减阶段加入低资源语言，mmBERT在分类表现与OpenAI的o3和Google Gemini 2.5 Pro相当，并显著提高了所有语种的分类和检索任务表现。

Conclusion: mmBERT在分类和检索任务中，无论高资源还是低资源语言，均显著优于上一代模型。

Abstract: Encoder-only languages models are frequently used for a variety of standard
machine learning tasks, including classification and retrieval. However, there
has been a lack of recent research for encoder models, especially with respect
to multilingual models. We introduce mmBERT, an encoder-only language model
pretrained on 3T tokens of multilingual text in over 1800 languages. To build
mmBERT we introduce several novel elements, including an inverse mask ratio
schedule and an inverse temperature sampling ratio. We add over 1700
low-resource languages to the data mix only during the decay phase, showing
that it boosts performance dramatically and maximizes the gains from the
relatively small amount of training data. Despite only including these
low-resource languages in the short decay phase we achieve similar
classification performance to models like OpenAI's o3 and Google's Gemini 2.5
Pro. Overall, we show that mmBERT significantly outperforms the previous
generation of models on classification and retrieval tasks -- on both high and
low-resource languages.

</details>


### [98] [Proof-Carrying Numbers (PCN): A Protocol for Trustworthy Numeric Answers from LLMs via Claim Verification](https://arxiv.org/abs/2509.06902)
*Aivin V. Solatorio*

Main category: cs.CL

TL;DR: 该论文提出PCN协议，通过展示层强制机械验证每个数字，确保大模型输出的数据可以被信任；未验证数字将自动标记为不确定。


<details>
  <summary>Details</summary>
Motivation: 现有方法虽提高透明度，但无法彻底解决大模型生成虚假或错误数值的问题。需要一种系统机制，从展示层强制保障每个数字的真实。

Method: 提出Proof-Carrying Numbers（PCN）协议，将数值与结构化声明绑定，利用外部验证器按照预设策略（如精确匹配、四舍五入等）进行机械验证，并将验证与渲染过程分离，实现自动化检查。

Result: PCN协议已被形式化，证明了其在真诚令牌下的完整性、可靠性（fail-closed）与策略递增单调性。模型无关、轻量级、易集成，并可扩展至更强的密码学承诺。

Conclusion: PCN协议可以有效保障大语言模型生成的数字内容的可靠性，通过强制验证，在数值敏感场景下提升信任度。

Abstract: Large Language Models (LLMs) as stochastic systems may generate numbers that
deviate from available data, a failure known as \emph{numeric hallucination}.
Existing safeguards -- retrieval-augmented generation, citations, and
uncertainty estimation -- improve transparency but cannot guarantee fidelity:
fabricated or misquoted values may still be displayed as if correct. We propose
\textbf{Proof-Carrying Numbers (PCN)}, a presentation-layer protocol that
enforces numeric fidelity through mechanical verification. Under PCN, numeric
spans are emitted as \emph{claim-bound tokens} tied to structured claims, and a
verifier checks each token under a declared policy (e.g., exact equality,
rounding, aliases, or tolerance with qualifiers). Crucially, PCN places
verification in the \emph{renderer}, not the model: only claim-checked numbers
are marked as verified, and all others default to unverified. This separation
prevents spoofing and guarantees fail-closed behavior. We formalize PCN and
prove soundness, completeness under honest tokens, fail-closed behavior, and
monotonicity under policy refinement. PCN is lightweight and model-agnostic,
integrates seamlessly into existing applications, and can be extended with
cryptographic commitments. By enforcing verification as a mandatory step before
display, PCN establishes a simple contract for numerically sensitive settings:
\emph{trust is earned only by proof}, while the absence of a mark communicates
uncertainty.

</details>


### [99] [Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning](https://arxiv.org/abs/2509.06948)
*Liang Chen,Xueting Han,Li Shen,Jing Bai,Kam-Fai Wong*

Main category: cs.CL

TL;DR: 通过引入双层优化方法，本文实现了SFT与RL协同训练，有效提升大语言模型推理能力和训练效率，实验结果优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习（RL）在激发大语言模型（LLM）推理能力方面效果显著，但因试错特性，训练效率低。常用做法是先用监督微调（SFT）预热，再用RL调整，但这种两阶段分离方式导致两者之间难以良好协同，限制了模型总体性能。

Method: 本文提出一种新的学习推理模型方法，利用双层优化（bilevel optimization）机制，加强SFT与RL的协作：在训练中，下层通过RL训练同时接受SFT监督，上层则直接优化SFT-RL联合训练相比纯RL带来的协同增益。此方法使得SFT能够元学习，主动引导RL的优化过程。

Result: 在五个推理任务基准上进行实证评估，该方法在有效性与效率之间取得更优平衡，表现持续优于现有基线方法。

Conclusion: 通过双层优化框架，将SFT与RL训练过程深度融合，有效提升了LLM在推理任务上的表现，并缓解了RL训练效率低下的问题。

Abstract: Reinforcement learning (RL) has proven effective in incentivizing the
reasoning abilities of large language models (LLMs), but suffers from severe
efficiency challenges due to its trial-and-error nature. While the common
practice employs supervised fine-tuning (SFT) as a warm-up stage for RL, this
decoupled two-stage approach limits interaction between SFT and RL, thereby
constraining overall effectiveness. This study introduces a novel method for
learning reasoning models that employs bilevel optimization to facilitate
better cooperation between these training paradigms. By conditioning the SFT
objective on the optimal RL policy, our approach enables SFT to meta-learn how
to guide RL's optimization process. During training, the lower level performs
RL updates while simultaneously receiving SFT supervision, and the upper level
explicitly maximizes the cooperative gain-the performance advantage of joint
SFT-RL training over RL alone. Empirical evaluations on five reasoning
benchmarks demonstrate that our method consistently outperforms baselines and
achieves a better balance between effectiveness and efficiency.

</details>


### [100] [Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models](https://arxiv.org/abs/2509.06949)
*Yinjie Wang,Ling Yang,Bowen Li,Ye Tian,Ke Shen,Mengdi Wang*

Main category: cs.CL

TL;DR: TraceRL通过引入识别推理轨迹的强化学习与扩散价值模型，大幅提升DLM在数学及编码任务上的推理能力和训练稳定性。新开发的TraDo模型在数学推理上超越主流AR模型，并开放了完整的可复现框架供实际开发。


<details>
  <summary>Details</summary>
Motivation: 现有扩散语言模型虽有潜力，但在复杂推理与实际部署中采样灵活性与稳定性仍有限，亟需新的算法框架提升表现与适应性。

Method: 引入轨迹感知思想，将偏好的推理轨迹融入模型后训练，通过扩散式价值模型增强训练稳定性，并采用课程学习衍生长链推理DLM。同时支持模型灵活扩展、加速KV缓存与推理引擎。

Result: TraDo-4B-Instruct在复杂数学推理始终领先7B规模AR模型，TraDo-8B-Instruct在数学基准上相对精确率比Qwen2.5-7B-Instruct提高6.1%，比Llama3.1-8B-Instruct提高51.3%。长链推理DLM在MATH500上相对精确率提升18.1%。开放框架支持多模型、推理与RL任务。

Conclusion: 提出了一种轨迹感知的强化学习框架TraceRL，可提升扩散语言模型（DLM）在数学与编码推理任务上的表现，新模型TraDo在多个基准上超越了同规模主流自回归模型。

Abstract: We propose TraceRL, a trajectory-aware reinforcement learning framework for
diffusion language models (DLMs) that incorporates preferred inference
trajectory into post-training, and is applicable across different
architectures. Equipped with a diffusion-based value model that enhances
training stability, we demonstrate improved reasoning performance on complex
math and coding tasks. Besides, it can also be applied to adapt block-specific
models to larger blocks, which improves sampling flexibility. Employing
TraceRL, we derive a series of state-of-the-art diffusion language models,
namely TraDo. Although smaller than 7B-scale AR models, TraDo-4B-Instruct still
consistently outperforms them across complex math reasoning tasks.
TraDo-8B-Instruct achieves relative accuracy improvements of 6.1% over
Qwen2.5-7B-Instruct and 51.3% over Llama3.1-8B-Instruct on mathematical
reasoning benchmarks. Through curriculum learning, we also derive the first
long-CoT DLM, outperforming Qwen2.5-7B-Instruct on MATH500 with an 18.1%
relative accuracy gain. To facilitate reproducible research and practical
applications, we release a comprehensive open-source framework for building,
training, and deploying diffusion LLMs across diverse architectures. The
framework integrates accelerated KV-cache techniques and inference engines for
both inference and reinforcement learning, and includes implementations of
various supervised fine-tuning and RL methods for mathematics, coding, and
general tasks. Code and Models: https://github.com/Gen-Verse/dLLM-RL

</details>


### [101] [On the Same Wavelength? Evaluating Pragmatic Reasoning in Language Models across Broad Concepts](https://arxiv.org/abs/2509.06952)
*Linlu Qiu,Cedegao E. Zhang,Joshua B. Tenenbaum,Yoon Kim,Roger P. Levy*

Main category: cs.CL

TL;DR: 作者基于Wavelength沟通游戏提出了一套评估语言模型语用推理能力的框架。结果显示当前大型语言模型在理解方面接近人类表现，通过链式思考和RSA推理能提升生成效果。这为今后提升语言模型的理解和社交推理能力提供了思路。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型广泛应用于对话场景，理解模型的语用推理能力变得越来越重要这一背景下，作者希望评估语言模型在语境理解和生成上的实际表现与提升空间。

Method: 提出了一种评估框架，借鉴了沟通游戏Wavelength，通过直接和链式思考（CoT）提示，在语言理解和生成两个方面测试一系列语言模型，并探索将贝叶斯语用推理（Rational Speech Act, RSA）方法融入模型推理。

Result: 最先进的大型语言模型在语言理解任务上能够表现出接近人类的准确性，无需CoT或RSA即可与人类判断高度相关，而小模型则达不到此水平。在语言生成任务上，链式思考提示优于直接提示，而RSA方法能显著提升两者的表现。

Conclusion: 当前先进语言模型具备强劲的语用推理能力，尤其在理解方面接近人类水平；通过采用RSA等语用推理机制，模型在语言生成任务上也能取得更大提升。该工作揭示了模型的优势与不足，为未来理解模型的语言、概念与社会推理能力提供了新方向。

Abstract: Language use is shaped by pragmatics -- i.e., reasoning about communicative
goals and norms in context. As language models (LMs) are increasingly used as
conversational agents, it becomes ever more important to understand their
pragmatic reasoning abilities. We propose an evaluation framework derived from
Wavelength, a popular communication game where a speaker and a listener
communicate about a broad range of concepts in a granular manner. We study a
range of LMs on both language comprehension and language production using
direct and Chain-of-Thought (CoT) prompting, and further explore a Rational
Speech Act (RSA) approach to incorporating Bayesian pragmatic reasoning into LM
inference. We find that state-of-the-art LMs, but not smaller ones, achieve
strong performance on language comprehension, obtaining similar-to-human
accuracy and exhibiting high correlations with human judgments even without CoT
prompting or RSA. On language production, CoT can outperform direct prompting,
and using RSA provides significant improvements over both approaches. Our study
helps identify the strengths and limitations in LMs' pragmatic reasoning
abilities and demonstrates the potential for improving them with RSA, opening
up future avenues for understanding conceptual representation, language
understanding, and social reasoning in LMs and humans.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [102] [Diagonal Frobenius Number via Gomory's Relaxation and Discrepancy](https://arxiv.org/abs/2509.05629)
*Dmitry Gribanov,Dmitry Malyshev,Panos Pardalos*

Main category: cs.DM

TL;DR: 本文提出对角Frobenius数F_{diag}(A)及其推广形式F_{slack}(A)，证明其与最大子行列式Δ相关，并讨论如何高效找到可行解，核心工具为角多面体松弛与离差理论。


<details>
  <summary>Details</summary>
Motivation: 研究矩阵方程Ax=b在大于某阈值t的实数解存在条件下，是否总能找到非负整数解，以及该阈值的定量界限和可计算性。

Method: 使用Gomory角多面体松弛和离差理论工具，推导Frobenius数的界并证明主结论，同时给出算法实现方案。

Result: 证明了F_{diag}(A) = Δ + O(log k)，并根据不同的算法条件，给出了多组t的界，且都能在多项式时间找到整数解。此外，推广为F_{slack}(A)并用更一般的系统给出证明。

Conclusion: 提出并分析了矩阵的对角Frobenius数以及其推广形式，证明了其与子行列式的最大绝对值Δ之间的近似关系，并给出可行整数解的算法和复杂度结论。

Abstract: For a matrix $A \in Z^{k \times n}$ of rank $k$, the diagonal Frobenius
number $F_{\text{diag}}(A)$ is defined as the minimum $t \in Z_{\geq 1}$, such
that, for any $b \in \text{span}_{Z}(A)$, the condition \begin{equation*}
  \exists x \in R_{\geq 0}^n,\, x \geq t \cdot 1 \colon \quad b = A x
\end{equation*} implies that \begin{equation*}
  \exists z \in Z_{\geq 0}^n \colon\quad b = A z. \end{equation*}
  In this work, we show that \begin{equation*}
  F_{\text{diag}}(A) = \Delta + O(\log k), \end{equation*} where $\Delta$
denotes the maximum absolute value of $k \times k$ sub-determinants of $A$.
  From the computational complexity perspective, we show that the integer
vector $z$ can be found by a polynomial-time algorithm for some weaker values
of $t$ in the described condition. For example, we can choose $t = O( \Delta
\cdot \log k)$ or $t = \Delta + O(\sqrt{k} \cdot \log k)$. Additionally, in the
assumption that a $2^k$-time preprocessing is allowed or a base $J$ with
$|{\det A_{J}}| = \Delta$ is given, we can choose $t = \Delta + O(\log k)$.
  Finally, we define a more general notion of the diagonal Frobenius number for
slacks $F_{\text{slack}}(A)$, which is a generalization of $F_{\text{diag}}(A)$
for canonical-form systems, like $A x \leq b$. All the proofs are mainly done
with respect to $F_{\text{slack}}(A)$. The proof technique uses some properties
of the Gomory's corner polyhedron relaxation and tools from discrepancy theory.

</details>


### [103] [Degree Realization by Bipartite Cactus Graphs](https://arxiv.org/abs/2509.06194)
*Amotz Bar-Noy,Toni Bohnlein,David Peleg,Yingli Ran,Dror Rawitz*

Main category: cs.DM

TL;DR: 提出了双分仙人掌图及其子类（如桥无、核和双分子类）度序列实现的系统判别和算法，丰富了图序列可实现性理论。


<details>
  <summary>Details</summary>
Motivation: 图度序列是否可被某类图族（如双分仙人掌图）实现，是图论中的基本问题，但需要精确判定及高效算法，且目前对特定图族的可实现性描述有限。

Method: 系统化构建该类可实现性判别的方法，同时给出对应的实现算法，对仙人掌类图（尤其是双分仙人掌图）进行判别和生成的统一处理。

Result: 该文提供了双分仙人掌图可实现度序列的系统性判别方法和具体算法，同时扩展到桥无仙人掌、核仙人掌和这些图族中双分子类的度序列判别。

Conclusion: 该研究不仅丰富了关于特定图族的度序列实现理论，还提供了高效实际算法，推动相关图论问题的理论与应用发展。

Abstract: The \textsc{Degree Realization} problem with respect to a graph family
$\mathcal{F}$ is defined as follows. The input is a sequence $d$ of $n$
positive integers, and the goal is to decide whether there exists a graph $G
\in \mathcal{F}$ whose degrees correspond to $d$. The main challenges are to
provide a precise characterization of all the sequences that admit a
realization in $\mathcal{F}$ and to design efficient algorithms that construct
one of the possible realizations, if one exists.
  This paper studies the problem of realizing degree sequences by bipartite
cactus graphs (where the input is given as a single sequence, without the
bi-partition). A characterization of the sequences that have a cactus
realization is already known [28]. In this paper, we provide a systematic way
to obtain such a characterization, accompanied by a realization algorithm. This
allows us to derive a characterization for bipartite cactus graphs, and as a
byproduct, also for several other interesting sub-families of cactus graphs,
including bridge-less cactus graphs and core cactus graphs, as well as for the
bipartite sub-families of these families.

</details>


### [104] [Optimal Average Disk-Inspection via Fermat's Principle](https://arxiv.org/abs/2509.06334)
*Konstantinos Georgiou*

Main category: cs.DM

TL;DR: 本文首次严格求解了盘检查问题的平均最优代价，得到精确值3.549259…，且否定了此前关于轨迹需接触盘体的猜想。


<details>
  <summary>Details</summary>
Motivation: “盘检查”问题的最坏情况已于1957年被Isbell最优解答，而平均情况一直是悬而未决的公开问题：此前仅有启发式上界，缺乏精确分析和严格解答。该工作旨在填补这一理论空白。

Method: 采用费马最短时间原理结合新提出的离散化框架，把最优轨迹问题归约为单参数递推，并进一步化为单参数最优控制问题，通过理论证明和数值计算获得了精确结果。

Result: 确定了“盘检查”问题的精确平均最优代价，不仅给出数值结果，还证明了最优轨迹不会接触盘体，从而以数学方式解决该问题。

Conclusion: 本文精确求解了“盘检查”问题的平均最优代价，结果为3.549259…，精度达到至少六位小数。通过严格的数学分析，否定了Gluss关于轨迹必须经过圆盘的猜想。

Abstract: This work resolves the optimal average-case cost of the Disk-Inspection
problem, a variant of Bellman's 1955 lost-in-a-forest problem. In
Disk-Inspection, a mobile agent starts at the center of a unit disk and follows
a trajectory that inspects perimeter points whenever the disk does not obstruct
visibility. The worst-case cost was solved optimally in 1957 by Isbell, but the
average-case version remained open, with heuristic upper bounds proposed by
Gluss in 1961 and improved only recently.
  Our approach applies Fermat's Principle of Least Time to a recently proposed
discretization framework, showing that optimal solutions are captured by a
one-parameter family of recurrences independent of the discretization size. In
the continuum limit these recurrences give rise to a single-parameter optimal
control problem, whose trajectories coincide with limiting solutions of the
original Disk-Inspection problem. A crucial step is proving that the optimal
initial condition generates a trajectory that avoids the unit disk, thereby
validating the optics formulation and reducing the many-variable optimization
to a rigorous one-parameter problem. In particular, this disproves Gluss's
conjecture that optimal trajectories must touch the disk.
  Our analysis determines the exact optimal average-case inspection cost, equal
to $3.549259\ldots$ and certified to at least six digits of accuracy.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [105] [Scalable Learning of One-Counter Automata via State-Merging Algorithms](https://arxiv.org/abs/2509.05762)
*Shibashis Guha,Anirban Majumdar,Prince Mathew,A. V. Sreejith*

Main category: cs.FL

TL;DR: OPNI是一种高效的被动学习DROCA的新算法，结合主动学习后在扩展性与性能上均超越当前方法，并已实际实现和验证。


<details>
  <summary>Details</summary>
Motivation: 现有的确定性实时一计数器自动机学习算法在扩展性和性能方面存在局限，亟需更高效的学习方法。

Method: 基于RPNI算法思想，开发了用于确定性实时一计数器自动机的被动学习算法OPNI，并提出了OPNI与主动学习相结合的方法，进行了实验实现与对比分析。

Result: 实验结果显示，OPNI方法在扩展性和效率上优于当前最优的算法，并验证了其在学习可见一计数器自动机时的有效性。

Conclusion: 提出了一种有效的被动学习算法（OPNI），并与现有方法对比，其在DROCA学习任务上的扩展性和效率表现更优。

Abstract: We propose One-counter Positive Negative Inference (OPNI), a passive learning
algorithm for deterministic real-time one-counter automata (DROCA). Inspired by
the RPNI algorithm for regular languages, OPNI constructs a DROCA consistent
with any given valid sample set.
  We further present a method for combining OPNI with active learning of DROCA,
and provide an implementation of the approach. Our experimental results
demonstrate that this approach scales more effectively than existing
state-of-the-art algorithms. We also evaluate the performance of the proposed
approach for learning visibly one-counter automata.

</details>


### [106] [On Synthesis of Timed Regular Expressions](https://arxiv.org/abs/2509.06262)
*Ziran Wang,Jie An,Naijun Zhan,Miaomiao Zhang,Zhenya Zhang*

Main category: cs.FL

TL;DR: 本文研究如何根据正例和反例自动合成时序正则表达式。提出了可判定的合成流程，并通过SMT编码优化参数，实验显示方法高效且结果简洁。


<details>
  <summary>Details</summary>
Motivation: 时序正则表达式用于描述网络物理系统的实时行为，但对于如何根据系统表现（包括正例和反例）自动合成时序正则表达式，仍存在挑战和研究空白。本文旨在填补该空白，实现高效且一致的合成方法。

Method: 本文首先证明了时序正则表达式合成问题的可判定性。然后提出两步合成方法：第一步枚举并筛选候选参数化时序正则表达式，第二步将候选表达式与样本集合的一致性要求编码为SMT公式，通过求解确定时间参数。最后在随机生成的测试行为和实例案例上进行了方法评估。

Result: 实验结果表明，该方法能够生成长度最短、与给定正反例一致的时序正则表达式，并在多种基准集合和案例研究中取得了有效表现。

Conclusion: 本文提出的时序正则表达式合成方法能自动、高效地产生与系统行为样本一致且简洁的表达式，是针对网络物理系统实时行为建模和分析的有效工具，为后续实际应用和理论研究奠定基础。

Abstract: Timed regular expressions serve as a formalism for specifying real-time
behaviors of Cyber-Physical Systems. In this paper, we consider the synthesis
of timed regular expressions, focusing on generating a timed regular expression
consistent with a given set of system behaviors including positive and negative
examples, i.e., accepting all positive examples and rejecting all negative
examples. We first prove the decidability of the synthesis problem through an
exploration of simple timed regular expressions. Subsequently, we propose our
method of generating a consistent timed regular expression with minimal length,
which unfolds in two steps. The first step is to enumerate and prune candidate
parametric timed regular expressions. In the second step, we encode the
requirement that a candidate generated by the first step is consistent with the
given set into a Satisfiability Modulo Theories (SMT) formula, which is
consequently solved to determine a solution to parametric time constraints.
Finally, we evaluate our approach on benchmarks, including randomly generated
behaviors from target timed models and a case study.

</details>
