<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]
- [cs.SE](#cs.SE) [Total: 12]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.CL](#cs.CL) [Total: 25]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Filling the Gaps of Polarity: Implementing Dependent Data and Codata Types with Implicit Arguments](https://arxiv.org/abs/2511.15819)
*Bohdan Liesnikov,David Binder,Tim Süberkrüb*

Main category: cs.PL

TL;DR: 论文针对Polarity语言中归纳与协同类型对称支持的表达式问题，提出了完整的类型系统和隐式参数推断算法，并实现了相关原型，具有指导意义。


<details>
  <summary>Details</summary>
Motivation: 表达式问题揭示了类型扩展的两种主要方式——通过代数数据类型添加新操作和通过接口实现扩展新构造器。在依赖类型语言中，前者（归纳类型）的支持很好，而后者（协同类型）的支持较差。Polarity语言旨在对这两种类型进行对称处理，但目前缺乏可用性更强的特征，如隐式参数。

Method: 设计了一套算法类型系统和类型推断算法，支持隐式参数，且保持语言对于归纳类型和协同类型的核心对称性。具体包括详细的类型系统算法描述、统一归纳与协同类型的综合单一化算法，并给出简化语义、转换检查和模式匹配单一化的规则。

Result: 实现了一个完整的Polarity类型系统算法描述，以及归纳与协同类型的单一化算法的全面说明，目前已有初步实现可供测试。该工作为其他支持两种类型对称的依赖类型语言提供了参考蓝图。

Conclusion: 提出的算法和设计为依赖类型语言的隐式参数推断和类型扩展提供了对称、实用的基础架构，并为后续相关语言的发展奠定了理论和工程基础。

Abstract: The expression problem describes a fundamental tradeoff between two types of extensibility: extending a type with new operations, such as by pattern matching on an algebraic data type in functional programming, and extending a type with new constructors, such as by adding a new object implementing an interface in object-oriented programming. Most dependently typed languages have good support for the former style through inductive types, but support for the latter style through coinductive types is usually much poorer. Polarity is a language that treats both kinds of types symmetrically and allows the developer to switch between type representations.However, it currently lacks several features expected of a state-of-the-art dependently typed language, such as implicit arguments. The central aim of this paper is to provide an algorithmic type system and inference algorithm for implicit arguments that respect the core symmetry of the language. Our work provides two key contributions: a complete algorithmic description of the type system backing Polarity, and a comprehensive description of a unification algorithm that covers arbitrary inductive and coinductive types. We give rules for reduction semantics, conversion checking, and a unification algorithm for pattern-matching, which are essential for a usable implementation. A work-in-progress implementation of the algorithms in this paper is available at https://polarity-lang.github.io/. We expect that the comprehensive account of the unification algorithm and our design decisions can serve as a blueprint for other dependently typed languages that support inductive and coinductive types symmetrically.

</details>


### [2] [Chorex: Restartable, Language-Integrated Choreographies](https://arxiv.org/abs/2511.15820)
*Ashton Wiersdorf,Ben Greenman*

Main category: cs.PL

TL;DR: Chorex是一种将编排式容错编程带入Elixir的新语言，支持actor故障自动恢复，通过元编程实现与Elixir的紧密集成，有效提升分布式系统的鲁棒性与开发体验。


<details>
  <summary>Details</summary>
Motivation: 分布式应用开发中，容错与系统鲁棒性至关重要，但现有编排语言通常难以处理actor故障。作者期望通过Chorex，将编排式容错能力嵌入主流语言，并简化分布式系统开发。

Method: Chorex采用元编程方式在Elixir中实现编排式编程，关键技术包括：容错机制（actor崩溃时重启和状态恢复）、静态检测（以源代码层精准报错），并通过具体应用案例和性能测量加以验证。

Result: Chorex能够自动容错，支持actor重启和状态恢复，且编排与Elixir高度集成，实现了静态错误报告。实际案例及性能测试表明，Chorex的检查点机制带来的性能开销可接受，其无状态函数投影方案也可为其他语言参考。

Conclusion: Chorex成功将编排式编程引入Elixir，能容忍分布式环境下的actor故障，并通过过程恢复、状态检查点与网络更新等机制提升系统鲁棒性。同时，其基于元编程的实现方式与Elixir紧密集成，有效提升了语言兼容性和开发体验。

Abstract: We built Chorex, a language that brings choreographic programming to Elixir as a path toward robust distributed applications. Chorex is unique among choreographic languages because it tolerates failure among actors: when an actor crashes, Chorex spawns a new process, restores state using a checkpoint, and updates the network configuration for all actors. Chorex also proves that full-featured choreographies can be implemented via metaprogramming, and that doing so achieves tight integration with the host language. For example, mismatches between choreography requirements and an actor implementation are reported statically and in terms of source code rather than macro-expanded code. This paper illustrates Chorex on several examples, ranging from a higher-order bookseller to a secure remote password protocol, details its implementation, and measures the overhead of checkpointing. We conjecture that Chorex's projection strategy, which outputs sets of stateless functions, is a viable approach for other languages to support restartable actors.

</details>


### [3] [BlueScript: A Disaggregated Virtual Machine for Microcontrollers](https://arxiv.org/abs/2511.15821)
*Fumika Mochizuki,Tetsuro Yamazaki,Shigeru Chiba*

Main category: cs.PL

TL;DR: 本文提出了将虚拟机组件最大化卸载到主机的新架构BlueScript VM，并通过“影子机”等技术实现高速和交互性能。实验表明该方法比现有方案更快，并可在微控制器上实现丰富功能。


<details>
  <summary>Details</summary>
Motivation: 由于微控制器物理内存有限，传统虚拟机无法同时具备交互性和高速运行。已有的组件卸载研究受限，难以完全发挥主机特性。为提升性能和扩展功能，需更彻底的卸载设计。

Method: 设计并实现了一种分解式虚拟机结构，称为BlueScript VM，将虚拟机组件最大化卸载到主机，同时通过“影子机”数据结构减小主机与微控制器之间的通信开销，并通过实验验证方法。

Result: 卸载增量编译器后，BlueScript VM的执行速度快于MicroPython和Espruino，且交互性与MicroPython相当；卸载动态编译器后，虚拟机性能也显著提升。证明了丰富功能依然可在资源受限的微控制器上实现。

Conclusion: 证明高性能和丰富功能的虚拟机在内存受限的微控制器上是可行的，只需将大部分虚拟机组件卸载到主机上。

Abstract: Virtual machines (VMs) are highly beneficial for microcontroller development. 
In particular, interactive programming environments greatly facilitate iterative development processes, 
and higher execution speeds expand the range of applications that can be developed. 
However, due to their limited memory size, microcontroller VMs provide a limited set of features. 
Widely used VMs for microcontrollers often lack interactive responsiveness and/or high execution speed. 
While researchers have investigated offloading certain VM components to other machines,the types of components that can be offloaded are still restricted. 
In this paper, we propose a disaggregated VM that offloads as many components as possible to a host machine. 
This makes it possible to exploit the abundant memory of the host machine and its powerful processing capability to provide rich features through the VM. 
As an instance of a disaggregated VM, we design and implement a BlueScript VM. 
The BlueScript VM is a virtual machine for microcontrollers that provides an interactive development environment. 
We offload most of the components of the BlueScript VM to a host machine. 
To reduce communication overhead between the host machine and the microcontroller,  
we employed a data structure called a shadow machine on the host machine, 
which mirrors the execution state of the microcontroller. 
Through our experiments, we confirmed that offloading components does not seriously compromise their expected benefits.  
We assess that an offloaded incremental compiler results in faster execution speed than MicroPython and Espruino,  
while keeping interactivity comparable with MicroPython.  
In addition, our experiments observe that the offloaded dynamic compiler improves VM performance. 
Through this investigation, we demonstrate the feasibility of providing rich features even on VMs for memory-limited microcontrollers.

</details>


### [4] [Operon: Incremental Construction of Ragged Data via Named Dimensions](https://arxiv.org/abs/2511.16080)
*Sungbin Moon,Jiho Park,Suyoung Hwang,Donghyun Koh,Seunghyun Moon,Minhyeong Lee*

Main category: cs.PL

TL;DR: 本论文介绍了Rust实现的工作流引擎Operon，围绕命名维度和显式依赖关系处理非均匀数据，打破了现有引擎的局限。Operon可自动跟踪数据形状和依赖关系，实现高效、可扩展并行调度，支持严谨的数据持久化和恢复，比主流引擎性能提升显著，尤其适合机器学习等大规模数据生成场景。


<details>
  <summary>Details</summary>
Motivation: 现代数据处理流程常常遇到非均匀（ragged）数据，这些数据集合中的元素长度不一，广泛存在于自然语言处理、科学测量和自主AI系统等领域。现有工作流引擎缺乏对这类数据结构及其依赖关系的原生支持，导致用户不得不手动管理复杂的索引和依赖，工作量大且容易出错。

Method: 本文提出了Operon，一个基于Rust的工作流引擎，采用命名维度及显式依赖关系的新型形式化方法。Operon通过特定领域语言（DSL）让用户在创建数据处理流程时为其任务声明维度，并通过静态验证确保流程的正确性，同时系统在运行时可根据数据形状动态调度任务。此外，论文从数学角度形式化了部分数据形状的表达，为流程的增量构建算法提供理论基础，并证明其并行环境下的确定性和合流性。

Result: Operon能够显式建模部分已知的数据状态，支持高可靠的数据持久化与恢复机制，其多队列架构针对每个任务类型实现高效并行调度。实验证明，在大规模数据生成和机器学习场景下，Operon相较于现有引擎具有显著优势，如基准开销降低14.94倍，并在工作负载增加时保持近乎线性的输出速率。

Conclusion: Operon通过创新的数据形状与依赖建模和高效的并行调度，为处理非均匀数据的工作流提供了强有力的支持，尤其适用于大规模数据生成和机器学习任务。

Abstract: Modern data processing workflows frequently encounter ragged data: collections with variable-length elements that arise naturally in domains like natural language processing, scientific measurements, and autonomous AI agents. Existing workflow engines lack native support for tracking the shapes and dependencies inherent to ragged data, forcing users to manage complex indexing and dependency bookkeeping manually. We present Operon, a Rust-based workflow engine that addresses these challenges through a novel formalism of named dimensions with explicit dependency relations. Operon provides a domain-specific language where users declare pipelines with dimension annotations that are statically verified for correctness, while the runtime system dynamically schedules tasks as data shapes are incrementally discovered during execution. We formalize the mathematical foundation for reasoning about partial shapes and prove that Operon's incremental construction algorithm guarantees deterministic and confluent execution in parallel settings. The system's explicit modeling of partially-known states enables robust persistence and recovery mechanisms, while its per-task multi-queue architecture achieves efficient parallelism across heterogeneous task types. Empirical evaluation demonstrates that Operon outperforms an existing workflow engine with 14.94x baseline overhead reduction while maintaining near-linear end-to-end output rates as workloads scale, making it particularly suitable for large-scale data generation pipelines in machine learning applications.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [5] [Technique to Baseline QE Artefact Generation Aligned to Quality Metrics](https://arxiv.org/abs/2511.15733)
*Eitan Farchi,Kiran Nayak,Papia Ghosh Majumdar,Saritha Route*

Main category: cs.SE

TL;DR: 论文提出了一套结合LLM生成、逆向生成和迭代细则的QE产物评估框架，通过实验验证其在多个项目中的高效性和可靠性，为自动化产物的质量保障提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）在自动生成质量工程（QE）相关产物（如需求、测试用例和BDD场景）方面极具变革性，但其输出质量难以保证，亟需一种系统化的评估与保障方法。

Method: 提出了一种系统性技术，利用可量化评估指标对QE产物进行基线评估。该方法结合了LLM驱动生成、逆向生成以及基于评分细则的迭代改进，针对清晰性、完整性、一致性、可测性开展细致评估。

Result: 实验结果覆盖了12个项目，显示逆向生成的产物可在低质量输入下超越原始输入，并在高质量输入下维持高标准，为QE产物验证提供了高可扩展性和可靠性。

Conclusion: 该框架实现了QE产物的大规模、可靠验证，有效衔接了自动化与质量问责之间的桥梁，提升了LLM生成内容在质量工程领域的应用价值。

Abstract: Large Language Models (LLMs) are transforming Quality Engineering (QE) by automating the generation of artefacts such as requirements, test cases, and Behavior Driven Development (BDD) scenarios. However, ensuring the quality of these outputs remains a challenge. This paper presents a systematic technique to baseline and evaluate QE artefacts using quantifiable metrics. The approach combines LLM-driven generation, reverse generation , and iterative refinement guided by rubrics technique for clarity, completeness, consistency, and testability. Experimental results across 12 projects show that reverse-generated artefacts can outperform low-quality inputs and maintain high standards when inputs are strong. The framework enables scalable, reliable QE artefact validation, bridging automation with accountability.

</details>


### [6] [Rethinking Kernel Program Repair: Benchmarking and Enhancing LLMs with RGym](https://arxiv.org/abs/2511.15757)
*Kareem Shehada,Yifan Wu,Wyatt D. Feng,Adithya Iyer,Gryphon Kumfert,Yangruibo Ding,Zhiyun Qian*

Main category: cs.SE

TL;DR: 本文提出了在本地硬件可运行的Linux内核自动修复评测框架RGym，并结合新颖定位方法和GPT-5实现高达43.36%的修复通过率，修复成本显著降低，推进了内核空间自动修复发展。


<details>
  <summary>Details</summary>
Motivation: 现有的自动程序修复（APR）基准主要关注用户空间应用，忽略了内核空间调试和修复的复杂性。Linux 内核因其整体结构、并发性和底层硬件交互带来了独特挑战，现有方案在这一领域成效有限，成本高且实际效果不佳。

Method: 作者提出了RGym，一个轻量、平台无关的Linux内核APR评测框架，可在本地普通硬件上运行。基于RGym，提出了一条结合专用定位技术（例如调用栈和问题提交定位）的APR流程，旨在替代现有高成本、过于依赖oracle的方案。

Result: 在精筛验证的143个Linux内核bug上，采用GPT-5 Thinking实现的修复流程最高通过率达43.36%，单个bug的平均修复成本低于0.20美元。消融实验显示，定位策略、prompt结构和模型选择均对结果有重要影响，基于反馈的多次重试进一步提升通过率。

Conclusion: RGym框架与新型修复流程显著提高了Linux内核APR的可行性和经济性，为低成本、高效的自动程序修复提供了新路线。消融实验表明各子模块均有积极贡献。

Abstract: Large Language Models (LLMs) have revolutionized automated program repair (APR) but current benchmarks like SWE-Bench predominantly focus on userspace applications and overlook the complexities of kernel-space debugging and repair. The Linux kernel poses unique challenges due to its monolithic structure, concurrency, and low-level hardware interactions. Prior efforts such as KGym and CrashFixer have highlighted the difficulty of APR in this domain, reporting low success rates or relying on costly and complex pipelines and pricey cloud infrastructure. In this work, we introduce RGym, a lightweight, platform-agnostic APR evaluation framework for the Linux kernel designed to operate on local commodity hardware. Built on RGym, we propose a simple yet effective APR pipeline leveraging specialized localization techniques (e.g., call stacks and blamed commits) to overcome the unrealistic usage of oracles in KGym. We test on a filtered and verified dataset of 143 bugs. Our method achieves up to a 43.36% pass rate with GPT-5 Thinking while maintaining a cost of under $0.20 per bug. We further conduct an ablation study to analyze contributions from our proposed localization strategy, prompt structure, and model choice, and demonstrate that feedback-based retries can significantly enhance success rates.

</details>


### [7] [A Causal Perspective on Measuring, Explaining and Mitigating Smells in \llm-Generated Code](https://arxiv.org/abs/2511.15817)
*Alejandro Velasco,Daniel Rodriguez-Cardenas,Dipin Khati,David N. Palacio,Luftar Rahman Alif,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: 本文系统研究LLMs生成代码中代码异味产生的机制及影响因素，并提出PSC指标用于评估和缓解代码异味。结果表明prompt设计与模型架构影响显著，并可通过PSC帮助开发者判断代码质量，为质量感知型大模型应用提供实践基础。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在软件工程中的应用越来越广，但生成的代码常存在结构质量问题，如代码异味（影响可读性、可维护性或设计完整性的模式）。目前虽然有研究关注检测与修复代码异味，但关于这些问题在生成代码中如何出现及其成因仍不清楚。

Method: 本文以Propensity Smelly Score（PSC）这一用于概率估算异味类型出现可能性的度量为基础，系统性地测量、解释并缓解LLMs生成代码的异味倾向。通过PSC进行因果分析，研究生成策略、模型规模、架构和prompt设计对生成代码结构质量的影响。并通过用户研究考察PSC辅助开发者理解模型行为及评估代码质量的作用。

Result: 研究发现prompt设计和架构选择对代码异味的产生有决定性影响，并提出了实际可行的缓解策略。用户研究表明PSC能够帮助开发者更好地评估和理解生成代码质量。

Conclusion: PSC是衡量生成代码结构质量的有效信号，可辅助开发者判断代码质量。本文为在LLMs评估和部署过程中引入质量感知评测机制提供了基础。

Abstract: Recent advances in large language models (LLMs) have accelerated their adoption in software engineering contexts. However, concerns persist about the structural quality of the code they produce. In particular, LLMs often replicate poor coding practices, introducing code smells (i.e., patterns that hinder readability, maintainability, or design integrity). Although prior research has examined the detection or repair of smells, we still lack a clear understanding of how and when these issues emerge in generated code.
  This paper addresses this gap by systematically measuring, explaining and mitigating smell propensity in LLM-generated code. We build on the Propensity Smelly Score (PSC), a probabilistic metric that estimates the likelihood of generating particular smell types, and establish its robustness as a signal of structural quality. Using PSC as an instrument for causal analysis, we identify how generation strategy, model size, model architecture and prompt formulation shape the structural properties of generated code. Our findings show that prompt design and architectural choices play a decisive role in smell propensity and motivate practical mitigation strategies that reduce its occurrence. A user study further demonstrates that PSC helps developers interpret model behavior and assess code quality, providing evidence that smell propensity signals can support human judgement. Taken together, our work lays the groundwork for integrating quality-aware assessments into the evaluation and deployment of LLMs for code.

</details>


### [8] [AI-Enabled Orchestration of Event-Driven Business Processes in Workday ERP for Healthcare Enterprises](https://arxiv.org/abs/2511.15852)
*Monu Sharma*

Main category: cs.SE

TL;DR: 本文提出利用AI和事件驱动方法增强Workday云ERP在医疗场景下的自动化和智能响应能力，经实际案例验证提升了流程效率、成本透明和决策准确性，为智能ERP集成和未来医疗自动化提供参考。


<details>
  <summary>Details</summary>
Motivation: 尽管云端ERP平台如Workday革新了医疗行业的运营，将财务、供应链和人力资源整合于一体，但其传统工作流逻辑难以应对高度事件驱动和数据密集的医疗环境。现有系统缺乏足够灵活性，难以实时响应医疗运营中的突发情况。

Method: 本文提出在Workday ERP中嵌入AI驱动的事件编排框架。该框架融合了机器学习触发器、异常检测和流程挖掘分析，以预测并自动应对运营事件（如库存耗尽、付款延迟或患者需求波动）。通过多组织案例分析，评估该框架的实际应用成效。

Result: 多组织案例表明，该AI事件编排框架提升了流程效率、成本可见性和决策准确性。嵌入AI能力后，Workday的事件架构提高了运营韧性、治理能力和可扩展性。

Conclusion: 将AI能力嵌入云端ERP的事件驱动架构，能够显著优化医疗行业的运营流程和决策效率，为下一代医疗自动化集成提供了有益参考。

Abstract: The adoption of cloud-based Enterprise Resource Planning (ERP) platforms such as Workday has transformed healthcare operations by integrating financial, supply-chain, and workforce processes into a unified ecosystem. However, traditional workflow logic in ERP systems often lacks the adaptability required to manage event-driven and data-intensive healthcare environments.
  This study proposes an AI-enabled event-driven orchestration framework within Workday ERP that intelligently synchronizes financial and supply-chain workflows across distributed healthcare entities. The framework employs machine-learning triggers, anomaly detection, and process mining analytics to anticipate and automate responses to operational events such as inventory depletion, payment delays, or patient demand fluctuations. A multi-organization case analysis demonstrates measurable gains in process efficiency, cost visibility, and decision accuracy.
  Results confirm that embedding AI capabilities into Workday's event-based architecture enhances operational resilience, governance, and scalability. The proposed model contributes to the broader understanding of intelligent ERP integration and establishes a reference for next-generation automation strategies in healthcare enterprises.

</details>


### [9] [RE for AI in Practice: Managing Data Annotation Requirements for AI Autonomous Driving Systems](https://arxiv.org/abs/2511.15859)
*Hina Saeeda,Mazen Mohamad,Eric Knauss,Jennifer Horkoff,Ali Nouri*

Main category: cs.SE

TL;DR: 本研究通过行业访谈分析自动驾驶AI感知系统数据标注需求存在的主要挑战和改进实践，并首次提出有实证支持的优化建议，为AI需求工程和软件工程领域提供了重要参考。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶AI感知系统依赖高质量数据标注要求，这些要求的制定和管理尚未被充分研究，导致了实际中的不一致、安全隐患和法规风险。

Method: 采用19次半结构化访谈，调研了6家国际公司和4家科研机构，并对结果进行了主题分析。

Result: 揭示了五大主要挑战（歧义、边界案例复杂性、需求变化、不一致性、资源受限）和三类最佳实践（伦理合规、改进标注需求指南、嵌入式质量保证）；明确了需求缺陷如何影响整个AI感知系统开发流程。

Conclusion: 论文首次实证性地指导了改进数据标注需求，从而提升了数据标注质量、监管合规性和系统可靠性。推动了AI领域软件工程和需求工程的结合。

Abstract: High-quality data annotation requirements are crucial for the development of safe and reliable AI-enabled perception systems (AIePS) in autonomous driving. Although these requirements play a vital role in reducing bias and enhancing performance, their formulation and management remain underexplored, leading to inconsistencies, safety risks, and regulatory concerns. Our study investigates how annotation requirements are defined and used in practice, the challenges in ensuring their quality, practitioner-recommended improvements, and their impact on AIePS development and performance. We conducted $19$ semi-structured interviews with participants from six international companies and four research organisations. Our thematic analysis reveals five main key challenges: ambiguity, edge case complexity, evolving requirements, inconsistencies, and resource constraints and three main categories of best practices, including ensuring compliance with ethical standards, improving data annotation requirements guidelines, and embedded quality assurance for data annotation requirements. We also uncover critical interrelationships between annotation requirements, annotation practices, annotated data quality, and AIePS performance and development, showing how requirement flaws propagate through the AIePS development pipeline. To the best of our knowledge, this study is the first to offer empirically grounded guidance on improving annotation requirements, offering actionable insights to enhance annotation quality, regulatory compliance, and system reliability. It also contributes to the emerging fields of Software Engineering (SE for AI) and Requirements Engineering (RE for AI) by bridging the gap between RE and AI in a timely and much-needed manner.

</details>


### [10] [InfCode: Adversarial Iterative Refinement of Tests and Patches for Reliable Software Issue Resolution](https://arxiv.org/abs/2511.16004)
*KeFan Li,Mengfei Wang,Hengzhi Zhang,Zhichao Li,Yuan Yuan,Mu Li,Xiang Gao,Hailong Sun,Chunming Hu,Weifeng Lv*

Main category: cs.SE

TL;DR: InfCode通过多agent对抗与迭代优化，实现自动仓库级软件修复，性能超越现有方法，并已成为新的业界标杆。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型推动了软件工程自动化，但现实软件问题的自动解决依然复杂，因其需仓库级推理、准确诊断及强验证信号。目前基于agent或pipeline的方法多依赖不足的测试，容易生成表面上通过验证却未真正修复缺陷的补丁。

Method: 提出了InfCode框架，通过对抗性多agent（测试补丁生成器与代码补丁生成器之间的对抗互动）实现测试与补丁的迭代优化，同时由选择器agent甄选最优修复方案。整个过程在容器化环境中完成，支持真实的仓库级操作和验证。

Result: 在SWE-bench Lite和SWE-bench Verified基准测试上，InfCode在使用DeepSeek-V3和Claude 4.5 Sonnet等模型时，表现均超过现有强力基线方法。在SWE-bench Verified上达到79.4%的新SOTA。

Conclusion: InfCode显著提升了针对真实软件仓库问题的自动修复能力，是目前仓库级自动化问题解决的最新最强方案，并已开源。

Abstract: Large language models have advanced software engineering automation, yet resolving real-world software issues remains difficult because it requires repository-level reasoning, accurate diagnostics, and strong verification signals. Existing agent-based and pipeline-based methods often rely on insufficient tests, which can lead to patches that satisfy verification but fail to fix the underlying defect. We present InfCode, an adversarial multi-agent framework for automated repository-level issue resolution. InfCode iteratively refines both tests and patches through adversarial interaction between a Test Patch Generator and a Code Patch Generator, while a Selector agent identifies the most reliable fix. The framework runs inside a containerized environment that supports realistic repository inspection, modification, and validation. Experiments on SWE-bench Lite and SWE-bench Verified using models such as DeepSeek-V3 and Claude 4.5 Sonnet show that InfCode consistently outperforms strong baselines. It achieves 79.4% performance on SWE-bench Verified, establishing a new state-of-the-art. We have released InfCode as an open-source project at https://github.com/Tokfinity/InfCode.

</details>


### [11] [InfCode-C++: Intent-Guided Semantic Retrieval and AST-Structured Search for C++ Issue Resolution](https://arxiv.org/abs/2511.16005)
*Qingao Dong,Mengfei Wang,Hengzhi Zhang,Zhichao Li,Yuan Yuan,Mu Li,Xiang Gao,Hailong Sun,Chunming Hu,Weifeng Lv*

Main category: cs.SE

TL;DR: 本文提出了面向C++的自动化代码修复系统INFCODE-C++，利用语义检索和AST结构分析显著提升了在C++项目中的问题解决率，性能远超先前以Python为主的系统，验证了面向静态类型语言的语言感知方法的必要性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大型语言模型的代码修复系统主要针对Python，依赖词法检索和浅层代码导航，难以应对C++项目中复杂的语义和结构，导致其在C++上的效果显著下降。

Method: 提出INFCODE-C++，结合了语义代码意图检索和基于AST结构的确定性查询，能够为修复任务构建出精确且语言感知的上下文信息，实现C++大型仓库中的精确定位和健壮修复。

Result: 在MultiSWE-bench-CPP基准测试上，INFCODE-C++的修复率达到25.58%，比之前的最佳模型高出10.85个百分点，是MSWE-agent性能的两倍以上。消融和行为研究彰显了语义检索和结构分析的关键作用。

Conclusion: INFCODE-C++是首个面向C++的自主演化修复系统，为大规模、静态类型复杂生态下的LLM驱动修复研究奠定了基础，也强调了多语言软件智能体需要语言感知推理。

Abstract: Large language model (LLM) agents have recently shown strong performance on repository-level issue resolution, but existing systems are almost exclusively designed for Python and rely heavily on lexical retrieval and shallow code navigation. These approaches transfer poorly to C++ projects, where overloaded identifiers, nested namespaces, template instantiations, and deep control-flow structures make context retrieval and fault localization substantially more difficult. As a result, state-of-the-art Python-oriented agents show a drastic performance drop on the C++ subset of MultiSWE-bench. We introduce INFCODE-C++, the first C++-aware autonomous system for end-to-end issue resolution. The system combines two complementary retrieval mechanisms -- semantic code-intent retrieval and deterministic AST-structured querying -- to construct accurate, language-aware context for repair.These components enable precise localization and robust patch synthesis in large, statically typed C++ repositories. Evaluated on the \texttt{MultiSWE-bench-CPP} benchmark, INFCODE-C++ achieves a resolution rate of 25.58\%, outperforming the strongest prior agent by 10.85 percentage points and more than doubling the performance of MSWE-agent. Ablation and behavioral studies further demonstrate the critical role of semantic retrieval, structural analysis, and accurate reproduction in C++ issue resolution. INFCODE-C++ highlights the need for language-aware reasoning in multi-language software agents and establishes a foundation for future research on scalable, LLM-driven repair for complex, statically typed ecosystems.

</details>


### [12] [The Future of Development Environments with AI Foundation Models: NII Shonan Meeting 222 Report](https://arxiv.org/abs/2511.16092)
*Xing Hu,Raula Gaikovina Kula,Christoph Treude*

Main category: cs.SE

TL;DR: 本文报告了33位专家对生成式AI如何影响开发环境及人机协作模式的讨论，强调了GenAI推动IDE变革的趋势和相关挑战。


<details>
  <summary>Details</summary>
Motivation: 随着GenAI在代码生成、测试、代码审查和程序修复等任务上取得突破性进展，有必要探讨其对IDE以及开发人员工作方式的潜在影响和改变人机协作模式。

Method: 通过Shonan Meeting 222，召集了33位来自软件工程、人工智能和人机交互领域的专家进行专题讨论和交流。

Result: 专家们讨论了GenAI对IDE带来的挑战与机遇，为未来开发工具和开发流程的创新提供了前瞻性见解。

Conclusion: GenAI正在推动集成开发环境（IDE）和人机交互模式的变革，对开发流程与工具设计都将产生深远影响。

Abstract: Generative Artificial Intelligence (GenAI) models are achieving remarkable performance in various tasks, including code generation, testing, code review, and program repair. The ability to increase the level of abstraction away from writing code has the potential to change the Human-AI interaction within the integrated development environment (IDE). To explore the impact of GenAI on IDEs, 33 experts from the Software Engineering, Artificial Intelligence, and Human-Computer Interaction domains gathered to discuss challenges and opportunities at Shonan Meeting 222. This is the report

</details>


### [13] [Domain-constrained Synthesis of Inconsistent Key Aspects in Textual Vulnerability Descriptions](https://arxiv.org/abs/2511.16123)
*Linyi Han,Shidong Pan,Zhenchang Xing,Sofonias Yitagesu,Xiaowang Zhang,Zhiyong Feng,Jiamou Sun,Qing Huang*

Main category: cs.SE

TL;DR: 针对漏洞描述不一致问题，提出领域约束LLM综合框架与可视化工具Digest Labels，在准确性、效率和可用性上都有明显提升。


<details>
  <summary>Details</summary>
Motivation: 现有不同仓库中的文本漏洞描述存在关键方面不一致，影响安全分析师对漏洞的全面理解。已有方法试图通过外部知识库对齐来缓解，但常常丢失关键信息，无法综合表示。

Method: 提出一个受领域约束的基于大语言模型的综合框架。分为三阶段：1) 通过模板规则提取关键信息；2) 利用领域特定锚词进行自我评估，衡量各来源语义差异；3) 运用信息熵融合，协调不一致并突出重要细节。此外，开发Digest Labels工具用于可视化。

Result: 该框架提升了关键方面补全的F1分数从0.82到0.87；理解与效率提高超过30%。Digest Labels工具提升了可用性，经人工评估有显著效果。

Conclusion: 领域约束LLM综合框架能有效统一不同来源的漏洞描述关键内容，提升理解效率与可用性。Digest Labels进一步辅助分析工作。

Abstract: Textual Vulnerability Descriptions (TVDs) are crucial for security analysts to understand and address software vulnerabilities. However, the key aspect inconsistencies in TVDs from different repositories pose challenges for achieving a comprehensive understanding of vulnerabilities. Existing approaches aim to mitigate inconsistencies by aligning TVDs with external knowledge bases, but they often discard valuable information and fail to synthesize comprehensive representations. In this paper, we propose a domain-constrained LLM-based synthesis framework for unifying key aspects of TVDs. Our framework consists of three stages: 1) Extraction, guided by rule-based templates to ensure all critical details are captured; 2) Self-evaluation, using domain-specific anchor words to assess semantic variability across sources; and 3) Fusion, leveraging information entropy to reconcile inconsistencies and prioritize relevant details. This framework improves synthesis performance, increasing the F1 score for key aspect augmentation from 0.82 to 0.87, while enhancing comprehension and efficiency by over 30\%. We further develop Digest Labels, a practical tool for visualizing TVDs, which human evaluations show significantly boosts usability.

</details>


### [14] [Beyond Code Similarity: Benchmarking the Plausibility, Efficiency, and Complexity of LLM-Generated Smart Contracts](https://arxiv.org/abs/2511.16224)
*Francesco Salzano,Simone Scalabrino,Rocco Oliveto,Simone Scalabrino*

Main category: cs.SE

TL;DR: LLM能生成语义接近真实合约的Solidity代码，但功能正确率低，检索增强（RAG）虽提升表现，仍难直接生产部署，专家验证必不可少。


<details>
  <summary>Details</summary>
Motivation: 智能合约复杂度高，涉及gas消耗、安全性和确定性等特殊约束，目前尚缺乏针对LLM模型生成Solidity代码的全面评估，特别是功能和非功能属性。

Method: 在零样本和检索增强生成设置下，对四种主流LLM模型进行了基准测试，涵盖500个真实智能合约函数。评估指标包括代码相似度、语义嵌入、自动化测试、gas消耗分析以及认知和圈复杂度分析。

Result: LLM生成的代码语义相似度高，但功能正确率低，零样本下仅有20%-26%的代码能在测试中表现一致。生成代码结构更简单，gas消耗更低，常因省略验证逻辑。检索增强生成（RAG）能显著提升表现，功能正确率上升至45%，代码更简洁高效。

Conclusion: 语义相似无法保证功能正确，RAG可显著提升LLM生成智能合约质量，但距离可生产部署代码仍有较大差距，需要专家仔细审查和验证。

Abstract: Smart Contracts are critical components of blockchain ecosystems, with Solidity as the dominant programming language. While LLMs excel at general-purpose code generation, the unique constraints of Smart Contracts, such as gas consumption, security, and determinism, raise open questions about the reliability of LLM-generated Solidity code. Existing studies lack a comprehensive evaluation of these critical functional and non-functional properties. We benchmark four state-of-the-art models under zero-shot and retrieval-augmented generation settings across 500 real-world functions. Our multi-faceted assessment employs code similarity metrics, semantic embeddings, automated test execution, gas profiling, and cognitive and cyclomatic complexity analysis. Results show that while LLMs produce code with high semantic similarity to real contracts, their functional correctness is low: only 20% to 26% of zero-shot generations behave identically to ground-truth implementations under testing. The generated code is consistently simpler, with significantly lower complexity and gas consumption, often due to omitted validation logic. Retrieval-Augmented Generation markedly improves performance, boosting functional correctness by up to 45% and yielding more concise and efficient code. Our findings reveal a significant gap between semantic similarity and functional plausibility in LLM-generated Smart Contracts. We conclude that while RAG is a powerful enhancer, achieving robust, production-ready code generation remains a substantial challenge, necessitating careful expert validation.

</details>


### [15] [Data Annotation Quality Problems in AI-Enabled Perception System Development](https://arxiv.org/abs/2511.16410)
*Hina Saeeda,Tommy Johansson,Mazen Mohamad,Eric Knauss*

Main category: cs.SE

TL;DR: 本文通过跨组织实证研究，构建了自动驾驶AI感知系统数据标注错误的分类法，有助于供应链各环节提升数据质量和系统可靠性，为行业出台统一标准和实践指南提供支持。


<details>
  <summary>Details</summary>
Motivation: 人工智能感知系统在自动驾驶中的发展高度依赖高质量的数据标注，但标注过程极易产生错误，影响模型性能、系统安全和可靠性。业界目前缺乏关于标注错误如何在汽车供应链中产生和传播的实证洞见。

Method: 作者采用多组织案例研究，涵盖了欧洲及英国6家公司和4个研究机构，通过19次半结构化访谈（20名专家，50小时访谈记录）以及六阶段主题分析方法，归纳整理标注错误类型。

Result: 研究归纳了18种常见的标注错误类型，涵盖完整性、准确性和一致性三大数据质量维度，并通过与行业实践者的验证确认该分类法在根源分析、供应商质量审核、人才培训及改进标注指南方面具有实用价值。

Conclusion: 该研究将数据标注质量视为生命周期和供应链问题，提出了统一的术语、诊断工具和可操作建议，为建立更可信赖的AI感知系统提供了理论和实践支持。

Abstract: Data annotation is essential but highly error-prone in the development of AI-enabled perception systems (AIePS) for automated driving, and its quality directly influences model performance, safety, and reliability. However, the industry lacks empirical insights into how annotation errors emerge and spread across the multi-organisational automotive supply chain. This study addresses this gap through a multi-organisation case study involving six companies and four research institutes across Europe and the UK. Based on 19 semi-structured interviews with 20 experts (50 hours of transcripts) and a six-phase thematic analysis, we develop a taxonomy of 18 recurring annotation error types across three data-quality dimensions: completeness (e.g., attribute omission, missing feedback loops, edge-case omissions, selection bias), accuracy (e.g., mislabelling, bounding-box inaccuracies, granularity mismatches, bias-driven errors), and consistency (e.g., inter-annotator disagreement, ambiguous instructions, misaligned hand-offs, cross-modality inconsistencies). The taxonomy was validated with industry practitioners, who reported its usefulness for root-cause analysis, supplier quality reviews, onboarding, and improving annotation guidelines. They described it as a failure-mode catalogue similar to FMEA. By conceptualising annotation quality as a lifecycle and supply-chain issue, this study contributes to SE4AI by offering a shared vocabulary, diagnostic toolset, and actionable guidance for building trustworthy AI-enabled perception systems.

</details>


### [16] [Green Resilience of Cyber-Physical Systems: Doctoral Dissertation](https://arxiv.org/abs/2511.16593)
*Diaeddin Rimawi*

Main category: cs.SE

TL;DR: 本文针对协作型在线AI系统在遭遇干扰时的韧性与绿色性能权衡问题，提出GResilience框架和多种决策策略。实验证明，所提方法有效提升了系统韧性并优化能耗表现，强化学习策略效果最佳，但需注意CO2排放的权衡。


<details>
  <summary>Details</summary>
Motivation: 在线协作AI系统（OL-CAIS）在与人类协作学习以达成共同目标的过程中，容易受到干扰事件影响，导致性能下降。决策者需在恢复性能和降低能耗间做权衡，因此需要研究如何平衡系统的韧性（resilience）与绿色性能（greenness）。

Method: 建立OL-CAIS的三种运行状态模型（稳定、干扰、终态）；提出GResilience框架，通过多目标优化（单智能体）、博弈论决策（双智能体）及强化学习（RL-智能体）策略为系统恢复提供决策；设计度量体系定量分析韧性和绿色性能；通过真实与模拟场景下的协作机器人实验进行验证。

Result: GResilience策略改善了系统的绿色恢复能力，缩短恢复时间、提升性能稳定性、减少对人的依赖。强化学习策略表现最优，但CO2排放略有增加。多次干扰后出现灾难性遗忘现象，所提政策可一定程度维持系统稳定。对比容器化执行，容器化能使CO2排放减半。

Conclusion: 本文提出了兼顾韧性与绿色性能的模型、度量方法和恢复策略，为OL-CAIS绿色恢复提供了理论与实证支持。

Abstract: Cyber-physical systems (CPS) combine computational and physical components. Online Collaborative AI System (OL-CAIS) is a type of CPS that learn online in collaboration with humans to achieve a common goal, which makes it vulnerable to disruptive events that degrade performance. Decision-makers must therefore restore performance while limiting energy impact, creating a trade-off between resilience and greenness. This research addresses how to balance these two properties in OL-CAIS. It aims to model resilience for automatic state detection, develop agent-based policies that optimize the greenness-resilience trade-off, and understand catastrophic forgetting to maintain performance consistency. We model OL-CAIS behavior through three operational states: steady, disruptive, and final. To support recovery during disruptions, we introduce the GResilience framework, which provides recovery strategies through multi-objective optimization (one-agent), game-theoretic decision-making (two-agent), and reinforcement learning (RL-agent). We also design a measurement framework to quantify resilience and greenness. Empirical evaluation uses real and simulated experiments with a collaborative robot learning object classification from human demonstrations. Results show that the resilience model captures performance transitions during disruptions, and that GResilience policies improve green recovery by shortening recovery time, stabilizing performance, and reducing human dependency. RL-agent policies achieve the strongest results, although with a marginal increase in CO2 emissions. We also observe catastrophic forgetting after repeated disruptions, while our policies help maintain steadiness. A comparison with containerized execution shows that containerization cuts CO2 emissions by half. Overall, this research provides models, metrics, and policies that ensure the green recovery of OL-CAIS.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [17] [Synthesis of Safety Specifications for Probabilistic Systems](https://arxiv.org/abs/2511.16579)
*Gaspard Ohlmann,Edwin Hamel-De le Court,Francesco Belardinelli*

Main category: cs.LO

TL;DR: 本论文提出了面向safe-PCTL片段的规范合成理论框架和基于值迭代的新方法，实现了对更广泛时序属性的表达和控制器设计，并严格证明了算法的有效性。


<details>
  <summary>Details</summary>
Motivation: 在安全关键环境下，确保智能体满足安全规范至关重要。然而，现有方法多将安全时序规范限制于概率避免约束，缺乏对更通用时序属性的支持。因此，论文动机是在概率系统中引入更具表现力的安全规范表达方法。

Method: 提出了一个新的理论框架来实现safe-PCTL规范的综合，包括将全局规范满足性归约为局部约束，并定义了CPCTL（一种safe-PCTL片段）；随后，提出了一种基于值迭代（Value Iteration）的算法，用于解决这些更一般的时序属性的综合问题，并证明了其完备性与可靠性。

Result: 理论上提出了CPCTL片段，证明了其在安全规范综合问题中的相关性，并且提出的算法能够解决广义时序属性的规范合成，且方法具备理论上的可靠性与完备性。

Conclusion: 本研究为概率系统中更广泛时序安全属性的规范合成问题，提供了新的理论与算法支持，拓展了现有方法的表达能力和适用范围。通过CPCTL定义及值迭代算法，证明了对安全-时序规范合成问题的有效性与严谨性。

Abstract: Ensuring that agents satisfy safety specifications can be crucial in safety-critical environments. While methods exist for controller synthesis with safe temporal specifications, most existing methods restrict safe temporal specifications to probabilistic-avoidance constraints. Formal methods typically offer more expressive ways to express safety in probabilistic systems, such as Probabilistic Computation Tree Logic (PCTL) formulas. Thus, in this paper, we develop a new approach that supports more general temporal properties expressed in PCTL. Our contribution is twofold. First, we develop a theoretical framework for the Synthesis of safe-PCTL specifications. We show how the reducing global specification satisfaction to local constraints, and define CPCTL, a fragment of safe-PCTL. We demonstrate how the expressiveness of CPCTL makes it a relevant fragment for the Synthesis Problem. Second, we leverage these results and propose a new Value Iteration-based algorithm to solve the synthesis problem for these more general temporal properties, and we prove the soundness and completeness of our method.

</details>


### [18] [Faster Certified Symmetry Breaking Using Orders With Auxiliary Variables](https://arxiv.org/abs/2511.16637)
*Markus Anders,Bart Bogaerts,Benjamin Bogø,Arthur Gontier,Wietze Koops,Ciaran McCreesh,Magnus O. Myreen,Jakob Nordström,Andy Oertel,Adrian Rebola-Pardo,Yong Kiam Tan*

Main category: cs.LO

TL;DR: 本文提出用辅助变量编码有序关系，高效地将对称性推理纳入可验证证明体系，经理论和实验验证后在复杂SAT问题上大幅提升了对称断言证明与检查效率。


<details>
  <summary>Details</summary>
Motivation: 对称性破缺是组合优化求解中的重要技巧，但保证其实现正确性非常困难。现有主流做法是让解算器有能力产生可验证的证明，从而确保其输出的可信性。然而，如何高效地将对称性推理纳入证明体系成为难题。此前提出的一种通用方法在处理大规模对称性时效率低下。

Method: 提出了一种用辅助变量编码有序关系的方法，而不是传统的基于大整数的字典序编码。这种方法更适合大规模对称性问题。通过在最先进的 satsuma symmetry breaker 和 VeriPB 证明检查工具链上，对 SAT 对称破缺进行证明日志记录与验证试验。

Result: 理论与实验均显示，辅助变量编码法能带来数量级的速度提升，大规模对称断言的证明生成与验证效率显著提高。

Conclusion: 辅助变量编码为证明体系中的对称破缺提供了高效可扩展的新方法，显著缓解了此前通用方法的效率瓶颈，有助于推动可认证求解器的实用化。

Abstract: Symmetry breaking is a crucial technique in modern combinatorial solving, but it is difficult to be sure it is implemented correctly. The most successful approach to deal with bugs is to make solvers certifying, so that they output not just a solution, but also a mathematical proof of correctness in a standard format, which can then be checked by a formally verified checker. This requires justifying symmetry reasoning within the proof, but developing efficient methods for this has remained a long-standing open challenge. A fully general approach was recently proposed by Bogaerts et al. (2023), but it relies on encoding lexicographic orders with big integers, which quickly becomes infeasible for large symmetries. In this work, we develop a method for instead encoding orders with auxiliary variables. We show that this leads to orders-of-magnitude speed-ups in both theory and practice by running experiments on proof logging and checking for SAT symmetry breaking using the state-of-the-art satsuma symmetry breaker and the VeriPB proof checking toolchain.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [19] [What Really Counts? Examining Step and Token Level Attribution in Multilingual CoT Reasoning](https://arxiv.org/abs/2511.15886)
*Jeremias Ferrao,Ezgi Basar,Khondoker Ittehadul Islam,Mahrokh Hassani*

Main category: cs.CL

TL;DR: 本文分析了多语言LLM在Chain-of-Thought推理时的归因机制，发现现有CoT提示存在跨语言表现不均、容易受扰动影响、以及结果解释性不足等问题，对后续多语言推理及可解释性研究具有启示意义。


<details>
  <summary>Details</summary>
Motivation: 前人研究发现Chain-of-Thought (CoT)提示有助于提升大模型在任务上的表现，但关于其推理链条的真实性及可解释性仍存在担忧，因此作者希望系统分析多语言环境下CoT推理的归因表现。

Method: 作者采用了两个归因方法：ContextCite（用于推理步骤级别归因）和Inseq（用于词元级别归因），并在Qwen2.5 1.5B-Instruct大模型及MGSM多语言推理基准上进行实验。

Result: 核心结果包括：（1）归因分数在错误推理时过度强调最终一步；（2）结构化CoT提示主要提升高资源拉丁字母语言的准确性；（3）通过否定和干扰句的有控扰动会降低模型准确性和归因一致性。

Conclusion: CoT提示在提升多语言模型推理能力方面有限，尤其是在多语种健壮性和推理解释透明性方面存在不足。

Abstract: This study investigates the attribution patterns underlying Chain-of-Thought (CoT) reasoning in multilingual LLMs. While prior works demonstrate the role of CoT prompting in improving task performance, there are concerns regarding the faithfulness and interpretability of the generated reasoning chains. To assess these properties across languages, we applied two complementary attribution methods--ContextCite for step-level attribution and Inseq for token-level attribution--to the Qwen2.5 1.5B-Instruct model using the MGSM benchmark. Our experimental results highlight key findings such as: (1) attribution scores excessively emphasize the final reasoning step, particularly in incorrect generations; (2) structured CoT prompting significantly improves accuracy primarily for high-resource Latin-script languages; and (3) controlled perturbations via negation and distractor sentences reduce model accuracy and attribution coherence. These findings highlight the limitations of CoT prompting, particularly in terms of multilingual robustness and interpretive transparency.

</details>


### [20] [Mind the Motions: Benchmarking Theory-of-Mind in Everyday Body Language](https://arxiv.org/abs/2511.15887)
*Seungbeen Lee,Jinhong Jeong,Donghyun Kim,Yejin Son,Youngjae Yu*

Main category: cs.CL

TL;DR: 该论文提出了Motion2Mind框架和新数据集，用于评估AI解读非言语交流线索（如肢体语言）推理心理状态的能力。结果显示，现有AI在这一任务上明显落后于人类，尤其是在检测准确率和解释合理性方面。


<details>
  <summary>Details</summary>
Motivation: 现有的理论心智(ToM)评测指标主要关注于错误信念任务和非对称信息推理，忽略了信念以外的其他心理状态以及丰富的人类非言语沟通。因此，亟需一个衡量AI解读非言语线索能力的新框架。

Method: 提出了Motion2Mind框架，通过专家编撰的肢体语言参考资料建立知识库，构建了包含精细化非言语线索标注和心理解释的视频数据集。该数据集包括222类非言语线索和397种心理状态。

Result: 通过该框架评估发现，当前AI在NVC解释方面的能力远不及人类，特别是在检测任务存在显著性能差距，同时在解释任务中有过度解读现象。

Conclusion: 现有的AI系统在解释非言语线索（NVC）时存在明显不足，相较于人类，AI在检测任务上的表现较差，并且在解释任务中有过度解读的模式。

Abstract: Our ability to interpret others' mental states through nonverbal cues (NVCs) is fundamental to our survival and social cohesion. While existing Theory of Mind (ToM) benchmarks have primarily focused on false-belief tasks and reasoning with asymmetric information, they overlook other mental states beyond belief and the rich tapestry of human nonverbal communication. We present Motion2Mind, a framework for evaluating the ToM capabilities of machines in interpreting NVCs. Leveraging an expert-curated body-language reference as a proxy knowledge base, we build Motion2Mind, a carefully curated video dataset with fine-grained nonverbal cue annotations paired with manually verified psychological interpretations. It encompasses 222 types of nonverbal cues and 397 mind states. Our evaluation reveals that current AI systems struggle significantly with NVC interpretation, exhibiting not only a substantial performance gap in Detection, as well as patterns of over-interpretation in Explanation compared to human annotators.

</details>


### [21] [TOD-ProcBench: Benchmarking Complex Instruction-Following in Task-Oriented Dialogues](https://arxiv.org/abs/2511.15976)
*Sarik Ghazarian,Abhinav Gullapalli,Swair Shah,Anurag Beniwal,Nanyun Peng,Narayanan Sadagopan,Zhou Yu*

Main category: cs.CL

TL;DR: 本文提出TOD-ProcBench，一个用于评测LLMs复杂自然语任务指令执行及合规能力的新基准。包含三项任务，系统分析模型在检索、生成和合规性上的能力，发现多语言和指令格式影响模型表现。数据和工具已开放发布。


<details>
  <summary>Details</summary>
Motivation: 现有的任务型对话系统基准往往过度简化任务指令，只用意图、槽位和API调用来描述，无法真实反映复杂指令执行能力。实际应用中，智能体需要准确遵循复杂、多层次的自然语言指令。本文希望系统性评测大语言模型（LLMs）在遵循复杂指令的能力。

Method: 提出了TOD-ProcBench，一个包含复杂多层次指令集的新任务型对话基准。数据集源自高质量ABCD数据集，并经人工质量控制。将指令细分为条件-动作形式的多层语句。设计三项任务，分别评估LLMs在指令检索与行动预测、识别违指令响应，以及基于复杂指令的条件响应生成能力。同时研究多语言和不同指令格式对模型遵循能力的影响。

Result: TOD-ProcBench能够系统性评价LLMs在多轮对话中遵循复杂指令的能力。通过三项任务有效揭示了模型在检索、生成、合规性方面的表现差异，并发现语言和指令书写格式对模型合规性有显著影响。数据集和基准都已开放发布。

Conclusion: TOD-ProcBench填补了任务型对话领域复杂自然语言指令遵循能力评测的空白，有助于推动高精度任务型LLM对话系统发展。

Abstract: In real-world task-oriented dialogue (TOD) settings, agents are required to strictly adhere to complex instructions while conducting multi-turn conversations with customers. These instructions are typically presented in natural language format and include general guidelines and step-by-step procedures with complex constraints. Existing TOD benchmarks often oversimplify the complex nature of these instructions by reducing them to simple schemas composed of intents, slots, and API call configurations. To address this gap and systematically benchmark LLMs' instruction-following capabilities, we propose TOD-ProcBench, a challenging benchmark featuring complex process instructions with intricate, fine-grained constraints that evaluates various LLMs' abilities to understand and follow instructions in multi-turn TODs. Our benchmark dataset comprises instruction documents derived from the high-quality ABCD dataset with corresponding conversations under human quality control. We formulate fine-grained constraints and action procedures as multi-level condition-action instruction statements. We design three tasks to comprehensively benchmark LLMs' complex instruction-following capabilities in multi-turn TODs. Task 1 evaluates how LLMs retrieve the most relevant statement from a complex instruction and predict the corresponding next action. In Task 2, we synthesize instruction-violating responses by injecting inconsistencies and manipulating the original instructions, and then we analyze how effectively LLMs can identify instruction-violating responses. Task 3 investigates LLMs' abilities in conditional generation of instruction-following responses based on the original complex instructions. Additionally, we conduct studies on the impact of multilingual settings and different instruction text formats on compliance performance. We release our benchmark under the Llama 3.3 Community License Agreement.

</details>


### [22] [Liars' Bench: Evaluating Lie Detectors for Language Models](https://arxiv.org/abs/2511.16035)
*Kieron Kretschmar,Walter Laurito,Sharan Maiya,Samuel Marks*

Main category: cs.CL

TL;DR: 本文提出LIARS' BENCH谎言检测测试平台，涵盖多类型谎言，并实证发现现有检测方法在部分场景中效果有限，从而推动谎言检测研究进展。


<details>
  <summary>Details</summary>
Motivation: 现有关于大语言模型撒谎（即生成其认为是错误的陈述）的检测技术，验证范围狭窄，无法覆盖模型能生成的各种谎言类型。缺乏综合性测试平台验证这些检测方法的有效性。

Method: 作者提出了LIARS' BENCH，这是一个包含72863个谎言与真实回答的测试库，由四个开源权重模型在七个数据集上生成，设计涵盖谎言类型及动机和对象两个维度。按这一平台对三种黑箱和白箱谎言检测技术进行评估。

Result: 实验发现，现有检测方法在某些谎言类型上会系统性地失效，特别是无法仅通过对话内容判断模型是否撒谎的设置中表现较差。

Conclusion: LIARS' BENCH 揭示了现有谎言检测技术的不足，为该领域的进步与方法评估提供了实用基准和测试平台。

Abstract: Prior work has introduced techniques for detecting when large language models (LLMs) lie, that is, generating statements they believe are false. However, these techniques are typically validated in narrow settings that do not capture the diverse lies LLMs can generate. We introduce LIARS' BENCH, a testbed consisting of 72,863 examples of lies and honest responses generated by four open-weight models across seven datasets. Our settings capture qualitatively different types of lies and vary along two dimensions: the model's reason for lying and the object of belief targeted by the lie. Evaluating three black- and white-box lie detection techniques on LIARS' BENCH, we find that existing techniques systematically fail to identify certain types of lies, especially in settings where it's not possible to determine whether the model lied from the transcript alone. Overall, LIARS' BENCH reveals limitations in prior techniques and provides a practical testbed for guiding progress in lie detection.

</details>


### [23] [Learning Tractable Distributions Of Language Model Continuations](https://arxiv.org/abs/2511.16054)
*Gwen Yidou-Weng,Ian Li,Anji Liu,Oliver Broadrick,Guy Van den Broeck,Benjie Wang*

Main category: cs.CL

TL;DR: LTLA是一种融合语言模型和HMM的高效受控文本生成方法，能更好地处理语境和约束，提升生成质量且推理开销低。


<details>
  <summary>Details</summary>
Motivation: 现有的受控文本生成方法需要在序列级约束（如句法、风格或安全性）下生成文本，而这些约束可能依赖未来的token，直接对自回归语言模型施加约束难以实现。以往的方法通常采用隐马尔可夫模型（HMM）等可处理的替代方式，但这类方法的上下文感知能力较差，导致生成文本质量下降。

Method: 提出了Learning to Look Ahead (LTLA)混合方法，将基础语言模型用于丰富的前缀编码，与一个固定且可处理的代理模型（如HMM）结合，计算精确的续写概率。LTLA通过批量化的HMM更新，一次性处理所有候选token，且只将代理模型的隐状态先验与语言模型的隐藏表示联系起来，而保持代理模型解码器不变，达到了高效计算和前缀间复用。

Result: LTLA在受约束生成任务中提升了条件似然性，比无条件HMM更好地逼近续写分布。对于视觉-语言模型，LTLA能够实现HMM无法编码的视觉上下文，在保持流畅性的同时提升约束满足度，并且推理开销极小。

Conclusion: LTLA克服了现有受控生成方法的上下文感知不足和效率低下的问题，实现了高效且高质量的受控文本生成。

Abstract: Controlled language generation conditions text on sequence-level constraints (for example, syntax, style, or safety). These constraints may depend on future tokens, which makes directly conditioning an autoregressive language model (LM) generally intractable. Prior work uses tractable surrogates such as hidden Markov models (HMMs) to approximate the distribution over continuations and adjust the model's next-token logits at decoding time. However, we find that these surrogates are often weakly context aware, which reduces query quality. We propose Learning to Look Ahead (LTLA), a hybrid approach that pairs the same base language model for rich prefix encoding with a fixed tractable surrogate model that computes exact continuation probabilities. Two efficiency pitfalls arise when adding neural context: (i) naively rescoring the prefix with every candidate next token requires a sweep over the entire vocabulary at each step, and (ii) predicting fresh surrogate parameters for each prefix, although tractable at a single step, forces recomputation of future probabilities for every new prefix and eliminates reuse. LTLA avoids both by using a single batched HMM update to account for all next-token candidates at once, and by conditioning only the surrogate's latent state prior on the LM's hidden representations while keeping the surrogate decoder fixed, so computations can be reused across prefixes. Empirically, LTLA attains higher conditional likelihood than an unconditional HMM, approximates continuation distributions for vision-language models where a standalone HMM cannot encode visual context, and improves constraint satisfaction at comparable fluency on controlled-generation tasks, with minimal inference overhead.

</details>


### [24] [Early science acceleration experiments with GPT-5](https://arxiv.org/abs/2511.16072)
*Sébastien Bubeck,Christian Coester,Ronen Eldan,Timothy Gowers,Yin Tat Lee,Alexandru Lupsasca,Mehtaab Sawhney,Robert Scherrer,Mark Sellke,Brian K. Spears,Derya Unutmaz,Kevin Weil,Steven Yin,Nikita Zhivotovskiy*

Main category: cs.CL

TL;DR: 本文通过多个案例展示了GPT-5如何加速科学研究，并实际促进了诸如数学等领域的新成果，同时强调了AI与人类专家协作的必要性与意义。


<details>
  <summary>Details</summary>
Motivation: 科学界已有AI工具，但许多研究人员对最前沿AI的实际应用和效能并不熟悉，本文旨在展示并验证这些AI工具如何为科学研究提供支持和促进。

Method: 通过多学科的实地案例研究，记录人类科学家与GPT-5在研究过程中的具体互动，并对AI产出的数学新结果进行人工核查。

Result: GPT-5成功推动了数学、物理、天文、计算机、生物和材料科学等领域的研究进展，产生并核实了4项新的数学结论，同时也分析了AI加速研究的场景与短板。

Conclusion: GPT-5等先进AI模型已能够在多个科学领域，与人类专家合作推动实际研究，并取得一定成果，特别是在数学领域已帮助解决了一些之前未解的问题。虽然AI在促进科学研究方面非常有潜力，但人类的专业知识和审查仍然不可或缺。

Abstract: AI models like GPT-5 are an increasingly valuable tool for scientists, but many remain unaware of the capabilities of frontier AI. We present a collection of short case studies in which GPT-5 produced new, concrete steps in ongoing research across mathematics, physics, astronomy, computer science, biology, and materials science. In these examples, the authors highlight how AI accelerated their work, and where it fell short; where expert time was saved, and where human input was still key. We document the interactions of the human authors with GPT-5, as guiding examples of fruitful collaboration with AI. Of note, this paper includes four new results in mathematics (carefully verified by the human authors), underscoring how GPT-5 can help human mathematicians settle previously unsolved problems. These contributions are modest in scope but profound in implication, given the rate at which frontier AI is progressing.

</details>


### [25] [ELPO: Ensemble Learning Based Prompt Optimization for Large Language Models](https://arxiv.org/abs/2511.16122)
*Qing Zhang,Bing Xu,Xudong Zhang,Yifan Shi,Yang Li,Chen Zhang,Yik Chung Wu,Ngai Wong,Yijie Chen,Hong Dai,Xiansen Chen,Mian Zhang*

Main category: cs.CL

TL;DR: 手动提示工程繁琐，限制了大模型实际应用。本文提出ELPO框架，融合多种算法与投票机制以自动优化提示，显著提升了各项任务表现，改善了方法的泛化与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）的卓越表现高度依赖于精心设计的提示（prompts），而手动编写提示是一个耗时且繁琐的过程，成为实际应用中的核心瓶颈，促发了自动化提示优化（APO）领域的快速发展。现有方法多针对单一模型或算法，难以应对复杂任务。

Method: 提出一种基于集成学习的提示优化框架（ELPO），通过投票机制和共享生成策略结合多种搜索方法进行提示优化，并设计高效的生成与搜索算法。

Result: ELPO在多项任务上均优于当前最先进的提示优化方法，例如在ArSarcasm数据集上的F1分数提升了7.6。

Conclusion: 基于集成学习的ELPO框架能够实现更准确、鲁棒的自动提示优化，打破了现有方法在复杂任务上的性能瓶颈。

Abstract: The remarkable performance of Large Language Models (LLMs) highly relies on crafted prompts. However, manual prompt engineering is a laborious process, creating a core bottleneck for practical application of LLMs. This phenomenon has led to the emergence of a new research area known as Automatic Prompt Optimization (APO), which develops rapidly in recent years. Existing APO methods such as those based on evolutionary algorithms or trial-and-error approaches realize an efficient and accurate prompt optimization to some extent. However, those researches focus on a single model or algorithm for the generation strategy and optimization process, which limits their performance when handling complex tasks. To address this, we propose a novel framework called Ensemble Learning based Prompt Optimization (ELPO) to achieve more accurate and robust results. Motivated by the idea of ensemble learning, ELPO conducts voting mechanism and introduces shared generation strategies along with different search methods for searching superior prompts. Moreover, ELPO creatively presents more efficient algorithms for the prompt generation and search process. Experimental results demonstrate that ELPO outperforms state-of-the-art prompt optimization methods across different tasks, e.g., improving F1 score by 7.6 on ArSarcasm dataset.

</details>


### [26] [TS-PEFT: Token-Selective Parameter-Efficient Fine-Tuning with Learnable Threshold Gating](https://arxiv.org/abs/2511.16147)
*Dabiao Ma,Ziming Dai,Zhimin Xin,Shu Wang,Ye Wang,Haojun Fei*

Main category: cs.CL

TL;DR: 传统PEFT对所有位置都微调是多余甚至有害的。TS-PEFT通过只选择部分位置进行微调，提升了大模型的下游任务表现，未来微调方法应更加有选择性。


<details>
  <summary>Details</summary>
Motivation: 当前参数高效微调（PEFT）方法在NLP和CV领域广泛用于大模型微调，但现有方法对所有位置索引都进行参数修改，作者质疑这种做法的必要性。

Method: 提出了Token-Selective PEFT（TS-PEFT）新范式，通过一个选择函数S，仅对部分位置索引应用PEFT修改，而不是全部应用。

Result: 实验发现，对全部索引应用PEFT不仅不必要，甚至可能导致效果变差；有选择性地应用PEFT能提升下游任务性能。

Conclusion: 该研究突破了传统PEFT无差别微调的思路，主张采用有针对性的位置选择，推动未来探索更优的大模型微调方法。

Abstract: In the field of large models (LMs) for natural language processing (NLP) and computer vision (CV), Parameter-Efficient Fine-Tuning (PEFT) has emerged as a resource-efficient method that modifies a limited number of parameters while keeping the pretrained weights fixed. This paper investigates the traditional PEFT approach, which applies modifications to all position indices, and questions its necessity. We introduce a new paradigm called Token-Selective PEFT (TS-PEFT), in which a function S selectively applies PEFT modifications to a subset of position indices, potentially enhancing performance on downstream tasks. Our experimental results reveal that the indiscriminate application of PEFT to all indices is not only superfluous, but may also be counterproductive. This study offers a fresh perspective on PEFT, advocating for a more targeted approach to modifications and providing a framework for future research to optimize the fine-tuning process for large models.

</details>


### [27] [SemanticCite: Citation Verification with AI-Powered Full-Text Analysis and Evidence-Based Reasoning](https://arxiv.org/abs/2511.16198)
*Sebastian Haan*

Main category: cs.CL

TL;DR: 本文提出了SemanticCite系统，能自动核查学术引用准确性，通过轻量模型和多检索方法实现高效验证，并发布了丰富数据和开源工具，大幅提升科研引用质量与透明度。


<details>
  <summary>Details</summary>
Motivation: 当前学术引用面临误用、AI生成虚假引用、传统引用不指向具体证据片段等问题，亟需更细致、可扩展、自动化的引文验证流程提升科学沟通质量。

Method: 结合多检索方法与轻量化语言模型，将引用与原文进行语义比对，采用‘Supported, Partially Supported, Unsupported, Uncertain’四分类方法判断引用准确性，并公开详细数据集和工具。

Result: 轻量化模型性能可媲美商用大模型，计算资源需求显著降低，验证过程透明，并提供丰富数据集和开源工具，助力大规模引用核查，优化同行评审及AI内容质量控制流程。

Conclusion: SemanticCite通过结合多检索方法和四分类体系，实现了高效、可扩展且透明的学术引文核查，有助于提升科研诚信和引用质量。

Abstract: Effective scientific communication depends on accurate citations that validate sources and guide readers to supporting evidence. Yet academic literature faces mounting challenges: semantic citation errors that misrepresent sources, AI-generated hallucinated references, and traditional citation formats that point to entire papers without indicating which sections substantiate specific claims. We introduce SemanticCite, an AI-powered system that verifies citation accuracy through full-text source analysis while providing rich contextual information via detailed reasoning and relevant text snippets. Our approach combines multiple retrieval methods with a four-class classification system (Supported, Partially Supported, Unsupported, Uncertain) that captures nuanced claim-source relationships and enables appropriate remedial actions for different error types. Our experiments show that fine-tuned lightweight language models achieve performance comparable to large commercial systems with significantly lower computational requirements, making large-scale citation verification practically feasible. The system provides transparent, evidence-based explanations that support user understanding and trust. We contribute a comprehensive dataset of over 1,000 citations with detailed alignments, functional classifications, semantic annotations, and bibliometric metadata across eight disciplines, alongside fine-tuned models and the complete verification framework as open-source software. SemanticCite addresses critical challenges in research integrity through scalable citation verification, streamlined peer review, and quality control for AI-generated content, providing an open-source foundation for maintaining citation accuracy at scale.

</details>


### [28] [SeSE: A Structural Information-Guided Uncertainty Quantification Framework for Hallucination Detection in LLMs](https://arxiv.org/abs/2511.16275)
*Xingtao Zhao,Hao Peng,Dingli Su,Xianghua Zeng,Chunyang Liu,Jinzhi Liao,Philip S. Yu*

Main category: cs.CL

TL;DR: 本论文提出了语义结构熵（SeSE）作为新的语言模型不确定性量化方法，通过利用语义结构信息更精准地检测模型幻觉，实验表明其效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有主流不确定性量化方法忽略了潜在的语义结构信息，不足以支持大型语言模型在安全关键场景准确检测不确定性和避免幻觉。为此，需要更精细的结构信息来提升不确定性判断能力。

Method: 提出Semantic Structural Entropy（SeSE）作为新的不确定性量化框架，通过构建自适应稀疏有向语义图，捕捉语义依赖并进行自动剪枝；结合分层抽象，定义最佳语义编码树的结构熵来衡量语义空间中的内在不确定性。同时将SeSE扩展用于长文本中单独断言的不确定性量化。

Result: 在29组模型-数据集的实验中，SeSE在不确定性量化和幻觉检测上显著超越了包括监督方法和KLE在内的先进基线方法。

Conclusion: SeSE方法在量化大型语言模型不确定性和检测幻觉方面效果显著，优于现有的不确定性量化方法。

Abstract: Reliable uncertainty quantification (UQ) is essential for deploying large language models (LLMs) in safety-critical scenarios, as it enables them to abstain from responding when uncertain, thereby avoiding hallucinating falsehoods. However, state-of-the-art UQ methods primarily rely on semantic probability distributions or pairwise distances, overlooking latent semantic structural information that could enable more precise uncertainty estimates. This paper presents Semantic Structural Entropy (SeSE), a principled UQ framework that quantifies the inherent semantic uncertainty of LLMs from a structural information perspective for hallucination detection. Specifically, to effectively model semantic spaces, we first develop an adaptively sparsified directed semantic graph construction algorithm that captures directional semantic dependencies while automatically pruning unnecessary connections that introduce negative interference. We then exploit latent semantic structural information through hierarchical abstraction: SeSE is defined as the structural entropy of the optimal semantic encoding tree, formalizing intrinsic uncertainty within semantic spaces after optimal compression. A higher SeSE value corresponds to greater uncertainty, indicating that LLMs are highly likely to generate hallucinations. In addition, to enhance fine-grained UQ in long-form generation -- where existing methods often rely on heuristic sample-and-count techniques -- we extend SeSE to quantify the uncertainty of individual claims by modeling their random semantic interactions, providing theoretically explicable hallucination detection. Extensive experiments across 29 model-dataset combinations show that SeSE significantly outperforms advanced UQ baselines, including strong supervised methods and the recently proposed KLE.

</details>


### [29] [SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning](https://arxiv.org/abs/2511.16324)
*Wei Xia,Zhi-Hong Deng*

Main category: cs.CL

TL;DR: 本文提出了一种无需微调、对模型无关的动态分布对齐（SDA）方法，通过调控输出概率分布，提高了开源大语言模型在多维度对齐上的性能，且支持个性化应用，实验效果显著。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）被广泛应用于实际领域，但模型输出与人类意图对齐仍是重大挑战。如何在推理阶段无需昂贵再训练或大量监督，实现高效且有效的对齐，是亟需解决的问题。

Method: 提出了SDA（Steering-Driven Distribution Alignment）框架，这是一种训练无关、模型无关的对齐方法。SDA根据用户指令动态调整模型输出概率分布，无需微调，且可独立运行或与训练型对齐策略结合。支持个性化偏好控制，适配多种开源大模型。

Result: 在8个不同规模和来源的开源大语言模型中，SDA在真诚、无害、有用（3H）三个对齐维度均显著提升：平均提升64.4%有用性、30%真诚、11.5%无害性。

Conclusion: SDA方法无需再训练、资源消耗低，可显著提高开源大模型的意图对齐效果。适用性广泛，并支持个性化对齐需求。

Abstract: With the rapid advancement of large language models (LLMs), their deployment in real-world applications has become increasingly widespread. LLMs are expected to deliver robust performance across diverse tasks, user preferences, and practical scenarios. However, as demands grow, ensuring that LLMs produce responses aligned with human intent remains a foundational challenge. In particular, aligning model behavior effectively and efficiently during inference, without costly retraining or extensive supervision, is both a critical requirement and a non-trivial technical endeavor. To address the challenge, we propose SDA (Steering-Driven Distribution Alignment), a training-free and model-agnostic alignment framework designed for open-source LLMs. SDA dynamically redistributes model output probabilities based on user-defined alignment instructions, enhancing alignment between model behavior and human intents without fine-tuning. The method is lightweight, resource-efficient, and compatible with a wide range of open-source LLMs. It can function independently during inference or be integrated with training-based alignment strategies. Moreover, SDA supports personalized preference alignment, enabling flexible control over the model response behavior. Empirical results demonstrate that SDA consistently improves alignment performance across 8 open-source LLMs with varying scales and diverse origins, evaluated on three key alignment dimensions, helpfulness, harmlessness, and honesty (3H). Specifically, SDA achieves average gains of 64.4% in helpfulness, 30% in honesty and 11.5% in harmlessness across the tested models, indicating its effectiveness and generalization across diverse models and application scenarios.

</details>


### [30] [Incorporating Self-Rewriting into Large Language Model Reasoning Reinforcement](https://arxiv.org/abs/2511.16331)
*Jiashu Yao,Heyan Huang,Shuang Zeng,Chuwei Luo,WangJie You,Jie Tang,Qingsong Liu,Yuhang Guo,Yangyang Kang*

Main category: cs.CL

TL;DR: 本文提出自重写训练方法，以模型自我重写推理文本并学习，以优化内部推理质量，显著提升准确率和推理效率，超越现有强基线，是提升大模型推理可靠性的有效途径。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习方法仅关注最终结果的正确性，忽略了对模型内部推理过程的详细监督，导致内部推理质量存在问题，如思考过度、思考不足、冗余或混乱。为提升大推理模型（LRMs）的推理过程质量，需要更细致的监督和优化方法。

Method: 提出了自重写（self-rewriting）框架：模型自行重写其推理文本，并以重写后的推理进行学习，从而优化思维过程。具体算法采用了选择性重写，只对“简单”样本（模型多次预测始终正确的样本）进行重写，保留全部原始奖励信号。同时，通过混合重写与基础生成于同一批次训练，保持RL的可扩展性，并仅带来约10%的计算开销。

Result: 广泛实验表明，自重写框架在多任务、多模型规模下均取得优异效果：在准确率与推理长度权衡中，准确率提升（+0.6），推理长度显著减少（-46%），且无需在重写提示中明确要求缩短推理。采用LLM-as-a-judge评价指标，内部推理质量提升明显（+7.2），有效缓解了原有的推理过程各类缺陷。

Conclusion: 自重写方法能够在不影响奖励信号完整性及训练可扩展性的前提下，显著提升大推理模型推理过程的有效性与效率，改善了推理内在质量与最终表现。

Abstract: Through reinforcement learning (RL) with outcome correctness rewards, large reasoning models (LRMs) with scaled inference computation have demonstrated substantial success on complex reasoning tasks. However, the one-sided reward, focused solely on final correctness, limits its ability to provide detailed supervision over internal reasoning process. This deficiency leads to suboptimal internal reasoning quality, manifesting as issues like over-thinking, under-thinking, redundant-thinking, and disordered-thinking. Inspired by the recent progress in LRM self-rewarding, we introduce self-rewriting framework, where a model rewrites its own reasoning texts, and subsequently learns from the rewritten reasoning to improve the internal thought process quality. For algorithm design, we propose a selective rewriting approach wherein only "simple" samples, defined by the model's consistent correctness, are rewritten, thereby preserving all original reward signals of GRPO. For practical implementation, we compile rewriting and vanilla generation within one single batch, maintaining the scalability of the RL algorithm and introducing only ~10% overhead. Extensive experiments on diverse tasks with different model sizes validate the effectiveness of self-rewriting. In terms of the accuracy-length tradeoff, the self-rewriting approach achieves improved accuracy (+0.6) with substantially shorter reasoning (-46%) even without explicit instructions in rewriting prompts to reduce reasoning length, outperforming existing strong baselines. In terms of internal reasoning quality, self-rewriting achieves significantly higher scores (+7.2) under the LLM-as-a-judge metric, successfully mitigating internal reasoning flaws.

</details>


### [31] [NLP Datasets for Idiom and Figurative Language Tasks](https://arxiv.org/abs/2511.16345)
*Blake Matheny,Phuong Minh Nguyen,Minh Le Nguyen,Stephanie Reynolds*

Main category: cs.CL

TL;DR: 本文提出了三个新的习语及比喻性语言数据集，为改进大语言模型对复杂语言现象（如习语和比喻表达）的理解能力提供了训练和评估资源，填补了现有数据集的不足，对NLP相关任务具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 习语和比喻性语言在日常口语和书面语中占有很大比例。随着社交媒体的发展，非正式语言的数据更易获得，但这些语言类型仍然难以被大语言模型（LLM）充分理解和处理。当前微调是效果较好的方法，但构建更大、更优质的数据集有助于提升LLM对习语和比喻性表达的理解能力。

Method: 作者整合了近期习语和比喻性语言的数据集，构建了一个综合习语列表，从大型语料库中获取相关语境序列。由此创建了一个大规模潜在习语和比喻性表达数据集，以及两个额外的人类标注的明确习语和比喻性表达数据集，用于评估预训练语言模型在习语识别（检测）任务中的基础能力。这些数据集经过后处理以适配模型无关训练，并用于slot labeling和序列标注任务的训练与评估。

Result: 得到了一个大规模潜在习语与比喻性语言表达数据集，以及两个高质量的人类标注数据集。这些数据集经过模型无关性处理，实现了在slot labeling和序列标注上的训练和评估，为预训练语言模型处理习语与比喻性语言提供了重要资源和测试基准。

Conclusion: 构建了可提升LLM理解习语和比喻性语言能力的大规模、多样化数据集，并验证了这些数据集在相关任务上的应用效果。该工作为习语识别和比喻性语言理解相关的NLP模型训练与评估提供了新资源和方法。

Abstract: Idiomatic and figurative language form a large portion of colloquial speech and writing. With social media, this informal language has become more easily observable to people and trainers of large language models (LLMs) alike. While the advantage of large corpora seems like the solution to all machine learning and Natural Language Processing (NLP) problems, idioms and figurative language continue to elude LLMs. Finetuning approaches are proving to be optimal, but better and larger datasets can help narrow this gap even further. The datasets presented in this paper provide one answer, while offering a diverse set of categories on which to build new models and develop new approaches. A selection of recent idiom and figurative language datasets were used to acquire a combined idiom list, which was used to retrieve context sequences from a large corpus. One large-scale dataset of potential idiomatic and figurative language expressions and two additional human-annotated datasets of definite idiomatic and figurative language expressions were created to evaluate the baseline ability of pre-trained language models in handling figurative meaning through idiom recognition (detection) tasks. The resulting datasets were post-processed for model agnostic training compatibility, utilized in training, and evaluated on slot labeling and sequence tagging.

</details>


### [32] [Learning from Sufficient Rationales: Analysing the Relationship Between Explanation Faithfulness and Token-level Regularisation Strategies](https://arxiv.org/abs/2511.16353)
*Jonathan Kamp,Lisa Beinborn,Antske Fokkens*

Main category: cs.CL

TL;DR: 本研究分析了自然语言解释（rationales）在模型训练中的作用，发现现有的充分性指标并不能全面反应解释对模型性能的影响，表现和任务类型有关，提示需开发更细致的度量方法。


<details>
  <summary>Details</summary>
Motivation: 现有充分性指标只能估计解释的信息量，难以揭示解释信息对模型实际分类性能的影响，因此尝试探究解释与模型表现的真实关系。

Method: 通过两种建模范式来评估自然语言解释（rationales）：一，token分类检测哪些词汇属于解释；二，通过attention正则化将解释信息融入模型输入以提升表现。

Result: 高度信息性的解释未必提升分类准确率，充分性反映了上下文干扰，且合理性信息用于模型输入在跨领域任务中有时有帮助，但结果不稳定。同时，充分性指标与token分类能力无明显关系。

Conclusion: 研究发现，充分性指标与模型正确分类并无直接关联，且与token分类能力无关，表明对解释性评估需开发更系统的度量方法。

Abstract: Human explanations of natural language, rationales, form a tool to assess whether models learn a label for the right reasons or rely on dataset-specific shortcuts. Sufficiency is a common metric for estimating the informativeness of rationales, but it provides limited insight into the effects of rationale information on model performance. We address this limitation by relating sufficiency to two modelling paradigms: the ability of models to identify which tokens are part of the rationale (through token classification) and the ability of improving model performance by incorporating rationales in the input (through attention regularisation). We find that highly informative rationales are not likely to help classify the instance correctly. Sufficiency conversely captures the classification impact of the non-rationalised context, which interferes with rationale information in the same input. We also find that incorporating rationale information in model inputs can boost cross-domain classification, but results are inconsistent per task and model type. Finally, sufficiency and token classification appear to be unrelated. These results exemplify the complexity of rationales, showing that metrics capable of systematically capturing this type of information merit further investigation.

</details>


### [33] [AICC: Parse HTML Finer, Make Models Better -- A 7.3T AI-Ready Corpus Built by a Model-Based HTML Parser](https://arxiv.org/abs/2511.16397)
*Ren Ma,Jiantao Qiu,Chao Xu,Pei Chu,Kaiwen Liu,Pengli Ren,Yuan Qu,Jiahui Peng,Linfeng Hou,Mengjie Liu,Lindong Lu,Wenchang Ning,Jia Yu,Rui Min,Jin Shi,Haojiong Chen,Peng Zhang,Wenjian Zhang,Qian Jiang,Zengjie Hu,Guoqiang Yang,Zhenxiang Li,Fukai Shang,Zhongying Tu,Wentao Zhang,Dahua Lin,Conghui He*

Main category: cs.CL

TL;DR: 该论文发现提升HTML到文本抽取质量，对大模型性能的影响不亚于过滤等传统策略。作者提出了用语言模型进行语义标注的新抽取管道（MinerU-HTML），在结构元素保留和整体指标上显著优于主流工具，并据此构建大规模多语料库（AICC），实验表明能有效提升大模型下游性能。团队已开源相关数据和工具，强调HTML抽取过程的重要性。


<details>
  <summary>Details</summary>
Motivation: 目前网页数据质量对大语言模型非常关键，但大多数整理工作都集中在过滤和去重上，而将HTML转文本仅作为固定的预处理步骤。现有网页语料库使用基于启发式的提取工具（如Trafilatura），但这些工具难以保留文档结构，且易破坏结构化元素如公式、代码、表格。论文认为提升HTML抽取质量对于下游模型性能的影响不亚于过滤策略，有必要开发新的抽取方法。

Method: 提出MinerU-HTML，一个将内容抽取重构为序列标注问题的新型管道，并用0.6B参数规模的语言模型解决。其流程分为两阶段：先语义分类，再转为Markdown，区别于传统文本密度启发式方法，能够更好地语义理解和结构保留。该方法具有可扩展性，克服了启发式方案的提升瓶颈。

Result: 在MainWebBench基准（7,887网页）上，MinerU-HTML取得81.8%的ROUGE-N F1，远高于Trafilatura的63.6%，且能很好保护结构化元素（代码块90.9%、公式94.0%）。据此构建了AICC，一个包含7.3万亿token的多语言网页语料库。预训练实验显示，在相同过滤条件下，基于AICC训练的模型在13项基准平均准确率为50.8%，比TfCC高1.08个百分点。AICC在关键基准上也优于RefinedWeb和FineWeb。

Conclusion: HTML抽取质量显著影响下游语言模型性能，HTML抽取本身是构建高质量网页语料库的关键但常被低估环节。论文公开了MainWebBench、MinerU-HTML与AICC工具和数据集，推动社区重视HTML抽取过程，提升大模型训练数据质量。

Abstract: While web data quality is crucial for large language models, most curation efforts focus on filtering and deduplication,treating HTML-to-text extraction as a fixed pre-processing step. Existing web corpora rely on heuristic-based extractors like Trafilatura, which struggle to preserve document structure and frequently corrupt structured elements such as formulas, codes, and tables. We hypothesize that improving extraction quality can be as impactful as aggressive filtering strategies for downstream performance. We introduce MinerU-HTML, a novel extraction pipeline that reformulates content extraction as a sequence labeling problem solved by a 0.6B-parameter language model. Unlike text-density heuristics, MinerU-HTML leverages semantic understanding and employs a two-stage formatting pipeline that explicitly categorizes semantic elements before converting to Markdown. Crucially, its model-based approach is inherently scalable, whereas heuristic methods offer limited improvement pathways. On MainWebBench, our benchmark of 7,887 annotated web pages, MinerU-HTML achieves 81.8\% ROUGE-N F1 compared to Trafilatura's 63.6\%, with exceptional structured element preservation (90.9\% for code blocks, 94.0\% for formulas). Using MinerU-HTML, we construct AICC (AI-ready Common Crawl), a 7.3-trillion token multilingual corpus from two Common Crawl snapshots. In controlled pretraining experiments where AICC and Trafilatura-extracted TfCC undergo identical filtering, models trained on AICC (62B tokens) achieve 50.8\% average accuracy across 13 benchmarks, outperforming TfCC by 1.08pp-providing direct evidence that extraction quality significantly impacts model capabilities. AICC also surpasses RefinedWeb and FineWeb on key benchmarks. We publicly release MainWebBench, MinerU-HTML, and AICC, demonstrating that HTML extraction is a critical, often underestimated component of web corpus construction.

</details>


### [34] [Classification of worldwide news articles by perceived quality, 2018-2024](https://arxiv.org/abs/2511.16416)
*Connor McElroy,Thiago E. A. de Oliveira,Chris Brogly*

Main category: cs.CL

TL;DR: 机器学习和深度学习模型能够准确地区分高低质量新闻文章，BERT类深度学习模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨机器学习和深度学习模型是否能够有效区分感知为低质量与高质量的新闻文章，回应新闻质量自动化评估的需求。

Method: 采用新建的数据集，包含2018-2024年Common Crawl收集的1,412,272篇英文新闻文章，通过专家对579个新闻源网站的共识评分，将文章按中位数分为高低质量两类（各约70.6万篇），并提取每篇文章194个语言学特征。随后，评估了3种传统机器学习分类器（如随机森林）以及3种深度学习模型（如ModernBERT、DistilBERT）的性能。

Result: 随机森林模型准确率为0.7355，ROC AUC为0.8131。深度学习模型表现更优，其中ModernBERT-large（256 context长度）准确率达0.8744，ROC AUC达0.9593，F1分数为0.8739，其次为DistilBERT-base（512 context长度），准确率0.8685，ROC AUC为0.9554。

Conclusion: 无论是传统机器学习还是深度学习模型，都能够有效区分全球新闻文章的高低感知质量，其中深度学习模型（尤其是BERT变种）表现尤为突出。

Abstract: This study explored whether supervised machine learning and deep learning models can effectively distinguish perceived lower-quality news articles from perceived higher-quality news articles. 3 machine learning classifiers and 3 deep learning models were assessed using a newly created dataset of 1,412,272 English news articles from the Common Crawl over 2018-2024. Expert consensus ratings on 579 source websites were split at the median, creating perceived low and high-quality classes of about 706,000 articles each, with 194 linguistic features per website-level labelled article. Traditional machine learning classifiers such as the Random Forest demonstrated capable performance (0.7355 accuracy, 0.8131 ROC AUC). For deep learning, ModernBERT-large (256 context length) achieved the best performance (0.8744 accuracy; 0.9593 ROC-AUC; 0.8739 F1), followed by DistilBERT-base (512 context length) at 0.8685 accuracy and 0.9554 ROC-AUC. DistilBERT-base (256 context length) reached 0.8478 accuracy and 0.9407 ROC-AUC, while ModernBERT-base (256 context length) attained 0.8569 accuracy and 0.9470 ROC-AUC. These results suggest that the perceived quality of worldwide news articles can be effectively differentiated by traditional CPU-based machine learning classifiers and deep learning classifiers.

</details>


### [35] [ESGBench: A Benchmark for Explainable ESG Question Answering in Corporate Sustainability Reports](https://arxiv.org/abs/2511.16438)
*Sherine George,Nithish Saji*

Main category: cs.CL

TL;DR: ESGBench是一个专注于企业可持续报告的ESG问答基准及评估框架，提供细致的模型评估标准。实验显示现有大模型在事实和领域对齐等方面还存在挑战，该基准有助加速透明、可解释的ESG AI系统发展。


<details>
  <summary>Details</summary>
Motivation: 近年来企业在可持续发展（ESG）方面的信息透明和责任越来越受到关注，然而针对企业ESG报告的问答系统在可解释性和准确性方面尚有不足。尤其在模型如何推理、回答以及追溯事实的能力上，缺乏细致的评估标准。作者旨在推动ESG领域问答系统的可解释性评估进步。

Method: 作者构建了一个名为ESGBench的基准数据集和评估框架，涵盖多个ESG主题。在该数据集中，针对企业可持续发展报告提出了领域特定的问题，并配有人类标注的答案和支持性证据，以此用于模型推理的细粒度评价，并分析了最新大语言模型（LLM）在该基准上的表现。

Result: 实验揭示了当前主流LLM在ESGBench上的关键挑战，包括事实一致性、答案可追溯性以及领域适应性等方面。

Conclusion: ESGBench可促进ESG报告分析相关AI系统的透明度和问责性研究，为推动企业可持续和社会责任领域AI的进步提供有力工具。

Abstract: We present ESGBench, a benchmark dataset and evaluation framework designed to assess explainable ESG question answering systems using corporate sustainability reports. The benchmark consists of domain-grounded questions across multiple ESG themes, paired with human-curated answers and supporting evidence to enable fine-grained evaluation of model reasoning. We analyze the performance of state-of-the-art LLMs on ESGBench, highlighting key challenges in factual consistency, traceability, and domain alignment. ESGBench aims to accelerate research in transparent and accountable ESG-focused AI systems.

</details>


### [36] [Anatomy of an Idiom: Tracing Non-Compositionality in Language Models](https://arxiv.org/abs/2511.16467)
*Andrew Gomes*

Main category: cs.CL

TL;DR: 本文提出新方法分析transformer模型处理惯用语时的计算电路，发现独特的注意力头和增强机制，对深入理解非组合性语言处理及更复杂语法结构的机制具有指导意义。


<details>
  <summary>Details</summary>
Motivation: 理解transformer语言模型如何处理惯用语（idiomatic expressions），尤其是非组合性语言结构的内部机制和电路特征。

Method: 提出一套新的电路发现和分析技术，尤其是通过改进的路径修补（path patching）算法，系统分析transformer模型中惯用表达的处理模式。

Result: 发现了“Idiom Heads”（在多个惯用语中频繁激活的注意力头）和“增强接收”（前期处理导致惯用语各词之间的关注增强）。分析了这些机制及其在提升计算效率和鲁棒性方面的作用。

Conclusion: transformers在处理非组合性语言时表现出独特的电路和机制，相关发现为理解transformer模型处理复杂语法结构提供了新思路。

Abstract: We investigate the processing of idiomatic expressions in transformer-based language models using a novel set of techniques for circuit discovery and analysis. First discovering circuits via a modified path patching algorithm, we find that idiom processing exhibits distinct computational patterns. We identify and investigate ``Idiom Heads,'' attention heads that frequently activate across different idioms, as well as enhanced attention between idiom tokens due to earlier processing, which we term ``augmented reception.'' We analyze these phenomena and the general features of the discovered circuits as mechanisms by which transformers balance computational efficiency and robustness. Finally, these findings provide insights into how transformers handle non-compositional language and suggest pathways for understanding the processing of more complex grammatical constructions.

</details>


### [37] [Arctic-Extract Technical Report](https://arxiv.org/abs/2511.16470)
*Mateusz Chiliński,Julita Ołtusek,Wojciech Jaśkowski*

Main category: cs.CL

TL;DR: Arctic-Extract是一款高性能且轻量级的结构化文档信息抽取模型，适合部署在资源有限的设备上，同时在问答、实体和表格识别等任务上表现突出。


<details>
  <summary>Details</summary>
Motivation: 当前业务文档结构化信息抽取需要高效、资源友好的模型，尤其是在硬件资源受限的场景下（如低端GPU）。

Method: 提出并训练了Arctic-Extract模型，使用新的训练协议以提升模型在问答、实体识别和表格抽取任务上的能力，并进行了详细性能评估。

Result: Arctic-Extract仅6.6 GiB，能在24GB显存的A10 GPU上一次处理最多125页A4文档，且在文档理解任务中表现优异。

Conclusion: Arctic-Extract结合了技术先进性与部署友好性，实现了面向资源受限硬件的高性能文档结构数据抽取。

Abstract: Arctic-Extract is a state-of-the-art model designed for extracting structural data (question answering, entities and tables) from scanned or digital-born business documents. Despite its SoTA capabilities, the model is deployable on resource-constrained hardware, weighting only 6.6 GiB, making it suitable for deployment on devices with limited resources, such as A10 GPUs with 24 GB of memory. Arctic-Extract can process up to 125 A4 pages on those GPUs, making suitable for long document processing. This paper highlights Arctic-Extract's training protocols and evaluation results, demonstrating its strong performance in document understanding.

</details>


### [38] [TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval](https://arxiv.org/abs/2511.16528)
*Özay Ezerceli,Mahmoud El Hussieni,Selva Taş,Reyhan Bayraktar,Fatma Betül Terzioğlu,Yusuf Çelebi,Yağız Asker*

Main category: cs.CL

TL;DR: 本研究首次系统比较土耳其语信息检索中的稠密编码器与后期交互模型。提出TurkColBERT基准，展示小参数ColBERT后期交互模型在性能和效率上的巨大优势。MUVERA索引方案提升检索速度和mAP。公开全部模型及工具，未来需在更大规模数据上验证效果。


<details>
  <summary>Details</summary>
Motivation: 神经信息检索（IR）系统在高资源语言中表现优异，但在形态结构丰富且资源较低的语言（如土耳其语）中研究较少。现有土耳其语IR主要依赖于稠密双编码器，对保留词级表示的后期交互模型尚未系统评估。

Method: 提出TurkColBERT基准，用于系统比较土耳其语稠密编码器与后期交互模型。采用两阶段适配流程：先以土耳其语NLI/STS任务微调英语及多语种编码器，再用PyLate训练将其转化为ColBERT风格检索器（用MS MARCO-TR数据集训练）。在五个领域的土耳其语BEIR数据集上评估10个模型，并比较多种索引算法。

Result: 小参数后期交互模型在保持稀疏参数量的情况下，性能远超传统稠密编码器。例如colbert-hash-nano-tr参数量仅1.0M，比600M的dense encoder小600倍，却保留71%的mAP；ColmmBERT-base-TR在特定领域任务可提升mAP最高至13.8%。MUVERA+Rerank索引比PLAID快3.33倍且mAP提升1.7%，可实现低延迟检索。

Conclusion: 后期交互模型（如ColBERT系列）在土耳其语IR中极具参数效率和性能优势，特别适用于低资源场景。MUVERA索引进一步提升速度和准确率，推动土耳其语信息检索更加低延迟、高效。公开相关模型与工具。但仍需在更大规模和真实数据集上进一步验证结论。

Abstract: Neural information retrieval systems excel in high-resource languages but remain underexplored for morphologically rich, lower-resource languages such as Turkish. Dense bi-encoders currently dominate Turkish IR, yet late-interaction models -- which retain token-level representations for fine-grained matching -- have not been systematically evaluated. We introduce TurkColBERT, the first comprehensive benchmark comparing dense encoders and late-interaction models for Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders on Turkish NLI/STS tasks, then converts them into ColBERT-style retrievers using PyLate trained on MS MARCO-TR. We evaluate 10 models across five Turkish BEIR datasets covering scientific, financial, and argumentative domains. Results show strong parameter efficiency: the 1.0M-parameter colbert-hash-nano-tr is 600$\times$ smaller than the 600M turkish-e5-large dense encoder while preserving over 71\% of its average mAP. Late-interaction models that are 3--5$\times$ smaller than dense encoders significantly outperform them; ColmmBERT-base-TR yields up to +13.8\% mAP on domain-specific tasks. For production-readiness, we compare indexing algorithms: MUVERA+Rerank is 3.33$\times$ faster than PLAID and offers +1.7\% relative mAP gain. This enables low-latency retrieval, with ColmmBERT-base-TR achieving 0.54 ms query times under MUVERA. We release all checkpoints, configs, and evaluation scripts. Limitations include reliance on moderately sized datasets ($\leq$50K documents) and translated benchmarks, which may not fully reflect real-world Turkish retrieval conditions; larger-scale MUVERA evaluations remain necessary.

</details>


### [39] [Beyond Tokens in Language Models: Interpreting Activations through Text Genre Chunks](https://arxiv.org/abs/2511.16540)
*Éloïse Benito-Rodriguez,Einar Urdshals,Jasmina Nasufi,Nicky Pochinkov*

Main category: cs.CL

TL;DR: 本研究利用LLM内部激活信息，通过浅层机器学习模型成功预测提示文本体裁，为LLM解释性及安全性研究提供了新思路。


<details>
  <summary>Details</summary>
Motivation: LLM在实际部署中如何安全有益地使用，受限于其难以解释的结构和无法人工评估全部输出。本研究希望通过激活预测建立可解释性框架，提升LLM的安全性与可靠性。

Method: 使用Mistral-7B模型，对两个数据集进行实验，采用scikit-learn分类器，根据LLM内部激活信息预测文本体裁。

Result: 文本体裁预测F1分数最高达98%和71%，且在所有数据集上均优于对照实验，证明了通过LLM激活可用浅层学习模型推断文本体裁。

Conclusion: 通过浅层学习模型，可以根据LLM的激活状态高效预测提示文本的体裁，F1得分显著高于对照任务。

Abstract: Understanding Large Language Models (LLMs) is key to ensure their safe and beneficial deployment. This task is complicated by the difficulty of interpretability of LLM structures, and the inability to have all their outputs human-evaluated. In this paper, we present the first step towards a predictive framework, where the genre of a text used to prompt an LLM, is predicted based on its activations. Using Mistral-7B and two datasets, we show that genre can be extracted with F1-scores of up to 98% and 71% using scikit-learn classifiers. Across both datasets, results consistently outperform the control task, providing a proof of concept that text genres can be inferred from LLMs with shallow learning models.

</details>


### [40] [WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue](https://arxiv.org/abs/2511.16544)
*Zachary Ellis,Jared Joselowitz,Yash Deo,Yajie He,Anna Kalygina,Aisling Higham,Mana Rahimzadeh,Yan Jia,Ibrahim Habli,Ernest Lim*

Main category: cs.CL

TL;DR: 论文指出，现有ASR评估指标与临床实际风险相关性弱，通过建立专家标注体系并引入优化的大模型自动判别系统，可实现对ASR在医疗场景下临床安全性的准确自动评估。


<details>
  <summary>Details</summary>
Motivation: 当前ASR在医疗场景应用广泛，但评估方法单一，主要依赖WER等指标，无法准确反映文字错误对临床风险的实际影响。亟需创新评估体系，将评判重点从文本准确率转向临床安全性。

Method: 建立专家医生标注的黄金标准基准，通过比较真实语句与ASR转录语句，标记临床风险。随后分析WER等指标与风险标签的相关性，并引入基于大模型调优的新评估体系（LLM-as-a-Judge，优化算法GEPA等）。

Result: LLM-as-a-Judge（Gemini-2.5-Pro）基于自动化优化后，实现了专家级评估（准确率90%，Cohen's kappa达0.816），与人工标注表现相当，显著优于传统指标。

Conclusion: 传统的ASR评估指标（如WER）与临床实际风险相关性较弱。通过引入LLM-as-a-Judge系统，能够实现对ASR临床安全性更准确、自动化的评估。

Abstract: As Automatic Speech Recognition (ASR) is increasingly deployed in clinical dialogue, standard evaluations still rely heavily on Word Error Rate (WER). This paper challenges that standard, investigating whether WER or other common metrics correlate with the clinical impact of transcription errors. We establish a gold-standard benchmark by having expert clinicians compare ground-truth utterances to their ASR-generated counterparts, labeling the clinical impact of any discrepancies found in two distinct doctor-patient dialogue datasets. Our analysis reveals that WER and a comprehensive suite of existing metrics correlate poorly with the clinician-assigned risk labels (No, Minimal, or Significant Impact). To bridge this evaluation gap, we introduce an LLM-as-a-Judge, programmatically optimized using GEPA to replicate expert clinical assessment. The optimized judge (Gemini-2.5-Pro) achieves human-comparable performance, obtaining 90% accuracy and a strong Cohen's $κ$ of 0.816. This work provides a validated, automated framework for moving ASR evaluation beyond simple textual fidelity to a necessary, scalable assessment of safety in clinical dialogue.

</details>


### [41] [Integrating Symbolic Natural Language Understanding and Language Models for Word Sense Disambiguation](https://arxiv.org/abs/2511.16577)
*Kexin Zhao,Ken Forbus*

Main category: cs.CL

TL;DR: 本文提出了一种无需手工标注的词义消歧方法，通过把词义候选转为自然语言再由LLM判断，实现细粒度复杂知识体系的自动消歧，并在实验中取得了不错效果。


<details>
  <summary>Details</summary>
Motivation: 当前词义消歧方法主要针对粗粒度意义且依赖人工标注，这限制了在更复杂知识体系上的应用。作者希望开发一种无需人工标注的数据驱动细粒度消歧方法。

Method: 将符号自然语言理解系统生成的多个候选词义转化为可区分的自然语言表述，再通过大型语言模型（LLM）根据上下文进行选择，最终将选择结果反馈回符号NLU系统。

Result: 该方法能在无需标注数据的情况下，实现对复杂词义的自动消歧，并在人工标注金标准数据集上证明了其有效性。

Conclusion: 所提出的方法能够有效利用统计语言模型来进行词义消歧，而无需手工注释训练数据，具有实际应用价值。

Abstract: Word sense disambiguation is a fundamental challenge in natural language understanding. Current methods are primarily aimed at coarse-grained representations (e.g. WordNet synsets or FrameNet frames) and require hand-annotated training data to construct. This makes it difficult to automatically disambiguate richer representations (e.g. built on OpenCyc) that are needed for sophisticated inference. We propose a method that uses statistical language models as oracles for disambiguation that does not require any hand-annotation of training data. Instead, the multiple candidate meanings generated by a symbolic NLU system are converted into distinguishable natural language alternatives, which are used to query an LLM to select appropriate interpretations given the linguistic context. The selected meanings are propagated back to the symbolic NLU system. We evaluate our method against human-annotated gold answers to demonstrate its effectiveness.

</details>


### [42] [Comparison of Text-Based and Image-Based Retrieval in Multimodal Retrieval Augmented Generation Large Language Model Systems](https://arxiv.org/abs/2511.16654)
*Elias Lumer,Alex Cardenas,Matt Melich,Myles Mason,Sara Dieter,Vamse Kumar Subbiah,Pradeep Honaganahalli Basavaraju,Roberto Hernandez*

Main category: cs.CL

TL;DR: 仅将图片内容摘要为文本会丢失金融文档中的重要信息。将图片直接以多模态嵌入存储并检索能大幅提升下游检索与问答的效果。


<details>
  <summary>Details</summary>
Motivation: 在面向金融文档检索与问答的场景中，既有的方法大多将图片信息通过LLM转为文本后进行处理，导致在检索和问答环节中丢失了重要的上下文和视觉细节。该研究旨在解决这种因信息简化带来的性能瓶颈，探索更优的多模态知识检索方式。

Method: 本文对两种多模态RAG系统检索方式进行了对比：一是基于文本的分块检索（图片被转为文本处理），二是直接多模态嵌入检索（图像直接以原始形式存储在向量空间）。实验基于一个新构建的财报领域子集，涉及6种LLM和2种多模态嵌入模型，通过40对问答与配对文档（各含一图一文本）的评测体系进行评估。

Result: 直接多模态嵌入检索在所有主要评价指标上显著优于文本化方法，mAP@5提升13%，nDCG@5提升11%，相对提升分别为32%与20%。此外，直接多模态检索结果的一致性和事实准确性也更高。

Conclusion: 与LLM文本总结相比，直接多模态嵌入检索更有效地保留了原始视觉上下文和信息，有助于提升金融多模态文档的检索及问答性能，体现了较高的实用价值。

Abstract: Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models (LLMs) to access multimodal knowledge bases containing both text and visual information such as charts, diagrams, and tables in financial documents. However, existing multimodal RAG systems rely on LLM-based summarization to convert images into text during preprocessing, storing only text representations in vector databases, which causes loss of contextual information and visual details critical for downstream retrieval and question answering. To address this limitation, we present a comprehensive comparative analysis of two retrieval approaches for multimodal RAG systems, including text-based chunk retrieval (where images are summarized into text before embedding) and direct multimodal embedding retrieval (where images are stored natively in the vector space). We evaluate all three approaches across 6 LLM models and a two multi-modal embedding models on a newly created financial earnings call benchmark comprising 40 question-answer pairs, each paired with 2 documents (1 image and 1 text chunk). Experimental results demonstrate that direct multimodal embedding retrieval significantly outperforms LLM-summary-based approaches, achieving absolute improvements of 13% in mean average precision (mAP@5) and 11% in normalized discounted cumulative gain. These gains correspond to relative improvements of 32% in mAP@5 and 20% in nDCG@5, providing stronger evidence of their practical impact. We additionally find that direct multimodal retrieval produces more accurate and factually consistent answers as measured by LLM-as-a-judge pairwise comparisons. We demonstrate that LLM summarization introduces information loss during preprocessing, whereas direct multimodal embeddings preserve visual context for retrieval and inference.

</details>


### [43] [Nemotron Elastic: Towards Efficient Many-in-One Reasoning LLMs](https://arxiv.org/abs/2511.16664)
*Ali Taghibakhshi,Sharath Turuvekere Sreenivas,Saurav Muralidharan,Ruisi Cai,Marcin Chochowski,Ameya Sunil Mahabaleshwarkar,Yoshi Suhara,Oluwatobi Olabiyi,Daniel Korzekwa,Mostofa Patwary,Mohammad Shoeybi,Jan Kautz,Bryan Catanzaro,Ashwath Aithal,Nima Tajbakhsh,Pavlo Molchanov*

Main category: cs.CL

TL;DR: Nemotron Elastic能够在单一父模型中嵌套多个推理型LLM子模型，通过创新训练和弹性结构设计，极大降低训练和部署成本，同时保持顶尖准确率。


<details>
  <summary>Details</summary>
Motivation: 目前训练多规模的语言模型家族成本极高，每种模型尺寸都需要单独训练，耗费大量计算资源和数据。现有的模型压缩方法虽有降低成本，但依然较高，因此亟需开发一种高效构建多规模推理型大语言模型的解决方案。

Method: 提出Nemotron Elastic框架，它可在一个父模型中嵌入多个子模型，每个子模型针对不同部署目标优化，并且可以零样本（zero-shot）提取，无需额外训练。核心方法包括：端到端训练的路由器、两阶段训练课程、组感知SSM弹性化、异构MLP弹性化、归一化MSE层重要性用于深度选择，以及知识蒸馏实现多预算同时优化。

Result: 将Nemotron Elastic应用于Nemotron Nano V2 12B模型，仅用110B训练token同时得到9B和6B模型。与从头训练模型家族相比，成本降低超过360倍，与当前最佳压缩技术相比约降7倍。所有嵌套子模型准确率均与SoTA持平或更优。此外，该方法实现多模型嵌套，在部署时无论模型数量如何，内存占用保持不变。

Conclusion: Nemotron Elastic有效构建高效的多规模推理型语言模型家族，极大降低训练和部署成本，并保持模型性能优势。其创新的嵌套结构和多预算优化方法为大模型部署提供新选择。

Abstract: Training a family of large language models targeting multiple scales and deployment objectives is prohibitively expensive, requiring separate training runs for each different size. Recent work on model compression through pruning and knowledge distillation has reduced this cost; however, this process still incurs hundreds of billions of tokens worth of training cost per compressed model. In this paper, we present Nemotron Elastic, a framework for building reasoning-oriented LLMs, including hybrid Mamba-Attention architectures, that embed multiple nested submodels within a single parent model, each optimized for different deployment configurations and budgets. Each of these submodels shares weights with the parent model and can be extracted zero-shot during deployment without additional training or fine-tuning. We enable this functionality through an end-to-end trained router, tightly coupled to a two-stage training curriculum designed specifically for reasoning models. We additionally introduce group-aware SSM elastification that preserves Mamba's structural constraints, heterogeneous MLP elastification, normalized MSE-based layer importance for improved depth selection, and knowledge distillation enabling simultaneous multi-budget optimization. We apply Nemotron Elastic to the Nemotron Nano V2 12B model, simultaneously producing a 9B and a 6B model using only 110B training tokens; this results in over 360x cost reduction compared to training model families from scratch, and around 7x compared to SoTA compression techniques. Each of the nested models performs on par or better than the SoTA in accuracy. Moreover, unlike other compression methods, the nested capability of our approach allows having a many-in-one reasoning model that has constant deployment memory against the number of models in the family.

</details>
