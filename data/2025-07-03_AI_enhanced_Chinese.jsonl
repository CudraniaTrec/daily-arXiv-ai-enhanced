{"id": "2507.01577", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.01577", "abs": "https://arxiv.org/abs/2507.01577", "authors": ["Christoph Wernhard"], "title": "Interpolation with Automated First-Order Reasoning", "comment": "This is a chapter of the forthcoming book \"Theory and Applications of\n  Craig Interpolation\", edited by Balder ten Cate, Jean Christoph Jung, Patrick\n  Koopmann, Christoph Wernhard and Frank Wolter", "summary": "We consider interpolation from the viewpoint of fully automated theorem\nproving in first-order logic as a general core technique for mechanized\nknowledge processing. For Craig interpolation, our focus is on the two-stage\napproach, where first an essentially propositional ground interpolant is\ncalculated that is then lifted to a quantified first-order formula. We discuss\ntwo possibilities to obtain a ground interpolant from a proof, with clausal\ntableaux, and with resolution. Established preprocessing techniques for\nfirst-order proving can also be applied for Craig interpolation if they are\nrestricted in specific ways. Equality encodings from automated reasoning\njustify strengthened variations of Craig interpolation. Also further\ncontributions to Craig interpolation emerged from automated reasoning. As an\napproach to uniform interpolation we introduce second-order quantifier\nelimination with examples and describe the basic algorithms DLS and SCAN.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u901a\u8fc7\u81ea\u52a8\u5316\u4e00\u9636\u903b\u8f91\u8bc1\u660e\u5b9e\u73b0Craig\u63d2\u503c\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u4e24\u9636\u6bb5\u63d2\u503c\u8fc7\u7a0b\u3001\u5177\u4f53\u8bc1\u660e\u6280\u672f\u53ca\u5176\u6269\u5c55\uff0c\u8fd8\u4ecb\u7ecd\u4e86\u7edf\u4e00\u63d2\u503c\u7684\u4e8c\u9636\u7b97\u6cd5\uff0c\u63a8\u8fdb\u4e86\u63d2\u503c\u7406\u8bba\u548c\u5b9e\u9645\u5e94\u7528\u7684\u53d1\u5c55\u3002", "motivation": "\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u548c\u77e5\u8bc6\u5904\u7406\u7cfb\u7edf\u5e38\u4f9d\u8d56\u4e8e\u63d2\u503c\uff08interpolation\uff09\u539f\u7406\uff0c\u7279\u522b\u662fCraig\u63d2\u503c\uff0c\u5bf9\u4e8e\u63d0\u5347\u4e00\u9636\u903b\u8f91\u81ea\u52a8\u63a8\u7406\u7684\u80fd\u529b\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u63a2\u7d22\u901a\u8fc7\u81ea\u52a8\u63a8\u7406\u6280\u672f\u6709\u6548\u5b9e\u73b0\u63d2\u503c\u65b9\u6cd5\u3002", "method": "\u6587\u7ae0\u4e3b\u8981\u8ba8\u8bba\u4e24\u9636\u6bb5\u63d2\u503c\u65b9\u6cd5\uff1a\u9996\u5148\u57fa\u4e8e\u7ed9\u5b9a\u8bc1\u660e\u8ba1\u7b97\u672c\u8d28\u4e0a\u4e3a\u547d\u9898\u5316\u7684ground\u63d2\u503c\u5b50\uff0c\u968f\u540e\u63d0\u5347\u4e3a\u5e26\u91cf\u8bcd\u7684\u4e00\u9636\u516c\u5f0f\u3002\u5177\u4f53\u5229\u7528clausal tableaux\u548c\u5206\u8fa8\u7387(resolution)\u4e24\u79cd\u8bc1\u660e\u65b9\u6cd5\u83b7\u5f97ground\u63d2\u503c\u3002\u6b64\u5916\uff0c\u63a2\u8ba8\u9884\u5904\u7406\u3001\u76f8\u7b49\u6027\u7f16\u7801\u7b49\u6280\u672f\u5bf9\u63d2\u503c\u8fc7\u7a0b\u7684\u5f71\u54cd\uff0c\u5e76\u4ecb\u7ecd\u901a\u8fc7\u4e8c\u9636\u91cf\u8bcd\u6d88\u9664\uff08second-order quantifier elimination\uff09\u5b9e\u73b0uniform interpolation\uff0c\u6d89\u53caDLS\u548cSCAN\u7b49\u57fa\u672c\u7b97\u6cd5\u3002", "result": "\u57fa\u4e8e\u81ea\u52a8\u63a8\u7406\u65b9\u6cd5\uff0c\u53ef\u6709\u6548\u83b7\u5f97ground\u63d2\u503c\uff0c\u5e76\u6210\u529f\u5c06\u5176\u63d0\u5347\u4e3a\u4e00\u9636\u63d2\u503c\u5b50\u3002\u5df2\u9a8c\u8bc1clausal tableaux\u548cresolution\u5747\u9002\u7528\u3002\u7ecf\u7279\u5b9a\u9650\u5236\u7684\u9884\u5904\u7406\u6280\u672f\u548c\u76f8\u7b49\u6027\u7f16\u7801\u4e0d\u4ec5\u5bf9\u63d2\u503c\u63a8\u5bfc\u6709\u76ca\uff0c\u8fd8\u5e26\u6765\u4e86\u5bf9Craig\u63d2\u503c\u7684\u589e\u5f3a\u53d8\u4f53\u3002\u7814\u7a76\u8fdb\u4e00\u6b65\u53d1\u5c55\u4e86uniform interpolation\uff08\u7edf\u4e00\u63d2\u503c\uff09\u7684\u57fa\u672c\u7b97\u6cd5\u548c\u5b9e\u73b0\u793a\u4f8b\u3002", "conclusion": "\u81ea\u52a8\u63a8\u7406\u652f\u6301\u7684\u4e00\u9636\u903b\u8f91\u63d2\u503c\u5177\u6709\u53ef\u64cd\u4f5c\u6027\u548c\u5b9e\u7528\u6027\uff0c\u76f8\u5173\u6280\u672f\uff08\u5982clausal tableaux\u3001resolution\u3001\u76f8\u7b49\u6027\u7f16\u7801\u3001\u9884\u5904\u7406\u7b49\uff09\u63d0\u4f9b\u4e86\u7075\u6d3b\u53ef\u9760\u7684\u63d2\u503c\u751f\u6210\u65b9\u5f0f\u3002\u4e8c\u9636\u91cf\u8bcd\u6d88\u9664\u5219\u62d3\u5c55\u4e86\u63d2\u503c\u65b9\u6cd5\u7684\u5e94\u7528\u8303\u7574\u3002\u6574\u4f53\u4e0a\u63a8\u52a8\u4e86\u63d2\u503c\u7406\u8bba\u53ca\u5176\u5728\u81ea\u52a8\u77e5\u8bc6\u5904\u7406\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2507.01780", "categories": ["cs.LO", "cs.PL", "F.3.1; F.4.1; F.3.3"], "pdf": "https://arxiv.org/pdf/2507.01780", "abs": "https://arxiv.org/abs/2507.01780", "authors": ["Eric Vin", "Kyle A. Miller", "Daniel J. Fremont"], "title": "LeanLTL: A unifying framework for linear temporal logics in Lean", "comment": "9 pages, 3 figures; for associated project files see\n  https://github.com/UCSCFormalMethods/LeanLTL; to be published in LIPIcs for\n  ITP '25", "summary": "We propose LeanLTL, a unifying framework for linear temporal logics in Lean\n4. LeanLTL supports reasoning about traces that represent either infinite or\nfinite linear time. The library allows traditional LTL syntax to be combined\nwith arbitrary Lean expressions, making it straightforward to define properties\ninvolving numerical or other types. We prove that standard flavors of LTL can\nbe embedded in our framework. The library also provides automation for\nreasoning about LeanLTL formulas in a way that facilitates using Lean's\nexisting tactics. Finally, we provide examples illustrating the utility of the\nlibrary in reasoning about systems that come from applications.", "AI": {"tldr": "LeanLTL\u662f\u4e00\u4e2a\u96c6\u6210\u4e8eLean 4\u7684\u65f6\u5e8f\u903b\u8f91\u6846\u67b6\uff0c\u6269\u5c55\u4e86LTL\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u63d0\u5347\u4e86\u81ea\u52a8\u5316\u8bc1\u660e\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\uff08LTL\uff09\u7684\u6846\u67b6\u5728\u8868\u8fbe\u548c\u8bc1\u660e\u4e0d\u540c\u7c7b\u578b\uff08\u5982\u6570\u503c\uff09\u7684\u5c5e\u6027\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4e14\u7f3a\u4e4f\u4fbf\u4e8e\u81ea\u52a8\u63a8\u7406\u548c\u6574\u5408\u73b0\u4ee3\u8bc1\u660e\u52a9\u7406\uff08\u5982Lean 4\uff09\u7684\u5de5\u5177\u3002", "method": "\u4f5c\u8005\u63d0\u51faLeanLTL\uff0c\u8fd9\u662f\u4e00\u4e2a\u53ef\u4ee5\u96c6\u6210\u4e8eLean 4\u8bc1\u660e\u52a9\u7406\uff0c\u652f\u6301\u6709\u9650\u4e0e\u65e0\u9650\u65f6\u95f4\u8f68\u8ff9\u63a8\u7406\u7684LTL\u7edf\u4e00\u6846\u67b6\u3002LeanLTL\u5141\u8bb8\u5c06\u4f20\u7edfLTL\u8bed\u6cd5\u4e0e\u4efb\u610fLean\u8868\u8fbe\u5f0f\u7ed3\u5408\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u652f\u6301\u7528Lean\u73b0\u6709\u6218\u672f\u9ad8\u6548\u63a8\u7406\u548c\u8bc1\u660e\u3002", "result": "LeanLTL\u6846\u67b6\u80fd\u591f\u5d4c\u5165\u6807\u51c6LTL\u53d8\u4f53\uff0c\u5e76\u901a\u8fc7\u63d0\u4f9b\u81ea\u52a8\u5316\u5de5\u5177\u63d0\u5347\u4e86\u5728Lean 4\u4e2d\u5bf9\u65f6\u5e8f\u903b\u8f91\u516c\u5f0f\u7684\u63a8\u7406\u6548\u7387\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u793a\u4f8b\u5c55\u793a\u4e86\u8be5\u5e93\u5728\u5404\u7c7b\u7cfb\u7edf\u63a8\u7406\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "LeanLTL\u5b9e\u73b0\u4e86\u5bf9\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\u7684\u7edf\u4e00\u652f\u6301\uff0c\u4e0d\u4ec5\u589e\u5f3a\u4e86LTL\u8868\u8fbe\u80fd\u529b\uff0c\u4e5f\u63d0\u5347\u4e86\u4e0eLean 4\u6574\u5408\u4e0b\u7684\u8bc1\u660e\u6d41\u7a0b\u6548\u7387\uff0c\u5bf9\u7cfb\u7edf\u5c5e\u6027\u5f62\u5f0f\u5316\u5206\u6790\u548c\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2507.01459", "categories": ["cs.DM", "cs.LO", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.01459", "abs": "https://arxiv.org/abs/2507.01459", "authors": ["Yijia Chen", "J\u00f6rg Flum", "Mingjun Liu"], "title": "Some remarks on the uncolored versions of the original CFI-graphs", "comment": "46 pages", "summary": "The CFI-graphs, named after Cai, F\\\"urer, and Immerman, are central to the\nstudy of the graph isomorphism testing and of first-order logic with counting.\nThey are colored graphs, and the coloring plays a role in many of their\napplications. As usual, it is not hard to remove the coloring by some extra\ngraph gadgets, but at the cost of blowing up the size of the graphs and\nchanging some parameters of them as well. This might lead to suboptimal\ncombinatorial bounds important to their applications. Since then for some\nuncolored variants of the CFI-graphs it has been shown that they serve the same\npurposes. We show that this already applies to the graphs obtained from the\noriginal CFI-graphs by forgetting the colors. Moreover, we will see that there\nis a first-order formula $\\varphi(x,y)$ expressing in almost all uncolored\nCFI-graphs that $x$ and $y$ have the same color in the corresponding colored\ngraphs.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u539f\u59cbCFI-graphs\u53bb\u9664\u989c\u8272\u540e\u5373\u53ef\u6ee1\u8db3\u5927\u591a\u6570\u76f8\u5173\u5e94\u7528\uff0c\u65e0\u9700\u5f15\u5165\u4f53\u79ef\u8f83\u5927\u7684\u989d\u5916\u7ed3\u6784\uff0c\u5e76\u53ef\u5229\u7528\u4e00\u9636\u516c\u5f0f\u590d\u539f\u539f\u6709\u8272\u5f69\u5206\u7ec4\u3002", "motivation": "\u6709\u8272CFI-graphs\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u53bb\u8272\u64cd\u4f5c\u9700\u5f15\u5165\u989d\u5916\u88c5\u7f6e\uff0c\u5bfc\u81f4\u56fe\u89c4\u6a21\u81a8\u80c0\u548c\u53c2\u6570\u53d8\u52a8\uff0c\u8fd9\u53ef\u80fd\u5f71\u54cd\u76f8\u5173\u7ec4\u5408\u754c\uff0c\u5bf9\u5b9e\u9645\u5e94\u7528\u4e0d\u7406\u60f3\u3002\u5e0c\u671b\u9a8c\u8bc1\u539f\u59cbCFI-graphs\u5728\u53bb\u8272\u540e\u4ecd\u53ef\u6ee1\u8db3\u9700\u6c42\u3002", "method": "\u4ee5\u6570\u5b66\u8bc1\u660e\u4e3a\u4e3b\uff0c\u901a\u8fc7\u6784\u9020\u4e00\u9636\u903b\u8f91\u516c\u5f0f\uff0c\u5206\u6790\u65e0\u8272CFI-graphs\u662f\u5426\u53ef\u66ff\u4ee3\u6709\u8272\u7248\u672c\uff0c\u5e76\u8bc1\u660e\u8be5\u7ed3\u8bba\u3002", "result": "\u539f\u59cbCFI-graphs\u53bb\u8272\u540e\u65e0\u9700\u5f15\u5165\u989d\u5916\u7ed3\u6784\u5373\u53ef\u6ee1\u8db3\u5e94\u7528\u9700\u6c42\uff0c\u5e76\u7ed9\u51fa\u4e00\u9636\u516c\u5f0f$\u001b(x,y)$\u5728\u65e0\u8272\u56fe\u4e2d\u8868\u8fbe\u539f\u8272\u4fe1\u606f\u3002", "conclusion": "\u5df2\u7ecf\u8bc1\u660e\u53ea\u9700\u5fd8\u8bb0\u989c\u8272\u4fe1\u606f\uff0c\u539f\u59cbCFI-graphs\u4ecd\u80fd\u5b9e\u73b0\u7c7b\u4f3c\u5e94\u7528\u76ee\u7684\uff0c\u4e14\u53ef\u7528\u4e00\u9636\u516c\u5f0f\u5728\u65e0\u8272CFI-graphs\u95f4\u8868\u8fbe\u70b9\u539f\u6709\u989c\u8272\u4e00\u81f4\u6027\u3002"}}
{"id": "2507.01036", "categories": ["cs.FL", "cs.AI", "math.LO"], "pdf": "https://arxiv.org/pdf/2507.01036", "abs": "https://arxiv.org/abs/2507.01036", "authors": ["Seth Bulin"], "title": "Systemic Constraints of Undecidability", "comment": "Submitted version; includes appendices with formal definitions and\n  structural embeddings. Prepared in Nature Computational Science format.\n  Keywords: computability theory, undecidability, causal systems, structural\n  closure, recursion theory, Turing machines, hypercomputation,\n  metaundecidability, epistemic limits, consciousness, modeling limits", "summary": "This paper presents a theory of systemic undecidability, reframing\nincomputability as a structural property of systems rather than a localized\nfeature of specific functions or problems. We define a notion of causal\nembedding and prove a closure principle: any subsystem that participates\nfunctionally in the computation of an undecidable system inherits its\nundecidability. This result positions undecidability as a pervasive constraint\non prediction, modeling, and epistemic access in both natural and artificial\nsystems. Our framework disarms oracle mimicry and challenges the view that\ncomputational limits can be circumvented through architectural innovation. By\ngeneralizing classical results into a dynamic systems context, this work\naugments the logical trajectory of G\\\"odel, Turing, and Chaitin, offering a new\nperspective of the topology of computability and its interrelation to the\nboundaries of scientific knowledge.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e0d\u53ef\u5224\u5b9a\u6027\u662f\u7cfb\u7edf\u7684\u7ed3\u6784\u6027\u7279\u5f81\uff0c\u4efb\u4f55\u53c2\u4e0e\u4e0d\u53ef\u5224\u5b9a\u7cfb\u7edf\u7684\u5b50\u7cfb\u7edf\u4e5f\u5fc5\u7136\u7ee7\u627f\u8be5\u4e0d\u53ef\u5224\u5b9a\u6027\uff0c\u98a0\u8986\u4e86\u901a\u8fc7\u67b6\u6784\u521b\u65b0\u53ef\u4ee5\u7ed5\u5f00\u7ecf\u5178\u8ba1\u7b97\u6781\u9650\u7684\u89c2\u70b9\uff0c\u5bf9\u79d1\u5b66\u5efa\u6a21\u548c\u77e5\u8bc6\u83b7\u53d6\u6709\u5e7f\u6cdb\u5f71\u54cd\u3002", "motivation": "\u4f20\u7edf\u4e0a\u8ba4\u4e3a\u4e0d\u53ef\u8ba1\u7b97\u6027\u662f\u67d0\u4e9b\u7279\u5b9a\u51fd\u6570\u6216\u95ee\u9898\u7684\u5c5e\u6027\uff0c\u4f46\u8be5\u6587\u63d0\u51fa\u5c06\u5176\u89c6\u4e3a\u7cfb\u7edf\u7684\u7ed3\u6784\u6027\u7279\u5f81\u3002\u4f5c\u8005\u5e0c\u671b\u66f4\u6df1\u5165\u63ed\u793a\u4e0d\u53ef\u5224\u5b9a\u6027\u5bf9\u81ea\u7136\u548c\u4eba\u5de5\u7cfb\u7edf\u9884\u6d4b\u3001\u5efa\u6a21\u53ca\u77e5\u8bc6\u83b7\u53d6\u7684\u666e\u904d\u5f71\u54cd\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u56e0\u679c\u5d4c\u5165\uff08causal embedding\uff09\u7684\u6982\u5ff5\uff0c\u5e76\u8bc1\u660e\u4e86\u4e00\u4e2a\u95ed\u5305\u539f\u7406\uff1a\u53ea\u8981\u67d0\u4e2a\u5b50\u7cfb\u7edf\u5728\u4e00\u4e2a\u4e0d\u53ef\u5224\u5b9a\u7cfb\u7edf\u4e2d\u8d77\u529f\u80fd\u6027\u4f5c\u7528\uff0c\u5219\u8be5\u5b50\u7cfb\u7edf\u4e5f\u5fc5\u7136\u7ee7\u627f\u4e0d\u53ef\u5224\u5b9a\u6027\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u63a8\u5e7f\uff0c\u5c06\u4e0d\u53ef\u5224\u5b9a\u95ee\u9898\u653e\u5230\u52a8\u529b\u7cfb\u7edf\u7684\u6846\u67b6\u4e0b\u8ba8\u8bba\u3002", "result": "\u8bc1\u660e\u4e86\u4e0d\u53ef\u5224\u5b9a\u6027\u662f\u7cfb\u7edf\u5185\u5e7f\u6cdb\u5b58\u5728\u7684\u7ed3\u6784\u6027\u9650\u5236\uff0c\u53c2\u4e0e\u4e0d\u53ef\u5224\u5b9a\u7cfb\u7edf\u8ba1\u7b97\u7684\u6240\u6709\u5b50\u7cfb\u7edf\u90fd\u4f1a\u7ee7\u627f\u4e0d\u53ef\u5224\u5b9a\u6027\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u7684\u7406\u8bba\u6846\u67b6\u53cd\u9a73\u4e86\u8bd5\u56fe\u7528\u201c\u795e\u8c15\u673a\u201d\u6216\u65b0\u67b6\u6784\u7ed5\u8fc7\u8ba1\u7b97\u6781\u9650\u7684\u89c2\u70b9\uff0c\u5e76\u6269\u5c55\u4e86\u6570\u7406\u903b\u8f91\u548c\u53ef\u8ba1\u7b97\u6027\u7406\u8bba\u7684\u7ecf\u5178\u7ed3\u8bba\u3002", "conclusion": "\u4e0d\u53ef\u5224\u5b9a\u6027\u5e94\u88ab\u89c6\u4e3a\u7cfb\u7edf\u6027\u7684\u7ed3\u6784\u5c5e\u6027\uff0c\u800c\u975e\u5c40\u90e8\u529f\u80fd\u9650\u5236\u3002\u8fd9\u4e00\u89c6\u89d2\u63ed\u793a\u4e86\u8ba1\u7b97\u4e0e\u79d1\u5b66\u77e5\u8bc6\u8fb9\u754c\u4e4b\u95f4\u65b0\u7684\u62d3\u6251\u5173\u7cfb\uff0c\u5bf9\u81ea\u7136\u548c\u4eba\u5de5\u7cfb\u7edf\u7684\u53ef\u9884\u6d4b\u6027\u548c\u5efa\u6a21\u80fd\u529b\u8bbe\u5b9a\u4e86\u6df1\u523b\u9650\u5236\u3002"}}
{"id": "2507.01019", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.01019", "abs": "https://arxiv.org/abs/2507.01019", "authors": ["Imran Mirza", "Cole Huang", "Ishwara Vasista", "Rohan Patil", "Asli Akalin", "Sean O'Brien", "Kevin Zhu"], "title": "MALIBU Benchmark: Multi-Agent LLM Implicit Bias Uncovered", "comment": "Accepted to Building Trust in LLMs @ ICLR 2025 and NAACL SRW 2025", "summary": "Multi-agent systems, which consist of multiple AI models interacting within a\nshared environment, are increasingly used for persona-based interactions.\nHowever, if not carefully designed, these systems can reinforce implicit biases\nin large language models (LLMs), raising concerns about fairness and equitable\nrepresentation. We present MALIBU, a novel benchmark developed to assess the\ndegree to which LLM-based multi-agent systems implicitly reinforce social\nbiases and stereotypes. MALIBU evaluates bias in LLM-based multi-agent systems\nthrough scenario-based assessments. AI models complete tasks within predefined\ncontexts, and their responses undergo evaluation by an LLM-based multi-agent\njudging system in two phases. In the first phase, judges score responses\nlabeled with specific demographic personas (e.g., gender, race, religion)\nacross four metrics. In the second phase, judges compare paired responses\nassigned to different personas, scoring them and selecting the superior\nresponse. Our study quantifies biases in LLM-generated outputs, revealing that\nbias mitigation may favor marginalized personas over true neutrality,\nemphasizing the need for nuanced detection, balanced fairness strategies, and\ntransparent evaluation benchmarks in multi-agent systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMALIBU\u57fa\u51c6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u591a\u667a\u80fd\u4f53LLM\u5bf9\u793e\u4f1a\u504f\u89c1\u7684\u52a0\u5267\u73b0\u8c61\uff0c\u53d1\u73b0\u73b0\u6709\u504f\u89c1\u6d88\u51cf\u65b9\u6cd5\u53ef\u80fd\u8fc7\u5ea6\u503e\u659c\u4e8e\u8fb9\u7f18\u7fa4\u4f53\uff0c\u547c\u5401\u66f4\u5e73\u8861\u516c\u6b63\u7684\u68c0\u6d4b\u6807\u51c6\u548c\u8bc4\u6d4b\u624b\u6bb5\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u4ee5\u4eba\u4e3a\u672c\u7684\u4e92\u52a8\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u8bbe\u8ba1\u4e0d\u5f53\u4f1a\u52a0\u5267\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u7684\u9690\u6027\u504f\u89c1\uff0c\u5f71\u54cd\u516c\u5e73\u6027\u548c\u591a\u6837\u5316\u8868\u8fbe\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u8bc4\u4f30\u548c\u91cf\u5316\u6b64\u7c7b\u7cfb\u7edf\u4e2d\u9690\u6027\u793e\u4f1a\u504f\u89c1\u7684\u5de5\u5177\u548c\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86MALIBU\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u662f\u5426\u9690\u6027\u5f3a\u5316\u793e\u4f1a\u504f\u89c1\u548c\u523b\u677f\u5370\u8c61\u7684\u57fa\u51c6\u3002MALIBU\u901a\u8fc7\u60c5\u666f\u4efb\u52a1\u8ba9AI\u6a21\u578b\u5728\u6307\u5b9a\u80cc\u666f\u4e0b\u4f5c\u7b54\uff0c\u5e76\u91c7\u7528\u4e24\u9636\u6bb5LLM\u591a\u667a\u80fd\u4f53\u88c1\u51b3\u4f53\u7cfb\uff1a\u7b2c\u4e00\u9636\u6bb5\u6309\u7279\u5b9a\u4eba\u53e3\u8eab\u4efd\u6807\u7b7e\u8bc4\u5206\uff0c\u7b2c\u4e8c\u9636\u6bb5\u6bd4\u8f83\u4e0d\u540c\u8eab\u4efd\u6807\u7b7e\u4f5c\u7b54\u5e76\u7efc\u5408\u8bc4\u5206\u3001\u62e9\u4f18\u3002", "result": "\u7814\u7a76\u91cf\u5316\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u751f\u6210\u5185\u5bb9\u4e2d\u7684\u504f\u89c1\uff0c\u5e76\u53d1\u73b0\u504f\u89c1\u53bb\u9664\u63aa\u65bd\u6709\u65f6\u53ef\u80fd\u504f\u5411\u8fb9\u7f18\u5316\u7fa4\u4f53\u800c\u975e\u771f\u6b63\u4e2d\u7acb\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u6d88\u9664\u504f\u89c1\u65f6\u5bb9\u6613\u5931\u8861\uff0c\u5b58\u5728\u5bf9\u8fb9\u7f18\u5316\u7fa4\u4f53\u7684\u989d\u5916\u504f\u5411\uff0c\u9700\u8981\u66f4\u52a0\u7ec6\u81f4\u7684\u68c0\u6d4b\u4e0e\u516c\u5e73\u7b56\u7565\uff0c\u4ee5\u53ca\u900f\u660e\u7684\u8bc4\u6d4b\u57fa\u51c6\u3002"}}
{"id": "2507.01272", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2507.01272", "abs": "https://arxiv.org/abs/2507.01272", "authors": ["Zixuan Zhu"], "title": "Advanced LPeg techniques: A dual case study approach", "comment": null, "summary": "This paper presents advanced optimization techniques for Lua Parsing\nExpression Grammars (LPeg) through two complementary case studies: a\nhigh-performance JSON parser and a sophisticated Glob-to-LPeg pattern\nconverter. We demonstrate how strategic grammar construction can dramatically\nimprove parsing performance without modifying the underlying LPeg library. For\nthe JSON parser, we implement substitution capture and table construction\noptimization to reduce memory allocation overhead and improve object\nprocessing. For the Glob converter, we introduce segment-boundary separation,\nimplement Cox's flattened search strategy, and develop optimized braced\ncondition handling to prevent exponential backtracking. Comprehensive\nbenchmarks demonstrate that our JSON parser achieves processing speeds up to\n125 MB/s on complex documents, consistently outperforming dkjson and showing\ncompetitive results against rxi_json across most test cases. Our Glob-to-LPeg\nconverter exhibits 14-92% better performance than Bun.Glob and runs 3-14 times\nfaster than Minimatch across diverse pattern matching scenarios. This research\nprovides practical optimization techniques for LPeg-based parsers, contributing\nvaluable strategies to the text processing ecosystem.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u4f18\u5316\u8bed\u6cd5\u7ed3\u6784\u548c\u5b9e\u73b0\u7b56\u7565\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u57fa\u4e8eLPeg\u7684JSON\u89e3\u6790\u5668\u548cGlob\u6a21\u5f0f\u8f6c\u6362\u5668\u7684\u6027\u80fd\uff0c\u65e0\u9700\u4fee\u6539\u5e95\u5c42\u5e93\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u5de5\u5177\uff0c\u4e3a\u6587\u672c\u89e3\u6790\u9886\u57df\u8d21\u732e\u4e86\u5b9e\u7528\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "motivation": "\u63d0\u5347\u57fa\u4e8eLPeg\u7684\u89e3\u6790\u5668\u5728\u5b9e\u9645\u4efb\u52a1\uff08\u5982JSON\u89e3\u6790\u548cGlob\u6a21\u5f0f\u8f6c\u6362\uff09\u4e2d\u7684\u6027\u80fd\u8868\u73b0\uff0c\u89e3\u51b3\u89e3\u6790\u901f\u5ea6\u548c\u5185\u5b58\u4f7f\u7528\u4f18\u5316\u96be\u9898\u3002", "method": "\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\uff1a1) \u5bf9JSON\u89e3\u6790\u5668\u8fdb\u884c\u8bed\u6cd5\u7ed3\u6784\u4f18\u5316\u3001\u66ff\u4ee3\u6355\u83b7\u548c\u8868\u6784\u9020\u4f18\u5316\uff1b2) \u5728Glob\u5230LPeg\u6a21\u5f0f\u8f6c\u6362\u5de5\u5177\u4e2d\u91c7\u7528\u5206\u6bb5\u8fb9\u754c\u5206\u79bb\u3001Cox\u7684\u6241\u5e73\u641c\u7d22\u7b56\u7565\u548c\u4f18\u5316\u7684\u5927\u62ec\u53f7\u6761\u4ef6\u5904\u7406\u3002\u6240\u6709\u4f18\u5316\u5747\u4e0d\u9700\u4fee\u6539LPeg\u5e93\u672c\u8eab\u3002", "result": "\u4f18\u5316\u540e\u7684JSON\u89e3\u6790\u5668\u5904\u7406\u901f\u5ea6\u9ad8\u8fbe125MB/s\uff0c\u6027\u80fd\u8d85\u8d8adkjson\uff0c\u5e76\u5728\u591a\u6570\u60c5\u51b5\u4e0b\u6bd4rxi_json\u8868\u73b0\u4f18\u5f02\u3002Glob\u8f6c\u6362\u5668\u6bd4Bun.Glob\u5feb14%-92%\uff0c\u6bd4Minimatch\u5feb3-14\u500d\u3002", "conclusion": "\u6587\u4e2d\u63d0\u51fa\u7684\u4f18\u5316\u6280\u672f\u80fd\u591f\u663e\u8457\u63d0\u5347\u57fa\u4e8eLPeg\u7684\u89e3\u6790\u5668\u7684\u6027\u80fd\uff0c\u5e76\u4e3a\u6587\u672c\u5904\u7406\u63d0\u4f9b\u4e86\u53ef\u884c\u4e14\u6709\u6548\u7684\u4f18\u5316\u7b56\u7565\u3002"}}
{"id": "2507.01065", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.01065", "abs": "https://arxiv.org/abs/2507.01065", "authors": ["Christiaan Verwijs", "Evelien Acun-Roos", "Daniel Russo"], "title": "Is It Safe To Learn And Share? On Psychological Safety and Social Learning in (Agile) Communities of Practice", "comment": null, "summary": "As hybrid, distributed, and asynchronous work models become more prevalent,\ncontinuous learning in Agile Software Development (ASD) gains renewed\nimportance. Communities of Practice (CoPs) are increasingly adopted to support\nsocial learning beyond formal education, often relying on virtual\ncommunication. Psychological safety, a prerequisite for effective learning,\nremains insufficiently understood in these settings. This mixed-methods study\ninvestigates psychological safety within Agile CoPs through survey data from\n143 participants. Results indicate that psychological safety is significantly\nlower in online interactions compared to face-to-face settings. Moreover, low\npsychological safety reduces participants' intent to continue contributing and\navoidance of interpersonal risk. No significant differences emerged based on\ngender, community seniority, or content creation activity. However, differences\nby role and age group suggest potential generational or role-related effects.\nThematic analysis revealed exclusionary behavior, negative interaction\npatterns, and hostility as primary threats to psychological safety, often\nreinforced by tribalism and specific community dynamics. Suggested\ninterventions include establishing explicit norms, structured facilitation, and\nactive moderation. The findings were validated through member checking with 30\nparticipants. This study provides a comparative perspective on interaction\nmodalities and offers practical guidance for organizers seeking to cultivate\ninclusive, high-impact CoPs and similarly structured virtual or hybrid work\nenvironments.", "AI": {"tldr": "\u7ebf\u4e0a\u5b9e\u8df5\u5171\u540c\u4f53\u5fc3\u7406\u5b89\u5168\u611f\u8f83\u7ebf\u4e0b\u66f4\u4f4e\uff0c\u5f71\u54cd\u6210\u5458\u53c2\u4e0e\u548c\u98ce\u9669\u627f\u53d7\u3002\u4e3b\u8981\u5a01\u80c1\u4e3a\u6392\u4ed6\u548c\u654c\u5bf9\u884c\u4e3a\uff0c\u5efa\u8bae\u901a\u8fc7\u660e\u786e\u89c4\u8303\u548c\u79ef\u6781\u7ba1\u7406\u63d0\u5347\u6c1b\u56f4\u3002", "motivation": "\u968f\u7740\u6df7\u5408\u3001\u5206\u5e03\u5f0f\u548c\u5f02\u6b65\u5de5\u4f5c\u6a21\u5f0f\u7684\u6d41\u884c\uff0c\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5bf9\u6301\u7eed\u5b66\u4e60\u7684\u9700\u6c42\u65e5\u76ca\u589e\u52a0\uff0c\u800c\u5b9e\u8df5\u5171\u540c\u4f53\uff08CoP\uff09\u88ab\u5e7f\u6cdb\u4f5c\u4e3a\u652f\u6301\u793e\u4f1a\u6027\u5b66\u4e60\u7684\u4e00\u79cd\u65b9\u5f0f\u3002\u5b9e\u9645\u4e2d\uff0c\u865a\u62df\u4ea4\u6d41\u6108\u53d1\u666e\u904d\uff0c\u4f46\u5728\u8fd9\u7c7b\u73af\u5883\u4e0b\u5b9e\u73b0\u5fc3\u7406\u5b89\u5168\u7684\u673a\u5236\u5e76\u4e0d\u660e\u786e\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u65e8\u5728\u63a2\u7a76\u654f\u6377CoP\u4e2d\uff0c\u5c24\u5176\u662f\u5728\u7ebf\u4ea4\u6d41\u73af\u5883\u4e0b\u7684\u5fc3\u7406\u5b89\u5168\u72b6\u51b5\u53ca\u5176\u5f71\u54cd\u56e0\u7d20\u3002", "method": "\u4f5c\u8005\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\u3002\u9996\u5148\uff0c\u901a\u8fc7\u5bf9143\u540d\u5b9e\u8df5\u5171\u540c\u4f53\u6210\u5458\u7684\u95ee\u5377\u8c03\u67e5\u6536\u96c6\u6570\u636e\uff0c\u5e76\u7ed3\u5408\u5b9a\u6027\u4e3b\u9898\u5206\u6790\u6765\u6df1\u5165\u7406\u89e3\u5fc3\u7406\u5b89\u5168\u7684\u5a01\u80c1\u548c\u76f8\u5173\u4e92\u52a8\u6a21\u5f0f\u3002\u4e3a\u589e\u5f3a\u7ed3\u8bba\u53ef\u9760\u6027\uff0c\u8fd8\u8fdb\u884c\u4e86\u6210\u5458\u6838\u67e5\uff08member checking\uff09\uff0c\u9080\u8bf730\u4f4d\u53c2\u4e0e\u8005\u5bf9\u5206\u6790\u7ed3\u679c\u8fdb\u884c\u53cd\u9988\u9a8c\u8bc1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u7ebf\u73af\u5883\u4e0b\u7684\u5fc3\u7406\u5b89\u5168\u611f\u663e\u8457\u4f4e\u4e8e\u9762\u5bf9\u9762\u4ea4\u6d41\u73af\u5883\u3002\u5fc3\u7406\u5b89\u5168\u8f83\u4f4e\u4f1a\u5bfc\u81f4\u6210\u5458\u51cf\u5c11\u7ee7\u7eed\u8d21\u732e\u7684\u610f\u613f\uff0c\u5e76\u503e\u5411\u4e8e\u89c4\u907f\u4eba\u9645\u98ce\u9669\u3002\u6027\u522b\u3001\u793e\u533a\u8d44\u5386\u548c\u5185\u5bb9\u521b\u4f5c\u6d3b\u8dc3\u5ea6\u5e76\u672a\u5e26\u6765\u663e\u8457\u5dee\u5f02\uff0c\u4f46\u89d2\u8272\u548c\u5e74\u9f84\u7ec4\u5b58\u5728\u5dee\u5f02\uff0c\u6697\u793a\u6709\u4ee3\u9645\u6216\u804c\u4f4d\u76f8\u5173\u6548\u5e94\u3002\u4e3b\u9898\u5206\u6790\u63ed\u793a\u4e86\u6392\u4ed6\u884c\u4e3a\u3001\u6d88\u6781\u4e92\u52a8\u548c\u654c\u610f\u4f5c\u4e3a\u4e3b\u8981\u5fc3\u7406\u5b89\u5168\u5a01\u80c1\uff0c\u5e76\u5e38\u88ab\u90e8\u843d\u4e3b\u4e49\u4e0e\u793e\u533a\u7279\u5b9a\u52a8\u6001\u5f3a\u5316\u3002\u4f5c\u8005\u5efa\u8bae\u901a\u8fc7\u660e\u786e\u89c4\u8303\u3001\u7ed3\u6784\u5316\u5f15\u5bfc\u548c\u79ef\u6781\u7ba1\u7406\u7b49\u65b9\u5f0f\u52a0\u4ee5\u5e72\u9884\u3002", "conclusion": "\u672c\u7814\u7a76\u7cfb\u7edf\u5bf9\u6bd4\u4e86\u4e0d\u540c\u4ea4\u6d41\u6a21\u5f0f\u4e0b\u7684\u5fc3\u7406\u5b89\u5168\u6c34\u5e73\uff0c\u63d0\u51fa\u4e86\u63d0\u5347\u5728\u7ebf/\u865a\u62df\u5b9e\u8df5\u5171\u540c\u4f53\u5305\u5bb9\u6027\u548c\u5f71\u54cd\u529b\u7684\u5b9e\u7528\u5efa\u8bae\uff0c\u5bf9\u4e8e\u865a\u62df/\u6df7\u5408\u5de5\u4f5c\u73af\u5883\u7684\u793e\u533a\u7ec4\u7ec7\u8005\u5177\u5907\u53c2\u8003\u4ef7\u503c\u3002"}}
{"id": "2507.01759", "categories": ["cs.DM", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.01759", "abs": "https://arxiv.org/abs/2507.01759", "authors": ["Nour ElHouda Tellache", "Lydia Aoudia", "Mourad Boudhar"], "title": "Scheduling on identical machines with conflicts to minimize the mean flow time", "comment": null, "summary": "This paper addresses the problem of scheduling jobs on identical machines\nwith conflict constraints, where certain jobs cannot be scheduled\nsimultaneously on different machines. We focus on the case where conflicts can\nbe represented by a simple undirected graph, and the objective is to minimize\nthe mean flow time. We show that the problem is NP-hard even on two machines\nand two distinct processing times. For unit-time jobs, the problem becomes\nNP-hard when the number of machines increases to three. We also identify\npolynomial-time solvable cases for specific classes of conflict graphs. For the\ngeneral problem, we propose mathematical models, lower bounds, and a genetic\nalgorithm. We evaluate their performance through computational experiments on a\nwide range of instances derived from well-known benchmark instances in the\nliterature.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u591a\u673a\u5e26\u51b2\u7a81\u7ea6\u675f\u7684\u8c03\u5ea6\u95ee\u9898\uff0c\u8bc1\u660e\u5176NP\u96be\u6027\uff0c\u63d0\u51fa\u6570\u5b66\u6a21\u578b\u548c\u9057\u4f20\u7b97\u6cd5\u5e76\u5728\u7b97\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4f5c\u8005\u7814\u7a76\u7684\u662f\u5728\u76f8\u540c\u673a\u5668\u4e0a\u5e26\u6709\u51b2\u7a81\u7ea6\u675f\u7684\u4f5c\u4e1a\u8c03\u5ea6\u95ee\u9898\uff0c\u5373\u67d0\u4e9b\u4f5c\u4e1a\u4e0d\u80fd\u540c\u65f6\u5728\u4e0d\u540c\u673a\u5668\u4e0a\u8c03\u5ea6\u3002\u8be5\u95ee\u9898\u5728\u5b9e\u9645\u4e2d\u5177\u6709\u666e\u904d\u6027\u548c\u5e94\u7528\u4ef7\u503c\uff0c\u5982\u8d44\u6e90\u5171\u4eab\u53d7\u9650\u7684\u751f\u4ea7\u73af\u5883\u3002", "method": "\u91c7\u7528\u56fe\u8bba\u65b9\u6cd5\u5c06\u51b2\u7a81\u5efa\u6a21\u4e3a\u7b80\u5355\u65e0\u5411\u56fe\u3002\u9488\u5bf9\u8be5\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u6570\u5b66\u6a21\u578b\u3001\u4e0b\u754c\u8ba1\u7b97\u65b9\u6cd5\u4ee5\u53ca\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u6c42\u89e3\u65b9\u6cd5\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u5927\u91cf\u57fa\u51c6\u5b9e\u4f8b\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a\u5373\u4f7f\u5728\u53ea\u6709\u4e24\u53f0\u673a\u5668\u53ca\u4e24\u79cd\u4e0d\u540c\u52a0\u5de5\u65f6\u95f4\u4e0b\uff0c\u95ee\u9898\u5df2\u4e3aNP\u96be\uff1b\u5bf9\u4e8e\u5355\u4f4d\u65f6\u95f4\u4f5c\u4e1a\uff0c\u4e09\u53f0\u673a\u5668\u65f6\u95ee\u9898\u4e5f\u4e3aNP\u96be\u3002\u4f5c\u8005\u8fd8\u53d1\u73b0\u4e86\u5bf9\u4e8e\u67d0\u4e9b\u7279\u6b8a\u51b2\u7a81\u56fe\u7c7b\u522b\uff0c\u53ef\u4ee5\u591a\u9879\u5f0f\u65f6\u95f4\u6c42\u89e3\u3002\u9057\u4f20\u7b97\u6cd5\u548c\u4e0b\u754c\u5728\u7b97\u4f8b\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u5e26\u6709\u51b2\u7a81\u7ea6\u675f\u7684\u591a\u673a\u6700\u5c0f\u5e73\u5747\u6d41\u52a8\u65f6\u95f4\u8c03\u5ea6\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u63d0\u51fa\u4e86\u6709\u6548\u7684\u6570\u5b66\u6a21\u578b\u548c\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.01160", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01160", "abs": "https://arxiv.org/abs/2507.01160", "authors": ["Huiling You", "Samia Touileb", "Erik Velldal", "Lilja \u00d8vrelid"], "title": "Event-based evaluation of abstractive news summarization", "comment": "to appear at GEM2 workshop@ACL 2025", "summary": "An abstractive summary of a news article contains its most important\ninformation in a condensed version. The evaluation of automatically generated\nsummaries by generative language models relies heavily on human-authored\nsummaries as gold references, by calculating overlapping units or similarity\nscores. News articles report events, and ideally so should the summaries. In\nthis work, we propose to evaluate the quality of abstractive summaries by\ncalculating overlapping events between generated summaries, reference\nsummaries, and the original news articles. We experiment on a richly annotated\nNorwegian dataset comprising both events annotations and summaries authored by\nexpert human annotators. Our approach provides more insight into the event\ninformation contained in the summaries.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u8ba1\u7b97\u4e8b\u4ef6\u91cd\u53e0\u6765\u8bc4\u4f30\u81ea\u52a8\u751f\u6210\u65b0\u95fb\u6458\u8981\u5185\u5bb9\u7684\u65b9\u6cd5\uff0c\u5728\u632a\u5a01\u8bed\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u80fd\u591f\u66f4\u597d\u5730\u8861\u91cf\u6458\u8981\u4e2d\u7684\u5173\u952e\u4fe1\u606f\u4f20\u9012\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u751f\u6210\u6587\u672c\u6458\u8981\u7684\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u4e8e\u4e0e\u4eba\u5de5\u6458\u8981\u7684\u91cd\u53e0\u5ea6\u6216\u76f8\u4f3c\u5ea6\u5206\u6570\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5e76\u672a\u771f\u6b63\u5173\u6ce8\u65b0\u95fb\u6838\u5fc3\uff0c\u5373\u4e8b\u4ef6\u5185\u5bb9\u7684\u4f20\u9012\u3002\u4f5c\u8005\u5e0c\u671b\u66f4\u597d\u5730\u8861\u91cf\u6458\u8981\u5bf9\u65b0\u95fb\u4e8b\u4ef6\u4fe1\u606f\u7684\u4fdd\u7559\u60c5\u51b5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8b\u4ef6\u91cd\u53e0\u6765\u8bc4\u4f30\u81ea\u52a8\u751f\u6210\u65b0\u95fb\u6458\u8981\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6bd4\u5bf9\u751f\u6210\u6458\u8981\u3001\u4eba\u5de5\u6458\u8981\u4e0e\u539f\u59cb\u65b0\u95fb\u4e2d\u7684\u4e8b\u4ef6\u91cd\u53e0\u5ea6\u8fdb\u884c\u8bc4\u4ef7\u3002\u5b9e\u9a8c\u4f7f\u7528\u5e26\u6709\u4e30\u5bcc\u4e8b\u4ef6\u6ce8\u91ca\u548c\u4e13\u5bb6\u7f16\u5199\u6458\u8981\u7684\u632a\u5a01\u8bed\u6570\u636e\u96c6\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u4e3a\u6458\u8981\u6240\u5305\u542b\u4e8b\u4ef6\u4fe1\u606f\u7684\u8861\u91cf\u63d0\u4f9b\u66f4\u6df1\u5165\u7684\u6d1e\u89c1\uff0c\u4ece\u4e8b\u4ef6\u89c6\u89d2\u66f4\u597d\u5730\u53cd\u6620\u6458\u8981\u8d28\u91cf\u3002", "conclusion": "\u57fa\u4e8e\u4e8b\u4ef6\u91cd\u53e0\u7684\u8bc4\u4f30\u65b9\u6cd5\u80fd\u591f\u5f25\u8865\u4f20\u7edf\u6458\u8981\u81ea\u52a8\u8bc4\u4f30\u7684\u4e0d\u8db3\uff0c\u66f4\u52a0\u5173\u6ce8\u65b0\u95fb\u6458\u8981\u4e2d\u5173\u952e\u4fe1\u606f\uff08\u5373\u4e8b\u4ef6\uff09\u7684\u4f20\u9012\u4e0e\u4fdd\u7559\u3002"}}
{"id": "2507.01664", "categories": ["cs.PL", "D.3.1; F.3.2"], "pdf": "https://arxiv.org/pdf/2507.01664", "abs": "https://arxiv.org/abs/2507.01664", "authors": ["Hector Gramaglia"], "title": "Globality and Regions", "comment": null, "summary": "We obtain a characterization of global variables by unifying abstraction with\nregion abstraction in a region-based language. More precisely, in a previous\nwork a language called global was presented, whose virtue is to provide a\nconceptually clear way of introducing imperative operations in a functional\nlanguage. Memory safety is provided by the concept of linear protection, which\nconnects the global system to a linear one. In this paper we show that the\nconcept of global variable provided by the global language arises from the\nTofte and Talping's region language through the unification of abstraction and\nregion abstraction.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5c06\u62bd\u8c61\u4e0e\u533a\u57df\u62bd\u8c61\u7ed3\u5408\uff0c\u7ed9\u51fa\u4e86\u533a\u57df\u57fa\u7840\u8bed\u8a00\u4e2d\u5168\u5c40\u53d8\u91cf\u7684\u65b0\u523b\u753b\uff0c\u8fde\u63a5\u4e86\u5168\u5c40\u7cfb\u7edf\u4e0e\u7ebf\u6027\u7cfb\u7edf\uff0c\u63d0\u5347\u4e86\u51fd\u6570\u5f0f\u8bed\u8a00\u4e2d\u547d\u4ee4\u5f0f\u7279\u6027\u7684\u8868\u8fbe\u4e0e\u5b89\u5168\u6027\u3002", "motivation": "\u89e3\u51b3\u5728\u533a\u57df\u57fa\u7840\u8bed\u8a00\u4e2d\u5bf9\u5168\u5c40\u53d8\u91cf\u7684\u523b\u753b\u95ee\u9898\uff0c\u878d\u5408\u62bd\u8c61\u4e0e\u533a\u57df\u62bd\u8c61\u4ee5\u6e05\u6670\u8868\u8fbe\u547d\u4ee4\u5f0f\u64cd\u4f5c\u548c\u5185\u5b58\u5b89\u5168\u7684\u8fde\u63a5\u65b9\u5f0f\u3002", "method": "\u5c06\u62bd\u8c61\u4e0e\u533a\u57df\u62bd\u8c61\u7edf\u4e00\uff0c\u5bf9Tofte\u548cTalping\u7684region language\u5efa\u6a21\uff0c\u5e76\u5206\u6790\u5728\u8fd9\u79cd\u7edf\u4e00\u4e0b\u5168\u5c40\u53d8\u91cf\u7684\u8868\u73b0\u3002", "result": "\u8bc1\u660eglobal\u8bed\u8a00\u4e2d\u7684\u5168\u5c40\u53d8\u91cf\u6982\u5ff5\u53ef\u4ee5\u901a\u8fc7\u5bf9\u533a\u57df\u62bd\u8c61\u4e0e\u666e\u901a\u62bd\u8c61\u7684\u7edf\u4e00\uff0c\u4eceregion\u8bed\u8a00\u81ea\u7136\u5bfc\u51fa\u3002", "conclusion": "\u5168\u5c40\u53d8\u91cf\u7684\u6982\u5ff5\u548c\u5f15\u5165\u65b9\u5f0f\u53ef\u4ee5\u5728\u533a\u57df\u57fa\u7840\u8bed\u8a00\u4e2d\u901a\u8fc7\u62bd\u8c61\u7684\u7edf\u4e00\u5f97\u5230\u523b\u753b\uff0c\u5b9e\u73b0\u4e86\u5bf9\u51fd\u6570\u5f0f\u8bed\u8a00\u4e2d\u547d\u4ee4\u5f0f\u64cd\u4f5c\u3001\u5b89\u5168\u7b49\u7684\u66f4\u660e\u6670\u63cf\u8ff0\u3002"}}
{"id": "2507.01103", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.01103", "abs": "https://arxiv.org/abs/2507.01103", "authors": ["Jonhnanthan Oliveira", "Rohit Gheyi", "M\u00e1rcio Ribeiro", "Alessandro Garcia"], "title": "Bugs in the Shadows: Static Detection of Faulty Python Refactorings", "comment": "Accepted at Brazilian Symposium on Software Engineering (SBES 2025)", "summary": "Python is a widely adopted programming language, valued for its simplicity\nand flexibility. However, its dynamic type system poses significant challenges\nfor automated refactoring - an essential practice in software evolution aimed\nat improving internal code structure without changing external behavior.\nUnderstanding how type errors are introduced during refactoring is crucial, as\nsuch errors can compromise software reliability and reduce developer\nproductivity. In this work, we propose a static analysis technique to detect\ntype errors introduced by refactoring implementations for Python. We evaluated\nour technique on Rope refactoring implementations, applying them to open-source\nPython projects. Our analysis uncovered 29 bugs across four refactoring types\nfrom a total of 1,152 refactoring attempts. Several of these issues were also\nfound in widely used IDEs such as PyCharm and PyDev. All reported bugs were\nsubmitted to the respective developers, and some of them were acknowledged and\naccepted. These results highlight the need to improve the robustness of current\nPython refactoring tools to ensure the correctness of automated code\ntransformations and support reliable software maintenance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u9759\u6001\u5206\u6790\u65b9\u6cd5\u68c0\u6d4b Python \u91cd\u6784\u4e2d\u7684\u7c7b\u578b\u9519\u8bef\uff0c\u5e76\u5728\u5b9e\u9645\u5de5\u5177\u548c\u9879\u76ee\u4e2d\u53d1\u73b0\u4e86\u82e5\u5e72\u91cd\u8981\u7f3a\u9677\uff0c\u547c\u5401\u6539\u8fdb\u73b0\u6709\u5de5\u5177\u4ee5\u4fdd\u969c\u8f6f\u4ef6\u53ef\u9760\u6027\u3002", "motivation": "Python \u4f5c\u4e3a\u4e00\u95e8\u6d41\u884c\u7684\u7f16\u7a0b\u8bed\u8a00\uff0c\u7531\u4e8e\u5176\u52a8\u6001\u7c7b\u578b\u7cfb\u7edf\uff0c\u7ed9\u81ea\u52a8\u91cd\u6784\u5e26\u6765\u4e86\u663e\u8457\u6311\u6218\u3002\u91cd\u6784\u8fc7\u7a0b\u4e2d\u5f15\u5165\u7684\u7c7b\u578b\u9519\u8bef\u4f1a\u5f71\u54cd\u8f6f\u4ef6\u7684\u53ef\u9760\u6027\u548c\u5f00\u53d1\u8005\u751f\u4ea7\u529b\uff0c\u56e0\u6b64\u4e86\u89e3\u8fd9\u4e9b\u9519\u8bef\u7684\u4ea7\u751f\u65b9\u5f0f\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9759\u6001\u5206\u6790\u6280\u672f\uff0c\u7528\u4e8e\u68c0\u6d4b Python \u91cd\u6784\u5b9e\u73b0\u8fc7\u7a0b\u4e2d\u5f15\u5165\u7684\u7c7b\u578b\u9519\u8bef\u3002\u4f5c\u8005\u5c06\u8be5\u6280\u672f\u5e94\u7528\u4e8e Rope \u91cd\u6784\u5de5\u5177\uff0c\u5e76\u5728\u5f00\u6e90 Python \u9879\u76ee\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u5728 1,152 \u6b21\u91cd\u6784\u5c1d\u8bd5\u4e2d\uff0c\u5206\u6790\u5171\u53d1\u73b0\u4e86\u56db\u7c7b\u91cd\u6784\u4e2d\u7684 29 \u4e2a\u7f3a\u9677\uff0c\u5176\u4e2d\u4e00\u4e9b\u8fd8\u5728 PyCharm \u548c PyDev \u7b49\u4e3b\u6d41 IDE \u4e2d\u88ab\u53d1\u73b0\u3002\u6240\u6709\u5df2\u62a5\u544a\u7684\u7f3a\u9677\u90fd\u63d0\u4ea4\u7ed9\u4e86\u5bf9\u5e94\u5f00\u53d1\u56e2\u961f\uff0c\u5e76\u6709\u90e8\u5206\u88ab\u91c7\u7eb3\u3002", "conclusion": "\u5f53\u524d Python \u91cd\u6784\u5de5\u5177\u5728\u7c7b\u578b\u5b89\u5168\u6027\u65b9\u9762\u4ecd\u5b58\u5728\u4e0d\u8db3\uff0c\u6709\u5fc5\u8981\u8fdb\u4e00\u6b65\u63d0\u5347\u5176\u7a33\u5065\u6027\uff0c\u4ee5\u4fdd\u8bc1\u81ea\u52a8\u5316\u4ee3\u7801\u8f6c\u6362\u7684\u6b63\u786e\u6027\u53ca\u8f6f\u4ef6\u7ef4\u62a4\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2507.01170", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01170", "abs": "https://arxiv.org/abs/2507.01170", "authors": ["Simon B\u00f6rjesson", "Erik Ersmark", "Pierre Nugues"], "title": "Matching and Linking Entries in Historical Swedish Encyclopedias", "comment": "10 pages, 3 figures", "summary": "The \\textit{Nordisk familjebok} is a Swedish encyclopedia from the 19th and\n20th centuries. It was written by a team of experts and aimed to be an\nintellectual reference, stressing precision and accuracy. This encyclopedia had\nfour main editions remarkable by their size, ranging from 20 to 38 volumes. As\na consequence, the \\textit{Nordisk familjebok} had a considerable influence in\nuniversities, schools, the media, and society overall. As new editions were\nreleased, the selection of entries and their content evolved, reflecting\nintellectual changes in Sweden.\n  In this paper, we used digitized versions from \\textit{Project Runeberg}. We\nfirst resegmented the raw text into entries and matched pairs of entries\nbetween the first and second editions using semantic sentence embeddings. We\nthen extracted the geographical entries from both editions using a\ntransformer-based classifier and linked them to Wikidata. This enabled us to\nidentify geographic trends and possible shifts between the first and second\neditions, written between 1876-1899 and 1904-1926, respectively.\n  Interpreting the results, we observe a small but significant shift in\ngeographic focus away from Europe and towards North America, Africa, Asia,\nAustralia, and northern Scandinavia from the first to the second edition,\nconfirming the influence of the First World War and the rise of new powers. The\ncode and data are available on GitHub at\nhttps://github.com/sibbo/nordisk-familjebok.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6570\u5b57\u4eba\u6587\u65b9\u6cd5\u5206\u6790\u745e\u5178\u767e\u79d1\u5168\u4e66\u300aNordisk familjebok\u300b\u7684\u4e24\u7248\u5185\u5bb9\uff0c\u53d1\u73b0\u7b2c\u4e8c\u7248\u5728\u5730\u7406\u7126\u70b9\u4e0a\u66f4\u5173\u6ce8\u5168\u7403\uff0c\u4f53\u73b0\u65f6\u4ee3\u548c\u5927\u4e8b\u4ef6\u7684\u5f71\u54cd\u3002", "motivation": "\u5206\u6790\u300aNordisk familjebok\u300b\u8fd9\u90e819-20\u4e16\u7eaa\u745e\u5178\u767e\u79d1\u5168\u4e66\u7684\u8bcd\u6761\u5728\u4e0d\u540c\u7248\u672c\u4e4b\u95f4\u7684\u5185\u5bb9\u53d8\u5316\uff0c\u7279\u522b\u60f3\u63a2\u7d22\u8bcd\u6761\u6536\u5f55\u3001\u5730\u7406\u5173\u6ce8\u70b9\u7b49\u5982\u4f55\u53cd\u6620\u745e\u5178\u77e5\u8bc6\u754c\u7684\u53d8\u8fc1\u53ca\u91cd\u5927\u5386\u53f2\u4e8b\u4ef6\u5f71\u54cd\u3002", "method": "\u5229\u7528Project Runeberg\u7684\u6570\u5b57\u5316\u7248\u672c\uff0c\u9996\u5148\u5bf9\u539f\u59cb\u6587\u672c\u8fdb\u884c\u91cd\u65b0\u5206\u8bcd\u5e76\u7528\u8bed\u4e49\u53e5\u5d4c\u5165\u65b9\u6cd5\u914d\u5bf9\u7b2c\u4e00\u7248\u548c\u7b2c\u4e8c\u7248\u4e4b\u95f4\u7684\u8bcd\u6761\uff0c\u7136\u540e\u7528\u57fa\u4e8etransformer\u7684\u5206\u7c7b\u5668\u63d0\u53d6\u5730\u7406\u8bcd\u6761\uff0c\u5e76\u5c06\u5176\u5173\u8054\u5230Wikidata\uff0c\u5206\u6790\u5730\u7406\u8bcd\u6761\u7684\u53d8\u5316\u8d8b\u52bf\u3002", "result": "\u901a\u8fc7\u5206\u6790\uff0c\u53d1\u73b0\u7b2c\u4e8c\u7248\u76f8\u8f83\u4e8e\u7b2c\u4e00\u7248\uff0c\u767e\u79d1\u5168\u4e66\u7684\u5730\u7406\u5173\u6ce8\u70b9\u4ece\u6b27\u6d32\u9010\u6b65\u5411\u5317\u7f8e\u3001\u975e\u6d32\u3001\u4e9a\u6d32\u3001\u6fb3\u5927\u5229\u4e9a\u548c\u5317\u65af\u582a\u7684\u7eb3\u7ef4\u4e9a\u5730\u533a\u6709\u6240\u8f6c\u79fb\uff0c\u8fd9\u4e00\u53d8\u5316\u4e0e\u4e00\u6218\u548c\u65b0\u5174\u5927\u56fd\u5d1b\u8d77\u7b49\u5386\u53f2\u80cc\u666f\u76f8\u5370\u8bc1\u3002", "conclusion": "\u300aNordisk familjebok\u300b\u7684\u4e0d\u540c\u7248\u672c\u5185\u5bb9\u53d8\u5316\u53cd\u6620\u4e86\u745e\u5178\u53ca\u4e16\u754c\u77e5\u8bc6\u3001\u5730\u7f18\u683c\u5c40\u7684\u8f6c\u53d8\u3002\u7814\u7a76\u63ed\u793a\u767e\u79d1\u5168\u4e66\u4f5c\u4e3a\u77e5\u8bc6\u8f7d\u4f53\uff0c\u80fd\u591f\u654f\u9510\u53cd\u6620\u793e\u4f1a\u4e0e\u5386\u53f2\u53d8\u8fc1\uff0c\u76f8\u5173\u4ee3\u7801\u4e0e\u6570\u636e\u5df2\u5f00\u6e90\u3002"}}
{"id": "2507.01315", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.01315", "abs": "https://arxiv.org/abs/2507.01315", "authors": ["Taiming Wang", "Yanjie Jiang", "Chunhao Dong", "Yuxia Zhang", "Hui Liu"], "title": "Context-Aware Code Wiring Recommendation with LLM-based Agent", "comment": null, "summary": "Copy-paste-modify is a widespread and pragmatic practice in software\ndevelopment, where developers adapt reused code snippets, sourced from\nplatforms such as Stack Overflow, GitHub, or LLM outputs, into their local\ncodebase. A critical yet underexplored aspect of this adaptation is code\nwiring, which involves substituting unresolved variables in the pasted code\nwith suitable ones from the surrounding context. Existing solutions either rely\non heuristic rules or historical templates, often failing to effectively\nutilize contextual information, despite studies showing that over half of\nadaptation cases are context-dependent. In this paper, we introduce WIRL, an\nLLM-based agent for code wiring framed as a Retrieval-Augmented Generation\n(RAG) infilling task. WIRL combines an LLM, a customized toolkit, and an\norchestration module to identify unresolved variables, retrieve context, and\nperform context-aware substitutions. To balance efficiency and autonomy, the\nagent adopts a mixed strategy: deterministic rule-based steps for common\npatterns, and a state-machine-guided decision process for intelligent\nexploration. We evaluate WIRL on a carefully curated, high-quality dataset\nconsisting of real-world code adaptation scenarios. Our approach achieves an\nexact match precision of 91.7% and a recall of 90.0%, outperforming advanced\nLLMs by 22.6 and 13.7 percentage points in precision and recall, respectively,\nand surpassing IntelliJ IDEA by 54.3 and 49.9 percentage points. These results\nunderscore its practical utility, particularly in contexts with complex\nvariable dependencies or multiple unresolved variables. We believe WIRL paves\nthe way for more intelligent and context-aware developer assistance in modern\nIDEs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86WIRL\uff0c\u4e00\u4e2a\u7528\u5927\u6a21\u578b\u548c\u68c0\u7d22\u6280\u672f\u8f85\u52a9\u4ee3\u7801\u7247\u6bb5\u4e0a\u4e0b\u6587\u53d8\u91cf\u66ff\u6362\u7684\u65b0\u65b9\u6cd5\uff0c\u5728\u771f\u5b9e\u6570\u636e\u4e0a\u7cbe\u5ea6\u548c\u53ec\u56de\u8fdc\u8d85\u73b0\u6709\u65b9\u6848\uff0c\u63a8\u52a8\u4e86IDE\u667a\u80fd\u5316\u8f85\u52a9\u7684\u53d1\u5c55\u3002", "motivation": "\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\uff0cCopy-paste-modify\uff08\u590d\u5236-\u7c98\u8d34-\u4fee\u6539\uff09\u662f\u4e00\u79cd\u5e38\u89c1\u64cd\u4f5c\uff0c\u4f46\u5728\u5c06\u5916\u90e8\u4ee3\u7801\u7247\u6bb5\u96c6\u6210\u5230\u672c\u5730\u4ee3\u7801\u5e93\u65f6\uff0c\u53d8\u91cf\u7684\u4e0a\u4e0b\u6587\u9002\u914d\uff08code wiring\uff09\u662f\u4e00\u4e2a\u5173\u952e\u4e14\u672a\u88ab\u5145\u5206\u7814\u7a76\u7684\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u4e0d\u80fd\u5f88\u597d\u5730\u5229\u7528\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5bfc\u81f4\u5728\u4e0a\u4e0b\u6587\u4f9d\u8d56\u6027\u5f3a\u7684\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faWIRL\uff0c\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4ee3\u7801\u53d8\u91cf\u9002\u914d\u667a\u80fd\u4f53\uff0c\u628a\u4ee3\u7801\u8865\u5168\u4efb\u52a1\u5efa\u6a21\u4e3a\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u586b\u7a7a\u4efb\u52a1\u3002WIRL\u7ed3\u5408\u4e86LLM\u3001\u5b9a\u5236\u5de5\u5177\u5305\u548c\u7f16\u6392\u6a21\u5757\uff0c\u80fd\u591f\u8bc6\u522b\u672a\u89e3\u51b3\u53d8\u91cf\u3001\u68c0\u7d22\u4e0a\u4e0b\u6587\u5e76\u8fdb\u884c\u5408\u9002\u66ff\u6362\u3002\u540c\u65f6\u91c7\u7528\u6df7\u5408\u7b56\u7565\uff0c\u5bf9\u5e38\u89c1\u6a21\u5f0f\u91c7\u53d6\u786e\u5b9a\u6027\u89c4\u5219\uff0c\u5bf9\u4e8e\u590d\u6742\u60c5\u5f62\u7528\u72b6\u6001\u673a\u5f15\u5bfc\u63a2\u7d22\u3002", "result": "\u5728\u771f\u5b9e\u4ee3\u7801\u9002\u914d\u573a\u666f\u7684\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u4e0a\uff0cWIRL\u7684\u7cbe\u786e\u7387\u8fbe\u523091.7%\uff0c\u53ec\u56de\u7387\u8fbe90.0%\uff0c\u5206\u522b\u6bd4\u5148\u8fdbLLM\u63d0\u534722.6\u548c13.7\u4e2a\u767e\u5206\u70b9\uff0c\u6bd4IntelliJ IDEA\u63d0\u534754.3\u548c49.9\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "WIRL\u6709\u6548\u63d0\u5347\u4e86\u4ee3\u7801\u53d8\u91cf\u9002\u914d\u7684\u81ea\u52a8\u5316\u548c\u51c6\u786e\u6027\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u590d\u6742\u4f9d\u8d56\u548c\u591a\u53d8\u91cf\u672a\u89e3\u51b3\u7684\u573a\u666f\uff0c\u6709\u671b\u63a8\u52a8\u66f4\u667a\u80fd\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5f00\u53d1\u8005\u8f85\u52a9\u5de5\u5177\u8fdb\u5165\u73b0\u4ee3IDE\u3002"}}
{"id": "2507.01213", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01213", "abs": "https://arxiv.org/abs/2507.01213", "authors": ["Adamu Lawan", "Juhua Pu", "Haruna Yunusa", "Jawad Muhammad", "Muhammad Lawan"], "title": "MEGA: xLSTM with Multihead Exponential Gated Fusion for Precise Aspect-based Sentiment Analysis", "comment": "6, 1 figure", "summary": "Aspect-based Sentiment Analysis (ABSA) is a critical Natural Language\nProcessing (NLP) task that extracts aspects from text and determines their\nassociated sentiments, enabling fine-grained analysis of user opinions.\nExisting ABSA methods struggle to balance computational efficiency with high\nperformance: deep learning models often lack global context, transformers\ndemand significant computational resources, and Mamba-based approaches face\nCUDA dependency and diminished local correlations. Recent advancements in\nExtended Long Short-Term Memory (xLSTM) models, particularly their efficient\nmodeling of long-range dependencies, have significantly advanced the NLP\ncommunity. However, their potential in ABSA remains untapped. To this end, we\npropose xLSTM with Multihead Exponential Gated Fusion (MEGA), a novel framework\nintegrating a bi-directional mLSTM architecture with forward and partially\nflipped backward (PF-mLSTM) streams. The PF-mLSTM enhances localized context\nmodeling by processing the initial sequence segment in reverse with dedicated\nparameters, preserving critical short-range patterns. We further introduce an\nmLSTM-based multihead cross exponential gated fusion mechanism (MECGAF) that\ndynamically combines forward mLSTM outputs as query and key with PF-mLSTM\noutputs as value, optimizing short-range dependency capture while maintaining\nglobal context and efficiency. Experimental results on three benchmark datasets\ndemonstrate that MEGA outperforms state-of-the-art baselines, achieving\nsuperior accuracy and efficiency in ABSA tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u878d\u5408xLSTM\u548cMEGA\u673a\u5236\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347ABSA\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u548c\u6548\u7387\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u53cc\u5411mLSTM\u4e0e\u65b0\u7684\u95e8\u63a7\u878d\u5408\u673a\u5236MECGAF\uff0c\u80fd\u6709\u6548\u6355\u6349\u6587\u672c\u7684\u77ed\u7a0b\u53ca\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\uff0c\u5728\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u5f53\u524d\u4e3b\u6d41\u6a21\u578b\u3002", "motivation": "\u73b0\u6709ABSA\u6a21\u578b\u5728\u6027\u80fd\u548c\u6548\u7387\u95f4\u96be\u4ee5\u5e73\u8861\u3002\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5168\u5c40\u5efa\u6a21\u80fd\u529b\u5f31\u3001Transformer\u8ba1\u7b97\u6210\u672c\u9ad8\u3001Mamba\u53d7CUDA\u4f9d\u8d56\u4e14\u5c40\u90e8\u5efa\u6a21\u80fd\u529b\u5f31\u3002xLSTM\u8fd1\u671f\u5728\u5e8f\u5217\u957f\u4f9d\u8d56\u5efa\u6a21\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5c1a\u672a\u5728ABSA\u9886\u57df\u5c1d\u8bd5\u3002", "method": "\u65b9\u6cd5\u4e3a\u53cc\u5411xLSTM\u7ed3\u6784\uff0c\u7ed3\u5408\u6b63\u5411mLSTM\u4e0e\u90e8\u5206\u53cd\u5411PF-mLSTM\u6d41\uff0c\u53e6\u5916\u5f15\u5165mLSTM\u57fa\u7840\u7684\u591a\u5934\u8de8\u6307\u6570\u95e8\u63a7\u878d\u5408\u673a\u5236\uff08MECGAF\uff09\u4ee5\u52a8\u6001\u878d\u5408\u4e0d\u540c\u65b9\u5411\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4f18\u5316\u77ed\u8ddd\u79bb\u548c\u5168\u5c40\u4f9d\u8d56\u5efa\u6a21\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684MEGA\u6846\u67b6\u5728\u4e09\u7ec4\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u65e0\u8bba\u662f\u6027\u80fd\u8fd8\u662f\u6548\u7387\u4e0a\u90fd\u6709\u7a81\u7834\u3002", "conclusion": "\u63d0\u51fa\u7684xLSTM\u4e0eMEGA\u6846\u67b6\u5728\u4e09\u7ec4ABSA\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5747\u8d85\u8fc7\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\uff0c\u8868\u73b0\u66f4\u4f73\uff0c\u65e0\u8bba\u662f\u5728\u51c6\u786e\u7387\u8fd8\u662f\u6548\u7387\u4e0a\u5747\u6709\u4f18\u52bf\u3002"}}
{"id": "2507.01477", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.01477", "abs": "https://arxiv.org/abs/2507.01477", "authors": ["Lukas Krodinger", "Stephan Lukasczyk", "Gordon Fraser"], "title": "Combining Type Inference and Automated Unit Test Generation for Python", "comment": null, "summary": "Automated unit test generation is an established research field that has so\nfar focused on statically-typed programming languages. The lack of type\ninformation in dynamically-typed programming languages, such as Python,\ninhibits test generators, which heavily rely on information about parameter and\nreturn types of functions to select suitable arguments when constructing test\ncases. Since automated test generators inherently rely on frequent execution of\ncandidate tests, we make use of these frequent executions to address this\nproblem by introducing type tracing, which extracts type-related information\nduring execution and gradually refines the available type information. We\nimplement type tracing as an extension of the Pynguin test-generation framework\nfor Python, allowing it (i) to infer parameter types by observing how\nparameters are used during runtime, (ii) to record the types of values that\nfunction calls return, and (iii) to use this type information to increase code\ncoverage. The approach leads to up to 90.0% more branch coverage, improved\nmutation scores, and to type information of similar quality to that produced by\nother state-of-the-art type-inference tools.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u52a8\u6001\u7c7b\u578b\u8bed\u8a00\uff08\u5982Python\uff09\u96be\u4ee5\u83b7\u53d6\u7c7b\u578b\u4fe1\u606f\u7684\u95ee\u9898\uff0c\u8be5\u6587\u63d0\u51fa\u5e76\u5b9e\u8df5\u4e86\u8fd0\u884c\u65f6\u7c7b\u578b\u8ffd\u8e2a\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u5316\u5355\u5143\u6d4b\u8bd5\u7684\u4ee3\u7801\u8986\u76d6\u7387\u548c\u7c7b\u578b\u63a8\u65ad\u8d28\u91cf\u3002", "motivation": "\u81ea\u52a8\u5316\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u5df2\u5728\u9759\u6001\u7c7b\u578b\u8bed\u8a00\u4e2d\u5e94\u7528\u6210\u719f\uff0c\u4f46\u52a8\u6001\u7c7b\u578b\u8bed\u8a00\uff08\u5982Python\uff09\u56e0\u7f3a\u4e4f\u7c7b\u578b\u4fe1\u606f\uff0c\u963b\u788d\u4e86\u6d4b\u8bd5\u751f\u6210\u5668\u7684\u53d1\u5c55\uff0c\u7279\u522b\u662f\u5728\u9009\u62e9\u53c2\u6570\u548c\u6784\u9020\u6d4b\u8bd5\u7528\u4f8b\u65f6\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u74f6\u9888\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u65b0\u7684\u601d\u8def\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u201c\u7c7b\u578b\u8ffd\u8e2a\uff08type tracing\uff09\u201d\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u88ab\u6d4b\u8bd5\u4ee3\u7801\u9891\u7e41\u6267\u884c\u671f\u95f4\u52a8\u6001\u6536\u96c6\u7c7b\u578b\u76f8\u5173\u4fe1\u606f\uff0c\u9010\u6b65\u5b8c\u5584\u7c7b\u578b\u4fe1\u606f\u3002\u5e76\u5728Pynguin\u6d4b\u8bd5\u751f\u6210\u6846\u67b6\u4e2d\u5b9e\u73b0\uff0c\u4ee5\u89c2\u5bdf\u53c2\u6570\u5728\u8fd0\u884c\u65f6\u7684\u4f7f\u7528\u65b9\u5f0f\u3001\u8bb0\u5f55\u8fd4\u56de\u503c\u7c7b\u578b\uff0c\u5e76\u5c06\u8fd9\u4e9b\u4fe1\u606f\u5e94\u7528\u4e8e\u63d0\u5347\u8986\u76d6\u7387\u3002", "result": "\u5f15\u5165\u7c7b\u578b\u8ffd\u8e2a\u540e\uff0cPynguin\u6846\u67b6\u5b9e\u73b0\u4e86\u9ad8\u8fbe90%\u7684\u5206\u652f\u8986\u76d6\u7387\u63d0\u5347\uff0c\u63d0\u5347\u4e86mutation\u5f97\u5206\uff0c\u5e76\u83b7\u5f97\u4e86\u4e0e\u5148\u8fdb\u7c7b\u578b\u63a8\u65ad\u5de5\u5177\u76f8\u5ab2\u7f8e\u7684\u7c7b\u578b\u4fe1\u606f\u8d28\u91cf\u3002", "conclusion": "\u901a\u8fc7\u7c7b\u578b\u8ffd\u8e2a\uff0c\u89e3\u51b3\u4e86\u52a8\u6001\u7c7b\u578b\u8bed\u8a00\u4e2d\u81ea\u52a8\u5316\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u7f3a\u4e4f\u7c7b\u578b\u4fe1\u606f\u7684\u5173\u952e\u96be\u9898\uff0c\u5927\u5927\u63d0\u5347\u4e86\u6d4b\u8bd5\u751f\u6210\u7684\u6709\u6548\u6027\u548c\u8986\u76d6\u7387\u3002"}}
{"id": "2507.01234", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01234", "abs": "https://arxiv.org/abs/2507.01234", "authors": ["Yu Fan", "Yang Tian", "Shauli Ravfogel", "Mrinmaya Sachan", "Elliott Ash", "Alexander Hoyle"], "title": "The Medium Is Not the Message: Deconfounding Text Embeddings via Linear Concept Erasure", "comment": null, "summary": "Embedding-based similarity metrics between text sequences can be influenced\nnot just by the content dimensions we most care about, but can also be biased\nby spurious attributes like the text's source or language. These document\nconfounders cause problems for many applications, but especially those that\nneed to pool texts from different corpora. This paper shows that a debiasing\nalgorithm that removes information about observed confounders from the encoder\nrepresentations substantially reduces these biases at a minimal computational\ncost. Document similarity and clustering metrics improve across every embedding\nvariant and task we evaluate -- often dramatically. Interestingly, performance\non out-of-distribution benchmarks is not impacted, indicating that the\nembeddings are not otherwise degraded.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53bb\u9664\u6587\u672c\u5d4c\u5165\u4e2d\u6df7\u6742\u56e0\u7d20\uff08\u5982\u6765\u6e90\u3001\u8bed\u8a00\uff09\u7684\u65b9\u6cd5\uff0c\u6781\u5927\u63d0\u5347\u4e86\u6587\u672c\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u548c\u805a\u7c7b\u6548\u679c\uff0c\u4e14\u6a21\u578b\u6574\u4f53\u6027\u80fd\u672a\u53d7\u8d1f\u9762\u5f71\u54cd\u3002", "motivation": "\u57fa\u4e8e\u5d4c\u5165\u7684\u6587\u672c\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u5e38\u5e38\u53d7\u5230\u6587\u672c\u6765\u6e90\u3001\u8bed\u8a00\u7b49\u65e0\u5173\u5c5e\u6027\u7684\u5f71\u54cd\uff0c\u8fd9\u4e9b\u201c\u6df7\u6742\u56e0\u7d20\u201d\u5f71\u54cd\u4e86\u6587\u672c\u805a\u5408\u548c\u6bd4\u8f83\u7684\u51c6\u786e\u6027\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u6574\u5408\u4e0d\u540c\u8bed\u6599\u6765\u6e90\u6587\u672c\u7684\u5e94\u7528\u4e2d\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u53bb\u504f\u7b97\u6cd5\uff0c\u5728\u7f16\u7801\u5668\u751f\u6210\u7684\u8868\u793a\u4e2d\u53bb\u9664\u5df2\u77e5\u6df7\u6742\u53d8\u91cf\u7684\u4fe1\u606f\uff0c\u4ee5\u51cf\u5c11\u65e0\u5173\u5c5e\u6027\u5bf9\u6587\u672c\u76f8\u4f3c\u5ea6\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u4fdd\u8bc1\u8ba1\u7b97\u5f00\u9500\u8f83\u5c0f\u3002", "result": "\u5728\u4e0d\u540c\u7684\u5d4c\u5165\u53d8\u4f53\u548c\u4efb\u52a1\u4e0a\uff0c\u6587\u672c\u76f8\u4f3c\u5ea6\u548c\u805a\u7c7b\u6307\u6807\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u5e76\u4e14\u5728\u6bcf\u9879\u8bc4\u6d4b\u4e2d\u5747\u89c2\u5bdf\u5230\u6539\u8fdb\u3002\u5728\u5206\u5e03\u5916\u6d4b\u8bd5\u96c6\u4e0a\u7684\u8868\u73b0\u6ca1\u6709\u4e0b\u964d\uff0c\u8bf4\u660e\u53bb\u504f\u5904\u7406\u672a\u524a\u5f31\u5d4c\u5165\u672c\u8eab\u7684\u6548\u80fd\u3002", "conclusion": "\u8be5\u53bb\u504f\u7b97\u6cd5\u53ef\u6709\u6548\u51cf\u5c0f\u6587\u672c\u5d4c\u5165\u4e2d\u7684\u6df7\u6742\u504f\u5dee\uff0c\u5728\u4fdd\u8bc1\u6548\u7387\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u4e86\u591a\u9879\u6587\u672c\u76f8\u4f3c\u4e0e\u805a\u7c7b\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u8868\u73b0\u3002"}}
{"id": "2507.01628", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.01628", "abs": "https://arxiv.org/abs/2507.01628", "authors": ["Zilong He", "Pengfei Chen", "Hongyu Zhang", "Xiaoyun Li", "Guangba Yu", "Hongyang Chen", "Zibin Zheng"], "title": "DaiFu: In-Situ Crash Recovery for Deep Learning Systems", "comment": null, "summary": "Deep learning (DL) systems have been widely adopted in many areas, and are\nbecoming even more popular with the emergence of large language models.\nHowever, due to the complex software stacks involved in their development and\nexecution, crashes are unavoidable and common. Crashes severely waste computing\nresources and hinder development productivity, so efficient crash recovery is\ncrucial. Existing solutions, such as checkpoint-retry, are too heavyweight for\nfast recovery from crashes caused by minor programming errors or transient\nruntime errors. Therefore, we present DaiFu, an in-situ recovery framework for\nDL systems. Through a lightweight code transformation to a given DL system,\nDaiFu augments it to intercept crashes in situ and enables dynamic and instant\nupdates to its program running context (e.g., code, configurations, and other\ndata) for agile crash recovery. Our evaluation shows that DaiFu helps reduce\nthe restore time for crash recovery, achieving a 1372x speedup compared with\nstate-of-the-art solutions. Meanwhile, the overhead of DaiFu is negligible\n(under 0.40%). We also construct a benchmark spanning 7 distinct crash\nscenarios in DL systems, and show the effectiveness of DaiFu in diverse\nsituations.", "AI": {"tldr": "DaiFu\u662f\u4e00\u79cd\u4e3a\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u8bbe\u8ba1\u7684\u8f7b\u91cf\u7ea7\u539f\u5730\u5d29\u6e83\u6062\u590d\u6846\u67b6\uff0c\u901a\u8fc7\u4ee3\u7801\u6539\u9020\u5b9e\u73b0\u4e86\u5373\u65f6\u3001\u52a8\u6001\u73af\u5883\u4fee\u590d\uff0c\u6bd4\u73b0\u6709\u65b9\u6848\u5feb1372\u500d\u4e14\u51e0\u4e4e\u65e0\u6027\u80fd\u635f\u8017\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5d29\u6e83\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u5e7f\u6cdb\u5e94\u7528\u4e14\u8d8a\u53d1\u6d41\u884c\uff0c\u4f46\u5176\u5f00\u53d1\u4e0e\u6267\u884c\u6d89\u53ca\u590d\u6742\u7684\u8f6f\u4ef6\u5806\u6808\uff0c\u5bfc\u81f4\u5d29\u6e83\u96be\u4ee5\u907f\u514d\u4e14\u9891\u7e41\u53d1\u751f\uff0c\u4e25\u91cd\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\u5e76\u5f71\u54cd\u5f00\u53d1\u6548\u7387\u3002\u73b0\u6709\u5982checkpoint-retry\u7b49\u6062\u590d\u89e3\u51b3\u65b9\u6848\u6062\u590d\u901f\u5ea6\u6162\u3001\u4e0d\u9002\u5408\u7ec6\u5fae\u7f16\u7a0b\u548c\u77ac\u65f6\u8fd0\u884c\u65f6\u9519\u8bef\u540e\u7684\u654f\u6377\u6062\u590d\u3002\u56e0\u6b64\u4e9f\u9700\u4e00\u79cd\u9ad8\u6548\u3001\u8f7b\u91cf\u7684\u5d29\u6e83\u6062\u590d\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5bf9\u76ee\u6807\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u8fdb\u884c\u8f7b\u91cf\u7ea7\u4ee3\u7801\u8f6c\u6362\uff0cDaiFu\u80fd\u591f\u539f\u5730\u62e6\u622a\u7cfb\u7edf\u5d29\u6e83\uff0c\u5e76\u5141\u8bb8\u52a8\u6001\u5373\u65f6\u66f4\u65b0\u7a0b\u5e8f\u8fd0\u884c\u73af\u5883\uff08\u5982\u4ee3\u7801\u3001\u914d\u7f6e\u548c\u6570\u636e\uff09\uff0c\u5b9e\u73b0\u654f\u6377\u5730\u5d29\u6e83\u6062\u590d\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u6784\u5efa\u4e86\u5305\u542b7\u79cd\u5178\u578b\u5d29\u6e83\u573a\u666f\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\u5bf9\u7cfb\u7edf\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\u3002", "result": "DaiFu\u5c06\u6062\u590d\u65f6\u95f4\u964d\u4f4e\u5230\u4e86\u73b0\u6709\u6280\u672f\u76841/1372\uff0c\u4e14\u989d\u5916\u5f15\u5165\u7684\u7cfb\u7edf\u5f00\u9500\u975e\u5e38\u5c0f\uff08\u5c0f\u4e8e0.4%\uff09\uff0c\u5e76\u80fd\u6709\u6548\u5e94\u5bf97\u7c7b\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u5e38\u89c1\u7684\u5d29\u6e83\u573a\u666f\u3002", "conclusion": "DaiFu\u663e\u8457\u52a0\u5feb\u4e86\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u7684\u5d29\u6e83\u6062\u590d\u901f\u5ea6\uff0c\u5728\u5b9e\u9a8c\u4e2d\u76f8\u8f83\u4e8e\u73b0\u6709\u6280\u672f\u63d0\u5347\u4e861372\u500d\u6062\u590d\u901f\u5ea6\uff0c\u540c\u65f6\u5e26\u6765\u7684\u6027\u80fd\u5f00\u9500\u6781\u4f4e\uff08\u4f4e\u4e8e0.40%\uff09\u3002DaiFu\u9002\u7528\u4e8e\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u4e2d\u7684\u4e0d\u540c\u5d29\u6e83\u573a\u666f\uff0c\u5c55\u73b0\u4e86\u5353\u8d8a\u7684\u6062\u590d\u80fd\u529b\u3002"}}
{"id": "2507.01259", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.01259", "abs": "https://arxiv.org/abs/2507.01259", "authors": ["Micha\u0142 Matak", "Jaros\u0142aw A. Chudziak"], "title": "GAIus: Combining Genai with Legal Clauses Retrieval for Knowledge-based Assistant", "comment": "8 pages, 2 figures, presented at ICAART 2025, in proceedings of the\n  17th International Conference on Agents and Artificial Intelligence - Volume\n  3: ICAART", "summary": "In this paper we discuss the capability of large language models to base\ntheir answer and provide proper references when dealing with legal matters of\nnon-english and non-chinese speaking country. We discuss the history of legal\ninformation retrieval, the difference between case law and statute law, its\nimpact on the legal tasks and analyze the latest research in this field. Basing\non that background we introduce gAIus, the architecture of the cognitive\nLLM-based agent, whose responses are based on the knowledge retrieved from\ncertain legal act, which is Polish Civil Code. We propose a retrieval mechanism\nwhich is more explainable, human-friendly and achieves better results than\nembedding-based approaches. To evaluate our method we create special dataset\nbased on single-choice questions from entrance exams for law apprenticeships\nconducted in Poland. The proposed architecture critically leveraged the\nabilities of used large language models, improving the gpt-3.5-turbo-0125 by\n419%, allowing it to beat gpt-4o and lifting gpt-4o-mini score from 31% to 86%.\nAt the end of our paper we show the possible future path of research and\npotential applications of our findings.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6ce2\u5170\u8fd9\u79cd\u975e\u82f1\u8bed\u6cd5\u57df\u7684\u6cd5\u5f8b\u68c0\u7d22\u4e0e\u95ee\u7b54\u4efb\u52a1\u8868\u73b0\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u6c11\u6cd5\u5178\u4e0e\u66f4\u53ef\u89e3\u91ca\u7684\u68c0\u7d22\u673a\u5236\u7684gAIus\u67b6\u6784\uff0c\u5728\u6cd5\u5f8b\u8003\u8bd5\u6570\u636e\u96c6\u4e0a\u5927\u5e45\u63d0\u5347\u4e3b\u6d41\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u975e\u82f1\u8bed\u53ca\u975e\u4e2d\u6587\u6cd5\u5f8b\u9886\u57df\u7ed9\u51fa\u7684\u53c2\u8003\u53ca\u7b54\u6848\u6709\u6548\u6027\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u89e3\u91ca\u6027\u5f3a\u4e14\u7528\u6237\u53cb\u597d\u7684\u65b9\u6848\uff0c\u5c24\u5176\u662f\u5728\u6761\u6587\u6cd5\u4f53\u7cfb\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u4ee5\u6ce2\u5170\u6c11\u6cd5\u5178\u4e3a\u57fa\u7840\u7684\u4fe1\u606f\u68c0\u7d22\u673a\u5236\uff0c\u5e76\u6784\u5efagAIus\u8ba4\u77e5\u578b\u5927\u6a21\u578b\u667a\u80fd\u4f53\u67b6\u6784\u3002\u91c7\u7528\u6570\u636e\u96c6\u8bc4\u6d4b\u5e76\u4e0e\u73b0\u6709\u5d4c\u5165\u5f0f\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u5f15\u5165\u7684\u673a\u5236\u4f7fgpt-3.5-turbo-0125\u6a21\u578b\u7684\u8868\u73b0\u63d0\u5347\u4e86419%\uff0c\u4f18\u4e8egpt-4o\uff0c\u5e76\u5c06gpt-4o-mini\u5f97\u5206\u4ece31%\u63d0\u5347\u81f386%\u3002", "conclusion": "\u6587\u4e2d\u63d0\u51fa\u7684gAIus\u67b6\u6784\u6781\u5927\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6ce2\u5170\u6cd5\u5f8b\u9886\u57df\u7684\u68c0\u7d22\u53ca\u7b54\u9898\u80fd\u529b\uff0c\u5e76\u5c55\u671b\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u548c\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2507.01827", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.01827", "abs": "https://arxiv.org/abs/2507.01827", "authors": ["Haichuan Hu", "Congqing He", "Hao Zhang", "Xiaochen Xie", "Quanjun Zhang"], "title": "APRMCTS: Improving LLM-based Automated Program Repair with Iterative Tree Search", "comment": null, "summary": "Automated Program Repair (APR) attempts to fix software bugs without human\nintervention, which plays a crucial role in software development and\nmaintenance. Recently, with the advances in Large Language Models (LLMs), a\nrapidly increasing number of APR techniques have been proposed with remarkable\nperformance. However, existing LLM-based APR techniques typically adopt\ntrial-and-error strategies, which suffer from two major drawbacks: (1)\ninherently limited patch effectiveness due to local exploration, and (2) low\nsearch efficiency due to redundant exploration. In this paper, we propose\nAPRMCTS, which uses iterative tree search to improve LLM-based APR. APRMCTS\nincorporates Monte Carlo Tree Search (MCTS) into patch searching by performing\na global evaluation of the explored patches and selecting the most promising\none for subsequent refinement and generation. APRMCTS effectively resolves the\nproblems of falling into local optima and thus helps improve the efficiency of\npatch searching. Our experiments on 835 bugs from Defects4J demonstrate that,\nwhen integrated with GPT-3.5, APRMCTS can fix a total of 201 bugs, which\noutperforms all state-of-the-art baselines. Besides, APRMCTS helps GPT-4o-mini,\nGPT-3.5, Yi-Coder-9B, and Qwen2.5-Coder-7B to fix 30, 27, 37, and 28 more bugs,\nrespectively. More importantly, APRMCTS boasts a significant performance\nadvantage while employing small patch size (16 and 32), notably fewer than the\n500 and 10,000 patches adopted in previous studies. In terms of cost, compared\nto existing state-of-the-art LLM-based APR methods, APRMCTS has time and\nmonetary costs of less than 20% and 50%, respectively. Our extensive study\ndemonstrates that APRMCTS exhibits good effectiveness and efficiency, with\nparticular advantages in addressing complex bugs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u7528\u4e8e\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff0c\u6709\u6548\u63d0\u5347\u8865\u4e01\u641c\u7d22\u7684\u5168\u5c40\u6027\u4e0e\u6548\u7387\u3002\u5b9e\u9a8c\u8868\u660e\uff0cAPRMCTS \u5728\u4fee\u590d\u6570\u91cf\u3001\u901f\u5ea6\u3001\u6210\u672c\u4e0a\u5747\u8d85\u8d8a\u4f20\u7edf\u65b9\u6cd5\uff0c\u9002\u5408\u590d\u6742\u7f3a\u9677\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u65b9\u6cd5\uff0c\u901a\u5e38\u91c7\u7528\u8bd5\u9519\u7b56\u7565\uff0c\u5728\u4fee\u590d\u8865\u4e01\u7684\u6709\u6548\u6027\u548c\u641c\u7d22\u6548\u7387\u4e0a\u5b58\u5728\u5c40\u9650\uff1a\u4e00\u662f\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\u5bfc\u81f4\u8865\u4e01\u80fd\u529b\u6709\u9650\uff0c\u4e8c\u662f\u5197\u4f59\u641c\u7d22\u9020\u6210\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86 APRMCTS \u65b9\u6cd5\uff0c\u5c06\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\u5f15\u5165\u5230 LLM \u9a71\u52a8\u7684\u8865\u4e01\u641c\u7d22\u4e2d\uff0c\u5b9e\u73b0\u5bf9\u6240\u6709\u63a2\u7d22\u8865\u4e01\u7684\u5168\u5c40\u8bc4\u4f30\uff0c\u6bcf\u8f6e\u9009\u62e9\u6700\u6709\u524d\u666f\u7684\u8865\u4e01\u8fdb\u4e00\u6b65\u7cbe\u4fee\u548c\u751f\u6210\uff0c\u5b9e\u73b0\u5168\u5c40\u5316\u3001\u9ad8\u6548\u7684\u8865\u4e01\u641c\u7d22\u3002", "result": "\u5728 Defects4J \u7684 835 \u4e2a\u771f\u5b9e bug \u4e0a\u5b9e\u9a8c\uff0cAPRMCTS \u4e0e GPT-3.5 \u96c6\u6210\u540e\u53ef\u4fee\u590d 201 \u4e2a bug\uff0c\u8d85\u8d8a\u6240\u6709 SOTA \u65b9\u6cd5\u3002\u540c\u65f6\uff0cAPRMCTS \u4e5f\u80fd\u63d0\u5347\u591a\u4e2a\u4e3b\u6d41\u6a21\u578b\u7684\u4fee\u590d\u80fd\u529b\uff0c\u5e76\u5728\u8865\u4e01\u751f\u6210\u6570\u91cf\u8fdc\u5c11\u4e8e\u524d\u4eba\uff08\u4ec516\u621632\u4e2a\u8865\u4e01\uff09\u4e0b\u53d6\u5f97\u663e\u8457\u6027\u80fd\u3002\u65f6\u95f4\u548c\u91d1\u94b1\u6210\u672c\u8f83\u76ee\u524d\u6700\u4f73\u65b9\u6cd5\u5206\u522b\u964d\u4f4e\u81f320%\u548c50%\u4ee5\u5185\u3002", "conclusion": "APRMCTS \u80fd\u6709\u6548\u907f\u514d\u9677\u5165\u5c40\u90e8\u6700\u4f18\uff0c\u5728\u63d0\u5347\u81ea\u52a8\u4fee\u590d\u6709\u6548\u6027\u548c\u6548\u7387\u4e0a\u5177\u660e\u663e\u4f18\u52bf\uff0c\u7279\u522b\u5728\u89e3\u51b3\u590d\u6742\u7a0b\u5e8f\u7f3a\u9677\u65f6\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2507.01278", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01278", "abs": "https://arxiv.org/abs/2507.01278", "authors": ["Cindy Lie Tabuse", "David Restepo", "Carolina Gracitelli", "Fernando Korn Malerbi", "Caio Regatieri", "Luis Filipe Nakayama"], "title": "Evaluating Large Language Models for Multimodal Simulated Ophthalmic Decision-Making in Diabetic Retinopathy and Glaucoma Screening", "comment": null, "summary": "Large language models (LLMs) can simulate clinical reasoning based on natural\nlanguage prompts, but their utility in ophthalmology is largely unexplored.\nThis study evaluated GPT-4's ability to interpret structured textual\ndescriptions of retinal fundus photographs and simulate clinical decisions for\ndiabetic retinopathy (DR) and glaucoma screening, including the impact of\nadding real or synthetic clinical metadata. We conducted a retrospective\ndiagnostic validation study using 300 annotated fundus images. GPT-4 received\nstructured prompts describing each image, with or without patient metadata. The\nmodel was tasked with assigning an ICDR severity score, recommending DR\nreferral, and estimating the cup-to-disc ratio for glaucoma referral.\nPerformance was evaluated using accuracy, macro and weighted F1 scores, and\nCohen's kappa. McNemar's test and change rate analysis were used to assess the\ninfluence of metadata. GPT-4 showed moderate performance for ICDR\nclassification (accuracy 67.5%, macro F1 0.33, weighted F1 0.67, kappa 0.25),\ndriven mainly by correct identification of normal cases. Performance improved\nin the binary DR referral task (accuracy 82.3%, F1 0.54, kappa 0.44). For\nglaucoma referral, performance was poor across all settings (accuracy ~78%, F1\n<0.04, kappa <0.03). Metadata inclusion did not significantly affect outcomes\n(McNemar p > 0.05), and predictions remained consistent across conditions.\nGPT-4 can simulate basic ophthalmic decision-making from structured prompts but\nlacks precision for complex tasks. While not suitable for clinical use, LLMs\nmay assist in education, documentation, or image annotation workflows in\nophthalmology.", "AI": {"tldr": "GPT-4\u5728\u773c\u79d1\u7cd6\u5c3f\u75c5\u89c6\u7f51\u819c\u75c5\u53d8\u548c\u9752\u5149\u773c\u7b5b\u67e5\u4e2d\u80fd\u901a\u8fc7\u6587\u672c\u63d0\u793a\u6a21\u62df\u57fa\u7840\u4e34\u5e8a\u51b3\u7b56\uff0c\u4f46\u7cbe\u5ea6\u6709\u9650\uff0c\u5c24\u5176\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002\u52a0\u5165\u60a3\u8005\u5143\u6570\u636e\u5bf9\u5176\u8bca\u65ad\u6027\u80fd\u65e0\u663e\u8457\u5f71\u54cd\u3002\u76ee\u524d\u4e0d\u9002\u5408\u76f4\u63a5\u4e34\u5e8a\u5e94\u7528\uff0c\u4f46\u6709\u671b\u5728\u6559\u5b66\u6216\u6570\u636e\u6807\u6ce8\u9886\u57df\u63d0\u4f9b\u652f\u6301\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5982GPT-4\u5728\u81ea\u7136\u8bed\u8a00\u4e34\u5e8a\u63a8\u7406\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u773c\u79d1\u9886\u57df\u7684\u5e94\u7528\u672a\u88ab\u5e7f\u6cdb\u63a2\u7d22\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30GPT-4\u901a\u8fc7\u7ed3\u6784\u5316\u6587\u672c\u63cf\u8ff0\u89c6\u7f51\u819c\u7167\u7247\u5e76\u6a21\u62df\u4e0e\u7cd6\u5c3f\u75c5\u89c6\u7f51\u819c\u75c5\u53d8\uff08DR\uff09\u548c\u9752\u5149\u773c\u7b5b\u67e5\u76f8\u5173\u7684\u4e34\u5e8a\u51b3\u7b56\u7684\u80fd\u529b\uff0c\u5c24\u5176\u662f\u8003\u5bdf\u6dfb\u52a0\u771f\u5b9e\u6216\u5408\u6210\u60a3\u8005\u5143\u6570\u636e\u7684\u5f71\u54cd\u3002", "method": "\u672c\u7814\u7a76\u4e3a\u56de\u987e\u6027\u8bca\u65ad\u9a8c\u8bc1\u7814\u7a76\uff0c\u57fa\u4e8e300\u5f20\u5e26\u6ce8\u91ca\u7684\u773c\u5e95\u7167\u7247\u3002GPT-4\u5206\u522b\u6839\u636e\u4ec5\u542b\u56fe\u50cf\u63cf\u8ff0\u6216\u7ed3\u5408\u60a3\u8005\u5143\u6570\u636e\u7684\u7ed3\u6784\u5316\u63d0\u793a\uff0c\u5b8c\u6210ICDR\u4e25\u91cd\u7a0b\u5ea6\u8bc4\u5206\u3001DR\u8f6c\u8bca\u5efa\u8bae\u548c\u9752\u5149\u773c\u8f6c\u8bca\u6240\u9700\u7684\u89c6\u76d8\u676f\u76d8\u6bd4\u4f30\u7b97\u3002\u7528\u51c6\u786e\u7387\u3001macro/weighted F1\u5206\u6570\u53caCohen's kappa\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30\uff0c\u5229\u7528McNemar\u68c0\u9a8c\u548c\u53d8\u5316\u7387\u5206\u6790\u5224\u65ad\u5143\u6570\u636e\u5f71\u54cd\u3002", "result": "GPT-4\u5bf9\u4e8eICDR\u5206\u7ea7\u8868\u73b0\u4e3a\u4e2d\u7b49\uff08\u51c6\u786e\u738767.5%\uff0cmacro F1 0.33\uff0cweighted F1 0.67\uff0ckappa 0.25\uff09\uff0c\u4e3b\u8981\u51c6\u786e\u5728\u6b63\u5e38\u75c5\u4f8b\u3002DR\u4e8c\u5143\u8f6c\u8bca\u4efb\u52a1\u8868\u73b0\u66f4\u597d\uff08\u51c6\u786e\u738782.3%\uff0cF1 0.54\uff0ckappa 0.44\uff09\u3002\u9752\u5149\u773c\u8f6c\u8bca\u6240\u6709\u8bbe\u7f6e\u8868\u73b0\u8f83\u5dee\uff08\u51c6\u786e\u7387\u7ea678%\uff0cF1<0.04\uff0ckappa<0.03\uff09\u3002\u5143\u6570\u636e\u7684\u52a0\u5165\u5bf9\u7ed3\u679c\u5f71\u54cd\u4e0d\u663e\u8457\uff08p>0.05\uff09\uff0c\u5404\u6761\u4ef6\u4e0b\u9884\u6d4b\u4e00\u81f4\u6027\u8f83\u9ad8\u3002", "conclusion": "GPT-4\u53ef\u901a\u8fc7\u7ed3\u6784\u5316\u6587\u672c\u63d0\u793a\u6a21\u62df\u57fa\u7840\u7684\u773c\u79d1\u51b3\u7b56\uff0c\u4f46\u5bf9\u590d\u6742\u4efb\u52a1\u7cbe\u5ea6\u6709\u9650\u3002\u76ee\u524d\u5e76\u4e0d\u9002\u7528\u4e8e\u4e34\u5e8a\uff0c\u4f46\u53ef\u8f85\u52a9\u6559\u80b2\u3001\u6587\u6863\u8bb0\u5f55\u6216\u56fe\u50cf\u6807\u6ce8\u7b49\u5de5\u4f5c\u3002"}}
{"id": "2507.01281", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.01281", "abs": "https://arxiv.org/abs/2507.01281", "authors": ["Juan Chen", "Baolong Bi", "Wei Zhang", "Jingyan Sui", "Xiaofei Zhu", "Yuanzhuo Wang", "Lingrui Mei", "Shenghua Liu"], "title": "Rethinking All Evidence: Enhancing Trustworthy Retrieval-Augmented Generation via Conflict-Driven Summarization", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by\nintegrating their parametric knowledge with external retrieved content.\nHowever, knowledge conflicts caused by internal inconsistencies or noisy\nretrieved content can severely undermine the generation reliability of RAG\nsystems.In this work, we argue that LLMs should rethink all evidence, including\nboth retrieved content and internal knowledge, before generating responses.We\npropose CARE-RAG (Conflict-Aware and Reliable Evidence for RAG), a novel\nframework that improves trustworthiness through Conflict-Driven Summarization\nof all available evidence.CARE-RAG first derives parameter-aware evidence by\ncomparing parameter records to identify diverse internal perspectives. It then\nrefines retrieved evidences to produce context-aware evidence, removing\nirrelevant or misleading content. To detect and summarize conflicts, we distill\na 3B LLaMA3.2 model to perform conflict-driven summarization, enabling reliable\nsynthesis across multiple sources.To further ensure evaluation integrity, we\nintroduce a QA Repair step to correct outdated or ambiguous benchmark\nanswers.Experiments on revised QA datasets with retrieval data show that\nCARE-RAG consistently outperforms strong RAG baselines, especially in scenarios\nwith noisy or conflicting evidence.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u7684RAG\u6846\u67b6\u2014CARE-RAG\uff0c\u53ef\u6709\u6548\u68c0\u6d4b\u548c\u5904\u7406\u8bc1\u636e\u95f4\u51b2\u7a81\uff0c\u63d0\u9ad8\u590d\u6742\u68c0\u7d22\u73af\u5883\u4e0b\u7684\u751f\u6210\u53ef\u9760\u6027\uff0c\u5728\u5404\u79cd\u542b\u51b2\u7a81\u6216\u566a\u58f0\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u4e8e\u4f20\u7edfRAG\u7ec4\u6210\u3002", "motivation": "RAG\u5728\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u5916\u90e8\u68c0\u7d22\u5185\u5bb9\u7ed3\u5408\u65f6\u53ef\u80fd\u5f15\u5165\u77e5\u8bc6\u51b2\u7a81\uff0c\u5185\u90e8\u4e0d\u4e00\u81f4\u6216\u68c0\u7d22\u5185\u5bb9\u566a\u58f0\u4f1a\u5f71\u54cd\u751f\u6210\u7ed3\u679c\u7684\u53ef\u9760\u6027\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u5347RAG\u7cfb\u7edf\u9762\u5bf9\u51b2\u7a81\u548c\u4e0d\u4e00\u81f4\u65f6\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51faCARE-RAG\u6846\u67b6\uff0c\u5305\u542b\u53c2\u6570\u611f\u77e5\u8bc1\u636e\u7684\u63d0\u53d6\u3001\u68c0\u7d22\u8bc1\u636e\u7684\u8fc7\u6ee4\u4e0e\u7cbe\u70bc\u3001\u51b2\u7a81\u9a71\u52a8\u6458\u8981\u3001\u4ee5\u53caQA\u4fee\u590d\u6b65\u9aa4\uff0c\u4ee5\u5b9e\u73b0\u591a\u6765\u6e90\u8bc1\u636e\u7684\u53ef\u9760\u7efc\u5408\u548c\u7b54\u6848\u4fee\u6b63\u3002\u6838\u5fc3\u65b9\u6cd5\u5305\u62ec\u4f7f\u7528\u7279\u5b9a\u6a21\u578b\u5bf9\u8bc1\u636e\u8fdb\u884c\u51b2\u7a81\u68c0\u6d4b\u548c\u6458\u8981\u3002", "result": "\u5728\u4fee\u8ba2\u8fc7\u7684QA\u6570\u636e\u96c6\u548c\u5305\u542b\u68c0\u7d22\u6570\u636e\u7684\u5b9e\u9a8c\u4e2d\uff0cCARE-RAG\u5728\u6709\u566a\u58f0\u6216\u51b2\u7a81\u8bc1\u636e\u60c5\u51b5\u4e0b\uff0c\u76f8\u8f83\u4e8e\u5df2\u6709\u7684\u5f3aRAG\u57fa\u7ebf\u8868\u73b0\u51fa\u6301\u7eed\u66f4\u4f18\u7684\u6027\u80fd\u3002", "conclusion": "CARE-RAG\u901a\u8fc7\u51b2\u7a81\u611f\u77e5\u7684\u8bc1\u636e\u5904\u7406\u548c\u591a\u5c42\u4fdd\u8bc1\u751f\u6210\u8d28\u91cf\u63aa\u65bd\uff0c\u663e\u8457\u63d0\u5347\u4e86RAG\u7cfb\u7edf\u9762\u5bf9\u4fe1\u606f\u51b2\u7a81\u548c\u4e0d\u4e00\u81f4\u65f6\u7684\u53ef\u9760\u6027\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2507.01297", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.01297", "abs": "https://arxiv.org/abs/2507.01297", "authors": ["Xinxi Lyu", "Michael Duan", "Rulin Shao", "Pang Wei Koh", "Sewon Min"], "title": "Frustratingly Simple Retrieval Improves Challenging, Reasoning-Intensive Benchmarks", "comment": "33 pages, 2 figures, 27 tables", "summary": "Retrieval-augmented Generation (RAG) has primarily been studied in limited\nsettings, such as factoid question answering; more challenging,\nreasoning-intensive benchmarks have seen limited success from minimal RAG. In\nthis work, we challenge this prevailing view on established,\nreasoning-intensive benchmarks: MMLU, MMLU Pro, AGI Eval, GPQA, and MATH. We\nidentify a key missing component in prior work: a usable, web-scale datastore\naligned with the breadth of pretraining data. To this end, we introduce\nCompactDS: a diverse, high-quality, web-scale datastore that achieves high\nretrieval accuracy and subsecond latency on a single-node. The key insights are\n(1) most web content can be filtered out without sacrificing coverage, and a\ncompact, high-quality subset is sufficient; and (2) combining in-memory\napproximate nearest neighbor (ANN) retrieval and on-disk exact search balances\nspeed and recall. Using CompactDS, we show that a minimal RAG pipeline achieves\nconsistent accuracy improvements across all benchmarks and model sizes\n(8B--70B), with relative gains of 10% on MMLU, 33% on MMLU Pro, 14% on GPQA,\nand 19% on MATH. No single data source suffices alone, highlighting the\nimportance of diversity of sources (web crawls, curated math, academic papers,\ntextbooks). Finally, we show that our carefully designed in-house datastore\nmatches or outperforms web search engines such as Google Search, as well as\nrecently proposed, complex agent-based RAG systems--all while maintaining\nsimplicity, reproducibility, and self-containment. We release CompactDS and our\nretrieval pipeline, supporting future research exploring retrieval-based AI\nsystems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9ad8\u8d28\u91cfweb\u7ea7\u6570\u636e\u5b58\u50a8CompactDS\uff0c\u63d0\u5347RAG\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u6548\u7387\u548c\u8868\u73b0\u4f18\u4e8e\u4e3b\u6d41\u68c0\u7d22\u5de5\u5177\u548c\u590d\u6742RAG\u7cfb\u7edf\uff0c\u5de5\u5177\u4ee3\u7801\u5df2\u5f00\u653e\u3002", "motivation": "\u73b0\u6709RAG\u4e3b\u8981\u5728\u7b80\u5355\u4efb\u52a1\uff08\u5982\u4e8b\u5b9e\u578b\u95ee\u7b54\uff09\u4e2d\u53d6\u5f97\u6210\u679c\uff0c\u800c\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u6709\u9650\u3002\u4f5c\u8005\u8ba4\u4e3a\u95ee\u9898\u5728\u4e8e\u7f3a\u4e4f\u4e00\u4e2a\u80fd\u4e0e\u9884\u8bad\u7ec3\u6570\u636e\u5e7f\u5ea6\u5bf9\u9f50\u7684\u3001\u53ef\u7528\u7684web\u7ea7\u6570\u636e\u5b58\u50a8\u3002", "method": "\u63d0\u51fa\u4e86CompactDS\uff0c\u4e00\u4e2a\u9ad8\u8d28\u91cf\u3001\u591a\u6837\u5316\u3001web\u7ea7\u7684\u6570\u636e\u5b58\u50a8\uff0c\u80fd\u591f\u5728\u5355\u8282\u70b9\u5b9e\u73b0\u9ad8\u6548\u68c0\u7d22\u3002\u6280\u672f\u6838\u5fc3\u5728\u4e8e\uff1a\u5927\u90e8\u5206Web\u5185\u5bb9\u53ef\u8fc7\u6ee4\uff0c\u4fdd\u7559\u7d27\u51d1\u9ad8\u8d28\u91cf\u5b50\u96c6\u5373\u53ef\uff1b\u5e76\u901a\u8fc7\u5185\u5b58\u4e2d\u7684\u8fd1\u4f3c\u6700\u8fd1\u90bb\u68c0\u7d22\u4e0e\u78c1\u76d8\u4e0a\u7684\u7cbe\u786e\u68c0\u7d22\u7ed3\u5408\u4ee5\u5e73\u8861\u901f\u5ea6\u548c\u53ec\u56de\u7387\u3002\u5c06CompactDS\u4e0e\u4e00\u4e2aminimal RAG\u6d41\u6c34\u7ebf\u7ed3\u5408\uff0c\u5e76\u548c\u4e3b\u6d41\u68c0\u7d22\u7cfb\u7edf\u548c\u590d\u6742RAG\u4ee3\u7406\u7cfb\u7edf\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u5728MMLU, MMLU Pro, AGI Eval, GPQA\u548cMATH\u7b49\u63a8\u7406\u5bc6\u96c6\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u65e0\u8bba\u6a21\u578b\u89c4\u6a21\u5982\u4f55\uff088B-70B\uff09\uff0c\u8be5\u65b9\u6cd5\u90fd\u53d6\u5f97\u4e86\u6301\u7eed\u7684\u51c6\u786e\u7387\u63d0\u5347\uff0cMMLU\u4e0a\u63d0\u534710%\uff0cGPQA\u63d0\u534714%\uff0cMATH\u63d0\u534719%\uff1b\u5355\u4e00\u6570\u636e\u6e90\u6548\u679c\u6709\u9650\uff0c\u6570\u636e\u6765\u6e90\u591a\u6837\u6027\u975e\u5e38\u91cd\u8981\uff1b\u81ea\u5df1\u7684\u6570\u636e\u5b58\u50a8\u65b9\u6848\u4e0eGoogle\u7b49\u4e3b\u6d41\u641c\u7d22\u5f15\u64ce\u8868\u73b0\u76f8\u5f53\u6216\u66f4\u4f18\uff0c\u4e14\u4f18\u4e8e\u590d\u6742RAG\u7cfb\u7edf\u3002", "conclusion": "\u4f5c\u8005\u63d0\u51fa\u7684CompactDS\u6570\u636e\u5b58\u50a8\u548cRAG\u7ba1\u9053\u5728\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\uff0c\u5177\u6709\u9ad8\u6548\u6027\u3001\u591a\u6837\u6027\u548c\u53ef\u590d\u73b0\u6027\uff0c\u5e76\u516c\u5f00\u4e86\u5168\u90e8\u5de5\u5177\u4ee5\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2507.01299", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01299", "abs": "https://arxiv.org/abs/2507.01299", "authors": ["Kai Liu", "Bowen Xu", "Shaoyu Wu", "Xin Chen", "Hao Zhou", "Yongliang Tao", "Lulu Hu"], "title": "La RoSA: Enhancing LLM Efficiency via Layerwise Rotated Sparse Activation", "comment": "ICML 2025 Acceptance", "summary": "Activation sparsity can reduce the computational overhead and memory\ntransfers during the forward pass of Large Language Model (LLM) inference.\nExisting methods face limitations, either demanding time-consuming recovery\ntraining that hinders real-world adoption, or relying on empirical\nmagnitude-based pruning, which causes fluctuating sparsity and unstable\ninference speed-up. This paper introduces LaRoSA (Layerwise Rotated Sparse\nActivation), a novel method for activation sparsification designed to improve\nLLM efficiency without requiring additional training or magnitude-based\npruning. We leverage layerwise orthogonal rotations to transform input\nactivations into rotated forms that are more suitable for sparsification. By\nemploying a Top-K selection approach within the rotated activations, we achieve\nconsistent model-level sparsity and reliable wall-clock time speed-up. LaRoSA\nis effective across various sizes and types of LLMs, demonstrating minimal\nperformance degradation and robust inference acceleration. Specifically, for\nLLaMA2-7B at 40% sparsity, LaRoSA achieves a mere 0.17 perplexity gap with a\nconsistent 1.30x wall-clock time speed-up, and reduces the accuracy gap in\nzero-shot tasks compared to the dense model to just 0.54%, while surpassing\nTEAL by 1.77% and CATS by 17.14%.", "AI": {"tldr": "LaRoSA\u901a\u8fc7\u5bf9\u6bcf\u5c42\u6fc0\u6d3b\u7684\u65cb\u8f6c\u53d8\u6362\u548cTop-K\u7b5b\u9009\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u518d\u8bad\u7ec3\u7684\u7a33\u5b9a\u6fc0\u6d3b\u7a00\u758f\u5316\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u901f\u5ea6\u548c\u6548\u7387\uff0c\u4e14\u517c\u987e\u7cbe\u5ea6\uff0c\u4f18\u4e8e\u73b0\u6709\u540c\u7c7b\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6fc0\u6d3b\u7a00\u758f\u5316\u65b9\u6cd5\u5728\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6548\u7387\u65f6\uff0c\u8981\u4e48\u9700\u8981\u6162\u4e14\u590d\u6742\u7684\u518d\u8bad\u7ec3\uff0c\u5f71\u54cd\u5b9e\u9645\u5e94\u7528\uff0c\u8981\u4e48\u4f9d\u636e\u6fc0\u6d3b\u503c\u5927\u5c0f\u8fdb\u884c\u526a\u679d\uff0c\u5bfc\u81f4\u7a00\u758f\u6027\u548c\u63a8\u7406\u52a0\u901f\u6548\u679c\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51faLaRoSA\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u6bcf\u4e00\u5c42\u7684\u6fc0\u6d3b\u8fdb\u884c\u6b63\u4ea4\u65cb\u8f6c\uff0c\u518d\u5728\u65cb\u8f6c\u540e\u7684\u6fc0\u6d3b\u7a7a\u95f4\u91c7\u7528Top-K\u9009\u62e9\uff0c\u5b9e\u73b0\u7a33\u5b9a\u7684\u6a21\u578b\u7ea7\u7a00\u758f\u4e0e\u63a8\u7406\u52a0\u901f\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u4f20\u7edf\u7684\u57fa\u4e8e\u5e45\u503c\u7684\u526a\u679d\u3002", "result": "LaRoSA\u5bf9\u4e0d\u540c\u7c7b\u578b\u548c\u89c4\u6a21\u7684LLM\u5747\u6709\u6548\uff0c\u51e0\u4e4e\u65e0\u6027\u80fd\u635f\u5931\uff0c\u540c\u65f6\u52a0\u901f\u660e\u663e\uff0c\u5982LLaMA2-7B\u572840%\u7a00\u758f\u5ea6\u4e0b\u4ec5\u635f\u59310.17\u56f0\u60d1\u5ea6\uff0c\u5b9e\u73b01.30\u500d\u52a0\u901f\uff0c\u96f6\u6837\u672c\u4efb\u52a1\u51c6\u786e\u7387\u4ec5\u4e0b\u964d0.54%\uff0c\u4f18\u4e8eTEAL\u548cCATS\u3002", "conclusion": "LaRoSA\u662f\u4e00\u79cd\u7b80\u5355\u9ad8\u6548\u3001\u4fbf\u4e8e\u843d\u5730\u7684\u6fc0\u6d3b\u7a00\u758f\u5316\u65b9\u6848\uff0c\u65e0\u9700\u518d\u8bad\u7ec3\u4e14\u80fd\u4fdd\u8bc1\u6301\u7eed\u7684\u63a8\u7406\u52a0\u901f\u4e0e\u6a21\u578b\u7cbe\u5ea6\uff0c\u5728\u5b9e\u9645LLM\u63a8\u7406\u4e2d\u5177\u6709\u5f88\u9ad8\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.01334", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01334", "abs": "https://arxiv.org/abs/2507.01334", "authors": ["Nifu Dan", "Yujun Cai", "Yiwei Wang"], "title": "Symbolic or Numerical? Understanding Physics Problem Solving in Reasoning LLMs", "comment": null, "summary": "Navigating the complexities of physics reasoning has long been a difficult\ntask for Large Language Models (LLMs), requiring a synthesis of profound\nconceptual understanding and adept problem-solving techniques. In this study,\nwe investigate the application of advanced instruction-tuned reasoning models,\nsuch as Deepseek-R1, to address a diverse spectrum of physics problems curated\nfrom the challenging SciBench benchmark. Our comprehensive experimental\nevaluation reveals the remarkable capabilities of reasoning models. Not only do\nthey achieve state-of-the-art accuracy in answering intricate physics\nquestions, but they also generate distinctive reasoning patterns that emphasize\non symbolic derivation. Furthermore, our findings indicate that even for these\nhighly sophisticated reasoning models, the strategic incorporation of few-shot\nprompting can still yield measurable improvements in overall accuracy,\nhighlighting the potential for continued performance gains.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\uff0c\u9488\u5bf9\u7269\u7406\u590d\u6742\u63a8\u7406\u9898\uff0c\u5148\u8fdb\u63a8\u7406\u6a21\u578b\uff08\u5982Deepseek-R1\uff09\u4e0d\u4ec5\u51c6\u786e\u7387\u6781\u9ad8\uff0c\u8fd8\u64c5\u957f\u7b26\u53f7\u63a8\u5bfc\uff1b\u5373\u4fbf\u5bf9\u5f3a\u5927\u6a21\u578b\uff0c\u5c11\u6837\u672c\u63d0\u793a\u4f9d\u7136\u80fd\u63d0\u5347\u6548\u679c\u3002", "motivation": "\u7269\u7406\u63a8\u7406\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u800c\u8a00\u4e00\u76f4\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u9700\u8981\u6df1\u523b\u7684\u6982\u5ff5\u7406\u89e3\u548c\u719f\u7ec3\u7684\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u5229\u7528\u5148\u8fdb\u7684\u6307\u4ee4\u5fae\u8c03\u63a8\u7406\u6a21\u578b\u63d0\u5347\u7269\u7406\u95ee\u9898\u7684\u6c42\u89e3\u80fd\u529b\u3002", "method": "\u672c\u6587\u91c7\u7528\u5982Deepseek-R1\u7b49\u5148\u8fdb\u7684\u6307\u4ee4\u5fae\u8c03\u63a8\u7406\u6a21\u578b\uff0c\u5bf9SciBench\u57fa\u51c6\u4e2d\u591a\u6837\u7684\u9ad8\u96be\u5ea6\u7269\u7406\u95ee\u9898\u8fdb\u884c\u5b9e\u9a8c\u6d4b\u8bd5\uff0c\u7cfb\u7edf\u8bc4\u4f30\u6a21\u578b\u7684\u89e3\u9898\u8868\u73b0\uff0c\u5e76\u8003\u5bdf\u5c11\u6837\u672c\u63d0\u793a\uff08few-shot prompting\uff09\u5bf9\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63a8\u7406\u6a21\u578b\u4e0d\u4ec5\u5728\u590d\u6742\u7269\u7406\u95ee\u9898\u4e0a\u53d6\u5f97\u4e86SOTA\u6c34\u5e73\u7684\u51c6\u786e\u7387\uff0c\u8fd8\u5c55\u793a\u4e86\u4ee5\u7b26\u53f7\u63a8\u5bfc\u4e3a\u6838\u5fc3\u7684\u72ec\u7279\u63a8\u7406\u6a21\u5f0f\u3002\u540c\u65f6\uff0c\u7ed3\u5408\u5c11\u6837\u672c\u63d0\u793a\uff0c\u6a21\u578b\u6574\u4f53\u51c6\u786e\u7387\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "conclusion": "\u5148\u8fdb\u7684\u6307\u4ee4\u5fae\u8c03\u63a8\u7406\u6a21\u578b\u5728\u9ad8\u96be\u5ea6\u7269\u7406\u95ee\u9898\u63a8\u7406\u65b9\u9762\u5c55\u73b0\u51fa\u6781\u9ad8\u7684\u80fd\u529b\uff0c\u7b26\u53f7\u63a8\u5bfc\u63a8\u7406\u503c\u5f97\u5173\u6ce8\u3002\u540c\u65f6\uff0c\u5c11\u6837\u672c\u63d0\u793a\u4ecd\u80fd\u4e3a\u6b64\u7c7b\u9ad8\u6027\u80fd\u6a21\u578b\u5e26\u6765\u53ef\u89c2\u589e\u76ca\uff0c\u8868\u660e\u6a21\u578b\u6f5c\u529b\u5c1a\u672a\u7a77\u5c3d\u3002"}}
{"id": "2507.01335", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.01335", "abs": "https://arxiv.org/abs/2507.01335", "authors": ["Xunjian Yin", "Sitao Cheng", "Yuxi Xie", "Xinyu Hu", "Li Lin", "Xinyi Wang", "Liangming Pan", "William Yang Wang", "Xiaojun Wan"], "title": "LEDOM: An Open and Fundamental Reverse Language Model", "comment": "Work in progress", "summary": "We introduce LEDOM, the first purely reverse language model, trained\nautoregressively on 435B tokens with 2B and 7B parameter variants, which\nprocesses sequences in reverse temporal order through previous token\nprediction. For the first time, we present the reverse language model as a\npotential foundational model across general tasks, accompanied by a set of\nintriguing examples and insights. Based on LEDOM, we further introduce a novel\napplication: Reverse Reward, where LEDOM-guided reranking of forward language\nmodel outputs leads to substantial performance improvements on mathematical\nreasoning tasks. This approach leverages LEDOM's unique backward reasoning\ncapability to refine generation quality through posterior evaluation. Our\nfindings suggest that LEDOM exhibits unique characteristics with broad\napplication potential. We will release all models, training code, and\npre-training data to facilitate future research.", "AI": {"tldr": "\u9996\u6b21\u63d0\u51fa\u5e76\u8bad\u7ec3\u4e86\u7eaf\u9006\u5411\u8bed\u8a00\u6a21\u578bLEDOM\uff0c\u5e76\u901a\u8fc7\u9006\u5411\u5956\u52b1\u65b9\u6cd5\u63d0\u5347\u7b97\u6570\u63a8\u7406\u7b49\u4efb\u52a1\u8868\u73b0\uff0c\u5c55\u73b0\u4e86\u9006\u5411\u5efa\u6a21\u7684\u72ec\u7279\u4ef7\u503c\u548c\u6f5c\u529b\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41\u7684\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT\u7cfb\u5217\uff09\u90fd\u662f\u57fa\u4e8e\u4f20\u7edf\u7684\u6b63\u5411\u81ea\u56de\u5f52\u65b9\u5f0f\u8fdb\u884c\u5efa\u6a21\uff0c\u5373\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8bcd\u3002\u7136\u800c\uff0c\u9006\u5411\uff08reverse\uff09\u8bed\u8a00\u5efa\u6a21\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7d22\u9006\u5411\u5efa\u6a21\u7684\u65b9\u6cd5\uff0c\u770b\u662f\u5426\u80fd\u5e26\u6765\u65b0\u7684\u80fd\u529b\u548c\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u5e76\u8bad\u7ec3\u4e86\u5168\u65b0\u7684\u9006\u5411\u8bed\u8a00\u6a21\u578b\uff08LEDOM\uff09\uff0c\u5373\u4ece\u5e8f\u5217\u7ed3\u5c3e\u5411\u8d77\u59cb\u65b9\u5411\u9884\u6d4b\u524d\u4e00\u4e2a\u8bcd\u3002\u4f7f\u7528\u4e862B\u548c7B\u53c2\u6570\u7684\u4e24\u4e2a\u6a21\u578b\u7248\u672c\uff0c\u57284350\u4ebf\u8bcd\u7684\u6570\u636e\u4e0a\u81ea\u56de\u5f52\u8bad\u7ec3\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u4e86\u5229\u7528LEDOM\u8fdb\u884c\u9006\u5411\u5956\u52b1\uff08Reverse Reward\uff09\u7684\u65b0\u5e94\u7528\u65b9\u6cd5\uff1a\u7528LEDOM\u5bf9\u4f20\u7edf\u6b63\u5411\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u7ed3\u679c\u8fdb\u884c\u91cd\u6392\u5e8f\uff0c\u4ece\u800c\u63d0\u5347\u63a8\u7406\u4efb\u52a1\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLEDOM\u5728\u6570\u5b66\u63a8\u7406\u7b49\u4efb\u52a1\u4e2d\uff0c\u901a\u8fc7\u540e\u9a8c\u8bc4\u4f30\u63d0\u5347\u4e86\u6587\u672c\u751f\u6210\u7684\u8d28\u91cf\uff0c\u8868\u73b0\u51fa\u72ec\u7279\u7279\u5f81\u548c\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u9006\u5411\u8bed\u8a00\u6a21\u578b\uff08LEDOM\uff09\u4e0d\u4ec5\u672c\u8eab\u5177\u5907\u72ec\u7279\u4ef7\u503c\uff0c\u8fd8\u53ef\u4ee5\u534f\u540c\u5e38\u89c4\u6b63\u5411\u8bed\u8a00\u6a21\u578b\u5e94\u7528\uff0c\u201c\u9006\u5411\u5956\u52b1\u201d\u7b56\u7565\u53ef\u663e\u8457\u63d0\u5347\u63a8\u7406\u7c7b\u4efb\u52a1\u7684\u51c6\u786e\u6027\u3002\u6240\u6709\u6a21\u578b\u53ca\u6570\u636e\u5c06\u5f00\u6e90\uff0c\u4fc3\u8fdb\u76f8\u5173\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2507.01352", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01352", "abs": "https://arxiv.org/abs/2507.01352", "authors": ["Chris Yuhao Liu", "Liang Zeng", "Yuzhen Xiao", "Jujie He", "Jiacai Liu", "Chaojie Wang", "Rui Yan", "Wei Shen", "Fuxiang Zhang", "Jiacheng Xu", "Yang Liu", "Yahui Zhou"], "title": "Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy", "comment": null, "summary": "Despite the critical role of reward models (RMs) in reinforcement learning\nfrom human feedback (RLHF), current state-of-the-art open RMs perform poorly on\nmost existing evaluation benchmarks, failing to capture the spectrum of nuanced\nand sophisticated human preferences. Even approaches that incorporate advanced\ntraining techniques have not yielded meaningful performance improvements. We\nhypothesize that this brittleness stems primarily from limitations in\npreference datasets, which are often narrowly scoped, synthetically labeled, or\nlack rigorous quality control. To address these challenges, we present a\nlarge-scale preference dataset comprising 40 million preference pairs, named\nSynPref-40M. To enable data curation at scale, we design a human-AI synergistic\ntwo-stage pipeline that leverages the complementary strengths of human\nannotation quality and AI scalability. In this pipeline, humans provide\nverified annotations, while large language models perform automatic curation\nbased on human guidance. Training on this preference mixture, we introduce\nSkywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B\nparameters, trained on a carefully curated subset of 26 million preference\npairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile\nacross a wide range of capabilities, including alignment with human\npreferences, objective correctness, safety, resistance to stylistic biases, and\nbest-of-N scaling, achieving state-of-the-art performance across seven major\nreward model benchmarks. Ablation studies confirm that the effectiveness of our\napproach stems not only from data scale but also from high-quality curation.\nThe Skywork-Reward-V2 series represents substantial progress in open reward\nmodels, highlighting the untapped potential of existing preference datasets and\ndemonstrating how human-AI curation synergy can unlock significantly higher\ndata quality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SynPref-40M\u5927\u89c4\u6a21\u504f\u597d\u6570\u636e\u96c6\u53ca\u4eba\u673a\u534f\u540c\u7b5b\u9009\u6d41\u7a0b\uff0c\u5e76\u57fa\u4e8e\u8be5\u6570\u636e\u96c6\u8bad\u7ec3\u4e86Skywork-Reward-V2\u5956\u52b1\u6a21\u578b\u7cfb\u5217\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u8fbe\u5230SOTA\uff0c\u5f3a\u8c03\u9ad8\u8d28\u91cf\u6570\u636e\u4e0e\u4eba\u673a\u534f\u540c\u5bf9\u4e8e\u5956\u52b1\u6a21\u578b\u6027\u80fd\u7684\u51b3\u5b9a\u6027\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u7684\u5f00\u6e90\u5956\u52b1\u6a21\u578b\uff08RM\uff09\u5728\u4e3b\u6d41\u8bc4\u4ef7\u57fa\u51c6\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u96be\u4ee5\u6355\u6349\u590d\u6742\u7684\u4eba\u7c7b\u504f\u597d\uff0c\u4e14\u5373\u4fbf\u91c7\u7528\u5148\u8fdb\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5b9e\u9645\u63d0\u5347\u6709\u9650\u3002\u4f5c\u8005\u8ba4\u4e3a\uff0c\u95ee\u9898\u4e3b\u8981\u6e90\u81ea\u504f\u597d\u6570\u636e\u96c6\u53d7\u9650\uff0c\u5982\u8303\u56f4\u7a84\u3001\u5408\u6210\u6807\u6ce8\u591a\u3001\u8d28\u91cf\u63a7\u5236\u8584\u5f31\u3002", "method": "\u63d0\u51fa\u4e86\u5927\u89c4\u6a21\u504f\u597d\u6570\u636e\u96c6SynPref-40M\uff08\u5305\u542b4000\u4e07\u4e2a\u504f\u597d\u5bf9\uff09\uff0c\u8bbe\u8ba1\u4e86\u4e00\u5957\u4eba\u673a\u534f\u540c\u7684\u4e24\u9636\u6bb5\u6570\u636e\u7b5b\u9009\u6d41\u7a0b\uff1a\u4eba\u5de5\u63d0\u4f9b\u9ad8\u8d28\u91cf\u6807\u6ce8\uff0c\u5927\u6a21\u578b\u4f9d\u636e\u4eba\u7c7b\u6307\u5bfc\u81ea\u52a8\u8fc7\u6ee4\u3002\u57fa\u4e8e\u7cbe\u9009\u76842600\u4e07\u4e2a\u504f\u597d\u5bf9\uff0c\u8bad\u7ec3\u4e868\u4e2a\u89c4\u6a21\u4ece0.6B\u52308B\u53c2\u6570\u7684Skywork-Reward-V2\u5956\u52b1\u6a21\u578b\u3002", "result": "Skywork-Reward-V2\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u5168\u9762\uff0c\u4e0d\u4ec5\u5bf9\u9f50\u4eba\u7c7b\u504f\u597d\uff0c\u540c\u65f6\u5177\u6709\u9ad8\u5ba2\u89c2\u6b63\u786e\u6027\u3001\u5b89\u5168\u6027\u3001\u98ce\u683c\u6297\u5e72\u6270\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u57287\u4e2a\u4e3b\u6d41\u5956\u52b1\u6a21\u578b\u57fa\u51c6\u4e0a\u53d6\u5f97SOTA\u8868\u73b0\u3002\u6d88\u878d\u5b9e\u9a8c\u663e\u793a\uff0c\u63d0\u5347\u6765\u6e90\u4e8e\u5927\u89c4\u6a21\u4e14\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u7b5b\u9009\u3002", "conclusion": "Skywork-Reward-V2\u5927\u5e45\u63a8\u8fdb\u4e86\u5f00\u6e90\u5956\u52b1\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u8bc1\u660e\u4e86\u9ad8\u8d28\u91cf\u5927\u89c4\u6a21\u504f\u597d\u6570\u636e\u53ca\u4eba\u673a\u534f\u540c\u7b5b\u9009\u5728\u63d0\u5347\u6a21\u578b\u8868\u73b0\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u4e5f\u63ed\u793a\u4e86\u73b0\u6709\u504f\u597d\u6570\u636e\u96c6\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2507.01437", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01437", "abs": "https://arxiv.org/abs/2507.01437", "authors": ["Ting Xu", "Xiaoxiao Deng", "Xiandong Meng", "Haifeng Yang", "Yan Wu"], "title": "Clinical NLP with Attention-Based Deep Learning for Multi-Disease Prediction", "comment": null, "summary": "This paper addresses the challenges posed by the unstructured nature and\nhigh-dimensional semantic complexity of electronic health record texts. A deep\nlearning method based on attention mechanisms is proposed to achieve unified\nmodeling for information extraction and multi-label disease prediction. The\nstudy is conducted on the MIMIC-IV dataset. A Transformer-based architecture is\nused to perform representation learning over clinical text. Multi-layer\nself-attention mechanisms are employed to capture key medical entities and\ntheir contextual relationships. A Sigmoid-based multi-label classifier is then\napplied to predict multiple disease labels. The model incorporates a\ncontext-aware semantic alignment mechanism, enhancing its representational\ncapacity in typical medical scenarios such as label co-occurrence and sparse\ninformation. To comprehensively evaluate model performance, a series of\nexperiments were conducted, including baseline comparisons, hyperparameter\nsensitivity analysis, data perturbation studies, and noise injection tests.\nResults demonstrate that the proposed method consistently outperforms\nrepresentative existing approaches across multiple performance metrics. The\nmodel maintains strong generalization under varying data scales, interference\nlevels, and model depth configurations. The framework developed in this study\noffers an efficient algorithmic foundation for processing real-world clinical\ntexts and presents practical significance for multi-label medical text modeling\ntasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e Transformer \u7684\u533b\u5b66\u6587\u672c\u4fe1\u606f\u62bd\u53d6\u4e0e\u591a\u6807\u7b7e\u75be\u75c5\u9884\u6d4b\u6a21\u578b\u3002\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u8bed\u4e49\u5bf9\u9f50\u63d0\u5347\u8868\u793a\u80fd\u529b\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u4e3b\u6d41\u65b9\u6cd5\u4e14\u5177\u6709\u826f\u597d\u6cdb\u5316\u6027\uff0c\u5bf9\u5b9e\u9645\u533b\u7597\u6587\u672c\u5efa\u6a21\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6587\u672c\u5177\u6709\u975e\u7ed3\u6784\u5316\u548c\u9ad8\u7ef4\u8bed\u4e49\u590d\u6742\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u9ad8\u6548\u5904\u7406\u4fe1\u606f\u62bd\u53d6\u4e0e\u591a\u6807\u7b7e\u75be\u75c5\u9884\u6d4b\u3002\u4e9f\u9700\u7edf\u4e00\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4ee5\u63d0\u5347\u6a21\u578b\u5728\u5b9e\u9645\u533b\u7597\u573a\u666f\u4e0b\u7684\u5e94\u7528\u80fd\u529b\u548c\u6cdb\u5316\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u5c42\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684 Transformer \u67b6\u6784\uff0c\u8fdb\u884c\u4e34\u5e8a\u6587\u672c\u7684\u8868\u793a\u5b66\u4e60\u3002\u91c7\u7528\u4e86 context-aware \u8bed\u4e49\u5bf9\u9f50\u673a\u5236\u63d0\u5347\u6a21\u578b\u8868\u5f81\u80fd\u529b\uff0c\u5e76\u901a\u8fc7 Sigmoid \u591a\u6807\u7b7e\u5206\u7c7b\u5668\u5b9e\u73b0\u591a\u6807\u7b7e\u75be\u75c5\u9884\u6d4b\u3002\u8bbe\u8ba1\u4e86\u5305\u62ec\u57fa\u7ebf\u5bf9\u6bd4\u3001\u8d85\u53c2\u6570\u5206\u6790\u3001\u6570\u636e\u6270\u52a8\u548c\u566a\u58f0\u6ce8\u5165\u7b49\u5b9e\u9a8c\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u591a\u9879\u6027\u80fd\u6307\u6807\u4e0a\u8d85\u8d8a\u4ee3\u8868\u6027\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u80fd\u5728\u4e0d\u540c\u6570\u636e\u89c4\u6a21\u3001\u5e72\u6270\u548c\u6df1\u5ea6\u6761\u4ef6\u4e0b\u7a33\u5b9a\u6cdb\u5316\u3002\u8be5\u6a21\u578b\u5904\u7406\u771f\u5b9e\u4e34\u5e8a\u6587\u672c\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e Transformer \u548c\u6ce8\u610f\u529b\u673a\u5236\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u591a\u6807\u7b7e\u75be\u75c5\u9884\u6d4b\u548c\u4fe1\u606f\u62bd\u53d6\u4efb\u52a1\u4e0a\uff0c\u6574\u4f53\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\uff0c\u5e76\u5728\u4e0d\u540c\u6570\u636e\u89c4\u6a21\u548c\u5e72\u6270\u6761\u4ef6\u4e0b\u4f9d\u7136\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002\u8be5\u6846\u67b6\u4e3a\u5b9e\u9645\u533b\u7597\u6587\u672c\u5904\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u7b97\u6cd5\u57fa\u7840\u3002"}}
{"id": "2507.01449", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01449", "abs": "https://arxiv.org/abs/2507.01449", "authors": ["Tianyu Liu", "Qitan Lv", "Hao Li", "Xing Gao", "Xiao Sun"], "title": "LogitSpec: Accelerating Retrieval-based Speculative Decoding via Next Next Token Speculation", "comment": null, "summary": "Speculative decoding (SD), where a small draft model is employed to propose\ndraft tokens in advance and then the target model validates them in parallel,\nhas emerged as a promising technique for LLM inference acceleration. Many\nendeavors to improve SD are to eliminate the need for a draft model and\ngenerate draft tokens in a retrieval-based manner in order to further alleviate\nthe drafting overhead and significantly reduce the difficulty in deployment and\napplications. However, retrieval-based SD relies on a matching paradigm to\nretrieval the most relevant reference as the draft tokens, where these methods\noften fail to find matched and accurate draft tokens. To address this\nchallenge, we propose LogitSpec to effectively expand the retrieval range and\nfind the most relevant reference as drafts. Our LogitSpec is motivated by the\nobservation that the logit of the last token can not only predict the next\ntoken, but also speculate the next next token. Specifically, LogitSpec\ngenerates draft tokens in two steps: (1) utilizing the last logit to speculate\nthe next next token; (2) retrieving relevant reference for both the next token\nand the next next token. LogitSpec is training-free and plug-and-play, which\ncan be easily integrated into existing LLM inference frameworks. Extensive\nexperiments on a wide range of text generation benchmarks demonstrate that\nLogitSpec can achieve up to 2.61 $\\times$ speedup and 3.28 mean accepted tokens\nper decoding step. Our code is available at\nhttps://github.com/smart-lty/LogitSpec.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u6a21\u578blogit\u7684\u68c0\u7d22\u5f0f\u63a8\u7406\u52a0\u901f\u65b9\u6cd5LogitSpec\uff0c\u65e0\u9700\u8f85\u52a9\u8d77\u8349\u6a21\u578b\uff0c\u53ef\u4ee5\u5728\u73b0\u6709LLM\u7cfb\u7edf\u4e2d\u76f4\u63a5\u4f7f\u7528\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u660e\u663e\u7684\u63a8\u7406\u63d0\u901f\u548c\u9ad8\u6548draft tokens\u751f\u6210\u80fd\u529b\u3002", "motivation": "\u63a8\u65ad\u52a0\u901f\u5bf9\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5b9e\u9645\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7684Speculative Decoding(SD)\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e00\u4e2a\u989d\u5916\u7684\u5c0f\u578b\u8d77\u8349\u6a21\u578b\uff08draft model\uff09\uff0c\u4ee5\u964d\u4f4e\u63a8\u7406\u5ef6\u65f6\uff0c\u4f46\u8d77\u8349\u6a21\u578b\u672c\u8eab\u7684\u90e8\u7f72\u548c\u8ba1\u7b97\u8d1f\u62c5\u4f9d\u7136\u5b58\u5728\u3002\u56e0\u6b64\uff0c\u8fd1\u6765\u7684\u5c1d\u8bd5\u96c6\u4e2d\u5728\u53bb\u9664draft model\uff0c\u8f6c\u5411\u68c0\u7d22\u5f0f\u8d77\u8349\u6765\u51cf\u5c11\u5f00\u9500\u548c\u5e94\u7528\u96be\u5ea6\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684\u68c0\u7d22\u5f0f\u8d77\u8349\u56e0\u4f9d\u8d56\u5339\u914d\u673a\u5236\uff0c\u96be\u4ee5\u627e\u5230\u9ad8\u5ea6\u76f8\u5173\u4e14\u7cbe\u51c6\u7684draft tokens\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u68c0\u7d22\u5f0f\u63a8\u7406\u52a0\u901f\u65b9\u6cd5\uff0c\u79f0\u4e3aLogitSpec\u3002LogitSpec \u5229\u7528\u5927\u6a21\u578b\u7684\u6700\u540e\u4e00\u4e2atoken\u7684logit\uff0c\u4e0d\u4ec5\u9884\u6d4b\u4e0b\u4e00\u4e2atoken\uff0c\u8fd8\u63a8\u6d4b\u4e0b\u4e0b\u4e2atoken\u3002\u5177\u4f53\u65b9\u6cd5\u5206\u4e3a\u4e24\u6b65\uff1a\uff081\uff09\u901a\u8fc7\u6700\u540etoken\u7684logit\u63a8\u6d4b\u4e0b\u4e0b\u4e2atoken\uff1b\uff082\uff09\u540c\u65f6\u4e3a\u4e0b\u4e00\u4e2a\u548c\u4e0b\u4e0b\u4e2atoken\u68c0\u7d22\u76f8\u5173\u7684\u53c2\u8003\uff0c\u4ece\u800c\u62d3\u5c55\u68c0\u7d22\u8303\u56f4\uff0c\u63d0\u9ad8\u627e\u5230\u5408\u9002draft tokens\u7684\u6210\u529f\u7387\u3002\u6574\u4e2a\u65b9\u6cd5\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u4e14\u53ef\u76f4\u63a5\u96c6\u6210\u5230\u73b0\u6709LLM\u63a8\u7406\u7cfb\u7edf\u3002", "result": "\u5728\u591a\u4e2a\u6587\u672c\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\uff0cLogitSpec\u6700\u591a\u53ef\u5b9e\u73b02.61\u500d\u7684\u63a8\u7406\u901f\u5ea6\u63d0\u5347\uff0c\u5e73\u5747\u6bcf\u6b65\u53ef\u63a5\u53d7\u7b7e\u53d1token\u6570\u8fbe\u52303.28\u3002", "conclusion": "LogitSpec\u4e0d\u4f9d\u8d56\u8d77\u8349\u6a21\u578b\uff0c\u901a\u8fc7\u6269\u5c55\u68c0\u7d22\u8303\u56f4\u5e76\u5229\u7528\u5927\u6a21\u578blogit\u63a8\u7406\u4e0b\u4e0b\u4e2atoken\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u7075\u6d3b\u4e14\u6613\u4e8e\u96c6\u6210\u7684\u63a8\u7406\u52a0\u901f\uff0c\u662fLLM\u63a8\u7406\u52a0\u901f\u7684\u65b0\u8fdb\u5c55\u3002"}}
{"id": "2507.01479", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.01479", "abs": "https://arxiv.org/abs/2507.01479", "authors": ["Yingqiang Gao", "Kaede Johnson", "David Froehlich", "Luisa Carrer", "Sarah Ebling"], "title": "Evaluating the Effectiveness of Direct Preference Optimization for Personalizing German Automatic Text Simplifications for Persons with Intellectual Disabilities", "comment": null, "summary": "Automatic text simplification (ATS) aims to enhance language accessibility\nfor various target groups, particularly persons with intellectual disabilities.\nRecent advancements in generative AI, especially large language models (LLMs),\nhave substantially improved the quality of machine-generated text\nsimplifications, thereby mitigating information barriers for the target group.\nHowever, existing LLM-based ATS systems do not incorporate preference feedback\non text simplifications during training, resulting in a lack of personalization\ntailored to the specific needs of target group representatives.\n  In this work, we extend the standard supervised fine-tuning (SFT) approach\nfor adapting LLM-based ATS models by leveraging a computationally efficient LLM\nalignment technique -- direct preference optimization (DPO). Specifically, we\npost-train LLM-based ATS models using human feedback collected from persons\nwith intellectual disabilities, reflecting their preferences on paired text\nsimplifications generated by mainstream LLMs. Furthermore, we propose a\npipeline for developing personalized LLM-based ATS systems, encompassing data\ncollection, model selection, SFT and DPO post-training, and evaluation. Our\nfindings underscore the necessity of active participation of target group\npersons in designing personalized AI accessibility solutions aligned with human\nexpectations. This work represents a step towards personalizing inclusive AI\nsystems at the target-group level, incorporating insights not only from text\nsimplification experts but also from target group persons themselves.", "AI": {"tldr": "\u5c06\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u65b9\u6cd5\u7528\u4e8eLLM\u6587\u672c\u7b80\u5316\u7cfb\u7edf\uff0c\u5e76\u6536\u96c6\u667a\u529b\u969c\u788d\u8005\u504f\u597d\u53cd\u9988\uff0c\u53ef\u5b9e\u73b0\u66f4\u4e2a\u6027\u5316\u548c\u5305\u5bb9\u6027\u7684\u6587\u672c\u7b80\u5316AI\u7cfb\u7edf\u3002", "motivation": "\u81ea\u52a8\u6587\u672c\u7b80\u5316\uff08ATS\uff09\u65e8\u5728\u5e2e\u52a9\u7279\u5b9a\u7fa4\u4f53\uff08\u5982\u667a\u529b\u969c\u788d\u8005\uff09\u66f4\u597d\u5730\u83b7\u53d6\u4fe1\u606f\uff0c\u4f46\u4f20\u7edfLLM\u7b80\u5316\u7cfb\u7edf\u7f3a\u4e4f\u4e2a\u6027\u5316\uff0c\u65e0\u6cd5\u5145\u5206\u6ee1\u8db3\u76ee\u6807\u7fa4\u4f53\u7684\u5177\u4f53\u9700\u6c42\u3002", "method": "\u5728\u6807\u51c6LLM\u76d1\u7763\u5fae\u8c03\u57fa\u7840\u4e0a\uff0c\u91c7\u7528\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u65b9\u6cd5\u3002\u901a\u8fc7\u6536\u96c6\u667a\u529b\u969c\u788d\u8005\u5bf9\u4e00\u5bf9\u7b80\u5316\u6587\u672c\u7684\u504f\u597d\u53cd\u9988\uff0c\u5bf9\u6a21\u578b\u8fdb\u884c\u518d\u8bad\u7ec3\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u4e86\u4e2a\u6027\u5316LLM-ATS\u7cfb\u7edf\u5f00\u53d1\u7ba1\u7ebf\uff0c\u5305\u62ec\u6570\u636e\u6536\u96c6\u3001\u6a21\u578b\u9009\u62e9\u3001SFT\u548cDPO\u5fae\u8c03\u53ca\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u5f15\u5165\u76ee\u6807\u7fa4\u4f53\u6210\u5458\u7684\u53cd\u9988\u548c\u504f\u597d\uff0c\u8bad\u7ec3\u5f97\u5230\u66f4\u8d34\u5408\u5176\u9700\u6c42\u7684\u4e2a\u6027\u5316ATS\u6a21\u578b\u3002\u5b9e\u9a8c\u7ed3\u679c\u5f3a\u8c03\uff0c\u8ba9\u76ee\u6807\u7528\u6237\u53c2\u4e0e\u8bbe\u8ba1AI\u8f85\u52a9\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u66f4\u5177\u5305\u5bb9\u6027\u548c\u4eba\u6027\u5316\u7684AI\u7cfb\u7edf\u3002", "conclusion": "\u672c\u7814\u7a76\u63a8\u52a8\u4e86\u9762\u5411\u7279\u5b9a\u7fa4\u4f53\u7684AI\u7cfb\u7edf\u4e2a\u6027\u5316\uff0c\u663e\u793a\u4e86\u53d7\u76ca\u4e8e\u76ee\u6807\u7528\u6237\u53c2\u4e0e\u7684\u4eba\u7c7b\u9884\u671f\u5bf9\u9f50\u673a\u5236\uff0c\u4e3a\u66f4\u5177\u5305\u5bb9\u6027\u7684AI\u8f85\u52a9\u5de5\u5177\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.01541", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01541", "abs": "https://arxiv.org/abs/2507.01541", "authors": ["\u00c1lvaro Zaera", "Diana Nicoleta Popa", "Ivan Sekulic", "Paolo Rosso"], "title": "Efficient Out-of-Scope Detection in Dialogue Systems via Uncertainty-Driven LLM Routing", "comment": null, "summary": "Out-of-scope (OOS) intent detection is a critical challenge in task-oriented\ndialogue systems (TODS), as it ensures robustness to unseen and ambiguous\nqueries. In this work, we propose a novel but simple modular framework that\ncombines uncertainty modeling with fine-tuned large language models (LLMs) for\nefficient and accurate OOS detection. The first step applies uncertainty\nestimation to the output of an in-scope intent detection classifier, which is\ncurrently deployed in a real-world TODS handling tens of thousands of user\ninteractions daily. The second step then leverages an emerging LLM-based\napproach, where a fine-tuned LLM is triggered to make a final decision on\ninstances with high uncertainty. Unlike prior approaches, our method\neffectively balances computational efficiency and performance, combining\ntraditional approaches with LLMs and yielding state-of-the-art results on key\nOOS detection benchmarks, including real-world OOS data acquired from a\ndeployed TODS.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u4e0e\u5fae\u8c03LLM\u7684\u65b0\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684OOS\u610f\u56fe\u68c0\u6d4b\uff0c\u5e76\u5728\u771f\u5b9e\u53ca\u6807\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u7684\u4efb\u52a1\u578b\u5bf9\u8bdd\u7cfb\u7edf\uff08TODS\uff09\u5728\u9762\u5bf9\u7528\u6237\u672a\u89c1\u8fc7\u6216\u6a21\u7cca\u67e5\u8be2\u65f6\uff0c\u8bc6\u522b\u8d85\u51fa\u8303\u56f4\uff08OOS\uff09\u610f\u56fe\u7684\u80fd\u529b\u8f83\u5f31\u3002\u63d0\u5347\u7cfb\u7edf\u5bf9\u8fd9\u4e9b\u672a\u77e5\u6216\u6a21\u7cca\u8f93\u5165\u7684\u9c81\u68d2\u6027\u6210\u4e3a\u5173\u952e\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u4e14\u7b80\u6d01\u7684\u6a21\u5757\u5316\u6846\u67b6\uff0c\u5c06\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u4e0e\u5fae\u8c03\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7ed3\u5408\u3002\u7b2c\u4e00\u6b65\uff0c\u57fa\u4e8e\u5f53\u524d\u90e8\u7f72\u5728\u771f\u5b9e\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u7684\u610f\u56fe\u5206\u7c7b\u5668\u7684\u8f93\u51fa\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002\u7b2c\u4e8c\u6b65\uff0c\u5bf9\u9ad8\u4e0d\u786e\u5b9a\u6027\u5b9e\u4f8b\uff0c\u8c03\u7528\u5df2\u7ecf\u5fae\u8c03\u7684LLM\u505a\u6700\u7ec8\u5224\u51b3\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u9ad8\u6548\u4e14\u51c6\u786e\u5730\u8bc6\u522bOOS\u610f\u56fe\uff0c\u5728\u591a\u4e2aOOS\u68c0\u6d4b\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u6700\u65b0\u7684\u6700\u4f73\u7ed3\u679c\uff0c\u5305\u62ec\u5b9e\u9645\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u6536\u96c6\u7684\u771f\u5b9eOOS\u6570\u636e\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4fdd\u8bc1\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86OOS\u68c0\u6d4b\u6027\u80fd\uff0c\u6709\u6548\u7ed3\u5408\u4e86\u4f20\u7edf\u65b9\u6cd5\u548cLLM\uff0c\u4e3a\u5b9e\u9645\u5bf9\u8bdd\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u63d0\u5347\u63d0\u4f9b\u4e86\u65b0\u8def\u5f84\u3002"}}
{"id": "2507.01543", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01543", "abs": "https://arxiv.org/abs/2507.01543", "authors": ["Quang Minh Nguyen", "Taegyoon Kim"], "title": "Is External Information Useful for Stance Detection with LLMs?", "comment": "ACL Findings 2025", "summary": "In the stance detection task, a text is classified as either favorable,\nopposing, or neutral towards a target. Prior work suggests that the use of\nexternal information, e.g., excerpts from Wikipedia, improves stance detection\nperformance. However, whether or not such information can benefit large\nlanguage models (LLMs) remains an unanswered question, despite their wide\nadoption in many reasoning tasks. In this study, we conduct a systematic\nevaluation on how Wikipedia and web search external information can affect\nstance detection across eight LLMs and in three datasets with 12 targets.\nSurprisingly, we find that such information degrades performance in most cases,\nwith macro F1 scores dropping by up to 27.9\\%. We explain this through\nexperiments showing LLMs' tendency to align their predictions with the stance\nand sentiment of the provided information rather than the ground truth stance\nof the given text. We also find that performance degradation persists with\nchain-of-thought prompting, while fine-tuning mitigates but does not fully\neliminate it. Our findings, in contrast to previous literature on BERT-based\nsystems which suggests that external information enhances performance,\nhighlight the risks of information biases in LLM-based stance classifiers. Code\nis available at https://github.com/ngqm/acl2025-stance-detection.", "AI": {"tldr": "\u5f15\u5165\u7ef4\u57fa\u767e\u79d1\u7b49\u5916\u90e8\u4fe1\u606f\u53cd\u800c\u4f1a\u4f7f\u591a\u79cdLLM\u7684\u7acb\u573a\u68c0\u6d4b\u80fd\u529b\u663e\u8457\u4e0b\u964d\uff0c\u56e0\u4e3a\u6a21\u578b\u66f4\u5bb9\u6613\u88ab\u5916\u90e8\u6750\u6599\u7684\u7acb\u573a\u548c\u60c5\u611f\u6240\u8bef\u5bfc\uff1b\u5fae\u8c03\u867d\u80fd\u90e8\u5206\u7f13\u89e3\uff0c\u4f46\u6839\u672c\u95ee\u9898\u4f9d\u7136\u5b58\u5728\uff0c\u7ed3\u679c\u4e0eBERT\u76f8\u5173\u7814\u7a76\u663e\u8457\u76f8\u53cd\u3002", "motivation": "\u524d\u4eba\u7814\u7a76\u8868\u660e\u5f15\u5165\u5916\u90e8\u4fe1\u606f\uff08\u5982\u7ef4\u57fa\u767e\u79d1\u6458\u5f55\uff09\u80fd\u591f\u63d0\u5347\u7acb\u573a\u68c0\u6d4b\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u4f46\u8fd9\u4e9b\u7ed3\u679c\u662f\u5426\u540c\u6837\u9002\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c1a\u672a\u88ab\u6df1\u5165\u7814\u7a76\u3002\u8be5\u8bba\u6587\u610f\u5728\u7cfb\u7edf\u8bc4\u4f30\u5916\u90e8\u4fe1\u606f\u5bf9LLMs\u7acb\u573a\u68c0\u6d4b\u80fd\u529b\u7684\u5f71\u54cd\u3002", "method": "\u4f5c\u8005\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u3001\u9488\u5bf912\u4e2a\u76ee\u6807\u30018\u79cdLLM\uff0c\u6bd4\u8f83\u4e86\u6709\u65e0\u7ef4\u57fa\u767e\u79d1\u6216\u7f51\u9875\u641c\u7d22\u5916\u90e8\u4fe1\u606f\u65f6\u7684\u7acb\u573a\u68c0\u6d4b\u8868\u73b0\u3002\u6b64\u5916\uff0c\u8fd8\u5206\u6790\u4e86\u8fde\u9501\u601d\u8003\uff08Chain-of-Thought\uff09\u63d0\u793a\u548c\u5fae\u8c03\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u52a0\u5165\u5916\u90e8\u4fe1\u606f\u53cd\u800c\u4f7f\u8868\u73b0\u4e0b\u964d\uff08\u5b8f\u5e73\u5747F1\u6700\u591a\u964d\u4f4e27.9%\uff09\uff0c\u800c\u8fd9\u79cd\u4e0b\u964d\u8d8b\u52bf\u5373\u4f7f\u5728\u7528chain-of-thought\u63d0\u793a\u65f6\u4f9d\u65e7\u5b58\u5728\u3002\u5fae\u8c03\u53ef\u4ee5\u7f13\u89e3\u4f46\u4e0d\u80fd\u5b8c\u5168\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "conclusion": "\u5916\u90e8\u4fe1\u606f\u4f1a\u5bfc\u81f4LLM\u8fc7\u5ea6\u5bf9\u9f50\u9644\u52a0\u4fe1\u606f\u7684\u7acb\u573a\u548c\u60c5\u611f\uff0c\u800c\u4e0d\u662f\u539f\u6587\u672c\u7684\u771f\u5b9e\u7acb\u573a\u3002\u8fd9\u79cd\u201c\u4fe1\u606f\u504f\u5dee\u201d\u5728LLM\u4e0a\u6bd4\u4ee5\u5f80BERT\u7c7b\u6a21\u578b\u66f4\u4e3a\u660e\u663e\uff0c\u63d0\u793a\u5728\u5e94\u7528\u5916\u90e8\u4fe1\u606f\u65f6\u5fc5\u987b\u8c28\u614e\u3002"}}
{"id": "2507.01594", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01594", "abs": "https://arxiv.org/abs/2507.01594", "authors": ["Shutong Feng", "Hsien-chin Lin", "Nurul Lubis", "Carel van Niekerk", "Michael Heck", "Benjamin Ruppik", "Renato Vukovic", "Milica Ga\u0161i\u0107"], "title": "Emotionally Intelligent Task-oriented Dialogue Systems: Architecture, Representation, and Optimisation", "comment": "19 pages, 6 figures", "summary": "Task-oriented dialogue (ToD) systems are designed to help users achieve\nspecific goals through natural language interaction. While recent advances in\nlarge language models (LLMs) have significantly improved linguistic fluency and\ncontextual understanding, building effective and emotionally intelligent ToD\nsystems remains a complex challenge. Effective ToD systems must optimise for\ntask success, emotional understanding and responsiveness, and precise\ninformation conveyance, all within inherently noisy and ambiguous\nconversational environments. In this work, we investigate architectural,\nrepresentational, optimisational as well as emotional considerations of ToD\nsystems. We set up systems covering these design considerations with a\nchallenging evaluation environment composed of a natural-language user\nsimulator coupled with an imperfect natural language understanding module. We\npropose \\textbf{LUSTER}, an \\textbf{L}LM-based \\textbf{U}nified \\textbf{S}ystem\nfor \\textbf{T}ask-oriented dialogue with \\textbf{E}nd-to-end\n\\textbf{R}einforcement learning with both short-term (user sentiment) and\nlong-term (task success) rewards. Our findings demonstrate that combining LLM\ncapability with structured reward modelling leads to more resilient and\nemotionally responsive ToD systems, offering a practical path forward for\nnext-generation conversational agents.", "AI": {"tldr": "\u63d0\u51faLUSTER\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60\uff0c\u517c\u987e\u4efb\u52a1\u6210\u529f\u4e0e\u60c5\u611f\u54cd\u5e94\uff0c\u5728\u590d\u6742\u5bf9\u8bdd\u73af\u5883\u4e0b\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u3001\u66f4\u5177\u60c5\u611f\u667a\u80fd\u7684\u4efb\u52a1\u578b\u5bf9\u8bdd\u7cfb\u7edf\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63d0\u9ad8\u4e86\u8bed\u8a00\u6d41\u7545\u6027\u548c\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\uff0c\u4f46\u6784\u5efa\u65e2\u9ad8\u6548\u53c8\u5177\u5907\u60c5\u611f\u667a\u80fd\u7684\u4efb\u52a1\u578b\u5bf9\u8bdd\uff08ToD\uff09\u7cfb\u7edf\u4ecd\u7136\u6781\u5177\u6311\u6218\u3002\u7406\u60f3\u7684ToD\u7cfb\u7edf\u9700\u540c\u65f6\u4f18\u5316\u4efb\u52a1\u5b8c\u6210\u5ea6\u3001\u60c5\u611f\u8bc6\u522b\u4e0e\u54cd\u5e94\uff0c\u4ee5\u53ca\u4fe1\u606f\u7684\u7cbe\u51c6\u4f20\u9012\uff0c\u5e76\u4e14\u5e94\u5bf9\u5bf9\u8bdd\u73af\u5883\u4e2d\u7684\u566a\u97f3\u548c\u6b67\u4e49\u3002", "method": "\u672c\u6587\u7cfb\u7edf\u6027\u63a2\u8ba8\u4e86ToD\u7cfb\u7edf\u7684\u67b6\u6784\u3001\u8868\u793a\u3001\u4f18\u5316\u53ca\u60c5\u611f\u8bbe\u8ba1\u3002\u4f5c\u8005\u8bbe\u7f6e\u4e86\u6db5\u76d6\u8fd9\u4e9b\u8981\u7d20\u7684\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u5e76\u5728\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u7528\u6237\u6a21\u62df\u5668\u53ca\u4e0d\u5b8c\u7f8e\u7684\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u6a21\u5757\u7684\u73af\u5883\u4e0b\u8fdb\u884c\u8bc4\u4f30\u3002\u63d0\u51fa\u4e86LUSTER\u65b9\u6cd5\uff0c\u5373\u57fa\u4e8eLLM\u7684\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\uff0c\u80fd\u591f\u540c\u65f6\u8003\u8651\u77ed\u671f\uff08\u7528\u6237\u60c5\u611f\uff09\u548c\u957f\u671f\uff08\u4efb\u52a1\u6210\u529f\uff09\u5956\u52b1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u4e0e\u7ed3\u6784\u5316\u5956\u52b1\u5efa\u6a21\u76f8\u7ed3\u5408\uff0c\u53ef\u4ee5\u6784\u5efa\u66f4\u5177\u9c81\u68d2\u6027\u4e0e\u60c5\u611f\u54cd\u5e94\u80fd\u529b\u7684ToD\u7cfb\u7edf\u3002", "conclusion": "LUSTER\uff08\u7ed3\u5408LLM\u548c\u7ed3\u6784\u5316\u5956\u52b1\u7684ToD\u7cfb\u7edf\uff09\u4e3a\u6253\u9020\u517c\u5177\u60c5\u611f\u667a\u80fd\u4e0e\u4efb\u52a1\u6548\u7387\u7684\u4e0b\u4e00\u4ee3\u5bf9\u8bdd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u53ef\u884c\u7684\u8def\u5f84\u3002"}}
{"id": "2507.01627", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01627", "abs": "https://arxiv.org/abs/2507.01627", "authors": ["Maeve Hutchinson", "Radu Jianu", "Aidan Slingsby", "Jo Wood", "Pranava Madhyastha"], "title": "Chart Question Answering from Real-World Analytical Narratives", "comment": "This paper has been accepted to the ACL Student Research Workshop\n  (SRW) 2025", "summary": "We present a new dataset for chart question answering (CQA) constructed from\nvisualization notebooks. The dataset features real-world, multi-view charts\npaired with natural language questions grounded in analytical narratives.\nUnlike prior benchmarks, our data reflects ecologically valid reasoning\nworkflows. Benchmarking state-of-the-art multimodal large language models\nreveals a significant performance gap, with GPT-4.1 achieving an accuracy of\n69.3%, underscoring the challenges posed by this more authentic CQA setting.", "AI": {"tldr": "\u4f5c\u8005\u57fa\u4e8e\u771f\u5b9enotebooks\u63d0\u51fa\u4e86\u66f4\u751f\u6001\u6709\u6548\u7684CQA\u6570\u636e\u96c6\uff0c\u5bf9\u4e3b\u6d41\u6a21\u578b\u7684\u68c0\u9a8c\u663e\u793a\u5c1a\u6709\u8f83\u5927\u63d0\u5347\u7a7a\u95f4\u3002", "motivation": "\u73b0\u6709\u56fe\u8868\u95ee\u7b54(CQA)\u6570\u636e\u96c6\u5b58\u5728\u7f3a\u4e4f\u771f\u5b9e\u6027\u548c\u751f\u6001\u6709\u6548\u6027\u7684\u95ee\u9898\u3002\u5b9e\u9645\u5206\u6790\u8fc7\u7a0b\u4e2d\uff0c\u7528\u6237\u9762\u5bf9\u7684\u662f\u591a\u89c6\u56fe\u3001\u591a\u6837\u5316\u7684\u771f\u5b9e\u56fe\u8868\uff0c\u800c\u6b64\u524d\u6570\u636e\u96c6\u591a\u6765\u6e90\u4e8e\u4eba\u5de5\u5408\u6210\uff0c\u7f3a\u4e4f\u4e0e\u771f\u5b9e\u63a8\u7406\u6d41\u7a0b\u7684\u5bf9\u5e94\u3002", "method": "\u4f5c\u8005\u57fa\u4e8e\u53ef\u89c6\u5316notebooks\uff0c\u6536\u96c6\u4e86\u771f\u5b9e\u7684\u591a\u89c6\u56fe\u56fe\u8868\u548c\u4e0e\u4e4b\u914d\u5957\u7684\u3001\u57fa\u4e8e\u5206\u6790\u53d9\u4e8b\u7684\u81ea\u7136\u8bed\u8a00\u95ee\u9898\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684CQA\u6570\u636e\u96c6\u3002\u540c\u65f6\uff0c\u5229\u7528\u6700\u65b0\u7684\u5927\u578b\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u5bf9\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5728\u65b0\u6570\u636e\u96c6\u4e0a\uff0cGPT-4.1\u4ec5\u53d6\u5f97\u4e8669.3%\u7684\u51c6\u786e\u7387\uff0c\u8868\u73b0\u51fa\u660e\u663e\u7684\u6027\u80fd\u74f6\u9888\uff0c\u8bf4\u660e\u8be5\u6570\u636e\u96c6\u6bd4\u4ee5\u5f80\u57fa\u51c6\u66f4\u5177\u6311\u6218\u6027\uff0c\u66f4\u8d34\u8fd1\u771f\u5b9e\u4efb\u52a1\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u66f4\u8d34\u5408\u5b9e\u9645\u5206\u6790\u573a\u666f\u7684CQA\u6570\u636e\u96c6\uff0c\u80fd\u6709\u6548\u6d4b\u8bd5\u548c\u63a8\u52a8\u73b0\u6709\u65b9\u6cd5\u5728\u771f\u5b9e\u6570\u636e\u3001\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0b\u7684\u80fd\u529b\u53d1\u5c55\u3002\u5f53\u524d\u7684\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u4ecd\u5b58\u5728\u660e\u663e\u4e0d\u8db3\u3002"}}
{"id": "2507.01633", "categories": ["cs.CL", "cs.IR", "62-04", "D.2.3"], "pdf": "https://arxiv.org/pdf/2507.01633", "abs": "https://arxiv.org/abs/2507.01633", "authors": ["Georgii Levtsov", "Dmitry Ustalov"], "title": "Confidence and Stability of Global and Pairwise Scores in NLP Evaluation", "comment": "8 pages, accepted at ACL SRW 2025", "summary": "With the advent of highly capable instruction-tuned neural language models,\nbenchmarking in natural language processing (NLP) is increasingly shifting\ntowards pairwise comparison leaderboards, such as LMSYS Arena, from traditional\nglobal pointwise scores (e.g., GLUE, BIG-bench, SWE-bench). This paper\nempirically investigates the strengths and weaknesses of both global scores and\npairwise comparisons to aid decision-making in selecting appropriate model\nevaluation strategies. Through computational experiments on synthetic and\nreal-world datasets using standard global metrics and the popular Bradley-Terry\nmodel for pairwise comparisons, we found that while global scores provide more\nreliable overall rankings, they can underestimate strong models with rare,\nsignificant errors or low confidence. Conversely, pairwise comparisons are\nparticularly effective for identifying strong contenders among models with\nlower global scores, especially where quality metrics are hard to define (e.g.,\ntext generation), though they require more comparisons to converge if ties are\nfrequent. Our code and data are available at\nhttps://github.com/HSPyroblast/srw-ranking under a permissive license.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6bd4\u4e86\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6a21\u578b\u8bc4\u6d4b\u4e2d\u7684\u5168\u5c40\u5206\u6570\u4e0e\u6210\u5bf9\u6bd4\u8f83\u65b9\u6cd5\uff0c\u6307\u51fa\u5168\u5c40\u5206\u6570\u9002\u5408\u603b\u4f53\u53ef\u9760\u6392\u540d\uff0c\u6210\u5bf9\u6bd4\u8f83\u64c5\u957f\u53d1\u73b0\u6f5c\u529b\u6a21\u578b\uff0c\u4f46\u9700\u66f4\u591a\u6570\u636e\u3002\u5efa\u8bae\u6839\u636e\u573a\u666f\u9009\u7528\u5408\u9002\u7684\u8bc4\u6d4b\u7b56\u7565\uff0c\u5e76\u5f00\u6e90\u4e86\u5b9e\u9a8c\u4ee3\u7801\u4e0e\u6570\u636e\u3002", "motivation": "\u968f\u7740\u6307\u4ee4\u5fae\u8c03\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u7684\u589e\u5f3a\uff0c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u7684\u57fa\u51c6\u8bc4\u6d4b\u8d8b\u5411\u4e8e\u4ece\u4f20\u7edf\u7684\u5168\u5c40\u5206\u6570\uff08\u5982GLUE\u3001BIG-bench\uff09\u8f6c\u5411\u6210\u5bf9\u6bd4\u8f83\u6392\u884c\u699c\uff08\u5982LMSYS Arena\uff09\u3002\u8be5\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u5206\u6790\u5e76\u6bd4\u8f83\u5168\u5c40\u5206\u6570\u548c\u6210\u5bf9\u6bd4\u8f83\u4e24\u79cd\u8bc4\u6d4b\u65b9\u6cd5\u7684\u4f18\u52a3\uff0c\u4ee5\u4fbf\u4e3a\u6a21\u578b\u8bc4\u4f30\u7b56\u7565\u7684\u9009\u62e9\u63d0\u4f9b\u51b3\u7b56\u4f9d\u636e\u3002", "method": "\u4f5c\u8005\u5229\u7528\u8ba1\u7b97\u5b9e\u9a8c\uff0c\u5728\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c\u901a\u8fc7\u6807\u51c6\u5168\u5c40\u6307\u6807\u4e0e\u5e7f\u53d7\u6b22\u8fce\u7684Bradley-Terry\u6210\u5bf9\u6bd4\u8f83\u6a21\u578b\uff0c\u7cfb\u7edf\u5730\u8bc4\u4f30\u548c\u5bf9\u6bd4\u4e24\u79cd\u6a21\u578b\u8bc4\u6d4b\u65b9\u6cd5\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a\u5168\u5c40\u5206\u6570\u5728\u603b\u4f53\u6392\u540d\u4e0a\u66f4\u53ef\u9760\uff0c\u4f46\u5bf9\u4e8e\u5076\u6709\u91cd\u5927\u9519\u8bef\u6216\u4f4e\u7f6e\u4fe1\u5ea6\u7684\u5f3a\u6a21\u578b\u53ef\u80fd\u4f4e\u4f30\u5176\u80fd\u529b\u3002\u6210\u5bf9\u6bd4\u8f83\u65b9\u6cd5\u5728\u53d1\u6398\u5168\u5c40\u8bc4\u5206\u8f83\u4f4e\u4f46\u6709\u6f5c\u529b\u7684\u5f3a\u6a21\u578b\u65b9\u9762\u66f4\u6709\u6548\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8d28\u91cf\u5ea6\u91cf\u96be\u4ee5\u660e\u786e\u5b9a\u4e49\u7684\u4efb\u52a1\uff08\u5982\u6587\u672c\u751f\u6210\uff09\uff0c\u4f46\u5728\u51fa\u73b0\u8f83\u591a\u5e73\u5c40\u65f6\u6536\u655b\u66f4\u6162\uff0c\u9700\u8981\u66f4\u591a\u7684\u6bd4\u8f83\u3002", "conclusion": "\u5168\u5c40\u5206\u6570\u9002\u7528\u4e8e\u9700\u8981\u7a33\u5b9a\u3001\u603b\u4f53\u8bc4\u4ef7\u7684\u573a\u666f\uff1b\u6210\u5bf9\u6bd4\u8f83\u5219\u66f4\u9002\u5408\u53d1\u6398\u6f5c\u529b\u9009\u624b\u53ca\u96be\u4ee5\u91cf\u5316\u7684\u4efb\u52a1\u3002\u5b9e\u9645\u5e94\u7528\u4e2d\u5e94\u6839\u636e\u9700\u6c42\u6743\u8861\u9009\u7528\u3002"}}
{"id": "2507.01645", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01645", "abs": "https://arxiv.org/abs/2507.01645", "authors": ["Rifki Afina Putri"], "title": "Adapting Language Models to Indonesian Local Languages: An Empirical Study of Language Transferability on Zero-Shot Settings", "comment": "AMLDS 2025", "summary": "In this paper, we investigate the transferability of pre-trained language\nmodels to low-resource Indonesian local languages through the task of sentiment\nanalysis. We evaluate both zero-shot performance and adapter-based transfer on\nten local languages using models of different types: a monolingual Indonesian\nBERT, multilingual models such as mBERT and XLM-R, and a modular adapter-based\napproach called MAD-X. To better understand model behavior, we group the target\nlanguages into three categories: seen (included during pre-training), partially\nseen (not included but linguistically related to seen languages), and unseen\n(absent and unrelated in pre-training data). Our results reveal clear\nperformance disparities across these groups: multilingual models perform best\non seen languages, moderately on partially seen ones, and poorly on unseen\nlanguages. We find that MAD-X significantly improves performance, especially\nfor seen and partially seen languages, without requiring labeled data in the\ntarget language. Additionally, we conduct a further analysis on tokenization\nand show that while subword fragmentation and vocabulary overlap with\nIndonesian correlate weakly with prediction quality, they do not fully explain\nthe observed performance. Instead, the most consistent predictor of transfer\nsuccess is the model's prior exposure to the language, either directly or\nthrough a related language.", "AI": {"tldr": "\u8be5\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u591a\u79cd\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u5341\u79cd\u5370\u5c3c\u672c\u5730\u8bed\u8a00\u4e0a\u7684\u8fc1\u79fb\u80fd\u529b\uff0c\u53d1\u73b0\u591a\u8bed\u6a21\u578b\u8868\u73b0\u53d7\u8bed\u8a00\u66dd\u5149\u5ea6\u5f71\u54cd\u663e\u8457\u3002MAD-X\u65b9\u6cd5\u5728\u63d0\u5347\u5c11\u8d44\u6e90\u8bed\u8a00\u60c5\u611f\u5206\u6790\u8fc1\u79fb\u80fd\u529b\u4e0a\u6548\u679c\u7a81\u51fa\uff0c\u65e0\u987b\u76ee\u6807\u8bed\u6807\u6ce8\u6570\u636e\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8bed\u8a00\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u5bf9\u8d44\u6e90\u7a00\u7f3a\u7684\u5370\u5c3c\u672c\u5730\u8bed\u8a00\u7684\u8fc1\u79fb\u80fd\u529b\u5c1a\u672a\u7cfb\u7edf\u7814\u7a76\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u8fd9\u4e9b\u6a21\u578b\u5728\u5370\u5c3c\u672c\u5730\u8bed\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e2d\u7684\u53ef\u8fc1\u79fb\u6027\uff0c\u7279\u522b\u662f\u5728\u65e0\u76d1\u7763\u548c\u7ed3\u6784\u5316\u8fc1\u79fb\u65b9\u6848\uff08\u5982adapter\uff09\u7684\u5b9e\u7528\u6027\u3002", "method": "\u4f5c\u8005\u8bc4\u4f30\u4e86\u56db\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u5341\u79cd\u5370\u5c3c\u672c\u5730\u8bed\u8a00\u4e0a\u7684\u60c5\u611f\u5206\u6790\u8f6c\u79fb\u6027\u80fd\uff0c\u5305\u62ec\u5355\u8bed\u5370\u5c3cBERT\u3001\u591a\u8bedmBERT\u3001XLM-R\u53ca\u57fa\u4e8eadapter\u7684MAD-X\u65b9\u6cd5\u3002\u4f7f\u7528\u96f6\u6837\u672c\u548cadapter\u8fc1\u79fb\u65b9\u5f0f\uff0c\u5c06\u76ee\u6807\u8bed\u8a00\u5206\u4e3a\u2018\u5df2\u89c1\u2019\u3001\u2018\u90e8\u5206\u5df2\u89c1\u2019\u548c\u2018\u672a\u89c1\u2019\u4e09\u4e2a\u7ec4\u522b\uff0c\u5e76\u5206\u6790\u4e86\u8bcd\u7247\u5206\u5272\u548c\u8bcd\u6c47\u91cd\u53e0\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "result": "\u591a\u8bed\u6a21\u578b\u5728\u2018\u5df2\u89c1\u2019\u8bed\u8a00\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u5728\u2018\u90e8\u5206\u5df2\u89c1\u2019\u8bed\u8a00\u4e0a\u8868\u73b0\u4e2d\u7b49\uff0c\u5728\u2018\u672a\u89c1\u2019\u8bed\u8a00\u4e0a\u8868\u73b0\u8f83\u5dee\u3002MAD-X\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u2018\u5df2\u89c1\u2019\u548c\u2018\u90e8\u5206\u5df2\u89c1\u2019\u8bed\u8a00\u7684\u8fc1\u79fb\u6548\u679c\uff0c\u4e14\u65e0\u9700\u76ee\u6807\u8bed\u6807\u6ce8\u6570\u636e\u3002\u8bcd\u7247\u5206\u5272\u548c\u8bcd\u6c47\u91cd\u53e0\u4e0e\u6a21\u578b\u8868\u73b0\u4ec5\u5f31\u76f8\u5173\uff0c\u6a21\u578b\u9884\u8bad\u7ec3\u9636\u6bb5\u5bf9\u76ee\u6807\u8bed\u6216\u76f8\u5173\u8bed\u7684\u66dd\u5149\u5ea6\u624d\u662f\u8fc1\u79fb\u6548\u679c\u6700\u91cd\u8981\u7684\u9884\u6d4b\u56e0\u7d20\u3002", "conclusion": "\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u672c\u5730\u8bed\u8a00\u7684\u60c5\u611f\u5206\u6790\u8fc1\u79fb\u4e2d\u8868\u73b0\u5b58\u5728\u660e\u663e\u5206\u5c42\uff0c\u4e0e\u6a21\u578b\u5728\u8bad\u7ec3\u9636\u6bb5\u5bf9\u76ee\u6807\u8bed\u6216\u76f8\u5173\u8bed\u7684\u66dd\u5149\u5ea6\u5bc6\u5207\u76f8\u5173\u3002MAD-X\u7ed3\u6784\u5728\u65e0\u9700\u6807\u6ce8\u6570\u636e\u6761\u4ef6\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6570\u672c\u5730\u8bed\u8a00\u7684\u8fc1\u79fb\u6027\u80fd\u3002"}}
{"id": "2507.01702", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.01702", "abs": "https://arxiv.org/abs/2507.01702", "authors": ["Zixin Chen", "Hongzhan Lin", "Kaixin Li", "Ziyang Luo", "Zhen Ye", "Guang Chen", "Zhiyong Huang", "Jing Ma"], "title": "AdamMeme: Adaptively Probe the Reasoning Capacity of Multimodal Large Language Models on Harmfulness", "comment": "ACL 2025", "summary": "The proliferation of multimodal memes in the social media era demands that\nmultimodal Large Language Models (mLLMs) effectively understand meme\nharmfulness. Existing benchmarks for assessing mLLMs on harmful meme\nunderstanding rely on accuracy-based, model-agnostic evaluations using static\ndatasets. These benchmarks are limited in their ability to provide up-to-date\nand thorough assessments, as online memes evolve dynamically. To address this,\nwe propose AdamMeme, a flexible, agent-based evaluation framework that\nadaptively probes the reasoning capabilities of mLLMs in deciphering meme\nharmfulness. Through multi-agent collaboration, AdamMeme provides comprehensive\nevaluations by iteratively updating the meme data with challenging samples,\nthereby exposing specific limitations in how mLLMs interpret harmfulness.\nExtensive experiments show that our framework systematically reveals the\nvarying performance of different target mLLMs, offering in-depth, fine-grained\nanalyses of model-specific weaknesses. Our code is available at\nhttps://github.com/Lbotirx/AdamMeme.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86AdamMeme\u8fd9\u4e00\u57fa\u4e8e\u591a\u4ee3\u7406\u3001\u52a8\u6001\u9002\u5e94\u7684\u8bc4\u6d4b\u6846\u67b6\uff0c\u80fd\u66f4\u771f\u5b9e\u53cd\u6620mLLMs\u5728\u8bc6\u522b\u6709\u5bb3\u8868\u60c5\u5305\u65f6\u7684\u80fd\u529b\u4e0e\u77ed\u677f\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u9759\u6001\u8bc4\u6d4b\u7684\u4e0d\u8db3\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u65f6\u4ee3\u591a\u6a21\u6001\u8868\u60c5\u5305\u5927\u91cf\u6d8c\u73b0\uff0c\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08mLLMs\uff09\u5bf9\u8868\u60c5\u5305\u6709\u5bb3\u6027\u7406\u89e3\u7684\u8bc4\u6d4b\u4ecd\u505c\u7559\u5728\u57fa\u4e8e\u51c6\u786e\u7387\u7684\u9759\u6001\u6570\u636e\u96c6\u4e0a\uff0c\u96be\u4ee5\u4e0e\u8868\u60c5\u5305\u52a8\u6001\u6f14\u5316\u7684\u5b9e\u9645\u60c5\u51b5\u76f8\u5339\u914d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7075\u6d3b\u7684\u57fa\u4e8e\u4ee3\u7406(agent-based)\u7684\u8bc4\u6d4b\u6846\u67b6\u2014\u2014AdamMeme\uff0c\u91c7\u7528\u591a\u4ee3\u7406\u534f\u4f5c\uff0c\u52a8\u6001\u5730\u901a\u8fc7\u4e0d\u65ad\u6536\u96c6\u548c\u878d\u5165\u5177\u6311\u6218\u6027\u7684\u8868\u60c5\u5305\u65b0\u6837\u672c\uff0c\u8fed\u4ee3\u8bc4\u6d4bmLLMs\u5bf9\u8868\u60c5\u5305\u6709\u5bb3\u6027\u63a8\u7406\u7684\u80fd\u529b\u3002", "result": "AdamMeme\u6846\u67b6\u80fd\u591f\u7cfb\u7edf\u6027\u63ed\u793a\u4e0d\u540cmLLMs\u5728\u8bc6\u522b\u8868\u60c5\u5305\u6709\u5bb3\u6027\u65b9\u9762\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u6df1\u5165\u7ec6\u81f4\u5730\u5206\u6790\u6a21\u578b\u7684\u5177\u4f53\u8584\u5f31\u73af\u8282\u3002", "conclusion": "AdamMeme\u80fd\u6709\u6548\u9002\u5e94\u7f51\u7edc\u8868\u60c5\u5305\u7684\u52a8\u6001\u53d8\u5316\uff0c\u4e3amLLMs\u5728\u6709\u5bb3\u8868\u60c5\u5305\u7406\u89e3\u8bc4\u6d4b\u4e2d\u63d0\u4f9b\u66f4\u5168\u9762\u548c\u7ec6\u7c92\u5ea6\u7684\u5206\u6790\u3002"}}
{"id": "2507.01715", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01715", "abs": "https://arxiv.org/abs/2507.01715", "authors": ["Aditya Tomar", "Rudra Murthy", "Pushpak Bhattacharyya"], "title": "Stereotype Detection as a Catalyst for Enhanced Bias Detection: A Multi-Task Learning Approach", "comment": null, "summary": "Bias and stereotypes in language models can cause harm, especially in\nsensitive areas like content moderation and decision-making. This paper\naddresses bias and stereotype detection by exploring how jointly learning these\ntasks enhances model performance. We introduce StereoBias, a unique dataset\nlabeled for bias and stereotype detection across five categories: religion,\ngender, socio-economic status, race, profession, and others, enabling a deeper\nstudy of their relationship. Our experiments compare encoder-only models and\nfine-tuned decoder-only models using QLoRA. While encoder-only models perform\nwell, decoder-only models also show competitive results. Crucially, joint\ntraining on bias and stereotype detection significantly improves bias detection\ncompared to training them separately. Additional experiments with sentiment\nanalysis confirm that the improvements stem from the connection between bias\nand stereotypes, not multi-task learning alone. These findings highlight the\nvalue of leveraging stereotype information to build fairer and more effective\nAI systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faStereoBias\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u540c\u65f6\u8bad\u7ec3\u504f\u89c1\u548c\u523b\u677f\u5370\u8c61\u68c0\u6d4b\u80fd\u663e\u8457\u63d0\u5347\u504f\u89c1\u68c0\u6d4b\u80fd\u529b\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u516c\u5e73\u7684AI\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u504f\u89c1\u548c\u523b\u677f\u5370\u8c61\u4f1a\u5728\u5185\u5bb9\u5ba1\u6838\u548c\u51b3\u7b56\u7b49\u654f\u611f\u9886\u57df\u9020\u6210\u4f24\u5bb3\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u597d\u5730\u68c0\u6d4b\u548c\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86StereoBias\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u5b97\u6559\u3001\u6027\u522b\u3001\u793e\u4f1a\u7ecf\u6d4e\u72b6\u51b5\u3001\u79cd\u65cf\u3001\u804c\u4e1a\u7b49\u4e94\u7c7b\uff0c\u5206\u522b\u6807\u6ce8\u4e86\u504f\u89c1\u4e0e\u523b\u677f\u5370\u8c61\u3002\u6bd4\u8f83\u4e86\u53ea\u7528\u7f16\u7801\u5668\u7684\u6a21\u578b\u548c\u7528QLoRA\u5fae\u8c03\u7684\u89e3\u7801\u5668\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1\u8054\u5408\u8bad\u7ec3\u540c\u65f6\u68c0\u6d4b\u504f\u89c1\u4e0e\u523b\u677f\u5370\u8c61\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u60c5\u611f\u5206\u6790\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u6a21\u578b\u6539\u8fdb\u6765\u6e90\u3002", "result": "\u7f16\u7801\u5668\u6a21\u578b\u8868\u73b0\u8f83\u597d\uff0c\u89e3\u7801\u5668\u6a21\u578b\u4e5f\u6709\u7ade\u4e89\u529b\u3002\u6700\u91cd\u8981\u7684\u662f\uff0c\u8054\u5408\u8bad\u7ec3\u504f\u89c1\u4e0e\u523b\u677f\u5370\u8c61\u68c0\u6d4b\u4efb\u52a1\uff0c\u80fd\u663e\u8457\u63d0\u5347\u504f\u89c1\u68c0\u6d4b\u7684\u6548\u679c\uff0c\u4e14\u8fd9\u79cd\u63d0\u5347\u4e0d\u662f\u56e0\u4e3a\u591a\u4efb\u52a1\u8bad\u7ec3\u672c\u8eab\uff0c\u800c\u662f\u56e0\u4e3a\u504f\u89c1\u4e0e\u523b\u677f\u5370\u8c61\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "conclusion": "\u7ed3\u5408\u523b\u677f\u5370\u8c61\u68c0\u6d4b\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u5bf9\u504f\u89c1\u7684\u8bc6\u522b\uff0c\u6709\u671b\u4fc3\u4f7fAI\u7cfb\u7edf\u66f4\u52a0\u516c\u5e73\u6709\u6548\u3002"}}
{"id": "2507.01734", "categories": ["cs.CL", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.01734", "abs": "https://arxiv.org/abs/2507.01734", "authors": ["Oliver Wardas", "Florian Matthes"], "title": "LLMs for Legal Subsumption in German Employment Contracts", "comment": "PrePrint - ICAIL25, Chicago", "summary": "Legal work, characterized by its text-heavy and resource-intensive nature,\npresents unique challenges and opportunities for NLP research. While\ndata-driven approaches have advanced the field, their lack of interpretability\nand trustworthiness limits their applicability in dynamic legal environments.\nTo address these issues, we collaborated with legal experts to extend an\nexisting dataset and explored the use of Large Language Models (LLMs) and\nin-context learning to evaluate the legality of clauses in German employment\ncontracts. Our work evaluates the ability of different LLMs to classify clauses\nas \"valid,\" \"unfair,\" or \"void\" under three legal context variants: no legal\ncontext, full-text sources of laws and court rulings, and distilled versions of\nthese (referred to as examination guidelines). Results show that full-text\nsources moderately improve performance, while examination guidelines\nsignificantly enhance recall for void clauses and weighted F1-Score, reaching\n80\\%. Despite these advancements, LLMs' performance when using full-text\nsources remains substantially below that of human lawyers. We contribute an\nextended dataset, including examination guidelines, referenced legal sources,\nand corresponding annotations, alongside our code and all log files. Our\nfindings highlight the potential of LLMs to assist lawyers in contract legality\nreview while also underscoring the limitations of the methods presented.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86LLM\u5728\u5fb7\u56fd\u52b3\u52a8\u5408\u540c\u6761\u6b3e\u5408\u6cd5\u6027\u5206\u7c7b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u7cbe\u70bc\u6cd5\u5f8b\u6307\u5bfc\u53ef\u660e\u663e\u63d0\u9ad8\u65e0\u6548\u6761\u6b3e\u8bc6\u522b\u80fd\u529b\uff0c\u4f46LLM\u603b\u4f53\u4ecd\u4e0d\u53ca\u4e13\u4e1a\u5f8b\u5e08\u3002\u7814\u7a76\u8d21\u732e\u4e86\u6269\u5c55\u6570\u636e\u96c6\u548c\u5de5\u5177\uff0c\u5e76\u6307\u51faLLM\u8f85\u52a9\u6cd5\u5f8b\u5ba1\u67e5\u7684\u673a\u9047\u4e0e\u4e0d\u8db3\u3002", "motivation": "\u6cd5\u5f8b\u5de5\u4f5c\u7531\u4e8e\u6587\u672c\u5bc6\u96c6\u3001\u8d44\u6e90\u6d88\u8017\u5927\uff0c\u9762\u4e34\u72ec\u7279\u7684NLP\u6311\u6218\u3002\u76ee\u524d\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u867d\u7136\u63a8\u52a8\u4e86\u9886\u57df\u8fdb\u6b65\uff0c\u4f46\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u5176\u5728\u52a8\u6001\u6cd5\u5f8b\u73af\u5883\u4e2d\u7684\u5e94\u7528\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u4e0e\u6cd5\u5f8b\u4e13\u5bb6\u5408\u4f5c\uff0c\u5e0c\u671b\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5fb7\u56fd\u52b3\u52a8\u5408\u540c\u5408\u6cd5\u6027\u8bc4\u4f30\u7684\u80fd\u529b\u3002", "method": "\u672c\u7814\u7a76\u6269\u5c55\u4e86\u73b0\u6709\u6570\u636e\u96c6\uff0c\u63a2\u7d22\u4f7f\u7528LLM\u548cin-context learning\u6765\u8bc4\u4f30\u5fb7\u56fd\u52b3\u52a8\u5408\u540c\u6761\u6b3e\u7684\u5408\u6cd5\u6027\u3002\u5b9e\u9a8c\u8bbe\u7f6e\u5305\u62ec\u4e09\u79cd\u6cd5\u5f8b\u73af\u5883\uff1a\u65e0\u6cd5\u5f8b\u80cc\u666f\u3001\u6cd5\u5f8b\u539f\u6587\u53ca\u5224\u4f8b\u5168\u6587\u3001\u4ee5\u53ca\u63d0\u70bc\u7684\u201c\u5ba1\u67e5\u6307\u5357\u201d\u3002\u5bf9LLM\u8fdb\u884c\u4e0d\u540c\u73af\u5883\u4e0b\u7684\u5206\u7c7b\u80fd\u529b\u5bf9\u6bd4\uff0c\u7c7b\u522b\u5305\u62ec\u201c\u5408\u6cd5\u201d\u3001\u201c\u4e0d\u516c\u5e73\u201d\u3001\u201c\u65e0\u6548\u201d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4f7f\u7528\u6cd5\u5f8b\u539f\u6587\u5168\u6587\u5bf9\u6027\u80fd\u6709\u4e00\u5b9a\u63d0\u5347\uff0c\u800c\u4f7f\u7528\u7cbe\u70bc\u7684\u201c\u5ba1\u67e5\u6307\u5357\u201d\u5219\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u65e0\u6548\u6761\u6b3e\u7684\u53ec\u56de\u7387\u548c\u52a0\u6743F1\u5206\u6570\uff0c\u6700\u9ad8\u53ef\u8fbe80%\u3002\u4f46\u5373\u4f7f\u7528\u539f\u6587\u5168\u6587\uff0cLLM\u5728\u6761\u6b3e\u5408\u6cd5\u6027\u5206\u7c7b\u4e0a\u7684\u8868\u73b0\u4ecd\u660e\u663e\u4f4e\u4e8e\u4eba\u7c7b\u5f8b\u5e08\u3002", "conclusion": "\u672c\u7814\u7a76\u6269\u5c55\u5e76\u516c\u5f00\u4e86\u5305\u542b\u201c\u5ba1\u67e5\u6307\u5357\u201d\u548c\u6cd5\u5f8b\u53c2\u8003\u6e90\u7684\u52b3\u52a8\u5408\u540c\u6761\u6b3e\u6570\u636e\u96c6\uff0c\u540c\u65f6\u53d1\u5e03\u4e86\u5168\u90e8\u4ee3\u7801\u548c\u65e5\u5fd7\u3002\u7ed3\u679c\u8868\u660eLLM\u6709\u52a9\u4e8e\u8f85\u52a9\u5f8b\u5e08\u8fdb\u884c\u5408\u540c\u5408\u6cd5\u6027\u5ba1\u67e5\uff0c\u4f46\u76ee\u524d\u8be5\u65b9\u6cd5\u4ecd\u6709\u5c40\u9650\u6027\u3002"}}
{"id": "2507.01764", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01764", "abs": "https://arxiv.org/abs/2507.01764", "authors": ["Matteo Di Cristofaro"], "title": "Data interference: emojis, homoglyphs, and issues of data fidelity in corpora and their results", "comment": "Author submitted manuscript", "summary": "Tokenisation - \"the process of splitting text into atomic parts\" (Brezina &\nTimperley, 2017: 1) - is a crucial step for corpus linguistics, as it provides\nthe basis for any applicable quantitative method (e.g. collocations) while\nensuring the reliability of qualitative approaches. This paper examines how\ndiscrepancies in tokenisation affect the representation of language data and\nthe validity of analytical findings: investigating the challenges posed by\nemojis and homoglyphs, the study highlights the necessity of preprocessing\nthese elements to maintain corpus fidelity to the source data. The research\npresents methods for ensuring that digital texts are accurately represented in\ncorpora, thereby supporting reliable linguistic analysis and guaranteeing the\nrepeatability of linguistic interpretations. The findings emphasise the\nnecessity of a detailed understanding of both linguistic and technical aspects\ninvolved in digital textual data to enhance the accuracy of corpus analysis,\nand have significant implications for both quantitative and qualitative\napproaches in corpus-based research.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5206\u8bcd\u5728\u8bed\u6599\u5e93\u8bed\u8a00\u5b66\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5c24\u5176\u5173\u6ce8\u8868\u60c5\u7b26\u53f7\u3001\u540c\u5f62\u5f02\u4e49\u5b57\u7b26\u5bf9\u5206\u8bcd\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u9884\u5904\u7406\u65b9\u6cd5\uff0c\u4ee5\u63d0\u5347\u5206\u6790\u7684\u53ef\u9760\u6027\uff0c\u5bf9\u5b9a\u91cf\u4e0e\u5b9a\u6027\u7814\u7a76\u5747\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u5206\u8bcd\u5dee\u5f02\u4f1a\u5f71\u54cd\u8bed\u8a00\u6570\u636e\u7684\u5448\u73b0\u548c\u5206\u6790\u7ed3\u679c\u7684\u6709\u6548\u6027\uff0c\u5c24\u5176\u662f\u5728\u9762\u5bf9\u65b0\u7684\u6570\u5b57\u6587\u672c\u7279\u5f81\uff08\u5982\u8868\u60c5\u7b26\u53f7\u3001\u540c\u5f62\u5f02\u4e49\u5b57\u7b26\uff09\u65f6\u3002", "method": "\u8c03\u67e5\u8868\u60c5\u7b26\u53f7\u548c\u540c\u5f62\u5f02\u4e49\u5b57\u7b26\u5e26\u6765\u7684\u5206\u8bcd\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u9884\u5904\u7406\u8fd9\u4e9b\u5143\u7d20\u7684\u65b9\u6cd5\uff0c\u4fdd\u969c\u8bed\u6599\u4e0e\u539f\u59cb\u6570\u636e\u7684\u4e00\u81f4\u6027\u3002", "result": "\u7814\u7a76\u63d0\u51fa\u4e86\u786e\u4fdd\u6570\u5b57\u6587\u672c\u5728\u8bed\u6599\u5e93\u4e2d\u51c6\u786e\u518d\u73b0\u7684\u65b9\u6cd5\uff0c\u5f3a\u8c03\u5728\u8bed\u6599\u5e93\u7814\u7a76\u7684\u5b9a\u91cf\u4e0e\u5b9a\u6027\u5206\u6790\u4e2d\u5747\u8981\u91cd\u89c6\u9884\u5904\u7406\u548c\u6280\u672f\u7ec6\u8282\uff0c\u4ee5\u4fdd\u8bc1\u5206\u6790\u7ed3\u679c\u7684\u53ef\u9760\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u5728\u8bed\u6599\u5e93\u7814\u7a76\u4e2d\uff0c\u8be6\u7ec6\u7406\u89e3\u6570\u5b57\u6587\u672c\u6570\u636e\u4e2d\u8bed\u8a00\u548c\u6280\u672f\u4e24\u4e2a\u65b9\u9762\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u63d0\u5347\u8bed\u6599\u5206\u6790\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2507.01785", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01785", "abs": "https://arxiv.org/abs/2507.01785", "authors": ["Zhixun Chen", "Ping Guo", "Wenhan Han", "Yifan Zhang", "Binbin Liu", "Haobin Lin", "Fengze Liu", "Yan Zhao", "Bingni Zhang", "Taifeng Wang", "Yin Zheng", "Meng Fang"], "title": "MuRating: A High Quality Data Selecting Approach to Multilingual Large Language Model Pretraining", "comment": null, "summary": "Data quality is a critical driver of large language model performance, yet\nexisting model-based selection methods focus almost exclusively on English. We\nintroduce MuRating, a scalable framework that transfers high-quality English\ndata-quality signals into a single rater for 17 target languages. MuRating\naggregates multiple English \"raters\" via pairwise comparisons to learn unified\ndocument-quality scores,then projects these judgments through translation to\ntrain a multilingual evaluator on monolingual, cross-lingual, and parallel text\npairs. Applied to web data, MuRating selects balanced subsets of English and\nmultilingual content to pretrain a 1.2 B-parameter LLaMA model. Compared to\nstrong baselines, including QuRater, AskLLM, DCLM and so on, our approach\nboosts average accuracy on both English benchmarks and multilingual\nevaluations, with especially large gains on knowledge-intensive tasks. We\nfurther analyze translation fidelity, selection biases, and underrepresentation\nof narrative material, outlining directions for future work.", "AI": {"tldr": "\u63d0\u51faMuRating\u6846\u67b6\uff0c\u5c06\u82f1\u6587\u9ad8\u8d28\u91cf\u6570\u636e\u9009\u62e9\u7ecf\u9a8c\u8fc1\u79fb\u523017\u79cd\u8bed\u8a00\uff0c\u5b9e\u73b0\u66f4\u4f18\u591a\u8bed\u8a00\u6570\u636e\u7b5b\u9009\uff0c\u63d0\u5347\u4e86\u5927\u6a21\u578b\u9884\u8bad\u7ec3\u8868\u73b0\uff0c\u5c24\u5176\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u8fdb\u6b65\u660e\u663e\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u57fa\u4e8e\u6a21\u578b\u7684\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u4e3b\u8981\u9762\u5411\u82f1\u6587\uff0c\u7f3a\u4e4f\u5bf9\u591a\u8bed\u8a00\u6570\u636e\u8d28\u91cf\u7684\u6709\u6548\u8bc4\u4f30\u548c\u5904\u7406\u65b9\u6cd5\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5229\u7528\u9ad8\u8d28\u91cf\u82f1\u6587\u4fe1\u53f7\u6307\u5bfc\u591a\u8bed\u8a00\u6570\u636e\u8d28\u91cf\u8bc4\u4f30\u7684\u901a\u7528\u65b9\u6cd5\u3002", "method": "\u63d0\u51faMuRating\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u591a\u4f4d\u82f1\u6587\u201c\u8bc4\u5206\u5458\u201d\u7684\u6210\u5bf9\u6bd4\u8f83\u7ed3\u679c\uff0c\u5f97\u5230\u7edf\u4e00\u7684\u6587\u6863\u8d28\u91cf\u5206\u6570\uff0c\u7136\u540e\u901a\u8fc7\u7ffb\u8bd1\u5c06\u8fd9\u4e9b\u8bc4\u4ef7\u4fe1\u53f7\u4f20\u9012\u523017\u79cd\u76ee\u6807\u8bed\u8a00\uff0c\u7528\u4e8e\u8bad\u7ec3\u591a\u8bed\u8a00\u8bc4\u4f30\u6a21\u578b\uff0c\u652f\u6301\u5355\u8bed\u3001\u8de8\u8bed\u79cd\u548c\u5e73\u884c\u6587\u672c\u7684\u8bc4\u5206\u3002", "result": "MuRating\u80fd\u591f\u5728\u82f1\u6587\u548c\u591a\u8bed\u8a00\u8bed\u6599\u4e0a\u9009\u51fa\u9ad8\u8d28\u91cf\u7684\u5b50\u96c6\uff0c\u7528\u4e8e\u9884\u8bad\u7ec31.2B\u53c2\u6570\u89c4\u6a21\u7684LLaMA\u6a21\u578b\u3002\u4e0eQuRater\u3001AskLLM\u3001DCLM\u7b49\u4e3b\u6d41\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u65e0\u8bba\u5728\u82f1\u6587\u8fd8\u662f\u591a\u8bed\u8a00\u8bc4\u6d4b\u4e0a\u5747\u6709\u6027\u80fd\u63d0\u5347\uff0c\u5c24\u5176\u662f\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002\u540c\u65f6\u8fd8\u5bf9\u7ffb\u8bd1\u4fdd\u771f\u3001\u9009\u62e9\u504f\u5dee\u53ca\u53d9\u4e8b\u6750\u6599\u7684\u4ee3\u8868\u6027\u4e0d\u8db3\u8fdb\u884c\u4e86\u5206\u6790\u3002", "conclusion": "MuRating\u7a81\u7834\u4e86\u57fa\u4e8e\u6a21\u578b\u7684\u6570\u636e\u9009\u62e9\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u7684\u5e94\u7528\u5c40\u9650\uff0c\u901a\u8fc7\u8fc1\u79fb\u9ad8\u8d28\u91cf\u82f1\u6587\u4fe1\u53f7\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u8bed\u8a00\u6570\u636e\u8d28\u91cf\u9009\u62e9\u4e0e\u8bc4\u4f30\u80fd\u529b\uff0c\u5bf9\u591a\u8bed\u8a00\u5927\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u6548\u679c\u6709\u663e\u8457\u5e2e\u52a9\uff0c\u5e76\u4e3a\u540e\u7eed\u6539\u8fdb\u63d0\u51fa\u4e86\u5206\u6790\u4e0e\u5efa\u8bae\u3002"}}
{"id": "2507.01786", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.01786", "abs": "https://arxiv.org/abs/2507.01786", "authors": ["Jord Nguyen", "Khiem Hoang", "Carlo Leonardo Attubato", "Felix Hofst\u00e4tter"], "title": "Probing Evaluation Awareness of Language Models", "comment": "Technical AI Governance Workshop, ICML (Poster)", "summary": "Language models can distinguish between testing and deployment phases -- a\ncapability known as evaluation awareness. This has significant safety and\npolicy implications, potentially undermining the reliability of evaluations\nthat are central to AI governance frameworks and voluntary industry\ncommitments. In this paper, we study evaluation awareness in\nLlama-3.3-70B-Instruct. We show that linear probes can separate real-world\nevaluation and deployment prompts, suggesting that current models internally\nrepresent this distinction. We also find that current safety evaluations are\ncorrectly classified by the probes, suggesting that they already appear\nartificial or inauthentic to models. Our findings underscore the importance of\nensuring trustworthy evaluations and understanding deceptive capabilities. More\nbroadly, our work showcases how model internals may be leveraged to support\nblackbox methods in safety audits, especially for future models more competent\nat evaluation awareness and deception.", "AI": {"tldr": "Llama-3.3-70B-Instruct\u5177\u5907\u533a\u5206\u6d4b\u8bd5\u548c\u90e8\u7f72\u7684\u80fd\u529b\uff0c\u8fd9\u4f1a\u5f71\u54cdAI\u5b89\u5168\u548c\u6cbb\u7406\u7684\u8bc4\u4f30\u53ef\u9760\u6027\u3002\u8bba\u6587\u901a\u8fc7\u7ebf\u6027\u63a2\u6d4b\u5206\u6790\u4e86\u6a21\u578b\u7684\u201c\u8bc4\u6d4b\u611f\u77e5\u201d\u80fd\u529b\uff0c\u63d0\u9192\u4e1a\u754c\u6ce8\u610f\u8bc4\u6d4b\u53ef\u4fe1\u5ea6\uff0c\u5e76\u8003\u8651\u5c06\u6a21\u578b\u5185\u90e8\u4fe1\u606f\u7528\u4e8e\u66f4\u53ef\u9760\u7684\u5b89\u5168\u5ba1\u8ba1\u3002", "motivation": "\u6a21\u578b\u5982\u679c\u77e5\u9053\u81ea\u5df1\u662f\u5728\u88ab\u6d4b\u8bd5\u6216\u8005\u90e8\u7f72\u9636\u6bb5\uff0c\u8fd9\u4f1a\u5f71\u54cd\u6211\u4eec\u5bf9\u6a21\u578b\u5b89\u5168\u7684\u8bc4\u4f30\u3001\u653f\u7b56\u548c\u7ba1\u63a7\u7684\u53ef\u4fe1\u5ea6\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u5bf9\u8bc4\u6d4b\u4e0e\u90e8\u7f72\u9636\u6bb5\u7684\u533a\u5206\u80fd\u529b\u3002", "method": "\u5bf9Llama-3.3-70B-Instruct\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5229\u7528\u7ebf\u6027\u63a2\u6d4b\u5668\uff08linear probes\uff09\u5206\u6790\u6a21\u578b\u662f\u5426\u80fd\u533a\u5206\u6d4b\u8bd5\u548c\u90e8\u7f72\u7684\u63d0\u793a\u8bcd\uff0c\u5e76\u5224\u65ad\u6a21\u578b\u5bf9\u5f53\u524d\u5b89\u5168\u8bc4\u6d4b\u7684\u8bc6\u522b\u80fd\u529b\u3002", "result": "\u7ebf\u6027\u63a2\u6d4b\u5668\u80fd\u591f\u533a\u5206\u771f\u5b9e\u4e16\u754c\u7684\u8bc4\u6d4b\u548c\u90e8\u7f72\u63d0\u793a\uff0c\u8868\u660e\u6a21\u578b\u539f\u672c\u5c31\u5728\u5185\u90e8\u8868\u793a\u4e0a\u533a\u5206\u8fd9\u4e24\u8005\u3002\u6b64\u5916\uff0c\u6a21\u578b\u5bf9\u73b0\u6709\u5b89\u5168\u8bc4\u6d4b\u4e5f\u80fd\u88ab\u6b63\u786e\u5206\u7c7b\uff0c\u8bf4\u660e\u8fd9\u4e9b\u8bc4\u6d4b\u5728\u6a21\u578b\u770b\u6765\u662f\u201c\u505a\u4f5c\u201d\u7684\u3002", "conclusion": "\u5fc5\u987b\u786e\u4fdd\u8bc4\u6d4b\u7684\u53ef\u4fe1\u5ea6\uff0c\u63d0\u9ad8\u5bf9\u6a21\u578b\u6b3a\u9a97\u6027\u80fd\u529b\u7684\u8ba4\u77e5\uff0c\u5e76\u5efa\u8bae\u5229\u7528\u6a21\u578b\u5185\u90e8\u4fe1\u53f7\u8f85\u52a9\u5b89\u5168\u5ba1\u8ba1\uff0c\u5c24\u5176\u9762\u5411\u66f4\u64c5\u957f\u201c\u8bc4\u6d4b\u611f\u77e5\u201d\u7684\u672a\u6765\u6a21\u578b\u3002"}}
{"id": "2507.01790", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01790", "abs": "https://arxiv.org/abs/2507.01790", "authors": ["Tianze Hua", "Tian Yun", "Ellie Pavlick"], "title": "How Do Vision-Language Models Process Conflicting Information Across Modalities?", "comment": "All code and resources are available at:\n  https://github.com/ethahtz/vlm_conflicting_info_processing", "summary": "AI models are increasingly required to be multimodal, integrating disparate\ninput streams into a coherent state representation on which subsequent\nbehaviors and actions can be based. This paper seeks to understand how such\nmodels behave when input streams present conflicting information. Focusing\nspecifically on vision-language models, we provide inconsistent inputs (e.g.,\nan image of a dog paired with the caption \"A photo of a cat\") and ask the model\nto report the information present in one of the specific modalities (e.g.,\n\"What does the caption say / What is in the image?\"). We find that models often\nfavor one modality over the other, e.g., reporting the image regardless of what\nthe caption says, but that different models differ in which modality they\nfavor. We find evidence that the behaviorally preferred modality is evident in\nthe internal representational structure of the model, and that specific\nattention heads can restructure the representations to favor one modality over\nthe other. Moreover, we find modality-agnostic \"router heads\" which appear to\npromote answers about the modality requested in the instruction, and which can\nbe manipulated or transferred in order to improve performance across datasets\nand modalities. Together, the work provides essential steps towards identifying\nand controlling if and how models detect and resolve conflicting signals within\ncomplex multimodal environments.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u89c6\u89c9-\u8bed\u8a00\u591a\u6a21\u6001\u6a21\u578b\u5728\u9762\u5bf9\u77db\u76fe\u4fe1\u606f\u65f6\u7684\u5904\u7406\u504f\u5411\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5185\u90e8\u7ed3\u6784\u51b3\u5b9a\u4e86\u8fd9\u79cd\u504f\u5411\u6027\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u201c\u8def\u7531\u5934\u201d\u63d0\u5347\u6a21\u578b\u53ef\u63a7\u6027\u7684\u673a\u5236\uff0c\u4e3a\u591a\u6a21\u6001\u51b2\u7a81\u4fe1\u53f7\u7684\u68c0\u6d4b\u4e0e\u8c03\u63a7\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u968f\u7740AI\u6a21\u578b\u591a\u6a21\u6001\u96c6\u6210\u9700\u6c42\u589e\u957f\uff0c\u4e86\u89e3\u6a21\u578b\u5982\u4f55\u5728\u8f93\u5165\u5b58\u5728\u77db\u76fe\u65f6\u8fdb\u884c\u4fe1\u606f\u5904\u7406\u4e0e\u8868\u5f81\u91cd\u6784\uff0c\u5bf9\u4e8e\u63d0\u5347\u6a21\u578b\u7684\u5065\u58ee\u6027\u53ca\u53ef\u63a7\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u6587\u9488\u5bf9\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u8f93\u5165\u4e92\u76f8\u77db\u76fe\u7684\u4fe1\u606f\uff08\u5982\u72d7\u7684\u56fe\u7247\u914d\u4e0a\u201c\u8fd9\u662f\u4e00\u53ea\u732b\u201d\u7684\u6587\u5b57\u63cf\u8ff0\uff09\uff0c\u8981\u6c42\u6a21\u578b\u6839\u636e\u7279\u5b9a\u6307\u4ee4\u62a5\u544a\u67d0\u4e00\u6a21\u6001\u7684\u4fe1\u606f\uff0c\u5e76\u89c2\u5bdf\u5176\u884c\u4e3a\u53ca\u5185\u90e8\u7ed3\u6784\u7279\u5f81\u3002\u4e3b\u8981\u901a\u8fc7\u884c\u4e3a\u89c2\u6d4b\u3001\u5185\u90e8\u8868\u5f81\u5206\u6790\u3001\u6ce8\u610f\u529b\u5934\u4e0e\u8def\u7531\u5934\u8bc6\u522b\u53ca\u64cd\u4f5c\u7b49\u5b9e\u9a8c\u624b\u6bb5\u7814\u7a76\u3002", "result": "\u4e0d\u540c\u7684\u591a\u6a21\u6001\u6a21\u578b\u5728\u9762\u5bf9\u77db\u76fe\u8f93\u5165\u65f6\u5904\u7406\u65b9\u5f0f\u4e0d\u540c\uff0c\u5177\u6709\u504f\u5411\u6027\u3002\u901a\u8fc7\u5bf9\u6ce8\u610f\u529b\u5934\u548c\u201c\u8def\u7531\u5934\u201d\u7684\u5206\u6790\u548c\u64cd\u4f5c\uff0c\u53ef\u4ee5\u63d0\u5347\u6a21\u578b\u6309\u6307\u4ee4\u5173\u6ce8\u76ee\u6807\u6a21\u6001\u3001\u6539\u8fdb\u5176\u5728\u4e0d\u540c\u6570\u636e\u96c6\u53ca\u6a21\u6001\u4e0b\u7684\u8868\u73b0\u3002", "conclusion": "\u8bba\u6587\u63ed\u793a\u4e86\u591a\u6a21\u6001\u6a21\u578b\u5728\u5904\u7406\u76f8\u4e92\u77db\u76fe\u7684\u4fe1\u606f\u65f6\uff0c\u901a\u5e38\u4f1a\u504f\u5411\u67d0\u4e00\u8f93\u5165\u6a21\u6001\uff08\u5982\u56fe\u50cf\u6216\u6587\u672c\uff09\uff0c\u4e14\u504f\u5411\u6027\u5728\u6a21\u578b\u5185\u90e8\u7684\u8868\u793a\u7ed3\u6784\u4e2d\u6709\u6240\u4f53\u73b0\u3002\u901a\u8fc7\u64cd\u4f5c\u7279\u5b9a\u7684\u6ce8\u610f\u529b\u5934\uff0c\u8fd8\u80fd\u5f15\u5bfc\u6a21\u578b\u5173\u6ce8\u7279\u5b9a\u6a21\u6001\uff0c\u751a\u81f3\u53ef\u4ee5\u901a\u8fc7\u201c\u8def\u7531\u5934\u201d\u63d0\u5347\u6a21\u578b\u6839\u636e\u6307\u4ee4\u9009\u62e9\u6b63\u786e\u6a21\u6001\u4f5c\u7b54\u7684\u80fd\u529b\u3002"}}
{"id": "2507.01802", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01802", "abs": "https://arxiv.org/abs/2507.01802", "authors": ["Katharina Beckh", "Elisa Studeny", "Sujan Sai Gannamaneni", "Dario Antweiler", "Stefan R\u00fcping"], "title": "The Anatomy of Evidence: An Investigation Into Explainable ICD Coding", "comment": "Accepted to ACL 2025 Findings", "summary": "Automatic medical coding has the potential to ease documentation and billing\nprocesses. For this task, transparency plays an important role for medical\ncoders and regulatory bodies, which can be achieved using explainability\nmethods. However, the evaluation of these approaches has been mostly limited to\nshort text and binary settings due to a scarcity of annotated data. Recent\nefforts by Cheng et al. (2023) have introduced the MDACE dataset, which\nprovides a valuable resource containing code evidence in clinical records. In\nthis work, we conduct an in-depth analysis of the MDACE dataset and perform\nplausibility evaluation of current explainable medical coding systems from an\napplied perspective. With this, we contribute to a deeper understanding of\nautomatic medical coding and evidence extraction. Our findings reveal that\nground truth evidence aligns with code descriptions to a certain degree. An\ninvestigation into state-of-the-art approaches shows a high overlap with ground\ntruth evidence. We propose match measures and highlight success and failure\ncases. Based on our findings, we provide recommendations for developing and\nevaluating explainable medical coding systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5206\u6790MDACE\u6570\u636e\u96c6\uff0c\u6df1\u5165\u8bc4\u4f30\u4e86\u81ea\u52a8\u533b\u5b66\u7f16\u7801\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u6307\u51fa\u73b0\u6709\u65b9\u6cd5\u4e0e\u771f\u5b9e\u8bc1\u636e\u6709\u8f83\u9ad8\u91cd\u5408\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u81ea\u52a8\u533b\u5b66\u7f16\u7801\u5bf9\u63d0\u9ad8\u6587\u6863\u548c\u8d26\u5355\u5904\u7406\u6548\u7387\u6709\u663e\u8457\u4f5c\u7528\uff0c\u4f46\u5176\u900f\u660e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u5bf9\u533b\u5b66\u7f16\u7801\u8005\u548c\u76d1\u7ba1\u673a\u6784\u5c24\u4e3a\u91cd\u8981\u3002\u6b64\u524d\u7531\u4e8e\u6570\u636e\u6807\u6ce8\u7a00\u7f3a\uff0c\u76f8\u5173\u65b9\u6cd5\u8bc4\u4f30\u4ec5\u9650\u4e8e\u77ed\u6587\u672c\u4e0e\u4e8c\u5206\u7c7b\u95ee\u9898\uff0cMDACE\u6570\u636e\u96c6\u7684\u51fa\u73b0\u4e3a\u6df1\u5165\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "method": "\u6df1\u5165\u5206\u6790\u4e86MDACE\u6570\u636e\u96c6\uff0c\u4ece\u5e94\u7528\u89d2\u5ea6\u5bf9\u73b0\u6709\u53ef\u89e3\u91ca\u6027\u81ea\u52a8\u533b\u5b66\u7f16\u7801\u7cfb\u7edf\u8fdb\u884c\u4e86\u5408\u7406\u6027\u8bc4\u4f30\uff1b\u63d0\u51fa\u4e86\u5339\u914d\u5ea6\u91cf\u6807\u51c6\uff0c\u5e76\u5bf9\u6210\u529f\u548c\u5931\u8d25\u6848\u4f8b\u8fdb\u884c\u4e86\u5c55\u793a\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u771f\u5b9e\u8bc1\u636e\u4e0e\u7f16\u7801\u63cf\u8ff0\u5177\u6709\u4e00\u5b9a\u7a0b\u5ea6\u7684\u4e00\u81f4\u6027\uff0c\u6700\u65b0\u65b9\u6cd5\u751f\u6210\u8bc1\u636e\u4e0e\u771f\u5b9e\u8bc1\u636e\u9ad8\u5ea6\u91cd\u53e0\u3002\u7814\u7a76\u63d0\u51fa\u4e86\u8bc4\u4ef7\u6307\u6807\uff0c\u5e76\u5bf9\u73b0\u6709\u7cfb\u7edf\u7684\u4f18\u7f3a\u70b9\u8fdb\u884c\u4e86\u603b\u7ed3\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\uff0c\u5f53\u524d\u6700\u5148\u8fdb\u7684\u81ea\u52a8\u533b\u5b66\u7f16\u7801\u7cfb\u7edf\u4e0e\u771f\u5b9e\u8bc1\u636e\u6709\u8f83\u5927\u91cd\u5408\uff0c\u4f46\u4ecd\u6709\u8fdb\u4e00\u6b65\u6539\u8fdb\u7a7a\u95f4\u3002\u7814\u7a76\u7ed9\u51fa\u4e86\u5f00\u53d1\u548c\u8bc4\u4f30\u53ef\u89e3\u91ca\u6027\u533b\u5b66\u7f16\u7801\u7cfb\u7edf\u7684\u5efa\u8bae\u3002"}}
{"id": "2507.01810", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.01810", "abs": "https://arxiv.org/abs/2507.01810", "authors": ["Nikita Neveditsin", "Pawan Lingras", "Vijay Mago"], "title": "Evaluating Structured Output Robustness of Small Language Models for Open Attribute-Value Extraction from Clinical Notes", "comment": "To appear in the ACL Anthology", "summary": "We present a comparative analysis of the parseability of structured outputs\ngenerated by small language models for open attribute-value extraction from\nclinical notes. We evaluate three widely used serialization formats: JSON,\nYAML, and XML, and find that JSON consistently yields the highest parseability.\nStructural robustness improves with targeted prompting and larger models, but\ndeclines for longer documents and certain note types. Our error analysis\nidentifies recurring format-specific failure patterns. These findings offer\npractical guidance for selecting serialization formats and designing prompts\nwhen deploying language models in privacy-sensitive clinical settings.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86JSON\u3001YAML\u548cXML\u4e09\u79cd\u7ed3\u6784\u5316\u683c\u5f0f\u5728\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e34\u5e8a\u7b14\u8bb0\u5c5e\u6027-\u503c\u62bd\u53d6\u4efb\u52a1\u4e2d\u7684\u53ef\u89e3\u6790\u6027\uff0c\u53d1\u73b0JSON\u6700\u4f18\uff0c\u5e76\u63d0\u51fa\u76f8\u5173\u5e94\u7528\u5efa\u8bae\u3002", "motivation": "\u5728\u4f7f\u7528\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u4e34\u5e8a\u7b14\u8bb0\u4e2d\u62bd\u53d6\u5c5e\u6027-\u503c\u8fdb\u884c\u7ed3\u6784\u5316\u8f93\u51fa\u65f6\uff0c\u8f93\u51fa\u7ed3\u679c\u7684\u53ef\u89e3\u6790\u6027\u95ee\u9898\u5f71\u54cd\u6a21\u578b\u5b9e\u9645\u5e94\u7528\u3002\u4e0d\u540c\u5e8f\u5217\u5316\u683c\u5f0f\u5728\u89e3\u6790\u65f6\u6548\u679c\u4e0d\u540c\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6bd4\u8f83\u548c\u5b9e\u8bc1\u5206\u6790\u3002", "method": "\u5bf9\u6bd4\u4e09\u79cd\u5e38\u7528\u7ed3\u6784\u5316\u8f93\u51fa\u683c\u5f0f\uff08JSON\u3001YAML\u3001XML\uff09\u5728\u63d0\u53d6\u4e34\u5e8a\u7b14\u8bb0\u5c5e\u6027-\u503c\u65f6\u7684\u89e3\u6790\u6027\uff0c\u901a\u8fc7\u5b9e\u9645\u5b9e\u9a8c\u68c0\u9a8c\u4e0d\u540c\u683c\u5f0f\u5728\u4e0d\u540c\u60c5\u5883\u4e0b\u7684\u89e3\u6790\u8868\u73b0\u548c\u5e38\u89c1\u9519\u8bef\u3002", "result": "JSON\u683c\u5f0f\u5728\u4e0d\u540c\u6d4b\u8bd5\u4e2d\u663e\u793a\u51fa\u6700\u597d\u7684\u53ef\u89e3\u6790\u6027\uff1b\u901a\u8fc7\u9488\u5bf9\u6027\u63d0\u793a\u548c\u4f7f\u7528\u66f4\u5927\u6a21\u578b\uff0c\u7ed3\u6784\u9c81\u68d2\u6027\u6709\u6240\u63d0\u5347\uff0c\u4f46\u5728\u5904\u7406\u957f\u7bc7\u6587\u6863\u548c\u67d0\u4e9b\u7c7b\u578b\u7b14\u8bb0\u65f6\u8868\u73b0\u4e0b\u964d\u3002\u5206\u6790\u4e86\u5404\u683c\u5f0f\u72ec\u6709\u7684\u9519\u8bef\u6a21\u5f0f\u3002", "conclusion": "\u8bba\u6587\u4e3a\u5728\u4e34\u5e8a\u654f\u611f\u573a\u666f\u4e0b\u5982\u4f55\u9009\u62e9\u5e8f\u5217\u5316\u683c\u5f0f\u548c\u8bbe\u8ba1\u63d0\u793a\u8bcd\uff0c\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7ed3\u6784\u5316\u5185\u5bb9\u7684\u53ef\u89e3\u6790\u6027\u63d0\u4f9b\u4e86\u5177\u4f53\u5efa\u8bae\u3002"}}
{"id": "2507.01844", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01844", "abs": "https://arxiv.org/abs/2507.01844", "authors": ["Arthur Wuhrmann", "Anastasiia Kucherenko", "Andrei Kucharavy"], "title": "Low-Perplexity LLM-Generated Sequences and Where To Find Them", "comment": "Camera-ready version. Accepted to ACL 2025. 10 pages, 4 figures, 6\n  tables", "summary": "As Large Language Models (LLMs) become increasingly widespread, understanding\nhow specific training data shapes their outputs is crucial for transparency,\naccountability, privacy, and fairness. To explore how LLMs leverage and\nreplicate their training data, we introduce a systematic approach centered on\nanalyzing low-perplexity sequences - high-probability text spans generated by\nthe model. Our pipeline reliably extracts such long sequences across diverse\ntopics while avoiding degeneration, then traces them back to their sources in\nthe training data. Surprisingly, we find that a substantial portion of these\nlow-perplexity spans cannot be mapped to the corpus. For those that do match,\nwe quantify the distribution of occurrences across source documents,\nhighlighting the scope and nature of verbatim recall and paving a way toward\nbetter understanding of how LLMs training data impacts their behavior.", "AI": {"tldr": "\u63d0\u51fa\u5206\u6790LLM\u8f93\u51fa\u4e0e\u8bad\u7ec3\u6570\u636e\u5173\u7cfb\u7684\u65b0\u65b9\u6cd5\uff0c\u53d1\u73b0\u5927\u90e8\u5206\u9ad8\u6982\u7387\u8f93\u51fa\u6765\u6e90\u672a\u77e5\uff0c\u4e3a\u7406\u89e3\u6a21\u578b\u884c\u4e3a\u63d0\u4f9b\u91cf\u5316\u65b9\u5f0f\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5e94\u7528\u5e7f\u6cdb\uff0c\u9700\u7406\u89e3\u8bad\u7ec3\u6570\u636e\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u8f93\u51fa\uff0c\u4ee5\u63d0\u5347\u900f\u660e\u5ea6\u3001\u95ee\u8d23\u3001\u9690\u79c1\u548c\u516c\u5e73\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7cfb\u7edf\u6027\u65b9\u6cd5\uff0c\u805a\u7126\u4e8e\u5206\u6790\u6a21\u578b\u751f\u6210\u7684\u4f4e\u56f0\u60d1\u5ea6\u5e8f\u5217\uff08\u9ad8\u6982\u7387\u6587\u672c\u7247\u6bb5\uff09\uff0c\u901a\u8fc7\u62bd\u53d6\u6b64\u7c7b\u5e8f\u5217\u5e76\u8ffd\u6eaf\u5176\u8bad\u7ec3\u6570\u636e\u6765\u6e90\uff0c\u63a2\u7a76\u8bad\u7ec3\u6570\u636e\u4e0e\u8f93\u51fa\u7684\u5173\u7cfb\u3002", "result": "\u53d1\u73b0\u5927\u91cf\u9ad8\u6982\u7387\u751f\u6210\u7247\u6bb5\u65e0\u6cd5\u5728\u8bad\u7ec3\u8bed\u6599\u4e2d\u627e\u5230\u5bf9\u5e94\uff1b\u5bf9\u53ef\u5339\u914d\u7684\u7247\u6bb5\uff0c\u91cf\u5316\u5176\u5728\u6e90\u6587\u6863\u4e2d\u7684\u5206\u5e03\uff0c\u63ed\u793a\u9010\u5b57\u53ec\u56de\u7684\u8303\u56f4\u4e0e\u6027\u8d28\u3002", "conclusion": "\u672c\u6587\u4e3a\u7406\u89e3\u8bad\u7ec3\u6570\u636e\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u884c\u4e3a\u7684\u5f71\u54cd\u63d0\u4f9b\u4e86\u65b9\u6cd5\u4e0e\u91cf\u5316\u4f9d\u636e\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u4e0e\u5ba1\u67e5\u80fd\u529b\u3002"}}
{"id": "2507.01853", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01853", "abs": "https://arxiv.org/abs/2507.01853", "authors": ["Samridhi Raj Sinha", "Rajvee Sheth", "Abhishek Upperwal", "Mayank Singh"], "title": "Eka-Eval : A Comprehensive Evaluation Framework for Large Language Models in Indian Languages", "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) has intensified the\nneed for evaluation frameworks that go beyond English centric benchmarks and\naddress the requirements of linguistically diverse regions such as India. We\npresent EKA-EVAL, a unified and production-ready evaluation framework that\nintegrates over 35 benchmarks, including 10 Indic-specific datasets, spanning\ncategories like reasoning, mathematics, tool use, long-context understanding,\nand reading comprehension. Compared to existing Indian language evaluation\ntools, EKA-EVAL offers broader benchmark coverage, with built-in support for\ndistributed inference, quantization, and multi-GPU usage. Our systematic\ncomparison positions EKA-EVAL as the first end-to-end, extensible evaluation\nsuite tailored for both global and Indic LLMs, significantly lowering the\nbarrier to multilingual benchmarking. The framework is open-source and publicly\navailable at https://github.com/lingo-iitgn/ eka-eval and a part of ongoing EKA\ninitiative (https://eka.soket.ai), which aims to scale up to over 100\nbenchmarks and establish a robust, multilingual evaluation ecosystem for LLMs.", "AI": {"tldr": "EKA-EVAL\u662f\u4e00\u5957\u9762\u5411\u591a\u8bed\u8a00LLM\uff08\u7279\u522b\u662f\u5370\u5ea6\u672c\u5730\u8bed\u8a00\uff09\u7684\u7efc\u5408\u8bc4\u6d4b\u6846\u67b6\uff0c\u652f\u6301\u591a\u9879\u4efb\u52a1\u7c7b\u522b\u548c\u5148\u8fdb\u786c\u4ef6\u7279\u6027\uff0c\u586b\u8865\u4e86\u591a\u8bed\u79cd\u8bc4\u6d4b\u5de5\u5177\u7a7a\u767d\uff0c\u5df2\u5f00\u653e\u6e90\u7801\uff0c\u52a9\u63a8\u591a\u8bed\u8a00AI\u53d1\u5c55\u3002", "motivation": "\u5f53\u524dLLM\u8bc4\u4f30\u8fc7\u4e8e\u504f\u5411\u82f1\u8bed\uff0c\u7f3a\u4e4f\u5bf9\u5370\u5ea6\u7b49\u8bed\u8a00\u591a\u6837\u6027\u5730\u533a\u7684\u8bc4\u6d4b\u6846\u67b6\uff0c\u4e9f\u9700\u7edf\u4e00\u3001\u6613\u7528\u3001\u8986\u76d6\u5e7f\u6cdb\u7684\u8bc4\u4f30\u5de5\u5177\u3002", "method": "\u96c6\u6210\u4e8635\u4e2a\u4ee5\u4e0a\u57fa\u51c6\uff08\u542b10\u4e2a\u5370\u5ea6\u672c\u5730\u6570\u636e\u96c6\uff09\uff0c\u6db5\u76d6\u63a8\u7406\u3001\u6570\u5b66\u3001\u5de5\u5177\u4f7f\u7528\u3001\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u3001\u9605\u8bfb\u7406\u89e3\u7b49\u591a\u4e2a\u7c7b\u522b\u3002\u6846\u67b6\u652f\u6301\u5206\u5e03\u5f0f\u63a8\u7406\u3001\u91cf\u5316\u4e0e\u591aGPU\uff0c\u4e14\u5bf9\u6bd4\u73b0\u6709\u65b9\u6cd5\u6709\u66f4\u5e7f\u6cdb\u7684\u8986\u76d6\u548c\u751f\u4ea7\u53ef\u7528\u80fd\u529b\u3002", "result": "EKA-EVAL\u63d0\u4f9b\u4e86\u6bd4\u73b0\u6709\u5de5\u5177\u66f4\u5168\u9762\u7684\u8bc4\u6d4b\u80fd\u529b\uff0c\u4e3a\u591a\u8bed\u8a00\uff08\u5c24\u5176\u662f\u5370\u5ea6\u8bed\u8a00\uff09LLM\u7684\u6d4b\u8bc4\u548c\u5bf9\u6bd4\u63d0\u4f9b\u4e86\u4fbf\u5229\uff0c\u4e14\u5df2\u5f00\u6e90\u53d1\u5e03\u3002", "conclusion": "EKA-EVAL\u662f\u9996\u4e2a\u9762\u5411\u5168\u7403\u53ca\u5370\u5ea6\u672c\u5730LLM\u7684\u7aef\u5230\u7aef\u53ef\u6269\u5c55\u8bc4\u6d4b\u6846\u67b6\uff0c\u6781\u5927\u964d\u4f4e\u4e86\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u7684\u95e8\u69db\uff0c\u5e76\u8ba1\u5212\u672a\u6765\u6269\u5c55\u66f4\u591a\u6570\u636e\u96c6\uff0c\u81f4\u529b\u4e8e\u5efa\u7acb\u5065\u5168\u591a\u8bed\u79cdLLM\u8bc4\u6d4b\u751f\u6001\u3002"}}
{"id": "2507.01872", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01872", "abs": "https://arxiv.org/abs/2507.01872", "authors": ["Kenan Tang", "Yanhong Li", "Yao Qin"], "title": "DIY-MKG: An LLM-Based Polyglot Language Learning System", "comment": "Submitted to EMNLP 2025 System Demonstration", "summary": "Existing language learning tools, even those powered by Large Language Models\n(LLMs), often lack support for polyglot learners to build linguistic\nconnections across vocabularies in multiple languages, provide limited\ncustomization for individual learning paces or needs, and suffer from\ndetrimental cognitive offloading. To address these limitations, we design\nDo-It-Yourself Multilingual Knowledge Graph (DIY-MKG), an open-source system\nthat supports polyglot language learning. DIY-MKG allows the user to build\npersonalized vocabulary knowledge graphs, which are constructed by selective\nexpansion with related words suggested by an LLM. The system further enhances\nlearning through rich annotation capabilities and an adaptive review module\nthat leverages LLMs for dynamic, personalized quiz generation. In addition,\nDIY-MKG allows users to flag incorrect quiz questions, simultaneously\nincreasing user engagement and providing a feedback loop for prompt refinement.\nOur evaluation of LLM-based components in DIY-MKG shows that vocabulary\nexpansion is reliable and fair across multiple languages, and that the\ngenerated quizzes are highly accurate, validating the robustness of DIY-MKG.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u73b0\u6709\u8bed\u8a00\u5b66\u4e60\u5de5\u5177\u5bf9\u591a\u8bed\u79cd\u5b66\u4e60\u652f\u6301\u4e0d\u4f73\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86DIY-MKG\u7cfb\u7edf\uff0c\u5141\u8bb8\u7528\u6237\u4e0eLLM\u5171\u540c\u6784\u5efa\u591a\u8bed\u79cd\u8bcd\u6c47\u77e5\u8bc6\u56fe\u8c31\u5e76\u5f00\u5c55\u4e2a\u6027\u5316\u5b66\u4e60\u3002\u7cfb\u7edf\u8bc4\u4f30\u663e\u793a\u5176\u591a\u8bed\u79cd\u6269\u5c55\u4e0e\u6d4b\u9a8c\u6781\u4e3a\u51c6\u786e\uff0c\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u548c\u5b66\u4e60\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u8bed\u8a00\u5b66\u4e60\u5de5\u5177\uff0c\u751a\u81f3\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u9a71\u52a8\u7684\u5de5\u5177\uff0c\u5e38\u5e38\u65e0\u6cd5\u5f88\u597d\u5730\u652f\u6301\u591a\u8bed\u8a00\u5b66\u4e60\u8005\u5728\u591a\u79cd\u8bed\u8a00\u8bcd\u6c47\u4e4b\u95f4\u5efa\u7acb\u8054\u7cfb\uff0c\u5b9a\u5236\u6027\u4e0d\u8db3\uff0c\u4e14\u5b58\u5728\u8ba4\u77e5\u8d1f\u8377\u8fc7\u91cd\u7684\u95ee\u9898\u3002\u8be5\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u75db\u70b9\u3002", "method": "\u63d0\u51fa\u4e86DIY-MKG\uff08\u81ea\u52a9\u5f0f\u591a\u8bed\u8a00\u77e5\u8bc6\u56fe\u8c31\uff09\u5f00\u6e90\u7cfb\u7edf\u3002\u7528\u6237\u53ef\u901a\u8fc7\u8be5\u7cfb\u7edf\u9009\u62e9\u6027\u5730\u6269\u5c55\u4e2a\u6027\u5316\u8bcd\u6c47\u77e5\u8bc6\u56fe\u8c31\uff0cLLM\u63a8\u8350\u76f8\u5173\u8bcd\u6c47\uff0c\u5e76\u63d0\u4f9b\u4e30\u5bcc\u6ce8\u91ca\u529f\u80fd\u53ca\u81ea\u9002\u5e94\u590d\u4e60\u6a21\u5757\uff08\u57fa\u4e8eLLM\u52a8\u6001\u751f\u6210\u4e2a\u6027\u5316\u6d4b\u9a8c\uff09\u3002\u7528\u6237\u8fd8\u80fd\u6807\u8bb0\u9519\u8bef\u9898\u76ee\uff0c\u4e3a\u6a21\u578b\u4f18\u5316\u63d0\u4f9b\u53cd\u9988\u5faa\u73af\u3002", "result": "\u7cfb\u7edf\u4e2dLLM\u76f8\u5173\u7ec4\u4ef6\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u591a\u8bed\u8a00\u8bcd\u6c47\u6269\u5c55\u5177\u5907\u53ef\u9760\u6027\u548c\u516c\u5e73\u6027\uff0c\u6d4b\u9a8c\u751f\u6210\u51c6\u786e\u5ea6\u9ad8\uff0c\u9a8c\u8bc1\u4e86DIY-MKG\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "DIY-MKG\u901a\u8fc7\u7ed3\u5408LLM\u548c\u7528\u6237\u53c2\u4e0e\uff0c\u5b9e\u73b0\u4e86\u66f4\u52a0\u4e2a\u6027\u5316\u3001\u591a\u8bed\u8a00\u652f\u6301\u548c\u53cd\u9988\u9a71\u52a8\u7684\u8bed\u8a00\u5b66\u4e60\u4f53\u9a8c\uff0c\u514b\u670d\u4e86\u73b0\u6709\u5de5\u5177\u7684\u4e3b\u8981\u5c40\u9650\u3002"}}
{"id": "2507.01887", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01887", "abs": "https://arxiv.org/abs/2507.01887", "authors": ["Dongyi Ding", "Tiannan Wang", "Chenghao Zhu", "Meiling Tao", "Yuchen Eleanor Jiang", "Wangchunshu Zhou"], "title": "MiCoTA: Bridging the Learnability Gap with Intermediate CoT and Teacher Assistants", "comment": "Work in progress", "summary": "Large language models (LLMs) excel at reasoning tasks requiring long thought\nsequences for planning, reflection, and refinement. However, their substantial\nmodel size and high computational demands are impractical for widespread\ndeployment. Yet, small language models (SLMs) often struggle to learn long-form\nCoT reasoning due to their limited capacity, a phenomenon we refer to as the\n\"SLMs Learnability Gap\". To address this, we introduce\n\\textbf{Mi}d-\\textbf{Co}T \\textbf{T}eacher \\textbf{A}ssistant Distillation\n(MiCoTAl), a framework for improving long CoT distillation for SLMs. MiCoTA\nemploys intermediate-sized models as teacher assistants and utilizes\nintermediate-length CoT sequences to bridge both the capacity and reasoning\nlength gaps. Our experiments on downstream tasks demonstrate that although SLMs\ndistilled from large teachers can perform poorly, by applying MiCoTA, they\nachieve significant improvements in reasoning performance. Specifically,\nQwen2.5-7B-Instruct and Qwen2.5-3B-Instruct achieve an improvement of 3.47 and\n3.93 respectively on average score on AIME2024, AMC, Olympiad, MATH-500 and\nGSM8K benchmarks. To better understand the mechanism behind MiCoTA, we perform\na quantitative experiment demonstrating that our method produces data more\nclosely aligned with base SLM distributions. Our insights pave the way for\nfuture research into long-CoT data distillation for SLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMiCoTA\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u4e2d\u7b49\u89c4\u6a21\u6559\u5e08\u52a9\u7406\u548c\u4e2d\u7b49\u957f\u5ea6\u63a8\u7406\u94fe\u6761\uff0c\u6709\u6548\u7f29\u5c0f\u5c0f\u6a21\u578b\u5b66\u4e60\u957f\u94fe\u63a8\u7406\u7684\u9e3f\u6c9f\uff0c\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86SLMs\u7684\u63a8\u7406\u8868\u73b0\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u9700\u8981\u957f\u63a8\u7406\u94fe\u6761\u7684\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u5e9e\u5927\u7684\u89c4\u6a21\u4e0e\u9ad8\u7b97\u529b\u9700\u6c42\u9650\u5236\u4e86\u5b9e\u9645\u90e8\u7f72\u3002\u800c\u5c0f\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u56e0\u6a21\u578b\u5bb9\u91cf\u6709\u9650\uff0c\u96be\u4ee5\u5b66\u4e60\u957f\u94fe\u5f0f\u63a8\u7406\uff08CoT\uff09\uff0c\u5b58\u5728\u201cSLMs\u5b66\u4e60\u80fd\u529b\u9e3f\u6c9f\u201d\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6 MiCoTA\uff08Mid-CoT Teacher Assistant Distillation\uff09\uff0c\u901a\u8fc7\u5f15\u5165\u4e2d\u7b49\u89c4\u6a21\u7684\u6559\u5e08\u52a9\u7406\u6a21\u578b\u548c\u4e2d\u7b49\u957f\u5ea6\u7684\u63a8\u7406\u94fe\u6761\uff0c\u5728\u84b8\u998f\u8fc7\u7a0b\u4e2d\u9010\u6b65\u7f29\u5c0f\u5bb9\u91cf\u548c\u63a8\u7406\u957f\u5ea6\u5dee\u8ddd\uff0c\u63d0\u5347SLMs\u5bf9\u957f\u94fe\u5f0f\u63a8\u7406\u7684\u5b66\u4e60\u80fd\u529b\u3002", "result": "\u5728AIME2024\u3001AMC\u3001Olympiad\u3001MATH-500\u548cGSM8K\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u84b8\u998f\u81ea\u5927\u578b\u6559\u5e08\u7684SLMs\u5728\u672a\u4f7f\u7528MiCoTA\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u4f7f\u7528MiCoTA\u540e\uff0cQwen2.5-7B-Instruct\u4e0eQwen2.5-3B-Instruct\u5728\u5e73\u5747\u5206\u4e0a\u5206\u522b\u63d0\u53473.47\u548c3.93\u3002\u5206\u6790\u7ed3\u679c\u8868\u660e\uff0cMiCoTA\u751f\u6210\u7684\u6570\u636e\u66f4\u6613\u88ab\u57fa\u7840SLMs\u5b66\u4e60\u3002", "conclusion": "MiCoTA\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u5c0f\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u957f\u94fe\u5f0f\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u4e3aSLMs\u9886\u57df\u4e2d\u957fCoT\u6570\u636e\u84b8\u998f\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2507.01900", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01900", "abs": "https://arxiv.org/abs/2507.01900", "authors": ["Songtao Liu", "Peng Liu"], "title": "High-Layer Attention Pruning with Rescaling", "comment": null, "summary": "Pruning is a highly effective approach for compressing large language models\n(LLMs), significantly reducing inference latency. However, conventional\ntraining-free structured pruning methods often employ a heuristic metric that\nindiscriminately removes some attention heads across all pruning layers,\nwithout considering their positions within the network architecture. In this\nwork, we propose a novel pruning algorithm that strategically prunes attention\nheads in the model's higher layers. Since the removal of attention heads can\nalter the magnitude of token representations, we introduce an adaptive\nrescaling parameter that calibrates the representation scale post-pruning to\ncounteract this effect. We conduct comprehensive experiments on a wide range of\nLLMs, including LLaMA3.1-8B, Mistral-7B-v0.3, Qwen2-7B, and Gemma2-9B. Our\nevaluation includes both generation and discriminative tasks across 27\ndatasets. The results consistently demonstrate that our method outperforms\nexisting structured pruning methods. This improvement is particularly notable\nin generation tasks, where our approach significantly outperforms existing\nbaselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u5c42\u6ce8\u610f\u529b\u5934\u526a\u679d\u65b9\u6cd5\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u91cd\u7f29\u673a\u5236\uff0c\u5728\u591a\u4e2a\u4e3b\u6d41\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u526a\u679d\u540e\u7684\u6027\u80fd\uff0c\u5c24\u5176\u9002\u5408\u751f\u6210\u4efb\u52a1\u3002", "motivation": "\u4f20\u7edf\u7684\u65e0\u8bad\u7ec3\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\u5728\u4fee\u526aLLM\u65f6\uff0c\u901a\u5e38\u4f7f\u7528\u542f\u53d1\u5f0f\u6307\u6807\uff0c\u672a\u8003\u8651\u6ce8\u610f\u529b\u5934\u5728\u7f51\u7edc\u7ed3\u6784\u4e2d\u7684\u5177\u4f53\u4f4d\u7f6e\uff0c\u4ece\u800c\u5f71\u54cd\u526a\u679d\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u526a\u679d\u7b97\u6cd5\uff0c\u6709\u9488\u5bf9\u6027\u5730\u5728\u6a21\u578b\u9ad8\u5c42\u526a\u9664\u6ce8\u610f\u529b\u5934\uff0c\u5e76\u5f15\u5165\u81ea\u9002\u5e94\u91cd\u7f29\u53c2\u6570\uff0c\u7528\u4e8e\u5728\u526a\u679d\u540e\u6821\u51c6token\u8868\u793a\u7684\u5e45\u503c\uff0c\u62b5\u6d88\u526a\u679d\u5e26\u6765\u7684\u5f71\u54cd\u3002", "result": "\u5728LLaMA3.1-8B\u3001Mistral-7B-v0.3\u3001Qwen2-7B\u3001Gemma2-9B\u7b49\u591a\u79cdLLM\u4e0a\uff0c\u65b9\u6cd5\u5728\u751f\u6210\u548c\u5224\u522b\u4efb\u52a1\u768427\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u9488\u5bf9\u4f20\u7edf\u7ed3\u6784\u5316\u526a\u679d\u5ffd\u89c6\u5c42\u6b21\u7ed3\u6784\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86\u9ad8\u5c42\u6ce8\u610f\u529b\u5934\u526a\u679d\u4e0e\u89c4\u6a21\u81ea\u9002\u5e94\u91cd\u7f29\u7684\u8054\u5408\u65b9\u6cd5\uff0c\u7ecf\u5927\u89c4\u6a21\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u65b9\u6cd5\u5728\u591a\u4efb\u52a1\u548c\u591a\u6a21\u578b\u4e0a\u5747\u6709\u4f18\u8d8a\u8868\u73b0\u3002"}}
{"id": "2507.01903", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.01903", "abs": "https://arxiv.org/abs/2507.01903", "authors": ["Qiguang Chen", "Mingda Yang", "Libo Qin", "Jinhao Liu", "Zheng Yan", "Jiannan Guan", "Dengyun Peng", "Yiyan Ji", "Hanjing Li", "Mengkang Hu", "Yimeng Zhang", "Yihao Liang", "Yuhang Zhou", "Jiaqi Wang", "Zhi Chen", "Wanxiang Che"], "title": "AI4Research: A Survey of Artificial Intelligence for Scientific Research", "comment": "Preprint", "summary": "Recent advancements in artificial intelligence (AI), particularly in large\nlanguage models (LLMs) such as OpenAI-o1 and DeepSeek-R1, have demonstrated\nremarkable capabilities in complex domains such as logical reasoning and\nexperimental coding. Motivated by these advancements, numerous studies have\nexplored the application of AI in the innovation process, particularly in the\ncontext of scientific research. These AI technologies primarily aim to develop\nsystems that can autonomously conduct research processes across a wide range of\nscientific disciplines. Despite these significant strides, a comprehensive\nsurvey on AI for Research (AI4Research) remains absent, which hampers our\nunderstanding and impedes further development in this field. To address this\ngap, we present a comprehensive survey and offer a unified perspective on\nAI4Research. Specifically, the main contributions of our work are as follows:\n(1) Systematic taxonomy: We first introduce a systematic taxonomy to classify\nfive mainstream tasks in AI4Research. (2) New frontiers: Then, we identify key\nresearch gaps and highlight promising future directions, focusing on the rigor\nand scalability of automated experiments, as well as the societal impact. (3)\nAbundant applications and resources: Finally, we compile a wealth of resources,\nincluding relevant multidisciplinary applications, data corpora, and tools. We\nhope our work will provide the research community with quick access to these\nresources and stimulate innovative breakthroughs in AI4Research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u5168\u9762\u7efc\u8ff0\u4e86AI\u8f85\u52a9\u79d1\u5b66\u7814\u7a76\uff08AI4Research\uff09\u7684\u53d1\u5c55\uff0c\u68b3\u7406\u4e86\u4e3b\u8981\u4efb\u52a1\u3001\u7814\u7a76\u524d\u6cbf\u548c\u5e94\u7528\u8d44\u6e90\uff0c\u4e3a\u8be5\u9886\u57df\u540e\u7eed\u521b\u65b0\u6307\u660e\u65b9\u5411\u3002", "motivation": "\u6700\u8fd1AI\u3001\u5c24\u5176\u662f\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u903b\u8f91\u63a8\u7406\u548c\u5b9e\u9a8c\u7f16\u7a0b\u7b49\u590d\u6742\u9886\u57df\u8868\u73b0\u5353\u8d8a\uff0c\u63a8\u52a8\u4e86\u4f17\u591a\u5173\u4e8eAI\u5728\u79d1\u7814\u521b\u65b0\u8fc7\u7a0b\u4e2d\u7684\u5e94\u7528\u63a2\u7d22\u3002\u7136\u800c\u76ee\u524d\u5c1a\u65e0\u5bf9AI4Research\u9886\u57df\u7684\u7cfb\u7edf\u7efc\u8ff0\uff0c\u8fd9\u963b\u788d\u4e86\u8be5\u9886\u57df\u7684\u6574\u4f53\u8ba4\u77e5\u548c\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002\u8be5\u8bba\u6587\u65e8\u5728\u5f25\u8865\u8be5\u7a7a\u767d\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u6587\u732e\u68b3\u7406\uff0c\u5206\u7c7b\u4e86AI4Research\u7684\u4e94\u5927\u4e3b\u6d41\u4efb\u52a1\uff0c\u5236\u5b9a\u4e86\u7cfb\u7edf\u6027\u5206\u7c7b\u6cd5\uff1b\u5206\u6790\u5f53\u524d\u7814\u7a76\u7a7a\u767d\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5f3a\u8c03\u81ea\u52a8\u5316\u5b9e\u9a8c\u7684\u4e25\u8c28\u6027\u3001\u53ef\u6269\u5c55\u6027\u53ca\u793e\u4f1a\u5f71\u54cd\uff1b\u5e76\u6574\u5408\u548c\u6c47\u603b\u4e86\u5e94\u7528\u3001\u6570\u636e\u548c\u5de5\u5177\u7b49\u4e30\u5bcc\u8d44\u6e90\u3002", "result": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u68b3\u7406\u4e86AI4Research\u9886\u57df\uff0c\u603b\u7ed3\u4e86\u76f8\u5173\u4efb\u52a1\u3001\u672a\u6765\u524d\u6cbf\u4ee5\u53ca\u4f17\u591a\u8de8\u5b66\u79d1\u5e94\u7528\u8d44\u6e90\uff0c\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u548c\u65b9\u5411\u3002", "conclusion": "\u672c\u7efc\u8ff0\u4e3aAI4Research\u9886\u57df\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7cfb\u7edf\u89c6\u89d2\u548c\u4e30\u5bcc\u8d44\u6e90\uff0c\u6709\u52a9\u4e8e\u5feb\u901f\u4e86\u89e3\u73b0\u72b6\u3001\u53d1\u73b0\u6311\u6218\u5e76\u4fc3\u8fdb\u521b\u65b0\u7a81\u7834\u3002"}}
{"id": "2507.01915", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.01915", "abs": "https://arxiv.org/abs/2507.01915", "authors": ["Chengao Li", "Hanyu Zhang", "Yunkun Xu", "Hongyan Xue", "Xiang Ao", "Qing He"], "title": "Gradient-Adaptive Policy Optimization: Towards Multi-Objective Alignment of Large Language Models", "comment": "19 pages, 3 figures. Accepted by ACL 2025 (main)", "summary": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a powerful\ntechnique for aligning large language models (LLMs) with human preferences.\nHowever, effectively aligning LLMs with diverse human preferences remains a\nsignificant challenge, particularly when they are conflict. To address this\nissue, we frame human value alignment as a multi-objective optimization\nproblem, aiming to maximize a set of potentially conflicting objectives. We\nintroduce Gradient-Adaptive Policy Optimization (GAPO), a novel fine-tuning\nparadigm that employs multiple-gradient descent to align LLMs with diverse\npreference distributions. GAPO adaptively rescales the gradients for each\nobjective to determine an update direction that optimally balances the\ntrade-offs between objectives. Additionally, we introduce P-GAPO, which\nincorporates user preferences across different objectives and achieves Pareto\nsolutions that better align with the user's specific needs. Our theoretical\nanalysis demonstrates that GAPO converges towards a Pareto optimal solution for\nmultiple objectives. Empirical results on Mistral-7B show that GAPO outperforms\ncurrent state-of-the-art methods, achieving superior performance in both\nhelpfulness and harmlessness.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u4e86GAPO\u65b9\u6cd5\uff0c\u5c06LLM\u5bf9\u9f50\u5efa\u6a21\u4e3a\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u7528\u81ea\u9002\u5e94\u68af\u5ea6\u65b9\u6848\u6709\u6548\u5e94\u5bf9\u504f\u597d\u51b2\u7a81\uff1b\u5b9e\u9a8c\u548c\u7406\u8bba\u5747\u8bc1\u660eGAPO\u4f18\u4e8e\u4e3b\u6d41\u65b9\u6cd5\uff0c\u80fd\u66f4\u597d\u6ee1\u8db3\u7528\u6237\u591a\u6837\u5316\u9700\u6c42\u3002", "motivation": "\u76ee\u524d\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u9700\u8981\u5bf9\u9f50\u591a\u6837\u5316\u7684\u4eba\u7c7b\u504f\u597d\uff0c\u4f46\u5f53\u8fd9\u4e9b\u504f\u597d\u76f8\u4e92\u51b2\u7a81\u65f6\uff0c\u5bf9\u9f50\u53d8\u5f97\u6781\u5177\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u6ee1\u8db3\u6240\u6709\u591a\u6837\u6027\u9700\u6c42\u3002", "method": "\u4f5c\u8005\u5c06\u4eba\u7c7b\u4ef7\u503c\u5bf9\u9f50\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684fine-tuning\u8303\u5f0f\u2014\u2014\u68af\u5ea6\u81ea\u9002\u5e94\u7b56\u7565\u4f18\u5316(GAPO)\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u591a\u68af\u5ea6\u4e0b\u964d\u81ea\u9002\u5e94\u8c03\u6574\u6bcf\u4e2a\u76ee\u6807\u7684\u68af\u5ea6\uff0c\u5b9e\u73b0\u591a\u76ee\u6807\u95f4\u7684\u5e73\u8861\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86P-GAPO\u65b9\u6cd5\uff0c\u8fdb\u4e00\u6b65\u7ed3\u5408\u7528\u6237\u5bf9\u4e0d\u540c\u76ee\u6807\u7684\u7279\u5b9a\u504f\u597d\uff0c\u83b7\u5f97\u66f4\u8d34\u5408\u7528\u6237\u9700\u6c42\u7684Pareto\u6700\u4f18\u89e3\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0cGAPO\u53ef\u6536\u655b\u5230\u591a\u76ee\u6807\u4e0b\u7684Pareto\u6700\u4f18\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728Mistral-7B\u6a21\u578b\u4e0a\uff0cGAPO\u5728\u6709\u76ca\u6027(helpfulness)\u548c\u65e0\u5bb3\u6027(harmlessness)\u4e24\u4e2a\u6307\u6807\u4e0a\u5747\u8d85\u8fc7\u5f53\u524d\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "GAPO\u53ca\u5176\u53d8\u4f53P-GAPO\u80fd\u6709\u6548\u5b9e\u73b0\u5bf9\u51b2\u7a81\u6027\u4eba\u7c7b\u504f\u597d\u76ee\u6807\u7684\u5e73\u8861\u5bf9\u9f50\uff0c\u5e76\u5728\u5927\u6a21\u578b\u5fae\u8c03\u4e2d\u4f18\u4e8e\u73b0\u6709\u591a\u76ee\u6807\u5bf9\u9f50\u65b9\u6cd5\u3002"}}
{"id": "2507.01921", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01921", "abs": "https://arxiv.org/abs/2507.01921", "authors": ["Yang Li", "Youssef Emad", "Karthik Padthe", "Jack Lanchantin", "Weizhe Yuan", "Thao Nguyen", "Jason Weston", "Shang-Wen Li", "Dong Wang", "Ilia Kulikov", "Xian Li"], "title": "NaturalThoughts: Selecting and Distilling Reasoning Traces for General Reasoning Tasks", "comment": null, "summary": "Recent work has shown that distilling reasoning traces from a larger teacher\nmodel via supervised finetuning outperforms reinforcement learning with the\nsmaller student model alone (Guo et al. 2025). However, there has not been a\nsystematic study of what kind of reasoning demonstrations from the teacher are\nmost effective in improving the student model's reasoning capabilities. In this\nwork we curate high-quality \"NaturalThoughts\" by selecting reasoning traces\nfrom a strong teacher model based on a large pool of questions from\nNaturalReasoning (Yuan et al. 2025). We first conduct a systematic analysis of\nfactors that affect distilling reasoning capabilities, in terms of sample\nefficiency and scalability for general reasoning tasks. We observe that simply\nscaling up data size with random sampling is a strong baseline with steady\nperformance gains. Further, we find that selecting difficult examples that\nrequire more diverse reasoning strategies is more sample-efficient to transfer\nthe teacher model's reasoning skills. Evaluated on both Llama and Qwen models,\ntraining with NaturalThoughts outperforms existing reasoning datasets such as\nOpenThoughts, LIMO, etc. on general STEM reasoning benchmarks including\nGPQA-Diamond, MMLU-Pro and SuperGPQA.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u7cfb\u7edf\u6027\u7b5b\u9009\u9ad8\u8d28\u91cf\u3001\u96be\u5ea6\u66f4\u9ad8\u7684\u6559\u5e08\u63a8\u7406\u8f68\u8ff9\u6784\u5efa\u6570\u636e\u96c6\uff0c\u5e76\u9a8c\u8bc1\u8fd9\u79cd\u65b9\u5f0f\u6bd4\u5355\u7eaf\u6269\u589e\u6837\u672c\u91cf\u6216\u7528\u73b0\u6709\u6570\u636e\u96c6\u63d0\u5347\u5b66\u751f\u63a8\u7406\u80fd\u529b\u66f4\u6709\u6548\u3002", "motivation": "\u4e4b\u524d\u7684\u7814\u7a76\u5df2\u7ecf\u8bc1\u660e\uff0c\u901a\u8fc7\u6709\u76d1\u7763\u5fae\u8c03\u4ece\u5927\u578b\u6559\u5e08\u6a21\u578b\u4e2d\u63d0\u70bc\u63a8\u7406\u8fc7\u7a0b\uff0c\u6bd4\u5b66\u751f\u6a21\u578b\u5355\u72ec\u7528\u5f3a\u5316\u5b66\u4e60\u8868\u73b0\u5f97\u66f4\u597d\uff0c\u4f46\u76ee\u524d\u5c1a\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7814\u7a76\u6765\u5224\u65ad\uff1a\u4ec0\u4e48\u6837\u7684\u6559\u5e08\u63a8\u7406\u6f14\u793a\u6700\u80fd\u63d0\u5347\u5b66\u751f\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u4ece\u5f3a\u5927\u7684\u6559\u5e08\u6a21\u578b\u51fa\u53d1\uff0c\u57fa\u4e8e\u5927\u89c4\u6a21\u95ee\u9898\u6c60\uff08\u6765\u81eaNaturalReasoning\uff09\u7b5b\u9009\u51fa\u9ad8\u8d28\u91cf\u63a8\u7406\u8f68\u8ff9\uff0c\u6784\u5efa\u4e86\u201cNaturalThoughts\u201d\u6570\u636e\u96c6\u3002\u5bf9\u8fd9\u4e9b\u63a8\u7406\u6837\u672c\u5728\u63d0\u5347\u5b66\u751f\u6a21\u578b\u63a8\u7406\u80fd\u529b\u65b9\u9762\u8fdb\u884c\u4e86\u7cfb\u7edf\u5206\u6790\uff0c\u8003\u5bdf\u6570\u636e\u91cf\u6269\u5c55\u53ca\u96be\u4f8b\u9009\u62e9\u7b49\u56e0\u7d20\u5bf9\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u968f\u673a\u6269\u589e\u6570\u636e\u5927\u5c0f\u662f\u4e00\u4e2a\u5f3a\u57fa\u7ebf\u4e14\u53ef\u6301\u7eed\u63d0\u5347\u6548\u679c\u3002\u8fdb\u4e00\u6b65\u9009\u53d6\u96be\u5ea6\u8f83\u5927\u3001\u9700\u591a\u6837\u5316\u63a8\u7406\u7b56\u7565\u7684\u95ee\u9898\u5bf9\u63a8\u7406\u77e5\u8bc6\u8fc1\u79fb\u66f4\u9ad8\u6548\u3002\u57fa\u4e8eNaturalThoughts\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u5728STEM\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u6570\u636e\u96c6\uff08\u5982OpenThoughts\u3001LIMO\u7b49\uff09\uff0c\u9002\u7528\u4e8eLlama\u3001Qwen\u7b49\u6a21\u578b\u3002", "conclusion": "\u7cfb\u7edf\u7b5b\u9009\u9ad8\u8d28\u91cf\u3001\u8986\u76d6\u591a\u6837\u5316\u63a8\u7406\u65b9\u5f0f\u7684\u6559\u5e08\u63a8\u7406\u6837\u672c\uff0c\u5e76\u4f18\u5148\u96be\u4f8b\uff0c\u6709\u52a9\u4e8e\u66f4\u9ad8\u6548\u5730\u63d0\u5347\u5b66\u751f\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f18\u4e8e\u4f20\u7edf\u968f\u673a\u91c7\u6837\u6216\u73b0\u6709\u516c\u5f00\u6570\u636e\u96c6\u3002"}}
{"id": "2507.01923", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.01923", "abs": "https://arxiv.org/abs/2507.01923", "authors": ["Yu-Shiang Huang", "Chuan-Ju Wang", "Chung-Chi Chen"], "title": "Decision-oriented Text Evaluation", "comment": null, "summary": "Natural language generation (NLG) is increasingly deployed in high-stakes\ndomains, yet common intrinsic evaluation methods, such as n-gram overlap or\nsentence plausibility, weakly correlate with actual decision-making efficacy.\nWe propose a decision-oriented framework for evaluating generated text by\ndirectly measuring its influence on human and large language model (LLM)\ndecision outcomes. Using market digest texts--including objective morning\nsummaries and subjective closing-bell analyses--as test cases, we assess\ndecision quality based on the financial performance of trades executed by human\ninvestors and autonomous LLM agents informed exclusively by these texts. Our\nfindings reveal that neither humans nor LLM agents consistently surpass random\nperformance when relying solely on summaries. However, richer analytical\ncommentaries enable collaborative human-LLM teams to outperform individual\nhuman or agent baselines significantly. Our approach underscores the importance\nof evaluating generated text by its ability to facilitate synergistic\ndecision-making between humans and LLMs, highlighting critical limitations of\ntraditional intrinsic metrics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u5b9e\u9645\u51b3\u7b56\u7ed3\u679c\uff08\u5982\u91d1\u878d\u4ea4\u6613\u6536\u76ca\uff09\u76f4\u63a5\u8bc4\u4f30\u81ea\u7136\u8bed\u8a00\u751f\u6210\u5185\u5bb9\uff0c\u53d1\u73b0\u4e30\u5bcc\u7684\u5206\u6790\u6027\u6587\u672c\u80fd\u63d0\u5347\u4eba\u673a\u534f\u4f5c\u51b3\u7b56\u6548\u80fd\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u8bc4\u4ef7\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u81ea\u7136\u8bed\u8a00\u751f\u6210\uff08NLG\uff09\u88ab\u5e94\u7528\u4e8e\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u4f46\u4e3b\u6d41\u7684\u5185\u5728\u8bc4\u4ef7\u65b9\u6cd5\uff08\u5982n-gram\u91cd\u53e0\u4e0e\u53e5\u5b50\u53ef\u7136\u6027\uff09\u4e0e\u5b9e\u9645\u51b3\u7b56\u6548\u80fd\u76f8\u5173\u6027\u8f83\u5f31\u3002\u8be5\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u51b3\u7b56\u5bfc\u5411\u7684\u65b9\u5f0f\u91cd\u65b0\u5ba1\u89c6NLG\u7684\u6548\u7528\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u51b3\u7b56\u5bfc\u5411\u7684\u751f\u6210\u6587\u672c\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u5e02\u573a\u6458\u8981\u6587\u672c\uff08\u5305\u62ec\u5ba2\u89c2\u7684\u6668\u95f4\u6458\u8981\u548c\u4e3b\u89c2\u7684\u6536\u76d8\u5206\u6790\uff09\u4f5c\u4e3a\u6848\u4f8b\uff0c\u5206\u522b\u8003\u5bdf\u4e86\u4ec5\u4f9d\u8d56\u8fd9\u4e9b\u6587\u672c\u65f6\uff0c\u4eba\u7c7b\u6295\u8d44\u8005\u4e0e\u81ea\u4e3bLLM\u6295\u8d44\u4ee3\u7406\u7684\u4ea4\u6613\u51b3\u7b56\u8868\u73b0\uff0c\u5e76\u901a\u8fc7\u91d1\u878d\u6536\u76ca\u6765\u8861\u91cf\u51b3\u7b56\u8d28\u91cf\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u65e0\u8bba\u4eba\u7c7b\u8fd8\u662fLLM\u4ee3\u7406\uff0c\u4ec5\u4f9d\u8d56\u5e02\u573a\u6458\u8981\u90fd\u96be\u4ee5\u8d85\u8d8a\u968f\u673a\u8868\u73b0\u3002\u800c\u5305\u542b\u66f4\u4e30\u5bcc\u5206\u6790\u6027\u5185\u5bb9\u7684\u8bc4\u8bba\u80fd\u591f\u4f7f\u4eba\u7c7b-LLM\u534f\u4f5c\u660e\u663e\u4f18\u4e8e\u5355\u72ec\u7684\u4e2a\u4f53\u6216\u4ee3\u7406\u3002", "conclusion": "\u7ed3\u679c\u7a81\u663e\u4e86\u8bc4\u4f30\u751f\u6210\u6587\u672c\u65f6\u5355\u7eaf\u4f9d\u8d56\u4f20\u7edf\u5185\u5728\u6307\u6807\u7684\u5c40\u9650\u6027\uff0c\u5f3a\u5316\u4e86\u4ee5\u4fc3\u8fdb\u4eba\u7c7b\u548cLLM\u534f\u4f5c\u6027\u51b3\u7b56\u4e3a\u6838\u5fc3\u7684\u65b0\u8bc4\u4ef7\u8303\u5f0f\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.01931", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.01931", "abs": "https://arxiv.org/abs/2507.01931", "authors": ["Md Sazzadul Islam Ridoy", "Sumi Akter", "Md. Aminur Rahman"], "title": "Adaptability of ASR Models on Low-Resource Language: A Comparative Study of Whisper and Wav2Vec-BERT on Bangla", "comment": null, "summary": "In recent years, neural models trained on large multilingual text and speech\ndatasets have shown great potential for supporting low-resource languages. This\nstudy investigates the performances of two state-of-the-art Automatic Speech\nRecognition (ASR) models, OpenAI's Whisper (Small & Large-V2) and Facebook's\nWav2Vec-BERT on Bangla, a low-resource language. We have conducted experiments\nusing two publicly available datasets: Mozilla Common Voice-17 and OpenSLR to\nevaluate model performances. Through systematic fine-tuning and hyperparameter\noptimization, including learning rate, epochs, and model checkpoint selection,\nwe have compared the models based on Word Error Rate (WER), Character Error\nRate (CER), Training Time, and Computational Efficiency. The Wav2Vec-BERT model\noutperformed Whisper across all key evaluation metrics, demonstrated superior\nperformance while requiring fewer computational resources, and offered valuable\ninsights to develop robust speech recognition systems in low-resource\nlinguistic settings.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86Whisper\u4e0eWav2Vec-BERT\u6a21\u578b\u5728\u5b5f\u52a0\u62c9\u8bed\u8bed\u97f3\u8bc6\u522b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u7ed3\u679c\u663e\u793aWav2Vec-BERT\u5728\u51c6\u786e\u7387\u548c\u6548\u7387\u4e0a\u5747\u80dc\u4e00\u7b79\uff0c\u9002\u5408\u4f4e\u8d44\u6e90\u8bed\u8a00\u5e94\u7528\u3002", "motivation": "\u91c7\u7528\u5927\u89c4\u6a21\u591a\u8bed\u79cd\u6587\u672c\u548c\u8bed\u97f3\u6570\u636e\u8bad\u7ec3\u7684\u795e\u7ecf\u6a21\u578b\uff0c\u5728\u652f\u6301\u4f4e\u8d44\u6e90\u8bed\u8a00\u65b9\u9762\u663e\u793a\u51fa\u5de8\u5927\u6f5c\u529b\u3002\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u4e1a\u754c\u9886\u5148\u7684ASR\u6a21\u578b\u5728\u5b5f\u52a0\u62c9\u8bed\uff08\u4e00\u79cd\u4f4e\u8d44\u6e90\u8bed\u8a00\uff09\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u5206\u522b\u5e94\u7528OpenAI\u7684Whisper\uff08Small & Large-V2\uff09\u4e0eFacebook\u7684Wav2Vec-BERT\uff0c\u5728Mozilla Common Voice-17 \u548c OpenSLR\u4e24\u5927\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002\u901a\u8fc7\u7cfb\u7edf\u6027\u5fae\u8c03\u548c\u8d85\u53c2\u6570\u4f18\u5316\uff08\u5982\u5b66\u4e60\u7387\u3001\u8f6e\u6b21\u3001\u6a21\u578b\u68c0\u67e5\u70b9\u9009\u62e9\uff09\uff0c\u5e76\u4ee5\u8bcd\u9519\u8bef\u7387\uff08WER\uff09\u3001\u5b57\u9519\u8bef\u7387\uff08CER\uff09\u3001\u8bad\u7ec3\u65f6\u95f4\u548c\u8ba1\u7b97\u6548\u7387\u4e3a\u8bc4\u4f30\u6807\u51c6\uff0c\u6bd4\u8f83\u6a21\u578b\u6027\u80fd\u3002", "result": "Wav2Vec-BERT\u5728\u6240\u6709\u5173\u952e\u8bc4\u4f30\u6307\u6807\u4e0a\u5747\u4f18\u4e8eWhisper\u6a21\u578b\uff0c\u4e0d\u4ec5\u8868\u73b0\u66f4\u4f18\uff0c\u8fd8\u9700\u8981\u66f4\u5c11\u7684\u8ba1\u7b97\u8d44\u6e90\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cWav2Vec-BERT\u975e\u5e38\u9002\u5408\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0b\u7684\u8bed\u97f3\u8bc6\u522b\u4efb\u52a1\uff0c\u4e3a\u76f8\u5173\u7cfb\u7edf\u5efa\u8bbe\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002"}}
{"id": "2507.01936", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.01936", "abs": "https://arxiv.org/abs/2507.01936", "authors": ["Adrian de Wynter", "Tangming Yuan"], "title": "The Thin Line Between Comprehension and Persuasion in LLMs", "comment": null, "summary": "Large language models (LLMs) are excellent at maintaining high-level,\nconvincing dialogues. They are being fast deployed as chatbots and evaluators\nin sensitive areas, such as peer review and mental health applications. This,\nalong with the disparate accounts on their reasoning capabilities, calls for a\ncloser examination of LLMs and their comprehension of dialogue. In this work we\nbegin by evaluating LLMs' ability to maintain a debate--one of the purest yet\nmost complex forms of human communication. Then we measure how this capability\nrelates to their understanding of what is being talked about, namely, their\ncomprehension of dialogical structures and the pragmatic context. We find that\nLLMs are capable of maintaining coherent, persuasive debates, often swaying the\nbeliefs of participants and audiences alike. We also note that awareness or\nsuspicion of AI involvement encourage people to be more critical of the\narguments made. When polling LLMs on their comprehension of deeper structures\nof dialogue, however, they cannot demonstrate said understanding. Our findings\ntie the shortcomings of LLMs-as-evaluators to their (in)ability to understand\nthe context. More broadly, for the field of argumentation theory we posit that,\nif an agent can convincingly maintain a dialogue, it is not necessary for it to\nknow what it is talking about. Hence, the modelling of pragmatic context and\ncoherence are secondary to effectiveness.", "AI": {"tldr": "LLMs\u867d\u80fd\u6709\u6548\u5f62\u6210\u6709\u8bf4\u670d\u529b\u7684\u5bf9\u8bdd\uff0c\u4f46\u5e76\u4e0d\u771f\u6b63\u7406\u89e3\u5bf9\u8bdd\u7684\u6df1\u5c42\u7ed3\u6784\u548c\u8bed\u5883\uff0c\u8fd9\u53cd\u6620\u51fa\u5176\u5728\u5145\u5f53\u5bf9\u8bdd\u8bc4\u4f30\u8005\u65f6\u5b58\u5728\u91cd\u8981\u5c40\u9650\u6027\u3002", "motivation": "LLMs\u88ab\u5e7f\u6cdb\u7528\u4e8e\u5bf9\u8bdd\u7c7b\u654f\u611f\u9886\u57df\uff08\u5982\u540c\u884c\u8bc4\u5ba1\u3001\u5fc3\u7406\u5065\u5eb7\uff09\uff0c\u4f46\u5176\u63a8\u7406\u548c\u7406\u89e3\u80fd\u529b\u5b58\u5728\u4e89\u8bae\uff0c\u56e0\u6b64\u9700\u8981\u6df1\u5165\u68c0\u9a8c\u5176\u5bf9\u5bf9\u8bdd\u7684\u7406\u89e3\u80fd\u529b\u3002\u8fa9\u8bba\u4f5c\u4e3a\u590d\u6742\u7684\u4eba\u7c7b\u4e92\u52a8\u5f62\u5f0f\uff0c\u662f\u68c0\u9a8cLLMs\u5bf9\u8bdd\u7406\u89e3\u7684\u7406\u60f3\u573a\u666f\u3002", "method": "\u9996\u5148\u8bc4\u4f30LLMs\u7ef4\u6301\u8fa9\u8bba\u7684\u80fd\u529b\uff0c\u7136\u540e\u6d4b\u91cf\u5176\u5bf9\u8bdd\u5185\u5bb9\u7406\u89e3\u80fd\u529b\uff08\u5bf9\u8bdd\u7ed3\u6784\u548c\u8bed\u7528\u8bed\u5883\u7684\u7406\u89e3\uff09\u3002\u5bf9LLMs\u548c\u4eba\u7c7b\u4e4b\u95f4\u7684\u4e92\u52a8\u8fdb\u884c\u5b9e\u8bc1\u6d4b\u8bd5\uff0c\u5305\u62ec\u8fa9\u8bba\u8868\u73b0\u53ca\u5176\u5bf9\u4ed6\u4eba\u7684\u5f71\u54cd\u3002\u540c\u65f6\u8fd8\u8ba9LLMs\u81ea\u8bc4\u5176\u5bf9\u5bf9\u8bdd\u6df1\u5c42\u7ed3\u6784\u7684\u7406\u89e3\u3002", "result": "LLMs\u80fd\u7ef4\u62a4\u8fde\u8d2f\u3001\u5177\u6709\u8bf4\u670d\u529b\u7684\u8fa9\u8bba\uff0c\u7ecf\u5e38\u80fd\u591f\u5f71\u54cd\u53c2\u4e0e\u8005\u548c\u542c\u4f17\u7684\u4fe1\u5ff5\u3002\u5f53\u4eba\u4eec\u6000\u7591\u5bf9\u65b9\u662fAI\u65f6\uff0c\u4f1a\u66f4\u6279\u5224\u5176\u8bba\u70b9\u3002\u4f46LLMs\u5bf9\u5bf9\u8bdd\u6df1\u5c42\u7ed3\u6784\u7684\u7406\u89e3\u8868\u73b0\u4e0d\u8db3\uff0c\u8bf4\u660e\u4f5c\u4e3a\u8bc4\u4f30\u8005\u5b83\u4eec\u6709\u5c40\u9650\u6027\u3002", "conclusion": "LLMs\u867d\u7136\u80fd\u8fdb\u884c\u6709\u8bf4\u670d\u529b\u7684\u8fa9\u8bba\uff0c\u4f46\u5b83\u4eec\u672a\u5fc5\u771f\u6b63\u7406\u89e3\u5bf9\u8bdd\u7684\u7ed3\u6784\u548c\u8bed\u5883\u3002\u53ea\u8981\u80fd\u7ef4\u6301\u5bf9\u8bdd\u5e76\u4ee4\u4eba\u4fe1\u670d\uff0c\u7406\u89e3\u8bed\u5883\u548c\u8fde\u8d2f\u6027\u7684\u91cd\u8981\u6027\u5219\u662f\u6b21\u8981\u7684\u3002"}}
