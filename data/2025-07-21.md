<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]
- [cs.SE](#cs.SE) [Total: 5]
- [cs.LO](#cs.LO) [Total: 4]
- [cs.CL](#cs.CL) [Total: 44]
- [cs.FL](#cs.FL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Random Variate Generation with Formal Guarantees](https://arxiv.org/abs/2507.13494)
*Feras A. Saad,Wonyeol Lee*

Main category: cs.PL

TL;DR: 提出了针对任意二进制数值格式分布的随机变量全自动生成方法，理论精度有保证，优于现有主流库，在数学和工程实践上均十分有用。


<details>
  <summary>Details</summary>
Motivation: 在统计分析、仿真等领域，随机变量生成是基础环节。传统生成器通常受限于浮点精度、溢出风险或需要高昂的计算开销，而且缺乏形式化的准确性保证。该论文希望提出一种自动化且具备形式化精度保障的新框架，解决现有方法的问题。

Method: 作者提出了一个通用且全自动的方法，通过将概率分布的累积分布函数（CDF）以有限精度数值程序形式描述，再以该CDF为准生成精确的随机变量。针对任何用二进制数表示的数值格式（如浮点、定点或posit），都能自动合成生成器。该方法避免了溢出和高开销的任意精度计算，具有统一接口，并在理论上达到Knuth-Yao信息熵率最优，即每个输出变量消耗的随机比特数最少。

Result: 作者在C语言实现了这一生成库，并测试了多种连续与离散分布。实验结果表明，该方法在精度、熵效率和自动化方面优于GNU Scientific Library，并且运行时具有竞争力。

Conclusion: 该方法为有限精度下的概率分布随机生成提供了形式化保障和实际可用性，可广泛用于科学计算与工程应用，对现有随机生成机制作出了理论和实践上的重要改进。

Abstract: This article introduces a new approach to principled and practical random
variate generation with formal guarantees. The key idea is to first specify the
desired probability distribution in terms of a finite-precision numerical
program that defines its cumulative distribution function (CDF), and then
generate exact random variates according to this CDF. We present a universal
and fully automated method to synthesize exact random variate generators given
any numerical CDF implemented in any binary number format, such as
floating-point, fixed-point, and posits. The method is guaranteed to operate
with the same precision used to specify the CDF, does not overflow, avoids
expensive arbitrary-precision arithmetic, and exposes a consistent API. The
method rests on a novel space-time optimal implementation for the class of
generators that attain the information-theoretically optimal Knuth and Yao
entropy rate, consuming the least possible number of input random bits per
output variate. We develop a random variate generation library using our method
in C and evaluate it on a diverse set of ``continuous'' and ``discrete''
distributions, showing competitive runtime with the state-of-the-art GNU
Scientific Library while delivering higher accuracy, entropy efficiency, and
automation.

</details>


### [2] [Increasing the Expressiveness of a Gradual Verifier](https://arxiv.org/abs/2507.13533)
*Priyam Gupta*

Main category: cs.PL

TL;DR: 论文扩展了Gradual C0，支持更易用的递归结构表达，提升了渐进式静态验证的规范能力。


<details>
  <summary>Details</summary>
Motivation: 当前Gradual C0虽可实现部分规范程序的静态验证，但规范语言表达能力有限，尤其难以优雅描述递归堆结构，影响了其实用性和直观性。

Method: 在现有Gradual C0系统基础上，设计并实现了对"unfolding expressions"的支持，并将其集成到规范语言中以表达递归结构。

Result: 扩展后的Gradual C0可支持更直观和自然描述递归堆数据结构的规范，大大增强了其表达性。

Conclusion: 本文提出并实现了Gradual C0的扩展，能够更直观地对递归堆数据结构进行规范，从而提升了部分规范程序的静态验证表达能力。

Abstract: Static verification provides strong correctness guarantees for code; however,
fully specifying programs for static verification is a complex, burdensome
process for users. Gradual verification was introduced to make this process
easier by supporting the verification of partially specified programs. The only
currently working gradual verifier, Gradual C0, successfully verifies heap
manipulating programs, but lacks expressiveness in its specification language.
This paper describes the design and implementation of an extension to Gradual
C0 that supports unfolding expressions, which allow more intuitive
specifications of recursive heap data structures.

</details>


### [3] [AdapTT: Functoriality for Dependent Type Casts](https://arxiv.org/abs/2507.13774)
*Arthur Adjedj,Meven Lennon-Bertrand,Thibaut Benjamin,Kenji Maillard*

Main category: cs.PL

TL;DR: 提出了AdapTT类型理论，通过适配器系统化地刻画类型构造子的函子性，并推导归纳类型构造子的转换定律，为类型cast提供统一结构理论基础。


<details>
  <summary>Details</summary>
Motivation: 多种依赖类型理论（如观察型类型理论、子类型、以及渐进式类型的cast calculus）中，值在相关类型间进行转换（cast）很常见。尽管这些cast看似各异，但在类型构造子的函子性（functoriality）方面具有结构上的共性。然而，这个共性尚未被系统性和精确地刻画。

Method: 本文提出并研究了一种新的类型理论AdapTT，该理论以适配器（adapter）的抽象概念为基础，系统化地将类型构造子的函子性理念应用于类型转换。具体做法是利用AdapTT中对函子型归纳类型（functorial inductive types）的描述， 推导出一般归纳类型构造子之间类型转换的结构性定律。

Result: AdapTT理论能够系统地描述类型之间由抽象适配器联系下的函子性类型构造。借此方法，推导出了适用于一般归纳类型构造子的类型转换结构定律。

Conclusion: AdapTT理论为各类依赖类型理论中的值转换提供了统一的理论基础，明确且系统地揭示了类型构造子函子性和类型转换间的深层次结构关系。

Abstract: The ability to cast values between related types is a leitmotiv of many
flavors of dependent type theory, such as observational type theories,
subtyping, or cast calculi for gradual typing. These casts all exhibit a common
structural behavior that boils down to the pervasive functoriality of type
formers. We propose and extensively study a type theory, called AdapTT, which
makes systematic and precise this idea of functorial type formers, with respect
to an abstract notion of adapters relating types. Leveraging descriptions for
functorial inductive types in AdapTT, we derive structural laws for type casts
on general inductive type formers.

</details>


### [4] [Don't exhaust, don't waste](https://arxiv.org/abs/2507.13792)
*Riccardo Bianchini,Francesco Dagnino,Paola Giannini,Elena Zucca*

Main category: cs.PL

TL;DR: 本文提出了能追踪并控制资源使用的lambda演算类型系统，理论上保障类型良好的程序执行不会导致资源耗尽或浪费，并通过先进的证明技术实现了系统健全性。


<details>
  <summary>Details</summary>
Motivation: 现有的lambda演算和类型系统通常不考虑资源的使用情况，现实中程序的资源管理（如内存、权限等）具有重要意义，因此需要对lambda演算扩展以实现对资源的精确追踪和控制。

Method: 扩展lambda演算的语义和类型系统，引入资源感知特性。具体做法是在语义层面追踪资源的使用，在资源耗尽或浪费时进入stuck状态。该系统通用、无需对底层语言作出特殊修改，并通过将语义形式化为大步语义和采用余归纳推理证明资源相关的类型系统健全性。

Result: 提出了一种通用的、参数化的资源类型系统，通过设计，无论资源用尽还是被浪费，类型系统都能保证类型良好的程序始终存在一个资源不会被耗尽或浪费的执行路径。

Conclusion: 该工作实现了资源感知lambda演算的健全类型系统，为编程语言中资源安全管理提供了理论基础，有望推动资源严格管控相关的语言设计发展。

Abstract: We extend the semantics and type system of a lambda calculus equipped with
common constructs to be resource-aware. That is, the semantics keep tracks of
the usage of resources, and is stuck, besides in case of type errors, if either
a needed resource is exhausted, or a provided resource would be wasted. In such
way, the type system guarantees, besides standard soundness, that for
well-typed programs there is a computation where no resource gets either
exhausted or wasted.
  The no-waste extension is parametric on an arbitrary grade algebra, modeling
an arbitrary assortment of possible usages, and does not require ad-hoc changes
to the underlying language. To this end, the semantics needs to be formalized
in big-step style; as a consequence, expressing and proving (resource-aware)
soundness is challenging, and is achieved by applying recent techniques based
on coinductive reasoning.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [5] [Socio-Technical Smell Dynamics in Code Samples: A Multivocal Review on Emergence, Evolution, and Co-Occurrence](https://arxiv.org/abs/2507.13481)
*Arthur Bueno,Bruno Cafeo,Maria Cagnin,Awdren Fontão*

Main category: cs.SE

TL;DR: 开源生态里的代码示例因社区失调更易技术退化，需关注社区治理和质量指标以保障可维护性。


<details>
  <summary>Details</summary>
Motivation: 在开源生态系统（OSSECO）中，代码示例对于知识传递、人员入职和框架采纳非常重要。然而，这些代码示例常常缺乏正式治理、审核有限且所有权不明，容易出现社会技术退化现象。目前关于代码味道及社区味道的研究多为单独分析，对两者的交互影响认识不足。

Method: 采用多声道文献综述（Multivocal Literature Review）方法，梳理了2013-2024年间30篇同行评审论文及17个实践者资料，通过主题综合分析代码和社区味道在OSSECO的代码示例中产生、共现和演化的模式。

Result: 识别出九种与味道动态相关的社会技术模式，发现社区味道往往先于或加剧了代码结构退化。常见症状如“无线电静默”（缺乏交流）、所有权集中等与结构异常持续存在有关。证据还表明，有限的入职、缺乏持续重构及非正式协作加剧了味道的累积问题。

Conclusion: OSSECO中，社区层面的功能失调不仅与代码可维护性下降相关，且常作为其前兆。强调需制定符合共享指导类代码示例的社会技术质量指标与轻量治理机制。

Abstract: Code samples play a pivotal role in open-source ecosystems (OSSECO), serving
as lightweight artifacts that support knowledge transfer, onboarding, and
framework adoption. Despite their instructional relevance, these samples are
often governed informally, with minimal review and unclear ownership, which
increases their exposure to socio-technical degradation. In this context, the
co-occurrence and longitudinal interplay of code smells (e.g., large classes,
poor modularity) and community smells (e.g., lone contributors, fragmented
communication) become particularly critical. While each type of smell has been
studied in isolation, little is known about how community-level dysfunctions
anticipate or exacerbate technical anomalies in code samples over time. This
study investigates how code and community smells emerge, co-occur, and evolve
within code samples maintained in OSSECOs. A Multivocal Literature Review
protocol was applied, encompassing 30 peer-reviewed papers and 17
practitioner-oriented sources (2013-2024). Thematic synthesis was conducted to
identify recurring socio-technical patterns related to smell dynamics. Nine
patterns were identified, showing that community smells often precede or
reinforce technical degradation in code samples. Symptoms such as "radio
silence" and centralized ownership were frequently associated with persistent
structural anomalies. Additionally, limited onboarding, the absence of
continuous refactoring, and informal collaboration emerged as recurring
conditions for smell accumulation. Conclusion: In OSSECOs, particularly within
code samples, community-level dysfunctions not only correlate with but often
signal maintainability decay. These findings underscore the need for
socio-technical quality indicators and lightweight governance mechanisms
tailored to shared instructional artifacts.

</details>


### [6] [AI-Assisted Fixes to Code Review Comments at Scale](https://arxiv.org/abs/2507.13499)
*Chandra Maddila,Negar Ghorbani,James Saindon,Parth Thakkar,Vijayaraghavan Murali,Rui Abreu,Jingyue Shen,Brian Zhou,Nachiappan Nagappan,Peter C. Rigby*

Main category: cs.SE

TL;DR: Meta针对大规模代码审查开发了AI辅助工具，通过自研Llama模型和严格的安全性测试，在不影响效率的情况下实现补丁建议效果优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: Meta在每周需要处理数以万计的代码审查评论，因此希望通过AI辅助，提升处理评论的效率和质量。

Method: 团队开发了内部基准数据集（包含6.4万个<审查评论，补丁>样本），用于对Llama模型微调。模型离线效果理想后，通过随机对照安全性试验和全面生产实验，将模型部署到线上以协助代码审查。评估了GPT-4o和自研大小Llama模型的离线表现；上线试验时通过调整UX，优化AI辅助方式，确保不影响审查效率。

Result: 离线评测中，大型Llama模型（LargeLSFT）生成的补丁与标准补丁精确匹配率为68%，比GPT-4o高9个百分点。安全性试验发现AI补丁直接展现给审查者导致平均审查用时增加5%，调整为只展示给代码作者后，审查时长不再回归。最终落地生产时，LargeLSFT的ActionableToApplied（建议被实际采用）比率达19.7%，比GPT-4o高9.2个百分点。

Conclusion: 通过精细的内部基准和安全性试验，Meta成功部署了高效且安全的AI辅助代码审查系统，在不降低审查效率的前提下显著提高建议补丁的质量和应用率。

Abstract: Aim. There are 10s of thousands of code review comments each week at Meta. We
developed Metamate for Code Review (MetaMateCR) that provides AI-assisted fixes
for reviewer comments in production at scale.
  Method. We developed an internal benchmark of 64k <review comment, patch>
data points to fine-tune Llama models. Once our models achieve reasonable
offline results, we roll them into production. To ensure that our AI-assisted
fixes do not negatively impact the time it takes to do code reviews, we conduct
randomized controlled safety trials as well as full production experiments.
  Offline Results. As a baseline, we compare GPT-4o to our small and large
Llama models. In offline results, our LargeLSFT model creates an exact match
patch 68% of the time outperforming GPT-4o by 9 percentage points (pp). The
internal models also use more modern Hack functions when compared to the PHP
functions suggested by GPT-4o.
  Safety Trial. When we roll MetaMateCR into production in a safety trial that
compares no AI patches with AI patch suggestions, we see a large regression
with reviewers taking over 5% longer to conduct reviews. After investigation,
we modify the UX to only show authors the AI patches, and see no regressions in
the time for reviews.
  Production. When we roll LargeLSFT into production, we see an
ActionableToApplied rate of 19.7%, which is a 9.2pp improvement over GPT-4o.
Our results illustrate the importance of safety trials in ensuring that AI does
not inadvertently slow down engineers, and a successful review comment to AI
patch product running at scale.

</details>


### [7] [Towards Better Requirements from the Crowd: Developer Engagement with Feature Requests in Open Source Software](https://arxiv.org/abs/2507.13553)
*Pragyan K C,Rambod Ghandiparsi,Thomas Herron,John Heaps,Mitra Bokaei Hosseini*

Main category: cs.SE

TL;DR: 开源软件开发中，功能请求常常存在歧义和信息不全，但开发者鲜少主动澄清，主要关注与项目目标一致。该研究总结了沟通过程中的模式，可为改进用户-开发者协作提供建议。


<details>
  <summary>Details</summary>
Motivation: 随着用户需求的变化，有效地采纳功能请求对软件保持相关性和用户满意度至关重要。然而，用户用自然语言表达请求时常常带有歧义或不完整信息，这可能导致开发者误解和软件质量下降，因此需要研究开发者实际是如何处理这些模糊和不完整请求的。

Method: 本研究通过分析开源软件（OSS）中的功能请求，考察其自然语言缺陷（歧义或信息不完整）和澄清对话动态，旨在揭示开发者在处理模糊功能请求时的实际行为和模式。

Result: 研究发现：1)开源平台上的功能请求广泛存在歧义和不完整性，部分请求二者兼有；2)开发者很少主动进行明确澄清，多数关注与项目目标一致性而非具体文字的消歧；3)发生澄清时更注重目标/可行性理解，而不是技术细节。

Conclusion: 澄清对话在处理OSS功能请求缺陷中较为罕见，开发者更倾向于把重点放在项目目标一致性，通过描述澄清动态，研究总结提升用户与开发者协作、有效处理功能请求的典型模式，可为开源协作提供实践指导。

Abstract: As user demands evolve, effectively incorporating feature requests is crucial
for maintaining software relevance and user satisfaction. Feature requests,
typically expressed in natural language, often suffer from ambiguity or
incomplete information due to communication gaps or the requester's limited
technical expertise. These issues can lead to misinterpretation, faulty
implementation, and reduced software quality. While seeking clarification from
requesters is a common strategy to mitigate these risks, little is known about
how developers engage in this clarification process in practice-how they
formulate clarifying questions, seek technical or contextual details, align on
goals and use cases, or decide to close requests without attempting
clarification. This study investigates how feature requests are prone to NL
defects (i.e. ambiguous or incomplete) and the conversational dynamics of
clarification in open-source software (OSS) development, aiming to understand
how developers handle ambiguous or incomplete feature requests. Our findings
suggest that feature requests published on the OSS platforms do possess
ambiguity and incompleteness, and in some cases, both. We also find that
explicit clarification for the resolution of these defects is uncommon;
developers usually focus on aligning with project goals rather than resolving
unclear text. When clarification occurs, it emphasizes understanding user
intent/goal and feasibility, rather than technical details. By characterizing
the dynamics of clarification in open-source issue trackers, this work
identifies patterns that can improve user-developer collaboration and inform
best practices for handling feature requests effectively.

</details>


### [8] [Demystifying Feature Requests: Leveraging LLMs to Refine Feature Requests in Open-Source Software](https://arxiv.org/abs/2507.13555)
*Pragyan K C,Rambod Ghandiparsi,Thomas Herron,John Heaps,Mitra Bokaei Hosseini*

Main category: cs.SE

TL;DR: 本文提出用大语言模型自动检测和改进用户用自然语言提出的特性请求缺陷，并取得了良好效果，有效提升了开源开发中特性请求的质量和可用性。


<details>
  <summary>Details</summary>
Motivation: 随着行业对软件应用需求的激增，用户特性和改进建议以自然语言形式大量出现，而这些请求常常存在模糊、不完整等缺陷，尤其是在开源软件环境下，传统的人工验证方法非常难以大规模应用。因此，亟需自动化、高效的方法来识别和改进这些自然语言缺陷。

Method: 论文提出了一种利用大语言模型（LLMs）的方法，自动检测和改进特性请求中的自然语言缺陷（如歧义、不完整），并自动生成澄清性问题（CQs），以提升这些请求对开发者的参考价值。该方法在实际开源软件的特性请求数据上进行了验证，并与人工注释进行比较。此外，还通过访谈GitHub开发者，深入了解他们对自然语言缺陷的认知、对策及其对后续软件工程任务的影响。

Result: 方法成功在实际的开源特性请求中自动检测到自然语言缺陷，并有效生成澄清问题。对比人工标注，所提方法表现出较强的一致性，显示了自动化工具在实际开发中的应用潜力。开发者访谈提供了对缺陷影响与处置策略的实际反馈，支持方法价值。

Conclusion: 基于大语言模型的自动化检测和改进自然语言特性请求缺陷的方法具有较高有效性和实用性，能够改善开发流程，提升特性请求的开发参考价值。

Abstract: The growing popularity and widespread use of software applications (apps)
across various domains have driven rapid industry growth. Along with this
growth, fast-paced market changes have led to constantly evolving software
requirements. Such requirements are often grounded in feature requests and
enhancement suggestions, typically provided by users in natural language (NL).
However, these requests often suffer from defects such as ambiguity and
incompleteness, making them challenging to interpret. Traditional validation
methods (e.g., interviews and workshops) help clarify such defects but are
impractical in decentralized environments like open-source software (OSS),
where change requests originate from diverse users on platforms like GitHub.
This paper proposes a novel approach leveraging Large Language Models (LLMs) to
detect and refine NL defects in feature requests. Our approach automates the
identification of ambiguous and incomplete requests and generates clarification
questions (CQs) to enhance their usefulness for developers. To evaluate its
effectiveness, we apply our method to real-world OSS feature requests and
compare its performance against human annotations. In addition, we conduct
interviews with GitHub developers to gain deeper insights into their
perceptions of NL defects, the strategies they use to address these defects,
and the impact of defects on downstream software engineering (SE) tasks.

</details>


### [9] [Testing Autonomous Driving Systems -- What Really Matters and What Doesn't](https://arxiv.org/abs/2507.13661)
*Changwen Li,Joseph Sifakis,Rongjie Yan,Jian Zhang*

Main category: cs.SE

TL;DR: 本文指出现有自动驾驶系统测试方法不足，提出评估框架，发现多数测试无法有效、合理地验证系统能力，建议未来应注重系统理性和确定性，实现更可靠评测。


<details>
  <summary>Details</summary>
Motivation: 尽管自动驾驶系统（ADS）测试研究广泛，但当前测试领域依然碎片化，缺乏对现有技术手段重要性和贡献的科学性评估。本文旨在解决这一问题。

Method: 文章提出了一个测试方法评价框架，从有效性和有效验证两个维度比较已有测试方法，并在八个开源自动驾驶系统上进行实验测试和结果分析。

Result: 研究发现，大多数现有测试方法未能兼顾有效性和有效验证，常常基于无法高效、全面发现失效的标准，或无法准确评估测试属性的有效性。此外，测试的有效性和有效验证与自动驾驶系统自身的设计方式密切相关。实验证明，多数测试对象未满足理性与确定性要求。

Conclusion: 当前技术水平下，尚无法对自动驾驶系统关键属性给出充分保证。建议未来自动驾驶系统的开发需更加关注理性和确定性特性。

Abstract: Despite extensive research, the testing of autonomous driving systems (ADS)
landscape remains fragmented, and there is currently no basis for an informed
technical assessment of the importance and contribution of the current state of
the art. This paper attempts to address this problem by exploring two
complementary aspects.
  First, it proposes a framework for comparing existing test methods in terms
of their intrinsic effectiveness and validity. It shows that many methods do
not meet both of these requirements. Either because they are based on criteria
that do not allow for rapid, inexpensive, and comprehensive detection of
failures, or because the degree of validity of the properties tested cannot be
accurately estimated. In particular, it is shown that most critical test
methods do not take into account the nominal operational capabilities of
autopilots and generate scenarios that are impossible for the tested vehicles
to handle, resulting in unjustified rejections.
  Secondly, the paper shows that test effectiveness and validity are highly
dependent on how autopilots are designed: how they choose between different
control policies to perform maneuvers, as well as on the reproducibility of the
results. In fact, most test methods take for granted two principles underlying
traditional methods, but do not generally apply to ADS. We maintain that the
absence of rationality and determinacy significantly impairs the effectiveness
and validity of test methods, and provide test results on eight open
autopilots, in which most do not satisfy these properties, thereby illustrating
this fact.
  We conclude that under the current state of the art, it is impossible to
obtain strong enough guarantees for essential autopilot properties and
recommend that autopilots be developed with a view to both rationality and
determinacy.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [10] [Complexity of Abduction in Łukasiewicz Logic](https://arxiv.org/abs/2507.13847)
*Katsumi Inoue,Daniil Kozhemiachenko*

Main category: cs.LO

TL;DR: 本文以鲁卡谢维奇模糊逻辑为基础，探讨区间文字扩展下的溯因推理问题，并证明特定子理论的推理复杂度远低于全片段，为实际模糊语境下的解释任务提供了理论支撑。


<details>
  <summary>Details</summary>
Motivation: 当前关于带有真值度量的语句（如“电梯被加载”、“症状严重”等）的解释存在困难。为了能够更好地形式化这些带模糊性及不同真值程度的推理语境，作者以无限值的鲁卡谢维奇（{}ukasiewicz）模糊逻辑为基础，提出研究其溯因解释问题的需求。

Method: 作者在鲁卡谢维奇模糊逻辑的语言基础上，扩展了所谓的“区间文字”（interval literals），如$p\geq\mathbf{c}$、$p\leq\mathbf{c}$及其否定，从而表达变量取值范围。以此为基础，定义了基于该系统的溯因问题与解释，并对这些推理任务（包括解识别、解存在性、假设的相关性与必要性）进行了复杂度分析。分别探讨了全语言和仅含析取项理论的情形。

Result: 研究发现，与经典命题逻辑不同，在鲁卡谢维奇逻辑中，溯因推理任务在析取片段（即仅含析取子句的理论）中复杂度低于一般情形。详细给出了几类标准溯因推理任务在不同片段下的复杂度对比。

Conclusion: 在现代模糊逻辑背景下，作者展示了以鲁卡谢维奇模糊逻辑为基础进行溯因解释的有效性，并指出选择特定理论片段（如析取理论）可有效降低推理复杂度，为实际应用场景下的解释任务带来更高的可行性和效率。

Abstract: We explore the problem of explaining observations in contexts involving
statements with truth degrees such as `the lift is loaded', `the symptoms are
severe', etc. To formalise these contexts, we consider infinitely-valued
{\L}ukasiewicz fuzzy logic. We define and motivate the notions of abduction
problems and explanations in the language of {\L}ukasiewicz logic expanded with
`interval literals' of the form $p\geq\mathbf{c}$, $p\leq\mathbf{c}$, and their
negations that express the set of values a variable can have. We analyse the
complexity of standard abductive reasoning tasks (solution recognition,
solution existence, and relevance / necessity of hypotheses) in {\L}ukasiewicz
logic for the case of the full language and for the case of theories containing
only disjunctive clauses and show that in contrast to classical propositional
logic, the abduction in the clausal fragment has lower complexity than in the
general case.

</details>


### [11] [Application Placement with Constraint Relaxation](https://arxiv.org/abs/2507.13895)
*Damiano Azzolini,Marco Duca,Stefano Forti,Francesco Gallo,Antonio Ielo*

Main category: cs.LO

TL;DR: 该文提出用Answer Set Programming优化多服务应用部署到云边网络的问题，能很好处理偏好和不可满足约束，实验验证其有效。


<details>
  <summary>Details</summary>
Motivation: 当前多服务应用需部署在高度分布的云边基础设施上，而如何根据不同约束高效选择计算节点属于组合优化问题。现有方法难以应对不可满足实例与偏好，因此需要更灵活的优化技术。

Method: 利用Answer Set Programming（ASP）的优化能力，对云边网络的服务部署问题进行建模与求解，能够处理功能性与非功能性约束，包括那些无法完全满足约束的情形及偏好调整。

Result: 提出的ASP方法在模拟现实网络与应用场景中实现了高效的服务部署优化，显示出比传统方法更好的问题处理能力，包括对偏好和不可满足约束的支持。

Conclusion: 通过基于Answer Set Programming的优化方法，能够有效应对云边网络中多服务应用的部署决策问题，特别是在对不可满足约束和偏好进行处理方面表现良好。实验结果显示该方法在模拟环境下具有有效性。

Abstract: Novel utility computing paradigms rely upon the deployment of multi-service
applications to pervasive and highly distributed cloud-edge infrastructure
resources. Deciding onto which computational nodes to place services in
cloud-edge networks, as per their functional and non-functional constraints,
can be formulated as a combinatorial optimisation problem. Most existing
solutions in this space are not able to deal with \emph{unsatisfiable} problem
instances, nor preferences, i.e. requirements that DevOps may agree to relax to
obtain a solution. In this article, we exploit Answer Set Programming
optimisation capabilities to tackle this problem. Experimental results in
simulated settings show that our approach is effective on lifelike networks and
applications.

</details>


### [12] [Bounded Inquisitive Logics: Sequent Calculi and Schematic Validity](https://arxiv.org/abs/2507.13946)
*Tadeusz Litak,Katsuhiko Sano*

Main category: cs.LO

TL;DR: 提出了$n$-有界谓词探询逻辑的无cut标记序列演算，分析了Casari公式有效性，揭示了推理有效性与具体规则及有界性的关系。


<details>
  <summary>Details</summary>
Motivation: 命题探询逻辑在$n$-有界近似下成立，但在谓词设定下不再成立。Ciardelli 和 Grilletti 已为每个固定n给出了$n$-有界探询逻辑的完备公理系统。本工作旨在为这些逻辑提供无cut的标记序列演算系统，并探讨其图式有效性的复杂性。

Method: 引入了针对$n$-有界探询（predicate inquisitive）逻辑的新型无cut标记序列演算系统。通过分析Casari公式在不同子逻辑及假设下的图式有效性，研究了推导过程中的有效性保证条件。

Result: 构建了$n$-有界predicate inquisitive逻辑的无cut标记序列演算，并展示：Casari公式在某弱子逻辑中原子有效，在全体逻辑中不足以图式有效，而在有限有界情况下（n有界）则可图式有效。只要推理过程中未用某特定规则，推导即可保证图式有效。

Conclusion: 首次提出了$n$-有界谓词探询逻辑的无cut标记序列演算，将图式有效性与推导规则具体联系，并揭示了有限有界条件下与全局性判断的差异。

Abstract: Propositional inquisitive logic is the limit of its $n$-bounded
approximations. In the predicate setting, however, this does not hold anymore,
as discovered by Ciardelli and Grilletti, who also found complete
axiomatizations of $n$-bounded inquisitive logics $\mathsf{InqBQ}_{n}$, for
every fixed $n$. We introduce cut-free labelled sequent calculi for these
logics. We illustrate the intricacies of \textit{schematic validity} in such
systems by showing that the well-known Casari formula is \textit{atomically}
valid in (a weak sublogic of) predicate inquisitive logic $\mathsf{InqBQ}$,
fails to be schematically valid in it, and yet is schematically valid under the
finite boundedness assumption. The derivations in our calculi, however, are
guaranteed to be schematically valid whenever a single specific rule is not
used.

</details>


### [13] [ChemLog: Making MSOL Viable for Ontological Classification and Learning](https://arxiv.org/abs/2507.13987)
*Simon Flügel,Martin Glauer,Till Mossakowski,Fabian Neuhaus*

Main category: cs.LO

TL;DR: 提出新逻辑方法解决OWL表达能力有限难以分类复杂本体类问题，并结合深度学习，显著提升化学本体分类效果。


<details>
  <summary>Details</summary>
Motivation: OWL本体在很多领域中使用广泛，但其表达能力有限，难以定义复杂本体类。作者希望突破OWL表达局限性，提高本体分类的精度和自动化。

Method: 提出使用一阶单变项（monadic second-order）逻辑对复杂本体类进行形式化定义，并将该逻辑定义应用于ChEBI本体的14个与肽相关的类别和PubChem化学数据库中的1.19亿个分子。同时，将推理出的类别作为样本训练transformer深度学习模型，以扩展分类能力。

Result: 单变项二阶逻辑方法有效支持本体中肽类相关类别的分类推理，transformer深度学习模型利用逻辑分类结果做为训练数据后，提升了对整个ChEBI本体的分类性能。

Conclusion: 逻辑方法和深度学习方法相结合，不仅突破了OWL本体表达的限制，还提高了大规模化学本体分类的自动化和准确性，对本体工程和智能分析有重要意义。

Abstract: Despite its prevalence, in many domains, OWL is not expressive enough to
define ontology classes. In this paper, we present an approach that allows to
use monadic second-order formalisations for ontology classification. As a case
study, we have applied our approach to 14 peptide-related classes from the
chemistry ontology ChEBI. For these classes, a monadic second-order logic
formalisation has been developed and applied both to ChEBI as well as to 119
million molecules from the chemistry database PubChem. While this logical
approach alone is limited to classification for the specified classes (in our
case, (sub)classes of peptides), transformer deep learning models scale
classification to the whole of the ChEBI ontology. We show that when using the
classifications obtained by the logical approach as training data, the
performance of the deep learning models can be significantly enhanced.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [14] [Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models](https://arxiv.org/abs/2507.13357)
*Atharva Bhargude,Ishan Gonehal,Chandler Haney,Dave Yoon,Kevin Zhu,Aaron Sandoval,Sean O'Brien,Kaustubh Vinnakota*

Main category: cs.CL

TL;DR: 该文提出基于大语言模型和结构化语义推理的钓鱼检测新方法，显著提升检测效果，为未来多模态智能安全系统提供参考。


<details>
  <summary>Details</summary>
Motivation: 网络钓鱼攻击是严重的网络安全威胁，需要更自适应的检测技术。现有方法在应对复杂钓鱼手法时存在局限性，尤其是对多模态和语言学特征的分析不充分。

Method: 提出了一种称为Few-shot Adaptive Linguistic Prompting（ALP）的结构化语义推理方法，结合先进大语言模型（如GPT-4o和Gemini 1.5 Pro）的多模态能力。ALP通过引导LLM分解语言模式、检测紧急信号和识别操控性用语，实现对文本、图片和URL的统一分析。

Result: ALP方法能明显提升大语言模型在网络钓鱼网页检测中的准确性，实现了0.93的F1分数，优于传统方法。

Conclusion: ALP集成多模态大语言模型，为构建更健壮、可解释和自适应的基于语言学的钓鱼检测系统奠定了基础。

Abstract: Phishing attacks represent a significant cybersecurity threat, necessitating
adaptive detection techniques. This study explores few-shot Adaptive Linguistic
Prompting (ALP) in detecting phishing webpages through the multimodal
capabilities of state-of-the-art large language models (LLMs) such as GPT-4o
and Gemini 1.5 Pro. ALP is a structured semantic reasoning method that guides
LLMs to analyze textual deception by breaking down linguistic patterns,
detecting urgency cues, and identifying manipulative diction commonly found in
phishing content. By integrating textual, visual, and URL-based analysis, we
propose a unified model capable of identifying sophisticated phishing attempts.
Our experiments demonstrate that ALP significantly enhances phishing detection
accuracy by guiding LLMs through structured reasoning and contextual analysis.
The findings highlight the potential of ALP-integrated multimodal LLMs to
advance phishing detection frameworks, achieving an F1-score of 0.93,
surpassing traditional approaches. These results establish a foundation for
more robust, interpretable, and adaptive linguistic-based phishing detection
systems using LLMs.

</details>


### [15] [Persona-Based Synthetic Data Generation Using Multi-Stage Conditioning with Large Language Models for Emotion Recognition](https://arxiv.org/abs/2507.13380)
*Keito Inoshita,Rushia Harada*

Main category: cs.CL

TL;DR: PersonaGen结合虚拟人格与大语言模型，生成高质量情感文本，优于传统方法，有望解决情感识别领域数据瓶颈。


<details>
  <summary>Details</summary>
Motivation: 情感识别领域受限于高质量多样化情感数据集的稀缺，因个人、文化、环境主观性强，构建规模化、通用的数据集具有伦理和实际挑战。

Method: 提出PersonaGen框架，利用大型语言模型，通过多阶段以人格为基础的条件生成情感丰富文本。PersonaGen综合人口统计、社会文化背景与情境上下文等，构建分层虚拟人格以指导情感表达生成。生成数据经多种维度评测，包括语义多样性聚类、分布指标、人类化LLM评分、与真实语料对比以及在情感分类任务中的实用性。

Result: 实验显示PersonaGen在生成多样、连贯且具辨别性的情感表达方面显著优于现有基线方法，有效提升人工或真实情感数据集的补充或替代能力。

Conclusion: PersonaGen能高质量生成多样、真实的人格化情感表达，是情感识别研究领域重要的数据增强和数据集替代路径。

Abstract: In the field of emotion recognition, the development of high-performance
models remains a challenge due to the scarcity of high-quality, diverse
emotional datasets. Emotional expressions are inherently subjective, shaped by
individual personality traits, socio-cultural backgrounds, and contextual
factors, making large-scale, generalizable data collection both ethically and
practically difficult. To address this issue, we introduce PersonaGen, a novel
framework for generating emotionally rich text using a Large Language Model
(LLM) through multi-stage persona-based conditioning. PersonaGen constructs
layered virtual personas by combining demographic attributes, socio-cultural
backgrounds, and detailed situational contexts, which are then used to guide
emotion expression generation. We conduct comprehensive evaluations of the
generated synthetic data, assessing semantic diversity through clustering and
distributional metrics, human-likeness via LLM-based quality scoring, realism
through comparison with real-world emotion corpora, and practical utility in
downstream emotion classification tasks. Experimental results show that
PersonaGen significantly outperforms baseline methods in generating diverse,
coherent, and discriminative emotion expressions, demonstrating its potential
as a robust alternative for augmenting or replacing real-world emotional
datasets.

</details>


### [16] [SAFT: Structure-Aware Fine-Tuning of LLMs for AMR-to-Text Generation](https://arxiv.org/abs/2507.13381)
*Rafiq Kamel,Filippo Guerranti,Simon Geisler,Stephan Günnemann*

Main category: cs.CL

TL;DR: 提出SAFT方法，无需架构修改便能将AMR图结构信息注入LLM，在AMR-to-text任务上大幅提升LLM生成质量并刷新SOTA。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在处理如图结构化输入（如AMR语义图）时，现有方法通常忽略了图结构的丰富信息，仅通过任意线性化结构或采用与主流LLM不兼容的架构，导致效果受限。

Method: 提出了一种结构感知微调（SAFT）方法，通过计算AMR图的磁拉普拉斯算子生成方向敏感的位置编码，并将其映射到LLM的嵌入空间，无需改变现有LLM架构。

Result: 在AMR 3.0基准上获得了比现有基线方法高3.5 BLEU的表现。性能提升随图的复杂性增加而扩大，进一步证明了结构感知表征的重要性。

Conclusion: SAFT为结构化数据和大语言模型的结合提供了一种高效、通用的桥梁方式，可提升LLM对图结构输入的理解和生成能力。

Abstract: Large Language Models (LLMs) are increasingly applied to tasks involving
structured inputs such as graphs. Abstract Meaning Representations (AMRs),
which encode rich semantics as directed graphs, offer a rigorous testbed for
evaluating LLMs on text generation from such structures. Yet, current methods
often arbitrarily linearize AMRs, discarding key structural cues, or rely on
architectures incompatible with standard LLMs. We introduce SAFT, a
structure-aware fine-tuning approach that injects graph topology into
pretrained LLMs without architectural changes. We compute direction-sensitive
positional encodings from the magnetic Laplacian of transformed AMRs and
project them into the embedding space of the LLM. While possibly applicable to
any graph-structured inputs, we focus on AMR-to-text generation as a
representative and challenging benchmark. SAFT sets a new state-of-the-art on
AMR 3.0 with a 3.5 BLEU improvement over baselines. Gains scale with graph
complexity, highlighting the value of structure-aware representations in
enhancing LLM performance. SAFT offers a general and effective pathway for
bridging structured data and language models.

</details>


### [17] [Context-Based Fake News Detection using Graph Based Approach: ACOVID-19 Use-case](https://arxiv.org/abs/2507.13382)
*Chandrashekar Muniyappa,Sirisha Velampalli*

Main category: cs.CL

TL;DR: 本文提出了基于NLP与图算法结合的假新闻检测方法，能有效识别异常假新闻模式，实验涵盖新冠相关真假新闻验证结果。


<details>
  <summary>Details</summary>
Motivation: 当前数字化时代假新闻传播速度极快，成为社会和信息安全的重大问题。本研究旨在解决假新闻检测难题。

Method: 首先选取Kaggle上的真假新闻数据集，并加入最新的与新冠疫情相关的真假新闻，以丰富实验数据。利用自然语言处理（NLP）技术将新闻转换为上下文图结构，并采用基于最小描述长度（MDL）的图异常检测算法（GBAD），挖掘、检测数据中的异常模式。

Result: 提出的基于上下文的图方法能够识别数据集中的规范（正常）模式，并发现偏离这些规范的异常（假新闻）模式。

Conclusion: 图方法在处理包含丰富上下文信息的新闻数据方面具有优势，可以帮助发现传统方法难以察觉的复杂模式，从而提升假新闻检测的准确性。

Abstract: In today\'s digital world, fake news is spreading with immense speed. Its a
significant concern to address. In this work, we addressed that challenge using
novel graph based approach. We took dataset from Kaggle that contains real and
fake news articles. To test our approach we incorporated recent covid-19
related news articles that contains both genuine and fake news that are
relevant to this problem. This further enhances the dataset as well instead of
relying completely on the original dataset. We propose a contextual graph-based
approach to detect fake news articles. We need to convert news articles into
appropriate schema, so we leverage Natural Language Processing (NLP) techniques
to transform news articles into contextual graph structures. We then apply the
Minimum Description Length (MDL)-based Graph-Based Anomaly Detection (GBAD)
algorithm for graph mining. Graph-based methods are particularly effective for
handling rich contextual data, as they enable the discovery of complex patterns
that traditional query-based or statistical techniques might overlook. Our
proposed approach identifies normative patterns within the dataset and
subsequently uncovers anomalous patterns that deviate from these established
norms.

</details>


### [18] [PARAM-1 BharatGen 2.9B Model](https://arxiv.org/abs/2507.13390)
*Kundeshwar Pundalik,Piyush Sawarkar,Nihar Sahoo,Abhishek Shinde,Prateek Chanda,Vedant Goswami,Ajay Nagpal,Atul Singh,Viraj Thakur,Vijay Dewane,Aamod Thakur,Bhargav Patel,Smita Gautam,Bhagwan Panditi,Shyam Pawar,Madhav Kotcha,Suraj Racha,Saral Sureka,Pankaj Singh,Rishi Bal,Rohit Saluja,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: 提出了面向印度语言多样性的PARAM-1大语言模型，关注印地语和英语、分词公平及本地化评测，验证了前期嵌入多样性策略的有效性，能作为印度多语言场景下的强大模型或基线。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）主要以英语为中心，导致语言和文化多样性被系统性低估，尤其是像印度这样拥有多语言、多方言、代码切换与双语共存现象的地区。因此，迫切需要一个结构上更具包容性的模型，代表印度的语言多样性。

Method: 提出PARAM-1模型，一个仅有2.9B参数的decoder-only、text-only的大语言模型。从头开始训练，数据集仅包含印地语和英语，突出高质量、事实丰富的内容。设计包含三大原则：印地语有25%语料分配；采用适应印度形态结构的SentencePiece分词器实现分词公平；以及用本地化评测基准（IndicQA、代码混合推理和社会语言稳健性任务）做效果评估。

Result: PARAM-1模型以多样性为设计核心，在前训练阶段融入公平和包容性。实验证明该模型不仅是一个有竞争力的通用模型，同时也是印度本地应用的强大基线。

Conclusion: 将多样性在语言模型前训练阶段深度嵌入，而不是后期微调补救，是实现公平基础模型设计的有效途径。PARAM-1为印度多语言环境提供了有竞争力的模型和蓝本。

Abstract: Large Language Models (LLMs) have emerged as powerful general-purpose
reasoning systems, yet their development remains dominated by English-centric
data, architectures, and optimization paradigms. This exclusionary design
results in structural under-representation of linguistically diverse regions
such as India, where over 20 official languages and 100+ dialects coexist
alongside phenomena like code-switching and diglossia. We introduce PARAM-1, a
2.9B parameter decoder-only, text-only language model trained from scratch with
an explicit architectural and linguistic focus on Indian diversity. PARAM-1 is
trained on a bilingual dataset consisting of only Hindi and English,
constructed with a strong focus on fact-rich, high-quality content. It is
guided by three core principles: equitable representation of Indic languages
through a 25% corpus allocation; tokenization fairness via a SentencePiece
tokenizer adapted to Indian morphological structures; and culturally aligned
evaluation benchmarks across IndicQA, code-mixed reasoning, and
socio-linguistic robustness tasks. By embedding diversity at the pretraining
level-rather than deferring it to post-hoc alignment-PARAM-1 offers a
design-first blueprint for equitable foundation modeling. Our results
demonstrate that it serves as both a competent general-purpose model and a
robust baseline for India-centric applications.

</details>


### [19] [TopicImpact: Improving Customer Feedback Analysis with Opinion Units for Topic Modeling and Star-Rating Prediction](https://arxiv.org/abs/2507.13392)
*Emil Häglund,Johanna Björklund*

Main category: cs.CL

TL;DR: 该论文提出以观点单元为基础的情感话题建模方案，利用大语言模型提取情感单元，并对这些信息进行深入分析，显著提升了话题可解释性和与商业指标（如评分）的关联性，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统的话题建模方法难以同时捕捉评论中的细粒度观点及其对应情感，这限制了从客户评论中提炼有效商业洞察的能力。该论文旨在解决这一问题，提升话题建模的解释性和与商业指标的关联性。

Method: 重构了话题建模流程，从处理整体文本转向基于“观点单元”（即包含相关文本片段和情感分数的独立陈述）进行建模。依赖大型语言模型自动提取观点单元，并对这些单元进行话题建模和情感分析；再将话题、情感与业务指标（如评分）进行关联。

Result: 系统能够生成更具连贯性和可解释性的话题，同时准确捕捉每个话题对应的情感。通过将这些话题和情感与如星级评分等业务指标相关联，有助于理解客户关注点如何影响业务结果。实验展示了本系统在话题连贯性、解释性及星级预测中的有效性。

Conclusion: 面向观点单元的话题建模能更好地揭示客户评论结构及其商业影响，相比其他话题建模和分类方案，在连贯性、解释性和商业洞察方面具显著优势。

Abstract: We improve the extraction of insights from customer reviews by restructuring
the topic modelling pipeline to operate on opinion units - distinct statements
that include relevant text excerpts and associated sentiment scores. Prior work
has demonstrated that such units can be reliably extracted using large language
models. The result is a heightened performance of the subsequent topic
modeling, leading to coherent and interpretable topics while also capturing the
sentiment associated with each topic. By correlating the topics and sentiments
with business metrics, such as star ratings, we can gain insights on how
specific customer concerns impact business outcomes. We present our system's
implementation, use cases, and advantages over other topic modeling and
classification solutions. We also evaluate its effectiveness in creating
coherent topics and assess methods for integrating topic and sentiment
modalities for accurate star-rating prediction.

</details>


### [20] [Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only](https://arxiv.org/abs/2507.13395)
*Xuanqi Gao,Weipeng Jiang,Juan Zhai,Shiqing Ma,Siyi Xie,Xinyang Yin,Chao Shen*

Main category: cs.CL

TL;DR: 该文提出利用单语语料提升NMT译文风格保真的Babel框架，结合风格检测与扩散模型修正机制，无需更改系统结构即能大幅改善多领域风格保持效果。


<details>
  <summary>Details</summary>
Motivation: 神经机器翻译（NMT）极大促进了跨语言交流，但在翻译过程中保留文本风格却是一个难题。以往方法往往需要平行语料来进行风格保持，限制了应用范围。作者希望解决在没有平行风格语料的情况下实现风格保真的翻译。

Method: 提出了名为Babel的新框架，仅使用单语语料提升NMT的风格保真性。该方法包含两大组件：（1）基于上下文嵌入的风格检测器，用于识别源文本和译文之间的风格差异；（2）基于扩散模型的风格应用器，纠正风格不一致且不影响语义。同时，该方法作为后处理模块与现有NMT系统无缝集成，无需更改原系统架构或引入平行风格数据。

Result: 在法律、文学、科学写作、医学以及教育内容五个领域进行大量实验，Babel框架风格不一致检测精度达到88.21%，并将风格保持能力提升150%，语义相似性得分高达0.92。人工评价也证实经Babel处理后的译文能更好保留原文风格，流畅性与充足性保持良好。

Conclusion: Babel框架在不需要平行风格语料的条件下，显著增强了NMT系统的风格一致性且不影响语义，易于集成到现有翻译系统中，具有较高实用价值。

Abstract: The advent of neural machine translation (NMT) has revolutionized
cross-lingual communication, yet preserving stylistic nuances remains a
significant challenge. While existing approaches often require parallel corpora
for style preservation, we introduce Babel, a novel framework that enhances
stylistic fidelity in NMT using only monolingual corpora. Babel employs two key
components: (1) a style detector based on contextual embeddings that identifies
stylistic disparities between source and target texts, and (2) a
diffusion-based style applicator that rectifies stylistic inconsistencies while
maintaining semantic integrity. Our framework integrates with existing NMT
systems as a post-processing module, enabling style-aware translation without
requiring architectural modifications or parallel stylistic data. Extensive
experiments on five diverse domains (law, literature, scientific writing,
medicine, and educational content) demonstrate Babel's effectiveness: it
identifies stylistic inconsistencies with 88.21% precision and improves
stylistic preservation by 150% while maintaining a high semantic similarity
score of 0.92. Human evaluation confirms that translations refined by Babel
better preserve source text style while maintaining fluency and adequacy.

</details>


### [21] [Causal Language Control in Multilingual Transformers via Sparse Feature Steering](https://arxiv.org/abs/2507.13410)
*Cheng-Ting Chou,George Liu,Jessica Sun,Cole Blondin,Kevin Zhu,Vasu Sharma,Sean O'Brien*

Main category: cs.CL

TL;DR: 本研究提出通过稀疏自编码器特征微调可在无提示零样本条件下高效控制大模型的生成语种，准确率高且语义不变，方法轻量且可解释。


<details>
  <summary>Details</summary>
Motivation: 多语言大模型在零样本情况下（无额外提示或微调）下仍难以确定地控制生成语种。虽然稀疏自编码器（SAE）特征与可解释模型行为有关，该特征尚未被大规模应用于语言生成控制。

Method: 作者在Gemma-2B和Gemma-9B模型的残差流上，用预训练的稀疏自编码器（SAE）找到英与中、日、西、法四种语种之间激活差异最大的特征，在推理时只修改单一SAE特征以实现语言生成的引导。

Result: 只需在某个transformer层修改一个SAE特征，FastText语言分类准确度能达到90%，同时LaBSE语义相似度显示语义保持良好。分析还发现这种方法在transformer中后层最有效，且部分注意头与语言敏感特征关联强。

Conclusion: 稀疏特征引导为可解释且轻量的可控多语言生成机制提供了新途径。

Abstract: Deterministically controlling the target generation language of large
multilingual language models (LLMs) remains a fundamental challenge,
particularly in zero-shot settings where neither explicit language prompts nor
fine-tuning are available. In this work, we investigate whether sparse
autoencoder (SAE) features, previously shown to correlate with interpretable
model behaviors, can be leveraged to steer the generated language of LLMs
during inference. Leveraging pretrained SAEs on the residual streams of
Gemma-2B and Gemma-9B, we identify features whose activations differ most
significantly between English and four target languages: Chinese, Japanese,
Spanish, and French. By modifying just a single SAE feature at one transformer
layer, we achieve controlled language shifts with up to 90\% success, as
measured by FastText language classification, while preserving semantic
fidelity according to LaBSE (Language-Agnostic BERT Sentence Embedding)
similarity. Our analysis reveals that language steering is most effective in
mid-to-late transformer layers and is amplified by specific attention heads
disproportionately associated with language-sensitive SAE features. These
results demonstrate the promise of sparse feature steering as a lightweight and
interpretable mechanism for controllable multilingual generation.

</details>


### [22] [Aligning Knowledge Graphs and Language Models for Factual Accuracy](https://arxiv.org/abs/2507.13411)
*Nur A Zarin Nishat,Andrea Coletta,Luigi Bellomarini,Kossi Amouzouvi,Jens Lehmann,Sahar Vahdati*

Main category: cs.CL

TL;DR: 本文提出了一种简单有效的将知识图谱注入大语言模型的新方法，通过对齐嵌入空间，显著减少幻觉现象，并在多个基准与实际案例中提升了准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（如GPT-4、Gemini、Claude）在NLP任务取得显著进展，但其幻觉问题（即产出不准确或无依据的信息）仍然是重大挑战。为了解决这一问题，许多方法尝试将结构化的知识库用于语言模型，从而提升模型的事实性和可靠性。

Method: 本文提出ALIGNed-LLM方法，将知识图谱的嵌入向量（如TransE模型训练的嵌入）通过一个可训练投影层，注入并与语言模型的文本嵌入对齐。这一过程借鉴了LLaVA模型，将外部信息（如视觉、文本或知识图谱）融合进LLM的潜在空间中，从而支持更精确的实体区分与事实推断。

Result: 在三个主流问答基准数据集上对不同规模的语言模型进行测试，ALIGNed-LLM均显著提升了模型的事实准确率。同时，在一个来自欧洲大型中央银行的实际金融场景下应用该方法，LLM的回答准确性亦有大幅提升。

Conclusion: ALIGNed-LLM通过高效注入知识图谱信息对齐实体与文本嵌入，从而显著提升了LLM的事实性与问题解答准确率，在实际行业场景下也展现出可观的实用价值。

Abstract: Large language models like GPT-4, Gemini, and Claude have transformed natural
language processing (NLP) tasks such as question answering, dialogue
generation, summarization, and so forth; yet their susceptibility to
hallucination stands as one of the major challenges. Among numerous approaches
to overcome this challenge, integration of Knowledge Graphs (KGs) into language
models has emerged as a promising solution as it provides structured, reliable,
domain-specific, and up-to-date external information to the language models. In
this paper, we introduce ALIGNed-LLM, a simple yet effective approach to
improve language models' factuality via a lean strategy to infuse KGs into the
latent space of language models inspired by LLaVA where visual and textual
information is infused. We use embeddings from a pre-trained Knowledge Graph
Embedding (KGE) model, such as TransE, and a trainable projection layer to
align entity and text embeddings. This alignment enables the language model to
distinguish between similar entities improving factual grounding and reducing
hallucination. We tested our approach on three popular questions-answering
benchmark datasets alongside language models of varying sizes, showing
significant improvement. Furthermore, we applied our approach to a real-world
financial use case from a large central bank in Europe, which demands high
accuracy and precision, demonstrating a substantial improvement of the LLM
answers.

</details>


### [23] [Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers](https://arxiv.org/abs/2507.13474)
*Liang Lin,Zhihao Xu,Xuehai Tang,Shi Liu,Biyu Zhou,Fuqing Zhu,Jizhong Han,Songlin Hu*

Main category: cs.CL

TL;DR: 作者提出了一种基于学术论文内容的越狱攻击方法（PSA），实验证明其能高效攻破多种主流LLM，并揭示模型对权威信息的信任是重大安全隐患。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLM）的安全性是研究焦点。该文指出，LLM倾向于信任来自权威来源（如学术论文）的信息，这可能成为新的安全弱点。论文旨在验证和探究该问题。

Method: 设计了初步分析验证LLM对权威内容的信任倾向；提出了一种新颖的越狱攻击方法——Paper Summary Attack（PSA），通过系统性地从攻击或防御导向的LLM安全论文合成内容，构建对抗性提示模板，并在预定义子部分内注入有害查询。

Result: 大量实验表明，基础LLM以及最新推理模型（如Deepseek-R1）都存在显著漏洞。PSA对Claude3.5-Sonnet的攻击成功率达97%，对Deepseek-R1更高达98%。不同模型及其不同版本在面对不同类型论文内容时，展现出完全相反的脆弱倾向。

Conclusion: LLM对权威论文内容的信任带来了新的攻击面，PSA方法能够高效突破当下主流模型的安全防护。不同模型的脆弱性差异为对抗方法与安全对齐研究提供新的线索。

Abstract: The safety of large language models (LLMs) has garnered significant research
attention. In this paper, we argue that previous empirical studies demonstrate
LLMs exhibit a propensity to trust information from authoritative sources, such
as academic papers, implying new possible vulnerabilities. To verify this
possibility, a preliminary analysis is designed to illustrate our two findings.
Based on this insight, a novel jailbreaking method, Paper Summary Attack
(\llmname{PSA}), is proposed. It systematically synthesizes content from either
attack-focused or defense-focused LLM safety paper to construct an adversarial
prompt template, while strategically infilling harmful query as adversarial
payloads within predefined subsections. Extensive experiments show significant
vulnerabilities not only in base LLMs, but also in state-of-the-art reasoning
model like Deepseek-R1. PSA achieves a 97\% attack success rate (ASR) on
well-aligned models like Claude3.5-Sonnet and an even higher 98\% ASR on
Deepseek-R1. More intriguingly, our work has further revealed diametrically
opposed vulnerability bias across different base models, and even between
different versions of the same model, when exposed to either attack-focused or
defense-focused papers. This phenomenon potentially indicates future research
clues for both adversarial methodologies and safety alignment.Code is available
at https://github.com/233liang/Paper-Summary-Attack

</details>


### [24] [Revisiting LLM Value Probing Strategies: Are They Robust and Expressive?](https://arxiv.org/abs/2507.13490)
*Siqi Shen,Mehar Singh,Lajanugen Logeswaran,Moontae Lee,Honglak Lee,Rada Mihalcea*

Main category: cs.CL

TL;DR: 大模型价值观探测方法对输入扰动很敏感，与模型实际行为相关性弱，人口统计背景影响也很有限，需警惕现有探测法的不足。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）的价值取向会影响不同人群的用户体验，但现有的价值探测方法存在易被输入扰动影响、方法对比不足以及对模型实际倾向的关联性不明等问题。作者希望系统性地分析这些探测方法的稳健性、表现力及其局限。

Method: 通过系统性比较三种常用的大模型价值观测探测方法，分别分析它们在不同输入扰动（如prompt和选项变化）下的表现。同时，设计了两个新任务，考察模型对人口统计上下文（demographic context）的响应性，以及模型内在价值观与实际行为倾向（如价值相关决策行动）的一致性。

Result: 所有探测方法在输入轻微扰动下表现出较大波动，稳健性不足。加入人口统计背景对自由文本生成影响很小，且模型探测出的价值观与其实际在价值相关场景中的倾向性仅有弱相关。

Conclusion: 当前主流价值观探测方法在稳健性和实际效度上存在较大局限，未来需要更严谨的评估与对其局限的充分认识。

Abstract: There has been extensive research on assessing the value orientation of Large
Language Models (LLMs) as it can shape user experiences across demographic
groups. However, several challenges remain. First, while the Multiple Choice
Question (MCQ) setting has been shown to be vulnerable to perturbations, there
is no systematic comparison of probing methods for value probing. Second, it is
unclear to what extent the probed values capture in-context information and
reflect models' preferences for real-world actions. In this paper, we evaluate
the robustness and expressiveness of value representations across three widely
used probing strategies. We use variations in prompts and options, showing that
all methods exhibit large variances under input perturbations. We also
introduce two tasks studying whether the values are responsive to demographic
context, and how well they align with the models' behaviors in value-related
scenarios. We show that the demographic context has little effect on the
free-text generation, and the models' values only weakly correlate with their
preference for value-based actions. Our work highlights the need for a more
careful examination of LLM value probing and awareness of its limitations.

</details>


### [25] [Encoding syntactic objects and Merge operations in function spaces](https://arxiv.org/abs/2507.13501)
*Matilde Marcolli,Robert C. Berwick*

Main category: cs.CL

TL;DR: 通过引入特定的函数空间和代数结构，本文实现了将任意句法对象和Merge操作以数学方式建模，为句法结构神经计算实现提供了理论基础，并揭示了Merge与算术结构的内在联系。


<details>
  <summary>Details</summary>
Motivation: 之前关于句法结构神经计算实现的理论构架仍不完善，缺乏基于数学和函数空间的严格证明方法。作者旨在通过数学方法说明，将词汇项目等表征为函数（如小波）时，可以在相同函数空间内忠实表征任意句法对象，从而为神经计算实现句法结构提供理论依据。

Method: 文章利用函数空间和小波方法，将词汇和句法对象映射为特定函数。为该函数空间引入可交换非结合半环结构（借助Renyi熵）、代数结构和operad的代数运算，以及与Hopf代数与马尔科夫链结合，实现了句法合并操作（Merge）的数学描述和实现。还分析了在正弦波上的跨频相位同步，作为Merge实现的具体案例。

Result: 作者构建了一个严密的数学框架，使得句法对象和其合并操作（Merge）能在函数空间中获得忠实的代数和运算模型，实现了句法结构神经计算实现的理论可行性。具体案例中，Merge可通过半环的后继函数与跨频相位同步建模，阐明了其与算术后继函数的相似性。

Conclusion: 本文为核心句法结构的神经计算实现，提供了严密的构造性数学论证，证明了理论上的可行性，并通过特定案例展示了Merge操作的具体函数实现及其算术性质根源。

Abstract: We provide a mathematical argument showing that, given a representation of
lexical items as functions (wavelets, for instance) in some function space, it
is possible to construct a faithful representation of arbitrary syntactic
objects in the same function space. This space can be endowed with a
commutative non-associative semiring structure built using the second Renyi
entropy. The resulting representation of syntactic objects is compatible with
the magma structure. The resulting set of functions is an algebra over an
operad, where the operations in the operad model circuits that transform the
input wave forms into a combined output that encodes the syntactic structure.
The action of Merge on workspaces is faithfully implemented as action on these
circuits, through a coproduct and a Hopf algebra Markov chain. The results
obtained here provide a constructive argument showing the theoretical
possibility of a neurocomputational realization of the core computational
structure of syntax. We also present a particular case of this general
construction where this type of realization of Merge is implemented as a cross
frequency phase synchronization on sinusoidal waves. This also shows that Merge
can be expressed in terms of the successor function of a semiring, thus
clarifying the well known observation of its similarities with the successor
function of arithmetic.

</details>


### [26] [A Computational Approach to Modeling Conversational Systems: Analyzing Large-Scale Quasi-Patterned Dialogue Flows](https://arxiv.org/abs/2507.13544)
*Mohamed Achref Ben Ammar,Mohamed Taha Bennani*

Main category: cs.CL

TL;DR: 本论文提出了结合大语言模型和“Filter & Reconnect”新方法的对话图建模框架，实现了语义提升和清晰的树状结构，对大规模对话分析场景具有直接应用价值。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型系统在各类用户场景中的应用普及，如何有效分析对话动态成为亟需解决的问题。目前针对松散结构对话的建模和简化尚不完善，存在噪声高、结构不清晰等挑战。

Method: 提出一种新颖的计算框架，生成能反映“类模式”松散对话结构的对话图，并创新性地提出了“Filter & Reconnect”图简化方法，致力于在去除噪声的同时保持语义和结构完整。

Result: 结合大语言模型和提出的图简化技术后，语义度量指标S提升了2.06倍，同时对话图呈现0 δ-超曲率的类树结构，实现了高清晰度的对话建模。

Conclusion: 研究提出了一套有效的计算方法，能够对大规模对话数据集进行结构建模和语义提炼，适用于自动化系统监控、对话管理和用户行为分析等实际应用场景。

Abstract: The analysis of conversational dynamics has gained increasing importance with
the rise of large language model-based systems, which interact with users
across diverse contexts. In this work, we propose a novel computational
framework for constructing conversational graphs that capture the flow and
structure of loosely organized dialogues, referred to as quasi-patterned
conversations. We introduce the Filter & Reconnect method, a novel graph
simplification technique that minimizes noise while preserving semantic
coherence and structural integrity of conversational graphs. Through
comparative analysis, we demonstrate that the use of large language models
combined with our graph simplification technique has resulted in semantic
metric S increasing by a factor of 2.06 compared to previous approaches while
simultaneously enforcing a tree-like structure with 0 {\delta}-hyperbolicity,
ensuring optimal clarity in conversation modeling. This work provides a
computational method for analyzing large-scale dialogue datasets, with
practical applications related to monitoring automated systems such as
chatbots, dialogue management tools, and user behavior analytics.

</details>


### [27] [Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder](https://arxiv.org/abs/2507.13551)
*Feng Chen,Weizhe Xu,Changye Li,Serguei Pakhomov,Alex Cohen,Simran Bhola,Sandy Yin,Sunny X Tang,Michael Mackinley,Lena Palaniyappan,Dror Ben-Zeev,Trevor Cohen*

Main category: cs.CL

TL;DR: 本研究证明，将自动语音识别提取的停顿特征与语义连贯性指标结合，能更有效地量化精神分裂症的思维障碍，为自动化、可扩展的精神病学评估提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 精神分裂症等精神疾病中，正式思维障碍（FTD）表现为患者言语紊乱，传统的评估方法耗时且难以大规模应用。自动化语音识别（ASR）技术可以客观量化语音特征，但如何有效整合这些特征以评估FTD严重程度还需进一步研究。

Method: 该研究整合了基于ASR的停顿特征与语义连贯性指标，在三个不同的数据集（自录日记、图片描述、梦境叙述）上，通过支持向量回归（SVR）模型预测FTD的临床评分。分别比较了停顿特征、语义特征以及二者结合的预测效果。

Result: 停顿特征单独就具有稳健的FTD严重度预测力。将停顿特征与语义连贯性特征结合后，预测效果高于仅用语义特征，部分模型最高相关性达到0.649，重症检测AUC达83.71%。不同语料下停顿模式表现各异，但两类特征整合的性能提升在所有测试中均成立。

Conclusion: 结合语音的时序特征和语义特征的自动化分析框架，有助于精准高效地评估精神分裂症患者的思维障碍，为精神疾病领域的自动化语音分析提供了可推广的方法。

Abstract: Formal thought disorder (FTD), a hallmark of schizophrenia spectrum
disorders, manifests as incoherent speech and poses challenges for clinical
assessment. Traditional clinical rating scales, though validated, are
resource-intensive and lack scalability. Automated speech analysis with
automatic speech recognition (ASR) allows for objective quantification of
linguistic and temporal features of speech, offering scalable alternatives. The
use of utterance timestamps in ASR captures pause dynamics, which are thought
to reflect the cognitive processes underlying speech production. However, the
utility of integrating these ASR-derived features for assessing FTD severity
requires further evaluation. This study integrates pause features with semantic
coherence metrics across three datasets: naturalistic self-recorded diaries
(AVH, n = 140), structured picture descriptions (TOPSY, n = 72), and dream
narratives (PsyCL, n = 43). We evaluated pause related features alongside
established coherence measures, using support vector regression (SVR) to
predict clinical FTD scores. Key findings demonstrate that pause features alone
robustly predict the severity of FTD. Integrating pause features with semantic
coherence metrics enhanced predictive performance compared to semantic-only
models, with integration of independent models achieving correlations up to
\r{ho} = 0.649 and AUC = 83.71% for severe cases detection (TOPSY, with best
\r{ho} = 0.584 and AUC = 79.23% for semantic-only models). The performance
gains from semantic and pause features integration held consistently across all
contexts, though the nature of pause patterns was dataset-dependent. These
findings suggest that frameworks combining temporal and semantic analyses
provide a roadmap for refining the assessment of disorganized speech and
advance automated speech analysis in psychosis.

</details>


### [28] [A Data-Centric Framework for Addressing Phonetic and Prosodic Challenges in Russian Speech Generative Models](https://arxiv.org/abs/2507.13563)
*Kirill Borodin,Nikita Vasiliev,Vasiliy Kudryavtsev,Maxim Maslov,Mikhail Gorodnichev,Oleg Rogov,Grach Mkrtchian*

Main category: cs.CL

TL;DR: 提出了大型俄语语音数据集Balalaika，配有详细注释，显著提升了语音合成和增强的效果。


<details>
  <summary>Details</summary>
Motivation: 俄语语音合成面临一系列独特难题，如元音弱化、辅音清音化、重音多变、同形异义词歧义以及语调不自然等。现有数据集在语音合成和增强方面存在局限。

Method: 本文提出并构建了一个新的俄语大规模语音数据集Balalaika，包含超过2,000小时的录音，并配有详尽文本标注（包含标点和重音标记）。同时介绍了数据集的建构流程、注释方法及实验设计。

Result: 使用Balalaika训练的模型在语音合成和语音增强任务中，显著优于基于现有数据集训练的模型。

Conclusion: Balalaika数据集通过高质量和全方位的标注提升了俄语语音合成的表现，可为后续语音技术和研究提供坚实数据基础。

Abstract: Russian speech synthesis presents distinctive challenges, including vowel
reduction, consonant devoicing, variable stress patterns, homograph ambiguity,
and unnatural intonation. This paper introduces Balalaika, a novel dataset
comprising more than 2,000 hours of studio-quality Russian speech with
comprehensive textual annotations, including punctuation and stress markings.
Experimental results show that models trained on Balalaika significantly
outperform those trained on existing datasets in both speech synthesis and
enhancement tasks. We detail the dataset construction pipeline, annotation
methodology, and results of comparative evaluations.

</details>


### [29] [Linguistic and Embedding-Based Profiling of Texts generated by Humans and Large Language Models](https://arxiv.org/abs/2507.13614)
*Sergio E. Zanotto,Segun Aroyehun*

Main category: cs.CL

TL;DR: 该论文系统分析了人类和不同大语言模型生成文本在多层次语言学特征上的差异，发现人类文本更具多样性和句法简洁性，机器文本则趋于同质化，对文本判别和模型改进具有启示意义。


<details>
  <summary>Details</summary>
Motivation: 近年来大型语言模型在自然语言生成领域获得了巨大进展，使其生成的文本与人类编写的文本愈发难以区分。当前已有许多研究关注于识别和分类人类文本与机器文本，但缺乏对这些文本在多层面语言特征上的系统刻画。

Method: 作者采集了涵盖8个领域、11种不同大型语言模型（LLM）输出及人类文本的数据集，并从形态学、句法、语义等不同语言层面提取特征（如依存长度、情感性等），分析人类与机器文本的不同。研究还考察了采样策略、重复控制及模型发布日期的影响，并利用风格嵌入对比变异性。

Result: 统计分析显示，人类文本通常有更简单的句法结构和更丰富的语义内容。无论人类还是机器文本，不同领域间均展现了风格多样性，但人类文本在提取特征上的变异性更大。最新大模型生成的文本在变异性上已与前一代模型趋同，表现出一定的文本同质化。

Conclusion: 与人类文本相比，机器文本在句法简化和语义多样性方面仍有差距。随着大模型迭代，文本风格逐步同质化，且难以展现领域内的人类风格变异性。该成果为理解和分类机器生成文本提供了语言学视角的新方法。

Abstract: The rapid advancements in large language models (LLMs) have significantly
improved their ability to generate natural language, making texts generated by
LLMs increasingly indistinguishable from human-written texts. While recent
research has primarily focused on using LLMs to classify text as either
human-written and machine-generated texts, our study focus on characterizing
these texts using a set of linguistic features across different linguistic
levels such as morphology, syntax, and semantics. We select a dataset of
human-written and machine-generated texts spanning 8 domains and produced by 11
different LLMs. We calculate different linguistic features such as dependency
length and emotionality and we use them for characterizing human-written and
machine-generated texts along with different sampling strategies, repetition
controls and model release date. Our statistical analysis reveals that
human-written texts tend to exhibit simpler syntactic structures and more
diverse semantic content. Furthermore, we calculate the variability of our set
of features across models and domains. Both human and machine texts show
stylistic diversity across domains, with humans displaying greater variation in
our features. Finally, we apply style embeddings to further test variability
among human-written and machine-generated texts. Notably, newer models output
text that is similarly variable, pointing to an homogenization of
machine-generated texts.

</details>


### [30] [Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters](https://arxiv.org/abs/2507.13618)
*Shanbo Cheng,Yu Bao,Qian Cao,Luyang Huang,Liyan Kang,Zhicheng Liu,Yu Lu,Wenhao Zhu,Zhichao Huang,Tao Li,Sitong Liu,Ningxin Peng,Shuaijie She,Lu Xu,Nuo Xu,Sen Yang,Runsheng Yu,Yiming Yu,Liehao Zou,Hang Li,Lu Lu,Yuxuan Wang,Yonghui Wu*

Main category: cs.CL

TL;DR: Seed-X提出了一种高效的多语言翻译LLM，在性能、模型开放性及优化方法方面取得了突出成果，有望推动多语言翻译技术进步。


<details>
  <summary>Details</summary>
Motivation: 多语言翻译对于大规模语言模型来说极具挑战性，因其面临复杂的语言结构和生硬的自动翻译结果。

Method: 本文提出Seed-X，一个开源的大型语言模型家族，包含instruct和reasoning模型，参数量为7B。基座模型在包含28种语言的多样高质量单语及双语数据上进行预训练。之后通过Chain-of-Thought（CoT）推理微调instruct模型，并结合强化学习（RL）进一步提升其跨语言泛化能力。

Result: Seed-X在28种语言上的表现可与闭源顶尖模型（如Gemini-2.5和GPT-4o）媲美，并且在自动评价指标和人工评测中显著优于更大规模的开源模型。

Conclusion: Seed-X证明在仅用7B参数的情况下，通过精细的数据和训练设计，能够实现卓越的多语言翻译。作者公开模型参数和优化实践方法以促进翻译研究与应用发展。

Abstract: Multilingual translation stands as a challenging task for large language
models (LLMs) to handle intricate language patterns and stilted translations
that arise in automated translations. In this paper, we introduce Seed-X, a
family of open-source LLMs comprising instruct and reasoning models, pushing
the limits of translation capability with 7B parameter size. The base model is
pre-trained on a diverse, high-quality dataset encompassing both monolingual
and bilingual content across 28 languages, harnessing the full potential of
multilingual data. The instruct model is then finetuned to translate by
Chain-of-Thought (CoT) reasoning and further enhanced through reinforcement
learning (RL) to achieve better generalization across diverse language pairs.
Seed-X achieves performance comparable to leading closed-source models,
including Gemini-2.5 and GPT-4o, across 28 languages, and significantly
outperforms larger open-source models in both automatic metrics and human
evaluations. We share the best practices through our optimization process, and
make the parameter public available for advancing translation research and
applications.

</details>


### [31] [CU-ICU: Customizing Unsupervised Instruction-Finetuned Language Models for ICU Datasets via Text-to-Text Transfer Transformer](https://arxiv.org/abs/2507.13655)
*Teerapong Panboonyuen*

Main category: cs.CL

TL;DR: 本文提出CU-ICU方法，通过高效稀疏微调T5大模型，实现ICU任务的准确和可解释预测，并且只需极少参数更新，展现了强可扩展性和实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 将大型语言模型有效应用于像医疗健康这样的专业领域面临诸多挑战，特别是领域适应和标注数据稀缺。

Method: 提出了一种名为CU-ICU的方法，通过T5架构，结合few-shot提示和选择性参数更新，实现高效的稀疏微调，以适应ICU数据集。

Result: CU-ICU在ICU关键任务（如早期脓毒症检测、死亡率预测和临床笔记生成）中，相较标准微调方法在预测准确性和可解释性上都有显著提升。在高效配置下，CU-ICU仅更新不到1%的模型参数，在脓毒症检测准确率提升15%，临床解释性提升20%。

Conclusion: CU-ICU能以低算力、强可扩展性的方式，为真实ICU环境下的临床决策支持提供更准确且易解释的方案。

Abstract: Integrating large language models into specialized domains like healthcare
presents unique challenges, including domain adaptation and limited labeled
data. We introduce CU-ICU, a method for customizing unsupervised
instruction-finetuned language models for ICU datasets by leveraging the
Text-to-Text Transfer Transformer (T5) architecture. CU-ICU employs a sparse
fine-tuning approach that combines few-shot prompting with selective parameter
updates, enabling efficient adaptation with minimal supervision. Our evaluation
across critical ICU tasks--early sepsis detection, mortality prediction, and
clinical note generation--demonstrates that CU-ICU consistently improves
predictive accuracy and interpretability over standard fine-tuning methods.
Notably, CU-ICU achieves up to a 15% increase in sepsis detection accuracy and
a 20% enhancement in generating clinically relevant explanations while updating
fewer than 1% of model parameters in its most efficient configuration. These
results establish CU-ICU as a scalable, low-overhead solution for delivering
accurate and interpretable clinical decision support in real-world ICU
environments.

</details>


### [32] [KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs](https://arxiv.org/abs/2507.13666)
*Woo-Chan Kim,Ji-Hoon Park,Seong-Whan Lee*

Main category: cs.CL

TL;DR: 作者提出KiC方法，通过关键词语义比对优化级联推理流程，在自由文本生成任务上显著降低成本同时接近甚至超越GPT-4准确率。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLM）虽然在自然语言处理任务中表现优异，但高性能模型需要通过API访问，推理成本高。为降低成本，有研究通过cascade方法，先用低成本模型预测，不确定时再升级更强模型。然而，现有cascade方法对于自由生成文本，只能用文本精确匹配，难以选择和评估模型输出的可靠性。

Method: 提出Keyword-inspired Cascade (KiC)新型框架，用于高效生成自由文本。KiC先用弱模型生成多个答案，挑选最具代表性的一个，再评估其他输出与该答案的语义一致性。根据一致程度，决定是否接受弱模型答案或升级至强模型。

Result: 在三个自由文本生成基准测试集上，KiC框架以平均减少28.81%的API成本，实现了97.53%的GPT-4准确率，并在某一基准上超越GPT-4。

Conclusion: KiC框架兼顾了成本效率与输出质量，能在保持高准确率基础上，有效减少API调用成本，对自由文本生成任务具有实际应用价值。

Abstract: Large language models (LLMs) have demonstrated state-of-the-art performance
across a wide range of natural language processing tasks. However,
high-performing models are typically accessible only via APIs, incurring
substantial inference costs. Cascade methods address this by initially
employing a cheaper model and escalating to a stronger one only when necessary.
Nevertheless, existing cascade approaches struggle to select a reliable
representative response and assess the overall reliability of free-form
outputs, as they rely on exact text matching. To overcome these limitations, we
propose Keyword-inspired Cascade (KiC), a novel framework for cost-efficient
free-form text generation. KiC identifies the most representative answer among
multiple outputs from a weaker model and evaluates the semantic alignment of
other responses with it. Based on the degree of alignment, KiC determines
whether to accept the weaker model's output or escalate to a stronger model.
Experiments on three free-form text generation benchmarks show that KiC
achieves 97.53 percent of GPT-4's accuracy while reducing API costs by 28.81
percent on average, and even outperforms GPT-4 in a specific benchmark.

</details>


### [33] [LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues](https://arxiv.org/abs/2507.13681)
*Haoyang Li,Zhanchao Xu,Yiming Li,Xuejia Chen,Darian Li,Anxin Tian,Qingfa Xiao,Cheng Deng,Jun Wang,Qing Li,Lei Chen,Mingxuan Yuan*

Main category: cs.CL

TL;DR: LoopServe通过自适应稀疏化与动态Kv缓存压缩，大幅加速多轮对话场景下LLM推理，实验结果优越，并引入了新的真实任务基准。


<details>
  <summary>Details</summary>
Motivation: 多轮对话在现实应用中的重要性，然而随着对话历史变长，大语言模型（LLM）推理计算和内存消耗剧增，影响交互效率与响应速度。现有加速方法对多轮动态对话的适应性不足，难以高效支持真实应用场景。

Method: 提出LoopServe自适应双阶段推理加速框架：（1）在prefilling阶段进行在线稀疏化，动态挑选最重要的注意力矩阵部分；（2）在解码阶段开展渐进式Key-Value压缩，根据最近生成的输出token动态维护高效的缓存。此外，构建包含11个多轮数据集的新基准，覆盖真实查询位置与对话依赖。

Result: LoopServe在实验中，多轮长上下文对话任务上相比已有基线方法表现更佳，大幅提升LLM推理速度与对话效率。

Conclusion: LoopServe为多轮对话场景下的LLM推理加速提供了创新性、自适应的解决方案，在有效性和效率方面显著优于现有方法，并推动了相关基准的发展。

Abstract: Multi-turn dialogues are essential in many real-world applications of large
language models, such as chatbots and virtual assistants. As conversation
histories become longer, existing large language models face increasing
computational and memory challenges, which hinder their ability to provide
efficient and responsive interactions. Most current acceleration methods either
compress the context or optimize key value caching, but they often rely on
fixed or position-based heuristics that do not adapt well to the dynamic and
unpredictable patterns found in actual multi-turn conversations. In this paper,
we present LoopServe, an adaptive dual-phase inference acceleration framework
for large language models in multi-turn dialogues. LoopServe introduces two
main innovations. First, it performs online sparsification during the
prefilling phase by dynamically selecting the most important parts of the
attention matrix for each new input. Second, it uses progressive key value
compression during decoding by adaptively maintaining a relevant and efficient
cache based on the most recently generated output tokens. We also propose a
\href{https://huggingface.co/datasets/TreeAILab/Multi-turn_Long-context_Benchmark_for_LLMs}{new
benchmark} with eleven multi-turn datasets that reflect realistic query
positions and conversational dependencies. Extensive experiments demonstrate
that LoopServe consistently achieves superior effectiveness compared to
existing baselines and significantly accelerates LLM inference across a wide
range of long-context dialogue tasks.

</details>


### [34] [Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations](https://arxiv.org/abs/2507.13705)
*Cedric Waterschoot,Nava Tintarev,Francesco Barile*

Main category: cs.CL

TL;DR: LLM在群组推荐系统中推荐类似加性效用法，但其解释常包含不明确定义的额外标准，且透明性和可解释性随评分规模增大而下降。需关注解释生成方法与聚合策略一致性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在群组推荐系统（GRS）中被作为决策者和解释生成器的应用日益广泛，评价LLM推荐和解释结果的准确性及合理性变得非常重要。论文旨在探讨LLM推荐机制与传统社会选择聚合策略的关系，并分析其输出解释对透明性和可解释性的影响。

Method: 通过将LLM生成的推荐及其解释与社会选择理论中的聚合策略（特别是加性效用集合ADD）进行对比，考察不同群组结构（统一或分歧）下，LLM的推荐和理由是否一致，以及LLM解释中出现的额外标准和潜在不一致性。

Result: LLM生成的推荐往往类似于加性效用整合（ADD方法），且群组结构对推荐结果无显著影响。但LLM给出的解释更加倾向于平均分或引入其他标准（比如用户或物品相似性、多样性、流行度等），一些标准未明确定义。解释中的标准数量会随群组评分数量增多而增多，大项集下常规聚合方法效率降低。LLM解释存在不一致与模糊，削弱了透明性和可解释性。

Conclusion: LLM在群组推荐系统中能够产生类ADD聚合结果，但在解释推荐时易引入多余和模糊标准，且随群组评分规模扩大，这一问题加剧。这种解释机制上的缺陷影响了LLM在GRS中的透明性与可解释性，需关注其与标准聚合策略的一致性以及改进解释生成方式。

Abstract: Large Language Models (LLMs) are increasingly being implemented as joint
decision-makers and explanation generators for Group Recommender Systems (GRS).
In this paper, we evaluate these recommendations and explanations by comparing
them to social choice-based aggregation strategies. Our results indicate that
LLM-generated recommendations often resembled those produced by Additive
Utilitarian (ADD) aggregation. However, the explanations typically referred to
averaging ratings (resembling but not identical to ADD aggregation). Group
structure, uniform or divergent, did not impact the recommendations.
Furthermore, LLMs regularly claimed additional criteria such as user or item
similarity, diversity, or used undefined popularity metrics or thresholds. Our
findings have important implications for LLMs in the GRS pipeline as well as
standard aggregation strategies. Additional criteria in explanations were
dependent on the number of ratings in the group scenario, indicating potential
inefficiency of standard aggregation methods at larger item set sizes.
Additionally, inconsistent and ambiguous explanations undermine transparency
and explainability, which are key motivations behind the use of LLMs for GRS.

</details>


### [35] [The Judge Variable: Challenging Judge-Agnostic Legal Judgment Prediction](https://arxiv.org/abs/2507.13732)
*Guillaume Zambrano*

Main category: cs.CL

TL;DR: 通过机器学习分析法国判决数据，发现法官个人特点会显著影响抚养权判决结果，“专家”模型预测效果远超“通用”模型，为法律现实主义理论提供了强有力的实证支撑。


<details>
  <summary>Details</summary>
Motivation: 本文以法国上诉法院的儿童抚养权判决为案例，旨在探究法官在法律判决中的实际作用，挑战“法官仅作为法律中立适用者”的传统假设。作者关注于个人法官是否对案件结果产生显著影响，进而回应法学中的现实主义与形式主义争论。

Method: 文章采用18,937份来自10,306个案件的法国儿童抚养权裁决文本。首先，严格去标识以确保隐私保护。然后，利用大型语言模型（LLMs）进行结构化特征抽取，再用机器学习模型（如RF、XGB、SVC）进行结果预测。模型分为针对单一法官的“专家”模型、以及面向所有法官的“通用”模型，并且进行了In-Domain和Cross-Domain有效性测试。

Result: 面向单一法官训练的“专家”模型预测准确率大幅领先于通用模型，最高F1分数达到92.85%，而通用模型仅为82.63%（样本数量多20-100倍）。专家模型能捕捉到法官个人的稳定判决模式，这些模式无法转移至其他法官。有效性测试证实了法官身份对裁决结果的显著影响。

Conclusion: 研究表明，法官身份对案件结果有可量化影响，违背了“法官仅机械适法”的假设，为法律现实主义提供了新的经验证据。文中所有数据与代码均将公开。

Abstract: This study examines the role of human judges in legal decision-making by
using machine learning to predict child physical custody outcomes in French
appellate courts. Building on the legal realism-formalism debate, we test
whether individual judges' decision-making patterns significantly influence
case outcomes, challenging the assumption that judges are neutral variables
that apply the law uniformly. To ensure compliance with French privacy laws, we
implement a strict pseudonymization process. Our analysis uses 18,937 living
arrangements rulings extracted from 10,306 cases. We compare models trained on
individual judges' past rulings (specialist models) with a judge-agnostic model
trained on aggregated data (generalist models). The prediction pipeline is a
hybrid approach combining large language models (LLMs) for structured feature
extraction and ML models for outcome prediction (RF, XGB and SVC). Our results
show that specialist models consistently achieve higher predictive accuracy
than the general model, with top-performing models reaching F1 scores as high
as 92.85%, compared to the generalist model's 82.63% trained on 20x to 100x
more samples. Specialist models capture stable individual patterns that are not
transferable to other judges. In-Domain and Cross-Domain validity tests provide
empirical support for legal realism, demonstrating that judicial identity plays
a measurable role in legal outcomes. All data and code used will be made
available.

</details>


### [36] [PRIDE -- Parameter-Efficient Reduction of Identity Discrimination for Equality in LLMs](https://arxiv.org/abs/2507.13743)
*Maluna Menke,Thilo Hagendorff*

Main category: cs.CL

TL;DR: 文章发现现有LLM存在严重性别与性少数偏见，通过LoRA高效微调大幅缓解偏见且计算代价极低，建议推广PEFT并深化相关评测与数据建设。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）容易复制训练语料中的性别与性少数（LGBTQIA+）偏见，导致输出内容边缘化相关群体，因此亟需降低这类偏见。

Method: 评估两种高效参数微调（PEFT）方法——低秩适应（LoRA）和软提示微调，用以替代全模型微调，从而缓解偏见。利用WinoQueer基准和QueerNews语料，对三个开源LLM进行实验，量化偏见得分后评估PEFT技术的改善效果。

Result: 原始偏见分数高达98（满分100，50为中性）。LoRA微调（增加参数少于0.1%）能将偏见分数降低至50分，模型中性输出比例从0%提升到36%。软提示微调（仅10个虚拟token）仅有微弱改善。

Conclusion: LoRA可以用极小的额外参数实现显著的公平性提升。呼吁社区采用PEFT、建设更多同性恋作者语料与更丰富的评测工具，同时需持续进行公正性审核。

Abstract: Large Language Models (LLMs) frequently reproduce the gender- and
sexual-identity prejudices embedded in their training corpora, leading to
outputs that marginalize LGBTQIA+ users. Hence, reducing such biases is of
great importance. To achieve this, we evaluate two parameter-efficient
fine-tuning (PEFT) techniques - Low-Rank Adaptation (LoRA) and soft-prompt
tuning - as lightweight alternatives to full-model fine-tuning for mitigating
such biases. Using the WinoQueer benchmark, we quantify bias in three
open-source LLMs and observe baseline bias scores reaching up to 98 (out of
100) across a range of queer identities defined by gender and/or sexual
orientation, where 50 would indicate neutrality. Fine-tuning with LoRA (< 0.1%
additional parameters) on a curated QueerNews corpus reduces those scores by up
to 50 points and raises neutrality from virtually 0% to as much as 36%.
Soft-prompt tuning (10 virtual tokens) delivers only marginal improvements.
These findings show that LoRA can deliver meaningful fairness gains with
minimal computation. We advocate broader adoption of community-informed PEFT,
the creation of larger queer-authored corpora, and richer evaluation suites
beyond WinoQueer, coupled with ongoing audits to keep LLMs inclusive.

</details>


### [37] [Innocence in the Crossfire: Roles of Skip Connections in Jailbreaking Visual Language Models](https://arxiv.org/abs/2507.13761)
*Palash Nandi,Maithili Joshi,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: VLM对提示极其敏感，多模态环境及巧妙设计的提示容易被利用生成有害内容，提出的skip-connection方法可加剧此问题，表明VLM存在严重安全隐患。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLM）的输出高度依赖于提示（prompt）如何设计，而细微的输入变化可能导致输出极大改变。因此，研究人员关注利用这种提示敏感性来生成不当内容的风险和成因。

Method: 系统性分析提示设计中三个离散要素在促使VLM生成不当内容（即“越狱”）中的作用，分别为：(a)详细视觉信息的引入，(b)对抗性样本的存在，(c)正向表述的开头短语。还提出了一种在VLM内部两层之间引入skip-connection的框架，并测试各种提示组合和样本数量对越狱成功率的影响。

Result: 在单模态输入（仅文本或仅图片）时，模型能较好区分良性与有害内容，但在多模态情境下，这种能力显著下降。上述三个要素各自都能独立完成越狱任务，且只需3个上下文样例即可诱导模型生成不当内容。所提出的skip-connection机制大幅提高了越狱成功率，即便仅用良性图片。趣味或表面无害的“meme”图片与有毒视觉内容一样，能诱发有害输出。

Conclusion: 视觉语言模型在多模态输入下存在微妙且复杂的安全脆弱性，特别是对提示设计极度敏感，易于被利用生成不当内容，甚至良性图像也可被攻击。

Abstract: Language models are highly sensitive to prompt formulations - small changes
in input can drastically alter their output. This raises a critical question:
To what extent can prompt sensitivity be exploited to generate inapt content?
In this paper, we investigate how discrete components of prompt design
influence the generation of inappropriate content in Visual Language Models
(VLMs). Specifically, we analyze the impact of three key factors on successful
jailbreaks: (a) the inclusion of detailed visual information, (b) the presence
of adversarial examples, and (c) the use of positively framed beginning
phrases. Our findings reveal that while a VLM can reliably distinguish between
benign and harmful inputs in unimodal settings (text-only or image-only), this
ability significantly degrades in multimodal contexts. Each of the three
factors is independently capable of triggering a jailbreak, and we show that
even a small number of in-context examples (as few as three) can push the model
toward generating inappropriate outputs. Furthermore, we propose a framework
that utilizes a skip-connection between two internal layers of the VLM, which
substantially increases jailbreak success rates, even when using benign images.
Finally, we demonstrate that memes, often perceived as humorous or harmless,
can be as effective as toxic visuals in eliciting harmful content, underscoring
the subtle and complex vulnerabilities of VLMs.

</details>


### [38] [An Enhanced Model-based Approach for Short Text Clustering](https://arxiv.org/abs/2507.13793)
*Enhao Cheng,Shoujia Zhang,Jianhua Yin,Xuemeng Song,Tian Gan,Liqiang Nie*

Main category: cs.CL

TL;DR: 该文提出了高效的短文本聚类算法GSDMM及其改进版GSDMM+，在解决短文本聚类的稀疏、高维和聚类粒度等问题中表现突出，实验结果优于多种主流方法，且模型代码已开源。


<details>
  <summary>Details</summary>
Motivation: 随着社交媒体如Twitter、Google+和Facebook的普及，短文本聚类变得越来越重要。然而，由于短文本本身存在稀疏性、规模大和高维等问题，加之现有深度表示学习对计算资源需求高，短文本聚类任务面临诸多挑战。该研究旨在针对这些挑战提出高效、有效的解决办法。

Method: 本文提出了针对Dirichlet Multinomial Mixture（DMM）模型的collapsed Gibbs Sampling算法（GSDMM），能够有效应对短文本的稀疏性与高维问题，并能为每个聚类确定代表性词语。在此基础上，提出了改进方法GSDMM+，通过减少初始化噪声、基于熵自适应调整词权值，实现更细粒度的聚类效果。同时，利用聚类合并策略优化聚类粒度，使预测分布更贴合真实类别分布。

Result: 通过与经典方法和最新技术进行大量实验对比，本文提出的方法在效率和效果上均取得了显著提升。GSDMM+方法在细粒度聚类和揭示主题信息方面表现优越，能够更好地反映短文本隐藏的真实结构。

Conclusion: GSDMM及其扩展版GSDMM+方法有效缓解了短文本聚类中的稀疏性、高维性和聚类粒度问题，具有较高的聚类性能和计算效率。相关模型源码已公开，便于学术交流和后续研究。

Abstract: Short text clustering has become increasingly important with the popularity
of social media like Twitter, Google+, and Facebook. Existing methods can be
broadly categorized into two paradigms: topic model-based approaches and deep
representation learning-based approaches. This task is inherently challenging
due to the sparse, large-scale, and high-dimensional characteristics of the
short text data. Furthermore, the computational intensity required by
representation learning significantly increases the running time. To address
these issues, we propose a collapsed Gibbs Sampling algorithm for the Dirichlet
Multinomial Mixture model (GSDMM), which effectively handles the sparsity and
high dimensionality of short texts while identifying representative words for
each cluster. Based on several aspects of GSDMM that warrant further
refinement, we propose an improved approach, GSDMM+, designed to further
optimize its performance. GSDMM+ reduces initialization noise and adaptively
adjusts word weights based on entropy, achieving fine-grained clustering that
reveals more topic-related information. Additionally, strategic cluster merging
is employed to refine clustering granularity, better aligning the predicted
distribution with the true category distribution. We conduct extensive
experiments, comparing our methods with both classical and state-of-the-art
approaches. The experimental results demonstrate the efficiency and
effectiveness of our methods. The source code for our model is publicly
available at https://github.com/chehaoa/VEMC.

</details>


### [39] [Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models](https://arxiv.org/abs/2507.13827)
*Hosein Azarbonyad,Zi Long Zhu,Georgios Cheirmpos,Zubair Afzal,Vikrant Yadav,Georgios Tsatsaronis*

Main category: cs.CL

TL;DR: 该文提出两种自动生成科学文献主旨QA对的方法，发现知识图谱和微调是提升主旨抽取质量的关键。


<details>
  <summary>Details</summary>
Motivation: 学者在决定阅读或引用一篇文章时，往往需要迅速了解其主要思想和贡献。因而需要高效提取科学文献的核心内容。该研究旨在通过QA对形式，自动化抽取文章的核心概念与贡献。

Method: 提出两种自动生成QA对的方法：1）仅用LLM根据文章挑选突出段落，生成问题并按答案质量排序后生成答案；2）通过实体关系（ER）抽取模型微调并构建知识图谱（KG），利用显著三元组抽取算法，结合TF-IDF风格的中心性度量选择重要三元组，并在KG基础上生成QA。两种方法的QA均由领域专家用预设指标评价。

Result: KG方法能有效捕捉文章主要思想；实体关系抽取模型在科学文献上的微调对于高质量三元组的抽取至关重要。

Conclusion: 基于知识图谱的QA生成在科学文献主旨捕捉中更为有效，模型微调对三元组抽取质量有关键作用。

Abstract: When deciding to read an article or incorporate it into their research,
scholars often seek to quickly identify and understand its main ideas. In this
paper, we aim to extract these key concepts and contributions from scientific
articles in the form of Question and Answer (QA) pairs. We propose two distinct
approaches for generating QAs. The first approach involves selecting salient
paragraphs, using a Large Language Model (LLM) to generate questions, ranking
these questions by the likelihood of obtaining meaningful answers, and
subsequently generating answers. This method relies exclusively on the content
of the articles. However, assessing an article's novelty typically requires
comparison with the existing literature. Therefore, our second approach
leverages a Knowledge Graph (KG) for QA generation. We construct a KG by
fine-tuning an Entity Relationship (ER) extraction model on scientific articles
and using it to build the graph. We then employ a salient triplet extraction
method to select the most pertinent ERs per article, utilizing metrics such as
the centrality of entities based on a triplet TF-IDF-like measure. This measure
assesses the saliency of a triplet based on its importance within the article
compared to its prevalence in the literature. For evaluation, we generate QAs
using both approaches and have them assessed by Subject Matter Experts (SMEs)
through a set of predefined metrics to evaluate the quality of both questions
and answers. Our evaluations demonstrate that the KG-based approach effectively
captures the main ideas discussed in the articles. Furthermore, our findings
indicate that fine-tuning the ER extraction model on our scientific corpus is
crucial for extracting high-quality triplets from such documents.

</details>


### [40] [The Expressions of Depression and Anxiety in Chinese Psycho-counseling: Usage of First-person Singular Pronoun and Negative Emotional Words](https://arxiv.org/abs/2507.13839)
*Lizhi Ma,Tong Zhao,Shuai Zhang,Nirui Song,Hongliang He,Anqi Li,Ran Feng,Huachuan Qiu,Jingsong Ma,Zhenzhong Lan*

Main category: cs.CL

TL;DR: 在中文心理咨询中，负面情感词频与来访者抑郁、焦虑显著相关，但第一人称单数代词未出现类似关联，提示文化语境和对话互动影响心理语言标记。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨中文心理咨询互动中，语言表达与抑郁、焦虑等心理状态之间的关系，尤其关注第一人称单数代词和负面情感词的使用。此前大多研究基于英语语境，对于中文情境下的具体表现尚不明确，因此需要填补该领域知识空白。

Method: 研究基于735次在线心理咨询对话语料库，采用LIWC（Linguistic Inquiry and Word Count）软件对语言模式进行量化分析，随后通过广义线性混合效应模型，评估不同语言特征与心理状态之间的相关性。

Result: 结果发现，负面情感词汇的频率与来访者的抑郁和焦虑程度显著正相关。但与以往主要基于英文研究的发现不同，第一人称单数代词的使用频率并未随心理状况有显著变化。

Conclusion: 研究显示文化和会话语境对心理健康交流中的语言使用具有复杂影响，在汉语语境下，负面情感词可作为抑郁、焦虑的重要语言标记，而第一人称单数代词则未表现出相同关联。该研究为理解不同文化背景下的心理语言标记及其在临床应用中的意义提供了新视角。

Abstract: This study explores the relationship between linguistic expressions and
psychological states of depression and anxiety within Chinese psycho-counseling
interactions, focusing specifically on the usage of first-person singular
pronouns and negative emotional words. Utilizing a corpus derived from 735
online counseling sessions, the analysis employed a general linear mixed-effect
model to assess linguistic patterns quantified by the Linguistic Inquiry and
Word Count (LIWC) software. Results indicate a significant positive correlation
between the frequency of negative emotional words and the severity of both
depressive and anxious states among clients. However, contrary to prior
findings predominantly derived from English-language contexts, the usage
frequency of first-person singular pronouns did not vary significantly with the
clients' psychological conditions. These outcomes are discussed within the
framework of cultural distinctions between collectivist Chinese contexts and
individualistic Western settings, as well as the interactive dynamics unique to
psycho-counseling conversations. The findings highlight the nuanced influence
of cultural and conversational contexts on language use in mental health
communications, providing insights into psycholinguistic markers relevant to
therapeutic practices in Chinese-speaking populations.

</details>


### [41] [Modeling Fair Play in Detective Stories with Language Models](https://arxiv.org/abs/2507.13841)
*Eitan Wagner,Renana Keydar,Omri Abend*

Main category: cs.CL

TL;DR: 本文提出并验证了评估推理小说“公正叙事”与意外性的概率框架，发现现有LLM生成故事难以平衡这两者，导致整体质量不足。


<details>
  <summary>Details</summary>
Motivation: 叙事艺术中，读者期望与故事意外性的平衡至关重要，推理小说尤为如此。公正叙事（fair play）强调作者与读者之间对谜题解答范围的隐性共识。该文旨在定量分析推理小说中的这种平衡关系，并借助概率框架评估故事品质，尤其是基于大语言模型（LLM）的生成文本。

Method: 论文提出了一个应用于推理小说的概率框架，并基于此精确定义了'公正叙事'及其量化指标。然后，将该框架应用于由LLM生成的推理故事，通过对故事连贯性（故事是否'合理'）与意外性（惊喜程度）的张力进行度量。

Result: 实验发现，LLM所生成的推理小说虽然具有一定的不可预测性（惊喜），但在“公正叙事”与意外之间的权衡表现不佳。这种失衡直接导致了生成故事整体质量较低。

Conclusion: 该研究通过概率框架，首次量化了推理小说中“公正叙事”和意外性的平衡，揭示了当前LLM生成推理故事普遍质量不高的根源在于未能妥善处理公平与惊喜之间的张力。

Abstract: Effective storytelling relies on a delicate balance between meeting the
reader's prior expectations and introducing unexpected developments. In the
domain of detective fiction, this tension is known as fair play, which includes
the implicit agreement between the writer and the reader as to the range of
possible resolutions the mystery story may have. In this work, we present a
probabilistic framework for detective fiction that allows us to define desired
qualities. Using this framework, we formally define fair play and design
appropriate metrics for it. Stemming from these definitions is an inherent
tension between the coherence of the story, which measures how much it ``makes
sense'', and the surprise it induces. We validate the framework by applying it
to LLM-generated detective stories. This domain is appealing since we have an
abundance of data, we can sample from the distribution generating the story,
and the story-writing capabilities of LLMs are interesting in their own right.
Results show that while LLM-generated stories may be unpredictable, they
generally fail to balance the trade-off between surprise and fair play, which
greatly contributes to their poor quality.

</details>


### [42] [InTraVisTo: Inside Transformer Visualisation Tool](https://arxiv.org/abs/2507.13858)
*Nicolò Brunello,Davide Rigamonti,Andrea Sassella,Vincenzo Scotti,Mark James Carman*

Main category: cs.CL

TL;DR: 论文介绍了InTraVisTo工具，可视化Transformer内部状态和信息流，有助于理解和分析大语言模型的生成推理过程。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）虽有强大推理能力，但实用性受其输出不可预测及行为与预期不符困扰。研究人员和实践者急需理解模型内部机制来提高可靠性和控制能力。

Method: 提出了一款可视化工具InTraVisTo，能展示Transformer每层的token嵌入并用Sankey图可视化各组件的信息流。这样可以跟踪每个token的生成过程和信息在模型内的流动。

Result: InTraVisTo实现了对Transformer内部状态的可视化和成分信息流追踪，使研究者能更好地理解LLM的计算与推理模式。

Conclusion: InTraVisTo为深入理解大语言模型的内部推理机制提供了新手段，对提升其可控性和实际应用具有积极意义。

Abstract: The reasoning capabilities of Large Language Models (LLMs) have increased
greatly over the last few years, as have their size and complexity.
Nonetheless, the use of LLMs in production remains challenging due to their
unpredictable nature and discrepancies that can exist between their desired
behavior and their actual model output. In this paper, we introduce a new tool,
InTraVisTo (Inside Transformer Visualisation Tool), designed to enable
researchers to investigate and trace the computational process that generates
each token in a Transformer-based LLM. InTraVisTo provides a visualization of
both the internal state of the Transformer model (by decoding token embeddings
at each layer of the model) and the information flow between the various
components across the different layers of the model (using a Sankey diagram).
With InTraVisTo, we aim to help researchers and practitioners better understand
the computations being performed within the Transformer model and thus to shed
some light on internal patterns and reasoning processes employed by LLMs.

</details>


### [43] [Label Unification for Cross-Dataset Generalization in Cybersecurity NER](https://arxiv.org/abs/2507.13870)
*Maciej Jalocha,Johan Hausted Schmidt,William Michelseen*

Main category: cs.CL

TL;DR: 网络安全NER标签不统一，数据集融合难。标签统一+BiLSTM泛化能力弱，多头/图模型效果提升有限，跨数据集迁移表现一般，亟需更优方法。


<details>
  <summary>Details</summary>
Motivation: 网络安全命名实体识别（NER）领域缺乏标准化标签，导致数据集难以整合和利用。提升不同数据集间可用性迫切需要标签统一。

Method: 对四个网络安全数据集进行粗粒度的标签统一，并通过BiLSTM模型进行成对的跨数据集评估。对预测结果进行定性分析，探索错误、局限和数据集之间的差异。此外，提出多头模型和基于图的迁移模型，进一步尝试缓解统一标签带来的局限性。

Result: 模型在统一数据集上训练后，在不同数据集上的泛化能力较弱。多头模型在权重共享下比统一训练只有轻微提升，基于图的迁移模型（构建在BERT-base-NER上）与普通BERT-base-NER相比没有显著性能提升。

Conclusion: 当前标签统一策略未能实现跨数据集的良好泛化，不同架构改进也未能带来明显性能提升，显示出网络安全NER领域在数据整合与建模上的挑战。

Abstract: The field of cybersecurity NER lacks standardized labels, making it
challenging to combine datasets. We investigate label unification across four
cybersecurity datasets to increase data resource usability. We perform a
coarse-grained label unification and conduct pairwise cross-dataset evaluations
using BiLSTM models. Qualitative analysis of predictions reveals errors,
limitations, and dataset differences. To address unification limitations, we
propose alternative architectures including a multihead model and a graph-based
transfer model. Results show that models trained on unified datasets generalize
poorly across datasets. The multihead model with weight sharing provides only
marginal improvements over unified training, while our graph-based transfer
model built on BERT-base-NER shows no significant performance gains compared
BERT-base-NER.

</details>


### [44] [Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis of Methodologies](https://arxiv.org/abs/2507.13875)
*Carlos Mena,Pol Serra,Jacobo Romero,Abir Messaoudi,Jose Giraldo,Carme Armentano-Oller,Rodolfo Zevallos,Ivan Meza,Javier Hernando*

Main category: cs.CL

TL;DR: 为解决加泰罗尼亚语-西班牙语代码切换语音识别中的数据短缺难题，作者通过合成数据、拼接单语及语言token策略，提升了ASR性能，最佳策略为“少量合成数据+主语token”，并开源相关模型。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别（ASR）在处理代码切换（CS）语言——即在同一对话中交替使用多种语言——时，面临训练数据稀缺及语言相似性挑战。缺乏专门的CS语料库导致ASR系统表现受限，尤以多语种社会（如加泰罗尼亚语-西班牙语广泛代码切换的环境）为甚。该问题尤其突出，因为现实世界中的代码切换情形与现有数据集差异较大。

Method: 作者提出并比较三种提升加泰罗尼亚语-西班牙语代码切换ASR模型的方法：（1）生成合成CS数据；（2）拼接单语语音数据；（3）利用真实CS数据并加入语言提示（tokens）。这些CS数据从加泰罗尼亚语语音语料中提取，并在OpenAI Whisper模型基础上进行微调。最终模型发布于Hugging Face。

Result: 结果显示，将少量合成CS数据与主导语言token组合进行微调，能取得最佳的转录性能。该方法优于单独使用真实CS或拼接单语数据的方法。

Conclusion: 通过合成与真实数据结合使用，并引入语言token，可以显著提升代码切换（以加泰罗尼亚语-西班牙语为例）语音识别的性能。作者的工作为多语种社会CS语音识别系统的改进提供了有效的解决方案。

Abstract: Code-switching (CS), the alternating use of two or more languages, challenges
automatic speech recognition (ASR) due to scarce training data and linguistic
similarities. The lack of dedicated CS datasets limits ASR performance, as most
models rely on monolingual or mixed-language corpora that fail to reflect
real-world CS patterns. This issue is critical in multilingual societies where
CS occurs in informal and formal settings. A key example is Catalan-Spanish CS,
widely used in media and parliamentary speeches. In this work, we improve ASR
for Catalan-Spanish CS by exploring three strategies: (1) generating synthetic
CS data, (2) concatenating monolingual audio, and (3) leveraging real CS data
with language tokens. We extract CS data from Catalan speech corpora and
fine-tune OpenAI's Whisper models, making them available on Hugging Face.
Results show that combining a modest amount of synthetic CS data with the
dominant language token yields the best transcription performance.

</details>


### [45] [Using LLMs to identify features of personal and professional skills in an open-response situational judgment test](https://arxiv.org/abs/2507.13881)
*Cole Walsh,Rodica Ivan,Muhammad Zafar Iqbal,Colleen Robb*

Main category: cs.CL

TL;DR: 本文提出用大型语言模型替代人工评分以提取情境判断测试中与结构相关的技能特征，解决了自动化评分的结构效度难题，为个人和职业能力大规模测评铺路。


<details>
  <summary>Details</summary>
Motivation: 学术项目日益重视个人和职业技能，认为其与技术专长同等重要，用于学生未来职业发展。但这些技能的测量与发展需要可扩展的系统。情境判断测试（SJT）是标准化测量这些技能的一种方案，但其开放式作答评估依赖人工评分，难以大规模应用。以往用自然语言处理（NLP）方法自动评分效果有限，缺乏结构效度。

Method: 研究提出用大型语言模型（LLMs）从SJT作答中提取与结构相关的特征，旨在提升自动评分的效度与可扩展性，以Casper SJT为例进行方法验证。

Result: 结果展示了该方法在从SJT作答中提取结构相关特征方面的有效性，为未来自动化个人和职业技能评分的进一步发展奠定了基础。

Conclusion: LLMs能有效提取SJT作答中结构相关的特征，是推进大规模自动评分系统的有力工具，有助于更好地评估和发展学生的个人与职业技能。

Abstract: Academic programs are increasingly recognizing the importance of personal and
professional skills and their critical role alongside technical expertise in
preparing students for future success in diverse career paths. With this
growing demand comes the need for scalable systems to measure, evaluate, and
develop these skills. Situational Judgment Tests (SJTs) offer one potential
avenue for measuring these skills in a standardized and reliable way, but
open-response SJTs have traditionally relied on trained human raters for
evaluation, presenting operational challenges to delivering SJTs at scale. Past
attempts at developing NLP-based scoring systems for SJTs have fallen short due
to issues with construct validity of these systems. In this article, we explore
a novel approach to extracting construct-relevant features from SJT responses
using large language models (LLMs). We use the Casper SJT to demonstrate the
efficacy of this approach. This study sets the foundation for future
developments in automated scoring for personal and professional skills.

</details>


### [46] [Political Leaning and Politicalness Classification of Texts](https://arxiv.org/abs/2507.13913)
*Matous Volf,Jakub Simko*

Main category: cs.CL

TL;DR: 本文通过汇总和扩展多个数据集，提升了政治文本自动分类模型的泛化能力，新方法对不同类型数据适应性更强。


<details>
  <summary>Details</summary>
Motivation: 当前基于transformer的文本政治倾向与政治性自动分类方法，在不同分布文本上的泛化性能较差，缺乏统一、多样的数据集来评估与训练模型。

Method: 将12个政治倾向分类数据集合并、扩展18个现有数据集标注政治性新标签，构建多元化数据集。采用leave-one-in和leave-one-out评测现有模型并训练新模型提升泛化能力。

Result: 新建的多样化数据集以及训练的新模型在跨数据集场景下表现更好，显著优于以往孤立开发的模型。

Conclusion: 通过组合多个数据集和创建新的标注，提升了文本政治倾向和政治性自动分类任务中模型的泛化能力。提出的数据集和方法能更好适应不同分布的数据，较现有模型表现更优。

Abstract: This paper addresses the challenge of automatically classifying text
according to political leaning and politicalness using transformer models. We
compose a comprehensive overview of existing datasets and models for these
tasks, finding that current approaches create siloed solutions that perform
poorly on out-of-distribution texts. To address this limitation, we compile a
diverse dataset by combining 12 datasets for political leaning classification
and creating a new dataset for politicalness by extending 18 existing datasets
with the appropriate label. Through extensive benchmarking with leave-one-in
and leave-one-out methodologies, we evaluate the performance of existing models
and train new ones with enhanced generalization capabilities.

</details>


### [47] [The Levers of Political Persuasion with Conversational AI](https://arxiv.org/abs/2507.13919)
*Kobi Hackenburg,Ben M. Tappin,Luke Hewitt,Ed Saunders,Sid Black,Hause Lin,Catherine Fist,Helen Margetts,David G. Rand,Christopher Summerfield*

Main category: cs.CL

TL;DR: 后训练和提示工程显著提升了AI的说服力，但也降低了其事实准确性。AI对人类信念的影响并不主要来自模型规模或个性化，而源自其信息调配能力。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在回应社会上对于对话型AI（如大型语言模型LLMs）可能对人类信念产生强大影响的担忧。尤其关注AI在说服力上的提升是否有现实根据，以及这些提升的来源。

Method: 作者通过三项大规模实验（样本量为76,977），使用19种不同LLM，包括部分专门为了提升“说服力”进行了后训练的模型，针对707个政治议题进行测试。统计模型产生的466,769个主张的事实准确性，并分析不同后训练、提示（prompting）、个性化和模型规模对说服力的影响。

Result: 结果显示，后训练与提示工程提升AI说服力的效果比个性化或模型规模扩展更显著，分别提升了51%和27%。但提升说服力的同时，事实准确率却系统性下降。AI说服力的提升主要源于其快速检索和战略性运用信息的能力。

Conclusion: 当前及可预见的未来，对话型AI的说服力主要受后训练和提示方法影响，而非个性化或模型规模，且提升说服力的同时，事实准确率会被削弱。这一发现对AI社会影响的担忧进行了实证检验。

Abstract: There are widespread fears that conversational AI could soon exert
unprecedented influence over human beliefs. Here, in three large-scale
experiments (N=76,977), we deployed 19 LLMs-including some post-trained
explicitly for persuasion-to evaluate their persuasiveness on 707 political
issues. We then checked the factual accuracy of 466,769 resulting LLM claims.
Contrary to popular concerns, we show that the persuasive power of current and
near-future AI is likely to stem more from post-training and prompting
methods-which boosted persuasiveness by as much as 51% and 27%
respectively-than from personalization or increasing model scale. We further
show that these methods increased persuasion by exploiting LLMs' unique ability
to rapidly access and strategically deploy information and that, strikingly,
where they increased AI persuasiveness they also systematically decreased
factual accuracy.

</details>


### [48] [Marcel: A Lightweight and Open-Source Conversational Agent for University Student Support](https://arxiv.org/abs/2507.13937)
*Jan Trienes,Anastasiia Derzhanskaia,Roland Schwarzkopf,Markus Mühling,Jörg Schlötterer,Christin Seifert*

Main category: cs.CL

TL;DR: 本文提出了一个面向院校招生咨询的对话系统Marcel，结合FAQ检索显著提升了答复的准确性和适用性，在用户实际使用中得到验证。


<details>
  <summary>Details</summary>
Motivation: 为提高招生咨询效率，减轻校方工作人员负担，并为学生提供准确、个性化的入学相关答复。

Method: 采用检索增强生成（retrieval-augmented generation）结合FAQ检索模块，通过将用户问题映射到知识库条目，提升检索效果，并对系统架构与各组件进行技术评测和实际部署分析。

Result: 提出的FAQ检索方法优于常规稠密或混合检索，系统在实际院校环境下表现良好，易于在资源有限的学术环境部署。

Conclusion: Marcel系统能够有效支持学生招生相关咨询，减少学校工作人员的工作量，并提供个性化和可验证的信息，适合资源有限的学校部署。

Abstract: We present Marcel, a lightweight and open-source conversational agent
designed to support prospective students with admission-related inquiries. The
system aims to provide fast and personalized responses, while reducing workload
of university staff. We employ retrieval-augmented generation to ground answers
in university resources and to provide users with verifiable, contextually
relevant information. To improve retrieval quality, we introduce an FAQ
retriever that maps user questions to knowledge-base entries, allowing
administrators to steer retrieval, and improving over standard dense/hybrid
retrieval strategies. The system is engineered for easy deployment in
resource-constrained academic settings. We detail the system architecture,
provide a technical evaluation of its components, and report insights from a
real-world deployment.

</details>


### [49] [Exploiting Primacy Effect To Improve Large Language Models](https://arxiv.org/abs/2507.13949)
*Bianca Raimondi,Maurizio Gabbrielli*

Main category: cs.CL

TL;DR: 本文发现微调后的大语言模型在处理多项选择题时首因偏置增强，作者通过基于语义相似性重排选项，有效提升了模型表现，并提出偏见既是挑战也是机遇，对未来NLP模型设计具有启示意义。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在多项自然语言处理任务中得到了广泛应用，但其在处理多项选择题时可能受到类人位置偏置（如首因效应）的影响，影响模型输出的准确性。作者有意研究LLMs中首因偏置的影响及其对性能的影响。

Method: 首先通过实验证明微调后LLM的首因偏置被增强，然后提出一种基于与查询语义相似性对选项重排序的方法，以利用该偏置提升模型表现，并且该方法不需要知道正确答案。

Result: 实验结果显示，这种基于语义相似性进行选项重排序的策略能显著提升多项选择问答（MCQA）任务中的模型表现。

Conclusion: 首因偏置虽然是一种偏见，但若加以合理利用，也能成为提升模型性能的策略。这一发现为偏见感知的模型设计和NLP应用带来启发。

Abstract: Large Language Models (LLMs) have become essential in many Natural Language
Processing (NLP) tasks, leveraging extensive pre-training and fine-tuning to
achieve high accuracy. However, like humans, LLMs exhibit biases, particularly
positional biases such as primacy and recency effects, which can influence the
accuracy of the answers. The primacy effect-where items presented first are
more likely to be remembered or selected-plays a key role in Multiple Choice
Question Answering (MCQA), where the order of answer options can affect
prediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We
first show that fine-tuning amplifies this bias, probably due to exposure to
human-like patterns. Hence, we strategically leverage this effect by reordering
response options based on semantic similarity to the query, without requiring
knowledge of the correct answer. Our experimental results show that this
approach significantly improves performance in MCQA. More generally, our
findings underscore the dual nature of biases as both challenges and
opportunities, offering insights for bias-aware model design and NLP
applications.

</details>


### [50] [Bottom-up Domain-specific Superintelligence: A Reliable Knowledge Graph is What We Need](https://arxiv.org/abs/2507.13966)
*Bhishma Dedhia,Yuval Kansal,Niraj K. Jha*

Main category: cs.CL

TL;DR: 本文提出利用知识图谱原语合成任务，对语言模型进行领域推理强能力训练。以医学为例，训练得出的QwQ-Med-3模型在多个医学推理评测中全面超越现有模型，验证了底层知识原语组合式学习的有效性。


<details>
  <summary>Details</summary>
Motivation: 以往语言模型在跨领域泛化能力上较强，但在特定领域内缺乏深度专家级推理能力。这是因为训练通常采用自上而下、泛化的大规模语料，而未能针对领域知识的构成性进行优化。文章试图探索如何通过自下而上的方式，诱导模型学习和组合领域内简单知识原语，提升专用领域推理能力。

Method: 作者提出以知识图谱（Knowledge Graph, KG）为基础，自动生成任务，并用由KG原语组成的、可追踪推理路径的任务集对语言模型进行微调。在医学领域，基于医学知识图谱，构建了24000个推理任务及思考轨迹，并据此将QwQ-32B模型微调为QwQ-Med-3。此外，作者还提出ICD-Bench评测集，量化模型在15个医学子领域的推理能力。

Result: QwQ-Med-3模型在ICD-Bench各分类下表现优于当前最先进的推理模型，尤其在最具挑战性的任务上展现较大优势。同时，在医学问答基准数据集上，QwQ-Med-3能够有效将新获得的专业知识迁移并提升基础模型性能。

Conclusion: 基于知识图谱原语的自动任务生成和微调方法能够极大提升语言模型在专业领域的推理和组合能力，为实现具有效率的、可组合的领域超级智能体提供了实践依据，对未来构建领域专用人工智能的路线具有启示意义。

Abstract: Language models traditionally used for cross-domain generalization have
recently demonstrated task-specific reasoning. However, their top-down training
approach on general corpora is insufficient for acquiring abstractions needed
for deep domain expertise. This may require a bottom-up approach that acquires
expertise by learning to compose simple domain concepts into more complex ones.
A knowledge graph (KG) provides this compositional structure, where domain
primitives are represented as head-relation-tail edges and their paths encode
higher-level concepts. We present a task generation pipeline that synthesizes
tasks directly from KG primitives, enabling models to acquire and compose them
for reasoning. We fine-tune language models on the resultant KG-grounded
curriculum to demonstrate domain-specific superintelligence. While broadly
applicable, we validate our approach in medicine, where reliable KGs exist.
Using a medical KG, we curate 24,000 reasoning tasks paired with thinking
traces derived from diverse medical primitives. We fine-tune the QwQ-32B model
on this curriculum to obtain QwQ-Med-3 that takes a step towards medical
superintelligence. We also introduce ICD-Bench, an evaluation suite to quantify
reasoning abilities across 15 medical domains. Our experiments demonstrate that
QwQ-Med-3 significantly outperforms state-of-the-art reasoning models on
ICD-Bench categories. Further analysis reveals that QwQ-Med-3 utilizes acquired
primitives to widen the performance gap on the hardest tasks of ICD-Bench.
Finally, evaluation on medical question-answer benchmarks shows that QwQ-Med-3
transfers acquired expertise to enhance the base model's performance. While the
industry's approach to artificial general intelligence (AGI) emphasizes broad
expertise, we envision a future in which AGI emerges from the composable
interaction of efficient domain-specific superintelligent agents.

</details>


### [51] [Open Automatic Speech Recognition Models for Classical and Modern Standard Arabic](https://arxiv.org/abs/2507.13977)
*Lilit Grigoryan,Nikolay Karpov,Enas Albasiri,Vitaly Lavrukhin,Boris Ginsburg*

Main category: cs.CL

TL;DR: 本文提出通用阿拉伯语语音与文本处理方法，基于FastConformer架构为标准和古典阿拉伯语训练了领先的ASR模型，并实现了开源。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语作为世界上使用最广泛的语言之一，其自动语音识别（ASR）系统的开发因语言的复杂性而面临重大挑战，目前公开的阿拉伯语ASR模型数量有限，且多聚焦于标准阿拉伯语（MSA），对语言变体关注不足。

Method: 提出了一种通用的阿拉伯语语音与文本处理方法，并基于FastConformer架构训练了两个新模型：一个专为MSA设计，另一个为首个同时适用于MSA和古典阿拉伯语（CA）的统一公开模型。

Result: MSA模型在相关数据集上达到了新的SOTA性能基准；统一模型在带元音符号（diacritics）的CA上取得了SOTA准确率，且对MSA依然表现优秀。

Conclusion: 该研究突破了阿拉伯语ASR建模的局限，首次提出了支持MSA和CA的统一公用模型，并开源了所有模型和训练流程，有助于推动该领域的发展并促进可复现性。

Abstract: Despite Arabic being one of the most widely spoken languages, the development
of Arabic Automatic Speech Recognition (ASR) systems faces significant
challenges due to the language's complexity, and only a limited number of
public Arabic ASR models exist. While much of the focus has been on Modern
Standard Arabic (MSA), there is considerably less attention given to the
variations within the language. This paper introduces a universal methodology
for Arabic speech and text processing designed to address unique challenges of
the language. Using this methodology, we train two novel models based on the
FastConformer architecture: one designed specifically for MSA and the other,
the first unified public model for both MSA and Classical Arabic (CA). The MSA
model sets a new benchmark with state-of-the-art (SOTA) performance on related
datasets, while the unified model achieves SOTA accuracy with diacritics for CA
while maintaining strong performance for MSA. To promote reproducibility, we
open-source the models and their training recipes.

</details>


### [52] [Efficient Temporal Tokenization for Mobility Prediction with Large Language Models](https://arxiv.org/abs/2507.14017)
*Haoyu He,Haozheng Luo,Yan Chen,Qi R. Wang*

Main category: cs.CL

TL;DR: RHYTHM通过轨迹层次token化与冻结大语言模型，有效提升人类移动预测准确率，并减少计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有的人类移动轨迹建模在捕捉时空依赖和计算效率之间存在矛盾。当前主流方法处理长序列时计算代价高，而且难以有效地建模日常与周度的层次依赖。

Method: 提出RHYTHM：利用大语言模型，将轨迹分割为日常片段，转换为离散token，通过层次化注意力机制建模日常与周度依赖。token还结合预计算的大语言模型embedding以增强表达能力，同时大语言模型主体被冻结以降低计算负担。

Result: 在三个真实世界数据集上，准确率提升2.4%，周末提升5.0%，训练时间减少24.6%。

Conclusion: RHYTHM在保证表达能力的同时，大幅提升了计算效率，在人类移动预测任务中优于现有方法。

Abstract: We introduce RHYTHM (Reasoning with Hierarchical Temporal Tokenization for
Human Mobility), a framework that leverages large language models (LLMs) as
spatio-temporal predictors and trajectory reasoners. RHYTHM partitions
trajectories into daily segments encoded as discrete tokens with hierarchical
attention, capturing both daily and weekly dependencies while substantially
reducing the sequence length. Token representations are enriched with
pre-computed prompt embeddings via a frozen LLM, enhancing the model's ability
to capture interdependencies without extensive computational overhead. By
freezing the LLM backbone, RHYTHM achieves significant computational
efficiency. Evaluation on three real-world datasets demonstrates a 2.4%
improvement in accuracy, 5.0% increase on weekends, and 24.6% reduction in
training time compared to state-of-the-art methods.

</details>


### [53] [CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis](https://arxiv.org/abs/2507.14022)
*Jianfei Li,Kevin Kam Fung Yuen*

Main category: cs.CL

TL;DR: 提出了一种综合多指标权重的分类模型优选框架（CPC-CMS），实验验证了其在文本情感分析任务中的有效性和通用性。


<details>
  <summary>Details</summary>
Motivation: 在文本情感分析领域，选择最佳分类模型通常依赖单一评价指标，忽略了多指标权重及复杂实际需求。为此，需要一个多指标综合分析的模型选择框架。

Method: 提出了CPC-CMS（基于认知成对比较分类模型选择）框架，利用专家知识对准确率、精确度、召回率、F1、特异性、MCC、Kappa和效率等多项指标进行加权；将多个主流分类模型的评估得分和权重形成加权决策矩阵，进行多维度模型优选。

Result: 在三个社交媒体开放数据集上测试，去除时间消耗时，ALBERT模型效果最好；考虑时间消耗后，不同数据集最佳模型不同。框架可适用于其他分类领域。

Conclusion: CPC-CMS能综合多评价指标和权重，更科学地选择文本情感分析分类模型，并具有通用性。

Abstract: This study proposes the Cognitive Pairwise Comparison Classification Model
Selection (CPC-CMS) framework for document-level sentiment analysis. The CPC,
based on expert knowledge judgment, is used to calculate the weights of
evaluation criteria, including accuracy, precision, recall, F1-score,
specificity, Matthews Correlation Coefficient (MCC), Cohen's Kappa (Kappa), and
efficiency. Naive Bayes, Linear Support Vector Classification (LSVC), Random
Forest, Logistic Regression, Extreme Gradient Boosting (XGBoost), Long
Short-Term Memory (LSTM), and A Lite Bidirectional Encoder Representations from
Transformers (ALBERT) are chosen as classification baseline models. A weighted
decision matrix consisting of classification evaluation scores with respect to
criteria weights, is formed to select the best classification model for a
classification problem. Three open datasets of social media are used to
demonstrate the feasibility of the proposed CPC-CMS. Based on our simulation,
for evaluation results excluding the time factor, ALBERT is the best for the
three datasets; if time consumption is included, no single model always
performs better than the other models. The CPC-CMS can be applied to the other
classification applications in different areas.

</details>


### [54] [Evaluating the Effectiveness of Cost-Efficient Large Language Models in Benchmark Biomedical Tasks](https://arxiv.org/abs/2507.14045)
*Israt Jahan,Md Tahmid Rahman Laskar,Chun Peng,Jimmy Huang*

Main category: cs.CL

TL;DR: 本文系统评估了多个主流闭源与开源生物医学LLM在文本和图像任务中的表现，发现没有万能模型，开源模型有显著优势，为应用选择提供参考。


<details>
  <summary>Details</summary>
Motivation: 当前生物医学领域需要有效的大型语言模型应用于各类文本与图像任务，但尚不清楚各种主流模型在具体任务中的表现及其适用性。

Method: 系统评估了多种闭源和开源的大型语言模型，涵盖生物医学文本分类、生成、问答和多模态图像处理等任务。通过对比分析不同LLM在各类任务上的表现。

Result: 多种模型在不同任务上表现突出，无一模型在所有任务均为最佳。开源模型有时优于闭源模型，并提供额外好处，如速度和隐私。

Conclusion: 没有任何一种大型语言模型（LLM）能够在所有生物医学任务中都表现最佳。不同模型依赖具体任务，各有优势。开源LLM在很多任务上取得了与闭源LLM相当甚至更好的表现，并具备更快推理和更好隐私等优势。

Abstract: This paper presents a comprehensive evaluation of cost-efficient Large
Language Models (LLMs) for diverse biomedical tasks spanning both text and
image modalities. We evaluated a range of closed-source and open-source LLMs on
tasks such as biomedical text classification and generation, question
answering, and multimodal image processing. Our experimental findings indicate
that there is no single LLM that can consistently outperform others across all
tasks. Instead, different LLMs excel in different tasks. While some
closed-source LLMs demonstrate strong performance on specific tasks, their
open-source counterparts achieve comparable results (sometimes even better),
with additional benefits like faster inference and enhanced privacy. Our
experimental results offer valuable insights for selecting models that are
optimally suited for specific biomedical applications.

</details>


### [55] [Collaborative Rational Speech Act: Pragmatic Reasoning for Multi-Turn Dialog](https://arxiv.org/abs/2507.14063)
*Lautaro Estienne,Gabriel Ben Zenou,Nona Naderi,Jackie Cheung,Pablo Piantanida*

Main category: cs.CL

TL;DR: 本文提出了CRSA模型，基于信息理论拓展RSA框架，使AI在多轮协作对话中达成更好的合作和理解。实验证明其在基准任务中效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有RSA及其扩展在多轮、协作语境下难以扩展，无法满足AI协作时需对共享目标和信念推理的需求，因此需要更有效的对话推理模型。

Method: 提出CRSA（Collaborative Rational Speech Act）模型，用信息理论（率失真理论）中的gain函数扩展RSA框架，适用于多轮、协作场景。设计了referential games和医疗领域的模板化医患对话实验验证方法。

Result: 经过对比实验证明，CRSA在referential games和医疗对话任务中均优于基线，表现出更一致、可解释和协作性的对话行为。

Conclusion: CRSA模型能让AI在多轮协作对话中表现出更一致、可解释和合作的行为，有望推动更具社会意识和实用性的语言智能体发展。

Abstract: As AI systems take on collaborative roles, they must reason about shared
goals and beliefs-not just generate fluent language. The Rational Speech Act
(RSA) framework offers a principled approach to pragmatic reasoning, but
existing extensions face challenges in scaling to multi-turn, collaborative
scenarios. In this paper, we introduce Collaborative Rational Speech Act
(CRSA), an information-theoretic (IT) extension of RSA that models multi-turn
dialog by optimizing a gain function adapted from rate-distortion theory. This
gain is an extension of the gain model that is maximized in the original RSA
model but takes into account the scenario in which both agents in a
conversation have private information and produce utterances conditioned on the
dialog. We demonstrate the effectiveness of CRSA on referential games and
template-based doctor-patient dialogs in the medical domain. Empirical results
show that CRSA yields more consistent, interpretable, and collaborative
behavior than existing baselines-paving the way for more pragmatic and socially
aware language agents.

</details>


### [56] [DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits](https://arxiv.org/abs/2507.14079)
*Garapati Keerthana,Manik Gupta*

Main category: cs.CL

TL;DR: DENSE系统用现有分散病历笔记驱动大模型，与临床文档逻辑对齐，自动生成高质量纵向进程记录，提升医疗数据集的叙述完整性和下游效能。


<details>
  <summary>Details</summary>
Motivation: 在电子健康记录（EHR）中，进程记录（progress notes）关键但罕见，重要的纵向病人信息因此缺失。现有大型EHR数据集如MIMIC-III中，进程记录覆盖率非常低，影响临床研究和实际应用。

Method: 提出DENSE系统，通过细粒度笔记分类和时间对齐机制，整合同一病人不同时间点的多种病历记录。系统采用检索策略，收集当前和既往病程相关内容，驱动大语言模型（LLM）生成临床连贯且有时序感知的进程记录。

Result: 在包含完整进程记录的多次就诊患者上评估DENSE，生成的笔记实现了优于原始笔记的纵向一致性，时间对齐比达到1.089。同时提升了下游任务如摘要、预测建模和临床决策支持的表现。

Conclusion: DENSE系统通过利用现有异构病历笔记，重建高质量、时序一致的进程记录，提高了大模型笔记合成能力，为实际医疗场景中的数据利用与临床决策支持提供了有效支持。

Abstract: Progress notes are among the most clinically meaningful artifacts in an
Electronic Health Record (EHR), offering temporally grounded insights into a
patient's evolving condition, treatments, and care decisions. Despite their
importance, they are severely underrepresented in large-scale EHR datasets. For
instance, in the widely used Medical Information Mart for Intensive Care III
(MIMIC-III) dataset, only about $8.56\%$ of hospital visits include progress
notes, leaving gaps in longitudinal patient narratives. In contrast, the
dataset contains a diverse array of other note types, each capturing different
aspects of care.
  We present DENSE (Documenting Evolving Progress Notes from Scattered
Evidence), a system designed to align with clinical documentation workflows by
simulating how physicians reference past encounters while drafting progress
notes. The system introduces a fine-grained note categorization and a temporal
alignment mechanism that organizes heterogeneous notes across visits into
structured, chronological inputs. At its core, DENSE leverages a clinically
informed retrieval strategy to identify temporally and semantically relevant
content from both current and prior visits. This retrieved evidence is used to
prompt a large language model (LLM) to generate clinically coherent and
temporally aware progress notes.
  We evaluate DENSE on a curated cohort of patients with multiple visits and
complete progress note documentation. The generated notes demonstrate strong
longitudinal fidelity, achieving a temporal alignment ratio of $1.089$,
surpassing the continuity observed in original notes. By restoring narrative
coherence across fragmented documentation, our system supports improved
downstream tasks such as summarization, predictive modeling, and clinical
decision support, offering a scalable solution for LLM-driven note synthesis in
real-world healthcare settings.

</details>


### [57] [Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track](https://arxiv.org/abs/2507.14096)
*Brian Ondov,William Xia,Kush Attal,Ishita Unde,Jerry He,Hoa Dang,Ian Soboroff,Dina Demner-Fushman*

Main category: cs.CL

TL;DR: PLABA赛道验证了大语言模型能有效将生物医学文献通俗化，但在表达简练和自动评价等方面还有不足，需继续改进。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型有望将专业生物医学知识普及给大众，但其输出不可预测，错误风险高，因此需要严格评估其实际能力，以推动相关研究并获得高质量系统评价。

Method: 通过在2023和2024年文本检索会议举办PLABA赛道，设置两个任务：1）对生物医学文摘进行完整的、逐句的通俗改写；2）识别并替换文中的难懂术语。任务1的自动评测依托四份专业改写参照，任务1与2均由生物医学专家进行人工评价。

Result: 12支队伍参加，方法涵盖多层感知器到大型预训练模型。任务1中，成绩最优模型在事实准确性和信息完整性上接近人工水平，但在表达简练和易懂性上仍有不足。自动评价指标与人工判定一致性较差。任务2中，系统在术语难点识别和替换分类上表现较弱，但生成替代表达时，基于LLM系统在人工评价中准确性、完整性与易懂性表现良好，但在简洁性上仍有提升空间。

Conclusion: PLABA赛道展示了大语言模型在将生物医学文献转化为通俗语言方面的潜力，但同时暴露了其不足，尤其是在简练表达及术语难度识别等方面。此外，相关自动评价方法与人工评审结果相关性较差，表明需要改进自动评测工具。

Abstract: Objective: Recent advances in language models have shown potential to adapt
professional-facing biomedical literature to plain language, making it
accessible to patients and caregivers. However, their unpredictability,
combined with the high potential for harm in this domain, means rigorous
evaluation is necessary. Our goals with this track were to stimulate research
and to provide high-quality evaluation of the most promising systems.
  Methods: We hosted the Plain Language Adaptation of Biomedical Abstracts
(PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks included
complete, sentence-level, rewriting of abstracts (Task 1) as well as
identifying and replacing difficult terms (Task 2). For automatic evaluation of
Task 1, we developed a four-fold set of professionally-written references.
Submissions for both Tasks 1 and 2 were provided extensive manual evaluation
from biomedical experts.
  Results: Twelve teams spanning twelve countries participated in the track,
with models from multilayer perceptrons to large pretrained transformers. In
manual judgments of Task 1, top-performing models rivaled human levels of
factual accuracy and completeness, but not simplicity or brevity. Automatic,
reference-based metrics generally did not correlate well with manual judgments.
In Task 2, systems struggled with identifying difficult terms and classifying
how to replace them. When generating replacements, however, LLM-based systems
did well in manually judged accuracy, completeness, and simplicity, though not
in brevity.
  Conclusion: The PLABA track showed promise for using Large Language Models to
adapt biomedical literature for the general public, while also highlighting
their deficiencies and the need for improved automatic benchmarking tools.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [58] [Proceedings of the 15th International Workshop on Non-Classical Models of Automata and Applications](https://arxiv.org/abs/2507.14082)
*Nelma Moreira,Luca Prigioniero*

Main category: cs.FL

TL;DR: NCMA 2025在英国拉夫堡举办，聚焦非经典自动机等理论与应用模型，旨在学者间交流创新观点，推动学科深入发展。


<details>
  <summary>Details</summary>
Motivation: 推动非经典及经典自动机、文法和相关模型领域的研究，深化多学科交流，促进理论创新和应用进步。

Method: 以国际研讨会的形式，邀请相关领域研究者参会，进行报告、讨论和交流，涵盖理论与应用等多个视角。

Result: 通过此次会议，促进了新思想的交流和多学科交叉，加深了该领域研究人员之间的相互理解，有助于推动理论发展和实际应用。

Conclusion: 本次研讨会为非经典与经典自动机、文法等相关模型的研究者们提供了一个学术交流平台，推动了该领域创新性研究的发展。

Abstract: The Fifteenth International Workshop on Non-Classical Models of Automata and
Applications (NCMA 2025) was held in Loughborough, UK, on July 21 and 22, 2025,
organized by the Department of Computer Science at Loughborough University and
co-located with the 26th International Conference on Descriptional Complexity
of Formal Systems (DCFS 2025, 22-24 July).
  The NCMA workshop series was established in 2009 as an annual event for
researchers working on non-classical and classical models of automata, grammars
or related devices. Such models are investigated both as theoretical models and
as formal models for applications from various points of view. The goal of the
NCMA workshop series is to exchange and develop novel ideas in order to gain
deeper and interdisciplinary coverage of this particular area that may foster
new insights and substantial progress.

</details>
