<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.SE](#cs.SE) [Total: 7]
- [cs.LO](#cs.LO) [Total: 4]
- [cs.CL](#cs.CL) [Total: 3]
- [cs.DM](#cs.DM) [Total: 4]
- [cs.FL](#cs.FL) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [From Tool Calling to Symbolic Thinking: LLMs in a Persistent Lisp Metaprogramming Loop](https://arxiv.org/abs/2506.10021)
*Jordi de la Torre*

Main category: cs.PL

TL;DR: 作者提出让大语言模型与Lisp交互环境实时集成，赋予其外部状态记忆、反思和自我演化工具构建能力，并建立了交互式AI架构的原则和方法。


<details>
  <summary>Details</summary>
Motivation: LLMs缺少持续外部记忆和动态工具构建能力。作者希望结合符号编程与神经语言生成，让AI系统具备状态持久化、反思和动态功能扩展的能力。

Method: 通过在生成过程中嵌入Lisp代码，并在中间件层进行拦截，实现LLM与Lisp REPL的实时编程和工具演化交互。论文还提出了设计框架和架构原则。

Result: 实现了LLM与Lisp交互环境的整合，展示了如何通过此方法实现持续外部记忆、动态工具创建和反思式编程等高级AI功能，并提出了相关架构原则。

Conclusion: 该论文提出了一种新的架构，使大语言模型（LLMs）能够和持久、交互式的Lisp环境整合。该系统能够让LLM通过编程与实时REPL互动，定义、调用并演化自有工具。此外，通过中间件层拦截嵌入的Lisp表达式，实现有状态外部记忆、反思式编程和动态工具创建，为未来AI交互系统的实现提供了指导原则和框架。

Abstract: We propose a novel architecture for integrating large language models (LLMs)
with a persistent, interactive Lisp environment. This setup enables LLMs to
define, invoke, and evolve their own tools through programmatic interaction
with a live REPL. By embedding Lisp expressions within generation and
intercepting them via a middleware layer, the system allows for stateful
external memory, reflective programming, and dynamic tool creation. We present
a design framework and architectural principles to guide future implementations
of interactive AI systems that integrate symbolic programming with neural
language generation.

</details>


### [2] [A Language-Agnostic Logical Relation for Message-Passing Protocols](https://arxiv.org/abs/2506.10026)
*Tesla Zhang,Sonya Simkin,Rui Li,Yue Yao,Stephanie Balzer*

Main category: cs.PL

TL;DR: 本论文提出并机械化实现了一种与语言无关的协议遵从性验证框架，突破了传统验证需共语言和类型系统的限制，实现了可扩展到外部实体的分布式系统安全验证。


<details>
  <summary>Details</summary>
Motivation: 当前分布式和异构系统（如云计算和物联网）的应用程序越来越普遍，这些应用通常是并发的、消息传递型的，并且与外部对象（如物理设备或外部代码）交互。传统的验证方法依赖于共有实现语言和类型系统，但复杂、多语言和异构的应用环境下，这些假设不再成立，现有方法难以确保协议遵从性。

Method: 该论文提出并实现了一个协议一致性认证框架，首次对“与语言无关的逻辑关系”进行了机械化建模。这一逻辑关系基于带标签的转换语义，可容纳任意实现（包括有类型、无类型以及外部对象），无需假设统一的实现语言或类型系统。

Result: 逻辑关系定义以及两个应用场景（具体实例验证和针对具体类型系统的“一劳永逸”验证）均已在Coq定理证明器中实现，能够有效用于保证分布式异构消息传递系统的协议遵从性。

Conclusion: 该框架为分布式异构环境下消息传递程序的协议遵从性验证提供了理论基础和实践工具，突破了语言和类型系统的限制，填补了相关领域的空白。

Abstract: Today's computing landscape has been gradually shifting to applications
targeting distributed and *heterogeneous* systems, such as cloud computing and
Internet of Things (IoT) applications. These applications are predominantly
*concurrent*, employ *message-passing*, and interface with *foreign objects*,
ranging from externally implemented code to actual physical devices such as
sensors. Verifying that the resulting systems adhere to the intended protocol
of interaction is challenging -- the usual assumption of a common
implementation language, let alone a type system, no longer applies, ruling out
any verification method based on them. This paper develops a framework for
certifying *protocol compliance* of heterogeneous message-passing systems. It
contributes the first mechanization of a *language-agnostic logical relation*,
asserting that its inhabitants comply with the protocol specified. This
definition relies entirely on a labelled transition-based semantics,
accommodating arbitrary inhabitants, typed and untyped alike, including foreign
objects. As a case study, the paper considers two scenarios: (1) *per-instance
verification* of a specific application or hardware device, and (2)
*once-and-for-all verification* of well-typed applications for a given type
system. The logical relation and both scenarios are mechanized in the Coq
theorem prover.

</details>


### [3] [Hazel Deriver: A Live Editor for Constructing Rule-Based Derivations](https://arxiv.org/abs/2506.10781)
*Zhiyao Zhong,Cyrus Omar*

Main category: cs.PL

TL;DR: 提出了Hazel Deriver实时推导编辑器，显著提升学生在规则推导任务中的理解与体验，但系统辅助与学习自主性需权衡。


<details>
  <summary>Details</summary>
Motivation: 学生在编程语言和形式逻辑课程中常常因为推理规则应用复杂、反馈不及时以及手写证明费力等原因，难以构建基于规则的推导树。

Method: 提出并设计了Hazel Deriver，这是一个基于Web的实时编辑器，内嵌于Hazel语言环境中，通过多层次支撑为推导树构造提供结构化互动体验，并鼓励渐进式探索和实时反馈。

Result: 初步用户研究表明，Hazel Deriver能降低推导任务的主观难度，提高学生的概念理解与参与度。

Conclusion: Hazel Deriver在支持推导树构造和学习方面具有积极效果，但也需要在系统引导与学生自主性之间寻找平衡。

Abstract: Students in programming languages and formal logic courses often struggle
with constructing rule-based derivation trees due to the complexity of applying
inference rules, the lack of immediate feedback, and the manual effort required
for handwritten proofs. We present Hazel Deriver, a live, web-based editor
designed to scaffold derivation construction through multiple layers of
support. Built on the Hazel live programming environment, it provides a
structured, interactive experience that encourages iterative exploration and
real-time feedback. A preliminary user study with former students suggests that
Hazel Deriver reduces the perceived difficulty of derivation tasks while
improving conceptual understanding and engagement. We discuss the design of its
layered scaffolding features and raise questions about balancing system
guidance with learner autonomy.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [TrioXpert: An automated incident management framework for microservice system](https://arxiv.org/abs/2506.10043)
*Yongqian Sun,Yu Luo,Xidao Wen,Yuan Yuan,Xiaohui Nie,Shenglin Zhang,Tong Liu,Xi Luo*

Main category: cs.SE

TL;DR: TrioXpert是一个面向微服务系统的多模态、可解释性强的多任务事件管理框架，在异常检测、故障分级、根因定位等任务上均取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有微服务系统的自动化事件管理方法多数只利用单一模态数据，难以同时处理异常检测、故障分级和根因定位等多种任务。此外，现有方法在可解释性方面也存在不足。

Method: 提出了一种名为TrioXpert的端到端事件管理框架，能够充分利用多模态数据。TrioXpert基于不同模态特性设计了三条独立的数据处理管道，并结合大语言模型协同推理机制，实现多任务处理同时增强解释能力。

Result: 在两个主流微服务系统数据集上的大量实验表明，TrioXpert在异常检测、故障分级和根因定位任务上的性能分别提升了4.7%~57.7%、2.1%~40.6%和1.6%~163.1%。

Conclusion: TrioXpert能够更好地利用多模态信息，有效提升多种事件管理任务的性能，并且显著增强了解释能力。

Abstract: Automated incident management plays a pivotal role in large-scale
microservice systems. However, many existing methods rely solely on
single-modal data (e.g., metrics, logs, and traces) and struggle to
simultaneously address multiple downstream tasks, including anomaly detection
(AD), failure triage (FT), and root cause localization (RCL). Moreover, the
lack of clear reasoning evidence in current techniques often leads to
insufficient interpretability. To address these limitations, we propose
TrioXpert, an end-to-end incident management framework capable of fully
leveraging multimodal data. TrioXpert designs three independent data processing
pipelines based on the inherent characteristics of different modalities,
comprehensively characterizing the operational status of microservice systems
from both numerical and textual dimensions. It employs a collaborative
reasoning mechanism using large language models (LLMs) to simultaneously handle
multiple tasks while providing clear reasoning evidence to ensure strong
interpretability. We conducted extensive evaluations on two popular
microservice system datasets, and the experimental results demonstrate that
TrioXpert achieves outstanding performance in AD (improving by 4.7% to 57.7%),
FT (improving by 2.1% to 40.6%), and RCL (improving by 1.6% to 163.1%) tasks.

</details>


### [5] [Online Discovery of Simulation Models for Evolving Business Processes (Extended Version)](https://arxiv.org/abs/2506.10049)
*Francesco Vinci,Gyunam Park,Wil van der Aalst,Massimiliano de Leoni*

Main category: cs.SE

TL;DR: 本文提出了一种结合增量流程发现与在线机器学习的流式仿真模型自动发现方法，能够适应业务流程中的实时变化，对新旧数据动态赋权，生成更稳定且具有鲁棒性的仿真模型。


<details>
  <summary>Details</summary>
Motivation: 传统的业务流程仿真模型自动发现方法难以适应真实业务流程中的实时变化，缺乏对最新操作动态的响应能力，影响仿真模型的实用性和准确性。

Method: 将增量式流程发现与在线机器学习方法整合，开发了一种新的流式业务流程仿真模型发现技术，重点优先考虑最新数据，同时保留历史信息。通过在四个不同的事件日志上开展实验进行验证。

Result: 实验证明，在仿真中对最新数据赋予更高权重、同时保留历史知识，可以获得更稳定、鲁棒的仿真效果，尤其在应对概念漂移时表现突出。

Conclusion: 提出的方法能够生成更加稳定、适应动态变化的仿真模型，并在实际用例中对概念漂移有较强的鲁棒性。

Abstract: Business Process Simulation (BPS) refers to techniques designed to replicate
the dynamic behavior of a business process. Many approaches have been proposed
to automatically discover simulation models from historical event logs,
reducing the cost and time to manually design them. However, in dynamic
business environments, organizations continuously refine their processes to
enhance efficiency, reduce costs, and improve customer satisfaction. Existing
techniques to process simulation discovery lack adaptability to real-time
operational changes. In this paper, we propose a streaming process simulation
discovery technique that integrates Incremental Process Discovery with Online
Machine Learning methods. This technique prioritizes recent data while
preserving historical information, ensuring adaptation to evolving process
dynamics. Experiments conducted on four different event logs demonstrate the
importance in simulation of giving more weight to recent data while retaining
historical knowledge. Our technique not only produces more stable simulations
but also exhibits robustness in handling concept drift, as highlighted in one
of the use cases.

</details>


### [6] [The Effects of GitHub Copilot on Computing Students' Programming Effectiveness, Efficiency, and Processes in Brownfield Programming Tasks](https://arxiv.org/abs/2506.10051)
*Md Istiak Hossain Shihab,Christopher Hundhausen,Ahsun Tariq,Summit Haque,Yunhan Qiao,Brian Mulanda*

Main category: cs.SE

TL;DR: 生成式AI助手（如Copilot）能大幅提升学生在旧有代码中的编程效率，但同时可能减少对代码细节的理解，教育者需引导学生反思AI建议并调整教学策略。


<details>
  <summary>Details</summary>
Motivation: 计算机专业毕业生在进入软件行业时，经常需要参与已有遗留代码（brownfield development）的开发工作。当前生成式AI（如GitHub Copilot）迅速影响软件开发流程，但它对学生程序员在传统遗留代码环境下编程的影响尚未被充分研究。

Method: 作者设计了一项对照实验，让10名本科计算机学生在不熟悉的遗留web应用中执行相似的brownfield开发任务，各自使用和不使用Copilot。采用混合方法：包括性能分析、行为分析以及访谈等。

Result: 使用Copilot时，学生完成任务速度提升35%，解决方案进度提升50%；手写代码时间减少11%，网络搜索时间减少12%（统计上显著）。

Conclusion: Copilot显著提升了学生在遗留代码环境下的开发效率，但也带来了对理解AI建议底层原理和机制的担忧。建议教育者探索融合AI助手的新教学方式，平衡效率和知识掌握。

Abstract: When graduates of computing degree programs enter the software industry, they
will most likely join teams working on legacy code bases developed by people
other than themselves. In these so-called brownfield software development
settings, generative artificial intelligence (GenAI) coding assistants like
GitHub Copilot are rapidly transforming software development practices, yet the
impact of GenAI on student programmers performing brownfield development tasks
remains underexplored. This paper investigates how GitHub Copilot influences
undergraduate students' programming performance, behaviors, and understanding
when completing brownfield programming tasks in which they add new code to an
unfamiliar code base. We conducted a controlled experiment in which 10
undergraduate computer science students completed highly similar brownfield
development tasks with and without Copilot in a legacy web application. Using a
mixed-methods approach combining performance analysis, behavioral analysis, and
exit interviews, we found that students completed tasks 35% faster (p < 0.05)
and made 50% more solution progress p (< 0.05) when using Copilot. Moreover,
our analysis revealed that, when using Copilot, students spent 11% less time
manually writing code (p < 0.05), and 12% less time conducting web searches (p
< 0.05), providing evidence of a fundamental shift in how they engaged in
programming. In exit interviews, students reported concerns about not
understanding how or why Copilot suggestions work. This research suggests the
need for computing educators to develop new pedagogical approaches that
leverage GenAI assistants' benefits while fostering reflection on how and why
GenAI suggestions address brownfield programming tasks. Complete study results
and analysis are presented at https://ghcopilot-icer.github.io/.

</details>


### [7] [Reward Models Enable Scalable Code Verification by Trading Accuracy for Throughput](https://arxiv.org/abs/2506.10056)
*Gabriel Orlanski,Nicholas Roberts,Aws Albarghouthi,Frederic Sala*

Main category: cs.SE

TL;DR: 虽然全量测试的准确度高，ORM可在大幅提速的同时保持较高准确性，新的范式在实际系统中具有更好扩展性和实用价值。


<details>
  <summary>Details</summary>
Motivation: 当前大多数通过大语言模型（LLM）解决编程任务的方法采用“生成再排序”范式，排序环节通常依赖全量测试集等全面验证，而较少关注在速度和准确度之间的权衡。

Method: 系统地比较了全面验证（如全量测试集）与成果奖励模型（ORM）在准确度和速度上的权衡，并提出了generate-prune-then-rank方法，先用快速但不太准确的验证器筛除错误解，再进行排序。

Result: 使用generate-prune-then-rank方法，系统比直接用完整测试快11.65倍，准确度只下降了8.33%。分析发现，这种方法能有效过滤掉排名高但错误的解。

Conclusion: 成果奖励模型（ORM）在可扩展性和效率上有不可替代的作用，通过合理权衡速度和准确性，能设计出高效且准确的程序排名系统。

Abstract: The standard paradigm for solving coding tasks via large language models
(LLMs) is to generate-then-rank programs, where the latter step uses a verifier
in the ranking process. The growing consensus is that a comprehensive verifier
(e.g., a full test suite) should be prioritized over an outcome reward model
(ORM) whenever possible, with little consideration given to the trade-offs
involved. We aim to challenge this assumption by systematically exploring the
tradeoff between speed and accuracy. We find that ORMs play a crucial role in
scaling verification through trading accuracy for speed, even when a
comprehensive verifier is available. Their value becomes especially apparent
when used in a generate-prune-then-rank approach, where a faster but less
accurate verifier removes incorrect solutions prior to ranking -- leading to a
system that is 11.65x faster while only being 8.33% less accurate than the full
test suite. We analyze the generate-prune-then-rank approach and show that it
works by filtering out incorrect but highly ranked solutions. These findings
enable the design of scalable and accurate program ranking systems.

</details>


### [8] [Prompt Variability Effects On LLM Code Generation](https://arxiv.org/abs/2506.10204)
*Andrei Paleyes,Radzim Sendyka,Diana Robinson,Christian Cabrera,Neil D. Lawrence*

Main category: cs.SE

TL;DR: 文献提出系统自动化+persona方法，评估LLM代码生成对用户背景的敏感性，方法通用并实验有效。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型已广泛用于代码生成，但生成结果高度依赖提示词质量，且不同用户背景带来的输入变化会影响代码生成效果，因此需要系统性地评估LLM对输入多样性的敏感性。

Method: 提出了一套合成（synthetic）的代码生成评测流程，以及一个基于用户persona的系统化评测方法，通过实验分析不同背景用户输入对LLM生成代码质量的影响，且方法对特定编程任务及模型无依赖。

Result: 提出的评估方法能够揭示不同用户背景下LLMs生成代码时在功能、质量等方面的差异，具有广泛适用性，并通过实验验证了方法的有效性。

Conclusion: 文章提出的基于persona的评测方法和自动化评测流程，可以有效量化和评估当前主流大语言模型在代码生成任务中对不同输入提示、不同用户背景的敏感性，并验证方法具有通用性和实用价值。

Abstract: Code generation is one of the most active areas of application of Large
Language Models (LLMs). While LLMs lower barriers to writing code and
accelerate development process, the overall quality of generated programs
depends on the quality of given prompts. Specifically, functionality and
quality of generated code can be sensitive to user's background and familiarity
with software development. It is therefore important to quantify LLM's
sensitivity to variations in the input. To this end we propose a synthetic
evaluation pipeline for code generation with LLMs, as well as a systematic
persona-based evaluation approach to expose qualitative differences of LLM
responses dependent on prospective user background. Both proposed methods are
completely independent from specific programming tasks and LLMs, and thus are
widely applicable. We provide experimental evidence illustrating utility of our
methods and share our code for the benefit of the community.

</details>


### [9] [AI-Based Software Vulnerability Detection: A Systematic Literature Review](https://arxiv.org/abs/2506.10280)
*Samiha Shimmi,Hamed Okhravi,Mona Rahimi*

Main category: cs.SE

TL;DR: 本文系统综述了近年来AI驱动的软体漏洞检测研究，图神经网络应用最广，但数据集与可解释性等问题突出，建议关注联邦学习和量子神经网络等未来方向。


<details>
  <summary>Details</summary>
Motivation: 源代码中的软体漏洞严重威胁网络安全，传统检测方式已经不能满足当下需求，亟需系统梳理AI驱动的漏洞检测方法现状、瓶颈及未来方向。

Method: 采用系统性综述方法，回顾和分类了2018到2023年期间的软件漏洞检测相关研究，涵盖了算法技术、特征表达及嵌入方法，并进行定量统计与趋势分析。

Result: 91%的研究采用AI方法进行漏洞检测，图结构模型最常见；同时发现普遍存在数据集质量低、难以复现实验和缺乏模型可解释性等问题，指出联邦学习和量子神经网络是值得关注的新兴技术。

Conclusion: 绝大多数软体漏洞检测研究采用了AI驱动方法，图神经网络模型成为主流，但当前领域在数据集质量、复现性和可解释性方面仍有明显不足。前沿方向如联邦学习和量子神经网络值得后续探索。

Abstract: Software vulnerabilities in source code pose serious cybersecurity risks,
prompting a shift from traditional detection methods (e.g., static analysis,
rule-based matching) to AI-driven approaches. This study presents a systematic
review of software vulnerability detection (SVD) research from 2018 to 2023,
offering a comprehensive taxonomy of techniques, feature representations, and
embedding methods. Our analysis reveals that 91% of studies use AI-based
methods, with graph-based models being the most prevalent. We identify key
limitations, including dataset quality, reproducibility, and interpretability,
and highlight emerging opportunities in underexplored techniques such as
federated learning and quantum neural networks, providing a roadmap for future
research.

</details>


### [10] [Minimizing False Positives in Static Bug Detection via LLM-Enhanced Path Feasibility Analysis](https://arxiv.org/abs/2506.10322)
*Xueying Du,Kai Yu,Chong Wang,Yi Zou,Wentai Deng,Zuoyu Ou,Xin Peng,Lingming Zhang,Yiling Lou*

Main category: cs.SE

TL;DR: LLM4PFA以LLM agent为核心，有效解决了复杂路径可达性分析难题，大幅降低了静态缺陷检测的误报并具备较高实用价值。


<details>
  <summary>Details</summary>
Motivation: 现有静态缺陷检测工具在大规模代码库中的高误报率，主要由于复杂的条件分支和数据依赖导致路径可达性验证能力有限，而现有LLM方案受限于约束分析和可扩展性，效果不理想。

Method: 本文提出LLM4PFA框架，基于LLM agent的约束推理及关键上下文感知分析，通过智能体规划驱动，实现复杂跨过程路径可达性分析，从而降低静态缺陷检测中的误报率。

Result: LLM4PFA可有效过滤掉72%到96%的静态分析误报，相较所有基线方法提升41.1%-105.7%；在检测45个真实缺陷时，仅漏报3个。

Conclusion: LLM4PFA利用大语言模型智能体在约束分析和上下文感知的优势，显著提升了静态缺陷检测的准确性和可扩展性，显著降低误报。

Abstract: Static bug analyzers play a crucial role in ensuring software quality.
However, existing analyzers for bug detection in large codebases often suffer
from high false positive rates. This is primarily due to the limited
capabilities of analyzers in path feasibility validation with multiple
conditional branches and complex data dependencies. While current LLM-based
approaches attempt to address this issue, their effectiveness remains limited
due to insufficient constraint cascade analysis and scalability challenges in
large projects. To address this challenge, we propose an iterative path
feasibility analysis framework LLM4PFA. By leveraging LLM agent based targeted
constraint reasoning, and key context-aware analysis driven by agent planning,
LLM4PFA effectively enhances complex inter-procedural path feasibility analysis
for minimizing false positives in static bug detection. Evaluation results show
that LLM4PFA precisely filters out 72% to 96% false positives reported during
static bug detection, significantly outperforming all the baselines by 41.1% -
105.7% improvements; meanwhile LLM4PFA only misses 3 real bugs of 45 true
positives.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [11] [Growing a Modular Framework for Modal Systems- HOLMS: a HOL Light Library](https://arxiv.org/abs/2506.10048)
*Antonella Bilotta*

Main category: cs.LO

TL;DR: 该论文提出并实现了HOLMS，一个在HOL Light中支持K、T、K4、GL等模态系统的模块化推理工具，统一了充分性证明流程，并增强了自动化推理和反模型构建能力，对理论和实践均有提升。


<details>
  <summary>Details</summary>
Motivation: 目前在HOL Light证明助手中，关于模态逻辑的自动化和理论化支持有限。研究旨在为该领域提供一个模块化、统一的分析与证明环境，提高HOL Light对模态推理的支持度。

Method: 论文首先介绍模态逻辑基础和HOL Light的使用方法，然后设计并实现了一个用于多种标准模态系统（K、T、K4、GL）的统一、模块化的充分性定理证明策略，并融合自动化决策过程、反模型构造器。该方法直接在HOL Light环境中完成，评估了Boolos关于完备性证明的通用性和组合性。

Result: 实现了HOLMS框架，可在HOL Light内自动证明、多模块处理多个标准模态系统的充分性定理，具备自动决策、反模型构造等功能，显示了将通用定理证明助手与模态逻辑研究有效结合的可行性和灵活性。

Conclusion: HOLMS不仅巩固了理论基础，还实现了实用工具，推动了HOL Light在模态推理自动化领域的发展，并为后续框架扩展奠定基础。

Abstract: The present dissertation introduces the research project on HOLMS
(\textbf{HOL} Light Library for \textbf{M}odal \textbf{S}ystems), a growing
modular framework for modal reasoning within the HOL Light proof assistant. To
provide an accessible introduction to the library, the fundamentals of modal
logic are outlined first, followed by a concise manual for the proof assistant
itself. The core contribution of this work on HOLMS is the development of a
unified and modular strategy for proving adequacy theorems with respect to
relational semantics directly within HOL Light for several normal modal
systems, currently including K, T, K4, and GL. Adequacy theorems establish a
formal connection between syntactic proof systems and their intended relational
models, ensuring that derivable statements align with valid ones. This approach
extends previous research on G\"odel-L\"ob logic (GL) by two HOLMS developers.
It also assesses the generality and compositionality of the completeness proofs
in George Boolos' monograph \textit{The logic of provability}. Beyond
theoretical contributions, HOLMS incorporates automated decision procedures and
a countermodel constructor for K, T, K4, and GL, illustrating how
general-purpose proof assistants can be effectively combined with research on
labelled sequent calculi and key insights from correspondence and bisimulation
theories. The implementation in HOL Light demonstrates the feasibility of
mechanising modal reasoning in a flexible and robust manner, paving the way for
further developments of the HOLMS framework.

</details>


### [12] [Notes on applicative matching logic](https://arxiv.org/abs/2506.10088)
*Laurentiu Leustean*

Main category: cs.LO

TL;DR: 本文系统介绍了应用匹配逻辑（AML）的基本理论，是AML领域的入门教材型成果。


<details>
  <summary>Details</summary>
Motivation: 为编程语言的形式语义定义、程序行为的规范与推理提供逻辑基础，并推动AML这一匹配逻辑的函数型分支的入门和普及。

Method: 通过梳理AML的基本定义和理论结果，并吸收了Monk的数理逻辑教材的影响，系统地介绍了AML的相关内容。

Result: 给出了AML的基本定义和主要理论成果，体系化了该领域的知识，便于初学者学习和研究。

Conclusion: 本文展示了应用匹配逻辑（AML）的一些基本定义和结果，可作为AML理论的入门教材。

Abstract: Matching logic (ML) was developed by Grigore Ro\c{s}u and collaborators as a
logic for defining the formal semantics of programming languages and for
specifying and reasoning about the behavior of programs. These lecture notes
present basic definitions and results on applicative matching logic (AML), a
functional variant of ML introduced recently by Xiaohong Chen and Grigore
Ro\c{s}u. They can be used as an introductory text in the theory of AML. Monk's
textbook on mathematical logic has an enormous influence on the notes.

</details>


### [13] [StepProof: Step-by-step verification of natural language mathematical proofs](https://arxiv.org/abs/2506.10558)
*Xiaolin Hu,Qinghua Zhou,Bogdan Grechuk,Ivan Y. Tyukin*

Main category: cs.LO

TL;DR: StepProof方法让自然语言证明逐步被自动形式化成可验证的子证明，显著提升了自动验证效果。


<details>
  <summary>Details</summary>
Motivation: 现有交互式定理证明器缺乏自然语言接口，当前的自动形式化方法仅能验证完整证明，无法实现细粒度的句级验证。

Method: 提出了StepProof，将完整证明分解为可逐句验证的子证明，实现细粒度的自动形式化验证。

Result: StepProof较传统方法，证明成功率和效率显著提升，微调自然语言输入后性能进一步增强。

Conclusion: StepProof提高了证明的成功率和效率，并且在对自然语言证明微调后表现更佳。

Abstract: Interactive theorem provers (ITPs) are powerful tools for the formal
verification of mathematical proofs down to the axiom level. However, their
lack of a natural language interface remains a significant limitation. Recent
advancements in large language models (LLMs) have enhanced the understanding of
natural language inputs, paving the way for autoformalization - the process of
translating natural language proofs into formal proofs that can be verified.
Despite these advancements, existing autoformalization approaches are limited
to verifying complete proofs and lack the capability for finer, sentence-level
verification. To address this gap, we propose StepProof, a novel
autoformalization method designed for granular, step-by-step verification.
StepProof breaks down complete proofs into multiple verifiable subproofs,
enabling sentence-level verification. Experimental results demonstrate that
StepProof significantly improves proof success rates and efficiency compared to
traditional methods. Additionally, we found that minor manual adjustments to
the natural language proofs, tailoring them for step-level verification,
further enhanced StepProof's performance in autoformalization.

</details>


### [14] [Encoding call-by-push-value in the pi-calculus](https://arxiv.org/abs/2506.10584)
*Benjamin Bennetzen,Nikolaj Rossander Kristensen,Peter Buus Steffensen*

Main category: cs.LO

TL;DR: 本文提出了将CBPV lambda演算编码进多种pi演算的体系，证明其健全、完备，并初步进行了Coq形式化验证，推动了函数式和过程式理论的桥接。


<details>
  <summary>Details</summary>
Motivation: 将Levy提出的call-by-push-value (CBPV) lambda演算编码进pi演算，有助于桥接函数式与过程式计算模型，提升对于两者理论变换的理解。过去对于编码的充分性和可满足性研究有限，且对形式化验证的需求增加。

Method: 将CBPV lambda演算编码进pi演算，尤其是内部pi演算（pi-i-calculus），以避免de Bruijn索引在形式化时的挑战，并提升与互模拟相关证明的便利。采用手工和部分Coq工具支持，逐步验证编码的健壮性。

Result: 提出了健全且完备的编码，并非正式地证明了主要引理和结论，通过手工和初步Coq形式化进行了佐证。证明了该编码符合Gorla提出的良好编码五大标准，并与Milner的编码法有相似之处，实现了CBPV到多种pi演算的编码。部分引理仅手工证明或认为可由Coq形式形式推导。

Conclusion: 该研究提供了CBPV到pi演算及其变体之间的健全且完备的编码体系，不仅满足理论要求，也在形式化验证上迈出一步，为进一步自动化和标准化相关证明奠定基础。

Abstract: In this report we define an encoding of Levys call-by-push-value
lambda-calculus (CBPV) in the pi-calculus, and prove that our encoding is both
sound and complete. We present informal (by-hand) proofs of soundness,
completeness, and all required lemmas. The encoding is specialized to the
internal pi-calculus (pi-i-calculus) to circumvent certain challenges
associated with using de Bruijn index in a formalization, and it also helps
with bisimulation as early-, late- and open-bisimulation coincide in this
setting, furthermore bisimulation is a congruence. Additionally, we argue that
our encoding also satisfies the five criteria for good encodings proposed by
Gorla, as well as show similarities between Milners and our encoding. This
paper includes encodings from CBPV in the pi-i-calculus, asynchronous polyadic
pi-calculus and the local pi-calculus. We begin a formalization of the proof in
Coq for the soundness and completeness of the encoding in the pi-i-calculus.
Not all lemmas used in the formalization are themselves formally proven.
However, we argue that the non-proven lemmas are reasonable, as they are proven
by hand, or amount to Coq formalities that are straightforward given informal
arguments.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [15] [A Survey of Automatic Evaluation Methods on Text, Visual and Speech Generations](https://arxiv.org/abs/2506.10019)
*Tian Lan,Yang-Hao Zhou,Zi-Ao Ma,Fanshu Sun,Rui-Qing Sun,Junyu Luo,Rong-Cheng Tu,Heyan Huang,Chen Xu,Zhijing Wu,Xian-Ling Mao*

Main category: cs.CL

TL;DR: 本文系统梳理并统一分类了文本、图像和音频三大领域生成内容的自动评价方法，首次提出跨模态通用的评价体系和五大范式，并展望了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 尽管生成式AI在文本、图像和音频等领域取得了长足进步，但对这些生成内容进行自动化高效评价仍面临挑战，目前缺乏跨模态的系统性组织和统一框架。

Method: 采用文献综述的方法，归纳出生成内容自动评价的五大基本范式，并建立统一的分类体系，分别分析文本、图像、音频三大模态的自动评价方法。

Result: 提出了涵盖三大模态（文本、视觉、音频）的生成内容自动评价统一分类体系，识别了五类评价范式，并展现了该体系在不同模态下的适用性。还讨论了未来跨模态自动评价的研究前景。

Conclusion: 本论文提出了一个自动评价生成内容（文本、图像、音频）的方法体系，对现有方法进行了系统梳理和统一分类，并指出未来跨模态评价的研究方向。

Abstract: Recent advances in deep learning have significantly enhanced generative AI
capabilities across text, images, and audio. However, automatically evaluating
the quality of these generated outputs presents ongoing challenges. Although
numerous automatic evaluation methods exist, current research lacks a
systematic framework that comprehensively organizes these methods across text,
visual, and audio modalities. To address this issue, we present a comprehensive
review and a unified taxonomy of automatic evaluation methods for generated
content across all three modalities; We identify five fundamental paradigms
that characterize existing evaluation approaches across these domains. Our
analysis begins by examining evaluation methods for text generation, where
techniques are most mature. We then extend this framework to image and audio
generation, demonstrating its broad applicability. Finally, we discuss
promising directions for future research in cross-modal evaluation
methodologies.

</details>


### [16] [TaskCraft: Automated Generation of Agentic Tasks](https://arxiv.org/abs/2506.10055)
*Dingfeng Shi,Jingyi Cao,Qianben Chen,Weichen Sun,Weizhen Li,Hongxuan Lu,Fangchen Dong,Tianrui Qin,King Zhu,Minghao Yang,Jian Yang,Ge Zhang,Jiaheng Liu,Changwang Zhang,Jun Wang,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: 本研究提出TaskCraft自动生成多步、难度可控、多工具结合的Agentic任务，突破了人工制作数据的瓶颈，显著促进了大规模模型的训练与评测，发布了大数据集供后续研究。


<details>
  <summary>Details</summary>
Motivation: 当前NLP和AI领域对多步骤、自主和工具使用能力（Agentic任务）的需求日益提升，但现有数据集缺乏工具交互，相关基准测试依赖人工注释，难以大规模扩展。

Method: 提出TaskCraft自动化流程，利用深度和宽度拓展方式，将原子任务扩展为结构与层级更复杂的多步任务，并生成可复现的执行轨迹。

Result: TaskCraft生成的任务有助于提示工程和智能体模型的监督微调，作者还构建了约36,000条不同难度的合成任务，推动智能体调优和评测研究。

Conclusion: TaskCraft能够自动生成可扩展、多工具、可验证的Agentic任务，大规模合成数据支持智能体能力的研究与提升。

Abstract: Agentic tasks, which require multi-step problem solving with autonomy, tool
use, and adaptive reasoning, are becoming increasingly central to the
advancement of NLP and AI. However, existing instruction data lacks tool
interaction, and current agentic benchmarks rely on costly human annotation,
limiting their scalability. We introduce \textsc{TaskCraft}, an automated
workflow for generating difficulty-scalable, multi-tool, and verifiable agentic
tasks with execution trajectories. TaskCraft expands atomic tasks using
depth-based and width-based extensions to create structurally and
hierarchically complex challenges. Empirical results show that these tasks
improve prompt optimization in the generation workflow and enhance supervised
fine-tuning of agentic foundation models. We present a large-scale synthetic
dataset of approximately 36,000 tasks with varying difficulty to support future
research on agent tuning and evaluation.

</details>


### [17] [A quantum semantic framework for natural language processing](https://arxiv.org/abs/2506.10077)
*Christopher J. Agostino,Quan Le Thien,Molly Apsel,Denizhan Pak,Elina Lesyk,Ashabari Majumdar*

Main category: cs.CL

TL;DR: 本文指出，语义退化是自然语言的根本属性，使得表达复杂性增加时，单一准确解释变得不可计算。经实验表明，无论人类还是LLM，解释歧义时都具有明显的非经典上下文性特征，挑战了经典语义观，建议用贝叶斯方法处理自然语言意义。


<details>
  <summary>Details</summary>
Motivation: 自然语言具有语义退化的特性，导致表达式复杂性增加时可能的解释数量呈指数增长，这对LLM和NLP系统构成了根本性的挑战。作者欲探究自然语言语义表达的局限性及其本质。

Method: 通过Kolmogorov复杂度分析表达复杂度与语义解释准确性的关系，并采用语义Bell不等式实验，利用多种LLM作为“计算认知系统”，在不同上下文下解释歧义词对，分析LLM在解释自然语言歧义时的行为。

Result: 多组实验中，CHSH期望值平均在1.2到2.8之间，多次结果（如2.3-2.4）显著突破经典界限（|S|≤2），证明了LLM对自然语言的歧义解释呈现非经典的“上下文性”特征，与人类认知实验一致。

Conclusion: 自然语言表达的意义不是静态归属于形式本身，而是在观察者的解释行为中实现。传统频率学派方法对自然语言的分析有损失，建议采用贝叶斯式反复采样方法更实际地刻画语言语义。

Abstract: Semantic degeneracy represents a fundamental property of natural language
that extends beyond simple polysemy to encompass the combinatorial explosion of
potential interpretations that emerges as semantic expressions increase in
complexity. Large Language Models (LLMs) and other modern NLP systems face
inherent limitations precisely because they operate within natural language
itself, making them subject to the same interpretive constraints imposed by
semantic degeneracy. In this work, we argue using Kolmogorov complexity that as
an expression's complexity grows, the likelihood of any interpreting agent
(human or LLM-powered AI) recovering the single intended meaning vanishes. This
computational intractability suggests the classical view that linguistic forms
possess meaning in and of themselves is flawed. We alternatively posit that
meaning is instead actualized through an observer-dependent interpretive act.
To test this, we conducted a semantic Bell inequality test using diverse LLM
agents as ``computational cognitive systems'' to interpret ambiguous word pairs
under varied contextual settings. Across several independent experiments, we
found average CHSH expectation values ranging from 1.2 to 2.8, with several
runs yielding values (e.g., 2.3-2.4) that significantly violate the classical
boundary ($|S|\leq2$). This demonstrates that linguistic interpretation under
ambiguity can exhibit non-classical contextuality, consistent with results from
human cognition experiments. These results inherently imply that classical
frequentist-based analytical approaches for natural language are necessarily
lossy. Instead, we propose that Bayesian-style repeated sampling approaches can
provide more practically useful and appropriate characterizations of linguistic
meaning in context.

</details>


<div id='cs.DM'></div>

# cs.DM [[Back]](#toc)

### [18] [The Freight Multimodal Transport Problem with Buses and Drones: An Integrated Approach for Last-Mile Delivery](https://arxiv.org/abs/2506.10311)
*E Su,Hu Qin,Jiliu Li,Rui Zhang*

Main category: cs.DM

TL;DR: 提出公交+无人机协同配送模型与高效求解算法，在真实数据上显著提升效率与降低成本，为城市物流提供创新解决方案。


<details>
  <summary>Details</summary>
Motivation: 城市物流中“最后一公里”配送成本高、效率低，现有方式难以兼顾成本、覆盖面和环保需求。通过将公交与无人机结合，可以提升配送效率和覆盖范围，但需要有效优化调度和成本分配方案。

Method: 提出了一个集成公交-无人机协同货运的多式联运优化模型，使用紧凑的混合整数线性规划(MILP)和带有指数级变量的整数规划。同时，针对实际大规模数据，设计了一个基于分支-定价和Benders剪枝(Branch-Price-and-Benders-Cut)的高效算法，用于求解NP-hard问题，并进行了算法加速改进。

Result: 实验基于真实公交数据，结果显示新提出的算法在效率和解质量上均优于CPLEX商业求解器。与顺序决策方法相比，联合优化可节省6%以上成本。此外，分析了不同成本参数、储物柜配置和环境效益等因素对系统表现的影响。

Conclusion: 集成公交-无人机系统在提升城市“最后一公里”效率、降低成本和环境影响方面具有显著潜力，为城市物流管理者提供了可行的优化方案和管理建议。

Abstract: This paper proposes a novel freight multimodal transport problem with buses
and drones, where buses are responsible for transporting parcels to lockers at
bus stops for storage, while drones are used to deliver each parcel from the
locker to the corresponding customer. The integrated bus-drone system
synergistically expands drone service coverage using the bus network to ensure
efficient final delivery. Minimizing the total operational costs while
satisfying customer demands necessitates the joint optimization of parcel
assignments and drone flights. We model the problem into a compact
mixed-integer linear programming formulation and propose an integer programming
formulation with exponentially many variables. To address real-world scale
instances, we propose a Branch-Price-and-Benders-Cut algorithm for this
non-deterministic polynomial-time (NP)-hard problem. This algorithm,
integrating column generation and Benders decomposition within a
Branch-and-Bound framework, is developed to obtain optimal or near-optimal
solutions. Additionally, we introduce algorithmic enhancements aimed at
accelerating the convergence of the algorithm. Computational experiments on
instances generated from real-world bus data demonstrate that the proposed
algorithms outperform CPLEX regarding both efficiency and solution quality.
Moreover, our approaches can lead to over 6% cost savings compared to
situations where we determine parcel assignments and drone flights
sequentially. We evaluate the environmental advantages of integrating buses and
drones, study the impact of different cost parameters in the system, and
investigate the impact of the parcel locker configuration on performance. These
findings provide valuable managerial insights for urban logistics managers,
highlighting the potential of the integrated bus-drone system to improve
traditional last-mile delivery.

</details>


### [19] [Contributions to conjectures in planar graphs: Induced Substructures, Treewidth, and Dominating Sets](https://arxiv.org/abs/2506.10471)
*Kengo Enami,Naoki Matsumoto,Takamasa Yashima*

Main category: cs.DM

TL;DR: 该文梳理并分析了与AB和MT猜想相关的概念及猜想，给出反例和最优上界，推动了领域理解与研究进展。


<details>
  <summary>Details</summary>
Motivation: 两大图论中的未解猜想——Albertson-Berman猜想和Matheson-Tarjan猜想——一直受到广泛关注。尽管已有部分成果和弱于原猜想的界限，但这两个问题仍未解决。论文旨在推动猜想的理解及其关联研究。

Method: 梳理并澄清与这两大猜想相关的若干概念（如连通支配、诱导外平面子图等），综述相关的猜想，提供一些反例，并对不同结构条件下诱导子图的最大阶数差距给出最优上界。同时，依据图的treewidth，提出诱导子图阶数的一般上界。

Result: 论文给出了一些相关猜想的反例，确立了不同结构下诱导子图最大阶数差距的最优界限，并用treewidth这一基本图不变量给出了诱导子图阶数的一般上界。

Conclusion: 本文加深了对Albertson-Berman和Matheson-Tarjan两大猜想及其广义形式的理解，并通过反例和界限推动了相关研究进展。

Abstract: Two of the most prominent unresolved conjectures in graph theory, the
Albertson-Berman conjecture and the Matheson-Tarjan conjecture, have been
extensively studied by many researchers.
  (AB) Every planar graph of order $n$ has an induced forest of order at least
$\frac{n}{2}$.
  (MT) Every plane triangulation of sufficiently large order $n$ has a
dominating set of cardinality at most $\frac{n}{4}$.
  Although partial results and weaker bounds than those originally conjectured
have been obtained, both problems remain open. To contribute to their
resolution, various generalizations and variations of the original concepts
have been investigated, such as total dominating set, induced linear forests,
and others. In this paper, we clarify the relations among several notions
related to these two major conjectures, such as connected domination and
induced outerplanar subgraphs, etc., and survey the associated conjectures. We
then provide counterexamples to some of these conjectures and establish the
best bounds on the gap between the maximum orders of induced subgraphs under
different structural conditions. In addition, we present a general upper bound
on the order of induced subgraphs in terms of treewidth, a fundamental graph
invariant.

</details>


### [20] [The LLLR generalised Langton's ant](https://arxiv.org/abs/2506.10482)
*Victor Lutfalla*

Main category: cs.DM

TL;DR: 本文简要讨论了LLLR变体Langton蚂蚁的动力学，发现它有两种不同的长期演化行为。


<details>
  <summary>Details</summary>
Motivation: Langton的蚂蚁是一种经典的元胞自动机，广泛用于研究复杂系统和简单规则下的演化行为。作者希望研究其广义形式（LLLR变体），以探索不同规则下的动力学表现。

Method: 作者通过理论分析和数值实验，考察了LLLR（左、左、左、右）规则下蚂蚁的长期动力学行为。

Result: 研究发现LLLR蚂蚁表现出两种不同的渐进行为。

Conclusion: 不同规则下的Langton蚂蚁能展现出各种复杂度动力学，LLLR蚂蚁有两种渐近动力学可能。

Abstract: We present a short note on the dynamics of the LLLR generalised Langton's
ant. We describe two different asymptotic behaviours for the LLLR ant.

</details>


### [21] [Circulant TSP: Vertices of the Edge-Length Polytope and Superpolynomial Lower Bounds](https://arxiv.org/abs/2506.10758)
*Samuel C. Gutekunst*

Main category: cs.DM

TL;DR: 该论文探讨了环行TSP中edge-length polytope与参数n因式分解的关系，揭示了特定情形下的高效算法机会，并对相关数论猜想的组合下界提供了新结果。


<details>
  <summary>Details</summary>
Motivation: 受到环行旅行商问题（Circulant TSP）算法研究，以及与Buratti-Horak-Rosa猜想相关的数论研究的推动，论文探索了edge-length polytope的性质。Circulant TSP复杂度仍未彻底解决，而其分析和求解与多边体结构密切相关。

Method: 论文分析了Circulant TSP中edge-length polytope的顶点数量与参数n的因数分解之间的关系，并以具体例子（如n为素数，素数的平方，2的幂等）展示不同情形下的多面体顶点数量。此外，作为中间步骤，还针对Buratti-Horak-Rosa猜想相关组合序列给出了超级多项式下界。

Result: 当n为素数时，edge-length polytope的顶点数与n成正比；n为素数平方时与n的3/2次方相关；当n为2的幂时，顶点数达到超级多项式量级。相比之下，标准对称TSP多面体有约n!个顶点。部分情况下，基于n的因式分解，对多面体每个顶点暴力枚举算法是有效的。此外，对Buratti-Horak-Rosa猜想的两个组合序列给出了超级多项式下界。

Conclusion: edge-length polytope的结构与n的因式分解密切相关，这不仅影响Circulant TSP的复杂性，也为理解Hamilton路径长度组合提供了新视角。对于某些n，Circulant TSP的问题可以高效暴力求解。还对相关数论问题注入了组合下界的新进展。

Abstract: We study the edge-length polytope, motivated both by algorithmic research on
the Circulant Traveling Salesman Problem (Circulant TSP) and number-theoretic
research related to the Buratti-Horak-Rosa conjecture. Circulant TSP is a
special case of TSP whose overall complexity is a significant still-open
question, and where on an input with vertices $\{1, 2, ..., n\}$, the cost of
an edge $\{i, j\}$ depends only on its length $\min\{|i-j|, n-|i-j|\}$. The
edge-length polytope provides one path to solving circulant TSP instances, and
we show that it is intimately connected to the factorization of $n$: the number
of vertices scales with $n$ whenever $n$ is prime and with $n^{3/2}$ whenever
$n$ is a prime-squared, but there are a superpolynomial number of vertices
whenever $n$ is a power of 2. In contrast, the more-standard Symmetric TSP
Polytope has roughly $n!$ vertices. Hence, for Circulant TSP, a brute-force
algorithm checking every vertex is actually efficient in some cases, based on
the factorization of $n$. As an intermediate step, we give superpolynomial
lower-bounds on two combinatorial sequences related to the Buratti-Horak-Rosa
conjecture, which asks what combinations of edge lengths can comprise a
Hamiltonian path.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [22] [Chance and Mass Interpretations of Probabilities in Markov Decision Processes (Extended Version)](https://arxiv.org/abs/2506.10377)
*Yun Chen Tsai,Kittiphon Phalakarn,S. Akshay,Ichiro Hasuo*

Main category: cs.FL

TL;DR: 该文提出了马尔可夫决策过程（MDP）语义的统一框架，用数学方法涵盖和比较了4种语义，并针对新语义下的可达性问题提出了算法和复杂性分析。


<details>
  <summary>Details</summary>
Motivation: 马尔可夫决策过程（MDP）广泛应用于不确定性决策问题，但不同领域通常采用不同的语义解释。以往主要有两种MDP的语义解释方式，但尚未有统一框架涵盖多种语义，且部分新语义下的一些基本问题（如可达性）尚未被充分研究。

Method: 提出并建立了一个统一的语义框架，通过引入“chance-mass (CM) classifier”这一数学构造统一四种MDP语义（分别源于调度器、配置及转移中的随机性与概率解释方式），并在两个新提出的语义下系统地定义了可达性问题，提出两种算法解决，并分析了这些问题的复杂性。

Result: 成功用CM分类器统一描述了MDP的四种语义，理论上明确展示了不同语义下的可达性问题的难度，并为两个新语义提出了可达性求解算法。

Conclusion: 本文首次理论上统一了MDP的主要语义解释，并针对新语义下的关键问题提供了算法支持，为动态系统等复杂场景中的不确定性建模和验证提供了重要工具。

Abstract: Markov decision processes (MDPs) are a popular model for decision-making in
the presence of uncertainty. The conventional view of MDPs in verification
treats them as state transformers with probabilities defined over sequences of
states and with schedulers making random choices. An alternative view,
especially well-suited for modeling dynamical systems, defines MDPs as
distribution transformers with schedulers distributing probability masses. Our
main contribution is a unified semantical framework that accommodates these two
views and two new ones. These four semantics of MDPs arise naturally through
identifying different sources of randomness in an MDP (namely schedulers,
configurations, and transitions) and providing different ways of interpreting
these probabilities (called the chance and mass interpretations). These
semantics are systematically unified through a mathematical construct called
chance-mass (CM) classifier. As another main contribution, we study a
reachability problem in each of the two new semantics, demonstrating their
hardness and providing two algorithms for solving them.

</details>


### [23] [Minimality and computability of languages of G-shifts](https://arxiv.org/abs/2506.10610)
*Djamel Eddine Amir,Benjamin Hellouin de Menibus*

Main category: cs.FL

TL;DR: 本文将强可计算类型的概念推广到G-移位系统，获得了关于极小性的新刻画，证明了乘积下封闭等新性质，统一和拓展了当前多个相关结果，为后续研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 受到可计算分析中集合强可计算类型概念的启发，作者希望将其推广到G-移位系统领域，研究G-移位系统（G为具有可判定词问题的有限生成群）上的强可计算类型性质，并揭示其相关的结构特征和推广意义。

Method: 作者定义了G-移位系统上的强可计算类型，并利用与计算复杂度有界属性相关的极小性概念，对具有强可计算类型的G-移位系统进行了刻画。文中给出了自洽的直接证明，同时说明如何从Amir与Hoyrup对集合的对应结果推广得到。此外，将该刻画理论应用于极小性相关的移位类，并讨论了理论与闭包空间相关结果的联系。

Result: 文中获得了G-移位系统强可计算类型的刻画，并将其应用于多类极小性移位系统，展示了该理论对统一与推广既有工作的重要作用。同时证明了在G-移位系统下，强可计算类型性质在乘积下可保持，这与集合情形不同。最后还讨论了进一步推广和后续研究的方向。

Conclusion: 提出了G-移位系统的强可计算类型概念，获得了极小性等价刻画，并展现该理论在多个移位类别下的重要应用，同时揭示了与既有集合和闭包空间理论间的联系，也发现了与集合情形不同的新性质。该理论不仅统一和推广了已有结果，还为未来相关领域的研究提供了方向。

Abstract: Motivated by the notion of strong computable type for sets in computable
analysis, we define the notion of strong computable type for $G$-shifts, where
$G$ is a finitely generated group with decidable word problem. A $G$-shift has
strong computable type if one can compute its language from the complement of
its language. We obtain a characterization of $G$-shifts with strong computable
type in terms of a notion of minimality with respect to properties with a
bounded computational complexity. We provide a self-contained direct proof, and
also explain how this characterization can be obtained from an existing similar
characterization for sets by Amir and Hoyrup, and discuss its connexions with
results by Jeandel on closure spaces. We apply this characterization to several
classes of shifts that are minimal with respect to specific properties. This
provides a unifying approach that not only generalizes many existing results
but also has the potential to yield new findings effortlessly. In contrast to
the case of sets, we prove that strong computable type for G-shifts is
preserved under products. We conclude by discussing some generalizations and
future directions.

</details>
