{"id": "2507.22910", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22910", "abs": "https://arxiv.org/abs/2507.22910", "authors": ["Sergio Di Meglio", "Aniello Somma", "Luigi Libero Lucio Starace", "Fabio Scippacercola", "Giancarlo Sperl\u00ec", "Sergio Di Martino"], "title": "Large Language Models in the Travel Domain: An Industrial Experience", "comment": "Manuscript accepted to the International Conference on Software\n  Engineering and Knowledge Engineering (SEKE) 2025", "summary": "Online property booking platforms are widely used and rely heavily on\nconsistent, up-to-date information about accommodation facilities, often\nsourced from third-party providers. However, these external data sources are\nfrequently affected by incomplete or inconsistent details, which can frustrate\nusers and result in a loss of market. In response to these challenges, we\npresent an industrial case study involving the integration of Large Language\nModels (LLMs) into CALEIDOHOTELS, a property reservation platform developed by\nFERVENTO. We evaluate two well-known LLMs in this context: Mistral 7B,\nfine-tuned with QLoRA, and Mixtral 8x7B, utilized with a refined system prompt.\nBoth models were assessed based on their ability to generate consistent and\nhomogeneous descriptions while minimizing hallucinations. Mixtral 8x7B\noutperformed Mistral 7B in terms of completeness (99.6% vs. 93%), precision\n(98.8% vs. 96%), and hallucination rate (1.2% vs. 4%), producing shorter yet\nmore concise content (249 vs. 277 words on average). However, this came at a\nsignificantly higher computational cost: 50GB VRAM and $1.61/hour versus 5GB\nand $0.16/hour for Mistral 7B. Our findings provide practical insights into the\ntrade-offs between model quality and resource efficiency, offering guidance for\ndeploying LLMs in production environments and demonstrating their effectiveness\nin enhancing the consistency and reliability of accommodation data.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e24\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7269\u4e1a\u9884\u8ba2\u5e73\u53f0\u4e0a\u7684\u5b9e\u9645\u8868\u73b0\uff0c\u53d1\u73b0\u66f4\u9ad8\u7ea7\u6a21\u578b\u80fd\u63d0\u5347\u6570\u636e\u63cf\u8ff0\u8d28\u91cf\uff0c\u4f46\u9700\u4ed8\u51fa\u66f4\u9ad8\u7b97\u529b\u548c\u6210\u672c\uff0c\u63d0\u793a\u5e94\u7528\u65f6\u9700\u5408\u7406\u6743\u8861\u3002", "motivation": "\u5728\u7ebf\u7269\u4e1a\u9884\u8ba2\u5e73\u53f0\u4f9d\u8d56\u5916\u90e8\u6570\u636e\u6e90\uff0c\u8fd9\u4e9b\u6e90\u5e38\u5e38\u4fe1\u606f\u4e0d\u5168\u6216\u4e0d\u4e00\u81f4\uff0c\u5bfc\u81f4\u7528\u6237\u4f53\u9a8c\u53d8\u5dee\u548c\u5e02\u573a\u635f\u5931\u3002", "method": "\u5c06\u4e24\u79cd\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\uff08Mistral 7B \u548c Mixtral 8x7B\uff09\u96c6\u6210\u5728CALEIDOHOTELS\u7269\u4e1a\u9884\u8ba2\u5e73\u53f0\uff0c\u5bf9\u5b83\u4eec\u751f\u6210\u63cf\u8ff0\u7684\u80fd\u529b\u53ca\u51cf\u5c11\u5e7b\u89c9\u8868\u73b0\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u6bd4\u8f83\u5176\u8d44\u6e90\u6d88\u8017\u3002", "result": "Mixtral 8x7B\u5728\u63cf\u8ff0\u5b8c\u6574\u6027\uff0899.6%\u5bf993%\uff09\u3001\u7cbe\u786e\u6027\uff0898.8%\u5bf996%\uff09\u548c\u5e7b\u89c9\u7387\uff081.2%\u5bf94%\uff09\u7b49\u65b9\u9762\u4f18\u4e8eMistral 7B\uff0c\u540c\u65f6\u5185\u5bb9\u66f4\u7b80\u6d01\uff0c\u4f46\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u663e\u8457\u66f4\u9ad8\uff0850GB VRAM\u3001$1.61/\u5c0f\u65f6 vs 5GB\u3001$0.16/\u5c0f\u65f6\uff09\u3002", "conclusion": "LLM\u80fd\u63d0\u5347\u4f4f\u5bbf\u6570\u636e\u63cf\u8ff0\u7684\u4e00\u81f4\u6027\u4e0e\u53ef\u9760\u6027\uff0c\u4f46\u9700\u8981\u5728\u6a21\u578b\u8d28\u91cf\u4e0e\u8d44\u6e90\u6548\u7387\u4e4b\u95f4\u6743\u8861\uff0c\u4e3a\u751f\u4ea7\u73af\u5883\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u9645\u6307\u5bfc\u3002"}}
{"id": "2507.22911", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22911", "abs": "https://arxiv.org/abs/2507.22911", "authors": ["Jinzhi Wang", "Qingke Peng", "Haozhou Li", "Zeyuan Zeng", "Qinfeng Song", "Kaixuan Yang", "Jiangbo Zhang", "Yaoying Wang", "Ruimeng Li", "Biyi Zhou"], "title": "ElectriQ: A Benchmark for Assessing the Response Capability of Large Language Models in Power Marketing", "comment": null, "summary": "Electric power marketing customer service plays a critical role in addressing\ninquiries, complaints, and service requests. However, current systems, such as\nChina's 95598 hotline, often struggle with slow response times, inflexible\nprocedures, and limited accuracy in domain-specific tasks. While large language\nmodels (LLMs) like GPT-4o and Claude 3 demonstrate strong general capabilities,\nthey lack the domain expertise and empathy required in this field. To bridge\nthis gap, we introduce ElectriQ, the first benchmark designed to evaluate and\nenhance LLMs in electric power marketing scenarios. ElectriQ consists of a\ndialogue dataset covering six key service categories and introduces four\nevaluation metrics: professionalism, popularity, readability, and\nuser-friendliness. We further incorporate a domain-specific knowledge base and\npropose a knowledge augmentation method to boost model performance. Experiments\non 13 LLMs reveal that smaller models such as LLama3-8B, when fine-tuned and\naugmented, can surpass GPT-4o in terms of professionalism and\nuser-friendliness. ElectriQ establishes a comprehensive foundation for\ndeveloping LLMs tailored to the needs of power marketing services.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7535\u529b\u8425\u9500\u9886\u57df\u9996\u4e2aLLM\u8bc4\u6d4b\u57fa\u51c6ElectriQ\uff0c\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u589e\u5f3a\u540e\uff0c\u5c0f\u578bLLM\u80fd\u8d85\u8fc7\u4e3b\u6d41\u5927\u6a21\u578b\uff0c\u4e3a\u667a\u80fd\u7535\u529b\u5ba2\u670d\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u7684\u7535\u529b\u8425\u9500\u5ba2\u6237\u670d\u52a1\u7cfb\u7edf\uff08\u5982\u4e2d\u56fd95598\u70ed\u7ebf\uff09\u5b58\u5728\u54cd\u5e94\u6162\u3001\u6d41\u7a0b\u50f5\u5316\u3001\u5904\u7406\u4e13\u4e1a\u9886\u57df\u95ee\u9898\u51c6\u786e\u7387\u4f4e\u7b49\u95ee\u9898\u3002\u540c\u65f6\uff0c\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u62e5\u6709\u826f\u597d\u7684\u901a\u7528\u80fd\u529b\uff0c\u4f46\u7f3a\u4e4f\u7535\u529b\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u548c\u5171\u60c5\u80fd\u529b\uff0c\u96be\u4ee5\u6ee1\u8db3\u590d\u6742\u5ba2\u6237\u670d\u52a1\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86ElectriQ\uff0c\u8fd9\u662f\u9996\u4e2a\u9762\u5411\u7535\u529b\u8425\u9500\u573a\u666f\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u6d4b\u57fa\u51c6\u3002ElectriQ\u5305\u542b\u8986\u76d6\u516d\u5927\u670d\u52a1\u7c7b\u522b\u7684\u5bf9\u8bdd\u6570\u636e\u96c6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u56db\u4e2a\u8bc4\u4ef7\u6307\u6807\uff1a\u4e13\u4e1a\u6027\u3001\u901a\u7528\u6027\u3001\u53ef\u8bfb\u6027\u3001\u6613\u7528\u6027\u3002\u8fd8\u878d\u5165\u4e86\u9886\u57df\u7279\u5b9a\u7684\u77e5\u8bc6\u5e93\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u77e5\u8bc6\u589e\u5f3a\u65b9\u6cd5\u4ee5\u63d0\u5347\u6a21\u578b\u8868\u73b0\u3002\u968f\u540e\u5bf913\u4e2a\u4e3b\u6d41LLM\u8fdb\u884c\u4e86\u5b9e\u9a8c\u8bc1\u660e\u6210\u6548\u3002", "result": "\u7ecf\u8fc7\u5fae\u8c03\u548c\u77e5\u8bc6\u589e\u5f3a\u540e\uff0c\u5c0f\u578b\u6a21\u578b\uff08\u5982LLama3-8B\uff09\u5728\u4e13\u4e1a\u6027\u548c\u7528\u6237\u53cb\u597d\u6027\u4e0a\u751a\u81f3\u80fd\u8d85\u8fc7GPT-4o\u3002ElectriQ\u4e3a\u540e\u7eed\u53d1\u5c55\u66f4\u5951\u5408\u7535\u529b\u8425\u9500\u9700\u6c42\u7684\u4e13\u7528LLM\u63d0\u4f9b\u4e86\u6570\u636e\u548c\u8bc4\u6d4b\u57fa\u7840\u3002", "conclusion": "ElectriQ\u57fa\u51c6\u586b\u8865\u4e86\u7535\u529b\u8425\u9500\u9886\u57dfLLM\u8bc4\u6d4b\u7684\u7a7a\u767d\uff0c\u901a\u8fc7\u4e13\u4e1a\u6570\u636e\u96c6\u548c\u6307\u6807\u63a8\u52a8\u6a21\u578b\u9488\u5bf9\u6027\u63d0\u5347\uff0c\u5bf9\u667a\u80fd\u5ba2\u6237\u670d\u52a1\u9886\u57df\u5177\u6709\u91cd\u8981\u63a8\u52a8\u4f5c\u7528\u3002"}}
{"id": "2507.22912", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T07, 68T50"], "pdf": "https://arxiv.org/pdf/2507.22912", "abs": "https://arxiv.org/abs/2507.22912", "authors": ["Navid Yazdanjue", "Morteza Rakhshaninejad", "Hossein Yazdanjouei", "Mohammad Sadegh Khorshidi", "Mikko S. Niemela", "Fang Chen", "Amir H. Gandomi"], "title": "A Language Model-Driven Semi-Supervised Ensemble Framework for Illicit Market Detection Across Deep/Dark Web and Social Platforms", "comment": "16 pages, 5 figures, 9 tables", "summary": "Illegal marketplaces have increasingly shifted to concealed parts of the\ninternet, including the deep and dark web, as well as platforms such as\nTelegram, Reddit, and Pastebin. These channels enable the anonymous trade of\nillicit goods including drugs, weapons, and stolen credentials. Detecting and\ncategorizing such content remains challenging due to limited labeled data, the\nevolving nature of illicit language, and the structural heterogeneity of online\nsources. This paper presents a hierarchical classification framework that\ncombines fine-tuned language models with a semi-supervised ensemble learning\nstrategy to detect and classify illicit marketplace content across diverse\nplatforms. We extract semantic representations using ModernBERT, a transformer\nmodel for long documents, finetuned on domain-specific data from deep and dark\nweb pages, Telegram channels, Subreddits, and Pastebin pastes to capture\nspecialized jargon and ambiguous linguistic patterns. In addition, we\nincorporate manually engineered features such as document structure, embedded\npatterns including Bitcoin addresses, emails, and IPs, and metadata, which\ncomplement language model embeddings. The classification pipeline operates in\ntwo stages. The first stage uses a semi-supervised ensemble of XGBoost, Random\nForest, and SVM with entropy-based weighted voting to detect sales-related\ndocuments. The second stage further classifies these into drug, weapon, or\ncredential sales. Experiments on three datasets, including our multi-source\ncorpus, DUTA, and CoDA, show that our model outperforms several baselines,\nincluding BERT, ModernBERT, DarkBERT, ALBERT, Longformer, and BigBird. The\nmodel achieves an accuracy of 0.96489, an F1-score of 0.93467, and a TMCC of\n0.95388, demonstrating strong generalization, robustness under limited\nsupervision, and effectiveness in real-world illicit content detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u91c7\u7528\u591a\u5c42\u6b21\u5206\u7c7b\u6846\u67b6\u53ca\u591a\u7279\u5f81\u878d\u5408\uff0c\u5229\u7528\u589e\u5f3a\u7248ModernBERT\u4e0e\u52a0\u6743\u96c6\u6210\u534a\u76d1\u7763\u5b66\u4e60\uff0c\u6709\u6548\u63d0\u5347\u5728\u6df1\u7f51\u7b49\u591a\u5e73\u53f0\u975e\u6cd5\u5546\u54c1\u8bc6\u522b\u4e0a\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5176\u8868\u73b0\u8d85\u8d8a\u8bf8\u591a\u4e3b\u6d41\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u968f\u7740\u975e\u6cd5\u5e02\u573a\u8f6c\u5411\u66f4\u52a0\u9690\u853d\u7684\u4e92\u8054\u7f51\u90e8\u5206\uff08\u6df1\u7f51\u3001\u6697\u7f51\u7b49\uff09\uff0c\u4ee5\u53caTelegram\u3001Reddit\u3001Pastebin\u7b49\u5e73\u53f0\uff0c\u68c0\u6d4b\u548c\u5206\u7c7b\u6b64\u7c7b\u975e\u6cd5\u5185\u5bb9\u53d8\u5f97\u66f4\u5177\u6311\u6218\u6027\u3002\u539f\u56e0\u5728\u4e8e\u6807\u6ce8\u6570\u636e\u6709\u9650\u3001\u975e\u6cd5\u8bed\u8a00\u4e0d\u65ad\u6f14\u53d8\u3001\u6570\u636e\u7ed3\u6784\u5f02\u8d28\u6027\u9ad8\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5c42\u6b21\u5316\u5206\u7c7b\u6846\u67b6\uff0c\u5c06\u7ecf\u8fc7\u9884\u8bad\u7ec3\u548c\u9886\u57df\u5fae\u8c03\u7684ModernBERT\u8bed\u8a00\u6a21\u578b\u4e0e\u534a\u76d1\u7763\u96c6\u6210\u5b66\u4e60\uff08XGBoost\u3001Random Forest\u3001SVM\u901a\u8fc7\u57fa\u4e8e\u71b5\u7684\u52a0\u6743\u6295\u7968\uff09\u7ed3\u5408\u3002\u9996\u5148\u8bc6\u522b\u9500\u552e\u76f8\u5173\u6587\u6863\uff0c\u518d\u7ec6\u5206\u4e3a\u6bd2\u54c1\u3001\u6b66\u5668\u6216\u51ed\u8bc1\u4e70\u5356\u3002\u540c\u65f6\u7ed3\u5408\u4eba\u5de5\u8bbe\u8ba1\u7279\u5f81\uff08\u5982\u7ed3\u6784\u7279\u5f81\u3001\u5d4c\u5165\u5f0f\u6bd4\u7279\u5e01\u5730\u5740\u3001\u90ae\u7bb1\u3001IP\u548c\u5143\u6570\u636e\uff09\u589e\u5f3a\u6a21\u578b\u8868\u73b0\u3002", "result": "\u5728\u4e09\u7ec4\u6570\u636e\u96c6\uff08\u5305\u62ec\u81ea\u5efa\u591a\u6e90\u8bed\u6599\u5e93\u3001DUTA\u3001CoDA\uff09\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6240\u63d0\u6a21\u578b\u5728\u51c6\u786e\u7387\uff080.96489\uff09\u3001F1 \u5206\u6570\uff080.93467\uff09\u3001TMCC\uff080.95388\uff09\u7b49\u591a\u9879\u6307\u6807\u4e0a\u4f18\u4e8eBERT\u3001ModernBERT\u3001DarkBERT\u3001ALBERT\u3001Longformer\u3001BigBird\u7b49\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u7ed3\u5408\u5148\u8fdb\u8bed\u8a00\u6a21\u578b\u9886\u57df\u5fae\u8c03\u4e0e\u591a\u7279\u5f81\u96c6\u6210\u5b66\u4e60\uff0c\u80fd\u5728\u975e\u6cd5\u5e02\u573a\u5185\u5bb9\u8bc6\u522b\u4e0e\u5206\u7c7b\u4e0a\u83b7\u5f97\u5353\u8d8a\u4e14\u7a33\u5065\u7684\u6548\u679c\uff0c\u5c24\u5176\u9002\u5e94\u6570\u636e\u7a00\u7f3a\u548c\u590d\u6742\u73af\u5883\u3002\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u5f3a\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u73af\u5883\u4e0b\u7684\u975e\u6cd5\u5185\u5bb9\u4fa6\u6d4b\u3002"}}
{"id": "2507.23151", "categories": ["cs.PL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.23151", "abs": "https://arxiv.org/abs/2507.23151", "authors": ["Louis Rustenholz", "Pedro Lopez-Garcia", "Manuel V. Hermenegildo"], "title": "Abstractions of Sequences, Functions and Operators", "comment": "Under consideration for publication in STTT", "summary": "We present theoretical and practical results on the order theory of lattices\nof functions, focusing on Galois connections that abstract (sets of) functions\n- a topic known as higher-order abstract interpretation.\n  We are motivated by the challenge of inferring closed-form bounds on\nfunctions which are defined recursively, i.e. as the fixed point of an operator\nor, equivalently, as the solution to a functional equation. This has multiple\napplications in program analysis (e.g. cost analysis, loop acceleration,\ndeclarative language analysis) and in hybrid systems governed by differential\nequations.\n  Our main contribution is a new family of constraint-based abstract domains\nfor abstracting numerical functions, B-bound domains, which abstract a function\nf by a conjunction of bounds from a preselected set of boundary functions. They\nallow inferring highly non-linear numerical invariants, which classical\nnumerical abstract domains struggle with. We uncover a convexity property in\nthe constraint space that simplifies, and, in some cases, fully automates,\ntransfer function design.\n  We also introduce domain abstraction, a functor that lifts arbitrary mappings\nin value space to Galois connections in function space. This supports\nabstraction from symbolic to numerical functions (i.e. size abstraction), and\nenables dimensionality reduction of equations.\n  We base our constructions of transfer functions on a simple operator\nlanguage, starting with sequences, and extending to more general functions,\nincluding multivariate, piecewise, and non-discrete domains.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faB-bound\u7ea6\u675f\u57df\uff0c\u5b9e\u73b0\u5bf9\u590d\u6742\u9012\u5f52\u51fd\u6570\u7684\u9ad8\u5ea6\u975e\u7ebf\u6027\u6570\u503c\u4e0d\u53d8\u91cf\u7684\u81ea\u52a8\u5316\u63a8\u65ad\uff0c\u540c\u65f6\u501f\u52a9\u57df\u62bd\u8c61\u548c\u51f8\u6027\u7279\u6027\uff0c\u63d0\u5347\u4e86\u62bd\u8c61\u89e3\u91ca\u5728\u7a0b\u5e8f\u5206\u6790\u7b49\u9886\u57df\u7684\u6548\u7387\u548c\u81ea\u52a8\u5316\u6c34\u5e73\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u4e3a\u4e86\u63a8\u5bfc\u9012\u5f52\u5b9a\u4e49\u51fd\u6570\uff08\u5982\u7b97\u5b50\u4e0d\u52a8\u70b9\u6216\u6cdb\u51fd\u65b9\u7a0b\u89e3\uff09\u7684\u95ed\u5f0f\u754c\u9650\uff0c\u8fd9\u5bf9\u4e8e\u7a0b\u5e8f\u5206\u6790\uff08\u5982\u590d\u6742\u6027\u5206\u6790\u3001\u5faa\u73af\u52a0\u901f\u3001\u58f0\u660e\u5f0f\u8bed\u8a00\u5206\u6790\uff09\u548c\u6df7\u5408\u7cfb\u7edf\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u3002\u4f20\u7edf\u6570\u503c\u62bd\u8c61\u57df\u96be\u4ee5\u63a8\u65ad\u9ad8\u5ea6\u975e\u7ebf\u6027\u6570\u503c\u4e0d\u53d8\u91cf\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u7406\u8bba\u548c\u5de5\u5177\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ea6\u675f\u7684\u62bd\u8c61\u57dfB-bound\uff08\u8fb9\u754c\u7ed1\u5b9a\uff09\u57df\uff0c\u7528\u4e00\u7ec4\u9884\u9009\u7684\u8fb9\u754c\u51fd\u6570\u7684\u7ed3\u5408\u6765\u62bd\u8c61\u6570\u503c\u51fd\u6570\u3002\u8fd9\u79cd\u65b9\u6cd5\u53ef\u63a8\u65ad\u96be\u4ee5\u901a\u8fc7\u4f20\u7edf\u6570\u503c\u62bd\u8c61\u57df\u53d1\u73b0\u7684\u9ad8\u5ea6\u975e\u7ebf\u6027\u4e0d\u53d8\u91cf\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u4e86\u57df\u62bd\u8c61\u5316\u65b9\u6cd5\u2014\u2014\u4e00\u79cd\u51fd\u5b50\uff0c\u53ef\u5c06\u4efb\u610f\u503c\u57df\u6620\u5c04\u63d0\u5347\u5230\u51fd\u6570\u57df\u7684\u4f3d\u7f57\u74e6\u8fde\u63a5\uff0c\u652f\u6301\u5c06\u7b26\u53f7\u51fd\u6570\u62bd\u8c61\u4e3a\u6570\u503c\u51fd\u6570\uff0c\u5b9e\u73b0\u7ef4\u5ea6\u7ea6\u7b80\u3002\u76f8\u5173\u7684\u8f6c\u79fb\u51fd\u6570\u5728\u7b80\u5355\u7684\u7b97\u5b50\u8bed\u8a00\u57fa\u7840\u4e0a\u6784\u5efa\uff0c\u6db5\u76d6\u5e8f\u5217\u3001\u591a\u5143\u3001\u5206\u6bb5\u53ca\u975e\u79bb\u6563\u57df\u51fd\u6570\u3002", "result": "B-bound\u62bd\u8c61\u57df\u80fd\u591f\u81ea\u52a8\u3001\u9ad8\u6548\u5730\u63a8\u65ad\u9ad8\u5ea6\u975e\u7ebf\u6027\u7684\u6570\u503c\u4e0d\u53d8\u91cf\u3002\u7ea6\u675f\u7a7a\u95f4\u4e2d\u63ed\u793a\u7684\u51f8\u6027\u7279\u6027\u53ef\u7b80\u5316\u751a\u81f3\u81ea\u52a8\u5316\u8f6c\u79fb\u51fd\u6570\u7684\u8bbe\u8ba1\u3002\u57df\u62bd\u8c61\u5316\u6280\u672f\u5219\u652f\u6301\u65b9\u7a0b\u6c42\u89e3\u7684\u7ef4\u5ea6\u7ea6\u7b80\u548c\u66f4\u52a0\u666e\u9002\u7684\u62bd\u8c61\u80fd\u529b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b0\u578b\u57fa\u4e8e\u7ea6\u675f\u7684B-bound\u62bd\u8c61\u57df\u53ca\u5176\u76f8\u5173\u65b9\u6cd5\u5728\u9ad8\u9636\u62bd\u8c61\u89e3\u91ca\u3001\u590d\u6742\u9012\u5f52\u51fd\u6570\u7ea6\u675f\u63a8\u7406\u7b49\u65b9\u9762\u8868\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u4e3a\u7a0b\u5e8f\u5206\u6790\u548c\u6df7\u5408\u7cfb\u7edf\u4e2d\u51fd\u6570\u63a8\u65ad\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u8def\u5f84\u3002"}}
{"id": "2507.22913", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22913", "abs": "https://arxiv.org/abs/2507.22913", "authors": ["Jinyu Liu", "Xiaoying Song", "Diana Zhang", "Jason Thomale", "Daqing He", "Lingzi Hong"], "title": "A Hybrid Framework for Subject Analysis: Integrating Embedding-Based Regression Models with Large Language Models", "comment": "13 pages, 2 figures, accepted by ASIST 2025", "summary": "Providing subject access to information resources is an essential function of\nany library management system. Large language models (LLMs) have been widely\nused in classification and summarization tasks, but their capability to perform\nsubject analysis is underexplored. Multi-label classification with traditional\nmachine learning (ML) models has been used for subject analysis but struggles\nwith unseen cases. LLMs offer an alternative but often over-generate and\nhallucinate. Therefore, we propose a hybrid framework that integrates\nembedding-based ML models with LLMs. This approach uses ML models to (1)\npredict the optimal number of LCSH labels to guide LLM predictions and (2)\npost-edit the predicted terms with actual LCSH terms to mitigate\nhallucinations. We experimented with LLMs and the hybrid framework to predict\nthe subject terms of books using the Library of Congress Subject Headings\n(LCSH). Experiment results show that providing initial predictions to guide LLM\ngenerations and imposing post-edits result in more controlled and\nvocabulary-aligned outputs.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u7528\u673a\u5668\u5b66\u4e60\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u7684\u65b9\u6cd5\u6539\u8fdb\u56fe\u4e66\u4e3b\u9898\u8bcd\u81ea\u52a8\u5206\u914d\uff0c\u5728\u51c6\u786e\u7387\u548c\u8bcd\u6c47\u4e00\u81f4\u6027\u4e0a\u4f18\u4e8e\u5355\u4e00LLM\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7684\u591a\u6807\u7b7e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u867d\u7136\u7528\u4e8e\u4e3b\u9898\u5206\u6790\uff0c\u4f46\u5728\u5904\u7406\u65b0\u7684\u3001\u672a\u77e5\u7684\u6848\u4f8b\u65f6\u6548\u679c\u4e0d\u4f73\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5bb9\u6613\u4ea7\u751f\u8fc7\u591a\u6807\u7b7e\u548c\u5e7b\u89c9\uff08\u5373\u751f\u6210\u4e0d\u51c6\u786e\u7684\u4fe1\u606f\uff09\uff0c\u4e9f\u9700\u66f4\u6709\u6548\u548c\u53ef\u9760\u7684\u65b9\u6848\u8fdb\u884c\u6587\u732e\u4e3b\u9898\u5206\u6790\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u5d4c\u5165\u5f0f\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7ed3\u5408\u7684\u6df7\u5408\u6846\u67b6\u3002\u5177\u4f53\u5305\u62ec\uff1a1\uff09\u7528ML\u6a21\u578b\u9884\u6d4b\u6700\u4f18\u7684LCSH\u6807\u7b7e\u6570\u91cf\u6765\u6307\u5bfcLLM\u7684\u751f\u6210\u8fc7\u7a0b\uff1b2\uff09\u5bf9LLM\u8f93\u51fa\u7684\u4e3b\u9898\u8bcd\u8fdb\u884c\u540e\u671f\u7f16\u8f91\uff0c\u4f7f\u5176\u4e0e\u5b9e\u9645LCSH\u672f\u8bed\u4e00\u81f4\uff0c\u4ece\u800c\u51cf\u5c11\u5e7b\u89c9\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5229\u7528ML\u6a21\u578b\u7684\u521d\u6b65\u9884\u6d4b\u6765\u6307\u5bfcLLM\u751f\u6210\uff0c\u4ee5\u53ca\u540e\u671f\u7684\u672f\u8bed\u6821\u6b63\uff0c\u80fd\u591f\u66f4\u597d\u5730\u63a7\u5236LLM\u8f93\u51fa\uff0c\u5e76\u4f7f\u5176\u4e0e\u6807\u51c6\u8bcd\u6c47\u66f4\u4e3a\u4e00\u81f4\u3002\u751f\u6210\u7684\u4e3b\u9898\u8bcd\u66f4\u7cbe\u51c6\u3001\u89c4\u8303\u3002", "conclusion": "\u6df7\u5408\u4e86\u5d4c\u5165\u5f0fML\u6a21\u578b\u548cLLM\u7684\u4e3b\u9898\u5206\u6790\u6846\u67b6\uff0c\u80fd\u6709\u6548\u63d0\u5347\u4e3b\u9898\u8bcd\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u89c4\u8303\u6027\uff0c\u51cf\u5c11\u6a21\u578b\u5e7b\u89c9\uff0c\u9002\u7528\u4e8e\u4e3a\u56fe\u4e66\u5206\u914d\u5408\u9002\u7684LCSH\u4e3b\u9898\u3002"}}
{"id": "2507.23205", "categories": ["cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.23205", "abs": "https://arxiv.org/abs/2507.23205", "authors": ["Hebi Li", "Forrest Sheng Bao", "Qi Xiao", "Jin Tian"], "title": "Kernel-FFI: Transparent Foreign Function Interfaces for Interactive Notebooks", "comment": null, "summary": "Foreign Function Interfaces (FFIs) are essential for enabling\ninteroperability between programming languages, yet existing FFI solutions are\nill-suited for the dynamic, interactive workflows prevalent in modern notebook\nenvironments such as Jupyter. Current approaches require extensive manual\nconfiguration, introduce significant boilerplate, and often lack support for\nrecursive calls and object-oriented programming (OOP) constructs-features\ncritical for productive, multi-language development.\n  We present Kernel-FFI, a transparent, language-agnostic framework that\nenables seamless cross-language function calls and object manipulation within\ninteractive notebooks. Kernel-FFI employs source-level transformation to\nautomatically rewrite cross-language invocations, eliminating the need for\nmanual bindings or boilerplate. Kernel-FFI provides robust support for OOP by\nenabling foreign object referencing and automatic resource management across\nlanguage boundaries. Furthermore, to address the blocking nature of Jupyter\nkernels and support recursive and asynchronous foreign calls, we introduce a\nnovel side-channel communication mechanism. Our tool will be open-sourced and\navailable at https://codepod.io/docs/kernel-ffi", "AI": {"tldr": "Kernel-FFI\u662f\u4e00\u79cd\u652f\u6301\u4ea4\u4e92\u5f0f\u7b14\u8bb0\u672c\uff08\u5982Jupyter\uff09\u8de8\u8bed\u8a00\u529f\u80fd\u8c03\u7528\u548c\u5bf9\u8c61\u64cd\u4f5c\u7684\u81ea\u52a8\u5316FFI\u6846\u67b6\uff0c\u7b80\u5316\u4e86\u591a\u8bed\u8a00\u534f\u4f5c\u5f00\u53d1\uff0c\u5b9e\u73b0\u4e86\u66f4\u5f3a\u5927\u7684OOP\u548c\u9012\u5f52/\u5f02\u6b65\u8c03\u7528\u652f\u6301\u3002", "motivation": "\u73b0\u6709\u7684\u5916\u90e8\u51fd\u6570\u63a5\u53e3\uff08FFI\uff09\u96be\u4ee5\u6ee1\u8db3\u8bf8\u5982Jupyter\u7b14\u8bb0\u672c\u7b49\u73b0\u4ee3\u4ea4\u4e92\u5f0f\u73af\u5883\u4e2d\u7684\u52a8\u6001\u5f00\u53d1\u9700\u6c42\uff0c\u4e3b\u8981\u95ee\u9898\u5305\u62ec\u624b\u52a8\u914d\u7f6e\u7e41\u7410\u3001\u6a21\u677f\u4ee3\u7801\u591a\u3001\u9012\u5f52\u8c03\u7528\u548c\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\uff08OOP\uff09\u652f\u6301\u4e0d\u8db3\uff0c\u4e25\u91cd\u5f71\u54cd\u591a\u8bed\u8a00\u5f00\u53d1\u6548\u7387\u3002", "method": "\u63d0\u51faKernel-FFI\u6846\u67b6\uff0c\u91c7\u7528\u6e90\u4ee3\u7801\u7ea7\u8f6c\u6362\u81ea\u52a8\u91cd\u5199\u8de8\u8bed\u8a00\u8c03\u7528\uff0c\u65e0\u9700\u624b\u52a8\u7ed1\u5b9a\u6216\u6a21\u677f\u4ee3\u7801\uff1b\u901a\u8fc7\u65b0\u9896\u7684\u8f85\u52a9\u901a\u9053\u901a\u4fe1\u673a\u5236\u89e3\u51b3Jupyter\u5185\u6838\u963b\u585e\u95ee\u9898\uff0c\u652f\u6301\u9012\u5f52\u4e0e\u5f02\u6b65\u5916\u90e8\u8c03\u7528\uff0c\u540c\u65f6\u5b9e\u73b0\u8de8\u8bed\u8a00\u5bf9\u8c61\u5f15\u7528\u548c\u81ea\u52a8\u8d44\u6e90\u7ba1\u7406\u4ee5\u589e\u5f3aOOP\u652f\u6301\u3002", "result": "Kernel-FFI\u5b9e\u73b0\u4e86\u5728\u4ea4\u4e92\u5f0f\u7b14\u8bb0\u672c\u4e2d\u65e0\u7f1d\u7684\u8de8\u8bed\u8a00\u51fd\u6570\u8c03\u7528\u548c\u5bf9\u8c61\u64cd\u4f5c\uff0c\u663e\u8457\u7b80\u5316\u4e86\u5f00\u53d1\u6d41\u7a0b\uff0c\u63d0\u5347\u4e86\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u7684\u5de5\u4f5c\u6548\u7387\u3002\u5de5\u5177\u5c06\u5f00\u6e90\u63d0\u4f9b\u3002", "conclusion": "Kernel-FFI\u4e3a\u73b0\u4ee3\u4ea4\u4e92\u5f0f\u5f00\u53d1\u73af\u5883\u5e26\u6765\u4e86\u900f\u660e\u4e14\u9ad8\u6548\u7684\u8bed\u8a00\u4e92\u64cd\u4f5c\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u4ee5\u5f80FFI\u5728Jupyter\u7b49\u7b14\u8bb0\u672c\u73af\u5883\u4e2d\u7684\u4e3b\u8981\u75db\u70b9\uff0c\u7279\u522b\u662f\u5728OOP\u548c\u9012\u5f52/\u5f02\u6b65\u8c03\u7528\u65b9\u9762\u3002"}}
{"id": "2507.23603", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.23603", "abs": "https://arxiv.org/abs/2507.23603", "authors": ["Andoni Rodriguez", "Irfansha Shaik", "Davide Corsi", "Roy Fox", "Cesar Sanchez"], "title": "Explanations for Unrealizability of Infinite-State Safety Shields", "comment": null, "summary": "Safe Reinforcement Learning focuses on developing optimal policies while\nensuring safety. A popular method to address such task is shielding, in which a\ncorrect-by-construction safety component is synthesized from logical\nspecifications. Recently, shield synthesis has been extended to infinite-state\ndomains, such as continuous environments. This makes shielding more applicable\nto realistic scenarios. However, often shields might be unrealizable because\nthe specification is inconsistent (e.g., contradictory). In order to address\nthis gap, we present a method to obtain simple unconditional and conditional\nexplanations that witness unrealizability, which goes by temporal formula\nunrolling. In this paper, we show different variants of the technique and its\napplicability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u65f6\u5e8f\u516c\u5f0f\u5c55\u5f00\u6765\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u5b89\u5168\u5c4f\u853d\u4e0d\u53ef\u5b9e\u73b0\u6027\u7684\u6280\u672f\uff0c\u80fd\u6709\u6548\u4e3a\u89c4\u8303\u4e0d\u4e00\u81f4\u9020\u6210\u7684\u95ee\u9898\u7ed9\u51fa\u76f4\u89c2\u8bf4\u660e\uff0c\u589e\u5f3a\u4e86\u5c4f\u853d\u65b9\u6cd5\u5728\u590d\u6742\u8fde\u7eed\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u65e8\u5728\u4f18\u5316\u7b56\u7565\u7684\u540c\u65f6\u4fdd\u8bc1\u7cfb\u7edf\u5b89\u5168\u3002\u73b0\u6709\u7684\u5c4f\u853d\u6280\u672f\u5b58\u5728\u65e0\u6cd5\u5b9e\u73b0\u7684\u95ee\u9898\uff0c\u901a\u5e38\u6e90\u4e8e\u89c4\u8303\u81ea\u8eab\u4e0d\u4e00\u81f4\uff08\u5982\u77db\u76fe\uff09\uff0c\u8fd9\u4e00\u95ee\u9898\u76f4\u63a5\u963b\u788d\u4e86\u5c4f\u853d\u65b9\u6cd5\u5728\u5b9e\u9645\u590d\u6742\u73af\u5883\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65f6\u5e8f\u516c\u5f0f\u5c55\u5f00\u7684\u6280\u672f\uff0c\u7528\u4e8e\u751f\u6210\u7b80\u5355\u7684\u65e0\u6761\u4ef6\u548c\u6709\u6761\u4ef6\u89e3\u91ca\uff0c\u5e2e\u52a9\u89e3\u91ca\u5c4f\u853d\u65e0\u6cd5\u5b9e\u73b0\u7684\u5177\u4f53\u539f\u56e0\u3002\u6587\u4e2d\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u4e0d\u540c\u53d8\u4f53\u53ca\u5176\u9002\u7528\u6027\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u4e3a\u4e0d\u53ef\u80fd\u5b9e\u73b0\u5c4f\u853d\u7684\u60c5\u5f62\u63d0\u4f9b\u660e\u6670\u7684\u89e3\u91ca\uff0c\u4ece\u800c\u5f25\u8865\u4e86\u4ee5\u5f80\u5c4f\u853d\u6280\u672f\u5728\u9762\u5bf9\u89c4\u8303\u4e0d\u4e00\u81f4\u65f6\u7684\u5206\u6790\u7a7a\u767d\u3002", "conclusion": "\u901a\u8fc7\u65f6\u5e8f\u516c\u5f0f\u5c55\u5f00\u83b7\u53d6\u89e3\u91ca\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u8005\u5feb\u901f\u5b9a\u4f4d\u548c\u7406\u89e3\u5c4f\u853d\u7269\u7406\u4e0d\u53ef\u5b9e\u73b0\u7684\u6839\u672c\u539f\u56e0\uff0c\u63d0\u5347\u4e86\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u5728\u5b9e\u9645\u8fde\u7eed\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2507.23087", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23087", "abs": "https://arxiv.org/abs/2507.23087", "authors": ["Fabian Stiehle", "Hans Weytjens", "Ingo Weber"], "title": "On LLM-Assisted Generation of Smart Contracts from Business Processes", "comment": "Accepted at the Workshop on Distributed Ledger Technologies in\n  Business Process Management, At the International Conference for Business\n  Process Management (BPM), 2025", "summary": "Large language models (LLMs) have changed the reality of how software is\nproduced. Within the wider software engineering community, among many other\npurposes, they are explored for code generation use cases from different types\nof input. In this work, we present an exploratory study to investigate the use\nof LLMs for generating smart contract code from business process descriptions,\nan idea that has emerged in recent literature to overcome the limitations of\ntraditional rule-based code generation approaches. However, current LLM-based\nwork evaluates generated code on small samples, relying on manual inspection,\nor testing whether code compiles but ignoring correct execution. With this\nwork, we introduce an automated evaluation framework and provide empirical data\nfrom larger data sets of process models. We test LLMs of different types and\nsizes in their capabilities of achieving important properties of process\nexecution, including enforcing process flow, resource allocation, and\ndata-based conditions. Our results show that LLM performance falls short of the\nperfect reliability required for smart contract development. We suggest future\nwork to explore responsible LLM integrations in existing tools for code\ngeneration to ensure more reliable output. Our benchmarking framework can serve\nas a foundation for developing and evaluating such integrations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u8bc4\u6d4bLLM\u751f\u6210\u667a\u80fd\u5408\u7ea6\u4ee3\u7801\u7684\u6846\u67b6\uff0c\u53d1\u73b0\u73b0\u6709LLM\u5728\u53ef\u9760\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5efa\u8bae\u672a\u6765\u7ed3\u5408\u8bc4\u6d4b\u6846\u67b6\u4f18\u5316LLM\u5728\u5b9e\u9645\u5f00\u53d1\u4e2d\u5e94\u7528\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u751f\u6210\u4e3b\u8981\u4f9d\u8d56\u4eba\u5de5\u68c0\u67e5\u6216\u7f16\u8bd1\u901a\u8fc7\uff0c\u7f3a\u4e4f\u5bf9\u4ee3\u7801\u6b63\u786e\u6267\u884c\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\uff0c\u5c24\u5176\u5728\u667a\u80fd\u5408\u7ea6\u751f\u6210\u9886\u57df\uff0c\u4f20\u7edf\u65b9\u6cd5\u5c40\u9650\u660e\u663e\uff0c\u56e0\u6b64\u4e9f\u9700\u66f4\u81ea\u52a8\u5316\u3001\u5168\u9762\u7684\u8bc4\u6d4b\u6846\u67b6\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u8bc4\u6d4b\u6846\u67b6\uff0c\u57fa\u4e8e\u5927\u89c4\u6a21\u4e1a\u52a1\u6d41\u7a0b\u6a21\u578b\u6570\u636e\u96c6\uff0c\u5bf9\u4e0d\u540c\u578b\u53f7\u548c\u89c4\u6a21\u7684LLM\u8fdb\u884c\u5b9e\u9a8c\uff0c\u91cd\u70b9\u8003\u5bdfLLM\u5728\u6d41\u7a0b\u6267\u884c\u7279\u6027\uff08\u5982\u6d41\u7a0b\u6d41\u8f6c\u3001\u8d44\u6e90\u5206\u914d\u3001\u57fa\u4e8e\u6570\u636e\u7684\u6761\u4ef6\uff09\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0c\u73b0\u6709LLM\u5728\u667a\u80fd\u5408\u7ea6\u5f00\u53d1\u6240\u9700\u7684\u53ef\u9760\u6027\u4e0a\u8868\u73b0\u4e0d\u8db3\uff0c\u672a\u80fd\u8fbe\u5230\u5b9e\u9645\u5e94\u7528\u6807\u51c6\u3002", "conclusion": "\u63d0\u51fa\u5e94\u5728\u73b0\u6709\u4ee3\u7801\u751f\u6210\u5de5\u5177\u4e2d\u63a2\u7d22\u8d1f\u8d23\u4efb\u5730\u96c6\u6210LLM\u65b9\u6cd5\uff0c\u7ed3\u5408\u8be5\u8bc4\u6d4b\u6846\u67b6\u4ee5\u63d0\u5347\u8f93\u51fa\u53ef\u9760\u6027\uff0c\u4e3a\u672a\u6765\u76f8\u5173\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2507.22914", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.22914", "abs": "https://arxiv.org/abs/2507.22914", "authors": ["Victor Eiti Yamamoto", "Hideaki Takeda"], "title": "Full Triple Matcher: Integrating all triple elements between heterogeneous Knowledge Graphs", "comment": null, "summary": "Knowledge graphs (KGs) are powerful tools for representing and reasoning over\nstructured information. Their main components include schema, identity, and\ncontext. While schema and identity matching are well-established in ontology\nand entity matching research, context matching remains largely unexplored. This\nis particularly important because real-world KGs often vary significantly in\nsource, size, and information density - factors not typically represented in\nthe datasets on which current entity matching methods are evaluated. As a\nresult, existing approaches may fall short in scenarios where diverse and\ncomplex contexts need to be integrated.\n  To address this gap, we propose a novel KG integration method consisting of\nlabel matching and triple matching. We use string manipulation, fuzzy matching,\nand vector similarity techniques to align entity and predicate labels. Next, we\nidentify mappings between triples that convey comparable information, using\nthese mappings to improve entity-matching accuracy. Our approach demonstrates\ncompetitive performance compared to leading systems in the OAEI competition and\nagainst supervised methods, achieving high accuracy across diverse test cases.\nAdditionally, we introduce a new dataset derived from the benchmark dataset to\nevaluate the triple-matching step more comprehensively.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u77e5\u8bc6\u56fe\u8c31\u96c6\u6210\u65b9\u6cd5\uff0c\u91cd\u70b9\u89e3\u51b3\u73b0\u5b9e\u5f02\u8d28\u77e5\u8bc6\u56fe\u8c31\u7684\u4e0a\u4e0b\u6587\u96c6\u6210\u96be\u9898\uff0c\u5728\u516c\u5f00\u7ade\u8d5b\u548c\u591a\u7c7b\u6d4b\u8bd5\u4e2d\u83b7\u5f97\u4e86\u9ad8\u51c6\u786e\u7387\uff0c\u5e76\u53d1\u5e03\u4e86\u65b0\u6570\u636e\u96c6\u3002", "motivation": "\u73b0\u6709\u5173\u4e8e\u672c\u4f53\u548c\u5b9e\u4f53\u5339\u914d\u7684\u7814\u7a76\u591a\u96c6\u4e2d\u4e8e\u6a21\u5f0f(schema)\u4e0e\u8eab\u4efd(identity)\u5339\u914d\uff0c\u5bf9\u4e8e\u8bed\u5883(context)\u5339\u914d\u7814\u7a76\u8f83\u5c11\uff1b\u800c\u5b9e\u9645\u77e5\u8bc6\u56fe\u8c31\u5728\u4fe1\u606f\u6e90\u3001\u89c4\u6a21\u548c\u5bc6\u5ea6\u7b49\u65b9\u9762\u9ad8\u5ea6\u5f02\u8d28\uff0c\u56e0\u6b64\u5f53\u524d\u5b9e\u4f53\u5339\u914d\u65b9\u6cd5\u5728\u590d\u6742\u591a\u53d8\u7684\u80cc\u666f\u4e0b\u5c06\u9762\u4e34\u6311\u6218\u3002\u4f5c\u8005\u65e8\u5728\u5f25\u8865\u5f53\u524d\u7814\u7a76\u5728\u590d\u6742\u4e0a\u4e0b\u6587\u96c6\u6210\u80fd\u529b\u4e0a\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6807\u7b7e\u5339\u914d\u4e0e\u4e09\u5143\u7ec4\u5339\u914d\u7684\u77e5\u8bc6\u56fe\u8c31\u96c6\u6210\u65b9\u6cd5\uff0c\u5176\u4e2d\u91c7\u7528\u5b57\u7b26\u4e32\u5904\u7406\u3001\u6a21\u7cca\u5339\u914d\u548c\u5411\u91cf\u76f8\u4f3c\u5ea6\u6280\u672f\u5bf9\u5b9e\u4f53\u4e0e\u8c13\u8bcd\u6807\u7b7e\u5bf9\u9f50\uff0c\u5e76\u8bc6\u522b\u8868\u8fbe\u53ef\u6bd4\u4fe1\u606f\u7684\u4e09\u5143\u7ec4\u6620\u5c04\uff0c\u4ece\u800c\u63d0\u9ad8\u5b9e\u4f53\u5339\u914d\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728OAEI\u7ade\u8d5b\u4e2d\u4ee5\u53ca\u4e0e\u6709\u76d1\u7763\u65b9\u6cd5\u5bf9\u6bd4\u4e0b\u8868\u73b0\u5177\u6709\u7ade\u4e89\u529b\uff0c\u5e76\u5728\u5404\u7c7b\u6d4b\u8bd5\u7528\u4f8b\u4e0a\u53d6\u5f97\u9ad8\u7cbe\u51c6\u5ea6\uff1b\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u6784\u5efa\u4e86\u4e00\u4e2a\u65b0\u6570\u636e\u96c6\u7528\u4e8e\u8bc4\u4f30\u4e09\u5143\u7ec4\u5339\u914d\u6b65\u9aa4\uff0c\u63d0\u5347\u8bc4\u6d4b\u5168\u9762\u6027\u3002", "conclusion": "\u4f5c\u8005\u63d0\u51fa\u7684\u65b9\u6cd5\u5728OAEI\u7ade\u8d5b\u53ca\u4e0e\u6709\u76d1\u7763\u65b9\u6cd5\u7684\u5bf9\u6bd4\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5728\u591a\u6837\u5316\u7684\u6d4b\u8bd5\u573a\u666f\u4e0b\u53d6\u5f97\u4e86\u9ad8\u51c6\u786e\u7387\u3002"}}
{"id": "2507.23118", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.23118", "abs": "https://arxiv.org/abs/2507.23118", "authors": ["Mattia Di Profio", "Mingjun Zhong", "Yaji Sripada", "Marcel Jaspars"], "title": "FlowETL: An Autonomous Example-Driven Pipeline for Data Engineering", "comment": null, "summary": "The Extract, Transform, Load (ETL) workflow is fundamental for populating and\nmaintaining data warehouses and other data stores accessed by analysts for\ndownstream tasks. A major shortcoming of modern ETL solutions is the extensive\nneed for a human-in-the-loop, required to design and implement\ncontext-specific, and often non-generalisable transformations. While related\nwork in the field of ETL automation shows promising progress, there is a lack\nof solutions capable of automatically designing and applying these\ntransformations. We present FlowETL, a novel example-based autonomous ETL\npipeline architecture designed to automatically standardise and prepare input\ndatasets according to a concise, user-defined target dataset. FlowETL is an\necosystem of components which interact together to achieve the desired outcome.\nA Planning Engine uses a paired input-output datasets sample to construct a\ntransformation plan, which is then applied by an ETL worker to the source\ndataset. Monitoring and logging provide observability throughout the entire\npipeline. The results show promising generalisation capabilities across 14\ndatasets of various domains, file structures, and file sizes.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u4e86FlowETL\u7cfb\u7edf\uff0c\u53ef\u6839\u636e\u793a\u4f8b\u81ea\u52a8\u89c4\u5212\u548c\u6267\u884cETL\u8f6c\u6362\u4efb\u52a1\uff0c\u5728\u591a\u79cd\u7c7b\u578b\u7684\u6570\u636e\u96c6\u4e0a\u5c55\u73b0\u4e86\u8f83\u5f3a\u7684\u81ea\u52a8\u5316\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u6781\u5927\u7b80\u5316\u4e86\u4f20\u7edfETL\u6d41\u7a0b\u4e2d\u7684\u4eba\u5de5\u8bbe\u8ba1\u8fc7\u7a0b\u3002", "motivation": "\u5f53\u524dETL\uff08\u63d0\u53d6\u3001\u8f6c\u6362\u3001\u52a0\u8f7d\uff09\u6d41\u7a0b\u5bf9\u4e8e\u6570\u636e\u4ed3\u5e93\u548c\u6570\u636e\u5206\u6790\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709ETL\u65b9\u6848\u5927\u591a\u4f9d\u8d56\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u548c\u5b9e\u73b0\u7279\u5b9a\u573a\u666f\u4e0b\u7684\u6570\u636e\u8f6c\u6362\uff0c\u96be\u4ee5\u81ea\u52a8\u5316\u548c\u6cdb\u5316\u5904\u7406\u5404\u79cd\u7c7b\u578b\u7684\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e86FlowETL\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u793a\u4f8b\u7684\u81ea\u4e3bETL\u7ba1\u9053\u67b6\u6784\uff0c\u80fd\u591f\u6839\u636e\u7528\u6237\u5b9a\u4e49\u7684\u76ee\u6807\u6570\u636e\u96c6\u81ea\u52a8\u6807\u51c6\u5316\u548c\u51c6\u5907\u8f93\u5165\u6570\u636e\u3002\u8be5\u67b6\u6784\u5305\u62ec\u89c4\u5212\u5f15\u64ce\uff08\u6839\u636e\u8f93\u5165-\u8f93\u51fa\u6837\u672c\u81ea\u52a8\u751f\u6210\u8f6c\u6362\u8ba1\u5212\uff09\u3001ETL\u5de5\u4f5c\u5355\u5143\uff08\u81ea\u52a8\u65bd\u52a0\u8f6c\u6362\uff09\uff0c\u5e76\u5728\u6574\u4e2a\u6d41\u7a0b\u4e2d\u63d0\u4f9b\u76d1\u63a7\u4e0e\u65e5\u5fd7\u3002", "result": "FlowETL\u572814\u4e2a\u5305\u542b\u4e0d\u540c\u9886\u57df\u3001\u6587\u4ef6\u7ed3\u6784\u548c\u6587\u4ef6\u5927\u5c0f\u7684\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4e86\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u81ea\u52a8\u5b9e\u73b0\u4e86\u6570\u636e\u8f6c\u6362\u548c\u6807\u51c6\u5316\u3002", "conclusion": "FlowETL\u80fd\u591f\u5b9e\u73b0ETL\u6d41\u7a0b\u7684\u9ad8\u6548\u81ea\u52a8\u5316\uff0c\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\uff0c\u5bf9\u4e8e\u63d0\u5347\u6570\u636e\u9884\u5904\u7406\u6548\u7387\u548c\u7075\u6d3b\u6027\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2507.22915", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22915", "abs": "https://arxiv.org/abs/2507.22915", "authors": ["Esmail Gumaan"], "title": "Theoretical Foundations and Mitigation of Hallucination in Large Language Models", "comment": "12 pages", "summary": "Hallucination in Large Language Models (LLMs) refers to the generation of\ncontent that is not faithful to the input or the real-world facts. This paper\nprovides a rigorous treatment of hallucination in LLMs, including formal\ndefinitions and theoretical analyses. We distinguish between intrinsic and\nextrinsic hallucinations, and define a \\textit{hallucination risk} for models.\nWe derive bounds on this risk using learning-theoretic frameworks (PAC-Bayes\nand Rademacher complexity). We then survey detection strategies for\nhallucinations, such as token-level uncertainty estimation, confidence\ncalibration, and attention alignment checks. On the mitigation side, we discuss\napproaches including retrieval-augmented generation, hallucination-aware\nfine-tuning, logit calibration, and the incorporation of fact-verification\nmodules. We propose a unified detection and mitigation workflow, illustrated\nwith a diagram, to integrate these strategies. Finally, we outline evaluation\nprotocols for hallucination, recommending datasets, metrics, and experimental\nsetups to quantify and reduce hallucinations. Our work lays a theoretical\nfoundation and practical guidelines for addressing the crucial challenge of\nhallucination in LLMs.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u7406\u8bba\u4e0a\u754c\u5b9a\u98ce\u9669\u5e76\u96c6\u6210\u591a\u7b56\u7565\u68c0\u6d4b\u4e0e\u7f13\u89e3\u624b\u6bb5\uff0c\u63d0\u51fa\u8bc4\u4f30\u6d41\u7a0b\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u4e0e\u5e94\u7528\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "LLM\u5e38\u51fa\u73b0\u751f\u6210\u5185\u5bb9\u4e0e\u8f93\u5165\u6216\u4e8b\u5b9e\u4e0d\u4e00\u81f4\u7684\u5e7b\u89c9\u73b0\u8c61\uff0c\u4e9f\u9700\u7cfb\u7edf\u7684\u7406\u8bba\u5206\u6790\u4e0e\u5b9e\u9645\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u5347\u6a21\u578b\u53ef\u9760\u6027\u3002", "method": "\u91c7\u7528\u4e86\u7406\u8bba\u5206\u6790\uff08\u5982PAC-Bayes\u3001Rademacher\u590d\u6742\u5ea6\uff09\u754c\u5b9a\u5e7b\u89c9\u98ce\u9669\uff0c\u7efc\u8ff0\u4e86\u591a\u79cd\u5e7b\u89c9\u68c0\u6d4b\u548c\u7f13\u89e3\u6280\u672f\uff0c\u5e76\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u5de5\u4f5c\u6d41\u53ca\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u533a\u5206\u4e86\u5185\u5728\u4e0e\u5916\u5728\u5e7b\u89c9\uff0c\u5b9a\u4e49\u4e86\u5e7b\u89c9\u98ce\u9669\u5e76\u7ed9\u51fa\u4e86\u7406\u8bba\u754c\uff0c\u901a\u8fc7\u8c03\u7814\u548c\u96c6\u6210\u68c0\u6d4b\u4e0e\u7f13\u89e3\u65b9\u6848\uff0c\u63d0\u51fa\u4e86\u8bc4\u6d4b\u6d41\u7a0b\u4e0e\u5b9e\u8df5\u6307\u5357\u3002", "conclusion": "\u672c\u6587\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u7684\u5e7b\u89c9\u73b0\u8c61\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u9645\u64cd\u4f5c\u5efa\u8bae\uff0c\u4ece\u5b9a\u4e49\u3001\u98ce\u9669\u754c\u5b9a\u5230\u68c0\u6d4b\u4e0e\u7f13\u89e3\uff0c\u5e76\u63d0\u51fa\u4e86\u53ef\u8bc4\u4f30\u7684\u5b9e\u9a8c\u6d41\u7a0b\uff0c\u4e3a\u672a\u6765\u89e3\u51b3\u5e7b\u89c9\u95ee\u9898\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2507.23120", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.23120", "abs": "https://arxiv.org/abs/2507.23120", "authors": ["Jordi Cabot"], "title": "Vibe Modeling: Challenges and Opportunities", "comment": null, "summary": "There is a pressing need for better development methods and tools to keep up\nwith the growing demand and increasing complexity of new software systems. New\ntypes of user interfaces, the need for intelligent components, sustainability\nconcerns, ... bring new challenges that we need to handle. In the last years,\nmodel-driven engineering (MDE) has been key to improving the quality and\nproductivity of software development, but models themselves are becoming\nincreasingly complex to specify and manage. At the same time, we are witnessing\nthe growing popularity of vibe coding approaches that rely on Large Language\nModels (LLMs) to transform natural language descriptions into running code at\nthe expenses of code vulnerabilities, scalability issues and maintainability\nconcerns. In this paper, we introduce the concept of \\textit{vibe modeling} as\na novel approach to integrate the best of both worlds (AI and MDE) to speed up\nthe development of reliable complex systems. We outline the key concepts of\nvibe modeling and highlight the opportunities and open challenges it presents\nfor the future of modeling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4ee5vibe modeling\u6574\u5408AI\uff08LLM\uff09\u548cMDE\u4f18\u70b9\uff0c\u52a0\u901f\u5e76\u63d0\u5347\u590d\u6742\u8f6f\u4ef6\u7cfb\u7edf\u5f00\u53d1\uff0c\u5c55\u671b\u4e86\u5176\u673a\u9047\u4e0e\u6311\u6218\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u7cfb\u7edf\u9700\u6c42\u589e\u957f\u548c\u590d\u6742\u6027\u63d0\u5347\uff0c\u73b0\u6709\u5f00\u53d1\u65b9\u6cd5\u548c\u5de5\u5177\u96be\u4ee5\u6ee1\u8db3\u9700\u6c42\u3002\u65b0\u578b\u7528\u6237\u754c\u9762\u3001\u667a\u80fd\u7ec4\u4ef6\u548c\u53ef\u6301\u7eed\u6027\u7b49\u95ee\u9898\u4e5f\u5e26\u6765\u65b0\u7684\u6311\u6218\u3002\u5c3d\u7ba1\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\uff08MDE\uff09\u63d0\u5347\u4e86\u8f6f\u4ef6\u5f00\u53d1\u7684\u8d28\u91cf\u548c\u751f\u4ea7\u529b\uff0c\u4f46\u6a21\u578b\u672c\u8eab\u53d8\u5f97\u8d8a\u6765\u8d8a\u590d\u6742\u3002\u540c\u65f6\uff0c\u4f9d\u9760\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u81ea\u7136\u8bed\u8a00\u5230\u4ee3\u7801\u81ea\u52a8\u751f\u6210\u7684\u201cvibe coding\u201d\u6d41\u884c\u8d77\u6765\uff0c\u5374\u5b58\u5728\u4ee3\u7801\u8106\u5f31\u3001\u5b89\u5168\u3001\u53ef\u7ef4\u62a4\u6027\u5dee\u7b49\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201cvibe modeling\u201d\u7684\u65b0\u8303\u5f0f\uff0c\u5b83\u5c06\u4eba\u5de5\u667a\u80fd\uff08\u5982LLMs\uff09\u7684\u4f18\u52bf\u4e0e\u4f20\u7edf\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\uff08MDE\uff09\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u590d\u6742\u7cfb\u7edf\u7684\u9ad8\u53ef\u9760\u6027\u3001\u9ad8\u6548\u5f00\u53d1\u3002\u6587\u7ae0\u6982\u8ff0\u4e86vibe modeling\u7684\u6838\u5fc3\u6982\u5ff5\u4e0e\u65b9\u6cd5\u3002", "result": "\u672c\u6587\u5c55\u793a\u4e86vibe modeling\u878d\u5408AI\u4e0eMDE\u7684\u53ef\u80fd\u6027\uff0c\u6307\u51fa\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u63d0\u5347\u5f00\u53d1\u6548\u7387\u4e0e\u7cfb\u7edf\u53ef\u9760\u6027\uff0c\u540c\u65f6\u4e5f\u63d0\u51fa\u4e86\u5176\u9762\u4e34\u7684\u65b0\u673a\u9047\u4e0e\u6311\u6218\u3002", "conclusion": "vibe modeling\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u5efa\u6a21\u65b9\u5f0f\uff0c\u6709\u671b\u52a0\u901f\u590d\u6742\u7cfb\u7edf\u7684\u5f00\u53d1\u5e76\u63d0\u5347\u5176\u53ef\u9760\u6027\uff0c\u4e3a\u8f6f\u4ef6\u5efa\u6a21\u7684\u672a\u6765\u63d0\u4f9b\u65b0\u65b9\u5411\uff0c\u4f46\u8fd8\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u63a2\u8ba8\u5176\u5177\u4f53\u5b9e\u73b0\u4e0e\u6311\u6218\u3002"}}
{"id": "2507.22917", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.22917", "abs": "https://arxiv.org/abs/2507.22917", "authors": ["Kwun Hang Lau", "Ruiyuan Zhang", "Weijie Shi", "Xiaofang Zhou", "Xiaojun Cheng"], "title": "Reading Between the Timelines: RAG for Answering Diachronic Questions", "comment": null, "summary": "While Retrieval-Augmented Generation (RAG) excels at injecting static,\nfactual knowledge into Large Language Models (LLMs), it exhibits a critical\ndeficit in handling longitudinal queries that require tracking entities and\nphenomena across time. This blind spot arises because conventional,\nsemantically-driven retrieval methods are not equipped to gather evidence that\nis both topically relevant and temporally coherent for a specified duration. We\naddress this challenge by proposing a new framework that fundamentally\nredesigns the RAG pipeline to infuse temporal logic. Our methodology begins by\ndisentangling a user's query into its core subject and its temporal window. It\nthen employs a specialized retriever that calibrates semantic matching against\ntemporal relevance, ensuring the collection of a contiguous evidence set that\nspans the entire queried period. To enable rigorous evaluation of this\ncapability, we also introduce the Analytical Diachronic Question Answering\nBenchmark (ADQAB), a challenging evaluation suite grounded in a hybrid corpus\nof real and synthetic financial news. Empirical results on ADQAB show that our\napproach yields substantial gains in answer accuracy, surpassing standard RAG\nimplementations by 13% to 27%. This work provides a validated pathway toward\nRAG systems capable of performing the nuanced, evolutionary analysis required\nfor complex, real-world questions. The dataset and code for this study are\npublicly available at https://github.com/kwunhang/TA-RAG.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5728RAG\u4e2d\u5f15\u5165\u65f6\u5e8f\u903b\u8f91\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u62c6\u89e3\u67e5\u8be2\u548c\u7279\u5316\u68c0\u7d22\uff0c\u6709\u6548\u8986\u76d6\u65f6\u95f4\u8de8\u5ea6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5728\u590d\u6742\u957f\u671f\u95ee\u9898\u4e0a\u7cbe\u5ea6\u63d0\u5347\u663e\u8457\uff0c\u540c\u65f6\u516c\u5f00\u4e86\u6570\u636e\u548c\u4ee3\u7801\u3002", "motivation": "\u4f20\u7edfRAG\u65b9\u6cd5\u53ea\u91cd\u89c6\u8bed\u4e49\u76f8\u5173\u6027\uff0c\u96be\u4ee5\u5904\u7406\u9700\u8ffd\u8e2a\u5b9e\u4f53\u548c\u73b0\u8c61\u968f\u65f6\u95f4\u6f14\u53d8\u7684\u957f\u671f\u67e5\u8be2\uff0c\u56e0\u6b64\u9700\u901a\u8fc7\u5f15\u5165\u65f6\u5e8f\u903b\u8f91\u89e3\u51b3\u8bc1\u636e\u68c0\u7d22\u7684\u65f6\u95f4\u4e00\u81f4\u6027\u95ee\u9898\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u5c06\u67e5\u8be2\u62c6\u5206\u4e3a\u4e3b\u9898\u6838\u5fc3\u548c\u65f6\u95f4\u7a97\u53e3\uff0c\u5e76\u901a\u8fc7\u7279\u5316\u7684\u68c0\u7d22\u5668\u7ed3\u5408\u8bed\u4e49\u4e0e\u65f6\u5e8f\u76f8\u5173\u6027\uff0c\u786e\u4fdd\u68c0\u7d22\u5230\u8986\u76d6\u6574\u4e2a\u65f6\u95f4\u6bb5\u3001\u8bdd\u9898\u76f8\u5173\u7684\u8bc1\u636e\u96c6\u5408\u3002", "result": "\u5728\u65b0\u63d0\u51fa\u7684\u91d1\u878d\u65b0\u95fb\u57fa\u51c6\u96c6ADQAB\u4e0a\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u7cbe\u786e\u7387\u6bd4\u4f20\u7edfRAG\u63d0\u5347\u4e8613%\u201427%\uff0c\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u7eb5\u5411\u5206\u6790\u80fd\u529b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u5728RAG\u7cfb\u7edf\u4e2d\u6ce8\u5165\u65f6\u95f4\u903b\u8f91\u7684\u65b0\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5176\u5904\u7406\u6a2a\u8de8\u65f6\u95f4\u7684\u590d\u6742\u67e5\u8be2\u7684\u80fd\u529b\uff0c\u5728\u6743\u5a01\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5927\u5e45\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2507.23168", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.23168", "abs": "https://arxiv.org/abs/2507.23168", "authors": ["Elmira Onagh", "Maleknaz Nayebi"], "title": "Extension Decisions in Open Source Software Ecosystem", "comment": "Paper published in JSS journal", "summary": "GitHub Marketplace is expanding by approximately 41% annually, with new\ntools; however, many additions replicate existing functionality. We study this\nphenomenon in the platform's largest segment, Continuous Integration (CI), by\nlinking 6,983 CI Actions to 3,869 providers and mining their version histories.\nOur graph model timestamps every functionality's debut, tracks its adoption,\nand clusters redundant tools. We find that approximately 65% of new CI Actions\nreplicate existing capabilities, typically within six months, and that a small\nset of first-mover Actions accounts for most subsequent forks and extensions.\nThese insights enable developers to choose the optimal moment to launch, target\nunmet functionality, and help maintainers eliminate redundant tools. We publish\nthe complete graph and dataset to encourage longitudinal research on innovation\nand competition in software ecosystems, and to provide practitioners with a\ndata-driven roadmap for identifying emerging trends and guiding product\nstrategy.", "AI": {"tldr": "GitHub Marketplace\u4e2d\u7ea665%\u65b0CI\u5de5\u5177\u91cd\u590d\u5df2\u6709\u529f\u80fd\uff0c\u5f71\u54cd\u521b\u65b0\u4e0e\u751f\u6001\u6548\u7387\u3002\u4f5c\u8005\u5206\u6790\u4e86\u5de5\u5177\u5197\u4f59\u7684\u65f6\u673a\u4e0e\u6a21\u5f0f\uff0c\u4e3a\u5f00\u53d1\u8005\u548c\u7ef4\u62a4\u8005\u63d0\u4f9b\u4f18\u5316\u5efa\u8bae\uff0c\u5e76\u5f00\u653e\u6570\u636e\u4f9b\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "motivation": "GitHub Marketplace\u5de5\u5177\u6570\u91cf\u6bcf\u5e74\u5feb\u901f\u589e\u957f\uff0c\u4f46\u5927\u91cf\u65b0\u589e\u5de5\u5177\u5b9e\u9645\u4e3a\u73b0\u6709\u529f\u80fd\u7684\u91cd\u590d\uff0c\u9020\u6210\u8d44\u6e90\u6d6a\u8d39\u548c\u5e02\u573a\u6df7\u4e71\u3002\u4f5c\u8005\u5e0c\u671b\u5206\u6790\u548c\u91cf\u5316\u8fd9\u79cd\u5197\u4f59\u73b0\u8c61\uff0c\u5c24\u5176\u805a\u7126\u5728\u6700\u5927\u7ec6\u5206\u9886\u57df\u2014\u2014\u6301\u7eed\u96c6\u6210\uff08CI\uff09\u5de5\u5177\u3002", "method": "\u5c066,983\u4e2aCI Action\u4e0e3,869\u4e2a\u63d0\u4f9b\u8005\u5173\u8054\uff0c\u6316\u6398\u7248\u672c\u5386\u53f2\uff0c\u5229\u7528\u56fe\u6a21\u578b\u6807\u6ce8\u6bcf\u9879\u529f\u80fd\u9996\u53d1\u65f6\u95f4\u3001\u8ddf\u8e2a\u91c7\u7eb3\u8fc7\u7a0b\uff0c\u5e76\u5bf9\u5197\u4f59\u5de5\u5177\u8fdb\u884c\u805a\u7c7b\u5206\u6790\u3002", "result": "\u7ea665%\u65b0\u589eCI Action\u4e3a\u73b0\u6709\u529f\u80fd\u7684\u518d\u5b9e\u73b0\uff0c\u4e14\u901a\u5e38\u57286\u4e2a\u6708\u5185\u53d1\u751f\u3002\u5c11\u6570\u9996\u53d1\u5de5\u5177\u6210\u4e3a\u540e\u7eed\u5e7f\u6cdb\u5206\u53c9\u548c\u6269\u5c55\u7684\u57fa\u7840\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86CI\u5de5\u5177\u5e02\u573a\u521b\u65b0\u4e0e\u91cd\u590d\u7684\u6df1\u5ea6\u5206\u6790\uff0c\u7ed3\u679c\u53ef\u6307\u5bfc\u5f00\u53d1\u8005\u9009\u62e9\u6700\u4f73\u53d1\u5e03\u65f6\u95f4\u3001\u53d1\u73b0\u5e02\u573a\u7a7a\u767d\uff0c\u5e76\u5e2e\u52a9\u7ef4\u62a4\u8005\u51cf\u5c11\u5197\u4f59\u3002\u516c\u5f00\u6570\u636e\u96c6\u6709\u52a9\u4e8e\u540e\u7eed\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u521b\u65b0\u4e0e\u7ade\u4e89\u7684\u7eb5\u5411\u7814\u7a76\u3002"}}
{"id": "2507.22918", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2507.22918", "abs": "https://arxiv.org/abs/2507.22918", "authors": ["Daniel Son", "Sanjana Rathore", "Andrew Rufail", "Adrian Simon", "Daniel Zhang", "Soham Dave", "Cole Blondin", "Kevin Zhu", "Sean O'Brien"], "title": "Semantic Convergence: Investigating Shared Representations Across Scaled LLMs", "comment": "Submitted to ACL 2025 Student Research Workshop (poster)", "summary": "We investigate feature universality in Gemma-2 language models (Gemma-2-2B\nand Gemma-2-9B), asking whether models with a four-fold difference in scale\nstill converge on comparable internal concepts. Using the Sparse Autoencoder\n(SAE) dictionary-learning pipeline, we utilize SAEs on each model's\nresidual-stream activations, align the resulting monosemantic features via\nactivation correlation, and compare the matched feature spaces with SVCCA and\nRSA. Middle layers yield the strongest overlap, while early and late layers\nshow far less similarity. Preliminary experiments extend the analysis from\nsingle tokens to multi-token subspaces, showing that semantically similar\nsubspaces interact similarly with language models. These results strengthen the\ncase that large language models carve the world into broadly similar,\ninterpretable features despite size differences, reinforcing universality as a\nfoundation for cross-model interpretability.", "AI": {"tldr": "\u65e0\u8bba\u53c2\u6570\u89c4\u6a21\uff0cGemma-2\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e2d\u95f4\u5c42\u90fd\u80fd\u751f\u6210\u7c7b\u4f3c\u7684\u5185\u90e8\u8bed\u4e49\u7279\u5f81\uff0c\u8fdb\u4e00\u6b65\u8bc1\u660e\u7279\u5f81\u901a\u7528\u6027\u6709\u52a9\u4e8e\u8de8\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u63a2\u7a76\u4e0d\u540c\u89c4\u6a21\uff082B\u548c9B\u53c2\u6570\u91cf\uff09Gemma-2\u8bed\u8a00\u6a21\u578b\u5728\u5185\u90e8\u7279\u5f81\u4e0a\u7684\u901a\u7528\u6027\uff0c\u4ee5\u53ca\u6a21\u578b\u89c4\u6a21\u5dee\u5f02\u662f\u5426\u5f71\u54cd\u5176\u5185\u90e8\u8bed\u4e49\u6982\u5ff5\u7684\u8d8b\u540c\u3002\u6b64\u7c7b\u7814\u7a76\u6709\u52a9\u4e8e\u63a8\u52a8\u8de8\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u7684\u7814\u7a76\u57fa\u7840\u3002", "method": "\u91c7\u7528\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\uff08Sparse Autoencoder, SAE\uff09\u5bf9\u6a21\u578b\u6b8b\u5dee\u6d41\u6fc0\u6d3b\u8fdb\u884c\u5b57\u5178\u5b66\u4e60\uff0c\u63d0\u53d6\u5355\u8bed\u4e49\u7279\u5f81\u3002\u901a\u8fc7\u6fc0\u6d3b\u76f8\u5173\u6027\u5bf9\u9f50\u4e0d\u540c\u6a21\u578b\u4e4b\u95f4\u7684\u7279\u5f81\uff0c\u5e76\u8fd0\u7528SVCCA\u548cRSA\u7b49\u65b9\u6cd5\u5bf9\u6bd4\u5339\u914d\u7279\u5f81\u7a7a\u95f4\u7684\u76f8\u4f3c\u6027\u3002\u6b64\u5916\uff0c\u8fd8\u5c06\u5206\u6790\u4ece\u5355token\u6269\u5c55\u5230\u591atoken\u5b50\u7a7a\u95f4\u3002", "result": "\u53d1\u73b0\u4e2d\u95f4\u5c42\u7279\u5f81\u91cd\u53e0\u5ea6\u6700\u9ad8\uff0c\u8868\u73b0\u51fa\u8f83\u5f3a\u7684\u4e00\u81f4\u6027\uff0c\u800c\u65e9\u671f\u5c42\u548c\u540e\u671f\u5c42\u7684\u7279\u5f81\u76f8\u4f3c\u6027\u8f83\u4f4e\u3002\u521d\u6b65\u5b9e\u9a8c\u8fd8\u53d1\u73b0\uff0c\u76f8\u4f3c\u8bed\u4e49\u7684\u591atoken\u5b50\u7a7a\u95f4\u4e0e\u6a21\u578b\u7684\u76f8\u4e92\u4f5c\u7528\u65b9\u5f0f\u4e5f\u5f88\u76f8\u4f3c\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u89c4\u6a21\u4e0b\u4f1a\u63d0\u53d6\u51fa\u5927\u81f4\u76f8\u4f3c\u3001\u53ef\u89e3\u91ca\u7684\u7279\u5f81\uff0c\u8fd9\u8fdb\u4e00\u6b65\u652f\u6301\u4e86\u7279\u5f81\u901a\u7528\u6027\u7684\u89c2\u70b9\uff0c\u4e3a\u4e0d\u540c\u6a21\u578b\u95f4\u7684\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2507.23178", "categories": ["cs.SE", "cs.AI", "I.2.5"], "pdf": "https://arxiv.org/pdf/2507.23178", "abs": "https://arxiv.org/abs/2507.23178", "authors": ["Siyuan Liu", "Zhice Yang", "Huangxun Chen"], "title": "AutoBridge: Automating Smart Device Integration with Centralized Platform", "comment": "14 pages, 12 figures, under review", "summary": "Multimodal IoT systems coordinate diverse IoT devices to deliver\nhuman-centered services. The ability to incorporate new IoT devices under the\nmanagement of a centralized platform is an essential requirement. However, it\nrequires significant human expertise and effort to program the complex IoT\nintegration code that enables the platform to understand and control the device\nfunctions. Therefore, we propose AutoBridge to automate IoT integration code\ngeneration. Specifically, AutoBridge adopts a divide-and-conquer strategy: it\nfirst generates device control logic by progressively retrieving\ndevice-specific knowledge, then synthesizes platformcompliant integration code\nusing platform-specific knowledge. To ensure correctness, AutoBridge features a\nmulti-stage debugging pipeline, including an automated debugger for virtual IoT\ndevice testing and an interactive hardware-in-the-loop debugger that requires\nonly binary user feedback (yes and no) for real-device verification. We\nevaluate AutoBridge on a benchmark of 34 IoT devices across two open-source IoT\nplatforms. The results demonstrate that AutoBridge can achieves an average\nsuccess rate of 93.87% and an average function coverage of 94.87%, without any\nhuman involvement. With minimal binary yes and no feedback from users, the code\nis then revised to reach 100% function coverage. A user study with 15\nparticipants further shows that AutoBridge outperforms expert programmers by\n50% to 80% in code accuracy, even when the programmers are allowed to use\ncommercial code LLMs.", "AI": {"tldr": "AutoBridge\u901a\u8fc7\u81ea\u52a8\u5316\u65b9\u6cd5\u751f\u6210\u5e76\u8c03\u8bd5IoT\u96c6\u6210\u4ee3\u7801\uff0c\u5728\u51c6\u786e\u7387\u548c\u6548\u7387\u4e0a\u5168\u9762\u8d85\u8d8a\u4eba\u7c7b\u4e13\u5bb6\u548c\u5546\u7528\u4ee3\u7801\u5927\u6a21\u578b\uff0c\u5927\u5e45\u7b80\u5316\u7269\u8054\u7f51\u8bbe\u5907\u96c6\u6210\u6d41\u7a0b\u3002", "motivation": "\u968f\u7740\u591a\u6a21\u6001\u7269\u8054\u7f51\uff08IoT\uff09\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u96c6\u6210\u65b0\u578bIoT\u8bbe\u5907\u6210\u4e3a\u666e\u904d\u9700\u6c42\uff0c\u800c\u624b\u52a8\u7f16\u7a0b\u96c6\u6210\u4ee3\u7801\u8017\u65f6\u8d39\u529b\u4e14\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\uff0c\u6210\u4e3aIoT\u5e73\u53f0\u53d1\u5c55\u7684\u4e3b\u8981\u74f6\u9888\u3002", "method": "\u63d0\u51faAutoBridge\u7cfb\u7edf\uff0c\u91c7\u7528\u5206\u800c\u6cbb\u4e4b\u7b56\u7565\uff0c\u5148\u901a\u8fc7\u68c0\u7d22\u8bbe\u5907\u7279\u5b9a\u77e5\u8bc6\u751f\u6210\u8bbe\u5907\u63a7\u5236\u903b\u8f91\uff0c\u518d\u7ed3\u5408\u5e73\u53f0\u7279\u5b9a\u77e5\u8bc6\u5408\u6210\u5e73\u53f0\u517c\u5bb9\u7684\u96c6\u6210\u4ee3\u7801\u3002\u4e3a\u4fdd\u8bc1\u6b63\u786e\u6027\uff0c\u8bbe\u8ba1\u4e86\u5305\u542b\u865a\u62dfIoT\u8bbe\u5907\u81ea\u52a8\u8c03\u8bd5\u5668\u548c\u5b9e\u65f6\u786c\u4ef6\u4eba\u673a\u4ea4\u4e92\u8c03\u8bd5\u5668\u7684\u591a\u9636\u6bb5\u8c03\u8bd5\u6d41\u7a0b\uff0c\u5176\u4e2d\u540e\u8005\u4ec5\u9700\u7528\u6237\u4e8c\u5143\u53cd\u9988\uff08\u662f/\u5426\uff09\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u572834\u79cdIoT\u8bbe\u5907\u548c2\u4e2a\u5f00\u6e90IoT\u5e73\u53f0\u4e0a\u6d4b\u8bd5\uff0cAutoBridge\u5728\u65e0\u4eba\u53c2\u4e0e\u60c5\u51b5\u4e0b\u5e73\u5747\u6210\u529f\u7387\u4e3a93.87%\u3001\u529f\u80fd\u8986\u76d6\u7387\u4e3a94.87%\uff1b\u7ed3\u5408\u7528\u6237\u6781\u5c11\u91cf\u4e8c\u5143\u53cd\u9988\u540e\uff0c\u529f\u80fd\u8986\u76d6\u7387\u63d0\u5347\u81f3100%\u3002\u7528\u6237\u5b9e\u9a8c\u663e\u793a\uff0cAutoBridge\u7684\u4ee3\u7801\u51c6\u786e\u7387\u6bd4\u4e13\u5bb6\u7a0b\u5e8f\u5458\u9ad850%-80%\uff0c\u5373\u4fbf\u4e13\u5bb6\u53ef\u7528\u5546\u4e1a\u4ee3\u7801\u5927\u6a21\u578b\u8f85\u52a9\u3002", "conclusion": "AutoBridge\u5927\u5e45\u63d0\u9ad8\u4e86IoT\u96c6\u6210\u4ee3\u7801\u7684\u751f\u6210\u6548\u7387\u4e0e\u51c6\u786e\u6027\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u6c34\u5e73\u663e\u8457\u8d85\u8d8a\u4eba\u5de5\u4e0e\u73b0\u6709\u5de5\u5177\uff0c\u5e76\u6709\u6548\u964d\u4f4e\u4e86\u96c6\u6210\u65b0\u8bbe\u5907\u7684\u95e8\u69db\u3002"}}
{"id": "2507.22919", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22919", "abs": "https://arxiv.org/abs/2507.22919", "authors": ["Qixuan Hu", "Xumou Zhang", "Jinman Kim", "Florence Bourgeois", "Adam G. Dunn"], "title": "A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations", "comment": null, "summary": "Objectives: With accurate estimates of expected safety results, clinical\ntrials could be designed to avoid terminations and limit exposing participants\nto unnecessary risks. We evaluated methods for predicting serious adverse event\n(SAE) results in clinical trials using information only from their\nregistrations prior to the trial. Material and Methods: We analysed 22,107\ntwo-arm parallel interventional clinical trials from ClinicalTrials.gov with\nstructured summary results. Two prediction models were developed: a classifier\npredicting will experimental arm have higher SAE rates (area under the receiver\noperating characteristic curve; AUC) than control arm, and a regression model\nto predict the proportion of SAEs in control arms (root mean squared error;\nRMSE). A transfer learning approach using pretrained language models (e.g.,\nClinicalT5, BioBERT) was used for feature extraction, combined with downstream\nmodel for prediction. To maintain semantic representation in long trial texts\nexceeding localised language model input limits, a sliding window method was\ndeveloped for embedding extraction. Results: The best model\n(ClinicalT5+Transformer+MLP) had 77.6% AUC predicting which trial arm has a\nhigher proportion of patients with SAEs. When predicting proportion of\nparticipants experiencing SAE in the control arm, the same model achieved RMSE\nof 18.6%. The sliding window approach consistently outperformed methods without\nit. Across 12 classifiers, the average absolute AUC increase was 2.00%; across\n12 regressors, the average absolute RMSE reduction was 1.58%. Discussion:\nSummary results data available at ClinicalTrials.gov remains underutilised. The\npotential to estimate results of trials before they start is an opportunity to\nimprove trial design and flag discrepancies between expected and reported\nsafety results.", "AI": {"tldr": "\u8be5\u7814\u7a76\u57fa\u4e8e2\u4e07\u4f59\u9879\u4e34\u5e8a\u8bd5\u9a8c\u6ce8\u518c\u6570\u636e\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u548c\u6ed1\u52a8\u7a97\u53e3\u6cd5\uff0c\u5f00\u53d1\u51fa\u53ef\u8f83\u597d\u9884\u6d4b\u8bd5\u9a8c\u4e2d\u4e25\u91cd\u4e0d\u826f\u4e8b\u4ef6\u7684\u65b0\u6a21\u578b\uff0c\u6709\u52a9\u4e8e\u63d0\u524d\u8bc4\u4f30\u8bd5\u9a8c\u98ce\u9669\u3001\u4f18\u5316\u8bbe\u8ba1\u3002", "motivation": "\u4e34\u5e8a\u8bd5\u9a8c\u5982\u679c\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u5b89\u5168\u7ed3\u679c\uff0c\u53ef\u4ee5\u907f\u514d\u8bd5\u9a8c\u4e2d\u9014\u7ec8\u6b62\uff0c\u4e5f\u80fd\u51cf\u5c11\u53c2\u4e0e\u8005\u66b4\u9732\u4e8e\u4e0d\u5fc5\u8981\u98ce\u9669\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u65e8\u5728\u5229\u7528\u73b0\u6709\u6ce8\u518c\u4fe1\u606f\uff0c\u4ec5\u57fa\u4e8e\u8bd5\u9a8c\u6ce8\u518c\u524d\u8d44\u6599\u9884\u6d4b\u4e25\u91cd\u4e0d\u826f\u4e8b\u4ef6\uff08SAE\uff09\u7684\u53d1\u751f\u60c5\u51b5\u3002", "method": "\u4f5c\u8005\u5206\u6790\u4e86ClinicalTrials.gov\u4e0a22,107\u9879\u4e24\u7ec4\u5e73\u884c\u5bf9\u7167\u5e72\u9884\u578b\u4e34\u5e8a\u8bd5\u9a8c\u3002\u5f00\u53d1\u4e86\u4e24\u4e2a\u9884\u6d4b\u6a21\u578b\uff1a\u4e00\u662f\u5206\u7c7b\u6a21\u578b\u9884\u6d4b\u5b9e\u9a8c\u7ec4\u7684SAE\u53d1\u751f\u7387\u662f\u5426\u9ad8\u4e8e\u5bf9\u7167\u7ec4\uff08\u7528AUC\u8bc4\u4ef7\uff09\uff1b\u4e8c\u662f\u56de\u5f52\u6a21\u578b\u9884\u6d4b\u5bf9\u7167\u7ec4SAE\u53d1\u751f\u6bd4\u4f8b\uff08\u7528RMSE\u8bc4\u4ef7\uff09\u3002\u65b9\u6cd5\u91c7\u7528\u8f6c\u79fb\u5b66\u4e60\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08\u5982ClinicalT5\u3001BioBERT\uff09\u63d0\u53d6\u7279\u5f81\uff0c\u5e76\u7ed3\u5408\u4e0b\u6e38\u9884\u6d4b\u6a21\u578b\u3002\u4e3a\u5904\u7406\u8bd5\u9a8c\u6587\u672c\u8f83\u957f\u8d85\u51fa\u6a21\u578b\u8f93\u5165\u957f\u5ea6\uff0c\u63d0\u51fa\u6ed1\u52a8\u7a97\u53e3\u5d4c\u5165\u63d0\u53d6\u6cd5\u3002", "result": "\u6700\u4f73\u6a21\u578b\uff08ClinicalT5+Transformer+MLP\uff09\u5728\u9884\u6d4b\u54ea\u4e2a\u8bd5\u9a8c\u7ec4SAE\u6bd4\u4f8b\u66f4\u9ad8\u65f6AUC\u4e3a77.6%\uff1b\u9884\u6d4b\u5bf9\u7167\u7ec4SAE\u53d1\u751f\u6bd4\u4f8b\u65f6\uff0cRMSE\u4e3a18.6%\u3002\u6ed1\u52a8\u7a97\u53e3\u6cd5\u5728\u6240\u6709\u6a21\u578b\u4e2d\u90fd\u4f18\u4e8e\u672a\u7528\u8be5\u6cd5\u7684\u6a21\u578b\uff0c\u5e73\u5747\u4f7fAUC\u63d0\u53472.00%\uff0cRMSE\u4e0b\u964d1.58%\u3002", "conclusion": "\u5229\u7528\u6ce8\u518c\u524d\u7684\u4e34\u5e8a\u8bd5\u9a8c\u4fe1\u606f\u548c\u516c\u5f00\u7ed3\u679c\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u53ef\u6709\u6548\u9884\u6d4b\u8bd5\u9a8c\u4e2d\u7684\u4e25\u91cd\u4e0d\u826f\u4e8b\u4ef6\u3002\u8fd9\u6709\u52a9\u4e8e\u4f18\u5316\u4e34\u5e8a\u8bd5\u9a8c\u8bbe\u8ba1\uff0c\u63d0\u5347\u5b89\u5168\u6027\u548c\u6548\u7387\u3002ClinicalTrials.gov\u4e0a\u7684\u603b\u7ed3\u6027\u7ed3\u679c\u6570\u636e\u5c1a\u672a\u88ab\u5145\u5206\u5229\u7528\u3002"}}
{"id": "2507.23269", "categories": ["cs.SE", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.23269", "abs": "https://arxiv.org/abs/2507.23269", "authors": ["Peter Fettke", "Fabiana Fournier", "Lior Limonad", "Andreas Metzger", "Stefanie Rinderle-Ma", "Barbara Weber"], "title": "XABPs: Towards eXplainable Autonomous Business Processes", "comment": null, "summary": "Autonomous business processes (ABPs), i.e., self-executing workflows\nleveraging AI/ML, have the potential to improve operational efficiency, reduce\nerrors, lower costs, improve response times, and free human workers for more\nstrategic and creative work. However, ABPs may raise specific concerns\nincluding decreased stakeholder trust, difficulties in debugging, hindered\naccountability, risk of bias, and issues with regulatory compliance. We argue\nfor eXplainable ABPs (XABPs) to address these concerns by enabling systems to\narticulate their rationale. The paper outlines a systematic approach to XABPs,\ncharacterizing their forms, structuring explainability, and identifying key BPM\nresearch challenges towards XABPs.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u81ea\u4e3b\u4e1a\u52a1\u6d41\u7a0b\u5e26\u6765\u7684\u4fe1\u4efb\u4e0e\u76d1\u7ba1\u7b49\u95ee\u9898\uff0c\u63d0\u51fa\u5e76\u7cfb\u7edf\u5316\u4e86\u53ef\u89e3\u91ca\u7684ABPs\uff08XABPs\uff09\u6846\u67b6\uff0c\u4e3a\u672a\u6765\u4e1a\u52a1\u6d41\u7a0b\u7ba1\u7406\u63d0\u4f9b\u4e86\u7814\u7a76\u548c\u5b9e\u8df5\u8def\u5f84\u3002", "motivation": "\u81ea\u4e3b\u4e1a\u52a1\u6d41\u7a0b\uff08ABPs\uff09\u5229\u7528AI/ML\u81ea\u52a8\u6267\u884c\u590d\u6742\u6d41\u7a0b\uff0c\u5177\u5907\u63d0\u5347\u6548\u7387\u3001\u964d\u4f4e\u9519\u8bef\u548c\u6210\u672c\u3001\u63d0\u5347\u54cd\u5e94\u901f\u5ea6\u7b49\u6f5c\u529b\u3002\u4f46\u8fd9\u7c7b\u7cfb\u7edf\u5e26\u6765\u4e86\u5982\u4fe1\u4efb\u5ea6\u4e0b\u964d\u3001\u8c03\u8bd5\u56f0\u96be\u3001\u95ee\u8d23\u673a\u5236\u5f31\u5316\u3001\u504f\u5dee\u98ce\u9669\u53ca\u5408\u89c4\u6311\u6218\u7b49\u95ee\u9898\u3002", "method": "\u6587\u7ae0\u63d0\u51fa\u4e86\u201c\u53ef\u89e3\u91ca\u7684\u81ea\u4e3b\u4e1a\u52a1\u6d41\u7a0b\uff08XABPs\uff09\u201d\u7684\u7cfb\u7edf\u6027\u65b9\u6cd5\uff0c\u6db5\u76d6\u53ef\u89e3\u91ca\u6027\u6a21\u5f0f\u7684\u5b9a\u4e49\u3001\u7ed3\u6784\u5316\uff0c\u5e76\u8bc6\u522b\u4e86\u76f8\u5173\u7684\u4e1a\u52a1\u6d41\u7a0b\u7ba1\u7406\uff08BPM\uff09\u9886\u57df\u7684\u6838\u5fc3\u7814\u7a76\u96be\u9898\u3002", "result": "\u7cfb\u7edf\u9610\u8ff0\u4e86\u6784\u5efaXABPs\u7684\u591a\u79cd\u5f62\u5f0f\u3001\u53ef\u89e3\u91ca\u6027\u7684\u7ed3\u6784\u4ee5\u53ca\u672a\u6765\u5e94\u5173\u6ce8\u7684\u4e3b\u8981\u7814\u7a76\u6311\u6218\u3002", "conclusion": "\u63a8\u884cXABPs\u4e0d\u4ec5\u6709\u52a9\u4e8e\u89e3\u51b3AI\u9a71\u52a8\u6d41\u7a0b\u4e2d\u7684\u4fe1\u4efb\u3001\u95ee\u8d23\u548c\u5408\u89c4\u7b49\u98ce\u9669\u95ee\u9898\uff0c\u4e5f\u4e3aBPM\u7814\u7a76\u6307\u660e\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.22920", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22920", "abs": "https://arxiv.org/abs/2507.22920", "authors": ["Jindong Li", "Yali Fu", "Jiahong Liu", "Linxiao Cao", "Wei Ji", "Menglin Yang", "Irwin King", "Ming-Hsuan Yang"], "title": "Discrete Tokenization for Multimodal LLMs: A Comprehensive Survey", "comment": null, "summary": "The rapid advancement of large language models (LLMs) has intensified the\nneed for effective mechanisms to transform continuous multimodal data into\ndiscrete representations suitable for language-based processing. Discrete\ntokenization, with vector quantization (VQ) as a central approach, offers both\ncomputational efficiency and compatibility with LLM architectures. Despite its\ngrowing importance, there is a lack of a comprehensive survey that\nsystematically examines VQ techniques in the context of LLM-based systems. This\nwork fills this gap by presenting the first structured taxonomy and analysis of\ndiscrete tokenization methods designed for LLMs. We categorize 8 representative\nVQ variants that span classical and modern paradigms and analyze their\nalgorithmic principles, training dynamics, and integration challenges with LLM\npipelines. Beyond algorithm-level investigation, we discuss existing research\nin terms of classical applications without LLMs, LLM-based single-modality\nsystems, and LLM-based multimodal systems, highlighting how quantization\nstrategies influence alignment, reasoning, and generation performance. In\naddition, we identify key challenges including codebook collapse, unstable\ngradient estimation, and modality-specific encoding constraints. Finally, we\ndiscuss emerging research directions such as dynamic and task-adaptive\nquantization, unified tokenization frameworks, and biologically inspired\ncodebook learning. This survey bridges the gap between traditional vector\nquantization and modern LLM applications, serving as a foundational reference\nfor the development of efficient and generalizable multimodal systems. A\ncontinuously updated version is available at:\nhttps://github.com/jindongli-Ai/LLM-Discrete-Tokenization-Survey.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u68b3\u7406\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u79bb\u6563\u5316\uff08\u77e2\u91cf\u91cf\u5316\uff09\u65b9\u6cd5\uff0c\u5f52\u7eb38\u79cd\u4ee3\u8868\u6027\u53d8\u4f53\uff0c\u603b\u7ed3\u73b0\u6709\u6311\u6218\u5e76\u5c55\u671b\u672a\u6765\u53d1\u5c55\uff0c\u4e3a\u591a\u6a21\u6001LLM\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u6838\u5fc3\u53c2\u8003\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u9700\u8981\u6709\u6548\u7684\u65b9\u6cd5\u5c06\u8fde\u7eed\u7684\u591a\u6a21\u6001\u6570\u636e\u8f6c\u5316\u4e3a\u9002\u5408\u8bed\u8a00\u5904\u7406\u7684\u79bb\u6563\u8868\u793a\u3002\u79bb\u6563\u5316\uff08\u5982\u77e2\u91cf\u91cf\u5316\uff0cVQ\uff09\u4e0d\u4ec5\u8ba1\u7b97\u9ad8\u6548\uff0c\u4e5f\u5951\u5408LLM\u67b6\u6784\uff0c\u4f46\u5f53\u524d\u5c1a\u65e0\u7cfb\u7edf\u7efc\u8ff0\u5206\u6790VQ\u65b9\u6cd5\u5728LLM\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u672c\u8bba\u6587\u5bf9\u7528\u4e8eLLM\u7684\u79bb\u6563\u5316\u65b9\u6cd5\u8fdb\u884c\u4e86\u9996\u6b21\u7ed3\u6784\u5316\u5206\u7c7b\u548c\u5206\u6790\u3002\u5f52\u7eb3\u603b\u7ed3\u4e868\u79cd\u5177\u6709\u4ee3\u8868\u6027\u7684VQ\u53d8\u4f53\uff0c\u7cfb\u7edf\u5206\u6790\u5176\u7b97\u6cd5\u539f\u7406\u3001\u8bad\u7ec3\u673a\u5236\u53ca\u4e0eLLM\u96c6\u6210\u7684\u6311\u6218\u3002\u6b64\u5916\uff0c\u4ece\u4f20\u7edf\u5e94\u7528\u3001\u5355\u6a21\u6001LLM\u3001\u591a\u6a21\u6001LLM\u7684\u89d2\u5ea6\u68b3\u7406\u76f8\u5173\u7814\u7a76\uff0c\u5e76\u5206\u6790\u91cf\u5316\u7b56\u7565\u5bf9\u5bf9\u9f50\u3001\u63a8\u7406\u4e0e\u751f\u6210\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u8bba\u6587\u5f52\u7eb3\u4e86VQ\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\uff0c\u5305\u62ec\u7801\u672c\u5d29\u584c\u3001\u68af\u5ea6\u4f30\u8ba1\u4e0d\u7a33\u5b9a\u3001\u7279\u5b9a\u6a21\u6001\u7f16\u7801\u7ea6\u675f\u7b49\u3002\u63a2\u8ba8\u4e86\u52a8\u6001/\u4efb\u52a1\u81ea\u9002\u5e94\u91cf\u5316\u3001\u7edf\u4e00\u79bb\u6563\u6846\u67b6\u3001\u751f\u7269\u542f\u53d1\u5f0f\u7801\u672c\u5b66\u4e60\u7b49\u672a\u6765\u65b9\u5411\u3002\u901a\u8fc7\u7cfb\u7edf\u68b3\u7406\uff0c\u642d\u5efa\u4e86VQ\u4e0e\u73b0\u4ee3LLM\u4e4b\u95f4\u7684\u6865\u6881\uff0c\u4e3a\u591a\u6a21\u6001\u7cfb\u7edf\u9ad8\u6548\u4e0e\u6cdb\u5316\u53d1\u5c55\u63d0\u4f9b\u57fa\u7840\u53c2\u8003\u3002", "conclusion": "\u672c\u7efc\u8ff0\u9996\u6b21\u7cfb\u7edf\u68b3\u7406\u4e86\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u79bb\u6563\u5316\u4e0e\u77e2\u91cf\u91cf\u5316\u65b9\u6cd5\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u77e5\u8bc6\uff0c\u5e76\u6307\u660e\u4e86\u672a\u6765\u53d1\u5c55\u4e0e\u6311\u6218\u65b9\u5411\uff0c\u662f\u8be5\u9886\u57df\u91cd\u8981\u7684\u53c2\u8003\u6587\u732e\u3002"}}
{"id": "2507.23348", "categories": ["cs.SE", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23348", "abs": "https://arxiv.org/abs/2507.23348", "authors": ["Han Li", "Yuling Shi", "Shaoxin Lin", "Xiaodong Gu", "Heng Lian", "Xin Wang", "Yantao Jia", "Tao Huang", "Qianxiang Wang"], "title": "SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution", "comment": "Our code and data are available at\n  https://github.com/YerbaPage/SWE-Debate", "summary": "Issue resolution has made remarkable progress thanks to the advanced\nreasoning capabilities of large language models (LLMs). Recently, agent-based\nframeworks such as SWE-agent have further advanced this progress by enabling\nautonomous, tool-using agents to tackle complex software engineering tasks.\nWhile existing agent-based issue resolution approaches are primarily based on\nagents' independent explorations, they often get stuck in local solutions and\nfail to identify issue patterns that span across different parts of the\ncodebase. To address this limitation, we propose SWE-Debate, a competitive\nmulti-agent debate framework that encourages diverse reasoning paths and\nachieves more consolidated issue localization. SWE-Debate first creates\nmultiple fault propagation traces as localization proposals by traversing a\ncode dependency graph. Then, it organizes a three-round debate among\nspecialized agents, each embodying distinct reasoning perspectives along the\nfault propagation trace. This structured competition enables agents to\ncollaboratively converge on a consolidated fix plan. Finally, this consolidated\nfix plan is integrated into an MCTS-based code modification agent for patch\ngeneration. Experiments on the SWE-bench benchmark show that SWE-Debate\nachieves new state-of-the-art results in open-source agent frameworks and\noutperforms baselines by a large margin.", "AI": {"tldr": "SWE-Debate\u5229\u7528\u591a\u4ee3\u7406\u8fa9\u8bba\u548c\u591a\u89c6\u89d2\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u95ee\u9898\u7684\u5b9a\u4f4d\u4e0e\u4fee\u590d\u6548\u679c\uff0c\u5728\u4e3b\u6d41\u57fa\u51c6\u4e0a\u5237\u65b0\u4e86\u6027\u80fd\u8bb0\u5f55\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5927\u6a21\u578b\u7684\u81ea\u52a8\u5316\u4ee3\u7801\u95ee\u9898\u89e3\u51b3\u8fdb\u5c55\u5f88\u5927\uff0c\u4f46\u4e3b\u6d41\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5355\u4e00\u667a\u80fd\u4f53\u7684\u72ec\u7acb\u63a2\u7d22\uff0c\u5e38\u5e38\u9677\u5165\u5c40\u90e8\u6700\u4f18\uff0c\u96be\u4ee5\u8bc6\u522b\u6d89\u53ca\u4ee3\u7801\u5e93\u4e0d\u540c\u90e8\u5206\u7684\u590d\u6742\u95ee\u9898\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aSWE-Debate\u7684\u591a\u667a\u80fd\u4f53\u7ade\u4e89\u8fa9\u8bba\u6846\u67b6\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u904d\u5386\u4ee3\u7801\u4f9d\u8d56\u56fe\uff0c\u751f\u6210\u591a\u6761\u9519\u8bef\u4f20\u64ad\u8def\u5f84\u4f5c\u4e3a\u5b9a\u4f4d\u5efa\u8bae\uff0c\u5e76\u8ba9\u4e0d\u540c\u63a8\u7406\u89c6\u89d2\u7684\u4e13\u95e8\u667a\u80fd\u4f53\u8fdb\u884c\u4e09\u56de\u5408\u8fa9\u8bba\uff0c\u6700\u7ec8\u8fbe\u6210\u7edf\u4e00\u7684\u4fee\u590d\u65b9\u6848\uff0c\u518d\u7531\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\u7684\u4ee3\u7801\u4fee\u6539\u667a\u80fd\u4f53\u751f\u6210\u8865\u4e01\u3002", "result": "\u5728SWE-bench\u57fa\u51c6\u6d4b\u8bd5\u96c6\u4e0a\uff0cSWE-Debate\u5728\u5f00\u6e90\u667a\u80fd\u4f53\u6846\u67b6\u4e2d\u53d6\u5f97\u4e86\u65b0\u7684\u6700\u4f18\u6027\u80fd\uff0c\u5e76\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u7ade\u4e89\u4e0e\u591a\u6837\u5316\u63a8\u7406\u673a\u5236\uff0cSWE-Debate\u80fd\u591f\u66f4\u52a0\u6709\u6548\u5730\u5b9a\u4f4d\u548c\u4fee\u590d\u590d\u6742\u4ee3\u7801\u95ee\u9898\uff0c\u63a8\u52a8\u4e86\u81ea\u52a8\u5316\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u7684\u8fdb\u6b65\u3002"}}
{"id": "2507.22921", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.22921", "abs": "https://arxiv.org/abs/2507.22921", "authors": ["Lee Harris"], "title": "Fast and Accurate Contextual Knowledge Extraction Using Cascading Language Model Chains and Candidate Answers", "comment": null, "summary": "Language models can capture complex relationships in given text, but these\nare notorious for being costly and for producing information that does not\nexist (i.e., hallucinations). Furthermore, the resources invested into\nproducing this information would be wasted if it were incorrect. We address\nthese issues by proposing, implementing, and applying the Language Model Chain\n(LMC) algorithm. In this, a language model's response to a given prompt about\ngiven text is only correct if it exists in the collection of possible (i.e.,\ncandidate) answers, and text corresponding to incorrect responses is fed into a\nmore predictive (but slower) language model. This process is repeated for a\ncollection of language models, or until all predictions about the text are\ncorrect. We used the LMC algorithm to extract patient dates of birth from\nmedical documents, and combining a collection of language models in a\nmulti-stage cascade significantly increased prediction speed and accuracy over\nindividual language models, while greatly reducing the number of corresponding\nhallucinations. We believe that the novel LMC algorithm significantly\ncontributes to the knowledge extraction field, and that this should be explored\nmuch further in the future.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86LMC\u7b97\u6cd5\uff0c\u5728\u591a\u6a21\u578b\u7ea7\u8054\u4e0b\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u62bd\u53d6\u533b\u7597\u6587\u672c\u4fe1\u606f\u7684\u901f\u5ea6\u548c\u51c6\u786e\u6027\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u6a21\u578b\u5e7b\u89c9\uff0c\u4e3a\u77e5\u8bc6\u62bd\u53d6\u9886\u57df\u5e26\u6765\u65b0\u601d\u8def\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u867d\u80fd\u6293\u4f4f\u6587\u672c\u590d\u6742\u5173\u7cfb\uff0c\u4f46\u6210\u672c\u9ad8\u4e14\u5bb9\u6613\u751f\u6210\u865a\u5047\u4fe1\u606f\uff08\u5e7b\u89c9\uff09\uff0c\u5bfc\u81f4\u8d44\u6e90\u6d6a\u8d39\u3002\u4e3a\u63d0\u5347\u4fe1\u606f\u63d0\u53d6\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u63d0\u51fa\u65b0\u7684\u7b97\u6cd5\u5e94\u5bf9\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86Language Model Chain\uff08LMC\uff09\u7b97\u6cd5\u3002LMC\u901a\u8fc7\u5c06\u6a21\u578b\u7684\u5019\u9009\u7b54\u6848\u505a\u8fc7\u6ee4\uff0c\u5c06\u6f5c\u5728\u9519\u8bef\u4ea4\u7531\u66f4\u5f3a\u4f46\u66f4\u6162\u7684\u5927\u6a21\u578b\u5904\u7406\uff0c\u5206\u9636\u6bb5\u3001\u591a\u7ea7\u8054\u52a8\u5730\u63d0\u9ad8\u6574\u4f53\u51c6\u786e\u7387\uff0c\u5e94\u7528\u4e8e\u62bd\u53d6\u533b\u7597\u6587\u6863\u4e2d\u7684\u60a3\u8005\u51fa\u751f\u65e5\u671f\u3002", "result": "\u91c7\u7528LMC\u7b97\u6cd5\u540e\uff0c\u591a\u6a21\u578b\u7ea7\u8054\u76f8\u8f83\u5355\u4e00\u8bed\u8a00\u6a21\u578b\uff0c\u9884\u6d4b\u901f\u5ea6\u548c\u51c6\u786e\u7387\u663e\u8457\u63d0\u5347\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u4e86\u5e7b\u89c9\u7684\u53d1\u751f\u7387\u3002", "conclusion": "LMC\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u62bd\u53d6\u4e2d\u7684\u51c6\u786e\u7387\u548c\u6548\u7387\uff0c\u5e76\u51cf\u5c11\u5e7b\u89c9\u73b0\u8c61\uff0c\u503c\u5f97\u5728\u672a\u6765\u8fdb\u4e00\u6b65\u6df1\u5165\u7814\u7a76\u548c\u5e94\u7528\u3002"}}
{"id": "2507.23356", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23356", "abs": "https://arxiv.org/abs/2507.23356", "authors": ["Shmulik Froimovich", "Raviv Gal", "Wesam Ibraheem", "Avi Ziv"], "title": "Quality Evaluation of COBOL to Java Code Transformation", "comment": "Submitted to ASE 2025", "summary": "We present an automated evaluation system for assessing COBOL-to-Java code\ntranslation within IBM's watsonx Code Assistant for Z (WCA4Z). The system\naddresses key challenges in evaluating LLM-based translators, including model\nopacity and the complexity of translation quality assessment. Our approach\ncombines analytic checkers with LLM-as-a-judge (LaaJ) techniques to deliver\nscalable, multi-faceted evaluations. The system supports continuous integration\nworkflows, enables large-scale benchmarking, and reduces reliance on manual\nreview. We describe the system architecture, evaluation strategies, and\nreporting mechanisms that provide actionable insights for developers and\nproject managers, facilitating the evolution of high-quality, modernized\ncodebases.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u79cd\u8bc4\u6d4b\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u5bf9COBOL\u5230Java\u4ee3\u7801\u8fc1\u79fb\u7684\u9ad8\u6548\u81ea\u52a8\u8bc4\u4f30\uff0c\u4fc3\u8fdb\u4e86\u4ee3\u7801\u73b0\u4ee3\u5316\u8fdb\u7a0b\u3002", "motivation": "\u5f53\u524dCOBOL\u5230Java\u7684\u4ee3\u7801\u81ea\u52a8\u8fc1\u79fb\u8fc7\u7a0b\u4e2d\uff0c\u4f7f\u7528\u5927\u6a21\u578b\uff08LLM\uff09\u8fdb\u884c\u7ffb\u8bd1\u5df2\u6210\u8d8b\u52bf\uff0c\u4f46\u5982\u4f55\u5168\u9762\u3001\u5ba2\u89c2\u3001\u81ea\u52a8\u5730\u8bc4\u4f30\u7ffb\u8bd1\u8d28\u91cf\u4ecd\u5b58\u5728\u5de8\u5927\u6311\u6218\u3002\u4f8b\u5982\uff0c\u5927\u6a21\u578b\u7684\u51b3\u7b56\u8fc7\u7a0b\u4e0d\u900f\u660e\uff0c\u8bc4\u4f30\u6807\u51c6\u590d\u6742\uff0c\u4f9d\u8d56\u4eba\u5de5\u5ba1\u67e5\u6548\u7387\u4f4e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u5957\u81ea\u52a8\u5316\u8bc4\u4f30\u7cfb\u7edf\uff0c\u7ed3\u5408\u5206\u6790\u578b\u68c0\u6d4b\u5de5\u5177\u4e0e\u201cLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u201d\uff08LaaJ\uff09\u6280\u672f\uff0c\u5bf9\u57fa\u4e8eIBM watsonx Code Assistant for Z (WCA4Z)\u7684COBOL\u5230Java\u4ee3\u7801\u7ffb\u8bd1\u6548\u679c\u8fdb\u884c\u591a\u7ef4\u5ea6\u3001\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\uff0c\u5e76\u96c6\u6210\u5165\u6301\u7eed\u96c6\u6210\u6d41\u7a0b\u3002", "result": "\u7cfb\u7edf\u652f\u6301\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u51cf\u5c11\u4eba\u5de5\u8bc4\u5ba1\u5de5\u4f5c\uff0c\u5e76\u80fd\u4e3a\u5f00\u53d1\u8005\u548c\u9879\u76ee\u7ba1\u7406\u8005\u63d0\u4f9b\u6709\u7528\u7684\u8d28\u91cf\u62a5\u544a\uff0c\u5e2e\u52a9\u6301\u7eed\u8fed\u4ee3\u5f62\u6210\u9ad8\u8d28\u91cf\u73b0\u4ee3\u5316\u4ee3\u7801\u5e93\u3002", "conclusion": "\u901a\u8fc7\u96c6\u6210\u5206\u6790\u5de5\u5177\u548cLaaJ\uff0c\u63d0\u9ad8\u4e86\u4ee3\u7801\u8fc1\u79fb\u7684\u81ea\u52a8\u8bc4\u6d4b\u8986\u76d6\u5ea6\u548c\u6548\u7387\uff0c\u52a9\u529b\u73b0\u4ee3\u5316\u9879\u76ee\u9ad8\u6548\u63a8\u8fdb\u3002"}}
{"id": "2507.22922", "categories": ["cs.CL", "cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2507.22922", "abs": "https://arxiv.org/abs/2507.22922", "authors": ["Mateusz Kmak", "Kamil Chmurzy\u0144ski", "Kamil Matejuk", "Pawe\u0142 Kotzbach", "Jan Koco\u0144"], "title": "Predicting stock prices with ChatGPT-annotated Reddit sentiment", "comment": "International Conference on Computational Science 2025", "summary": "The surge of retail investor activity on social media, exemplified by the\n2021 GameStop short squeeze, raised questions about the influence of online\nsentiment on stock prices. This paper explores whether sentiment derived from\nsocial media discussions can meaningfully predict stock market movements. We\nfocus on Reddit's r/wallstreetbets and analyze sentiment related to two\ncompanies: GameStop (GME) and AMC Entertainment (AMC). To assess sentiment's\nrole, we employ two existing text-based sentiment analysis methods and\nintroduce a third, a ChatGPT-annotated and fine-tuned RoBERTa-based model\ndesigned to better interpret the informal language and emojis prevalent in\nsocial media discussions. We use correlation and causality metrics to determine\nthese models' predictive power. Surprisingly, our findings suggest that social\nmedia sentiment has only a weak correlation with stock prices. At the same\ntime, simpler metrics, such as the volume of comments and Google search trends,\nexhibit stronger predictive signals. These results highlight the complexity of\nretail investor behavior and suggest that traditional sentiment analysis may\nnot fully capture the nuances of market-moving online discussions.", "AI": {"tldr": "\u793e\u4ea4\u5a92\u4f53\u60c5\u7eea\u5bf9\u80a1\u7968\u9884\u6d4b\u4f5c\u7528\u6709\u9650\uff0c\u8bc4\u8bba\u91cf\u4e0e\u70ed\u5ea6\u66f4\u5177\u53c2\u8003\u4ef7\u503c\uff0c\u4f20\u7edf\u60c5\u7eea\u5206\u6790\u6a21\u578b\u96be\u4ee5\u628a\u63e1\u793e\u4ea4\u8ba8\u8bba\u7684\u590d\u6742\u6027\u3002", "motivation": "\u8fd1\u671f\u6563\u6237\u5728\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u6d3b\u8dc3\uff0c\u5c24\u5176\u662f2021\u5e74GameStop\u4e8b\u4ef6\uff0c\u5f15\u53d1\u4e86\u5bf9\u7ebf\u4e0a\u60c5\u7eea\u5f71\u54cd\u80a1\u7968\u4ef7\u683c\u7684\u5173\u6ce8\u3002\u672c\u6587\u7814\u7a76\u793e\u4ea4\u5a92\u4f53\u8ba8\u8bba\u4e2d\u7684\u60c5\u7eea\u80fd\u5426\u6709\u6548\u9884\u6d4b\u80a1\u5e02\u52a8\u6001\u3002", "method": "\u805a\u7126Reddit\u7684r/wallstreetbets\uff0c\u4ee5GME\u548cAMC\u4e3a\u7814\u7a76\u5bf9\u8c61\uff0c\u5e94\u7528\u4e24\u79cd\u73b0\u6709\u7801\u6587\u672c\u60c5\u7eea\u5206\u6790\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u7528ChatGPT\u6807\u6ce8\u5e76\u5fae\u8c03\u7684RoBERTa\u6a21\u578b\uff0c\u4ee5\u66f4\u597d\u9002\u914d\u793e\u4ea4\u5a92\u4f53\u4e2d\u7684\u975e\u6b63\u5f0f\u8bed\u8a00\u548c\u8868\u60c5\u3002\u901a\u8fc7\u76f8\u5173\u6027\u548c\u56e0\u679c\u6027\u6307\u6807\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u7684\u9884\u6d4b\u80fd\u529b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u793e\u4ea4\u5a92\u4f53\u60c5\u7eea\u4e0e\u80a1\u7968\u4ef7\u683c\u7684\u76f8\u5173\u6027\u8f83\u5f31\uff0c\u800c\u8bc4\u8bba\u91cf\u4e0eGoogle\u641c\u7d22\u70ed\u5ea6\u7b49\u7b80\u5355\u6307\u6807\u6709\u66f4\u5f3a\u7684\u9884\u6d4b\u4f5c\u7528\u3002", "conclusion": "\u793e\u4ea4\u5a92\u4f53\u60c5\u7eea\u5206\u6790\u5bf9\u80a1\u4ef7\u9884\u6d4b\u4f5c\u7528\u6709\u9650\uff0c\u8868\u660e\u6563\u6237\u884c\u4e3a\u590d\u6742\uff0c\u4f20\u7edf\u60c5\u7eea\u5206\u6790\u96be\u4ee5\u6355\u6349\u5f71\u54cd\u5e02\u573a\u7684\u7f51\u7edc\u8ba8\u8bba\u7ec6\u8282\u3002"}}
{"id": "2507.23361", "categories": ["cs.SE", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.23361", "abs": "https://arxiv.org/abs/2507.23361", "authors": ["Silin Chen", "Shaoxin Lin", "Xiaodong Gu", "Yuling Shi", "Heng Lian", "Longfei Yun", "Dong Chen", "Weiguo Sun", "Lin Cao", "Qianxiang Wang"], "title": "SWE-Exp: Experience-Driven Software Issue Resolution", "comment": "Our code and data are available at\n  https://github.com/YerbaPage/SWE-Exp", "summary": "Recent advances in large language model (LLM) agents have shown remarkable\nprogress in software issue resolution, leveraging advanced techniques such as\nmulti-agent collaboration and Monte Carlo Tree Search (MCTS). However, current\nagents act as memoryless explorers - treating each problem separately without\nretaining or reusing knowledge from previous repair experiences. This leads to\nredundant exploration of failed trajectories and missed chances to adapt\nsuccessful issue resolution methods to similar problems. To address this\nproblem, we introduce SWE-Exp, an experience - enhanced approach that distills\nconcise and actionable experience from prior agent trajectories, enabling\ncontinuous learning across issues. Our method introduces a multi-faceted\nexperience bank that captures both successful and failed repair attempts.\nSpecifically, it extracts reusable issue resolution knowledge at different\nlevels - from high-level problem comprehension to specific code changes.\nExperiments show that SWE-Exp achieves state-of-the-art resolution rate (41.6%\nPass@1) on SWE-bench-Verified under open-source agent frameworks. Our approach\nestablishes a new paradigm in which automated software engineering agents\nsystematically accumulate and leverage repair expertise, fundamentally shifting\nfrom trial-and-error exploration to strategic, experience-driven issue\nresolution.", "AI": {"tldr": "SWE-Exp\u901a\u8fc7\u6c89\u6dc0\u548c\u590d\u7528\u4ee5\u5f80\u4fee\u590d\u7ecf\u9a8c\uff0c\u4f7f\u8f6f\u4ef6\u5de5\u7a0b\u7c7b\u667a\u80fd\u4f53\u7a81\u7834\u4e86\u4f20\u7edf\u5355\u6b21\u8bb0\u5fc6\u7684\u5c40\u9650\uff0c\u5728\u5f00\u6e90\u6d4b\u8bd5\u96c6\u4e0a\u53d6\u5f97\u6700\u4f18\u6210\u7ee9\uff0c\u4e3aAI\u81ea\u52a8\u4fee\u590d\u5e26\u6765\u6301\u7eed\u6027\u5b66\u4e60\u548c\u77e5\u8bc6\u8fc1\u79fb\u7684\u65b0\u601d\u8def\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8f6f\u4ef6\u95ee\u9898\u89e3\u51b3\u667a\u80fd\u4f53\uff0c\u867d\u7136\u5728\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u7b97\u6cd5\u63a2\u7d22\u65b9\u9762\u8868\u73b0\u5353\u8d8a\uff0c\u4f46\u6bcf\u6b21\u4fee\u590d\u4efb\u52a1\u90fd\u4ece\u5934\u5f00\u59cb\uff0c\u65e0\u6cd5\u79ef\u7d2f\u548c\u590d\u7528\u4ee5\u5f80\u7684\u7ecf\u9a8c\uff0c\u5bfc\u81f4\u91cd\u590d\u65e0\u6548\u5c1d\u8bd5\u548c\u9519\u8fc7\u8fc1\u79fb\u6210\u529f\u7ecf\u9a8c\u7684\u673a\u4f1a\u3002", "method": "\u63d0\u51faSWE-Exp\uff0c\u4e00\u79cd\u5c06\u667a\u80fd\u4f53\u4ee5\u5f80\u4fee\u590d\u8f68\u8ff9\u4e2d\u7684\u53ef\u7528\u7ecf\u9a8c\u8fdb\u884c\u63d0\u70bc\u548c\u6c89\u6dc0\u7684\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u591a\u5143\u7ecf\u9a8c\u5e93\uff0c\u7cfb\u7edf\u91c7\u96c6\u5e76\u5b58\u50a8\u6210\u529f\u53ca\u5931\u8d25\u7684\u4fee\u590d\u5c1d\u8bd5\uff0c\u5e76\u5728\u9ad8\u5c42\u6b21\u7406\u89e3\u5230\u5177\u4f53\u4ee3\u7801\u4fee\u6539\u591a\u7ea7\u62bd\u53d6\u53ef\u590d\u7528\u7684\u77e5\u8bc6\uff0c\u5b9e\u73b0\u6301\u7eed\u8de8\u4efb\u52a1\u5b66\u4e60\u3002", "result": "\u5728SWE-bench-Verified\u6d4b\u8bd5\u96c6\uff08\u57fa\u4e8e\u5f00\u6e90\u667a\u80fd\u4f53\u6846\u67b6\uff09\u4e0a\uff0cSWE-Exp\u8fbe\u5230\u4e8641.6%\u7684Pass@1\uff0c\u521b\u4e0b\u6700\u4f18\u8868\u73b0\u3002", "conclusion": "SWE-Exp\u5f00\u542f\u4e86\u8ba9\u81ea\u52a8\u5316\u8f6f\u4ef6\u5de5\u7a0b\u667a\u80fd\u4f53\u7cfb\u7edf\u6027\u79ef\u7d2f\u548c\u5229\u7528\u4fee\u590d\u77e5\u8bc6\u7684\u65b0\u8303\u5f0f\uff0c\u7531\u76f2\u76ee\u8bd5\u9519\u8f6c\u5411\u6218\u7565\u6027\u3001\u7ecf\u9a8c\u9a71\u52a8\u7684\u95ee\u9898\u89e3\u51b3\u3002"}}
{"id": "2507.22923", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22923", "abs": "https://arxiv.org/abs/2507.22923", "authors": ["Aman Gupta", "Yingying Zhuang", "Zhou Yu", "Ziji Zhang", "Anurag Beniwal"], "title": "How and Where to Translate? The Impact of Translation Strategies in Cross-lingual LLM Prompting", "comment": "Accepted at Prompt Optimization KDD '25", "summary": "Despite advances in the multilingual capabilities of Large Language Models\n(LLMs), their performance varies substantially across different languages and\ntasks. In multilingual retrieval-augmented generation (RAG)-based systems,\nknowledge bases (KB) are often shared from high-resource languages (such as\nEnglish) to low-resource ones, resulting in retrieved information from the KB\nbeing in a different language than the rest of the context. In such scenarios,\ntwo common practices are pre-translation to create a mono-lingual prompt and\ncross-lingual prompting for direct inference. However, the impact of these\nchoices remains unclear. In this paper, we systematically evaluate the impact\nof different prompt translation strategies for classification tasks with\nRAG-enhanced LLMs in multilingual systems. Experimental results show that an\noptimized prompting strategy can significantly improve knowledge sharing across\nlanguages, therefore improve the performance on the downstream classification\ntask. The findings advocate for a broader utilization of multilingual resource\nsharing and cross-lingual prompt optimization for non-English languages,\nespecially the low-resource ones.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u591a\u8bed\u8a00RAG\u7cfb\u7edf\u4e2d\u63d0\u793a\u7ffb\u8bd1\u7b56\u7565\u5bf9\u5206\u7c7b\u4efb\u52a1\u7684\u5f71\u54cd\u3002\u5b9e\u9a8c\u8868\u660e\u4f18\u5316\u63d0\u793a\u8bbe\u8ba1\u53ef\u660e\u663e\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u4efb\u52a1\u8868\u73b0\uff0c\u63d0\u5021\u66f4\u5e7f\u6cdb\u7684\u591a\u8bed\u8a00\u8d44\u6e90\u5171\u4eab\u548c\u63d0\u793a\u4f18\u5316\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u591a\u8bed\u8a00\u80fd\u529b\u4e0a\u53d6\u5f97\u4e86\u8fdb\u6b65\uff0c\u4f46\u5176\u5728\u4e0d\u540c\u8bed\u8a00\u548c\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u4ecd\u5b58\u5728\u8f83\u5927\u5dee\u5f02\u3002\u5728\u591a\u8bed\u8a00\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u4e2d\uff0c\u77e5\u8bc6\u5e93\u5e38\u4e3a\u9ad8\u8d44\u6e90\u8bed\u8a00\uff08\u5982\u82f1\u8bed\uff09\uff0c\u5bfc\u81f4\u68c0\u7d22\u4fe1\u606f\u5e38\u4e0e\u4e0a\u4e0b\u6587\u8bed\u8a00\u4e0d\u4e00\u81f4\u3002\u73b0\u6709\u5e38\u89c1\u505a\u6cd5\u4e3a\u9884\u7ffb\u8bd1\u5355\u8bed\u63d0\u793a\u6216\u76f4\u63a5\u91c7\u7528\u8de8\u8bed\u8a00\u63d0\u793a\uff0c\u7136\u800c\u8fd9\u4e9b\u7b56\u7565\u7684\u5b9e\u9645\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e86\u5728RAG\u589e\u5f3a\u7684\u591a\u8bed\u8a00\u7cfb\u7edf\u4e2d\uff0c\u4e0d\u540c\u63d0\u793a\u7ffb\u8bd1\u7b56\u7565\u5bf9\u5206\u7c7b\u4efb\u52a1\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u5b9e\u9a8c\u5bf9\u6bd4\u4f18\u5316\u4e0d\u540c\u7684\u63d0\u793a\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u4f18\u5316\u7684\u63d0\u793a\u7b56\u7565\u80fd\u663e\u8457\u63d0\u5347\u8de8\u8bed\u8a00\u77e5\u8bc6\u5171\u4eab\uff0c\u5e76\u6539\u5584\u4e0b\u6e38\u5206\u7c7b\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u5efa\u8bae\u5728\u975e\u82f1\u8bed\uff0c\u5c24\u5176\u662f\u4f4e\u8d44\u6e90\u8bed\u8a00\u60c5\u5883\u4e0b\uff0c\u8fdb\u4e00\u6b65\u63a8\u5e7f\u591a\u8bed\u8a00\u8d44\u6e90\u5171\u4eab\u548c\u8de8\u8bed\u8a00\u63d0\u793a\u4f18\u5316\u3002"}}
{"id": "2507.23370", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.23370", "abs": "https://arxiv.org/abs/2507.23370", "authors": ["Trae Research Team", "Pengfei Gao", "Zhao Tian", "Xiangxin Meng", "Xinchen Wang", "Ruida Hu", "Yuanan Xiao", "Yizhou Liu", "Zhao Zhang", "Junjie Chen", "Cuiyun Gao", "Yun Lin", "Yingfei Xiong", "Chao Peng", "Xia Liu"], "title": "Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling", "comment": "Pengfei Gao and Zhao Tian contributed equally to this technical\n  report", "summary": "Software issue resolution is a critical challenge in software engineering and\nhas garnered increasing attention in recent years. With the rapid advancement\nof large language models (LLMs), substantial progress has been made in\naddressing real-world software engineering tasks. Recent studies have\nintroduced ensemble reasoning techniques to enhance the performance of\nLLM-based issue resolution. However, existing prompting-based methods still\nface limitations in effectively exploring large ensemble spaces and lack the\ncapacity for repository-level understanding, both of which constrain their\noverall effectiveness. In this paper, we propose Trae Agent, the first\nagent-based ensemble reasoning approach for repository-level issue resolution.\nTrae Agent formulates our goal as an optimal solution search problem and\naddresses two key challenges, i.e., large ensemble spaces and repository-level\nunderstanding, through modular agents for generation, pruning, and selection.\nWe conduct extensive experiments using three leading LLMs on the widely-adopted\nSWE-bench benchmark, comparing Trae Agent against four state-of-the-art\nensemble reasoning techniques. Experimental results demonstrate that Trae Agent\nconsistently achieves superior performance, with an average improvement of\n10.22% over all baselines in terms of Pass@1. Trae Agent has achieved first\nplace on the SWE-bench Verified leaderboard, with a notable Pass@1 score of\n75.20%. We are pleased to release Trae Agent as an open-source project to\nsupport the research community, with all resources available at\nhttps://github.com/bytedance/trae-agent.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u96c6\u6210\u591a\u667a\u80fd\u4f53\u7684Trae Agent\u65b9\u6cd5\uff0c\u8865\u8db3LLM\u5728\u5e93\u7ea7\u95ee\u9898\u89e3\u51b3\u548c\u5927\u96c6\u6210\u7a7a\u95f4\u641c\u7d22\u7684\u80fd\u529b\u77ed\u677f\u3002\u5b9e\u9a8c\u663e\u793a\u5176\u5728SWE-bench\u6570\u636e\u96c6\u548c\u591aLLM\u4e0b\u5747\u8d85\u8d8a\u73b0\u6709\u6280\u672f\uff0c\u63d0\u5347\u663e\u8457\uff0c\u5e76\u5df2\u5f00\u6e90\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u8f6f\u4ef6\u95ee\u9898\u89e3\u51b3\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u96c6\u6210\u63a8\u7406\u7a7a\u95f4\u548c\u7f3a\u4e4f\u5e93\u7ea7\u7406\u89e3\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5f71\u54cd\u4e86\u6574\u4f53\u8868\u73b0\u3002\u672c\u6587\u8bd5\u56fe\u7a81\u7834\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTrae Agent\u7684\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u96c6\u6210\u63a8\u7406\u65b9\u6cd5\u3002\u901a\u8fc7\u6a21\u5757\u5316\u7684\u751f\u6210\u3001\u4fee\u526a\u548c\u9009\u62e9\u667a\u80fd\u4f53\uff0c\u5e94\u5bf9\u5927\u96c6\u6210\u63a8\u7406\u7a7a\u95f4\u548c\u5e93\u7ea7\u7406\u89e3\u4e24\u5927\u6311\u6218\u3002\u5c06\u76ee\u6807\u5efa\u6a21\u4e3a\u6700\u4f18\u89e3\u641c\u7d22\u95ee\u9898\uff0c\u5e76\u5728SWE-bench\u57fa\u51c6\u4e0a\u540c\u56db\u79cd\u5148\u8fdb\u96c6\u6210\u63a8\u7406\u65b9\u6cd5\u505a\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "Trae Agent\u5728\u6240\u6709\u5bf9\u6bd4\u65b9\u6cd5\u4e2d\u8868\u73b0\u6700\u4f73\uff0cPass@1\u5e73\u5747\u63d0\u534710.22%\u3002\u5728SWE-bench Verified\u699c\u5355\u4e0a\u53d6\u5f97\u7b2c\u4e00\uff0cPass@1\u5f97\u5206\u4e3a75.20%\u3002", "conclusion": "Trae Agent\u4ee5\u6a21\u5757\u5316\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u663e\u8457\u589e\u5f3a\u4e86LLM\u5728\u5e93\u7ea7\u95ee\u9898\u89e3\u51b3\u7684\u80fd\u529b\uff0c\u7a81\u7834\u4e86\u4ee5\u5f80\u96c6\u6210\u63a8\u7406\u7684\u5173\u952e\u74f6\u9888\uff0c\u5e76\u4f5c\u4e3a\u5f00\u6e90\u9879\u76ee\u4e3a\u793e\u533a\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2507.22924", "categories": ["cs.CL", "I.2.7; K.3.1"], "pdf": "https://arxiv.org/pdf/2507.22924", "abs": "https://arxiv.org/abs/2507.22924", "authors": ["Brittney Exline", "Melanie Duffin", "Brittany Harbison", "Chrissa da Gomez", "David Joyner"], "title": "Using Sentiment Analysis to Investigate Peer Feedback by Native and Non-Native English Speakers", "comment": null, "summary": "Graduate-level CS programs in the U.S. increasingly enroll international\nstudents, with 60.2 percent of master's degrees in 2023 awarded to non-U.S.\nstudents. Many of these students take online courses, where peer feedback is\nused to engage students and improve pedagogy in a scalable manner. Since these\ncourses are conducted in English, many students study in a language other than\ntheir first. This paper examines how native versus non-native English speaker\nstatus affects three metrics of peer feedback experience in online U.S.-based\ncomputing courses. Using the Twitter-roBERTa-based model, we analyze the\nsentiment of peer reviews written by and to a random sample of 500 students. We\nthen relate sentiment scores and peer feedback ratings to students' language\nbackground. Results show that native English speakers rate feedback less\nfavorably, while non-native speakers write more positively but receive less\npositive sentiment in return. When controlling for sex and age, significant\ninteractions emerge, suggesting that language background plays a modest but\ncomplex role in shaping peer feedback experiences.", "AI": {"tldr": "\u4ee5\u82f1\u8bed\u4e3a\u6bcd\u8bed\u4e0e\u5426\u4f1a\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u5f71\u54cd\u7f8e\u56fd\u5728\u7ebfCS\u8bfe\u7a0b\u5b66\u751f\u7684\u540c\u4f34\u4e92\u8bc4\u4f53\u9a8c\u3002\u975e\u6bcd\u8bed\u5b66\u751f\u5199\u8bc4\u8bba\u66f4\u79ef\u6781\uff0c\u4f46\u6536\u5230\u7684\u8bc4\u4ef7\u8f83\u4e0d\u79ef\u6781\uff1b\u6bcd\u8bed\u5b66\u751f\u5bf9\u6536\u5230\u7684\u53cd\u9988\u8bc4\u4ef7\u66f4\u4f4e\u3002\u8bed\u8a00\u80cc\u666f\u5f71\u54cd\u5b58\u5728\uff0c\u4f46\u590d\u6742\u4e14\u5e45\u5ea6\u6709\u9650\u3002", "motivation": "\u7f8e\u56fd\u9ad8\u6821\u7814\u7a76\u751fCS\u9879\u76ee\u4e2d\uff0c\u56fd\u9645\u5b66\u751f\u6bd4\u4f8b\u9010\u6e10\u5347\u9ad8\uff0c\u4e14\u8bb8\u591a\u56fd\u9645\u5b66\u751f\u901a\u8fc7\u5728\u7ebf\u8bfe\u7a0b\u5b66\u4e60\uff0c\u8fd9\u4e9b\u8bfe\u7a0b\u5e38\u7528\u540c\u4f34\u4e92\u8bc4\u4fc3\u8fdb\u5b66\u4e60\u3002\u7136\u800c\uff0c\u8bfe\u7a0b\u5e38\u7528\u82f1\u8bed\u6388\u8bfe\uff0c\u8bb8\u591a\u5b66\u751f\u5e76\u975e\u4ee5\u82f1\u8bed\u4e3a\u6bcd\u8bed\u3002\u7814\u7a76\u5e0c\u671b\u63a2\u8ba8\u6bcd\u8bed\u4e0e\u5426\u5982\u4f55\u5f71\u54cd\u5b66\u751f\u5728\u5728\u7ebf\u540c\u4f34\u4e92\u8bc4\u4e2d\u7684\u4f53\u9a8c\u3002", "method": "\u8be5\u7814\u7a76\u91c7\u7528Twitter-roBERTa\u6a21\u578b\u5206\u6790\u4e86500\u540d\u5b66\u751f\u7684\u540c\u4f34\u4e92\u8bc4\uff08\u5305\u62ec\u5199\u51fa\u4e0e\u6536\u5230\u7684\uff09\u60c5\u611f\u503e\u5411\uff0c\u5e76\u7ed3\u5408\u5b66\u751f\u8bed\u8a00\u80cc\u666f\uff08\u6bcd\u8bed/\u975e\u6bcd\u8bed\uff09\u63a2\u8ba8\u60c5\u611f\u5f97\u5206\u4e0e\u4e92\u8bc4\u8bc4\u5206\u7684\u5173\u7cfb\u3002\u63a7\u5236\u4e86\u6027\u522b\u548c\u5e74\u9f84\u53d8\u91cf\uff0c\u5206\u6790\u5176\u4ea4\u4e92\u4f5c\u7528\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a1\uff09\u4ee5\u82f1\u8bed\u4e3a\u6bcd\u8bed\u7684\u5b66\u751f\u5bf9\u6536\u5230\u7684\u53cd\u9988\u8bc4\u4ef7\u8f83\u4f4e\uff1b2\uff09\u975e\u6bcd\u8bed\u5b66\u751f\u5199\u51fa\u7684\u53cd\u9988\u60c5\u611f\u66f4\u79ef\u6781\uff0c\u4f46\u4ed6\u4eec\u6536\u5230\u7684\u53cd\u9988\u60c5\u611f\u5206\u53cd\u800c\u8f83\u4f4e\uff1b3\uff09\u63a7\u5236\u6027\u522b\u4e0e\u5e74\u9f84\u540e\uff0c\u8bed\u8a00\u80cc\u666f\u5bf9\u540c\u4f34\u4e92\u8bc4\u4f53\u9a8c\u6709\u7edf\u8ba1\u5b66\u7684\u663e\u8457\u590d\u6742\u4f5c\u7528\uff0c\u4f46\u5f71\u54cd\u5e45\u5ea6\u9002\u4e2d\u3002", "conclusion": "\u8bed\u8a00\u80cc\u666f\u5bf9\u5728\u7ebf\u8ba1\u7b97\u673a\u8bfe\u7a0b\u4e2d\u540c\u4f34\u4e92\u8bc4\u4f53\u9a8c\u6709\u4e00\u5b9a\u4f46\u590d\u6742\u7684\u5f71\u54cd\uff0c\u9700\u5145\u5206\u5173\u6ce8\u56fd\u9645\u5b66\u751f\u7684\u8bed\u8a00\u548c\u6587\u5316\u5dee\u5f02\u3002"}}
{"id": "2507.23425", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.23425", "abs": "https://arxiv.org/abs/2507.23425", "authors": ["Daphn\u00e9 Larrivain", "Shinhyung Yang", "Wilhelm Hasselbring"], "title": "Dynamic and Static Analysis of Python Software with Kieker Including Reconstructed Architectures", "comment": "9 pages, 9 figures", "summary": "The Kieker observability framework is a tool that provides users with the\nmeans to design a custom observability pipeline for their application.\nOriginally tailored for Java, supporting Python with Kieker is worthwhile.\nPython's popularity has exploded over the years, thus making structural\ninsights of Python applications highly valuable. Our Python analysis pipeline\ncombines static and dynamic analysis in order to build a complete picture of a\ngiven system.", "AI": {"tldr": "Kieker\u6846\u67b6\u65b0\u589e\u4e86\u5bf9Python\u7684\u652f\u6301\uff0c\u7ed3\u5408\u9759\u6001\u548c\u52a8\u6001\u5206\u6790\uff0c\u53ef\u4e3aPython\u5e94\u7528\u63d0\u4f9b\u6df1\u5165\u7684\u7ed3\u6784\u6d1e\u5bdf\u3002", "motivation": "\u539f\u672cKieker\u89c2\u6d4b\u6846\u67b6\u4e3b\u8981\u652f\u6301Java\uff0c\u4f46\u7531\u4e8ePython\u8fd1\u5e74\u6765\u6781\u5ea6\u6d41\u884c\uff0c\u56e0\u6b64\u4e3aPython\u5e94\u7528\u63d0\u4f9b\u89c2\u6d4b\u4e0e\u7ed3\u6784\u6027\u5206\u6790\u5de5\u5177\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u7ed3\u5408\u9759\u6001\u5206\u6790\u548c\u52a8\u6001\u5206\u6790\u65b9\u5f0f\uff0c\u5bf9Python\u5e94\u7528\u6784\u5efa\u5b8c\u6574\u7684\u7cfb\u7edf\u7ed3\u6784\u89c6\u56fe\u3002", "result": "\u5f00\u53d1\u5e76\u5b9e\u73b0\u4e86\u652f\u6301Python\u5206\u6790\u7684Kieker\u7ba1\u9053\uff0c\u53ef\u7528\u4e8e\u7cfb\u7edf\u7ed3\u6784\u6027\u6d1e\u89c1\u3002", "conclusion": "\u901a\u8fc7\u4e3aKieker\u89c2\u6d4b\u6846\u67b6\u589e\u52a0Python\u652f\u6301\uff0c\u6269\u5c55\u4e86\u5176\u5e94\u7528\u8303\u56f4\uff0c\u8ba9\u7528\u6237\u80fd\u591f\u9488\u5bf9Python\u5e94\u7528\u7075\u6d3b\u8bbe\u8ba1\u5b9a\u5236\u5316\u89c2\u6d4b\u6d41\u7a0b\u3002"}}
{"id": "2507.22925", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22925", "abs": "https://arxiv.org/abs/2507.22925", "authors": ["Haoran Sun", "Shaoning Zeng"], "title": "Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents", "comment": null, "summary": "Long-term memory is one of the key factors influencing the reasoning\ncapabilities of Large Language Model Agents (LLM Agents). Incorporating a\nmemory mechanism that effectively integrates past interactions can\nsignificantly enhance decision-making and contextual coherence of LLM Agents.\nWhile recent works have made progress in memory storage and retrieval, such as\nencoding memory into dense vectors for similarity-based search or organizing\nknowledge in the form of graph, these approaches often fall short in structured\nmemory organization and efficient retrieval. To address these limitations, we\npropose a Hierarchical Memory (H-MEM) architecture for LLM Agents that\norganizes and updates memory in a multi-level fashion based on the degree of\nsemantic abstraction. Each memory vector is embedded with a positional index\nencoding pointing to its semantically related sub-memories in the next layer.\nDuring the reasoning phase, an index-based routing mechanism enables efficient,\nlayer-by-layer retrieval without performing exhaustive similarity computations.\nWe evaluate our method on five task settings from the LoCoMo dataset.\nExperimental results show that our approach consistently outperforms five\nbaseline methods, demonstrating its effectiveness in long-term dialogue\nscenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5c42\u6b21\u5316\u8bb0\u5fc6\u7ed3\u6784H-MEM\uff0c\u63d0\u5347\u4e86LLM\u4ee3\u7406\u7684\u957f\u671f\u8bb0\u5fc6\u4e0e\u63a8\u7406\u6027\u80fd\uff0c\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u957f\u671f\u8bb0\u5fc6\u5bf9\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\uff08LLM Agents\uff09\u7684\u63a8\u7406\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002\u76ee\u524d\u7528\u4e8e\u8bb0\u5fc6\u5b58\u50a8\u4e0e\u68c0\u7d22\u7684\u65b9\u6cd5\u5728\u7ed3\u6784\u5316\u548c\u9ad8\u6548\u68c0\u7d22\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9650\u5236\u4e86LLM\u4ee3\u7406\u7684\u51b3\u7b56\u548c\u4e0a\u4e0b\u6587\u8fde\u8d2f\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5206\u5c42\u8bb0\u5fc6\uff08Hierarchical Memory, H-MEM\uff09\u67b6\u6784\uff0c\u5c06\u8bb0\u5fc6\u6309\u7167\u8bed\u4e49\u62bd\u8c61\u7a0b\u5ea6\u8fdb\u884c\u591a\u5c42\u6b21\u7ec4\u7ec7\u548c\u66f4\u65b0\u3002\u6bcf\u4e2a\u8bb0\u5fc6\u5411\u91cf\u5d4c\u5165\u4e86\u5e26\u6709\u4f4d\u7f6e\u4fe1\u606f\u7684\u7d22\u5f15\uff0c\u7528\u4ee5\u6307\u5411\u4e0b\u4e00\u5c42\u76f8\u5173\u5b50\u8bb0\u5fc6\u3002\u5728\u63a8\u7406\u9636\u6bb5\uff0c\u901a\u8fc7\u57fa\u4e8e\u7d22\u5f15\u7684\u8def\u7531\u673a\u5236\u8fdb\u884c\u9010\u5c42\u9ad8\u6548\u68c0\u7d22\uff0c\u907f\u514d\u4e86\u7e41\u7410\u7684\u5168\u91cf\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u3002", "result": "\u5728LoCoMo\u6570\u636e\u96c6\u7684\u4e94\u4e2a\u4efb\u52a1\u573a\u666f\u4e0b\u8fdb\u884c\u6d4b\u8bd5\uff0c\u8be5\u65b9\u6cd5\u5728\u957f\u671f\u5bf9\u8bdd\u4efb\u52a1\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u4e94\u79cd\u4e3b\u6d41\u5bf9\u6bd4\u65b9\u6cd5\u3002", "conclusion": "H-MEM\u67b6\u6784\u80fd\u6709\u6548\u63d0\u5347LLM\u4ee3\u7406\u7684\u957f\u671f\u8bb0\u5fc6\u80fd\u529b\uff0c\u4f7f\u5f97\u591a\u8f6e\u63a8\u7406\u548c\u5bf9\u8bdd\u4efb\u52a1\u4e2d\u7684\u51b3\u7b56\u66f4\u52a0\u9ad8\u6548\u548c\u8fde\u8d2f\u3002"}}
{"id": "2507.23640", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2507.23640", "abs": "https://arxiv.org/abs/2507.23640", "authors": ["Samah Kansab", "Mohammed Sayagh", "Francis Bordeleau", "Ali Tizghadam"], "title": "An Empirical Study on the Amount of Changes Required for Merge Request Acceptance", "comment": null, "summary": "Code review (CR) is essential to software development, helping ensure that\nnew code is properly integrated. However, the CR process often involves\nsignificant effort, including code adjustments, responses to reviewers, and\ncontinued implementation. While past studies have examined CR delays and\niteration counts, few have investigated the effort based on the volume of code\nchanges required, especially in the context of GitLab Merge Requests (MRs),\nwhich remains underexplored. In this paper, we define and measure CR effort as\nthe amount of code modified after submission, using a dataset of over 23,600\nMRs from four GitLab projects. We find that up to 71% of MRs require\nadjustments after submission, and 28% of these involve changes to more than 200\nlines of code. Surprisingly, this effort is not correlated with review time or\nthe number of participants. To better understand and predict CR effort, we\ntrain an interpretable machine learning model using metrics across multiple\ndimensions: text features, code complexity, developer experience, review\nhistory, and branching. Our model achieves strong performance (AUC 0.84-0.88)\nand reveals that complexity, experience, and text features are key predictors.\nHistorical project characteristics also influence current review effort. Our\nfindings highlight the feasibility of using machine learning to explain and\nanticipate the effort needed to integrate code changes during review.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u4e30\u5bcc\u7684GitLab MRs\u6570\u636e\uff0c\u9996\u6b21\u7cfb\u7edf\u5316\u5206\u6790\u4ee3\u7801\u5ba1\u67e5\uff08CR\uff09\u6240\u9700\u7684\u4ee3\u7801\u4fee\u6539\u91cf\uff0c\u53d1\u73b0\u8fd1\u4e09\u6210MR\u9700\u5927\u5e45\u8c03\u6574\u3002\u63d0\u51fa\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u53ef\u9ad8\u6548\u9884\u6d4bCR\u5de5\u4f5c\u91cf\uff0c\u63ed\u793a\u6587\u672c\u3001\u590d\u6742\u5ea6\u3001\u7ecf\u9a8c\u7b49\u5173\u952e\u5f71\u54cd\u56e0\u5b50\uff0c\u5bf9\u5b9e\u9645\u8f6f\u4ef6\u5f00\u53d1\u7ba1\u7406\u5177\u6709\u53c2\u8003\u4ef7\u503c\u3002", "motivation": "\u867d\u7136\u4ee3\u7801\u5ba1\u67e5\uff08CR\uff09\u5bf9\u4e8e\u4fdd\u8bc1\u65b0\u4ee3\u7801\u7684\u9ad8\u8d28\u91cf\u96c6\u6210\u81f3\u5173\u91cd\u8981\uff0c\u4f46CR\u8fc7\u7a0b\u5e38\u5e38\u8017\u8d39\u5927\u91cf\u4eba\u529b\uff0c\u5305\u62ec\u4ee3\u7801\u8c03\u6574\u548c\u56de\u5e94\u5ba1\u67e5\u610f\u89c1\u3002\u4ee5\u5f80\u7814\u7a76\u867d\u7136\u5206\u6790\u4e86CR\u5ef6\u8fdf\u548c\u8fed\u4ee3\u6b21\u6570\uff0c\u4f46\u9c9c\u6709\u57fa\u4e8e\u4ee3\u7801\u4fee\u6539\u91cf\u91cf\u5316\u5ba1\u67e5\u5de5\u4f5c\u91cf\uff0c\u5c24\u5176\u662f\u5728GitLab Merge Requests\uff08MRs\uff09\u573a\u666f\u4e0b\u3002\u56e0\u6b64\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u4f5c\u8005\u4ee5\u56db\u4e2aGitLab\u9879\u76ee\u4e2d\u8d85\u8fc723600\u4e2aMerge Requests\u4e3a\u6570\u636e\u96c6\uff0c\u5c06CR\u5de5\u4f5c\u91cf\u5b9a\u4e49\u4e3a\u63d0\u4ea4\u540e\u88ab\u4fee\u6539\u7684\u4ee3\u7801\u884c\u6570\u3002\u901a\u8fc7\u7edf\u8ba1\u5206\u6790MR\u8c03\u6574\u60c5\u51b5\uff0c\u5e76\u8bad\u7ec3\u89e3\u91ca\u6027\u5f3a\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7ed3\u5408\u6587\u672c\u7279\u5f81\u3001\u4ee3\u7801\u590d\u6742\u5ea6\u3001\u5f00\u53d1\u7ecf\u9a8c\u3001\u5ba1\u9605\u5386\u53f2\u3001\u5206\u652f\u7b49\u591a\u7ef4\u5ea6\u7279\u5f81\u9884\u6d4bCR\u5de5\u4f5c\u91cf\u3002\u91c7\u7528AUC\u4f5c\u4e3a\u8861\u91cf\u6a21\u578b\u6027\u80fd\u7684\u6807\u51c6\u3002", "result": "\u9ad8\u8fbe71%\u7684MR\u63d0\u4ea4\u540e\u9700\u8c03\u6574\uff0c\u5176\u4e2d28%\u6d89\u53ca200\u884c\u4ee5\u4e0a\u4ee3\u7801\u66f4\u6539\u3002CR\u5de5\u4f5c\u91cf\u4e0e\u5ba1\u67e5\u65f6\u957f\u6216\u53c2\u4e0e\u4eba\u6570\u5e76\u65e0\u76f8\u5173\u6027\u3002\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u8868\u73b0\u4f18\u5f02\uff08AUC 0.84-0.88\uff09\uff0c\u8868\u660e\u4ee3\u7801\u590d\u6742\u6027\u3001\u5f00\u53d1\u8005\u7ecf\u9a8c\u548c\u6587\u672c\u7279\u5f81\u6700\u4e3a\u5173\u952e\uff0c\u540c\u65f6\u9879\u76ee\u5386\u53f2\u7279\u5f81\u4e5f\u5bf9\u6700\u65b0CR\u5de5\u4f5c\u91cf\u6709\u5f71\u54cd\u3002", "conclusion": "\u901a\u8fc7\u591a\u7ef4\u5ea6\u7279\u5f81\u5efa\u6a21\uff0c\u80fd\u591f\u6709\u6548\u9884\u6d4b\u548c\u89e3\u91caCR\u9636\u6bb5\u6240\u9700\u5de5\u4f5c\u91cf\uff0c\u4e3a\u4ee3\u7801\u96c6\u6210\u7ba1\u7406\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u3002\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u8f85\u52a9\u8bc6\u522b\u9ad8\u5de5\u4f5c\u91cfMR\uff0c\u5bf9\u8d44\u6e90\u5206\u914d\u548c\u6d41\u7a0b\u4f18\u5316\u5177\u6709\u5b9e\u9645\u610f\u4e49\u3002"}}
{"id": "2507.22926", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.22926", "abs": "https://arxiv.org/abs/2507.22926", "authors": ["Nilesh", "Atul Gupta", "Avinash C Panday"], "title": "Multi-Relation Extraction in Entity Pairs using Global Context", "comment": "11 pages, 9 figures", "summary": "In document-level relation extraction, entities may appear multiple times in\na document, and their relationships can shift from one context to another.\nAccurate prediction of the relationship between two entities across an entire\ndocument requires building a global context spanning all relevant sentences.\nPrevious approaches have focused only on the sentences where entities are\nmentioned, which fails to capture the complete document context necessary for\naccurate relation extraction. Therefore, this paper introduces a novel input\nembedding approach to capture the positions of mentioned entities throughout\nthe document rather than focusing solely on the span where they appear. The\nproposed input encoding approach leverages global relationships and\nmulti-sentence reasoning by representing entities as standalone segments,\nindependent of their positions within the document. The performance of the\nproposed method has been tested on three benchmark relation extraction\ndatasets, namely DocRED, Re-DocRED, and REBEL. The experimental results\ndemonstrated that the proposed method accurately predicts relationships between\nentities in a document-level setting. The proposed research also has\ntheoretical and practical implications. Theoretically, it advances global\ncontext modeling and multi-sentence reasoning in document-level relation\nextraction. Practically, it enhances relationship detection, enabling improved\nperformance in real-world NLP applications requiring comprehensive entity-level\ninsights and interpretability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6355\u6349\u5168\u5c40\u5b9e\u4f53\u4f4d\u7f6e\u4fe1\u606f\u7684\u65b0\u578b\u8f93\u5165\u7f16\u7801\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u6587\u6863\u7ea7\u5173\u7cfb\u62bd\u53d6\u7684\u51c6\u786e\u7387\uff0c\u5e76\u5177\u5907\u826f\u597d\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u4ef7\u503c\u3002", "motivation": "\u5728\u6587\u6863\u7ea7\u5173\u7cfb\u62bd\u53d6\u4efb\u52a1\u4e2d\uff0c\u5b9e\u4f53\u53ef\u80fd\u5728\u6587\u6863\u4e2d\u591a\u6b21\u51fa\u73b0\uff0c\u4e14\u5176\u5173\u7cfb\u4f1a\u968f\u4e0a\u4e0b\u6587\u53d8\u5316\u3002\u4ee5\u5f80\u65b9\u6cd5\u4ec5\u5173\u6ce8\u5b9e\u4f53\u51fa\u73b0\u7684\u53e5\u5b50\uff0c\u96be\u4ee5\u6355\u6349\u5168\u5c40\u4e0a\u4e0b\u6587\uff0c\u4ece\u800c\u5f71\u54cd\u5173\u7cfb\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u9700\u8981\u6709\u6548\u5efa\u6a21\u6574\u4e2a\u6587\u6863\u8303\u56f4\u5185\u7684\u5b9e\u4f53\u5173\u7cfb\u548c\u63a8\u7406\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8f93\u5165\u5d4c\u5165\u65b9\u6cd5\uff0c\u7528\u4e8e\u6355\u6349\u5b9e\u4f53\u5728\u6574\u4e2a\u6587\u6863\u4e2d\u7684\u4f4d\u7f6e\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5b83\u4eec\u51fa\u73b0\u7684\u5177\u4f53\u7247\u6bb5\u3002\u901a\u8fc7\u5c06\u5b9e\u4f53\u89c6\u4e3a\u72ec\u7acb\u7247\u6bb5\u8fdb\u884c\u7f16\u7801\uff0c\u5b9e\u73b0\u5168\u7403\u5173\u7cfb\u5efa\u6a21\u548c\u591a\u53e5\u63a8\u7406\u3002", "result": "\u5728DocRED\u3001Re-DocRED\u548cREBEL\u7b49\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u6587\u6863\u7ea7\u5b9e\u4f53\u5173\u7cfb\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u7406\u8bba\u4e0a\u63a8\u52a8\u4e86\u5168\u7403\u4e0a\u4e0b\u6587\u5efa\u6a21\u4e0e\u591a\u53e5\u63a8\u7406\u6280\u672f\u7684\u53d1\u5c55\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e0a\u80fd\u5927\u5e45\u63d0\u5347\u9700\u8981\u5168\u9762\u5b9e\u4f53\u7ea7\u5206\u6790\u548c\u53ef\u89e3\u91ca\u6027\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u8868\u73b0\u3002"}}
{"id": "2507.22927", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.22927", "abs": "https://arxiv.org/abs/2507.22927", "authors": ["Zhehao Tan", "Yihan Jiao", "Dan Yang", "Lei Liu", "Jie Feng", "Duolin Sun", "Yue Shen", "Jian Wang", "Peng Wei", "Jinjie Gu"], "title": "PRGB Benchmark: A Robust Placeholder-Assisted Algorithm for Benchmarking Retrieval-Augmented Generation", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by\nintegrating external knowledge, where the LLM's ability to generate responses\nbased on the combination of a given query and retrieved documents is crucial.\nHowever, most benchmarks focus on overall RAG system performance, rarely\nassessing LLM-specific capabilities. Current benchmarks emphasize broad aspects\nsuch as noise robustness, but lack a systematic and granular evaluation\nframework on document utilization. To this end, we introduce\n\\textit{Placeholder-RAG-Benchmark}, a multi-level fine-grained benchmark,\nemphasizing the following progressive dimensions: (1) multi-level filtering\nabilities, (2) combination abilities, and (3) reference reasoning. To provide a\nmore nuanced understanding of LLMs' roles in RAG systems, we formulate an\ninnovative placeholder-based approach to decouple the contributions of the\nLLM's parametric knowledge and the external knowledge. Experiments demonstrate\nthe limitations of representative LLMs in the RAG system's generation\ncapabilities, particularly in error resilience and context faithfulness. Our\nbenchmark provides a reproducible framework for developing more reliable and\nefficient RAG systems. Our code is available in\nhttps://github.com/Alipay-Med/PRGB.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ec6\u7c92\u5ea6\u7684RAG\u57fa\u51c6\u8bc4\u6d4b\u4f53\u7cfb\uff0c\u53d1\u73b0\u4e3b\u6d41\u5927\u6a21\u578b\u5728\u6587\u6863\u5229\u7528\u65b9\u9762\u4ecd\u6709\u660e\u663e\u4e0d\u8db3\uff0c\u4e3aRAG\u7cfb\u7edf\u7684\u8fdb\u6b65\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u548c\u601d\u8def\u3002", "motivation": "\u867d\u7136RAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09\u7cfb\u7edf\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\uff0c\u4f46\u73b0\u6709\u8bc4\u6d4b\u4f53\u7cfb\u66f4\u5173\u6ce8\u6574\u4f53\u6548\u679c\uff0c\u7f3a\u4e4f\u5bf9LLM\u672c\u8eab\u80fd\u529b\u7684\u7ec6\u81f4\u5206\u6790\uff0c\u5c24\u5176\u662f\u5728\u6587\u6863\u5229\u7528\u4e0a\u3002", "method": "\u63d0\u51fa\u4e86Placeholder-RAG-Benchmark\uff0c\u8fd9\u662f\u4e00\u5957\u591a\u5c42\u6b21\u3001\u7ec6\u7c92\u5ea6\u7684\u57fa\u51c6\uff0c\u805a\u7126\u591a\u7ea7\u8fc7\u6ee4\u80fd\u529b\u3001\u7ec4\u5408\u80fd\u529b\u548c\u53c2\u8003\u63a8\u7406\uff0c\u5e76\u901a\u8fc7\u521b\u65b0\u7684Placeholder\u65b9\u6cd5\u5c06\u6a21\u578b\u56fa\u6709\u77e5\u8bc6\u4e0e\u5916\u90e8\u77e5\u8bc6\u8d21\u732e\u89e3\u8026\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u524d\u4e3b\u6d41LLMs\u5728RAG\u7cfb\u7edf\u4e2d\u7684\u751f\u6210\u80fd\u529b\u5b58\u5728\u5c40\u9650\uff0c\u5c24\u5176\u5728\u9519\u8bef\u6062\u590d\u548c\u5185\u5bb9\u5fe0\u5b9e\u6027\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\u3002\u57fa\u51c6\u4e3a\u5f00\u53d1\u66f4\u53ef\u9760\u9ad8\u6548\u7684RAG\u7cfb\u7edf\u63d0\u4f9b\u53ef\u590d\u73b0\u7684\u8bc4\u6d4b\u6846\u67b6\u3002", "conclusion": "Placeholder-RAG-Benchmark\u53ef\u4ee5\u66f4\u7ec6\u81f4\u5730\u8bc4\u4f30LLM\u5728RAG\u7cfb\u7edf\u4e2d\u7684\u6587\u6863\u5229\u7528\u80fd\u529b\uff0c\u4fc3\u8fdb\u884c\u4e1a\u5185\u5bf9\u66f4\u5f3aRAG\u7cfb\u7edf\u7684\u63a2\u7d22\u4e0e\u6539\u8fdb\u3002"}}
{"id": "2507.22928", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22928", "abs": "https://arxiv.org/abs/2507.22928", "authors": ["Xi Chen", "Aske Plaat", "Niki van Stein"], "title": "How does Chain of Thought Think? Mechanistic Interpretability of Chain-of-Thought Reasoning with Sparse Autoencoding", "comment": null, "summary": "Chain-of-thought (CoT) prompting boosts Large Language Models accuracy on\nmulti-step tasks, yet whether the generated \"thoughts\" reflect the true\ninternal reasoning process is unresolved. We present the first feature-level\ncausal study of CoT faithfulness. Combining sparse autoencoders with activation\npatching, we extract monosemantic features from Pythia-70M and Pythia-2.8B\nwhile they tackle GSM8K math problems under CoT and plain (noCoT) prompting.\nSwapping a small set of CoT-reasoning features into a noCoT run raises answer\nlog-probabilities significantly in the 2.8B model, but has no reliable effect\nin 70M, revealing a clear scale threshold. CoT also leads to significantly\nhigher activation sparsity and feature interpretability scores in the larger\nmodel, signalling more modular internal computation. For example, the model's\nconfidence in generating correct answers improves from 1.2 to 4.3. We introduce\npatch-curves and random-feature patching baselines, showing that useful CoT\ninformation is not only present in the top-K patches but widely distributed.\nOverall, our results indicate that CoT can induce more interpretable internal\nstructures in high-capacity LLMs, validating its role as a structured prompting\nmethod.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u7528\u56e0\u679c\u5206\u6790\u624b\u6bb5\uff0c\u63ed\u793aCoT\u4e0d\u4ec5\u63d0\u5347\u5927\u6a21\u578b\u591a\u6b65\u63a8\u7406\u8868\u73b0\u4e14\u80fd\u5e26\u6765\u66f4\u6e05\u6670\u7684\u5185\u90e8\u8868\u5f81\uff0c\u9a8c\u8bc1\u4e86\u5176\u4fc3\u8fdb\u6a21\u578b\u7ed3\u6784\u5316\u63a8\u7406\u548c\u89e3\u91ca\u6027\u7684\u4f5c\u7528\u3002", "motivation": "\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u5728\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5904\u7406\u591a\u6b65\u9aa4\u4efb\u52a1\u51c6\u786e\u6027\u4e0a\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u6a21\u578b\u751f\u6210\u7684\u201c\u601d\u7ef4\u94fe\u201d\u662f\u5426\u771f\u5b9e\u53cd\u6620\u5176\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\u3002\u4f5c\u8005\u8bd5\u56fe\u901a\u8fc7\u7279\u5f81\u5c42\u9762\u7684\u56e0\u679c\u5206\u6790\u7814\u7a76CoT\u7684\u5fe0\u5b9e\u6027\u3002", "method": "\u5c06\u7a00\u758f\u81ea\u52a8\u7f16\u7801\u5668\u4e0e\u6fc0\u6d3b\u4fee\u8865\uff08activation patching\uff09\u6280\u672f\u7ed3\u5408\uff0c\u4ecePythia-70M\u548cPythia-2.8B\u6a21\u578b\u4e2d\u63d0\u53d6\u5355\u8bed\u4e49\u7279\u5f81\u3002\u5728GSM8K\u6570\u5b66\u9898\u76ee\u4e0a\u5206\u522b\u91c7\u7528\u6709CoT\u548c\u65e0CoT\u63d0\u793a\u8bcd\u8fdb\u884c\u8f93\u5165\uff0c\u5e76\u901a\u8fc7\u4ea4\u6362\u7279\u5f81\u6fc0\u6d3b\uff0c\u68c0\u6d4bCoT\u63a8\u7406\u7279\u5f81\u5bf9\u65e0CoT\u6d41\u7a0b\u7684\u5f71\u54cd\uff0c\u4ee5\u5206\u6790\u795e\u7ecf\u5143\u5c42\u9762\u4e0a\u601d\u7ef4\u94fe\u4ea7\u751f\u7684\u6548\u679c\u3002\u6b64\u5916\uff0c\u5f15\u5165patch-curves\u548c\u968f\u673a\u7279\u5f81\u4fee\u8865\u5bf9\u7167\u5b9e\u9a8c\u3002", "result": "\u5c06CoT\u63a8\u7406\u7279\u5f81\u6ce8\u5165\u65e0CoT\u6d41\u7a0b\u53ef\u663e\u8457\u63d0\u5347Pythia-2.8B\u6a21\u578b\u7684\u7b54\u6848\u5bf9\u6570\u6982\u7387\uff08\u4f46\u5bf970M\u6a21\u578b\u65e0\u663e\u8457\u4f5c\u7528\uff09\uff0c\u663e\u793a\u51fa\u6a21\u578b\u89c4\u6a21\u4e0a\u7684\u660e\u663e\u95e8\u69db\u3002\u5927\u6a21\u578b\u5728CoT\u4e0b\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u6fc0\u6d3b\u7a00\u758f\u5ea6\u53ca\u66f4\u597d\u7684\u7279\u5f81\u53ef\u89e3\u91ca\u6027\uff0c\u8868\u660e\u5176\u5185\u90e8\u5206\u5de5\u66f4\u52a0\u6a21\u5757\u5316\uff08\u5982\u7b54\u6848\u7f6e\u4fe1\u5ea6\u4ece1.2\u63d0\u5347\u81f34.3\uff09\u3002\u4fe1\u606f\u4e0d\u4ec5\u5728\u6700\u4f18\u4fee\u8865\u4e2d\u6709\u6548\uff0c\u800c\u662f\u5e7f\u6cdb\u5206\u5e03\u4e8e\u591a\u4e2a\u7279\u5f81\u3002", "conclusion": "CoT\u80fd\u5728\u9ad8\u5bb9\u91cfLLM\u4e2d\u8bf1\u53d1\u66f4\u5177\u53ef\u89e3\u91ca\u6027\u548c\u6a21\u5757\u5316\u7684\u5185\u90e8\u7ed3\u6784\uff0c\u9a8c\u8bc1\u4e86\u601d\u7ef4\u94fe\u4f5c\u4e3a\u7ed3\u6784\u5316\u63d0\u793a\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.22929", "categories": ["cs.CL", "cs.CV", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.22929", "abs": "https://arxiv.org/abs/2507.22929", "authors": ["Xiaoyu Pan", "Yang Bai", "Ke Zou", "Yang Zhou", "Jun Zhou", "Huazhu Fu", "Yih-Chung Tham", "Yong Liu"], "title": "EH-Benchmark Ophthalmic Hallucination Benchmark and Agent-Driven Top-Down Traceable Reasoning Workflow", "comment": "9 figures, 5 tables. submit/6621751", "summary": "Medical Large Language Models (MLLMs) play a crucial role in ophthalmic\ndiagnosis, holding significant potential to address vision-threatening\ndiseases. However, their accuracy is constrained by hallucinations stemming\nfrom limited ophthalmic knowledge, insufficient visual localization and\nreasoning capabilities, and a scarcity of multimodal ophthalmic data, which\ncollectively impede precise lesion detection and disease diagnosis.\nFurthermore, existing medical benchmarks fail to effectively evaluate various\ntypes of hallucinations or provide actionable solutions to mitigate them. To\naddress the above challenges, we introduce EH-Benchmark, a novel ophthalmology\nbenchmark designed to evaluate hallucinations in MLLMs. We categorize MLLMs'\nhallucinations based on specific tasks and error types into two primary\nclasses: Visual Understanding and Logical Composition, each comprising multiple\nsubclasses. Given that MLLMs predominantly rely on language-based reasoning\nrather than visual processing, we propose an agent-centric, three-phase\nframework, including the Knowledge-Level Retrieval stage, the Task-Level Case\nStudies stage, and the Result-Level Validation stage. Experimental results show\nthat our multi-agent framework significantly mitigates both types of\nhallucinations, enhancing accuracy, interpretability, and reliability. Our\nproject is available at https://github.com/ppxy1/EH-Benchmark.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u533b\u5b66\u5927\u8bed\u8a00\u6a21\u578b\u5728\u773c\u79d1\u5e94\u7528\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u8bc4\u6d4b\u57fa\u51c6\u548c\u591a\u667a\u80fd\u4f53\u4e09\u9636\u6bb5\u7f13\u89e3\u6846\u67b6\uff0c\u6781\u5927\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u533b\u5b66\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u773c\u79d1\u8bca\u65ad\u4e2d\u4f5c\u7528\u91cd\u8981\uff0c\u4f46\u5728\u6709\u9650\u7684\u4e13\u4e1a\u77e5\u8bc6\u3001\u89c6\u89c9\u5b9a\u4f4d\u4e0e\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u53ca\u591a\u6a21\u6001\u6570\u636e\u7a00\u7f3a\u7684\u9650\u5236\u4e0b\uff0c\u51c6\u786e\u6027\u53d7\u5e7b\u89c9\u5f71\u54cd\uff0c\u73b0\u6709\u57fa\u51c6\u4e5f\u96be\u4ee5\u6709\u6548\u8bc4\u6d4b\u548c\u51cf\u5c11\u5e7b\u89c9\u3002", "method": "\u63d0\u51fa EH-Benchmark\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30 MLLMs \u5e7b\u89c9\u7684\u65b0\u578b\u773c\u79d1\u57fa\u51c6\u3002\u4f5c\u8005\u5c06\u5e7b\u89c9\u5206\u4e3a\u89c6\u89c9\u7406\u89e3\u548c\u903b\u8f91\u7ec4\u5408\u4e24\u5927\u7c7b\uff0c\u5e76\u7ec6\u5206\u4e3a\u591a\u4e2a\u5b50\u7c7b\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u4ee5\u667a\u80fd\u4f53\u4e3a\u4e2d\u5fc3\u7684\u4e09\u9636\u6bb5\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u62ec\u77e5\u8bc6\u68c0\u7d22\u3001\u6848\u4f8b\u5206\u6790\u53ca\u7ed3\u679c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u591a\u667a\u80fd\u4f53\u6846\u67b6\u6709\u6548\u964d\u4f4e\u4e86\u4e24\u7c7b\u5e7b\u89c9\uff0c\u63d0\u5347\u4e86\u8bca\u65ad\u7684\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "EH-Benchmark \u80fd\u7cfb\u7edf\u5730\u8bc4\u4f30\u5e76\u7f13\u89e3\u533b\u5b66\u5927\u8bed\u8a00\u6a21\u578b\u5728\u773c\u79d1\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u5176\u4e09\u9636\u6bb5\u667a\u80fd\u4f53\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u8868\u73b0\u3002"}}
{"id": "2507.22930", "categories": ["cs.CL", "cs.SI"], "pdf": "https://arxiv.org/pdf/2507.22930", "abs": "https://arxiv.org/abs/2507.22930", "authors": ["Shalini Jangra", "Suparna De", "Nishanth Sastry", "Saeed Fadaei"], "title": "Protecting Vulnerable Voices: Synthetic Dataset Generation for Self-Disclosure Detection", "comment": "15 pages, 4 Figures, Accepted in \"The 17th International Conference\n  on Advances in Social Networks Analysis and Mining -ASONAM-2025\"", "summary": "Social platforms such as Reddit have a network of communities of shared\ninterests, with a prevalence of posts and comments from which one can infer\nusers' Personal Information Identifiers (PIIs). While such self-disclosures can\nlead to rewarding social interactions, they pose privacy risks and the threat\nof online harms. Research into the identification and retrieval of such risky\nself-disclosures of PIIs is hampered by the lack of open-source labeled\ndatasets. To foster reproducible research into PII-revealing text detection, we\ndevelop a novel methodology to create synthetic equivalents of PII-revealing\ndata that can be safely shared. Our contributions include creating a taxonomy\nof 19 PII-revealing categories for vulnerable populations and the creation and\nrelease of a synthetic PII-labeled multi-text span dataset generated from 3\ntext generation Large Language Models (LLMs), Llama2-7B, Llama3-8B, and\nzephyr-7b-beta, with sequential instruction prompting to resemble the original\nReddit posts. The utility of our methodology to generate this synthetic dataset\nis evaluated with three metrics: First, we require reproducibility equivalence,\ni.e., results from training a model on the synthetic data should be comparable\nto those obtained by training the same models on the original posts. Second, we\nrequire that the synthetic data be unlinkable to the original users, through\ncommon mechanisms such as Google Search. Third, we wish to ensure that the\nsynthetic data be indistinguishable from the original, i.e., trained humans\nshould not be able to tell them apart. We release our dataset and code at\nhttps://netsys.surrey.ac.uk/datasets/synthetic-self-disclosure/ to foster\nreproducible research into PII privacy risks in online social media.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5408\u6210\u6807\u6ce8\u4e2a\u4eba\u4fe1\u606f\u62ab\u9732\u7684\u65b0\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u4e86\u7f3a\u4e4f\u516c\u5f00PII\u6807\u6ce8\u6570\u636e\u96be\u9898\uff0c\u5e76\u6709\u6548\u4fdd\u8bc1\u6570\u636e\u5b89\u5168\u6027\u3001\u96be\u6eaf\u6e90\u6027\u3001\u4e0e\u771f\u5b9e\u6570\u636e\u7684\u9ad8\u5ea6\u76f8\u4f3c\uff0c\u6709\u52a9\u793e\u4ea4\u5a92\u4f53\u9690\u79c1\u98ce\u9669\u7814\u7a76\u7684\u53d1\u5c55\u3002", "motivation": "\u793e\u4ea4\u5e73\u53f0\u5982Reddit\u4e2d\u5927\u91cf\u6d89\u53ca\u4e2a\u4eba\u4fe1\u606f\u62ab\u9732\u7684\u5e16\u5b50\uff0c\u4f46\u76f8\u5173\u98ce\u9669\u7814\u7a76\u53d7\u9650\u4e8e\u7f3a\u4e4f\u53ef\u516c\u5f00\u7684\u5e26\u6807\u7b7e\u6570\u636e\u96c6\u3002\u4e3a\u63a8\u8fdb\u8be5\u9886\u57df\u53ef\u590d\u73b0\u6027\u7814\u7a76\uff0c\u9700\u8981\u5b89\u5168\u53ef\u5206\u4eab\u7684\u5408\u6210\u4eba\u5de5\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982Llama2-7B\u3001Llama3-8B\u548czephyr-7b-beta\uff09\u6309\u987a\u5e8f\u63d0\u793a\uff0c\u5408\u6210\u4e0e\u539fReddit\u6570\u636e\u76f8\u4f3c\u3001\u53ef\u516c\u5f00\u7684PII\u6807\u7b7e\u6587\u672c\u6570\u636e\u3002\u6784\u5efa19\u7c7b\u6613\u53d7\u5a01\u80c1\u4eba\u7fa4\u7684PII\u5206\u7c7b\u6cd5\u3002", "result": "\u751f\u6210\u5e76\u516c\u5f00\u4e86\u57fa\u4e8e\u4e09\u79cdLLM\u5408\u6210\u7684\u591a\u6587\u672cPII\u6807\u7b7e\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u4e09\u9879\u6807\u51c6\u8bc4\u4f30\uff1a\uff081\uff09\u6a21\u578b\u5728\u5408\u6210\u6570\u636e\u548c\u539f\u59cb\u6570\u636e\u8bad\u7ec3\u7684\u6548\u679c\u7b49\u4ef7\u6027\uff1b\uff082\uff09\u5408\u6210\u6570\u636e\u65e0\u6cd5\u6eaf\u6e90\u771f\u5b9e\u7528\u6237\uff1b\uff083\uff09\u4eba\u7c7b\u96be\u4ee5\u533a\u5206\u539f\u59cb\u4e0e\u5408\u6210\u6570\u636e\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u80fd\u5b89\u5168\u516c\u5f00\u3001\u7ed3\u6784\u5316\u5408\u6210\u4e14\u4e0e\u771f\u5b9e\u6570\u636e\u9ad8\u5ea6\u7b49\u4ef7\u7684PII\u6570\u636e\u96c6\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u793e\u4ea4\u5a92\u4f53PII\u98ce\u9669\u7814\u7a76\u7684\u53ef\u590d\u73b0\u53d1\u5c55\u3002"}}
{"id": "2507.22931", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22931", "abs": "https://arxiv.org/abs/2507.22931", "authors": ["Shuyu Guo", "Zhaochun Ren"], "title": "Enhancing RAG Efficiency with Adaptive Context Compression", "comment": null, "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs)\nwith external knowledge but incurs significant inference costs due to lengthy\nretrieved contexts. While context compression mitigates this issue, existing\nmethods apply fixed compression rates, over-compressing simple queries or\nunder-compressing complex ones. We propose Adaptive Context Compression for RAG\n(ACC-RAG), a framework that dynamically adjusts compression rates based on\ninput complexity, optimizing inference efficiency without sacrificing accuracy.\nACC-RAG combines a hierarchical compressor (for multi-granular embeddings) with\na context selector to retain minimal sufficient information, akin to human\nskimming. Evaluated on Wikipedia and five QA datasets, ACC-RAG outperforms\nfixed-rate methods and matches/unlocks over 4 times faster inference versus\nstandard RAG while maintaining or improving accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u4e0a\u4e0b\u6587\u538b\u7f29\uff08ACC-RAG\uff09\u6846\u67b6\uff0c\u6839\u636e\u67e5\u8be2\u590d\u6742\u5ea6\u52a8\u6001\u8c03\u6574\u538b\u7f29\u7387\uff0c\u5927\u5e45\u63d0\u5347RAG\u63a8\u7406\u901f\u5ea6\u4e14\u4e0d\u635f\u5931\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u4f20\u7edf\u56fa\u5b9a\u538b\u7f29\u65b9\u6848\u3002", "motivation": "\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\u867d\u7136\u80fd\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u5916\u90e8\u77e5\u8bc6\uff0c\u4f46\u56e0\u9700\u8981\u5904\u7406\u5927\u91cf\u5197\u957f\u7684\u68c0\u7d22\u5185\u5bb9\u800c\u5bfc\u81f4\u63a8\u7406\u6210\u672c\u5f88\u9ad8\u3002\u73b0\u6709\u4e0a\u4e0b\u6587\u538b\u7f29\u65b9\u6cd5\u91c7\u7528\u56fa\u5b9a\u538b\u7f29\u7387\uff0c\u65e0\u6cd5\u517c\u987e\u7b80\u5355\u67e5\u8be2\u548c\u590d\u6742\u67e5\u8be2\u7684\u5dee\u5f02\uff0c\u5bb9\u6613\u8fc7\u5ea6\u6216\u4e0d\u8db3\u538b\u7f29\u3002", "method": "\u672c\u6587\u63d0\u51fa\u81ea\u9002\u5e94\u4e0a\u4e0b\u6587\u538b\u7f29\u7684RAG\uff08ACC-RAG\uff09\u6846\u67b6\uff0c\u6839\u636e\u8f93\u5165\u590d\u6742\u5ea6\u52a8\u6001\u8c03\u6574\u538b\u7f29\u7387\u3002ACC-RAG\u5305\u62ec\u5206\u5c42\u538b\u7f29\u5668\uff08\u5b9e\u73b0\u591a\u7c92\u5ea6\u5d4c\u5165\uff09\u548c\u4e0a\u4e0b\u6587\u9009\u62e9\u5668\uff0c\u5b9e\u73b0\u7c7b\u4f3c\u4eba\u7c7b\u6d4f\u89c8\u7684\u6700\u5c0f\u5145\u5206\u4fe1\u606f\u4fdd\u7559\u3002", "result": "\u5728Wikipedia\u53ca\u4e94\u4e2a\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\uff0cACC-RAG\u76f8\u8f83\u4e8e\u56fa\u5b9a\u538b\u7f29\u7387\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\uff0c\u5e76\u4e14\u5728\u63a8\u7406\u901f\u5ea6\u4e0a\u53ef\u8fbe\u5230\u6807\u51c6RAG\u76844\u500d\u4ee5\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u51c6\u786e\u7387\u3002", "conclusion": "ACC-RAG\u80fd\u591f\u5728\u4e0d\u727a\u7272\u6a21\u578b\u51c6\u786e\u7387\u7684\u524d\u63d0\u4e0b\uff0c\u5927\u5e45\u63d0\u5347\u63a8\u7406\u6548\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u56fa\u5b9a\u538b\u7f29\u65b9\u6cd5\uff0c\u4e3a\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4efb\u52a1\u5e26\u6765\u66f4\u7075\u6d3b\u9ad8\u6548\u7684\u65b9\u6848\u3002"}}
{"id": "2507.22932", "categories": ["cs.CL", "q-fin.GN"], "pdf": "https://arxiv.org/pdf/2507.22932", "abs": "https://arxiv.org/abs/2507.22932", "authors": ["Baptiste Lefort", "Eric Benhamou", "Beatrice Guez", "Jean-Jacques Ohana", "Ethan Setrouk", "Alban Etienne"], "title": "FinMarBa: A Market-Informed Dataset for Financial Sentiment Classification", "comment": "8 pages", "summary": "This paper presents a novel hierarchical framework for portfolio\noptimization, integrating lightweight Large Language Models (LLMs) with Deep\nReinforcement Learning (DRL) to combine sentiment signals from financial news\nwith traditional market indicators. Our three-tier architecture employs base RL\nagents to process hybrid data, meta-agents to aggregate their decisions, and a\nsuper-agent to merge decisions based on market data and sentiment analysis.\nEvaluated on data from 2018 to 2024, after training on 2000-2017, the framework\nachieves a 26% annualized return and a Sharpe ratio of 1.2, outperforming\nequal-weighted and S&P 500 benchmarks. Key contributions include scalable\ncross-modal integration, a hierarchical RL structure for enhanced stability,\nand open-source reproducibility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u8f7b\u91cf\u7ea7LLM\u4e0e\u5c42\u6b21\u5316DRL\u7ed3\u5408\u7684\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u65b9\u6cd5\uff0c\u6709\u6548\u878d\u5408\u5e02\u573a\u6307\u6807\u548c\u65b0\u95fb\u60c5\u611f\uff0c\u5b9e\u73b0\u5e74\u531626%\u7684\u9ad8\u6536\u76ca\uff0c\u5e76\u5f00\u6e90\u590d\u73b0\uff0c\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\u3002", "motivation": "\u5728\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u9886\u57df\uff0c\u5982\u4f55\u6709\u6548\u878d\u5408\u91d1\u878d\u65b0\u95fb\u8206\u60c5\u4e0e\u4f20\u7edf\u5e02\u573a\u6307\u6807\u3001\u63d0\u5347\u6536\u76ca\u5e76\u589e\u5f3a\u6a21\u578b\u7a33\u5b9a\u6027\u4e00\u76f4\u662f\u91cd\u8981\u6311\u6218\u3002\u5f53\u524d\u7684\u65b9\u6cd5\u5728\u5229\u7528\u591a\u6a21\u6001\u6570\u636e\u548c\u63d0\u5347\u6a21\u578b\u53ef\u6269\u5c55\u6027\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u4e09\u7ea7\u5206\u5c42\u67b6\u6784\uff0c\u5c06\u8f7b\u91cf\u7ea7\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u4e0e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60(DRL)\u76f8\u7ed3\u5408\u3002\u5e95\u5c42RL\u667a\u80fd\u4f53\u5904\u7406\u878d\u5408\u7684\u5e02\u573a\u4e0e\u8206\u60c5\u6570\u636e\uff0c\u5143\u667a\u80fd\u4f53\u5bf9\u51b3\u7b56\u8fdb\u884c\u805a\u5408\uff0c\u8d85\u7ea7\u667a\u80fd\u4f53\u6700\u7ec8\u878d\u5408\u5e02\u573a\u4e0e\u60c5\u611f\u5206\u6790\u7ed3\u679c\uff0c\u4e3a\u6295\u8d44\u7ec4\u5408\u63d0\u4f9b\u4f18\u5316\u5efa\u8bae\u3002", "result": "\u57282018-2024\u5e74\u6570\u636e\u4e0a\u6d4b\u8bd5\uff08\u8bad\u7ec3\u6570\u636e\u4e3a2000-2017\uff09\uff0c\u6846\u67b6\u5b9e\u73b0\u4e86\u5e74\u531626%\u6536\u76ca\u7387\u548c1.2\u7684\u590f\u666e\u6bd4\u7387\uff0c\u5747\u4f18\u4e8e\u7b49\u6743\u548c\u6807\u666e500\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u5206\u5c42\u67b6\u6784\u901a\u8fc7\u8de8\u6a21\u6001\u878d\u5408\u4e0e\u5c42\u6b21\u5316RL\u7ed3\u6784\u63d0\u5347\u4e86\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u7684\u7a33\u5b9a\u6027\u4e0e\u6536\u76ca\u8868\u73b0\u3002\u540c\u65f6\uff0c\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u53ef\u590d\u73b0\u6027\uff0c\u5bf9\u91d1\u878d\u4eba\u5de5\u667a\u80fd\u9886\u57df\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.22933", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22933", "abs": "https://arxiv.org/abs/2507.22933", "authors": ["Anthony C Davis", "Burhan Sadiq", "Tianmin Shu", "Chien-Ming Huang"], "title": "Augmented Vision-Language Models: A Systematic Review", "comment": null, "summary": "Recent advances in visual-language machine learning models have demonstrated\nexceptional ability to use natural language and understand visual scenes by\ntraining on large, unstructured datasets. However, this training paradigm\ncannot produce interpretable explanations for its outputs, requires retraining\nto integrate new information, is highly resource-intensive, and struggles with\ncertain forms of logical reasoning. One promising solution involves integrating\nneural networks with external symbolic information systems, forming neural\nsymbolic systems that can enhance reasoning and memory abilities. These neural\nsymbolic systems provide more interpretable explanations to their outputs and\nthe capacity to assimilate new information without extensive retraining.\nUtilizing powerful pre-trained Vision-Language Models (VLMs) as the core neural\ncomponent, augmented by external systems, offers a pragmatic approach to\nrealizing the benefits of neural-symbolic integration. This systematic\nliterature review aims to categorize techniques through which visual-language\nunderstanding can be improved by interacting with external symbolic information\nsystems.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u901a\u8fc7\u7ed3\u5408\u5916\u90e8\u7b26\u53f7\u7cfb\u7edf\u63d0\u5347\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u7684\u6700\u65b0\u6280\u672f\u4e0e\u7814\u7a76\u8fdb\u5c55\uff0c\u5f3a\u8c03\u795e\u7ecf-\u7b26\u53f7\u7cfb\u7edf\u5728\u53ef\u89e3\u91ca\u6027\u548c\u9002\u5e94\u6027\u7b49\u65b9\u9762\u7684\u4f18\u52bf\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u867d\u7136\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5b58\u5728\u53ef\u89e3\u91ca\u6027\u5dee\u3001\u96be\u4ee5\u96c6\u6210\u65b0\u77e5\u8bc6\u3001\u8d44\u6e90\u6d88\u8017\u5927\u3001\u903b\u8f91\u63a8\u7406\u80fd\u529b\u6709\u9650\u7b49\u95ee\u9898\u3002\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u901a\u8fc7\u5f15\u5165\u5916\u90e8\u7b26\u53f7\u7cfb\u7edf\uff0c\u63d0\u5347\u6a21\u578b\u5728\u63a8\u7406\u3001\u8bb0\u5fc6\u548c\u89e3\u91ca\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff08systematic literature review\uff09\u7684\u65b9\u6cd5\uff0c\u68b3\u7406\u5206\u6790\u4e86\u89c6\u89c9-\u8bed\u8a00\u7406\u89e3\u4e0e\u5916\u90e8\u7b26\u53f7\u4fe1\u606f\u7cfb\u7edf\u4ea4\u4e92\u7684\u4e3b\u8981\u6280\u672f\u8def\u5f84\u548c\u65b9\u5f0f\u3002", "result": "\u5f52\u7eb3\u5e76\u5206\u7c7b\u4e86\u5c06\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4e0e\u5916\u90e8\u7b26\u53f7\u4fe1\u606f\u7cfb\u7edf\u7ed3\u5408\u4ee5\u63d0\u5347\u5176\u7406\u89e3\u80fd\u529b\u7684\u5404\u79cd\u6280\u672f\u624b\u6bb5\uff0c\u5e76\u603b\u7ed3\u4e86\u5f53\u524d\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\u3002", "conclusion": "\u5c06\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4e0e\u5916\u90e8\u7b26\u53f7\u4fe1\u606f\u7cfb\u7edf\u7ed3\u5408\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3001\u63a8\u7406\u80fd\u529b\u4e0e\u5bf9\u65b0\u77e5\u8bc6\u7684\u9002\u5e94\u6027\uff0c\u662f\u89c6\u89c9-\u8bed\u8a00\u7406\u89e3\u9886\u57df\u7684\u91cd\u8981\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2507.22934", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22934", "abs": "https://arxiv.org/abs/2507.22934", "authors": ["Jingwei Zhao", "Yuhua Wen", "Qifei Li", "Minchi Hu", "Yingying Zhou", "Jingyao Xue", "Junyang Wu", "Yingming Gao", "Zhengqi Wen", "Jianhua Tao", "Ya Li"], "title": "Deep Learning Approaches for Multimodal Intent Recognition: A Survey", "comment": "Submitted to ACM Computing Surveys", "summary": "Intent recognition aims to identify users' underlying intentions,\ntraditionally focusing on text in natural language processing. With growing\ndemands for natural human-computer interaction, the field has evolved through\ndeep learning and multimodal approaches, incorporating data from audio, vision,\nand physiological signals. Recently, the introduction of Transformer-based\nmodels has led to notable breakthroughs in this domain. This article surveys\ndeep learning methods for intent recognition, covering the shift from unimodal\nto multimodal techniques, relevant datasets, methodologies, applications, and\ncurrent challenges. It provides researchers with insights into the latest\ndevelopments in multimodal intent recognition (MIR) and directions for future\nresearch.", "AI": {"tldr": "\u672c\u6587\u662f\u4e00\u7bc7\u5173\u4e8e\u610f\u56fe\u8bc6\u522b\u9886\u57df\u6df1\u5ea6\u5b66\u4e60\u548c\u591a\u6a21\u6001\u65b9\u6cd5\u7684\u7efc\u8ff0\uff0c\u603b\u7ed3\u4e86\u6280\u672f\u8fdb\u5c55\u3001\u6570\u636e\u96c6\u3001\u5e94\u7528\u3001\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\uff0c\u91cd\u70b9\u5173\u6ce8Transformer\u7b49\u65b0\u6a21\u578b\u5e26\u6765\u7684\u7a81\u7834\u53ca\u5176\u5bf9\u81ea\u7136\u4eba\u673a\u4ea4\u4e92\u7684\u63a8\u52a8\u4f5c\u7528\u3002", "motivation": "\u968f\u7740\u4eba\u673a\u81ea\u7136\u4ea4\u4e92\u9700\u6c42\u7684\u4e0d\u65ad\u589e\u957f\uff0c\u4f20\u7edf\u4ec5\u4f9d\u8d56\u6587\u672c\u7684\u610f\u56fe\u8bc6\u522b\u5df2\u65e0\u6cd5\u6ee1\u8db3\u5b9e\u9645\u5e94\u7528\uff0c\u4fc3\u4f7f\u7814\u7a76\u5411\u591a\u6a21\u6001\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u6f14\u8fdb\u3002", "method": "\u672c\u6587\u7efc\u8ff0\u4e86\u610f\u56fe\u8bc6\u522b\u9886\u57df\u4e2d\uff0c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7684\u53d1\u5c55\uff0c\u5305\u62ec\u4ece\u5355\u4e00\u6a21\u6001\u5230\u591a\u6a21\u6001\u7684\u6f14\u53d8\uff0c\u4ee5\u53ca\u76f8\u5173\u6570\u636e\u96c6\u3001\u65b9\u6cd5\u3001\u5e94\u7528\u548c\u5f53\u524d\u9762\u4e34\u7684\u6311\u6218\u3002", "result": "\u603b\u7ed3\u4e86\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u548c\u591a\u6a21\u6001\u610f\u56fe\u8bc6\u522b\u9886\u57df\u7684\u4e3b\u8981\u8fdb\u5c55\uff0c\u5bf9Transformer\u7b49\u65b0\u6a21\u578b\u5e26\u6765\u7684\u7a81\u7834\u8fdb\u884c\u4e86\u4ecb\u7ecd\uff0c\u5e76\u5f52\u7eb3\u4e86\u9762\u5411\u672a\u6765\u7814\u7a76\u7684\u4e3b\u8981\u65b9\u5411\u3002", "conclusion": "\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u6709\u6548\u63a8\u52a8\u4e86\u610f\u56fe\u8bc6\u522b\u7684\u53d1\u5c55\uff0c\u4f46\u4ecd\u6709\u8bf8\u591a\u6311\u6218\uff0c\u9700\u8981\u6301\u7eed\u63a2\u7d22\u65b0\u578b\u6a21\u578b\u4e0e\u8de8\u6a21\u6001\u4fe1\u606f\u7684\u878d\u5408\u3002"}}
{"id": "2507.22935", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22935", "abs": "https://arxiv.org/abs/2507.22935", "authors": ["Kathleen Mealey", "Jonathan A. Karr Jr.", "Priscila Saboia Moreira", "Paul R. Brenner", "Charles F. Vardeman II"], "title": "Trusted Knowledge Extraction for Operations and Maintenance Intelligence", "comment": null, "summary": "Deriving operational intelligence from organizational data repositories is a\nkey challenge due to the dichotomy of data confidentiality vs data integration\nobjectives, as well as the limitations of Natural Language Processing (NLP)\ntools relative to the specific knowledge structure of domains such as\noperations and maintenance. In this work, we discuss Knowledge Graph\nconstruction and break down the Knowledge Extraction process into its Named\nEntity Recognition, Coreference Resolution, Named Entity Linking, and Relation\nExtraction functional components. We then evaluate sixteen NLP tools in concert\nwith or in comparison to the rapidly advancing capabilities of Large Language\nModels (LLMs). We focus on the operational and maintenance intelligence use\ncase for trusted applications in the aircraft industry. A baseline dataset is\nderived from a rich public domain US Federal Aviation Administration dataset\nfocused on equipment failures or maintenance requirements. We assess the\nzero-shot performance of NLP and LLM tools that can be operated within a\ncontrolled, confidential environment (no data is sent to third parties). Based\non our observation of significant performance limitations, we discuss the\nchallenges related to trusted NLP and LLM tools as well as their Technical\nReadiness Level for wider use in mission-critical industries such as aviation.\nWe conclude with recommendations to enhance trust and provide our open-source\ncurated dataset to support further baseline testing and evaluation.", "AI": {"tldr": "\u672c\u8bba\u6587\u9488\u5bf9\u822a\u7a7a\u884c\u4e1a\u8bbe\u5907\u7ef4\u62a4\u5e94\u7528\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e8616\u79cdNLP\u5de5\u5177\u53caLLM\u7684\u77e5\u8bc6\u62bd\u53d6\u80fd\u529b\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u5b89\u5168\u53d7\u63a7\u73af\u5883\u4e0b\u53d7\u9650\u660e\u663e\uff0c\u5c1a\u4e0d\u80fd\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5173\u952e\u884c\u4e1a\u3002\u4f5c\u8005\u5f00\u6e90\u6570\u636e\u96c6\u5e76\u63d0\u51fa\u4e86\u589e\u5f3a\u53ef\u4fe1\u5ea6\u7684\u5efa\u8bae\u3002", "motivation": "\u7ec4\u7ec7\u6570\u636e\u4ed3\u5e93\u9700\u8981\u5e73\u8861\u6570\u636e\u673a\u5bc6\u6027\u548c\u6570\u636e\u96c6\u6210\u7684\u8981\u6c42\uff0c\u5e76\u4e14NLP\u5de5\u5177\u5728\u7279\u5b9a\u9886\u57df\uff08\u5982\u8fd0\u7ef4\u9886\u57df\uff09\u77e5\u8bc6\u7ed3\u6784\u4e0b\u8868\u73b0\u6709\u9650\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u7814\u7a76\u5982\u4f55\u9ad8\u6548\u3001\u5b89\u5168\u5730\u4ece\u6570\u636e\u4e2d\u63d0\u53d6\u77e5\u8bc6\u4ee5\u83b7\u5f97\u8fd0\u8425\u667a\u80fd\u3002", "method": "\u8bba\u6587\u5bf9\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u8fc7\u7a0b\u8fdb\u884c\u4e86\u5206\u89e3\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u3001\u5171\u6307\u6d88\u89e3\u3001\u5b9e\u4f53\u94fe\u63a5\u548c\u5173\u7cfb\u62bd\u53d6\u56db\u4e2a\u529f\u80fd\u73af\u8282\uff0c\u5e76\u5bf916\u79cdNLP\u5de5\u5177\u53ca\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u96f6\u6837\u672c\u8868\u73b0\u8fdb\u884c\u4e86\u7cfb\u7edf\u8bc4\u4f30\u3002\u6570\u636e\u96c6\u4ee5\u7f8e\u56fd\u8054\u90a6\u822a\u7a7a\u5c40\u516c\u5f00\u8bbe\u5907\u6545\u969c/\u7ef4\u62a4\u9700\u6c42\u6570\u636e\u4e3a\u57fa\u7840\uff0c\u4e14\u6240\u6709\u8bc4\u4f30\u5747\u4fdd\u8bc1\u6570\u636e\u5728\u53d7\u63a7\u73af\u5883\u5185\u5904\u7406\uff0c\u4e0d\u5916\u53d1\u81f3\u7b2c\u4e09\u65b9\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u524dNLP\u548cLLM\u5de5\u5177\u5728\u53d7\u63a7\u73af\u5883\u4e0b\u7684\u96f6\u6837\u672c\u6027\u80fd\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u9ad8\u5ea6\u53ef\u4fe1\u7684\u822a\u7a7a\u5de5\u4e1a\u667a\u80fd\u5e94\u7528\u4e2d\uff0c\u5b83\u4eec\u7684\u6280\u672f\u6210\u719f\u5ea6\uff08TRL\uff09\u5c1a\u4e0d\u8db3\u4ee5\u5e7f\u6cdb\u5e94\u7528\u3002\u8bba\u6587\u8fd8\u5f00\u6e90\u4e86\u7ecf\u6574\u7406\u7684\u6570\u636e\u96c6\u4ee5\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u57fa\u7ebf\u6d4b\u8bd5\u4e0e\u8bc4\u4f30\u3002", "conclusion": "\u73b0\u6709\u7684NLP\u53caLLM\u5de5\u5177\u5728\u822a\u7a7a\u7b49\u5173\u952e\u884c\u4e1a\u7684\u53d7\u63a7\u73af\u5883\u4e0b\uff0c\u4e00\u65b9\u9762\u56e0\u9690\u79c1\u548c\u5b89\u5168\u9700\u6c42\u9650\u5236\uff0c\u53e6\u4e00\u65b9\u9762\u53d7\u6280\u672f\u80fd\u529b\u5236\u7ea6\uff0c\u96be\u4ee5\u6ee1\u8db3\u4fe1\u4efb\u548c\u96c6\u6210\u8981\u6c42\u3002\u4f5c\u8005\u5efa\u8bae\u52a0\u5f3a\u5de5\u5177\u7684\u53ef\u4fe1\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u653e\u6570\u636e\u96c6\u4ee5\u652f\u6301\u540e\u7eed\u6539\u8fdb\u548c\u8bc4\u4f30\u3002"}}
{"id": "2507.22936", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.HC", "q-fin.CP"], "pdf": "https://arxiv.org/pdf/2507.22936", "abs": "https://arxiv.org/abs/2507.22936", "authors": ["Md Talha Mohsin"], "title": "Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis", "comment": "22 Pages, 6 Tables, 7 Figures", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\na wide variety of Financial Natural Language Processing (FinNLP) tasks.\nHowever, systematic comparisons among widely used LLMs remain underexplored.\nGiven the rapid advancement and growing influence of LLMs in financial\nanalysis, this study conducts a thorough comparative evaluation of five leading\nLLMs, GPT, Claude, Perplexity, Gemini and DeepSeek, using 10-K filings from the\n'Magnificent Seven' technology companies. We create a set of domain-specific\nprompts and then use three methodologies to evaluate model performance: human\nannotation, automated lexical-semantic metrics (ROUGE, Cosine Similarity,\nJaccard), and model behavior diagnostics (prompt-level variance and\nacross-model similarity). The results show that GPT gives the most coherent,\nsemantically aligned, and contextually relevant answers; followed by Claude and\nPerplexity. Gemini and DeepSeek, on the other hand, have more variability and\nless agreement. Also, the similarity and stability of outputs change from\ncompany to company and over time, showing that they are sensitive to how\nprompts are written and what source material is used.", "AI": {"tldr": "\u5bf9\u4e94\u79cd\u4e3b\u6d41LLM\u5728\u91d1\u878d10-K\u6587\u672c\u6458\u8981\u4efb\u52a1\u4e2d\u5c55\u5f00\u7cfb\u7edf\u6027\u8bc4\u6d4b\uff0c\u53d1\u73b0GPT\u8868\u73b0\u6700\u4f73\uff0c\u4e0d\u540c\u6a21\u578b\u95f4\u5dee\u5f02\u660e\u663e\uff0c\u4e14\u53d7\u4e1a\u6001\u548c\u65f6\u95f4\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u91d1\u878d\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4e0d\u540c\u4e3b\u6d41LLM\u4e4b\u95f4\u7684\u7cfb\u7edf\u6bd4\u8f83\u4ecd\u7136\u76f8\u5bf9\u7f3a\u4e4f\u3002\u968f\u7740LLM\u5728\u91d1\u878d\u5206\u6790\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u7cfb\u7edf\u6027\u8bc4\u4f30\u5bf9\u5b9e\u9645\u5e94\u7528\u5177\u6709\u91cd\u8981\u6307\u5bfc\u610f\u4e49\u3002", "method": "\u9009\u53d6GPT\u3001Claude\u3001Perplexity\u3001Gemini\u548cDeepSeek\u4e94\u79cd\u4e3b\u6d41LLM\uff0c\u57fa\u4e8e'Magnificent Seven'\u79d1\u6280\u516c\u53f8\u768410-K\u8d22\u62a5\uff0c\u8bbe\u8ba1\u91d1\u878d\u9886\u57df\u7279\u5b9a\u7684prompt\uff0c\u4ece\u4eba\u5de5\u6807\u6ce8\u3001\u81ea\u52a8\u8bcd\u6c47\u2014\u8bed\u4e49\u6307\u6807\uff08\u5982ROUGE\u3001\u4f59\u5f26\u76f8\u4f3c\u5ea6\u3001Jaccard\uff09\u548c\u6a21\u578b\u884c\u4e3a\u8bca\u65ad\uff08prompt\u5c42\u9762\u7684\u65b9\u5dee\u3001\u4e0d\u540c\u6a21\u578b\u8f93\u51fa\u76f8\u4f3c\u6027\uff09\u4e09\u4e2a\u65b9\u9762\uff0c\u7efc\u5408\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "GPT\u5728\u8fde\u8d2f\u6027\u3001\u8bed\u4e49\u5bf9\u9f50\u4ee5\u53ca\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u5176\u6b21\u662fClaude\u548cPerplexity\u3002Gemini\u548cDeepSeek\u8868\u73b0\u6ce2\u52a8\u66f4\u5927\u3001\u4e00\u81f4\u6027\u8f83\u5dee\u3002\u6b64\u5916\uff0c\u6a21\u578b\u8f93\u51fa\u7684\u76f8\u4f3c\u6027\u548c\u7a33\u5b9a\u6027\u56e0\u516c\u53f8\u548c\u65f6\u95f4\u6709\u6240\u53d8\u5316\uff0c\u5bf9prompt\u5199\u4f5c\u65b9\u5f0f\u548c\u539f\u59cb\u6750\u6599\u654f\u611f\u3002", "conclusion": "\u5728\u91d1\u878dNLP\u573a\u666f\u4e0b\uff0cGPT\u8868\u73b0\u6700\u4f18\uff0cClaude\u548cPerplexity\u6b21\u4e4b\u3002\u4e0d\u540cLLM\u7684\u8868\u73b0\u53d7\u5177\u4f53\u4efb\u52a1\u3001\u6570\u636e\u548cprompt\u8bbe\u8ba1\u5f71\u54cd\u663e\u8457\uff0c\u8bf4\u660e\u6a21\u578b\u9009\u62e9\u9700\u7ed3\u5408\u5b9e\u9645\u9700\u6c42\u548c\u573a\u666f\u7279\u6027\u3002"}}
{"id": "2507.22937", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22937", "abs": "https://arxiv.org/abs/2507.22937", "authors": ["Jinkun Zhao", "Yuanshuai Wang", "Xingjian Zhang", "Ruibo Chen", "Xingchuang Liao", "Junle Wang", "Lei Huang", "Kui Zhang", "Wenjun Wu"], "title": "CoE-Ops: Collaboration of LLM-based Experts for AIOps Question-Answering", "comment": null, "summary": "With the rapid evolution of artificial intelligence, AIOps has emerged as a\nprominent paradigm in DevOps. Lots of work has been proposed to improve the\nperformance of different AIOps phases. However, constrained by domain-specific\nknowledge, a single model can only handle the operation requirement of a\nspecific task,such as log parser,root cause analysis. Meanwhile, combining\nmultiple models can achieve more efficient results, which have been proved in\nboth previous ensemble learning and the recent LLM training domain. Inspired by\nthese works,to address the similar challenges in AIOPS, this paper first\nproposes a collaboration-of-expert framework(CoE-Ops) incorporating a\ngeneral-purpose large language model task classifier. A retrieval-augmented\ngeneration mechanism is introduced to improve the framework's capability in\nhandling both Question-Answering tasks with high-level(Code,build,Test,etc.)\nand low-level(fault analysis,anomaly detection,etc.). Finally, the proposed\nmethod is implemented in the AIOps domain, and extensive experiments are\nconducted on the DevOps-EVAL dataset. Experimental results demonstrate that\nCoE-Ops achieves a 72% improvement in routing accuracy for high-level AIOps\ntasks compared to existing CoE methods, delivers up to 8% accuracy enhancement\nover single AIOps models in DevOps problem resolution, and outperforms\nlarger-scale Mixture-of-Experts (MoE) models by up to 14% in accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u4e13\u5bb6\u534f\u4f5c\u7684\u5927\u8bed\u8a00\u6a21\u578b+\u68c0\u7d22\u589e\u5f3a\u673a\u5236\u7684\u65b0AIOps\u6846\u67b6\uff0c\u5728\u591a\u4e2aAIOps\u4efb\u52a1\u4e0a\u5168\u9762\u8d85\u8d8a\u4e86\u4f20\u7edf\u53ca\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u6307\u6807\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u5f53\u524dAIOps\u9886\u57df\u5185\uff0c\u5355\u4e00\u6a21\u578b\u901a\u5e38\u53d7\u9650\u4e8e\u7279\u5b9a\u9886\u57df\u77e5\u8bc6\uff0c\u53ea\u80fd\u5b8c\u6210\u7279\u5b9a\u4efb\u52a1\uff08\u5982\u65e5\u5fd7\u89e3\u6790\u3001\u6839\u56e0\u5206\u6790\uff09\uff0c\u800c\u591a\u6a21\u578b\u534f\u4f5c\u65b9\u6cd5\u5728\u63d0\u5347\u6027\u80fd\u4e0a\u5df2\u6709\u524d\u4eba\u7814\u7a76\uff08\u96c6\u6210\u5b66\u4e60\u3001LLM\u7b49\uff09\uff0c\u8be5\u6587\u5e0c\u671b\u89e3\u51b3AIOps\u4e2d\u5355\u6a21\u578b\u9002\u5e94\u6027\u5dee\u3001\u7ec4\u5408\u6a21\u578b\u6548\u7387\u4e0d\u8db3\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e13\u5bb6\u534f\u4f5c\u67b6\u6784\uff08CoE-Ops\uff09\uff0c\u6574\u5408\u4e86\u901a\u7528\u578b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4efb\u52a1\u5206\u7c7b\u5668\uff0c\u5e76\u5f15\u5165\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u673a\u5236\uff0c\u4ee5\u589e\u5f3a\u8be5\u6846\u67b6\u5728\u5904\u7406\u9ad8\u3001\u4f4e\u5c42\u6b21\u95ee\u9898\uff08\u5982\u4ee3\u7801\u3001\u6784\u5efa\u3001\u6d4b\u8bd5\u4e0e\u6545\u969c\u5206\u6790\u3001\u5f02\u5e38\u68c0\u6d4b\u7b49\uff09\u65f6\u7684\u80fd\u529b\uff0c\u5e76\u5728AIOps\u9886\u57df\u5185\u8fdb\u884c\u5b9e\u73b0\u53ca\u5b9e\u9a8c\u3002", "result": "\u5728DevOps-EVAL\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cCoE-Ops\u5728\u9ad8\u5c42\u6b21AIOps\u4efb\u52a1\u7684\u8def\u7531\u7cbe\u5ea6\u6bd4\u73b0\u6709\u4e13\u5bb6\u534f\u4f5c\u65b9\u6cd5\u63d0\u9ad8\u4e8672%\uff0c\u5728DevOps\u95ee\u9898\u89e3\u51b3\u4e0a\u6bd4\u5355\u4e00AIOps\u6a21\u578b\u63d0\u5347\u4e868%\u51c6\u786e\u7387\uff0c\u4e14\u5728\u51c6\u786e\u7387\u4e0a\u8f83\u5927\u89c4\u6a21\u7684\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\uff08MoE\uff09\u63d0\u5347\u4e8614%\u3002", "conclusion": "\u63d0\u51fa\u7684CoE-Ops\u6846\u67b6\u80fd\u591f\u9ad8\u6548\u6574\u5408\u591a\u79cd\u6a21\u578b\uff0c\u901a\u8fc7LLM\u5206\u7c7b\u5668\u4e0e\u68c0\u7d22\u589e\u5f3a\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86AIOps\u4efb\u52a1\u7684\u9002\u5e94\u6027\u4e0e\u7cbe\u5ea6\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5355\u6a21\u578b\u53ca\u6df7\u5408\u4e13\u5bb6\u65b9\u6cd5\u3002"}}
{"id": "2507.22938", "categories": ["cs.CL", "cs.AI", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.22938", "abs": "https://arxiv.org/abs/2507.22938", "authors": ["Sumit Soman", "H. G. Ranjani", "Sujoy Roychowdhury", "Venkata Dharma Surya Narayana Sastry", "Akshat Jain", "Pranav Gangrade", "Ayaaz Khan"], "title": "A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents", "comment": "Accepted for publication at the KDD 2025 Workshop on Structured\n  Knowledge for Large Language Models", "summary": "Question-Answering (QA) from technical documents often involves questions\nwhose answers are present in figures, such as flowcharts or flow diagrams.\nText-based Retrieval Augmented Generation (RAG) systems may fail to answer such\nquestions. We leverage graph representations of flowcharts obtained from Visual\nlarge Language Models (VLMs) and incorporate them in a text-based RAG system to\nshow that this approach can enable image retrieval for QA in the telecom\ndomain. We present the end-to-end approach from processing technical documents,\nclassifying image types, building graph representations, and incorporating them\nwith the text embedding pipeline for efficient retrieval. We benchmark the same\non a QA dataset created based on proprietary telecom product information\ndocuments. Results show that the graph representations obtained using a\nfine-tuned VLM model have lower edit distance with respect to the ground truth,\nwhich illustrate the robustness of these representations for flowchart images.\nFurther, the approach for QA using these representations gives good retrieval\nperformance using text-based embedding models, including a telecom-domain\nadapted one. Our approach also alleviates the need for a VLM in inference,\nwhich is an important cost benefit for deployed QA systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5bf9\u6280\u672f\u6587\u6863\u4e2d\u7684\u6d41\u7a0b\u56fe\u5148\u7528\u89c6\u89c9\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u56fe\u7ed3\u6784\uff0c\u518d\u7ed3\u5408\u6587\u672cRAG\u7528\u4e8e\u9ad8\u6548\u95ee\u7b54\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u63d0\u5347\u4e86\u95ee\u7b54\u51c6\u786e\u7387\uff0c\u4e14\u63a8\u7406\u901f\u5ea6\u5feb\u3001\u6210\u672c\u4f4e\u3002", "motivation": "\u5f53\u524d\u6280\u672f\u6587\u6863\u4e2d\u7684\u95ee\u7b54\u7cfb\u7edf\uff08QA\uff09\u5e38\u5e38\u9047\u5230\u9700\u8981\u53c2\u8003\u6d41\u7a0b\u56fe\u7b49\u56fe\u7247\u4fe1\u606f\u7684\u95ee\u9898\uff0c\u800c\u4f20\u7edf\u7684\u57fa\u4e8e\u6587\u672c\u7684RAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u8fd9\u7c7b\u95ee\u9898\u3002", "method": "\u7528\u89c6\u89c9\u5927\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u83b7\u53d6\u6d41\u7a0b\u56fe\u7684\u56fe\u7ed3\u6784\u8868\u793a\uff0c\u5e76\u5c06\u8fd9\u4e9b\u4fe1\u606f\u878d\u5408\u8fdb\u6587\u672cRAG\u7cfb\u7edf\u3002\u6b64\u5916\uff0c\u8bbe\u8ba1\u4e86\u7aef\u5230\u7aef\u6d41\u7a0b\uff0c\u5305\u62ec\u6280\u672f\u6587\u6863\u5904\u7406\u3001\u56fe\u7247\u7c7b\u578b\u5206\u7c7b\u3001\u56fe\u7ed3\u6784\u6784\u5efa\u548c\u4e0e\u6587\u672c\u5d4c\u5165\u6d41\u7a0b\u7ed3\u5408\uff0c\u5b9e\u73b0\u9ad8\u6548\u68c0\u7d22\u3002", "result": "\u5728\u57fa\u4e8e\u4e13\u6709\u7535\u4fe1\u4ea7\u54c1\u6587\u6863\u521b\u5efa\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u5fae\u8c03\u540e\u7684VLM\u6a21\u578b\u83b7\u53d6\u7684\u56fe\u7ed3\u6784\u8868\u793a\u4e0e\u771f\u5b9e\u7b54\u6848\u7684\u7f16\u8f91\u8ddd\u79bb\u8f83\u4f4e\uff0c\u8868\u660e\u5176\u5bf9\u6d41\u7a0b\u56fe\u56fe\u50cf\u7684\u8868\u793a\u7a33\u5065\u3002\u57fa\u4e8e\u8fd9\u4e9b\u7ed3\u6784\u8fdb\u884cQA\u8868\u73b0\u826f\u597d\uff0c\u4e14\u68c0\u7d22\u6027\u80fd\u4f18\u5f02\uff0c\u540c\u65f6\u63a8\u7406\u8fc7\u7a0b\u4e2d\u51cf\u5c11\u4e86\u5bf9VLM\u7684\u4f9d\u8d56\uff0c\u964d\u4f4e\u4e86\u90e8\u7f72\u6210\u672c\u3002", "conclusion": "\u5c06\u6d41\u7a0b\u56fe\u7b49\u56fe\u50cf\u7684\u7ed3\u6784\u4fe1\u606f\u4e0e\u6587\u672c\u68c0\u7d22\u7cfb\u7edf\u7ed3\u5408\uff0c\u63d0\u5347\u4e86\u7535\u4fe1\u9886\u57dfQA\u7cfb\u7edf\u5bf9\u6280\u672f\u6587\u6863\u56fe\u50cf\u4fe1\u606f\u7684\u5904\u7406\u80fd\u529b\uff0c\u5e76\u53ef\u6709\u6548\u964d\u4f4e\u63a8\u7406\u6210\u672c\u3002"}}
{"id": "2507.22939", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22939", "abs": "https://arxiv.org/abs/2507.22939", "authors": ["Bastien Le Guellec", "Kokou Adambounou", "Lisa C Adams", "Thibault Agripnidis", "Sung Soo Ahn", "Radhia Ait Chalal", "Tugba Akinci D Antonoli", "Philippe Amouyel", "Henrik Andersson", "Raphael Bentegeac", "Claudio Benzoni", "Antonino Andrea Blandino", "Felix Busch", "Elif Can", "Riccardo Cau", "Armando Ugo Cavallo", "Christelle Chavihot", "Erwin Chiquete", "Renato Cuocolo", "Eugen Divjak", "Gordana Ivanac", "Barbara Dziadkowiec Macek", "Armel Elogne", "Salvatore Claudio Fanni", "Carlos Ferrarotti", "Claudia Fossataro", "Federica Fossataro", "Katarzyna Fulek", "Michal Fulek", "Pawel Gac", "Martyna Gachowska", "Ignacio Garcia Juarez", "Marco Gatti", "Natalia Gorelik", "Alexia Maria Goulianou", "Aghiles Hamroun", "Nicolas Herinirina", "Krzysztof Kraik", "Dominik Krupka", "Quentin Holay", "Felipe Kitamura", "Michail E Klontzas", "Anna Kompanowska", "Rafal Kompanowski", "Alexandre Lefevre", "Tristan Lemke", "Maximilian Lindholz", "Lukas Muller", "Piotr Macek", "Marcus Makowski", "Luigi Mannacio", "Aymen Meddeb", "Antonio Natale", "Beatrice Nguema Edzang", "Adriana Ojeda", "Yae Won Park", "Federica Piccione", "Andrea Ponsiglione", "Malgorzata Poreba", "Rafal Poreba", "Philipp Prucker", "Jean Pierre Pruvo", "Rosa Alba Pugliesi", "Feno Hasina Rabemanorintsoa", "Vasileios Rafailidis", "Katarzyna Resler", "Jan Rotkegel", "Luca Saba", "Ezann Siebert", "Arnaldo Stanzione", "Ali Fuat Tekin", "Liz Toapanta Yanchapaxi", "Matthaios Triantafyllou", "Ekaterini Tsaoulia", "Evangelia Vassalou", "Federica Vernuccio", "Johan Wasselius", "Weilang Wang", "Szymon Urban", "Adrian Wlodarczak", "Szymon Wlodarczak", "Andrzej Wysocki", "Lina Xu", "Tomasz Zatonski", "Shuhang Zhang", "Sebastian Ziegelmayer", "Gregory Kuchcinski", "Keno K Bressem"], "title": "PARROT: An Open Multilingual Radiology Reports Dataset", "comment": null, "summary": "Rationale and Objectives: To develop and validate PARROT (Polyglottal\nAnnotated Radiology Reports for Open Testing), a large, multicentric,\nopen-access dataset of fictional radiology reports spanning multiple languages\nfor testing natural language processing applications in radiology. Materials\nand Methods: From May to September 2024, radiologists were invited to\ncontribute fictional radiology reports following their standard reporting\npractices. Contributors provided at least 20 reports with associated metadata\nincluding anatomical region, imaging modality, clinical context, and for\nnon-English reports, English translations. All reports were assigned ICD-10\ncodes. A human vs. AI report differentiation study was conducted with 154\nparticipants (radiologists, healthcare professionals, and non-healthcare\nprofessionals) assessing whether reports were human-authored or AI-generated.\nResults: The dataset comprises 2,658 radiology reports from 76 authors across\n21 countries and 13 languages. Reports cover multiple imaging modalities (CT:\n36.1%, MRI: 22.8%, radiography: 19.0%, ultrasound: 16.8%) and anatomical\nregions, with chest (19.9%), abdomen (18.6%), head (17.3%), and pelvis (14.1%)\nbeing most prevalent. In the differentiation study, participants achieved 53.9%\naccuracy (95% CI: 50.7%-57.1%) in distinguishing between human and AI-generated\nreports, with radiologists performing significantly better (56.9%, 95% CI:\n53.3%-60.6%, p<0.05) than other groups. Conclusion: PARROT represents the\nlargest open multilingual radiology report dataset, enabling development and\nvalidation of natural language processing applications across linguistic,\ngeographic, and clinical boundaries without privacy constraints.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u5e76\u5f00\u653e\u4e86\u5168\u7403\u6700\u5927\u3001\u591a\u8bed\u79cd\u7684\u865a\u6784\u5f71\u50cf\u62a5\u544a\u6570\u636e\u96c6\uff08PARROT\uff09\uff0c\u5305\u542b\u5927\u6837\u672c\u3001\u591a\u5143\u5143\u6570\u636e\u4e0e\u82f1\u6587\u5bf9\u7167\uff0c\u5b9e\u73b0NLP\u6a21\u578b\u8de8\u8bed\u79cd\u548c\u4e34\u5e8a\u573a\u666f\u6d4b\u8bd5\u3002\u6570\u636e\u96c6\u6d88\u9664\u4e86\u9690\u79c1\u9650\u5236\uff0c\u6709\u529b\u63a8\u52a8\u533b\u5b66NLP\u53d1\u5c55\u3002", "motivation": "\u7531\u4e8e\u73b0\u6709\u7684\u533b\u5b66\u5f71\u50cf\u62a5\u544a\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u7814\u7a76\u53d7\u9650\u4e8e\u6570\u636e\u96c6\u8bed\u8a00\u5355\u4e00\u3001\u6837\u672c\u91cf\u4e0d\u8db3\u4ee5\u53ca\u6d89\u53ca\u9690\u79c1\u4fdd\u62a4\u7b49\u95ee\u9898\uff0c\u8feb\u5207\u9700\u8981\u6784\u5efa\u4e00\u4e2a\u591a\u8bed\u8a00\u3001\u5f00\u653e\u5171\u4eab\u3001\u4e14\u9690\u79c1\u53cb\u597d\u7684\u5927\u578b\u5f71\u50cf\u62a5\u544a\u6570\u636e\u96c6\uff0c\u4ee5\u4fc3\u8fdb\u8de8\u8bed\u79cdNLP\u5728\u533b\u5b66\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "\u8be5\u7814\u7a76\u901a\u8fc7\u9080\u8bf7\u6765\u81ea21\u4e2a\u56fd\u5bb6\u517176\u4f4d\u653e\u5c04\u79d1\u533b\u751f\uff0c\u6309\u7167\u5404\u81ea\u60ef\u7528\u62a5\u544a\u65b9\u5f0f\u64b0\u5199\u865a\u6784\u7684\u5f71\u50cf\u5b66\u62a5\u544a\uff0c\u6db5\u76d613\u79cd\u8bed\u8a00\u3002\u6bcf\u4efd\u62a5\u544a\u914d\u6709\u76f8\u5173\u5143\u6570\u636e\uff08\u89e3\u5256\u90e8\u4f4d\u3001\u68c0\u67e5\u7c7b\u578b\u3001\u4e34\u5e8a\u80cc\u666f\u7b49\uff09\uff0c\u975e\u82f1\u6587\u62a5\u544a\u5747\u9644\u6709\u82f1\u6587\u7ffb\u8bd1\uff0c\u5e76\u7edf\u4e00\u5206\u914dICD-10\u7f16\u7801\u3002\u53e6\u5f00\u5c55\u4e86\u7531154\u540d\u53c2\u4e0e\u8005\u53c2\u4e0e\u7684\u4eba-\u673a\u62a5\u544a\u8fa8\u522b\u5b9e\u9a8c\uff0c\u4ee5\u8bc4\u4f30AI\u751f\u6210\u62a5\u544a\u4e0e\u771f\u4eba\u62a5\u544a\u7684\u53ef\u8fa8\u8bc6\u6027\u3002", "result": "\u6700\u7ec8\u6536\u96c6\u52302,658\u4efd\u62a5\u544a\uff0c\u6db5\u76d6CT\u3001MRI\u3001X\u7ebf\u3001\u8d85\u58f0\u7b49\u591a\u79cd\u5f71\u50cf\u65b9\u5f0f\uff0c\u4ee5\u53ca\u591a\u4e2a\u4e3b\u8981\u89e3\u5256\u90e8\u4f4d\uff08\u5982\u80f8\u90e8\u3001\u8179\u90e8\u3001\u5934\u90e8\u3001\u9aa8\u76c6\uff09\u3002\u5728\u8fa8\u522b\u5b9e\u9a8c\u4e2d\uff0c\u53c2\u4e0e\u8005\u6574\u4f53\u8fa8\u522b\u6b63\u786e\u7387\u4e3a53.9%\uff1b\u653e\u5c04\u79d1\u533b\u751f\u7ec4\u8868\u73b0\u6700\u4f73\uff0c\u6b63\u786e\u7387\u4e3a56.9%\u3002", "conclusion": "PARROT\u6570\u636e\u96c6\u662f\u76ee\u524d\u89c4\u6a21\u6700\u5927\u3001\u6837\u672c\u591a\u8bed\u79cd\u3001\u5b8c\u5168\u5f00\u653e\u7684\u865a\u6784\u653e\u5c04\u5b66\u62a5\u544a\u96c6\uff0c\u53ef\u5e7f\u6cdb\u4fc3\u8fdb\u8de8\u8bed\u8a00\u3001\u8de8\u5730\u57df\u3001\u8de8\u4e34\u5e8a\u573a\u666f\u7684\u533b\u5b66NLP\u76f8\u5173\u5e94\u7528\u5f00\u53d1\u548c\u9a8c\u8bc1\uff0c\u65e0\u9700\u62c5\u5fe7\u9690\u79c1\u95ee\u9898\u3002"}}
{"id": "2507.22940", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.22940", "abs": "https://arxiv.org/abs/2507.22940", "authors": ["Rui Jiao", "Yue Zhang", "Jinku Li"], "title": "Trustworthy Reasoning: Evaluating and Enhancing Factual Accuracy in LLM Intermediate Thought Processes", "comment": null, "summary": "We present RELIANCE (Reasoning Evaluation with Logical Integrity and Accuracy\nfor Confidence Enhancement), a novel framework addressing a critical\nvulnerability in Large Language Models (LLMs): the prevalence of factual\ninaccuracies within intermediate reasoning steps despite correct final answers.\nThis phenomenon poses substantial risks in high-stakes domains including\nhealthcare, legal analysis, and scientific research, where erroneous yet\nconfidently presented reasoning can mislead users into dangerous decisions. Our\nframework integrates three core components: (1) a specialized fact-checking\nclassifier trained on counterfactually augmented data to detect subtle factual\ninconsistencies within reasoning chains; (2) a Group Relative Policy\nOptimization (GRPO) reinforcement learning approach that balances factuality,\ncoherence, and structural correctness through multi-dimensional rewards; and\n(3) a mechanistic interpretability module examining how factuality improvements\nmanifest in model activations during reasoning processes. Extensive evaluation\nacross ten state-of-the-art models reveals concerning patterns: even leading\nmodels like Claude-3.7 and GPT-o1 demonstrate reasoning factual accuracy of\nonly 81.93% and 82.57% respectively. RELIANCE significantly enhances factual\nrobustness (up to 49.90% improvement) while maintaining or improving\nperformance on challenging benchmarks including Math-500, AIME-2024, and GPQA.\nFurthermore, our activation-level analysis provides actionable insights into\nhow factual enhancements reshape reasoning trajectories within model\narchitectures, establishing foundations for future training methodologies that\nexplicitly target factual robustness through activation-guided optimization.", "AI": {"tldr": "RELIANCE\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u5927\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6bcf\u4e00\u6b65\u7684\u4e8b\u5b9e\u51c6\u786e\u7387\uff0c\u5e76\u63d0\u51fa\u6fc0\u6d3b\u5c42\u53ef\u89e3\u91ca\u6027\u5206\u6790\uff0c\u6709\u671b\u4e3a\u672a\u6765\u63d0\u5347LLMs\u4e8b\u5b9e\u5065\u58ee\u6027\u63d0\u4f9b\u6280\u672f\u8def\u7ebf\u3002", "motivation": "\u8fd1\u5e74\u6765\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\uff0c\u5c3d\u7ba1\u6700\u7ec8\u7b54\u6848\u6b63\u786e\uff0c\u4f46\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u4e2d\u7ecf\u5e38\u5b58\u5728\u4e8b\u5b9e\u6027\u9519\u8bef\u3002\u5c24\u5176\u5728\u533b\u7597\u3001\u6cd5\u5f8b\u53ca\u79d1\u7814\u7b49\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u8fd9\u79cd\u5e26\u6709\u81ea\u4fe1\u7684\u9519\u8bef\u63a8\u7406\u5bf9\u7528\u6237\u51b3\u7b56\u6784\u6210\u4e25\u91cd\u5371\u9669\u3002\u56e0\u6b64\uff0c\u9700\u8981\u63d0\u5347LLMs\u5728\u63a8\u7406\u5168\u8fc7\u7a0b\u4e2d\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faRELIANCE\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u6210\u90e8\u5206\uff1a1\uff09\u5229\u7528\u53cd\u4e8b\u5b9e\u589e\u5f3a\u6570\u636e\u8bad\u7ec3\u7684\u4e8b\u5b9e\u6838\u67e5\u5206\u7c7b\u5668\uff0c\u5728\u63a8\u7406\u94fe\u4e2d\u68c0\u6d4b\u7ec6\u5fae\u7684\u4e8b\u5b9e\u4e0d\u4e00\u81f4\u6027\uff1b2\uff09\u4f7f\u7528\u7fa4\u4f53\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u5f3a\u5316\u5b66\u4e60\uff0c\u901a\u8fc7\u591a\u7ef4\u5956\u52b1\u540c\u65f6\u63d0\u5347\u4e8b\u5b9e\u6027\u3001\u8fde\u8d2f\u6027\u548c\u7ed3\u6784\u6b63\u786e\u6027\uff1b3\uff09\u673a\u5236\u53ef\u89e3\u91ca\u6027\u6a21\u5757\uff0c\u5206\u6790\u4e8b\u5b9e\u6027\u63d0\u5347\u5728\u6a21\u578b\u6fc0\u6d3b\u5c42\u9762\u7684\u4f53\u73b0\u3002", "result": "\u5728\u5341\u4e2a\u6700\u5148\u8fdb\u7684\u5927\u6a21\u578b\u4e0a\u8bc4\u4f30\u540e\u53d1\u73b0\uff0c\u5373\u4f7f\u662fClaude-3.7\u548cGPT-o1\u7b49\u9886\u5148\u6a21\u578b\uff0c\u5176\u63a8\u7406\u4e8b\u5b9e\u51c6\u786e\u7387\u4ec5\u4e3a81.93%\u548c82.57%\u3002RELIANCE\u53ef\u4f7f\u4e8b\u5b9e\u5065\u58ee\u6027\u63d0\u5347\u6700\u9ad8\u8fbe49.90%\uff0c\u4e14\u5728Math-500\u3001AIME-2024\u548cGPQA\u7b49\u9ad8\u96be\u5ea6\u57fa\u51c6\u4e0a\u8868\u73b0\u63d0\u5347\u6216\u6301\u5e73\u3002\u6fc0\u6d3b\u5c42\u5206\u6790\u8fd8\u4e3a\u672a\u6765\u901a\u8fc7\u6fc0\u6d3b\u5c42\u4f18\u5316\u63d0\u5347\u4e8b\u5b9e\u5065\u58ee\u6027\u63d0\u4f9b\u652f\u6301\u3002", "conclusion": "RELIANCE\u6709\u6548\u89e3\u51b3\u4e86LLMs\u5728\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u4e2d\u7684\u4e8b\u5b9e\u6027\u9519\u8bef\u95ee\u9898\uff0c\u5927\u5e45\u589e\u5f3a\u4e86\u6a21\u578b\u63a8\u7406\u7684\u4e8b\u5b9e\u5065\u58ee\u6027\uff0c\u5e76\u4e3a\u540e\u7eed\u901a\u8fc7\u6fc0\u6d3b\u5c42\u4f18\u5316\u8fdb\u4e00\u6b65\u63d0\u5347\u4e8b\u5b9e\u6027\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.22941", "categories": ["cs.CL", "cs.CY", "cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2507.22941", "abs": "https://arxiv.org/abs/2507.22941", "authors": ["Paul Minchella", "Lo\u00efc Verlingue", "St\u00e9phane Chr\u00e9tien", "R\u00e9mi Vaucher", "Guillaume Metzler"], "title": "SigBERT: Combining Narrative Medical Reports and Rough Path Signature Theory for Survival Risk Estimation in Oncology", "comment": "12 pages, 2 figures, accepted for ECML PKDD 2025", "summary": "Electronic medical reports (EHR) contain a vast amount of information that\ncan be leveraged for machine learning applications in healthcare. However,\nexisting survival analysis methods often struggle to effectively handle the\ncomplexity of textual data, particularly in its sequential form. Here, we\npropose SigBERT, an innovative temporal survival analysis framework designed to\nefficiently process a large number of clinical reports per patient. SigBERT\nprocesses timestamped medical reports by extracting and averaging word\nembeddings into sentence embeddings. To capture temporal dynamics from the time\nseries of sentence embedding coordinates, we apply signature extraction from\nrough path theory to derive geometric features for each patient, which\nsignificantly enhance survival model performance by capturing complex temporal\ndynamics. These features are then integrated into a LASSO-penalized Cox model\nto estimate patient-specific risk scores. The model was trained and evaluated\non a real-world oncology dataset from the L\\'eon B\\'erard Center corpus, with a\nC-index score of 0.75 (sd 0.014) on the independent test cohort. SigBERT\nintegrates sequential medical data to enhance risk estimation, advancing\nnarrative-based survival analysis.", "AI": {"tldr": "SigBERT\u7ed3\u5408BERT\u548c\u7c97\u8def\u5f84signature\u6280\u672f\uff0c\u5c06\u6587\u672c\u65f6\u5e8f\u7279\u5f81\u5f15\u5165\u751f\u5b58\u5206\u6790\uff0c\u5728\u771f\u5b9e\u80bf\u7624\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u8f83\u597d\u8868\u73b0\uff0c\u63d0\u5347\u4e86\u57fa\u4e8e\u6587\u672c\u7684\u98ce\u9669\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7684\u751f\u5b58\u5206\u6790\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u4e2d\u7684\u590d\u6742\u6587\u672c\u6570\u636e\uff0c\u7279\u522b\u662f\u5728\u987a\u5e8f\u6027\u65b9\u9762\u3002\u5982\u4f55\u5229\u7528\u5927\u91cf\u7684\u4e34\u5e8a\u6587\u672c\u4fe1\u606f\u63d0\u5347\u751f\u5b58\u5206\u6790\u6a21\u578b\u7684\u8868\u73b0\u662f\u4e00\u4e2a\u4e9f\u5f85\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86SigBERT\u6846\u67b6\uff1a\u5148\u7528BERT\u62bd\u53d6\u65f6\u95f4\u6233\u533b\u7597\u62a5\u544a\u7684\u8bcd\u5d4c\u5165\uff0c\u5e76\u5e73\u5747\u751f\u6210\u53e5\u5b50\u5d4c\u5165\uff0c\u518d\u901a\u8fc7\u7c97\u8def\u5f84\u7406\u8bba\u7684signature\u63d0\u53d6\u65b9\u6cd5\u5f97\u5230\u6bcf\u4e2a\u60a3\u8005\u7684\u51e0\u4f55\u7279\u5f81\uff0c\u6700\u540e\u5c06\u8fd9\u4e9b\u7279\u5f81\u8f93\u5165\u5230LASSO\u60e9\u7f5a\u7684Cox\u6a21\u578b\u4e2d\u7528\u4ee5\u98ce\u9669\u8bc4\u5206\u3002", "result": "\u5728L\u00e9on B\u00e9rard Center\u7684\u771f\u5b9e\u80bf\u7624\u5b66\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0cSigBERT\u6a21\u578b\u5728\u72ec\u7acb\u6d4b\u8bd5\u961f\u5217\u4e0a\u53d6\u5f97\u4e86C-index 0.75\uff08\u6807\u51c6\u5dee0.014\uff09\u3002", "conclusion": "SigBERT\u80fd\u591f\u6709\u6548\u96c6\u6210\u987a\u5e8f\u533b\u7597\u6587\u672c\u4fe1\u606f\uff0c\u589e\u5f3a\u98ce\u9669\u4f30\u8ba1\u80fd\u529b\uff0c\u5bf9\u57fa\u4e8e\u53d9\u8ff0\u7684\u751f\u5b58\u5206\u6790\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b0\u8fdb\u5c55\u3002"}}
{"id": "2507.22943", "categories": ["cs.CL", "stat.ME"], "pdf": "https://arxiv.org/pdf/2507.22943", "abs": "https://arxiv.org/abs/2507.22943", "authors": ["Shirley V Wang", "Georg Hahn", "Sushama Kattinakere Sreedhara", "Mufaddal Mahesri", "Haritha S. Pillai", "Rajendra Aldis", "Joyce Lii", "Sarah K. Dutcher", "Rhoda Eniafe", "Jamal T. Jones", "Keewan Kim", "Jiwei He", "Hana Lee", "Sengwee Toh", "Rishi J Desai", "Jie Yang"], "title": "A chart review process aided by natural language processing and multi-wave adaptive sampling to expedite validation of code-based algorithms for large database studies", "comment": null, "summary": "Background: One of the ways to enhance analyses conducted with large claims\ndatabases is by validating the measurement characteristics of code-based\nalgorithms used to identify health outcomes or other key study parameters of\ninterest. These metrics can be used in quantitative bias analyses to assess the\nrobustness of results for an inferential study given potential bias from\noutcome misclassification. However, extensive time and resource allocation are\ntypically re-quired to create reference-standard labels through manual chart\nreview of free-text notes from linked electronic health records. Methods: We\ndescribe an expedited process that introduces efficiency in a validation study\nus-ing two distinct mechanisms: 1) use of natural language processing (NLP) to\nreduce time spent by human reviewers to review each chart, and 2) a multi-wave\nadaptive sampling approach with pre-defined criteria to stop the validation\nstudy once performance characteristics are identified with sufficient\nprecision. We illustrate this process in a case study that validates the\nperformance of a claims-based outcome algorithm for intentional self-harm in\npatients with obesity. Results: We empirically demonstrate that the\nNLP-assisted annotation process reduced the time spent on review per chart by\n40% and use of the pre-defined stopping rule with multi-wave samples would have\nprevented review of 77% of patient charts with limited compromise to precision\nin derived measurement characteristics. Conclusion: This approach could\nfacilitate more routine validation of code-based algorithms used to define key\nstudy parameters, ultimately enhancing understanding of the reliability of\nfind-ings derived from database studies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e0e\u81ea\u9002\u5e94\u62bd\u6837\u7684\u65b0\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u57fa\u4e8e\u4ee3\u7801\u7b97\u6cd5\u5065\u5eb7\u7ed3\u679c\u8bc6\u522b\u7684\u9a8c\u8bc1\u6548\u7387\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u524d\u63d0\u4e0b\u51cf\u5c11\u4e86\u5927\u91cf\u4eba\u5de5\u5de5\u4f5c\uff0c\u6709\u52a9\u4e8e\u6570\u636e\u5e93\u7814\u7a76\u7684\u53ef\u9760\u6027\u63d0\u5347\u3002", "motivation": "\u57fa\u4e8e\u4ee3\u7801\u7684\u7b97\u6cd5\u5728\u5065\u5eb7\u7814\u7a76\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u51c6\u786e\u6027\u5f80\u5f80\u9700\u8981\u901a\u8fc7\u624b\u52a8\u5ba1\u67e5\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6765\u9a8c\u8bc1\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u8d39\u65f6\u8d39\u529b\u3002\u63d0\u5347\u9a8c\u8bc1\u6548\u7387\u5bf9\u4e8e\u6570\u636e\u5e93\u7814\u7a76\u7684\u53ef\u4fe1\u5ea6\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u63d0\u51fa\u5e76\u5e94\u7528\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1a\uff081\uff09\u5229\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u51cf\u5c11\u4eba\u5de5\u5ba1\u67e5\u6bcf\u4efd\u75c5\u4f8b\u7684\u65f6\u95f4\uff1b\uff082\uff09\u591a\u6ce2\u6b21\u81ea\u9002\u5e94\u62bd\u6837\uff0c\u5236\u5b9a\u7cbe\u786e\u5ea6\u8fbe\u6807\u7684\u63d0\u524d\u7ec8\u6b62\u6807\u51c6\uff0c\u4ece\u800c\u63a7\u5236\u6240\u9700\u5ba1\u67e5\u7684\u75c5\u4f8b\u6570\u91cf\u3002", "result": "NLP\u8f85\u52a9\u5ba1\u67e5\u5c06\u5355\u4efd\u75c5\u5386\u7684\u5ba1\u67e5\u65f6\u95f4\u51cf\u5c1140%\uff0c\u591a\u6ce2\u6b21\u62bd\u6837\u65b9\u6848\u53ef\u51cf\u5c1177%\u7684\u75c5\u4f8b\u5ba1\u67e5\u91cf\uff0c\u540c\u65f6\u5bf9\u6d4b\u91cf\u7cbe\u5ea6\u5f71\u54cd\u6709\u9650\u3002", "conclusion": "\u8be5\u6d41\u7a0b\u53ef\u9ad8\u6548\u4fc3\u8fdb\u57fa\u4e8e\u4ee3\u7801\u7684\u7b97\u6cd5\u5e38\u89c4\u5316\u9a8c\u8bc1\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u6570\u636e\u5e93\u7814\u7a76\u7ed3\u679c\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2507.22944", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.22944", "abs": "https://arxiv.org/abs/2507.22944", "authors": ["Naomi Omeonga wa Kayembe"], "title": "Opacity as Authority: Arbitrariness and the Preclusion of Contestation", "comment": null, "summary": "This article redefines arbitrariness not as a normative flaw or a symptom of\ndomination, but as a foundational functional mechanism structuring human\nsystems and interactions. Diverging from critical traditions that conflate\narbitrariness with injustice, it posits arbitrariness as a semiotic trait: a\nproperty enabling systems - linguistic, legal, or social - to operate\neffectively while withholding their internal rationale. Building on Ferdinand\nde Saussure's concept of l'arbitraire du signe, the analysis extends this\nprinciple beyond language to demonstrate its cross-domain applicability,\nparticularly in law and social dynamics. The paper introduces the \"Motivation\n-> Constatability -> Contestability\" chain, arguing that motivation functions\nas a crucial interface rendering an act's logic vulnerable to intersubjective\ncontestation. When this chain is broken through mechanisms like\n\"immotivization\" or \"Conflict Lateralization\" (exemplified by \"the blur of the\nwolf drowned in the fish\"), acts produce binding effects without exposing their\nrationale, thus precluding justiciability. This structural opacity, while\nappearing illogical, is a deliberate design protecting authority from\naccountability. Drawing on Shannon's entropy model, the paper formalizes\narbitrariness as A = H(L|M) (conditional entropy). It thereby proposes a modern\ntheory of arbitrariness as a neutral operator central to control as well as\ncare, an overlooked dimension of interpersonal relations. While primarily\ndeveloped through human social systems, this framework also illuminates a new\npathway for analyzing explainability in advanced artificial intelligence\nsystems.", "AI": {"tldr": "\u672c\u6587\u5c06\u4efb\u610f\u6027\u4ece\u4f20\u7edf\u7684\u8d1f\u9762\u89c6\u89d2\u8f6c\u4e3a\u4e2d\u6027\u4e43\u81f3\u6838\u5fc3\u673a\u5236\uff0c\u63d0\u51fa\u5176\u5728\u8bed\u8a00\u3001\u6cd5\u5f8b\u3001\u793e\u4f1a\u4e92\u52a8\u548cAI\u53ef\u89e3\u91ca\u6027\u4e2d\uff0c\u90fd\u662f\u4fdd\u62a4\u6743\u5a01\u548c\u7ef4\u6301\u7cfb\u7edf\u8fd0\u4f5c\u7684\u7ed3\u6784\u7279\u5f81\u3002", "motivation": "\u6279\u5224\u4f20\u7edf\u7406\u8bba\u5c06\u4efb\u610f\u6027\u7b49\u540c\u4e8e\u4e0d\u516c\u6b63\u3001\u652f\u914d\u6216\u89c4\u8303\u7f3a\u9677\uff0c\u4f5c\u8005\u65e8\u5728\u91cd\u65b0\u754c\u5b9a\u4efb\u610f\u6027\u5728\u5404\u7c7b\u4eba\u7c7b\u7cfb\u7edf\u4e2d\u7684\u529f\u80fd\uff0c\u5e76\u7528\u4ee5\u89e3\u91ca\u6cd5\u5f8b\u548c\u793e\u4f1a\u4e92\u52a8\u4e2d\u7684\u7ed3\u6784\u6027\u4e0d\u900f\u660e\u3002", "method": "\u4f5c\u8005\u57fa\u4e8e\u7d22\u7eea\u5c14\u7684\u7b26\u53f7\u4efb\u610f\u6027\u7406\u8bba\uff0c\u5c06\u5176\u4ece\u8bed\u8a00\u9886\u57df\u6269\u5c55\u5230\u6cd5\u5f8b\u3001\u793e\u4f1a\u7cfb\u7edf\uff0c\u5e76\u7ed3\u5408\u9999\u519c\u7684\u4fe1\u606f\u71b5\u6a21\u578b\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5c06\u201c\u52a8\u673a-\u53ef\u8bc1\u5b9e\u6027-\u53ef\u4e89\u8bae\u6027\u201d\u94fe\u6761\u4e0e\u7cfb\u7edf\u63a7\u5236\u5173\u8054\u8d77\u6765\u7684\u5f62\u5f0f\u5316\u6a21\u578b\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u201c\u52a8\u673a-\u53ef\u8bc1\u5b9e\u6027-\u53ef\u4e89\u8bae\u6027\u201d\u94fe\u6761\uff0c\u89e3\u91ca\u4e86\u5f53\u94fe\u6761\u65ad\u88c2\u65f6\uff0c\u4efb\u610f\u6027\u63a9\u76d6\u4e86\u7cfb\u7edf\u8fd0\u4f5c\u7684\u5185\u90e8\u52a8\u56e0\uff0c\u4ece\u800c\u4f7f\u6743\u529b\u89c4\u907f\u95ee\u8d23\u3002\u6b64\u5916\uff0c\u8fd9\u4e00\u6846\u67b6\u88ab\u7528\u4e8e\u89e3\u91caAI\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u95ee\u9898\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u5206\u6790\u65b0\u601d\u8def\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\uff0c\u4efb\u610f\u6027\u672c\u8d28\u4e0a\u662f\u4e00\u79cd\u7ed3\u6784\u6027\u673a\u5236\uff0c\u662f\u4eba\u7c7b\u7cfb\u7edf\u548c\u4e92\u52a8\u7684\u57fa\u672c\u529f\u80fd\uff0c\u800c\u975e\u4ec5\u4ec5\u662f\u4e00\u79cd\u89c4\u8303\u7f3a\u9677\u6216\u652f\u914d\u7684\u8868\u73b0\u3002"}}
